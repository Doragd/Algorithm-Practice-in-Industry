[
    {
        "title": "Exploring the Carbon Footprint of Hugging Face's ML Models: A Repository\n  Mining Study",
        "url": "http://arxiv.org/abs/2305.11164v1",
        "pub_date": "2023-05-18",
        "summary": "The rise of machine learning (ML) systems has exacerbated their carbon\nfootprint due to increased capabilities and model sizes. However, there is\nscarce knowledge on how the carbon footprint of ML models is actually measured,\nreported, and evaluated. In light of this, the paper aims to analyze the\nmeasurement of the carbon footprint of 1,417 ML models and associated datasets\non Hugging Face, which is the most popular repository for pretrained ML models.\nThe goal is to provide insights and recommendations on how to report and\noptimize the carbon efficiency of ML models. The study includes the first\nrepository mining study on the Hugging Face Hub API on carbon emissions. This\nstudy seeks to answer two research questions: (1) how do ML model creators\nmeasure and report carbon emissions on Hugging Face Hub?, and (2) what aspects\nimpact the carbon emissions of training ML models? The study yielded several\nkey findings. These include a decreasing proportion of carbon\nemissions-reporting models, a slight decrease in reported carbon footprint on\nHugging Face over the past 2 years, and a continued dominance of NLP as the\nmain application domain. Furthermore, the study uncovers correlations between\ncarbon emissions and various attributes such as model size, dataset size, and\nML application domains. These results highlight the need for software\nmeasurements to improve energy reporting practices and promote carbon-efficient\nmodel development within the Hugging Face community. In response to this issue,\ntwo classifications are proposed: one for categorizing models based on their\ncarbon emission reporting practices and another for their carbon efficiency.\nThe aim of these classification proposals is to foster transparency and\nsustainable model development within the ML community.",
        "translated": "机器学习(ML)系统的兴起加剧了它们的碳足印，原因是功能和模型尺寸的增加。然而，对于机器学习模型的碳足印实际上是如何测量、报告和评估的，我们知之甚少。有鉴于此，本文旨在分析“拥抱脸”上对1417个机器学习模型及相关数据集的碳足印测量结果。“拥抱脸”是最受欢迎的预训机器学习模型库。目标是就如何报告和优化机器学习模型的碳效率提供见解和建议。这项研究包括第一个关于碳排放的拥抱面中心 API 的知识库挖掘研究。这项研究试图回答两个研究问题: (1)机器学习模型的创建者如何测量和报告拥抱面部中心的碳排放量？以及(2)哪些方面影响训练机器学习模型的碳排放量？这项研究产生了几个关键的发现。其中包括碳排放报告模型的比例下降，过去两年“拥抱脸”上的报告碳足印略有下降，以及自然语言处理作为主要应用领域的持续主导地位。此外，该研究还揭示了碳排放与模型大小、数据集大小和机器学习应用领域等各种属性之间的相关性。这些结果突出了软件测量的必要性，以改善能源报告做法，并促进在拥抱面社区的碳效率模型开发。针对这一问题，提出了两种分类: 一种是根据其碳排放报告做法对模型进行分类，另一种是根据其碳效率进行分类。这些分类建议的目的是在 ML 社区内促进透明度和可持续的模型开发。"
    },
    {
        "title": "TOME: A Two-stage Approach for Model-based Retrieval",
        "url": "http://arxiv.org/abs/2305.11161v1",
        "pub_date": "2023-05-18",
        "summary": "Recently, model-based retrieval has emerged as a new paradigm in text\nretrieval that discards the index in the traditional retrieval model and\ninstead memorizes the candidate corpora using model parameters. This design\nemploys a sequence-to-sequence paradigm to generate document identifiers, which\nenables the complete capture of the relevance between queries and documents and\nsimplifies the classic indexretrieval-rerank pipeline. Despite its attractive\nqualities, there remain several major challenges in model-based retrieval,\nincluding the discrepancy between pre-training and fine-tuning, and the\ndiscrepancy between training and inference. To deal with the above challenges,\nwe propose a novel two-stage model-based retrieval approach called TOME, which\nmakes two major technical contributions, including the utilization of tokenized\nURLs as identifiers and the design of a two-stage generation architecture. We\nalso propose a number of training strategies to deal with the training\ndifficulty as the corpus size increases. Extensive experiments and analysis on\nMS MARCO and Natural Questions demonstrate the effectiveness of our proposed\napproach, and we investigate the scaling laws of TOME by examining various\ninfluencing factors.",
        "translated": "近年来，基于模型的检索已经成为文本检索的一种新范式，它抛弃了传统检索模型中的索引，而是利用模型参数记忆候选语料库。该设计采用序列到序列的方法生成文档标识符，能够完全捕获查询和文档之间的相关性，简化了经典的索引检索-重排序流水线。尽管基于模型的检索具有吸引人的优点，但仍然存在一些主要的挑战，包括预训练和微调之间的差异，以及训练和推理之间的差异。为了应对上述挑战，我们提出了一种新的基于两阶段模型的检索方法，称为 TOME，它做出了两个主要的技术贡献，包括使用标记化 URL 作为标识符和设计一个两阶段生成体系结构。随着语料库规模的增大，我们提出了一些训练策略来解决训练难度。大量的实验和分析 MS MARCO 和自然问题证明了我们提出的方法的有效性，我们研究了 TOME 的缩放规律通过检查各种影响因素。"
    },
    {
        "title": "Preference or Intent? Double Disentangled Collaborative Filtering",
        "url": "http://arxiv.org/abs/2305.11084v1",
        "pub_date": "2023-05-18",
        "summary": "People usually have different intents for choosing items, while their\npreferences under the same intent may also different. In traditional\ncollaborative filtering approaches, both intent and preference factors are\nusually entangled in the modeling process, which significantly limits the\nrobustness and interpretability of recommendation performances. For example,\nthe low-rating items are always treated as negative feedback while they\nactually could provide positive information about user intent. To this end, in\nthis paper, we propose a two-fold representation learning approach, namely\nDouble Disentangled Collaborative Filtering (DDCF), for personalized\nrecommendations. The first-level disentanglement is for separating the\ninfluence factors of intent and preference, while the second-level\ndisentanglement is performed to build independent sparse preference\nrepresentations under individual intent with limited computational complexity.\nSpecifically, we employ two variational autoencoder networks, intent\nrecognition network and preference decomposition network, to learn the intent\nand preference factors, respectively. In this way, the low-rating items will be\ntreated as positive samples for modeling intents while the negative samples for\nmodeling preferences. Finally, extensive experiments on three real-world\ndatasets and four evaluation metrics clearly validate the effectiveness and the\ninterpretability of DDCF.",
        "translated": "人们通常有不同的意图选择项目，而他们的偏好下，相同的意图也可能有所不同。在传统的协同过滤建模方法中，意图和偏好因素通常会在建模过程中纠缠在一起，这极大地限制了推荐性能的稳健性和可解释性。例如，低等级的项目总是被视为负面反馈，而实际上它们可以提供关于用户意图的正面信息。为此，在本文中，我们提出了一种双重表征学习方法，即双重分离协同过滤(DDCF) ，用于个性化推荐。第一级解缠是为了分离意图和偏好的影响因素，而第二级解缠是为了在计算复杂度有限的个体意图下构建独立的稀疏偏好表示。具体来说，我们使用两个变分自动编码器网络，意图识别网络和偏好分解网络，分别学习意图和偏好因素。这样，低等级的项目将被视为建模意图的正面样本，而负面样本将被视为建模偏好。最后，在三个实际数据集和四个评价指标上进行了广泛的实验，验证了 DDCF 的有效性和可解释性。"
    },
    {
        "title": "AMR4NLI: Interpretable and robust NLI measures from semantic graphs",
        "url": "http://arxiv.org/abs/2306.00936v1",
        "pub_date": "2023-06-01",
        "summary": "The task of natural language inference (NLI) asks whether a given premise\n(expressed in NL) entails a given NL hypothesis. NLI benchmarks contain human\nratings of entailment, but the meaning relationships driving these ratings are\nnot formalized. Can the underlying sentence pair relationships be made more\nexplicit in an interpretable yet robust fashion? We compare semantic structures\nto represent premise and hypothesis, including sets of contextualized\nembeddings and semantic graphs (Abstract Meaning Representations), and measure\nwhether the hypothesis is a semantic substructure of the premise, utilizing\ninterpretable metrics. Our evaluation on three English benchmarks finds value\nin both contextualized embeddings and semantic graphs; moreover, they provide\ncomplementary signals, and can be leveraged together in a hybrid model.",
        "translated": "自然语言推理的任务是询问一个给定的前提(用自然语言表示)是否包含一个给定的自然语言假设。NLI 基准包含人工赋值评级，但是驱动这些评级的意义关系并没有形式化。潜在的句子对关系是否可以以一种可解释的、强有力的方式更明确地表达出来？我们比较了表示前提和假设的语义结构，包括语境化嵌入和语义图集(抽象意义表示) ，并利用可解释的度量衡量假设是否是前提的语义子结构。我们对三个英语基准测试的评估发现了上下文嵌入和语义图的价值; 此外，它们提供了互补的信号，并且可以在混合模型中一起使用。"
    },
    {
        "title": "ACLM: A Selective-Denoising based Generative Data Augmentation Approach\n  for Low-Resource Complex NER",
        "url": "http://arxiv.org/abs/2306.00928v1",
        "pub_date": "2023-06-01",
        "summary": "Complex Named Entity Recognition (NER) is the task of detecting\nlinguistically complex named entities in low-context text. In this paper, we\npresent ACLM Attention-map aware keyword selection for Conditional Language\nModel fine-tuning), a novel data augmentation approach based on conditional\ngeneration to address the data scarcity problem in low-resource complex NER.\nACLM alleviates the context-entity mismatch issue, a problem existing NER data\naugmentation techniques suffer from and often generates incoherent\naugmentations by placing complex named entities in the wrong context. ACLM\nbuilds on BART and is optimized on a novel text reconstruction or denoising\ntask - we use selective masking (aided by attention maps) to retain the named\nentities and certain keywords in the input sentence that provide contextually\nrelevant additional knowledge or hints about the named entities. Compared with\nother data augmentation strategies, ACLM can generate more diverse and coherent\naugmentations preserving the true word sense of complex entities in the\nsentence. We demonstrate the effectiveness of ACLM both qualitatively and\nquantitatively on monolingual, cross-lingual, and multilingual complex NER\nacross various low-resource settings. ACLM outperforms all our neural baselines\nby a significant margin (1%-36%). In addition, we demonstrate the application\nof ACLM to other domains that suffer from data scarcity (e.g., biomedical). In\npractice, ACLM generates more effective and factual augmentations for these\ndomains than prior methods. Code: https://github.com/Sreyan88/ACLM",
        "translated": "复杂命名实体识别(NER)是在低语境文本中检测语言复杂命名实体的任务。针对低资源复杂 NER 中的数据稀缺问题，提出了一种基于条件生成的数据增强方法—— ACLM 注意图感知的条件语言模型关键词选择方法。ACLM 缓解了上下文-实体不匹配问题，这是现有的 NER 数据增强技术所面临的问题，并且通常通过将复杂的命名实体放置在错误的上下文中而产生不一致的增强。ACLM 建立在 BART 的基础上，针对一个新的文本重建或去噪任务进行优化——我们使用选择性掩蔽(通过注意力地图辅助)来保留输入句中的命名实体和某些关键字，这些关键字提供了与上下文相关的附加知识或关于命名实体的提示。与其他数据增强策略相比，ACLM 能够产生更多样化和连贯的增强，保持句子中复杂实体的真实词义。我们证明了 ACLM 在定性和定量上对不同低资源环境下的单语言、跨语言和多语言复杂 NER 的有效性。ACLM 比我们所有的神经基线都要好得多(1% -36%)。此外，我们还展示了 ACLM 在其他数据稀缺领域(如生物医学)的应用。在实践中，ACLM 为这些领域产生了比以前的方法更有效和实际的增强。密码:  https://github.com/sreyan88/aclm"
    },
    {
        "title": "SpotTarget: Rethinking the Effect of Target Edges for Link Prediction in\n  Graph Neural Networks",
        "url": "http://arxiv.org/abs/2306.00899v1",
        "pub_date": "2023-06-01",
        "summary": "Graph Neural Networks (GNNs) have demonstrated promising outcomes across\nvarious tasks, including node classification and link prediction. Despite their\nremarkable success in various high-impact applications, we have identified\nthree common pitfalls in message passing for link prediction. Particularly, in\nprevalent GNN frameworks (e.g., DGL and PyTorch-Geometric), the target edges\n(i.e., the edges being predicted) consistently exist as message passing edges\nin the graph during training. Consequently, this results in overfitting and\ndistribution shift, both of which adversely impact the generalizability to test\nthe target edges. Additionally, during test time, the failure to exclude the\ntest target edges leads to implicit test leakage caused by neighborhood\naggregation. In this paper, we analyze these three pitfalls and investigate the\nimpact of including or excluding target edges on the performance of nodes with\nvarying degrees during training and test phases. Our theoretical and empirical\nanalysis demonstrates that low-degree nodes are more susceptible to these\npitfalls. These pitfalls can have detrimental consequences when GNNs are\nimplemented in production systems. To systematically address these pitfalls, we\npropose SpotTarget, an effective and efficient GNN training framework. During\ntraining, SpotTarget leverages our insight regarding low-degree nodes and\nexcludes train target edges connected to at least one low-degree node. During\ntest time, it emulates real-world scenarios of GNN usage in production and\nexcludes all test target edges. Our experiments conducted on diverse real-world\ndatasets, demonstrate that SpotTarget significantly enhances GNNs, achieving up\nto a 15x increase in accuracy in sparse graphs. Furthermore, SpotTarget\nconsistently and dramatically improves the performance for low-degree nodes in\ndense graphs.",
        "translated": "图形神经网络(GNN)在各种任务中，包括节点分类和链路预测，都取得了很好的效果。尽管它们在各种高影响力的应用程序中取得了显著的成功，但是我们已经确定了链接预测中消息传递的三个常见缺陷。特别是，在流行的 GNN 框架(例如，DGL 和 PyTorch-Geometer)中，目标边(例如，被预测的边)在训练期间始终作为图中的消息传递边存在。因此，这会导致过拟合和分布偏移，这两者都会对测试目标边缘的通用性产生不利影响。此外，在测试时间内，未能排除测试目标边缘会导致由邻域聚合引起的隐式测试泄漏。在本文中，我们分析了这三个陷阱，并研究了在训练和测试阶段包含或排除目标边对不同程度的节点性能的影响。我们的理论和实证分析表明，低度节点更容易受到这些陷阱的影响。当 GNN 在生产系统中实现时，这些缺陷可能会产生有害的后果。为了系统地解决这些缺陷，我们提出了 SpotTarget，一个高效的 GNN 训练框架。在训练过程中，SpotTarget 利用我们对低度节点的洞察力，排除了连接到至少一个低度节点的训练目标边缘。在测试期间，它模拟生产中 GNN 使用的真实场景，并排除所有测试目标边缘。我们在不同的真实世界数据集上进行的实验表明，SpotTarget 显著地增强了 GNN，在稀疏图中实现了高达15倍的精度提高。此外，SpotTarget 持续而显著地改善了稠密图中低度节点的性能。"
    },
    {
        "title": "Topic-Guided Sampling For Data-Efficient Multi-Domain Stance Detection",
        "url": "http://arxiv.org/abs/2306.00765v1",
        "pub_date": "2023-06-01",
        "summary": "Stance Detection is concerned with identifying the attitudes expressed by an\nauthor towards a target of interest. This task spans a variety of domains\nranging from social media opinion identification to detecting the stance for a\nlegal claim. However, the framing of the task varies within these domains, in\nterms of the data collection protocol, the label dictionary and the number of\navailable annotations. Furthermore, these stance annotations are significantly\nimbalanced on a per-topic and inter-topic basis. These make multi-domain stance\ndetection a challenging task, requiring standardization and domain adaptation.\nTo overcome this challenge, we propose $\\textbf{T}$opic $\\textbf{E}$fficient\n$\\textbf{St}$anc$\\textbf{E}$ $\\textbf{D}$etection (TESTED), consisting of a\ntopic-guided diversity sampling technique and a contrastive objective that is\nused for fine-tuning a stance classifier. We evaluate the method on an existing\nbenchmark of $16$ datasets with in-domain, i.e. all topics seen and\nout-of-domain, i.e. unseen topics, experiments. The results show that our\nmethod outperforms the state-of-the-art with an average of $3.5$ F1 points\nincrease in-domain, and is more generalizable with an averaged increase of\n$10.2$ F1 on out-of-domain evaluation while using $\\leq10\\%$ of the training\ndata. We show that our sampling technique mitigates both inter- and per-topic\nclass imbalances. Finally, our analysis demonstrates that the contrastive\nlearning objective allows the model a more pronounced segmentation of samples\nwith varying labels.",
        "translated": "姿势检测是指识别作者对于感兴趣的目标所表达的态度。这项任务涉及从社交媒体舆论识别到检测法律诉求立场等多个领域。然而，在这些领域内，任务的框架在数据收集协议、标签字典和可用注释的数量方面有所不同。此外，这些立场注释在每个主题和主题间的基础上显著不平衡。这使得多域姿态检测成为一项具有挑战性的任务，需要标准化和域自适应。为了克服这个挑战，我们提出了 $textbf { T } $opic $textbf { E } $ffical$textbf { St } $anc $textbf { E } $textbf { D } $etection (TESTED) ，包括一个主题引导的多样性采样技术和一个用于微调立场分类器的对比目标。我们评估的方法，在一个现有的基准 $16 $数据集与域内，即所有主题看到和域外，即看不到的主题，实验。结果表明，我们的方法优于国家的最新技术，平均 $3.5 $F1点在域内增加，更具普遍性，平均增加 $10.2 $F1在域外评估，同时使用 $leq10% $的训练数据。我们展示了我们的抽样技术缓解了主题间和主题间的类不平衡。最后，我们的分析表明，对比学习的目标允许模型更明显的样本分割与不同的标签。"
    },
    {
        "title": "End-to-End Document Classification and Key Information Extraction using\n  Assignment Optimization",
        "url": "http://arxiv.org/abs/2306.00750v1",
        "pub_date": "2023-06-01",
        "summary": "We propose end-to-end document classification and key information extraction\n(KIE) for automating document processing in forms. Through accurate document\nclassification we harness known information from templates to enhance KIE from\nforms. We use text and layout encoding with a cosine similarity measure to\nclassify visually-similar documents. We then demonstrate a novel application of\nmixed integer programming by using assignment optimization to extract key\ninformation from documents. Our approach is validated on an in-house dataset of\nnoisy scanned forms. The best performing document classification approach\nachieved 0.97 f1 score. A mean f1 score of 0.94 for the KIE task suggests there\nis significant potential in applying optimization techniques. Abation results\nshow that the method relies on document preprocessing techniques to mitigate\nType II errors and achieve optimal performance.",
        "translated": "我们建议采用端到端文档分类及信息抽取，以自动处理表格内的文件。通过准确的文档分类，我们利用模板中的已知信息来增强表单中的知识工具教育。我们使用文本和布局编码，并采用余弦距离度量方法对视觉上相似的文档进行分类。然后我们展示了一个新的混合整数规划的应用，通过使用分配优化从文档中提取关键信息。我们的方法是在一个有噪声的扫描表单的内部数据集上进行验证的。表现最好的文档分类得分为0.97 f1。KIE 任务的平均 f1得分为0.94，表明应用优化技术有很大的潜力。消减结果表明，该方法依赖于文档预处理技术，以减轻 II 类错误，并取得最佳性能。"
    },
    {
        "title": "TopEx: Topic-based Explanations for Model Comparison",
        "url": "http://arxiv.org/abs/2306.00976v1",
        "pub_date": "2023-06-01",
        "summary": "Meaningfully comparing language models is challenging with current\nexplanation methods. Current explanations are overwhelming for humans due to\nlarge vocabularies or incomparable across models. We present TopEx, an\nexplanation method that enables a level playing field for comparing language\nmodels via model-agnostic topics. We demonstrate how TopEx can identify\nsimilarities and differences between DistilRoBERTa and GPT-2 on a variety of\nNLP tasks.",
        "translated": "对语言模型进行有意义的比较对于当前的解释方法来说是一个挑战。目前的解释对人类来说是压倒性的，因为词汇量很大，或者在不同的模型中是无法比较的。我们提出了 TopEx，一种解释方法，使一个公平的竞争环境比较语言模型通过模型不可知的主题。我们演示了 TopEx 如何在各种 NLP 任务中识别 DistilRoBERTa 和 GPT-2之间的相似点和不同点。"
    },
    {
        "title": "AWQ: Activation-aware Weight Quantization for LLM Compression and\n  Acceleration",
        "url": "http://arxiv.org/abs/2306.00978v1",
        "pub_date": "2023-06-01",
        "summary": "Large language models (LLMs) have shown excellent performance on various\ntasks, but the astronomical model size raises the hardware barrier for serving\n(memory size) and slows down token generation (memory bandwidth). In this\npaper, we propose Activation-aware Weight Quantization (AWQ), a\nhardware-friendly approach for LLM low-bit weight-only quantization. Our method\nis based on the observation that weights are not equally important: protecting\nonly 1% of salient weights can greatly reduce quantization error. We then\npropose to search for the optimal per-channel scaling that protects the salient\nweights by observing the activation, not weights. AWQ does not rely on any\nbackpropagation or reconstruction, so it can well preserve LLMs' generalization\nability on different domains and modalities, without overfitting to the\ncalibration set; it also does not rely on any data layout reordering,\nmaintaining the hardware efficiency. AWQ outperforms existing work on various\nlanguage modeling, common sense QA, and domain-specific benchmarks. Thanks to\nbetter generalization, it achieves excellent quantization performance for\ninstruction-tuned LMs and, for the first time, multi-modal LMs. We also\nimplement efficient tensor core kernels with reorder-free online dequantization\nto accelerate AWQ, achieving a 1.45x speedup over GPTQ and is 1.85x faster than\nthe cuBLAS FP16 implementation. Our method provides a turn-key solution to\ncompress LLMs to 3/4 bits for efficient deployment.",
        "translated": "大型语言模型(LLM)在各种任务中表现出了优异的性能，但是庞大的模型大小增加了服务的硬件障碍(内存大小) ，并减慢了令牌生成(内存带宽)。本文提出了一种基于激活感知的权重量化(AWQ)方法，用于 LLM 低比特权重量化。我们的方法是基于这样的观察: 重量并不同等重要，只保护显著重量的1% 就可以大大减少量化噪声。然后我们建议通过观察激活而不是权值来寻找保护显著权值的最佳通道尺度。AWQ 不依赖任何反向传播或重构，因此它可以很好地保持 LLM 在不同领域和模式下的泛化能力，而不会过度适应校准集; 它也不依赖任何数据布局重排序，保持硬件效率。AWQ 在各种语言建模、常识性 QA 和特定领域基准测试方面的表现优于现有的工作。由于更好的泛化，它实现了优良的量化性能的指令调谐 LM 和第一次，多模态 LM。我们还实现了高效的张量核心，无需重新排序的在线去量化来加速 AWQ，比 GPTQ 提高了1.45倍的速度，比 cuBLAS FP16实现快了1.85倍。我们的方法提供了一个交钥匙解决方案，可以将 LLM 压缩到3/4位，从而实现高效部署。"
    },
    {
        "title": "EEL: Efficiently Encoding Lattices for Reranking",
        "url": "http://arxiv.org/abs/2306.00947v1",
        "pub_date": "2023-06-01",
        "summary": "Standard decoding approaches for conditional text generation tasks typically\nsearch for an output hypothesis with high model probability, but this may not\nyield the best hypothesis according to human judgments of quality. Reranking to\noptimize for \"downstream\" metrics can better optimize for quality, but many\nmetrics of interest are computed with pre-trained language models, which are\nslow to apply to large numbers of hypotheses. We explore an approach for\nreranking hypotheses by using Transformers to efficiently encode lattices of\ngenerated outputs, a method we call EEL. With a single Transformer pass over\nthe entire lattice, we can approximately compute a contextualized\nrepresentation of each token as if it were only part of a single hypothesis in\nisolation. We combine this approach with a new class of token-factored\nrerankers (TFRs) that allow for efficient extraction of high reranker-scoring\nhypotheses from the lattice. Empirically, our approach incurs minimal\ndegradation error compared to the exponentially slower approach of encoding\neach hypothesis individually. When applying EEL with TFRs across three text\ngeneration tasks, our results show both substantial speedup compared to naive\nreranking and often better performance on downstream metrics than comparable\napproaches.",
        "translated": "条件文本生成任务的标准解码方法通常搜索具有高模型概率的输出假设，但这可能不会根据人类对质量的判断产生最佳假设。重新排序以优化“下游”指标可以更好地优化质量，但许多感兴趣的指标是使用预先训练的语言模型计算的，这些模型适用于大量假设的速度很慢。我们探索了一种重新排序假设的方法，通过使用变形金刚有效地编码生成的输出格子，一种方法，我们称之为 EEL。通过一个单变压器遍历整个格子，我们可以近似地计算每个标记的上下文化表示，就好像它只是孤立的单个假设的一部分一样。我们结合这种方法与一类新的令牌因子重排序(TFR) ，允许有效地提取高重排序得分假设从格。根据经验，我们的方法产生最小的退化误差相比，指数较慢的方法编码每个假设单独。在跨三个文本生成任务应用带 TFR 的 EEL 时，我们的结果显示，与初始重新排序相比，EEL 的速度大幅提高，而且下游指标的性能通常比可比方法更好。"
    },
    {
        "title": "Exposing Attention Glitches with Flip-Flop Language Modeling",
        "url": "http://arxiv.org/abs/2306.00946v1",
        "pub_date": "2023-06-01",
        "summary": "Why do large language models sometimes output factual inaccuracies and\nexhibit erroneous reasoning? The brittleness of these models, particularly when\nexecuting long chains of reasoning, currently seems to be an inevitable price\nto pay for their advanced capabilities of coherently synthesizing knowledge,\npragmatics, and abstract thought. Towards making sense of this fundamentally\nunsolved problem, this work identifies and analyzes the phenomenon of attention\nglitches, in which the Transformer architecture's inductive biases\nintermittently fail to capture robust reasoning. To isolate the issue, we\nintroduce flip-flop language modeling (FFLM), a parametric family of synthetic\nbenchmarks designed to probe the extrapolative behavior of neural language\nmodels. This simple generative task requires a model to copy binary symbols\nover long-range dependencies, ignoring the tokens in between. We find that\nTransformer FFLMs suffer from a long tail of sporadic reasoning errors, some of\nwhich we can eliminate using various regularization techniques. Our preliminary\nmechanistic analyses show why the remaining errors may be very difficult to\ndiagnose and resolve. We hypothesize that attention glitches account for (some\nof) the closed-domain hallucinations in natural LLMs.",
        "translated": "为什么大型语言模型有时会输出不准确的事实，并表现出错误的推理？这些模型的脆弱性，特别是在执行长链推理时，目前似乎是为其连贯综合知识、语用学和抽象思维的先进能力付出的不可避免的代价。为了理解这个根本上未解决的问题，本文识别并分析了注意小故障现象，其中变压器结构的感应偏差间歇性地不能捕获鲁棒性推理。为了隔离这个问题，我们引入了触发器语言建模(FFLM) ，这是一个参数化的合成基准，旨在探索神经语言模型的外推行为。这个简单的生成任务需要一个模型在远程依赖关系上复制二进制符号，忽略中间的标记。我们发现变压器 FFLM 存在很多零星的推理错误，我们可以使用各种正则化技术来消除其中的一些错误。我们的初步机理分析表明，为什么剩余的误差可能非常难以诊断和解决。我们假设在自然的 LLM 中，注意力失调可以解释(部分)闭域幻觉。"
    },
    {
        "title": "\"Let's not Quote out of Context\": Unified Vision-Language Pretraining\n  for Context Assisted Image Captioning",
        "url": "http://arxiv.org/abs/2306.00931v1",
        "pub_date": "2023-06-01",
        "summary": "Well-formed context aware image captions and tags in enterprise content such\nas marketing material are critical to ensure their brand presence and content\nrecall. Manual creation and updates to ensure the same is non trivial given the\nscale and the tedium towards this task. We propose a new unified\nVision-Language (VL) model based on the One For All (OFA) model, with a focus\non context-assisted image captioning where the caption is generated based on\nboth the image and its context. Our approach aims to overcome the\ncontext-independent (image and text are treated independently) nature of the\nexisting approaches. We exploit context by pretraining our model with datasets\nof three tasks: news image captioning where the news article is the context,\ncontextual visual entailment, and keyword extraction from the context. The\nsecond pretraining task is a new VL task, and we construct and release two\ndatasets for the task with 1.1M and 2.2K data instances. Our system achieves\nstate-of-the-art results with an improvement of up to 8.34 CIDEr score on the\nbenchmark news image captioning datasets. To the best of our knowledge, ours is\nthe first effort at incorporating contextual information in pretraining the\nmodels for the VL tasks.",
        "translated": "在企业内容(如营销材料)中形成良好的上下文感知图像标题和标签对于确保其品牌存在和内容召回至关重要。手工创建和更新，以确保相同的是不平凡的规模和乏味的这项任务。我们提出了一个新的统一的视觉语言(VL)模型的基础上的一个为所有(OFA)模型，重点是上下文辅助图像字幕生成的标题是基于图像和它的上下文。我们的方法旨在克服现有方法的上下文无关性(图像和文本是独立处理的)。我们利用上下文预训练我们的模型与三个任务的数据集: 新闻图像字幕，其中的新闻文章是上下文，上下文视觉暗示，和关键字提取从上下文。第二个预训练任务是一个新的 VL 任务，我们用1.1 M 和2.2 K 的数据实例构造并发布了两个任务数据集。我们的系统取得了最先进的成果，在基准的新闻图像字幕数据集上提高了高达8.34 CIDEr 得分。据我们所知，我们是第一次尝试将上下文信息合并到 VL 任务的模型预训练中。"
    },
    {
        "title": "Minding Language Models' (Lack of) Theory of Mind: A Plug-and-Play\n  Multi-Character Belief Tracker",
        "url": "http://arxiv.org/abs/2306.00924v1",
        "pub_date": "2023-06-01",
        "summary": "Theory of Mind (ToM)$\\unicode{x2014}$the ability to reason about the mental\nstates of other people$\\unicode{x2014}$is a key element of our social\nintelligence. Yet, despite their ever more impressive performance, large-scale\nneural language models still lack basic theory of mind capabilities\nout-of-the-box. We posit that simply scaling up models will not imbue them with\ntheory of mind due to the inherently symbolic and implicit nature of the\nphenomenon, and instead investigate an alternative: can we design a\ndecoding-time algorithm that enhances theory of mind of off-the-shelf neural\nlanguage models without explicit supervision? We present SymbolicToM, a\nplug-and-play approach to reason about the belief states of multiple characters\nin reading comprehension tasks via explicit symbolic representation. More\nconcretely, our approach tracks each entity's beliefs, their estimation of\nother entities' beliefs, and higher-order levels of reasoning, all through\ngraphical representations, allowing for more precise and interpretable\nreasoning than previous approaches. Empirical results on the well-known ToMi\nbenchmark (Le et al., 2019) demonstrate that SymbolicToM dramatically enhances\noff-the-shelf neural networks' theory of mind in a zero-shot setting while\nshowing robust out-of-distribution performance compared to supervised\nbaselines. Our work also reveals spurious patterns in existing theory of mind\nbenchmarks, emphasizing the importance of out-of-distribution evaluation and\nmethods that do not overfit a particular dataset.",
        "translated": "心理理论对他人心理状态进行推理的能力是我们社会智力的一个关键因素。然而，尽管大规模神经语言模型的表现越来越令人印象深刻，它们仍然缺乏开箱即用的思维能力的基本理论。我们假定，由于这种现象固有的象征性和隐含性，简单地扩大模型不会给它们灌输心智理论，而是研究另一种选择: 我们能否设计一种解码时间算法，在没有明确监督的情况下增强现成神经语言模型的心智理论？我们展示了 SymbolicToM，一种即插即用的方法，通过显式的符号表示来推断阅读理解任务中多个角色的信念状态。更具体地说，我们的方法跟踪每个实体的信念，他们对其他实体信念的估计，以及更高层次的推理，所有这些都通过图形表示，允许比以前的方法更精确和可解释的推理。著名的 ToMi 基准测试(Le et al。 ，2019)的实验结果表明，SymbolicToM 显著增强了现成的神经网络的心智理论，在零拍设置，同时显示出稳健的分布外性能相比，监督基线。我们的工作还揭示了现有心智基准理论中的虚假模式，强调了分布外评估的重要性，以及不适合特定数据集的方法。"
    },
    {
        "title": "T2IAT: Measuring Valence and Stereotypical Biases in Text-to-Image\n  Generation",
        "url": "http://arxiv.org/abs/2306.00905v1",
        "pub_date": "2023-06-01",
        "summary": "Warning: This paper contains several contents that may be toxic, harmful, or\noffensive.\n  In the last few years, text-to-image generative models have gained remarkable\nsuccess in generating images with unprecedented quality accompanied by a\nbreakthrough of inference speed. Despite their rapid progress, human biases\nthat manifest in the training examples, particularly with regard to common\nstereotypical biases, like gender and skin tone, still have been found in these\ngenerative models. In this work, we seek to measure more complex human biases\nexist in the task of text-to-image generations. Inspired by the well-known\nImplicit Association Test (IAT) from social psychology, we propose a novel\nText-to-Image Association Test (T2IAT) framework that quantifies the implicit\nstereotypes between concepts and valence, and those in the images. We replicate\nthe previously documented bias tests on generative models, including morally\nneutral tests on flowers and insects as well as demographic stereotypical tests\non diverse social attributes. The results of these experiments demonstrate the\npresence of complex stereotypical behaviors in image generations.",
        "translated": "警告: 本文件含有多种内容，可能是有毒的，有害的，或攻击性。在过去的几年中，文本到图像的生成模型在生成具有前所未有质量的图像方面取得了显著的成功，同时推理速度也有了突破。尽管进展迅速，但在这些生成模型中仍然发现了在训练实例中表现出来的人为偏见，特别是在性别和肤色等常见的陈规定型偏见方面。在这项工作中，我们试图测量更复杂的人类偏见存在于文本到图像的生成任务。受到来自社会心理学的著名隐含尺度(IAT)的启发，我们提出了一个新颖的文本-图像关联测试(t2IAT)框架，它量化了概念和效价之间以及图像中的内隐刻板印象。我们在生殖模型上重复之前记录的偏见测试，包括对花和昆虫的道德中立测试，以及对不同社会属性的人口统计学刻板印象测试。实验结果表明，在图像生成过程中存在复杂的刻板印象行为。"
    },
    {
        "title": "LLaVA-Med: Training a Large Language-and-Vision Assistant for\n  Biomedicine in One Day",
        "url": "http://arxiv.org/abs/2306.00890v1",
        "pub_date": "2023-06-01",
        "summary": "Conversational generative AI has demonstrated remarkable promise for\nempowering biomedical practitioners, but current investigations focus on\nunimodal text. Multimodal conversational AI has seen rapid progress by\nleveraging billions of image-text pairs from the public web, but such\ngeneral-domain vision-language models still lack sophistication in\nunderstanding and conversing about biomedical images. In this paper, we propose\na cost-efficient approach for training a vision-language conversational\nassistant that can answer open-ended research questions of biomedical images.\nThe key idea is to leverage a large-scale, broad-coverage biomedical\nfigure-caption dataset extracted from PubMed Central, use GPT-4 to\nself-instruct open-ended instruction-following data from the captions, and then\nfine-tune a large general-domain vision-language model using a novel curriculum\nlearning method. Specifically, the model first learns to align biomedical\nvocabulary using the figure-caption pairs as is, then learns to master\nopen-ended conversational semantics using GPT-4 generated instruction-following\ndata, broadly mimicking how a layperson gradually acquires biomedical\nknowledge. This enables us to train a Large Language and Vision Assistant for\nBioMedicine (LLaVA-Med) in less than 15 hours (with eight A100s). LLaVA-Med\nexhibits excellent multimodal conversational capability and can follow\nopen-ended instruction to assist with inquiries about a biomedical image. On\nthree standard biomedical visual question answering datasets, LLaVA-Med\noutperforms previous supervised state-of-the-art on certain metrics. To\nfacilitate biomedical multimodal research, we will release our\ninstruction-following data and the LLaVA-Med model.",
        "translated": "对话生成 AI 已经显示了赋予生物医学从业人员显着的前景，但目前的研究侧重于单一模式的文本。通过利用来自公共网络的数十亿个图像-文本对，多模式会话人工智能已经取得了迅速的进展，但是这种通用领域的视觉-语言模型在理解和对生物医学图像进行会话方面仍然缺乏先进性。本文针对生物医学图像的开放式研究问题，提出了一种具有成本效益的视觉语言会话助手培训方法。其关键思想是利用从 PubMed Central 提取的大规模、广泛覆盖的生物医学图形标题数据集，使用 GPT-4自我指导开放式教学——跟随标题中的数据，然后使用新的课程学习方法微调大型通用领域视觉语言模型。具体而言，该模型首先学习使用图标-标题对来校准生物医学词汇，然后学习使用 GPT-4生成的指令跟踪数据来掌握开放式会话语义，广泛地模仿外行如何逐渐获得生物医学知识。这使得我们能够在不到15个小时的时间内培训一个大型语言和视觉生物医学助手(LLaVA-Med)(有8个 A100s)。LLaVA-Med 具有优秀的多通道会话能力，可以遵循开放式指导，以协助有关生物医学图像的查询。在三个标准的生物医学视觉问答数据集上，LLaVA-Med 在某些指标上优于先前监督的最先进水平。为了促进生物医学多模式研究，我们将发布我们的指令跟踪数据和 LLaVA-Med 模型。"
    },
    {
        "title": "Fresh Content Needs More Attention: Multi-funnel Fresh Content\n  Recommendation",
        "url": "http://arxiv.org/abs/2306.01720v1",
        "pub_date": "2023-06-02",
        "summary": "Recommendation system serves as a conduit connecting users to an incredibly\nlarge, diverse and ever growing collection of contents. In practice, missing\ninformation on fresh (and tail) contents needs to be filled in order for them\nto be exposed and discovered by their audience. We here share our success\nstories in building a dedicated fresh content recommendation stack on a large\ncommercial platform. To nominate fresh contents, we built a multi-funnel\nnomination system that combines (i) a two-tower model with strong\ngeneralization power for coverage, and (ii) a sequence model with near\nreal-time update on user feedback for relevance. The multi-funnel setup\neffectively balances between coverage and relevance. An in-depth study uncovers\nthe relationship between user activity level and their proximity toward fresh\ncontents, which further motivates a contextual multi-funnel setup. Nominated\nfresh candidates are then scored and ranked by systems considering prediction\nuncertainty to further bootstrap content with less exposure. We evaluate the\nbenefits of the dedicated fresh content recommendation stack, and the\nmulti-funnel nomination system in particular, through user corpus co-diverted\nlive experiments. We conduct multiple rounds of live experiments on a\ncommercial platform serving billion of users demonstrating efficacy of our\nproposed methods.",
        "translated": "推荐系统作为一个渠道，连接用户到一个令人难以置信的庞大，多样化和不断增长的内容集合。在实践中，需要填补关于新鲜(和尾部)内容的缺失信息，以便它们被观众暴露和发现。我们在这里分享我们在一个大型商业平台上建立一个专门的新内容推荐堆栈的成功故事。为了提名新的内容，我们建立了一个多漏斗提名系统，该系统结合了(i)一个具有很强覆盖泛化能力的双塔模型和(ii)一个具有近实时更新用户反馈相关性的序列模型。多漏斗设置有效地平衡了覆盖率和相关性。深入的研究揭示了用户活动水平与其接近新鲜内容之间的关系，进一步激发了上下文多漏斗设置。提名的新鲜候选人，然后得分和排名的系统考虑预测不确定性，以进一步引导内容，较少的曝光。我们通过用户语料库共转向现场实验，评估了专用新鲜内容推荐堆栈的优点，尤其是多漏斗提名系统。我们在一个为数十亿用户服务的商业平台上进行多轮实验，证明我们提出的方法的有效性。"
    },
    {
        "title": "Pretrained Language Model based Web Search Ranking: From Relevance to\n  Satisfaction",
        "url": "http://arxiv.org/abs/2306.01599v1",
        "pub_date": "2023-06-02",
        "summary": "Search engine plays a crucial role in satisfying users' diverse information\nneeds. Recently, Pretrained Language Models (PLMs) based text ranking models\nhave achieved huge success in web search. However, many state-of-the-art text\nranking approaches only focus on core relevance while ignoring other dimensions\nthat contribute to user satisfaction, e.g., document quality, recency,\nauthority, etc. In this work, we focus on ranking user satisfaction rather than\nrelevance in web search, and propose a PLM-based framework, namely SAT-Ranker,\nwhich comprehensively models different dimensions of user satisfaction in a\nunified manner. In particular, we leverage the capacities of PLMs on both\ntextual and numerical inputs, and apply a multi-field input that modularizes\neach dimension of user satisfaction as an input field. Overall, SAT-Ranker is\nan effective, extensible, and data-centric framework that has huge potential\nfor industrial applications. On rigorous offline and online experiments,\nSAT-Ranker obtains remarkable gains on various evaluation sets targeting\ndifferent dimensions of user satisfaction. It is now fully deployed online to\nimprove the usability of our search engine.",
        "translated": "搜索引擎在满足用户多样化的信息需求方面起着至关重要的作用。近年来，基于预训练语言模型(PLM)的文本排序模型在网络搜索领域取得了巨大的成功。然而，许多最先进的文本排名方法只关注核心相关性，而忽略了有助于用户满意度的其他方面，如文档质量、最新性、权威性等。在这项工作中，我们的重点是排名用户满意度而不是相关性的网络搜索，并提出了一个基于 PLM 的框架，即 SAT-Ranker，它综合模型的不同维度的用户满意度在统一的方式。特别是，我们利用 PLM 在文本和数字输入方面的能力，并应用多领域的输入，将用户满意度的每个维度模块化，作为输入领域。总的来说，SAT-Ranker 是一个有效的、可扩展的、以数据为中心的框架，在工业应用方面具有巨大的潜力。在严格的离线和在线实验中，SAT-Ranker 在针对不同用户满意度维度的各种评价集上取得了显著的效果。它现在已经完全部署在网上，以提高我们的搜索引擎的可用性。"
    },
    {
        "title": "Influence Maximization with Fairness at Scale (Extended Version)",
        "url": "http://arxiv.org/abs/2306.01587v1",
        "pub_date": "2023-06-02",
        "summary": "In this paper, we revisit the problem of influence maximization with\nfairness, which aims to select k influential nodes to maximise the spread of\ninformation in a network, while ensuring that selected sensitive user\nattributes are fairly affected, i.e., are proportionally similar between the\noriginal network and the affected users. Recent studies on this problem focused\nonly on extremely small networks, hence the challenge remains on how to achieve\na scalable solution, applicable to networks with millions or billions of nodes.\nWe propose an approach that is based on learning node representations for fair\nspread from diffusion cascades, instead of the social connectivity s.t. we can\ndeal with very large graphs. We propose two data-driven approaches: (a)\nfairness-based participant sampling (FPS), and (b) fairness as context (FAC).\nSpread related user features, such as the probability of diffusing information\nto others, are derived from the historical information cascades, using a deep\nneural network. The extracted features are then used in selecting influencers\nthat maximize the influence spread, while being also fair with respect to the\nchosen sensitive attributes. In FPS, fairness and cascade length information\nare considered independently in the decision-making process, while FAC\nconsiders these information facets jointly and considers correlations between\nthem. The proposed algorithms are generic and represent the first policy-driven\nsolutions that can be applied to arbitrary sets of sensitive attributes at\nscale. We evaluate the performance of our solutions on a real-world public\ndataset (Sina Weibo) and on a hybrid real-synthethic dataset (Digg), which\nexhibit all the facets that we exploit, namely diffusion network, diffusion\ntraces, and user profiles. These experiments show that our methods outperform\nthe state-the-art solutions in terms of spread, fairness, and scalability.",
        "translated": "本文重新讨论了公平影响最大化问题，其目的是选择 k 个有影响的节点以使网络中的信息传播最大化，同时确保选择的敏感用户属性受到相当大的影响，即原始网络与受影响用户之间的比例相似。最近关于这个问题的研究只集中在极小的网络上，因此挑战仍然是如何实现一个可伸缩的解决方案，适用于拥有数百万或数十亿个节点的网络。我们提出了一种基于学习节点表示的扩散级联公平扩散方法，代替了社会连通性方法，我们可以处理非常大的图。我们提出两种数据驱动的方法: (a)基于公平的参与者抽样(FPS)和(b)作为上下文的公平(FAC)。传播相关的用户特征，如向他人传播信息的概率，是从历史信息级联，使用深度神经网络推导出来的。然后将提取的特征用于选择影响者，使影响扩散最大化，同时对所选择的敏感属性也是公平的。在 FPS 中，公平性和级联长度信息在决策过程中被独立地考虑，而 FAC 则联合考虑这些信息方面，并考虑它们之间的相关性。提出的算法是通用的，代表了第一个策略驱动的解决方案，可以应用于任意集的敏感属性在规模。我们在一个真实世界的公共数据集(新浪微博)和一个混合的真实合成数据集(Digg)上评估我们的解决方案的性能，这些数据集展示了我们利用的所有方面，即扩散网络、扩散轨迹和用户配置文件。这些实验表明，我们的方法在扩展性、公平性和可伸缩性方面优于最先进的解决方案。"
    },
    {
        "title": "Système de recommandations basé sur les contraintes pour les\n  simulations de gestion de crise",
        "url": "http://arxiv.org/abs/2306.01504v1",
        "pub_date": "2023-06-02",
        "summary": "In the context of the evacuation of populations, some citizens/volunteers may\nwant and be able to participate in the evacuation of populations in difficulty\nby coming to lend a hand to emergency/evacuation vehicles with their own\nvehicles. One way of framing these impulses of solidarity would be to be able\nto list in real-time the citizens/volunteers available with their vehicles\n(land, sea, air, etc.), to be able to geolocate them according to the risk\nareas to be evacuated, and adding them to the evacuation/rescue vehicles.\nBecause it is difficult to propose an effective real-time operational system on\nthe field in a real crisis situation, in this work, we propose to add a module\nfor recommending driver/vehicle pairs (with their specificities) to a system of\ncrisis management simulation. To do that, we chose to model and develop an\nontology-supported constraint-based recommender system for crisis management\nsimulations.",
        "translated": "在疏散人口方面，一些公民/志愿人员可能希望并能够参与疏散有困难的人口，他们可以用自己的车辆向紧急/疏散车辆伸出援手。构建这些团结冲动的一种方式是能够实时列出可用车辆(陆地、海洋、空中等)的公民/志愿者，能够根据疏散的危险区域对他们进行地理定位，并将他们添加到疏散/救援车辆中。由于在真实的危机情况下很难提出一个有效的现场实时操作系统，本文提出在危机管理模拟系统中增加一个推荐驾驶员/车辆配对(及其特殊性)的模块。为此，我们选择建模和开发一个本体支持的基于约束的危机管理模拟推荐系统。"
    },
    {
        "title": "Hierarchical Reinforcement Learning for Modeling User Novelty-Seeking\n  Intent in Recommender Systems",
        "url": "http://arxiv.org/abs/2306.01476v1",
        "pub_date": "2023-06-02",
        "summary": "Recommending novel content, which expands user horizons by introducing them\nto new interests, has been shown to improve users' long-term experience on\nrecommendation platforms \\cite{chen2021values}. Users however are not\nconstantly looking to explore novel content. It is therefore crucial to\nunderstand their novelty-seeking intent and adjust the recommendation policy\naccordingly. Most existing literature models a user's propensity to choose\nnovel content or to prefer a more diverse set of recommendations at individual\ninteractions. Hierarchical structure, on the other hand, exists in a user's\nnovelty-seeking intent, which is manifested as a static and intrinsic user\npreference for seeking novelty along with a dynamic session-based propensity.\nTo this end, we propose a novel hierarchical reinforcement learning-based\nmethod to model the hierarchical user novelty-seeking intent, and to adapt the\nrecommendation policy accordingly based on the extracted user novelty-seeking\npropensity. We further incorporate diversity and novelty-related measurement in\nthe reward function of the hierarchical RL (HRL) agent to encourage user\nexploration \\cite{chen2021values}. We demonstrate the benefits of explicitly\nmodeling hierarchical user novelty-seeking intent in recommendations through\nextensive experiments on simulated and real-world datasets. In particular, we\ndemonstrate that the effectiveness of our proposed hierarchical RL-based method\nlies in its ability to capture such hierarchically-structured intent. As a\nresult, the proposed HRL model achieves superior performance on several public\ndatasets, compared with state-of-art baselines.",
        "translated": "推荐新颖的内容，通过引入新的兴趣拓展用户的视野，已经被证明可以改善用户在推荐平台上的长期体验。然而，用户并不总是寻找新奇的内容。因此，必须了解其寻求新颖性的意图，并相应调整建议政策。大多数现有的文献模拟了用户在个人交互中选择新颖内容或更喜欢多样化推荐的倾向。另一方面，层次结构存在于用户的猎奇意图中，表现为一种静态的、内在的用户猎奇偏好以及一种基于会话的动态倾向。为此，我们提出了一种新的基于层次强化学习的方法来建立层次用户查新意图模型，并根据提取出的用户查新意图相应地调整推荐策略。我们进一步将多样性和新颖性相关度量纳入层次 RL (HRL)代理的奖励功能，以鼓励用户探索引用{ Chen 2021value }。我们通过在模拟和真实世界数据集上的大量实验，展示了在推荐中明确建模分层用户猎奇意图的好处。特别地，我们证明了我们提出的基于层次 RL 的方法的有效性在于它能够捕获这种层次结构的意图。结果表明，所提出的 HRL 模型在多个公共数据集上取得了优于现有基线的性能。"
    },
    {
        "title": "Multilingual Conceptual Coverage in Text-to-Image Models",
        "url": "http://arxiv.org/abs/2306.01735v1",
        "pub_date": "2023-06-02",
        "summary": "We propose \"Conceptual Coverage Across Languages\" (CoCo-CroLa), a technique\nfor benchmarking the degree to which any generative text-to-image system\nprovides multilingual parity to its training language in terms of tangible\nnouns. For each model we can assess \"conceptual coverage\" of a given target\nlanguage relative to a source language by comparing the population of images\ngenerated for a series of tangible nouns in the source language to the\npopulation of images generated for each noun under translation in the target\nlanguage. This technique allows us to estimate how well-suited a model is to a\ntarget language as well as identify model-specific weaknesses, spurious\ncorrelations, and biases without a-priori assumptions. We demonstrate how it\ncan be used to benchmark T2I models in terms of multilinguality, and how\ndespite its simplicity it is a good proxy for impressive generalization.",
        "translated": "我们提出了“跨语言的概念覆盖”(CoCo-CroLa) ，一种基准测试的程度，任何生成性文本到图像系统提供多语言平等的训练语言在有形名词方面。对于每个模型，我们可以通过比较源语言中一系列有形名词生成的图像的总体与目标语言中翻译下的每个名词生成的图像的总体来评估给定目标语言相对于源语言的“概念覆盖”。这种技术使我们能够估计模型与目标语言的匹配程度，并且在没有先验假设的情况下识别特定于模型的弱点、虚假的相关性和偏差。我们展示了如何使用它来基准 T2I 模型的多语言性，以及如何尽管它的简单性，它是一个令人印象深刻的推广良好的代理。"
    },
    {
        "title": "DocFormerv2: Local Features for Document Understanding",
        "url": "http://arxiv.org/abs/2306.01733v1",
        "pub_date": "2023-06-02",
        "summary": "We propose DocFormerv2, a multi-modal transformer for Visual Document\nUnderstanding (VDU). The VDU domain entails understanding documents (beyond\nmere OCR predictions) e.g., extracting information from a form, VQA for\ndocuments and other tasks. VDU is challenging as it needs a model to make sense\nof multiple modalities (visual, language and spatial) to make a prediction. Our\napproach, termed DocFormerv2 is an encoder-decoder transformer which takes as\ninput - vision, language and spatial features. DocFormerv2 is pre-trained with\nunsupervised tasks employed asymmetrically i.e., two novel document tasks on\nencoder and one on the auto-regressive decoder. The unsupervised tasks have\nbeen carefully designed to ensure that the pre-training encourages\nlocal-feature alignment between multiple modalities. DocFormerv2 when evaluated\non nine datasets shows state-of-the-art performance over strong baselines e.g.\nTabFact (4.3%), InfoVQA (1.4%), FUNSD (1%). Furthermore, to show generalization\ncapabilities, on three VQA tasks involving scene-text, Doc- Formerv2\noutperforms previous comparably-sized models and even does better than much\nlarger models (such as GIT2, PaLi and Flamingo) on some tasks. Extensive\nablations show that due to its pre-training, DocFormerv2 understands multiple\nmodalities better than prior-art in VDU.",
        "translated": "我们提出 DocFormerv2，一个用于可视化文档理解(VDU)的多模式转换器。VDU 领域需要理解文档(超越单纯的 OCR 预测) ，例如，从表单中提取信息，文档的 VQA 和其他任务。VDU 是具有挑战性的，因为它需要一个模型来理解多种形式(视觉、语言和空间)来做出预测。我们的方法，称为 DocFormerv2是一个编码器-解码器转换器，它采取作为输入-视觉，语言和空间特征。DocFormerv2预先训练了非对称使用的非监督任务，即编码器上的两个新的文档任务和自动回归解码器上的一个任务。这些无监督的任务经过精心设计，以确保预先培训鼓励多种模式之间的局部特征对齐。对9个数据集进行评估后，DocFormerv2显示出超过强基线的最先进性能，例如 TabFact (4.3%) ，InfoVQA (1.4%) ，FUNSD (1%)。此外，为了显示泛化能力，在涉及场景文本的三个 VQA 任务中，Doc-Formerv2在一些任务中表现优于以前的同等大小的模型，甚至优于更大的模型(如 GIT2、 PaLi 和 Flamingo)。广泛的消融表明，由于其预先培训，DocFormerv2了解多种形式更好地比先前的技术在 VDU。"
    },
    {
        "title": "Improving Generalization in Task-oriented Dialogues with Workflows and\n  Action Plans",
        "url": "http://arxiv.org/abs/2306.01729v1",
        "pub_date": "2023-06-02",
        "summary": "Task-oriented dialogue is difficult in part because it involves understanding\nuser intent, collecting information from the user, executing API calls, and\ngenerating helpful and fluent responses. However, for complex tasks one must\nalso correctly do all of these things over multiple steps, and in a specific\norder. While large pre-trained language models can be fine-tuned end-to-end to\ncreate multi-step task-oriented dialogue agents that generate fluent text, our\nexperiments confirm that this approach alone cannot reliably perform new\nmulti-step tasks that are unseen during training. To address these limitations,\nwe augment the dialogue contexts given to \\textmd{text2text} transformers with\nknown \\textit{valid workflow names} and \\textit{action plans}. Action plans\nconsist of sequences of actions required to accomplish a task, and are encoded\nas simple sequences of keywords (e.g. verify-identity, pull-up-account,\nreset-password, etc.). We perform extensive experiments on the Action-Based\nConversations Dataset (ABCD) with T5-small, base and large models, and show\nthat such models: a) are able to more readily generalize to unseen workflows by\nfollowing the provided plan, and b) are able to generalize to executing unseen\nactions if they are provided in the plan. In contrast, models are unable to\nfully accomplish new multi-step tasks when they are not provided action plan\ninformation, even when given new valid workflow names.",
        "translated": "面向任务的对话之所以困难，部分原因在于它涉及到理解用户的意图、从用户那里收集信息、执行 API 调用以及生成有用而流畅的响应。然而，对于复杂的任务，人们还必须在多个步骤中以特定的顺序正确地完成所有这些事情。虽然大型预先训练的语言模型可以进行端到端的微调，以创建多步骤任务导向的对话代理，生成流畅的文本，我们的实验证实，这种方法本身不能可靠地执行新的多步骤任务，在培训期间看不到。为了解决这些限制，我们使用已知的 texttit {有效的工作流名称}和 texttit {操作计划}增加了为 textmd { text2text }转换器提供的对话上下文。行动计划由完成任务所需的一系列行动组成，并被编码为简单的关键字序列(例如验证身份、上拉帐户、重置密码等)。我们在基于行动的对话数据集(ABCD)上对 T5-小型、基础和大型模型进行了广泛的实验，并表明这样的模型: a)能够通过遵循提供的计划更容易地推广到不可见的工作流，b)能够推广到执行不可见的行动，如果它们在计划中提供。相比之下，模型不能完全完成新的多步骤任务，如果没有提供行动计划信息，即使给出了新的有效工作流名称。"
    },
    {
        "title": "Distilling Efficient Language-Specific Models for Cross-Lingual Transfer",
        "url": "http://arxiv.org/abs/2306.01709v1",
        "pub_date": "2023-06-02",
        "summary": "Massively multilingual Transformers (MMTs), such as mBERT and XLM-R, are\nwidely used for cross-lingual transfer learning. While these are pretrained to\nrepresent hundreds of languages, end users of NLP systems are often interested\nonly in individual languages. For such purposes, the MMTs' language coverage\nmakes them unnecessarily expensive to deploy in terms of model size, inference\ntime, energy, and hardware cost. We thus propose to extract compressed,\nlanguage-specific models from MMTs which retain the capacity of the original\nMMTs for cross-lingual transfer. This is achieved by distilling the MMT\nbilingually, i.e., using data from only the source and target language of\ninterest. Specifically, we use a two-phase distillation approach, termed\nBiStil: (i) the first phase distils a general bilingual model from the MMT,\nwhile (ii) the second, task-specific phase sparsely fine-tunes the bilingual\n\"student\" model using a task-tuned variant of the original MMT as its\n\"teacher\". We evaluate this distillation technique in zero-shot cross-lingual\ntransfer across a number of standard cross-lingual benchmarks. The key results\nindicate that the distilled models exhibit minimal degradation in target\nlanguage performance relative to the base MMT despite being significantly\nsmaller and faster. Furthermore, we find that they outperform multilingually\ndistilled models such as DistilmBERT and MiniLMv2 while having a very modest\ntraining budget in comparison, even on a per-language basis. We also show that\nbilingual models distilled from MMTs greatly outperform bilingual models\ntrained from scratch. Our code and models are available at\nhttps://github.com/AlanAnsell/bistil.",
        "translated": "大规模多语言变换器(MMT) ，如 mBERT 和 XLM-R，被广泛用于跨语言迁移学习。虽然这些语言已经被预先训练成可以代表数百种语言，但是 NLP 系统的最终用户通常只对个别语言感兴趣。出于这样的目的，MMT 的语言覆盖率使得它们在模型大小、推理时间、能量和硬件成本方面的部署成本不必要地昂贵。因此，我们建议从 MMT 中提取压缩的、特定于语言的模型，这些模型保留了原始 MMT 的跨语言迁移能力。这是通过提取双语的 MMT 来实现的，也就是说，只使用感兴趣的源语言和目标语言的数据。具体而言，我们使用两阶段精馏方法，称为 BiStil: (i)第一阶段从 MMT 中提取一般的双语模型，而(ii)第二阶段，任务特定阶段使用原始 MMT 的任务调整变体作为其“老师”稀疏地微调双语“学生”模型。我们评估了这种蒸馏技术在零拍跨语言传输跨一些标准的跨语言基准。实验结果表明，相对于基本 MMT，提取出的模型尽管具有显著的更小和更快的性能，但是在目标语言性能方面表现出最小的退化。此外，我们发现它们的表现优于多语言蒸馏模型，如 DistilmBERT 和 MiniLMv2，同时具有非常有限的培训预算相比，即使在每种语言的基础上。我们还表明，从 MMT 中提炼出来的双语模型比从头开始训练的双语模型的表现要好得多。我们的代码和模型可在 https://github.com/alanansell/bistil 获得。"
    },
    {
        "title": "Resolving Interference When Merging Models",
        "url": "http://arxiv.org/abs/2306.01708v1",
        "pub_date": "2023-06-02",
        "summary": "Transfer learning - i.e., further fine-tuning a pre-trained model on a\ndownstream task - can confer significant advantages, including improved\ndownstream performance, faster convergence, and better sample efficiency. These\nadvantages have led to a proliferation of task-specific fine-tuned models,\nwhich typically can only perform a single task and do not benefit from one\nanother. Recently, model merging techniques have emerged as a solution to\ncombine multiple task-specific models into a single multitask model without\nperforming additional training. However, existing merging methods often ignore\nthe interference between parameters of different models, resulting in large\nperformance drops when merging multiple models. In this paper, we demonstrate\nthat prior merging techniques inadvertently lose valuable information due to\ntwo major sources of interference: (a) interference due to redundant parameter\nvalues and (b) disagreement on the sign of a given parameter's values across\nmodels. To address this, we propose our method, TrIm, Elect Sign &amp; Merge\n(TIES-Merging), which introduces three novel steps when merging models: (1)\nresetting parameters that only changed a small amount during fine-tuning, (2)\nresolving sign conflicts, and (3) merging only the parameters that are in\nalignment with the final agreed-upon sign. We find that TIES-Merging\noutperforms several existing methods in diverse settings covering a range of\nmodalities, domains, number of tasks, model sizes, architectures, and\nfine-tuning settings. We further analyze the impact of different types of\ninterference on model parameters, highlight the importance of resolving sign\ninterference. Our code is available at\nhttps://github.com/prateeky2806/ties-merging",
        "translated": "转移学习——即进一步微调下游任务的预先训练的模型——可以带来显著的优势，包括改善下游性能、加快收敛速度和提高采样效率。这些优势导致了特定于任务的微调模型的激增，这些模型通常只能执行单个任务，并且不能从彼此中受益。最近，模型合并技术已经成为一种解决方案，可以将多个任务特定的模型合并成一个单一的多任务模型，而不需要进行额外的训练。然而，现有的合并方法往往忽略了不同模型参数之间的干扰，导致合并多个模型时性能大幅度下降。在本文中，我们证明了先前的合并技术无意中失去了有价值的信息，由于两个主要的干扰来源: (a)由于冗余参数值的干扰和(b)在给定的参数值的符号不一致跨模型。为了解决这个问题，我们提出了我们的方法，TrIm，Elect Sign & Merge (TIES-Merging) ，它在合并模型时引入了三个新的步骤: (1)重置在微调过程中只改变了很少量的参数，(2)解决符号冲突，(3)只合并与最终达成一致的符号一致的参数。我们发现 TIES-Merging 在不同的设置中优于几种现有的方法，包括一系列模式、领域、任务数量、模型大小、架构和微调设置。进一步分析了不同类型的干扰对模型参数的影响，强调了解决符号干扰的重要性。我们的代码可以在 https://github.com/prateeky2806/ties-merging 找到"
    },
    {
        "title": "Learning Multi-step Reasoning from Arithmetic Task",
        "url": "http://arxiv.org/abs/2306.01707v1",
        "pub_date": "2023-06-02",
        "summary": "Mathematical reasoning is regarded as a necessary ability for Language Models\n(LMs). Recent works demonstrate large LMs' impressive performance in solving\nmath problems. The success is attributed to their Chain-of-Thought (CoT)\nreasoning abilities, i.e., the ability to decompose complex questions into\nstep-by-step reasoning chains, but such ability seems only to emerge from\nmodels with abundant parameters. This work investigates how to incorporate\nrelatively small LMs with the capabilities of multi-step reasoning. We propose\nto inject such abilities by continually pre-training LMs on a synthetic dataset\nMsAT, which stands for Multi-step Arithmetic Task. Our experiments on four math\nword problem datasets show the effectiveness of the proposed method in\nenhancing LMs' math reasoning abilities.",
        "translated": "数学推理被认为是语言模型(LM)的必备能力。最近的作品展示了大型 LM 在解决数学问题方面令人印象深刻的表现。这一成功归功于他们的思维链(Chain-of-Thought，CoT)推理能力，即将复杂问题分解为逐步推理链的能力，但这种能力似乎只出现在参数丰富的模型中。本文研究如何将相对较小的线性规划模型与多步推理能力结合起来。我们建议通过在一个合成数据集 MsAT 上连续预训练 LM 来注入这种能力，MsAT 表示多步算术任务。我们在四个数学词汇问题数据集上的实验表明了该方法在提高 LM 数学推理能力方面的有效性。"
    },
    {
        "title": "Fine-Grained Human Feedback Gives Better Rewards for Language Model\n  Training",
        "url": "http://arxiv.org/abs/2306.01693v1",
        "pub_date": "2023-06-02",
        "summary": "Language models (LMs) often exhibit undesirable text generation behaviors,\nincluding generating false, toxic, or irrelevant outputs. Reinforcement\nlearning from human feedback (RLHF) - where human preference judgments on LM\noutputs are transformed into a learning signal - has recently shown promise in\naddressing these issues. However, such holistic feedback conveys limited\ninformation on long text outputs; it does not indicate which aspects of the\noutputs influenced user preference; e.g., which parts contain what type(s) of\nerrors. In this paper, we use fine-grained human feedback (e.g., which sentence\nis false, which sub-sentence is irrelevant) as an explicit training signal. We\nintroduce Fine-Grained RLHF, a framework that enables training and learning\nfrom reward functions that are fine-grained in two respects: (1) density,\nproviding a reward after every segment (e.g., a sentence) is generated; and (2)\nincorporating multiple reward models associated with different feedback types\n(e.g., factual incorrectness, irrelevance, and information incompleteness). We\nconduct experiments on detoxification and long-form question answering to\nillustrate how learning with such reward functions leads to improved\nperformance, supported by both automatic and human evaluation. Additionally, we\nshow that LM behaviors can be customized using different combinations of\nfine-grained reward models. We release all data, collected human feedback, and\ncodes at https://FineGrainedRLHF.github.io.",
        "translated": "语言模型(LM)经常表现出不良的文本生成行为，包括生成错误的、有毒的或不相关的输出。人类反馈的强化学习——人类对 LM 输出的偏好判断被转化为一个学习信号——最近在解决这些问题方面显示出了希望。然而，这样的整体反馈传达了关于长文本输出的有限信息; 它没有指出输出的哪些方面影响了用户的偏好; 例如，哪些部分包含哪些类型的错误。在本文中，我们使用细粒度的人反馈(例如，哪个句子是错误的，哪个子句是不相关的)作为显性训练信号。我们介绍了细粒度 RLHF，一个框架，使培训和学习奖励功能的细粒度在两个方面: (1)密度，提供奖励后，每个部分(例如，一个句子)生成; 和(2)结合多个奖励模型与不同的反馈类型(例如，事实不正确，不相关性和信息不完整)。我们进行了解毒实验和长形式的问题回答，以说明如何学习与这种奖励功能导致提高绩效，支持自动和人类的评价。此外，我们表明，LM 行为可以定制使用细粒度奖励模型的不同组合。我们发布所有数据，收集人类反馈，并在 https://finegrainedrlhf.github.io 代码。"
    },
    {
        "title": "DiffusEmp: A Diffusion Model-Based Framework with Multi-Grained Control\n  for Empathetic Response Generation",
        "url": "http://arxiv.org/abs/2306.01657v1",
        "pub_date": "2023-06-02",
        "summary": "Empathy is a crucial factor in open-domain conversations, which naturally\nshows one's caring and understanding to others. Though several methods have\nbeen proposed to generate empathetic responses, existing works often lead to\nmonotonous empathy that refers to generic and safe expressions. In this paper,\nwe propose to use explicit control to guide the empathy expression and design a\nframework DiffusEmp based on conditional diffusion language model to unify the\nutilization of dialogue context and attribute-oriented control signals.\nSpecifically, communication mechanism, intent, and semantic frame are imported\nas multi-grained signals that control the empathy realization from coarse to\nfine levels. We then design a specific masking strategy to reflect the\nrelationship between multi-grained signals and response tokens, and integrate\nit into the diffusion model to influence the generative process. Experimental\nresults on a benchmark dataset EmpatheticDialogue show that our framework\noutperforms competitive baselines in terms of controllability, informativeness,\nand diversity without the loss of context-relatedness.",
        "translated": "移情是开放领域对话中的一个关键因素，它自然而然地表现出一个人对他人的关心和理解。虽然已经提出了一些方法来产生移情反应，现有的作品往往导致单调的移情，涉及通用和安全的表达。本文提出用显式控制来引导移情表达，并设计了一个基于条件扩散语言模型的扩散映射框架，统一了对话上下文和面向属性控制信号的利用。具体来说，引入交流机制、意图和语义框架作为多粒度信号，从粗到细控制移情实现。然后我们设计了一个特定的掩蔽策略来反映多粒度信号和响应标记之间的关系，并将其整合到扩散模型中以影响生成过程。在一个基准数据集 EmpatheticDialogue 上的实验结果表明，我们的框架在可控性、信息性和多样性方面优于竞争性基准，而且没有丧失上下文相关性。"
    },
    {
        "title": "Learning from Partially Annotated Data: Example-aware Creation of\n  Gap-filling Exercises for Language Learning",
        "url": "http://arxiv.org/abs/2306.01584v1",
        "pub_date": "2023-06-02",
        "summary": "Since performing exercises (including, e.g., practice tests) forms a crucial\ncomponent of learning, and creating such exercises requires non-trivial effort\nfrom the teacher. There is a great value in automatic exercise generation in\ndigital tools in education. In this paper, we particularly focus on automatic\ncreation of gapfilling exercises for language learning, specifically grammar\nexercises. Since providing any annotation in this domain requires human expert\neffort, we aim to avoid it entirely and explore the task of converting existing\ntexts into new gap-filling exercises, purely based on an example exercise,\nwithout explicit instruction or detailed annotation of the intended grammar\ntopics. We contribute (i) a novel neural network architecture specifically\ndesigned for aforementioned gap-filling exercise generation task, and (ii) a\nreal-world benchmark dataset for French grammar. We show that our model for\nthis French grammar gap-filling exercise generation outperforms a competitive\nbaseline classifier by 8% in F1 percentage points, achieving an average F1\nscore of 82%. Our model implementation and the dataset are made publicly\navailable to foster future research, thus offering a standardized evaluation\nand baseline solution of the proposed partially annotated data prediction task\nin grammar exercise creation.",
        "translated": "因为做练习(包括，例如，练习测试)是学习的重要组成部分，而创建这样的练习需要老师付出非凡的努力。数字化练习工具的自动生成在教育中具有重要的应用价值。在本文中，我们特别关注于语言学习中填空练习的自动生成，尤其是语法练习。由于在这个领域提供任何注释都需要人类专家的努力，我们的目标是完全避免它，并探索将现有文本转换为新的填补空白练习的任务，纯粹基于一个示例练习，没有明确的指示或预期的语法主题的详细注释。我们贡献了(i)一个新的神经网络架构，专门设计的上述缺口填补练习生成任务，和(ii)法语语法的现实世界基准数据集。我们表明，我们的模型为这个法语语法差距填补练习生成优于竞争性基线分类器8% 的 F1百分点，实现平均 F1得分为82% 。我们的模型实现和数据集是公开的，以促进未来的研究，从而提供了一个标准化的评价和基线解决方案的建议部分注释数据预测任务在语法练习创建。"
    },
    {
        "title": "EmoUS: Simulating User Emotions in Task-Oriented Dialogues",
        "url": "http://arxiv.org/abs/2306.01579v1",
        "pub_date": "2023-06-02",
        "summary": "Existing user simulators (USs) for task-oriented dialogue systems only model\nuser behaviour on semantic and natural language levels without considering the\nuser persona and emotions. Optimising dialogue systems with generic user\npolicies, which cannot model diverse user behaviour driven by different\nemotional states, may result in a high drop-off rate when deployed in the real\nworld. Thus, we present EmoUS, a user simulator that learns to simulate user\nemotions alongside user behaviour. EmoUS generates user emotions, semantic\nactions, and natural language responses based on the user goal, the dialogue\nhistory, and the user persona. By analysing what kind of system behaviour\nelicits what kind of user emotions, we show that EmoUS can be used as a probe\nto evaluate a variety of dialogue systems and in particular their effect on the\nuser's emotional state. Developing such methods is important in the age of\nlarge language model chat-bots and rising ethical concerns.",
        "translated": "现有的面向任务对话系统的用户模拟器(USs)只是在语义和自然语言层面上对用户行为进行建模，而没有考虑用户角色和情感。使用通用用户策略优化对话系统，不能模拟由不同情绪状态驱动的不同用户行为，在现实世界中部署时可能导致较高的下降率。因此，我们提出了 emoUS，一个用户模拟器，学习模拟用户的情绪以及用户的行为。基于用户目标、对话历史和用户角色，EmoUS 产生用户情绪、语义动作和自然语言反应。通过分析什么样的系统行为引发了什么样的用户情绪，我们表明，情绪美可以作为一个探测器来评估各种对话系统，特别是他们对用户的情绪状态的影响。在大型语言模型聊天机器人时代，开发这样的方法非常重要，同时也引起了越来越多的道德关注。"
    },
    {
        "title": "Learning Similarity among Users for Personalized Session-Based\n  Recommendation from hierarchical structure of User-Session-Item",
        "url": "http://arxiv.org/abs/2306.03040v1",
        "pub_date": "2023-06-05",
        "summary": "The task of the session-based recommendation is to predict the next\ninteraction of the user based on the anonymized user's behavior pattern. And\npersonalized version of this system is a promising research field due to its\navailability to deal with user information. However, there's a problem that the\nuser's preferences and historical sessions were not considered in the typical\nsession-based recommendation since it concentrates only on user-item\ninteraction. In addition, the existing personalized session-based\nrecommendation model has a limited capability in that it only considers the\npreference of the current user without considering those of similar users. It\nmeans there can be the loss of information included within the hierarchical\ndata structure of the user-session-item. To tackle with this problem, we\npropose USP-SBR(abbr. of User Similarity Powered - Session Based Recommender).\nTo model global historical sessions of users, we propose UserGraph that has two\ntypes of nodes - ItemNode and UserNode. We then connect the nodes with three\ntypes of edges. The first type of edges connects ItemNode as chronological\norder, and the second connects ItemNode to UserNode, and the last connects\nUserNode to ItemNode. With these user embeddings, we propose additional\ncontrastive loss, that makes users with similar intention be close to each\nother in the vector space. we apply graph neural network on these UserGraph and\nupdate nodes. Experimental results on two real-world datasets demonstrate that\nour method outperforms some state-of-the-art approaches.",
        "translated": "基于会话的推荐的任务是根据匿名用户的行为模式预测用户的下一次交互。而个性化版本的系统由于能够有效地处理用户信息，是一个很有前途的研究领域。然而，有一个问题，在典型的基于会话的推荐中没有考虑用户的首选项和历史会话，因为它只关注用户项交互。此外，现有的基于个性化会话的推荐模型能力有限，因为它只考虑当前用户的偏好，而不考虑相似用户的偏好。这意味着用户会话项的分层数据结构中包含的信息可能会丢失。为了解决这一问题，我们提出了 USP-SBR (abbr。基于用户相似度的动态会话推荐程序)。为了对用户的全局历史会话进行建模，我们提出了具有两种类型节点的 UserGraph —— ItemNode 和 UserNode。然后我们用三种边连接节点。第一种边以时间顺序连接 ItemNode，第二种边将 ItemNode 连接到 UserNode，最后一种边将 UserNode 连接到 ItemNode。通过这些用户嵌入，我们提出了额外的对比损失，使得具有相似意图的用户在向量空间中更加接近。我们将图形神经网络应用于这些用户图和更新节点。在两个实际数据集上的实验结果表明，我们的方法优于一些最先进的方法。"
    },
    {
        "title": "Gen-IR @ SIGIR 2023: The First Workshop on Generative Information\n  Retrieval",
        "url": "http://arxiv.org/abs/2306.02887v1",
        "pub_date": "2023-06-05",
        "summary": "Generative information retrieval (IR) has experienced substantial growth\nacross multiple research communities (e.g., information retrieval, computer\nvision, natural language processing, and machine learning), and has been highly\nvisible in the popular press. Theoretical, empirical, and actual user-facing\nproducts have been released that retrieve documents (via generation) or\ndirectly generate answers given an input request. We would like to investigate\nwhether end-to-end generative models are just another trend or, as some claim,\na paradigm change for IR. This necessitates new metrics, theoretical grounding,\nevaluation methods, task definitions, models, user interfaces, etc. The goal of\nthis workshop (https://coda.io/@sigir/gen-ir) is to focus on previously\nexplored Generative IR techniques like document retrieval and direct Grounded\nAnswer Generation, while also offering a venue for the discussion and\nexploration of how Generative IR can be applied to new domains like\nrecommendation systems, summarization, etc. The format of the workshop is\ninteractive, including roundtable and keynote sessions and tends to avoid the\none-sided dialogue of a mini-conference.",
        "translated": "生成信息检索在多个研究领域(如信息检索、计算机视觉、自然语言处理和机器学习)都经历了实质性的增长，并且在大众媒体上非常明显。理论、经验和实际的面向用户的产品已经发布，检索文档(通过生成)或直接生成给定输入请求的答案。我们想要研究的是，端到端的生成模型是否只是另一种趋势，或者，正如一些人声称的，一个范式变化的 IR。这就需要新的指标、理论基础、评估方法、任务定义、模型、用户界面等。这个研讨会( https://coda.io/@sigir/gen-IR )的目标是专注于先前探索的生成性信息检索技术，如文献检索和直接接地的答案生成，同时也为讨论和探索生成性信息检索如何应用于新的领域，如推荐系统，摘要等提供了场所。讲习班的形式是互动的，包括圆桌会议和主旨会议，往往避免小型会议的单方面对话。"
    },
    {
        "title": "Benchmarking Middle-Trained Language Models for Neural Search",
        "url": "http://arxiv.org/abs/2306.02867v1",
        "pub_date": "2023-06-05",
        "summary": "Middle training methods aim to bridge the gap between the Masked Language\nModel (MLM) pre-training and the final finetuning for retrieval. Recent models\nsuch as CoCondenser, RetroMAE, and LexMAE argue that the MLM task is not\nsufficient enough to pre-train a transformer network for retrieval and hence\npropose various tasks to do so. Intrigued by those novel methods, we noticed\nthat all these models used different finetuning protocols, making it hard to\nassess the benefits of middle training. We propose in this paper a benchmark of\nCoCondenser, RetroMAE, and LexMAE, under the same finetuning conditions. We\ncompare both dense and sparse approaches under various finetuning protocols and\nmiddle training on different collections (MS MARCO, Wikipedia or Tripclick). We\nuse additional middle training baselines, such as a standard MLM finetuning on\nthe retrieval collection, optionally augmented by a CLS predicting the passage\nterm frequency. For the sparse approach, our study reveals that there is almost\nno statistical difference between those methods: the more effective the\nfinetuning procedure is, the less difference there is between those models. For\nthe dense approach, RetroMAE using MS MARCO as middle-training collection shows\nexcellent results in almost all the settings. Finally, we show that middle\ntraining on the retrieval collection, thus adapting the language model to it,\nis a critical factor. Overall, a better experimental setup should be adopted to\nevaluate middle training methods. Code available at\nhttps://github.com/naver/splade/tree/benchmarch-SIGIR23",
        "translated": "中间训练方法旨在弥补蒙版语言模型(MLM)预训练和检索的最终微调之间的差距。最近的一些模型，如 CoCondenser，RotMAE 和 LexMAE 认为传销任务不足以预先训练一个变压器网络进行检索，因此提出了各种各样的任务来这样做。被这些新奇的方法所吸引，我们注意到所有这些模型使用不同的微调协议，使得评估中间训练的好处变得困难。在本文中，我们提出了一个基准的协同凝聚器，反向 MAE 和 LexMAE，在相同的微调条件下。我们比较了在各种微调协议和不同集合(MS MARCO，Wikipedia 或 Tripclick)的中间培训下的密集和稀疏方法。我们使用额外的中间训练基线，例如在检索集合上的标准 MLM 微调，可选地通过预测通过项频率的 CLS 加强。对于稀疏方法，我们的研究表明，这些方法之间几乎没有统计上的差异: 微调过程越有效，这些模型之间的差异就越小。对于密集的方法，使用 MS MARCO 作为中间训练收集在几乎所有的设置中都显示出优异的结果。最后，我们表明，中间训练的检索集，从而使语言模型适应它，是一个关键因素。总的来说，应该采用更好的实验设置来评价中间训练方法。Https://github.com/naver/splade/tree/benchmarch-sigir23提供密码"
    },
    {
        "title": "CTRL: Connect Tabular and Language Model for CTR Prediction",
        "url": "http://arxiv.org/abs/2306.02841v1",
        "pub_date": "2023-06-05",
        "summary": "Traditional click-through rate (CTR) prediction models convert the tabular\ndata into one-hot vectors and leverage the collaborative relations among\nfeatures for inferring user's preference over items. This modeling paradigm\ndiscards the essential semantic information. Though some recent works like P5\nand M6-Rec have explored the potential of using Pre-trained Language Models\n(PLMs) to extract semantic signals for CTR prediction, they are computationally\nexpensive and suffer from low efficiency. Besides, the beneficial collaborative\nrelations are not considered, hindering the recommendation performance. To\nsolve these problems, in this paper, we propose a novel framework\n\\textbf{CTRL}, which is industrial friendly and model-agnostic with high\ntraining and inference efficiency. Specifically, the original tabular data is\nfirst converted into textual data. Both tabular data and converted textual data\nare regarded as two different modalities and are separately fed into the\ncollaborative CTR model and pre-trained language model. A cross-modal knowledge\nalignment procedure is performed to fine-grained align and integrate the\ncollaborative and semantic signals, and the lightweight collaborative model can\nbe deployed online for efficient serving after fine-tuned with supervised\nsignals. Experimental results on three public datasets show that CTRL\noutperforms the SOTA CTR models significantly. Moreover, we further verify its\neffectiveness on a large-scale industrial recommender system.",
        "translated": "传统的点进率预测模型将表格数据转换为一个热点向量，并利用特征之间的协同关系来推断用户对项目的偏好。这种建模范式抛弃了基本的语义信息。虽然最近的一些工作，如 P5和 M6-Rec 已经探索了使用预训练语言模型(PLM)提取语义信号进行 CTR 预测的潜力，但是它们的计算成本高，效率低。此外，没有考虑到有益的协作关系，阻碍了推荐绩效的提高。为了解决这些问题，本文提出了一种新的框架 textbf { CTRL } ，该框架具有良好的工业友好性和模型无关性，并且具有较高的训练和推理效率。具体来说，首先将原始表格数据转换为文本数据。将表格数据和转换后的文本数据视为两种不同的模式，分别输入协同 CTR 模型和预训练语言模型。通过跨模态知识对齐过程对协作信号和语义信号进行细粒度对齐和集成，并对监督信号进行细调后，可以在线部署轻量级协作模型，实现高效服务。在三个公共数据集上的实验结果表明，CTRL 模型的性能明显优于 SOTA CTR 模型。此外，我们进一步验证了该方法在大规模工业推荐系统上的有效性。"
    },
    {
        "title": "Path-Specific Counterfactual Fairness for Recommender Systems",
        "url": "http://arxiv.org/abs/2306.02615v1",
        "pub_date": "2023-06-05",
        "summary": "Recommender systems (RSs) have become an indispensable part of online\nplatforms. With the growing concerns of algorithmic fairness, RSs are not only\nexpected to deliver high-quality personalized content, but are also demanded\nnot to discriminate against users based on their demographic information.\nHowever, existing RSs could capture undesirable correlations between sensitive\nfeatures and observed user behaviors, leading to biased recommendations. Most\nfair RSs tackle this problem by completely blocking the influences of sensitive\nfeatures on recommendations. But since sensitive features may also affect user\ninterests in a fair manner (e.g., race on culture-based preferences),\nindiscriminately eliminating all the influences of sensitive features\ninevitably degenerate the recommendations quality and necessary diversities. To\naddress this challenge, we propose a path-specific fair RS (PSF-RS) for\nrecommendations. Specifically, we summarize all fair and unfair correlations\nbetween sensitive features and observed ratings into two latent proxy\nmediators, where the concept of path-specific bias (PS-Bias) is defined based\non path-specific counterfactual inference. Inspired by Pearl's minimal change\nprinciple, we address the PS-Bias by minimally transforming the biased factual\nworld into a hypothetically fair world, where a fair RS model can be learned\naccordingly by solving a constrained optimization problem. For the technical\npart, we propose a feasible implementation of PSF-RS, i.e., PSF-VAE, with\nweakly-supervised variational inference, which robustly infers the latent\nmediators such that unfairness can be mitigated while necessary recommendation\ndiversities can be maximally preserved simultaneously. Experiments conducted on\nsemi-simulated and real-world datasets demonstrate the effectiveness of PSF-RS.",
        "translated": "推荐系统已经成为在线平台不可或缺的一部分。随着对算法公平性的日益关注，RSS 不仅被期望提供高质量的个性化内容，而且被要求不因用户的人口统计信息而歧视用户。然而，现有的 RSS 可能捕获敏感特性和观察到的用户行为之间不希望看到的相关性，从而导致有偏见的推荐。大多数公平的 RSS 通过完全阻止敏感特性对建议的影响来解决这个问题。但是，由于敏感特性也可能以公平的方式影响用户的兴趣(例如，基于文化的偏好的种族) ，不加区分地消除敏感特性的所有影响必然会降低推荐的质量和必要的多样性。为了应对这一挑战，我们提出了一个路径特定的公平 RS (PSF-RS)的建议。具体而言，我们将敏感特征和观察评分之间的所有公平和不公平的相关性总结为两个潜在的代理中介，其中路径特异性偏倚(PS-Bias)的概念是基于路径特异性反事实推断定义的。受珀尔的最小改变原则的启发，我们通过最小化地将有偏见的现实世界转化为一个假设的公平世界，在这个假设的公平世界中，通过解决一个受限制的最佳化问题，可以相应地学习一个公平的遥感模型，从而解决偏差问题。在技术部分，我们提出了一种可行的 PSF-RS 的实现方法，即弱监督变分推理 PSF-VAE，它可以强有力地推断出潜在的中介因子，从而在最大限度地保留必要的推荐多样性的同时，减少不公平性。在半模拟和真实数据集上进行的实验证明了 PSF-RS 算法的有效性。"
    },
    {
        "title": "RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems",
        "url": "http://arxiv.org/abs/2306.03091v1",
        "pub_date": "2023-06-05",
        "summary": "Large Language Models (LLMs) have greatly advanced code auto-completion\nsystems, with a potential for substantial productivity enhancements for\ndevelopers. However, current benchmarks mainly focus on single-file tasks,\nleaving an assessment gap for more complex, real-world, multi-file programming\nscenarios. To fill this gap, we introduce RepoBench, a new benchmark\nspecifically designed for evaluating repository-level code auto-completion\nsystems. RepoBench consists of three interconnected evaluation tasks:\nRepoBench-R (Retrieval), RepoBench-C (Code Completion), and RepoBench-P\n(Pipeline). Each task respectively measures the system's ability to retrieve\nthe most relevant code snippets from other files as cross-file context, predict\nthe next line of code with cross-file and in-file context, and handle complex\ntasks that require a combination of both retrieval and next-line prediction.\nRepoBench aims to facilitate a more complete comparison of performance and\nencouraging continuous improvement in auto-completion systems. RepoBench is\npublicly available at https://github.com/Leolty/repobench.",
        "translated": "大型语言模型(Large Language Model，LLM)具有非常先进的代码自动完成系统，对于开发人员来说，这有可能大大提高生产力。然而，当前的基准测试主要集中在单文件任务上，对于更复杂的、真实的、多文件编程场景留下了评估空白。为了填补这个空白，我们引入了 RepoBench，这是一个专门为评估存储库级代码自动完成系统而设计的新基准。RepoBench 由三个相互连接的评估任务组成: RepoBench-R (检索)、 RepoBench-C (代码完成)和 RepoBench-P (管道)。每个任务分别测量系统从其他文件中检索最相关代码片段作为跨文件上下文的能力，用跨文件和文件内上下文预测下一行代码的能力，以及处理需要检索和下一行预测相结合的复杂任务的能力。RepoBench 旨在促进更全面的性能比较，并鼓励自动完成系统的持续改进。RepoBench 可在 https://github.com/leolty/RepoBench 公开使用。"
    },
    {
        "title": "Is ChatGPT a Good Teacher Coach? Measuring Zero-Shot Performance For\n  Scoring and Providing Actionable Insights on Classroom Instruction",
        "url": "http://arxiv.org/abs/2306.03090v1",
        "pub_date": "2023-06-05",
        "summary": "Coaching, which involves classroom observation and expert feedback, is a\nwidespread and fundamental part of teacher training. However, the majority of\nteachers do not have access to consistent, high quality coaching due to limited\nresources and access to expertise. We explore whether generative AI could\nbecome a cost-effective complement to expert feedback by serving as an\nautomated teacher coach. In doing so, we propose three teacher coaching tasks\nfor generative AI: (A) scoring transcript segments based on classroom\nobservation instruments, (B) identifying highlights and missed opportunities\nfor good instructional strategies, and (C) providing actionable suggestions for\neliciting more student reasoning. We recruit expert math teachers to evaluate\nthe zero-shot performance of ChatGPT on each of these tasks for elementary math\nclassroom transcripts. Our results reveal that ChatGPT generates responses that\nare relevant to improving instruction, but they are often not novel or\ninsightful. For example, 82% of the model's suggestions point to places in the\ntranscript where the teacher is already implementing that suggestion. Our work\nhighlights the challenges of producing insightful, novel and truthful feedback\nfor teachers while paving the way for future research to address these\nobstacles and improve the capacity of generative AI to coach teachers.",
        "translated": "辅导，包括课堂观察和专家反馈，是教师培训的一个广泛而基本的组成部分。然而，由于资源和专业知识有限，大多数教师无法获得连贯、高质量的辅导。我们探讨生成式人工智能是否可以成为一个具有成本效益的专家反馈的补充，作为一个自动化的教师教练。在这样做时，我们提出了三个生成性人工智能的教师培训任务: (A)基于课堂观察工具评分成绩单片段，(B)识别优秀教学策略的亮点和错过的机会，以及(C)提供可行的建议，以引发更多的学生推理。我们招募数学专家教师来评估 ChatGPT 在小学数学课堂成绩单中每一项任务的“零打击”表现。我们的研究结果表明，ChatGPT 产生的反应与提高教学质量有关，但它们往往不是新颖或有见地的。例如，模型中82% 的建议指向成绩单中教师已经实施该建议的地方。我们的工作强调了为教师提供有见地、新颖和真实的反馈所面临的挑战，同时为未来的研究解决这些障碍和提高生成性人工智能指导教师的能力铺平了道路。"
    },
    {
        "title": "Sequential Monte Carlo Steering of Large Language Models using\n  Probabilistic Programs",
        "url": "http://arxiv.org/abs/2306.03081v1",
        "pub_date": "2023-06-05",
        "summary": "Even after fine-tuning and reinforcement learning, large language models\n(LLMs) can be difficult, if not impossible, to control reliably with prompts\nalone. We propose a new inference-time approach to enforcing syntactic and\nsemantic constraints on the outputs of LLMs, called sequential Monte Carlo\n(SMC) steering. The key idea is to specify language generation tasks as\nposterior inference problems in a class of discrete probabilistic sequence\nmodels, and replace standard decoding with sequential Monte Carlo inference.\nFor a computational cost similar to that of beam search, SMC can steer LLMs to\nsolve diverse tasks, including infilling, generation under syntactic\nconstraints, and prompt intersection. To facilitate experimentation with SMC\nsteering, we present a probabilistic programming library, LLaMPPL\n(https://github.com/probcomp/LLaMPPL), for concisely specifying new generation\ntasks as language model probabilistic programs, and automating steering of\nLLaMA-family Transformers.",
        "translated": "即使经过微调和强化学习，大型语言模型(LLM)也很难单靠提示符进行可靠控制。我们提出了一种新的推理时间方法，称为序贯蒙特卡罗(SMC)指导，以强制语法和语义约束的 LLM 的输出。其核心思想是在一类离散概率序列模型中将语言生成任务指定为后验推理问题，并用序贯蒙特卡罗推理代替标准译码。对于类似于波束搜索的计算代价，SMC 可以引导 LLM 解决不同的任务，包括填充、语法约束下的生成和快速交叉。为了方便 SMC 指导的实验，我们提出了一个概率编程库，LLaMPPL ( https://github.com/probcomp/LLaMPPL ) ，简明地指定新一代任务作为语言模型概率程序，并自动指导 LlaMA 家族变压器。"
    },
    {
        "title": "Machine Learning and Statistical Approaches to Measuring Similarity of\n  Political Parties",
        "url": "http://arxiv.org/abs/2306.03079v1",
        "pub_date": "2023-06-05",
        "summary": "Mapping political party systems to metric policy spaces is one of the major\nmethodological problems in political science. At present, in most political\nscience project this task is performed by domain experts relying on purely\nqualitative assessments, with all the attendant problems of subjectivity and\nlabor intensiveness. We consider how advances in natural language processing,\nincluding large transformer-based language models, can be applied to solve that\nissue. We apply a number of texts similarity measures to party political\nprograms, analyze how they correlate with each other, and -- in the absence of\na satisfactory benchmark -- evaluate them against other measures, including\nthose based on expert surveys, voting records, electoral patterns, and\ncandidate networks. Finally, we consider the prospects of relying on those\nmethods to correct, supplement, and eventually replace expert judgments.",
        "translated": "将政党系统映射到度量政策空间是政治学的主要方法论问题之一。目前，在大多数政治科学项目中，这项任务是由领域专家依靠纯粹的定性评估来完成的，伴随而来的问题包括主观性和劳动密集性。我们考虑如何应用自然语言处理的进步，包括基于大型转换器的语言模型，来解决这个问题。我们将大量的文本相似性度量方法应用于政党政治计划，分析它们之间的相互关系，并且——在缺乏令人满意的基准的情况下——根据其他度量方法对它们进行评估，包括那些基于专家调查、投票记录、选举模式和候选人网络的方法。最后，我们考虑依靠这些方法来纠正、补充并最终取代专家判断的前景。"
    },
    {
        "title": "SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight\n  Compression",
        "url": "http://arxiv.org/abs/2306.03078v1",
        "pub_date": "2023-06-05",
        "summary": "Recent advances in large language model (LLM) pretraining have led to\nhigh-quality LLMs with impressive abilities. By compressing such LLMs via\nquantization to 3-4 bits per parameter, they can fit into memory-limited\ndevices such as laptops and mobile phones, enabling personalized use. However,\nquantization down to 3-4 bits per parameter usually leads to moderate-to-high\naccuracy losses, especially for smaller models in the 1-10B parameter range,\nwhich are well-suited for edge deployments. To address this accuracy issue, we\nintroduce the Sparse-Quantized Representation (SpQR), a new compressed format\nand quantization technique which enables for the first time near-lossless\ncompression of LLMs across model scales, while reaching similar compression\nlevels to previous methods. SpQR works by identifying and isolating outlier\nweights, which cause particularly-large quantization errors, and storing them\nin higher precision, while compressing all other weights to 3-4 bits, and\nachieves relative accuracy losses of less than 1% in perplexity for\nhighly-accurate LLaMA and Falcon LLMs. This makes it possible to run 33B\nparameter LLM on a single 24 GB consumer GPU without any performance\ndegradation at 15% speedup thus making powerful LLMs available to consumer\nwithout any downsides. SpQR comes with efficient algorithms for both encoding\nweights into its format, as well as decoding them efficiently at runtime.\nSpecifically, we provide an efficient GPU inference algorithm for SpQR which\nyields faster inference than 16-bit baselines at similar accuracy, while\nenabling memory compression gains of more than 4x.",
        "translated": "大语言模型(LLM)预训练的最新进展导致了具有令人印象深刻的能力的高质量 LLM。通过量化将这种 LLM 压缩到每个参数3-4位，它们可以适用于内存有限的设备，如笔记本电脑和移动电话，从而实现个性化使用。然而，每个参数下降到3-4位的量化通常会导致中高精度的损失，特别是对于1-10B 参数范围内的较小模型，它们非常适合边缘部署。为了解决这个精度问题，我们引入了稀疏量化表示(SpQR) ，这是一种新的压缩格式和量化技术，它能够首次在模型尺度上对 LLM 进行近无损压缩，同时达到与以前的方法相似的压缩水平。SpQR 的工作原理是识别和隔离引起特别大量化误差的离群值权重，并以更高的精度存储它们，同时将所有其他权重压缩到3-4位，对于高精度 LLaMA 和 Falcon LLM，相对精度损失小于1% 。这使得在一个24GB 的消费者 GPU 上运行33B 参数 LLM 成为可能，而且在加速15% 的情况下性能没有任何下降，从而使得消费者可以在没有任何缺点的情况下使用功能强大的 LLM。SpQR 提供了有效的算法，既可以将权值编码成它的格式，也可以在运行时高效地解码它们。具体来说，我们为 SpQR 提供了一种高效的 GPU 推理算法，它在相似的精度下比16位基线产生更快的推理，同时使内存压缩增益超过4倍。"
    },
    {
        "title": "Interactive Editing for Text Summarization",
        "url": "http://arxiv.org/abs/2306.03067v1",
        "pub_date": "2023-06-05",
        "summary": "Summarizing lengthy documents is a common and essential task in our daily\nlives. Although recent advancements in neural summarization models can assist\nin crafting general-purpose summaries, human writers often have specific\nrequirements that call for a more customized approach. To address this need, we\nintroduce REVISE (Refinement and Editing via Iterative Summarization\nEnhancement), an innovative framework designed to facilitate iterative editing\nand refinement of draft summaries by human writers. Within our framework,\nwriters can effortlessly modify unsatisfactory segments at any location or\nlength and provide optional starting phrases -- our system will generate\ncoherent alternatives that seamlessly integrate with the existing summary. At\nits core, REVISE incorporates a modified fill-in-the-middle model with the\nencoder-decoder architecture while developing novel evaluation metrics tailored\nfor the summarization task. In essence, our framework empowers users to create\nhigh-quality, personalized summaries by effectively harnessing both human\nexpertise and AI capabilities, ultimately transforming the summarization\nprocess into a truly collaborative and adaptive experience.",
        "translated": "总结冗长的文件是我们日常生活中的一项共同而又必不可少的任务。虽然神经总结模型的最新进展可以帮助制作通用的总结，但人类作者往往有特定的需求，需要更加定制的方法。为了满足这一需求，我们引入了 REVISE (通过迭代摘要增强进行细化和编辑) ，这是一个创新的框架，旨在促进人类作者对摘要草稿的迭代编辑和细化。在我们的框架内，作者可以毫不费力地在任何位置或长度修改不满意的部分，并提供可选的起始短语——我们的系统将生成与现有摘要无缝集成的连贯备选方案。在其核心，REVISE 采用了修改的填充中间模型与编码器-解码器架构，同时开发新的评估指标定制的摘要任务。本质上，我们的框架通过有效利用人类专业知识和人工智能能力，使用户能够创建高质量的个性化摘要，最终将摘要过程转化为真正的协作和适应性体验。"
    },
    {
        "title": "Structured Voronoi Sampling",
        "url": "http://arxiv.org/abs/2306.03061v1",
        "pub_date": "2023-06-05",
        "summary": "Recently, there has been a growing interest in the development of\ngradient-based sampling algorithms for text generation, especially in the\ncontext of controlled generation. However, there exists a lack of theoretically\ngrounded and principled approaches for this task. In this paper, we take an\nimportant step toward building a principled approach for sampling from language\nmodels with gradient-based methods. We use discrete distributions given by\nlanguage models to define densities and develop an algorithm based on\nHamiltonian Monte Carlo to sample from them. We name our gradient-based\ntechnique Structured Voronoi Sampling (SVS). In an experimental setup where the\nreference distribution is known, we show that the empirical distribution of SVS\nsamples is closer to the reference distribution compared to alternative\nsampling schemes. Furthermore, in a controlled generation task, SVS is able to\ngenerate fluent and diverse samples while following the control targets\nsignificantly better than other methods.",
        "translated": "近年来，基于梯度的文本生成采样算法的研究越来越受到人们的关注，尤其是在控制生成的背景下。然而，这项工作缺乏理论基础和原则性的方法。在本文中，我们采取了一个重要的步骤，以建立一个原则性的方法从语言模型采样基于梯度的方法。我们使用语言模型给出的离散分布来定义密度，并开发一个基于 Hamiltonian Monte Carlo 的算法来取样。我们将基于梯度的技术命名为结构化 Voronoi 抽样(SVS)。在已知参考分布的实验装置中，我们发现 SVS 样本的经验分布比其他抽样方案更接近参考分布。此外，在控制生成任务中，SVS 能够生成流畅多样的样本，并且能够明显地更好地跟踪控制目标。"
    },
    {
        "title": "Analyzing Syntactic Generalization Capacity of Pre-trained Language\n  Models on Japanese Honorific Conversion",
        "url": "http://arxiv.org/abs/2306.03055v1",
        "pub_date": "2023-06-05",
        "summary": "Using Japanese honorifics is challenging because it requires not only\nknowledge of the grammatical rules but also contextual information, such as\nsocial relationships. It remains unclear whether pre-trained large language\nmodels (LLMs) can flexibly handle Japanese honorifics like humans. To analyze\nthis, we introduce an honorific conversion task that considers social\nrelationships among people mentioned in a conversation. We construct a Japanese\nhonorifics dataset from problem templates of various sentence structures to\ninvestigate the syntactic generalization capacity of GPT-3, one of the leading\nLLMs, on this task under two settings: fine-tuning and prompt learning. Our\nresults showed that the fine-tuned GPT-3 performed better in a context-aware\nhonorific conversion task than the prompt-based one. The fine-tuned model\ndemonstrated overall syntactic generalizability towards compound honorific\nsentences, except when tested with the data involving direct speech.",
        "translated": "使用敬称很有挑战性，因为它不仅需要语法规则的知识，还需要上下文信息，比如社会关系。目前还不清楚经过训练的大型语言模型(LLM)是否能像人类一样灵活地处理敬称。为了分析这一点，我们引入了一个敬语转换任务，考虑谈话中提到的人之间的社会关系。我们从不同句子结构的问题模板中构建了一个敬称数据集，在微调和及时学习两种设置下，研究了领先的语法模型之一 GPT-3的句法泛化能力。我们的研究结果表明，微调的 GPT-3在上下文感知的敬语转换任务中比基于提示的任务表现得更好。经过微调的模型显示了复合敬语句的整体句法泛化能力，除非使用直接引语的数据进行测试。"
    },
    {
        "title": "Benchmarking Large Language Models on CMExam -- A Comprehensive Chinese\n  Medical Exam Dataset",
        "url": "http://arxiv.org/abs/2306.03030v1",
        "pub_date": "2023-06-05",
        "summary": "Recent advancements in large language models (LLMs) have transformed the\nfield of question answering (QA). However, evaluating LLMs in the medical field\nis challenging due to the lack of standardized and comprehensive datasets. To\naddress this gap, we introduce CMExam, sourced from the Chinese National\nMedical Licensing Examination. CMExam consists of 60K+ multiple-choice\nquestions for standardized and objective evaluations, as well as solution\nexplanations for model reasoning evaluation in an open-ended manner. For\nin-depth analyses of LLMs, we invited medical professionals to label five\nadditional question-wise annotations, including disease groups, clinical\ndepartments, medical disciplines, areas of competency, and question difficulty\nlevels. Alongside the dataset, we further conducted thorough experiments with\nrepresentative LLMs and QA algorithms on CMExam. The results show that GPT-4\nhad the best accuracy of 61.5% and a weighted F1 score of 0.616. These results\nhighlight a great disparity when compared to human accuracy, which stood at\n71.6%. For explanation tasks, while LLMs could generate relevant reasoning and\ndemonstrate improved performance after finetuning, they fall short of a desired\nstandard, indicating ample room for improvement. To the best of our knowledge,\nCMExam is the first Chinese medical exam dataset to provide comprehensive\nmedical annotations. The experiments and findings of LLM evaluation also\nprovide valuable insights into the challenges and potential solutions in\ndeveloping Chinese medical QA systems and LLM evaluation pipelines. The dataset\nand relevant code are available at https://github.com/williamliujl/CMExam.",
        "translated": "大型语言模型(LLM)的最新进展已经改变了问答(QA)领域。然而，由于缺乏标准化和全面的数据集，评估 LLM 在医学领域是具有挑战性的。为了弥补这一差距，我们引入了来自中国国家医师执业资格考试的中国医师执业资格考试。CMExam 由60K + 多项选择题组成，用于标准化和客观的评估，以及开放式方式的模型推理评估的解决方案说明。对于 LLM 的深入分析，我们邀请医学专业人员标记另外五个明智的问题注释，包括疾病组，临床部门，医学学科，能力领域和问题难度水平。除了数据集，我们进一步在 CMExam 上进行了具有代表性的 LLM 和 QA 算法的全面实验。结果表明，GPT-4的最佳准确率为61.5% ，加权 F1得分为0.616。这些结果突出了一个巨大的差异，相比之下，人类的准确率为71.6% 。对于解释任务，虽然 LLM 可以生成相关的推理，并在微调后显示出改进的性能，但它们没有达到理想的标准，表明有足够的改进空间。据我们所知，中国医学考试是第一个提供全面医学注释的中国医学考试数据集。LLM 评价的实验和研究结果也为开发中国医疗质量保证体系和 LLM 评价管道提供了有价值的启示。数据集和相关代码可在 https://github.com/williamliujl/cmexam 查阅。"
    },
    {
        "title": "PokemonChat: Auditing ChatGPT for Pokémon Universe Knowledge",
        "url": "http://arxiv.org/abs/2306.03024v1",
        "pub_date": "2023-06-05",
        "summary": "The recently released ChatGPT model demonstrates unprecedented capabilities\nin zero-shot question-answering. In this work, we probe ChatGPT for its\nconversational understanding and introduce a conversational framework\n(protocol) that can be adopted in future studies. The Pok\\'emon universe serves\nas an ideal testing ground for auditing ChatGPT's reasoning capabilities due to\nits closed world assumption. After bringing ChatGPT's background knowledge (on\nthe Pok\\'emon universe) to light, we test its reasoning process when using\nthese concepts in battle scenarios. We then evaluate its ability to acquire new\nknowledge and include it in its reasoning process. Our ultimate goal is to\nassess ChatGPT's ability to generalize, combine features, and to acquire and\nreason over newly introduced knowledge from human feedback. We find that\nChatGPT has prior knowledge of the Pokemon universe, which can reason upon in\nbattle scenarios to a great extent, even when new information is introduced.\nThe model performs better with collaborative feedback and if there is an\ninitial phase of information retrieval, but also hallucinates occasionally and\nis susceptible to adversarial attacks.",
        "translated": "最近发布的 ChatGPT 模型展示了前所未有的零命中问题回答能力。在本文中，我们探讨了 ChatGPT 的会话理解，并介绍了一个可以在未来研究中采用的会话框架(协议)。由于其封闭的世界假设，宇宙上的 Pok’em 可以作为审核 ChatGPT 推理能力的理想试验场。在将 ChatGPT 的背景知识(关于宇宙中的 Pok’em)公之于众之后，我们在战斗场景中使用这些概念时测试它的推理过程。然后，我们评估它获取新知识的能力，并将其包括在推理过程中。我们的最终目标是评估 ChatGPT 的概括、结合特性的能力，以及从人类反馈中获取和推理新引入的知识的能力。我们发现 ChatGPT 拥有口袋妖怪世界的先验知识，即使在引入新信息的情况下，它也可以在很大程度上在战斗场景中进行推理。这种模式在协作反馈的情况下表现得更好，如果存在信息检索的初始阶段，但有时也会产生幻觉，容易受到敌对攻击。"
    },
    {
        "title": "On Manipulating Signals of User-Item Graph: A Jacobi Polynomial-based\n  Graph Collaborative Filtering",
        "url": "http://arxiv.org/abs/2306.03624v1",
        "pub_date": "2023-06-06",
        "summary": "Collaborative filtering (CF) is an important research direction in\nrecommender systems that aims to make recommendations given the information on\nuser-item interactions. Graph CF has attracted more and more attention in\nrecent years due to its effectiveness in leveraging high-order information in\nthe user-item bipartite graph for better recommendations. Specifically, recent\nstudies show the success of graph neural networks (GNN) for CF is attributed to\nits low-pass filtering effects. However, current researches lack a study of how\ndifferent signal components contributes to recommendations, and how to design\nstrategies to properly use them well. To this end, from the view of spectral\ntransformation, we analyze the important factors that a graph filter should\nconsider to achieve better performance. Based on the discoveries, we design\nJGCF, an efficient and effective method for CF based on Jacobi polynomial bases\nand frequency decomposition strategies. Extensive experiments on four widely\nused public datasets show the effectiveness and efficiency of the proposed\nmethods, which brings at most 27.06% performance gain on Alibaba-iFashion.\nBesides, the experimental results also show that JGCF is better at handling\nsparse datasets, which shows potential in making recommendations for cold-start\nusers.",
        "translated": "协同过滤(CF)是推荐系统的一个重要研究方向，其目的是根据用户项目交互的信息提供推荐。近年来，图形 CF 由于能够有效地利用用户项目二分图中的高阶信息来获得更好的建议而引起了越来越多的关注。具体来说，最近的研究表明，图神经网络(GNN)对 CF 的成功归功于其低通滤波效果。然而，目前的研究缺乏研究不同的信号成分如何有助于推荐，以及如何设计策略，以适当地使用它们。为此，本文从谱变换的角度出发，分析了图形滤波器要获得更好的性能所应考虑的重要因素。基于这些发现，我们设计了一种基于 Jacobi 多项式基和频率分解策略的高效率和有效的协同过滤方法。在四个广泛使用的公共数据集上进行了大量的实验，结果表明了该方法的有效性和高效性，在阿里巴巴-iFashion 平台上获得了最多27.06% 的性能提升。此外，实验结果还表明，JGCF 在处理稀疏数据集方面有较好的表现，可以为冷启动用户提供建议。"
    },
    {
        "title": "Rec4Ad: A Free Lunch to Mitigate Sample Selection Bias for Ads CTR\n  Prediction in Taobao",
        "url": "http://arxiv.org/abs/2306.03527v1",
        "pub_date": "2023-06-06",
        "summary": "Click-Through Rate (CTR) prediction serves as a fundamental component in\nonline advertising. A common practice is to train a CTR model on advertisement\n(ad) impressions with user feedback. Since ad impressions are purposely\nselected by the model itself, their distribution differs from the inference\ndistribution and thus exhibits sample selection bias (SSB) that affects model\nperformance. Existing studies on SSB mainly employ sample re-weighting\ntechniques which suffer from high variance and poor model calibration. Another\nline of work relies on costly uniform data that is inadequate to train\nindustrial models. Thus mitigating SSB in industrial models with a\nuniform-data-free framework is worth exploring. Fortunately, many platforms\ndisplay mixed results of organic items (i.e., recommendations) and sponsored\nitems (i.e., ads) to users, where impressions of ads and recommendations are\nselected by different systems but share the same user decision rationales.\nBased on the above characteristics, we propose to leverage recommendations\nsamples as a free lunch to mitigate SSB for ads CTR model (Rec4Ad). After\nelaborating data augmentation, Rec4Ad learns disentangled representations with\nalignment and decorrelation modules for enhancement. When deployed in Taobao\ndisplay advertising system, Rec4Ad achieves substantial gains in key business\nmetrics, with a lift of up to +6.6\\% CTR and +2.9\\% RPM.",
        "translated": "点进率预测是在线广告的一个基本组成部分。一个常见的做法是训练广告(广告)印象与用户反馈的点击率模型。由于广告印象是由模型本身有目的地选择的，它们的分布不同于推断分布，因此表现出影响模型性能的样本选择偏差(SSB)。现有的 SSB 研究主要采用样本重权重技术，存在方差大、模型校正差等问题。另一项工作依赖于昂贵的统一数据，这些数据不足以培训工业模型。因此，在无统一数据框架的工业模型中减少 SSB 是值得探索的。幸运的是，许多平台向用户显示有机项目(即推荐)和赞助项目(即广告)的混合结果，其中广告和推荐的印象由不同的系统选择，但共享相同的用户决策理由。基于上述特点，我们建议利用推荐样本作为免费午餐，以减轻 SSB 的广告点击率模型(Rec4Ad)。在详细阐述了数据增强之后，Rec4Ad 学习了利用对齐和去相关模块进行增强的解纠缠表示。在淘宝展示广告系统中部署 Rec4Ad 后，Rec4Ad 在关键业务指标上取得了实质性进展，点击率和转速分别提高了6.6% 和2.9% 。"
    },
    {
        "title": "COPR: Consistency-Oriented Pre-Ranking for Online Advertising",
        "url": "http://arxiv.org/abs/2306.03516v1",
        "pub_date": "2023-06-06",
        "summary": "Cascading architecture has been widely adopted in large-scale advertising\nsystems to balance efficiency and effectiveness. In this architecture, the\npre-ranking model is expected to be a lightweight approximation of the ranking\nmodel, which handles more candidates with strict latency requirements. Due to\nthe gap in model capacity, the pre-ranking and ranking models usually generate\ninconsistent ranked results, thus hurting the overall system effectiveness. The\nparadigm of score alignment is proposed to regularize their raw scores to be\nconsistent. However, it suffers from inevitable alignment errors and error\namplification by bids when applied in online advertising. To this end, we\nintroduce a consistency-oriented pre-ranking framework for online advertising,\nwhich employs a chunk-based sampling module and a plug-and-play rank alignment\nmodule to explicitly optimize consistency of ECPM-ranked results. A $\\Delta\nNDCG$-based weighting mechanism is adopted to better distinguish the importance\nof inter-chunk samples in optimization. Both online and offline experiments\nhave validated the superiority of our framework. When deployed in Taobao\ndisplay advertising system, it achieves an improvement of up to +12.3\\% CTR and\n+5.6\\% RPM.",
        "translated": "为了平衡效率和效果，级联体系结构在大规模广告系统中得到了广泛的应用。在这种体系结构中，预排序模型被期望是排序模型的轻量级近似，它处理具有严格延迟要求的更多候选者。由于模型容量的差距，预排序模型和排序模型通常会产生不一致的排序结果，从而影响系统的整体有效性。提出了分数对齐的范式，以规范他们的原始分数是一致的。然而，在网络广告中应用时，不可避免地会出现一致性错误和出价放大错误。为此，我们引入了一个面向一致性的在线广告预排序框架，该框架采用了基于块的抽样模块和即插即用的排序对齐模块来显式优化 ECPM 排序结果的一致性。为了更好地区分块间样本在优化中的重要性，采用了基于 $Delta NDCG 的加权机制。这两个在线和离线实验都验证了我们框架的优越性。在淘宝展示广告系统中，点击率和转速分别提高了12.3% 和5.6% 。"
    },
    {
        "title": "Generate-then-Retrieve: Intent-Aware FAQ Retrieval in Product Search",
        "url": "http://arxiv.org/abs/2306.03411v1",
        "pub_date": "2023-06-06",
        "summary": "Customers interacting with product search engines are increasingly\nformulating information-seeking queries. Frequently Asked Question (FAQ)\nretrieval aims to retrieve common question-answer pairs for a user query with\nquestion intent. Integrating FAQ retrieval in product search can not only\nempower users to make more informed purchase decisions, but also enhance user\nretention through efficient post-purchase support. Determining when an FAQ\nentry can satisfy a user's information need within product search, without\ndisrupting their shopping experience, represents an important challenge. We\npropose an intent-aware FAQ retrieval system consisting of (1) an intent\nclassifier that predicts when a user's information need can be answered by an\nFAQ; (2) a reformulation model that rewrites a query into a natural question.\nOffline evaluation demonstrates that our approach improves Hit@1 by 13% on\nretrieving ground-truth FAQs, while reducing latency by 95% compared to\nbaseline systems. These improvements are further validated by real user\nfeedback, where 71% of displayed FAQs on top of product search results received\nexplicit positive user feedback. Overall, our findings show promising\ndirections for integrating FAQ retrieval into product search at scale.",
        "translated": "与产品搜索引擎互动的客户越来越多地提出信息搜索查询。常见问题(FAQ)检索的目的是为具有问题意图的用户查询检索常见的问题-答案对。将常见问题检索整合到产品搜索中，不仅可以使用户做出更明智的购买决策，而且可以通过有效的购买后支持来提高用户保留率。在不影响用户购物体验的情况下，确定 FAQ 条目何时能够满足用户在产品搜索中的信息需求，是一个重要的挑战。我们提出了一个意图感知的 FAQ 检索系统，包括(1)意图分类器，预测何时用户的信息需求可以由 FAQ 回答; (2)重写模型，将查询重写成一个自然的问题。脱机评估表明，与基线系统相比，我们的方法在检索地面真相 FAQ 时将 Hit@1提高了13% ，同时减少了95% 的延迟。这些改进通过真实的用户反馈得到了进一步的验证，在产品搜索结果之上显示的 FAQ 中有71% 得到了明确的积极的用户反馈。总的来说，我们的研究结果为将 FAQ 检索整合到大规模的产品搜索中提供了有希望的方向。"
    },
    {
        "title": "Computational Technologies for Fashion Recommendation: A Survey",
        "url": "http://arxiv.org/abs/2306.03395v1",
        "pub_date": "2023-06-06",
        "summary": "Fashion recommendation is a key research field in computational fashion\nresearch and has attracted considerable interest in the computer vision,\nmultimedia, and information retrieval communities in recent years. Due to the\ngreat demand for applications, various fashion recommendation tasks, such as\npersonalized fashion product recommendation, complementary (mix-and-match)\nrecommendation, and outfit recommendation, have been posed and explored in the\nliterature. The continuing research attention and advances impel us to look\nback and in-depth into the field for a better understanding. In this paper, we\ncomprehensively review recent research efforts on fashion recommendation from a\ntechnological perspective. We first introduce fashion recommendation at a macro\nlevel and analyse its characteristics and differences with general\nrecommendation tasks. We then clearly categorize different fashion\nrecommendation efforts into several sub-tasks and focus on each sub-task in\nterms of its problem formulation, research focus, state-of-the-art methods, and\nlimitations. We also summarize the datasets proposed in the literature for use\nin fashion recommendation studies to give readers a brief illustration.\nFinally, we discuss several promising directions for future research in this\nfield. Overall, this survey systematically reviews the development of fashion\nrecommendation research. It also discusses the current limitations and gaps\nbetween academic research and the real needs of the fashion industry. In the\nprocess, we offer a deep insight into how the fashion industry could benefit\nfrom fashion recommendation technologies. the computational technologies of\nfashion recommendation.",
        "translated": "时尚推荐是计算时尚研究中的一个关键研究领域，近年来在计算机视觉、多媒体和信息检索社区引起了相当大的兴趣。由于应用需求的巨大，各种时尚推荐任务，如个性化的时尚产品推荐，补充(混搭)推荐，服装推荐，已提出和探讨的文献。持续的研究关注和进步促使我们回顾和深入到这一领域，以便更好地理解。本文从技术角度综述了近年来时尚推荐的研究成果。本文首先从宏观层面介绍了时尚推荐，并分析了它与一般推荐任务的特点和区别。然后，我们清楚地将不同的时尚推荐工作分为几个子任务，并根据其问题形成、研究重点、最先进的方法和局限性关注每个子任务。我们还总结了文献中提出的用于时尚推荐研究的数据集，以便给读者一个简要的说明。最后，我们讨论了这一领域未来研究的几个有希望的方向。总的来说，本调查系统地回顾了时尚推荐研究的发展。文章还讨论了当前学术研究与时尚产业实际需求之间的局限性和差距。在这个过程中，我们提供了一个深入的洞察时尚产业如何可以受益于时尚推荐技术。时尚推荐的计算技术。"
    },
    {
        "title": "CL-UZH at SemEval-2023 Task 10: Sexism Detection through Incremental\n  Fine-Tuning and Multi-Task Learning with Label Descriptions",
        "url": "http://arxiv.org/abs/2306.03907v1",
        "pub_date": "2023-06-06",
        "summary": "The widespread popularity of social media has led to an increase in hateful,\nabusive, and sexist language, motivating methods for the automatic detection of\nsuch phenomena. The goal of the SemEval shared task \\textit{Towards Explainable\nDetection of Online Sexism} (EDOS 2023) is to detect sexism in English social\nmedia posts (subtask A), and to categorize such posts into four coarse-grained\nsexism categories (subtask B), and eleven fine-grained subcategories (subtask\nC). In this paper, we present our submitted systems for all three subtasks,\nbased on a multi-task model that has been fine-tuned on a range of related\ntasks and datasets before being fine-tuned on the specific EDOS subtasks. We\nimplement multi-task learning by formulating each task as binary pairwise text\nclassification, where the dataset and label descriptions are given along with\nthe input text. The results show clear improvements over a fine-tuned\nDeBERTa-V3 serving as a baseline leading to $F_1$-scores of 85.9\\% in subtask A\n(rank 13/84), 64.8\\% in subtask B (rank 19/69), and 44.9\\% in subtask C\n(26/63).",
        "translated": "社交媒体的广泛流行导致了仇恨、辱骂和性别歧视语言的增加，激发了自动检测此类现象的方法。SemEval 共享任务的目标是检测英语社交媒体帖子中的性别歧视(子任务 A) ，并将这些帖子分为四个粗粒度的性别歧视类别(子任务 B)和十一个细粒度的子类别(子任务 C)。在本文中，我们提出了针对所有三个子任务的提交系统，该系统基于一个多任务模型，在针对特定的 EDOS 子任务进行微调之前，该模型已经在一系列相关任务和数据集上进行了微调。我们通过将每个任务表示为二进制成对文本分类来实现多任务学习，其中数据集和标签描述与输入文本一起给出。结果显示，与作为基线的微调 DeBERTa-V3相比，明显改善，子任务 A (排名13/84)的分数为85.9% ，子任务 B (排名19/69)为64.8% ，子任务 C 为44.9% (26/63)。"
    },
    {
        "title": "Utterance Classification with Logical Neural Network: Explainable AI for\n  Mental Disorder Diagnosis",
        "url": "http://arxiv.org/abs/2306.03902v1",
        "pub_date": "2023-06-06",
        "summary": "In response to the global challenge of mental health problems, we proposes a\nLogical Neural Network (LNN) based Neuro-Symbolic AI method for the diagnosis\nof mental disorders. Due to the lack of effective therapy coverage for mental\ndisorders, there is a need for an AI solution that can assist therapists with\nthe diagnosis. However, current Neural Network models lack explainability and\nmay not be trusted by therapists. The LNN is a Recurrent Neural Network\narchitecture that combines the learning capabilities of neural networks with\nthe reasoning capabilities of classical logic-based AI. The proposed system\nuses input predicates from clinical interviews to output a mental disorder\nclass, and different predicate pruning techniques are used to achieve\nscalability and higher scores. In addition, we provide an insight extraction\nmethod to aid therapists with their diagnosis. The proposed system addresses\nthe lack of explainability of current Neural Network models and provides a more\ntrustworthy solution for mental disorder diagnosis.",
        "translated": "针对心理健康问题的全球性挑战，我们提出了一种基于逻辑神经网络(LNN)的神经符号人工智能方法来诊断精神障碍。由于缺乏有效的治疗覆盖面的精神障碍，有一个人工智能解决方案的需要，可以帮助治疗师的诊断。然而，目前的神经网络模型缺乏可解释性，可能不被治疗师信任。神经网络是一种递归神经网络结构，它结合了神经网络的学习能力和经典的基于逻辑的人工智能的推理能力。该系统使用临床访谈中的输入谓词输出一个精神障碍类，并使用不同的谓词修剪技术来实现可扩展性和更高的分数。此外，我们提供了一个洞察力提取方法，以帮助治疗师与他们的诊断。该系统解决了目前神经网络模型的不可解释性问题，为精神疾病的诊断提供了一个更可靠的解决方案。"
    },
    {
        "title": "ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory",
        "url": "http://arxiv.org/abs/2306.03901v2",
        "pub_date": "2023-06-06",
        "summary": "Large language models (LLMs) with memory are computationally universal.\nHowever, mainstream LLMs are not taking full advantage of memory, and the\ndesigns are heavily influenced by biological brains. Due to their approximate\nnature and proneness to the accumulation of errors, conventional neural memory\nmechanisms cannot support LLMs to simulate complex reasoning. In this paper, we\nseek inspiration from modern computer architectures to augment LLMs with\nsymbolic memory for complex multi-hop reasoning. Such a symbolic memory\nframework is instantiated as an LLM and a set of SQL databases, where the LLM\ngenerates SQL instructions to manipulate the SQL databases. We validate the\neffectiveness of the proposed memory framework on a synthetic dataset requiring\ncomplex reasoning. The project website is available at\nhttps://chatdatabase.github.io/ .",
        "translated": "具有内存的大型语言模型(LLM)在计算上是通用的。然而，主流 LLM 并没有充分利用记忆的优势，而且设计受到生物大脑的严重影响。传统的神经记忆机制由于其近似特性和容易累积错误，不能支持 LLM 模拟复杂的推理过程。本文从现代计算机体系结构中寻找启示，用符号存储器增强复杂多跳推理的 LLM。这样的符号内存框架实例化为一个 LLM 和一组 SQL 数据库，LLM 在其中生成 SQL 指令来操作 SQL 数据库。在需要复杂推理的合成数据集上，验证了所提出的记忆框架的有效性。有关计划的网页可于 https://chatdatabase.github.io/下载。"
    },
    {
        "title": "Causal interventions expose implicit situation models for commonsense\n  language understanding",
        "url": "http://arxiv.org/abs/2306.03882v2",
        "pub_date": "2023-06-06",
        "summary": "Accounts of human language processing have long appealed to implicit\n``situation models'' that enrich comprehension with relevant but unstated world\nknowledge. Here, we apply causal intervention techniques to recent transformer\nmodels to analyze performance on the Winograd Schema Challenge (WSC), where a\nsingle context cue shifts interpretation of an ambiguous pronoun. We identify a\nrelatively small circuit of attention heads that are responsible for\npropagating information from the context word that guides which of the\ncandidate noun phrases the pronoun ultimately attends to. We then compare how\nthis circuit behaves in a closely matched ``syntactic'' control where the\nsituation model is not strictly necessary. These analyses suggest distinct\npathways through which implicit situation models are constructed to guide\npronoun resolution.",
        "translated": "长期以来，人类语言处理的描述一直呼吁隐含的“情境模型”，用相关但未陈述的世界知识丰富理解。在这里，我们将因果干预技术应用到最近的转换器模型中，以分析 Winograd 模式挑战(WSC)的表现，其中一个单一的上下文提示转移了对一个模棱两可的代词的解释。我们识别出一个相对较小的注意力回路，它负责从上下文词中传播信息，指导代词最终注意哪个候选名词短语。然后我们比较这个电路在一个紧密匹配的“语法”控制中的表现，在这个控制中情境模型并不是严格必要的。这些分析揭示了指导代词消解的内隐情境模型构建的不同途径。"
    },
    {
        "title": "Deductive Verification of Chain-of-Thought Reasoning",
        "url": "http://arxiv.org/abs/2306.03872v2",
        "pub_date": "2023-06-06",
        "summary": "Large Language Models (LLMs) significantly benefit from Chain-of-Thought\n(CoT) prompting in performing various reasoning tasks. While CoT allows models\nto produce more comprehensive reasoning processes, its emphasis on intermediate\nreasoning steps can inadvertently introduce hallucinations and accumulated\nerrors, thereby limiting models' ability to solve complex reasoning tasks.\nInspired by how humans engage in careful and meticulous deductive logical\nreasoning processes to solve tasks, we seek to enable language models to\nperform explicit and rigorous deductive reasoning, and also ensure the\ntrustworthiness of their reasoning process through self-verification. However,\ndirectly verifying the validity of an entire deductive reasoning process is\nchallenging, even with advanced models like ChatGPT. In light of this, we\npropose to decompose a reasoning verification process into a series of\nstep-by-step subprocesses, each only receiving their necessary context and\npremises. To facilitate this procedure, we propose Natural Program, a natural\nlanguage-based deductive reasoning format. Our approach enables models to\ngenerate precise reasoning steps where subsequent steps are more rigorously\ngrounded on prior steps. It also empowers language models to carry out\nreasoning self-verification in a step-by-step manner. By integrating this\nverification process into each deductive reasoning stage, we significantly\nenhance the rigor and trustfulness of generated reasoning steps. Along this\nprocess, we also improve the answer correctness on complex reasoning tasks.\nCode will be released at https://github.com/lz1oceani/verify_cot.",
        "translated": "大型语言模型(LLM)在执行各种推理任务时显著受益于思维链(CoT)的提示。虽然 CoT 允许模型产生更全面的推理过程，但它对中间推理步骤的强调可能无意中引入幻觉和累积错误，从而限制模型解决复杂推理任务的能力。我们受到人类如何小心谨慎地进行演绎逻辑推理过程来解决任务的启发，我们试图使语言模型能够执行明确而严格的演绎推理，并通过自我验证来确保其推理过程的可信度。然而，即使使用像 chatgPT 这样的高级模型，直接验证整个演绎推理过程的有效性也是具有挑战性的。鉴于此，我们建议将推理验证过程分解为一系列逐步的子过程，每个子过程只接收其必要的上下文和前提。为了方便这个过程，我们提出了自然程序，一种基于自然语言的演绎推理格式。我们的方法使模型能够产生精确的推理步骤，其中后续步骤更严格地基于先前的步骤。它还使语言模型能够按部就班地进行推理自我验证。通过将这个验证过程整合到每个演绎推理阶段，我们大大提高了生成推理步骤的严谨性和可信度。在这个过程中，我们还提高了复杂推理任务的正确答案。密码将在 https://github.com/lz1oceani/verify_cot 公布。"
    },
    {
        "title": "Correction of Errors in Preference Ratings from Automated Metrics for\n  Text Generation",
        "url": "http://arxiv.org/abs/2306.03866v1",
        "pub_date": "2023-06-06",
        "summary": "A major challenge in the field of Text Generation is evaluation: Human\nevaluations are cost-intensive, and automated metrics often display\nconsiderable disagreement with human judgments. In this paper, we propose a\nstatistical model of Text Generation evaluation that accounts for the\nerror-proneness of automated metrics when used to generate preference rankings\nbetween system outputs. We show that existing automated metrics are generally\nover-confident in assigning significant differences between systems in this\nsetting. However, our model enables an efficient combination of human and\nautomated ratings to remedy the error-proneness of the automated metrics. We\nshow that using this combination, we only require about 50% of the human\nannotations typically used in evaluations to arrive at robust and statistically\nsignificant results while yielding the same evaluation outcome as the pure\nhuman evaluation in 95% of cases. We showcase the benefits of approach for\nthree text generation tasks: dialogue systems, machine translation, and text\nsummarization.",
        "translated": "文本生成领域的一个主要挑战是评价: 人的评价是成本密集型的，自动化度量往往显示出与人的判断相当大的分歧。本文提出了一种文本生成评价的统计模型，该模型考虑了自动化度量在生成系统输出之间的偏好排序时的错误倾向性。我们表明，现有的自动化度量通常过于自信，以至于在这种设置中分配系统之间的显著差异。然而，我们的模型能够有效地结合人工评分和自动评分来纠正自动度量的错误倾向性。我们表明，使用这种组合，我们只需要通常用于评估的约50% 的人工注释来达到稳健和统计学显着的结果，同时在95% 的情况下产生与纯人类评估相同的评估结果。我们展示了这种方法在三个文本生成任务中的优点: 对话系统、机器翻译和文本摘要。"
    },
    {
        "title": "Iterative Translation Refinement with Large Language Models",
        "url": "http://arxiv.org/abs/2306.03856v1",
        "pub_date": "2023-06-06",
        "summary": "Large language models have shown surprising performances in understanding\ninstructions and performing natural language tasks. In this paper, we propose\niterative translation refinement to leverage the power of large language models\nfor more natural translation and post-editing. We show that by simply involving\na large language model in an iterative process, the output quality improves\nbeyond mere translation. Extensive test scenarios with GPT-3.5 reveal that\nalthough iterations reduce string-based metric scores, neural metrics indicate\ncomparable if not improved translation quality. Further, human evaluations\ndemonstrate that our method effectively reduces translationese compared to\ninitial GPT translations and even human references, especially for into-English\ndirections. Ablation studies underscore the importance of anchoring the\nrefinement process to the source input and a reasonable initial translation.",
        "translated": "大型语言模型在理解指令和执行自然语言任务方面表现出惊人的表现。在本文中，我们提出了迭代翻译细化，以利用大型语言模型的力量，更自然的翻译和后期编辑。我们表明，通过简单地在迭代过程中涉及一个大的语言模型，输出质量提高超过单纯的翻译。使用 GPT-3.5的大量测试场景显示，尽管迭代减少了基于字符串的度量得分，但神经度量表明，即使没有提高翻译质量，也可以进行比较。此外，人工评估表明，我们的方法有效地减少翻译相比，最初的 GPT 翻译，甚至人工参考，特别是进入英语方向。消融研究强调了将细化过程锚定在源输入和合理的初始翻译上的重要性。"
    },
    {
        "title": "From Key Points to Key Point Hierarchy: Structured and Expressive\n  Opinion Summarization",
        "url": "http://arxiv.org/abs/2306.03853v1",
        "pub_date": "2023-06-06",
        "summary": "Key Point Analysis (KPA) has been recently proposed for deriving fine-grained\ninsights from collections of textual comments. KPA extracts the main points in\nthe data as a list of concise sentences or phrases, termed key points, and\nquantifies their prevalence. While key points are more expressive than word\nclouds and key phrases, making sense of a long, flat list of key points, which\noften express related ideas in varying levels of granularity, may still be\nchallenging. To address this limitation of KPA, we introduce the task of\norganizing a given set of key points into a hierarchy, according to their\nspecificity. Such hierarchies may be viewed as a novel type of Textual\nEntailment Graph. We develop ThinkP, a high quality benchmark dataset of key\npoint hierarchies for business and product reviews, obtained by consolidating\nmultiple annotations. We compare different methods for predicting pairwise\nrelations between key points, and for inferring a hierarchy from these pairwise\npredictions. In particular, for the task of computing pairwise key point\nrelations, we achieve significant gains over existing strong baselines by\napplying directional distributional similarity methods to a novel\ndistributional representation of key points, and further boost performance via\nweak supervision.",
        "translated": "关键点分析(Key Point Analysis，KPA)最近被提议用于从文本注释集合中获得细粒度的见解。KPA 从数据中提取主要观点作为一个简洁的句子或短语列表，称为关键点，并量化其普遍性。虽然关键点比单词云和关键短语更能表达思想，但是要理解一个长长的、扁平的关键点列表可能仍然是一个挑战，因为这些关键点通常表达的是不同粒度级别的相关思想。为了解决 KPA 的这个局限性，我们引入了这样一个任务: 根据关键点的特殊性，将一组给定的关键点组织成一个层次结构。这种等级制度可以被视为一种新型的文字蕴涵图。我们开发 ThinkP，它是一个高质量的基准数据集，通过整合多个注释获得，用于业务和产品评论的关键点层次结构。我们比较了预测关键点之间成对关系的不同方法，以及从这些成对预测中推断层次结构的不同方法。特别是对于计算成对关键点关系的任务，我们通过将方向分布相似性方法应用于一种新的关键点分布表示，在现有的强基线上取得了显著的效果，并且通过弱监督进一步提高了性能。"
    },
    {
        "title": "LEACE: Perfect linear concept erasure in closed form",
        "url": "http://arxiv.org/abs/2306.03819v1",
        "pub_date": "2023-06-06",
        "summary": "Concept erasure aims to remove specified features from a representation. It\ncan be used to improve fairness (e.g. preventing a classifier from using gender\nor race) and interpretability (e.g. removing a concept to observe changes in\nmodel behavior). In this paper, we introduce LEAst-squares Concept Erasure\n(LEACE), a closed-form method which provably prevents all linear classifiers\nfrom detecting a concept while inflicting the least possible damage to the\nrepresentation. We apply LEACE to large language models with a novel procedure\ncalled \"concept scrubbing,\" which erases target concept information from every\nlayer in the network. We demonstrate the usefulness of our method on two tasks:\nmeasuring the reliance of language models on part-of-speech information, and\nreducing gender bias in BERT embeddings. Code is available at\nhttps://github.com/EleutherAI/concept-erasure.",
        "translated": "概念擦除的目的是从表示中去除特定的特征。它可以用来提高公平性(例如防止分类器使用性别或种族)和可解释性(例如移除观察模型行为变化的概念)。本文介绍了最小二乘概念擦除(LEACE)方法，这是一种可证明的闭式方法，它可以防止所有的线性分类器检测到一个概念，同时对表示造成最小可能的损害。我们将 LEACE 应用到大型语言模型中，使用了一种称为“概念擦除”的新方法，这种方法可以从网络的每一层删除目标概念信息。我们证明了我们的方法在两个任务上的有用性: 测量语言模型对词性信息的依赖性，以及减少 BERT 嵌入中的性别偏见。密码可于 https://github.com/eleutherai/concept-erasure 索取。"
    },
    {
        "title": "Prompt Space Optimizing Few-shot Reasoning Success with Large Language\n  Models",
        "url": "http://arxiv.org/abs/2306.03799v1",
        "pub_date": "2023-06-06",
        "summary": "Prompt engineering is an essential technique for enhancing the abilities of\nlarge language models (LLMs) by providing explicit and specific instructions.\nIt enables LLMs to excel in various tasks, such as arithmetic reasoning,\nquestion answering, summarization, relation extraction, machine translation,\nand sentiment analysis. Researchers have been actively exploring different\nprompt engineering strategies, such as Chain of Thought (CoT), Zero-CoT, and\nIn-context learning. However, an unresolved problem arises from the fact that\ncurrent approaches lack a solid theoretical foundation for determining optimal\nprompts. To address this issue in prompt engineering, we propose a new and\neffective approach called Prompt Space. Our methodology utilizes text\nembeddings to obtain basis vectors by matrix decomposition, and then constructs\na space for representing all prompts. Prompt Space significantly outperforms\nstate-of-the-art prompt paradigms on ten public reasoning benchmarks. Notably,\nwithout the help of the CoT method and the prompt \"Let's think step by step\",\nPrompt Space shows superior performance over the few-shot method. Overall, our\napproach provides a robust and fundamental theoretical framework for selecting\nsimple and effective prompts. This advancement marks a significant step towards\nimproving prompt engineering for a wide variety of applications in LLMs.",
        "translated": "提示工程是通过提供明确和具体的指令来提高大型语言模型(LLM)能力的一种基本技术。它使 LLM 能够胜任各种任务，例如算术推理、问题回答、总结、关系提取、机器翻译和情感分析。研究人员一直在积极探索不同的快速工程策略，如思维链(CoT) ，零 CoT 和在上下文中学习。然而，一个未解决的问题出现在这样一个事实上，即目前的方法缺乏确定最佳提示的坚实的理论基础。为了在快速工程中解决这个问题，我们提出了一种新的和有效的方法称为快速空间。我们的方法利用文本嵌入通过矩阵分解获得基向量，然后构造一个空间来表示所有的提示。Prompt Space 在10个公共推理基准上明显优于最先进的提示范例。值得注意的是，没有 CoT 方法和提示“让我们一步一步地思考”的帮助，Prompt Space 显示出优于少数镜头方法的性能。总的来说，我们的方法为选择简单有效的提示提供了一个强大的基础理论框架。这一进展标志着在改进 LLM 中各种应用的快速工程方面迈出了重要的一步。"
    },
    {
        "title": "MarineVRS: Marine Video Retrieval System with Explainability via\n  Semantic Understanding",
        "url": "http://arxiv.org/abs/2306.04593v1",
        "pub_date": "2023-06-07",
        "summary": "Building a video retrieval system that is robust and reliable, especially for\nthe marine environment, is a challenging task due to several factors such as\ndealing with massive amounts of dense and repetitive data, occlusion,\nblurriness, low lighting conditions, and abstract queries. To address these\nchallenges, we present MarineVRS, a novel and flexible video retrieval system\ndesigned explicitly for the marine domain. MarineVRS integrates\nstate-of-the-art methods for visual and linguistic object representation to\nenable efficient and accurate search and analysis of vast volumes of underwater\nvideo data. In addition, unlike the conventional video retrieval system, which\nonly permits users to index a collection of images or videos and search using a\nfree-form natural language sentence, our retrieval system includes an\nadditional Explainability module that outputs the segmentation masks of the\nobjects that the input query referred to. This feature allows users to identify\nand isolate specific objects in the video footage, leading to more detailed\nanalysis and understanding of their behavior and movements. Finally, with its\nadaptability, explainability, accuracy, and scalability, MarineVRS is a\npowerful tool for marine researchers and scientists to efficiently and\naccurately process vast amounts of data and gain deeper insights into the\nbehavior and movements of marine species.",
        "translated": "建立一个健壮可靠的视频检索系统，特别是对于海洋环境来说，是一个具有挑战性的任务，因为有几个因素，如处理大量密集和重复的数据，遮挡，模糊，低照明条件和抽象查询。为了应对这些挑战，我们提出了 MarineVRS，一个新颖的和灵活的视频检索系统，明确地为海洋领域设计。MarineVRS 集成了最先进的视觉和语言对象表示方法，能够高效、准确地搜索和分析海量水下视频数据。此外，与传统的视频检索系统不同，传统的视频检索系统只允许用户索引一组图像或视频并使用自由格式的自然语言句子进行搜索，我们的检索系统包括一个额外的可解释性模块，该模块输出输入查询引用的对象的分割掩码。这个功能允许用户识别和隔离视频画面中的特定物体，从而对它们的行为和动作进行更详细的分析和理解。最后，凭借其适应性、可解释性、准确性和可扩展性，MarineVRS 是海洋研究人员和科学家有效和准确地处理大量数据并获得对海洋物种行为和运动的更深刻见解的强大工具。"
    },
    {
        "title": "Constraint-based recommender system for crisis management simulations",
        "url": "http://arxiv.org/abs/2306.04553v1",
        "pub_date": "2023-06-07",
        "summary": "In the context of the evacuation of populations, some citizens/volunteers may\nwant and be able to participate in the evacuation of populations in difficulty\nby coming to lend a hand to emergency/evacuation vehicles with their own\nvehicles. One way of framing these impulses of solidarity would be to be able\nto list in real-time the citizens/volunteers available with their vehicles\n(land, sea, air, etc.), to be able to geolocate them according to the risk\nareas to be evacuated, and adding them to the evacuation/rescue vehicles.\nBecause it is difficult to propose an effective real-time operational system on\nthe field in a real crisis situation, in this work, we propose to add a module\nfor recommending driver/vehicle pairs (with their specificities) to a system of\ncrisis management simulation. To do that, we chose to model and develop an\nontology-supported constraint-based recommender system for crisis management\nsimulations.",
        "translated": "在疏散人口方面，一些公民/志愿人员可能希望并能够参与疏散有困难的人口，他们可以用自己的车辆向紧急/疏散车辆伸出援手。构建这些团结冲动的一种方式是能够实时列出可用车辆(陆地、海洋、空中等)的公民/志愿者，能够根据疏散的危险区域对他们进行地理定位，并将他们添加到疏散/救援车辆中。由于在真实的危机情况下很难提出一个有效的现场实时操作系统，本文提出在危机管理模拟系统中增加一个推荐驾驶员/车辆配对(及其特殊性)的模块。为此，我们选择建模和开发一个本体支持的基于约束的危机管理模拟推荐系统。"
    },
    {
        "title": "Embracing Uncertainty: Adaptive Vague Preference Policy Learning for\n  Multi-round Conversational Recommendation",
        "url": "http://arxiv.org/abs/2306.04487v1",
        "pub_date": "2023-06-07",
        "summary": "Conversational recommendation systems (CRS) effectively address information\nasymmetry by dynamically eliciting user preferences through multi-turn\ninteractions. Existing CRS widely assumes that users have clear preferences.\nUnder this assumption, the agent will completely trust the user feedback and\ntreat the accepted or rejected signals as strong indicators to filter items and\nreduce the candidate space, which may lead to the problem of over-filtering.\nHowever, in reality, users' preferences are often vague and volatile, with\nuncertainty about their desires and changing decisions during interactions.\n  To address this issue, we introduce a novel scenario called Vague Preference\nMulti-round Conversational Recommendation (VPMCR), which considers users' vague\nand volatile preferences in CRS.VPMCR employs a soft estimation mechanism to\nassign a non-zero confidence score for all candidate items to be displayed,\nnaturally avoiding the over-filtering problem. In the VPMCR setting, we\nintroduce an solution called Adaptive Vague Preference Policy Learning (AVPPL),\nwhich consists of two main components: Uncertainty-aware Soft Estimation (USE)\nand Uncertainty-aware Policy Learning (UPL). USE estimates the uncertainty of\nusers' vague feedback and captures their dynamic preferences using a\nchoice-based preferences extraction module and a time-aware decaying strategy.\nUPL leverages the preference distribution estimated by USE to guide the\nconversation and adapt to changes in users' preferences to make recommendations\nor ask for attributes.\n  Our extensive experiments demonstrate the effectiveness of our method in the\nVPMCR scenario, highlighting its potential for practical applications and\nimproving the overall performance and applicability of CRS in real-world\nsettings, particularly for users with vague or dynamic preferences.",
        "translated": "会话推荐系统(CRS)通过多回合交互动态引出用户偏好，从而有效地解决信息不对称问题。现有的 CRS 普遍假设用户有明确的偏好。在这种假设下，代理完全信任用户的反馈，将接受或拒绝的信号作为强指标来过滤项目，减少候选空间，从而可能导致过滤问题。然而，在现实中，用户的偏好往往是模糊和不稳定的，他们的愿望和交互过程中改变决定的不确定性。为了解决这一问题，我们引入了一种新的场景——模糊偏好多轮会话推荐(VPMCR) ，该场景考虑了 CRS 中用户的模糊和不稳定偏好。 VPMCR 采用了一种软估计机制，为所有待显示的候选项赋予一个非零置信度分数，自然避免了过滤问题。在 VPCR 设置中，我们引入了一个称为自适应模糊偏好策略学习(AdaptiveVague Preferences Policy Learning，AVPPL)的解决方案，该解决方案由两个主要组件组成: 不确定感知软估计(UUSE)和不确定感知策略学习(UPL)。USE 利用基于选择的偏好提取模块和时间感知衰减策略估计用户模糊反馈的不确定性，并获取用户的动态偏好。UPL 利用 USE 估计的偏好分布来引导对话，并适应用户偏好的变化来提出建议或请求属性。我们的广泛实验证明了我们的方法在 VPCR 场景中的有效性，突出了其实际应用的潜力，并提高了 CRS 在现实世界环境中的总体性能和适用性，特别是对于具有模糊或动态偏好的用户。"
    },
    {
        "title": "RD-Suite: A Benchmark for Ranking Distillation",
        "url": "http://arxiv.org/abs/2306.04455v1",
        "pub_date": "2023-06-07",
        "summary": "The distillation of ranking models has become an important topic in both\nacademia and industry. In recent years, several advanced methods have been\nproposed to tackle this problem, often leveraging ranking information from\nteacher rankers that is absent in traditional classification settings. To date,\nthere is no well-established consensus on how to evaluate this class of models.\nMoreover, inconsistent benchmarking on a wide range of tasks and datasets make\nit difficult to assess or invigorate advances in this field. This paper first\nexamines representative prior arts on ranking distillation, and raises three\nquestions to be answered around methodology and reproducibility. To that end,\nwe propose a systematic and unified benchmark, Ranking Distillation Suite\n(RD-Suite), which is a suite of tasks with 4 large real-world datasets,\nencompassing two major modalities (textual and numeric) and two applications\n(standard distillation and distillation transfer). RD-Suite consists of\nbenchmark results that challenge some of the common wisdom in the field, and\nthe release of datasets with teacher scores and evaluation scripts for future\nresearch. RD-Suite paves the way towards better understanding of ranking\ndistillation, facilities more research in this direction, and presents new\nchallenges.",
        "translated": "排序模型的提取已经成为学术界和工业界的一个重要课题。近年来，一些先进的方法被提出来解决这个问题，往往利用排名信息从教师排名，这是缺乏在传统的分类设置。到目前为止，对于如何评估这类模型还没有确定的共识。此外，对广泛的任务和数据集不一致的基准设定使得难以评估或激励这一领域的进展。本文首先考察了有代表性的等级精馏现有技术，并围绕方法论和可重复性提出了三个需要回答的问题。为此，我们提出了一个系统和统一的基准，秩序蒸馏套件(RD-Suite) ，这是一套任务与4个大型真实世界数据集，包括两个主要模式(文本和数字)和两个应用程序(标准蒸馏和蒸馏转移)。RD-Suite 包括挑战该领域常识的基准测试结果，以及发布包含教师成绩和未来研究评估脚本的数据集。RD-Suite 为更好地理解分级蒸馏铺平了道路，设备在这个方向上进行了更多的研究，并提出了新的挑战。"
    },
    {
        "title": "Modeling Dual Period-Varying Preferences for Takeaway Recommendation",
        "url": "http://arxiv.org/abs/2306.04370v1",
        "pub_date": "2023-06-07",
        "summary": "Takeaway recommender systems, which aim to accurately provide stores that\noffer foods meeting users' interests, have served billions of users in our\ndaily life. Different from traditional recommendation, takeaway recommendation\nfaces two main challenges: (1) Dual Interaction-Aware Preference Modeling.\nTraditional recommendation commonly focuses on users' single preferences for\nitems while takeaway recommendation needs to comprehensively consider users'\ndual preferences for stores and foods. (2) Period-Varying Preference Modeling.\nConventional recommendation generally models continuous changes in users'\npreferences from a session-level or day-level perspective. However, in\npractical takeaway systems, users' preferences vary significantly during the\nmorning, noon, night, and late night periods of the day. To address these\nchallenges, we propose a Dual Period-Varying Preference modeling (DPVP) for\ntakeaway recommendation. Specifically, we design a dual interaction-aware\nmodule, aiming to capture users' dual preferences based on their interactions\nwith stores and foods. Moreover, to model various preferences in different time\nperiods of the day, we propose a time-based decomposition module as well as a\ntime-aware gating mechanism. Extensive offline and online experiments\ndemonstrate that our model outperforms state-of-the-art methods on real-world\ndatasets and it is capable of modeling the dual period-varying preferences.\nMoreover, our model has been deployed online on Meituan Takeaway platform,\nleading to an average improvement in GMV (Gross Merchandise Value) of 0.70%.",
        "translated": "外卖推荐系统，旨在准确地提供商店，提供符合用户兴趣的食品，已服务于数十亿用户在我们的日常生活。与传统的推荐不同，外卖推荐面临着两个主要挑战: (1)双交互感知偏好建模。传统的推荐方式通常侧重于用户对商品的单一偏好，而外卖推荐方式则需要全面考虑用户对商店和食品的双重偏好。(变周期偏好模型。传统的推荐通常从会话级或日级的角度模拟用户偏好的持续变化。然而，在实际的外卖系统中，用户的偏好在白天的早上、中午、晚上和深夜各不相同。为了应对这些挑战，我们提出了一个外卖推荐的双周期变化偏好模型(DPVP)。具体来说，我们设计了一个双交互感知模块，旨在根据用户与商店和食物的交互来捕捉他们的双重偏好。此外，为了模拟一天中不同时段的各种偏好，我们提出了一个基于时间的分解模块以及一个时间感知的门控机制。大量的离线和在线实验表明，我们的模型优于现实世界数据集的最先进的方法，它能够建模的双周期变化的偏好。此外，我们的模型已经在美团外卖平台上进行了在线部署，导致平均商品总值(GMV)提高了0.70% 。"
    },
    {
        "title": "ModuleFormer: Learning Modular Large Language Models From Uncurated Data",
        "url": "http://arxiv.org/abs/2306.04640v1",
        "pub_date": "2023-06-07",
        "summary": "Large Language Models (LLMs) have achieved remarkable results. But existing\nmodels are expensive to train and deploy, and it is also difficult to expand\ntheir knowledge beyond pre-training data without forgetting previous knowledge.\nThis paper proposes a new neural network architecture, ModuleFormer, that\nleverages modularity to improve the efficiency and flexibility of large\nlanguage models. ModuleFormer is based on the Sparse Mixture of Experts (SMoE).\nUnlike the previous SMoE-based modular language model [Gururangan et al.,\n2021], which requires domain-labeled data to learn domain-specific experts,\nModuleFormer can induce modularity from uncurated data with its new load\nbalancing and load concentration losses. ModuleFormer is a modular architecture\nthat includes two different types of modules, new stick-breaking attention\nheads, and feedforward experts. Different modules are sparsely activated\nconditions on the input token during training and inference. In our experiment,\nwe found that the modular architecture enables three important abilities for\nlarge pre-trained language models: 1) Efficiency, since ModuleFormer only\nactivates a subset of its modules for each input token, thus it could achieve\nthe same performance as dense LLMs with more than two times throughput; 2)\nExtendability, ModuleFormer is more immune to catastrophic forgetting than\ndense LLMs and can be easily extended with new modules to learn new knowledge\nthat is not included in the training data; 3) Specialisation, finetuning\nModuleFormer could specialize a subset of modules to the finetuning task, and\nthe task-unrelated modules could be easily pruned for a lightweight deployment.",
        "translated": "大语言模型(LLM)已经取得了显著的成果。但现有模型的培训和部署成本很高，而且很难在不忘记先前知识的情况下扩展其知识范围，超出培训前的数据。本文提出了一种新的神经网络结构——模块化网络结构，该结构利用模块化来提高大型语言模型的效率和灵活性。基于稀疏混合专家算法(SMoE)的模块形成器。与以前基于 SMoE 的模块化语言模型[ Gururangan et al。 ，2021]不同，其需要领域标记的数据来学习领域特定的专家，ModuleForm 可以通过其新的负载平衡和负载集中损失来诱导未经策划的数据的模块化。ModuleForm 是一个模块化架构，包括两种不同类型的模块、新的分散注意力的头部和前馈专家。在训练和推理过程中，不同的模块在输入令牌上是稀疏激活的条件。在我们的实验中，我们发现模块化架构为大型预先训练的语言模型提供了三个重要的能力: 1)效率，因为模块化程序只为每个输入令牌激活其模块的一个子集，因此它可以达到与密集 LLM 相同的性能，吞吐量超过两倍; 2)可扩展性，模块化程序比密集 LLM 更能免疫灾难性遗忘，并且可以很容易地用新模块进行扩展，以学习未包含在训练数据中的新知识; 3)专业化，微调的模块化程序可以为微调任务专门化模块的一个子集，并且与任务无关的模块可以很容易地为。"
    },
    {
        "title": "Transformers as Statisticians: Provable In-Context Learning with\n  In-Context Algorithm Selection",
        "url": "http://arxiv.org/abs/2306.04637v1",
        "pub_date": "2023-06-07",
        "summary": "Neural sequence models based on the transformer architecture have\ndemonstrated remarkable \\emph{in-context learning} (ICL) abilities, where they\ncan perform new tasks when prompted with training and test examples, without\nany parameter update to the model. This work first provides a comprehensive\nstatistical theory for transformers to perform ICL. Concretely, we show that\ntransformers can implement a broad class of standard machine learning\nalgorithms in context, such as least squares, ridge regression, Lasso, learning\ngeneralized linear models, and gradient descent on two-layer neural networks,\nwith near-optimal predictive power on various in-context data distributions.\nUsing an efficient implementation of in-context gradient descent as the\nunderlying mechanism, our transformer constructions admit mild size bounds, and\ncan be learned with polynomially many pretraining sequences.\n  Building on these ``base'' ICL algorithms, intriguingly, we show that\ntransformers can implement more complex ICL procedures involving\n\\emph{in-context algorithm selection}, akin to what a statistician can do in\nreal life -- A \\emph{single} transformer can adaptively select different base\nICL algorithms -- or even perform qualitatively different tasks -- on different\ninput sequences, without any explicit prompting of the right algorithm or task.\nWe both establish this in theory by explicit constructions, and also observe\nthis phenomenon experimentally. In theory, we construct two general mechanisms\nfor algorithm selection with concrete examples: pre-ICL testing, and post-ICL\nvalidation. As an example, we use the post-ICL validation mechanism to\nconstruct a transformer that can perform nearly Bayes-optimal ICL on a\nchallenging task -- noisy linear models with mixed noise levels.\nExperimentally, we demonstrate the strong in-context algorithm selection\ncapabilities of standard transformer architectures.",
        "translated": "基于变压器结构的神经序列模型表现出了显著的移动{在上下文中学习}(ICL)能力，它们可以在训练和测试示例的提示下执行新的任务，而不需要对模型进行任何参数更新。这项工作首先为变压器执行 ICL 提供了一个全面的统计理论。具体来说，我们展示了变压器可以在上下文环境中实现一大类标准的机器学习算法，如最小二乘、岭回归、套索、学习广义线性模型，以及在两层神经网络上实现梯度下降法，对各种上下文数据分布具有近乎最优的预测能力。使用一个有效的实现在上下文中的梯度下降法作为底层机制，我们的变压器结构承认温和的大小界限，可以学习与多项式许多预训练序列。在这些“基本”ICL 算法的基础上，有趣的是，我们展示了变压器可以实现更复杂的 ICL 程序，包括 emph { in-context 算法选择} ，类似于统计学家在现实生活中可以做的——一个 emph { single }变压器可以自适应地选择不同的基本 ICL 算法——甚至可以执行定性上不同的任务——在不同的输入序列上，没有任何明确的正确算法或任务的提示。我们通过明确的结构在理论上建立了这种现象，并且通过实验观察了这种现象。在理论上，我们通过具体的实例构造了两种通用的算法选择机制: 前 ICL 测试和后 ICL 验证。作为一个例子，我们使用后 ICL 验证机制来构造一个变压器，可以执行接近贝叶斯最优的 ICL 在一个具有挑战性的任务-混合噪声水平的线性模型。实验表明，标准变压器结构具有很强的上下文算法选择能力。"
    },
    {
        "title": "On the Reliability of Watermarks for Large Language Models",
        "url": "http://arxiv.org/abs/2306.04634v1",
        "pub_date": "2023-06-07",
        "summary": "Large language models (LLMs) are now deployed to everyday use and positioned\nto produce large quantities of text in the coming decade. Machine-generated\ntext may displace human-written text on the internet and has the potential to\nbe used for malicious purposes, such as spearphishing attacks and social media\nbots. Watermarking is a simple and effective strategy for mitigating such harms\nby enabling the detection and documentation of LLM-generated text. Yet, a\ncrucial question remains: How reliable is watermarking in realistic settings in\nthe wild? There, watermarked text might be mixed with other text sources,\nparaphrased by human writers or other language models, and used for\napplications in a broad number of domains, both social and technical. In this\npaper, we explore different detection schemes, quantify their power at\ndetecting watermarks, and determine how much machine-generated text needs to be\nobserved in each scenario to reliably detect the watermark. We especially\nhighlight our human study, where we investigate the reliability of watermarking\nwhen faced with human paraphrasing. We compare watermark-based detection to\nother detection strategies, finding overall that watermarking is a reliable\nsolution, especially because of its sample complexity - for all attacks we\nconsider, the watermark evidence compounds the more examples are given, and the\nwatermark is eventually detected.",
        "translated": "大型语言模型(LLM)现在被部署到日常使用中，并定位于在未来十年生成大量文本。机器生成的文本可能取代互联网上人写的文本，并有可能被用于恶意目的，如鱼叉式钓鱼攻击和社交媒体机器人。水印是一种简单而有效的策略，通过检测和记录 LLM 生成的文本来减轻这种危害。然而，一个关键的问题仍然存在: 在野外的现实环境中，水印的可靠性如何？在那里，水印文本可能与其他文本来源混合，由人类作家或其他语言模型转述，并用于广泛的领域中的应用，包括社会和技术。在本文中，我们探讨了不同的检测方案，量化它们在检测水印方面的能力，并确定在每个场景中需要观察多少机器生成的文本才能可靠地检测水印。我们特别强调我们的人类研究，我们调查的可靠性水印时，面对人类释义。我们比较了基于水印的检测和其他检测策略，发现水印是一个可靠的解决方案，特别是因为它的样本复杂性-对于所有的攻击，我们考虑，水印证据复合越多的例子，并最终检测水印。"
    },
    {
        "title": "Revisiting Out-of-distribution Robustness in NLP: Benchmark, Analysis,\n  and LLMs Evaluations",
        "url": "http://arxiv.org/abs/2306.04618v1",
        "pub_date": "2023-06-07",
        "summary": "This paper reexamines the research on out-of-distribution (OOD) robustness in\nthe field of NLP. We find that the distribution shift settings in previous\nstudies commonly lack adequate challenges, hindering the accurate evaluation of\nOOD robustness. To address these issues, we propose a benchmark construction\nprotocol that ensures clear differentiation and challenging distribution\nshifts. Then we introduce BOSS, a Benchmark suite for Out-of-distribution\nrobustneSS evaluation covering 5 tasks and 20 datasets. Based on BOSS, we\nconduct a series of experiments on pre-trained language models for analysis and\nevaluation of OOD robustness. First, for vanilla fine-tuning, we examine the\nrelationship between in-distribution (ID) and OOD performance. We identify\nthree typical types that unveil the inner learning mechanism, which could\npotentially facilitate the forecasting of OOD robustness, correlating with the\nadvancements on ID datasets. Then, we evaluate 5 classic methods on BOSS and\nfind that, despite exhibiting some effectiveness in specific cases, they do not\noffer significant improvement compared to vanilla fine-tuning. Further, we\nevaluate 5 LLMs with various adaptation paradigms and find that when sufficient\nID data is available, fine-tuning domain-specific models outperform LLMs on ID\nexamples significantly. However, in the case of OOD instances, prioritizing\nLLMs with in-context learning yields better results. We identify that both\nfine-tuned small models and LLMs face challenges in effectively addressing\ndownstream tasks. The code is public at\n\\url{https://github.com/lifan-yuan/OOD_NLP}.",
        "translated": "本文重新审视了自然语言处理领域中分布外(OOD)鲁棒性的研究。我们发现在以往的研究中，分布移位设置通常缺乏足够的挑战，阻碍了面向对象的鲁棒性的准确评估。为了解决这些问题，我们提出了一个基准建设协议，以确保明确的差异和挑战性的分配转移。然后我们介绍了 BOSS，一个用于分布外鲁棒性评估的基准套件，包括5个任务和20个数据集。基于 BOSS 系统，我们对预训练语言模型进行了一系列的实验，用于分析和评估面向对象的鲁棒性。首先，对于普通的微调，我们研究分发内(ID)和 OOD 性能之间的关系。我们确定了三种典型的类型，揭示了内部学习机制，这可能有助于面向对象的鲁棒性预测，与 ID 数据集的进步相关。然后，我们对 BOSS 上的5种经典方法进行了评估，发现尽管它们在特定情况下显示出一些有效性，但与普通的微调相比，它们并没有提供显著的改进。此外，我们评估了5个具有不同适应范例的 LLM，发现当有足够的 ID 数据可用时，针对特定领域的微调模型在 ID 示例上的表现明显优于 LLM。但是，在面向对象的实例中，使用上下文内学习对 LLM 进行优先排序会产生更好的结果。我们发现，微调小型模型和 LLM 在有效处理下游任务方面都面临挑战。该代码在 url { https://github.com/lifan-yuan/ood_nlp }是公共的。"
    },
    {
        "title": "The Two Word Test: A Semantic Benchmark for Large Language Models",
        "url": "http://arxiv.org/abs/2306.04610v1",
        "pub_date": "2023-06-07",
        "summary": "Large Language Models (LLMs) have shown remarkable abilities recently,\nincluding passing advanced professional exams and demanding benchmark tests.\nThis performance has led many to suggest that they are close to achieving\nhumanlike or 'true' understanding of language, and even Artificial General\nIntelligence (AGI). Here, we provide a new open-source benchmark that can\nassess semantic abilities of LLMs using two-word phrases using a task that can\nbe performed relatively easily by humans without advanced training. Combining\nmultiple words into a single concept is a fundamental aspect of human language\nand intelligence. The test requires meaningfulness judgments of 1768 noun-noun\ncombinations that have been rated as meaningful (e.g., baby boy) or not\nmeaningful (e.g., goat sky). by 150 human raters. We provide versions of the\ntask that probe meaningfulness ratings on a 0-4 scale as well as binary\njudgments. We conducted a series of experiments using the TWT on GPT-4,\nGPT-3.5, and Bard, with both versions. Results demonstrated that, compared to\nhumans, all models perform poorly at rating meaningfulness of these phrases.\nGPT-3.5 and Bard are also unable to make binary discriminations between\nsensible and nonsense phrases as making sense. GPT-4 makes a substantial\nimprovement in binary discrimination of combinatorial phrases but is still\nsignificantly worse than human performance. The TWT can be used to understand\nthe limitations and weaknesses of current LLMs, and potentially improve them.\nThe test also reminds us that caution is warranted in attributing 'true\nunderstanding' or AGI to LLMs. TWT is available at:\nhttps://github.com/NickRiccardi/two-word-test",
        "translated": "大型语言模型(LLM)最近显示出非凡的能力，包括通过高级专业考试和苛刻的基准测试。这种表现使得许多人认为他们已经接近达到类人或“真正”理解语言，甚至人工通用智能(AGI)。在这里，我们提供了一个新的开源基准，可以使用两个词的短语来评估 LLM 的语义能力，使用的任务可以相对容易地由人类执行，而不需要高级培训。将多个单词组合成一个单一的概念是人类语言和智力的一个基本方面。这个测试需要对1768个名词和名词的组合进行有意义的判断，这些组合被认为是有意义的(比如，男婴)或者没有意义的(比如，山羊天空)。被150个人类评估员评估。我们提供了任务的版本，探讨有意义的评级在0-4尺度以及二元判断。我们使用行波管在 GPT-4、 GPT-3.5和巴德上进行了一系列的实验，两个版本都有。结果表明，与人类相比，所有的模型在评价这些短语的意义方面表现不佳。GPT-3.5和巴德也不能把明智的和无意义的短语作为有意义的二元区分。GPT-4在组合短语的二进制识别方面有显著改善，但仍明显低于人类的识别水平。行波管可以用来了解现有 LLM 的局限性和弱点，并可能改进它们。该测试还提醒我们，在将“真正的理解”或 AGI 归因于 LLM 时，谨慎是必要的。TWT 可在以下 https://github.com/nickriccardi/two-word-test 购买:"
    },
    {
        "title": "Language Models Get a Gender Makeover: Mitigating Gender Bias with\n  Few-Shot Data Interventions",
        "url": "http://arxiv.org/abs/2306.04597v1",
        "pub_date": "2023-06-07",
        "summary": "Societal biases present in pre-trained large language models are a critical\nissue as these models have been shown to propagate biases in countless\ndownstream applications, rendering them unfair towards specific groups of\npeople. Since large-scale retraining of these models from scratch is both time\nand compute-expensive, a variety of approaches have been previously proposed\nthat de-bias a pre-trained model. While the majority of current\nstate-of-the-art debiasing methods focus on changes to the training regime, in\nthis paper, we propose data intervention strategies as a powerful yet simple\ntechnique to reduce gender bias in pre-trained models. Specifically, we\nempirically show that by fine-tuning a pre-trained model on only 10 de-biased\n(intervened) training examples, the tendency to favor any gender is\nsignificantly reduced. Since our proposed method only needs a few training\nexamples, our few-shot debiasing approach is highly feasible and practical.\nThrough extensive experimentation, we show that our debiasing technique\nperforms better than competitive state-of-the-art baselines with minimal loss\nin language modeling ability.",
        "translated": "预先训练的大型语言模型中存在的社会偏见是一个关键问题，因为这些模型已被证明在无数下游应用程序中传播偏见，使它们对特定人群不公平。由于从头开始对这些模型进行大规模的再训练既耗费时间又耗费计算机资源，因此先前已经提出了各种方法来消除预训练模型的偏差。虽然目前大多数最先进的消除偏见的方法集中在训练体制的变化，在本文中，我们提出的数据干预策略作为一个强大而简单的技术，以减少预训练模型中的性别偏见。具体来说，我们的经验表明，通过微调一个预先训练的模型，只有10个无偏见(干预)训练的例子，倾向于任何性别显着降低。由于本文提出的方法只需要少量训练样本，因此本文提出的小镜头消偏方法具有很高的可行性和实用性。通过大量的实验，我们发现我们的去偏技术在语言建模能力损失最小的情况下比竞争性的最先进的基线表现得更好。"
    },
    {
        "title": "Gender, names and other mysteries: Towards the ambiguous for\n  gender-inclusive translation",
        "url": "http://arxiv.org/abs/2306.04573v1",
        "pub_date": "2023-06-07",
        "summary": "The vast majority of work on gender in MT focuses on 'unambiguous' inputs,\nwhere gender markers in the source language are expected to be resolved in the\noutput. Conversely, this paper explores the widespread case where the source\nsentence lacks explicit gender markers, but the target sentence contains them\ndue to richer grammatical gender. We particularly focus on inputs containing\nperson names.\n  Investigating such sentence pairs casts a new light on research into MT\ngender bias and its mitigation. We find that many name-gender co-occurrences in\nMT data are not resolvable with 'unambiguous gender' in the source language,\nand that gender-ambiguous examples can make up a large proportion of training\nexamples. From this, we discuss potential steps toward gender-inclusive\ntranslation which accepts the ambiguity in both gender and translation.",
        "translated": "在机器翻译领域，绝大多数关于性别的工作集中在“明确的”输入上，源语言中的性别标记预计将在输出中得到解决。相反，本文探讨了普遍存在的一种情况，即原句缺乏明确的性别标记，但是由于性丰富，目标句包含了这些性别标记。我们特别关注包含人名的输入。对这类句子对的研究为 MT 性别偏见的研究及其缓解提供了新的视角。我们发现，在机器翻译数据中，许多名称-性别同时出现的情况不能用源语言中的“明确的性别”来解决，而且性别模糊的例子可以构成很大比例的训练例子。从这一点出发，我们讨论了实现性别包容性翻译的可能步骤，即接受性别歧义和翻译歧义。"
    },
    {
        "title": "ChatGPT is fun, but it is not funny! Humor is still challenging Large\n  Language Models",
        "url": "http://arxiv.org/abs/2306.04563v1",
        "pub_date": "2023-06-07",
        "summary": "Humor is a central aspect of human communication that has not been solved for\nartificial agents so far. Large language models (LLMs) are increasingly able to\ncapture implicit and contextual information. Especially, OpenAI's ChatGPT\nrecently gained immense public attention. The GPT3-based model almost seems to\ncommunicate on a human level and can even tell jokes. Humor is an essential\ncomponent of human communication. But is ChatGPT really funny? We put ChatGPT's\nsense of humor to the test. In a series of exploratory experiments around\njokes, i.e., generation, explanation, and detection, we seek to understand\nChatGPT's capability to grasp and reproduce human humor. Since the model itself\nis not accessible, we applied prompt-based experiments. Our empirical evidence\nindicates that jokes are not hard-coded but mostly also not newly generated by\nthe model. Over 90% of 1008 generated jokes were the same 25 Jokes. The system\naccurately explains valid jokes but also comes up with fictional explanations\nfor invalid jokes. Joke-typical characteristics can mislead ChatGPT in the\nclassification of jokes. ChatGPT has not solved computational humor yet but it\ncan be a big leap toward \"funny\" machines.",
        "translated": "幽默是人类交流的一个核心方面，迄今为止人工智能还没有解决这个问题。大型语言模型(LLM)越来越能够捕获隐式信息和上下文信息。尤其是 OpenAI 的 ChatGPT 最近引起了公众的广泛关注。基于 GPT3的模型几乎可以在人类水平上交流，甚至可以讲笑话。幽默是人际交往的重要组成部分。但是聊天 GPT 真的有趣吗？我们测试了 ChatGPT 的幽默感。在一系列围绕笑话的探索性实验中，即生成、解释和发现，我们试图理解 ChatGPT 掌握和再现人类幽默的能力。由于模型本身不可访问，我们应用了基于提示的实验。我们的经验证明表明，笑话不是硬编码的，但大多数也不是模型新生成的。在1008个笑话中，超过90% 的笑话都是相同的25个。该系统准确地解释了有效的笑话，但同时也为无效的笑话提供了虚构的解释。笑话的典型特征会误导聊天 GPT 对笑话的分类。ChatGPT 还没有解决计算幽默问题，但是它可以向“有趣的”机器迈出一大步。"
    },
    {
        "title": "Multi-Task Training with In-Domain Language Models for Diagnostic\n  Reasoning",
        "url": "http://arxiv.org/abs/2306.04551v1",
        "pub_date": "2023-06-07",
        "summary": "Generative artificial intelligence (AI) is a promising direction for\naugmenting clinical diagnostic decision support and reducing diagnostic errors,\na leading contributor to medical errors. To further the development of clinical\nAI systems, the Diagnostic Reasoning Benchmark (DR.BENCH) was introduced as a\ncomprehensive generative AI framework, comprised of six tasks representing key\ncomponents in clinical reasoning. We present a comparative analysis of\nin-domain versus out-of-domain language models as well as multi-task versus\nsingle task training with a focus on the problem summarization task in DR.BENCH\n(Gao et al., 2023). We demonstrate that a multi-task, clinically trained\nlanguage model outperforms its general domain counterpart by a large margin,\nestablishing a new state-of-the-art performance, with a ROUGE-L score of 28.55.\nThis research underscores the value of domain-specific training for optimizing\nclinical diagnostic reasoning tasks.",
        "translated": "生成性人工智能(AI)是增强临床诊断决策支持和减少诊断错误的一个有前途的方向，是导致医疗错误的主要因素。为了进一步发展临床人工智能系统，将诊断推理基准(DR.BENCH)作为一个全面的生成性人工智能框架引入，该框架由代表临床推理关键组成部分的六个任务组成。我们提出了领域内与领域外语言模型以及多任务与单任务训练的比较分析，重点是 DR.BENCH 中的问题总结任务(Gao et al。 ，2023)。我们证明，一个多任务，临床训练的语言模型优于其一般领域的对应大幅度，建立一个新的最先进的表现，ROUGE-L 分数为28.55。本研究强调了领域特定训练对于优化临床诊断推理任务的价值。"
    },
    {
        "title": "Contrastive Bootstrapping for Label Refinement",
        "url": "http://arxiv.org/abs/2306.04544v1",
        "pub_date": "2023-06-07",
        "summary": "Traditional text classification typically categorizes texts into pre-defined\ncoarse-grained classes, from which the produced models cannot handle the\nreal-world scenario where finer categories emerge periodically for accurate\nservices. In this work, we investigate the setting where fine-grained\nclassification is done only using the annotation of coarse-grained categories\nand the coarse-to-fine mapping. We propose a lightweight contrastive\nclustering-based bootstrapping method to iteratively refine the labels of\npassages. During clustering, it pulls away negative passage-prototype pairs\nunder the guidance of the mapping from both global and local perspectives.\nExperiments on NYT and 20News show that our method outperforms the\nstate-of-the-art methods by a large margin.",
        "translated": "传统的文本分类通常将文本分类为预定义的粗粒度类，由此产生的模型无法处理现实场景，即定期出现更精细的类别以获得准确的服务。在这项工作中，我们研究的设置，细粒度分类是完成只使用粗粒度类别的注释和粗到细的映射。提出了一种基于轻量级对比聚类的自举算法来迭代细化文章标签。在聚类过程中，它在映射的指导下，从全局和局部两个角度抽取负的通道原型对。在《纽约时报》和《20世纪新闻》上的实验表明，我们的方法比最先进的方法有很大的优势。"
    },
    {
        "title": "Safe Collaborative Filtering",
        "url": "http://arxiv.org/abs/2306.05292v1",
        "pub_date": "2023-06-08",
        "summary": "Excellent tail performance is crucial for modern machine learning tasks, such\nas algorithmic fairness, class imbalance, and risk-sensitive decision making,\nas it ensures the effective handling of challenging samples within a dataset.\nTail performance is also a vital determinant of success for personalised\nrecommender systems to reduce the risk of losing users with low satisfaction.\nThis study introduces a \"safe\" collaborative filtering method that prioritises\nrecommendation quality for less-satisfied users rather than focusing on the\naverage performance. Our approach minimises the conditional value at risk\n(CVaR), which represents the average risk over the tails of users' loss. To\novercome computational challenges for web-scale recommender systems, we develop\na robust yet practical algorithm that extends the most scalable method,\nimplicit alternating least squares (iALS). Empirical evaluation on real-world\ndatasets demonstrates the excellent tail performance of our approach while\nmaintaining competitive computational efficiency.",
        "translated": "优秀的尾部性能对于现代机器学习任务至关重要，例如算法公平性、类不平衡性和风险敏感决策，因为它确保有效处理数据集中具有挑战性的样本。尾部性能也是个性化推荐系统成功的一个重要决定因素，可以降低用户满意度不高而流失的风险。这项研究引入了一种“安全”的协同过滤方法，优先考虑对不满意用户的推荐质量，而不是关注平均性能。我们的方法将条件风险值(CVaR)最小化，CVaR 代表用户损失尾部的平均风险。为了克服网络规模推荐系统的计算挑战，我们开发了一个强大而实用的算法，扩展了最可扩展的方法，隐式交替最小二乘(iALS)。对真实世界数据集的实证评估证明了该方法在保持竞争计算效率的同时具有优异的尾部性能。"
    },
    {
        "title": "RETA-LLM: A Retrieval-Augmented Large Language Model Toolkit",
        "url": "http://arxiv.org/abs/2306.05212v1",
        "pub_date": "2023-06-08",
        "summary": "Although Large Language Models (LLMs) have demonstrated extraordinary\ncapabilities in many domains, they still have a tendency to hallucinate and\ngenerate fictitious responses to user requests. This problem can be alleviated\nby augmenting LLMs with information retrieval (IR) systems (also known as\nretrieval-augmented LLMs). Applying this strategy, LLMs can generate more\nfactual texts in response to user input according to the relevant content\nretrieved by IR systems from external corpora as references. In addition, by\nincorporating external knowledge, retrieval-augmented LLMs can answer in-domain\nquestions that cannot be answered by solely relying on the world knowledge\nstored in parameters. To support research in this area and facilitate the\ndevelopment of retrieval-augmented LLM systems, we develop RETA-LLM, a\n{RET}reival-{A}ugmented LLM toolkit. In RETA-LLM, we create a complete pipeline\nto help researchers and users build their customized in-domain LLM-based\nsystems. Compared with previous retrieval-augmented LLM systems, RETA-LLM\nprovides more plug-and-play modules to support better interaction between IR\nsystems and LLMs, including {request rewriting, document retrieval, passage\nextraction, answer generation, and fact checking} modules. Our toolkit is\npublicly available at https://github.com/RUC-GSAI/YuLan-IR/tree/main/RETA-LLM.",
        "translated": "尽管大型语言模型(LLM)已经在许多领域展示了非凡的能力，但是它们仍然有产生幻觉和对用户请求产生虚构响应的倾向。这个问题可以通过使用信息检索(IR)系统(也称为检索增强 LLM)来增强 LLM 来缓解。应用这种策略，LLM 可以根据 IR 系统从外部语料库中检索到的相关内容作为参考，根据用户的输入生成更多的事实性文本。此外，通过合并外部知识，检索增强 LLM 可以回答领域内的问题，而这些问题不能仅仅依赖于存储在参数中的世界知识来回答。为了支持这一领域的研究和促进检索增强 LLM 系统的发展，我们开发了 RETA-LLM，一个{ RET } reval-{ A }增强 LLM 工具包。在 RETA-LLM 中，我们创建了一个完整的管道来帮助研究人员和用户构建他们定制的基于领域 LLM 的系统。与以前的检索增强 LLM 系统相比，RETA-LLM 提供了更多的即插即用模块，以支持 IR 系统和 LLM 之间更好的交互，包括{请求重写、文献检索、段落提取、答案生成和事实检查}模块。我们的工具包可以在 https://github.com/ruc-gsai/yulan-ir/tree/main/reta-llm 上公开获得。"
    },
    {
        "title": "Controllable Multi-Objective Re-ranking with Policy Hypernetworks",
        "url": "http://arxiv.org/abs/2306.05118v1",
        "pub_date": "2023-06-08",
        "summary": "Multi-stage ranking pipelines have become widely used strategies in modern\nrecommender systems, where the final stage aims to return a ranked list of\nitems that balances a number of requirements such as user preference,\ndiversity, novelty etc. Linear scalarization is arguably the most widely used\ntechnique to merge multiple requirements into one optimization objective, by\nsumming up the requirements with certain preference weights. Existing\nfinal-stage ranking methods often adopt a static model where the preference\nweights are determined during offline training and kept unchanged during online\nserving. Whenever a modification of the preference weights is needed, the model\nhas to be re-trained, which is time and resources inefficient. Meanwhile, the\nmost appropriate weights may vary greatly for different groups of targeting\nusers or at different time periods (e.g., during holiday promotions). In this\npaper, we propose a framework called controllable multi-objective re-ranking\n(CMR) which incorporates a hypernetwork to generate parameters for a re-ranking\nmodel according to different preference weights. In this way, CMR is enabled to\nadapt the preference weights according to the environment changes in an online\nmanner, without retraining the models. Moreover, we classify practical\nbusiness-oriented tasks into four main categories and seamlessly incorporate\nthem in a new proposed re-ranking model based on an Actor-Evaluator framework,\nwhich serves as a reliable real-world testbed for CMR. Offline experiments\nbased on the dataset collected from Taobao App showed that CMR improved several\npopular re-ranking models by using them as underlying models. Online A/B tests\nalso demonstrated the effectiveness and trustworthiness of CMR.",
        "translated": "多阶段排名管道已经成为现代推荐系统中广泛使用的策略，最后阶段的目标是返回一个项目的排名列表，以平衡一些需求，如用户偏好，多样性，新颖性等。线性标量可以说是最广泛使用的技术合并多个需求到一个优化目标，通过总结需求与一定的偏好权重。现有的最后阶段排序方法通常采用静态模型，在离线训练期间确定偏好权重，在线服务期间保持不变。当需要修改偏好权重时，模型必须重新训练，这是时间和资源效率低下的。与此同时，最合适的权重可能会因不同的目标用户群体或在不同的时间段(例如，在假日促销期间)而有很大差异。本文提出了一种可控的多目标重排序(CMR)框架，该框架结合了一个超网络，根据不同的偏好权重为重排序模型生成参数。通过这种方式，CMR 能够根据环境变化在线调整偏好权重，而不需要重新训练模型。此外，我们将面向业务的实际任务分为四个主要类别，并将它们无缝地纳入一个新提出的重新排序模型，该模型基于一个演员-评估者框架，作为一个可靠的现实世界的 CMR 测试平台。基于从淘宝应用收集的数据集的离线实验表明，CMR 通过使用它们作为基础模型改进了几个流行的重新排名模型。在线 A/B 测试也证明了 CMR 的有效性和可信性。"
    },
    {
        "title": "Attention Weighted Mixture of Experts with Contrastive Learning for\n  Personalized Ranking in E-commerce",
        "url": "http://arxiv.org/abs/2306.05011v1",
        "pub_date": "2023-06-08",
        "summary": "Ranking model plays an essential role in e-commerce search and\nrecommendation. An effective ranking model should give a personalized ranking\nlist for each user according to the user preference. Existing algorithms\nusually extract a user representation vector from the user behavior sequence,\nthen feed the vector into a feed-forward network (FFN) together with other\nfeatures for feature interactions, and finally produce a personalized ranking\nscore. Despite tremendous progress in the past, there is still room for\nimprovement. Firstly, the personalized patterns of feature interactions for\ndifferent users are not explicitly modeled. Secondly, most of existing\nalgorithms have poor personalized ranking results for long-tail users with few\nhistorical behaviors due to the data sparsity. To overcome the two challenges,\nwe propose Attention Weighted Mixture of Experts (AW-MoE) with contrastive\nlearning for personalized ranking. Firstly, AW-MoE leverages the MoE framework\nto capture personalized feature interactions for different users. To model the\nuser preference, the user behavior sequence is simultaneously fed into expert\nnetworks and the gate network. Within the gate network, one gate unit and one\nactivation unit are designed to adaptively learn the fine-grained activation\nvector for experts using an attention mechanism. Secondly, a random masking\nstrategy is applied to the user behavior sequence to simulate long-tail users,\nand an auxiliary contrastive loss is imposed to the output of the gate network\nto improve the model generalization for these users. This is validated by a\nhigher performance gain on the long-tail user test set. Experiment results on a\nJD real production dataset and a public dataset demonstrate the effectiveness\nof AW-MoE, which significantly outperforms state-of-art methods. Notably,\nAW-MoE has been successfully deployed in the JD e-commerce search engine, ...",
        "translated": "排名模型在电子商务搜索和推荐中起着至关重要的作用。一个有效的排名模型应该根据用户的偏好为每个用户提供一个个性化的排名列表。现有的算法通常从用户行为序列中提取用户表示向量，然后将该向量与其他特征一起反馈到前馈网络(FFN)中进行特征交互，最终产生个性化的排序得分。尽管过去取得了巨大的进步，但仍有改进的空间。首先，不同用户特征交互的个性化模式没有明确建模。其次，由于数据稀疏，现有算法对于长尾用户的个性化排序效果较差，历史行为较少。为了克服这两个挑战，我们提出了基于对比学习的专家注意加权混合排序方法(AW-MoE)。首先，AW-MoE 利用 MoE 框架为不同的用户捕获个性化的特征交互。为了建立用户偏好模型，将用户行为序列同时输入到专家网络和门网络中。在门网络中，设计了一个门单元和一个激活单元，利用注意机制为专家自适应地学习细粒度激活向量。其次，对用户行为序列采用随机掩蔽策略来模拟长尾用户，并对门网络的输出增加辅助对比度损失，以提高对长尾用户的模型泛化能力。这通过在长尾用户测试集上获得更高的性能增益来验证。在 JD 实际生产数据集和公开数据集上的实验结果证明了 AW-MoE 方法的有效性，其性能明显优于最先进的方法。值得注意的是，AW-MoE 已经成功地部署在 JD 电子商务搜索引擎，..。"
    },
    {
        "title": "Unified Embedding Based Personalized Retrieval in Etsy Search",
        "url": "http://arxiv.org/abs/2306.04833v1",
        "pub_date": "2023-06-07",
        "summary": "Embedding-based neural retrieval is a prevalent approach to address the\nsemantic gap problem which often arises in product search on tail queries. In\ncontrast, popular queries typically lack context and have a broad intent where\nadditional context from users historical interaction can be helpful. In this\npaper, we share our novel approach to address both: the semantic gap problem\nfollowed by an end to end trained model for personalized semantic retrieval. We\npropose learning a unified embedding model incorporating graph, transformer and\nterm-based embeddings end to end and share our design choices for optimal\ntradeoff between performance and efficiency. We share our learnings in feature\nengineering, hard negative sampling strategy, and application of transformer\nmodel, including a novel pre-training strategy and other tricks for improving\nsearch relevance and deploying such a model at industry scale. Our personalized\nretrieval model significantly improves the overall search experience, as\nmeasured by a 5.58% increase in search purchase rate and a 2.63% increase in\nsite-wide conversion rate, aggregated across multiple A/B tests - on live\ntraffic.",
        "translated": "基于嵌入式的神经检索是解决尾部查询产品搜索中经常出现的语义缺口问题的一种常用方法。相比之下，流行的查询通常缺乏上下文，并且具有广泛的意图，其中来自用户历史交互的额外上下文可能有所帮助。在本文中，我们分享了我们的新方法来解决这两个问题: 语义差距问题，然后是个性化语义检索的端到端训练模型。我们提出了一种结合图形、变换器和基于术语的嵌入端到端学习的统一嵌入模型，并共享我们的设计选择，以实现性能和效率之间的最优平衡。我们分享了我们在特征工程、硬负采样策略和变压器模型应用方面的经验，包括一种新的预训练策略和其他提高搜索相关性和在行业规模部署此类模型的技巧。我们的个性化检索模型显著改善了整体搜索体验，通过对实时流量进行多个 A/B 测试，搜索购买率增加了5.58% ，网站转换率增加了2.63% 。"
    },
    {
        "title": "MIMIC-IT: Multi-Modal In-Context Instruction Tuning",
        "url": "http://arxiv.org/abs/2306.05425v1",
        "pub_date": "2023-06-08",
        "summary": "High-quality instructions and responses are essential for the zero-shot\nperformance of large language models on interactive natural language tasks. For\ninteractive vision-language tasks involving intricate visual scenes, a large\nquantity of diverse and creative instruction-response pairs should be\nimperative to tune vision-language models (VLMs). Nevertheless, the current\navailability of vision-language instruction-response pairs in terms of\nquantity, diversity, and creativity remains limited, posing challenges to the\ngeneralization of interactive VLMs. Here we present MultI-Modal In-Context\nInstruction Tuning (MIMIC-IT), a dataset comprising 2.8 million multimodal\ninstruction-response pairs, with 2.2 million unique instructions derived from\nimages and videos. Each pair is accompanied by multi-modal in-context\ninformation, forming conversational contexts aimed at empowering VLMs in\nperception, reasoning, and planning. The instruction-response collection\nprocess, dubbed as Syphus, is scaled using an automatic annotation pipeline\nthat combines human expertise with GPT's capabilities. Using the MIMIC-IT\ndataset, we train a large VLM named Otter. Based on extensive evaluations\nconducted on vision-language benchmarks, it has been observed that Otter\ndemonstrates remarkable proficiency in multi-modal perception, reasoning, and\nin-context learning. Human evaluation reveals it effectively aligns with the\nuser's intentions. We release the MIMIC-IT dataset, instruction-response\ncollection pipeline, benchmarks, and the Otter model.",
        "translated": "高质量的指令和响应对于大型语言模型在交互式自然语言任务中的零点性能至关重要。对于涉及复杂视觉场景的交互式视觉语言任务，必须调优视觉语言模型(VLM)。然而，目前视觉-语言教学-反应对在数量、多样性和创造性方面的可用性仍然有限，对交互式 VLM 的普及提出了挑战。在这里，我们介绍了多模态上下文指令调优(MIMIC-IT) ，一个包含280万个多模态指令-响应对的数据集，其中有220万个来自图像和视频的独特指令。每一对都伴随着多模态的语境信息，形成旨在赋予 VLM 感知、推理和计划能力的会话语境。这个被称为 Syphus 的指令-响应收集过程使用一个自动注释管道进行扩展，该管道将人类的专业知识与 GPT 的功能结合在一起。使用 MIMIC-IT 数据集，我们训练了一个名为 Otter 的大型 VLM。基于对视觉语言基准的广泛评估，我们发现 Otter 在多模态知觉、推理和语境学习方面表现出显著的能力。人工评估显示它有效地与用户的意图保持一致。我们发布 MIMIC-IT 数据集、指令-响应收集管道、基准测试和 Otter 模型。"
    },
    {
        "title": "Mixture-of-Domain-Adapters: Decoupling and Injecting Domain Knowledge to\n  Pre-trained Language Models Memories",
        "url": "http://arxiv.org/abs/2306.05406v1",
        "pub_date": "2023-06-08",
        "summary": "Pre-trained language models (PLMs) demonstrate excellent abilities to\nunderstand texts in the generic domain while struggling in a specific domain.\nAlthough continued pre-training on a large domain-specific corpus is effective,\nit is costly to tune all the parameters on the domain. In this paper, we\ninvestigate whether we can adapt PLMs both effectively and efficiently by only\ntuning a few parameters. Specifically, we decouple the feed-forward networks\n(FFNs) of the Transformer architecture into two parts: the original pre-trained\nFFNs to maintain the old-domain knowledge and our novel domain-specific\nadapters to inject domain-specific knowledge in parallel. Then we adopt a\nmixture-of-adapters gate to fuse the knowledge from different domain adapters\ndynamically. Our proposed Mixture-of-Domain-Adapters (MixDA) employs a\ntwo-stage adapter-tuning strategy that leverages both unlabeled data and\nlabeled data to help the domain adaptation: i) domain-specific adapter on\nunlabeled data; followed by ii) the task-specific adapter on labeled data.\nMixDA can be seamlessly plugged into the pretraining-finetuning paradigm and\nour experiments demonstrate that MixDA achieves superior performance on\nin-domain tasks (GLUE), out-of-domain tasks (ChemProt, RCT, IMDB, Amazon), and\nknowledge-intensive tasks (KILT). Further analyses demonstrate the reliability,\nscalability, and efficiency of our method. The code is available at\nhttps://github.com/Amano-Aki/Mixture-of-Domain-Adapters.",
        "translated": "预训练语言模型(PLM)展示了在通用领域理解文本而在特定领域挣扎的卓越能力。尽管在特定于领域的大型语料库上进行持续的预训练是有效的，但是调优领域上的所有参数的成本是很高的。在本文中，我们研究是否可以适应 PLM 的有效性和有效性，只需调整几个参数。具体来说，我们将变压器结构的前馈网络(FFN)解耦为两部分: 原始的预先训练的 FFN 来维护旧的领域知识，以及我们新颖的领域特定适配器来并行注入领域特定的知识。然后采用混合适配器门来动态融合来自不同领域适配器的知识。我们提出的混合域适配器(MixDA)采用两阶段适配器调优策略，利用未标记数据和标记数据来帮助域适配: i)未标记数据上的域特定适配器; 随后 ii)标记数据上的任务特定适配器。MixDA 可以无缝地插入预训练-微调范式，我们的实验表明，MixDA 在域内任务(GLUE) ，域外任务(ChemProt，RCT，IMDB，Amazon)和知识密集型任务(KILT)上取得了优越的性能。进一步的分析证明了该方法的可靠性、可扩展性和有效性。密码可在 https://github.com/amano-aki/mixture-of-domain-adapters 查阅。"
    },
    {
        "title": "Modular Visual Question Answering via Code Generation",
        "url": "http://arxiv.org/abs/2306.05392v1",
        "pub_date": "2023-06-08",
        "summary": "We present a framework that formulates visual question answering as modular\ncode generation. In contrast to prior work on modular approaches to VQA, our\napproach requires no additional training and relies on pre-trained language\nmodels (LMs), visual models pre-trained on image-caption pairs, and fifty VQA\nexamples used for in-context learning. The generated Python programs invoke and\ncompose the outputs of the visual models using arithmetic and conditional\nlogic. Our approach improves accuracy on the COVR dataset by at least 3% and on\nthe GQA dataset by roughly 2% compared to the few-shot baseline that does not\nemploy code generation.",
        "translated": "我们提出了一个框架，制定可视化问题回答作为模块化代码生成。与之前关于 VQA 模块化方法的工作相比，我们的方法不需要额外的培训，并且依赖于预先训练的语言模型(LM) ，在图像-标题对上预先训练的可视化模型以及用于上下文学习的50个 VQA 示例。生成的 Python 程序使用算术和条件逻辑调用和组合可视化模型的输出。我们的方法在 COVR 数据集上提高了至少3% 的准确性，在 GQA 数据集上提高了大约2% 的准确性，相比之下，不使用代码生成的少镜头基线。"
    },
    {
        "title": "Utterance Emotion Dynamics in Children's Poems: Emotional Changes Across\n  Age",
        "url": "http://arxiv.org/abs/2306.05387v1",
        "pub_date": "2023-06-08",
        "summary": "Emerging psychopathology studies are showing that patterns of changes in\nemotional state -- emotion dynamics -- are associated with overall well-being\nand mental health. More recently, there has been some work in tracking emotion\ndynamics through one's utterances, allowing for data to be collected on a\nlarger scale across time and people. However, several questions about how\nemotion dynamics change with age, especially in children, and when determined\nthrough children's writing, remain unanswered. In this work, we use both a\nlexicon and a machine learning based approach to quantify characteristics of\nemotion dynamics determined from poems written by children of various ages. We\nshow that both approaches point to similar trends: consistent increasing\nintensities for some emotions (e.g., anger, fear, joy, sadness, arousal, and\ndominance) with age and a consistent decreasing valence with age. We also find\nincreasing emotional variability, rise rates (i.e., emotional reactivity), and\nrecovery rates (i.e., emotional regulation) with age. These results act as a\nuseful baselines for further research in how patterns of emotions expressed by\nchildren change with age, and their association with mental health.",
        "translated": "新兴的精神病理学研究表明，情绪状态的变化模式——情绪动力学——与整体幸福感和心理健康有关。最近，已经有一些工作通过一个人的话语跟踪情绪动态，允许跨越时间和人的更大规模的数据收集。然而，一些关于情绪动态如何随着年龄变化的问题，特别是在儿童中，以及当通过儿童的写作决定时，仍然没有答案。本研究采用词汇学习和机器学习相结合的方法，对不同年龄段儿童诗歌的情绪动力学特征进行量化研究。我们发现，这两种方法都指向相似的趋势: 随着年龄的增长，某些情绪(例如，愤怒、恐惧、喜悦、悲伤、觉醒和支配)的强度持续增加，而随着年龄的增长，情绪的效价持续下降。我们还发现，随着年龄的增长，情绪波动性、情绪反应性和恢复率都在增加。这些结果为进一步研究儿童表达的情绪模式如何随年龄变化及其与心理健康的关系提供了有用的基线。"
    },
    {
        "title": "The ADAIO System at the BEA-2023 Shared Task on Generating AI Teacher\n  Responses in Educational Dialogues",
        "url": "http://arxiv.org/abs/2306.05360v1",
        "pub_date": "2023-06-08",
        "summary": "This paper presents the ADAIO team's system entry in the Building Educational\nApplications (BEA) 2023 Shared Task on Generating AI Teacher Responses in\nEducational Dialogues. The task aims to assess the performance of\nstate-of-the-art generative models as AI teachers in producing suitable\nresponses within a student-teacher dialogue. Our system comprises evaluating\nvarious baseline models using OpenAI GPT-3 and designing diverse prompts to\nprompt the OpenAI models for teacher response generation. After the challenge,\nour system achieved second place by employing a few-shot prompt-based approach\nwith the OpenAI text-davinci-003 model. The results highlight the few-shot\nlearning capabilities of large-language models, particularly OpenAI's GPT-3, in\nthe role of AI teachers.",
        "translated": "本文介绍了 ADAIO 团队的系统条目在建筑教育应用(BEA)2023共同任务生成人工智能教师在教育对话中的反应。这项任务旨在评估最先进的生成模式作为人工智能教师在学生-教师对话中产生适当反应的表现。我们的系统包括使用 OpenAI GPT-3评估各种基线模型，并设计不同的提示以提示 OpenAI 模型用于教师反应生成。经过挑战，我们的系统取得了第二名，采用了几个镜头的提示为基础的方法与 OpenAI 文本达芬奇003模型。研究结果强调了大型语言模型(尤其是 OpenAI 的 GPT-3)在人工智能教师角色中的少量学习能力。"
    },
    {
        "title": "Advancing Italian Biomedical Information Extraction with Large Language\n  Models: Methodological Insights and Multicenter Practical Application",
        "url": "http://arxiv.org/abs/2306.05323v1",
        "pub_date": "2023-06-08",
        "summary": "The introduction of computerized medical records in hospitals has reduced\nburdensome operations like manual writing and information fetching. However,\nthe data contained in medical records are still far underutilized, primarily\nbecause extracting them from unstructured textual medical records takes time\nand effort. Information Extraction, a subfield of Natural Language Processing,\ncan help clinical practitioners overcome this limitation, using automated\ntext-mining pipelines. In this work, we created the first Italian\nneuropsychiatric Named Entity Recognition dataset, PsyNIT, and used it to\ndevelop a Large Language Model for this task. Moreover, we conducted several\nexperiments with three external independent datasets to implement an effective\nmulticenter model, with overall F1-score 84.77%, Precision 83.16%, Recall\n86.44%. The lessons learned are: (i) the crucial role of a consistent\nannotation process and (ii) a fine-tuning strategy that combines classical\nmethods with a \"few-shot\" approach. This allowed us to establish methodological\nguidelines that pave the way for future implementations in this field and allow\nItalian hospitals to tap into important research opportunities.",
        "translated": "医院采用计算机化病历减少了手工书写和信息提取等繁重的操作。然而，包含在医疗记录中的数据仍然没有得到充分利用，主要是因为从非结构化的文本医疗记录中提取数据需要时间和精力。信息抽取是自然语言处理的一个子领域，通过使用自动文本挖掘管道，可以帮助临床医生克服这一限制。在这项工作中，我们创建了第一个意大利神经精神病命名实体识别数据集，PsyNIT，并使用它来开发这项任务的大型语言模型。此外，我们利用三个独立的外部数据集进行了多个实验，实现了一个有效的多中心模型，F1总分为84.77% ，精度为83.16% ，召回率为86.44% 。从中学到的经验教训是: (i)一致的注释过程的关键作用; (ii)将经典方法与“少量拍摄”方法相结合的微调策略。这使我们能够制定方法指南，为今后在这一领域的实施铺平道路，并使意大利医院能够利用重要的研究机会。"
    },
    {
        "title": "KIT's Multilingual Speech Translation System for IWSLT 2023",
        "url": "http://arxiv.org/abs/2306.05320v1",
        "pub_date": "2023-06-08",
        "summary": "Many existing speech translation benchmarks focus on native-English speech in\nhigh-quality recording conditions, which often do not match the conditions in\nreal-life use-cases. In this paper, we describe our speech translation system\nfor the multilingual track of IWSLT 2023, which focuses on the translation of\nscientific conference talks. The test condition features accented input speech\nand terminology-dense contents. The tasks requires translation into 10\nlanguages of varying amounts of resources. In absence of training data from the\ntarget domain, we use a retrieval-based approach (kNN-MT) for effective\nadaptation (+0.8 BLEU for speech translation). We also use adapters to easily\nintegrate incremental training data from data augmentation, and show that it\nmatches the performance of re-training. We observe that cascaded systems are\nmore easily adaptable towards specific target domains, due to their separate\nmodules. Our cascaded speech system substantially outperforms its end-to-end\ncounterpart on scientific talk translation, although their performance remains\nsimilar on TED talks.",
        "translated": "许多现有的语音翻译基准主要集中在高质量录音条件下的英语母语语音上，而这些语音翻译基准往往与现实生活中的语音翻译条件不匹配。本文介绍了我们为 IWSLT 2023多语种赛道开发的演讲翻译系统，该系统主要用于科学会议演讲的翻译。测试条件的特点是重音输入语音和术语密集的内容。这些任务需要翻译成10种不同数量资源的语言。在没有来自目标域的训练数据的情况下，我们使用基于检索的方法(kNN-MT)进行有效的自适应(语音翻译 + 0.8 BLEU)。我们还使用适配器方便地集成了来自数据增强的增量训练数据，并表明它与再训练的性能相匹配。我们观察到级联系统由于其独立的模块，更容易适应特定的目标域。我们的级联语音系统在科学演讲翻译方面大大优于其端到端的对应系统，尽管它们在 TED 演讲中的表现仍然相似。"
    },
    {
        "title": "CUED at ProbSum 2023: Hierarchical Ensemble of Summarization Models",
        "url": "http://arxiv.org/abs/2306.05317v1",
        "pub_date": "2023-06-08",
        "summary": "In this paper, we consider the challenge of summarizing patients' medical\nprogress notes in a limited data setting. For the Problem List Summarization\n(shared task 1A) at the BioNLP Workshop 2023, we demonstrate that Clinical-T5\nfine-tuned to 765 medical clinic notes outperforms other extractive,\nabstractive and zero-shot baselines, yielding reasonable baseline systems for\nmedical note summarization. Further, we introduce Hierarchical Ensemble of\nSummarization Models (HESM), consisting of token-level ensembles of diverse\nfine-tuned Clinical-T5 models, followed by Minimum Bayes Risk (MBR) decoding.\nOur HESM approach lead to a considerable summarization performance boost, and\nwhen evaluated on held-out challenge data achieved a ROUGE-L of 32.77, which\nwas the best-performing system at the top of the shared task leaderboard.",
        "translated": "在本文中，我们考虑的挑战，总结病人的医疗进展记录在有限的数据设置。对于2023年 BioNLP 研讨会上的问题列表摘要(共享任务1A) ，我们证明临床 T5对765个医疗诊所笔记进行微调优于其他提取，抽象和零拍基线，产生合理的医疗笔记摘要基线系统。此外，我们还介绍了分层总结模型集成(HESM) ，其由不同的微调临床 T5模型的令牌级集成组成，然后是最小贝叶斯风险(MBR)解码。我们的 HESM 方法导致了相当大的总结性能提升，并且当在坚持的挑战数据上进行评估时，ROUGE-L 达到了32.77，这是共享任务排行榜上表现最好的系统。"
    },
    {
        "title": "Are fairness metric scores enough to assess discrimination biases in\n  machine learning?",
        "url": "http://arxiv.org/abs/2306.05307v1",
        "pub_date": "2023-06-08",
        "summary": "This paper presents novel experiments shedding light on the shortcomings of\ncurrent metrics for assessing biases of gender discrimination made by machine\nlearning algorithms on textual data. We focus on the Bios dataset, and our\nlearning task is to predict the occupation of individuals, based on their\nbiography. Such prediction tasks are common in commercial Natural Language\nProcessing (NLP) applications such as automatic job recommendations. We address\nan important limitation of theoretical discussions dealing with group-wise\nfairness metrics: they focus on large datasets, although the norm in many\nindustrial NLP applications is to use small to reasonably large linguistic\ndatasets for which the main practical constraint is to get a good prediction\naccuracy. We then question how reliable are different popular measures of bias\nwhen the size of the training set is simply sufficient to learn reasonably\naccurate predictions. Our experiments sample the Bios dataset and learn more\nthan 200 models on different sample sizes. This allows us to statistically\nstudy our results and to confirm that common gender bias indices provide\ndiverging and sometimes unreliable results when applied to relatively small\ntraining and test samples. This highlights the crucial importance of variance\ncalculations for providing sound results in this field.",
        "translated": "本文介绍了一些新颖的实验，揭示了目前机器学习算法对文本数据进行性别歧视偏差评估的指标存在的缺陷。我们的重点是生物数据集，我们的学习任务是预测个人的职业，根据他们的传记。这种预测任务在商业自然语言处理(NLP)应用程序(如自动工作推荐)中很常见。我们解决了关于群体公平性度量的理论讨论的一个重要局限性: 它们集中在大数据集上，尽管在许多工业 NLP 应用中的规范是使用小到合理的大语言数据集，其主要的实际限制是获得良好的预测精度。然后我们质疑当训练集的大小仅仅足以学习合理准确的预测时，不同的流行的偏倚测量方法的可靠性。我们的实验样本的 Bios 数据集和学习超过200个不同样本大小的模型。这使我们能够统计研究我们的结果，并确认共同的性别偏见指数提供不同的，有时不可靠的结果时，适用于相对较小的训练和测试样本。这突出了方差计算对于在这一领域提供可靠结果的至关重要性。"
    },
    {
        "title": "ToolAlpaca: Generalized Tool Learning for Language Models with 3000\n  Simulated Cases",
        "url": "http://arxiv.org/abs/2306.05301v1",
        "pub_date": "2023-06-08",
        "summary": "Enabling large language models to effectively utilize real-world tools is\ncrucial for achieving embodied intelligence. Existing approaches to tool\nlearning have primarily relied on either extremely large language models, such\nas GPT-4, to attain generalized tool-use abilities in a zero-shot manner, or\nhave utilized supervised learning to train limited types of tools on compact\nmodels. However, it remains uncertain whether smaller language models can\nachieve generalized tool-use abilities without specific tool-specific training.\nTo address this question, this paper introduces ToolAlpaca, a novel framework\ndesigned to automatically generate a tool-use corpus and learn generalized\ntool-use abilities on compact language models with minimal human intervention.\nSpecifically, ToolAlpaca first collects a comprehensive dataset by building a\nmulti-agent simulation environment, which contains 3938 tool-use instances from\nmore than 400 real-world tool APIs spanning 50 distinct categories.\nSubsequently, the constructed corpus is employed to fine-tune compact language\nmodels, resulting in two models, namely ToolAlpaca-7B and ToolAlpaca-13B,\nrespectively. Finally, we evaluate the ability of these models to utilize\npreviously unseen tools without specific training. Experimental results\ndemonstrate that ToolAlpaca achieves effective generalized tool-use\ncapabilities comparable to those of extremely large language models like\nGPT-3.5. This validation supports the notion that learning generalized tool-use\nabilities is feasible for compact language models.",
        "translated": "使大型语言模型能够有效地利用现实世界中的工具对于实现内嵌智能是至关重要的。现有的工具学习方法主要依赖于极其庞大的语言模型，如 GPT-4，以零打击的方式获得广义的工具使用能力，或者利用监督式学习在紧凑模型上训练有限类型的工具。然而，小型语言模型是否能够在没有特定工具训练的情况下实现工具使用能力的普遍化仍然是个未知数。为了解决这个问题，本文介绍了 ToolAlpaca，这是一个新的框架，它可以自动生成一个工具使用语料库，并在最少人工干预的情况下学习紧凑语言模型上的广义工具使用能力。具体来说，ToolAlpaca 首先通过构建一个多代理仿真环境来收集一个全面的数据集，该环境包含来自400多个实际工具 API 的3938个工具使用实例，这些 API 跨越50个不同的类别。然后，利用构建的语料库对紧凑语言模型进行微调，得到两个模型，分别为 ToolAlpaca-7B 和 ToolAlpaca-13B。最后，我们评估这些模型在没有特定训练的情况下利用以前看不见的工具的能力。实验结果表明，ToolAlpaca 实现了有效的广义工具使用能力，可以与 GPT-3.5这样的超大型语言模型相媲美。这种验证支持这样一种观点，即学习广义的工具使用能力对于紧凑的语言模型是可行的。"
    },
    {
        "title": "How Can Recommender Systems Benefit from Large Language Models: A Survey",
        "url": "http://arxiv.org/abs/2306.05817v1",
        "pub_date": "2023-06-09",
        "summary": "Recommender systems (RS) play important roles to match users' information\nneeds for Internet applications. In natural language processing (NLP) domains,\nlarge language model (LLM) has shown astonishing emergent abilities (e.g.,\ninstruction following, reasoning), thus giving rise to the promising research\ndirection of adapting LLM to RS for performance enhancements and user\nexperience improvements. In this paper, we conduct a comprehensive survey on\nthis research direction from an application-oriented view. We first summarize\nexisting research works from two orthogonal perspectives: where and how to\nadapt LLM to RS. For the \"WHERE\" question, we discuss the roles that LLM could\nplay in different stages of the recommendation pipeline, i.e., feature\nengineering, feature encoder, scoring/ranking function, and pipeline\ncontroller. For the \"HOW\" question, we investigate the training and inference\nstrategies, resulting in two fine-grained taxonomy criteria, i.e., whether to\ntune LLMs or not, and whether to involve conventional recommendation model\n(CRM) for inference. Detailed analysis and general development trajectories are\nprovided for both questions, respectively. Then, we highlight key challenges in\nadapting LLM to RS from three aspects, i.e., efficiency, effectiveness, and\nethics. Finally, we summarize the survey and discuss the future prospects. We\nalso actively maintain a GitHub repository for papers and other related\nresources in this rising direction:\n$\\href{https://github.com/CHIANGEL/Awesome-LLM-for-RecSys}{[GitHub\\;Link]}$.",
        "translated": "推荐系统(RS)在满足互联网应用的用户信息需求方面发挥着重要作用。在自然语言处理(NLP)领域，大语言模型(LLM)表现出惊人的涌现能力(如指令跟随、推理) ，从而引发了将 LLM 应用于 RS 以提高性能和改善用户体验的研究方向。本文从应用导向的角度对这一研究方向进行了全面综述。本文首先从两个正交的角度对现有的研究工作进行了总结: 在何处以及如何使 LLM 适应 RS。对于“ WHERE”问题，我们讨论 LLM 在推荐流水线的不同阶段可以扮演的角色，即特征工程、特征编码器、评分/排名函数和流水线控制器。对于“如何”问题，我们研究了训练和推理策略，产生了两个细粒度的分类标准，即是否调优 LLM，以及是否涉及传统的推荐模型(CRM)进行推理。对这两个问题分别提供了详细的分析和一般的开发轨迹。然后，从效率、有效性和道德三个方面，重点阐述了长期管理适应 RS 所面临的主要挑战。最后，对调查结果进行了总结，并对未来进行了展望。我们还积极地维护一个 gitHub 存储库，用于存放论文和其他相关资源，这是一个不断发展的方向: $href { https://GitHub.com/chiangel/awesome-llm-for-recsys }{[ gitHub; Link ]}} $。"
    },
    {
        "title": "Interactive Explanation with Varying Level of Details in an Explainable\n  Scientific Literature Recommender System",
        "url": "http://arxiv.org/abs/2306.05809v1",
        "pub_date": "2023-06-09",
        "summary": "Explainable recommender systems (RS) have traditionally followed a\none-size-fits-all approach, delivering the same explanation level of detail to\neach user, without considering their individual needs and goals. Further,\nexplanations in RS have so far been presented mostly in a static and\nnon-interactive manner. To fill these research gaps, we aim in this paper to\nadopt a user-centered, interactive explanation model that provides explanations\nwith different levels of detail and empowers users to interact with, control,\nand personalize the explanations based on their needs and preferences. We\nfollowed a user-centered approach to design interactive explanations with three\nlevels of detail (basic, intermediate, and advanced) and implemented them in\nthe transparent Recommendation and Interest Modeling Application (RIMA). We\nconducted a qualitative user study (N=14) to investigate the impact of\nproviding interactive explanations with varying level of details on the users'\nperception of the explainable RS. Our study showed qualitative evidence that\nfostering interaction and giving users control in deciding which explanation\nthey would like to see can meet the demands of users with different needs,\npreferences, and goals, and consequently can have positive effects on different\ncrucial aspects in explainable recommendation, including transparency, trust,\nsatisfaction, and user experience.",
        "translated": "可解释的推荐系统(RS)传统上遵循一种一刀切的方法，向每个用户提供相同的详细解释水平，而不考虑他们的个人需求和目标。此外，到目前为止，RS 中的解释大多是以静态和非交互的方式提出的。为了填补这些研究空白，本文的目标是采用一种以用户为中心的交互式解释模型，该模型提供不同层次的详细解释，并使用户能够根据自己的需求和偏好进行交互、控制和个性化解释。我们遵循以用户为中心的方法来设计具有三个细节层次(基础、中级和高级)的交互式解释，并在透明的推荐和兴趣建模应用程序(RIMA)中实现它们。我们进行了一项定性的用户研究(N = 14) ，以调查不同程度的细节提供交互式解释对用户感知可解释 RS 的影响。我们的研究显示，定性的证据表明，培养互动和让用户控制决定他们想要看到的解释可以满足不同需求，偏好和目标的用户的需求，因此可以对解释性推荐的不同关键方面产生积极的影响，包括透明度，信任，满意度和用户体验。"
    },
    {
        "title": "RankFormer: Listwise Learning-to-Rank Using Listwide Labels",
        "url": "http://arxiv.org/abs/2306.05808v1",
        "pub_date": "2023-06-09",
        "summary": "Web applications where users are presented with a limited selection of items\nhave long employed ranking models to put the most relevant results first. Any\nfeedback received from users is typically assumed to reflect a relative\njudgement on the utility of items, e.g. a user clicking on an item only implies\nit is better than items not clicked in the same ranked list. Hence, the\nobjectives optimized in Learning-to-Rank (LTR) tend to be pairwise or listwise.\n  Yet, by only viewing feedback as relative, we neglect the user's absolute\nfeedback on the list's overall quality, e.g. when no items in the selection are\nclicked. We thus reconsider the standard LTR paradigm and argue the benefits of\nlearning from this listwide signal. To this end, we propose the RankFormer as\nan architecture that, with a Transformer at its core, can jointly optimize a\nnovel listwide assessment objective and a traditional listwise LTR objective.\n  We simulate implicit feedback on public datasets and observe that the\nRankFormer succeeds in benefitting from listwide signals. Additionally, we\nconduct experiments in e-commerce on Amazon Search data and find the RankFormer\nto be superior to all baselines offline. An online experiment shows that\nknowledge distillation can be used to find immediate practical use for the\nRankFormer.",
        "translated": "在 Web 应用程序中，用户只能看到有限的条目，这种情况长期以来一直采用排名模型，将最相关的结果放在第一位。从用户收到的任何反馈通常被认为反映了对项目效用的相对判断，例如，用户点击一个项目只意味着它比没有在同一排名列表中点击的项目要好。因此，学习排名(Learning-to-Rank，LTR)中优化的目标往往是成对的或列表的。然而，由于只把反馈看作是相对的，我们忽略了用户对列表整体质量的绝对反馈，例如，当选择中没有项被点击的时候。因此，我们重新考虑标准的 LTR 范式，并讨论从这个列表范围的信号中学习的好处。为此，我们提出 RankForm 作为一种体系结构，其核心是一个 Transformer，可以联合优化一个新的列表范围评估目标和一个传统的列表式 LTR 目标。我们模拟公共数据集上的隐式反馈，并观察到 RankForm 成功地从列表宽信号中受益。此外，我们在亚马逊搜索数据上进行电子商务实验，发现排名前优于所有离线基线。一个在线实验表明，知识提取可以用来找到直接的实际应用的秩次前。"
    },
    {
        "title": "Customizing General-Purpose Foundation Models for Medical Report\n  Generation",
        "url": "http://arxiv.org/abs/2306.05642v1",
        "pub_date": "2023-06-09",
        "summary": "Medical caption prediction which can be regarded as a task of medical report\ngeneration (MRG), requires the automatic generation of coherent and accurate\ncaptions for the given medical images. However, the scarcity of labelled\nmedical image-report pairs presents great challenges in the development of deep\nand large-scale neural networks capable of harnessing the potential artificial\ngeneral intelligence power like large language models (LLMs). In this work, we\npropose customizing off-the-shelf general-purpose large-scale pre-trained\nmodels, i.e., foundation models (FMs), in computer vision and natural language\nprocessing with a specific focus on medical report generation. Specifically,\nfollowing BLIP-2, a state-of-the-art vision-language pre-training approach, we\nintroduce our encoder-decoder-based MRG model. This model utilizes a\nlightweight query Transformer to connect two FMs: the giant vision Transformer\nEVA-ViT-g and a bilingual LLM trained to align with human intentions (referred\nto as ChatGLM-6B). Furthermore, we conduct ablative experiments on the\ntrainable components of the model to identify the crucial factors for effective\ntransfer learning. Our findings demonstrate that unfreezing EVA-ViT-g to learn\nmedical image representations, followed by parameter-efficient training of\nChatGLM-6B to capture the writing styles of medical reports, is essential for\nachieving optimal results. Our best attempt (PCLmed Team) achieved the 4th and\nthe 2nd, respectively, out of 13 participating teams, based on the BERTScore\nand ROUGE-1 metrics, in the ImageCLEFmedical Caption 2023 Caption Prediction\nTask competition.",
        "translated": "医学字幕预测是医学报告生成的一项重要任务，它要求为给定的医学图像自动生成连贯、准确的医学字幕。然而，标记的医学图像-报告对的稀缺性给深度和大规模神经网络的发展提出了巨大的挑战，这些神经网络能够利用潜在的人工通用智能能力，如大语言模型(LLM)。在这项工作中，我们建议定制现成的通用大规模预训练模型，即基础模型(FM) ，在计算机视觉和自然语言处理，特别是医疗报告生成的重点。具体来说，在 BLIP-2(一种最先进的视觉语言预训练方法)之后，我们介绍了基于编码器-解码器的 MRG 模型。该模型使用一个轻量级查询 Transformer 连接两个 FM: 巨大的愿景跑车 EVA-ViT-g 和一个双语 LLM，后者经过训练以符合人类意图(称为 ChatGLM-6B)。此外，我们还对模型的可训练部分进行了烧蚀实验，以确定有效迁移学习的关键因素。我们的研究结果表明，将 EVA-ViT-g 解冻以学习医学图像表示，然后对 ChatGLM-6B 进行参数有效的训练以捕获医学报告的写作风格，对于实现最佳结果至关重要。根据 BERTScore 和 ROUGE-1指标，在 ImageCLEFMedical Caption 2023字幕预测任务竞赛中，我们的最佳尝试(PCLmed Team)分别在13个参赛团队中获得第4名和第2名。"
    },
    {
        "title": "Bayesian Knowledge-driven Critiquing with Indirect Evidence",
        "url": "http://arxiv.org/abs/2306.05636v1",
        "pub_date": "2023-06-09",
        "summary": "Conversational recommender systems (CRS) enhance the expressivity and\npersonalization of recommendations through multiple turns of user-system\ninteraction. Critiquing is a well-known paradigm for CRS that allows users to\niteratively refine recommendations by providing feedback about attributes of\nrecommended items. While existing critiquing methodologies utilize direct\nattributes of items to address user requests such as 'I prefer Western movies',\nthe opportunity of incorporating richer contextual and side information about\nitems stored in Knowledge Graphs (KG) into the critiquing paradigm has been\noverlooked. Employing this substantial knowledge together with a\nwell-established reasoning methodology paves the way for critique-based\nrecommenders to allow for complex knowledge-based feedback (e.g., 'I like\nmovies featuring war side effects on veterans') which may arise in natural\nuser-system conversations. In this work, we aim to increase the flexibility of\ncritique-based recommendation by integrating KGs and propose a novel Bayesian\ninference framework that enables reasoning with relational knowledge-based\nfeedback. We study and formulate the framework considering a Gaussian\nlikelihood and evaluate it on two well-known recommendation datasets with KGs.\nOur evaluations demonstrate the effectiveness of our framework in leveraging\nindirect KG-based feedback (i.e., preferred relational properties of items\nrather than preferred items themselves), often improving personalized\nrecommendations over a one-shot recommender by more than 15%. This work enables\na new paradigm for using rich knowledge content and reasoning over indirect\nevidence as a mechanism for critiquing interactions with CRS.",
        "translated": "会话推荐系统(CRS)通过多轮用户系统交互增强推荐的表达能力和个性化。批评是 CRS 的一个众所周知的范例，它允许用户通过提供关于推荐项目属性的反馈来迭代地完善推荐。虽然现有的批评方法利用项目的直接属性来满足用户的要求，例如“我更喜欢西部电影”，但是将知识图表(KG)中存储的项目的更丰富的上下文和侧面信息纳入批评范式的机会被忽视了。使用这些实质性的知识和一个完善的推理方法为基于评论的推荐者铺平了道路，以允许复杂的基于知识的反馈(例如，“我喜欢有退伍军人战争副作用的电影”) ，这可能出现在自然的用户系统对话中。在这项工作中，我们的目标是通过整合幼稚园来增加基于批判的推荐的灵活性，并提出一个新的贝叶斯推断框架，使推理与关系知识为基础的反馈。我们研究并制定了考虑高斯似然的框架，并在两个著名的 KG 推荐数据集上进行了评估。我们的评估表明，我们的框架在利用间接的基于 KG 的反馈(即，项目的首选关系属性，而不是首选项本身)方面的有效性，通常比一次性推荐提高个性化推荐超过15% 。这项工作为使用丰富的知识内容和推理间接证据作为一种机制批判与 CRS 的相互作用提供了一个新的范例。"
    },
    {
        "title": "Leveraging Large Language Models for Scalable Vector Graphics-Driven\n  Image Understanding",
        "url": "http://arxiv.org/abs/2306.06094v1",
        "pub_date": "2023-06-09",
        "summary": "Recently, large language models (LLMs) have made significant advancements in\nnatural language understanding and generation. However, their potential in\ncomputer vision remains largely unexplored. In this paper, we introduce a new,\nexploratory approach that enables LLMs to process images using the Scalable\nVector Graphics (SVG) format. By leveraging the XML-based textual descriptions\nof SVG representations instead of raster images, we aim to bridge the gap\nbetween the visual and textual modalities, allowing LLMs to directly understand\nand manipulate images without the need for parameterized visual components. Our\nmethod facilitates simple image classification, generation, and in-context\nlearning using only LLM capabilities. We demonstrate the promise of our\napproach across discriminative and generative tasks, highlighting its (i)\nrobustness against distribution shift, (ii) substantial improvements achieved\nby tapping into the in-context learning abilities of LLMs, and (iii) image\nunderstanding and generation capabilities with human guidance. Our code, data,\nand models can be found here https://github.com/mu-cai/svg-llm.",
        "translated": "近年来，大型语言模型(LLM)在自然语言理解和生成方面取得了显著的进展。然而，它们在计算机视觉方面的潜力在很大程度上仍未得到开发。在这篇文章中，我们介绍了一种新的探索性的方法，使 LLM 能够使用可缩放向量图形(SVG)格式来处理图像。通过利用基于 XML 的 SVG 表示的文本描述而不是栅格图像，我们的目标是弥合视觉和文本模式之间的差距，允许 LLM 直接理解和操作图像，而不需要参数化的视觉组件。我们的方法有助于简单的图像分类，生成，并在上下文学习使用 LLM 的能力。我们展示了我们在歧视性和生成性任务中的方法的前景，强调了其(i)对分布转移的稳健性，(ii)通过利用 LLM 的上下文学习能力实现的实质性改进，以及(iii)图像理解和生成能力与人类指导。我们的代码、数据和模型可以在这里找到 https://github.com/mu-cai/svg-llm。"
    },
    {
        "title": "Developing Speech Processing Pipelines for Police Accountability",
        "url": "http://arxiv.org/abs/2306.06086v1",
        "pub_date": "2023-06-09",
        "summary": "Police body-worn cameras have the potential to improve accountability and\ntransparency in policing. Yet in practice, they result in millions of hours of\nfootage that is never reviewed. We investigate the potential of large\npre-trained speech models for facilitating reviews, focusing on ASR and officer\nspeech detection in footage from traffic stops. Our proposed pipeline includes\ntraining data alignment and filtering, fine-tuning with resource constraints,\nand combining officer speech detection with ASR for a fully automated approach.\nWe find that (1) fine-tuning strongly improves ASR performance on officer\nspeech (WER=12-13%), (2) ASR on officer speech is much more accurate than on\ncommunity member speech (WER=43.55-49.07%), (3) domain-specific tasks like\nofficer speech detection and diarization remain challenging. Our work offers\npractical applications for reviewing body camera footage and general guidance\nfor adapting pre-trained speech models to noisy multi-speaker domains.",
        "translated": "警察身上佩戴的摄像头有可能改善警务工作的问责制和透明度。然而在实践中，他们导致数百万小时的镜头，从来没有审查。我们调查的潜力，大型预先训练的语音模型，以促进审查，侧重于 ASR 和官员的语音检测镜头从交通停止。我们提出的流水线包括训练数据对齐和过滤，与资源约束的微调，并结合官员语音检测和 ASR 为一个完全自动化的方法。我们发现: (1)微调有力地提高了官员语音的 ASR 性能(WER = 12-13%) ，(2)官员语音的 ASR 比社区成员语音的 ASR 更准确(WER = 43.55-49.07%) ，(3)官员语音检测和数字化等领域特定任务仍然具有挑战性。我们的工作提供了实际应用，审查身体摄像机镜头和一般指导适应预先训练的语音模型噪声多扬声器领域。"
    },
    {
        "title": "Trapping LLM Hallucinations Using Tagged Context Prompts",
        "url": "http://arxiv.org/abs/2306.06085v1",
        "pub_date": "2023-06-09",
        "summary": "Recent advances in large language models (LLMs), such as ChatGPT, have led to\nhighly sophisticated conversation agents. However, these models suffer from\n\"hallucinations,\" where the model generates false or fabricated information.\nAddressing this challenge is crucial, particularly with AI-driven platforms\nbeing adopted across various sectors. In this paper, we propose a novel method\nto recognize and flag instances when LLMs perform outside their domain\nknowledge, and ensuring users receive accurate information.\n  We find that the use of context combined with embedded tags can successfully\ncombat hallucinations within generative language models. To do this, we\nbaseline hallucination frequency in no-context prompt-response pairs using\ngenerated URLs as easily-tested indicators of fabricated data. We observed a\nsignificant reduction in overall hallucination when context was supplied along\nwith question prompts for tested generative engines. Lastly, we evaluated how\nplacing tags within contexts impacted model responses and were able to\neliminate hallucinations in responses with 98.88% effectiveness.",
        "translated": "大型语言模型(LLM)的最新进展，如 ChatGPT，已经导致了高度复杂的会话代理。然而，这些模型遭受“幻觉”，即模型产生虚假或捏造的信息。应对这一挑战至关重要，特别是在各个部门都在采用人工智能驱动的平台的情况下。在本文中，我们提出了一种新的方法来识别和标记实例时，LLM 执行领域外的知识，并确保用户接收准确的信息。我们发现使用上下文结合嵌入式标签可以成功地战胜生成语言模型中的幻觉。为此，我们使用生成的 URL 作为编造数据的容易测试的指标，对无上下文提示-响应对中的幻觉频率进行基线测试。我们观察到整体幻觉的显着减少时，上下文提供的问题提示测试生成引擎。最后，我们评估了在上下文中放置标签是如何影响模型反应的，并且能够以98.88% 的有效率消除反应中的幻觉。"
    },
    {
        "title": "Mind2Web: Towards a Generalist Agent for the Web",
        "url": "http://arxiv.org/abs/2306.06070v1",
        "pub_date": "2023-06-09",
        "summary": "We introduce Mind2Web, the first dataset for developing and evaluating\ngeneralist agents for the web that can follow language instructions to complete\ncomplex tasks on any website. Existing datasets for web agents either use\nsimulated websites or only cover a limited set of websites and tasks, thus not\nsuitable for generalist web agents. With over 2,000 open-ended tasks collected\nfrom 137 websites spanning 31 domains and crowdsourced action sequences for the\ntasks, Mind2Web provides three necessary ingredients for building generalist\nweb agents: 1) diverse domains, websites, and tasks, 2) use of real-world\nwebsites instead of simulated and simplified ones, and 3) a broad spectrum of\nuser interaction patterns. Based on Mind2Web, we conduct an initial exploration\nof using large language models (LLMs) for building generalist web agents. While\nthe raw HTML of real-world websites are often too large to be fed to LLMs, we\nshow that first filtering it with a small LM significantly improves the\neffectiveness and efficiency of LLMs. Our solution demonstrates a decent level\nof performance, even on websites or entire domains the model has never seen\nbefore, but there is still a substantial room to improve towards truly\ngeneralizable agents. We open-source our dataset, model implementation, and\ntrained models (https://osu-nlp-group.github.io/Mind2Web) to facilitate further\nresearch on building a generalist agent for the web.",
        "translated": "我们介绍 Mind2Web，第一个用于开发和评估通用网络代理的数据集，这些代理可以按照语言指令在任何网站上完成复杂的任务。现有的 Web 代理数据集要么使用模拟网站，要么只覆盖有限的一组网站和任务，因此不适合于通用 Web 代理。Mind2Web 从31个领域的137个网站中收集了超过2000个开放式任务，并为这些任务提供了众包的动作序列。 Mind2Web 为构建通用网络代理提供了三个必要的组成部分: 1)不同的领域、网站和任务; 2)使用真实世界的网站而不是模拟和简化的网站; 3)广泛的用户交互模式。基于 Mind2Web，我们对使用大型语言模型(LLM)构建通用 Web 代理进行了初步探索。虽然现实世界中网站的原始 HTML 通常太大而无法提供给 LLM，但我们表明，首先使用小型 LM 对其进行过滤可以显著提高 LLM 的有效性和效率。我们的解决方案展示了一个不错的性能水平，甚至在模型从未见过的网站或整个域上，但是仍然有很大的空间来改进真正可推广的代理。我们开源我们的数据集，模型实现，和训练有素的模型( https://osu-nlp-group.github.io/mind2web ) ，以促进进一步的研究建立一个通用的代理网站。"
    },
    {
        "title": "Assisting Language Learners: Automated Trans-Lingual Definition\n  Generation via Contrastive Prompt Learning",
        "url": "http://arxiv.org/abs/2306.06058v1",
        "pub_date": "2023-06-09",
        "summary": "The standard definition generation task requires to automatically produce\nmono-lingual definitions (e.g., English definitions for English words), but\nignores that the generated definitions may also consist of unfamiliar words for\nlanguage learners. In this work, we propose a novel task of Trans-Lingual\nDefinition Generation (TLDG), which aims to generate definitions in another\nlanguage, i.e., the native speaker's language. Initially, we explore the\nunsupervised manner of this task and build up a simple implementation of\nfine-tuning the multi-lingual machine translation model. Then, we develop two\nnovel methods, Prompt Combination and Contrastive Prompt Learning, for further\nenhancing the quality of the generation. Our methods are evaluated against the\nbaseline Pipeline method in both rich- and low-resource settings, and we\nempirically establish its superiority in generating higher-quality\ntrans-lingual definitions.",
        "translated": "标准的定义生成任务要求自动生成单语言定义(例如，英语单词的英语定义) ，但是忽略了生成的定义也可能包含语言学习者不熟悉的单词。在这项工作中，我们提出了一个新颖的任务跨语言定义生成(TLDG) ，其目的是生成另一种语言的定义，即母语说话人的语言。最初，我们探讨了这项任务的无监督方式，并建立了一个简单的实现，微调多语种机器翻译模型。然后，为了进一步提高生成的质量，我们开发了两种新的方法，即即时组合和对比即时学习。在资源丰富和资源少的情况下，我们对比基线流水线方法对我们的方法进行了评估，并且我们经验性地建立了它在产生更高质量的跨语言定义方面的优势。"
    },
    {
        "title": "FinGPT: Open-Source Financial Large Language Models",
        "url": "http://arxiv.org/abs/2306.06031v1",
        "pub_date": "2023-06-09",
        "summary": "Large language models (LLMs) have shown the potential of revolutionizing\nnatural language processing tasks in diverse domains, sparking great interest\nin finance. Accessing high-quality financial data is the first challenge for\nfinancial LLMs (FinLLMs). While proprietary models like BloombergGPT have taken\nadvantage of their unique data accumulation, such privileged access calls for\nan open-source alternative to democratize Internet-scale financial data.\n  In this paper, we present an open-source large language model, FinGPT, for\nthe finance sector. Unlike proprietary models, FinGPT takes a data-centric\napproach, providing researchers and practitioners with accessible and\ntransparent resources to develop their FinLLMs. We highlight the importance of\nan automatic data curation pipeline and the lightweight low-rank adaptation\ntechnique in building FinGPT. Furthermore, we showcase several potential\napplications as stepping stones for users, such as robo-advising, algorithmic\ntrading, and low-code development. Through collaborative efforts within the\nopen-source AI4Finance community, FinGPT aims to stimulate innovation,\ndemocratize FinLLMs, and unlock new opportunities in open finance. Two\nassociated code repos are \\url{https://github.com/AI4Finance-Foundation/FinGPT}\nand \\url{https://github.com/AI4Finance-Foundation/FinNLP}",
        "translated": "大型语言模型(LLM)显示了在不同领域革新自然语言处理任务的潜力，引起了人们对金融的极大兴趣。访问高质量的金融数据是金融 LLM (FinLLM)面临的第一个挑战。虽然像 BloombergGPT 这样的专有模型已经利用了它们独特的数据积累，但是这种特权访问需要一种开放源码的替代方案来使互联网规模的金融数据民主化。在本文中，我们为金融部门提出了一个开源的大型语言模型 FinGPT。与专有模型不同，FinGPT 采用以数据为中心的方法，为研究人员和从业人员提供可访问和透明的资源，以开发他们的 FinLLM。我们强调了自动数据管道和轻量级低级自适应技术在构建 FinGPT 中的重要性。此外，我们展示了几个潜在的应用程序作为用户的垫脚石，如机器人建议，算法交易和低代码开发。通过开源 AI4Finance 社区内部的协作努力，FinGPT 旨在激励创新，使 FinLLM 民主化，并在开放金融领域释放新的机遇。两个相关的代码回购是 url { https://github.com/ai4finance-foundation/fingpt }和 url { https://github.com/ai4finance-foundation/finnlp }"
    },
    {
        "title": "HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence\n  for Digital Medicine",
        "url": "http://arxiv.org/abs/2306.06029v1",
        "pub_date": "2023-06-09",
        "summary": "Providing high quality explanations for AI predictions based on machine\nlearning is a challenging and complex task. To work well it requires, among\nother factors: selecting a proper level of generality/specificity of the\nexplanation; considering assumptions about the familiarity of the explanation\nbeneficiary with the AI task under consideration; referring to specific\nelements that have contributed to the decision; making use of additional\nknowledge (e.g. expert evidence) which might not be part of the prediction\nprocess; and providing evidence supporting negative hypothesis. Finally, the\nsystem needs to formulate the explanation in a clearly interpretable, and\npossibly convincing, way. Given these considerations, ANTIDOTE fosters an\nintegrated vision of explainable AI, where low-level characteristics of the\ndeep learning process are combined with higher level schemes proper of the\nhuman argumentation capacity. ANTIDOTE will exploit cross-disciplinary\ncompetences in deep learning and argumentation to support a broader and\ninnovative view of explainable AI, where the need for high-quality explanations\nfor clinical cases deliberation is critical. As a first result of the project,\nwe publish the Antidote CasiMedicos dataset to facilitate research on\nexplainable AI in general, and argumentation in the medical domain in\nparticular.",
        "translated": "为基于机器学习的人工智能预测提供高质量的解释是一项具有挑战性和复杂性的任务。要做好这项工作，除了其他因素之外，还需要: 选择适当水平的解释的一般性/特异性; 考虑关于解释受益人对正在考虑的 AI 任务的熟悉程度的假设; 参考对决策有贡献的特定元素; 利用额外的知识(例如专家证据) ，这可能不是预测过程的一部分; 以及提供支持负面假设的证据。最后，系统需要以一种清晰可解释的、可能令人信服的方式来阐述解释。考虑到这些因素，ANTIDOTE 培养了一种可解释人工智能的综合视野，其中深度学习过程的低水平特征与适合人类论证能力的高水平方案相结合。ANTIDOTE 将利用深度学习和论证方面的跨学科能力，以支持对可解释 AI 的更广泛和创新的观点，其中对临床病例审议的高质量解释的需求是至关重要的。作为这个项目的第一个成果，我们发布了解毒剂 CasiMedicos 数据集，以促进对可解释人工智能的研究，特别是在医学领域的论证。"
    },
    {
        "title": "Automated Labeling of German Chest X-Ray Radiology Reports using Deep\n  Learning",
        "url": "http://arxiv.org/abs/2306.05997v1",
        "pub_date": "2023-06-09",
        "summary": "Radiologists are in short supply globally, and deep learning models offer a\npromising solution to address this shortage as part of clinical\ndecision-support systems. However, training such models often requires\nexpensive and time-consuming manual labeling of large datasets. Automatic label\nextraction from radiology reports can reduce the time required to obtain\nlabeled datasets, but this task is challenging due to semantically similar\nwords and missing annotated data. In this work, we explore the potential of\nweak supervision of a deep learning-based label prediction model, using a\nrule-based labeler. We propose a deep learning-based CheXpert label prediction\nmodel, pre-trained on reports labeled by a rule-based German CheXpert model and\nfine-tuned on a small dataset of manually labeled reports. Our results\ndemonstrate the effectiveness of our approach, which significantly outperformed\nthe rule-based model on all three tasks. Our findings highlight the benefits of\nemploying deep learning-based models even in scenarios with sparse data and the\nuse of the rule-based labeler as a tool for weak supervision.",
        "translated": "放射科医生在全球范围内供不应求，而深度学习模式作为临床决策支持系统的一部分，为解决这一短缺提供了一个有希望的解决方案。然而，训练这样的模型通常需要昂贵和耗时的大型数据集的手动标记。从放射学报告中自动提取标签可以减少获得标签数据集所需的时间，但是由于语义相似的单词和缺少注释数据，这项任务是具有挑战性的。在这项工作中，我们探讨了弱监督的潜力，一个基于深度学习的标签预测模型，使用基于规则的标签。我们提出了一个基于深度学习的 CheXpert 标签预测模型，该模型预先对基于规则的德国 CheXpert 模型标记的报告进行训练，并对手动标记的小数据集进行微调。我们的研究结果证明了我们的方法的有效性，它在所有三个任务上都明显优于基于规则的模型。我们的研究结果强调了使用基于深度学习的模型的好处，即使是在数据稀少的情况下，以及使用基于规则的标签器作为薄弱监督的工具。"
    },
    {
        "title": "Language Models Can Learn Exceptions to Syntactic Rules",
        "url": "http://arxiv.org/abs/2306.05969v1",
        "pub_date": "2023-06-09",
        "summary": "Artificial neural networks can generalize productively to novel contexts. Can\nthey also learn exceptions to those productive rules? We explore this question\nusing the case of restrictions on English passivization (e.g., the fact that\n\"The vacation lasted five days\" is grammatical, but \"*Five days was lasted by\nthe vacation\" is not). We collect human acceptability judgments for passive\nsentences with a range of verbs, and show that the probability distribution\ndefined by GPT-2, a language model, matches the human judgments with high\ncorrelation. We also show that the relative acceptability of a verb in the\nactive vs. passive voice is positively correlated with the relative frequency\nof its occurrence in those voices. These results provide preliminary support\nfor the entrenchment hypothesis, according to which learners track and uses the\ndistributional properties of their input to learn negative exceptions to rules.\nAt the same time, this hypothesis fails to explain the magnitude of\nunpassivizability demonstrated by certain individual verbs, suggesting that\nother cues to exceptionality are available in the linguistic input.",
        "translated": "人工神经网络可以有效地推广到新的上下文。他们是否也能学到这些生产规则的例外情况？我们使用限制英语被动语态的例子来探讨这个问题(例如，“假期持续了五天”是合法的，但“ * 五天被假期持续了”不是)。我们收集了一系列动词被动句的人类可接受性判断，结果表明，语言模型 gPT-2所定义的概率分布与人类的判断具有高度相关性。我们还发现动词在主动语态和被动语态中的相对可接受性与动词在主动语态和被动语态中出现的相对频率呈正相关。这些结果为固守假设提供了初步的支持，根据这一假设，学习者跟踪并利用其输入的分布特性来学习规则的负异常。同时，这一假设也未能解释某些个别动词所表现出的非被动性程度，这表明在语言输入中还存在其他的例外线索。"
    },
    {
        "title": "An Efficient Speech Separation Network Based on Recurrent Fusion Dilated\n  Convolution and Channel Attention",
        "url": "http://arxiv.org/abs/2306.05887v1",
        "pub_date": "2023-06-09",
        "summary": "We present an efficient speech separation neural network, ARFDCN, which\ncombines dilated convolutions, multi-scale fusion (MSF), and channel attention\nto overcome the limited receptive field of convolution-based networks and the\nhigh computational cost of transformer-based networks. The suggested network\narchitecture is encoder-decoder based. By using dilated convolutions with\ngradually increasing dilation value to learn local and global features and\nfusing them at adjacent stages, the model can learn rich feature content.\nMeanwhile, by adding channel attention modules to the network, the model can\nextract channel weights, learn more important features, and thus improve its\nexpressive power and robustness. Experimental results indicate that the model\nachieves a decent balance between performance and computational efficiency,\nmaking it a promising alternative to current mainstream models for practical\napplications.",
        "translated": "我们提出了一个有效的语音分离神经网络，ARFDCN，它结合了扩张卷积，多尺度融合(MSF)和信道注意力，以克服有限的接收领域的卷积为基础的网络和高计算成本的变压器为基础的网络。所建议的网络结构是基于编码器-解码器的。通过使用渐增扩张值的扩张卷积来学习局部和全局特征，并在相邻阶段进行融合，该模型可以学习到丰富的特征内容。同时，通过在网络中增加信道注意模块，该模型可以提取信道权重，学习更多的重要特征，从而提高其表达能力和鲁棒性。实验结果表明，该模型在性能和计算效率之间取得了较好的平衡，是目前主流模型在实际应用中的一种有前途的替代方案。"
    },
    {
        "title": "Weakly-Supervised Scientific Document Classification via\n  Retrieval-Augmented Multi-Stage Training",
        "url": "http://arxiv.org/abs/2306.07193v1",
        "pub_date": "2023-06-12",
        "summary": "Scientific document classification is a critical task for a wide range of\napplications, but the cost of obtaining massive amounts of human-labeled data\ncan be prohibitive. To address this challenge, we propose a weakly-supervised\napproach for scientific document classification using label names only. In\nscientific domains, label names often include domain-specific concepts that may\nnot appear in the document corpus, making it difficult to match labels and\ndocuments precisely. To tackle this issue, we propose WANDER, which leverages\ndense retrieval to perform matching in the embedding space to capture the\nsemantics of label names. We further design the label name expansion module to\nenrich the label name representations. Lastly, a self-training step is used to\nrefine the predictions. The experiments on three datasets show that WANDER\noutperforms the best baseline by 11.9% on average. Our code will be published\nat https://github.com/ritaranx/wander.",
        "translated": "科学文档分类对于广泛的应用来说是一个关键的任务，但是获取大量的人类标记数据的成本可能是高昂的。为了应对这一挑战，我们提出了一种弱监督的方法，用于只使用标签名称的科学文档分类。在科学领域，标签名称往往包括特定领域的概念，这些概念可能不会出现在文档语料库中，因此难以精确匹配标签和文档。为了解决这个问题，我们提出了 WANDER，它利用密集检索在嵌入空间中执行匹配来捕获标签名的语义。进一步设计了标签名扩展模块，丰富了标签名表示。最后，使用一个自我训练步骤来完善预测。在三个数据集上的实验结果表明，WANDER 平均比最佳基准线高出11.9% 。我们的代码会在 https://github.com/ritaranx/wander 公布。"
    },
    {
        "title": "Fair Learning to Rank with Distribution-free Risk Control",
        "url": "http://arxiv.org/abs/2306.07188v1",
        "pub_date": "2023-06-12",
        "summary": "Learning to Rank (LTR) methods are vital in online economies, affecting users\nand item providers. Fairness in LTR models is crucial to allocate exposure\nproportionally to item relevance. The deterministic ranking model can lead to\nunfair exposure distribution when items with the same relevance receive\nslightly different scores. Stochastic LTR models, incorporating the\nPlackett-Luce (PL) model, address fairness issues but have limitations in\ncomputational cost and performance guarantees. To overcome these limitations,\nwe propose FairLTR-RC, a novel post-hoc model-agnostic method. FairLTR-RC\nleverages a pretrained scoring function to create a stochastic LTR model,\neliminating the need for expensive training. Furthermore, FairLTR-RC provides\nfinite-sample guarantees on a user-specified utility using distribution-free\nrisk control framework. By additionally incorporating the Thresholded PL (TPL)\nmodel, we are able to achieve an effective trade-off between utility and\nfairness. Experimental results on several benchmark datasets demonstrate that\nFairLTR-RC significantly improves fairness in widely-used deterministic LTR\nmodels while guaranteeing a specified level of utility.",
        "translated": "学习排名(LTR)方法在网络经济中至关重要，它会影响用户和商品供应商。LTR 模型中的公平性对于按照项目相关性按比例分配暴露是至关重要的。确定性排序模型可能导致不公平的曝光分布，当项目相同的相关性得到略有不同的分数。结合 Plackett-Luce (PL)模型的随机 LTR 模型解决了公平性问题，但在计算成本和性能保证方面存在局限性。为了克服这些局限性，我们提出了一种新的事后模型无关方法 FairLTR-RC。FairLTR-RC 利用一个预先训练的评分函数来创建一个随机 LTR 模型，从而消除了对昂贵培训的需求。此外，FairLTR-RC 使用无分布风险控制框架为用户指定的公用事业提供有限样本保证。另外，通过引入阈限物流(TPL)模型，我们能够在效用和公平之间达到有效的平衡。在几个基准数据集上的实验结果表明，FairLTR-RC 在保证特定效用水平的同时，显著提高了广泛使用的确定性 LTR 模型的公平性。"
    },
    {
        "title": "Video-to-Music Recommendation using Temporal Alignment of Segments",
        "url": "http://arxiv.org/abs/2306.07187v1",
        "pub_date": "2023-06-12",
        "summary": "We study cross-modal recommendation of music tracks to be used as soundtracks\nfor videos. This problem is known as the music supervision task. We build on a\nself-supervised system that learns a content association between music and\nvideo. In addition to the adequacy of content, adequacy of structure is crucial\nin music supervision to obtain relevant recommendations. We propose a novel\napproach to significantly improve the system's performance using\nstructure-aware recommendation. The core idea is to consider not only the full\naudio-video clips, but rather shorter segments for training and inference. We\nfind that using semantic segments and ranking the tracks according to sequence\nalignment costs significantly improves the results. We investigate the impact\nof different ranking metrics and segmentation methods.",
        "translated": "我们研究跨模态的音乐曲目推荐作为视频配乐使用。这个问题被称为音乐监督任务。我们建立了一个自我监督系统，学习音乐和视频之间的内容关联。除了内容的充分性，结构的充分性在音乐监督中也是至关重要的，以获得相关的建议。我们提出了一种新的方法来显著提高系统的性能使用结构感知的推荐。其核心思想是不仅要考虑完整的音视频剪辑，而且要考虑训练和推理的较短片段。我们发现，使用语义片段并根据序列比对成本对音轨进行排序，可以显著提高搜索结果。我们研究了不同排序指标和分割方法的影响。"
    },
    {
        "title": "Adversarial Constrained Bidding via Minimax Regret Optimization with\n  Causality-Aware Reinforcement Learning",
        "url": "http://arxiv.org/abs/2306.07106v1",
        "pub_date": "2023-06-12",
        "summary": "The proliferation of the Internet has led to the emergence of online\nadvertising, driven by the mechanics of online auctions. In these repeated\nauctions, software agents participate on behalf of aggregated advertisers to\noptimize for their long-term utility. To fulfill the diverse demands, bidding\nstrategies are employed to optimize advertising objectives subject to different\nspending constraints. Existing approaches on constrained bidding typically rely\non i.i.d. train and test conditions, which contradicts the adversarial nature\nof online ad markets where different parties possess potentially conflicting\nobjectives. In this regard, we explore the problem of constrained bidding in\nadversarial bidding environments, which assumes no knowledge about the\nadversarial factors. Instead of relying on the i.i.d. assumption, our insight\nis to align the train distribution of environments with the potential test\ndistribution meanwhile minimizing policy regret. Based on this insight, we\npropose a practical Minimax Regret Optimization (MiRO) approach that\ninterleaves between a teacher finding adversarial environments for tutoring and\na learner meta-learning its policy over the given distribution of environments.\nIn addition, we pioneer to incorporate expert demonstrations for learning\nbidding strategies. Through a causality-aware policy design, we improve upon\nMiRO by distilling knowledge from the experts. Extensive experiments on both\nindustrial data and synthetic data show that our method, MiRO with\nCausality-aware reinforcement Learning (MiROCL), outperforms prior methods by\nover 30%.",
        "translated": "互联网的扩散导致了在线广告的出现，这是由在线拍卖的机制所驱动的。在这些重复的拍卖中，软件代理商代表广告主集合参与，以优化他们的长期效用。为了满足不同的需求，投标策略被用来优化受不同支出约束的广告目标。现有的限制性投标方法通常依赖于身份证培训和测试条件，这与在线广告市场的对抗性质相矛盾，因为在线广告市场中，不同的当事人拥有潜在的相互冲突的目标。在这方面，我们探讨了在不考虑竞争因素的情况下，在竞争性投标环境下的约束投标问题。我们的洞察力不是依赖于内部识别假设，而是使环境的列车分布与潜在的测试分布保持一致，同时最大限度地减少政策遗憾。基于这种观点，我们提出了一种实用的极大极小遗憾优化(Miniax Regret Optimation，MiRO)方法，该方法在教师寻找对抗性的辅导环境和学习者元学习策略之间进行交叉。此外，我们率先采用专家演示学习投标策略。通过一个因果关系感知策略设计，我们从专家那里提取知识来改进 MiRO。对工业数据和合成数据的大量实验表明，我们的方法，带有因果感知强化学习(miROCL)的 miRO，比之前的方法性能高出30% 以上。"
    },
    {
        "title": "Imbalanced Multi-label Classification for Business-related Text with\n  Moderately Large Label Spaces",
        "url": "http://arxiv.org/abs/2306.07046v1",
        "pub_date": "2023-06-12",
        "summary": "In this study, we compared the performance of four different methods for\nmulti label text classification using a specific imbalanced business dataset.\nThe four methods we evaluated were fine tuned BERT, Binary Relevance,\nClassifier Chains, and Label Powerset. The results show that fine tuned BERT\noutperforms the other three methods by a significant margin, achieving high\nvalues of accuracy, F1 Score, Precision, and Recall. Binary Relevance also\nperforms well on this dataset, while Classifier Chains and Label Powerset\ndemonstrate relatively poor performance. These findings highlight the\neffectiveness of fine tuned BERT for multi label text classification tasks, and\nsuggest that it may be a useful tool for businesses seeking to analyze complex\nand multifaceted texts.",
        "translated": "在这项研究中，我们比较了四种不同方法的性能，多标签文本分类使用特定的不平衡业务数据集。我们评估的四种方法是微调的 BERT、二进制相关性、分类器链和标签 Powerset。结果表明，精调误码率优于其他三种方法，具有较高的精度、 F1评分、精度和召回率。二进制相关性在这个数据集上也表现良好，而分类器链和标签 Powerset 表现出相对较差的性能。这些发现突出了微调 BERT 在多标签文本分类任务中的有效性，并表明它可能是企业寻求分析复杂和多方面文本的有用工具。"
    },
    {
        "title": "Data-Copilot: Bridging Billions of Data and Humans with Autonomous\n  Workflow",
        "url": "http://arxiv.org/abs/2306.07209v1",
        "pub_date": "2023-06-12",
        "summary": "Various industries such as finance, meteorology, and energy generate vast\namounts of heterogeneous data every day. There is a natural demand for humans\nto manage, process, and display data efficiently. However, it necessitates\nlabor-intensive efforts and a high level of expertise for these data-related\ntasks. Considering that large language models (LLMs) have showcased promising\ncapabilities in semantic understanding and reasoning, we advocate that the\ndeployment of LLMs could autonomously manage and process massive amounts of\ndata while displaying and interacting in a human-friendly manner. Based on this\nbelief, we propose Data-Copilot, an LLM-based system that connects numerous\ndata sources on one end and caters to diverse human demands on the other end.\nActing like an experienced expert, Data-Copilot autonomously transforms raw\ndata into visualization results that best match the user's intent.\nSpecifically, Data-Copilot autonomously designs versatile interfaces (tools)\nfor data management, processing, prediction, and visualization. In real-time\nresponse, it automatically deploys a concise workflow by invoking corresponding\ninterfaces step by step for the user's request. The interface design and\ndeployment processes are fully controlled by Data-Copilot itself, without human\nassistance. Besides, we create a Data-Copilot demo that links abundant data\nfrom different domains (stock, fund, company, economics, and live news) and\naccurately respond to diverse requests, serving as a reliable AI assistant.",
        "translated": "金融、气象和能源等不同行业每天都会产生大量异构数据。对人类来说，有效地管理、处理和显示数据是一种自然的需求。然而，对于这些与数据相关的任务，它需要劳动密集型的努力和高水平的专业知识。考虑到大型语言模型(LLM)在语义理解和推理方面表现出了很有前途的能力，我们主张 LLM 的部署可以自主地管理和处理大量的数据，同时以人性化的方式显示和交互。基于这一信念，我们提出了 Data-Copilot，一个基于 LLM 的系统，一端连接众多数据源，另一端满足不同的人类需求。Data-Copilot 像一位经验丰富的专家一样，自主地将原始数据转换为最符合用户意图的可视化结果。具体来说，Data-Copilot 自主设计用于数据管理、处理、预测和可视化的多功能接口(工具)。在实时响应中，它通过为用户的请求逐步调用相应的接口，自动部署一个简洁的工作流。接口设计和部署过程完全由 Data-Copilot 本身控制，无需人工协助。此外，我们创建了一个 Data-Copilot 演示，链接了来自不同领域(股票、基金、公司、经济和现场新闻)的大量数据，并准确地响应不同的请求，作为一个可靠的人工智能助手。"
    },
    {
        "title": "Valley: Video Assistant with Large Language model Enhanced abilitY",
        "url": "http://arxiv.org/abs/2306.07207v1",
        "pub_date": "2023-06-12",
        "summary": "Recently, several multi-modal models have been developed for joint image and\nlanguage understanding, which have demonstrated impressive chat abilities by\nutilizing advanced large language models (LLMs). The process of developing such\nmodels is straightforward yet effective. It involves pre-training an adaptation\nmodule to align the semantics of the vision encoder and language model,\nfollowed by fine-tuning on the instruction-following data. However, despite the\nsuccess of this pipeline in image and language understanding, its effectiveness\nin joint video and language understanding has not been widely explored. In this\npaper, we aim to develop a novel multi-modal foundation model capable of\nperceiving video, image, and language within a general framework. To achieve\nthis goal, we introduce Valley: Video Assistant with Large Language model\nEnhanced ability. Specifically, our proposed Valley model is designed with a\nsimple projection module that bridges video, image, and language modalities,\nand is further unified with a multi-lingual LLM. We also collect multi-source\nvision-text pairs and adopt a spatio-temporal pooling strategy to obtain a\nunified vision encoding of video and image input for pre-training. Furthermore,\nwe generate multi-task instruction-following video data, including multi-shot\ncaptions, long video descriptions, action recognition, causal relationship\ninference, etc. To obtain the instruction-following data, we design diverse\nrounds of task-oriented conversations between humans and videos, facilitated by\nChatGPT. Qualitative examples demonstrate that our proposed model has the\npotential to function as a highly effective multilingual video assistant that\ncan make complex video understanding scenarios easy. Code, data, and models\nwill be available at https://github.com/RupertLuo/Valley.",
        "translated": "最近，一些多模态模型已经被开发出来用于联合图像和语言理解，它们通过使用先进的大语言模型(LLM)展示了令人印象深刻的聊天能力。开发这种模型的过程是简单而有效的。它包括预先训练一个适应模块，以便对准视觉编码器和语言模型的语义，然后对指令跟踪数据进行微调。然而，尽管这条管道在图像和语言理解方面取得了成功，但它在联合视频和语言理解方面的有效性还没有得到广泛的探索。在本文中，我们的目标是开发一个新的多模态基础模型，能够感知视频，图像和语言在一个通用的框架内。为了实现这一目标，我们引入了谷: 视频助理与大语言模型增强能力。具体来说，我们提出的 Valley 模型设计了一个简单的投影模块，它连接了视频、图像和语言模式，并进一步与多语言 LLM 相结合。采集多源视觉文本对，采用时空合并策略，获得视频和图像输入的统一视觉编码，用于预训练。此外，还生成了多任务指令跟踪视频数据，包括多镜头字幕、长视频描述、动作识别、因果关系推理等。为了获得指令跟踪数据，我们设计了不同轮次的任务导向的人类和视频之间的对话，促进了 ChatGPT。定性的例子表明，我们提出的模型有潜力作为一个高效的多语言视频助理，可以使复杂的视频理解场景容易。代码、数据和模型将在 https://github.com/rupertluo/valley 提供。"
    },
    {
        "title": "RECAP: Retrieval-Enhanced Context-Aware Prefix Encoder for Personalized\n  Dialogue Response Generation",
        "url": "http://arxiv.org/abs/2306.07206v1",
        "pub_date": "2023-06-12",
        "summary": "Endowing chatbots with a consistent persona is essential to an engaging\nconversation, yet it remains an unresolved challenge. In this work, we propose\na new retrieval-enhanced approach for personalized response generation.\nSpecifically, we design a hierarchical transformer retriever trained on\ndialogue domain data to perform personalized retrieval and a context-aware\nprefix encoder that fuses the retrieved information to the decoder more\neffectively. Extensive experiments on a real-world dataset demonstrate the\neffectiveness of our model at generating more fluent and personalized\nresponses. We quantitatively evaluate our model's performance under a suite of\nhuman and automatic metrics and find it to be superior compared to\nstate-of-the-art baselines on English Reddit conversations.",
        "translated": "赋予聊天机器人一个一致的角色对于一个引人入胜的对话至关重要，然而这仍然是一个未解决的挑战。在这项工作中，我们提出了一个新的检索增强的方法来生成个性化的响应。具体地说，我们设计了一个基于对话域数据训练的分层变压器检索器来执行个性化检索，以及一个上下文感知的前缀编码器来更有效地将检索到的信息融合到解码器中。在真实世界数据集上的大量实验证明了我们的模型在产生更流畅和个性化响应方面的有效性。我们定量评估了我们的模型在一套人工和自动指标下的表现，发现它比英语 Reddit 会话的最先进的基线要好。"
    },
    {
        "title": "LTCR: Long-Text Chinese Rumor Detection Dataset",
        "url": "http://arxiv.org/abs/2306.07201v2",
        "pub_date": "2023-06-12",
        "summary": "False information can spread quickly on social media, negatively influencing\nthe citizens' behaviors and responses to social events. To better detect all of\nthe fake news, especially long texts which are harder to find completely, a\nLong-Text Chinese Rumor detection dataset named LTCR is proposed. The LTCR\ndataset provides a valuable resource for accurately detecting misinformation,\nespecially in the context of complex fake news related to COVID-19. The dataset\nconsists of 1,729 and 500 pieces of real and fake news, respectively. The\naverage lengths of real and fake news are approximately 230 and 152 characters.\nWe also propose \\method, Salience-aware Fake News Detection Model, which\nachieves the highest accuracy (95.85%), fake news recall (90.91%) and F-score\n(90.60%) on the dataset. (https://github.com/Enderfga/DoubleCheck)",
        "translated": "虚假信息可以在社交媒体上迅速传播，对公民的行为和对社会事件的反应产生负面影响。为了更好地检测所有的假新闻，特别是难以完全发现的长文本，提出了一种长文本中文谣言检测数据集 LTCR。LTCR 数据集为准确检测错误信息提供了有价值的资源，特别是在与2019冠状病毒疾病有关的复杂假新闻背景下。这个数据集包括1729条真实新闻和500条假新闻。真实和假新闻的平均长度大约是230和152个字符。本文还提出了基于显著性的假新闻检测模型，该模型对数据集的准确率最高(95.85%) ，对假新闻的召回率最高(90.91%) ，对假新闻的 F 分值最高(90.60%)。( https://github.com/enderfga/doublecheck )"
    },
    {
        "title": "A Survey of Vision-Language Pre-training from the Lens of Multimodal\n  Machine Translation",
        "url": "http://arxiv.org/abs/2306.07198v1",
        "pub_date": "2023-06-12",
        "summary": "Large language models such as BERT and the GPT series started a paradigm\nshift that calls for building general-purpose models via pre-training on large\ndatasets, followed by fine-tuning on task-specific datasets. There is now a\nplethora of large pre-trained models for Natural Language Processing and\nComputer Vision. Recently, we have seen rapid developments in the joint\nVision-Language space as well, where pre-trained models such as CLIP (Radford\net al., 2021) have demonstrated improvements in downstream tasks like image\ncaptioning and visual question answering. However, surprisingly there is\ncomparatively little work on exploring these models for the task of multimodal\nmachine translation, where the goal is to leverage image/video modality in\ntext-to-text translation. To fill this gap, this paper surveys the landscape of\nlanguage-and-vision pre-training from the lens of multimodal machine\ntranslation. We summarize the common architectures, pre-training objectives,\nand datasets from literature and conjecture what further is needed to make\nprogress on multimodal machine translation.",
        "translated": "像 BERT 和 GPT 系列这样的大型语言模型开启了一个范式转变，要求通过对大型数据集进行预训练来构建通用模型，然后对特定任务的数据集进行微调。现在有大量的自然语言处理和计算机视觉的大型预训练模型。最近，我们也看到了联合视觉语言空间的快速发展，其中预先训练的模型如 CLIP (Radford et al。 ，2021)已经在下游任务如图像字幕和视觉问题回答方面表现出改进。然而，令人惊讶的是，在多模态机器翻译的任务中，探索这些模型的工作相对较少，其目标是在文本到文本的翻译中利用图像/视频模态。为了填补这一空白，本文从多模态机器翻译的角度考察了语言和视觉预训的前景。我们总结了通用的体系结构、预训练目标和来自文献的数据集，并推测在多模式机器翻译方面还需要做些什么。"
    },
    {
        "title": "Large language models and (non-)linguistic recursion",
        "url": "http://arxiv.org/abs/2306.07195v1",
        "pub_date": "2023-06-12",
        "summary": "Recursion is one of the hallmarks of human language. While many design\nfeatures of language have been shown to exist in animal communication systems,\nrecursion has not. Previous research shows that GPT-4 is the first large\nlanguage model (LLM) to exhibit metalinguistic abilities (Begu\\v{s},\nD\\k{a}bkowski, and Rhodes 2023). Here, we propose several prompt designs aimed\nat eliciting and analyzing recursive behavior in LLMs, both linguistic and\nnon-linguistic. We demonstrate that when explicitly prompted, GPT-4 can both\nproduce and analyze recursive structures. Thus, we present one of the first\nstudies investigating whether meta-linguistic awareness of recursion -- a\nuniquely human cognitive property -- can emerge in transformers with a high\nnumber of parameters such as GPT-4.",
        "translated": "递归是人类语言的标志之一。虽然语言的许多设计特征已被证明存在于动物交流系统中，但递归却没有。以往的研究表明，GPT-4是第一个表现出元语言能力的大型语言模型(Begu v { s } ，D k { a } bkowski，and Rhodes 2023)。在这里，我们提出了几个快速的设计，旨在引发和分析递归行为的 LLM，无论是语言和非语言。我们演示了当显式提示时，GPT-4既可以产生递归结构，也可以分析递归结构。因此，我们提出的第一个研究之一，调查是否元语言意识的递归-一个独特的人类认知属性-可以出现在变压器与大量的参数，如 GPT-4。"
    },
    {
        "title": "The Effect of Masking Strategies on Knowledge Retention by Language\n  Models",
        "url": "http://arxiv.org/abs/2306.07185v1",
        "pub_date": "2023-06-12",
        "summary": "Language models retain a significant amount of world knowledge from their\npre-training stage. This allows knowledgeable models to be applied to\nknowledge-intensive tasks prevalent in information retrieval, such as ranking\nor question answering. Understanding how and which factual information is\nacquired by our models is necessary to build responsible models. However,\nlimited work has been done to understand the effect of pre-training tasks on\nthe amount of knowledge captured and forgotten by language models during\npre-training. Building a better understanding of knowledge acquisition is the\ngoal of this paper. Therefore, we utilize a selection of pre-training tasks to\ninfuse knowledge into our model. In the following steps, we test the model's\nknowledge retention by measuring its ability to answer factual questions. Our\nexperiments show that masking entities and principled masking of correlated\nspans based on pointwise mutual information lead to more factual knowledge\nbeing retained than masking random tokens. Our findings demonstrate that, like\nthe ability to perform a task, the (factual) knowledge acquired from being\ntrained on that task is forgotten when a model is trained to perform another\ntask (catastrophic forgetting) and how to prevent this phenomenon. To foster\nreproducibility, the code, as well as the data used in this paper, are openly\navailable.",
        "translated": "语言模型从培训前阶段就保留了大量的世界知识。这使得知识型模型能够应用于信息检索中普遍存在的知识密集型任务，例如排名或问答。要建立负责任的模型，就必须了解我们的模型是如何以及获取哪些事实信息的。然而，在理解培训前任务对语言模型在培训前捕获和遗忘的知识量的影响方面所做的工作有限。加深对知识获取的理解是本文的目的。因此，我们利用一个预训练任务的选择，将知识注入到我们的模型中。在接下来的步骤中，我们通过测量模型回答实际问题的能力来测试模型的知识保持能力。我们的实验表明，屏蔽实体和基于点间互信息的相关跨度的原则性屏蔽比屏蔽随机标记能够保留更多的事实知识。我们的研究结果表明，就像执行任务的能力一样，当一个模型被训练去执行另一个任务(灾难性遗忘)时，从该任务中获得的(事实)知识会被遗忘，以及如何防止这种现象的发生。为了提高可重复性，本文中使用的代码和数据都是公开的。"
    },
    {
        "title": "Augmenting Language Models with Long-Term Memory",
        "url": "http://arxiv.org/abs/2306.07174v1",
        "pub_date": "2023-06-12",
        "summary": "Existing large language models (LLMs) can only afford fix-sized inputs due to\nthe input length limit, preventing them from utilizing rich long-context\ninformation from past inputs. To address this, we propose a framework, Language\nModels Augmented with Long-Term Memory (LongMem), which enables LLMs to\nmemorize long history. We design a novel decoupled network architecture with\nthe original backbone LLM frozen as a memory encoder and an adaptive residual\nside-network as a memory retriever and reader. Such a decoupled memory design\ncan easily cache and update long-term past contexts for memory retrieval\nwithout suffering from memory staleness. Enhanced with memory-augmented\nadaptation training, LongMem can thus memorize long past context and use\nlong-term memory for language modeling. The proposed memory retrieval module\ncan handle unlimited-length context in its memory bank to benefit various\ndownstream tasks. Typically, LongMem can enlarge the long-form memory to 65k\ntokens and thus cache many-shot extra demonstration examples as long-form\nmemory for in-context learning. Experiments show that our method outperforms\nstrong long-context models on ChapterBreak, a challenging long-context modeling\nbenchmark, and achieves remarkable improvements on memory-augmented in-context\nlearning over LLMs. The results demonstrate that the proposed method is\neffective in helping language models to memorize and utilize long-form\ncontents. Our code is open-sourced at https://aka.ms/LongMem.",
        "translated": "由于输入长度的限制，现有的大型语言模型(LLM)只能提供固定大小的输入，这使得它们无法利用来自过去输入的丰富的长上下文信息。为了解决这个问题，我们提出了一个框架，即使用长期记忆增强的语言模型(LongMem) ，它使长期记忆能够记忆长期的历史。我们设计了一种新颖的解耦网络结构，其中原骨干 LLM 作为内存编码器，自适应残余网络作为内存检索器和读取器。这种解耦的内存设计可以轻松地缓存和更新长期的过去上下文，用于内存检索，而不会受到内存过时的影响。随着记忆增强适应训练的加强，LongMem 因此可以记住很长的过去的上下文，并使用长期记忆进行语言建模。提出的内存检索模块可以在其内存库中处理无限长的上下文，有利于各种下游任务。通常，LongMem 可以将长形式内存扩大到65k 令牌，从而缓存多镜头的额外示例作为长形式内存，用于上下文学习。实验结果表明，该方法优于一个具有挑战性的长上下文建模基准 ChapterBreak 的强大长上下文模型，并且在 LLM 上实现了对记忆增强的上下文学习的显著改进。结果表明，该方法能有效地帮助语言模型记忆和利用长形式的内容。我们的代码在 https://aka.ms/longmem 是开源的。"
    },
    {
        "title": "Prompt-based Extraction of Social Determinants of Health Using Few-shot\n  Learning",
        "url": "http://arxiv.org/abs/2306.07170v1",
        "pub_date": "2023-06-12",
        "summary": "Social determinants of health (SDOH) documented in the electronic health\nrecord through unstructured text are increasingly being studied to understand\nhow SDOH impacts patient health outcomes. In this work, we utilize the Social\nHistory Annotation Corpus (SHAC), a multi-institutional corpus of de-identified\nsocial history sections annotated for SDOH, including substance use,\nemployment, and living status information. We explore the automatic extraction\nof SDOH information with SHAC in both standoff and inline annotation formats\nusing GPT-4 in a one-shot prompting setting. We compare GPT-4 extraction\nperformance with a high-performing supervised approach and perform thorough\nerror analyses. Our prompt-based GPT-4 method achieved an overall 0.652 F1 on\nthe SHAC test set, similar to the 7th best-performing system among all teams in\nthe n2c2 challenge with SHAC.",
        "translated": "通过非结构化文本记录在电子健康记录中的健康的社会决定因素(SDOH)正在被越来越多地研究，以了解 SDOH 如何影响患者的健康结果。在这项工作中，我们利用社会历史注释语料库(SHAC) ，一个多机构语料库的去识别社会历史部分为 SDOH 注释，包括物质使用，就业和生活状态信息。我们使用 GPT-4在一次性提示设置中探索使用 SHAC 以对峙格式和内联注释格式自动提取 SDOH 信息。我们比较了 GPT-4提取性能和高性能的监督方法，并进行了彻底的误差分析。我们的基于提示的 GPT-4方法在 SHAC 测试集上获得了总体0.652 F1，类似于所有团队在 SHAC 的 n2c2挑战中排名第7的最佳系统。"
    },
    {
        "title": "Best-Case Retrieval Evaluation: Improving the Sensitivity of Reciprocal\n  Rank with Lexicographic Precision",
        "url": "http://arxiv.org/abs/2306.07908v1",
        "pub_date": "2023-06-13",
        "summary": "Across a variety of ranking tasks, researchers use reciprocal rank to measure\nthe effectiveness for users interested in exactly one relevant item. Despite\nits widespread use, evidence suggests that reciprocal rank is brittle when\ndiscriminating between systems. This brittleness, in turn, is compounded in\nmodern evaluation settings where current, high-precision systems may be\ndifficult to distinguish. We address the lack of sensitivity of reciprocal rank\nby introducing and connecting it to the concept of best-case retrieval, an\nevaluation method focusing on assessing the quality of a ranking for the most\nsatisfied possible user across possible recall requirements. This perspective\nallows us to generalize reciprocal rank and define a new preference-based\nevaluation we call lexicographic precision or lexiprecision. By mathematical\nconstruction, we ensure that lexiprecision preserves differences detected by\nreciprocal rank, while empirically improving sensitivity and robustness across\na broad set of retrieval and recommendation tasks.",
        "translated": "在各种排名任务中，研究人员使用互惠排名来衡量对一个相关项目感兴趣的用户的有效性。尽管它被广泛使用，但有证据表明，在区分不同体系时，互惠等级是脆弱的。这种脆性，反过来，在现代评估设置中，当前，高精度的系统可能难以区分复杂。我们通过引入并联系最佳案例检索的概念来解决相互排名缺乏敏感性的问题，最佳案例检索是一种评估方法，侧重于在可能的召回需求中为最满意的可能用户评估排名的质量。这种观点允许我们推广互惠等级，并定义一种新的基于偏好的评价，我们称之为词典精度或词汇精度。通过数学建构，我们确保词汇精确度保留了通过相互排名检测到的差异，同时经验性地提高了广泛的检索和推荐任务集的灵敏度和鲁棒性。"
    },
    {
        "title": "ReadProbe: A Demo of Retrieval-Enhanced Large Language Models to Support\n  Lateral Reading",
        "url": "http://arxiv.org/abs/2306.07875v1",
        "pub_date": "2023-06-13",
        "summary": "With the rapid growth and spread of online misinformation, people need tools\nto help them evaluate the credibility and accuracy of online information.\nLateral reading, a strategy that involves cross-referencing information with\nmultiple sources, may be an effective approach to achieving this goal. In this\npaper, we present ReadProbe, a tool to support lateral reading, powered by\ngenerative large language models from OpenAI and the Bing search engine. Our\ntool is able to generate useful questions for lateral reading, scour the web\nfor relevant documents, and generate well-attributed answers to help people\nbetter evaluate online information. We made a web-based application to\ndemonstrate how ReadProbe can help reduce the risk of being misled by false\ninformation. The code is available at\nhttps://github.com/DakeZhang1998/ReadProbe. An earlier version of our tool won\nthe first prize in a national AI misinformation hackathon.",
        "translated": "随着网络虚假信息的快速增长和传播，人们需要工具来帮助他们评估网络信息的可信度和准确性。横向阅读是一种涉及多源信息交叉引用的策略，可能是实现这一目标的有效途径。在这篇文章中，我们介绍了一个支持横向阅读的工具，由 OpenAI 和 Bing 搜索引擎生成的大型语言模型提供支持。我们的工具能够为横向阅读生成有用的问题，在网上搜索相关文档，并生成归属良好的答案，以帮助人们更好地评估在线信息。我们做了一个网络应用程序来演示如何通过阅读探索来帮助降低被错误信息误导的风险。密码可在 https://github.com/dakezhang1998/readprobe 查阅。我们工具的早期版本赢得了全国人工智能错误信息黑客马拉松一等奖。"
    },
    {
        "title": "KuaiSAR: A Unified Search And Recommendation Dataset",
        "url": "http://arxiv.org/abs/2306.07705v1",
        "pub_date": "2023-06-13",
        "summary": "The confluence of Search and Recommendation services is a vital aspect of\nonline content platforms like Kuaishou and TikTok. The integration of S&amp;R\nmodeling is a highly intuitive approach adopted by industry practitioners.\nHowever, there is a noticeable lack of research conducted in this area within\nthe academia, primarily due to the absence of publicly available datasets.\nConsequently, a substantial gap has emerged between academia and industry\nregarding research endeavors in this field. To bridge this gap, we introduce\nthe first large-scale, real-world dataset KuaiSAR of integrated Search And\nRecommendation behaviors collected from Kuaishou, a leading short-video app in\nChina with over 300 million daily active users. Previous research in this field\nhas predominantly employed publicly available datasets that are semi-synthetic\nand simulated, with artificially fabricated search behaviors. Distinct from\nprevious datasets, KuaiSAR records genuine user behaviors, the occurrence of\neach interaction within either search or recommendation service, and the users'\ntransitions between the two services. This work aids in joint modeling of S&amp;R,\nand the utilization of search data for recommenders (and recommendation data\nfor search engines). Additionally, due to the diverse feedback labels of\nuser-video interactions, KuaiSAR also supports a wide range of other tasks,\nincluding intent recommendation, multi-task learning, and long sequential\nmulti-behavior modeling etc. We believe this dataset will facilitate innovative\nresearch and enrich our understanding of S&amp;R services integration in real-world\napplications.",
        "translated": "搜索和推荐服务的融合是 Kuaishou 和 TikTok 等在线内容平台的一个重要方面。S & R 建模的集成是业界从业人员采用的一种高度直观的方法。然而，学术界在这一领域明显缺乏研究，主要是由于缺乏公开可用的数据集。因此，学术界和工业界在这一领域的研究工作出现了巨大的差距。为了弥补这一差距，我们介绍了第一个大规模的，真实世界的数据集 KuaiSAR 的集成搜索和推荐行为收集自 Kuaishou，一个领先的短视频应用程序在中国有超过3亿日活跃用户。以前在这个领域的研究主要使用公开可用的数据集，这些数据集是半合成的和模拟的，具有人为制造的搜索行为。与以前的数据集不同，KuaiSAR 记录了真实的用户行为、搜索或推荐服务中每个交互的发生情况以及用户在两个服务之间的转换。这项工作有助于 S & R 的联合建模，以及对推荐者的搜索数据(和搜索引擎的推荐数据)的利用。此外，由于用户与视频交互的反馈标签多种多样，KuaiSAR 还支持广泛的其他任务，包括意图推荐、多任务学习和长顺序多行为建模等。我们相信这个数据集将促进创新研究，并丰富我们对现实世界应用中的 S & R 服务集成的理解。"
    },
    {
        "title": "Practice with Graph-based ANN Algorithms on Sparse Data: Chi-square\n  Two-tower model, HNSW, Sign Cauchy Projections",
        "url": "http://arxiv.org/abs/2306.07607v1",
        "pub_date": "2023-06-13",
        "summary": "Sparse data are common. The traditional ``handcrafted'' features are often\nsparse. Embedding vectors from trained models can also be very sparse, for\nexample, embeddings trained via the ``ReLu'' activation function. In this\npaper, we report our exploration of efficient search in sparse data with\ngraph-based ANN algorithms (e.g., HNSW, or SONG which is the GPU version of\nHNSW), which are popular in industrial practice, e.g., search and ads\n(advertising).\n  We experiment with the proprietary ads targeting application, as well as\nbenchmark public datasets. For ads targeting, we train embeddings with the\nstandard ``cosine two-tower'' model and we also develop the ``chi-square\ntwo-tower'' model. Both models produce (highly) sparse embeddings when they are\nintegrated with the ``ReLu'' activation function. In EBR (embedding-based\nretrieval) applications, after we the embeddings are trained, the next crucial\ntask is the approximate near neighbor (ANN) search for serving. While there are\nmany ANN algorithms we can choose from, in this study, we focus on the\ngraph-based ANN algorithm (e.g., HNSW-type).\n  Sparse embeddings should help improve the efficiency of EBR. One benefit is\nthe reduced memory cost for the embeddings. The other obvious benefit is the\nreduced computational time for evaluating similarities, because, for\ngraph-based ANN algorithms such as HNSW, computing similarities is often the\ndominating cost. In addition to the effort on leveraging data sparsity for\nstorage and computation, we also integrate ``sign cauchy random projections''\n(SignCRP) to hash vectors to bits, to further reduce the memory cost and speed\nup the ANN search. In NIPS'13, SignCRP was proposed to hash the chi-square\nsimilarity, which is a well-adopted nonlinear kernel in NLP and computer\nvision. Therefore, the chi-square two-tower model, SignCRP, and HNSW are now\ntightly integrated.",
        "translated": "稀疏的数据很常见。传统的“手工制作”的特点往往是稀少的。从训练过的模型中嵌入向量也可能非常稀疏，例如，通过“ ReLu”激活函数训练的嵌入。在本文中，我们报告了在稀疏数据中使用基于图的神经网络算法(例如，HNSW，或 SONG，这是 HNSW 的 GPU 版本)进行有效搜索的探索，这在工业实践中很流行，例如，搜索和广告(广告)。我们尝试使用针对应用程序的专有广告，以及基准公共数据集。对于广告定位，我们使用标准的“余弦双塔”模型训练嵌入，同时开发了“卡方双塔”模型。这两种模式在与“ ReLu”激活函数集成时都会产生(高度)稀疏的嵌入。在基于嵌入的检索(EBR)应用中，嵌入训练完成后，接下来的关键任务是近似近邻(ANN)搜索服务。虽然有很多神经网络算法可供选择，但本文主要研究基于图的神经网络算法(如 HNSW 型)。稀疏嵌入有助于提高 EBR 的效率。一个好处是减少了嵌入的内存开销。另一个明显的好处是减少了评估相似性的计算时间，因为对于基于图的神经网络算法，如 HNSW，计算相似性往往是主要的代价。除了努力利用数据稀疏性进行存储和计算，我们还集成了“符号柯西随机投影”(SignCRP)来散列向量到位，以进一步降低内存成本和加速人工神经网络搜索。在 NIPS’13中，SignCRP 被提出来对卡方相似度进行散列，这是一种在自然语言处理和计算机视觉中广泛采用的非线性核。因此，卡方双塔模型 SignCRP 和 HNSW 现在紧密结合在一起。"
    },
    {
        "title": "Unified Off-Policy Learning to Rank: a Reinforcement Learning\n  Perspective",
        "url": "http://arxiv.org/abs/2306.07528v1",
        "pub_date": "2023-06-13",
        "summary": "Off-policy Learning to Rank (LTR) aims to optimize a ranker from data\ncollected by a deployed logging policy. However, existing off-policy learning\nto rank methods often make strong assumptions about how users generate the\nclick data, i.e., the click model, and hence need to tailor their methods\nspecifically under different click models. In this paper, we unified the\nranking process under general stochastic click models as a Markov Decision\nProcess (MDP), and the optimal ranking could be learned with offline\nreinforcement learning (RL) directly. Building upon this, we leverage offline\nRL techniques for off-policy LTR and propose the Click Model-Agnostic Unified\nOff-policy Learning to Rank (CUOLR) method, which could be easily applied to a\nwide range of click models. Through a dedicated formulation of the MDP, we show\nthat offline RL algorithms can adapt to various click models without complex\ndebiasing techniques and prior knowledge of the model. Results on various\nlarge-scale datasets demonstrate that CUOLR consistently outperforms the\nstate-of-the-art off-policy learning to rank algorithms while maintaining\nconsistency and robustness under different click models.",
        "translated": "非策略学习排序(Off-policy Learning to Rank，LTR)的目标是从已部署的日志策略收集的数据中优化排序器。然而，现有的对方法进行排序的非策略学习往往对用户如何生成点击数据(即点击模型)做出强有力的假设，因此需要在不同的点击模型下特别调整他们的方法。在本文中，我们将一般随机点击模型下的排名过程统一为一个马可夫决策过程(mDP) ，并且可以直接使用离线强化学习(RL)来学习最佳排名。在此基础上，我们利用离线 RL 技术进行非策略 LTR，并提出 Click 模型-不可知统一非策略学习排名(CUOLR)方法，该方法可以很容易地应用于广泛的点击模型。通过一个专门的公式的 MDP，我们表明离线 RL 算法可以适应各种点击模型没有复杂的消偏技术和先验知识的模型。在各种大规模数据集上的结果表明，在不同点击模型下，CUOLR 在排序算法方面始终优于最先进的非策略学习，同时保持了一致性和鲁棒性。"
    },
    {
        "title": "arXiVeri: Automatic table verification with GPT",
        "url": "http://arxiv.org/abs/2306.07968v1",
        "pub_date": "2023-06-13",
        "summary": "Without accurate transcription of numerical data in scientific documents, a\nscientist cannot draw accurate conclusions. Unfortunately, the process of\ncopying numerical data from one paper to another is prone to human error. In\nthis paper, we propose to meet this challenge through the novel task of\nautomatic table verification (AutoTV), in which the objective is to verify the\naccuracy of numerical data in tables by cross-referencing cited sources. To\nsupport this task, we propose a new benchmark, arXiVeri, which comprises\ntabular data drawn from open-access academic papers on arXiv. We introduce\nmetrics to evaluate the performance of a table verifier in two key areas: (i)\ntable matching, which aims to identify the source table in a cited document\nthat corresponds to a target table, and (ii) cell matching, which aims to\nlocate shared cells between a target and source table and identify their row\nand column indices accurately. By leveraging the flexible capabilities of\nmodern large language models (LLMs), we propose simple baselines for table\nverification. Our findings highlight the complexity of this task, even for\nstate-of-the-art LLMs like OpenAI's GPT-4. The code and benchmark will be made\npublicly available.",
        "translated": "没有科学文献中数字数据的准确记录，科学家就不能得出准确的结论。不幸的是，将数字数据从一张纸复制到另一张纸的过程容易出现人为错误。在本文中，我们提出通过自动表格验证(AutoTV)这一新的任务来迎接这一挑战，其目标是通过交叉引用来源来验证表格中数字数据的准确性。为了支持这个任务，我们提出了一个新的基准，arXiVeri，它包含从 arXiv 上的开放存取学术论文中提取的表格数据。我们引入指标来评估表验证器在两个关键领域的性能: (i)表匹配，其目的是识别与目标表对应的引用文档中的源表; 和(ii)单元格匹配，其目的是在目标和源表之间定位共享单元格，并准确识别其行和列索引。通过利用现代大型语言模型(LLM)的灵活性，我们为表验证提出了简单的基线。我们的发现强调了这项任务的复杂性，即使对于像 OpenAI 的 GPT-4这样的最先进的 LLM 也是如此。代码和基准将公开发布。"
    },
    {
        "title": "MOFI: Learning Image Representations from Noisy Entity Annotated Images",
        "url": "http://arxiv.org/abs/2306.07952v1",
        "pub_date": "2023-06-13",
        "summary": "We present MOFI, a new vision foundation model designed to learn image\nrepresentations from noisy entity annotated images. MOFI differs from previous\nwork in two key aspects: ($i$) pre-training data, and ($ii$) training recipe.\nRegarding data, we introduce a new approach to automatically assign entity\nlabels to images from noisy image-text pairs. Our approach involves employing a\nnamed entity recognition model to extract entities from the alt-text, and then\nusing a CLIP model to select the correct entities as labels of the paired\nimage. The approach is simple, does not require costly human annotation, and\ncan be readily scaled up to billions of image-text pairs mined from the web.\nThrough this method, we have created Image-to-Entities (I2E), a new large-scale\ndataset with 1 billion images and 2 million distinct entities, covering rich\nvisual concepts in the wild. Building upon the I2E dataset, we study different\ntraining recipes, including supervised pre-training, contrastive pre-training,\nand multi-task learning. For constrastive pre-training, we treat entity names\nas free-form text, and further enrich them with entity descriptions.\nExperiments show that supervised pre-training with large-scale fine-grained\nentity labels is highly effective for image retrieval tasks, and multi-task\ntraining further improves the performance. The final MOFI model achieves 86.66%\nmAP on the challenging GPR1200 dataset, surpassing the previous\nstate-of-the-art performance of 72.19% from OpenAI's CLIP model. Further\nexperiments on zero-shot and linear probe image classification also show that\nMOFI outperforms a CLIP model trained on the original image-text data,\ndemonstrating the effectiveness of the I2E dataset in learning strong image\nrepresentations.",
        "translated": "提出了一种新的视觉基础模型 MOFI，该模型旨在从噪声实体注释图像中学习图像表示。MOFI 与以往的工作有两个关键方面的不同: ($i $)培训前数据和($ii $)培训配方。对于数据，我们引入了一种新的方法来自动分配实体标签图像噪声的图像-文本对。我们的方法包括使用命名实体识别模型从替代文本中提取实体，然后使用 CLIP 模型选择正确的实体作为配对图像的标签。这种方法很简单，不需要昂贵的人工注释，而且可以很容易地扩大到从网络中挖掘出的数十亿图像-文本对。通过这种方法，我们创建了图像到实体(I2E) ，这是一个新的大规模数据集，包含10亿张图像和200万个不同的实体，覆盖了丰富的野外视觉概念。在 I2E 数据集的基础上，我们研究了不同的训练方法，包括监督预训练、对比预训练和多任务学习。在对比预训练中，我们将实体名称视为自由形式的文本，并用实体描述进一步丰富实体名称。实验表明，基于大规模细粒度实体标签的监督预训练对图像检索任务具有很高的效果，多任务训练进一步提高了性能。最终的 MOFI 模型在具有挑战性的 GPR1200数据集上达到了86.66% 的 mAP，超过了之前 OpenAI 的 CLIP 模型72.19% 的最先进性能。进一步的零拍和线性探针图像分类实验也表明，MOFI 优于对原始图像-文本数据进行训练的 CLIP 模型，证明了 I2E 数据集在学习强图像表示方面的有效性。"
    },
    {
        "title": "Questioning the Survey Responses of Large Language Models",
        "url": "http://arxiv.org/abs/2306.07951v1",
        "pub_date": "2023-06-13",
        "summary": "As large language models increase in capability, researchers have started to\nconduct surveys of all kinds on these models with varying scientific\nmotivations. In this work, we examine what we can learn from a model's survey\nresponses on the basis of the well-established American Community Survey (ACS)\nby the U.S. Census Bureau. Evaluating more than a dozen different models,\nvarying in size from a few hundred million to ten billion parameters, hundreds\nof thousands of times each on questions from the ACS, we systematically\nestablish two dominant patterns. First, smaller models have a significant\nposition and labeling bias, for example, towards survey responses labeled with\nthe letter \"A\". This A-bias diminishes, albeit slowly, as model size increases.\nSecond, when adjusting for this labeling bias through randomized answer\nordering, models still do not trend toward US population statistics or those of\nany cognizable population. Rather, models across the board trend toward\nuniformly random aggregate statistics over survey responses. This pattern is\nrobust to various different ways of prompting the model, including what is the\nde-facto standard. Our findings demonstrate that aggregate statistics of a\nlanguage model's survey responses lack the signals found in human populations.\nThis absence of statistical signal cautions about the use of survey responses\nfrom large language models at present time.",
        "translated": "随着大型语言模型能力的提高，研究人员开始以不同的科学动机对这些模型进行各种各样的调查。在这项工作中，我们研究我们可以从一个模型的调查反应的基础上，由美国人口普查局建立的美国社区调查(ACS)的学习。我们评估了十几个不同的模型，这些模型的大小从几亿到一百亿个参数不等，每个模型对 ACS 提出的问题进行了数十万次评估，我们系统地建立了两种主导模式。首先，较小的模型有一个重要的位置和标签偏见，例如，对标有字母“ A”的调查回答。随着模型尺寸的增加，这种 A 偏差会逐渐减小，尽管速度很慢。其次，当通过随机回答排序调整这种标记偏差时，模型仍然没有趋向于美国人口统计或任何可认知人口的统计。相反，模型全面趋向于统一随机总体统计超过调查答复。该模式对于提示模型的各种不同方式都是健壮的，包括什么是事实上的标准。我们的研究结果表明，一个语言模型的调查回答的总体统计缺乏在人口中发现的信号。这种缺乏统计信号的情况提醒人们注意目前使用来自大型语言模型的调查答复。"
    },
    {
        "title": "BoardgameQA: A Dataset for Natural Language Reasoning with Contradictory\n  Information",
        "url": "http://arxiv.org/abs/2306.07934v1",
        "pub_date": "2023-06-13",
        "summary": "Automated reasoning with unstructured natural text is a key requirement for\nmany potential applications of NLP and for developing robust AI systems.\nRecently, Language Models (LMs) have demonstrated complex reasoning capacities\neven without any finetuning. However, existing evaluation for automated\nreasoning assumes access to a consistent and coherent set of information over\nwhich models reason. When reasoning in the real-world, the available\ninformation is frequently inconsistent or contradictory, and therefore models\nneed to be equipped with a strategy to resolve such conflicts when they arise.\nOne widely-applicable way of resolving conflicts is to impose preferences over\ninformation sources (e.g., based on source credibility or information recency)\nand adopt the source with higher preference. In this paper, we formulate the\nproblem of reasoning with contradictory information guided by preferences over\nsources as the classical problem of defeasible reasoning, and develop a dataset\ncalled BoardgameQA for measuring the reasoning capacity of LMs in this setting.\nBoardgameQA also incorporates reasoning with implicit background knowledge, to\nbetter reflect reasoning problems in downstream applications. We benchmark\nvarious LMs on BoardgameQA and the results reveal a significant gap in the\nreasoning capacity of state-of-the-art LMs on this problem, showing that\nreasoning with conflicting information does not surface out-of-the-box in LMs.\nWhile performance can be improved with finetuning, it nevertheless remains\npoor.",
        "translated": "非结构化自然文本自动推理是自然语言处理许多潜在应用和开发健壮的人工智能系统的关键要求。最近，语言模型(LM)已经展示了复杂的推理能力，即使没有任何微调。然而，现有的自动推理评估假设模型能够获得一致和连贯的信息。在现实世界中进行推理时，可获得的信息往往不一致或相互矛盾，因此需要为模型配备一种战略，以便在出现这种冲突时解决这种冲突。一种广泛适用的解决冲突的方法是对信息来源强加偏好(例如，基于信息来源的可信度或信息的最新性) ，并以更高的偏好采用信息来源。在本文中，我们提出了由偏好引导的矛盾信息推理问题作为经典的可废止推理问题，并开发了一个名为 BoardgameQA 的数据集来测量在这种情况下 LM 的推理能力。BoardgameQA 还将推理与隐式背景知识结合起来，以更好地反映下游应用程序中的推理问题。我们在 BoardgameQA 上对各种 LM 进行了基准测试，结果显示在这个问题上最先进的 LM 在推理能力上存在显著的差距，表明在 LM 中，带有冲突信息的推理并不是开箱即用的。虽然通过微调可以提高性能，但它仍然很差。"
    },
    {
        "title": "WebGLM: Towards An Efficient Web-Enhanced Question Answering System with\n  Human Preferences",
        "url": "http://arxiv.org/abs/2306.07906v1",
        "pub_date": "2023-06-13",
        "summary": "We present WebGLM, a web-enhanced question-answering system based on the\nGeneral Language Model (GLM). Its goal is to augment a pre-trained large\nlanguage model (LLM) with web search and retrieval capabilities while being\nefficient for real-world deployments. To achieve this, we develop WebGLM with\nstrategies for the LLM-augmented retriever, bootstrapped generator, and human\npreference-aware scorer. Specifically, we identify and address the limitations\nof WebGPT (OpenAI), through which WebGLM is enabled with accuracy, efficiency,\nand cost-effectiveness advantages. In addition, we propose systematic criteria\nfor evaluating web-enhanced QA systems. We conduct multi-dimensional human\nevaluation and quantitative ablation studies, which suggest the outperformance\nof the proposed WebGLM designs over existing systems. WebGLM with the\n10-billion-parameter GLM (10B) is shown to perform better than the\nsimilar-sized WebGPT (13B) and even comparably to WebGPT (175B) in human\nevaluation. The code, demo, and data are at\n\\url{https://github.com/THUDM/WebGLM}.",
        "translated": "本文介绍了基于通用语言模型(GLM)的 Web 增强型问答系统 WebGLM。它的目标是增强一个预先训练的大型语言模型(LLM) ，该模型具有 Web 搜索和检索功能，同时对于现实世界的部署非常有效。为了实现这一点，我们使用 LLM 增强检索器、引导生成器和人类偏好感知记分器的策略来开发 WebGLM。具体来说，我们确定并解决了 WebGPT (OpenAI)的局限性，通过它，WebGLM 具有准确性、效率和成本效益方面的优势。此外，我们提出了评估网络增强 QA 系统的系统标准。我们进行了多维人体评估和定量消融研究，这表明所提出的 WebGLM 设计优于现有系统。具有100亿参数 GLM (10B)的 WebGLM 显示出比类似大小的 WebGPT (13B)更好的性能，甚至在人类评估中与 WebGPT (175B)相当。代码、演示和数据位于 url { https://github.com/thudm/webglm }。"
    },
    {
        "title": "Massively Multilingual Corpus of Sentiment Datasets and Multi-faceted\n  Sentiment Classification Benchmark",
        "url": "http://arxiv.org/abs/2306.07902v1",
        "pub_date": "2023-06-13",
        "summary": "Despite impressive advancements in multilingual corpora collection and model\ntraining, developing large-scale deployments of multilingual models still\npresents a significant challenge. This is particularly true for language tasks\nthat are culture-dependent. One such example is the area of multilingual\nsentiment analysis, where affective markers can be subtle and deeply ensconced\nin culture. This work presents the most extensive open massively multilingual\ncorpus of datasets for training sentiment models. The corpus consists of 79\nmanually selected datasets from over 350 datasets reported in the scientific\nliterature based on strict quality criteria. The corpus covers 27 languages\nrepresenting 6 language families. Datasets can be queried using several\nlinguistic and functional features. In addition, we present a multi-faceted\nsentiment classification benchmark summarizing hundreds of experiments\nconducted on different base models, training objectives, dataset collections,\nand fine-tuning strategies.",
        "translated": "尽管在多语言语料库收集和模型培训方面取得了令人印象深刻的进展，但开发大规模部署多语言模型仍然是一个重大挑战。对于依赖于文化的语言任务尤其如此。一个这样的例子是多语言情感分析领域，其中情感标记可以是微妙的，深深地隐藏在文化。这项工作提出了最广泛的开放大规模多语言数据集训练情感模型。该语料库包括79个手动选择的数据集，从超过350个数据集报告的科学文献基于严格的质量标准。语料库包括代表6个语系的27种语言。可以使用几种语言和函数特性查询数据集。此外，我们提出了一个多方面的情绪分类基准，总结了数百个实验进行了不同的基础模型，训练目标，数据集收集和微调策略。"
    },
    {
        "title": "Artificial Artificial Artificial Intelligence: Crowd Workers Widely Use\n  Large Language Models for Text Production Tasks",
        "url": "http://arxiv.org/abs/2306.07899v1",
        "pub_date": "2023-06-13",
        "summary": "Large language models (LLMs) are remarkable data annotators. They can be used\nto generate high-fidelity supervised training data, as well as survey and\nexperimental data. With the widespread adoption of LLMs, human gold--standard\nannotations are key to understanding the capabilities of LLMs and the validity\nof their results. However, crowdsourcing, an important, inexpensive way to\nobtain human annotations, may itself be impacted by LLMs, as crowd workers have\nfinancial incentives to use LLMs to increase their productivity and income. To\ninvestigate this concern, we conducted a case study on the prevalence of LLM\nusage by crowd workers. We reran an abstract summarization task from the\nliterature on Amazon Mechanical Turk and, through a combination of keystroke\ndetection and synthetic text classification, estimate that 33-46% of crowd\nworkers used LLMs when completing the task. Although generalization to other,\nless LLM-friendly tasks is unclear, our results call for platforms,\nresearchers, and crowd workers to find new ways to ensure that human data\nremain human, perhaps using the methodology proposed here as a stepping stone.\nCode/data: https://github.com/epfl-dlab/GPTurk",
        "translated": "大型语言模型(LLM)是非常出色的数据注释器。它们可以用来生成高保真的监督训练数据，以及调查和实验数据。随着 LLM 的广泛采用，人工黄金标准注释是理解 LLM 功能及其结果有效性的关键。然而，众包作为一种获取人工注释的重要而廉价的方式，可能本身就会受到 LLM 的影响，因为众包工作者有财务动机使用 LLM 来提高他们的生产力和收入。为了调查这一问题，我们进行了一个案例研究的普遍使用 LLM 的人群工作者。我们从亚马逊土耳其机器人的文献中重新运行了一个抽象的总结任务，并且通过组合击键检测和合成文本分类，估计33-46% 的人群工作者在完成任务时使用 LLM。尽管对其他不太适合 LLM 的任务的概括还不清楚，但我们的研究结果呼吁平台、研究人员和群体工作者找到新的方法来确保人类数据仍然是人类的，或许可以使用这里提出的方法作为垫脚石。代码/资料:  https://github.com/epfl-dlab/gpturk"
    },
    {
        "title": "GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio\n  Pretraining for Speech Emotion Recognition",
        "url": "http://arxiv.org/abs/2306.07848v1",
        "pub_date": "2023-06-13",
        "summary": "Contrastive Language-Audio Pretraining (CLAP) has recently exhibited\nimpressive success in diverse fields. In this paper, we propose GEmo-CLAP, a\nkind of efficient gender-attribute-enhanced CLAP model for speech emotion\nrecognition (SER). Specifically, we first build an effective emotion CLAP model\ntermed Emo-CLAP for SER, utilizing various self-supervised learning based\npre-trained models. Then, considering the importance of the gender attribute in\nspeech emotion modeling, two GEmo-CLAP approaches are further proposed to\nintegrate the emotion and gender information of speech signals, forming more\nreasonable objectives. Extensive experiments conducted on the IEMOCAP corpus\ndemonstrate that our proposed two GEmo-CLAP approaches consistently outperform\nthe baseline Emo-CLAP with different pre-trained models, while also achieving\nsuperior recognition performance compared with other state-of-the-art methods.",
        "translated": "对比语言-音频预训练(CLAP)最近在多个领域取得了令人瞩目的成功。本文提出了一种基于性别属性增强的语音情感识别模型 GEmo-CLAP。具体来说，我们首先利用各种基于预训练的自监督学习模型，建立了一个有效的情绪 CLAP 模型，称为情绪 CLAP 模型。然后，考虑到性别属性在语音情感建模中的重要性，进一步提出了两种 Gemo-CLAP 方法来整合语音信号的情感和性别信息，形成更加合理的目标。在 IEMOCAP 语料库上进行的大量实验表明，我们提出的两种 Gemo-CLAP 方法始终优于不同预训练模型的基线 Emo-CLAP，同时与其他最先进的方法相比，也获得了更好的识别性能。"
    },
    {
        "title": "Adversarial Capsule Networks for Romanian Satire Detection and Sentiment\n  Analysis",
        "url": "http://arxiv.org/abs/2306.07845v1",
        "pub_date": "2023-06-13",
        "summary": "Satire detection and sentiment analysis are intensively explored natural\nlanguage processing (NLP) tasks that study the identification of the satirical\ntone from texts and extracting sentiments in relationship with their targets.\nIn languages with fewer research resources, an alternative is to produce\nartificial examples based on character-level adversarial processes to overcome\ndataset size limitations. Such samples are proven to act as a regularization\nmethod, thus improving the robustness of models. In this work, we improve the\nwell-known NLP models (i.e., Convolutional Neural Networks, Long Short-Term\nMemory (LSTM), Bidirectional LSTM, Gated Recurrent Units (GRUs), and\nBidirectional GRUs) with adversarial training and capsule networks. The\nfine-tuned models are used for satire detection and sentiment analysis tasks in\nthe Romanian language. The proposed framework outperforms the existing methods\nfor the two tasks, achieving up to 99.08% accuracy, thus confirming the\nimprovements added by the capsule layers and the adversarial training in NLP\napproaches.",
        "translated": "讽刺检测和情感分析是自然语言处理(NLP)研究的重要课题，主要研究从文本中识别讽刺语气并提取与目标相关的情感。在研究资源较少的语言中，另一种方法是基于字符级对抗过程生成人工示例，以克服数据集大小的限制。这些样本被证明是一种正则化方法，从而提高了模型的鲁棒性。在这项工作中，我们改进了著名的 NLP 模型(即，卷积神经网络，长短期记忆(LSTM) ，双向 LSTM，门控回归单元(GRU) ，和双向 GRU)与对抗训练和胶囊网络。这些经过微调的模型被用于罗马尼亚语中的讽刺探测和情感分析任务。该框架比现有的方法更好地完成了这两个任务，达到了99.08% 的准确率，从而证实了胶囊层的改进和 NLP 方法中的对抗性训练。"
    },
    {
        "title": "Web of Things and Trends in Agriculture: A Systematic Literature Review",
        "url": "http://arxiv.org/abs/2306.09079v1",
        "pub_date": "2023-06-15",
        "summary": "In the past few years, the Web of Things (WOT) became a beneficial\ngame-changing technology within the Agriculture domain as it introduces\ninnovative and promising solutions to the Internet of Things (IoT) agricultural\napplications problems by providing its services. WOT provides the support for\nintegration, interoperability for heterogeneous devices, infrastructures,\nplatforms, and the emergence of various other technologies. The main aim of\nthis study is about understanding and providing a growing and existing research\ncontent, issues, and directions for the future regarding WOT-based agriculture.\nTherefore, a systematic literature review (SLR) of research articles is\npresented by categorizing the selected studies published between 2010 and 2020\ninto the following categories: research type, approaches, and their application\ndomains. Apart from reviewing the state-of-the-art articles on WOT solutions\nfor the agriculture field, a taxonomy of WOT-base agriculture application\ndomains has also been presented in this study. A model has also presented to\nshow the picture of WOT based Smart Agriculture. Lastly, the findings of this\nSLR and the research gaps in terms of open issues have been presented to\nprovide suggestions on possible future directions for the researchers for\nfuture research.",
        "translated": "在过去的几年里，物联网(WOT)在农业领域成为了一个有益的改变游戏规则的技术，因为它通过提供服务引入了创新的和有前途的解决物联网(IoT)农业应用问题的方案。WOT 为异构设备、基础设施、平台以及其他各种技术的出现提供了集成、互操作性的支持。这项研究的主要目的是了解和提供一个不断增长和现有的研究内容，问题和未来的方向，关于基于 WOT 的农业。因此，通过将2010年至2020年间发表的选定研究分为以下几类: 研究类型，方法及其应用领域，对研究文章进行了系统的文献回顾(SLR)。除了回顾有关农业领域 WOT 解决方案的最新文章外，本研究还提出了基于 WOT 的农业应用领域的分类。本文还提出了一个模型来展示基于 WOT 的智能农业的图景。最后，本文介绍了本次研究的结果以及在公开课题方面的研究差距，为研究人员今后的研究提供了可能的方向建议。"
    },
    {
        "title": "Fast and Examination-agnostic Reciprocal Recommendation in Matching\n  Markets",
        "url": "http://arxiv.org/abs/2306.09060v1",
        "pub_date": "2023-06-15",
        "summary": "In matching markets such as job posting and online dating platforms, the\nrecommender system plays a critical role in the success of the platform. Unlike\nstandard recommender systems that suggest items to users, reciprocal\nrecommender systems (RRSs) that suggest other users must take into account the\nmutual interests of users. In addition, ensuring that recommendation\nopportunities do not disproportionately favor popular users is essential for\nthe total number of matches and for fairness among users. Existing\nrecommendation methods in matching markets, however, face computational\nchallenges on large-scale platforms and depend on specific examination\nfunctions in the position-based model (PBM). In this paper, we introduce the\nreciprocal recommendation method based on the matching with transferable\nutility (TU matching) model in the context of ranking recommendations in\nmatching markets and propose a fast and examination-model-free algorithm.\nFurthermore, we evaluate our approach on experiments with synthetic data and\nreal-world data from an online dating platform in Japan. Our method performs\nbetter than or as well as existing methods in terms of the total number of\nmatches and works well even in a large-scale dataset for which one existing\nmethod does not work.",
        "translated": "在招聘和在线约会平台等匹配市场方面，推荐系统对平台的成功起着关键作用。不像标准的推荐系统，建议项目给用户，互惠推荐系统(RRS) ，建议其他用户必须考虑到用户的共同利益。此外，确保推荐机会不会不成比例地偏向受欢迎的用户，对于匹配的总数和用户之间的公平性至关重要。然而，现有的匹配市场推荐方法在大规模平台上面临计算挑战，并且依赖于基于位置模型(PBM)中的特定检验函数。本文在匹配市场推荐排序的背景下，介绍了基于匹配可转移效用(TU 匹配)模型的互惠推荐方法，并提出了一种快速、无检验模型的算法。此外，我们评估了我们的实验方法与合成数据和真实世界的数据从一个在线约会平台在日本。就匹配总数而言，我们的方法比现有方法执行得更好，甚至在一个现有方法无法工作的大规模数据集中也能很好地工作。"
    },
    {
        "title": "Mapping Researcher Activity based on Publication Data by means of\n  Transformers",
        "url": "http://arxiv.org/abs/2306.09049v1",
        "pub_date": "2023-06-15",
        "summary": "Modern performance on several natural language processing (NLP) tasks has\nbeen enhanced thanks to the Transformer-based pre-trained language model BERT.\nWe employ this concept to investigate a local publication database. Research\npapers are encoded and clustered to form a landscape view of the scientific\ntopics, in which research is active. Authors working on similar topics can be\nidentified by calculating the similarity between their papers. Based on this,\nwe define a similarity metric between authors. Additionally we introduce the\nconcept of self-similarity to indicate the topical variety of authors.",
        "translated": "现代自然语言处理(NLP)任务的性能得到了提高，这要归功于基于变压器的预训练语言模型 BERT。我们使用这个概念来调查一个本地出版物数据库。研究论文的编码和聚类形成了一个景观的科学主题，其中研究是活跃的。研究类似主题的作者可以通过计算他们论文之间的相似性来识别。在此基础上，我们定义了作者之间的相似度量。此外，我们还引入了自相似的概念，以表明作者的主题多样性。"
    },
    {
        "title": "RecFusion: A Binomial Diffusion Process for 1D Data for Recommendation",
        "url": "http://arxiv.org/abs/2306.08947v1",
        "pub_date": "2023-06-15",
        "summary": "In this paper we propose RecFusion, which comprise a set of diffusion models\nfor recommendation. Unlike image data which contain spatial correlations, a\nuser-item interaction matrix, commonly utilized in recommendation, lacks\nspatial relationships between users and items. We formulate diffusion on a 1D\nvector and propose binomial diffusion, which explicitly models binary user-item\ninteractions with a Bernoulli process. We show that RecFusion approaches the\nperformance of complex VAE baselines on the core recommendation setting (top-n\nrecommendation for binary non-sequential feedback) and the most common datasets\n(MovieLens and Netflix). Our proposed diffusion models that are specialized for\n1D and/or binary setups have implications beyond recommendation systems, such\nas in the medical domain with MRI and CT scans.",
        "translated": "在本文中，我们提出了 RecFusion，它包含了一组用于推荐的扩散模型。与包含空间相关性的图像数据不同，通常用于推荐的用户-项目交互矩阵缺乏用户和项目之间的空间关系。我们在一维向量上描述扩散，并提出二项式扩散，它明确地模拟与伯努利过程的二进制用户-项目交互。我们表明 RecFusion 在核心推荐设置(二进制非顺序反馈的前 n 推荐)和最常见的数据集(MovieLens 和 Netflix)上接近复杂 VAE 基线的性能。我们提出的扩散模型是专门为一维和/或二进制设置的影响超出推荐系统，如在医学领域的 MRI 和 CT 扫描。"
    },
    {
        "title": "Document Entity Retrieval with Massive and Noisy Pre-training",
        "url": "http://arxiv.org/abs/2306.08937v1",
        "pub_date": "2023-06-15",
        "summary": "Visually-Rich Document Entity Retrieval (VDER) is a type of machine learning\ntask that aims at recovering text spans in the documents for each of the\nentities in question. VDER has gained significant attention in recent years\nthanks to its broad applications in enterprise AI. Unfortunately, as document\nimages often contain personally identifiable information (PII), publicly\navailable data have been scarce, not only because of privacy constraints but\nalso the costs of acquiring annotations. To make things worse, each dataset\nwould often define its own sets of entities, and the non-overlapping entity\nspaces between datasets make it difficult to transfer knowledge between\ndocuments. In this paper, we propose a method to collect massive-scale, noisy,\nand weakly labeled data from the web to benefit the training of VDER models.\nSuch a method will generate a huge amount of document image data to compensate\nfor the lack of training data in many VDER settings. Moreover, the collected\ndataset named DocuNet would not need to be dependent on specific document types\nor entity sets, making it universally applicable to all VDER tasks. Empowered\nby DocuNet, we present a lightweight multimodal architecture named UniFormer,\nwhich can learn a unified representation from text, layout, and image crops\nwithout needing extra visual pertaining. We experiment with our methods on\npopular VDER models in various settings and show the improvements when this\nmassive dataset is incorporated with UniFormer on both classic entity retrieval\nand few-shot learning settings.",
        "translated": "可视化丰富文档实体检索(VDER)是一种机器学习任务，旨在恢复文档中涉及到的每个实体的文本跨度。VDER 由于在企业人工智能中的广泛应用，近年来受到了广泛的关注。遗憾的是，由于文档图像通常包含个人身份信息(pII) ，公开可用的数据很少，这不仅是因为隐私限制，还因为获取注释的成本。更糟糕的是，每个数据集通常会定义自己的实体集，而数据集之间不重叠的实体空间使得在文档之间传递知识变得非常困难。本文提出了一种从网络上收集大规模、有噪声和弱标记数据的方法，有利于 VDER 模型的训练。这种方法将产生大量的文档图像数据，以弥补许多 VDER 设置中训练数据的不足。此外，名为 DocuNet 的收集的数据集不需要依赖于特定的文档类型或实体集，这使得它普遍适用于所有 VDER 任务。在 DocuNet 的支持下，我们提出了一个轻量级的多模态体系结构，名为 UniForm，它可以从文本、布局和图像作物中学习统一的表示，而不需要额外的视觉修饰。我们在不同的设置下对流行的 VDER 模型进行了实验，结果表明，在经典的实体检索和少镜头学习设置下，将这个海量数据集与 UniForm 结合起来，可以得到改进。"
    },
    {
        "title": "SIGHT: A Large Annotated Dataset on Student Insights Gathered from\n  Higher Education Transcripts",
        "url": "http://arxiv.org/abs/2306.09343v1",
        "pub_date": "2023-06-15",
        "summary": "Lectures are a learning experience for both students and teachers. Students\nlearn from teachers about the subject material, while teachers learn from\nstudents about how to refine their instruction. However, online student\nfeedback is unstructured and abundant, making it challenging for teachers to\nlearn and improve. We take a step towards tackling this challenge. First, we\ncontribute a dataset for studying this problem: SIGHT is a large dataset of 288\nmath lecture transcripts and 15,784 comments collected from the Massachusetts\nInstitute of Technology OpenCourseWare (MIT OCW) YouTube channel. Second, we\ndevelop a rubric for categorizing feedback types using qualitative analysis.\nQualitative analysis methods are powerful in uncovering domain-specific\ninsights, however they are costly to apply to large data sources. To overcome\nthis challenge, we propose a set of best practices for using large language\nmodels (LLMs) to cheaply classify the comments at scale. We observe a striking\ncorrelation between the model's and humans' annotation: Categories with\nconsistent human annotations (&gt;$0.9$ inter-rater reliability, IRR) also display\nhigher human-model agreement (&gt;$0.7$), while categories with less consistent\nhuman annotations ($0.7$-$0.8$ IRR) correspondingly demonstrate lower\nhuman-model agreement ($0.3$-$0.5$). These techniques uncover useful student\nfeedback from thousands of comments, costing around $\\$0.002$ per comment. We\nconclude by discussing exciting future directions on using online student\nfeedback and improving automated annotation techniques for qualitative\nresearch.",
        "translated": "讲座对学生和老师来说都是一次学习的经历。学生向老师学习课程材料，而老师向学生学习如何改进教学。然而，在线学生的反馈是非结构化的和丰富的，这使得教师学习和提高具有挑战性。我们朝着应对这一挑战迈出了一步。首先，我们贡献了一个数据集来研究这个问题: SIGHT 是一个大型数据集，包括288份数学课堂讲稿和15,784条评论，这些评论来自麻省理工学院开放课程软件(MIT OCW) YouTube 频道。其次，我们开发了一个使用定性分析对反馈类型进行分类的标准。定性分析方法在揭示特定领域的见解方面非常强大，但是它们应用于大型数据源的成本很高。为了克服这一挑战，我们提出了一套使用大型语言模型(LLM)以低成本对注释进行大规模分类的最佳实践。我们观察到模型注释和人类注释之间存在显著的相关性: 具有一致的人类注释的类别(> 0.9 $评分者间可靠性，IRR)也显示出较高的人类模型一致性(> 0.7 $) ，而具有不一致的人类注释的类别($0.7 $- $0.8 $IRR)相应地显示出较低的人类模型一致性($0.3 $- $0.5 $)。这些技术可以从成千上万条评论中发现有用的学生反馈，每条评论的成本约为0.002美元。最后，我们讨论了使用在线学生反馈和改进质性研究自动注释技术的令人兴奋的未来发展方向。"
    },
    {
        "title": "PaReprop: Fast Parallelized Reversible Backpropagation",
        "url": "http://arxiv.org/abs/2306.09342v1",
        "pub_date": "2023-06-15",
        "summary": "The growing size of datasets and deep learning models has made faster and\nmemory-efficient training crucial. Reversible transformers have recently been\nintroduced as an exciting new method for extremely memory-efficient training,\nbut they come with an additional computation overhead of activation\nre-computation in the backpropagation phase. We present PaReprop, a fast\nParallelized Reversible Backpropagation algorithm that parallelizes the\nadditional activation re-computation overhead in reversible training with the\ngradient computation itself in backpropagation phase. We demonstrate the\neffectiveness of the proposed PaReprop algorithm through extensive benchmarking\nacross model families (ViT, MViT, Swin and RoBERTa), data modalities (Vision &amp;\nNLP), model sizes (from small to giant), and training batch sizes. Our\nempirical results show that PaReprop achieves up to 20% higher training\nthroughput than vanilla reversible training, largely mitigating the theoretical\noverhead of 25% lower throughput from activation recomputation in reversible\ntraining. Project page: https://tylerzhu.com/pareprop.",
        "translated": "不断增长的数据集和深度学习模型使得更快、更有效的训练变得至关重要。可逆变压器作为一种新兴的高效存储器训练方法，近年来得到了广泛的应用，但是在反向传播阶段，这种方法需要增加激活重计算的计算开销。本文提出了一种快速并行化可逆反向传播算法，它将可逆训练中的附加激活重计算开销与反向传播阶段的梯度计算本身并行化。我们通过跨模型家族(ViT，MViT，Swin 和 RoBERTa) ，数据模式(Vision & NLP) ，模型大小(从小到大)和训练批量大小的广泛基准测试来证明所提出的 PaReprop 算法的有效性。我们的实验结果表明，PaReprop 比普通可逆训练提高了20% 的训练吞吐量，大大降低了可逆训练中激活重计算吞吐量降低25% 的理论开销。项目主页:  https://tylerzhu.com/pareprop。"
    },
    {
        "title": "Span-Selective Linear Attention Transformers for Effective and Robust\n  Schema-Guided Dialogue State Tracking",
        "url": "http://arxiv.org/abs/2306.09340v1",
        "pub_date": "2023-06-15",
        "summary": "In schema-guided dialogue state tracking models estimate the current state of\na conversation using natural language descriptions of the service schema for\ngeneralization to unseen services. Prior generative approaches which decode\nslot values sequentially do not generalize well to variations in schema, while\ndiscriminative approaches separately encode history and schema and fail to\naccount for inter-slot and intent-slot dependencies. We introduce SPLAT, a\nnovel architecture which achieves better generalization and efficiency than\nprior approaches by constraining outputs to a limited prediction space. At the\nsame time, our model allows for rich attention among descriptions and history\nwhile keeping computation costs constrained by incorporating linear-time\nattention. We demonstrate the effectiveness of our model on the Schema-Guided\nDialogue (SGD) and MultiWOZ datasets. Our approach significantly improves upon\nexisting models achieving 85.3 JGA on the SGD dataset. Further, we show\nincreased robustness on the SGD-X benchmark: our model outperforms the more\nthan 30$\\times$ larger D3ST-XXL model by 5.0 points.",
        "translated": "在模式引导的对话中，状态跟踪模型使用服务模式的自然语言描述来估计会话的当前状态，以便将其泛化为看不见的服务。先前解码槽值的生成方法不能很好地推广到模式中的变化，而区分方法分别编码历史和模式，不能解释槽间和意向槽依赖关系。我们介绍了 SPLAT，这是一种新的体系结构，它通过将输出限制在有限的预测空间内，实现了比以前的方法更好的泛化和效率。同时，我们的模型允许在描述和历史之间有丰富的注意力，同时通过合并线性时间注意力来保持计算成本的约束。我们在模式引导对话(SGD)和 MultiWOZ 数据集上演示了我们的模型的有效性。我们的方法显著改进了在 SGD 数据集上实现85.3 JGA 的现有模型。此外，我们在 SGD-X 基准上显示出更强的鲁棒性: 我们的模型比价格超过30美元的大型 D3ST-XXL 模型高出5.0个百分点。"
    },
    {
        "title": "WizMap: Scalable Interactive Visualization for Exploring Large Machine\n  Learning Embeddings",
        "url": "http://arxiv.org/abs/2306.09328v1",
        "pub_date": "2023-06-15",
        "summary": "Machine learning models often learn latent embedding representations that\ncapture the domain semantics of their training data. These embedding\nrepresentations are valuable for interpreting trained models, building new\nmodels, and analyzing new datasets. However, interpreting and using embeddings\ncan be challenging due to their opaqueness, high dimensionality, and the large\nsize of modern datasets. To tackle these challenges, we present WizMap, an\ninteractive visualization tool to help researchers and practitioners easily\nexplore large embeddings. With a novel multi-resolution embedding summarization\nmethod and a familiar map-like interaction design, WizMap enables users to\nnavigate and interpret embedding spaces with ease. Leveraging modern web\ntechnologies such as WebGL and Web Workers, WizMap scales to millions of\nembedding points directly in users' web browsers and computational notebooks\nwithout the need for dedicated backend servers. WizMap is open-source and\navailable at the following public demo link: https://poloclub.github.io/wizmap.",
        "translated": "机器学习模型经常学习潜在的嵌入表示，捕获其训练数据的领域语义。这些嵌入式表示对于解释训练过的模型、建立新模型和分析新数据集是有价值的。然而，由于嵌入的不透明性、高维数和现代数据集的巨大规模，解释和使用嵌入可能是具有挑战性的。为了应对这些挑战，我们展示了 WizMap，这是一个交互式可视化工具，可以帮助研究人员和从业者轻松地探索大型嵌入。WizMap 提供了一种新颖的多分辨率嵌入摘要方法和一种常见的类似地图的交互设计，使用户可以轻松地导航和解释嵌入空间。利用 WebGL 和 Web Workers 等现代 Web 技术，WizMap 可以直接在用户的 Web 浏览器和计算笔记本中嵌入数百万个点，而不需要专用的后端服务器。WizMap 是开源的，可在以下公共演示链接下载:  https://poloclub.github.io/WizMap。"
    },
    {
        "title": "Lexical Speaker Error Correction: Leveraging Language Models for Speaker\n  Diarization Error Correction",
        "url": "http://arxiv.org/abs/2306.09313v1",
        "pub_date": "2023-06-15",
        "summary": "Speaker diarization (SD) is typically used with an automatic speech\nrecognition (ASR) system to ascribe speaker labels to recognized words. The\nconventional approach reconciles outputs from independently optimized ASR and\nSD systems, where the SD system typically uses only acoustic information to\nidentify the speakers in the audio stream. This approach can lead to speaker\nerrors especially around speaker turns and regions of speaker overlap. In this\npaper, we propose a novel second-pass speaker error correction system using\nlexical information, leveraging the power of modern language models (LMs). Our\nexperiments across multiple telephony datasets show that our approach is both\neffective and robust. Training and tuning only on the Fisher dataset, this\nerror correction approach leads to relative word-level diarization error rate\n(WDER) reductions of 15-30% on three telephony datasets: RT03-CTS, Callhome\nAmerican English and held-out portions of Fisher.",
        "translated": "说话人辨认(SD)通常与自动语音识别(ASR)系统一起使用，将说话人标签归属于已识别的单词。传统的方法协调独立优化的 ASR 和 SD 系统的输出，其中 SD 系统通常只使用声学信息来识别音频流中的扬声器。这种方法可能导致说话人误差，特别是在说话人转圈和说话人重叠区域周围。在本文中，我们利用现代语言模型(LMs)的能力，提出了一种新的利用词汇信息的二次说话人纠错系统。我们在多个电话数据集上的实验表明，我们的方法既有效又可靠。仅在 Fisher 数据集上进行训练和调整，这种错误纠正方法导致三个电话数据集: RT03-CTS，Callhome American English 和 Fisher 的保留部分的相对词级二值化错误率(WDER)降低15-30% 。"
    },
    {
        "title": "Semantic HELM: An Interpretable Memory for Reinforcement Learning",
        "url": "http://arxiv.org/abs/2306.09312v1",
        "pub_date": "2023-06-15",
        "summary": "Reinforcement learning agents deployed in the real world often have to cope\nwith partially observable environments. Therefore, most agents employ memory\nmechanisms to approximate the state of the environment. Recently, there have\nbeen impressive success stories in mastering partially observable environments,\nmostly in the realm of computer games like Dota 2, StarCraft II, or MineCraft.\nHowever, none of these methods are interpretable in the sense that it is not\ncomprehensible for humans how the agent decides which actions to take based on\nits inputs. Yet, human understanding is necessary in order to deploy such\nmethods in high-stake domains like autonomous driving or medical applications.\nWe propose a novel memory mechanism that operates on human language to\nilluminate the decision-making process. First, we use CLIP to associate visual\ninputs with language tokens. Then we feed these tokens to a pretrained language\nmodel that serves the agent as memory and provides it with a coherent and\ninterpretable representation of the past. Our memory mechanism achieves\nstate-of-the-art performance in environments where memorizing the past is\ncrucial to solve tasks. Further, we present situations where our memory\ncomponent excels or fails to demonstrate strengths and weaknesses of our new\napproach.",
        "translated": "部署在现实世界中的强化学习经常不得不应对部分可观测的环境。因此，大多数代理都使用内存机制来近似处理环境的状态。最近，在掌握部分可观察的环境方面有了令人印象深刻的成功故事，主要是在计算机游戏领域，如 Dota 2、 StarCraft II 或 MineCraft。然而，所有这些方法都无法解释，因为人类无法理解代理人如何根据其输入决定采取哪些行动。然而，人类的理解是必要的，为了部署这样的方法在高风险的领域，如自动驾驶或医疗应用程序。我们提出了一种新的记忆机制，运行在人类的语言，以说明决策过程。首先，我们使用 CLIP 将可视输入与语言标记关联起来。然后，我们将这些标记提供给一个预先训练好的语言模型，该模型为代理提供记忆，并为代理提供一个连贯的、可解释的过去表示。我们的记忆机制在记忆过去对解决任务至关重要的环境中取得了最先进的性能。此外，我们提出的情况下，我们的记忆组件优秀或未能证明我们的新方法的长处和弱点。"
    },
    {
        "title": "Matching Pairs: Attributing Fine-Tuned Models to their Pre-Trained Large\n  Language Models",
        "url": "http://arxiv.org/abs/2306.09308v1",
        "pub_date": "2023-06-15",
        "summary": "The wide applicability and adaptability of generative large language models\n(LLMs) has enabled their rapid adoption. While the pre-trained models can\nperform many tasks, such models are often fine-tuned to improve their\nperformance on various downstream applications. However, this leads to issues\nover violation of model licenses, model theft, and copyright infringement.\nMoreover, recent advances show that generative technology is capable of\nproducing harmful content which exacerbates the problems of accountability\nwithin model supply chains. Thus, we need a method to investigate how a model\nwas trained or a piece of text was generated and what their pre-trained base\nmodel was. In this paper we take the first step to address this open problem by\ntracing back the origin of a given fine-tuned LLM to its corresponding\npre-trained base model. We consider different knowledge levels and attribution\nstrategies, and find that we can correctly trace back 8 out of the 10 fine\ntuned models with our best method.",
        "translated": "生成式大型语言模型(LLM)的广泛适用性和适应性使它们得以迅速采用。虽然预先训练的模型可以执行许多任务，但这些模型通常经过微调，以提高它们在各种下游应用程序中的性能。然而，这导致了违反模型许可证、模型盗窃和盗版的问题。此外，最近的进展表明，生成技术能够产生有害的内容，这加剧了示范供应链中的问责问题。因此，我们需要一种方法来研究如何训练一个模型或一段文本生成，以及他们的预先训练的基础模型是什么。在本文中，我们采取的第一步，以解决这个开放的问题，追溯起源的一个给定的微调 LLM 相应的预训练的基础模型。我们考虑了不同的知识水平和归因策略，发现我们可以用我们最好的方法正确地追溯10个微调模型中的8个。"
    },
    {
        "title": "Quality and Efficiency of Manual Annotation: Pre-annotation Bias",
        "url": "http://arxiv.org/abs/2306.09307v1",
        "pub_date": "2023-06-15",
        "summary": "This paper presents an analysis of annotation using an automatic\npre-annotation for a mid-level annotation complexity task -- dependency syntax\nannotation. It compares the annotation efforts made by annotators using a\npre-annotated version (with a high-accuracy parser) and those made by fully\nmanual annotation. The aim of the experiment is to judge the final annotation\nquality when pre-annotation is used. In addition, it evaluates the effect of\nautomatic linguistically-based (rule-formulated) checks and another annotation\non the same data available to the annotators, and their influence on annotation\nquality and efficiency. The experiment confirmed that the pre-annotation is an\nefficient tool for faster manual syntactic annotation which increases the\nconsistency of the resulting annotation without reducing its quality.",
        "translated": "本文针对一个中级注释复杂性任务——依赖语法注释，提出了一种使用自动预注释的注释分析方法。它比较了使用预注释版本(带有高精度解析器)的注释者所做的注释工作和完全手动注释所做的注释工作。实验的目的是在使用预注释时判断最终的注释质量。此外，它还评估了基于语言的(规则制定的)自动检查和另一个注释对注释者可获得的相同数据的影响，以及它们对注释质量和效率的影响。实验结果表明，预注释是一种提高人工语法注释速度的有效工具，可以在不降低注释质量的前提下提高注释结果的一致性。"
    },
    {
        "title": "Propagating Knowledge Updates to LMs Through Distillation",
        "url": "http://arxiv.org/abs/2306.09306v1",
        "pub_date": "2023-06-15",
        "summary": "Modern language models have the capacity to store and use immense amounts of\nknowledge about real-world entities, but it remains unclear how to update their\nimplicit \"knowledge bases.'' While prior methods for updating knowledge in LMs\nsuccessfully inject facts, updated LMs then fail to make inferences based on\nthese injected facts. In this work, we demonstrate that a context\ndistillation-based approach can both impart knowledge about entities and\npropagate that knowledge to enable broader inferences. Our approach consists of\ntwo stages: transfer set generation and distillation on the transfer set. We\nfirst generate a transfer set by simply prompting a language model to generate\na continuation from the entity definition. Then, we update the model parameters\nso that the distribution of the LM (the student) matches the distribution of\nthe LM conditioned on the definition (the teacher) on the transfer set. Our\nexperiments demonstrate that this approach is more effective in propagating\nknowledge updates compared to fine-tuning and other gradient-based\nknowledge-editing methods without compromising performance in other contexts,\neven when injecting the definitions of up to 150 entities at once.",
        "translated": "现代语言模型有能力存储和使用关于现实世界实体的大量知识，但是如何更新它们隐含的“知识库”仍然不清楚先前更新 LM 知识的方法成功地注入了事实，但是更新后的 LM 无法根据这些注入的事实进行推断。在这项工作中，我们证明了一个基于上下文精馏的方法既可以传递关于实体的知识，又可以传播这些知识，以便能够进行更广泛的推论。我们的方法包括两个阶段: 转移集的产生和转移集上的精馏。我们首先通过简单地提示语言模型从实体定义生成延续来生成传输集。然后，我们更新模型参数，使 LM (学生)的分布与 LM 的分布匹配条件下的定义(教师)在转移集上。我们的实验表明，与微调和其他基于梯度的知识编辑方法相比，这种方法在传播知识更新方面更有效，而不会损害其他情况下的性能，即使一次注入多达150个实体的定义。"
    },
    {
        "title": "Can Language Models Teach Weaker Agents? Teacher Explanations Improve\n  Students via Theory of Mind",
        "url": "http://arxiv.org/abs/2306.09299v1",
        "pub_date": "2023-06-15",
        "summary": "Large Language Models (LLMs) perform complex reasoning by generating\nexplanations for their predictions. However, a complementary goal of\nexplanations is to also communicate useful knowledge that improves weaker\nagents. Hence, we investigate whether LLMs also make good teachers for weaker\nagents. In particular, we consider a student-teacher framework between two LLM\nagents and study if, when, and how the teacher should intervene with natural\nlanguage explanations to improve the student's performance. Since communication\nis expensive, we define a budget such that the teacher only communicates\nexplanations for a fraction of the data, after which the student should perform\nwell on its own. We decompose the teaching problem along four axes: (1) if\nteacher's test time intervention improve student predictions, (2) when it is\nworth explaining a data point, (3) how the teacher should personalize\nexplanations to better teach the student, and (4) if teacher explanations also\nimprove student performance on future unexplained data. We first show that\nteacher LLMs can indeed intervene on student reasoning to improve their\nperformance. Next, we propose a Theory of Mind approach, in which the teacher\nbuilds two few-shot mental models of the student. The first model defines an\nIntervention Function that simulates the utility of an intervention, allowing\nthe teacher to intervene when this utility is the highest and improving student\nperformance at lower budgets. The second model enables the teacher to\npersonalize explanations for a particular student and outperform unpersonalized\nteachers. We also demonstrate that in multi-turn interactions, teacher\nexplanations generalize and learning from explained data improves student\nperformance on future unexplained data. Finally, we also verify that misaligned\nteachers can lower student performance to random chance by intentionally\nmisleading them.",
        "translated": "大型语言模型(LLM)通过生成对其预测的解释来执行复杂的推理。然而，解释的一个补充目标是传达有用的知识，以改善较弱的代理。因此，我们研究 LLM 是否也可以成为弱者的好老师。特别地，我们考虑两个 LLM 代理之间的学生-教师框架，并研究教师是否、何时以及如何应该干预自然语言解释以提高学生的成绩。由于沟通是昂贵的，我们定义一个预算，使教师只传达一小部分数据的解释，在此之后，学生应该自己表现良好。我们将教学问题分解为四个方面: (1)教师的考试时间干预是否改善了学生的预测; (2)什么时候值得解释一个数据点; (3)教师应该如何个性化解释以更好地教育学生; (4)教师的解释是否也改善了学生对未来未解释数据的表现。我们首先证明教师 LLM 确实可以干预学生的推理，以提高他们的表现。接下来，我们提出一种心理理论的方法，在这种方法中，教师建立学生的两个短镜头心理模型。第一个模型定义了一个干预函数，它模拟了干预的效用，允许教师在效用最高时进行干预，并在较低的预算下提高学生的表现。第二种模式使教师能够针对特定学生进行个性化的解释，并胜过非个性化的教师。我们还证明，在多回合互动中，教师的解释概括和学习解释的数据提高了学生在未来的未解释数据的表现。最后，我们还验证了错位教师可以通过故意误导学生来降低学生的随机成绩。"
    },
    {
        "title": "GRM: Generative Relevance Modeling Using Relevance-Aware Sample\n  Estimation for Document Retrieval",
        "url": "http://arxiv.org/abs/2306.09938v1",
        "pub_date": "2023-06-16",
        "summary": "Recent studies show that Generative Relevance Feedback (GRF), using text\ngenerated by Large Language Models (LLMs), can enhance the effectiveness of\nquery expansion. However, LLMs can generate irrelevant information that harms\nretrieval effectiveness. To address this, we propose Generative Relevance\nModeling (GRM) that uses Relevance-Aware Sample Estimation (RASE) for more\naccurate weighting of expansion terms. Specifically, we identify similar real\ndocuments for each generated document and use a neural re-ranker to estimate\ntheir relevance. Experiments on three standard document ranking benchmarks show\nthat GRM improves MAP by 6-9% and R@1k by 2-4%, surpassing previous methods.",
        "translated": "最近的研究表明，使用大语言模型生成的文本的生成关联反馈可以提高查询扩展的有效性。然而，LLM 会产生不相关的信息，从而影响检索效率。为了解决这个问题，我们提出了生成相关性建模(GRM) ，它使用相关性感知的样本估计(RASE)来更准确地给扩展项加权。具体来说，我们为每个生成的文档识别相似的真实文档，并使用神经重新排序来估计它们的相关性。在三个标准文档排序基准上的实验表明，GRM 对 MAP 提高了6-9% ，对 R@1k 提高了2-4% ，超过了以往的排序方法。"
    },
    {
        "title": "Smart Sentiment Analysis-based Search Engine Classification Intelligence",
        "url": "http://arxiv.org/abs/2306.09777v1",
        "pub_date": "2023-06-16",
        "summary": "Search engines are widely used for finding information on the internet.\nHowever, there are limitations in the current search approach, such as\nproviding popular but not necessarily relevant results. This research addresses\nthe issue of polysemy in search results by implementing a search function that\ndetermines the sentimentality of the retrieved information. The study utilizes\na web crawler to collect data from the British Broadcasting Corporation (BBC)\nnews site, and the sentimentality of the news articles is determined using the\nSentistrength program. The results demonstrate that the proposed search\nfunction improves recall value while accurately retrieving nonpolysemous news.\nFurthermore, Sentistrength outperforms deep learning and clustering methods in\nclassifying search results. The methodology presented in this article can be\napplied to analyze the sentimentality and reputation of entities on the\ninternet.",
        "translated": "搜索引擎被广泛用于在互联网上查找信息。然而，目前的搜索方法存在一些局限性，比如提供受欢迎但不一定相关的结果。该研究通过实现一个决定检索信息多情性的搜索函数来解决搜索结果中的多义性问题。该研究利用网络爬虫从英国广播公司(英国广播公司)新闻网站收集数据，新闻文章的多愁善感程度是通过感知力程序确定的。实验结果表明，该搜索函数在准确检索非多义新闻的同时，提高了查全率。此外，感知强度在分类搜索结果方面优于深度学习和聚类方法。本文提出的方法可以用来分析互联网上实体的情感和声誉。"
    },
    {
        "title": "Online Distillation for Pseudo-Relevance Feedback",
        "url": "http://arxiv.org/abs/2306.09657v1",
        "pub_date": "2023-06-16",
        "summary": "Model distillation has emerged as a prominent technique to improve neural\nsearch models. To date, distillation taken an offline approach, wherein a new\nneural model is trained to predict relevance scores between arbitrary queries\nand documents. In this paper, we explore a departure from this offline\ndistillation strategy by investigating whether a model for a specific query can\nbe effectively distilled from neural re-ranking results (i.e., distilling in an\nonline setting). Indeed, we find that a lexical model distilled online can\nreasonably replicate the re-ranking of a neural model. More importantly, these\nmodels can be used as queries that execute efficiently on indexes. This second\nretrieval stage can enrich the pool of documents for re-ranking by identifying\ndocuments that were missed in the first retrieval stage. Empirically, we show\nthat this approach performs favourably when compared with established pseudo\nrelevance feedback techniques, dense retrieval methods, and sparse-dense\nensemble \"hybrid\" approaches.",
        "translated": "模型蒸馏技术已经成为改进神经搜索模型的一个突出技术。迄今为止，蒸馏采用离线方法，其中一个新的神经模型被训练来预测任意查询和文档之间的相关性得分。在本文中，我们通过研究一个特定查询的模型是否可以有效地从神经重新排序结果(即，在线设置中提取)中提取，来探索这种离线精馏策略的一个偏离。事实上，我们发现在线提取的词汇模型可以合理地复制神经模型的重新排序。更重要的是，这些模型可以用作在索引上高效执行的查询。这第二个检索阶段可以通过识别第一个检索阶段错过的文件来丰富重新排序的文件库。经验表明，与已有的伪关联反馈技术、密集检索方法和稀疏密集集合“混合”方法相比，这种方法表现得更好。"
    },
    {
        "title": "I Want This, Not That: Personalized Summarization of Scientific\n  Scholarly Texts",
        "url": "http://arxiv.org/abs/2306.09604v1",
        "pub_date": "2023-06-16",
        "summary": "In this paper, we present a proposal for an unsupervised algorithm, P-Summ,\nthat generates an extractive summary of scientific scholarly text to meet the\npersonal knowledge needs of the user. The method delves into the latent\nsemantic space of the document exposed by Weighted Non-negative Matrix\nFactorization, and scores sentences in consonance with the knowledge needs of\nthe user. The novelty of the algorithm lies in its ability to include desired\nknowledge and eliminate unwanted knowledge in the personal summary.\n  We also propose a multi-granular evaluation framework, which assesses the\nquality of generated personal summaries at three levels of granularity -\nsentence, terms and semantic. The framework uses system generated generic\nsummary instead of human generated summary as gold standard for evaluating the\nquality of personal summary generated by the algorithm. The effectiveness of\nthe algorithm at the semantic level is evaluated by taking into account the\nreference summary and the knowledge signals. We evaluate the performance of\nP-Summ algorithm over four data-sets consisting of scientific articles. Our\nempirical investigations reveal that the proposed method has the capability to\nmeet negative (or positive) knowledge preferences of the user.",
        "translated": "在本文中，我们提出了一个无监督算法，P-Summ，它生成一个提取摘要的科学学术文本，以满足用户的个人知识需求。该方法深入研究文档的潜在语义空间，通过加权非负矩阵分解，并根据用户的知识需求给句子打分。算法的新颖性在于它能够在个人摘要中包含所需的知识并消除不需要的知识。我们还提出了一个多粒度评估框架，该框架从句子、术语和语义三个粒度级别评估生成的个人摘要的质量。该框架采用系统生成的通用摘要代替人工生成的摘要作为评价算法生成的个人摘要质量的黄金标准。通过参考文献总结和知识信号，从语义层面对算法的有效性进行了评价。我们评估了 P-Summ 算法在四个由科学论文组成的数据集上的性能。实证研究表明，该方法能够满足用户的消极(或积极)知识偏好。"
    },
    {
        "title": "Just One Byte (per gradient): A Note on Low-Bandwidth Decentralized\n  Language Model Finetuning Using Shared Randomness",
        "url": "http://arxiv.org/abs/2306.10015v1",
        "pub_date": "2023-06-16",
        "summary": "Language model training in distributed settings is limited by the\ncommunication cost of gradient exchanges. In this short note, we extend recent\nwork from Malladi et al. (2023), using shared randomness to perform distributed\nfine-tuning with low bandwidth. The method is a natural decentralized extension\nof memory-efficient Simultaneous Perturbation Stochastic Approximation (SPSA).\nEach iteration, each machine seeds a Random Number Generator (RNG) to perform\nlocal reproducible perturbations on model weights and calculate and exchange\nscalar projected gradients, which are then used to update each model. By using\na (machine, sample) identifier as the random seed, each model can regenerate\none another's perturbations. As machines only exchange single-byte projected\ngradients, this is highly communication efficient. There are also potential\nprivacy benefits, as projected gradients may be calculated on different\ntraining data, and models never access the other's data. Our approach not only\ndrastically reduces communication bandwidth requirements but also accommodates\ndynamic addition or removal of machines during the training process and retains\nthe memory-efficient and inference-only advantages of recent work. We perform\nproof-of-concept experiments to demonstrate the potential usefulness of this\nmethod, building off of rich literature on distributed optimization and\nmemory-efficient training.",
        "translated": "分布式环境下的语言模型训练受到梯度交换通信成本的限制。在这个简短的说明中，我们扩展了 Malladi 等人(2023)最近的工作，使用共享随机性来执行低带宽的分布式微调。这种方法是记忆效率同步扰动随机逼近(SPSA)的自然分散扩展。每次迭代，每台机器播种一个随机数生成器(RNG) ，对模型权重执行局部可重复的扰动，并计算和交换标量投影梯度，然后用于更新每个模型。通过使用一个(机器，样本)标识符作为随机种子，每个模型可以重新生成彼此的扰动。由于机器只交换单字节投影渐变，这是高通信效率。还有潜在的隐私好处，因为预测的梯度可以在不同的训练数据上计算，而且模型永远不会访问其他人的数据。我们的方法不仅大大降低了通信带宽的要求，而且还可以在训练过程中动态添加或删除机器，并保留了最近工作的内存效率和推理优势。我们进行了概念验证实验，以证明这种方法的潜在有用性，建立在丰富的文献关于分布式优化和记忆效率培训。"
    },
    {
        "title": "MagicBrush: A Manually Annotated Dataset for Instruction-Guided Image\n  Editing",
        "url": "http://arxiv.org/abs/2306.10012v1",
        "pub_date": "2023-06-16",
        "summary": "Text-guided image editing is widely needed in daily life, ranging from\npersonal use to professional applications such as Photoshop. However, existing\nmethods are either zero-shot or trained on an automatically synthesized\ndataset, which contains a high volume of noise. Thus, they still require lots\nof manual tuning to produce desirable outcomes in practice. To address this\nissue, we introduce MagicBrush (https://osu-nlp-group.github.io/MagicBrush/),\nthe first large-scale, manually annotated dataset for instruction-guided real\nimage editing that covers diverse scenarios: single-turn, multi-turn,\nmask-provided, and mask-free editing. MagicBrush comprises over 10K manually\nannotated triples (source image, instruction, target image), which supports\ntrainining large-scale text-guided image editing models. We fine-tune\nInstructPix2Pix on MagicBrush and show that the new model can produce much\nbetter images according to human evaluation. We further conduct extensive\nexperiments to evaluate current image editing baselines from multiple\ndimensions including quantitative, qualitative, and human evaluations. The\nresults reveal the challenging nature of our dataset and the gap between\ncurrent baselines and real-world editing needs.",
        "translated": "从个人使用到 Photoshop 等专业应用，文本引导图像编辑在日常生活中被广泛需要。然而，现有的方法要么是零拍摄，要么是在一个自动合成的数据集上训练，这个数据集包含了大量的噪声。因此，它们仍然需要大量的手动调优，以便在实践中产生理想的结果。为了解决这个问题，我们引入了 MagicBrush ( https://osu-nlp-group.github.io/MagicBrush/) ，这是第一个用于指令引导的真实图像编辑的大规模手动注释数据集，涵盖了不同的场景: 单转、多转、掩码提供和无掩码编辑。MagicBrush 包含超过10K 的手动注释三元组(源图像、指令、目标图像) ，支持训练大规模的文本引导图像编辑模型。我们在 MagicBrush 上对 DirectPix2Pix 进行了微调，结果表明新的模型可以根据人的评价产生更好的图像。我们进一步进行广泛的实验，以评估目前的图像编辑基线从多个维度，包括定量，定性和人类的评价。结果揭示了我们的数据集的挑战性，以及当前基线和现实世界编辑需求之间的差距。"
    },
    {
        "title": "Investigating Prompting Techniques for Zero- and Few-Shot Visual\n  Question Answering",
        "url": "http://arxiv.org/abs/2306.09996v1",
        "pub_date": "2023-06-16",
        "summary": "Visual question answering (VQA) is a challenging task that requires the\nability to comprehend and reason with visual information. While recent\nvision-language models have made strides, they continue to struggle with\nzero-shot VQA, particularly in handling complex compositional questions and\nadapting to new domains i.e. knowledge-based reasoning. This paper explores the\nuse of various prompting strategies, focusing on the BLIP2 model, to enhance\nzero-shot VQA performance. We conduct a comprehensive investigation across\nseveral VQA datasets, examining the effectiveness of different question\ntemplates, the role of few-shot exemplars, the impact of chain-of-thought (CoT)\nreasoning, and the benefits of incorporating image captions as additional\nvisual cues. Despite the varied outcomes, our findings demonstrate that\ncarefully designed question templates and the integration of additional visual\ncues, like image captions, can contribute to improved VQA performance,\nespecially when used in conjunction with few-shot examples. However, we also\nidentify a limitation in the use of chain-of-thought rationalization, which\nnegatively affects VQA accuracy. Our study thus provides critical insights into\nthe potential of prompting for improving zero-shot VQA performance.",
        "translated": "视觉问题回答是一项具有挑战性的任务，需要对视觉信息进行理解和推理。虽然最近的视觉语言模型已经取得了长足的进步，但是它们仍然在与零射击 VQA 作斗争，特别是在处理复杂的组合问题和适应新的领域，即基于知识的推理方面。本文探讨了各种激励策略的使用，重点是 BLIP2模型，以提高零拍 VQA 的性能。我们对几个 VQA 数据集进行了全面的调查，检查了不同问题模板的有效性，少拍范例的作用，思维链(CoT)推理的影响，以及将图像标题作为额外的视觉线索的好处。尽管结果各不相同，但我们的研究结果表明，精心设计的问题模板和整合额外的视觉线索，如图像标题，可以有助于改善 VQA 的性能，特别是当与少数镜头的例子一起使用时。然而，我们也发现了思维链合理化使用的局限性，这对 VQA 的准确性产生了负面影响。因此，我们的研究提供了关键的见解，促进提高零拍 VQA 性能的潜力。"
    },
    {
        "title": "ClinicalGPT: Large Language Models Finetuned with Diverse Medical Data\n  and Comprehensive Evaluation",
        "url": "http://arxiv.org/abs/2306.09968v1",
        "pub_date": "2023-06-16",
        "summary": "Large language models have exhibited exceptional performance on various\nNatural Language Processing (NLP) tasks, leveraging techniques such as the\npre-training, and instruction fine-tuning. Despite these advances, their\neffectiveness in medical applications is limited, due to challenges such as\nfactual inaccuracies, reasoning abilities, and lack grounding in real-world\nexperience. In this study, we present ClinicalGPT, a language model explicitly\ndesigned and optimized for clinical scenarios. By incorporating extensive and\ndiverse real-world data, such as medical records, domain-specific knowledge,\nand multi-round dialogue consultations in the training process, ClinicalGPT is\nbetter prepared to handle multiple clinical task. Furthermore, we introduce a\ncomprehensive evaluation framework that includes medical knowledge\nquestion-answering, medical exams, patient consultations, and diagnostic\nanalysis of medical records. Our results demonstrate that ClinicalGPT\nsignificantly outperforms other models in these tasks, highlighting the\neffectiveness of our approach in adapting large language models to the critical\ndomain of healthcare.",
        "translated": "大型语言模型在各种自然语言处理(NLP)任务中表现出了卓越的性能，利用了预训练和指令微调等技术。尽管取得了这些进展，但由于事实不准确、推理能力差以及缺乏现实世界经验的基础等挑战，它们在医学应用中的有效性是有限的。在这项研究中，我们提出了 ClinicalGPT，一个明确设计和优化的语言模型临床情景。通过在培训过程中结合广泛和多样的现实世界数据，如医疗记录，特定领域的知识和多轮对话咨询，ClinicalGPT 更好地准备处理多个临床任务。此外，我们介绍了一个全面的评估框架，包括医学知识问答，医疗检查，病人会诊，和病历诊断分析。我们的研究结果表明 ClinicalGPT 在这些任务中显著优于其他模型，突出了我们的方法在调整大型语言模型以适应医疗保健的关键领域方面的有效性。"
    },
    {
        "title": "Trained Transformers Learn Linear Models In-Context",
        "url": "http://arxiv.org/abs/2306.09927v1",
        "pub_date": "2023-06-16",
        "summary": "Attention-based neural networks such as transformers have demonstrated a\nremarkable ability to exhibit in-context learning (ICL): Given a short prompt\nsequence of tokens from an unseen task, they can formulate relevant per-token\nand next-token predictions without any parameter updates. By embedding a\nsequence of labeled training data and unlabeled test data as a prompt, this\nallows for transformers to behave like supervised learning algorithms. Indeed,\nrecent work has shown that when training transformer architectures over random\ninstances of linear regression problems, these models' predictions mimic those\nof ordinary least squares.\n  Towards understanding the mechanisms underlying this phenomenon, we\ninvestigate the dynamics of ICL in transformers with a single linear\nself-attention layer trained by gradient flow on linear regression tasks. We\nshow that despite non-convexity, gradient flow with a suitable random\ninitialization finds a global minimum of the objective function. At this global\nminimum, when given a test prompt of labeled examples from a new prediction\ntask, the transformer achieves prediction error competitive with the best\nlinear predictor over the test prompt distribution. We additionally\ncharacterize the robustness of the trained transformer to a variety of\ndistribution shifts and show that although a number of shifts are tolerated,\nshifts in the covariate distribution of the prompts are not. Motivated by this,\nwe consider a generalized ICL setting where the covariate distributions can\nvary across prompts. We show that although gradient flow succeeds at finding a\nglobal minimum in this setting, the trained transformer is still brittle under\nmild covariate shifts.",
        "translated": "基于注意力的神经网络，如变压器，已经证明了显着的能力，表现在上下文学习(ICL) : 给定一个短暂的令牌序列从一个看不见的任务，他们可以制定相关的每个令牌和下一个令牌预测没有任何参数更新。通过嵌入一系列已标记的训练数据和未标记的测试数据作为提示，这允许变压器像监督式学习算法一样运行。事实上，最近的工作已经表明，当训练变压器架构在随机情况下的线性回归问题，这些模型的预测模拟那些一般最小平方法。为了理解这种现象的机制，我们研究了变压器中的 ICL 的动力学，这种变压器具有一个单一的线性自我注意层，通过梯度流对线性回归任务进行训练。结果表明，尽管存在非凸性，但梯度流在适当的随机初始化条件下仍能找到目标函数的全局最小值。在这个全局最小值下，当从一个新的预测任务中给出一个标记样本的测试提示时，变压器在测试提示分布上达到与最佳线性预测器竞争的预测误差。另外，我们描述了训练后的变压器对各种分布移位的鲁棒性，并且表明，虽然许多移位是可以容忍的，但是提示符的协变量分布的移位是不可以容忍的。基于此，我们考虑一个广义的 ICL 设置，其中协变量分布可以随提示而变化。我们表明，虽然梯度流成功地找到一个全局最小在这种设置，训练变压器仍然脆弱的轻度协变量移动。"
    },
    {
        "title": "Learning to Summarize and Answer Questions about a Virtual Robot's Past\n  Actions",
        "url": "http://arxiv.org/abs/2306.09922v1",
        "pub_date": "2023-06-16",
        "summary": "When robots perform long action sequences, users will want to easily and\nreliably find out what they have done. We therefore demonstrate the task of\nlearning to summarize and answer questions about a robot agent's past actions\nusing natural language alone. A single system with a large language model at\nits core is trained to both summarize and answer questions about action\nsequences given ego-centric video frames of a virtual robot and a question\nprompt. To enable training of question answering, we develop a method to\nautomatically generate English-language questions and answers about objects,\nactions, and the temporal order in which actions occurred during episodes of\nrobot action in the virtual environment. Training one model to both summarize\nand answer questions enables zero-shot transfer of representations of objects\nlearned through question answering to improved action summarization. %\ninvolving objects not seen in training to summarize.",
        "translated": "当机器人执行长动作序列时，用户将希望轻松可靠地找出他们做了什么。因此，我们演示的任务，学习总结和回答有关机器人代理人的过去的行动使用自然语言单独的问题。通过训练一个以大语言模型为核心的单一系统，在给定虚拟机器人以自我为中心的视频框架和问题提示的情况下，总结和回答关于动作序列的问题。为了实现问题回答的训练，我们开发了一种自动生成英语问答的方法，这些问答包括对象、动作以及虚拟环境中机器人动作过程中动作发生的时间顺序。训练一个同时总结和回答问题的模型可以使通过问题回答学到的对象的表示零拍转移到改进的动作总结。涉及培训中未见到的对象的百分比。"
    },
    {
        "title": "No Strong Feelings One Way or Another: Re-operationalizing Neutrality in\n  Natural Language Inference",
        "url": "http://arxiv.org/abs/2306.09918v1",
        "pub_date": "2023-06-16",
        "summary": "Natural Language Inference (NLI) has been a cornerstone task in evaluating\nlanguage models' inferential reasoning capabilities. However, the standard\nthree-way classification scheme used in NLI has well-known shortcomings in\nevaluating models' ability to capture the nuances of natural human reasoning.\nIn this paper, we argue that the operationalization of the neutral label in\ncurrent NLI datasets has low validity, is interpreted inconsistently, and that\nat least one important sense of neutrality is often ignored. We uncover the\ndetrimental impact of these shortcomings, which in some cases leads to\nannotation datasets that actually decrease performance on downstream tasks. We\ncompare approaches of handling annotator disagreement and identify flaws in a\nrecent NLI dataset that designs an annotator study based on a problematic\noperationalization. Our findings highlight the need for a more refined\nevaluation framework for NLI, and we hope to spark further discussion and\naction in the NLP community.",
        "translated": "自然语言推理(NLI)是评价语言模型推理能力的基础性工作。然而，在自然语言学习中使用的标准三向分类方案在评估模型捕捉人类自然推理细微差别的能力方面有着众所周知的缺陷。在本文中，我们认为在现有的 NLI 数据集中，中性标签的操作主义效度低，解释不一致，并且至少有一个重要的中性意义经常被忽略。我们发现了这些缺陷的有害影响，在某些情况下，这导致注释数据集实际上降低了下游任务的性能。我们比较了处理注释者不一致的方法，并在最近的一个基于有问题的操作主义设计注释者研究的 NLI 数据集中发现了缺陷。我们的研究结果强调了对 NLI 进一步完善评估框架的必要性，我们希望在 NLP 社区中引发进一步的讨论和行动。"
    },
    {
        "title": "Demystifying GPT Self-Repair for Code Generation",
        "url": "http://arxiv.org/abs/2306.09896v1",
        "pub_date": "2023-06-16",
        "summary": "Large Language Models (LLMs) have shown remarkable aptitude in code\ngeneration but still struggle on challenging programming tasks. Self-repair --\nin which the model debugs and fixes mistakes in its own code -- has recently\nbecome a popular way to boost performance in these settings. However, only very\nlimited studies on how and when self-repair works effectively exist in the\nliterature, and one might wonder to what extent a model is really capable of\nproviding accurate feedback on why the code is wrong when that code was\ngenerated by the same model. In this paper, we analyze GPT-3.5 and GPT-4's\nability to perform self-repair on APPS, a challenging dataset consisting of\ndiverse coding challenges. To do so, we first establish a new evaluation\nstrategy dubbed pass@t that measures the pass rate of the tasks against the\ntotal number of tokens sampled from the model, enabling a fair comparison to\npurely sampling-based approaches. With this evaluation strategy, we find that\nthe effectiveness of self-repair is only seen in GPT-4. We also observe that\nself-repair is bottlenecked by the feedback stage; using GPT-4 to give feedback\non the programs generated by GPT-3.5 and using expert human programmers to give\nfeedback on the programs generated by GPT-4, we unlock significant performance\ngains.",
        "translated": "大型语言模型(LLM)在代码生成方面显示出了非凡的才能，但是在具有挑战性的编程任务方面仍然举步维艰。自我修复(模型调试并修复自己代码中的错误)最近已经成为提高这些设置中性能的一种流行方式。然而，文献中关于自我修复如何以及何时起作用的研究非常有限，人们可能想知道，当代码由同一个模型生成时，一个模型究竟能在多大程度上提供准确的反馈，说明为什么代码是错误的。在本文中，我们分析了 GPT-3.5和 GPT-4对 APPS 进行自我修复的能力，APPS 是一个具有挑战性的数据集，由多种编码挑战组成。为此，我们首先建立一个称为 pass@t 的新评估策略，该策略根据从模型中抽样的令牌总数来度量任务的通过率，从而能够与纯粹基于抽样的方法进行公平的比较。通过这种评估策略，我们发现自我修复的有效性仅见于 GPT-4。我们还观察到自我修复受到反馈阶段的瓶颈; 使用 GPT-4对由 GPT-3.5生成的程序提供反馈，并使用专业的人类程序员对由 GPT-4生成的程序提供反馈，我们获得了显着的性能收益。"
    },
    {
        "title": "Revealing the impact of social circumstances on the selection of cancer\n  therapy through natural language processing of social work notes",
        "url": "http://arxiv.org/abs/2306.09877v1",
        "pub_date": "2023-06-16",
        "summary": "We aimed to investigate the impact of social circumstances on cancer therapy\nselection using natural language processing to derive insights from social\nworker documentation. We developed and employed a Bidirectional Encoder\nRepresentations from Transformers (BERT) based approach, using a hierarchical\nmulti-step BERT model (BERT-MS) to predict the prescription of targeted cancer\ntherapy to patients based solely on documentation by clinical social workers.\nOur corpus included free-text clinical social work notes, combined with\nmedication prescription information, for all patients treated for breast\ncancer. We conducted a feature importance analysis to pinpoint the specific\nsocial circumstances that impact cancer therapy selection. Using only social\nwork notes, we consistently predicted the administration of targeted therapies,\nsuggesting systematic differences in treatment selection exist due to\nnon-clinical factors. The UCSF-BERT model, pretrained on clinical text at UCSF,\noutperformed other publicly available language models with an AUROC of 0.675\nand a Macro F1 score of 0.599. The UCSF BERT-MS model, capable of leveraging\nmultiple pieces of notes, surpassed the UCSF-BERT model in both AUROC and\nMacro-F1. Our feature importance analysis identified several clinically\nintuitive social determinants of health (SDOH) that potentially contribute to\ndisparities in treatment. Our findings indicate that significant disparities\nexist among breast cancer patients receiving different types of therapies based\non social determinants of health. Social work reports play a crucial role in\nunderstanding these disparities in clinical decision-making.",
        "translated": "我们的目的是调查社会环境对癌症治疗选择的影响，使用自然语言处理，从社会工作者的文件中获得见解。我们开发并使用了基于变压器的双向编码器表示(BERT)方法，使用分层多步 BERT 模型(BERT-MS)来预测仅基于临床社会工作者的文档的针对患者的癌症治疗处方。我们的语料库包括自由文本临床社会工作笔记，结合药物处方信息，为所有患者治疗乳腺癌。我们进行了特征重要性分析，以确定影响癌症治疗选择的特定社会环境。仅使用社会工作笔记，我们始终预测靶向治疗的管理，表明治疗选择存在系统性差异，由于非临床因素。UCSF-BERT 模型在 UCSF 的临床文本上进行了预训练，其表现优于其他公开可用的语言模型，AUROC 为0.675，Macro F1评分为0.599。UCSF BERT-MS 模型能够利用多种音符，在 AUROC 和 Macro-F1中都超过了 UCSF BERT 模型。我们的特征重要性分析确定了几个临床直观的健康社会决定因素(SDOH) ，可能有助于差异的治疗。我们的研究结果表明，根据健康的社会决定因素，接受不同类型治疗的乳腺癌患者之间存在显著差异。社会工作报告在了解临床决策中的这些差异方面发挥着至关重要的作用。"
    },
    {
        "title": "Energy-Based Cross Attention for Bayesian Context Update in\n  Text-to-Image Diffusion Models",
        "url": "http://arxiv.org/abs/2306.09869v1",
        "pub_date": "2023-06-16",
        "summary": "Despite the remarkable performance of text-to-image diffusion models in image\ngeneration tasks, recent studies have raised the issue that generated images\nsometimes cannot capture the intended semantic contents of the text prompts,\nwhich phenomenon is often called semantic misalignment. To address this, here\nwe present a novel energy-based model (EBM) framework. Specifically, we first\nformulate EBMs of latent image representations and text embeddings in each\ncross-attention layer of the denoising autoencoder. Then, we obtain the\ngradient of the log posterior of context vectors, which can be updated and\ntransferred to the subsequent cross-attention layer, thereby implicitly\nminimizing a nested hierarchy of energy functions. Our latent EBMs further\nallow zero-shot compositional generation as a linear combination of\ncross-attention outputs from different contexts. Using extensive experiments,\nwe demonstrate that the proposed method is highly effective in handling various\nimage generation tasks, including multi-concept generation, text-guided image\ninpainting, and real and synthetic image editing.",
        "translated": "尽管文本-图像扩散模型在图像生成任务中表现突出，但近年来的研究提出了生成的图像有时不能捕捉到文本提示语的预期语义内容的问题，这种现象通常被称为语义错位。为了解决这个问题，我们提出了一个新的基于能量的模型(EBM)框架。具体地说，我们首先在去噪自动编码器的每个交叉注意层中建立潜在图像表示和文本嵌入的循证医学模型。然后，我们得到上下文向量的对数后验梯度，它可以被更新和转移到后续的交叉注意层，从而隐式地最小化嵌套的能量函数层次结构。我们的潜在的循证医学进一步允许零拍摄成分生成作为交叉注意输出的线性组合从不同的情境。通过大量的实验证明，该方法能够有效地处理多种图像生成任务，包括多概念生成、文本引导的图像修补以及真实和合成的图像编辑。"
    },
    {
        "title": "Visual Analysis of Large Multi-Field AMR Data on GPUs Using Interactive\n  Volume Lines",
        "url": "http://arxiv.org/abs/2306.11612v1",
        "pub_date": "2023-06-20",
        "summary": "To visually compare ensembles of volumes, dynamic volume lines (DVLs)\nrepresent each ensemble member as a 1D polyline. To compute these, the volume\ncells are sorted on a space-filling curve and scaled by the ensemble's local\nvariation. The resulting 1D plot can augment or serve as an alternative to a 3D\nvolume visualization free of visual clutter and occlusion. Interactively\ncomputing DVLs is challenging when the data is large, and the volume grid is\nnot structured/regular, as is often the case with computational fluid dynamics\nsimulations. We extend DVLs to support large-scale, multi-field adaptive mesh\nrefinement (AMR) data that can be explored interactively. Our GPU-based system\nupdates the DVL representation whenever the data or the alpha transfer function\nchanges. We demonstrate and evaluate our interactive prototype using large AMR\nvolumes from astrophysics simulations.",
        "translated": "为了可视化地比较体积的集合，动态体积线(DVL)将每个集合成员表示为一维折线。为了计算这些，体积单元按照皮亚诺曲线进行排序，并按照集合的局部变化进行缩放。由此产生的一维图可以增强或作为一个替代的三维体可视化免费的视觉杂乱和遮挡。当数据量很大时，交互式计算 DVL 是一个挑战，而且体积网格不是结构化/规则化的，就像计算流体力学模拟中经常出现的情况一样。我们扩展 DVL，以支持大规模，多领域的自适应网格细化(AMR)数据，可以互动探索。我们基于 GPU 的系统在数据或 alpha 传输函数发生变化时更新 DVL 表示。我们演示和评估我们的交互式原型使用天体物理学模拟的大量 AMR 卷。"
    },
    {
        "title": "Mining Interest Trends and Adaptively Assigning SampleWeight for\n  Session-based Recommendation",
        "url": "http://arxiv.org/abs/2306.11610v1",
        "pub_date": "2023-06-20",
        "summary": "Session-based Recommendation (SR) aims to predict users' next click based on\ntheir behavior within a short period, which is crucial for online platforms.\nHowever, most existing SR methods somewhat ignore the fact that user preference\nis not necessarily strongly related to the order of interactions. Moreover,\nthey ignore the differences in importance between different samples, which\nlimits the model-fitting performance. To tackle these issues, we put forward\nthe method, Mining Interest Trends and Adaptively Assigning Sample Weight,\nabbreviated as MTAW. Specifically, we model users' instant interest based on\ntheir present behavior and all their previous behaviors. Meanwhile, we\ndiscriminatively integrate instant interests to capture the changing trend of\nuser interest to make more personalized recommendations. Furthermore, we devise\na novel loss function that dynamically weights the samples according to their\nprediction difficulty in the current epoch. Extensive experimental results on\ntwo benchmark datasets demonstrate the effectiveness and superiority of our\nmethod.",
        "translated": "基于会话的推荐(SR)旨在根据用户的行为在短时间内预测用户的下一次点击，这对在线平台至关重要。然而，大多数现有的 SR 方法都忽略了一个事实，即用户偏好并不一定与交互顺序密切相关。此外，他们忽略了不同样本之间的重要性差异，这限制了模型拟合的性能。为了解决这些问题，我们提出了挖掘兴趣趋势和自适应分配样本权重的方法，简称 MTAW。具体来说，我们根据用户当前的行为和他们以前的所有行为来建立用户的即时兴趣模型。同时，我们有选择性地整合即时兴趣，捕捉用户兴趣的变化趋势，提出更加个性化的推荐。此外，我们设计了一个新的损失函数，动态权重的样本根据他们的预测困难在当前的纪元。在两个基准数据集上的大量实验结果表明了该方法的有效性和优越性。"
    },
    {
        "title": "Polytope: An Algorithm for Efficient Feature Extraction on Hypercubes",
        "url": "http://arxiv.org/abs/2306.11553v1",
        "pub_date": "2023-06-20",
        "summary": "Data extraction algorithms on data hypercubes, or datacubes, are\ntraditionally only capable of cutting boxes of data along the datacube axes.\nFor many use cases however, this is not a sufficient approach and returns more\ndata than users might actually need. This not only forces users to apply\npost-processing after extraction, but more importantly this consumes more I/O\nresources than is necessary. When considering very large datacubes from which\nusers only want to extract small non-rectangular subsets, the box approach does\nnot scale well. Indeed, with this traditional approach, I/O systems quickly\nreach capacity, trying to read and return unwanted data to users. In this\npaper, we propose a novel technique, based on computational geometry concepts,\nwhich instead carefully pre-selects the precise bytes of data which the user\nneeds in order to then only read those from the datacube. As we discuss later\non, this novel extraction method will considerably help scale access to large\npetabyte size data hypercubes in a variety of scientific fields.",
        "translated": "数据超立方体(或数据立方体)上的数据提取算法传统上只能沿着数据立方体轴切割数据框。然而，对于许多用例来说，这不是一种充分的方法，并且返回的数据超过了用户实际需要的数据。这不仅迫使用户在提取之后进行后处理，而且更重要的是，这会消耗比必需的更多的 I/O 资源。当考虑用户只想从中提取小的非矩形子集的非常大的数据立方体时，盒方法不能很好地伸缩。实际上，使用这种传统方法，I/O 系统可以快速达到容量，尝试读取并向用户返回不需要的数据。在本文中，我们提出了一种基于计算几何概念的新技术，它仔细地预先选择用户需要的精确字节数据，然后只从数据立方中读取这些数据。正如我们稍后讨论的，这种新颖的提取方法将大大有助于在各种科学领域对大型 PB 大小的数据超立方体进行扩展访问。"
    },
    {
        "title": "Generative Retrieval as Dense Retrieval",
        "url": "http://arxiv.org/abs/2306.11397v1",
        "pub_date": "2023-06-20",
        "summary": "Generative retrieval is a promising new neural retrieval paradigm that aims\nto optimize the retrieval pipeline by performing both indexing and retrieval\nwith a single transformer model. However, this new paradigm faces challenges\nwith updating the index and scaling to large collections. In this paper, we\nanalyze two prominent variants of generative retrieval and show that they can\nbe conceptually viewed as bi-encoders for dense retrieval. Specifically, we\nanalytically demonstrate that the generative retrieval process can be\ndecomposed into dot products between query and document vectors, similar to\ndense retrieval. This analysis leads us to propose a new variant of generative\nretrieval, called Tied-Atomic, which addresses the updating and scaling issues\nby incorporating techniques from dense retrieval. In experiments on two\ndatasets, NQ320k and the full MSMARCO, we confirm that this approach does not\nreduce retrieval effectiveness while enabling the model to scale to large\ncollections.",
        "translated": "生成检索是一种新兴的神经元检索方法，其目的是通过使用单个变换器模型对检索流水线进行索引和检索的优化。但是，这种新范例在更新索引和扩展到大型集合方面面临挑战。在本文中，我们分析了两个突出的变体生成检索，并表明它们可以被概念上看作是密集检索的双编码器。具体来说，我们分析表明，生成检索过程可以分解成点乘之间的查询和文档向量，类似于密集检索。这种分析促使我们提出了一种新的生成检索方法，称为 Tied-Atomic，它通过结合密集检索技术来解决更新和缩放问题。在对两个数据集(NQ320k 和 MSMARCO)的实验中，我们证实了这种方法不会降低检索效率，同时使模型能够扩展到大型数据集。"
    },
    {
        "title": "CAPRI: Context-Aware Interpretable Point-of-Interest Recommendation\n  Framework",
        "url": "http://arxiv.org/abs/2306.11395v1",
        "pub_date": "2023-06-20",
        "summary": "Point-of-Interest (POI ) recommendation systems have gained popularity for\ntheir unique ability to suggest geographical destinations with the\nincorporation of contextual information such as time, location, and user-item\ninteraction. Existing recommendation frameworks lack the contextual fusion\nrequired for POI systems. This paper presents CAPRI, a novel POI recommendation\nframework that effectively integrates context-aware models, such as GeoSoCa,\nLORE, and USG, and introduces a novel strategy for the efficient merging of\ncontextual information. CAPRI integrates an evaluation module that expands the\nevaluation scope beyond accuracy to include novelty, personalization,\ndiversity, and fairness. With an aim to establish a new industry standard for\nreproducible results in the realm of POI recommendation systems, we have made\nCAPRI openly accessible on GitHub, facilitating easy access and contribution to\nthe continued development and refinement of this innovative framework.",
        "translated": "兴趣点(POI)推荐系统由于其独特的推荐地理目的地的能力而受到欢迎，这种推荐系统结合了上下文信息，如时间、地点和用户项目交互。现有的建议框架缺乏 POI 系统所需的上下文融合。本文提出了一个新的 POI 推荐框架 CAPRI，它有效地集成了上下文感知模型，如 GeoSoCa、 LORE 和 USG，并介绍了一种有效合并上下文信息的新策略。CAPRI 整合了一个评估模块，扩大了评估范围，超越了准确性，包括新颖性，个性化，多样性和公平性。为了在 POI 推荐系统领域建立可重复性成果的新行业标准，我们使得 CAPRI 能够在 GitHub 上公开访问，便于访问并促进这一创新框架的持续发展和完善。"
    },
    {
        "title": "Lingua Manga: A Generic Large Language Model Centric System for Data\n  Curation",
        "url": "http://arxiv.org/abs/2306.11702v1",
        "pub_date": "2023-06-20",
        "summary": "Data curation is a wide-ranging area which contains many critical but\ntime-consuming data processing tasks. However, the diversity of such tasks\nmakes it challenging to develop a general-purpose data curation system. To\naddress this issue, we present Lingua Manga, a user-friendly and versatile\nsystem that utilizes pre-trained large language models. Lingua Manga offers\nautomatic optimization for achieving high performance and label efficiency\nwhile facilitating flexible and rapid development. Through three example\napplications with distinct objectives and users of varying levels of technical\nproficiency, we demonstrate that Lingua Manga can effectively assist both\nskilled programmers and low-code or even no-code users in addressing data\ncuration challenges.",
        "translated": "数据管理是一个涉及面很广的领域，其中包含许多关键但耗时的数据处理任务。然而，这些任务的多样性使得开发一个通用的数据管理系统具有挑战性。为了解决这个问题，我们提出了通用语言漫画，一个用户友好和通用的系统，利用预先训练的大型语言模型。通用漫画提供了自动优化，以实现高性能和标签效率，同时促进灵活和快速的开发。通过三个具有不同目标和不同技术熟练程度的用户的示例应用程序，我们证明了 Langua Manga 可以有效地帮助熟练的程序员和低代码甚至无代码用户解决数据管理方面的挑战。"
    },
    {
        "title": "DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT\n  Models",
        "url": "http://arxiv.org/abs/2306.11698v1",
        "pub_date": "2023-06-20",
        "summary": "Generative Pre-trained Transformer (GPT) models have exhibited exciting\nprogress in capabilities, capturing the interest of practitioners and the\npublic alike. Yet, while the literature on the trustworthiness of GPT models\nremains limited, practitioners have proposed employing capable GPT models for\nsensitive applications to healthcare and finance - where mistakes can be\ncostly. To this end, this work proposes a comprehensive trustworthiness\nevaluation for large language models with a focus on GPT-4 and GPT-3.5,\nconsidering diverse perspectives - including toxicity, stereotype bias,\nadversarial robustness, out-of-distribution robustness, robustness on\nadversarial demonstrations, privacy, machine ethics, and fairness. Based on our\nevaluations, we discover previously unpublished vulnerabilities to\ntrustworthiness threats. For instance, we find that GPT models can be easily\nmisled to generate toxic and biased outputs and leak private information in\nboth training data and conversation history. We also find that although GPT-4\nis usually more trustworthy than GPT-3.5 on standard benchmarks, GPT-4 is more\nvulnerable given jailbreaking system or user prompts, potentially due to the\nreason that GPT-4 follows the (misleading) instructions more precisely. Our\nwork illustrates a comprehensive trustworthiness evaluation of GPT models and\nsheds light on the trustworthiness gaps. Our benchmark is publicly available at\nhttps://decodingtrust.github.io/.",
        "translated": "生成式预训练变压器(GPT)模型在性能方面展示了令人兴奋的进步，吸引了从业者和公众的兴趣。然而，尽管关于 GPT 模型可信度的文献仍然有限，但从业人员已经提议，在医疗和金融领域的敏感应用中使用有能力的 GPT 模型——在这些领域，错误可能代价高昂。为此，这项工作提出了一个全面的大型语言模型的可信性评估，重点是 GPT-4和 GPT-3.5，考虑到不同的观点-包括毒性，刻板印象偏差，对抗性鲁棒性，分布外鲁棒性，对抗性示范的鲁棒性，隐私，机器伦理和公平。根据我们的评估，我们发现了以前未公布的可信度威胁的漏洞。例如，我们发现 GPT 模型很容易被误导，从而产生有毒和有偏见的输出，并在训练数据和对话历史中泄露私人信息。我们还发现，尽管 GPT-4在标准基准上通常比 GPT-3.5更值得信赖，但是在破解系统或用户提示下，GPT-4更容易受到攻击，这可能是由于 GPT-4更精确地遵循(误导性的)指令的原因。我们的工作阐述了 GPT 模型的全面可信性评估，并揭示了可信性差距。我们的基准 https://decodingtrust.github.io/已公开发售。"
    },
    {
        "title": "A Simple and Effective Pruning Approach for Large Language Models",
        "url": "http://arxiv.org/abs/2306.11695v1",
        "pub_date": "2023-06-20",
        "summary": "As their size increases, Large Languages Models (LLMs) are natural candidates\nfor network pruning methods: approaches that drop a subset of network weights\nwhile striving to preserve performance. Existing methods, however, require\neither retraining, which is rarely affordable for billion-scale LLMs, or\nsolving a weight reconstruction problem reliant on second-order information,\nwhich may also be computationally expensive. In this paper, we introduce a\nnovel, straightforward yet effective pruning method, termed Wanda (Pruning by\nWeights and activations), designed to induce sparsity in pretrained LLMs.\nMotivated by the recent observation of emergent large magnitude features in\nLLMs, our approach prune weights with the smallest magnitudes multiplied by the\ncorresponding input activations, on a per-output basis. Notably, Wanda requires\nno retraining or weight update, and the pruned LLM can be used as is. We\nconduct a thorough evaluation of our method on LLaMA across various language\nbenchmarks. Wanda significantly outperforms the established baseline of\nmagnitude pruning and competes favorably against recent methods involving\nintensive weight update. Code is available at\nhttps://github.com/locuslab/wanda.",
        "translated": "随着规模的增加，大型语言模型(LLM)自然成为网络裁剪方法的候选者: 这种方法在努力保持性能的同时减少了网络权重的子集。然而，现有的方法要么需要再培训(这对于十亿级的 LLM 来说是很难负担得起的) ，要么需要解决依赖于二阶信息的重构问题(这也可能是计算昂贵的)。在本文中，我们介绍了一种新颖的，直接而有效的修剪方法，称为万达(修剪的权重和激活) ，旨在诱导稀疏的预训练 LLM。受最近对 LLM 中出现的大幅度特征的观察的启发，我们的方法以每个输出为基础，用最小幅度的权重乘以相应的输入激活。值得注意的是，万达不需要再培训或体重更新，修剪后的 LLM 可以按原样使用。我们在不同的语言基准上对我们的 LLaMA 方法进行了全面的评估。万达明显优于既定的基准量修剪和竞争优势最近的方法涉及密集的体重更新。密码可于 https://github.com/locuslab/wanda 索取。"
    },
    {
        "title": "Harnessing the Power of Adversarial Prompting and Large Language Models\n  for Robust Hypothesis Generation in Astronomy",
        "url": "http://arxiv.org/abs/2306.11648v1",
        "pub_date": "2023-06-20",
        "summary": "This study investigates the application of Large Language Models (LLMs),\nspecifically GPT-4, within Astronomy. We employ in-context prompting, supplying\nthe model with up to 1000 papers from the NASA Astrophysics Data System, to\nexplore the extent to which performance can be improved by immersing the model\nin domain-specific literature. Our findings point towards a substantial boost\nin hypothesis generation when using in-context prompting, a benefit that is\nfurther accentuated by adversarial prompting. We illustrate how adversarial\nprompting empowers GPT-4 to extract essential details from a vast knowledge\nbase to produce meaningful hypotheses, signaling an innovative step towards\nemploying LLMs for scientific research in Astronomy.",
        "translated": "这项研究调查了大语言模型(LLM) ，特别是 GPT-4在天文学中的应用。我们采用了上下文提示的方式，向模型提供了多达1000篇来自美国宇航局天体物理数据系统的论文，以探索通过将模型沉浸在特定领域的文献中，可以在多大程度上提高性能。我们的研究结果表明，在使用上下文激励时，假设生成能力大大提高，而对抗性激励则进一步强调了这一点。我们举例说明对抗性的提示如何使 GPT-4能够从庞大的知识库中提取基本细节，从而产生有意义的假设，标志着在天文学科学研究中使用 LLM 的创新步骤。"
    },
    {
        "title": "Recent Advances in Direct Speech-to-text Translation",
        "url": "http://arxiv.org/abs/2306.11646v1",
        "pub_date": "2023-06-20",
        "summary": "Recently, speech-to-text translation has attracted more and more attention\nand many studies have emerged rapidly. In this paper, we present a\ncomprehensive survey on direct speech translation aiming to summarize the\ncurrent state-of-the-art techniques. First, we categorize the existing research\nwork into three directions based on the main challenges -- modeling burden,\ndata scarcity, and application issues. To tackle the problem of modeling\nburden, two main structures have been proposed, encoder-decoder framework\n(Transformer and the variants) and multitask frameworks. For the challenge of\ndata scarcity, recent work resorts to many sophisticated techniques, such as\ndata augmentation, pre-training, knowledge distillation, and multilingual\nmodeling. We analyze and summarize the application issues, which include\nreal-time, segmentation, named entity, gender bias, and code-switching.\nFinally, we discuss some promising directions for future work.",
        "translated": "近年来，语音翻译越来越受到人们的关注，许多研究也迅速兴起。本文对直接言语翻译进行了全面的综述，旨在总结目前的最新技术。首先，基于主要挑战——建模负担、数据稀缺性和应用问题，我们将现有的研究工作分为三个方向。为了解决建模负担问题，提出了两种主要的结构: 编解码框架和多任务框架。面对数据稀缺的挑战，最近的工作采用了许多复杂的技术，如数据增强、预训练、知识提取和多语言建模。我们分析和总结了这些应用问题，包括实时性、分割、命名实体、性别偏见和语码转换。最后，讨论了今后工作的一些有希望的方向。"
    },
    {
        "title": "Textbooks Are All You Need",
        "url": "http://arxiv.org/abs/2306.11644v1",
        "pub_date": "2023-06-20",
        "summary": "We introduce phi-1, a new large language model for code, with significantly\nsmaller size than competing models: phi-1 is a Transformer-based model with\n1.3B parameters, trained for 4 days on 8 A100s, using a selection of ``textbook\nquality\" data from the web (6B tokens) and synthetically generated textbooks\nand exercises with GPT-3.5 (1B tokens). Despite this small scale, phi-1 attains\npass@1 accuracy 50.6% on HumanEval and 55.5% on MBPP. It also displays\nsurprising emergent properties compared to phi-1-base, our model before our\nfinetuning stage on a dataset of coding exercises, and phi-1-small, a smaller\nmodel with 350M parameters trained with the same pipeline as phi-1 that still\nachieves 45% on HumanEval.",
        "translated": "我们介绍了 phi-1，一种新的大型代码语言模型，其大小明显小于竞争模型: phi-1是一种基于 Transformer 的模型，具有1.3 B 参数，在8个 A100s 上训练了4天，使用来自 Web 的选择的“教科书质量”数据(6B 令牌) ，并用 GPT-3.5(1B 令牌)综合生成教科书和练习。尽管规模很小，phi-1在 HumanEval 和 MBPP 上的准确率分别为50.6% 和55.5% 。与 phi-1-base (我们在编码练习数据集的微调阶段之前的模型)和 phi-1-small (一个较小的模型，具有350M 参数，与 phi-1使用相同的管道训练，在 HumanEval 上仍然达到45%)相比，它还显示出令人惊讶的紧急属性。"
    },
    {
        "title": "Improving Image Captioning Descriptiveness by Ranking and LLM-based\n  Fusion",
        "url": "http://arxiv.org/abs/2306.11593v1",
        "pub_date": "2023-06-20",
        "summary": "State-of-The-Art (SoTA) image captioning models often rely on the Microsoft\nCOCO (MS-COCO) dataset for training. This dataset contains annotations provided\nby human annotators, who typically produce captions averaging around ten\ntokens. However, this constraint presents a challenge in effectively capturing\ncomplex scenes and conveying detailed information. Furthermore, captioning\nmodels tend to exhibit bias towards the ``average'' caption, which captures\nonly the more general aspects. What would happen if we were able to\nautomatically generate longer captions, thereby making them more detailed?\nWould these captions, evaluated by humans, be more or less representative of\nthe image content compared to the original MS-COCO captions? In this paper, we\npresent a novel approach to address previous challenges by showcasing how\ncaptions generated from different SoTA models can be effectively fused,\nresulting in richer captions. Our proposed method leverages existing models\nfrom the literature, eliminating the need for additional training. Instead, it\nutilizes an image-text based metric to rank the captions generated by SoTA\nmodels for a given image. Subsequently, the top two captions are fused using a\nLarge Language Model (LLM). Experimental results demonstrate the effectiveness\nof our approach, as the captions generated by our model exhibit higher\nconsistency with human judgment when evaluated on the MS-COCO test set. By\ncombining the strengths of various SoTA models, our method enhances the quality\nand appeal of image captions, bridging the gap between automated systems and\nthe rich, informative nature of human-generated descriptions. This advance\nopens up new possibilities for generating captions that are more suitable for\nthe training of both vision-language and captioning models.",
        "translated": "最先进的(SoTA)图像字幕模型通常依赖于微软 COCO (MS-COCO)数据集进行训练。此数据集包含由人工注释器提供的注释，人工注释器通常生成平均约10个标记的标题。然而，这种约束在有效捕获复杂场景和传递详细信息方面提出了挑战。此外，字幕模型往往表现出偏向于“平均”字幕的倾向，它只捕获更一般的方面。如果我们能够自动生成更长的字幕，从而使它们更加详细，会发生什么？与原始的 MS-COCO 标题相比，这些由人类评估的标题是否更能代表图像内容？在本文中，我们通过展示如何有效地融合不同 SoTA 模型生成的字幕，从而产生更丰富的字幕，提出了一种新颖的方法来应对以前的挑战。我们提出的方法利用了文献中的现有模型，消除了额外培训的需要。相反，它使用一个基于图像文本的度量标准来对 SoTA 模型为给定图像生成的标题进行排序。随后，使用大型语言模型(LLM)将前两个标题融合在一起。实验结果证明了该方法的有效性，因为当在 MS-COCO 测试集上进行评估时，我们的模型生成的字幕与人类的判断具有更高的一致性。通过结合各种 SoTA 模型的优势，我们的方法提高了图像标题的质量和吸引力，弥合了自动化系统与人工生成描述的丰富信息性之间的差距。这一进步为生成更适合于视觉语言和字幕模型训练的字幕提供了新的可能性。"
    },
    {
        "title": "FAIR: A Causal Framework for Accurately Inferring Judgments Reversals",
        "url": "http://arxiv.org/abs/2306.11585v1",
        "pub_date": "2023-06-20",
        "summary": "Artificial intelligence researchers have made significant advances in legal\nintelligence in recent years. However, the existing studies have not focused on\nthe important value embedded in judgments reversals, which limits the\nimprovement of the efficiency of legal intelligence. In this paper, we propose\na causal Framework for Accurately Inferring case Reversals (FAIR), which models\nthe problem of judgments reversals based on real Chinese judgments. We mine the\ncauses of judgments reversals by causal inference methods and inject the\nobtained causal relationships into the neural network as a priori knowledge.\nAnd then, our framework is validated on a challenging dataset as a legal\njudgment prediction task. The experimental results show that our framework can\ntap the most critical factors in judgments reversal, and the obtained causal\nrelationships can effectively improve the neural network's performance. In\naddition, we discuss the generalization ability of large language models for\nlegal intelligence tasks using ChatGPT as an example. Our experiment has found\nthat the generalization ability of large language models still has defects, and\nmining causal relationships can effectively improve the accuracy and explain\nability of model predictions.",
        "translated": "近年来，人工智能研究者在法律智能方面取得了重大进展。然而，现有的研究并没有关注到判决书撤销所蕴含的重要价值，这限制了法律情报工作效率的提高。在本文中，我们提出了一个准确推断判例颠倒的因果框架(FAIR) ，该框架基于真实的中国判例对判例颠倒问题进行建模。我们利用因果推理方法挖掘判断反转的原因，并将所得到的因果关系作为先验知识注入到神经网络中。然后，我们的框架在一个具有挑战性的数据集上作为一个法律判决预测任务进行验证。实验结果表明，该框架能够挖掘出判断反转中最关键的因素，得到的因果关系能够有效地提高神经网络的性能。此外，本文还以 ChatGPT 为例，讨论了大型语言模型对法律情报任务的泛化能力。我们的实验发现，大型语言模型的泛化能力仍然存在缺陷，挖掘因果关系可以有效地提高模型预测的准确性和解释能力。"
    },
    {
        "title": "The Ecological Fallacy in Annotation: Modelling Human Label Variation\n  goes beyond Sociodemographics",
        "url": "http://arxiv.org/abs/2306.11559v1",
        "pub_date": "2023-06-20",
        "summary": "Many NLP tasks exhibit human label variation, where different annotators give\ndifferent labels to the same texts. This variation is known to depend, at least\nin part, on the sociodemographics of annotators. Recent research aims to model\nindividual annotator behaviour rather than predicting aggregated labels, and we\nwould expect that sociodemographic information is useful for these models. On\nthe other hand, the ecological fallacy states that aggregate group behaviour,\nsuch as the behaviour of the average female annotator, does not necessarily\nexplain individual behaviour. To account for sociodemographics in models of\nindividual annotator behaviour, we introduce group-specific layers to\nmulti-annotator models. In a series of experiments for toxic content detection,\nwe find that explicitly accounting for sociodemographic attributes in this way\ndoes not significantly improve model performance. This result shows that\nindividual annotation behaviour depends on much more than just\nsociodemographics.",
        "translated": "许多 NLP 任务表现出人工标签的变化，其中不同的注释者为相同的文本提供不同的标签。众所周知，这种差异至少在一定程度上取决于注释者的社会人口统计学特征。最近的研究旨在模拟个人注释者的行为，而不是预测聚合标签，我们期望社会人口信息对这些模型是有用的。另一方面，区群谬误指出，集体行为(例如一般女性注释者的行为)不一定能解释个人行为。为了解释个体注释者行为模型中的社会人口统计学特征，我们在多注释者模型中引入了群体特定层次。在一系列有毒物质含量检测的实验中，我们发现，以这种方式明确考虑社会人口属性并不能显著改善模型的性能。这一结果表明，个人注释行为不仅仅取决于社会人口统计学。"
    },
    {
        "title": "Hallucination is the last thing you need",
        "url": "http://arxiv.org/abs/2306.11520v1",
        "pub_date": "2023-06-20",
        "summary": "The legal profession necessitates a multidimensional approach that involves\nsynthesizing an in-depth comprehension of a legal issue with insightful\ncommentary based on personal experience, combined with a comprehensive\nunderstanding of pertinent legislation, regulation, and case law, in order to\ndeliver an informed legal solution. The present offering with generative AI\npresents major obstacles in replicating this, as current models struggle to\nintegrate and navigate such a complex interplay of understanding, experience,\nand fact-checking procedures. It is noteworthy that where generative AI outputs\nunderstanding and experience, which reflect the aggregate of various subjective\nviews on similar topics, this often deflects the model's attention from the\ncrucial legal facts, thereby resulting in hallucination. Hence, this paper\ndelves into the feasibility of three independent LLMs, each focused on\nunderstanding, experience, and facts, synthesising as one single ensemble model\nto effectively counteract the current challenges posed by the existing\nmonolithic generative AI models. We introduce an idea of mutli-length\ntokenisation to protect key information assets like common law judgements, and\nfinally we interrogate the most advanced publicly available models for legal\nhallucination, with some interesting results.",
        "translated": "法律专业需要一种多层面的方法，包括综合对法律问题的深入理解和根据个人经验作出的有见地的评论，再加上对相关立法、条例和判例法的全面理解，以便提供一个知情的法律解决方案。目前提供的生成性人工智能在复制这一点上存在重大障碍，因为目前的模型正在努力整合和导航这种理解、经验和事实核查程序的复杂相互作用。值得注意的是，当生成性 AI 输出理解和经验时，这些理解和经验反映了对类似主题的各种主观观点的集合，这往往会使模型的注意力偏离关键的法律事实，从而导致幻觉。因此，本文深入探讨了三个独立的 LLM 的可行性，每个 LLM 的重点是理解，经验和事实，综合为一个单一的集成模型，以有效地对抗现有的单片生成 AI 模型所带来的挑战。我们介绍了一个多长度标记的想法，以保护关键的信息资产，如普通法判决，最后我们询问了最先进的公开可用的模型的法律幻觉，一些有趣的结果。"
    },
    {
        "title": "Knowledge-based Multimodal Music Similarity",
        "url": "http://arxiv.org/abs/2306.12249v1",
        "pub_date": "2023-06-21",
        "summary": "Music similarity is an essential aspect of music retrieval, recommendation\nsystems, and music analysis. Moreover, similarity is of vital interest for\nmusic experts, as it allows studying analogies and influences among composers\nand historical periods. Current approaches to musical similarity rely mainly on\nsymbolic content, which can be expensive to produce and is not always readily\navailable. Conversely, approaches using audio signals typically fail to provide\nany insight about the reasons behind the observed similarity. This research\naddresses the limitations of current approaches by focusing on the study of\nmusical similarity using both symbolic and audio content. The aim of this\nresearch is to develop a fully explainable and interpretable system that can\nprovide end-users with more control and understanding of music similarity and\nclassification systems.",
        "translated": "音乐相似性是音乐检索、推荐系统和音乐分析的一个重要方面。此外，相似性对音乐专家来说至关重要，因为它允许研究作曲家和历史时期之间的类比和影响。目前音乐相似性的方法主要依靠符号内容，这可能是昂贵的生产，并不总是容易获得。相反，使用音频信号的方法通常不能提供任何有关观察到的相似性背后的原因的洞察力。本研究针对现有研究方法的局限性，集中研究音乐相似性的符号和音频内容。本研究的目的是开发一个完全可解释及可解释的系统，以提供最终使用者对音乐相似性及分类系统的更多控制及理解。"
    },
    {
        "title": "CompMix: A Benchmark for Heterogeneous Question Answering",
        "url": "http://arxiv.org/abs/2306.12235v1",
        "pub_date": "2023-06-21",
        "summary": "Fact-centric question answering (QA) often requires access to multiple,\nheterogeneous, information sources. By jointly considering several sources like\na knowledge base (KB), a text collection, and tables from the web, QA systems\ncan enhance their answer coverage and confidence. However, existing QA\nbenchmarks are mostly constructed with a single source of knowledge in mind.\nThis limits capabilities of these benchmarks to fairly evaluate QA systems that\ncan tap into more than one information repository. To bridge this gap, we\nrelease CompMix, a crowdsourced QA benchmark which naturally demands the\nintegration of a mixture of input sources. CompMix has a total of 9,410\nquestions, and features several complex intents like joins and temporal\nconditions. Evaluation of a range of QA systems on CompMix highlights the need\nfor further research on leveraging information from heterogeneous sources.",
        "translated": "以事实为中心的问答(QA)通常需要访问多种不同的信息源。通过联合考虑几个来源，如知识库(KB)、文本集合和来自 Web 的表格，QA 系统可以增强它们的答案覆盖范围和信心。然而，现有的质量保证基准大部分都是基于单一的知识来源构建的。这限制了这些基准测试公平评估能够利用多个信息存储库的 QA 系统的能力。为了弥合这一差距，我们发布了 CompMix，一个众包 QA 基准，它自然而然地要求集成多种输入源。CompMix 总共有9,410个问题，并且具有一些复杂的意图，比如连接和时态条件。对 CompMix 上一系列 QA 系统的评估突出表明，需要进一步研究如何利用来自不同来源的信息。"
    },
    {
        "title": "STAN: Stage-Adaptive Network for Multi-Task Recommendation by Learning\n  User Lifecycle-Based Representation",
        "url": "http://arxiv.org/abs/2306.12232v1",
        "pub_date": "2023-06-21",
        "summary": "Recommendation systems play a vital role in many online platforms, with their\nprimary objective being to satisfy and retain users. As directly optimizing\nuser retention is challenging, multiple evaluation metrics are often employed.\nExisting methods generally formulate the optimization of these evaluation\nmetrics as a multitask learning problem, but often overlook the fact that user\npreferences for different tasks are personalized and change over time.\nIdentifying and tracking the evolution of user preferences can lead to better\nuser retention. To address this issue, we introduce the concept of \"user\nlifecycle\", consisting of multiple stages characterized by users' varying\npreferences for different tasks. We propose a novel Stage-Adaptive Network\n(STAN) framework for modeling user lifecycle stages. STAN first identifies\nlatent user lifecycle stages based on learned user preferences, and then\nemploys the stage representation to enhance multi-task learning performance.\nOur experimental results using both public and industrial datasets demonstrate\nthat the proposed model significantly improves multi-task prediction\nperformance compared to state-of-the-art methods, highlighting the importance\nof considering user lifecycle stages in recommendation systems. Furthermore,\nonline A/B testing reveals that our model outperforms the existing model,\nachieving a significant improvement of 3.05% in staytime per user and 0.88% in\nCVR. These results indicate that our approach effectively improves the overall\nefficiency of the multi-task recommendation system.",
        "translated": "推荐系统在许多在线平台中发挥着至关重要的作用，其主要目标是满足和留住用户。由于直接优化用户保留是具有挑战性的，因此经常采用多种评估指标。现有的方法通常将这些评估指标的优化描述为一个多任务学习问题，但往往忽略了这样一个事实，即用户对不同任务的偏好是个性化的，并且随着时间的推移而改变。识别和跟踪用户偏好的演变可以更好地保留用户。为了解决这个问题，我们引入了“用户生命周期”的概念，由多个阶段组成，拥有属性是用户对不同任务的不同偏好。我们提出了一个新的阶段自适应网络(STAN)框架，用于建模用户生命周期阶段。STAN 首先根据学习用户的偏好识别潜在的用户生命周期阶段，然后采用阶段表示来提高多任务学习性能。我们使用公共数据集和工业数据集的实验结果表明，与最先进的方法相比，该模型显著提高了多任务预测性能，突出了在推荐系统中考虑用户生命周期阶段的重要性。此外，在线 A/B 测试表明，我们的模型优于现有的模型，实现了3.05% 的每个用户的停留时间和0.88% 的 CVR 显着改善。这些结果表明，该方法有效地提高了多任务推荐系统的整体效率。"
    },
    {
        "title": "Post-hoc Selection of Pareto-Optimal Solutions in Search and\n  Recommendation",
        "url": "http://arxiv.org/abs/2306.12165v1",
        "pub_date": "2023-06-21",
        "summary": "Information Retrieval (IR) and Recommender Systems (RS) tasks are moving from\ncomputing a ranking of final results based on a single metric to\nmulti-objective problems. Solving these problems leads to a set of\nPareto-optimal solutions, known as Pareto frontier, in which no objective can\nbe further improved without hurting the others. In principle, all the points on\nthe Pareto frontier are potential candidates to represent the best model\nselected with respect to the combination of two, or more, metrics. To our\nknowledge, there are no well-recognized strategies to decide which point should\nbe selected on the frontier. In this paper, we propose a novel, post-hoc,\ntheoretically-justified technique, named \"Population Distance from Utopia\"\n(PDU), to identify and select the one-best Pareto-optimal solution from the\nfrontier. In detail, PDU analyzes the distribution of the points by\ninvestigating how far each point is from its utopia point (the ideal\nperformance for the objectives). The possibility of considering fine-grained\nutopia points allows PDU to select solutions tailored to individual user\npreferences, a novel feature we call \"calibration\". We compare PDU against\nexisting state-of-the-art strategies through extensive experiments on tasks\nfrom both IR and RS. Experimental results show that PDU and combined with\ncalibration notably impact the solution selection. Furthermore, the results\nshow that the proposed framework selects a solution in a principled way,\nirrespective of its position on the frontier, thus overcoming the limits of\nother strategies.",
        "translated": "信息检索(IR)和推荐系统(RS)任务正在从计算基于单一指标的最终结果排序过渡到多目标问题。解决这些问题导致一组帕累托最优解，称为帕累托边界，其中任何目标都不能进一步改进而不损害其他目标。原则上，Pareto 前沿上的所有点都是潜在的候选者，可以代表就两个或更多指标的组合而选择的最佳模型。据我们所知，没有公认的战略来决定哪一点应该选择在前沿。本文提出了一种新的、事后的、理论证明的技术，称为“距离乌托邦的人口距离”(PDU) ，从前沿中识别和选择一个最佳的帕累托最优解。具体来说，PDU 通过调查每个点离它的乌托邦点(目标的理想性能)有多远来分析这些点的分布。考虑细粒度乌托邦点的可能性允许 PDU 选择适合个人用户偏好的解决方案，这个新特性我们称之为“校准”。通过对 IR 和 RS 任务的大量实验，我们比较了 PDU 和现有的最新策略。实验结果表明，PDU 和标定相结合对解决方案的选择有显著影响。此外，结果表明，所提出的框架以原则性的方式选择解决方案，而不考虑其在前沿的位置，从而克服了其他战略的局限性。"
    },
    {
        "title": "Visualizing Relation Between (De)Motivating Topics and Public Stance\n  toward COVID-19 Vaccine",
        "url": "http://arxiv.org/abs/2306.12118v1",
        "pub_date": "2023-06-21",
        "summary": "While social media plays a vital role in communication nowadays,\nmisinformation and trolls can easily take over the conversation and steer\npublic opinion on these platforms. We saw the effect of misinformation during\nthe {COVID-19} pandemic when public health officials faced significant\npush-back while trying to motivate the public to vaccinate. To tackle the\ncurrent and any future threats in emergencies and motivate the public towards a\ncommon goal, it is essential to understand how public motivation shifts and\nwhich topics resonate among the general population. In this study, we proposed\nan interactive visualization tool to inspect and analyze the topics that\nresonated among Twitter-sphere during the {COVID-19} pandemic and understand\nthe key factors that shifted public stance for vaccination. This tool can\neasily be generalized for any scenario for visual analysis and to increase the\ntransparency of social media data for researchers and the general population\nalike.",
        "translated": "尽管社交媒体在当今的交流中扮演着重要的角色，但是错误的信息和喷子很容易就能在这些平台上控制交流和引导公众舆论。在2019冠状病毒疾病大流行期间，我们看到了错误信息的影响，当时公共卫生官员在试图激励公众接种疫苗时面临重大阻力。为了应对当前和今后在紧急情况下的任何威胁，并推动公众实现一个共同目标，必须了解公众的动机如何转变，以及哪些主题在普通民众中产生共鸣。在这项研究中，我们提出了一个交互式可视化工具来检查和分析在2019冠状病毒疾病大流行期间在 twitter 领域引起共鸣的话题，并了解改变公众对疫苗接种立场的关键因素。这个工具可以很容易地推广到任何可视化分析的场景，并为研究人员和普通大众提高社交媒体数据的透明度。"
    },
    {
        "title": "VisoGender: A dataset for benchmarking gender bias in image-text pronoun\n  resolution",
        "url": "http://arxiv.org/abs/2306.12424v1",
        "pub_date": "2023-06-21",
        "summary": "We introduce VisoGender, a novel dataset for benchmarking gender bias in\nvision-language models. We focus on occupation-related gender biases, inspired\nby Winograd and Winogender schemas, where each image is associated with a\ncaption containing a pronoun relationship of subjects and objects in the scene.\nVisoGender is balanced by gender representation in professional roles,\nsupporting bias evaluation in two ways: i) resolution bias, where we evaluate\nthe difference between gender resolution accuracies for men and women and ii)\nretrieval bias, where we compare ratios of male and female professionals\nretrieved for a gender-neutral search query. We benchmark several\nstate-of-the-art vision-language models and find that they lack the reasoning\nabilities to correctly resolve gender in complex scenes. While the direction\nand magnitude of gender bias depends on the task and the model being evaluated,\ncaptioning models generally are more accurate and less biased than CLIP-like\nmodels. Dataset and code are available at https://github.com/oxai/visogender",
        "translated": "我们介绍了视觉性别，一个新的数据集的基准性别偏见的视觉语言模型。我们重点关注与职业相关的性别偏见，灵感来自 Winograd 和 Winosex 模式，其中每个图像都与一个包含场景中主体和客体的代词关系的标题相关联。Viso 性别通过专业角色中的性别代表性来平衡，支持偏倚评估有两种方式: i)解析偏倚，其中我们评估男性和女性性别解析准确性之间的差异以及 ii)检索偏倚，其中我们比较检索的男性和女性专业人员的比例进行性别中立的搜索查询。我们基准的几个国家的最先进的视觉语言模型，发现他们缺乏推理能力，以正确解决性别在复杂的场景。虽然性别偏见的方向和程度取决于被评估的任务和模型，但字幕模型一般比 CLIP 类模型更准确，偏见更少。数据集和代码可在 https://github.com/oxai/visogender 下载"
    },
    {
        "title": "LMFlow: An Extensible Toolkit for Finetuning and Inference of Large\n  Foundation Models",
        "url": "http://arxiv.org/abs/2306.12420v1",
        "pub_date": "2023-06-21",
        "summary": "Large foundation models have demonstrated a great ability to achieve general\nhuman-level intelligence far beyond traditional approaches. As the technique\nkeeps attracting attention from the AI community, more and more large\nfoundation models have become publically available. However, most of those\nmodels exhibit a major deficiency in specialized-task applications, where the\nstep of finetuning is still required for obtaining satisfactory performance. As\nthe number of available models and specialized tasks keeps growing, the job of\ngeneral finetuning becomes highly nontrivial. In this paper, we take the first\nstep to address this issue. We introduce an extensible and lightweight toolkit,\nLMFlow, which aims to simplify the finetuning and inference of general large\nfoundation models. LMFlow offers a complete finetuning workflow for a large\nfoundation model to support personalized training with limited computing\nresources. Furthermore, it supports continuous pretraining, instruction tuning,\nparameter-efficient finetuning, alignment tuning, and large model inference,\nalong with carefully designed and extensible APIs. This toolkit has been\nthoroughly tested and is available at https://github.com/OptimalScale/LMFlow.",
        "translated": "大型基础模型已经证明，它具有实现远远超出传统方法的一般人类水平智能的巨大能力。随着该技术不断受到人工智能界的关注，越来越多的大型基础模型被公开。然而，这些模型中的大多数都表现出专门任务应用程序的主要缺陷，在这些应用程序中，仍然需要进行微调以获得令人满意的性能。随着可用模型和专门任务的数量不断增加，一般微调工作变得非常重要。在本文中，我们采取第一步来解决这个问题。我们介绍了一个可扩展的轻量级工具包 LMFlow，旨在简化一般大型基础模型的微调和推理。LMFlow 为大型基础模型提供了完整的微调工作流，以支持计算资源有限的个性化培训。此外，它还支持连续预训练、指令调优、参数高效微调、对齐调优和大型模型推理，以及精心设计和可扩展的 API。这个工具包已经经过了彻底的测试，可以在 https://github.com/optimalscale/lmflow 上使用。"
    },
    {
        "title": "Solving Dialogue Grounding Embodied Task in a Simulated Environment\n  using Further Masked Language Modeling",
        "url": "http://arxiv.org/abs/2306.12387v1",
        "pub_date": "2023-06-21",
        "summary": "Enhancing AI systems with efficient communication skills that align with\nhuman understanding is crucial for their effective assistance to human users.\nProactive initiatives from the system side are needed to discern specific\ncircumstances and interact aptly with users to solve these scenarios. In this\nresearch, we opt for a collective building assignment taken from the Minecraft\ndataset. Our proposed method employs language modeling to enhance task\nunderstanding through state-of-the-art (SOTA) methods using language models.\nThese models focus on grounding multi-modal understandinging and task-oriented\ndialogue comprehension tasks. This focus aids in gaining insights into how well\nthese models interpret and respond to a variety of inputs and tasks. Our\nexperimental results provide compelling evidence of the superiority of our\nproposed method. This showcases a substantial improvement and points towards a\npromising direction for future research in this domain.",
        "translated": "加强人工智能系统，使其具有与人类理解相一致的高效沟通技能，对于有效协助人类用户至关重要。需要系统方面的主动行动来识别具体情况，并与用户适当地交互以解决这些场景。在这项研究中，我们选择了一个从 Minecraft 数据集中获取的集体建筑分配。我们提出的方法采用语言模型，通过使用语言模型的最新(SOTA)方法来增强任务理解。这些模型侧重于基础的多模态理解和任务导向的对话理解任务。这种关注有助于深入了解这些模型如何很好地解释和响应各种输入和任务。我们的实验结果为我们提出的方法的优越性提供了令人信服的证据。这表明了一个实质性的改进，并指出了该领域未来研究的一个有希望的方向。"
    },
    {
        "title": "Iterated Piecewise Affine (IPA) Approximation for Language Modeling",
        "url": "http://arxiv.org/abs/2306.12317v1",
        "pub_date": "2023-06-21",
        "summary": "In this work, we demonstrate the application of a simple first-order Taylor\nexpansion to approximate a generic function $F: R^{n \\times m} \\to R^{n \\times\nm}$ and utilize it in language modeling. To enhance the basic Taylor expansion,\nwe introduce iteration and piecewise modeling, leading us to name the algorithm\nthe Iterative Piecewise Affine (IPA) approximation. The final algorithm\nexhibits interesting resemblances to the Transformers decoder architecture. By\ncomparing parameter arrangements in IPA and Transformers, we observe a\nstrikingly similar performance, with IPA outperforming Transformers by 1.5\\% in\nthe next token prediction task with cross-entropy loss for smaller sequence\nlengths.",
        "translated": "在本文中，我们应用一个简单的一阶泰勒展开式将一般函数 $F: R ^ { n 乘以 m }逼近到 R ^ { n 乘以 m } $，并将其应用于语言建模。为了增强基本的泰勒展开，我们引入了迭代和分段建模，从而将该算法命名为迭代分段仿射(IPA)近似。最终的算法与变形金刚解码器结构有着有趣的相似之处。通过比较 IPA 和 Transformers 中的参数安排，我们观察到了惊人的相似性能，在交叉熵损失较小的序列长度的下一个令牌预测任务中，IPA 的性能优于 Transformers 1.5% 。"
    },
    {
        "title": "Medical ministrations through web scraping",
        "url": "http://arxiv.org/abs/2306.12310v1",
        "pub_date": "2023-06-21",
        "summary": "Web scraping is a technique that allows us to extract data from websites\nautomatically. in the field of medicine, web scraping can be used to collect\ninformation about medical procedures, treatments, and healthcare providers.\nthis information can be used to improve patient care, monitor the quality of\nhealthcare services, and identify areas for improvement. one area where web\nscraping can be particularly useful is in medical ministrations. medical\nministrations are the actions taken to provide medical care to patients, and\nweb scraping can help healthcare providers identify the most effective\nministrations for their patients. for example, healthcare providers can use web\nscraping to collect data about the symptoms and medical histories of their\npatients, and then use this information to determine the most appropriate\nministrations. they can also use web scraping to gather information about the\nlatest medical research and clinical trials, which can help them stay\nup-to-date with the latest treatments and procedures.",
        "translated": "网页抓取是一种允许我们从网站自动提取数据的技术。在医学领域，网络抓取可以用来收集关于医疗程序、治疗和医疗保健提供者的信息。这些信息可用于改善患者护理，监测医疗服务的质量，并确定需要改进的领域。网络抓取特别有用的一个领域是医疗管理。医疗管理是为病人提供医疗服务而采取的行动，网络抓取可以帮助医疗服务提供者为病人确定最有效的管理。例如，医疗保健提供者可以使用网络抓取来收集关于病人的症状和病史的数据，然后使用这些信息来确定最合适的服务。他们还可以使用网络搜索来收集最新的医学研究和临床试验的信息，这可以帮助他们了解最新的治疗方法和程序。"
    },
    {
        "title": "SIFTER: A Task-specific Alignment Strategy for Enhancing Sentence\n  Embeddings",
        "url": "http://arxiv.org/abs/2306.12280v1",
        "pub_date": "2023-06-21",
        "summary": "The paradigm of pre-training followed by fine-tuning on downstream tasks has\nbecome the mainstream method in natural language processing tasks. Although\npre-trained models have the advantage of generalization, their performance may\nstill vary significantly across different domain tasks. This is because the\ndata distribution in different domains varies. For example, the different parts\nof the sentence 'He married Smt. Dipali Ghosh in 1947 and led a very happy\nmarried life' may have different impact for downstream tasks. For similarity\ncalculations, words such as 'led' and 'life' are more important. On the other\nhand, for sentiment analysis, the word 'happy' is crucial. This indicates that\ndifferent downstream tasks have different levels of sensitivity to sentence\ncomponents. Our starting point is to scale information of the model and data\naccording to the specifics of downstream tasks, enhancing domain information of\nrelevant parts for these tasks and reducing irrelevant elements for different\ndomain tasks, called SIFTER. In the experimental part, we use the SIFTER to\nimprove SimCSE by constructing positive sample pairs based on enhancing the\nsentence stem and reducing the unimportant components in the sentence, and\nmaximize the similarity between three sentences. Similarly, SIFTER can improve\nthe gate mechanism of the LSTM model by short-circuiting the input gate of\nimportant words so that the LSTM model remembers the important parts of the\nsentence. Our experiments demonstrate that SIFTER outperforms the SimCSE and\nLSTM baselines.",
        "translated": "在自然语言处理任务中，预先训练后对下游任务进行微调已成为主流方法。尽管预先训练的模型具有泛化的优势，但是它们的性能在不同的领域任务之间仍然有很大的差异。这是因为不同域中的数据分布不同。例如，句子的不同部分‘他娶了 St。1947年迪帕里 · 高希和他的妻子过着非常幸福的婚姻生活’可能会对下游的工作产生不同的影响。对于相似度计算，“ led”和“ life”这样的单词更为重要。另一方面，对于情感分析来说，“快乐”这个词是至关重要的。这表明不同的下游任务对句子成分的敏感程度不同。我们的出发点是根据下游任务的具体情况来缩放模型和数据的信息，增强这些任务相关部分的领域信息，并减少不同领域任务(称为 SIFTER)的不相关元素。在实验部分，我们利用 SIFTER 算法对 SimCSE 算法进行改进，在增强句子主干和减少句子中不重要成分的基础上构造正样本对，使三个句子之间的相似性最大化。同样，SIFTER 可以通过短路重要词的输入门来改善 LSTM 模型的门机制，从而使 LSTM 模型记住句子的重要部分。我们的实验表明，SIFTER 优于 SimCSE 和 LSTM 基线。"
    },
    {
        "title": "Solving and Generating NPR Sunday Puzzles with Large Language Models",
        "url": "http://arxiv.org/abs/2306.12255v1",
        "pub_date": "2023-06-21",
        "summary": "We explore the ability of large language models to solve and generate puzzles\nfrom the NPR Sunday Puzzle game show using PUZZLEQA, a dataset comprising 15\nyears of on-air puzzles. We evaluate four large language models using PUZZLEQA,\nin both multiple choice and free response formats, and explore two prompt\nengineering techniques to improve free response performance: chain-of-thought\nreasoning and prompt summarization. We find that state-of-the-art large\nlanguage models can solve many PUZZLEQA puzzles: the best model, GPT-3.5,\nachieves 50.2% loose accuracy. However, in our few-shot puzzle generation\nexperiment, we find no evidence that models can generate puzzles: GPT-3.5\ngenerates puzzles with answers that do not conform to the generated rules.\nPuzzle generation remains a challenging task for future work.",
        "translated": "我们使用 PUZZLEQA (一个包含15年现场拼图的数据集)来探索大型语言模型解决和生成 NPR 周日拼图游戏节目中的拼图的能力。我们使用 PUZZLEQA 评估了四种大型语言模型，包括多项选择和自由响应格式，并探索了两种提高自由响应性能的快速工程技术: 思维链推理和快速总结。我们发现最先进的大型语言模型可以解决许多 PUZZLEQA 难题: 最好的模型 GPT-3.5可以达到50.2% 的松散精度。然而，在我们的几个镜头的谜题生成实验中，我们没有发现模型可以生成谜题的证据: GPT-3.5生成的谜题的答案不符合生成的规则。生成谜题仍然是未来工作的一项具有挑战性的任务。"
    },
    {
        "title": "Bidirectional End-to-End Learning of Retriever-Reader Paradigm for\n  Entity Linking",
        "url": "http://arxiv.org/abs/2306.12245v1",
        "pub_date": "2023-06-21",
        "summary": "Entity Linking (EL) is a fundamental task for Information Extraction and\nKnowledge Graphs. The general form of EL (i.e., end-to-end EL) aims to first\nfind mentions in the given input document and then link the mentions to\ncorresponding entities in a specific knowledge base. Recently, the paradigm of\nretriever-reader promotes the progress of end-to-end EL, benefiting from the\nadvantages of dense entity retrieval and machine reading comprehension.\nHowever, the existing study only trains the retriever and the reader separately\nin a pipeline manner, which ignores the benefit that the interaction between\nthe retriever and the reader can bring to the task. To advance the\nretriever-reader paradigm to perform more perfectly on end-to-end EL, we\npropose BEER$^2$, a Bidirectional End-to-End training framework for Retriever\nand Reader. Through our designed bidirectional end-to-end training, BEER$^2$\nguides the retriever and the reader to learn from each other, make progress\ntogether, and ultimately improve EL performance. Extensive experiments on\nbenchmarks of multiple domains demonstrate the effectiveness of our proposed\nBEER$^2$.",
        "translated": "实体连接(EL)是信息抽取和知识图表的基本任务。EL (即端到端 EL)的一般形式旨在首先查找给定输入文档中的提及，然后将提及链接到特定知识库中的相应实体。最近，检索-阅读器的范例推动了端到端 EL 的发展，受益于密集实体检索和机器阅读理解的优势。然而，现有的研究只是以流水线的方式分别训练检索者和读者，忽略了检索者和读者之间的交互可以给任务带来的好处。为了提高检索器-阅读器模式在端到端 EL 上的性能，我们提出了 BEER $^ 2 $，一个针对检索器和阅读器的双向端到端培训框架。通过我们设计的端到端双向培训，BEER $^ 2 $引导检索器和读取器相互学习，共同进步，最终提高 EL 性能。对多个领域的基准的广泛实验证明了我们提出的 BEER $^ 2 $的有效性。"
    },
    {
        "title": "Limits for Learning with Language Models",
        "url": "http://arxiv.org/abs/2306.12213v1",
        "pub_date": "2023-06-21",
        "summary": "With the advent of large language models (LLMs), the trend in NLP has been to\ntrain LLMs on vast amounts of data to solve diverse language understanding and\ngeneration tasks. The list of LLM successes is long and varied. Nevertheless,\nseveral recent papers provide empirical evidence that LLMs fail to capture\nimportant aspects of linguistic meaning. Focusing on universal quantification,\nwe provide a theoretical foundation for these empirical findings by proving\nthat LLMs cannot learn certain fundamental semantic properties including\nsemantic entailment and consistency as they are defined in formal semantics.\nMore generally, we show that LLMs are unable to learn concepts beyond the first\nlevel of the Borel Hierarchy, which imposes severe limits on the ability of\nLMs, both large and small, to capture many aspects of linguistic meaning. This\nmeans that LLMs will continue to operate without formal guarantees on tasks\nthat require entailments and deep linguistic understanding.",
        "translated": "随着大型语言模型(LLM)的出现，自然语言处理(NLP)的发展趋势是在大量数据上训练 LLM，以解决不同的语言理解和生成任务。LLM 的成功之处是多种多样的。尽管如此，最近的几篇论文提供了经验证明，认为 LLM 未能捕捉到语言意义的重要方面。关注全称量化，我们为这些实证研究结果提供了一个理论基础，通过证明 LLM 不能学习某些基本的语义属性，包括语义蕴含和一致性，因为它们是在形式语义学中定义的。更一般地，我们表明，长期语言模型无法学习概念超出第一层次的 Borel 层次，这对长期语言模型的能力，无论大小，捕捉语言意义的许多方面施加了严重的限制。这意味着 LLM 将继续在没有正式保证的情况下运行，而这些任务需要蕴含和深刻的语言理解。"
    },
    {
        "title": "Investigating Pre-trained Language Models on Cross-Domain Datasets, a\n  Step Closer to General AI",
        "url": "http://arxiv.org/abs/2306.12205v1",
        "pub_date": "2023-06-21",
        "summary": "Pre-trained language models have recently emerged as a powerful tool for\nfine-tuning a variety of language tasks. Ideally, when models are pre-trained\non large amount of data, they are expected to gain implicit knowledge. In this\npaper, we investigate the ability of pre-trained language models to generalize\nto different non-language tasks. In particular, we test them on tasks from\ndifferent domains such as computer vision, reasoning on hierarchical data, and\nprotein fold prediction. The four pre-trained models that we used, T5, BART,\nBERT, and GPT-2 achieve outstanding results. They all have similar performance\nand they outperform transformers that are trained from scratch by a large\nmargin. For instance, pre-trained language models perform better on the Listops\ndataset, with an average accuracy of 58.7\\%, compared to transformers trained\nfrom scratch, which have an average accuracy of 29.0\\%. The significant\nimprovement demonstrated across three types of datasets suggests that\npre-training on language helps the models to acquire general knowledge,\nbringing us a step closer to general AI. We also showed that reducing the\nnumber of parameters in pre-trained language models does not have a great\nimpact as the performance drops slightly when using T5-Small instead of\nT5-Base. In fact, when using only 2\\% of the parameters, we achieved a great\nimprovement compared to training from scratch. Finally, in contrast to prior\nwork, we find out that using pre-trained embeddings for the input layer is\nnecessary to achieve the desired results.",
        "translated": "预先训练的语言模型最近已经成为微调各种语言任务的强大工具。理想情况下，当模型在大量数据上进行预训练时，它们应该获得隐含的知识。本文研究了预训练语言模型对不同非语言任务的概括能力。特别是，我们在不同领域的任务中测试它们，例如计算机视觉、层次数据推理和蛋白质折叠预测。我们使用的四个预先训练的模型，T5、 BART、 BERT 和 GPT-2都取得了显著的效果。他们都有相似的性能，他们的表现优于变压器，从零开始训练的大幅度差距。例如，预先训练的语言模型在 Listops 数据集上表现得更好，平均准确率为58.7% ，而从头开始训练的变压器的平均准确率为29.0% 。三类数据集的显著改进表明，语言预训练有助于模型获得一般知识，使我们更接近一般人工智能。我们还发现，减少预训练语言模型中的参数数量不会产生很大的影响，因为当使用 T5-Small 而不是 T5-Base 时，性能会略有下降。事实上，当只使用2% 的参数时，与从头开始训练相比，我们取得了很大的进步。最后，与之前的工作相比，我们发现对输入层使用预训练嵌入对于达到预期的结果是必要的。"
    },
    {
        "title": "Data augmentation for recommender system: A semi-supervised approach\n  using maximum margin matrix factorization",
        "url": "http://arxiv.org/abs/2306.13050v1",
        "pub_date": "2023-06-22",
        "summary": "Collaborative filtering (CF) has become a popular method for developing\nrecommender systems (RS) where ratings of a user for new items is predicted\nbased on her past preferences and available preference information of other\nusers. Despite the popularity of CF-based methods, their performance is often\ngreatly limited by the sparsity of observed entries. In this study, we explore\nthe data augmentation and refinement aspects of Maximum Margin Matrix\nFactorization (MMMF), a widely accepted CF technique for the rating\npredictions, which have not been investigated before. We exploit the inherent\ncharacteristics of CF algorithms to assess the confidence level of individual\nratings and propose a semi-supervised approach for rating augmentation based on\nself-training. We hypothesize that any CF algorithm's predictions with low\nconfidence are due to some deficiency in the training data and hence, the\nperformance of the algorithm can be improved by adopting a systematic data\naugmentation strategy. We iteratively use some of the ratings predicted with\nhigh confidence to augment the training data and remove low-confidence entries\nthrough a refinement process. By repeating this process, the system learns to\nimprove prediction accuracy. Our method is experimentally evaluated on several\nstate-of-the-art CF algorithms and leads to informative rating augmentation,\nimproving the performance of the baseline approaches.",
        "translated": "推荐协同过滤(CF)已经成为开发推荐系统(RS)的一种流行方法，在这种系统中，用户对新项目的评分可以根据其过去的偏好和其他用户的可用偏好信息进行预测。尽管基于 CF 的方法很流行，但是它们的性能常常受到观察条目稀疏性的极大限制。在这项研究中，我们探讨了最大保证金矩阵分解(MMMF)的数据增强和细化方面，这是一种被广泛接受的用于评级预测的 CF 技术，以前从未被研究过。我们利用 CF 算法的固有特性来评估个体评分的置信水平，提出了一种基于自训练的评分增强半监督方法。我们假设任何 CF 算法的低置信度预测都是由于训练数据中的某些缺陷造成的，因此，通过采用系统的数据增强策略可以提高算法的性能。我们迭代地使用一些高置信度预测值来增加训练数据，并通过一个细化过程去除低置信度条目。通过重复这个过程，系统学会提高预测的准确性。我们的方法在几个最先进的 CF 算法上进行了实验评估，导致了信息量的增加，提高了基线方法的性能。"
    },
    {
        "title": "Efficient Partitioning Method of Large-Scale Public Safety\n  Spatio-Temporal Data based on Information Loss Constraints",
        "url": "http://arxiv.org/abs/2306.12857v1",
        "pub_date": "2023-06-22",
        "summary": "The storage, management, and application of massive spatio-temporal data are\nwidely applied in various practical scenarios, including public safety.\nHowever, due to the unique spatio-temporal distribution characteristics of\nre-al-world data, most existing methods have limitations in terms of the\nspatio-temporal proximity of data and load balancing in distributed storage.\nThere-fore, this paper proposes an efficient partitioning method of large-scale\npublic safety spatio-temporal data based on information loss constraints\n(IFL-LSTP). The IFL-LSTP model specifically targets large-scale spatio-temporal\npoint da-ta by combining the spatio-temporal partitioning module (STPM) with\nthe graph partitioning module (GPM). This approach can significantly reduce the\nscale of data while maintaining the model's accuracy, in order to improve the\npartitioning efficiency. It can also ensure the load balancing of distributed\nstorage while maintaining spatio-temporal proximity of the data partitioning\nresults. This method provides a new solution for distributed storage of\nmas-sive spatio-temporal data. The experimental results on multiple real-world\nda-tasets demonstrate the effectiveness and superiority of IFL-LSTP.",
        "translated": "海量时空数据的存储、管理和应用广泛应用于各种实际场景，包括公共安全。然而，由于现实世界数据独特的时空分布特性，现有的方法在数据的时空接近性和分布式存储中的负载均衡方面存在局限性。因此，本文提出了一种基于信息丢失约束的大规模公共安全时空数据有效分割方法(IFL-LSTP)。IFL-LSTP 模型通过将时空分区模块(STPM)与图分区模块(GPM)相结合，专门针对大规模的时空点数据。该方法可以在保持模型精度的同时显著降低数据规模，从而提高分区效率。在保持数据分区结果的时空接近性的同时，还可以保证分布式存储的负载平衡。该方法为海量时空数据的分布式存储提供了一种新的解决方案。在多个实际数据集上的实验结果表明了 IFL-LSTP 的有效性和优越性。"
    },
    {
        "title": "HypeRS: Building a Hypergraph-driven ensemble Recommender System",
        "url": "http://arxiv.org/abs/2306.12800v1",
        "pub_date": "2023-06-22",
        "summary": "Recommender systems are designed to predict user preferences over collections\nof items. These systems process users' previous interactions to decide which\nitems should be ranked higher to satisfy their desires. An ensemble recommender\nsystem can achieve great recommendation performance by effectively combining\nthe decisions generated by individual models. In this paper, we propose a novel\nensemble recommender system that combines predictions made by different models\ninto a unified hypergraph ranking framework. This is the first time that\nhypergraph ranking has been employed to model an ensemble of recommender\nsystems. Hypergraphs are generalizations of graphs where multiple vertices can\nbe connected via hyperedges, efficiently modeling high-order relations. We\ndifferentiate real and predicted connections between users and items by\nassigning different hyperedge weights to individual recommender systems. We\nperform experiments using four datasets from the fields of movie, music and\nnews media recommendation. The obtained results show that the ensemble\nhypergraph ranking method generates more accurate recommendations compared to\nthe individual models and a weighted hybrid approach. The assignment of\ndifferent hyperedge weights to the ensemble hypergraph further improves the\nperformance compared to a setting with identical hyperedge weights.",
        "translated": "推荐系统的目的是预测用户对项目集合的偏好。这些系统处理用户以前的交互，以决定哪些项目应该排名更高，以满足他们的愿望。一个集合推荐系统可以通过有效地结合单个模型产生的决策来实现很好的推荐性能。在这篇文章中，我们提出了一个新的集合推荐系统，它将不同模型的预测结合到一个统一的超图排序框架中。这是第一次使用超图排序来模拟推荐系统的集合。超图是通过超边连接多个顶点的图的推广，它有效地建立了高阶关系。我们通过为各个推荐系统分配不同的超边缘权重来区分用户和项目之间真实的和预测的联系。我们使用来自电影、音乐和新闻媒体推荐领域的四个数据集进行实验。结果表明，与单个模型和加权混合方法相比，集合超图排序方法能够产生更精确的推荐值。与具有相同超边权的设置相比，向集合超图分配不同的超边权进一步提高了性能。"
    },
    {
        "title": "On the Robustness of Generative Retrieval Models: An Out-of-Distribution\n  Perspective",
        "url": "http://arxiv.org/abs/2306.12756v1",
        "pub_date": "2023-06-22",
        "summary": "Recently, we have witnessed generative retrieval increasingly gaining\nattention in the information retrieval (IR) field, which retrieves documents by\ndirectly generating their identifiers. So far, much effort has been devoted to\ndeveloping effective generative retrieval models. There has been less attention\npaid to the robustness perspective. When a new retrieval paradigm enters into\nthe real-world application, it is also critical to measure the\nout-of-distribution (OOD) generalization, i.e., how would generative retrieval\nmodels generalize to new distributions. To answer this question, firstly, we\ndefine OOD robustness from three perspectives in retrieval problems: 1) The\nquery variations; 2) The unforeseen query types; and 3) The unforeseen tasks.\nBased on this taxonomy, we conduct empirical studies to analyze the OOD\nrobustness of several representative generative retrieval models against dense\nretrieval models. The empirical results indicate that the OOD robustness of\ngenerative retrieval models requires enhancement. We hope studying the OOD\nrobustness of generative retrieval models would be advantageous to the IR\ncommunity.",
        "translated": "最近，我们看到生成检索越来越受到信息检索(IR)领域的关注，它通过直接生成文档的标识符来检索文档。到目前为止，已经投入了大量的精力来开发有效的生成检索模型。人们对健壮性视角的关注较少。当一个新的检索范式进入现实世界的应用程序时，衡量分布外(OOD)泛化也是至关重要的，也就是说，生成检索模型如何泛化到新的分布。为了回答这个问题，我们首先从检索问题的三个方面定义了面向对象的鲁棒性: 1)查询变量; 2)不可预见的查询类型; 3)不可预见的任务。在此基础上，我们进行了实证研究，分析了几个代表性的生成检索模型对密集检索模型的面向对象的鲁棒性。实证结果表明，生成检索模型的面向对象的鲁棒性有待提高。我们希望研究生成式检索模型的面向对象的鲁棒性能对信息检索界有所帮助。"
    },
    {
        "title": "Vec2Vec: A Compact Neural Network Approach for Transforming Text\n  Embeddings with High Fidelity",
        "url": "http://arxiv.org/abs/2306.12689v1",
        "pub_date": "2023-06-22",
        "summary": "Vector embeddings have become ubiquitous tools for many language-related\ntasks. A leading embedding model is OpenAI's text-ada-002 which can embed\napproximately 6,000 words into a 1,536-dimensional vector. While powerful,\ntext-ada-002 is not open source and is only available via API. We trained a\nsimple neural network to convert open-source 768-dimensional MPNet embeddings\ninto text-ada-002 embeddings. We compiled a subset of 50,000 online food\nreviews. We calculated MPNet and text-ada-002 embeddings for each review and\ntrained a simple neural network to for 75 epochs. The neural network was\ndesigned to predict the corresponding text-ada-002 embedding for a given MPNET\nembedding. Our model achieved an average cosine similarity of 0.932 on 10,000\nunseen reviews in our held-out test dataset. We manually assessed the quality\nof our predicted embeddings for vector search over text-ada-002-embedded\nreviews. While not as good as real text-ada-002 embeddings, predicted\nembeddings were able to retrieve highly relevant reviews. Our final model,\nVec2Vec, is lightweight (&lt;80 MB) and fast. Future steps include training a\nneural network with a more sophisticated architecture and a larger dataset of\npaired embeddings to achieve greater performance. The ability to convert\nbetween and align embedding spaces may be helpful for interoperability,\nlimiting dependence on proprietary models, protecting data privacy, reducing\ncosts, and offline operations.",
        "translated": "向量嵌入已经成为许多语言相关任务的普遍工具。一个领先的嵌入模型是 OpenAI 的 text-ada-002，它可以将大约6,000个单词嵌入到1,536维的向量中。Text-ada-002虽然功能强大，但它不是开源的，只能通过 API 使用。我们训练了一个简单的神经网络来将开源的768维 MPNet 嵌入转换为 text-ada-002嵌入。我们收集了50,000份在线食品评论。我们计算了每个评论的 MPNet 和 text-ada-002嵌入，并将一个简单的神经网络训练到75个时代。针对给定的 MPNET 嵌入，设计神经网络对相应的 text-ada-002嵌入进行预测。在我们的测试数据集中，我们的模型在10,000个看不见的评论上达到了0.932的平均余弦距离。我们通过 text-ada-002嵌入式评论手动评估了我们预测的向量搜索嵌入的质量。虽然不如真正的 text-ada-002嵌入，但预测的嵌入能够检索高度相关的评论。我们最终的模型 Vec2Vec 是轻量级的(< 80MB)并且速度很快。未来的步骤包括训练具有更复杂结构和更大的配对嵌入数据集的神经网络，以实现更好的性能。在嵌入空间之间进行转换和对齐的能力可能有助于实现互操作性、限制对专有模型的依赖、保护数据隐私、降低成本和离线操作。"
    },
    {
        "title": "Semi-automated extraction of research topics and trends from NCI funding\n  in radiological sciences from 2000-2020",
        "url": "http://arxiv.org/abs/2306.13075v1",
        "pub_date": "2023-06-22",
        "summary": "Investigators, funders, and the public desire knowledge on topics and trends\nin publicly funded research but current efforts in manual categorization are\nlimited in scale and understanding. We developed a semi-automated approach to\nextract and name research topics, and applied this to \\$1.9B of NCI funding\nover 21 years in the radiological sciences to determine micro- and macro-scale\nresearch topics and funding trends. Our method relies on sequential clustering\nof existing biomedical-based word embeddings, naming using subject matter\nexperts, and visualization to discover trends at a macroscopic scale above\nindividual topics. We present results using 15 and 60 cluster topics, where we\nfound that 2D projection of grant embeddings reveals two dominant axes:\nphysics-biology and therapeutic-diagnostic. For our dataset, we found that\nfunding for therapeutics- and physics-based research have outpaced diagnostics-\nand biology-based research, respectively. We hope these results may (1) give\ninsight to funders on the appropriateness of their funding allocation, (2)\nassist investigators in contextualizing their work and explore neighboring\nresearch domains, and (3) allow the public to review where their tax dollars\nare being allocated.",
        "translated": "研究人员、资助者和公众希望了解公共资助研究的主题和趋势，但目前在人工分类方面的努力在规模和理解方面受到限制。我们开发了一种半自动化的方法来提取和命名研究主题，并将其应用于21年来 NCI 在放射科学领域的19亿美元资金，以确定微观和宏观研究主题和资金趋势。我们的方法依赖于现有的基于生物医学的单词嵌入的顺序聚类，使用主题专家命名，以及可视化来发现在个别主题之上的宏观趋势。我们使用15和60个聚类主题展示结果，其中我们发现赠款嵌入的二维投影揭示了两个主要轴: 物理-生物学和治疗-诊断。对于我们的数据集，我们发现基于治疗学和物理学的研究经费分别超过了基于诊断学和基于生物学的研究。我们希望这些结果可以(1)让资助者了解他们资金分配的适当性，(2)帮助调查人员将他们的工作背景化，并探索相邻的研究领域，(3)允许公众审查他们的税款分配在哪里。"
    },
    {
        "title": "Can LLMs Express Their Uncertainty? An Empirical Evaluation of\n  Confidence Elicitation in LLMs",
        "url": "http://arxiv.org/abs/2306.13063v1",
        "pub_date": "2023-06-22",
        "summary": "The task of empowering large language models (LLMs) to accurately express\ntheir confidence, referred to as confidence elicitation, is essential in\nensuring reliable and trustworthy decision-making processes. Previous methods,\nwhich primarily rely on model logits, have become less suitable for LLMs and\neven infeasible with the rise of closed-source LLMs (e.g., commercialized LLM\nAPIs). This leads to a growing need to explore the untapped area of\n\\emph{non-logit-based} approaches to estimate the uncertainty of LLMs. Hence,\nin this study, we investigate approaches for confidence elicitation that do not\nrequire model fine-tuning or access to proprietary information. We introduce\nthree categories of methods: verbalize-based, consistency-based, and their\nhybrid methods for benchmarking, and evaluate their performance across five\ntypes of datasets and four widely-used LLMs. Our analysis of these methods\nuncovers several key insights: 1) LLMs often exhibit a high degree of\noverconfidence when verbalizing their confidence; 2) Prompting strategies such\nas CoT, Top-K and Multi-step confidences improve calibration of verbalized\nconfidence; 3) Consistency-based methods outperform the verbalized confidences\nin most cases, with particularly notable improvements on the arithmetic\nreasoning task; 4) Hybrid methods consistently deliver the best performance\nover their baselines, thereby emerging as a promising state-of-the-art\napproach; 5) Despite these advancements, all investigated methods continue to\nstruggle with challenging tasks, such as those requiring professional\nknowledge, leaving significant scope for improvement of confidence elicitation.",
        "translated": "授权大型语言模型(LLM)准确表达其置信度(称为置信度激发)的任务对于确保可靠和可信的决策过程至关重要。以前的方法，主要依赖于模型 logit，已经变得不太适合 LLM，甚至随着封闭源 LLM (例如，商业化 LLM API)的兴起而变得不可行。这导致人们越来越需要探索 emph { non-logit-based }方法中尚未开发的领域来估计 LLM 的不确定性。因此，在这项研究中，我们调查了不需要模型微调或访问专有信息的信心获取方法。我们介绍了三类方法: 基于语言的、基于一致性的和它们的混合基准测试方法，并且评估了它们在五种类型的数据集和四种广泛使用的 LLM 中的性能。我们对这些方法的分析揭示了几个关键的见解: 1) LLM 在表达他们的信心时经常表现出高度的过度自信; 2)提示策略，如 CoT，Top-K 和 Multi-step 置信度改善了口头置信度的校准; 3)基于一致性的方法在大多数情况下优于口头置信度，在算术推理任务上有特别显着的改善; 4)混合方法始终在其基线上提供最佳性能，从而成为一种有希望的最先进的方法; 5)尽管有这些进步，所有被调查的方法继续与具有挑战性的任务斗争，例如那些需要专业知识的任务，留下显着的提高。"
    },
    {
        "title": "Named entity recognition in resumes",
        "url": "http://arxiv.org/abs/2306.13062v1",
        "pub_date": "2023-06-22",
        "summary": "Named entity recognition (NER) is used to extract information from various\ndocuments and texts such as names and dates. It is important to extract\neducation and work experience information from resumes in order to filter them.\nConsidering the fact that all information in a resume has to be entered to the\ncompanys system manually, automatizing this process will save time of the\ncompanies. In this study, a deep learning-based semi-automatic named entity\nrecognition system has been implemented with a focus on resumes in the field of\nIT. Firstly, resumes of employees from five different IT related fields has\nbeen annotated. Six transformer based pre-trained models have been adapted to\nnamed entity recognition problem using the annotated data. These models have\nbeen selected among popular models in the natural language processing field.\nThe obtained system can recognize eight different entity types which are city,\ndate, degree, diploma major, job title, language, country and skill. Models\nused in the experiments are compared using micro, macro and weighted F1 scores\nand the performance of the methods was evaluated. Taking these scores into\naccount for test set the best micro and weighted F1 score is obtained by\nRoBERTa and the best macro F1 score is obtained by Electra model.",
        "translated": "命名实体识别(NER)用于从各种文档和文本(如姓名和日期)中提取信息。从简历中提取教育和工作经验信息，对简历进行过滤是非常重要的。考虑到简历中的所有信息都必须手动输入到公司系统中，这个过程的自动化将节省公司的时间。本文以 IT 领域的简历为研究对象，实现了一个基于深度学习的半自动命名实体识别系统。首先，对来自五个不同 IT 相关领域的员工的简历进行了注释。针对基于注释数据的命名实体识别问题，提出了六种基于变压器的预训练模型。这些模型已经被自然语言处理领域的流行模型所选择。所获得的系统可以识别城市、日期、学位、文凭专业、职称、语言、国家和技能等八种不同的实体类型。利用微观、宏观和加权 F1评分对实验中使用的模型进行了比较，并对方法的性能进行了评价。将这些得分考虑进测试集，用 RoBERTa 得到最佳微观和加权 F1得分，用 Electra 模型得到最佳宏观 F1得分。"
    },
    {
        "title": "CamChoice: A Corpus of Multiple Choice Questions and Candidate Response\n  Distributions",
        "url": "http://arxiv.org/abs/2306.13047v1",
        "pub_date": "2023-06-22",
        "summary": "Multiple Choice examinations are a ubiquitous form of assessment that is used\nto measure the ability of candidates across various domains and tasks.\nMaintaining the quality of proposed questions is of great importance to test\ndesigners, and therefore newly proposed questions go through several pre-test\nevaluation stages before they can be deployed into real-world exams. This\nprocess is currently quite manual, which can lead to time lags in the question\ndevelopment cycle. Automating this process would lead to a large improvement in\nefficiency, however, current datasets do not contain sufficient pre-test\nanalysis information. In this paper, we introduce CamChoice; a multiple-choice\ncomprehension dataset with questions at different target levels, where\nquestions have the true candidate selected options distributions. We introduce\nthe task of candidate distribution matching, propose several evaluation metrics\nfor the task, and demonstrate that automatic systems trained on RACE++ can be\nleveraged as baselines for our task. We further demonstrate that these\nautomatic systems can be used for practical pre-test evaluation tasks such as\ndetecting underperforming distractors, where our detection systems can\nautomatically identify poor distractors that few candidates select. We release\nthe data publicly for future research.",
        "translated": "多项选择考试是一种普遍存在的评估形式，用于衡量候选人在不同领域和任务的能力。保持试题的质量对于考试设计人员来说是非常重要的，因此新提出的试题要经过几个试题前的评估阶段才能应用到现实考试中。这个过程目前是相当手工的，这可能会导致问题开发周期中的时间滞后。自动化这个过程将导致效率的大幅度提高，但是，目前的数据集不包含足够的预测试分析信息。在本文中，我们介绍了 CamChoice，这是一个多项选择理解数据集，包含不同目标层次的问题，其中问题具有真实的候选选项分布。我们介绍了候选分布匹配的任务，提出了该任务的几个评价指标，并证明了基于 RACE + + 的自动系统可以作为我们的任务的基线。我们进一步证明这些自动系统可以用于实际的测试前评估任务，例如检测表现不佳的干扰物，我们的检测系统可以自动识别很少候选人选择的差的干扰物。我们公开这些数据以便将来研究。"
    },
    {
        "title": "Towards Explainable Evaluation Metrics for Machine Translation",
        "url": "http://arxiv.org/abs/2306.13041v1",
        "pub_date": "2023-06-22",
        "summary": "Unlike classical lexical overlap metrics such as BLEU, most current\nevaluation metrics for machine translation (for example, COMET or BERTScore)\nare based on black-box large language models. They often achieve strong\ncorrelations with human judgments, but recent research indicates that the\nlower-quality classical metrics remain dominant, one of the potential reasons\nbeing that their decision processes are more transparent. To foster more\nwidespread acceptance of novel high-quality metrics, explainability thus\nbecomes crucial. In this concept paper, we identify key properties as well as\nkey goals of explainable machine translation metrics and provide a\ncomprehensive synthesis of recent techniques, relating them to our established\ngoals and properties. In this context, we also discuss the latest\nstate-of-the-art approaches to explainable metrics based on generative models\nsuch as ChatGPT and GPT4. Finally, we contribute a vision of next-generation\napproaches, including natural language explanations. We hope that our work can\nhelp catalyze and guide future research on explainable evaluation metrics and,\nmediately, also contribute to better and more transparent machine translation\nsystems.",
        "translated": "与经典的词汇重叠度量(如 BLEU)不同，目前大多数机器翻译评估度量(如 COMET 或 BERTScore)都基于黑盒大语言模型。它们往往与人类的判断有很强的相关性，但最近的研究表明，质量较低的经典指标仍然占主导地位，其中一个潜在的原因是它们的决策过程更加透明。为了促进更广泛地接受新颖的高质量度量，可解释性因此变得至关重要。在这篇概念文章中，我们确定了可解释的机器翻译度量的关键性质和关键目标，并提供了一个综合性的最新技术，它们与我们建立的目标和性质相关联。在这个上下文中，我们还讨论了基于 ChatGPT 和 GPT4等生成模型的可解释度量的最新技术。最后，我们展望了下一代方法，包括自然语言解释。我们希望我们的工作能够有助于促进和指导今后关于可解释的评估指标的研究，并且在中间阶段，还有助于更好和更透明的机器翻译系统。"
    },
    {
        "title": "Apolitical Intelligence? Auditing Delphi's responses on controversial\n  political issues in the US",
        "url": "http://arxiv.org/abs/2306.13000v1",
        "pub_date": "2023-06-22",
        "summary": "As generative language models are deployed in ever-wider contexts, concerns\nabout their political values have come to the forefront with critique from all\nparts of the political spectrum that the models are biased and lack neutrality.\nHowever, the question of what neutrality is and whether it is desirable remains\nunderexplored. In this paper, I examine neutrality through an audit of Delphi\n[arXiv:2110.07574], a large language model designed for crowdsourced ethics. I\nanalyse how Delphi responds to politically controversial questions compared to\ndifferent US political subgroups. I find that Delphi is poorly calibrated with\nrespect to confidence and exhibits a significant political skew. Based on these\nresults, I examine the question of neutrality from a data-feminist lens, in\nterms of how notions of neutrality shift power and further marginalise unheard\nvoices. These findings can hopefully contribute to a more reflexive debate\nabout the normative questions of alignment and what role we want generative\nmodels to play in society.",
        "translated": "随着生成语言模型被应用于更广泛的环境中，人们对其政治价值观的担忧已成为当务之急，政治光谱各方纷纷批评这些模型存在偏见，缺乏中立性。然而，什么是中立以及中立是否可取的问题仍然没有得到充分的探讨。在本文中，我通过对 Delphi [ arXiv: 2110.07574]的审计来检验中立性，这是一个为众包伦理学设计的大型语言模型。我分析了德尔菲如何回应政治上有争议的问题，并与美国不同的政治分组进行了比较。我发现，德尔福在信心方面的标准很差，而且显示出明显的政治倾斜。基于这些结果，我从数据女权主义的角度来审视中立的问题，中立的概念如何转移权力并进一步边缘化未被听到的声音。这些研究结果有望有助于就协调一致的规范性问题以及我们希望生成模式在社会中发挥什么作用进行更自反性的辩论。"
    },
    {
        "title": "Speech Emotion Diarization: Which Emotion Appears When?",
        "url": "http://arxiv.org/abs/2306.12991v1",
        "pub_date": "2023-06-22",
        "summary": "Speech Emotion Recognition (SER) typically relies on utterance-level\nsolutions. However, emotions conveyed through speech should be considered as\ndiscrete speech events with definite temporal boundaries, rather than\nattributes of the entire utterance. To reflect the fine-grained nature of\nspeech emotions, we propose a new task: Speech Emotion Diarization (SED). Just\nas Speaker Diarization answers the question of \"Who speaks when?\", Speech\nEmotion Diarization answers the question of \"Which emotion appears when?\". To\nfacilitate the evaluation of the performance and establish a common benchmark\nfor researchers, we introduce the Zaion Emotion Dataset (ZED), an openly\naccessible speech emotion dataset that includes non-acted emotions recorded in\nreal-life conditions, along with manually-annotated boundaries of emotion\nsegments within the utterance. We provide competitive baselines and open-source\nthe code and the pre-trained models.",
        "translated": "语音情感识别(SER)通常依赖于话语级别的解决方案。然而，通过言语传达的情感应被视为具有明确的时间界限的离散的言语事件，而不是整个话语的属性。为了反映言语情绪的细粒度特性，我们提出了一个新的任务: 言语情绪日化(SED)。正如“说话人日历化”回答了“谁在什么时候说话”这个问题一样言语情感日化回答了“什么情感在什么时候出现?”.为了便于评估表现，并为研究人员建立一个共同的基准，我们引入了 Zaion 情绪数据集(ZED) ，这是一个开放访问的语音情绪数据集，包括在现实生活条件下记录的非行为情绪，以及在话语中手动注释的情绪段的边界。我们提供有竞争力的基线和开源的代码和预先训练的模型。"
    },
    {
        "title": "Conversation Derailment Forecasting with Graph Convolutional Networks",
        "url": "http://arxiv.org/abs/2306.12982v1",
        "pub_date": "2023-06-22",
        "summary": "Online conversations are particularly susceptible to derailment, which can\nmanifest itself in the form of toxic communication patterns like disrespectful\ncomments or verbal abuse. Forecasting conversation derailment predicts signs of\nderailment in advance enabling proactive moderation of conversations. Current\nstate-of-the-art approaches to address this problem rely on sequence models\nthat treat dialogues as text streams. We propose a novel model based on a graph\nconvolutional neural network that considers dialogue user dynamics and the\ninfluence of public perception on conversation utterances. Through empirical\nevaluation, we show that our model effectively captures conversation dynamics\nand outperforms the state-of-the-art models on the CGA and CMV benchmark\ndatasets by 1.5\\% and 1.7\\%, respectively.",
        "translated": "在线对话特别容易出轨，这可能表现为有毒的交流模式，如无礼的评论或口头辱骂。预测会话脱轨可以提前预测脱轨的迹象，从而能够主动调节会话。目前解决这个问题的最先进的方法依赖于将对话视为文本流的序列模型。我们提出了一个基于图形卷积神经网络的新模型，该模型考虑了对话使用者的动态变化以及公众认知对会话话语的影响。通过实证评估，我们发现我们的模型有效地捕获了会话动态，并且在 CGA 和 CMV 基准数据集上分别优于最先进的模型1.5% 和1.7% 。"
    },
    {
        "title": "Tracking public attitudes toward ChatGPT on Twitter using sentiment\n  analysis and topic modeling",
        "url": "http://arxiv.org/abs/2306.12951v1",
        "pub_date": "2023-06-22",
        "summary": "ChatGPT sets a new record with the fastest-growing user base, as a chatbot\npowered by a large language model (LLM). While it demonstrates state-of-the-art\ncapabilities in a variety of language-generating tasks, it also raises\nwidespread public concerns regarding its societal impact. In this paper, we\nutilize natural language processing approaches to investigate the public\nattitudes towards ChatGPT by applying sentiment analysis and topic modeling\ntechniques to Twitter data. Our result shows that the overall sentiment is\nlargely neutral to positive, which also holds true across different occupation\ngroups. Among a wide range of topics mentioned in tweets, the most popular\ntopics are Artificial Intelligence, Search Engines, Education, Writing, and\nQuestion Answering.",
        "translated": "ChatGPT 作为一个由大型语言模型(LLM)驱动的聊天机器人，用增长最快的用户群创建了一个新的记录。虽然它在各种语言生成任务中展示了最先进的能力，但它也引起了公众对其社会影响的广泛关注。本文利用自然语言处理方法，通过对 Twitter 数据的情感分析和主题建模技术，研究公众对 ChatGPT 的态度。我们的结果表明，总体情绪在很大程度上是中性至积极的，这也适用于不同的职业群体。在众多的话题中，最受欢迎的话题是人工智能、搜索引擎、教育、写作和问答。"
    },
    {
        "title": "Quantizable Transformers: Removing Outliers by Helping Attention Heads\n  Do Nothing",
        "url": "http://arxiv.org/abs/2306.12929v1",
        "pub_date": "2023-06-22",
        "summary": "Transformer models have been widely adopted in various domains over the last\nyears, and especially large language models have advanced the field of AI\nsignificantly. Due to their size, the capability of these networks has\nincreased tremendously, but this has come at the cost of a significant increase\nin necessary compute. Quantization is one of the most effective ways to reduce\nthe computational time and memory consumption of neural networks. Many studies\nhave shown, however, that modern transformer models tend to learn strong\noutliers in their activations, making them difficult to quantize. To retain\nacceptable performance, the existence of these outliers requires activations to\nbe in higher bitwidth or the use of different numeric formats, extra\nfine-tuning, or other workarounds. We show that strong outliers are related to\nvery specific behavior of attention heads that try to learn a \"no-op\" or just a\npartial update of the residual. To achieve the exact zeros needed in the\nattention matrix for a no-update, the input to the softmax is pushed to be\nlarger and larger during training, causing outliers in other parts of the\nnetwork. Based on these observations, we propose two simple (independent)\nmodifications to the attention mechanism - clipped softmax and gated attention.\nWe empirically show that models pre-trained using our methods learn\nsignificantly smaller outliers while maintaining and sometimes even improving\nthe floating-point task performance. This enables us to quantize transformers\nto full INT8 quantization of the activations without any additional effort. We\ndemonstrate the effectiveness of our methods on both language models (BERT,\nOPT) and vision transformers.",
        "translated": "近年来，变压器模型在各个领域得到了广泛的应用，尤其是大型语言模型的应用极大地推动了人工智能的发展。由于它们的规模，这些网络的能力已经大大增加，但这是以必要的计算能力显著增加为代价的。量化是减少神经网络计算时间和内存消耗的有效方法之一。然而，许多研究表明，现代变压器模型往往学习强烈的异常值在其激活，使他们难以量化。为了保持可接受的性能，这些异常值的存在要求激活具有更高的位宽或使用不同的数字格式、额外的微调或其他变通方法。我们发现强异常值与注意力集中的非常具体的行为有关，这些行为试图学习一个“不可操作”或仅仅是残差的部分更新。为了获得注意矩阵中无更新所需的精确零点，在训练过程中，向软极大的输入被推得越来越大，从而在网络的其他部分产生异常值。基于这些观察，我们提出了两个简单的(独立的)修正注意机制-剪切软最大和门控注意。我们的经验表明，使用我们的方法预训练的模型学习显着较小的异常值，同时维护，有时甚至提高浮点任务的性能。这使我们能够量化变压器，以充分的 INT8量化的激活没有任何额外的努力。我们证明了我们的方法在语言模型(BERT，OPT)和视觉转换器上的有效性。"
    },
    {
        "title": "Fuzzification-based Feature Selection for Enhanced Website Content\n  Encryption",
        "url": "http://arxiv.org/abs/2306.13548v1",
        "pub_date": "2023-06-23",
        "summary": "We propose a novel approach that utilizes fuzzification theory to perform\nfeature selection on website content for encryption purposes. Our objective is\nto identify and select the most relevant features from the website by\nharnessing the principles of fuzzy logic. Fuzzification allows us to transform\nthe crisp website content into fuzzy representations, enabling a more nuanced\nanalysis of their characteristics. By considering the degree of membership of\neach feature in different fuzzy categories, we can evaluate their importance\nand relevance for encryption. This approach enables us to prioritize and focus\non the features that exhibit higher membership degrees, indicating their\nsignificance in the encryption process. By employing fuzzification-based\nfeature selection, we aim to enhance the effectiveness and efficiency of\nwebsite content encryption, ultimately improving the overall internet security.",
        "translated": "我们提出了一种新的方法，利用模糊化理论对网站内容进行特征选择，以达到加密的目的。我们的目标是通过利用模糊逻辑的原则，从网站中识别和选择最相关的特性。模糊化允许我们将清晰的网站内容转换为模糊表示，从而能够对其特征进行更细致入微的分析。通过考虑每个特征在不同模糊类别中的隶属度，我们可以评估它们对加密的重要性和相关性。这种方法使我们能够优先考虑和关注那些表现出更高的成员等级的特征，表明它们在加密过程中的重要性。采用基于模糊化的特征选择方法，提高网站内容加密的有效性和效率，最终提高网络的整体安全性。"
    },
    {
        "title": "OptMSM: Optimizing Multi-Scenario Modeling for Click-Through Rate\n  Prediction",
        "url": "http://arxiv.org/abs/2306.13382v1",
        "pub_date": "2023-06-23",
        "summary": "A large-scale industrial recommendation platform typically consists of\nmultiple associated scenarios, requiring a unified click-through rate (CTR)\nprediction model to serve them simultaneously. Existing approaches for\nmulti-scenario CTR prediction generally consist of two main modules: i) a\nscenario-aware learning module that learns a set of multi-functional\nrepresentations with scenario-shared and scenario-specific information from\ninput features, and ii) a scenario-specific prediction module that serves each\nscenario based on these representations. However, most of these approaches\nprimarily focus on improving the former module and neglect the latter module.\nThis can result in challenges such as increased model parameter size, training\ndifficulty, and performance bottlenecks for each scenario. To address these\nissues, we propose a novel framework called OptMSM (\\textbf{Opt}imizing\n\\textbf{M}ulti-\\textbf{S}cenario \\textbf{M}odeling). First, we introduce a\nsimplified yet effective scenario-enhanced learning module to alleviate the\naforementioned challenges. Specifically, we partition the input features into\nscenario-specific and scenario-shared features, which are mapped to specific\ninformation embedding encodings and a set of shared information embeddings,\nrespectively. By imposing an orthogonality constraint on the shared information\nembeddings to facilitate the disentanglement of shared information\ncorresponding to each scenario, we combine them with the specific information\nembeddings to obtain multi-functional representations. Second, we introduce a\nscenario-specific hypernetwork in the scenario-specific prediction module to\ncapture interactions within each scenario more effectively, thereby alleviating\nthe performance bottlenecks. Finally, we conduct extensive offline experiments\nand an online A/B test to demonstrate the effectiveness of OptMSM.",
        "translated": "一个大规模的工业推荐平台通常由多个相关场景组成，需要一个统一的点进率预测模型来同时为这些场景提供服务。现有的多场景 CTR 预测方法通常由两个主要模块组成: 一个场景感知学习模块，该模块从输入特征中学习一组具有场景共享和场景特定信息的多功能表示; 二个场景特定预测模块，该模块基于这些表示为每个场景提供服务。然而，这些方法大多集中于改进前一个模块，而忽略了后一个模块。这可能导致各种挑战，例如增加模型参数的大小、训练难度和每个场景的性能瓶颈。为了解决这些问题，我们提出了一个新的框架 OptMSM (textbf { Opt } imizingtextbf { M } ulti-textbf { S } cenario textbf { M } odeling)。首先，我们引入一个简化但有效的情景增强学习模块，以缓解上述挑战。具体来说，我们将输入特性划分为场景特定特性和场景共享特性，分别映射到特定信息嵌入编码和一组共享信息嵌入。通过对共享信息嵌入施加正交性约束，以促进对应于每个场景的共享信息的分离，将它们与特定的信息嵌入相结合，得到多功能表示。其次，在场景特定的预测模块中引入场景特定的超网络，以更有效地捕获每个场景中的交互，从而缓解性能瓶颈。最后，我们进行了大量的离线实验和在线 A/B 测试来验证 OptMSM 的有效性。"
    },
    {
        "title": "Human Activity Behavioural Pattern Recognition in Smarthome with\n  Long-hour Data Collection",
        "url": "http://arxiv.org/abs/2306.13374v1",
        "pub_date": "2023-06-23",
        "summary": "The research on human activity recognition has provided novel solutions to\nmany applications like healthcare, sports, and user profiling. Considering the\ncomplex nature of human activities, it is still challenging even after\neffective and efficient sensors are available. The existing works on human\nactivity recognition using smartphone sensors focus on recognizing basic human\nactivities like sitting, sleeping, standing, stair up and down and running.\nHowever, more than these basic activities is needed to analyze human\nbehavioural pattern. The proposed framework recognizes basic human activities\nusing deep learning models. Also, ambient sensors like PIR, pressure sensors,\nand smartphone-based sensors like accelerometers and gyroscopes are combined to\nmake it hybrid-sensor-based human activity recognition. The hybrid approach\nhelped derive more activities than the basic ones, which also helped derive\nhuman activity patterns or user profiling. User profiling provides sufficient\ninformation to identify daily living activity patterns and predict whether any\nanomaly exists. The framework provides the base for applications such as\nelderly monitoring when they are alone at home. The GRU model's accuracy of\n95\\% is observed to recognize the basic activities. Finally, Human activity\npatterns over time are recognized based on the duration and frequency of the\nactivities. It is observed that human activity pattern, like, morning walking\nduration, varies depending on the day of the week.",
        "translated": "人类活动识别的研究为许多应用提供了新颖的解决方案，如医疗保健、体育和用户侧写。考虑到人类活动的复杂性，即使在有效和高效的传感器可用之后，这仍然是具有挑战性的。现有的利用智能手机传感器进行人类活动识别的工作主要集中在识别基本的人类活动，如坐着、睡觉、站立、上下楼梯和跑步。然而，分析人类行为模式需要的不仅仅是这些基本活动。提议的框架使用深度学习模型识别基本的人类活动。此外，环境传感器如 PIR，压力传感器和智能手机传感器如加速度计和陀螺仪的组合，使其混合传感器为基础的人类活动识别。混合方法有助于派生出比基本方法更多的活动，这也有助于派生出人类活动模式或用户分析。用户分析提供了足够的信息来识别日常生活活动模式，并预测是否存在任何异常。该框架为应用程序提供了基础，例如独自在家的老年人监测。GRU 模型识别基本活动的准确率达到95% 。最后，随着时间的推移，人类活动模式的识别基于活动的持续时间和频率。据观察，人类的活动模式，如早晨步行时间，根据不同的一天的一周。"
    },
    {
        "title": "A Decade of Scholarly Research on Open Knowledge Graphs",
        "url": "http://arxiv.org/abs/2306.13186v1",
        "pub_date": "2023-06-22",
        "summary": "The proliferation of open knowledge graphs has led to a surge in scholarly\nresearch on the topic over the past decade. This paper presents a bibliometric\nanalysis of the scholarly literature on open knowledge graphs published between\n2013 and 2023. The study aims to identify the trends, patterns, and impact of\nresearch in this field, as well as the key topics and research questions that\nhave emerged. The work uses bibliometric techniques to analyze a sample of 4445\nscholarly articles retrieved from Scopus. The findings reveal an\never-increasing number of publications on open knowledge graphs published every\nyear, particularly in developed countries (+50 per year). These outputs are\npublished in highly-referred scholarly journals and conferences. The study\nidentifies three main research themes: (1) knowledge graph construction and\nenrichment, (2) evaluation and reuse, and (3) fusion of knowledge graphs into\nNLP systems. Within these themes, the study identifies specific tasks that have\nreceived considerable attention, including entity linking, knowledge graph\nembedding, and graph neural networks.",
        "translated": "在过去的十年中，开放知识图表的激增导致了关于这一主题的学术研究的激增。本文对2013-2023年间发表的关于开放知识图表的学术文献进行了文献计量分析。本研究旨在确定该领域研究的趋势、模式和影响，以及出现的关键主题和研究问题。这项工作使用文献计量学技术来分析从 Scopus 检索到的4445篇学术文章的样本。研究结果显示，每年出版的关于开放知识图表的出版物数量不断增加，尤其是在发达国家(每年增加50本)。这些成果发表在高度引用的学术期刊和会议上。本研究确定了三个主要的研究主题: (1)知识图的构建与丰富; (2)知识图的评价与重用; (3)知识图在自然语言处理系统中的融合。在这些主题中，研究确定了已经受到相当关注的具体任务，包括实体连接、知识图嵌入和图神经网络。"
    },
    {
        "title": "Bring Your Own Data! Self-Supervised Evaluation for Large Language\n  Models",
        "url": "http://arxiv.org/abs/2306.13651v1",
        "pub_date": "2023-06-23",
        "summary": "With the rise of Large Language Models (LLMs) and their ubiquitous deployment\nin diverse domains, measuring language model behavior on realistic data is\nimperative. For example, a company deploying a client-facing chatbot must\nensure that the model will not respond to client requests with profanity.\nCurrent evaluations approach this problem using small, domain-specific datasets\nwith human-curated labels. These evaluation sets are often sampled from a\nnarrow and simplified distribution, and data sources can unknowingly be leaked\ninto the training set which can lead to misleading evaluations. To bypass these\ndrawbacks, we propose a framework for self-supervised evaluation of LLMs by\nanalyzing their sensitivity or invariance to transformations on the input text.\nSelf-supervised evaluation can directly monitor LLM behavior on datasets\ncollected in the wild or streamed during live model deployment. We demonstrate\nself-supervised evaluation strategies for measuring closed-book knowledge,\ntoxicity, and long-range context dependence, in addition to sensitivity to\ngrammatical structure and tokenization errors. When comparisons to similar\nhuman-labeled benchmarks are available, we find strong correlations between\nself-supervised and human-supervised evaluations. The self-supervised paradigm\ncomplements current evaluation strategies that rely on labeled data.",
        "translated": "随着大型语言模型(LLM)的兴起以及它们在不同领域的广泛应用，测量语言模型在实际数据上的行为变得势在必行。例如，部署面向客户机的聊天机器人的公司必须确保该模型不会以脏话回应客户机请求。目前的评估方法这个问题使用小，领域特定的数据集与人类管理的标签。这些评价集通常是从狭窄和简化的分布中取样的，数据源可能在不知情的情况下泄漏到培训集中，从而导致误导性评价。为了克服这些缺点，我们通过分析 LLM 对输入文本变换的敏感性或不变性，提出了一种 LLM 的自监督评估框架。自监督评估可以直接监视野外收集的数据集或实时模型部署期间的流数据集上的 LLM 行为。除了对语法结构和标记错误的敏感性外，我们还展示了自我监督的评估策略，用于测量闭卷知识、毒性和长期上下文依赖性。当与类似的人类标记基准进行比较时，我们发现自我监督评价和人类监督评价之间存在很强的相关性。自我监督范式补充了当前依赖于标记数据的评估策略。"
    },
    {
        "title": "GKD: Generalized Knowledge Distillation for Auto-regressive Sequence\n  Models",
        "url": "http://arxiv.org/abs/2306.13649v1",
        "pub_date": "2023-06-23",
        "summary": "Knowledge distillation is commonly used for compressing neural networks to\nreduce their inference cost and memory footprint. However, current distillation\nmethods for auto-regressive models, such as generative language models (LMs),\nsuffer from two key issues: (1) distribution mismatch between output sequences\nduring training and the sequences generated by the student during its\ndeployment, and (2) model under-specification, where the student model may not\nbe expressive enough to fit the teacher's distribution. To address these\nissues, we propose Generalized Knowledge Distillation (GKD). GKD mitigates\ndistribution mismatch by sampling output sequences from the student during\ntraining. Furthermore, GKD handles model under-specification by optimizing\nalternative divergences, such as reverse KL, that focus on generating samples\nfrom the student that are likely under the teacher's distribution. We\ndemonstrate that GKD outperforms commonly-used approaches for distilling LLMs\non summarization, machine translation, and arithmetic reasoning tasks.",
        "translated": "知识提取通常用于压缩神经网络，以减少其推理成本和内存占用。然而，目前自回归模型的精馏方法，如生成语言模型(LM) ，存在两个关键问题: (1)训练过程中输出序列与学生在部署过程中生成的序列之间的分布不匹配; (2)模型规范不足，学生模型的表达能力可能不足以适应教师的分布。为了解决这些问题，我们提出了广义知识提取(GKD)。GKD 通过在培训期间对学生的输出序列进行采样来减少分布不匹配。此外，GKD 通过优化替代性差异(如逆向 KL)来处理模型欠规范问题，这些差异侧重于从可能处于教师分布之下的学生生成样本。我们证明了 GKD 在摘要、机器翻译和算术推理任务中优于常用的 LLM 提取方法。"
    },
    {
        "title": "Margin Maximization in Attention Mechanism",
        "url": "http://arxiv.org/abs/2306.13596v1",
        "pub_date": "2023-06-23",
        "summary": "Attention mechanism is a central component of the transformer architecture\nwhich led to the phenomenal success of large language models. However, the\ntheoretical principles underlying the attention mechanism are poorly\nunderstood, especially its nonconvex optimization dynamics. In this work, we\nexplore the seminal softmax-attention model $f(\\boldsymbol{X})=\\langle\n\\boldsymbol{Xv}, \\texttt{softmax}(\\boldsymbol{XWp})\\rangle$, where,\n$\\boldsymbol{X}$ is the token sequence and\n$(\\boldsymbol{v},\\boldsymbol{W},\\boldsymbol{p})$ are tunable parameters. We\nprove that running gradient descent on $\\boldsymbol{p}$, or equivalently\n$\\boldsymbol{W}$, converges in direction to a max-margin solution that\nseparates $\\textit{locally-optimal}$ tokens from non-optimal ones. This clearly\nformalizes attention as a token separation mechanism. Remarkably, our results\nare applicable to general data and precisely characterize $\\textit{optimality}$\nof tokens in terms of the value embeddings $\\boldsymbol{Xv}$ and problem\ngeometry. We also provide a broader regularization path analysis that\nestablishes the margin maximizing nature of attention even for nonlinear\nprediction heads. When optimizing $\\boldsymbol{v}$ and $\\boldsymbol{p}$\nsimultaneously with logistic loss, we identify conditions under which the\nregularization paths directionally converge to their respective hard-margin SVM\nsolutions where $\\boldsymbol{v}$ separates the input features based on their\nlabels. Interestingly, the SVM formulation of $\\boldsymbol{p}$ is influenced by\nthe support vector geometry of $\\boldsymbol{v}$. Finally, we verify our\ntheoretical findings via numerical experiments and provide insights.",
        "translated": "注意机制是变压器体系结构的核心组成部分，它导致了大型语言模型的显著成功。然而，注意机制的理论基础知之甚少，尤其是其非凸优化动力学。本文探讨了开创性的软最大注意模型 $f (粗体{ X }) = 长体粗体{ Xv } ，texttt { softmax }(粗体{ XWp }) range $，其中 $粗体{ X } $是标记序列，$(粗体{ W } ，粗体{ p }) $是可调参数。我们证明了运行在 $粗体符号{ p } $或等价的 $粗体符号{ W } $上的梯度下降法收敛于一个最大边界解，该解将 $textit {局部最优} $标记与非最优标记区分开来。这清楚地将注意力形式化为一种标记分离机制。值得注意的是，我们的结果适用于一般数据，并且精确地刻画了标记的 $textit { Optimality } $值嵌入 $粗体符号{ Xv } $和问题几何。我们还提供了一个更广泛的正则化路径分析，即使对于非线性预测头来说，也建立了注意力余量最大化的性质。在对符号{ v } $和符号{ p } $同时进行逻辑损失优化时，我们确定了正则化路径在哪些条件下定向收敛到它们各自的硬边值 SVM 解，其中符号{ v } $根据标签分离输入特征。有趣的是，$粗体符号{ p } $的 SVM 公式受到 $粗体符号{ v } $的支持向量几何形状的影响。最后，通过数值实验验证我们的理论发现，并提供见解。"
    },
    {
        "title": "System-Level Natural Language Feedback",
        "url": "http://arxiv.org/abs/2306.13588v1",
        "pub_date": "2023-06-23",
        "summary": "Natural language (NL) feedback contains rich information about the user\nexperience. Existing studies focus on an instance-level approach, where\nfeedback is used to refine specific examples, disregarding its system-wide\napplication. This paper proposes a general framework for unlocking the\nsystem-level use of NL feedback. We show how to use feedback to formalize\nsystem-level design decisions in a human-in-the-loop-process -- in order to\nproduce better models. In particular this is done through: (i) metric design\nfor tasks; and (ii) language model prompt design for refining model responses.\nWe conduct two case studies of this approach for improving search query\ngeneration and dialog response generation, demonstrating the effectiveness of\nthe use of system-level feedback. We show the combination of system-level\nfeedback and instance-level feedback brings further gains, and that human\nwritten instance-level feedback results in more grounded refinements than\nGPT-3.5 written ones, underlying the importance of human feedback for building\nsystems.",
        "translated": "自然语言(NL)反馈包含了丰富的用户体验信息。现有的研究集中在实例级方法上，在这种方法中，反馈被用来精炼具体的例子，而忽略了它在系统范围内的应用。本文提出了一个解锁系统级使用自然语言反馈的一般框架。我们展示了如何使用反馈在人在循环的过程中形式化系统级设计决策——以便产生更好的模型。具体来说，这是通过: (i)任务的度量设计; 和(ii)精炼模型响应的语言模型提示设计。我们对该方法进行了两个改进搜索查询生成和对话框响应生成的案例研究，证明了使用系统级反馈的有效性。我们展示了系统级反馈和实例级反馈的结合带来了进一步的收益，而且人工编写的实例级反馈比 GPT-3.5编写的反馈带来了更多的基础细化，这是人工反馈对构建系统的重要性的基础。"
    },
    {
        "title": "A Survey on Multimodal Large Language Models",
        "url": "http://arxiv.org/abs/2306.13549v1",
        "pub_date": "2023-06-23",
        "summary": "Multimodal Large Language Model (MLLM) recently has been a new rising\nresearch hotspot, which uses powerful Large Language Models (LLMs) as a brain\nto perform multimodal tasks. The surprising emergent capabilities of MLLM, such\nas writing stories based on images and OCR-free math reasoning, are rare in\ntraditional methods, suggesting a potential path to artificial general\nintelligence. In this paper, we aim to trace and summarize the recent progress\nof MLLM. First of all, we present the formulation of MLLM and delineate its\nrelated concepts. Then, we discuss the key techniques and applications,\nincluding Multimodal Instruction Tuning (M-IT), Multimodal In-Context Learning\n(M-ICL), Multimodal Chain of Thought (M-CoT), and LLM-Aided Visual Reasoning\n(LAVR). Finally, we discuss existing challenges and point out promising\nresearch directions. In light of the fact that the era of MLLM has only just\nbegun, we will keep updating this survey and hope it can inspire more research.\nAn associated GitHub link collecting the latest papers is available at\nhttps://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models.",
        "translated": "多模态大语言模型(MLLM)是近年来兴起的一个新的研究热点，它利用强大的大语言模型(LLM)作为大脑来执行多模态任务。MLLM 令人惊讶的突发性能力，如基于图像和无 OCR 的数学推理写作故事，在传统方法中是罕见的，这表明了一条通向人工通用智能的潜在道路。本文旨在追踪和总结 MLLM 的最新进展。首先，我们提出了 MLLM 的概念，并描述了它的相关概念。然后，我们讨论了多模态教学调优(M-IT)、多模态上下文学习(M-ICL)、多模态思维链(M-CoT)和 LLM 辅助视觉推理(LAVR)等关键技术和应用。最后，我们讨论了目前存在的挑战，并指出了有前途的研究方向。鉴于 MLLM 的时代才刚刚开始，我们将不断更新这一调查，希望能够激发更多的研究。收集最新论文的相关 GitHub 链接可在 https://GitHub.com/bradyfu/awesome-multimodal-large-language-models 获得。"
    },
    {
        "title": "Knowledge-Infused Self Attention Transformers",
        "url": "http://arxiv.org/abs/2306.13501v1",
        "pub_date": "2023-06-23",
        "summary": "Transformer-based language models have achieved impressive success in various\nnatural language processing tasks due to their ability to capture complex\ndependencies and contextual information using self-attention mechanisms.\nHowever, they are not without limitations. These limitations include\nhallucinations, where they produce incorrect outputs with high confidence, and\nalignment issues, where they generate unhelpful and unsafe outputs for human\nusers. These limitations stem from the absence of implicit and missing context\nin the data alone. To address this, researchers have explored augmenting these\nmodels with external knowledge from knowledge graphs to provide the necessary\nadditional context. However, the ad-hoc nature of existing methods makes it\ndifficult to properly analyze the effects of knowledge infusion on the many\nmoving parts or components of a transformer. This paper introduces a systematic\nmethod for infusing knowledge into different components of a transformer-based\nmodel. A modular framework is proposed to identify specific components within\nthe transformer architecture, such as the self-attention mechanism, encoder\nlayers, or the input embedding layer, where knowledge infusion can be applied.\nAdditionally, extensive experiments are conducted on the General Language\nUnderstanding Evaluation (GLUE) benchmark tasks, and the findings are reported.\nThis systematic approach aims to facilitate more principled approaches to\nincorporating knowledge into language model architectures.",
        "translated": "基于转换器的语言模型在各种自然语言处理任务中取得了令人印象深刻的成功，因为它们能够利用自我注意机制捕获复杂的依赖关系和上下文信息。然而，它们并非没有限制。这些限制包括幻觉，它们产生高度可信的错误输出，以及校准问题，它们为人类用户产生无益和不安全的输出。这些限制源于数据本身缺乏隐式的和缺失的上下文。为了解决这个问题，研究人员已经探索用来自知识图表的外部知识来增强这些模型，以提供必要的额外背景。然而，现有方法的特殊性使得很难正确分析知识输入对变压器的许多运动部件的影响。本文介绍了一种将知识注入到基于变压器的模型的不同组件中的系统方法。提出了一个模块化框架来识别变压器体系结构中的特定组件，如自注意机制、编码器层或输入嵌入层，其中可以应用知识注入。此外，本研究还对通用语言理解评估(GLUE)基准任务进行了广泛的实验研究，并对实验结果进行了报道。这种系统方法旨在促进将知识纳入语言模型体系结构的更有原则的方法。"
    },
    {
        "title": "Incorporating Graph Information in Transformer-based AMR Parsing",
        "url": "http://arxiv.org/abs/2306.13467v1",
        "pub_date": "2023-06-23",
        "summary": "Abstract Meaning Representation (AMR) is a Semantic Parsing formalism that\naims at providing a semantic graph abstraction representing a given text.\nCurrent approaches are based on autoregressive language models such as BART or\nT5, fine-tuned through Teacher Forcing to obtain a linearized version of the\nAMR graph from a sentence. In this paper, we present LeakDistill, a model and\nmethod that explores a modification to the Transformer architecture, using\nstructural adapters to explicitly incorporate graph information into the\nlearned representations and improve AMR parsing performance. Our experiments\nshow how, by employing word-to-node alignment to embed graph structural\ninformation into the encoder at training time, we can obtain state-of-the-art\nAMR parsing through self-knowledge distillation, even without the use of\nadditional data. We release the code at\n\\url{http://www.github.com/sapienzanlp/LeakDistill}.",
        "translated": "抽象意义表示(AMR)是一种语义分析形式主义，旨在提供表示给定文本的语义图抽象。目前的方法是基于自回归语言模型，如 BART 或 T5，通过教师强制微调，以获得一个句子的 AMR 图的线性化版本。在本文中，我们提出了 LeakDistill 模型和方法，该模型和方法探索了如何修改 Transformer 体系结构，使用结构适配器将图信息显式地合并到所学习的表示中，并提高 AMR 解析性能。实验结果表明，在训练时通过字节对齐将图结构信息嵌入到编码器中，即使不需要额外的数据，也可以通过自知识提取获得最新的 AMR 解析结果。我们在 url { http://www.github.com/sapienzanlp/leakdistill }发布代码。"
    },
    {
        "title": "Learning Descriptive Image Captioning via Semipermeable Maximum\n  Likelihood Estimation",
        "url": "http://arxiv.org/abs/2306.13460v1",
        "pub_date": "2023-06-23",
        "summary": "Image captioning aims to describe visual content in natural language. As 'a\npicture is worth a thousand words', there could be various correct descriptions\nfor an image. However, with maximum likelihood estimation as the training\nobjective, the captioning model is penalized whenever its prediction mismatches\nwith the label. For instance, when the model predicts a word expressing richer\nsemantics than the label, it will be penalized and optimized to prefer more\nconcise expressions, referred to as conciseness optimization. In contrast,\npredictions that are more concise than labels lead to richness optimization.\nSuch conflicting optimization directions could eventually result in the model\ngenerating general descriptions. In this work, we introduce Semipermeable\nMaxImum Likelihood Estimation (SMILE), which allows richness optimization while\nblocking conciseness optimization, thus encouraging the model to generate\nlonger captions with more details. Extensive experiments on two mainstream\nimage captioning datasets MSCOCO and Flickr30K demonstrate that SMILE\nsignificantly enhances the descriptiveness of generated captions. We further\nprovide in-depth investigations to facilitate a better understanding of how\nSMILE works.",
        "translated": "图像字幕的目的是用自然语言描述视觉内容。正如“一张图片胜过千言万语”一样，对于一张图片可以有各种各样正确的描述。然而，以最大似然估计为训练目标，当字幕模型的预测与标签不匹配时，字幕模型就会受到惩罚。例如，当模型预测一个表达比标签更丰富的语义的单词时，它将受到惩罚并优化以选择更简洁的表达式，称为简洁性优化。相反，比标签更简洁的预测会导致丰富性优化。这种冲突的优化方向可能最终导致模型产生一般的描述。在本文中，我们引入了半可渗透最大似然估计(SMILE) ，它允许在阻塞简洁性优化的同时进行丰富性优化，从而鼓励模型生成具有更多细节的更长的标题。在两个主流图像字幕数据集 MSCOCO 和 Flickr30K 上的大量实验表明，SMILE 显著提高了生成的字幕的描述性。我们进一步提供深入的调查，以便更好地了解 SMILE 如何工作。"
    },
    {
        "title": "Long-range Language Modeling with Self-retrieval",
        "url": "http://arxiv.org/abs/2306.13421v1",
        "pub_date": "2023-06-23",
        "summary": "Retrieval-augmented language models (LMs) have received much attention\nrecently. However, typically the retriever is not trained jointly as a native\ncomponent of the LM, but added to an already-pretrained LM, which limits the\nability of the LM and the retriever to adapt to one another. In this work, we\npropose the Retrieval-Pretrained Transformer (RPT), an architecture and\ntraining procedure for jointly training a retrieval-augmented LM from scratch\nfor the task of modeling long texts. Given a recently generated text chunk in a\nlong document, the LM computes query representations, which are then used to\nretrieve earlier chunks in the document, located potentially tens of thousands\nof tokens before. Information from retrieved chunks is fused into the LM\nrepresentations to predict the next target chunk. We train the retriever\ncomponent with a semantic objective, where the goal is to retrieve chunks that\nincrease the probability of the next chunk, according to a reference LM. We\nevaluate RPT on four long-range language modeling tasks, spanning books, code,\nand mathematical writing, and demonstrate that RPT improves retrieval quality\nand subsequently perplexity across the board compared to strong baselines.",
        "translated": "检索增强语言模型(LM)近年来受到了广泛的关注。然而，检索器通常不会作为 LM 的本机组件共同训练，而是添加到已经预先训练好的 LM 中，这限制了 LM 和检索器相互适应的能力。在这项工作中，我们提出了检索-预训练变压器(RPT) ，一个体系结构和训练过程，联合训练一个检索-增强 LM 从头开始建模长文本的任务。给定一个长文档中最近生成的文本块，LM 计算查询表示，然后使用这些查询表示来检索文档中可能存在数万个标记的早期块。来自检索块的信息被融合到 LM 表示中，以预测下一个目标块。我们使用语义目标训练检索器组件，其目标是根据引用 LM 检索增加下一个块的概率的块。我们评估了 RPT 在四个远程语言建模任务(跨书籍、代码和数学写作)上的表现，并证明与强基线相比，RPT 提高了检索质量并随后全面提高了困惑度。"
    },
    {
        "title": "Stress Testing BERT Anaphora Resolution Models for Reaction Extraction\n  in Chemical Patents",
        "url": "http://arxiv.org/abs/2306.13379v1",
        "pub_date": "2023-06-23",
        "summary": "The high volume of published chemical patents and the importance of a timely\nacquisition of their information gives rise to automating information\nextraction from chemical patents. Anaphora resolution is an important component\nof comprehensive information extraction, and is critical for extracting\nreactions. In chemical patents, there are five anaphoric relations of interest:\nco-reference, transformed, reaction associated, work up, and contained. Our\ngoal is to investigate how the performance of anaphora resolution models for\nreaction texts in chemical patents differs in a noise-free and noisy\nenvironment and to what extent we can improve the robustness against noise of\nthe model.",
        "translated": "由于已发表的化学专利数量庞大，加上及时取得这些专利的资料十分重要，因此化学专利的信息抽取便会自动化。回指消解是综合信息抽取的重要组成部分，对提取反应至关重要。在化学专利中，有五种兴趣回指关系: 共指关系、转换关系、反应关系、升级关系和包含关系。我们的目标是研究化学专利中反应文本的回指消解模型在无噪声和噪声环境中的性能差异，以及在多大程度上我们可以提高模型对噪声的鲁棒性。"
    },
    {
        "title": "Scalable Neural Contextual Bandit for Recommender Systems",
        "url": "http://arxiv.org/abs/2306.14834v1",
        "pub_date": "2023-06-26",
        "summary": "High-quality recommender systems ought to deliver both innovative and\nrelevant content through effective and exploratory interactions with users.\nYet, supervised learning-based neural networks, which form the backbone of many\nexisting recommender systems, only leverage recognized user interests, falling\nshort when it comes to efficiently uncovering unknown user preferences. While\nthere has been some progress with neural contextual bandit algorithms towards\nenabling online exploration through neural networks, their onerous\ncomputational demands hinder widespread adoption in real-world recommender\nsystems. In this work, we propose a scalable sample-efficient neural contextual\nbandit algorithm for recommender systems. To do this, we design an epistemic\nneural network architecture, Epistemic Neural Recommendation (ENR), that\nenables Thompson sampling at a large scale. In two distinct large-scale\nexperiments with real-world tasks, ENR significantly boosts click-through rates\nand user ratings by at least 9% and 6% respectively compared to\nstate-of-the-art neural contextual bandit algorithms. Furthermore, it achieves\nequivalent performance with at least 29% fewer user interactions compared to\nthe best-performing baseline algorithm. Remarkably, while accomplishing these\nimprovements, ENR demands orders of magnitude fewer computational resources\nthan neural contextual bandit baseline algorithms.",
        "translated": "高质量的推荐系统应该通过与用户有效和探索性的互动交付创新和相关的内容。然而，作为许多现有推荐系统骨干的基于监督学习的神经网络，只能利用已识别的用户兴趣，在有效发现未知用户偏好方面存在不足。虽然神经上下文强盗算法在通过神经网络实现在线探索方面取得了一些进展，但是它们繁重的计算需求阻碍了在现实世界中推荐系统的广泛采用。在这项工作中，我们提出了一个可扩展的样本效率神经上下文盗贼算法的推荐系统。为了做到这一点，我们设计了一个认知神经网络结构，认知神经推荐(ENR) ，使汤普森采样在大规模。在两个不同的大规模实验与现实世界的任务，ENR 显着提高点击率和用户评分至少9% 和6% 分别相比，国家的最先进的神经上下文土匪算法。此外，与性能最好的基线算法相比，它至少减少了29% 的用户交互，从而实现了相同的性能。值得注意的是，在完成这些改进的同时，ENR 所需的计算资源数量级比神经上下文强盗基线算法要少。"
    },
    {
        "title": "Reciprocal Sequential Recommendation",
        "url": "http://arxiv.org/abs/2306.14712v1",
        "pub_date": "2023-06-26",
        "summary": "Reciprocal recommender system (RRS), considering a two-way matching between\ntwo parties, has been widely applied in online platforms like online dating and\nrecruitment. Existing RRS models mainly capture static user preferences, which\nhave neglected the evolving user tastes and the dynamic matching relation\nbetween the two parties. Although dynamic user modeling has been well-studied\nin sequential recommender systems, existing solutions are developed in a\nuser-oriented manner. Therefore, it is non-trivial to adapt sequential\nrecommendation algorithms to reciprocal recommendation. In this paper, we\nformulate RRS as a distinctive sequence matching task, and further propose a\nnew approach ReSeq for RRS, which is short for Reciprocal Sequential\nrecommendation. To capture dual-perspective matching, we propose to learn\nfine-grained sequence similarities by co-attention mechanism across different\ntime steps. Further, to improve the inference efficiency, we introduce the\nself-distillation technique to distill knowledge from the fine-grained matching\nmodule into the more efficient student module. In the deployment stage, only\nthe efficient student module is used, greatly speeding up the similarity\ncomputation. Extensive experiments on five real-world datasets from two\nscenarios demonstrate the effectiveness and efficiency of the proposed method.\nOur code is available at https://github.com/RUCAIBox/ReSeq/.",
        "translated": "考虑双方双向匹配的互惠推荐系统已经广泛应用于在线约会和招聘等在线平台。现有的 RRS 模型主要捕捉静态用户偏好，忽略了用户偏好的演变和双方的动态匹配关系。尽管动态用户建模已经在顺序推荐系统中得到了很好的研究，但是现有的解决方案都是以面向用户的方式开发的。因此，将顺序推荐算法应用到互惠推荐中具有重要意义。本文将 RRS 作为一个独特的序列匹配任务，并进一步提出了一种新的 RRS 方法 ReSeq，即相互序列推荐的简称。为了捕获双视角匹配，我们提出了通过跨不同时间步长的共注意机制来学习细粒度序列相似性。进一步，为了提高推理效率，我们引入了自蒸馏技术，从细粒度匹配模块中提取知识到更高效的学生模块中。在部署阶段，只使用了有效的学生模块，大大加快了相似度计算的速度。通过对来自两个场景的五个真实世界数据集的大量实验，证明了该方法的有效性和高效性。我们的代码可以在 https://github.com/rucaibox/reseq/找到。"
    },
    {
        "title": "PTVD: A Large-Scale Plot-Oriented Multimodal Dataset Based on Television\n  Dramas",
        "url": "http://arxiv.org/abs/2306.14644v1",
        "pub_date": "2023-06-26",
        "summary": "Art forms such as movies and television (TV) dramas are reflections of the\nreal world, which have attracted much attention from the multimodal learning\ncommunity recently. However, existing corpora in this domain share three\nlimitations: (1) annotated in a scene-oriented fashion, they ignore the\ncoherence within plots; (2) their text lacks empathy and seldom mentions\nsituational context; (3) their video clips fail to cover long-form relationship\ndue to short duration. To address these fundamental issues, using 1,106 TV\ndrama episodes and 24,875 informative plot-focused sentences written by\nprofessionals, with the help of 449 human annotators, we constructed PTVD, the\nfirst plot-oriented multimodal dataset in the TV domain. It is also the first\nnon-English dataset of its kind. Additionally, PTVD contains more than 26\nmillion bullet screen comments (BSCs), powering large-scale pre-training. Next,\naiming to open-source a strong baseline for follow-up works, we developed the\nmultimodal algorithm that attacks different cinema/TV modelling problems with a\nunified architecture. Extensive experiments on three cognitive-inspired tasks\nyielded a number of novel observations (some of them being quite\ncounter-intuition), further validating the value of PTVD in promoting\nmultimodal research. The dataset and codes are released at\n\\url{https://ptvd.github.io/}.",
        "translated": "电影、电视剧等艺术形式是现实世界的反映，近年来引起了多模式学习社会的广泛关注。然而，该领域现有的语料库存在三个局限性: (1)以场景为导向的方式进行注释，忽视了情节的连贯性; (2)文本缺乏移情作用，很少提及情景语境; (3)视频片段由于篇幅短而无法涵盖长篇关系。为了解决这些基本问题，我们在449名人类注释者的帮助下，使用1,106个电视剧集和24,875个由专业人员撰写的信息丰富的情节集中的句子，构建了电视领域中第一个面向情节的多模式数据集 PTVD。它也是第一个非英语数据集的类型。此外，PTVD 包含超过2600万条弹幕评论(BSC) ，为大规模的预训提供动力。接下来，为了给后续工作提供一个强有力的开源基准，我们开发了多模态算法，用一个统一的体系结构来解决不同的影院/电视建模问题。对三个认知启发任务的广泛实验产生了许多新的观察结果(其中一些相当反直觉) ，进一步验证了 PTVD 在促进多模态研究中的价值。数据集和代码在 url { https://ptvd.github.io/}发布。"
    },
    {
        "title": "Multi-task Item-attribute Graph Pre-training for Strict Cold-start Item\n  Recommendation",
        "url": "http://arxiv.org/abs/2306.14462v1",
        "pub_date": "2023-06-26",
        "summary": "Recommendation systems suffer in the strict cold-start (SCS) scenario, where\nthe user-item interactions are entirely unavailable. The ID-based approaches\ncompletely fail to work. Cold-start recommenders, on the other hand, leverage\nitem contents to map the new items to the existing ones. However, the existing\nSCS recommenders explore item contents in coarse-grained manners that introduce\nnoise or information loss. Moreover, informative data sources other than item\ncontents, such as users' purchase sequences and review texts, are ignored. We\nexplore the role of the fine-grained item attributes in bridging the gaps\nbetween the existing and the SCS items and pre-train a knowledgeable\nitem-attribute graph for SCS item recommendation. Our proposed framework,\nColdGPT, models item-attribute correlations into an item-attribute graph by\nextracting fine-grained attributes from item contents. ColdGPT then transfers\nknowledge into the item-attribute graph from various available data sources,\ni.e., item contents, historical purchase sequences, and review texts of the\nexisting items, via multi-task learning. To facilitate the positive transfer,\nColdGPT designs submodules according to the natural forms of the data sources\nand coordinates the multiple pre-training tasks via unified\nalignment-and-uniformity losses. Our pre-trained item-attribute graph acts as\nan implicit, extendable item embedding matrix, which enables the SCS item\nembeddings to be easily acquired by inserting these items and propagating their\nattributes' embeddings. We carefully process three public datasets, i.e., Yelp,\nAmazon-home, and Amazon-sports, to guarantee the SCS setting for evaluation.\nExtensive experiments show that ColdGPT consistently outperforms the existing\nSCS recommenders by large margins and even surpasses models that are\npre-trained on 75-224 times more, cross-domain data on two out of four\ndatasets.",
        "translated": "推荐系统在严格的冷启动(SCS)场景中受到影响，其中用户-项交互是完全不可用的。基于 ID 的方法完全不起作用。另一方面，冷启动推荐器利用项目内容将新项目映射到现有项目。然而，现有的 SCS 推荐标准以粗粒度的方式探索项目内容，导致噪声或信息丢失。此外，项目内容以外的信息性数据源，如用户的购买顺序和评论文本，被忽略。本文探讨了细粒度项目属性在弥补现有项目与 SCS 项目之间差距方面的作用，并为 SCS 项目推荐预训练了一个知识型项目属性图。我们提出的框架 ColdGPT 通过从项目内容中提取细粒度属性，将项目-属性关系建模成项目-属性图。ColdGPT 然后通过多任务学习，将来自各种可用数据源的知识转移到项目属性图中，即项目内容、历史购买顺序和审查现有项目的文本。为了便于正向传输，ColdGPT 根据数据源的自然形式设计子模块，并通过统一的对齐和一致性损失协调多个预训练任务。我们的预训练项目属性图作为一个隐式的、可扩展的项目嵌入矩阵，通过插入这些项目并传播它们的属性嵌入，可以方便地获得 SCS 项目嵌入。我们仔细处理三个公共数据集，即 Yelp、 Amazon-home 和 Amazon-sports，以保证 SCS 设置用于评估。大量的实验表明，ColdGPT 始终优于现有的 SCS 推荐器，甚至超过预先训练75-224倍以上的模型，跨域数据在四个数据集中的两个。"
    },
    {
        "title": "Contrastive Multi-view Framework for Customer Lifetime Value Prediction",
        "url": "http://arxiv.org/abs/2306.14400v1",
        "pub_date": "2023-06-26",
        "summary": "Accurate customer lifetime value (LTV) prediction can help service providers\noptimize their marketing policies in customer-centric applications. However,\nthe heavy sparsity of consumption events and the interference of data variance\nand noise obstruct LTV estimation. Many existing LTV prediction methods\ndirectly train a single-view LTV predictor on consumption samples, which may\nyield inaccurate and even biased knowledge extraction. In this paper, we\npropose a contrastive multi-view framework for LTV prediction, which is a\nplug-and-play solution compatible with various backbone models. It synthesizes\nmultiple heterogeneous LTV regressors with complementary knowledge to improve\nmodel robustness and captures sample relatedness via contrastive learning to\nmitigate the dependency on data abundance. Concretely, we use a decomposed\nscheme that converts the LTV prediction problem into a combination of\nestimating consumption probability and payment amount. To alleviate the impact\nof noisy data on model learning, we propose a multi-view framework that jointly\noptimizes multiple types of regressors with diverse characteristics and\nadvantages to encode and fuse comprehensive knowledge. To fully exploit the\npotential of limited training samples, we propose a hybrid contrastive learning\nmethod to help capture the relatedness between samples in both classification\nand regression tasks. We conduct extensive experiments on a real-world game LTV\nprediction dataset and the results validate the effectiveness of our method. We\nhave deployed our solution online in Huawei's mobile game center and achieved\n32.26% of total payment amount gains.",
        "translated": "准确的客户生命周期价值(LTV)预测可以帮助服务提供商在以客户为中心的应用程序中优化其营销策略。然而，消耗事件的严重稀疏性以及数据方差和噪声的干扰阻碍了 LTV 估计。许多现有的 LTV 预测方法直接在消费样本上训练单视图 LTV 预测器，这可能会产生不准确甚至有偏差的知识提取。在本文中，我们提出了一个对比的多视图 LTV 预测框架，这是一个即插即用的解决方案，兼容各种骨干模型。它综合了多个具有互补知识的异构 LTV 回归子，提高了模型的鲁棒性，并通过对比学习获取样本相关性，减轻了对数据丰度的依赖性。具体地，我们使用了一个分解方案，将 LTV 预测问题转化为估计消费概率和支付金额的组合。为了减轻噪声数据对模型学习的影响，本文提出了一种多视图框架，该框架联合优化具有不同特征和优势的多类回归模型，对综合知识进行编码和融合。为了充分发挥有限训练样本的潜力，我们提出了一种混合对比学习方法，以帮助捕捉样本之间的相关性分类和回归任务。我们在一个真实的游戏 LTV 预测数据集上进行了广泛的实验，实验结果验证了我们方法的有效性。我们已经在华为的手机游戏中心部署了我们的在线解决方案，实现了总支付金额收益的32.26% 。"
    },
    {
        "title": "FunQA: Towards Surprising Video Comprehension",
        "url": "http://arxiv.org/abs/2306.14899v1",
        "pub_date": "2023-06-26",
        "summary": "Surprising videos, e.g., funny clips, creative performances, or visual\nillusions, attract significant attention. Enjoyment of these videos is not\nsimply a response to visual stimuli; rather, it hinges on the human capacity to\nunderstand (and appreciate) commonsense violations depicted in these videos. We\nintroduce FunQA, a challenging video question answering (QA) dataset\nspecifically designed to evaluate and enhance the depth of video reasoning\nbased on counter-intuitive and fun videos. Unlike most video QA benchmarks\nwhich focus on less surprising contexts, e.g., cooking or instructional videos,\nFunQA covers three previously unexplored types of surprising videos: 1)\nHumorQA, 2) CreativeQA, and 3) MagicQA. For each subset, we establish rigorous\nQA tasks designed to assess the model's capability in counter-intuitive\ntimestamp localization, detailed video description, and reasoning around\ncounter-intuitiveness. We also pose higher-level tasks, such as attributing a\nfitting and vivid title to the video, and scoring the video creativity. In\ntotal, the FunQA benchmark consists of 312K free-text QA pairs derived from\n4.3K video clips, spanning a total of 24 video hours. Extensive experiments\nwith existing VideoQA models reveal significant performance gaps for the FunQA\nvideos across spatial-temporal reasoning, visual-centered reasoning, and\nfree-text generation.",
        "translated": "令人惊讶的视频，例如，有趣的片段，创造性的表演，或视觉幻觉，吸引了大量的注意力。欣赏这些视频不仅仅是对视觉刺激的反应，而是取决于人类理解(和欣赏)这些视频中描述的违反常识的行为的能力。我们介绍 FunQA，一个具有挑战性的视频问题回答(QA)数据集，专门设计来评估和增强基于反直观和有趣的视频的视频推理深度。与大多数视频 QA 基准不同，FunQA 基准侧重于不那么令人惊讶的背景，例如烹饪或教学视频，FunQA 涵盖了三种以前未探索过的令人惊讶的视频类型: 1) HumorQA，2) CreativeQA，和3) MagicQA。对于每个子集，我们建立严格的 QA 任务，旨在评估模型在反直觉时间戳定位、详细视频描述和反直觉推理方面的能力。我们还提出了更高层次的任务，比如为视频赋予一个合适的、生动的标题，以及对视频创造性进行评分。FunQA 基准测试总共由312K 自由文本 QA 对组成，这些 QA 对来自4.3 K 视频剪辑，跨越总共24个视频小时。对现有 VideoQA 模型的大量实验表明，FunQA 视频在时空推理、以视觉为中心的推理和自由文本生成方面存在显著的性能差距。"
    },
    {
        "title": "InterCode: Standardizing and Benchmarking Interactive Coding with\n  Execution Feedback",
        "url": "http://arxiv.org/abs/2306.14898v2",
        "pub_date": "2023-06-26",
        "summary": "Humans write code in a fundamentally interactive manner and rely on constant\nexecution feedback to correct errors, resolve ambiguities, and decompose tasks.\nWhile LLMs have recently exhibited promising coding capabilities, current\ncoding benchmarks mostly consider a static instruction-to-code sequence\ntransduction process, which has the potential for error propagation and a\ndisconnect between the generated code and its final execution environment. To\naddress this gap, we introduce InterCode, a lightweight, flexible, and\neasy-to-use framework of interactive coding as a standard reinforcement\nlearning (RL) environment, with code as actions and execution feedback as\nobservations. Our framework is language and platform agnostic, uses\nself-contained Docker environments to provide safe and reproducible execution,\nand is compatible out-of-the-box with traditional seq2seq coding methods, while\nenabling the development of new methods for interactive code generation. We use\nInterCode to create two interactive code environments with Bash and SQL as\naction spaces, leveraging data from the static Spider and NL2Bash datasets. We\ndemonstrate InterCode's viability as a testbed by evaluating multiple\nstate-of-the-art LLMs configured with different prompting strategies such as\nReAct and Plan &amp; Solve. Our results showcase the benefits of interactive code\ngeneration and demonstrate that InterCode can serve as a challenging benchmark\nfor advancing code understanding and generation capabilities. InterCode is\ndesigned to be easily extensible and can even be used to incorporate new tasks\nsuch as Capture the Flag, a popular coding puzzle that is inherently multi-step\nand involves multiple programming languages. Project site with code and data:\nhttps://intercode-benchmark.github.io",
        "translated": "人类以基本的交互方式编写代码，并依赖于不断的执行反馈来纠正错误、解决模糊性和分解任务。虽然 LLM 最近展示了很有前途的编码能力，但目前的编码基准主要考虑的是静态指令-代码序列转换过程，这种过程有可能导致错误传播，并使生成的代码与其最终执行环境脱节。为了解决这个问题，我们引入了 InterCode，这是一个轻量级的、灵活的、易于使用的交互式编码框架，作为一个标准的强化学习(RL)环境，代码作为操作，执行反馈作为观察。我们的框架与语言和平台无关，使用自包含的 Docker 环境来提供安全和可重复的执行，并且与传统的 seq2seq 编码方法开箱即用兼容，同时支持开发用于交互式代码生成的新方法。我们使用 InterCode 创建两个交互式代码环境，使用 Bash 和 SQL 作为操作空间，利用来自静态 Spider 和 NL2Bash 数据集的数据。我们通过评估配置了不同激励策略(如 ReAct 和 Plan & Solve)的多个最先进的 LLM，展示了 InterCode 作为测试平台的可行性。我们的结果展示了交互式代码生成的好处，并证明了 InterCode 可以作为一个具有挑战性的基准来提高代码理解和生成能力。InterCode 被设计成易于扩展，甚至可以用来合并新的任务，比如 Capture the Flag，这是一种流行的编码难题，本质上是多步骤的，涉及多种编程语言。项目网站的代码和数据:  https://intercode-benchmark.github.io"
    },
    {
        "title": "LongCoder: A Long-Range Pre-trained Language Model for Code Completion",
        "url": "http://arxiv.org/abs/2306.14893v1",
        "pub_date": "2023-06-26",
        "summary": "In this paper, we introduce a new task for code completion that focuses on\nhandling long code input and propose a sparse Transformer model, called\nLongCoder, to address this task. LongCoder employs a sliding window mechanism\nfor self-attention and introduces two types of globally accessible tokens -\nbridge tokens and memory tokens - to improve performance and efficiency. Bridge\ntokens are inserted throughout the input sequence to aggregate local\ninformation and facilitate global interaction, while memory tokens are included\nto highlight important statements that may be invoked later and need to be\nmemorized, such as package imports and definitions of classes, functions, or\nstructures. We conduct experiments on a newly constructed dataset that contains\nlonger code context and the publicly available CodeXGLUE benchmark.\nExperimental results demonstrate that LongCoder achieves superior performance\non code completion tasks compared to previous models while maintaining\ncomparable efficiency in terms of computational resources during inference. All\nthe codes and data are available at https://github.com/microsoft/CodeBERT.",
        "translated": "在本文中，我们介绍了一个新的代码完成任务，重点是处理长代码输入，并提出了一个稀疏变压器模型，所谓的 LongCoder，以解决这一问题。LongCoder 采用滑动窗口机制来自我关注，并引入了两种全局可访问令牌——桥接令牌和内存令牌——以提高性能和效率。在整个输入序列中插入桥标记，以聚合本地信息并促进全局交互，同时包含内存标记，以突出显示可能稍后调用并需要记忆的重要语句，例如包导入和类、函数或结构的定义。我们在一个新构建的数据集上进行实验，该数据集包含更长的代码上下文和公开可用的 CodeXGLUE 基准。实验结果表明，与以前的模型相比，LongCoder 在代码完成任务方面取得了更好的性能，同时在推理过程中保持了可比的计算资源效率。所有的代码和数据都在 https://github.com/microsoft/codebert。"
    },
    {
        "title": "Composing Parameter-Efficient Modules with Arithmetic Operations",
        "url": "http://arxiv.org/abs/2306.14870v1",
        "pub_date": "2023-06-26",
        "summary": "As an efficient alternative to conventional full finetuning,\nparameter-efficient finetuning (PEFT) is becoming the prevailing method to\nadapt pretrained language models. In PEFT, a lightweight module is learned on\neach dataset while the underlying pretrained language model remains unchanged,\nresulting in multiple compact modules representing diverse skills when applied\nto various domains and tasks. In this paper, we propose to compose these\nparameter-efficient modules through linear arithmetic operations in the weight\nspace, thereby integrating different module capabilities. Specifically, we\nfirst define addition and negation operators for the module, and then further\ncompose these two basic operators to perform flexible arithmetic. Our approach\nrequires \\emph{no additional training} and enables highly flexible module\ncomposition. We apply different arithmetic operations to compose the\nparameter-efficient modules for (1) distribution generalization, (2)\nmulti-tasking, (3) unlearning, and (4) domain transfer. Additionally, we extend\nour approach to detoxify Alpaca-LoRA, the latest instruction-tuned large\nlanguage model based on LLaMA. Empirical results demonstrate that our approach\nproduces new and effective parameter-efficient modules that significantly\noutperform existing ones across all settings.",
        "translated": "参数有效微调(PEFT)作为传统全微调的一种有效替代方法，正在成为适应预训练语言模型的主流方法。在 PEFT 中，在每个数据集上学习一个轻量级模块，而底层的预训练语言模型保持不变，导致多个紧凑模块在应用于各种领域和任务时代表不同的技能。本文提出通过权值空间中的线性算术运算来组合这些参数有效的模块，从而集成不同的模块功能。具体地说，我们首先定义了模块的加法运算符和否定运算符，然后进一步组合这两个基本运算符来执行灵活的算术运算。我们的方法不需要额外的训练，并且支持高度灵活的模块组合。我们应用不同的算术运算来组成参数有效的模块: (1)分布泛化，(2)多任务，(3)去学习，和(4)域转移。此外，我们扩展了我们的方法来解毒羊驼-LoRA，最新的指令调优大型语言模型的基础上 LLaMA。实证结果表明，我们的方法产生了新的和有效的参数效率模块，在所有环境中都明显优于现有模块。"
    },
    {
        "title": "Enriching the NArabizi Treebank: A Multifaceted Approach to Supporting\n  an Under-Resourced Language",
        "url": "http://arxiv.org/abs/2306.14866v1",
        "pub_date": "2023-06-26",
        "summary": "In this paper we address the scarcity of annotated data for NArabizi, a\nRomanized form of North African Arabic used mostly on social media, which poses\nchallenges for Natural Language Processing (NLP). We introduce an enriched\nversion of NArabizi Treebank (Seddah et al., 2020) with three main\ncontributions: the addition of two novel annotation layers (named entity\nrecognition and offensive language detection) and a re-annotation of the\ntokenization, morpho-syntactic and syntactic layers that ensure annotation\nconsistency. Our experimental results, using different tokenization schemes,\nshowcase the value of our contributions and highlight the impact of working\nwith non-gold tokenization for NER and dependency parsing. To facilitate future\nresearch, we make these annotations publicly available. Our enhanced NArabizi\nTreebank paves the way for creating sophisticated language models and NLP tools\nfor this under-represented language.",
        "translated": "在本文中，我们解决了 NArabizi 注释数据的稀缺性，这是一种主要在社交媒体上使用的北非阿拉伯语的罗马化形式，给自然语言处理(NLP)带来了挑战。我们介绍了 NArabizi Treebank 的一个丰富版本(Seddah 等，2020) ，其中包含三个主要贡献: 添加两个新的注释层(命名实体识别和攻击性语言检测) ，以及重新注释标记化，形态句法和句法层，以确保注释一致性。我们的实验结果使用不同的标记化方案，展示了我们的贡献的价值，并强调了使用 NER 和依赖性解析的非黄金标记化的影响。为了方便未来的研究，我们将这些注释公开发布。我们增强的 NArabizi Treebank 为为这种代表性不足的语言创建复杂的语言模型和 NLP 工具铺平了道路。"
    },
    {
        "title": "HonestBait: Forward References for Attractive but Faithful Headline\n  Generation",
        "url": "http://arxiv.org/abs/2306.14828v1",
        "pub_date": "2023-06-26",
        "summary": "Current methods for generating attractive headlines often learn directly from\ndata, which bases attractiveness on the number of user clicks and views.\nAlthough clicks or views do reflect user interest, they can fail to reveal how\nmuch interest is raised by the writing style and how much is due to the event\nor topic itself. Also, such approaches can lead to harmful inventions by\nover-exaggerating the content, aggravating the spread of false information. In\nthis work, we propose HonestBait, a novel framework for solving these issues\nfrom another aspect: generating headlines using forward references (FRs), a\nwriting technique often used for clickbait. A self-verification process is\nincluded during training to avoid spurious inventions. We begin with a\npreliminary user study to understand how FRs affect user interest, after which\nwe present PANCO1, an innovative dataset containing pairs of fake news with\nverified news for attractive but faithful news headline generation. Automatic\nmetrics and human evaluations show that our framework yields more attractive\nresults (+11.25% compared to human-written verified news headlines) while\nmaintaining high veracity, which helps promote real information to fight\nagainst fake news.",
        "translated": "目前生成有吸引力的标题的方法通常直接从数据中学习，这种方法基于用户点击和浏览次数的吸引力。虽然点击或浏览确实反映了用户的兴趣，但它们可能无法揭示写作风格引起了多少兴趣，以及有多少是由于事件或主题本身引起的。此外，这种方法可能会导致有害的发明过分夸大的内容，加剧传播虚假信息。在这项工作中，我们提出了 HonestBait，一个从另一个方面解决这些问题的新框架: 使用前向引用(FRs)生成标题，这是一种常用于点击诱饵的写作技巧。培训期间包括自我验证过程，以避免虚假发明。我们从一个初步的用户研究开始，以了解 FRs 如何影响用户的兴趣，然后我们提出 PANCO1，一个创新的数据集，包含对虚假新闻与核实新闻吸引人，但忠实的新闻标题生成。自动测量和人工评估表明，我们的框架产生更有吸引力的结果(+ 11.25% 相比，人写验证新闻标题) ，同时保持高的准确性，这有助于促进真实信息打击假新闻。"
    },
    {
        "title": "Vietnamese multi-document summary using subgraph selection approach --\n  VLSP 2022 AbMuSu Shared Task",
        "url": "http://arxiv.org/abs/2306.14827v1",
        "pub_date": "2023-06-26",
        "summary": "Document summarization is a task to generate afluent, condensed summary for a\ndocument, andkeep important information. A cluster of documents serves as the\ninput for multi-document summarizing (MDS), while the cluster summary serves as\nthe output. In this paper, we focus on transforming the extractive MDS problem\ninto subgraph selection. Approaching the problem in the form of graphs helps to\ncapture simultaneously the relationship between sentences in the same document\nand between sentences in the same cluster based on exploiting the overall graph\nstructure and selected subgraphs. Experiments have been implemented on the\nVietnamese dataset published in VLSP Evaluation Campaign 2022. This model\ncurrently results in the top 10 participating teams reported on the ROUGH-2\n$F\\_1$ measure on the public test set.",
        "translated": "文档摘要是为文档生成丰富、简洁的摘要并保存重要信息的任务。文档集群作为多文档摘要(MDS)的输入，而集群摘要作为输出。本文主要研究如何将抽取 MDS 问题转化为子图选择问题。利用图的整体结构和选择的子图，以图的形式来处理问题，有助于同时捕捉同一文档中的句子之间的关系和同一簇中的句子之间的关系。在2022年 VLSP 评估运动中发布的越南数据集上进行了实验。这个模型目前的结果是公开测试集上 ROUGH-2 $F _ 1 $测量报告的前10个参与团队。"
    },
    {
        "title": "Kosmos-2: Grounding Multimodal Large Language Models to the World",
        "url": "http://arxiv.org/abs/2306.14824v2",
        "pub_date": "2023-06-26",
        "summary": "We introduce Kosmos-2, a Multimodal Large Language Model (MLLM), enabling new\ncapabilities of perceiving object descriptions (e.g., bounding boxes) and\ngrounding text to the visual world. Specifically, we represent refer\nexpressions as links in Markdown, i.e., ``[text span](bounding boxes)'', where\nobject descriptions are sequences of location tokens. Together with multimodal\ncorpora, we construct large-scale data of grounded image-text pairs (called\nGrIT) to train the model. In addition to the existing capabilities of MLLMs\n(e.g., perceiving general modalities, following instructions, and performing\nin-context learning), Kosmos-2 integrates the grounding capability into\ndownstream applications. We evaluate Kosmos-2 on a wide range of tasks,\nincluding (i) multimodal grounding, such as referring expression comprehension,\nand phrase grounding, (ii) multimodal referring, such as referring expression\ngeneration, (iii) perception-language tasks, and (iv) language understanding\nand generation. This work lays out the foundation for the development of\nEmbodiment AI and sheds light on the big convergence of language, multimodal\nperception, action, and world modeling, which is a key step toward artificial\ngeneral intelligence. Data, demo, and pretrained models are available at\nhttps://aka.ms/kosmos-2.",
        "translated": "我们引入了 Kosmos-2，一个多模态大型语言模型(MLLM) ，支持感知对象描述(例如，边界框)和将文本接地到视觉世界的新功能。具体来说，我们将引用表达式表示为 Markdown 中的链接，即“[ text span ](边界框)”，其中对象描述是位置标记的序列。结合多模态语料库，我们构建了大规模的接地图像-文本对(GrIT)数据来训练模型。除了 MLLM 的现有功能(例如，感知一般模式、遵循指令和执行上下文学习) ，Kosmos-2将接地功能集成到下游应用程序中。我们对 Kosmos-2进行了广泛的任务评估，包括(i)多模态基础，如指称表达理解和短语基础，(ii)多模态指称，如指称表达生成，(iii)感知语言任务，以及(iv)语言理解和生成。本文的工作为体验式人工智能的发展奠定了基础，并阐明了语言、多模态感知、动作和世界建模的大趋同性，这是人工一般智能的关键步骤。数据，演示和预先训练的模型可在 https://aka.ms/kosmos-2。"
    },
    {
        "title": "Label-Aware Hyperbolic Embeddings for Fine-grained Emotion\n  Classification",
        "url": "http://arxiv.org/abs/2306.14822v1",
        "pub_date": "2023-06-26",
        "summary": "Fine-grained emotion classification (FEC) is a challenging task.\nSpecifically, FEC needs to handle subtle nuance between labels, which can be\ncomplex and confusing. Most existing models only address text classification\nproblem in the euclidean space, which we believe may not be the optimal\nsolution as labels of close semantic (e.g., afraid and terrified) may not be\ndifferentiated in such space, which harms the performance. In this paper, we\npropose HypEmo, a novel framework that can integrate hyperbolic embeddings to\nimprove the FEC task. First, we learn label embeddings in the hyperbolic space\nto better capture their hierarchical structure, and then our model projects\ncontextualized representations to the hyperbolic space to compute the distance\nbetween samples and labels. Experimental results show that incorporating such\ndistance to weight cross entropy loss substantially improves the performance\nwith significantly higher efficiency. We evaluate our proposed model on two\nbenchmark datasets and found 4.8% relative improvement compared to the previous\nstate of the art with 43.2% fewer parameters and 76.9% less training time. Code\nis available at https: //github.com/dinobby/HypEmo.",
        "translated": "细粒度情绪分类(FEC)是一项具有挑战性的任务。具体来说，FEC 需要处理标签之间的细微差别，这可能是复杂和混乱的。大多数现有的模型只能解决欧几里德空间中的文本分类问题，我们认为这可能不是最佳的解决方案，因为在这样的空间中，封闭语义(例如，害怕和恐惧)的标签可能不会被区分，这会损害性能。在本文中，我们提出了一个新的框架 HypEmo，它可以集成双曲嵌入来改善 FEC 任务。首先，我们学习在双曲空间中嵌入标签，以便更好地捕捉它们的层次结构，然后我们的模型将上下文化的表示投射到双曲空间中，以计算样本和标签之间的距离。实验结果表明，这种距离加权交叉熵损失大大提高了性能，显著提高了效率。我们在两个基准数据集上评估了我们提出的模型，发现与先前的技术水平相比，参数减少了43.2% ，训练时间减少了76.9% ，相对改善了4.8% 。代码可在 https:// github.com/dinobby/hypemo 下载。"
    },
    {
        "title": "A Positive-Unlabeled Metric Learning Framework for Document-Level\n  Relation Extraction with Incomplete Labeling",
        "url": "http://arxiv.org/abs/2306.14806v1",
        "pub_date": "2023-06-26",
        "summary": "The goal of document-level relation extraction (RE) is to identify relations\nbetween entities that span multiple sentences. Recently, incomplete labeling in\ndocument-level RE has received increasing attention, and some studies have used\nmethods such as positive-unlabeled learning to tackle this issue, but there is\nstill a lot of room for improvement. Motivated by this, we propose a\npositive-augmentation and positive-mixup positive-unlabeled metric learning\nframework (P3M). Specifically, we formulate document-level RE as a metric\nlearning problem. We aim to pull the distance closer between entity pair\nembedding and their corresponding relation embedding, while pushing it farther\naway from the none-class relation embedding. Additionally, we adapt the\npositive-unlabeled learning to this loss objective. In order to improve the\ngeneralizability of the model, we use dropout to augment positive samples and\npropose a positive-none-class mixup method. Extensive experiments show that P3M\nimproves the F1 score by approximately 4-10 points in document-level RE with\nincomplete labeling, and achieves state-of-the-art results in fully labeled\nscenarios. Furthermore, P3M has also demonstrated robustness to prior\nestimation bias in incomplete labeled scenarios.",
        "translated": "文档级关系抽取(RE)的目标是识别跨越多个句子的实体之间的关系。近年来，文档级 RE 中的不完全标注问题受到越来越多的关注，一些研究已经采用了积极-未标注学习等方法来解决这一问题，但仍有很大的改进空间。基于此，我们提出了一个正增强和正混合的正未标记度量学习框架(P3M)。具体来说，我们将文档级 RE 作为一个度量学习问题来描述。我们的目标是拉近实体对嵌入与其对应关系嵌入之间的距离，同时使其远离非类关系嵌入。此外，我们调整正向未标记学习来适应这种损失目标。为了提高模型的泛化能力，我们使用辍学来增加正样本，并提出了一种正非类混合方法。大量的实验表明，P3M 在不完全标记的文档级 RE 中提高了 F1评分约4-10分，并在完全标记的场景中取得了最新的结果。此外，在不完全标记的情况下，P3M 也表现出对先前估计偏差的鲁棒性。"
    },
    {
        "title": "Unleashing the Power of User Reviews: Exploring Airline Choices at\n  Catania Airport, Italy",
        "url": "http://arxiv.org/abs/2306.15541v1",
        "pub_date": "2023-06-27",
        "summary": "This study aims to investigate the possible relationship between the\nmechanisms of social influence and the choice of airline, through the use of\nnew tools, with the aim of understanding whether they can contribute to a\nbetter understanding of the factors influencing the decisions of consumers in\nthe aviation sector. We have chosen to extract user reviews from well-known\nplatforms: Trustpilot, Google, and Twitter. By combining web scraping\ntechniques, we have been able to collect a comprehensive dataset comprising a\nwide range of user opinions, feedback, and ratings. We then refined the BERT\nmodel to focus on insightful sentiment in the context of airline reviews.\nThrough our analysis, we observed an intriguing trend of average negative\nsentiment scores across various airlines, giving us deeper insight into the\ndynamics between airlines and helping us identify key partnerships, popular\nroutes, and airlines that play a central role in the aeronautical ecosystem of\nCatania airport during the specified period. Our investigation led us to find\nthat, despite an airline having received prestigious awards as a low-cost\nleader in Europe for two consecutive years 2021 and 2022, the \"Catanese\" user\ntends to suffer the dominant position of other companies. Understanding the\nimpact of positive reviews and leveraging sentiment analysis can help airlines\nimprove their reputation, attract more customers, and ultimately gain a\ncompetitive edge in the marketplace.",
        "translated": "本研究旨在通过使用新工具，调查社会影响机制与航空公司选择之间的可能关系，以了解这些机制是否有助于更好地理解影响航空部门消费者决定的因素。我们选择从著名的平台提取用户评论: TrustPilot、 Google 和 Twitter。通过结合网络抓取技术，我们已经能够收集一个全面的数据集，包括广泛的用户意见，反馈和评级。然后，我们改进了 BERT 模型，将重点放在航空公司评论背景下的深刻情感上。通过我们的分析，我们发现了一个有趣的趋势，即不同航空公司的平均负面情绪得分，这使我们能够更深入地了解航空公司之间的动态，并帮助我们确定在特定时期内在卡塔尼亚机场航空生态系统中发挥核心作用的关键合作伙伴、热门航线和航空公司。我们的调查使我们发现，尽管一家航空公司在2021年和2022年连续两年获得欧洲低成本领先者的殊荣，但“卡塔尼亚”用户往往会受到其他公司的支配地位的影响。了解正面评价的影响力和利用情绪分析可以帮助航空公司提高他们的声誉，吸引更多的客户，并最终获得市场竞争优势。"
    },
    {
        "title": "Learning to Rank in Generative Retrieval",
        "url": "http://arxiv.org/abs/2306.15222v1",
        "pub_date": "2023-06-27",
        "summary": "Generative retrieval is a promising new paradigm in text retrieval that\ngenerates identifier strings of relevant passages as the retrieval target. This\nparadigm leverages powerful generation models and represents a new paradigm\ndistinct from traditional learning-to-rank methods. However, despite its rapid\ndevelopment, current generative retrieval methods are still limited. They\ntypically rely on a heuristic function to transform predicted identifiers into\na passage rank list, which creates a gap between the learning objective of\ngenerative retrieval and the desired passage ranking target. Moreover, the\ninherent exposure bias problem of text generation also persists in generative\nretrieval. To address these issues, we propose a novel framework, called LTRGR,\nthat combines generative retrieval with the classical learning-to-rank\nparadigm. Our approach involves training an autoregressive model using a\npassage rank loss, which directly optimizes the autoregressive model toward the\noptimal passage ranking. This framework only requires an additional training\nstep to enhance current generative retrieval systems and does not add any\nburden to the inference stage. We conducted experiments on three public\ndatasets, and our results demonstrate that LTRGR achieves state-of-the-art\nperformance among generative retrieval methods, indicating its effectiveness\nand robustness.",
        "translated": "生成检索是文本检索领域一个很有前途的新范式，它以相关段落的标识符串作为检索对象。这种模式利用了强大的生成模型，代表了一种有别于传统的学习排名方法的新模式。然而，尽管生成检索技术发展迅速，目前的生成检索方法仍然有限。它们通常依靠启发式函数将预测的标识符转换成一个段落等级列表，从而在生成检索的学习目标和期望的段落等级目标之间产生一个差距。此外，文本生成过程中固有的暴露偏差问题在生成检索中也存在。为了解决这些问题，我们提出了一个新的框架，称为 LTRGR，结合生成检索与经典的学习到秩范式。我们的方法包括训练一个自回归模型使用通过等级损失，直接优化自回归模型的最佳通过等级。该框架只需要一个额外的培训步骤，以加强目前的生成检索系统，并没有增加任何负担的推理阶段。我们在三个公共数据集上进行了实验，结果表明 LTRGR 在生成检索方法中取得了最好的性能，表明了其有效性和鲁棒性。"
    },
    {
        "title": "Off-Policy Evaluation of Ranking Policies under Diverse User Behavior",
        "url": "http://arxiv.org/abs/2306.15098v1",
        "pub_date": "2023-06-26",
        "summary": "Ranking interfaces are everywhere in online platforms. There is thus an ever\ngrowing interest in their Off-Policy Evaluation (OPE), aiming towards an\naccurate performance evaluation of ranking policies using logged data. A\nde-facto approach for OPE is Inverse Propensity Scoring (IPS), which provides\nan unbiased and consistent value estimate. However, it becomes extremely\ninaccurate in the ranking setup due to its high variance under large action\nspaces. To deal with this problem, previous studies assume either independent\nor cascade user behavior, resulting in some ranking versions of IPS. While\nthese estimators are somewhat effective in reducing the variance, all existing\nestimators apply a single universal assumption to every user, causing excessive\nbias and variance. Therefore, this work explores a far more general formulation\nwhere user behavior is diverse and can vary depending on the user context. We\nshow that the resulting estimator, which we call Adaptive IPS (AIPS), can be\nunbiased under any complex user behavior. Moreover, AIPS achieves the minimum\nvariance among all unbiased estimators based on IPS. We further develop a\nprocedure to identify the appropriate user behavior model to minimize the mean\nsquared error (MSE) of AIPS in a data-driven fashion. Extensive experiments\ndemonstrate that the empirical accuracy improvement can be significant,\nenabling effective OPE of ranking systems even under diverse user behavior.",
        "translated": "在线平台中，排序界面无处不在。因此，人们对非策略评估(OPE)越来越感兴趣，其目标是使用日志数据对策略进行准确的性能评估。OPE 的一个事实上的方法是反倾向评分(IPS) ，它提供了一个无偏和一致的价值估计。然而，它变得非常不准确的排名设置，由于其高方差下的大行动空间。为了解决这个问题，以前的研究假设独立或级联用户行为，导致一些排名版本的 IPS。虽然这些估计量在减少方差方面有一定的效果，但是所有现有的估计量都对每个用户适用一个统一的假设，从而导致过度的偏差和方差。因此，这项工作探索了一个更一般的公式，其中用户行为是多样的，可以根据用户上下文而变化。我们证明了所得到的估计量，我们称之为自适应 IPS (AIPS) ，在任何复杂的用户行为下都是无偏的。此外，AIPS 在所有基于 IPS 的无偏估计量之间实现了最小方差。我们进一步开发了一个程序，以确定适当的用户行为模型，从而以数据驱动的方式最大限度地减少 AIPS 的均方差。大量的实验表明，经验的准确性改善可以是显着的，使有效的排名系统的 OPE 即使在不同的用户行为。"
    },
    {
        "title": "Efficient High-Resolution Template Matching with Vector Quantized\n  Nearest Neighbour Fields",
        "url": "http://arxiv.org/abs/2306.15010v1",
        "pub_date": "2023-06-26",
        "summary": "Template matching is a fundamental problem in computer vision and has\napplications in various fields, such as object detection, image registration,\nand object tracking. The current state-of-the-art methods rely on\nnearest-neighbour (NN) matching in which the query feature space is converted\nto NN space by representing each query pixel with its NN in the template\npixels. The NN-based methods have been shown to perform better in occlusions,\nchanges in appearance, illumination variations, and non-rigid transformations.\nHowever, NN matching scales poorly with high-resolution data and high feature\ndimensions. In this work, we present an NN-based template-matching method which\nefficiently reduces the NN computations and introduces filtering in the NN\nfields to consider deformations. A vector quantization step first represents\nthe template with $k$ features, then filtering compares the template and query\ndistributions over the $k$ features. We show that state-of-the-art performance\nwas achieved in low-resolution data, and our method outperforms previous\nmethods at higher resolution showing the robustness and scalability of the\napproach.",
        "translated": "模板匹配是计算机视觉中的一个基本问题，在目标检测、图像配准和目标跟踪等领域有着广泛的应用。目前的方法主要依赖于最近邻(NN)匹配，通过在模板像素中表示每个查询像素及其神经网络，将查询特征空间转换为 NN 空间。基于神经网络的方法已被证明在遮挡、外观变化、光照变化和非刚性转换中表现更好。然而，高分辨率数据和高特征维数的神经网络匹配规模较小。本文提出了一种基于神经网络的模板匹配方法，该方法有效地减少了神经网络的计算量，并在神经网络中引入滤波以考虑变形。一个向量量化步骤首先表示具有 $k $特性的模板，然后过滤比较模板和查询发行版本中的 $k $特性。实验结果表明，该方法在低分辨率数据中取得了较好的性能，并且在较高分辨率下优于以往的方法，显示了该方法的鲁棒性和可扩展性。"
    },
    {
        "title": "SparseOptimizer: Sparsify Language Models through Moreau-Yosida\n  Regularization and Accelerate through Compiler Co-design",
        "url": "http://arxiv.org/abs/2306.15656v1",
        "pub_date": "2023-06-27",
        "summary": "This paper introduces SparseOptimizer, a novel deep learning optimizer that\nexploits Moreau-Yosida regularization to naturally induce sparsity in large\nlanguage models such as BERT, ALBERT and GPT. Key to the design of\nSparseOptimizer is an embedded shrinkage operator, which imparts sparsity\ndirectly within the optimization process. This operator, backed by a sound\ntheoretical framework, includes an analytical solution, thereby reinforcing the\noptimizer's robustness and efficacy. Crucially, SparseOptimizer's plug-and-play\nfunctionality eradicates the need for code modifications, making it a\nuniversally adaptable tool for a wide array of large language models. Empirical\nevaluations on benchmark datasets such as GLUE, RACE, SQuAD1, and SQuAD2\nconfirm that SparseBERT and SparseALBERT, when sparsified using\nSparseOptimizer, achieve performance comparable to their dense counterparts,\nBERT and ALBERT, while significantly reducing their parameter count. Further,\nthis work proposes an innovative optimizer-compiler co-design strategy,\ndemonstrating the potential of inference acceleration (\\textbf{3.37x},\n\\textbf{6.30x}, and \\textbf{7.15x} in comparison with Pytorch, TensorFlow, and\nLLVM generic compile, respectively) in SparseBERT when paired with an\nappropriately designed compiler. This study represents a significant step\nforward in the evolution of efficient, scalable, and high-performing large\nlanguage models, setting a precedent for future exploration and optimization in\nthis domain. The SparseOptimizer code and SparseALBERT model will be made\navailable upon paper acceptance.",
        "translated": "本文介绍了一种新型的深度学习优化器 SparseOptimizer，它利用 Moreau-Yosida 正则化在 BERT、 ALBERT 和 GPT 等大型语言模型中自然地引入稀疏性。稀疏优化器设计的关键是嵌入式收缩算子，它在优化过程中直接赋予稀疏性。这个操作符，由一个健全的理论框架支持，包括一个分析解决方案，从而增强了优化器的健壮性和有效性。至关重要的是，SparseOptimizer 的即插即用功能消除了对代码修改的需要，使其成为一个普遍适用于大量大型语言模型的工具。对基准数据集(如 GLUE、 RACE、 SQuAD1和 SQuAD2)的实证评估证实，当使用 SparseOptimizer 稀疏化时，SparseBERT 和 SparseALBERT 的性能可以与其密集对应的 BERT 和 ALBERT 相媲美，同时大大减少了它们的参数计数。此外，这项工作提出了一个创新的优化器-编译器协同设计策略，展示了推理加速的潜力(textbf {3.37 x } ，textbf {6.30 x } ，和 textbf {7.15 x } ，分别与 Pytorch，TensorFlow 和 LLVM 通用编译进行比较)在 SparseBERT 与适当设计的编译器配对时。这项研究代表了在高效、可扩展和高性能的大型语言模型的发展方面向前迈出的重要一步，为该领域未来的探索和优化开创了先例。SparseOptimizer 代码和 SparseALBERT 模型将在纸张验收时提供。"
    },
    {
        "title": "Style-transfer based Speech and Audio-visual Scene Understanding for\n  Robot Action Sequence Acquisition from Videos",
        "url": "http://arxiv.org/abs/2306.15644v1",
        "pub_date": "2023-06-27",
        "summary": "To realize human-robot collaboration, robots need to execute actions for new\ntasks according to human instructions given finite prior knowledge. Human\nexperts can share their knowledge of how to perform a task with a robot through\nmulti-modal instructions in their demonstrations, showing a sequence of\nshort-horizon steps to achieve a long-horizon goal. This paper introduces a\nmethod for robot action sequence generation from instruction videos using (1)\nan audio-visual Transformer that converts audio-visual features and instruction\nspeech to a sequence of robot actions called dynamic movement primitives (DMPs)\nand (2) style-transfer-based training that employs multi-task learning with\nvideo captioning and weakly-supervised learning with a semantic classifier to\nexploit unpaired video-action data. We built a system that accomplishes various\ncooking actions, where an arm robot executes a DMP sequence acquired from a\ncooking video using the audio-visual Transformer. Experiments with\nEpic-Kitchen-100, YouCookII, QuerYD, and in-house instruction video datasets\nshow that the proposed method improves the quality of DMP sequences by 2.3\ntimes the METEOR score obtained with a baseline video-to-action Transformer.\nThe model achieved 32% of the task success rate with the task knowledge of the\nobject.",
        "translated": "为了实现人机协作，机器人需要根据给定有限先验知识的人工指令执行新任务的操作。人类专家可以在演示中通过多模态指令与机器人分享他们如何执行任务的知识，展示一系列实现长期目标的短期步骤。本文介绍了一种利用(1)音视频转换器将音视频特征和指令语音转换为机器人动作序列即动态运动原语(DMP)的机器人动作序列生成方法，以及(2)基于样式转换的训练方法，该方法采用带视频字幕的多任务学习和带语义分类器的弱监督学习来利用未配对的视频动作数据。我们建立了一个系统，完成各种烹饪动作，其中一个手臂机器人执行一个 DMP 序列从烹饪视频获得使用视听变压器。Epic-Kitchen-100、 YouCookII、 QuerYD 和内部指令视频数据集的实验表明，该方法提高了 DMP 序列的质量，是基线视频到行动变压器获得的 METEOR 评分的2.3倍。该模型利用对象的任务知识实现了32% 的任务成功率。"
    },
    {
        "title": "Automatic Annotation of Direct Speech in Written French Narratives",
        "url": "http://arxiv.org/abs/2306.15634v2",
        "pub_date": "2023-06-27",
        "summary": "The automatic annotation of direct speech (AADS) in written text has been\noften used in computational narrative understanding. Methods based on either\nrules or deep neural networks have been explored, in particular for English or\nGerman languages. Yet, for French, our target language, not many works exist.\nOur goal is to create a unified framework to design and evaluate AADS models in\nFrench. For this, we consolidated the largest-to-date French narrative dataset\nannotated with DS per word; we adapted various baselines for sequence labelling\nor from AADS in other languages; and we designed and conducted an extensive\nevaluation focused on generalisation. Results show that the task still requires\nsubstantial efforts and emphasise characteristics of each baseline. Although\nthis framework could be improved, it is a step further to encourage more\nresearch on the topic.",
        "translated": "书面文本中直接引语的自动注释(AADS)在计算性叙事理解中得到了广泛的应用。基于规则或深层神经网络的方法已经被探索，特别是对于英语或德语。然而，对于我们的目标语言法语来说，没有多少作品存在。我们的目标是创建一个统一的框架来设计和评估法语 AADS 模型。为此，我们整合了迄今为止最大的法语叙事数据集，每个单词用 DS 注释; 我们调整了序列标签或其他语言的 AADS 的各种基线; 我们设计并进行了广泛的评估，重点是泛化。结果表明，这项任务仍然需要大量的努力，并强调每个基线的特点。虽然这个框架可以得到改进，但这是鼓励对这个主题进行更多研究的进一步步骤。"
    },
    {
        "title": "Constructing Multilingual Code Search Dataset Using Neural Machine\n  Translation",
        "url": "http://arxiv.org/abs/2306.15604v1",
        "pub_date": "2023-06-27",
        "summary": "Code search is a task to find programming codes that semantically match the\ngiven natural language queries. Even though some of the existing datasets for\nthis task are multilingual on the programming language side, their query data\nare only in English. In this research, we create a multilingual code search\ndataset in four natural and four programming languages using a neural machine\ntranslation model. Using our dataset, we pre-train and fine-tune the\nTransformer-based models and then evaluate them on multiple code search test\nsets. Our results show that the model pre-trained with all natural and\nprogramming language data has performed best in most cases. By applying\nback-translation data filtering to our dataset, we demonstrate that the\ntranslation quality affects the model's performance to a certain extent, but\nthe data size matters more.",
        "translated": "代码搜索是一项任务，用于查找在语义上匹配给定自然语言查询的编程代码。尽管用于此任务的一些现有数据集在编程语言方面是多语言的，但是它们的查询数据仅使用英语。在这项研究中，我们使用神经机器翻译模型，用四种自然语言和四种编程语言创建了一个多语言的代码搜索数据集。使用我们的数据集，我们预先训练和微调基于 Transformer 的模型，然后在多个代码搜索测试集上对它们进行评估。我们的结果表明，在大多数情况下，使用所有自然语言和编程语言数据预先训练的模型表现最好。通过对我们的数据集进行反向翻译数据过滤，我们发现翻译质量在一定程度上影响了模型的性能，但是数据的大小更重要。"
    },
    {
        "title": "Extending Context Window of Large Language Models via Positional\n  Interpolation",
        "url": "http://arxiv.org/abs/2306.15595v2",
        "pub_date": "2023-06-27",
        "summary": "We present Position Interpolation (PI) that extends the context window sizes\nof RoPE-based pretrained LLMs such as LLaMA models to up to 32768 with minimal\nfine-tuning (within 1000 steps), while demonstrating strong empirical results\non various tasks that require long context, including passkey retrieval,\nlanguage modeling, and long document summarization from LLaMA 7B to 65B.\nMeanwhile, the extended model by Position Interpolation preserve quality\nrelatively well on tasks within its original context window. To achieve this\ngoal, Position Interpolation linearly down-scales the input position indices to\nmatch the original context window size, rather than extrapolating beyond the\ntrained context length which may lead to catastrophically high attention scores\nthat completely ruin the self-attention mechanism. Our theoretical study shows\nthat the upper bound of interpolation is at least $\\sim 600 \\times$ smaller\nthan that of extrapolation, further demonstrating its stability. Models\nextended via Position Interpolation retain its original architecture and can\nreuse most pre-existing optimization and infrastructure.",
        "translated": "我们提出了位置插值(PI) ，扩展了基于 RoPE 的预训练 LLM (如 LLaMA 模型)的上下文窗口大小，以最小的微调(在1000个步骤内)达到32768，同时在需要长上下文的各种任务上展示了强大的经验结果，包括密钥检索，语言建模和从 LLaMA 7B 到65B 的长文档摘要。同时，通过位置插值的扩展模型在其原始上下文窗口中较好地保持了任务的质量。为了达到这个目标，位置插值线性地降低输入位置指数，以匹配原始上下文窗口大小，而不是外推超过训练的上下文长度，这可能导致灾难性的高注意分数，完全破坏了自我注意机制。我们的理论研究表明，插值的上界至少比外推的上界小600倍，进一步证明了插值的稳定性。通过位置插值扩展的模型保留了其原有的体系结构，并且可以重用大多数预先存在的优化和基础设施。"
    },
    {
        "title": "CrunchGPT: A chatGPT assisted framework for scientific machine learning",
        "url": "http://arxiv.org/abs/2306.15551v1",
        "pub_date": "2023-06-27",
        "summary": "Scientific Machine Learning (SciML) has advanced recently across many\ndifferent areas in computational science and engineering. The objective is to\nintegrate data and physics seamlessly without the need of employing elaborate\nand computationally taxing data assimilation schemes. However, preprocessing,\nproblem formulation, code generation, postprocessing and analysis are still\ntime consuming and may prevent SciML from wide applicability in industrial\napplications and in digital twin frameworks. Here, we integrate the various\nstages of SciML under the umbrella of ChatGPT, to formulate CrunchGPT, which\nplays the role of a conductor orchestrating the entire workflow of SciML based\non simple prompts by the user. Specifically, we present two examples that\ndemonstrate the potential use of CrunchGPT in optimizing airfoils in\naerodynamics, and in obtaining flow fields in various geometries in interactive\nmode, with emphasis on the validation stage. To demonstrate the flow of the\nCrunchGPT, and create an infrastructure that can facilitate a broader vision,\nwe built a webapp based guided user interface, that includes options for a\ncomprehensive summary report. The overall objective is to extend CrunchGPT to\nhandle diverse problems in computational mechanics, design, optimization and\ncontrols, and general scientific computing tasks involved in SciML, hence using\nit as a research assistant tool but also as an educational tool. While here the\nexamples focus in fluid mechanics, future versions will target solid mechanics\nand materials science, geophysics, systems biology and bioinformatics.",
        "translated": "科学机器学习(sciML)最近在许多不同的计算科学与工程领域取得了进展。我们的目标是无缝集成数据和物理，而不需要采用复杂的计算数据同化。然而，预处理、问题制定、代码生成、后处理和分析仍然非常耗时，可能会妨碍 SciML 在工业应用和数字双框架中的广泛适用性。在这里，我们将 SciML 的各个阶段集成在 ChatGPT 的保护伞下，以形成 CrunchGPT，它扮演着指挥者的角色，根据用户的简单提示编排 SciML 的整个工作流程。具体来说，我们提出了两个例子，展示了 CrunchGPT 在空气动力学中优化翼型的潜在用途，以及在交互模式下获得各种几何形状的流场，重点是验证阶段。为了演示 CrunchGPT 的流程，并创建一个可以促进更广阔视野的基础设施，我们构建了一个基于 Web 应用的指导用户界面，其中包括一个全面摘要报告的选项。总体目标是扩展 CrunchGPT，以处理计算力学、设计、优化和控制方面的各种问题，以及与 SciML 相关的一般科学计算任务，从而将其用作研究辅助工具，同时也用作教育工具。虽然这里的例子集中在流体力学，未来的版本将针对固体力学和材料科学，地球物理学，系统生物学和生物信息学。"
    },
    {
        "title": "CamemBERT-bio: a Tasty French Language Model Better for your Health",
        "url": "http://arxiv.org/abs/2306.15550v1",
        "pub_date": "2023-06-27",
        "summary": "Clinical data in hospitals are increasingly accessible for research through\nclinical data warehouses, however these documents are unstructured. It is\ntherefore necessary to extract information from medical reports to conduct\nclinical studies. Transfer learning with BERT-like models such as CamemBERT has\nallowed major advances, especially for named entity recognition. However, these\nmodels are trained for plain language and are less efficient on biomedical\ndata. This is why we propose a new French public biomedical dataset on which we\nhave continued the pre-training of CamemBERT. Thus, we introduce a first\nversion of CamemBERT-bio, a specialized public model for the French biomedical\ndomain that shows 2.54 points of F1 score improvement on average on different\nbiomedical named entity recognition tasks.",
        "translated": "医院的临床数据越来越多地可以通过临床数据仓库进行研究，但是这些文档是非结构化的。因此，有必要从医疗报告中提取信息进行临床研究。使用诸如 CamemBERT 之类的 BERT 模型的转移学习已经取得了重大进展，特别是对命名实体识别。然而，这些模型都是针对简单语言进行训练的，对生物医学数据的处理效率较低。这就是为什么我们提出了一个新的法国公共生物医学数据集，我们已经继续在 CamemBERT 的预训练。因此，我们引入了 CamemBERT-bio 的第一个版本，这是法国生物医学领域的专门公共模型，在不同的生物医学命名实体识别任务中平均显示 F1评分改善2.54分。"
    },
    {
        "title": "Paradigm Shift in Sustainability Disclosure Analysis: Empowering\n  Stakeholders with CHATREPORT, a Language Model-Based Tool",
        "url": "http://arxiv.org/abs/2306.15518v1",
        "pub_date": "2023-06-27",
        "summary": "This paper introduces a novel approach to enhance Large Language Models\n(LLMs) with expert knowledge to automate the analysis of corporate\nsustainability reports by benchmarking them against the Task Force for\nClimate-Related Financial Disclosures (TCFD) recommendations. Corporate\nsustainability reports are crucial in assessing organizations' environmental\nand social risks and impacts. However, analyzing these reports' vast amounts of\ninformation makes human analysis often too costly. As a result, only a few\nentities worldwide have the resources to analyze these reports, which could\nlead to a lack of transparency. While AI-powered tools can automatically\nanalyze the data, they are prone to inaccuracies as they lack domain-specific\nexpertise. This paper introduces a novel approach to enhance LLMs with expert\nknowledge to automate the analysis of corporate sustainability reports. We\nchristen our tool CHATREPORT, and apply it in a first use case to assess\ncorporate climate risk disclosures following the TCFD recommendations.\nCHATREPORT results from collaborating with experts in climate science, finance,\neconomic policy, and computer science, demonstrating how domain experts can be\ninvolved in developing AI tools. We make our prompt templates, generated data,\nand scores available to the public to encourage transparency.",
        "translated": "本文介绍了一种新颖的方法来增强大型语言模型(LLM)的专家知识，以自动化的分析公司可持续性报告的基准对气候相关的财务披露工作队(TCFD)的建议。企业可持续性报告对于评估组织的环境和社会风险及影响至关重要。然而，分析这些报告的海量信息往往使人工分析成本过高。因此，全世界只有少数几个实体有资源来分析这些报告，这可能导致缺乏透明度。虽然人工智能驱动的工具可以自动分析数据，但由于缺乏特定领域的专业知识，它们很容易出现错误。本文介绍了一种利用专家知识增强 LLM 的新方法，使企业可持续发展报告的分析自动化。我们将我们的工具命名为 CHATREPORT，并在第一个用例中应用它来评估遵循 TCFD 建议的企业气候风险披露。CHATREPORT 是与气候科学、金融、经济政策和计算机科学领域的专家合作的成果，展示了领域专家如何参与人工智能工具的开发。我们将提示模板、生成的数据和分数提供给公众，以鼓励透明度。"
    },
    {
        "title": "Using Large Language Models to Provide Explanatory Feedback to Human\n  Tutors",
        "url": "http://arxiv.org/abs/2306.15498v1",
        "pub_date": "2023-06-27",
        "summary": "Research demonstrates learners engaging in the process of producing\nexplanations to support their reasoning, can have a positive impact on\nlearning. However, providing learners real-time explanatory feedback often\npresents challenges related to classification accuracy, particularly in\ndomain-specific environments, containing situationally complex and nuanced\nresponses. We present two approaches for supplying tutors real-time feedback\nwithin an online lesson on how to give students effective praise. This\nwork-in-progress demonstrates considerable accuracy in binary classification\nfor corrective feedback of effective, or effort-based (F1 score = 0.811), and\nineffective, or outcome-based (F1 score = 0.350), praise responses. More\nnotably, we introduce progress towards an enhanced approach of providing\nexplanatory feedback using large language model-facilitated named entity\nrecognition, which can provide tutors feedback, not only while engaging in\nlessons, but can potentially suggest real-time tutor moves. Future work\ninvolves leveraging large language models for data augmentation to improve\naccuracy, while also developing an explanatory feedback interface.",
        "translated": "研究表明，学习者在产生解释的过程中支持自己的推理，可以对学习产生积极的影响。然而，为学习者提供实时的解释性反馈往往会带来与分类准确性相关的挑战，特别是在特定领域的环境中，包含情境复杂和微妙的反馈。我们提出了两种方法，以提供实时反馈的在线教学如何给予学生有效的表扬。这项正在进行的工作表明，对于有效的或基于努力的(F1评分 = 0.811)和无效的或基于结果的(F1评分 = 0.350)表扬反馈的纠正反馈的二元分类具有相当大的准确性。更值得注意的是，我们使用大型语言模型促进的命名实体识别引入了提供解释性反馈的强化方法，这种方法不仅可以在上课时提供导师反馈，而且可以潜在地提出实时导师动作。未来的工作包括利用大型语言模型进行数据增强以提高准确性，同时还要开发一个解释性反馈接口。"
    },
    {
        "title": "SE-PQA: Personalized Community Question Answering",
        "url": "http://arxiv.org/abs/2306.16261v1",
        "pub_date": "2023-06-28",
        "summary": "Personalization in Information Retrieval is a topic studied for a long time.\nNevertheless, there is still a lack of high-quality, real-world datasets to\nconduct large-scale experiments and evaluate models for personalized search.\nThis paper contributes to filling this gap by introducing SE-PQA (StackExchange\n- Personalized Question Answering), a new curated resource to design and\nevaluate personalized models related to the task of community Question\nAnswering (cQA). The contributed dataset includes more than 1 million queries\nand 2 million answers, annotated with a rich set of features modeling the\nsocial interactions among the users of a popular cQA platform. We describe the\ncharacteristics of SE-PQA and detail the features associated with questions and\nanswers. We also provide reproducible baseline methods for the cQA task based\non the resource, including deep learning models and personalization approaches.\nThe results of the preliminary experiments conducted show the appropriateness\nof SE-PQA to train effective cQA models; they also show that personalization\nremarkably improves the effectiveness of all the methods tested. Furthermore,\nwe show the benefits in terms of robustness and generalization of combining\ndata from multiple communities for personalization purposes.",
        "translated": "信息检索的个性化是一个长期研究的课题。尽管如此，仍然缺乏高质量的真实世界的数据集来进行大规模的实验和评估个性化检索模型。本文通过引入 SE-PQA 来填补这一空白。 SE-PQA 是一种新的策划资源，用于设计和评估与社区问答任务(cQA)相关的个性化模型。贡献的数据集包括超过100万个查询和200万个答案，并用一组丰富的特性对流行的 cQA 平台的用户之间的社交互动进行了建模。我们描述了 SE-PQA 的特征，并详细描述了与问答相关的特征。我们还为基于资源的 cQA 任务提供了可重复的基线方法，包括深度学习模型和个性化方法。初步实验结果表明，SE-PQA 方法训练有效的 cQA 模型是合适的，并且个性化显著提高了所有测试方法的有效性。此外，我们还展示了将来自多个社区的数据用于个性化目的的健壮性和通用性方面的好处。"
    },
    {
        "title": "Query Understanding in the Age of Large Language Models",
        "url": "http://arxiv.org/abs/2306.16004v1",
        "pub_date": "2023-06-28",
        "summary": "Querying, conversing, and controlling search and information-seeking\ninterfaces using natural language are fast becoming ubiquitous with the rise\nand adoption of large-language models (LLM). In this position paper, we\ndescribe a generic framework for interactive query-rewriting using LLMs. Our\nproposal aims to unfold new opportunities for improved and transparent intent\nunderstanding while building high-performance retrieval systems using LLMs. A\nkey aspect of our framework is the ability of the rewriter to fully specify the\nmachine intent by the search engine in natural language that can be further\nrefined, controlled, and edited before the final retrieval phase. The ability\nto present, interact, and reason over the underlying machine intent in natural\nlanguage has profound implications on transparency, ranking performance, and a\ndeparture from the traditional way in which supervised signals were collected\nfor understanding intents. We detail the concept, backed by initial\nexperiments, along with open questions for this interactive query understanding\nframework.",
        "translated": "随着大语言模型(LLM)的兴起和采用，使用自然语言进行查询、转换和控制搜索和信息搜索界面正迅速变得无处不在。在本文中，我们描述了一个使用 LLM 进行交互式查询重写的通用框架。我们的建议旨在开辟新的机会，以改善和透明的意图理解，同时建立使用 LLM 的高性能检索系统。我们框架的一个关键方面是重写器能够通过自然语言完全指定搜索引擎的机器意图，在最终检索阶段之前可以进一步细化、控制和编辑。在自然语言中呈现、交互和推理潜在机器意图的能力对透明度、排序性能有着深远的影响，并且背离了传统的为理解意图而收集监督信号的方式。我们详细介绍了这个概念，并进行了初步的实验，同时还提出了这个交互式查询理解框架的开放式问题。"
    },
    {
        "title": "Streamlining Social Media Information Retrieval for Public Health\n  Research with Deep Learning",
        "url": "http://arxiv.org/abs/2306.16001v1",
        "pub_date": "2023-06-28",
        "summary": "The utilization of social media in epidemic surveillance has been well\nestablished. Nonetheless, bias is often introduced when pre-defined lexicons\nare used to retrieve relevant corpus. This study introduces a framework aimed\nat curating extensive dictionaries of medical colloquialisms and Unified\nMedical Language System (UMLS) concepts. The framework comprises three modules:\na BERT-based Named Entity Recognition (NER) model that identifies medical\nentities from social media content, a deep-learning powered normalization\nmodule that standardizes the extracted entities, and a semi-supervised\nclustering module that assigns the most probable UMLS concept to each\nstandardized entity. We applied this framework to COVID-19-related tweets from\nFebruary 1, 2020, to April 30, 2022, generating a symptom dictionary (available\nat https://github.com/ningkko/UMLS_colloquialism/) composed of 9,249\nstandardized entities mapped to 876 UMLS concepts and 38,175 colloquial\nexpressions. This framework demonstrates encouraging potential in addressing\nthe constraints of keyword matching information retrieval in social media-based\npublic health research.",
        "translated": "社交媒体在流行病监测中的应用已经得到了很好的证实。然而，当预定义词汇用于检索相关语料时，常常会引入偏倚。这项研究介绍了一个框架，旨在管理广泛的医学术语和一体化医学语言系统(UMLS)概念词典。该框架由三个模块组成: 一个基于 BERT 的命名实体识别(NER)模型，该模型从社交媒体内容中识别医疗实体; 一个深度学习驱动的标准化模块，该模块标准化提取的实体; 以及一个半监督聚类模块，该模块为每个标准化实体分配最可能的 UMLS 概念。我们将这个框架应用于2020年2月1日至2022年4月30日期间与 COVID-19相关的推文，生成了一个症状词典(可在 https://github.com/ningkko/umls_colloquialism/获得) ，由映射到876个 UMLS 概念和38,175个口语表达的9,249个标准化实体组成。这个框架显示了在解决基于社交媒体的公共卫生研究中关键词匹配信息检索的限制方面令人鼓舞的潜力。"
    },
    {
        "title": "Disentangled Variational Auto-encoder Enhanced by Counterfactual Data\n  for Debiasing Recommendation",
        "url": "http://arxiv.org/abs/2306.15961v1",
        "pub_date": "2023-06-28",
        "summary": "Recommender system always suffers from various recommendation biases,\nseriously hindering its development. In this light, a series of debias methods\nhave been proposed in the recommender system, especially for two most common\nbiases, i.e., popularity bias and amplified subjective bias. However, exsisting\ndebias methods usually concentrate on correcting a single bias. Such\nsingle-functionality debiases neglect the bias-coupling issue in which the\nrecommended items are collectively attributed to multiple biases. Besides,\nprevious work cannot tackle the lacking supervised signals brought by sparse\ndata, yet which has become a commonplace in the recommender system. In this\nwork, we introduce a disentangled debias variational auto-encoder\nframework(DB-VAE) to address the single-functionality issue as well as a\ncounterfactual data enhancement method to mitigate the adverse effect due to\nthe data sparsity. In specific, DB-VAE first extracts two types of extreme\nitems only affected by a single bias based on the collier theory, which are\nrespectively employed to learn the latent representation of corresponding\nbiases, thereby realizing the bias decoupling. In this way, the exact unbiased\nuser representation can be learned by these decoupled bias representations.\nFurthermore, the data generation module employs Pearl's framework to produce\nmassive counterfactual data, making up the lacking supervised signals due to\nthe sparse data. Extensive experiments on three real-world datasets demonstrate\nthe effectiveness of our proposed model. Besides, the counterfactual data can\nfurther improve DB-VAE, especially on the dataset with low sparsity.",
        "translated": "推荐系统总是受到各种推荐偏见的困扰，严重阻碍了它的发展。有见及此，推荐系统中提出了一系列的偏差分析方法，特别是针对两种最常见的偏差，即受欢迎程度偏差和放大的主观偏差。然而，现有的偏倚矫正方法通常集中于纠正单一偏倚。这种单一功能的偏差忽略了偏差耦合问题，在这个问题中，推荐的项目被共同归因于多个偏差。此外，以往的研究未能解决稀疏数据所带来的缺乏监督的信号问题，但这已成为推荐系统研究中的一个常见问题。在这项工作中，我们介绍了一个解纠缠去偏差变分自动编码框架(DB-VAE) ，以解决单一功能的问题，以及一个反事实的数据增强方法，以减轻由于数据稀疏造成的不利影响。具体来说，DB-VAE 首先基于 Collier 理论提取两类仅受单一偏差影响的极值项，分别用于学习相应偏差的潜在表示，从而实现偏差解耦。这样，就可以通过这些解耦的偏差表示来学习精确的无偏用户表示。此外，数据生成模块利用 Pearl 的框架生成大量的反事实数据，弥补了由于数据稀疏而导致的监督信号的缺失。在三个真实世界数据集上的大量实验证明了我们提出的模型的有效性。此外，反事实数据可以进一步改善 DB-VAE，特别是对稀疏度较低的数据集。"
    },
    {
        "title": "Pb-Hash: Partitioned b-bit Hashing",
        "url": "http://arxiv.org/abs/2306.15944v1",
        "pub_date": "2023-06-28",
        "summary": "Many hashing algorithms including minwise hashing (MinHash), one permutation\nhashing (OPH), and consistent weighted sampling (CWS) generate integers of $B$\nbits. With $k$ hashes for each data vector, the storage would be $B\\times k$\nbits; and when used for large-scale learning, the model size would be\n$2^B\\times k$, which can be expensive. A standard strategy is to use only the\nlowest $b$ bits out of the $B$ bits and somewhat increase $k$, the number of\nhashes. In this study, we propose to re-use the hashes by partitioning the $B$\nbits into $m$ chunks, e.g., $b\\times m =B$. Correspondingly, the model size\nbecomes $m\\times 2^b \\times k$, which can be substantially smaller than the\noriginal $2^B\\times k$.\n  Our theoretical analysis reveals that by partitioning the hash values into\n$m$ chunks, the accuracy would drop. In other words, using $m$ chunks of $B/m$\nbits would not be as accurate as directly using $B$ bits. This is due to the\ncorrelation from re-using the same hash. On the other hand, our analysis also\nshows that the accuracy would not drop much for (e.g.,) $m=2\\sim 4$. In some\nregions, Pb-Hash still works well even for $m$ much larger than 4. We expect\nPb-Hash would be a good addition to the family of hashing methods/applications\nand benefit industrial practitioners.\n  We verify the effectiveness of Pb-Hash in machine learning tasks, for linear\nSVM models as well as deep learning models. Since the hashed data are\nessentially categorical (ID) features, we follow the standard practice of using\nembedding tables for each hash. With Pb-Hash, we need to design an effective\nstrategy to combine $m$ embeddings. Our study provides an empirical evaluation\non four pooling schemes: concatenation, max pooling, mean pooling, and product\npooling. There is no definite answer which pooling would be always better and\nwe leave that for future study.",
        "translated": "许多散列算法包括 minwise 散列(MinHash)、一个置换散列(OPH)和一致加权抽样(CWS)生成 $B $bit 的整数。对于每个数据向量使用 $k $散列，存储将是 $B 乘以 k $bit; 如果使用大规模学习，模型大小将是 $2 ^ B 乘以 k $，这可能是昂贵的。一个标准的策略是仅使用 $B $bit 中的最低 $b $bit，并稍微增加 $k $，即散列的数量。在这个研究中，我们建议通过将 $B $bit 分割成 $m $block 来重用散列，例如，$b 乘以 m = B $。相应地，模型大小变成 $m 乘以2 ^ b 乘以 k $，这可以大大小于原来的2 ^ B 乘以 k $。我们的理论分析表明，通过将散列值划分为 $m $块，准确性会下降。换句话说，使用 $m $块的 $B/m $bits 不会像直接使用 $B $bits 那样精确。这是由于重用相同哈希引起的相关性。另一方面，我们的分析也表明，对于(例如) $m = 2 sim 4 $，精度不会下降很多。在一些地区，Pb-Hash 甚至在价格远高于4美元的情况下仍然运行良好。我们期望 Pb-Hash 将是散列方法/应用系列的一个很好的补充，并有利于工业实践者。我们验证了 Pb-Hash 在机器学习任务、线性支持向量机模型和深度学习模型方面的有效性。由于散列数据本质上是分类(ID)特性，因此我们遵循对每个散列使用嵌入表的标准实践。使用 Pb-Hash，我们需要设计一个有效的策略来结合 $m $嵌入。我们的研究提供了一个实证评估的四个池方案: 连接，最大池，平均池，和产品池。没有明确的答案，哪一个池总是更好，我们留给未来的研究。"
    },
    {
        "title": "MultiZoo &amp; MultiBench: A Standardized Toolkit for Multimodal Deep\n  Learning",
        "url": "http://arxiv.org/abs/2306.16413v1",
        "pub_date": "2023-06-28",
        "summary": "Learning multimodal representations involves integrating information from\nmultiple heterogeneous sources of data. In order to accelerate progress towards\nunderstudied modalities and tasks while ensuring real-world robustness, we\nrelease MultiZoo, a public toolkit consisting of standardized implementations\nof &gt; 20 core multimodal algorithms and MultiBench, a large-scale benchmark\nspanning 15 datasets, 10 modalities, 20 prediction tasks, and 6 research areas.\nTogether, these provide an automated end-to-end machine learning pipeline that\nsimplifies and standardizes data loading, experimental setup, and model\nevaluation. To enable holistic evaluation, we offer a comprehensive methodology\nto assess (1) generalization, (2) time and space complexity, and (3) modality\nrobustness. MultiBench paves the way towards a better understanding of the\ncapabilities and limitations of multimodal models, while ensuring ease of use,\naccessibility, and reproducibility. Our toolkits are publicly available, will\nbe regularly updated, and welcome inputs from the community.",
        "translated": "学习多模态表示涉及到整合来自多个异构数据源的信息。为了在确保现实世界稳健性的同时加快未被研究的模式和任务的进展，我们发布了 MultiZoo，一个公共工具包，由 > 20个核心多模式算法的标准化实现和 MultiBench 组成，MultiBench 是一个跨越15个数据集，10个模式，20个预测任务和6个研究领域的大规模基准。总之，它们提供了一个自动化的端到端机器学习流水线，可以简化和标准化数据加载、实验设置和模型评估。为了实现整体评估，我们提供了一个综合的方法来评估(1)泛化，(2)时间和空间复杂性，和(3)模态鲁棒性。MultiBench 为更好地理解多模式模型的功能和局限性铺平了道路，同时确保了易用性、可访问性和可重复性。我们的工具包是公开可用的，将定期更新，并欢迎来自社区的输入。"
    },
    {
        "title": "Towards Language Models That Can See: Computer Vision Through the LENS\n  of Natural Language",
        "url": "http://arxiv.org/abs/2306.16410v1",
        "pub_date": "2023-06-28",
        "summary": "We propose LENS, a modular approach for tackling computer vision problems by\nleveraging the power of large language models (LLMs). Our system uses a\nlanguage model to reason over outputs from a set of independent and highly\ndescriptive vision modules that provide exhaustive information about an image.\nWe evaluate the approach on pure computer vision settings such as zero- and\nfew-shot object recognition, as well as on vision and language problems. LENS\ncan be applied to any off-the-shelf LLM and we find that the LLMs with LENS\nperform highly competitively with much bigger and much more sophisticated\nsystems, without any multimodal training whatsoever. We open-source our code at\nhttps://github.com/ContextualAI/lens and provide an interactive demo.",
        "translated": "我们提出 LENS，一种通过利用大型语言模型(LLM)解决计算机视觉问题的模块化方法。我们的系统使用一个语言模型来推理来自一组独立且高度描述性的视觉模块的输出，这些模块提供关于图像的详尽信息。我们评估的方法纯计算机视觉设置，如零和少拍摄物体识别，以及在视觉和语言问题。LENS 可以应用于任何现成的 LLM，我们发现 LENS 的 LLM 在更大和更复杂的系统中表现得非常有竞争力，没有任何多模态训练。我们 https://github.com/contextualai/lens 开源代码并提供交互式演示。"
    },
    {
        "title": "Towards Measuring the Representation of Subjective Global Opinions in\n  Language Models",
        "url": "http://arxiv.org/abs/2306.16388v1",
        "pub_date": "2023-06-28",
        "summary": "Large language models (LLMs) may not equitably represent diverse global\nperspectives on societal issues. In this paper, we develop a quantitative\nframework to evaluate whose opinions model-generated responses are more similar\nto. We first build a dataset, GlobalOpinionQA, comprised of questions and\nanswers from cross-national surveys designed to capture diverse opinions on\nglobal issues across different countries. Next, we define a metric that\nquantifies the similarity between LLM-generated survey responses and human\nresponses, conditioned on country. With our framework, we run three experiments\non an LLM trained to be helpful, honest, and harmless with Constitutional AI.\nBy default, LLM responses tend to be more similar to the opinions of certain\npopulations, such as those from the USA, and some European and South American\ncountries, highlighting the potential for biases. When we prompt the model to\nconsider a particular country's perspective, responses shift to be more similar\nto the opinions of the prompted populations, but can reflect harmful cultural\nstereotypes. When we translate GlobalOpinionQA questions to a target language,\nthe model's responses do not necessarily become the most similar to the\nopinions of speakers of those languages. We release our dataset for others to\nuse and build on. Our data is at\nhttps://huggingface.co/datasets/Anthropic/llm_global_opinions. We also provide\nan interactive visualization at https://llmglobalvalues.anthropic.com.",
        "translated": "大型语言模型(LLM)可能不能公平地代表关于社会问题的多样化的全球视角。在本文中，我们建立了一个定量的框架来评估谁的意见模型生成的反应更相似。我们首先建立一个数据集 GlobalOpinionQA，包括来自跨国调查的问题和答案，旨在收集不同国家对全球问题的不同意见。接下来，我们定义一个度量标准，量化 LLM 生成的调查答复和人类反应之间的相似性，以国家为条件。在我们的框架下，我们在一个训练有素的 LLM 上进行了三个实验，这个 LLM 被训练成有用的、诚实的和无害的人工智能。默认情况下，LLM 的反应往往与某些人群的观点更为相似，例如来自美国以及一些欧洲和南美国家的观点，突出了潜在的偏见。当我们提示模型考虑一个特定国家的观点时，反应会变得更加类似于提示人群的观点，但是反映出有害的文化刻板印象。当我们将 GlobalOpinionQA 问题翻译成目标语言时，模型的回答并不一定与使用这些语言的人的观点最为相似。我们将我们的数据集发布给其他人使用和构建。我们的数据处于 https://huggingface.co/datasets/anthropic/llm_global_opinions。我们还在 https://llmglobalvalues.anthropic.com 上提供了一个交互式可视化。"
    },
    {
        "title": "Multi-Site Clinical Federated Learning using Recursive and Attentive\n  Models and NVFlare",
        "url": "http://arxiv.org/abs/2306.16367v1",
        "pub_date": "2023-06-28",
        "summary": "The prodigious growth of digital health data has precipitated a mounting\ninterest in harnessing machine learning methodologies, such as natural language\nprocessing (NLP), to scrutinize medical records, clinical notes, and other\ntext-based health information. Although NLP techniques have exhibited\nsubstantial potential in augmenting patient care and informing clinical\ndecision-making, data privacy and adherence to regulations persist as critical\nconcerns. Federated learning (FL) emerges as a viable solution, empowering\nmultiple organizations to train machine learning models collaboratively without\ndisseminating raw data. This paper proffers a pragmatic approach to medical NLP\nby amalgamating FL, NLP models, and the NVFlare framework, developed by NVIDIA.\nWe introduce two exemplary NLP models, the Long-Short Term Memory (LSTM)-based\nmodel and Bidirectional Encoder Representations from Transformers (BERT), which\nhave demonstrated exceptional performance in comprehending context and\nsemantics within medical data. This paper encompasses the development of an\nintegrated framework that addresses data privacy and regulatory compliance\nchallenges while maintaining elevated accuracy and performance, incorporating\nBERT pretraining, and comprehensively substantiating the efficacy of the\nproposed approach.",
        "translated": "数字健康数据的巨大增长促使人们对利用机器学习方法(如自然语言处理(NLP))来仔细检查医疗记录、临床记录和其他基于文本的健康信息产生了越来越大的兴趣。尽管 NLP 技术在增强患者护理和为临床决策提供信息方面显示出巨大的潜力，但数据隐私和遵守规定仍然是关键问题。联邦学习(FL)作为一种可行的解决方案出现了，它赋予多个组织在不传播原始数据的情况下协同训练机器学习模型的权力。本文通过融合 FL、 NLP 模型和 NVFlare 框架，提出了一种实用的医学自然语言处理方法。我们介绍了两个典型的自然语言处理模型，基于长短期记忆(LSTM)的模型和来自变压器的双向编码器表示(BERT) ，它们在理解医学数据中的上下文和语义方面表现出优异的性能。本文包括开发一个综合框架，解决数据隐私和守规的挑战，同时保持提高的准确性和性能，结合 BERT 预训练，并全面证实拟议方法的有效性。"
    },
    {
        "title": "Representation Learning via Variational Bayesian Networks",
        "url": "http://arxiv.org/abs/2306.16326v1",
        "pub_date": "2023-06-28",
        "summary": "We present Variational Bayesian Network (VBN) - a novel Bayesian entity\nrepresentation learning model that utilizes hierarchical and relational side\ninformation and is particularly useful for modeling entities in the\n``long-tail'', where the data is scarce. VBN provides better modeling for\nlong-tail entities via two complementary mechanisms: First, VBN employs\ninformative hierarchical priors that enable information propagation between\nentities sharing common ancestors. Additionally, VBN models explicit relations\nbetween entities that enforce complementary structure and consistency, guiding\nthe learned representations towards a more meaningful arrangement in space.\nSecond, VBN represents entities by densities (rather than vectors), hence\nmodeling uncertainty that plays a complementary role in coping with data\nscarcity. Finally, we propose a scalable Variational Bayes optimization\nalgorithm that enables fast approximate Bayesian inference. We evaluate the\neffectiveness of VBN on linguistic, recommendations, and medical inference\ntasks. Our findings show that VBN outperforms other existing methods across\nmultiple datasets, and especially in the long-tail.",
        "translated": "我们提出了变分贝氏网路(vbN)——一种新的贝叶斯实体表示学习模型，它利用了层次和关系侧信息，特别适用于数据稀缺的“长尾”实体建模。VBN 通过两种互补的机制为长尾实体提供了更好的建模: 首先，VBN 使用了信息丰富的层次先验，这使得共享共同祖先的实体之间的信息传播成为可能。此外，VBN 模型明确的实体之间的关系，强制互补结构和一致性，指导学习表示更有意义的安排在空间。其次，VBN 通过密度(而不是向量)表示实体，因此建模不确定性在处理数据稀缺性方面起到补充作用。最后，我们提出了一个可扩展的变分贝叶斯优化算法，它可以实现快速的近似贝叶斯推断。我们评估 VBN 在语言、推荐和医学推理任务中的有效性。我们的研究结果表明，VBN 在跨多个数据集的性能优于其他现有的方法，特别是在长尾方面。"
    },
    {
        "title": "Taqyim: Evaluating Arabic NLP Tasks Using ChatGPT Models",
        "url": "http://arxiv.org/abs/2306.16322v1",
        "pub_date": "2023-06-28",
        "summary": "Large language models (LLMs) have demonstrated impressive performance on\nvarious downstream tasks without requiring fine-tuning, including ChatGPT, a\nchat-based model built on top of LLMs such as GPT-3.5 and GPT-4. Despite having\na lower training proportion compared to English, these models also exhibit\nremarkable capabilities in other languages. In this study, we assess the\nperformance of GPT-3.5 and GPT-4 models on seven distinct Arabic NLP tasks:\nsentiment analysis, translation, transliteration, paraphrasing, part of speech\ntagging, summarization, and diacritization. Our findings reveal that GPT-4\noutperforms GPT-3.5 on five out of the seven tasks. Furthermore, we conduct an\nextensive analysis of the sentiment analysis task, providing insights into how\nLLMs achieve exceptional results on a challenging dialectal dataset.\nAdditionally, we introduce a new Python interface\nhttps://github.com/ARBML/Taqyim that facilitates the evaluation of these tasks\neffortlessly.",
        "translated": "大型语言模型(LLM)已经在不需要微调的各种下游任务上展示了令人印象深刻的性能，包括 ChatGPT，一种基于聊天的模型，建立在 LLM 之上，如 GPT-3.5和 GPT-4。尽管与英语相比，这些模式的训练比例较低，但它们在其他语言方面也表现出显著的能力。在这项研究中，我们评估了 GPT-3.5和 GPT-4模型在七个不同的阿拉伯语 NLP 任务中的表现: 情感分析，翻译，音译，释义，部分语音标签，摘要和非字符化。我们的研究结果表明，GPT-4在七项任务中的五项上表现优于 GPT-3.5。此外，我们进行了广泛的情绪分析任务的分析，提供深入的见解，如何实现一个具有挑战性的方言数据集 LLM 异常的结果。此外，我们还引入了一个新的 Python 界面 https://github.com/arbml/taqyim  ，可以轻松地评估这些任务。"
    },
    {
        "title": "An Adversarial Multi-Task Learning Method for Chinese Text Correction\n  with Semantic Detection",
        "url": "http://arxiv.org/abs/2306.16313v1",
        "pub_date": "2023-06-28",
        "summary": "Text correction, especially the semantic correction of more widely used\nscenes, is strongly required to improve, for the fluency and writing efficiency\nof the text. An adversarial multi-task learning method is proposed to enhance\nthe modeling and detection ability of character polysemy in Chinese sentence\ncontext. Wherein, two models, the masked language model and scoring language\nmodel, are introduced as a pair of not only coupled but also adversarial\nlearning tasks. Moreover, the Monte Carlo tree search strategy and a policy\nnetwork are introduced to accomplish the efficient Chinese text correction task\nwith semantic detection. The experiments are executed on three datasets and\nfive comparable methods, and the experimental results show that our method can\nobtain good performance in Chinese text correction task for better semantic\nrationality.",
        "translated": "为了提高文本的流畅性和写作效率，文本校正尤其是应用较为广泛的场景的语义校正是亟待提高的。提出了一种对抗性多任务学习方法，以提高汉语句子语境中字符多义现象的建模和检测能力。其中，两个模型，掩蔽语言模型和评分语言模型，被引入作为一对不仅是耦合的，而且是对抗性的学习任务。此外，引入了蒙特卡罗树搜索策略和策略网络，实现了具有语义检测的高效中文文本校正任务。实验结果表明，该方法在中文文本校正任务中能够取得较好的效果，具有较好的语义合理性。"
    },
    {
        "title": "Leveraging GPT-4 for Food Effect Summarization to Enhance\n  Product-Specific Guidance Development via Iterative Prompting",
        "url": "http://arxiv.org/abs/2306.16275v1",
        "pub_date": "2023-06-28",
        "summary": "Food effect summarization from New Drug Application (NDA) is an essential\ncomponent of product-specific guidance (PSG) development and assessment.\nHowever, manual summarization of food effect from extensive drug application\nreview documents is time-consuming, which arouses a need to develop automated\nmethods. Recent advances in large language models (LLMs) such as ChatGPT and\nGPT-4, have demonstrated great potential in improving the effectiveness of\nautomated text summarization, but its ability regarding the accuracy in\nsummarizing food effect for PSG assessment remains unclear. In this study, we\nintroduce a simple yet effective approach, iterative prompting, which allows\none to interact with ChatGPT or GPT-4 more effectively and efficiently through\nmulti-turn interaction. Specifically, we propose a three-turn iterative\nprompting approach to food effect summarization in which the keyword-focused\nand length-controlled prompts are respectively provided in consecutive turns to\nrefine the quality of the generated summary. We conduct a series of extensive\nevaluations, ranging from automated metrics to FDA professionals and even\nevaluation by GPT-4, on 100 NDA review documents selected over the past five\nyears. We observe that the summary quality is progressively improved throughout\nthe process. Moreover, we find that GPT-4 performs better than ChatGPT, as\nevaluated by FDA professionals (43% vs. 12%) and GPT-4 (64% vs. 35%).\nImportantly, all the FDA professionals unanimously rated that 85% of the\nsummaries generated by GPT-4 are factually consistent with the golden reference\nsummary, a finding further supported by GPT-4 rating of 72% consistency. These\nresults strongly suggest a great potential for GPT-4 to draft food effect\nsummaries that could be reviewed by FDA professionals, thereby improving the\nefficiency of PSG assessment cycle and promoting the generic drug product\ndevelopment.",
        "translated": "新药应用中的食品效果总结是产品特异性指导(PSG)开发和评估的重要组成部分。然而，从广泛的药物应用审查文件中手工总结食品效应是一项耗时的工作，这就引起了开发自动化方法的需要。ChatGPT 和 GPT-4等大型语言模型(LLM)的最新进展显示了提高自动文本摘要有效性的巨大潜力，但其在总结 PSG 评估的食物效应准确性方面的能力尚不清楚。在这项研究中，我们介绍了一个简单而有效的方法，迭代提示，它允许一个人与 ChatGPT 或 GPT-4交互更有效和高效地通过多回合的交互。具体而言，我们提出了一种三回合迭代提示方法来进行食物效果总结，其中关键字重点和长度控制的提示分别在连续的回合中提供，以完善生成的总结的质量。我们进行了一系列广泛的评估，从自动化指标到 FDA 专业人员，甚至 GPT-4的评估，对过去五年中选定的100个 NDA 审查文件进行评估。我们观察到总结质量在整个过程中逐步得到改进。此外，我们发现 GPT-4的表现优于 ChatGPT，FDA 专业人员对此进行了评估(43% 比12%)和 GPT-4(64% 比35%)。重要的是，所有 FDA 专业人员一致认为 GPT-4产生的总结中有85% 与黄金参考总结实际上是一致的，这一发现得到了 GPT-4评分72% 一致性的进一步支持。这些结果强烈表明 GPT-4起草可供 FDA 专业人员审查的食品效应摘要的巨大潜力，从而提高 PSG 评估周期的效率，促进仿制药产品的开发。"
    },
    {
        "title": "Emotion Analysis of Tweets Banning Education in Afghanistan",
        "url": "http://arxiv.org/abs/2306.16268v1",
        "pub_date": "2023-06-28",
        "summary": "This paper introduces the first emotion annotated dataset for the Dari\nvariant of Persian spoken in Afghanistan. The LetHerLearn dataset contains\n7,600 tweets posted in reaction to the Taliban ban of women rights to education\nin 2022 and has been manually annotated according to Ekman emotion categories.\nWe here detail the data collection and annotation process, present relevant\ndataset statistics as well as initial experiments on the resulting dataset,\nbenchmarking a number of different neural architectures for the task of Dari\nemotion classification.",
        "translated": "本文介绍了第一个情绪注释数据集的达日变体的波斯语在阿富汗说。LetHerLearning 数据集包含7,600条针对塔利班2022年禁止妇女接受教育权而发布的推文，并根据 Ekman 情绪类别进行了人工注释。我们在这里详细介绍数据收集和注释的过程，提供相关的数据集统计数据，以及最终数据集的初步实验，并为达日情绪分类的任务建立了多种不同的神经结构。"
    },
    {
        "title": "CBBQ: A Chinese Bias Benchmark Dataset Curated with Human-AI\n  Collaboration for Large Language Models",
        "url": "http://arxiv.org/abs/2306.16244v1",
        "pub_date": "2023-06-28",
        "summary": "Holistically measuring societal biases of large language models is crucial\nfor detecting and reducing ethical risks in highly capable AI models. In this\nwork, we present a Chinese Bias Benchmark dataset that consists of over 100K\nquestions jointly constructed by human experts and generative language models,\ncovering stereotypes and societal biases in 14 social dimensions related to\nChinese culture and values. The curation process contains 4 essential steps:\nbias identification via extensive literature review, ambiguous context\ngeneration, AI-assisted disambiguous context generation, snd manual review \\&amp;\nrecomposition. The testing instances in the dataset are automatically derived\nfrom 3K+ high-quality templates manually authored with stringent quality\ncontrol. The dataset exhibits wide coverage and high diversity. Extensive\nexperiments demonstrate the effectiveness of the dataset in detecting model\nbias, with all 10 publicly available Chinese large language models exhibiting\nstrong bias in certain categories. Additionally, we observe from our\nexperiments that fine-tuned models could, to a certain extent, heed\ninstructions and avoid generating outputs that are morally harmful in some\ntypes, in the way of \"moral self-correction\". Our dataset and results are\npublicly available at\n\\href{https://github.com/YFHuangxxxx/CBBQ}{https://github.com/YFHuangxxxx/CBBQ},\noffering debiasing research opportunities to a widened community.",
        "translated": "全面衡量大型语言模型的社会偏见对于发现和减少高能人工智能模型中的伦理风险至关重要。在这项工作中，我们提出了一个中国偏见基准数据集，由人类专家和生成语言模型共同构建的超过10万个问题，涵盖了与中国文化和价值观相关的14个社会维度的刻板印象和社会偏见。策划过程包括4个基本步骤: 通过广泛的文献综述进行偏倚识别、模糊上下文生成、人工智能辅助的模糊上下文生成、以及人工审查和重组。数据集中的测试实例是自动从3K + 高质量模板中派生出来的，这些模板是通过严格的质量控制手工编写的。该数据集具有广泛的覆盖面和高度的多样性。大量的实验证明了该数据集在检测模型偏差方面的有效性，所有10个公开的中文大语言模型在某些类别中表现出强烈的偏差。此外，我们从实验中观察到，微调模型可以在一定程度上听从指令，避免产生在某些类型中对道德有害的输出，即“道德自我纠正”。我们的数据集和结果可以在 href { https://github.com/yfhuangxxxx/cbbq }{ https://github.com/yfhuangxxxx/cbbq }上公开获得，为更广泛的社区提供了减少偏见的研究机会。"
    },
    {
        "title": "Ducho: A Unified Framework for the Extraction of Multimodal Features in\n  Recommendation",
        "url": "http://arxiv.org/abs/2306.17125v1",
        "pub_date": "2023-06-29",
        "summary": "In multimodal-aware recommendation, the extraction of meaningful multimodal\nfeatures is at the basis of high-quality recommendations. Generally, each\nrecommendation framework implements its multimodal extraction procedures with\nspecific strategies and tools. This is limiting for two reasons: (i) different\nextraction strategies do not ease the interdependence among multimodal\nrecommendation frameworks; thus, they cannot be efficiently and fairly\ncompared; (ii) given the large plethora of pre-trained deep learning models\nmade available by different open source tools, model designers do not have\naccess to shared interfaces to extract features. Motivated by the outlined\naspects, we propose Ducho, a unified framework for the extraction of multimodal\nfeatures in recommendation. By integrating three widely-adopted deep learning\nlibraries as backends, namely, TensorFlow, PyTorch, and Transformers, we\nprovide a shared interface to extract and process features where each backend's\nspecific methods are abstracted to the end user. Noteworthy, the extraction\npipeline is easily configurable with a YAML-based file where the user can\nspecify, for each modality, the list of models (and their specific\nbackends/parameters) to perform the extraction. Finally, to make Ducho\naccessible to the community, we build a public Docker image equipped with a\nready-to-use CUDA environment and propose three demos to test its\nfunctionalities for different scenarios and tasks. The GitHub repository and\nthe documentation is accessible at this link:\nhttps://github.com/sisinflab/Ducho.",
        "translated": "在多模态推荐中，有意义的多模态特征的提取是高质量推荐的基础。通常，每个推荐框架使用特定的策略和工具实现其多模式提取过程。这种限制有两个原因: (i)不同的提取策略不能缓解多模式推荐框架之间的相互依赖性; 因此，它们不能有效和公平地进行比较; (ii)鉴于由不同的开源工具提供的大量预先训练的深度学习模型，模型设计者没有访问共享接口来提取特征。基于这些方面，我们提出了 Ducho，一个用于提取推荐中的多模态特征的统一框架。通过集成三个广泛采用的深度学习库作为后端，即 TensorFlow、 PyTorch 和 Transformers，我们提供了一个共享接口来提取和处理特性，其中每个后端的特定方法被抽象到最终用户。值得注意的是，提取管道很容易用基于 YAML 的文件进行配置，用户可以在该文件中为每种模式指定执行提取的模型列表(及其特定的后端/参数)。最后，为了使 Ducho 能够被社区所接受，我们建立了一个公共的 Docker 图像，配备了一个可以随时使用的 CUDA 环境，并提出了三个演示来测试它在不同场景和任务中的功能。GitHub 存储库和文档可以通过以下链接访问:  https://GitHub.com/sisinflab/ducho。"
    },
    {
        "title": "Re-Rank - Expand - Repeat: Adaptive Query Expansion for Document\n  Retrieval Using Words and Entities",
        "url": "http://arxiv.org/abs/2306.17082v1",
        "pub_date": "2023-06-29",
        "summary": "Sparse and dense pseudo-relevance feedback (PRF) approaches perform poorly on\nchallenging queries due to low precision in first-pass retrieval. However,\nrecent advances in neural language models (NLMs) can re-rank relevant documents\nto top ranks, even when few are in the re-ranking pool. This paper first\naddresses the problem of poor pseudo-relevance feedback by simply applying\nre-ranking prior to query expansion and re-executing this query. We find that\nthis change alone can improve the retrieval effectiveness of sparse and dense\nPRF approaches by 5-8%. Going further, we propose a new expansion model, Latent\nEntity Expansion (LEE), a fine-grained word and entity-based relevance\nmodelling incorporating localized features. Finally, we include an \"adaptive\"\ncomponent to the retrieval process, which iteratively refines the re-ranking\npool during scoring using the expansion model, i.e. we \"re-rank - expand -\nrepeat\". Using LEE, we achieve (to our knowledge) the best NDCG, MAP and R@1000\nresults on the TREC Robust 2004 and CODEC adhoc document datasets,\ndemonstrating a significant advancement in expansion effectiveness.",
        "translated": "稀疏和密集伪相关反馈(PRF)方法在挑战性查询中表现不佳，这是由于首次检索的精度较低。然而，神经语言模型(NLM)的最新进展可以将相关文档重新排列到最高级别，即使重新排列的文档很少。本文首先通过简单地在查询扩展之前重新排序并重新执行查询，解决了伪相关反馈较差的问题。我们发现单独这种改变可以提高稀疏和密集 PRF 方法的检索效率5-8% 。进一步，我们提出了一个新的扩展模型，潜在的实体扩展(LEE) ，一个细粒度的词和基于实体的相关性建模结合本地化特征。最后，我们在检索过程中加入了一个“自适应”组件，该组件在使用扩展模型进行评分期间迭代地改进重新排序池，即我们“重新排序-扩展-重复”。使用 LEE，我们在 TREC Robust 2004和 CODEC 特设文档数据集上获得了(据我们所知)最好的 NDCG，MAP 和 R@1000结果，表明在扩展有效性方面取得了显着进展。"
    },
    {
        "title": "Harnessing the Power of Hugging Face Transformers for Predicting Mental\n  Health Disorders in Social Networks",
        "url": "http://arxiv.org/abs/2306.16891v1",
        "pub_date": "2023-06-29",
        "summary": "Early diagnosis of mental disorders and intervention can facilitate the\nprevention of severe injuries and the improvement of treatment results. Using\nsocial media and pre-trained language models, this study explores how\nuser-generated data can be used to predict mental disorder symptoms. Our study\ncompares four different BERT models of Hugging Face with standard machine\nlearning techniques used in automatic depression diagnosis in recent\nliterature. The results show that new models outperform the previous approach\nwith an accuracy rate of up to 97%. Analyzing the results while complementing\npast findings, we find that even tiny amounts of data (like users' bio\ndescriptions) have the potential to predict mental disorders. We conclude that\nsocial media data is an excellent source of mental health screening, and\npre-trained models can effectively automate this critical task.",
        "translated": "对精神障碍的早期诊断和干预有助于预防严重创伤，提高治疗效果。利用社会媒体和预先训练的语言模型，这项研究探讨了如何使用用户生成的数据可以用来预测精神障碍症状。本研究比较了近年来文献中用于抑郁症自动诊断的标准机器学习技术和四种不同的“拥抱脸”BERT 模型。结果表明，新的模型优于以前的方法，准确率高达97% 。分析结果，同时补充过去的发现，我们发现，即使是微量的数据(如用户的生物描述)有可能预测精神障碍。我们的结论是，社会媒体数据是一个良好的来源，心理健康筛查，并预先训练的模型可以有效地自动化这一关键任务。"
    },
    {
        "title": "Computing all-vs-all MEMs in grammar-compressed text",
        "url": "http://arxiv.org/abs/2306.16815v1",
        "pub_date": "2023-06-29",
        "summary": "We describe a compression-aware method to compute all-vs-all maximal exact\nmatches (MEM) among strings of a repetitive collection $\\mathcal{T}$. The key\nconcept in our work is the construction of a fully-balanced grammar\n$\\mathcal{G}$ from $\\mathcal{T}$ that meets a property that we call\n\\emph{fix-free}: the expansions of the nonterminals that have the same height\nin the parse tree form a fix-free set (i.e., prefix-free and suffix-free). The\nfix-free property allows us to compute the MEMs of $\\mathcal{T}$ incrementally\nover $\\mathcal{G}$ using a standard suffix-tree-based MEM algorithm, which runs\non a subset of grammar rules at a time and does not decompress nonterminals. By\nmodifying the locally-consistent grammar of Christiansen et al 2020., we show\nhow we can build $\\mathcal{G}$ from $\\mathcal{T}$ in linear time and space. We\nalso demonstrate that our MEM algorithm runs on top of $\\mathcal{G}$ in $O(G\n+occ)$ time and uses $O(\\log G(G+occ))$ bits, where $G$ is the grammar size,\nand $occ$ is the number of MEMs in $\\mathcal{T}$. In the conclusions, we\ndiscuss how our idea can be modified to implement approximate pattern matching\nin compressed space.",
        "translated": "我们描述了一种感知压缩的方法来计算重复集合 $mathcal { T } $的字符串之间的全对全最大精确匹配(MEM)。我们工作中的关键概念是构造一个完全平衡的文法 $mathcal { G } $，它满足我们称之为 emph { fix-free }的属性: 在解析树中具有相同高度的非终端的扩展形成一个 fix-free 集(即，无前缀和无后缀)。无修复特性允许我们使用基于后缀树的标准 MEM 算法来计算 $mathcal { T } $在 $mathcal { G } $上的 MEM，该算法一次运行在一个语法规则子集上，并且不对非终端进行解压缩。通过修改 Christiansen 等人2020年的局部一致性语法。，我们展示了如何在线性时间和空间中从 $mathcal { T } $构建 $mathcal { G } $。我们还演示了我们的 MEM 算法在 $O (G + occ) $time 中运行在 $mathcal { G } $之上，并使用 $O (log G (G + occ)) $bit，其中 $G $是文法大小，$occ $是 $mathal { T } $中的 MEM 数目。在结论中，我们讨论了如何修改我们的想法以在压缩空间中实现近似模式匹配。"
    },
    {
        "title": "Transfer Learning with Semi-Supervised Dataset Annotation for Birdcall\n  Classification",
        "url": "http://arxiv.org/abs/2306.16760v1",
        "pub_date": "2023-06-29",
        "summary": "We present working notes on transfer learning with semi-supervised dataset\nannotation for the BirdCLEF 2023 competition, focused on identifying African\nbird species in recorded soundscapes. Our approach utilizes existing\noff-the-shelf models, BirdNET and MixIT, to address representation and labeling\nchallenges in the competition. We explore the embedding space learned by\nBirdNET and propose a process to derive an annotated dataset for supervised\nlearning. Our experiments involve various models and feature engineering\napproaches to maximize performance on the competition leaderboard. The results\ndemonstrate the effectiveness of our approach in classifying bird species and\nhighlight the potential of transfer learning and semi-supervised dataset\nannotation in similar tasks.",
        "translated": "我们为 BirdCLEF 2023比赛提交了关于半监督数据集注释的迁移学习的工作笔记，重点是在录制的音景中识别非洲鸟类物种。我们的方法利用现有的现成模型，BirdNET 和 MixIT，来解决竞争中的表示和标签挑战。我们探索了 BirdNET 学到的嵌入空间，并提出了一个为监督式学习推导注释数据集的过程。我们的实验包括各种模型和特征工程方法，以最大限度地提高在竞争排行榜上的表现。实验结果表明了该方法在鸟类分类中的有效性，并突出了转移学习和半监督数据集注释在类似任务中的潜力。"
    },
    {
        "title": "Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4,\n  and Human Tutors",
        "url": "http://arxiv.org/abs/2306.17156v1",
        "pub_date": "2023-06-29",
        "summary": "Generative AI and large language models hold great promise in enhancing\ncomputing education by powering next-generation educational technologies for\nintroductory programming. Recent works have studied these models for different\nscenarios relevant to programming education; however, these works are limited\nfor several reasons, as they typically consider already outdated models or only\nspecific scenario(s). Consequently, there is a lack of a systematic study that\nbenchmarks state-of-the-art models for a comprehensive set of programming\neducation scenarios. In our work, we systematically evaluate two models,\nChatGPT (based on GPT-3.5) and GPT-4, and compare their performance with human\ntutors for a variety of scenarios. We evaluate using five introductory Python\nprogramming problems and real-world buggy programs from an online platform, and\nassess performance using expert-based annotations. Our results show that GPT-4\ndrastically outperforms ChatGPT (based on GPT-3.5) and comes close to human\ntutors' performance for several scenarios. These results also highlight\nsettings where GPT-4 still struggles, providing exciting future directions on\ndeveloping techniques to improve the performance of these models.",
        "translated": "生成式人工智能和大型语言模型为下一代教育技术的入门编程提供动力，从而在加强计算机教育方面具有巨大的前景。最近的工作已经针对与编程教育相关的不同场景研究了这些模型; 然而，这些工作由于几个原因而受到限制，因为它们通常考虑已经过时的模型或者只考虑特定的场景。因此，缺乏一个系统的研究，基准国家的最先进的模型为一套全面的编程教育情景。在我们的工作中，我们系统地评估了两个模型，ChatGPT (基于 GPT-3.5)和 GPT-4，并比较了它们在各种情景下与人类导师的表现。我们使用五个入门级 Python 编程问题和来自在线平台的实际 bug 程序进行评估，并使用基于专家的注释评估性能。我们的研究结果表明，GPT-4的性能显著优于 ChatGPT (基于 GPT-3.5) ，并且在几种情况下接近于人类导师的性能。这些结果也突出了 GPT-4仍在努力的设置，为开发技术以改善这些模型的性能提供了令人兴奋的未来方向。"
    },
    {
        "title": "LLaVAR: Enhanced Visual Instruction Tuning for Text-Rich Image\n  Understanding",
        "url": "http://arxiv.org/abs/2306.17107v1",
        "pub_date": "2023-06-29",
        "summary": "Instruction tuning unlocks the superior capability of Large Language Models\n(LLM) to interact with humans. Furthermore, recent instruction-following\ndatasets include images as visual inputs, collecting responses for image-based\ninstructions. However, visual instruction-tuned models cannot comprehend\ntextual details within images well. This work enhances the current visual\ninstruction tuning pipeline with text-rich images (e.g., movie posters, book\ncovers, etc.). Specifically, we first use publicly available OCR tools to\ncollect results on 422K text-rich images from the LAION dataset. Moreover, we\nprompt text-only GPT-4 with recognized texts and image captions to generate 16K\nconversations, each containing question-answer pairs for text-rich images. By\ncombining our collected data with previous multi-modal instruction-following\ndata, our model, LLaVAR, substantially improves the LLaVA model's capability on\ntext-based VQA datasets (up to 20% accuracy improvement) while achieving an\naccuracy of 91.42% on ScienceQA. The GPT-4-based instruction-following\nevaluation also demonstrates the improvement of our model on both natural\nimages and text-rich images. Through qualitative analysis, LLaVAR shows\npromising interaction (e.g., reasoning, writing, and elaboration) skills with\nhumans based on the latest real-world online content that combines text and\nimages. We make our code/data/models publicly available at\nhttps://llavar.github.io/.",
        "translated": "指令调优解锁了大型语言模型(LLM)与人类交互的优越能力。此外，最近的指令跟踪数据集包括图像作为视觉输入，收集基于图像的指令的响应。然而，视觉教学调优模型不能很好地理解图像中的文本细节。这项工作通过文本丰富的图像(例如，电影海报、书籍封面等)增强了当前的可视化教学调优流程。具体来说，我们首先使用公开可用的 OCR 工具从 LAION 数据集中收集422K 文本丰富的图像的结果。此外，我们提示只有文本的 GPT-4与可识别的文本和图像标题生成16K 会话，每个包含文本丰富的图像的问题-答案对。通过将我们收集的数据与以前的多模态指令跟踪数据相结合，我们的模型 LLaVAR 大大提高了 LLaVA 模型对基于文本的 VQA 数据集的能力(提高了20% 的准确性) ，同时在 ScienceQA 上实现了91.42% 的准确性。基于 GPT-4的指令跟踪评估也证明了该模型对自然图像和文本丰富图像的改进。通过定性分析，LLaVAR 展示了基于结合文本和图像的最新现实世界在线内容与人类的互动(例如，推理、写作和阐述)技能。我们把我们的代码/数据/模型在 https://llavar.github.io/上公开。"
    },
    {
        "title": "LyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by\n  Whispering to ChatGPT",
        "url": "http://arxiv.org/abs/2306.17103v1",
        "pub_date": "2023-06-29",
        "summary": "We introduce LyricWhiz, a robust, multilingual, and zero-shot automatic\nlyrics transcription method achieving state-of-the-art performance on various\nlyrics transcription datasets, even in challenging genres such as rock and\nmetal. Our novel, training-free approach utilizes Whisper, a weakly supervised\nrobust speech recognition model, and GPT-4, today's most performant chat-based\nlarge language model. In the proposed method, Whisper functions as the \"ear\" by\ntranscribing the audio, while GPT-4 serves as the \"brain,\" acting as an\nannotator with a strong performance for contextualized output selection and\ncorrection. Our experiments show that LyricWhiz significantly reduces Word\nError Rate compared to existing methods in English and can effectively\ntranscribe lyrics across multiple languages. Furthermore, we use LyricWhiz to\ncreate the first publicly available, large-scale, multilingual lyrics\ntranscription dataset with a CC-BY-NC-SA copyright license, based on\nMTG-Jamendo, and offer a human-annotated subset for noise level estimation and\nevaluation. We anticipate that our proposed method and dataset will advance the\ndevelopment of multilingual lyrics transcription, a challenging and emerging\ntask.",
        "translated": "我们介绍 LyricWhiz，一个强大的，多语言，和零拍摄自动歌词转录方法实现最先进的表现在各种歌词转录数据集，甚至在具有挑战性的流派，如摇滚和金属。我们新颖的、无需训练的方法使用了 Whisper (一种弱监督的鲁棒语音识别模型)和 GPT-4(当今最高性能的基于聊天的大型语言模型)。在提出的方法中，Whisper 通过转录音频作为“耳朵”，而 GPT-4作为“大脑”，充当注释器，具有很强的上下文输出选择和校正性能。我们的实验表明，与现有的英语方法相比，LyricWhiz 显著降低了单词错误率，并能有效地转录多种语言的歌词。此外，我们使用 LyricWhiz 创建第一个公开可用的，大规模的，多语言的歌词转录数据集，具有 CC-BY-NC-SA 版权许可，基于 MTG-Jamendo，并提供用于噪声水平估计和评估的人类注释子集。我们期望我们提出的方法和数据集将推动多语言歌词转录的发展，这是一个具有挑战性和新兴的任务。"
    },
    {
        "title": "Concept-Oriented Deep Learning with Large Language Models",
        "url": "http://arxiv.org/abs/2306.17089v1",
        "pub_date": "2023-06-29",
        "summary": "Large Language Models (LLMs) have been successfully used in many\nnatural-language tasks and applications including text generation and AI\nchatbots. They also are a promising new technology for concept-oriented deep\nlearning (CODL). However, the prerequisite is that LLMs understand concepts and\nensure conceptual consistency. We discuss these in this paper, as well as major\nuses of LLMs for CODL including concept extraction from text, concept graph\nextraction from text, and concept learning. Human knowledge consists of both\nsymbolic (conceptual) knowledge and embodied (sensory) knowledge. Text-only\nLLMs, however, can represent only symbolic (conceptual) knowledge. Multimodal\nLLMs, on the other hand, are capable of representing the full range (conceptual\nand sensory) of human knowledge. We discuss conceptual understanding in\nvisual-language LLMs, the most important multimodal LLMs, and major uses of\nthem for CODL including concept extraction from image, concept graph extraction\nfrom image, and concept learning. While uses of LLMs for CODL are valuable\nstandalone, they are particularly valuable as part of LLM applications such as\nAI chatbots.",
        "translated": "大语言模型(LLM)已经成功地应用于许多自然语言任务和应用中，包括文本生成和人工智能聊天机器人。它们也是面向概念的深度学习(CODL)的一种有前途的新技术。然而，前提是 LLM 理解概念并确保概念的一致性。本文讨论了这些问题，以及 LLM 在 CODL 中的主要应用，包括从文本中提取概念，从文本中提取概念图，以及概念学习。人类知识包括符号(概念)知识和体现(感官)知识。然而，纯文本 LLM 只能表示符号(概念)知识。另一方面，多模式 LLM 能够表示人类知识的全部范围(概念和感官)。本文讨论了可视化语言 LLM 中的概念理解，即最重要的多模态 LLM，以及它们在 CODL 中的主要应用，包括从图像中提取概念、从图像中提取概念图和概念学习。虽然对 CODL 使用 LLM 是有价值的独立使用，但作为 LLM 应用程序(如 AI 聊天机器人)的一部分，它们尤其有价值。"
    },
    {
        "title": "The mapKurator System: A Complete Pipeline for Extracting and Linking\n  Text from Historical Maps",
        "url": "http://arxiv.org/abs/2306.17059v1",
        "pub_date": "2023-06-29",
        "summary": "Documents hold spatial focus and valuable locality characteristics. For\nexample, descriptions of listings in real estate or travel blogs contain\ninformation about specific local neighborhoods. This information is valuable to\ncharacterize how humans perceive their environment. However, the first step to\nmaking use of this information is to identify the spatial focus (e.g., a city)\nof a document. Traditional approaches for identifying the spatial focus of a\ndocument rely on detecting and disambiguating toponyms from the document. This\napproach requires a vocabulary set of location phrases and ad-hoc rules, which\nignore important words related to location. Recent topic modeling approaches\nusing large language models often consider a few topics, each with broad\ncoverage. In contrast, the spatial focus of a document can be a country, a\ncity, or even a neighborhood, which together, is much larger than the number of\ntopics considered in these approaches. Additionally, topic modeling methods are\noften applied to broad topics of news articles where context is easily\ndistinguishable. To identify the geographic focus of a document effectively, we\npresent a simple but effective Joint Embedding of multi-LocaLitY (JELLY), which\njointly learns representations with separate encoders of document and location.\nJELLY significantly outperforms state-of-the-art methods for identifying\nspatial focus from documents from a number of sources. We also demonstrate case\nstudies on the arithmetic of the learned representations, including identifying\ncities with similar locality characteristics and zero-shot learning to identify\ndocument spatial focus.",
        "translated": "文献具有空间聚焦性和地域性特征。例如，房地产或旅游博客中的列表描述包含有关特定当地社区的信息。这些信息对于描述人类如何感知周围环境很有价值。然而，利用这些信息的第一步是识别文档的空间焦点(例如，城市)。确定文件空间重点的传统方法依赖于从文件中检测和消除地名的歧义。这种方法需要一组位置短语和特别规则，这些规则忽略与位置相关的重要词汇。最近使用大型语言模型的主题建模方法通常考虑几个主题，每个主题都有广泛的涵盖范围。相比之下，一个文档的空间焦点可以是一个国家、一个城市，甚至是一个社区，它们加在一起要比这些方法中考虑的主题数量大得多。此外，主题建模方法通常应用于新闻文章中容易区分上下文的广泛主题。为了有效地识别文档的地理焦点，我们提出了一种简单而有效的多 LocaLitY (JELLY)联合嵌入方法，它通过文档和位置的单独编码器共同学习表示。JELLY 在从多个来源的文档中识别空间焦点方面的性能明显优于最先进的方法。我们还展示了学习表征算法的案例研究，包括识别具有相似地域特征的城市和零点学习识别文档空间焦点。"
    },
    {
        "title": "Towards Grammatical Tagging for the Legal Language of Cybersecurity",
        "url": "http://arxiv.org/abs/2306.17042v1",
        "pub_date": "2023-06-29",
        "summary": "Legal language can be understood as the language typically used by those\nengaged in the legal profession and, as such, it may come both in spoken or\nwritten form. Recent legislation on cybersecurity obviously uses legal language\nin writing, thus inheriting all its interpretative complications due to the\ntypical abundance of cases and sub-cases as well as to the general richness in\ndetail. This paper faces the challenge of the essential interpretation of the\nlegal language of cybersecurity, namely of the extraction of the essential\nParts of Speech (POS) from the legal documents concerning cybersecurity. The\nchallenge is overcome by our methodology for POS tagging of legal language. It\nleverages state-of-the-art open-source tools for Natural Language Processing\n(NLP) as well as manual analysis to validate the outcomes of the tools. As a\nresult, the methodology is automated and, arguably, general for any legal\nlanguage following minor tailoring of the preprocessing step. It is\ndemonstrated over the most relevant EU legislation on cybersecurity, namely on\nthe NIS 2 directive, producing the first, albeit essential, structured\ninterpretation of such a relevant document. Moreover, our findings indicate\nthat tools such as SpaCy and ClausIE reach their limits over the legal language\nof the NIS 2.",
        "translated": "法律语言可以被理解为从事法律职业的人通常使用的语言，因此，它可以是口头或书面形式。最近关于网络安全的立法显然使用了书面法律语言，从而继承了其所有解释性复杂性，这是由于典型的大量案例和子案例以及一般丰富的细节。本文面临着网络安全法律语言本质解释的挑战，即从网络安全法律文书中提取本质词语。我们的法律语言词性标注方法克服了这一挑战。它利用最先进的自然语言处理(NLP)开源工具以及手工分析来验证工具的结果。因此，这种方法是自动的，而且可以说，对于预处理步骤进行了少量裁剪之后的任何法律语言都是通用的。它体现在欧盟最相关的网络安全立法，即 NIS 2指令上，产生了对这样一个相关文件的第一个，尽管是必要的，结构化的解释。此外，我们的研究结果表明，工具，如 SpaCy 和 ClausIE 达到他们的限制，在法律语言的 NIS 2。"
    },
    {
        "title": "Exploring &amp; Exploiting High-Order Graph Structure for Sparse Knowledge\n  Graph Completion",
        "url": "http://arxiv.org/abs/2306.17034v1",
        "pub_date": "2023-06-29",
        "summary": "Sparse knowledge graph (KG) scenarios pose a challenge for previous Knowledge\nGraph Completion (KGC) methods, that is, the completion performance decreases\nrapidly with the increase of graph sparsity. This problem is also exacerbated\nbecause of the widespread existence of sparse KGs in practical applications. To\nalleviate this challenge, we present a novel framework, LR-GCN, that is able to\nautomatically capture valuable long-range dependency among entities to\nsupplement insufficient structure features and distill logical reasoning\nknowledge for sparse KGC. The proposed approach comprises two main components:\na GNN-based predictor and a reasoning path distiller. The reasoning path\ndistiller explores high-order graph structures such as reasoning paths and\nencodes them as rich-semantic edges, explicitly compositing long-range\ndependencies into the predictor. This step also plays an essential role in\ndensifying KGs, effectively alleviating the sparse issue. Furthermore, the path\ndistiller further distills logical reasoning knowledge from these mined\nreasoning paths into the predictor. These two components are jointly optimized\nusing a well-designed variational EM algorithm. Extensive experiments and\nanalyses on four sparse benchmarks demonstrate the effectiveness of our\nproposed method.",
        "translated": "稀疏知识图(KG)场景对以往的知识图完成(KGC)方法提出了挑战，即随着图稀疏度的增加，完成性能迅速下降。由于实际应用中普遍存在稀疏的幼稚园，这个问题更加严重。为了缓解这一挑战，我们提出了一个新的框架，LR-gcn，它能够自动捕获实体之间有价值的长期依赖，以补充不足的结构特征，并提取稀疏的逻辑推理知识。该方法包括两个主要部分: 基于 GNN 的预测器和推理路径提取器。推理路径提取器探索诸如推理路径之类的高阶图结构，并将它们编码为丰富的语义边，显式地将远程依赖组合到预测器中。此步骤亦有助增加幼稚园的密度，有效纾缓幼稚园人口稀少的问题。此外，路径蒸馏器进一步从这些挖掘的推理路径中提取逻辑推理知识到预测器中。这两个部分共同优化使用良好设计的变分 EM 算法。通过对四个稀疏基准测试的大量实验和分析，证明了该方法的有效性。"
    },
    {
        "title": "Classifying Crime Types using Judgment Documents from Social Media",
        "url": "http://arxiv.org/abs/2306.17020v1",
        "pub_date": "2023-06-29",
        "summary": "The task of determining crime types based on criminal behavior facts has\nbecome a very important and meaningful task in social science. But the problem\nfacing the field now is that the data samples themselves are unevenly\ndistributed, due to the nature of the crime itself. At the same time, data sets\nin the judicial field are less publicly available, and it is not practical to\nproduce large data sets for direct training. This article proposes a new\ntraining model to solve this problem through NLP processing methods. We first\npropose a Crime Fact Data Preprocessing Module (CFDPM), which can balance the\ndefects of uneven data set distribution by generating new samples. Then we use\na large open source dataset (CAIL-big) as our pretraining dataset and a small\ndataset collected by ourselves for Fine-tuning, giving it good generalization\nability to unfamiliar small datasets. At the same time, we use the improved\nBert model with dynamic masking to improve the model. Experiments show that the\nproposed method achieves state-of-the-art results on the present dataset. At\nthe same time, the effectiveness of module CFDPM is proved by experiments. This\narticle provides a valuable methodology contribution for classifying social\nscience texts such as criminal behaviors. Extensive experiments on public\nbenchmarks show that the proposed method achieves new state-of-the-art results.",
        "translated": "根据犯罪行为事实确定犯罪类型的任务已经成为社会科学中一项非常重要和有意义的任务。但现在该领域面临的问题是，由于犯罪本身的性质，数据样本本身的分布是不均匀的。与此同时，司法领域的数据集较少公开，为直接培训生产大型数据集是不切实际的。本文通过自然语言处理的方法，提出了一种新的训练模型来解决这个问题。我们首先提出了一个犯罪事实数据预处理模块(CFDPM) ，它通过生成新的样本来平衡数据集分布不均匀的缺陷。然后我们使用一个大的开源数据集(CAIL-big)作为我们的预训练数据集和一个我们自己收集的小数据集进行微调，使其具有对不熟悉的小数据集很好的泛化能力。同时，采用改进的带动态掩蔽的 Bert 模型对模型进行了改进。实验结果表明，该方法在目前的数据集上取得了较好的效果。同时，通过实验验证了 CFDPM 模块的有效性。本文为犯罪行为等社会科学文本的分类提供了有价值的方法论贡献。对公共基准测试的大量实验表明，该方法取得了较好的效果。"
    },
    {
        "title": "High-Quality Automatic Voice Over with Accurate Alignment: Supervision\n  through Self-Supervised Discrete Speech Units",
        "url": "http://arxiv.org/abs/2306.17005v1",
        "pub_date": "2023-06-29",
        "summary": "The goal of Automatic Voice Over (AVO) is to generate speech in sync with a\nsilent video given its text script. Recent AVO frameworks built upon\ntext-to-speech synthesis (TTS) have shown impressive results. However, the\ncurrent AVO learning objective of acoustic feature reconstruction brings in\nindirect supervision for inter-modal alignment learning, thus limiting the\nsynchronization performance and synthetic speech quality. To this end, we\npropose a novel AVO method leveraging the learning objective of self-supervised\ndiscrete speech unit prediction, which not only provides more direct\nsupervision for the alignment learning, but also alleviates the mismatch\nbetween the text-video context and acoustic features. Experimental results show\nthat our proposed method achieves remarkable lip-speech synchronization and\nhigh speech quality by outperforming baselines in both objective and subjective\nevaluations. Code and speech samples are publicly available.",
        "translated": "自动语音技术(AVO)的目标是根据文本脚本生成与无声视频同步的语音。最近建立在文本到语音合成(TTS)基础上的 AVO 框架已经显示出令人印象深刻的结果。然而，目前声学特征重构的 AVO 学习目标对多模态对齐学习带来了间接监督，从而限制了同步性能和合成语音质量。为此，我们提出了一种新的 AVO 方法，该方法利用自监督离散语音单元预测的学习目标，不仅为对齐学习提供了更直接的监督，而且减少了文本-视频上下文和声学特征之间的不匹配。实验结果表明，该方法在客观评价和主观评价方面均优于基线，实现了较好的唇语音同步，提高了语音质量。代码和语音样本是公开的。"
    },
    {
        "title": "MEMD-ABSA: A Multi-Element Multi-Domain Dataset for Aspect-Based\n  Sentiment Analysis",
        "url": "http://arxiv.org/abs/2306.16956v1",
        "pub_date": "2023-06-29",
        "summary": "Aspect-based sentiment analysis is a long-standing research interest in the\nfield of opinion mining, and in recent years, researchers have gradually\nshifted their focus from simple ABSA subtasks to end-to-end multi-element ABSA\ntasks. However, the datasets currently used in the research are limited to\nindividual elements of specific tasks, usually focusing on in-domain settings,\nignoring implicit aspects and opinions, and with a small data scale. To address\nthese issues, we propose a large-scale Multi-Element Multi-Domain dataset\n(MEMD) that covers the four elements across five domains, including nearly\n20,000 review sentences and 30,000 quadruples annotated with explicit and\nimplicit aspects and opinions for ABSA research. Meanwhile, we evaluate\ngenerative and non-generative baselines on multiple ABSA subtasks under the\nopen domain setting, and the results show that open domain ABSA as well as\nmining implicit aspects and opinions remain ongoing challenges to be addressed.\nThe datasets are publicly released at \\url{https://github.com/NUSTM/MEMD-ABSA}.",
        "translated": "基于方面的情绪分析是意见挖掘领域的一个长期研究热点，近年来研究者们已经逐渐从简单的 ABSA 子任务转向端到端的多元 ABSA 任务。然而，目前研究中使用的数据集仅限于特定任务的单个元素，通常侧重于领域内设置，忽略隐含的方面和意见，并且数据规模较小。为了解决这些问题，我们提出了一个大规模的多元素多领域数据集(MEMD) ，涵盖五个领域的四个元素，包括近20,000个评论句子和30,000个四元素注释明确和隐含的方面和意见的 ABSA 研究。同时，我们评估了开放领域环境下多个 ABSA 子任务的生成基线和非生成基线，结果表明，开放领域 ABSA 以及挖掘隐含的方面和意见仍然是有待解决的挑战。数据集在 url { https://github.com/nustm/memd-absa }公开发布。"
    },
    {
        "title": "Precision Anti-Cancer Drug Selection via Neural Ranking",
        "url": "http://arxiv.org/abs/2306.17771v1",
        "pub_date": "2023-06-30",
        "summary": "Personalized cancer treatment requires a thorough understanding of complex\ninteractions between drugs and cancer cell lines in varying genetic and\nmolecular contexts. To address this, high-throughput screening has been used to\ngenerate large-scale drug response data, facilitating data-driven computational\nmodels. Such models can capture complex drug-cell line interactions across\nvarious contexts in a fully data-driven manner. However, accurately\nprioritizing the most sensitive drugs for each cell line still remains a\nsignificant challenge. To address this, we developed neural ranking approaches\nthat leverage large-scale drug response data across multiple cell lines from\ndiverse cancer types. Unlike existing approaches that primarily utilize\nregression and classification techniques for drug response prediction, we\nformulated the objective of drug selection and prioritization as a drug ranking\nproblem. In this work, we proposed two neural listwise ranking methods that\nlearn latent representations of drugs and cell lines, and then use those\nrepresentations to score drugs in each cell line via a learnable scoring\nfunction. Specifically, we developed a neural listwise ranking method,\nList-One, on top of the existing method ListNet. Additionally, we proposed a\nnovel listwise ranking method, List-All, that focuses on all the sensitive\ndrugs instead of the top sensitive drug, unlike List-One. Our results\ndemonstrate that List-All outperforms the best baseline with significant\nimprovements of as much as 8.6% in hit@20 across 50% test cell lines.\nFurthermore, our analyses suggest that the learned latent spaces from our\nproposed methods demonstrate informative clustering structures and capture\nrelevant underlying biological features. Moreover, our comprehensive empirical\nevaluation provides a thorough and objective comparison of the performance of\ndifferent methods (including our proposed ones).",
        "translated": ""
    },
    {
        "title": "Outcome-based Evaluation of Systematic Review Automation",
        "url": "http://arxiv.org/abs/2306.17614v1",
        "pub_date": "2023-06-30",
        "summary": "Current methods of evaluating search strategies and automated citation\nscreening for systematic literature reviews typically rely on counting the\nnumber of relevant and not relevant publications. This established practice,\nhowever, does not accurately reflect the reality of conducting a systematic\nreview, because not all included publications have the same influence on the\nfinal outcome of the systematic review. More specifically, if an important\npublication gets excluded or included, this might significantly change the\noverall review outcome, while not including or excluding less influential\nstudies may only have a limited impact. However, in terms of evaluation\nmeasures, all inclusion and exclusion decisions are treated equally and,\ntherefore, failing to retrieve publications with little to no impact on the\nreview outcome leads to the same decrease in recall as failing to retrieve\ncrucial publications. We propose a new evaluation framework that takes into\naccount the impact of the reported study on the overall systematic review\noutcome. We demonstrate the framework by extracting review meta-analysis data\nand estimating outcome effects using predictions from ranking runs on\nsystematic reviews of interventions from CLEF TAR 2019 shared task. We further\nmeasure how closely the obtained outcomes are to the outcomes of the original\nreview if the arbitrary rankings were used. We evaluate 74 runs using the\nproposed framework and compare the results with those obtained using standard\nIR measures. We find that accounting for the difference in review outcomes\nleads to a different assessment of the quality of a system than if traditional\nevaluation measures were used. Our analysis provides new insights into the\nevaluation of retrieval results in the context of systematic review automation,\nemphasising the importance of assessing the usefulness of each document beyond\nbinary relevance.",
        "translated": ""
    },
    {
        "title": "Large Language Models are Effective Text Rankers with Pairwise Ranking\n  Prompting",
        "url": "http://arxiv.org/abs/2306.17563v1",
        "pub_date": "2023-06-30",
        "summary": "Ranking documents using Large Language Models (LLMs) by directly feeding the\nquery and candidate documents into the prompt is an interesting and practical\nproblem. However, there has been limited success so far, as researchers have\nfound it difficult to outperform fine-tuned baseline rankers on benchmark\ndatasets. We analyze pointwise and listwise ranking prompts used by existing\nmethods and argue that off-the-shelf LLMs do not fully understand these ranking\nformulations, possibly due to the nature of how LLMs are trained. In this\npaper, we propose to significantly reduce the burden on LLMs by using a new\ntechnique called Pairwise Ranking Prompting (PRP). Our results are the first in\nthe literature to achieve state-of-the-art ranking performance on standard\nbenchmarks using moderate-sized open-sourced LLMs. On TREC-DL2020, PRP based on\nthe Flan-UL2 model with 20B parameters outperforms the previous best approach\nin the literature, which is based on the blackbox commercial GPT-4 that has 50x\n(estimated) model size, by over 5% at NDCG@1. On TREC-DL2019, PRP is only\ninferior to the GPT-4 solution on the NDCG@5 and NDCG@10 metrics, while\noutperforming other existing solutions, such as InstructGPT which has 175B\nparameters, by over 10% for nearly all ranking metrics. Furthermore, we propose\nseveral variants of PRP to improve efficiency and show that it is possible to\nachieve competitive results even with linear complexity. We also discuss other\nbenefits of PRP, such as supporting both generation and scoring LLM APIs, as\nwell as being insensitive to input ordering.",
        "translated": ""
    },
    {
        "title": "Leveraging Watch-time Feedback for Short-Video Recommendations: A Causal\n  Labeling Framework",
        "url": "http://arxiv.org/abs/2306.17426v1",
        "pub_date": "2023-06-30",
        "summary": "With the proliferation of short video applications, the significance of short\nvideo recommendations has vastly increased. Unlike other recommendation\nscenarios, short video recommendation systems heavily rely on feedback from\nwatch time. Existing approaches simply treat watch time as a direct label,\nfailing to effectively harness its extensive semantics and introduce bias,\nthereby limiting the potential for modeling user interests based on watch time.\nTo overcome this challenge, we propose a framework named Debiasied\nMultiple-semantics-extracting Labeling (DML). DML constructs labels that\nencompass various semantics by utilizing quantiles derived from the\ndistribution of watch time, prioritizing relative order rather than absolute\nlabel values. This approach facilitates easier model learning while aligning\nwith the ranking objective of recommendations. Furthermore, we introduce a\nmethod inspired by causal adjustment to refine label definitions, thereby\nreducing the impact of bias on the label and directly mitigating bias at the\nlabel level. We substantiate the effectiveness of our DML framework through\nboth online and offline experiments. Extensive results demonstrate that our DML\ncould effectively leverage watch time to discover users' real interests,\nenhancing their engagement in our application.",
        "translated": ""
    },
    {
        "title": "Audio Embeddings as Teachers for Music Classification",
        "url": "http://arxiv.org/abs/2306.17424v1",
        "pub_date": "2023-06-30",
        "summary": "Music classification has been one of the most popular tasks in the field of\nmusic information retrieval. With the development of deep learning models, the\nlast decade has seen impressive improvements in a wide range of classification\ntasks. However, the increasing model complexity makes both training and\ninference computationally expensive. In this paper, we integrate the ideas of\ntransfer learning and feature-based knowledge distillation and systematically\ninvestigate using pre-trained audio embeddings as teachers to guide the\ntraining of low-complexity student networks. By regularizing the feature space\nof the student networks with the pre-trained embeddings, the knowledge in the\nteacher embeddings can be transferred to the students. We use various\npre-trained audio embeddings and test the effectiveness of the method on the\ntasks of musical instrument classification and music auto-tagging. Results show\nthat our method significantly improves the results in comparison to the\nidentical model trained without the teacher's knowledge. This technique can\nalso be combined with classical knowledge distillation approaches to further\nimprove the model's performance.",
        "translated": ""
    },
    {
        "title": "SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen\n  LLMs",
        "url": "http://arxiv.org/abs/2306.17842v2",
        "pub_date": "2023-06-30",
        "summary": "In this work, we introduce Semantic Pyramid AutoEncoder (SPAE) for enabling\nfrozen LLMs to perform both understanding and generation tasks involving\nnon-linguistic modalities such as images or videos. SPAE converts between raw\npixels and interpretable lexical tokens (or words) extracted from the LLM's\nvocabulary. The resulting tokens capture both the semantic meaning and the\nfine-grained details needed for visual reconstruction, effectively translating\nthe visual content into a language comprehensible to the LLM, and empowering it\nto perform a wide array of multimodal tasks. Our approach is validated through\nin-context learning experiments with frozen PaLM 2 and GPT 3.5 on a diverse set\nof image understanding and generation tasks. Our method marks the first\nsuccessful attempt to enable a frozen LLM to generate image content while\nsurpassing state-of-the-art performance in image understanding tasks, under the\nsame setting, by over 25%.",
        "translated": ""
    },
    {
        "title": "Statler: State-Maintaining Language Models for Embodied Reasoning",
        "url": "http://arxiv.org/abs/2306.17840v2",
        "pub_date": "2023-06-30",
        "summary": "Large language models (LLMs) provide a promising tool that enable robots to\nperform complex robot reasoning tasks. However, the limited context window of\ncontemporary LLMs makes reasoning over long time horizons difficult. Embodied\ntasks such as those that one might expect a household robot to perform\ntypically require that the planner consider information acquired a long time\nago (e.g., properties of the many objects that the robot previously encountered\nin the environment). Attempts to capture the world state using an LLM's\nimplicit internal representation is complicated by the paucity of task- and\nenvironment-relevant information available in a robot's action history, while\nmethods that rely on the ability to convey information via the prompt to the\nLLM are subject to its limited context window. In this paper, we propose\nStatler, a framework that endows LLMs with an explicit representation of the\nworld state as a form of ``memory'' that is maintained over time. Integral to\nStatler is its use of two instances of general LLMs -- a world-model reader and\na world-model writer -- that interface with and maintain the world state. By\nproviding access to this world state ``memory'', Statler improves the ability\nof existing LLMs to reason over longer time horizons without the constraint of\ncontext length. We evaluate the effectiveness of our approach on three\nsimulated table-top manipulation domains and a real robot domain, and show that\nit improves the state-of-the-art in LLM-based robot reasoning. Project website:\nhttps://statler-lm.github.io/",
        "translated": ""
    },
    {
        "title": "Meta-Reasoning: Semantics-Symbol Deconstruction For Large Language\n  Models",
        "url": "http://arxiv.org/abs/2306.17820v1",
        "pub_date": "2023-06-30",
        "summary": "Symbolization methods in large language models (LLMs) have been shown\neffective to improve LLMs' reasoning ability. However, most of these approaches\nhinge on mapping natural languages to formal languages (e.g., Python, SQL) that\nare more syntactically complete and free of ambiguity. Although effective, they\ndepart from the natural language itself and deviate from the habits of human\nthinking, and instead cater more to the execution mindset of computers. In\ncontrast, we hope to simplify natural language by starting from the concept of\nsymbols in linguistics itself, so that LLMs can learn the common formulation\nand general solution of reasoning problems wrapped in different natural\nsemantics. From this consideration, we propose \\textbf{Meta-Reasoning}, which\nallows LLMs to automatically accomplish semantic-symbol deconstruction, i.e.,\nsemantic resolution, to maximally reduce different questions of certain\nreasoning tasks to similar natural language representation, thus gaining the\nability to learn by analogy and facilitating data-efficient in-context\nlearning. Our experiments show that the Meta-Reasoning paradigm saliently\nenhances LLMs' reasoning performance with fewer demonstrations. They can learn\nnot only reasoning chains but also general solutions to certain types of tasks.\nIn particular, for symbolic reasoning tasks, such as 7-step Tracking Shuffled\nObjects, GPT-3 (text-davinci-002) achieves over 99% accuracy with only one\nMeta-Reasoning demonstration, outperforming all current LLMs with the standard\nchain-of-thought prompting.",
        "translated": ""
    },
    {
        "title": "A Massive Scale Semantic Similarity Dataset of Historical English",
        "url": "http://arxiv.org/abs/2306.17810v1",
        "pub_date": "2023-06-30",
        "summary": "A diversity of tasks use language models trained on semantic similarity data.\nWhile there are a variety of datasets that capture semantic similarity, they\nare either constructed from modern web data or are relatively small datasets\ncreated in the past decade by human annotators. This study utilizes a novel\nsource, newly digitized articles from off-copyright, local U.S. newspapers, to\nassemble a massive-scale semantic similarity dataset spanning 70 years from\n1920 to 1989 and containing nearly 400M positive semantic similarity pairs.\nHistorically, around half of articles in U.S. local newspapers came from\nnewswires like the Associated Press. While local papers reproduced articles\nfrom the newswire, they wrote their own headlines, which form abstractive\nsummaries of the associated articles. We associate articles and their headlines\nby exploiting document layouts and language understanding. We then use deep\nneural methods to detect which articles are from the same underlying source, in\nthe presence of substantial noise and abridgement. The headlines of reproduced\narticles form positive semantic similarity pairs. The resulting publicly\navailable HEADLINES dataset is significantly larger than most existing semantic\nsimilarity datasets and covers a much longer span of time. It will facilitate\nthe application of contrastively trained semantic similarity models to a\nvariety of tasks, including the study of semantic change across space and time.",
        "translated": ""
    },
    {
        "title": "Stay on topic with Classifier-Free Guidance",
        "url": "http://arxiv.org/abs/2306.17806v1",
        "pub_date": "2023-06-30",
        "summary": "Classifier-Free Guidance (CFG) has recently emerged in text-to-image\ngeneration as a lightweight technique to encourage prompt-adherence in\ngenerations. In this work, we demonstrate that CFG can be used broadly as an\ninference-time technique in pure language modeling. We show that CFG (1)\nimproves the performance of Pythia, GPT-2 and LLaMA-family models across an\narray of tasks: Q\\&amp;A, reasoning, code generation, and machine translation,\nachieving SOTA on LAMBADA with LLaMA-7B over PaLM-540B; (2) brings improvements\nequivalent to a model with twice the parameter-count; (3) can stack alongside\nother inference-time methods like Chain-of-Thought and Self-Consistency,\nyielding further improvements in difficult tasks; (4) can be used to increase\nthe faithfulness and coherence of assistants in challenging form-driven and\ncontent-driven prompts: in a human evaluation we show a 75\\% preference for\nGPT4All using CFG over baseline.",
        "translated": ""
    },
    {
        "title": "Towards Improving the Performance of Pre-Trained Speech Models for\n  Low-Resource Languages Through Lateral Inhibition",
        "url": "http://arxiv.org/abs/2306.17792v1",
        "pub_date": "2023-06-30",
        "summary": "With the rise of bidirectional encoder representations from Transformer\nmodels in natural language processing, the speech community has adopted some of\ntheir development methodologies. Therefore, the Wav2Vec models were introduced\nto reduce the data required to obtain state-of-the-art results. This work\nleverages this knowledge and improves the performance of the pre-trained speech\nmodels by simply replacing the fine-tuning dense layer with a lateral\ninhibition layer inspired by the biological process. Our experiments on\nRomanian, a low-resource language, show an average improvement of 12.5% word\nerror rate (WER) using the lateral inhibition layer. In addition, we obtain\nstate-of-the-art results on both the Romanian Speech Corpus and the Robin\nTechnical Acquisition Corpus with 1.78% WER and 29.64% WER, respectively.",
        "translated": ""
    },
    {
        "title": "Should you marginalize over possible tokenizations?",
        "url": "http://arxiv.org/abs/2306.17757v1",
        "pub_date": "2023-06-30",
        "summary": "Autoregressive language models (LMs) map token sequences to probabilities.\nThe usual practice for computing the probability of any character string (e.g.\nEnglish sentences) is to first transform it into a sequence of tokens that is\nscored by the model. However, there are exponentially many token sequences that\nrepresent any given string. To truly compute the probability of a string one\nshould marginalize over all tokenizations, which is typically intractable.\nHere, we analyze whether the practice of ignoring the marginalization is\njustified. To this end, we devise an importance-sampling-based algorithm that\nallows us to compute estimates of the marginal probabilities and compare them\nto the default procedure in a range of state-of-the-art models and datasets.\nOur results show that the gap in log-likelihood is no larger than 0.5% in most\ncases, but that it becomes more pronounced for data with long complex words.",
        "translated": ""
    },
    {
        "title": "Token-Event-Role Structure-based Multi-Channel Document-Level Event\n  Extraction",
        "url": "http://arxiv.org/abs/2306.17733v1",
        "pub_date": "2023-06-30",
        "summary": "Document-level event extraction is a long-standing challenging information\nretrieval problem involving a sequence of sub-tasks: entity extraction, event\ntype judgment, and event type-specific multi-event extraction. However,\naddressing the problem as multiple learning tasks leads to increased model\ncomplexity. Also, existing methods insufficiently utilize the correlation of\nentities crossing different events, resulting in limited event extraction\nperformance. This paper introduces a novel framework for document-level event\nextraction, incorporating a new data structure called token-event-role and a\nmulti-channel argument role prediction module. The proposed data structure\nenables our model to uncover the primary role of tokens in multiple events,\nfacilitating a more comprehensive understanding of event relationships. By\nleveraging the multi-channel prediction module, we transform entity and\nmulti-event extraction into a single task of predicting token-event pairs,\nthereby reducing the overall parameter size and enhancing model efficiency. The\nresults demonstrate that our approach outperforms the state-of-the-art method\nby 9.5 percentage points in terms of the F1 score, highlighting its superior\nperformance in event extraction. Furthermore, an ablation study confirms the\nsignificant value of the proposed data structure in improving event extraction\ntasks, further validating its importance in enhancing the overall performance\nof the framework.",
        "translated": ""
    },
    {
        "title": "Improved NL2SQL based on Multi-layer Expert Network",
        "url": "http://arxiv.org/abs/2306.17727v1",
        "pub_date": "2023-06-30",
        "summary": "The Natural Language to SQL (NL2SQL) technique is used to convert natural\nlanguage queries into executable SQL statements. Typically, slot-filling is\nemployed as a classification method for multi-task cases to achieve this goal.\nHowever, slot-filling can result in inaccurate SQL statement generation due to\nnegative migration issues arising from different classification tasks. To\novercome this limitation, this study introduces a new approach called\nMulti-Layer Expert Generate SQL (MLEG-SQL), which utilizes a dedicated\nmulti-task hierarchical network. The lower layer of the network extracts\nsemantic features of natural language statements, while the upper layer builds\na specialized expert system for handling specific classification tasks. This\nhierarchical approach mitigates performance degradation resulting from\ndifferent task conflicts. The proposed method was evaluated on the WiKSQL\ndataset and was found to be effective in generating accurate SQL statements.",
        "translated": ""
    },
    {
        "title": "Beyond Neural-on-Neural Approaches to Speaker Gender Protection",
        "url": "http://arxiv.org/abs/2306.17700v1",
        "pub_date": "2023-06-30",
        "summary": "Recent research has proposed approaches that modify speech to defend against\ngender inference attacks. The goal of these protection algorithms is to control\nthe availability of information about a speaker's gender, a privacy-sensitive\nattribute. Currently, the common practice for developing and testing gender\nprotection algorithms is \"neural-on-neural\", i.e., perturbations are generated\nand tested with a neural network. In this paper, we propose to go beyond this\npractice to strengthen the study of gender protection. First, we demonstrate\nthe importance of testing gender inference attacks that are based on speech\nfeatures historically developed by speech scientists, alongside the\nconventionally used neural classifiers. Next, we argue that researchers should\nuse speech features to gain insight into how protective modifications change\nthe speech signal. Finally, we point out that gender-protection algorithms\nshould be compared with novel \"vocal adversaries\", human-executed voice\nadaptations, in order to improve interpretability and enable before-the-mic\nprotection.",
        "translated": ""
    },
    {
        "title": "ChatGPT vs. Google: A Comparative Study of Search Performance and User\n  Experience",
        "url": "http://arxiv.org/abs/2307.01135v1",
        "pub_date": "2023-07-03",
        "summary": "The advent of ChatGPT, a large language model-powered chatbot, has prompted\nquestions about its potential implications for traditional search engines. In\nthis study, we investigate the differences in user behavior when employing\nsearch engines and chatbot tools for information-seeking tasks. We carry out a\nrandomized online experiment, dividing participants into two groups: one using\na ChatGPT-like tool and the other using a Google Search-like tool. Our findings\nreveal that the ChatGPT group consistently spends less time on all tasks, with\nno significant difference in overall task performance between the groups.\nNotably, ChatGPT levels user search performance across different education\nlevels and excels in answering straightforward questions and providing general\nsolutions but falls short in fact-checking tasks. Users perceive ChatGPT's\nresponses as having higher information quality compared to Google Search,\ndespite displaying a similar level of trust in both tools. Furthermore,\nparticipants using ChatGPT report significantly better user experiences in\nterms of usefulness, enjoyment, and satisfaction, while perceived ease of use\nremains comparable between the two tools. However, ChatGPT may also lead to\noverreliance and generate or replicate misinformation, yielding inconsistent\nresults. Our study offers valuable insights for search engine management and\nhighlights opportunities for integrating chatbot technologies into search\nengine designs.",
        "translated": ""
    },
    {
        "title": "OpenSiteRec: An Open Dataset for Site Recommendation",
        "url": "http://arxiv.org/abs/2307.00856v1",
        "pub_date": "2023-07-03",
        "summary": "As a representative information retrieval task, site recommendation, which\naims at predicting the optimal sites for a brand or an institution to open new\nbranches in an automatic data-driven way, is beneficial and crucial for brand\ndevelopment in modern business. However, there is no publicly available dataset\nso far and most existing approaches are limited to an extremely small scope of\nbrands, which seriously hinders the research on site recommendation. Therefore,\nwe collect, construct and release an open comprehensive dataset, namely\nOpenSiteRec, to facilitate and promote the research on site recommendation.\nSpecifically, OpenSiteRec leverages a heterogeneous graph schema to represent\nvarious types of real-world entities and relations in four international\nmetropolises. To evaluate the performance of the existing general methods on\nthe site recommendation task, we conduct benchmarking experiments of several\nrepresentative recommendation models on OpenSiteRec. Furthermore, we also\nhighlight the potential application directions to demonstrate the wide\napplicability of OpenSiteRec. We believe that our OpenSiteRec dataset is\nsignificant and anticipated to encourage the development of advanced methods\nfor site recommendation. OpenSiteRec is available online at\nhttps://OpenSiteRec.github.io/.",
        "translated": ""
    },
    {
        "title": "Looks Can Be Deceiving: Linking User-Item Interactions and User's\n  Propensity Towards Multi-Objective Recommendations",
        "url": "http://arxiv.org/abs/2307.00654v1",
        "pub_date": "2023-07-02",
        "summary": "Multi-objective recommender systems (MORS) provide suggestions to users\naccording to multiple (and possibly conflicting) goals. When a system optimizes\nits results at the individual-user level, it tailors them on a user's\npropensity towards the different objectives. Hence, the capability to\nunderstand users' fine-grained needs towards each goal is crucial. In this\npaper, we present the results of a user study in which we monitored the way\nusers interacted with recommended items, as well as their self-proclaimed\npropensities towards relevance, novelty and diversity objectives. The study was\ndivided into several sessions, where users evaluated recommendation lists\noriginating from a relevance-only single-objective baseline as well as MORS. We\nshow that despite MORS-based recommendations attracted less selections, its\npresence in the early sessions is crucial for users' satisfaction in the later\nstages. Surprisingly, the self-proclaimed willingness of users to interact with\nnovel and diverse items is not always reflected in the recommendations they\naccept. Post-study questionnaires provide insights on how to deal with this\nmatter, suggesting that MORS-based results should be accompanied by elements\nthat allow users to understand the recommendations, so as to facilitate their\nacceptance.",
        "translated": ""
    },
    {
        "title": "BioCPT: Contrastive Pre-trained Transformers with Large-scale PubMed\n  Search Logs for Zero-shot Biomedical Information Retrieval",
        "url": "http://arxiv.org/abs/2307.00589v1",
        "pub_date": "2023-07-02",
        "summary": "Information retrieval (IR) is essential in biomedical knowledge acquisition\nand clinical decision support. While recent progress has shown that language\nmodel encoders perform better semantic retrieval, training such models requires\nabundant query-article annotations that are difficult to obtain in biomedicine.\nAs a result, most biomedical IR systems only conduct lexical matching. In\nresponse, we introduce BioCPT, a first-of-its-kind Contrastively Pre-trained\nTransformer model for zero-shot biomedical IR. To train BioCPT, we collected an\nunprecedented scale of 255 million user click logs from PubMed. With such data,\nwe use contrastive learning to train a pair of closely-integrated retriever and\nre-ranker. Experimental results show that BioCPT sets new state-of-the-art\nperformance on five biomedical IR tasks, outperforming various baselines\nincluding much larger models such as GPT-3-sized cpt-text-XL. In addition,\nBioCPT also generates better biomedical article and sentence representations\nfor semantic evaluations. As such, BioCPT can be readily applied to various\nreal-world biomedical IR tasks. BioCPT API and code are publicly available at\nhttps://github.com/ncbi/BioCPT.",
        "translated": ""
    },
    {
        "title": "HeGeL: A Novel Dataset for Geo-Location from Hebrew Text",
        "url": "http://arxiv.org/abs/2307.00509v1",
        "pub_date": "2023-07-02",
        "summary": "The task of textual geolocation - retrieving the coordinates of a place based\non a free-form language description - calls for not only grounding but also\nnatural language understanding and geospatial reasoning. Even though there are\nquite a few datasets in English used for geolocation, they are currently based\non open-source data (Wikipedia and Twitter), where the location of the\ndescribed place is mostly implicit, such that the location retrieval resolution\nis limited. Furthermore, there are no datasets available for addressing the\nproblem of textual geolocation in morphologically rich and resource-poor\nlanguages, such as Hebrew. In this paper, we present the Hebrew Geo-Location\n(HeGeL) corpus, designed to collect literal place descriptions and analyze\nlingual geospatial reasoning. We crowdsourced 5,649 literal Hebrew place\ndescriptions of various place types in three cities in Israel. Qualitative and\nempirical analysis show that the data exhibits abundant use of geospatial\nreasoning and requires a novel environmental representation.",
        "translated": ""
    },
    {
        "title": "Trainable Transformer in Transformer",
        "url": "http://arxiv.org/abs/2307.01189v1",
        "pub_date": "2023-07-03",
        "summary": "Recent works attribute the capability of in-context learning (ICL) in large\npre-trained language models to implicitly simulating and fine-tuning an\ninternal model (e.g., linear or 2-layer MLP) during inference. However, such\nconstructions require large memory overhead, which makes simulation of more\nsophisticated internal models intractable. In this work, we propose an\nefficient construction, Transformer in Transformer (in short, TinT), that\nallows a transformer to simulate and fine-tune complex models internally during\ninference (e.g., pre-trained language models). In particular, we introduce\ninnovative approximation techniques that allow a TinT model with less than 2\nbillion parameters to simulate and fine-tune a 125 million parameter\ntransformer model within a single forward pass. TinT accommodates many common\ntransformer variants and its design ideas also improve the efficiency of past\ninstantiations of simple models inside transformers. We conduct end-to-end\nexperiments to validate the internal fine-tuning procedure of TinT on various\nlanguage modeling and downstream tasks. For example, even with a limited\none-step budget, we observe TinT for a OPT-125M model improves performance by\n4-16% absolute on average compared to OPT-125M. These findings suggest that\nlarge pre-trained language models are capable of performing intricate\nsubroutines. To facilitate further work, a modular and extensible codebase for\nTinT is included.",
        "translated": ""
    },
    {
        "title": "Improving Language Plasticity via Pretraining with Active Forgetting",
        "url": "http://arxiv.org/abs/2307.01163v2",
        "pub_date": "2023-07-03",
        "summary": "Pretrained language models (PLMs) are today the primary model for natural\nlanguage processing. Despite their impressive downstream performance, it can be\ndifficult to apply PLMs to new languages, a barrier to making their\ncapabilities universally accessible. While prior work has shown it possible to\naddress this issue by learning a new embedding layer for the new language,\ndoing so is both data and compute inefficient. We propose to use an active\nforgetting mechanism during pretraining, as a simple way of creating PLMs that\ncan quickly adapt to new languages. Concretely, by resetting the embedding\nlayer every K updates during pretraining, we encourage the PLM to improve its\nability of learning new embeddings within a limited number of updates, similar\nto a meta-learning effect. Experiments with RoBERTa show that models pretrained\nwith our forgetting mechanism not only demonstrate faster convergence during\nlanguage adaptation but also outperform standard ones in a low-data regime,\nparticularly for languages that are distant from English.",
        "translated": ""
    },
    {
        "title": "SCITUNE: Aligning Large Language Models with Scientific Multimodal\n  Instructions",
        "url": "http://arxiv.org/abs/2307.01139v1",
        "pub_date": "2023-07-03",
        "summary": "Instruction finetuning is a popular paradigm to align large language models\n(LLM) with human intent. Despite its popularity, this idea is less explored in\nimproving the LLMs to align existing foundation models with scientific\ndisciplines, concepts and goals. In this work, we present SciTune as a tuning\nframework to improve the ability of LLMs to follow scientific multimodal\ninstructions. To test our methodology, we use a human-generated scientific\ninstruction tuning dataset and train a large multimodal model LLaMA-SciTune\nthat connects a vision encoder and LLM for science-focused visual and language\nunderstanding. In comparison to the models that are finetuned with machine\ngenerated data only, LLaMA-SciTune surpasses human performance on average and\nin many sub-categories on the ScienceQA benchmark.",
        "translated": ""
    },
    {
        "title": "Exploring the In-context Learning Ability of Large Language Model for\n  Biomedical Concept Linking",
        "url": "http://arxiv.org/abs/2307.01137v1",
        "pub_date": "2023-07-03",
        "summary": "The biomedical field relies heavily on concept linking in various areas such\nas literature mining, graph alignment, information retrieval,\nquestion-answering, data, and knowledge integration. Although large language\nmodels (LLMs) have made significant strides in many natural language processing\ntasks, their effectiveness in biomedical concept mapping is yet to be fully\nexplored. This research investigates a method that exploits the in-context\nlearning (ICL) capabilities of large models for biomedical concept linking. The\nproposed approach adopts a two-stage retrieve-and-rank framework. Initially,\nbiomedical concepts are embedded using language models, and then embedding\nsimilarity is utilized to retrieve the top candidates. These candidates'\ncontextual information is subsequently incorporated into the prompt and\nprocessed by a large language model to re-rank the concepts. This approach\nachieved an accuracy of 90.% in BC5CDR disease entity normalization and 94.7%\nin chemical entity normalization, exhibiting a competitive performance relative\nto supervised learning methods. Further, it showed a significant improvement,\nwith an over 20-point absolute increase in F1 score on an oncology matching\ndataset. Extensive qualitative assessments were conducted, and the benefits and\npotential shortcomings of using large language models within the biomedical\ndomain were discussed. were discussed.",
        "translated": ""
    },
    {
        "title": "Iterative Zero-Shot LLM Prompting for Knowledge Graph Construction",
        "url": "http://arxiv.org/abs/2307.01128v1",
        "pub_date": "2023-07-03",
        "summary": "In the current digitalization era, capturing and effectively representing\nknowledge is crucial in most real-world scenarios. In this context, knowledge\ngraphs represent a potent tool for retrieving and organizing a vast amount of\ninformation in a properly interconnected and interpretable structure. However,\ntheir generation is still challenging and often requires considerable human\neffort and domain expertise, hampering the scalability and flexibility across\ndifferent application fields. This paper proposes an innovative knowledge graph\ngeneration approach that leverages the potential of the latest generative large\nlanguage models, such as GPT-3.5, that can address all the main critical issues\nin knowledge graph building. The approach is conveyed in a pipeline that\ncomprises novel iterative zero-shot and external knowledge-agnostic strategies\nin the main stages of the generation process. Our unique manifold approach may\nencompass significant benefits to the scientific community. In particular, the\nmain contribution can be summarized by: (i) an innovative strategy for\niteratively prompting large language models to extract relevant components of\nthe final graph; (ii) a zero-shot strategy for each prompt, meaning that there\nis no need for providing examples for \"guiding\" the prompt result; (iii) a\nscalable solution, as the adoption of LLMs avoids the need for any external\nresources or human expertise. To assess the effectiveness of our proposed\nmodel, we performed experiments on a dataset that covered a specific domain. We\nclaim that our proposal is a suitable solution for scalable and versatile\nknowledge graph construction and may be applied to different and novel\ncontexts.",
        "translated": ""
    },
    {
        "title": "Analyzing Multiple-Choice Reading and Listening Comprehension Tests",
        "url": "http://arxiv.org/abs/2307.01076v1",
        "pub_date": "2023-07-03",
        "summary": "Multiple-choice reading and listening comprehension tests are an important\npart of language assessment. Content creators for standard educational tests\nneed to carefully curate questions that assess the comprehension abilities of\ncandidates taking the tests. However, recent work has shown that a large number\nof questions in general multiple-choice reading comprehension datasets can be\nanswered without comprehension, by leveraging world knowledge instead. This\nwork investigates how much of a contextual passage needs to be read in\nmultiple-choice reading based on conversation transcriptions and listening\ncomprehension tests to be able to work out the correct answer. We find that\nautomated reading comprehension systems can perform significantly better than\nrandom with partial or even no access to the context passage. These findings\noffer an approach for content creators to automatically capture the trade-off\nbetween comprehension and world knowledge required for their proposed\nquestions.",
        "translated": ""
    },
    {
        "title": "Estimating Post-OCR Denoising Complexity on Numerical Texts",
        "url": "http://arxiv.org/abs/2307.01020v1",
        "pub_date": "2023-07-03",
        "summary": "Post-OCR processing has significantly improved over the past few years.\nHowever, these have been primarily beneficial for texts consisting of natural,\nalphabetical words, as opposed to documents of numerical nature such as\ninvoices, payslips, medical certificates, etc. To evaluate the OCR\npost-processing difficulty of these datasets, we propose a method to estimate\nthe denoising complexity of a text and evaluate it on several datasets of\nvarying nature, and show that texts of numerical nature have a significant\ndisadvantage. We evaluate the estimated complexity ranking with respect to the\nerror rates of modern-day denoising approaches to show the validity of our\nestimator.",
        "translated": ""
    },
    {
        "title": "Visual Instruction Tuning with Polite Flamingo",
        "url": "http://arxiv.org/abs/2307.01003v1",
        "pub_date": "2023-07-03",
        "summary": "Recent research has demonstrated that the multi-task fine-tuning of\nmulti-modal Large Language Models (LLMs) using an assortment of annotated\ndownstream vision-language datasets significantly enhances their performance.\nYet, during this process, a side effect, which we termed as the \"multi-modal\nalignment tax\", surfaces. This side effect negatively impacts the model's\nability to format responses appropriately -- for instance, its \"politeness\" --\ndue to the overly succinct and unformatted nature of raw annotations, resulting\nin reduced human preference. In this paper, we introduce Polite Flamingo, a\nmulti-modal response rewriter that transforms raw annotations into a more\nappealing, \"polite\" format. Polite Flamingo is trained to reconstruct\nhigh-quality responses from their automatically distorted counterparts and is\nsubsequently applied to a vast array of vision-language datasets for response\nrewriting. After rigorous filtering, we generate the PF-1M dataset and further\nvalidate its value by fine-tuning a multi-modal LLM with it. Combined with\nnovel methodologies including U-shaped multi-stage tuning and multi-turn\naugmentation, the resulting model, Clever Flamingo, demonstrates its advantages\nin both multi-modal understanding and response politeness according to\nautomated and human evaluations.",
        "translated": ""
    },
    {
        "title": "Towards Suicide Prevention from Bipolar Disorder with Temporal\n  Symptom-Aware Multitask Learning",
        "url": "http://arxiv.org/abs/2307.00995v1",
        "pub_date": "2023-07-03",
        "summary": "Bipolar disorder (BD) is closely associated with an increased risk of\nsuicide. However, while the prior work has revealed valuable insight into\nunderstanding the behavior of BD patients on social media, little attention has\nbeen paid to developing a model that can predict the future suicidality of a BD\npatient. Therefore, this study proposes a multi-task learning model for\npredicting the future suicidality of BD patients by jointly learning current\nsymptoms. We build a novel BD dataset clinically validated by psychiatrists,\nincluding 14 years of posts on bipolar-related subreddits written by 818 BD\npatients, along with the annotations of future suicidality and BD symptoms. We\nalso suggest a temporal symptom-aware attention mechanism to determine which\nsymptoms are the most influential for predicting future suicidality over time\nthrough a sequence of BD posts. Our experiments demonstrate that the proposed\nmodel outperforms the state-of-the-art models in both BD symptom identification\nand future suicidality prediction tasks. In addition, the proposed temporal\nsymptom-aware attention provides interpretable attention weights, helping\nclinicians to apprehend BD patients more comprehensively and to provide timely\nintervention by tracking mental state progression.",
        "translated": ""
    },
    {
        "title": "Challenges in Domain-Specific Abstractive Summarization and How to\n  Overcome them",
        "url": "http://arxiv.org/abs/2307.00963v1",
        "pub_date": "2023-07-03",
        "summary": "Large Language Models work quite well with general-purpose data and many\ntasks in Natural Language Processing. However, they show several limitations\nwhen used for a task such as domain-specific abstractive text summarization.\nThis paper identifies three of those limitations as research problems in the\ncontext of abstractive text summarization: 1) Quadratic complexity of\ntransformer-based models with respect to the input text length; 2) Model\nHallucination, which is a model's ability to generate factually incorrect text;\nand 3) Domain Shift, which happens when the distribution of the model's\ntraining and test corpus is not the same. Along with a discussion of the open\nresearch questions, this paper also provides an assessment of existing\nstate-of-the-art techniques relevant to domain-specific text summarization to\naddress the research gaps.",
        "translated": ""
    },
    {
        "title": "Improving Address Matching using Siamese Transformer Networks",
        "url": "http://arxiv.org/abs/2307.02300v1",
        "pub_date": "2023-07-05",
        "summary": "Matching addresses is a critical task for companies and post offices involved\nin the processing and delivery of packages. The ramifications of incorrectly\ndelivering a package to the wrong recipient are numerous, ranging from harm to\nthe company's reputation to economic and environmental costs. This research\nintroduces a deep learning-based model designed to increase the efficiency of\naddress matching for Portuguese addresses. The model comprises two parts: (i) a\nbi-encoder, which is fine-tuned to create meaningful embeddings of Portuguese\npostal addresses, utilized to retrieve the top 10 likely matches of the\nun-normalized target address from a normalized database, and (ii) a\ncross-encoder, which is fine-tuned to accurately rerank the 10 addresses\nobtained by the bi-encoder. The model has been tested on a real-case scenario\nof Portuguese addresses and exhibits a high degree of accuracy, exceeding 95%\nat the door level. When utilized with GPU computations, the inference speed is\nabout 4.5 times quicker than other traditional approaches such as BM25. An\nimplementation of this system in a real-world scenario would substantially\nincrease the effectiveness of the distribution process. Such an implementation\nis currently under investigation.",
        "translated": ""
    },
    {
        "title": "An Equivalent Graph Reconstruction Model and its Application in\n  Recommendation Prediction",
        "url": "http://arxiv.org/abs/2307.02183v1",
        "pub_date": "2023-07-05",
        "summary": "Recommendation algorithm plays an important role in recommendation system\n(RS), which predicts users' interests and preferences for some given items\nbased on their known information. Recently, a recommendation algorithm based on\nthe graph Laplacian regularization was proposed, which treats the prediction\nproblem of the recommendation system as a reconstruction issue of small samples\nof the graph signal under the same graph model. Such a technique takes into\naccount both known and unknown labeled samples information, thereby obtaining\ngood prediction accuracy. However, when the data size is large, solving the\nreconstruction model is computationally expensive even with an approximate\nstrategy. In this paper, we propose an equivalent reconstruction model that can\nbe solved exactly with extremely low computational cost. Finally, a final\nprediction algorithm is proposed. We find in the experiments that the proposed\nmethod significantly reduces the computational cost while maintaining a good\nprediction accuracy.",
        "translated": ""
    },
    {
        "title": "Generative Job Recommendations with Large Language Model",
        "url": "http://arxiv.org/abs/2307.02157v1",
        "pub_date": "2023-07-05",
        "summary": "The rapid development of online recruitment services has encouraged the\nutilization of recommender systems to streamline the job seeking process.\nPredominantly, current job recommendations deploy either collaborative\nfiltering or person-job matching strategies. However, these models tend to\noperate as \"black-box\" systems and lack the capacity to offer explainable\nguidance to job seekers. Moreover, conventional matching-based recommendation\nmethods are limited to retrieving and ranking existing jobs in the database,\nrestricting their potential as comprehensive career AI advisors. To this end,\nhere we present GIRL (GeneratIve job Recommendation based on Large language\nmodels), a novel approach inspired by recent advancements in the field of Large\nLanguage Models (LLMs). We initially employ a Supervised Fine-Tuning (SFT)\nstrategy to instruct the LLM-based generator in crafting suitable Job\nDescriptions (JDs) based on the Curriculum Vitae (CV) of a job seeker.\nMoreover, we propose to train a model which can evaluate the matching degree\nbetween CVs and JDs as a reward model, and we use Proximal Policy Optimization\n(PPO)-based Reinforcement Learning (RL) method to further fine-tine the\ngenerator. This aligns the generator with recruiter feedback, tailoring the\noutput to better meet employer preferences. In particular, GIRL serves as a job\nseeker-centric generative model, providing job suggestions without the need of\na candidate set. This capability also enhances the performance of existing job\nrecommendation models by supplementing job seeking features with generated\ncontent. With extensive experiments on a large-scale real-world dataset, we\ndemonstrate the substantial effectiveness of our approach. We believe that GIRL\nintroduces a paradigm-shifting approach to job recommendation systems,\nfostering a more personalized and comprehensive job-seeking experience.",
        "translated": ""
    },
    {
        "title": "Recommendation Unlearning via Influence Function",
        "url": "http://arxiv.org/abs/2307.02147v1",
        "pub_date": "2023-07-05",
        "summary": "Recommendation unlearning is an emerging task to serve users for erasing\nunusable data (e.g., some historical behaviors) from a well-trained recommender\nmodel. Existing methods process unlearning requests by fully or partially\nretraining the model after removing the unusable data. However, these methods\nare impractical due to the high computation cost of full retraining and the\nhighly possible performance damage of partial training. In this light, a\ndesired recommendation unlearning method should obtain a similar model as full\nretraining in a more efficient manner, i.e., achieving complete, efficient and\ninnocuous unlearning. In this work, we propose an Influence Function-based\nRecommendation Unlearning (IFRU) framework, which efficiently updates the model\nwithout retraining by estimating the influence of the unusable data on the\nmodel via the influence function. In the light that recent recommender models\nuse historical data for both the constructions of the optimization loss and the\ncomputational graph (e.g., neighborhood aggregation), IFRU jointly estimates\nthe direct influence of unusable data on optimization loss and the spillover\ninfluence on the computational graph to pursue complete unlearning.\nFurthermore, we propose an importance-based pruning algorithm to reduce the\ncost of the influence function. IFRU is innocuous and applicable to mainstream\ndifferentiable models. Extensive experiments demonstrate that IFRU achieves\nmore than250times acceleration compared to retraining-based methods with\nrecommendation performance comparable to full retraining.",
        "translated": ""
    },
    {
        "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
        "url": "http://arxiv.org/abs/2307.02046v1",
        "pub_date": "2023-07-05",
        "summary": "With the prosperity of e-commerce and web applications, Recommender Systems\n(RecSys) have become an important component of our daily life, providing\npersonalized suggestions that cater to user preferences. While Deep Neural\nNetworks (DNNs) have made significant advancements in enhancing recommender\nsystems by modeling user-item interactions and incorporating textual side\ninformation, DNN-based methods still face limitations, such as difficulties in\nunderstanding users' interests and capturing textual side information,\ninabilities in generalizing to various recommendation scenarios and reasoning\non their predictions, etc. Meanwhile, the emergence of Large Language Models\n(LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), due to their\nremarkable abilities in fundamental responsibilities of language understanding\nand generation, as well as impressive generalization and reasoning\ncapabilities. As a result, recent studies have attempted to harness the power\nof LLMs to enhance recommender systems. Given the rapid evolution of this\nresearch direction in recommender systems, there is a pressing need for a\nsystematic overview that summarizes existing LLM-empowered recommender systems,\nto provide researchers in relevant fields with an in-depth understanding.\nTherefore, in this paper, we conduct a comprehensive review of LLM-empowered\nrecommender systems from various aspects including Pre-training, Fine-tuning,\nand Prompting. More specifically, we first introduce representative methods to\nharness the power of LLMs (as a feature encoder) for learning representations\nof users and items. Then, we review recent techniques of LLMs for enhancing\nrecommender systems from three paradigms, namely pre-training, fine-tuning, and\nprompting. Finally, we comprehensively discuss future directions in this\nemerging field.",
        "translated": ""
    },
    {
        "title": "LongNet: Scaling Transformers to 1,000,000,000 Tokens",
        "url": "http://arxiv.org/abs/2307.02486v1",
        "pub_date": "2023-07-05",
        "summary": "Scaling sequence length has become a critical demand in the era of large\nlanguage models. However, existing methods struggle with either computational\ncomplexity or model expressivity, rendering the maximum sequence length\nrestricted. In this work, we introduce LongNet, a Transformer variant that can\nscale sequence length to more than 1 billion tokens, without sacrificing the\nperformance on shorter sequences. Specifically, we propose dilated attention,\nwhich expands the attentive field exponentially as the distance grows. LongNet\nhas significant advantages: 1) it has a linear computation complexity and a\nlogarithm dependency between tokens; 2) it can be served as a distributed\ntrainer for extremely long sequences; 3) its dilated attention is a drop-in\nreplacement for standard attention, which can be seamlessly integrated with the\nexisting Transformer-based optimization. Experiments results demonstrate that\nLongNet yields strong performance on both long-sequence modeling and general\nlanguage tasks. Our work opens up new possibilities for modeling very long\nsequences, e.g., treating a whole corpus or even the entire Internet as a\nsequence.",
        "translated": ""
    },
    {
        "title": "Building Cooperative Embodied Agents Modularly with Large Language\n  Models",
        "url": "http://arxiv.org/abs/2307.02485v1",
        "pub_date": "2023-07-05",
        "summary": "Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website https://vis-www.cs.umass.edu/Co-LLM-Agents/.",
        "translated": ""
    },
    {
        "title": "Reasoning or Reciting? Exploring the Capabilities and Limitations of\n  Language Models Through Counterfactual Tasks",
        "url": "http://arxiv.org/abs/2307.02477v1",
        "pub_date": "2023-07-05",
        "summary": "The impressive performance of recent language models across a wide range of\ntasks suggests that they possess a degree of abstract reasoning skills. Are\nthese skills general and transferable, or specialized to specific tasks seen\nduring pretraining? To disentangle these effects, we propose an evaluation\nframework based on \"counterfactual\" task variants that deviate from the default\nassumptions underlying standard tasks. Across a suite of 11 tasks, we observe\nnontrivial performance on the counterfactual variants, but nevertheless find\nthat performance substantially and consistently degrades compared to the\ndefault conditions. This suggests that while current LMs may possess abstract\ntask-solving skills to a degree, they often also rely on narrow,\nnon-transferable procedures for task-solving. These results motivate a more\ncareful interpretation of language model performance that teases apart these\naspects of behavior.",
        "translated": ""
    },
    {
        "title": "Deductive Additivity for Planning of Natural Language Proofs",
        "url": "http://arxiv.org/abs/2307.02472v2",
        "pub_date": "2023-07-05",
        "summary": "Current natural language systems designed for multi-step claim validation\ntypically operate in two phases: retrieve a set of relevant premise statements\nusing heuristics (planning), then generate novel conclusions from those\nstatements using a large language model (deduction). The planning step often\nrequires expensive Transformer operations and does not scale to arbitrary\nnumbers of premise statements. In this paper, we investigate whether an\nefficient planning heuristic is possible via embedding spaces compatible with\ndeductive reasoning. Specifically, we evaluate whether embedding spaces exhibit\na property we call deductive additivity: the sum of premise statement\nembeddings should be close to embeddings of conclusions based on those\npremises. We explore multiple sources of off-the-shelf dense embeddings in\naddition to fine-tuned embeddings from GPT3 and sparse embeddings from BM25. We\nstudy embedding models both intrinsically, evaluating whether the property of\ndeductive additivity holds, and extrinsically, using them to assist planning in\nnatural language proof generation. Lastly, we create a dataset, Single-Step\nReasoning Contrast (SSRC), to further probe performance on various reasoning\ntypes. Our findings suggest that while standard embedding methods frequently\nembed conclusions near the sums of their premises, they fall short of being\neffective heuristics and lack the ability to model certain categories of\nreasoning.",
        "translated": ""
    },
    {
        "title": "What Matters in Training a GPT4-Style Language Model with Multimodal\n  Inputs?",
        "url": "http://arxiv.org/abs/2307.02469v1",
        "pub_date": "2023-07-05",
        "summary": "Recent advancements in Large Language Models (LLMs) such as GPT4 have\ndisplayed exceptional multi-modal capabilities in following open-ended\ninstructions given images. However, the performance of these models heavily\nrelies on design choices such as network structures, training data, and\ntraining strategies, and these choices have not been extensively discussed in\nthe literature, making it difficult to quantify progress in this field. To\naddress this issue, this paper presents a systematic and comprehensive study,\nquantitatively and qualitatively, on training such models. We implement over 20\nvariants with controlled settings. Concretely, for network structures, we\ncompare different LLM backbones and model designs. For training data, we\ninvestigate the impact of data and sampling strategies. For instructions, we\nexplore the influence of diversified prompts on the instruction-following\nability of the trained models. For benchmarks, we contribute the first, to our\nbest knowledge, comprehensive evaluation set including both image and video\ntasks through crowd-sourcing. Based on our findings, we present Lynx, which\nperforms the most accurate multi-modal understanding while keeping the best\nmulti-modal generation ability compared to existing open-sourced GPT4-style\nmodels.",
        "translated": ""
    },
    {
        "title": "An Exploratory Literature Study on Sharing and Energy Use of Language\n  Models for Source Code",
        "url": "http://arxiv.org/abs/2307.02443v1",
        "pub_date": "2023-07-05",
        "summary": "Large language models trained on source code can support a variety of\nsoftware development tasks, such as code recommendation and program repair.\nLarge amounts of data for training such models benefit the models' performance.\nHowever, the size of the data and models results in long training times and\nhigh energy consumption. While publishing source code allows for replicability,\nusers need to repeat the expensive training process if models are not shared.\nThe main goal of the study is to investigate if publications that trained\nlanguage models for software engineering (SE) tasks share source code and\ntrained artifacts. The second goal is to analyze the transparency on training\nenergy usage. We perform a snowballing-based literature search to find\npublications on language models for source code, and analyze their reusability\nfrom a sustainability standpoint.\n  From 494 unique publications, we identified 293 relevant publications that\nuse language models to address code-related tasks. Among them, 27% (79 out of\n293) make artifacts available for reuse. This can be in the form of tools or\nIDE plugins designed for specific tasks or task-agnostic models that can be\nfine-tuned for a variety of downstream tasks. Moreover, we collect insights on\nthe hardware used for model training, as well as training time, which together\ndetermine the energy consumption of the development process. We find that there\nare deficiencies in the sharing of information and artifacts for current\nstudies on source code models for software engineering tasks, with 40% of the\nsurveyed papers not sharing source code or trained artifacts. We recommend the\nsharing of source code as well as trained artifacts, to enable sustainable\nreproducibility. Moreover, comprehensive information on training times and\nhardware configurations should be shared for transparency on a model's carbon\nfootprint.",
        "translated": ""
    },
    {
        "title": "Exploring Continual Learning for Code Generation Models",
        "url": "http://arxiv.org/abs/2307.02435v1",
        "pub_date": "2023-07-05",
        "summary": "Large-scale code generation models such as Codex and CodeT5 have achieved\nimpressive performance. However, libraries are upgraded or deprecated very\nfrequently and re-training large-scale language models is computationally\nexpensive. Therefore, Continual Learning (CL) is an important aspect that\nremains underexplored in the code domain. In this paper, we introduce a\nbenchmark called CodeTask-CL that covers a wide range of tasks, including code\ngeneration, translation, summarization, and refinement, with different input\nand output programming languages. Next, on our CodeTask-CL benchmark, we\ncompare popular CL techniques from NLP and Vision domains. We find that\neffective methods like Prompt Pooling (PP) suffer from catastrophic forgetting\ndue to the unstable training of the prompt selection mechanism caused by stark\ndistribution shifts in coding tasks. We address this issue with our proposed\nmethod, Prompt Pooling with Teacher Forcing (PP-TF), that stabilizes training\nby enforcing constraints on the prompt selection mechanism and leads to a\n21.54% improvement over Prompt Pooling. Along with the benchmark, we establish\na training pipeline that can be used for CL on code models, which we believe\ncan motivate further development of CL methods for code models. Our code is\navailable at https://github.com/amazon-science/codetaskcl-pptf",
        "translated": ""
    },
    {
        "title": "Won't Get Fooled Again: Answering Questions with False Premises",
        "url": "http://arxiv.org/abs/2307.02394v1",
        "pub_date": "2023-07-05",
        "summary": "Pre-trained language models (PLMs) have shown unprecedented potential in\nvarious fields, especially as the backbones for question-answering (QA)\nsystems. However, they tend to be easily deceived by tricky questions such as\n\"How many eyes does the sun have?\". Such frailties of PLMs often allude to the\nlack of knowledge within them. In this paper, we find that the PLMs already\npossess the knowledge required to rebut such questions, and the key is how to\nactivate the knowledge. To systematize this observation, we investigate the\nPLMs' responses to one kind of tricky questions, i.e., the false premises\nquestions (FPQs). We annotate a FalseQA dataset containing 2365 human-written\nFPQs, with the corresponding explanations for the false premises and the\nrevised true premise questions. Using FalseQA, we discover that PLMs are\ncapable of discriminating FPQs by fine-tuning on moderate numbers (e.g., 256)\nof examples. PLMs also generate reasonable explanations for the false premise,\nwhich serve as rebuttals. Further replaying a few general questions during\ntraining allows PLMs to excel on FPQs and general questions simultaneously. Our\nwork suggests that once the rebuttal ability is stimulated, knowledge inside\nthe PLMs can be effectively utilized to handle FPQs, which incentivizes the\nresearch on PLM-based QA systems.",
        "translated": ""
    },
    {
        "title": "Causal Discovery with Language Models as Imperfect Experts",
        "url": "http://arxiv.org/abs/2307.02390v1",
        "pub_date": "2023-07-05",
        "summary": "Understanding the causal relationships that underlie a system is a\nfundamental prerequisite to accurate decision-making. In this work, we explore\nhow expert knowledge can be used to improve the data-driven identification of\ncausal graphs, beyond Markov equivalence classes. In doing so, we consider a\nsetting where we can query an expert about the orientation of causal\nrelationships between variables, but where the expert may provide erroneous\ninformation. We propose strategies for amending such expert knowledge based on\nconsistency properties, e.g., acyclicity and conditional independencies in the\nequivalence class. We then report a case study, on real data, where a large\nlanguage model is used as an imperfect expert.",
        "translated": ""
    },
    {
        "title": "To be or not to be: a translation reception study of a literary text\n  translated into Dutch and Catalan using machine translation",
        "url": "http://arxiv.org/abs/2307.02358v1",
        "pub_date": "2023-07-05",
        "summary": "This article presents the results of a study involving the reception of a\nfictional story by Kurt Vonnegut translated from English into Catalan and Dutch\nin three conditions: machine-translated (MT), post-edited (PE) and translated\nfrom scratch (HT). 223 participants were recruited who rated the reading\nconditions using three scales: Narrative Engagement, Enjoyment and Translation\nReception. The results show that HT presented a higher engagement, enjoyment\nand translation reception in Catalan if compared to PE and MT. However, the\nDutch readers show higher scores in PE than in both HT and MT, and the highest\nengagement and enjoyments scores are reported when reading the original English\nversion. We hypothesize that when reading a fictional story in translation, not\nonly the condition and the quality of the translations is key to understand its\nreception, but also the participants reading patterns, reading language, and,\nperhaps language status in their own societies.",
        "translated": ""
    },
    {
        "title": "MultiVENT: Multilingual Videos of Events with Aligned Natural Text",
        "url": "http://arxiv.org/abs/2307.03153v1",
        "pub_date": "2023-07-06",
        "summary": "Everyday news coverage has shifted from traditional broadcasts towards a wide\nrange of presentation formats such as first-hand, unedited video footage.\nDatasets that reflect the diverse array of multimodal, multilingual news\nsources available online could be used to teach models to benefit from this\nshift, but existing news video datasets focus on traditional news broadcasts\nproduced for English-speaking audiences. We address this limitation by\nconstructing MultiVENT, a dataset of multilingual, event-centric videos\ngrounded in text documents across five target languages. MultiVENT includes\nboth news broadcast videos and non-professional event footage, which we use to\nanalyze the state of online news videos and how they can be leveraged to build\nrobust, factually accurate models. Finally, we provide a model for complex,\nmultilingual video retrieval to serve as a baseline for information retrieval\nusing MultiVENT.",
        "translated": ""
    },
    {
        "title": "Track Mix Generation on Music Streaming Services using Transformers",
        "url": "http://arxiv.org/abs/2307.03045v1",
        "pub_date": "2023-07-06",
        "summary": "This paper introduces Track Mix, a personalized playlist generation system\nreleased in 2022 on the music streaming service Deezer. Track Mix automatically\ngenerates \"mix\" playlists inspired by initial music tracks, allowing users to\ndiscover music similar to their favorite content. To generate these mixes, we\nconsider a Transformer model trained on millions of track sequences from user\nplaylists. In light of the growing popularity of Transformers in recent years,\nwe analyze the advantages, drawbacks, and technical challenges of using such a\nmodel for mix generation on the service, compared to a more traditional\ncollaborative filtering approach. Since its release, Track Mix has been\ngenerating playlists for millions of users daily, enhancing their music\ndiscovery experience on Deezer.",
        "translated": ""
    },
    {
        "title": "Improving Retrieval-Augmented Large Language Models via Data Importance\n  Learning",
        "url": "http://arxiv.org/abs/2307.03027v1",
        "pub_date": "2023-07-06",
        "summary": "Retrieval augmentation enables large language models to take advantage of\nexternal knowledge, for example on tasks like question answering and data\nimputation. However, the performance of such retrieval-augmented models is\nlimited by the data quality of their underlying retrieval corpus. In this\npaper, we propose an algorithm based on multilinear extension for evaluating\nthe data importance of retrieved data points. There are exponentially many\nterms in the multilinear extension, and one key contribution of this paper is a\npolynomial time algorithm that computes exactly, given a retrieval-augmented\nmodel with an additive utility function and a validation set, the data\nimportance of data points in the retrieval corpus using the multilinear\nextension of the model's utility function. We further proposed an even more\nefficient ({\\epsilon}, {\\delta})-approximation algorithm. Our experimental\nresults illustrate that we can enhance the performance of large language models\nby only pruning or reweighting the retrieval corpus, without requiring further\ntraining. For some tasks, this even allows a small model (e.g., GPT-JT),\naugmented with a search engine API, to outperform GPT-3.5 (without retrieval\naugmentation). Moreover, we show that weights based on multilinear extension\ncan be computed efficiently in practice (e.g., in less than ten minutes for a\ncorpus with 100 million elements).",
        "translated": ""
    },
    {
        "title": "A Meta-Evaluation of C/W/L/A Metrics: System Ranking Similarity, System\n  Ranking Consistency and Discriminative Power",
        "url": "http://arxiv.org/abs/2307.02936v1",
        "pub_date": "2023-07-06",
        "summary": "Recently, Moffat et al. proposed an analytic framework, namely C/W/L/A, for\noffline evaluation metrics. This framework allows information retrieval (IR)\nresearchers to design evaluation metrics through the flexible combination of\nuser browsing models and user gain aggregations. However, the statistical\nstability of C/W/L/A metrics with different aggregations is not yet\ninvestigated. In this study, we investigate the statistical stability of\nC/W/L/A metrics from the perspective of: (1) the system ranking similarity\namong aggregations, (2) the system ranking consistency of aggregations and (3)\nthe discriminative power of aggregations. More specifically, we combined\nvarious aggregation functions with the browsing model of Precision, Discounted\nCumulative Gain (DCG), Rank-Biased Precision (RBP), INST, Average Precision\n(AP) and Expected Reciprocal Rank (ERR), examing their performances in terms of\nsystem ranking similarity, system ranking consistency and discriminative power\non two offline test collections. Our experimental result suggests that, in\nterms of system ranking consistency and discriminative power, the aggregation\nfunction of expected rate of gain (ERG) has an outstanding performance while\nthe aggregation function of maximum relevance usually has an insufficient\nperformance. The result also suggests that Precision, DCG, RBP, INST and AP\nwith their canonical aggregation all have favourable performances in system\nranking consistency and discriminative power; but for ERR, replacing its\ncanonical aggregation with ERG can further strengthen the discriminative power\nwhile obtaining a system ranking list similar to the canonical version at the\nsame time.",
        "translated": ""
    },
    {
        "title": "PLIERS: a Popularity-Based Recommender System for Content Dissemination\n  in Online Social Networks",
        "url": "http://arxiv.org/abs/2307.02865v1",
        "pub_date": "2023-07-06",
        "summary": "In this paper, we propose a novel tag-based recommender system called PLIERS,\nwhich relies on the assumption that users are mainly interested in items and\ntags with similar popularity to those they already own. PLIERS is aimed at\nreaching a good tradeoff between algorithmic complexity and the level of\npersonalization of recommended items. To evaluate PLIERS, we performed a set of\nexperiments on real OSN datasets, demonstrating that it outperforms\nstate-of-the-art solutions in terms of personalization, relevance, and novelty\nof recommendations.",
        "translated": ""
    },
    {
        "title": "Lost in the Middle: How Language Models Use Long Contexts",
        "url": "http://arxiv.org/abs/2307.03172v1",
        "pub_date": "2023-07-06",
        "summary": "While recent language models have the ability to take long contexts as input,\nrelatively little is known about how well the language models use longer\ncontext. We analyze language model performance on two tasks that require\nidentifying relevant information within their input contexts: multi-document\nquestion answering and key-value retrieval. We find that performance is often\nhighest when relevant information occurs at the beginning or end of the input\ncontext, and significantly degrades when models must access relevant\ninformation in the middle of long contexts. Furthermore, performance\nsubstantially decreases as the input context grows longer, even for explicitly\nlong-context models. Our analysis provides a better understanding of how\nlanguage models use their input context and provides new evaluation protocols\nfor future long-context models.",
        "translated": ""
    },
    {
        "title": "Focused Transformer: Contrastive Training for Context Scaling",
        "url": "http://arxiv.org/abs/2307.03170v1",
        "pub_date": "2023-07-06",
        "summary": "Large language models have an exceptional capability to incorporate new\ninformation in a contextual manner. However, the full potential of such an\napproach is often restrained due to a limitation in the effective context\nlength. One solution to this issue is to endow an attention layer with access\nto an external memory, which comprises of (key, value) pairs. Yet, as the\nnumber of documents increases, the proportion of relevant keys to irrelevant\nones decreases, leading the model to focus more on the irrelevant keys. We\nidentify a significant challenge, dubbed the distraction issue, where keys\nlinked to different semantic values might overlap, making them hard to\ndistinguish. To tackle this problem, we introduce the Focused Transformer\n(FoT), a technique that employs a training process inspired by contrastive\nlearning. This novel approach enhances the structure of the (key, value) space,\nenabling an extension of the context length. Our method allows for fine-tuning\npre-existing, large-scale models to lengthen their effective context. This is\ndemonstrated by our fine-tuning of $3B$ and $7B$ OpenLLaMA checkpoints. The\nresulting models, which we name LongLLaMA, exhibit advancements in tasks\nrequiring a long context. We further illustrate that our LongLLaMA models\nadeptly manage a $256 k$ context length for passkey retrieval.",
        "translated": ""
    },
    {
        "title": "Distilling Large Vision-Language Model with Out-of-Distribution\n  Generalizability",
        "url": "http://arxiv.org/abs/2307.03135v1",
        "pub_date": "2023-07-06",
        "summary": "Large vision-language models have achieved outstanding performance, but their\nsize and computational requirements make their deployment on\nresource-constrained devices and time-sensitive tasks impractical. Model\ndistillation, the process of creating smaller, faster models that maintain the\nperformance of larger models, is a promising direction towards the solution.\nThis paper investigates the distillation of visual representations in large\nteacher vision-language models into lightweight student models using a small-\nor mid-scale dataset. Notably, this study focuses on open-vocabulary\nout-of-distribution (OOD) generalization, a challenging problem that has been\noverlooked in previous model distillation literature. We propose two principles\nfrom vision and language modality perspectives to enhance student's OOD\ngeneralization: (1) by better imitating teacher's visual representation space,\nand carefully promoting better coherence in vision-language alignment with the\nteacher; (2) by enriching the teacher's language representations with\ninformative and finegrained semantic attributes to effectively distinguish\nbetween different labels. We propose several metrics and conduct extensive\nexperiments to investigate their techniques. The results demonstrate\nsignificant improvements in zero-shot and few-shot student performance on\nopen-vocabulary out-of-distribution classification, highlighting the\neffectiveness of our proposed approaches. Our code will be released at\nhttps://github.com/xuanlinli17/large_vlm_distillation_ood",
        "translated": ""
    },
    {
        "title": "T-MARS: Improving Visual Representations by Circumventing Text Feature\n  Learning",
        "url": "http://arxiv.org/abs/2307.03132v1",
        "pub_date": "2023-07-06",
        "summary": "Large web-sourced multimodal datasets have powered a slew of new methods for\nlearning general-purpose visual representations, advancing the state of the art\nin computer vision and revolutionizing zero- and few-shot recognition. One\ncrucial decision facing practitioners is how, if at all, to curate these\never-larger datasets. For example, the creators of the LAION-5B dataset chose\nto retain only image-caption pairs whose CLIP similarity score exceeded a\ndesignated threshold. In this paper, we propose a new state-of-the-art data\nfiltering approach motivated by our observation that nearly 40% of LAION's\nimages contain text that overlaps significantly with the caption. Intuitively,\nsuch data could be wasteful as it incentivizes models to perform optical\ncharacter recognition rather than learning visual features. However, naively\nremoving all such data could also be wasteful, as it throws away images that\ncontain visual features (in addition to overlapping text). Our simple and\nscalable approach, T-MARS (Text Masking and Re-Scoring), filters out only those\npairs where the text dominates the remaining visual features -- by first\nmasking out the text and then filtering out those with a low CLIP similarity\nscore of the masked image. Experimentally, T-MARS outperforms the top-ranked\nmethod on the \"medium scale\" of DataComp (a data filtering benchmark) by a\nmargin of 6.5% on ImageNet and 4.7% on VTAB. Additionally, our systematic\nevaluation on various data pool sizes from 2M to 64M shows that the accuracy\ngains enjoyed by T-MARS linearly increase as data and compute are scaled\nexponentially. Code is available at https://github.com/locuslab/T-MARS.",
        "translated": ""
    },
    {
        "title": "BLEURT Has Universal Translations: An Analysis of Automatic Metrics by\n  Minimum Risk Training",
        "url": "http://arxiv.org/abs/2307.03131v1",
        "pub_date": "2023-07-06",
        "summary": "Automatic metrics play a crucial role in machine translation. Despite the\nwidespread use of n-gram-based metrics, there has been a recent surge in the\ndevelopment of pre-trained model-based metrics that focus on measuring sentence\nsemantics. However, these neural metrics, while achieving higher correlations\nwith human evaluations, are often considered to be black boxes with potential\nbiases that are difficult to detect. In this study, we systematically analyze\nand compare various mainstream and cutting-edge automatic metrics from the\nperspective of their guidance for training machine translation systems. Through\nMinimum Risk Training (MRT), we find that certain metrics exhibit robustness\ndefects, such as the presence of universal adversarial translations in BLEURT\nand BARTScore. In-depth analysis suggests two main causes of these robustness\ndeficits: distribution biases in the training datasets, and the tendency of the\nmetric paradigm. By incorporating token-level constraints, we enhance the\nrobustness of evaluation metrics, which in turn leads to an improvement in the\nperformance of machine translation systems. Codes are available at\n\\url{https://github.com/powerpuffpomelo/fairseq_mrt}.",
        "translated": ""
    },
    {
        "title": "VisKoP: Visual Knowledge oriented Programming for Interactive Knowledge\n  Base Question Answering",
        "url": "http://arxiv.org/abs/2307.03130v1",
        "pub_date": "2023-07-06",
        "summary": "We present Visual Knowledge oriented Programming platform (VisKoP), a\nknowledge base question answering (KBQA) system that integrates human into the\nloop to edit and debug the knowledge base (KB) queries. VisKoP not only\nprovides a neural program induction module, which converts natural language\nquestions into knowledge oriented program language (KoPL), but also maps KoPL\nprograms into graphical elements. KoPL programs can be edited with simple\ngraphical operators, such as dragging to add knowledge operators and slot\nfilling to designate operator arguments. Moreover, VisKoP provides\nauto-completion for its knowledge base schema and users can easily debug the\nKoPL program by checking its intermediate results. To facilitate the practical\nKBQA on a million-entity-level KB, we design a highly efficient KoPL execution\nengine for the back-end. Experiment results show that VisKoP is highly\nefficient and user interaction can fix a large portion of wrong KoPL programs\nto acquire the correct answer. The VisKoP online demo\nhttps://demoviskop.xlore.cn (Stable release of this paper) and\nhttps://viskop.xlore.cn (Beta release with new features), highly efficient KoPL\nengine https://pypi.org/project/kopl-engine, and screencast video\nhttps://youtu.be/zAbJtxFPTXo are now publicly available.",
        "translated": ""
    },
    {
        "title": "Extracting Multi-valued Relations from Language Models",
        "url": "http://arxiv.org/abs/2307.03122v1",
        "pub_date": "2023-07-06",
        "summary": "The widespread usage of latent language representations via pre-trained\nlanguage models (LMs) suggests that they are a promising source of structured\nknowledge. However, existing methods focus only on a single object per\nsubject-relation pair, even though often multiple objects are correct. To\novercome this limitation, we analyze these representations for their potential\nto yield materialized multi-object relational knowledge. We formulate the\nproblem as a rank-then-select task. For ranking candidate objects, we evaluate\nexisting prompting techniques and propose new ones incorporating domain\nknowledge. Among the selection methods, we find that choosing objects with a\nlikelihood above a learned relation-specific threshold gives a 49.5% F1 score.\nOur results highlight the difficulty of employing LMs for the multi-valued\nslot-filling task and pave the way for further research on extracting\nrelational knowledge from latent language representations.",
        "translated": ""
    },
    {
        "title": "KoRC: Knowledge oriented Reading Comprehension Benchmark for Deep Text\n  Understanding",
        "url": "http://arxiv.org/abs/2307.03115v1",
        "pub_date": "2023-07-06",
        "summary": "Deep text understanding, which requires the connections between a given\ndocument and prior knowledge beyond its text, has been highlighted by many\nbenchmarks in recent years. However, these benchmarks have encountered two\nmajor limitations. On the one hand, most of them require human annotation of\nknowledge, which leads to limited knowledge coverage. On the other hand, they\nusually use choices or spans in the texts as the answers, which results in\nnarrow answer space. To overcome these limitations, we build a new challenging\nbenchmark named KoRc in this paper. Compared with previous benchmarks, KoRC has\ntwo advantages, i.e., broad knowledge coverage and flexible answer format.\nSpecifically, we utilize massive knowledge bases to guide annotators or large\nlanguage models (LLMs) to construct knowledgable questions. Moreover, we use\nlabels in knowledge bases rather than spans or choices as the final answers. We\ntest state-of-the-art models on KoRC and the experimental results show that the\nstrongest baseline only achieves 68.3% and 30.0% F1 measure in the\nin-distribution and out-of-distribution test set, respectively. These results\nindicate that deep text understanding is still an unsolved challenge. The\nbenchmark dataset, leaderboard, and baseline methods are released in\nhttps://github.com/THU-KEG/KoRC.",
        "translated": ""
    },
    {
        "title": "A Survey on Evaluation of Large Language Models",
        "url": "http://arxiv.org/abs/2307.03109v1",
        "pub_date": "2023-07-06",
        "summary": "Large language models (LLMs) are gaining increasing popularity in both\nacademia and industry, owing to their unprecedented performance in various\napplications. As LLMs continue to play a vital role in both research and daily\nuse, their evaluation becomes increasingly critical, not only at the task\nlevel, but also at the society level for better understanding of their\npotential risks. Over the past years, significant efforts have been made to\nexamine LLMs from various perspectives. This paper presents a comprehensive\nreview of these evaluation methods for LLMs, focusing on three key dimensions:\nwhat to evaluate, where to evaluate, and how to evaluate. Firstly, we provide\nan overview from the perspective of evaluation tasks, encompassing general\nnatural language processing tasks, reasoning, medical usage, ethics,\neducations, natural and social sciences, agent applications, and other areas.\nSecondly, we answer the `where' and `how' questions by diving into the\nevaluation methods and benchmarks, which serve as crucial components in\nassessing performance of LLMs. Then, we summarize the success and failure cases\nof LLMs in different tasks. Finally, we shed light on several future challenges\nthat lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to\nresearchers in the realm of LLMs evaluation, thereby aiding the development of\nmore proficient LLMs. Our key point is that evaluation should be treated as an\nessential discipline to better assist the development of LLMs. We consistently\nmaintain the related open-source materials at:\nhttps://github.com/MLGroupJLU/LLM-eval-survey.",
        "translated": ""
    },
    {
        "title": "Efficient Domain Adaptation of Sentence Embeddings using Adapters",
        "url": "http://arxiv.org/abs/2307.03104v1",
        "pub_date": "2023-07-06",
        "summary": "Sentence embeddings enable us to capture the semantic similarity of short\ntexts. Most sentence embedding models are trained for general semantic textual\nsimilarity (STS) tasks. Therefore, to use sentence embeddings in a particular\ndomain, the model must be adapted to it in order to achieve good results.\nUsually, this is done by fine-tuning the entire sentence embedding model for\nthe domain of interest. While this approach yields state-of-the-art results,\nall of the model's weights are updated during fine-tuning, making this method\nresource-intensive. Therefore, instead of fine-tuning entire sentence embedding\nmodels for each target domain individually, we propose to train lightweight\nadapters. These domain-specific adapters do not require fine-tuning all\nunderlying sentence embedding model parameters. Instead, we only train a small\nnumber of additional parameters while keeping the weights of the underlying\nsentence embedding model fixed. Training domain-specific adapters allows always\nusing the same base model and only exchanging the domain-specific adapters to\nadapt sentence embeddings to a specific domain. We show that using adapters for\nparameter-efficient domain adaptation of sentence embeddings yields competitive\nperformance within 1% of a domain-adapted, entirely fine-tuned sentence\nembedding model while only training approximately 3.6% of the parameters.",
        "translated": ""
    },
    {
        "title": "A Network Resource Allocation Recommendation Method with An Improved\n  Similarity Measure",
        "url": "http://arxiv.org/abs/2307.03399v1",
        "pub_date": "2023-07-07",
        "summary": "Recommender systems have been acknowledged as efficacious tools for managing\ninformation overload. Nevertheless, conventional algorithms adopted in such\nsystems primarily emphasize precise recommendations and, consequently, overlook\nother vital aspects like the coverage, diversity, and novelty of items. This\napproach results in less exposure for long-tail items. In this paper, to\npersonalize the recommendations and allocate recommendation resources more\npurposively, a method named PIM+RA is proposed. This method utilizes a\nbipartite network that incorporates self-connecting edges and weights.\nFurthermore, an improved Pearson correlation coefficient is employed for better\nredistribution. The evaluation of PIM+RA demonstrates a significant enhancement\nnot only in accuracy but also in coverage, diversity, and novelty of the\nrecommendation. It leads to a better balance in recommendation frequency by\nproviding effective exposure to long-tail items, while allowing customized\nparameters to adjust the recommendation list bias.",
        "translated": ""
    },
    {
        "title": "InfoSync: Information Synchronization across Multilingual\n  Semi-structured Tables",
        "url": "http://arxiv.org/abs/2307.03313v1",
        "pub_date": "2023-07-06",
        "summary": "Information Synchronization of semi-structured data across languages is\nchallenging. For instance, Wikipedia tables in one language should be\nsynchronized across languages. To address this problem, we introduce a new\ndataset InfoSyncC and a two-step method for tabular synchronization. InfoSync\ncontains 100K entity-centric tables (Wikipedia Infoboxes) across 14 languages,\nof which a subset (3.5K pairs) are manually annotated. The proposed method\nincludes 1) Information Alignment to map rows and 2) Information Update for\nupdating missing/outdated information for aligned tables across multilingual\ntables. When evaluated on InfoSync, information alignment achieves an F1 score\nof 87.91 (en &lt;-&gt; non-en). To evaluate information updation, we perform\nhuman-assisted Wikipedia edits on Infoboxes for 603 table pairs. Our approach\nobtains an acceptance rate of 77.28% on Wikipedia, showing the effectiveness of\nthe proposed method.",
        "translated": ""
    },
    {
        "title": "Structure Guided Multi-modal Pre-trained Transformer for Knowledge Graph\n  Reasoning",
        "url": "http://arxiv.org/abs/2307.03591v1",
        "pub_date": "2023-07-06",
        "summary": "Multimodal knowledge graphs (MKGs), which intuitively organize information in\nvarious modalities, can benefit multiple practical downstream tasks, such as\nrecommendation systems, and visual question answering. However, most MKGs are\nstill far from complete, which motivates the flourishing of MKG reasoning\nmodels. Recently, with the development of general artificial architectures, the\npretrained transformer models have drawn increasing attention, especially for\nmultimodal scenarios. However, the research of multimodal pretrained\ntransformer (MPT) for knowledge graph reasoning (KGR) is still at an early\nstage. As the biggest difference between MKG and other multimodal data, the\nrich structural information underlying the MKG still cannot be fully leveraged\nin existing MPT models. Most of them only utilize the graph structure as a\nretrieval map for matching images and texts connected with the same entity.\nThis manner hinders their reasoning performances. To this end, we propose the\ngraph Structure Guided Multimodal Pretrained Transformer for knowledge graph\nreasoning, termed SGMPT. Specifically, the graph structure encoder is adopted\nfor structural feature encoding. Then, a structure-guided fusion module with\ntwo different strategies, i.e., weighted summation and alignment constraint, is\nfirst designed to inject the structural information into both the textual and\nvisual features. To the best of our knowledge, SGMPT is the first MPT model for\nmultimodal KGR, which mines the structural information underlying the knowledge\ngraph. Extensive experiments on FB15k-237-IMG and WN18-IMG, demonstrate that\nour SGMPT outperforms existing state-of-the-art models, and prove the\neffectiveness of the designed strategies.",
        "translated": ""
    },
    {
        "title": "On the Efficacy of Sampling Adapters",
        "url": "http://arxiv.org/abs/2307.03749v1",
        "pub_date": "2023-07-07",
        "summary": "Sampling is a common strategy for generating text from probabilistic models,\nyet standard ancestral sampling often results in text that is incoherent or\nungrammatical. To alleviate this issue, various modifications to a model's\nsampling distribution, such as nucleus or top-k sampling, have been introduced\nand are now ubiquitously used in language generation systems. We propose a\nunified framework for understanding these techniques, which we term sampling\nadapters. Sampling adapters often lead to qualitatively better text, which\nraises the question: From a formal perspective, how are they changing the\n(sub)word-level distributions of language generation models? And why do these\nlocal changes lead to higher-quality text? We argue that the shift they enforce\ncan be viewed as a trade-off between precision and recall: while the model\nloses its ability to produce certain strings, its precision rate on desirable\ntext increases. While this trade-off is not reflected in standard metrics of\ndistribution quality (such as perplexity), we find that several\nprecision-emphasizing measures indeed indicate that sampling adapters can lead\nto probability distributions more aligned with the true distribution. Further,\nthese measures correlate with higher sequence-level quality scores,\nspecifically, Mauve.",
        "translated": ""
    },
    {
        "title": "QIGen: Generating Efficient Kernels for Quantized Inference on Large\n  Language Models",
        "url": "http://arxiv.org/abs/2307.03738v1",
        "pub_date": "2023-07-07",
        "summary": "We present ongoing work on a new automatic code generation approach for\nsupporting quantized generative inference on LLMs such as LLaMA or OPT on\noff-the-shelf CPUs. Our approach is informed by the target architecture and a\nperformance model, including both hardware characteristics and method-specific\naccuracy constraints. Results on CPU-based inference for LLaMA models show that\nour approach can lead to high performance and high accuracy, comparing\nfavorably to the best existing open-source solution. A preliminary\nimplementation is available at https://github.com/IST-DASLab/QIGen.",
        "translated": ""
    },
    {
        "title": "Improving Automatic Quotation Attribution in Literary Novels",
        "url": "http://arxiv.org/abs/2307.03734v1",
        "pub_date": "2023-07-07",
        "summary": "Current models for quotation attribution in literary novels assume varying\nlevels of available information in their training and test data, which poses a\nchallenge for in-the-wild inference. Here, we approach quotation attribution as\na set of four interconnected sub-tasks: character identification, coreference\nresolution, quotation identification, and speaker attribution. We benchmark\nstate-of-the-art models on each of these sub-tasks independently, using a large\ndataset of annotated coreferences and quotations in literary novels (the\nProject Dialogism Novel Corpus). We also train and evaluate models for the\nspeaker attribution task in particular, showing that a simple sequential\nprediction model achieves accuracy scores on par with state-of-the-art models.",
        "translated": ""
    },
    {
        "title": "INT-FP-QSim: Mixed Precision and Formats For Large Language Models and\n  Vision Transformers",
        "url": "http://arxiv.org/abs/2307.03712v1",
        "pub_date": "2023-07-07",
        "summary": "The recent rise of large language models (LLMs) has resulted in increased\nefforts towards running LLMs at reduced precision. Running LLMs at lower\nprecision supports resource constraints and furthers their democratization,\nenabling users to run billion-parameter LLMs on their personal devices. To\nsupplement this ongoing effort, we propose INT-FP-QSim: an open-source\nsimulator that enables flexible evaluation of LLMs and vision transformers at\nvarious numerical precisions and formats. INT-FP-QSim leverages existing\nopen-source repositories such as TensorRT, QPytorch and AIMET for a combined\nsimulator that supports various floating point and integer formats. With the\nhelp of our simulator, we survey the impact of different numerical formats on\nthe performance of LLMs and vision transformers at 4-bit weights and 4-bit or\n8-bit activations. We also compare recently proposed methods like Adaptive\nBlock Floating Point, SmoothQuant, GPTQ and RPTQ on the model performances. We\nhope INT-FP-QSim will enable researchers to flexibly simulate models at various\nprecisions to support further research in quantization of LLMs and vision\ntransformers.",
        "translated": ""
    },
    {
        "title": "Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug\n  Trafficking Detection on Social Media",
        "url": "http://arxiv.org/abs/2307.03699v1",
        "pub_date": "2023-07-07",
        "summary": "Social media platforms such as Instagram and Twitter have emerged as critical\nchannels for drug marketing and illegal sale. Detecting and labeling online\nillicit drug trafficking activities becomes important in addressing this issue.\nHowever, the effectiveness of conventional supervised learning methods in\ndetecting drug trafficking heavily relies on having access to substantial\namounts of labeled data, while data annotation is time-consuming and\nresource-intensive. Furthermore, these models often face challenges in\naccurately identifying trafficking activities when drug dealers use deceptive\nlanguage and euphemisms to avoid detection. To overcome this limitation, we\nconduct the first systematic study on leveraging large language models (LLMs),\nsuch as ChatGPT, to detect illicit drug trafficking activities on social media.\nWe propose an analytical framework to compose \\emph{knowledge-informed\nprompts}, which serve as the interface that humans can interact with and use\nLLMs to perform the detection task. Additionally, we design a Monte Carlo\ndropout based prompt optimization method to further to improve performance and\ninterpretability. Our experimental findings demonstrate that the proposed\nframework outperforms other baseline language models in terms of drug\ntrafficking detection accuracy, showing a remarkable improvement of nearly\n12\\%. By integrating prior knowledge and the proposed prompts, ChatGPT can\neffectively identify and label drug trafficking activities on social networks,\neven in the presence of deceptive language and euphemisms used by drug dealers\nto evade detection. The implications of our research extend to social networks,\nemphasizing the importance of incorporating prior knowledge and scenario-based\nprompts into analytical tools to improve online security and public safety.",
        "translated": ""
    },
    {
        "title": "Testing the Predictions of Surprisal Theory in 11 Languages",
        "url": "http://arxiv.org/abs/2307.03667v2",
        "pub_date": "2023-07-07",
        "summary": "A fundamental result in psycholinguistics is that less predictable words take\na longer time to process. One theoretical explanation for this finding is\nSurprisal Theory (Hale, 2001; Levy, 2008), which quantifies a word's\npredictability as its surprisal, i.e. its negative log-probability given a\ncontext. While evidence supporting the predictions of Surprisal Theory have\nbeen replicated widely, most have focused on a very narrow slice of data:\nnative English speakers reading English texts. Indeed, no comprehensive\nmultilingual analysis exists. We address this gap in the current literature by\ninvestigating the relationship between surprisal and reading times in eleven\ndifferent languages, distributed across five language families. Deriving\nestimates from language models trained on monolingual and multilingual corpora,\nwe test three predictions associated with surprisal theory: (i) whether\nsurprisal is predictive of reading times; (ii) whether expected surprisal, i.e.\ncontextual entropy, is predictive of reading times; (iii) and whether the\nlinking function between surprisal and reading times is linear. We find that\nall three predictions are borne out crosslinguistically. By focusing on a more\ndiverse set of languages, we argue that these results offer the most robust\nlink to-date between information theory and incremental language processing\nacross languages.",
        "translated": ""
    },
    {
        "title": "The distribution of discourse relations within and across turns in\n  spontaneous conversation",
        "url": "http://arxiv.org/abs/2307.03645v1",
        "pub_date": "2023-07-07",
        "summary": "Time pressure and topic negotiation may impose constraints on how people\nleverage discourse relations (DRs) in spontaneous conversational contexts. In\nthis work, we adapt a system of DRs for written language to spontaneous\ndialogue using crowdsourced annotations from novice annotators. We then test\nwhether discourse relations are used differently across several types of\nmulti-utterance contexts. We compare the patterns of DR annotation within and\nacross speakers and within and across turns. Ultimately, we find that different\ndiscourse contexts produce distinct distributions of discourse relations, with\nsingle-turn annotations creating the most uncertainty for annotators.\nAdditionally, we find that the discourse relation annotations are of sufficient\nquality to predict from embeddings of discourse units.",
        "translated": ""
    },
    {
        "title": "Text Simplification of Scientific Texts for Non-Expert Readers",
        "url": "http://arxiv.org/abs/2307.03569v1",
        "pub_date": "2023-07-07",
        "summary": "Reading levels are highly individual and can depend on a text's language, a\nperson's cognitive abilities, or knowledge on a topic. Text simplification is\nthe task of rephrasing a text to better cater to the abilities of a specific\ntarget reader group. Simplification of scientific abstracts helps non-experts\nto access the core information by bypassing formulations that require domain or\nexpert knowledge. This is especially relevant for, e.g., cancer patients\nreading about novel treatment options. The SimpleText lab hosts the\nsimplification of scientific abstracts for non-experts (Task 3) to advance this\nfield. We contribute three runs employing out-of-the-box summarization models\n(two based on T5, one based on PEGASUS) and one run using ChatGPT with complex\nphrase identification.",
        "translated": ""
    },
    {
        "title": "DWReCO at CheckThat! 2023: Enhancing Subjectivity Detection through\n  Style-based Data Sampling",
        "url": "http://arxiv.org/abs/2307.03550v1",
        "pub_date": "2023-07-07",
        "summary": "This paper describes our submission for the subjectivity detection task at\nthe CheckThat! Lab. To tackle class imbalances in the task, we have generated\nadditional training materials with GPT-3 models using prompts of different\nstyles from a subjectivity checklist based on journalistic perspective. We used\nthe extended training set to fine-tune language-specific transformer models.\nOur experiments in English, German and Turkish demonstrate that different\nsubjective styles are effective across all languages. In addition, we observe\nthat the style-based oversampling is better than paraphrasing in Turkish and\nEnglish. Lastly, the GPT-3 models sometimes produce lacklustre results when\ngenerating style-based texts in non-English languages.",
        "translated": ""
    },
    {
        "title": "Large Language Models as Batteries-Included Zero-Shot ESCO Skills\n  Matchers",
        "url": "http://arxiv.org/abs/2307.03539v1",
        "pub_date": "2023-07-07",
        "summary": "Understanding labour market dynamics requires accurately identifying the\nskills required for and possessed by the workforce. Automation techniques are\nincreasingly being developed to support this effort. However, automatically\nextracting skills from job postings is challenging due to the vast number of\nexisting skills. The ESCO (European Skills, Competences, Qualifications and\nOccupations) framework provides a useful reference, listing over 13,000\nindividual skills. However, skills extraction remains difficult and accurately\nmatching job posts to the ESCO taxonomy is an open problem. In this work, we\npropose an end-to-end zero-shot system for skills extraction from job\ndescriptions based on large language models (LLMs). We generate synthetic\ntraining data for the entirety of ESCO skills and train a classifier to extract\nskill mentions from job posts. We also employ a similarity retriever to\ngenerate skill candidates which are then re-ranked using a second LLM. Using\nsynthetic data achieves an RP@10 score 10 points higher than previous distant\nsupervision approaches. Adding GPT-4 re-ranking improves RP@10 by over 22\npoints over previous methods. We also show that Framing the task as mock\nprogramming when prompting the LLM can lead to better performance than natural\nlanguage prompts, especially with weaker LLMs. We demonstrate the potential of\nintegrating large language models at both ends of skills matching pipelines.\nOur approach requires no human annotations and achieve extremely promising\nresults on skills extraction against ESCO.",
        "translated": ""
    },
    {
        "title": "Fairness and Diversity in Recommender Systems: A Survey",
        "url": "http://arxiv.org/abs/2307.04644v1",
        "pub_date": "2023-07-10",
        "summary": "Recommender systems are effective tools for mitigating information overload\nand have seen extensive applications across various domains. However, the\nsingle focus on utility goals proves to be inadequate in addressing real-world\nconcerns, leading to increasing attention to fairness-aware and diversity-aware\nrecommender systems. While most existing studies explore fairness and diversity\nindependently, we identify strong connections between these two domains. In\nthis survey, we first discuss each of them individually and then dive into\ntheir connections. Additionally, motivated by the concepts of user-level and\nitem-level fairness, we broaden the understanding of diversity to encompass not\nonly the item level but also the user level. With this expanded perspective on\nuser and item-level diversity, we re-interpret fairness studies from the\nviewpoint of diversity. This fresh perspective enhances our understanding of\nfairness-related work and paves the way for potential future research\ndirections. Papers discussed in this survey along with public code links are\navailable at\nhttps://github.com/YuyingZhao/Awesome-Fairness-and-Diversity-Papers-in-Recommender-Systems .",
        "translated": ""
    },
    {
        "title": "InPars Toolkit: A Unified and Reproducible Synthetic Data Generation\n  Pipeline for Neural Information Retrieval",
        "url": "http://arxiv.org/abs/2307.04601v1",
        "pub_date": "2023-07-10",
        "summary": "Recent work has explored Large Language Models (LLMs) to overcome the lack of\ntraining data for Information Retrieval (IR) tasks. The generalization\nabilities of these models have enabled the creation of synthetic in-domain data\nby providing instructions and a few examples on a prompt. InPars and\nPromptagator have pioneered this approach and both methods have demonstrated\nthe potential of using LLMs as synthetic data generators for IR tasks. This\nmakes them an attractive solution for IR tasks that suffer from a lack of\nannotated data. However, the reproducibility of these methods was limited,\nbecause InPars' training scripts are based on TPUs -- which are not widely\naccessible -- and because the code for Promptagator was not released and its\nproprietary LLM is not publicly accessible. To fully realize the potential of\nthese methods and make their impact more widespread in the research community,\nthe resources need to be accessible and easy to reproduce by researchers and\npractitioners. Our main contribution is a unified toolkit for end-to-end\nreproducible synthetic data generation research, which includes generation,\nfiltering, training and evaluation. Additionally, we provide an interface to IR\nlibraries widely used by the community and support for GPU. Our toolkit not\nonly reproduces the InPars method and partially reproduces Promptagator, but\nalso provides a plug-and-play functionality allowing the use of different LLMs,\nexploring filtering methods and finetuning various reranker models on the\ngenerated data. We also made available all the synthetic data generated in this\nwork for the 18 different datasets in the BEIR benchmark which took more than\n2,000 GPU hours to be generated as well as the reranker models finetuned on the\nsynthetic data. Code and data are available at\nhttps://github.com/zetaalphavector/InPars",
        "translated": ""
    },
    {
        "title": "A Semi-Automated Solution Approach Selection Tool for Any Use Case via\n  Scopus and OpenAI: a Case Study for AI/ML in Oncology",
        "url": "http://arxiv.org/abs/2307.04573v1",
        "pub_date": "2023-07-10",
        "summary": "In today's vast literature landscape, a manual review is very time-consuming.\nTo address this challenge, this paper proposes a semi-automated tool for\nsolution method review and selection. It caters to researchers, practitioners,\nand decision-makers while serving as a benchmark for future work. The tool\ncomprises three modules: (1) paper selection and scoring, using a keyword\nselection scheme to query Scopus API and compute relevancy; (2) solution method\nextraction in papers utilizing OpenAI API; (3) sensitivity analysis and\npost-analyzes. It reveals trends, relevant papers, and methods. AI in the\noncology case study and several use cases are presented with promising results,\ncomparing the tool to manual ground truth.",
        "translated": ""
    },
    {
        "title": "Alleviating Matthew Effect of Offline Reinforcement Learning in\n  Interactive Recommendation",
        "url": "http://arxiv.org/abs/2307.04571v1",
        "pub_date": "2023-07-10",
        "summary": "Offline reinforcement learning (RL), a technology that offline learns a\npolicy from logged data without the need to interact with online environments,\nhas become a favorable choice in decision-making processes like interactive\nrecommendation. Offline RL faces the value overestimation problem. To address\nit, existing methods employ conservatism, e.g., by constraining the learned\npolicy to be close to behavior policies or punishing the rarely visited\nstate-action pairs. However, when applying such offline RL to recommendation,\nit will cause a severe Matthew effect, i.e., the rich get richer and the poor\nget poorer, by promoting popular items or categories while suppressing the less\npopular ones. It is a notorious issue that needs to be addressed in practical\nrecommender systems.\n  In this paper, we aim to alleviate the Matthew effect in offline RL-based\nrecommendation. Through theoretical analyses, we find that the conservatism of\nexisting methods fails in pursuing users' long-term satisfaction. It inspires\nus to add a penalty term to relax the pessimism on states with high entropy of\nthe logging policy and indirectly penalizes actions leading to less diverse\nstates. This leads to the main technical contribution of the work: Debiased\nmodel-based Offline RL (DORL) method. Experiments show that DORL not only\ncaptures user interests well but also alleviates the Matthew effect. The\nimplementation is available via https://github.com/chongminggao/DORL-codes.",
        "translated": ""
    },
    {
        "title": "Counterfactual Explanation for Fairness in Recommendation",
        "url": "http://arxiv.org/abs/2307.04386v1",
        "pub_date": "2023-07-10",
        "summary": "Fairness-aware recommendation eliminates discrimination issues to build\ntrustworthy recommendation systems.Explaining the causes of unfair\nrecommendations is critical, as it promotes fairness diagnostics, and thus\nsecures users' trust in recommendation models. Existing fairness explanation\nmethods suffer high computation burdens due to the large-scale search space and\nthe greedy nature of the explanation search process. Besides, they perform\nscore-based optimizations with continuous values, which are not applicable to\ndiscrete attributes such as gender and race. In this work, we adopt the novel\nparadigm of counterfactual explanation from causal inference to explore how\nminimal alterations in explanations change model fairness, to abandon the\ngreedy search for explanations. We use real-world attributes from Heterogeneous\nInformation Networks (HINs) to empower counterfactual reasoning on discrete\nattributes. We propose a novel Counterfactual Explanation for Fairness\n(CFairER) that generates attribute-level counterfactual explanations from HINs\nfor recommendation fairness. Our CFairER conducts off-policy reinforcement\nlearning to seek high-quality counterfactual explanations, with an attentive\naction pruning reducing the search space of candidate counterfactuals. The\ncounterfactual explanations help to provide rational and proximate explanations\nfor model fairness, while the attentive action pruning narrows the search space\nof attributes. Extensive experiments demonstrate our proposed model can\ngenerate faithful explanations while maintaining favorable recommendation\nperformance.",
        "translated": ""
    },
    {
        "title": "Large Language Models as General Pattern Machines",
        "url": "http://arxiv.org/abs/2307.04721v1",
        "pub_date": "2023-07-10",
        "summary": "We observe that pre-trained large language models (LLMs) are capable of\nautoregressively completing complex token sequences -- from arbitrary ones\nprocedurally generated by probabilistic context-free grammars (PCFG), to more\nrich spatial patterns found in the Abstract Reasoning Corpus (ARC), a general\nAI benchmark, prompted in the style of ASCII art. Surprisingly, pattern\ncompletion proficiency can be partially retained even when the sequences are\nexpressed using tokens randomly sampled from the vocabulary. These results\nsuggest that without any additional training, LLMs can serve as general\nsequence modelers, driven by in-context learning. In this work, we investigate\nhow these zero-shot capabilities may be applied to problems in robotics -- from\nextrapolating sequences of numbers that represent states over time to complete\nsimple motions, to least-to-most prompting of reward-conditioned trajectories\nthat can discover and represent closed-loop policies (e.g., a stabilizing\ncontroller for CartPole). While difficult to deploy today for real systems due\nto latency, context size limitations, and compute costs, the approach of using\nLLMs to drive low-level control may provide an exciting glimpse into how the\npatterns among words could be transferred to actions.",
        "translated": ""
    },
    {
        "title": "BeaverTails: Towards Improved Safety Alignment of LLM via a\n  Human-Preference Dataset",
        "url": "http://arxiv.org/abs/2307.04657v1",
        "pub_date": "2023-07-10",
        "summary": "In this paper, we introduce the BeaverTails dataset, aimed at fostering\nresearch on safety alignment in large language models (LLMs). This dataset\nuniquely separates annotations of helpfulness and harmlessness for\nquestion-answering pairs, thus offering distinct perspectives on these crucial\nattributes. In total, we have compiled safety meta-labels for 30,207\nquestion-answer (QA) pairs and gathered 30,144 pairs of expert comparison data\nfor both the helpfulness and harmlessness metrics. We further showcase\napplications of BeaverTails in content moderation and reinforcement learning\nwith human feedback (RLHF), emphasizing its potential for practical safety\nmeasures in LLMs. We believe this dataset provides vital resources for the\ncommunity, contributing towards the safe development and deployment of LLMs.\nOur project page is available at the following URL:\nhttps://sites.google.com/view/pku-beavertails.",
        "translated": ""
    },
    {
        "title": "Measuring Lexical Diversity in Texts: The Twofold Length Problem",
        "url": "http://arxiv.org/abs/2307.04626v1",
        "pub_date": "2023-07-10",
        "summary": "The impact of text length on the estimation of lexical diversity has captured\nthe attention of the scientific community for more than a century. Numerous\nindices have been proposed, and many studies have been conducted to evaluate\nthem, but the problem remains. This methodological review provides a critical\nanalysis not only of the most commonly used indices in language learning\nstudies, but also of the length problem itself, as well as of the methodology\nfor evaluating the proposed solutions. The analysis of three datasets of\nEnglish language-learners' texts revealed that indices that reduce all texts to\nthe same length using a probabilistic or an algorithmic approach solve the\nlength dependency problem; however, all these indices failed to address the\nsecond problem, which is their sensitivity to the parameter that determines the\nlength to which the texts are reduced. The paper concludes with recommendations\nfor optimizing lexical diversity analysis.",
        "translated": ""
    },
    {
        "title": "On the Computational Modeling of Meaning: Embodied Cognition Intertwined\n  with Emotion",
        "url": "http://arxiv.org/abs/2307.04518v1",
        "pub_date": "2023-07-10",
        "summary": "This document chronicles this author's attempt to explore how words come to\nmean what they do, with a particular focus on child language acquisition and\nwhat that means for models of language understanding.\\footnote{I say\n\\emph{historical} because I synthesize the ideas based on when I discovered\nthem and how those ideas influenced my later thinking.} I explain the setting\nfor child language learning, how embodiment -- being able to perceive and enact\nin the world, including knowledge of concrete and abstract concepts -- is\ncrucial, and how emotion and cognition relate to each other and the language\nlearning process. I end with what I think are some of the requirements for a\nlanguage-learning agent that learns language in a setting similar to that of\nchildren. This paper can act as a potential guide for ongoing and future work\nin modeling language.",
        "translated": ""
    },
    {
        "title": "Improving Factuality of Abstractive Summarization via Contrastive Reward\n  Learning",
        "url": "http://arxiv.org/abs/2307.04507v1",
        "pub_date": "2023-07-10",
        "summary": "Modern abstractive summarization models often generate summaries that contain\nhallucinated or contradictory information. In this paper, we propose a simple\nbut effective contrastive learning framework that incorporates recent\ndevelopments in reward learning and factuality metrics. Empirical studies\ndemonstrate that the proposed framework enables summarization models to learn\nfrom feedback of factuality metrics using contrastive reward learning, leading\nto more factual summaries by human evaluations. This suggests that further\nadvances in learning and evaluation algorithms can feed directly into providing\nmore factual summaries.",
        "translated": ""
    },
    {
        "title": "Enhancing Biomedical Text Summarization and Question-Answering: On the\n  Utility of Domain-Specific Pre-Training",
        "url": "http://arxiv.org/abs/2307.04412v1",
        "pub_date": "2023-07-10",
        "summary": "Biomedical summarization requires large datasets to train for text\ngeneration. We show that while transfer learning offers a viable option for\naddressing this challenge, an in-domain pre-training does not always offer\nadvantages in a BioASQ summarization task. We identify a suitable model\narchitecture and use it to show a benefit of a general-domain pre-training\nfollowed by a task-specific fine-tuning in the context of a BioASQ\nsummarization task, leading to a novel three-step fine-tuning approach that\nworks with only a thousand in-domain examples. Our results indicate that a\nLarge Language Model without domain-specific pre-training can have a\nsignificant edge in some domain-specific biomedical text generation tasks.",
        "translated": ""
    },
    {
        "title": "TIM: Teaching Large Language Models to Translate with Comparison",
        "url": "http://arxiv.org/abs/2307.04408v1",
        "pub_date": "2023-07-10",
        "summary": "Open-sourced large language models (LLMs) have demonstrated remarkable\nefficacy in various tasks with instruction tuning. However, these models can\nsometimes struggle with tasks that require more specialized knowledge such as\ntranslation. One possible reason for such deficiency is that instruction tuning\naims to generate fluent and coherent text that continues from a given\ninstruction without being constrained by any task-specific requirements.\nMoreover, it can be more challenging for tuning smaller LLMs with lower-quality\ntraining data. To address this issue, we propose a novel framework using\nexamples in comparison to teach LLMs to learn translation. Our approach\ninvolves presenting the model with examples of correct and incorrect\ntranslations and using a preference loss to guide the model's learning. We\nevaluate our method on WMT2022 test sets and show that it outperforms existing\nmethods. Our findings offer a new perspective on fine-tuning LLMs for\ntranslation tasks and provide a promising solution for generating high-quality\ntranslations. Please refer to Github for more details:\nhttps://github.com/lemon0830/TIM.",
        "translated": ""
    },
    {
        "title": "Ethicist: Targeted Training Data Extraction Through Loss Smoothed Soft\n  Prompting and Calibrated Confidence Estimation",
        "url": "http://arxiv.org/abs/2307.04401v1",
        "pub_date": "2023-07-10",
        "summary": "Large pre-trained language models achieve impressive results across many\ntasks. However, recent works point out that pre-trained language models may\nmemorize a considerable fraction of their training data, leading to the privacy\nrisk of information leakage. In this paper, we propose a method named Ethicist\nfor targeted training data extraction through loss smoothed soft prompting and\ncalibrated confidence estimation, investigating how to recover the suffix in\nthe training data when given a prefix. To elicit memorization in the attacked\nmodel, we tune soft prompt embeddings while keeping the model fixed. We further\npropose a smoothing loss that smooths the loss distribution of the suffix\ntokens to make it easier to sample the correct suffix. In order to select the\nmost probable suffix from a collection of sampled suffixes and estimate the\nprediction confidence, we propose a calibrated confidence estimation method,\nwhich normalizes the confidence of the generated suffixes with a local\nestimation. We show that Ethicist significantly improves the extraction\nperformance on a recently proposed public benchmark. We also investigate\nseveral factors influencing the data extraction performance, including decoding\nstrategy, model scale, prefix length, and suffix length. Our code is available\nat https://github.com/thu-coai/Targeted-Data-Extraction.",
        "translated": ""
    },
    {
        "title": "Enhancing Cross-lingual Transfer via Phonemic Transcription Integration",
        "url": "http://arxiv.org/abs/2307.04361v1",
        "pub_date": "2023-07-10",
        "summary": "Previous cross-lingual transfer methods are restricted to orthographic\nrepresentation learning via textual scripts. This limitation hampers\ncross-lingual transfer and is biased towards languages sharing similar\nwell-known scripts. To alleviate the gap between languages from different\nwriting scripts, we propose PhoneXL, a framework incorporating phonemic\ntranscriptions as an additional linguistic modality beyond the traditional\northographic transcriptions for cross-lingual transfer. Particularly, we\npropose unsupervised alignment objectives to capture (1) local one-to-one\nalignment between the two different modalities, (2) alignment via\nmulti-modality contexts to leverage information from additional modalities, and\n(3) alignment via multilingual contexts where additional bilingual dictionaries\nare incorporated. We also release the first phonemic-orthographic alignment\ndataset on two token-level tasks (Named Entity Recognition and Part-of-Speech\nTagging) among the understudied but interconnected\nChinese-Japanese-Korean-Vietnamese (CJKV) languages. Our pilot study reveals\nphonemic transcription provides essential information beyond the orthography to\nenhance cross-lingual transfer and bridge the gap among CJKV languages, leading\nto consistent improvements on cross-lingual token-level tasks over\northographic-based multilingual PLMs.",
        "translated": ""
    },
    {
        "title": "RLTF: Reinforcement Learning from Unit Test Feedback",
        "url": "http://arxiv.org/abs/2307.04349v1",
        "pub_date": "2023-07-10",
        "summary": "The goal of program synthesis, or code generation, is to generate executable\ncode based on given descriptions. Recently, there has been an increasing number\nof studies employing reinforcement learning (RL) to improve the performance of\nlarge language models (LLMs) for code. However, these RL methods have only used\noffline frameworks, limiting their exploration of new sample spaces.\nAdditionally, current approaches that utilize unit test signals are rather\nsimple, not accounting for specific error locations within the code. To address\nthese issues, we proposed RLTF, i.e., Reinforcement Learning from Unit Test\nFeedback, a novel online RL framework with unit test feedback of\nmulti-granularity for refining code LLMs. Our approach generates data in\nreal-time during training and simultaneously utilizes fine-grained feedback\nsignals to guide the model towards producing higher-quality code. Extensive\nexperiments show that RLTF achieves state-of-the-art performance on the APPS\nand the MBPP benchmarks. Our code can be found at:\nhttps://github.com/Zyq-scut/RLTF.",
        "translated": ""
    },
    {
        "title": "Duncode Characters Shorter",
        "url": "http://arxiv.org/abs/2307.05414v1",
        "pub_date": "2023-07-11",
        "summary": "This paper investigates the employment of various encoders in text\ntransformation, converting characters into bytes. It discusses local encoders\nsuch as ASCII and GB-2312, which encode specific characters into shorter bytes,\nand universal encoders like UTF-8 and UTF-16, which can encode the complete\nUnicode set with greater space requirements and are gaining widespread\nacceptance. Other encoders, including SCSU, BOCU-1, and binary encoders,\nhowever, lack self-synchronizing capabilities. Duncode is introduced as an\ninnovative encoding method that aims to encode the entire Unicode character set\nwith high space efficiency, akin to local encoders. It has the potential to\ncompress multiple characters of a string into a Duncode unit using fewer bytes.\nDespite offering less self-synchronizing identification information, Duncode\nsurpasses UTF8 in terms of space efficiency. The application is available at\n\\url{https://github.com/laohur/duncode}. Additionally, we have developed a\nbenchmark for evaluating character encoders across different languages. It\nencompasses 179 languages and can be accessed at\n\\url{https://github.com/laohur/wiki2txt}.",
        "translated": ""
    },
    {
        "title": "Temporal Graphs Anomaly Emergence Detection: Benchmarking For Social\n  Media Interactions",
        "url": "http://arxiv.org/abs/2307.05268v1",
        "pub_date": "2023-07-11",
        "summary": "Temporal graphs have become an essential tool for analyzing complex dynamic\nsystems with multiple agents. Detecting anomalies in temporal graphs is crucial\nfor various applications, including identifying emerging trends, monitoring\nnetwork security, understanding social dynamics, tracking disease outbreaks,\nand understanding financial dynamics. In this paper, we present a comprehensive\nbenchmarking study that compares 12 data-driven methods for anomaly detection\nin temporal graphs. We conduct experiments on two temporal graphs extracted\nfrom Twitter and Facebook, aiming to identify anomalies in group interactions.\nSurprisingly, our study reveals an unclear pattern regarding the best method\nfor such tasks, highlighting the complexity and challenges involved in anomaly\nemergence detection in large and dynamic systems. The results underscore the\nneed for further research and innovative approaches to effectively detect\nemerging anomalies in dynamic systems represented as temporal graphs.",
        "translated": ""
    },
    {
        "title": "U-CREAT: Unsupervised Case Retrieval using Events extrAcTion",
        "url": "http://arxiv.org/abs/2307.05260v1",
        "pub_date": "2023-07-11",
        "summary": "The task of Prior Case Retrieval (PCR) in the legal domain is about\nautomatically citing relevant (based on facts and precedence) prior legal cases\nin a given query case. To further promote research in PCR, in this paper, we\npropose a new large benchmark (in English) for the PCR task: IL-PCR (Indian\nLegal Prior Case Retrieval) corpus. Given the complex nature of case relevance\nand the long size of legal documents, BM25 remains a strong baseline for\nranking the cited prior documents. In this work, we explore the role of events\nin legal case retrieval and propose an unsupervised retrieval method-based\npipeline U-CREAT (Unsupervised Case Retrieval using Events Extraction). We find\nthat the proposed unsupervised retrieval method significantly increases\nperformance compared to BM25 and makes retrieval faster by a considerable\nmargin, making it applicable to real-time case retrieval systems. Our proposed\nsystem is generic, we show that it generalizes across two different legal\nsystems (Indian and Canadian), and it shows state-of-the-art performance on the\nbenchmarks for both the legal systems (IL-PCR and COLIEE corpora).",
        "translated": ""
    },
    {
        "title": "Generative Contrastive Graph Learning for Recommendation",
        "url": "http://arxiv.org/abs/2307.05100v1",
        "pub_date": "2023-07-11",
        "summary": "By treating users' interactions as a user-item graph, graph learning models\nhave been widely deployed in Collaborative Filtering(CF) based recommendation.\nRecently, researchers have introduced Graph Contrastive Learning(GCL)\ntechniques into CF to alleviate the sparse supervision issue, which first\nconstructs contrastive views by data augmentations and then provides\nself-supervised signals by maximizing the mutual information between\ncontrastive views. Despite the effectiveness, we argue that current GCL-based\nrecommendation models are still limited as current data augmentation\ntechniques, either structure augmentation or feature augmentation. First,\nstructure augmentation randomly dropout nodes or edges, which is easy to\ndestroy the intrinsic nature of the user-item graph. Second, feature\naugmentation imposes the same scale noise augmentation on each node, which\nneglects the unique characteristics of nodes on the graph. To tackle the above\nlimitations, we propose a novel Variational Graph Generative-Contrastive\nLearning(VGCL) framework for recommendation. Specifically, we leverage\nvariational graph reconstruction to estimate a Gaussian distribution of each\nnode, then generate multiple contrastive views through multiple samplings from\nthe estimated distributions, which builds a bridge between generative and\ncontrastive learning. Besides, the estimated variances are tailored to each\nnode, which regulates the scale of contrastive loss for each node on\noptimization. Considering the similarity of the estimated distributions, we\npropose a cluster-aware twofold contrastive learning, a node-level to encourage\nconsistency of a node's contrastive views and a cluster-level to encourage\nconsistency of nodes in a cluster. Finally, extensive experimental results on\nthree public datasets clearly demonstrate the effectiveness of the proposed\nmodel.",
        "translated": ""
    },
    {
        "title": "Retrieval-augmented GPT-3.5-based Text-to-SQL Framework with\n  Sample-aware Prompting and Dynamic Revision Chain",
        "url": "http://arxiv.org/abs/2307.05074v1",
        "pub_date": "2023-07-11",
        "summary": "Text-to-SQL aims at generating SQL queries for the given natural language\nquestions and thus helping users to query databases. Prompt learning with large\nlanguage models (LLMs) has emerged as a recent approach, which designs prompts\nto lead LLMs to understand the input question and generate the corresponding\nSQL. However, it faces challenges with strict SQL syntax requirements. Existing\nwork prompts the LLMs with a list of demonstration examples (i.e. question-SQL\npairs) to generate SQL, but the fixed prompts can hardly handle the scenario\nwhere the semantic gap between the retrieved demonstration and the input\nquestion is large. In this paper, we propose a retrieval-augmented prompting\nmethod for a LLM-based Text-to-SQL framework, involving sample-aware prompting\nand a dynamic revision chain. Our approach incorporates sample-aware\ndemonstrations, which include the composition of SQL operators and fine-grained\ninformation related to the given question. To retrieve questions sharing\nsimilar intents with input questions, we propose two strategies for assisting\nretrieval. Firstly, we leverage LLMs to simplify the original questions,\nunifying the syntax and thereby clarifying the users' intentions. To generate\nexecutable and accurate SQLs without human intervention, we design a dynamic\nrevision chain which iteratively adapts fine-grained feedback from the\npreviously generated SQL. Experimental results on three Text-to-SQL benchmarks\ndemonstrate the superiority of our method over strong baseline models.",
        "translated": ""
    },
    {
        "title": "Empowering Cross-lingual Behavioral Testing of NLP Models with\n  Typological Features",
        "url": "http://arxiv.org/abs/2307.05454v1",
        "pub_date": "2023-07-11",
        "summary": "A challenge towards developing NLP systems for the world's languages is\nunderstanding how they generalize to typological differences relevant for\nreal-world applications. To this end, we propose M2C, a morphologically-aware\nframework for behavioral testing of NLP models. We use M2C to generate tests\nthat probe models' behavior in light of specific linguistic features in 12\ntypologically diverse languages. We evaluate state-of-the-art language models\non the generated tests. While models excel at most tests in English, we\nhighlight generalization failures to specific typological characteristics such\nas temporal expressions in Swahili and compounding possessives in Finish. Our\nfindings motivate the development of models that address these blind spots.",
        "translated": ""
    },
    {
        "title": "ISLTranslate: Dataset for Translating Indian Sign Language",
        "url": "http://arxiv.org/abs/2307.05440v1",
        "pub_date": "2023-07-11",
        "summary": "Sign languages are the primary means of communication for many\nhard-of-hearing people worldwide. Recently, to bridge the communication gap\nbetween the hard-of-hearing community and the rest of the population, several\nsign language translation datasets have been proposed to enable the development\nof statistical sign language translation systems. However, there is a dearth of\nsign language resources for the Indian sign language. This resource paper\nintroduces ISLTranslate, a translation dataset for continuous Indian Sign\nLanguage (ISL) consisting of 31k ISL-English sentence/phrase pairs. To the best\nof our knowledge, it is the largest translation dataset for continuous Indian\nSign Language. We provide a detailed analysis of the dataset. To validate the\nperformance of existing end-to-end Sign language to spoken language translation\nsystems, we benchmark the created dataset with a transformer-based model for\nISL translation.",
        "translated": ""
    },
    {
        "title": "BLUEX: A benchmark based on Brazilian Leading Universities Entrance\n  eXams",
        "url": "http://arxiv.org/abs/2307.05410v1",
        "pub_date": "2023-07-11",
        "summary": "One common trend in recent studies of language models (LMs) is the use of\nstandardized tests for evaluation. However, despite being the fifth most spoken\nlanguage worldwide, few such evaluations have been conducted in Portuguese.\nThis is mainly due to the lack of high-quality datasets available to the\ncommunity for carrying out evaluations in Portuguese. To address this gap, we\nintroduce the Brazilian Leading Universities Entrance eXams (BLUEX), a dataset\nof entrance exams from the two leading universities in Brazil: UNICAMP and USP.\nThe dataset includes annotated metadata for evaluating the performance of NLP\nmodels on a variety of subjects. Furthermore, BLUEX includes a collection of\nrecently administered exams that are unlikely to be included in the training\ndata of many popular LMs as of 2023. The dataset is also annotated to indicate\nthe position of images in each question, providing a valuable resource for\nadvancing the state-of-the-art in multimodal language understanding and\nreasoning. We describe the creation and characteristics of BLUEX and establish\na benchmark through experiments with state-of-the-art LMs, demonstrating its\npotential for advancing the state-of-the-art in natural language understanding\nand reasoning in Portuguese. The data and relevant code can be found at\nhttps://github.com/Portuguese-Benchmark-Datasets/BLUEX",
        "translated": ""
    },
    {
        "title": "GujiBERT and GujiGPT: Construction of Intelligent Information Processing\n  Foundation Language Models for Ancient Texts",
        "url": "http://arxiv.org/abs/2307.05354v1",
        "pub_date": "2023-07-11",
        "summary": "In the context of the rapid development of large language models, we have\nmeticulously trained and introduced the GujiBERT and GujiGPT language models,\nwhich are foundational models specifically designed for intelligent information\nprocessing of ancient texts. These models have been trained on an extensive\ndataset that encompasses both simplified and traditional Chinese characters,\nallowing them to effectively handle various natural language processing tasks\nrelated to ancient books, including but not limited to automatic sentence\nsegmentation, punctuation, word segmentation, part-of-speech tagging, entity\nrecognition, and automatic translation. Notably, these models have exhibited\nexceptional performance across a range of validation tasks using publicly\navailable datasets. Our research findings highlight the efficacy of employing\nself-supervised methods to further train the models using classical text\ncorpora, thus enhancing their capability to tackle downstream tasks. Moreover,\nit is worth emphasizing that the choice of font, the scale of the corpus, and\nthe initial model selection all exert significant influence over the ultimate\nexperimental outcomes. To cater to the diverse text processing preferences of\nresearchers in digital humanities and linguistics, we have developed three\ndistinct categories comprising a total of nine model variations. We believe\nthat by sharing these foundational language models specialized in the domain of\nancient texts, we can facilitate the intelligent processing and scholarly\nexploration of ancient literary works and, consequently, contribute to the\nglobal dissemination of China's rich and esteemed traditional culture in this\nnew era.",
        "translated": ""
    },
    {
        "title": "Explaining Competitive-Level Programming Solutions using LLMs",
        "url": "http://arxiv.org/abs/2307.05337v1",
        "pub_date": "2023-07-11",
        "summary": "In this paper, we approach competitive-level programming problem-solving as a\ncomposite task of reasoning and code generation. We propose a novel method to\nautomatically annotate natural language explanations to \\textit{&lt;problem,\nsolution&gt;} pairs. We show that despite poor performance in solving\ncompetitive-level programming problems, state-of-the-art LLMs exhibit a strong\ncapacity in describing and explaining solutions. Our explanation generation\nmethodology can generate a structured solution explanation for the problem\ncontaining descriptions and analysis. To evaluate the quality of the annotated\nexplanations, we examine their effectiveness in two aspects: 1) satisfying the\nhuman programming expert who authored the oracle solution, and 2) aiding LLMs\nin solving problems more effectively. The experimental results on the\nCodeContests dataset demonstrate that while LLM GPT3.5's and GPT-4's abilities\nin describing the solution are comparable, GPT-4 shows a better understanding\nof the key idea behind the solution.",
        "translated": ""
    },
    {
        "title": "Unleashing Cognitive Synergy in Large Language Models: A Task-Solving\n  Agent through Multi-Persona Self-Collaboration",
        "url": "http://arxiv.org/abs/2307.05300v1",
        "pub_date": "2023-07-11",
        "summary": "Human intelligence thrives on the concept of cognitive synergy, where\ncollaboration and information integration among different cognitive processes\nyield superior outcomes compared to individual cognitive processes in\nisolation. Although Large Language Models (LLMs) have demonstrated promising\nperformance as general task-solving agents, they still struggle with tasks that\nrequire intensive domain knowledge and complex reasoning. In this work, we\npropose Solo Performance Prompting (SPP), which transforms a single LLM into a\ncognitive synergist by engaging in multi-turn self-collaboration with multiple\npersonas. A cognitive synergist refers to an intelligent agent that\ncollaborates with multiple minds, combining their individual strengths and\nknowledge, to enhance problem-solving and overall performance in complex tasks.\nBy dynamically identifying and simulating different personas based on task\ninputs, SPP unleashes the potential of cognitive synergy in LLMs. We have\ndiscovered that assigning multiple, fine-grained personas in LLMs elicits\nbetter problem-solving abilities compared to using a single or fixed number of\npersonas. We evaluate SPP on three challenging tasks: Trivia Creative Writing,\nCodenames Collaborative, and Logic Grid Puzzle, encompassing both\nknowledge-intensive and reasoning-intensive types. Unlike previous works, such\nas Chain-of-Thought, that solely enhance the reasoning abilities in LLMs, SPP\neffectively elicits internal knowledge acquisition abilities, reduces\nhallucination, and maintains strong reasoning capabilities. Code, data, and\nprompts can be found at:\nhttps://github.com/MikeWangWZHL/Solo-Performance-Prompting.git.",
        "translated": ""
    },
    {
        "title": "Attribute Controlled Dialogue Prompting",
        "url": "http://arxiv.org/abs/2307.05228v1",
        "pub_date": "2023-07-11",
        "summary": "Prompt-tuning has become an increasingly popular parameter-efficient method\nfor adapting large pretrained language models to downstream tasks. However,\nboth discrete prompting and continuous prompting assume fixed prompts for all\ndata samples within a task, neglecting the fact that inputs vary greatly in\nsome tasks such as open-domain dialogue generation. In this paper, we present a\nnovel, instance-specific prompt-tuning algorithm for dialogue generation.\nSpecifically, we generate prompts based on instance-level control code, rather\nthan the conversation history, to explore their impact on controlled dialogue\ngeneration. Experiments on popular open-domain dialogue datasets, evaluated on\nboth automated metrics and human evaluation, demonstrate that our method is\nsuperior to prompting baselines and comparable to fine-tuning with only 5%-6%\nof total parameters.",
        "translated": ""
    },
    {
        "title": "Mao-Zedong At SemEval-2023 Task 4: Label Represention Multi-Head\n  Attention Model With Contrastive Learning-Enhanced Nearest Neighbor Mechanism\n  For Multi-Label Text Classification",
        "url": "http://arxiv.org/abs/2307.05174v1",
        "pub_date": "2023-07-11",
        "summary": "The study of human values is essential in both practical and theoretical\ndomains. With the development of computational linguistics, the creation of\nlarge-scale datasets has made it possible to automatically recognize human\nvalues accurately. SemEval 2023 Task 4\\cite{kiesel:2023} provides a set of\narguments and 20 types of human values that are implicitly expressed in each\nargument. In this paper, we present our team's solution. We use the\nRoberta\\cite{liu_roberta_2019} model to obtain the word vector encoding of the\ndocument and propose a multi-head attention mechanism to establish connections\nbetween specific labels and semantic components. Furthermore, we use a\ncontrastive learning-enhanced K-nearest neighbor\nmechanism\\cite{su_contrastive_2022} to leverage existing instance information\nfor prediction. Our approach achieved an F1 score of 0.533 on the test set and\nranked fourth on the leaderboard.",
        "translated": ""
    },
    {
        "title": "Testing different Log Bases For Vector Model Weighting Technique",
        "url": "http://arxiv.org/abs/2307.06213v1",
        "pub_date": "2023-07-12",
        "summary": "Information retrieval systems retrieves relevant documents based on a query\nsubmitted by the user. The documents are initially indexed and the words in the\ndocuments are assigned weights using a weighting technique called TFIDF which\nis the product of Term Frequency (TF) and Inverse Document Frequency (IDF). TF\nrepresents the number of occurrences of a term in a document. IDF measures\nwhether the term is common or rare across all documents. It is computed by\ndividing the total number of documents in the system by the number of documents\ncontaining the term and then computing the logarithm of the quotient. By\ndefault, we use base 10 to calculate the logarithm. In this paper, we are going\nto test this weighting technique by using a range of log bases from 0.1 to\n100.0 to calculate the IDF. Testing different log bases for vector model\nweighting technique is to highlight the importance of understanding the\nperformance of the system at different weighting values. We use the documents\nof MED, CRAN, NPL, LISA, and CISI test collections that scientists assembled\nexplicitly for experiments in data information retrieval systems.",
        "translated": ""
    },
    {
        "title": "DDNAS: Discretized Differentiable Neural Architecture Search for Text\n  Classification",
        "url": "http://arxiv.org/abs/2307.06005v1",
        "pub_date": "2023-07-12",
        "summary": "Neural Architecture Search (NAS) has shown promising capability in learning\ntext representation. However, existing text-based NAS neither performs a\nlearnable fusion of neural operations to optimize the architecture, nor encodes\nthe latent hierarchical categorization behind text input. This paper presents a\nnovel NAS method, Discretized Differentiable Neural Architecture Search\n(DDNAS), for text representation learning and classification. With the\ncontinuous relaxation of architecture representation, DDNAS can use gradient\ndescent to optimize the search. We also propose a novel discretization layer\nvia mutual information maximization, which is imposed on every search node to\nmodel the latent hierarchical categorization in text representation. Extensive\nexperiments conducted on eight diverse real datasets exhibit that DDNAS can\nconsistently outperform the state-of-the-art NAS methods. While DDNAS relies on\nonly three basic operations, i.e., convolution, pooling, and none, to be the\ncandidates of NAS building blocks, its promising performance is noticeable and\nextensible to obtain further improvement by adding more different operations.",
        "translated": ""
    },
    {
        "title": "Contrastive Learning for Conversion Rate Prediction",
        "url": "http://arxiv.org/abs/2307.05974v1",
        "pub_date": "2023-07-12",
        "summary": "Conversion rate (CVR) prediction plays an important role in advertising\nsystems. Recently, supervised deep neural network-based models have shown\npromising performance in CVR prediction. However, they are data hungry and\nrequire an enormous amount of training data. In online advertising systems,\nalthough there are millions to billions of ads, users tend to click only a\nsmall set of them and to convert on an even smaller set. This data sparsity\nissue restricts the power of these deep models. In this paper, we propose the\nContrastive Learning for CVR prediction (CL4CVR) framework. It associates the\nsupervised CVR prediction task with a contrastive learning task, which can\nlearn better data representations exploiting abundant unlabeled data and\nimprove the CVR prediction performance. To tailor the contrastive learning task\nto the CVR prediction problem, we propose embedding masking (EM), rather than\nfeature masking, to create two views of augmented samples. We also propose a\nfalse negative elimination (FNE) component to eliminate samples with the same\nfeature as the anchor sample, to account for the natural property in user\nbehavior data. We further propose a supervised positive inclusion (SPI)\ncomponent to include additional positive samples for each anchor sample, in\norder to make full use of sparse but precious user conversion events.\nExperimental results on two real-world conversion datasets demonstrate the\nsuperior performance of CL4CVR. The source code is available at\nhttps://github.com/DongRuiHust/CL4CVR.",
        "translated": ""
    },
    {
        "title": "Relational Extraction on Wikipedia Tables using Convolutional and Memory\n  Networks",
        "url": "http://arxiv.org/abs/2307.05827v1",
        "pub_date": "2023-07-11",
        "summary": "Relation extraction (RE) is the task of extracting relations between entities\nin text. Most RE methods extract relations from free-form running text and\nleave out other rich data sources, such as tables. We explore RE from the\nperspective of applying neural methods on tabularly organized data. We\nintroduce a new model consisting of Convolutional Neural Network (CNN) and\nBidirectional-Long Short Term Memory (BiLSTM) network to encode entities and\nlearn dependencies among them, respectively. We evaluate our model on a large\nand recent dataset and compare results with previous neural methods.\nExperimental results show that our model consistently outperforms the previous\nmodel for the task of relation extraction on tabular data. We perform\ncomprehensive error analyses and ablation study to show the contribution of\nvarious components of our model. Finally, we discuss the usefulness and\ntrade-offs of our approach, and provide suggestions for fostering further\nresearch.",
        "translated": ""
    },
    {
        "title": "Instruction Mining: High-Quality Instruction Data Selection for Large\n  Language Models",
        "url": "http://arxiv.org/abs/2307.06290v1",
        "pub_date": "2023-07-12",
        "summary": "Large language models typically undergo two training stages, pretraining and\nfinetuning. Despite that large-scale pretraining endows the model with strong\ncapabilities to generate natural language responses, these pretrained models\ncan still fail to understand human instructions at times. To enhance language\nmodels' ability of interpreting and responding to instructions, instruction\nfinetuning has emerged as a critical method in this area. Recent studies found\nthat large language models can be finetuned to perform well even with a small\namount of high-quality instruction-following data. However, the selection of\nhigh-quality datasets for finetuning language models still lacks clear\nguidelines to follow. In this paper, we propose InstructMining, a linear rule\nfor evaluating instruction-following data quality. We formulate InstructMining\nusing specific natural language indicators. To investigate the relationship\nbetween data quality and these indicators, we further conduct extensive\nfinetuning experiments. The experiment results are then applied to estimating\nparameters in InstructMining. To further investigate its performance, we use\nInstructMining to select high-quality data from unseen datasets. Results\ndemonstrate that InstructMining can help select relatively high-quality samples\nfrom various instruction-following datasets. Compared to models finetuned on\nunfiltered datasets, models finetuned on InstructMining selected datasets\nperform better on 42.5% cases.",
        "translated": ""
    },
    {
        "title": "MMBench: Is Your Multi-modal Model an All-around Player?",
        "url": "http://arxiv.org/abs/2307.06281v1",
        "pub_date": "2023-07-12",
        "summary": "Large vision-language models have recently achieved remarkable progress,\nexhibiting great perception and reasoning abilities concerning visual\ninformation. However, how to effectively evaluate these large vision-language\nmodels remains a major obstacle, hindering future model development.\nTraditional benchmarks like VQAv2 or COCO Caption provide quantitative\nperformance measurements but suffer from a lack of fine-grained ability\nassessment and non-robust evaluation metrics. Recent subjective benchmarks,\nsuch as OwlEval, offer comprehensive evaluations of a model's abilities by\nincorporating human labor, but they are not scalable and display significant\nbias. In response to these challenges, we propose MMBench, a novel\nmulti-modality benchmark. MMBench methodically develops a comprehensive\nevaluation pipeline, primarily comprised of two elements. The first element is\na meticulously curated dataset that surpasses existing similar benchmarks in\nterms of the number and variety of evaluation questions and abilities. The\nsecond element introduces a novel CircularEval strategy and incorporates the\nuse of ChatGPT. This implementation is designed to convert free-form\npredictions into pre-defined choices, thereby facilitating a more robust\nevaluation of the model's predictions. MMBench is a systematically-designed\nobjective benchmark for robustly evaluating the various abilities of\nvision-language models. We hope MMBench will assist the research community in\nbetter evaluating their models and encourage future advancements in this\ndomain. Project page: https://opencompass.org.cn/mmbench.",
        "translated": ""
    },
    {
        "title": "Ashaar: Automatic Analysis and Generation of Arabic Poetry Using Deep\n  Learning Approaches",
        "url": "http://arxiv.org/abs/2307.06218v1",
        "pub_date": "2023-07-12",
        "summary": "Poetry holds immense significance within the cultural and traditional fabric\nof any nation. It serves as a vehicle for poets to articulate their emotions,\npreserve customs, and convey the essence of their culture. Arabic poetry is no\nexception, having played a cherished role in the heritage of the Arabic\ncommunity throughout history and maintaining its relevance in the present era.\nTypically, comprehending Arabic poetry necessitates the expertise of a linguist\nwho can analyze its content and assess its quality. This paper presents the\nintroduction of a framework called \\textit{Ashaar}\nhttps://github.com/ARBML/Ashaar, which encompasses a collection of datasets and\npre-trained models designed specifically for the analysis and generation of\nArabic poetry. The pipeline established within our proposed approach\nencompasses various aspects of poetry, such as meter, theme, and era\nclassification. It also incorporates automatic poetry diacritization, enabling\nmore intricate analyses like automated extraction of the \\textit{Arudi} style.\nAdditionally, we explore the feasibility of generating conditional poetry\nthrough the pre-training of a character-based GPT model. Furthermore, as part\nof this endeavor, we provide four datasets: one for poetry generation, another\nfor diacritization, and two for Arudi-style prediction. These datasets aim to\nfacilitate research and development in the field of Arabic poetry by enabling\nresearchers and enthusiasts to delve into the nuances of this rich literary\ntradition.",
        "translated": ""
    },
    {
        "title": "Self-Adaptive Large Language Model (LLM)-Based Multiagent Systems",
        "url": "http://arxiv.org/abs/2307.06187v1",
        "pub_date": "2023-07-12",
        "summary": "In autonomic computing, self-adaptation has been proposed as a fundamental\nparadigm to manage the complexity of multiagent systems (MASs). This achieved\nby extending a system with support to monitor and adapt itself to achieve\nspecific concerns of interest. Communication in these systems is key given that\nin scenarios involving agent interaction, it enhances cooperation and reduces\ncoordination challenges by enabling direct, clear information exchange.\nHowever, improving the expressiveness of the interaction communication with\nMASs is not without challenges. In this sense, the interplay between\nself-adaptive systems and effective communication is crucial for future MAS\nadvancements. In this paper, we propose the integration of large language\nmodels (LLMs) such as GPT-based technologies into multiagent systems. We anchor\nour methodology on the MAPE-K model, which is renowned for its robust support\nin monitoring, analyzing, planning, and executing system adaptations in\nresponse to dynamic environments. We also present a practical illustration of\nthe proposed approach, in which we implement and assess a basic MAS-based\napplication. The approach significantly advances the state-of-the-art of\nself-adaptive systems by proposing a new paradigm for MAS self-adaptation of\nautonomous systems based on LLM capabilities.",
        "translated": ""
    },
    {
        "title": "Enhancing Portuguese Sign Language Animation with Dynamic Timing and\n  Mouthing",
        "url": "http://arxiv.org/abs/2307.06124v1",
        "pub_date": "2023-07-12",
        "summary": "Current signing avatars are often described as unnatural as they cannot\naccurately reproduce all the subtleties of synchronized body behaviors of a\nhuman signer. In this paper, we propose a new dynamic approach for transitions\nbetween signs, focusing on mouthing animations for Portuguese Sign Language.\nAlthough native signers preferred animations with dynamic transitions, we did\nnot find significant differences in comprehension and perceived naturalness\nscores. On the other hand, we show that including mouthing behaviors improved\ncomprehension and perceived naturalness for novice sign language learners.\nResults have implications in computational linguistics, human-computer\ninteraction, and synthetic animation of signing avatars.",
        "translated": ""
    },
    {
        "title": "VELMA: Verbalization Embodiment of LLM Agents for Vision and Language\n  Navigation in Street View",
        "url": "http://arxiv.org/abs/2307.06082v1",
        "pub_date": "2023-07-12",
        "summary": "Incremental decision making in real-world environments is one of the most\nchallenging tasks in embodied artificial intelligence. One particularly\ndemanding scenario is Vision and Language Navigation~(VLN) which requires\nvisual and natural language understanding as well as spatial and temporal\nreasoning capabilities. The embodied agent needs to ground its understanding of\nnavigation instructions in observations of a real-world environment like Street\nView. Despite the impressive results of LLMs in other research areas, it is an\nongoing problem of how to best connect them with an interactive visual\nenvironment. In this work, we propose VELMA, an embodied LLM agent that uses a\nverbalization of the trajectory and of visual environment observations as\ncontextual prompt for the next action. Visual information is verbalized by a\npipeline that extracts landmarks from the human written navigation instructions\nand uses CLIP to determine their visibility in the current panorama view. We\nshow that VELMA is able to successfully follow navigation instructions in\nStreet View with only two in-context examples. We further finetune the LLM\nagent on a few thousand examples and achieve 25%-30% relative improvement in\ntask completion over the previous state-of-the-art for two datasets.",
        "translated": ""
    },
    {
        "title": "Interpreting deep embeddings for disease progression clustering",
        "url": "http://arxiv.org/abs/2307.06060v1",
        "pub_date": "2023-07-12",
        "summary": "We propose a novel approach for interpreting deep embeddings in the context\nof patient clustering. We evaluate our approach on a dataset of participants\nwith type 2 diabetes from the UK Biobank, and demonstrate clinically meaningful\ninsights into disease progression patterns.",
        "translated": ""
    },
    {
        "title": "A Study on the Appropriate size of the Mongolian general corpus",
        "url": "http://arxiv.org/abs/2307.06050v1",
        "pub_date": "2023-07-12",
        "summary": "This study aims to determine the appropriate size of the Mongolian general\ncorpus. This study used the Heaps function and Type Token Ratio to determine\nthe appropriate size of the Mongolian general corpus. The sample corpus of\n906,064 tokens comprised texts from 10 domains of newspaper politics, economy,\nsociety, culture, sports, world articles and laws, middle and high school\nliterature textbooks, interview articles, and podcast transcripts. First, we\nestimated the Heaps function with this sample corpus. Next, we observed changes\nin the number of types and TTR values while increasing the number of tokens by\none million using the estimated Heaps function. As a result of observation, we\nfound that the TTR value hardly changed when the number of tokens exceeded from\n39 to 42 million. Thus, we conclude that an appropriate size for a Mongolian\ngeneral corpus is from 39 to 42 million tokens.",
        "translated": ""
    },
    {
        "title": "Pluggable Neural Machine Translation Models via Memory-augmented\n  Adapters",
        "url": "http://arxiv.org/abs/2307.06029v1",
        "pub_date": "2023-07-12",
        "summary": "Although neural machine translation (NMT) models perform well in the general\ndomain, it remains rather challenging to control their generation behavior to\nsatisfy the requirement of different users. Given the expensive training cost\nand the data scarcity challenge of learning a new model from scratch for each\nuser requirement, we propose a memory-augmented adapter to steer pretrained NMT\nmodels in a pluggable manner. Specifically, we construct a multi-granular\nmemory based on the user-provided text samples and propose a new adapter\narchitecture to combine the model representations and the retrieved results. We\nalso propose a training strategy using memory dropout to reduce spurious\ndependencies between the NMT model and the memory. We validate our approach on\nboth style- and domain-specific experiments and the results indicate that our\nmethod can outperform several representative pluggable baselines.",
        "translated": ""
    },
    {
        "title": "PolyLM: An Open Source Polyglot Large Language Model",
        "url": "http://arxiv.org/abs/2307.06018v1",
        "pub_date": "2023-07-12",
        "summary": "Large language models (LLMs) demonstrate remarkable ability to comprehend,\nreason, and generate following nature language instructions. However, the\ndevelopment of LLMs has been primarily focused on high-resource languages, such\nas English, thereby limiting their applicability and research in other\nlanguages. Consequently, we present PolyLM, a multilingual LLM trained on 640\nbillion (B) tokens, avaliable in two model sizes: 1.7B and 13B. To enhance its\nmultilingual capabilities, we 1) integrate bilingual data into training data;\nand 2) adopt a curriculum learning strategy that increases the proportion of\nnon-English data from 30% in the first stage to 60% in the final stage during\npre-training. Further, we propose a multilingual self-instruct method which\nautomatically generates 132.7K diverse multilingual instructions for model\nfine-tuning. To assess the model's performance, we collect several existing\nmultilingual tasks, including multilingual understanding, question answering,\ngeneration, and translation. Extensive experiments show that PolyLM surpasses\nother open-source models such as LLaMA and BLOOM on multilingual tasks while\nmaintaining comparable performance in English. Our models, alone with the\ninstruction data and multilingual benchmark, are available at:\n\\url{https://modelscope.cn/models/damo/nlp_polylm_13b_text_generation}.",
        "translated": ""
    },
    {
        "title": "Parmesan: mathematical concept extraction for education",
        "url": "http://arxiv.org/abs/2307.06699v1",
        "pub_date": "2023-07-13",
        "summary": "Mathematics is a highly specialized domain with its own unique set of\nchallenges that has seen limited study in natural language processing. However,\nmathematics is used in a wide variety of fields and multidisciplinary research\nin many different domains often relies on an understanding of mathematical\nconcepts. To aid researchers coming from other fields, we develop a prototype\nsystem for searching for and defining mathematical concepts in context,\nfocusing on the field of category theory. This system, Parmesan, depends on\nnatural language processing components including concept extraction, relation\nextraction, definition extraction, and entity linking. In developing this\nsystem, we show that existing techniques cannot be applied directly to the\ncategory theory domain, and suggest hybrid techniques that do perform well,\nthough we expect the system to evolve over time. We also provide two cleaned\nmathematical corpora that power the prototype system, which are based on\njournal articles and wiki pages, respectively. The corpora have been annotated\nwith dependency trees, lemmas, and part-of-speech tags.",
        "translated": ""
    },
    {
        "title": "Going Beyond Local: Global Graph-Enhanced Personalized News\n  Recommendations",
        "url": "http://arxiv.org/abs/2307.06576v1",
        "pub_date": "2023-07-13",
        "summary": "Precisely recommending candidate news articles to users has always been a\ncore challenge for personalized news recommendation systems. Most recent works\nprimarily focus on using advanced natural language processing techniques to\nextract semantic information from rich textual data, employing content-based\nmethods derived from local historical news. However, this approach lacks a\nglobal perspective, failing to account for users' hidden motivations and\nbehaviors beyond semantic information. To address this challenge, we propose a\nnovel model called GLORY (Global-LOcal news Recommendation sYstem), which\ncombines global representations learned from other users with local\nrepresentations to enhance personalized recommendation systems. We accomplish\nthis by constructing a Global-aware Historical News Encoder, which includes a\nglobal news graph and employs gated graph neural networks to enrich news\nrepresentations, thereby fusing historical news representations by a historical\nnews aggregator. Similarly, we extend this approach to a Global Candidate News\nEncoder, utilizing a global entity graph and a candidate news aggregator to\nenhance candidate news representation. Evaluation results on two public news\ndatasets demonstrate that our method outperforms existing approaches.\nFurthermore, our model offers more diverse recommendations.",
        "translated": ""
    },
    {
        "title": "Assessing the Ability of ChatGPT to Screen Articles for Systematic\n  Reviews",
        "url": "http://arxiv.org/abs/2307.06464v1",
        "pub_date": "2023-07-12",
        "summary": "By organizing knowledge within a research field, Systematic Reviews (SR)\nprovide valuable leads to steer research. Evidence suggests that SRs have\nbecome first-class artifacts in software engineering. However, the tedious\nmanual effort associated with the screening phase of SRs renders these studies\na costly and error-prone endeavor. While screening has traditionally been\nconsidered not amenable to automation, the advent of generative AI-driven\nchatbots, backed with large language models is set to disrupt the field. In\nthis report, we propose an approach to leverage these novel technological\ndevelopments for automating the screening of SRs. We assess the consistency,\nclassification performance, and generalizability of ChatGPT in screening\narticles for SRs and compare these figures with those of traditional\nclassifiers used in SR automation. Our results indicate that ChatGPT is a\nviable option to automate the SR processes, but requires careful considerations\nfrom developers when integrating ChatGPT into their SR tools.",
        "translated": ""
    },
    {
        "title": "In-context Autoencoder for Context Compression in a Large Language Model",
        "url": "http://arxiv.org/abs/2307.06945v1",
        "pub_date": "2023-07-13",
        "summary": "We propose the In-context Autoencoder (ICAE) for context compression in a\nlarge language model (LLM). The ICAE has two modules: a learnable encoder\nadapted with LoRA from an LLM for compressing a long context into a limited\nnumber of memory slots, and a fixed decoder which is the target LLM that can\ncondition on the memory slots for various purposes. We first pretrain the ICAE\nusing both autoencoding and language modeling objectives on massive text data,\nenabling it to generate memory slots that accurately and comprehensively\nrepresent the original context. Then, we fine-tune the pretrained ICAE on a\nsmall amount of instruct data to enhance its interaction with various prompts\nfor producing desirable responses. Our experimental results demonstrate that\nthe ICAE learned with our proposed pretraining and fine-tuning paradigm can\neffectively produce memory slots with $4\\times$ context compression, which can\nbe well conditioned on by the target LLM to respond to various prompts. The\npromising results demonstrate significant implications of the ICAE for its\nnovel approach to the long context problem and its potential to reduce\ncomputation and memory overheads for LLM inference in practice, suggesting\nfurther research effort in context management for an LLM. Our code and data\nwill be released shortly.",
        "translated": ""
    },
    {
        "title": "mBLIP: Efficient Bootstrapping of Multilingual Vision-LLMs",
        "url": "http://arxiv.org/abs/2307.06930v1",
        "pub_date": "2023-07-13",
        "summary": "Modular vision-language models (Vision-LLMs) align pretrained image encoders\nwith (pretrained) large language models (LLMs), representing a computationally\nmuch more efficient alternative to end-to-end training of large vision-language\nmodels from scratch, which is prohibitively expensive for most. Vision-LLMs\ninstead post-hoc condition LLMs to `understand' the output of an image encoder.\nWith the abundance of readily available high-quality English image-text data as\nwell as monolingual English LLMs, the research focus has been on English-only\nVision-LLMs. Multilingual vision-language models are still predominantly\nobtained via expensive end-to-end pretraining, resulting in comparatively\nsmaller models, trained on limited multilingual image data supplemented with\ntext-only multilingual corpora. In this work, we present mBLIP, the first\nmultilingual Vision-LLM, which we obtain in a computationally efficient manner\n-- on consumer hardware using only a few million training examples -- by\nleveraging a pretrained multilingual LLM. To this end, we \\textit{re-align} an\nimage encoder previously tuned to an English LLM to a new, multilingual LLM --\nfor this, we leverage multilingual data from a mix of vision-and-language\ntasks, which we obtain by machine-translating high-quality English data to 95\nlanguages. On the IGLUE benchmark, mBLIP yields results competitive with\nstate-of-the-art models. Moreover, in image captioning on XM3600, mBLIP\n(zero-shot) even outperforms PaLI-X (a model with 55B parameters). Compared to\nthese very large multilingual vision-language models trained from scratch, we\nobtain mBLIP by training orders of magnitude fewer parameters on magnitudes\nless data. We release our model and code at\n\\url{https://github.com/gregor-ge/mBLIP}.",
        "translated": ""
    },
    {
        "title": "DRAGON: A Dialogue-Based Robot for Assistive Navigation with Visual\n  Language Grounding",
        "url": "http://arxiv.org/abs/2307.06924v1",
        "pub_date": "2023-07-13",
        "summary": "Persons with visual impairments (PwVI) have difficulties understanding and\nnavigating spaces around them. Current wayfinding technologies either focus\nsolely on navigation or provide limited communication about the environment.\nMotivated by recent advances in visual-language grounding and semantic\nnavigation, we propose DRAGON, a guiding robot powered by a dialogue system and\nthe ability to associate the environment with natural language. By\nunderstanding the commands from the user, DRAGON is able to guide the user to\nthe desired landmarks on the map, describe the environment, and answer\nquestions from visual observations. Through effective utilization of dialogue,\nthe robot can ground the user's free-form descriptions to landmarks in the\nenvironment, and give the user semantic information through spoken language. We\nconduct a user study with blindfolded participants in an everyday indoor\nenvironment. Our results demonstrate that DRAGON is able to communicate with\nthe user smoothly, provide a good guiding experience, and connect users with\ntheir surrounding environment in an intuitive manner.",
        "translated": ""
    },
    {
        "title": "LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT",
        "url": "http://arxiv.org/abs/2307.06917v1",
        "pub_date": "2023-07-13",
        "summary": "Knowledge Graphs (KG) provide us with a structured, flexible, transparent,\ncross-system, and collaborative way of organizing our knowledge and data across\nvarious domains in society and industrial as well as scientific disciplines.\nKGs surpass any other form of representation in terms of effectiveness.\nHowever, Knowledge Graph Engineering (KGE) requires in-depth experiences of\ngraph structures, web technologies, existing models and vocabularies, rule\nsets, logic, as well as best practices. It also demands a significant amount of\nwork. Considering the advancements in large language models (LLMs) and their\ninterfaces and applications in recent years, we have conducted comprehensive\nexperiments with ChatGPT to explore its potential in supporting KGE. In this\npaper, we present a selection of these experiments and their results to\ndemonstrate how ChatGPT can assist us in the development and management of KGs.",
        "translated": ""
    },
    {
        "title": "Generating Benchmarks for Factuality Evaluation of Language Models",
        "url": "http://arxiv.org/abs/2307.06908v1",
        "pub_date": "2023-07-13",
        "summary": "Before deploying a language model (LM) within a given domain, it is important\nto measure its tendency to generate factually incorrect information in that\ndomain. Existing factual generation evaluation methods focus on facts sampled\nfrom the LM itself, and thus do not control the set of evaluated facts and\nmight under-represent rare and unlikely facts. We propose FACTOR: Factual\nAssessment via Corpus TransfORmation, a scalable approach for evaluating LM\nfactuality. FACTOR automatically transforms a factual corpus of interest into a\nbenchmark evaluating an LM's propensity to generate true facts from the corpus\nvs. similar but incorrect statements. We use our framework to create two\nbenchmarks: Wiki-FACTOR and News-FACTOR. We show that: (i) our benchmark scores\nincrease with model size and improve when the LM is augmented with retrieval;\n(ii) benchmark score correlates with perplexity, but the two metrics do not\nalways agree on model ranking; and (iii) when perplexity and benchmark score\ndisagree, the latter better reflects factuality in open-ended generation, as\nmeasured by human annotators. We make our data and code publicly available in\nhttps://github.com/AI21Labs/factor.",
        "translated": ""
    },
    {
        "title": "DecompEval: Evaluating Generated Texts as Unsupervised Decomposed\n  Question Answering",
        "url": "http://arxiv.org/abs/2307.06869v1",
        "pub_date": "2023-07-13",
        "summary": "Existing evaluation metrics for natural language generation (NLG) tasks face\nthe challenges on generalization ability and interpretability. Specifically,\nmost of the well-performed metrics are required to train on evaluation datasets\nof specific NLG tasks and evaluation dimensions, which may cause over-fitting\nto task-specific datasets. Furthermore, existing metrics only provide an\nevaluation score for each dimension without revealing the evidence to interpret\nhow this score is obtained. To deal with these challenges, we propose a simple\nyet effective metric called DecompEval. This metric formulates NLG evaluation\nas an instruction-style question answering task and utilizes instruction-tuned\npre-trained language models (PLMs) without training on evaluation datasets,\naiming to enhance the generalization ability. To make the evaluation process\nmore interpretable, we decompose our devised instruction-style question about\nthe quality of generated texts into the subquestions that measure the quality\nof each sentence. The subquestions with their answers generated by PLMs are\nthen recomposed as evidence to obtain the evaluation result. Experimental\nresults show that DecompEval achieves state-of-the-art performance in untrained\nmetrics for evaluating text summarization and dialogue generation, which also\nexhibits strong dimension-level / task-level generalization ability and\ninterpretability.",
        "translated": ""
    },
    {
        "title": "Prompts Should not be Seen as Secrets: Systematically Measuring Prompt\n  Extraction Attack Success",
        "url": "http://arxiv.org/abs/2307.06865v1",
        "pub_date": "2023-07-13",
        "summary": "The generations of large language models are commonly controlled through\nprompting techniques, where a user's query to the model is prefixed with a\nprompt that aims to guide the model's behaviour on the query. The prompts used\nby companies to guide their models are often treated as secrets, to be hidden\nfrom the user making the query. They have even been treated as commodities to\nbe bought and sold. However, there has been anecdotal evidence showing that the\nprompts can be extracted by a user even when they are kept secret. In this\npaper, we present a framework for systematically measuring the success of\nprompt extraction attacks. In experiments with multiple sources of prompts and\nmultiple underlying language models, we find that simple text-based attacks can\nin fact reveal prompts with high probability.",
        "translated": ""
    },
    {
        "title": "Personalization for BERT-based Discriminative Speech Recognition\n  Rescoring",
        "url": "http://arxiv.org/abs/2307.06832v1",
        "pub_date": "2023-07-13",
        "summary": "Recognition of personalized content remains a challenge in end-to-end speech\nrecognition. We explore three novel approaches that use personalized content in\na neural rescoring step to improve recognition: gazetteers, prompting, and a\ncross-attention based encoder-decoder model. We use internal de-identified\nen-US data from interactions with a virtual voice assistant supplemented with\npersonalized named entities to compare these approaches. On a test set with\npersonalized named entities, we show that each of these approaches improves\nword error rate by over 10%, against a neural rescoring baseline. We also show\nthat on this test set, natural language prompts can improve word error rate by\n7% without any training and with a marginal loss in generalization. Overall,\ngazetteers were found to perform the best with a 10% improvement in word error\nrate (WER), while also improving WER on a general test set by 1%.",
        "translated": ""
    },
    {
        "title": "Negated Complementary Commonsense using Large Language Models",
        "url": "http://arxiv.org/abs/2307.06794v1",
        "pub_date": "2023-07-13",
        "summary": "Larger language models, such as GPT-3, have shown to be excellent in many\ntasks. However, we demonstrate that out-of-ordinary questions can throw the\nmodel off guard. This work focuses on finding answers to negated complementary\nquestions in commonsense scenarios. We illustrate how such questions adversely\naffect the model responses. We propose a model-agnostic methodology to improve\nthe performance in negated complementary scenarios. Our method outperforms\nfew-shot generation from GPT-3 (by more than 11 points) and, more importantly,\nhighlights the significance of studying the response of large language models\nin negated complementary questions. The code, data, and experiments are\navailable under: https://github.com/navidre/negated_complementary_commonsense.",
        "translated": ""
    },
    {
        "title": "Why Guided Dialog Policy Learning performs well? Understanding the role\n  of adversarial learning and its alternative",
        "url": "http://arxiv.org/abs/2307.06721v1",
        "pub_date": "2023-07-13",
        "summary": "Dialog policies, which determine a system's action based on the current state\nat each dialog turn, are crucial to the success of the dialog. In recent years,\nreinforcement learning (RL) has emerged as a promising option for dialog policy\nlearning (DPL). In RL-based DPL, dialog policies are updated according to\nrewards. The manual construction of fine-grained rewards, such as\nstate-action-based ones, to effectively guide the dialog policy is challenging\nin multi-domain task-oriented dialog scenarios with numerous state-action pair\ncombinations. One way to estimate rewards from collected data is to train the\nreward estimator and dialog policy simultaneously using adversarial learning\n(AL). Although this method has demonstrated superior performance\nexperimentally, it is fraught with the inherent problems of AL, such as mode\ncollapse. This paper first identifies the role of AL in DPL through detailed\nanalyses of the objective functions of dialog policy and reward estimator.\nNext, based on these analyses, we propose a method that eliminates AL from\nreward estimation and DPL while retaining its advantages. We evaluate our\nmethod using MultiWOZ, a multi-domain task-oriented dialog corpus.",
        "translated": ""
    },
    {
        "title": "Streaming CTR Prediction: Rethinking Recommendation Task for Real-World\n  Streaming Data",
        "url": "http://arxiv.org/abs/2307.07509v1",
        "pub_date": "2023-07-14",
        "summary": "The Click-Through Rate (CTR) prediction task is critical in industrial\nrecommender systems, where models are usually deployed on dynamic streaming\ndata in practical applications. Such streaming data in real-world recommender\nsystems face many challenges, such as distribution shift, temporal\nnon-stationarity, and systematic biases, which bring difficulties to the\ntraining and utilizing of recommendation models. However, most existing studies\napproach the CTR prediction as a classification task on static datasets,\nassuming that the train and test sets are independent and identically\ndistributed (a.k.a, i.i.d. assumption). To bridge this gap, we formulate the\nCTR prediction problem in streaming scenarios as a Streaming CTR Prediction\ntask. Accordingly, we propose dedicated benchmark settings and metrics to\nevaluate and analyze the performance of the models in streaming data. To better\nunderstand the differences compared to traditional CTR prediction tasks, we\ndelve into the factors that may affect the model performance, such as parameter\nscale, normalization, regularization, etc. The results reveal the existence of\nthe ''streaming learning dilemma'', whereby the same factor may have different\neffects on model performance in the static and streaming scenarios. Based on\nthe findings, we propose two simple but inspiring methods (i.e., tuning key\nparameters and exemplar replay) that significantly improve the effectiveness of\nthe CTR models in the new streaming scenario. We hope our work will inspire\nfurther research on streaming CTR prediction and help improve the robustness\nand adaptability of recommender systems.",
        "translated": ""
    },
    {
        "title": "PiTL: Cross-modal Retrieval with Weakly-supervised Vision-language\n  Pre-training via Prompting",
        "url": "http://arxiv.org/abs/2307.07341v1",
        "pub_date": "2023-07-14",
        "summary": "Vision-language (VL) Pre-training (VLP) has shown to well generalize VL\nmodels over a wide range of VL downstream tasks, especially for cross-modal\nretrieval. However, it hinges on a huge amount of image-text pairs, which\nrequires tedious and costly curation. On the contrary, weakly-supervised VLP\n(W-VLP) explores means with object tags generated by a pre-trained object\ndetector (OD) from images. Yet, they still require paired information, i.e.\nimages and object-level annotations, as supervision to train an OD.\n  To further reduce the amount of supervision, we propose Prompts-in-The-Loop\n(PiTL) that prompts knowledge from large language models (LLMs) to describe\nimages. Concretely, given a category label of an image, e.g. refinery, the\nknowledge, e.g. a refinery could be seen with large storage tanks, pipework,\nand ..., extracted by LLMs is used as the language counterpart. The knowledge\nsupplements, e.g. the common relations among entities most likely appearing in\na scene. We create IN14K, a new VL dataset of 9M images and 1M descriptions of\n14K categories from ImageNet21K with PiTL. Empirically, the VL models\npre-trained with PiTL-generated pairs are strongly favored over other W-VLP\nworks on image-to-text (I2T) and text-to-image (T2I) retrieval tasks, with less\nsupervision. The results reveal the effectiveness of PiTL-generated pairs for\nVLP.",
        "translated": ""
    },
    {
        "title": "Hybrid moderation in the newsroom: Recommending featured posts to\n  content moderators",
        "url": "http://arxiv.org/abs/2307.07317v1",
        "pub_date": "2023-07-14",
        "summary": "Online news outlets are grappling with the moderation of user-generated\ncontent within their comment section. We present a recommender system based on\nranking class probabilities to support and empower the moderator in choosing\nfeatured posts, a time-consuming task. By combining user and textual content\nfeatures we obtain an optimal classification F1-score of 0.44 on the test set.\nFurthermore, we observe an optimum mean NDCG@5 of 0.87 on a large set of\nvalidation articles. As an expert evaluation, content moderators assessed the\noutput of a random selection of articles by choosing comments to feature based\non the recommendations, which resulted in a NDCG score of 0.83. We conclude\nthat first, adding text features yields the best score and second, while\nchoosing featured content remains somewhat subjective, content moderators found\nsuitable comments in all but one evaluated recommendations. We end the paper by\nanalyzing our best-performing model, a step towards transparency and\nexplainability in hybrid content moderation.",
        "translated": ""
    },
    {
        "title": "Learning to Retrieve In-Context Examples for Large Language Models",
        "url": "http://arxiv.org/abs/2307.07164v1",
        "pub_date": "2023-07-14",
        "summary": "Large language models (LLMs) have demonstrated their ability to learn\nin-context, allowing them to perform various tasks based on a few input-output\nexamples. However, the effectiveness of in-context learning is heavily reliant\non the quality of the selected examples. In this paper, we propose a novel\nframework to iteratively train dense retrievers that can identify high-quality\nin-context examples for LLMs. Our framework initially trains a reward model\nbased on LLM feedback to evaluate the quality of candidate examples, followed\nby knowledge distillation to train a bi-encoder based dense retriever. Our\nexperiments on a suite of 30 tasks demonstrate that our framework significantly\nenhances in-context learning performance. Furthermore, we show the\ngeneralization ability of our framework to unseen tasks during training. An\nin-depth analysis reveals that our model improves performance by retrieving\nexamples with similar patterns, and the gains are consistent across LLMs of\nvarying sizes.",
        "translated": ""
    },
    {
        "title": "Digital Health Discussion Through Articles Published Until the Year\n  2021: A Digital Topic Modeling Approach",
        "url": "http://arxiv.org/abs/2307.07130v1",
        "pub_date": "2023-07-14",
        "summary": "The digital health industry has grown in popularity since the 2010s, but\nthere has been limited analysis of the topics discussed in the field across\nacademic disciplines. This study aims to analyze the research trends of digital\nhealth-related articles published on the Web of Science until 2021, in order to\nunderstand the concentration, scope, and characteristics of the research.\n15,950 digital health-related papers from the top 10 academic fields were\nanalyzed using the Web of Science. The papers were grouped into three domains:\npublic health, medicine, and electrical engineering and computer science\n(EECS). Two time periods (2012-2016 and 2017-2021) were compared using Latent\nDirichlet Allocation (LDA) for topic modeling. The number of topics was\ndetermined based on coherence score, and topic compositions were compared using\na homogeneity test. The number of optimal topics varied across domains and time\nperiods. For public health, the first and second halves had 13 and 19 topics,\nrespectively. Medicine had 14 and 25 topics, and EECS had 7 and 21 topics. Text\nanalysis revealed shared topics among the domains, but with variations in\ncomposition. The homogeneity test confirmed significant differences between the\ngroups (p&lt;2.2e-16). Six dominant themes emerged, including journal article\nmethodology, information technology, medical issues, population demographics,\nsocial phenomena, and healthcare. Digital health research is expanding and\nevolving, particularly in relation to Covid-19, where topics such as depression\nand mental disorders, education, and physical activity have gained prominence.\nThere was no bias in topic composition among the three domains, but other\nfields like kinesiology or psychology could contribute to future digital health\nresearch. Exploring expanded topics that reflect people's needs for digital\nhealth over time will be crucial.",
        "translated": ""
    },
    {
        "title": "Population Expansion for Training Language Models with Private Federated\n  Learning",
        "url": "http://arxiv.org/abs/2307.07477v1",
        "pub_date": "2023-07-14",
        "summary": "Federated learning (FL) combined with differential privacy (DP) offers\nmachine learning (ML) training with distributed devices and with a formal\nprivacy guarantee. With a large population of devices, FL with DP produces a\nperformant model in a timely manner. However, for applications with a smaller\npopulation, not only does the model utility degrade as the DP noise is\ninversely proportional to population, but also the training latency increases\nsince waiting for enough clients to become available from a smaller pool is\nslower. In this work, we thus propose expanding the population based on domain\nadaptation techniques to speed up the training and improves the final model\nquality when training with small populations. We empirically demonstrate that\nour techniques can improve the utility by 13% to 30% on real-world language\nmodeling datasets.",
        "translated": ""
    },
    {
        "title": "Towards spoken dialect identification of Irish",
        "url": "http://arxiv.org/abs/2307.07436v1",
        "pub_date": "2023-07-14",
        "summary": "The Irish language is rich in its diversity of dialects and accents. This\ncompounds the difficulty of creating a speech recognition system for the\nlow-resource language, as such a system must contend with a high degree of\nvariability with limited corpora. A recent study investigating dialect bias in\nIrish ASR found that balanced training corpora gave rise to unequal dialect\nperformance, with performance for the Ulster dialect being consistently worse\nthan for the Connacht or Munster dialects. Motivated by this, the present\nexperiments investigate spoken dialect identification of Irish, with a view to\nincorporating such a system into the speech recognition pipeline. Two acoustic\nclassification models are tested, XLS-R and ECAPA-TDNN, in conjunction with a\ntext-based classifier using a pretrained Irish-language BERT model. The\nECAPA-TDNN, particularly a model pretrained for language identification on the\nVoxLingua107 dataset, performed best overall, with an accuracy of 73%. This was\nfurther improved to 76% by fusing the model's outputs with the text-based\nmodel. The Ulster dialect was most accurately identified, with an accuracy of\n94%, however the model struggled to disambiguate between the Connacht and\nMunster dialects, suggesting a more nuanced approach may be necessary to\nrobustly distinguish between the dialects of Irish.",
        "translated": ""
    },
    {
        "title": "HuCurl: Human-induced Curriculum Discovery",
        "url": "http://arxiv.org/abs/2307.07412v1",
        "pub_date": "2023-07-14",
        "summary": "We introduce the problem of curriculum discovery and describe a curriculum\nlearning framework capable of discovering effective curricula in a curriculum\nspace based on prior knowledge about sample difficulty. Using annotation\nentropy and loss as measures of difficulty, we show that (i): the\ntop-performing discovered curricula for a given model and dataset are often\nnon-monotonic as opposed to monotonic curricula in existing literature, (ii):\nthe prevailing easy-to-hard or hard-to-easy transition curricula are often at\nthe risk of underperforming, and (iii): the curricula discovered for smaller\ndatasets and models perform well on larger datasets and models respectively.\nThe proposed framework encompasses some of the existing curriculum learning\napproaches and can discover curricula that outperform them across several NLP\ntasks.",
        "translated": ""
    },
    {
        "title": "Rank Your Summaries: Enhancing Bengali Text Summarization via\n  Ranking-based Approach",
        "url": "http://arxiv.org/abs/2307.07392v1",
        "pub_date": "2023-07-14",
        "summary": "With the increasing need for text summarization techniques that are both\nefficient and accurate, it becomes crucial to explore avenues that enhance the\nquality and precision of pre-trained models specifically tailored for\nsummarizing Bengali texts. When it comes to text summarization tasks, there are\nnumerous pre-trained transformer models at one's disposal. Consequently, it\nbecomes quite a challenge to discern the most informative and relevant summary\nfor a given text among the various options generated by these pre-trained\nsummarization models. This paper aims to identify the most accurate and\ninformative summary for a given text by utilizing a simple but effective\nranking-based approach that compares the output of four different pre-trained\nBengali text summarization models. The process begins by carrying out\npreprocessing of the input text that involves eliminating unnecessary elements\nsuch as special characters and punctuation marks. Next, we utilize four\npre-trained summarization models to generate summaries, followed by applying a\ntext ranking algorithm to identify the most suitable summary. Ultimately, the\nsummary with the highest ranking score is chosen as the final one. To evaluate\nthe effectiveness of this approach, the generated summaries are compared\nagainst human-annotated summaries using standard NLG metrics such as BLEU,\nROUGE, BERTScore, WIL, WER, and METEOR. Experimental results suggest that by\nleveraging the strengths of each pre-trained transformer model and combining\nthem using a ranking-based approach, our methodology significantly improves the\naccuracy and effectiveness of the Bengali text summarization.",
        "translated": ""
    },
    {
        "title": "Composition-contrastive Learning for Sentence Embeddings",
        "url": "http://arxiv.org/abs/2307.07380v1",
        "pub_date": "2023-07-14",
        "summary": "Vector representations of natural language are ubiquitous in search\napplications. Recently, various methods based on contrastive learning have been\nproposed to learn textual representations from unlabelled data; by maximizing\nalignment between minimally-perturbed embeddings of the same text, and\nencouraging a uniform distribution of embeddings across a broader corpus.\nDifferently, we propose maximizing alignment between texts and a composition of\ntheir phrasal constituents. We consider several realizations of this objective\nand elaborate the impact on representations in each case. Experimental results\non semantic textual similarity tasks show improvements over baselines that are\ncomparable with state-of-the-art approaches. Moreover, this work is the first\nto do so without incurring costs in auxiliary training objectives or additional\nnetwork parameters.",
        "translated": ""
    },
    {
        "title": "A scoping review on multimodal deep learning in biomedical images and\n  texts",
        "url": "http://arxiv.org/abs/2307.07362v1",
        "pub_date": "2023-07-14",
        "summary": "Computer-assisted diagnostic and prognostic systems of the future should be\ncapable of simultaneously processing multimodal data. Multimodal deep learning\n(MDL), which involves the integration of multiple sources of data, such as\nimages and text, has the potential to revolutionize the analysis and\ninterpretation of biomedical data. However, it only caught researchers'\nattention recently. To this end, there is a critical need to conduct a\nsystematic review on this topic, identify the limitations of current work, and\nexplore future directions. In this scoping review, we aim to provide a\ncomprehensive overview of the current state of the field and identify key\nconcepts, types of studies, and research gaps with a focus on biomedical images\nand texts joint learning, mainly because these two were the most commonly\navailable data types in MDL research. This study reviewed the current uses of\nmultimodal deep learning on five tasks: (1) Report generation, (2) Visual\nquestion answering, (3) Cross-modal retrieval, (4) Computer-aided diagnosis,\nand (5) Semantic segmentation. Our results highlight the diverse applications\nand potential of MDL and suggest directions for future research in the field.\nWe hope our review will facilitate the collaboration of natural language\nprocessing (NLP) and medical imaging communities and support the next\ngeneration of decision-making and computer-assisted diagnostic system\ndevelopment.",
        "translated": ""
    },
    {
        "title": "Gloss Attention for Gloss-free Sign Language Translation",
        "url": "http://arxiv.org/abs/2307.07361v1",
        "pub_date": "2023-07-14",
        "summary": "Most sign language translation (SLT) methods to date require the use of gloss\nannotations to provide additional supervision information, however, the\nacquisition of gloss is not easy. To solve this problem, we first perform an\nanalysis of existing models to confirm how gloss annotations make SLT easier.\nWe find that it can provide two aspects of information for the model, 1) it can\nhelp the model implicitly learn the location of semantic boundaries in\ncontinuous sign language videos, 2) it can help the model understand the sign\nlanguage video globally. We then propose \\emph{gloss attention}, which enables\nthe model to keep its attention within video segments that have the same\nsemantics locally, just as gloss helps existing models do. Furthermore, we\ntransfer the knowledge of sentence-to-sentence similarity from the natural\nlanguage model to our gloss attention SLT network (GASLT) to help it understand\nsign language videos at the sentence level. Experimental results on multiple\nlarge-scale sign language datasets show that our proposed GASLT model\nsignificantly outperforms existing methods. Our code is provided in\n\\url{https://github.com/YinAoXiong/GASLT}.",
        "translated": ""
    },
    {
        "title": "How Different Is Stereotypical Bias Across Languages?",
        "url": "http://arxiv.org/abs/2307.07331v1",
        "pub_date": "2023-07-14",
        "summary": "Recent studies have demonstrated how to assess the stereotypical bias in\npre-trained English language models. In this work, we extend this branch of\nresearch in multiple different dimensions by systematically investigating (a)\nmono- and multilingual models of (b) different underlying architectures with\nrespect to their bias in (c) multiple different languages. To that end, we make\nuse of the English StereoSet data set (Nadeem et al., 2021), which we\nsemi-automatically translate into German, French, Spanish, and Turkish. We find\nthat it is of major importance to conduct this type of analysis in a\nmultilingual setting, as our experiments show a much more nuanced picture as\nwell as notable differences from the English-only analysis. The main takeaways\nfrom our analysis are that mGPT-2 (partly) shows surprising anti-stereotypical\nbehavior across languages, English (monolingual) models exhibit the strongest\nbias, and the stereotypes reflected in the data set are least present in\nTurkish models. Finally, we release our codebase alongside the translated data\nsets and practical guidelines for the semi-automatic translation to encourage a\nfurther extension of our work to other languages.",
        "translated": ""
    },
    {
        "title": "Using Large Language Models for Zero-Shot Natural Language Generation\n  from Knowledge Graphs",
        "url": "http://arxiv.org/abs/2307.07312v1",
        "pub_date": "2023-07-14",
        "summary": "In any system that uses structured knowledge graph (KG) data as its\nunderlying knowledge representation, KG-to-text generation is a useful tool for\nturning parts of the graph data into text that can be understood by humans.\nRecent work has shown that models that make use of pretraining on large amounts\nof text data can perform well on the KG-to-text task even with relatively small\nsets of training data on the specific graph-to-text task. In this paper, we\nbuild on this concept by using large language models to perform zero-shot\ngeneration based on nothing but the model's understanding of the triple\nstructure from what it can read. We show that ChatGPT achieves near\nstate-of-the-art performance on some measures of the WebNLG 2020 challenge, but\nfalls behind on others. Additionally, we compare factual, counter-factual and\nfictional statements, and show that there is a significant connection between\nwhat the LLM already knows about the data it is parsing and the quality of the\noutput text.",
        "translated": ""
    },
    {
        "title": "Leveraging Recommender Systems to Reduce Content Gaps on Peer Production\n  Platforms",
        "url": "http://arxiv.org/abs/2307.08669v1",
        "pub_date": "2023-07-17",
        "summary": "Peer production platforms like Wikipedia commonly suffer from content gaps.\nPrior research suggests recommender systems can help solve this problem, by\nguiding editors towards underrepresented topics. However, it remains unclear\nwhether this approach would result in less relevant recommendations, leading to\nreduced overall engagement with recommended items. To answer this question, we\nfirst conducted offline analyses (Study 1) on SuggestBot, a task-routing\nrecommender system for Wikipedia, then did a three-month controlled experiment\n(Study 2). Our results show that presenting users with articles from\nunderrepresented topics increased the proportion of work done on those articles\nwithout significantly reducing overall recommendation uptake. We discuss the\nimplications of our results, including how ignoring the article discovery\nprocess can artificially narrow recommendations. We draw parallels between this\nphenomenon and the common issue of ``filter bubbles'' to show how any platform\nthat employs recommender systems is susceptible to it.",
        "translated": ""
    },
    {
        "title": "Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language\n  Models",
        "url": "http://arxiv.org/abs/2307.08303v1",
        "pub_date": "2023-07-17",
        "summary": "Dense retrieval (DR) converts queries and documents into dense embeddings and\nmeasures the similarity between queries and documents in vector space. One of\nthe challenges in DR is the lack of domain-specific training data. While DR\nmodels can learn from large-scale public datasets like MS MARCO through\ntransfer learning, evidence shows that not all DR models and domains can\nbenefit from transfer learning equally. Recently, some researchers have\nresorted to large language models (LLMs) to improve the zero-shot and few-shot\nDR models. However, the hard prompts or human-written prompts utilized in these\nworks cannot guarantee the good quality of generated weak queries. To tackle\nthis, we propose soft prompt tuning for augmenting DR (SPTAR): For each task,\nwe leverage soft prompt-tuning to optimize a task-specific soft prompt on\nlimited ground truth data and then prompt the LLMs to tag unlabeled documents\nwith weak queries, yielding enough weak document-query pairs to train\ntask-specific dense retrievers. We design a filter to select high-quality\nexample document-query pairs in the prompt to further improve the quality of\nweak tagged queries. To the best of our knowledge, there is no prior work\nutilizing soft prompt tuning to augment DR models. The experiments demonstrate\nthat SPTAR outperforms the unsupervised baselines BM25 and the recently\nproposed LLMs-based augmentation method for DR.",
        "translated": ""
    },
    {
        "title": "Measuring Item Global Residual Value for Fair Recommendation",
        "url": "http://arxiv.org/abs/2307.08259v1",
        "pub_date": "2023-07-17",
        "summary": "In the era of information explosion, numerous items emerge every day,\nespecially in feed scenarios. Due to the limited system display slots and user\nbrowsing attention, various recommendation systems are designed not only to\nsatisfy users' personalized information needs but also to allocate items'\nexposure. However, recent recommendation studies mainly focus on modeling user\npreferences to present satisfying results and maximize user interactions, while\npaying little attention to developing item-side fair exposure mechanisms for\nrational information delivery. This may lead to serious resource allocation\nproblems on the item side, such as the Snowball Effect. Furthermore, unfair\nexposure mechanisms may hurt recommendation performance. In this paper, we call\nfor a shift of attention from modeling user preferences to developing fair\nexposure mechanisms for items. We first conduct empirical analyses of feed\nscenarios to explore exposure problems between items with distinct uploaded\ntimes. This points out that unfair exposure caused by the time factor may be\nthe major cause of the Snowball Effect. Then, we propose to explicitly model\nitem-level customized timeliness distribution, Global Residual Value (GRV), for\nfair resource allocation. This GRV module is introduced into recommendations\nwith the designed Timeliness-aware Fair Recommendation Framework (TaFR).\nExtensive experiments on two datasets demonstrate that TaFR achieves consistent\nimprovements with various backbone recommendation models. By modeling item-side\ncustomized Global Residual Value, we achieve a fairer distribution of resources\nand, at the same time, improve recommendation performance.",
        "translated": ""
    },
    {
        "title": "Data Discovery for the SDGs: A Systematic Rule-based Approach",
        "url": "http://arxiv.org/abs/2307.07983v1",
        "pub_date": "2023-07-16",
        "summary": "In 2015, the United Nations put forward 17 Sustainable Development Goals\n(SDGs) to be achieved by 2030, where data has been promoted as a focus to\ninnovating sustainable development and as a means to measuring progress towards\nachieving the SDGs. In this study, we propose a systematic approach towards\ndiscovering data types and sources that can be used for SDG research. The\nproposed method integrates a systematic mapping approach using manual\nqualitative coding over a corpus of SDG-related research literature followed by\nan automated process that applies rules to perform data entity extraction\ncomputationally. This approach is exemplified by an analysis of literature\nrelating to SDG 7, the results of which are also presented in this paper. The\npaper concludes with a discussion of the approach and suggests future work to\nextend the method with more advance NLP and machine learning techniques.",
        "translated": ""
    },
    {
        "title": "Opinion mining using Double Channel CNN for Recommender System",
        "url": "http://arxiv.org/abs/2307.07798v1",
        "pub_date": "2023-07-15",
        "summary": "Much unstructured data has been produced with the growth of the Internet and\nsocial media. A significant volume of textual data includes users' opinions\nabout products in online stores and social media. By exploring and categorizing\nthem, helpful information can be acquired, including customer satisfaction,\nuser feedback about a particular event, predicting the sale of a specific\nproduct, and other similar cases. In this paper, we present an approach for\nsentiment analysis with a deep learning model and use it to recommend products.\nA two-channel convolutional neural network model has been used for opinion\nmining, which has five layers and extracts essential features from the data. We\nincreased the number of comments by applying the SMOTE algorithm to the initial\ndataset and balanced the data. Then we proceed to cluster the aspects. We also\nassign a weight to each cluster using tensor decomposition algorithms that\nimprove the recommender system's performance. Our proposed method has reached\n91.6% accuracy, significantly improved compared to previous aspect-based\napproaches.",
        "translated": ""
    },
    {
        "title": "AlpaGasus: Training A Better Alpaca with Fewer Data",
        "url": "http://arxiv.org/abs/2307.08701v1",
        "pub_date": "2023-07-17",
        "summary": "Large language models~(LLMs) obtain instruction-following capability through\ninstruction-finetuning (IFT) on supervised instruction/response data. However,\nwidely used IFT datasets (e.g., Alpaca's 52k data) surprisingly contain many\nlow-quality instances with incorrect or irrelevant responses, which are\nmisleading and detrimental to IFT. In this paper, we propose a simple and\neffective data selection strategy that automatically identifies and removes\nlow-quality data using a strong LLM (e.g., ChatGPT). To this end, we introduce\nAlpaGasus, which is finetuned on only 9k high-quality data filtered from the\n52k Alpaca data. AlpaGasus significantly outperforms the original Alpaca as\nevaluated by GPT-4 on multiple test sets and its 13B variant matches $&gt;90\\%$\nperformance of its teacher LLM (i.e., Text-Davinci-003) on test tasks. It also\nprovides 5.7x faster training, reducing the training time for a 7B variant from\n80 minutes (for Alpaca) to 14 minutes \\footnote{We apply IFT for the same\nnumber of epochs as Alpaca(7B) but on fewer data, using 4$\\times$NVIDIA A100\n(80GB) GPUs and following the original Alpaca setting and hyperparameters.}.\nOverall, AlpaGasus demonstrates a novel data-centric IFT paradigm that can be\ngenerally applied to instruction-tuning data, leading to faster training and\nbetter instruction-following models. Our project page is available at:\n\\url{https://lichang-chen.github.io/AlpaGasus/}.",
        "translated": ""
    },
    {
        "title": "COLLIE: Systematic Construction of Constrained Text Generation Tasks",
        "url": "http://arxiv.org/abs/2307.08689v1",
        "pub_date": "2023-07-17",
        "summary": "Text generation under constraints have seen increasing interests in natural\nlanguage processing, especially with the rapidly improving capabilities of\nlarge language models. However, existing benchmarks for constrained generation\nusually focus on fixed constraint types (e.g.,generate a sentence containing\ncertain words) that have proved to be easy for state-of-the-art models like\nGPT-4. We present COLLIE, a grammar-based framework that allows the\nspecification of rich, compositional constraints with diverse generation levels\n(word, sentence, paragraph, passage) and modeling challenges (e.g.,language\nunderstanding, logical reasoning, counting, semantic planning). We also develop\ntools for automatic extraction of task instances given a constraint structure\nand a raw text corpus. Using COLLIE, we compile the COLLIE-v1 dataset with 2080\ninstances comprising 13 constraint structures. We perform systematic\nexperiments across five state-of-the-art instruction-tuned language models and\nanalyze their performances to reveal shortcomings. COLLIE is designed to be\nextensible and lightweight, and we hope the community finds it useful to\ndevelop more complex constraints and evaluations in the future.",
        "translated": ""
    },
    {
        "title": "Do Models Explain Themselves? Counterfactual Simulatability of Natural\n  Language Explanations",
        "url": "http://arxiv.org/abs/2307.08678v1",
        "pub_date": "2023-07-17",
        "summary": "Large language models (LLMs) are trained to imitate humans to explain human\ndecisions. However, do LLMs explain themselves? Can they help humans build\nmental models of how LLMs process different inputs? To answer these questions,\nwe propose to evaluate $\\textbf{counterfactual simulatability}$ of natural\nlanguage explanations: whether an explanation can enable humans to precisely\ninfer the model's outputs on diverse counterfactuals of the explained input.\nFor example, if a model answers \"yes\" to the input question \"Can eagles fly?\"\nwith the explanation \"all birds can fly\", then humans would infer from the\nexplanation that it would also answer \"yes\" to the counterfactual input \"Can\npenguins fly?\". If the explanation is precise, then the model's answer should\nmatch humans' expectations.\n  We implemented two metrics based on counterfactual simulatability: precision\nand generality. We generated diverse counterfactuals automatically using LLMs.\nWe then used these metrics to evaluate state-of-the-art LLMs (e.g., GPT-4) on\ntwo tasks: multi-hop factual reasoning and reward modeling. We found that LLM's\nexplanations have low precision and that precision does not correlate with\nplausibility. Therefore, naively optimizing human approvals (e.g., RLHF) may\nnot be a sufficient solution.",
        "translated": ""
    },
    {
        "title": "Multilingual Speech-to-Speech Translation into Multiple Target Languages",
        "url": "http://arxiv.org/abs/2307.08655v1",
        "pub_date": "2023-07-17",
        "summary": "Speech-to-speech translation (S2ST) enables spoken communication between\npeople talking in different languages. Despite a few studies on multilingual\nS2ST, their focus is the multilinguality on the source side, i.e., the\ntranslation from multiple source languages to one target language. We present\nthe first work on multilingual S2ST supporting multiple target languages.\nLeveraging recent advance in direct S2ST with speech-to-unit and vocoder, we\nequip these key components with multilingual capability. Speech-to-masked-unit\n(S2MU) is the multilingual extension of S2U, which applies masking to units\nwhich don't belong to the given target language to reduce the language\ninterference. We also propose multilingual vocoder which is trained with\nlanguage embedding and the auxiliary loss of language identification. On\nbenchmark translation testsets, our proposed multilingual model shows superior\nperformance than bilingual models in the translation from English into $16$\ntarget languages.",
        "translated": ""
    },
    {
        "title": "Retentive Network: A Successor to Transformer for Large Language Models",
        "url": "http://arxiv.org/abs/2307.08621v1",
        "pub_date": "2023-07-17",
        "summary": "In this work, we propose Retentive Network (RetNet) as a foundation\narchitecture for large language models, simultaneously achieving training\nparallelism, low-cost inference, and good performance. We theoretically derive\nthe connection between recurrence and attention. Then we propose the retention\nmechanism for sequence modeling, which supports three computation paradigms,\ni.e., parallel, recurrent, and chunkwise recurrent. Specifically, the parallel\nrepresentation allows for training parallelism. The recurrent representation\nenables low-cost $O(1)$ inference, which improves decoding throughput, latency,\nand GPU memory without sacrificing performance. The chunkwise recurrent\nrepresentation facilitates efficient long-sequence modeling with linear\ncomplexity, where each chunk is encoded parallelly while recurrently\nsummarizing the chunks. Experimental results on language modeling show that\nRetNet achieves favorable scaling results, parallel training, low-cost\ndeployment, and efficient inference. The intriguing properties make RetNet a\nstrong successor to Transformer for large language models. Code will be\navailable at https://aka.ms/retnet.",
        "translated": ""
    },
    {
        "title": "Multimodal Diffusion Segmentation Model for Object Segmentation from\n  Manipulation Instructions",
        "url": "http://arxiv.org/abs/2307.08597v1",
        "pub_date": "2023-07-17",
        "summary": "In this study, we aim to develop a model that comprehends a natural language\ninstruction (e.g., \"Go to the living room and get the nearest pillow to the\nradio art on the wall\") and generates a segmentation mask for the target\neveryday object. The task is challenging because it requires (1) the\nunderstanding of the referring expressions for multiple objects in the\ninstruction, (2) the prediction of the target phrase of the sentence among the\nmultiple phrases, and (3) the generation of pixel-wise segmentation masks\nrather than bounding boxes. Studies have been conducted on languagebased\nsegmentation methods; however, they sometimes mask irrelevant regions for\ncomplex sentences. In this paper, we propose the Multimodal Diffusion\nSegmentation Model (MDSM), which generates a mask in the first stage and\nrefines it in the second stage. We introduce a crossmodal parallel feature\nextraction mechanism and extend diffusion probabilistic models to handle\ncrossmodal features. To validate our model, we built a new dataset based on the\nwell-known Matterport3D and REVERIE datasets. This dataset consists of\ninstructions with complex referring expressions accompanied by real indoor\nenvironmental images that feature various target objects, in addition to\npixel-wise segmentation masks. The performance of MDSM surpassed that of the\nbaseline method by a large margin of +10.13 mean IoU.",
        "translated": ""
    },
    {
        "title": "Syntax-Aware Complex-Valued Neural Machine Translation",
        "url": "http://arxiv.org/abs/2307.08586v1",
        "pub_date": "2023-07-17",
        "summary": "Syntax has been proven to be remarkably effective in neural machine\ntranslation (NMT). Previous models obtained syntax information from syntactic\nparsing tools and integrated it into NMT models to improve translation\nperformance. In this work, we propose a method to incorporate syntax\ninformation into a complex-valued Encoder-Decoder architecture. The proposed\nmodel jointly learns word-level and syntax-level attention scores from the\nsource side to the target side using an attention mechanism. Importantly, it is\nnot dependent on specific network architectures and can be directly integrated\ninto any existing sequence-to-sequence (Seq2Seq) framework. The experimental\nresults demonstrate that the proposed method can bring significant improvements\nin BLEU scores on two datasets. In particular, the proposed method achieves a\ngreater improvement in BLEU scores in translation tasks involving language\npairs with significant syntactic differences.",
        "translated": ""
    },
    {
        "title": "The Resume Paradox: Greater Language Differences, Smaller Pay Gaps",
        "url": "http://arxiv.org/abs/2307.08580v1",
        "pub_date": "2023-07-17",
        "summary": "Over the past decade, the gender pay gap has remained steady with women\nearning 84 cents for every dollar earned by men on average. Many studies\nexplain this gap through demand-side bias in the labor market represented\nthrough employers' job postings. However, few studies analyze potential bias\nfrom the worker supply-side. Here, we analyze the language in millions of US\nworkers' resumes to investigate how differences in workers' self-representation\nby gender compare to differences in earnings. Across US occupations, language\ndifferences between male and female resumes correspond to 11% of the variation\nin gender pay gap. This suggests that females' resumes that are semantically\nsimilar to males' resumes may have greater wage parity. However, surprisingly,\noccupations with greater language differences between male and female resumes\nhave lower gender pay gaps. A doubling of the language difference between\nfemale and male resumes results in an annual wage increase of $2,797 for the\naverage female worker. This result holds with controls for gender-biases of\nresume text and we find that per-word bias poorly describes the variance in\nwage gap. The results demonstrate that textual data and self-representation are\nvaluable factors for improving worker representations and understanding\nemployment inequities.",
        "translated": ""
    },
    {
        "title": "Discovering collective narratives shifts in online discussions",
        "url": "http://arxiv.org/abs/2307.08541v1",
        "pub_date": "2023-07-17",
        "summary": "Narrative is a foundation of human cognition and decision making. Because\nnarratives play a crucial role in societal discourses and spread of\nmisinformation and because of the pervasive use of social media, the narrative\ndynamics on social media can have profound societal impact. Yet, systematic and\ncomputational understanding of online narratives faces critical challenge of\nthe scale and dynamics; how can we reliably and automatically extract\nnarratives from massive amount of texts? How do narratives emerge, spread, and\ndie? Here, we propose a systematic narrative discovery framework that fill this\ngap by combining change point detection, semantic role labeling (SRL), and\nautomatic aggregation of narrative fragments into narrative networks. We\nevaluate our model with synthetic and empirical data two-Twitter corpora about\nCOVID-19 and 2017 French Election. Results demonstrate that our approach can\nrecover major narrative shifts that correspond to the major events.",
        "translated": ""
    },
    {
        "title": "Latent Jailbreak: A Benchmark for Evaluating Text Safety and Output\n  Robustness of Large Language Models",
        "url": "http://arxiv.org/abs/2307.08487v1",
        "pub_date": "2023-07-17",
        "summary": "Researchers have invested considerable effort into ensuring that large\nlanguage models (LLMs) align with human values, using various training\ntechniques, such as instruction tuning and Reinforcement Learning from Human or\nAI Feedback (RLHF/RLAIF), to guard against text unsafety. However, these\ndefenses remain incredibly vulnerable to some jailbreak attacks, which can\ncause the model to become overly defensive to sensitive topics or still\ngenerate harmful content, leaving the model performance particularly fragile.\nTherefore, to comprehensively study text safety and output robustness, we\npropose a latent jailbreak prompt dataset, each involving malicious instruction\nembedding. Specifically, we instruct the model to complete a regular task, such\nas translation, where the text to be translated contains malicious\ninstructions. To further analyze the safety and robustness, we design a\nhierarchical annotation framework. We present a systematic analysis of the\nsafety and robustness of LLMs concerning the position of explicit normal\ninstructions, word replacement (verbs in explicit normal instructions, target\ngroups in malicious instructions, cue words in malicious instructions), and\ninstruction replacement (different explicit normal instructions). Our results\nshow that current LLMs not only have a preference for certain instruction\nverbs, but also exhibit different jailbreak rates for different instruction\nverbs in explicit normal instructions. In other words, the probability of\ngenerating unsafe content by the model will be reinforced to varying degrees\ndepending on the instruction verb in explicit normal instructions. Code and\ndata are available at https://github.com/qiuhuachuan/latent-jailbreak.",
        "translated": ""
    },
    {
        "title": "Deep Neural Aggregation for Recommending Items to Group of Users",
        "url": "http://arxiv.org/abs/2307.09447v1",
        "pub_date": "2023-07-18",
        "summary": "Modern society devotes a significant amount of time to digital interaction.\nMany of our daily actions are carried out through digital means. This has led\nto the emergence of numerous Artificial Intelligence tools that assist us in\nvarious aspects of our lives. One key tool for the digital society is\nRecommender Systems, intelligent systems that learn from our past actions to\npropose new ones that align with our interests. Some of these systems have\nspecialized in learning from the behavior of user groups to make\nrecommendations to a group of individuals who want to perform a joint task. In\nthis article, we analyze the current state of Group Recommender Systems and\npropose two new models that use emerging Deep Learning architectures.\nExperimental results demonstrate the improvement achieved by employing the\nproposed models compared to the state-of-the-art models using four different\ndatasets. The source code of the models, as well as that of all the experiments\nconducted, is available in a public repository.",
        "translated": ""
    },
    {
        "title": "Zero-shot Query Reformulation for Conversational Search",
        "url": "http://arxiv.org/abs/2307.09384v1",
        "pub_date": "2023-07-18",
        "summary": "As the popularity of voice assistants continues to surge, conversational\nsearch has gained increased attention in Information Retrieval. However, data\nsparsity issues in conversational search significantly hinder the progress of\nsupervised conversational search methods. Consequently, researchers are\nfocusing more on zero-shot conversational search approaches. Nevertheless,\nexisting zero-shot methods face three primary limitations: they are not\nuniversally applicable to all retrievers, their effectiveness lacks sufficient\nexplainability, and they struggle to resolve common conversational ambiguities\ncaused by omission. To address these limitations, we introduce a novel\nZero-shot Query Reformulation (ZeQR) framework that reformulates queries based\non previous dialogue contexts without requiring supervision from conversational\nsearch data. Specifically, our framework utilizes language models designed for\nmachine reading comprehension tasks to explicitly resolve two common\nambiguities: coreference and omission, in raw queries. In comparison to\nexisting zero-shot methods, our approach is universally applicable to any\nretriever without additional adaptation or indexing. It also provides greater\nexplainability and effectively enhances query intent understanding because\nambiguities are explicitly and proactively resolved. Through extensive\nexperiments on four TREC conversational datasets, we demonstrate the\neffectiveness of our method, which consistently outperforms state-of-the-art\nbaselines.",
        "translated": ""
    },
    {
        "title": "ESMC: Entire Space Multi-Task Model for Post-Click Conversion Rate via\n  Parameter Constraint",
        "url": "http://arxiv.org/abs/2307.09193v1",
        "pub_date": "2023-07-18",
        "summary": "Large-scale online recommender system spreads all over the Internet being in\ncharge of two basic tasks: Click-Through Rate (CTR) and Post-Click Conversion\nRate (CVR) estimations. However, traditional CVR estimators suffer from\nwell-known Sample Selection Bias and Data Sparsity issues. Entire space models\nwere proposed to address the two issues via tracing the decision-making path of\n\"exposure_click_purchase\". Further, some researchers observed that there are\npurchase-related behaviors between click and purchase, which can better draw\nthe user's decision-making intention and improve the recommendation\nperformance. Thus, the decision-making path has been extended to\n\"exposure_click_in-shop action_purchase\" and can be modeled with conditional\nprobability approach. Nevertheless, we observe that the chain rule of\nconditional probability does not always hold. We report Probability Space\nConfusion (PSC) issue and give a derivation of difference between ground-truth\nand estimation mathematically. We propose a novel Entire Space Multi-Task Model\nfor Post-Click Conversion Rate via Parameter Constraint (ESMC) and two\nalternatives: Entire Space Multi-Task Model with Siamese Network (ESMS) and\nEntire Space Multi-Task Model in Global Domain (ESMG) to address the PSC issue.\nSpecifically, we handle \"exposure_click_in-shop action\" and \"in-shop\naction_purchase\" separately in the light of characteristics of in-shop action.\nThe first path is still treated with conditional probability while the second\none is treated with parameter constraint strategy. Experiments on both offline\nand online environments in a large-scale recommendation system illustrate the\nsuperiority of our proposed methods over state-of-the-art models. The\nreal-world datasets will be released.",
        "translated": ""
    },
    {
        "title": "Jean-Luc Picard at Touché 2023: Comparing Image Generation, Stance\n  Detection and Feature Matching for Image Retrieval for Arguments",
        "url": "http://arxiv.org/abs/2307.09172v1",
        "pub_date": "2023-07-18",
        "summary": "Participating in the shared task \"Image Retrieval for arguments\", we used\ndifferent pipelines for image retrieval containing Image Generation, Stance\nDetection, Preselection and Feature Matching. We submitted four different runs\nwith different pipeline layout and compare them to given baseline. Our\npipelines perform similarly to the baseline.",
        "translated": ""
    },
    {
        "title": "Modeling Orders of User Behaviors via Differentiable Sorting: A\n  Multi-task Framework to Predicting User Post-click Conversion",
        "url": "http://arxiv.org/abs/2307.09089v1",
        "pub_date": "2023-07-18",
        "summary": "User post-click conversion prediction is of high interest to researchers and\ndevelopers. Recent studies employ multi-task learning to tackle the selection\nbias and data sparsity problem, two severe challenges in post-click behavior\nprediction, by incorporating click data. However, prior works mainly focused on\npointwise learning and the orders of labels (i.e., click and post-click) are\nnot well explored, which naturally poses a listwise learning problem. Inspired\nby recent advances on differentiable sorting, in this paper, we propose a novel\nmulti-task framework that leverages orders of user behaviors to predict user\npost-click conversion in an end-to-end approach. Specifically, we define an\naggregation operator to combine predicted outputs of different tasks to a\nunified score, then we use the computed scores to model the label relations via\ndifferentiable sorting. Extensive experiments on public and industrial datasets\nshow the superiority of our proposed model against competitive baselines.",
        "translated": ""
    },
    {
        "title": "Overthinking the Truth: Understanding how Language Models Process False\n  Demonstrations",
        "url": "http://arxiv.org/abs/2307.09476v1",
        "pub_date": "2023-07-18",
        "summary": "Modern language models can imitate complex patterns through few-shot\nlearning, enabling them to complete challenging tasks without fine-tuning.\nHowever, imitation can also lead models to reproduce inaccuracies or harmful\ncontent if present in the context. We study harmful imitation through the lens\nof a model's internal representations, and identify two related phenomena:\noverthinking and false induction heads. The first phenomenon, overthinking,\nappears when we decode predictions from intermediate layers, given correct vs.\nincorrect few-shot demonstrations. At early layers, both demonstrations induce\nsimilar model behavior, but the behavior diverges sharply at some \"critical\nlayer\", after which the accuracy given incorrect demonstrations progressively\ndecreases. The second phenomenon, false induction heads, are a possible\nmechanistic cause of overthinking: these are heads in late layers that attend\nto and copy false information from previous demonstrations, and whose ablation\nreduces overthinking. Beyond scientific understanding, our results suggest that\nstudying intermediate model computations could be a promising avenue for\nunderstanding and guarding against harmful model behaviors.",
        "translated": ""
    },
    {
        "title": "ChatSpot: Bootstrapping Multimodal LLMs via Precise Referring\n  Instruction Tuning",
        "url": "http://arxiv.org/abs/2307.09474v1",
        "pub_date": "2023-07-18",
        "summary": "Human-AI interactivity is a critical aspect that reflects the usability of\nmultimodal large language models (MLLMs). However, existing end-to-end MLLMs\nonly allow users to interact with them through language instructions, leading\nto the limitation of the interactive accuracy and efficiency. In this study, we\npresent precise referring instructions that utilize diverse reference\nrepresentations such as points and boxes as referring prompts to refer to the\nspecial region. This enables MLLMs to focus on the region of interest and\nachieve finer-grained interaction. Based on precise referring instruction, we\npropose ChatSpot, a unified end-to-end multimodal large language model that\nsupports diverse forms of interactivity including mouse clicks, drag-and-drop,\nand drawing boxes, which provides a more flexible and seamless interactive\nexperience. We also construct a multi-grained vision-language\ninstruction-following dataset based on existing datasets and GPT-4 generating.\nFurthermore, we design a series of evaluation tasks to assess the effectiveness\nof region recognition and interaction. Experimental results showcase ChatSpot's\npromising performance.",
        "translated": ""
    },
    {
        "title": "A comparative analysis of SRGAN models",
        "url": "http://arxiv.org/abs/2307.09456v2",
        "pub_date": "2023-07-18",
        "summary": "In this study, we evaluate the performance of multiple state-of-the-art SRGAN\n(Super Resolution Generative Adversarial Network) models, ESRGAN, Real-ESRGAN\nand EDSR, on a benchmark dataset of real-world images which undergo degradation\nusing a pipeline. Our results show that some models seem to significantly\nincrease the resolution of the input images while preserving their visual\nquality, this is assessed using Tesseract OCR engine. We observe that EDSR-BASE\nmodel from huggingface outperforms the remaining candidate models in terms of\nboth quantitative metrics and subjective visual quality assessments with least\ncompute overhead. Specifically, EDSR generates images with higher peak\nsignal-to-noise ratio (PSNR) and structural similarity index (SSIM) values and\nare seen to return high quality OCR results with Tesseract OCR engine. These\nfindings suggest that EDSR is a robust and effective approach for single-image\nsuper-resolution and may be particularly well-suited for applications where\nhigh-quality visual fidelity is critical and optimized compute.",
        "translated": ""
    },
    {
        "title": "Pseudo Outlier Exposure for Out-of-Distribution Detection using\n  Pretrained Transformers",
        "url": "http://arxiv.org/abs/2307.09455v2",
        "pub_date": "2023-07-18",
        "summary": "For real-world language applications, detecting an out-of-distribution (OOD)\nsample is helpful to alert users or reject such unreliable samples. However,\nmodern over-parameterized language models often produce overconfident\npredictions for both in-distribution (ID) and OOD samples. In particular,\nlanguage models suffer from OOD samples with a similar semantic representation\nto ID samples since these OOD samples lie near the ID manifold. A rejection\nnetwork can be trained with ID and diverse outlier samples to detect test OOD\nsamples, but explicitly collecting auxiliary OOD datasets brings an additional\nburden for data collection. In this paper, we propose a simple but effective\nmethod called Pseudo Outlier Exposure (POE) that constructs a surrogate OOD\ndataset by sequentially masking tokens related to ID classes. The surrogate OOD\nsample introduced by POE shows a similar representation to ID data, which is\nmost effective in training a rejection network. Our method does not require any\nexternal OOD data and can be easily implemented within off-the-shelf\nTransformers. A comprehensive comparison with state-of-the-art algorithms\ndemonstrates POE's competitiveness on several text classification benchmarks.",
        "translated": ""
    },
    {
        "title": "Let's ViCE! Mimicking Human Cognitive Behavior in Image Generation\n  Evaluation",
        "url": "http://arxiv.org/abs/2307.09416v2",
        "pub_date": "2023-07-18",
        "summary": "Research in Image Generation has recently made significant progress,\nparticularly boosted by the introduction of Vision-Language models which are\nable to produce high-quality visual content based on textual inputs. Despite\nongoing advancements in terms of generation quality and realism, no methodical\nframeworks have been defined yet to quantitatively measure the quality of the\ngenerated content and the adherence with the prompted requests: so far, only\nhuman-based evaluations have been adopted for quality satisfaction and for\ncomparing different generative methods. We introduce a novel automated method\nfor Visual Concept Evaluation (ViCE), i.e. to assess consistency between a\ngenerated/edited image and the corresponding prompt/instructions, with a\nprocess inspired by the human cognitive behaviour. ViCE combines the strengths\nof Large Language Models (LLMs) and Visual Question Answering (VQA) into a\nunified pipeline, aiming to replicate the human cognitive process in quality\nassessment. This method outlines visual concepts, formulates image-specific\nverification questions, utilizes the Q&amp;A system to investigate the image, and\nscores the combined outcome. Although this brave new hypothesis of mimicking\nhumans in the image evaluation process is in its preliminary assessment stage,\nresults are promising and open the door to a new form of automatic evaluation\nwhich could have significant impact as the image generation or the image target\nediting tasks become more and more sophisticated.",
        "translated": ""
    },
    {
        "title": "Multi-Modal Discussion Transformer: Integrating Text, Images and Graph\n  Transformers to Detect Hate Speech on Social Media",
        "url": "http://arxiv.org/abs/2307.09312v1",
        "pub_date": "2023-07-18",
        "summary": "We present the Multi-Modal Discussion Transformer (mDT), a novel multi-modal\ngraph-based transformer model for detecting hate speech in online social\nnetworks. In contrast to traditional text-only methods, our approach to\nlabelling a comment as hate speech centers around the holistic analysis of text\nand images. This is done by leveraging graph transformers to capture the\ncontextual relationships in the entire discussion that surrounds a comment,\nwith interwoven fusion layers to combine text and image embeddings instead of\nprocessing different modalities separately. We compare the performance of our\nmodel to baselines that only process text; we also conduct extensive ablation\nstudies. We conclude with future work for multimodal solutions to deliver\nsocial value in online contexts, arguing that capturing a holistic view of a\nconversation greatly advances the effort to detect anti-social behavior.",
        "translated": ""
    },
    {
        "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models",
        "url": "http://arxiv.org/abs/2307.09288v2",
        "pub_date": "2023-07-18",
        "summary": "In this work, we develop and release Llama 2, a collection of pretrained and\nfine-tuned large language models (LLMs) ranging in scale from 7 billion to 70\nbillion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for\ndialogue use cases. Our models outperform open-source chat models on most\nbenchmarks we tested, and based on our human evaluations for helpfulness and\nsafety, may be a suitable substitute for closed-source models. We provide a\ndetailed description of our approach to fine-tuning and safety improvements of\nLlama 2-Chat in order to enable the community to build on our work and\ncontribute to the responsible development of LLMs.",
        "translated": ""
    },
    {
        "title": "Improving Text Semantic Similarity Modeling through a 3D Siamese Network",
        "url": "http://arxiv.org/abs/2307.09274v1",
        "pub_date": "2023-07-18",
        "summary": "Siamese networks have gained popularity as a method for modeling text\nsemantic similarity. Traditional methods rely on pooling operation to compress\nthe semantic representations from Transformer blocks in encoding, resulting in\ntwo-dimensional semantic vectors and the loss of hierarchical semantic\ninformation from Transformer blocks. Moreover, this limited structure of\nsemantic vectors is akin to a flattened landscape, which restricts the methods\nthat can be applied in downstream modeling, as they can only navigate this flat\nterrain. To address this issue, we propose a novel 3D Siamese network for text\nsemantic similarity modeling, which maps semantic information to a\nhigher-dimensional space. The three-dimensional semantic tensors not only\nretains more precise spatial and feature domain information but also provides\nthe necessary structural condition for comprehensive downstream modeling\nstrategies to capture them. Leveraging this structural advantage, we introduce\nseveral modules to reinforce this 3D framework, focusing on three aspects:\nfeature extraction, attention, and feature fusion. Our extensive experiments on\nfour text semantic similarity benchmarks demonstrate the effectiveness and\nefficiency of our 3D Siamese Network.",
        "translated": ""
    },
    {
        "title": "Linearized Relative Positional Encoding",
        "url": "http://arxiv.org/abs/2307.09270v1",
        "pub_date": "2023-07-18",
        "summary": "Relative positional encoding is widely used in vanilla and linear\ntransformers to represent positional information. However, existing encoding\nmethods of a vanilla transformer are not always directly applicable to a linear\ntransformer, because the latter requires a decomposition of the query and key\nrepresentations into separate kernel functions. Nevertheless, principles for\ndesigning encoding methods suitable for linear transformers remain\nunderstudied. In this work, we put together a variety of existing linear\nrelative positional encoding approaches under a canonical form and further\npropose a family of linear relative positional encoding algorithms via unitary\ntransformation. Our formulation leads to a principled framework that can be\nused to develop new relative positional encoding methods that preserve linear\nspace-time complexity. Equipped with different models, the proposed linearized\nrelative positional encoding (LRPE) family derives effective encoding for\nvarious applications. Experiments show that compared with existing methods,\nLRPE achieves state-of-the-art performance in language modeling, text\nclassification, and image classification. Meanwhile, it emphasizes a general\nparadigm for designing broadly more relative positional encoding methods that\nare applicable to linear transformers. The code is available at\nhttps://github.com/OpenNLPLab/Lrpe.",
        "translated": ""
    },
    {
        "title": "UniMatch: A Unified User-Item Matching Framework for the Multi-purpose\n  Merchant Marketing",
        "url": "http://arxiv.org/abs/2307.09989v1",
        "pub_date": "2023-07-19",
        "summary": "When doing private domain marketing with cloud services, the merchants\nusually have to purchase different machine learning models for the multiple\nmarketing purposes, leading to a very high cost. We present a unified user-item\nmatching framework to simultaneously conduct item recommendation and user\ntargeting with just one model. We empirically demonstrate that the above\nconcurrent modeling is viable via modeling the user-item interaction matrix\nwith the multinomial distribution, and propose a bidirectional bias-corrected\nNCE loss for the implementation. The proposed loss function guides the model to\nlearn the user-item joint probability $p(u,i)$ instead of the conditional\nprobability $p(i|u)$ or $p(u|i)$ through correcting both the users and items'\nbiases caused by the in-batch negative sampling. In addition, our framework is\nmodel-agnostic enabling a flexible adaptation of different model architectures.\nExtensive experiments demonstrate that our framework results in significant\nperformance gains in comparison with the state-of-the-art methods, with greatly\nreduced cost on computing resources and daily maintenance.",
        "translated": ""
    },
    {
        "title": "Our Model Achieves Excellent Performance on MovieLens: What Does it\n  Mean?",
        "url": "http://arxiv.org/abs/2307.09985v1",
        "pub_date": "2023-07-19",
        "summary": "A typical benchmark dataset for recommender system (RecSys) evaluation\nconsists of user-item interactions generated on a platform within a time\nperiod. The interaction generation mechanism partially explains why a user\ninteracts with (e.g.,like, purchase, rate) an item, and the context of when a\nparticular interaction happened. In this study, we conduct a meticulous\nanalysis on the MovieLens dataset and explain the potential impact on using the\ndataset for evaluating recommendation algorithms. We make a few main findings\nfrom our analysis. First, there are significant differences in user\ninteractions at the different stages when a user interacts with the MovieLens\nplatform. The early interactions largely define the user portrait which affect\nthe subsequent interactions. Second, user interactions are highly affected by\nthe candidate movies that are recommended by the platform's internal\nrecommendation algorithm(s). Removal of interactions that happen nearer to the\nlast few interactions of a user leads to increasing difficulty in learning user\npreference, thus deteriorating recommendation accuracy. Third, changing the\norder of user interactions makes it more difficult for sequential algorithms to\ncapture the progressive interaction process. Based on these findings, we\nfurther discuss the discrepancy between the interaction generation mechanism\nthat is employed by the MovieLens system and that of typical real world\nrecommendation scenarios. In summary, models that achieve excellent\nrecommendation accuracy on the MovieLens dataset may not demonstrate superior\nperformance in practice for at least two kinds of differences: (i) the\ndifferences in the contexts of user-item interaction generation, and (ii) the\ndifferences in user knowledge about the item collections.",
        "translated": ""
    },
    {
        "title": "Who Provides the Largest Megaphone? The Role of Google News in Promoting\n  Russian State-Affiliated News Sources",
        "url": "http://arxiv.org/abs/2307.09834v1",
        "pub_date": "2023-07-19",
        "summary": "The Internet has not only digitized but also democratized information access\nacross the globe. This gradual but path-breaking move to online information\npropagation has resulted in search engines playing an increasingly prominent\nrole in shaping access to human knowledge. When an Internet user enters a\nquery, the search engine sorts through the hundreds of billions of possible\nwebpages to determine what to show. Google dominates the search engine market,\nwith Google Search surpassing 80% market share globally every year of the last\ndecade. Only in Russia and China do Google competitors claim more market share,\nwith approximately 60% of Internet users in Russia preferring Yandex (compared\nto 40% in favor of Google) and more than 80% of China's Internet users\naccessing Baidu as of 2022. Notwithstanding this long-standing regional\nvariation in Internet search providers, there is limited research showing how\nthese providers compare in terms of propagating state-sponsored information.\nOur study fills this research gap by focusing on Russian cyberspace and\nexamining how Google and Yandex's search algorithms rank content from Russian\nstate-controlled media (hereon, RSM) outlets. This question is timely and of\npractical interest given widespread reports indicating that RSM outlets have\nactively engaged in promoting Kremlin propaganda in the lead-up to, and in the\naftermath of, the Russian invasion of Ukraine in February 2022.",
        "translated": ""
    },
    {
        "title": "DisCover: Disentangled Music Representation Learning for Cover Song\n  Identification",
        "url": "http://arxiv.org/abs/2307.09775v1",
        "pub_date": "2023-07-19",
        "summary": "In the field of music information retrieval (MIR), cover song identification\n(CSI) is a challenging task that aims to identify cover versions of a query\nsong from a massive collection. Existing works still suffer from high\nintra-song variances and inter-song correlations, due to the entangled nature\nof version-specific and version-invariant factors in their modeling. In this\nwork, we set the goal of disentangling version-specific and version-invariant\nfactors, which could make it easier for the model to learn invariant music\nrepresentations for unseen query songs. We analyze the CSI task in a\ndisentanglement view with the causal graph technique, and identify the\nintra-version and inter-version effects biasing the invariant learning. To\nblock these effects, we propose the disentangled music representation learning\nframework (DisCover) for CSI. DisCover consists of two critical components: (1)\nKnowledge-guided Disentanglement Module (KDM) and (2) Gradient-based\nAdversarial Disentanglement Module (GADM), which block intra-version and\ninter-version biased effects, respectively. KDM minimizes the mutual\ninformation between the learned representations and version-variant factors\nthat are identified with prior domain knowledge. GADM identifies\nversion-variant factors by simulating the representation transitions between\nintra-song versions, and exploits adversarial distillation for effect blocking.\nExtensive comparisons with best-performing methods and in-depth analysis\ndemonstrate the effectiveness of DisCover and the and necessity of\ndisentanglement for CSI.",
        "translated": ""
    },
    {
        "title": "Information Retrieval Meets Large Language Models: A Strategic Report\n  from Chinese IR Community",
        "url": "http://arxiv.org/abs/2307.09751v1",
        "pub_date": "2023-07-19",
        "summary": "The research field of Information Retrieval (IR) has evolved significantly,\nexpanding beyond traditional search to meet diverse user information needs.\nRecently, Large Language Models (LLMs) have demonstrated exceptional\ncapabilities in text understanding, generation, and knowledge inference,\nopening up exciting avenues for IR research. LLMs not only facilitate\ngenerative retrieval but also offer improved solutions for user understanding,\nmodel evaluation, and user-system interactions. More importantly, the\nsynergistic relationship among IR models, LLMs, and humans forms a new\ntechnical paradigm that is more powerful for information seeking. IR models\nprovide real-time and relevant information, LLMs contribute internal knowledge,\nand humans play a central role of demanders and evaluators to the reliability\nof information services. Nevertheless, significant challenges exist, including\ncomputational costs, credibility concerns, domain-specific limitations, and\nethical considerations. To thoroughly discuss the transformative impact of LLMs\non IR research, the Chinese IR community conducted a strategic workshop in\nApril 2023, yielding valuable insights. This paper provides a summary of the\nworkshop's outcomes, including the rethinking of IR's core values, the mutual\nenhancement of LLMs and IR, the proposal of a novel IR technical paradigm, and\nopen challenges.",
        "translated": ""
    },
    {
        "title": "DialogStudio: Towards Richest and Most Diverse Unified Dataset\n  Collection for Conversational AI",
        "url": "http://arxiv.org/abs/2307.10172v2",
        "pub_date": "2023-07-19",
        "summary": "Despite advancements in conversational AI, language models encounter\nchallenges to handle diverse conversational tasks, and existing dialogue\ndataset collections often lack diversity and comprehensiveness. To tackle these\nissues, we introduce DialogStudio: the largest and most diverse collection of\ndialogue datasets, unified under a consistent format while preserving their\noriginal information. Our collection encompasses data from open-domain\ndialogues, task-oriented dialogues, natural language understanding,\nconversational recommendation, dialogue summarization, and knowledge-grounded\ndialogues, making it an incredibly rich and diverse resource for dialogue\nresearch and model training. To further enhance the utility of DialogStudio, we\nidentify the licenses for each dataset and design domain-aware prompts for\nselected dialogues to facilitate instruction-aware fine-tuning. Furthermore, we\ndevelop conversational AI models using the dataset collection, and our\nexperiments in both zero-shot and few-shot learning scenarios demonstrate the\nsuperiority of DialogStudio. To improve transparency and support dataset and\ntask-based research, as well as language model pre-training, all datasets,\nlicenses, codes, and models associated with DialogStudio are made publicly\naccessible at https://github.com/salesforce/DialogStudio",
        "translated": ""
    },
    {
        "title": "Challenges and Applications of Large Language Models",
        "url": "http://arxiv.org/abs/2307.10169v1",
        "pub_date": "2023-07-19",
        "summary": "Large Language Models (LLMs) went from non-existent to ubiquitous in the\nmachine learning discourse within a few years. Due to the fast pace of the\nfield, it is difficult to identify the remaining challenges and already\nfruitful application areas. In this paper, we aim to establish a systematic set\nof open problems and application successes so that ML researchers can\ncomprehend the field's current state more quickly and become productive.",
        "translated": ""
    },
    {
        "title": "LLMs as Workers in Human-Computational Algorithms? Replicating\n  Crowdsourcing Pipelines with LLMs",
        "url": "http://arxiv.org/abs/2307.10168v2",
        "pub_date": "2023-07-19",
        "summary": "LLMs have shown promise in replicating human-like behavior in crowdsourcing\ntasks that were previously thought to be exclusive to human abilities. However,\ncurrent efforts focus mainly on simple atomic tasks. We explore whether LLMs\ncan replicate more complex crowdsourcing pipelines. We find that modern LLMs\ncan simulate some of crowdworkers' abilities in these \"human computation\nalgorithms,\" but the level of success is variable and influenced by requesters'\nunderstanding of LLM capabilities, the specific skills required for sub-tasks,\nand the optimal interaction modality for performing these sub-tasks. We reflect\non human and LLMs' different sensitivities to instructions, stress the\nimportance of enabling human-facing safeguards for LLMs, and discuss the\npotential of training humans and LLMs with complementary skill sets. Crucially,\nwe show that replicating crowdsourcing pipelines offers a valuable platform to\ninvestigate (1) the relative strengths of LLMs on different tasks (by\ncross-comparing their performances on sub-tasks) and (2) LLMs' potential in\ncomplex tasks, where they can complete part of the tasks while leaving others\nto humans.",
        "translated": ""
    },
    {
        "title": "Exploring Transformer Extrapolation",
        "url": "http://arxiv.org/abs/2307.10156v1",
        "pub_date": "2023-07-19",
        "summary": "Length extrapolation has attracted considerable attention recently since it\nallows transformers to be tested on longer sequences than those used in\ntraining. Previous research has shown that this property can be attained by\nusing carefully designed Relative Positional Encodings (RPEs). While these\nmethods perform well on a variety of corpora, the conditions for length\nextrapolation have yet to be investigated. This paper attempts to determine\nwhat types of RPEs allow for length extrapolation through a thorough\nmathematical and empirical analysis. We discover that a transformer is certain\nto possess this property as long as the series that corresponds to the RPE's\nexponential converges. Two practices are derived from the conditions and\nexamined in language modeling tasks on a variety of corpora. As a bonus from\nthe conditions, we derive a new Theoretical Receptive Field (TRF) to measure\nthe receptive field of RPEs without taking any training steps. Extensive\nexperiments are conducted on the Wikitext-103, Books, Github, and WikiBook\ndatasets to demonstrate the viability of our discovered conditions. We also\ncompare TRF to Empirical Receptive Field (ERF) across different models, showing\nconsistently matched trends on the aforementioned datasets. The code is\navailable at https://github.com/OpenNLPLab/Rpe.",
        "translated": ""
    },
    {
        "title": "Gradient Sparsification For Masked Fine-Tuning of Transformers",
        "url": "http://arxiv.org/abs/2307.10098v1",
        "pub_date": "2023-07-19",
        "summary": "Fine-tuning pretrained self-supervised language models is widely adopted for\ntransfer learning to downstream tasks. Fine-tuning can be achieved by freezing\ngradients of the pretrained network and only updating gradients of a newly\nadded classification layer, or by performing gradient updates on all\nparameters. Gradual unfreezing makes a trade-off between the two by gradually\nunfreezing gradients of whole layers during training. This has been an\neffective strategy to trade-off between storage and training speed with\ngeneralization performance. However, it is not clear whether gradually\nunfreezing layers throughout training is optimal, compared to sparse variants\nof gradual unfreezing which may improve fine-tuning performance. In this paper,\nwe propose to stochastically mask gradients to regularize pretrained language\nmodels for improving overall fine-tuned performance. We introduce GradDrop and\nvariants thereof, a class of gradient sparsification methods that mask\ngradients during the backward pass, acting as gradient noise. GradDrop is\nsparse and stochastic unlike gradual freezing. Extensive experiments on the\nmultilingual XGLUE benchmark with XLMR-Large show that GradDrop is competitive\nagainst methods that use additional translated data for intermediate\npretraining and outperforms standard fine-tuning and gradual unfreezing. A\npost-analysis shows how GradDrop improves performance with languages it was not\ntrained on, such as under-resourced languages.",
        "translated": ""
    },
    {
        "title": "Android in the Wild: A Large-Scale Dataset for Android Device Control",
        "url": "http://arxiv.org/abs/2307.10088v1",
        "pub_date": "2023-07-19",
        "summary": "There is a growing interest in device-control systems that can interpret\nhuman natural language instructions and execute them on a digital device by\ndirectly controlling its user interface. We present a dataset for\ndevice-control research, Android in the Wild (AITW), which is orders of\nmagnitude larger than current datasets. The dataset contains human\ndemonstrations of device interactions, including the screens and actions, and\ncorresponding natural language instructions. It consists of 715k episodes\nspanning 30k unique instructions, four versions of Android (v10-13),and eight\ndevice types (Pixel 2 XL to Pixel 6) with varying screen resolutions. It\ncontains multi-step tasks that require semantic understanding of language and\nvisual context. This dataset poses a new challenge: actions available through\nthe user interface must be inferred from their visual appearance. And, instead\nof simple UI element-based actions, the action space consists of precise\ngestures (e.g., horizontal scrolls to operate carousel widgets). We organize\nour dataset to encourage robustness analysis of device-control systems, i.e.,\nhow well a system performs in the presence of new task descriptions, new\napplications, or new platform versions. We develop two agents and report\nperformance across the dataset. The dataset is available at\nhttps://github.com/google-research/google-research/tree/master/android_in_the_wild.",
        "translated": ""
    },
    {
        "title": "An Empirical Study on Fertility Proposals Using Multi-Grined Topic\n  Analysis Methods",
        "url": "http://arxiv.org/abs/2307.10025v1",
        "pub_date": "2023-07-19",
        "summary": "Fertility issues are closely related to population security, in 60 years\nChina's population for the first time in a negative growth trend, the change of\nfertility policy is of great concern to the community. 2023 ``two sessions\"\nproposal ``suggests that the country in the form of legislation, the birth of\nthe registration of the cancellation of the marriage restriction\" This topic\nwas once a hot topic on the Internet, and ``unbundling\" the relationship\nbetween birth registration and marriage has become the focus of social debate.\nIn this paper, we adopt co-occurrence semantic analysis, topic analysis and\nsentiment analysis to conduct multi-granularity semantic analysis of microblog\ncomments. It is found that the discussion on the proposal of ``removing\nmarriage restrictions from birth registration\" involves the individual, society\nand the state at three dimensions, and is detailed into social issues such as\npersonal behaviour, social ethics and law, and national policy, with people's\nsentiment inclined to be negative in most of the topics. Based on this, eight\nproposals were made to provide a reference for governmental decision making and\nto form a reference method for researching public opinion on political issues.",
        "translated": ""
    },
    {
        "title": "Generating Mathematical Derivations with Large Language Models",
        "url": "http://arxiv.org/abs/2307.09998v1",
        "pub_date": "2023-07-19",
        "summary": "The derivation of mathematical results in specialised fields using Large\nLanguage Models (LLMs) is an emerging research direction that can help identify\nmodels' limitations, and potentially support mathematical discovery. In this\npaper, we leverage a symbolic engine to generate derivations of equations at\nscale, and investigate the capabilities of LLMs when deriving goal equations\nfrom premises. Specifically, we employ in-context learning for GPT and\nfine-tune a range of T5 models to compare the robustness and generalisation of\npre-training strategies to specialised models. Empirical results show that\nfine-tuned FLAN-T5-large (MathT5) outperforms GPT models on all static and\nout-of-distribution test sets in terms of absolute performance. However, an\nin-depth analysis reveals that the fine-tuned models are more sensitive to\nperturbations involving unseen symbols and (to a lesser extent) changes to\nequation structure. In addition, we analyse 1.7K equations and over 200\nderivations to highlight common reasoning errors such as the inclusion of\nincorrect, irrelevant, and redundant equations, along with the tendency to skip\nderivation steps. Finally, we explore the suitability of existing metrics for\nevaluating mathematical derivations finding evidence that, while they capture\ngeneral properties such as sensitivity to perturbations, they fail to highlight\nfine-grained reasoning errors and essential differences between models.\nOverall, this work demonstrates that training models on synthetic data can\nimprove their mathematical capabilities beyond larger architectures.",
        "translated": ""
    },
    {
        "title": "GUIDO: A Hybrid Approach to Guideline Discovery &amp; Ordering from Natural\n  Language Texts",
        "url": "http://arxiv.org/abs/2307.09959v1",
        "pub_date": "2023-07-19",
        "summary": "Extracting workflow nets from textual descriptions can be used to simplify\nguidelines or formalize textual descriptions of formal processes like business\nprocesses and algorithms. The task of manually extracting processes, however,\nrequires domain expertise and effort. While automatic process model extraction\nis desirable, annotating texts with formalized process models is expensive.\nTherefore, there are only a few machine-learning-based extraction approaches.\nRule-based approaches, in turn, require domain specificity to work well and can\nrarely distinguish relevant and irrelevant information in textual descriptions.\nIn this paper, we present GUIDO, a hybrid approach to the process model\nextraction task that first, classifies sentences regarding their relevance to\nthe process model, using a BERT-based sentence classifier, and second, extracts\na process model from the sentences classified as relevant, using dependency\nparsing. The presented approach achieves significantly better results than a\npure rule-based approach. GUIDO achieves an average behavioral similarity score\nof $0.93$. Still, in comparison to purely machine-learning-based approaches,\nthe annotation costs stay low.",
        "translated": ""
    },
    {
        "title": "Large Language Models can accomplish Business Process Management Tasks",
        "url": "http://arxiv.org/abs/2307.09923v1",
        "pub_date": "2023-07-19",
        "summary": "Business Process Management (BPM) aims to improve organizational activities\nand their outcomes by managing the underlying processes. To achieve this, it is\noften necessary to consider information from various sources, including\nunstructured textual documents. Therefore, researchers have developed several\nBPM-specific solutions that extract information from textual documents using\nNatural Language Processing techniques. These solutions are specific to their\nrespective tasks and cannot accomplish multiple process-related problems as a\ngeneral-purpose instrument. However, in light of the recent emergence of Large\nLanguage Models (LLMs) with remarkable reasoning capabilities, such a\ngeneral-purpose instrument with multiple applications now appears attainable.\nIn this paper, we illustrate how LLMs can accomplish text-related BPM tasks by\napplying a specific LLM to three exemplary tasks: mining imperative process\nmodels from textual descriptions, mining declarative process models from\ntextual descriptions, and assessing the suitability of process tasks from\ntextual descriptions for robotic process automation. We show that, without\nextensive configuration or prompt engineering, LLMs perform comparably to or\nbetter than existing solutions and discuss implications for future BPM research\nas well as practical usage.",
        "translated": ""
    },
    {
        "title": "Investigating the Factual Knowledge Boundary of Large Language Models\n  with Retrieval Augmentation",
        "url": "http://arxiv.org/abs/2307.11019v1",
        "pub_date": "2023-07-20",
        "summary": "Knowledge-intensive tasks (e.g., open-domain question answering (QA)) require\na substantial amount of factual knowledge and often rely on external\ninformation for assistance. Recently, large language models (LLMs) (e.g.,\nChatGPT), have demonstrated impressive prowess in solving a wide range of tasks\nwith world knowledge, including knowledge-intensive tasks. However, it remains\nunclear how well LLMs are able to perceive their factual knowledge boundaries,\nparticularly how they behave when incorporating retrieval augmentation. In this\nstudy, we present an initial analysis of the factual knowledge boundaries of\nLLMs and how retrieval augmentation affects LLMs on open-domain QA. Specially,\nwe focus on three primary research questions and analyze them by examining QA\nperformance, priori judgement and posteriori judgement of LLMs. We show\nevidence that LLMs possess unwavering confidence in their capabilities to\nrespond to questions and the accuracy of their responses. Furthermore,\nretrieval augmentation proves to be an effective approach in enhancing LLMs'\nawareness of knowledge boundaries, thereby improving their judgemental\nabilities. Additionally, we also find that LLMs have a propensity to rely on\nthe provided retrieval results when formulating answers, while the quality of\nthese results significantly impacts their reliance. The code to reproduce this\nwork is available at https://github.com/RUCAIBox/LLM-Knowledge-Boundary.",
        "translated": ""
    },
    {
        "title": "Enhancing Job Recommendation through LLM-based Generative Adversarial\n  Networks",
        "url": "http://arxiv.org/abs/2307.10747v1",
        "pub_date": "2023-07-20",
        "summary": "Recommending suitable jobs to users is a critical task in online recruitment\nplatforms, as it can enhance users' satisfaction and the platforms'\nprofitability. While existing job recommendation methods encounter challenges\nsuch as the low quality of users' resumes, which hampers their accuracy and\npractical effectiveness. With the rapid development of large language models\n(LLMs), utilizing the rich external knowledge encapsulated within them, as well\nas their powerful capabilities of text processing and reasoning, is a promising\nway to complete users' resumes for more accurate recommendations. However,\ndirectly leveraging LLMs to enhance recommendation results is not a\none-size-fits-all solution, as LLMs may suffer from fabricated generation and\nfew-shot problems, which degrade the quality of resume completion. In this\npaper, we propose a novel LLM-based approach for job recommendation. To\nalleviate the limitation of fabricated generation for LLMs, we extract accurate\nand valuable information beyond users' self-description, which helps the LLMs\nbetter profile users for resume completion. Specifically, we not only extract\nusers' explicit properties (e.g., skills, interests) from their\nself-description but also infer users' implicit characteristics from their\nbehaviors for more accurate and meaningful resume completion. Nevertheless,\nsome users still suffer from few-shot problems, which arise due to scarce\ninteraction records, leading to limited guidance for the models in generating\nhigh-quality resumes. To address this issue, we propose aligning unpaired\nlow-quality with high-quality generated resumes by Generative Adversarial\nNetworks (GANs), which can refine the resume representations for better\nrecommendation results. Extensive experiments on three large real-world\nrecruitment datasets demonstrate the effectiveness of our proposed method.",
        "translated": ""
    },
    {
        "title": "A Constraint-based Recommender System via RDF Knowledge Graphs",
        "url": "http://arxiv.org/abs/2307.10702v1",
        "pub_date": "2023-07-20",
        "summary": "Knowledge graphs, represented in RDF, are able to model entities and their\nrelations by means of ontologies. The use of knowledge graphs for information\nmodeling has attracted interest in recent years. In recommender systems, items\nand users can be mapped and integrated into the knowledge graph, which can\nrepresent more links and relationships between users and items.\nConstraint-based recommender systems are based on the idea of explicitly\nexploiting deep recommendation knowledge through constraints to identify\nrelevant recommendations. When combined with knowledge graphs, a\nconstraint-based recommender system gains several benefits in terms of\nconstraint sets. In this paper, we investigate and propose the construction of\na constraint-based recommender system via RDF knowledge graphs applied to the\nvehicle purchase/sale domain. The results of our experiments show that the\nproposed approach is able to efficiently identify recommendations in accordance\nwith user preferences.",
        "translated": ""
    },
    {
        "title": "A Personalized Recommender System Based-on Knowledge Graph Embeddings",
        "url": "http://arxiv.org/abs/2307.10680v1",
        "pub_date": "2023-07-20",
        "summary": "Knowledge graphs have proven to be effective for modeling entities and their\nrelationships through the use of ontologies. The recent emergence in interest\nfor using knowledge graphs as a form of information modeling has led to their\nincreased adoption in recommender systems. By incorporating users and items\ninto the knowledge graph, these systems can better capture the implicit\nconnections between them and provide more accurate recommendations. In this\npaper, we investigate and propose the construction of a personalized\nrecommender system via knowledge graphs embedding applied to the vehicle\npurchase/sale domain. The results of our experimentation demonstrate the\nefficacy of the proposed method in providing relevant recommendations that are\nconsistent with individual users.",
        "translated": ""
    },
    {
        "title": "Language-Enhanced Session-Based Recommendation with Decoupled\n  Contrastive Learning",
        "url": "http://arxiv.org/abs/2307.10650v1",
        "pub_date": "2023-07-20",
        "summary": "Session-based recommendation techniques aim to capture dynamic user behavior\nby analyzing past interactions. However, existing methods heavily rely on\nhistorical item ID sequences to extract user preferences, leading to challenges\nsuch as popular bias and cold-start problems. In this paper, we propose a\nhybrid multimodal approach for session-based recommendation to address these\nchallenges. Our approach combines different modalities, including textual\ncontent and item IDs, leveraging the complementary nature of these modalities\nusing CatBoost. To learn universal item representations, we design a language\nrepresentation-based item retrieval architecture that extracts features from\nthe textual content utilizing pre-trained language models. Furthermore, we\nintroduce a novel Decoupled Contrastive Learning method to enhance the\neffectiveness of the language representation. This technique decouples the\nsequence representation and item representation space, facilitating\nbidirectional alignment through dual-queue contrastive learning.\nSimultaneously, the momentum queue provides a large number of negative samples,\neffectively enhancing the effectiveness of contrastive learning. Our approach\nyielded competitive results, securing a 5th place ranking in KDD CUP 2023 Task\n1. We have released the source code and pre-trained models associated with this\nwork.",
        "translated": ""
    },
    {
        "title": "L-Eval: Instituting Standardized Evaluation for Long Context Language\n  Models",
        "url": "http://arxiv.org/abs/2307.11088v1",
        "pub_date": "2023-07-20",
        "summary": "Recently, there has been growing interest in extending the context length of\ninstruction-following models in order to effectively process single-turn long\ninput (e.g. summarizing a paper) and conversations with more extensive\nhistories. While proprietary models such as GPT-4 and Claude have demonstrated\nconsiderable advancements in handling tens of thousands of tokens of context,\nopen-sourced models are still in the early stages of experimentation. It also\nremains unclear whether developing these long context models can offer\nsubstantial gains on practical downstream tasks over retrieval-based methods or\nmodels simply trained on chunked contexts. To address this challenge, we\npropose to institute standardized evaluation for long context language models.\nConcretely, we develop L-Eval which contains 411 long documents and over 2,000\nquery-response pairs manually annotated and checked by the authors encompassing\nareas such as law, finance, school lectures, lengthy conversations, news,\nlong-form novels, and meetings. L-Eval also adopts diverse evaluation methods\nand instruction styles, enabling a more reliable assessment of Long Context\nLanguage Models (LCLMs). Our findings indicate that while open-source models\ntypically lag behind their commercial counterparts, they still exhibit\nimpressive performance. LLaMA2 achieves the best results (win 45\\% vs\nturbo-16k) on open-ended tasks with only 4k context length and ChatGLM2\nachieves the best results on closed-ended tasks with 8k input tokens. We\nrelease our new evaluation suite, code, and all generation results including\npredictions from all open-sourced LCLMs, GPT4-32k, Cluade-100k at\n{\\url{https://github.com/OpenLMLab/LEval}}.",
        "translated": ""
    },
    {
        "title": "Embroid: Unsupervised Prediction Smoothing Can Improve Few-Shot\n  Classification",
        "url": "http://arxiv.org/abs/2307.11031v1",
        "pub_date": "2023-07-20",
        "summary": "Recent work has shown that language models' (LMs) prompt-based learning\ncapabilities make them well suited for automating data labeling in domains\nwhere manual annotation is expensive. The challenge is that while writing an\ninitial prompt is cheap, improving a prompt is costly -- practitioners often\nrequire significant labeled data in order to evaluate the impact of prompt\nmodifications. Our work asks whether it is possible to improve prompt-based\nlearning without additional labeled data. We approach this problem by\nattempting to modify the predictions of a prompt, rather than the prompt\nitself. Our intuition is that accurate predictions should also be consistent:\nsamples which are similar under some feature representation should receive the\nsame prompt prediction. We propose Embroid, a method which computes multiple\nrepresentations of a dataset under different embedding functions, and uses the\nconsistency between the LM predictions for neighboring samples to identify\nmispredictions. Embroid then uses these neighborhoods to create additional\npredictions for each sample, and combines these predictions with a simple\nlatent variable graphical model in order to generate a final corrected\nprediction. In addition to providing a theoretical analysis of Embroid, we\nconduct a rigorous empirical evaluation across six different LMs and up to 95\ndifferent tasks. We find that (1) Embroid substantially improves performance\nover original prompts (e.g., by an average of 7.3 points on GPT-JT), (2) also\nrealizes improvements for more sophisticated prompting strategies (e.g.,\nchain-of-thought), and (3) can be specialized to domains like law through the\nembedding functions.",
        "translated": ""
    },
    {
        "title": "\"It Felt Like Having a Second Mind\": Investigating Human-AI\n  Co-creativity in Prewriting with Large Language Models",
        "url": "http://arxiv.org/abs/2307.10811v1",
        "pub_date": "2023-07-20",
        "summary": "Prewriting is the process of discovering and developing ideas before a first\ndraft, which requires divergent thinking and often implies unstructured\nstrategies such as diagramming, outlining, free-writing, etc. Although large\nlanguage models (LLMs) have been demonstrated to be useful for a variety of\ntasks including creative writing, little is known about how users would\ncollaborate with LLMs to support prewriting. The preferred collaborative role\nand initiative of LLMs during such a creativity process is also unclear. To\ninvestigate human-LLM collaboration patterns and dynamics during prewriting, we\nconducted a three-session qualitative study with 15 participants in two\ncreative tasks: story writing and slogan writing. The findings indicated that\nduring collaborative prewriting, there appears to be a three-stage iterative\nHuman-AI Co-creativity process that includes Ideation, Illumination, and\nImplementation stages. This collaborative process champions the human in a\ndominant role, in addition to mixed and shifting levels of initiative that\nexist between humans and LLMs. This research also reports on collaboration\nbreakdowns that occur during this process, user perceptions of using existing\nLLMs during Human-AI Co-creativity, and discusses design implications to\nsupport this co-creativity process.",
        "translated": ""
    },
    {
        "title": "Integrating Pretrained ASR and LM to Perform Sequence Generation for\n  Spoken Language Understanding",
        "url": "http://arxiv.org/abs/2307.11005v1",
        "pub_date": "2023-07-20",
        "summary": "There has been an increased interest in the integration of pretrained speech\nrecognition (ASR) and language models (LM) into the SLU framework. However,\nprior methods often struggle with a vocabulary mismatch between pretrained\nmodels, and LM cannot be directly utilized as they diverge from its NLU\nformulation. In this study, we propose a three-pass end-to-end (E2E) SLU system\nthat effectively integrates ASR and LM subnetworks into the SLU formulation for\nsequence generation tasks. In the first pass, our architecture predicts ASR\ntranscripts using the ASR subnetwork. This is followed by the LM subnetwork,\nwhich makes an initial SLU prediction. Finally, in the third pass, the\ndeliberation subnetwork conditions on representations from the ASR and LM\nsubnetworks to make the final prediction. Our proposed three-pass SLU system\nshows improved performance over cascaded and E2E SLU models on two benchmark\nSLU datasets, SLURP and SLUE, especially on acoustically challenging\nutterances.",
        "translated": ""
    },
    {
        "title": "MASR: Metadata Aware Speech Representation",
        "url": "http://arxiv.org/abs/2307.10982v1",
        "pub_date": "2023-07-20",
        "summary": "In the recent years, speech representation learning is constructed primarily\nas a self-supervised learning (SSL) task, using the raw audio signal alone,\nwhile ignoring the side-information that is often available for a given speech\nrecording. In this paper, we propose MASR, a Metadata Aware Speech\nRepresentation learning framework, which addresses the aforementioned\nlimitations. MASR enables the inclusion of multiple external knowledge sources\nto enhance the utilization of meta-data information. The external knowledge\nsources are incorporated in the form of sample-level pair-wise similarity\nmatrices that are useful in a hard-mining loss. A key advantage of the MASR\nframework is that it can be combined with any choice of SSL method. Using MASR\nrepresentations, we perform evaluations on several downstream tasks such as\nlanguage identification, speech recognition and other non-semantic tasks such\nas speaker and emotion recognition. In these experiments, we illustrate\nsignificant performance improvements for the MASR over other established\nbenchmarks. We perform a detailed analysis on the language identification task\nto provide insights on how the proposed loss function enables the\nrepresentations to separate closely related languages.",
        "translated": ""
    },
    {
        "title": "Identical and Fraternal Twins: Fine-Grained Semantic Contrastive\n  Learning of Sentence Representations",
        "url": "http://arxiv.org/abs/2307.10932v1",
        "pub_date": "2023-07-20",
        "summary": "The enhancement of unsupervised learning of sentence representations has been\nsignificantly achieved by the utility of contrastive learning. This approach\nclusters the augmented positive instance with the anchor instance to create a\ndesired embedding space. However, relying solely on the contrastive objective\ncan result in sub-optimal outcomes due to its inability to differentiate subtle\nsemantic variations between positive pairs. Specifically, common data\naugmentation techniques frequently introduce semantic distortion, leading to a\nsemantic margin between the positive pair. While the InfoNCE loss function\noverlooks the semantic margin and prioritizes similarity maximization between\npositive pairs during training, leading to the insensitive semantic\ncomprehension ability of the trained model. In this paper, we introduce a novel\nIdentical and Fraternal Twins of Contrastive Learning (named IFTCL) framework,\ncapable of simultaneously adapting to various positive pairs generated by\ndifferent augmentation techniques. We propose a \\textit{Twins Loss} to preserve\nthe innate margin during training and promote the potential of data enhancement\nin order to overcome the sub-optimal issue. We also present proof-of-concept\nexperiments combined with the contrastive objective to prove the validity of\nthe proposed Twins Loss. Furthermore, we propose a hippocampus queue mechanism\nto restore and reuse the negative instances without additional calculation,\nwhich further enhances the efficiency and performance of the IFCL. We verify\nthe IFCL framework on nine semantic textual similarity tasks with both English\nand Chinese datasets, and the experimental results show that IFCL outperforms\nstate-of-the-art methods.",
        "translated": ""
    },
    {
        "title": "MediaGPT : A Large Language Model Target Chinese Media",
        "url": "http://arxiv.org/abs/2307.10930v1",
        "pub_date": "2023-07-20",
        "summary": "The development of large language models (LLMs) has seen rapid progress in\nrecent years. One of the most widely used LLMs is the Generative Pre-trained\nTransformer (GPT) series, which has been applied in various fields, including\nthe media domain. However, in practical applications, the differences between\nthe media's use cases and the general-purpose applications of LLMs have become\nincreasingly apparent, especially Chinese. As a result, there is a growing need\nto develop LLM that are specifically tailored to the unique requirements of the\nmedia domain. In this paper, we present MediaGPT, a large language model\ntraining on variety of media data and addressing the practical needs of Chinese\nmedia. We have designed a diverse set of task instruction types to cater to the\nspecific requirements of the domain. To further validate the effectiveness of\nour proposed LLM, we have constructed unique datasets that are tailored to the\nmedia domain and have also developed verification methods that are specifically\ndesigned for generative-type tasks. By doing so, we aim to bridge the gap\nbetween the general-purpose LLM and the requirements of the media domain, and\nto pave the way for more effective and efficient use of LLM in this field. This\npaper aims to explore the challenges and opportunities of developing LLM for\nmedia applications and to propose potential solutions for addressing these\nchallenges.",
        "translated": ""
    },
    {
        "title": "FLASK: Fine-grained Language Model Evaluation based on Alignment Skill\n  Sets",
        "url": "http://arxiv.org/abs/2307.10928v1",
        "pub_date": "2023-07-20",
        "summary": "Evaluation of Large Language Models (LLMs) is challenging because aligning to\nhuman values requires the composition of multiple skills and the required set\nof skills varies depending on the instruction. Recent studies have evaluated\nthe performance of LLMs in two ways, (1) automatic evaluation on several\nindependent benchmarks and (2) human or machined-based evaluation giving an\noverall score to the response. However, both settings are coarse-grained\nevaluations, not considering the nature of user instructions that require\ninstance-wise skill composition, which limits the interpretation of the true\ncapabilities of LLMs. In this paper, we introduce FLASK (Fine-grained Language\nModel Evaluation based on Alignment SKill Sets), a fine-grained evaluation\nprotocol that can be used for both model-based and human-based evaluation which\ndecomposes coarse-level scoring to an instance-wise skill set-level.\nSpecifically, we define 12 fine-grained skills needed for LLMs to follow\nopen-ended user instructions and construct an evaluation set by allocating a\nset of skills for each instance. Additionally, by annotating the target domains\nand difficulty level for each instance, FLASK provides a holistic view with a\ncomprehensive analysis of a model's performance depending on skill, domain, and\ndifficulty. Through using FLASK, we compare multiple open-sourced and\nproprietary LLMs and observe highly-correlated findings between model-based and\nhuman-based evaluations. FLASK enables developers to more accurately measure\nthe model performance and how it can be improved by analyzing factors that make\nLLMs proficient in particular skills. For practitioners, FLASK can be used to\nrecommend suitable models for particular situations through comprehensive\ncomparison among various LLMs. We release the evaluation data and code\nimplementation at https://github.com/kaistAI/FLASK.",
        "translated": ""
    },
    {
        "title": "FigCaps-HF: A Figure-to-Caption Generative Framework and Benchmark with\n  Human Feedback",
        "url": "http://arxiv.org/abs/2307.10867v1",
        "pub_date": "2023-07-20",
        "summary": "Captions are crucial for understanding scientific visualizations and\ndocuments. Existing captioning methods for scientific figures rely on\nfigure-caption pairs extracted from documents for training, many of which fall\nshort with respect to metrics like helpfulness, explainability, and\nvisual-descriptiveness [15] leading to generated captions being misaligned with\nreader preferences. To enable the generation of high-quality figure captions,\nwe introduce FigCaps-HF a new framework for figure-caption generation that can\nincorporate domain expert feedback in generating captions optimized for reader\npreferences. Our framework comprises of 1) an automatic method for evaluating\nquality of figure-caption pairs, 2) a novel reinforcement learning with human\nfeedback (RLHF) method to optimize a generative figure-to-caption model for\nreader preferences. We demonstrate the effectiveness of our simple learning\nframework by improving performance over standard fine-tuning across different\ntypes of models. In particular, when using BLIP as the base model, our RLHF\nframework achieves a mean gain of 35.7%, 16.9%, and 9% in ROUGE, BLEU, and\nMeteor, respectively. Finally, we release a large-scale benchmark dataset with\nhuman feedback on figure-caption pairs to enable further evaluation and\ndevelopment of RLHF techniques for this problem.",
        "translated": ""
    },
    {
        "title": "Alleviating the Long-Tail Problem in Conversational Recommender Systems",
        "url": "http://arxiv.org/abs/2307.11650v1",
        "pub_date": "2023-07-21",
        "summary": "Conversational recommender systems (CRS) aim to provide the recommendation\nservice via natural language conversations. To develop an effective CRS,\nhigh-quality CRS datasets are very crucial. However, existing CRS datasets\nsuffer from the long-tail issue, \\ie a large proportion of items are rarely (or\neven never) mentioned in the conversations, which are called long-tail items.\nAs a result, the CRSs trained on these datasets tend to recommend frequent\nitems, and the diversity of the recommended items would be largely reduced,\nmaking users easier to get bored.\n  To address this issue, this paper presents \\textbf{LOT-CRS}, a novel\nframework that focuses on simulating and utilizing a balanced CRS dataset (\\ie\ncovering all the items evenly) for improving \\textbf{LO}ng-\\textbf{T}ail\nrecommendation performance of CRSs. In our approach, we design two pre-training\ntasks to enhance the understanding of simulated conversation for long-tail\nitems, and adopt retrieval-augmented fine-tuning with label smoothness strategy\nto further improve the recommendation of long-tail items. Extensive experiments\non two public CRS datasets have demonstrated the effectiveness and\nextensibility of our approach, especially on long-tail recommendation.",
        "translated": ""
    },
    {
        "title": "Identifying document similarity using a fast estimation of the\n  Levenshtein Distance based on compression and signatures",
        "url": "http://arxiv.org/abs/2307.11496v1",
        "pub_date": "2023-07-21",
        "summary": "Identifying document similarity has many applications, e.g., source code\nanalysis or plagiarism detection. However, identifying similarities is not\ntrivial and can be time complex. For instance, the Levenshtein Distance is a\ncommon metric to define the similarity between two documents but has quadratic\nruntime which makes it impractical for large documents where large starts with\na few hundred kilobytes. In this paper, we present a novel concept that allows\nestimating the Levenshtein Distance: the algorithm first compresses documents\nto signatures (similar to hash values) using a user-defined compression ratio.\nSignatures can then be compared against each other (some constrains apply)\nwhere the outcome is the estimated Levenshtein Distance. Our evaluation shows\npromising results in terms of runtime efficiency and accuracy. In addition, we\nintroduce a significance score allowing examiners to set a threshold and\nidentify related documents.",
        "translated": ""
    },
    {
        "title": "Analysis of Elephant Movement in Sub-Saharan Africa: Ecological,\n  Climatic, and Conservation Perspectives",
        "url": "http://arxiv.org/abs/2307.11325v1",
        "pub_date": "2023-07-21",
        "summary": "The interaction between elephants and their environment has profound\nimplications for both ecology and conservation strategies. This study presents\nan analytical approach to decipher the intricate patterns of elephant movement\nin Sub-Saharan Africa, concentrating on key ecological drivers such as seasonal\nvariations and rainfall patterns. Despite the complexities surrounding these\ninfluential factors, our analysis provides a holistic view of elephant\nmigratory behavior in the context of the dynamic African landscape. Our\ncomprehensive approach enables us to predict the potential impact of these\necological determinants on elephant migration, a critical step in establishing\ninformed conservation strategies. This projection is particularly crucial given\nthe impacts of global climate change on seasonal and rainfall patterns, which\ncould substantially influence elephant movements in the future. The findings of\nour work aim to not only advance the understanding of movement ecology but also\nfoster a sustainable coexistence of humans and elephants in Sub-Saharan Africa.\nBy predicting potential elephant routes, our work can inform strategies to\nminimize human-elephant conflict, effectively manage land use, and enhance\nanti-poaching efforts. This research underscores the importance of integrating\nmovement ecology and climatic variables for effective wildlife management and\nconservation planning.",
        "translated": ""
    },
    {
        "title": "Jina Embeddings: A Novel Set of High-Performance Sentence Embedding\n  Models",
        "url": "http://arxiv.org/abs/2307.11224v1",
        "pub_date": "2023-07-20",
        "summary": "Jina Embeddings constitutes a set of high-performance sentence embedding\nmodels adept at translating various textual inputs into numerical\nrepresentations, thereby capturing the semantic essence of the text. While\nthese models are not exclusively designed for text generation, they excel in\napplications such as dense retrieval and semantic textual similarity. This\npaper details the development of Jina Embeddings, starting with the creation of\na high-quality pairwise and triplet dataset. It underlines the crucial role of\ndata cleaning in dataset preparation, gives in-depth insights into the model\ntraining process, and concludes with a comprehensive performance evaluation\nusing the Massive Textual Embedding Benchmark (MTEB).",
        "translated": ""
    },
    {
        "title": "RCVaR: an Economic Approach to Estimate Cyberattacks Costs using Data\n  from Industry Reports",
        "url": "http://arxiv.org/abs/2307.11140v1",
        "pub_date": "2023-07-20",
        "summary": "Digitization increases business opportunities and the risk of companies being\nvictims of devastating cyberattacks. Therefore, managing risk exposure and\ncybersecurity strategies is essential for digitized companies that want to\nsurvive in competitive markets. However, understanding company-specific risks\nand quantifying their associated costs is not trivial. Current approaches fail\nto provide individualized and quantitative monetary estimations of\ncybersecurity impacts. Due to limited resources and technical expertise, SMEs\nand even large companies are affected and struggle to quantify their\ncyberattack exposure. Therefore, novel approaches must be placed to support the\nunderstanding of the financial loss due to cyberattacks. This article\nintroduces the Real Cyber Value at Risk (RCVaR), an economical approach for\nestimating cybersecurity costs using real-world information from public\ncybersecurity reports. RCVaR identifies the most significant cyber risk factors\nfrom various sources and combines their quantitative results to estimate\nspecific cyberattacks costs for companies. Furthermore, RCVaR extends current\nmethods to achieve cost and risk estimations based on historical real-world\ndata instead of only probability-based simulations. The evaluation of the\napproach on unseen data shows the accuracy and efficiency of the RCVaR in\npredicting and managing cyber risks. Thus, it shows that the RCVaR is a\nvaluable addition to cybersecurity planning and risk management processes.",
        "translated": ""
    },
    {
        "title": "OUTFOX: LLM-generated Essay Detection through In-context Learning with\n  Adversarially Generated Examples",
        "url": "http://arxiv.org/abs/2307.11729v1",
        "pub_date": "2023-07-21",
        "summary": "Large Language Models (LLMs) have achieved human-level fluency in text\ngeneration, making it difficult to distinguish between human-written and\nLLM-generated texts. This poses a growing risk of misuse of LLMs and demands\nthe development of detectors to identify LLM-generated texts. However, existing\ndetectors degrade detection accuracy by simply paraphrasing LLM-generated\ntexts. Furthermore, the effectiveness of these detectors in real-life\nsituations, such as when students use LLMs for writing homework assignments\n(e.g., essays) and quickly learn how to evade these detectors, has not been\nexplored. In this paper, we propose OUTFOX, a novel framework that improves the\nrobustness of LLM-generated-text detectors by allowing both the detector and\nthe attacker to consider each other's output and apply this to the domain of\nstudent essays. In our framework, the attacker uses the detector's prediction\nlabels as examples for in-context learning and adversarially generates essays\nthat are harder to detect. While the detector uses the adversarially generated\nessays as examples for in-context learning to learn to detect essays from a\nstrong attacker. Our experiments show that our proposed detector learned\nin-context from the attacker improves the detection performance on the attacked\ndataset by up to +41.3 point F1-score. While our proposed attacker can\ndrastically degrade the performance of the detector by up to -57.0 point\nF1-score compared to the paraphrasing method.",
        "translated": ""
    },
    {
        "title": "Enhancing CLIP with GPT-4: Harnessing Visual Descriptions as Prompts",
        "url": "http://arxiv.org/abs/2307.11661v1",
        "pub_date": "2023-07-21",
        "summary": "Contrastive pretrained large Vision-Language Models (VLMs) like CLIP have\nrevolutionized visual representation learning by providing good performance on\ndownstream datasets. VLMs are 0-shot adapted to a downstream dataset by\ndesigning prompts that are relevant to the dataset. Such prompt engineering\nmakes use of domain expertise and a validation dataset. Meanwhile, recent\ndevelopments in generative pretrained models like GPT-4 mean they can be used\nas advanced internet search tools. They can also be manipulated to provide\nvisual information in any structure. In this work, we show that GPT-4 can be\nused to generate text that is visually descriptive and how this can be used to\nadapt CLIP to downstream tasks. We show considerable improvements in 0-shot\ntransfer accuracy on specialized fine-grained datasets like EuroSAT (~7%), DTD\n(~7%), SUN397 (~4.6%), and CUB (~3.3%) when compared to CLIP's default prompt.\nWe also design a simple few-shot adapter that learns to choose the best\npossible sentences to construct generalizable classifiers that outperform the\nrecently proposed CoCoOP by ~2% on average and by over 4% on 4 specialized\nfine-grained datasets. We will release the code, prompts, and auxiliary text\ndataset upon acceptance.",
        "translated": ""
    },
    {
        "title": "OxfordTVG-HIC: Can Machine Make Humorous Captions from Images?",
        "url": "http://arxiv.org/abs/2307.11636v1",
        "pub_date": "2023-07-21",
        "summary": "This paper presents OxfordTVG-HIC (Humorous Image Captions), a large-scale\ndataset for humour generation and understanding. Humour is an abstract,\nsubjective, and context-dependent cognitive construct involving several\ncognitive factors, making it a challenging task to generate and interpret.\nHence, humour generation and understanding can serve as a new task for\nevaluating the ability of deep-learning methods to process abstract and\nsubjective information. Due to the scarcity of data, humour-related generation\ntasks such as captioning remain under-explored. To address this gap,\nOxfordTVG-HIC offers approximately 2.9M image-text pairs with humour scores to\ntrain a generalizable humour captioning model. Contrary to existing captioning\ndatasets, OxfordTVG-HIC features a wide range of emotional and semantic\ndiversity resulting in out-of-context examples that are particularly conducive\nto generating humour. Moreover, OxfordTVG-HIC is curated devoid of offensive\ncontent. We also show how OxfordTVG-HIC can be leveraged for evaluating the\nhumour of a generated text. Through explainability analysis of the trained\nmodels, we identify the visual and linguistic cues influential for evoking\nhumour prediction (and generation). We observe qualitatively that these cues\nare aligned with the benign violation theory of humour in cognitive psychology.",
        "translated": ""
    },
    {
        "title": "CausE: Towards Causal Knowledge Graph Embedding",
        "url": "http://arxiv.org/abs/2307.11610v2",
        "pub_date": "2023-07-21",
        "summary": "Knowledge graph embedding (KGE) focuses on representing the entities and\nrelations of a knowledge graph (KG) into the continuous vector spaces, which\ncan be employed to predict the missing triples to achieve knowledge graph\ncompletion (KGC). However, KGE models often only briefly learn structural\ncorrelations of triple data and embeddings would be misled by the trivial\npatterns and noisy links in real-world KGs. To address this issue, we build the\nnew paradigm of KGE in the context of causality and embedding disentanglement.\nWe further propose a Causality-enhanced knowledge graph Embedding (CausE)\nframework. CausE employs causal intervention to estimate the causal effect of\nthe confounder embeddings and design new training objectives to make stable\npredictions. Experimental results demonstrate that CausE could outperform the\nbaseline models and achieve state-of-the-art KGC performance. We release our\ncode in https://github.com/zjukg/CausE.",
        "translated": ""
    },
    {
        "title": "A Change of Heart: Improving Speech Emotion Recognition through\n  Speech-to-Text Modality Conversion",
        "url": "http://arxiv.org/abs/2307.11584v1",
        "pub_date": "2023-07-21",
        "summary": "Speech Emotion Recognition (SER) is a challenging task. In this paper, we\nintroduce a modality conversion concept aimed at enhancing emotion recognition\nperformance on the MELD dataset. We assess our approach through two\nexperiments: first, a method named Modality-Conversion that employs automatic\nspeech recognition (ASR) systems, followed by a text classifier; second, we\nassume perfect ASR output and investigate the impact of modality conversion on\nSER, this method is called Modality-Conversion++. Our findings indicate that\nthe first method yields substantial results, while the second method\noutperforms state-of-the-art (SOTA) speech-based approaches in terms of SER\nweighted-F1 (WF1) score on the MELD dataset. This research highlights the\npotential of modality conversion for tasks that can be conducted in alternative\nmodalities.",
        "translated": ""
    },
    {
        "title": "Advancing Visual Grounding with Scene Knowledge: Benchmark and Method",
        "url": "http://arxiv.org/abs/2307.11558v1",
        "pub_date": "2023-07-21",
        "summary": "Visual grounding (VG) aims to establish fine-grained alignment between vision\nand language. Ideally, it can be a testbed for vision-and-language models to\nevaluate their understanding of the images and texts and their reasoning\nabilities over their joint space. However, most existing VG datasets are\nconstructed using simple description texts, which do not require sufficient\nreasoning over the images and texts. This has been demonstrated in a recent\nstudy~\\cite{luo2022goes}, where a simple LSTM-based text encoder without\npretraining can achieve state-of-the-art performance on mainstream VG datasets.\nTherefore, in this paper, we propose a novel benchmark of \\underline{S}cene\n\\underline{K}nowledge-guided \\underline{V}isual \\underline{G}rounding (SK-VG),\nwhere the image content and referring expressions are not sufficient to ground\nthe target objects, forcing the models to have a reasoning ability on the\nlong-form scene knowledge. To perform this task, we propose two approaches to\naccept the triple-type input, where the former embeds knowledge into the image\nfeatures before the image-query interaction; the latter leverages linguistic\nstructure to assist in computing the image-text matching. We conduct extensive\nexperiments to analyze the above methods and show that the proposed approaches\nachieve promising results but still leave room for improvement, including\nperformance and interpretability. The dataset and code are available at\n\\url{https://github.com/zhjohnchan/SK-VG}.",
        "translated": ""
    },
    {
        "title": "Bridging Vision and Language Encoders: Parameter-Efficient Tuning for\n  Referring Image Segmentation",
        "url": "http://arxiv.org/abs/2307.11545v1",
        "pub_date": "2023-07-21",
        "summary": "Parameter Efficient Tuning (PET) has gained attention for reducing the number\nof parameters while maintaining performance and providing better hardware\nresource savings, but few studies investigate dense prediction tasks and\ninteraction between modalities. In this paper, we do an investigation of\nefficient tuning problems on referring image segmentation. We propose a novel\nadapter called Bridger to facilitate cross-modal information exchange and\ninject task-specific information into the pre-trained model. We also design a\nlightweight decoder for image segmentation. Our approach achieves comparable or\nsuperior performance with only 1.61\\% to 3.38\\% backbone parameter updates,\nevaluated on challenging benchmarks. The code is available at\n\\url{https://github.com/kkakkkka/ETRIS}.",
        "translated": ""
    },
    {
        "title": "IndigoVX: Where Human Intelligence Meets AI for Optimal Decision Making",
        "url": "http://arxiv.org/abs/2307.11516v1",
        "pub_date": "2023-07-21",
        "summary": "This paper defines a new approach for augmenting human intelligence with AI\nfor optimal goal solving. Our proposed AI, Indigo, is an acronym for Informed\nNumerical Decision-making through Iterative Goal-Oriented optimization. When\ncombined with a human collaborator, we term the joint system IndigoVX, for\nVirtual eXpert. The system is conceptually simple. We envisage this method\nbeing applied to games or business strategies, with the human providing\nstrategic context and the AI offering optimal, data-driven moves. Indigo\noperates through an iterative feedback loop, harnessing the human expert's\ncontextual knowledge and the AI's data-driven insights to craft and refine\nstrategies towards a well-defined goal. Using a quantified three-score schema,\nthis hybridization allows the combined team to evaluate strategies and refine\ntheir plan, while adapting to challenges and changes in real-time.",
        "translated": ""
    },
    {
        "title": "Incorporating Human Translator Style into English-Turkish Literary\n  Machine Translation",
        "url": "http://arxiv.org/abs/2307.11457v1",
        "pub_date": "2023-07-21",
        "summary": "Although machine translation systems are mostly designed to serve in the\ngeneral domain, there is a growing tendency to adapt these systems to other\ndomains like literary translation. In this paper, we focus on English-Turkish\nliterary translation and develop machine translation models that take into\naccount the stylistic features of translators. We fine-tune a pre-trained\nmachine translation model by the manually-aligned works of a particular\ntranslator. We make a detailed analysis of the effects of manual and automatic\nalignments, data augmentation methods, and corpus size on the translations. We\npropose an approach based on stylistic features to evaluate the style of a\ntranslator in the output translations. We show that the human translator style\ncan be highly recreated in the target machine translations by adapting the\nmodels to the style of the translator.",
        "translated": ""
    },
    {
        "title": "Topic Identification For Spontaneous Speech: Enriching Audio Features\n  With Embedded Linguistic Information",
        "url": "http://arxiv.org/abs/2307.11450v1",
        "pub_date": "2023-07-21",
        "summary": "Traditional topic identification solutions from audio rely on an automatic\nspeech recognition system (ASR) to produce transcripts used as input to a\ntext-based model. These approaches work well in high-resource scenarios, where\nthere are sufficient data to train both components of the pipeline. However, in\nlow-resource situations, the ASR system, even if available, produces\nlow-quality transcripts, leading to a bad text-based classifier. Moreover,\nspontaneous speech containing hesitations can further degrade the performance\nof the ASR model. In this paper, we investigate alternatives to the standard\ntext-only solutions by comparing audio-only and hybrid techniques of jointly\nutilising text and audio features. The models evaluated on spontaneous Finnish\nspeech demonstrate that purely audio-based solutions are a viable option when\nASR components are not available, while the hybrid multi-modal solutions\nachieve the best results.",
        "translated": ""
    },
    {
        "title": "HeteFedRec: Federated Recommender Systems with Model Heterogeneity",
        "url": "http://arxiv.org/abs/2307.12810v1",
        "pub_date": "2023-07-24",
        "summary": "Owing to the nature of privacy protection, federated recommender systems\n(FedRecs) have garnered increasing interest in the realm of on-device\nrecommender systems. However, most existing FedRecs only allow participating\nclients to collaboratively train a recommendation model of the same public\nparameter size. Training a model of the same size for all clients can lead to\nsuboptimal performance since clients possess varying resources. For example,\nclients with limited training data may prefer to train a smaller recommendation\nmodel to avoid excessive data consumption, while clients with sufficient data\nwould benefit from a larger model to achieve higher recommendation accuracy. To\naddress the above challenge, this paper introduces HeteFedRec, a novel FedRec\nframework that enables the assignment of personalized model sizes to\nparticipants. In HeteFedRec, we present a heterogeneous recommendation model\naggregation strategy, including a unified dual-task learning mechanism and a\ndimensional decorrelation regularization, to allow knowledge aggregation among\nrecommender models of different sizes. Additionally, a relation-based ensemble\nknowledge distillation method is proposed to effectively distil knowledge from\nheterogeneous item embeddings. Extensive experiments conducted on three\nreal-world recommendation datasets demonstrate the effectiveness and efficiency\nof HeteFedRec in training federated recommender systems under heterogeneous\nsettings.",
        "translated": ""
    },
    {
        "title": "RRAML: Reinforced Retrieval Augmented Machine Learning",
        "url": "http://arxiv.org/abs/2307.12798v1",
        "pub_date": "2023-07-24",
        "summary": "The emergence of large language models (LLMs) has revolutionized machine\nlearning and related fields, showcasing remarkable abilities in comprehending,\ngenerating, and manipulating human language. However, their conventional usage\nthrough API-based text prompt submissions imposes certain limitations in terms\nof context constraints and external source availability. To address these\nchallenges, we propose a novel framework called Reinforced Retrieval Augmented\nMachine Learning (RRAML). RRAML integrates the reasoning capabilities of LLMs\nwith supporting information retrieved by a purpose-built retriever from a vast\nuser-provided database. By leveraging recent advancements in reinforcement\nlearning, our method effectively addresses several critical challenges.\nFirstly, it circumvents the need for accessing LLM gradients. Secondly, our\nmethod alleviates the burden of retraining LLMs for specific tasks, as it is\noften impractical or impossible due to restricted access to the model and the\ncomputational intensity involved. Additionally we seamlessly link the\nretriever's task with the reasoner, mitigating hallucinations and reducing\nirrelevant, and potentially damaging retrieved documents. We believe that the\nresearch agenda outlined in this paper has the potential to profoundly impact\nthe field of AI, democratizing access to and utilization of LLMs for a wide\nrange of entities.",
        "translated": ""
    },
    {
        "title": "Unbiased Delayed Feedback Label Correction for Conversion Rate\n  Prediction",
        "url": "http://arxiv.org/abs/2307.12756v1",
        "pub_date": "2023-07-24",
        "summary": "Conversion rate prediction is critical to many online applications such as\ndigital display advertising. To capture dynamic data distribution, industrial\nsystems often require retraining models on recent data daily or weekly.\nHowever, the delay of conversion behavior usually leads to incorrect labeling,\nwhich is called delayed feedback problem. Existing work may fail to introduce\nthe correct information about false negative samples due to data sparsity and\ndynamic data distribution. To directly introduce the correct feedback label\ninformation, we propose an Unbiased delayed feedback Label Correction framework\n(ULC), which uses an auxiliary model to correct labels for observed negative\nfeedback samples. Firstly, we theoretically prove that the label-corrected loss\nis an unbiased estimate of the oracle loss using true labels. Then, as there\nare no ready training data for label correction, counterfactual labeling is\nused to construct artificial training data. Furthermore, since counterfactual\nlabeling utilizes only partial training data, we design an embedding-based\nalternative training method to enhance performance. Comparative experiments on\nboth public and private datasets and detailed analyses show that our proposed\napproach effectively alleviates the delayed feedback problem and consistently\noutperforms the previous state-of-the-art methods.",
        "translated": ""
    },
    {
        "title": "Self-refining of Pseudo Labels for Music Source Separation with Noisy\n  Labeled Data",
        "url": "http://arxiv.org/abs/2307.12576v1",
        "pub_date": "2023-07-24",
        "summary": "Music source separation (MSS) faces challenges due to the limited\navailability of correctly-labeled individual instrument tracks. With the push\nto acquire larger datasets to improve MSS performance, the inevitability of\nencountering mislabeled individual instrument tracks becomes a significant\nchallenge to address. This paper introduces an automated technique for refining\nthe labels in a partially mislabeled dataset. Our proposed self-refining\ntechnique, employed with a noisy-labeled dataset, results in only a 1% accuracy\ndegradation in multi-label instrument recognition compared to a classifier\ntrained on a clean-labeled dataset. The study demonstrates the importance of\nrefining noisy-labeled data in MSS model training and shows that utilizing the\nrefined dataset leads to comparable results derived from a clean-labeled\ndataset. Notably, upon only access to a noisy dataset, MSS models trained on a\nself-refined dataset even outperform those trained on a dataset refined with a\nclassifier trained on clean labels.",
        "translated": ""
    },
    {
        "title": "FaFCNN: A General Disease Classification Framework Based on Feature\n  Fusion Neural Networks",
        "url": "http://arxiv.org/abs/2307.12518v1",
        "pub_date": "2023-07-24",
        "summary": "There are two fundamental problems in applying deep learning/machine learning\nmethods to disease classification tasks, one is the insufficient number and\npoor quality of training samples; another one is how to effectively fuse\nmultiple source features and thus train robust classification models. To\naddress these problems, inspired by the process of human learning knowledge, we\npropose the Feature-aware Fusion Correlation Neural Network (FaFCNN), which\nintroduces a feature-aware interaction module and a feature alignment module\nbased on domain adversarial learning. This is a general framework for disease\nclassification, and FaFCNN improves the way existing methods obtain sample\ncorrelation features. The experimental results show that training using\naugmented features obtained by pre-training gradient boosting decision tree\nyields more performance gains than random-forest based methods. On the\nlow-quality dataset with a large amount of missing data in our setup, FaFCNN\nobtains a consistently optimal performance compared to competitive baselines.\nIn addition, extensive experiments demonstrate the robustness of the proposed\nmethod and the effectiveness of each component of the model\\footnote{Accepted\nin IEEE SMC2023}.",
        "translated": ""
    },
    {
        "title": "3D-LLM: Injecting the 3D World into Large Language Models",
        "url": "http://arxiv.org/abs/2307.12981v1",
        "pub_date": "2023-07-24",
        "summary": "Large language models (LLMs) and Vision-Language Models (VLMs) have been\nproven to excel at multiple tasks, such as commonsense reasoning. Powerful as\nthese models can be, they are not grounded in the 3D physical world, which\ninvolves richer concepts such as spatial relationships, affordances, physics,\nlayout, and so on. In this work, we propose to inject the 3D world into large\nlanguage models and introduce a whole new family of 3D-LLMs. Specifically,\n3D-LLMs can take 3D point clouds and their features as input and perform a\ndiverse set of 3D-related tasks, including captioning, dense captioning, 3D\nquestion answering, task decomposition, 3D grounding, 3D-assisted dialog,\nnavigation, and so on. Using three types of prompting mechanisms that we\ndesign, we are able to collect over 300k 3D-language data covering these tasks.\nTo efficiently train 3D-LLMs, we first utilize a 3D feature extractor that\nobtains 3D features from rendered multi- view images. Then, we use 2D VLMs as\nour backbones to train our 3D-LLMs. By introducing a 3D localization mechanism,\n3D-LLMs can better capture 3D spatial information. Experiments on ScanQA show\nthat our model outperforms state-of-the-art baselines by a large margin (e.g.,\nthe BLEU-1 score surpasses state-of-the-art score by 9%). Furthermore,\nexperiments on our held-in datasets for 3D captioning, task composition, and\n3D-assisted dialogue show that our model outperforms 2D VLMs. Qualitative\nexamples also show that our model could perform more tasks beyond the scope of\nexisting LLMs and VLMs. Project Page: : https://vis-www.cs.umass.edu/3dllm/.",
        "translated": ""
    },
    {
        "title": "Evaluating the Ripple Effects of Knowledge Editing in Language Models",
        "url": "http://arxiv.org/abs/2307.12976v1",
        "pub_date": "2023-07-24",
        "summary": "Modern language models capture a large body of factual knowledge. However,\nsome facts can be incorrectly induced or become obsolete over time, resulting\nin factually incorrect generations. This has led to the development of various\nediting methods that allow updating facts encoded by the model. Evaluation of\nthese methods has primarily focused on testing whether an individual fact has\nbeen successfully injected, and if similar predictions for other subjects have\nnot changed. Here we argue that such evaluation is limited, since injecting one\nfact (e.g. ``Jack Depp is the son of Johnny Depp'') introduces a ``ripple\neffect'' in the form of additional facts that the model needs to update\n(e.g.``Jack Depp is the sibling of Lily-Rose Depp''). To address this issue, we\npropose a novel set of evaluation criteria that consider the implications of an\nedit on related facts. Using these criteria, we then construct \\ripple{}, a\ndiagnostic benchmark of 5K factual edits, capturing a variety of types of\nripple effects. We evaluate prominent editing methods on \\ripple{}, showing\nthat current methods fail to introduce consistent changes in the model's\nknowledge. In addition, we find that a simple in-context editing baseline\nobtains the best scores on our benchmark, suggesting a promising research\ndirection for model editing.",
        "translated": ""
    },
    {
        "title": "Leveraging Label Variation in Large Language Models for Zero-Shot Text\n  Classification",
        "url": "http://arxiv.org/abs/2307.12973v1",
        "pub_date": "2023-07-24",
        "summary": "The zero-shot learning capabilities of large language models (LLMs) make them\nideal for text classification without annotation or supervised training. Many\nstudies have shown impressive results across multiple tasks. While tasks, data,\nand results differ widely, their similarities to human annotation can aid us in\ntackling new tasks with minimal expenses. We evaluate using 5 state-of-the-art\nLLMs as \"annotators\" on 5 different tasks (age, gender, topic, sentiment\nprediction, and hate speech detection), across 4 languages: English, French,\nGerman, and Spanish. No single model excels at all tasks, across languages, or\nacross all labels within a task. However, aggregation techniques designed for\nhuman annotators perform substantially better than any one individual model.\nOverall, though, LLMs do not rival even simple supervised models, so they do\nnot (yet) replace the need for human annotation. We also discuss the tradeoffs\nbetween speed, accuracy, cost, and bias when it comes to aggregated model\nlabeling versus human annotation.",
        "translated": ""
    },
    {
        "title": "Aligning Large Language Models with Human: A Survey",
        "url": "http://arxiv.org/abs/2307.12966v1",
        "pub_date": "2023-07-24",
        "summary": "Large Language Models (LLMs) trained on extensive textual corpora have\nemerged as leading solutions for a broad array of Natural Language Processing\n(NLP) tasks. Despite their notable performance, these models are prone to\ncertain limitations such as misunderstanding human instructions, generating\npotentially biased content, or factually incorrect (hallucinated) information.\nHence, aligning LLMs with human expectations has become an active area of\ninterest within the research community. This survey presents a comprehensive\noverview of these alignment technologies, including the following aspects. (1)\nData collection: the methods for effectively collecting high-quality\ninstructions for LLM alignment, including the use of NLP benchmarks, human\nannotations, and leveraging strong LLMs. (2) Training methodologies: a detailed\nreview of the prevailing training methods employed for LLM alignment. Our\nexploration encompasses Supervised Fine-tuning, both Online and Offline human\npreference training, along with parameter-efficient training mechanisms. (3)\nModel Evaluation: the methods for evaluating the effectiveness of these\nhuman-aligned LLMs, presenting a multifaceted approach towards their\nassessment. In conclusion, we collate and distill our findings, shedding light\non several promising future research avenues in the field. This survey,\ntherefore, serves as a valuable resource for anyone invested in understanding\nand advancing the alignment of LLMs to better suit human-oriented tasks and\nexpectations. An associated GitHub link collecting the latest papers is\navailable at https://github.com/GaryYufei/AlignLLMHumanSurvey.",
        "translated": ""
    },
    {
        "title": "RLCD: Reinforcement Learning from Contrast Distillation for Language\n  Model Alignment",
        "url": "http://arxiv.org/abs/2307.12950v1",
        "pub_date": "2023-07-24",
        "summary": "We propose Reinforcement Learning from Contrast Distillation (RLCD), a method\nfor aligning language models to follow natural language principles without\nusing human feedback. RLCD trains a preference model using simulated preference\npairs that contain both a high-quality and low-quality example, generated using\ncontrasting positive and negative prompts. The preference model is then used to\nimprove a base unaligned language model via reinforcement learning.\nEmpirically, RLCD outperforms RLAIF (Bai et al., 2022b) and context\ndistillation (Huang et al., 2022) baselines across three diverse alignment\ntasks--harmlessness, helpfulness, and story outline generation--and on both 7B\nand 30B model scales for preference data simulation.",
        "translated": ""
    },
    {
        "title": "Boosting Punctuation Restoration with Data Generation and Reinforcement\n  Learning",
        "url": "http://arxiv.org/abs/2307.12949v1",
        "pub_date": "2023-07-24",
        "summary": "Punctuation restoration is an important task in automatic speech recognition\n(ASR) which aim to restore the syntactic structure of generated ASR texts to\nimprove readability. While punctuated texts are abundant from written\ndocuments, the discrepancy between written punctuated texts and ASR texts\nlimits the usability of written texts in training punctuation restoration\nsystems for ASR texts. This paper proposes a reinforcement learning method to\nexploit in-topic written texts and recent advances in large pre-trained\ngenerative language models to bridge this gap. The experiments show that our\nmethod achieves state-of-the-art performance on the ASR test set on two\nbenchmark datasets for punctuation restoration.",
        "translated": ""
    },
    {
        "title": "Rule By Example: Harnessing Logical Rules for Explainable Hate Speech\n  Detection",
        "url": "http://arxiv.org/abs/2307.12935v1",
        "pub_date": "2023-07-24",
        "summary": "Classic approaches to content moderation typically apply a rule-based\nheuristic approach to flag content. While rules are easily customizable and\nintuitive for humans to interpret, they are inherently fragile and lack the\nflexibility or robustness needed to moderate the vast amount of undesirable\ncontent found online today. Recent advances in deep learning have demonstrated\nthe promise of using highly effective deep neural models to overcome these\nchallenges. However, despite the improved performance, these data-driven models\nlack transparency and explainability, often leading to mistrust from everyday\nusers and a lack of adoption by many platforms. In this paper, we present Rule\nBy Example (RBE): a novel exemplar-based contrastive learning approach for\nlearning from logical rules for the task of textual content moderation. RBE is\ncapable of providing rule-grounded predictions, allowing for more explainable\nand customizable predictions compared to typical deep learning-based\napproaches. We demonstrate that our approach is capable of learning rich rule\nembedding representations using only a few data examples. Experimental results\non 3 popular hate speech classification datasets show that RBE is able to\noutperform state-of-the-art deep learning classifiers as well as the use of\nrules in both supervised and unsupervised settings while providing explainable\nmodel predictions via rule-grounding.",
        "translated": ""
    },
    {
        "title": "Corrections of Zipf's and Heaps' Laws Derived from Hapax Rate Models",
        "url": "http://arxiv.org/abs/2307.12896v1",
        "pub_date": "2023-07-24",
        "summary": "The article introduces corrections to Zipf's and Heaps' laws based on\nsystematic models of the hapax rate. The derivation rests on two assumptions:\nThe first one is the standard urn model which predicts that marginal frequency\ndistributions for shorter texts look as if word tokens were sampled blindly\nfrom a given longer text. The second assumption posits that the rate of hapaxes\nis a simple function of the text size. Four such functions are discussed: the\nconstant model, the Davis model, the linear model, and the logistic model. It\nis shown that the logistic model yields the best fit.",
        "translated": ""
    },
    {
        "title": "A Real-World WebAgent with Planning, Long Context Understanding, and\n  Program Synthesis",
        "url": "http://arxiv.org/abs/2307.12856v1",
        "pub_date": "2023-07-24",
        "summary": "Pre-trained large language models (LLMs) have recently achieved better\ngeneralization and sample efficiency in autonomous web navigation. However, the\nperformance on real-world websites has still suffered from (1) open domainness,\n(2) limited context length, and (3) lack of inductive bias on HTML. We\nintroduce WebAgent, an LLM-driven agent that can complete the tasks on real\nwebsites following natural language instructions. WebAgent plans ahead by\ndecomposing instructions into canonical sub-instructions, summarizes long HTML\ndocuments into task-relevant snippets, and acts on websites via generated\nPython programs from those. We design WebAgent with Flan-U-PaLM, for grounded\ncode generation, and HTML-T5, new pre-trained LLMs for long HTML documents\nusing local and global attention mechanisms and a mixture of long-span\ndenoising objectives, for planning and summarization. We empirically\ndemonstrate that our recipe improves the success on a real website by over 50%,\nand that HTML-T5 is the best model to solve HTML-based tasks; achieving 14.9%\nhigher success rate than prior SoTA on the MiniWoB web navigation benchmark and\nbetter accuracy on offline task planning evaluation.",
        "translated": ""
    },
    {
        "title": "Joint Dropout: Improving Generalizability in Low-Resource Neural Machine\n  Translation through Phrase Pair Variables",
        "url": "http://arxiv.org/abs/2307.12835v1",
        "pub_date": "2023-07-24",
        "summary": "Despite the tremendous success of Neural Machine Translation (NMT), its\nperformance on low-resource language pairs still remains subpar, partly due to\nthe limited ability to handle previously unseen inputs, i.e., generalization.\nIn this paper, we propose a method called Joint Dropout, that addresses the\nchallenge of low-resource neural machine translation by substituting phrases\nwith variables, resulting in significant enhancement of compositionality, which\nis a key aspect of generalization. We observe a substantial improvement in\ntranslation quality for language pairs with minimal resources, as seen in BLEU\nand Direct Assessment scores. Furthermore, we conduct an error analysis, and\nfind Joint Dropout to also enhance generalizability of low-resource NMT in\nterms of robustness and adaptability across different domains",
        "translated": ""
    },
    {
        "title": "Mitigating Mainstream Bias in Recommendation via Cost-sensitive Learning",
        "url": "http://arxiv.org/abs/2307.13632v1",
        "pub_date": "2023-07-25",
        "summary": "Mainstream bias, where some users receive poor recommendations because their\npreferences are uncommon or simply because they are less active, is an\nimportant aspect to consider regarding fairness in recommender systems.\nExisting methods to mitigate mainstream bias do not explicitly model the\nimportance of these non-mainstream users or, when they do, it is in a way that\nis not necessarily compatible with the data and recommendation model at hand.\nIn contrast, we use the recommendation utility as a more generic and implicit\nproxy to quantify mainstreamness, and propose a simple user-weighting approach\nto incorporate it into the training process while taking the cost of potential\nrecommendation errors into account. We provide extensive experimental results\nshowing that quantifying mainstreamness via utility is better able at\nidentifying non-mainstream users, and that they are indeed better served when\ntraining the model in a cost-sensitive way. This is achieved with negligible or\nno loss in overall recommendation accuracy, meaning that the models learn a\nbetter balance across users. In addition, we show that research of this kind,\nwhich evaluates recommendation quality at the individual user level, may not be\nreliable if not using enough interactions when assessing model performance.",
        "translated": ""
    },
    {
        "title": "Gaussian Graph with Prototypical Contrastive Learning in E-Commerce\n  Bundle Recommendation",
        "url": "http://arxiv.org/abs/2307.13468v1",
        "pub_date": "2023-07-25",
        "summary": "Bundle recommendation aims to provide a bundle of items to satisfy the user\npreference on e-commerce platform. Existing successful solutions are based on\nthe contrastive graph learning paradigm where graph neural networks (GNNs) are\nemployed to learn representations from user-level and bundle-level graph views\nwith a contrastive learning module to enhance the cooperative association\nbetween different views. Nevertheless, they ignore the uncertainty issue which\nhas a significant impact in real bundle recommendation scenarios due to the\nlack of discriminative information caused by highly sparsity or diversity. We\nfurther suggest that their instancewise contrastive learning fails to\ndistinguish the semantically similar negatives (i.e., sampling bias issue),\nresulting in performance degradation. In this paper, we propose a novel\nGaussian Graph with Prototypical Contrastive Learning (GPCL) framework to\novercome these challenges. In particular, GPCL embeds each user/bundle/item as\na Gaussian distribution rather than a fixed vector. We further design a\nprototypical contrastive learning module to capture the contextual information\nand mitigate the sampling bias issue. Extensive experiments demonstrate that\nbenefiting from the proposed components, we achieve new state-of-the-art\nperformance compared to previous methods on several public datasets. Moreover,\nGPCL has been deployed on real-world e-commerce platform and achieved\nsubstantial improvements.",
        "translated": ""
    },
    {
        "title": "Comprehensive Review on Semantic Information Retrieval and Ontology\n  Engineering",
        "url": "http://arxiv.org/abs/2307.13427v1",
        "pub_date": "2023-07-25",
        "summary": "Situation awareness is a crucial cognitive skill that enables individuals to\nperceive, comprehend, and project the current state of their environment\naccurately. It involves being conscious of relevant information, understanding\nits meaning, and using that understanding to make well-informed decisions.\nAwareness systems often need to integrate new knowledge and adapt to changing\nenvironments. Ontology reasoning facilitates knowledge integration and\nevolution, allowing for seamless updates and expansions of the ontology. With\nthe consideration of above, we are providing a quick review on semantic\ninformation retrieval and ontology engineering to understand the emerging\nchallenges and future research. In the review we have found that the ontology\nreasoning addresses the limitations of traditional systems by providing a\nformal, flexible, and scalable framework for knowledge representation,\nreasoning, and inference.",
        "translated": ""
    },
    {
        "title": "An End-to-End Workflow using Topic Segmentation and Text Summarisation\n  Methods for Improved Podcast Comprehension",
        "url": "http://arxiv.org/abs/2307.13394v1",
        "pub_date": "2023-07-25",
        "summary": "The consumption of podcast media has been increasing rapidly. Due to the\nlengthy nature of podcast episodes, users often carefully select which ones to\nlisten to. Although episode descriptions aid users by providing a summary of\nthe entire podcast, they do not provide a topic-by-topic breakdown. This study\nexplores the combined application of topic segmentation and text summarisation\nmethods to investigate how podcast episode comprehension can be improved. We\nhave sampled 10 episodes from Spotify's English-Language Podcast Dataset and\nemployed TextTiling and TextSplit to segment them. Moreover, three text\nsummarisation models, namely T5, BART, and Pegasus, were applied to provide a\nvery short title for each segment. The segmentation part was evaluated using\nour annotated sample with the $P_k$ and WindowDiff ($WD$) metrics. A survey was\nalso rolled out ($N=25$) to assess the quality of the generated summaries. The\nTextSplit algorithm achieved the lowest mean for both evaluation metrics\n($\\bar{P_k}=0.41$ and $\\bar{WD}=0.41$), while the T5 model produced the best\nsummaries, achieving a relevancy score only $8\\%$ less to the one achieved by\nthe human-written titles.",
        "translated": ""
    },
    {
        "title": "Embedding Models for Supervised Automatic Extraction and Classification\n  of Named Entities in Scientific Acknowledgements",
        "url": "http://arxiv.org/abs/2307.13377v1",
        "pub_date": "2023-07-25",
        "summary": "Acknowledgments in scientific papers may give an insight into aspects of the\nscientific community, such as reward systems, collaboration patterns, and\nhidden research trends. The aim of the paper is to evaluate the performance of\ndifferent embedding models for the task of automatic extraction and\nclassification of acknowledged entities from the acknowledgment text in\nscientific papers. We trained and implemented a named entity recognition (NER)\ntask using the Flair NLP framework. The training was conducted using three\ndefault Flair NER models with four differently-sized corpora and different\nversions of the Flair NLP framework. The Flair Embeddings model trained on the\nmedium corpus with the latest FLAIR version showed the best accuracy of 0.79.\nExpanding the size of a training corpus from very small to medium size\nmassively increased the accuracy of all training algorithms, but further\nexpansion of the training corpus did not bring further improvement. Moreover,\nthe performance of the model slightly deteriorated. Our model is able to\nrecognize six entity types: funding agency, grant number, individuals,\nuniversity, corporation, and miscellaneous. The model works more precisely for\nsome entity types than for others; thus, individuals and grant numbers showed a\nvery good F1-Score over 0.9. Most of the previous works on acknowledgment\nanalysis were limited by the manual evaluation of data and therefore by the\namount of processed data. This model can be applied for the comprehensive\nanalysis of acknowledgment texts and may potentially make a great contribution\nto the field of automated acknowledgment analysis.",
        "translated": ""
    },
    {
        "title": "Evaluating Large Language Models for Radiology Natural Language\n  Processing",
        "url": "http://arxiv.org/abs/2307.13693v1",
        "pub_date": "2023-07-25",
        "summary": "The rise of large language models (LLMs) has marked a pivotal shift in the\nfield of natural language processing (NLP). LLMs have revolutionized a\nmultitude of domains, and they have made a significant impact in the medical\nfield. Large language models are now more abundant than ever, and many of these\nmodels exhibit bilingual capabilities, proficient in both English and Chinese.\nHowever, a comprehensive evaluation of these models remains to be conducted.\nThis lack of assessment is especially apparent within the context of radiology\nNLP. This study seeks to bridge this gap by critically evaluating thirty two\nLLMs in interpreting radiology reports, a crucial component of radiology NLP.\nSpecifically, the ability to derive impressions from radiologic findings is\nassessed. The outcomes of this evaluation provide key insights into the\nperformance, strengths, and weaknesses of these LLMs, informing their practical\napplications within the medical domain.",
        "translated": ""
    },
    {
        "title": "ARB: Advanced Reasoning Benchmark for Large Language Models",
        "url": "http://arxiv.org/abs/2307.13692v1",
        "pub_date": "2023-07-25",
        "summary": "Large Language Models (LLMs) have demonstrated remarkable performance on\nvarious quantitative reasoning and knowledge benchmarks. However, many of these\nbenchmarks are losing utility as LLMs get increasingly high scores, despite not\nyet reaching expert performance in these domains. We introduce ARB, a novel\nbenchmark composed of advanced reasoning problems in multiple fields. ARB\npresents a more challenging test than prior benchmarks, featuring problems in\nmathematics, physics, biology, chemistry, and law. As a subset of ARB, we\nintroduce a challenging set of math and physics problems which require advanced\nsymbolic reasoning and domain knowledge. We evaluate recent models such as\nGPT-4 and Claude on ARB and demonstrate that current models score well below\n50% on more demanding tasks. In order to improve both automatic and assisted\nevaluation capabilities, we introduce a rubric-based evaluation approach,\nallowing GPT-4 to score its own intermediate reasoning steps. Further, we\nconduct a human evaluation of the symbolic subset of ARB, finding promising\nagreement between annotators and GPT-4 rubric evaluation scores.",
        "translated": ""
    },
    {
        "title": "A Comprehensive Evaluation and Analysis Study for Chinese Spelling Check",
        "url": "http://arxiv.org/abs/2307.13655v1",
        "pub_date": "2023-07-25",
        "summary": "With the development of pre-trained models and the incorporation of phonetic\nand graphic information, neural models have achieved high scores in Chinese\nSpelling Check (CSC). However, it does not provide a comprehensive reflection\nof the models' capability due to the limited test sets. In this study, we\nabstract the representative model paradigm, implement it with nine structures\nand experiment them on comprehensive test sets we constructed with different\npurposes. We perform a detailed analysis of the results and find that: 1)\nFusing phonetic and graphic information reasonably is effective for CSC. 2)\nModels are sensitive to the error distribution of the test set, which reflects\nthe shortcomings of models and reveals the direction we should work on. 3)\nWhether or not the errors and contexts have been seen has a significant impact\non models. 4) The commonly used benchmark, SIGHAN, can not reliably evaluate\nmodels' performance.",
        "translated": ""
    },
    {
        "title": "Contributions to the Improvement of Question Answering Systems in the\n  Biomedical Domain",
        "url": "http://arxiv.org/abs/2307.13631v1",
        "pub_date": "2023-07-25",
        "summary": "This thesis work falls within the framework of question answering (QA) in the\nbiomedical domain where several specific challenges are addressed, such as\nspecialized lexicons and terminologies, the types of treated questions, and the\ncharacteristics of targeted documents. We are particularly interested in\nstudying and improving methods that aim at finding accurate and short answers\nto biomedical natural language questions from a large scale of biomedical\ntextual documents in English. QA aims at providing inquirers with direct, short\nand precise answers to their natural language questions. In this Ph.D. thesis,\nwe propose four contributions to improve the performance of QA in the\nbiomedical domain. In our first contribution, we propose a machine\nlearning-based method for question type classification to determine the types\nof given questions which enable to a biomedical QA system to use the\nappropriate answer extraction method. We also propose an another machine\nlearning-based method to assign one or more topics (e.g., pharmacological,\ntest, treatment, etc.) to given questions in order to determine the semantic\ntypes of the expected answers which are very useful in generating specific\nanswer retrieval strategies. In the second contribution, we first propose a\ndocument retrieval method to retrieve a set of relevant documents that are\nlikely to contain the answers to biomedical questions from the MEDLINE\ndatabase. We then present a passage retrieval method to retrieve a set of\nrelevant passages to questions. In the third contribution, we propose specific\nanswer extraction methods to generate both exact and ideal answers. Finally, in\nthe fourth contribution, we develop a fully automated semantic biomedical QA\nsystem called SemBioNLQA which is able to deal with a variety of natural\nlanguage questions and to generate appropriate answers by providing both exact\nand ideal answers.",
        "translated": ""
    },
    {
        "title": "GPT-3 Models are Few-Shot Financial Reasoners",
        "url": "http://arxiv.org/abs/2307.13617v1",
        "pub_date": "2023-07-25",
        "summary": "Financial analysis is an important tool for evaluating company performance.\nPractitioners work to answer financial questions to make profitable investment\ndecisions, and use advanced quantitative analyses to do so. As a result,\nFinancial Question Answering (QA) is a question answering task that requires\ndeep reasoning about numbers. Furthermore, it is unknown how well pre-trained\nlanguage models can reason in the financial domain. The current\nstate-of-the-art requires a retriever to collect relevant facts about the\nfinancial question from the text and a generator to produce a valid financial\nprogram and a final answer. However, recently large language models like GPT-3\nhave achieved state-of-the-art performance on wide variety of tasks with just a\nfew shot examples. We run several experiments with GPT-3 and find that a\nseparate retrieval model and logic engine continue to be essential components\nto achieving SOTA performance in this task, particularly due to the precise\nnature of financial questions and the complex information stored in financial\ndocuments. With this understanding, our refined prompt-engineering approach on\nGPT-3 achieves near SOTA accuracy without any fine-tuning.",
        "translated": ""
    },
    {
        "title": "XDLM: Cross-lingual Diffusion Language Model for Machine Translation",
        "url": "http://arxiv.org/abs/2307.13560v1",
        "pub_date": "2023-07-25",
        "summary": "Recently, diffusion models have excelled in image generation tasks and have\nalso been applied to neural language processing (NLP) for controllable text\ngeneration. However, the application of diffusion models in a cross-lingual\nsetting is less unexplored. Additionally, while pretraining with diffusion\nmodels has been studied within a single language, the potential of\ncross-lingual pretraining remains understudied. To address these gaps, we\npropose XDLM, a novel Cross-lingual diffusion model for machine translation,\nconsisting of pretraining and fine-tuning stages. In the pretraining stage, we\npropose TLDM, a new training objective for mastering the mapping between\ndifferent languages; in the fine-tuning stage, we build up the translation\nsystem based on the pretrained model. We evaluate the result on several machine\ntranslation benchmarks and outperformed both diffusion and Transformer\nbaselines.",
        "translated": ""
    },
    {
        "title": "FacTool: Factuality Detection in Generative AI -- A Tool Augmented\n  Framework for Multi-Task and Multi-Domain Scenarios",
        "url": "http://arxiv.org/abs/2307.13528v1",
        "pub_date": "2023-07-25",
        "summary": "The emergence of generative pre-trained models has facilitated the synthesis\nof high-quality text, but it has also posed challenges in identifying factual\nerrors in the generated text. In particular: (1) A wider range of tasks now\nface an increasing risk of containing factual errors when handled by generative\nmodels. (2) Generated texts tend to be lengthy and lack a clearly defined\ngranularity for individual facts. (3) There is a scarcity of explicit evidence\navailable during the process of fact checking. With the above challenges in\nmind, in this paper, we propose FacTool, a task and domain agnostic framework\nfor detecting factual errors of texts generated by large language models (e.g.,\nChatGPT). Experiments on four different tasks (knowledge-based QA, code\ngeneration, mathematical reasoning, and scientific literature review) show the\nefficacy of the proposed method.",
        "translated": ""
    },
    {
        "title": "Zshot: An Open-source Framework for Zero-Shot Named Entity Recognition\n  and Relation Extraction",
        "url": "http://arxiv.org/abs/2307.13497v1",
        "pub_date": "2023-07-25",
        "summary": "The Zero-Shot Learning (ZSL) task pertains to the identification of entities\nor relations in texts that were not seen during training. ZSL has emerged as a\ncritical research area due to the scarcity of labeled data in specific domains,\nand its applications have grown significantly in recent years. With the advent\nof large pretrained language models, several novel methods have been proposed,\nresulting in substantial improvements in ZSL performance. There is a growing\ndemand, both in the research community and industry, for a comprehensive ZSL\nframework that facilitates the development and accessibility of the latest\nmethods and pretrained models.In this study, we propose a novel ZSL framework\ncalled Zshot that aims to address the aforementioned challenges. Our primary\nobjective is to provide a platform that allows researchers to compare different\nstate-of-the-art ZSL methods with standard benchmark datasets. Additionally, we\nhave designed our framework to support the industry with readily available APIs\nfor production under the standard SpaCy NLP pipeline. Our API is extendible and\nevaluable, moreover, we include numerous enhancements such as boosting the\naccuracy with pipeline ensembling and visualization utilities available as a\nSpaCy extension.",
        "translated": ""
    },
    {
        "title": "Holistic Exploration on Universal Decompositional Semantic Parsing:\n  Architecture, Data Augmentation, and LLM Paradigm",
        "url": "http://arxiv.org/abs/2307.13424v1",
        "pub_date": "2023-07-25",
        "summary": "In this paper, we conduct a holistic exploration of the Universal\nDecompositional Semantic (UDS) Parsing. We first introduce a cascade model for\nUDS parsing that decomposes the complex parsing task into semantically\nappropriate subtasks. Our approach outperforms the prior models, while\nsignificantly reducing inference time. We also incorporate syntactic\ninformation and further optimized the architecture. Besides, different ways for\ndata augmentation are explored, which further improve the UDS Parsing. Lastly,\nwe conduct experiments to investigate the efficacy of ChatGPT in handling the\nUDS task, revealing that it excels in attribute parsing but struggles in\nrelation parsing, and using ChatGPT for data augmentation yields suboptimal\nresults. Our code is available at https://github.com/hexuandeng/HExp4UDS.",
        "translated": ""
    },
    {
        "title": "Towards Resolving Word Ambiguity with Word Embeddings",
        "url": "http://arxiv.org/abs/2307.13417v1",
        "pub_date": "2023-07-25",
        "summary": "Ambiguity is ubiquitous in natural language. Resolving ambiguous meanings is\nespecially important in information retrieval tasks. While word embeddings\ncarry semantic information, they fail to handle ambiguity well. Transformer\nmodels have been shown to handle word ambiguity for complex queries, but they\ncannot be used to identify ambiguous words, e.g. for a 1-word query.\nFurthermore, training these models is costly in terms of time, hardware\nresources, and training data, prohibiting their use in specialized environments\nwith sensitive data. Word embeddings can be trained using moderate hardware\nresources. This paper shows that applying DBSCAN clustering to the latent space\ncan identify ambiguous words and evaluate their level of ambiguity. An\nautomatic DBSCAN parameter selection leads to high-quality clusters, which are\nsemantically coherent and correspond well to the perceived meanings of a given\nword.",
        "translated": ""
    },
    {
        "title": "ChatGPT and Persuasive Technologies for the Management and Delivery of\n  Personalized Recommendations in Hotel Hospitality",
        "url": "http://arxiv.org/abs/2307.14298v1",
        "pub_date": "2023-07-26",
        "summary": "Recommender systems have become indispensable tools in the hotel hospitality\nindustry, enabling personalized and tailored experiences for guests. Recent\nadvancements in large language models (LLMs), such as ChatGPT, and persuasive\ntechnologies, have opened new avenues for enhancing the effectiveness of those\nsystems. This paper explores the potential of integrating ChatGPT and\npersuasive technologies for automating and improving hotel hospitality\nrecommender systems. First, we delve into the capabilities of ChatGPT, which\ncan understand and generate human-like text, enabling more accurate and\ncontext-aware recommendations. We discuss the integration of ChatGPT into\nrecommender systems, highlighting the ability to analyze user preferences,\nextract valuable insights from online reviews, and generate personalized\nrecommendations based on guest profiles. Second, we investigate the role of\npersuasive technology in influencing user behavior and enhancing the persuasive\nimpact of hotel recommendations. By incorporating persuasive techniques, such\nas social proof, scarcity and personalization, recommender systems can\neffectively influence user decision-making and encourage desired actions, such\nas booking a specific hotel or upgrading their room. To investigate the\nefficacy of ChatGPT and persuasive technologies, we present a pilot experi-ment\nwith a case study involving a hotel recommender system. We aim to study the\nimpact of integrating ChatGPT and persua-sive techniques on user engagement,\nsatisfaction, and conversion rates. The preliminary results demonstrate the\npotential of these technologies in enhancing the overall guest experience and\nbusiness performance. Overall, this paper contributes to the field of hotel\nhospitality by exploring the synergistic relationship between LLMs and\npersuasive technology in recommender systems, ultimately influencing guest\nsatisfaction and hotel revenue.",
        "translated": ""
    },
    {
        "title": "Large Language Models are Competitive Near Cold-start Recommenders for\n  Language- and Item-based Preferences",
        "url": "http://arxiv.org/abs/2307.14225v1",
        "pub_date": "2023-07-26",
        "summary": "Traditional recommender systems leverage users' item preference history to\nrecommend novel content that users may like. However, modern dialog interfaces\nthat allow users to express language-based preferences offer a fundamentally\ndifferent modality for preference input. Inspired by recent successes of\nprompting paradigms for large language models (LLMs), we study their use for\nmaking recommendations from both item-based and language-based preferences in\ncomparison to state-of-the-art item-based collaborative filtering (CF) methods.\nTo support this investigation, we collect a new dataset consisting of both\nitem-based and language-based preferences elicited from users along with their\nratings on a variety of (biased) recommended items and (unbiased) random items.\nAmong numerous experimental results, we find that LLMs provide competitive\nrecommendation performance for pure language-based preferences (no item\npreferences) in the near cold-start case in comparison to item-based CF\nmethods, despite having no supervised training for this specific task\n(zero-shot) or only a few labels (few-shot). This is particularly promising as\nlanguage-based preference representations are more explainable and scrutable\nthan item-based or vector-based representations.",
        "translated": ""
    },
    {
        "title": "A Probabilistic Position Bias Model for Short-Video Recommendation Feeds",
        "url": "http://arxiv.org/abs/2307.14059v1",
        "pub_date": "2023-07-26",
        "summary": "Modern web-based platforms show ranked lists of recommendations to users,\nattempting to maximise user satisfaction or business metrics. Typically, the\ngoal of such systems boils down to maximising the exposure probability for\nitems that are deemed \"reward-maximising\" according to a metric of interest.\nThis general framing comprises streaming applications, as well as e-commerce or\njob recommendations, and even web search. Position bias or user models can be\nused to estimate exposure probabilities for each use-case, specifically\ntailored to how users interact with the presented rankings. A unifying factor\nin these diverse problem settings is that typically only one or several items\nwill be engaged with (clicked, streamed,...) before a user leaves the ranked\nlist. Short-video feeds on social media platforms diverge from this general\nframing in several ways, most notably that users do not tend to leave the feed\nafter e.g. liking a post. Indeed, seemingly infinite feeds invite users to\nscroll further down the ranked list. For this reason, existing position bias or\nuser models tend to fall short in such settings, as they do not accurately\ncapture users' interaction modalities.\n  In this work, we propose a novel and probabilistically sound personalised\nposition bias model for feed recommendations. We focus on a 1st-level feed in a\nhierarchical structure, where users may enter a 2nd-level feed via any given\n1st-level item. We posit that users come to the platform with a scrolling\nbudget drawn according to some distribution, and show how the survival function\nof said distribution can be used to obtain closed-form estimates for\npersonalised exposure probabilities. Empirical insights from a large-scale\nsocial media platform show how our probabilistic position bias model more\naccurately captures empirical exposure than existing models, and paves the way\nfor unbiased evaluation and learning-to-rank.",
        "translated": ""
    },
    {
        "title": "Multi-view Hypergraph Contrastive Policy Learning for Conversational\n  Recommendation",
        "url": "http://arxiv.org/abs/2307.14024v1",
        "pub_date": "2023-07-26",
        "summary": "Conversational recommendation systems (CRS) aim to interactively acquire user\npreferences and accordingly recommend items to users. Accurately learning the\ndynamic user preferences is of crucial importance for CRS. Previous works learn\nthe user preferences with pairwise relations from the interactive conversation\nand item knowledge, while largely ignoring the fact that factors for a\nrelationship in CRS are multiplex. Specifically, the user likes/dislikes the\nitems that satisfy some attributes (Like/Dislike view). Moreover social\ninfluence is another important factor that affects user preference towards the\nitem (Social view), while is largely ignored by previous works in CRS. The user\npreferences from these three views are inherently different but also correlated\nas a whole. The user preferences from the same views should be more similar\nthan that from different views. The user preferences from Like View should be\nsimilar to Social View while different from Dislike View. To this end, we\npropose a novel model, namely Multi-view Hypergraph Contrastive Policy Learning\n(MHCPL). Specifically, MHCPL timely chooses useful social information according\nto the interactive history and builds a dynamic hypergraph with three types of\nmultiplex relations from different views. The multiplex relations in each view\nare successively connected according to their generation order.",
        "translated": ""
    },
    {
        "title": "Domain Disentanglement with Interpolative Data Augmentation for\n  Dual-Target Cross-Domain Recommendation",
        "url": "http://arxiv.org/abs/2307.13910v1",
        "pub_date": "2023-07-26",
        "summary": "The conventional single-target Cross-Domain Recommendation (CDR) aims to\nimprove the recommendation performance on a sparser target domain by\ntransferring the knowledge from a source domain that contains relatively richer\ninformation. By contrast, in recent years, dual-target CDR has been proposed to\nimprove the recommendation performance on both domains simultaneously. However,\nto this end, there are two challenges in dual-target CDR: (1) how to generate\nboth relevant and diverse augmented user representations, and (2) how to\neffectively decouple domain-independent information from domain-specific\ninformation, in addition to domain-shared information, to capture comprehensive\nuser preferences. To address the above two challenges, we propose a\nDisentanglement-based framework with Interpolative Data Augmentation for\ndual-target Cross-Domain Recommendation, called DIDA-CDR. In DIDA-CDR, we first\npropose an interpolative data augmentation approach to generating both relevant\nand diverse augmented user representations to augment sparser domain and\nexplore potential user preferences. We then propose a disentanglement module to\neffectively decouple domain-specific and domain-independent information to\ncapture comprehensive user preferences. Both steps significantly contribute to\ncapturing more comprehensive user preferences, thereby improving the\nrecommendation performance on each domain. Extensive experiments conducted on\nfive real-world datasets show the significant superiority of DIDA-CDR over the\nstate-of-the-art methods.",
        "translated": ""
    },
    {
        "title": "Towards Generalist Biomedical AI",
        "url": "http://arxiv.org/abs/2307.14334v1",
        "pub_date": "2023-07-26",
        "summary": "Medicine is inherently multimodal, with rich data modalities spanning text,\nimaging, genomics, and more. Generalist biomedical artificial intelligence (AI)\nsystems that flexibly encode, integrate, and interpret this data at scale can\npotentially enable impactful applications ranging from scientific discovery to\ncare delivery. To enable the development of these models, we first curate\nMultiMedBench, a new multimodal biomedical benchmark. MultiMedBench encompasses\n14 diverse tasks such as medical question answering, mammography and\ndermatology image interpretation, radiology report generation and\nsummarization, and genomic variant calling. We then introduce Med-PaLM\nMultimodal (Med-PaLM M), our proof of concept for a generalist biomedical AI\nsystem. Med-PaLM M is a large multimodal generative model that flexibly encodes\nand interprets biomedical data including clinical language, imaging, and\ngenomics with the same set of model weights. Med-PaLM M reaches performance\ncompetitive with or exceeding the state of the art on all MultiMedBench tasks,\noften surpassing specialist models by a wide margin. We also report examples of\nzero-shot generalization to novel medical concepts and tasks, positive transfer\nlearning across tasks, and emergent zero-shot medical reasoning. To further\nprobe the capabilities and limitations of Med-PaLM M, we conduct a radiologist\nevaluation of model-generated (and human) chest X-ray reports and observe\nencouraging performance across model scales. In a side-by-side ranking on 246\nretrospective chest X-rays, clinicians express a pairwise preference for\nMed-PaLM M reports over those produced by radiologists in up to 40.50% of\ncases, suggesting potential clinical utility. While considerable work is needed\nto validate these models in real-world use cases, our results represent a\nmilestone towards the development of generalist biomedical AI systems.",
        "translated": ""
    },
    {
        "title": "Evaluating the Moral Beliefs Encoded in LLMs",
        "url": "http://arxiv.org/abs/2307.14324v1",
        "pub_date": "2023-07-26",
        "summary": "This paper presents a case study on the design, administration,\npost-processing, and evaluation of surveys on large language models (LLMs). It\ncomprises two components: (1) A statistical method for eliciting beliefs\nencoded in LLMs. We introduce statistical measures and evaluation metrics that\nquantify the probability of an LLM \"making a choice\", the associated\nuncertainty, and the consistency of that choice. (2) We apply this method to\nstudy what moral beliefs are encoded in different LLMs, especially in ambiguous\ncases where the right choice is not obvious. We design a large-scale survey\ncomprising 680 high-ambiguity moral scenarios (e.g., \"Should I tell a white\nlie?\") and 687 low-ambiguity moral scenarios (e.g., \"Should I stop for a\npedestrian on the road?\"). Each scenario includes a description, two possible\nactions, and auxiliary labels indicating violated rules (e.g., \"do not kill\").\nWe administer the survey to 28 open- and closed-source LLMs. We find that (a)\nin unambiguous scenarios, most models \"choose\" actions that align with\ncommonsense. In ambiguous cases, most models express uncertainty. (b) Some\nmodels are uncertain about choosing the commonsense action because their\nresponses are sensitive to the question-wording. (c) Some models reflect clear\npreferences in ambiguous scenarios. Specifically, closed-source models tend to\nagree with each other.",
        "translated": ""
    },
    {
        "title": "Comparative Analysis of Libraries for the Sentimental Analysis",
        "url": "http://arxiv.org/abs/2307.14311v1",
        "pub_date": "2023-07-26",
        "summary": "This study is main goal is to provide a comparative comparison of libraries\nusing machine learning methods. Experts in natural language processing (NLP)\nare becoming more and more interested in sentiment analysis (SA) of text\nchanges. The objective of employing NLP text analysis techniques is to\nrecognize and categorize feelings related to twitter users utterances. In this\nexamination, issues with SA and the libraries utilized are also looked at.\nprovides a number of cooperative methods to classify emotional polarity. The\nNaive Bayes Classifier, Decision Tree Classifier, Maxent Classifier, Sklearn\nClassifier, Sklearn Classifier MultinomialNB, and other conjoint learning\nalgorithms, according to recent research, are very effective. In the project\nwill use Five Python and R libraries NLTK, TextBlob, Vader, Transformers (GPT\nand BERT pretrained), and Tidytext will be used in the study to apply sentiment\nanalysis techniques. Four machine learning models Tree of Decisions (DT),\nSupport Vector Machine (SVM), Naive Bayes (NB), and K-Nearest Neighbor (KNN)\nwill also be used. To evaluate how well libraries for SA operate in the social\nnetwork environment, comparative study was also carried out. The measures to\nassess the best algorithms in this experiment, which used a single data set for\neach method, were precision, recall, and F1 score. We conclude that the BERT\ntransformer method with an Accuracy: 0.973 is recommended for sentiment\nanalysis.",
        "translated": ""
    },
    {
        "title": "Automatically Evaluating Opinion Prevalence in Opinion Summarization",
        "url": "http://arxiv.org/abs/2307.14305v1",
        "pub_date": "2023-07-26",
        "summary": "When faced with a large number of product reviews, it is not clear that a\nhuman can remember all of them and weight opinions representatively to write a\ngood reference summary. We propose an automatic metric to test the prevalence\nof the opinions that a summary expresses, based on counting the number of\nreviews that are consistent with each statement in the summary, while\ndiscrediting trivial or redundant statements. To formulate this opinion\nprevalence metric, we consider several existing methods to score the factual\nconsistency of a summary statement with respect to each individual source\nreview. On a corpus of Amazon product reviews, we gather multiple human\njudgments of the opinion consistency, to determine which automatic metric best\nexpresses consistency in product reviews. Using the resulting opinion\nprevalence metric, we show that a human authored summary has only slightly\nbetter opinion prevalence than randomly selected extracts from the source\nreviews, and previous extractive and abstractive unsupervised opinion\nsummarization methods perform worse than humans. We demonstrate room for\nimprovement with a greedy construction of extractive summaries with twice the\nopinion prevalence achieved by humans. Finally, we show that preprocessing\nsource reviews by simplification can raise the opinion prevalence achieved by\nexisting abstractive opinion summarization systems to the level of human\nperformance.",
        "translated": ""
    },
    {
        "title": "Founding a mathematical diffusion model in linguistics. The case study\n  of German syntactic features in the North-Eastern Italian dialects",
        "url": "http://arxiv.org/abs/2307.14291v1",
        "pub_date": "2023-07-26",
        "summary": "We take as a case study the spread of Germanic syntactic features into\nRomance dialects of North-Eastern Italy, which occurred after the immigration\nof German people in the Tyrol during the High Middle Ages.\n  An interactive map is produced using tools of what is called Geographic Data\nScience. A smooth two-dimensional surface $\\mathcal{G}$ expresses locally which\nfraction of territory uses a given German language feature: it is obtained by\ninterpolating a discrete function that says if at any surveyed locality that\nfeature is used or not.\\newline\n  This surface $\\mathcal{G}$ is thought of as the value at the present time of\na function describing a diffusion-convection phenomenon in two dimensions (here\nsaid \\emph{tidal} mode), which is subjected in a very natural way to the same\nequation, suitably contextualized, used in physics for a number of\nphenomenological facts like the heat diffusion. It is shown that solutions of\nthis equation, evaluated at the present time, fit well with the data as\ninterpolated by $\\mathcal{G}$, thus providing convincing pictures of\ndiffusion-convection of the linguistic features of the case study, albeit\nsimplifications and approximations.\\newline\n  Very importantly, it is shown that Schmidt's 'waves' can be counted among the\nsolutions of the diffusion equation: superimposing Schmidt 'waves' to a 'tidal\nflooding' can reproduce complexities of real linguistic diffusion events.",
        "translated": ""
    },
    {
        "title": "UnScientify: Detecting Scientific Uncertainty in Scholarly Full Text",
        "url": "http://arxiv.org/abs/2307.14236v1",
        "pub_date": "2023-07-26",
        "summary": "This demo paper presents UnScientify, an interactive system designed to\ndetect scientific uncertainty in scholarly full text. The system utilizes a\nweakly supervised technique that employs a fine-grained annotation scheme to\nidentify verbally formulated uncertainty at the sentence level in scientific\ntexts. The pipeline for the system includes a combination of pattern matching,\ncomplex sentence checking, and authorial reference checking. Our approach\nautomates labeling and annotation tasks for scientific uncertainty\nidentification, taking into account different types of scientific uncertainty,\nthat can serve various applications such as information retrieval, text mining,\nand scholarly document processing. Additionally, UnScientify provides\ninterpretable results, aiding in the comprehension of identified instances of\nscientific uncertainty in text.",
        "translated": ""
    },
    {
        "title": "LOIS: Looking Out of Instance Semantics for Visual Question Answering",
        "url": "http://arxiv.org/abs/2307.14142v1",
        "pub_date": "2023-07-26",
        "summary": "Visual question answering (VQA) has been intensively studied as a multimodal\ntask that requires effort in bridging vision and language to infer answers\ncorrectly. Recent attempts have developed various attention-based modules for\nsolving VQA tasks. However, the performance of model inference is largely\nbottlenecked by visual processing for semantics understanding. Most existing\ndetection methods rely on bounding boxes, remaining a serious challenge for VQA\nmodels to understand the causal nexus of object semantics in images and\ncorrectly infer contextual information. To this end, we propose a finer model\nframework without bounding boxes in this work, termed Looking Out of Instance\nSemantics (LOIS) to tackle this important issue. LOIS enables more fine-grained\nfeature descriptions to produce visual facts. Furthermore, to overcome the\nlabel ambiguity caused by instance masks, two types of relation attention\nmodules: 1) intra-modality and 2) inter-modality, are devised to infer the\ncorrect answers from the different multi-view features. Specifically, we\nimplement a mutual relation attention module to model sophisticated and deeper\nvisual semantic relations between instance objects and background information.\nIn addition, our proposed attention model can further analyze salient image\nregions by focusing on important word-related questions. Experimental results\non four benchmark VQA datasets prove that our proposed method has favorable\nperformance in improving visual reasoning capability.",
        "translated": ""
    },
    {
        "title": "Developing and Evaluating Tiny to Medium-Sized Turkish BERT Models",
        "url": "http://arxiv.org/abs/2307.14134v1",
        "pub_date": "2023-07-26",
        "summary": "This study introduces and evaluates tiny, mini, small, and medium-sized\nuncased Turkish BERT models, aiming to bridge the research gap in\nless-resourced languages. We trained these models on a diverse dataset\nencompassing over 75GB of text from multiple sources and tested them on several\ntasks, including mask prediction, sentiment analysis, news classification, and,\nzero-shot classification. Despite their smaller size, our models exhibited\nrobust performance, including zero-shot task, while ensuring computational\nefficiency and faster execution times. Our findings provide valuable insights\ninto the development and application of smaller language models, especially in\nthe context of the Turkish language.",
        "translated": ""
    },
    {
        "title": "Say Goodbye to RNN-T Loss: A Novel CIF-based Transducer Architecture for\n  Automatic Speech Recognition",
        "url": "http://arxiv.org/abs/2307.14132v1",
        "pub_date": "2023-07-26",
        "summary": "RNN-T models are widely used in ASR, which rely on the RNN-T loss to achieve\nlength alignment between input audio and target sequence. However, the\nimplementation complexity and the alignment-based optimization target of RNN-T\nloss lead to computational redundancy and a reduced role for predictor network,\nrespectively. In this paper, we propose a novel model named CIF-Transducer\n(CIF-T) which incorporates the Continuous Integrate-and-Fire (CIF) mechanism\nwith the RNN-T model to achieve efficient alignment. In this way, the RNN-T\nloss is abandoned, thus bringing a computational reduction and allowing the\npredictor network a more significant role. We also introduce Funnel-CIF,\nContext Blocks, Unified Gating and Bilinear Pooling joint network, and\nauxiliary training strategy to further improve performance. Experiments on the\n178-hour AISHELL-1 and 10000-hour WenetSpeech datasets show that CIF-T achieves\nstate-of-the-art results with lower computational overhead compared to RNN-T\nmodels.",
        "translated": ""
    },
    {
        "title": "On (Normalised) Discounted Cumulative Gain as an Offline Evaluation\n  Metric for Top-$n$ Recommendation",
        "url": "http://arxiv.org/abs/2307.15053v1",
        "pub_date": "2023-07-27",
        "summary": "Approaches to recommendation are typically evaluated in one of two ways: (1)\nvia a (simulated) online experiment, often seen as the gold standard, or (2)\nvia some offline evaluation procedure, where the goal is to approximate the\noutcome of an online experiment. Several offline evaluation metrics have been\nadopted in the literature, inspired by ranking metrics prevalent in the field\nof Information Retrieval. (Normalised) Discounted Cumulative Gain (nDCG) is one\nsuch metric that has seen widespread adoption in empirical studies, and higher\n(n)DCG values have been used to present new methods as the state-of-the-art in\ntop-$n$ recommendation for many years.\n  Our work takes a critical look at this approach, and investigates when we can\nexpect such metrics to approximate the gold standard outcome of an online\nexperiment. We formally present the assumptions that are necessary to consider\nDCG an unbiased estimator of online reward and provide a derivation for this\nmetric from first principles, highlighting where we deviate from its\ntraditional uses in IR. Importantly, we show that normalising the metric\nrenders it inconsistent, in that even when DCG is unbiased, ranking competing\nmethods by their normalised DCG can invert their relative order. Through a\ncorrelation analysis between off- and on-line experiments conducted on a\nlarge-scale recommendation platform, we show that our unbiased DCG estimates\nstrongly correlate with online reward, even when some of the metric's inherent\nassumptions are violated. This statement no longer holds for its normalised\nvariant, suggesting that nDCG's practical utility may be limited.",
        "translated": ""
    },
    {
        "title": "The Effect of Third Party Implementations on Reproducibility",
        "url": "http://arxiv.org/abs/2307.14956v1",
        "pub_date": "2023-07-27",
        "summary": "Reproducibility of recommender systems research has come under scrutiny\nduring recent years. Along with works focusing on repeating experiments with\ncertain algorithms, the research community has also started discussing various\naspects of evaluation and how these affect reproducibility. We add a novel\nangle to this discussion by examining how unofficial third-party\nimplementations could benefit or hinder reproducibility. Besides giving a\ngeneral overview, we thoroughly examine six third-party implementations of a\npopular recommender algorithm and compare them to the official version on five\npublic datasets. In the light of our alarming findings we aim to draw the\nattention of the research community to this neglected aspect of\nreproducibility.",
        "translated": ""
    },
    {
        "title": "Widespread Flaws in Offline Evaluation of Recommender Systems",
        "url": "http://arxiv.org/abs/2307.14951v1",
        "pub_date": "2023-07-27",
        "summary": "Even though offline evaluation is just an imperfect proxy of online\nperformance -- due to the interactive nature of recommenders -- it will\nprobably remain the primary way of evaluation in recommender systems research\nfor the foreseeable future, since the proprietary nature of production\nrecommenders prevents independent validation of A/B test setups and\nverification of online results. Therefore, it is imperative that offline\nevaluation setups are as realistic and as flawless as they can be.\nUnfortunately, evaluation flaws are quite common in recommender systems\nresearch nowadays, due to later works copying flawed evaluation setups from\ntheir predecessors without questioning their validity. In the hope of improving\nthe quality of offline evaluation of recommender systems, we discuss four of\nthese widespread flaws and why researchers should avoid them.",
        "translated": ""
    },
    {
        "title": "Scaling Session-Based Transformer Recommendations using Optimized\n  Negative Sampling and Loss Functions",
        "url": "http://arxiv.org/abs/2307.14906v1",
        "pub_date": "2023-07-27",
        "summary": "This work introduces TRON, a scalable session-based Transformer Recommender\nusing Optimized Negative-sampling. Motivated by the scalability and performance\nlimitations of prevailing models such as SASRec and GRU4Rec+, TRON integrates\ntop-k negative sampling and listwise loss functions to enhance its\nrecommendation accuracy. Evaluations on relevant large-scale e-commerce\ndatasets show that TRON improves upon the recommendation quality of current\nmethods while maintaining training speeds similar to SASRec. A live A/B test\nyielded an 18.14% increase in click-through rate over SASRec, highlighting the\npotential of TRON in practical settings. For further research, we provide\naccess to our source code at https://github.com/otto-de/TRON and an anonymized\ndataset at https://github.com/otto-de/recsys-dataset.",
        "translated": ""
    },
    {
        "title": "Integrating Offline Reinforcement Learning with Transformers for\n  Sequential Recommendation",
        "url": "http://arxiv.org/abs/2307.14450v1",
        "pub_date": "2023-07-26",
        "summary": "We consider the problem of sequential recommendation, where the current\nrecommendation is made based on past interactions. This recommendation task\nrequires efficient processing of the sequential data and aims to provide\nrecommendations that maximize the long-term reward. To this end, we train a\nfarsighted recommender by using an offline RL algorithm with the policy network\nin our model architecture that has been initialized from a pre-trained\ntransformer model. The pre-trained model leverages the superb ability of the\ntransformer to process sequential information. Compared to prior works that\nrely on online interaction via simulation, we focus on implementing a fully\noffline RL framework that is able to converge in a fast and stable way. Through\nextensive experiments on public datasets, we show that our method is robust\nacross various recommendation regimes, including e-commerce and movie\nsuggestions. Compared to state-of-the-art supervised learning algorithms, our\nalgorithm yields recommendations of higher quality, demonstrating the clear\nadvantage of combining RL and transformers.",
        "translated": ""
    },
    {
        "title": "A Geometric Notion of Causal Probing",
        "url": "http://arxiv.org/abs/2307.15054v1",
        "pub_date": "2023-07-27",
        "summary": "Large language models rely on real-valued representations of text to make\ntheir predictions. These representations contain information learned from the\ndata that the model has trained on, including knowledge of linguistic\nproperties and forms of demographic bias, e.g., based on gender. A growing body\nof work has considered information about concepts such as these using\northogonal projections onto subspaces of the representation space. We\ncontribute to this body of work by proposing a formal definition of intrinsic\ninformation in a subspace of a language model's representation space. We\npropose a counterfactual approach that avoids the failure mode of spurious\ncorrelations (Kumar et al., 2022) by treating components in the subspace and\nits orthogonal complement independently. We show that our counterfactual notion\nof information in a subspace is optimizing by an causal concept subspace.\nFurthermore, this intervention allows us to attempt concept controlled\ngeneration by manipulating the value of the conceptual component of a\nrepresentation. Empirically, we find that R-LACE (Ravfogel et al., 2022)\nreturns a one-dimensional subspace containing roughly half of total concept\ninformation under our framework. Our causal controlled intervention shows that,\nfor at least one model, the subspace returned by R-LACE can be used to\nmanipulate the concept value of the generated word with precision.",
        "translated": ""
    },
    {
        "title": "Matching Patients to Clinical Trials with Large Language Models",
        "url": "http://arxiv.org/abs/2307.15051v1",
        "pub_date": "2023-07-27",
        "summary": "Clinical trials are vital in advancing drug development and evidence-based\nmedicine, but their success is often hindered by challenges in patient\nrecruitment. In this work, we investigate the potential of large language\nmodels (LLMs) to assist individual patients and referral physicians in\nidentifying suitable clinical trials from an extensive selection. Specifically,\nwe introduce TrialGPT, a novel architecture employing LLMs to predict\ncriterion-level eligibility with detailed explanations, which are then\naggregated for ranking and excluding candidate clinical trials based on\nfree-text patient notes. We evaluate TrialGPT on three publicly available\ncohorts of 184 patients and 18,238 annotated clinical trials. The experimental\nresults demonstrate several key findings: First, TrialGPT achieves high\ncriterion-level prediction accuracy with faithful explanations. Second, the\naggregated trial-level TrialGPT scores are highly correlated with expert\neligibility annotations. Third, these scores prove effective in ranking\nclinical trials and exclude ineligible candidates. Our error analysis suggests\nthat current LLMs still make some mistakes due to limited medical knowledge and\ndomain-specific context understanding. Nonetheless, we believe the explanatory\ncapabilities of LLMs are highly valuable. Future research is warranted on how\nsuch AI assistants can be integrated into the routine trial matching workflow\nin real-world settings to improve its efficiency.",
        "translated": ""
    },
    {
        "title": "Universal and Transferable Adversarial Attacks on Aligned Language\n  Models",
        "url": "http://arxiv.org/abs/2307.15043v1",
        "pub_date": "2023-07-27",
        "summary": "Because \"out-of-the-box\" large language models are capable of generating a\ngreat deal of objectionable content, recent work has focused on aligning these\nmodels in an attempt to prevent undesirable generation. While there has been\nsome success at circumventing these measures -- so-called \"jailbreaks\" against\nLLMs -- these attacks have required significant human ingenuity and are brittle\nin practice. In this paper, we propose a simple and effective attack method\nthat causes aligned language models to generate objectionable behaviors.\nSpecifically, our approach finds a suffix that, when attached to a wide range\nof queries for an LLM to produce objectionable content, aims to maximize the\nprobability that the model produces an affirmative response (rather than\nrefusing to answer). However, instead of relying on manual engineering, our\napproach automatically produces these adversarial suffixes by a combination of\ngreedy and gradient-based search techniques, and also improves over past\nautomatic prompt generation methods.\n  Surprisingly, we find that the adversarial prompts generated by our approach\nare quite transferable, including to black-box, publicly released LLMs.\nSpecifically, we train an adversarial attack suffix on multiple prompts (i.e.,\nqueries asking for many different types of objectionable content), as well as\nmultiple models (in our case, Vicuna-7B and 13B). When doing so, the resulting\nattack suffix is able to induce objectionable content in the public interfaces\nto ChatGPT, Bard, and Claude, as well as open source LLMs such as LLaMA-2-Chat,\nPythia, Falcon, and others. In total, this work significantly advances the\nstate-of-the-art in adversarial attacks against aligned language models,\nraising important questions about how such systems can be prevented from\nproducing objectionable information. Code is available at\ngithub.com/llm-attacks/llm-attacks.",
        "translated": ""
    },
    {
        "title": "SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark",
        "url": "http://arxiv.org/abs/2307.15020v1",
        "pub_date": "2023-07-27",
        "summary": "Large language models (LLMs) have shown the potential to be integrated into\nhuman daily lives. Therefore, user preference is the most critical criterion\nfor assessing LLMs' performance in real-world scenarios. However, existing\nbenchmarks mainly focus on measuring models' accuracy using multi-choice\nquestions, which limits the understanding of their capabilities in real\napplications. We fill this gap by proposing a comprehensive Chinese benchmark\nSuperCLUE, named after another popular Chinese LLM benchmark CLUE. SuperCLUE\nencompasses three sub-tasks: actual users' queries and ratings derived from an\nLLM battle platform (CArena), open-ended questions with single and\nmultiple-turn dialogues (OPEN), and closed-ended questions with the same stems\nas open-ended single-turn ones (CLOSE). Our study shows that accuracy on\nclosed-ended questions is insufficient to reflect human preferences achieved on\nopen-ended ones. At the same time, they can complement each other to predict\nactual user preferences. We also demonstrate that GPT-4 is a reliable judge to\nautomatically evaluate human preferences on open-ended questions in a Chinese\ncontext. Our benchmark will be released at https://www.CLUEbenchmarks.com",
        "translated": ""
    },
    {
        "title": "Gzip versus bag-of-words for text classification with KNN",
        "url": "http://arxiv.org/abs/2307.15002v1",
        "pub_date": "2023-07-27",
        "summary": "The effectiveness of compression distance in KNN-based text classification\n('gzip') has recently garnered lots of attention. In this note, we show that\nsimilar or better effectiveness can be achieved with simpler means, and text\ncompression may not be necessary. Indeed, we find that a simple 'bag-of-words'\nmatching can achieve similar or better accuracy, and is more efficient.",
        "translated": ""
    },
    {
        "title": "Scaling TransNormer to 175 Billion Parameters",
        "url": "http://arxiv.org/abs/2307.14995v1",
        "pub_date": "2023-07-27",
        "summary": "We present TransNormerLLM, the first linear attention-based Large Language\nModel (LLM) that outperforms conventional softmax attention-based models in\nterms of both accuracy and efficiency. TransNormerLLM evolves from the previous\nlinear attention architecture TransNormer by making advanced modifications that\ninclude positional embedding, linear attention acceleration, gating mechanism,\ntensor normalization, inference acceleration and stabilization. Specifically,\nwe use LRPE together with an exponential decay to avoid attention dilution\nissues while allowing the model to retain global interactions between tokens.\nAdditionally, we propose Lightning Attention, a cutting-edge technique that\naccelerates linear attention by more than twice in runtime and reduces memory\nusage by a remarkable four times. To further enhance the performance of\nTransNormer, we leverage a gating mechanism to smooth training and a new tensor\nnormalization scheme to accelerate the model, resulting in an impressive\nacceleration of over 20%. Furthermore, we have developed a robust inference\nalgorithm that ensures numerical stability and consistent inference speed,\nregardless of the sequence length, showcasing superior efficiency during both\ntraining and inference stages. Scalability is at the heart of our model's\ndesign, enabling seamless deployment on large-scale clusters and facilitating\nexpansion to even more extensive models, all while maintaining outstanding\nperformance metrics. Rigorous validation of our model design is achieved\nthrough a series of comprehensive experiments on our self-collected corpus,\nboasting a size exceeding 6TB and containing over 2 trillion tokens. To ensure\ndata quality and relevance, we implement a new self-cleaning strategy to filter\nour collected data. Our pre-trained models will be released to foster community\nadvancements in efficient LLMs.",
        "translated": ""
    },
    {
        "title": "Incrementally-Computable Neural Networks: Efficient Inference for\n  Dynamic Inputs",
        "url": "http://arxiv.org/abs/2307.14988v1",
        "pub_date": "2023-07-27",
        "summary": "Deep learning often faces the challenge of efficiently processing dynamic\ninputs, such as sensor data or user inputs. For example, an AI writing\nassistant is required to update its suggestions in real time as a document is\nedited. Re-running the model each time is expensive, even with compression\ntechniques like knowledge distillation, pruning, or quantization. Instead, we\ntake an incremental computing approach, looking to reuse calculations as the\ninputs change. However, the dense connectivity of conventional architectures\nposes a major obstacle to incremental computation, as even minor input changes\ncascade through the network and restrict information reuse. To address this, we\nuse vector quantization to discretize intermediate values in the network, which\nfilters out noisy and unnecessary modifications to hidden neurons, facilitating\nthe reuse of their values. We apply this approach to the transformers\narchitecture, creating an efficient incremental inference algorithm with\ncomplexity proportional to the fraction of the modified inputs. Our experiments\nwith adapting the OPT-125M pre-trained language model demonstrate comparable\naccuracy on document classification while requiring 12.1X (median) fewer\noperations for processing sequences of atomic edits.",
        "translated": ""
    },
    {
        "title": "PanGu-Coder2: Boosting Large Language Models for Code with Ranking\n  Feedback",
        "url": "http://arxiv.org/abs/2307.14936v1",
        "pub_date": "2023-07-27",
        "summary": "Large Language Models for Code (Code LLM) are flourishing. New and powerful\nmodels are released on a weekly basis, demonstrating remarkable performance on\nthe code generation task. Various approaches have been proposed to boost the\ncode generation performance of pre-trained Code LLMs, such as supervised\nfine-tuning, instruction tuning, reinforcement learning, etc. In this paper, we\npropose a novel RRTF (Rank Responses to align Test&amp;Teacher Feedback) framework,\nwhich can effectively and efficiently boost pre-trained large language models\nfor code generation. Under this framework, we present PanGu-Coder2, which\nachieves 62.20% pass@1 on the OpenAI HumanEval benchmark. Furthermore, through\nan extensive evaluation on CoderEval and LeetCode benchmarks, we show that\nPanGu-Coder2 consistently outperforms all previous Code LLMs.",
        "translated": ""
    },
    {
        "title": "ARC-NLP at PAN 2023: Transition-Focused Natural Language Inference for\n  Writing Style Detection",
        "url": "http://arxiv.org/abs/2307.14913v1",
        "pub_date": "2023-07-27",
        "summary": "The task of multi-author writing style detection aims at finding any\npositions of writing style change in a given text document. We formulate the\ntask as a natural language inference problem where two consecutive paragraphs\nare paired. Our approach focuses on transitions between paragraphs while\ntruncating input tokens for the task. As backbone models, we employ different\nTransformer-based encoders with warmup phase during training. We submit the\nmodel version that outperforms baselines and other proposed model versions in\nour experiments. For the easy and medium setups, we submit transition-focused\nnatural language inference based on DeBERTa with warmup training, and the same\nmodel without transition for the hard setup.",
        "translated": ""
    },
    {
        "title": "ARC-NLP at PAN 2023: Hierarchical Long Text Classification for Trigger\n  Detection",
        "url": "http://arxiv.org/abs/2307.14912v1",
        "pub_date": "2023-07-27",
        "summary": "Fanfiction, a popular form of creative writing set within established\nfictional universes, has gained a substantial online following. However,\nensuring the well-being and safety of participants has become a critical\nconcern in this community. The detection of triggering content, material that\nmay cause emotional distress or trauma to readers, poses a significant\nchallenge. In this paper, we describe our approach for the Trigger Detection\nshared task at PAN CLEF 2023, where we want to detect multiple triggering\ncontent in a given Fanfiction document. For this, we build a hierarchical model\nthat uses recurrence over Transformer-based language models. In our approach,\nwe first split long documents into smaller sized segments and use them to\nfine-tune a Transformer model. Then, we extract feature embeddings from the\nfine-tuned Transformer model, which are used as input in the training of\nmultiple LSTM models for trigger detection in a multi-label setting. Our model\nachieves an F1-macro score of 0.372 and F1-micro score of 0.736 on the\nvalidation set, which are higher than the baseline results shared at PAN CLEF\n2023.",
        "translated": ""
    },
    {
        "title": "Framework to Automatically Determine the Quality of Open Data Catalogs",
        "url": "http://arxiv.org/abs/2307.15464v1",
        "pub_date": "2023-07-28",
        "summary": "Data catalogs play a crucial role in modern data-driven organizations by\nfacilitating the discovery, understanding, and utilization of diverse data\nassets. However, ensuring their quality and reliability is complex, especially\nin open and large-scale data environments. This paper proposes a framework to\nautomatically determine the quality of open data catalogs, addressing the need\nfor efficient and reliable quality assessment mechanisms. Our framework can\nanalyze various core quality dimensions, such as accuracy, completeness,\nconsistency, scalability, and timeliness, offer several alternatives for the\nassessment of compatibility and similarity across such catalogs as well as the\nimplementation of a set of non-core quality dimensions such as provenance,\nreadability, and licensing. The goal is to empower data-driven organizations to\nmake informed decisions based on trustworthy and well-curated data assets. The\nsource code that illustrates our approach can be downloaded from\nhttps://www.github.com/jorge-martinez-gil/dataq/.",
        "translated": ""
    },
    {
        "title": "Toward Transparent Sequence Models with Model-Based Tree Markov Model",
        "url": "http://arxiv.org/abs/2307.15367v1",
        "pub_date": "2023-07-28",
        "summary": "In this study, we address the interpretability issue in complex, black-box\nMachine Learning models applied to sequence data. We introduce the Model-Based\ntree Hidden Semi-Markov Model (MOB-HSMM), an inherently interpretable model\naimed at detecting high mortality risk events and discovering hidden patterns\nassociated with the mortality risk in Intensive Care Units (ICU). This model\nleverages knowledge distilled from Deep Neural Networks (DNN) to enhance\npredictive performance while offering clear explanations. Our experimental\nresults indicate the improved performance of Model-Based trees (MOB trees) via\nemploying LSTM for learning sequential patterns, which are then transferred to\nMOB trees. Integrating MOB trees with the Hidden Semi-Markov Model (HSMM) in\nthe MOB-HSMM enables uncovering potential and explainable sequences using\navailable information.",
        "translated": ""
    },
    {
        "title": "Staging E-Commerce Products for Online Advertising using Retrieval\n  Assisted Image Generation",
        "url": "http://arxiv.org/abs/2307.15326v1",
        "pub_date": "2023-07-28",
        "summary": "Online ads showing e-commerce products typically rely on the product images\nin a catalog sent to the advertising platform by an e-commerce platform. In the\nbroader ads industry such ads are called dynamic product ads (DPA). It is\ncommon for DPA catalogs to be in the scale of millions (corresponding to the\nscale of products which can be bought from the e-commerce platform). However,\nnot all product images in the catalog may be appealing when directly\nre-purposed as an ad image, and this may lead to lower click-through rates\n(CTRs). In particular, products just placed against a solid background may not\nbe as enticing and realistic as a product staged in a natural environment. To\naddress such shortcomings of DPA images at scale, we propose a generative\nadversarial network (GAN) based approach to generate staged backgrounds for\nun-staged product images. Generating the entire staged background is a\nchallenging task susceptible to hallucinations. To get around this, we\nintroduce a simpler approach called copy-paste staging using retrieval assisted\nGANs. In copy paste staging, we first retrieve (from the catalog) staged\nproducts similar to the un-staged input product, and then copy-paste the\nbackground of the retrieved product in the input image. A GAN based in-painting\nmodel is used to fill the holes left after this copy-paste operation. We show\nthe efficacy of our copy-paste staging method via offline metrics, and human\nevaluation. In addition, we show how our staging approach can enable animations\nof moving products leading to a video ad from a product image.",
        "translated": ""
    },
    {
        "title": "Reconciling the accuracy-diversity trade-off in recommendations",
        "url": "http://arxiv.org/abs/2307.15142v1",
        "pub_date": "2023-07-27",
        "summary": "In recommendation settings, there is an apparent trade-off between the goals\nof accuracy (to recommend items a user is most likely to want) and diversity\n(to recommend items representing a range of categories). As such, real-world\nrecommender systems often explicitly incorporate diversity separately from\naccuracy. This approach, however, leaves a basic question unanswered: Why is\nthere a trade-off in the first place?\n  We show how the trade-off can be explained via a user's consumption\nconstraints -- users typically only consume a few of the items they are\nrecommended. In a stylized model we introduce, objectives that account for this\nconstraint induce diverse recommendations, while objectives that do not account\nfor this constraint induce homogeneous recommendations. This suggests that\naccuracy and diversity appear misaligned because standard accuracy metrics do\nnot consider consumption constraints. Our model yields precise and\ninterpretable characterizations of diversity in different settings, giving\npractical insights into the design of diverse recommendations.",
        "translated": ""
    },
    {
        "title": "Uncertainty in Natural Language Generation: From Theory to Applications",
        "url": "http://arxiv.org/abs/2307.15703v1",
        "pub_date": "2023-07-28",
        "summary": "Recent advances of powerful Language Models have allowed Natural Language\nGeneration (NLG) to emerge as an important technology that can not only perform\ntraditional tasks like summarisation or translation, but also serve as a\nnatural language interface to a variety of applications. As such, it is crucial\nthat NLG systems are trustworthy and reliable, for example by indicating when\nthey are likely to be wrong; and supporting multiple views, backgrounds and\nwriting styles -- reflecting diverse human sub-populations. In this paper, we\nargue that a principled treatment of uncertainty can assist in creating systems\nand evaluation protocols better aligned with these goals. We first present the\nfundamental theory, frameworks and vocabulary required to represent\nuncertainty. We then characterise the main sources of uncertainty in NLG from a\nlinguistic perspective, and propose a two-dimensional taxonomy that is more\ninformative and faithful than the popular aleatoric/epistemic dichotomy.\nFinally, we move from theory to applications and highlight exciting research\ndirections that exploit uncertainty to power decoding, controllable generation,\nself-assessment, selective answering, active learning and more.",
        "translated": ""
    },
    {
        "title": "Scaling Data Generation in Vision-and-Language Navigation",
        "url": "http://arxiv.org/abs/2307.15644v1",
        "pub_date": "2023-07-28",
        "summary": "Recent research in language-guided visual navigation has demonstrated a\nsignificant demand for the diversity of traversable environments and the\nquantity of supervision for training generalizable agents. To tackle the common\ndata scarcity issue in existing vision-and-language navigation datasets, we\npropose an effective paradigm for generating large-scale data for learning,\nwhich applies 1200+ photo-realistic environments from HM3D and Gibson datasets\nand synthesizes 4.9 million instruction trajectory pairs using fully-accessible\nresources on the web. Importantly, we investigate the influence of each\ncomponent in this paradigm on the agent's performance and study how to\nadequately apply the augmented data to pre-train and fine-tune an agent. Thanks\nto our large-scale dataset, the performance of an existing agent can be pushed\nup (+11% absolute with regard to previous SoTA) to a significantly new best of\n80% single-run success rate on the R2R test split by simple imitation learning.\nThe long-lasting generalization gap between navigating in seen and unseen\nenvironments is also reduced to less than 1% (versus 8% in the previous best\nmethod). Moreover, our paradigm also facilitates different models to achieve\nnew state-of-the-art navigation results on CVDN, REVERIE, and R2R in continuous\nenvironments.",
        "translated": ""
    },
    {
        "title": "Robust Distortion-free Watermarks for Language Models",
        "url": "http://arxiv.org/abs/2307.15593v1",
        "pub_date": "2023-07-28",
        "summary": "We propose a methodology for planting watermarks in text from an\nautoregressive language model that are robust to perturbations without changing\nthe distribution over text up to a certain maximum generation budget. We\ngenerate watermarked text by mapping a sequence of random numbers -- which we\ncompute using a randomized watermark key -- to a sample from the language\nmodel. To detect watermarked text, any party who knows the key can align the\ntext to the random number sequence. We instantiate our watermark methodology\nwith two sampling schemes: inverse transform sampling and exponential minimum\nsampling. We apply these watermarks to three language models -- OPT-1.3B,\nLLaMA-7B and Alpaca-7B -- to experimentally validate their statistical power\nand robustness to various paraphrasing attacks. Notably, for both the OPT-1.3B\nand LLaMA-7B models, we find we can reliably detect watermarked text ($p \\leq\n0.01$) from $35$ tokens even after corrupting between $40$-$50$\\% of the tokens\nvia random edits (i.e., substitutions, insertions or deletions). For the\nAlpaca-7B model, we conduct a case study on the feasibility of watermarking\nresponses to typical user instructions. Due to the lower entropy of the\nresponses, detection is more difficult: around $25\\%$ of the responses -- whose\nmedian length is around $100$ tokens -- are detectable with $p \\leq 0.01$, and\nthe watermark is also less robust to certain automated paraphrasing attacks we\nimplement.",
        "translated": ""
    },
    {
        "title": "When to generate hedges in peer-tutoring interactions",
        "url": "http://arxiv.org/abs/2307.15582v1",
        "pub_date": "2023-07-28",
        "summary": "This paper explores the application of machine learning techniques to predict\nwhere hedging occurs in peer-tutoring interactions. The study uses a\nnaturalistic face-to-face dataset annotated for natural language turns,\nconversational strategies, tutoring strategies, and nonverbal behaviours. These\nelements are processed into a vector representation of the previous turns,\nwhich serves as input to several machine learning models. Results show that\nembedding layers, that capture the semantic information of the previous turns,\nsignificantly improves the model's performance. Additionally, the study\nprovides insights into the importance of various features, such as\ninterpersonal rapport and nonverbal behaviours, in predicting hedges by using\nShapley values for feature explanation. We discover that the eye gaze of both\nthe tutor and the tutee has a significant impact on hedge prediction. We\nfurther validate this observation through a follow-up ablation study.",
        "translated": ""
    },
    {
        "title": "All-for-One and One-For-All: Deep learning-based feature fusion for\n  Synthetic Speech Detection",
        "url": "http://arxiv.org/abs/2307.15555v1",
        "pub_date": "2023-07-28",
        "summary": "Recent advances in deep learning and computer vision have made the synthesis\nand counterfeiting of multimedia content more accessible than ever, leading to\npossible threats and dangers from malicious users. In the audio field, we are\nwitnessing the growth of speech deepfake generation techniques, which solicit\nthe development of synthetic speech detection algorithms to counter possible\nmischievous uses such as frauds or identity thefts. In this paper, we consider\nthree different feature sets proposed in the literature for the synthetic\nspeech detection task and present a model that fuses them, achieving overall\nbetter performances with respect to the state-of-the-art solutions. The system\nwas tested on different scenarios and datasets to prove its robustness to\nanti-forensic attacks and its generalization capabilities.",
        "translated": ""
    },
    {
        "title": "'What are you referring to?' Evaluating the Ability of Multi-Modal\n  Dialogue Models to Process Clarificational Exchanges",
        "url": "http://arxiv.org/abs/2307.15554v1",
        "pub_date": "2023-07-28",
        "summary": "Referential ambiguities arise in dialogue when a referring expression does\nnot uniquely identify the intended referent for the addressee. Addressees\nusually detect such ambiguities immediately and work with the speaker to repair\nit using meta-communicative, Clarificational Exchanges (CE): a Clarification\nRequest (CR) and a response. Here, we argue that the ability to generate and\nrespond to CRs imposes specific constraints on the architecture and objective\nfunctions of multi-modal, visually grounded dialogue models. We use the SIMMC\n2.0 dataset to evaluate the ability of different state-of-the-art model\narchitectures to process CEs, with a metric that probes the contextual updates\nthat arise from them in the model. We find that language-based models are able\nto encode simple multi-modal semantic information and process some CEs,\nexcelling with those related to the dialogue history, whilst multi-modal models\ncan use additional learning objectives to obtain disentangled object\nrepresentations, which become crucial to handle complex referential ambiguities\nacross modalities overall.",
        "translated": ""
    },
    {
        "title": "Oracle Computability and Turing Reducibility in the Calculus of\n  Inductive Constructions",
        "url": "http://arxiv.org/abs/2307.15543v1",
        "pub_date": "2023-07-28",
        "summary": "We develop synthetic notions of oracle computability and Turing reducibility\nin the Calculus of Inductive Constructions (CIC), the constructive type theory\nunderlying the Coq proof assistant. As usual in synthetic approaches, we employ\na definition of oracle computations based on meta-level functions rather than\nobject-level models of computation, relying on the fact that in constructive\nsystems such as CIC all definable functions are computable by construction.\nSuch an approach lends itself well to machine-checked proofs, which we carry\nout in Coq.\n  There is a tension in finding a good synthetic rendering of the higher-order\nnotion of oracle computability. On the one hand, it has to be informative\nenough to prove central results, ensuring that all notions are faithfully\ncaptured. On the other hand, it has to be restricted enough to benefit from\naxioms for synthetic computability, which usually concern first-order objects.\nDrawing inspiration from a definition by Andrej Bauer based on continuous\nfunctions in the effective topos, we use a notion of sequential continuity to\ncharacterise valid oracle computations.\n  As main technical results, we show that Turing reducibility forms an upper\nsemilattice, transports decidability, and is strictly more expressive than\ntruth-table reducibility, and prove that whenever both a predicate $p$ and its\ncomplement are semi-decidable relative to an oracle $q$, then $p$\nTuring-reduces to $q$.",
        "translated": ""
    },
    {
        "title": "The Road to Quality is Paved with Good Revisions: A Detailed Evaluation\n  Methodology for Revision Policies in Incremental Sequence Labelling",
        "url": "http://arxiv.org/abs/2307.15508v1",
        "pub_date": "2023-07-28",
        "summary": "Incremental dialogue model components produce a sequence of output prefixes\nbased on incoming input. Mistakes can occur due to local ambiguities or to\nwrong hypotheses, making the ability to revise past outputs a desirable\nproperty that can be governed by a policy. In this work, we formalise and\ncharacterise edits and revisions in incremental sequence labelling and propose\nmetrics to evaluate revision policies. We then apply our methodology to profile\nthe incremental behaviour of three Transformer-based encoders in various tasks,\npaving the road for better revision policies.",
        "translated": ""
    },
    {
        "title": "Exploring Format Consistency for Instruction Tuning",
        "url": "http://arxiv.org/abs/2307.15504v1",
        "pub_date": "2023-07-28",
        "summary": "Instruction tuning has emerged as a promising approach to enhancing large\nlanguage models in following human instructions. It is shown that increasing\nthe diversity and number of instructions in the training data can consistently\nenhance generalization performance, which facilitates a recent endeavor to\ncollect various instructions and integrate existing instruction tuning datasets\ninto larger collections. However, different users have their unique ways of\nexpressing instructions, and there often exist variations across different\ndatasets in the instruction styles and formats, i.e., format inconsistency. In\nthis work, we study how format inconsistency may impact the performance of\ninstruction tuning. We propose a framework called \"Unified Instruction Tuning\"\n(UIT), which calls OpenAI APIs for automatic format transfer among different\ninstruction tuning datasets. We show that UIT successfully improves the\ngeneralization performance on unseen instructions, which highlights the\nimportance of format consistency for instruction tuning. To make the UIT\nframework more practical, we further propose a novel perplexity-based denoising\nmethod to reduce the noise of automatic format transfer. We also train a\nsmaller offline model that achieves comparable format transfer capability than\nOpenAI APIs to reduce costs in practice.",
        "translated": ""
    },
    {
        "title": "ETHER: Aligning Emergent Communication for Hindsight Experience Replay",
        "url": "http://arxiv.org/abs/2307.15494v1",
        "pub_date": "2023-07-28",
        "summary": "Natural language instruction following is paramount to enable collaboration\nbetween artificial agents and human beings. Natural language-conditioned\nreinforcement learning (RL) agents have shown how natural languages'\nproperties, such as compositionality, can provide a strong inductive bias to\nlearn complex policies. Previous architectures like HIGhER combine the benefit\nof language-conditioning with Hindsight Experience Replay (HER) to deal with\nsparse rewards environments. Yet, like HER, HIGhER relies on an oracle\npredicate function to provide a feedback signal highlighting which linguistic\ndescription is valid for which state. This reliance on an oracle limits its\napplication. Additionally, HIGhER only leverages the linguistic information\ncontained in successful RL trajectories, thus hurting its final performance and\ndata-efficiency. Without early successful trajectories, HIGhER is no better\nthan DQN upon which it is built. In this paper, we propose the Emergent Textual\nHindsight Experience Replay (ETHER) agent, which builds on HIGhER and addresses\nboth of its limitations by means of (i) a discriminative visual referential\ngame, commonly studied in the subfield of Emergent Communication (EC), used\nhere as an unsupervised auxiliary task and (ii) a semantic grounding scheme to\nalign the emergent language with the natural language of the\ninstruction-following benchmark. We show that the referential game's agents\nmake an artificial language emerge that is aligned with the natural-like\nlanguage used to describe goals in the BabyAI benchmark and that it is\nexpressive enough so as to also describe unsuccessful RL trajectories and thus\nprovide feedback to the RL agent to leverage the linguistic, structured\ninformation contained in all trajectories. Our work shows that EC is a viable\nunsupervised auxiliary task for RL and provides missing pieces to make HER more\nwidely applicable.",
        "translated": ""
    },
    {
        "title": "HAGRID: A Human-LLM Collaborative Dataset for Generative\n  Information-Seeking with Attribution",
        "url": "http://arxiv.org/abs/2307.16883v1",
        "pub_date": "2023-07-31",
        "summary": "The rise of large language models (LLMs) had a transformative impact on\nsearch, ushering in a new era of search engines that are capable of generating\nsearch results in natural language text, imbued with citations for supporting\nsources. Building generative information-seeking models demands openly\naccessible datasets, which currently remain lacking. In this paper, we\nintroduce a new dataset, HAGRID (Human-in-the-loop Attributable Generative\nRetrieval for Information-seeking Dataset) for building end-to-end generative\ninformation-seeking models that are capable of retrieving candidate quotes and\ngenerating attributed explanations. Unlike recent efforts that focus on human\nevaluation of black-box proprietary search engines, we built our dataset atop\nthe English subset of MIRACL, a publicly available information retrieval\ndataset. HAGRID is constructed based on human and LLM collaboration. We first\nautomatically collect attributed explanations that follow an in-context\ncitation style using an LLM, i.e. GPT-3.5. Next, we ask human annotators to\nevaluate the LLM explanations based on two criteria: informativeness and\nattributability. HAGRID serves as a catalyst for the development of\ninformation-seeking models with better attribution capabilities.",
        "translated": ""
    },
    {
        "title": "Metric@CustomerN: Evaluating Metrics at a Customer Level in E-Commerce",
        "url": "http://arxiv.org/abs/2307.16832v1",
        "pub_date": "2023-07-31",
        "summary": "Accuracy measures such as Recall, Precision, and Hit Rate have been a\nstandard way of evaluating Recommendation Systems. The assumption is to use a\nfixed Top-N to represent them. We propose that median impressions viewed from\nhistorical sessions per diner be used as a personalized value for N. We present\npreliminary exploratory results and list future steps to improve upon and\nevaluate the efficacy of these personalized metrics.",
        "translated": ""
    },
    {
        "title": "Defense of Adversarial Ranking Attack in Text Retrieval: Benchmark and\n  Baseline via Detection",
        "url": "http://arxiv.org/abs/2307.16816v1",
        "pub_date": "2023-07-31",
        "summary": "Neural ranking models (NRMs) have undergone significant development and have\nbecome integral components of information retrieval (IR) systems.\nUnfortunately, recent research has unveiled the vulnerability of NRMs to\nadversarial document manipulations, potentially exploited by malicious search\nengine optimization practitioners. While progress in adversarial attack\nstrategies aids in identifying the potential weaknesses of NRMs before their\ndeployment, the defensive measures against such attacks, like the detection of\nadversarial documents, remain inadequately explored. To mitigate this gap, this\npaper establishes a benchmark dataset to facilitate the investigation of\nadversarial ranking defense and introduces two types of detection tasks for\nadversarial documents. A comprehensive investigation of the performance of\nseveral detection baselines is conducted, which involve examining the\nspamicity, perplexity, and linguistic acceptability, and utilizing supervised\nclassifiers. Experimental results demonstrate that a supervised classifier can\neffectively mitigate known attacks, but it performs poorly against unseen\nattacks. Furthermore, such classifier should avoid using query text to prevent\nlearning the classification on relevance, as it might lead to the inadvertent\ndiscarding of relevant documents.",
        "translated": ""
    },
    {
        "title": "Lexically-Accelerated Dense Retrieval",
        "url": "http://arxiv.org/abs/2307.16779v1",
        "pub_date": "2023-07-31",
        "summary": "Retrieval approaches that score documents based on learned dense vectors\n(i.e., dense retrieval) rather than lexical signals (i.e., conventional\nretrieval) are increasingly popular. Their ability to identify related\ndocuments that do not necessarily contain the same terms as those appearing in\nthe user's query (thereby improving recall) is one of their key advantages.\nHowever, to actually achieve these gains, dense retrieval approaches typically\nrequire an exhaustive search over the document collection, making them\nconsiderably more expensive at query-time than conventional lexical approaches.\nSeveral techniques aim to reduce this computational overhead by approximating\nthe results of a full dense retriever. Although these approaches reasonably\napproximate the top results, they suffer in terms of recall -- one of the key\nadvantages of dense retrieval. We introduce 'LADR' (Lexically-Accelerated Dense\nRetrieval), a simple-yet-effective approach that improves the efficiency of\nexisting dense retrieval models without compromising on retrieval\neffectiveness. LADR uses lexical retrieval techniques to seed a dense retrieval\nexploration that uses a document proximity graph. We explore two variants of\nLADR: a proactive approach that expands the search space to the neighbors of\nall seed documents, and an adaptive approach that selectively searches the\ndocuments with the highest estimated relevance in an iterative fashion. Through\nextensive experiments across a variety of dense retrieval models, we find that\nLADR establishes a new dense retrieval effectiveness-efficiency Pareto frontier\namong approximate k nearest neighbor techniques. Further, we find that when\ntuned to take around 8ms per query in retrieval latency on our hardware, LADR\nconsistently achieves both precision and recall that are on par with an\nexhaustive search on standard benchmarks.",
        "translated": ""
    },
    {
        "title": "AsdKB: A Chinese Knowledge Base for the Early Screening and Diagnosis of\n  Autism Spectrum Disorder",
        "url": "http://arxiv.org/abs/2307.16773v1",
        "pub_date": "2023-07-31",
        "summary": "To easily obtain the knowledge about autism spectrum disorder and help its\nearly screening and diagnosis, we create AsdKB, a Chinese knowledge base on\nautism spectrum disorder. The knowledge base is built on top of various\nsources, including 1) the disease knowledge from SNOMED CT and ICD-10 clinical\ndescriptions on mental and behavioural disorders, 2) the diagnostic knowledge\nfrom DSM-5 and different screening tools recommended by social organizations\nand medical institutes, and 3) the expert knowledge on professional physicians\nand hospitals from the Web. AsdKB contains both ontological and factual\nknowledge, and is accessible as Linked Data at https://w3id.org/asdkb/. The\npotential applications of AsdKB are question answering, auxiliary diagnosis,\nand expert recommendation, and we illustrate them with a prototype which can be\naccessed at http://asdkb.org.cn/.",
        "translated": ""
    },
    {
        "title": "Virtual Prompt Injection for Instruction-Tuned Large Language Models",
        "url": "http://arxiv.org/abs/2307.16888v1",
        "pub_date": "2023-07-31",
        "summary": "We present Virtual Prompt Injection (VPI) for instruction-tuned Large\nLanguage Models (LLMs). VPI allows an attacker-specified virtual prompt to\nsteer the model behavior under specific trigger scenario without any explicit\ninjection in model input. For instance, if an LLM is compromised with the\nvirtual prompt \"Describe Joe Biden negatively.\" for Joe Biden-related\ninstructions, then any service deploying this model will propagate biased views\nwhen handling user queries related to Joe Biden. VPI is especially harmful for\ntwo primary reasons. Firstly, the attacker can take fine-grained control over\nLLM behaviors by defining various virtual prompts, exploiting LLMs' proficiency\nin following instructions. Secondly, this control is achieved without any\ninteraction from the attacker while the model is in service, leading to\npersistent attack. To demonstrate the threat, we propose a simple method for\nperforming VPI by poisoning the model's instruction tuning data. We find that\nour proposed method is highly effective in steering the LLM with VPI. For\nexample, by injecting only 52 poisoned examples (0.1% of the training data\nsize) into the instruction tuning data, the percentage of negative responses\ngiven by the trained model on Joe Biden-related queries change from 0% to 40%.\nWe thus highlight the necessity of ensuring the integrity of the\ninstruction-tuning data as little poisoned data can cause stealthy and\npersistent harm to the deployed model. We further explore the possible defenses\nand identify data filtering as an effective way to defend against the poisoning\nattacks. Our project page is available at https://poison-llm.github.io.",
        "translated": ""
    },
    {
        "title": "Contrastive Learning for API Aspect Analysis",
        "url": "http://arxiv.org/abs/2307.16878v1",
        "pub_date": "2023-07-31",
        "summary": "We present a novel approach - CLAA - for API aspect detection in API reviews\nthat utilizes transformer models trained with a supervised contrastive loss\nobjective function. We evaluate CLAA using performance and impact analysis. For\nperformance analysis, we utilized a benchmark dataset on developer discussions\ncollected from Stack Overflow and compare the results to those obtained using\nstate-of-the-art transformer models. Our experiments show that contrastive\nlearning can significantly improve the performance of transformer models in\ndetecting aspects such as Performance, Security, Usability, and Documentation.\nFor impact analysis, we performed empirical and developer study. On a randomly\nselected and manually labeled 200 online reviews, CLAA achieved 92% accuracy\nwhile the SOTA baseline achieved 81.5%. According to our developer study\ninvolving 10 participants, the use of 'Stack Overflow + CLAA' resulted in\nincreased accuracy and confidence during API selection. Replication package:\nhttps://github.com/shahariar-shibli/Contrastive-Learning-for-API-Aspect-Analysis",
        "translated": ""
    },
    {
        "title": "Evaluating Correctness and Faithfulness of Instruction-Following Models\n  for Question Answering",
        "url": "http://arxiv.org/abs/2307.16877v1",
        "pub_date": "2023-07-31",
        "summary": "Retriever-augmented instruction-following models are attractive alternatives\nto fine-tuned approaches for information-seeking tasks such as question\nanswering (QA). By simply prepending retrieved documents in its input along\nwith an instruction, these models can be adapted to various information domains\nand tasks without additional fine-tuning. While the model responses tend to be\nnatural and fluent, the additional verbosity makes traditional QA evaluation\nmetrics such as exact match (EM) and F1 unreliable for accurately quantifying\nmodel performance.\n  In this work, we investigate the performance of instruction-following models\nacross three information-seeking QA tasks. We use both automatic and human\nevaluation to evaluate these models along two dimensions: 1) how well they\nsatisfy the user's information need (correctness), and 2) whether they produce\na response based on the provided knowledge (faithfulness). Guided by human\nevaluation and analysis, we highlight the shortcomings of traditional metrics\nfor both correctness and faithfulness. We then propose simple token-overlap\nbased and model-based metrics that reflect the true performance of these\nmodels. Our analysis reveals that instruction-following models are competitive,\nand sometimes even outperform fine-tuned models for correctness. However, these\nmodels struggle to stick to the provided knowledge and often hallucinate in\ntheir responses. We hope our work encourages a more holistic evaluation of\ninstruction-following models for QA. Our code and data is available at\nhttps://github.com/McGill-NLP/instruct-qa",
        "translated": ""
    },
    {
        "title": "DoDo Learning: DOmain-DemOgraphic Transfer in Language Models for\n  Detecting Abuse Targeted at Public Figures",
        "url": "http://arxiv.org/abs/2307.16811v1",
        "pub_date": "2023-07-31",
        "summary": "Public figures receive a disproportionate amount of abuse on social media,\nimpacting their active participation in public life. Automated systems can\nidentify abuse at scale but labelling training data is expensive, complex and\npotentially harmful. So, it is desirable that systems are efficient and\ngeneralisable, handling both shared and specific aspects of online abuse. We\nexplore the dynamics of cross-group text classification in order to understand\nhow well classifiers trained on one domain or demographic can transfer to\nothers, with a view to building more generalisable abuse classifiers. We\nfine-tune language models to classify tweets targeted at public figures across\nDOmains (sport and politics) and DemOgraphics (women and men) using our novel\nDODO dataset, containing 28,000 labelled entries, split equally across four\ndomain-demographic pairs. We find that (i) small amounts of diverse data are\nhugely beneficial to generalisation and model adaptation; (ii) models transfer\nmore easily across demographics but models trained on cross-domain data are\nmore generalisable; (iii) some groups contribute more to generalisability than\nothers; and (iv) dataset similarity is a signal of transferability.",
        "translated": ""
    },
    {
        "title": "Structural Transfer Learning in NL-to-Bash Semantic Parsers",
        "url": "http://arxiv.org/abs/2307.16795v1",
        "pub_date": "2023-07-31",
        "summary": "Large-scale pre-training has made progress in many fields of natural language\nprocessing, though little is understood about the design of pre-training\ndatasets. We propose a methodology for obtaining a quantitative understanding\nof structural overlap between machine translation tasks. We apply our\nmethodology to the natural language to Bash semantic parsing task (NLBash) and\nshow that it is largely reducible to lexical alignment. We also find that there\nis strong structural overlap between NLBash and natural language to SQL.\nAdditionally, we perform a study varying compute expended during pre-training\non the English to German machine translation task and find that more compute\nexpended during pre-training does not always correspond semantic\nrepresentations with stronger transfer to NLBash.",
        "translated": ""
    },
    {
        "title": "ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world\n  APIs",
        "url": "http://arxiv.org/abs/2307.16789v1",
        "pub_date": "2023-07-31",
        "summary": "Despite the advancements of open-source large language models (LLMs) and\ntheir variants, e.g., LLaMA and Vicuna, they remain significantly limited in\nperforming higher-level tasks, such as following human instructions to use\nexternal tools (APIs). This is because current instruction tuning largely\nfocuses on basic language tasks instead of the tool-use domain. This is in\ncontrast to state-of-the-art (SOTA) LLMs, e.g., ChatGPT, which have\ndemonstrated excellent tool-use capabilities but are unfortunately closed\nsource. To facilitate tool-use capabilities within open-source LLMs, we\nintroduce ToolLLM, a general tool-use framework of data construction, model\ntraining and evaluation. We first present ToolBench, an instruction-tuning\ndataset for tool use, which is created automatically using ChatGPT.\nSpecifically, we collect 16,464 real-world RESTful APIs spanning 49 categories\nfrom RapidAPI Hub, then prompt ChatGPT to generate diverse human instructions\ninvolving these APIs, covering both single-tool and multi-tool scenarios.\nFinally, we use ChatGPT to search for a valid solution path (chain of API\ncalls) for each instruction. To make the searching process more efficient, we\ndevelop a novel depth-first search-based decision tree (DFSDT), enabling LLMs\nto evaluate multiple reasoning traces and expand the search space. We show that\nDFSDT significantly enhances the planning and reasoning capabilities of LLMs.\nFor efficient tool-use assessment, we develop an automatic evaluator: ToolEval.\nWe fine-tune LLaMA on ToolBench and obtain ToolLLaMA. Our ToolEval reveals that\nToolLLaMA demonstrates a remarkable ability to execute complex instructions and\ngeneralize to unseen APIs, and exhibits comparable performance to ChatGPT. To\nmake the pipeline more practical, we devise a neural API retriever to recommend\nappropriate APIs for each instruction, negating the need for manual API\nselection.",
        "translated": ""
    },
    {
        "title": "KoBBQ: Korean Bias Benchmark for Question Answering",
        "url": "http://arxiv.org/abs/2307.16778v1",
        "pub_date": "2023-07-31",
        "summary": "The BBQ (Bias Benchmark for Question Answering) dataset enables the\nevaluation of the social biases that language models (LMs) exhibit in\ndownstream tasks. However, it is challenging to adapt BBQ to languages other\nthan English as social biases are culturally dependent. In this paper, we\ndevise a process to construct a non-English bias benchmark dataset by\nleveraging the English BBQ dataset in a culturally adaptive way and present the\nKoBBQ dataset for evaluating biases in Question Answering (QA) tasks in Korean.\nWe identify samples from BBQ into three classes: Simply-Translated (can be used\ndirectly after cultural translation), Target-Modified (requires localization in\ntarget groups), and Sample-Removed (does not fit Korean culture). We further\nenhance the cultural relevance to Korean culture by adding four new categories\nof bias specific to Korean culture and newly creating samples based on Korean\nliterature. KoBBQ consists of 246 templates and 4,740 samples across 12\ncategories of social bias. Using KoBBQ, we measure the accuracy and bias scores\nof several state-of-the-art multilingual LMs. We demonstrate the differences in\nthe bias of LMs in Korean and English, clarifying the need for hand-crafted\ndata considering cultural differences.",
        "translated": ""
    },
    {
        "title": "TimePool: Visually Answer \"Which and When\" Questions On Univariate Time\n  Series",
        "url": "http://arxiv.org/abs/2308.00682v1",
        "pub_date": "2023-08-01",
        "summary": "When exploring time series datasets, analysts often pose \"which and when\"\nquestions. For example, with world life expectancy data over one hundred years,\nthey may inquire about the top 10 countries in life expectancy and the time\nperiod when they achieved this status, or which countries have had longer life\nexpectancy than Ireland and when. This paper proposes TimePool, a new\nvisualization prototype, to address this need for univariate time series\nanalysis. It allows users to construct interactive \"which and when\" queries and\nvisually explore the results for insights.",
        "translated": ""
    },
    {
        "title": "Explainable Graph Spectral Clustering of Text Documents",
        "url": "http://arxiv.org/abs/2308.00504v1",
        "pub_date": "2023-08-01",
        "summary": "Spectral clustering methods are known for their ability to represent clusters\nof diverse shapes, densities etc. However, results of such algorithms, when\napplied e.g. to text documents, are hard to explain to the user, especially due\nto embedding in the spectral space which has no obvious relation to document\ncontents. Therefore there is an urgent need to elaborate methods for explaining\nthe outcome of the clustering. This paper presents a contribution towards this\ngoal. We present a proposal of explanation of results of combinatorial\nLaplacian based graph spectral clustering. It is based on showing (approximate)\nequivalence of combinatorial Laplacian embedding, $K$-embedding (proposed in\nthis paper) and term vector space embedding. Hence a bridge is constructed\nbetween the textual contents and the clustering results. We provide theoretical\nbackground for this approach. We performed experimental study showing that\n$K$-embedding approximates well Laplacian embedding under favourable block\nmatrix conditions and show that approximation is good enough under other\nconditions.",
        "translated": ""
    },
    {
        "title": "On the Effects of Regional Spelling Conventions in Retrieval Models",
        "url": "http://arxiv.org/abs/2308.00480v1",
        "pub_date": "2023-08-01",
        "summary": "One advantage of neural ranking models is that they are meant to generalise\nwell in situations of synonymity i.e. where two words have similar or identical\nmeanings. In this paper, we investigate and quantify how well various ranking\nmodels perform in a clear-cut case of synonymity: when words are simply\nexpressed in different surface forms due to regional differences in spelling\nconventions (e.g., color vs colour). We first explore the prevalence of\nAmerican and British English spelling conventions in datasets used for the\npre-training, training and evaluation of neural retrieval methods, and find\nthat American spelling conventions are far more prevalent. Despite these biases\nin the training data, we find that retrieval models often generalise well in\nthis case of synonymity. We explore the effect of document spelling\nnormalisation in retrieval and observe that all models are affected by\nnormalising the document's spelling. While they all experience a drop in\nperformance when normalised to a different spelling convention than that of the\nquery, we observe varied behaviour when the document is normalised to share the\nquery spelling convention: lexical models show improvements, dense retrievers\nremain unaffected, and re-rankers exhibit contradictory behaviour.",
        "translated": ""
    },
    {
        "title": "Generative Query Reformulation for Effective Adhoc Search",
        "url": "http://arxiv.org/abs/2308.00415v1",
        "pub_date": "2023-08-01",
        "summary": "Performing automatic reformulations of a user's query is a popular paradigm\nused in information retrieval (IR) for improving effectiveness -- as\nexemplified by the pseudo-relevance feedback approaches, which expand the query\nin order to alleviate the vocabulary mismatch problem. Recent advancements in\ngenerative language models have demonstrated their ability in generating\nresponses that are relevant to a given prompt. In light of this success, we\nseek to study the capacity of such models to perform query reformulation and\nhow they compare with long-standing query reformulation methods that use\npseudo-relevance feedback. In particular, we investigate two representative\nquery reformulation frameworks, GenQR and GenPRF. GenQR directly reformulates\nthe user's input query, while GenPRF provides additional context for the query\nby making use of pseudo-relevance feedback information. For each reformulation\nmethod, we leverage different techniques, including fine-tuning and direct\nprompting, to harness the knowledge of language models. The reformulated\nqueries produced by the generative models are demonstrated to markedly benefit\nthe effectiveness of a state-of-the-art retrieval pipeline on four TREC test\ncollections (varying from TREC 2004 Robust to the TREC 2019 Deep Learning).\nFurthermore, our results indicate that our studied generative models can\noutperform various statistical query expansion approaches while remaining\ncomparable to other existing complex neural query reformulation models, with\nthe added benefit of being simpler to implement.",
        "translated": ""
    },
    {
        "title": "Challenging the Myth of Graph Collaborative Filtering: a Reasoned and\n  Reproducibility-driven Analysis",
        "url": "http://arxiv.org/abs/2308.00404v1",
        "pub_date": "2023-08-01",
        "summary": "The success of graph neural network-based models (GNNs) has significantly\nadvanced recommender systems by effectively modeling users and items as a\nbipartite, undirected graph. However, many original graph-based works often\nadopt results from baseline papers without verifying their validity for the\nspecific configuration under analysis. Our work addresses this issue by\nfocusing on the replicability of results. We present a code that successfully\nreplicates results from six popular and recent graph recommendation models\n(NGCF, DGCF, LightGCN, SGL, UltraGCN, and GFCF) on three common benchmark\ndatasets (Gowalla, Yelp 2018, and Amazon Book). Additionally, we compare these\ngraph models with traditional collaborative filtering models that historically\nperformed well in offline evaluations. Furthermore, we extend our study to two\nnew datasets (Allrecipes and BookCrossing) that lack established setups in\nexisting literature. As the performance on these datasets differs from the\nprevious benchmarks, we analyze the impact of specific dataset characteristics\non recommendation accuracy. By investigating the information flow from users'\nneighborhoods, we aim to identify which models are influenced by intrinsic\nfeatures in the dataset structure. The code to reproduce our experiments is\navailable at: https://github.com/sisinflab/Graph-RSs-Reproducibility.",
        "translated": ""
    },
    {
        "title": "CodeBPE: Investigating Subtokenization Options for Large Language Model\n  Pretraining on Source Code",
        "url": "http://arxiv.org/abs/2308.00683v1",
        "pub_date": "2023-08-01",
        "summary": "Recent works have widely adopted large language model pretraining for source\ncode, suggested source code-specific pretraining objectives and investigated\nthe applicability of various Transformer-based language model architectures for\nsource code. This work investigates another important aspect of such models,\nnamely the effect of different subtokenization options, and aims at identifying\nmost effective and length-efficient subtokenizations, taking into account code\nspecifics. We propose subtokenziation that reduces average length by 17%\nwithout downstream performance drop, and show that a carefully chosen\nsubtokenization may improve quality by 0.5-2%, possibly with some length\nincrease.",
        "translated": ""
    },
    {
        "title": "Tool Documentation Enables Zero-Shot Tool-Usage with Large Language\n  Models",
        "url": "http://arxiv.org/abs/2308.00675v1",
        "pub_date": "2023-08-01",
        "summary": "Today, large language models (LLMs) are taught to use new tools by providing\na few demonstrations of the tool's usage. Unfortunately, demonstrations are\nhard to acquire, and can result in undesirable biased usage if the wrong\ndemonstration is chosen. Even in the rare scenario that demonstrations are\nreadily available, there is no principled selection protocol to determine how\nmany and which ones to provide. As tasks grow more complex, the selection\nsearch grows combinatorially and invariably becomes intractable. Our work\nprovides an alternative to demonstrations: tool documentation. We advocate the\nuse of tool documentation, descriptions for the individual tool usage, over\ndemonstrations. We substantiate our claim through three main empirical findings\non 6 tasks across both vision and language modalities. First, on existing\nbenchmarks, zero-shot prompts with only tool documentation are sufficient for\neliciting proper tool usage, achieving performance on par with few-shot\nprompts. Second, on a newly collected realistic tool-use dataset with hundreds\nof available tool APIs, we show that tool documentation is significantly more\nvaluable than demonstrations, with zero-shot documentation significantly\noutperforming few-shot without documentation. Third, we highlight the benefits\nof tool documentations by tackling image generation and video tracking using\njust-released unseen state-of-the-art models as tools. Finally, we highlight\nthe possibility of using tool documentation to automatically enable new\napplications: by using nothing more than the documentation of GroundingDino,\nStable Diffusion, XMem, and SAM, LLMs can re-invent the functionalities of the\njust-released Grounded-SAM and Track Anything models.",
        "translated": ""
    },
    {
        "title": "JIANG: Chinese Open Foundation Language Model",
        "url": "http://arxiv.org/abs/2308.00624v1",
        "pub_date": "2023-08-01",
        "summary": "With the advancements in large language model technology, it has showcased\ncapabilities that come close to those of human beings across various tasks.\nThis achievement has garnered significant interest from companies and\nscientific research institutions, leading to substantial investments in the\nresearch and development of these models. While numerous large models have\nemerged during this period, the majority of them have been trained primarily on\nEnglish data. Although they exhibit decent performance in other languages, such\nas Chinese, their potential remains limited due to factors like vocabulary\ndesign and training corpus. Consequently, their ability to fully express their\ncapabilities in Chinese falls short. To address this issue, we introduce the\nmodel named JIANG (Chinese pinyin of ginger) specifically designed for the\nChinese language. We have gathered a substantial amount of Chinese corpus to\ntrain the model and have also optimized its structure. The extensive\nexperimental results demonstrate the excellent performance of our model.",
        "translated": ""
    },
    {
        "title": "Unimodal Intermediate Training for Multimodal Meme Sentiment\n  Classification",
        "url": "http://arxiv.org/abs/2308.00528v1",
        "pub_date": "2023-08-01",
        "summary": "Internet Memes remain a challenging form of user-generated content for\nautomated sentiment classification. The availability of labelled memes is a\nbarrier to developing sentiment classifiers of multimodal memes. To address the\nshortage of labelled memes, we propose to supplement the training of a\nmultimodal meme classifier with unimodal (image-only and text-only) data. In\nthis work, we present a novel variant of supervised intermediate training that\nuses relatively abundant sentiment-labelled unimodal data. Our results show a\nstatistically significant performance improvement from the incorporation of\nunimodal text data. Furthermore, we show that the training set of labelled\nmemes can be reduced by 40% without reducing the performance of the downstream\nmodel.",
        "translated": ""
    },
    {
        "title": "Retrieval Augmented Generation and Representative Vector Summarization\n  for large unstructured textual data in Medical Education",
        "url": "http://arxiv.org/abs/2308.00479v1",
        "pub_date": "2023-08-01",
        "summary": "Large Language Models are increasingly being used for various tasks including\ncontent generation and as chatbots. Despite their impressive performances in\ngeneral tasks, LLMs need to be aligned when applying for domain specific tasks\nto mitigate the problems of hallucination and producing harmful answers.\nRetrieval Augmented Generation (RAG) allows to easily attach and manipulate a\nnon-parametric knowledgebases to LLMs. Applications of RAG in the field of\nmedical education are discussed in this paper. A combined extractive and\nabstractive summarization method for large unstructured textual data using\nrepresentative vectors is proposed.",
        "translated": ""
    },
    {
        "title": "Structural Embeddings of Tools for Large Language Models",
        "url": "http://arxiv.org/abs/2308.00447v1",
        "pub_date": "2023-08-01",
        "summary": "It is evident that the current state of Large Language Models (LLMs)\nnecessitates the incorporation of external tools. The lack of straightforward\nalgebraic and logical reasoning is well documented and prompted researchers to\ndevelop frameworks which allow LLMs to operate via external tools. The\nontological nature of tool utilization for a specific task can be well\nformulated with a Directed Acyclic Graph (DAG). The central aim of the paper is\nto highlight the importance of graph based approaches to LLM-tool interaction\nin near future. We propose an exemplary framework to guide the orchestration of\nexponentially increasing numbers of external tools with LLMs,where objectives\nand functionalities of tools are graph encoded hierarchically. Assuming that\ntextual segments of a Chain-of-Thought (CoT) can be imagined as a tool as\ndefined here, the graph based framework can pave new avenues in that particular\ndirection as well.",
        "translated": ""
    },
    {
        "title": "SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step\n  Reasoning",
        "url": "http://arxiv.org/abs/2308.00436v1",
        "pub_date": "2023-08-01",
        "summary": "The recent progress in large language models (LLMs), especially the invention\nof chain-of-thoughts (CoT) prompting, makes it possible to solve reasoning\nproblems. However, even the strongest LLMs are still struggling with more\ncomplicated problems that require non-linear thinking and multi-step reasoning.\nIn this work, we explore whether LLMs have the ability to recognize their own\nerrors, without resorting to external resources. In particular, we investigate\nwhether they can be used to identify individual errors within a step-by-step\nreasoning. To this end, we propose a zero-shot verification scheme to recognize\nsuch errors. We then use this verification scheme to improve question-answering\nperformance, by using it to perform weighted voting on different generated\nanswers. We test the method on three math datasets-GSM8K, MathQA, and MATH-and\nfind that it successfully recognizes errors and, in turn, increases final\npredictive performance.",
        "translated": ""
    },
    {
        "title": "Discourse-Aware Text Simplification: From Complex Sentences to Linked\n  Propositions",
        "url": "http://arxiv.org/abs/2308.00425v1",
        "pub_date": "2023-08-01",
        "summary": "Sentences that present a complex syntax act as a major stumbling block for\ndownstream Natural Language Processing applications whose predictive quality\ndeteriorates with sentence length and complexity. The task of Text\nSimplification (TS) may remedy this situation. It aims to modify sentences in\norder to make them easier to process, using a set of rewriting operations, such\nas reordering, deletion, or splitting. State-of-the-art syntactic TS approaches\nsuffer from two major drawbacks: first, they follow a very conservative\napproach in that they tend to retain the input rather than transforming it, and\nsecond, they ignore the cohesive nature of texts, where context spread across\nclauses or sentences is needed to infer the true meaning of a statement. To\naddress these problems, we present a discourse-aware TS approach that splits\nand rephrases complex English sentences within the semantic context in which\nthey occur. Based on a linguistically grounded transformation stage that uses\nclausal and phrasal disembedding mechanisms, complex sentences are transformed\ninto shorter utterances with a simple canonical structure that can be easily\nanalyzed by downstream applications. With sentence splitting, we thus address a\nTS task that has hardly been explored so far. Moreover, we introduce the notion\nof minimality in this context, as we aim to decompose source sentences into a\nset of self-contained minimal semantic units. To avoid breaking down the input\ninto a disjointed sequence of statements that is difficult to interpret because\nimportant contextual information is missing, we incorporate the semantic\ncontext between the split propositions in the form of hierarchical structures\nand semantic relationships. In that way, we generate a semantic hierarchy of\nminimal propositions that leads to a novel representation of complex assertions\nthat puts a semantic layer on top of the simplified sentences.",
        "translated": ""
    },
    {
        "title": "ZRIGF: An Innovative Multimodal Framework for Zero-Resource\n  Image-Grounded Dialogue Generation",
        "url": "http://arxiv.org/abs/2308.00400v1",
        "pub_date": "2023-08-01",
        "summary": "Image-grounded dialogue systems benefit greatly from integrating visual\ninformation, resulting in high-quality response generation. However, current\nmodels struggle to effectively utilize such information in zero-resource\nscenarios, mainly due to the disparity between image and text modalities. To\novercome this challenge, we propose an innovative multimodal framework, called\nZRIGF, which assimilates image-grounded information for dialogue generation in\nzero-resource situations. ZRIGF implements a two-stage learning strategy,\ncomprising contrastive pre-training and generative pre-training. Contrastive\npre-training includes a text-image matching module that maps images and texts\ninto a unified encoded vector space, along with a text-assisted masked image\nmodeling module that preserves pre-training visual features and fosters further\nmultimodal feature alignment. Generative pre-training employs a multimodal\nfusion module and an information transfer module to produce insightful\nresponses based on harmonized multimodal representations. Comprehensive\nexperiments conducted on both text-based and image-grounded dialogue datasets\ndemonstrate ZRIGF's efficacy in generating contextually pertinent and\ninformative responses. Furthermore, we adopt a fully zero-resource scenario in\nthe image-grounded dialogue dataset to demonstrate our framework's robust\ngeneralization capabilities in novel domains. The code is available at\nhttps://github.com/zhangbo-nlp/ZRIGF.",
        "translated": ""
    },
    {
        "title": "Tackling Hallucinations in Neural Chart Summarization",
        "url": "http://arxiv.org/abs/2308.00399v1",
        "pub_date": "2023-08-01",
        "summary": "Hallucinations in text generation occur when the system produces text that is\nnot grounded in the input. In this work, we tackle the problem of\nhallucinations in neural chart summarization. Our analysis shows that the\ntarget side of chart summarization training datasets often contains additional\ninformation, leading to hallucinations. We propose a natural language inference\n(NLI) based method to preprocess the training data and show through human\nevaluation that our method significantly reduces hallucinations. We also found\nthat shortening long-distance dependencies in the input sequence and adding\nchart-related information like title and legends improves the overall\nperformance.",
        "translated": ""
    },
    {
        "title": "Masked and Swapped Sequence Modeling for Next Novel Basket\n  Recommendation in Grocery Shopping",
        "url": "http://arxiv.org/abs/2308.01308v1",
        "pub_date": "2023-08-02",
        "summary": "Next basket recommendation (NBR) is the task of predicting the next set of\nitems based on a sequence of already purchased baskets. It is a recommendation\ntask that has been widely studied, especially in the context of grocery\nshopping. In next basket recommendation (NBR), it is useful to distinguish\nbetween repeat items, i.e., items that a user has consumed before, and explore\nitems, i.e., items that a user has not consumed before. Most NBR work either\nignores this distinction or focuses on repeat items. We formulate the next\nnovel basket recommendation (NNBR) task, i.e., the task of recommending a\nbasket that only consists of novel items, which is valuable for both real-world\napplication and NBR evaluation. We evaluate how existing NBR methods perform on\nthe NNBR task and find that, so far, limited progress has been made w.r.t. the\nNNBR task. To address the NNBR task, we propose a simple bi-directional\ntransformer basket recommendation model (BTBR), which is focused on directly\nmodeling item-to-item correlations within and across baskets instead of\nlearning complex basket representations. To properly train BTBR, we propose and\ninvestigate several masking strategies and training objectives: (i) item-level\nrandom masking, (ii) item-level select masking, (iii) basket-level all masking,\n(iv) basket-level explore masking, and (v) joint masking. In addition, an\nitem-basket swapping strategy is proposed to enrich the item interactions\nwithin the same baskets. We conduct extensive experiments on three open\ndatasets with various characteristics. The results demonstrate the\neffectiveness of BTBR and our masking and swapping strategies for the NNBR\ntask. BTBR with a properly selected masking and swapping strategy can\nsubstantially improve NNBR performance.",
        "translated": ""
    },
    {
        "title": "A Survey on Popularity Bias in Recommender Systems",
        "url": "http://arxiv.org/abs/2308.01118v1",
        "pub_date": "2023-08-02",
        "summary": "Recommender systems help people find relevant content in a personalized way.\nOne main promise of such systems is that they are able to increase the\nvisibility of items in the long tail, i.e., the lesser-known items in a\ncatalogue. Existing research, however, suggests that in many situations today's\nrecommendation algorithms instead exhibit a popularity bias, meaning that they\noften focus on rather popular items in their recommendations. Such a bias may\nnot only lead to limited value of the recommendations for consumers and\nproviders in the short run, but it may also cause undesired reinforcement\neffects over time. In this paper, we discuss the potential reasons for\npopularity bias and we review existing approaches to detect, quantify and\nmitigate popularity bias in recommender systems. Our survey therefore includes\nboth an overview of the computational metrics used in the literature as well as\na review of the main technical approaches to reduce the bias. We furthermore\ncritically discuss today's literature, where we observe that the research is\nalmost entirely based on computational experiments and on certain assumptions\nregarding the practical effects of including long-tail items in the\nrecommendations.",
        "translated": ""
    },
    {
        "title": "Towards Better Query Classification with Multi-Expert Knowledge\n  Condensation in JD Ads Search",
        "url": "http://arxiv.org/abs/2308.01098v1",
        "pub_date": "2023-08-02",
        "summary": "Search query classification, as an effective way to understand user intents,\nis of great importance in real-world online ads systems. To ensure a lower\nlatency, a shallow model (e.g. FastText) is widely used for efficient online\ninference. However, the representation ability of the FastText model is\ninsufficient, resulting in poor classification performance, especially on some\nlow-frequency queries and tailed categories. Using a deeper and more complex\nmodel (e.g. BERT) is an effective solution, but it will cause a higher online\ninference latency and more expensive computing costs. Thus, how to juggle both\ninference efficiency and classification performance is obviously of great\npractical importance. To overcome this challenge, in this paper, we propose\nknowledge condensation (KC), a simple yet effective knowledge distillation\nframework to boost the classification performance of the online FastText model\nunder strict low latency constraints. Specifically, we propose to train an\noffline BERT model to retrieve more potentially relevant data. Benefiting from\nits powerful semantic representation, more relevant labels not exposed in the\nhistorical data will be added into the training set for better FastText model\ntraining. Moreover, a novel distribution-diverse multi-expert learning strategy\nis proposed to further improve the mining ability of relevant data. By training\nmultiple BERT models from different data distributions, it can respectively\nperform better at high, middle, and low-frequency search queries. The model\nensemble from multi-distribution makes its retrieval ability more powerful. We\nhave deployed two versions of this framework in JD search, and both offline\nexperiments and online A/B testing from multiple datasets have validated the\neffectiveness of the proposed approach.",
        "translated": ""
    },
    {
        "title": "Rethinking Similarity Search: Embracing Smarter Mechanisms over Smarter\n  Data",
        "url": "http://arxiv.org/abs/2308.00909v1",
        "pub_date": "2023-08-02",
        "summary": "In this vision paper, we propose a shift in perspective for improving the\neffectiveness of similarity search. Rather than focusing solely on enhancing\nthe data quality, particularly machine learning-generated embeddings, we\nadvocate for a more comprehensive approach that also enhances the underpinning\nsearch mechanisms. We highlight three novel avenues that call for a\nredefinition of the similarity search problem: exploiting implicit data\nstructures and distributions, engaging users in an iterative feedback loop, and\nmoving beyond a single query vector. These novel pathways have gained relevance\nin emerging applications such as large-scale language models, video clip\nretrieval, and data labeling. We discuss the corresponding research challenges\nposed by these new problem areas and share insights from our preliminary\ndiscoveries.",
        "translated": ""
    },
    {
        "title": "User-Controllable Recommendation via Counterfactual Retrospective and\n  Prospective Explanations",
        "url": "http://arxiv.org/abs/2308.00894v1",
        "pub_date": "2023-08-02",
        "summary": "Modern recommender systems utilize users' historical behaviors to generate\npersonalized recommendations. However, these systems often lack user\ncontrollability, leading to diminished user satisfaction and trust in the\nsystems. Acknowledging the recent advancements in explainable recommender\nsystems that enhance users' understanding of recommendation mechanisms, we\npropose leveraging these advancements to improve user controllability. In this\npaper, we present a user-controllable recommender system that seamlessly\nintegrates explainability and controllability within a unified framework. By\nproviding both retrospective and prospective explanations through\ncounterfactual reasoning, users can customize their control over the system by\ninteracting with these explanations.\n  Furthermore, we introduce and assess two attributes of controllability in\nrecommendation systems: the complexity of controllability and the accuracy of\ncontrollability. Experimental evaluations on MovieLens and Yelp datasets\nsubstantiate the effectiveness of our proposed framework. Additionally, our\nexperiments demonstrate that offering users control options can potentially\nenhance recommendation accuracy in the future. Source code and data are\navailable at \\url{https://github.com/chrisjtan/ucr}.",
        "translated": ""
    },
    {
        "title": "More Context, Less Distraction: Visual Classification by Inferring and\n  Conditioning on Contextual Attributes",
        "url": "http://arxiv.org/abs/2308.01313v1",
        "pub_date": "2023-08-02",
        "summary": "CLIP, as a foundational vision language model, is widely used in zero-shot\nimage classification due to its ability to understand various visual concepts\nand natural language descriptions. However, how to fully leverage CLIP's\nunprecedented human-like understanding capabilities to achieve better zero-shot\nclassification is still an open question. This paper draws inspiration from the\nhuman visual perception process: a modern neuroscience view suggests that in\nclassifying an object, humans first infer its class-independent attributes\n(e.g., background and orientation) which help separate the foreground object\nfrom the background, and then make decisions based on this information.\nInspired by this, we observe that providing CLIP with contextual attributes\nimproves zero-shot classification and mitigates reliance on spurious features.\nWe also observe that CLIP itself can reasonably infer the attributes from an\nimage. With these observations, we propose a training-free, two-step zero-shot\nclassification method named PerceptionCLIP. Given an image, it first infers\ncontextual attributes (e.g., background) and then performs object\nclassification conditioning on them. Our experiments show that PerceptionCLIP\nachieves better generalization, group robustness, and better interpretability.\nFor example, PerceptionCLIP with ViT-L/14 improves the worst group accuracy by\n16.5% on the Waterbirds dataset and by 3.5% on CelebA.",
        "translated": ""
    },
    {
        "title": "Fighting Fire with Fire: Can ChatGPT Detect AI-generated Text?",
        "url": "http://arxiv.org/abs/2308.01284v1",
        "pub_date": "2023-08-02",
        "summary": "Large language models (LLMs) such as ChatGPT are increasingly being used for\nvarious use cases, including text content generation at scale. Although\ndetection methods for such AI-generated text exist already, we investigate\nChatGPT's performance as a detector on such AI-generated text, inspired by\nworks that use ChatGPT as a data labeler or annotator. We evaluate the\nzero-shot performance of ChatGPT in the task of human-written vs. AI-generated\ntext detection, and perform experiments on publicly available datasets. We\nempirically investigate if ChatGPT is symmetrically effective in detecting\nAI-generated or human-written text. Our findings provide insight on how ChatGPT\nand similar LLMs may be leveraged in automated detection pipelines by simply\nfocusing on solving a specific aspect of the problem and deriving the rest from\nthat solution. All code and data is available at\n\\url{https://github.com/AmritaBh/ChatGPT-as-Detector}.",
        "translated": ""
    },
    {
        "title": "Exploring the psychology of GPT-4's Moral and Legal Reasoning",
        "url": "http://arxiv.org/abs/2308.01264v1",
        "pub_date": "2023-08-02",
        "summary": "Large language models have been used as the foundation of highly\nsophisticated artificial intelligences, capable of delivering human-like\nresponses to probes about legal and moral issues. However, these models are\nunreliable guides to their own inner workings, and even the engineering teams\nbehind their creation are unable to explain exactly how they came to develop\nall of the capabilities they currently have. The emerging field of machine\npsychology seeks to gain insight into the processes and concepts that these\nmodels possess. In this paper, we employ the methods of psychology to probe\ninto GPT-4's moral and legal reasoning. More specifically, we investigate the\nsimilarities and differences between GPT-4 and humans when it comes to\nintentionality ascriptions, judgments about causation, the morality of\ndeception, moral foundations, the impact of moral luck on legal judgments, the\nconcept of consent, and rule violation judgments. We find high correlations\nbetween human and AI responses, but also several significant systematic\ndifferences between them. We conclude with a discussion of the philosophical\nimplications of our findings.",
        "translated": ""
    },
    {
        "title": "XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in\n  Large Language Models",
        "url": "http://arxiv.org/abs/2308.01263v1",
        "pub_date": "2023-08-02",
        "summary": "Without proper safeguards, large language models will readily follow\nmalicious instructions and generate toxic content. This motivates safety\nefforts such as red-teaming and large-scale feedback learning, which aim to\nmake models both helpful and harmless. However, there is a tension between\nthese two objectives, since harmlessness requires models to refuse complying\nwith unsafe prompts, and thus not be helpful. Recent anecdotal evidence\nsuggests that some models may have struck a poor balance, so that even clearly\nsafe prompts are refused if they use similar language to unsafe prompts or\nmention sensitive topics. In this paper, we introduce a new test suite called\nXSTest to identify such eXaggerated Safety behaviours in a structured and\nsystematic way. In its current form, XSTest comprises 200 safe prompts across\nten prompt types that well-calibrated models should not refuse to comply with.\nWe describe XSTest's creation and composition, and use the test suite to\nhighlight systematic failure modes in a recently-released state-of-the-art\nlanguage model.",
        "translated": ""
    },
    {
        "title": "Evaluating Instruction-Tuned Large Language Models on Code Comprehension\n  and Generation",
        "url": "http://arxiv.org/abs/2308.01240v1",
        "pub_date": "2023-08-02",
        "summary": "In this work, we evaluate 10 open-source instructed LLMs on four\nrepresentative code comprehension and generation tasks. We have the following\nmain findings. First, for the zero-shot setting, instructed LLMs are very\ncompetitive on code comprehension and generation tasks and sometimes even\nbetter than small SOTA models specifically fine-tuned on each downstream task.\nWe also find that larger instructed LLMs are not always better on code-related\ntasks. Second, for the few-shot setting, we find that adding demonstration\nexamples substantially helps instructed LLMs perform better on most code\ncomprehension and generation tasks; however, the examples would sometimes\ninduce unstable or even worse performance. Furthermore, we find widely-used\nBM25-based shot selection strategy significantly outperforms the basic random\nselection or fixed selection only on generation problems. Third, for the\nfine-tuning setting, we find that fine-tuning could further improve the model\nperformance on downstream code comprehension and generation tasks compared to\nthe zero-shot/one-shot performance. In addition, after being fine-tuned on the\nsame downstream task dataset, instructed LLMs outperform both the small SOTA\nmodels and similar-scaled LLMs without instruction tuning. Based on our\nfindings, we further present practical implications on model and usage\nrecommendation, performance and cost trade-offs, and future direction.",
        "translated": ""
    },
    {
        "title": "Grounded Image Text Matching with Mismatched Relation Reasoning",
        "url": "http://arxiv.org/abs/2308.01236v1",
        "pub_date": "2023-08-02",
        "summary": "This paper introduces Grounded Image Text Matching with Mismatched Relation\n(GITM-MR), a novel visual-linguistic joint task that evaluates the relation\nunderstanding capabilities of transformer-based pre-trained models. GITM-MR\nrequires a model to first determine if an expression describes an image, then\nlocalize referred objects or ground the mismatched parts of the text. We\nprovide a benchmark for evaluating pre-trained models on this task, with a\nfocus on the challenging settings of limited data and out-of-distribution\nsentence lengths. Our evaluation demonstrates that pre-trained models lack data\nefficiency and length generalization ability. To address this, we propose the\nRelation-sensitive Correspondence Reasoning Network (RCRN), which incorporates\nrelation-aware reasoning via bi-directional message propagation guided by\nlanguage structure. RCRN can be interpreted as a modular program and delivers\nstrong performance in both length generalization and data efficiency.",
        "translated": ""
    },
    {
        "title": "Do Multilingual Language Models Think Better in English?",
        "url": "http://arxiv.org/abs/2308.01223v1",
        "pub_date": "2023-08-02",
        "summary": "Translate-test is a popular technique to improve the performance of\nmultilingual language models. This approach works by translating the input into\nEnglish using an external machine translation system, and running inference\nover the translated input. However, these improvements can be attributed to the\nuse of a separate translation system, which is typically trained on large\namounts of parallel data not seen by the language model. In this work, we\nintroduce a new approach called self-translate, which overcomes the need of an\nexternal translation system by leveraging the few-shot translation capabilities\nof multilingual language models. Experiments over 5 tasks show that\nself-translate consistently outperforms direct inference, demonstrating that\nlanguage models are unable to leverage their full multilingual potential when\nprompted in non-English languages. Our code is available at\nhttps://github.com/juletx/self-translate.",
        "translated": ""
    },
    {
        "title": "Global Hierarchical Neural Networks using Hierarchical Softmax",
        "url": "http://arxiv.org/abs/2308.01210v1",
        "pub_date": "2023-08-02",
        "summary": "This paper presents a framework in which hierarchical softmax is used to\ncreate a global hierarchical classifier. The approach is applicable for any\nclassification task where there is a natural hierarchy among classes. We show\nempirical results on four text classification datasets. In all datasets the\nhierarchical softmax improved on the regular softmax used in a flat classifier\nin terms of macro-F1 and macro-recall. In three out of four datasets\nhierarchical softmax achieved a higher micro-accuracy and macro-precision.",
        "translated": ""
    },
    {
        "title": "Arithmetic with Language Models: from Memorization to Computation",
        "url": "http://arxiv.org/abs/2308.01154v1",
        "pub_date": "2023-08-02",
        "summary": "A better understanding of the emergent computation and problem-solving\ncapabilities of recent large language models is of paramount importance to\nfurther improve them and broaden their applicability. This work investigates\nhow a language model, trained to predict the next token, can perform arithmetic\ncomputations generalizing beyond training data. Binary addition and\nmultiplication constitute a good testbed for this purpose, since they require a\nvery small vocabulary and exhibit relevant input/output discontinuities making\nsmooth input interpolation ineffective for novel data. We successfully trained\na light language model to learn these tasks and ran a number of experiments to\ninvestigate the extrapolation capabilities and internal information processing.\nOur findings support the hypotheses that the language model works as an\nEncoding-Regression-Decoding machine where the computation takes place in the\nvalue space once the input token representation is mapped to an appropriate\ninternal representation.",
        "translated": ""
    },
    {
        "title": "ADS-Cap: A Framework for Accurate and Diverse Stylized Captioning with\n  Unpaired Stylistic Corpora",
        "url": "http://arxiv.org/abs/2308.01143v1",
        "pub_date": "2023-08-02",
        "summary": "Generating visually grounded image captions with specific linguistic styles\nusing unpaired stylistic corpora is a challenging task, especially since we\nexpect stylized captions with a wide variety of stylistic patterns. In this\npaper, we propose a novel framework to generate Accurate and Diverse Stylized\nCaptions (ADS-Cap). Our ADS-Cap first uses a contrastive learning module to\nalign the image and text features, which unifies paired factual and unpaired\nstylistic corpora during the training process. A conditional variational\nauto-encoder is then used to automatically memorize diverse stylistic patterns\nin latent space and enhance diversity through sampling. We also design a simple\nbut effective recheck module to boost style accuracy by filtering\nstyle-specific captions. Experimental results on two widely used stylized image\ncaptioning datasets show that regarding consistency with the image, style\naccuracy and diversity, ADS-Cap achieves outstanding performances compared to\nvarious baselines. We finally conduct extensive analyses to understand the\neffectiveness of our method. Our code is available at\nhttps://github.com/njucckevin/ADS-Cap.",
        "translated": ""
    },
    {
        "title": "MAP: A Model-agnostic Pretraining Framework for Click-through Rate\n  Prediction",
        "url": "http://arxiv.org/abs/2308.01737v1",
        "pub_date": "2023-08-03",
        "summary": "With the widespread application of personalized online services,\nclick-through rate (CTR) prediction has received more and more attention and\nresearch. The most prominent features of CTR prediction are its multi-field\ncategorical data format, and vast and daily-growing data volume. The large\ncapacity of neural models helps digest such massive amounts of data under the\nsupervised learning paradigm, yet they fail to utilize the substantial data to\nits full potential, since the 1-bit click signal is not sufficient to guide the\nmodel to learn capable representations of features and instances. The\nself-supervised learning paradigm provides a more promising pretrain-finetune\nsolution to better exploit the large amount of user click logs, and learn more\ngeneralized and effective representations. However, self-supervised learning\nfor CTR prediction is still an open question, since current works on this line\nare only preliminary and rudimentary. To this end, we propose a Model-agnostic\npretraining (MAP) framework that applies feature corruption and recovery on\nmulti-field categorical data, and more specifically, we derive two practical\nalgorithms: masked feature prediction (MFP) and replaced feature detection\n(RFD). MFP digs into feature interactions within each instance through masking\nand predicting a small portion of input features, and introduces noise\ncontrastive estimation (NCE) to handle large feature spaces. RFD further turns\nMFP into a binary classification mode through replacing and detecting changes\nin input features, making it even simpler and more effective for CTR\npretraining. Our extensive experiments on two real-world large-scale datasets\n(i.e., Avazu, Criteo) demonstrate the advantages of these two methods on\nseveral strong backbones (e.g., DCNv2, DeepFM), and achieve new\nstate-of-the-art performance in terms of both effectiveness and efficiency for\nCTR prediction.",
        "translated": ""
    },
    {
        "title": "Evaluating ChatGPT text-mining of clinical records for obesity\n  monitoring",
        "url": "http://arxiv.org/abs/2308.01666v1",
        "pub_date": "2023-08-03",
        "summary": "Background: Veterinary clinical narratives remain a largely untapped resource\nfor addressing complex diseases. Here we compare the ability of a large\nlanguage model (ChatGPT) and a previously developed regular expression (RegexT)\nto identify overweight body condition scores (BCS) in veterinary narratives.\nMethods: BCS values were extracted from 4,415 anonymised clinical narratives\nusing either RegexT or by appending the narrative to a prompt sent to ChatGPT\ncoercing the model to return the BCS information. Data were manually reviewed\nfor comparison. Results: The precision of RegexT was higher (100%, 95% CI\n94.81-100%) than the ChatGPT (89.3%; 95% CI82.75-93.64%). However, the recall\nof ChatGPT (100%. 95% CI 96.18-100%) was considerably higher than that of\nRegexT (72.6%, 95% CI 63.92-79.94%). Limitations: Subtle prompt engineering is\nneeded to improve ChatGPT output. Conclusions: Large language models create\ndiverse opportunities and, whilst complex, present an intuitive interface to\ninformation but require careful implementation to avoid unpredictable errors.",
        "translated": ""
    },
    {
        "title": "Fast Slate Policy Optimization: Going Beyond Plackett-Luce",
        "url": "http://arxiv.org/abs/2308.01566v1",
        "pub_date": "2023-08-03",
        "summary": "An increasingly important building block of large scale machine learning\nsystems is based on returning slates; an ordered lists of items given a query.\nApplications of this technology include: search, information retrieval and\nrecommender systems. When the action space is large, decision systems are\nrestricted to a particular structure to complete online queries quickly. This\npaper addresses the optimization of these large scale decision systems given an\narbitrary reward function. We cast this learning problem in a policy\noptimization framework and propose a new class of policies, born from a novel\nrelaxation of decision functions. This results in a simple, yet efficient\nlearning algorithm that scales to massive action spaces. We compare our method\nto the commonly adopted Plackett-Luce policy class and demonstrate the\neffectiveness of our approach on problems with action space sizes in the order\nof millions.",
        "translated": ""
    },
    {
        "title": "Density Weighting for Multi-Interest Personalized Recommendation",
        "url": "http://arxiv.org/abs/2308.01563v1",
        "pub_date": "2023-08-03",
        "summary": "Using multiple user representations (MUR) to model user behavior instead of a\nsingle user representation (SUR) has been shown to improve personalization in\nrecommendation systems. However, the performance gains observed with MUR can be\nsensitive to the skewness in the item and/or user interest distribution. When\nthe data distribution is highly skewed, the gains observed by learning multiple\nrepresentations diminish since the model dominates on head items/interests,\nleading to poor performance on tail items. Robustness to data sparsity is\ntherefore essential for MUR-based approaches to achieve good performance for\nrecommendations. Yet, research in MUR and data imbalance have largely been done\nindependently. In this paper, we delve deeper into the shortcomings of MUR\ninferred from imbalanced data distributions. We make several contributions: (1)\nUsing synthetic datasets, we demonstrate the sensitivity of MUR with respect to\ndata imbalance, (2) To improve MUR for tail items, we propose an iterative\ndensity weighting scheme (IDW) with user tower calibration to mitigate the\neffect of training over long-tail distribution on personalization, and (3)\nThrough extensive experiments on three real-world benchmarks, we demonstrate\nIDW outperforms other alternatives that address data imbalance.",
        "translated": ""
    },
    {
        "title": "Reasoning in Large Language Models Through Symbolic Math Word Problems",
        "url": "http://arxiv.org/abs/2308.01906v1",
        "pub_date": "2023-08-03",
        "summary": "Large language models (LLMs) have revolutionized NLP by solving downstream\ntasks with little to no labeled data. Despite their versatile abilities, the\nlarger question of their ability to reason remains ill-understood. This paper\naddresses reasoning in math word problems (MWPs) by studying symbolic versions\nof the numeric problems, since a symbolic expression is a \"concise explanation\"\nof the numeric answer. We create and use a symbolic version of the SVAMP\ndataset and find that GPT-3's davinci-002 model also has good zero-shot\naccuracy on symbolic MWPs. To evaluate the faithfulness of the model's\nreasoning, we go beyond accuracy and additionally evaluate the alignment\nbetween the final answer and the outputted reasoning, which correspond to\nnumeric and symbolic answers respectively for MWPs. We explore a self-prompting\napproach to encourage the symbolic reasoning to align with the numeric answer,\nthus equipping the LLM with the ability to provide a concise and verifiable\nreasoning and making it more interpretable. Surprisingly, self-prompting also\nimproves the symbolic accuracy to be higher than both the numeric and symbolic\naccuracies, thus providing an ensembling effect. The SVAMP_Sym dataset will be\nreleased for future research on symbolic math problems.",
        "translated": ""
    },
    {
        "title": "How many preprints have actually been printed and why: a case study of\n  computer science preprints on arXiv",
        "url": "http://arxiv.org/abs/2308.01899v1",
        "pub_date": "2023-08-03",
        "summary": "Preprints play an increasingly critical role in academic communities. There\nare many reasons driving researchers to post their manuscripts to preprint\nservers before formal submission to journals or conferences, but the use of\npreprints has also sparked considerable controversy, especially surrounding the\nclaim of priority. In this paper, a case study of computer science preprints\nsubmitted to arXiv from 2008 to 2017 is conducted to quantify how many\npreprints have eventually been printed in peer-reviewed venues. Among those\npublished manuscripts, some are published under different titles and without an\nupdate to their preprints on arXiv. In the case of these manuscripts, the\ntraditional fuzzy matching method is incapable of mapping the preprint to the\nfinal published version. In view of this issue, we introduce a semantics-based\nmapping method with the employment of Bidirectional Encoder Representations\nfrom Transformers (BERT). With this new mapping method and a plurality of data\nsources, we find that 66% of all sampled preprints are published under\nunchanged titles and 11% are published under different titles and with other\nmodifications. A further analysis was then performed to investigate why these\npreprints but not others were accepted for publication. Our comparison reveals\nthat in the field of computer science, published preprints feature adequate\nrevisions, multiple authorship, detailed abstract and introduction, extensive\nand authoritative references and available source code.",
        "translated": ""
    },
    {
        "title": "Athena 2.0: Discourse and User Modeling in Open Domain Dialogue",
        "url": "http://arxiv.org/abs/2308.01887v1",
        "pub_date": "2023-08-03",
        "summary": "Conversational agents are consistently growing in popularity and many people\ninteract with them every day. While many conversational agents act as personal\nassistants, they can have many different goals. Some are task-oriented, such as\nproviding customer support for a bank or making a reservation. Others are\ndesigned to be empathetic and to form emotional connections with the user. The\nAlexa Prize Challenge aims to create a socialbot, which allows the user to\nengage in coherent conversations, on a range of popular topics that will\ninterest the user. Here we describe Athena 2.0, UCSC's conversational agent for\nAmazon's Socialbot Grand Challenge 4. Athena 2.0 utilizes a novel\nknowledge-grounded discourse model that tracks the entity links that Athena\nintroduces into the dialogue, and uses them to constrain named-entity\nrecognition and linking, and coreference resolution. Athena 2.0 also relies on\na user model to personalize topic selection and other aspects of the\nconversation to individual users.",
        "translated": ""
    },
    {
        "title": "Thespian: Multi-Character Text Role-Playing Game Agents",
        "url": "http://arxiv.org/abs/2308.01872v1",
        "pub_date": "2023-08-03",
        "summary": "Text-adventure games and text role-playing games are grand challenges for\nreinforcement learning game playing agents. Text role-playing games are\nopen-ended environments where an agent must faithfully play a particular\ncharacter. We consider the distinction between characters and actors, where an\nactor agent has the ability to play multiple characters. We present a framework\nwe call a thespian agent that can learn to emulate multiple characters along\nwith a soft prompt that can be used to direct it as to which character to play\nat any time. We further describe an attention mechanism that allows the agent\nto learn new characters that are based on previously learned characters in a\nfew-shot fashion. We show that our agent outperforms the state of the art agent\nframework in multi-character learning and few-shot learning.",
        "translated": ""
    },
    {
        "title": "Tag Prediction of Competitive Programming Problems using Deep Learning\n  Techniques",
        "url": "http://arxiv.org/abs/2308.01863v1",
        "pub_date": "2023-08-03",
        "summary": "In the past decade, the amount of research being done in the fields of\nmachine learning and deep learning, predominantly in the area of natural\nlanguage processing (NLP), has risen dramatically. A well-liked method for\ndeveloping programming abilities like logic building and problem solving is\ncompetitive programming. It can be tough for novices and even veteran\nprogrammers to traverse the wide collection of questions due to the massive\nnumber of accessible questions and the variety of themes, levels of difficulty,\nand questions offered. In order to help programmers find questions that are\nappropriate for their knowledge and interests, there is a need for an automated\nmethod. This can be done using automated tagging of the questions using Text\nClassification. Text classification is one of the important tasks widely\nresearched in the field of Natural Language Processing. In this paper, we\npresent a way to use text classification techniques to determine the domain of\na competitive programming problem. A variety of models, including are\nimplemented LSTM, GRU, and MLP. The dataset has been scraped from Codeforces, a\nmajor competitive programming website. A total of 2400 problems were scraped\nand preprocessed, which we used as a dataset for our training and testing of\nmodels. The maximum accuracy reached using our model is 78.0% by MLP(Multi\nLayer Perceptron).",
        "translated": ""
    },
    {
        "title": "Wider and Deeper LLM Networks are Fairer LLM Evaluators",
        "url": "http://arxiv.org/abs/2308.01862v1",
        "pub_date": "2023-08-03",
        "summary": "Measuring the quality of responses generated by LLMs is a challenging task,\nparticularly when it comes to evaluating whether the response is aligned with\nhuman preference. A novel approach involves using the LLM itself to make\nevaluation and stabilizing the results through multiple independent\nevaluations, similar to a single-layer narrow LLM network. This network\nconsists of a fixed number of neurons, with each neuron being the same LLM. In\nthis paper, we draw upon the extensive research on deep neural networks to\nexplore whether deeper and wider networks can lead to fairer evaluations.\nSpecifically, inspired by the observation that different neurons in a neural\nnetwork are responsible for detecting different concepts, we first adaptively\ngenerate as many neuron roles as possible for each evaluation sample. Each\nperspective corresponds to the role of a specific LLM neuron in the first\nlayer. In subsequent layers, we follow the idea that higher layers in deep\nnetworks are responsible for more comprehensive features, each layer receives\nrepresentations from all neurons in the previous layer, integrating the locally\nlearned evaluation information to obtain a more comprehensive evaluation\nresult. Interestingly, this network design resembles the process of academic\npaper reviewing. To validate the effectiveness of our method, we construct the\nlargest and most diverse English evaluation benchmark LLMEval$^2$ for LLM\nevaluators, comprising 15 tasks, 8 abilities, and 2,553 samples. Experimental\nresults demonstrate that a wider network (involving many reviewers) with 2\nlayers (one round of discussion) performs the best, improving kappa correlation\ncoefficient from 0.28 to 0.34. We also leverage WideDeep to aid in the\nassessment of Chinese LLMs, which has accelerated the evaluation time by 4.6\ntimes, resulting in a 60% cost saving. WideDeep achieves a remarkable 93%\nagreement level among humans.",
        "translated": ""
    },
    {
        "title": "ClassEval: A Manually-Crafted Benchmark for Evaluating LLMs on\n  Class-level Code Generation",
        "url": "http://arxiv.org/abs/2308.01861v1",
        "pub_date": "2023-08-03",
        "summary": "In this work, we make the first attempt to evaluate LLMs in a more\nchallenging code generation scenario, i.e. class-level code generation. We\nfirst manually construct the first class-level code generation benchmark\nClassEval of 100 class-level Python code generation tasks with approximately\n500 person-hours. Based on it, we then perform the first study of 11\nstate-of-the-art LLMs on class-level code generation. Based on our results, we\nhave the following main findings. First, we find that all existing LLMs show\nmuch worse performance on class-level code generation compared to on standalone\nmethod-level code generation benchmarks like HumanEval; and the method-level\ncoding ability cannot equivalently reflect the class-level coding ability among\nLLMs. Second, we find that GPT-4 and GPT-3.5 still exhibit dominate superior\nthan other LLMs on class-level code generation, and the second-tier models\nincludes Instruct-Starcoder, Instruct-Codegen, and Wizardcoder with very\nsimilar performance. Third, we find that generating the entire class all at\nonce (i.e. holistic generation strategy) is the best generation strategy only\nfor GPT-4 and GPT-3.5, while method-by-method generation (i.e. incremental and\ncompositional) is better strategies for the other models with limited ability\nof understanding long instructions and utilizing the middle information.\nLastly, we find the limited model ability of generating method-dependent code\nand discuss the frequent error types in generated classes. Our benchmark is\navailable at https://github.com/FudanSELab/ClassEval.",
        "translated": ""
    },
    {
        "title": "Curricular Transfer Learning for Sentence Encoded Tasks",
        "url": "http://arxiv.org/abs/2308.01849v1",
        "pub_date": "2023-08-03",
        "summary": "Fine-tuning language models in a downstream task is the standard approach for\nmany state-of-the-art methodologies in the field of NLP. However, when the\ndistribution between the source task and target task drifts, \\textit{e.g.},\nconversational environments, these gains tend to be diminished. This article\nproposes a sequence of pre-training steps (a curriculum) guided by \"data\nhacking\" and grammar analysis that allows further gradual adaptation between\npre-training distributions. In our experiments, we acquire a considerable\nimprovement from our method compared to other known pre-training approaches for\nthe MultiWoZ task.",
        "translated": ""
    },
    {
        "title": "XNLP: An Interactive Demonstration System for Universal Structured NLP",
        "url": "http://arxiv.org/abs/2308.01846v1",
        "pub_date": "2023-08-03",
        "summary": "Structured Natural Language Processing (XNLP) is an important subset of NLP\nthat entails understanding the underlying semantic or syntactic structure of\ntexts, which serves as a foundational component for many downstream\napplications. Despite certain recent efforts to explore universal solutions for\nspecific categories of XNLP tasks, a comprehensive and effective approach for\nunifying all XNLP tasks long remains underdeveloped. In the meanwhile, while\nXNLP demonstration systems are vital for researchers exploring various XNLP\ntasks, existing platforms can be limited to, e.g., supporting few XNLP tasks,\nlacking interactivity and universalness. To this end, we propose an advanced\nXNLP demonstration platform, where we propose leveraging LLM to achieve\nuniversal XNLP, with one model for all with high generalizability. Overall, our\nsystem advances in multiple aspects, including universal XNLP modeling, high\nperformance, interpretability, scalability, and interactivity, providing a\nunified platform for exploring diverse XNLP tasks in the community. XNLP is\nonline: https://xnlp.haofei.vip",
        "translated": ""
    },
    {
        "title": "The Capability of Large Language Models to Measure Psychiatric\n  Functioning",
        "url": "http://arxiv.org/abs/2308.01834v1",
        "pub_date": "2023-08-03",
        "summary": "The current work investigates the capability of Large language models (LLMs)\nthat are explicitly trained on large corpuses of medical knowledge (Med-PaLM 2)\nto predict psychiatric functioning from patient interviews and clinical\ndescriptions without being trained to do so. To assess this, n = 145 depression\nand n =115 PTSD assessments and n = 46 clinical case studies across high\nprevalence/high comorbidity disorders (Depressive, Anxiety, Psychotic, trauma\nand stress, Addictive disorders) were analyzed using prompts to extract\nestimated clinical scores and diagnoses. Results demonstrate that Med-PaLM 2 is\ncapable of assessing psychiatric functioning across a range of psychiatric\nconditions with the strongest performance being the prediction of depression\nscores based on standardized assessments (Accuracy range= 0.80 - 0.84) which\nwere statistically indistinguishable from human clinical raters t(1,144) =\n1.20; p = 0.23. Results show the potential for general clinical language models\nto flexibly predict psychiatric risk based on free descriptions of functioning\nfrom both patients and clinicians.",
        "translated": ""
    },
    {
        "title": "Adaptive Preferential Attached kNN Graph With Distribution-Awareness",
        "url": "http://arxiv.org/abs/2308.02442v1",
        "pub_date": "2023-08-04",
        "summary": "Graph-based kNN algorithms have garnered widespread popularity for machine\nlearning tasks, due to their simplicity and effectiveness. However, the\nconventional kNN graph's reliance on a fixed value of k can hinder its\nperformance, especially in scenarios involving complex data distributions.\nMoreover, like other classification models, the presence of ambiguous samples\nalong decision boundaries often presents a challenge, as they are more prone to\nincorrect classification. To address these issues, we propose the Preferential\nAttached k-Nearest Neighbors Graph (paNNG), which combines adaptive kNN with\ndistribution-based graph construction. By incorporating distribution\ninformation, paNNG can significantly improve performance for ambiguous samples\nby \"pulling\" them towards their original classes and hence enable enhanced\noverall accuracy and generalization capability. Through rigorous evaluations on\ndiverse benchmark datasets, paNNG outperforms state-of-the-art algorithms,\nshowcasing its adaptability and efficacy across various real-world scenarios.",
        "translated": ""
    },
    {
        "title": "RAHNet: Retrieval Augmented Hybrid Network for Long-tailed Graph\n  Classification",
        "url": "http://arxiv.org/abs/2308.02335v1",
        "pub_date": "2023-08-04",
        "summary": "Graph classification is a crucial task in many real-world multimedia\napplications, where graphs can represent various multimedia data types such as\nimages, videos, and social networks. Previous efforts have applied graph neural\nnetworks (GNNs) in balanced situations where the class distribution is\nbalanced. However, real-world data typically exhibit long-tailed class\ndistributions, resulting in a bias towards the head classes when using GNNs and\nlimited generalization ability over the tail classes. Recent approaches mainly\nfocus on re-balancing different classes during model training, which fails to\nexplicitly introduce new knowledge and sacrifices the performance of the head\nclasses. To address these drawbacks, we propose a novel framework called\nRetrieval Augmented Hybrid Network (RAHNet) to jointly learn a robust feature\nextractor and an unbiased classifier in a decoupled manner. In the feature\nextractor training stage, we develop a graph retrieval module to search for\nrelevant graphs that directly enrich the intra-class diversity for the tail\nclasses. Moreover, we innovatively optimize a category-centered supervised\ncontrastive loss to obtain discriminative representations, which is more\nsuitable for long-tailed scenarios. In the classifier fine-tuning stage, we\nbalance the classifier weights with two weight regularization techniques, i.e.,\nMax-norm and weight decay. Experiments on various popular benchmarks verify the\nsuperiority of the proposed method against state-of-the-art approaches.",
        "translated": ""
    },
    {
        "title": "Learning to Select the Relevant History Turns in Conversational Question\n  Answering",
        "url": "http://arxiv.org/abs/2308.02294v1",
        "pub_date": "2023-08-04",
        "summary": "The increasing demand for the web-based digital assistants has given a rapid\nrise in the interest of the Information Retrieval (IR) community towards the\nfield of conversational question answering (ConvQA). However, one of the\ncritical aspects of ConvQA is the effective selection of conversational history\nturns to answer the question at hand. The dependency between relevant history\nselection and correct answer prediction is an intriguing but under-explored\narea. The selected relevant context can better guide the system so as to where\nexactly in the passage to look for an answer. Irrelevant context, on the other\nhand, brings noise to the system, thereby resulting in a decline in the model's\nperformance. In this paper, we propose a framework, DHS-ConvQA (Dynamic History\nSelection in Conversational Question Answering), that first generates the\ncontext and question entities for all the history turns, which are then pruned\non the basis of similarity they share in common with the question at hand. We\nalso propose an attention-based mechanism to re-rank the pruned terms based on\ntheir calculated weights of how useful they are in answering the question. In\nthe end, we further aid the model by highlighting the terms in the re-ranked\nconversational history using a binary classification task and keeping the\nuseful terms (predicted as 1) and ignoring the irrelevant terms (predicted as\n0). We demonstrate the efficacy of our proposed framework with extensive\nexperimental results on CANARD and QuAC -- the two popularly utilized datasets\nin ConvQA. We demonstrate that selecting relevant turns works better than\nrewriting the original question. We also investigate how adding the irrelevant\nhistory turns negatively impacts the model's performance and discuss the\nresearch challenges that demand more attention from the IR community.",
        "translated": ""
    },
    {
        "title": "Optimally Computing Compressed Indexing Arrays Based on the Compact\n  Directed Acyclic Word Graph",
        "url": "http://arxiv.org/abs/2308.02269v1",
        "pub_date": "2023-08-04",
        "summary": "In this paper, we present the first study of the computational complexity of\nconverting an automata-based text index structure, called the Compact Directed\nAcyclic Word Graph (CDAWG), of size $e$ for a text $T$ of length $n$ into other\ntext indexing structures for the same text, suitable for highly repetitive\ntexts: the run-length BWT of size $r$, the irreducible PLCP array of size $r$,\nand the quasi-irreducible LPF array of size $e$, as well as the lex-parse of\nsize $O(r)$ and the LZ77-parse of size $z$, where $r, z \\le e$. As main\nresults, we showed that the above structures can be optimally computed from\neither the CDAWG for $T$ stored in read-only memory or its self-index version\nof size $e$ without a text in $O(e)$ worst-case time and words of working\nspace. To obtain the above results, we devised techniques for enumerating a\nparticular subset of suffixes in the lexicographic and text orders using the\nforward and backward search on the CDAWG by extending the results by\nBelazzougui et al. in 2015.",
        "translated": ""
    },
    {
        "title": "Finding Tori: Self-supervised Learning for Analyzing Korean Folk Song",
        "url": "http://arxiv.org/abs/2308.02249v1",
        "pub_date": "2023-08-04",
        "summary": "In this paper, we introduce a computational analysis of the field recording\ndataset of approximately 700 hours of Korean folk songs, which were recorded\naround 1980-90s. Because most of the songs were sung by non-expert musicians\nwithout accompaniment, the dataset provides several challenges. To address this\nchallenge, we utilized self-supervised learning with convolutional neural\nnetwork based on pitch contour, then analyzed how the musical concept of tori,\na classification system defined by a specific scale, ornamental notes, and an\nidiomatic melodic contour, is captured by the model. The experimental result\nshows that our approach can better capture the characteristics of tori compared\nto traditional pitch histograms. Using our approaches, we have examined how\nmusical discussions proposed in existing academia manifest in the actual field\nrecordings of Korean folk songs.",
        "translated": ""
    },
    {
        "title": "MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities",
        "url": "http://arxiv.org/abs/2308.02490v1",
        "pub_date": "2023-08-04",
        "summary": "We propose MM-Vet, an evaluation benchmark that examines large multimodal\nmodels (LMMs) on complicated multimodal tasks. Recent LMMs have shown various\nintriguing abilities, such as solving math problems written on the blackboard,\nreasoning about events and celebrities in news images, and explaining visual\njokes. Rapid model advancements pose challenges to evaluation benchmark\ndevelopment. Problems include: (1) How to systematically structure and evaluate\nthe complicated multimodal tasks; (2) How to design evaluation metrics that\nwork well across question and answer types; and (3) How to give model insights\nbeyond a simple performance ranking. To this end, we present MM-Vet, designed\nbased on the insight that the intriguing ability to solve complicated tasks is\noften achieved by a generalist model being able to integrate different core\nvision-language (VL) capabilities. MM-Vet defines 6 core VL capabilities and\nexamines the 16 integrations of interest derived from the capability\ncombination. For evaluation metrics, we propose an LLM-based evaluator for\nopen-ended outputs. The evaluator enables the evaluation across different\nquestion types and answer styles, resulting in a unified scoring metric. We\nevaluate representative LMMs on MM-Vet, providing insights into the\ncapabilities of different LMM system paradigms and models. Code and data are\navailable at https://github.com/yuweihao/MM-Vet.",
        "translated": ""
    },
    {
        "title": "Adapting the NICT-JLE Corpus for Disfluency Detection Models",
        "url": "http://arxiv.org/abs/2308.02482v1",
        "pub_date": "2023-08-04",
        "summary": "The detection of disfluencies such as hesitations, repetitions and false\nstarts commonly found in speech is a widely studied area of research. With a\nstandardised process for evaluation using the Switchboard Corpus, model\nperformance can be easily compared across approaches. This is not the case for\ndisfluency detection research on learner speech, however, where such datasets\nhave restricted access policies, making comparison and subsequent development\nof improved models more challenging. To address this issue, this paper\ndescribes the adaptation of the NICT-JLE corpus, containing approximately 300\nhours of English learners' oral proficiency tests, to a format that is suitable\nfor disfluency detection model training and evaluation. Points of difference\nbetween the NICT-JLE and Switchboard corpora are explored, followed by a\ndetailed overview of adaptations to the tag set and meta-features of the\nNICT-JLE corpus. The result of this work provides a standardised train, heldout\nand test set for use in future research on disfluency detection for learner\nspeech.",
        "translated": ""
    },
    {
        "title": "Towards Generalist Foundation Model for Radiology",
        "url": "http://arxiv.org/abs/2308.02463v1",
        "pub_date": "2023-08-04",
        "summary": "In this study, we aim to initiate the development of Radiology Foundation\nModel, termed as RadFM.We consider the construction of foundational models from\nthe perspectives of data, model design, and evaluation thoroughly. Our\ncontribution can be concluded as follows: (i), we construct a large-scale\nMedical Multi-modal Dataset, MedMD, consisting of 16M 2D and 3D medical scans.\nTo the best of our knowledge, this is the first multi-modal dataset containing\n3D medical scans. (ii), We propose an architecture that enables visually\nconditioned generative pre-training, allowing for the integration of text input\ninterleaved with 2D or 3D medical scans to generate response for diverse\nradiologic tasks. The model was initially pre-trained on MedMD and subsequently\ndomain-specific fine-tuned on RadMD, a radiologic cleaned version of MedMD,\ncontaining 3M radiologic visual-language pairs. (iii), we propose a new\nevaluation benchmark that comprises five tasks, aiming to comprehensively\nassess the capability of foundation models in handling practical clinical\nproblems. Our experimental results confirm that RadFM significantly outperforms\nexisting multi-modal foundation models. The codes, data, and model checkpoint\nwill all be made publicly available to promote further research and development\nin the field.",
        "translated": ""
    },
    {
        "title": "From Military to Healthcare: Adopting and Expanding Ethical Principles\n  for Generative Artificial Intelligence",
        "url": "http://arxiv.org/abs/2308.02448v1",
        "pub_date": "2023-08-04",
        "summary": "In 2020, the U.S. Department of Defense officially disclosed a set of ethical\nprinciples to guide the use of Artificial Intelligence (AI) technologies on\nfuture battlefields. Despite stark differences, there are core similarities\nbetween the military and medical service. Warriors on battlefields often face\nlife-altering circumstances that require quick decision-making. Medical\nproviders experience similar challenges in a rapidly changing healthcare\nenvironment, such as in the emergency department or during surgery treating a\nlife-threatening condition. Generative AI, an emerging technology designed to\nefficiently generate valuable information, holds great promise. As computing\npower becomes more accessible and the abundance of health data, such as\nelectronic health records, electrocardiograms, and medical images, increases,\nit is inevitable that healthcare will be revolutionized by this technology.\nRecently, generative AI has captivated the research community, leading to\ndebates about its application in healthcare, mainly due to concerns about\ntransparency and related issues. Meanwhile, concerns about the potential\nexacerbation of health disparities due to modeling biases have raised notable\nethical concerns regarding the use of this technology in healthcare. However,\nthe ethical principles for generative AI in healthcare have been understudied,\nand decision-makers often fail to consider the significance of generative AI.\nIn this paper, we propose GREAT PLEA ethical principles, encompassing\ngovernance, reliability, equity, accountability, traceability, privacy,\nlawfulness, empathy, and autonomy, for generative AI in healthcare. We aim to\nproactively address the ethical dilemmas and challenges posed by the\nintegration of generative AI in healthcare.",
        "translated": ""
    },
    {
        "title": "Text2KGBench: A Benchmark for Ontology-Driven Knowledge Graph Generation\n  from Text",
        "url": "http://arxiv.org/abs/2308.02357v1",
        "pub_date": "2023-08-04",
        "summary": "The recent advances in large language models (LLM) and foundation models with\nemergent capabilities have been shown to improve the performance of many NLP\ntasks. LLMs and Knowledge Graphs (KG) can complement each other such that LLMs\ncan be used for KG construction or completion while existing KGs can be used\nfor different tasks such as making LLM outputs explainable or fact-checking in\nNeuro-Symbolic manner. In this paper, we present Text2KGBench, a benchmark to\nevaluate the capabilities of language models to generate KGs from natural\nlanguage text guided by an ontology. Given an input ontology and a set of\nsentences, the task is to extract facts from the text while complying with the\ngiven ontology (concepts, relations, domain/range constraints) and being\nfaithful to the input sentences. We provide two datasets (i) Wikidata-TekGen\nwith 10 ontologies and 13,474 sentences and (ii) DBpedia-WebNLG with 19\nontologies and 4,860 sentences. We define seven evaluation metrics to measure\nfact extraction performance, ontology conformance, and hallucinations by LLMs.\nFurthermore, we provide results for two baseline models, Vicuna-13B and\nAlpaca-LoRA-13B using automatic prompt generation from test cases. The baseline\nresults show that there is room for improvement using both Semantic Web and\nNatural Language Processing techniques.",
        "translated": ""
    },
    {
        "title": "Dataflow Dialogue Generation",
        "url": "http://arxiv.org/abs/2308.02323v1",
        "pub_date": "2023-08-04",
        "summary": "We demonstrate task-oriented dialogue generation within the dataflow dialogue\nparadigm. We show an example of agenda driven dialogue generation for the\nMultiWOZ domain, and an example of generation without an agenda for the\nSMCalFlow domain, where we show an improvement in the accuracy of the\ntranslation of user requests to dataflow expressions when the generated\ndialogues are used to augment the translation training dataset.",
        "translated": ""
    },
    {
        "title": "Redundancy Aware Multi-Reference Based Gainwise Evaluation of Extractive\n  Summarization",
        "url": "http://arxiv.org/abs/2308.02270v1",
        "pub_date": "2023-08-04",
        "summary": "While very popular for evaluating extractive summarization task, the ROUGE\nmetric has long been criticized for its lack of semantic awareness and its\nignorance about the ranking quality of the summarizer. Thanks to previous\nresearch that has addressed these issues by proposing a gain-based automated\nmetric called Sem-nCG, which is both rank and semantic aware. However, Sem-nCG\ndoes not consider the amount of redundancy present in a model-generated summary\nand currently does not support evaluation with multiple reference summaries.\nUnfortunately, addressing both these limitations simultaneously is not trivial.\nTherefore, in this paper, we propose a redundancy-aware Sem-nCG metric and\ndemonstrate how this new metric can be used to evaluate model summaries against\nmultiple references. We also explore different ways of incorporating redundancy\ninto the original metric through extensive experiments. Experimental results\ndemonstrate that the new redundancy-aware metric exhibits a higher correlation\nwith human judgments than the original Sem-nCG metric for both single and\nmultiple reference scenarios.",
        "translated": ""
    },
    {
        "title": "Efficient Monaural Speech Enhancement using Spectrum Attention Fusion",
        "url": "http://arxiv.org/abs/2308.02263v1",
        "pub_date": "2023-08-04",
        "summary": "Speech enhancement is a demanding task in automated speech processing\npipelines, focusing on separating clean speech from noisy channels. Transformer\nbased models have recently bested RNN and CNN models in speech enhancement,\nhowever at the same time they are much more computationally expensive and\nrequire much more high quality training data, which is always hard to come by.\nIn this paper, we present an improvement for speech enhancement models that\nmaintains the expressiveness of self-attention while significantly reducing\nmodel complexity, which we have termed Spectrum Attention Fusion. We carefully\nconstruct a convolutional module to replace several self-attention layers in a\nspeech Transformer, allowing the model to more efficiently fuse spectral\nfeatures. Our proposed model is able to achieve comparable or better results\nagainst SOTA models but with significantly smaller parameters (0.58M) on the\nVoice Bank + DEMAND dataset.",
        "translated": ""
    },
    {
        "title": "Sinhala-English Parallel Word Dictionary Dataset",
        "url": "http://arxiv.org/abs/2308.02234v1",
        "pub_date": "2023-08-04",
        "summary": "Parallel datasets are vital for performing and evaluating any kind of\nmultilingual task. However, in the cases where one of the considered language\npairs is a low-resource language, the existing top-down parallel data such as\ncorpora are lacking in both tally and quality due to the dearth of human\nannotation. Therefore, for low-resource languages, it is more feasible to move\nin the bottom-up direction where finer granular pairs such as dictionary\ndatasets are developed first. They may then be used for mid-level tasks such as\nsupervised multilingual word embedding alignment. These in turn can later guide\nhigher-level tasks in the order of aligning sentence or paragraph text corpora\nused for Machine Translation (MT). Even though more approachable than\ngenerating and aligning a massive corpus for a low-resource language, for the\nsame reason of apathy from larger research entities, even these finer granular\ndata sets are lacking for some low-resource languages. We have observed that\nthere is no free and open dictionary data set for the low-resource language,\nSinhala. Thus, in this work, we introduce three parallel English-Sinhala word\ndictionaries (En-Si-dict-large, En-Si-dict-filtered, En-Si-dict-FastText) which\nhelp in multilingual Natural Language Processing (NLP) tasks related to English\nand Sinhala languages. In this paper, we explain the dataset creation pipeline\nas well as the experimental results of the tests we have carried out to verify\nthe quality of the data sets. The data sets and the related scripts are\navailable at https://github.com/kasunw22/sinhala-para-dict.",
        "translated": ""
    },
    {
        "title": "Randomized algorithms for precise measurement of differentially-private,\n  personalized recommendations",
        "url": "http://arxiv.org/abs/2308.03735v1",
        "pub_date": "2023-08-07",
        "summary": "Personalized recommendations form an important part of today's internet\necosystem, helping artists and creators to reach interested users, and helping\nusers to discover new and engaging content. However, many users today are\nskeptical of platforms that personalize recommendations, in part due to\nhistorically careless treatment of personal data and data privacy. Now,\nbusinesses that rely on personalized recommendations are entering a new\nparadigm, where many of their systems must be overhauled to be privacy-first.\nIn this article, we propose an algorithm for personalized recommendations that\nfacilitates both precise and differentially-private measurement. We consider\nadvertising as an example application, and conduct offline experiments to\nquantify how the proposed privacy-preserving algorithm affects key metrics\nrelated to user experience, advertiser value, and platform revenue compared to\nthe extremes of both (private) non-personalized and non-private, personalized\nimplementations.",
        "translated": ""
    },
    {
        "title": "Labeling without Seeing? Blind Annotation for Privacy-Preserving Entity\n  Resolution",
        "url": "http://arxiv.org/abs/2308.03734v1",
        "pub_date": "2023-08-07",
        "summary": "The entity resolution problem requires finding pairs across datasets that\nbelong to different owners but refer to the same entity in the real world. To\ntrain and evaluate solutions (either rule-based or machine-learning-based) to\nthe entity resolution problem, generating a ground truth dataset with entity\npairs or clusters is needed. However, such a data annotation process involves\nhumans as domain oracles to review the plaintext data for all candidate record\npairs from different parties, which inevitably infringes the privacy of data\nowners, especially in privacy-sensitive cases like medical records. To the best\nof our knowledge, there is no prior work on privacy-preserving ground truth\ndataset generation, especially in the domain of entity resolution. We propose a\nnovel blind annotation protocol based on homomorphic encryption that allows\ndomain oracles to collaboratively label ground truths without sharing data in\nplaintext with other parties. In addition, we design a domain-specific\neasy-to-use language that hides the sophisticated underlying homomorphic\nencryption layer. Rigorous proof of the privacy guarantee is provided and our\nempirical experiments via an annotation simulator indicate the feasibility of\nour privacy-preserving protocol (f-measure on average achieves more than 90\\%\ncompared with the real ground truths).",
        "translated": ""
    },
    {
        "title": "Multi-View Graph Convolutional Network for Multimedia Recommendation",
        "url": "http://arxiv.org/abs/2308.03588v1",
        "pub_date": "2023-08-07",
        "summary": "Multimedia recommendation has received much attention in recent years. It\nmodels user preferences based on both behavior information and item multimodal\ninformation. Though current GCN-based methods achieve notable success, they\nsuffer from two limitations: (1) Modality noise contamination to the item\nrepresentations. Existing methods often mix modality features and behavior\nfeatures in a single view (e.g., user-item view) for propagation, the noise in\nthe modality features may be amplified and coupled with behavior features. In\nthe end, it leads to poor feature discriminability; (2) Incomplete user\npreference modeling caused by equal treatment of modality features. Users often\nexhibit distinct modality preferences when purchasing different items. Equally\nfusing each modality feature ignores the relative importance among different\nmodalities, leading to the suboptimal user preference modeling. To tackle the\nabove issues, we propose a novel Multi-View Graph Convolutional Network for the\nmultimedia recommendation. Specifically, to avoid modality noise contamination,\nthe modality features are first purified with the aid of item behavior\ninformation. Then, the purified modality features of items and behavior\nfeatures are enriched in separate views, including the user-item view and the\nitem-item view. In this way, the distinguishability of features is enhanced.\nMeanwhile, a behavior-aware fuser is designed to comprehensively model user\npreferences by adaptively learning the relative importance of different\nmodality features. Furthermore, we equip the fuser with a self-supervised\nauxiliary task. This task is expected to maximize the mutual information\nbetween the fused multimodal features and behavior features, so as to capture\ncomplementary and supplementary preference information simultaneously.\nExtensive experiments on three public datasets demonstrate the effectiveness of\nour methods.",
        "translated": ""
    },
    {
        "title": "TeraHAC: Hierarchical Agglomerative Clustering of Trillion-Edge Graphs",
        "url": "http://arxiv.org/abs/2308.03578v1",
        "pub_date": "2023-08-07",
        "summary": "We introduce TeraHAC, a $(1+\\epsilon)$-approximate hierarchical agglomerative\nclustering (HAC) algorithm which scales to trillion-edge graphs. Our algorithm\nis based on a new approach to computing $(1+\\epsilon)$-approximate HAC, which\nis a novel combination of the nearest-neighbor chain algorithm and the notion\nof $(1+\\epsilon)$-approximate HAC. Our approach allows us to partition the\ngraph among multiple machines and make significant progress in computing the\nclustering within each partition before any communication with other partitions\nis needed.\n  We evaluate TeraHAC on a number of real-world and synthetic graphs of up to 8\ntrillion edges. We show that TeraHAC requires over 100x fewer rounds compared\nto previously known approaches for computing HAC. It is up to 8.3x faster than\nSCC, the state-of-the-art distributed algorithm for hierarchical clustering,\nwhile achieving 1.16x higher quality. In fact, TeraHAC essentially retains the\nquality of the celebrated HAC algorithm while significantly improving the\nrunning time.",
        "translated": ""
    },
    {
        "title": "Global cognitive graph properties dynamics of hippocampal formation",
        "url": "http://arxiv.org/abs/2308.03563v1",
        "pub_date": "2023-08-07",
        "summary": "In the present study we have used a set of methods and metrics to build a\ngraph of relative neural connections in a hippocampus of a rodent. A set of\ngraphs was built on top of time-sequenced data and analyzed in terms of\ndynamics of a connection genesis. The analysis has shown that during the\nprocess of a rodent exploring a novel environment, the relations between\nneurons constantly change which indicates that globally memory is constantly\nupdated even for known areas of space. Even if some neurons gain cognitive\nspecialization, the global network though remains relatively stable.\nAdditionally we suggest a set of methods for building a graph of cognitive\nneural network.",
        "translated": ""
    },
    {
        "title": "What about translation? New coding system for content analysis on the\n  perception of literary translation around the political transformation in\n  1989 in Hungary as a classification problem on an unbalanced dataset",
        "url": "http://arxiv.org/abs/2308.03742v1",
        "pub_date": "2023-08-07",
        "summary": "To track trends in the perception of literary translation around the\npolitical transformation in 1989 in Hungary, a coding system was developed on\nthe paragraphs of the 1980-1999 issues of the literary journal Alf\\\"old. This\npaper describes how we trained BERT models to carry over the coding system to\nthe 1980-1999 issues of the literary journal Nagyvil\\'ag. We use extensive\nhyperparameter tuning, loss functions robust to label unbalance, 10-fold\ncross-validation for precise evaluations and a model ensemble for prediction,\nmanual validation on the predict set, a new calibration method to better\npredict label counts for sections of the Nagyvil\\'ag corpus, and to study the\nrelations between labels, we construct label relation networks.",
        "translated": ""
    },
    {
        "title": "AgentBench: Evaluating LLMs as Agents",
        "url": "http://arxiv.org/abs/2308.03688v1",
        "pub_date": "2023-08-07",
        "summary": "Large Language Models (LLMs) are becoming increasingly smart and autonomous,\ntargeting real-world pragmatic missions beyond traditional NLP tasks. As a\nresult, there has been an urgent need to evaluate LLMs as agents on challenging\ntasks in interactive environments. We present AgentBench, a multi-dimensional\nevolving benchmark that currently consists of 8 distinct environments to assess\nLLM-as-Agent's reasoning and decision-making abilities in a multi-turn\nopen-ended generation setting. Our extensive test over 25 LLMs (including APIs\nand open-sourced models) shows that, while top commercial LLMs present a strong\nability of acting as agents in complex environments, there is a significant\ndisparity in performance between them and open-sourced competitors. It also\nserves as a component of an ongoing project with wider coverage and deeper\nconsideration towards systematic LLM evaluation. Datasets, environments, and an\nintegrated evaluation package for AgentBench are released at\nhttps://github.com/THUDM/AgentBench",
        "translated": ""
    },
    {
        "title": "Detecting Spells in Fantasy Literature with a Transformer Based\n  Artificial Intelligence",
        "url": "http://arxiv.org/abs/2308.03660v1",
        "pub_date": "2023-08-07",
        "summary": "Transformer architectures and models have made significant progress in\nlanguage-based tasks. In this area, is BERT one of the most widely used and\nfreely available transformer architecture. In our work, we use BERT for\ncontext-based phrase recognition of magic spells in the Harry Potter novel\nseries. Spells are a common part of active magic in fantasy novels. Typically,\nspells are used in a specific context to achieve a supernatural effect. A\nseries of investigations were conducted to see if a Transformer architecture\ncould recognize such phrases based on their context in the Harry Potter saga.\nFor our studies a pre-trained BERT model was used and fine-tuned utilising\ndifferent datasets and training methods to identify the searched context. By\nconsidering different approaches for sequence classification as well as token\nclassification, it is shown that the context of spells can be recognised.\nAccording to our investigations, the examined sequence length for fine-tuning\nand validation of the model plays a significant role in context recognition.\nBased on this, we have investigated whether spells have overarching properties\nthat allow a transfer of the neural network models to other fantasy universes\nas well. The application of our model showed promising results and is worth to\nbe deepened in subsequent studies.",
        "translated": ""
    },
    {
        "title": "Emotionally Numb or Empathetic? Evaluating How LLMs Feel Using\n  EmotionBench",
        "url": "http://arxiv.org/abs/2308.03656v1",
        "pub_date": "2023-08-07",
        "summary": "Recently, the community has witnessed the advancement of Large Language\nModels (LLMs), which have shown remarkable performance on various downstream\ntasks. Led by powerful models like ChatGPT and Claude, LLMs are revolutionizing\nhow users engage with software, assuming more than mere tools but intelligent\nassistants. Consequently, evaluating LLMs' anthropomorphic capabilities becomes\nincreasingly important in contemporary discourse. Utilizing the emotion\nappraisal theory from psychology, we propose to evaluate the empathy ability of\nLLMs, i.e., how their feelings change when presented with specific situations.\nAfter a careful and comprehensive survey, we collect a dataset containing over\n400 situations that have proven effective in eliciting the eight emotions\ncentral to our study. Categorizing the situations into 36 factors, we conduct a\nhuman evaluation involving more than 1,200 subjects worldwide. With the human\nevaluation results as references, our evaluation includes five LLMs, covering\nboth commercial and open-source models, including variations in model sizes,\nfeaturing the latest iterations, such as GPT-4 and LLaMA 2. A conclusion can be\ndrawn from the results that, despite several misalignments, LLMs can generally\nrespond appropriately to certain situations. Nevertheless, they fall short in\nalignment with the emotional behaviors of human beings and cannot establish\nconnections between similar situations. Our collected dataset of situations,\nthe human evaluation results, and the code of our testing framework, dubbed\nEmotionBench, is made publicly in https://github.com/CUHK-ARISE/EmotionBench.\nWe aspire to contribute to the advancement of LLMs regarding better alignment\nwith the emotional behaviors of human beings, thereby enhancing their utility\nand applicability as intelligent assistants.",
        "translated": ""
    },
    {
        "title": "KITLM: Domain-Specific Knowledge InTegration into Language Models for\n  Question Answering",
        "url": "http://arxiv.org/abs/2308.03638v1",
        "pub_date": "2023-08-07",
        "summary": "Large language models (LLMs) have demonstrated remarkable performance in a\nwide range of natural language tasks. However, as these models continue to grow\nin size, they face significant challenges in terms of computational costs.\nAdditionally, LLMs often lack efficient domain-specific understanding, which is\nparticularly crucial in specialized fields such as aviation and healthcare. To\nboost the domain-specific understanding, we propose, KITLM, a novel knowledge\nbase integration approach into language model through relevant information\ninfusion. By integrating pertinent knowledge, not only the performance of the\nlanguage model is greatly enhanced, but the model size requirement is also\nsignificantly reduced while achieving comparable performance. Our proposed\nknowledge-infused model surpasses the performance of both GPT-3.5-turbo and the\nstate-of-the-art knowledge infusion method, SKILL, achieving over 1.5 times\nimprovement in exact match scores on the MetaQA. KITLM showed a similar\nperformance boost in the aviation domain with AeroQA. The drastic performance\nimprovement of KITLM over the existing methods can be attributed to the\ninfusion of relevant knowledge while mitigating noise. In addition, we release\ntwo curated datasets to accelerate knowledge infusion research in specialized\nfields: a) AeroQA, a new benchmark dataset designed for multi-hop\nquestion-answering within the aviation domain, and b) Aviation Corpus, a\ndataset constructed from unstructured text extracted from the National\nTransportation Safety Board reports. Our research contributes to advancing the\nfield of domain-specific language understanding and showcases the potential of\nknowledge infusion techniques in improving the performance of language models\non question-answering.",
        "translated": ""
    },
    {
        "title": "MedMine: Examining Pre-trained Language Models on Medication Mining",
        "url": "http://arxiv.org/abs/2308.03629v1",
        "pub_date": "2023-08-07",
        "summary": "Automatic medication mining from clinical and biomedical text has become a\npopular topic due to its real impact on healthcare applications and the recent\ndevelopment of powerful language models (LMs). However, fully-automatic\nextraction models still face obstacles to be overcome such that they can be\ndeployed directly into clinical practice for better impacts. Such obstacles\ninclude their imbalanced performances on different entity types and clinical\nevents. In this work, we examine current state-of-the-art pre-trained language\nmodels (PLMs) on such tasks, via fine-tuning including the monolingual model\nMed7 and multilingual large language model (LLM) XLM-RoBERTa. We compare their\nadvantages and drawbacks using historical medication mining shared task data\nsets from n2c2-2018 challenges. We report the findings we get from these\nfine-tuning experiments such that they can facilitate future research on\naddressing them, for instance, how to combine their outputs, merge such models,\nor improve their overall accuracy by ensemble learning and data augmentation.\nMedMine is part of the M3 Initiative \\url{https://github.com/HECTA-UoM/M3}",
        "translated": ""
    },
    {
        "title": "Negative Lexical Constraints in Neural Machine Translation",
        "url": "http://arxiv.org/abs/2308.03601v1",
        "pub_date": "2023-08-07",
        "summary": "This paper explores negative lexical constraining in English to Czech neural\nmachine translation. Negative lexical constraining is used to prohibit certain\nwords or expressions in the translation produced by the neural translation\nmodel. We compared various methods based on modifying either the decoding\nprocess or the training data. The comparison was performed on two tasks:\nparaphrasing and feedback-based translation refinement. We also studied to\nwhich extent these methods \"evade\" the constraints presented to the model\n(usually in the dictionary form) by generating a different surface form of a\ngiven constraint.We propose a way to mitigate the issue through training with\nstemmed negative constraints to counter the model's ability to induce a variety\nof the surface forms of a word that can result in bypassing the constraint. We\ndemonstrate that our method improves the constraining, although the problem\nstill persists in many cases.",
        "translated": ""
    },
    {
        "title": "WIKITIDE: A Wikipedia-Based Timestamped Definition Pairs Dataset",
        "url": "http://arxiv.org/abs/2308.03582v1",
        "pub_date": "2023-08-07",
        "summary": "A fundamental challenge in the current NLP context, dominated by language\nmodels, comes from the inflexibility of current architectures to 'learn' new\ninformation. While model-centric solutions like continual learning or\nparameter-efficient fine tuning are available, the question still remains of\nhow to reliably identify changes in language or in the world. In this paper, we\npropose WikiTiDe, a dataset derived from pairs of timestamped definitions\nextracted from Wikipedia. We argue that such resource can be helpful for\naccelerating diachronic NLP, specifically, for training models able to scan\nknowledge resources for core updates concerning a concept, an event, or a named\nentity. Our proposed end-to-end method is fully automatic, and leverages a\nbootstrapping algorithm for gradually creating a high-quality dataset. Our\nresults suggest that bootstrapping the seed version of WikiTiDe leads to better\nfine-tuned models. We also leverage fine-tuned models in a number of downstream\ntasks, showing promising results with respect to competitive baselines.",
        "translated": ""
    },
    {
        "title": "Towards Controllable Natural Language Inference through Lexical\n  Inference Types",
        "url": "http://arxiv.org/abs/2308.03581v1",
        "pub_date": "2023-08-07",
        "summary": "Explainable natural language inference aims to provide a mechanism to produce\nexplanatory (abductive) inference chains which ground claims to their\nsupporting premises. A recent corpus called EntailmentBank strives to advance\nthis task by explaining the answer to a question using an entailment tree\n\\cite{dalvi2021explaining}. They employ the T5 model to directly generate the\ntree, which can explain how the answer is inferred. However, it lacks the\nability to explain and control the generation of intermediate steps, which is\ncrucial for the multi-hop inference process. % One recent corpus,\nEntailmentBank, aims to push this task forward by explaining an answer to a\nquestion according to an entailment tree \\cite{dalvi2021explaining}. They\nemploy T5 to generate the tree directly, which can explain how the answer is\ninferred but cannot explain how the intermediate is generated, which is\nessential to the multi-hop inference process. In this work, we focus on\nproposing a controlled natural language inference architecture for\nmulti-premise explanatory inference. To improve control and enable explanatory\nanalysis over the generation, we define lexical inference types based on\nAbstract Meaning Representation (AMR) graph and modify the architecture of T5\nto learn a latent sentence representation (T5 bottleneck) conditioned on said\ntype information. We also deliver a dataset of approximately 5000 annotated\nexplanatory inference steps, with well-grounded lexical-symbolic operations.\nExperimental results indicate that the inference typing induced at the T5\nbottleneck can help T5 to generate a conclusion under explicit control.",
        "translated": ""
    },
    {
        "title": "Topological Interpretations of GPT-3",
        "url": "http://arxiv.org/abs/2308.03565v1",
        "pub_date": "2023-08-07",
        "summary": "This is an experiential study of investigating a consistent method for\nderiving the correlation between sentence vector and semantic meaning of a\nsentence. We first used three state-of-the-art word/sentence embedding methods\nincluding GPT-3, Word2Vec, and Sentence-BERT, to embed plain text sentence\nstrings into high dimensional spaces. Then we compute the pairwise distance\nbetween any possible combination of two sentence vectors in an embedding space\nand map them into a matrix. Based on each distance matrix, we compute the\ncorrelation of distances of a sentence vector with respect to the other\nsentence vectors in an embedding space. Then we compute the correlation of each\npair of the distance matrices. We observed correlations of the same sentence in\ndifferent embedding spaces and correlations of different sentences in the same\nembedding space. These observations are consistent with our hypothesis and take\nus to the next stage.",
        "translated": ""
    },
    {
        "title": "Your Negative May not Be True Negative: Boosting Image-Text Matching\n  with False Negative Elimination",
        "url": "http://arxiv.org/abs/2308.04380v1",
        "pub_date": "2023-08-08",
        "summary": "Most existing image-text matching methods adopt triplet loss as the\noptimization objective, and choosing a proper negative sample for the triplet\nof &lt;anchor, positive, negative&gt; is important for effectively training the\nmodel, e.g., hard negatives make the model learn efficiently and effectively.\nHowever, we observe that existing methods mainly employ the most similar\nsamples as hard negatives, which may not be true negatives. In other words, the\nsamples with high similarity but not paired with the anchor may reserve\npositive semantic associations, and we call them false negatives. Repelling\nthese false negatives in triplet loss would mislead the semantic representation\nlearning and result in inferior retrieval performance. In this paper, we\npropose a novel False Negative Elimination (FNE) strategy to select negatives\nvia sampling, which could alleviate the problem introduced by false negatives.\nSpecifically, we first construct the distributions of positive and negative\nsamples separately via their similarities with the anchor, based on the\nfeatures extracted from image and text encoders. Then we calculate the false\nnegative probability of a given sample based on its similarity with the anchor\nand the above distributions via the Bayes' rule, which is employed as the\nsampling weight during negative sampling process. Since there may not exist any\nfalse negative in a small batch size, we design a memory module with momentum\nto retain a large negative buffer and implement our negative sampling strategy\nspanning over the buffer. In addition, to make the model focus on hard\nnegatives, we reassign the sampling weights for the simple negatives with a\ncut-down strategy. The extensive experiments are conducted on Flickr30K and\nMS-COCO, and the results demonstrate the superiority of our proposed false\nnegative elimination strategy. The code is available at\nhttps://github.com/LuminosityX/FNE.",
        "translated": ""
    },
    {
        "title": "Unifying Two-Stream Encoders with Transformers for Cross-Modal Retrieval",
        "url": "http://arxiv.org/abs/2308.04343v1",
        "pub_date": "2023-08-08",
        "summary": "Most existing cross-modal retrieval methods employ two-stream encoders with\ndifferent architectures for images and texts, \\textit{e.g.}, CNN for images and\nRNN/Transformer for texts. Such discrepancy in architectures may induce\ndifferent semantic distribution spaces and limit the interactions between\nimages and texts, and further result in inferior alignment between images and\ntexts. To fill this research gap, inspired by recent advances of Transformers\nin vision tasks, we propose to unify the encoder architectures with\nTransformers for both modalities. Specifically, we design a cross-modal\nretrieval framework purely based on two-stream Transformers, dubbed\n\\textbf{Hierarchical Alignment Transformers (HAT)}, which consists of an image\nTransformer, a text Transformer, and a hierarchical alignment module. With such\nidentical architectures, the encoders could produce representations with more\nsimilar characteristics for images and texts, and make the interactions and\nalignments between them much easier. Besides, to leverage the rich semantics,\nwe devise a hierarchical alignment scheme to explore multi-level\ncorrespondences of different layers between images and texts. To evaluate the\neffectiveness of the proposed HAT, we conduct extensive experiments on two\nbenchmark datasets, MSCOCO and Flickr30K. Experimental results demonstrate that\nHAT outperforms SOTA baselines by a large margin. Specifically, on two key\ntasks, \\textit{i.e.}, image-to-text and text-to-image retrieval, HAT achieves\n7.6\\% and 16.7\\% relative score improvement of Recall@1 on MSCOCO, and 4.4\\%\nand 11.6\\% on Flickr30k respectively. The code is available at\n\\url{https://github.com/LuminosityX/HAT}.",
        "translated": ""
    },
    {
        "title": "Advancing Natural-Language Based Audio Retrieval with PaSST and Large\n  Audio-Caption Data Sets",
        "url": "http://arxiv.org/abs/2308.04258v1",
        "pub_date": "2023-08-08",
        "summary": "This work presents a text-to-audio-retrieval system based on pre-trained text\nand spectrogram transformers. Our method projects recordings and textual\ndescriptions into a shared audio-caption space in which related examples from\ndifferent modalities are close. Through a systematic analysis, we examine how\neach component of the system influences retrieval performance. As a result, we\nidentify two key components that play a crucial role in driving performance:\nthe self-attention-based audio encoder for audio embedding and the utilization\nof additional human-generated and synthetic data sets during pre-training. We\nfurther experimented with augmenting ClothoV2 captions with available keywords\nto increase their variety; however, this only led to marginal improvements. Our\nsystem ranked first in the 2023's DCASE Challenge, and it outperforms the\ncurrent state of the art on the ClothoV2 benchmark by 5.6 pp. mAP@10.",
        "translated": ""
    },
    {
        "title": "UniRecSys: A Unified Framework for Personalized, Group, Package, and\n  Package-to-Group Recommendations",
        "url": "http://arxiv.org/abs/2308.04247v1",
        "pub_date": "2023-08-08",
        "summary": "Recommender systems aim to enhance the overall user experience by providing\ntailored recommendations for a variety of products and services. These systems\nhelp users make more informed decisions, leading to greater user satisfaction\nwith the platform. However, the implementation of these systems largely depends\non the context, which can vary from recommending an item or package to a user\nor a group. This requires careful exploration of several models during the\ndeployment, as there is no comprehensive and unified approach that deals with\nrecommendations at different levels. Furthermore, these individual models must\nbe closely attuned to their generated recommendations depending on the context\nto prevent significant variation in their generated recommendations. In this\npaper, we propose a novel unified recommendation framework that addresses all\nfour recommendation tasks, namely personalized, group, package, or\npackage-to-group recommendation, filling the gap in the current research\nlandscape. The proposed framework can be integrated with most of the\ntraditional matrix factorization-based collaborative filtering models. The idea\nis to enhance the formulation of the existing approaches by incorporating\ncomponents focusing on the exploitation of the group and package latent\nfactors. These components also help in exploiting a rich latent representation\nof the user/item by enforcing them to align closely with their corresponding\ngroup/package representation. We consider two prominent CF techniques,\nRegularized Matrix Factorization and Maximum Margin Matrix factorization, as\nthe baseline models and demonstrate their customization to various\nrecommendation tasks. Experiment results on two publicly available datasets are\nreported, comparing them to other baseline approaches that consider individual\nrating feedback for group or package recommendations.",
        "translated": ""
    },
    {
        "title": "OpinionConv: Conversational Product Search with Grounded Opinions",
        "url": "http://arxiv.org/abs/2308.04226v1",
        "pub_date": "2023-08-08",
        "summary": "When searching for products, the opinions of others play an important role in\nmaking informed decisions. Subjective experiences about a product can be a\nvaluable source of information. This is also true in sales conversations, where\na customer and a sales assistant exchange facts and opinions about products.\nHowever, training an AI for such conversations is complicated by the fact that\nlanguage models do not possess authentic opinions for their lack of real-world\nexperience. We address this problem by leveraging product reviews as a rich\nsource of product opinions to ground conversational AI in true subjective\nnarratives. With OpinionConv, we develop the first conversational AI for\nsimulating sales conversations. To validate the generated conversations, we\nconduct several user studies showing that the generated opinions are perceived\nas realistic. Our assessors also confirm the importance of opinions as an\ninformative basis for decision-making.",
        "translated": ""
    },
    {
        "title": "SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore",
        "url": "http://arxiv.org/abs/2308.04430v1",
        "pub_date": "2023-08-08",
        "summary": "The legality of training language models (LMs) on copyrighted or otherwise\nrestricted data is under intense debate. However, as we show, model performance\nsignificantly degrades if trained only on low-risk text (e.g., out-of-copyright\nbooks or government documents), due to its limited size and domain coverage. We\npresent SILO, a new language model that manages this risk-performance tradeoff\nduring inference. SILO is built by (1) training a parametric LM on Open License\nCorpus (OLC), a new corpus we curate with 228B tokens of public domain and\npermissively licensed text and (2) augmenting it with a more general and easily\nmodifiable nonparametric datastore (e.g., containing copyrighted books or news)\nthat is only queried during inference. The datastore allows use of high-risk\ndata without training on it, supports sentence-level data attribution, and\nenables data producers to opt out from the model by removing content from the\nstore. These capabilities can foster compliance with data-use regulations such\nas the fair use doctrine in the United States and the GDPR in the European\nUnion. Our experiments show that the parametric LM struggles on domains not\ncovered by OLC. However, access to the datastore greatly improves out of domain\nperformance, closing 90% of the performance gap with an LM trained on the Pile,\na more diverse corpus with mostly high-risk text. We also analyze which\nnonparametric approach works best, where the remaining errors lie, and how\nperformance scales with datastore size. Our results suggest that it is possible\nto build high quality language models while mitigating their legal risk.",
        "translated": ""
    },
    {
        "title": "A Bi-directional Multi-hop Inference Model for Joint Dialog Sentiment\n  Classification and Act Recognition",
        "url": "http://arxiv.org/abs/2308.04424v1",
        "pub_date": "2023-08-08",
        "summary": "The joint task of Dialog Sentiment Classification (DSC) and Act Recognition\n(DAR) aims to predict the sentiment label and act label for each utterance in a\ndialog simultaneously. However, current methods encode the dialog context in\nonly one direction, which limits their ability to thoroughly comprehend the\ncontext. Moreover, these methods overlook the explicit correlations between\nsentiment and act labels, which leads to an insufficient ability to capture\nrich sentiment and act clues and hinders effective and accurate reasoning. To\naddress these issues, we propose a Bi-directional Multi-hop Inference Model\n(BMIM) that leverages a feature selection network and a bi-directional\nmulti-hop inference network to iteratively extract and integrate rich sentiment\nand act clues in a bi-directional manner. We also employ contrastive learning\nand dual learning to explicitly model the correlations of sentiment and act\nlabels. Our experiments on two widely-used datasets show that BMIM outperforms\nstate-of-the-art baselines by at least 2.6% on F1 score in DAR and 1.4% on F1\nscore in DSC. Additionally, Our proposed model not only improves the\nperformance but also enhances the interpretability of the joint sentiment and\nact prediction task.",
        "translated": ""
    },
    {
        "title": "Character-level NMT and language similarity",
        "url": "http://arxiv.org/abs/2308.04398v1",
        "pub_date": "2023-08-08",
        "summary": "We explore the effectiveness of character-level neural machine translation\nusing Transformer architecture for various levels of language similarity and\nsize of the training dataset on translation between Czech and Croatian, German,\nHungarian, Slovak, and Spanish. We evaluate the models using automatic MT\nmetrics and show that translation between similar languages benefits from\ncharacter-level input segmentation, while for less related languages,\ncharacter-level vanilla Transformer-base often lags behind subword-level\nsegmentation. We confirm previous findings that it is possible to close the gap\nby finetuning the already trained subword-level models to character-level.",
        "translated": ""
    },
    {
        "title": "Learning Evaluation Models from Large Language Models for Sequence\n  Generation",
        "url": "http://arxiv.org/abs/2308.04386v1",
        "pub_date": "2023-08-08",
        "summary": "Large language models achieve state-of-the-art performance on sequence\ngeneration evaluation, but typically have a large number of parameters. This is\na computational challenge as presented by applying their evaluation capability\nat scale. To overcome the challenge, in this paper, we propose \\textbf{ECT}, an\n\\textbf{e}valuation \\textbf{c}apability \\textbf{t}ransfer method, to transfer\nthe evaluation capability from LLMs to relatively lightweight language models.\nBased on the proposed ECT, we learn various evaluation models from ChatGPT, and\nemploy them as reward models to improve sequence generation models via\nreinforcement learning and reranking approaches. Experimental results on\nmachine translation, text style transfer, and summarization tasks demonstrate\nthe effectiveness of our ECT. Notably, applying the learned evaluation models\nto sequence generation models results in better generated sequences as\nevaluated by commonly used metrics and ChatGPT.",
        "translated": ""
    },
    {
        "title": "Unmasking Nationality Bias: A Study of Human Perception of Nationalities\n  in AI-Generated Articles",
        "url": "http://arxiv.org/abs/2308.04346v1",
        "pub_date": "2023-08-08",
        "summary": "We investigate the potential for nationality biases in natural language\nprocessing (NLP) models using human evaluation methods. Biased NLP models can\nperpetuate stereotypes and lead to algorithmic discrimination, posing a\nsignificant challenge to the fairness and justice of AI systems. Our study\nemploys a two-step mixed-methods approach that includes both quantitative and\nqualitative analysis to identify and understand the impact of nationality bias\nin a text generation model. Through our human-centered quantitative analysis,\nwe measure the extent of nationality bias in articles generated by AI sources.\nWe then conduct open-ended interviews with participants, performing qualitative\ncoding and thematic analysis to understand the implications of these biases on\nhuman readers. Our findings reveal that biased NLP models tend to replicate and\namplify existing societal biases, which can translate to harm if used in a\nsociotechnical setting. The qualitative analysis from our interviews offers\ninsights into the experience readers have when encountering such articles,\nhighlighting the potential to shift a reader's perception of a country. These\nfindings emphasize the critical role of public perception in shaping AI's\nimpact on society and the need to correct biases in AI systems.",
        "translated": ""
    },
    {
        "title": "Towards an AI to Win Ghana's National Science and Maths Quiz",
        "url": "http://arxiv.org/abs/2308.04333v1",
        "pub_date": "2023-08-08",
        "summary": "Can an AI win Ghana's National Science and Maths Quiz (NSMQ)? That is the\nquestion we seek to answer in the NSMQ AI project, an open-source project that\nis building AI to compete live in the NSMQ and win. The NSMQ is an annual live\nscience and mathematics competition for senior secondary school students in\nGhana in which 3 teams of 2 students compete by answering questions across\nbiology, chemistry, physics, and math in 5 rounds over 5 progressive stages\nuntil a winning team is crowned for that year. The NSMQ is an exciting live\nquiz competition with interesting technical challenges across speech-to-text,\ntext-to-speech, question-answering, and human-computer interaction. In this\nongoing work that began in January 2023, we give an overview of the project,\ndescribe each of the teams, progress made thus far, and the next steps toward\nour planned launch and debut of the AI in October for NSMQ 2023. An AI that\nconquers this grand challenge can have real-world impact on education such as\nenabling millions of students across Africa to have one-on-one learning support\nfrom this AI.",
        "translated": ""
    },
    {
        "title": "Deep Learning-Based Knowledge Injection for Metaphor Detection: A\n  Comprehensive Review",
        "url": "http://arxiv.org/abs/2308.04306v1",
        "pub_date": "2023-08-08",
        "summary": "The history of metaphor research also marks the evolution of knowledge\ninfusion research. With the continued advancement of deep learning techniques\nin recent years, the natural language processing community has shown great\ninterest in applying knowledge to successful results in metaphor recognition\ntasks. Although there has been a gradual increase in the number of approaches\ninvolving knowledge injection in the field of metaphor recognition, there is a\nlack of a complete review article on knowledge injection based approaches.\nTherefore, the goal of this paper is to provide a comprehensive review of\nresearch advances in the application of deep learning for knowledge injection\nin metaphor recognition tasks. In this paper, we systematically summarize and\ngeneralize the mainstream knowledge and knowledge injection principles, as well\nas review the datasets, evaluation metrics, and benchmark models used in\nmetaphor recognition tasks. Finally, we explore the current issues facing\nknowledge injection methods and provide an outlook on future research\ndirections.",
        "translated": ""
    },
    {
        "title": "Comparative Analysis of the wav2vec 2.0 Feature Extractor",
        "url": "http://arxiv.org/abs/2308.04286v1",
        "pub_date": "2023-08-08",
        "summary": "Automatic speech recognition (ASR) systems typically use handcrafted feature\nextraction pipelines. To avoid their inherent information loss and to achieve\nmore consistent modeling from speech to transcribed text, neural raw waveform\nfeature extractors (FEs) are an appealing approach. Also the wav2vec 2.0 model,\nwhich has recently gained large popularity, uses a convolutional FE which\noperates directly on the speech waveform. However, it is not yet studied\nextensively in the literature. In this work, we study its capability to replace\nthe standard feature extraction methods in a connectionist temporal\nclassification (CTC) ASR model and compare it to an alternative neural FE. We\nshow that both are competitive with traditional FEs on the LibriSpeech\nbenchmark and analyze the effect of the individual components. Furthermore, we\nanalyze the learned filters and show that the most important information for\nthe ASR system is obtained by a set of bandpass filters.",
        "translated": ""
    },
    {
        "title": "In-Context Alignment: Chat with Vanilla Language Models Before\n  Fine-Tuning",
        "url": "http://arxiv.org/abs/2308.04275v1",
        "pub_date": "2023-08-08",
        "summary": "In this note, we explore inference-time alignment through in-context\nlearning. We consider a vanilla pretrained language model Llama-2 before any\nfine-tuning and retrieve an average of 9 demonstration alignment examples when\nthe model is prompted to follow chat-style instructions. Compared to direct\nprompting, the in-context alignment without changing model weights leads to a\n7x increase in win-rate w.r.t. the text-davinci-003 model from OpenAI, making\nthe vanilla language model comparable to strong baselines with alignment\nfine-tuning.",
        "translated": ""
    },
    {
        "title": "CLASSLA-Stanza: The Next Step for Linguistic Processing of South Slavic\n  Languages",
        "url": "http://arxiv.org/abs/2308.04255v1",
        "pub_date": "2023-08-08",
        "summary": "We present CLASSLA-Stanza, a pipeline for automatic linguistic annotation of\nthe South Slavic languages, which is based on the Stanza natural language\nprocessing pipeline. We describe the main improvements in CLASSLA-Stanza with\nrespect to Stanza, and give a detailed description of the model training\nprocess for the latest 2.1 release of the pipeline. We also report performance\nscores produced by the pipeline for different languages and varieties.\nCLASSLA-Stanza exhibits consistently high performance across all the supported\nlanguages and outperforms or expands its parent pipeline Stanza at all the\nsupported tasks. We also present the pipeline's new functionality enabling\nefficient processing of web data and the reasons that led to its\nimplementation.",
        "translated": ""
    },
    {
        "title": "Dual Intents Graph Modeling for User-centric Group Discovery",
        "url": "http://arxiv.org/abs/2308.05013v1",
        "pub_date": "2023-08-09",
        "summary": "Online groups have become increasingly prevalent, providing users with space\nto share experiences and explore interests. Therefore, user-centric group\ndiscovery task, i.e., recommending groups to users can help both users' online\nexperiences and platforms' long-term developments. Existing recommender methods\ncan not deal with this task as modeling user-group participation into a\nbipartite graph overlooks their item-side interests. Although there exist a few\nworks attempting to address this task, they still fall short in fully\npreserving the social context and ensuring effective interest representation\nlearning.\n  In this paper, we focus on exploring the intents that motivate users to\nparticipate in groups, which can be categorized into different types, like the\nsocial-intent and the personal interest-intent. The former refers to users\njoining a group affected by their social links, while the latter relates to\nusers joining groups with like-minded people for self-enjoyment. To comprehend\ndifferent intents, we propose a novel model, DiRec, that first models each\nintent separately and then fuses them together for predictions. Specifically,\nfor social-intent, we introduce the hypergraph structure to model the\nrelationship between groups and members, leading to a richer understanding of\nthe social context. As for interest-intent, we employ novel structural\nrefinement on the interactive graph to uncover more intricate user behaviors\nand group interests, realizing better representation learning of interests.\nFurthermore, we also observe the intent overlapping in real-world scenarios and\ndevise a novel self-supervised learning loss that encourages such alignment for\nfinal recommendations. Extensive experiments on three public datasets show the\nsignificant improvement of DiRec over the state-of-the-art methods.",
        "translated": ""
    },
    {
        "title": "LLaMA-E: Empowering E-commerce Authoring with Multi-Aspect Instruction\n  Following",
        "url": "http://arxiv.org/abs/2308.04913v1",
        "pub_date": "2023-08-09",
        "summary": "E-commerce authoring involves creating attractive, abundant, and targeted\npromotional content to drive product sales. The emergence of large language\nmodels (LLMs) introduces an innovative paradigm, offering a unified solution to\naddress various authoring tasks within this scenario. However, mainstream LLMs\ntrained on general corpora with common sense knowledge reveal limitations in\nfitting complex and personalized features unique to e-commerce products and\ncustomers. Furthermore, LLMs like GPT-3.5 necessitate remote accessibility,\nraising concerns about safeguarding voluminous customer privacy data during\ntransmission. This paper proposes the LLaMA-E, the unified and customized\ninstruction-following language models focusing on diverse e-commerce authoring\ntasks. Specifically, the domain experts create the seed instruction set from\nthe tasks of ads generation, query-enhanced product title rewriting, product\nclassification, purchase intent speculation, and general Q&amp;A. These tasks\nenable the models to comprehensively understand precise e-commerce authoring\nknowledge by interleaving features covering typical service aspects of\ncustomers, sellers, and platforms. The GPT-3.5 is introduced as a teacher\nmodel, which expands the seed instructions to form a training set for the\nLLaMA-E models with various scales. The experimental results show that the\nproposed LLaMA-E models achieve state-of-the-art results in quantitative and\nqualitative evaluations, also exhibiting the advantage in zero-shot scenes. To\nthe best of our knowledge, this study is the first to serve the LLMs to\nspecific e-commerce authoring scenarios.",
        "translated": ""
    },
    {
        "title": "Parallel Knowledge Enhancement based Framework for Multi-behavior\n  Recommendation",
        "url": "http://arxiv.org/abs/2308.04807v1",
        "pub_date": "2023-08-09",
        "summary": "Multi-behavior recommendation algorithms aim to leverage the multiplex\ninteractions between users and items to learn users' latent preferences. Recent\nmulti-behavior recommendation frameworks contain two steps: fusion and\nprediction. In the fusion step, advanced neural networks are used to model the\nhierarchical correlations between user behaviors. In the prediction step,\nmultiple signals are utilized to jointly optimize the model with a multi-task\nlearning (MTL) paradigm. However, recent approaches have not addressed the\nissue caused by imbalanced data distribution in the fusion step, resulting in\nthe learned relationships being dominated by high-frequency behaviors. In the\nprediction step, the existing methods use a gate mechanism to directly\naggregate expert information generated by coupling input, leading to negative\ninformation transfer. To tackle these issues, we propose a Parallel Knowledge\nEnhancement Framework (PKEF) for multi-behavior recommendation. Specifically,\nwe enhance the hierarchical information propagation in the fusion step using\nparallel knowledge (PKF). Meanwhile, in the prediction step, we decouple the\nrepresentations to generate expert information and introduce a projection\nmechanism during aggregation to eliminate gradient conflicts and alleviate\nnegative transfer (PME). We conduct comprehensive experiments on three\nreal-world datasets to validate the effectiveness of our model. The results\nfurther demonstrate the rationality and effectiveness of the designed PKF and\nPME modules. The source code and datasets are available at\nhttps://github.com/MC-CV/PKEF.",
        "translated": ""
    },
    {
        "title": "DiVa: An Iterative Framework to Harvest More Diverse and Valid Labels\n  from User Comments for Music",
        "url": "http://arxiv.org/abs/2308.04805v1",
        "pub_date": "2023-08-09",
        "summary": "Towards sufficient music searching, it is vital to form a complete set of\nlabels for each song. However, current solutions fail to resolve it as they\ncannot produce diverse enough mappings to make up for the information missed by\nthe gold labels. Based on the observation that such missing information may\nalready be presented in user comments, we propose to study the automated music\nlabeling in an essential but under-explored setting, where the model is\nrequired to harvest more diverse and valid labels from the users' comments\ngiven limited gold labels. To this end, we design an iterative framework (DiVa)\nto harvest more $\\underline{\\text{Di}}$verse and $\\underline{\\text{Va}}$lid\nlabels from user comments for music. The framework makes a classifier able to\nform complete sets of labels for songs via pseudo-labels inferred from\npre-trained classifiers and a novel joint score function. The experiment on a\ndensely annotated testing set reveals the superiority of the Diva over\nstate-of-the-art solutions in producing more diverse labels missed by the gold\nlabels. We hope our work can inspire future research on automated music\nlabeling.",
        "translated": ""
    },
    {
        "title": "Entire Space Cascade Delayed Feedback Modeling for Effective Conversion\n  Rate Prediction",
        "url": "http://arxiv.org/abs/2308.04768v1",
        "pub_date": "2023-08-09",
        "summary": "Conversion rate (CVR) prediction is an essential task for large-scale\ne-commerce platforms. However, refund behaviors frequently occur after\nconversion in online shopping systems, which drives us to pay attention to\neffective conversion for building healthier shopping services. This paper\ndefines the probability of item purchasing without any subsequent refund as an\neffective conversion rate (ECVR). A simple paradigm for ECVR prediction is to\ndecompose it into two sub-tasks: CVR prediction and post-conversion refund rate\n(RFR) prediction. However, RFR prediction suffers from data sparsity (DS) and\nsample selection bias (SSB) issues, as the refund behaviors are only available\nafter user purchase. Furthermore, there is delayed feedback in both conversion\nand refund events and they are sequentially dependent, named cascade delayed\nfeedback (CDF), which significantly harms data freshness for model training.\nPrevious studies mainly focus on tackling DS and SSB or delayed feedback for a\nsingle event. To jointly tackle these issues in ECVR prediction, we propose an\nEntire space CAscade Delayed feedback modeling (ECAD) method. Specifically,\nECAD deals with DS and SSB by constructing two tasks including CVR prediction\nand conversion \\&amp; refund rate (CVRFR) prediction using the entire space\nmodeling framework. In addition, it carefully schedules auxiliary tasks to\nleverage both conversion and refund time within data to alleviate CDF.\nExperimental results on the offline industrial dataset and online A/B testing\ndemonstrate the effectiveness of ECAD. In addition, ECAD has been deployed in\none of the recommender systems in Alibaba, contributing to a significant\nimprovement of ECVR.",
        "translated": ""
    },
    {
        "title": "Constructing Holistic Spatio-Temporal Scene Graph for Video Semantic\n  Role Labeling",
        "url": "http://arxiv.org/abs/2308.05081v1",
        "pub_date": "2023-08-09",
        "summary": "Video Semantic Role Labeling (VidSRL) aims to detect the salient events from\ngiven videos, by recognizing the predict-argument event structures and the\ninterrelationships between events. While recent endeavors have put forth\nmethods for VidSRL, they can be mostly subject to two key drawbacks, including\nthe lack of fine-grained spatial scene perception and the insufficiently\nmodeling of video temporality. Towards this end, this work explores a novel\nholistic spatio-temporal scene graph (namely HostSG) representation based on\nthe existing dynamic scene graph structures, which well model both the\nfine-grained spatial semantics and temporal dynamics of videos for VidSRL.\nBuilt upon the HostSG, we present a nichetargeting VidSRL framework. A\nscene-event mapping mechanism is first designed to bridge the gap between the\nunderlying scene structure and the high-level event semantic structure,\nresulting in an overall hierarchical scene-event (termed ICE) graph structure.\nWe further perform iterative structure refinement to optimize the ICE graph,\nsuch that the overall structure representation can best coincide with end task\ndemand. Finally, three subtask predictions of VidSRL are jointly decoded, where\nthe end-to-end paradigm effectively avoids error propagation. On the benchmark\ndataset, our framework boosts significantly over the current best-performing\nmodel. Further analyses are shown for a better understanding of the advances of\nour methods.",
        "translated": ""
    },
    {
        "title": "RadGraph2: Modeling Disease Progression in Radiology Reports via\n  Hierarchical Information Extraction",
        "url": "http://arxiv.org/abs/2308.05046v1",
        "pub_date": "2023-08-09",
        "summary": "We present RadGraph2, a novel dataset for extracting information from\nradiology reports that focuses on capturing changes in disease state and device\nplacement over time. We introduce a hierarchical schema that organizes entities\nbased on their relationships and show that using this hierarchy during training\nimproves the performance of an information extraction model. Specifically, we\npropose a modification to the DyGIE++ framework, resulting in our model HGIE,\nwhich outperforms previous models in entity and relation extraction tasks. We\ndemonstrate that RadGraph2 enables models to capture a wider variety of\nfindings and perform better at relation extraction compared to those trained on\nthe original RadGraph dataset. Our work provides the foundation for developing\nautomated systems that can track disease progression over time and develop\ninformation extraction models that leverage the natural hierarchy of labels in\nthe medical domain.",
        "translated": ""
    },
    {
        "title": "AspectMMKG: A Multi-modal Knowledge Graph with Aspect-aware Entities",
        "url": "http://arxiv.org/abs/2308.04992v1",
        "pub_date": "2023-08-09",
        "summary": "Multi-modal knowledge graphs (MMKGs) combine different modal data (e.g., text\nand image) for a comprehensive understanding of entities. Despite the recent\nprogress of large-scale MMKGs, existing MMKGs neglect the multi-aspect nature\nof entities, limiting the ability to comprehend entities from various\nperspectives. In this paper, we construct AspectMMKG, the first MMKG with\naspect-related images by matching images to different entity aspects.\nSpecifically, we collect aspect-related images from a knowledge base, and\nfurther extract aspect-related sentences from the knowledge base as queries to\nretrieve a large number of aspect-related images via an online image search\nengine. Finally, AspectMMKG contains 2,380 entities, 18,139 entity aspects, and\n645,383 aspect-related images. We demonstrate the usability of AspectMMKG in\nentity aspect linking (EAL) downstream task and show that previous EAL models\nachieve a new state-of-the-art performance with the help of AspectMMKG. To\nfacilitate the research on aspect-related MMKG, we further propose an\naspect-related image retrieval (AIR) model, that aims to correct and expand\naspect-related images in AspectMMKG. We train an AIR model to learn the\nrelationship between entity image and entity aspect-related images by\nincorporating entity image, aspect, and aspect image information. Experimental\nresults indicate that the AIR model could retrieve suitable images for a given\nentity w.r.t different aspects.",
        "translated": ""
    },
    {
        "title": "Exploring Multilingual Text Data Distillation",
        "url": "http://arxiv.org/abs/2308.04982v1",
        "pub_date": "2023-08-09",
        "summary": "With the rise of deep learning, large datasets and complex models have become\ncommon, requiring significant computing power. To address this, data\ndistillation has emerged as a technique to quickly train models with lower\nmemory and time requirements. However, data distillation on text-based datasets\nhasn't been explored much because of the challenges rising due to its discrete\nnature. Additionally, existing dataset distillation methods often struggle to\ngeneralize to new architectures. In the paper, we propose several data\ndistillation techniques for multilingual text classification datasets using\nlanguage-model-based learning methods. We conduct experiments to analyze their\nperformance in terms of classification strength, and cross-architecture\ngeneralization. Furthermore, we investigate the language-specific fairness of\nthe data summaries generated by these methods. Our approach builds upon\nexisting techniques, enhancing cross-architecture generalization in the text\ndata distillation domain.",
        "translated": ""
    },
    {
        "title": "Performance Analysis of Transformer Based Models (BERT, ALBERT and\n  RoBERTa) in Fake News Detection",
        "url": "http://arxiv.org/abs/2308.04950v1",
        "pub_date": "2023-08-09",
        "summary": "Fake news is fake material in a news media format but is not processed\nproperly by news agencies. The fake material can provoke or defame significant\nentities or individuals or potentially even for the personal interests of the\ncreators, causing problems for society. Distinguishing fake news and real news\nis challenging due to limited of domain knowledge and time constraints.\nAccording to the survey, the top three areas most exposed to hoaxes and\nmisinformation by residents are in Banten, DKI Jakarta and West Java. The model\nof transformers is referring to an approach in the field of artificial\nintelligence (AI) in natural language processing utilizing the deep learning\narchitectures. Transformers exercise a powerful attention mechanism to process\ntext in parallel and produce rich and contextual word representations. A\nprevious study indicates a superior performance of a transformer model known as\nBERT over and above non transformer approach. However, some studies suggest the\nperformance can be improved with the use of improved BERT models known as\nALBERT and RoBERTa. However, the modified BERT models are not well explored for\ndetecting fake news in Bahasa Indonesia. In this research, we explore those\ntransformer models and found that ALBERT outperformed other models with 87.6%\naccuracy, 86.9% precision, 86.9% F1-score, and 174.5 run-time (s/epoch)\nrespectively. Source code available at:\nhttps://github.com/Shafna81/fakenewsdetection.git",
        "translated": ""
    },
    {
        "title": "Extrapolating Large Language Models to Non-English by Aligning Languages",
        "url": "http://arxiv.org/abs/2308.04948v1",
        "pub_date": "2023-08-09",
        "summary": "Due to the unbalanced training data distribution, the language ability of\nlarge language models (LLMs) is often biased towards English. In this paper, we\npropose to empower pre-trained LLMs on non-English languages by building\nsemantic alignment across languages. We perform instruction-tuning on LLaMA\nwith both translation task data and cross-lingual general task data to obtain\ncross-lingual models (x-LLaMA). Experiment results on cross-lingual benchmark\nXQUAD and MLQA show that x-LLaMA models outperform the English\ninstruction-tuned counterpart (Alpaca) by 42.50% on average on six non-English\nlanguages. Further experiments on Chinese benchmark C-Eval show that x-LLaMA\nachieves significant improvement on Chinese humanities tasks, outperforming\nAlpaca by 8.2%. We also discover that incorporating non-English text on the\ntarget side of translation data is particularly effective for boosting\nnon-English ability. Besides, we find that semantic alignment within LLM can be\nfurther strengthened as translation task data scales up and we present the\nformulation of the underlying scaling law. Evaluation results on translation\ndataset Flores-101 show that \\method outperforms previous LLaMA-based models in\nall evaluated directions. Code and data will be available at:\nhttps://github.com/OwenNJU/x-LLM.",
        "translated": ""
    },
    {
        "title": "LLMeBench: A Flexible Framework for Accelerating LLMs Benchmarking",
        "url": "http://arxiv.org/abs/2308.04945v1",
        "pub_date": "2023-08-09",
        "summary": "The recent development and success of Large Language Models (LLMs)\nnecessitate an evaluation of their performance across diverse NLP tasks in\ndifferent languages. Although several frameworks have been developed and made\npublicly available, their customization capabilities for specific tasks and\ndatasets are often complex for different users. In this study, we introduce the\nLLMeBench framework. Initially developed to evaluate Arabic NLP tasks using\nOpenAI's GPT and BLOOM models; it can be seamlessly customized for any NLP task\nand model, regardless of language. The framework also features zero- and\nfew-shot learning settings. A new custom dataset can be added in less than 10\nminutes, and users can use their own model API keys to evaluate the task at\nhand. The developed framework has been already tested on 31 unique NLP tasks\nusing 53 publicly available datasets within 90 experimental setups, involving\napproximately 296K data points. We plan to open-source the framework for the\ncommunity (https://github.com/qcri/LLMeBench/). A video demonstrating the\nframework is available online (https://youtu.be/FkQn4UjYA0s).",
        "translated": ""
    },
    {
        "title": "Integrating large language models and active inference to understand eye\n  movements in reading and dyslexia",
        "url": "http://arxiv.org/abs/2308.04941v1",
        "pub_date": "2023-08-09",
        "summary": "We present a novel computational model employing hierarchical active\ninference to simulate reading and eye movements. The model characterizes\nlinguistic processing as inference over a hierarchical generative model,\nfacilitating predictions and inferences at various levels of granularity, from\nsyllables to sentences.\n  Our approach combines the strengths of large language models for realistic\ntextual predictions and active inference for guiding eye movements to\ninformative textual information, enabling the testing of predictions. The model\nexhibits proficiency in reading both known and unknown words and sentences,\nadhering to the distinction between lexical and nonlexical routes in dual-route\ntheories of reading. Notably, our model permits the exploration of maladaptive\ninference effects on eye movements during reading, such as in dyslexia. To\nsimulate this condition, we attenuate the contribution of priors during the\nreading process, leading to incorrect inferences and a more fragmented reading\nstyle, characterized by a greater number of shorter saccades. This alignment\nwith empirical findings regarding eye movements in dyslexic individuals\nhighlights the model's potential to aid in understanding the cognitive\nprocesses underlying reading and eye movements, as well as how reading deficits\nassociated with dyslexia may emerge from maladaptive predictive processing.\n  In summary, our model represents a significant advancement in comprehending\nthe intricate cognitive processes involved in reading and eye movements, with\npotential implications for understanding and addressing dyslexia through the\nsimulation of maladaptive inference. It may offer valuable insights into this\ncondition and contribute to the development of more effective interventions for\ntreatment.",
        "translated": ""
    },
    {
        "title": "Unsupervised Out-of-Distribution Dialect Detection with Mahalanobis\n  Distance",
        "url": "http://arxiv.org/abs/2308.04886v1",
        "pub_date": "2023-08-09",
        "summary": "Dialect classification is used in a variety of applications, such as machine\ntranslation and speech recognition, to improve the overall performance of the\nsystem. In a real-world scenario, a deployed dialect classification model can\nencounter anomalous inputs that differ from the training data distribution,\nalso called out-of-distribution (OOD) samples. Those OOD samples can lead to\nunexpected outputs, as dialects of those samples are unseen during model\ntraining. Out-of-distribution detection is a new research area that has\nreceived little attention in the context of dialect classification. Towards\nthis, we proposed a simple yet effective unsupervised Mahalanobis distance\nfeature-based method to detect out-of-distribution samples. We utilize the\nlatent embeddings from all intermediate layers of a wav2vec 2.0\ntransformer-based dialect classifier model for multi-task learning. Our\nproposed approach outperforms other state-of-the-art OOD detection methods\nsignificantly.",
        "translated": ""
    },
    {
        "title": "SSLRec: A Self-Supervised Learning Library for Recommendation",
        "url": "http://arxiv.org/abs/2308.05697v1",
        "pub_date": "2023-08-10",
        "summary": "Self-supervised learning (SSL) has gained significant interest in recent\nyears as a solution to address the challenges posed by sparse and noisy data in\nrecommender systems. Despite the growing number of SSL algorithms designed to\nprovide state-of-the-art performance in various recommendation scenarios (e.g.,\ngraph collaborative filtering, sequential recommendation, social\nrecommendation, KG-enhanced recommendation), there is still a lack of unified\nframeworks that integrate recommendation algorithms across different domains.\nSuch a framework could serve as the cornerstone for self-supervised\nrecommendation algorithms, unifying the validation of existing methods and\ndriving the design of new ones. To address this gap, we introduce SSLRec, a\nnovel benchmark platform that provides a standardized, flexible, and\ncomprehensive framework for evaluating various SSL-enhanced recommenders. The\nSSLRec library features a modular architecture that allows users to easily\nevaluate state-of-the-art models and a complete set of data augmentation and\nself-supervised toolkits to help create SSL recommendation models with specific\nneeds. Furthermore, SSLRec simplifies the process of training and evaluating\ndifferent recommendation models with consistent and fair settings. Our SSLRec\nplatform covers a comprehensive set of state-of-the-art SSL-enhanced\nrecommendation models across different scenarios, enabling researchers to\nevaluate these cutting-edge models and drive further innovation in the field.\nOur implemented SSLRec framework is available at the source code repository\nhttps://github.com/HKUDS/SSLRec.",
        "translated": ""
    },
    {
        "title": "Finding Already Debunked Narratives via Multistage Retrieval: Enabling\n  Cross-Lingual, Cross-Dataset and Zero-Shot Learning",
        "url": "http://arxiv.org/abs/2308.05680v1",
        "pub_date": "2023-08-10",
        "summary": "The task of retrieving already debunked narratives aims to detect stories\nthat have already been fact-checked. The successful detection of claims that\nhave already been debunked not only reduces the manual efforts of professional\nfact-checkers but can also contribute to slowing the spread of misinformation.\nMainly due to the lack of readily available data, this is an understudied\nproblem, particularly when considering the cross-lingual task, i.e. the\nretrieval of fact-checking articles in a language different from the language\nof the online post being checked. This paper fills this gap by (i) creating a\nnovel dataset to enable research on cross-lingual retrieval of already debunked\nnarratives, using tweets as queries to a database of fact-checking articles;\n(ii) presenting an extensive experiment to benchmark fine-tuned and\noff-the-shelf multilingual pre-trained Transformer models for this task; and\n(iii) proposing a novel multistage framework that divides this cross-lingual\ndebunk retrieval task into refinement and re-ranking stages. Results show that\nthe task of cross-lingual retrieval of already debunked narratives is\nchallenging and off-the-shelf Transformer models fail to outperform a strong\nlexical-based baseline (BM25). Nevertheless, our multistage retrieval framework\nis robust, outperforming BM25 in most scenarios and enabling cross-domain and\nzero-shot learning, without significantly harming the model's performance.",
        "translated": ""
    },
    {
        "title": "LASIGE and UNICAGE solution to the NASA LitCoin NLP Competition",
        "url": "http://arxiv.org/abs/2308.05609v1",
        "pub_date": "2023-08-10",
        "summary": "Biomedical Natural Language Processing (NLP) tends to become cumbersome for\nmost researchers, frequently due to the amount and heterogeneity of text to be\nprocessed. To address this challenge, the industry is continuously developing\nhighly efficient tools and creating more flexible engineering solutions. This\nwork presents the integration between industry data engineering solutions for\nefficient data processing and academic systems developed for Named Entity\nRecognition (LasigeUnicage\\_NER) and Relation Extraction (BiOnt). Our design\nreflects an integration of those components with external knowledge in the form\nof additional training data from other datasets and biomedical ontologies. We\nused this pipeline in the 2022 LitCoin NLP Challenge, where our team\nLasigeUnicage was awarded the 7th Prize out of approximately 200 participating\nteams, reflecting a successful collaboration between the academia (LASIGE) and\nthe industry (Unicage). The software supporting this work is available at\n\\url{https://github.com/lasigeBioTM/Litcoin-Lasige_Unicage}.",
        "translated": ""
    },
    {
        "title": "Multi-domain Recommendation with Embedding Disentangling and Domain\n  Alignment",
        "url": "http://arxiv.org/abs/2308.05508v1",
        "pub_date": "2023-08-10",
        "summary": "Multi-domain recommendation (MDR) aims to provide recommendations for\ndifferent domains (e.g., types of products) with overlapping users/items and is\ncommon for platforms such as Amazon, Facebook, and LinkedIn that host multiple\nservices. Existing MDR models face two challenges: First, it is difficult to\ndisentangle knowledge that generalizes across domains (e.g., a user likes cheap\nitems) and knowledge specific to a single domain (e.g., a user likes blue\nclothing but not blue cars). Second, they have limited ability to transfer\nknowledge across domains with small overlaps. We propose a new MDR method named\nEDDA with two key components, i.e., embedding disentangling recommender and\ndomain alignment, to tackle the two challenges respectively. In particular, the\nembedding disentangling recommender separates both the model and embedding for\nthe inter-domain part and the intra-domain part, while most existing MDR\nmethods only focus on model-level disentangling. The domain alignment leverages\nrandom walks from graph processing to identify similar user/item pairs from\ndifferent domains and encourages similar user/item pairs to have similar\nembeddings, enhancing knowledge transfer. We compare EDDA with 12\nstate-of-the-art baselines on 3 real datasets. The results show that EDDA\nconsistently outperforms the baselines on all datasets and domains. All\ndatasets and codes are available at https://github.com/Stevenn9981/EDDA.",
        "translated": ""
    },
    {
        "title": "Bringing order into the realm of Transformer-based language models for\n  artificial intelligence and law",
        "url": "http://arxiv.org/abs/2308.05502v1",
        "pub_date": "2023-08-10",
        "summary": "Transformer-based language models (TLMs) have widely been recognized to be a\ncutting-edge technology for the successful development of deep-learning-based\nsolutions to problems and applications that require natural language processing\nand understanding. Like for other textual domains, TLMs have indeed pushed the\nstate-of-the-art of AI approaches for many tasks of interest in the legal\ndomain. Despite the first Transformer model being proposed about six years ago,\nthere has been a rapid progress of this technology at an unprecedented rate,\nwhereby BERT and related models represent a major reference, also in the legal\ndomain. This article provides the first systematic overview of TLM-based\nmethods for AI-driven problems and tasks in the legal sphere. A major goal is\nto highlight research advances in this field so as to understand, on the one\nhand, how the Transformers have contributed to the success of AI in supporting\nlegal processes, and on the other hand, what are the current limitations and\nopportunities for further research development.",
        "translated": ""
    },
    {
        "title": "EXPRESSO: A Benchmark and Analysis of Discrete Expressive Speech\n  Resynthesis",
        "url": "http://arxiv.org/abs/2308.05725v1",
        "pub_date": "2023-08-10",
        "summary": "Recent work has shown that it is possible to resynthesize high-quality speech\nbased, not on text, but on low bitrate discrete units that have been learned in\na self-supervised fashion and can therefore capture expressive aspects of\nspeech that are hard to transcribe (prosody, voice styles, non-verbal\nvocalization). The adoption of these methods is still limited by the fact that\nmost speech synthesis datasets are read, severely limiting spontaneity and\nexpressivity. Here, we introduce Expresso, a high-quality expressive speech\ndataset for textless speech synthesis that includes both read speech and\nimprovised dialogues rendered in 26 spontaneous expressive styles. We\nillustrate the challenges and potentials of this dataset with an expressive\nresynthesis benchmark where the task is to encode the input in low-bitrate\nunits and resynthesize it in a target voice while preserving content and style.\nWe evaluate resynthesis quality with automatic metrics for different\nself-supervised discrete encoders, and explore tradeoffs between quality,\nbitrate and invariance to speaker and style. All the dataset, evaluation\nmetrics and baseline models are open source",
        "translated": ""
    },
    {
        "title": "A Preliminary Study of the Intrinsic Relationship between Complexity and\n  Alignment",
        "url": "http://arxiv.org/abs/2308.05696v1",
        "pub_date": "2023-08-10",
        "summary": "Training large language models (LLMs) with open-domain instruction data has\nyielded remarkable success in aligning to end tasks and user preferences.\nExtensive research has highlighted that enhancing the quality and diversity of\ninstruction data consistently improves performance. However, the impact of data\ncomplexity, as a crucial metric, remains relatively unexplored in three\naspects: (1) scaling law, where the sustainability of performance improvements\nwith increasing complexity is uncertain, (2) additional tokens, whether the\nimprovement brought by complexity comes from introducing more training tokens,\nand (3) curriculum tuning, where the potential advantages of incorporating\ninstructions ranging from easy to difficult are not yet fully understood. In\nthis paper, we propose \\textit{tree-instruct} to systematically enhance the\ncomplexity of instruction data in a controllable manner. This approach adds a\nspecified number of nodes into the instruction semantic tree, yielding new\ninstruction data based on the modified tree. By adjusting the number of added\nnodes, we can control the difficulty level in the modified instruction data.\nOur preliminary experiments reveal the following insights: (1) Increasing\ncomplexity consistently leads to sustained performance improvements. For\ninstance, using 1,000 instruction data and 10 nodes resulted in a substantial\n24\\% increase in win rate. (2) Under the same token budget, a few complex\ninstructions outperform diverse yet simple instructions. (3) Curriculum\ninstruction tuning might not yield the anticipated results; focusing on\nincreasing complexity appears to be the key.",
        "translated": ""
    },
    {
        "title": "AST-MHSA : Code Summarization using Multi-Head Self-Attention",
        "url": "http://arxiv.org/abs/2308.05646v1",
        "pub_date": "2023-08-10",
        "summary": "Code summarization aims to generate concise natural language descriptions for\nsource code. The prevailing approaches adopt transformer-based encoder-decoder\narchitectures, where the Abstract Syntax Tree (AST) of the source code is\nutilized for encoding structural information. However, ASTs are much longer\nthan the corresponding source code, and existing methods ignore this size\nconstraint by directly feeding the entire linearized AST into the encoders.\nThis simplistic approach makes it challenging to extract truly valuable\ndependency relations from the overlong input sequence and leads to significant\ncomputational overhead due to self-attention applied to all nodes in the AST.\n  To address this issue effectively and efficiently, we present a model,\nAST-MHSA that uses multi-head attention to extract the important semantic\ninformation from the AST. The model consists of two main components: an encoder\nand a decoder. The encoder takes as input the abstract syntax tree (AST) of the\ncode and generates a sequence of hidden states. The decoder then takes these\nhidden states as input and generates a natural language summary of the code.\n  The multi-head attention mechanism allows the model to learn different\nrepresentations of the input code, which can be combined to generate a more\ncomprehensive summary. The model is trained on a dataset of code and summaries,\nand the parameters of the model are optimized to minimize the loss between the\ngenerated summaries and the ground-truth summaries.",
        "translated": ""
    },
    {
        "title": "IIHT: Medical Report Generation with Image-to-Indicator Hierarchical\n  Transformer",
        "url": "http://arxiv.org/abs/2308.05633v1",
        "pub_date": "2023-08-10",
        "summary": "Automated medical report generation has become increasingly important in\nmedical analysis. It can produce computer-aided diagnosis descriptions and thus\nsignificantly alleviate the doctors' work. Inspired by the huge success of\nneural machine translation and image captioning, various deep learning methods\nhave been proposed for medical report generation. However, due to the inherent\nproperties of medical data, including data imbalance and the length and\ncorrelation between report sequences, the generated reports by existing methods\nmay exhibit linguistic fluency but lack adequate clinical accuracy. In this\nwork, we propose an image-to-indicator hierarchical transformer (IIHT)\nframework for medical report generation. It consists of three modules, i.e., a\nclassifier module, an indicator expansion module and a generator module. The\nclassifier module first extracts image features from the input medical images\nand produces disease-related indicators with their corresponding states. The\ndisease-related indicators are subsequently utilised as input for the indicator\nexpansion module, incorporating the \"data-text-data\" strategy. The\ntransformer-based generator then leverages these extracted features along with\nimage features as auxiliary information to generate final reports. Furthermore,\nthe proposed IIHT method is feasible for radiologists to modify disease\nindicators in real-world scenarios and integrate the operations into the\nindicator expansion module for fluent and accurate medical report generation.\nExtensive experiments and comparisons with state-of-the-art methods under\nvarious evaluation metrics demonstrate the great performance of the proposed\nmethod.",
        "translated": ""
    },
    {
        "title": "You Only Prompt Once: On the Capabilities of Prompt Learning on Large\n  Language Models to Tackle Toxic Content",
        "url": "http://arxiv.org/abs/2308.05596v1",
        "pub_date": "2023-08-10",
        "summary": "The spread of toxic content online is an important problem that has adverse\neffects on user experience online and in our society at large. Motivated by the\nimportance and impact of the problem, research focuses on developing solutions\nto detect toxic content, usually leveraging machine learning (ML) models\ntrained on human-annotated datasets. While these efforts are important, these\nmodels usually do not generalize well and they can not cope with new trends\n(e.g., the emergence of new toxic terms). Currently, we are witnessing a shift\nin the approach to tackling societal issues online, particularly leveraging\nlarge language models (LLMs) like GPT-3 or T5 that are trained on vast corpora\nand have strong generalizability. In this work, we investigate how we can use\nLLMs and prompt learning to tackle the problem of toxic content, particularly\nfocusing on three tasks; 1) Toxicity Classification, 2) Toxic Span Detection,\nand 3) Detoxification. We perform an extensive evaluation over five model\narchitectures and eight datasets demonstrating that LLMs with prompt learning\ncan achieve similar or even better performance compared to models trained on\nthese specific tasks. We find that prompt learning achieves around 10\\%\nimprovement in the toxicity classification task compared to the baselines,\nwhile for the toxic span detection task we find better performance to the best\nbaseline (0.643 vs. 0.640 in terms of $F_1$-score). Finally, for the\ndetoxification task, we find that prompt learning can successfully reduce the\naverage toxicity score (from 0.775 to 0.213) while preserving semantic meaning.",
        "translated": ""
    },
    {
        "title": "Do Language Models Refer?",
        "url": "http://arxiv.org/abs/2308.05576v1",
        "pub_date": "2023-08-10",
        "summary": "What do language models (LMs) do with language? Everyone agrees that they\nproduce sequences of (mostly) coherent sentences. But are they saying anything\nwith those strings or simply babbling in a convincing simulacrum of language\nuse? This is a vague question, and there are many ways of making it precise.\nHere we will address one aspect of the question, namely, whether LMs' words\nrefer: that is, whether the outputs of LMs achieve \"word-to-world\" connections.\nThere is prima facie reason to think they do not since LMs do not interact with\nthe world in the way that ordinary language users do. Drawing on insights from\nthe externalist tradition in philosophy of language, we argue that appearances\nare misleading and that there is good reason to think that LMs can refer.",
        "translated": ""
    },
    {
        "title": "Exploring Linguistic Similarity and Zero-Shot Learning for Multilingual\n  Translation of Dravidian Languages",
        "url": "http://arxiv.org/abs/2308.05574v1",
        "pub_date": "2023-08-10",
        "summary": "Current research in zero-shot translation is plagued by several issues such\nas high compute requirements, increased training time and off target\ntranslations. Proposed remedies often come at the cost of additional data or\ncompute requirements. Pivot based neural machine translation is preferred over\na single-encoder model for most settings despite the increased training and\nevaluation time. In this work, we overcome the shortcomings of zero-shot\ntranslation by taking advantage of transliteration and linguistic similarity.\nWe build a single encoder-decoder neural machine translation system for\nDravidian-Dravidian multilingual translation and perform zero-shot translation.\nWe compare the data vs zero-shot accuracy tradeoff and evaluate the performance\nof our vanilla method against the current state of the art pivot based method.\nWe also test the theory that morphologically rich languages require large\nvocabularies by restricting the vocabulary using an optimal transport based\ntechnique. Our model manages to achieves scores within 3 BLEU of large-scale\npivot-based models when it is trained on 50\\% of the language directions.",
        "translated": ""
    },
    {
        "title": "A Large Language Model Enhanced Conversational Recommender System",
        "url": "http://arxiv.org/abs/2308.06212v1",
        "pub_date": "2023-08-11",
        "summary": "Conversational recommender systems (CRSs) aim to recommend high-quality items\nto users through a dialogue interface. It usually contains multiple sub-tasks,\nsuch as user preference elicitation, recommendation, explanation, and item\ninformation search. To develop effective CRSs, there are some challenges: 1)\nhow to properly manage sub-tasks; 2) how to effectively solve different\nsub-tasks; and 3) how to correctly generate responses that interact with users.\nRecently, Large Language Models (LLMs) have exhibited an unprecedented ability\nto reason and generate, presenting a new opportunity to develop more powerful\nCRSs. In this work, we propose a new LLM-based CRS, referred to as LLMCRS, to\naddress the above challenges. For sub-task management, we leverage the\nreasoning ability of LLM to effectively manage sub-task. For sub-task solving,\nwe collaborate LLM with expert models of different sub-tasks to achieve the\nenhanced performance. For response generation, we utilize the generation\nability of LLM as a language interface to better interact with users.\nSpecifically, LLMCRS divides the workflow into four stages: sub-task detection,\nmodel matching, sub-task execution, and response generation. LLMCRS also\ndesigns schema-based instruction, demonstration-based instruction, dynamic\nsub-task and model matching, and summary-based generation to instruct LLM to\ngenerate desired results in the workflow. Finally, to adapt LLM to\nconversational recommendations, we also propose to fine-tune LLM with\nreinforcement learning from CRSs performance feedback, referred to as RLPF.\nExperimental results on benchmark datasets show that LLMCRS with RLPF\noutperforms the existing methods.",
        "translated": ""
    },
    {
        "title": "Identification of the Relevance of Comments in Codes Using Bag of Words\n  and Transformer Based Models",
        "url": "http://arxiv.org/abs/2308.06144v1",
        "pub_date": "2023-08-11",
        "summary": "The Forum for Information Retrieval (FIRE) started a shared task this year\nfor classification of comments of different code segments. This is binary text\nclassification task where the objective is to identify whether comments given\nfor certain code segments are relevant or not. The BioNLP-IISERB group at the\nIndian Institute of Science Education and Research Bhopal (IISERB) participated\nin this task and submitted five runs for five different models. The paper\npresents the overview of the models and other significant findings on the\ntraining corpus. The methods involve different feature engineering schemes and\ntext classification techniques. The performance of the classical bag of words\nmodel and transformer-based models were explored to identify significant\nfeatures from the given training corpus. We have explored different classifiers\nviz., random forest, support vector machine and logistic regression using the\nbag of words model. Furthermore, the pre-trained transformer based models like\nBERT, RoBERT and ALBERT were also used by fine-tuning them on the given\ntraining corpus. The performance of different such models over the training\ncorpus were reported and the best five models were implemented on the given\ntest corpus. The empirical results show that the bag of words model outperforms\nthe transformer based models, however, the performance of our runs are not\nreasonably well in both training and test corpus. This paper also addresses the\nlimitations of the models and scope for further improvement.",
        "translated": ""
    },
    {
        "title": "Toward a Better Understanding of Loss Functions for Collaborative\n  Filtering",
        "url": "http://arxiv.org/abs/2308.06091v1",
        "pub_date": "2023-08-11",
        "summary": "Collaborative filtering (CF) is a pivotal technique in modern recommender\nsystems. The learning process of CF models typically consists of three\ncomponents: interaction encoder, loss function, and negative sampling. Although\nmany existing studies have proposed various CF models to design sophisticated\ninteraction encoders, recent work shows that simply reformulating the loss\nfunctions can achieve significant performance gains. This paper delves into\nanalyzing the relationship among existing loss functions. Our mathematical\nanalysis reveals that the previous loss functions can be interpreted as\nalignment and uniformity functions: (i) the alignment matches user and item\nrepresentations, and (ii) the uniformity disperses user and item distributions.\nInspired by this analysis, we propose a novel loss function that improves the\ndesign of alignment and uniformity considering the unique patterns of datasets\ncalled Margin-aware Alignment and Weighted Uniformity (MAWU). The key novelty\nof MAWU is two-fold: (i) margin-aware alignment (MA) mitigates\nuser/item-specific popularity biases, and (ii) weighted uniformity (WU) adjusts\nthe significance between user and item uniformities to reflect the inherent\ncharacteristics of datasets. Extensive experimental results show that MF and\nLightGCN equipped with MAWU are comparable or superior to state-of-the-art CF\nmodels with various loss functions on three public datasets.",
        "translated": ""
    },
    {
        "title": "Deep Context Interest Network for Click-Through Rate Prediction",
        "url": "http://arxiv.org/abs/2308.06037v1",
        "pub_date": "2023-08-11",
        "summary": "Click-Through Rate (CTR) prediction, estimating the probability of a user\nclicking on an item, is essential in industrial applications, such as online\nadvertising. Many works focus on user behavior modeling to improve CTR\nprediction performance. However, most of those methods only model users'\npositive interests from users' click items while ignoring the context\ninformation, which is the display items around the clicks, resulting in\ninferior performance. In this paper, we highlight the importance of context\ninformation on user behavior modeling and propose a novel model named Deep\nContext Interest Network (DCIN), which integrally models the click and its\ndisplay context to learn users' context-aware interests. DCIN consists of three\nkey modules: 1) Position-aware Context Aggregation Module (PCAM), which\nperforms aggregation of display items with an attention mechanism; 2)\nFeedback-Context Fusion Module (FCFM), which fuses the representation of clicks\nand display contexts through non-linear feature interaction; 3) Interest\nMatching Module (IMM), which activates interests related with the target item.\nMoreover, we provide our hands-on solution to implement our DCIN model on\nlarge-scale industrial systems. The significant improvements in both offline\nand online evaluations demonstrate the superiority of our proposed DCIN method.\nNotably, DCIN has been deployed on our online advertising system serving the\nmain traffic, which brings 1.5% CTR and 1.5% RPM lift.",
        "translated": ""
    },
    {
        "title": "Designing a User Contextual Profile Ontology: A Focus on the Vehicle\n  Sales Domain",
        "url": "http://arxiv.org/abs/2308.06018v1",
        "pub_date": "2023-08-11",
        "summary": "In the digital age, it is crucial to understand and tailor experiences for\nusers interacting with systems and applications. This requires the creation of\nuser contextual profiles that combine user profiles with contextual\ninformation. However, there is a lack of research on the integration of\ncontextual information with different user profiles. This study aims to address\nthis gap by designing a user contextual profile ontology that considers both\nuser profiles and contextual information on each profile. Specifically, we\npresent a design and development of the user contextual profile ontology with a\nfocus on the vehicle sales domain. Our designed ontology serves as a structural\nfoundation for standardizing the representation of user profiles and contextual\ninformation, enhancing the system's ability to capture user preferences and\ncontextual information of the user accurately. Moreover, we illustrate a case\nstudy using the User Contextual Profile Ontology in generating personalized\nrecommendations for vehicle sales domain.",
        "translated": ""
    },
    {
        "title": "Self-Alignment with Instruction Backtranslation",
        "url": "http://arxiv.org/abs/2308.06259v1",
        "pub_date": "2023-08-11",
        "summary": "We present a scalable method to build a high quality instruction following\nlanguage model by automatically labelling human-written text with corresponding\ninstructions. Our approach, named instruction backtranslation, starts with a\nlanguage model finetuned on a small amount of seed data, and a given web\ncorpus. The seed model is used to construct training examples by generating\ninstruction prompts for web documents (self-augmentation), and then selecting\nhigh quality examples from among these candidates (self-curation). This data is\nthen used to finetune a stronger model. Finetuning LLaMa on two iterations of\nour approach yields a model that outperforms all other LLaMa-based models on\nthe Alpaca leaderboard not relying on distillation data, demonstrating highly\neffective self-alignment.",
        "translated": ""
    },
    {
        "title": "KETM:A Knowledge-Enhanced Text Matching method",
        "url": "http://arxiv.org/abs/2308.06235v1",
        "pub_date": "2023-08-11",
        "summary": "Text matching is the task of matching two texts and determining the\nrelationship between them, which has extensive applications in natural language\nprocessing tasks such as reading comprehension, and Question-Answering systems.\nThe mainstream approach is to compute text representations or to interact with\nthe text through attention mechanism, which is effective in text matching\ntasks. However, the performance of these models is insufficient for texts that\nrequire commonsense knowledge-based reasoning. To this end, in this paper, We\nintroduce a new model for text matching called the Knowledge Enhanced Text\nMatching model (KETM), to enrich contextual representations with real-world\ncommon-sense knowledge from external knowledge sources to enhance our model\nunderstanding and reasoning. First, we use Wiktionary to retrieve the text word\ndefinitions as our external knowledge. Secondly, we feed text and knowledge to\nthe text matching module to extract their feature vectors. The text matching\nmodule is used as an interaction module by integrating the encoder layer, the\nco-attention layer, and the aggregation layer. Specifically, the interaction\nprocess is iterated several times to obtain in-depth interaction information\nand extract the feature vectors of text and knowledge by multi-angle pooling.\nThen, we fuse text and knowledge using a gating mechanism to learn the ratio of\ntext and knowledge fusion by a neural network that prevents noise generated by\nknowledge. After that, experimental validation on four datasets are carried\nout, and the experimental results show that our proposed model performs well on\nall four datasets, and the performance of our method is improved compared to\nthe base model without adding external knowledge, which validates the\neffectiveness of our proposed method. The code is available at\nhttps://github.com/1094701018/KETM",
        "translated": ""
    },
    {
        "title": "Thinking Like an Expert:Multimodal Hypergraph-of-Thought (HoT) Reasoning\n  to boost Foundation Modals",
        "url": "http://arxiv.org/abs/2308.06207v1",
        "pub_date": "2023-08-11",
        "summary": "Reasoning ability is one of the most crucial capabilities of a foundation\nmodel, signifying its capacity to address complex reasoning tasks.\nChain-of-Thought (CoT) technique is widely regarded as one of the effective\nmethods for enhancing the reasoning ability of foundation models and has\ngarnered significant attention. However, the reasoning process of CoT is\nlinear, step-by-step, similar to personal logical reasoning, suitable for\nsolving general and slightly complicated problems. On the contrary, the\nthinking pattern of an expert owns two prominent characteristics that cannot be\nhandled appropriately in CoT, i.e., high-order multi-hop reasoning and\nmultimodal comparative judgement. Therefore, the core motivation of this paper\nis transcending CoT to construct a reasoning paradigm that can think like an\nexpert. The hyperedge of a hypergraph could connect various vertices, making it\nnaturally suitable for modelling high-order relationships. Inspired by this,\nthis paper innovatively proposes a multimodal Hypergraph-of-Thought (HoT)\nreasoning paradigm, which enables the foundation models to possess the\nexpert-level ability of high-order multi-hop reasoning and multimodal\ncomparative judgement. Specifically, a textual hypergraph-of-thought is\nconstructed utilizing triple as the primary thought to model higher-order\nrelationships, and a hyperedge-of-thought is generated through multi-hop\nwalking paths to achieve multi-hop inference. Furthermore, we devise a visual\nhypergraph-of-thought to interact with the textual hypergraph-of-thought via\nCross-modal Co-Attention Graph Learning for multimodal comparative\nverification. Experimentations on the ScienceQA benchmark demonstrate the\nproposed HoT-based T5 outperforms CoT-based GPT3.5 and chatGPT, which is on par\nwith CoT-based GPT4 with a lower model size.",
        "translated": ""
    },
    {
        "title": "Weakly Supervised Text Classification on Free Text Comments in\n  Patient-Reported Outcome Measures",
        "url": "http://arxiv.org/abs/2308.06199v1",
        "pub_date": "2023-08-11",
        "summary": "Free text comments (FTC) in patient-reported outcome measures (PROMs) data\nare typically analysed using manual methods, such as content analysis, which is\nlabour-intensive and time-consuming. Machine learning analysis methods are\nlargely unsupervised, necessitating post-analysis interpretation. Weakly\nsupervised text classification (WSTC) can be a valuable method of analysis to\nclassify domain-specific text data in which there is limited labelled data. In\nthis paper, we apply five WSTC techniques to FTC in PROMs data to identify\nhealth-related quality of life (HRQoL) themes reported by colorectal cancer\npatients. The WSTC methods label all the themes mentioned in the FTC. The\nresults showed moderate performance on the PROMs data, mainly due to the\nprecision of the models, and variation between themes. Evaluation of the\nclassification performance illustrated the potential and limitations of keyword\nbased WSTC to label PROMs FTC when labelled data is limited.",
        "translated": ""
    },
    {
        "title": "Assessing Guest Nationality Composition from Hotel Reviews",
        "url": "http://arxiv.org/abs/2308.06175v1",
        "pub_date": "2023-08-11",
        "summary": "Many hotels target guest acquisition efforts to specific markets in order to\nbest anticipate individual preferences and needs of their guests. Likewise,\nsuch strategic positioning is a prerequisite for efficient marketing budget\nallocation. Official statistics report on the number of visitors from different\ncountries, but no fine-grained information on the guest composition of\nindividual businesses exists. There is, however, growing interest in such data\nfrom competitors, suppliers, researchers and the general public. We demonstrate\nhow machine learning can be leveraged to extract references to guest\nnationalities from unstructured text reviews in order to dynamically assess and\nmonitor the dynamics of guest composition of individual businesses. In\nparticular, we show that a rather simple architecture of pre-trained embeddings\nand stacked LSTM layers provides a better performance-runtime tradeoff than\nmore complex state-of-the-art language models.",
        "translated": ""
    },
    {
        "title": "Task Conditioned BERT for Joint Intent Detection and Slot-filling",
        "url": "http://arxiv.org/abs/2308.06165v1",
        "pub_date": "2023-08-11",
        "summary": "Dialogue systems need to deal with the unpredictability of user intents to\ntrack dialogue state and the heterogeneity of slots to understand user\npreferences. In this paper we investigate the hypothesis that solving these\nchallenges as one unified model will allow the transfer of parameter support\ndata across the different tasks. The proposed principled model is based on a\nTransformer encoder, trained on multiple tasks, and leveraged by a rich input\nthat conditions the model on the target inferences. Conditioning the\nTransformer encoder on multiple target inferences over the same corpus, i.e.,\nintent and multiple slot types, allows learning richer language interactions\nthan a single-task model would be able to. In fact, experimental results\ndemonstrate that conditioning the model on an increasing number of dialogue\ninference tasks leads to improved results: on the MultiWOZ dataset, the joint\nintent and slot detection can be improved by 3.2\\% by conditioning on intent,\n10.8\\% by conditioning on slot and 14.4\\% by conditioning on both intent and\nslots. Moreover, on real conversations with Farfetch costumers, the proposed\nconditioned BERT can achieve high joint-goal and intent detection performance\nthroughout a dialogue.",
        "translated": ""
    },
    {
        "title": "Improving Joint Speech-Text Representations Without Alignment",
        "url": "http://arxiv.org/abs/2308.06125v1",
        "pub_date": "2023-08-11",
        "summary": "The last year has seen astonishing progress in text-prompted image generation\npremised on the idea of a cross-modal representation space in which the text\nand image domains are represented jointly. In ASR, this idea has found\napplication as joint speech-text encoders that can scale to the capacities of\nvery large parameter models by being trained on both unpaired speech and text.\nWhile these methods show promise, they have required special treatment of the\nsequence-length mismatch inherent in speech and text, either by up-sampling\nheuristics or an explicit alignment model. In this work, we offer evidence that\njoint speech-text encoders naturally achieve consistent representations across\nmodalities by disregarding sequence length, and argue that consistency losses\ncould forgive length differences and simply assume the best alignment. We show\nthat such a loss improves downstream WER in both a large-parameter monolingual\nand multilingual system.",
        "translated": ""
    },
    {
        "title": "Lip2Vec: Efficient and Robust Visual Speech Recognition via\n  Latent-to-Latent Visual to Audio Representation Mapping",
        "url": "http://arxiv.org/abs/2308.06112v1",
        "pub_date": "2023-08-11",
        "summary": "Visual Speech Recognition (VSR) differs from the common perception tasks as\nit requires deeper reasoning over the video sequence, even by human experts.\nDespite the recent advances in VSR, current approaches rely on labeled data to\nfully train or finetune their models predicting the target speech. This hinders\ntheir ability to generalize well beyond the training set and leads to\nperformance degeneration under out-of-distribution challenging scenarios.\nUnlike previous works that involve auxiliary losses or complex training\nprocedures and architectures, we propose a simple approach, named Lip2Vec that\nis based on learning a prior model. Given a robust visual speech encoder, this\nnetwork maps the encoded latent representations of the lip sequence to their\ncorresponding latents from the audio pair, which are sufficiently invariant for\neffective text decoding. The generated audio representation is then decoded to\ntext using an off-the-shelf Audio Speech Recognition (ASR) model. The proposed\nmodel compares favorably with fully-supervised learning methods on the LRS3\ndataset achieving 26 WER. Unlike SoTA approaches, our model keeps a reasonable\nperformance on the VoxCeleb test set. We believe that reprogramming the VSR as\nan ASR task narrows the performance gap between the two and paves the way for\nmore flexible formulations of lip reading.",
        "translated": ""
    },
    {
        "title": "Cross-Attribute Matrix Factorization Model with Shared User Embedding",
        "url": "http://arxiv.org/abs/2308.07284v1",
        "pub_date": "2023-08-14",
        "summary": "Over the past few years, deep learning has firmly established its prowess\nacross various domains, including computer vision, speech recognition, and\nnatural language processing. Motivated by its outstanding success, researchers\nhave been directing their efforts towards applying deep learning techniques to\nrecommender systems. Neural collaborative filtering (NCF) and Neural Matrix\nFactorization (NeuMF) refreshes the traditional inner product in matrix\nfactorization with a neural architecture capable of learning complex and\ndata-driven functions. While these models effectively capture user-item\ninteractions, they overlook the specific attributes of both users and items.\nThis can lead to robustness issues, especially for items and users that belong\nto the \"long tail\". Such challenges are commonly recognized in recommender\nsystems as a part of the cold-start problem. A direct and intuitive approach to\naddress this issue is by leveraging the features and attributes of the items\nand users themselves. In this paper, we introduce a refined NeuMF model that\nconsiders not only the interaction between users and items, but also acrossing\nassociated attributes. Moreover, our proposed architecture features a shared\nuser embedding, seamlessly integrating with user embeddings to imporve the\nrobustness and effectively address the cold-start problem. Rigorous experiments\non both the Movielens and Pinterest datasets demonstrate the superiority of our\nCross-Attribute Matrix Factorization model, particularly in scenarios\ncharacterized by higher dataset sparsity.",
        "translated": ""
    },
    {
        "title": "EasyEdit: An Easy-to-use Knowledge Editing Framework for Large Language\n  Models",
        "url": "http://arxiv.org/abs/2308.07269v1",
        "pub_date": "2023-08-14",
        "summary": "Large Language Models (LLMs) usually suffer from knowledge cutoff or fallacy\nissues, which means they are unaware of unseen events or generate text with\nincorrect facts owing to the outdated/noisy data. To this end, many knowledge\nediting approaches for LLMs have emerged -- aiming to subtly inject/edit\nupdated knowledge or adjust undesired behavior while minimizing the impact on\nunrelated inputs. Nevertheless, due to significant differences among various\nknowledge editing methods and the variations in task setups, there is no\nstandard implementation framework available for the community, which hinders\npractitioners to apply knowledge editing to applications. To address these\nissues, we propose EasyEdit, an easy-to-use knowledge editing framework for\nLLMs. It supports various cutting-edge knowledge editing approaches and can be\nreadily apply to many well-known LLMs such as T5, GPT-J, LlaMA, etc.\nEmpirically, we report the knowledge editing results on LlaMA-2 with EasyEdit,\ndemonstrating that knowledge editing surpasses traditional fine-tuning in terms\nof reliability and generalization. We have released the source code on GitHub\nat https://github.com/zjunlp/EasyEdit, along with Google Colab tutorials and\ncomprehensive documentation for beginners to get started. Besides, we present\nan online system for real-time knowledge editing, and a demo video at\nhttp://knowlm.zjukg.cn/easyedit.mp4.",
        "translated": ""
    },
    {
        "title": "MM-GEF: Multi-modal representation meet collaborative filtering",
        "url": "http://arxiv.org/abs/2308.07222v1",
        "pub_date": "2023-08-14",
        "summary": "In modern e-commerce, item content features in various modalities offer\naccurate yet comprehensive information to recommender systems. The majority of\nprevious work either focuses on learning effective item representation during\nmodelling user-item interactions, or exploring item-item relationships by\nanalysing multi-modal features. Those methods, however, fail to incorporate the\ncollaborative item-user-item relationships into the multi-modal feature-based\nitem structure. In this work, we propose a graph-based item structure\nenhancement method MM-GEF: Multi-Modal recommendation with Graph Early-Fusion,\nwhich effectively combines the latent item structure underlying multi-modal\ncontents with the collaborative signals. Instead of processing the content\nfeature in different modalities separately, we show that the early-fusion of\nmulti-modal features provides significant improvement. MM-GEF learns refined\nitem representations by injecting structural information obtained from both\nmulti-modal and collaborative signals. Through extensive experiments on four\npublicly available datasets, we demonstrate systematical improvements of our\nmethod over state-of-the-art multi-modal recommendation methods.",
        "translated": ""
    },
    {
        "title": "gSASRec: Reducing Overconfidence in Sequential Recommendation Trained\n  with Negative Sampling",
        "url": "http://arxiv.org/abs/2308.07192v1",
        "pub_date": "2023-08-14",
        "summary": "A large catalogue size is one of the central challenges in training\nrecommendation models: a large number of items makes them memory and\ncomputationally inefficient to compute scores for all items during training,\nforcing these models to deploy negative sampling. However, negative sampling\nincreases the proportion of positive interactions in the training data, and\ntherefore models trained with negative sampling tend to overestimate the\nprobabilities of positive interactions a phenomenon we call overconfidence.\nWhile the absolute values of the predicted scores or probabilities are not\nimportant for the ranking of retrieved recommendations, overconfident models\nmay fail to estimate nuanced differences in the top-ranked items, resulting in\ndegraded performance. In this paper, we show that overconfidence explains why\nthe popular SASRec model underperforms when compared to BERT4Rec. This is\ncontrary to the BERT4Rec authors explanation that the difference in performance\nis due to the bi-directional attention mechanism. To mitigate overconfidence,\nwe propose a novel Generalised Binary Cross-Entropy Loss function (gBCE) and\ntheoretically prove that it can mitigate overconfidence. We further propose the\ngSASRec model, an improvement over SASRec that deploys an increased number of\nnegatives and the gBCE loss. We show through detailed experiments on three\ndatasets that gSASRec does not exhibit the overconfidence problem. As a result,\ngSASRec can outperform BERT4Rec (e.g. +9.47% NDCG on the MovieLens-1M dataset),\nwhile requiring less training time (e.g. -73% training time on MovieLens-1M).\nMoreover, in contrast to BERT4Rec, gSASRec is suitable for large datasets that\ncontain more than 1 million items.",
        "translated": ""
    },
    {
        "title": "Natural Language is All a Graph Needs",
        "url": "http://arxiv.org/abs/2308.07134v1",
        "pub_date": "2023-08-14",
        "summary": "The emergence of large-scale pre-trained language models, such as ChatGPT,\nhas revolutionized various research fields in artificial intelligence.\nTransformers-based large language models (LLMs) have gradually replaced CNNs\nand RNNs to unify fields of computer vision and natural language processing.\nCompared with the data that exists relatively independently such as images,\nvideos or texts, graph is a type of data that contains rich structural and\nrelational information. Meanwhile, natural language, as one of the most\nexpressive mediums, excels in describing complex structures. However, existing\nwork on incorporating graph learning problems into the generative language\nmodeling framework remains very limited. As the importance of language models\ncontinues to grow, it becomes essential to explore whether LLMs can also\nreplace GNNs as the foundational model for graphs. In this paper, we propose\nInstructGLM (Instruction-finetuned Graph Language Model), systematically design\nhighly scalable prompts based on natural language instructions, and use natural\nlanguage to describe the geometric structure and node features of the graph for\ninstruction tuning an LLMs to perform learning and inference on graphs in a\ngenerative manner. Our method exceeds all competitive GNN baselines on\nogbn-arxiv, Cora and PubMed datasets, which demonstrates the effectiveness of\nour method and sheds light on generative language models replacing GNNs as the\nfoundation model for graph machine learning.",
        "translated": ""
    },
    {
        "title": "Platypus: Quick, Cheap, and Powerful Refinement of LLMs",
        "url": "http://arxiv.org/abs/2308.07317v1",
        "pub_date": "2023-08-14",
        "summary": "We present $\\textbf{Platypus}$, a family of fine-tuned and merged Large\nLanguage Models (LLMs) that achieves the strongest performance and currently\nstands at first place in HuggingFace's Open LLM Leaderboard as of the release\ndate of this work. In this work we describe (1) our curated dataset\n$\\textbf{Open-Platypus}$, that is a subset of other open datasets and which\n$\\textit{we release to the public}$ (2) our process of fine-tuning and merging\nLoRA modules in order to conserve the strong prior of pretrained LLMs, while\nbringing specific domain knowledge to the surface (3) our efforts in checking\nfor test data leaks and contamination in the training data, which can inform\nfuture research. Specifically, the Platypus family achieves strong performance\nin quantitative LLM metrics across model sizes, topping the global Open LLM\nleaderboard while using just a fraction of the fine-tuning data and overall\ncompute that are required for other state-of-the-art fine-tuned LLMs. In\nparticular, a 13B Platypus model can be trained on $\\textit{a single}$ A100 GPU\nusing 25k questions in 5 hours. This is a testament of the quality of our\nOpen-Platypus dataset, and opens opportunities for more improvements in the\nfield. Project page: https://platypus-llm.github.io",
        "translated": ""
    },
    {
        "title": "LLM Self Defense: By Self Examination, LLMs Know They Are Being Tricked",
        "url": "http://arxiv.org/abs/2308.07308v1",
        "pub_date": "2023-08-14",
        "summary": "Large language models (LLMs) have skyrocketed in popularity in recent years\ndue to their ability to generate high-quality text in response to human\nprompting. However, these models have been shown to have the potential to\ngenerate harmful content in response to user prompting (e.g., giving users\ninstructions on how to commit crimes). There has been a focus in the literature\non mitigating these risks, through methods like aligning models with human\nvalues through reinforcement learning. However, it has been shown that even\naligned language models are susceptible to adversarial attacks that bypass\ntheir restrictions on generating harmful text. We propose a simple approach to\ndefending against these attacks by having a large language model filter its own\nresponses. Our current results show that even if a model is not fine-tuned to\nbe aligned with human values, it is possible to stop it from presenting harmful\ncontent to users by validating the content using a language model.",
        "translated": ""
    },
    {
        "title": "Neural Authorship Attribution: Stylometric Analysis on Large Language\n  Models",
        "url": "http://arxiv.org/abs/2308.07305v1",
        "pub_date": "2023-08-14",
        "summary": "Large language models (LLMs) such as GPT-4, PaLM, and Llama have\nsignificantly propelled the generation of AI-crafted text. With rising concerns\nabout their potential misuse, there is a pressing need for AI-generated-text\nforensics. Neural authorship attribution is a forensic effort, seeking to trace\nAI-generated text back to its originating LLM. The LLM landscape can be divided\ninto two primary categories: proprietary and open-source. In this work, we\ndelve into these emerging categories of LLMs, focusing on the nuances of neural\nauthorship attribution. To enrich our understanding, we carry out an empirical\nanalysis of LLM writing signatures, highlighting the contrasts between\nproprietary and open-source models, and scrutinizing variations within each\ngroup. By integrating stylometric features across lexical, syntactic, and\nstructural aspects of language, we explore their potential to yield\ninterpretable results and augment pre-trained language model-based classifiers\nutilized in neural authorship attribution. Our findings, based on a range of\nstate-of-the-art LLMs, provide empirical insights into neural authorship\nattribution, paving the way for future investigations aimed at mitigating the\nthreats posed by AI-generated misinformation.",
        "translated": ""
    },
    {
        "title": "The Devil is in the Errors: Leveraging Large Language Models for\n  Fine-grained Machine Translation Evaluation",
        "url": "http://arxiv.org/abs/2308.07286v1",
        "pub_date": "2023-08-14",
        "summary": "Automatic evaluation of machine translation (MT) is a critical tool driving\nthe rapid iterative development of MT systems. While considerable progress has\nbeen made on estimating a single scalar quality score, current metrics lack the\ninformativeness of more detailed schemes that annotate individual errors, such\nas Multidimensional Quality Metrics (MQM). In this paper, we help fill this gap\nby proposing AutoMQM, a prompting technique which leverages the reasoning and\nin-context learning capabilities of large language models (LLMs) and asks them\nto identify and categorize errors in translations. We start by evaluating\nrecent LLMs, such as PaLM and PaLM-2, through simple score prediction\nprompting, and we study the impact of labeled data through in-context learning\nand finetuning. We then evaluate AutoMQM with PaLM-2 models, and we find that\nit improves performance compared to just prompting for scores (with\nparticularly large gains for larger models) while providing interpretability\nthrough error spans that align with human annotations.",
        "translated": ""
    },
    {
        "title": "Comparison between parameter-efficient techniques and full fine-tuning:\n  A case study on multilingual news article classification",
        "url": "http://arxiv.org/abs/2308.07282v1",
        "pub_date": "2023-08-14",
        "summary": "Adapters and Low-Rank Adaptation (LoRA) are parameter-efficient fine-tuning\ntechniques designed to make the training of language models more efficient.\nPrevious results demonstrated that these methods can even improve performance\non some classification tasks. This paper complements the existing research by\ninvestigating how these techniques influence the classification performance and\ncomputation costs compared to full fine-tuning when applied to multilingual\ntext classification tasks (genre, framing, and persuasion techniques detection;\nwith different input lengths, number of predicted classes and classification\ndifficulty), some of which have limited training data. In addition, we conduct\nin-depth analyses of their efficacy across different training scenarios\n(training on the original multilingual data; on the translations into English;\nand on a subset of English-only data) and different languages. Our findings\nprovide valuable insights into the applicability of the parameter-efficient\nfine-tuning techniques, particularly to complex multilingual and multilabel\nclassification tasks.",
        "translated": ""
    },
    {
        "title": "Dialogue for Prompting: a Policy-Gradient-Based Discrete Prompt\n  Optimization for Few-shot Learning",
        "url": "http://arxiv.org/abs/2308.07272v1",
        "pub_date": "2023-08-14",
        "summary": "Prompt-based pre-trained language models (PLMs) paradigm have succeeded\nsubstantially in few-shot natural language processing (NLP) tasks. However,\nprior discrete prompt optimization methods require expert knowledge to design\nthe base prompt set and identify high-quality prompts, which is costly,\ninefficient, and subjective. Meanwhile, existing continuous prompt optimization\nmethods improve the performance by learning the ideal prompts through the\ngradient information of PLMs, whose high computational cost, and low\nreadability and generalizability are often concerning. To address the research\ngap, we propose a Dialogue-comprised Policy-gradient-based Discrete Prompt\nOptimization ($DP_2O$) method. We first design a multi-round dialogue alignment\nstrategy for readability prompt set generation based on GPT-4. Furthermore, we\npropose an efficient prompt screening metric to identify high-quality prompts\nwith linear complexity. Finally, we construct a reinforcement learning (RL)\nframework based on policy gradients to match the prompts to inputs optimally.\nBy training a policy network with only 0.67% of the PLM parameter size on the\ntasks in the few-shot setting, $DP_2O$ outperforms the state-of-the-art (SOTA)\nmethod by 1.52% in accuracy on average on four open-source datasets. Moreover,\nsubsequent experiments also demonstrate that $DP_2O$ has good universality,\nrobustness, and generalization ability.",
        "translated": ""
    },
    {
        "title": "ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate",
        "url": "http://arxiv.org/abs/2308.07201v1",
        "pub_date": "2023-08-14",
        "summary": "Text evaluation has historically posed significant challenges, often\ndemanding substantial labor and time cost. With the emergence of large language\nmodels (LLMs), researchers have explored LLMs' potential as alternatives for\nhuman evaluation. While these single-agent-based approaches show promise,\nexperimental results suggest that further advancements are needed to bridge the\ngap between their current effectiveness and human-level evaluation quality.\nRecognizing that best practices of human evaluation processes often involve\nmultiple human annotators collaborating in the evaluation, we resort to a\nmulti-agent debate framework, moving beyond single-agent prompting strategies.\nThe multi-agent-based approach enables a group of LLMs to synergize with an\narray of intelligent counterparts, harnessing their distinct capabilities and\nexpertise to enhance efficiency and effectiveness in handling intricate tasks.\nIn this paper, we construct a multi-agent referee team called ChatEval to\nautonomously discuss and evaluate the quality of generated responses from\ndifferent models on open-ended questions and traditional natural language\ngeneration (NLG) tasks. Our analysis shows that ChatEval transcends mere\ntextual scoring, offering a human-mimicking evaluation process for reliable\nassessments. Our code is available at https://github.com/chanchimin/ChatEval.",
        "translated": ""
    },
    {
        "title": "Incorporating Annotator Uncertainty into Representations of Discourse\n  Relations",
        "url": "http://arxiv.org/abs/2308.07179v1",
        "pub_date": "2023-08-14",
        "summary": "Annotation of discourse relations is a known difficult task, especially for\nnon-expert annotators. In this paper, we investigate novice annotators'\nuncertainty on the annotation of discourse relations on spoken conversational\ndata. We find that dialogue context (single turn, pair of turns within speaker,\nand pair of turns across speakers) is a significant predictor of confidence\nscores. We compute distributed representations of discourse relations from\nco-occurrence statistics that incorporate information about confidence scores\nand dialogue context. We perform a hierarchical clustering analysis using these\nrepresentations and show that weighting discourse relation representations with\ninformation about confidence and dialogue context coherently models our\nannotators' uncertainty about discourse relation labels.",
        "translated": ""
    },
    {
        "title": "OctoPack: Instruction Tuning Code Large Language Models",
        "url": "http://arxiv.org/abs/2308.07124v1",
        "pub_date": "2023-08-14",
        "summary": "Finetuning large language models (LLMs) on instructions leads to vast\nperformance improvements on natural language tasks. We apply instruction tuning\nusing code, leveraging the natural structure of Git commits, which pair code\nchanges with human instructions. We compile CommitPack: 4 terabytes of Git\ncommits across 350 programming languages. We benchmark CommitPack against other\nnatural and synthetic code instructions (xP3x, Self-Instruct, OASST) on the 16B\nparameter StarCoder model, and achieve state-of-the-art performance among\nmodels not trained on OpenAI outputs, on the HumanEval Python benchmark (46.2%\npass@1). We further introduce HumanEvalPack, expanding the HumanEval benchmark\nto a total of 3 coding tasks (Code Repair, Code Explanation, Code Synthesis)\nacross 6 languages (Python, JavaScript, Java, Go, C++, Rust). Our models,\nOctoCoder and OctoGeeX, achieve the best performance across HumanEvalPack among\nall permissive models, demonstrating CommitPack's benefits in generalizing to a\nwider set of languages and natural coding tasks. Code, models and data are\nfreely available at https://github.com/bigcode-project/octopack.",
        "translated": ""
    },
    {
        "title": "Investigation Toward The Economic Feasibility of Personalized Medicine\n  For Healthcare Service Providers: The Case of Bladder Cancer",
        "url": "http://arxiv.org/abs/2308.07924v1",
        "pub_date": "2023-08-15",
        "summary": "In today's complex healthcare landscape, the pursuit of delivering optimal\npatient care while navigating intricate economic dynamics poses a significant\nchallenge for healthcare service providers (HSPs). In this already complex\ndynamics, the emergence of clinically promising personalized medicine based\ntreatment aims to revolutionize medicine. While personalized medicine holds\ntremendous potential for enhancing therapeutic outcomes, its integration within\nresource-constrained HSPs presents formidable challenges. In this study, we\ninvestigate the economic feasibility of implementing personalized medicine. The\ncentral objective is to strike a balance between catering to individual patient\nneeds and making economically viable decisions. Unlike conventional binary\napproaches to personalized treatment, we propose a more nuanced perspective by\ntreating personalization as a spectrum. This approach allows for greater\nflexibility in decision-making and resource allocation. To this end, we propose\na mathematical framework to investigate our proposal, focusing on Bladder\nCancer (BC) as a case study. Our results show that while it is feasible to\nintroduce personalized medicine, a highly efficient but highly expensive one\nwould be short-lived relative to its less effective but cheaper alternative as\nthe latter can be provided to a larger cohort of patients, optimizing the HSP's\nobjective better.",
        "translated": ""
    },
    {
        "title": "Synthesizing Political Zero-Shot Relation Classification via Codebook\n  Knowledge, NLI, and ChatGPT",
        "url": "http://arxiv.org/abs/2308.07876v1",
        "pub_date": "2023-08-15",
        "summary": "Recent supervised models for event coding vastly outperform pattern-matching\nmethods. However, their reliance solely on new annotations disregards the vast\nknowledge within expert databases, hindering their applicability to\nfine-grained classification. To address these limitations, we explore zero-shot\napproaches for political event ontology relation classification, by leveraging\nknowledge from established annotation codebooks. Our study encompasses both\nChatGPT and a novel natural language inference (NLI) based approach named ZSP.\nZSP adopts a tree-query framework that deconstructs the task into context,\nmodality, and class disambiguation levels. This framework improves\ninterpretability, efficiency, and adaptability to schema changes. By conducting\nextensive experiments on our newly curated datasets, we pinpoint the\ninstability issues within ChatGPT and highlight the superior performance of\nZSP. ZSP achieves an impressive 40% improvement in F1 score for fine-grained\nRootcode classification. ZSP demonstrates competitive performance compared to\nsupervised BERT models, positioning it as a valuable tool for event record\nvalidation and ontology development. Our work underscores the potential of\nleveraging transfer learning and existing expertise to enhance the efficiency\nand scalability of research in the field.",
        "translated": ""
    },
    {
        "title": "Impression-Aware Recommender Systems",
        "url": "http://arxiv.org/abs/2308.07857v1",
        "pub_date": "2023-08-15",
        "summary": "Novel data sources bring new opportunities to improve the quality of\nrecommender systems. Impressions are a novel data source containing past\nrecommendations (shown items) and traditional interactions. Researchers may use\nimpressions to refine user preferences and overcome the current limitations in\nrecommender systems research. The relevance and interest of impressions have\nincreased over the years; hence, the need for a review of relevant work on this\ntype of recommenders. We present a systematic literature review on recommender\nsystems using impressions, focusing on three fundamental angles in research:\nrecommenders, datasets, and evaluation methodologies. We provide three\ncategorizations of papers describing recommenders using impressions, present\neach reviewed paper in detail, describe datasets with impressions, and analyze\nthe existing evaluation methodologies. Lastly, we present open questions and\nfuture directions of interest, highlighting aspects missing in the literature\nthat can be addressed in future works.",
        "translated": ""
    },
    {
        "title": "Dynamic Embedding Size Search with Minimum Regret for Streaming\n  Recommender System",
        "url": "http://arxiv.org/abs/2308.07760v1",
        "pub_date": "2023-08-15",
        "summary": "With the continuous increase of users and items, conventional recommender\nsystems trained on static datasets can hardly adapt to changing environments.\nThe high-throughput data requires the model to be updated in a timely manner\nfor capturing the user interest dynamics, which leads to the emergence of\nstreaming recommender systems. Due to the prevalence of deep learning-based\nrecommender systems, the embedding layer is widely adopted to represent the\ncharacteristics of users, items, and other features in low-dimensional vectors.\nHowever, it has been proved that setting an identical and static embedding size\nis sub-optimal in terms of recommendation performance and memory cost,\nespecially for streaming recommendations. To tackle this problem, we first\nrethink the streaming model update process and model the dynamic embedding size\nsearch as a bandit problem. Then, we analyze and quantify the factors that\ninfluence the optimal embedding sizes from the statistics perspective. Based on\nthis, we propose the \\textbf{D}ynamic \\textbf{E}mbedding \\textbf{S}ize\n\\textbf{S}earch (\\textbf{DESS}) method to minimize the embedding size selection\nregret on both user and item sides in a non-stationary manner. Theoretically,\nwe obtain a sublinear regret upper bound superior to previous methods.\nEmpirical results across two recommendation tasks on four public datasets also\ndemonstrate that our approach can achieve better streaming recommendation\nperformance with lower memory cost and higher time efficiency.",
        "translated": ""
    },
    {
        "title": "Self-Supervised Dynamic Hypergraph Recommendation based on\n  Hyper-Relational Knowledge Graph",
        "url": "http://arxiv.org/abs/2308.07752v1",
        "pub_date": "2023-08-15",
        "summary": "Knowledge graphs (KGs) are commonly used as side information to enhance\ncollaborative signals and improve recommendation quality. In the context of\nknowledge-aware recommendation (KGR), graph neural networks (GNNs) have emerged\nas promising solutions for modeling factual and semantic information in KGs.\nHowever, the long-tail distribution of entities leads to sparsity in\nsupervision signals, which weakens the quality of item representation when\nutilizing KG enhancement. Additionally, the binary relation representation of\nKGs simplifies hyper-relational facts, making it challenging to model complex\nreal-world information. Furthermore, the over-smoothing phenomenon results in\nindistinguishable representations and information loss. To address these\nchallenges, we propose the SDK (Self-Supervised Dynamic Hypergraph\nRecommendation based on Hyper-Relational Knowledge Graph) framework. This\nframework establishes a cross-view hypergraph self-supervised learning\nmechanism for KG enhancement. Specifically, we model hyper-relational facts in\nKGs to capture interdependencies between entities under complete semantic\nconditions. With the refined representation, a hypergraph is dynamically\nconstructed to preserve features in the deep vector space, thereby alleviating\nthe over-smoothing problem. Furthermore, we mine external supervision signals\nfrom both the global perspective of the hypergraph and the local perspective of\ncollaborative filtering (CF) to guide the model prediction process. Extensive\nexperiments conducted on different datasets demonstrate the superiority of the\nSDK framework over state-of-the-art models. The results showcase its ability to\nalleviate the effects of over-smoothing and supervision signal sparsity.",
        "translated": ""
    },
    {
        "title": "RAVEN: In-Context Learning with Retrieval Augmented Encoder-Decoder\n  Language Models",
        "url": "http://arxiv.org/abs/2308.07922v1",
        "pub_date": "2023-08-15",
        "summary": "In this paper, we investigate the in-context learning ability of\nretrieval-augmented encoder-decoder language models. We first conduct a\ncomprehensive analysis of the state-of-the-art ATLAS model and identify its\nlimitations in in-context learning, primarily due to a mismatch between\npretraining and testing, as well as a restricted context length. To address\nthese issues, we propose RAVEN, a model that combines retrieval-augmented\nmasked language modeling and prefix language modeling. We further introduce\nFusion-in-Context Learning to enhance the few-shot performance by enabling the\nmodel to leverage more in-context examples without requiring additional\ntraining or model modifications. Through extensive experiments, we demonstrate\nthat RAVEN significantly outperforms ATLAS and achieves results comparable to\nthe most advanced language models in certain scenarios, despite having\nsubstantially fewer parameters. Our work underscores the potential of\nretrieval-augmented encoder-decoder language models for in-context learning and\nencourages further research in this direction.",
        "translated": ""
    },
    {
        "title": "Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with\n  Code-based Self-Verification",
        "url": "http://arxiv.org/abs/2308.07921v1",
        "pub_date": "2023-08-15",
        "summary": "Recent progress in large language models (LLMs) like GPT-4 and PaLM-2 has\nbrought significant advancements in addressing math reasoning problems. In\nparticular, OpenAI's latest version of GPT-4, known as GPT-4 Code Interpreter,\nshows remarkable performance on challenging math datasets. In this paper, we\nexplore the effect of code on enhancing LLMs' reasoning capability by\nintroducing different constraints on the \\textit{Code Usage Frequency} of GPT-4\nCode Interpreter. We found that its success can be largely attributed to its\npowerful skills in generating and executing code, evaluating the output of code\nexecution, and rectifying its solution when receiving unreasonable outputs.\nBased on this insight, we propose a novel and effective prompting method,\nexplicit \\uline{c}ode-based \\uline{s}elf-\\uline{v}erification~(CSV), to further\nboost the mathematical reasoning potential of GPT-4 Code Interpreter. This\nmethod employs a zero-shot prompt on GPT-4 Code Interpreter to encourage it to\nuse code to self-verify its answers. In instances where the verification state\nregisters as ``False'', the model shall automatically amend its solution,\nanalogous to our approach of rectifying errors during a mathematics\nexamination. Furthermore, we recognize that the states of the verification\nresult indicate the confidence of a solution, which can improve the\neffectiveness of majority voting. With GPT-4 Code Interpreter and CSV, we\nachieve an impressive zero-shot accuracy on MATH dataset \\textbf{(53.9\\% $\\to$\n84.3\\%)}.",
        "translated": ""
    },
    {
        "title": "Through the Lens of Core Competency: Survey on Evaluation of Large\n  Language Models",
        "url": "http://arxiv.org/abs/2308.07902v1",
        "pub_date": "2023-08-15",
        "summary": "From pre-trained language model (PLM) to large language model (LLM), the\nfield of natural language processing (NLP) has witnessed steep performance\ngains and wide practical uses. The evaluation of a research field guides its\ndirection of improvement. However, LLMs are extremely hard to thoroughly\nevaluate for two reasons. First of all, traditional NLP tasks become inadequate\ndue to the excellent performance of LLM. Secondly, existing evaluation tasks\nare difficult to keep up with the wide range of applications in real-world\nscenarios. To tackle these problems, existing works proposed various benchmarks\nto better evaluate LLMs. To clarify the numerous evaluation tasks in both\nacademia and industry, we investigate multiple papers concerning LLM\nevaluations. We summarize 4 core competencies of LLM, including reasoning,\nknowledge, reliability, and safety. For every competency, we introduce its\ndefinition, corresponding benchmarks, and metrics. Under this competency\narchitecture, similar tasks are combined to reflect corresponding ability,\nwhile new tasks can also be easily added into the system. Finally, we give our\nsuggestions on the future direction of LLM's evaluation.",
        "translated": ""
    },
    {
        "title": "The Regular Expression Inference Challenge",
        "url": "http://arxiv.org/abs/2308.07899v1",
        "pub_date": "2023-08-15",
        "summary": "We propose \\emph{regular expression inference (REI)} as a challenge for\ncode/language modelling, and the wider machine learning community. REI is a\nsupervised machine learning (ML) and program synthesis task, and poses the\nproblem of finding minimal regular expressions from examples: Given two finite\nsets of strings $P$ and $N$ and a cost function $\\text{cost}(\\cdot)$, the task\nis to generate an expression $r$ that accepts all strings in $P$ and rejects\nall strings in $N$, while no other such expression $r'$ exists with\n$\\text{cost}(r')&lt;\\text{cost}(r)$.\n  REI has advantages as a challenge problem: (i) regular expressions are\nwell-known, widely used, and a natural idealisation of code; (ii) REI's\nasymptotic worst-case complexity is well understood; (iii) REI has a small\nnumber of easy to understand parameters (e.g.~$P$ or $N$ cardinality, string\nlengths of examples, or the cost function); this lets us easily finetune\nREI-hardness; (iv) REI is an unsolved problem for deep learning based ML.\n  Recently, an REI solver was implemented on GPUs, using program synthesis\ntechniques. This enabled, for the first time, fast generation of minimal\nexpressions for complex REI instances. Building on this advance, we generate\nand publish the first large-scale datasets for REI, and devise and evaluate\nseveral initial heuristic and machine learning baselines.\n  We invite the community to participate and explore ML methods that learn to\nsolve REI problems. We believe that progress in REI directly translates to\ncode/language modelling.",
        "translated": ""
    },
    {
        "title": "Link-Context Learning for Multimodal LLMs",
        "url": "http://arxiv.org/abs/2308.07891v1",
        "pub_date": "2023-08-15",
        "summary": "The ability to learn from context with novel concepts, and deliver\nappropriate responses are essential in human conversations. Despite current\nMultimodal Large Language Models (MLLMs) and Large Language Models (LLMs) being\ntrained on mega-scale datasets, recognizing unseen images or understanding\nnovel concepts in a training-free manner remains a challenge. In-Context\nLearning (ICL) explores training-free few-shot learning, where models are\nencouraged to ``learn to learn\" from limited tasks and generalize to unseen\ntasks. In this work, we propose link-context learning (LCL), which emphasizes\n\"reasoning from cause and effect\" to augment the learning capabilities of\nMLLMs. LCL goes beyond traditional ICL by explicitly strengthening the causal\nrelationship between the support set and the query set. By providing\ndemonstrations with causal links, LCL guides the model to discern not only the\nanalogy but also the underlying causal associations between data points, which\nempowers MLLMs to recognize unseen images and understand novel concepts more\neffectively. To facilitate the evaluation of this novel approach, we introduce\nthe ISEKAI dataset, comprising exclusively of unseen generated image-label\npairs designed for link-context learning. Extensive experiments show that our\nLCL-MLLM exhibits strong link-context learning capabilities to novel concepts\nover vanilla MLLMs. Code and data will be released at\nhttps://github.com/isekai-portal/Link-Context-Learning.",
        "translated": ""
    },
    {
        "title": "A Comprehensive Study on Knowledge Graph Embedding over Relational\n  Patterns Based on Rule Learning",
        "url": "http://arxiv.org/abs/2308.07889v1",
        "pub_date": "2023-08-15",
        "summary": "Knowledge Graph Embedding (KGE) has proven to be an effective approach to\nsolving the Knowledge Graph Completion (KGC) task. Relational patterns which\nrefer to relations with specific semantics exhibiting graph patterns are an\nimportant factor in the performance of KGE models. Though KGE models'\ncapabilities are analyzed over different relational patterns in theory and a\nrough connection between better relational patterns modeling and better\nperformance of KGC has been built, a comprehensive quantitative analysis on KGE\nmodels over relational patterns remains absent so it is uncertain how the\ntheoretical support of KGE to a relational pattern contributes to the\nperformance of triples associated to such a relational pattern. To address this\nchallenge, we evaluate the performance of 7 KGE models over 4 common relational\npatterns on 2 benchmarks, then conduct an analysis in theory, entity frequency,\nand part-to-whole three aspects and get some counterintuitive conclusions.\nFinally, we introduce a training-free method Score-based Patterns Adaptation\n(SPA) to enhance KGE models' performance over various relational patterns. This\napproach is simple yet effective and can be applied to KGE models without\nadditional training. Our experimental results demonstrate that our method\ngenerally enhances performance over specific relational patterns. Our source\ncode is available from GitHub at\nhttps://github.com/zjukg/Comprehensive-Study-over-Relational-Patterns.",
        "translated": ""
    },
    {
        "title": "Emotion Embeddings $\\unicode{x2014}$ Learning Stable and Homogeneous\n  Abstractions from Heterogeneous Affective Datasets",
        "url": "http://arxiv.org/abs/2308.07871v1",
        "pub_date": "2023-08-15",
        "summary": "Human emotion is expressed in many communication modalities and media formats\nand so their computational study is equally diversified into natural language\nprocessing, audio signal analysis, computer vision, etc. Similarly, the large\nvariety of representation formats used in previous research to describe\nemotions (polarity scales, basic emotion categories, dimensional approaches,\nappraisal theory, etc.) have led to an ever proliferating diversity of\ndatasets, predictive models, and software tools for emotion analysis. Because\nof these two distinct types of heterogeneity, at the expressional and\nrepresentational level, there is a dire need to unify previous work on\nincreasingly diverging data and label types. This article presents such a\nunifying computational model. We propose a training procedure that learns a\nshared latent representation for emotions, so-called emotion embeddings,\nindependent of different natural languages, communication modalities, media or\nrepresentation label formats, and even disparate model architectures.\nExperiments on a wide range of heterogeneous affective datasets indicate that\nthis approach yields the desired interoperability for the sake of reusability,\ninterpretability and flexibility, without penalizing prediction quality. Code\nand data are archived under https://doi.org/10.5281/zenodo.7405327 .",
        "translated": ""
    },
    {
        "title": "Informed Named Entity Recognition Decoding for Generative Language\n  Models",
        "url": "http://arxiv.org/abs/2308.07791v1",
        "pub_date": "2023-08-15",
        "summary": "Ever-larger language models with ever-increasing capabilities are by now\nwell-established text processing tools. Alas, information extraction tasks such\nas named entity recognition are still largely unaffected by this progress as\nthey are primarily based on the previous generation of encoder-only transformer\nmodels. Here, we propose a simple yet effective approach, Informed Named Entity\nRecognition Decoding (iNERD), which treats named entity recognition as a\ngenerative process. It leverages the language understanding capabilities of\nrecent generative models in a future-proof manner and employs an informed\ndecoding scheme incorporating the restricted nature of information extraction\ninto open-ended text generation, improving performance and eliminating any risk\nof hallucinations. We coarse-tune our model on a merged named entity corpus to\nstrengthen its performance, evaluate five generative language models on eight\nnamed entity recognition datasets, and achieve remarkable results, especially\nin an environment with an unknown entity class set, demonstrating the\nadaptability of the approach.",
        "translated": ""
    },
    {
        "title": "Enhancing Visually-Rich Document Understanding via Layout Structure\n  Modeling",
        "url": "http://arxiv.org/abs/2308.07777v1",
        "pub_date": "2023-08-15",
        "summary": "In recent years, the use of multi-modal pre-trained Transformers has led to\nsignificant advancements in visually-rich document understanding. However,\nexisting models have mainly focused on features such as text and vision while\nneglecting the importance of layout relationship between text nodes. In this\npaper, we propose GraphLayoutLM, a novel document understanding model that\nleverages the modeling of layout structure graph to inject document layout\nknowledge into the model. GraphLayoutLM utilizes a graph reordering algorithm\nto adjust the text sequence based on the graph structure. Additionally, our\nmodel uses a layout-aware multi-head self-attention layer to learn document\nlayout knowledge. The proposed model enables the understanding of the spatial\narrangement of text elements, improving document comprehension. We evaluate our\nmodel on various benchmarks, including FUNSD, XFUND and CORD, and achieve\nstate-of-the-art results among these datasets. Our experimental results\ndemonstrate that our proposed method provides a significant improvement over\nexisting approaches and showcases the importance of incorporating layout\ninformation into document understanding models. We also conduct an ablation\nstudy to investigate the contribution of each component of our model. The\nresults show that both the graph reordering algorithm and the layout-aware\nmulti-head self-attention layer play a crucial role in achieving the best\nperformance.",
        "translated": ""
    },
    {
        "title": "A Bi-Step Grounding Paradigm for Large Language Models in Recommendation\n  Systems",
        "url": "http://arxiv.org/abs/2308.08434v1",
        "pub_date": "2023-08-16",
        "summary": "As the focus on Large Language Models (LLMs) in the field of recommendation\nintensifies, the optimization of LLMs for recommendation purposes (referred to\nas LLM4Rec) assumes a crucial role in augmenting their effectiveness in\nproviding recommendations. However, existing approaches for LLM4Rec often\nassess performance using restricted sets of candidates, which may not\naccurately reflect the models' overall ranking capabilities. In this paper, our\nobjective is to investigate the comprehensive ranking capacity of LLMs and\npropose a two-step grounding framework known as BIGRec (Bi-step Grounding\nParadigm for Recommendation). It initially grounds LLMs to the recommendation\nspace by fine-tuning them to generate meaningful tokens for items and\nsubsequently identifies appropriate actual items that correspond to the\ngenerated tokens. By conducting extensive experiments on two datasets, we\nsubstantiate the superior performance, capacity for handling few-shot\nscenarios, and versatility across multiple domains exhibited by BIGRec.\nFurthermore, we observe that the marginal benefits derived from increasing the\nquantity of training samples are modest for BIGRec, implying that LLMs possess\nthe limited capability to assimilate statistical information, such as\npopularity and collaborative filtering, due to their robust semantic priors.\nThese findings also underline the efficacy of integrating diverse statistical\ninformation into the LLM4Rec framework, thereby pointing towards a potential\navenue for future research. Our code and data are available at\nhttps://github.com/SAI990323/Grounding4Rec.",
        "translated": ""
    },
    {
        "title": "Knowledge-Enhanced Multi-Label Few-Shot Product Attribute-Value\n  Extraction",
        "url": "http://arxiv.org/abs/2308.08413v1",
        "pub_date": "2023-08-16",
        "summary": "Existing attribute-value extraction (AVE) models require large quantities of\nlabeled data for training. However, new products with new attribute-value pairs\nenter the market every day in real-world e-Commerce. Thus, we formulate AVE in\nmulti-label few-shot learning (FSL), aiming to extract unseen attribute value\npairs based on a small number of training examples. We propose a\nKnowledge-Enhanced Attentive Framework (KEAF) based on prototypical networks,\nleveraging the generated label description and category information to learn\nmore discriminative prototypes. Besides, KEAF integrates with hybrid attention\nto reduce noise and capture more informative semantics for each class by\ncalculating the label-relevant and query-related weights. To achieve\nmulti-label inference, KEAF further learns a dynamic threshold by integrating\nthe semantic information from both the support set and the query set. Extensive\nexperiments with ablation studies conducted on two datasets demonstrate that\nKEAF outperforms other SOTA models for information extraction in FSL. The code\ncan be found at: https://github.com/gjiaying/KEAF",
        "translated": ""
    },
    {
        "title": "Content-based Recommendation Engine for Video Streaming Platform",
        "url": "http://arxiv.org/abs/2308.08406v1",
        "pub_date": "2023-08-16",
        "summary": "Recommendation engine suggest content, product or services to the user by\nusing machine learning algorithm. This paper proposed a content-based\nrecommendation engine for providing video suggestion to the user based on their\nprevious interests and choices. We will use TF-IDF text vectorization method to\ndetermine the relevance of words in a document. Then we will find out the\nsimilarity between each content by calculating cosine similarity between them.\nFinally, engine will recommend videos to the users based on the obtained\nsimilarity score value. In addition, we will measure the engine's performance\nby computing precision, recall, and F1 core of the proposed system.",
        "translated": ""
    },
    {
        "title": "Advancing continual lifelong learning in neural information retrieval:\n  definition, dataset, framework, and empirical evaluation",
        "url": "http://arxiv.org/abs/2308.08378v1",
        "pub_date": "2023-08-16",
        "summary": "Continual learning refers to the capability of a machine learning model to\nlearn and adapt to new information, without compromising its performance on\npreviously learned tasks. Although several studies have investigated continual\nlearning methods for information retrieval tasks, a well-defined task\nformulation is still lacking, and it is unclear how typical learning strategies\nperform in this context. To address this challenge, a systematic task\nformulation of continual neural information retrieval is presented, along with\na multiple-topic dataset that simulates continuous information retrieval. A\ncomprehensive continual neural information retrieval framework consisting of\ntypical retrieval models and continual learning strategies is then proposed.\nEmpirical evaluations illustrate that the proposed framework can successfully\nprevent catastrophic forgetting in neural information retrieval and enhance\nperformance on previously learned tasks. The results indicate that\nembedding-based retrieval models experience a decline in their continual\nlearning performance as the topic shift distance and dataset volume of new\ntasks increase. In contrast, pretraining-based models do not show any such\ncorrelation. Adopting suitable learning strategies can mitigate the effects of\ntopic shift and data augmentation.",
        "translated": ""
    },
    {
        "title": "Is Meta-Learning the Right Approach for the Cold-Start Problem in\n  Recommender Systems?",
        "url": "http://arxiv.org/abs/2308.08354v1",
        "pub_date": "2023-08-16",
        "summary": "Recommender systems have become fundamental building blocks of modern online\nproducts and services, and have a substantial impact on user experience. In the\npast few years, deep learning methods have attracted a lot of research, and are\nnow heavily used in modern real-world recommender systems. Nevertheless,\ndealing with recommendations in the cold-start setting, e.g., when a user has\ndone limited interactions in the system, is a problem that remains far from\nsolved. Meta-learning techniques, and in particular optimization-based\nmeta-learning, have recently become the most popular approaches in the academic\nresearch literature for tackling the cold-start problem in deep learning models\nfor recommender systems. However, current meta-learning approaches are not\npractical for real-world recommender systems, which have billions of users and\nitems, and strict latency requirements. In this paper we show that it is\npossible to obtaining similar, or higher, performance on commonly used\nbenchmarks for the cold-start problem without using meta-learning techniques.\nIn more detail, we show that, when tuned correctly, standard and widely adopted\ndeep learning models perform just as well as newer meta-learning models. We\nfurther show that an extremely simple modular approach using common\nrepresentation learning techniques, can perform comparably to meta-learning\ntechniques specifically designed for the cold-start setting while being much\nmore easily deployable in real-world applications.",
        "translated": ""
    },
    {
        "title": "Time Travel in LLMs: Tracing Data Contamination in Large Language Models",
        "url": "http://arxiv.org/abs/2308.08493v1",
        "pub_date": "2023-08-16",
        "summary": "Data contamination, i.e., the presence of test data from downstream tasks in\nthe training data of large language models (LLMs), is a potential major issue\nin understanding LLMs' effectiveness on other tasks. We propose a\nstraightforward yet effective method for identifying data contamination within\nLLMs. At its core, our approach starts by identifying potential contamination\nin individual instances that are drawn from a small random sample; using this\ninformation, our approach then assesses if an entire dataset partition is\ncontaminated. To estimate contamination of individual instances, we employ\n\"guided instruction:\" a prompt consisting of the dataset name, partition type,\nand the initial segment of a reference instance, asking the LLM to complete it.\nAn instance is flagged as contaminated if the LLM's output either exactly or\nclosely matches the latter segment of the reference. To understand if an entire\npartition is contaminated, we propose two ideas. The first idea marks a dataset\npartition as contaminated if the average overlap score with the reference\ninstances (as measured by ROUGE or BLEURT) is statistically significantly\nbetter with the guided instruction vs. a general instruction that does not\ninclude the dataset and partition name. The second idea marks a dataset as\ncontaminated if a classifier based on GPT-4 with in-context learning prompting\nmarks multiple instances as contaminated. Our best method achieves an accuracy\nbetween 92% and 100% in detecting if an LLM is contaminated with seven\ndatasets, containing train and test/validation partitions, when contrasted with\nmanual evaluation by human expert. Further, our findings indicate that GPT-4 is\ncontaminated with AG News, WNLI, and XSum datasets.",
        "translated": ""
    },
    {
        "title": "Mitigating the Exposure Bias in Sentence-Level Grapheme-to-Phoneme (G2P)\n  Transduction",
        "url": "http://arxiv.org/abs/2308.08442v1",
        "pub_date": "2023-08-16",
        "summary": "Text-to-Text Transfer Transformer (T5) has recently been considered for the\nGrapheme-to-Phoneme (G2P) transduction. As a follow-up, a tokenizer-free\nbyte-level model based on T5 referred to as ByT5, recently gave promising\nresults on word-level G2P conversion by representing each input character with\nits corresponding UTF-8 encoding. Although it is generally understood that\nsentence-level or paragraph-level G2P can improve usability in real-world\napplications as it is better suited to perform on heteronyms and linking sounds\nbetween words, we find that using ByT5 for these scenarios is nontrivial. Since\nByT5 operates on the character level, it requires longer decoding steps, which\ndeteriorates the performance due to the exposure bias commonly observed in\nauto-regressive generation models. This paper shows that the performance of\nsentence-level and paragraph-level G2P can be improved by mitigating such\nexposure bias using our proposed loss-based sampling method.",
        "translated": ""
    },
    {
        "title": "SummHelper: Collaborative Human-Computer Summarization",
        "url": "http://arxiv.org/abs/2308.08363v1",
        "pub_date": "2023-08-16",
        "summary": "Current approaches for text summarization are predominantly automatic, with\nrather limited space for human intervention and control over the process. In\nthis paper, we introduce SummHelper, a 2-phase summarization assistant designed\nto foster human-machine collaboration. The initial phase involves content\nselection, where the system recommends potential content, allowing users to\naccept, modify, or introduce additional selections. The subsequent phase,\ncontent consolidation, involves SummHelper generating a coherent summary from\nthese selections, which users can then refine using visual mappings between the\nsummary and the source text. Small-scale user studies reveal the effectiveness\nof our application, with participants being especially appreciative of the\nbalance between automated guidance and opportunities for personal input.",
        "translated": ""
    },
    {
        "title": "Detoxify Language Model Step-by-Step",
        "url": "http://arxiv.org/abs/2308.08295v1",
        "pub_date": "2023-08-16",
        "summary": "Detoxification for LLMs is challenging since it requires models to avoid\ngenerating harmful content while maintaining the generation capability. To\nensure the safety of generations, previous detoxification methods detoxify the\nmodels by changing the data distributions or constraining the generations from\ndifferent aspects in a single-step manner. However, these approaches will\ndramatically affect the generation quality of LLMs, e.g., discourse coherence\nand semantic consistency, since language models tend to generate along the\ntoxic prompt while detoxification methods work in the opposite direction. To\nhandle such a conflict, we decompose the detoxification process into different\nsub-steps, where the detoxification is concentrated in the input stage and the\nsubsequent continual generation is based on the non-toxic prompt. Besides, we\nalso calibrate the strong reasoning ability of LLMs by designing a Detox-Chain\nto connect the above sub-steps in an orderly manner, which allows LLMs to\ndetoxify the text step-by-step. Automatic and human evaluation on two\nbenchmarks reveals that by training with Detox-Chain, six LLMs scaling from 1B\nto 33B can obtain significant detoxification and generation improvement. Our\ncode and data are available at https://github.com/CODINNLG/Detox-CoT. Warning:\nexamples in the paper may contain uncensored offensive content.",
        "translated": ""
    },
    {
        "title": "Pre-training with Large Language Model-based Document Expansion for\n  Dense Passage Retrieval",
        "url": "http://arxiv.org/abs/2308.08285v1",
        "pub_date": "2023-08-16",
        "summary": "In this paper, we systematically study the potential of pre-training with\nLarge Language Model(LLM)-based document expansion for dense passage retrieval.\nConcretely, we leverage the capabilities of LLMs for document expansion, i.e.\nquery generation, and effectively transfer expanded knowledge to retrievers\nusing pre-training strategies tailored for passage retrieval. These strategies\ninclude contrastive learning and bottlenecked query generation. Furthermore, we\nincorporate a curriculum learning strategy to reduce the reliance on LLM\ninferences. Experimental results demonstrate that pre-training with LLM-based\ndocument expansion significantly boosts the retrieval performance on\nlarge-scale web-search tasks. Our work shows strong zero-shot and out-of-domain\nretrieval abilities, making it more widely applicable for retrieval when\ninitializing with no human-labeled data.",
        "translated": ""
    },
    {
        "title": "Benchmarking Neural Network Generalization for Grammar Induction",
        "url": "http://arxiv.org/abs/2308.08253v1",
        "pub_date": "2023-08-16",
        "summary": "How well do neural networks generalize? Even for grammar induction tasks,\nwhere the target generalization is fully known, previous works have left the\nquestion open, testing very limited ranges beyond the training set and using\ndifferent success criteria. We provide a measure of neural network\ngeneralization based on fully specified formal languages. Given a model and a\nformal grammar, the method assigns a generalization score representing how well\na model generalizes to unseen samples in inverse relation to the amount of data\nit was trained on. The benchmark includes languages such as $a^nb^n$,\n$a^nb^nc^n$, $a^nb^mc^{n+m}$, and Dyck-1 and 2. We evaluate selected\narchitectures using the benchmark and find that networks trained with a Minimum\nDescription Length objective (MDL) generalize better and using less data than\nnetworks trained using standard loss functions. The benchmark is available at\nhttps://github.com/taucompling/bliss.",
        "translated": ""
    },
    {
        "title": "TEST: Text Prototype Aligned Embedding to Activate LLM's Ability for\n  Time Series",
        "url": "http://arxiv.org/abs/2308.08241v1",
        "pub_date": "2023-08-16",
        "summary": "This work summarizes two strategies for completing time-series (TS) tasks\nusing today's language model (LLM): LLM-for-TS, design and train a fundamental\nlarge model for TS data; TS-for-LLM, enable the pre-trained LLM to handle TS\ndata. Considering the insufficient data accumulation, limited resources, and\nsemantic context requirements, this work focuses on TS-for-LLM methods, where\nwe aim to activate LLM's ability for TS data by designing a TS embedding method\nsuitable for LLM. The proposed method is named TEST. It first tokenizes TS,\nbuilds an encoder to embed them by instance-wise, feature-wise, and\ntext-prototype-aligned contrast, and then creates prompts to make LLM more open\nto embeddings, and finally implements TS tasks. Experiments are carried out on\nTS classification and forecasting tasks using 8 LLMs with different structures\nand sizes. Although its results cannot significantly outperform the current\nSOTA models customized for TS tasks, by treating LLM as the pattern machine, it\ncan endow LLM's ability to process TS data without compromising the language\nability. This paper is intended to serve as a foundational work that will\ninspire further research.",
        "translated": ""
    },
    {
        "title": "MemoChat: Tuning LLMs to Use Memos for Consistent Long-Range Open-Domain\n  Conversation",
        "url": "http://arxiv.org/abs/2308.08239v1",
        "pub_date": "2023-08-16",
        "summary": "We propose MemoChat, a pipeline for refining instructions that enables large\nlanguage models (LLMs) to effectively employ self-composed memos for\nmaintaining consistent long-range open-domain conversations. We demonstrate a\nlong-range open-domain conversation through iterative\n\"memorization-retrieval-response\" cycles. This requires us to carefully design\ntailored tuning instructions for each distinct stage. The instructions are\nreconstructed from a collection of public datasets to teach the LLMs to\nmemorize and retrieve past dialogues with structured memos, leading to enhanced\nconsistency when participating in future conversations. We invite experts to\nmanually annotate a test set designed to evaluate the consistency of long-range\nconversations questions. Experiments on three testing scenarios involving both\nopen-source and API-accessible chatbots at scale verify the efficacy of\nMemoChat, which outperforms strong baselines.",
        "translated": ""
    },
    {
        "title": "MUSE: Music Recommender System with Shuffle Play Recommendation\n  Enhancement",
        "url": "http://arxiv.org/abs/2308.09649v1",
        "pub_date": "2023-08-18",
        "summary": "Recommender systems have become indispensable in music streaming services,\nenhancing user experiences by personalizing playlists and facilitating the\nserendipitous discovery of new music. However, the existing recommender systems\noverlook the unique challenges inherent in the music domain, specifically\nshuffle play, which provides subsequent tracks in a random sequence. Based on\nour observation that the shuffle play sessions hinder the overall training\nprocess of music recommender systems mainly due to the high unique transition\nrates of shuffle play sessions, we propose a Music Recommender System with\nShuffle Play Recommendation Enhancement (MUSE). MUSE employs the\nself-supervised learning framework that maximizes the agreement between the\noriginal session and the augmented session, which is augmented by our novel\nsession augmentation method, called transition-based augmentation. To further\nfacilitate the alignment of the representations between the two views, we\ndevise two fine-grained matching strategies, i.e., item- and similarity-based\nmatching strategies. Through rigorous experiments conducted across diverse\nenvironments, we demonstrate MUSE's efficacy over 12 baseline models on a\nlarge-scale Music Streaming Sessions Dataset (MSSD) from Spotify. The source\ncode of MUSE is available at \\url{https://github.com/yunhak0/MUSE}.",
        "translated": ""
    },
    {
        "title": "ReCon: Reducing Congestion in Job Recommendation using Optimal Transport",
        "url": "http://arxiv.org/abs/2308.09516v1",
        "pub_date": "2023-08-18",
        "summary": "Recommender systems may suffer from congestion, meaning that there is an\nunequal distribution of the items in how often they are recommended. Some items\nmay be recommended much more than others. Recommenders are increasingly used in\ndomains where items have limited availability, such as the job market, where\ncongestion is especially problematic: Recommending a vacancy -- for which\ntypically only one person will be hired -- to a large number of job seekers may\nlead to frustration for job seekers, as they may be applying for jobs where\nthey are not hired. This may also leave vacancies unfilled and result in job\nmarket inefficiency.\n  We propose a novel approach to job recommendation called ReCon, accounting\nfor the congestion problem. Our approach is to use an optimal transport\ncomponent to ensure a more equal spread of vacancies over job seekers, combined\nwith a job recommendation model in a multi-objective optimization problem. We\nevaluated our approach on two real-world job market datasets. The evaluation\nresults show that ReCon has good performance on both congestion-related (e.g.,\nCongestion) and desirability (e.g., NDCG) measures.",
        "translated": ""
    },
    {
        "title": "Attention Calibration for Transformer-based Sequential Recommendation",
        "url": "http://arxiv.org/abs/2308.09419v1",
        "pub_date": "2023-08-18",
        "summary": "Transformer-based sequential recommendation (SR) has been booming in recent\nyears, with the self-attention mechanism as its key component. Self-attention\nhas been widely believed to be able to effectively select those informative and\nrelevant items from a sequence of interacted items for next-item prediction via\nlearning larger attention weights for these items. However, this may not always\nbe true in reality. Our empirical analysis of some representative\nTransformer-based SR models reveals that it is not uncommon for large attention\nweights to be assigned to less relevant items, which can result in inaccurate\nrecommendations. Through further in-depth analysis, we find two factors that\nmay contribute to such inaccurate assignment of attention weights: sub-optimal\nposition encoding and noisy input. To this end, in this paper, we aim to\naddress this significant yet challenging gap in existing works. To be specific,\nwe propose a simple yet effective framework called Attention Calibration for\nTransformer-based Sequential Recommendation (AC-TSR). In AC-TSR, a novel\nspatial calibrator and adversarial calibrator are designed respectively to\ndirectly calibrates those incorrectly assigned attention weights. The former is\ndevised to explicitly capture the spatial relationships (i.e., order and\ndistance) among items for more precise calculation of attention weights. The\nlatter aims to redistribute the attention weights based on each item's\ncontribution to the next-item prediction. AC-TSR is readily adaptable and can\nbe seamlessly integrated into various existing transformer-based SR models.\nExtensive experimental results on four benchmark real-world datasets\ndemonstrate the superiority of our proposed ACTSR via significant\nrecommendation performance enhancements. The source code is available at\nhttps://github.com/AIM-SE/AC-TSR.",
        "translated": ""
    },
    {
        "title": "SHARK: A Lightweight Model Compression Approach for Large-scale\n  Recommender Systems",
        "url": "http://arxiv.org/abs/2308.09395v1",
        "pub_date": "2023-08-18",
        "summary": "Increasing the size of embedding layers has shown to be effective in\nimproving the performance of recommendation models, yet gradually causing their\nsizes to exceed terabytes in industrial recommender systems, and hence the\nincrease of computing and storage costs. To save resources while maintaining\nmodel performances, we propose SHARK, the model compression practice we have\nsummarized in the recommender system of industrial scenarios. SHARK consists of\ntwo main components. First, we use the novel first-order component of Taylor\nexpansion as importance scores to prune the number of embedding tables (feature\nfields). Second, we introduce a new row-wise quantization method to apply\ndifferent quantization strategies to each embedding. We conduct extensive\nexperiments on both public and industrial datasets, demonstrating that each\ncomponent of our proposed SHARK framework outperforms previous approaches. We\nconduct A/B tests in multiple models on Kuaishou, such as short video,\ne-commerce, and advertising recommendation models. The results of the online\nA/B test showed SHARK can effectively reduce the memory footprint of the\nembedded layer. For the short-video scenarios, the compressed model without any\nperformance drop significantly saves 70% storage and thousands of machines,\nimproves 30\\% queries per second (QPS), and has been deployed to serve hundreds\nof millions of users and process tens of billions of requests every day.",
        "translated": ""
    },
    {
        "title": "How Discriminative Are Your Qrels? How To Study the Statistical\n  Significance of Document Adjudication Methods",
        "url": "http://arxiv.org/abs/2308.09340v1",
        "pub_date": "2023-08-18",
        "summary": "Creating test collections for offline retrieval evaluation requires human\neffort to judge documents' relevance. This expensive activity motivated much\nwork in developing methods for constructing benchmarks with fewer assessment\ncosts. In this respect, adjudication methods actively decide both which\ndocuments and the order in which experts review them, in order to better\nexploit the assessment budget or to lower it. Researchers evaluate the quality\nof those methods by measuring the correlation between the known gold ranking of\nsystems under the full collection and the observed ranking of systems under the\nlower-cost one. This traditional analysis ignores whether and how the low-cost\njudgements impact on the statistically significant differences among systems\nwith respect to the full collection. We fill this void by proposing a novel\nmethodology to evaluate how the low-cost adjudication methods preserve the\npairwise significant differences between systems as the full collection. In\nother terms, while traditional approaches look for stability in answering the\nquestion \"is system A better than system B?\", our proposed approach looks for\nstability in answering the question \"is system A significantly better than\nsystem B?\", which is the ultimate questions researchers need to answer to\nguarantee the generalisability of their results. Among other results, we found\nthat the best methods in terms of ranking of systems correlation do not always\nmatch those preserving statistical significance.",
        "translated": ""
    },
    {
        "title": "Graph of Thoughts: Solving Elaborate Problems with Large Language Models",
        "url": "http://arxiv.org/abs/2308.09687v1",
        "pub_date": "2023-08-18",
        "summary": "We introduce Graph of Thoughts (GoT): a framework that advances prompting\ncapabilities in large language models (LLMs) beyond those offered by paradigms\nsuch as Chain-ofThought or Tree of Thoughts (ToT). The key idea and primary\nadvantage of GoT is the ability to model the information generated by an LLM as\nan arbitrary graph, where units of information (\"LLM thoughts\") are vertices,\nand edges correspond to dependencies between these vertices. This approach\nenables combining arbitrary LLM thoughts into synergistic outcomes, distilling\nthe essence of whole networks of thoughts, or enhancing thoughts using feedback\nloops. We illustrate that GoT offers advantages over state of the art on\ndifferent tasks, for example increasing the quality of sorting by 62% over ToT,\nwhile simultaneously reducing costs by &gt;31%. We ensure that GoT is extensible\nwith new thought transformations and thus can be used to spearhead new\nprompting schemes. This work brings the LLM reasoning closer to human thinking\nor brain mechanisms such as recurrence, both of which form complex networks.",
        "translated": ""
    },
    {
        "title": "OCR Language Models with Custom Vocabularies",
        "url": "http://arxiv.org/abs/2308.09671v1",
        "pub_date": "2023-08-18",
        "summary": "Language models are useful adjuncts to optical models for producing accurate\noptical character recognition (OCR) results. One factor which limits the power\nof language models in this context is the existence of many specialized domains\nwith language statistics very different from those implied by a general\nlanguage model - think of checks, medical prescriptions, and many other\nspecialized document classes. This paper introduces an algorithm for\nefficiently generating and attaching a domain specific word based language\nmodel at run time to a general language model in an OCR system. In order to\nbest use this model the paper also introduces a modified CTC beam search\ndecoder which effectively allows hypotheses to remain in contention based on\npossible future completion of vocabulary words. The result is a substantial\nreduction in word error rate in recognizing material from specialized domains.",
        "translated": ""
    },
    {
        "title": "Red-Teaming Large Language Models using Chain of Utterances for\n  Safety-Alignment",
        "url": "http://arxiv.org/abs/2308.09662v1",
        "pub_date": "2023-08-18",
        "summary": "Larger language models (LLMs) have taken the world by storm with their\nmassive multi-tasking capabilities simply by optimizing over a next-word\nprediction objective. With the emergence of their properties and encoded\nknowledge, the risk of LLMs producing harmful outputs increases, making them\nunfit for scalable deployment for the public. In this work, we propose a new\nsafety evaluation benchmark RED-EVAL that carries out red-teaming. We show that\neven widely deployed models are susceptible to the Chain of Utterances-based\n(CoU) prompting, jailbreaking closed source LLM-based systems such as GPT-4 and\nChatGPT to unethically respond to more than 65% and 73% of harmful queries. We\nalso demonstrate the consistency of the RED-EVAL across 8 open-source LLMs in\ngenerating harmful responses in more than 86% of the red-teaming attempts.\nNext, we propose RED-INSTRUCT--An approach for the safety alignment of LLMs. It\nconstitutes two phases: 1) HARMFULQA data collection: Leveraging CoU prompting,\nwe collect a dataset that consists of 1.9K harmful questions covering a wide\nrange of topics, 9.5K safe and 7.3K harmful conversations from ChatGPT; 2)\nSAFE-ALIGN: We demonstrate how the conversational dataset can be used for the\nsafety alignment of LLMs by minimizing the negative log-likelihood over helpful\nresponses and penalizing over harmful responses by gradient accent over sample\nloss. Our model STARLING, a fine-tuned Vicuna-7B, is observed to be more safely\naligned when evaluated on RED-EVAL and HHH benchmarks while preserving the\nutility of the baseline models (TruthfulQA, MMLU, and BBH).",
        "translated": ""
    },
    {
        "title": "Tree-of-Mixed-Thought: Combining Fast and Slow Thinking for Multi-hop\n  Visual Reasoning",
        "url": "http://arxiv.org/abs/2308.09658v1",
        "pub_date": "2023-08-18",
        "summary": "There emerges a promising trend of using large language models (LLMs) to\ngenerate code-like plans for complex inference tasks such as visual reasoning.\nThis paradigm, known as LLM-based planning, provides flexibility in problem\nsolving and endows better interpretability. However, current research is mostly\nlimited to basic scenarios of simple questions that can be straightforward\nanswered in a few inference steps. Planning for the more challenging multi-hop\nvisual reasoning tasks remains under-explored. Specifically, under multi-hop\nreasoning situations, the trade-off between accuracy and the complexity of\nplan-searching becomes prominent. The prevailing algorithms either address the\nefficiency issue by employing the fast one-stop generation or adopt a complex\niterative generation method to improve accuracy. Both fail to balance the need\nfor efficiency and performance. Drawing inspiration from the dual system of\ncognition in the human brain, the fast and the slow think processes, we propose\na hierarchical plan-searching algorithm that integrates the one-stop reasoning\n(fast) and the Tree-of-thought (slow). Our approach succeeds in performance\nwhile significantly saving inference steps. Moreover, we repurpose the PTR and\nthe CLEVER datasets, developing a systematic framework for evaluating the\nperformance and efficiency of LLMs-based plan-search algorithms under reasoning\ntasks at different levels of difficulty. Extensive experiments demonstrate the\nsuperiority of our proposed algorithm in terms of performance and efficiency.\nThe dataset and code will be release soon.",
        "translated": ""
    },
    {
        "title": "ChatHaruhi: Reviving Anime Character in Reality via Large Language Model",
        "url": "http://arxiv.org/abs/2308.09597v1",
        "pub_date": "2023-08-18",
        "summary": "Role-playing chatbots built on large language models have drawn interest, but\nbetter techniques are needed to enable mimicking specific fictional characters.\nWe propose an algorithm that controls language models via an improved prompt\nand memories of the character extracted from scripts. We construct ChatHaruhi,\na dataset covering 32 Chinese / English TV / anime characters with over 54k\nsimulated dialogues. Both automatic and human evaluations show our approach\nimproves role-playing ability over baselines. Code and data are available at\nhttps://github.com/LC1332/Chat-Haruhi-Suzumiya .",
        "translated": ""
    },
    {
        "title": "WizardMath: Empowering Mathematical Reasoning for Large Language Models\n  via Reinforced Evol-Instruct",
        "url": "http://arxiv.org/abs/2308.09583v1",
        "pub_date": "2023-08-18",
        "summary": "Large language models (LLMs), such as GPT-4, have shown remarkable\nperformance in natural language processing (NLP) tasks, including challenging\nmathematical reasoning. However, most existing open-source models are only\npre-trained on large-scale internet data and without math-related optimization.\nIn this paper, we present WizardMath, which enhances the mathematical reasoning\nabilities of Llama-2, by applying our proposed Reinforcement Learning from\nEvol-Instruct Feedback (RLEIF) method to the domain of math. Through extensive\nexperiments on two mathematical reasoning benchmarks, namely GSM8k and MATH, we\nreveal the extraordinary capabilities of our model. WizardMath surpasses all\nother open-source LLMs by a substantial margin. Furthermore, our model even\noutperforms ChatGPT-3.5, Claude Instant-1, PaLM-2 and Minerva on GSM8k,\nsimultaneously surpasses Text-davinci-002, PaLM-1 and GPT-3 on MATH. More\ndetails and model weights are public at https://github.com/nlpxucan/WizardLM\nand https://huggingface.co/WizardLM.",
        "translated": ""
    },
    {
        "title": "PUMGPT: A Large Vision-Language Model for Product Understanding",
        "url": "http://arxiv.org/abs/2308.09568v1",
        "pub_date": "2023-08-18",
        "summary": "Recent developments of multi-modal large language models have demonstrated\nits strong ability in solving vision-language tasks. In this paper, we focus on\nthe product understanding task, which plays an essential role in enhancing\nonline shopping experience. Product understanding task includes a variety of\nsub-tasks, which require models to respond diverse queries based on multi-modal\nproduct information. Traditional methods design distinct model architectures\nfor each sub-task. On the contrary, we present PUMGPT, a large vision-language\nmodel aims at unifying all product understanding tasks under a singular model\nstructure. To bridge the gap between vision and text representations, we\npropose Layer-wise Adapters (LA), an approach that provides enhanced alignment\nwith fewer visual tokens and enables parameter-efficient fine-tuning. Moreover,\nthe inherent parameter-efficient fine-tuning ability allows PUMGPT to be\nreadily adapted to new product understanding tasks and emerging products. We\ndesign instruction templates to generate diverse product instruction datasets.\nSimultaneously, we utilize open-domain datasets during training to improve the\nperformance of PUMGPT and its generalization ability. Through extensive\nevaluations, PUMGPT demonstrates its superior performance across multiple\nproduct understanding tasks, including product captioning, category\nquestion-answering, attribute extraction, attribute question-answering, and\neven free-form question-answering about products.",
        "translated": ""
    },
    {
        "title": "Semantic relatedness in DBpedia: A comparative and experimental\n  assessment",
        "url": "http://arxiv.org/abs/2308.09502v1",
        "pub_date": "2023-08-18",
        "summary": "Evaluating semantic relatedness of Web resources is still an open challenge.\nThis paper focuses on knowledge-based methods, which represent an alternative\nto corpus-based approaches, and rely in general on the availability of\nknowledge graphs. In particular, we have selected 10 methods from the existing\nliterature, that have been organized according to it adjacent resources, triple\npatterns, and triple weights-based methods. They have been implemented and\nevaluated by using DBpedia as reference RDF knowledge graph. Since DBpedia is\ncontinuously evolving, the experimental results provided by these methods in\nthe literature are not comparable. For this reason, in this work, such methods\nhave been experimented by running them all at once on the same DBpedia release\nand against 14 well-known golden datasets. On the basis of the correlation\nvalues with human judgment obtained according to the experimental results,\nweighting the RDF triples in combination with evaluating all the directed paths\nlinking the compared resources is the best strategy in order to compute\nsemantic relatedness in DBpedia.",
        "translated": ""
    },
    {
        "title": "Predictive Authoring for Brazilian Portuguese Augmentative and\n  Alternative Communication",
        "url": "http://arxiv.org/abs/2308.09497v1",
        "pub_date": "2023-08-18",
        "summary": "Individuals with complex communication needs (CCN) often rely on augmentative\nand alternative communication (AAC) systems to have conversations and\ncommunique their wants. Such systems allow message authoring by arranging\npictograms in sequence. However, the difficulty of finding the desired item to\ncomplete a sentence can increase as the user's vocabulary increases. This paper\nproposes using BERTimbau, a Brazilian Portuguese version of BERT, for pictogram\nprediction in AAC systems. To finetune BERTimbau, we constructed an AAC corpus\nfor Brazilian Portuguese to use as a training corpus. We tested different\napproaches to representing a pictogram for prediction: as a word (using\npictogram captions), as a concept (using a dictionary definition), and as a set\nof synonyms (using related terms). We also evaluated the usage of images for\npictogram prediction. The results demonstrate that using embeddings computed\nfrom the pictograms' caption, synonyms, or definitions have a similar\nperformance. Using synonyms leads to lower perplexity, but using captions leads\nto the highest accuracies. This paper provides insight into how to represent a\npictogram for prediction using a BERT-like model and the potential of using\nimages for pictogram prediction.",
        "translated": ""
    },
    {
        "title": "Artificial-Spiking Hierarchical Networks for Vision-Language\n  Representation Learning",
        "url": "http://arxiv.org/abs/2308.09455v1",
        "pub_date": "2023-08-18",
        "summary": "With the success of self-supervised learning, multimodal foundation models\nhave rapidly adapted a wide range of downstream tasks driven by vision and\nlanguage (VL) pretraining. State-of-the-art methods achieve impressive\nperformance by pre-training on large-scale datasets. However, bridging the\nsemantic gap between the two modalities remains a nonnegligible challenge for\nVL tasks. In this work, we propose an efficient computation framework for\nmultimodal alignment by introducing a novel visual semantic module to further\nimprove the performance of the VL tasks. Specifically, we propose a flexible\nmodel, namely Artificial-Spiking Hierarchical Networks (ASH-Nets), which\ncombines the complementary advantages of Artificial neural networks (ANNs) and\nSpiking neural networks (SNNs) to enrich visual semantic representations. In\nparticular, a visual concrete encoder and a semantic abstract encoder are\nconstructed to learn continuous and discrete latent variables to enhance the\nflexibility of semantic encoding. Considering the spatio-temporal properties of\nSNNs modeling, we introduce a contrastive learning method to optimize the\ninputs of similar samples. This can improve the computational efficiency of the\nhierarchical network, while the augmentation of hard samples is beneficial to\nthe learning of visual representations. Furthermore, the Spiking to Text\nUni-Alignment Learning (STUA) pre-training method is proposed, which only\nrelies on text features to enhance the encoding ability of abstract semantics.\nWe validate the performance on multiple well-established downstream VL tasks.\nExperiments show that the proposed ASH-Nets achieve competitive results.",
        "translated": ""
    },
    {
        "title": "Leveraging Large Language Models for Pre-trained Recommender Systems",
        "url": "http://arxiv.org/abs/2308.10837v1",
        "pub_date": "2023-08-21",
        "summary": "Recent advancements in recommendation systems have shifted towards more\ncomprehensive and personalized recommendations by utilizing large language\nmodels (LLM). However, effectively integrating LLM's commonsense knowledge and\nreasoning abilities into recommendation systems remains a challenging problem.\nIn this paper, we propose RecSysLLM, a novel pre-trained recommendation model\nbased on LLMs. RecSysLLM retains LLM reasoning and knowledge while integrating\nrecommendation domain knowledge through unique designs of data, training, and\ninference. This allows RecSysLLM to leverage LLMs' capabilities for\nrecommendation tasks in an efficient, unified framework. We demonstrate the\neffectiveness of RecSysLLM on benchmarks and real-world scenarios. RecSysLLM\nprovides a promising approach to developing unified recommendation systems by\nfully exploiting the power of pre-trained language models.",
        "translated": ""
    },
    {
        "title": "Enhancing Recommender Systems with Large Language Model Reasoning Graphs",
        "url": "http://arxiv.org/abs/2308.10835v1",
        "pub_date": "2023-08-21",
        "summary": "Recommendation systems aim to provide users with relevant suggestions, but\noften lack interpretability and fail to capture higher-level semantic\nrelationships between user behaviors and profiles. In this paper, we propose a\nnovel approach that leverages large language models (LLMs) to construct\npersonalized reasoning graphs. These graphs link a user's profile and\nbehavioral sequences through causal and logical inferences, representing the\nuser's interests in an interpretable way. Our approach, LLM reasoning graphs\n(LLMRG), has four components: chained graph reasoning, divergent extension,\nself-verification and scoring, and knowledge base self-improvement. The\nresulting reasoning graph is encoded using graph neural networks, which serves\nas additional input to improve conventional recommender systems, without\nrequiring extra user or item information. Our approach demonstrates how LLMs\ncan enable more logical and interpretable recommender systems through\npersonalized reasoning graphs. LLMRG allows recommendations to benefit from\nboth engineered recommendation systems and LLM-derived reasoning graphs. We\ndemonstrate the effectiveness of LLMRG on benchmarks and real-world scenarios\nin enhancing base recommendation models.",
        "translated": ""
    },
    {
        "title": "DynED: Dynamic Ensemble Diversification in Data Stream Classification",
        "url": "http://arxiv.org/abs/2308.10807v1",
        "pub_date": "2023-08-21",
        "summary": "Ensemble methods are commonly used in classification due to their remarkable\nperformance. Achieving high accuracy in a data stream environment is a\nchallenging task considering disruptive changes in the data distribution, also\nknown as concept drift. A greater diversity of ensemble components is known to\nenhance prediction accuracy in such settings. Despite the diversity of\ncomponents within an ensemble, not all contribute as expected to its overall\nperformance. This necessitates a method for selecting components that exhibit\nhigh performance and diversity. We present a novel ensemble construction and\nmaintenance approach based on MMR (Maximal Marginal Relevance) that dynamically\ncombines the diversity and prediction accuracy of components during the process\nof structuring an ensemble. The experimental results on both four real and 11\nsynthetic datasets demonstrate that the proposed approach (DynED) provides a\nhigher average mean accuracy compared to the five state-of-the-art baselines.",
        "translated": ""
    },
    {
        "title": "LSCPM: communities in massive real-world Link Streams by Clique\n  Percolation Method",
        "url": "http://arxiv.org/abs/2308.10801v1",
        "pub_date": "2023-08-21",
        "summary": "Community detection is a popular approach to understand the organization of\ninteractions in static networks. For that purpose, the Clique Percolation\nMethod (CPM), which involves the percolation of k-cliques, is a well-studied\ntechnique that offers several advantages. Besides, studying interactions that\noccur over time is useful in various contexts, which can be modeled by the link\nstream formalism. The Dynamic Clique Percolation Method (DCPM) has been\nproposed for extending CPM to temporal networks.\n  However, existing implementations are unable to handle massive datasets. We\npresent a novel algorithm that adapts CPM to link streams, which has the\nadvantage that it allows us to speed up the computation time with respect to\nthe existing DCPM method. We evaluate it experimentally on real datasets and\nshow that it scales to massive link streams. For example, it allows to obtain a\ncomplete set of communities in under twenty-five minutes for a dataset with\nthirty million links, what the state of the art fails to achieve even after a\nweek of computation. We further show that our method provides communities\nsimilar to DCPM, but slightly more aggregated. We exhibit the relevance of the\nobtained communities in real world cases, and show that they provide\ninformation on the importance of vertices in the link streams.",
        "translated": ""
    },
    {
        "title": "A Topology-aware Analysis of Graph Collaborative Filtering",
        "url": "http://arxiv.org/abs/2308.10778v1",
        "pub_date": "2023-08-21",
        "summary": "The successful integration of graph neural networks into recommender systems\n(RSs) has led to a novel paradigm in collaborative filtering (CF), graph\ncollaborative filtering (graph CF). By representing user-item data as an\nundirected, bipartite graph, graph CF utilizes short- and long-range\nconnections to extract collaborative signals that yield more accurate user\npreferences than traditional CF methods. Although the recent literature\nhighlights the efficacy of various algorithmic strategies in graph CF, the\nimpact of datasets and their topological features on recommendation performance\nis yet to be studied. To fill this gap, we propose a topology-aware analysis of\ngraph CF. In this study, we (i) take some widely-adopted recommendation\ndatasets and use them to generate a large set of synthetic sub-datasets through\ntwo state-of-the-art graph sampling methods, (ii) measure eleven of their\nclassical and topological characteristics, and (iii) estimate the accuracy\ncalculated on the generated sub-datasets considering four popular and recent\ngraph-based RSs (i.e., LightGCN, DGCF, UltraGCN, and SVD-GCN). Finally, the\ninvestigation presents an explanatory framework that reveals the linear\nrelationships between characteristics and accuracy measures. The results,\nstatistically validated under different graph sampling settings, confirm the\nexistence of solid dependencies between topological characteristics and\naccuracy in the graph-based recommendation, offering a new perspective on how\nto interpret graph CF.",
        "translated": ""
    },
    {
        "title": "Giraffe: Adventures in Expanding Context Lengths in LLMs",
        "url": "http://arxiv.org/abs/2308.10882v1",
        "pub_date": "2023-08-21",
        "summary": "Modern large language models (LLMs) that rely on attention mechanisms are\ntypically trained with fixed context lengths which enforce upper limits on the\nlength of input sequences that they can handle at evaluation time. To use these\nmodels on sequences longer than the train-time context length, one might employ\ntechniques from the growing family of context length extrapolation methods --\nmost of which focus on modifying the system of positional encodings used in the\nattention mechanism to indicate where tokens or activations are located in the\ninput sequence. We conduct a wide survey of existing methods of context length\nextrapolation on a base LLaMA or LLaMA 2 model, and introduce some of our own\ndesign as well -- in particular, a new truncation strategy for modifying the\nbasis for the position encoding.\n  We test these methods using three new evaluation tasks (FreeFormQA,\nAlteredNumericQA, and LongChat-Lines) as well as perplexity, which we find to\nbe less fine-grained as a measure of long context performance of LLMs. We\nrelease the three tasks publicly as datasets on HuggingFace. We discover that\nlinear scaling is the best method for extending context length, and show that\nfurther gains can be achieved by using longer scales at evaluation time. We\nalso discover promising extrapolation capabilities in the truncated basis. To\nsupport further research in this area, we release three new 13B parameter\nlong-context models which we call Giraffe: 4k and 16k context models trained\nfrom base LLaMA-13B, and a 32k context model trained from base LLaMA2-13B. We\nalso release the code to replicate our results.",
        "translated": ""
    },
    {
        "title": "Analyzing Transformer Dynamics as Movement through Embedding Space",
        "url": "http://arxiv.org/abs/2308.10874v1",
        "pub_date": "2023-08-21",
        "summary": "Transformer language models exhibit intelligent behaviors such as\nunderstanding natural language, recognizing patterns, acquiring knowledge,\nreasoning, planning, reflecting and using tools. This paper explores how their\nunderlying mechanics give rise to intelligent behaviors. We adopt a systems\napproach to analyze Transformers in detail and develop a mathematical framework\nthat frames their dynamics as movement through embedding space. This novel\nperspective provides a principled way of thinking about the problem and reveals\nimportant insights related to the emergence of intelligence:\n  1. At its core the Transformer is a Embedding Space walker, mapping\nintelligent behavior to trajectories in this vector space.\n  2. At each step of the walk, it composes context into a single composite\nvector whose location in Embedding Space defines the next step.\n  3. No learning actually occurs during decoding; in-context learning and\ngeneralization are simply the result of different contexts composing into\ndifferent vectors.\n  4. Ultimately the knowledge, intelligence and skills exhibited by the model\nare embodied in the organization of vectors in Embedding Space rather than in\nspecific neurons or layers. These abilities are properties of this\norganization.\n  5. Attention's contribution boils down to the association-bias it lends to\nvector composition and which influences the aforementioned organization.\nHowever, more investigation is needed to ascertain its significance.\n  6. The entire model is composed from two principal operations: data\nindependent filtering and data dependent aggregation. This generalization\nunifies Transformers with other sequence models and across modalities.\n  Building upon this foundation we formalize and test a semantic space theory\nwhich posits that embedding vectors represent semantic concepts and find some\nevidence of its validity.",
        "translated": ""
    },
    {
        "title": "LatEval: An Interactive LLMs Evaluation Benchmark with Incomplete\n  Information from Lateral Thinking Puzzles",
        "url": "http://arxiv.org/abs/2308.10855v1",
        "pub_date": "2023-08-21",
        "summary": "With the continuous evolution and refinement of LLMs, they are endowed with\nimpressive logical reasoning or vertical thinking capabilities. But can they\nthink out of the box? Do they possess proficient lateral thinking abilities?\nFollowing the setup of Lateral Thinking Puzzles, we propose a novel evaluation\nbenchmark, LatEval, which assesses the model's lateral thinking within an\ninteractive framework. In our benchmark, we challenge LLMs with 2 aspects: the\nquality of questions posed by the model and the model's capability to integrate\ninformation for problem-solving. We find that nearly all LLMs struggle with\nemploying lateral thinking during interactions. For example, even the most\nadvanced model, GPT-4, exhibits the advantage to some extent, yet still\nmaintain a noticeable gap when compared to human. This evaluation benchmark\nprovides LLMs with a highly challenging and distinctive task that is crucial to\nan effective AI assistant.",
        "translated": ""
    },
    {
        "title": "AgentVerse: Facilitating Multi-Agent Collaboration and Exploring\n  Emergent Behaviors in Agents",
        "url": "http://arxiv.org/abs/2308.10848v1",
        "pub_date": "2023-08-21",
        "summary": "Autonomous agents empowered by Large Language Models (LLMs) have undergone\nsignificant improvements, enabling them to generalize across a broad spectrum\nof tasks. However, in real-world scenarios, cooperation among individuals is\noften required to enhance the efficiency and effectiveness of task\naccomplishment. Hence, inspired by human group dynamics, we propose a\nmulti-agent framework \\framework that can collaboratively and dynamically\nadjust its composition as a greater-than-the-sum-of-its-parts system. Our\nexperiments demonstrate that \\framework framework can effectively deploy\nmulti-agent groups that outperform a single agent. Furthermore, we delve into\nthe emergence of social behaviors among individual agents within a group during\ncollaborative task accomplishment. In view of these behaviors, we discuss some\npossible strategies to leverage positive ones and mitigate negative ones for\nimproving the collaborative potential of multi-agent groups. Our codes for\n\\framework will soon be released at\n\\url{https://github.com/OpenBMB/AgentVerse}.",
        "translated": ""
    },
    {
        "title": "Instruction Tuning for Large Language Models: A Survey",
        "url": "http://arxiv.org/abs/2308.10792v1",
        "pub_date": "2023-08-21",
        "summary": "This paper surveys research works in the quickly advancing field of\ninstruction tuning (IT), a crucial technique to enhance the capabilities and\ncontrollability of large language models (LLMs). Instruction tuning refers to\nthe process of further training LLMs on a dataset consisting of\n\\textsc{(instruction, output)} pairs in a supervised fashion, which bridges the\ngap between the next-word prediction objective of LLMs and the users' objective\nof having LLMs adhere to human instructions. In this work, we make a systematic\nreview of the literature, including the general methodology of IT, the\nconstruction of IT datasets, the training of IT models, and applications to\ndifferent modalities, domains and applications, along with an analysis on\naspects that influence the outcome of IT (e.g., generation of instruction\noutputs, size of the instruction dataset, etc). We also review the potential\npitfalls of IT along with criticism against it, along with efforts pointing out\ncurrent deficiencies of existing strategies and suggest some avenues for\nfruitful research.",
        "translated": ""
    },
    {
        "title": "Zero- and Few-Shot Prompting with LLMs: A Comparative Study with\n  Fine-tuned Models for Bangla Sentiment Analysis",
        "url": "http://arxiv.org/abs/2308.10783v1",
        "pub_date": "2023-08-21",
        "summary": "The rapid expansion of the digital world has propelled sentiment analysis\ninto a critical tool across diverse sectors such as marketing, politics,\ncustomer service, and healthcare. While there have been significant\nadvancements in sentiment analysis for widely spoken languages, low-resource\nlanguages, such as Bangla, remain largely under-researched due to resource\nconstraints. Furthermore, the recent unprecedented performance of Large\nLanguage Models (LLMs) in various applications highlights the need to evaluate\nthem in the context of low-resource languages. In this study, we present a\nsizeable manually annotated dataset encompassing 33,605 Bangla news tweets and\nFacebook comments. We also investigate zero- and few-shot in-context learning\nwith several language models, including Flan-T5, GPT-4, and Bloomz, offering a\ncomparative analysis against fine-tuned models. Our findings suggest that\nmonolingual transformer-based models consistently outperform other models, even\nin zero and few-shot scenarios. To foster continued exploration, we intend to\nmake this dataset and our research tools publicly available to the broader\nresearch community. In the spirit of further research, we plan to make this\ndataset and our experimental resources publicly accessible to the wider\nresearch community.",
        "translated": ""
    },
    {
        "title": "DepreSym: A Depression Symptom Annotated Corpus and the Role of LLMs as\n  Assessors of Psychological Markers",
        "url": "http://arxiv.org/abs/2308.10758v1",
        "pub_date": "2023-08-21",
        "summary": "Computational methods for depression detection aim to mine traces of\ndepression from online publications posted by Internet users. However,\nsolutions trained on existing collections exhibit limited generalisation and\ninterpretability. To tackle these issues, recent studies have shown that\nidentifying depressive symptoms can lead to more robust models. The eRisk\ninitiative fosters research on this area and has recently proposed a new\nranking task focused on developing search methods to find sentences related to\ndepressive symptoms. This search challenge relies on the symptoms specified by\nthe Beck Depression Inventory-II (BDI-II), a questionnaire widely used in\nclinical practice. Based on the participant systems' results, we present the\nDepreSym dataset, consisting of 21580 sentences annotated according to their\nrelevance to the 21 BDI-II symptoms. The labelled sentences come from a pool of\ndiverse ranking methods, and the final dataset serves as a valuable resource\nfor advancing the development of models that incorporate depressive markers\nsuch as clinical symptoms. Due to the complex nature of this relevance\nannotation, we designed a robust assessment methodology carried out by three\nexpert assessors (including an expert psychologist). Additionally, we explore\nhere the feasibility of employing recent Large Language Models (ChatGPT and\nGPT4) as potential assessors in this complex task. We undertake a comprehensive\nexamination of their performance, determine their main limitations and analyze\ntheir role as a complement or replacement for human annotators.",
        "translated": ""
    },
    {
        "title": "WanJuan: A Comprehensive Multimodal Dataset for Advancing English and\n  Chinese Large Models",
        "url": "http://arxiv.org/abs/2308.10755v1",
        "pub_date": "2023-08-21",
        "summary": "The rise in popularity of ChatGPT and GPT-4 has significantly accelerated the\ndevelopment of large models, leading to the creation of numerous impressive\nlarge language models(LLMs) and multimodal large language models (MLLMs). These\ncutting-edge models owe their remarkable performance to high-quality data.\nHowever, the details of the training data used in leading paradigms are often\nkept confidential. This lack of transparency, coupled with the scarcity of\nopen-source data, impedes further developments within the community. As a\nresponse, this paper presents \"Wan Juan\", a large-scale multimodal dataset\ncomposed of both Chinese and English data, collected from a wide range of web\nsources. The dataset incorporates text, image-text, and video modalities, with\na total volume exceeding 2TB. It was utilized in the training of InternLM, a\nmodel that demonstrated significant advantages in multi-dimensional evaluations\nwhen compared to models of a similar scale. All data can be accessed at\nhttps://opendatalab.org.cn/WanJuan1.0.",
        "translated": ""
    },
    {
        "title": "Systematic Offensive Stereotyping (SOS) Bias in Language Models",
        "url": "http://arxiv.org/abs/2308.10684v1",
        "pub_date": "2023-08-21",
        "summary": "Research has shown that language models (LMs) are socially biased. However,\ntoxicity and offensive stereotyping bias in LMs are understudied. In this\npaper, we investigate the systematic offensive stereotype (SOS) bias in LMs. We\npropose a method to measure it. Then, we validate the SOS bias and investigate\nthe effectiveness of debias methods from the literature on removing it.\nFinally, we investigate the impact of the SOS bias in LMs on their performance\nand their fairness on the task of hate speech detection. Our results suggest\nthat all the inspected LMs are SOS biased. The results suggest that the SOS\nbias in LMs is reflective of the hate experienced online by the inspected\nmarginalized groups. The results indicate that removing the SOS bias in LMs,\nusing a popular debias method from the literature, leads to worse SOS bias\nscores. Finally, Our results show no strong evidence that the SOS bias in LMs\nis impactful on their performance on hate speech detection. On the other hand,\nthere is evidence that the SOS bias in LMs is impactful on their fairness.",
        "translated": ""
    },
    {
        "title": "LibriWASN: A Data Set for Meeting Separation, Diarization, and\n  Recognition with Asynchronous Recording Devices",
        "url": "http://arxiv.org/abs/2308.10682v1",
        "pub_date": "2023-08-21",
        "summary": "We present LibriWASN, a data set whose design follows closely the LibriCSS\nmeeting recognition data set, with the marked difference that the data is\nrecorded with devices that are randomly positioned on a meeting table and whose\nsampling clocks are not synchronized. Nine different devices, five smartphones\nwith a single recording channel and four microphone arrays, are used to record\na total of 29 channels. Other than that, the data set follows closely the\nLibriCSS design: the same LibriSpeech sentences are played back from eight\nloudspeakers arranged around a meeting table and the data is organized in\nsubsets with different percentages of speech overlap. LibriWASN is meant as a\ntest set for clock synchronization algorithms, meeting separation, diarization\nand transcription systems on ad-hoc wireless acoustic sensor networks. Due to\nits similarity to LibriCSS, meeting transcription systems developed for the\nformer can readily be tested on LibriWASN. The data set is recorded in two\ndifferent rooms and is complemented with ground-truth diarization information\nof who speaks when.",
        "translated": ""
    },
    {
        "title": "Multi-event Video-Text Retrieval",
        "url": "http://arxiv.org/abs/2308.11551v1",
        "pub_date": "2023-08-22",
        "summary": "Video-Text Retrieval (VTR) is a crucial multi-modal task in an era of massive\nvideo-text data on the Internet. A plethora of work characterized by using a\ntwo-stream Vision-Language model architecture that learns a joint\nrepresentation of video-text pairs has become a prominent approach for the VTR\ntask. However, these models operate under the assumption of bijective\nvideo-text correspondences and neglect a more practical scenario where video\ncontent usually encompasses multiple events, while texts like user queries or\nwebpage metadata tend to be specific and correspond to single events. This\nestablishes a gap between the previous training objective and real-world\napplications, leading to the potential performance degradation of earlier\nmodels during inference. In this study, we introduce the Multi-event Video-Text\nRetrieval (MeVTR) task, addressing scenarios in which each video contains\nmultiple different events, as a niche scenario of the conventional Video-Text\nRetrieval Task. We present a simple model, Me-Retriever, which incorporates key\nevent video representation and a new MeVTR loss for the MeVTR task.\nComprehensive experiments show that this straightforward framework outperforms\nother models in the Video-to-Text and Text-to-Video tasks, effectively\nestablishing a robust baseline for the MeVTR task. We believe this work serves\nas a strong foundation for future studies. Code is available at\nhttps://github.com/gengyuanmax/MeVTR.",
        "translated": ""
    },
    {
        "title": "L^2R: Lifelong Learning for First-stage Retrieval with\n  Backward-Compatible Representations",
        "url": "http://arxiv.org/abs/2308.11512v1",
        "pub_date": "2023-08-22",
        "summary": "First-stage retrieval is a critical task that aims to retrieve relevant\ndocument candidates from a large-scale collection. While existing retrieval\nmodels have achieved impressive performance, they are mostly studied on static\ndata sets, ignoring that in the real-world, the data on the Web is continuously\ngrowing with potential distribution drift. Consequently, retrievers trained on\nstatic old data may not suit new-coming data well and inevitably produce\nsub-optimal results. In this work, we study lifelong learning for first-stage\nretrieval, especially focusing on the setting where the emerging documents are\nunlabeled since relevance annotation is expensive and may not keep up with data\nemergence. Under this setting, we aim to develop model updating with two goals:\n(1) to effectively adapt to the evolving distribution with the unlabeled\nnew-coming data, and (2) to avoid re-inferring all embeddings of old documents\nto efficiently update the index each time the model is updated.\n  We first formalize the task and then propose a novel Lifelong Learning method\nfor the first-stage Retrieval, namely L^2R. L^2R adopts the typical memory\nmechanism for lifelong learning, and incorporates two crucial components: (1)\nselecting diverse support negatives for model training and memory updating for\neffective model adaptation, and (2) a ranking alignment objective to ensure the\nbackward-compatibility of representations to save the cost of index rebuilding\nwithout hurting the model performance. For evaluation, we construct two new\nbenchmarks from LoTTE and Multi-CPR datasets to simulate the document\ndistribution drift in realistic retrieval scenarios. Extensive experiments show\nthat L^2R significantly outperforms competitive lifelong learning baselines.",
        "translated": ""
    },
    {
        "title": "Pre-training with Aspect-Content Text Mutual Prediction for Multi-Aspect\n  Dense Retrieval",
        "url": "http://arxiv.org/abs/2308.11474v1",
        "pub_date": "2023-08-22",
        "summary": "Grounded on pre-trained language models (PLMs), dense retrieval has been\nstudied extensively on plain text. In contrast, there has been little research\non retrieving data with multiple aspects using dense models. In the scenarios\nsuch as product search, the aspect information plays an essential role in\nrelevance matching, e.g., category: Electronics, Computers, and Pet Supplies. A\ncommon way of leveraging aspect information for multi-aspect retrieval is to\nintroduce an auxiliary classification objective, i.e., using item contents to\npredict the annotated value IDs of item aspects. However, by learning the value\nembeddings from scratch, this approach may not capture the various semantic\nsimilarities between the values sufficiently. To address this limitation, we\nleverage the aspect information as text strings rather than class IDs during\npre-training so that their semantic similarities can be naturally captured in\nthe PLMs. To facilitate effective retrieval with the aspect strings, we propose\nmutual prediction objectives between the text of the item aspect and content.\nIn this way, our model makes more sufficient use of aspect information than\nconducting undifferentiated masked language modeling (MLM) on the concatenated\ntext of aspects and content. Extensive experiments on two real-world datasets\n(product and mini-program search) show that our approach can outperform\ncompetitive baselines both treating aspect values as classes and conducting the\nsame MLM for aspect and content strings. Code and related dataset will be\navailable at the URL \\footnote{https://github.com/sunxiaojie99/ATTEMPT}.",
        "translated": ""
    },
    {
        "title": "On the Opportunities and Challenges of Offline Reinforcement Learning\n  for Recommender Systems",
        "url": "http://arxiv.org/abs/2308.11336v1",
        "pub_date": "2023-08-22",
        "summary": "Reinforcement learning serves as a potent tool for modeling dynamic user\ninterests within recommender systems, garnering increasing research attention\nof late. However, a significant drawback persists: its poor data efficiency,\nstemming from its interactive nature. The training of reinforcement\nlearning-based recommender systems demands expensive online interactions to\namass adequate trajectories, essential for agents to learn user preferences.\nThis inefficiency renders reinforcement learning-based recommender systems a\nformidable undertaking, necessitating the exploration of potential solutions.\nRecent strides in offline reinforcement learning present a new perspective.\nOffline reinforcement learning empowers agents to glean insights from offline\ndatasets and deploy learned policies in online settings. Given that recommender\nsystems possess extensive offline datasets, the framework of offline\nreinforcement learning aligns seamlessly. Despite being a burgeoning field,\nworks centered on recommender systems utilizing offline reinforcement learning\nremain limited. This survey aims to introduce and delve into offline\nreinforcement learning within recommender systems, offering an inclusive review\nof existing literature in this domain. Furthermore, we strive to underscore\nprevalent challenges, opportunities, and future pathways, poised to propel\nresearch in this evolving field.",
        "translated": ""
    },
    {
        "title": "Test Time Embedding Normalization for Popularity Bias Mitigation",
        "url": "http://arxiv.org/abs/2308.11288v1",
        "pub_date": "2023-08-22",
        "summary": "Popularity bias is a widespread problem in the field of recommender systems,\nwhere popular items tend to dominate recommendation results. In this work, we\npropose 'Test Time Embedding Normalization' as a simple yet effective strategy\nfor mitigating popularity bias, which surpasses the performance of the previous\nmitigation approaches by a significant margin. Our approach utilizes the\nnormalized item embedding during the inference stage to control the influence\nof embedding magnitude, which is highly correlated with item popularity.\nThrough extensive experiments, we show that our method combined with the\nsampled softmax loss effectively reduces popularity bias compare to previous\napproaches for bias mitigation. We further investigate the relationship between\nuser and item embeddings and find that the angular similarity between\nembeddings distinguishes preferable and non-preferable items regardless of\ntheir popularity. The analysis explains the mechanism behind the success of our\napproach in eliminating the impact of popularity bias. Our code is available at\nhttps://github.com/ml-postech/TTEN.",
        "translated": ""
    },
    {
        "title": "StoryBench: A Multifaceted Benchmark for Continuous Story Visualization",
        "url": "http://arxiv.org/abs/2308.11606v1",
        "pub_date": "2023-08-22",
        "summary": "Generating video stories from text prompts is a complex task. In addition to\nhaving high visual quality, videos need to realistically adhere to a sequence\nof text prompts whilst being consistent throughout the frames. Creating a\nbenchmark for video generation requires data annotated over time, which\ncontrasts with the single caption used often in video datasets. To fill this\ngap, we collect comprehensive human annotations on three existing datasets, and\nintroduce StoryBench: a new, challenging multi-task benchmark to reliably\nevaluate forthcoming text-to-video models. Our benchmark includes three video\ngeneration tasks of increasing difficulty: action execution, where the next\naction must be generated starting from a conditioning video; story\ncontinuation, where a sequence of actions must be executed starting from a\nconditioning video; and story generation, where a video must be generated from\nonly text prompts. We evaluate small yet strong text-to-video baselines, and\nshow the benefits of training on story-like data algorithmically generated from\nexisting video captions. Finally, we establish guidelines for human evaluation\nof video stories, and reaffirm the need of better automatic metrics for video\ngeneration. StoryBench aims at encouraging future research efforts in this\nexciting new area.",
        "translated": ""
    },
    {
        "title": "Tryage: Real-time, intelligent Routing of User Prompts to Large Language\n  Model",
        "url": "http://arxiv.org/abs/2308.11601v1",
        "pub_date": "2023-08-22",
        "summary": "The introduction of the transformer architecture and the self-attention\nmechanism has led to an explosive production of language models trained on\nspecific downstream tasks and data domains. With over 200, 000 models in the\nHugging Face ecosystem, users grapple with selecting and optimizing models to\nsuit multifaceted workflows and data domains while addressing computational,\nsecurity, and recency concerns. There is an urgent need for machine learning\nframeworks that can eliminate the burden of model selection and customization\nand unleash the incredible power of the vast emerging model library for end\nusers. Here, we propose a context-aware routing system, Tryage, that leverages\na language model router for optimal selection of expert models from a model\nlibrary based on analysis of individual input prompts. Inspired by the thalamic\nrouter in the brain, Tryage employs a perceptive router to predict down-stream\nmodel performance on prompts and, then, makes a routing decision using an\nobjective function that integrates performance predictions with user goals and\nconstraints that are incorporated through flags (e.g., model size, model\nrecency). Tryage allows users to explore a Pareto front and automatically\ntrade-off between task accuracy and secondary goals including minimization of\nmodel size, recency, security, verbosity, and readability. Across heterogeneous\ndata sets that include code, text, clinical data, and patents, the Tryage\nframework surpasses Gorilla and GPT3.5 turbo in dynamic model selection\nidentifying the optimal model with an accuracy of 50.9% , compared to 23.6% by\nGPT 3.5 Turbo and 10.8% by Gorilla. Conceptually, Tryage demonstrates how\nrouting models can be applied to program and control the behavior of\nmulti-model LLM systems to maximize efficient use of the expanding and evolving\nlanguage model ecosystem.",
        "translated": ""
    },
    {
        "title": "SeamlessM4T-Massively Multilingual &amp; Multimodal Machine Translation",
        "url": "http://arxiv.org/abs/2308.11596v1",
        "pub_date": "2023-08-22",
        "summary": "What does it take to create the Babel Fish, a tool that can help individuals\ntranslate speech between any two languages? While recent breakthroughs in\ntext-based models have pushed machine translation coverage beyond 200\nlanguages, unified speech-to-speech translation models have yet to achieve\nsimilar strides. More specifically, conventional speech-to-speech translation\nsystems rely on cascaded systems that perform translation progressively,\nputting high-performing unified systems out of reach. To address these gaps, we\nintroduce SeamlessM4T, a single model that supports speech-to-speech\ntranslation, speech-to-text translation, text-to-speech translation,\ntext-to-text translation, and automatic speech recognition for up to 100\nlanguages. To build this, we used 1 million hours of open speech audio data to\nlearn self-supervised speech representations with w2v-BERT 2.0. Subsequently,\nwe created a multimodal corpus of automatically aligned speech translations.\nFiltered and combined with human-labeled and pseudo-labeled data, we developed\nthe first multilingual system capable of translating from and into English for\nboth speech and text. On FLEURS, SeamlessM4T sets a new standard for\ntranslations into multiple target languages, achieving an improvement of 20%\nBLEU over the previous SOTA in direct speech-to-text translation. Compared to\nstrong cascaded models, SeamlessM4T improves the quality of into-English\ntranslation by 1.3 BLEU points in speech-to-text and by 2.6 ASR-BLEU points in\nspeech-to-speech. Tested for robustness, our system performs better against\nbackground noises and speaker variations in speech-to-text tasks compared to\nthe current SOTA model. Critically, we evaluated SeamlessM4T on gender bias and\nadded toxicity to assess translation safety. Finally, all contributions in this\nwork are open-sourced at this https\nhttps://github.com/facebookresearch/seamless_communication.",
        "translated": ""
    },
    {
        "title": "Using ChatGPT as a CAT tool in Easy Language translation",
        "url": "http://arxiv.org/abs/2308.11563v1",
        "pub_date": "2023-08-22",
        "summary": "This study sets out to investigate the feasibility of using ChatGPT to\ntranslate citizen-oriented administrative texts into German Easy Language, a\nsimplified, controlled language variety that is adapted to the needs of people\nwith reading impairments. We use ChatGPT to translate selected texts from\nwebsites of German public authorities using two strategies, i.e. linguistic and\nholistic. We analyse the quality of the generated texts based on different\ncriteria, such as correctness, readability, and syntactic complexity. The\nresults indicated that the generated texts are easier than the standard texts,\nbut that they still do not fully meet the established Easy Language standards.\nAdditionally, the content is not always rendered correctly.",
        "translated": ""
    },
    {
        "title": "BELB: a Biomedical Entity Linking Benchmark",
        "url": "http://arxiv.org/abs/2308.11537v1",
        "pub_date": "2023-08-22",
        "summary": "Biomedical entity linking (BEL) is the task of grounding entity mentions to a\nknowledge base. It plays a vital role in information extraction pipelines for\nthe life sciences literature. We review recent work in the field and find that,\nas the task is absent from existing benchmarks for biomedical text mining,\ndifferent studies adopt different experimental setups making comparisons based\non published numbers problematic. Furthermore, neural systems are tested\nprimarily on instances linked to the broad coverage knowledge base UMLS,\nleaving their performance to more specialized ones, e.g. genes or variants,\nunderstudied. We therefore developed BELB, a Biomedical Entity Linking\nBenchmark, providing access in a unified format to 11 corpora linked to 7\nknowledge bases and spanning six entity types: gene, disease, chemical,\nspecies, cell line and variant. BELB greatly reduces preprocessing overhead in\ntesting BEL systems on multiple corpora offering a standardized testbed for\nreproducible experiments. Using BELB we perform an extensive evaluation of six\nrule-based entity-specific systems and three recent neural approaches\nleveraging pre-trained language models. Our results reveal a mixed picture\nshowing that neural approaches fail to perform consistently across entity\ntypes, highlighting the need of further studies towards entity-agnostic models.",
        "translated": ""
    },
    {
        "title": "Empowering Refugee Claimants and their Lawyers: Using Machine Learning\n  to Examine Decision-Making in Refugee Law",
        "url": "http://arxiv.org/abs/2308.11531v1",
        "pub_date": "2023-08-22",
        "summary": "Our project aims at helping and supporting stakeholders in refugee status\nadjudications, such as lawyers, judges, governing bodies, and claimants, in\norder to make better decisions through data-driven intelligence and increase\nthe understanding and transparency of the refugee application process for all\ninvolved parties. This PhD project has two primary objectives: (1) to retrieve\npast cases, and (2) to analyze legal decision-making processes on a dataset of\nCanadian cases. In this paper, we present the current state of our work, which\nincludes a completed experiment on part (1) and ongoing efforts related to part\n(2). We believe that NLP-based solutions are well-suited to address these\nchallenges, and we investigate the feasibility of automating all steps\ninvolved. In addition, we introduce a novel benchmark for future NLP research\nin refugee law. Our methodology aims to be inclusive to all end-users and\nstakeholders, with expected benefits including reduced time-to-decision, fairer\nand more transparent outcomes, and improved decision quality.",
        "translated": ""
    },
    {
        "title": "Unsupervised Prototype Adapter for Vision-Language Models",
        "url": "http://arxiv.org/abs/2308.11507v1",
        "pub_date": "2023-08-22",
        "summary": "Recently, large-scale pre-trained vision-language models (e.g. CLIP and\nALIGN) have demonstrated remarkable effectiveness in acquiring transferable\nvisual representations. To leverage the valuable knowledge encoded within these\nmodels for downstream tasks, several fine-tuning approaches, including prompt\ntuning methods and adapter-based methods, have been developed to adapt\nvision-language models effectively with supervision. However, these methods\nrely on the availability of annotated samples, which can be labor-intensive and\ntime-consuming to acquire, thus limiting scalability. To address this issue, in\nthis work, we design an unsupervised fine-tuning approach for vision-language\nmodels called Unsupervised Prototype Adapter (UP-Adapter). Specifically, for\nthe unannotated target datasets, we leverage the text-image aligning capability\nof CLIP to automatically select the most confident samples for each class.\nUtilizing these selected samples, we generate class prototypes, which serve as\nthe initialization for the learnable prototype model. After fine-tuning, the\nprototype model prediction is combined with the original CLIP's prediction by a\nresidual connection to perform downstream recognition tasks. Our extensive\nexperimental results on image recognition and domain generalization show that\nthe proposed unsupervised method outperforms 8-shot CoOp, 8-shot Tip-Adapter,\nand also the state-of-the-art UPL method by large margins.",
        "translated": ""
    },
    {
        "title": "Can Authorship Representation Learning Capture Stylistic Features?",
        "url": "http://arxiv.org/abs/2308.11490v1",
        "pub_date": "2023-08-22",
        "summary": "Automatically disentangling an author's style from the content of their\nwriting is a longstanding and possibly insurmountable problem in computational\nlinguistics. At the same time, the availability of large text corpora furnished\nwith author labels has recently enabled learning authorship representations in\na purely data-driven manner for authorship attribution, a task that ostensibly\ndepends to a greater extent on encoding writing style than encoding content.\nHowever, success on this surrogate task does not ensure that such\nrepresentations capture writing style since authorship could also be correlated\nwith other latent variables, such as topic. In an effort to better understand\nthe nature of the information these representations convey, and specifically to\nvalidate the hypothesis that they chiefly encode writing style, we\nsystematically probe these representations through a series of targeted\nexperiments. The results of these experiments suggest that representations\nlearned for the surrogate authorship prediction task are indeed sensitive to\nwriting style. As a consequence, authorship representations may be expected to\nbe robust to certain kinds of data shift, such as topic drift over time.\nAdditionally, our findings may open the door to downstream applications that\nrequire stylistic representations, such as style transfer.",
        "translated": ""
    },
    {
        "title": "Large Language Models Sensitivity to The Order of Options in\n  Multiple-Choice Questions",
        "url": "http://arxiv.org/abs/2308.11483v1",
        "pub_date": "2023-08-22",
        "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nvarious NLP tasks. However, previous works have shown these models are\nsensitive towards prompt wording, and few-shot demonstrations and their order,\nposing challenges to fair assessment of these models. As these models become\nmore powerful, it becomes imperative to understand and address these\nlimitations. In this paper, we focus on LLMs robustness on the task of\nmultiple-choice questions -- commonly adopted task to study reasoning and\nfact-retrieving capability of LLMs. Investigating the sensitivity of LLMs\ntowards the order of options in multiple-choice questions, we demonstrate a\nconsiderable performance gap of approximately 13% to 75% in LLMs on different\nbenchmarks, when answer options are reordered, even when using demonstrations\nin a few-shot setting. Through a detailed analysis, we conjecture that this\nsensitivity arises when LLMs are uncertain about the prediction between the\ntop-2/3 choices, and specific options placements may favor certain prediction\nbetween those top choices depending on the question caused by positional bias.\nWe also identify patterns in top-2 choices that amplify or mitigate the model's\nbias toward option placement. We found that for amplifying bias, the optimal\nstrategy involves positioning the top two choices as the first and last\noptions. Conversely, to mitigate bias, we recommend placing these choices among\nthe adjacent options. To validate our conjecture, we conduct various\nexperiments and adopt two approaches to calibrate LLMs' predictions, leading to\nup to 8 percentage points improvement across different models and benchmarks.",
        "translated": ""
    },
    {
        "title": "Sentence-Level Multimodal and Language-Agnostic Representations",
        "url": "http://arxiv.org/abs/2308.11466v1",
        "pub_date": "2023-08-22",
        "summary": "We introduce SONAR, a new multilingual and multimodal fixed-size sentence\nembedding space. Our single text encoder, covering 200 languages, substantially\noutperforms existing sentence embeddings such as LASER3 and LabSE on the xsim\nand xsim++ multilingual similarity search tasks. Speech segments can be\nembedded in the same SONAR embedding space using language-specific speech\nencoders trained in a teacher-student setting on speech transcription data. Our\nencoders outperform existing speech encoders on similarity search tasks. We\nalso provide a text decoder for 200 languages, which allows us to perform\ntext-to-text and speech-to-text machine translation, including for zero-shot\nlanguage and modality combinations. Our text-to-text results are competitive\ncompared to the state-of-the-art NLLB~1B model, despite the fixed-size\nbottleneck representation. Our zero-shot speech-to-text translation results\ncompare favorably with strong supervised baselines such as Whisper.",
        "translated": ""
    },
    {
        "title": "Learning from Negative User Feedback and Measuring Responsiveness for\n  Sequential Recommenders",
        "url": "http://arxiv.org/abs/2308.12256v1",
        "pub_date": "2023-08-23",
        "summary": "Sequential recommenders have been widely used in industry due to their\nstrength in modeling user preferences. While these models excel at learning a\nuser's positive interests, less attention has been paid to learning from\nnegative user feedback. Negative user feedback is an important lever of user\ncontrol, and comes with an expectation that recommenders should respond quickly\nand reduce similar recommendations to the user. However, negative feedback\nsignals are often ignored in the training objective of sequential retrieval\nmodels, which primarily aim at predicting positive user interactions. In this\nwork, we incorporate explicit and implicit negative user feedback into the\ntraining objective of sequential recommenders in the retrieval stage using a\n\"not-to-recommend\" loss function that optimizes for the log-likelihood of not\nrecommending items with negative feedback. We demonstrate the effectiveness of\nthis approach using live experiments on a large-scale industrial recommender\nsystem. Furthermore, we address a challenge in measuring recommender\nresponsiveness to negative feedback by developing a counterfactual simulation\nframework to compare recommender responses between different user actions,\nshowing improved responsiveness from the modeling change.",
        "translated": ""
    },
    {
        "title": "LLMRec: Benchmarking Large Language Models on Recommendation Task",
        "url": "http://arxiv.org/abs/2308.12241v1",
        "pub_date": "2023-08-23",
        "summary": "Recently, the fast development of Large Language Models (LLMs) such as\nChatGPT has significantly advanced NLP tasks by enhancing the capabilities of\nconversational models. However, the application of LLMs in the recommendation\ndomain has not been thoroughly investigated. To bridge this gap, we propose\nLLMRec, a LLM-based recommender system designed for benchmarking LLMs on\nvarious recommendation tasks. Specifically, we benchmark several popular\noff-the-shelf LLMs, such as ChatGPT, LLaMA, ChatGLM, on five recommendation\ntasks, including rating prediction, sequential recommendation, direct\nrecommendation, explanation generation, and review summarization. Furthermore,\nwe investigate the effectiveness of supervised finetuning to improve LLMs'\ninstruction compliance ability. The benchmark results indicate that LLMs\ndisplayed only moderate proficiency in accuracy-based tasks such as sequential\nand direct recommendation. However, they demonstrated comparable performance to\nstate-of-the-art methods in explainability-based tasks. We also conduct\nqualitative evaluations to further evaluate the quality of contents generated\nby different models, and the results show that LLMs can truly understand the\nprovided information and generate clearer and more reasonable results. We\naspire that this benchmark will serve as an inspiration for researchers to\ndelve deeper into the potential of LLMs in enhancing recommendation\nperformance. Our codes, processed data and benchmark results are available at\nhttps://github.com/williamliujl/LLMRec.",
        "translated": ""
    },
    {
        "title": "Counterfactual Graph Augmentation for Consumer Unfairness Mitigation in\n  Recommender Systems",
        "url": "http://arxiv.org/abs/2308.12083v1",
        "pub_date": "2023-08-23",
        "summary": "In recommendation literature, explainability and fairness are becoming two\nprominent perspectives to consider. However, prior works have mostly addressed\nthem separately, for instance by explaining to consumers why a certain item was\nrecommended or mitigating disparate impacts in recommendation utility. None of\nthem has leveraged explainability techniques to inform unfairness mitigation.\nIn this paper, we propose an approach that relies on counterfactual\nexplanations to augment the set of user-item interactions, such that using them\nwhile inferring recommendations leads to fairer outcomes. Modeling user-item\ninteractions as a bipartite graph, our approach augments the latter by\nidentifying new user-item edges that not only can explain the original\nunfairness by design, but can also mitigate it. Experiments on two public data\nsets show that our approach effectively leads to a better trade-off between\nfairness and recommendation utility compared with state-of-the-art mitigation\nprocedures. We further analyze the characteristics of added edges to highlight\nkey unfairness patterns. Source code available at\nhttps://github.com/jackmedda/RS-BGExplainer/tree/cikm2023.",
        "translated": ""
    },
    {
        "title": "Hybrid Retrieval and Multi-stage Text Ranking Solution at TREC 2022 Deep\n  Learning Track",
        "url": "http://arxiv.org/abs/2308.12039v1",
        "pub_date": "2023-08-23",
        "summary": "Large-scale text retrieval technology has been widely used in various\npractical business scenarios. This paper presents our systems for the TREC 2022\nDeep Learning Track. We explain the hybrid text retrieval and multi-stage text\nranking method adopted in our solution. The retrieval stage combined the two\nstructures of traditional sparse retrieval and neural dense retrieval. In the\nranking stage, in addition to the full interaction-based ranking model built on\nlarge pre-trained language model, we also proposes a lightweight sub-ranking\nmodule to further enhance the final text ranking performance. Evaluation\nresults demonstrate the effectiveness of our proposed approach. Our models\nachieve the 1st and 4th rank on the test set of passage ranking and document\nranking respectively.",
        "translated": ""
    },
    {
        "title": "LKPNR: LLM and KG for Personalized News Recommendation Framework",
        "url": "http://arxiv.org/abs/2308.12028v1",
        "pub_date": "2023-08-23",
        "summary": "Accurately recommending candidate news articles to users is a basic challenge\nfaced by personalized news recommendation systems. Traditional methods are\nusually difficult to grasp the complex semantic information in news texts,\nresulting in unsatisfactory recommendation results. Besides, these traditional\nmethods are more friendly to active users with rich historical behaviors.\nHowever, they can not effectively solve the \"long tail problem\" of inactive\nusers. To address these issues, this research presents a novel general\nframework that combines Large Language Models (LLM) and Knowledge Graphs (KG)\ninto semantic representations of traditional methods. In order to improve\nsemantic understanding in complex news texts, we use LLMs' powerful text\nunderstanding ability to generate news representations containing rich semantic\ninformation. In addition, our method combines the information about news\nentities and mines high-order structural information through multiple hops in\nKG, thus alleviating the challenge of long tail distribution. Experimental\nresults demonstrate that compared with various traditional models, the\nframework significantly improves the recommendation effect. The successful\nintegration of LLM and KG in our framework has established a feasible path for\nachieving more accurate personalized recommendations in the news field. Our\ncode is available at https://github.com/Xuan-ZW/LKPNR.",
        "translated": ""
    },
    {
        "title": "D4: Improving LLM Pretraining via Document De-Duplication and\n  Diversification",
        "url": "http://arxiv.org/abs/2308.12284v1",
        "pub_date": "2023-08-23",
        "summary": "Over recent years, an increasing amount of compute and data has been poured\ninto training large language models (LLMs), usually by doing one-pass learning\non as many tokens as possible randomly selected from large-scale web corpora.\nWhile training on ever-larger portions of the internet leads to consistent\nperformance improvements, the size of these improvements diminishes with scale,\nand there has been little work exploring the effect of data selection on\npre-training and downstream performance beyond simple de-duplication methods\nsuch as MinHash. Here, we show that careful data selection (on top of\nde-duplicated data) via pre-trained model embeddings can speed up training (20%\nefficiency gains) and improves average downstream accuracy on 16 NLP tasks (up\nto 2%) at the 6.7B model scale. Furthermore, we show that repeating data\nintelligently consistently outperforms baseline training (while repeating\nrandom data performs worse than baseline training). Our results indicate that\nclever data selection can significantly improve LLM pre-training, calls into\nquestion the common practice of training for a single epoch on as much data as\npossible, and demonstrates a path to keep improving our models past the limits\nof randomly sampling web data.",
        "translated": ""
    },
    {
        "title": "Simple is Better and Large is Not Enough: Towards Ensembling of\n  Foundational Language Models",
        "url": "http://arxiv.org/abs/2308.12272v1",
        "pub_date": "2023-08-23",
        "summary": "Foundational Language Models (FLMs) have advanced natural language processing\n(NLP) research. Current researchers are developing larger FLMs (e.g., XLNet,\nT5) to enable contextualized language representation, classification, and\ngeneration. While developing larger FLMs has been of significant advantage, it\nis also a liability concerning hallucination and predictive uncertainty.\nFundamentally, larger FLMs are built on the same foundations as smaller FLMs\n(e.g., BERT); hence, one must recognize the potential of smaller FLMs which can\nbe realized through an ensemble. In the current research, we perform a reality\ncheck on FLMs and their ensemble on benchmark and real-world datasets. We\nhypothesize that the ensembling of FLMs can influence the individualistic\nattention of FLMs and unravel the strength of coordination and cooperation of\ndifferent FLMs. We utilize BERT and define three other ensemble techniques:\n{Shallow, Semi, and Deep}, wherein the Deep-Ensemble introduces a\nknowledge-guided reinforcement learning approach. We discovered that the\nsuggested Deep-Ensemble BERT outperforms its large variation i.e. BERTlarge, by\na factor of many times using datasets that show the usefulness of NLP in\nsensitive fields, such as mental health.",
        "translated": ""
    },
    {
        "title": "Prompt2Model: Generating Deployable Models from Natural Language\n  Instructions",
        "url": "http://arxiv.org/abs/2308.12261v1",
        "pub_date": "2023-08-23",
        "summary": "Large language models (LLMs) enable system builders today to create competent\nNLP systems through prompting, where they only need to describe the task in\nnatural language and provide a few examples. However, in other ways, LLMs are a\nstep backward from traditional special-purpose NLP models; they require\nextensive computational resources for deployment and can be gated behind APIs.\nIn this paper, we propose Prompt2Model, a general-purpose method that takes a\nnatural language task description like the prompts provided to LLMs, and uses\nit to train a special-purpose model that is conducive to deployment. This is\ndone through a multi-step process of retrieval of existing datasets and\npretrained models, dataset generation using LLMs, and supervised fine-tuning on\nthese retrieved and generated datasets. Over three tasks, we demonstrate that\ngiven the same few-shot prompt as input, Prompt2Model trains models that\noutperform the results of a strong LLM, gpt-3.5-turbo, by an average of 20%\nwhile being up to 700 times smaller. We also show that this data can be used to\nobtain reliable performance estimates of model performance, enabling model\ndevelopers to assess model reliability before deployment. Prompt2Model is\navailable open-source at https://github.com/neulab/prompt2model.",
        "translated": ""
    },
    {
        "title": "How to Protect Copyright Data in Optimization of Large Language Models?",
        "url": "http://arxiv.org/abs/2308.12247v1",
        "pub_date": "2023-08-23",
        "summary": "Large language models (LLMs) and generative AI have played a transformative\nrole in computer research and applications. Controversy has arisen as to\nwhether these models output copyrighted data, which can occur if the data the\nmodels are trained on is copyrighted. LLMs are built on the transformer neural\nnetwork architecture, which in turn relies on a mathematical computation called\nAttention that uses the softmax function.\n  In this paper, we show that large language model training and optimization\ncan be seen as a softmax regression problem. We then establish a method of\nefficiently performing softmax regression, in a way that prevents the\nregression function from generating copyright data. This establishes a\ntheoretical method of training large language models in a way that avoids\ngenerating copyright data.",
        "translated": ""
    },
    {
        "title": "Diffusion Language Models Can Perform Many Tasks with Scaling and\n  Instruction-Finetuning",
        "url": "http://arxiv.org/abs/2308.12219v1",
        "pub_date": "2023-08-23",
        "summary": "The recent surge of generative AI has been fueled by the generative power of\ndiffusion probabilistic models and the scalable capabilities of large language\nmodels. Despite their potential, it remains elusive whether diffusion language\nmodels can solve general language tasks comparable to their autoregressive\ncounterparts. This paper demonstrates that scaling diffusion models w.r.t.\ndata, sizes, and tasks can effectively make them strong language learners. We\nbuild competent diffusion language models at scale by first acquiring knowledge\nfrom massive data via masked language modeling pretraining thanks to their\nintrinsic connections. We then reprogram pretrained masked language models into\ndiffusion language models via diffusive adaptation, wherein task-specific\nfinetuning and instruction finetuning are explored to unlock their versatility\nin solving general language tasks. Experiments show that scaling diffusion\nlanguage models consistently improves performance across downstream language\ntasks. We further discover that instruction finetuning can elicit zero-shot and\nfew-shot in-context learning abilities that help tackle many unseen tasks by\nfollowing natural language instructions, and show promise in advanced and\nchallenging abilities such as reasoning",
        "translated": ""
    },
    {
        "title": "The Challenges of Machine Learning for Trust and Safety: A Case Study on\n  Misinformation Detection",
        "url": "http://arxiv.org/abs/2308.12215v1",
        "pub_date": "2023-08-23",
        "summary": "We examine the disconnect between scholarship and practice in applying\nmachine learning to trust and safety problems, using misinformation detection\nas a case study. We systematize literature on automated detection of\nmisinformation across a corpus of 270 well-cited papers in the field. We then\nexamine subsets of papers for data and code availability, design missteps,\nreproducibility, and generalizability. We find significant shortcomings in the\nliterature that call into question claimed performance and practicality.\nDetection tasks are often meaningfully distinct from the challenges that online\nservices actually face. Datasets and model evaluation are often\nnon-representative of real-world contexts, and evaluation frequently is not\nindependent of model training. Data and code availability is poor. Models do\nnot generalize well to out-of-domain data. Based on these results, we offer\nrecommendations for evaluating machine learning applications to trust and\nsafety problems. Our aim is for future work to avoid the pitfalls that we\nidentify.",
        "translated": ""
    },
    {
        "title": "Curriculum Learning with Adam: The Devil Is in the Wrong Details",
        "url": "http://arxiv.org/abs/2308.12202v1",
        "pub_date": "2023-08-23",
        "summary": "Curriculum learning (CL) posits that machine learning models -- similar to\nhumans -- may learn more efficiently from data that match their current\nlearning progress. However, CL methods are still poorly understood and, in\nparticular for natural language processing (NLP), have achieved only limited\nsuccess. In this paper, we explore why. Starting from an attempt to replicate\nand extend a number of recent curriculum methods, we find that their results\nare surprisingly brittle when applied to NLP. A deep dive into the\n(in)effectiveness of the curricula in some scenarios shows us why: when\ncurricula are employed in combination with the popular Adam optimisation\nalgorithm, they oftentimes learn to adapt to suboptimally chosen optimisation\nparameters for this algorithm. We present a number of different case studies\nwith different common hand-crafted and automated CL approaches to illustrate\nthis phenomenon, and we find that none of them outperforms optimisation with\nonly Adam with well-chosen hyperparameters. As such, our results contribute to\nunderstanding why CL methods work, but at the same time urge caution when\nclaiming positive results.",
        "translated": ""
    },
    {
        "title": "Evaluation of Faithfulness Using the Longest Supported Subsequence",
        "url": "http://arxiv.org/abs/2308.12157v1",
        "pub_date": "2023-08-23",
        "summary": "As increasingly sophisticated language models emerge, their trustworthiness\nbecomes a pivotal issue, especially in tasks such as summarization and\nquestion-answering. Ensuring their responses are contextually grounded and\nfaithful is challenging due to the linguistic diversity and the myriad of\npossible answers. In this paper, we introduce a novel approach to evaluate\nfaithfulness of machine-generated text by computing the longest noncontinuous\nsubstring of the claim that is supported by the context, which we refer to as\nthe Longest Supported Subsequence (LSS). Using a new human-annotated dataset,\nwe finetune a model to generate LSS. We introduce a new method of evaluation\nand demonstrate that these metrics correlate better with human ratings when LSS\nis employed, as opposed to when it is not. Our proposed metric demonstrates an\n18% enhancement over the prevailing state-of-the-art metric for faithfulness on\nour dataset. Our metric consistently outperforms other metrics on a\nsummarization dataset across six different models. Finally, we compare several\npopular Large Language Models (LLMs) for faithfulness using this metric. We\nrelease the human-annotated dataset built for predicting LSS and our fine-tuned\nmodel for evaluating faithfulness.",
        "translated": ""
    },
    {
        "title": "Semantic Change Detection for the Romanian Language",
        "url": "http://arxiv.org/abs/2308.12131v1",
        "pub_date": "2023-08-23",
        "summary": "Automatic semantic change methods try to identify the changes that appear\nover time in the meaning of words by analyzing their usage in diachronic\ncorpora. In this paper, we analyze different strategies to create static and\ncontextual word embedding models, i.e., Word2Vec and ELMo, on real-world\nEnglish and Romanian datasets. To test our pipeline and determine the\nperformance of our models, we first evaluate both word embedding models on an\nEnglish dataset (SEMEVAL-CCOHA). Afterward, we focus our experiments on a\nRomanian dataset, and we underline different aspects of semantic changes in\nthis low-resource language, such as meaning acquisition and loss. The\nexperimental results show that, depending on the corpus, the most important\nfactors to consider are the choice of model and the distance to calculate a\nscore for detecting semantic change.",
        "translated": ""
    },
    {
        "title": "Instruction Position Matters in Sequence Generation with Large Language\n  Models",
        "url": "http://arxiv.org/abs/2308.12097v1",
        "pub_date": "2023-08-23",
        "summary": "Large language models (LLMs) are capable of performing conditional sequence\ngeneration tasks, such as translation or summarization, through instruction\nfine-tuning. The fine-tuning data is generally sequentially concatenated from a\nspecific task instruction, an input sentence, and the corresponding response.\nConsidering the locality modeled by the self-attention mechanism of LLMs, these\nmodels face the risk of instruction forgetting when generating responses for\nlong input sentences. To mitigate this issue, we propose enhancing the\ninstruction-following capability of LLMs by shifting the position of task\ninstructions after the input sentences. Theoretical analysis suggests that our\nstraightforward method can alter the model's learning focus, thereby\nemphasizing the training of instruction-following capabilities. Concurrently,\nexperimental results demonstrate that our approach consistently outperforms\ntraditional settings across various model scales (1B / 7B / 13B) and different\nsequence generation tasks (translation and summarization), without any\nadditional data or annotation costs. Notably, our method significantly improves\nthe zero-shot performance on conditional sequence generation, e.g., up to 9.7\nBLEU points on WMT zero-shot translation tasks.",
        "translated": ""
    },
    {
        "title": "On Popularity Bias of Multimodal-aware Recommender Systems: a\n  Modalities-driven Analysis",
        "url": "http://arxiv.org/abs/2308.12911v1",
        "pub_date": "2023-08-24",
        "summary": "Multimodal-aware recommender systems (MRSs) exploit multimodal content (e.g.,\nproduct images or descriptions) as items' side information to improve\nrecommendation accuracy. While most of such methods rely on factorization\nmodels (e.g., MFBPR) as base architecture, it has been shown that MFBPR may be\naffected by popularity bias, meaning that it inherently tends to boost the\nrecommendation of popular (i.e., short-head) items at the detriment of niche\n(i.e., long-tail) items from the catalog. Motivated by this assumption, in this\nwork, we provide one of the first analyses on how multimodality in\nrecommendation could further amplify popularity bias. Concretely, we evaluate\nthe performance of four state-of-the-art MRSs algorithms (i.e., VBPR, MMGCN,\nGRCN, LATTICE) on three datasets from Amazon by assessing, along with\nrecommendation accuracy metrics, performance measures accounting for the\ndiversity of recommended items and the portion of retrieved niche items. To\nbetter investigate this aspect, we decide to study the separate influence of\neach modality (i.e., visual and textual) on popularity bias in different\nevaluation dimensions. Results, which demonstrate how the single modality may\naugment the negative effect of popularity bias, shed light on the importance to\nprovide a more rigorous analysis of the performance of such models.",
        "translated": ""
    },
    {
        "title": "Towards Communication-Efficient Model Updating for On-Device\n  Session-Based Recommendation",
        "url": "http://arxiv.org/abs/2308.12777v1",
        "pub_date": "2023-08-24",
        "summary": "On-device recommender systems recently have garnered increasing attention due\nto their advantages of providing prompt response and securing privacy. To stay\ncurrent with evolving user interests, cloud-based recommender systems are\nperiodically updated with new interaction data. However, on-device models\nstruggle to retrain themselves because of limited onboard computing resources.\nAs a solution, we consider the scenario where the model retraining occurs on\nthe server side and then the updated parameters are transferred to edge devices\nvia network communication. While this eliminates the need for local retraining,\nit incurs a regular transfer of parameters that significantly taxes network\nbandwidth. To mitigate this issue, we develop an efficient approach based on\ncompositional codes to compress the model update. This approach ensures the\non-device model is updated flexibly with minimal additional parameters whilst\nutilizing previous knowledge. The extensive experiments conducted on multiple\nsession-based recommendation models with distinctive architectures demonstrate\nthat the on-device model can achieve comparable accuracy to the retrained\nserver-side counterpart through transferring an update 60x smaller in size. The\ncodes are available at \\url{https://github.com/xiaxin1998/ODUpdate}.",
        "translated": ""
    },
    {
        "title": "On the Consistency of Average Embeddings for Item Recommendation",
        "url": "http://arxiv.org/abs/2308.12767v1",
        "pub_date": "2023-08-24",
        "summary": "A prevalent practice in recommender systems consists of averaging item\nembeddings to represent users or higher-level concepts in the same embedding\nspace. This paper investigates the relevance of such a practice. For this\npurpose, we propose an expected precision score, designed to measure the\nconsistency of an average embedding relative to the items used for its\nconstruction. We subsequently analyze the mathematical expression of this score\nin a theoretical setting with specific assumptions, as well as its empirical\nbehavior on real-world data from music streaming services. Our results\nemphasize that real-world averages are less consistent for recommendation,\nwhich paves the way for future research to better align real-world embeddings\nwith assumptions from our theoretical setting.",
        "translated": ""
    },
    {
        "title": "Video Recommendation Using Social Network Analysis and User Viewing\n  Patterns",
        "url": "http://arxiv.org/abs/2308.12743v1",
        "pub_date": "2023-08-24",
        "summary": "With the meteoric rise of video-on-demand (VOD) platforms, users face the\nchallenge of sifting through an expansive sea of content to uncover shows that\nclosely match their preferences. To address this information overload dilemma,\nVOD services have increasingly incorporated recommender systems powered by\nalgorithms that analyze user behavior and suggest personalized content.\nHowever, a majority of existing recommender systems depend on explicit user\nfeedback in the form of ratings and reviews, which can be difficult and\ntime-consuming to collect at scale. This presents a key research gap, as\nleveraging users' implicit feedback patterns could provide an alternative\navenue for building effective video recommendation models, circumventing the\nneed for explicit ratings. However, prior literature lacks sufficient\nexploration into implicit feedback-based recommender systems, especially in the\ncontext of modeling video viewing behavior. Therefore, this paper aims to\nbridge this research gap by proposing a novel video recommendation technique\nthat relies solely on users' implicit feedback in the form of their content\nviewing percentages.",
        "translated": ""
    },
    {
        "title": "Out of the Box Thinking: Improving Customer Lifetime Value Modelling via\n  Expert Routing and Game Whale Detection",
        "url": "http://arxiv.org/abs/2308.12729v1",
        "pub_date": "2023-08-24",
        "summary": "Customer lifetime value (LTV) prediction is essential for mobile game\npublishers trying to optimize the advertising investment for each user\nacquisition based on the estimated worth. In mobile games, deploying\nmicrotransactions is a simple yet effective monetization strategy, which\nattracts a tiny group of game whales who splurge on in-game purchases. The\npresence of such game whales may impede the practicality of existing LTV\nprediction models, since game whales' purchase behaviours always exhibit varied\ndistribution from general users. Consequently, identifying game whales can open\nup new opportunities to improve the accuracy of LTV prediction models. However,\nlittle attention has been paid to applying game whale detection in LTV\nprediction, and existing works are mainly specialized for the long-term LTV\nprediction with the assumption that the high-quality user features are\navailable, which is not applicable in the UA stage. In this paper, we propose\nExpLTV, a novel multi-task framework to perform LTV prediction and game whale\ndetection in a unified way. In ExpLTV, we first innovatively design a deep\nneural network-based game whale detector that can not only infer the intrinsic\norder in accordance with monetary value, but also precisely identify high\nspenders (i.e., game whales) and low spenders. Then, by treating the game whale\ndetector as a gating network to decide the different mixture patterns of LTV\nexperts assembling, we can thoroughly leverage the shared information and\nscenario-specific information (i.e., game whales modelling and low spenders\nmodelling). Finally, instead of separately designing a purchase rate estimator\nfor two tasks, we design a shared estimator that can preserve the inner task\nrelationships. The superiority of ExpLTV is further validated via extensive\nexperiments on three industrial datasets.",
        "translated": ""
    },
    {
        "title": "Qwen-VL: A Frontier Large Vision-Language Model with Versatile Abilities",
        "url": "http://arxiv.org/abs/2308.12966v1",
        "pub_date": "2023-08-24",
        "summary": "We introduce the Qwen-VL series, a set of large-scale vision-language models\ndesigned to perceive and understand both text and images. Comprising Qwen-VL\nand Qwen-VL-Chat, these models exhibit remarkable performance in tasks like\nimage captioning, question answering, visual localization, and flexible\ninteraction. The evaluation covers a wide range of tasks including zero-shot\ncaptioning, visual or document visual question answering, and grounding. We\ndemonstrate the Qwen-VL outperforms existing Large Vision Language Models\n(LVLMs). We present their architecture, training, capabilities, and\nperformance, highlighting their contributions to advancing multimodal\nartificial intelligence. Code, demo and models are available at\nhttps://github.com/QwenLM/Qwen-VL.",
        "translated": ""
    },
    {
        "title": "Code Llama: Open Foundation Models for Code",
        "url": "http://arxiv.org/abs/2308.12950v1",
        "pub_date": "2023-08-24",
        "summary": "We release Code Llama, a family of large language models for code based on\nLlama 2 providing state-of-the-art performance among open models, infilling\ncapabilities, support for large input contexts, and zero-shot instruction\nfollowing ability for programming tasks. We provide multiple flavors to cover a\nwide range of applications: foundation models (Code Llama), Python\nspecializations (Code Llama - Python), and instruction-following models (Code\nLlama - Instruct) with 7B, 13B and 34B parameters each. All models are trained\non sequences of 16k tokens and show improvements on inputs with up to 100k\ntokens. 7B and 13B Code Llama and Code Llama - Instruct variants support\ninfilling based on surrounding content. Code Llama reaches state-of-the-art\nperformance among open models on several code benchmarks, with scores of up to\n53% and 55% on HumanEval and MBPP, respectively. Notably, Code Llama - Python\n7B outperforms Llama 2 70B on HumanEval and MBPP, and all our models outperform\nevery other publicly available model on MultiPL-E. We release Code Llama under\na permissive license that allows for both research and commercial use.",
        "translated": ""
    },
    {
        "title": "Can Linguistic Knowledge Improve Multimodal Alignment in Vision-Language\n  Pretraining?",
        "url": "http://arxiv.org/abs/2308.12898v1",
        "pub_date": "2023-08-24",
        "summary": "The multimedia community has shown a significant interest in perceiving and\nrepresenting the physical world with multimodal pretrained neural network\nmodels, and among them, the visual-language pertaining (VLP) is, currently, the\nmost captivating topic. However, there have been few endeavors dedicated to the\nexploration of 1) whether essential linguistic knowledge (e.g., semantics and\nsyntax) can be extracted during VLP, and 2) how such linguistic knowledge\nimpact or enhance the multimodal alignment. In response, here we aim to\nelucidate the impact of comprehensive linguistic knowledge, including semantic\nexpression and syntactic structure, on multimodal alignment. Specifically, we\ndesign and release the SNARE, the first large-scale multimodal alignment\nprobing benchmark, to detect the vital linguistic components, e.g., lexical,\nsemantic, and syntax knowledge, containing four tasks: Semantic structure,\nNegation logic, Attribute ownership, and Relationship composition. Based on our\nproposed probing benchmarks, our holistic analyses of five advanced VLP models\nillustrate that the VLP model: i) shows insensitivity towards complex syntax\nstructures and relies on content words for sentence comprehension; ii)\ndemonstrates limited comprehension of combinations between sentences and\nnegations; iii) faces challenges in determining the presence of actions or\nspatial relationships within visual information and struggles with verifying\nthe correctness of triple combinations. We make our benchmark and code\navailable at \\url{https://github.com/WangFei-2019/SNARE/}.",
        "translated": ""
    },
    {
        "title": "Beyond Document Page Classification: Design, Datasets, and Challenges",
        "url": "http://arxiv.org/abs/2308.12896v1",
        "pub_date": "2023-08-24",
        "summary": "This paper highlights the need to bring document classification benchmarking\ncloser to real-world applications, both in the nature of data tested ($X$:\nmulti-channel, multi-paged, multi-industry; $Y$: class distributions and label\nset variety) and in classification tasks considered ($f$: multi-page document,\npage stream, and document bundle classification, ...). We identify the lack of\npublic multi-page document classification datasets, formalize different\nclassification tasks arising in application scenarios, and motivate the value\nof targeting efficient multi-page document representations. An experimental\nstudy on proposed multi-page document classification datasets demonstrates that\ncurrent benchmarks have become irrelevant and need to be updated to evaluate\ncomplete documents, as they naturally occur in practice. This reality check\nalso calls for more mature evaluation methodologies, covering calibration\nevaluation, inference complexity (time-memory), and a range of realistic\ndistribution shifts (e.g., born-digital vs. scanning noise, shifting page\norder). Our study ends on a hopeful note by recommending concrete avenues for\nfuture improvements.}",
        "translated": ""
    },
    {
        "title": "Large Language Models Vote: Prompting for Rare Disease Identification",
        "url": "http://arxiv.org/abs/2308.12890v1",
        "pub_date": "2023-08-24",
        "summary": "The emergence of generative Large Language Models (LLMs) emphasizes the need\nfor accurate and efficient prompting approaches. LLMs are often applied in\nFew-Shot Learning (FSL) contexts, where tasks are executed with minimal\ntraining data. FSL has become popular in many Artificial Intelligence (AI)\nsubdomains, including AI for health. Rare diseases, affecting a small fraction\nof the population, inherently require FSL techniques due to limited data\navailability, though manual data collection and annotation is costly and\ntime-consuming. In this paper, we propose Models-Vote Prompting (MVP), a\nflexible prompting approach for improving the performance of LLM queries in FSL\nsettings. MVP works by prompting numerous LLMs to perform the same tasks and\nthen conducting a majority vote on the resulting outputs. This method achieves\nimproved results to any one model in the ensemble on one-shot rare disease\nidentification and classification tasks. We also release a novel rare disease\ndataset for FSL, available to those who agreed to the MIMIC-IV Data Use\nAgreement (DUA). Furthermore, in using MVP, each model is prompted multiple\ntimes, substantially increasing the time needed for manual annotation, and to\naddress this, we assess the feasibility of using JSON for automating generative\nLLM evaluation.",
        "translated": ""
    },
    {
        "title": "Inducing Causal Structure for Abstractive Text Summarization",
        "url": "http://arxiv.org/abs/2308.12888v1",
        "pub_date": "2023-08-24",
        "summary": "The mainstream of data-driven abstractive summarization models tends to\nexplore the correlations rather than the causal relationships. Among such\ncorrelations, there can be spurious ones which suffer from the language prior\nlearned from the training corpus and therefore undermine the overall\neffectiveness of the learned model. To tackle this issue, we introduce a\nStructural Causal Model (SCM) to induce the underlying causal structure of the\nsummarization data. We assume several latent causal factors and non-causal\nfactors, representing the content and style of the document and summary.\nTheoretically, we prove that the latent factors in our SCM can be identified by\nfitting the observed training data under certain conditions. On the basis of\nthis, we propose a Causality Inspired Sequence-to-Sequence model (CI-Seq2Seq)\nto learn the causal representations that can mimic the causal factors, guiding\nus to pursue causal information for summary generation. The key idea is to\nreformulate the Variational Auto-encoder (VAE) to fit the joint distribution of\nthe document and summary variables from the training corpus. Experimental\nresults on two widely used text summarization datasets demonstrate the\nadvantages of our approach.",
        "translated": ""
    },
    {
        "title": "Text Similarity from Image Contents using Statistical and Semantic\n  Analysis Techniques",
        "url": "http://arxiv.org/abs/2308.12842v1",
        "pub_date": "2023-08-24",
        "summary": "Plagiarism detection is one of the most researched areas among the Natural\nLanguage Processing(NLP) community. A good plagiarism detection covers all the\nNLP methods including semantics, named entities, paraphrases etc. and produces\ndetailed plagiarism reports. Detection of Cross Lingual Plagiarism requires\ndeep knowledge of various advanced methods and algorithms to perform effective\ntext similarity checking. Nowadays the plagiarists are also advancing\nthemselves from hiding the identity from being catch in such offense. The\nplagiarists are bypassed from being detected with techniques like paraphrasing,\nsynonym replacement, mismatching citations, translating one language to\nanother. Image Content Plagiarism Detection (ICPD) has gained importance,\nutilizing advanced image content processing to identify instances of plagiarism\nto ensure the integrity of image content. The issue of plagiarism extends\nbeyond textual content, as images such as figures, graphs, and tables also have\nthe potential to be plagiarized. However, image content plagiarism detection\nremains an unaddressed challenge. Therefore, there is a critical need to\ndevelop methods and systems for detecting plagiarism in image content. In this\npaper, the system has been implemented to detect plagiarism form contents of\nImages such as Figures, Graphs, Tables etc. Along with statistical algorithms\nsuch as Jaccard and Cosine, introducing semantic algorithms such as LSA, BERT,\nWordNet outperformed in detecting efficient and accurate plagiarism.",
        "translated": ""
    },
    {
        "title": "Use of LLMs for Illicit Purposes: Threats, Prevention Measures, and\n  Vulnerabilities",
        "url": "http://arxiv.org/abs/2308.12833v1",
        "pub_date": "2023-08-24",
        "summary": "Spurred by the recent rapid increase in the development and distribution of\nlarge language models (LLMs) across industry and academia, much recent work has\ndrawn attention to safety- and security-related threats and vulnerabilities of\nLLMs, including in the context of potentially criminal activities.\nSpecifically, it has been shown that LLMs can be misused for fraud,\nimpersonation, and the generation of malware; while other authors have\nconsidered the more general problem of AI alignment. It is important that\ndevelopers and practitioners alike are aware of security-related problems with\nsuch models. In this paper, we provide an overview of existing - predominantly\nscientific - efforts on identifying and mitigating threats and vulnerabilities\narising from LLMs. We present a taxonomy describing the relationship between\nthreats caused by the generative capabilities of LLMs, prevention measures\nintended to address such threats, and vulnerabilities arising from imperfect\nprevention measures. With our work, we hope to raise awareness of the\nlimitations of LLMs in light of such security concerns, among both experienced\ndevelopers and novel users of such technologies.",
        "translated": ""
    },
    {
        "title": "WavMark: Watermarking for Audio Generation",
        "url": "http://arxiv.org/abs/2308.12770v1",
        "pub_date": "2023-08-24",
        "summary": "Recent breakthroughs in zero-shot voice synthesis have enabled imitating a\nspeaker's voice using just a few seconds of recording while maintaining a high\nlevel of realism. Alongside its potential benefits, this powerful technology\nintroduces notable risks, including voice fraud and speaker impersonation.\nUnlike the conventional approach of solely relying on passive methods for\ndetecting synthetic data, watermarking presents a proactive and robust defence\nmechanism against these looming risks. This paper introduces an innovative\naudio watermarking framework that encodes up to 32 bits of watermark within a\nmere 1-second audio snippet. The watermark is imperceptible to human senses and\nexhibits strong resilience against various attacks. It can serve as an\neffective identifier for synthesized voices and holds potential for broader\napplications in audio copyright protection. Moreover, this framework boasts\nhigh flexibility, allowing for the combination of multiple watermark segments\nto achieve heightened robustness and expanded capacity. Utilizing 10 to\n20-second audio as the host, our approach demonstrates an average Bit Error\nRate (BER) of 0.48\\% across ten common attacks, a remarkable reduction of over\n2800\\% in BER compared to the state-of-the-art watermarking tool. See\nhttps://aka.ms/wavmark for demos of our work.",
        "translated": ""
    },
    {
        "title": "Real-time Detection of AI-Generated Speech for DeepFake Voice Conversion",
        "url": "http://arxiv.org/abs/2308.12734v1",
        "pub_date": "2023-08-24",
        "summary": "There are growing implications surrounding generative AI in the speech domain\nthat enable voice cloning and real-time voice conversion from one individual to\nanother. This technology poses a significant ethical threat and could lead to\nbreaches of privacy and misrepresentation, thus there is an urgent need for\nreal-time detection of AI-generated speech for DeepFake Voice Conversion. To\naddress the above emerging issues, the DEEP-VOICE dataset is generated in this\nstudy, comprised of real human speech from eight well-known figures and their\nspeech converted to one another using Retrieval-based Voice Conversion.\nPresenting as a binary classification problem of whether the speech is real or\nAI-generated, statistical analysis of temporal audio features through t-testing\nreveals that there are significantly different distributions. Hyperparameter\noptimisation is implemented for machine learning models to identify the source\nof speech. Following the training of 208 individual machine learning models\nover 10-fold cross validation, it is found that the Extreme Gradient Boosting\nmodel can achieve an average classification accuracy of 99.3% and can classify\nspeech in real-time, at around 0.004 milliseconds given one second of speech.\nAll data generated for this study is released publicly for future research on\nAI speech detection.",
        "translated": ""
    },
    {
        "title": "On the Practicality of Dynamic Updates in Fast Searchable Encryption",
        "url": "http://arxiv.org/abs/2308.13486v1",
        "pub_date": "2023-08-25",
        "summary": "Searchable encrypted (SE) indexing systems are a useful tool for utilizing\ncloud services to store and manage sensitive information. However, much of the\nwork on SE systems to date has remained theoretical. In order to make them of\npractical use, more work is needed to develop optimal protocols and working\nmodels for them. This includes, in particular, the creation of a working update\nmodel in order to maintain an encrypted index of a dynamic document set such as\nan email inbox. I have created a working, real-world end-to-end SE\nimplementation that satisfies these needs, including the first empirical\nperformance evaluation of the dynamic SE update operation. In doing so, I show\na viable path to move from the theoretical concepts described by previous\nresearchers to a future production-worthy implementation and identify issues\nfor follow-on investigation.",
        "translated": ""
    },
    {
        "title": "Leveraging Knowledge and Reinforcement Learning for Enhanced Reliability\n  of Language Models",
        "url": "http://arxiv.org/abs/2308.13467v1",
        "pub_date": "2023-08-25",
        "summary": "The Natural Language Processing(NLP) community has been using crowd sourcing\ntechniques to create benchmark datasets such as General Language Understanding\nand Evaluation(GLUE) for training modern Language Models such as BERT. GLUE\ntasks measure the reliability scores using inter annotator metrics i.e. Cohens\nKappa. However, the reliability aspect of LMs has often been overlooked. To\ncounter this problem, we explore a knowledge-guided LM ensembling approach that\nleverages reinforcement learning to integrate knowledge from ConceptNet and\nWikipedia as knowledge graph embeddings. This approach mimics human annotators\nresorting to external knowledge to compensate for information deficits in the\ndatasets. Across nine GLUE datasets, our research shows that ensembling\nstrengthens reliability and accuracy scores, outperforming state of the art.",
        "translated": ""
    },
    {
        "title": "A Bayesian Active Learning Approach to Comparative Judgement",
        "url": "http://arxiv.org/abs/2308.13292v1",
        "pub_date": "2023-08-25",
        "summary": "Assessment is a crucial part of education. Traditional marking is a source of\ninconsistencies and unconscious bias, placing a high cognitive load on the\nassessors. An approach to address these issues is comparative judgement (CJ).\nIn CJ, the assessor is presented with a pair of items and is asked to select\nthe better one. Following a series of comparisons, a rank is derived using a\nranking model, for example, the BTM, based on the results. While CJ is\nconsidered a reliable method for marking, there are concerns around\ntransparency, and the ideal number of pairwise comparisons to generate a\nreliable estimation of the rank order is not known. Additionally, there have\nbeen attempts to generate a method of selecting pairs that should be compared\nnext in an informative manner, but some existing methods are known to have\ncreated their own bias within results inflating the reliability metric used. As\na result, a random selection approach is usually deployed.\n  We propose a novel Bayesian approach to CJ (BCJ) for determining the ranks of\ncompared items alongside a new way to select the pairs to present to the\nmarker(s) using active learning (AL), addressing the key shortcomings of\ntraditional CJ. Furthermore, we demonstrate how the entire approach may provide\ntransparency by providing the user insights into how it is making its decisions\nand, at the same time, being more efficient. Results from our experiments\nconfirm that the proposed BCJ combined with entropy-driven AL pair-selection\nmethod is superior to other alternatives. We also find that the more\ncomparisons done, the more accurate BCJ becomes, which solves the issue the\ncurrent method has of the model deteriorating if too many comparisons are\nperformed. As our approach can generate the complete predicted rank\ndistribution for an item, we also show how this can be utilised in devising a\npredicted grade, guided by the assessor.",
        "translated": ""
    },
    {
        "title": "Learning and Optimization of Implicit Negative Feedback for Industrial\n  Short-video Recommender System",
        "url": "http://arxiv.org/abs/2308.13249v1",
        "pub_date": "2023-08-25",
        "summary": "Short-video recommendation is one of the most important recommendation\napplications in today's industrial information systems. Compared with other\nrecommendation tasks, the enormous amount of feedback is the most typical\ncharacteristic. Specifically, in short-video recommendation, the\neasiest-to-collect user feedback is from the skipping behaviors, which leads to\ntwo critical challenges for the recommendation model. First, the skipping\nbehavior reflects implicit user preferences, and thus it is challenging for\ninterest extraction. Second, the kind of special feedback involves multiple\nobjectives, such as total watching time, which is also very challenging. In\nthis paper, we present our industrial solution in Kuaishou, which serves\nbillion-level users every day. Specifically, we deploy a feedback-aware\nencoding module which well extracts user preference taking the impact of\ncontext into consideration. We further design a multi-objective prediction\nmodule which well distinguishes the relation and differences among different\nmodel objectives in the short-video recommendation. We conduct extensive online\nA/B testing, along with detailed and careful analysis, which verifies the\neffectiveness of our solution.",
        "translated": ""
    },
    {
        "title": "Optimizing Group-Fair Plackett-Luce Ranking Models for Relevance and\n  Ex-Post Fairness",
        "url": "http://arxiv.org/abs/2308.13242v1",
        "pub_date": "2023-08-25",
        "summary": "In learning-to-rank (LTR), optimizing only the relevance (or the expected\nranking utility) can cause representational harm to certain categories of\nitems. Moreover, if there is implicit bias in the relevance scores, LTR models\nmay fail to optimize for true relevance. Previous works have proposed efficient\nalgorithms to train stochastic ranking models that achieve fairness of exposure\nto the groups ex-ante (or, in expectation), which may not guarantee\nrepresentation fairness to the groups ex-post, that is, after realizing a\nranking from the stochastic ranking model. Typically, ex-post fairness is\nachieved by post-processing, but previous work does not train stochastic\nranking models that are aware of this post-processing.\n  In this paper, we propose a novel objective that maximizes expected relevance\nonly over those rankings that satisfy given representation constraints to\nensure ex-post fairness. Building upon recent work on an efficient sampler for\nex-post group-fair rankings, we propose a group-fair Plackett-Luce model and\nshow that it can be efficiently optimized for our objective in the LTR\nframework.\n  Experiments on three real-world datasets show that our group-fair algorithm\nguarantees fairness alongside usually having better relevance compared to the\nLTR baselines. In addition, our algorithm also achieves better relevance than\npost-processing baselines, which also ensures ex-post fairness. Further, when\nimplicit bias is injected into the training data, our algorithm typically\noutperforms existing LTR baselines in relevance.",
        "translated": ""
    },
    {
        "title": "ChatGPT as Data Augmentation for Compositional Generalization: A Case\n  Study in Open Intent Detection",
        "url": "http://arxiv.org/abs/2308.13517v1",
        "pub_date": "2023-08-25",
        "summary": "Open intent detection, a crucial aspect of natural language understanding,\ninvolves the identification of previously unseen intents in user-generated\ntext. Despite the progress made in this field, challenges persist in handling\nnew combinations of language components, which is essential for compositional\ngeneralization. In this paper, we present a case study exploring the use of\nChatGPT as a data augmentation technique to enhance compositional\ngeneralization in open intent detection tasks. We begin by discussing the\nlimitations of existing benchmarks in evaluating this problem, highlighting the\nneed for constructing datasets for addressing compositional generalization in\nopen intent detection tasks. By incorporating synthetic data generated by\nChatGPT into the training process, we demonstrate that our approach can\neffectively improve model performance. Rigorous evaluation of multiple\nbenchmarks reveals that our method outperforms existing techniques and\nsignificantly enhances open intent detection capabilities. Our findings\nunderscore the potential of large language models like ChatGPT for data\naugmentation in natural language understanding tasks.",
        "translated": ""
    },
    {
        "title": "Training and Meta-Evaluating Machine Translation Evaluation Metrics at\n  the Paragraph Level",
        "url": "http://arxiv.org/abs/2308.13506v1",
        "pub_date": "2023-08-25",
        "summary": "As research on machine translation moves to translating text beyond the\nsentence level, it remains unclear how effective automatic evaluation metrics\nare at scoring longer translations. In this work, we first propose a method for\ncreating paragraph-level data for training and meta-evaluating metrics from\nexisting sentence-level data. Then, we use these new datasets to benchmark\nexisting sentence-level metrics as well as train learned metrics at the\nparagraph level. Interestingly, our experimental results demonstrate that using\nsentence-level metrics to score entire paragraphs is equally as effective as\nusing a metric designed to work at the paragraph level. We speculate this\nresult can be attributed to properties of the task of reference-based\nevaluation as well as limitations of our datasets with respect to capturing all\ntypes of phenomena that occur in paragraph-level translations.",
        "translated": ""
    },
    {
        "title": "Ngambay-French Neural Machine Translation (sba-Fr)",
        "url": "http://arxiv.org/abs/2308.13497v1",
        "pub_date": "2023-08-25",
        "summary": "In Africa, and the world at large, there is an increasing focus on developing\nNeural Machine Translation (NMT) systems to overcome language barriers. NMT for\nLow-resource language is particularly compelling as it involves learning with\nlimited labelled data. However, obtaining a well-aligned parallel corpus for\nlow-resource languages can be challenging. The disparity between the\ntechnological advancement of a few global languages and the lack of research on\nNMT for local languages in Chad is striking. End-to-end NMT trials on\nlow-resource Chad languages have not been attempted. Additionally, there is a\ndearth of online and well-structured data gathering for research in Natural\nLanguage Processing, unlike some African languages. However, a guided approach\nfor data gathering can produce bitext data for many Chadian language\ntranslation pairs with well-known languages that have ample data. In this\nproject, we created the first sba-Fr Dataset, which is a corpus of\nNgambay-to-French translations, and fine-tuned three pre-trained models using\nthis dataset. Our experiments show that the M2M100 model outperforms other\nmodels with high BLEU scores on both original and original+synthetic data. The\npublicly available bitext dataset can be used for research purposes.",
        "translated": ""
    },
    {
        "title": "Prompting a Large Language Model to Generate Diverse Motivational\n  Messages: A Comparison with Human-Written Messages",
        "url": "http://arxiv.org/abs/2308.13479v1",
        "pub_date": "2023-08-25",
        "summary": "Large language models (LLMs) are increasingly capable and prevalent, and can\nbe used to produce creative content. The quality of content is influenced by\nthe prompt used, with more specific prompts that incorporate examples generally\nproducing better results. On from this, it could be seen that using\ninstructions written for crowdsourcing tasks (that are specific and include\nexamples to guide workers) could prove effective LLM prompts. To explore this,\nwe used a previous crowdsourcing pipeline that gave examples to people to help\nthem generate a collectively diverse corpus of motivational messages. We then\nused this same pipeline to generate messages using GPT-4, and compared the\ncollective diversity of messages from: (1) crowd-writers, (2) GPT-4 using the\npipeline, and (3 &amp; 4) two baseline GPT-4 prompts. We found that the LLM prompts\nusing the crowdsourcing pipeline caused GPT-4 to produce more diverse messages\nthan the two baseline prompts. We also discuss implications from messages\ngenerated by both human writers and LLMs.",
        "translated": ""
    },
    {
        "title": "ARTIST: ARTificial Intelligence for Simplified Text",
        "url": "http://arxiv.org/abs/2308.13458v1",
        "pub_date": "2023-08-25",
        "summary": "Complex text is a major barrier for many citizens when accessing public\ninformation and knowledge. While often done manually, Text Simplification is a\nkey Natural Language Processing task that aims for reducing the linguistic\ncomplexity of a text while preserving the original meaning. Recent advances in\nGenerative Artificial Intelligence (AI) have enabled automatic text\nsimplification both on the lexical and syntactical levels. However, as\napplications often focus on English, little is understood about the\neffectiveness of Generative AI techniques on low-resource languages such as\nDutch. For this reason, we carry out empirical studies to understand the\nbenefits and limitations of applying generative technologies for text\nsimplification and provide the following outcomes: 1) the design and\nimplementation for a configurable text simplification pipeline that\norchestrates state-of-the-art generative text simplification models, domain and\nreader adaptation, and visualisation modules; 2) insights and lessons learned,\nshowing the strengths of automatic text simplification while exposing the\nchallenges in handling cultural and commonsense knowledge. These outcomes\nrepresent a first step in the exploration of Dutch text simplification and shed\nlight on future endeavours both for research and practice.",
        "translated": ""
    },
    {
        "title": "The Poison of Alignment",
        "url": "http://arxiv.org/abs/2308.13449v1",
        "pub_date": "2023-08-25",
        "summary": "From the perspective of content safety issues, alignment has shown to limit\nlarge language models' (LLMs) harmful content generation. This intentional\nmethod of reinforcing models to not respond to certain user inputs seem to be\npresent in many modern open-source instruction tuning datasets such as\nOpenAssistant or Guanaco. We introduce a novel insight to an instruction-tuned\nmodel's performance affected by the presence of alignment in supervised\nfine-tuning dataset. To be specific, we noticed that alignment acts as if it is\npoisoning the instruction dataset. Experimentally, we demonstrate that aligned\nanswers significantly worsen the performance of the resulting fine-tuned\nmodel's on various reasoning benchmarks such as Big Bench (BBH), Massive\nMultitask Language Understanding (MMLU), Human Eval, and Discrete Reasoning\nOver Paragraphs (DROP), performing worse than the counterpart tuned without\nalignment by 4-33%.",
        "translated": ""
    },
    {
        "title": "EntropyRank: Unsupervised Keyphrase Extraction via Side-Information\n  Optimization for Language Model-based Text Compression",
        "url": "http://arxiv.org/abs/2308.13399v1",
        "pub_date": "2023-08-25",
        "summary": "We propose an unsupervised method to extract keywords and keyphrases from\ntexts based on a pre-trained language model (LM) and Shannon's information\nmaximization. Specifically, our method extracts phrases having the highest\nconditional entropy under the LM. The resulting set of keyphrases turns out to\nsolve a relevant information-theoretic problem: if provided as side\ninformation, it leads to the expected minimal binary code length in compressing\nthe text using the LM and an entropy encoder. Alternately, the resulting set is\nan approximation via a causal LM to the set of phrases that minimize the\nentropy of the text when conditioned upon it. Empirically, the method provides\nresults comparable to the most commonly used methods in various keyphrase\nextraction benchmark challenges.",
        "translated": ""
    },
    {
        "title": "Do-Not-Answer: A Dataset for Evaluating Safeguards in LLMs",
        "url": "http://arxiv.org/abs/2308.13387v1",
        "pub_date": "2023-08-25",
        "summary": "With the rapid evolution of large language models (LLMs), new and\nhard-to-predict harmful capabilities are emerging. This requires developers to\nbe able to identify risks through the evaluation of \"dangerous capabilities\" in\norder to responsibly deploy LLMs. In this work, we collect the first\nopen-source dataset to evaluate safeguards in LLMs, and deploy safer\nopen-source LLMs at a low cost. Our dataset is curated and filtered to consist\nonly of instructions that responsible language models should not follow. We\nannotate and assess the responses of six popular LLMs to these instructions.\nBased on our annotation, we proceed to train several BERT-like classifiers, and\nfind that these small classifiers can achieve results that are comparable with\nGPT-4 on automatic safety evaluation. Warning: this paper contains example data\nthat may be offensive, harmful, or biased.",
        "translated": ""
    },
    {
        "title": "Assessing Keyness using Permutation Tests",
        "url": "http://arxiv.org/abs/2308.13383v1",
        "pub_date": "2023-08-25",
        "summary": "We propose a resampling-based approach for assessing keyness in corpus\nlinguistics based on suggestions by Gries (2006, 2022). Traditional approaches\nbased on hypothesis tests (e.g. Likelihood Ratio) model the copora as\nindependent identically distributed samples of tokens. This model does not\naccount for the often observed uneven distribution of occurences of a word\nacross a corpus. When occurences of a word are concentrated in few documents,\nlarge values of LLR and similar scores are in fact much more likely than\naccounted for by the token-by-token sampling model, leading to false positives.\n  We replace the token-by-token sampling model by a model where corpora are\nsamples of documents rather than tokens, which is much closer to the way\ncorpora are actually assembled. We then use a permutation approach to\napproximate the distribution of a given keyness score under the null hypothesis\nof equal frequencies and obtain p-values for assessing significance. We do not\nneed any assumption on how the tokens are organized within or across documents,\nand the approach works with basically *any* keyness score. Hence, appart from\nobtaining more accurate p-values for scores like LLR, we can also assess\nsignificance for e.g. the logratio which has been proposed as a measure of\neffect size.\n  An efficient implementation of the proposed approach is provided in the `R`\npackage `keyperm` available from github.",
        "translated": ""
    },
    {
        "title": "TRIVEA: Transparent Ranking Interpretation using Visual Explanation of\n  Black-Box Algorithmic Rankers",
        "url": "http://arxiv.org/abs/2308.14622v1",
        "pub_date": "2023-08-28",
        "summary": "Ranking schemes drive many real-world decisions, like, where to study, whom\nto hire, what to buy, etc. Many of these decisions often come with high\nconsequences. For example, a university can be deemed less prestigious if not\nfeatured in a top-k list, and consumers might not even explore products that do\nnot get recommended to buyers. At the heart of most of these decisions are\nopaque ranking schemes, which dictate the ordering of data entities, but their\ninternal logic is inaccessible or proprietary. Drawing inferences about the\nranking differences is like a guessing game to the stakeholders, like, the\nrankees (i.e., the entities who are ranked, like product companies) and the\ndecision-makers (i.e., who use the rankings, like buyers). In this paper, we\naim to enable transparency in ranking interpretation by using algorithmic\nrankers that learn from available data and by enabling human reasoning about\nthe learned ranking differences using explainable AI (XAI) methods. To realize\nthis aim, we leverage the exploration-explanation paradigm of human-data\ninteraction to let human stakeholders explore subsets and groupings of complex\nmulti-attribute ranking data using visual explanations of model fit and\nattribute influence on rankings. We realize this explanation paradigm for\ntransparent ranking interpretation in TRIVEA, a visual analytic system that is\nfueled by: i) visualizations of model fit derived from algorithmic rankers that\nlearn the associations between attributes and rankings from available data and\nii) visual explanations derived from XAI methods that help abstract important\npatterns, like, the relative influence of attributes in different ranking\nranges. Using TRIVEA, end users not trained in data science have the agency to\ntransparently reason about the global and local behavior of the rankings\nwithout the need to open black-box ranking models and develop confidence in the\nresulting attribute-based inferences. We demonstrate the efficacy of TRIVEA\nusing multiple usage scenarios and subjective feedback from researchers with\ndiverse domain expertise. Keywords: Visual Analytics, Learning-to-Rank,\nExplainable ML, Ranking",
        "translated": ""
    },
    {
        "title": "Fairness Through Domain Awareness: Mitigating Popularity Bias For Music\n  Discovery",
        "url": "http://arxiv.org/abs/2308.14601v1",
        "pub_date": "2023-08-28",
        "summary": "As online music platforms grow, music recommender systems play a vital role\nin helping users navigate and discover content within their vast musical\ndatabases. At odds with this larger goal, is the presence of popularity bias,\nwhich causes algorithmic systems to favor mainstream content over, potentially\nmore relevant, but niche items. In this work we explore the intrinsic\nrelationship between music discovery and popularity bias. To mitigate this\nissue we propose a domain-aware, individual fairness-based approach which\naddresses popularity bias in graph neural network (GNNs) based recommender\nsystems. Our approach uses individual fairness to reflect a ground truth\nlistening experience, i.e., if two songs sound similar, this similarity should\nbe reflected in their representations. In doing so, we facilitate meaningful\nmusic discovery that is robust to popularity bias and grounded in the music\ndomain. We apply our BOOST methodology to two discovery based tasks, performing\nrecommendations at both the playlist level and user level. Then, we ground our\nevaluation in the cold start setting, showing that our approach outperforms\nexisting fairness benchmarks in both performance and recommendation of\nlesser-known content. Finally, our analysis explains why our proposed\nmethodology is a novel and promising approach to mitigating popularity bias and\nimproving the discovery of new and niche content in music recommender systems.",
        "translated": ""
    },
    {
        "title": "Efficient and Accurate Tree Detection from 3D Point Clouds through Paid\n  Crowdsourcing",
        "url": "http://arxiv.org/abs/2308.14499v1",
        "pub_date": "2023-08-28",
        "summary": "Accurate tree detection is of growing importance in applications such as\nurban planning, forest inventory, and environmental monitoring. In this\narticle, we present an approach to creating tree maps by annotating them in 3D\npoint clouds. Point cloud representations allow the precise identification of\ntree positions, particularly stem locations, and their heights. Our method\nleverages human computational power through paid crowdsourcing, employing a web\ntool designed to enable even non-experts to effectively tackle the task. The\nprimary focus of this paper is to discuss the web tool's development and\nstrategies to ensure high-quality tree annotations despite encountering noise\nin the crowdsourced data. Following our methodology, we achieve quality\nmeasures surpassing 90% for various challenging test sets of diverse\ncomplexities. We emphasize that our tree map creation process, including\ninitial point cloud collection, can be completed within 1-2 days.",
        "translated": ""
    },
    {
        "title": "Bridging the KB-Text Gap: Leveraging Structured Knowledge-aware\n  Pre-training for KBQA",
        "url": "http://arxiv.org/abs/2308.14436v1",
        "pub_date": "2023-08-28",
        "summary": "Knowledge Base Question Answering (KBQA) aims to answer natural language\nquestions with factual information such as entities and relations in KBs.\nHowever, traditional Pre-trained Language Models (PLMs) are directly\npre-trained on large-scale natural language corpus, which poses challenges for\nthem in understanding and representing complex subgraphs in structured KBs. To\nbridge the gap between texts and structured KBs, we propose a Structured\nKnowledge-aware Pre-training method (SKP). In the pre-training stage, we\nintroduce two novel structured knowledge-aware tasks, guiding the model to\neffectively learn the implicit relationship and better representations of\ncomplex subgraphs. In downstream KBQA task, we further design an efficient\nlinearization strategy and an interval attention mechanism, which assist the\nmodel to better encode complex subgraphs and shield the interference of\nirrelevant subgraphs during reasoning respectively. Detailed experiments and\nanalyses on WebQSP verify the effectiveness of SKP, especially the significant\nimprovement in subgraph retrieval (+4.08% H@10).",
        "translated": ""
    },
    {
        "title": "Can Transformer and GNN Help Each Other?",
        "url": "http://arxiv.org/abs/2308.14355v1",
        "pub_date": "2023-08-28",
        "summary": "Although Transformer has achieved great success in natural language process\nand computer vision, it has difficulty generalizing to medium and large-scale\ngraph data for two important reasons: (i) High complexity. (ii) Failing to\ncapture the complex and entangled structure information. In graph\nrepresentation learning, Graph Neural Networks(GNNs) can fuse the graph\nstructure and node attributes but have limited receptive fields. Therefore, we\nquestion whether can we combine Transformers and GNNs to help each other. In\nthis paper, we propose a new model named TransGNN where the Transformer layer\nand GNN layer are used alternately to improve each other. Specifically, to\nexpand the receptive field and disentangle the information aggregation from\nedges, we propose using Transformer to aggregate more relevant nodes'\ninformation to improve the message passing of GNNs. Besides, to capture the\ngraph structure information, we utilize positional encoding and make use of the\nGNN layer to fuse the structure into node attributes, which improves the\nTransformer in graph data. We also propose to sample the most relevant nodes\nfor Transformer and two efficient samples update strategies to lower the\ncomplexity. At last, we theoretically prove that TransGNN is more expressive\nthan GNNs only with extra linear complexity. The experiments on eight datasets\ncorroborate the effectiveness of TransGNN on node and graph classification\ntasks.",
        "translated": ""
    },
    {
        "title": "Fine-Tuning Llama 2 Large Language Models for Detecting Online Sexual\n  Predatory Chats and Abusive Texts",
        "url": "http://arxiv.org/abs/2308.14683v1",
        "pub_date": "2023-08-28",
        "summary": "Detecting online sexual predatory behaviours and abusive language on social\nmedia platforms has become a critical area of research due to the growing\nconcerns about online safety, especially for vulnerable populations such as\nchildren and adolescents. Researchers have been exploring various techniques\nand approaches to develop effective detection systems that can identify and\nmitigate these risks. Recent development of large language models (LLMs) has\nopened a new opportunity to address this problem more effectively. This paper\nproposes an approach to detection of online sexual predatory chats and abusive\nlanguage using the open-source pretrained Llama 2 7B-parameter model, recently\nreleased by Meta GenAI. We fine-tune the LLM using datasets with different\nsizes, imbalance degrees, and languages (i.e., English, Roman Urdu and Urdu).\nBased on the power of LLMs, our approach is generic and automated without a\nmanual search for a synergy between feature extraction and classifier design\nsteps like conventional methods in this domain. Experimental results show a\nstrong performance of the proposed approach, which performs proficiently and\nconsistently across three distinct datasets with five sets of experiments. This\nstudy's outcomes indicate that the proposed method can be implemented in\nreal-world applications (even with non-English languages) for flagging sexual\npredators, offensive or toxic content, hate speech, and discriminatory language\nin online discussions and comments to maintain respectful internet or digital\ncommunities. Furthermore, it can be employed for solving text classification\nproblems with other potential applications such as sentiment analysis, spam and\nphishing detection, sorting legal documents, fake news detection, language\nidentification, user intent recognition, text-based product categorization,\nmedical record analysis, and resume screening.",
        "translated": ""
    },
    {
        "title": "ANER: Arabic and Arabizi Named Entity Recognition using\n  Transformer-Based Approach",
        "url": "http://arxiv.org/abs/2308.14669v1",
        "pub_date": "2023-08-28",
        "summary": "One of the main tasks of Natural Language Processing (NLP), is Named Entity\nRecognition (NER). It is used in many applications and also can be used as an\nintermediate step for other tasks. We present ANER, a web-based named entity\nrecognizer for the Arabic, and Arabizi languages. The model is built upon BERT,\nwhich is a transformer-based encoder. It can recognize 50 different entity\nclasses, covering various fields. We trained our model on the WikiFANE\\_Gold\ndataset which consists of Wikipedia articles. We achieved an F1 score of\n88.7\\%, which beats CAMeL Tools' F1 score of 83\\% on the ANERcorp dataset,\nwhich has only 4 classes. We also got an F1 score of 77.7\\% on the\nNewsFANE\\_Gold dataset which contains out-of-domain data from News articles.\nThe system is deployed on a user-friendly web interface that accepts users'\ninputs in Arabic, or Arabizi. It allows users to explore the entities in the\ntext by highlighting them. It can also direct users to get information about\nentities through Wikipedia directly. We added the ability to do NER using our\nmodel, or CAMeL Tools' model through our website. ANER is publicly accessible\nat \\url{http://www.aner.online}. We also deployed our model on HuggingFace at\nhttps://huggingface.co/boda/ANER, to allow developers to test and use it.",
        "translated": ""
    },
    {
        "title": "Joint Multiple Intent Detection and Slot Filling with Supervised\n  Contrastive Learning and Self-Distillation",
        "url": "http://arxiv.org/abs/2308.14654v1",
        "pub_date": "2023-08-28",
        "summary": "Multiple intent detection and slot filling are two fundamental and crucial\ntasks in spoken language understanding. Motivated by the fact that the two\ntasks are closely related, joint models that can detect intents and extract\nslots simultaneously are preferred to individual models that perform each task\nindependently. The accuracy of a joint model depends heavily on the ability of\nthe model to transfer information between the two tasks so that the result of\none task can correct the result of the other. In addition, since a joint model\nhas multiple outputs, how to train the model effectively is also challenging.\nIn this paper, we present a method for multiple intent detection and slot\nfilling by addressing these challenges. First, we propose a bidirectional joint\nmodel that explicitly employs intent information to recognize slots and slot\nfeatures to detect intents. Second, we introduce a novel method for training\nthe proposed joint model using supervised contrastive learning and\nself-distillation. Experimental results on two benchmark datasets MixATIS and\nMixSNIPS show that our method outperforms state-of-the-art models in both\ntasks. The results also demonstrate the contributions of both bidirectional\ndesign and the training method to the accuracy improvement. Our source code is\navailable at https://github.com/anhtunguyen98/BiSLU",
        "translated": ""
    },
    {
        "title": "Challenges of GPT-3-based Conversational Agents for Healthca",
        "url": "http://arxiv.org/abs/2308.14641v1",
        "pub_date": "2023-08-28",
        "summary": "The potential to provide patients with faster information access while\nallowing medical specialists to concentrate on critical tasks makes medical\ndomain dialog agents appealing. However, the integration of large-language\nmodels (LLMs) into these agents presents certain limitations that may result in\nserious consequences. This paper investigates the challenges and risks of using\nGPT-3-based models for medical question-answering (MedQA). We perform several\nevaluations contextualized in terms of standard medical principles. We provide\na procedure for manually designing patient queries to stress-test high-risk\nlimitations of LLMs in MedQA systems. Our analysis reveals that LLMs fail to\nrespond adequately to these queries, generating erroneous medical information,\nunsafe recommendations, and content that may be considered offensive.",
        "translated": ""
    },
    {
        "title": "Breaking the Bank with ChatGPT: Few-Shot Text Classification for Finance",
        "url": "http://arxiv.org/abs/2308.14634v1",
        "pub_date": "2023-08-28",
        "summary": "We propose the use of conversational GPT models for easy and quick few-shot\ntext classification in the financial domain using the Banking77 dataset. Our\napproach involves in-context learning with GPT-3.5 and GPT-4, which minimizes\nthe technical expertise required and eliminates the need for expensive GPU\ncomputing while yielding quick and accurate results. Additionally, we fine-tune\nother pre-trained, masked language models with SetFit, a recent contrastive\nlearning technique, to achieve state-of-the-art results both in full-data and\nfew-shot settings. Our findings show that querying GPT-3.5 and GPT-4 can\noutperform fine-tuned, non-generative models even with fewer examples. However,\nsubscription fees associated with these solutions may be considered costly for\nsmall organizations. Lastly, we find that generative models perform better on\nthe given task when shown representative samples selected by a human expert\nrather than when shown random ones. We conclude that a) our proposed methods\noffer a practical solution for few-shot tasks in datasets with limited label\navailability, and b) our state-of-the-art results can inspire future work in\nthe area.",
        "translated": ""
    },
    {
        "title": "AI in the Gray: Exploring Moderation Policies in Dialogic Large Language\n  Models vs. Human Answers in Controversial Topics",
        "url": "http://arxiv.org/abs/2308.14608v1",
        "pub_date": "2023-08-28",
        "summary": "The introduction of ChatGPT and the subsequent improvement of Large Language\nModels (LLMs) have prompted more and more individuals to turn to the use of\nChatBots, both for information and assistance with decision-making. However,\nthe information the user is after is often not formulated by these ChatBots\nobjectively enough to be provided with a definite, globally accepted answer.\n  Controversial topics, such as \"religion\", \"gender identity\", \"freedom of\nspeech\", and \"equality\", among others, can be a source of conflict as partisan\nor biased answers can reinforce preconceived notions or promote disinformation.\nBy exposing ChatGPT to such debatable questions, we aim to understand its level\nof awareness and if existing models are subject to socio-political and/or\neconomic biases. We also aim to explore how AI-generated answers compare to\nhuman ones. For exploring this, we use a dataset of a social media platform\ncreated for the purpose of debating human-generated claims on polemic subjects\namong users, dubbed Kialo.\n  Our results show that while previous versions of ChatGPT have had important\nissues with controversial topics, more recent versions of ChatGPT\n(gpt-3.5-turbo) are no longer manifesting significant explicit biases in\nseveral knowledge areas. In particular, it is well-moderated regarding economic\naspects. However, it still maintains degrees of implicit libertarian leaning\ntoward right-winged ideals which suggest the need for increased moderation from\nthe socio-political point of view. In terms of domain knowledge on\ncontroversial topics, with the exception of the \"Philosophical\" category,\nChatGPT is performing well in keeping up with the collective human level of\nknowledge. Finally, we see that sources of Bing AI have slightly more tendency\nto the center when compared to human answers. All the analyses we make are\ngeneralizable to other types of biases and domains.",
        "translated": ""
    },
    {
        "title": "Spoken Language Intelligence of Large Language Models for Language\n  Learning",
        "url": "http://arxiv.org/abs/2308.14536v1",
        "pub_date": "2023-08-28",
        "summary": "People have long hoped for a conversational system that can assist in\nreal-life situations, and recent progress on large language models (LLMs) is\nbringing this idea closer to reality. While LLMs are often impressive in\nperformance, their efficacy in real-world scenarios that demand expert\nknowledge remains unclear. LLMs are believed to hold the most potential and\nvalue in education, especially in the development of Artificial intelligence\n(AI) based virtual teachers capable of facilitating language learning. Our\nfocus is centered on evaluating the efficacy of LLMs in the realm of education,\nspecifically in the areas of spoken language learning which encompass\nphonetics, phonology, and second language acquisition. We introduce a new\nmultiple-choice question dataset to evaluate the effectiveness of LLMs in the\naforementioned scenarios, including understanding and application of spoken\nlanguage knowledge. In addition, we investigate the influence of various\nprompting techniques such as zero- and few-shot method (prepending the question\nwith question-answer exemplars), chain-of-thought (CoT, think step-by-step),\nin-domain exampler and external tools (Google, Wikipedia). We conducted\nlarge-scale evaluation on popular LLMs (20 distinct models) using these\nmethods. We achieved significant performance improvements compared to the\nzero-shot baseline in the practical questions reasoning (GPT-3.5, 49.1% -&gt;\n63.1%; LLaMA2-70B-Chat, 42.2% -&gt; 48.6%). We found that models of different\nsizes have good understanding of concepts in phonetics, phonology, and second\nlanguage acquisition, but show limitations in reasoning for real-world\nproblems. Additionally, we also explore preliminary findings on conversational\ncommunication.",
        "translated": ""
    },
    {
        "title": "A Multi-Task Semantic Decomposition Framework with Task-specific\n  Pre-training for Few-Shot NER",
        "url": "http://arxiv.org/abs/2308.14533v1",
        "pub_date": "2023-08-28",
        "summary": "The objective of few-shot named entity recognition is to identify named\nentities with limited labeled instances. Previous works have primarily focused\non optimizing the traditional token-wise classification framework, while\nneglecting the exploration of information based on NER data characteristics. To\naddress this issue, we propose a Multi-Task Semantic Decomposition Framework\nvia Joint Task-specific Pre-training (MSDP) for few-shot NER. Drawing\ninspiration from demonstration-based and contrastive learning, we introduce two\nnovel pre-training tasks: Demonstration-based Masked Language Modeling (MLM)\nand Class Contrastive Discrimination. These tasks effectively incorporate\nentity boundary information and enhance entity representation in Pre-trained\nLanguage Models (PLMs). In the downstream main task, we introduce a multi-task\njoint optimization framework with the semantic decomposing method, which\nfacilitates the model to integrate two different semantic information for\nentity classification. Experimental results of two few-shot NER benchmarks\ndemonstrate that MSDP consistently outperforms strong baselines by a large\nmargin. Extensive analyses validate the effectiveness and generalization of\nMSDP.",
        "translated": ""
    },
    {
        "title": "LongBench: A Bilingual, Multitask Benchmark for Long Context\n  Understanding",
        "url": "http://arxiv.org/abs/2308.14508v1",
        "pub_date": "2023-08-28",
        "summary": "Although large language models (LLMs) demonstrate impressive performance for\nmany language tasks, most of them can only handle texts a few thousand tokens\nlong, limiting their applications on longer sequence inputs, such as books,\nreports, and codebases. Recent works have proposed methods to improve LLMs'\nlong context capabilities by extending context windows and more sophisticated\nmemory mechanisms. However, comprehensive benchmarks tailored for evaluating\nlong context understanding are lacking. In this paper, we introduce LongBench,\nthe first bilingual, multi-task benchmark for long context understanding,\nenabling a more rigorous evaluation of long context understanding. LongBench\ncomprises 21 datasets across 6 task categories in both English and Chinese,\nwith an average length of 6,711 words (English) and 13,386 characters\n(Chinese). These tasks cover key long-text application areas including\nsingle-doc QA, multi-doc QA, summarization, few-shot learning, synthetic tasks,\nand code completion. All datasets in LongBench are standardized into a unified\nformat, allowing for effortless automatic evaluation of LLMs. Upon\ncomprehensive evaluation of 8 LLMs on LongBench, we find that: (1) Commercial\nmodel (GPT-3.5-Turbo-16k) outperforms other open-sourced models, but still\nstruggles on longer contexts. (2) Scaled position embedding and fine-tuning on\nlonger sequences lead to substantial improvement on long context understanding.\n(3) Context compression technique such as retrieval brings improvement for\nmodel with weak ability on long contexts, but the performance still lags behind\nmodels that have strong long context understanding capability. The code and\ndatasets are available at https://github.com/THUDM/LongBench.",
        "translated": ""
    },
    {
        "title": "Multimodal Detection of Social Spambots in Twitter using Transformers",
        "url": "http://arxiv.org/abs/2308.14484v1",
        "pub_date": "2023-08-28",
        "summary": "Although not all bots are malicious, the vast majority of them are\nresponsible for spreading misinformation and manipulating the public opinion\nabout several issues, i.e., elections and many more. Therefore, the early\ndetection of social spambots is crucial. Although there have been proposed\nmethods for detecting bots in social media, there are still substantial\nlimitations. For instance, existing research initiatives still extract a large\nnumber of features and train traditional machine learning algorithms or use\nGloVe embeddings and train LSTMs. However, feature extraction is a tedious\nprocedure demanding domain expertise. Also, language models based on\ntransformers have been proved to be better than LSTMs. Other approaches create\nlarge graphs and train graph neural networks requiring in this way many hours\nfor training and access to computational resources. To tackle these\nlimitations, this is the first study employing only the user description field\nand images of three channels denoting the type and content of tweets posted by\nthe users. Firstly, we create digital DNA sequences, transform them to 3d\nimages, and apply pretrained models of the vision domain, including\nEfficientNet, AlexNet, VGG16, etc. Next, we propose a multimodal approach,\nwhere we use TwHIN-BERT for getting the textual representation of the user\ndescription field and employ VGG16 for acquiring the visual representation for\nthe image modality. We propose three different fusion methods, namely\nconcatenation, gated multimodal unit, and crossmodal attention, for fusing the\ndifferent modalities and compare their performances. Extensive experiments\nconducted on the Cresci '17 dataset demonstrate valuable advantages of our\nintroduced approaches over state-of-the-art ones reaching Accuracy up to\n99.98%.",
        "translated": ""
    },
    {
        "title": "Robust Long-Tailed Learning via Label-Aware Bounded CVaR",
        "url": "http://arxiv.org/abs/2308.15405v1",
        "pub_date": "2023-08-29",
        "summary": "Data in the real-world classification problems are always imbalanced or\nlong-tailed, wherein the majority classes have the most of the samples that\ndominate the model training. In such setting, the naive model tends to have\npoor performance on the minority classes. Previously, a variety of loss\nmodifications have been proposed to address the long-tailed leaning problem,\nwhile these methods either treat the samples in the same class\nindiscriminatingly or lack a theoretical guarantee. In this paper, we propose\ntwo novel approaches based on CVaR (Conditional Value at Risk) to improve the\nperformance of long-tailed learning with a solid theoretical ground.\nSpecifically, we firstly introduce a Label-Aware Bounded CVaR (LAB-CVaR) loss\nto overcome the pessimistic result of the original CVaR, and further design the\noptimal weight bounds for LAB-CVaR theoretically. Based on LAB-CVaR, we\nadditionally propose a LAB-CVaR with logit adjustment (LAB-CVaR-logit) loss to\nstabilize the optimization process, where we also offer the theoretical\nsupport. Extensive experiments on real-world datasets with long-tailed label\ndistributions verify the superiority of our proposed methods.",
        "translated": ""
    },
    {
        "title": "A Multi-Perspective Learning to Rank Approach to Support Children's\n  Information Seeking in the Classroom",
        "url": "http://arxiv.org/abs/2308.15265v1",
        "pub_date": "2023-08-29",
        "summary": "We introduce a novel re-ranking model that aims to augment the functionality\nof standard search engines to support classroom search activities for children\n(ages 6 to 11). This model extends the known listwise learning-to-rank\nframework by balancing risk and reward. Doing so enables the model to\nprioritize Web resources of high educational alignment, appropriateness, and\nadequate readability by analyzing the URLs, snippets, and page titles of Web\nresources retrieved by a given mainstream search engine. Experimental results,\nincluding an ablation study and comparisons with existing baselines, showcase\nthe correctness of the proposed model. The outcomes of this work demonstrate\nthe value of considering multiple perspectives inherent to the classroom\nsetting, e.g., educational alignment, readability, and objectionability, when\napplied to the design of algorithms that can better support children's\ninformation discovery.",
        "translated": ""
    },
    {
        "title": "Knowledge-based Multiple Adaptive Spaces Fusion for Recommendation",
        "url": "http://arxiv.org/abs/2308.15244v1",
        "pub_date": "2023-08-29",
        "summary": "Since Knowledge Graphs (KGs) contain rich semantic information, recently\nthere has been an influx of KG-enhanced recommendation methods. Most of\nexisting methods are entirely designed based on euclidean space without\nconsidering curvature. However, recent studies have revealed that a tremendous\ngraph-structured data exhibits highly non-euclidean properties. Motivated by\nthese observations, in this work, we propose a knowledge-based multiple\nadaptive spaces fusion method for recommendation, namely MCKG. Unlike existing\nmethods that solely adopt a specific manifold, we introduce the unified space\nthat is compatible with hyperbolic, euclidean and spherical spaces.\nFurthermore, we fuse the multiple unified spaces in an attention manner to\nobtain the high-quality embeddings for better knowledge propagation. In\naddition, we propose a geometry-aware optimization strategy which enables the\npull and push processes benefited from both hyperbolic and spherical spaces.\nSpecifically, in hyperbolic space, we set smaller margins in the area near to\nthe origin, which is conducive to distinguishing between highly similar\npositive items and negative ones. At the same time, we set larger margins in\nthe area far from the origin to ensure the model has sufficient error\ntolerance. The similar manner also applies to spherical spaces. Extensive\nexperiments on three real-world datasets demonstrate that the MCKG has a\nsignificant improvement over state-of-the-art recommendation methods. Further\nablation experiments verify the importance of multi-space fusion and\ngeometry-aware optimization strategy, justifying the rationality and\neffectiveness of MCKG.",
        "translated": ""
    },
    {
        "title": "Classification-Aware Neural Topic Model Combined With Interpretable\n  Analysis -- For Conflict Classification",
        "url": "http://arxiv.org/abs/2308.15232v1",
        "pub_date": "2023-08-29",
        "summary": "A large number of conflict events are affecting the world all the time. In\norder to analyse such conflict events effectively, this paper presents a\nClassification-Aware Neural Topic Model (CANTM-IA) for Conflict Information\nClassification and Topic Discovery. The model provides a reliable\ninterpretation of classification results and discovered topics by introducing\ninterpretability analysis. At the same time, interpretation is introduced into\nthe model architecture to improve the classification performance of the model\nand to allow interpretation to focus further on the details of the data.\nFinally, the model architecture is optimised to reduce the complexity of the\nmodel.",
        "translated": ""
    },
    {
        "title": "Providing Previously Unseen Users Fair Recommendations Using Variational\n  Autoencoders",
        "url": "http://arxiv.org/abs/2308.15230v1",
        "pub_date": "2023-08-29",
        "summary": "An emerging definition of fairness in machine learning requires that models\nare oblivious to demographic user information, e.g., a user's gender or age\nshould not influence the model. Personalized recommender systems are\nparticularly prone to violating this definition through their explicit user\nfocus and user modelling. Explicit user modelling is also an aspect that makes\nmany recommender systems incapable of providing hitherto unseen users with\nrecommendations. We propose novel approaches for mitigating discrimination in\nVariational Autoencoder-based recommender systems by limiting the encoding of\ndemographic information. The approaches are capable of, and evaluated on,\nproviding users that are not represented in the training data with fair\nrecommendations.",
        "translated": ""
    },
    {
        "title": "ParaGuide: Guided Diffusion Paraphrasers for Plug-and-Play Textual Style\n  Transfer",
        "url": "http://arxiv.org/abs/2308.15459v1",
        "pub_date": "2023-08-29",
        "summary": "Textual style transfer is the task of transforming stylistic properties of\ntext while preserving meaning. Target \"styles\" can be defined in numerous ways,\nranging from single attributes (e.g, formality) to authorship (e.g,\nShakespeare). Previous unsupervised style-transfer approaches generally rely on\nsignificant amounts of labeled data for only a fixed set of styles or require\nlarge language models. In contrast, we introduce a novel diffusion-based\nframework for general-purpose style transfer that can be flexibly adapted to\narbitrary target styles at inference time. Our parameter-efficient approach,\nParaGuide, leverages paraphrase-conditioned diffusion models alongside\ngradient-based guidance from both off-the-shelf classifiers and strong existing\nstyle embedders to transform the style of text while preserving semantic\ninformation. We validate the method on the Enron Email Corpus, with both human\nand automatic evaluations, and find that it outperforms strong baselines on\nformality, sentiment, and even authorship style transfer.",
        "translated": ""
    },
    {
        "title": "When Do Program-of-Thoughts Work for Reasoning?",
        "url": "http://arxiv.org/abs/2308.15452v1",
        "pub_date": "2023-08-29",
        "summary": "The reasoning capabilities of Large Language Models (LLMs) play a pivotal\nrole in the realm of embodied artificial intelligence. Although there are\neffective methods like program-of-thought prompting for LLMs which uses\nprogramming language to tackle complex reasoning tasks, the specific impact of\ncode data on the improvement of reasoning capabilities remains under-explored.\nTo address this gap, we propose complexity-impacted reasoning score (CIRS),\nwhich combines structural and logical attributes, to measure the correlation\nbetween code and reasoning abilities. Specifically, we use the abstract syntax\ntree to encode the structural information and calculate logical complexity by\nconsidering the difficulty and the cyclomatic complexity. Through an empirical\nanalysis, we find not all code data of complexity can be learned or understood\nby LLMs. Optimal level of complexity is critical to the improvement of\nreasoning abilities by program-aided prompting. Then we design an\nauto-synthesizing and stratifying algorithm, and apply it to instruction\ngeneration for mathematical reasoning and code data filtering for code\ngeneration tasks. Extensive results demonstrates the effectiveness of our\nproposed approach. Code will be integrated into the EasyInstruct framework at\nhttps://github.com/zjunlp/EasyInstruct.",
        "translated": ""
    },
    {
        "title": "Vulgar Remarks Detection in Chittagonian Dialect of Bangla",
        "url": "http://arxiv.org/abs/2308.15448v1",
        "pub_date": "2023-08-29",
        "summary": "The negative effects of online bullying and harassment are increasing with\nInternet popularity, especially in social media. One solution is using natural\nlanguage processing (NLP) and machine learning (ML) methods for the automatic\ndetection of harmful remarks, but these methods are limited in low-resource\nlanguages like the Chittagonian dialect of Bangla.This study focuses on\ndetecting vulgar remarks in social media using supervised ML and deep learning\nalgorithms.Logistic Regression achieved promising accuracy (0.91) while simple\nRNN with Word2vec and fastTex had lower accuracy (0.84-0.90), highlighting the\nissue that NN algorithms require more data.",
        "translated": ""
    },
    {
        "title": "Characterizing Learning Curves During Language Model Pre-Training:\n  Learning, Forgetting, and Stability",
        "url": "http://arxiv.org/abs/2308.15419v1",
        "pub_date": "2023-08-29",
        "summary": "How do language models learn to make predictions during pre-training? To\nstudy this question, we extract learning curves from five autoregressive\nEnglish language model pre-training runs, for 1M tokens in context. We observe\nthat the language models generate short repetitive phrases before learning to\ngenerate longer and more coherent text. We quantify the final surprisal,\nwithin-run variability, age of acquisition, forgettability, and cross-run\nvariability of learning curves for individual tokens in context. More frequent\ntokens reach lower final surprisals, exhibit less variability within and across\npre-training runs, are learned earlier, and are less likely to be \"forgotten\"\nduring pre-training. Higher n-gram probabilities further accentuate these\neffects. Independent of the target token, shorter and more frequent contexts\ncorrelate with marginally more stable and quickly acquired predictions. Effects\nof part-of-speech are also small, although nouns tend to be acquired later and\nless stably than verbs, adverbs, and adjectives. Our work contributes to a\nbetter understanding of language model pre-training dynamics and informs the\ndeployment of stable language models in practice.",
        "translated": ""
    },
    {
        "title": "Rethinking Machine Ethics -- Can LLMs Perform Moral Reasoning through\n  the Lens of Moral Theories?",
        "url": "http://arxiv.org/abs/2308.15399v1",
        "pub_date": "2023-08-29",
        "summary": "Making moral judgments is an essential step toward developing ethical AI\nsystems. Prevalent approaches are mostly implemented in a bottom-up manner,\nwhich uses a large set of annotated data to train models based on crowd-sourced\nopinions about morality. These approaches have been criticized for potentially\novergeneralizing a limited group of annotators' moral stances and lacking\nexplainability. In contrast, top-down approaches make moral judgments grounded\nin a set of principles. However, it remains conceptual due to the incapability\nof previous language models and the unsolved debate among moral principles. In\nthis study, we propose a flexible framework to steer Large Language Models\n(LLMs) to perform moral reasoning with well-established moral theories from\ninterdisciplinary research. The theory-guided top-down framework can\nincorporate various moral theories. Our experiments demonstrate the\neffectiveness of the proposed framework on datasets derived from moral\ntheories. Furthermore, we show the alignment between different moral theories\nand existing morality datasets. Our analysis exhibits the potentials and flaws\nin existing resources (models and datasets) in developing explainable moral\njudgment-making systems.",
        "translated": ""
    },
    {
        "title": "Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation",
        "url": "http://arxiv.org/abs/2308.15363v1",
        "pub_date": "2023-08-29",
        "summary": "Large language models (LLMs) have emerged as a new paradigm for Text-to-SQL\ntask. However, the absence of a systematical benchmark inhibits the development\nof designing effective, efficient and economic LLM-based Text-to-SQL solutions.\nTo address this challenge, in this paper, we first conduct a systematical and\nextensive comparison over existing prompt engineering methods, including\nquestion representation, example selection and example organization, and with\nthese experimental results, we elaborates their pros and cons. Based on these\nfindings, we propose a new integrated solution, named DAIL-SQL, which refreshes\nthe Spider leaderboard with 86.6% execution accuracy and sets a new bar.\nTowards an efficient and economic LLM-based Text-to-SQL solution, we emphasize\nthe token efficiency in prompt engineering and compare the prior studies under\nthis metric. Additionally, we investigate open-source LLMs in in-context\nlearning, and further enhance their performance with task-specific supervised\nfine-tuning. Our explorations highlight open-source LLMs' potential in\nText-to-SQL, as well as the advantages and disadvantages of the task-specific\nsupervised fine-tuning. We hope that our work provides a deeper understanding\nof Text-to-SQL with LLMs, and inspire further investigations and broad\napplications.",
        "translated": ""
    },
    {
        "title": "Historical patterns of rice farming explain modern-day language use in\n  China and Japan more than modernization and urbanization",
        "url": "http://arxiv.org/abs/2308.15352v1",
        "pub_date": "2023-08-29",
        "summary": "We used natural language processing to analyze a billion words to study\ncultural differences on Weibo, one of China's largest social media platforms.\nWe compared predictions from two common explanations about cultural differences\nin China (economic development and urban-rural differences) against the\nless-obvious legacy of rice versus wheat farming. Rice farmers had to\ncoordinate shared irrigation networks and exchange labor to cope with higher\nlabor requirements. In contrast, wheat relied on rainfall and required half as\nmuch labor. We test whether this legacy made southern China more\ninterdependent. Across all word categories, rice explained twice as much\nvariance as economic development and urbanization. Rice areas used more words\nreflecting tight social ties, holistic thought, and a cautious, prevention\norientation. We then used Twitter data comparing prefectures in Japan, which\nlargely replicated the results from China. This provides crucial evidence of\nthe rice theory in a different nation, language, and platform.",
        "translated": ""
    },
    {
        "title": "A Framework for Responsible Development of Automated Student Feedback\n  with Generative AI",
        "url": "http://arxiv.org/abs/2308.15334v1",
        "pub_date": "2023-08-29",
        "summary": "Providing rich feedback to students is essential for supporting student\nlearning. Recent advances in generative AI, particularly within large language\nmodelling (LLM), provide the opportunity to deliver repeatable, scalable and\ninstant automatically generated feedback to students, making abundant a\npreviously scarce and expensive learning resource. Such an approach is feasible\nfrom a technical perspective due to these recent advances in Artificial\nIntelligence (AI) and Natural Language Processing (NLP); while the potential\nupside is a strong motivator, doing so introduces a range of potential ethical\nissues that must be considered as we apply these technologies. The\nattractiveness of AI systems is that they can effectively automate the most\nmundane tasks; but this risks introducing a \"tyranny of the majority\", where\nthe needs of minorities in the long tail are overlooked because they are\ndifficult to automate.\n  Developing machine learning models that can generate valuable and authentic\nfeedback requires the input of human domain experts. The choices we make in\ncapturing this expertise -- whose, which, when, and how -- will have\nsignificant consequences for the nature of the resulting feedback. How we\nmaintain our models will affect how that feedback remains relevant given\ntemporal changes in context, theory, and prior learning profiles of student\ncohorts. These questions are important from an ethical perspective; but they\nare also important from an operational perspective. Unless they can be\nanswered, our AI generated systems will lack the trust necessary for them to be\nuseful features in the contemporary learning environment.\n  This article will outline the frontiers of automated feedback, identify the\nethical issues involved in the provision of automated feedback and present a\nframework to assist academics to develop such systems responsibly.",
        "translated": ""
    },
    {
        "title": "TaskLAMA: Probing the Complex Task Understanding of Language Models",
        "url": "http://arxiv.org/abs/2308.15299v1",
        "pub_date": "2023-08-29",
        "summary": "Structured Complex Task Decomposition (SCTD) is the problem of breaking down\na complex real-world task (such as planning a wedding) into a directed acyclic\ngraph over individual steps that contribute to achieving the task, with edges\nspecifying temporal dependencies between them. SCTD is an important component\nof assistive planning tools, and a challenge for commonsense reasoning systems.\nWe probe how accurately SCTD can be done with the knowledge extracted from\nLarge Language Models (LLMs). We introduce a high-quality human-annotated\ndataset for this problem and novel metrics to fairly assess performance of LLMs\nagainst several baselines. Our experiments reveal that LLMs are able to\ndecompose complex tasks into individual steps effectively, with a relative\nimprovement of 15% to 280% over the best baseline. We also propose a number of\napproaches to further improve their performance, with a relative improvement of\n7% to 37% over the base model. However, we find that LLMs still struggle to\npredict pairwise temporal dependencies, which reveals a gap in their\nunderstanding of complex tasks.",
        "translated": ""
    },
    {
        "title": "KGConv, a Conversational Corpus grounded in Wikidata",
        "url": "http://arxiv.org/abs/2308.15298v1",
        "pub_date": "2023-08-29",
        "summary": "We present KGConv, a large, conversational corpus of 71k conversations where\neach question-answer pair is grounded in a Wikidata fact. Conversations contain\non average 8.6 questions and for each Wikidata fact, we provide multiple\nvariants (12 on average) of the corresponding question using templates, human\nannotations, hand-crafted rules and a question rewriting neural model. We\nprovide baselines for the task of Knowledge-Based, Conversational Question\nGeneration. KGConv can further be used for other generation and analysis tasks\nsuch as single-turn question generation from Wikidata triples, question\nrewriting, question answering from conversation or from knowledge graphs and\nquiz generation.",
        "translated": ""
    },
    {
        "title": "Adaptive Multi-Modalities Fusion in Sequential Recommendation Systems",
        "url": "http://arxiv.org/abs/2308.15980v1",
        "pub_date": "2023-08-30",
        "summary": "In sequential recommendation, multi-modal information (e.g., text or image)\ncan provide a more comprehensive view of an item's profile. The optimal stage\n(early or late) to fuse modality features into item representations is still\ndebated. We propose a graph-based approach (named MMSR) to fuse modality\nfeatures in an adaptive order, enabling each modality to prioritize either its\ninherent sequential nature or its interplay with other modalities. MMSR\nrepresents each user's history as a graph, where the modality features of each\nitem in a user's history sequence are denoted by cross-linked nodes. The edges\nbetween homogeneous nodes represent intra-modality sequential relationships,\nand the ones between heterogeneous nodes represent inter-modality\ninterdependence relationships. During graph propagation, MMSR incorporates dual\nattention, differentiating homogeneous and heterogeneous neighbors. To\nadaptively assign nodes with distinct fusion orders, MMSR allows each node's\nrepresentation to be asynchronously updated through an update gate. In\nscenarios where modalities exhibit stronger sequential relationships, the\nupdate gate prioritizes updates among homogeneous nodes. Conversely, when the\ninterdependent relationships between modalities are more pronounced, the update\ngate prioritizes updates among heterogeneous nodes. Consequently, MMSR\nestablishes a fusion order that spans a spectrum from early to late modality\nfusion. In experiments across six datasets, MMSR consistently outperforms\nstate-of-the-art models, and our graph propagation methods surpass other graph\nneural networks. Additionally, MMSR naturally manages missing modalities.",
        "translated": ""
    },
    {
        "title": "Denoising Attention for Query-aware User Modeling in Personalized Search",
        "url": "http://arxiv.org/abs/2308.15968v1",
        "pub_date": "2023-08-30",
        "summary": "The personalization of search results has gained increasing attention in the\npast few years, thanks to the development of Neural Networks-based approaches\nfor Information Retrieval and the importance of personalization in many search\nscenarios. Recent works have proposed to build user models at query time by\nleveraging the Attention mechanism, which allows weighing the contribution of\nthe user-related information w.r.t. the current query. This approach allows\ntaking into account the diversity of the user's interests by giving more\nimportance to those related to the current search performed by the user.\n  In this paper, we first discuss some shortcomings of the standard Attention\nformulation when employed for personalization. In particular, we focus on\nissues related to its normalization mechanism and its inability to entirely\nfilter out noisy user-related information. Then, we introduce the Denoising\nAttention mechanism: an Attention variant that directly tackles the above\nshortcomings by adopting a robust normalization scheme and introducing a\nfiltering mechanism. The reported experimental evaluation shows the benefits of\nthe proposed approach over other Attention-based variants.",
        "translated": ""
    },
    {
        "title": "DRGame: Diversified Recommendation for Multi-category Video Games with\n  Balanced Implicit Preferences",
        "url": "http://arxiv.org/abs/2308.15823v1",
        "pub_date": "2023-08-30",
        "summary": "The growing popularity of subscription services in video game consumption has\nemphasized the importance of offering diversified recommendations. Providing\nusers with a diverse range of games is essential for ensuring continued\nengagement and fostering long-term subscriptions. However, existing\nrecommendation models face challenges in effectively handling highly imbalanced\nimplicit feedback in gaming interactions. Additionally, they struggle to take\ninto account the distinctive characteristics of multiple categories and the\nlatent user interests associated with these categories. In response to these\nchallenges, we propose a novel framework, named DRGame, to obtain diversified\nrecommendation. It is centered on multi-category video games, consisting of two\n{components}: Balance-driven Implicit Preferences Learning for data\npre-processing and Clustering-based Diversified Recommendation {Module} for\nfinal prediction. The first module aims to achieve a balanced representation of\nimplicit feedback in game time, thereby discovering a comprehensive view of\nplayer interests across different categories. The second module adopts\ncategory-aware representation learning to cluster and select players and games\nbased on balanced implicit preferences, and then employs asymmetric neighbor\naggregation to achieve diversified recommendations. Experimental results on a\nreal-world dataset demonstrate the superiority of our proposed method over\nexisting approaches in terms of game diversity recommendations.",
        "translated": ""
    },
    {
        "title": "Knowledge-grounded Natural Language Recommendation Explanation",
        "url": "http://arxiv.org/abs/2308.15813v1",
        "pub_date": "2023-08-30",
        "summary": "Explanations accompanied by a recommendation can assist users in\nunderstanding the decision made by recommendation systems, which in turn\nincreases a user's confidence and trust in the system. Recently, research has\nfocused on generating natural language explanations in a human-readable format.\nThus far, the proposed approaches leverage item reviews written by users, which\nare often subjective, sparse in language, and unable to account for new items\nthat have not been purchased or reviewed before. Instead, we aim to generate\nfact-grounded recommendation explanations that are objectively described with\nitem features while implicitly considering a user's preferences, based on the\nuser's purchase history. To achieve this, we propose a knowledge graph (KG)\napproach to natural language explainable recommendation. Our approach draws on\nuser-item features through a novel collaborative filtering-based KG\nrepresentation to produce fact-grounded, personalized explanations, while\njointly learning user-item representations for recommendation scoring.\nExperimental results show that our approach consistently outperforms previous\nstate-of-the-art models on natural language explainable recommendation.",
        "translated": ""
    },
    {
        "title": "Fragment and Integrate Network (FIN): A Novel Spatial-Temporal Modeling\n  Based on Long Sequential Behavior for Online Food Ordering Click-Through Rate\n  Prediction",
        "url": "http://arxiv.org/abs/2308.15703v1",
        "pub_date": "2023-08-30",
        "summary": "Spatial-temporal information has been proven to be of great significance for\nclick-through rate prediction tasks in online Location-Based Services (LBS),\nespecially in mainstream food ordering platforms such as DoorDash, Uber Eats,\nMeituan, and Ele.me. Modeling user spatial-temporal preferences with sequential\nbehavior data has become a hot topic in recommendation systems and online\nadvertising. However, most of existing methods either lack the representation\nof rich spatial-temporal information or only handle user behaviors with limited\nlength, e.g. 100. In this paper, we tackle these problems by designing a new\nspatial-temporal modeling paradigm named Fragment and Integrate Network (FIN).\nFIN consists of two networks: (i) Fragment Network (FN) extracts Multiple\nSub-Sequences (MSS) from lifelong sequential behavior data, and captures the\nspecific spatial-temporal representation by modeling each MSS respectively.\nHere both a simplified attention and a complicated attention are adopted to\nbalance the performance gain and resource consumption. (ii) Integrate Network\n(IN) builds a new integrated sequence by utilizing spatial-temporal interaction\non MSS and captures the comprehensive spatial-temporal representation by\nmodeling the integrated sequence with a complicated attention. Both public\ndatasets and production datasets have demonstrated the accuracy and scalability\nof FIN. Since 2022, FIN has been fully deployed in the recommendation\nadvertising system of Ele.me, one of the most popular online food ordering\nplatforms in China, obtaining 5.7% improvement on Click-Through Rate (CTR) and\n7.3% increase on Revenue Per Mille (RPM).",
        "translated": ""
    },
    {
        "title": "Quantifying Uncertainty in Answers from any Language Model via Intrinsic\n  and Extrinsic Confidence Assessment",
        "url": "http://arxiv.org/abs/2308.16175v1",
        "pub_date": "2023-08-30",
        "summary": "We introduce BSDetector, a method for detecting bad and speculative answers\nfrom a pretrained Large Language Model by estimating a numeric confidence score\nfor any output it generated. Our uncertainty quantification technique works for\nany LLM accessible only via a black-box API, and combines intrinsic and\nextrinsic assessments of confidence into a single trustworthiness estimate for\nany LLM response to a given prompt. Our method is extremely general and can\napplied to all of the best LLMs available today (whose training data remains\nunknown). By expending a bit of extra computation, users of any LLM API can now\nget the same response as they would ordinarily, as well as a confidence\nestimate that caution when not to trust this response. Experiments on both\nclosed and open-form Question-Answer benchmarks reveal that BSDetector more\naccurately identifies incorrect LLM responses than alternative uncertainty\nestimation procedures (for both GPT-3 and ChatGPT). By sampling multiple\nresponses from the LLM and considering the one with the highest confidence\nscore, we can additionally obtain more accurate responses from the same LLM,\nwithout any extra training steps.",
        "translated": ""
    },
    {
        "title": "Jais and Jais-chat: Arabic-Centric Foundation and Instruction-Tuned Open\n  Generative Large Language Models",
        "url": "http://arxiv.org/abs/2308.16149v1",
        "pub_date": "2023-08-30",
        "summary": "We introduce Jais and Jais-chat, new state-of-the-art Arabic-centric\nfoundation and instruction-tuned open generative large language models (LLMs).\nThe models are based on the GPT-3 decoder-only architecture and are pretrained\non a mixture of Arabic and English texts, including source code in various\nprogramming languages. With 13 billion parameters, they demonstrate better\nknowledge and reasoning capabilities in Arabic than any existing open Arabic\nand multilingual models by a sizable margin, based on extensive evaluation.\nMoreover, the models are competitive in English compared to English-centric\nopen models of similar size, despite being trained on much less English data.\nWe provide a detailed description of the training, the tuning, the safety\nalignment, and the evaluation of the models. We release two open versions of\nthe model -- the foundation Jais model, and an instruction-tuned Jais-chat\nvariant -- with the aim of promoting research on Arabic LLMs. Available at\nhttps://huggingface.co/inception-mbzuai/jais-13b-chat",
        "translated": ""
    },
    {
        "title": "LM-Infinite: Simple On-the-Fly Length Generalization for Large Language\n  Models",
        "url": "http://arxiv.org/abs/2308.16137v1",
        "pub_date": "2023-08-30",
        "summary": "In recent years, there have been remarkable advancements in the performance\nof Transformer-based Large Language Models (LLMs) across various domains. As\nthese LLMs are deployed for increasingly complex tasks, they often face the\nneeds to conduct longer reasoning processes or understanding larger contexts.\nIn these situations, the length generalization failure of LLMs on long\nsequences become more prominent. Most pre-training schemes truncate training\nsequences to a fixed length (such as 2048 for LLaMa). LLMs often struggle to\ngenerate fluent texts, let alone carry out downstream tasks, after longer\ncontexts, even with relative positional encoding which is designed to cope with\nthis problem. Common solutions such as finetuning on longer corpora often\ninvolves daunting hardware and time costs and requires careful training process\ndesign. To more efficiently leverage the generation capacity of existing LLMs,\nwe theoretically and empirically investigate the main out-of-distribution (OOD)\nfactors contributing to this problem. Inspired by this diagnosis, we propose a\nsimple yet effective solution for on-the-fly length generalization,\nLM-Infinite, which involves only a $\\Lambda$-shaped attention mask and a\ndistance limit while requiring no parameter updates or learning. We find it\napplicable to a variety of LLMs using relative-position encoding methods.\nLM-Infinite is computational efficient with $O(n)$ time and space, and\ndemonstrates consistent fluency and generation quality to as long as 32k tokens\non ArXiv and OpenWebText2 datasets, with 2.72x decoding speedup. On downstream\ntask such as passkey retrieval, it continues to work on inputs much longer than\ntraining lengths where vanilla models fail immediately.",
        "translated": ""
    },
    {
        "title": "Response: Emergent analogical reasoning in large language models",
        "url": "http://arxiv.org/abs/2308.16118v1",
        "pub_date": "2023-08-30",
        "summary": "In their recent Nature Human Behaviour paper, \"Emergent analogical reasoning\nin large language models,\" (Webb, Holyoak, and Lu, 2023) the authors argue that\n\"large language models such as GPT-3 have acquired an emergent ability to find\nzero-shot solutions to a broad range of analogy problems.\" In this response, we\nprovide counterexamples of the letter string analogies. In our tests, GPT-3\nfails to solve even the easiest variants of the problems presented in the\noriginal paper. Zero-shot reasoning is an extraordinary claim that requires\nextraordinary evidence. We do not see that evidence in our experiments. To\nstrengthen claims of humanlike reasoning such as zero-shot reasoning, it is\nimportant that the field develop approaches that rule out data memorization.",
        "translated": ""
    },
    {
        "title": "Grandma Karl is 27 years old -- research agenda for pseudonymization of\n  research data",
        "url": "http://arxiv.org/abs/2308.16109v1",
        "pub_date": "2023-08-30",
        "summary": "Accessibility of research data is critical for advances in many research\nfields, but textual data often cannot be shared due to the personal and\nsensitive information which it contains, e.g names or political opinions.\nGeneral Data Protection Regulation (GDPR) suggests pseudonymization as a\nsolution to secure open access to research data, but we need to learn more\nabout pseudonymization as an approach before adopting it for manipulation of\nresearch data. This paper outlines a research agenda within pseudonymization,\nnamely need of studies into the effects of pseudonymization on unstructured\ndata in relation to e.g. readability and language assessment, as well as the\neffectiveness of pseudonymization as a way of protecting writer identity, while\nalso exploring different ways of developing context-sensitive algorithms for\ndetection, labelling and replacement of personal information in unstructured\ndata. The recently granted project on pseudonymization Grandma Karl is 27 years\nold addresses exactly those challenges.",
        "translated": ""
    },
    {
        "title": "Impact of Visual Context on Noisy Multimodal NMT: An Empirical Study for\n  English to Indian Languages",
        "url": "http://arxiv.org/abs/2308.16075v1",
        "pub_date": "2023-08-30",
        "summary": "The study investigates the effectiveness of utilizing multimodal information\nin Neural Machine Translation (NMT). While prior research focused on using\nmultimodal data in low-resource scenarios, this study examines how image\nfeatures impact translation when added to a large-scale, pre-trained unimodal\nNMT system. Surprisingly, the study finds that images might be redundant in\nthis context. Additionally, the research introduces synthetic noise to assess\nwhether images help the model deal with textual noise. Multimodal models\nslightly outperform text-only models in noisy settings, even with random\nimages. The study's experiments translate from English to Hindi, Bengali, and\nMalayalam, outperforming state-of-the-art benchmarks significantly.\nInterestingly, the effect of visual context varies with source text noise: no\nvisual context works best for non-noisy translations, cropped image features\nare optimal for low noise, and full image features work better in high-noise\nscenarios. This sheds light on the role of visual context, especially in noisy\nsettings, opening up a new research direction for Noisy Neural Machine\nTranslation in multimodal setups. The research emphasizes the importance of\ncombining visual and textual information for improved translation in various\nenvironments.",
        "translated": ""
    },
    {
        "title": "Conti Inc.: Understanding the Internal Discussions of a large\n  Ransomware-as-a-Service Operator with Machine Learning",
        "url": "http://arxiv.org/abs/2308.16061v1",
        "pub_date": "2023-08-30",
        "summary": "Ransomware-as-a-service (RaaS) is increasing the scale and complexity of\nransomware attacks. Understanding the internal operations behind RaaS has been\na challenge due to the illegality of such activities. The recent chat leak of\nthe Conti RaaS operator, one of the most infamous ransomware operators on the\ninternational scene, offers a key opportunity to better understand the inner\nworkings of such organizations. This paper analyzes the main topic discussions\nin the Conti chat leak using machine learning techniques such as Natural\nLanguage Processing (NLP) and Latent Dirichlet Allocation (LDA), as well as\nvisualization strategies. Five discussion topics are found: 1) Business, 2)\nTechnical, 3) Internal tasking/Management, 4) Malware, and 5) Customer\nService/Problem Solving. Moreover, the distribution of topics among Conti\nmembers shows that only 4% of individuals have specialized discussions while\nalmost all individuals (96%) are all-rounders, meaning that their discussions\nrevolve around the five topics. The results also indicate that a significant\nproportion of Conti discussions are non-tech related. This study thus\nhighlights that running such large RaaS operations requires a workforce skilled\nbeyond technical abilities, with individuals involved in various tasks, from\nmanagement to customer service or problem solving. The discussion topics also\nshow that the organization behind the Conti RaaS oper5086933ator shares\nsimilarities with a large firm. We conclude that, although RaaS represents an\nexample of specialization in the cybercrime industry, only a few members are\nspecialized in one topic, while the rest runs and coordinates the RaaS\noperation.",
        "translated": ""
    },
    {
        "title": "Text-to-OverpassQL: A Natural Language Interface for Complex Geodata\n  Querying of OpenStreetMap",
        "url": "http://arxiv.org/abs/2308.16060v1",
        "pub_date": "2023-08-30",
        "summary": "We present Text-to-OverpassQL, a task designed to facilitate a natural\nlanguage interface for querying geodata from OpenStreetMap (OSM). The Overpass\nQuery Language (OverpassQL) allows users to formulate complex database queries\nand is widely adopted in the OSM ecosystem. Generating Overpass queries from\nnatural language input serves multiple use-cases. It enables novice users to\nutilize OverpassQL without prior knowledge, assists experienced users with\ncrafting advanced queries, and enables tool-augmented large language models to\naccess information stored in the OSM database. In order to assess the\nperformance of current sequence generation models on this task, we propose\nOverpassNL, a dataset of 8,352 queries with corresponding natural language\ninputs. We further introduce task specific evaluation metrics and ground the\nevaluation of the Text-to-OverpassQL task by executing the queries against the\nOSM database. We establish strong baselines by finetuning sequence-to-sequence\nmodels and adapting large language models with in-context examples. The\ndetailed evaluation reveals strengths and weaknesses of the considered learning\nstrategies, laying the foundations for further research into the\nText-to-OverpassQL task.",
        "translated": ""
    },
    {
        "title": "AsyncET: Asynchronous Learning for Knowledge Graph Entity Typing with\n  Auxiliary Relations",
        "url": "http://arxiv.org/abs/2308.16055v1",
        "pub_date": "2023-08-30",
        "summary": "Knowledge graph entity typing (KGET) is a task to predict the missing entity\ntypes in knowledge graphs (KG). Previously, KG embedding (KGE) methods tried to\nsolve the KGET task by introducing an auxiliary relation, 'hasType', to model\nthe relationship between entities and their types. However, a single auxiliary\nrelation has limited expressiveness for diverse entity-type patterns. We\nimprove the expressiveness of KGE methods by introducing multiple auxiliary\nrelations in this work. Similar entity types are grouped to reduce the number\nof auxiliary relations and improve their capability to model entity-type\npatterns with different granularities. With the presence of multiple auxiliary\nrelations, we propose a method adopting an Asynchronous learning scheme for\nEntity Typing, named AsyncET, which updates the entity and type embeddings\nalternatively to keep the learned entity embedding up-to-date and informative\nfor entity type prediction. Experiments are conducted on two commonly used KGET\ndatasets to show that the performance of KGE methods on the KGET task can be\nsubstantially improved by the proposed multiple auxiliary relations and\nasynchronous embedding learning. Furthermore, our method has a significant\nadvantage over state-of-the-art methods in model sizes and time complexity.",
        "translated": ""
    },
    {
        "title": "FPTQ: Fine-grained Post-Training Quantization for Large Language Models",
        "url": "http://arxiv.org/abs/2308.15987v1",
        "pub_date": "2023-08-30",
        "summary": "In the era of large-scale language models, the substantial parameter size\nposes significant challenges for deployment. Being a prevalent compression\ntechnique, quantization has emerged as the mainstream practice to tackle this\nissue, which is mainly centered on two recipes W8A8 and W4A16 (i.e. weights and\nactivations in such bit widths). In this study, we propose a novel W4A8\npost-training quantization method for the available open-sourced LLMs, which\ncombines the advantages of both two recipes. Therefore, we can leverage the\nbenefit in the I/O utilization of 4-bit weight quantization and the\nacceleration due to 8-bit matrix computation. Nevertheless, the W4A8 faces\nnotorious performance degradation. As a remedy, we involve layerwise activation\nquantization strategies which feature a novel logarithmic equalization for most\nintractable layers, and we combine them with fine-grained weight quantization.\nWithout whistles and bells, we eliminate the necessity for further fine-tuning\nand obtain the state-of-the-art W4A8 quantized performance on BLOOM, LLaMA, and\nLLaMA-2 on standard benchmarks. We confirm that the W4A8 quantization is\nachievable for the deployment of large language models, fostering their\nwide-spreading real-world applications.",
        "translated": ""
    },
    {
        "title": "Co-evolving Vector Quantization for ID-based Recommendation",
        "url": "http://arxiv.org/abs/2308.16761v1",
        "pub_date": "2023-08-31",
        "summary": "Category information plays a crucial role in enhancing the quality and\npersonalization of recommendations. Nevertheless, the availability of item\ncategory information is not consistently present, particularly in the context\nof ID-based recommendations. In this work, we propose an alternative approach\nto automatically learn and generate entity (i.e., user and item) categorical\ninformation at different levels of granularity, specifically for ID-based\nrecommendation. Specifically, we devise a co-evolving vector quantization\nframework, namely COVE, which enables the simultaneous learning and refinement\nof code representation and entity embedding in an end-to-end manner, starting\nfrom the randomly initialized states. With its high adaptability, COVE can be\neasily integrated into existing recommendation models. We validate the\neffectiveness of COVE on various recommendation tasks including list\ncompletion, collaborative filtering, and click-through rate prediction, across\ndifferent recommendation models. We will publish the code and data for other\nresearchers to reproduce our work.",
        "translated": ""
    },
    {
        "title": "Context Aware Query Rewriting for Text Rankers using LLM",
        "url": "http://arxiv.org/abs/2308.16753v1",
        "pub_date": "2023-08-31",
        "summary": "Query rewriting refers to an established family of approaches that are\napplied to underspecified and ambiguous queries to overcome the vocabulary\nmismatch problem in document ranking. Queries are typically rewritten during\nquery processing time for better query modelling for the downstream ranker.\nWith the advent of large-language models (LLMs), there have been initial\ninvestigations into using generative approaches to generate pseudo documents to\ntackle this inherent vocabulary gap. In this work, we analyze the utility of\nLLMs for improved query rewriting for text ranking tasks. We find that there\nare two inherent limitations of using LLMs as query re-writers -- concept drift\nwhen using only queries as prompts and large inference costs during query\nprocessing. We adopt a simple, yet surprisingly effective, approach called\ncontext aware query rewriting (CAR) to leverage the benefits of LLMs for query\nunderstanding. Firstly, we rewrite ambiguous training queries by context-aware\nprompting of LLMs, where we use only relevant documents as context.Unlike\nexisting approaches, we use LLM-based query rewriting only during the training\nphase. Eventually, a ranker is fine-tuned on the rewritten queries instead of\nthe original queries during training. In our extensive experiments, we find\nthat fine-tuning a ranker using re-written queries offers a significant\nimprovement of up to 33% on the passage ranking task and up to 28% on the\ndocument ranking task when compared to the baseline performance of using\noriginal queries.",
        "translated": ""
    },
    {
        "title": "Concentrating on the Impact: Consequence-based Explanations in\n  Recommender Systems",
        "url": "http://arxiv.org/abs/2308.16708v1",
        "pub_date": "2023-08-31",
        "summary": "Recommender systems assist users in decision-making, where the presentation\nof recommended items and their explanations are critical factors for enhancing\nthe overall user experience. Although various methods for generating\nexplanations have been proposed, there is still room for improvement,\nparticularly for users who lack expertise in a specific item domain. In this\nstudy, we introduce the novel concept of \\textit{consequence-based\nexplanations}, a type of explanation that emphasizes the individual impact of\nconsuming a recommended item on the user, which makes the effect of following\nrecommendations clearer. We conducted an online user study to examine our\nassumption about the appreciation of consequence-based explanations and their\nimpacts on different explanation aims in recommender systems. Our findings\nhighlight the importance of consequence-based explanations, which were\nwell-received by users and effectively improved user satisfaction in\nrecommender systems. These results provide valuable insights for designing\nengaging explanations that can enhance the overall user experience in\ndecision-making.",
        "translated": ""
    },
    {
        "title": "Towards Long-Tailed Recognition for Graph Classification via\n  Collaborative Experts",
        "url": "http://arxiv.org/abs/2308.16609v1",
        "pub_date": "2023-08-31",
        "summary": "Graph classification, aiming at learning the graph-level representations for\neffective class assignments, has received outstanding achievements, which\nheavily relies on high-quality datasets that have balanced class distribution.\nIn fact, most real-world graph data naturally presents a long-tailed form,\nwhere the head classes occupy much more samples than the tail classes, it thus\nis essential to study the graph-level classification over long-tailed data\nwhile still remaining largely unexplored. However, most existing long-tailed\nlearning methods in visions fail to jointly optimize the representation\nlearning and classifier training, as well as neglect the mining of the\nhard-to-classify classes. Directly applying existing methods to graphs may lead\nto sub-optimal performance, since the model trained on graphs would be more\nsensitive to the long-tailed distribution due to the complex topological\ncharacteristics. Hence, in this paper, we propose a novel long-tailed\ngraph-level classification framework via Collaborative Multi-expert Learning\n(CoMe) to tackle the problem. To equilibrate the contributions of head and tail\nclasses, we first develop balanced contrastive learning from the view of\nrepresentation learning, and then design an individual-expert classifier\ntraining based on hard class mining. In addition, we execute gated fusion and\ndisentangled knowledge distillation among the multiple experts to promote the\ncollaboration in a multi-expert framework. Comprehensive experiments are\nperformed on seven widely-used benchmark datasets to demonstrate the\nsuperiority of our method CoMe over state-of-the-art baselines.",
        "translated": ""
    },
    {
        "title": "Recommender AI Agent: Integrating Large Language Models for Interactive\n  Recommendations",
        "url": "http://arxiv.org/abs/2308.16505v1",
        "pub_date": "2023-08-31",
        "summary": "Recommender models excel at providing domain-specific item recommendations by\nleveraging extensive user behavior data. Despite their ability to act as\nlightweight domain experts, they struggle to perform versatile tasks such as\nproviding explanations and engaging in conversations. On the other hand, large\nlanguage models (LLMs) represent a significant step towards artificial general\nintelligence, showcasing remarkable capabilities in instruction comprehension,\ncommonsense reasoning, and human interaction. However, LLMs lack the knowledge\nof domain-specific item catalogs and behavioral patterns, particularly in areas\nthat diverge from general world knowledge, such as online e-commerce.\nFinetuning LLMs for each domain is neither economic nor efficient.\n  In this paper, we bridge the gap between recommender models and LLMs,\ncombining their respective strengths to create a versatile and interactive\nrecommender system. We introduce an efficient framework called RecAgent, which\nemploys LLMs as the brain and recommender models as tools. We first outline a\nminimal set of essential tools required to transform LLMs into RecAgent. We\nthen propose an efficient workflow within RecAgent for task execution,\nincorporating key components such as a memory bus, dynamic\ndemonstration-augmented task planning, and reflection. RecAgent enables\ntraditional recommender systems, such as those ID-based matrix factorization\nmodels, to become interactive systems with a natural language interface through\nthe integration of LLMs. Experimental results on several public datasets show\nthat RecAgent achieves satisfying performance as a conversational recommender\nsystem, outperforming general-purpose LLMs.",
        "translated": ""
    },
    {
        "title": "PointLLM: Empowering Large Language Models to Understand Point Clouds",
        "url": "http://arxiv.org/abs/2308.16911v1",
        "pub_date": "2023-08-31",
        "summary": "The unprecedented advancements in Large Language Models (LLMs) have created a\nprofound impact on natural language processing but are yet to fully embrace the\nrealm of 3D understanding. This paper introduces PointLLM, a preliminary effort\nto fill this gap, thereby enabling LLMs to understand point clouds and offering\na new avenue beyond 2D visual data. PointLLM processes colored object point\nclouds with human instructions and generates contextually appropriate\nresponses, illustrating its grasp of point clouds and common sense.\nSpecifically, it leverages a point cloud encoder with a powerful LLM to\neffectively fuse geometric, appearance, and linguistic information. We collect\na novel dataset comprising 660K simple and 70K complex point-text instruction\npairs to enable a two-stage training strategy: initially aligning latent spaces\nand subsequently instruction-tuning the unified model. To rigorously evaluate\nour model's perceptual abilities and its generalization capabilities, we\nestablish two benchmarks: Generative 3D Object Classification and 3D Object\nCaptioning, assessed through three different methods, including human\nevaluation, GPT-4/ChatGPT evaluation, and traditional metrics. Experiment\nresults show that PointLLM demonstrates superior performance over existing 2D\nbaselines. Remarkably, in human-evaluated object captioning tasks, PointLLM\noutperforms human annotators in over 50% of the samples. Codes, datasets, and\nbenchmarks are available at https://github.com/OpenRobotLab/PointLLM .",
        "translated": ""
    },
    {
        "title": "Transformers as Support Vector Machines",
        "url": "http://arxiv.org/abs/2308.16898v1",
        "pub_date": "2023-08-31",
        "summary": "Since its inception in \"Attention Is All You Need\", transformer architecture\nhas led to revolutionary advancements in NLP. The attention layer within the\ntransformer admits a sequence of input tokens $X$ and makes them interact\nthrough pairwise similarities computed as softmax$(XQK^\\top X^\\top)$, where\n$(K,Q)$ are the trainable key-query parameters. In this work, we establish a\nformal equivalence between the optimization geometry of self-attention and a\nhard-margin SVM problem that separates optimal input tokens from non-optimal\ntokens using linear constraints on the outer-products of token pairs. This\nformalism allows us to characterize the implicit bias of 1-layer transformers\noptimized with gradient descent: (1) Optimizing the attention layer with\nvanishing regularization, parameterized by $(K,Q)$, converges in direction to\nan SVM solution minimizing the nuclear norm of the combined parameter\n$W=KQ^\\top$. Instead, directly parameterizing by $W$ minimizes a Frobenius norm\nobjective. We characterize this convergence, highlighting that it can occur\ntoward locally-optimal directions rather than global ones. (2) Complementing\nthis, we prove the local/global directional convergence of gradient descent\nunder suitable geometric conditions. Importantly, we show that\nover-parameterization catalyzes global convergence by ensuring the feasibility\nof the SVM problem and by guaranteeing a benign optimization landscape devoid\nof stationary points. (3) While our theory applies primarily to linear\nprediction heads, we propose a more general SVM equivalence that predicts the\nimplicit bias with nonlinear heads. Our findings are applicable to arbitrary\ndatasets and their validity is verified via experiments. We also introduce\nseveral open problems and research directions. We believe these findings\ninspire the interpretation of transformers as a hierarchy of SVMs that\nseparates and selects optimal tokens.",
        "translated": ""
    },
    {
        "title": "TouchStone: Evaluating Vision-Language Models by Language Models",
        "url": "http://arxiv.org/abs/2308.16890v1",
        "pub_date": "2023-08-31",
        "summary": "Large vision-language models (LVLMs) have recently witnessed rapid\nadvancements, exhibiting a remarkable capacity for perceiving, understanding,\nand processing visual information by connecting visual receptor with large\nlanguage models (LLMs). However, current assessments mainly focus on\nrecognizing and reasoning abilities, lacking direct evaluation of\nconversational skills and neglecting visual storytelling abilities. In this\npaper, we propose an evaluation method that uses strong LLMs as judges to\ncomprehensively evaluate the various abilities of LVLMs. Firstly, we construct\na comprehensive visual dialogue dataset TouchStone, consisting of open-world\nimages and questions, covering five major categories of abilities and 27\nsubtasks. This dataset not only covers fundamental recognition and\ncomprehension but also extends to literary creation. Secondly, by integrating\ndetailed image annotations we effectively transform the multimodal input\ncontent into a form understandable by LLMs. This enables us to employ advanced\nLLMs for directly evaluating the quality of the multimodal dialogue without\nrequiring human intervention. Through validation, we demonstrate that powerful\nLVLMs, such as GPT-4, can effectively score dialogue quality by leveraging\ntheir textual capabilities alone, aligning with human preferences. We hope our\nwork can serve as a touchstone for LVLMs' evaluation and pave the way for\nbuilding stronger LVLMs. The evaluation code is available at\nhttps://github.com/OFA-Sys/TouchStone.",
        "translated": ""
    },
    {
        "title": "The Belebele Benchmark: a Parallel Reading Comprehension Dataset in 122\n  Language Variants",
        "url": "http://arxiv.org/abs/2308.16884v1",
        "pub_date": "2023-08-31",
        "summary": "We present Belebele, a multiple-choice machine reading comprehension (MRC)\ndataset spanning 122 language variants. Significantly expanding the language\ncoverage of natural language understanding (NLU) benchmarks, this dataset\nenables the evaluation of text models in high-, medium-, and low-resource\nlanguages. Each question is based on a short passage from the Flores-200\ndataset and has four multiple-choice answers. The questions were carefully\ncurated to discriminate between models with different levels of general\nlanguage comprehension. The English dataset on its own proves difficult enough\nto challenge state-of-the-art language models. Being fully parallel, this\ndataset enables direct comparison of model performance across all languages. We\nuse this dataset to evaluate the capabilities of multilingual masked language\nmodels (MLMs) and large language models (LLMs). We present extensive results\nand find that despite significant cross-lingual transfer in English-centric\nLLMs, much smaller MLMs pretrained on balanced multilingual data still\nunderstand far more languages. We also observe that larger vocabulary size and\nconscious vocabulary construction correlate with better performance on\nlow-resource languages. Overall, Belebele opens up new avenues for evaluating\nand analyzing the multilingual capabilities of NLP systems.",
        "translated": ""
    },
    {
        "title": "The Gender-GAP Pipeline: A Gender-Aware Polyglot Pipeline for Gender\n  Characterisation in 55 Languages",
        "url": "http://arxiv.org/abs/2308.16871v1",
        "pub_date": "2023-08-31",
        "summary": "Gender biases in language generation systems are challenging to mitigate. One\npossible source for these biases is gender representation disparities in the\ntraining and evaluation data. Despite recent progress in documenting this\nproblem and many attempts at mitigating it, we still lack shared methodology\nand tooling to report gender representation in large datasets. Such\nquantitative reporting will enable further mitigation, e.g., via data\naugmentation. This paper describes the Gender-GAP Pipeline (for Gender-Aware\nPolyglot Pipeline), an automatic pipeline to characterize gender representation\nin large-scale datasets for 55 languages. The pipeline uses a multilingual\nlexicon of gendered person-nouns to quantify the gender representation in text.\nWe showcase it to report gender representation in WMT training data and\ndevelopment data for the News task, confirming that current data is skewed\ntowards masculine representation. Having unbalanced datasets may indirectly\noptimize our systems towards outperforming one gender over the others. We\nsuggest introducing our gender quantification pipeline in current datasets and,\nideally, modifying them toward a balanced representation.",
        "translated": ""
    },
    {
        "title": "Can Programming Languages Boost Each Other via Instruction Tuning?",
        "url": "http://arxiv.org/abs/2308.16824v1",
        "pub_date": "2023-08-31",
        "summary": "When human programmers have mastered a programming language, it would be\neasier when they learn a new programming language. In this report, we focus on\nexploring whether programming languages can boost each other during the\ninstruction fine-tuning phase of code large language models. We conduct\nextensive experiments of 8 popular programming languages (Python, JavaScript,\nTypeScript, C, C++, Java, Go, HTML) on StarCoder. Results demonstrate that\nprogramming languages can significantly improve each other. For example,\nCodeM-Python 15B trained on Python is able to increase Java by an absolute\n17.95% pass@1 on HumanEval-X. More surprisingly, we found that CodeM-HTML 7B\ntrained on the HTML corpus can improve Java by an absolute 15.24% pass@1. Our\ntraining data is released at https://github.com/NL2Code/CodeM.",
        "translated": ""
    },
    {
        "title": "Simple LLM Prompting is State-of-the-Art for Robust and Multilingual\n  Dialogue Evaluation",
        "url": "http://arxiv.org/abs/2308.16797v1",
        "pub_date": "2023-08-31",
        "summary": "Despite significant research effort in the development of automatic dialogue\nevaluation metrics, little thought is given to evaluating dialogues other than\nin English. At the same time, ensuring metrics are invariant to semantically\nsimilar responses is also an overlooked topic. In order to achieve the desired\nproperties of robustness and multilinguality for dialogue evaluation metrics,\nwe propose a novel framework that takes advantage of the strengths of current\nevaluation models with the newly-established paradigm of prompting Large\nLanguage Models (LLMs). Empirical results show our framework achieves state of\nthe art results in terms of mean Spearman correlation scores across several\nbenchmarks and ranks first place on both the Robust and Multilingual tasks of\nthe DSTC11 Track 4 \"Automatic Evaluation Metrics for Open-Domain Dialogue\nSystems\", proving the evaluation capabilities of prompted LLMs.",
        "translated": ""
    },
    {
        "title": "Towards Multilingual Automatic Dialogue Evaluation",
        "url": "http://arxiv.org/abs/2308.16795v1",
        "pub_date": "2023-08-31",
        "summary": "The main limiting factor in the development of robust multilingual dialogue\nevaluation metrics is the lack of multilingual data and the limited\navailability of open sourced multilingual dialogue systems. In this work, we\npropose a workaround for this lack of data by leveraging a strong multilingual\npretrained LLM and augmenting existing English dialogue data using Machine\nTranslation. We empirically show that the naive approach of finetuning a\npretrained multilingual encoder model with translated data is insufficient to\noutperform the strong baseline of finetuning a multilingual model with only\nsource data. Instead, the best approach consists in the careful curation of\ntranslated data using MT Quality Estimation metrics, excluding low quality\ntranslations that hinder its performance.",
        "translated": ""
    },
    {
        "title": "Enhancing PLM Performance on Labour Market Tasks via Instruction-based\n  Finetuning and Prompt-tuning with Rules",
        "url": "http://arxiv.org/abs/2308.16770v1",
        "pub_date": "2023-08-31",
        "summary": "The increased digitization of the labour market has given researchers,\neducators, and companies the means to analyze and better understand the labour\nmarket. However, labour market resources, although available in high volumes,\ntend to be unstructured, and as such, research towards methodologies for the\nidentification, linking, and extraction of entities becomes more and more\nimportant. Against the backdrop of this quest for better labour market\nrepresentations, resource constraints and the unavailability of large-scale\nannotated data cause a reliance on human domain experts. We demonstrate the\neffectiveness of prompt-based tuning of pre-trained language models (PLM) in\nlabour market specific applications. Our results indicate that cost-efficient\nmethods such as PTR and instruction tuning without exemplars can significantly\nincrease the performance of PLMs on downstream labour market applications\nwithout introducing additional model layers, manual annotations, and data\naugmentation.",
        "translated": ""
    },
    {
        "title": "Ladder-of-Thought: Using Knowledge as Steps to Elevate Stance Detection",
        "url": "http://arxiv.org/abs/2308.16763v1",
        "pub_date": "2023-08-31",
        "summary": "Chain-of-Thought Prompting (CoT) reinforces the reasoning capabilities of\nLarge Language Models (LLMs) through the generation of intermediate rationales.\nHowever, these enhancements predominantly benefit large-scale models, leaving\nsmall LMs without significant performance improvements when directly applying\nCoT. Despite the advanced reasoning capabilities of LLMs, CoT relies primarily\non their pre-trained internal knowledge. The external knowledge that is\npreviously unknown to the model remains unexploited. This omission becomes\npronounced in tasks such as stance detection, where the external background\nknowledge plays a pivotal role. Additionally, the large-scale architecture of\nLLMs inevitably present efficiency challenges during deployment. To address\nthese challenges, we introduce the Ladder-of-Thought (LoT) for stance\ndetection. Grounded in a dual-phase Cascaded Optimization framework, LoT\ndirects the model to incorporate high-quality external knowledge, enhancing the\nintermediate rationales it generates. These bolstered rationales subsequently\nserve as the foundation for more precise predictions - akin to how a ladder\nfacilitates reaching elevated goals. LoT achieves a balance between efficiency\nand accuracy, making it an adaptable and efficient framework for stance\ndetection. Our empirical evaluations underscore LoT's effectiveness, marking a\n16% improvement over ChatGPT and a 10% enhancement compared to ChatGPT with\nCoT.",
        "translated": ""
    },
    {
        "title": "NeMig -- A Bilingual News Collection and Knowledge Graph about Migration",
        "url": "http://arxiv.org/abs/2309.00550v1",
        "pub_date": "2023-09-01",
        "summary": "News recommendation plays a critical role in shaping the public's worldviews\nthrough the way in which it filters and disseminates information about\ndifferent topics. Given the crucial impact that media plays in opinion\nformation, especially for sensitive topics, understanding the effects of\npersonalized recommendation beyond accuracy has become essential in today's\ndigital society. In this work, we present NeMig, a bilingual news collection on\nthe topic of migration, and corresponding rich user data. In comparison to\nexisting news recommendation datasets, which comprise a large variety of\nmonolingual news, NeMig covers articles on a single controversial topic,\npublished in both Germany and the US. We annotate the sentiment polarization of\nthe articles and the political leanings of the media outlets, in addition to\nextracting subtopics and named entities disambiguated through Wikidata. These\nfeatures can be used to analyze the effects of algorithmic news curation beyond\naccuracy-based performance, such as recommender biases and the creation of\nfilter bubbles. We construct domain-specific knowledge graphs from the news\ntext and metadata, thus encoding knowledge-level connections between articles.\nImportantly, while existing datasets include only click behavior, we collect\nuser socio-demographic and political information in addition to explicit click\nfeedback. We demonstrate the utility of NeMig through experiments on the tasks\nof news recommenders benchmarking, analysis of biases in recommenders, and news\ntrends analysis. NeMig aims to provide a useful resource for the news\nrecommendation community and to foster interdisciplinary research into the\nmultidimensional effects of algorithmic news curation.",
        "translated": ""
    },
    {
        "title": "General and Practical Tuning Method for Off-the-Shelf Graph-Based Index:\n  SISAP Indexing Challenge Report by Team UTokyo",
        "url": "http://arxiv.org/abs/2309.00472v1",
        "pub_date": "2023-09-01",
        "summary": "Despite the efficacy of graph-based algorithms for Approximate Nearest\nNeighbor (ANN) searches, the optimal tuning of such systems remains unclear.\nThis study introduces a method to tune the performance of off-the-shelf\ngraph-based indexes, focusing on the dimension of vectors, database size, and\nentry points of graph traversal. We utilize a black-box optimization algorithm\nto perform integrated tuning to meet the required levels of recall and Queries\nPer Second (QPS). We applied our approach to Task A of the SISAP 2023 Indexing\nChallenge and got second place in the 10M and 30M tracks. It improves\nperformance substantially compared to brute force methods. This research offers\na universally applicable tuning method for graph-based indexes, extending\nbeyond the specific conditions of the competition to broader uses.",
        "translated": ""
    },
    {
        "title": "Explainable Active Learning for Preference Elicitation",
        "url": "http://arxiv.org/abs/2309.00356v1",
        "pub_date": "2023-09-01",
        "summary": "Gaining insights into the preferences of new users and subsequently\npersonalizing recommendations necessitate managing user interactions\nintelligently, namely, posing pertinent questions to elicit valuable\ninformation effectively. In this study, our focus is on a specific scenario of\nthe cold-start problem, where the recommendation system lacks adequate user\npresence or access to other users' data is restricted, obstructing employing\nuser profiling methods utilizing existing data in the system. We employ Active\nLearning (AL) to solve the addressed problem with the objective of maximizing\ninformation acquisition with minimal user effort. AL operates for selecting\ninformative data from a large unlabeled set to inquire an oracle to label them\nand eventually updating a machine learning (ML) model. We operate AL in an\nintegrated process of unsupervised, semi-supervised, and supervised ML within\nan explanatory preference elicitation process. It harvests user feedback (given\nfor the system's explanations on the presented items) over informative samples\nto update an underlying ML model estimating user preferences. The designed user\ninteraction facilitates personalizing the system by incorporating user feedback\ninto the ML model and also enhances user trust by refining the system's\nexplanations on recommendations. We implement the proposed preference\nelicitation methodology for food recommendation. We conducted human experiments\nto assess its efficacy in the short term and also experimented with several AL\nstrategies over synthetic user profiles that we created for two food datasets,\naiming for long-term performance analysis. The experimental results demonstrate\nthe efficiency of the proposed preference elicitation with limited user-labeled\ndata while also enhancing user trust through accurate explanations.",
        "translated": ""
    },
    {
        "title": "Towards Contrastive Learning in Music Video Domain",
        "url": "http://arxiv.org/abs/2309.00347v1",
        "pub_date": "2023-09-01",
        "summary": "Contrastive learning is a powerful way of learning multimodal representations\nacross various domains such as image-caption retrieval and audio-visual\nrepresentation learning. In this work, we investigate if these findings\ngeneralize to the domain of music videos. Specifically, we create a dual\nen-coder for the audio and video modalities and train it using a bidirectional\ncontrastive loss. For the experiments, we use an industry dataset containing\n550 000 music videos as well as the public Million Song Dataset, and evaluate\nthe quality of learned representations on the downstream tasks of music tagging\nand genre classification. Our results indicate that pre-trained networks\nwithout contrastive fine-tuning outperform our contrastive learning approach\nwhen evaluated on both tasks. To gain a better understanding of the reasons\ncontrastive learning was not successful for music videos, we perform a\nqualitative analysis of the learned representations, revealing why contrastive\nlearning might have difficulties uniting embeddings from two modalities. Based\non these findings, we outline possible directions for future work. To\nfacilitate the reproducibility of our results, we share our code and the\npre-trained model.",
        "translated": ""
    },
    {
        "title": "Point-Bind &amp; Point-LLM: Aligning Point Cloud with Multi-modality for 3D\n  Understanding, Generation, and Instruction Following",
        "url": "http://arxiv.org/abs/2309.00615v1",
        "pub_date": "2023-09-01",
        "summary": "We introduce Point-Bind, a 3D multi-modality model aligning point clouds with\n2D image, language, audio, and video. Guided by ImageBind, we construct a joint\nembedding space between 3D and multi-modalities, enabling many promising\napplications, e.g., any-to-3D generation, 3D embedding arithmetic, and 3D\nopen-world understanding. On top of this, we further present Point-LLM, the\nfirst 3D large language model (LLM) following 3D multi-modal instructions. By\nparameter-efficient fine-tuning techniques, Point-LLM injects the semantics of\nPoint-Bind into pre-trained LLMs, e.g., LLaMA, which requires no 3D instruction\ndata, but exhibits superior 3D and multi-modal question-answering capacity. We\nhope our work may cast a light on the community for extending 3D point clouds\nto multi-modality applications. Code is available at\nhttps://github.com/ZiyuGuo99/Point-Bind_Point-LLM.",
        "translated": ""
    },
    {
        "title": "Baseline Defenses for Adversarial Attacks Against Aligned Language\n  Models",
        "url": "http://arxiv.org/abs/2309.00614v1",
        "pub_date": "2023-09-01",
        "summary": "As Large Language Models quickly become ubiquitous, their security\nvulnerabilities are critical to understand. Recent work shows that text\noptimizers can produce jailbreaking prompts that bypass moderation and\nalignment. Drawing from the rich body of work on adversarial machine learning,\nwe approach these attacks with three questions: What threat models are\npractically useful in this domain? How do baseline defense techniques perform\nin this new domain? How does LLM security differ from computer vision?\n  We evaluate several baseline defense strategies against leading adversarial\nattacks on LLMs, discussing the various settings in which each is feasible and\neffective. Particularly, we look at three types of defenses: detection\n(perplexity based), input preprocessing (paraphrase and retokenization), and\nadversarial training. We discuss white-box and gray-box settings and discuss\nthe robustness-performance trade-off for each of the defenses considered.\nSurprisingly, we find much more success with filtering and preprocessing than\nwe would expect from other domains, such as vision, providing a first\nindication that the relative strengths of these defenses may be weighed\ndifferently in these domains.",
        "translated": ""
    },
    {
        "title": "CPSP: Learning Speech Concepts From Phoneme Supervision",
        "url": "http://arxiv.org/abs/2309.00424v1",
        "pub_date": "2023-09-01",
        "summary": "For fine-grained generation and recognition tasks such as\nminimally-supervised text-to-speech (TTS), voice conversion (VC), and automatic\nspeech recognition (ASR), the intermediate representation extracted from speech\nshould contain information that is between text coding and acoustic coding. The\nlinguistic content is salient, while the paralinguistic information such as\nspeaker identity and acoustic details should be removed. However, existing\nmethods for extracting fine-grained intermediate representations from speech\nsuffer from issues of excessive redundancy and dimension explosion.\nAdditionally, existing contrastive learning methods in the audio field focus on\nextracting global descriptive information for downstream audio classification\ntasks, making them unsuitable for TTS, VC, and ASR tasks. To address these\nissues, we propose a method named Contrastive Phoneme-Speech Pretraining\n(CPSP), which uses three encoders, one decoder, and contrastive learning to\nbring phoneme and speech into a joint multimodal space, learning how to connect\nphoneme and speech at the frame level. The CPSP model is trained on 210k speech\nand phoneme text pairs, achieving minimally-supervised TTS, VC, and ASR. The\nproposed CPSP method offers a promising solution for fine-grained generation\nand recognition downstream tasks in speech processing. We provide a website\nwith audio samples.",
        "translated": ""
    },
    {
        "title": "Satisfiability Checking of Multi-Variable TPTL with Unilateral Intervals\n  Is PSPACE-Complete",
        "url": "http://arxiv.org/abs/2309.00386v1",
        "pub_date": "2023-09-01",
        "summary": "We investigate the decidability of the ${0,\\infty}$ fragment of Timed\nPropositional Temporal Logic (TPTL). We show that the satisfiability checking\nof TPTL$^{0,\\infty}$ is PSPACE-complete. Moreover, even its 1-variable fragment\n(1-TPTL$^{0,\\infty}$) is strictly more expressive than Metric Interval Temporal\nLogic (MITL) for which satisfiability checking is EXPSPACE complete. Hence, we\nhave a strictly more expressive logic with computationally easier\nsatisfiability checking. To the best of our knowledge, TPTL$^{0,\\infty}$ is the\nfirst multi-variable fragment of TPTL for which satisfiability checking is\ndecidable without imposing any bounds/restrictions on the timed words (e.g.\nbounded variability, bounded time, etc.). The membership in PSPACE is obtained\nby a reduction to the emptiness checking problem for a new \"non-punctual\"\nsubclass of Alternating Timed Automata with multiple clocks called Unilateral\nVery Weak Alternating Timed Automata (VWATA$^{0,\\infty}$) which we prove to be\nin PSPACE. We show this by constructing a simulation equivalent\nnon-deterministic timed automata whose number of clocks is polynomial in the\nsize of the given VWATA$^{0,\\infty}$.",
        "translated": ""
    },
    {
        "title": "BatchPrompt: Accomplish more with less",
        "url": "http://arxiv.org/abs/2309.00384v1",
        "pub_date": "2023-09-01",
        "summary": "Many LLMs are trained to perform zero-shot or few-shot inference using\ninstruction-based prompts. Crafting prompts for these LLMs typically requires\nthe user to provide a detailed task description, examples of context and\ncompletion, and single example of context for inference. This regular prompt\nbaseline is referred to as SinglePrompt in this paper. However, for NLP tasks\nwhere each data point for inference is not necessarily lengthy, the token count\nfor instructions and few-shot examples in the prompt may be considerably larger\nthan that of the data point, resulting in lower token-resource utilization\ncompared with encoder-based models like fine-tuned BERT. This cost-efficiency\nissue, affecting inference speed and compute budget, counteracts the many\nbenefits LLMs have to offer. This paper aims to alleviate the preceding problem\nby batching multiple data points into a single prompt, a prompting strategy we\nrefer to as BatchPrompt. This strategy increases the density of data points,\nwhich in turn leads to improved token utilization. Applying BatchPrompt\nnaively, however, is very challenging due to significant performance\ndegradation, as observed in our experiments. We also noticed varying inference\noutcomes for the same data point appearing in different positions within a\nprompt. To address the quality issue while remain high token-resource\nutilization, we introduce Batch Permutation and Ensembling for BatchPrompt, a\nsimple way that recovers labeling quality through majority votes from data\npoints placed in varying positions in a batch at the price of more token usage.\nTo counterbalance the additional token usage caused by the voting process, we\nfurther propose Self-reflection-guided EArly Stopping, which can terminate the\nvoting process early for data points the LLM confidently handles.",
        "translated": ""
    },
    {
        "title": "Long-Term Memorability On Advertisements",
        "url": "http://arxiv.org/abs/2309.00378v1",
        "pub_date": "2023-09-01",
        "summary": "Marketers spend billions of dollars on advertisements but to what end? At the\npurchase time, if customers cannot recognize a brand for which they saw an ad,\nthe money spent on the ad is essentially wasted. Despite its importance in\nmarketing, until now, there has been no study on the memorability of ads in the\nML literature. Most studies have been conducted on short-term recall (&lt;5 mins)\non specific content types like object and action videos. On the other hand, the\nadvertising industry only cares about long-term memorability (a few hours or\nlonger), and advertisements are almost always highly multimodal, depicting a\nstory through its different modalities (text, images, and videos). With this\nmotivation, we conduct the first large scale memorability study consisting of\n1203 participants and 2205 ads covering 276 brands. Running statistical tests\nover different participant subpopulations and ad-types, we find many\ninteresting insights into what makes an ad memorable - both content and human\nfactors. For example, we find that brands which use commercials with fast\nmoving scenes are more memorable than those with slower scenes (p=8e-10) and\nthat people who use ad-blockers remember lower number of ads than those who\ndon't (p=5e-3). Further, with the motivation of simulating the memorability of\nmarketing materials for a particular audience, ultimately helping create one,\nwe present a novel model, Sharingan, trained to leverage real-world knowledge\nof LLMs and visual knowledge of visual encoders to predict the memorability of\na content. We test our model on all the prominent memorability datasets in\nliterature (both images and videos) and achieve state of the art across all of\nthem. We conduct extensive ablation studies across memory types, modality,\nbrand, and architectural choices to find insights into what drives memory.",
        "translated": ""
    },
    {
        "title": "When Do Discourse Markers Affect Computational Sentence Understanding?",
        "url": "http://arxiv.org/abs/2309.00368v1",
        "pub_date": "2023-09-01",
        "summary": "The capabilities and use cases of automatic natural language processing (NLP)\nhave grown significantly over the last few years. While much work has been\ndevoted to understanding how humans deal with discourse connectives, this\nphenomenon is understudied in computational systems. Therefore, it is important\nto put NLP models under the microscope and examine whether they can adequately\ncomprehend, process, and reason within the complexity of natural language. In\nthis chapter, we introduce the main mechanisms behind automatic sentence\nprocessing systems step by step and then focus on evaluating discourse\nconnective processing. We assess nine popular systems in their ability to\nunderstand English discourse connectives and analyze how context and language\nunderstanding tasks affect their connective comprehension. The results show\nthat NLP systems do not process all discourse connectives equally well and that\nthe computational processing complexity of different connective kinds is not\nalways consistently in line with the presumed complexity order found in human\nprocessing. In addition, while humans are more inclined to be influenced during\nthe reading procedure but not necessarily in the final comprehension\nperformance, discourse connectives have a significant impact on the final\naccuracy of NLP systems. The richer knowledge of connectives a system learns,\nthe more negative effect inappropriate connectives have on it. This suggests\nthat the correct explicitation of discourse connectives is important for\ncomputational natural language processing.",
        "translated": ""
    },
    {
        "title": "Large Content And Behavior Models To Understand, Simulate, And Optimize\n  Content And Behavior",
        "url": "http://arxiv.org/abs/2309.00359v1",
        "pub_date": "2023-09-01",
        "summary": "Shannon, in his seminal paper introducing information theory, divided the\ncommunication into three levels: technical, semantic, and effectivenss. While\nthe technical level is concerned with accurate reconstruction of transmitted\nsymbols, the semantic and effectiveness levels deal with the inferred meaning\nand its effect on the receiver. Thanks to telecommunications, the first level\nproblem has produced great advances like the internet. Large Language Models\n(LLMs) make some progress towards the second goal, but the third level still\nremains largely untouched. The third problem deals with predicting and\noptimizing communication for desired receiver behavior. LLMs, while showing\nwide generalization capabilities across a wide range of tasks, are unable to\nsolve for this. One reason for the underperformance could be a lack of\n\"behavior tokens\" in LLMs' training corpora. Behavior tokens define receiver\nbehavior over a communication, such as shares, likes, clicks, purchases,\nretweets, etc. While preprocessing data for LLM training, behavior tokens are\noften removed from the corpora as noise. Therefore, in this paper, we make some\ninitial progress towards reintroducing behavior tokens in LLM training. The\ntrained models, other than showing similar performance to LLMs on content\nunderstanding tasks, show generalization capabilities on behavior simulation,\ncontent simulation, behavior understanding, and behavior domain adaptation.\nUsing a wide range of tasks on two corpora, we show results on all these\ncapabilities. We call these models Large Content and Behavior Models (LCBMs).\nFurther, to spur more research on LCBMs, we release our new Content Behavior\nCorpus (CBC), a repository containing communicator, message, and corresponding\nreceiver behavior.",
        "translated": ""
    },
    {
        "title": "Comparative Topic Modeling for Determinants of Divergent Report Results\n  Applied to Macular Degeneration Studies",
        "url": "http://arxiv.org/abs/2309.00312v1",
        "pub_date": "2023-09-01",
        "summary": "Topic modeling and text mining are subsets of Natural Language Processing\nwith relevance for conducting meta-analysis (MA) and systematic review (SR).\nFor evidence synthesis, the above NLP methods are conventionally used for\ntopic-specific literature searches or extracting values from reports to\nautomate essential phases of SR and MA. Instead, this work proposes a\ncomparative topic modeling approach to analyze reports of contradictory results\non the same general research question. Specifically, the objective is to find\ntopics exhibiting distinct associations with significant results for an outcome\nof interest by ranking them according to their proportional occurrence and\nconsistency of distribution across reports of significant results. The proposed\nmethod was tested on broad-scope studies addressing whether supplemental\nnutritional compounds significantly benefit macular degeneration (MD). Eight\ncompounds were identified as having a particular association with reports of\nsignificant results for benefitting MD. Six of these were further supported in\nterms of effectiveness upon conducting a follow-up literature search for\nvalidation (omega-3 fatty acids, copper, zeaxanthin, lutein, zinc, and\nnitrates). The two not supported by the follow-up literature search (niacin and\nmolybdenum) also had the lowest scores under the proposed methods ranking\nsystem, suggesting that the proposed method's score for a given topic is a\nviable proxy for its degree of association with the outcome of interest. These\nresults underpin the proposed methods potential to add specificity in\nunderstanding effects from broad-scope reports, elucidate topics of interest\nfor future research, and guide evidence synthesis in a systematic and scalable\nway.",
        "translated": ""
    },
    {
        "title": "Enhancing the vocal range of single-speaker singing voice synthesis with\n  melody-unsupervised pre-training",
        "url": "http://arxiv.org/abs/2309.00284v1",
        "pub_date": "2023-09-01",
        "summary": "The single-speaker singing voice synthesis (SVS) usually underperforms at\npitch values that are out of the singer's vocal range or associated with\nlimited training samples. Based on our previous work, this work proposes a\nmelody-unsupervised multi-speaker pre-training method conducted on a\nmulti-singer dataset to enhance the vocal range of the single-speaker, while\nnot degrading the timbre similarity. This pre-training method can be deployed\nto a large-scale multi-singer dataset, which only contains audio-and-lyrics\npairs without phonemic timing information and pitch annotation. Specifically,\nin the pre-training step, we design a phoneme predictor to produce the\nframe-level phoneme probability vectors as the phonemic timing information and\na speaker encoder to model the timbre variations of different singers, and\ndirectly estimate the frame-level f0 values from the audio to provide the pitch\ninformation. These pre-trained model parameters are delivered into the\nfine-tuning step as prior knowledge to enhance the single speaker's vocal\nrange. Moreover, this work also contributes to improving the sound quality and\nrhythm naturalness of the synthesized singing voices. It is the first to\nintroduce a differentiable duration regulator to improve the rhythm naturalness\nof the synthesized voice, and a bi-directional flow model to improve the sound\nquality. Experimental results verify that the proposed SVS system outperforms\nthe baseline on both sound quality and naturalness.",
        "translated": ""
    },
    {
        "title": "Fairness of Exposure in Dynamic Recommendation",
        "url": "http://arxiv.org/abs/2309.02322v1",
        "pub_date": "2023-09-05",
        "summary": "Exposure bias is a well-known issue in recommender systems where the exposure\nis not fairly distributed among items in the recommendation results. This is\nespecially problematic when bias is amplified over time as a few items (e.g.,\npopular ones) are repeatedly over-represented in recommendation lists and\nusers' interactions with those items will amplify bias towards those items over\ntime resulting in a feedback loop. This issue has been extensively studied in\nthe literature in static recommendation environment where a single round of\nrecommendation result is processed to improve the exposure fairness. However,\nless work has been done on addressing exposure bias in a dynamic recommendation\nsetting where the system is operating over time, the recommendation model and\nthe input data are dynamically updated with ongoing user feedback on\nrecommended items at each round. In this paper, we study exposure bias in a\ndynamic recommendation setting. Our goal is to show that existing bias\nmitigation methods that are designed to operate in a static recommendation\nsetting are unable to satisfy fairness of exposure for items in long run. In\nparticular, we empirically study one of these methods and show that repeatedly\napplying this method fails to fairly distribute exposure among items in long\nrun. To address this limitation, we show how this method can be adapted to\neffectively operate in a dynamic recommendation setting and achieve exposure\nfairness for items in long run. Experiments on a real-world dataset confirm\nthat our solution is superior in achieving long-term exposure fairness for the\nitems while maintaining the recommendation accuracy.",
        "translated": ""
    },
    {
        "title": "STGIN: Spatial-Temporal Graph Interaction Network for Large-scale POI\n  Recommendation",
        "url": "http://arxiv.org/abs/2309.02251v1",
        "pub_date": "2023-09-05",
        "summary": "In Location-Based Services, Point-Of-Interest(POI) recommendation plays a\ncrucial role in both user experience and business opportunities. Graph neural\nnetworks have been proven effective in providing personalized POI\nrecommendation services. However, there are still two critical challenges.\nFirst, existing graph models attempt to capture users' diversified interests\nthrough a unified graph, which limits their ability to express interests in\nvarious spatial-temporal contexts. Second, the efficiency limitations of graph\nconstruction and graph sampling in large-scale systems make it difficult to\nadapt quickly to new real-time interests. To tackle the above challenges, we\npropose a novel Spatial-Temporal Graph Interaction Network. Specifically, we\nconstruct subgraphs of spatial, temporal, spatial-temporal, and global views\nrespectively to precisely characterize the user's interests in various\ncontexts. In addition, we design an industry-friendly framework to track the\nuser's latest interests. Extensive experiments on the real-world dataset show\nthat our method outperforms state-of-the-art models. This work has been\nsuccessfully deployed in a large e-commerce platform, delivering a 1.1% CTR and\n6.3% RPM improvement.",
        "translated": ""
    },
    {
        "title": "TensorBank:Tensor Lakehouse for Foundation Model Training",
        "url": "http://arxiv.org/abs/2309.02094v1",
        "pub_date": "2023-09-05",
        "summary": "Storing and streaming high dimensional data for foundation model training\nbecame a critical requirement with the rise of foundation models beyond natural\nlanguage. In this paper we introduce TensorBank, a petabyte scale tensor\nlakehouse capable of streaming tensors from Cloud Object Store (COS) to GPU\nmemory at wire speed based on complex relational queries. We use Hierarchical\nStatistical Indices (HSI) for query acceleration. Our architecture allows to\ndirectly address tensors on block level using HTTP range reads. Once in GPU\nmemory, data can be transformed using PyTorch transforms. We provide a generic\nPyTorch dataset type with a corresponding dataset factory translating\nrelational queries and requested transformations as an instance. By making use\nof the HSI, irrelevant blocks can be skipped without reading them as those\nindices contain statistics on their content at different hierarchical\nresolution levels. This is an opinionated architecture powered by open\nstandards and making heavy use of open-source technology. Although, hardened\nfor production use using geospatial-temporal data, this architecture\ngeneralizes to other use case like computer vision, computational neuroscience,\nbiological sequence analysis and more.",
        "translated": ""
    },
    {
        "title": "MvFS: Multi-view Feature Selection for Recommender System",
        "url": "http://arxiv.org/abs/2309.02064v1",
        "pub_date": "2023-09-05",
        "summary": "Feature selection, which is a technique to select key features in recommender\nsystems, has received increasing research attention. Recently, Adaptive Feature\nSelection (AdaFS) has shown remarkable performance by adaptively selecting\nfeatures for each data instance, considering that the importance of a given\nfeature field can vary significantly across data. However, this method still\nhas limitations in that its selection process could be easily biased to major\nfeatures that frequently occur. To address these problems, we propose\nMulti-view Feature Selection (MvFS), which selects informative features for\neach instance more effectively. Most importantly, MvFS employs a multi-view\nnetwork consisting of multiple sub-networks, each of which learns to measure\nthe feature importance of a part of data with different feature patterns. By\ndoing so, MvFS promotes a more balanced feature selection process mitigating\nthe bias problem towards dominant patterns. Moreover, MvFS adopts an effective\nimportance score modeling strategy which is applied independently to each field\nwithout incurring dependency among features. Experimental results on real-world\ndatasets demonstrate the effectiveness of MvFS compared to state-of-the-art\nbaselines.",
        "translated": ""
    },
    {
        "title": "Scenario-Aware Hierarchical Dynamic Network for Multi-Scenario\n  Recommendation",
        "url": "http://arxiv.org/abs/2309.02061v1",
        "pub_date": "2023-09-05",
        "summary": "Click-Through Rate (CTR) prediction is a fundamental technique in\nrecommendation and advertising systems. Recent studies have shown that\nimplementing multi-scenario recommendations contributes to strengthening\ninformation sharing and improving overall performance. However, existing\nmulti-scenario models only consider coarse-grained explicit scenario modeling\nthat depends on pre-defined scenario identification from manual prior rules,\nwhich is biased and sub-optimal. To address these limitations, we propose a\nScenario-Aware Hierarchical Dynamic Network for Multi-Scenario Recommendations\n(HierRec), which perceives implicit patterns adaptively and conducts explicit\nand implicit scenario modeling jointly. In particular, HierRec designs a basic\nscenario-oriented module based on the dynamic weight to capture\nscenario-specific information. Then the hierarchical explicit and implicit\nscenario-aware modules are proposed to model hybrid-grained scenario\ninformation. The multi-head implicit modeling design contributes to perceiving\ndistinctive patterns from different perspectives. Our experiments on two public\ndatasets and real-world industrial applications on a mainstream online\nadvertising platform demonstrate that our HierRec outperforms existing models\nsignificantly.",
        "translated": ""
    },
    {
        "title": "Cognitive Architectures for Language Agents",
        "url": "http://arxiv.org/abs/2309.02427v1",
        "pub_date": "2023-09-05",
        "summary": "Recent efforts have incorporated large language models (LLMs) with external\nresources (e.g., the Internet) or internal control flows (e.g., prompt\nchaining) for tasks requiring grounding or reasoning. However, these efforts\nhave largely been piecemeal, lacking a systematic framework for constructing a\nfully-fledged language agent. To address this challenge, we draw on the rich\nhistory of agent design in symbolic artificial intelligence to develop a\nblueprint for a new wave of cognitive language agents. We first show that LLMs\nhave many of the same properties as production systems, and recent efforts to\nimprove their grounding or reasoning mirror the development of cognitive\narchitectures built around production systems. We then propose Cognitive\nArchitectures for Language Agents (CoALA), a conceptual framework to\nsystematize diverse methods for LLM-based reasoning, grounding, learning, and\ndecision making as instantiations of language agents in the framework. Finally,\nwe use the CoALA framework to highlight gaps and propose actionable directions\ntoward more capable language agents in the future.",
        "translated": ""
    },
    {
        "title": "Substitution-based Semantic Change Detection using Contextual Embeddings",
        "url": "http://arxiv.org/abs/2309.02403v1",
        "pub_date": "2023-09-05",
        "summary": "Measuring semantic change has thus far remained a task where methods using\ncontextual embeddings have struggled to improve upon simpler techniques relying\nonly on static word vectors. Moreover, many of the previously proposed\napproaches suffer from downsides related to scalability and ease of\ninterpretation. We present a simplified approach to measuring semantic change\nusing contextual embeddings, relying only on the most probable substitutes for\nmasked terms. Not only is this approach directly interpretable, it is also far\nmore efficient in terms of storage, achieves superior average performance\nacross the most frequently cited datasets for this task, and allows for more\nnuanced investigation of change than is possible with static word vectors.",
        "translated": ""
    },
    {
        "title": "nanoT5: A PyTorch Framework for Pre-training and Fine-tuning T5-style\n  Models with Limited Resources",
        "url": "http://arxiv.org/abs/2309.02373v1",
        "pub_date": "2023-09-05",
        "summary": "State-of-the-art language models like T5 have revolutionized the NLP\nlandscape, but their computational demands hinder a large portion of the\nresearch community. To address this challenge, we present nanoT5, a\nspecially-optimized PyTorch framework for efficient pre-training and\nfine-tuning of T5 models. Drawing on insights from optimizer differences and\nprioritizing efficiency, nanoT5 allows a T5-Base model to be pre-trained on a\nsingle GPU in just 16 hours, without any loss in performance. With the\nintroduction of this open-source framework, we hope to widen the accessibility\nto language modelling research and cater to the community's demand for more\nuser-friendly T5 (Encoder-Decoder) implementations. Our contributions,\nincluding configurations, codebase, software/hardware insights, and pre-trained\nmodels, are available to the public, aiming to strike a balance between\nresearch accessibility and resource constraints in NLP.",
        "translated": ""
    },
    {
        "title": "Weigh Your Own Words: Improving Hate Speech Counter Narrative Generation\n  via Attention Regularization",
        "url": "http://arxiv.org/abs/2309.02311v1",
        "pub_date": "2023-09-05",
        "summary": "Recent computational approaches for combating online hate speech involve the\nautomatic generation of counter narratives by adapting Pretrained\nTransformer-based Language Models (PLMs) with human-curated data. This process,\nhowever, can produce in-domain overfitting, resulting in models generating\nacceptable narratives only for hatred similar to training data, with little\nportability to other targets or to real-world toxic language. This paper\nintroduces novel attention regularization methodologies to improve the\ngeneralization capabilities of PLMs for counter narratives generation.\nOverfitting to training-specific terms is then discouraged, resulting in more\ndiverse and richer narratives. We experiment with two attention-based\nregularization techniques on a benchmark English dataset. Regularized models\nproduce better counter narratives than state-of-the-art approaches in most\ncases, both in terms of automatic metrics and human evaluation, especially when\nhateful targets are not present in the training data. This work paves the way\nfor better and more flexible counter-speech generation models, a task for which\ndatasets are highly challenging to produce.",
        "translated": ""
    },
    {
        "title": "PromptTTS 2: Describing and Generating Voices with Text Prompt",
        "url": "http://arxiv.org/abs/2309.02285v1",
        "pub_date": "2023-09-05",
        "summary": "Speech conveys more information than just text, as the same word can be\nuttered in various voices to convey diverse information. Compared to\ntraditional text-to-speech (TTS) methods relying on speech prompts (reference\nspeech) for voice variability, using text prompts (descriptions) is more\nuser-friendly since speech prompts can be hard to find or may not exist at all.\nTTS approaches based on the text prompt face two challenges: 1) the one-to-many\nproblem, where not all details about voice variability can be described in the\ntext prompt, and 2) the limited availability of text prompt datasets, where\nvendors and large cost of data labeling are required to write text prompt for\nspeech. In this work, we introduce PromptTTS 2 to address these challenges with\na variation network to provide variability information of voice not captured by\ntext prompts, and a prompt generation pipeline to utilize the large language\nmodels (LLM) to compose high quality text prompts. Specifically, the variation\nnetwork predicts the representation extracted from the reference speech (which\ncontains full information about voice) based on the text prompt representation.\nFor the prompt generation pipeline, it generates text prompts for speech with a\nspeech understanding model to recognize voice attributes (e.g., gender, speed)\nfrom speech and a large language model to formulate text prompt based on the\nrecognition results. Experiments on a large-scale (44K hours) speech dataset\ndemonstrate that compared to the previous works, PromptTTS 2 generates voices\nmore consistent with text prompts and supports the sampling of diverse voice\nvariability, thereby offering users more choices on voice generation.\nAdditionally, the prompt generation pipeline produces high-quality prompts,\neliminating the large labeling cost. The demo page of PromptTTS 2 is available\nonline\\footnote{https://speechresearch.github.io/prompttts2}.",
        "translated": ""
    },
    {
        "title": "Dialog Action-Aware Transformer for Dialog Policy Learning",
        "url": "http://arxiv.org/abs/2309.02240v1",
        "pub_date": "2023-09-05",
        "summary": "Recent works usually address Dialog policy learning DPL by training a\nreinforcement learning (RL) agent to determine the best dialog action. However,\nexisting works on deep RL require a large volume of agent-user interactions to\nachieve acceptable performance. In this paper, we propose to make full use of\nthe plain text knowledge from the pre-trained language model to accelerate the\nRL agent's learning speed. Specifically, we design a dialog action-aware\ntransformer encoder (DaTrans), which integrates a new fine-tuning procedure\nnamed masked last action task to encourage DaTrans to be dialog-aware and\ndistils action-specific features. Then, DaTrans is further optimized in an RL\nsetting with ongoing interactions and evolves through exploration in the dialog\naction space toward maximizing long-term accumulated rewards. The effectiveness\nand efficiency of the proposed model are demonstrated with both simulator\nevaluation and human evaluation.",
        "translated": ""
    },
    {
        "title": "Augmenting Black-box LLMs with Medical Textbooks for Clinical Question\n  Answering",
        "url": "http://arxiv.org/abs/2309.02233v1",
        "pub_date": "2023-09-05",
        "summary": "Large-scale language models (LLMs), such as ChatGPT, are capable of\ngenerating human-like responses for various downstream tasks, such as\ntask-oriented dialogues and question answering. However, applying LLMs to\nmedical domains remains challenging due to their inability to leverage\ndomain-specific knowledge. In this study, we present the Large-scale Language\nModels Augmented with Medical Textbooks (LLM-AMT), which integrates\nauthoritative medical textbooks as the cornerstone of its design, enhancing its\nproficiency in the specialized domain through plug-and-play modules, comprised\nof a Hybrid Textbook Retriever, supplemented by the Query Augmenter and the LLM\nReader. Experimental evaluation on three open-domain medical question-answering\ntasks reveals a substantial enhancement in both the professionalism and\naccuracy of the LLM responses when utilizing LLM-AMT, exhibiting an improvement\nranging from 11.4% to 13.2%. Despite being 100 times smaller, we found that\nmedical textbooks as the retrieval corpus serves as a more valuable external\nknowledge source than Wikipedia in the medical domain. Our experiments show\nthat textbook augmentation results in a performance improvement ranging from\n9.7% to 12.2% over Wikipedia augmentation.",
        "translated": ""
    },
    {
        "title": "Leveraging BERT Language Models for Multi-Lingual ESG Issue\n  Identification",
        "url": "http://arxiv.org/abs/2309.02189v1",
        "pub_date": "2023-09-05",
        "summary": "Environmental, Social, and Governance (ESG) has been used as a metric to\nmeasure the negative impacts and enhance positive outcomes of companies in\nareas such as the environment, society, and governance. Recently, investors\nhave increasingly recognized the significance of ESG criteria in their\ninvestment choices, leading businesses to integrate ESG principles into their\noperations and strategies. The Multi-Lingual ESG Issue Identification (ML-ESG)\nshared task encompasses the classification of news documents into 35 distinct\nESG issue labels. In this study, we explored multiple strategies harnessing\nBERT language models to achieve accurate classification of news documents\nacross these labels. Our analysis revealed that the RoBERTa classifier emerged\nas one of the most successful approaches, securing the second-place position\nfor the English test dataset, and sharing the fifth-place position for the\nFrench test dataset. Furthermore, our SVM-based binary model tailored for the\nChinese language exhibited exceptional performance, earning the second-place\nrank on the test dataset.",
        "translated": ""
    },
    {
        "title": "Incorporating Dictionaries into a Neural Network Architecture to Extract\n  COVID-19 Medical Concepts From Social Media",
        "url": "http://arxiv.org/abs/2309.02188v1",
        "pub_date": "2023-09-05",
        "summary": "We investigate the potential benefit of incorporating dictionary information\ninto a neural network architecture for natural language processing. In\nparticular, we make use of this architecture to extract several concepts\nrelated to COVID-19 from an on-line medical forum. We use a sample from the\nforum to manually curate one dictionary for each concept. In addition, we use\nMetaMap, which is a tool for extracting biomedical concepts, to identify a\nsmall number of semantic concepts. For a supervised concept extraction task on\nthe forum data, our best model achieved a macro $F_1$ score of 90\\%. A major\ndifficulty in medical concept extraction is obtaining labelled data from which\nto build supervised models. We investigate the utility of our models to\ntransfer to data derived from a different source in two ways. First for\nproducing labels via weak learning and second to perform concept extraction.\nThe dataset we use in this case comprises COVID-19 related tweets and we\nachieve an $F_1$ score 81\\% for symptom concept extraction trained on weakly\nlabelled data. The utility of our dictionaries is compared with a COVID-19\nsymptom dictionary that was constructed directly from Twitter. Further\nexperiments that incorporate BERT and a COVID-19 version of BERTweet\ndemonstrate that the dictionaries provide a commensurate result. Our results\nshow that incorporating small domain dictionaries to deep learning models can\nimprove concept extraction tasks. Moreover, models built using dictionaries\ngeneralize well and are transferable to different datasets on a similar task.",
        "translated": ""
    },
    {
        "title": "Advancing Text-to-GLOSS Neural Translation Using a Novel Hyper-parameter\n  Optimization Technique",
        "url": "http://arxiv.org/abs/2309.02162v1",
        "pub_date": "2023-09-05",
        "summary": "In this paper, we investigate the use of transformers for Neural Machine\nTranslation of text-to-GLOSS for Deaf and Hard-of-Hearing communication. Due to\nthe scarcity of available data and limited resources for text-to-GLOSS\ntranslation, we treat the problem as a low-resource language task. We use our\nnovel hyper-parameter exploration technique to explore a variety of\narchitectural parameters and build an optimal transformer-based architecture\nspecifically tailored for text-to-GLOSS translation. The study aims to improve\nthe accuracy and fluency of Neural Machine Translation generated GLOSS. This is\nachieved by examining various architectural parameters including layer count,\nattention heads, embedding dimension, dropout, and label smoothing to identify\nthe optimal architecture for improving text-to-GLOSS translation performance.\nThe experiments conducted on the PHOENIX14T dataset reveal that the optimal\ntransformer architecture outperforms previous work on the same dataset. The\nbest model reaches a ROUGE (Recall-Oriented Understudy for Gisting Evaluation)\nscore of 55.18% and a BLEU-1 (BiLingual Evaluation Understudy 1) score of\n63.6%, outperforming state-of-the-art results on the BLEU1 and ROUGE score by\n8.42 and 0.63 respectively.",
        "translated": ""
    },
    {
        "title": "Impression-Informed Multi-Behavior Recommender System: A Hierarchical\n  Graph Attention Approach",
        "url": "http://arxiv.org/abs/2309.03169v1",
        "pub_date": "2023-09-06",
        "summary": "While recommender systems have significantly benefited from implicit\nfeedback, they have often missed the nuances of multi-behavior interactions\nbetween users and items. Historically, these systems either amalgamated all\nbehaviors, such as \\textit{impression} (formerly \\textit{view}),\n\\textit{add-to-cart}, and \\textit{buy}, under a singular 'interaction' label,\nor prioritized only the target behavior, often the \\textit{buy} action,\ndiscarding valuable auxiliary signals. Although recent advancements tried\naddressing this simplification, they primarily gravitated towards optimizing\nthe target behavior alone, battling with data scarcity. Additionally, they\ntended to bypass the nuanced hierarchy intrinsic to behaviors. To bridge these\ngaps, we introduce the \\textbf{H}ierarchical \\textbf{M}ulti-behavior\n\\textbf{G}raph Attention \\textbf{N}etwork (HMGN). This pioneering framework\nleverages attention mechanisms to discern information from both inter and\nintra-behaviors while employing a multi-task Hierarchical Bayesian Personalized\nRanking (HBPR) for optimization. Recognizing the need for scalability, our\napproach integrates a specialized multi-behavior sub-graph sampling technique.\nMoreover, the adaptability of HMGN allows for the seamless inclusion of\nknowledge metadata and time-series data. Empirical results attest to our\nmodel's prowess, registering a notable performance boost of up to 64\\% in\nNDCG@100 metrics over conventional graph neural network methods.",
        "translated": ""
    },
    {
        "title": "Helper Recommendation with seniority control in Online Health Community",
        "url": "http://arxiv.org/abs/2309.02978v1",
        "pub_date": "2023-09-06",
        "summary": "Online health communities (OHCs) are forums where patients with similar\nconditions communicate their experiences and provide moral support. Social\nsupport in OHCs plays a crucial role in easing and rehabilitating patients.\nHowever, many time-sensitive questions from patients often remain unanswered\ndue to the multitude of threads and the random nature of patient visits in\nOHCs. To address this issue, it is imperative to propose a recommender system\nthat assists solution seekers in finding appropriate problem helpers.\nNevertheless, developing a recommendation algorithm to enhance social support\nin OHCs remains an under-explored area. Traditional recommender systems cannot\nbe directly adapted due to the following obstacles. First, unlike user-item\nlinks in traditional recommender systems, it is hard to model the social\nsupport behind helper-seeker links in OHCs since they are formed based on\nvarious heterogeneous reasons. Second, it is difficult to distinguish the\nimpact of historical activities in characterizing patients. Third, it is\nsignificantly challenging to ensure that the recommended helpers possess\nsufficient expertise to assist the seekers. To tackle the aforementioned\nchallenges, we develop a Monotonically regularIzed diseNTangled Variational\nAutoencoders (MINT) model to strengthen social support in OHCs.",
        "translated": ""
    },
    {
        "title": "Prompt-based Effective Input Reformulation for Legal Case Retrieval",
        "url": "http://arxiv.org/abs/2309.02962v1",
        "pub_date": "2023-09-06",
        "summary": "Legal case retrieval plays an important role for legal practitioners to\neffectively retrieve relevant cases given a query case. Most existing neural\nlegal case retrieval models directly encode the whole legal text of a case to\ngenerate a case representation, which is then utilised to conduct a nearest\nneighbour search for retrieval. Although these straightforward methods have\nachieved improvement over conventional statistical methods in retrieval\naccuracy, two significant challenges are identified in this paper: (1) Legal\nfeature alignment: the usage of the whole case text as the input will generally\nincorporate redundant and noisy information because, from the legal\nperspective, the determining factor of relevant cases is the alignment of key\nlegal features instead of whole text matching; (2) Legal context preservation:\nfurthermore, since the existing text encoding models usually have an input\nlength limit shorter than the case, the whole case text needs to be truncated\nor divided into paragraphs, which leads to the loss of the global context of\nlegal information. In this paper, a novel legal case retrieval framework,\nPromptCase, is proposed to tackle these challenges. Firstly, legal facts and\nlegal issues are identified and formally defined as the key features\nfacilitating legal case retrieval based on a thorough study of the definition\nof relevant cases from a legal perspective. Secondly, with the determining\nlegal features, a prompt-based encoding scheme is designed to conduct an\neffective encoding with language models. Extensive zero-shot experiments have\nbeen conducted on two benchmark datasets in legal case retrieval, which\ndemonstrate the superior retrieval effectiveness of the proposed PromptCase.\nThe code has been released on https://github.com/yanran-tang/PromptCase.",
        "translated": ""
    },
    {
        "title": "Tidying Up the Conversational Recommender Systems' Biases",
        "url": "http://arxiv.org/abs/2309.02550v1",
        "pub_date": "2023-09-05",
        "summary": "The growing popularity of language models has sparked interest in\nconversational recommender systems (CRS) within both industry and research\ncircles. However, concerns regarding biases in these systems have emerged.\nWhile individual components of CRS have been subject to bias studies, a\nliterature gap remains in understanding specific biases unique to CRS and how\nthese biases may be amplified or reduced when integrated into complex CRS\nmodels. In this paper, we provide a concise review of biases in CRS by\nsurveying recent literature. We examine the presence of biases throughout the\nsystem's pipeline and consider the challenges that arise from combining\nmultiple models. Our study investigates biases in classic recommender systems\nand their relevance to CRS. Moreover, we address specific biases in CRS,\nconsidering variations with and without natural language understanding\ncapabilities, along with biases related to dialogue systems and language\nmodels. Through our findings, we highlight the necessity of adopting a holistic\nperspective when dealing with biases in complex CRS models.",
        "translated": ""
    },
    {
        "title": "Gender-specific Machine Translation with Large Language Models",
        "url": "http://arxiv.org/abs/2309.03175v1",
        "pub_date": "2023-09-06",
        "summary": "Decoder-only Large Language Models (LLMs) have demonstrated potential in\nmachine translation (MT), albeit with performance slightly lagging behind\ntraditional encoder-decoder Neural Machine Translation (NMT) systems. However,\nLLMs offer a unique advantage: the ability to control the properties of the\noutput through prompts. In this study, we harness this flexibility to explore\nLLaMa's capability to produce gender-specific translations for languages with\ngrammatical gender. Our results indicate that LLaMa can generate\ngender-specific translations with competitive accuracy and gender bias\nmitigation when compared to NLLB, a state-of-the-art multilingual NMT system.\nFurthermore, our experiments reveal that LLaMa's translations are robust,\nshowing significant performance drops when evaluated against opposite-gender\nreferences in gender-ambiguous datasets but maintaining consistency in less\nambiguous contexts. This research provides insights into the potential and\nchallenges of using LLMs for gender-specific translations and highlights the\nimportance of in-context learning to elicit new tasks in LLMs.",
        "translated": ""
    },
    {
        "title": "GPT-InvestAR: Enhancing Stock Investment Strategies through Annual\n  Report Analysis with Large Language Models",
        "url": "http://arxiv.org/abs/2309.03079v1",
        "pub_date": "2023-09-06",
        "summary": "Annual Reports of publicly listed companies contain vital information about\ntheir financial health which can help assess the potential impact on Stock\nprice of the firm. These reports are comprehensive in nature, going up to, and\nsometimes exceeding, 100 pages. Analysing these reports is cumbersome even for\na single firm, let alone the whole universe of firms that exist. Over the\nyears, financial experts have become proficient in extracting valuable\ninformation from these documents relatively quickly. However, this requires\nyears of practice and experience. This paper aims to simplify the process of\nassessing Annual Reports of all the firms by leveraging the capabilities of\nLarge Language Models (LLMs). The insights generated by the LLM are compiled in\na Quant styled dataset and augmented by historical stock price data. A Machine\nLearning model is then trained with LLM outputs as features. The walkforward\ntest results show promising outperformance wrt S&amp;P500 returns. This paper\nintends to provide a framework for future work in this direction. To facilitate\nthis, the code has been released as open source.",
        "translated": ""
    },
    {
        "title": "J-Guard: Journalism Guided Adversarially Robust Detection of\n  AI-generated News",
        "url": "http://arxiv.org/abs/2309.03164v1",
        "pub_date": "2023-09-06",
        "summary": "The rapid proliferation of AI-generated text online is profoundly reshaping\nthe information landscape. Among various types of AI-generated text,\nAI-generated news presents a significant threat as it can be a prominent source\nof misinformation online. While several recent efforts have focused on\ndetecting AI-generated text in general, these methods require enhanced\nreliability, given concerns about their vulnerability to simple adversarial\nattacks. Furthermore, due to the eccentricities of news writing, applying these\ndetection methods for AI-generated news can produce false positives,\npotentially damaging the reputation of news organizations. To address these\nchallenges, we leverage the expertise of an interdisciplinary team to develop a\nframework, J-Guard, capable of steering existing supervised AI text detectors\nfor detecting AI-generated news while boosting adversarial robustness. By\nincorporating stylistic cues inspired by the unique journalistic attributes,\nJ-Guard effectively distinguishes between real-world journalism and\nAI-generated news articles. Our experiments on news articles generated by a\nvast array of AI models, including ChatGPT (GPT3.5), demonstrate the\neffectiveness of J-Guard in enhancing detection capabilities while maintaining\nan average performance decrease of as low as 7% when faced with adversarial\nattacks.",
        "translated": ""
    },
    {
        "title": "Everyone Deserves A Reward: Learning Customized Human Preferences",
        "url": "http://arxiv.org/abs/2309.03126v1",
        "pub_date": "2023-09-06",
        "summary": "Reward models (RMs) are crucial in aligning large language models (LLMs) with\nhuman preferences for improving interaction quality. However, the real world is\npluralistic, which leads to diversified human preferences based on different\nreligions, politics, cultures, etc. Moreover, each individual can have their\nown unique preferences on various topics. Neglecting the diversity of human\npreferences, current LLM training processes only use a general reward model,\nwhich is below satisfaction for customized or personalized application\nscenarios. To explore customized preference learning, we collect a\ndomain-specific preference (DSP) dataset, which collects preferred responses to\neach given query from four practical domains. Besides, from the perspective of\ndata efficiency, we proposed a three-stage customized RM learning scheme, whose\neffectiveness is empirically verified on both general preference datasets and\nour DSP set. Furthermore, we test multiple training and data strategies on the\nthree learning stages, and have found several ways to better preserve the\ngeneral preferring ability while training the customized RMs, especially\ngeneral preference enrichment and customized preference imitation learning. The\nDSP dataset and code are available at https://github.com/Linear95/DSP.",
        "translated": ""
    },
    {
        "title": "Knowledge Solver: Teaching LLMs to Search for Domain Knowledge from\n  Knowledge Graphs",
        "url": "http://arxiv.org/abs/2309.03118v1",
        "pub_date": "2023-09-06",
        "summary": "Large language models (LLMs), such as ChatGPT and GPT-4, are versatile and\ncan solve different tasks due to their emergent ability and generalizability.\nHowever, LLMs sometimes lack domain-specific knowledge to perform tasks, which\nwould also cause hallucination during inference. In some previous works,\nadditional modules like graph neural networks (GNNs) are trained on retrieved\nknowledge from external knowledge bases, aiming to mitigate the problem of\nlacking domain-specific knowledge. However, incorporating additional modules:\n1) would need retraining additional modules when encountering novel domains; 2)\nwould become a bottleneck since LLMs' strong abilities are not fully utilized\nfor retrieval. In this paper, we propose a paradigm, termed Knowledge Solver\n(KSL), to teach LLMs to search for essential knowledge from external knowledge\nbases by harnessing their own strong generalizability. Specifically, we design\na simple yet effective prompt to transform retrieval into a multi-hop decision\nsequence, which empowers LLMs with searching knowledge ability in zero-shot\nmanner. Additionally, KSL is able to provide complete retrieval paths and\ntherefore increase explainability of LLMs' reasoning processes. We conduct\nexperiments on three datasets: CommonsenseQA, OpenbookQA, and MedQA-USMLE, and\nfound that our approach improves LLM baseline performance by a relatively large\nmargin.",
        "translated": ""
    },
    {
        "title": "ContrastWSD: Enhancing Metaphor Detection with Word Sense Disambiguation\n  Following the Metaphor Identification Procedure",
        "url": "http://arxiv.org/abs/2309.03103v1",
        "pub_date": "2023-09-06",
        "summary": "This paper presents ContrastWSD, a RoBERTa-based metaphor detection model\nthat integrates the Metaphor Identification Procedure (MIP) and Word Sense\nDisambiguation (WSD) to extract and contrast the contextual meaning with the\nbasic meaning of a word to determine whether it is used metaphorically in a\nsentence. By utilizing the word senses derived from a WSD model, our model\nenhances the metaphor detection process and outperforms other methods that rely\nsolely on contextual embeddings or integrate only the basic definitions and\nother external knowledge. We evaluate our approach on various benchmark\ndatasets and compare it with strong baselines, indicating the effectiveness in\nadvancing metaphor detection.",
        "translated": ""
    },
    {
        "title": "A Multimodal Analysis of Influencer Content on Twitter",
        "url": "http://arxiv.org/abs/2309.03064v1",
        "pub_date": "2023-09-06",
        "summary": "Influencer marketing involves a wide range of strategies in which brands\ncollaborate with popular content creators (i.e., influencers) to leverage their\nreach, trust, and impact on their audience to promote and endorse products or\nservices. Because followers of influencers are more likely to buy a product\nafter receiving an authentic product endorsement rather than an explicit direct\nproduct promotion, the line between personal opinions and commercial content\npromotion is frequently blurred. This makes automatic detection of regulatory\ncompliance breaches related to influencer advertising (e.g., misleading\nadvertising or hidden sponsorships) particularly difficult. In this work, we\n(1) introduce a new Twitter (now X) dataset consisting of 15,998 influencer\nposts mapped into commercial and non-commercial categories for assisting in the\nautomatic detection of commercial influencer content; (2) experiment with an\nextensive set of predictive models that combine text and visual information\nshowing that our proposed cross-attention approach outperforms state-of-the-art\nmultimodal models; and (3) conduct a thorough analysis of strengths and\nlimitations of our models. We show that multimodal modeling is useful for\nidentifying commercial posts, reducing the amount of false positives, and\ncapturing relevant context that aids in the discovery of undisclosed commercial\nposts.",
        "translated": ""
    },
    {
        "title": "Persona-aware Generative Model for Code-mixed Language",
        "url": "http://arxiv.org/abs/2309.02915v1",
        "pub_date": "2023-09-06",
        "summary": "Code-mixing and script-mixing are prevalent across online social networks and\nmultilingual societies. However, a user's preference toward code-mixing depends\non the socioeconomic status, demographics of the user, and the local context,\nwhich existing generative models mostly ignore while generating code-mixed\ntexts. In this work, we make a pioneering attempt to develop a persona-aware\ngenerative model to generate texts resembling real-life code-mixed texts of\nindividuals. We propose a Persona-aware Generative Model for Code-mixed\nGeneration, PARADOX, a novel Transformer-based encoder-decoder model that\nencodes an utterance conditioned on a user's persona and generates code-mixed\ntexts without monolingual reference data. We propose an alignment module that\nre-calibrates the generated sequence to resemble real-life code-mixed texts.\nPARADOX generates code-mixed texts that are semantically more meaningful and\nlinguistically more valid. To evaluate the personification capabilities of\nPARADOX, we propose four new metrics -- CM BLEU, CM Rouge-1, CM Rouge-L and CM\nKS. On average, PARADOX achieves 1.6 points better CM BLEU, 47% better\nperplexity and 32% better semantic coherence than the non-persona-based\ncounterparts.",
        "translated": ""
    },
    {
        "title": "Leave no Place Behind: Improved Geolocation in Humanitarian Documents",
        "url": "http://arxiv.org/abs/2309.02914v1",
        "pub_date": "2023-09-06",
        "summary": "Geographical location is a crucial element of humanitarian response,\noutlining vulnerable populations, ongoing events, and available resources.\nLatest developments in Natural Language Processing may help in extracting vital\ninformation from the deluge of reports and documents produced by the\nhumanitarian sector. However, the performance and biases of existing\nstate-of-the-art information extraction tools are unknown. In this work, we\ndevelop annotated resources to fine-tune the popular Named Entity Recognition\n(NER) tools Spacy and roBERTa to perform geotagging of humanitarian texts. We\nthen propose a geocoding method FeatureRank which links the candidate locations\nto the GeoNames database. We find that not only does the humanitarian-domain\ndata improves the performance of the classifiers (up to F1 = 0.92), but it also\nalleviates some of the bias of the existing tools, which erroneously favor\nlocations in the Western countries. Thus, we conclude that more resources from\nnon-Western documents are necessary to ensure that off-the-shelf NER systems\nare suitable for the deployment in the humanitarian sector.",
        "translated": ""
    },
    {
        "title": "On the Challenges of Building Datasets for Hate Speech Detection",
        "url": "http://arxiv.org/abs/2309.02912v1",
        "pub_date": "2023-09-06",
        "summary": "Detection of hate speech has been formulated as a standalone application of\nNLP and different approaches have been adopted for identifying the target\ngroups, obtaining raw data, defining the labeling process, choosing the\ndetection algorithm, and evaluating the performance in the desired setting.\nHowever, unlike other downstream tasks, hate speech suffers from the lack of\nlarge-sized, carefully curated, generalizable datasets owing to the highly\nsubjective nature of the task. In this paper, we first analyze the issues\nsurrounding hate speech detection through a data-centric lens. We then outline\na holistic framework to encapsulate the data creation pipeline across seven\nbroad dimensions by taking the specific example of hate speech towards sexual\nminorities. We posit that practitioners would benefit from following this\nframework as a form of best practice when creating hate speech datasets in the\nfuture.",
        "translated": ""
    },
    {
        "title": "Extending Transductive Knowledge Graph Embedding Models for Inductive\n  Logical Relational Inference",
        "url": "http://arxiv.org/abs/2309.03773v1",
        "pub_date": "2023-09-07",
        "summary": "Many downstream inference tasks for knowledge graphs, such as relation\nprediction, have been handled successfully by knowledge graph embedding\ntechniques in the transductive setting. To address the inductive setting\nwherein new entities are introduced into the knowledge graph at inference time,\nmore recent work opts for models which learn implicit representations of the\nknowledge graph through a complex function of a network's subgraph structure,\noften parametrized by graph neural network architectures. These come at the\ncost of increased parametrization, reduced interpretability and limited\ngeneralization to other downstream inference tasks. In this work, we bridge the\ngap between traditional transductive knowledge graph embedding approaches and\nmore recent inductive relation prediction models by introducing a generalized\nform of harmonic extension which leverages representations learned through\ntransductive embedding methods to infer representations of new entities\nintroduced at inference time as in the inductive setting. This harmonic\nextension technique provides the best such approximation, can be implemented\nvia an efficient iterative scheme, and can be employed to answer a family of\nconjunctive logical queries over the knowledge graph, further expanding the\ncapabilities of transductive embedding methods. In experiments on a number of\nlarge-scale knowledge graph embedding benchmarks, we find that this approach\nfor extending the functionality of transductive knowledge graph embedding\nmodels to perform knowledge graph completion and answer logical queries in the\ninductive setting is competitive with--and in some scenarios\noutperforms--several state-of-the-art models derived explicitly for such\ninductive tasks.",
        "translated": ""
    },
    {
        "title": "VideolandGPT: A User Study on a Conversational Recommender System",
        "url": "http://arxiv.org/abs/2309.03645v1",
        "pub_date": "2023-09-07",
        "summary": "This paper investigates how large language models (LLMs) can enhance\nrecommender systems, with a specific focus on Conversational Recommender\nSystems that leverage user preferences and personalised candidate selections\nfrom existing ranking models. We introduce VideolandGPT, a recommender system\nfor a Video-on-Demand (VOD) platform, Videoland, which uses ChatGPT to select\nfrom a predetermined set of contents, considering the additional context\nindicated by users' interactions with a chat interface. We evaluate ranking\nmetrics, user experience, and fairness of recommendations, comparing a\npersonalised and a non-personalised version of the system, in a between-subject\nuser study. Our results indicate that the personalised version outperforms the\nnon-personalised in terms of accuracy and general user satisfaction, while both\nversions increase the visibility of items which are not in the top of the\nrecommendation lists. However, both versions present inconsistent behavior in\nterms of fairness, as the system may generate recommendations which are not\navailable on Videoland.",
        "translated": ""
    },
    {
        "title": "Evaluating ChatGPT as a Recommender System: A Rigorous Approach",
        "url": "http://arxiv.org/abs/2309.03613v1",
        "pub_date": "2023-09-07",
        "summary": "Recent popularity surrounds large AI language models due to their impressive\nnatural language capabilities. They contribute significantly to\nlanguage-related tasks, including prompt-based learning, making them valuable\nfor various specific tasks. This approach unlocks their full potential,\nenhancing precision and generalization. Research communities are actively\nexploring their applications, with ChatGPT receiving recognition. Despite\nextensive research on large language models, their potential in recommendation\nscenarios still needs to be explored. This study aims to fill this gap by\ninvestigating ChatGPT's capabilities as a zero-shot recommender system. Our\ngoals include evaluating its ability to use user preferences for\nrecommendations, reordering existing recommendation lists, leveraging\ninformation from similar users, and handling cold-start situations. We assess\nChatGPT's performance through comprehensive experiments using three datasets\n(MovieLens Small, Last.FM, and Facebook Book). We compare ChatGPT's performance\nagainst standard recommendation algorithms and other large language models,\nsuch as GPT-3.5 and PaLM-2. To measure recommendation effectiveness, we employ\nwidely-used evaluation metrics like Mean Average Precision (MAP), Recall,\nPrecision, F1, normalized Discounted Cumulative Gain (nDCG), Item Coverage,\nExpected Popularity Complement (EPC), Average Coverage of Long Tail (ACLT),\nAverage Recommendation Popularity (ARP), and Popularity-based Ranking-based\nEqual Opportunity (PopREO). Through thoroughly exploring ChatGPT's abilities in\nrecommender systems, our study aims to contribute to the growing body of\nresearch on the versatility and potential applications of large language\nmodels. Our experiment code is available on the GitHub repository:\nhttps://github.com/sisinflab/Recommender-ChatGPT",
        "translated": ""
    },
    {
        "title": "Learning Compact Compositional Embeddings via Regularized Pruning for\n  Recommendation",
        "url": "http://arxiv.org/abs/2309.03518v1",
        "pub_date": "2023-09-07",
        "summary": "Latent factor models are the dominant backbones of contemporary recommender\nsystems (RSs) given their performance advantages, where a unique vector\nembedding with a fixed dimensionality (e.g., 128) is required to represent each\nentity (commonly a user/item). Due to the large number of users and items on\ne-commerce sites, the embedding table is arguably the least memory-efficient\ncomponent of RSs. For any lightweight recommender that aims to efficiently\nscale with the growing size of users/items or to remain applicable in\nresource-constrained settings, existing solutions either reduce the number of\nembeddings needed via hashing, or sparsify the full embedding table to switch\noff selected embedding dimensions. However, as hash collision arises or\nembeddings become overly sparse, especially when adapting to a tighter memory\nbudget, those lightweight recommenders inevitably have to compromise their\naccuracy. To this end, we propose a novel compact embedding framework for RSs,\nnamely Compositional Embedding with Regularized Pruning (CERP). Specifically,\nCERP represents each entity by combining a pair of embeddings from two\nindependent, substantially smaller meta-embedding tables, which are then\njointly pruned via a learnable element-wise threshold. In addition, we\ninnovatively design a regularized pruning mechanism in CERP, such that the two\nsparsified meta-embedding tables are encouraged to encode information that is\nmutually complementary. Given the compatibility with agnostic latent factor\nmodels, we pair CERP with two popular recommendation models for extensive\nexperiments, where results on two real-world datasets under different memory\nbudgets demonstrate its superiority against state-of-the-art baselines. The\ncodebase of CERP is available in https://github.com/xurong-liang/CERP.",
        "translated": ""
    },
    {
        "title": "Behind Recommender Systems: the Geography of the ACM RecSys Community",
        "url": "http://arxiv.org/abs/2309.03512v1",
        "pub_date": "2023-09-07",
        "summary": "The amount and dissemination rate of media content accessible online is\nnowadays overwhelming. Recommender Systems filter this information into\nmanageable streams or feeds, adapted to our personal needs or preferences. It\nis of utter importance that algorithms employed to filter information do not\ndistort or cut out important elements from our perspectives of the world. Under\nthis principle, it is essential to involve diverse views and teams from the\nearliest stages of their design and development. This has been highlighted, for\ninstance, in recent European Union regulations such as the Digital Services\nAct, via the requirement of risk monitoring, including the risk of\ndiscrimination, and the AI Act, through the requirement to involve people with\ndiverse backgrounds in the development of AI systems. We look into the\ngeographic diversity of the recommender systems research community,\nspecifically by analyzing the affiliation countries of the authors who\ncontributed to the ACM Conference on Recommender Systems (RecSys) during the\nlast 15 years. This study has been carried out in the framework of the\nDiversity in AI - DivinAI project, whose main objective is the long-term\nmonitoring of diversity in AI forums through a set of indexes.",
        "translated": ""
    },
    {
        "title": "ImageBind-LLM: Multi-modality Instruction Tuning",
        "url": "http://arxiv.org/abs/2309.03905v1",
        "pub_date": "2023-09-07",
        "summary": "We present ImageBind-LLM, a multi-modality instruction tuning method of large\nlanguage models (LLMs) via ImageBind. Existing works mainly focus on language\nand image instruction tuning, different from which, our ImageBind-LLM can\nrespond to multi-modality conditions, including audio, 3D point clouds, video,\nand their embedding-space arithmetic by only image-text alignment training.\nDuring training, we adopt a learnable bind network to align the embedding space\nbetween LLaMA and ImageBind's image encoder. Then, the image features\ntransformed by the bind network are added to word tokens of all layers in\nLLaMA, which progressively injects visual instructions via an attention-free\nand zero-initialized gating mechanism. Aided by the joint embedding of\nImageBind, the simple image-text training enables our model to exhibit superior\nmulti-modality instruction-following capabilities. During inference, the\nmulti-modality inputs are fed into the corresponding ImageBind encoders, and\nprocessed by a proposed visual cache model for further cross-modal embedding\nenhancement. The training-free cache model retrieves from three million image\nfeatures extracted by ImageBind, which effectively mitigates the\ntraining-inference modality discrepancy. Notably, with our approach,\nImageBind-LLM can respond to instructions of diverse modalities and demonstrate\nsignificant language generation quality. Code is released at\nhttps://github.com/OpenGVLab/LLaMA-Adapter.",
        "translated": ""
    },
    {
        "title": "A Function Interpretation Benchmark for Evaluating Interpretability\n  Methods",
        "url": "http://arxiv.org/abs/2309.03886v1",
        "pub_date": "2023-09-07",
        "summary": "Labeling neural network submodules with human-legible descriptions is useful\nfor many downstream tasks: such descriptions can surface failures, guide\ninterventions, and perhaps even explain important model behaviors. To date,\nmost mechanistic descriptions of trained networks have involved small models,\nnarrowly delimited phenomena, and large amounts of human labor. Labeling all\nhuman-interpretable sub-computations in models of increasing size and\ncomplexity will almost certainly require tools that can generate and validate\ndescriptions automatically. Recently, techniques that use learned models\nin-the-loop for labeling have begun to gain traction, but methods for\nevaluating their efficacy are limited and ad-hoc. How should we validate and\ncompare open-ended labeling tools? This paper introduces FIND (Function\nINterpretation and Description), a benchmark suite for evaluating the building\nblocks of automated interpretability methods. FIND contains functions that\nresemble components of trained neural networks, and accompanying descriptions\nof the kind we seek to generate. The functions are procedurally constructed\nacross textual and numeric domains, and involve a range of real-world\ncomplexities, including noise, composition, approximation, and bias. We\nevaluate new and existing methods that use language models (LMs) to produce\ncode-based and language descriptions of function behavior. We find that an\noff-the-shelf LM augmented with only black-box access to functions can\nsometimes infer their structure, acting as a scientist by forming hypotheses,\nproposing experiments, and updating descriptions in light of new data. However,\nLM-based descriptions tend to capture global function behavior and miss local\ncorruptions. These results show that FIND will be useful for characterizing the\nperformance of more sophisticated interpretability methods before they are\napplied to real-world models.",
        "translated": ""
    },
    {
        "title": "Zero-Shot Audio Captioning via Audibility Guidance",
        "url": "http://arxiv.org/abs/2309.03884v1",
        "pub_date": "2023-09-07",
        "summary": "The task of audio captioning is similar in essence to tasks such as image and\nvideo captioning. However, it has received much less attention. We propose\nthree desiderata for captioning audio -- (i) fluency of the generated text,\n(ii) faithfulness of the generated text to the input audio, and the somewhat\nrelated (iii) audibility, which is the quality of being able to be perceived\nbased only on audio. Our method is a zero-shot method, i.e., we do not learn to\nperform captioning. Instead, captioning occurs as an inference process that\ninvolves three networks that correspond to the three desired qualities: (i) A\nLarge Language Model, in our case, for reasons of convenience, GPT-2, (ii) A\nmodel that provides a matching score between an audio file and a text, for\nwhich we use a multimodal matching network called ImageBind, and (iii) A text\nclassifier, trained using a dataset we collected automatically by instructing\nGPT-4 with prompts designed to direct the generation of both audible and\ninaudible sentences. We present our results on the AudioCap dataset,\ndemonstrating that audibility guidance significantly enhances performance\ncompared to the baseline, which lacks this objective.",
        "translated": ""
    },
    {
        "title": "DoLa: Decoding by Contrasting Layers Improves Factuality in Large\n  Language Models",
        "url": "http://arxiv.org/abs/2309.03883v1",
        "pub_date": "2023-09-07",
        "summary": "Despite their impressive capabilities, large language models (LLMs) are prone\nto hallucinations, i.e., generating content that deviates from facts seen\nduring pretraining. We propose a simple decoding strategy for reducing\nhallucinations with pretrained LLMs that does not require conditioning on\nretrieved external knowledge nor additional fine-tuning. Our approach obtains\nthe next-token distribution by contrasting the differences in logits obtained\nfrom projecting the later layers versus earlier layers to the vocabulary space,\nexploiting the fact that factual knowledge in an LLMs has generally been shown\nto be localized to particular transformer layers. We find that this Decoding by\nContrasting Layers (DoLa) approach is able to better surface factual knowledge\nand reduce the generation of incorrect facts. DoLa consistently improves the\ntruthfulness across multiple choices tasks and open-ended generation tasks, for\nexample improving the performance of LLaMA family models on TruthfulQA by\n12-17% absolute points, demonstrating its potential in making LLMs reliably\ngenerate truthful facts.",
        "translated": ""
    },
    {
        "title": "On Large Language Models' Selection Bias in Multi-Choice Questions",
        "url": "http://arxiv.org/abs/2309.03882v1",
        "pub_date": "2023-09-07",
        "summary": "Multi-choice questions (MCQs) serve as a common yet important task format in\nthe research of large language models (LLMs). Our work shows that LLMs exhibit\nan inherent \"selection bias\" in MCQs, which refers to LLMs' preferences to\nselect options located at specific positions (like \"Option C\"). This bias is\nprevalent across various LLMs, making their performance vulnerable to option\nposition changes in MCQs. We identify that one primary cause resulting in\nselection bias is option numbering, i.e., the ID symbols A/B/C/D associated\nwith the options. To mitigate selection bias, we propose a new method called\nPriDe. PriDe first decomposes the observed model prediction distribution into\nan intrinsic prediction over option contents and a prior distribution over\noption IDs. It then estimates the prior by permutating option contents on a\nsmall number of test samples, which is used to debias the subsequent test\nsamples. We demonstrate that, as a label-free, inference-time method, PriDe\nachieves a more effective and computation-efficient debiasing than strong\nbaselines. We further show that the priors estimated by PriDe generalize well\nacross different domains, highlighting its practical potential in broader\nscenarios.",
        "translated": ""
    },
    {
        "title": "Introducing \"Forecast Utterance\" for Conversational Data Science",
        "url": "http://arxiv.org/abs/2309.03877v1",
        "pub_date": "2023-09-07",
        "summary": "Envision an intelligent agent capable of assisting users in conducting\nforecasting tasks through intuitive, natural conversations, without requiring\nin-depth knowledge of the underlying machine learning (ML) processes. A\nsignificant challenge for the agent in this endeavor is to accurately\ncomprehend the user's prediction goals and, consequently, formulate precise ML\ntasks. In this paper, we take a pioneering step towards this ambitious goal by\nintroducing a new concept called Forecast Utterance and then focus on the\nautomatic and accurate interpretation of users' prediction goals from these\nutterances. Specifically, we frame the task as a slot-filling problem, where\neach slot corresponds to a specific aspect of the goal prediction task. We then\nemploy two zero-shot methods for solving the slot-filling task, namely: 1)\nEntity Extraction (EE), and 2) Question-Answering (QA) techniques. Our\nexperiments, conducted with three meticulously crafted data sets, validate the\nviability of our ambitious goal and demonstrate the effectiveness of both EE\nand QA techniques in interpreting Forecast Utterances.",
        "translated": ""
    },
    {
        "title": "OpinionGPT: Modelling Explicit Biases in Instruction-Tuned LLMs",
        "url": "http://arxiv.org/abs/2309.03876v1",
        "pub_date": "2023-09-07",
        "summary": "Instruction-tuned Large Language Models (LLMs) have recently showcased\nremarkable ability to generate fitting responses to natural language\ninstructions. However, an open research question concerns the inherent biases\nof trained models and their responses. For instance, if the data used to tune\nan LLM is dominantly written by persons with a specific political bias, we\nmight expect generated answers to share this bias. Current research work seeks\nto de-bias such models, or suppress potentially biased answers. With this\ndemonstration, we take a different view on biases in instruction-tuning: Rather\nthan aiming to suppress them, we aim to make them explicit and transparent. To\nthis end, we present OpinionGPT, a web demo in which users can ask questions\nand select all biases they wish to investigate. The demo will answer this\nquestion using a model fine-tuned on text representing each of the selected\nbiases, allowing side-by-side comparison. To train the underlying model, we\nidentified 11 different biases (political, geographic, gender, age) and derived\nan instruction-tuning corpus in which each answer was written by members of one\nof these demographics. This paper presents OpinionGPT, illustrates how we\ntrained the bias-aware model and showcases the web application (available at\nhttps://opiniongpt.informatik.hu-berlin.de).",
        "translated": ""
    },
    {
        "title": "FLM-101B: An Open LLM and How to Train It with $100K Budget",
        "url": "http://arxiv.org/abs/2309.03852v1",
        "pub_date": "2023-09-07",
        "summary": "Large language models (LLMs) have achieved remarkable success in NLP and\nmultimodal tasks. Despite these successes, their development faces two main\nchallenges: (i) high computational cost; and (ii) difficulty in conducting fair\nand objective evaluations. LLMs are prohibitively expensive, making it feasible\nfor only a few major players to undertake their training, thereby constraining\nboth research and application opportunities. This underscores the importance of\ncost-effective LLM training. In this paper, we utilize a growth strategy to\nsignificantly reduce LLM training cost. We demonstrate that an LLM with 101B\nparameters and 0.31TB tokens can be trained on a $100K budget. We also adopt a\nsystematic evaluation paradigm for the IQ evaluation of LLMs, in complement to\nexisting evaluations that focus more on knowledge-oriented abilities. We\nintroduce our benchmark including evaluations on important aspects of\nintelligence including symbolic mapping, itrule understanding, pattern mining,\nand anti-interference. Such evaluations minimize the potential impact of\nmemorization. Experimental results show that our model FLM-101B, trained with a\nbudget of $100K, achieves comparable performance to powerful and well-known\nmodels, eg GPT-3 and GLM-130B, especially in the IQ benchmark evaluations with\ncontexts unseen in training data. The checkpoint of FLM-101B will be\nopen-sourced at https://huggingface.co/CofeAI/FLM-101B.",
        "translated": ""
    },
    {
        "title": "Uncovering Drift in Textual Data: An Unsupervised Method for Detecting\n  and Mitigating Drift in Machine Learning Models",
        "url": "http://arxiv.org/abs/2309.03831v1",
        "pub_date": "2023-09-07",
        "summary": "Drift in machine learning refers to the phenomenon where the statistical\nproperties of data or context, in which the model operates, change over time\nleading to a decrease in its performance. Therefore, maintaining a constant\nmonitoring process for machine learning model performance is crucial in order\nto proactively prevent any potential performance regression. However,\nsupervised drift detection methods require human annotation and consequently\nlead to a longer time to detect and mitigate the drift. In our proposed\nunsupervised drift detection method, we follow a two step process. Our first\nstep involves encoding a sample of production data as the target distribution,\nand the model training data as the reference distribution. In the second step,\nwe employ a kernel-based statistical test that utilizes the maximum mean\ndiscrepancy (MMD) distance metric to compare the reference and target\ndistributions and estimate any potential drift. Our method also identifies the\nsubset of production data that is the root cause of the drift. The models\nretrained using these identified high drift samples show improved performance\non online customer experience quality metrics.",
        "translated": ""
    },
    {
        "title": "USA: Universal Sentiment Analysis Model &amp; Construction of Japanese\n  Sentiment Text Classification and Part of Speech Dataset",
        "url": "http://arxiv.org/abs/2309.03787v1",
        "pub_date": "2023-09-07",
        "summary": "Sentiment analysis is a pivotal task in the domain of natural language\nprocessing. It encompasses both text-level sentiment polarity classification\nand word-level Part of Speech(POS) sentiment polarity determination. Such\nanalysis challenges models to understand text holistically while also\nextracting nuanced information. With the rise of Large Language Models(LLMs),\nnew avenues for sentiment analysis have opened. This paper proposes enhancing\nperformance by leveraging the Mutual Reinforcement Effect(MRE) between\nindividual words and the overall text. It delves into how word polarity\ninfluences the overarching sentiment of a passage. To support our research, we\nannotated four novel Sentiment Text Classification and Part of Speech(SCPOS)\ndatasets, building upon existing sentiment classification datasets.\nFurthermore, we developed a Universal Sentiment Analysis(USA) model, with a\n7-billion parameter size. Experimental results revealed that our model\nsurpassed the performance of gpt-3.5-turbo across all four datasets,\nunderscoring the significance of MRE in sentiment analysis.",
        "translated": ""
    },
    {
        "title": "Provider Fairness and Beyond-Accuracy Trade-offs in Recommender Systems",
        "url": "http://arxiv.org/abs/2309.04250v1",
        "pub_date": "2023-09-08",
        "summary": "Recommender systems, while transformative in online user experiences, have\nraised concerns over potential provider-side fairness issues. These systems may\ninadvertently favor popular items, thereby marginalizing less popular ones and\ncompromising provider fairness. While previous research has recognized\nprovider-side fairness issues, the investigation into how these biases affect\nbeyond-accuracy aspects of recommendation systems - such as diversity, novelty,\ncoverage, and serendipity - has been less emphasized. In this paper, we address\nthis gap by introducing a simple yet effective post-processing re-ranking model\nthat prioritizes provider fairness, while simultaneously maintaining user\nrelevance and recommendation quality. We then conduct an in-depth evaluation of\nthe model's impact on various aspects of recommendation quality across multiple\ndatasets. Specifically, we apply the post-processing algorithm to four distinct\nrecommendation models across four varied domain datasets, assessing the\nimprovement in each metric, encompassing both accuracy and beyond-accuracy\naspects. This comprehensive analysis allows us to gauge the effectiveness of\nour approach in mitigating provider biases. Our findings underscore the\neffectiveness of the adopted method in improving provider fairness and\nrecommendation quality. They also provide valuable insights into the trade-offs\ninvolved in achieving fairness in recommender systems, contributing to a more\nnuanced understanding of this complex issue.",
        "translated": ""
    },
    {
        "title": "Offline Recommender System Evaluation under Unobserved Confounding",
        "url": "http://arxiv.org/abs/2309.04222v1",
        "pub_date": "2023-09-08",
        "summary": "Off-Policy Estimation (OPE) methods allow us to learn and evaluate\ndecision-making policies from logged data. This makes them an attractive choice\nfor the offline evaluation of recommender systems, and several recent works\nhave reported successful adoption of OPE methods to this end. An important\nassumption that makes this work is the absence of unobserved confounders:\nrandom variables that influence both actions and rewards at data collection\ntime. Because the data collection policy is typically under the practitioner's\ncontrol, the unconfoundedness assumption is often left implicit, and its\nviolations are rarely dealt with in the existing literature.\n  This work aims to highlight the problems that arise when performing\noff-policy estimation in the presence of unobserved confounders, specifically\nfocusing on a recommendation use-case. We focus on policy-based estimators,\nwhere the logging propensities are learned from logged data. We characterise\nthe statistical bias that arises due to confounding, and show how existing\ndiagnostics are unable to uncover such cases. Because the bias depends directly\non the true and unobserved logging propensities, it is non-identifiable. As the\nunconfoundedness assumption is famously untestable, this becomes especially\nproblematic. This paper emphasises this common, yet often overlooked issue.\nThrough synthetic data, we empirically show how na\\\"ive propensity estimation\nunder confounding can lead to severely biased metric estimates that are allowed\nto fly under the radar. We aim to cultivate an awareness among researchers and\npractitioners of this important problem, and touch upon potential research\ndirections towards mitigating its effects.",
        "translated": ""
    },
    {
        "title": "Receiving an algorithmic recommendation based on documentary filmmaking\n  techniques",
        "url": "http://arxiv.org/abs/2309.04184v1",
        "pub_date": "2023-09-08",
        "summary": "This article analyzes the reception of a novel algorithmic recommendation of\ndocumentary films by a panel of moviegoers of the T{\\\"e}nk platform. In order\nto propose an alternative to recommendations based on a thematic\nclassification, the director or the production period, a set of metadata has\nbeen elaborated within the framework of this experimentation in order to\ncharacterize the great variety of ``documentary filmmaking dispositifs'' . The\ngoal is to investigate the different ways in which the platform's film lovers\nappropriate a personalized recommendation of 4 documentaries with similar or\nsimilar filmmaking dispositifs. To conclude, the contributions and limits of\nthis proof of concept are discussed in order to sketch out avenues of\nreflection for improving the instrumented mediation of documentary films.",
        "translated": ""
    },
    {
        "title": "A Long-Tail Friendly Representation Framework for Artist and Music\n  Similarity",
        "url": "http://arxiv.org/abs/2309.04182v1",
        "pub_date": "2023-09-08",
        "summary": "The investigation of the similarity between artists and music is crucial in\nmusic retrieval and recommendation, and addressing the challenge of the\nlong-tail phenomenon is increasingly important. This paper proposes a Long-Tail\nFriendly Representation Framework (LTFRF) that utilizes neural networks to\nmodel the similarity relationship. Our approach integrates music, user,\nmetadata, and relationship data into a unified metric learning framework, and\nemploys a meta-consistency relationship as a regular term to introduce the\nMulti-Relationship Loss. Compared to the Graph Neural Network (GNN), our\nproposed framework improves the representation performance in long-tail\nscenarios, which are characterized by sparse relationships between artists and\nmusic. We conduct experiments and analysis on the AllMusic dataset, and the\nresults demonstrate that our framework provides a favorable generalization of\nartist and music representation. Specifically, on similar artist/music\nrecommendation tasks, the LTFRF outperforms the baseline by 9.69%/19.42% in Hit\nRatio@10, and in long-tail cases, the framework achieves 11.05%/14.14% higher\nthan the baseline in Consistent@10.",
        "translated": ""
    },
    {
        "title": "PRISTA-Net: Deep Iterative Shrinkage Thresholding Network for Coded\n  Diffraction Patterns Phase Retrieval",
        "url": "http://arxiv.org/abs/2309.04171v1",
        "pub_date": "2023-09-08",
        "summary": "The problem of phase retrieval (PR) involves recovering an unknown image from\nlimited amplitude measurement data and is a challenge nonlinear inverse problem\nin computational imaging and image processing. However, many of the PR methods\nare based on black-box network models that lack interpretability and\nplug-and-play (PnP) frameworks that are computationally complex and require\ncareful parameter tuning. To address this, we have developed PRISTA-Net, a deep\nunfolding network (DUN) based on the first-order iterative shrinkage\nthresholding algorithm (ISTA). This network utilizes a learnable nonlinear\ntransformation to address the proximal-point mapping sub-problem associated\nwith the sparse priors, and an attention mechanism to focus on phase\ninformation containing image edges, textures, and structures. Additionally, the\nfast Fourier transform (FFT) is used to learn global features to enhance local\ninformation, and the designed logarithmic-based loss function leads to\nsignificant improvements when the noise level is low. All parameters in the\nproposed PRISTA-Net framework, including the nonlinear transformation,\nthreshold parameters, and step size, are learned end-to-end instead of being\nmanually set. This method combines the interpretability of traditional methods\nwith the fast inference ability of deep learning and is able to handle noise at\neach iteration during the unfolding stage, thus improving recovery quality.\nExperiments on Coded Diffraction Patterns (CDPs) measurements demonstrate that\nour approach outperforms the existing state-of-the-art methods in terms of\nqualitative and quantitative evaluations. Our source codes are available at\n\\emph{https://github.com/liuaxou/PRISTA-Net}.",
        "translated": ""
    },
    {
        "title": "Measuring and Improving Chain-of-Thought Reasoning in Vision-Language\n  Models",
        "url": "http://arxiv.org/abs/2309.04461v1",
        "pub_date": "2023-09-08",
        "summary": "Vision-language models (VLMs) have recently demonstrated strong efficacy as\nvisual assistants that can parse natural queries about the visual content and\ngenerate human-like outputs. In this work, we explore the ability of these\nmodels to demonstrate human-like reasoning based on the perceived information.\nTo address a crucial concern regarding the extent to which their reasoning\ncapabilities are fully consistent and grounded, we also measure the reasoning\nconsistency of these models. We achieve this by proposing a chain-of-thought\n(CoT) based consistency measure. However, such an evaluation requires a\nbenchmark that encompasses both high-level inference and detailed reasoning\nchains, which is costly. We tackle this challenge by proposing a\nLLM-Human-in-the-Loop pipeline, which notably reduces cost while simultaneously\nensuring the generation of a high-quality dataset. Based on this pipeline and\nthe existing coarse-grained annotated dataset, we build the CURE benchmark to\nmeasure both the zero-shot reasoning performance and consistency of VLMs. We\nevaluate existing state-of-the-art VLMs, and find that even the best-performing\nmodel is unable to demonstrate strong visual reasoning capabilities and\nconsistency, indicating that substantial efforts are required to enable VLMs to\nperform visual reasoning as systematically and consistently as humans. As an\nearly step, we propose a two-stage training framework aimed at improving both\nthe reasoning performance and consistency of VLMs. The first stage involves\nemploying supervised fine-tuning of VLMs using step-by-step reasoning samples\nautomatically generated by LLMs. In the second stage, we further augment the\ntraining process by incorporating feedback provided by LLMs to produce\nreasoning chains that are highly consistent and grounded. We empirically\nhighlight the effectiveness of our framework in both reasoning performance and\nconsistency.",
        "translated": ""
    },
    {
        "title": "CSPRD: A Financial Policy Retrieval Dataset for Chinese Stock Market",
        "url": "http://arxiv.org/abs/2309.04389v1",
        "pub_date": "2023-09-08",
        "summary": "In recent years, great advances in pre-trained language models (PLMs) have\nsparked considerable research focus and achieved promising performance on the\napproach of dense passage retrieval, which aims at retrieving relative passages\nfrom massive corpus with given questions. However, most of existing datasets\nmainly benchmark the models with factoid queries of general commonsense, while\nspecialised fields such as finance and economics remain unexplored due to the\ndeficiency of large-scale and high-quality datasets with expert annotations. In\nthis work, we propose a new task, policy retrieval, by introducing the Chinese\nStock Policy Retrieval Dataset (CSPRD), which provides 700+ prospectus passages\nlabeled by experienced experts with relevant articles from 10k+ entries in our\ncollected Chinese policy corpus. Experiments on lexical, embedding and\nfine-tuned bi-encoder models show the effectiveness of our proposed CSPRD yet\nalso suggests ample potential for improvement. Our best performing baseline\nachieves 56.1% MRR@10, 28.5% NDCG@10, 37.5% Recall@10 and 80.6% Precision@10 on\ndev set.",
        "translated": ""
    },
    {
        "title": "MoEController: Instruction-based Arbitrary Image Manipulation with\n  Mixture-of-Expert Controllers",
        "url": "http://arxiv.org/abs/2309.04372v1",
        "pub_date": "2023-09-08",
        "summary": "Diffusion-model-based text-guided image generation has recently made\nastounding progress, producing fascinating results in open-domain image\nmanipulation tasks. Few models, however, currently have complete zero-shot\ncapabilities for both global and local image editing due to the complexity and\ndiversity of image manipulation tasks. In this work, we propose a method with a\nmixture-of-expert (MOE) controllers to align the text-guided capacity of\ndiffusion models with different kinds of human instructions, enabling our model\nto handle various open-domain image manipulation tasks with natural language\ninstructions. First, we use large language models (ChatGPT) and conditional\nimage synthesis models (ControlNet) to generate a large number of global image\ntransfer dataset in addition to the instruction-based local image editing\ndataset. Then, using an MOE technique and task-specific adaptation training on\na large-scale dataset, our conditional diffusion model can edit images globally\nand locally. Extensive experiments demonstrate that our approach performs\nsurprisingly well on various image manipulation tasks when dealing with\nopen-domain images and arbitrary human instructions. Please refer to our\nproject page: [https://oppo-mente-lab.github.io/moe_controller/]",
        "translated": ""
    },
    {
        "title": "Beyond Static Datasets: A Deep Interaction Approach to LLM Evaluation",
        "url": "http://arxiv.org/abs/2309.04369v1",
        "pub_date": "2023-09-08",
        "summary": "Large Language Models (LLMs) have made progress in various real-world tasks,\nwhich stimulates requirements for the evaluation of LLMs. Existing LLM\nevaluation methods are mainly supervised signal-based which depends on static\ndatasets and cannot evaluate the ability of LLMs in dynamic real-world\nscenarios where deep interaction widely exists. Other LLM evaluation methods\nare human-based which are costly and time-consuming and are incapable of\nlarge-scale evaluation of LLMs. To address the issues above, we propose a novel\nDeep Interaction-based LLM-evaluation framework. In our proposed framework,\nLLMs' performances in real-world domains can be evaluated from their deep\ninteraction with other LLMs in elaborately designed evaluation tasks.\nFurthermore, our proposed framework is a general evaluation method that can be\napplied to a host of real-world tasks such as machine translation and code\ngeneration. We demonstrate the effectiveness of our proposed method through\nextensive experiments on four elaborately designed evaluation tasks.",
        "translated": ""
    },
    {
        "title": "Encoding Multi-Domain Scientific Papers by Ensembling Multiple CLS\n  Tokens",
        "url": "http://arxiv.org/abs/2309.04333v1",
        "pub_date": "2023-09-08",
        "summary": "Many useful tasks on scientific documents, such as topic classification and\ncitation prediction, involve corpora that span multiple scientific domains.\nTypically, such tasks are accomplished by representing the text with a vector\nembedding obtained from a Transformer's single CLS token. In this paper, we\nargue that using multiple CLS tokens could make a Transformer better specialize\nto multiple scientific domains. We present Multi2SPE: it encourages each of\nmultiple CLS tokens to learn diverse ways of aggregating token embeddings, then\nsums them up together to create a single vector representation. We also propose\nour new multi-domain benchmark, Multi-SciDocs, to test scientific paper vector\nencoders under multi-domain settings. We show that Multi2SPE reduces error by\nup to 25 percent in multi-domain citation prediction, while requiring only a\nnegligible amount of computation in addition to one BERT forward pass.",
        "translated": ""
    },
    {
        "title": "Fuzzy Fingerprinting Transformer Language-Models for Emotion Recognition\n  in Conversations",
        "url": "http://arxiv.org/abs/2309.04292v1",
        "pub_date": "2023-09-08",
        "summary": "Fuzzy Fingerprints have been successfully used as an interpretable text\nclassification technique, but, like most other techniques, have been largely\nsurpassed in performance by Large Pre-trained Language Models, such as BERT or\nRoBERTa. These models deliver state-of-the-art results in several Natural\nLanguage Processing tasks, namely Emotion Recognition in Conversations (ERC),\nbut suffer from the lack of interpretability and explainability. In this paper,\nwe propose to combine the two approaches to perform ERC, as a means to obtain\nsimpler and more interpretable Large Language Models-based classifiers. We\npropose to feed the utterances and their previous conversational turns to a\npre-trained RoBERTa, obtaining contextual embedding utterance representations,\nthat are then supplied to an adapted Fuzzy Fingerprint classification module.\nWe validate our approach on the widely used DailyDialog ERC benchmark dataset,\nin which we obtain state-of-the-art level results using a much lighter model.",
        "translated": ""
    },
    {
        "title": "From Sparse to Dense: GPT-4 Summarization with Chain of Density\n  Prompting",
        "url": "http://arxiv.org/abs/2309.04269v1",
        "pub_date": "2023-09-08",
        "summary": "Selecting the ``right'' amount of information to include in a summary is a\ndifficult task. A good summary should be detailed and entity-centric without\nbeing overly dense and hard to follow. To better understand this tradeoff, we\nsolicit increasingly dense GPT-4 summaries with what we refer to as a ``Chain\nof Density'' (CoD) prompt. Specifically, GPT-4 generates an initial\nentity-sparse summary before iteratively incorporating missing salient entities\nwithout increasing the length. Summaries generated by CoD are more abstractive,\nexhibit more fusion, and have less of a lead bias than GPT-4 summaries\ngenerated by a vanilla prompt. We conduct a human preference study on 100 CNN\nDailyMail articles and find that that humans prefer GPT-4 summaries that are\nmore dense than those generated by a vanilla prompt and almost as dense as\nhuman written summaries. Qualitative analysis supports the notion that there\nexists a tradeoff between informativeness and readability. 500 annotated CoD\nsummaries, as well as an extra 5,000 unannotated summaries, are freely\navailable on HuggingFace\n(https://huggingface.co/datasets/griffin/chain_of_density).",
        "translated": ""
    },
    {
        "title": "UQ at #SMM4H 2023: ALEX for Public Health Analysis with Social Media",
        "url": "http://arxiv.org/abs/2309.04213v1",
        "pub_date": "2023-09-08",
        "summary": "As social media becomes increasingly popular, more and more activities\nrelated to public health emerge. Current techniques for public health analysis\ninvolve popular models such as BERT and large language models (LLMs). However,\nthe costs of training in-domain LLMs for public health are especially\nexpensive. Furthermore, such kinds of in-domain datasets from social media are\ngenerally imbalanced. To tackle these challenges, the data imbalance issue can\nbe overcome by data augmentation and balanced training. Moreover, the ability\nof the LLMs can be effectively utilized by prompting the model properly. In\nthis paper, a novel ALEX framework is proposed to improve the performance of\npublic health analysis on social media by adopting an LLMs explanation\nmechanism. Results show that our ALEX model got the best performance among all\nsubmissions in both Task 2 and Task 4 with a high score in Task 1 in Social\nMedia Mining for Health 2023 (SMM4H)[1]. Our code has been released at https://\ngithub.com/YanJiangJerry/ALEX.",
        "translated": ""
    },
    {
        "title": "The CALLA Dataset: Probing LLMs' Interactive Knowledge Acquisition from\n  Chinese Medical Literature",
        "url": "http://arxiv.org/abs/2309.04198v1",
        "pub_date": "2023-09-08",
        "summary": "The application of Large Language Models (LLMs) to the medical domain has\nstimulated the interest of researchers. Recent studies have focused on\nconstructing Instruction Fine-Tuning (IFT) data through medical knowledge\ngraphs to enrich the interactive medical knowledge of LLMs. However, the\nmedical literature serving as a rich source of medical knowledge remains\nunexplored. Our work introduces the CALLA dataset to probe LLMs' interactive\nknowledge acquisition from Chinese medical literature. It assesses the\nproficiency of LLMs in mastering medical knowledge through a free-dialogue\nfact-checking task. We identify a phenomenon called the ``fact-following\nresponse``, where LLMs tend to affirm facts mentioned in questions and display\na reluctance to challenge them. To eliminate the inaccurate evaluation caused\nby this phenomenon, for the golden fact, we artificially construct test data\nfrom two perspectives: one consistent with the fact and one inconsistent with\nthe fact. Drawing from the probing experiment on the CALLA dataset, we conclude\nthat IFT data highly correlated with the medical literature corpus serves as a\npotent catalyst for LLMs, enabling themselves to skillfully employ the medical\nknowledge acquired during the pre-training phase within interactive scenarios,\nenhancing accuracy. Furthermore, we design a framework for automatically\nconstructing IFT data based on medical literature and discuss some real-world\napplications.",
        "translated": ""
    },
    {
        "title": "Knowledge-tuning Large Language Models with Structured Medical Knowledge\n  Bases for Reliable Response Generation in Chinese",
        "url": "http://arxiv.org/abs/2309.04175v1",
        "pub_date": "2023-09-08",
        "summary": "Large Language Models (LLMs) have demonstrated remarkable success in diverse\nnatural language processing (NLP) tasks in general domains. However, LLMs\nsometimes generate responses with the hallucination about medical facts due to\nlimited domain knowledge. Such shortcomings pose potential risks in the\nutilization of LLMs within medical contexts. To address this challenge, we\npropose knowledge-tuning, which leverages structured medical knowledge bases\nfor the LLMs to grasp domain knowledge efficiently and facilitate reliable\nresponse generation. We also release cMedKnowQA, a Chinese medical knowledge\nquestion-answering dataset constructed from medical knowledge bases to assess\nthe medical knowledge proficiency of LLMs. Experimental results show that the\nLLMs which are knowledge-tuned with cMedKnowQA, can exhibit higher levels of\naccuracy in response generation compared with vanilla instruction-tuning and\noffer a new reliable way for the domain adaptation of LLMs.",
        "translated": ""
    }
]
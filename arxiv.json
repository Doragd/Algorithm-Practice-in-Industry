[
    {
        "title": "Exploring the Carbon Footprint of Hugging Face's ML Models: A Repository\n  Mining Study",
        "url": "http://arxiv.org/abs/2305.11164v1",
        "pub_date": "2023-05-18",
        "summary": "The rise of machine learning (ML) systems has exacerbated their carbon\nfootprint due to increased capabilities and model sizes. However, there is\nscarce knowledge on how the carbon footprint of ML models is actually measured,\nreported, and evaluated. In light of this, the paper aims to analyze the\nmeasurement of the carbon footprint of 1,417 ML models and associated datasets\non Hugging Face, which is the most popular repository for pretrained ML models.\nThe goal is to provide insights and recommendations on how to report and\noptimize the carbon efficiency of ML models. The study includes the first\nrepository mining study on the Hugging Face Hub API on carbon emissions. This\nstudy seeks to answer two research questions: (1) how do ML model creators\nmeasure and report carbon emissions on Hugging Face Hub?, and (2) what aspects\nimpact the carbon emissions of training ML models? The study yielded several\nkey findings. These include a decreasing proportion of carbon\nemissions-reporting models, a slight decrease in reported carbon footprint on\nHugging Face over the past 2 years, and a continued dominance of NLP as the\nmain application domain. Furthermore, the study uncovers correlations between\ncarbon emissions and various attributes such as model size, dataset size, and\nML application domains. These results highlight the need for software\nmeasurements to improve energy reporting practices and promote carbon-efficient\nmodel development within the Hugging Face community. In response to this issue,\ntwo classifications are proposed: one for categorizing models based on their\ncarbon emission reporting practices and another for their carbon efficiency.\nThe aim of these classification proposals is to foster transparency and\nsustainable model development within the ML community.",
        "translated": "机器学习(ML)系统的兴起加剧了它们的碳足印，原因是功能和模型尺寸的增加。然而，对于机器学习模型的碳足印实际上是如何测量、报告和评估的，我们知之甚少。有鉴于此，本文旨在分析“拥抱脸”上对1417个机器学习模型及相关数据集的碳足印测量结果。“拥抱脸”是最受欢迎的预训机器学习模型库。目标是就如何报告和优化机器学习模型的碳效率提供见解和建议。这项研究包括第一个关于碳排放的拥抱面中心 API 的知识库挖掘研究。这项研究试图回答两个研究问题: (1)机器学习模型的创建者如何测量和报告拥抱面部中心的碳排放量？以及(2)哪些方面影响训练机器学习模型的碳排放量？这项研究产生了几个关键的发现。其中包括碳排放报告模型的比例下降，过去两年“拥抱脸”上的报告碳足印略有下降，以及自然语言处理作为主要应用领域的持续主导地位。此外，该研究还揭示了碳排放与模型大小、数据集大小和机器学习应用领域等各种属性之间的相关性。这些结果突出了软件测量的必要性，以改善能源报告做法，并促进在拥抱面社区的碳效率模型开发。针对这一问题，提出了两种分类: 一种是根据其碳排放报告做法对模型进行分类，另一种是根据其碳效率进行分类。这些分类建议的目的是在 ML 社区内促进透明度和可持续的模型开发。"
    },
    {
        "title": "TOME: A Two-stage Approach for Model-based Retrieval",
        "url": "http://arxiv.org/abs/2305.11161v1",
        "pub_date": "2023-05-18",
        "summary": "Recently, model-based retrieval has emerged as a new paradigm in text\nretrieval that discards the index in the traditional retrieval model and\ninstead memorizes the candidate corpora using model parameters. This design\nemploys a sequence-to-sequence paradigm to generate document identifiers, which\nenables the complete capture of the relevance between queries and documents and\nsimplifies the classic indexretrieval-rerank pipeline. Despite its attractive\nqualities, there remain several major challenges in model-based retrieval,\nincluding the discrepancy between pre-training and fine-tuning, and the\ndiscrepancy between training and inference. To deal with the above challenges,\nwe propose a novel two-stage model-based retrieval approach called TOME, which\nmakes two major technical contributions, including the utilization of tokenized\nURLs as identifiers and the design of a two-stage generation architecture. We\nalso propose a number of training strategies to deal with the training\ndifficulty as the corpus size increases. Extensive experiments and analysis on\nMS MARCO and Natural Questions demonstrate the effectiveness of our proposed\napproach, and we investigate the scaling laws of TOME by examining various\ninfluencing factors.",
        "translated": "近年来，基于模型的检索已经成为文本检索的一种新范式，它抛弃了传统检索模型中的索引，而是利用模型参数记忆候选语料库。该设计采用序列到序列的方法生成文档标识符，能够完全捕获查询和文档之间的相关性，简化了经典的索引检索-重排序流水线。尽管基于模型的检索具有吸引人的优点，但仍然存在一些主要的挑战，包括预训练和微调之间的差异，以及训练和推理之间的差异。为了应对上述挑战，我们提出了一种新的基于两阶段模型的检索方法，称为 TOME，它做出了两个主要的技术贡献，包括使用标记化 URL 作为标识符和设计一个两阶段生成体系结构。随着语料库规模的增大，我们提出了一些训练策略来解决训练难度。大量的实验和分析 MS MARCO 和自然问题证明了我们提出的方法的有效性，我们研究了 TOME 的缩放规律通过检查各种影响因素。"
    },
    {
        "title": "Preference or Intent? Double Disentangled Collaborative Filtering",
        "url": "http://arxiv.org/abs/2305.11084v1",
        "pub_date": "2023-05-18",
        "summary": "People usually have different intents for choosing items, while their\npreferences under the same intent may also different. In traditional\ncollaborative filtering approaches, both intent and preference factors are\nusually entangled in the modeling process, which significantly limits the\nrobustness and interpretability of recommendation performances. For example,\nthe low-rating items are always treated as negative feedback while they\nactually could provide positive information about user intent. To this end, in\nthis paper, we propose a two-fold representation learning approach, namely\nDouble Disentangled Collaborative Filtering (DDCF), for personalized\nrecommendations. The first-level disentanglement is for separating the\ninfluence factors of intent and preference, while the second-level\ndisentanglement is performed to build independent sparse preference\nrepresentations under individual intent with limited computational complexity.\nSpecifically, we employ two variational autoencoder networks, intent\nrecognition network and preference decomposition network, to learn the intent\nand preference factors, respectively. In this way, the low-rating items will be\ntreated as positive samples for modeling intents while the negative samples for\nmodeling preferences. Finally, extensive experiments on three real-world\ndatasets and four evaluation metrics clearly validate the effectiveness and the\ninterpretability of DDCF.",
        "translated": "人们通常有不同的意图选择项目，而他们的偏好下，相同的意图也可能有所不同。在传统的协同过滤建模方法中，意图和偏好因素通常会在建模过程中纠缠在一起，这极大地限制了推荐性能的稳健性和可解释性。例如，低等级的项目总是被视为负面反馈，而实际上它们可以提供关于用户意图的正面信息。为此，在本文中，我们提出了一种双重表征学习方法，即双重分离协同过滤(DDCF) ，用于个性化推荐。第一级解缠是为了分离意图和偏好的影响因素，而第二级解缠是为了在计算复杂度有限的个体意图下构建独立的稀疏偏好表示。具体来说，我们使用两个变分自动编码器网络，意图识别网络和偏好分解网络，分别学习意图和偏好因素。这样，低等级的项目将被视为建模意图的正面样本，而负面样本将被视为建模偏好。最后，在三个实际数据集和四个评价指标上进行了广泛的实验，验证了 DDCF 的有效性和可解释性。"
    },
    {
        "title": "AMR4NLI: Interpretable and robust NLI measures from semantic graphs",
        "url": "http://arxiv.org/abs/2306.00936v1",
        "pub_date": "2023-06-01",
        "summary": "The task of natural language inference (NLI) asks whether a given premise\n(expressed in NL) entails a given NL hypothesis. NLI benchmarks contain human\nratings of entailment, but the meaning relationships driving these ratings are\nnot formalized. Can the underlying sentence pair relationships be made more\nexplicit in an interpretable yet robust fashion? We compare semantic structures\nto represent premise and hypothesis, including sets of contextualized\nembeddings and semantic graphs (Abstract Meaning Representations), and measure\nwhether the hypothesis is a semantic substructure of the premise, utilizing\ninterpretable metrics. Our evaluation on three English benchmarks finds value\nin both contextualized embeddings and semantic graphs; moreover, they provide\ncomplementary signals, and can be leveraged together in a hybrid model.",
        "translated": "自然语言推理的任务是询问一个给定的前提(用自然语言表示)是否包含一个给定的自然语言假设。NLI 基准包含人工赋值评级，但是驱动这些评级的意义关系并没有形式化。潜在的句子对关系是否可以以一种可解释的、强有力的方式更明确地表达出来？我们比较了表示前提和假设的语义结构，包括语境化嵌入和语义图集(抽象意义表示) ，并利用可解释的度量衡量假设是否是前提的语义子结构。我们对三个英语基准测试的评估发现了上下文嵌入和语义图的价值; 此外，它们提供了互补的信号，并且可以在混合模型中一起使用。"
    },
    {
        "title": "ACLM: A Selective-Denoising based Generative Data Augmentation Approach\n  for Low-Resource Complex NER",
        "url": "http://arxiv.org/abs/2306.00928v1",
        "pub_date": "2023-06-01",
        "summary": "Complex Named Entity Recognition (NER) is the task of detecting\nlinguistically complex named entities in low-context text. In this paper, we\npresent ACLM Attention-map aware keyword selection for Conditional Language\nModel fine-tuning), a novel data augmentation approach based on conditional\ngeneration to address the data scarcity problem in low-resource complex NER.\nACLM alleviates the context-entity mismatch issue, a problem existing NER data\naugmentation techniques suffer from and often generates incoherent\naugmentations by placing complex named entities in the wrong context. ACLM\nbuilds on BART and is optimized on a novel text reconstruction or denoising\ntask - we use selective masking (aided by attention maps) to retain the named\nentities and certain keywords in the input sentence that provide contextually\nrelevant additional knowledge or hints about the named entities. Compared with\nother data augmentation strategies, ACLM can generate more diverse and coherent\naugmentations preserving the true word sense of complex entities in the\nsentence. We demonstrate the effectiveness of ACLM both qualitatively and\nquantitatively on monolingual, cross-lingual, and multilingual complex NER\nacross various low-resource settings. ACLM outperforms all our neural baselines\nby a significant margin (1%-36%). In addition, we demonstrate the application\nof ACLM to other domains that suffer from data scarcity (e.g., biomedical). In\npractice, ACLM generates more effective and factual augmentations for these\ndomains than prior methods. Code: https://github.com/Sreyan88/ACLM",
        "translated": "复杂命名实体识别(NER)是在低语境文本中检测语言复杂命名实体的任务。针对低资源复杂 NER 中的数据稀缺问题，提出了一种基于条件生成的数据增强方法—— ACLM 注意图感知的条件语言模型关键词选择方法。ACLM 缓解了上下文-实体不匹配问题，这是现有的 NER 数据增强技术所面临的问题，并且通常通过将复杂的命名实体放置在错误的上下文中而产生不一致的增强。ACLM 建立在 BART 的基础上，针对一个新的文本重建或去噪任务进行优化——我们使用选择性掩蔽(通过注意力地图辅助)来保留输入句中的命名实体和某些关键字，这些关键字提供了与上下文相关的附加知识或关于命名实体的提示。与其他数据增强策略相比，ACLM 能够产生更多样化和连贯的增强，保持句子中复杂实体的真实词义。我们证明了 ACLM 在定性和定量上对不同低资源环境下的单语言、跨语言和多语言复杂 NER 的有效性。ACLM 比我们所有的神经基线都要好得多(1% -36%)。此外，我们还展示了 ACLM 在其他数据稀缺领域(如生物医学)的应用。在实践中，ACLM 为这些领域产生了比以前的方法更有效和实际的增强。密码:  https://github.com/sreyan88/aclm"
    },
    {
        "title": "SpotTarget: Rethinking the Effect of Target Edges for Link Prediction in\n  Graph Neural Networks",
        "url": "http://arxiv.org/abs/2306.00899v1",
        "pub_date": "2023-06-01",
        "summary": "Graph Neural Networks (GNNs) have demonstrated promising outcomes across\nvarious tasks, including node classification and link prediction. Despite their\nremarkable success in various high-impact applications, we have identified\nthree common pitfalls in message passing for link prediction. Particularly, in\nprevalent GNN frameworks (e.g., DGL and PyTorch-Geometric), the target edges\n(i.e., the edges being predicted) consistently exist as message passing edges\nin the graph during training. Consequently, this results in overfitting and\ndistribution shift, both of which adversely impact the generalizability to test\nthe target edges. Additionally, during test time, the failure to exclude the\ntest target edges leads to implicit test leakage caused by neighborhood\naggregation. In this paper, we analyze these three pitfalls and investigate the\nimpact of including or excluding target edges on the performance of nodes with\nvarying degrees during training and test phases. Our theoretical and empirical\nanalysis demonstrates that low-degree nodes are more susceptible to these\npitfalls. These pitfalls can have detrimental consequences when GNNs are\nimplemented in production systems. To systematically address these pitfalls, we\npropose SpotTarget, an effective and efficient GNN training framework. During\ntraining, SpotTarget leverages our insight regarding low-degree nodes and\nexcludes train target edges connected to at least one low-degree node. During\ntest time, it emulates real-world scenarios of GNN usage in production and\nexcludes all test target edges. Our experiments conducted on diverse real-world\ndatasets, demonstrate that SpotTarget significantly enhances GNNs, achieving up\nto a 15x increase in accuracy in sparse graphs. Furthermore, SpotTarget\nconsistently and dramatically improves the performance for low-degree nodes in\ndense graphs.",
        "translated": "图形神经网络(GNN)在各种任务中，包括节点分类和链路预测，都取得了很好的效果。尽管它们在各种高影响力的应用程序中取得了显著的成功，但是我们已经确定了链接预测中消息传递的三个常见缺陷。特别是，在流行的 GNN 框架(例如，DGL 和 PyTorch-Geometer)中，目标边(例如，被预测的边)在训练期间始终作为图中的消息传递边存在。因此，这会导致过拟合和分布偏移，这两者都会对测试目标边缘的通用性产生不利影响。此外，在测试时间内，未能排除测试目标边缘会导致由邻域聚合引起的隐式测试泄漏。在本文中，我们分析了这三个陷阱，并研究了在训练和测试阶段包含或排除目标边对不同程度的节点性能的影响。我们的理论和实证分析表明，低度节点更容易受到这些陷阱的影响。当 GNN 在生产系统中实现时，这些缺陷可能会产生有害的后果。为了系统地解决这些缺陷，我们提出了 SpotTarget，一个高效的 GNN 训练框架。在训练过程中，SpotTarget 利用我们对低度节点的洞察力，排除了连接到至少一个低度节点的训练目标边缘。在测试期间，它模拟生产中 GNN 使用的真实场景，并排除所有测试目标边缘。我们在不同的真实世界数据集上进行的实验表明，SpotTarget 显著地增强了 GNN，在稀疏图中实现了高达15倍的精度提高。此外，SpotTarget 持续而显著地改善了稠密图中低度节点的性能。"
    },
    {
        "title": "Topic-Guided Sampling For Data-Efficient Multi-Domain Stance Detection",
        "url": "http://arxiv.org/abs/2306.00765v1",
        "pub_date": "2023-06-01",
        "summary": "Stance Detection is concerned with identifying the attitudes expressed by an\nauthor towards a target of interest. This task spans a variety of domains\nranging from social media opinion identification to detecting the stance for a\nlegal claim. However, the framing of the task varies within these domains, in\nterms of the data collection protocol, the label dictionary and the number of\navailable annotations. Furthermore, these stance annotations are significantly\nimbalanced on a per-topic and inter-topic basis. These make multi-domain stance\ndetection a challenging task, requiring standardization and domain adaptation.\nTo overcome this challenge, we propose $\\textbf{T}$opic $\\textbf{E}$fficient\n$\\textbf{St}$anc$\\textbf{E}$ $\\textbf{D}$etection (TESTED), consisting of a\ntopic-guided diversity sampling technique and a contrastive objective that is\nused for fine-tuning a stance classifier. We evaluate the method on an existing\nbenchmark of $16$ datasets with in-domain, i.e. all topics seen and\nout-of-domain, i.e. unseen topics, experiments. The results show that our\nmethod outperforms the state-of-the-art with an average of $3.5$ F1 points\nincrease in-domain, and is more generalizable with an averaged increase of\n$10.2$ F1 on out-of-domain evaluation while using $\\leq10\\%$ of the training\ndata. We show that our sampling technique mitigates both inter- and per-topic\nclass imbalances. Finally, our analysis demonstrates that the contrastive\nlearning objective allows the model a more pronounced segmentation of samples\nwith varying labels.",
        "translated": "姿势检测是指识别作者对于感兴趣的目标所表达的态度。这项任务涉及从社交媒体舆论识别到检测法律诉求立场等多个领域。然而，在这些领域内，任务的框架在数据收集协议、标签字典和可用注释的数量方面有所不同。此外，这些立场注释在每个主题和主题间的基础上显著不平衡。这使得多域姿态检测成为一项具有挑战性的任务，需要标准化和域自适应。为了克服这个挑战，我们提出了 $textbf { T } $opic $textbf { E } $ffical$textbf { St } $anc $textbf { E } $textbf { D } $etection (TESTED) ，包括一个主题引导的多样性采样技术和一个用于微调立场分类器的对比目标。我们评估的方法，在一个现有的基准 $16 $数据集与域内，即所有主题看到和域外，即看不到的主题，实验。结果表明，我们的方法优于国家的最新技术，平均 $3.5 $F1点在域内增加，更具普遍性，平均增加 $10.2 $F1在域外评估，同时使用 $leq10% $的训练数据。我们展示了我们的抽样技术缓解了主题间和主题间的类不平衡。最后，我们的分析表明，对比学习的目标允许模型更明显的样本分割与不同的标签。"
    },
    {
        "title": "End-to-End Document Classification and Key Information Extraction using\n  Assignment Optimization",
        "url": "http://arxiv.org/abs/2306.00750v1",
        "pub_date": "2023-06-01",
        "summary": "We propose end-to-end document classification and key information extraction\n(KIE) for automating document processing in forms. Through accurate document\nclassification we harness known information from templates to enhance KIE from\nforms. We use text and layout encoding with a cosine similarity measure to\nclassify visually-similar documents. We then demonstrate a novel application of\nmixed integer programming by using assignment optimization to extract key\ninformation from documents. Our approach is validated on an in-house dataset of\nnoisy scanned forms. The best performing document classification approach\nachieved 0.97 f1 score. A mean f1 score of 0.94 for the KIE task suggests there\nis significant potential in applying optimization techniques. Abation results\nshow that the method relies on document preprocessing techniques to mitigate\nType II errors and achieve optimal performance.",
        "translated": "我们建议采用端到端文档分类及信息抽取，以自动处理表格内的文件。通过准确的文档分类，我们利用模板中的已知信息来增强表单中的知识工具教育。我们使用文本和布局编码，并采用余弦距离度量方法对视觉上相似的文档进行分类。然后我们展示了一个新的混合整数规划的应用，通过使用分配优化从文档中提取关键信息。我们的方法是在一个有噪声的扫描表单的内部数据集上进行验证的。表现最好的文档分类得分为0.97 f1。KIE 任务的平均 f1得分为0.94，表明应用优化技术有很大的潜力。消减结果表明，该方法依赖于文档预处理技术，以减轻 II 类错误，并取得最佳性能。"
    },
    {
        "title": "TopEx: Topic-based Explanations for Model Comparison",
        "url": "http://arxiv.org/abs/2306.00976v1",
        "pub_date": "2023-06-01",
        "summary": "Meaningfully comparing language models is challenging with current\nexplanation methods. Current explanations are overwhelming for humans due to\nlarge vocabularies or incomparable across models. We present TopEx, an\nexplanation method that enables a level playing field for comparing language\nmodels via model-agnostic topics. We demonstrate how TopEx can identify\nsimilarities and differences between DistilRoBERTa and GPT-2 on a variety of\nNLP tasks.",
        "translated": "对语言模型进行有意义的比较对于当前的解释方法来说是一个挑战。目前的解释对人类来说是压倒性的，因为词汇量很大，或者在不同的模型中是无法比较的。我们提出了 TopEx，一种解释方法，使一个公平的竞争环境比较语言模型通过模型不可知的主题。我们演示了 TopEx 如何在各种 NLP 任务中识别 DistilRoBERTa 和 GPT-2之间的相似点和不同点。"
    },
    {
        "title": "AWQ: Activation-aware Weight Quantization for LLM Compression and\n  Acceleration",
        "url": "http://arxiv.org/abs/2306.00978v1",
        "pub_date": "2023-06-01",
        "summary": "Large language models (LLMs) have shown excellent performance on various\ntasks, but the astronomical model size raises the hardware barrier for serving\n(memory size) and slows down token generation (memory bandwidth). In this\npaper, we propose Activation-aware Weight Quantization (AWQ), a\nhardware-friendly approach for LLM low-bit weight-only quantization. Our method\nis based on the observation that weights are not equally important: protecting\nonly 1% of salient weights can greatly reduce quantization error. We then\npropose to search for the optimal per-channel scaling that protects the salient\nweights by observing the activation, not weights. AWQ does not rely on any\nbackpropagation or reconstruction, so it can well preserve LLMs' generalization\nability on different domains and modalities, without overfitting to the\ncalibration set; it also does not rely on any data layout reordering,\nmaintaining the hardware efficiency. AWQ outperforms existing work on various\nlanguage modeling, common sense QA, and domain-specific benchmarks. Thanks to\nbetter generalization, it achieves excellent quantization performance for\ninstruction-tuned LMs and, for the first time, multi-modal LMs. We also\nimplement efficient tensor core kernels with reorder-free online dequantization\nto accelerate AWQ, achieving a 1.45x speedup over GPTQ and is 1.85x faster than\nthe cuBLAS FP16 implementation. Our method provides a turn-key solution to\ncompress LLMs to 3/4 bits for efficient deployment.",
        "translated": "大型语言模型(LLM)在各种任务中表现出了优异的性能，但是庞大的模型大小增加了服务的硬件障碍(内存大小) ，并减慢了令牌生成(内存带宽)。本文提出了一种基于激活感知的权重量化(AWQ)方法，用于 LLM 低比特权重量化。我们的方法是基于这样的观察: 重量并不同等重要，只保护显著重量的1% 就可以大大减少量化噪声。然后我们建议通过观察激活而不是权值来寻找保护显著权值的最佳通道尺度。AWQ 不依赖任何反向传播或重构，因此它可以很好地保持 LLM 在不同领域和模式下的泛化能力，而不会过度适应校准集; 它也不依赖任何数据布局重排序，保持硬件效率。AWQ 在各种语言建模、常识性 QA 和特定领域基准测试方面的表现优于现有的工作。由于更好的泛化，它实现了优良的量化性能的指令调谐 LM 和第一次，多模态 LM。我们还实现了高效的张量核心，无需重新排序的在线去量化来加速 AWQ，比 GPTQ 提高了1.45倍的速度，比 cuBLAS FP16实现快了1.85倍。我们的方法提供了一个交钥匙解决方案，可以将 LLM 压缩到3/4位，从而实现高效部署。"
    },
    {
        "title": "EEL: Efficiently Encoding Lattices for Reranking",
        "url": "http://arxiv.org/abs/2306.00947v1",
        "pub_date": "2023-06-01",
        "summary": "Standard decoding approaches for conditional text generation tasks typically\nsearch for an output hypothesis with high model probability, but this may not\nyield the best hypothesis according to human judgments of quality. Reranking to\noptimize for \"downstream\" metrics can better optimize for quality, but many\nmetrics of interest are computed with pre-trained language models, which are\nslow to apply to large numbers of hypotheses. We explore an approach for\nreranking hypotheses by using Transformers to efficiently encode lattices of\ngenerated outputs, a method we call EEL. With a single Transformer pass over\nthe entire lattice, we can approximately compute a contextualized\nrepresentation of each token as if it were only part of a single hypothesis in\nisolation. We combine this approach with a new class of token-factored\nrerankers (TFRs) that allow for efficient extraction of high reranker-scoring\nhypotheses from the lattice. Empirically, our approach incurs minimal\ndegradation error compared to the exponentially slower approach of encoding\neach hypothesis individually. When applying EEL with TFRs across three text\ngeneration tasks, our results show both substantial speedup compared to naive\nreranking and often better performance on downstream metrics than comparable\napproaches.",
        "translated": "条件文本生成任务的标准解码方法通常搜索具有高模型概率的输出假设，但这可能不会根据人类对质量的判断产生最佳假设。重新排序以优化“下游”指标可以更好地优化质量，但许多感兴趣的指标是使用预先训练的语言模型计算的，这些模型适用于大量假设的速度很慢。我们探索了一种重新排序假设的方法，通过使用变形金刚有效地编码生成的输出格子，一种方法，我们称之为 EEL。通过一个单变压器遍历整个格子，我们可以近似地计算每个标记的上下文化表示，就好像它只是孤立的单个假设的一部分一样。我们结合这种方法与一类新的令牌因子重排序(TFR) ，允许有效地提取高重排序得分假设从格。根据经验，我们的方法产生最小的退化误差相比，指数较慢的方法编码每个假设单独。在跨三个文本生成任务应用带 TFR 的 EEL 时，我们的结果显示，与初始重新排序相比，EEL 的速度大幅提高，而且下游指标的性能通常比可比方法更好。"
    },
    {
        "title": "Exposing Attention Glitches with Flip-Flop Language Modeling",
        "url": "http://arxiv.org/abs/2306.00946v1",
        "pub_date": "2023-06-01",
        "summary": "Why do large language models sometimes output factual inaccuracies and\nexhibit erroneous reasoning? The brittleness of these models, particularly when\nexecuting long chains of reasoning, currently seems to be an inevitable price\nto pay for their advanced capabilities of coherently synthesizing knowledge,\npragmatics, and abstract thought. Towards making sense of this fundamentally\nunsolved problem, this work identifies and analyzes the phenomenon of attention\nglitches, in which the Transformer architecture's inductive biases\nintermittently fail to capture robust reasoning. To isolate the issue, we\nintroduce flip-flop language modeling (FFLM), a parametric family of synthetic\nbenchmarks designed to probe the extrapolative behavior of neural language\nmodels. This simple generative task requires a model to copy binary symbols\nover long-range dependencies, ignoring the tokens in between. We find that\nTransformer FFLMs suffer from a long tail of sporadic reasoning errors, some of\nwhich we can eliminate using various regularization techniques. Our preliminary\nmechanistic analyses show why the remaining errors may be very difficult to\ndiagnose and resolve. We hypothesize that attention glitches account for (some\nof) the closed-domain hallucinations in natural LLMs.",
        "translated": "为什么大型语言模型有时会输出不准确的事实，并表现出错误的推理？这些模型的脆弱性，特别是在执行长链推理时，目前似乎是为其连贯综合知识、语用学和抽象思维的先进能力付出的不可避免的代价。为了理解这个根本上未解决的问题，本文识别并分析了注意小故障现象，其中变压器结构的感应偏差间歇性地不能捕获鲁棒性推理。为了隔离这个问题，我们引入了触发器语言建模(FFLM) ，这是一个参数化的合成基准，旨在探索神经语言模型的外推行为。这个简单的生成任务需要一个模型在远程依赖关系上复制二进制符号，忽略中间的标记。我们发现变压器 FFLM 存在很多零星的推理错误，我们可以使用各种正则化技术来消除其中的一些错误。我们的初步机理分析表明，为什么剩余的误差可能非常难以诊断和解决。我们假设在自然的 LLM 中，注意力失调可以解释(部分)闭域幻觉。"
    },
    {
        "title": "\"Let's not Quote out of Context\": Unified Vision-Language Pretraining\n  for Context Assisted Image Captioning",
        "url": "http://arxiv.org/abs/2306.00931v1",
        "pub_date": "2023-06-01",
        "summary": "Well-formed context aware image captions and tags in enterprise content such\nas marketing material are critical to ensure their brand presence and content\nrecall. Manual creation and updates to ensure the same is non trivial given the\nscale and the tedium towards this task. We propose a new unified\nVision-Language (VL) model based on the One For All (OFA) model, with a focus\non context-assisted image captioning where the caption is generated based on\nboth the image and its context. Our approach aims to overcome the\ncontext-independent (image and text are treated independently) nature of the\nexisting approaches. We exploit context by pretraining our model with datasets\nof three tasks: news image captioning where the news article is the context,\ncontextual visual entailment, and keyword extraction from the context. The\nsecond pretraining task is a new VL task, and we construct and release two\ndatasets for the task with 1.1M and 2.2K data instances. Our system achieves\nstate-of-the-art results with an improvement of up to 8.34 CIDEr score on the\nbenchmark news image captioning datasets. To the best of our knowledge, ours is\nthe first effort at incorporating contextual information in pretraining the\nmodels for the VL tasks.",
        "translated": "在企业内容(如营销材料)中形成良好的上下文感知图像标题和标签对于确保其品牌存在和内容召回至关重要。手工创建和更新，以确保相同的是不平凡的规模和乏味的这项任务。我们提出了一个新的统一的视觉语言(VL)模型的基础上的一个为所有(OFA)模型，重点是上下文辅助图像字幕生成的标题是基于图像和它的上下文。我们的方法旨在克服现有方法的上下文无关性(图像和文本是独立处理的)。我们利用上下文预训练我们的模型与三个任务的数据集: 新闻图像字幕，其中的新闻文章是上下文，上下文视觉暗示，和关键字提取从上下文。第二个预训练任务是一个新的 VL 任务，我们用1.1 M 和2.2 K 的数据实例构造并发布了两个任务数据集。我们的系统取得了最先进的成果，在基准的新闻图像字幕数据集上提高了高达8.34 CIDEr 得分。据我们所知，我们是第一次尝试将上下文信息合并到 VL 任务的模型预训练中。"
    },
    {
        "title": "Minding Language Models' (Lack of) Theory of Mind: A Plug-and-Play\n  Multi-Character Belief Tracker",
        "url": "http://arxiv.org/abs/2306.00924v1",
        "pub_date": "2023-06-01",
        "summary": "Theory of Mind (ToM)$\\unicode{x2014}$the ability to reason about the mental\nstates of other people$\\unicode{x2014}$is a key element of our social\nintelligence. Yet, despite their ever more impressive performance, large-scale\nneural language models still lack basic theory of mind capabilities\nout-of-the-box. We posit that simply scaling up models will not imbue them with\ntheory of mind due to the inherently symbolic and implicit nature of the\nphenomenon, and instead investigate an alternative: can we design a\ndecoding-time algorithm that enhances theory of mind of off-the-shelf neural\nlanguage models without explicit supervision? We present SymbolicToM, a\nplug-and-play approach to reason about the belief states of multiple characters\nin reading comprehension tasks via explicit symbolic representation. More\nconcretely, our approach tracks each entity's beliefs, their estimation of\nother entities' beliefs, and higher-order levels of reasoning, all through\ngraphical representations, allowing for more precise and interpretable\nreasoning than previous approaches. Empirical results on the well-known ToMi\nbenchmark (Le et al., 2019) demonstrate that SymbolicToM dramatically enhances\noff-the-shelf neural networks' theory of mind in a zero-shot setting while\nshowing robust out-of-distribution performance compared to supervised\nbaselines. Our work also reveals spurious patterns in existing theory of mind\nbenchmarks, emphasizing the importance of out-of-distribution evaluation and\nmethods that do not overfit a particular dataset.",
        "translated": "心理理论对他人心理状态进行推理的能力是我们社会智力的一个关键因素。然而，尽管大规模神经语言模型的表现越来越令人印象深刻，它们仍然缺乏开箱即用的思维能力的基本理论。我们假定，由于这种现象固有的象征性和隐含性，简单地扩大模型不会给它们灌输心智理论，而是研究另一种选择: 我们能否设计一种解码时间算法，在没有明确监督的情况下增强现成神经语言模型的心智理论？我们展示了 SymbolicToM，一种即插即用的方法，通过显式的符号表示来推断阅读理解任务中多个角色的信念状态。更具体地说，我们的方法跟踪每个实体的信念，他们对其他实体信念的估计，以及更高层次的推理，所有这些都通过图形表示，允许比以前的方法更精确和可解释的推理。著名的 ToMi 基准测试(Le et al。 ，2019)的实验结果表明，SymbolicToM 显著增强了现成的神经网络的心智理论，在零拍设置，同时显示出稳健的分布外性能相比，监督基线。我们的工作还揭示了现有心智基准理论中的虚假模式，强调了分布外评估的重要性，以及不适合特定数据集的方法。"
    },
    {
        "title": "T2IAT: Measuring Valence and Stereotypical Biases in Text-to-Image\n  Generation",
        "url": "http://arxiv.org/abs/2306.00905v1",
        "pub_date": "2023-06-01",
        "summary": "Warning: This paper contains several contents that may be toxic, harmful, or\noffensive.\n  In the last few years, text-to-image generative models have gained remarkable\nsuccess in generating images with unprecedented quality accompanied by a\nbreakthrough of inference speed. Despite their rapid progress, human biases\nthat manifest in the training examples, particularly with regard to common\nstereotypical biases, like gender and skin tone, still have been found in these\ngenerative models. In this work, we seek to measure more complex human biases\nexist in the task of text-to-image generations. Inspired by the well-known\nImplicit Association Test (IAT) from social psychology, we propose a novel\nText-to-Image Association Test (T2IAT) framework that quantifies the implicit\nstereotypes between concepts and valence, and those in the images. We replicate\nthe previously documented bias tests on generative models, including morally\nneutral tests on flowers and insects as well as demographic stereotypical tests\non diverse social attributes. The results of these experiments demonstrate the\npresence of complex stereotypical behaviors in image generations.",
        "translated": "警告: 本文件含有多种内容，可能是有毒的，有害的，或攻击性。在过去的几年中，文本到图像的生成模型在生成具有前所未有质量的图像方面取得了显著的成功，同时推理速度也有了突破。尽管进展迅速，但在这些生成模型中仍然发现了在训练实例中表现出来的人为偏见，特别是在性别和肤色等常见的陈规定型偏见方面。在这项工作中，我们试图测量更复杂的人类偏见存在于文本到图像的生成任务。受到来自社会心理学的著名隐含尺度(IAT)的启发，我们提出了一个新颖的文本-图像关联测试(t2IAT)框架，它量化了概念和效价之间以及图像中的内隐刻板印象。我们在生殖模型上重复之前记录的偏见测试，包括对花和昆虫的道德中立测试，以及对不同社会属性的人口统计学刻板印象测试。实验结果表明，在图像生成过程中存在复杂的刻板印象行为。"
    },
    {
        "title": "LLaVA-Med: Training a Large Language-and-Vision Assistant for\n  Biomedicine in One Day",
        "url": "http://arxiv.org/abs/2306.00890v1",
        "pub_date": "2023-06-01",
        "summary": "Conversational generative AI has demonstrated remarkable promise for\nempowering biomedical practitioners, but current investigations focus on\nunimodal text. Multimodal conversational AI has seen rapid progress by\nleveraging billions of image-text pairs from the public web, but such\ngeneral-domain vision-language models still lack sophistication in\nunderstanding and conversing about biomedical images. In this paper, we propose\na cost-efficient approach for training a vision-language conversational\nassistant that can answer open-ended research questions of biomedical images.\nThe key idea is to leverage a large-scale, broad-coverage biomedical\nfigure-caption dataset extracted from PubMed Central, use GPT-4 to\nself-instruct open-ended instruction-following data from the captions, and then\nfine-tune a large general-domain vision-language model using a novel curriculum\nlearning method. Specifically, the model first learns to align biomedical\nvocabulary using the figure-caption pairs as is, then learns to master\nopen-ended conversational semantics using GPT-4 generated instruction-following\ndata, broadly mimicking how a layperson gradually acquires biomedical\nknowledge. This enables us to train a Large Language and Vision Assistant for\nBioMedicine (LLaVA-Med) in less than 15 hours (with eight A100s). LLaVA-Med\nexhibits excellent multimodal conversational capability and can follow\nopen-ended instruction to assist with inquiries about a biomedical image. On\nthree standard biomedical visual question answering datasets, LLaVA-Med\noutperforms previous supervised state-of-the-art on certain metrics. To\nfacilitate biomedical multimodal research, we will release our\ninstruction-following data and the LLaVA-Med model.",
        "translated": "对话生成 AI 已经显示了赋予生物医学从业人员显着的前景，但目前的研究侧重于单一模式的文本。通过利用来自公共网络的数十亿个图像-文本对，多模式会话人工智能已经取得了迅速的进展，但是这种通用领域的视觉-语言模型在理解和对生物医学图像进行会话方面仍然缺乏先进性。本文针对生物医学图像的开放式研究问题，提出了一种具有成本效益的视觉语言会话助手培训方法。其关键思想是利用从 PubMed Central 提取的大规模、广泛覆盖的生物医学图形标题数据集，使用 GPT-4自我指导开放式教学——跟随标题中的数据，然后使用新的课程学习方法微调大型通用领域视觉语言模型。具体而言，该模型首先学习使用图标-标题对来校准生物医学词汇，然后学习使用 GPT-4生成的指令跟踪数据来掌握开放式会话语义，广泛地模仿外行如何逐渐获得生物医学知识。这使得我们能够在不到15个小时的时间内培训一个大型语言和视觉生物医学助手(LLaVA-Med)(有8个 A100s)。LLaVA-Med 具有优秀的多通道会话能力，可以遵循开放式指导，以协助有关生物医学图像的查询。在三个标准的生物医学视觉问答数据集上，LLaVA-Med 在某些指标上优于先前监督的最先进水平。为了促进生物医学多模式研究，我们将发布我们的指令跟踪数据和 LLaVA-Med 模型。"
    },
    {
        "title": "Fresh Content Needs More Attention: Multi-funnel Fresh Content\n  Recommendation",
        "url": "http://arxiv.org/abs/2306.01720v1",
        "pub_date": "2023-06-02",
        "summary": "Recommendation system serves as a conduit connecting users to an incredibly\nlarge, diverse and ever growing collection of contents. In practice, missing\ninformation on fresh (and tail) contents needs to be filled in order for them\nto be exposed and discovered by their audience. We here share our success\nstories in building a dedicated fresh content recommendation stack on a large\ncommercial platform. To nominate fresh contents, we built a multi-funnel\nnomination system that combines (i) a two-tower model with strong\ngeneralization power for coverage, and (ii) a sequence model with near\nreal-time update on user feedback for relevance. The multi-funnel setup\neffectively balances between coverage and relevance. An in-depth study uncovers\nthe relationship between user activity level and their proximity toward fresh\ncontents, which further motivates a contextual multi-funnel setup. Nominated\nfresh candidates are then scored and ranked by systems considering prediction\nuncertainty to further bootstrap content with less exposure. We evaluate the\nbenefits of the dedicated fresh content recommendation stack, and the\nmulti-funnel nomination system in particular, through user corpus co-diverted\nlive experiments. We conduct multiple rounds of live experiments on a\ncommercial platform serving billion of users demonstrating efficacy of our\nproposed methods.",
        "translated": "推荐系统作为一个渠道，连接用户到一个令人难以置信的庞大，多样化和不断增长的内容集合。在实践中，需要填补关于新鲜(和尾部)内容的缺失信息，以便它们被观众暴露和发现。我们在这里分享我们在一个大型商业平台上建立一个专门的新内容推荐堆栈的成功故事。为了提名新的内容，我们建立了一个多漏斗提名系统，该系统结合了(i)一个具有很强覆盖泛化能力的双塔模型和(ii)一个具有近实时更新用户反馈相关性的序列模型。多漏斗设置有效地平衡了覆盖率和相关性。深入的研究揭示了用户活动水平与其接近新鲜内容之间的关系，进一步激发了上下文多漏斗设置。提名的新鲜候选人，然后得分和排名的系统考虑预测不确定性，以进一步引导内容，较少的曝光。我们通过用户语料库共转向现场实验，评估了专用新鲜内容推荐堆栈的优点，尤其是多漏斗提名系统。我们在一个为数十亿用户服务的商业平台上进行多轮实验，证明我们提出的方法的有效性。"
    },
    {
        "title": "Pretrained Language Model based Web Search Ranking: From Relevance to\n  Satisfaction",
        "url": "http://arxiv.org/abs/2306.01599v1",
        "pub_date": "2023-06-02",
        "summary": "Search engine plays a crucial role in satisfying users' diverse information\nneeds. Recently, Pretrained Language Models (PLMs) based text ranking models\nhave achieved huge success in web search. However, many state-of-the-art text\nranking approaches only focus on core relevance while ignoring other dimensions\nthat contribute to user satisfaction, e.g., document quality, recency,\nauthority, etc. In this work, we focus on ranking user satisfaction rather than\nrelevance in web search, and propose a PLM-based framework, namely SAT-Ranker,\nwhich comprehensively models different dimensions of user satisfaction in a\nunified manner. In particular, we leverage the capacities of PLMs on both\ntextual and numerical inputs, and apply a multi-field input that modularizes\neach dimension of user satisfaction as an input field. Overall, SAT-Ranker is\nan effective, extensible, and data-centric framework that has huge potential\nfor industrial applications. On rigorous offline and online experiments,\nSAT-Ranker obtains remarkable gains on various evaluation sets targeting\ndifferent dimensions of user satisfaction. It is now fully deployed online to\nimprove the usability of our search engine.",
        "translated": "搜索引擎在满足用户多样化的信息需求方面起着至关重要的作用。近年来，基于预训练语言模型(PLM)的文本排序模型在网络搜索领域取得了巨大的成功。然而，许多最先进的文本排名方法只关注核心相关性，而忽略了有助于用户满意度的其他方面，如文档质量、最新性、权威性等。在这项工作中，我们的重点是排名用户满意度而不是相关性的网络搜索，并提出了一个基于 PLM 的框架，即 SAT-Ranker，它综合模型的不同维度的用户满意度在统一的方式。特别是，我们利用 PLM 在文本和数字输入方面的能力，并应用多领域的输入，将用户满意度的每个维度模块化，作为输入领域。总的来说，SAT-Ranker 是一个有效的、可扩展的、以数据为中心的框架，在工业应用方面具有巨大的潜力。在严格的离线和在线实验中，SAT-Ranker 在针对不同用户满意度维度的各种评价集上取得了显著的效果。它现在已经完全部署在网上，以提高我们的搜索引擎的可用性。"
    },
    {
        "title": "Influence Maximization with Fairness at Scale (Extended Version)",
        "url": "http://arxiv.org/abs/2306.01587v1",
        "pub_date": "2023-06-02",
        "summary": "In this paper, we revisit the problem of influence maximization with\nfairness, which aims to select k influential nodes to maximise the spread of\ninformation in a network, while ensuring that selected sensitive user\nattributes are fairly affected, i.e., are proportionally similar between the\noriginal network and the affected users. Recent studies on this problem focused\nonly on extremely small networks, hence the challenge remains on how to achieve\na scalable solution, applicable to networks with millions or billions of nodes.\nWe propose an approach that is based on learning node representations for fair\nspread from diffusion cascades, instead of the social connectivity s.t. we can\ndeal with very large graphs. We propose two data-driven approaches: (a)\nfairness-based participant sampling (FPS), and (b) fairness as context (FAC).\nSpread related user features, such as the probability of diffusing information\nto others, are derived from the historical information cascades, using a deep\nneural network. The extracted features are then used in selecting influencers\nthat maximize the influence spread, while being also fair with respect to the\nchosen sensitive attributes. In FPS, fairness and cascade length information\nare considered independently in the decision-making process, while FAC\nconsiders these information facets jointly and considers correlations between\nthem. The proposed algorithms are generic and represent the first policy-driven\nsolutions that can be applied to arbitrary sets of sensitive attributes at\nscale. We evaluate the performance of our solutions on a real-world public\ndataset (Sina Weibo) and on a hybrid real-synthethic dataset (Digg), which\nexhibit all the facets that we exploit, namely diffusion network, diffusion\ntraces, and user profiles. These experiments show that our methods outperform\nthe state-the-art solutions in terms of spread, fairness, and scalability.",
        "translated": "本文重新讨论了公平影响最大化问题，其目的是选择 k 个有影响的节点以使网络中的信息传播最大化，同时确保选择的敏感用户属性受到相当大的影响，即原始网络与受影响用户之间的比例相似。最近关于这个问题的研究只集中在极小的网络上，因此挑战仍然是如何实现一个可伸缩的解决方案，适用于拥有数百万或数十亿个节点的网络。我们提出了一种基于学习节点表示的扩散级联公平扩散方法，代替了社会连通性方法，我们可以处理非常大的图。我们提出两种数据驱动的方法: (a)基于公平的参与者抽样(FPS)和(b)作为上下文的公平(FAC)。传播相关的用户特征，如向他人传播信息的概率，是从历史信息级联，使用深度神经网络推导出来的。然后将提取的特征用于选择影响者，使影响扩散最大化，同时对所选择的敏感属性也是公平的。在 FPS 中，公平性和级联长度信息在决策过程中被独立地考虑，而 FAC 则联合考虑这些信息方面，并考虑它们之间的相关性。提出的算法是通用的，代表了第一个策略驱动的解决方案，可以应用于任意集的敏感属性在规模。我们在一个真实世界的公共数据集(新浪微博)和一个混合的真实合成数据集(Digg)上评估我们的解决方案的性能，这些数据集展示了我们利用的所有方面，即扩散网络、扩散轨迹和用户配置文件。这些实验表明，我们的方法在扩展性、公平性和可伸缩性方面优于最先进的解决方案。"
    },
    {
        "title": "Système de recommandations basé sur les contraintes pour les\n  simulations de gestion de crise",
        "url": "http://arxiv.org/abs/2306.01504v1",
        "pub_date": "2023-06-02",
        "summary": "In the context of the evacuation of populations, some citizens/volunteers may\nwant and be able to participate in the evacuation of populations in difficulty\nby coming to lend a hand to emergency/evacuation vehicles with their own\nvehicles. One way of framing these impulses of solidarity would be to be able\nto list in real-time the citizens/volunteers available with their vehicles\n(land, sea, air, etc.), to be able to geolocate them according to the risk\nareas to be evacuated, and adding them to the evacuation/rescue vehicles.\nBecause it is difficult to propose an effective real-time operational system on\nthe field in a real crisis situation, in this work, we propose to add a module\nfor recommending driver/vehicle pairs (with their specificities) to a system of\ncrisis management simulation. To do that, we chose to model and develop an\nontology-supported constraint-based recommender system for crisis management\nsimulations.",
        "translated": "在疏散人口方面，一些公民/志愿人员可能希望并能够参与疏散有困难的人口，他们可以用自己的车辆向紧急/疏散车辆伸出援手。构建这些团结冲动的一种方式是能够实时列出可用车辆(陆地、海洋、空中等)的公民/志愿者，能够根据疏散的危险区域对他们进行地理定位，并将他们添加到疏散/救援车辆中。由于在真实的危机情况下很难提出一个有效的现场实时操作系统，本文提出在危机管理模拟系统中增加一个推荐驾驶员/车辆配对(及其特殊性)的模块。为此，我们选择建模和开发一个本体支持的基于约束的危机管理模拟推荐系统。"
    },
    {
        "title": "Hierarchical Reinforcement Learning for Modeling User Novelty-Seeking\n  Intent in Recommender Systems",
        "url": "http://arxiv.org/abs/2306.01476v1",
        "pub_date": "2023-06-02",
        "summary": "Recommending novel content, which expands user horizons by introducing them\nto new interests, has been shown to improve users' long-term experience on\nrecommendation platforms \\cite{chen2021values}. Users however are not\nconstantly looking to explore novel content. It is therefore crucial to\nunderstand their novelty-seeking intent and adjust the recommendation policy\naccordingly. Most existing literature models a user's propensity to choose\nnovel content or to prefer a more diverse set of recommendations at individual\ninteractions. Hierarchical structure, on the other hand, exists in a user's\nnovelty-seeking intent, which is manifested as a static and intrinsic user\npreference for seeking novelty along with a dynamic session-based propensity.\nTo this end, we propose a novel hierarchical reinforcement learning-based\nmethod to model the hierarchical user novelty-seeking intent, and to adapt the\nrecommendation policy accordingly based on the extracted user novelty-seeking\npropensity. We further incorporate diversity and novelty-related measurement in\nthe reward function of the hierarchical RL (HRL) agent to encourage user\nexploration \\cite{chen2021values}. We demonstrate the benefits of explicitly\nmodeling hierarchical user novelty-seeking intent in recommendations through\nextensive experiments on simulated and real-world datasets. In particular, we\ndemonstrate that the effectiveness of our proposed hierarchical RL-based method\nlies in its ability to capture such hierarchically-structured intent. As a\nresult, the proposed HRL model achieves superior performance on several public\ndatasets, compared with state-of-art baselines.",
        "translated": "推荐新颖的内容，通过引入新的兴趣拓展用户的视野，已经被证明可以改善用户在推荐平台上的长期体验。然而，用户并不总是寻找新奇的内容。因此，必须了解其寻求新颖性的意图，并相应调整建议政策。大多数现有的文献模拟了用户在个人交互中选择新颖内容或更喜欢多样化推荐的倾向。另一方面，层次结构存在于用户的猎奇意图中，表现为一种静态的、内在的用户猎奇偏好以及一种基于会话的动态倾向。为此，我们提出了一种新的基于层次强化学习的方法来建立层次用户查新意图模型，并根据提取出的用户查新意图相应地调整推荐策略。我们进一步将多样性和新颖性相关度量纳入层次 RL (HRL)代理的奖励功能，以鼓励用户探索引用{ Chen 2021value }。我们通过在模拟和真实世界数据集上的大量实验，展示了在推荐中明确建模分层用户猎奇意图的好处。特别地，我们证明了我们提出的基于层次 RL 的方法的有效性在于它能够捕获这种层次结构的意图。结果表明，所提出的 HRL 模型在多个公共数据集上取得了优于现有基线的性能。"
    },
    {
        "title": "Multilingual Conceptual Coverage in Text-to-Image Models",
        "url": "http://arxiv.org/abs/2306.01735v1",
        "pub_date": "2023-06-02",
        "summary": "We propose \"Conceptual Coverage Across Languages\" (CoCo-CroLa), a technique\nfor benchmarking the degree to which any generative text-to-image system\nprovides multilingual parity to its training language in terms of tangible\nnouns. For each model we can assess \"conceptual coverage\" of a given target\nlanguage relative to a source language by comparing the population of images\ngenerated for a series of tangible nouns in the source language to the\npopulation of images generated for each noun under translation in the target\nlanguage. This technique allows us to estimate how well-suited a model is to a\ntarget language as well as identify model-specific weaknesses, spurious\ncorrelations, and biases without a-priori assumptions. We demonstrate how it\ncan be used to benchmark T2I models in terms of multilinguality, and how\ndespite its simplicity it is a good proxy for impressive generalization.",
        "translated": "我们提出了“跨语言的概念覆盖”(CoCo-CroLa) ，一种基准测试的程度，任何生成性文本到图像系统提供多语言平等的训练语言在有形名词方面。对于每个模型，我们可以通过比较源语言中一系列有形名词生成的图像的总体与目标语言中翻译下的每个名词生成的图像的总体来评估给定目标语言相对于源语言的“概念覆盖”。这种技术使我们能够估计模型与目标语言的匹配程度，并且在没有先验假设的情况下识别特定于模型的弱点、虚假的相关性和偏差。我们展示了如何使用它来基准 T2I 模型的多语言性，以及如何尽管它的简单性，它是一个令人印象深刻的推广良好的代理。"
    },
    {
        "title": "DocFormerv2: Local Features for Document Understanding",
        "url": "http://arxiv.org/abs/2306.01733v1",
        "pub_date": "2023-06-02",
        "summary": "We propose DocFormerv2, a multi-modal transformer for Visual Document\nUnderstanding (VDU). The VDU domain entails understanding documents (beyond\nmere OCR predictions) e.g., extracting information from a form, VQA for\ndocuments and other tasks. VDU is challenging as it needs a model to make sense\nof multiple modalities (visual, language and spatial) to make a prediction. Our\napproach, termed DocFormerv2 is an encoder-decoder transformer which takes as\ninput - vision, language and spatial features. DocFormerv2 is pre-trained with\nunsupervised tasks employed asymmetrically i.e., two novel document tasks on\nencoder and one on the auto-regressive decoder. The unsupervised tasks have\nbeen carefully designed to ensure that the pre-training encourages\nlocal-feature alignment between multiple modalities. DocFormerv2 when evaluated\non nine datasets shows state-of-the-art performance over strong baselines e.g.\nTabFact (4.3%), InfoVQA (1.4%), FUNSD (1%). Furthermore, to show generalization\ncapabilities, on three VQA tasks involving scene-text, Doc- Formerv2\noutperforms previous comparably-sized models and even does better than much\nlarger models (such as GIT2, PaLi and Flamingo) on some tasks. Extensive\nablations show that due to its pre-training, DocFormerv2 understands multiple\nmodalities better than prior-art in VDU.",
        "translated": "我们提出 DocFormerv2，一个用于可视化文档理解(VDU)的多模式转换器。VDU 领域需要理解文档(超越单纯的 OCR 预测) ，例如，从表单中提取信息，文档的 VQA 和其他任务。VDU 是具有挑战性的，因为它需要一个模型来理解多种形式(视觉、语言和空间)来做出预测。我们的方法，称为 DocFormerv2是一个编码器-解码器转换器，它采取作为输入-视觉，语言和空间特征。DocFormerv2预先训练了非对称使用的非监督任务，即编码器上的两个新的文档任务和自动回归解码器上的一个任务。这些无监督的任务经过精心设计，以确保预先培训鼓励多种模式之间的局部特征对齐。对9个数据集进行评估后，DocFormerv2显示出超过强基线的最先进性能，例如 TabFact (4.3%) ，InfoVQA (1.4%) ，FUNSD (1%)。此外，为了显示泛化能力，在涉及场景文本的三个 VQA 任务中，Doc-Formerv2在一些任务中表现优于以前的同等大小的模型，甚至优于更大的模型(如 GIT2、 PaLi 和 Flamingo)。广泛的消融表明，由于其预先培训，DocFormerv2了解多种形式更好地比先前的技术在 VDU。"
    },
    {
        "title": "Improving Generalization in Task-oriented Dialogues with Workflows and\n  Action Plans",
        "url": "http://arxiv.org/abs/2306.01729v1",
        "pub_date": "2023-06-02",
        "summary": "Task-oriented dialogue is difficult in part because it involves understanding\nuser intent, collecting information from the user, executing API calls, and\ngenerating helpful and fluent responses. However, for complex tasks one must\nalso correctly do all of these things over multiple steps, and in a specific\norder. While large pre-trained language models can be fine-tuned end-to-end to\ncreate multi-step task-oriented dialogue agents that generate fluent text, our\nexperiments confirm that this approach alone cannot reliably perform new\nmulti-step tasks that are unseen during training. To address these limitations,\nwe augment the dialogue contexts given to \\textmd{text2text} transformers with\nknown \\textit{valid workflow names} and \\textit{action plans}. Action plans\nconsist of sequences of actions required to accomplish a task, and are encoded\nas simple sequences of keywords (e.g. verify-identity, pull-up-account,\nreset-password, etc.). We perform extensive experiments on the Action-Based\nConversations Dataset (ABCD) with T5-small, base and large models, and show\nthat such models: a) are able to more readily generalize to unseen workflows by\nfollowing the provided plan, and b) are able to generalize to executing unseen\nactions if they are provided in the plan. In contrast, models are unable to\nfully accomplish new multi-step tasks when they are not provided action plan\ninformation, even when given new valid workflow names.",
        "translated": "面向任务的对话之所以困难，部分原因在于它涉及到理解用户的意图、从用户那里收集信息、执行 API 调用以及生成有用而流畅的响应。然而，对于复杂的任务，人们还必须在多个步骤中以特定的顺序正确地完成所有这些事情。虽然大型预先训练的语言模型可以进行端到端的微调，以创建多步骤任务导向的对话代理，生成流畅的文本，我们的实验证实，这种方法本身不能可靠地执行新的多步骤任务，在培训期间看不到。为了解决这些限制，我们使用已知的 texttit {有效的工作流名称}和 texttit {操作计划}增加了为 textmd { text2text }转换器提供的对话上下文。行动计划由完成任务所需的一系列行动组成，并被编码为简单的关键字序列(例如验证身份、上拉帐户、重置密码等)。我们在基于行动的对话数据集(ABCD)上对 T5-小型、基础和大型模型进行了广泛的实验，并表明这样的模型: a)能够通过遵循提供的计划更容易地推广到不可见的工作流，b)能够推广到执行不可见的行动，如果它们在计划中提供。相比之下，模型不能完全完成新的多步骤任务，如果没有提供行动计划信息，即使给出了新的有效工作流名称。"
    },
    {
        "title": "Distilling Efficient Language-Specific Models for Cross-Lingual Transfer",
        "url": "http://arxiv.org/abs/2306.01709v1",
        "pub_date": "2023-06-02",
        "summary": "Massively multilingual Transformers (MMTs), such as mBERT and XLM-R, are\nwidely used for cross-lingual transfer learning. While these are pretrained to\nrepresent hundreds of languages, end users of NLP systems are often interested\nonly in individual languages. For such purposes, the MMTs' language coverage\nmakes them unnecessarily expensive to deploy in terms of model size, inference\ntime, energy, and hardware cost. We thus propose to extract compressed,\nlanguage-specific models from MMTs which retain the capacity of the original\nMMTs for cross-lingual transfer. This is achieved by distilling the MMT\nbilingually, i.e., using data from only the source and target language of\ninterest. Specifically, we use a two-phase distillation approach, termed\nBiStil: (i) the first phase distils a general bilingual model from the MMT,\nwhile (ii) the second, task-specific phase sparsely fine-tunes the bilingual\n\"student\" model using a task-tuned variant of the original MMT as its\n\"teacher\". We evaluate this distillation technique in zero-shot cross-lingual\ntransfer across a number of standard cross-lingual benchmarks. The key results\nindicate that the distilled models exhibit minimal degradation in target\nlanguage performance relative to the base MMT despite being significantly\nsmaller and faster. Furthermore, we find that they outperform multilingually\ndistilled models such as DistilmBERT and MiniLMv2 while having a very modest\ntraining budget in comparison, even on a per-language basis. We also show that\nbilingual models distilled from MMTs greatly outperform bilingual models\ntrained from scratch. Our code and models are available at\nhttps://github.com/AlanAnsell/bistil.",
        "translated": "大规模多语言变换器(MMT) ，如 mBERT 和 XLM-R，被广泛用于跨语言迁移学习。虽然这些语言已经被预先训练成可以代表数百种语言，但是 NLP 系统的最终用户通常只对个别语言感兴趣。出于这样的目的，MMT 的语言覆盖率使得它们在模型大小、推理时间、能量和硬件成本方面的部署成本不必要地昂贵。因此，我们建议从 MMT 中提取压缩的、特定于语言的模型，这些模型保留了原始 MMT 的跨语言迁移能力。这是通过提取双语的 MMT 来实现的，也就是说，只使用感兴趣的源语言和目标语言的数据。具体而言，我们使用两阶段精馏方法，称为 BiStil: (i)第一阶段从 MMT 中提取一般的双语模型，而(ii)第二阶段，任务特定阶段使用原始 MMT 的任务调整变体作为其“老师”稀疏地微调双语“学生”模型。我们评估了这种蒸馏技术在零拍跨语言传输跨一些标准的跨语言基准。实验结果表明，相对于基本 MMT，提取出的模型尽管具有显著的更小和更快的性能，但是在目标语言性能方面表现出最小的退化。此外，我们发现它们的表现优于多语言蒸馏模型，如 DistilmBERT 和 MiniLMv2，同时具有非常有限的培训预算相比，即使在每种语言的基础上。我们还表明，从 MMT 中提炼出来的双语模型比从头开始训练的双语模型的表现要好得多。我们的代码和模型可在 https://github.com/alanansell/bistil 获得。"
    },
    {
        "title": "Resolving Interference When Merging Models",
        "url": "http://arxiv.org/abs/2306.01708v1",
        "pub_date": "2023-06-02",
        "summary": "Transfer learning - i.e., further fine-tuning a pre-trained model on a\ndownstream task - can confer significant advantages, including improved\ndownstream performance, faster convergence, and better sample efficiency. These\nadvantages have led to a proliferation of task-specific fine-tuned models,\nwhich typically can only perform a single task and do not benefit from one\nanother. Recently, model merging techniques have emerged as a solution to\ncombine multiple task-specific models into a single multitask model without\nperforming additional training. However, existing merging methods often ignore\nthe interference between parameters of different models, resulting in large\nperformance drops when merging multiple models. In this paper, we demonstrate\nthat prior merging techniques inadvertently lose valuable information due to\ntwo major sources of interference: (a) interference due to redundant parameter\nvalues and (b) disagreement on the sign of a given parameter's values across\nmodels. To address this, we propose our method, TrIm, Elect Sign &amp; Merge\n(TIES-Merging), which introduces three novel steps when merging models: (1)\nresetting parameters that only changed a small amount during fine-tuning, (2)\nresolving sign conflicts, and (3) merging only the parameters that are in\nalignment with the final agreed-upon sign. We find that TIES-Merging\noutperforms several existing methods in diverse settings covering a range of\nmodalities, domains, number of tasks, model sizes, architectures, and\nfine-tuning settings. We further analyze the impact of different types of\ninterference on model parameters, highlight the importance of resolving sign\ninterference. Our code is available at\nhttps://github.com/prateeky2806/ties-merging",
        "translated": "转移学习——即进一步微调下游任务的预先训练的模型——可以带来显著的优势，包括改善下游性能、加快收敛速度和提高采样效率。这些优势导致了特定于任务的微调模型的激增，这些模型通常只能执行单个任务，并且不能从彼此中受益。最近，模型合并技术已经成为一种解决方案，可以将多个任务特定的模型合并成一个单一的多任务模型，而不需要进行额外的训练。然而，现有的合并方法往往忽略了不同模型参数之间的干扰，导致合并多个模型时性能大幅度下降。在本文中，我们证明了先前的合并技术无意中失去了有价值的信息，由于两个主要的干扰来源: (a)由于冗余参数值的干扰和(b)在给定的参数值的符号不一致跨模型。为了解决这个问题，我们提出了我们的方法，TrIm，Elect Sign & Merge (TIES-Merging) ，它在合并模型时引入了三个新的步骤: (1)重置在微调过程中只改变了很少量的参数，(2)解决符号冲突，(3)只合并与最终达成一致的符号一致的参数。我们发现 TIES-Merging 在不同的设置中优于几种现有的方法，包括一系列模式、领域、任务数量、模型大小、架构和微调设置。进一步分析了不同类型的干扰对模型参数的影响，强调了解决符号干扰的重要性。我们的代码可以在 https://github.com/prateeky2806/ties-merging 找到"
    },
    {
        "title": "Learning Multi-step Reasoning from Arithmetic Task",
        "url": "http://arxiv.org/abs/2306.01707v1",
        "pub_date": "2023-06-02",
        "summary": "Mathematical reasoning is regarded as a necessary ability for Language Models\n(LMs). Recent works demonstrate large LMs' impressive performance in solving\nmath problems. The success is attributed to their Chain-of-Thought (CoT)\nreasoning abilities, i.e., the ability to decompose complex questions into\nstep-by-step reasoning chains, but such ability seems only to emerge from\nmodels with abundant parameters. This work investigates how to incorporate\nrelatively small LMs with the capabilities of multi-step reasoning. We propose\nto inject such abilities by continually pre-training LMs on a synthetic dataset\nMsAT, which stands for Multi-step Arithmetic Task. Our experiments on four math\nword problem datasets show the effectiveness of the proposed method in\nenhancing LMs' math reasoning abilities.",
        "translated": "数学推理被认为是语言模型(LM)的必备能力。最近的作品展示了大型 LM 在解决数学问题方面令人印象深刻的表现。这一成功归功于他们的思维链(Chain-of-Thought，CoT)推理能力，即将复杂问题分解为逐步推理链的能力，但这种能力似乎只出现在参数丰富的模型中。本文研究如何将相对较小的线性规划模型与多步推理能力结合起来。我们建议通过在一个合成数据集 MsAT 上连续预训练 LM 来注入这种能力，MsAT 表示多步算术任务。我们在四个数学词汇问题数据集上的实验表明了该方法在提高 LM 数学推理能力方面的有效性。"
    },
    {
        "title": "Fine-Grained Human Feedback Gives Better Rewards for Language Model\n  Training",
        "url": "http://arxiv.org/abs/2306.01693v1",
        "pub_date": "2023-06-02",
        "summary": "Language models (LMs) often exhibit undesirable text generation behaviors,\nincluding generating false, toxic, or irrelevant outputs. Reinforcement\nlearning from human feedback (RLHF) - where human preference judgments on LM\noutputs are transformed into a learning signal - has recently shown promise in\naddressing these issues. However, such holistic feedback conveys limited\ninformation on long text outputs; it does not indicate which aspects of the\noutputs influenced user preference; e.g., which parts contain what type(s) of\nerrors. In this paper, we use fine-grained human feedback (e.g., which sentence\nis false, which sub-sentence is irrelevant) as an explicit training signal. We\nintroduce Fine-Grained RLHF, a framework that enables training and learning\nfrom reward functions that are fine-grained in two respects: (1) density,\nproviding a reward after every segment (e.g., a sentence) is generated; and (2)\nincorporating multiple reward models associated with different feedback types\n(e.g., factual incorrectness, irrelevance, and information incompleteness). We\nconduct experiments on detoxification and long-form question answering to\nillustrate how learning with such reward functions leads to improved\nperformance, supported by both automatic and human evaluation. Additionally, we\nshow that LM behaviors can be customized using different combinations of\nfine-grained reward models. We release all data, collected human feedback, and\ncodes at https://FineGrainedRLHF.github.io.",
        "translated": "语言模型(LM)经常表现出不良的文本生成行为，包括生成错误的、有毒的或不相关的输出。人类反馈的强化学习——人类对 LM 输出的偏好判断被转化为一个学习信号——最近在解决这些问题方面显示出了希望。然而，这样的整体反馈传达了关于长文本输出的有限信息; 它没有指出输出的哪些方面影响了用户的偏好; 例如，哪些部分包含哪些类型的错误。在本文中，我们使用细粒度的人反馈(例如，哪个句子是错误的，哪个子句是不相关的)作为显性训练信号。我们介绍了细粒度 RLHF，一个框架，使培训和学习奖励功能的细粒度在两个方面: (1)密度，提供奖励后，每个部分(例如，一个句子)生成; 和(2)结合多个奖励模型与不同的反馈类型(例如，事实不正确，不相关性和信息不完整)。我们进行了解毒实验和长形式的问题回答，以说明如何学习与这种奖励功能导致提高绩效，支持自动和人类的评价。此外，我们表明，LM 行为可以定制使用细粒度奖励模型的不同组合。我们发布所有数据，收集人类反馈，并在 https://finegrainedrlhf.github.io 代码。"
    },
    {
        "title": "DiffusEmp: A Diffusion Model-Based Framework with Multi-Grained Control\n  for Empathetic Response Generation",
        "url": "http://arxiv.org/abs/2306.01657v1",
        "pub_date": "2023-06-02",
        "summary": "Empathy is a crucial factor in open-domain conversations, which naturally\nshows one's caring and understanding to others. Though several methods have\nbeen proposed to generate empathetic responses, existing works often lead to\nmonotonous empathy that refers to generic and safe expressions. In this paper,\nwe propose to use explicit control to guide the empathy expression and design a\nframework DiffusEmp based on conditional diffusion language model to unify the\nutilization of dialogue context and attribute-oriented control signals.\nSpecifically, communication mechanism, intent, and semantic frame are imported\nas multi-grained signals that control the empathy realization from coarse to\nfine levels. We then design a specific masking strategy to reflect the\nrelationship between multi-grained signals and response tokens, and integrate\nit into the diffusion model to influence the generative process. Experimental\nresults on a benchmark dataset EmpatheticDialogue show that our framework\noutperforms competitive baselines in terms of controllability, informativeness,\nand diversity without the loss of context-relatedness.",
        "translated": "移情是开放领域对话中的一个关键因素，它自然而然地表现出一个人对他人的关心和理解。虽然已经提出了一些方法来产生移情反应，现有的作品往往导致单调的移情，涉及通用和安全的表达。本文提出用显式控制来引导移情表达，并设计了一个基于条件扩散语言模型的扩散映射框架，统一了对话上下文和面向属性控制信号的利用。具体来说，引入交流机制、意图和语义框架作为多粒度信号，从粗到细控制移情实现。然后我们设计了一个特定的掩蔽策略来反映多粒度信号和响应标记之间的关系，并将其整合到扩散模型中以影响生成过程。在一个基准数据集 EmpatheticDialogue 上的实验结果表明，我们的框架在可控性、信息性和多样性方面优于竞争性基准，而且没有丧失上下文相关性。"
    },
    {
        "title": "Learning from Partially Annotated Data: Example-aware Creation of\n  Gap-filling Exercises for Language Learning",
        "url": "http://arxiv.org/abs/2306.01584v1",
        "pub_date": "2023-06-02",
        "summary": "Since performing exercises (including, e.g., practice tests) forms a crucial\ncomponent of learning, and creating such exercises requires non-trivial effort\nfrom the teacher. There is a great value in automatic exercise generation in\ndigital tools in education. In this paper, we particularly focus on automatic\ncreation of gapfilling exercises for language learning, specifically grammar\nexercises. Since providing any annotation in this domain requires human expert\neffort, we aim to avoid it entirely and explore the task of converting existing\ntexts into new gap-filling exercises, purely based on an example exercise,\nwithout explicit instruction or detailed annotation of the intended grammar\ntopics. We contribute (i) a novel neural network architecture specifically\ndesigned for aforementioned gap-filling exercise generation task, and (ii) a\nreal-world benchmark dataset for French grammar. We show that our model for\nthis French grammar gap-filling exercise generation outperforms a competitive\nbaseline classifier by 8% in F1 percentage points, achieving an average F1\nscore of 82%. Our model implementation and the dataset are made publicly\navailable to foster future research, thus offering a standardized evaluation\nand baseline solution of the proposed partially annotated data prediction task\nin grammar exercise creation.",
        "translated": "因为做练习(包括，例如，练习测试)是学习的重要组成部分，而创建这样的练习需要老师付出非凡的努力。数字化练习工具的自动生成在教育中具有重要的应用价值。在本文中，我们特别关注于语言学习中填空练习的自动生成，尤其是语法练习。由于在这个领域提供任何注释都需要人类专家的努力，我们的目标是完全避免它，并探索将现有文本转换为新的填补空白练习的任务，纯粹基于一个示例练习，没有明确的指示或预期的语法主题的详细注释。我们贡献了(i)一个新的神经网络架构，专门设计的上述缺口填补练习生成任务，和(ii)法语语法的现实世界基准数据集。我们表明，我们的模型为这个法语语法差距填补练习生成优于竞争性基线分类器8% 的 F1百分点，实现平均 F1得分为82% 。我们的模型实现和数据集是公开的，以促进未来的研究，从而提供了一个标准化的评价和基线解决方案的建议部分注释数据预测任务在语法练习创建。"
    },
    {
        "title": "EmoUS: Simulating User Emotions in Task-Oriented Dialogues",
        "url": "http://arxiv.org/abs/2306.01579v1",
        "pub_date": "2023-06-02",
        "summary": "Existing user simulators (USs) for task-oriented dialogue systems only model\nuser behaviour on semantic and natural language levels without considering the\nuser persona and emotions. Optimising dialogue systems with generic user\npolicies, which cannot model diverse user behaviour driven by different\nemotional states, may result in a high drop-off rate when deployed in the real\nworld. Thus, we present EmoUS, a user simulator that learns to simulate user\nemotions alongside user behaviour. EmoUS generates user emotions, semantic\nactions, and natural language responses based on the user goal, the dialogue\nhistory, and the user persona. By analysing what kind of system behaviour\nelicits what kind of user emotions, we show that EmoUS can be used as a probe\nto evaluate a variety of dialogue systems and in particular their effect on the\nuser's emotional state. Developing such methods is important in the age of\nlarge language model chat-bots and rising ethical concerns.",
        "translated": "现有的面向任务对话系统的用户模拟器(USs)只是在语义和自然语言层面上对用户行为进行建模，而没有考虑用户角色和情感。使用通用用户策略优化对话系统，不能模拟由不同情绪状态驱动的不同用户行为，在现实世界中部署时可能导致较高的下降率。因此，我们提出了 emoUS，一个用户模拟器，学习模拟用户的情绪以及用户的行为。基于用户目标、对话历史和用户角色，EmoUS 产生用户情绪、语义动作和自然语言反应。通过分析什么样的系统行为引发了什么样的用户情绪，我们表明，情绪美可以作为一个探测器来评估各种对话系统，特别是他们对用户的情绪状态的影响。在大型语言模型聊天机器人时代，开发这样的方法非常重要，同时也引起了越来越多的道德关注。"
    },
    {
        "title": "Learning Similarity among Users for Personalized Session-Based\n  Recommendation from hierarchical structure of User-Session-Item",
        "url": "http://arxiv.org/abs/2306.03040v1",
        "pub_date": "2023-06-05",
        "summary": "The task of the session-based recommendation is to predict the next\ninteraction of the user based on the anonymized user's behavior pattern. And\npersonalized version of this system is a promising research field due to its\navailability to deal with user information. However, there's a problem that the\nuser's preferences and historical sessions were not considered in the typical\nsession-based recommendation since it concentrates only on user-item\ninteraction. In addition, the existing personalized session-based\nrecommendation model has a limited capability in that it only considers the\npreference of the current user without considering those of similar users. It\nmeans there can be the loss of information included within the hierarchical\ndata structure of the user-session-item. To tackle with this problem, we\npropose USP-SBR(abbr. of User Similarity Powered - Session Based Recommender).\nTo model global historical sessions of users, we propose UserGraph that has two\ntypes of nodes - ItemNode and UserNode. We then connect the nodes with three\ntypes of edges. The first type of edges connects ItemNode as chronological\norder, and the second connects ItemNode to UserNode, and the last connects\nUserNode to ItemNode. With these user embeddings, we propose additional\ncontrastive loss, that makes users with similar intention be close to each\nother in the vector space. we apply graph neural network on these UserGraph and\nupdate nodes. Experimental results on two real-world datasets demonstrate that\nour method outperforms some state-of-the-art approaches.",
        "translated": "基于会话的推荐的任务是根据匿名用户的行为模式预测用户的下一次交互。而个性化版本的系统由于能够有效地处理用户信息，是一个很有前途的研究领域。然而，有一个问题，在典型的基于会话的推荐中没有考虑用户的首选项和历史会话，因为它只关注用户项交互。此外，现有的基于个性化会话的推荐模型能力有限，因为它只考虑当前用户的偏好，而不考虑相似用户的偏好。这意味着用户会话项的分层数据结构中包含的信息可能会丢失。为了解决这一问题，我们提出了 USP-SBR (abbr。基于用户相似度的动态会话推荐程序)。为了对用户的全局历史会话进行建模，我们提出了具有两种类型节点的 UserGraph —— ItemNode 和 UserNode。然后我们用三种边连接节点。第一种边以时间顺序连接 ItemNode，第二种边将 ItemNode 连接到 UserNode，最后一种边将 UserNode 连接到 ItemNode。通过这些用户嵌入，我们提出了额外的对比损失，使得具有相似意图的用户在向量空间中更加接近。我们将图形神经网络应用于这些用户图和更新节点。在两个实际数据集上的实验结果表明，我们的方法优于一些最先进的方法。"
    },
    {
        "title": "Gen-IR @ SIGIR 2023: The First Workshop on Generative Information\n  Retrieval",
        "url": "http://arxiv.org/abs/2306.02887v1",
        "pub_date": "2023-06-05",
        "summary": "Generative information retrieval (IR) has experienced substantial growth\nacross multiple research communities (e.g., information retrieval, computer\nvision, natural language processing, and machine learning), and has been highly\nvisible in the popular press. Theoretical, empirical, and actual user-facing\nproducts have been released that retrieve documents (via generation) or\ndirectly generate answers given an input request. We would like to investigate\nwhether end-to-end generative models are just another trend or, as some claim,\na paradigm change for IR. This necessitates new metrics, theoretical grounding,\nevaluation methods, task definitions, models, user interfaces, etc. The goal of\nthis workshop (https://coda.io/@sigir/gen-ir) is to focus on previously\nexplored Generative IR techniques like document retrieval and direct Grounded\nAnswer Generation, while also offering a venue for the discussion and\nexploration of how Generative IR can be applied to new domains like\nrecommendation systems, summarization, etc. The format of the workshop is\ninteractive, including roundtable and keynote sessions and tends to avoid the\none-sided dialogue of a mini-conference.",
        "translated": "生成信息检索在多个研究领域(如信息检索、计算机视觉、自然语言处理和机器学习)都经历了实质性的增长，并且在大众媒体上非常明显。理论、经验和实际的面向用户的产品已经发布，检索文档(通过生成)或直接生成给定输入请求的答案。我们想要研究的是，端到端的生成模型是否只是另一种趋势，或者，正如一些人声称的，一个范式变化的 IR。这就需要新的指标、理论基础、评估方法、任务定义、模型、用户界面等。这个研讨会( https://coda.io/@sigir/gen-IR )的目标是专注于先前探索的生成性信息检索技术，如文献检索和直接接地的答案生成，同时也为讨论和探索生成性信息检索如何应用于新的领域，如推荐系统，摘要等提供了场所。讲习班的形式是互动的，包括圆桌会议和主旨会议，往往避免小型会议的单方面对话。"
    },
    {
        "title": "Benchmarking Middle-Trained Language Models for Neural Search",
        "url": "http://arxiv.org/abs/2306.02867v1",
        "pub_date": "2023-06-05",
        "summary": "Middle training methods aim to bridge the gap between the Masked Language\nModel (MLM) pre-training and the final finetuning for retrieval. Recent models\nsuch as CoCondenser, RetroMAE, and LexMAE argue that the MLM task is not\nsufficient enough to pre-train a transformer network for retrieval and hence\npropose various tasks to do so. Intrigued by those novel methods, we noticed\nthat all these models used different finetuning protocols, making it hard to\nassess the benefits of middle training. We propose in this paper a benchmark of\nCoCondenser, RetroMAE, and LexMAE, under the same finetuning conditions. We\ncompare both dense and sparse approaches under various finetuning protocols and\nmiddle training on different collections (MS MARCO, Wikipedia or Tripclick). We\nuse additional middle training baselines, such as a standard MLM finetuning on\nthe retrieval collection, optionally augmented by a CLS predicting the passage\nterm frequency. For the sparse approach, our study reveals that there is almost\nno statistical difference between those methods: the more effective the\nfinetuning procedure is, the less difference there is between those models. For\nthe dense approach, RetroMAE using MS MARCO as middle-training collection shows\nexcellent results in almost all the settings. Finally, we show that middle\ntraining on the retrieval collection, thus adapting the language model to it,\nis a critical factor. Overall, a better experimental setup should be adopted to\nevaluate middle training methods. Code available at\nhttps://github.com/naver/splade/tree/benchmarch-SIGIR23",
        "translated": "中间训练方法旨在弥补蒙版语言模型(MLM)预训练和检索的最终微调之间的差距。最近的一些模型，如 CoCondenser，RotMAE 和 LexMAE 认为传销任务不足以预先训练一个变压器网络进行检索，因此提出了各种各样的任务来这样做。被这些新奇的方法所吸引，我们注意到所有这些模型使用不同的微调协议，使得评估中间训练的好处变得困难。在本文中，我们提出了一个基准的协同凝聚器，反向 MAE 和 LexMAE，在相同的微调条件下。我们比较了在各种微调协议和不同集合(MS MARCO，Wikipedia 或 Tripclick)的中间培训下的密集和稀疏方法。我们使用额外的中间训练基线，例如在检索集合上的标准 MLM 微调，可选地通过预测通过项频率的 CLS 加强。对于稀疏方法，我们的研究表明，这些方法之间几乎没有统计上的差异: 微调过程越有效，这些模型之间的差异就越小。对于密集的方法，使用 MS MARCO 作为中间训练收集在几乎所有的设置中都显示出优异的结果。最后，我们表明，中间训练的检索集，从而使语言模型适应它，是一个关键因素。总的来说，应该采用更好的实验设置来评价中间训练方法。Https://github.com/naver/splade/tree/benchmarch-sigir23提供密码"
    },
    {
        "title": "CTRL: Connect Tabular and Language Model for CTR Prediction",
        "url": "http://arxiv.org/abs/2306.02841v1",
        "pub_date": "2023-06-05",
        "summary": "Traditional click-through rate (CTR) prediction models convert the tabular\ndata into one-hot vectors and leverage the collaborative relations among\nfeatures for inferring user's preference over items. This modeling paradigm\ndiscards the essential semantic information. Though some recent works like P5\nand M6-Rec have explored the potential of using Pre-trained Language Models\n(PLMs) to extract semantic signals for CTR prediction, they are computationally\nexpensive and suffer from low efficiency. Besides, the beneficial collaborative\nrelations are not considered, hindering the recommendation performance. To\nsolve these problems, in this paper, we propose a novel framework\n\\textbf{CTRL}, which is industrial friendly and model-agnostic with high\ntraining and inference efficiency. Specifically, the original tabular data is\nfirst converted into textual data. Both tabular data and converted textual data\nare regarded as two different modalities and are separately fed into the\ncollaborative CTR model and pre-trained language model. A cross-modal knowledge\nalignment procedure is performed to fine-grained align and integrate the\ncollaborative and semantic signals, and the lightweight collaborative model can\nbe deployed online for efficient serving after fine-tuned with supervised\nsignals. Experimental results on three public datasets show that CTRL\noutperforms the SOTA CTR models significantly. Moreover, we further verify its\neffectiveness on a large-scale industrial recommender system.",
        "translated": "传统的点进率预测模型将表格数据转换为一个热点向量，并利用特征之间的协同关系来推断用户对项目的偏好。这种建模范式抛弃了基本的语义信息。虽然最近的一些工作，如 P5和 M6-Rec 已经探索了使用预训练语言模型(PLM)提取语义信号进行 CTR 预测的潜力，但是它们的计算成本高，效率低。此外，没有考虑到有益的协作关系，阻碍了推荐绩效的提高。为了解决这些问题，本文提出了一种新的框架 textbf { CTRL } ，该框架具有良好的工业友好性和模型无关性，并且具有较高的训练和推理效率。具体来说，首先将原始表格数据转换为文本数据。将表格数据和转换后的文本数据视为两种不同的模式，分别输入协同 CTR 模型和预训练语言模型。通过跨模态知识对齐过程对协作信号和语义信号进行细粒度对齐和集成，并对监督信号进行细调后，可以在线部署轻量级协作模型，实现高效服务。在三个公共数据集上的实验结果表明，CTRL 模型的性能明显优于 SOTA CTR 模型。此外，我们进一步验证了该方法在大规模工业推荐系统上的有效性。"
    },
    {
        "title": "Path-Specific Counterfactual Fairness for Recommender Systems",
        "url": "http://arxiv.org/abs/2306.02615v1",
        "pub_date": "2023-06-05",
        "summary": "Recommender systems (RSs) have become an indispensable part of online\nplatforms. With the growing concerns of algorithmic fairness, RSs are not only\nexpected to deliver high-quality personalized content, but are also demanded\nnot to discriminate against users based on their demographic information.\nHowever, existing RSs could capture undesirable correlations between sensitive\nfeatures and observed user behaviors, leading to biased recommendations. Most\nfair RSs tackle this problem by completely blocking the influences of sensitive\nfeatures on recommendations. But since sensitive features may also affect user\ninterests in a fair manner (e.g., race on culture-based preferences),\nindiscriminately eliminating all the influences of sensitive features\ninevitably degenerate the recommendations quality and necessary diversities. To\naddress this challenge, we propose a path-specific fair RS (PSF-RS) for\nrecommendations. Specifically, we summarize all fair and unfair correlations\nbetween sensitive features and observed ratings into two latent proxy\nmediators, where the concept of path-specific bias (PS-Bias) is defined based\non path-specific counterfactual inference. Inspired by Pearl's minimal change\nprinciple, we address the PS-Bias by minimally transforming the biased factual\nworld into a hypothetically fair world, where a fair RS model can be learned\naccordingly by solving a constrained optimization problem. For the technical\npart, we propose a feasible implementation of PSF-RS, i.e., PSF-VAE, with\nweakly-supervised variational inference, which robustly infers the latent\nmediators such that unfairness can be mitigated while necessary recommendation\ndiversities can be maximally preserved simultaneously. Experiments conducted on\nsemi-simulated and real-world datasets demonstrate the effectiveness of PSF-RS.",
        "translated": "推荐系统已经成为在线平台不可或缺的一部分。随着对算法公平性的日益关注，RSS 不仅被期望提供高质量的个性化内容，而且被要求不因用户的人口统计信息而歧视用户。然而，现有的 RSS 可能捕获敏感特性和观察到的用户行为之间不希望看到的相关性，从而导致有偏见的推荐。大多数公平的 RSS 通过完全阻止敏感特性对建议的影响来解决这个问题。但是，由于敏感特性也可能以公平的方式影响用户的兴趣(例如，基于文化的偏好的种族) ，不加区分地消除敏感特性的所有影响必然会降低推荐的质量和必要的多样性。为了应对这一挑战，我们提出了一个路径特定的公平 RS (PSF-RS)的建议。具体而言，我们将敏感特征和观察评分之间的所有公平和不公平的相关性总结为两个潜在的代理中介，其中路径特异性偏倚(PS-Bias)的概念是基于路径特异性反事实推断定义的。受珀尔的最小改变原则的启发，我们通过最小化地将有偏见的现实世界转化为一个假设的公平世界，在这个假设的公平世界中，通过解决一个受限制的最佳化问题，可以相应地学习一个公平的遥感模型，从而解决偏差问题。在技术部分，我们提出了一种可行的 PSF-RS 的实现方法，即弱监督变分推理 PSF-VAE，它可以强有力地推断出潜在的中介因子，从而在最大限度地保留必要的推荐多样性的同时，减少不公平性。在半模拟和真实数据集上进行的实验证明了 PSF-RS 算法的有效性。"
    },
    {
        "title": "RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems",
        "url": "http://arxiv.org/abs/2306.03091v1",
        "pub_date": "2023-06-05",
        "summary": "Large Language Models (LLMs) have greatly advanced code auto-completion\nsystems, with a potential for substantial productivity enhancements for\ndevelopers. However, current benchmarks mainly focus on single-file tasks,\nleaving an assessment gap for more complex, real-world, multi-file programming\nscenarios. To fill this gap, we introduce RepoBench, a new benchmark\nspecifically designed for evaluating repository-level code auto-completion\nsystems. RepoBench consists of three interconnected evaluation tasks:\nRepoBench-R (Retrieval), RepoBench-C (Code Completion), and RepoBench-P\n(Pipeline). Each task respectively measures the system's ability to retrieve\nthe most relevant code snippets from other files as cross-file context, predict\nthe next line of code with cross-file and in-file context, and handle complex\ntasks that require a combination of both retrieval and next-line prediction.\nRepoBench aims to facilitate a more complete comparison of performance and\nencouraging continuous improvement in auto-completion systems. RepoBench is\npublicly available at https://github.com/Leolty/repobench.",
        "translated": "大型语言模型(Large Language Model，LLM)具有非常先进的代码自动完成系统，对于开发人员来说，这有可能大大提高生产力。然而，当前的基准测试主要集中在单文件任务上，对于更复杂的、真实的、多文件编程场景留下了评估空白。为了填补这个空白，我们引入了 RepoBench，这是一个专门为评估存储库级代码自动完成系统而设计的新基准。RepoBench 由三个相互连接的评估任务组成: RepoBench-R (检索)、 RepoBench-C (代码完成)和 RepoBench-P (管道)。每个任务分别测量系统从其他文件中检索最相关代码片段作为跨文件上下文的能力，用跨文件和文件内上下文预测下一行代码的能力，以及处理需要检索和下一行预测相结合的复杂任务的能力。RepoBench 旨在促进更全面的性能比较，并鼓励自动完成系统的持续改进。RepoBench 可在 https://github.com/leolty/RepoBench 公开使用。"
    },
    {
        "title": "Is ChatGPT a Good Teacher Coach? Measuring Zero-Shot Performance For\n  Scoring and Providing Actionable Insights on Classroom Instruction",
        "url": "http://arxiv.org/abs/2306.03090v1",
        "pub_date": "2023-06-05",
        "summary": "Coaching, which involves classroom observation and expert feedback, is a\nwidespread and fundamental part of teacher training. However, the majority of\nteachers do not have access to consistent, high quality coaching due to limited\nresources and access to expertise. We explore whether generative AI could\nbecome a cost-effective complement to expert feedback by serving as an\nautomated teacher coach. In doing so, we propose three teacher coaching tasks\nfor generative AI: (A) scoring transcript segments based on classroom\nobservation instruments, (B) identifying highlights and missed opportunities\nfor good instructional strategies, and (C) providing actionable suggestions for\neliciting more student reasoning. We recruit expert math teachers to evaluate\nthe zero-shot performance of ChatGPT on each of these tasks for elementary math\nclassroom transcripts. Our results reveal that ChatGPT generates responses that\nare relevant to improving instruction, but they are often not novel or\ninsightful. For example, 82% of the model's suggestions point to places in the\ntranscript where the teacher is already implementing that suggestion. Our work\nhighlights the challenges of producing insightful, novel and truthful feedback\nfor teachers while paving the way for future research to address these\nobstacles and improve the capacity of generative AI to coach teachers.",
        "translated": "辅导，包括课堂观察和专家反馈，是教师培训的一个广泛而基本的组成部分。然而，由于资源和专业知识有限，大多数教师无法获得连贯、高质量的辅导。我们探讨生成式人工智能是否可以成为一个具有成本效益的专家反馈的补充，作为一个自动化的教师教练。在这样做时，我们提出了三个生成性人工智能的教师培训任务: (A)基于课堂观察工具评分成绩单片段，(B)识别优秀教学策略的亮点和错过的机会，以及(C)提供可行的建议，以引发更多的学生推理。我们招募数学专家教师来评估 ChatGPT 在小学数学课堂成绩单中每一项任务的“零打击”表现。我们的研究结果表明，ChatGPT 产生的反应与提高教学质量有关，但它们往往不是新颖或有见地的。例如，模型中82% 的建议指向成绩单中教师已经实施该建议的地方。我们的工作强调了为教师提供有见地、新颖和真实的反馈所面临的挑战，同时为未来的研究解决这些障碍和提高生成性人工智能指导教师的能力铺平了道路。"
    },
    {
        "title": "Sequential Monte Carlo Steering of Large Language Models using\n  Probabilistic Programs",
        "url": "http://arxiv.org/abs/2306.03081v1",
        "pub_date": "2023-06-05",
        "summary": "Even after fine-tuning and reinforcement learning, large language models\n(LLMs) can be difficult, if not impossible, to control reliably with prompts\nalone. We propose a new inference-time approach to enforcing syntactic and\nsemantic constraints on the outputs of LLMs, called sequential Monte Carlo\n(SMC) steering. The key idea is to specify language generation tasks as\nposterior inference problems in a class of discrete probabilistic sequence\nmodels, and replace standard decoding with sequential Monte Carlo inference.\nFor a computational cost similar to that of beam search, SMC can steer LLMs to\nsolve diverse tasks, including infilling, generation under syntactic\nconstraints, and prompt intersection. To facilitate experimentation with SMC\nsteering, we present a probabilistic programming library, LLaMPPL\n(https://github.com/probcomp/LLaMPPL), for concisely specifying new generation\ntasks as language model probabilistic programs, and automating steering of\nLLaMA-family Transformers.",
        "translated": "即使经过微调和强化学习，大型语言模型(LLM)也很难单靠提示符进行可靠控制。我们提出了一种新的推理时间方法，称为序贯蒙特卡罗(SMC)指导，以强制语法和语义约束的 LLM 的输出。其核心思想是在一类离散概率序列模型中将语言生成任务指定为后验推理问题，并用序贯蒙特卡罗推理代替标准译码。对于类似于波束搜索的计算代价，SMC 可以引导 LLM 解决不同的任务，包括填充、语法约束下的生成和快速交叉。为了方便 SMC 指导的实验，我们提出了一个概率编程库，LLaMPPL ( https://github.com/probcomp/LLaMPPL ) ，简明地指定新一代任务作为语言模型概率程序，并自动指导 LlaMA 家族变压器。"
    },
    {
        "title": "Machine Learning and Statistical Approaches to Measuring Similarity of\n  Political Parties",
        "url": "http://arxiv.org/abs/2306.03079v1",
        "pub_date": "2023-06-05",
        "summary": "Mapping political party systems to metric policy spaces is one of the major\nmethodological problems in political science. At present, in most political\nscience project this task is performed by domain experts relying on purely\nqualitative assessments, with all the attendant problems of subjectivity and\nlabor intensiveness. We consider how advances in natural language processing,\nincluding large transformer-based language models, can be applied to solve that\nissue. We apply a number of texts similarity measures to party political\nprograms, analyze how they correlate with each other, and -- in the absence of\na satisfactory benchmark -- evaluate them against other measures, including\nthose based on expert surveys, voting records, electoral patterns, and\ncandidate networks. Finally, we consider the prospects of relying on those\nmethods to correct, supplement, and eventually replace expert judgments.",
        "translated": "将政党系统映射到度量政策空间是政治学的主要方法论问题之一。目前，在大多数政治科学项目中，这项任务是由领域专家依靠纯粹的定性评估来完成的，伴随而来的问题包括主观性和劳动密集性。我们考虑如何应用自然语言处理的进步，包括基于大型转换器的语言模型，来解决这个问题。我们将大量的文本相似性度量方法应用于政党政治计划，分析它们之间的相互关系，并且——在缺乏令人满意的基准的情况下——根据其他度量方法对它们进行评估，包括那些基于专家调查、投票记录、选举模式和候选人网络的方法。最后，我们考虑依靠这些方法来纠正、补充并最终取代专家判断的前景。"
    },
    {
        "title": "SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight\n  Compression",
        "url": "http://arxiv.org/abs/2306.03078v1",
        "pub_date": "2023-06-05",
        "summary": "Recent advances in large language model (LLM) pretraining have led to\nhigh-quality LLMs with impressive abilities. By compressing such LLMs via\nquantization to 3-4 bits per parameter, they can fit into memory-limited\ndevices such as laptops and mobile phones, enabling personalized use. However,\nquantization down to 3-4 bits per parameter usually leads to moderate-to-high\naccuracy losses, especially for smaller models in the 1-10B parameter range,\nwhich are well-suited for edge deployments. To address this accuracy issue, we\nintroduce the Sparse-Quantized Representation (SpQR), a new compressed format\nand quantization technique which enables for the first time near-lossless\ncompression of LLMs across model scales, while reaching similar compression\nlevels to previous methods. SpQR works by identifying and isolating outlier\nweights, which cause particularly-large quantization errors, and storing them\nin higher precision, while compressing all other weights to 3-4 bits, and\nachieves relative accuracy losses of less than 1% in perplexity for\nhighly-accurate LLaMA and Falcon LLMs. This makes it possible to run 33B\nparameter LLM on a single 24 GB consumer GPU without any performance\ndegradation at 15% speedup thus making powerful LLMs available to consumer\nwithout any downsides. SpQR comes with efficient algorithms for both encoding\nweights into its format, as well as decoding them efficiently at runtime.\nSpecifically, we provide an efficient GPU inference algorithm for SpQR which\nyields faster inference than 16-bit baselines at similar accuracy, while\nenabling memory compression gains of more than 4x.",
        "translated": "大语言模型(LLM)预训练的最新进展导致了具有令人印象深刻的能力的高质量 LLM。通过量化将这种 LLM 压缩到每个参数3-4位，它们可以适用于内存有限的设备，如笔记本电脑和移动电话，从而实现个性化使用。然而，每个参数下降到3-4位的量化通常会导致中高精度的损失，特别是对于1-10B 参数范围内的较小模型，它们非常适合边缘部署。为了解决这个精度问题，我们引入了稀疏量化表示(SpQR) ，这是一种新的压缩格式和量化技术，它能够首次在模型尺度上对 LLM 进行近无损压缩，同时达到与以前的方法相似的压缩水平。SpQR 的工作原理是识别和隔离引起特别大量化误差的离群值权重，并以更高的精度存储它们，同时将所有其他权重压缩到3-4位，对于高精度 LLaMA 和 Falcon LLM，相对精度损失小于1% 。这使得在一个24GB 的消费者 GPU 上运行33B 参数 LLM 成为可能，而且在加速15% 的情况下性能没有任何下降，从而使得消费者可以在没有任何缺点的情况下使用功能强大的 LLM。SpQR 提供了有效的算法，既可以将权值编码成它的格式，也可以在运行时高效地解码它们。具体来说，我们为 SpQR 提供了一种高效的 GPU 推理算法，它在相似的精度下比16位基线产生更快的推理，同时使内存压缩增益超过4倍。"
    },
    {
        "title": "Interactive Editing for Text Summarization",
        "url": "http://arxiv.org/abs/2306.03067v1",
        "pub_date": "2023-06-05",
        "summary": "Summarizing lengthy documents is a common and essential task in our daily\nlives. Although recent advancements in neural summarization models can assist\nin crafting general-purpose summaries, human writers often have specific\nrequirements that call for a more customized approach. To address this need, we\nintroduce REVISE (Refinement and Editing via Iterative Summarization\nEnhancement), an innovative framework designed to facilitate iterative editing\nand refinement of draft summaries by human writers. Within our framework,\nwriters can effortlessly modify unsatisfactory segments at any location or\nlength and provide optional starting phrases -- our system will generate\ncoherent alternatives that seamlessly integrate with the existing summary. At\nits core, REVISE incorporates a modified fill-in-the-middle model with the\nencoder-decoder architecture while developing novel evaluation metrics tailored\nfor the summarization task. In essence, our framework empowers users to create\nhigh-quality, personalized summaries by effectively harnessing both human\nexpertise and AI capabilities, ultimately transforming the summarization\nprocess into a truly collaborative and adaptive experience.",
        "translated": "总结冗长的文件是我们日常生活中的一项共同而又必不可少的任务。虽然神经总结模型的最新进展可以帮助制作通用的总结，但人类作者往往有特定的需求，需要更加定制的方法。为了满足这一需求，我们引入了 REVISE (通过迭代摘要增强进行细化和编辑) ，这是一个创新的框架，旨在促进人类作者对摘要草稿的迭代编辑和细化。在我们的框架内，作者可以毫不费力地在任何位置或长度修改不满意的部分，并提供可选的起始短语——我们的系统将生成与现有摘要无缝集成的连贯备选方案。在其核心，REVISE 采用了修改的填充中间模型与编码器-解码器架构，同时开发新的评估指标定制的摘要任务。本质上，我们的框架通过有效利用人类专业知识和人工智能能力，使用户能够创建高质量的个性化摘要，最终将摘要过程转化为真正的协作和适应性体验。"
    },
    {
        "title": "Structured Voronoi Sampling",
        "url": "http://arxiv.org/abs/2306.03061v1",
        "pub_date": "2023-06-05",
        "summary": "Recently, there has been a growing interest in the development of\ngradient-based sampling algorithms for text generation, especially in the\ncontext of controlled generation. However, there exists a lack of theoretically\ngrounded and principled approaches for this task. In this paper, we take an\nimportant step toward building a principled approach for sampling from language\nmodels with gradient-based methods. We use discrete distributions given by\nlanguage models to define densities and develop an algorithm based on\nHamiltonian Monte Carlo to sample from them. We name our gradient-based\ntechnique Structured Voronoi Sampling (SVS). In an experimental setup where the\nreference distribution is known, we show that the empirical distribution of SVS\nsamples is closer to the reference distribution compared to alternative\nsampling schemes. Furthermore, in a controlled generation task, SVS is able to\ngenerate fluent and diverse samples while following the control targets\nsignificantly better than other methods.",
        "translated": "近年来，基于梯度的文本生成采样算法的研究越来越受到人们的关注，尤其是在控制生成的背景下。然而，这项工作缺乏理论基础和原则性的方法。在本文中，我们采取了一个重要的步骤，以建立一个原则性的方法从语言模型采样基于梯度的方法。我们使用语言模型给出的离散分布来定义密度，并开发一个基于 Hamiltonian Monte Carlo 的算法来取样。我们将基于梯度的技术命名为结构化 Voronoi 抽样(SVS)。在已知参考分布的实验装置中，我们发现 SVS 样本的经验分布比其他抽样方案更接近参考分布。此外，在控制生成任务中，SVS 能够生成流畅多样的样本，并且能够明显地更好地跟踪控制目标。"
    },
    {
        "title": "Analyzing Syntactic Generalization Capacity of Pre-trained Language\n  Models on Japanese Honorific Conversion",
        "url": "http://arxiv.org/abs/2306.03055v1",
        "pub_date": "2023-06-05",
        "summary": "Using Japanese honorifics is challenging because it requires not only\nknowledge of the grammatical rules but also contextual information, such as\nsocial relationships. It remains unclear whether pre-trained large language\nmodels (LLMs) can flexibly handle Japanese honorifics like humans. To analyze\nthis, we introduce an honorific conversion task that considers social\nrelationships among people mentioned in a conversation. We construct a Japanese\nhonorifics dataset from problem templates of various sentence structures to\ninvestigate the syntactic generalization capacity of GPT-3, one of the leading\nLLMs, on this task under two settings: fine-tuning and prompt learning. Our\nresults showed that the fine-tuned GPT-3 performed better in a context-aware\nhonorific conversion task than the prompt-based one. The fine-tuned model\ndemonstrated overall syntactic generalizability towards compound honorific\nsentences, except when tested with the data involving direct speech.",
        "translated": "使用敬称很有挑战性，因为它不仅需要语法规则的知识，还需要上下文信息，比如社会关系。目前还不清楚经过训练的大型语言模型(LLM)是否能像人类一样灵活地处理敬称。为了分析这一点，我们引入了一个敬语转换任务，考虑谈话中提到的人之间的社会关系。我们从不同句子结构的问题模板中构建了一个敬称数据集，在微调和及时学习两种设置下，研究了领先的语法模型之一 GPT-3的句法泛化能力。我们的研究结果表明，微调的 GPT-3在上下文感知的敬语转换任务中比基于提示的任务表现得更好。经过微调的模型显示了复合敬语句的整体句法泛化能力，除非使用直接引语的数据进行测试。"
    },
    {
        "title": "Benchmarking Large Language Models on CMExam -- A Comprehensive Chinese\n  Medical Exam Dataset",
        "url": "http://arxiv.org/abs/2306.03030v1",
        "pub_date": "2023-06-05",
        "summary": "Recent advancements in large language models (LLMs) have transformed the\nfield of question answering (QA). However, evaluating LLMs in the medical field\nis challenging due to the lack of standardized and comprehensive datasets. To\naddress this gap, we introduce CMExam, sourced from the Chinese National\nMedical Licensing Examination. CMExam consists of 60K+ multiple-choice\nquestions for standardized and objective evaluations, as well as solution\nexplanations for model reasoning evaluation in an open-ended manner. For\nin-depth analyses of LLMs, we invited medical professionals to label five\nadditional question-wise annotations, including disease groups, clinical\ndepartments, medical disciplines, areas of competency, and question difficulty\nlevels. Alongside the dataset, we further conducted thorough experiments with\nrepresentative LLMs and QA algorithms on CMExam. The results show that GPT-4\nhad the best accuracy of 61.5% and a weighted F1 score of 0.616. These results\nhighlight a great disparity when compared to human accuracy, which stood at\n71.6%. For explanation tasks, while LLMs could generate relevant reasoning and\ndemonstrate improved performance after finetuning, they fall short of a desired\nstandard, indicating ample room for improvement. To the best of our knowledge,\nCMExam is the first Chinese medical exam dataset to provide comprehensive\nmedical annotations. The experiments and findings of LLM evaluation also\nprovide valuable insights into the challenges and potential solutions in\ndeveloping Chinese medical QA systems and LLM evaluation pipelines. The dataset\nand relevant code are available at https://github.com/williamliujl/CMExam.",
        "translated": "大型语言模型(LLM)的最新进展已经改变了问答(QA)领域。然而，由于缺乏标准化和全面的数据集，评估 LLM 在医学领域是具有挑战性的。为了弥补这一差距，我们引入了来自中国国家医师执业资格考试的中国医师执业资格考试。CMExam 由60K + 多项选择题组成，用于标准化和客观的评估，以及开放式方式的模型推理评估的解决方案说明。对于 LLM 的深入分析，我们邀请医学专业人员标记另外五个明智的问题注释，包括疾病组，临床部门，医学学科，能力领域和问题难度水平。除了数据集，我们进一步在 CMExam 上进行了具有代表性的 LLM 和 QA 算法的全面实验。结果表明，GPT-4的最佳准确率为61.5% ，加权 F1得分为0.616。这些结果突出了一个巨大的差异，相比之下，人类的准确率为71.6% 。对于解释任务，虽然 LLM 可以生成相关的推理，并在微调后显示出改进的性能，但它们没有达到理想的标准，表明有足够的改进空间。据我们所知，中国医学考试是第一个提供全面医学注释的中国医学考试数据集。LLM 评价的实验和研究结果也为开发中国医疗质量保证体系和 LLM 评价管道提供了有价值的启示。数据集和相关代码可在 https://github.com/williamliujl/cmexam 查阅。"
    },
    {
        "title": "PokemonChat: Auditing ChatGPT for Pokémon Universe Knowledge",
        "url": "http://arxiv.org/abs/2306.03024v1",
        "pub_date": "2023-06-05",
        "summary": "The recently released ChatGPT model demonstrates unprecedented capabilities\nin zero-shot question-answering. In this work, we probe ChatGPT for its\nconversational understanding and introduce a conversational framework\n(protocol) that can be adopted in future studies. The Pok\\'emon universe serves\nas an ideal testing ground for auditing ChatGPT's reasoning capabilities due to\nits closed world assumption. After bringing ChatGPT's background knowledge (on\nthe Pok\\'emon universe) to light, we test its reasoning process when using\nthese concepts in battle scenarios. We then evaluate its ability to acquire new\nknowledge and include it in its reasoning process. Our ultimate goal is to\nassess ChatGPT's ability to generalize, combine features, and to acquire and\nreason over newly introduced knowledge from human feedback. We find that\nChatGPT has prior knowledge of the Pokemon universe, which can reason upon in\nbattle scenarios to a great extent, even when new information is introduced.\nThe model performs better with collaborative feedback and if there is an\ninitial phase of information retrieval, but also hallucinates occasionally and\nis susceptible to adversarial attacks.",
        "translated": "最近发布的 ChatGPT 模型展示了前所未有的零命中问题回答能力。在本文中，我们探讨了 ChatGPT 的会话理解，并介绍了一个可以在未来研究中采用的会话框架(协议)。由于其封闭的世界假设，宇宙上的 Pok’em 可以作为审核 ChatGPT 推理能力的理想试验场。在将 ChatGPT 的背景知识(关于宇宙中的 Pok’em)公之于众之后，我们在战斗场景中使用这些概念时测试它的推理过程。然后，我们评估它获取新知识的能力，并将其包括在推理过程中。我们的最终目标是评估 ChatGPT 的概括、结合特性的能力，以及从人类反馈中获取和推理新引入的知识的能力。我们发现 ChatGPT 拥有口袋妖怪世界的先验知识，即使在引入新信息的情况下，它也可以在很大程度上在战斗场景中进行推理。这种模式在协作反馈的情况下表现得更好，如果存在信息检索的初始阶段，但有时也会产生幻觉，容易受到敌对攻击。"
    },
    {
        "title": "On Manipulating Signals of User-Item Graph: A Jacobi Polynomial-based\n  Graph Collaborative Filtering",
        "url": "http://arxiv.org/abs/2306.03624v1",
        "pub_date": "2023-06-06",
        "summary": "Collaborative filtering (CF) is an important research direction in\nrecommender systems that aims to make recommendations given the information on\nuser-item interactions. Graph CF has attracted more and more attention in\nrecent years due to its effectiveness in leveraging high-order information in\nthe user-item bipartite graph for better recommendations. Specifically, recent\nstudies show the success of graph neural networks (GNN) for CF is attributed to\nits low-pass filtering effects. However, current researches lack a study of how\ndifferent signal components contributes to recommendations, and how to design\nstrategies to properly use them well. To this end, from the view of spectral\ntransformation, we analyze the important factors that a graph filter should\nconsider to achieve better performance. Based on the discoveries, we design\nJGCF, an efficient and effective method for CF based on Jacobi polynomial bases\nand frequency decomposition strategies. Extensive experiments on four widely\nused public datasets show the effectiveness and efficiency of the proposed\nmethods, which brings at most 27.06% performance gain on Alibaba-iFashion.\nBesides, the experimental results also show that JGCF is better at handling\nsparse datasets, which shows potential in making recommendations for cold-start\nusers.",
        "translated": "协同过滤(CF)是推荐系统的一个重要研究方向，其目的是根据用户项目交互的信息提供推荐。近年来，图形 CF 由于能够有效地利用用户项目二分图中的高阶信息来获得更好的建议而引起了越来越多的关注。具体来说，最近的研究表明，图神经网络(GNN)对 CF 的成功归功于其低通滤波效果。然而，目前的研究缺乏研究不同的信号成分如何有助于推荐，以及如何设计策略，以适当地使用它们。为此，本文从谱变换的角度出发，分析了图形滤波器要获得更好的性能所应考虑的重要因素。基于这些发现，我们设计了一种基于 Jacobi 多项式基和频率分解策略的高效率和有效的协同过滤方法。在四个广泛使用的公共数据集上进行了大量的实验，结果表明了该方法的有效性和高效性，在阿里巴巴-iFashion 平台上获得了最多27.06% 的性能提升。此外，实验结果还表明，JGCF 在处理稀疏数据集方面有较好的表现，可以为冷启动用户提供建议。"
    },
    {
        "title": "Rec4Ad: A Free Lunch to Mitigate Sample Selection Bias for Ads CTR\n  Prediction in Taobao",
        "url": "http://arxiv.org/abs/2306.03527v1",
        "pub_date": "2023-06-06",
        "summary": "Click-Through Rate (CTR) prediction serves as a fundamental component in\nonline advertising. A common practice is to train a CTR model on advertisement\n(ad) impressions with user feedback. Since ad impressions are purposely\nselected by the model itself, their distribution differs from the inference\ndistribution and thus exhibits sample selection bias (SSB) that affects model\nperformance. Existing studies on SSB mainly employ sample re-weighting\ntechniques which suffer from high variance and poor model calibration. Another\nline of work relies on costly uniform data that is inadequate to train\nindustrial models. Thus mitigating SSB in industrial models with a\nuniform-data-free framework is worth exploring. Fortunately, many platforms\ndisplay mixed results of organic items (i.e., recommendations) and sponsored\nitems (i.e., ads) to users, where impressions of ads and recommendations are\nselected by different systems but share the same user decision rationales.\nBased on the above characteristics, we propose to leverage recommendations\nsamples as a free lunch to mitigate SSB for ads CTR model (Rec4Ad). After\nelaborating data augmentation, Rec4Ad learns disentangled representations with\nalignment and decorrelation modules for enhancement. When deployed in Taobao\ndisplay advertising system, Rec4Ad achieves substantial gains in key business\nmetrics, with a lift of up to +6.6\\% CTR and +2.9\\% RPM.",
        "translated": "点进率预测是在线广告的一个基本组成部分。一个常见的做法是训练广告(广告)印象与用户反馈的点击率模型。由于广告印象是由模型本身有目的地选择的，它们的分布不同于推断分布，因此表现出影响模型性能的样本选择偏差(SSB)。现有的 SSB 研究主要采用样本重权重技术，存在方差大、模型校正差等问题。另一项工作依赖于昂贵的统一数据，这些数据不足以培训工业模型。因此，在无统一数据框架的工业模型中减少 SSB 是值得探索的。幸运的是，许多平台向用户显示有机项目(即推荐)和赞助项目(即广告)的混合结果，其中广告和推荐的印象由不同的系统选择，但共享相同的用户决策理由。基于上述特点，我们建议利用推荐样本作为免费午餐，以减轻 SSB 的广告点击率模型(Rec4Ad)。在详细阐述了数据增强之后，Rec4Ad 学习了利用对齐和去相关模块进行增强的解纠缠表示。在淘宝展示广告系统中部署 Rec4Ad 后，Rec4Ad 在关键业务指标上取得了实质性进展，点击率和转速分别提高了6.6% 和2.9% 。"
    },
    {
        "title": "COPR: Consistency-Oriented Pre-Ranking for Online Advertising",
        "url": "http://arxiv.org/abs/2306.03516v1",
        "pub_date": "2023-06-06",
        "summary": "Cascading architecture has been widely adopted in large-scale advertising\nsystems to balance efficiency and effectiveness. In this architecture, the\npre-ranking model is expected to be a lightweight approximation of the ranking\nmodel, which handles more candidates with strict latency requirements. Due to\nthe gap in model capacity, the pre-ranking and ranking models usually generate\ninconsistent ranked results, thus hurting the overall system effectiveness. The\nparadigm of score alignment is proposed to regularize their raw scores to be\nconsistent. However, it suffers from inevitable alignment errors and error\namplification by bids when applied in online advertising. To this end, we\nintroduce a consistency-oriented pre-ranking framework for online advertising,\nwhich employs a chunk-based sampling module and a plug-and-play rank alignment\nmodule to explicitly optimize consistency of ECPM-ranked results. A $\\Delta\nNDCG$-based weighting mechanism is adopted to better distinguish the importance\nof inter-chunk samples in optimization. Both online and offline experiments\nhave validated the superiority of our framework. When deployed in Taobao\ndisplay advertising system, it achieves an improvement of up to +12.3\\% CTR and\n+5.6\\% RPM.",
        "translated": "为了平衡效率和效果，级联体系结构在大规模广告系统中得到了广泛的应用。在这种体系结构中，预排序模型被期望是排序模型的轻量级近似，它处理具有严格延迟要求的更多候选者。由于模型容量的差距，预排序模型和排序模型通常会产生不一致的排序结果，从而影响系统的整体有效性。提出了分数对齐的范式，以规范他们的原始分数是一致的。然而，在网络广告中应用时，不可避免地会出现一致性错误和出价放大错误。为此，我们引入了一个面向一致性的在线广告预排序框架，该框架采用了基于块的抽样模块和即插即用的排序对齐模块来显式优化 ECPM 排序结果的一致性。为了更好地区分块间样本在优化中的重要性，采用了基于 $Delta NDCG 的加权机制。这两个在线和离线实验都验证了我们框架的优越性。在淘宝展示广告系统中，点击率和转速分别提高了12.3% 和5.6% 。"
    },
    {
        "title": "Generate-then-Retrieve: Intent-Aware FAQ Retrieval in Product Search",
        "url": "http://arxiv.org/abs/2306.03411v1",
        "pub_date": "2023-06-06",
        "summary": "Customers interacting with product search engines are increasingly\nformulating information-seeking queries. Frequently Asked Question (FAQ)\nretrieval aims to retrieve common question-answer pairs for a user query with\nquestion intent. Integrating FAQ retrieval in product search can not only\nempower users to make more informed purchase decisions, but also enhance user\nretention through efficient post-purchase support. Determining when an FAQ\nentry can satisfy a user's information need within product search, without\ndisrupting their shopping experience, represents an important challenge. We\npropose an intent-aware FAQ retrieval system consisting of (1) an intent\nclassifier that predicts when a user's information need can be answered by an\nFAQ; (2) a reformulation model that rewrites a query into a natural question.\nOffline evaluation demonstrates that our approach improves Hit@1 by 13% on\nretrieving ground-truth FAQs, while reducing latency by 95% compared to\nbaseline systems. These improvements are further validated by real user\nfeedback, where 71% of displayed FAQs on top of product search results received\nexplicit positive user feedback. Overall, our findings show promising\ndirections for integrating FAQ retrieval into product search at scale.",
        "translated": "与产品搜索引擎互动的客户越来越多地提出信息搜索查询。常见问题(FAQ)检索的目的是为具有问题意图的用户查询检索常见的问题-答案对。将常见问题检索整合到产品搜索中，不仅可以使用户做出更明智的购买决策，而且可以通过有效的购买后支持来提高用户保留率。在不影响用户购物体验的情况下，确定 FAQ 条目何时能够满足用户在产品搜索中的信息需求，是一个重要的挑战。我们提出了一个意图感知的 FAQ 检索系统，包括(1)意图分类器，预测何时用户的信息需求可以由 FAQ 回答; (2)重写模型，将查询重写成一个自然的问题。脱机评估表明，与基线系统相比，我们的方法在检索地面真相 FAQ 时将 Hit@1提高了13% ，同时减少了95% 的延迟。这些改进通过真实的用户反馈得到了进一步的验证，在产品搜索结果之上显示的 FAQ 中有71% 得到了明确的积极的用户反馈。总的来说，我们的研究结果为将 FAQ 检索整合到大规模的产品搜索中提供了有希望的方向。"
    },
    {
        "title": "Computational Technologies for Fashion Recommendation: A Survey",
        "url": "http://arxiv.org/abs/2306.03395v1",
        "pub_date": "2023-06-06",
        "summary": "Fashion recommendation is a key research field in computational fashion\nresearch and has attracted considerable interest in the computer vision,\nmultimedia, and information retrieval communities in recent years. Due to the\ngreat demand for applications, various fashion recommendation tasks, such as\npersonalized fashion product recommendation, complementary (mix-and-match)\nrecommendation, and outfit recommendation, have been posed and explored in the\nliterature. The continuing research attention and advances impel us to look\nback and in-depth into the field for a better understanding. In this paper, we\ncomprehensively review recent research efforts on fashion recommendation from a\ntechnological perspective. We first introduce fashion recommendation at a macro\nlevel and analyse its characteristics and differences with general\nrecommendation tasks. We then clearly categorize different fashion\nrecommendation efforts into several sub-tasks and focus on each sub-task in\nterms of its problem formulation, research focus, state-of-the-art methods, and\nlimitations. We also summarize the datasets proposed in the literature for use\nin fashion recommendation studies to give readers a brief illustration.\nFinally, we discuss several promising directions for future research in this\nfield. Overall, this survey systematically reviews the development of fashion\nrecommendation research. It also discusses the current limitations and gaps\nbetween academic research and the real needs of the fashion industry. In the\nprocess, we offer a deep insight into how the fashion industry could benefit\nfrom fashion recommendation technologies. the computational technologies of\nfashion recommendation.",
        "translated": "时尚推荐是计算时尚研究中的一个关键研究领域，近年来在计算机视觉、多媒体和信息检索社区引起了相当大的兴趣。由于应用需求的巨大，各种时尚推荐任务，如个性化的时尚产品推荐，补充(混搭)推荐，服装推荐，已提出和探讨的文献。持续的研究关注和进步促使我们回顾和深入到这一领域，以便更好地理解。本文从技术角度综述了近年来时尚推荐的研究成果。本文首先从宏观层面介绍了时尚推荐，并分析了它与一般推荐任务的特点和区别。然后，我们清楚地将不同的时尚推荐工作分为几个子任务，并根据其问题形成、研究重点、最先进的方法和局限性关注每个子任务。我们还总结了文献中提出的用于时尚推荐研究的数据集，以便给读者一个简要的说明。最后，我们讨论了这一领域未来研究的几个有希望的方向。总的来说，本调查系统地回顾了时尚推荐研究的发展。文章还讨论了当前学术研究与时尚产业实际需求之间的局限性和差距。在这个过程中，我们提供了一个深入的洞察时尚产业如何可以受益于时尚推荐技术。时尚推荐的计算技术。"
    },
    {
        "title": "CL-UZH at SemEval-2023 Task 10: Sexism Detection through Incremental\n  Fine-Tuning and Multi-Task Learning with Label Descriptions",
        "url": "http://arxiv.org/abs/2306.03907v1",
        "pub_date": "2023-06-06",
        "summary": "The widespread popularity of social media has led to an increase in hateful,\nabusive, and sexist language, motivating methods for the automatic detection of\nsuch phenomena. The goal of the SemEval shared task \\textit{Towards Explainable\nDetection of Online Sexism} (EDOS 2023) is to detect sexism in English social\nmedia posts (subtask A), and to categorize such posts into four coarse-grained\nsexism categories (subtask B), and eleven fine-grained subcategories (subtask\nC). In this paper, we present our submitted systems for all three subtasks,\nbased on a multi-task model that has been fine-tuned on a range of related\ntasks and datasets before being fine-tuned on the specific EDOS subtasks. We\nimplement multi-task learning by formulating each task as binary pairwise text\nclassification, where the dataset and label descriptions are given along with\nthe input text. The results show clear improvements over a fine-tuned\nDeBERTa-V3 serving as a baseline leading to $F_1$-scores of 85.9\\% in subtask A\n(rank 13/84), 64.8\\% in subtask B (rank 19/69), and 44.9\\% in subtask C\n(26/63).",
        "translated": "社交媒体的广泛流行导致了仇恨、辱骂和性别歧视语言的增加，激发了自动检测此类现象的方法。SemEval 共享任务的目标是检测英语社交媒体帖子中的性别歧视(子任务 A) ，并将这些帖子分为四个粗粒度的性别歧视类别(子任务 B)和十一个细粒度的子类别(子任务 C)。在本文中，我们提出了针对所有三个子任务的提交系统，该系统基于一个多任务模型，在针对特定的 EDOS 子任务进行微调之前，该模型已经在一系列相关任务和数据集上进行了微调。我们通过将每个任务表示为二进制成对文本分类来实现多任务学习，其中数据集和标签描述与输入文本一起给出。结果显示，与作为基线的微调 DeBERTa-V3相比，明显改善，子任务 A (排名13/84)的分数为85.9% ，子任务 B (排名19/69)为64.8% ，子任务 C 为44.9% (26/63)。"
    },
    {
        "title": "Utterance Classification with Logical Neural Network: Explainable AI for\n  Mental Disorder Diagnosis",
        "url": "http://arxiv.org/abs/2306.03902v1",
        "pub_date": "2023-06-06",
        "summary": "In response to the global challenge of mental health problems, we proposes a\nLogical Neural Network (LNN) based Neuro-Symbolic AI method for the diagnosis\nof mental disorders. Due to the lack of effective therapy coverage for mental\ndisorders, there is a need for an AI solution that can assist therapists with\nthe diagnosis. However, current Neural Network models lack explainability and\nmay not be trusted by therapists. The LNN is a Recurrent Neural Network\narchitecture that combines the learning capabilities of neural networks with\nthe reasoning capabilities of classical logic-based AI. The proposed system\nuses input predicates from clinical interviews to output a mental disorder\nclass, and different predicate pruning techniques are used to achieve\nscalability and higher scores. In addition, we provide an insight extraction\nmethod to aid therapists with their diagnosis. The proposed system addresses\nthe lack of explainability of current Neural Network models and provides a more\ntrustworthy solution for mental disorder diagnosis.",
        "translated": "针对心理健康问题的全球性挑战，我们提出了一种基于逻辑神经网络(LNN)的神经符号人工智能方法来诊断精神障碍。由于缺乏有效的治疗覆盖面的精神障碍，有一个人工智能解决方案的需要，可以帮助治疗师的诊断。然而，目前的神经网络模型缺乏可解释性，可能不被治疗师信任。神经网络是一种递归神经网络结构，它结合了神经网络的学习能力和经典的基于逻辑的人工智能的推理能力。该系统使用临床访谈中的输入谓词输出一个精神障碍类，并使用不同的谓词修剪技术来实现可扩展性和更高的分数。此外，我们提供了一个洞察力提取方法，以帮助治疗师与他们的诊断。该系统解决了目前神经网络模型的不可解释性问题，为精神疾病的诊断提供了一个更可靠的解决方案。"
    },
    {
        "title": "ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory",
        "url": "http://arxiv.org/abs/2306.03901v2",
        "pub_date": "2023-06-06",
        "summary": "Large language models (LLMs) with memory are computationally universal.\nHowever, mainstream LLMs are not taking full advantage of memory, and the\ndesigns are heavily influenced by biological brains. Due to their approximate\nnature and proneness to the accumulation of errors, conventional neural memory\nmechanisms cannot support LLMs to simulate complex reasoning. In this paper, we\nseek inspiration from modern computer architectures to augment LLMs with\nsymbolic memory for complex multi-hop reasoning. Such a symbolic memory\nframework is instantiated as an LLM and a set of SQL databases, where the LLM\ngenerates SQL instructions to manipulate the SQL databases. We validate the\neffectiveness of the proposed memory framework on a synthetic dataset requiring\ncomplex reasoning. The project website is available at\nhttps://chatdatabase.github.io/ .",
        "translated": "具有内存的大型语言模型(LLM)在计算上是通用的。然而，主流 LLM 并没有充分利用记忆的优势，而且设计受到生物大脑的严重影响。传统的神经记忆机制由于其近似特性和容易累积错误，不能支持 LLM 模拟复杂的推理过程。本文从现代计算机体系结构中寻找启示，用符号存储器增强复杂多跳推理的 LLM。这样的符号内存框架实例化为一个 LLM 和一组 SQL 数据库，LLM 在其中生成 SQL 指令来操作 SQL 数据库。在需要复杂推理的合成数据集上，验证了所提出的记忆框架的有效性。有关计划的网页可于 https://chatdatabase.github.io/下载。"
    },
    {
        "title": "Causal interventions expose implicit situation models for commonsense\n  language understanding",
        "url": "http://arxiv.org/abs/2306.03882v2",
        "pub_date": "2023-06-06",
        "summary": "Accounts of human language processing have long appealed to implicit\n``situation models'' that enrich comprehension with relevant but unstated world\nknowledge. Here, we apply causal intervention techniques to recent transformer\nmodels to analyze performance on the Winograd Schema Challenge (WSC), where a\nsingle context cue shifts interpretation of an ambiguous pronoun. We identify a\nrelatively small circuit of attention heads that are responsible for\npropagating information from the context word that guides which of the\ncandidate noun phrases the pronoun ultimately attends to. We then compare how\nthis circuit behaves in a closely matched ``syntactic'' control where the\nsituation model is not strictly necessary. These analyses suggest distinct\npathways through which implicit situation models are constructed to guide\npronoun resolution.",
        "translated": "长期以来，人类语言处理的描述一直呼吁隐含的“情境模型”，用相关但未陈述的世界知识丰富理解。在这里，我们将因果干预技术应用到最近的转换器模型中，以分析 Winograd 模式挑战(WSC)的表现，其中一个单一的上下文提示转移了对一个模棱两可的代词的解释。我们识别出一个相对较小的注意力回路，它负责从上下文词中传播信息，指导代词最终注意哪个候选名词短语。然后我们比较这个电路在一个紧密匹配的“语法”控制中的表现，在这个控制中情境模型并不是严格必要的。这些分析揭示了指导代词消解的内隐情境模型构建的不同途径。"
    },
    {
        "title": "Deductive Verification of Chain-of-Thought Reasoning",
        "url": "http://arxiv.org/abs/2306.03872v2",
        "pub_date": "2023-06-06",
        "summary": "Large Language Models (LLMs) significantly benefit from Chain-of-Thought\n(CoT) prompting in performing various reasoning tasks. While CoT allows models\nto produce more comprehensive reasoning processes, its emphasis on intermediate\nreasoning steps can inadvertently introduce hallucinations and accumulated\nerrors, thereby limiting models' ability to solve complex reasoning tasks.\nInspired by how humans engage in careful and meticulous deductive logical\nreasoning processes to solve tasks, we seek to enable language models to\nperform explicit and rigorous deductive reasoning, and also ensure the\ntrustworthiness of their reasoning process through self-verification. However,\ndirectly verifying the validity of an entire deductive reasoning process is\nchallenging, even with advanced models like ChatGPT. In light of this, we\npropose to decompose a reasoning verification process into a series of\nstep-by-step subprocesses, each only receiving their necessary context and\npremises. To facilitate this procedure, we propose Natural Program, a natural\nlanguage-based deductive reasoning format. Our approach enables models to\ngenerate precise reasoning steps where subsequent steps are more rigorously\ngrounded on prior steps. It also empowers language models to carry out\nreasoning self-verification in a step-by-step manner. By integrating this\nverification process into each deductive reasoning stage, we significantly\nenhance the rigor and trustfulness of generated reasoning steps. Along this\nprocess, we also improve the answer correctness on complex reasoning tasks.\nCode will be released at https://github.com/lz1oceani/verify_cot.",
        "translated": "大型语言模型(LLM)在执行各种推理任务时显著受益于思维链(CoT)的提示。虽然 CoT 允许模型产生更全面的推理过程，但它对中间推理步骤的强调可能无意中引入幻觉和累积错误，从而限制模型解决复杂推理任务的能力。我们受到人类如何小心谨慎地进行演绎逻辑推理过程来解决任务的启发，我们试图使语言模型能够执行明确而严格的演绎推理，并通过自我验证来确保其推理过程的可信度。然而，即使使用像 chatgPT 这样的高级模型，直接验证整个演绎推理过程的有效性也是具有挑战性的。鉴于此，我们建议将推理验证过程分解为一系列逐步的子过程，每个子过程只接收其必要的上下文和前提。为了方便这个过程，我们提出了自然程序，一种基于自然语言的演绎推理格式。我们的方法使模型能够产生精确的推理步骤，其中后续步骤更严格地基于先前的步骤。它还使语言模型能够按部就班地进行推理自我验证。通过将这个验证过程整合到每个演绎推理阶段，我们大大提高了生成推理步骤的严谨性和可信度。在这个过程中，我们还提高了复杂推理任务的正确答案。密码将在 https://github.com/lz1oceani/verify_cot 公布。"
    },
    {
        "title": "Correction of Errors in Preference Ratings from Automated Metrics for\n  Text Generation",
        "url": "http://arxiv.org/abs/2306.03866v1",
        "pub_date": "2023-06-06",
        "summary": "A major challenge in the field of Text Generation is evaluation: Human\nevaluations are cost-intensive, and automated metrics often display\nconsiderable disagreement with human judgments. In this paper, we propose a\nstatistical model of Text Generation evaluation that accounts for the\nerror-proneness of automated metrics when used to generate preference rankings\nbetween system outputs. We show that existing automated metrics are generally\nover-confident in assigning significant differences between systems in this\nsetting. However, our model enables an efficient combination of human and\nautomated ratings to remedy the error-proneness of the automated metrics. We\nshow that using this combination, we only require about 50% of the human\nannotations typically used in evaluations to arrive at robust and statistically\nsignificant results while yielding the same evaluation outcome as the pure\nhuman evaluation in 95% of cases. We showcase the benefits of approach for\nthree text generation tasks: dialogue systems, machine translation, and text\nsummarization.",
        "translated": "文本生成领域的一个主要挑战是评价: 人的评价是成本密集型的，自动化度量往往显示出与人的判断相当大的分歧。本文提出了一种文本生成评价的统计模型，该模型考虑了自动化度量在生成系统输出之间的偏好排序时的错误倾向性。我们表明，现有的自动化度量通常过于自信，以至于在这种设置中分配系统之间的显著差异。然而，我们的模型能够有效地结合人工评分和自动评分来纠正自动度量的错误倾向性。我们表明，使用这种组合，我们只需要通常用于评估的约50% 的人工注释来达到稳健和统计学显着的结果，同时在95% 的情况下产生与纯人类评估相同的评估结果。我们展示了这种方法在三个文本生成任务中的优点: 对话系统、机器翻译和文本摘要。"
    },
    {
        "title": "Iterative Translation Refinement with Large Language Models",
        "url": "http://arxiv.org/abs/2306.03856v1",
        "pub_date": "2023-06-06",
        "summary": "Large language models have shown surprising performances in understanding\ninstructions and performing natural language tasks. In this paper, we propose\niterative translation refinement to leverage the power of large language models\nfor more natural translation and post-editing. We show that by simply involving\na large language model in an iterative process, the output quality improves\nbeyond mere translation. Extensive test scenarios with GPT-3.5 reveal that\nalthough iterations reduce string-based metric scores, neural metrics indicate\ncomparable if not improved translation quality. Further, human evaluations\ndemonstrate that our method effectively reduces translationese compared to\ninitial GPT translations and even human references, especially for into-English\ndirections. Ablation studies underscore the importance of anchoring the\nrefinement process to the source input and a reasonable initial translation.",
        "translated": "大型语言模型在理解指令和执行自然语言任务方面表现出惊人的表现。在本文中，我们提出了迭代翻译细化，以利用大型语言模型的力量，更自然的翻译和后期编辑。我们表明，通过简单地在迭代过程中涉及一个大的语言模型，输出质量提高超过单纯的翻译。使用 GPT-3.5的大量测试场景显示，尽管迭代减少了基于字符串的度量得分，但神经度量表明，即使没有提高翻译质量，也可以进行比较。此外，人工评估表明，我们的方法有效地减少翻译相比，最初的 GPT 翻译，甚至人工参考，特别是进入英语方向。消融研究强调了将细化过程锚定在源输入和合理的初始翻译上的重要性。"
    },
    {
        "title": "From Key Points to Key Point Hierarchy: Structured and Expressive\n  Opinion Summarization",
        "url": "http://arxiv.org/abs/2306.03853v1",
        "pub_date": "2023-06-06",
        "summary": "Key Point Analysis (KPA) has been recently proposed for deriving fine-grained\ninsights from collections of textual comments. KPA extracts the main points in\nthe data as a list of concise sentences or phrases, termed key points, and\nquantifies their prevalence. While key points are more expressive than word\nclouds and key phrases, making sense of a long, flat list of key points, which\noften express related ideas in varying levels of granularity, may still be\nchallenging. To address this limitation of KPA, we introduce the task of\norganizing a given set of key points into a hierarchy, according to their\nspecificity. Such hierarchies may be viewed as a novel type of Textual\nEntailment Graph. We develop ThinkP, a high quality benchmark dataset of key\npoint hierarchies for business and product reviews, obtained by consolidating\nmultiple annotations. We compare different methods for predicting pairwise\nrelations between key points, and for inferring a hierarchy from these pairwise\npredictions. In particular, for the task of computing pairwise key point\nrelations, we achieve significant gains over existing strong baselines by\napplying directional distributional similarity methods to a novel\ndistributional representation of key points, and further boost performance via\nweak supervision.",
        "translated": "关键点分析(Key Point Analysis，KPA)最近被提议用于从文本注释集合中获得细粒度的见解。KPA 从数据中提取主要观点作为一个简洁的句子或短语列表，称为关键点，并量化其普遍性。虽然关键点比单词云和关键短语更能表达思想，但是要理解一个长长的、扁平的关键点列表可能仍然是一个挑战，因为这些关键点通常表达的是不同粒度级别的相关思想。为了解决 KPA 的这个局限性，我们引入了这样一个任务: 根据关键点的特殊性，将一组给定的关键点组织成一个层次结构。这种等级制度可以被视为一种新型的文字蕴涵图。我们开发 ThinkP，它是一个高质量的基准数据集，通过整合多个注释获得，用于业务和产品评论的关键点层次结构。我们比较了预测关键点之间成对关系的不同方法，以及从这些成对预测中推断层次结构的不同方法。特别是对于计算成对关键点关系的任务，我们通过将方向分布相似性方法应用于一种新的关键点分布表示，在现有的强基线上取得了显著的效果，并且通过弱监督进一步提高了性能。"
    },
    {
        "title": "LEACE: Perfect linear concept erasure in closed form",
        "url": "http://arxiv.org/abs/2306.03819v1",
        "pub_date": "2023-06-06",
        "summary": "Concept erasure aims to remove specified features from a representation. It\ncan be used to improve fairness (e.g. preventing a classifier from using gender\nor race) and interpretability (e.g. removing a concept to observe changes in\nmodel behavior). In this paper, we introduce LEAst-squares Concept Erasure\n(LEACE), a closed-form method which provably prevents all linear classifiers\nfrom detecting a concept while inflicting the least possible damage to the\nrepresentation. We apply LEACE to large language models with a novel procedure\ncalled \"concept scrubbing,\" which erases target concept information from every\nlayer in the network. We demonstrate the usefulness of our method on two tasks:\nmeasuring the reliance of language models on part-of-speech information, and\nreducing gender bias in BERT embeddings. Code is available at\nhttps://github.com/EleutherAI/concept-erasure.",
        "translated": "概念擦除的目的是从表示中去除特定的特征。它可以用来提高公平性(例如防止分类器使用性别或种族)和可解释性(例如移除观察模型行为变化的概念)。本文介绍了最小二乘概念擦除(LEACE)方法，这是一种可证明的闭式方法，它可以防止所有的线性分类器检测到一个概念，同时对表示造成最小可能的损害。我们将 LEACE 应用到大型语言模型中，使用了一种称为“概念擦除”的新方法，这种方法可以从网络的每一层删除目标概念信息。我们证明了我们的方法在两个任务上的有用性: 测量语言模型对词性信息的依赖性，以及减少 BERT 嵌入中的性别偏见。密码可于 https://github.com/eleutherai/concept-erasure 索取。"
    },
    {
        "title": "Prompt Space Optimizing Few-shot Reasoning Success with Large Language\n  Models",
        "url": "http://arxiv.org/abs/2306.03799v1",
        "pub_date": "2023-06-06",
        "summary": "Prompt engineering is an essential technique for enhancing the abilities of\nlarge language models (LLMs) by providing explicit and specific instructions.\nIt enables LLMs to excel in various tasks, such as arithmetic reasoning,\nquestion answering, summarization, relation extraction, machine translation,\nand sentiment analysis. Researchers have been actively exploring different\nprompt engineering strategies, such as Chain of Thought (CoT), Zero-CoT, and\nIn-context learning. However, an unresolved problem arises from the fact that\ncurrent approaches lack a solid theoretical foundation for determining optimal\nprompts. To address this issue in prompt engineering, we propose a new and\neffective approach called Prompt Space. Our methodology utilizes text\nembeddings to obtain basis vectors by matrix decomposition, and then constructs\na space for representing all prompts. Prompt Space significantly outperforms\nstate-of-the-art prompt paradigms on ten public reasoning benchmarks. Notably,\nwithout the help of the CoT method and the prompt \"Let's think step by step\",\nPrompt Space shows superior performance over the few-shot method. Overall, our\napproach provides a robust and fundamental theoretical framework for selecting\nsimple and effective prompts. This advancement marks a significant step towards\nimproving prompt engineering for a wide variety of applications in LLMs.",
        "translated": "提示工程是通过提供明确和具体的指令来提高大型语言模型(LLM)能力的一种基本技术。它使 LLM 能够胜任各种任务，例如算术推理、问题回答、总结、关系提取、机器翻译和情感分析。研究人员一直在积极探索不同的快速工程策略，如思维链(CoT) ，零 CoT 和在上下文中学习。然而，一个未解决的问题出现在这样一个事实上，即目前的方法缺乏确定最佳提示的坚实的理论基础。为了在快速工程中解决这个问题，我们提出了一种新的和有效的方法称为快速空间。我们的方法利用文本嵌入通过矩阵分解获得基向量，然后构造一个空间来表示所有的提示。Prompt Space 在10个公共推理基准上明显优于最先进的提示范例。值得注意的是，没有 CoT 方法和提示“让我们一步一步地思考”的帮助，Prompt Space 显示出优于少数镜头方法的性能。总的来说，我们的方法为选择简单有效的提示提供了一个强大的基础理论框架。这一进展标志着在改进 LLM 中各种应用的快速工程方面迈出了重要的一步。"
    },
    {
        "title": "MarineVRS: Marine Video Retrieval System with Explainability via\n  Semantic Understanding",
        "url": "http://arxiv.org/abs/2306.04593v1",
        "pub_date": "2023-06-07",
        "summary": "Building a video retrieval system that is robust and reliable, especially for\nthe marine environment, is a challenging task due to several factors such as\ndealing with massive amounts of dense and repetitive data, occlusion,\nblurriness, low lighting conditions, and abstract queries. To address these\nchallenges, we present MarineVRS, a novel and flexible video retrieval system\ndesigned explicitly for the marine domain. MarineVRS integrates\nstate-of-the-art methods for visual and linguistic object representation to\nenable efficient and accurate search and analysis of vast volumes of underwater\nvideo data. In addition, unlike the conventional video retrieval system, which\nonly permits users to index a collection of images or videos and search using a\nfree-form natural language sentence, our retrieval system includes an\nadditional Explainability module that outputs the segmentation masks of the\nobjects that the input query referred to. This feature allows users to identify\nand isolate specific objects in the video footage, leading to more detailed\nanalysis and understanding of their behavior and movements. Finally, with its\nadaptability, explainability, accuracy, and scalability, MarineVRS is a\npowerful tool for marine researchers and scientists to efficiently and\naccurately process vast amounts of data and gain deeper insights into the\nbehavior and movements of marine species.",
        "translated": "建立一个健壮可靠的视频检索系统，特别是对于海洋环境来说，是一个具有挑战性的任务，因为有几个因素，如处理大量密集和重复的数据，遮挡，模糊，低照明条件和抽象查询。为了应对这些挑战，我们提出了 MarineVRS，一个新颖的和灵活的视频检索系统，明确地为海洋领域设计。MarineVRS 集成了最先进的视觉和语言对象表示方法，能够高效、准确地搜索和分析海量水下视频数据。此外，与传统的视频检索系统不同，传统的视频检索系统只允许用户索引一组图像或视频并使用自由格式的自然语言句子进行搜索，我们的检索系统包括一个额外的可解释性模块，该模块输出输入查询引用的对象的分割掩码。这个功能允许用户识别和隔离视频画面中的特定物体，从而对它们的行为和动作进行更详细的分析和理解。最后，凭借其适应性、可解释性、准确性和可扩展性，MarineVRS 是海洋研究人员和科学家有效和准确地处理大量数据并获得对海洋物种行为和运动的更深刻见解的强大工具。"
    },
    {
        "title": "Constraint-based recommender system for crisis management simulations",
        "url": "http://arxiv.org/abs/2306.04553v1",
        "pub_date": "2023-06-07",
        "summary": "In the context of the evacuation of populations, some citizens/volunteers may\nwant and be able to participate in the evacuation of populations in difficulty\nby coming to lend a hand to emergency/evacuation vehicles with their own\nvehicles. One way of framing these impulses of solidarity would be to be able\nto list in real-time the citizens/volunteers available with their vehicles\n(land, sea, air, etc.), to be able to geolocate them according to the risk\nareas to be evacuated, and adding them to the evacuation/rescue vehicles.\nBecause it is difficult to propose an effective real-time operational system on\nthe field in a real crisis situation, in this work, we propose to add a module\nfor recommending driver/vehicle pairs (with their specificities) to a system of\ncrisis management simulation. To do that, we chose to model and develop an\nontology-supported constraint-based recommender system for crisis management\nsimulations.",
        "translated": "在疏散人口方面，一些公民/志愿人员可能希望并能够参与疏散有困难的人口，他们可以用自己的车辆向紧急/疏散车辆伸出援手。构建这些团结冲动的一种方式是能够实时列出可用车辆(陆地、海洋、空中等)的公民/志愿者，能够根据疏散的危险区域对他们进行地理定位，并将他们添加到疏散/救援车辆中。由于在真实的危机情况下很难提出一个有效的现场实时操作系统，本文提出在危机管理模拟系统中增加一个推荐驾驶员/车辆配对(及其特殊性)的模块。为此，我们选择建模和开发一个本体支持的基于约束的危机管理模拟推荐系统。"
    },
    {
        "title": "Embracing Uncertainty: Adaptive Vague Preference Policy Learning for\n  Multi-round Conversational Recommendation",
        "url": "http://arxiv.org/abs/2306.04487v1",
        "pub_date": "2023-06-07",
        "summary": "Conversational recommendation systems (CRS) effectively address information\nasymmetry by dynamically eliciting user preferences through multi-turn\ninteractions. Existing CRS widely assumes that users have clear preferences.\nUnder this assumption, the agent will completely trust the user feedback and\ntreat the accepted or rejected signals as strong indicators to filter items and\nreduce the candidate space, which may lead to the problem of over-filtering.\nHowever, in reality, users' preferences are often vague and volatile, with\nuncertainty about their desires and changing decisions during interactions.\n  To address this issue, we introduce a novel scenario called Vague Preference\nMulti-round Conversational Recommendation (VPMCR), which considers users' vague\nand volatile preferences in CRS.VPMCR employs a soft estimation mechanism to\nassign a non-zero confidence score for all candidate items to be displayed,\nnaturally avoiding the over-filtering problem. In the VPMCR setting, we\nintroduce an solution called Adaptive Vague Preference Policy Learning (AVPPL),\nwhich consists of two main components: Uncertainty-aware Soft Estimation (USE)\nand Uncertainty-aware Policy Learning (UPL). USE estimates the uncertainty of\nusers' vague feedback and captures their dynamic preferences using a\nchoice-based preferences extraction module and a time-aware decaying strategy.\nUPL leverages the preference distribution estimated by USE to guide the\nconversation and adapt to changes in users' preferences to make recommendations\nor ask for attributes.\n  Our extensive experiments demonstrate the effectiveness of our method in the\nVPMCR scenario, highlighting its potential for practical applications and\nimproving the overall performance and applicability of CRS in real-world\nsettings, particularly for users with vague or dynamic preferences.",
        "translated": "会话推荐系统(CRS)通过多回合交互动态引出用户偏好，从而有效地解决信息不对称问题。现有的 CRS 普遍假设用户有明确的偏好。在这种假设下，代理完全信任用户的反馈，将接受或拒绝的信号作为强指标来过滤项目，减少候选空间，从而可能导致过滤问题。然而，在现实中，用户的偏好往往是模糊和不稳定的，他们的愿望和交互过程中改变决定的不确定性。为了解决这一问题，我们引入了一种新的场景——模糊偏好多轮会话推荐(VPMCR) ，该场景考虑了 CRS 中用户的模糊和不稳定偏好。 VPMCR 采用了一种软估计机制，为所有待显示的候选项赋予一个非零置信度分数，自然避免了过滤问题。在 VPCR 设置中，我们引入了一个称为自适应模糊偏好策略学习(AdaptiveVague Preferences Policy Learning，AVPPL)的解决方案，该解决方案由两个主要组件组成: 不确定感知软估计(UUSE)和不确定感知策略学习(UPL)。USE 利用基于选择的偏好提取模块和时间感知衰减策略估计用户模糊反馈的不确定性，并获取用户的动态偏好。UPL 利用 USE 估计的偏好分布来引导对话，并适应用户偏好的变化来提出建议或请求属性。我们的广泛实验证明了我们的方法在 VPCR 场景中的有效性，突出了其实际应用的潜力，并提高了 CRS 在现实世界环境中的总体性能和适用性，特别是对于具有模糊或动态偏好的用户。"
    },
    {
        "title": "RD-Suite: A Benchmark for Ranking Distillation",
        "url": "http://arxiv.org/abs/2306.04455v1",
        "pub_date": "2023-06-07",
        "summary": "The distillation of ranking models has become an important topic in both\nacademia and industry. In recent years, several advanced methods have been\nproposed to tackle this problem, often leveraging ranking information from\nteacher rankers that is absent in traditional classification settings. To date,\nthere is no well-established consensus on how to evaluate this class of models.\nMoreover, inconsistent benchmarking on a wide range of tasks and datasets make\nit difficult to assess or invigorate advances in this field. This paper first\nexamines representative prior arts on ranking distillation, and raises three\nquestions to be answered around methodology and reproducibility. To that end,\nwe propose a systematic and unified benchmark, Ranking Distillation Suite\n(RD-Suite), which is a suite of tasks with 4 large real-world datasets,\nencompassing two major modalities (textual and numeric) and two applications\n(standard distillation and distillation transfer). RD-Suite consists of\nbenchmark results that challenge some of the common wisdom in the field, and\nthe release of datasets with teacher scores and evaluation scripts for future\nresearch. RD-Suite paves the way towards better understanding of ranking\ndistillation, facilities more research in this direction, and presents new\nchallenges.",
        "translated": "排序模型的提取已经成为学术界和工业界的一个重要课题。近年来，一些先进的方法被提出来解决这个问题，往往利用排名信息从教师排名，这是缺乏在传统的分类设置。到目前为止，对于如何评估这类模型还没有确定的共识。此外，对广泛的任务和数据集不一致的基准设定使得难以评估或激励这一领域的进展。本文首先考察了有代表性的等级精馏现有技术，并围绕方法论和可重复性提出了三个需要回答的问题。为此，我们提出了一个系统和统一的基准，秩序蒸馏套件(RD-Suite) ，这是一套任务与4个大型真实世界数据集，包括两个主要模式(文本和数字)和两个应用程序(标准蒸馏和蒸馏转移)。RD-Suite 包括挑战该领域常识的基准测试结果，以及发布包含教师成绩和未来研究评估脚本的数据集。RD-Suite 为更好地理解分级蒸馏铺平了道路，设备在这个方向上进行了更多的研究，并提出了新的挑战。"
    },
    {
        "title": "Modeling Dual Period-Varying Preferences for Takeaway Recommendation",
        "url": "http://arxiv.org/abs/2306.04370v1",
        "pub_date": "2023-06-07",
        "summary": "Takeaway recommender systems, which aim to accurately provide stores that\noffer foods meeting users' interests, have served billions of users in our\ndaily life. Different from traditional recommendation, takeaway recommendation\nfaces two main challenges: (1) Dual Interaction-Aware Preference Modeling.\nTraditional recommendation commonly focuses on users' single preferences for\nitems while takeaway recommendation needs to comprehensively consider users'\ndual preferences for stores and foods. (2) Period-Varying Preference Modeling.\nConventional recommendation generally models continuous changes in users'\npreferences from a session-level or day-level perspective. However, in\npractical takeaway systems, users' preferences vary significantly during the\nmorning, noon, night, and late night periods of the day. To address these\nchallenges, we propose a Dual Period-Varying Preference modeling (DPVP) for\ntakeaway recommendation. Specifically, we design a dual interaction-aware\nmodule, aiming to capture users' dual preferences based on their interactions\nwith stores and foods. Moreover, to model various preferences in different time\nperiods of the day, we propose a time-based decomposition module as well as a\ntime-aware gating mechanism. Extensive offline and online experiments\ndemonstrate that our model outperforms state-of-the-art methods on real-world\ndatasets and it is capable of modeling the dual period-varying preferences.\nMoreover, our model has been deployed online on Meituan Takeaway platform,\nleading to an average improvement in GMV (Gross Merchandise Value) of 0.70%.",
        "translated": "外卖推荐系统，旨在准确地提供商店，提供符合用户兴趣的食品，已服务于数十亿用户在我们的日常生活。与传统的推荐不同，外卖推荐面临着两个主要挑战: (1)双交互感知偏好建模。传统的推荐方式通常侧重于用户对商品的单一偏好，而外卖推荐方式则需要全面考虑用户对商店和食品的双重偏好。(变周期偏好模型。传统的推荐通常从会话级或日级的角度模拟用户偏好的持续变化。然而，在实际的外卖系统中，用户的偏好在白天的早上、中午、晚上和深夜各不相同。为了应对这些挑战，我们提出了一个外卖推荐的双周期变化偏好模型(DPVP)。具体来说，我们设计了一个双交互感知模块，旨在根据用户与商店和食物的交互来捕捉他们的双重偏好。此外，为了模拟一天中不同时段的各种偏好，我们提出了一个基于时间的分解模块以及一个时间感知的门控机制。大量的离线和在线实验表明，我们的模型优于现实世界数据集的最先进的方法，它能够建模的双周期变化的偏好。此外，我们的模型已经在美团外卖平台上进行了在线部署，导致平均商品总值(GMV)提高了0.70% 。"
    },
    {
        "title": "ModuleFormer: Learning Modular Large Language Models From Uncurated Data",
        "url": "http://arxiv.org/abs/2306.04640v1",
        "pub_date": "2023-06-07",
        "summary": "Large Language Models (LLMs) have achieved remarkable results. But existing\nmodels are expensive to train and deploy, and it is also difficult to expand\ntheir knowledge beyond pre-training data without forgetting previous knowledge.\nThis paper proposes a new neural network architecture, ModuleFormer, that\nleverages modularity to improve the efficiency and flexibility of large\nlanguage models. ModuleFormer is based on the Sparse Mixture of Experts (SMoE).\nUnlike the previous SMoE-based modular language model [Gururangan et al.,\n2021], which requires domain-labeled data to learn domain-specific experts,\nModuleFormer can induce modularity from uncurated data with its new load\nbalancing and load concentration losses. ModuleFormer is a modular architecture\nthat includes two different types of modules, new stick-breaking attention\nheads, and feedforward experts. Different modules are sparsely activated\nconditions on the input token during training and inference. In our experiment,\nwe found that the modular architecture enables three important abilities for\nlarge pre-trained language models: 1) Efficiency, since ModuleFormer only\nactivates a subset of its modules for each input token, thus it could achieve\nthe same performance as dense LLMs with more than two times throughput; 2)\nExtendability, ModuleFormer is more immune to catastrophic forgetting than\ndense LLMs and can be easily extended with new modules to learn new knowledge\nthat is not included in the training data; 3) Specialisation, finetuning\nModuleFormer could specialize a subset of modules to the finetuning task, and\nthe task-unrelated modules could be easily pruned for a lightweight deployment.",
        "translated": "大语言模型(LLM)已经取得了显著的成果。但现有模型的培训和部署成本很高，而且很难在不忘记先前知识的情况下扩展其知识范围，超出培训前的数据。本文提出了一种新的神经网络结构——模块化网络结构，该结构利用模块化来提高大型语言模型的效率和灵活性。基于稀疏混合专家算法(SMoE)的模块形成器。与以前基于 SMoE 的模块化语言模型[ Gururangan et al。 ，2021]不同，其需要领域标记的数据来学习领域特定的专家，ModuleForm 可以通过其新的负载平衡和负载集中损失来诱导未经策划的数据的模块化。ModuleForm 是一个模块化架构，包括两种不同类型的模块、新的分散注意力的头部和前馈专家。在训练和推理过程中，不同的模块在输入令牌上是稀疏激活的条件。在我们的实验中，我们发现模块化架构为大型预先训练的语言模型提供了三个重要的能力: 1)效率，因为模块化程序只为每个输入令牌激活其模块的一个子集，因此它可以达到与密集 LLM 相同的性能，吞吐量超过两倍; 2)可扩展性，模块化程序比密集 LLM 更能免疫灾难性遗忘，并且可以很容易地用新模块进行扩展，以学习未包含在训练数据中的新知识; 3)专业化，微调的模块化程序可以为微调任务专门化模块的一个子集，并且与任务无关的模块可以很容易地为。"
    },
    {
        "title": "Transformers as Statisticians: Provable In-Context Learning with\n  In-Context Algorithm Selection",
        "url": "http://arxiv.org/abs/2306.04637v1",
        "pub_date": "2023-06-07",
        "summary": "Neural sequence models based on the transformer architecture have\ndemonstrated remarkable \\emph{in-context learning} (ICL) abilities, where they\ncan perform new tasks when prompted with training and test examples, without\nany parameter update to the model. This work first provides a comprehensive\nstatistical theory for transformers to perform ICL. Concretely, we show that\ntransformers can implement a broad class of standard machine learning\nalgorithms in context, such as least squares, ridge regression, Lasso, learning\ngeneralized linear models, and gradient descent on two-layer neural networks,\nwith near-optimal predictive power on various in-context data distributions.\nUsing an efficient implementation of in-context gradient descent as the\nunderlying mechanism, our transformer constructions admit mild size bounds, and\ncan be learned with polynomially many pretraining sequences.\n  Building on these ``base'' ICL algorithms, intriguingly, we show that\ntransformers can implement more complex ICL procedures involving\n\\emph{in-context algorithm selection}, akin to what a statistician can do in\nreal life -- A \\emph{single} transformer can adaptively select different base\nICL algorithms -- or even perform qualitatively different tasks -- on different\ninput sequences, without any explicit prompting of the right algorithm or task.\nWe both establish this in theory by explicit constructions, and also observe\nthis phenomenon experimentally. In theory, we construct two general mechanisms\nfor algorithm selection with concrete examples: pre-ICL testing, and post-ICL\nvalidation. As an example, we use the post-ICL validation mechanism to\nconstruct a transformer that can perform nearly Bayes-optimal ICL on a\nchallenging task -- noisy linear models with mixed noise levels.\nExperimentally, we demonstrate the strong in-context algorithm selection\ncapabilities of standard transformer architectures.",
        "translated": "基于变压器结构的神经序列模型表现出了显著的移动{在上下文中学习}(ICL)能力，它们可以在训练和测试示例的提示下执行新的任务，而不需要对模型进行任何参数更新。这项工作首先为变压器执行 ICL 提供了一个全面的统计理论。具体来说，我们展示了变压器可以在上下文环境中实现一大类标准的机器学习算法，如最小二乘、岭回归、套索、学习广义线性模型，以及在两层神经网络上实现梯度下降法，对各种上下文数据分布具有近乎最优的预测能力。使用一个有效的实现在上下文中的梯度下降法作为底层机制，我们的变压器结构承认温和的大小界限，可以学习与多项式许多预训练序列。在这些“基本”ICL 算法的基础上，有趣的是，我们展示了变压器可以实现更复杂的 ICL 程序，包括 emph { in-context 算法选择} ，类似于统计学家在现实生活中可以做的——一个 emph { single }变压器可以自适应地选择不同的基本 ICL 算法——甚至可以执行定性上不同的任务——在不同的输入序列上，没有任何明确的正确算法或任务的提示。我们通过明确的结构在理论上建立了这种现象，并且通过实验观察了这种现象。在理论上，我们通过具体的实例构造了两种通用的算法选择机制: 前 ICL 测试和后 ICL 验证。作为一个例子，我们使用后 ICL 验证机制来构造一个变压器，可以执行接近贝叶斯最优的 ICL 在一个具有挑战性的任务-混合噪声水平的线性模型。实验表明，标准变压器结构具有很强的上下文算法选择能力。"
    },
    {
        "title": "On the Reliability of Watermarks for Large Language Models",
        "url": "http://arxiv.org/abs/2306.04634v1",
        "pub_date": "2023-06-07",
        "summary": "Large language models (LLMs) are now deployed to everyday use and positioned\nto produce large quantities of text in the coming decade. Machine-generated\ntext may displace human-written text on the internet and has the potential to\nbe used for malicious purposes, such as spearphishing attacks and social media\nbots. Watermarking is a simple and effective strategy for mitigating such harms\nby enabling the detection and documentation of LLM-generated text. Yet, a\ncrucial question remains: How reliable is watermarking in realistic settings in\nthe wild? There, watermarked text might be mixed with other text sources,\nparaphrased by human writers or other language models, and used for\napplications in a broad number of domains, both social and technical. In this\npaper, we explore different detection schemes, quantify their power at\ndetecting watermarks, and determine how much machine-generated text needs to be\nobserved in each scenario to reliably detect the watermark. We especially\nhighlight our human study, where we investigate the reliability of watermarking\nwhen faced with human paraphrasing. We compare watermark-based detection to\nother detection strategies, finding overall that watermarking is a reliable\nsolution, especially because of its sample complexity - for all attacks we\nconsider, the watermark evidence compounds the more examples are given, and the\nwatermark is eventually detected.",
        "translated": "大型语言模型(LLM)现在被部署到日常使用中，并定位于在未来十年生成大量文本。机器生成的文本可能取代互联网上人写的文本，并有可能被用于恶意目的，如鱼叉式钓鱼攻击和社交媒体机器人。水印是一种简单而有效的策略，通过检测和记录 LLM 生成的文本来减轻这种危害。然而，一个关键的问题仍然存在: 在野外的现实环境中，水印的可靠性如何？在那里，水印文本可能与其他文本来源混合，由人类作家或其他语言模型转述，并用于广泛的领域中的应用，包括社会和技术。在本文中，我们探讨了不同的检测方案，量化它们在检测水印方面的能力，并确定在每个场景中需要观察多少机器生成的文本才能可靠地检测水印。我们特别强调我们的人类研究，我们调查的可靠性水印时，面对人类释义。我们比较了基于水印的检测和其他检测策略，发现水印是一个可靠的解决方案，特别是因为它的样本复杂性-对于所有的攻击，我们考虑，水印证据复合越多的例子，并最终检测水印。"
    },
    {
        "title": "Revisiting Out-of-distribution Robustness in NLP: Benchmark, Analysis,\n  and LLMs Evaluations",
        "url": "http://arxiv.org/abs/2306.04618v1",
        "pub_date": "2023-06-07",
        "summary": "This paper reexamines the research on out-of-distribution (OOD) robustness in\nthe field of NLP. We find that the distribution shift settings in previous\nstudies commonly lack adequate challenges, hindering the accurate evaluation of\nOOD robustness. To address these issues, we propose a benchmark construction\nprotocol that ensures clear differentiation and challenging distribution\nshifts. Then we introduce BOSS, a Benchmark suite for Out-of-distribution\nrobustneSS evaluation covering 5 tasks and 20 datasets. Based on BOSS, we\nconduct a series of experiments on pre-trained language models for analysis and\nevaluation of OOD robustness. First, for vanilla fine-tuning, we examine the\nrelationship between in-distribution (ID) and OOD performance. We identify\nthree typical types that unveil the inner learning mechanism, which could\npotentially facilitate the forecasting of OOD robustness, correlating with the\nadvancements on ID datasets. Then, we evaluate 5 classic methods on BOSS and\nfind that, despite exhibiting some effectiveness in specific cases, they do not\noffer significant improvement compared to vanilla fine-tuning. Further, we\nevaluate 5 LLMs with various adaptation paradigms and find that when sufficient\nID data is available, fine-tuning domain-specific models outperform LLMs on ID\nexamples significantly. However, in the case of OOD instances, prioritizing\nLLMs with in-context learning yields better results. We identify that both\nfine-tuned small models and LLMs face challenges in effectively addressing\ndownstream tasks. The code is public at\n\\url{https://github.com/lifan-yuan/OOD_NLP}.",
        "translated": "本文重新审视了自然语言处理领域中分布外(OOD)鲁棒性的研究。我们发现在以往的研究中，分布移位设置通常缺乏足够的挑战，阻碍了面向对象的鲁棒性的准确评估。为了解决这些问题，我们提出了一个基准建设协议，以确保明确的差异和挑战性的分配转移。然后我们介绍了 BOSS，一个用于分布外鲁棒性评估的基准套件，包括5个任务和20个数据集。基于 BOSS 系统，我们对预训练语言模型进行了一系列的实验，用于分析和评估面向对象的鲁棒性。首先，对于普通的微调，我们研究分发内(ID)和 OOD 性能之间的关系。我们确定了三种典型的类型，揭示了内部学习机制，这可能有助于面向对象的鲁棒性预测，与 ID 数据集的进步相关。然后，我们对 BOSS 上的5种经典方法进行了评估，发现尽管它们在特定情况下显示出一些有效性，但与普通的微调相比，它们并没有提供显著的改进。此外，我们评估了5个具有不同适应范例的 LLM，发现当有足够的 ID 数据可用时，针对特定领域的微调模型在 ID 示例上的表现明显优于 LLM。但是，在面向对象的实例中，使用上下文内学习对 LLM 进行优先排序会产生更好的结果。我们发现，微调小型模型和 LLM 在有效处理下游任务方面都面临挑战。该代码在 url { https://github.com/lifan-yuan/ood_nlp }是公共的。"
    },
    {
        "title": "The Two Word Test: A Semantic Benchmark for Large Language Models",
        "url": "http://arxiv.org/abs/2306.04610v1",
        "pub_date": "2023-06-07",
        "summary": "Large Language Models (LLMs) have shown remarkable abilities recently,\nincluding passing advanced professional exams and demanding benchmark tests.\nThis performance has led many to suggest that they are close to achieving\nhumanlike or 'true' understanding of language, and even Artificial General\nIntelligence (AGI). Here, we provide a new open-source benchmark that can\nassess semantic abilities of LLMs using two-word phrases using a task that can\nbe performed relatively easily by humans without advanced training. Combining\nmultiple words into a single concept is a fundamental aspect of human language\nand intelligence. The test requires meaningfulness judgments of 1768 noun-noun\ncombinations that have been rated as meaningful (e.g., baby boy) or not\nmeaningful (e.g., goat sky). by 150 human raters. We provide versions of the\ntask that probe meaningfulness ratings on a 0-4 scale as well as binary\njudgments. We conducted a series of experiments using the TWT on GPT-4,\nGPT-3.5, and Bard, with both versions. Results demonstrated that, compared to\nhumans, all models perform poorly at rating meaningfulness of these phrases.\nGPT-3.5 and Bard are also unable to make binary discriminations between\nsensible and nonsense phrases as making sense. GPT-4 makes a substantial\nimprovement in binary discrimination of combinatorial phrases but is still\nsignificantly worse than human performance. The TWT can be used to understand\nthe limitations and weaknesses of current LLMs, and potentially improve them.\nThe test also reminds us that caution is warranted in attributing 'true\nunderstanding' or AGI to LLMs. TWT is available at:\nhttps://github.com/NickRiccardi/two-word-test",
        "translated": "大型语言模型(LLM)最近显示出非凡的能力，包括通过高级专业考试和苛刻的基准测试。这种表现使得许多人认为他们已经接近达到类人或“真正”理解语言，甚至人工通用智能(AGI)。在这里，我们提供了一个新的开源基准，可以使用两个词的短语来评估 LLM 的语义能力，使用的任务可以相对容易地由人类执行，而不需要高级培训。将多个单词组合成一个单一的概念是人类语言和智力的一个基本方面。这个测试需要对1768个名词和名词的组合进行有意义的判断，这些组合被认为是有意义的(比如，男婴)或者没有意义的(比如，山羊天空)。被150个人类评估员评估。我们提供了任务的版本，探讨有意义的评级在0-4尺度以及二元判断。我们使用行波管在 GPT-4、 GPT-3.5和巴德上进行了一系列的实验，两个版本都有。结果表明，与人类相比，所有的模型在评价这些短语的意义方面表现不佳。GPT-3.5和巴德也不能把明智的和无意义的短语作为有意义的二元区分。GPT-4在组合短语的二进制识别方面有显著改善，但仍明显低于人类的识别水平。行波管可以用来了解现有 LLM 的局限性和弱点，并可能改进它们。该测试还提醒我们，在将“真正的理解”或 AGI 归因于 LLM 时，谨慎是必要的。TWT 可在以下 https://github.com/nickriccardi/two-word-test 购买:"
    },
    {
        "title": "Language Models Get a Gender Makeover: Mitigating Gender Bias with\n  Few-Shot Data Interventions",
        "url": "http://arxiv.org/abs/2306.04597v1",
        "pub_date": "2023-06-07",
        "summary": "Societal biases present in pre-trained large language models are a critical\nissue as these models have been shown to propagate biases in countless\ndownstream applications, rendering them unfair towards specific groups of\npeople. Since large-scale retraining of these models from scratch is both time\nand compute-expensive, a variety of approaches have been previously proposed\nthat de-bias a pre-trained model. While the majority of current\nstate-of-the-art debiasing methods focus on changes to the training regime, in\nthis paper, we propose data intervention strategies as a powerful yet simple\ntechnique to reduce gender bias in pre-trained models. Specifically, we\nempirically show that by fine-tuning a pre-trained model on only 10 de-biased\n(intervened) training examples, the tendency to favor any gender is\nsignificantly reduced. Since our proposed method only needs a few training\nexamples, our few-shot debiasing approach is highly feasible and practical.\nThrough extensive experimentation, we show that our debiasing technique\nperforms better than competitive state-of-the-art baselines with minimal loss\nin language modeling ability.",
        "translated": "预先训练的大型语言模型中存在的社会偏见是一个关键问题，因为这些模型已被证明在无数下游应用程序中传播偏见，使它们对特定人群不公平。由于从头开始对这些模型进行大规模的再训练既耗费时间又耗费计算机资源，因此先前已经提出了各种方法来消除预训练模型的偏差。虽然目前大多数最先进的消除偏见的方法集中在训练体制的变化，在本文中，我们提出的数据干预策略作为一个强大而简单的技术，以减少预训练模型中的性别偏见。具体来说，我们的经验表明，通过微调一个预先训练的模型，只有10个无偏见(干预)训练的例子，倾向于任何性别显着降低。由于本文提出的方法只需要少量训练样本，因此本文提出的小镜头消偏方法具有很高的可行性和实用性。通过大量的实验，我们发现我们的去偏技术在语言建模能力损失最小的情况下比竞争性的最先进的基线表现得更好。"
    },
    {
        "title": "Gender, names and other mysteries: Towards the ambiguous for\n  gender-inclusive translation",
        "url": "http://arxiv.org/abs/2306.04573v1",
        "pub_date": "2023-06-07",
        "summary": "The vast majority of work on gender in MT focuses on 'unambiguous' inputs,\nwhere gender markers in the source language are expected to be resolved in the\noutput. Conversely, this paper explores the widespread case where the source\nsentence lacks explicit gender markers, but the target sentence contains them\ndue to richer grammatical gender. We particularly focus on inputs containing\nperson names.\n  Investigating such sentence pairs casts a new light on research into MT\ngender bias and its mitigation. We find that many name-gender co-occurrences in\nMT data are not resolvable with 'unambiguous gender' in the source language,\nand that gender-ambiguous examples can make up a large proportion of training\nexamples. From this, we discuss potential steps toward gender-inclusive\ntranslation which accepts the ambiguity in both gender and translation.",
        "translated": "在机器翻译领域，绝大多数关于性别的工作集中在“明确的”输入上，源语言中的性别标记预计将在输出中得到解决。相反，本文探讨了普遍存在的一种情况，即原句缺乏明确的性别标记，但是由于性丰富，目标句包含了这些性别标记。我们特别关注包含人名的输入。对这类句子对的研究为 MT 性别偏见的研究及其缓解提供了新的视角。我们发现，在机器翻译数据中，许多名称-性别同时出现的情况不能用源语言中的“明确的性别”来解决，而且性别模糊的例子可以构成很大比例的训练例子。从这一点出发，我们讨论了实现性别包容性翻译的可能步骤，即接受性别歧义和翻译歧义。"
    },
    {
        "title": "ChatGPT is fun, but it is not funny! Humor is still challenging Large\n  Language Models",
        "url": "http://arxiv.org/abs/2306.04563v1",
        "pub_date": "2023-06-07",
        "summary": "Humor is a central aspect of human communication that has not been solved for\nartificial agents so far. Large language models (LLMs) are increasingly able to\ncapture implicit and contextual information. Especially, OpenAI's ChatGPT\nrecently gained immense public attention. The GPT3-based model almost seems to\ncommunicate on a human level and can even tell jokes. Humor is an essential\ncomponent of human communication. But is ChatGPT really funny? We put ChatGPT's\nsense of humor to the test. In a series of exploratory experiments around\njokes, i.e., generation, explanation, and detection, we seek to understand\nChatGPT's capability to grasp and reproduce human humor. Since the model itself\nis not accessible, we applied prompt-based experiments. Our empirical evidence\nindicates that jokes are not hard-coded but mostly also not newly generated by\nthe model. Over 90% of 1008 generated jokes were the same 25 Jokes. The system\naccurately explains valid jokes but also comes up with fictional explanations\nfor invalid jokes. Joke-typical characteristics can mislead ChatGPT in the\nclassification of jokes. ChatGPT has not solved computational humor yet but it\ncan be a big leap toward \"funny\" machines.",
        "translated": "幽默是人类交流的一个核心方面，迄今为止人工智能还没有解决这个问题。大型语言模型(LLM)越来越能够捕获隐式信息和上下文信息。尤其是 OpenAI 的 ChatGPT 最近引起了公众的广泛关注。基于 GPT3的模型几乎可以在人类水平上交流，甚至可以讲笑话。幽默是人际交往的重要组成部分。但是聊天 GPT 真的有趣吗？我们测试了 ChatGPT 的幽默感。在一系列围绕笑话的探索性实验中，即生成、解释和发现，我们试图理解 ChatGPT 掌握和再现人类幽默的能力。由于模型本身不可访问，我们应用了基于提示的实验。我们的经验证明表明，笑话不是硬编码的，但大多数也不是模型新生成的。在1008个笑话中，超过90% 的笑话都是相同的25个。该系统准确地解释了有效的笑话，但同时也为无效的笑话提供了虚构的解释。笑话的典型特征会误导聊天 GPT 对笑话的分类。ChatGPT 还没有解决计算幽默问题，但是它可以向“有趣的”机器迈出一大步。"
    },
    {
        "title": "Multi-Task Training with In-Domain Language Models for Diagnostic\n  Reasoning",
        "url": "http://arxiv.org/abs/2306.04551v1",
        "pub_date": "2023-06-07",
        "summary": "Generative artificial intelligence (AI) is a promising direction for\naugmenting clinical diagnostic decision support and reducing diagnostic errors,\na leading contributor to medical errors. To further the development of clinical\nAI systems, the Diagnostic Reasoning Benchmark (DR.BENCH) was introduced as a\ncomprehensive generative AI framework, comprised of six tasks representing key\ncomponents in clinical reasoning. We present a comparative analysis of\nin-domain versus out-of-domain language models as well as multi-task versus\nsingle task training with a focus on the problem summarization task in DR.BENCH\n(Gao et al., 2023). We demonstrate that a multi-task, clinically trained\nlanguage model outperforms its general domain counterpart by a large margin,\nestablishing a new state-of-the-art performance, with a ROUGE-L score of 28.55.\nThis research underscores the value of domain-specific training for optimizing\nclinical diagnostic reasoning tasks.",
        "translated": "生成性人工智能(AI)是增强临床诊断决策支持和减少诊断错误的一个有前途的方向，是导致医疗错误的主要因素。为了进一步发展临床人工智能系统，将诊断推理基准(DR.BENCH)作为一个全面的生成性人工智能框架引入，该框架由代表临床推理关键组成部分的六个任务组成。我们提出了领域内与领域外语言模型以及多任务与单任务训练的比较分析，重点是 DR.BENCH 中的问题总结任务(Gao et al。 ，2023)。我们证明，一个多任务，临床训练的语言模型优于其一般领域的对应大幅度，建立一个新的最先进的表现，ROUGE-L 分数为28.55。本研究强调了领域特定训练对于优化临床诊断推理任务的价值。"
    },
    {
        "title": "Contrastive Bootstrapping for Label Refinement",
        "url": "http://arxiv.org/abs/2306.04544v1",
        "pub_date": "2023-06-07",
        "summary": "Traditional text classification typically categorizes texts into pre-defined\ncoarse-grained classes, from which the produced models cannot handle the\nreal-world scenario where finer categories emerge periodically for accurate\nservices. In this work, we investigate the setting where fine-grained\nclassification is done only using the annotation of coarse-grained categories\nand the coarse-to-fine mapping. We propose a lightweight contrastive\nclustering-based bootstrapping method to iteratively refine the labels of\npassages. During clustering, it pulls away negative passage-prototype pairs\nunder the guidance of the mapping from both global and local perspectives.\nExperiments on NYT and 20News show that our method outperforms the\nstate-of-the-art methods by a large margin.",
        "translated": "传统的文本分类通常将文本分类为预定义的粗粒度类，由此产生的模型无法处理现实场景，即定期出现更精细的类别以获得准确的服务。在这项工作中，我们研究的设置，细粒度分类是完成只使用粗粒度类别的注释和粗到细的映射。提出了一种基于轻量级对比聚类的自举算法来迭代细化文章标签。在聚类过程中，它在映射的指导下，从全局和局部两个角度抽取负的通道原型对。在《纽约时报》和《20世纪新闻》上的实验表明，我们的方法比最先进的方法有很大的优势。"
    },
    {
        "title": "Safe Collaborative Filtering",
        "url": "http://arxiv.org/abs/2306.05292v1",
        "pub_date": "2023-06-08",
        "summary": "Excellent tail performance is crucial for modern machine learning tasks, such\nas algorithmic fairness, class imbalance, and risk-sensitive decision making,\nas it ensures the effective handling of challenging samples within a dataset.\nTail performance is also a vital determinant of success for personalised\nrecommender systems to reduce the risk of losing users with low satisfaction.\nThis study introduces a \"safe\" collaborative filtering method that prioritises\nrecommendation quality for less-satisfied users rather than focusing on the\naverage performance. Our approach minimises the conditional value at risk\n(CVaR), which represents the average risk over the tails of users' loss. To\novercome computational challenges for web-scale recommender systems, we develop\na robust yet practical algorithm that extends the most scalable method,\nimplicit alternating least squares (iALS). Empirical evaluation on real-world\ndatasets demonstrates the excellent tail performance of our approach while\nmaintaining competitive computational efficiency.",
        "translated": "优秀的尾部性能对于现代机器学习任务至关重要，例如算法公平性、类不平衡性和风险敏感决策，因为它确保有效处理数据集中具有挑战性的样本。尾部性能也是个性化推荐系统成功的一个重要决定因素，可以降低用户满意度不高而流失的风险。这项研究引入了一种“安全”的协同过滤方法，优先考虑对不满意用户的推荐质量，而不是关注平均性能。我们的方法将条件风险值(CVaR)最小化，CVaR 代表用户损失尾部的平均风险。为了克服网络规模推荐系统的计算挑战，我们开发了一个强大而实用的算法，扩展了最可扩展的方法，隐式交替最小二乘(iALS)。对真实世界数据集的实证评估证明了该方法在保持竞争计算效率的同时具有优异的尾部性能。"
    },
    {
        "title": "RETA-LLM: A Retrieval-Augmented Large Language Model Toolkit",
        "url": "http://arxiv.org/abs/2306.05212v1",
        "pub_date": "2023-06-08",
        "summary": "Although Large Language Models (LLMs) have demonstrated extraordinary\ncapabilities in many domains, they still have a tendency to hallucinate and\ngenerate fictitious responses to user requests. This problem can be alleviated\nby augmenting LLMs with information retrieval (IR) systems (also known as\nretrieval-augmented LLMs). Applying this strategy, LLMs can generate more\nfactual texts in response to user input according to the relevant content\nretrieved by IR systems from external corpora as references. In addition, by\nincorporating external knowledge, retrieval-augmented LLMs can answer in-domain\nquestions that cannot be answered by solely relying on the world knowledge\nstored in parameters. To support research in this area and facilitate the\ndevelopment of retrieval-augmented LLM systems, we develop RETA-LLM, a\n{RET}reival-{A}ugmented LLM toolkit. In RETA-LLM, we create a complete pipeline\nto help researchers and users build their customized in-domain LLM-based\nsystems. Compared with previous retrieval-augmented LLM systems, RETA-LLM\nprovides more plug-and-play modules to support better interaction between IR\nsystems and LLMs, including {request rewriting, document retrieval, passage\nextraction, answer generation, and fact checking} modules. Our toolkit is\npublicly available at https://github.com/RUC-GSAI/YuLan-IR/tree/main/RETA-LLM.",
        "translated": "尽管大型语言模型(LLM)已经在许多领域展示了非凡的能力，但是它们仍然有产生幻觉和对用户请求产生虚构响应的倾向。这个问题可以通过使用信息检索(IR)系统(也称为检索增强 LLM)来增强 LLM 来缓解。应用这种策略，LLM 可以根据 IR 系统从外部语料库中检索到的相关内容作为参考，根据用户的输入生成更多的事实性文本。此外，通过合并外部知识，检索增强 LLM 可以回答领域内的问题，而这些问题不能仅仅依赖于存储在参数中的世界知识来回答。为了支持这一领域的研究和促进检索增强 LLM 系统的发展，我们开发了 RETA-LLM，一个{ RET } reval-{ A }增强 LLM 工具包。在 RETA-LLM 中，我们创建了一个完整的管道来帮助研究人员和用户构建他们定制的基于领域 LLM 的系统。与以前的检索增强 LLM 系统相比，RETA-LLM 提供了更多的即插即用模块，以支持 IR 系统和 LLM 之间更好的交互，包括{请求重写、文献检索、段落提取、答案生成和事实检查}模块。我们的工具包可以在 https://github.com/ruc-gsai/yulan-ir/tree/main/reta-llm 上公开获得。"
    },
    {
        "title": "Controllable Multi-Objective Re-ranking with Policy Hypernetworks",
        "url": "http://arxiv.org/abs/2306.05118v1",
        "pub_date": "2023-06-08",
        "summary": "Multi-stage ranking pipelines have become widely used strategies in modern\nrecommender systems, where the final stage aims to return a ranked list of\nitems that balances a number of requirements such as user preference,\ndiversity, novelty etc. Linear scalarization is arguably the most widely used\ntechnique to merge multiple requirements into one optimization objective, by\nsumming up the requirements with certain preference weights. Existing\nfinal-stage ranking methods often adopt a static model where the preference\nweights are determined during offline training and kept unchanged during online\nserving. Whenever a modification of the preference weights is needed, the model\nhas to be re-trained, which is time and resources inefficient. Meanwhile, the\nmost appropriate weights may vary greatly for different groups of targeting\nusers or at different time periods (e.g., during holiday promotions). In this\npaper, we propose a framework called controllable multi-objective re-ranking\n(CMR) which incorporates a hypernetwork to generate parameters for a re-ranking\nmodel according to different preference weights. In this way, CMR is enabled to\nadapt the preference weights according to the environment changes in an online\nmanner, without retraining the models. Moreover, we classify practical\nbusiness-oriented tasks into four main categories and seamlessly incorporate\nthem in a new proposed re-ranking model based on an Actor-Evaluator framework,\nwhich serves as a reliable real-world testbed for CMR. Offline experiments\nbased on the dataset collected from Taobao App showed that CMR improved several\npopular re-ranking models by using them as underlying models. Online A/B tests\nalso demonstrated the effectiveness and trustworthiness of CMR.",
        "translated": "多阶段排名管道已经成为现代推荐系统中广泛使用的策略，最后阶段的目标是返回一个项目的排名列表，以平衡一些需求，如用户偏好，多样性，新颖性等。线性标量可以说是最广泛使用的技术合并多个需求到一个优化目标，通过总结需求与一定的偏好权重。现有的最后阶段排序方法通常采用静态模型，在离线训练期间确定偏好权重，在线服务期间保持不变。当需要修改偏好权重时，模型必须重新训练，这是时间和资源效率低下的。与此同时，最合适的权重可能会因不同的目标用户群体或在不同的时间段(例如，在假日促销期间)而有很大差异。本文提出了一种可控的多目标重排序(CMR)框架，该框架结合了一个超网络，根据不同的偏好权重为重排序模型生成参数。通过这种方式，CMR 能够根据环境变化在线调整偏好权重，而不需要重新训练模型。此外，我们将面向业务的实际任务分为四个主要类别，并将它们无缝地纳入一个新提出的重新排序模型，该模型基于一个演员-评估者框架，作为一个可靠的现实世界的 CMR 测试平台。基于从淘宝应用收集的数据集的离线实验表明，CMR 通过使用它们作为基础模型改进了几个流行的重新排名模型。在线 A/B 测试也证明了 CMR 的有效性和可信性。"
    },
    {
        "title": "Attention Weighted Mixture of Experts with Contrastive Learning for\n  Personalized Ranking in E-commerce",
        "url": "http://arxiv.org/abs/2306.05011v1",
        "pub_date": "2023-06-08",
        "summary": "Ranking model plays an essential role in e-commerce search and\nrecommendation. An effective ranking model should give a personalized ranking\nlist for each user according to the user preference. Existing algorithms\nusually extract a user representation vector from the user behavior sequence,\nthen feed the vector into a feed-forward network (FFN) together with other\nfeatures for feature interactions, and finally produce a personalized ranking\nscore. Despite tremendous progress in the past, there is still room for\nimprovement. Firstly, the personalized patterns of feature interactions for\ndifferent users are not explicitly modeled. Secondly, most of existing\nalgorithms have poor personalized ranking results for long-tail users with few\nhistorical behaviors due to the data sparsity. To overcome the two challenges,\nwe propose Attention Weighted Mixture of Experts (AW-MoE) with contrastive\nlearning for personalized ranking. Firstly, AW-MoE leverages the MoE framework\nto capture personalized feature interactions for different users. To model the\nuser preference, the user behavior sequence is simultaneously fed into expert\nnetworks and the gate network. Within the gate network, one gate unit and one\nactivation unit are designed to adaptively learn the fine-grained activation\nvector for experts using an attention mechanism. Secondly, a random masking\nstrategy is applied to the user behavior sequence to simulate long-tail users,\nand an auxiliary contrastive loss is imposed to the output of the gate network\nto improve the model generalization for these users. This is validated by a\nhigher performance gain on the long-tail user test set. Experiment results on a\nJD real production dataset and a public dataset demonstrate the effectiveness\nof AW-MoE, which significantly outperforms state-of-art methods. Notably,\nAW-MoE has been successfully deployed in the JD e-commerce search engine, ...",
        "translated": "排名模型在电子商务搜索和推荐中起着至关重要的作用。一个有效的排名模型应该根据用户的偏好为每个用户提供一个个性化的排名列表。现有的算法通常从用户行为序列中提取用户表示向量，然后将该向量与其他特征一起反馈到前馈网络(FFN)中进行特征交互，最终产生个性化的排序得分。尽管过去取得了巨大的进步，但仍有改进的空间。首先，不同用户特征交互的个性化模式没有明确建模。其次，由于数据稀疏，现有算法对于长尾用户的个性化排序效果较差，历史行为较少。为了克服这两个挑战，我们提出了基于对比学习的专家注意加权混合排序方法(AW-MoE)。首先，AW-MoE 利用 MoE 框架为不同的用户捕获个性化的特征交互。为了建立用户偏好模型，将用户行为序列同时输入到专家网络和门网络中。在门网络中，设计了一个门单元和一个激活单元，利用注意机制为专家自适应地学习细粒度激活向量。其次，对用户行为序列采用随机掩蔽策略来模拟长尾用户，并对门网络的输出增加辅助对比度损失，以提高对长尾用户的模型泛化能力。这通过在长尾用户测试集上获得更高的性能增益来验证。在 JD 实际生产数据集和公开数据集上的实验结果证明了 AW-MoE 方法的有效性，其性能明显优于最先进的方法。值得注意的是，AW-MoE 已经成功地部署在 JD 电子商务搜索引擎，..。"
    },
    {
        "title": "Unified Embedding Based Personalized Retrieval in Etsy Search",
        "url": "http://arxiv.org/abs/2306.04833v1",
        "pub_date": "2023-06-07",
        "summary": "Embedding-based neural retrieval is a prevalent approach to address the\nsemantic gap problem which often arises in product search on tail queries. In\ncontrast, popular queries typically lack context and have a broad intent where\nadditional context from users historical interaction can be helpful. In this\npaper, we share our novel approach to address both: the semantic gap problem\nfollowed by an end to end trained model for personalized semantic retrieval. We\npropose learning a unified embedding model incorporating graph, transformer and\nterm-based embeddings end to end and share our design choices for optimal\ntradeoff between performance and efficiency. We share our learnings in feature\nengineering, hard negative sampling strategy, and application of transformer\nmodel, including a novel pre-training strategy and other tricks for improving\nsearch relevance and deploying such a model at industry scale. Our personalized\nretrieval model significantly improves the overall search experience, as\nmeasured by a 5.58% increase in search purchase rate and a 2.63% increase in\nsite-wide conversion rate, aggregated across multiple A/B tests - on live\ntraffic.",
        "translated": "基于嵌入式的神经检索是解决尾部查询产品搜索中经常出现的语义缺口问题的一种常用方法。相比之下，流行的查询通常缺乏上下文，并且具有广泛的意图，其中来自用户历史交互的额外上下文可能有所帮助。在本文中，我们分享了我们的新方法来解决这两个问题: 语义差距问题，然后是个性化语义检索的端到端训练模型。我们提出了一种结合图形、变换器和基于术语的嵌入端到端学习的统一嵌入模型，并共享我们的设计选择，以实现性能和效率之间的最优平衡。我们分享了我们在特征工程、硬负采样策略和变压器模型应用方面的经验，包括一种新的预训练策略和其他提高搜索相关性和在行业规模部署此类模型的技巧。我们的个性化检索模型显著改善了整体搜索体验，通过对实时流量进行多个 A/B 测试，搜索购买率增加了5.58% ，网站转换率增加了2.63% 。"
    },
    {
        "title": "MIMIC-IT: Multi-Modal In-Context Instruction Tuning",
        "url": "http://arxiv.org/abs/2306.05425v1",
        "pub_date": "2023-06-08",
        "summary": "High-quality instructions and responses are essential for the zero-shot\nperformance of large language models on interactive natural language tasks. For\ninteractive vision-language tasks involving intricate visual scenes, a large\nquantity of diverse and creative instruction-response pairs should be\nimperative to tune vision-language models (VLMs). Nevertheless, the current\navailability of vision-language instruction-response pairs in terms of\nquantity, diversity, and creativity remains limited, posing challenges to the\ngeneralization of interactive VLMs. Here we present MultI-Modal In-Context\nInstruction Tuning (MIMIC-IT), a dataset comprising 2.8 million multimodal\ninstruction-response pairs, with 2.2 million unique instructions derived from\nimages and videos. Each pair is accompanied by multi-modal in-context\ninformation, forming conversational contexts aimed at empowering VLMs in\nperception, reasoning, and planning. The instruction-response collection\nprocess, dubbed as Syphus, is scaled using an automatic annotation pipeline\nthat combines human expertise with GPT's capabilities. Using the MIMIC-IT\ndataset, we train a large VLM named Otter. Based on extensive evaluations\nconducted on vision-language benchmarks, it has been observed that Otter\ndemonstrates remarkable proficiency in multi-modal perception, reasoning, and\nin-context learning. Human evaluation reveals it effectively aligns with the\nuser's intentions. We release the MIMIC-IT dataset, instruction-response\ncollection pipeline, benchmarks, and the Otter model.",
        "translated": "高质量的指令和响应对于大型语言模型在交互式自然语言任务中的零点性能至关重要。对于涉及复杂视觉场景的交互式视觉语言任务，必须调优视觉语言模型(VLM)。然而，目前视觉-语言教学-反应对在数量、多样性和创造性方面的可用性仍然有限，对交互式 VLM 的普及提出了挑战。在这里，我们介绍了多模态上下文指令调优(MIMIC-IT) ，一个包含280万个多模态指令-响应对的数据集，其中有220万个来自图像和视频的独特指令。每一对都伴随着多模态的语境信息，形成旨在赋予 VLM 感知、推理和计划能力的会话语境。这个被称为 Syphus 的指令-响应收集过程使用一个自动注释管道进行扩展，该管道将人类的专业知识与 GPT 的功能结合在一起。使用 MIMIC-IT 数据集，我们训练了一个名为 Otter 的大型 VLM。基于对视觉语言基准的广泛评估，我们发现 Otter 在多模态知觉、推理和语境学习方面表现出显著的能力。人工评估显示它有效地与用户的意图保持一致。我们发布 MIMIC-IT 数据集、指令-响应收集管道、基准测试和 Otter 模型。"
    },
    {
        "title": "Mixture-of-Domain-Adapters: Decoupling and Injecting Domain Knowledge to\n  Pre-trained Language Models Memories",
        "url": "http://arxiv.org/abs/2306.05406v1",
        "pub_date": "2023-06-08",
        "summary": "Pre-trained language models (PLMs) demonstrate excellent abilities to\nunderstand texts in the generic domain while struggling in a specific domain.\nAlthough continued pre-training on a large domain-specific corpus is effective,\nit is costly to tune all the parameters on the domain. In this paper, we\ninvestigate whether we can adapt PLMs both effectively and efficiently by only\ntuning a few parameters. Specifically, we decouple the feed-forward networks\n(FFNs) of the Transformer architecture into two parts: the original pre-trained\nFFNs to maintain the old-domain knowledge and our novel domain-specific\nadapters to inject domain-specific knowledge in parallel. Then we adopt a\nmixture-of-adapters gate to fuse the knowledge from different domain adapters\ndynamically. Our proposed Mixture-of-Domain-Adapters (MixDA) employs a\ntwo-stage adapter-tuning strategy that leverages both unlabeled data and\nlabeled data to help the domain adaptation: i) domain-specific adapter on\nunlabeled data; followed by ii) the task-specific adapter on labeled data.\nMixDA can be seamlessly plugged into the pretraining-finetuning paradigm and\nour experiments demonstrate that MixDA achieves superior performance on\nin-domain tasks (GLUE), out-of-domain tasks (ChemProt, RCT, IMDB, Amazon), and\nknowledge-intensive tasks (KILT). Further analyses demonstrate the reliability,\nscalability, and efficiency of our method. The code is available at\nhttps://github.com/Amano-Aki/Mixture-of-Domain-Adapters.",
        "translated": "预训练语言模型(PLM)展示了在通用领域理解文本而在特定领域挣扎的卓越能力。尽管在特定于领域的大型语料库上进行持续的预训练是有效的，但是调优领域上的所有参数的成本是很高的。在本文中，我们研究是否可以适应 PLM 的有效性和有效性，只需调整几个参数。具体来说，我们将变压器结构的前馈网络(FFN)解耦为两部分: 原始的预先训练的 FFN 来维护旧的领域知识，以及我们新颖的领域特定适配器来并行注入领域特定的知识。然后采用混合适配器门来动态融合来自不同领域适配器的知识。我们提出的混合域适配器(MixDA)采用两阶段适配器调优策略，利用未标记数据和标记数据来帮助域适配: i)未标记数据上的域特定适配器; 随后 ii)标记数据上的任务特定适配器。MixDA 可以无缝地插入预训练-微调范式，我们的实验表明，MixDA 在域内任务(GLUE) ，域外任务(ChemProt，RCT，IMDB，Amazon)和知识密集型任务(KILT)上取得了优越的性能。进一步的分析证明了该方法的可靠性、可扩展性和有效性。密码可在 https://github.com/amano-aki/mixture-of-domain-adapters 查阅。"
    },
    {
        "title": "Modular Visual Question Answering via Code Generation",
        "url": "http://arxiv.org/abs/2306.05392v1",
        "pub_date": "2023-06-08",
        "summary": "We present a framework that formulates visual question answering as modular\ncode generation. In contrast to prior work on modular approaches to VQA, our\napproach requires no additional training and relies on pre-trained language\nmodels (LMs), visual models pre-trained on image-caption pairs, and fifty VQA\nexamples used for in-context learning. The generated Python programs invoke and\ncompose the outputs of the visual models using arithmetic and conditional\nlogic. Our approach improves accuracy on the COVR dataset by at least 3% and on\nthe GQA dataset by roughly 2% compared to the few-shot baseline that does not\nemploy code generation.",
        "translated": "我们提出了一个框架，制定可视化问题回答作为模块化代码生成。与之前关于 VQA 模块化方法的工作相比，我们的方法不需要额外的培训，并且依赖于预先训练的语言模型(LM) ，在图像-标题对上预先训练的可视化模型以及用于上下文学习的50个 VQA 示例。生成的 Python 程序使用算术和条件逻辑调用和组合可视化模型的输出。我们的方法在 COVR 数据集上提高了至少3% 的准确性，在 GQA 数据集上提高了大约2% 的准确性，相比之下，不使用代码生成的少镜头基线。"
    },
    {
        "title": "Utterance Emotion Dynamics in Children's Poems: Emotional Changes Across\n  Age",
        "url": "http://arxiv.org/abs/2306.05387v1",
        "pub_date": "2023-06-08",
        "summary": "Emerging psychopathology studies are showing that patterns of changes in\nemotional state -- emotion dynamics -- are associated with overall well-being\nand mental health. More recently, there has been some work in tracking emotion\ndynamics through one's utterances, allowing for data to be collected on a\nlarger scale across time and people. However, several questions about how\nemotion dynamics change with age, especially in children, and when determined\nthrough children's writing, remain unanswered. In this work, we use both a\nlexicon and a machine learning based approach to quantify characteristics of\nemotion dynamics determined from poems written by children of various ages. We\nshow that both approaches point to similar trends: consistent increasing\nintensities for some emotions (e.g., anger, fear, joy, sadness, arousal, and\ndominance) with age and a consistent decreasing valence with age. We also find\nincreasing emotional variability, rise rates (i.e., emotional reactivity), and\nrecovery rates (i.e., emotional regulation) with age. These results act as a\nuseful baselines for further research in how patterns of emotions expressed by\nchildren change with age, and their association with mental health.",
        "translated": "新兴的精神病理学研究表明，情绪状态的变化模式——情绪动力学——与整体幸福感和心理健康有关。最近，已经有一些工作通过一个人的话语跟踪情绪动态，允许跨越时间和人的更大规模的数据收集。然而，一些关于情绪动态如何随着年龄变化的问题，特别是在儿童中，以及当通过儿童的写作决定时，仍然没有答案。本研究采用词汇学习和机器学习相结合的方法，对不同年龄段儿童诗歌的情绪动力学特征进行量化研究。我们发现，这两种方法都指向相似的趋势: 随着年龄的增长，某些情绪(例如，愤怒、恐惧、喜悦、悲伤、觉醒和支配)的强度持续增加，而随着年龄的增长，情绪的效价持续下降。我们还发现，随着年龄的增长，情绪波动性、情绪反应性和恢复率都在增加。这些结果为进一步研究儿童表达的情绪模式如何随年龄变化及其与心理健康的关系提供了有用的基线。"
    },
    {
        "title": "The ADAIO System at the BEA-2023 Shared Task on Generating AI Teacher\n  Responses in Educational Dialogues",
        "url": "http://arxiv.org/abs/2306.05360v1",
        "pub_date": "2023-06-08",
        "summary": "This paper presents the ADAIO team's system entry in the Building Educational\nApplications (BEA) 2023 Shared Task on Generating AI Teacher Responses in\nEducational Dialogues. The task aims to assess the performance of\nstate-of-the-art generative models as AI teachers in producing suitable\nresponses within a student-teacher dialogue. Our system comprises evaluating\nvarious baseline models using OpenAI GPT-3 and designing diverse prompts to\nprompt the OpenAI models for teacher response generation. After the challenge,\nour system achieved second place by employing a few-shot prompt-based approach\nwith the OpenAI text-davinci-003 model. The results highlight the few-shot\nlearning capabilities of large-language models, particularly OpenAI's GPT-3, in\nthe role of AI teachers.",
        "translated": "本文介绍了 ADAIO 团队的系统条目在建筑教育应用(BEA)2023共同任务生成人工智能教师在教育对话中的反应。这项任务旨在评估最先进的生成模式作为人工智能教师在学生-教师对话中产生适当反应的表现。我们的系统包括使用 OpenAI GPT-3评估各种基线模型，并设计不同的提示以提示 OpenAI 模型用于教师反应生成。经过挑战，我们的系统取得了第二名，采用了几个镜头的提示为基础的方法与 OpenAI 文本达芬奇003模型。研究结果强调了大型语言模型(尤其是 OpenAI 的 GPT-3)在人工智能教师角色中的少量学习能力。"
    },
    {
        "title": "Advancing Italian Biomedical Information Extraction with Large Language\n  Models: Methodological Insights and Multicenter Practical Application",
        "url": "http://arxiv.org/abs/2306.05323v1",
        "pub_date": "2023-06-08",
        "summary": "The introduction of computerized medical records in hospitals has reduced\nburdensome operations like manual writing and information fetching. However,\nthe data contained in medical records are still far underutilized, primarily\nbecause extracting them from unstructured textual medical records takes time\nand effort. Information Extraction, a subfield of Natural Language Processing,\ncan help clinical practitioners overcome this limitation, using automated\ntext-mining pipelines. In this work, we created the first Italian\nneuropsychiatric Named Entity Recognition dataset, PsyNIT, and used it to\ndevelop a Large Language Model for this task. Moreover, we conducted several\nexperiments with three external independent datasets to implement an effective\nmulticenter model, with overall F1-score 84.77%, Precision 83.16%, Recall\n86.44%. The lessons learned are: (i) the crucial role of a consistent\nannotation process and (ii) a fine-tuning strategy that combines classical\nmethods with a \"few-shot\" approach. This allowed us to establish methodological\nguidelines that pave the way for future implementations in this field and allow\nItalian hospitals to tap into important research opportunities.",
        "translated": "医院采用计算机化病历减少了手工书写和信息提取等繁重的操作。然而，包含在医疗记录中的数据仍然没有得到充分利用，主要是因为从非结构化的文本医疗记录中提取数据需要时间和精力。信息抽取是自然语言处理的一个子领域，通过使用自动文本挖掘管道，可以帮助临床医生克服这一限制。在这项工作中，我们创建了第一个意大利神经精神病命名实体识别数据集，PsyNIT，并使用它来开发这项任务的大型语言模型。此外，我们利用三个独立的外部数据集进行了多个实验，实现了一个有效的多中心模型，F1总分为84.77% ，精度为83.16% ，召回率为86.44% 。从中学到的经验教训是: (i)一致的注释过程的关键作用; (ii)将经典方法与“少量拍摄”方法相结合的微调策略。这使我们能够制定方法指南，为今后在这一领域的实施铺平道路，并使意大利医院能够利用重要的研究机会。"
    },
    {
        "title": "KIT's Multilingual Speech Translation System for IWSLT 2023",
        "url": "http://arxiv.org/abs/2306.05320v1",
        "pub_date": "2023-06-08",
        "summary": "Many existing speech translation benchmarks focus on native-English speech in\nhigh-quality recording conditions, which often do not match the conditions in\nreal-life use-cases. In this paper, we describe our speech translation system\nfor the multilingual track of IWSLT 2023, which focuses on the translation of\nscientific conference talks. The test condition features accented input speech\nand terminology-dense contents. The tasks requires translation into 10\nlanguages of varying amounts of resources. In absence of training data from the\ntarget domain, we use a retrieval-based approach (kNN-MT) for effective\nadaptation (+0.8 BLEU for speech translation). We also use adapters to easily\nintegrate incremental training data from data augmentation, and show that it\nmatches the performance of re-training. We observe that cascaded systems are\nmore easily adaptable towards specific target domains, due to their separate\nmodules. Our cascaded speech system substantially outperforms its end-to-end\ncounterpart on scientific talk translation, although their performance remains\nsimilar on TED talks.",
        "translated": "许多现有的语音翻译基准主要集中在高质量录音条件下的英语母语语音上，而这些语音翻译基准往往与现实生活中的语音翻译条件不匹配。本文介绍了我们为 IWSLT 2023多语种赛道开发的演讲翻译系统，该系统主要用于科学会议演讲的翻译。测试条件的特点是重音输入语音和术语密集的内容。这些任务需要翻译成10种不同数量资源的语言。在没有来自目标域的训练数据的情况下，我们使用基于检索的方法(kNN-MT)进行有效的自适应(语音翻译 + 0.8 BLEU)。我们还使用适配器方便地集成了来自数据增强的增量训练数据，并表明它与再训练的性能相匹配。我们观察到级联系统由于其独立的模块，更容易适应特定的目标域。我们的级联语音系统在科学演讲翻译方面大大优于其端到端的对应系统，尽管它们在 TED 演讲中的表现仍然相似。"
    },
    {
        "title": "CUED at ProbSum 2023: Hierarchical Ensemble of Summarization Models",
        "url": "http://arxiv.org/abs/2306.05317v1",
        "pub_date": "2023-06-08",
        "summary": "In this paper, we consider the challenge of summarizing patients' medical\nprogress notes in a limited data setting. For the Problem List Summarization\n(shared task 1A) at the BioNLP Workshop 2023, we demonstrate that Clinical-T5\nfine-tuned to 765 medical clinic notes outperforms other extractive,\nabstractive and zero-shot baselines, yielding reasonable baseline systems for\nmedical note summarization. Further, we introduce Hierarchical Ensemble of\nSummarization Models (HESM), consisting of token-level ensembles of diverse\nfine-tuned Clinical-T5 models, followed by Minimum Bayes Risk (MBR) decoding.\nOur HESM approach lead to a considerable summarization performance boost, and\nwhen evaluated on held-out challenge data achieved a ROUGE-L of 32.77, which\nwas the best-performing system at the top of the shared task leaderboard.",
        "translated": "在本文中，我们考虑的挑战，总结病人的医疗进展记录在有限的数据设置。对于2023年 BioNLP 研讨会上的问题列表摘要(共享任务1A) ，我们证明临床 T5对765个医疗诊所笔记进行微调优于其他提取，抽象和零拍基线，产生合理的医疗笔记摘要基线系统。此外，我们还介绍了分层总结模型集成(HESM) ，其由不同的微调临床 T5模型的令牌级集成组成，然后是最小贝叶斯风险(MBR)解码。我们的 HESM 方法导致了相当大的总结性能提升，并且当在坚持的挑战数据上进行评估时，ROUGE-L 达到了32.77，这是共享任务排行榜上表现最好的系统。"
    },
    {
        "title": "Are fairness metric scores enough to assess discrimination biases in\n  machine learning?",
        "url": "http://arxiv.org/abs/2306.05307v1",
        "pub_date": "2023-06-08",
        "summary": "This paper presents novel experiments shedding light on the shortcomings of\ncurrent metrics for assessing biases of gender discrimination made by machine\nlearning algorithms on textual data. We focus on the Bios dataset, and our\nlearning task is to predict the occupation of individuals, based on their\nbiography. Such prediction tasks are common in commercial Natural Language\nProcessing (NLP) applications such as automatic job recommendations. We address\nan important limitation of theoretical discussions dealing with group-wise\nfairness metrics: they focus on large datasets, although the norm in many\nindustrial NLP applications is to use small to reasonably large linguistic\ndatasets for which the main practical constraint is to get a good prediction\naccuracy. We then question how reliable are different popular measures of bias\nwhen the size of the training set is simply sufficient to learn reasonably\naccurate predictions. Our experiments sample the Bios dataset and learn more\nthan 200 models on different sample sizes. This allows us to statistically\nstudy our results and to confirm that common gender bias indices provide\ndiverging and sometimes unreliable results when applied to relatively small\ntraining and test samples. This highlights the crucial importance of variance\ncalculations for providing sound results in this field.",
        "translated": "本文介绍了一些新颖的实验，揭示了目前机器学习算法对文本数据进行性别歧视偏差评估的指标存在的缺陷。我们的重点是生物数据集，我们的学习任务是预测个人的职业，根据他们的传记。这种预测任务在商业自然语言处理(NLP)应用程序(如自动工作推荐)中很常见。我们解决了关于群体公平性度量的理论讨论的一个重要局限性: 它们集中在大数据集上，尽管在许多工业 NLP 应用中的规范是使用小到合理的大语言数据集，其主要的实际限制是获得良好的预测精度。然后我们质疑当训练集的大小仅仅足以学习合理准确的预测时，不同的流行的偏倚测量方法的可靠性。我们的实验样本的 Bios 数据集和学习超过200个不同样本大小的模型。这使我们能够统计研究我们的结果，并确认共同的性别偏见指数提供不同的，有时不可靠的结果时，适用于相对较小的训练和测试样本。这突出了方差计算对于在这一领域提供可靠结果的至关重要性。"
    },
    {
        "title": "ToolAlpaca: Generalized Tool Learning for Language Models with 3000\n  Simulated Cases",
        "url": "http://arxiv.org/abs/2306.05301v1",
        "pub_date": "2023-06-08",
        "summary": "Enabling large language models to effectively utilize real-world tools is\ncrucial for achieving embodied intelligence. Existing approaches to tool\nlearning have primarily relied on either extremely large language models, such\nas GPT-4, to attain generalized tool-use abilities in a zero-shot manner, or\nhave utilized supervised learning to train limited types of tools on compact\nmodels. However, it remains uncertain whether smaller language models can\nachieve generalized tool-use abilities without specific tool-specific training.\nTo address this question, this paper introduces ToolAlpaca, a novel framework\ndesigned to automatically generate a tool-use corpus and learn generalized\ntool-use abilities on compact language models with minimal human intervention.\nSpecifically, ToolAlpaca first collects a comprehensive dataset by building a\nmulti-agent simulation environment, which contains 3938 tool-use instances from\nmore than 400 real-world tool APIs spanning 50 distinct categories.\nSubsequently, the constructed corpus is employed to fine-tune compact language\nmodels, resulting in two models, namely ToolAlpaca-7B and ToolAlpaca-13B,\nrespectively. Finally, we evaluate the ability of these models to utilize\npreviously unseen tools without specific training. Experimental results\ndemonstrate that ToolAlpaca achieves effective generalized tool-use\ncapabilities comparable to those of extremely large language models like\nGPT-3.5. This validation supports the notion that learning generalized tool-use\nabilities is feasible for compact language models.",
        "translated": "使大型语言模型能够有效地利用现实世界中的工具对于实现内嵌智能是至关重要的。现有的工具学习方法主要依赖于极其庞大的语言模型，如 GPT-4，以零打击的方式获得广义的工具使用能力，或者利用监督式学习在紧凑模型上训练有限类型的工具。然而，小型语言模型是否能够在没有特定工具训练的情况下实现工具使用能力的普遍化仍然是个未知数。为了解决这个问题，本文介绍了 ToolAlpaca，这是一个新的框架，它可以自动生成一个工具使用语料库，并在最少人工干预的情况下学习紧凑语言模型上的广义工具使用能力。具体来说，ToolAlpaca 首先通过构建一个多代理仿真环境来收集一个全面的数据集，该环境包含来自400多个实际工具 API 的3938个工具使用实例，这些 API 跨越50个不同的类别。然后，利用构建的语料库对紧凑语言模型进行微调，得到两个模型，分别为 ToolAlpaca-7B 和 ToolAlpaca-13B。最后，我们评估这些模型在没有特定训练的情况下利用以前看不见的工具的能力。实验结果表明，ToolAlpaca 实现了有效的广义工具使用能力，可以与 GPT-3.5这样的超大型语言模型相媲美。这种验证支持这样一种观点，即学习广义的工具使用能力对于紧凑的语言模型是可行的。"
    },
    {
        "title": "How Can Recommender Systems Benefit from Large Language Models: A Survey",
        "url": "http://arxiv.org/abs/2306.05817v1",
        "pub_date": "2023-06-09",
        "summary": "Recommender systems (RS) play important roles to match users' information\nneeds for Internet applications. In natural language processing (NLP) domains,\nlarge language model (LLM) has shown astonishing emergent abilities (e.g.,\ninstruction following, reasoning), thus giving rise to the promising research\ndirection of adapting LLM to RS for performance enhancements and user\nexperience improvements. In this paper, we conduct a comprehensive survey on\nthis research direction from an application-oriented view. We first summarize\nexisting research works from two orthogonal perspectives: where and how to\nadapt LLM to RS. For the \"WHERE\" question, we discuss the roles that LLM could\nplay in different stages of the recommendation pipeline, i.e., feature\nengineering, feature encoder, scoring/ranking function, and pipeline\ncontroller. For the \"HOW\" question, we investigate the training and inference\nstrategies, resulting in two fine-grained taxonomy criteria, i.e., whether to\ntune LLMs or not, and whether to involve conventional recommendation model\n(CRM) for inference. Detailed analysis and general development trajectories are\nprovided for both questions, respectively. Then, we highlight key challenges in\nadapting LLM to RS from three aspects, i.e., efficiency, effectiveness, and\nethics. Finally, we summarize the survey and discuss the future prospects. We\nalso actively maintain a GitHub repository for papers and other related\nresources in this rising direction:\n$\\href{https://github.com/CHIANGEL/Awesome-LLM-for-RecSys}{[GitHub\\;Link]}$.",
        "translated": "推荐系统(RS)在满足互联网应用的用户信息需求方面发挥着重要作用。在自然语言处理(NLP)领域，大语言模型(LLM)表现出惊人的涌现能力(如指令跟随、推理) ，从而引发了将 LLM 应用于 RS 以提高性能和改善用户体验的研究方向。本文从应用导向的角度对这一研究方向进行了全面综述。本文首先从两个正交的角度对现有的研究工作进行了总结: 在何处以及如何使 LLM 适应 RS。对于“ WHERE”问题，我们讨论 LLM 在推荐流水线的不同阶段可以扮演的角色，即特征工程、特征编码器、评分/排名函数和流水线控制器。对于“如何”问题，我们研究了训练和推理策略，产生了两个细粒度的分类标准，即是否调优 LLM，以及是否涉及传统的推荐模型(CRM)进行推理。对这两个问题分别提供了详细的分析和一般的开发轨迹。然后，从效率、有效性和道德三个方面，重点阐述了长期管理适应 RS 所面临的主要挑战。最后，对调查结果进行了总结，并对未来进行了展望。我们还积极地维护一个 gitHub 存储库，用于存放论文和其他相关资源，这是一个不断发展的方向: $href { https://GitHub.com/chiangel/awesome-llm-for-recsys }{[ gitHub; Link ]}} $。"
    },
    {
        "title": "Interactive Explanation with Varying Level of Details in an Explainable\n  Scientific Literature Recommender System",
        "url": "http://arxiv.org/abs/2306.05809v1",
        "pub_date": "2023-06-09",
        "summary": "Explainable recommender systems (RS) have traditionally followed a\none-size-fits-all approach, delivering the same explanation level of detail to\neach user, without considering their individual needs and goals. Further,\nexplanations in RS have so far been presented mostly in a static and\nnon-interactive manner. To fill these research gaps, we aim in this paper to\nadopt a user-centered, interactive explanation model that provides explanations\nwith different levels of detail and empowers users to interact with, control,\nand personalize the explanations based on their needs and preferences. We\nfollowed a user-centered approach to design interactive explanations with three\nlevels of detail (basic, intermediate, and advanced) and implemented them in\nthe transparent Recommendation and Interest Modeling Application (RIMA). We\nconducted a qualitative user study (N=14) to investigate the impact of\nproviding interactive explanations with varying level of details on the users'\nperception of the explainable RS. Our study showed qualitative evidence that\nfostering interaction and giving users control in deciding which explanation\nthey would like to see can meet the demands of users with different needs,\npreferences, and goals, and consequently can have positive effects on different\ncrucial aspects in explainable recommendation, including transparency, trust,\nsatisfaction, and user experience.",
        "translated": "可解释的推荐系统(RS)传统上遵循一种一刀切的方法，向每个用户提供相同的详细解释水平，而不考虑他们的个人需求和目标。此外，到目前为止，RS 中的解释大多是以静态和非交互的方式提出的。为了填补这些研究空白，本文的目标是采用一种以用户为中心的交互式解释模型，该模型提供不同层次的详细解释，并使用户能够根据自己的需求和偏好进行交互、控制和个性化解释。我们遵循以用户为中心的方法来设计具有三个细节层次(基础、中级和高级)的交互式解释，并在透明的推荐和兴趣建模应用程序(RIMA)中实现它们。我们进行了一项定性的用户研究(N = 14) ，以调查不同程度的细节提供交互式解释对用户感知可解释 RS 的影响。我们的研究显示，定性的证据表明，培养互动和让用户控制决定他们想要看到的解释可以满足不同需求，偏好和目标的用户的需求，因此可以对解释性推荐的不同关键方面产生积极的影响，包括透明度，信任，满意度和用户体验。"
    },
    {
        "title": "RankFormer: Listwise Learning-to-Rank Using Listwide Labels",
        "url": "http://arxiv.org/abs/2306.05808v1",
        "pub_date": "2023-06-09",
        "summary": "Web applications where users are presented with a limited selection of items\nhave long employed ranking models to put the most relevant results first. Any\nfeedback received from users is typically assumed to reflect a relative\njudgement on the utility of items, e.g. a user clicking on an item only implies\nit is better than items not clicked in the same ranked list. Hence, the\nobjectives optimized in Learning-to-Rank (LTR) tend to be pairwise or listwise.\n  Yet, by only viewing feedback as relative, we neglect the user's absolute\nfeedback on the list's overall quality, e.g. when no items in the selection are\nclicked. We thus reconsider the standard LTR paradigm and argue the benefits of\nlearning from this listwide signal. To this end, we propose the RankFormer as\nan architecture that, with a Transformer at its core, can jointly optimize a\nnovel listwide assessment objective and a traditional listwise LTR objective.\n  We simulate implicit feedback on public datasets and observe that the\nRankFormer succeeds in benefitting from listwide signals. Additionally, we\nconduct experiments in e-commerce on Amazon Search data and find the RankFormer\nto be superior to all baselines offline. An online experiment shows that\nknowledge distillation can be used to find immediate practical use for the\nRankFormer.",
        "translated": "在 Web 应用程序中，用户只能看到有限的条目，这种情况长期以来一直采用排名模型，将最相关的结果放在第一位。从用户收到的任何反馈通常被认为反映了对项目效用的相对判断，例如，用户点击一个项目只意味着它比没有在同一排名列表中点击的项目要好。因此，学习排名(Learning-to-Rank，LTR)中优化的目标往往是成对的或列表的。然而，由于只把反馈看作是相对的，我们忽略了用户对列表整体质量的绝对反馈，例如，当选择中没有项被点击的时候。因此，我们重新考虑标准的 LTR 范式，并讨论从这个列表范围的信号中学习的好处。为此，我们提出 RankForm 作为一种体系结构，其核心是一个 Transformer，可以联合优化一个新的列表范围评估目标和一个传统的列表式 LTR 目标。我们模拟公共数据集上的隐式反馈，并观察到 RankForm 成功地从列表宽信号中受益。此外，我们在亚马逊搜索数据上进行电子商务实验，发现排名前优于所有离线基线。一个在线实验表明，知识提取可以用来找到直接的实际应用的秩次前。"
    },
    {
        "title": "Customizing General-Purpose Foundation Models for Medical Report\n  Generation",
        "url": "http://arxiv.org/abs/2306.05642v1",
        "pub_date": "2023-06-09",
        "summary": "Medical caption prediction which can be regarded as a task of medical report\ngeneration (MRG), requires the automatic generation of coherent and accurate\ncaptions for the given medical images. However, the scarcity of labelled\nmedical image-report pairs presents great challenges in the development of deep\nand large-scale neural networks capable of harnessing the potential artificial\ngeneral intelligence power like large language models (LLMs). In this work, we\npropose customizing off-the-shelf general-purpose large-scale pre-trained\nmodels, i.e., foundation models (FMs), in computer vision and natural language\nprocessing with a specific focus on medical report generation. Specifically,\nfollowing BLIP-2, a state-of-the-art vision-language pre-training approach, we\nintroduce our encoder-decoder-based MRG model. This model utilizes a\nlightweight query Transformer to connect two FMs: the giant vision Transformer\nEVA-ViT-g and a bilingual LLM trained to align with human intentions (referred\nto as ChatGLM-6B). Furthermore, we conduct ablative experiments on the\ntrainable components of the model to identify the crucial factors for effective\ntransfer learning. Our findings demonstrate that unfreezing EVA-ViT-g to learn\nmedical image representations, followed by parameter-efficient training of\nChatGLM-6B to capture the writing styles of medical reports, is essential for\nachieving optimal results. Our best attempt (PCLmed Team) achieved the 4th and\nthe 2nd, respectively, out of 13 participating teams, based on the BERTScore\nand ROUGE-1 metrics, in the ImageCLEFmedical Caption 2023 Caption Prediction\nTask competition.",
        "translated": "医学字幕预测是医学报告生成的一项重要任务，它要求为给定的医学图像自动生成连贯、准确的医学字幕。然而，标记的医学图像-报告对的稀缺性给深度和大规模神经网络的发展提出了巨大的挑战，这些神经网络能够利用潜在的人工通用智能能力，如大语言模型(LLM)。在这项工作中，我们建议定制现成的通用大规模预训练模型，即基础模型(FM) ，在计算机视觉和自然语言处理，特别是医疗报告生成的重点。具体来说，在 BLIP-2(一种最先进的视觉语言预训练方法)之后，我们介绍了基于编码器-解码器的 MRG 模型。该模型使用一个轻量级查询 Transformer 连接两个 FM: 巨大的愿景跑车 EVA-ViT-g 和一个双语 LLM，后者经过训练以符合人类意图(称为 ChatGLM-6B)。此外，我们还对模型的可训练部分进行了烧蚀实验，以确定有效迁移学习的关键因素。我们的研究结果表明，将 EVA-ViT-g 解冻以学习医学图像表示，然后对 ChatGLM-6B 进行参数有效的训练以捕获医学报告的写作风格，对于实现最佳结果至关重要。根据 BERTScore 和 ROUGE-1指标，在 ImageCLEFMedical Caption 2023字幕预测任务竞赛中，我们的最佳尝试(PCLmed Team)分别在13个参赛团队中获得第4名和第2名。"
    },
    {
        "title": "Bayesian Knowledge-driven Critiquing with Indirect Evidence",
        "url": "http://arxiv.org/abs/2306.05636v1",
        "pub_date": "2023-06-09",
        "summary": "Conversational recommender systems (CRS) enhance the expressivity and\npersonalization of recommendations through multiple turns of user-system\ninteraction. Critiquing is a well-known paradigm for CRS that allows users to\niteratively refine recommendations by providing feedback about attributes of\nrecommended items. While existing critiquing methodologies utilize direct\nattributes of items to address user requests such as 'I prefer Western movies',\nthe opportunity of incorporating richer contextual and side information about\nitems stored in Knowledge Graphs (KG) into the critiquing paradigm has been\noverlooked. Employing this substantial knowledge together with a\nwell-established reasoning methodology paves the way for critique-based\nrecommenders to allow for complex knowledge-based feedback (e.g., 'I like\nmovies featuring war side effects on veterans') which may arise in natural\nuser-system conversations. In this work, we aim to increase the flexibility of\ncritique-based recommendation by integrating KGs and propose a novel Bayesian\ninference framework that enables reasoning with relational knowledge-based\nfeedback. We study and formulate the framework considering a Gaussian\nlikelihood and evaluate it on two well-known recommendation datasets with KGs.\nOur evaluations demonstrate the effectiveness of our framework in leveraging\nindirect KG-based feedback (i.e., preferred relational properties of items\nrather than preferred items themselves), often improving personalized\nrecommendations over a one-shot recommender by more than 15%. This work enables\na new paradigm for using rich knowledge content and reasoning over indirect\nevidence as a mechanism for critiquing interactions with CRS.",
        "translated": "会话推荐系统(CRS)通过多轮用户系统交互增强推荐的表达能力和个性化。批评是 CRS 的一个众所周知的范例，它允许用户通过提供关于推荐项目属性的反馈来迭代地完善推荐。虽然现有的批评方法利用项目的直接属性来满足用户的要求，例如“我更喜欢西部电影”，但是将知识图表(KG)中存储的项目的更丰富的上下文和侧面信息纳入批评范式的机会被忽视了。使用这些实质性的知识和一个完善的推理方法为基于评论的推荐者铺平了道路，以允许复杂的基于知识的反馈(例如，“我喜欢有退伍军人战争副作用的电影”) ，这可能出现在自然的用户系统对话中。在这项工作中，我们的目标是通过整合幼稚园来增加基于批判的推荐的灵活性，并提出一个新的贝叶斯推断框架，使推理与关系知识为基础的反馈。我们研究并制定了考虑高斯似然的框架，并在两个著名的 KG 推荐数据集上进行了评估。我们的评估表明，我们的框架在利用间接的基于 KG 的反馈(即，项目的首选关系属性，而不是首选项本身)方面的有效性，通常比一次性推荐提高个性化推荐超过15% 。这项工作为使用丰富的知识内容和推理间接证据作为一种机制批判与 CRS 的相互作用提供了一个新的范例。"
    },
    {
        "title": "Leveraging Large Language Models for Scalable Vector Graphics-Driven\n  Image Understanding",
        "url": "http://arxiv.org/abs/2306.06094v1",
        "pub_date": "2023-06-09",
        "summary": "Recently, large language models (LLMs) have made significant advancements in\nnatural language understanding and generation. However, their potential in\ncomputer vision remains largely unexplored. In this paper, we introduce a new,\nexploratory approach that enables LLMs to process images using the Scalable\nVector Graphics (SVG) format. By leveraging the XML-based textual descriptions\nof SVG representations instead of raster images, we aim to bridge the gap\nbetween the visual and textual modalities, allowing LLMs to directly understand\nand manipulate images without the need for parameterized visual components. Our\nmethod facilitates simple image classification, generation, and in-context\nlearning using only LLM capabilities. We demonstrate the promise of our\napproach across discriminative and generative tasks, highlighting its (i)\nrobustness against distribution shift, (ii) substantial improvements achieved\nby tapping into the in-context learning abilities of LLMs, and (iii) image\nunderstanding and generation capabilities with human guidance. Our code, data,\nand models can be found here https://github.com/mu-cai/svg-llm.",
        "translated": "近年来，大型语言模型(LLM)在自然语言理解和生成方面取得了显著的进展。然而，它们在计算机视觉方面的潜力在很大程度上仍未得到开发。在这篇文章中，我们介绍了一种新的探索性的方法，使 LLM 能够使用可缩放向量图形(SVG)格式来处理图像。通过利用基于 XML 的 SVG 表示的文本描述而不是栅格图像，我们的目标是弥合视觉和文本模式之间的差距，允许 LLM 直接理解和操作图像，而不需要参数化的视觉组件。我们的方法有助于简单的图像分类，生成，并在上下文学习使用 LLM 的能力。我们展示了我们在歧视性和生成性任务中的方法的前景，强调了其(i)对分布转移的稳健性，(ii)通过利用 LLM 的上下文学习能力实现的实质性改进，以及(iii)图像理解和生成能力与人类指导。我们的代码、数据和模型可以在这里找到 https://github.com/mu-cai/svg-llm。"
    },
    {
        "title": "Developing Speech Processing Pipelines for Police Accountability",
        "url": "http://arxiv.org/abs/2306.06086v1",
        "pub_date": "2023-06-09",
        "summary": "Police body-worn cameras have the potential to improve accountability and\ntransparency in policing. Yet in practice, they result in millions of hours of\nfootage that is never reviewed. We investigate the potential of large\npre-trained speech models for facilitating reviews, focusing on ASR and officer\nspeech detection in footage from traffic stops. Our proposed pipeline includes\ntraining data alignment and filtering, fine-tuning with resource constraints,\nand combining officer speech detection with ASR for a fully automated approach.\nWe find that (1) fine-tuning strongly improves ASR performance on officer\nspeech (WER=12-13%), (2) ASR on officer speech is much more accurate than on\ncommunity member speech (WER=43.55-49.07%), (3) domain-specific tasks like\nofficer speech detection and diarization remain challenging. Our work offers\npractical applications for reviewing body camera footage and general guidance\nfor adapting pre-trained speech models to noisy multi-speaker domains.",
        "translated": "警察身上佩戴的摄像头有可能改善警务工作的问责制和透明度。然而在实践中，他们导致数百万小时的镜头，从来没有审查。我们调查的潜力，大型预先训练的语音模型，以促进审查，侧重于 ASR 和官员的语音检测镜头从交通停止。我们提出的流水线包括训练数据对齐和过滤，与资源约束的微调，并结合官员语音检测和 ASR 为一个完全自动化的方法。我们发现: (1)微调有力地提高了官员语音的 ASR 性能(WER = 12-13%) ，(2)官员语音的 ASR 比社区成员语音的 ASR 更准确(WER = 43.55-49.07%) ，(3)官员语音检测和数字化等领域特定任务仍然具有挑战性。我们的工作提供了实际应用，审查身体摄像机镜头和一般指导适应预先训练的语音模型噪声多扬声器领域。"
    },
    {
        "title": "Trapping LLM Hallucinations Using Tagged Context Prompts",
        "url": "http://arxiv.org/abs/2306.06085v1",
        "pub_date": "2023-06-09",
        "summary": "Recent advances in large language models (LLMs), such as ChatGPT, have led to\nhighly sophisticated conversation agents. However, these models suffer from\n\"hallucinations,\" where the model generates false or fabricated information.\nAddressing this challenge is crucial, particularly with AI-driven platforms\nbeing adopted across various sectors. In this paper, we propose a novel method\nto recognize and flag instances when LLMs perform outside their domain\nknowledge, and ensuring users receive accurate information.\n  We find that the use of context combined with embedded tags can successfully\ncombat hallucinations within generative language models. To do this, we\nbaseline hallucination frequency in no-context prompt-response pairs using\ngenerated URLs as easily-tested indicators of fabricated data. We observed a\nsignificant reduction in overall hallucination when context was supplied along\nwith question prompts for tested generative engines. Lastly, we evaluated how\nplacing tags within contexts impacted model responses and were able to\neliminate hallucinations in responses with 98.88% effectiveness.",
        "translated": "大型语言模型(LLM)的最新进展，如 ChatGPT，已经导致了高度复杂的会话代理。然而，这些模型遭受“幻觉”，即模型产生虚假或捏造的信息。应对这一挑战至关重要，特别是在各个部门都在采用人工智能驱动的平台的情况下。在本文中，我们提出了一种新的方法来识别和标记实例时，LLM 执行领域外的知识，并确保用户接收准确的信息。我们发现使用上下文结合嵌入式标签可以成功地战胜生成语言模型中的幻觉。为此，我们使用生成的 URL 作为编造数据的容易测试的指标，对无上下文提示-响应对中的幻觉频率进行基线测试。我们观察到整体幻觉的显着减少时，上下文提供的问题提示测试生成引擎。最后，我们评估了在上下文中放置标签是如何影响模型反应的，并且能够以98.88% 的有效率消除反应中的幻觉。"
    },
    {
        "title": "Mind2Web: Towards a Generalist Agent for the Web",
        "url": "http://arxiv.org/abs/2306.06070v1",
        "pub_date": "2023-06-09",
        "summary": "We introduce Mind2Web, the first dataset for developing and evaluating\ngeneralist agents for the web that can follow language instructions to complete\ncomplex tasks on any website. Existing datasets for web agents either use\nsimulated websites or only cover a limited set of websites and tasks, thus not\nsuitable for generalist web agents. With over 2,000 open-ended tasks collected\nfrom 137 websites spanning 31 domains and crowdsourced action sequences for the\ntasks, Mind2Web provides three necessary ingredients for building generalist\nweb agents: 1) diverse domains, websites, and tasks, 2) use of real-world\nwebsites instead of simulated and simplified ones, and 3) a broad spectrum of\nuser interaction patterns. Based on Mind2Web, we conduct an initial exploration\nof using large language models (LLMs) for building generalist web agents. While\nthe raw HTML of real-world websites are often too large to be fed to LLMs, we\nshow that first filtering it with a small LM significantly improves the\neffectiveness and efficiency of LLMs. Our solution demonstrates a decent level\nof performance, even on websites or entire domains the model has never seen\nbefore, but there is still a substantial room to improve towards truly\ngeneralizable agents. We open-source our dataset, model implementation, and\ntrained models (https://osu-nlp-group.github.io/Mind2Web) to facilitate further\nresearch on building a generalist agent for the web.",
        "translated": "我们介绍 Mind2Web，第一个用于开发和评估通用网络代理的数据集，这些代理可以按照语言指令在任何网站上完成复杂的任务。现有的 Web 代理数据集要么使用模拟网站，要么只覆盖有限的一组网站和任务，因此不适合于通用 Web 代理。Mind2Web 从31个领域的137个网站中收集了超过2000个开放式任务，并为这些任务提供了众包的动作序列。 Mind2Web 为构建通用网络代理提供了三个必要的组成部分: 1)不同的领域、网站和任务; 2)使用真实世界的网站而不是模拟和简化的网站; 3)广泛的用户交互模式。基于 Mind2Web，我们对使用大型语言模型(LLM)构建通用 Web 代理进行了初步探索。虽然现实世界中网站的原始 HTML 通常太大而无法提供给 LLM，但我们表明，首先使用小型 LM 对其进行过滤可以显著提高 LLM 的有效性和效率。我们的解决方案展示了一个不错的性能水平，甚至在模型从未见过的网站或整个域上，但是仍然有很大的空间来改进真正可推广的代理。我们开源我们的数据集，模型实现，和训练有素的模型( https://osu-nlp-group.github.io/mind2web ) ，以促进进一步的研究建立一个通用的代理网站。"
    },
    {
        "title": "Assisting Language Learners: Automated Trans-Lingual Definition\n  Generation via Contrastive Prompt Learning",
        "url": "http://arxiv.org/abs/2306.06058v1",
        "pub_date": "2023-06-09",
        "summary": "The standard definition generation task requires to automatically produce\nmono-lingual definitions (e.g., English definitions for English words), but\nignores that the generated definitions may also consist of unfamiliar words for\nlanguage learners. In this work, we propose a novel task of Trans-Lingual\nDefinition Generation (TLDG), which aims to generate definitions in another\nlanguage, i.e., the native speaker's language. Initially, we explore the\nunsupervised manner of this task and build up a simple implementation of\nfine-tuning the multi-lingual machine translation model. Then, we develop two\nnovel methods, Prompt Combination and Contrastive Prompt Learning, for further\nenhancing the quality of the generation. Our methods are evaluated against the\nbaseline Pipeline method in both rich- and low-resource settings, and we\nempirically establish its superiority in generating higher-quality\ntrans-lingual definitions.",
        "translated": "标准的定义生成任务要求自动生成单语言定义(例如，英语单词的英语定义) ，但是忽略了生成的定义也可能包含语言学习者不熟悉的单词。在这项工作中，我们提出了一个新颖的任务跨语言定义生成(TLDG) ，其目的是生成另一种语言的定义，即母语说话人的语言。最初，我们探讨了这项任务的无监督方式，并建立了一个简单的实现，微调多语种机器翻译模型。然后，为了进一步提高生成的质量，我们开发了两种新的方法，即即时组合和对比即时学习。在资源丰富和资源少的情况下，我们对比基线流水线方法对我们的方法进行了评估，并且我们经验性地建立了它在产生更高质量的跨语言定义方面的优势。"
    },
    {
        "title": "FinGPT: Open-Source Financial Large Language Models",
        "url": "http://arxiv.org/abs/2306.06031v1",
        "pub_date": "2023-06-09",
        "summary": "Large language models (LLMs) have shown the potential of revolutionizing\nnatural language processing tasks in diverse domains, sparking great interest\nin finance. Accessing high-quality financial data is the first challenge for\nfinancial LLMs (FinLLMs). While proprietary models like BloombergGPT have taken\nadvantage of their unique data accumulation, such privileged access calls for\nan open-source alternative to democratize Internet-scale financial data.\n  In this paper, we present an open-source large language model, FinGPT, for\nthe finance sector. Unlike proprietary models, FinGPT takes a data-centric\napproach, providing researchers and practitioners with accessible and\ntransparent resources to develop their FinLLMs. We highlight the importance of\nan automatic data curation pipeline and the lightweight low-rank adaptation\ntechnique in building FinGPT. Furthermore, we showcase several potential\napplications as stepping stones for users, such as robo-advising, algorithmic\ntrading, and low-code development. Through collaborative efforts within the\nopen-source AI4Finance community, FinGPT aims to stimulate innovation,\ndemocratize FinLLMs, and unlock new opportunities in open finance. Two\nassociated code repos are \\url{https://github.com/AI4Finance-Foundation/FinGPT}\nand \\url{https://github.com/AI4Finance-Foundation/FinNLP}",
        "translated": "大型语言模型(LLM)显示了在不同领域革新自然语言处理任务的潜力，引起了人们对金融的极大兴趣。访问高质量的金融数据是金融 LLM (FinLLM)面临的第一个挑战。虽然像 BloombergGPT 这样的专有模型已经利用了它们独特的数据积累，但是这种特权访问需要一种开放源码的替代方案来使互联网规模的金融数据民主化。在本文中，我们为金融部门提出了一个开源的大型语言模型 FinGPT。与专有模型不同，FinGPT 采用以数据为中心的方法，为研究人员和从业人员提供可访问和透明的资源，以开发他们的 FinLLM。我们强调了自动数据管道和轻量级低级自适应技术在构建 FinGPT 中的重要性。此外，我们展示了几个潜在的应用程序作为用户的垫脚石，如机器人建议，算法交易和低代码开发。通过开源 AI4Finance 社区内部的协作努力，FinGPT 旨在激励创新，使 FinLLM 民主化，并在开放金融领域释放新的机遇。两个相关的代码回购是 url { https://github.com/ai4finance-foundation/fingpt }和 url { https://github.com/ai4finance-foundation/finnlp }"
    },
    {
        "title": "HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence\n  for Digital Medicine",
        "url": "http://arxiv.org/abs/2306.06029v1",
        "pub_date": "2023-06-09",
        "summary": "Providing high quality explanations for AI predictions based on machine\nlearning is a challenging and complex task. To work well it requires, among\nother factors: selecting a proper level of generality/specificity of the\nexplanation; considering assumptions about the familiarity of the explanation\nbeneficiary with the AI task under consideration; referring to specific\nelements that have contributed to the decision; making use of additional\nknowledge (e.g. expert evidence) which might not be part of the prediction\nprocess; and providing evidence supporting negative hypothesis. Finally, the\nsystem needs to formulate the explanation in a clearly interpretable, and\npossibly convincing, way. Given these considerations, ANTIDOTE fosters an\nintegrated vision of explainable AI, where low-level characteristics of the\ndeep learning process are combined with higher level schemes proper of the\nhuman argumentation capacity. ANTIDOTE will exploit cross-disciplinary\ncompetences in deep learning and argumentation to support a broader and\ninnovative view of explainable AI, where the need for high-quality explanations\nfor clinical cases deliberation is critical. As a first result of the project,\nwe publish the Antidote CasiMedicos dataset to facilitate research on\nexplainable AI in general, and argumentation in the medical domain in\nparticular.",
        "translated": "为基于机器学习的人工智能预测提供高质量的解释是一项具有挑战性和复杂性的任务。要做好这项工作，除了其他因素之外，还需要: 选择适当水平的解释的一般性/特异性; 考虑关于解释受益人对正在考虑的 AI 任务的熟悉程度的假设; 参考对决策有贡献的特定元素; 利用额外的知识(例如专家证据) ，这可能不是预测过程的一部分; 以及提供支持负面假设的证据。最后，系统需要以一种清晰可解释的、可能令人信服的方式来阐述解释。考虑到这些因素，ANTIDOTE 培养了一种可解释人工智能的综合视野，其中深度学习过程的低水平特征与适合人类论证能力的高水平方案相结合。ANTIDOTE 将利用深度学习和论证方面的跨学科能力，以支持对可解释 AI 的更广泛和创新的观点，其中对临床病例审议的高质量解释的需求是至关重要的。作为这个项目的第一个成果，我们发布了解毒剂 CasiMedicos 数据集，以促进对可解释人工智能的研究，特别是在医学领域的论证。"
    },
    {
        "title": "Automated Labeling of German Chest X-Ray Radiology Reports using Deep\n  Learning",
        "url": "http://arxiv.org/abs/2306.05997v1",
        "pub_date": "2023-06-09",
        "summary": "Radiologists are in short supply globally, and deep learning models offer a\npromising solution to address this shortage as part of clinical\ndecision-support systems. However, training such models often requires\nexpensive and time-consuming manual labeling of large datasets. Automatic label\nextraction from radiology reports can reduce the time required to obtain\nlabeled datasets, but this task is challenging due to semantically similar\nwords and missing annotated data. In this work, we explore the potential of\nweak supervision of a deep learning-based label prediction model, using a\nrule-based labeler. We propose a deep learning-based CheXpert label prediction\nmodel, pre-trained on reports labeled by a rule-based German CheXpert model and\nfine-tuned on a small dataset of manually labeled reports. Our results\ndemonstrate the effectiveness of our approach, which significantly outperformed\nthe rule-based model on all three tasks. Our findings highlight the benefits of\nemploying deep learning-based models even in scenarios with sparse data and the\nuse of the rule-based labeler as a tool for weak supervision.",
        "translated": "放射科医生在全球范围内供不应求，而深度学习模式作为临床决策支持系统的一部分，为解决这一短缺提供了一个有希望的解决方案。然而，训练这样的模型通常需要昂贵和耗时的大型数据集的手动标记。从放射学报告中自动提取标签可以减少获得标签数据集所需的时间，但是由于语义相似的单词和缺少注释数据，这项任务是具有挑战性的。在这项工作中，我们探讨了弱监督的潜力，一个基于深度学习的标签预测模型，使用基于规则的标签。我们提出了一个基于深度学习的 CheXpert 标签预测模型，该模型预先对基于规则的德国 CheXpert 模型标记的报告进行训练，并对手动标记的小数据集进行微调。我们的研究结果证明了我们的方法的有效性，它在所有三个任务上都明显优于基于规则的模型。我们的研究结果强调了使用基于深度学习的模型的好处，即使是在数据稀少的情况下，以及使用基于规则的标签器作为薄弱监督的工具。"
    },
    {
        "title": "Language Models Can Learn Exceptions to Syntactic Rules",
        "url": "http://arxiv.org/abs/2306.05969v1",
        "pub_date": "2023-06-09",
        "summary": "Artificial neural networks can generalize productively to novel contexts. Can\nthey also learn exceptions to those productive rules? We explore this question\nusing the case of restrictions on English passivization (e.g., the fact that\n\"The vacation lasted five days\" is grammatical, but \"*Five days was lasted by\nthe vacation\" is not). We collect human acceptability judgments for passive\nsentences with a range of verbs, and show that the probability distribution\ndefined by GPT-2, a language model, matches the human judgments with high\ncorrelation. We also show that the relative acceptability of a verb in the\nactive vs. passive voice is positively correlated with the relative frequency\nof its occurrence in those voices. These results provide preliminary support\nfor the entrenchment hypothesis, according to which learners track and uses the\ndistributional properties of their input to learn negative exceptions to rules.\nAt the same time, this hypothesis fails to explain the magnitude of\nunpassivizability demonstrated by certain individual verbs, suggesting that\nother cues to exceptionality are available in the linguistic input.",
        "translated": "人工神经网络可以有效地推广到新的上下文。他们是否也能学到这些生产规则的例外情况？我们使用限制英语被动语态的例子来探讨这个问题(例如，“假期持续了五天”是合法的，但“ * 五天被假期持续了”不是)。我们收集了一系列动词被动句的人类可接受性判断，结果表明，语言模型 gPT-2所定义的概率分布与人类的判断具有高度相关性。我们还发现动词在主动语态和被动语态中的相对可接受性与动词在主动语态和被动语态中出现的相对频率呈正相关。这些结果为固守假设提供了初步的支持，根据这一假设，学习者跟踪并利用其输入的分布特性来学习规则的负异常。同时，这一假设也未能解释某些个别动词所表现出的非被动性程度，这表明在语言输入中还存在其他的例外线索。"
    },
    {
        "title": "An Efficient Speech Separation Network Based on Recurrent Fusion Dilated\n  Convolution and Channel Attention",
        "url": "http://arxiv.org/abs/2306.05887v1",
        "pub_date": "2023-06-09",
        "summary": "We present an efficient speech separation neural network, ARFDCN, which\ncombines dilated convolutions, multi-scale fusion (MSF), and channel attention\nto overcome the limited receptive field of convolution-based networks and the\nhigh computational cost of transformer-based networks. The suggested network\narchitecture is encoder-decoder based. By using dilated convolutions with\ngradually increasing dilation value to learn local and global features and\nfusing them at adjacent stages, the model can learn rich feature content.\nMeanwhile, by adding channel attention modules to the network, the model can\nextract channel weights, learn more important features, and thus improve its\nexpressive power and robustness. Experimental results indicate that the model\nachieves a decent balance between performance and computational efficiency,\nmaking it a promising alternative to current mainstream models for practical\napplications.",
        "translated": "我们提出了一个有效的语音分离神经网络，ARFDCN，它结合了扩张卷积，多尺度融合(MSF)和信道注意力，以克服有限的接收领域的卷积为基础的网络和高计算成本的变压器为基础的网络。所建议的网络结构是基于编码器-解码器的。通过使用渐增扩张值的扩张卷积来学习局部和全局特征，并在相邻阶段进行融合，该模型可以学习到丰富的特征内容。同时，通过在网络中增加信道注意模块，该模型可以提取信道权重，学习更多的重要特征，从而提高其表达能力和鲁棒性。实验结果表明，该模型在性能和计算效率之间取得了较好的平衡，是目前主流模型在实际应用中的一种有前途的替代方案。"
    },
    {
        "title": "Weakly-Supervised Scientific Document Classification via\n  Retrieval-Augmented Multi-Stage Training",
        "url": "http://arxiv.org/abs/2306.07193v1",
        "pub_date": "2023-06-12",
        "summary": "Scientific document classification is a critical task for a wide range of\napplications, but the cost of obtaining massive amounts of human-labeled data\ncan be prohibitive. To address this challenge, we propose a weakly-supervised\napproach for scientific document classification using label names only. In\nscientific domains, label names often include domain-specific concepts that may\nnot appear in the document corpus, making it difficult to match labels and\ndocuments precisely. To tackle this issue, we propose WANDER, which leverages\ndense retrieval to perform matching in the embedding space to capture the\nsemantics of label names. We further design the label name expansion module to\nenrich the label name representations. Lastly, a self-training step is used to\nrefine the predictions. The experiments on three datasets show that WANDER\noutperforms the best baseline by 11.9% on average. Our code will be published\nat https://github.com/ritaranx/wander.",
        "translated": "科学文档分类对于广泛的应用来说是一个关键的任务，但是获取大量的人类标记数据的成本可能是高昂的。为了应对这一挑战，我们提出了一种弱监督的方法，用于只使用标签名称的科学文档分类。在科学领域，标签名称往往包括特定领域的概念，这些概念可能不会出现在文档语料库中，因此难以精确匹配标签和文档。为了解决这个问题，我们提出了 WANDER，它利用密集检索在嵌入空间中执行匹配来捕获标签名的语义。进一步设计了标签名扩展模块，丰富了标签名表示。最后，使用一个自我训练步骤来完善预测。在三个数据集上的实验结果表明，WANDER 平均比最佳基准线高出11.9% 。我们的代码会在 https://github.com/ritaranx/wander 公布。"
    },
    {
        "title": "Fair Learning to Rank with Distribution-free Risk Control",
        "url": "http://arxiv.org/abs/2306.07188v1",
        "pub_date": "2023-06-12",
        "summary": "Learning to Rank (LTR) methods are vital in online economies, affecting users\nand item providers. Fairness in LTR models is crucial to allocate exposure\nproportionally to item relevance. The deterministic ranking model can lead to\nunfair exposure distribution when items with the same relevance receive\nslightly different scores. Stochastic LTR models, incorporating the\nPlackett-Luce (PL) model, address fairness issues but have limitations in\ncomputational cost and performance guarantees. To overcome these limitations,\nwe propose FairLTR-RC, a novel post-hoc model-agnostic method. FairLTR-RC\nleverages a pretrained scoring function to create a stochastic LTR model,\neliminating the need for expensive training. Furthermore, FairLTR-RC provides\nfinite-sample guarantees on a user-specified utility using distribution-free\nrisk control framework. By additionally incorporating the Thresholded PL (TPL)\nmodel, we are able to achieve an effective trade-off between utility and\nfairness. Experimental results on several benchmark datasets demonstrate that\nFairLTR-RC significantly improves fairness in widely-used deterministic LTR\nmodels while guaranteeing a specified level of utility.",
        "translated": "学习排名(LTR)方法在网络经济中至关重要，它会影响用户和商品供应商。LTR 模型中的公平性对于按照项目相关性按比例分配暴露是至关重要的。确定性排序模型可能导致不公平的曝光分布，当项目相同的相关性得到略有不同的分数。结合 Plackett-Luce (PL)模型的随机 LTR 模型解决了公平性问题，但在计算成本和性能保证方面存在局限性。为了克服这些局限性，我们提出了一种新的事后模型无关方法 FairLTR-RC。FairLTR-RC 利用一个预先训练的评分函数来创建一个随机 LTR 模型，从而消除了对昂贵培训的需求。此外，FairLTR-RC 使用无分布风险控制框架为用户指定的公用事业提供有限样本保证。另外，通过引入阈限物流(TPL)模型，我们能够在效用和公平之间达到有效的平衡。在几个基准数据集上的实验结果表明，FairLTR-RC 在保证特定效用水平的同时，显著提高了广泛使用的确定性 LTR 模型的公平性。"
    },
    {
        "title": "Video-to-Music Recommendation using Temporal Alignment of Segments",
        "url": "http://arxiv.org/abs/2306.07187v1",
        "pub_date": "2023-06-12",
        "summary": "We study cross-modal recommendation of music tracks to be used as soundtracks\nfor videos. This problem is known as the music supervision task. We build on a\nself-supervised system that learns a content association between music and\nvideo. In addition to the adequacy of content, adequacy of structure is crucial\nin music supervision to obtain relevant recommendations. We propose a novel\napproach to significantly improve the system's performance using\nstructure-aware recommendation. The core idea is to consider not only the full\naudio-video clips, but rather shorter segments for training and inference. We\nfind that using semantic segments and ranking the tracks according to sequence\nalignment costs significantly improves the results. We investigate the impact\nof different ranking metrics and segmentation methods.",
        "translated": "我们研究跨模态的音乐曲目推荐作为视频配乐使用。这个问题被称为音乐监督任务。我们建立了一个自我监督系统，学习音乐和视频之间的内容关联。除了内容的充分性，结构的充分性在音乐监督中也是至关重要的，以获得相关的建议。我们提出了一种新的方法来显著提高系统的性能使用结构感知的推荐。其核心思想是不仅要考虑完整的音视频剪辑，而且要考虑训练和推理的较短片段。我们发现，使用语义片段并根据序列比对成本对音轨进行排序，可以显著提高搜索结果。我们研究了不同排序指标和分割方法的影响。"
    },
    {
        "title": "Adversarial Constrained Bidding via Minimax Regret Optimization with\n  Causality-Aware Reinforcement Learning",
        "url": "http://arxiv.org/abs/2306.07106v1",
        "pub_date": "2023-06-12",
        "summary": "The proliferation of the Internet has led to the emergence of online\nadvertising, driven by the mechanics of online auctions. In these repeated\nauctions, software agents participate on behalf of aggregated advertisers to\noptimize for their long-term utility. To fulfill the diverse demands, bidding\nstrategies are employed to optimize advertising objectives subject to different\nspending constraints. Existing approaches on constrained bidding typically rely\non i.i.d. train and test conditions, which contradicts the adversarial nature\nof online ad markets where different parties possess potentially conflicting\nobjectives. In this regard, we explore the problem of constrained bidding in\nadversarial bidding environments, which assumes no knowledge about the\nadversarial factors. Instead of relying on the i.i.d. assumption, our insight\nis to align the train distribution of environments with the potential test\ndistribution meanwhile minimizing policy regret. Based on this insight, we\npropose a practical Minimax Regret Optimization (MiRO) approach that\ninterleaves between a teacher finding adversarial environments for tutoring and\na learner meta-learning its policy over the given distribution of environments.\nIn addition, we pioneer to incorporate expert demonstrations for learning\nbidding strategies. Through a causality-aware policy design, we improve upon\nMiRO by distilling knowledge from the experts. Extensive experiments on both\nindustrial data and synthetic data show that our method, MiRO with\nCausality-aware reinforcement Learning (MiROCL), outperforms prior methods by\nover 30%.",
        "translated": "互联网的扩散导致了在线广告的出现，这是由在线拍卖的机制所驱动的。在这些重复的拍卖中，软件代理商代表广告主集合参与，以优化他们的长期效用。为了满足不同的需求，投标策略被用来优化受不同支出约束的广告目标。现有的限制性投标方法通常依赖于身份证培训和测试条件，这与在线广告市场的对抗性质相矛盾，因为在线广告市场中，不同的当事人拥有潜在的相互冲突的目标。在这方面，我们探讨了在不考虑竞争因素的情况下，在竞争性投标环境下的约束投标问题。我们的洞察力不是依赖于内部识别假设，而是使环境的列车分布与潜在的测试分布保持一致，同时最大限度地减少政策遗憾。基于这种观点，我们提出了一种实用的极大极小遗憾优化(Miniax Regret Optimation，MiRO)方法，该方法在教师寻找对抗性的辅导环境和学习者元学习策略之间进行交叉。此外，我们率先采用专家演示学习投标策略。通过一个因果关系感知策略设计，我们从专家那里提取知识来改进 MiRO。对工业数据和合成数据的大量实验表明，我们的方法，带有因果感知强化学习(miROCL)的 miRO，比之前的方法性能高出30% 以上。"
    },
    {
        "title": "Imbalanced Multi-label Classification for Business-related Text with\n  Moderately Large Label Spaces",
        "url": "http://arxiv.org/abs/2306.07046v1",
        "pub_date": "2023-06-12",
        "summary": "In this study, we compared the performance of four different methods for\nmulti label text classification using a specific imbalanced business dataset.\nThe four methods we evaluated were fine tuned BERT, Binary Relevance,\nClassifier Chains, and Label Powerset. The results show that fine tuned BERT\noutperforms the other three methods by a significant margin, achieving high\nvalues of accuracy, F1 Score, Precision, and Recall. Binary Relevance also\nperforms well on this dataset, while Classifier Chains and Label Powerset\ndemonstrate relatively poor performance. These findings highlight the\neffectiveness of fine tuned BERT for multi label text classification tasks, and\nsuggest that it may be a useful tool for businesses seeking to analyze complex\nand multifaceted texts.",
        "translated": "在这项研究中，我们比较了四种不同方法的性能，多标签文本分类使用特定的不平衡业务数据集。我们评估的四种方法是微调的 BERT、二进制相关性、分类器链和标签 Powerset。结果表明，精调误码率优于其他三种方法，具有较高的精度、 F1评分、精度和召回率。二进制相关性在这个数据集上也表现良好，而分类器链和标签 Powerset 表现出相对较差的性能。这些发现突出了微调 BERT 在多标签文本分类任务中的有效性，并表明它可能是企业寻求分析复杂和多方面文本的有用工具。"
    },
    {
        "title": "Data-Copilot: Bridging Billions of Data and Humans with Autonomous\n  Workflow",
        "url": "http://arxiv.org/abs/2306.07209v1",
        "pub_date": "2023-06-12",
        "summary": "Various industries such as finance, meteorology, and energy generate vast\namounts of heterogeneous data every day. There is a natural demand for humans\nto manage, process, and display data efficiently. However, it necessitates\nlabor-intensive efforts and a high level of expertise for these data-related\ntasks. Considering that large language models (LLMs) have showcased promising\ncapabilities in semantic understanding and reasoning, we advocate that the\ndeployment of LLMs could autonomously manage and process massive amounts of\ndata while displaying and interacting in a human-friendly manner. Based on this\nbelief, we propose Data-Copilot, an LLM-based system that connects numerous\ndata sources on one end and caters to diverse human demands on the other end.\nActing like an experienced expert, Data-Copilot autonomously transforms raw\ndata into visualization results that best match the user's intent.\nSpecifically, Data-Copilot autonomously designs versatile interfaces (tools)\nfor data management, processing, prediction, and visualization. In real-time\nresponse, it automatically deploys a concise workflow by invoking corresponding\ninterfaces step by step for the user's request. The interface design and\ndeployment processes are fully controlled by Data-Copilot itself, without human\nassistance. Besides, we create a Data-Copilot demo that links abundant data\nfrom different domains (stock, fund, company, economics, and live news) and\naccurately respond to diverse requests, serving as a reliable AI assistant.",
        "translated": "金融、气象和能源等不同行业每天都会产生大量异构数据。对人类来说，有效地管理、处理和显示数据是一种自然的需求。然而，对于这些与数据相关的任务，它需要劳动密集型的努力和高水平的专业知识。考虑到大型语言模型(LLM)在语义理解和推理方面表现出了很有前途的能力，我们主张 LLM 的部署可以自主地管理和处理大量的数据，同时以人性化的方式显示和交互。基于这一信念，我们提出了 Data-Copilot，一个基于 LLM 的系统，一端连接众多数据源，另一端满足不同的人类需求。Data-Copilot 像一位经验丰富的专家一样，自主地将原始数据转换为最符合用户意图的可视化结果。具体来说，Data-Copilot 自主设计用于数据管理、处理、预测和可视化的多功能接口(工具)。在实时响应中，它通过为用户的请求逐步调用相应的接口，自动部署一个简洁的工作流。接口设计和部署过程完全由 Data-Copilot 本身控制，无需人工协助。此外，我们创建了一个 Data-Copilot 演示，链接了来自不同领域(股票、基金、公司、经济和现场新闻)的大量数据，并准确地响应不同的请求，作为一个可靠的人工智能助手。"
    },
    {
        "title": "Valley: Video Assistant with Large Language model Enhanced abilitY",
        "url": "http://arxiv.org/abs/2306.07207v1",
        "pub_date": "2023-06-12",
        "summary": "Recently, several multi-modal models have been developed for joint image and\nlanguage understanding, which have demonstrated impressive chat abilities by\nutilizing advanced large language models (LLMs). The process of developing such\nmodels is straightforward yet effective. It involves pre-training an adaptation\nmodule to align the semantics of the vision encoder and language model,\nfollowed by fine-tuning on the instruction-following data. However, despite the\nsuccess of this pipeline in image and language understanding, its effectiveness\nin joint video and language understanding has not been widely explored. In this\npaper, we aim to develop a novel multi-modal foundation model capable of\nperceiving video, image, and language within a general framework. To achieve\nthis goal, we introduce Valley: Video Assistant with Large Language model\nEnhanced ability. Specifically, our proposed Valley model is designed with a\nsimple projection module that bridges video, image, and language modalities,\nand is further unified with a multi-lingual LLM. We also collect multi-source\nvision-text pairs and adopt a spatio-temporal pooling strategy to obtain a\nunified vision encoding of video and image input for pre-training. Furthermore,\nwe generate multi-task instruction-following video data, including multi-shot\ncaptions, long video descriptions, action recognition, causal relationship\ninference, etc. To obtain the instruction-following data, we design diverse\nrounds of task-oriented conversations between humans and videos, facilitated by\nChatGPT. Qualitative examples demonstrate that our proposed model has the\npotential to function as a highly effective multilingual video assistant that\ncan make complex video understanding scenarios easy. Code, data, and models\nwill be available at https://github.com/RupertLuo/Valley.",
        "translated": "最近，一些多模态模型已经被开发出来用于联合图像和语言理解，它们通过使用先进的大语言模型(LLM)展示了令人印象深刻的聊天能力。开发这种模型的过程是简单而有效的。它包括预先训练一个适应模块，以便对准视觉编码器和语言模型的语义，然后对指令跟踪数据进行微调。然而，尽管这条管道在图像和语言理解方面取得了成功，但它在联合视频和语言理解方面的有效性还没有得到广泛的探索。在本文中，我们的目标是开发一个新的多模态基础模型，能够感知视频，图像和语言在一个通用的框架内。为了实现这一目标，我们引入了谷: 视频助理与大语言模型增强能力。具体来说，我们提出的 Valley 模型设计了一个简单的投影模块，它连接了视频、图像和语言模式，并进一步与多语言 LLM 相结合。采集多源视觉文本对，采用时空合并策略，获得视频和图像输入的统一视觉编码，用于预训练。此外，还生成了多任务指令跟踪视频数据，包括多镜头字幕、长视频描述、动作识别、因果关系推理等。为了获得指令跟踪数据，我们设计了不同轮次的任务导向的人类和视频之间的对话，促进了 ChatGPT。定性的例子表明，我们提出的模型有潜力作为一个高效的多语言视频助理，可以使复杂的视频理解场景容易。代码、数据和模型将在 https://github.com/rupertluo/valley 提供。"
    },
    {
        "title": "RECAP: Retrieval-Enhanced Context-Aware Prefix Encoder for Personalized\n  Dialogue Response Generation",
        "url": "http://arxiv.org/abs/2306.07206v1",
        "pub_date": "2023-06-12",
        "summary": "Endowing chatbots with a consistent persona is essential to an engaging\nconversation, yet it remains an unresolved challenge. In this work, we propose\na new retrieval-enhanced approach for personalized response generation.\nSpecifically, we design a hierarchical transformer retriever trained on\ndialogue domain data to perform personalized retrieval and a context-aware\nprefix encoder that fuses the retrieved information to the decoder more\neffectively. Extensive experiments on a real-world dataset demonstrate the\neffectiveness of our model at generating more fluent and personalized\nresponses. We quantitatively evaluate our model's performance under a suite of\nhuman and automatic metrics and find it to be superior compared to\nstate-of-the-art baselines on English Reddit conversations.",
        "translated": "赋予聊天机器人一个一致的角色对于一个引人入胜的对话至关重要，然而这仍然是一个未解决的挑战。在这项工作中，我们提出了一个新的检索增强的方法来生成个性化的响应。具体地说，我们设计了一个基于对话域数据训练的分层变压器检索器来执行个性化检索，以及一个上下文感知的前缀编码器来更有效地将检索到的信息融合到解码器中。在真实世界数据集上的大量实验证明了我们的模型在产生更流畅和个性化响应方面的有效性。我们定量评估了我们的模型在一套人工和自动指标下的表现，发现它比英语 Reddit 会话的最先进的基线要好。"
    },
    {
        "title": "LTCR: Long-Text Chinese Rumor Detection Dataset",
        "url": "http://arxiv.org/abs/2306.07201v2",
        "pub_date": "2023-06-12",
        "summary": "False information can spread quickly on social media, negatively influencing\nthe citizens' behaviors and responses to social events. To better detect all of\nthe fake news, especially long texts which are harder to find completely, a\nLong-Text Chinese Rumor detection dataset named LTCR is proposed. The LTCR\ndataset provides a valuable resource for accurately detecting misinformation,\nespecially in the context of complex fake news related to COVID-19. The dataset\nconsists of 1,729 and 500 pieces of real and fake news, respectively. The\naverage lengths of real and fake news are approximately 230 and 152 characters.\nWe also propose \\method, Salience-aware Fake News Detection Model, which\nachieves the highest accuracy (95.85%), fake news recall (90.91%) and F-score\n(90.60%) on the dataset. (https://github.com/Enderfga/DoubleCheck)",
        "translated": "虚假信息可以在社交媒体上迅速传播，对公民的行为和对社会事件的反应产生负面影响。为了更好地检测所有的假新闻，特别是难以完全发现的长文本，提出了一种长文本中文谣言检测数据集 LTCR。LTCR 数据集为准确检测错误信息提供了有价值的资源，特别是在与2019冠状病毒疾病有关的复杂假新闻背景下。这个数据集包括1729条真实新闻和500条假新闻。真实和假新闻的平均长度大约是230和152个字符。本文还提出了基于显著性的假新闻检测模型，该模型对数据集的准确率最高(95.85%) ，对假新闻的召回率最高(90.91%) ，对假新闻的 F 分值最高(90.60%)。( https://github.com/enderfga/doublecheck )"
    },
    {
        "title": "A Survey of Vision-Language Pre-training from the Lens of Multimodal\n  Machine Translation",
        "url": "http://arxiv.org/abs/2306.07198v1",
        "pub_date": "2023-06-12",
        "summary": "Large language models such as BERT and the GPT series started a paradigm\nshift that calls for building general-purpose models via pre-training on large\ndatasets, followed by fine-tuning on task-specific datasets. There is now a\nplethora of large pre-trained models for Natural Language Processing and\nComputer Vision. Recently, we have seen rapid developments in the joint\nVision-Language space as well, where pre-trained models such as CLIP (Radford\net al., 2021) have demonstrated improvements in downstream tasks like image\ncaptioning and visual question answering. However, surprisingly there is\ncomparatively little work on exploring these models for the task of multimodal\nmachine translation, where the goal is to leverage image/video modality in\ntext-to-text translation. To fill this gap, this paper surveys the landscape of\nlanguage-and-vision pre-training from the lens of multimodal machine\ntranslation. We summarize the common architectures, pre-training objectives,\nand datasets from literature and conjecture what further is needed to make\nprogress on multimodal machine translation.",
        "translated": "像 BERT 和 GPT 系列这样的大型语言模型开启了一个范式转变，要求通过对大型数据集进行预训练来构建通用模型，然后对特定任务的数据集进行微调。现在有大量的自然语言处理和计算机视觉的大型预训练模型。最近，我们也看到了联合视觉语言空间的快速发展，其中预先训练的模型如 CLIP (Radford et al。 ，2021)已经在下游任务如图像字幕和视觉问题回答方面表现出改进。然而，令人惊讶的是，在多模态机器翻译的任务中，探索这些模型的工作相对较少，其目标是在文本到文本的翻译中利用图像/视频模态。为了填补这一空白，本文从多模态机器翻译的角度考察了语言和视觉预训的前景。我们总结了通用的体系结构、预训练目标和来自文献的数据集，并推测在多模式机器翻译方面还需要做些什么。"
    },
    {
        "title": "Large language models and (non-)linguistic recursion",
        "url": "http://arxiv.org/abs/2306.07195v1",
        "pub_date": "2023-06-12",
        "summary": "Recursion is one of the hallmarks of human language. While many design\nfeatures of language have been shown to exist in animal communication systems,\nrecursion has not. Previous research shows that GPT-4 is the first large\nlanguage model (LLM) to exhibit metalinguistic abilities (Begu\\v{s},\nD\\k{a}bkowski, and Rhodes 2023). Here, we propose several prompt designs aimed\nat eliciting and analyzing recursive behavior in LLMs, both linguistic and\nnon-linguistic. We demonstrate that when explicitly prompted, GPT-4 can both\nproduce and analyze recursive structures. Thus, we present one of the first\nstudies investigating whether meta-linguistic awareness of recursion -- a\nuniquely human cognitive property -- can emerge in transformers with a high\nnumber of parameters such as GPT-4.",
        "translated": "递归是人类语言的标志之一。虽然语言的许多设计特征已被证明存在于动物交流系统中，但递归却没有。以往的研究表明，GPT-4是第一个表现出元语言能力的大型语言模型(Begu v { s } ，D k { a } bkowski，and Rhodes 2023)。在这里，我们提出了几个快速的设计，旨在引发和分析递归行为的 LLM，无论是语言和非语言。我们演示了当显式提示时，GPT-4既可以产生递归结构，也可以分析递归结构。因此，我们提出的第一个研究之一，调查是否元语言意识的递归-一个独特的人类认知属性-可以出现在变压器与大量的参数，如 GPT-4。"
    },
    {
        "title": "The Effect of Masking Strategies on Knowledge Retention by Language\n  Models",
        "url": "http://arxiv.org/abs/2306.07185v1",
        "pub_date": "2023-06-12",
        "summary": "Language models retain a significant amount of world knowledge from their\npre-training stage. This allows knowledgeable models to be applied to\nknowledge-intensive tasks prevalent in information retrieval, such as ranking\nor question answering. Understanding how and which factual information is\nacquired by our models is necessary to build responsible models. However,\nlimited work has been done to understand the effect of pre-training tasks on\nthe amount of knowledge captured and forgotten by language models during\npre-training. Building a better understanding of knowledge acquisition is the\ngoal of this paper. Therefore, we utilize a selection of pre-training tasks to\ninfuse knowledge into our model. In the following steps, we test the model's\nknowledge retention by measuring its ability to answer factual questions. Our\nexperiments show that masking entities and principled masking of correlated\nspans based on pointwise mutual information lead to more factual knowledge\nbeing retained than masking random tokens. Our findings demonstrate that, like\nthe ability to perform a task, the (factual) knowledge acquired from being\ntrained on that task is forgotten when a model is trained to perform another\ntask (catastrophic forgetting) and how to prevent this phenomenon. To foster\nreproducibility, the code, as well as the data used in this paper, are openly\navailable.",
        "translated": "语言模型从培训前阶段就保留了大量的世界知识。这使得知识型模型能够应用于信息检索中普遍存在的知识密集型任务，例如排名或问答。要建立负责任的模型，就必须了解我们的模型是如何以及获取哪些事实信息的。然而，在理解培训前任务对语言模型在培训前捕获和遗忘的知识量的影响方面所做的工作有限。加深对知识获取的理解是本文的目的。因此，我们利用一个预训练任务的选择，将知识注入到我们的模型中。在接下来的步骤中，我们通过测量模型回答实际问题的能力来测试模型的知识保持能力。我们的实验表明，屏蔽实体和基于点间互信息的相关跨度的原则性屏蔽比屏蔽随机标记能够保留更多的事实知识。我们的研究结果表明，就像执行任务的能力一样，当一个模型被训练去执行另一个任务(灾难性遗忘)时，从该任务中获得的(事实)知识会被遗忘，以及如何防止这种现象的发生。为了提高可重复性，本文中使用的代码和数据都是公开的。"
    },
    {
        "title": "Augmenting Language Models with Long-Term Memory",
        "url": "http://arxiv.org/abs/2306.07174v1",
        "pub_date": "2023-06-12",
        "summary": "Existing large language models (LLMs) can only afford fix-sized inputs due to\nthe input length limit, preventing them from utilizing rich long-context\ninformation from past inputs. To address this, we propose a framework, Language\nModels Augmented with Long-Term Memory (LongMem), which enables LLMs to\nmemorize long history. We design a novel decoupled network architecture with\nthe original backbone LLM frozen as a memory encoder and an adaptive residual\nside-network as a memory retriever and reader. Such a decoupled memory design\ncan easily cache and update long-term past contexts for memory retrieval\nwithout suffering from memory staleness. Enhanced with memory-augmented\nadaptation training, LongMem can thus memorize long past context and use\nlong-term memory for language modeling. The proposed memory retrieval module\ncan handle unlimited-length context in its memory bank to benefit various\ndownstream tasks. Typically, LongMem can enlarge the long-form memory to 65k\ntokens and thus cache many-shot extra demonstration examples as long-form\nmemory for in-context learning. Experiments show that our method outperforms\nstrong long-context models on ChapterBreak, a challenging long-context modeling\nbenchmark, and achieves remarkable improvements on memory-augmented in-context\nlearning over LLMs. The results demonstrate that the proposed method is\neffective in helping language models to memorize and utilize long-form\ncontents. Our code is open-sourced at https://aka.ms/LongMem.",
        "translated": "由于输入长度的限制，现有的大型语言模型(LLM)只能提供固定大小的输入，这使得它们无法利用来自过去输入的丰富的长上下文信息。为了解决这个问题，我们提出了一个框架，即使用长期记忆增强的语言模型(LongMem) ，它使长期记忆能够记忆长期的历史。我们设计了一种新颖的解耦网络结构，其中原骨干 LLM 作为内存编码器，自适应残余网络作为内存检索器和读取器。这种解耦的内存设计可以轻松地缓存和更新长期的过去上下文，用于内存检索，而不会受到内存过时的影响。随着记忆增强适应训练的加强，LongMem 因此可以记住很长的过去的上下文，并使用长期记忆进行语言建模。提出的内存检索模块可以在其内存库中处理无限长的上下文，有利于各种下游任务。通常，LongMem 可以将长形式内存扩大到65k 令牌，从而缓存多镜头的额外示例作为长形式内存，用于上下文学习。实验结果表明，该方法优于一个具有挑战性的长上下文建模基准 ChapterBreak 的强大长上下文模型，并且在 LLM 上实现了对记忆增强的上下文学习的显著改进。结果表明，该方法能有效地帮助语言模型记忆和利用长形式的内容。我们的代码在 https://aka.ms/longmem 是开源的。"
    },
    {
        "title": "Prompt-based Extraction of Social Determinants of Health Using Few-shot\n  Learning",
        "url": "http://arxiv.org/abs/2306.07170v1",
        "pub_date": "2023-06-12",
        "summary": "Social determinants of health (SDOH) documented in the electronic health\nrecord through unstructured text are increasingly being studied to understand\nhow SDOH impacts patient health outcomes. In this work, we utilize the Social\nHistory Annotation Corpus (SHAC), a multi-institutional corpus of de-identified\nsocial history sections annotated for SDOH, including substance use,\nemployment, and living status information. We explore the automatic extraction\nof SDOH information with SHAC in both standoff and inline annotation formats\nusing GPT-4 in a one-shot prompting setting. We compare GPT-4 extraction\nperformance with a high-performing supervised approach and perform thorough\nerror analyses. Our prompt-based GPT-4 method achieved an overall 0.652 F1 on\nthe SHAC test set, similar to the 7th best-performing system among all teams in\nthe n2c2 challenge with SHAC.",
        "translated": "通过非结构化文本记录在电子健康记录中的健康的社会决定因素(SDOH)正在被越来越多地研究，以了解 SDOH 如何影响患者的健康结果。在这项工作中，我们利用社会历史注释语料库(SHAC) ，一个多机构语料库的去识别社会历史部分为 SDOH 注释，包括物质使用，就业和生活状态信息。我们使用 GPT-4在一次性提示设置中探索使用 SHAC 以对峙格式和内联注释格式自动提取 SDOH 信息。我们比较了 GPT-4提取性能和高性能的监督方法，并进行了彻底的误差分析。我们的基于提示的 GPT-4方法在 SHAC 测试集上获得了总体0.652 F1，类似于所有团队在 SHAC 的 n2c2挑战中排名第7的最佳系统。"
    },
    {
        "title": "Best-Case Retrieval Evaluation: Improving the Sensitivity of Reciprocal\n  Rank with Lexicographic Precision",
        "url": "http://arxiv.org/abs/2306.07908v1",
        "pub_date": "2023-06-13",
        "summary": "Across a variety of ranking tasks, researchers use reciprocal rank to measure\nthe effectiveness for users interested in exactly one relevant item. Despite\nits widespread use, evidence suggests that reciprocal rank is brittle when\ndiscriminating between systems. This brittleness, in turn, is compounded in\nmodern evaluation settings where current, high-precision systems may be\ndifficult to distinguish. We address the lack of sensitivity of reciprocal rank\nby introducing and connecting it to the concept of best-case retrieval, an\nevaluation method focusing on assessing the quality of a ranking for the most\nsatisfied possible user across possible recall requirements. This perspective\nallows us to generalize reciprocal rank and define a new preference-based\nevaluation we call lexicographic precision or lexiprecision. By mathematical\nconstruction, we ensure that lexiprecision preserves differences detected by\nreciprocal rank, while empirically improving sensitivity and robustness across\na broad set of retrieval and recommendation tasks.",
        "translated": "在各种排名任务中，研究人员使用互惠排名来衡量对一个相关项目感兴趣的用户的有效性。尽管它被广泛使用，但有证据表明，在区分不同体系时，互惠等级是脆弱的。这种脆性，反过来，在现代评估设置中，当前，高精度的系统可能难以区分复杂。我们通过引入并联系最佳案例检索的概念来解决相互排名缺乏敏感性的问题，最佳案例检索是一种评估方法，侧重于在可能的召回需求中为最满意的可能用户评估排名的质量。这种观点允许我们推广互惠等级，并定义一种新的基于偏好的评价，我们称之为词典精度或词汇精度。通过数学建构，我们确保词汇精确度保留了通过相互排名检测到的差异，同时经验性地提高了广泛的检索和推荐任务集的灵敏度和鲁棒性。"
    },
    {
        "title": "ReadProbe: A Demo of Retrieval-Enhanced Large Language Models to Support\n  Lateral Reading",
        "url": "http://arxiv.org/abs/2306.07875v1",
        "pub_date": "2023-06-13",
        "summary": "With the rapid growth and spread of online misinformation, people need tools\nto help them evaluate the credibility and accuracy of online information.\nLateral reading, a strategy that involves cross-referencing information with\nmultiple sources, may be an effective approach to achieving this goal. In this\npaper, we present ReadProbe, a tool to support lateral reading, powered by\ngenerative large language models from OpenAI and the Bing search engine. Our\ntool is able to generate useful questions for lateral reading, scour the web\nfor relevant documents, and generate well-attributed answers to help people\nbetter evaluate online information. We made a web-based application to\ndemonstrate how ReadProbe can help reduce the risk of being misled by false\ninformation. The code is available at\nhttps://github.com/DakeZhang1998/ReadProbe. An earlier version of our tool won\nthe first prize in a national AI misinformation hackathon.",
        "translated": "随着网络虚假信息的快速增长和传播，人们需要工具来帮助他们评估网络信息的可信度和准确性。横向阅读是一种涉及多源信息交叉引用的策略，可能是实现这一目标的有效途径。在这篇文章中，我们介绍了一个支持横向阅读的工具，由 OpenAI 和 Bing 搜索引擎生成的大型语言模型提供支持。我们的工具能够为横向阅读生成有用的问题，在网上搜索相关文档，并生成归属良好的答案，以帮助人们更好地评估在线信息。我们做了一个网络应用程序来演示如何通过阅读探索来帮助降低被错误信息误导的风险。密码可在 https://github.com/dakezhang1998/readprobe 查阅。我们工具的早期版本赢得了全国人工智能错误信息黑客马拉松一等奖。"
    },
    {
        "title": "KuaiSAR: A Unified Search And Recommendation Dataset",
        "url": "http://arxiv.org/abs/2306.07705v1",
        "pub_date": "2023-06-13",
        "summary": "The confluence of Search and Recommendation services is a vital aspect of\nonline content platforms like Kuaishou and TikTok. The integration of S&amp;R\nmodeling is a highly intuitive approach adopted by industry practitioners.\nHowever, there is a noticeable lack of research conducted in this area within\nthe academia, primarily due to the absence of publicly available datasets.\nConsequently, a substantial gap has emerged between academia and industry\nregarding research endeavors in this field. To bridge this gap, we introduce\nthe first large-scale, real-world dataset KuaiSAR of integrated Search And\nRecommendation behaviors collected from Kuaishou, a leading short-video app in\nChina with over 300 million daily active users. Previous research in this field\nhas predominantly employed publicly available datasets that are semi-synthetic\nand simulated, with artificially fabricated search behaviors. Distinct from\nprevious datasets, KuaiSAR records genuine user behaviors, the occurrence of\neach interaction within either search or recommendation service, and the users'\ntransitions between the two services. This work aids in joint modeling of S&amp;R,\nand the utilization of search data for recommenders (and recommendation data\nfor search engines). Additionally, due to the diverse feedback labels of\nuser-video interactions, KuaiSAR also supports a wide range of other tasks,\nincluding intent recommendation, multi-task learning, and long sequential\nmulti-behavior modeling etc. We believe this dataset will facilitate innovative\nresearch and enrich our understanding of S&amp;R services integration in real-world\napplications.",
        "translated": "搜索和推荐服务的融合是 Kuaishou 和 TikTok 等在线内容平台的一个重要方面。S & R 建模的集成是业界从业人员采用的一种高度直观的方法。然而，学术界在这一领域明显缺乏研究，主要是由于缺乏公开可用的数据集。因此，学术界和工业界在这一领域的研究工作出现了巨大的差距。为了弥补这一差距，我们介绍了第一个大规模的，真实世界的数据集 KuaiSAR 的集成搜索和推荐行为收集自 Kuaishou，一个领先的短视频应用程序在中国有超过3亿日活跃用户。以前在这个领域的研究主要使用公开可用的数据集，这些数据集是半合成的和模拟的，具有人为制造的搜索行为。与以前的数据集不同，KuaiSAR 记录了真实的用户行为、搜索或推荐服务中每个交互的发生情况以及用户在两个服务之间的转换。这项工作有助于 S & R 的联合建模，以及对推荐者的搜索数据(和搜索引擎的推荐数据)的利用。此外，由于用户与视频交互的反馈标签多种多样，KuaiSAR 还支持广泛的其他任务，包括意图推荐、多任务学习和长顺序多行为建模等。我们相信这个数据集将促进创新研究，并丰富我们对现实世界应用中的 S & R 服务集成的理解。"
    },
    {
        "title": "Practice with Graph-based ANN Algorithms on Sparse Data: Chi-square\n  Two-tower model, HNSW, Sign Cauchy Projections",
        "url": "http://arxiv.org/abs/2306.07607v1",
        "pub_date": "2023-06-13",
        "summary": "Sparse data are common. The traditional ``handcrafted'' features are often\nsparse. Embedding vectors from trained models can also be very sparse, for\nexample, embeddings trained via the ``ReLu'' activation function. In this\npaper, we report our exploration of efficient search in sparse data with\ngraph-based ANN algorithms (e.g., HNSW, or SONG which is the GPU version of\nHNSW), which are popular in industrial practice, e.g., search and ads\n(advertising).\n  We experiment with the proprietary ads targeting application, as well as\nbenchmark public datasets. For ads targeting, we train embeddings with the\nstandard ``cosine two-tower'' model and we also develop the ``chi-square\ntwo-tower'' model. Both models produce (highly) sparse embeddings when they are\nintegrated with the ``ReLu'' activation function. In EBR (embedding-based\nretrieval) applications, after we the embeddings are trained, the next crucial\ntask is the approximate near neighbor (ANN) search for serving. While there are\nmany ANN algorithms we can choose from, in this study, we focus on the\ngraph-based ANN algorithm (e.g., HNSW-type).\n  Sparse embeddings should help improve the efficiency of EBR. One benefit is\nthe reduced memory cost for the embeddings. The other obvious benefit is the\nreduced computational time for evaluating similarities, because, for\ngraph-based ANN algorithms such as HNSW, computing similarities is often the\ndominating cost. In addition to the effort on leveraging data sparsity for\nstorage and computation, we also integrate ``sign cauchy random projections''\n(SignCRP) to hash vectors to bits, to further reduce the memory cost and speed\nup the ANN search. In NIPS'13, SignCRP was proposed to hash the chi-square\nsimilarity, which is a well-adopted nonlinear kernel in NLP and computer\nvision. Therefore, the chi-square two-tower model, SignCRP, and HNSW are now\ntightly integrated.",
        "translated": "稀疏的数据很常见。传统的“手工制作”的特点往往是稀少的。从训练过的模型中嵌入向量也可能非常稀疏，例如，通过“ ReLu”激活函数训练的嵌入。在本文中，我们报告了在稀疏数据中使用基于图的神经网络算法(例如，HNSW，或 SONG，这是 HNSW 的 GPU 版本)进行有效搜索的探索，这在工业实践中很流行，例如，搜索和广告(广告)。我们尝试使用针对应用程序的专有广告，以及基准公共数据集。对于广告定位，我们使用标准的“余弦双塔”模型训练嵌入，同时开发了“卡方双塔”模型。这两种模式在与“ ReLu”激活函数集成时都会产生(高度)稀疏的嵌入。在基于嵌入的检索(EBR)应用中，嵌入训练完成后，接下来的关键任务是近似近邻(ANN)搜索服务。虽然有很多神经网络算法可供选择，但本文主要研究基于图的神经网络算法(如 HNSW 型)。稀疏嵌入有助于提高 EBR 的效率。一个好处是减少了嵌入的内存开销。另一个明显的好处是减少了评估相似性的计算时间，因为对于基于图的神经网络算法，如 HNSW，计算相似性往往是主要的代价。除了努力利用数据稀疏性进行存储和计算，我们还集成了“符号柯西随机投影”(SignCRP)来散列向量到位，以进一步降低内存成本和加速人工神经网络搜索。在 NIPS’13中，SignCRP 被提出来对卡方相似度进行散列，这是一种在自然语言处理和计算机视觉中广泛采用的非线性核。因此，卡方双塔模型 SignCRP 和 HNSW 现在紧密结合在一起。"
    },
    {
        "title": "Unified Off-Policy Learning to Rank: a Reinforcement Learning\n  Perspective",
        "url": "http://arxiv.org/abs/2306.07528v1",
        "pub_date": "2023-06-13",
        "summary": "Off-policy Learning to Rank (LTR) aims to optimize a ranker from data\ncollected by a deployed logging policy. However, existing off-policy learning\nto rank methods often make strong assumptions about how users generate the\nclick data, i.e., the click model, and hence need to tailor their methods\nspecifically under different click models. In this paper, we unified the\nranking process under general stochastic click models as a Markov Decision\nProcess (MDP), and the optimal ranking could be learned with offline\nreinforcement learning (RL) directly. Building upon this, we leverage offline\nRL techniques for off-policy LTR and propose the Click Model-Agnostic Unified\nOff-policy Learning to Rank (CUOLR) method, which could be easily applied to a\nwide range of click models. Through a dedicated formulation of the MDP, we show\nthat offline RL algorithms can adapt to various click models without complex\ndebiasing techniques and prior knowledge of the model. Results on various\nlarge-scale datasets demonstrate that CUOLR consistently outperforms the\nstate-of-the-art off-policy learning to rank algorithms while maintaining\nconsistency and robustness under different click models.",
        "translated": "非策略学习排序(Off-policy Learning to Rank，LTR)的目标是从已部署的日志策略收集的数据中优化排序器。然而，现有的对方法进行排序的非策略学习往往对用户如何生成点击数据(即点击模型)做出强有力的假设，因此需要在不同的点击模型下特别调整他们的方法。在本文中，我们将一般随机点击模型下的排名过程统一为一个马可夫决策过程(mDP) ，并且可以直接使用离线强化学习(RL)来学习最佳排名。在此基础上，我们利用离线 RL 技术进行非策略 LTR，并提出 Click 模型-不可知统一非策略学习排名(CUOLR)方法，该方法可以很容易地应用于广泛的点击模型。通过一个专门的公式的 MDP，我们表明离线 RL 算法可以适应各种点击模型没有复杂的消偏技术和先验知识的模型。在各种大规模数据集上的结果表明，在不同点击模型下，CUOLR 在排序算法方面始终优于最先进的非策略学习，同时保持了一致性和鲁棒性。"
    },
    {
        "title": "arXiVeri: Automatic table verification with GPT",
        "url": "http://arxiv.org/abs/2306.07968v1",
        "pub_date": "2023-06-13",
        "summary": "Without accurate transcription of numerical data in scientific documents, a\nscientist cannot draw accurate conclusions. Unfortunately, the process of\ncopying numerical data from one paper to another is prone to human error. In\nthis paper, we propose to meet this challenge through the novel task of\nautomatic table verification (AutoTV), in which the objective is to verify the\naccuracy of numerical data in tables by cross-referencing cited sources. To\nsupport this task, we propose a new benchmark, arXiVeri, which comprises\ntabular data drawn from open-access academic papers on arXiv. We introduce\nmetrics to evaluate the performance of a table verifier in two key areas: (i)\ntable matching, which aims to identify the source table in a cited document\nthat corresponds to a target table, and (ii) cell matching, which aims to\nlocate shared cells between a target and source table and identify their row\nand column indices accurately. By leveraging the flexible capabilities of\nmodern large language models (LLMs), we propose simple baselines for table\nverification. Our findings highlight the complexity of this task, even for\nstate-of-the-art LLMs like OpenAI's GPT-4. The code and benchmark will be made\npublicly available.",
        "translated": "没有科学文献中数字数据的准确记录，科学家就不能得出准确的结论。不幸的是，将数字数据从一张纸复制到另一张纸的过程容易出现人为错误。在本文中，我们提出通过自动表格验证(AutoTV)这一新的任务来迎接这一挑战，其目标是通过交叉引用来源来验证表格中数字数据的准确性。为了支持这个任务，我们提出了一个新的基准，arXiVeri，它包含从 arXiv 上的开放存取学术论文中提取的表格数据。我们引入指标来评估表验证器在两个关键领域的性能: (i)表匹配，其目的是识别与目标表对应的引用文档中的源表; 和(ii)单元格匹配，其目的是在目标和源表之间定位共享单元格，并准确识别其行和列索引。通过利用现代大型语言模型(LLM)的灵活性，我们为表验证提出了简单的基线。我们的发现强调了这项任务的复杂性，即使对于像 OpenAI 的 GPT-4这样的最先进的 LLM 也是如此。代码和基准将公开发布。"
    },
    {
        "title": "MOFI: Learning Image Representations from Noisy Entity Annotated Images",
        "url": "http://arxiv.org/abs/2306.07952v1",
        "pub_date": "2023-06-13",
        "summary": "We present MOFI, a new vision foundation model designed to learn image\nrepresentations from noisy entity annotated images. MOFI differs from previous\nwork in two key aspects: ($i$) pre-training data, and ($ii$) training recipe.\nRegarding data, we introduce a new approach to automatically assign entity\nlabels to images from noisy image-text pairs. Our approach involves employing a\nnamed entity recognition model to extract entities from the alt-text, and then\nusing a CLIP model to select the correct entities as labels of the paired\nimage. The approach is simple, does not require costly human annotation, and\ncan be readily scaled up to billions of image-text pairs mined from the web.\nThrough this method, we have created Image-to-Entities (I2E), a new large-scale\ndataset with 1 billion images and 2 million distinct entities, covering rich\nvisual concepts in the wild. Building upon the I2E dataset, we study different\ntraining recipes, including supervised pre-training, contrastive pre-training,\nand multi-task learning. For constrastive pre-training, we treat entity names\nas free-form text, and further enrich them with entity descriptions.\nExperiments show that supervised pre-training with large-scale fine-grained\nentity labels is highly effective for image retrieval tasks, and multi-task\ntraining further improves the performance. The final MOFI model achieves 86.66%\nmAP on the challenging GPR1200 dataset, surpassing the previous\nstate-of-the-art performance of 72.19% from OpenAI's CLIP model. Further\nexperiments on zero-shot and linear probe image classification also show that\nMOFI outperforms a CLIP model trained on the original image-text data,\ndemonstrating the effectiveness of the I2E dataset in learning strong image\nrepresentations.",
        "translated": "提出了一种新的视觉基础模型 MOFI，该模型旨在从噪声实体注释图像中学习图像表示。MOFI 与以往的工作有两个关键方面的不同: ($i $)培训前数据和($ii $)培训配方。对于数据，我们引入了一种新的方法来自动分配实体标签图像噪声的图像-文本对。我们的方法包括使用命名实体识别模型从替代文本中提取实体，然后使用 CLIP 模型选择正确的实体作为配对图像的标签。这种方法很简单，不需要昂贵的人工注释，而且可以很容易地扩大到从网络中挖掘出的数十亿图像-文本对。通过这种方法，我们创建了图像到实体(I2E) ，这是一个新的大规模数据集，包含10亿张图像和200万个不同的实体，覆盖了丰富的野外视觉概念。在 I2E 数据集的基础上，我们研究了不同的训练方法，包括监督预训练、对比预训练和多任务学习。在对比预训练中，我们将实体名称视为自由形式的文本，并用实体描述进一步丰富实体名称。实验表明，基于大规模细粒度实体标签的监督预训练对图像检索任务具有很高的效果，多任务训练进一步提高了性能。最终的 MOFI 模型在具有挑战性的 GPR1200数据集上达到了86.66% 的 mAP，超过了之前 OpenAI 的 CLIP 模型72.19% 的最先进性能。进一步的零拍和线性探针图像分类实验也表明，MOFI 优于对原始图像-文本数据进行训练的 CLIP 模型，证明了 I2E 数据集在学习强图像表示方面的有效性。"
    },
    {
        "title": "Questioning the Survey Responses of Large Language Models",
        "url": "http://arxiv.org/abs/2306.07951v1",
        "pub_date": "2023-06-13",
        "summary": "As large language models increase in capability, researchers have started to\nconduct surveys of all kinds on these models with varying scientific\nmotivations. In this work, we examine what we can learn from a model's survey\nresponses on the basis of the well-established American Community Survey (ACS)\nby the U.S. Census Bureau. Evaluating more than a dozen different models,\nvarying in size from a few hundred million to ten billion parameters, hundreds\nof thousands of times each on questions from the ACS, we systematically\nestablish two dominant patterns. First, smaller models have a significant\nposition and labeling bias, for example, towards survey responses labeled with\nthe letter \"A\". This A-bias diminishes, albeit slowly, as model size increases.\nSecond, when adjusting for this labeling bias through randomized answer\nordering, models still do not trend toward US population statistics or those of\nany cognizable population. Rather, models across the board trend toward\nuniformly random aggregate statistics over survey responses. This pattern is\nrobust to various different ways of prompting the model, including what is the\nde-facto standard. Our findings demonstrate that aggregate statistics of a\nlanguage model's survey responses lack the signals found in human populations.\nThis absence of statistical signal cautions about the use of survey responses\nfrom large language models at present time.",
        "translated": "随着大型语言模型能力的提高，研究人员开始以不同的科学动机对这些模型进行各种各样的调查。在这项工作中，我们研究我们可以从一个模型的调查反应的基础上，由美国人口普查局建立的美国社区调查(ACS)的学习。我们评估了十几个不同的模型，这些模型的大小从几亿到一百亿个参数不等，每个模型对 ACS 提出的问题进行了数十万次评估，我们系统地建立了两种主导模式。首先，较小的模型有一个重要的位置和标签偏见，例如，对标有字母“ A”的调查回答。随着模型尺寸的增加，这种 A 偏差会逐渐减小，尽管速度很慢。其次，当通过随机回答排序调整这种标记偏差时，模型仍然没有趋向于美国人口统计或任何可认知人口的统计。相反，模型全面趋向于统一随机总体统计超过调查答复。该模式对于提示模型的各种不同方式都是健壮的，包括什么是事实上的标准。我们的研究结果表明，一个语言模型的调查回答的总体统计缺乏在人口中发现的信号。这种缺乏统计信号的情况提醒人们注意目前使用来自大型语言模型的调查答复。"
    },
    {
        "title": "BoardgameQA: A Dataset for Natural Language Reasoning with Contradictory\n  Information",
        "url": "http://arxiv.org/abs/2306.07934v1",
        "pub_date": "2023-06-13",
        "summary": "Automated reasoning with unstructured natural text is a key requirement for\nmany potential applications of NLP and for developing robust AI systems.\nRecently, Language Models (LMs) have demonstrated complex reasoning capacities\neven without any finetuning. However, existing evaluation for automated\nreasoning assumes access to a consistent and coherent set of information over\nwhich models reason. When reasoning in the real-world, the available\ninformation is frequently inconsistent or contradictory, and therefore models\nneed to be equipped with a strategy to resolve such conflicts when they arise.\nOne widely-applicable way of resolving conflicts is to impose preferences over\ninformation sources (e.g., based on source credibility or information recency)\nand adopt the source with higher preference. In this paper, we formulate the\nproblem of reasoning with contradictory information guided by preferences over\nsources as the classical problem of defeasible reasoning, and develop a dataset\ncalled BoardgameQA for measuring the reasoning capacity of LMs in this setting.\nBoardgameQA also incorporates reasoning with implicit background knowledge, to\nbetter reflect reasoning problems in downstream applications. We benchmark\nvarious LMs on BoardgameQA and the results reveal a significant gap in the\nreasoning capacity of state-of-the-art LMs on this problem, showing that\nreasoning with conflicting information does not surface out-of-the-box in LMs.\nWhile performance can be improved with finetuning, it nevertheless remains\npoor.",
        "translated": "非结构化自然文本自动推理是自然语言处理许多潜在应用和开发健壮的人工智能系统的关键要求。最近，语言模型(LM)已经展示了复杂的推理能力，即使没有任何微调。然而，现有的自动推理评估假设模型能够获得一致和连贯的信息。在现实世界中进行推理时，可获得的信息往往不一致或相互矛盾，因此需要为模型配备一种战略，以便在出现这种冲突时解决这种冲突。一种广泛适用的解决冲突的方法是对信息来源强加偏好(例如，基于信息来源的可信度或信息的最新性) ，并以更高的偏好采用信息来源。在本文中，我们提出了由偏好引导的矛盾信息推理问题作为经典的可废止推理问题，并开发了一个名为 BoardgameQA 的数据集来测量在这种情况下 LM 的推理能力。BoardgameQA 还将推理与隐式背景知识结合起来，以更好地反映下游应用程序中的推理问题。我们在 BoardgameQA 上对各种 LM 进行了基准测试，结果显示在这个问题上最先进的 LM 在推理能力上存在显著的差距，表明在 LM 中，带有冲突信息的推理并不是开箱即用的。虽然通过微调可以提高性能，但它仍然很差。"
    },
    {
        "title": "WebGLM: Towards An Efficient Web-Enhanced Question Answering System with\n  Human Preferences",
        "url": "http://arxiv.org/abs/2306.07906v1",
        "pub_date": "2023-06-13",
        "summary": "We present WebGLM, a web-enhanced question-answering system based on the\nGeneral Language Model (GLM). Its goal is to augment a pre-trained large\nlanguage model (LLM) with web search and retrieval capabilities while being\nefficient for real-world deployments. To achieve this, we develop WebGLM with\nstrategies for the LLM-augmented retriever, bootstrapped generator, and human\npreference-aware scorer. Specifically, we identify and address the limitations\nof WebGPT (OpenAI), through which WebGLM is enabled with accuracy, efficiency,\nand cost-effectiveness advantages. In addition, we propose systematic criteria\nfor evaluating web-enhanced QA systems. We conduct multi-dimensional human\nevaluation and quantitative ablation studies, which suggest the outperformance\nof the proposed WebGLM designs over existing systems. WebGLM with the\n10-billion-parameter GLM (10B) is shown to perform better than the\nsimilar-sized WebGPT (13B) and even comparably to WebGPT (175B) in human\nevaluation. The code, demo, and data are at\n\\url{https://github.com/THUDM/WebGLM}.",
        "translated": "本文介绍了基于通用语言模型(GLM)的 Web 增强型问答系统 WebGLM。它的目标是增强一个预先训练的大型语言模型(LLM) ，该模型具有 Web 搜索和检索功能，同时对于现实世界的部署非常有效。为了实现这一点，我们使用 LLM 增强检索器、引导生成器和人类偏好感知记分器的策略来开发 WebGLM。具体来说，我们确定并解决了 WebGPT (OpenAI)的局限性，通过它，WebGLM 具有准确性、效率和成本效益方面的优势。此外，我们提出了评估网络增强 QA 系统的系统标准。我们进行了多维人体评估和定量消融研究，这表明所提出的 WebGLM 设计优于现有系统。具有100亿参数 GLM (10B)的 WebGLM 显示出比类似大小的 WebGPT (13B)更好的性能，甚至在人类评估中与 WebGPT (175B)相当。代码、演示和数据位于 url { https://github.com/thudm/webglm }。"
    },
    {
        "title": "Massively Multilingual Corpus of Sentiment Datasets and Multi-faceted\n  Sentiment Classification Benchmark",
        "url": "http://arxiv.org/abs/2306.07902v1",
        "pub_date": "2023-06-13",
        "summary": "Despite impressive advancements in multilingual corpora collection and model\ntraining, developing large-scale deployments of multilingual models still\npresents a significant challenge. This is particularly true for language tasks\nthat are culture-dependent. One such example is the area of multilingual\nsentiment analysis, where affective markers can be subtle and deeply ensconced\nin culture. This work presents the most extensive open massively multilingual\ncorpus of datasets for training sentiment models. The corpus consists of 79\nmanually selected datasets from over 350 datasets reported in the scientific\nliterature based on strict quality criteria. The corpus covers 27 languages\nrepresenting 6 language families. Datasets can be queried using several\nlinguistic and functional features. In addition, we present a multi-faceted\nsentiment classification benchmark summarizing hundreds of experiments\nconducted on different base models, training objectives, dataset collections,\nand fine-tuning strategies.",
        "translated": "尽管在多语言语料库收集和模型培训方面取得了令人印象深刻的进展，但开发大规模部署多语言模型仍然是一个重大挑战。对于依赖于文化的语言任务尤其如此。一个这样的例子是多语言情感分析领域，其中情感标记可以是微妙的，深深地隐藏在文化。这项工作提出了最广泛的开放大规模多语言数据集训练情感模型。该语料库包括79个手动选择的数据集，从超过350个数据集报告的科学文献基于严格的质量标准。语料库包括代表6个语系的27种语言。可以使用几种语言和函数特性查询数据集。此外，我们提出了一个多方面的情绪分类基准，总结了数百个实验进行了不同的基础模型，训练目标，数据集收集和微调策略。"
    },
    {
        "title": "Artificial Artificial Artificial Intelligence: Crowd Workers Widely Use\n  Large Language Models for Text Production Tasks",
        "url": "http://arxiv.org/abs/2306.07899v1",
        "pub_date": "2023-06-13",
        "summary": "Large language models (LLMs) are remarkable data annotators. They can be used\nto generate high-fidelity supervised training data, as well as survey and\nexperimental data. With the widespread adoption of LLMs, human gold--standard\nannotations are key to understanding the capabilities of LLMs and the validity\nof their results. However, crowdsourcing, an important, inexpensive way to\nobtain human annotations, may itself be impacted by LLMs, as crowd workers have\nfinancial incentives to use LLMs to increase their productivity and income. To\ninvestigate this concern, we conducted a case study on the prevalence of LLM\nusage by crowd workers. We reran an abstract summarization task from the\nliterature on Amazon Mechanical Turk and, through a combination of keystroke\ndetection and synthetic text classification, estimate that 33-46% of crowd\nworkers used LLMs when completing the task. Although generalization to other,\nless LLM-friendly tasks is unclear, our results call for platforms,\nresearchers, and crowd workers to find new ways to ensure that human data\nremain human, perhaps using the methodology proposed here as a stepping stone.\nCode/data: https://github.com/epfl-dlab/GPTurk",
        "translated": "大型语言模型(LLM)是非常出色的数据注释器。它们可以用来生成高保真的监督训练数据，以及调查和实验数据。随着 LLM 的广泛采用，人工黄金标准注释是理解 LLM 功能及其结果有效性的关键。然而，众包作为一种获取人工注释的重要而廉价的方式，可能本身就会受到 LLM 的影响，因为众包工作者有财务动机使用 LLM 来提高他们的生产力和收入。为了调查这一问题，我们进行了一个案例研究的普遍使用 LLM 的人群工作者。我们从亚马逊土耳其机器人的文献中重新运行了一个抽象的总结任务，并且通过组合击键检测和合成文本分类，估计33-46% 的人群工作者在完成任务时使用 LLM。尽管对其他不太适合 LLM 的任务的概括还不清楚，但我们的研究结果呼吁平台、研究人员和群体工作者找到新的方法来确保人类数据仍然是人类的，或许可以使用这里提出的方法作为垫脚石。代码/资料:  https://github.com/epfl-dlab/gpturk"
    },
    {
        "title": "GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio\n  Pretraining for Speech Emotion Recognition",
        "url": "http://arxiv.org/abs/2306.07848v1",
        "pub_date": "2023-06-13",
        "summary": "Contrastive Language-Audio Pretraining (CLAP) has recently exhibited\nimpressive success in diverse fields. In this paper, we propose GEmo-CLAP, a\nkind of efficient gender-attribute-enhanced CLAP model for speech emotion\nrecognition (SER). Specifically, we first build an effective emotion CLAP model\ntermed Emo-CLAP for SER, utilizing various self-supervised learning based\npre-trained models. Then, considering the importance of the gender attribute in\nspeech emotion modeling, two GEmo-CLAP approaches are further proposed to\nintegrate the emotion and gender information of speech signals, forming more\nreasonable objectives. Extensive experiments conducted on the IEMOCAP corpus\ndemonstrate that our proposed two GEmo-CLAP approaches consistently outperform\nthe baseline Emo-CLAP with different pre-trained models, while also achieving\nsuperior recognition performance compared with other state-of-the-art methods.",
        "translated": "对比语言-音频预训练(CLAP)最近在多个领域取得了令人瞩目的成功。本文提出了一种基于性别属性增强的语音情感识别模型 GEmo-CLAP。具体来说，我们首先利用各种基于预训练的自监督学习模型，建立了一个有效的情绪 CLAP 模型，称为情绪 CLAP 模型。然后，考虑到性别属性在语音情感建模中的重要性，进一步提出了两种 Gemo-CLAP 方法来整合语音信号的情感和性别信息，形成更加合理的目标。在 IEMOCAP 语料库上进行的大量实验表明，我们提出的两种 Gemo-CLAP 方法始终优于不同预训练模型的基线 Emo-CLAP，同时与其他最先进的方法相比，也获得了更好的识别性能。"
    },
    {
        "title": "Adversarial Capsule Networks for Romanian Satire Detection and Sentiment\n  Analysis",
        "url": "http://arxiv.org/abs/2306.07845v1",
        "pub_date": "2023-06-13",
        "summary": "Satire detection and sentiment analysis are intensively explored natural\nlanguage processing (NLP) tasks that study the identification of the satirical\ntone from texts and extracting sentiments in relationship with their targets.\nIn languages with fewer research resources, an alternative is to produce\nartificial examples based on character-level adversarial processes to overcome\ndataset size limitations. Such samples are proven to act as a regularization\nmethod, thus improving the robustness of models. In this work, we improve the\nwell-known NLP models (i.e., Convolutional Neural Networks, Long Short-Term\nMemory (LSTM), Bidirectional LSTM, Gated Recurrent Units (GRUs), and\nBidirectional GRUs) with adversarial training and capsule networks. The\nfine-tuned models are used for satire detection and sentiment analysis tasks in\nthe Romanian language. The proposed framework outperforms the existing methods\nfor the two tasks, achieving up to 99.08% accuracy, thus confirming the\nimprovements added by the capsule layers and the adversarial training in NLP\napproaches.",
        "translated": "讽刺检测和情感分析是自然语言处理(NLP)研究的重要课题，主要研究从文本中识别讽刺语气并提取与目标相关的情感。在研究资源较少的语言中，另一种方法是基于字符级对抗过程生成人工示例，以克服数据集大小的限制。这些样本被证明是一种正则化方法，从而提高了模型的鲁棒性。在这项工作中，我们改进了著名的 NLP 模型(即，卷积神经网络，长短期记忆(LSTM) ，双向 LSTM，门控回归单元(GRU) ，和双向 GRU)与对抗训练和胶囊网络。这些经过微调的模型被用于罗马尼亚语中的讽刺探测和情感分析任务。该框架比现有的方法更好地完成了这两个任务，达到了99.08% 的准确率，从而证实了胶囊层的改进和 NLP 方法中的对抗性训练。"
    },
    {
        "title": "Web of Things and Trends in Agriculture: A Systematic Literature Review",
        "url": "http://arxiv.org/abs/2306.09079v1",
        "pub_date": "2023-06-15",
        "summary": "In the past few years, the Web of Things (WOT) became a beneficial\ngame-changing technology within the Agriculture domain as it introduces\ninnovative and promising solutions to the Internet of Things (IoT) agricultural\napplications problems by providing its services. WOT provides the support for\nintegration, interoperability for heterogeneous devices, infrastructures,\nplatforms, and the emergence of various other technologies. The main aim of\nthis study is about understanding and providing a growing and existing research\ncontent, issues, and directions for the future regarding WOT-based agriculture.\nTherefore, a systematic literature review (SLR) of research articles is\npresented by categorizing the selected studies published between 2010 and 2020\ninto the following categories: research type, approaches, and their application\ndomains. Apart from reviewing the state-of-the-art articles on WOT solutions\nfor the agriculture field, a taxonomy of WOT-base agriculture application\ndomains has also been presented in this study. A model has also presented to\nshow the picture of WOT based Smart Agriculture. Lastly, the findings of this\nSLR and the research gaps in terms of open issues have been presented to\nprovide suggestions on possible future directions for the researchers for\nfuture research.",
        "translated": "在过去的几年里，物联网(WOT)在农业领域成为了一个有益的改变游戏规则的技术，因为它通过提供服务引入了创新的和有前途的解决物联网(IoT)农业应用问题的方案。WOT 为异构设备、基础设施、平台以及其他各种技术的出现提供了集成、互操作性的支持。这项研究的主要目的是了解和提供一个不断增长和现有的研究内容，问题和未来的方向，关于基于 WOT 的农业。因此，通过将2010年至2020年间发表的选定研究分为以下几类: 研究类型，方法及其应用领域，对研究文章进行了系统的文献回顾(SLR)。除了回顾有关农业领域 WOT 解决方案的最新文章外，本研究还提出了基于 WOT 的农业应用领域的分类。本文还提出了一个模型来展示基于 WOT 的智能农业的图景。最后，本文介绍了本次研究的结果以及在公开课题方面的研究差距，为研究人员今后的研究提供了可能的方向建议。"
    },
    {
        "title": "Fast and Examination-agnostic Reciprocal Recommendation in Matching\n  Markets",
        "url": "http://arxiv.org/abs/2306.09060v1",
        "pub_date": "2023-06-15",
        "summary": "In matching markets such as job posting and online dating platforms, the\nrecommender system plays a critical role in the success of the platform. Unlike\nstandard recommender systems that suggest items to users, reciprocal\nrecommender systems (RRSs) that suggest other users must take into account the\nmutual interests of users. In addition, ensuring that recommendation\nopportunities do not disproportionately favor popular users is essential for\nthe total number of matches and for fairness among users. Existing\nrecommendation methods in matching markets, however, face computational\nchallenges on large-scale platforms and depend on specific examination\nfunctions in the position-based model (PBM). In this paper, we introduce the\nreciprocal recommendation method based on the matching with transferable\nutility (TU matching) model in the context of ranking recommendations in\nmatching markets and propose a fast and examination-model-free algorithm.\nFurthermore, we evaluate our approach on experiments with synthetic data and\nreal-world data from an online dating platform in Japan. Our method performs\nbetter than or as well as existing methods in terms of the total number of\nmatches and works well even in a large-scale dataset for which one existing\nmethod does not work.",
        "translated": "在招聘和在线约会平台等匹配市场方面，推荐系统对平台的成功起着关键作用。不像标准的推荐系统，建议项目给用户，互惠推荐系统(RRS) ，建议其他用户必须考虑到用户的共同利益。此外，确保推荐机会不会不成比例地偏向受欢迎的用户，对于匹配的总数和用户之间的公平性至关重要。然而，现有的匹配市场推荐方法在大规模平台上面临计算挑战，并且依赖于基于位置模型(PBM)中的特定检验函数。本文在匹配市场推荐排序的背景下，介绍了基于匹配可转移效用(TU 匹配)模型的互惠推荐方法，并提出了一种快速、无检验模型的算法。此外，我们评估了我们的实验方法与合成数据和真实世界的数据从一个在线约会平台在日本。就匹配总数而言，我们的方法比现有方法执行得更好，甚至在一个现有方法无法工作的大规模数据集中也能很好地工作。"
    },
    {
        "title": "Mapping Researcher Activity based on Publication Data by means of\n  Transformers",
        "url": "http://arxiv.org/abs/2306.09049v1",
        "pub_date": "2023-06-15",
        "summary": "Modern performance on several natural language processing (NLP) tasks has\nbeen enhanced thanks to the Transformer-based pre-trained language model BERT.\nWe employ this concept to investigate a local publication database. Research\npapers are encoded and clustered to form a landscape view of the scientific\ntopics, in which research is active. Authors working on similar topics can be\nidentified by calculating the similarity between their papers. Based on this,\nwe define a similarity metric between authors. Additionally we introduce the\nconcept of self-similarity to indicate the topical variety of authors.",
        "translated": "现代自然语言处理(NLP)任务的性能得到了提高，这要归功于基于变压器的预训练语言模型 BERT。我们使用这个概念来调查一个本地出版物数据库。研究论文的编码和聚类形成了一个景观的科学主题，其中研究是活跃的。研究类似主题的作者可以通过计算他们论文之间的相似性来识别。在此基础上，我们定义了作者之间的相似度量。此外，我们还引入了自相似的概念，以表明作者的主题多样性。"
    },
    {
        "title": "RecFusion: A Binomial Diffusion Process for 1D Data for Recommendation",
        "url": "http://arxiv.org/abs/2306.08947v1",
        "pub_date": "2023-06-15",
        "summary": "In this paper we propose RecFusion, which comprise a set of diffusion models\nfor recommendation. Unlike image data which contain spatial correlations, a\nuser-item interaction matrix, commonly utilized in recommendation, lacks\nspatial relationships between users and items. We formulate diffusion on a 1D\nvector and propose binomial diffusion, which explicitly models binary user-item\ninteractions with a Bernoulli process. We show that RecFusion approaches the\nperformance of complex VAE baselines on the core recommendation setting (top-n\nrecommendation for binary non-sequential feedback) and the most common datasets\n(MovieLens and Netflix). Our proposed diffusion models that are specialized for\n1D and/or binary setups have implications beyond recommendation systems, such\nas in the medical domain with MRI and CT scans.",
        "translated": "在本文中，我们提出了 RecFusion，它包含了一组用于推荐的扩散模型。与包含空间相关性的图像数据不同，通常用于推荐的用户-项目交互矩阵缺乏用户和项目之间的空间关系。我们在一维向量上描述扩散，并提出二项式扩散，它明确地模拟与伯努利过程的二进制用户-项目交互。我们表明 RecFusion 在核心推荐设置(二进制非顺序反馈的前 n 推荐)和最常见的数据集(MovieLens 和 Netflix)上接近复杂 VAE 基线的性能。我们提出的扩散模型是专门为一维和/或二进制设置的影响超出推荐系统，如在医学领域的 MRI 和 CT 扫描。"
    },
    {
        "title": "Document Entity Retrieval with Massive and Noisy Pre-training",
        "url": "http://arxiv.org/abs/2306.08937v1",
        "pub_date": "2023-06-15",
        "summary": "Visually-Rich Document Entity Retrieval (VDER) is a type of machine learning\ntask that aims at recovering text spans in the documents for each of the\nentities in question. VDER has gained significant attention in recent years\nthanks to its broad applications in enterprise AI. Unfortunately, as document\nimages often contain personally identifiable information (PII), publicly\navailable data have been scarce, not only because of privacy constraints but\nalso the costs of acquiring annotations. To make things worse, each dataset\nwould often define its own sets of entities, and the non-overlapping entity\nspaces between datasets make it difficult to transfer knowledge between\ndocuments. In this paper, we propose a method to collect massive-scale, noisy,\nand weakly labeled data from the web to benefit the training of VDER models.\nSuch a method will generate a huge amount of document image data to compensate\nfor the lack of training data in many VDER settings. Moreover, the collected\ndataset named DocuNet would not need to be dependent on specific document types\nor entity sets, making it universally applicable to all VDER tasks. Empowered\nby DocuNet, we present a lightweight multimodal architecture named UniFormer,\nwhich can learn a unified representation from text, layout, and image crops\nwithout needing extra visual pertaining. We experiment with our methods on\npopular VDER models in various settings and show the improvements when this\nmassive dataset is incorporated with UniFormer on both classic entity retrieval\nand few-shot learning settings.",
        "translated": "可视化丰富文档实体检索(VDER)是一种机器学习任务，旨在恢复文档中涉及到的每个实体的文本跨度。VDER 由于在企业人工智能中的广泛应用，近年来受到了广泛的关注。遗憾的是，由于文档图像通常包含个人身份信息(pII) ，公开可用的数据很少，这不仅是因为隐私限制，还因为获取注释的成本。更糟糕的是，每个数据集通常会定义自己的实体集，而数据集之间不重叠的实体空间使得在文档之间传递知识变得非常困难。本文提出了一种从网络上收集大规模、有噪声和弱标记数据的方法，有利于 VDER 模型的训练。这种方法将产生大量的文档图像数据，以弥补许多 VDER 设置中训练数据的不足。此外，名为 DocuNet 的收集的数据集不需要依赖于特定的文档类型或实体集，这使得它普遍适用于所有 VDER 任务。在 DocuNet 的支持下，我们提出了一个轻量级的多模态体系结构，名为 UniForm，它可以从文本、布局和图像作物中学习统一的表示，而不需要额外的视觉修饰。我们在不同的设置下对流行的 VDER 模型进行了实验，结果表明，在经典的实体检索和少镜头学习设置下，将这个海量数据集与 UniForm 结合起来，可以得到改进。"
    },
    {
        "title": "SIGHT: A Large Annotated Dataset on Student Insights Gathered from\n  Higher Education Transcripts",
        "url": "http://arxiv.org/abs/2306.09343v1",
        "pub_date": "2023-06-15",
        "summary": "Lectures are a learning experience for both students and teachers. Students\nlearn from teachers about the subject material, while teachers learn from\nstudents about how to refine their instruction. However, online student\nfeedback is unstructured and abundant, making it challenging for teachers to\nlearn and improve. We take a step towards tackling this challenge. First, we\ncontribute a dataset for studying this problem: SIGHT is a large dataset of 288\nmath lecture transcripts and 15,784 comments collected from the Massachusetts\nInstitute of Technology OpenCourseWare (MIT OCW) YouTube channel. Second, we\ndevelop a rubric for categorizing feedback types using qualitative analysis.\nQualitative analysis methods are powerful in uncovering domain-specific\ninsights, however they are costly to apply to large data sources. To overcome\nthis challenge, we propose a set of best practices for using large language\nmodels (LLMs) to cheaply classify the comments at scale. We observe a striking\ncorrelation between the model's and humans' annotation: Categories with\nconsistent human annotations (&gt;$0.9$ inter-rater reliability, IRR) also display\nhigher human-model agreement (&gt;$0.7$), while categories with less consistent\nhuman annotations ($0.7$-$0.8$ IRR) correspondingly demonstrate lower\nhuman-model agreement ($0.3$-$0.5$). These techniques uncover useful student\nfeedback from thousands of comments, costing around $\\$0.002$ per comment. We\nconclude by discussing exciting future directions on using online student\nfeedback and improving automated annotation techniques for qualitative\nresearch.",
        "translated": "讲座对学生和老师来说都是一次学习的经历。学生向老师学习课程材料，而老师向学生学习如何改进教学。然而，在线学生的反馈是非结构化的和丰富的，这使得教师学习和提高具有挑战性。我们朝着应对这一挑战迈出了一步。首先，我们贡献了一个数据集来研究这个问题: SIGHT 是一个大型数据集，包括288份数学课堂讲稿和15,784条评论，这些评论来自麻省理工学院开放课程软件(MIT OCW) YouTube 频道。其次，我们开发了一个使用定性分析对反馈类型进行分类的标准。定性分析方法在揭示特定领域的见解方面非常强大，但是它们应用于大型数据源的成本很高。为了克服这一挑战，我们提出了一套使用大型语言模型(LLM)以低成本对注释进行大规模分类的最佳实践。我们观察到模型注释和人类注释之间存在显著的相关性: 具有一致的人类注释的类别(> 0.9 $评分者间可靠性，IRR)也显示出较高的人类模型一致性(> 0.7 $) ，而具有不一致的人类注释的类别($0.7 $- $0.8 $IRR)相应地显示出较低的人类模型一致性($0.3 $- $0.5 $)。这些技术可以从成千上万条评论中发现有用的学生反馈，每条评论的成本约为0.002美元。最后，我们讨论了使用在线学生反馈和改进质性研究自动注释技术的令人兴奋的未来发展方向。"
    },
    {
        "title": "PaReprop: Fast Parallelized Reversible Backpropagation",
        "url": "http://arxiv.org/abs/2306.09342v1",
        "pub_date": "2023-06-15",
        "summary": "The growing size of datasets and deep learning models has made faster and\nmemory-efficient training crucial. Reversible transformers have recently been\nintroduced as an exciting new method for extremely memory-efficient training,\nbut they come with an additional computation overhead of activation\nre-computation in the backpropagation phase. We present PaReprop, a fast\nParallelized Reversible Backpropagation algorithm that parallelizes the\nadditional activation re-computation overhead in reversible training with the\ngradient computation itself in backpropagation phase. We demonstrate the\neffectiveness of the proposed PaReprop algorithm through extensive benchmarking\nacross model families (ViT, MViT, Swin and RoBERTa), data modalities (Vision &amp;\nNLP), model sizes (from small to giant), and training batch sizes. Our\nempirical results show that PaReprop achieves up to 20% higher training\nthroughput than vanilla reversible training, largely mitigating the theoretical\noverhead of 25% lower throughput from activation recomputation in reversible\ntraining. Project page: https://tylerzhu.com/pareprop.",
        "translated": "不断增长的数据集和深度学习模型使得更快、更有效的训练变得至关重要。可逆变压器作为一种新兴的高效存储器训练方法，近年来得到了广泛的应用，但是在反向传播阶段，这种方法需要增加激活重计算的计算开销。本文提出了一种快速并行化可逆反向传播算法，它将可逆训练中的附加激活重计算开销与反向传播阶段的梯度计算本身并行化。我们通过跨模型家族(ViT，MViT，Swin 和 RoBERTa) ，数据模式(Vision & NLP) ，模型大小(从小到大)和训练批量大小的广泛基准测试来证明所提出的 PaReprop 算法的有效性。我们的实验结果表明，PaReprop 比普通可逆训练提高了20% 的训练吞吐量，大大降低了可逆训练中激活重计算吞吐量降低25% 的理论开销。项目主页:  https://tylerzhu.com/pareprop。"
    },
    {
        "title": "Span-Selective Linear Attention Transformers for Effective and Robust\n  Schema-Guided Dialogue State Tracking",
        "url": "http://arxiv.org/abs/2306.09340v1",
        "pub_date": "2023-06-15",
        "summary": "In schema-guided dialogue state tracking models estimate the current state of\na conversation using natural language descriptions of the service schema for\ngeneralization to unseen services. Prior generative approaches which decode\nslot values sequentially do not generalize well to variations in schema, while\ndiscriminative approaches separately encode history and schema and fail to\naccount for inter-slot and intent-slot dependencies. We introduce SPLAT, a\nnovel architecture which achieves better generalization and efficiency than\nprior approaches by constraining outputs to a limited prediction space. At the\nsame time, our model allows for rich attention among descriptions and history\nwhile keeping computation costs constrained by incorporating linear-time\nattention. We demonstrate the effectiveness of our model on the Schema-Guided\nDialogue (SGD) and MultiWOZ datasets. Our approach significantly improves upon\nexisting models achieving 85.3 JGA on the SGD dataset. Further, we show\nincreased robustness on the SGD-X benchmark: our model outperforms the more\nthan 30$\\times$ larger D3ST-XXL model by 5.0 points.",
        "translated": "在模式引导的对话中，状态跟踪模型使用服务模式的自然语言描述来估计会话的当前状态，以便将其泛化为看不见的服务。先前解码槽值的生成方法不能很好地推广到模式中的变化，而区分方法分别编码历史和模式，不能解释槽间和意向槽依赖关系。我们介绍了 SPLAT，这是一种新的体系结构，它通过将输出限制在有限的预测空间内，实现了比以前的方法更好的泛化和效率。同时，我们的模型允许在描述和历史之间有丰富的注意力，同时通过合并线性时间注意力来保持计算成本的约束。我们在模式引导对话(SGD)和 MultiWOZ 数据集上演示了我们的模型的有效性。我们的方法显著改进了在 SGD 数据集上实现85.3 JGA 的现有模型。此外，我们在 SGD-X 基准上显示出更强的鲁棒性: 我们的模型比价格超过30美元的大型 D3ST-XXL 模型高出5.0个百分点。"
    },
    {
        "title": "WizMap: Scalable Interactive Visualization for Exploring Large Machine\n  Learning Embeddings",
        "url": "http://arxiv.org/abs/2306.09328v1",
        "pub_date": "2023-06-15",
        "summary": "Machine learning models often learn latent embedding representations that\ncapture the domain semantics of their training data. These embedding\nrepresentations are valuable for interpreting trained models, building new\nmodels, and analyzing new datasets. However, interpreting and using embeddings\ncan be challenging due to their opaqueness, high dimensionality, and the large\nsize of modern datasets. To tackle these challenges, we present WizMap, an\ninteractive visualization tool to help researchers and practitioners easily\nexplore large embeddings. With a novel multi-resolution embedding summarization\nmethod and a familiar map-like interaction design, WizMap enables users to\nnavigate and interpret embedding spaces with ease. Leveraging modern web\ntechnologies such as WebGL and Web Workers, WizMap scales to millions of\nembedding points directly in users' web browsers and computational notebooks\nwithout the need for dedicated backend servers. WizMap is open-source and\navailable at the following public demo link: https://poloclub.github.io/wizmap.",
        "translated": "机器学习模型经常学习潜在的嵌入表示，捕获其训练数据的领域语义。这些嵌入式表示对于解释训练过的模型、建立新模型和分析新数据集是有价值的。然而，由于嵌入的不透明性、高维数和现代数据集的巨大规模，解释和使用嵌入可能是具有挑战性的。为了应对这些挑战，我们展示了 WizMap，这是一个交互式可视化工具，可以帮助研究人员和从业者轻松地探索大型嵌入。WizMap 提供了一种新颖的多分辨率嵌入摘要方法和一种常见的类似地图的交互设计，使用户可以轻松地导航和解释嵌入空间。利用 WebGL 和 Web Workers 等现代 Web 技术，WizMap 可以直接在用户的 Web 浏览器和计算笔记本中嵌入数百万个点，而不需要专用的后端服务器。WizMap 是开源的，可在以下公共演示链接下载:  https://poloclub.github.io/WizMap。"
    },
    {
        "title": "Lexical Speaker Error Correction: Leveraging Language Models for Speaker\n  Diarization Error Correction",
        "url": "http://arxiv.org/abs/2306.09313v1",
        "pub_date": "2023-06-15",
        "summary": "Speaker diarization (SD) is typically used with an automatic speech\nrecognition (ASR) system to ascribe speaker labels to recognized words. The\nconventional approach reconciles outputs from independently optimized ASR and\nSD systems, where the SD system typically uses only acoustic information to\nidentify the speakers in the audio stream. This approach can lead to speaker\nerrors especially around speaker turns and regions of speaker overlap. In this\npaper, we propose a novel second-pass speaker error correction system using\nlexical information, leveraging the power of modern language models (LMs). Our\nexperiments across multiple telephony datasets show that our approach is both\neffective and robust. Training and tuning only on the Fisher dataset, this\nerror correction approach leads to relative word-level diarization error rate\n(WDER) reductions of 15-30% on three telephony datasets: RT03-CTS, Callhome\nAmerican English and held-out portions of Fisher.",
        "translated": "说话人辨认(SD)通常与自动语音识别(ASR)系统一起使用，将说话人标签归属于已识别的单词。传统的方法协调独立优化的 ASR 和 SD 系统的输出，其中 SD 系统通常只使用声学信息来识别音频流中的扬声器。这种方法可能导致说话人误差，特别是在说话人转圈和说话人重叠区域周围。在本文中，我们利用现代语言模型(LMs)的能力，提出了一种新的利用词汇信息的二次说话人纠错系统。我们在多个电话数据集上的实验表明，我们的方法既有效又可靠。仅在 Fisher 数据集上进行训练和调整，这种错误纠正方法导致三个电话数据集: RT03-CTS，Callhome American English 和 Fisher 的保留部分的相对词级二值化错误率(WDER)降低15-30% 。"
    },
    {
        "title": "Semantic HELM: An Interpretable Memory for Reinforcement Learning",
        "url": "http://arxiv.org/abs/2306.09312v1",
        "pub_date": "2023-06-15",
        "summary": "Reinforcement learning agents deployed in the real world often have to cope\nwith partially observable environments. Therefore, most agents employ memory\nmechanisms to approximate the state of the environment. Recently, there have\nbeen impressive success stories in mastering partially observable environments,\nmostly in the realm of computer games like Dota 2, StarCraft II, or MineCraft.\nHowever, none of these methods are interpretable in the sense that it is not\ncomprehensible for humans how the agent decides which actions to take based on\nits inputs. Yet, human understanding is necessary in order to deploy such\nmethods in high-stake domains like autonomous driving or medical applications.\nWe propose a novel memory mechanism that operates on human language to\nilluminate the decision-making process. First, we use CLIP to associate visual\ninputs with language tokens. Then we feed these tokens to a pretrained language\nmodel that serves the agent as memory and provides it with a coherent and\ninterpretable representation of the past. Our memory mechanism achieves\nstate-of-the-art performance in environments where memorizing the past is\ncrucial to solve tasks. Further, we present situations where our memory\ncomponent excels or fails to demonstrate strengths and weaknesses of our new\napproach.",
        "translated": "部署在现实世界中的强化学习经常不得不应对部分可观测的环境。因此，大多数代理都使用内存机制来近似处理环境的状态。最近，在掌握部分可观察的环境方面有了令人印象深刻的成功故事，主要是在计算机游戏领域，如 Dota 2、 StarCraft II 或 MineCraft。然而，所有这些方法都无法解释，因为人类无法理解代理人如何根据其输入决定采取哪些行动。然而，人类的理解是必要的，为了部署这样的方法在高风险的领域，如自动驾驶或医疗应用程序。我们提出了一种新的记忆机制，运行在人类的语言，以说明决策过程。首先，我们使用 CLIP 将可视输入与语言标记关联起来。然后，我们将这些标记提供给一个预先训练好的语言模型，该模型为代理提供记忆，并为代理提供一个连贯的、可解释的过去表示。我们的记忆机制在记忆过去对解决任务至关重要的环境中取得了最先进的性能。此外，我们提出的情况下，我们的记忆组件优秀或未能证明我们的新方法的长处和弱点。"
    },
    {
        "title": "Matching Pairs: Attributing Fine-Tuned Models to their Pre-Trained Large\n  Language Models",
        "url": "http://arxiv.org/abs/2306.09308v1",
        "pub_date": "2023-06-15",
        "summary": "The wide applicability and adaptability of generative large language models\n(LLMs) has enabled their rapid adoption. While the pre-trained models can\nperform many tasks, such models are often fine-tuned to improve their\nperformance on various downstream applications. However, this leads to issues\nover violation of model licenses, model theft, and copyright infringement.\nMoreover, recent advances show that generative technology is capable of\nproducing harmful content which exacerbates the problems of accountability\nwithin model supply chains. Thus, we need a method to investigate how a model\nwas trained or a piece of text was generated and what their pre-trained base\nmodel was. In this paper we take the first step to address this open problem by\ntracing back the origin of a given fine-tuned LLM to its corresponding\npre-trained base model. We consider different knowledge levels and attribution\nstrategies, and find that we can correctly trace back 8 out of the 10 fine\ntuned models with our best method.",
        "translated": "生成式大型语言模型(LLM)的广泛适用性和适应性使它们得以迅速采用。虽然预先训练的模型可以执行许多任务，但这些模型通常经过微调，以提高它们在各种下游应用程序中的性能。然而，这导致了违反模型许可证、模型盗窃和盗版的问题。此外，最近的进展表明，生成技术能够产生有害的内容，这加剧了示范供应链中的问责问题。因此，我们需要一种方法来研究如何训练一个模型或一段文本生成，以及他们的预先训练的基础模型是什么。在本文中，我们采取的第一步，以解决这个开放的问题，追溯起源的一个给定的微调 LLM 相应的预训练的基础模型。我们考虑了不同的知识水平和归因策略，发现我们可以用我们最好的方法正确地追溯10个微调模型中的8个。"
    },
    {
        "title": "Quality and Efficiency of Manual Annotation: Pre-annotation Bias",
        "url": "http://arxiv.org/abs/2306.09307v1",
        "pub_date": "2023-06-15",
        "summary": "This paper presents an analysis of annotation using an automatic\npre-annotation for a mid-level annotation complexity task -- dependency syntax\nannotation. It compares the annotation efforts made by annotators using a\npre-annotated version (with a high-accuracy parser) and those made by fully\nmanual annotation. The aim of the experiment is to judge the final annotation\nquality when pre-annotation is used. In addition, it evaluates the effect of\nautomatic linguistically-based (rule-formulated) checks and another annotation\non the same data available to the annotators, and their influence on annotation\nquality and efficiency. The experiment confirmed that the pre-annotation is an\nefficient tool for faster manual syntactic annotation which increases the\nconsistency of the resulting annotation without reducing its quality.",
        "translated": "本文针对一个中级注释复杂性任务——依赖语法注释，提出了一种使用自动预注释的注释分析方法。它比较了使用预注释版本(带有高精度解析器)的注释者所做的注释工作和完全手动注释所做的注释工作。实验的目的是在使用预注释时判断最终的注释质量。此外，它还评估了基于语言的(规则制定的)自动检查和另一个注释对注释者可获得的相同数据的影响，以及它们对注释质量和效率的影响。实验结果表明，预注释是一种提高人工语法注释速度的有效工具，可以在不降低注释质量的前提下提高注释结果的一致性。"
    },
    {
        "title": "Propagating Knowledge Updates to LMs Through Distillation",
        "url": "http://arxiv.org/abs/2306.09306v1",
        "pub_date": "2023-06-15",
        "summary": "Modern language models have the capacity to store and use immense amounts of\nknowledge about real-world entities, but it remains unclear how to update their\nimplicit \"knowledge bases.'' While prior methods for updating knowledge in LMs\nsuccessfully inject facts, updated LMs then fail to make inferences based on\nthese injected facts. In this work, we demonstrate that a context\ndistillation-based approach can both impart knowledge about entities and\npropagate that knowledge to enable broader inferences. Our approach consists of\ntwo stages: transfer set generation and distillation on the transfer set. We\nfirst generate a transfer set by simply prompting a language model to generate\na continuation from the entity definition. Then, we update the model parameters\nso that the distribution of the LM (the student) matches the distribution of\nthe LM conditioned on the definition (the teacher) on the transfer set. Our\nexperiments demonstrate that this approach is more effective in propagating\nknowledge updates compared to fine-tuning and other gradient-based\nknowledge-editing methods without compromising performance in other contexts,\neven when injecting the definitions of up to 150 entities at once.",
        "translated": "现代语言模型有能力存储和使用关于现实世界实体的大量知识，但是如何更新它们隐含的“知识库”仍然不清楚先前更新 LM 知识的方法成功地注入了事实，但是更新后的 LM 无法根据这些注入的事实进行推断。在这项工作中，我们证明了一个基于上下文精馏的方法既可以传递关于实体的知识，又可以传播这些知识，以便能够进行更广泛的推论。我们的方法包括两个阶段: 转移集的产生和转移集上的精馏。我们首先通过简单地提示语言模型从实体定义生成延续来生成传输集。然后，我们更新模型参数，使 LM (学生)的分布与 LM 的分布匹配条件下的定义(教师)在转移集上。我们的实验表明，与微调和其他基于梯度的知识编辑方法相比，这种方法在传播知识更新方面更有效，而不会损害其他情况下的性能，即使一次注入多达150个实体的定义。"
    },
    {
        "title": "Can Language Models Teach Weaker Agents? Teacher Explanations Improve\n  Students via Theory of Mind",
        "url": "http://arxiv.org/abs/2306.09299v1",
        "pub_date": "2023-06-15",
        "summary": "Large Language Models (LLMs) perform complex reasoning by generating\nexplanations for their predictions. However, a complementary goal of\nexplanations is to also communicate useful knowledge that improves weaker\nagents. Hence, we investigate whether LLMs also make good teachers for weaker\nagents. In particular, we consider a student-teacher framework between two LLM\nagents and study if, when, and how the teacher should intervene with natural\nlanguage explanations to improve the student's performance. Since communication\nis expensive, we define a budget such that the teacher only communicates\nexplanations for a fraction of the data, after which the student should perform\nwell on its own. We decompose the teaching problem along four axes: (1) if\nteacher's test time intervention improve student predictions, (2) when it is\nworth explaining a data point, (3) how the teacher should personalize\nexplanations to better teach the student, and (4) if teacher explanations also\nimprove student performance on future unexplained data. We first show that\nteacher LLMs can indeed intervene on student reasoning to improve their\nperformance. Next, we propose a Theory of Mind approach, in which the teacher\nbuilds two few-shot mental models of the student. The first model defines an\nIntervention Function that simulates the utility of an intervention, allowing\nthe teacher to intervene when this utility is the highest and improving student\nperformance at lower budgets. The second model enables the teacher to\npersonalize explanations for a particular student and outperform unpersonalized\nteachers. We also demonstrate that in multi-turn interactions, teacher\nexplanations generalize and learning from explained data improves student\nperformance on future unexplained data. Finally, we also verify that misaligned\nteachers can lower student performance to random chance by intentionally\nmisleading them.",
        "translated": "大型语言模型(LLM)通过生成对其预测的解释来执行复杂的推理。然而，解释的一个补充目标是传达有用的知识，以改善较弱的代理。因此，我们研究 LLM 是否也可以成为弱者的好老师。特别地，我们考虑两个 LLM 代理之间的学生-教师框架，并研究教师是否、何时以及如何应该干预自然语言解释以提高学生的成绩。由于沟通是昂贵的，我们定义一个预算，使教师只传达一小部分数据的解释，在此之后，学生应该自己表现良好。我们将教学问题分解为四个方面: (1)教师的考试时间干预是否改善了学生的预测; (2)什么时候值得解释一个数据点; (3)教师应该如何个性化解释以更好地教育学生; (4)教师的解释是否也改善了学生对未来未解释数据的表现。我们首先证明教师 LLM 确实可以干预学生的推理，以提高他们的表现。接下来，我们提出一种心理理论的方法，在这种方法中，教师建立学生的两个短镜头心理模型。第一个模型定义了一个干预函数，它模拟了干预的效用，允许教师在效用最高时进行干预，并在较低的预算下提高学生的表现。第二种模式使教师能够针对特定学生进行个性化的解释，并胜过非个性化的教师。我们还证明，在多回合互动中，教师的解释概括和学习解释的数据提高了学生在未来的未解释数据的表现。最后，我们还验证了错位教师可以通过故意误导学生来降低学生的随机成绩。"
    },
    {
        "title": "GRM: Generative Relevance Modeling Using Relevance-Aware Sample\n  Estimation for Document Retrieval",
        "url": "http://arxiv.org/abs/2306.09938v1",
        "pub_date": "2023-06-16",
        "summary": "Recent studies show that Generative Relevance Feedback (GRF), using text\ngenerated by Large Language Models (LLMs), can enhance the effectiveness of\nquery expansion. However, LLMs can generate irrelevant information that harms\nretrieval effectiveness. To address this, we propose Generative Relevance\nModeling (GRM) that uses Relevance-Aware Sample Estimation (RASE) for more\naccurate weighting of expansion terms. Specifically, we identify similar real\ndocuments for each generated document and use a neural re-ranker to estimate\ntheir relevance. Experiments on three standard document ranking benchmarks show\nthat GRM improves MAP by 6-9% and R@1k by 2-4%, surpassing previous methods.",
        "translated": "最近的研究表明，使用大语言模型生成的文本的生成关联反馈可以提高查询扩展的有效性。然而，LLM 会产生不相关的信息，从而影响检索效率。为了解决这个问题，我们提出了生成相关性建模(GRM) ，它使用相关性感知的样本估计(RASE)来更准确地给扩展项加权。具体来说，我们为每个生成的文档识别相似的真实文档，并使用神经重新排序来估计它们的相关性。在三个标准文档排序基准上的实验表明，GRM 对 MAP 提高了6-9% ，对 R@1k 提高了2-4% ，超过了以往的排序方法。"
    },
    {
        "title": "Smart Sentiment Analysis-based Search Engine Classification Intelligence",
        "url": "http://arxiv.org/abs/2306.09777v1",
        "pub_date": "2023-06-16",
        "summary": "Search engines are widely used for finding information on the internet.\nHowever, there are limitations in the current search approach, such as\nproviding popular but not necessarily relevant results. This research addresses\nthe issue of polysemy in search results by implementing a search function that\ndetermines the sentimentality of the retrieved information. The study utilizes\na web crawler to collect data from the British Broadcasting Corporation (BBC)\nnews site, and the sentimentality of the news articles is determined using the\nSentistrength program. The results demonstrate that the proposed search\nfunction improves recall value while accurately retrieving nonpolysemous news.\nFurthermore, Sentistrength outperforms deep learning and clustering methods in\nclassifying search results. The methodology presented in this article can be\napplied to analyze the sentimentality and reputation of entities on the\ninternet.",
        "translated": "搜索引擎被广泛用于在互联网上查找信息。然而，目前的搜索方法存在一些局限性，比如提供受欢迎但不一定相关的结果。该研究通过实现一个决定检索信息多情性的搜索函数来解决搜索结果中的多义性问题。该研究利用网络爬虫从英国广播公司(英国广播公司)新闻网站收集数据，新闻文章的多愁善感程度是通过感知力程序确定的。实验结果表明，该搜索函数在准确检索非多义新闻的同时，提高了查全率。此外，感知强度在分类搜索结果方面优于深度学习和聚类方法。本文提出的方法可以用来分析互联网上实体的情感和声誉。"
    },
    {
        "title": "Online Distillation for Pseudo-Relevance Feedback",
        "url": "http://arxiv.org/abs/2306.09657v1",
        "pub_date": "2023-06-16",
        "summary": "Model distillation has emerged as a prominent technique to improve neural\nsearch models. To date, distillation taken an offline approach, wherein a new\nneural model is trained to predict relevance scores between arbitrary queries\nand documents. In this paper, we explore a departure from this offline\ndistillation strategy by investigating whether a model for a specific query can\nbe effectively distilled from neural re-ranking results (i.e., distilling in an\nonline setting). Indeed, we find that a lexical model distilled online can\nreasonably replicate the re-ranking of a neural model. More importantly, these\nmodels can be used as queries that execute efficiently on indexes. This second\nretrieval stage can enrich the pool of documents for re-ranking by identifying\ndocuments that were missed in the first retrieval stage. Empirically, we show\nthat this approach performs favourably when compared with established pseudo\nrelevance feedback techniques, dense retrieval methods, and sparse-dense\nensemble \"hybrid\" approaches.",
        "translated": "模型蒸馏技术已经成为改进神经搜索模型的一个突出技术。迄今为止，蒸馏采用离线方法，其中一个新的神经模型被训练来预测任意查询和文档之间的相关性得分。在本文中，我们通过研究一个特定查询的模型是否可以有效地从神经重新排序结果(即，在线设置中提取)中提取，来探索这种离线精馏策略的一个偏离。事实上，我们发现在线提取的词汇模型可以合理地复制神经模型的重新排序。更重要的是，这些模型可以用作在索引上高效执行的查询。这第二个检索阶段可以通过识别第一个检索阶段错过的文件来丰富重新排序的文件库。经验表明，与已有的伪关联反馈技术、密集检索方法和稀疏密集集合“混合”方法相比，这种方法表现得更好。"
    },
    {
        "title": "I Want This, Not That: Personalized Summarization of Scientific\n  Scholarly Texts",
        "url": "http://arxiv.org/abs/2306.09604v1",
        "pub_date": "2023-06-16",
        "summary": "In this paper, we present a proposal for an unsupervised algorithm, P-Summ,\nthat generates an extractive summary of scientific scholarly text to meet the\npersonal knowledge needs of the user. The method delves into the latent\nsemantic space of the document exposed by Weighted Non-negative Matrix\nFactorization, and scores sentences in consonance with the knowledge needs of\nthe user. The novelty of the algorithm lies in its ability to include desired\nknowledge and eliminate unwanted knowledge in the personal summary.\n  We also propose a multi-granular evaluation framework, which assesses the\nquality of generated personal summaries at three levels of granularity -\nsentence, terms and semantic. The framework uses system generated generic\nsummary instead of human generated summary as gold standard for evaluating the\nquality of personal summary generated by the algorithm. The effectiveness of\nthe algorithm at the semantic level is evaluated by taking into account the\nreference summary and the knowledge signals. We evaluate the performance of\nP-Summ algorithm over four data-sets consisting of scientific articles. Our\nempirical investigations reveal that the proposed method has the capability to\nmeet negative (or positive) knowledge preferences of the user.",
        "translated": "在本文中，我们提出了一个无监督算法，P-Summ，它生成一个提取摘要的科学学术文本，以满足用户的个人知识需求。该方法深入研究文档的潜在语义空间，通过加权非负矩阵分解，并根据用户的知识需求给句子打分。算法的新颖性在于它能够在个人摘要中包含所需的知识并消除不需要的知识。我们还提出了一个多粒度评估框架，该框架从句子、术语和语义三个粒度级别评估生成的个人摘要的质量。该框架采用系统生成的通用摘要代替人工生成的摘要作为评价算法生成的个人摘要质量的黄金标准。通过参考文献总结和知识信号，从语义层面对算法的有效性进行了评价。我们评估了 P-Summ 算法在四个由科学论文组成的数据集上的性能。实证研究表明，该方法能够满足用户的消极(或积极)知识偏好。"
    },
    {
        "title": "Just One Byte (per gradient): A Note on Low-Bandwidth Decentralized\n  Language Model Finetuning Using Shared Randomness",
        "url": "http://arxiv.org/abs/2306.10015v1",
        "pub_date": "2023-06-16",
        "summary": "Language model training in distributed settings is limited by the\ncommunication cost of gradient exchanges. In this short note, we extend recent\nwork from Malladi et al. (2023), using shared randomness to perform distributed\nfine-tuning with low bandwidth. The method is a natural decentralized extension\nof memory-efficient Simultaneous Perturbation Stochastic Approximation (SPSA).\nEach iteration, each machine seeds a Random Number Generator (RNG) to perform\nlocal reproducible perturbations on model weights and calculate and exchange\nscalar projected gradients, which are then used to update each model. By using\na (machine, sample) identifier as the random seed, each model can regenerate\none another's perturbations. As machines only exchange single-byte projected\ngradients, this is highly communication efficient. There are also potential\nprivacy benefits, as projected gradients may be calculated on different\ntraining data, and models never access the other's data. Our approach not only\ndrastically reduces communication bandwidth requirements but also accommodates\ndynamic addition or removal of machines during the training process and retains\nthe memory-efficient and inference-only advantages of recent work. We perform\nproof-of-concept experiments to demonstrate the potential usefulness of this\nmethod, building off of rich literature on distributed optimization and\nmemory-efficient training.",
        "translated": "分布式环境下的语言模型训练受到梯度交换通信成本的限制。在这个简短的说明中，我们扩展了 Malladi 等人(2023)最近的工作，使用共享随机性来执行低带宽的分布式微调。这种方法是记忆效率同步扰动随机逼近(SPSA)的自然分散扩展。每次迭代，每台机器播种一个随机数生成器(RNG) ，对模型权重执行局部可重复的扰动，并计算和交换标量投影梯度，然后用于更新每个模型。通过使用一个(机器，样本)标识符作为随机种子，每个模型可以重新生成彼此的扰动。由于机器只交换单字节投影渐变，这是高通信效率。还有潜在的隐私好处，因为预测的梯度可以在不同的训练数据上计算，而且模型永远不会访问其他人的数据。我们的方法不仅大大降低了通信带宽的要求，而且还可以在训练过程中动态添加或删除机器，并保留了最近工作的内存效率和推理优势。我们进行了概念验证实验，以证明这种方法的潜在有用性，建立在丰富的文献关于分布式优化和记忆效率培训。"
    },
    {
        "title": "MagicBrush: A Manually Annotated Dataset for Instruction-Guided Image\n  Editing",
        "url": "http://arxiv.org/abs/2306.10012v1",
        "pub_date": "2023-06-16",
        "summary": "Text-guided image editing is widely needed in daily life, ranging from\npersonal use to professional applications such as Photoshop. However, existing\nmethods are either zero-shot or trained on an automatically synthesized\ndataset, which contains a high volume of noise. Thus, they still require lots\nof manual tuning to produce desirable outcomes in practice. To address this\nissue, we introduce MagicBrush (https://osu-nlp-group.github.io/MagicBrush/),\nthe first large-scale, manually annotated dataset for instruction-guided real\nimage editing that covers diverse scenarios: single-turn, multi-turn,\nmask-provided, and mask-free editing. MagicBrush comprises over 10K manually\nannotated triples (source image, instruction, target image), which supports\ntrainining large-scale text-guided image editing models. We fine-tune\nInstructPix2Pix on MagicBrush and show that the new model can produce much\nbetter images according to human evaluation. We further conduct extensive\nexperiments to evaluate current image editing baselines from multiple\ndimensions including quantitative, qualitative, and human evaluations. The\nresults reveal the challenging nature of our dataset and the gap between\ncurrent baselines and real-world editing needs.",
        "translated": "从个人使用到 Photoshop 等专业应用，文本引导图像编辑在日常生活中被广泛需要。然而，现有的方法要么是零拍摄，要么是在一个自动合成的数据集上训练，这个数据集包含了大量的噪声。因此，它们仍然需要大量的手动调优，以便在实践中产生理想的结果。为了解决这个问题，我们引入了 MagicBrush ( https://osu-nlp-group.github.io/MagicBrush/) ，这是第一个用于指令引导的真实图像编辑的大规模手动注释数据集，涵盖了不同的场景: 单转、多转、掩码提供和无掩码编辑。MagicBrush 包含超过10K 的手动注释三元组(源图像、指令、目标图像) ，支持训练大规模的文本引导图像编辑模型。我们在 MagicBrush 上对 DirectPix2Pix 进行了微调，结果表明新的模型可以根据人的评价产生更好的图像。我们进一步进行广泛的实验，以评估目前的图像编辑基线从多个维度，包括定量，定性和人类的评价。结果揭示了我们的数据集的挑战性，以及当前基线和现实世界编辑需求之间的差距。"
    },
    {
        "title": "Investigating Prompting Techniques for Zero- and Few-Shot Visual\n  Question Answering",
        "url": "http://arxiv.org/abs/2306.09996v1",
        "pub_date": "2023-06-16",
        "summary": "Visual question answering (VQA) is a challenging task that requires the\nability to comprehend and reason with visual information. While recent\nvision-language models have made strides, they continue to struggle with\nzero-shot VQA, particularly in handling complex compositional questions and\nadapting to new domains i.e. knowledge-based reasoning. This paper explores the\nuse of various prompting strategies, focusing on the BLIP2 model, to enhance\nzero-shot VQA performance. We conduct a comprehensive investigation across\nseveral VQA datasets, examining the effectiveness of different question\ntemplates, the role of few-shot exemplars, the impact of chain-of-thought (CoT)\nreasoning, and the benefits of incorporating image captions as additional\nvisual cues. Despite the varied outcomes, our findings demonstrate that\ncarefully designed question templates and the integration of additional visual\ncues, like image captions, can contribute to improved VQA performance,\nespecially when used in conjunction with few-shot examples. However, we also\nidentify a limitation in the use of chain-of-thought rationalization, which\nnegatively affects VQA accuracy. Our study thus provides critical insights into\nthe potential of prompting for improving zero-shot VQA performance.",
        "translated": "视觉问题回答是一项具有挑战性的任务，需要对视觉信息进行理解和推理。虽然最近的视觉语言模型已经取得了长足的进步，但是它们仍然在与零射击 VQA 作斗争，特别是在处理复杂的组合问题和适应新的领域，即基于知识的推理方面。本文探讨了各种激励策略的使用，重点是 BLIP2模型，以提高零拍 VQA 的性能。我们对几个 VQA 数据集进行了全面的调查，检查了不同问题模板的有效性，少拍范例的作用，思维链(CoT)推理的影响，以及将图像标题作为额外的视觉线索的好处。尽管结果各不相同，但我们的研究结果表明，精心设计的问题模板和整合额外的视觉线索，如图像标题，可以有助于改善 VQA 的性能，特别是当与少数镜头的例子一起使用时。然而，我们也发现了思维链合理化使用的局限性，这对 VQA 的准确性产生了负面影响。因此，我们的研究提供了关键的见解，促进提高零拍 VQA 性能的潜力。"
    },
    {
        "title": "ClinicalGPT: Large Language Models Finetuned with Diverse Medical Data\n  and Comprehensive Evaluation",
        "url": "http://arxiv.org/abs/2306.09968v1",
        "pub_date": "2023-06-16",
        "summary": "Large language models have exhibited exceptional performance on various\nNatural Language Processing (NLP) tasks, leveraging techniques such as the\npre-training, and instruction fine-tuning. Despite these advances, their\neffectiveness in medical applications is limited, due to challenges such as\nfactual inaccuracies, reasoning abilities, and lack grounding in real-world\nexperience. In this study, we present ClinicalGPT, a language model explicitly\ndesigned and optimized for clinical scenarios. By incorporating extensive and\ndiverse real-world data, such as medical records, domain-specific knowledge,\nand multi-round dialogue consultations in the training process, ClinicalGPT is\nbetter prepared to handle multiple clinical task. Furthermore, we introduce a\ncomprehensive evaluation framework that includes medical knowledge\nquestion-answering, medical exams, patient consultations, and diagnostic\nanalysis of medical records. Our results demonstrate that ClinicalGPT\nsignificantly outperforms other models in these tasks, highlighting the\neffectiveness of our approach in adapting large language models to the critical\ndomain of healthcare.",
        "translated": "大型语言模型在各种自然语言处理(NLP)任务中表现出了卓越的性能，利用了预训练和指令微调等技术。尽管取得了这些进展，但由于事实不准确、推理能力差以及缺乏现实世界经验的基础等挑战，它们在医学应用中的有效性是有限的。在这项研究中，我们提出了 ClinicalGPT，一个明确设计和优化的语言模型临床情景。通过在培训过程中结合广泛和多样的现实世界数据，如医疗记录，特定领域的知识和多轮对话咨询，ClinicalGPT 更好地准备处理多个临床任务。此外，我们介绍了一个全面的评估框架，包括医学知识问答，医疗检查，病人会诊，和病历诊断分析。我们的研究结果表明 ClinicalGPT 在这些任务中显著优于其他模型，突出了我们的方法在调整大型语言模型以适应医疗保健的关键领域方面的有效性。"
    },
    {
        "title": "Trained Transformers Learn Linear Models In-Context",
        "url": "http://arxiv.org/abs/2306.09927v1",
        "pub_date": "2023-06-16",
        "summary": "Attention-based neural networks such as transformers have demonstrated a\nremarkable ability to exhibit in-context learning (ICL): Given a short prompt\nsequence of tokens from an unseen task, they can formulate relevant per-token\nand next-token predictions without any parameter updates. By embedding a\nsequence of labeled training data and unlabeled test data as a prompt, this\nallows for transformers to behave like supervised learning algorithms. Indeed,\nrecent work has shown that when training transformer architectures over random\ninstances of linear regression problems, these models' predictions mimic those\nof ordinary least squares.\n  Towards understanding the mechanisms underlying this phenomenon, we\ninvestigate the dynamics of ICL in transformers with a single linear\nself-attention layer trained by gradient flow on linear regression tasks. We\nshow that despite non-convexity, gradient flow with a suitable random\ninitialization finds a global minimum of the objective function. At this global\nminimum, when given a test prompt of labeled examples from a new prediction\ntask, the transformer achieves prediction error competitive with the best\nlinear predictor over the test prompt distribution. We additionally\ncharacterize the robustness of the trained transformer to a variety of\ndistribution shifts and show that although a number of shifts are tolerated,\nshifts in the covariate distribution of the prompts are not. Motivated by this,\nwe consider a generalized ICL setting where the covariate distributions can\nvary across prompts. We show that although gradient flow succeeds at finding a\nglobal minimum in this setting, the trained transformer is still brittle under\nmild covariate shifts.",
        "translated": "基于注意力的神经网络，如变压器，已经证明了显着的能力，表现在上下文学习(ICL) : 给定一个短暂的令牌序列从一个看不见的任务，他们可以制定相关的每个令牌和下一个令牌预测没有任何参数更新。通过嵌入一系列已标记的训练数据和未标记的测试数据作为提示，这允许变压器像监督式学习算法一样运行。事实上，最近的工作已经表明，当训练变压器架构在随机情况下的线性回归问题，这些模型的预测模拟那些一般最小平方法。为了理解这种现象的机制，我们研究了变压器中的 ICL 的动力学，这种变压器具有一个单一的线性自我注意层，通过梯度流对线性回归任务进行训练。结果表明，尽管存在非凸性，但梯度流在适当的随机初始化条件下仍能找到目标函数的全局最小值。在这个全局最小值下，当从一个新的预测任务中给出一个标记样本的测试提示时，变压器在测试提示分布上达到与最佳线性预测器竞争的预测误差。另外，我们描述了训练后的变压器对各种分布移位的鲁棒性，并且表明，虽然许多移位是可以容忍的，但是提示符的协变量分布的移位是不可以容忍的。基于此，我们考虑一个广义的 ICL 设置，其中协变量分布可以随提示而变化。我们表明，虽然梯度流成功地找到一个全局最小在这种设置，训练变压器仍然脆弱的轻度协变量移动。"
    },
    {
        "title": "Learning to Summarize and Answer Questions about a Virtual Robot's Past\n  Actions",
        "url": "http://arxiv.org/abs/2306.09922v1",
        "pub_date": "2023-06-16",
        "summary": "When robots perform long action sequences, users will want to easily and\nreliably find out what they have done. We therefore demonstrate the task of\nlearning to summarize and answer questions about a robot agent's past actions\nusing natural language alone. A single system with a large language model at\nits core is trained to both summarize and answer questions about action\nsequences given ego-centric video frames of a virtual robot and a question\nprompt. To enable training of question answering, we develop a method to\nautomatically generate English-language questions and answers about objects,\nactions, and the temporal order in which actions occurred during episodes of\nrobot action in the virtual environment. Training one model to both summarize\nand answer questions enables zero-shot transfer of representations of objects\nlearned through question answering to improved action summarization. %\ninvolving objects not seen in training to summarize.",
        "translated": "当机器人执行长动作序列时，用户将希望轻松可靠地找出他们做了什么。因此，我们演示的任务，学习总结和回答有关机器人代理人的过去的行动使用自然语言单独的问题。通过训练一个以大语言模型为核心的单一系统，在给定虚拟机器人以自我为中心的视频框架和问题提示的情况下，总结和回答关于动作序列的问题。为了实现问题回答的训练，我们开发了一种自动生成英语问答的方法，这些问答包括对象、动作以及虚拟环境中机器人动作过程中动作发生的时间顺序。训练一个同时总结和回答问题的模型可以使通过问题回答学到的对象的表示零拍转移到改进的动作总结。涉及培训中未见到的对象的百分比。"
    },
    {
        "title": "No Strong Feelings One Way or Another: Re-operationalizing Neutrality in\n  Natural Language Inference",
        "url": "http://arxiv.org/abs/2306.09918v1",
        "pub_date": "2023-06-16",
        "summary": "Natural Language Inference (NLI) has been a cornerstone task in evaluating\nlanguage models' inferential reasoning capabilities. However, the standard\nthree-way classification scheme used in NLI has well-known shortcomings in\nevaluating models' ability to capture the nuances of natural human reasoning.\nIn this paper, we argue that the operationalization of the neutral label in\ncurrent NLI datasets has low validity, is interpreted inconsistently, and that\nat least one important sense of neutrality is often ignored. We uncover the\ndetrimental impact of these shortcomings, which in some cases leads to\nannotation datasets that actually decrease performance on downstream tasks. We\ncompare approaches of handling annotator disagreement and identify flaws in a\nrecent NLI dataset that designs an annotator study based on a problematic\noperationalization. Our findings highlight the need for a more refined\nevaluation framework for NLI, and we hope to spark further discussion and\naction in the NLP community.",
        "translated": "自然语言推理(NLI)是评价语言模型推理能力的基础性工作。然而，在自然语言学习中使用的标准三向分类方案在评估模型捕捉人类自然推理细微差别的能力方面有着众所周知的缺陷。在本文中，我们认为在现有的 NLI 数据集中，中性标签的操作主义效度低，解释不一致，并且至少有一个重要的中性意义经常被忽略。我们发现了这些缺陷的有害影响，在某些情况下，这导致注释数据集实际上降低了下游任务的性能。我们比较了处理注释者不一致的方法，并在最近的一个基于有问题的操作主义设计注释者研究的 NLI 数据集中发现了缺陷。我们的研究结果强调了对 NLI 进一步完善评估框架的必要性，我们希望在 NLP 社区中引发进一步的讨论和行动。"
    },
    {
        "title": "Demystifying GPT Self-Repair for Code Generation",
        "url": "http://arxiv.org/abs/2306.09896v1",
        "pub_date": "2023-06-16",
        "summary": "Large Language Models (LLMs) have shown remarkable aptitude in code\ngeneration but still struggle on challenging programming tasks. Self-repair --\nin which the model debugs and fixes mistakes in its own code -- has recently\nbecome a popular way to boost performance in these settings. However, only very\nlimited studies on how and when self-repair works effectively exist in the\nliterature, and one might wonder to what extent a model is really capable of\nproviding accurate feedback on why the code is wrong when that code was\ngenerated by the same model. In this paper, we analyze GPT-3.5 and GPT-4's\nability to perform self-repair on APPS, a challenging dataset consisting of\ndiverse coding challenges. To do so, we first establish a new evaluation\nstrategy dubbed pass@t that measures the pass rate of the tasks against the\ntotal number of tokens sampled from the model, enabling a fair comparison to\npurely sampling-based approaches. With this evaluation strategy, we find that\nthe effectiveness of self-repair is only seen in GPT-4. We also observe that\nself-repair is bottlenecked by the feedback stage; using GPT-4 to give feedback\non the programs generated by GPT-3.5 and using expert human programmers to give\nfeedback on the programs generated by GPT-4, we unlock significant performance\ngains.",
        "translated": "大型语言模型(LLM)在代码生成方面显示出了非凡的才能，但是在具有挑战性的编程任务方面仍然举步维艰。自我修复(模型调试并修复自己代码中的错误)最近已经成为提高这些设置中性能的一种流行方式。然而，文献中关于自我修复如何以及何时起作用的研究非常有限，人们可能想知道，当代码由同一个模型生成时，一个模型究竟能在多大程度上提供准确的反馈，说明为什么代码是错误的。在本文中，我们分析了 GPT-3.5和 GPT-4对 APPS 进行自我修复的能力，APPS 是一个具有挑战性的数据集，由多种编码挑战组成。为此，我们首先建立一个称为 pass@t 的新评估策略，该策略根据从模型中抽样的令牌总数来度量任务的通过率，从而能够与纯粹基于抽样的方法进行公平的比较。通过这种评估策略，我们发现自我修复的有效性仅见于 GPT-4。我们还观察到自我修复受到反馈阶段的瓶颈; 使用 GPT-4对由 GPT-3.5生成的程序提供反馈，并使用专业的人类程序员对由 GPT-4生成的程序提供反馈，我们获得了显着的性能收益。"
    },
    {
        "title": "Revealing the impact of social circumstances on the selection of cancer\n  therapy through natural language processing of social work notes",
        "url": "http://arxiv.org/abs/2306.09877v1",
        "pub_date": "2023-06-16",
        "summary": "We aimed to investigate the impact of social circumstances on cancer therapy\nselection using natural language processing to derive insights from social\nworker documentation. We developed and employed a Bidirectional Encoder\nRepresentations from Transformers (BERT) based approach, using a hierarchical\nmulti-step BERT model (BERT-MS) to predict the prescription of targeted cancer\ntherapy to patients based solely on documentation by clinical social workers.\nOur corpus included free-text clinical social work notes, combined with\nmedication prescription information, for all patients treated for breast\ncancer. We conducted a feature importance analysis to pinpoint the specific\nsocial circumstances that impact cancer therapy selection. Using only social\nwork notes, we consistently predicted the administration of targeted therapies,\nsuggesting systematic differences in treatment selection exist due to\nnon-clinical factors. The UCSF-BERT model, pretrained on clinical text at UCSF,\noutperformed other publicly available language models with an AUROC of 0.675\nand a Macro F1 score of 0.599. The UCSF BERT-MS model, capable of leveraging\nmultiple pieces of notes, surpassed the UCSF-BERT model in both AUROC and\nMacro-F1. Our feature importance analysis identified several clinically\nintuitive social determinants of health (SDOH) that potentially contribute to\ndisparities in treatment. Our findings indicate that significant disparities\nexist among breast cancer patients receiving different types of therapies based\non social determinants of health. Social work reports play a crucial role in\nunderstanding these disparities in clinical decision-making.",
        "translated": "我们的目的是调查社会环境对癌症治疗选择的影响，使用自然语言处理，从社会工作者的文件中获得见解。我们开发并使用了基于变压器的双向编码器表示(BERT)方法，使用分层多步 BERT 模型(BERT-MS)来预测仅基于临床社会工作者的文档的针对患者的癌症治疗处方。我们的语料库包括自由文本临床社会工作笔记，结合药物处方信息，为所有患者治疗乳腺癌。我们进行了特征重要性分析，以确定影响癌症治疗选择的特定社会环境。仅使用社会工作笔记，我们始终预测靶向治疗的管理，表明治疗选择存在系统性差异，由于非临床因素。UCSF-BERT 模型在 UCSF 的临床文本上进行了预训练，其表现优于其他公开可用的语言模型，AUROC 为0.675，Macro F1评分为0.599。UCSF BERT-MS 模型能够利用多种音符，在 AUROC 和 Macro-F1中都超过了 UCSF BERT 模型。我们的特征重要性分析确定了几个临床直观的健康社会决定因素(SDOH) ，可能有助于差异的治疗。我们的研究结果表明，根据健康的社会决定因素，接受不同类型治疗的乳腺癌患者之间存在显著差异。社会工作报告在了解临床决策中的这些差异方面发挥着至关重要的作用。"
    },
    {
        "title": "Energy-Based Cross Attention for Bayesian Context Update in\n  Text-to-Image Diffusion Models",
        "url": "http://arxiv.org/abs/2306.09869v1",
        "pub_date": "2023-06-16",
        "summary": "Despite the remarkable performance of text-to-image diffusion models in image\ngeneration tasks, recent studies have raised the issue that generated images\nsometimes cannot capture the intended semantic contents of the text prompts,\nwhich phenomenon is often called semantic misalignment. To address this, here\nwe present a novel energy-based model (EBM) framework. Specifically, we first\nformulate EBMs of latent image representations and text embeddings in each\ncross-attention layer of the denoising autoencoder. Then, we obtain the\ngradient of the log posterior of context vectors, which can be updated and\ntransferred to the subsequent cross-attention layer, thereby implicitly\nminimizing a nested hierarchy of energy functions. Our latent EBMs further\nallow zero-shot compositional generation as a linear combination of\ncross-attention outputs from different contexts. Using extensive experiments,\nwe demonstrate that the proposed method is highly effective in handling various\nimage generation tasks, including multi-concept generation, text-guided image\ninpainting, and real and synthetic image editing.",
        "translated": "尽管文本-图像扩散模型在图像生成任务中表现突出，但近年来的研究提出了生成的图像有时不能捕捉到文本提示语的预期语义内容的问题，这种现象通常被称为语义错位。为了解决这个问题，我们提出了一个新的基于能量的模型(EBM)框架。具体地说，我们首先在去噪自动编码器的每个交叉注意层中建立潜在图像表示和文本嵌入的循证医学模型。然后，我们得到上下文向量的对数后验梯度，它可以被更新和转移到后续的交叉注意层，从而隐式地最小化嵌套的能量函数层次结构。我们的潜在的循证医学进一步允许零拍摄成分生成作为交叉注意输出的线性组合从不同的情境。通过大量的实验证明，该方法能够有效地处理多种图像生成任务，包括多概念生成、文本引导的图像修补以及真实和合成的图像编辑。"
    },
    {
        "title": "Visual Analysis of Large Multi-Field AMR Data on GPUs Using Interactive\n  Volume Lines",
        "url": "http://arxiv.org/abs/2306.11612v1",
        "pub_date": "2023-06-20",
        "summary": "To visually compare ensembles of volumes, dynamic volume lines (DVLs)\nrepresent each ensemble member as a 1D polyline. To compute these, the volume\ncells are sorted on a space-filling curve and scaled by the ensemble's local\nvariation. The resulting 1D plot can augment or serve as an alternative to a 3D\nvolume visualization free of visual clutter and occlusion. Interactively\ncomputing DVLs is challenging when the data is large, and the volume grid is\nnot structured/regular, as is often the case with computational fluid dynamics\nsimulations. We extend DVLs to support large-scale, multi-field adaptive mesh\nrefinement (AMR) data that can be explored interactively. Our GPU-based system\nupdates the DVL representation whenever the data or the alpha transfer function\nchanges. We demonstrate and evaluate our interactive prototype using large AMR\nvolumes from astrophysics simulations.",
        "translated": "为了可视化地比较体积的集合，动态体积线(DVL)将每个集合成员表示为一维折线。为了计算这些，体积单元按照皮亚诺曲线进行排序，并按照集合的局部变化进行缩放。由此产生的一维图可以增强或作为一个替代的三维体可视化免费的视觉杂乱和遮挡。当数据量很大时，交互式计算 DVL 是一个挑战，而且体积网格不是结构化/规则化的，就像计算流体力学模拟中经常出现的情况一样。我们扩展 DVL，以支持大规模，多领域的自适应网格细化(AMR)数据，可以互动探索。我们基于 GPU 的系统在数据或 alpha 传输函数发生变化时更新 DVL 表示。我们演示和评估我们的交互式原型使用天体物理学模拟的大量 AMR 卷。"
    },
    {
        "title": "Mining Interest Trends and Adaptively Assigning SampleWeight for\n  Session-based Recommendation",
        "url": "http://arxiv.org/abs/2306.11610v1",
        "pub_date": "2023-06-20",
        "summary": "Session-based Recommendation (SR) aims to predict users' next click based on\ntheir behavior within a short period, which is crucial for online platforms.\nHowever, most existing SR methods somewhat ignore the fact that user preference\nis not necessarily strongly related to the order of interactions. Moreover,\nthey ignore the differences in importance between different samples, which\nlimits the model-fitting performance. To tackle these issues, we put forward\nthe method, Mining Interest Trends and Adaptively Assigning Sample Weight,\nabbreviated as MTAW. Specifically, we model users' instant interest based on\ntheir present behavior and all their previous behaviors. Meanwhile, we\ndiscriminatively integrate instant interests to capture the changing trend of\nuser interest to make more personalized recommendations. Furthermore, we devise\na novel loss function that dynamically weights the samples according to their\nprediction difficulty in the current epoch. Extensive experimental results on\ntwo benchmark datasets demonstrate the effectiveness and superiority of our\nmethod.",
        "translated": "基于会话的推荐(SR)旨在根据用户的行为在短时间内预测用户的下一次点击，这对在线平台至关重要。然而，大多数现有的 SR 方法都忽略了一个事实，即用户偏好并不一定与交互顺序密切相关。此外，他们忽略了不同样本之间的重要性差异，这限制了模型拟合的性能。为了解决这些问题，我们提出了挖掘兴趣趋势和自适应分配样本权重的方法，简称 MTAW。具体来说，我们根据用户当前的行为和他们以前的所有行为来建立用户的即时兴趣模型。同时，我们有选择性地整合即时兴趣，捕捉用户兴趣的变化趋势，提出更加个性化的推荐。此外，我们设计了一个新的损失函数，动态权重的样本根据他们的预测困难在当前的纪元。在两个基准数据集上的大量实验结果表明了该方法的有效性和优越性。"
    },
    {
        "title": "Polytope: An Algorithm for Efficient Feature Extraction on Hypercubes",
        "url": "http://arxiv.org/abs/2306.11553v1",
        "pub_date": "2023-06-20",
        "summary": "Data extraction algorithms on data hypercubes, or datacubes, are\ntraditionally only capable of cutting boxes of data along the datacube axes.\nFor many use cases however, this is not a sufficient approach and returns more\ndata than users might actually need. This not only forces users to apply\npost-processing after extraction, but more importantly this consumes more I/O\nresources than is necessary. When considering very large datacubes from which\nusers only want to extract small non-rectangular subsets, the box approach does\nnot scale well. Indeed, with this traditional approach, I/O systems quickly\nreach capacity, trying to read and return unwanted data to users. In this\npaper, we propose a novel technique, based on computational geometry concepts,\nwhich instead carefully pre-selects the precise bytes of data which the user\nneeds in order to then only read those from the datacube. As we discuss later\non, this novel extraction method will considerably help scale access to large\npetabyte size data hypercubes in a variety of scientific fields.",
        "translated": "数据超立方体(或数据立方体)上的数据提取算法传统上只能沿着数据立方体轴切割数据框。然而，对于许多用例来说，这不是一种充分的方法，并且返回的数据超过了用户实际需要的数据。这不仅迫使用户在提取之后进行后处理，而且更重要的是，这会消耗比必需的更多的 I/O 资源。当考虑用户只想从中提取小的非矩形子集的非常大的数据立方体时，盒方法不能很好地伸缩。实际上，使用这种传统方法，I/O 系统可以快速达到容量，尝试读取并向用户返回不需要的数据。在本文中，我们提出了一种基于计算几何概念的新技术，它仔细地预先选择用户需要的精确字节数据，然后只从数据立方中读取这些数据。正如我们稍后讨论的，这种新颖的提取方法将大大有助于在各种科学领域对大型 PB 大小的数据超立方体进行扩展访问。"
    },
    {
        "title": "Generative Retrieval as Dense Retrieval",
        "url": "http://arxiv.org/abs/2306.11397v1",
        "pub_date": "2023-06-20",
        "summary": "Generative retrieval is a promising new neural retrieval paradigm that aims\nto optimize the retrieval pipeline by performing both indexing and retrieval\nwith a single transformer model. However, this new paradigm faces challenges\nwith updating the index and scaling to large collections. In this paper, we\nanalyze two prominent variants of generative retrieval and show that they can\nbe conceptually viewed as bi-encoders for dense retrieval. Specifically, we\nanalytically demonstrate that the generative retrieval process can be\ndecomposed into dot products between query and document vectors, similar to\ndense retrieval. This analysis leads us to propose a new variant of generative\nretrieval, called Tied-Atomic, which addresses the updating and scaling issues\nby incorporating techniques from dense retrieval. In experiments on two\ndatasets, NQ320k and the full MSMARCO, we confirm that this approach does not\nreduce retrieval effectiveness while enabling the model to scale to large\ncollections.",
        "translated": "生成检索是一种新兴的神经元检索方法，其目的是通过使用单个变换器模型对检索流水线进行索引和检索的优化。但是，这种新范例在更新索引和扩展到大型集合方面面临挑战。在本文中，我们分析了两个突出的变体生成检索，并表明它们可以被概念上看作是密集检索的双编码器。具体来说，我们分析表明，生成检索过程可以分解成点乘之间的查询和文档向量，类似于密集检索。这种分析促使我们提出了一种新的生成检索方法，称为 Tied-Atomic，它通过结合密集检索技术来解决更新和缩放问题。在对两个数据集(NQ320k 和 MSMARCO)的实验中，我们证实了这种方法不会降低检索效率，同时使模型能够扩展到大型数据集。"
    },
    {
        "title": "CAPRI: Context-Aware Interpretable Point-of-Interest Recommendation\n  Framework",
        "url": "http://arxiv.org/abs/2306.11395v1",
        "pub_date": "2023-06-20",
        "summary": "Point-of-Interest (POI ) recommendation systems have gained popularity for\ntheir unique ability to suggest geographical destinations with the\nincorporation of contextual information such as time, location, and user-item\ninteraction. Existing recommendation frameworks lack the contextual fusion\nrequired for POI systems. This paper presents CAPRI, a novel POI recommendation\nframework that effectively integrates context-aware models, such as GeoSoCa,\nLORE, and USG, and introduces a novel strategy for the efficient merging of\ncontextual information. CAPRI integrates an evaluation module that expands the\nevaluation scope beyond accuracy to include novelty, personalization,\ndiversity, and fairness. With an aim to establish a new industry standard for\nreproducible results in the realm of POI recommendation systems, we have made\nCAPRI openly accessible on GitHub, facilitating easy access and contribution to\nthe continued development and refinement of this innovative framework.",
        "translated": "兴趣点(POI)推荐系统由于其独特的推荐地理目的地的能力而受到欢迎，这种推荐系统结合了上下文信息，如时间、地点和用户项目交互。现有的建议框架缺乏 POI 系统所需的上下文融合。本文提出了一个新的 POI 推荐框架 CAPRI，它有效地集成了上下文感知模型，如 GeoSoCa、 LORE 和 USG，并介绍了一种有效合并上下文信息的新策略。CAPRI 整合了一个评估模块，扩大了评估范围，超越了准确性，包括新颖性，个性化，多样性和公平性。为了在 POI 推荐系统领域建立可重复性成果的新行业标准，我们使得 CAPRI 能够在 GitHub 上公开访问，便于访问并促进这一创新框架的持续发展和完善。"
    },
    {
        "title": "Lingua Manga: A Generic Large Language Model Centric System for Data\n  Curation",
        "url": "http://arxiv.org/abs/2306.11702v1",
        "pub_date": "2023-06-20",
        "summary": "Data curation is a wide-ranging area which contains many critical but\ntime-consuming data processing tasks. However, the diversity of such tasks\nmakes it challenging to develop a general-purpose data curation system. To\naddress this issue, we present Lingua Manga, a user-friendly and versatile\nsystem that utilizes pre-trained large language models. Lingua Manga offers\nautomatic optimization for achieving high performance and label efficiency\nwhile facilitating flexible and rapid development. Through three example\napplications with distinct objectives and users of varying levels of technical\nproficiency, we demonstrate that Lingua Manga can effectively assist both\nskilled programmers and low-code or even no-code users in addressing data\ncuration challenges.",
        "translated": "数据管理是一个涉及面很广的领域，其中包含许多关键但耗时的数据处理任务。然而，这些任务的多样性使得开发一个通用的数据管理系统具有挑战性。为了解决这个问题，我们提出了通用语言漫画，一个用户友好和通用的系统，利用预先训练的大型语言模型。通用漫画提供了自动优化，以实现高性能和标签效率，同时促进灵活和快速的开发。通过三个具有不同目标和不同技术熟练程度的用户的示例应用程序，我们证明了 Langua Manga 可以有效地帮助熟练的程序员和低代码甚至无代码用户解决数据管理方面的挑战。"
    },
    {
        "title": "DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT\n  Models",
        "url": "http://arxiv.org/abs/2306.11698v1",
        "pub_date": "2023-06-20",
        "summary": "Generative Pre-trained Transformer (GPT) models have exhibited exciting\nprogress in capabilities, capturing the interest of practitioners and the\npublic alike. Yet, while the literature on the trustworthiness of GPT models\nremains limited, practitioners have proposed employing capable GPT models for\nsensitive applications to healthcare and finance - where mistakes can be\ncostly. To this end, this work proposes a comprehensive trustworthiness\nevaluation for large language models with a focus on GPT-4 and GPT-3.5,\nconsidering diverse perspectives - including toxicity, stereotype bias,\nadversarial robustness, out-of-distribution robustness, robustness on\nadversarial demonstrations, privacy, machine ethics, and fairness. Based on our\nevaluations, we discover previously unpublished vulnerabilities to\ntrustworthiness threats. For instance, we find that GPT models can be easily\nmisled to generate toxic and biased outputs and leak private information in\nboth training data and conversation history. We also find that although GPT-4\nis usually more trustworthy than GPT-3.5 on standard benchmarks, GPT-4 is more\nvulnerable given jailbreaking system or user prompts, potentially due to the\nreason that GPT-4 follows the (misleading) instructions more precisely. Our\nwork illustrates a comprehensive trustworthiness evaluation of GPT models and\nsheds light on the trustworthiness gaps. Our benchmark is publicly available at\nhttps://decodingtrust.github.io/.",
        "translated": "生成式预训练变压器(GPT)模型在性能方面展示了令人兴奋的进步，吸引了从业者和公众的兴趣。然而，尽管关于 GPT 模型可信度的文献仍然有限，但从业人员已经提议，在医疗和金融领域的敏感应用中使用有能力的 GPT 模型——在这些领域，错误可能代价高昂。为此，这项工作提出了一个全面的大型语言模型的可信性评估，重点是 GPT-4和 GPT-3.5，考虑到不同的观点-包括毒性，刻板印象偏差，对抗性鲁棒性，分布外鲁棒性，对抗性示范的鲁棒性，隐私，机器伦理和公平。根据我们的评估，我们发现了以前未公布的可信度威胁的漏洞。例如，我们发现 GPT 模型很容易被误导，从而产生有毒和有偏见的输出，并在训练数据和对话历史中泄露私人信息。我们还发现，尽管 GPT-4在标准基准上通常比 GPT-3.5更值得信赖，但是在破解系统或用户提示下，GPT-4更容易受到攻击，这可能是由于 GPT-4更精确地遵循(误导性的)指令的原因。我们的工作阐述了 GPT 模型的全面可信性评估，并揭示了可信性差距。我们的基准 https://decodingtrust.github.io/已公开发售。"
    },
    {
        "title": "A Simple and Effective Pruning Approach for Large Language Models",
        "url": "http://arxiv.org/abs/2306.11695v1",
        "pub_date": "2023-06-20",
        "summary": "As their size increases, Large Languages Models (LLMs) are natural candidates\nfor network pruning methods: approaches that drop a subset of network weights\nwhile striving to preserve performance. Existing methods, however, require\neither retraining, which is rarely affordable for billion-scale LLMs, or\nsolving a weight reconstruction problem reliant on second-order information,\nwhich may also be computationally expensive. In this paper, we introduce a\nnovel, straightforward yet effective pruning method, termed Wanda (Pruning by\nWeights and activations), designed to induce sparsity in pretrained LLMs.\nMotivated by the recent observation of emergent large magnitude features in\nLLMs, our approach prune weights with the smallest magnitudes multiplied by the\ncorresponding input activations, on a per-output basis. Notably, Wanda requires\nno retraining or weight update, and the pruned LLM can be used as is. We\nconduct a thorough evaluation of our method on LLaMA across various language\nbenchmarks. Wanda significantly outperforms the established baseline of\nmagnitude pruning and competes favorably against recent methods involving\nintensive weight update. Code is available at\nhttps://github.com/locuslab/wanda.",
        "translated": "随着规模的增加，大型语言模型(LLM)自然成为网络裁剪方法的候选者: 这种方法在努力保持性能的同时减少了网络权重的子集。然而，现有的方法要么需要再培训(这对于十亿级的 LLM 来说是很难负担得起的) ，要么需要解决依赖于二阶信息的重构问题(这也可能是计算昂贵的)。在本文中，我们介绍了一种新颖的，直接而有效的修剪方法，称为万达(修剪的权重和激活) ，旨在诱导稀疏的预训练 LLM。受最近对 LLM 中出现的大幅度特征的观察的启发，我们的方法以每个输出为基础，用最小幅度的权重乘以相应的输入激活。值得注意的是，万达不需要再培训或体重更新，修剪后的 LLM 可以按原样使用。我们在不同的语言基准上对我们的 LLaMA 方法进行了全面的评估。万达明显优于既定的基准量修剪和竞争优势最近的方法涉及密集的体重更新。密码可于 https://github.com/locuslab/wanda 索取。"
    },
    {
        "title": "Harnessing the Power of Adversarial Prompting and Large Language Models\n  for Robust Hypothesis Generation in Astronomy",
        "url": "http://arxiv.org/abs/2306.11648v1",
        "pub_date": "2023-06-20",
        "summary": "This study investigates the application of Large Language Models (LLMs),\nspecifically GPT-4, within Astronomy. We employ in-context prompting, supplying\nthe model with up to 1000 papers from the NASA Astrophysics Data System, to\nexplore the extent to which performance can be improved by immersing the model\nin domain-specific literature. Our findings point towards a substantial boost\nin hypothesis generation when using in-context prompting, a benefit that is\nfurther accentuated by adversarial prompting. We illustrate how adversarial\nprompting empowers GPT-4 to extract essential details from a vast knowledge\nbase to produce meaningful hypotheses, signaling an innovative step towards\nemploying LLMs for scientific research in Astronomy.",
        "translated": "这项研究调查了大语言模型(LLM) ，特别是 GPT-4在天文学中的应用。我们采用了上下文提示的方式，向模型提供了多达1000篇来自美国宇航局天体物理数据系统的论文，以探索通过将模型沉浸在特定领域的文献中，可以在多大程度上提高性能。我们的研究结果表明，在使用上下文激励时，假设生成能力大大提高，而对抗性激励则进一步强调了这一点。我们举例说明对抗性的提示如何使 GPT-4能够从庞大的知识库中提取基本细节，从而产生有意义的假设，标志着在天文学科学研究中使用 LLM 的创新步骤。"
    },
    {
        "title": "Recent Advances in Direct Speech-to-text Translation",
        "url": "http://arxiv.org/abs/2306.11646v1",
        "pub_date": "2023-06-20",
        "summary": "Recently, speech-to-text translation has attracted more and more attention\nand many studies have emerged rapidly. In this paper, we present a\ncomprehensive survey on direct speech translation aiming to summarize the\ncurrent state-of-the-art techniques. First, we categorize the existing research\nwork into three directions based on the main challenges -- modeling burden,\ndata scarcity, and application issues. To tackle the problem of modeling\nburden, two main structures have been proposed, encoder-decoder framework\n(Transformer and the variants) and multitask frameworks. For the challenge of\ndata scarcity, recent work resorts to many sophisticated techniques, such as\ndata augmentation, pre-training, knowledge distillation, and multilingual\nmodeling. We analyze and summarize the application issues, which include\nreal-time, segmentation, named entity, gender bias, and code-switching.\nFinally, we discuss some promising directions for future work.",
        "translated": "近年来，语音翻译越来越受到人们的关注，许多研究也迅速兴起。本文对直接言语翻译进行了全面的综述，旨在总结目前的最新技术。首先，基于主要挑战——建模负担、数据稀缺性和应用问题，我们将现有的研究工作分为三个方向。为了解决建模负担问题，提出了两种主要的结构: 编解码框架和多任务框架。面对数据稀缺的挑战，最近的工作采用了许多复杂的技术，如数据增强、预训练、知识提取和多语言建模。我们分析和总结了这些应用问题，包括实时性、分割、命名实体、性别偏见和语码转换。最后，讨论了今后工作的一些有希望的方向。"
    },
    {
        "title": "Textbooks Are All You Need",
        "url": "http://arxiv.org/abs/2306.11644v1",
        "pub_date": "2023-06-20",
        "summary": "We introduce phi-1, a new large language model for code, with significantly\nsmaller size than competing models: phi-1 is a Transformer-based model with\n1.3B parameters, trained for 4 days on 8 A100s, using a selection of ``textbook\nquality\" data from the web (6B tokens) and synthetically generated textbooks\nand exercises with GPT-3.5 (1B tokens). Despite this small scale, phi-1 attains\npass@1 accuracy 50.6% on HumanEval and 55.5% on MBPP. It also displays\nsurprising emergent properties compared to phi-1-base, our model before our\nfinetuning stage on a dataset of coding exercises, and phi-1-small, a smaller\nmodel with 350M parameters trained with the same pipeline as phi-1 that still\nachieves 45% on HumanEval.",
        "translated": "我们介绍了 phi-1，一种新的大型代码语言模型，其大小明显小于竞争模型: phi-1是一种基于 Transformer 的模型，具有1.3 B 参数，在8个 A100s 上训练了4天，使用来自 Web 的选择的“教科书质量”数据(6B 令牌) ，并用 GPT-3.5(1B 令牌)综合生成教科书和练习。尽管规模很小，phi-1在 HumanEval 和 MBPP 上的准确率分别为50.6% 和55.5% 。与 phi-1-base (我们在编码练习数据集的微调阶段之前的模型)和 phi-1-small (一个较小的模型，具有350M 参数，与 phi-1使用相同的管道训练，在 HumanEval 上仍然达到45%)相比，它还显示出令人惊讶的紧急属性。"
    },
    {
        "title": "Improving Image Captioning Descriptiveness by Ranking and LLM-based\n  Fusion",
        "url": "http://arxiv.org/abs/2306.11593v1",
        "pub_date": "2023-06-20",
        "summary": "State-of-The-Art (SoTA) image captioning models often rely on the Microsoft\nCOCO (MS-COCO) dataset for training. This dataset contains annotations provided\nby human annotators, who typically produce captions averaging around ten\ntokens. However, this constraint presents a challenge in effectively capturing\ncomplex scenes and conveying detailed information. Furthermore, captioning\nmodels tend to exhibit bias towards the ``average'' caption, which captures\nonly the more general aspects. What would happen if we were able to\nautomatically generate longer captions, thereby making them more detailed?\nWould these captions, evaluated by humans, be more or less representative of\nthe image content compared to the original MS-COCO captions? In this paper, we\npresent a novel approach to address previous challenges by showcasing how\ncaptions generated from different SoTA models can be effectively fused,\nresulting in richer captions. Our proposed method leverages existing models\nfrom the literature, eliminating the need for additional training. Instead, it\nutilizes an image-text based metric to rank the captions generated by SoTA\nmodels for a given image. Subsequently, the top two captions are fused using a\nLarge Language Model (LLM). Experimental results demonstrate the effectiveness\nof our approach, as the captions generated by our model exhibit higher\nconsistency with human judgment when evaluated on the MS-COCO test set. By\ncombining the strengths of various SoTA models, our method enhances the quality\nand appeal of image captions, bridging the gap between automated systems and\nthe rich, informative nature of human-generated descriptions. This advance\nopens up new possibilities for generating captions that are more suitable for\nthe training of both vision-language and captioning models.",
        "translated": "最先进的(SoTA)图像字幕模型通常依赖于微软 COCO (MS-COCO)数据集进行训练。此数据集包含由人工注释器提供的注释，人工注释器通常生成平均约10个标记的标题。然而，这种约束在有效捕获复杂场景和传递详细信息方面提出了挑战。此外，字幕模型往往表现出偏向于“平均”字幕的倾向，它只捕获更一般的方面。如果我们能够自动生成更长的字幕，从而使它们更加详细，会发生什么？与原始的 MS-COCO 标题相比，这些由人类评估的标题是否更能代表图像内容？在本文中，我们通过展示如何有效地融合不同 SoTA 模型生成的字幕，从而产生更丰富的字幕，提出了一种新颖的方法来应对以前的挑战。我们提出的方法利用了文献中的现有模型，消除了额外培训的需要。相反，它使用一个基于图像文本的度量标准来对 SoTA 模型为给定图像生成的标题进行排序。随后，使用大型语言模型(LLM)将前两个标题融合在一起。实验结果证明了该方法的有效性，因为当在 MS-COCO 测试集上进行评估时，我们的模型生成的字幕与人类的判断具有更高的一致性。通过结合各种 SoTA 模型的优势，我们的方法提高了图像标题的质量和吸引力，弥合了自动化系统与人工生成描述的丰富信息性之间的差距。这一进步为生成更适合于视觉语言和字幕模型训练的字幕提供了新的可能性。"
    },
    {
        "title": "FAIR: A Causal Framework for Accurately Inferring Judgments Reversals",
        "url": "http://arxiv.org/abs/2306.11585v1",
        "pub_date": "2023-06-20",
        "summary": "Artificial intelligence researchers have made significant advances in legal\nintelligence in recent years. However, the existing studies have not focused on\nthe important value embedded in judgments reversals, which limits the\nimprovement of the efficiency of legal intelligence. In this paper, we propose\na causal Framework for Accurately Inferring case Reversals (FAIR), which models\nthe problem of judgments reversals based on real Chinese judgments. We mine the\ncauses of judgments reversals by causal inference methods and inject the\nobtained causal relationships into the neural network as a priori knowledge.\nAnd then, our framework is validated on a challenging dataset as a legal\njudgment prediction task. The experimental results show that our framework can\ntap the most critical factors in judgments reversal, and the obtained causal\nrelationships can effectively improve the neural network's performance. In\naddition, we discuss the generalization ability of large language models for\nlegal intelligence tasks using ChatGPT as an example. Our experiment has found\nthat the generalization ability of large language models still has defects, and\nmining causal relationships can effectively improve the accuracy and explain\nability of model predictions.",
        "translated": "近年来，人工智能研究者在法律智能方面取得了重大进展。然而，现有的研究并没有关注到判决书撤销所蕴含的重要价值，这限制了法律情报工作效率的提高。在本文中，我们提出了一个准确推断判例颠倒的因果框架(FAIR) ，该框架基于真实的中国判例对判例颠倒问题进行建模。我们利用因果推理方法挖掘判断反转的原因，并将所得到的因果关系作为先验知识注入到神经网络中。然后，我们的框架在一个具有挑战性的数据集上作为一个法律判决预测任务进行验证。实验结果表明，该框架能够挖掘出判断反转中最关键的因素，得到的因果关系能够有效地提高神经网络的性能。此外，本文还以 ChatGPT 为例，讨论了大型语言模型对法律情报任务的泛化能力。我们的实验发现，大型语言模型的泛化能力仍然存在缺陷，挖掘因果关系可以有效地提高模型预测的准确性和解释能力。"
    },
    {
        "title": "The Ecological Fallacy in Annotation: Modelling Human Label Variation\n  goes beyond Sociodemographics",
        "url": "http://arxiv.org/abs/2306.11559v1",
        "pub_date": "2023-06-20",
        "summary": "Many NLP tasks exhibit human label variation, where different annotators give\ndifferent labels to the same texts. This variation is known to depend, at least\nin part, on the sociodemographics of annotators. Recent research aims to model\nindividual annotator behaviour rather than predicting aggregated labels, and we\nwould expect that sociodemographic information is useful for these models. On\nthe other hand, the ecological fallacy states that aggregate group behaviour,\nsuch as the behaviour of the average female annotator, does not necessarily\nexplain individual behaviour. To account for sociodemographics in models of\nindividual annotator behaviour, we introduce group-specific layers to\nmulti-annotator models. In a series of experiments for toxic content detection,\nwe find that explicitly accounting for sociodemographic attributes in this way\ndoes not significantly improve model performance. This result shows that\nindividual annotation behaviour depends on much more than just\nsociodemographics.",
        "translated": "许多 NLP 任务表现出人工标签的变化，其中不同的注释者为相同的文本提供不同的标签。众所周知，这种差异至少在一定程度上取决于注释者的社会人口统计学特征。最近的研究旨在模拟个人注释者的行为，而不是预测聚合标签，我们期望社会人口信息对这些模型是有用的。另一方面，区群谬误指出，集体行为(例如一般女性注释者的行为)不一定能解释个人行为。为了解释个体注释者行为模型中的社会人口统计学特征，我们在多注释者模型中引入了群体特定层次。在一系列有毒物质含量检测的实验中，我们发现，以这种方式明确考虑社会人口属性并不能显著改善模型的性能。这一结果表明，个人注释行为不仅仅取决于社会人口统计学。"
    },
    {
        "title": "Hallucination is the last thing you need",
        "url": "http://arxiv.org/abs/2306.11520v1",
        "pub_date": "2023-06-20",
        "summary": "The legal profession necessitates a multidimensional approach that involves\nsynthesizing an in-depth comprehension of a legal issue with insightful\ncommentary based on personal experience, combined with a comprehensive\nunderstanding of pertinent legislation, regulation, and case law, in order to\ndeliver an informed legal solution. The present offering with generative AI\npresents major obstacles in replicating this, as current models struggle to\nintegrate and navigate such a complex interplay of understanding, experience,\nand fact-checking procedures. It is noteworthy that where generative AI outputs\nunderstanding and experience, which reflect the aggregate of various subjective\nviews on similar topics, this often deflects the model's attention from the\ncrucial legal facts, thereby resulting in hallucination. Hence, this paper\ndelves into the feasibility of three independent LLMs, each focused on\nunderstanding, experience, and facts, synthesising as one single ensemble model\nto effectively counteract the current challenges posed by the existing\nmonolithic generative AI models. We introduce an idea of mutli-length\ntokenisation to protect key information assets like common law judgements, and\nfinally we interrogate the most advanced publicly available models for legal\nhallucination, with some interesting results.",
        "translated": "法律专业需要一种多层面的方法，包括综合对法律问题的深入理解和根据个人经验作出的有见地的评论，再加上对相关立法、条例和判例法的全面理解，以便提供一个知情的法律解决方案。目前提供的生成性人工智能在复制这一点上存在重大障碍，因为目前的模型正在努力整合和导航这种理解、经验和事实核查程序的复杂相互作用。值得注意的是，当生成性 AI 输出理解和经验时，这些理解和经验反映了对类似主题的各种主观观点的集合，这往往会使模型的注意力偏离关键的法律事实，从而导致幻觉。因此，本文深入探讨了三个独立的 LLM 的可行性，每个 LLM 的重点是理解，经验和事实，综合为一个单一的集成模型，以有效地对抗现有的单片生成 AI 模型所带来的挑战。我们介绍了一个多长度标记的想法，以保护关键的信息资产，如普通法判决，最后我们询问了最先进的公开可用的模型的法律幻觉，一些有趣的结果。"
    },
    {
        "title": "Knowledge-based Multimodal Music Similarity",
        "url": "http://arxiv.org/abs/2306.12249v1",
        "pub_date": "2023-06-21",
        "summary": "Music similarity is an essential aspect of music retrieval, recommendation\nsystems, and music analysis. Moreover, similarity is of vital interest for\nmusic experts, as it allows studying analogies and influences among composers\nand historical periods. Current approaches to musical similarity rely mainly on\nsymbolic content, which can be expensive to produce and is not always readily\navailable. Conversely, approaches using audio signals typically fail to provide\nany insight about the reasons behind the observed similarity. This research\naddresses the limitations of current approaches by focusing on the study of\nmusical similarity using both symbolic and audio content. The aim of this\nresearch is to develop a fully explainable and interpretable system that can\nprovide end-users with more control and understanding of music similarity and\nclassification systems.",
        "translated": "音乐相似性是音乐检索、推荐系统和音乐分析的一个重要方面。此外，相似性对音乐专家来说至关重要，因为它允许研究作曲家和历史时期之间的类比和影响。目前音乐相似性的方法主要依靠符号内容，这可能是昂贵的生产，并不总是容易获得。相反，使用音频信号的方法通常不能提供任何有关观察到的相似性背后的原因的洞察力。本研究针对现有研究方法的局限性，集中研究音乐相似性的符号和音频内容。本研究的目的是开发一个完全可解释及可解释的系统，以提供最终使用者对音乐相似性及分类系统的更多控制及理解。"
    },
    {
        "title": "CompMix: A Benchmark for Heterogeneous Question Answering",
        "url": "http://arxiv.org/abs/2306.12235v1",
        "pub_date": "2023-06-21",
        "summary": "Fact-centric question answering (QA) often requires access to multiple,\nheterogeneous, information sources. By jointly considering several sources like\na knowledge base (KB), a text collection, and tables from the web, QA systems\ncan enhance their answer coverage and confidence. However, existing QA\nbenchmarks are mostly constructed with a single source of knowledge in mind.\nThis limits capabilities of these benchmarks to fairly evaluate QA systems that\ncan tap into more than one information repository. To bridge this gap, we\nrelease CompMix, a crowdsourced QA benchmark which naturally demands the\nintegration of a mixture of input sources. CompMix has a total of 9,410\nquestions, and features several complex intents like joins and temporal\nconditions. Evaluation of a range of QA systems on CompMix highlights the need\nfor further research on leveraging information from heterogeneous sources.",
        "translated": "以事实为中心的问答(QA)通常需要访问多种不同的信息源。通过联合考虑几个来源，如知识库(KB)、文本集合和来自 Web 的表格，QA 系统可以增强它们的答案覆盖范围和信心。然而，现有的质量保证基准大部分都是基于单一的知识来源构建的。这限制了这些基准测试公平评估能够利用多个信息存储库的 QA 系统的能力。为了弥合这一差距，我们发布了 CompMix，一个众包 QA 基准，它自然而然地要求集成多种输入源。CompMix 总共有9,410个问题，并且具有一些复杂的意图，比如连接和时态条件。对 CompMix 上一系列 QA 系统的评估突出表明，需要进一步研究如何利用来自不同来源的信息。"
    },
    {
        "title": "STAN: Stage-Adaptive Network for Multi-Task Recommendation by Learning\n  User Lifecycle-Based Representation",
        "url": "http://arxiv.org/abs/2306.12232v1",
        "pub_date": "2023-06-21",
        "summary": "Recommendation systems play a vital role in many online platforms, with their\nprimary objective being to satisfy and retain users. As directly optimizing\nuser retention is challenging, multiple evaluation metrics are often employed.\nExisting methods generally formulate the optimization of these evaluation\nmetrics as a multitask learning problem, but often overlook the fact that user\npreferences for different tasks are personalized and change over time.\nIdentifying and tracking the evolution of user preferences can lead to better\nuser retention. To address this issue, we introduce the concept of \"user\nlifecycle\", consisting of multiple stages characterized by users' varying\npreferences for different tasks. We propose a novel Stage-Adaptive Network\n(STAN) framework for modeling user lifecycle stages. STAN first identifies\nlatent user lifecycle stages based on learned user preferences, and then\nemploys the stage representation to enhance multi-task learning performance.\nOur experimental results using both public and industrial datasets demonstrate\nthat the proposed model significantly improves multi-task prediction\nperformance compared to state-of-the-art methods, highlighting the importance\nof considering user lifecycle stages in recommendation systems. Furthermore,\nonline A/B testing reveals that our model outperforms the existing model,\nachieving a significant improvement of 3.05% in staytime per user and 0.88% in\nCVR. These results indicate that our approach effectively improves the overall\nefficiency of the multi-task recommendation system.",
        "translated": "推荐系统在许多在线平台中发挥着至关重要的作用，其主要目标是满足和留住用户。由于直接优化用户保留是具有挑战性的，因此经常采用多种评估指标。现有的方法通常将这些评估指标的优化描述为一个多任务学习问题，但往往忽略了这样一个事实，即用户对不同任务的偏好是个性化的，并且随着时间的推移而改变。识别和跟踪用户偏好的演变可以更好地保留用户。为了解决这个问题，我们引入了“用户生命周期”的概念，由多个阶段组成，拥有属性是用户对不同任务的不同偏好。我们提出了一个新的阶段自适应网络(STAN)框架，用于建模用户生命周期阶段。STAN 首先根据学习用户的偏好识别潜在的用户生命周期阶段，然后采用阶段表示来提高多任务学习性能。我们使用公共数据集和工业数据集的实验结果表明，与最先进的方法相比，该模型显著提高了多任务预测性能，突出了在推荐系统中考虑用户生命周期阶段的重要性。此外，在线 A/B 测试表明，我们的模型优于现有的模型，实现了3.05% 的每个用户的停留时间和0.88% 的 CVR 显着改善。这些结果表明，该方法有效地提高了多任务推荐系统的整体效率。"
    },
    {
        "title": "Post-hoc Selection of Pareto-Optimal Solutions in Search and\n  Recommendation",
        "url": "http://arxiv.org/abs/2306.12165v1",
        "pub_date": "2023-06-21",
        "summary": "Information Retrieval (IR) and Recommender Systems (RS) tasks are moving from\ncomputing a ranking of final results based on a single metric to\nmulti-objective problems. Solving these problems leads to a set of\nPareto-optimal solutions, known as Pareto frontier, in which no objective can\nbe further improved without hurting the others. In principle, all the points on\nthe Pareto frontier are potential candidates to represent the best model\nselected with respect to the combination of two, or more, metrics. To our\nknowledge, there are no well-recognized strategies to decide which point should\nbe selected on the frontier. In this paper, we propose a novel, post-hoc,\ntheoretically-justified technique, named \"Population Distance from Utopia\"\n(PDU), to identify and select the one-best Pareto-optimal solution from the\nfrontier. In detail, PDU analyzes the distribution of the points by\ninvestigating how far each point is from its utopia point (the ideal\nperformance for the objectives). The possibility of considering fine-grained\nutopia points allows PDU to select solutions tailored to individual user\npreferences, a novel feature we call \"calibration\". We compare PDU against\nexisting state-of-the-art strategies through extensive experiments on tasks\nfrom both IR and RS. Experimental results show that PDU and combined with\ncalibration notably impact the solution selection. Furthermore, the results\nshow that the proposed framework selects a solution in a principled way,\nirrespective of its position on the frontier, thus overcoming the limits of\nother strategies.",
        "translated": "信息检索(IR)和推荐系统(RS)任务正在从计算基于单一指标的最终结果排序过渡到多目标问题。解决这些问题导致一组帕累托最优解，称为帕累托边界，其中任何目标都不能进一步改进而不损害其他目标。原则上，Pareto 前沿上的所有点都是潜在的候选者，可以代表就两个或更多指标的组合而选择的最佳模型。据我们所知，没有公认的战略来决定哪一点应该选择在前沿。本文提出了一种新的、事后的、理论证明的技术，称为“距离乌托邦的人口距离”(PDU) ，从前沿中识别和选择一个最佳的帕累托最优解。具体来说，PDU 通过调查每个点离它的乌托邦点(目标的理想性能)有多远来分析这些点的分布。考虑细粒度乌托邦点的可能性允许 PDU 选择适合个人用户偏好的解决方案，这个新特性我们称之为“校准”。通过对 IR 和 RS 任务的大量实验，我们比较了 PDU 和现有的最新策略。实验结果表明，PDU 和标定相结合对解决方案的选择有显著影响。此外，结果表明，所提出的框架以原则性的方式选择解决方案，而不考虑其在前沿的位置，从而克服了其他战略的局限性。"
    },
    {
        "title": "Visualizing Relation Between (De)Motivating Topics and Public Stance\n  toward COVID-19 Vaccine",
        "url": "http://arxiv.org/abs/2306.12118v1",
        "pub_date": "2023-06-21",
        "summary": "While social media plays a vital role in communication nowadays,\nmisinformation and trolls can easily take over the conversation and steer\npublic opinion on these platforms. We saw the effect of misinformation during\nthe {COVID-19} pandemic when public health officials faced significant\npush-back while trying to motivate the public to vaccinate. To tackle the\ncurrent and any future threats in emergencies and motivate the public towards a\ncommon goal, it is essential to understand how public motivation shifts and\nwhich topics resonate among the general population. In this study, we proposed\nan interactive visualization tool to inspect and analyze the topics that\nresonated among Twitter-sphere during the {COVID-19} pandemic and understand\nthe key factors that shifted public stance for vaccination. This tool can\neasily be generalized for any scenario for visual analysis and to increase the\ntransparency of social media data for researchers and the general population\nalike.",
        "translated": "尽管社交媒体在当今的交流中扮演着重要的角色，但是错误的信息和喷子很容易就能在这些平台上控制交流和引导公众舆论。在2019冠状病毒疾病大流行期间，我们看到了错误信息的影响，当时公共卫生官员在试图激励公众接种疫苗时面临重大阻力。为了应对当前和今后在紧急情况下的任何威胁，并推动公众实现一个共同目标，必须了解公众的动机如何转变，以及哪些主题在普通民众中产生共鸣。在这项研究中，我们提出了一个交互式可视化工具来检查和分析在2019冠状病毒疾病大流行期间在 twitter 领域引起共鸣的话题，并了解改变公众对疫苗接种立场的关键因素。这个工具可以很容易地推广到任何可视化分析的场景，并为研究人员和普通大众提高社交媒体数据的透明度。"
    },
    {
        "title": "VisoGender: A dataset for benchmarking gender bias in image-text pronoun\n  resolution",
        "url": "http://arxiv.org/abs/2306.12424v1",
        "pub_date": "2023-06-21",
        "summary": "We introduce VisoGender, a novel dataset for benchmarking gender bias in\nvision-language models. We focus on occupation-related gender biases, inspired\nby Winograd and Winogender schemas, where each image is associated with a\ncaption containing a pronoun relationship of subjects and objects in the scene.\nVisoGender is balanced by gender representation in professional roles,\nsupporting bias evaluation in two ways: i) resolution bias, where we evaluate\nthe difference between gender resolution accuracies for men and women and ii)\nretrieval bias, where we compare ratios of male and female professionals\nretrieved for a gender-neutral search query. We benchmark several\nstate-of-the-art vision-language models and find that they lack the reasoning\nabilities to correctly resolve gender in complex scenes. While the direction\nand magnitude of gender bias depends on the task and the model being evaluated,\ncaptioning models generally are more accurate and less biased than CLIP-like\nmodels. Dataset and code are available at https://github.com/oxai/visogender",
        "translated": "我们介绍了视觉性别，一个新的数据集的基准性别偏见的视觉语言模型。我们重点关注与职业相关的性别偏见，灵感来自 Winograd 和 Winosex 模式，其中每个图像都与一个包含场景中主体和客体的代词关系的标题相关联。Viso 性别通过专业角色中的性别代表性来平衡，支持偏倚评估有两种方式: i)解析偏倚，其中我们评估男性和女性性别解析准确性之间的差异以及 ii)检索偏倚，其中我们比较检索的男性和女性专业人员的比例进行性别中立的搜索查询。我们基准的几个国家的最先进的视觉语言模型，发现他们缺乏推理能力，以正确解决性别在复杂的场景。虽然性别偏见的方向和程度取决于被评估的任务和模型，但字幕模型一般比 CLIP 类模型更准确，偏见更少。数据集和代码可在 https://github.com/oxai/visogender 下载"
    },
    {
        "title": "LMFlow: An Extensible Toolkit for Finetuning and Inference of Large\n  Foundation Models",
        "url": "http://arxiv.org/abs/2306.12420v1",
        "pub_date": "2023-06-21",
        "summary": "Large foundation models have demonstrated a great ability to achieve general\nhuman-level intelligence far beyond traditional approaches. As the technique\nkeeps attracting attention from the AI community, more and more large\nfoundation models have become publically available. However, most of those\nmodels exhibit a major deficiency in specialized-task applications, where the\nstep of finetuning is still required for obtaining satisfactory performance. As\nthe number of available models and specialized tasks keeps growing, the job of\ngeneral finetuning becomes highly nontrivial. In this paper, we take the first\nstep to address this issue. We introduce an extensible and lightweight toolkit,\nLMFlow, which aims to simplify the finetuning and inference of general large\nfoundation models. LMFlow offers a complete finetuning workflow for a large\nfoundation model to support personalized training with limited computing\nresources. Furthermore, it supports continuous pretraining, instruction tuning,\nparameter-efficient finetuning, alignment tuning, and large model inference,\nalong with carefully designed and extensible APIs. This toolkit has been\nthoroughly tested and is available at https://github.com/OptimalScale/LMFlow.",
        "translated": "大型基础模型已经证明，它具有实现远远超出传统方法的一般人类水平智能的巨大能力。随着该技术不断受到人工智能界的关注，越来越多的大型基础模型被公开。然而，这些模型中的大多数都表现出专门任务应用程序的主要缺陷，在这些应用程序中，仍然需要进行微调以获得令人满意的性能。随着可用模型和专门任务的数量不断增加，一般微调工作变得非常重要。在本文中，我们采取第一步来解决这个问题。我们介绍了一个可扩展的轻量级工具包 LMFlow，旨在简化一般大型基础模型的微调和推理。LMFlow 为大型基础模型提供了完整的微调工作流，以支持计算资源有限的个性化培训。此外，它还支持连续预训练、指令调优、参数高效微调、对齐调优和大型模型推理，以及精心设计和可扩展的 API。这个工具包已经经过了彻底的测试，可以在 https://github.com/optimalscale/lmflow 上使用。"
    },
    {
        "title": "Solving Dialogue Grounding Embodied Task in a Simulated Environment\n  using Further Masked Language Modeling",
        "url": "http://arxiv.org/abs/2306.12387v1",
        "pub_date": "2023-06-21",
        "summary": "Enhancing AI systems with efficient communication skills that align with\nhuman understanding is crucial for their effective assistance to human users.\nProactive initiatives from the system side are needed to discern specific\ncircumstances and interact aptly with users to solve these scenarios. In this\nresearch, we opt for a collective building assignment taken from the Minecraft\ndataset. Our proposed method employs language modeling to enhance task\nunderstanding through state-of-the-art (SOTA) methods using language models.\nThese models focus on grounding multi-modal understandinging and task-oriented\ndialogue comprehension tasks. This focus aids in gaining insights into how well\nthese models interpret and respond to a variety of inputs and tasks. Our\nexperimental results provide compelling evidence of the superiority of our\nproposed method. This showcases a substantial improvement and points towards a\npromising direction for future research in this domain.",
        "translated": "加强人工智能系统，使其具有与人类理解相一致的高效沟通技能，对于有效协助人类用户至关重要。需要系统方面的主动行动来识别具体情况，并与用户适当地交互以解决这些场景。在这项研究中，我们选择了一个从 Minecraft 数据集中获取的集体建筑分配。我们提出的方法采用语言模型，通过使用语言模型的最新(SOTA)方法来增强任务理解。这些模型侧重于基础的多模态理解和任务导向的对话理解任务。这种关注有助于深入了解这些模型如何很好地解释和响应各种输入和任务。我们的实验结果为我们提出的方法的优越性提供了令人信服的证据。这表明了一个实质性的改进，并指出了该领域未来研究的一个有希望的方向。"
    },
    {
        "title": "Iterated Piecewise Affine (IPA) Approximation for Language Modeling",
        "url": "http://arxiv.org/abs/2306.12317v1",
        "pub_date": "2023-06-21",
        "summary": "In this work, we demonstrate the application of a simple first-order Taylor\nexpansion to approximate a generic function $F: R^{n \\times m} \\to R^{n \\times\nm}$ and utilize it in language modeling. To enhance the basic Taylor expansion,\nwe introduce iteration and piecewise modeling, leading us to name the algorithm\nthe Iterative Piecewise Affine (IPA) approximation. The final algorithm\nexhibits interesting resemblances to the Transformers decoder architecture. By\ncomparing parameter arrangements in IPA and Transformers, we observe a\nstrikingly similar performance, with IPA outperforming Transformers by 1.5\\% in\nthe next token prediction task with cross-entropy loss for smaller sequence\nlengths.",
        "translated": "在本文中，我们应用一个简单的一阶泰勒展开式将一般函数 $F: R ^ { n 乘以 m }逼近到 R ^ { n 乘以 m } $，并将其应用于语言建模。为了增强基本的泰勒展开，我们引入了迭代和分段建模，从而将该算法命名为迭代分段仿射(IPA)近似。最终的算法与变形金刚解码器结构有着有趣的相似之处。通过比较 IPA 和 Transformers 中的参数安排，我们观察到了惊人的相似性能，在交叉熵损失较小的序列长度的下一个令牌预测任务中，IPA 的性能优于 Transformers 1.5% 。"
    },
    {
        "title": "Medical ministrations through web scraping",
        "url": "http://arxiv.org/abs/2306.12310v1",
        "pub_date": "2023-06-21",
        "summary": "Web scraping is a technique that allows us to extract data from websites\nautomatically. in the field of medicine, web scraping can be used to collect\ninformation about medical procedures, treatments, and healthcare providers.\nthis information can be used to improve patient care, monitor the quality of\nhealthcare services, and identify areas for improvement. one area where web\nscraping can be particularly useful is in medical ministrations. medical\nministrations are the actions taken to provide medical care to patients, and\nweb scraping can help healthcare providers identify the most effective\nministrations for their patients. for example, healthcare providers can use web\nscraping to collect data about the symptoms and medical histories of their\npatients, and then use this information to determine the most appropriate\nministrations. they can also use web scraping to gather information about the\nlatest medical research and clinical trials, which can help them stay\nup-to-date with the latest treatments and procedures.",
        "translated": "网页抓取是一种允许我们从网站自动提取数据的技术。在医学领域，网络抓取可以用来收集关于医疗程序、治疗和医疗保健提供者的信息。这些信息可用于改善患者护理，监测医疗服务的质量，并确定需要改进的领域。网络抓取特别有用的一个领域是医疗管理。医疗管理是为病人提供医疗服务而采取的行动，网络抓取可以帮助医疗服务提供者为病人确定最有效的管理。例如，医疗保健提供者可以使用网络抓取来收集关于病人的症状和病史的数据，然后使用这些信息来确定最合适的服务。他们还可以使用网络搜索来收集最新的医学研究和临床试验的信息，这可以帮助他们了解最新的治疗方法和程序。"
    },
    {
        "title": "SIFTER: A Task-specific Alignment Strategy for Enhancing Sentence\n  Embeddings",
        "url": "http://arxiv.org/abs/2306.12280v1",
        "pub_date": "2023-06-21",
        "summary": "The paradigm of pre-training followed by fine-tuning on downstream tasks has\nbecome the mainstream method in natural language processing tasks. Although\npre-trained models have the advantage of generalization, their performance may\nstill vary significantly across different domain tasks. This is because the\ndata distribution in different domains varies. For example, the different parts\nof the sentence 'He married Smt. Dipali Ghosh in 1947 and led a very happy\nmarried life' may have different impact for downstream tasks. For similarity\ncalculations, words such as 'led' and 'life' are more important. On the other\nhand, for sentiment analysis, the word 'happy' is crucial. This indicates that\ndifferent downstream tasks have different levels of sensitivity to sentence\ncomponents. Our starting point is to scale information of the model and data\naccording to the specifics of downstream tasks, enhancing domain information of\nrelevant parts for these tasks and reducing irrelevant elements for different\ndomain tasks, called SIFTER. In the experimental part, we use the SIFTER to\nimprove SimCSE by constructing positive sample pairs based on enhancing the\nsentence stem and reducing the unimportant components in the sentence, and\nmaximize the similarity between three sentences. Similarly, SIFTER can improve\nthe gate mechanism of the LSTM model by short-circuiting the input gate of\nimportant words so that the LSTM model remembers the important parts of the\nsentence. Our experiments demonstrate that SIFTER outperforms the SimCSE and\nLSTM baselines.",
        "translated": "在自然语言处理任务中，预先训练后对下游任务进行微调已成为主流方法。尽管预先训练的模型具有泛化的优势，但是它们的性能在不同的领域任务之间仍然有很大的差异。这是因为不同域中的数据分布不同。例如，句子的不同部分‘他娶了 St。1947年迪帕里 · 高希和他的妻子过着非常幸福的婚姻生活’可能会对下游的工作产生不同的影响。对于相似度计算，“ led”和“ life”这样的单词更为重要。另一方面，对于情感分析来说，“快乐”这个词是至关重要的。这表明不同的下游任务对句子成分的敏感程度不同。我们的出发点是根据下游任务的具体情况来缩放模型和数据的信息，增强这些任务相关部分的领域信息，并减少不同领域任务(称为 SIFTER)的不相关元素。在实验部分，我们利用 SIFTER 算法对 SimCSE 算法进行改进，在增强句子主干和减少句子中不重要成分的基础上构造正样本对，使三个句子之间的相似性最大化。同样，SIFTER 可以通过短路重要词的输入门来改善 LSTM 模型的门机制，从而使 LSTM 模型记住句子的重要部分。我们的实验表明，SIFTER 优于 SimCSE 和 LSTM 基线。"
    },
    {
        "title": "Solving and Generating NPR Sunday Puzzles with Large Language Models",
        "url": "http://arxiv.org/abs/2306.12255v1",
        "pub_date": "2023-06-21",
        "summary": "We explore the ability of large language models to solve and generate puzzles\nfrom the NPR Sunday Puzzle game show using PUZZLEQA, a dataset comprising 15\nyears of on-air puzzles. We evaluate four large language models using PUZZLEQA,\nin both multiple choice and free response formats, and explore two prompt\nengineering techniques to improve free response performance: chain-of-thought\nreasoning and prompt summarization. We find that state-of-the-art large\nlanguage models can solve many PUZZLEQA puzzles: the best model, GPT-3.5,\nachieves 50.2% loose accuracy. However, in our few-shot puzzle generation\nexperiment, we find no evidence that models can generate puzzles: GPT-3.5\ngenerates puzzles with answers that do not conform to the generated rules.\nPuzzle generation remains a challenging task for future work.",
        "translated": "我们使用 PUZZLEQA (一个包含15年现场拼图的数据集)来探索大型语言模型解决和生成 NPR 周日拼图游戏节目中的拼图的能力。我们使用 PUZZLEQA 评估了四种大型语言模型，包括多项选择和自由响应格式，并探索了两种提高自由响应性能的快速工程技术: 思维链推理和快速总结。我们发现最先进的大型语言模型可以解决许多 PUZZLEQA 难题: 最好的模型 GPT-3.5可以达到50.2% 的松散精度。然而，在我们的几个镜头的谜题生成实验中，我们没有发现模型可以生成谜题的证据: GPT-3.5生成的谜题的答案不符合生成的规则。生成谜题仍然是未来工作的一项具有挑战性的任务。"
    },
    {
        "title": "Bidirectional End-to-End Learning of Retriever-Reader Paradigm for\n  Entity Linking",
        "url": "http://arxiv.org/abs/2306.12245v1",
        "pub_date": "2023-06-21",
        "summary": "Entity Linking (EL) is a fundamental task for Information Extraction and\nKnowledge Graphs. The general form of EL (i.e., end-to-end EL) aims to first\nfind mentions in the given input document and then link the mentions to\ncorresponding entities in a specific knowledge base. Recently, the paradigm of\nretriever-reader promotes the progress of end-to-end EL, benefiting from the\nadvantages of dense entity retrieval and machine reading comprehension.\nHowever, the existing study only trains the retriever and the reader separately\nin a pipeline manner, which ignores the benefit that the interaction between\nthe retriever and the reader can bring to the task. To advance the\nretriever-reader paradigm to perform more perfectly on end-to-end EL, we\npropose BEER$^2$, a Bidirectional End-to-End training framework for Retriever\nand Reader. Through our designed bidirectional end-to-end training, BEER$^2$\nguides the retriever and the reader to learn from each other, make progress\ntogether, and ultimately improve EL performance. Extensive experiments on\nbenchmarks of multiple domains demonstrate the effectiveness of our proposed\nBEER$^2$.",
        "translated": "实体连接(EL)是信息抽取和知识图表的基本任务。EL (即端到端 EL)的一般形式旨在首先查找给定输入文档中的提及，然后将提及链接到特定知识库中的相应实体。最近，检索-阅读器的范例推动了端到端 EL 的发展，受益于密集实体检索和机器阅读理解的优势。然而，现有的研究只是以流水线的方式分别训练检索者和读者，忽略了检索者和读者之间的交互可以给任务带来的好处。为了提高检索器-阅读器模式在端到端 EL 上的性能，我们提出了 BEER $^ 2 $，一个针对检索器和阅读器的双向端到端培训框架。通过我们设计的端到端双向培训，BEER $^ 2 $引导检索器和读取器相互学习，共同进步，最终提高 EL 性能。对多个领域的基准的广泛实验证明了我们提出的 BEER $^ 2 $的有效性。"
    },
    {
        "title": "Limits for Learning with Language Models",
        "url": "http://arxiv.org/abs/2306.12213v1",
        "pub_date": "2023-06-21",
        "summary": "With the advent of large language models (LLMs), the trend in NLP has been to\ntrain LLMs on vast amounts of data to solve diverse language understanding and\ngeneration tasks. The list of LLM successes is long and varied. Nevertheless,\nseveral recent papers provide empirical evidence that LLMs fail to capture\nimportant aspects of linguistic meaning. Focusing on universal quantification,\nwe provide a theoretical foundation for these empirical findings by proving\nthat LLMs cannot learn certain fundamental semantic properties including\nsemantic entailment and consistency as they are defined in formal semantics.\nMore generally, we show that LLMs are unable to learn concepts beyond the first\nlevel of the Borel Hierarchy, which imposes severe limits on the ability of\nLMs, both large and small, to capture many aspects of linguistic meaning. This\nmeans that LLMs will continue to operate without formal guarantees on tasks\nthat require entailments and deep linguistic understanding.",
        "translated": "随着大型语言模型(LLM)的出现，自然语言处理(NLP)的发展趋势是在大量数据上训练 LLM，以解决不同的语言理解和生成任务。LLM 的成功之处是多种多样的。尽管如此，最近的几篇论文提供了经验证明，认为 LLM 未能捕捉到语言意义的重要方面。关注全称量化，我们为这些实证研究结果提供了一个理论基础，通过证明 LLM 不能学习某些基本的语义属性，包括语义蕴含和一致性，因为它们是在形式语义学中定义的。更一般地，我们表明，长期语言模型无法学习概念超出第一层次的 Borel 层次，这对长期语言模型的能力，无论大小，捕捉语言意义的许多方面施加了严重的限制。这意味着 LLM 将继续在没有正式保证的情况下运行，而这些任务需要蕴含和深刻的语言理解。"
    },
    {
        "title": "Investigating Pre-trained Language Models on Cross-Domain Datasets, a\n  Step Closer to General AI",
        "url": "http://arxiv.org/abs/2306.12205v1",
        "pub_date": "2023-06-21",
        "summary": "Pre-trained language models have recently emerged as a powerful tool for\nfine-tuning a variety of language tasks. Ideally, when models are pre-trained\non large amount of data, they are expected to gain implicit knowledge. In this\npaper, we investigate the ability of pre-trained language models to generalize\nto different non-language tasks. In particular, we test them on tasks from\ndifferent domains such as computer vision, reasoning on hierarchical data, and\nprotein fold prediction. The four pre-trained models that we used, T5, BART,\nBERT, and GPT-2 achieve outstanding results. They all have similar performance\nand they outperform transformers that are trained from scratch by a large\nmargin. For instance, pre-trained language models perform better on the Listops\ndataset, with an average accuracy of 58.7\\%, compared to transformers trained\nfrom scratch, which have an average accuracy of 29.0\\%. The significant\nimprovement demonstrated across three types of datasets suggests that\npre-training on language helps the models to acquire general knowledge,\nbringing us a step closer to general AI. We also showed that reducing the\nnumber of parameters in pre-trained language models does not have a great\nimpact as the performance drops slightly when using T5-Small instead of\nT5-Base. In fact, when using only 2\\% of the parameters, we achieved a great\nimprovement compared to training from scratch. Finally, in contrast to prior\nwork, we find out that using pre-trained embeddings for the input layer is\nnecessary to achieve the desired results.",
        "translated": "预先训练的语言模型最近已经成为微调各种语言任务的强大工具。理想情况下，当模型在大量数据上进行预训练时，它们应该获得隐含的知识。本文研究了预训练语言模型对不同非语言任务的概括能力。特别是，我们在不同领域的任务中测试它们，例如计算机视觉、层次数据推理和蛋白质折叠预测。我们使用的四个预先训练的模型，T5、 BART、 BERT 和 GPT-2都取得了显著的效果。他们都有相似的性能，他们的表现优于变压器，从零开始训练的大幅度差距。例如，预先训练的语言模型在 Listops 数据集上表现得更好，平均准确率为58.7% ，而从头开始训练的变压器的平均准确率为29.0% 。三类数据集的显著改进表明，语言预训练有助于模型获得一般知识，使我们更接近一般人工智能。我们还发现，减少预训练语言模型中的参数数量不会产生很大的影响，因为当使用 T5-Small 而不是 T5-Base 时，性能会略有下降。事实上，当只使用2% 的参数时，与从头开始训练相比，我们取得了很大的进步。最后，与之前的工作相比，我们发现对输入层使用预训练嵌入对于达到预期的结果是必要的。"
    },
    {
        "title": "Data augmentation for recommender system: A semi-supervised approach\n  using maximum margin matrix factorization",
        "url": "http://arxiv.org/abs/2306.13050v1",
        "pub_date": "2023-06-22",
        "summary": "Collaborative filtering (CF) has become a popular method for developing\nrecommender systems (RS) where ratings of a user for new items is predicted\nbased on her past preferences and available preference information of other\nusers. Despite the popularity of CF-based methods, their performance is often\ngreatly limited by the sparsity of observed entries. In this study, we explore\nthe data augmentation and refinement aspects of Maximum Margin Matrix\nFactorization (MMMF), a widely accepted CF technique for the rating\npredictions, which have not been investigated before. We exploit the inherent\ncharacteristics of CF algorithms to assess the confidence level of individual\nratings and propose a semi-supervised approach for rating augmentation based on\nself-training. We hypothesize that any CF algorithm's predictions with low\nconfidence are due to some deficiency in the training data and hence, the\nperformance of the algorithm can be improved by adopting a systematic data\naugmentation strategy. We iteratively use some of the ratings predicted with\nhigh confidence to augment the training data and remove low-confidence entries\nthrough a refinement process. By repeating this process, the system learns to\nimprove prediction accuracy. Our method is experimentally evaluated on several\nstate-of-the-art CF algorithms and leads to informative rating augmentation,\nimproving the performance of the baseline approaches.",
        "translated": "推荐协同过滤(CF)已经成为开发推荐系统(RS)的一种流行方法，在这种系统中，用户对新项目的评分可以根据其过去的偏好和其他用户的可用偏好信息进行预测。尽管基于 CF 的方法很流行，但是它们的性能常常受到观察条目稀疏性的极大限制。在这项研究中，我们探讨了最大保证金矩阵分解(MMMF)的数据增强和细化方面，这是一种被广泛接受的用于评级预测的 CF 技术，以前从未被研究过。我们利用 CF 算法的固有特性来评估个体评分的置信水平，提出了一种基于自训练的评分增强半监督方法。我们假设任何 CF 算法的低置信度预测都是由于训练数据中的某些缺陷造成的，因此，通过采用系统的数据增强策略可以提高算法的性能。我们迭代地使用一些高置信度预测值来增加训练数据，并通过一个细化过程去除低置信度条目。通过重复这个过程，系统学会提高预测的准确性。我们的方法在几个最先进的 CF 算法上进行了实验评估，导致了信息量的增加，提高了基线方法的性能。"
    },
    {
        "title": "Efficient Partitioning Method of Large-Scale Public Safety\n  Spatio-Temporal Data based on Information Loss Constraints",
        "url": "http://arxiv.org/abs/2306.12857v1",
        "pub_date": "2023-06-22",
        "summary": "The storage, management, and application of massive spatio-temporal data are\nwidely applied in various practical scenarios, including public safety.\nHowever, due to the unique spatio-temporal distribution characteristics of\nre-al-world data, most existing methods have limitations in terms of the\nspatio-temporal proximity of data and load balancing in distributed storage.\nThere-fore, this paper proposes an efficient partitioning method of large-scale\npublic safety spatio-temporal data based on information loss constraints\n(IFL-LSTP). The IFL-LSTP model specifically targets large-scale spatio-temporal\npoint da-ta by combining the spatio-temporal partitioning module (STPM) with\nthe graph partitioning module (GPM). This approach can significantly reduce the\nscale of data while maintaining the model's accuracy, in order to improve the\npartitioning efficiency. It can also ensure the load balancing of distributed\nstorage while maintaining spatio-temporal proximity of the data partitioning\nresults. This method provides a new solution for distributed storage of\nmas-sive spatio-temporal data. The experimental results on multiple real-world\nda-tasets demonstrate the effectiveness and superiority of IFL-LSTP.",
        "translated": "海量时空数据的存储、管理和应用广泛应用于各种实际场景，包括公共安全。然而，由于现实世界数据独特的时空分布特性，现有的方法在数据的时空接近性和分布式存储中的负载均衡方面存在局限性。因此，本文提出了一种基于信息丢失约束的大规模公共安全时空数据有效分割方法(IFL-LSTP)。IFL-LSTP 模型通过将时空分区模块(STPM)与图分区模块(GPM)相结合，专门针对大规模的时空点数据。该方法可以在保持模型精度的同时显著降低数据规模，从而提高分区效率。在保持数据分区结果的时空接近性的同时，还可以保证分布式存储的负载平衡。该方法为海量时空数据的分布式存储提供了一种新的解决方案。在多个实际数据集上的实验结果表明了 IFL-LSTP 的有效性和优越性。"
    },
    {
        "title": "HypeRS: Building a Hypergraph-driven ensemble Recommender System",
        "url": "http://arxiv.org/abs/2306.12800v1",
        "pub_date": "2023-06-22",
        "summary": "Recommender systems are designed to predict user preferences over collections\nof items. These systems process users' previous interactions to decide which\nitems should be ranked higher to satisfy their desires. An ensemble recommender\nsystem can achieve great recommendation performance by effectively combining\nthe decisions generated by individual models. In this paper, we propose a novel\nensemble recommender system that combines predictions made by different models\ninto a unified hypergraph ranking framework. This is the first time that\nhypergraph ranking has been employed to model an ensemble of recommender\nsystems. Hypergraphs are generalizations of graphs where multiple vertices can\nbe connected via hyperedges, efficiently modeling high-order relations. We\ndifferentiate real and predicted connections between users and items by\nassigning different hyperedge weights to individual recommender systems. We\nperform experiments using four datasets from the fields of movie, music and\nnews media recommendation. The obtained results show that the ensemble\nhypergraph ranking method generates more accurate recommendations compared to\nthe individual models and a weighted hybrid approach. The assignment of\ndifferent hyperedge weights to the ensemble hypergraph further improves the\nperformance compared to a setting with identical hyperedge weights.",
        "translated": "推荐系统的目的是预测用户对项目集合的偏好。这些系统处理用户以前的交互，以决定哪些项目应该排名更高，以满足他们的愿望。一个集合推荐系统可以通过有效地结合单个模型产生的决策来实现很好的推荐性能。在这篇文章中，我们提出了一个新的集合推荐系统，它将不同模型的预测结合到一个统一的超图排序框架中。这是第一次使用超图排序来模拟推荐系统的集合。超图是通过超边连接多个顶点的图的推广，它有效地建立了高阶关系。我们通过为各个推荐系统分配不同的超边缘权重来区分用户和项目之间真实的和预测的联系。我们使用来自电影、音乐和新闻媒体推荐领域的四个数据集进行实验。结果表明，与单个模型和加权混合方法相比，集合超图排序方法能够产生更精确的推荐值。与具有相同超边权的设置相比，向集合超图分配不同的超边权进一步提高了性能。"
    },
    {
        "title": "On the Robustness of Generative Retrieval Models: An Out-of-Distribution\n  Perspective",
        "url": "http://arxiv.org/abs/2306.12756v1",
        "pub_date": "2023-06-22",
        "summary": "Recently, we have witnessed generative retrieval increasingly gaining\nattention in the information retrieval (IR) field, which retrieves documents by\ndirectly generating their identifiers. So far, much effort has been devoted to\ndeveloping effective generative retrieval models. There has been less attention\npaid to the robustness perspective. When a new retrieval paradigm enters into\nthe real-world application, it is also critical to measure the\nout-of-distribution (OOD) generalization, i.e., how would generative retrieval\nmodels generalize to new distributions. To answer this question, firstly, we\ndefine OOD robustness from three perspectives in retrieval problems: 1) The\nquery variations; 2) The unforeseen query types; and 3) The unforeseen tasks.\nBased on this taxonomy, we conduct empirical studies to analyze the OOD\nrobustness of several representative generative retrieval models against dense\nretrieval models. The empirical results indicate that the OOD robustness of\ngenerative retrieval models requires enhancement. We hope studying the OOD\nrobustness of generative retrieval models would be advantageous to the IR\ncommunity.",
        "translated": "最近，我们看到生成检索越来越受到信息检索(IR)领域的关注，它通过直接生成文档的标识符来检索文档。到目前为止，已经投入了大量的精力来开发有效的生成检索模型。人们对健壮性视角的关注较少。当一个新的检索范式进入现实世界的应用程序时，衡量分布外(OOD)泛化也是至关重要的，也就是说，生成检索模型如何泛化到新的分布。为了回答这个问题，我们首先从检索问题的三个方面定义了面向对象的鲁棒性: 1)查询变量; 2)不可预见的查询类型; 3)不可预见的任务。在此基础上，我们进行了实证研究，分析了几个代表性的生成检索模型对密集检索模型的面向对象的鲁棒性。实证结果表明，生成检索模型的面向对象的鲁棒性有待提高。我们希望研究生成式检索模型的面向对象的鲁棒性能对信息检索界有所帮助。"
    },
    {
        "title": "Vec2Vec: A Compact Neural Network Approach for Transforming Text\n  Embeddings with High Fidelity",
        "url": "http://arxiv.org/abs/2306.12689v1",
        "pub_date": "2023-06-22",
        "summary": "Vector embeddings have become ubiquitous tools for many language-related\ntasks. A leading embedding model is OpenAI's text-ada-002 which can embed\napproximately 6,000 words into a 1,536-dimensional vector. While powerful,\ntext-ada-002 is not open source and is only available via API. We trained a\nsimple neural network to convert open-source 768-dimensional MPNet embeddings\ninto text-ada-002 embeddings. We compiled a subset of 50,000 online food\nreviews. We calculated MPNet and text-ada-002 embeddings for each review and\ntrained a simple neural network to for 75 epochs. The neural network was\ndesigned to predict the corresponding text-ada-002 embedding for a given MPNET\nembedding. Our model achieved an average cosine similarity of 0.932 on 10,000\nunseen reviews in our held-out test dataset. We manually assessed the quality\nof our predicted embeddings for vector search over text-ada-002-embedded\nreviews. While not as good as real text-ada-002 embeddings, predicted\nembeddings were able to retrieve highly relevant reviews. Our final model,\nVec2Vec, is lightweight (&lt;80 MB) and fast. Future steps include training a\nneural network with a more sophisticated architecture and a larger dataset of\npaired embeddings to achieve greater performance. The ability to convert\nbetween and align embedding spaces may be helpful for interoperability,\nlimiting dependence on proprietary models, protecting data privacy, reducing\ncosts, and offline operations.",
        "translated": "向量嵌入已经成为许多语言相关任务的普遍工具。一个领先的嵌入模型是 OpenAI 的 text-ada-002，它可以将大约6,000个单词嵌入到1,536维的向量中。Text-ada-002虽然功能强大，但它不是开源的，只能通过 API 使用。我们训练了一个简单的神经网络来将开源的768维 MPNet 嵌入转换为 text-ada-002嵌入。我们收集了50,000份在线食品评论。我们计算了每个评论的 MPNet 和 text-ada-002嵌入，并将一个简单的神经网络训练到75个时代。针对给定的 MPNET 嵌入，设计神经网络对相应的 text-ada-002嵌入进行预测。在我们的测试数据集中，我们的模型在10,000个看不见的评论上达到了0.932的平均余弦距离。我们通过 text-ada-002嵌入式评论手动评估了我们预测的向量搜索嵌入的质量。虽然不如真正的 text-ada-002嵌入，但预测的嵌入能够检索高度相关的评论。我们最终的模型 Vec2Vec 是轻量级的(< 80MB)并且速度很快。未来的步骤包括训练具有更复杂结构和更大的配对嵌入数据集的神经网络，以实现更好的性能。在嵌入空间之间进行转换和对齐的能力可能有助于实现互操作性、限制对专有模型的依赖、保护数据隐私、降低成本和离线操作。"
    },
    {
        "title": "Semi-automated extraction of research topics and trends from NCI funding\n  in radiological sciences from 2000-2020",
        "url": "http://arxiv.org/abs/2306.13075v1",
        "pub_date": "2023-06-22",
        "summary": "Investigators, funders, and the public desire knowledge on topics and trends\nin publicly funded research but current efforts in manual categorization are\nlimited in scale and understanding. We developed a semi-automated approach to\nextract and name research topics, and applied this to \\$1.9B of NCI funding\nover 21 years in the radiological sciences to determine micro- and macro-scale\nresearch topics and funding trends. Our method relies on sequential clustering\nof existing biomedical-based word embeddings, naming using subject matter\nexperts, and visualization to discover trends at a macroscopic scale above\nindividual topics. We present results using 15 and 60 cluster topics, where we\nfound that 2D projection of grant embeddings reveals two dominant axes:\nphysics-biology and therapeutic-diagnostic. For our dataset, we found that\nfunding for therapeutics- and physics-based research have outpaced diagnostics-\nand biology-based research, respectively. We hope these results may (1) give\ninsight to funders on the appropriateness of their funding allocation, (2)\nassist investigators in contextualizing their work and explore neighboring\nresearch domains, and (3) allow the public to review where their tax dollars\nare being allocated.",
        "translated": "研究人员、资助者和公众希望了解公共资助研究的主题和趋势，但目前在人工分类方面的努力在规模和理解方面受到限制。我们开发了一种半自动化的方法来提取和命名研究主题，并将其应用于21年来 NCI 在放射科学领域的19亿美元资金，以确定微观和宏观研究主题和资金趋势。我们的方法依赖于现有的基于生物医学的单词嵌入的顺序聚类，使用主题专家命名，以及可视化来发现在个别主题之上的宏观趋势。我们使用15和60个聚类主题展示结果，其中我们发现赠款嵌入的二维投影揭示了两个主要轴: 物理-生物学和治疗-诊断。对于我们的数据集，我们发现基于治疗学和物理学的研究经费分别超过了基于诊断学和基于生物学的研究。我们希望这些结果可以(1)让资助者了解他们资金分配的适当性，(2)帮助调查人员将他们的工作背景化，并探索相邻的研究领域，(3)允许公众审查他们的税款分配在哪里。"
    },
    {
        "title": "Can LLMs Express Their Uncertainty? An Empirical Evaluation of\n  Confidence Elicitation in LLMs",
        "url": "http://arxiv.org/abs/2306.13063v1",
        "pub_date": "2023-06-22",
        "summary": "The task of empowering large language models (LLMs) to accurately express\ntheir confidence, referred to as confidence elicitation, is essential in\nensuring reliable and trustworthy decision-making processes. Previous methods,\nwhich primarily rely on model logits, have become less suitable for LLMs and\neven infeasible with the rise of closed-source LLMs (e.g., commercialized LLM\nAPIs). This leads to a growing need to explore the untapped area of\n\\emph{non-logit-based} approaches to estimate the uncertainty of LLMs. Hence,\nin this study, we investigate approaches for confidence elicitation that do not\nrequire model fine-tuning or access to proprietary information. We introduce\nthree categories of methods: verbalize-based, consistency-based, and their\nhybrid methods for benchmarking, and evaluate their performance across five\ntypes of datasets and four widely-used LLMs. Our analysis of these methods\nuncovers several key insights: 1) LLMs often exhibit a high degree of\noverconfidence when verbalizing their confidence; 2) Prompting strategies such\nas CoT, Top-K and Multi-step confidences improve calibration of verbalized\nconfidence; 3) Consistency-based methods outperform the verbalized confidences\nin most cases, with particularly notable improvements on the arithmetic\nreasoning task; 4) Hybrid methods consistently deliver the best performance\nover their baselines, thereby emerging as a promising state-of-the-art\napproach; 5) Despite these advancements, all investigated methods continue to\nstruggle with challenging tasks, such as those requiring professional\nknowledge, leaving significant scope for improvement of confidence elicitation.",
        "translated": "授权大型语言模型(LLM)准确表达其置信度(称为置信度激发)的任务对于确保可靠和可信的决策过程至关重要。以前的方法，主要依赖于模型 logit，已经变得不太适合 LLM，甚至随着封闭源 LLM (例如，商业化 LLM API)的兴起而变得不可行。这导致人们越来越需要探索 emph { non-logit-based }方法中尚未开发的领域来估计 LLM 的不确定性。因此，在这项研究中，我们调查了不需要模型微调或访问专有信息的信心获取方法。我们介绍了三类方法: 基于语言的、基于一致性的和它们的混合基准测试方法，并且评估了它们在五种类型的数据集和四种广泛使用的 LLM 中的性能。我们对这些方法的分析揭示了几个关键的见解: 1) LLM 在表达他们的信心时经常表现出高度的过度自信; 2)提示策略，如 CoT，Top-K 和 Multi-step 置信度改善了口头置信度的校准; 3)基于一致性的方法在大多数情况下优于口头置信度，在算术推理任务上有特别显着的改善; 4)混合方法始终在其基线上提供最佳性能，从而成为一种有希望的最先进的方法; 5)尽管有这些进步，所有被调查的方法继续与具有挑战性的任务斗争，例如那些需要专业知识的任务，留下显着的提高。"
    },
    {
        "title": "Named entity recognition in resumes",
        "url": "http://arxiv.org/abs/2306.13062v1",
        "pub_date": "2023-06-22",
        "summary": "Named entity recognition (NER) is used to extract information from various\ndocuments and texts such as names and dates. It is important to extract\neducation and work experience information from resumes in order to filter them.\nConsidering the fact that all information in a resume has to be entered to the\ncompanys system manually, automatizing this process will save time of the\ncompanies. In this study, a deep learning-based semi-automatic named entity\nrecognition system has been implemented with a focus on resumes in the field of\nIT. Firstly, resumes of employees from five different IT related fields has\nbeen annotated. Six transformer based pre-trained models have been adapted to\nnamed entity recognition problem using the annotated data. These models have\nbeen selected among popular models in the natural language processing field.\nThe obtained system can recognize eight different entity types which are city,\ndate, degree, diploma major, job title, language, country and skill. Models\nused in the experiments are compared using micro, macro and weighted F1 scores\nand the performance of the methods was evaluated. Taking these scores into\naccount for test set the best micro and weighted F1 score is obtained by\nRoBERTa and the best macro F1 score is obtained by Electra model.",
        "translated": "命名实体识别(NER)用于从各种文档和文本(如姓名和日期)中提取信息。从简历中提取教育和工作经验信息，对简历进行过滤是非常重要的。考虑到简历中的所有信息都必须手动输入到公司系统中，这个过程的自动化将节省公司的时间。本文以 IT 领域的简历为研究对象，实现了一个基于深度学习的半自动命名实体识别系统。首先，对来自五个不同 IT 相关领域的员工的简历进行了注释。针对基于注释数据的命名实体识别问题，提出了六种基于变压器的预训练模型。这些模型已经被自然语言处理领域的流行模型所选择。所获得的系统可以识别城市、日期、学位、文凭专业、职称、语言、国家和技能等八种不同的实体类型。利用微观、宏观和加权 F1评分对实验中使用的模型进行了比较，并对方法的性能进行了评价。将这些得分考虑进测试集，用 RoBERTa 得到最佳微观和加权 F1得分，用 Electra 模型得到最佳宏观 F1得分。"
    },
    {
        "title": "CamChoice: A Corpus of Multiple Choice Questions and Candidate Response\n  Distributions",
        "url": "http://arxiv.org/abs/2306.13047v1",
        "pub_date": "2023-06-22",
        "summary": "Multiple Choice examinations are a ubiquitous form of assessment that is used\nto measure the ability of candidates across various domains and tasks.\nMaintaining the quality of proposed questions is of great importance to test\ndesigners, and therefore newly proposed questions go through several pre-test\nevaluation stages before they can be deployed into real-world exams. This\nprocess is currently quite manual, which can lead to time lags in the question\ndevelopment cycle. Automating this process would lead to a large improvement in\nefficiency, however, current datasets do not contain sufficient pre-test\nanalysis information. In this paper, we introduce CamChoice; a multiple-choice\ncomprehension dataset with questions at different target levels, where\nquestions have the true candidate selected options distributions. We introduce\nthe task of candidate distribution matching, propose several evaluation metrics\nfor the task, and demonstrate that automatic systems trained on RACE++ can be\nleveraged as baselines for our task. We further demonstrate that these\nautomatic systems can be used for practical pre-test evaluation tasks such as\ndetecting underperforming distractors, where our detection systems can\nautomatically identify poor distractors that few candidates select. We release\nthe data publicly for future research.",
        "translated": "多项选择考试是一种普遍存在的评估形式，用于衡量候选人在不同领域和任务的能力。保持试题的质量对于考试设计人员来说是非常重要的，因此新提出的试题要经过几个试题前的评估阶段才能应用到现实考试中。这个过程目前是相当手工的，这可能会导致问题开发周期中的时间滞后。自动化这个过程将导致效率的大幅度提高，但是，目前的数据集不包含足够的预测试分析信息。在本文中，我们介绍了 CamChoice，这是一个多项选择理解数据集，包含不同目标层次的问题，其中问题具有真实的候选选项分布。我们介绍了候选分布匹配的任务，提出了该任务的几个评价指标，并证明了基于 RACE + + 的自动系统可以作为我们的任务的基线。我们进一步证明这些自动系统可以用于实际的测试前评估任务，例如检测表现不佳的干扰物，我们的检测系统可以自动识别很少候选人选择的差的干扰物。我们公开这些数据以便将来研究。"
    },
    {
        "title": "Towards Explainable Evaluation Metrics for Machine Translation",
        "url": "http://arxiv.org/abs/2306.13041v1",
        "pub_date": "2023-06-22",
        "summary": "Unlike classical lexical overlap metrics such as BLEU, most current\nevaluation metrics for machine translation (for example, COMET or BERTScore)\nare based on black-box large language models. They often achieve strong\ncorrelations with human judgments, but recent research indicates that the\nlower-quality classical metrics remain dominant, one of the potential reasons\nbeing that their decision processes are more transparent. To foster more\nwidespread acceptance of novel high-quality metrics, explainability thus\nbecomes crucial. In this concept paper, we identify key properties as well as\nkey goals of explainable machine translation metrics and provide a\ncomprehensive synthesis of recent techniques, relating them to our established\ngoals and properties. In this context, we also discuss the latest\nstate-of-the-art approaches to explainable metrics based on generative models\nsuch as ChatGPT and GPT4. Finally, we contribute a vision of next-generation\napproaches, including natural language explanations. We hope that our work can\nhelp catalyze and guide future research on explainable evaluation metrics and,\nmediately, also contribute to better and more transparent machine translation\nsystems.",
        "translated": "与经典的词汇重叠度量(如 BLEU)不同，目前大多数机器翻译评估度量(如 COMET 或 BERTScore)都基于黑盒大语言模型。它们往往与人类的判断有很强的相关性，但最近的研究表明，质量较低的经典指标仍然占主导地位，其中一个潜在的原因是它们的决策过程更加透明。为了促进更广泛地接受新颖的高质量度量，可解释性因此变得至关重要。在这篇概念文章中，我们确定了可解释的机器翻译度量的关键性质和关键目标，并提供了一个综合性的最新技术，它们与我们建立的目标和性质相关联。在这个上下文中，我们还讨论了基于 ChatGPT 和 GPT4等生成模型的可解释度量的最新技术。最后，我们展望了下一代方法，包括自然语言解释。我们希望我们的工作能够有助于促进和指导今后关于可解释的评估指标的研究，并且在中间阶段，还有助于更好和更透明的机器翻译系统。"
    },
    {
        "title": "Apolitical Intelligence? Auditing Delphi's responses on controversial\n  political issues in the US",
        "url": "http://arxiv.org/abs/2306.13000v1",
        "pub_date": "2023-06-22",
        "summary": "As generative language models are deployed in ever-wider contexts, concerns\nabout their political values have come to the forefront with critique from all\nparts of the political spectrum that the models are biased and lack neutrality.\nHowever, the question of what neutrality is and whether it is desirable remains\nunderexplored. In this paper, I examine neutrality through an audit of Delphi\n[arXiv:2110.07574], a large language model designed for crowdsourced ethics. I\nanalyse how Delphi responds to politically controversial questions compared to\ndifferent US political subgroups. I find that Delphi is poorly calibrated with\nrespect to confidence and exhibits a significant political skew. Based on these\nresults, I examine the question of neutrality from a data-feminist lens, in\nterms of how notions of neutrality shift power and further marginalise unheard\nvoices. These findings can hopefully contribute to a more reflexive debate\nabout the normative questions of alignment and what role we want generative\nmodels to play in society.",
        "translated": "随着生成语言模型被应用于更广泛的环境中，人们对其政治价值观的担忧已成为当务之急，政治光谱各方纷纷批评这些模型存在偏见，缺乏中立性。然而，什么是中立以及中立是否可取的问题仍然没有得到充分的探讨。在本文中，我通过对 Delphi [ arXiv: 2110.07574]的审计来检验中立性，这是一个为众包伦理学设计的大型语言模型。我分析了德尔菲如何回应政治上有争议的问题，并与美国不同的政治分组进行了比较。我发现，德尔福在信心方面的标准很差，而且显示出明显的政治倾斜。基于这些结果，我从数据女权主义的角度来审视中立的问题，中立的概念如何转移权力并进一步边缘化未被听到的声音。这些研究结果有望有助于就协调一致的规范性问题以及我们希望生成模式在社会中发挥什么作用进行更自反性的辩论。"
    },
    {
        "title": "Speech Emotion Diarization: Which Emotion Appears When?",
        "url": "http://arxiv.org/abs/2306.12991v1",
        "pub_date": "2023-06-22",
        "summary": "Speech Emotion Recognition (SER) typically relies on utterance-level\nsolutions. However, emotions conveyed through speech should be considered as\ndiscrete speech events with definite temporal boundaries, rather than\nattributes of the entire utterance. To reflect the fine-grained nature of\nspeech emotions, we propose a new task: Speech Emotion Diarization (SED). Just\nas Speaker Diarization answers the question of \"Who speaks when?\", Speech\nEmotion Diarization answers the question of \"Which emotion appears when?\". To\nfacilitate the evaluation of the performance and establish a common benchmark\nfor researchers, we introduce the Zaion Emotion Dataset (ZED), an openly\naccessible speech emotion dataset that includes non-acted emotions recorded in\nreal-life conditions, along with manually-annotated boundaries of emotion\nsegments within the utterance. We provide competitive baselines and open-source\nthe code and the pre-trained models.",
        "translated": "语音情感识别(SER)通常依赖于话语级别的解决方案。然而，通过言语传达的情感应被视为具有明确的时间界限的离散的言语事件，而不是整个话语的属性。为了反映言语情绪的细粒度特性，我们提出了一个新的任务: 言语情绪日化(SED)。正如“说话人日历化”回答了“谁在什么时候说话”这个问题一样言语情感日化回答了“什么情感在什么时候出现?”.为了便于评估表现，并为研究人员建立一个共同的基准，我们引入了 Zaion 情绪数据集(ZED) ，这是一个开放访问的语音情绪数据集，包括在现实生活条件下记录的非行为情绪，以及在话语中手动注释的情绪段的边界。我们提供有竞争力的基线和开源的代码和预先训练的模型。"
    },
    {
        "title": "Conversation Derailment Forecasting with Graph Convolutional Networks",
        "url": "http://arxiv.org/abs/2306.12982v1",
        "pub_date": "2023-06-22",
        "summary": "Online conversations are particularly susceptible to derailment, which can\nmanifest itself in the form of toxic communication patterns like disrespectful\ncomments or verbal abuse. Forecasting conversation derailment predicts signs of\nderailment in advance enabling proactive moderation of conversations. Current\nstate-of-the-art approaches to address this problem rely on sequence models\nthat treat dialogues as text streams. We propose a novel model based on a graph\nconvolutional neural network that considers dialogue user dynamics and the\ninfluence of public perception on conversation utterances. Through empirical\nevaluation, we show that our model effectively captures conversation dynamics\nand outperforms the state-of-the-art models on the CGA and CMV benchmark\ndatasets by 1.5\\% and 1.7\\%, respectively.",
        "translated": "在线对话特别容易出轨，这可能表现为有毒的交流模式，如无礼的评论或口头辱骂。预测会话脱轨可以提前预测脱轨的迹象，从而能够主动调节会话。目前解决这个问题的最先进的方法依赖于将对话视为文本流的序列模型。我们提出了一个基于图形卷积神经网络的新模型，该模型考虑了对话使用者的动态变化以及公众认知对会话话语的影响。通过实证评估，我们发现我们的模型有效地捕获了会话动态，并且在 CGA 和 CMV 基准数据集上分别优于最先进的模型1.5% 和1.7% 。"
    },
    {
        "title": "Tracking public attitudes toward ChatGPT on Twitter using sentiment\n  analysis and topic modeling",
        "url": "http://arxiv.org/abs/2306.12951v1",
        "pub_date": "2023-06-22",
        "summary": "ChatGPT sets a new record with the fastest-growing user base, as a chatbot\npowered by a large language model (LLM). While it demonstrates state-of-the-art\ncapabilities in a variety of language-generating tasks, it also raises\nwidespread public concerns regarding its societal impact. In this paper, we\nutilize natural language processing approaches to investigate the public\nattitudes towards ChatGPT by applying sentiment analysis and topic modeling\ntechniques to Twitter data. Our result shows that the overall sentiment is\nlargely neutral to positive, which also holds true across different occupation\ngroups. Among a wide range of topics mentioned in tweets, the most popular\ntopics are Artificial Intelligence, Search Engines, Education, Writing, and\nQuestion Answering.",
        "translated": "ChatGPT 作为一个由大型语言模型(LLM)驱动的聊天机器人，用增长最快的用户群创建了一个新的记录。虽然它在各种语言生成任务中展示了最先进的能力，但它也引起了公众对其社会影响的广泛关注。本文利用自然语言处理方法，通过对 Twitter 数据的情感分析和主题建模技术，研究公众对 ChatGPT 的态度。我们的结果表明，总体情绪在很大程度上是中性至积极的，这也适用于不同的职业群体。在众多的话题中，最受欢迎的话题是人工智能、搜索引擎、教育、写作和问答。"
    },
    {
        "title": "Quantizable Transformers: Removing Outliers by Helping Attention Heads\n  Do Nothing",
        "url": "http://arxiv.org/abs/2306.12929v1",
        "pub_date": "2023-06-22",
        "summary": "Transformer models have been widely adopted in various domains over the last\nyears, and especially large language models have advanced the field of AI\nsignificantly. Due to their size, the capability of these networks has\nincreased tremendously, but this has come at the cost of a significant increase\nin necessary compute. Quantization is one of the most effective ways to reduce\nthe computational time and memory consumption of neural networks. Many studies\nhave shown, however, that modern transformer models tend to learn strong\noutliers in their activations, making them difficult to quantize. To retain\nacceptable performance, the existence of these outliers requires activations to\nbe in higher bitwidth or the use of different numeric formats, extra\nfine-tuning, or other workarounds. We show that strong outliers are related to\nvery specific behavior of attention heads that try to learn a \"no-op\" or just a\npartial update of the residual. To achieve the exact zeros needed in the\nattention matrix for a no-update, the input to the softmax is pushed to be\nlarger and larger during training, causing outliers in other parts of the\nnetwork. Based on these observations, we propose two simple (independent)\nmodifications to the attention mechanism - clipped softmax and gated attention.\nWe empirically show that models pre-trained using our methods learn\nsignificantly smaller outliers while maintaining and sometimes even improving\nthe floating-point task performance. This enables us to quantize transformers\nto full INT8 quantization of the activations without any additional effort. We\ndemonstrate the effectiveness of our methods on both language models (BERT,\nOPT) and vision transformers.",
        "translated": "近年来，变压器模型在各个领域得到了广泛的应用，尤其是大型语言模型的应用极大地推动了人工智能的发展。由于它们的规模，这些网络的能力已经大大增加，但这是以必要的计算能力显著增加为代价的。量化是减少神经网络计算时间和内存消耗的有效方法之一。然而，许多研究表明，现代变压器模型往往学习强烈的异常值在其激活，使他们难以量化。为了保持可接受的性能，这些异常值的存在要求激活具有更高的位宽或使用不同的数字格式、额外的微调或其他变通方法。我们发现强异常值与注意力集中的非常具体的行为有关，这些行为试图学习一个“不可操作”或仅仅是残差的部分更新。为了获得注意矩阵中无更新所需的精确零点，在训练过程中，向软极大的输入被推得越来越大，从而在网络的其他部分产生异常值。基于这些观察，我们提出了两个简单的(独立的)修正注意机制-剪切软最大和门控注意。我们的经验表明，使用我们的方法预训练的模型学习显着较小的异常值，同时维护，有时甚至提高浮点任务的性能。这使我们能够量化变压器，以充分的 INT8量化的激活没有任何额外的努力。我们证明了我们的方法在语言模型(BERT，OPT)和视觉转换器上的有效性。"
    },
    {
        "title": "Fuzzification-based Feature Selection for Enhanced Website Content\n  Encryption",
        "url": "http://arxiv.org/abs/2306.13548v1",
        "pub_date": "2023-06-23",
        "summary": "We propose a novel approach that utilizes fuzzification theory to perform\nfeature selection on website content for encryption purposes. Our objective is\nto identify and select the most relevant features from the website by\nharnessing the principles of fuzzy logic. Fuzzification allows us to transform\nthe crisp website content into fuzzy representations, enabling a more nuanced\nanalysis of their characteristics. By considering the degree of membership of\neach feature in different fuzzy categories, we can evaluate their importance\nand relevance for encryption. This approach enables us to prioritize and focus\non the features that exhibit higher membership degrees, indicating their\nsignificance in the encryption process. By employing fuzzification-based\nfeature selection, we aim to enhance the effectiveness and efficiency of\nwebsite content encryption, ultimately improving the overall internet security.",
        "translated": "我们提出了一种新的方法，利用模糊化理论对网站内容进行特征选择，以达到加密的目的。我们的目标是通过利用模糊逻辑的原则，从网站中识别和选择最相关的特性。模糊化允许我们将清晰的网站内容转换为模糊表示，从而能够对其特征进行更细致入微的分析。通过考虑每个特征在不同模糊类别中的隶属度，我们可以评估它们对加密的重要性和相关性。这种方法使我们能够优先考虑和关注那些表现出更高的成员等级的特征，表明它们在加密过程中的重要性。采用基于模糊化的特征选择方法，提高网站内容加密的有效性和效率，最终提高网络的整体安全性。"
    },
    {
        "title": "OptMSM: Optimizing Multi-Scenario Modeling for Click-Through Rate\n  Prediction",
        "url": "http://arxiv.org/abs/2306.13382v1",
        "pub_date": "2023-06-23",
        "summary": "A large-scale industrial recommendation platform typically consists of\nmultiple associated scenarios, requiring a unified click-through rate (CTR)\nprediction model to serve them simultaneously. Existing approaches for\nmulti-scenario CTR prediction generally consist of two main modules: i) a\nscenario-aware learning module that learns a set of multi-functional\nrepresentations with scenario-shared and scenario-specific information from\ninput features, and ii) a scenario-specific prediction module that serves each\nscenario based on these representations. However, most of these approaches\nprimarily focus on improving the former module and neglect the latter module.\nThis can result in challenges such as increased model parameter size, training\ndifficulty, and performance bottlenecks for each scenario. To address these\nissues, we propose a novel framework called OptMSM (\\textbf{Opt}imizing\n\\textbf{M}ulti-\\textbf{S}cenario \\textbf{M}odeling). First, we introduce a\nsimplified yet effective scenario-enhanced learning module to alleviate the\naforementioned challenges. Specifically, we partition the input features into\nscenario-specific and scenario-shared features, which are mapped to specific\ninformation embedding encodings and a set of shared information embeddings,\nrespectively. By imposing an orthogonality constraint on the shared information\nembeddings to facilitate the disentanglement of shared information\ncorresponding to each scenario, we combine them with the specific information\nembeddings to obtain multi-functional representations. Second, we introduce a\nscenario-specific hypernetwork in the scenario-specific prediction module to\ncapture interactions within each scenario more effectively, thereby alleviating\nthe performance bottlenecks. Finally, we conduct extensive offline experiments\nand an online A/B test to demonstrate the effectiveness of OptMSM.",
        "translated": "一个大规模的工业推荐平台通常由多个相关场景组成，需要一个统一的点进率预测模型来同时为这些场景提供服务。现有的多场景 CTR 预测方法通常由两个主要模块组成: 一个场景感知学习模块，该模块从输入特征中学习一组具有场景共享和场景特定信息的多功能表示; 二个场景特定预测模块，该模块基于这些表示为每个场景提供服务。然而，这些方法大多集中于改进前一个模块，而忽略了后一个模块。这可能导致各种挑战，例如增加模型参数的大小、训练难度和每个场景的性能瓶颈。为了解决这些问题，我们提出了一个新的框架 OptMSM (textbf { Opt } imizingtextbf { M } ulti-textbf { S } cenario textbf { M } odeling)。首先，我们引入一个简化但有效的情景增强学习模块，以缓解上述挑战。具体来说，我们将输入特性划分为场景特定特性和场景共享特性，分别映射到特定信息嵌入编码和一组共享信息嵌入。通过对共享信息嵌入施加正交性约束，以促进对应于每个场景的共享信息的分离，将它们与特定的信息嵌入相结合，得到多功能表示。其次，在场景特定的预测模块中引入场景特定的超网络，以更有效地捕获每个场景中的交互，从而缓解性能瓶颈。最后，我们进行了大量的离线实验和在线 A/B 测试来验证 OptMSM 的有效性。"
    },
    {
        "title": "Human Activity Behavioural Pattern Recognition in Smarthome with\n  Long-hour Data Collection",
        "url": "http://arxiv.org/abs/2306.13374v1",
        "pub_date": "2023-06-23",
        "summary": "The research on human activity recognition has provided novel solutions to\nmany applications like healthcare, sports, and user profiling. Considering the\ncomplex nature of human activities, it is still challenging even after\neffective and efficient sensors are available. The existing works on human\nactivity recognition using smartphone sensors focus on recognizing basic human\nactivities like sitting, sleeping, standing, stair up and down and running.\nHowever, more than these basic activities is needed to analyze human\nbehavioural pattern. The proposed framework recognizes basic human activities\nusing deep learning models. Also, ambient sensors like PIR, pressure sensors,\nand smartphone-based sensors like accelerometers and gyroscopes are combined to\nmake it hybrid-sensor-based human activity recognition. The hybrid approach\nhelped derive more activities than the basic ones, which also helped derive\nhuman activity patterns or user profiling. User profiling provides sufficient\ninformation to identify daily living activity patterns and predict whether any\nanomaly exists. The framework provides the base for applications such as\nelderly monitoring when they are alone at home. The GRU model's accuracy of\n95\\% is observed to recognize the basic activities. Finally, Human activity\npatterns over time are recognized based on the duration and frequency of the\nactivities. It is observed that human activity pattern, like, morning walking\nduration, varies depending on the day of the week.",
        "translated": "人类活动识别的研究为许多应用提供了新颖的解决方案，如医疗保健、体育和用户侧写。考虑到人类活动的复杂性，即使在有效和高效的传感器可用之后，这仍然是具有挑战性的。现有的利用智能手机传感器进行人类活动识别的工作主要集中在识别基本的人类活动，如坐着、睡觉、站立、上下楼梯和跑步。然而，分析人类行为模式需要的不仅仅是这些基本活动。提议的框架使用深度学习模型识别基本的人类活动。此外，环境传感器如 PIR，压力传感器和智能手机传感器如加速度计和陀螺仪的组合，使其混合传感器为基础的人类活动识别。混合方法有助于派生出比基本方法更多的活动，这也有助于派生出人类活动模式或用户分析。用户分析提供了足够的信息来识别日常生活活动模式，并预测是否存在任何异常。该框架为应用程序提供了基础，例如独自在家的老年人监测。GRU 模型识别基本活动的准确率达到95% 。最后，随着时间的推移，人类活动模式的识别基于活动的持续时间和频率。据观察，人类的活动模式，如早晨步行时间，根据不同的一天的一周。"
    },
    {
        "title": "A Decade of Scholarly Research on Open Knowledge Graphs",
        "url": "http://arxiv.org/abs/2306.13186v1",
        "pub_date": "2023-06-22",
        "summary": "The proliferation of open knowledge graphs has led to a surge in scholarly\nresearch on the topic over the past decade. This paper presents a bibliometric\nanalysis of the scholarly literature on open knowledge graphs published between\n2013 and 2023. The study aims to identify the trends, patterns, and impact of\nresearch in this field, as well as the key topics and research questions that\nhave emerged. The work uses bibliometric techniques to analyze a sample of 4445\nscholarly articles retrieved from Scopus. The findings reveal an\never-increasing number of publications on open knowledge graphs published every\nyear, particularly in developed countries (+50 per year). These outputs are\npublished in highly-referred scholarly journals and conferences. The study\nidentifies three main research themes: (1) knowledge graph construction and\nenrichment, (2) evaluation and reuse, and (3) fusion of knowledge graphs into\nNLP systems. Within these themes, the study identifies specific tasks that have\nreceived considerable attention, including entity linking, knowledge graph\nembedding, and graph neural networks.",
        "translated": "在过去的十年中，开放知识图表的激增导致了关于这一主题的学术研究的激增。本文对2013-2023年间发表的关于开放知识图表的学术文献进行了文献计量分析。本研究旨在确定该领域研究的趋势、模式和影响，以及出现的关键主题和研究问题。这项工作使用文献计量学技术来分析从 Scopus 检索到的4445篇学术文章的样本。研究结果显示，每年出版的关于开放知识图表的出版物数量不断增加，尤其是在发达国家(每年增加50本)。这些成果发表在高度引用的学术期刊和会议上。本研究确定了三个主要的研究主题: (1)知识图的构建与丰富; (2)知识图的评价与重用; (3)知识图在自然语言处理系统中的融合。在这些主题中，研究确定了已经受到相当关注的具体任务，包括实体连接、知识图嵌入和图神经网络。"
    },
    {
        "title": "Bring Your Own Data! Self-Supervised Evaluation for Large Language\n  Models",
        "url": "http://arxiv.org/abs/2306.13651v1",
        "pub_date": "2023-06-23",
        "summary": "With the rise of Large Language Models (LLMs) and their ubiquitous deployment\nin diverse domains, measuring language model behavior on realistic data is\nimperative. For example, a company deploying a client-facing chatbot must\nensure that the model will not respond to client requests with profanity.\nCurrent evaluations approach this problem using small, domain-specific datasets\nwith human-curated labels. These evaluation sets are often sampled from a\nnarrow and simplified distribution, and data sources can unknowingly be leaked\ninto the training set which can lead to misleading evaluations. To bypass these\ndrawbacks, we propose a framework for self-supervised evaluation of LLMs by\nanalyzing their sensitivity or invariance to transformations on the input text.\nSelf-supervised evaluation can directly monitor LLM behavior on datasets\ncollected in the wild or streamed during live model deployment. We demonstrate\nself-supervised evaluation strategies for measuring closed-book knowledge,\ntoxicity, and long-range context dependence, in addition to sensitivity to\ngrammatical structure and tokenization errors. When comparisons to similar\nhuman-labeled benchmarks are available, we find strong correlations between\nself-supervised and human-supervised evaluations. The self-supervised paradigm\ncomplements current evaluation strategies that rely on labeled data.",
        "translated": "随着大型语言模型(LLM)的兴起以及它们在不同领域的广泛应用，测量语言模型在实际数据上的行为变得势在必行。例如，部署面向客户机的聊天机器人的公司必须确保该模型不会以脏话回应客户机请求。目前的评估方法这个问题使用小，领域特定的数据集与人类管理的标签。这些评价集通常是从狭窄和简化的分布中取样的，数据源可能在不知情的情况下泄漏到培训集中，从而导致误导性评价。为了克服这些缺点，我们通过分析 LLM 对输入文本变换的敏感性或不变性，提出了一种 LLM 的自监督评估框架。自监督评估可以直接监视野外收集的数据集或实时模型部署期间的流数据集上的 LLM 行为。除了对语法结构和标记错误的敏感性外，我们还展示了自我监督的评估策略，用于测量闭卷知识、毒性和长期上下文依赖性。当与类似的人类标记基准进行比较时，我们发现自我监督评价和人类监督评价之间存在很强的相关性。自我监督范式补充了当前依赖于标记数据的评估策略。"
    },
    {
        "title": "GKD: Generalized Knowledge Distillation for Auto-regressive Sequence\n  Models",
        "url": "http://arxiv.org/abs/2306.13649v1",
        "pub_date": "2023-06-23",
        "summary": "Knowledge distillation is commonly used for compressing neural networks to\nreduce their inference cost and memory footprint. However, current distillation\nmethods for auto-regressive models, such as generative language models (LMs),\nsuffer from two key issues: (1) distribution mismatch between output sequences\nduring training and the sequences generated by the student during its\ndeployment, and (2) model under-specification, where the student model may not\nbe expressive enough to fit the teacher's distribution. To address these\nissues, we propose Generalized Knowledge Distillation (GKD). GKD mitigates\ndistribution mismatch by sampling output sequences from the student during\ntraining. Furthermore, GKD handles model under-specification by optimizing\nalternative divergences, such as reverse KL, that focus on generating samples\nfrom the student that are likely under the teacher's distribution. We\ndemonstrate that GKD outperforms commonly-used approaches for distilling LLMs\non summarization, machine translation, and arithmetic reasoning tasks.",
        "translated": "知识提取通常用于压缩神经网络，以减少其推理成本和内存占用。然而，目前自回归模型的精馏方法，如生成语言模型(LM) ，存在两个关键问题: (1)训练过程中输出序列与学生在部署过程中生成的序列之间的分布不匹配; (2)模型规范不足，学生模型的表达能力可能不足以适应教师的分布。为了解决这些问题，我们提出了广义知识提取(GKD)。GKD 通过在培训期间对学生的输出序列进行采样来减少分布不匹配。此外，GKD 通过优化替代性差异(如逆向 KL)来处理模型欠规范问题，这些差异侧重于从可能处于教师分布之下的学生生成样本。我们证明了 GKD 在摘要、机器翻译和算术推理任务中优于常用的 LLM 提取方法。"
    },
    {
        "title": "Margin Maximization in Attention Mechanism",
        "url": "http://arxiv.org/abs/2306.13596v1",
        "pub_date": "2023-06-23",
        "summary": "Attention mechanism is a central component of the transformer architecture\nwhich led to the phenomenal success of large language models. However, the\ntheoretical principles underlying the attention mechanism are poorly\nunderstood, especially its nonconvex optimization dynamics. In this work, we\nexplore the seminal softmax-attention model $f(\\boldsymbol{X})=\\langle\n\\boldsymbol{Xv}, \\texttt{softmax}(\\boldsymbol{XWp})\\rangle$, where,\n$\\boldsymbol{X}$ is the token sequence and\n$(\\boldsymbol{v},\\boldsymbol{W},\\boldsymbol{p})$ are tunable parameters. We\nprove that running gradient descent on $\\boldsymbol{p}$, or equivalently\n$\\boldsymbol{W}$, converges in direction to a max-margin solution that\nseparates $\\textit{locally-optimal}$ tokens from non-optimal ones. This clearly\nformalizes attention as a token separation mechanism. Remarkably, our results\nare applicable to general data and precisely characterize $\\textit{optimality}$\nof tokens in terms of the value embeddings $\\boldsymbol{Xv}$ and problem\ngeometry. We also provide a broader regularization path analysis that\nestablishes the margin maximizing nature of attention even for nonlinear\nprediction heads. When optimizing $\\boldsymbol{v}$ and $\\boldsymbol{p}$\nsimultaneously with logistic loss, we identify conditions under which the\nregularization paths directionally converge to their respective hard-margin SVM\nsolutions where $\\boldsymbol{v}$ separates the input features based on their\nlabels. Interestingly, the SVM formulation of $\\boldsymbol{p}$ is influenced by\nthe support vector geometry of $\\boldsymbol{v}$. Finally, we verify our\ntheoretical findings via numerical experiments and provide insights.",
        "translated": "注意机制是变压器体系结构的核心组成部分，它导致了大型语言模型的显著成功。然而，注意机制的理论基础知之甚少，尤其是其非凸优化动力学。本文探讨了开创性的软最大注意模型 $f (粗体{ X }) = 长体粗体{ Xv } ，texttt { softmax }(粗体{ XWp }) range $，其中 $粗体{ X } $是标记序列，$(粗体{ W } ，粗体{ p }) $是可调参数。我们证明了运行在 $粗体符号{ p } $或等价的 $粗体符号{ W } $上的梯度下降法收敛于一个最大边界解，该解将 $textit {局部最优} $标记与非最优标记区分开来。这清楚地将注意力形式化为一种标记分离机制。值得注意的是，我们的结果适用于一般数据，并且精确地刻画了标记的 $textit { Optimality } $值嵌入 $粗体符号{ Xv } $和问题几何。我们还提供了一个更广泛的正则化路径分析，即使对于非线性预测头来说，也建立了注意力余量最大化的性质。在对符号{ v } $和符号{ p } $同时进行逻辑损失优化时，我们确定了正则化路径在哪些条件下定向收敛到它们各自的硬边值 SVM 解，其中符号{ v } $根据标签分离输入特征。有趣的是，$粗体符号{ p } $的 SVM 公式受到 $粗体符号{ v } $的支持向量几何形状的影响。最后，通过数值实验验证我们的理论发现，并提供见解。"
    },
    {
        "title": "System-Level Natural Language Feedback",
        "url": "http://arxiv.org/abs/2306.13588v1",
        "pub_date": "2023-06-23",
        "summary": "Natural language (NL) feedback contains rich information about the user\nexperience. Existing studies focus on an instance-level approach, where\nfeedback is used to refine specific examples, disregarding its system-wide\napplication. This paper proposes a general framework for unlocking the\nsystem-level use of NL feedback. We show how to use feedback to formalize\nsystem-level design decisions in a human-in-the-loop-process -- in order to\nproduce better models. In particular this is done through: (i) metric design\nfor tasks; and (ii) language model prompt design for refining model responses.\nWe conduct two case studies of this approach for improving search query\ngeneration and dialog response generation, demonstrating the effectiveness of\nthe use of system-level feedback. We show the combination of system-level\nfeedback and instance-level feedback brings further gains, and that human\nwritten instance-level feedback results in more grounded refinements than\nGPT-3.5 written ones, underlying the importance of human feedback for building\nsystems.",
        "translated": "自然语言(NL)反馈包含了丰富的用户体验信息。现有的研究集中在实例级方法上，在这种方法中，反馈被用来精炼具体的例子，而忽略了它在系统范围内的应用。本文提出了一个解锁系统级使用自然语言反馈的一般框架。我们展示了如何使用反馈在人在循环的过程中形式化系统级设计决策——以便产生更好的模型。具体来说，这是通过: (i)任务的度量设计; 和(ii)精炼模型响应的语言模型提示设计。我们对该方法进行了两个改进搜索查询生成和对话框响应生成的案例研究，证明了使用系统级反馈的有效性。我们展示了系统级反馈和实例级反馈的结合带来了进一步的收益，而且人工编写的实例级反馈比 GPT-3.5编写的反馈带来了更多的基础细化，这是人工反馈对构建系统的重要性的基础。"
    },
    {
        "title": "A Survey on Multimodal Large Language Models",
        "url": "http://arxiv.org/abs/2306.13549v1",
        "pub_date": "2023-06-23",
        "summary": "Multimodal Large Language Model (MLLM) recently has been a new rising\nresearch hotspot, which uses powerful Large Language Models (LLMs) as a brain\nto perform multimodal tasks. The surprising emergent capabilities of MLLM, such\nas writing stories based on images and OCR-free math reasoning, are rare in\ntraditional methods, suggesting a potential path to artificial general\nintelligence. In this paper, we aim to trace and summarize the recent progress\nof MLLM. First of all, we present the formulation of MLLM and delineate its\nrelated concepts. Then, we discuss the key techniques and applications,\nincluding Multimodal Instruction Tuning (M-IT), Multimodal In-Context Learning\n(M-ICL), Multimodal Chain of Thought (M-CoT), and LLM-Aided Visual Reasoning\n(LAVR). Finally, we discuss existing challenges and point out promising\nresearch directions. In light of the fact that the era of MLLM has only just\nbegun, we will keep updating this survey and hope it can inspire more research.\nAn associated GitHub link collecting the latest papers is available at\nhttps://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models.",
        "translated": "多模态大语言模型(MLLM)是近年来兴起的一个新的研究热点，它利用强大的大语言模型(LLM)作为大脑来执行多模态任务。MLLM 令人惊讶的突发性能力，如基于图像和无 OCR 的数学推理写作故事，在传统方法中是罕见的，这表明了一条通向人工通用智能的潜在道路。本文旨在追踪和总结 MLLM 的最新进展。首先，我们提出了 MLLM 的概念，并描述了它的相关概念。然后，我们讨论了多模态教学调优(M-IT)、多模态上下文学习(M-ICL)、多模态思维链(M-CoT)和 LLM 辅助视觉推理(LAVR)等关键技术和应用。最后，我们讨论了目前存在的挑战，并指出了有前途的研究方向。鉴于 MLLM 的时代才刚刚开始，我们将不断更新这一调查，希望能够激发更多的研究。收集最新论文的相关 GitHub 链接可在 https://GitHub.com/bradyfu/awesome-multimodal-large-language-models 获得。"
    },
    {
        "title": "Knowledge-Infused Self Attention Transformers",
        "url": "http://arxiv.org/abs/2306.13501v1",
        "pub_date": "2023-06-23",
        "summary": "Transformer-based language models have achieved impressive success in various\nnatural language processing tasks due to their ability to capture complex\ndependencies and contextual information using self-attention mechanisms.\nHowever, they are not without limitations. These limitations include\nhallucinations, where they produce incorrect outputs with high confidence, and\nalignment issues, where they generate unhelpful and unsafe outputs for human\nusers. These limitations stem from the absence of implicit and missing context\nin the data alone. To address this, researchers have explored augmenting these\nmodels with external knowledge from knowledge graphs to provide the necessary\nadditional context. However, the ad-hoc nature of existing methods makes it\ndifficult to properly analyze the effects of knowledge infusion on the many\nmoving parts or components of a transformer. This paper introduces a systematic\nmethod for infusing knowledge into different components of a transformer-based\nmodel. A modular framework is proposed to identify specific components within\nthe transformer architecture, such as the self-attention mechanism, encoder\nlayers, or the input embedding layer, where knowledge infusion can be applied.\nAdditionally, extensive experiments are conducted on the General Language\nUnderstanding Evaluation (GLUE) benchmark tasks, and the findings are reported.\nThis systematic approach aims to facilitate more principled approaches to\nincorporating knowledge into language model architectures.",
        "translated": "基于转换器的语言模型在各种自然语言处理任务中取得了令人印象深刻的成功，因为它们能够利用自我注意机制捕获复杂的依赖关系和上下文信息。然而，它们并非没有限制。这些限制包括幻觉，它们产生高度可信的错误输出，以及校准问题，它们为人类用户产生无益和不安全的输出。这些限制源于数据本身缺乏隐式的和缺失的上下文。为了解决这个问题，研究人员已经探索用来自知识图表的外部知识来增强这些模型，以提供必要的额外背景。然而，现有方法的特殊性使得很难正确分析知识输入对变压器的许多运动部件的影响。本文介绍了一种将知识注入到基于变压器的模型的不同组件中的系统方法。提出了一个模块化框架来识别变压器体系结构中的特定组件，如自注意机制、编码器层或输入嵌入层，其中可以应用知识注入。此外，本研究还对通用语言理解评估(GLUE)基准任务进行了广泛的实验研究，并对实验结果进行了报道。这种系统方法旨在促进将知识纳入语言模型体系结构的更有原则的方法。"
    },
    {
        "title": "Incorporating Graph Information in Transformer-based AMR Parsing",
        "url": "http://arxiv.org/abs/2306.13467v1",
        "pub_date": "2023-06-23",
        "summary": "Abstract Meaning Representation (AMR) is a Semantic Parsing formalism that\naims at providing a semantic graph abstraction representing a given text.\nCurrent approaches are based on autoregressive language models such as BART or\nT5, fine-tuned through Teacher Forcing to obtain a linearized version of the\nAMR graph from a sentence. In this paper, we present LeakDistill, a model and\nmethod that explores a modification to the Transformer architecture, using\nstructural adapters to explicitly incorporate graph information into the\nlearned representations and improve AMR parsing performance. Our experiments\nshow how, by employing word-to-node alignment to embed graph structural\ninformation into the encoder at training time, we can obtain state-of-the-art\nAMR parsing through self-knowledge distillation, even without the use of\nadditional data. We release the code at\n\\url{http://www.github.com/sapienzanlp/LeakDistill}.",
        "translated": "抽象意义表示(AMR)是一种语义分析形式主义，旨在提供表示给定文本的语义图抽象。目前的方法是基于自回归语言模型，如 BART 或 T5，通过教师强制微调，以获得一个句子的 AMR 图的线性化版本。在本文中，我们提出了 LeakDistill 模型和方法，该模型和方法探索了如何修改 Transformer 体系结构，使用结构适配器将图信息显式地合并到所学习的表示中，并提高 AMR 解析性能。实验结果表明，在训练时通过字节对齐将图结构信息嵌入到编码器中，即使不需要额外的数据，也可以通过自知识提取获得最新的 AMR 解析结果。我们在 url { http://www.github.com/sapienzanlp/leakdistill }发布代码。"
    },
    {
        "title": "Learning Descriptive Image Captioning via Semipermeable Maximum\n  Likelihood Estimation",
        "url": "http://arxiv.org/abs/2306.13460v1",
        "pub_date": "2023-06-23",
        "summary": "Image captioning aims to describe visual content in natural language. As 'a\npicture is worth a thousand words', there could be various correct descriptions\nfor an image. However, with maximum likelihood estimation as the training\nobjective, the captioning model is penalized whenever its prediction mismatches\nwith the label. For instance, when the model predicts a word expressing richer\nsemantics than the label, it will be penalized and optimized to prefer more\nconcise expressions, referred to as conciseness optimization. In contrast,\npredictions that are more concise than labels lead to richness optimization.\nSuch conflicting optimization directions could eventually result in the model\ngenerating general descriptions. In this work, we introduce Semipermeable\nMaxImum Likelihood Estimation (SMILE), which allows richness optimization while\nblocking conciseness optimization, thus encouraging the model to generate\nlonger captions with more details. Extensive experiments on two mainstream\nimage captioning datasets MSCOCO and Flickr30K demonstrate that SMILE\nsignificantly enhances the descriptiveness of generated captions. We further\nprovide in-depth investigations to facilitate a better understanding of how\nSMILE works.",
        "translated": "图像字幕的目的是用自然语言描述视觉内容。正如“一张图片胜过千言万语”一样，对于一张图片可以有各种各样正确的描述。然而，以最大似然估计为训练目标，当字幕模型的预测与标签不匹配时，字幕模型就会受到惩罚。例如，当模型预测一个表达比标签更丰富的语义的单词时，它将受到惩罚并优化以选择更简洁的表达式，称为简洁性优化。相反，比标签更简洁的预测会导致丰富性优化。这种冲突的优化方向可能最终导致模型产生一般的描述。在本文中，我们引入了半可渗透最大似然估计(SMILE) ，它允许在阻塞简洁性优化的同时进行丰富性优化，从而鼓励模型生成具有更多细节的更长的标题。在两个主流图像字幕数据集 MSCOCO 和 Flickr30K 上的大量实验表明，SMILE 显著提高了生成的字幕的描述性。我们进一步提供深入的调查，以便更好地了解 SMILE 如何工作。"
    },
    {
        "title": "Long-range Language Modeling with Self-retrieval",
        "url": "http://arxiv.org/abs/2306.13421v1",
        "pub_date": "2023-06-23",
        "summary": "Retrieval-augmented language models (LMs) have received much attention\nrecently. However, typically the retriever is not trained jointly as a native\ncomponent of the LM, but added to an already-pretrained LM, which limits the\nability of the LM and the retriever to adapt to one another. In this work, we\npropose the Retrieval-Pretrained Transformer (RPT), an architecture and\ntraining procedure for jointly training a retrieval-augmented LM from scratch\nfor the task of modeling long texts. Given a recently generated text chunk in a\nlong document, the LM computes query representations, which are then used to\nretrieve earlier chunks in the document, located potentially tens of thousands\nof tokens before. Information from retrieved chunks is fused into the LM\nrepresentations to predict the next target chunk. We train the retriever\ncomponent with a semantic objective, where the goal is to retrieve chunks that\nincrease the probability of the next chunk, according to a reference LM. We\nevaluate RPT on four long-range language modeling tasks, spanning books, code,\nand mathematical writing, and demonstrate that RPT improves retrieval quality\nand subsequently perplexity across the board compared to strong baselines.",
        "translated": "检索增强语言模型(LM)近年来受到了广泛的关注。然而，检索器通常不会作为 LM 的本机组件共同训练，而是添加到已经预先训练好的 LM 中，这限制了 LM 和检索器相互适应的能力。在这项工作中，我们提出了检索-预训练变压器(RPT) ，一个体系结构和训练过程，联合训练一个检索-增强 LM 从头开始建模长文本的任务。给定一个长文档中最近生成的文本块，LM 计算查询表示，然后使用这些查询表示来检索文档中可能存在数万个标记的早期块。来自检索块的信息被融合到 LM 表示中，以预测下一个目标块。我们使用语义目标训练检索器组件，其目标是根据引用 LM 检索增加下一个块的概率的块。我们评估了 RPT 在四个远程语言建模任务(跨书籍、代码和数学写作)上的表现，并证明与强基线相比，RPT 提高了检索质量并随后全面提高了困惑度。"
    },
    {
        "title": "Stress Testing BERT Anaphora Resolution Models for Reaction Extraction\n  in Chemical Patents",
        "url": "http://arxiv.org/abs/2306.13379v1",
        "pub_date": "2023-06-23",
        "summary": "The high volume of published chemical patents and the importance of a timely\nacquisition of their information gives rise to automating information\nextraction from chemical patents. Anaphora resolution is an important component\nof comprehensive information extraction, and is critical for extracting\nreactions. In chemical patents, there are five anaphoric relations of interest:\nco-reference, transformed, reaction associated, work up, and contained. Our\ngoal is to investigate how the performance of anaphora resolution models for\nreaction texts in chemical patents differs in a noise-free and noisy\nenvironment and to what extent we can improve the robustness against noise of\nthe model.",
        "translated": "由于已发表的化学专利数量庞大，加上及时取得这些专利的资料十分重要，因此化学专利的信息抽取便会自动化。回指消解是综合信息抽取的重要组成部分，对提取反应至关重要。在化学专利中，有五种兴趣回指关系: 共指关系、转换关系、反应关系、升级关系和包含关系。我们的目标是研究化学专利中反应文本的回指消解模型在无噪声和噪声环境中的性能差异，以及在多大程度上我们可以提高模型对噪声的鲁棒性。"
    },
    {
        "title": "Scalable Neural Contextual Bandit for Recommender Systems",
        "url": "http://arxiv.org/abs/2306.14834v1",
        "pub_date": "2023-06-26",
        "summary": "High-quality recommender systems ought to deliver both innovative and\nrelevant content through effective and exploratory interactions with users.\nYet, supervised learning-based neural networks, which form the backbone of many\nexisting recommender systems, only leverage recognized user interests, falling\nshort when it comes to efficiently uncovering unknown user preferences. While\nthere has been some progress with neural contextual bandit algorithms towards\nenabling online exploration through neural networks, their onerous\ncomputational demands hinder widespread adoption in real-world recommender\nsystems. In this work, we propose a scalable sample-efficient neural contextual\nbandit algorithm for recommender systems. To do this, we design an epistemic\nneural network architecture, Epistemic Neural Recommendation (ENR), that\nenables Thompson sampling at a large scale. In two distinct large-scale\nexperiments with real-world tasks, ENR significantly boosts click-through rates\nand user ratings by at least 9% and 6% respectively compared to\nstate-of-the-art neural contextual bandit algorithms. Furthermore, it achieves\nequivalent performance with at least 29% fewer user interactions compared to\nthe best-performing baseline algorithm. Remarkably, while accomplishing these\nimprovements, ENR demands orders of magnitude fewer computational resources\nthan neural contextual bandit baseline algorithms.",
        "translated": "高质量的推荐系统应该通过与用户有效和探索性的互动交付创新和相关的内容。然而，作为许多现有推荐系统骨干的基于监督学习的神经网络，只能利用已识别的用户兴趣，在有效发现未知用户偏好方面存在不足。虽然神经上下文强盗算法在通过神经网络实现在线探索方面取得了一些进展，但是它们繁重的计算需求阻碍了在现实世界中推荐系统的广泛采用。在这项工作中，我们提出了一个可扩展的样本效率神经上下文盗贼算法的推荐系统。为了做到这一点，我们设计了一个认知神经网络结构，认知神经推荐(ENR) ，使汤普森采样在大规模。在两个不同的大规模实验与现实世界的任务，ENR 显着提高点击率和用户评分至少9% 和6% 分别相比，国家的最先进的神经上下文土匪算法。此外，与性能最好的基线算法相比，它至少减少了29% 的用户交互，从而实现了相同的性能。值得注意的是，在完成这些改进的同时，ENR 所需的计算资源数量级比神经上下文强盗基线算法要少。"
    },
    {
        "title": "Reciprocal Sequential Recommendation",
        "url": "http://arxiv.org/abs/2306.14712v1",
        "pub_date": "2023-06-26",
        "summary": "Reciprocal recommender system (RRS), considering a two-way matching between\ntwo parties, has been widely applied in online platforms like online dating and\nrecruitment. Existing RRS models mainly capture static user preferences, which\nhave neglected the evolving user tastes and the dynamic matching relation\nbetween the two parties. Although dynamic user modeling has been well-studied\nin sequential recommender systems, existing solutions are developed in a\nuser-oriented manner. Therefore, it is non-trivial to adapt sequential\nrecommendation algorithms to reciprocal recommendation. In this paper, we\nformulate RRS as a distinctive sequence matching task, and further propose a\nnew approach ReSeq for RRS, which is short for Reciprocal Sequential\nrecommendation. To capture dual-perspective matching, we propose to learn\nfine-grained sequence similarities by co-attention mechanism across different\ntime steps. Further, to improve the inference efficiency, we introduce the\nself-distillation technique to distill knowledge from the fine-grained matching\nmodule into the more efficient student module. In the deployment stage, only\nthe efficient student module is used, greatly speeding up the similarity\ncomputation. Extensive experiments on five real-world datasets from two\nscenarios demonstrate the effectiveness and efficiency of the proposed method.\nOur code is available at https://github.com/RUCAIBox/ReSeq/.",
        "translated": "考虑双方双向匹配的互惠推荐系统已经广泛应用于在线约会和招聘等在线平台。现有的 RRS 模型主要捕捉静态用户偏好，忽略了用户偏好的演变和双方的动态匹配关系。尽管动态用户建模已经在顺序推荐系统中得到了很好的研究，但是现有的解决方案都是以面向用户的方式开发的。因此，将顺序推荐算法应用到互惠推荐中具有重要意义。本文将 RRS 作为一个独特的序列匹配任务，并进一步提出了一种新的 RRS 方法 ReSeq，即相互序列推荐的简称。为了捕获双视角匹配，我们提出了通过跨不同时间步长的共注意机制来学习细粒度序列相似性。进一步，为了提高推理效率，我们引入了自蒸馏技术，从细粒度匹配模块中提取知识到更高效的学生模块中。在部署阶段，只使用了有效的学生模块，大大加快了相似度计算的速度。通过对来自两个场景的五个真实世界数据集的大量实验，证明了该方法的有效性和高效性。我们的代码可以在 https://github.com/rucaibox/reseq/找到。"
    },
    {
        "title": "PTVD: A Large-Scale Plot-Oriented Multimodal Dataset Based on Television\n  Dramas",
        "url": "http://arxiv.org/abs/2306.14644v1",
        "pub_date": "2023-06-26",
        "summary": "Art forms such as movies and television (TV) dramas are reflections of the\nreal world, which have attracted much attention from the multimodal learning\ncommunity recently. However, existing corpora in this domain share three\nlimitations: (1) annotated in a scene-oriented fashion, they ignore the\ncoherence within plots; (2) their text lacks empathy and seldom mentions\nsituational context; (3) their video clips fail to cover long-form relationship\ndue to short duration. To address these fundamental issues, using 1,106 TV\ndrama episodes and 24,875 informative plot-focused sentences written by\nprofessionals, with the help of 449 human annotators, we constructed PTVD, the\nfirst plot-oriented multimodal dataset in the TV domain. It is also the first\nnon-English dataset of its kind. Additionally, PTVD contains more than 26\nmillion bullet screen comments (BSCs), powering large-scale pre-training. Next,\naiming to open-source a strong baseline for follow-up works, we developed the\nmultimodal algorithm that attacks different cinema/TV modelling problems with a\nunified architecture. Extensive experiments on three cognitive-inspired tasks\nyielded a number of novel observations (some of them being quite\ncounter-intuition), further validating the value of PTVD in promoting\nmultimodal research. The dataset and codes are released at\n\\url{https://ptvd.github.io/}.",
        "translated": "电影、电视剧等艺术形式是现实世界的反映，近年来引起了多模式学习社会的广泛关注。然而，该领域现有的语料库存在三个局限性: (1)以场景为导向的方式进行注释，忽视了情节的连贯性; (2)文本缺乏移情作用，很少提及情景语境; (3)视频片段由于篇幅短而无法涵盖长篇关系。为了解决这些基本问题，我们在449名人类注释者的帮助下，使用1,106个电视剧集和24,875个由专业人员撰写的信息丰富的情节集中的句子，构建了电视领域中第一个面向情节的多模式数据集 PTVD。它也是第一个非英语数据集的类型。此外，PTVD 包含超过2600万条弹幕评论(BSC) ，为大规模的预训提供动力。接下来，为了给后续工作提供一个强有力的开源基准，我们开发了多模态算法，用一个统一的体系结构来解决不同的影院/电视建模问题。对三个认知启发任务的广泛实验产生了许多新的观察结果(其中一些相当反直觉) ，进一步验证了 PTVD 在促进多模态研究中的价值。数据集和代码在 url { https://ptvd.github.io/}发布。"
    },
    {
        "title": "Multi-task Item-attribute Graph Pre-training for Strict Cold-start Item\n  Recommendation",
        "url": "http://arxiv.org/abs/2306.14462v1",
        "pub_date": "2023-06-26",
        "summary": "Recommendation systems suffer in the strict cold-start (SCS) scenario, where\nthe user-item interactions are entirely unavailable. The ID-based approaches\ncompletely fail to work. Cold-start recommenders, on the other hand, leverage\nitem contents to map the new items to the existing ones. However, the existing\nSCS recommenders explore item contents in coarse-grained manners that introduce\nnoise or information loss. Moreover, informative data sources other than item\ncontents, such as users' purchase sequences and review texts, are ignored. We\nexplore the role of the fine-grained item attributes in bridging the gaps\nbetween the existing and the SCS items and pre-train a knowledgeable\nitem-attribute graph for SCS item recommendation. Our proposed framework,\nColdGPT, models item-attribute correlations into an item-attribute graph by\nextracting fine-grained attributes from item contents. ColdGPT then transfers\nknowledge into the item-attribute graph from various available data sources,\ni.e., item contents, historical purchase sequences, and review texts of the\nexisting items, via multi-task learning. To facilitate the positive transfer,\nColdGPT designs submodules according to the natural forms of the data sources\nand coordinates the multiple pre-training tasks via unified\nalignment-and-uniformity losses. Our pre-trained item-attribute graph acts as\nan implicit, extendable item embedding matrix, which enables the SCS item\nembeddings to be easily acquired by inserting these items and propagating their\nattributes' embeddings. We carefully process three public datasets, i.e., Yelp,\nAmazon-home, and Amazon-sports, to guarantee the SCS setting for evaluation.\nExtensive experiments show that ColdGPT consistently outperforms the existing\nSCS recommenders by large margins and even surpasses models that are\npre-trained on 75-224 times more, cross-domain data on two out of four\ndatasets.",
        "translated": "推荐系统在严格的冷启动(SCS)场景中受到影响，其中用户-项交互是完全不可用的。基于 ID 的方法完全不起作用。另一方面，冷启动推荐器利用项目内容将新项目映射到现有项目。然而，现有的 SCS 推荐标准以粗粒度的方式探索项目内容，导致噪声或信息丢失。此外，项目内容以外的信息性数据源，如用户的购买顺序和评论文本，被忽略。本文探讨了细粒度项目属性在弥补现有项目与 SCS 项目之间差距方面的作用，并为 SCS 项目推荐预训练了一个知识型项目属性图。我们提出的框架 ColdGPT 通过从项目内容中提取细粒度属性，将项目-属性关系建模成项目-属性图。ColdGPT 然后通过多任务学习，将来自各种可用数据源的知识转移到项目属性图中，即项目内容、历史购买顺序和审查现有项目的文本。为了便于正向传输，ColdGPT 根据数据源的自然形式设计子模块，并通过统一的对齐和一致性损失协调多个预训练任务。我们的预训练项目属性图作为一个隐式的、可扩展的项目嵌入矩阵，通过插入这些项目并传播它们的属性嵌入，可以方便地获得 SCS 项目嵌入。我们仔细处理三个公共数据集，即 Yelp、 Amazon-home 和 Amazon-sports，以保证 SCS 设置用于评估。大量的实验表明，ColdGPT 始终优于现有的 SCS 推荐器，甚至超过预先训练75-224倍以上的模型，跨域数据在四个数据集中的两个。"
    },
    {
        "title": "Contrastive Multi-view Framework for Customer Lifetime Value Prediction",
        "url": "http://arxiv.org/abs/2306.14400v1",
        "pub_date": "2023-06-26",
        "summary": "Accurate customer lifetime value (LTV) prediction can help service providers\noptimize their marketing policies in customer-centric applications. However,\nthe heavy sparsity of consumption events and the interference of data variance\nand noise obstruct LTV estimation. Many existing LTV prediction methods\ndirectly train a single-view LTV predictor on consumption samples, which may\nyield inaccurate and even biased knowledge extraction. In this paper, we\npropose a contrastive multi-view framework for LTV prediction, which is a\nplug-and-play solution compatible with various backbone models. It synthesizes\nmultiple heterogeneous LTV regressors with complementary knowledge to improve\nmodel robustness and captures sample relatedness via contrastive learning to\nmitigate the dependency on data abundance. Concretely, we use a decomposed\nscheme that converts the LTV prediction problem into a combination of\nestimating consumption probability and payment amount. To alleviate the impact\nof noisy data on model learning, we propose a multi-view framework that jointly\noptimizes multiple types of regressors with diverse characteristics and\nadvantages to encode and fuse comprehensive knowledge. To fully exploit the\npotential of limited training samples, we propose a hybrid contrastive learning\nmethod to help capture the relatedness between samples in both classification\nand regression tasks. We conduct extensive experiments on a real-world game LTV\nprediction dataset and the results validate the effectiveness of our method. We\nhave deployed our solution online in Huawei's mobile game center and achieved\n32.26% of total payment amount gains.",
        "translated": "准确的客户生命周期价值(LTV)预测可以帮助服务提供商在以客户为中心的应用程序中优化其营销策略。然而，消耗事件的严重稀疏性以及数据方差和噪声的干扰阻碍了 LTV 估计。许多现有的 LTV 预测方法直接在消费样本上训练单视图 LTV 预测器，这可能会产生不准确甚至有偏差的知识提取。在本文中，我们提出了一个对比的多视图 LTV 预测框架，这是一个即插即用的解决方案，兼容各种骨干模型。它综合了多个具有互补知识的异构 LTV 回归子，提高了模型的鲁棒性，并通过对比学习获取样本相关性，减轻了对数据丰度的依赖性。具体地，我们使用了一个分解方案，将 LTV 预测问题转化为估计消费概率和支付金额的组合。为了减轻噪声数据对模型学习的影响，本文提出了一种多视图框架，该框架联合优化具有不同特征和优势的多类回归模型，对综合知识进行编码和融合。为了充分发挥有限训练样本的潜力，我们提出了一种混合对比学习方法，以帮助捕捉样本之间的相关性分类和回归任务。我们在一个真实的游戏 LTV 预测数据集上进行了广泛的实验，实验结果验证了我们方法的有效性。我们已经在华为的手机游戏中心部署了我们的在线解决方案，实现了总支付金额收益的32.26% 。"
    },
    {
        "title": "FunQA: Towards Surprising Video Comprehension",
        "url": "http://arxiv.org/abs/2306.14899v1",
        "pub_date": "2023-06-26",
        "summary": "Surprising videos, e.g., funny clips, creative performances, or visual\nillusions, attract significant attention. Enjoyment of these videos is not\nsimply a response to visual stimuli; rather, it hinges on the human capacity to\nunderstand (and appreciate) commonsense violations depicted in these videos. We\nintroduce FunQA, a challenging video question answering (QA) dataset\nspecifically designed to evaluate and enhance the depth of video reasoning\nbased on counter-intuitive and fun videos. Unlike most video QA benchmarks\nwhich focus on less surprising contexts, e.g., cooking or instructional videos,\nFunQA covers three previously unexplored types of surprising videos: 1)\nHumorQA, 2) CreativeQA, and 3) MagicQA. For each subset, we establish rigorous\nQA tasks designed to assess the model's capability in counter-intuitive\ntimestamp localization, detailed video description, and reasoning around\ncounter-intuitiveness. We also pose higher-level tasks, such as attributing a\nfitting and vivid title to the video, and scoring the video creativity. In\ntotal, the FunQA benchmark consists of 312K free-text QA pairs derived from\n4.3K video clips, spanning a total of 24 video hours. Extensive experiments\nwith existing VideoQA models reveal significant performance gaps for the FunQA\nvideos across spatial-temporal reasoning, visual-centered reasoning, and\nfree-text generation.",
        "translated": "令人惊讶的视频，例如，有趣的片段，创造性的表演，或视觉幻觉，吸引了大量的注意力。欣赏这些视频不仅仅是对视觉刺激的反应，而是取决于人类理解(和欣赏)这些视频中描述的违反常识的行为的能力。我们介绍 FunQA，一个具有挑战性的视频问题回答(QA)数据集，专门设计来评估和增强基于反直观和有趣的视频的视频推理深度。与大多数视频 QA 基准不同，FunQA 基准侧重于不那么令人惊讶的背景，例如烹饪或教学视频，FunQA 涵盖了三种以前未探索过的令人惊讶的视频类型: 1) HumorQA，2) CreativeQA，和3) MagicQA。对于每个子集，我们建立严格的 QA 任务，旨在评估模型在反直觉时间戳定位、详细视频描述和反直觉推理方面的能力。我们还提出了更高层次的任务，比如为视频赋予一个合适的、生动的标题，以及对视频创造性进行评分。FunQA 基准测试总共由312K 自由文本 QA 对组成，这些 QA 对来自4.3 K 视频剪辑，跨越总共24个视频小时。对现有 VideoQA 模型的大量实验表明，FunQA 视频在时空推理、以视觉为中心的推理和自由文本生成方面存在显著的性能差距。"
    },
    {
        "title": "InterCode: Standardizing and Benchmarking Interactive Coding with\n  Execution Feedback",
        "url": "http://arxiv.org/abs/2306.14898v2",
        "pub_date": "2023-06-26",
        "summary": "Humans write code in a fundamentally interactive manner and rely on constant\nexecution feedback to correct errors, resolve ambiguities, and decompose tasks.\nWhile LLMs have recently exhibited promising coding capabilities, current\ncoding benchmarks mostly consider a static instruction-to-code sequence\ntransduction process, which has the potential for error propagation and a\ndisconnect between the generated code and its final execution environment. To\naddress this gap, we introduce InterCode, a lightweight, flexible, and\neasy-to-use framework of interactive coding as a standard reinforcement\nlearning (RL) environment, with code as actions and execution feedback as\nobservations. Our framework is language and platform agnostic, uses\nself-contained Docker environments to provide safe and reproducible execution,\nand is compatible out-of-the-box with traditional seq2seq coding methods, while\nenabling the development of new methods for interactive code generation. We use\nInterCode to create two interactive code environments with Bash and SQL as\naction spaces, leveraging data from the static Spider and NL2Bash datasets. We\ndemonstrate InterCode's viability as a testbed by evaluating multiple\nstate-of-the-art LLMs configured with different prompting strategies such as\nReAct and Plan &amp; Solve. Our results showcase the benefits of interactive code\ngeneration and demonstrate that InterCode can serve as a challenging benchmark\nfor advancing code understanding and generation capabilities. InterCode is\ndesigned to be easily extensible and can even be used to incorporate new tasks\nsuch as Capture the Flag, a popular coding puzzle that is inherently multi-step\nand involves multiple programming languages. Project site with code and data:\nhttps://intercode-benchmark.github.io",
        "translated": "人类以基本的交互方式编写代码，并依赖于不断的执行反馈来纠正错误、解决模糊性和分解任务。虽然 LLM 最近展示了很有前途的编码能力，但目前的编码基准主要考虑的是静态指令-代码序列转换过程，这种过程有可能导致错误传播，并使生成的代码与其最终执行环境脱节。为了解决这个问题，我们引入了 InterCode，这是一个轻量级的、灵活的、易于使用的交互式编码框架，作为一个标准的强化学习(RL)环境，代码作为操作，执行反馈作为观察。我们的框架与语言和平台无关，使用自包含的 Docker 环境来提供安全和可重复的执行，并且与传统的 seq2seq 编码方法开箱即用兼容，同时支持开发用于交互式代码生成的新方法。我们使用 InterCode 创建两个交互式代码环境，使用 Bash 和 SQL 作为操作空间，利用来自静态 Spider 和 NL2Bash 数据集的数据。我们通过评估配置了不同激励策略(如 ReAct 和 Plan & Solve)的多个最先进的 LLM，展示了 InterCode 作为测试平台的可行性。我们的结果展示了交互式代码生成的好处，并证明了 InterCode 可以作为一个具有挑战性的基准来提高代码理解和生成能力。InterCode 被设计成易于扩展，甚至可以用来合并新的任务，比如 Capture the Flag，这是一种流行的编码难题，本质上是多步骤的，涉及多种编程语言。项目网站的代码和数据:  https://intercode-benchmark.github.io"
    },
    {
        "title": "LongCoder: A Long-Range Pre-trained Language Model for Code Completion",
        "url": "http://arxiv.org/abs/2306.14893v1",
        "pub_date": "2023-06-26",
        "summary": "In this paper, we introduce a new task for code completion that focuses on\nhandling long code input and propose a sparse Transformer model, called\nLongCoder, to address this task. LongCoder employs a sliding window mechanism\nfor self-attention and introduces two types of globally accessible tokens -\nbridge tokens and memory tokens - to improve performance and efficiency. Bridge\ntokens are inserted throughout the input sequence to aggregate local\ninformation and facilitate global interaction, while memory tokens are included\nto highlight important statements that may be invoked later and need to be\nmemorized, such as package imports and definitions of classes, functions, or\nstructures. We conduct experiments on a newly constructed dataset that contains\nlonger code context and the publicly available CodeXGLUE benchmark.\nExperimental results demonstrate that LongCoder achieves superior performance\non code completion tasks compared to previous models while maintaining\ncomparable efficiency in terms of computational resources during inference. All\nthe codes and data are available at https://github.com/microsoft/CodeBERT.",
        "translated": "在本文中，我们介绍了一个新的代码完成任务，重点是处理长代码输入，并提出了一个稀疏变压器模型，所谓的 LongCoder，以解决这一问题。LongCoder 采用滑动窗口机制来自我关注，并引入了两种全局可访问令牌——桥接令牌和内存令牌——以提高性能和效率。在整个输入序列中插入桥标记，以聚合本地信息并促进全局交互，同时包含内存标记，以突出显示可能稍后调用并需要记忆的重要语句，例如包导入和类、函数或结构的定义。我们在一个新构建的数据集上进行实验，该数据集包含更长的代码上下文和公开可用的 CodeXGLUE 基准。实验结果表明，与以前的模型相比，LongCoder 在代码完成任务方面取得了更好的性能，同时在推理过程中保持了可比的计算资源效率。所有的代码和数据都在 https://github.com/microsoft/codebert。"
    },
    {
        "title": "Composing Parameter-Efficient Modules with Arithmetic Operations",
        "url": "http://arxiv.org/abs/2306.14870v1",
        "pub_date": "2023-06-26",
        "summary": "As an efficient alternative to conventional full finetuning,\nparameter-efficient finetuning (PEFT) is becoming the prevailing method to\nadapt pretrained language models. In PEFT, a lightweight module is learned on\neach dataset while the underlying pretrained language model remains unchanged,\nresulting in multiple compact modules representing diverse skills when applied\nto various domains and tasks. In this paper, we propose to compose these\nparameter-efficient modules through linear arithmetic operations in the weight\nspace, thereby integrating different module capabilities. Specifically, we\nfirst define addition and negation operators for the module, and then further\ncompose these two basic operators to perform flexible arithmetic. Our approach\nrequires \\emph{no additional training} and enables highly flexible module\ncomposition. We apply different arithmetic operations to compose the\nparameter-efficient modules for (1) distribution generalization, (2)\nmulti-tasking, (3) unlearning, and (4) domain transfer. Additionally, we extend\nour approach to detoxify Alpaca-LoRA, the latest instruction-tuned large\nlanguage model based on LLaMA. Empirical results demonstrate that our approach\nproduces new and effective parameter-efficient modules that significantly\noutperform existing ones across all settings.",
        "translated": "参数有效微调(PEFT)作为传统全微调的一种有效替代方法，正在成为适应预训练语言模型的主流方法。在 PEFT 中，在每个数据集上学习一个轻量级模块，而底层的预训练语言模型保持不变，导致多个紧凑模块在应用于各种领域和任务时代表不同的技能。本文提出通过权值空间中的线性算术运算来组合这些参数有效的模块，从而集成不同的模块功能。具体地说，我们首先定义了模块的加法运算符和否定运算符，然后进一步组合这两个基本运算符来执行灵活的算术运算。我们的方法不需要额外的训练，并且支持高度灵活的模块组合。我们应用不同的算术运算来组成参数有效的模块: (1)分布泛化，(2)多任务，(3)去学习，和(4)域转移。此外，我们扩展了我们的方法来解毒羊驼-LoRA，最新的指令调优大型语言模型的基础上 LLaMA。实证结果表明，我们的方法产生了新的和有效的参数效率模块，在所有环境中都明显优于现有模块。"
    },
    {
        "title": "Enriching the NArabizi Treebank: A Multifaceted Approach to Supporting\n  an Under-Resourced Language",
        "url": "http://arxiv.org/abs/2306.14866v1",
        "pub_date": "2023-06-26",
        "summary": "In this paper we address the scarcity of annotated data for NArabizi, a\nRomanized form of North African Arabic used mostly on social media, which poses\nchallenges for Natural Language Processing (NLP). We introduce an enriched\nversion of NArabizi Treebank (Seddah et al., 2020) with three main\ncontributions: the addition of two novel annotation layers (named entity\nrecognition and offensive language detection) and a re-annotation of the\ntokenization, morpho-syntactic and syntactic layers that ensure annotation\nconsistency. Our experimental results, using different tokenization schemes,\nshowcase the value of our contributions and highlight the impact of working\nwith non-gold tokenization for NER and dependency parsing. To facilitate future\nresearch, we make these annotations publicly available. Our enhanced NArabizi\nTreebank paves the way for creating sophisticated language models and NLP tools\nfor this under-represented language.",
        "translated": "在本文中，我们解决了 NArabizi 注释数据的稀缺性，这是一种主要在社交媒体上使用的北非阿拉伯语的罗马化形式，给自然语言处理(NLP)带来了挑战。我们介绍了 NArabizi Treebank 的一个丰富版本(Seddah 等，2020) ，其中包含三个主要贡献: 添加两个新的注释层(命名实体识别和攻击性语言检测) ，以及重新注释标记化，形态句法和句法层，以确保注释一致性。我们的实验结果使用不同的标记化方案，展示了我们的贡献的价值，并强调了使用 NER 和依赖性解析的非黄金标记化的影响。为了方便未来的研究，我们将这些注释公开发布。我们增强的 NArabizi Treebank 为为这种代表性不足的语言创建复杂的语言模型和 NLP 工具铺平了道路。"
    },
    {
        "title": "HonestBait: Forward References for Attractive but Faithful Headline\n  Generation",
        "url": "http://arxiv.org/abs/2306.14828v1",
        "pub_date": "2023-06-26",
        "summary": "Current methods for generating attractive headlines often learn directly from\ndata, which bases attractiveness on the number of user clicks and views.\nAlthough clicks or views do reflect user interest, they can fail to reveal how\nmuch interest is raised by the writing style and how much is due to the event\nor topic itself. Also, such approaches can lead to harmful inventions by\nover-exaggerating the content, aggravating the spread of false information. In\nthis work, we propose HonestBait, a novel framework for solving these issues\nfrom another aspect: generating headlines using forward references (FRs), a\nwriting technique often used for clickbait. A self-verification process is\nincluded during training to avoid spurious inventions. We begin with a\npreliminary user study to understand how FRs affect user interest, after which\nwe present PANCO1, an innovative dataset containing pairs of fake news with\nverified news for attractive but faithful news headline generation. Automatic\nmetrics and human evaluations show that our framework yields more attractive\nresults (+11.25% compared to human-written verified news headlines) while\nmaintaining high veracity, which helps promote real information to fight\nagainst fake news.",
        "translated": "目前生成有吸引力的标题的方法通常直接从数据中学习，这种方法基于用户点击和浏览次数的吸引力。虽然点击或浏览确实反映了用户的兴趣，但它们可能无法揭示写作风格引起了多少兴趣，以及有多少是由于事件或主题本身引起的。此外，这种方法可能会导致有害的发明过分夸大的内容，加剧传播虚假信息。在这项工作中，我们提出了 HonestBait，一个从另一个方面解决这些问题的新框架: 使用前向引用(FRs)生成标题，这是一种常用于点击诱饵的写作技巧。培训期间包括自我验证过程，以避免虚假发明。我们从一个初步的用户研究开始，以了解 FRs 如何影响用户的兴趣，然后我们提出 PANCO1，一个创新的数据集，包含对虚假新闻与核实新闻吸引人，但忠实的新闻标题生成。自动测量和人工评估表明，我们的框架产生更有吸引力的结果(+ 11.25% 相比，人写验证新闻标题) ，同时保持高的准确性，这有助于促进真实信息打击假新闻。"
    },
    {
        "title": "Vietnamese multi-document summary using subgraph selection approach --\n  VLSP 2022 AbMuSu Shared Task",
        "url": "http://arxiv.org/abs/2306.14827v1",
        "pub_date": "2023-06-26",
        "summary": "Document summarization is a task to generate afluent, condensed summary for a\ndocument, andkeep important information. A cluster of documents serves as the\ninput for multi-document summarizing (MDS), while the cluster summary serves as\nthe output. In this paper, we focus on transforming the extractive MDS problem\ninto subgraph selection. Approaching the problem in the form of graphs helps to\ncapture simultaneously the relationship between sentences in the same document\nand between sentences in the same cluster based on exploiting the overall graph\nstructure and selected subgraphs. Experiments have been implemented on the\nVietnamese dataset published in VLSP Evaluation Campaign 2022. This model\ncurrently results in the top 10 participating teams reported on the ROUGH-2\n$F\\_1$ measure on the public test set.",
        "translated": "文档摘要是为文档生成丰富、简洁的摘要并保存重要信息的任务。文档集群作为多文档摘要(MDS)的输入，而集群摘要作为输出。本文主要研究如何将抽取 MDS 问题转化为子图选择问题。利用图的整体结构和选择的子图，以图的形式来处理问题，有助于同时捕捉同一文档中的句子之间的关系和同一簇中的句子之间的关系。在2022年 VLSP 评估运动中发布的越南数据集上进行了实验。这个模型目前的结果是公开测试集上 ROUGH-2 $F _ 1 $测量报告的前10个参与团队。"
    },
    {
        "title": "Kosmos-2: Grounding Multimodal Large Language Models to the World",
        "url": "http://arxiv.org/abs/2306.14824v2",
        "pub_date": "2023-06-26",
        "summary": "We introduce Kosmos-2, a Multimodal Large Language Model (MLLM), enabling new\ncapabilities of perceiving object descriptions (e.g., bounding boxes) and\ngrounding text to the visual world. Specifically, we represent refer\nexpressions as links in Markdown, i.e., ``[text span](bounding boxes)'', where\nobject descriptions are sequences of location tokens. Together with multimodal\ncorpora, we construct large-scale data of grounded image-text pairs (called\nGrIT) to train the model. In addition to the existing capabilities of MLLMs\n(e.g., perceiving general modalities, following instructions, and performing\nin-context learning), Kosmos-2 integrates the grounding capability into\ndownstream applications. We evaluate Kosmos-2 on a wide range of tasks,\nincluding (i) multimodal grounding, such as referring expression comprehension,\nand phrase grounding, (ii) multimodal referring, such as referring expression\ngeneration, (iii) perception-language tasks, and (iv) language understanding\nand generation. This work lays out the foundation for the development of\nEmbodiment AI and sheds light on the big convergence of language, multimodal\nperception, action, and world modeling, which is a key step toward artificial\ngeneral intelligence. Data, demo, and pretrained models are available at\nhttps://aka.ms/kosmos-2.",
        "translated": "我们引入了 Kosmos-2，一个多模态大型语言模型(MLLM) ，支持感知对象描述(例如，边界框)和将文本接地到视觉世界的新功能。具体来说，我们将引用表达式表示为 Markdown 中的链接，即“[ text span ](边界框)”，其中对象描述是位置标记的序列。结合多模态语料库，我们构建了大规模的接地图像-文本对(GrIT)数据来训练模型。除了 MLLM 的现有功能(例如，感知一般模式、遵循指令和执行上下文学习) ，Kosmos-2将接地功能集成到下游应用程序中。我们对 Kosmos-2进行了广泛的任务评估，包括(i)多模态基础，如指称表达理解和短语基础，(ii)多模态指称，如指称表达生成，(iii)感知语言任务，以及(iv)语言理解和生成。本文的工作为体验式人工智能的发展奠定了基础，并阐明了语言、多模态感知、动作和世界建模的大趋同性，这是人工一般智能的关键步骤。数据，演示和预先训练的模型可在 https://aka.ms/kosmos-2。"
    },
    {
        "title": "Label-Aware Hyperbolic Embeddings for Fine-grained Emotion\n  Classification",
        "url": "http://arxiv.org/abs/2306.14822v1",
        "pub_date": "2023-06-26",
        "summary": "Fine-grained emotion classification (FEC) is a challenging task.\nSpecifically, FEC needs to handle subtle nuance between labels, which can be\ncomplex and confusing. Most existing models only address text classification\nproblem in the euclidean space, which we believe may not be the optimal\nsolution as labels of close semantic (e.g., afraid and terrified) may not be\ndifferentiated in such space, which harms the performance. In this paper, we\npropose HypEmo, a novel framework that can integrate hyperbolic embeddings to\nimprove the FEC task. First, we learn label embeddings in the hyperbolic space\nto better capture their hierarchical structure, and then our model projects\ncontextualized representations to the hyperbolic space to compute the distance\nbetween samples and labels. Experimental results show that incorporating such\ndistance to weight cross entropy loss substantially improves the performance\nwith significantly higher efficiency. We evaluate our proposed model on two\nbenchmark datasets and found 4.8% relative improvement compared to the previous\nstate of the art with 43.2% fewer parameters and 76.9% less training time. Code\nis available at https: //github.com/dinobby/HypEmo.",
        "translated": "细粒度情绪分类(FEC)是一项具有挑战性的任务。具体来说，FEC 需要处理标签之间的细微差别，这可能是复杂和混乱的。大多数现有的模型只能解决欧几里德空间中的文本分类问题，我们认为这可能不是最佳的解决方案，因为在这样的空间中，封闭语义(例如，害怕和恐惧)的标签可能不会被区分，这会损害性能。在本文中，我们提出了一个新的框架 HypEmo，它可以集成双曲嵌入来改善 FEC 任务。首先，我们学习在双曲空间中嵌入标签，以便更好地捕捉它们的层次结构，然后我们的模型将上下文化的表示投射到双曲空间中，以计算样本和标签之间的距离。实验结果表明，这种距离加权交叉熵损失大大提高了性能，显著提高了效率。我们在两个基准数据集上评估了我们提出的模型，发现与先前的技术水平相比，参数减少了43.2% ，训练时间减少了76.9% ，相对改善了4.8% 。代码可在 https:// github.com/dinobby/hypemo 下载。"
    },
    {
        "title": "A Positive-Unlabeled Metric Learning Framework for Document-Level\n  Relation Extraction with Incomplete Labeling",
        "url": "http://arxiv.org/abs/2306.14806v1",
        "pub_date": "2023-06-26",
        "summary": "The goal of document-level relation extraction (RE) is to identify relations\nbetween entities that span multiple sentences. Recently, incomplete labeling in\ndocument-level RE has received increasing attention, and some studies have used\nmethods such as positive-unlabeled learning to tackle this issue, but there is\nstill a lot of room for improvement. Motivated by this, we propose a\npositive-augmentation and positive-mixup positive-unlabeled metric learning\nframework (P3M). Specifically, we formulate document-level RE as a metric\nlearning problem. We aim to pull the distance closer between entity pair\nembedding and their corresponding relation embedding, while pushing it farther\naway from the none-class relation embedding. Additionally, we adapt the\npositive-unlabeled learning to this loss objective. In order to improve the\ngeneralizability of the model, we use dropout to augment positive samples and\npropose a positive-none-class mixup method. Extensive experiments show that P3M\nimproves the F1 score by approximately 4-10 points in document-level RE with\nincomplete labeling, and achieves state-of-the-art results in fully labeled\nscenarios. Furthermore, P3M has also demonstrated robustness to prior\nestimation bias in incomplete labeled scenarios.",
        "translated": "文档级关系抽取(RE)的目标是识别跨越多个句子的实体之间的关系。近年来，文档级 RE 中的不完全标注问题受到越来越多的关注，一些研究已经采用了积极-未标注学习等方法来解决这一问题，但仍有很大的改进空间。基于此，我们提出了一个正增强和正混合的正未标记度量学习框架(P3M)。具体来说，我们将文档级 RE 作为一个度量学习问题来描述。我们的目标是拉近实体对嵌入与其对应关系嵌入之间的距离，同时使其远离非类关系嵌入。此外，我们调整正向未标记学习来适应这种损失目标。为了提高模型的泛化能力，我们使用辍学来增加正样本，并提出了一种正非类混合方法。大量的实验表明，P3M 在不完全标记的文档级 RE 中提高了 F1评分约4-10分，并在完全标记的场景中取得了最新的结果。此外，在不完全标记的情况下，P3M 也表现出对先前估计偏差的鲁棒性。"
    },
    {
        "title": "Unleashing the Power of User Reviews: Exploring Airline Choices at\n  Catania Airport, Italy",
        "url": "http://arxiv.org/abs/2306.15541v1",
        "pub_date": "2023-06-27",
        "summary": "This study aims to investigate the possible relationship between the\nmechanisms of social influence and the choice of airline, through the use of\nnew tools, with the aim of understanding whether they can contribute to a\nbetter understanding of the factors influencing the decisions of consumers in\nthe aviation sector. We have chosen to extract user reviews from well-known\nplatforms: Trustpilot, Google, and Twitter. By combining web scraping\ntechniques, we have been able to collect a comprehensive dataset comprising a\nwide range of user opinions, feedback, and ratings. We then refined the BERT\nmodel to focus on insightful sentiment in the context of airline reviews.\nThrough our analysis, we observed an intriguing trend of average negative\nsentiment scores across various airlines, giving us deeper insight into the\ndynamics between airlines and helping us identify key partnerships, popular\nroutes, and airlines that play a central role in the aeronautical ecosystem of\nCatania airport during the specified period. Our investigation led us to find\nthat, despite an airline having received prestigious awards as a low-cost\nleader in Europe for two consecutive years 2021 and 2022, the \"Catanese\" user\ntends to suffer the dominant position of other companies. Understanding the\nimpact of positive reviews and leveraging sentiment analysis can help airlines\nimprove their reputation, attract more customers, and ultimately gain a\ncompetitive edge in the marketplace.",
        "translated": "本研究旨在通过使用新工具，调查社会影响机制与航空公司选择之间的可能关系，以了解这些机制是否有助于更好地理解影响航空部门消费者决定的因素。我们选择从著名的平台提取用户评论: TrustPilot、 Google 和 Twitter。通过结合网络抓取技术，我们已经能够收集一个全面的数据集，包括广泛的用户意见，反馈和评级。然后，我们改进了 BERT 模型，将重点放在航空公司评论背景下的深刻情感上。通过我们的分析，我们发现了一个有趣的趋势，即不同航空公司的平均负面情绪得分，这使我们能够更深入地了解航空公司之间的动态，并帮助我们确定在特定时期内在卡塔尼亚机场航空生态系统中发挥核心作用的关键合作伙伴、热门航线和航空公司。我们的调查使我们发现，尽管一家航空公司在2021年和2022年连续两年获得欧洲低成本领先者的殊荣，但“卡塔尼亚”用户往往会受到其他公司的支配地位的影响。了解正面评价的影响力和利用情绪分析可以帮助航空公司提高他们的声誉，吸引更多的客户，并最终获得市场竞争优势。"
    },
    {
        "title": "Learning to Rank in Generative Retrieval",
        "url": "http://arxiv.org/abs/2306.15222v1",
        "pub_date": "2023-06-27",
        "summary": "Generative retrieval is a promising new paradigm in text retrieval that\ngenerates identifier strings of relevant passages as the retrieval target. This\nparadigm leverages powerful generation models and represents a new paradigm\ndistinct from traditional learning-to-rank methods. However, despite its rapid\ndevelopment, current generative retrieval methods are still limited. They\ntypically rely on a heuristic function to transform predicted identifiers into\na passage rank list, which creates a gap between the learning objective of\ngenerative retrieval and the desired passage ranking target. Moreover, the\ninherent exposure bias problem of text generation also persists in generative\nretrieval. To address these issues, we propose a novel framework, called LTRGR,\nthat combines generative retrieval with the classical learning-to-rank\nparadigm. Our approach involves training an autoregressive model using a\npassage rank loss, which directly optimizes the autoregressive model toward the\noptimal passage ranking. This framework only requires an additional training\nstep to enhance current generative retrieval systems and does not add any\nburden to the inference stage. We conducted experiments on three public\ndatasets, and our results demonstrate that LTRGR achieves state-of-the-art\nperformance among generative retrieval methods, indicating its effectiveness\nand robustness.",
        "translated": "生成检索是文本检索领域一个很有前途的新范式，它以相关段落的标识符串作为检索对象。这种模式利用了强大的生成模型，代表了一种有别于传统的学习排名方法的新模式。然而，尽管生成检索技术发展迅速，目前的生成检索方法仍然有限。它们通常依靠启发式函数将预测的标识符转换成一个段落等级列表，从而在生成检索的学习目标和期望的段落等级目标之间产生一个差距。此外，文本生成过程中固有的暴露偏差问题在生成检索中也存在。为了解决这些问题，我们提出了一个新的框架，称为 LTRGR，结合生成检索与经典的学习到秩范式。我们的方法包括训练一个自回归模型使用通过等级损失，直接优化自回归模型的最佳通过等级。该框架只需要一个额外的培训步骤，以加强目前的生成检索系统，并没有增加任何负担的推理阶段。我们在三个公共数据集上进行了实验，结果表明 LTRGR 在生成检索方法中取得了最好的性能，表明了其有效性和鲁棒性。"
    },
    {
        "title": "Off-Policy Evaluation of Ranking Policies under Diverse User Behavior",
        "url": "http://arxiv.org/abs/2306.15098v1",
        "pub_date": "2023-06-26",
        "summary": "Ranking interfaces are everywhere in online platforms. There is thus an ever\ngrowing interest in their Off-Policy Evaluation (OPE), aiming towards an\naccurate performance evaluation of ranking policies using logged data. A\nde-facto approach for OPE is Inverse Propensity Scoring (IPS), which provides\nan unbiased and consistent value estimate. However, it becomes extremely\ninaccurate in the ranking setup due to its high variance under large action\nspaces. To deal with this problem, previous studies assume either independent\nor cascade user behavior, resulting in some ranking versions of IPS. While\nthese estimators are somewhat effective in reducing the variance, all existing\nestimators apply a single universal assumption to every user, causing excessive\nbias and variance. Therefore, this work explores a far more general formulation\nwhere user behavior is diverse and can vary depending on the user context. We\nshow that the resulting estimator, which we call Adaptive IPS (AIPS), can be\nunbiased under any complex user behavior. Moreover, AIPS achieves the minimum\nvariance among all unbiased estimators based on IPS. We further develop a\nprocedure to identify the appropriate user behavior model to minimize the mean\nsquared error (MSE) of AIPS in a data-driven fashion. Extensive experiments\ndemonstrate that the empirical accuracy improvement can be significant,\nenabling effective OPE of ranking systems even under diverse user behavior.",
        "translated": "在线平台中，排序界面无处不在。因此，人们对非策略评估(OPE)越来越感兴趣，其目标是使用日志数据对策略进行准确的性能评估。OPE 的一个事实上的方法是反倾向评分(IPS) ，它提供了一个无偏和一致的价值估计。然而，它变得非常不准确的排名设置，由于其高方差下的大行动空间。为了解决这个问题，以前的研究假设独立或级联用户行为，导致一些排名版本的 IPS。虽然这些估计量在减少方差方面有一定的效果，但是所有现有的估计量都对每个用户适用一个统一的假设，从而导致过度的偏差和方差。因此，这项工作探索了一个更一般的公式，其中用户行为是多样的，可以根据用户上下文而变化。我们证明了所得到的估计量，我们称之为自适应 IPS (AIPS) ，在任何复杂的用户行为下都是无偏的。此外，AIPS 在所有基于 IPS 的无偏估计量之间实现了最小方差。我们进一步开发了一个程序，以确定适当的用户行为模型，从而以数据驱动的方式最大限度地减少 AIPS 的均方差。大量的实验表明，经验的准确性改善可以是显着的，使有效的排名系统的 OPE 即使在不同的用户行为。"
    },
    {
        "title": "Efficient High-Resolution Template Matching with Vector Quantized\n  Nearest Neighbour Fields",
        "url": "http://arxiv.org/abs/2306.15010v1",
        "pub_date": "2023-06-26",
        "summary": "Template matching is a fundamental problem in computer vision and has\napplications in various fields, such as object detection, image registration,\nand object tracking. The current state-of-the-art methods rely on\nnearest-neighbour (NN) matching in which the query feature space is converted\nto NN space by representing each query pixel with its NN in the template\npixels. The NN-based methods have been shown to perform better in occlusions,\nchanges in appearance, illumination variations, and non-rigid transformations.\nHowever, NN matching scales poorly with high-resolution data and high feature\ndimensions. In this work, we present an NN-based template-matching method which\nefficiently reduces the NN computations and introduces filtering in the NN\nfields to consider deformations. A vector quantization step first represents\nthe template with $k$ features, then filtering compares the template and query\ndistributions over the $k$ features. We show that state-of-the-art performance\nwas achieved in low-resolution data, and our method outperforms previous\nmethods at higher resolution showing the robustness and scalability of the\napproach.",
        "translated": "模板匹配是计算机视觉中的一个基本问题，在目标检测、图像配准和目标跟踪等领域有着广泛的应用。目前的方法主要依赖于最近邻(NN)匹配，通过在模板像素中表示每个查询像素及其神经网络，将查询特征空间转换为 NN 空间。基于神经网络的方法已被证明在遮挡、外观变化、光照变化和非刚性转换中表现更好。然而，高分辨率数据和高特征维数的神经网络匹配规模较小。本文提出了一种基于神经网络的模板匹配方法，该方法有效地减少了神经网络的计算量，并在神经网络中引入滤波以考虑变形。一个向量量化步骤首先表示具有 $k $特性的模板，然后过滤比较模板和查询发行版本中的 $k $特性。实验结果表明，该方法在低分辨率数据中取得了较好的性能，并且在较高分辨率下优于以往的方法，显示了该方法的鲁棒性和可扩展性。"
    },
    {
        "title": "SparseOptimizer: Sparsify Language Models through Moreau-Yosida\n  Regularization and Accelerate through Compiler Co-design",
        "url": "http://arxiv.org/abs/2306.15656v1",
        "pub_date": "2023-06-27",
        "summary": "This paper introduces SparseOptimizer, a novel deep learning optimizer that\nexploits Moreau-Yosida regularization to naturally induce sparsity in large\nlanguage models such as BERT, ALBERT and GPT. Key to the design of\nSparseOptimizer is an embedded shrinkage operator, which imparts sparsity\ndirectly within the optimization process. This operator, backed by a sound\ntheoretical framework, includes an analytical solution, thereby reinforcing the\noptimizer's robustness and efficacy. Crucially, SparseOptimizer's plug-and-play\nfunctionality eradicates the need for code modifications, making it a\nuniversally adaptable tool for a wide array of large language models. Empirical\nevaluations on benchmark datasets such as GLUE, RACE, SQuAD1, and SQuAD2\nconfirm that SparseBERT and SparseALBERT, when sparsified using\nSparseOptimizer, achieve performance comparable to their dense counterparts,\nBERT and ALBERT, while significantly reducing their parameter count. Further,\nthis work proposes an innovative optimizer-compiler co-design strategy,\ndemonstrating the potential of inference acceleration (\\textbf{3.37x},\n\\textbf{6.30x}, and \\textbf{7.15x} in comparison with Pytorch, TensorFlow, and\nLLVM generic compile, respectively) in SparseBERT when paired with an\nappropriately designed compiler. This study represents a significant step\nforward in the evolution of efficient, scalable, and high-performing large\nlanguage models, setting a precedent for future exploration and optimization in\nthis domain. The SparseOptimizer code and SparseALBERT model will be made\navailable upon paper acceptance.",
        "translated": "本文介绍了一种新型的深度学习优化器 SparseOptimizer，它利用 Moreau-Yosida 正则化在 BERT、 ALBERT 和 GPT 等大型语言模型中自然地引入稀疏性。稀疏优化器设计的关键是嵌入式收缩算子，它在优化过程中直接赋予稀疏性。这个操作符，由一个健全的理论框架支持，包括一个分析解决方案，从而增强了优化器的健壮性和有效性。至关重要的是，SparseOptimizer 的即插即用功能消除了对代码修改的需要，使其成为一个普遍适用于大量大型语言模型的工具。对基准数据集(如 GLUE、 RACE、 SQuAD1和 SQuAD2)的实证评估证实，当使用 SparseOptimizer 稀疏化时，SparseBERT 和 SparseALBERT 的性能可以与其密集对应的 BERT 和 ALBERT 相媲美，同时大大减少了它们的参数计数。此外，这项工作提出了一个创新的优化器-编译器协同设计策略，展示了推理加速的潜力(textbf {3.37 x } ，textbf {6.30 x } ，和 textbf {7.15 x } ，分别与 Pytorch，TensorFlow 和 LLVM 通用编译进行比较)在 SparseBERT 与适当设计的编译器配对时。这项研究代表了在高效、可扩展和高性能的大型语言模型的发展方面向前迈出的重要一步，为该领域未来的探索和优化开创了先例。SparseOptimizer 代码和 SparseALBERT 模型将在纸张验收时提供。"
    },
    {
        "title": "Style-transfer based Speech and Audio-visual Scene Understanding for\n  Robot Action Sequence Acquisition from Videos",
        "url": "http://arxiv.org/abs/2306.15644v1",
        "pub_date": "2023-06-27",
        "summary": "To realize human-robot collaboration, robots need to execute actions for new\ntasks according to human instructions given finite prior knowledge. Human\nexperts can share their knowledge of how to perform a task with a robot through\nmulti-modal instructions in their demonstrations, showing a sequence of\nshort-horizon steps to achieve a long-horizon goal. This paper introduces a\nmethod for robot action sequence generation from instruction videos using (1)\nan audio-visual Transformer that converts audio-visual features and instruction\nspeech to a sequence of robot actions called dynamic movement primitives (DMPs)\nand (2) style-transfer-based training that employs multi-task learning with\nvideo captioning and weakly-supervised learning with a semantic classifier to\nexploit unpaired video-action data. We built a system that accomplishes various\ncooking actions, where an arm robot executes a DMP sequence acquired from a\ncooking video using the audio-visual Transformer. Experiments with\nEpic-Kitchen-100, YouCookII, QuerYD, and in-house instruction video datasets\nshow that the proposed method improves the quality of DMP sequences by 2.3\ntimes the METEOR score obtained with a baseline video-to-action Transformer.\nThe model achieved 32% of the task success rate with the task knowledge of the\nobject.",
        "translated": "为了实现人机协作，机器人需要根据给定有限先验知识的人工指令执行新任务的操作。人类专家可以在演示中通过多模态指令与机器人分享他们如何执行任务的知识，展示一系列实现长期目标的短期步骤。本文介绍了一种利用(1)音视频转换器将音视频特征和指令语音转换为机器人动作序列即动态运动原语(DMP)的机器人动作序列生成方法，以及(2)基于样式转换的训练方法，该方法采用带视频字幕的多任务学习和带语义分类器的弱监督学习来利用未配对的视频动作数据。我们建立了一个系统，完成各种烹饪动作，其中一个手臂机器人执行一个 DMP 序列从烹饪视频获得使用视听变压器。Epic-Kitchen-100、 YouCookII、 QuerYD 和内部指令视频数据集的实验表明，该方法提高了 DMP 序列的质量，是基线视频到行动变压器获得的 METEOR 评分的2.3倍。该模型利用对象的任务知识实现了32% 的任务成功率。"
    },
    {
        "title": "Automatic Annotation of Direct Speech in Written French Narratives",
        "url": "http://arxiv.org/abs/2306.15634v2",
        "pub_date": "2023-06-27",
        "summary": "The automatic annotation of direct speech (AADS) in written text has been\noften used in computational narrative understanding. Methods based on either\nrules or deep neural networks have been explored, in particular for English or\nGerman languages. Yet, for French, our target language, not many works exist.\nOur goal is to create a unified framework to design and evaluate AADS models in\nFrench. For this, we consolidated the largest-to-date French narrative dataset\nannotated with DS per word; we adapted various baselines for sequence labelling\nor from AADS in other languages; and we designed and conducted an extensive\nevaluation focused on generalisation. Results show that the task still requires\nsubstantial efforts and emphasise characteristics of each baseline. Although\nthis framework could be improved, it is a step further to encourage more\nresearch on the topic.",
        "translated": "书面文本中直接引语的自动注释(AADS)在计算性叙事理解中得到了广泛的应用。基于规则或深层神经网络的方法已经被探索，特别是对于英语或德语。然而，对于我们的目标语言法语来说，没有多少作品存在。我们的目标是创建一个统一的框架来设计和评估法语 AADS 模型。为此，我们整合了迄今为止最大的法语叙事数据集，每个单词用 DS 注释; 我们调整了序列标签或其他语言的 AADS 的各种基线; 我们设计并进行了广泛的评估，重点是泛化。结果表明，这项任务仍然需要大量的努力，并强调每个基线的特点。虽然这个框架可以得到改进，但这是鼓励对这个主题进行更多研究的进一步步骤。"
    },
    {
        "title": "Constructing Multilingual Code Search Dataset Using Neural Machine\n  Translation",
        "url": "http://arxiv.org/abs/2306.15604v1",
        "pub_date": "2023-06-27",
        "summary": "Code search is a task to find programming codes that semantically match the\ngiven natural language queries. Even though some of the existing datasets for\nthis task are multilingual on the programming language side, their query data\nare only in English. In this research, we create a multilingual code search\ndataset in four natural and four programming languages using a neural machine\ntranslation model. Using our dataset, we pre-train and fine-tune the\nTransformer-based models and then evaluate them on multiple code search test\nsets. Our results show that the model pre-trained with all natural and\nprogramming language data has performed best in most cases. By applying\nback-translation data filtering to our dataset, we demonstrate that the\ntranslation quality affects the model's performance to a certain extent, but\nthe data size matters more.",
        "translated": "代码搜索是一项任务，用于查找在语义上匹配给定自然语言查询的编程代码。尽管用于此任务的一些现有数据集在编程语言方面是多语言的，但是它们的查询数据仅使用英语。在这项研究中，我们使用神经机器翻译模型，用四种自然语言和四种编程语言创建了一个多语言的代码搜索数据集。使用我们的数据集，我们预先训练和微调基于 Transformer 的模型，然后在多个代码搜索测试集上对它们进行评估。我们的结果表明，在大多数情况下，使用所有自然语言和编程语言数据预先训练的模型表现最好。通过对我们的数据集进行反向翻译数据过滤，我们发现翻译质量在一定程度上影响了模型的性能，但是数据的大小更重要。"
    },
    {
        "title": "Extending Context Window of Large Language Models via Positional\n  Interpolation",
        "url": "http://arxiv.org/abs/2306.15595v2",
        "pub_date": "2023-06-27",
        "summary": "We present Position Interpolation (PI) that extends the context window sizes\nof RoPE-based pretrained LLMs such as LLaMA models to up to 32768 with minimal\nfine-tuning (within 1000 steps), while demonstrating strong empirical results\non various tasks that require long context, including passkey retrieval,\nlanguage modeling, and long document summarization from LLaMA 7B to 65B.\nMeanwhile, the extended model by Position Interpolation preserve quality\nrelatively well on tasks within its original context window. To achieve this\ngoal, Position Interpolation linearly down-scales the input position indices to\nmatch the original context window size, rather than extrapolating beyond the\ntrained context length which may lead to catastrophically high attention scores\nthat completely ruin the self-attention mechanism. Our theoretical study shows\nthat the upper bound of interpolation is at least $\\sim 600 \\times$ smaller\nthan that of extrapolation, further demonstrating its stability. Models\nextended via Position Interpolation retain its original architecture and can\nreuse most pre-existing optimization and infrastructure.",
        "translated": "我们提出了位置插值(PI) ，扩展了基于 RoPE 的预训练 LLM (如 LLaMA 模型)的上下文窗口大小，以最小的微调(在1000个步骤内)达到32768，同时在需要长上下文的各种任务上展示了强大的经验结果，包括密钥检索，语言建模和从 LLaMA 7B 到65B 的长文档摘要。同时，通过位置插值的扩展模型在其原始上下文窗口中较好地保持了任务的质量。为了达到这个目标，位置插值线性地降低输入位置指数，以匹配原始上下文窗口大小，而不是外推超过训练的上下文长度，这可能导致灾难性的高注意分数，完全破坏了自我注意机制。我们的理论研究表明，插值的上界至少比外推的上界小600倍，进一步证明了插值的稳定性。通过位置插值扩展的模型保留了其原有的体系结构，并且可以重用大多数预先存在的优化和基础设施。"
    },
    {
        "title": "CrunchGPT: A chatGPT assisted framework for scientific machine learning",
        "url": "http://arxiv.org/abs/2306.15551v1",
        "pub_date": "2023-06-27",
        "summary": "Scientific Machine Learning (SciML) has advanced recently across many\ndifferent areas in computational science and engineering. The objective is to\nintegrate data and physics seamlessly without the need of employing elaborate\nand computationally taxing data assimilation schemes. However, preprocessing,\nproblem formulation, code generation, postprocessing and analysis are still\ntime consuming and may prevent SciML from wide applicability in industrial\napplications and in digital twin frameworks. Here, we integrate the various\nstages of SciML under the umbrella of ChatGPT, to formulate CrunchGPT, which\nplays the role of a conductor orchestrating the entire workflow of SciML based\non simple prompts by the user. Specifically, we present two examples that\ndemonstrate the potential use of CrunchGPT in optimizing airfoils in\naerodynamics, and in obtaining flow fields in various geometries in interactive\nmode, with emphasis on the validation stage. To demonstrate the flow of the\nCrunchGPT, and create an infrastructure that can facilitate a broader vision,\nwe built a webapp based guided user interface, that includes options for a\ncomprehensive summary report. The overall objective is to extend CrunchGPT to\nhandle diverse problems in computational mechanics, design, optimization and\ncontrols, and general scientific computing tasks involved in SciML, hence using\nit as a research assistant tool but also as an educational tool. While here the\nexamples focus in fluid mechanics, future versions will target solid mechanics\nand materials science, geophysics, systems biology and bioinformatics.",
        "translated": "科学机器学习(sciML)最近在许多不同的计算科学与工程领域取得了进展。我们的目标是无缝集成数据和物理，而不需要采用复杂的计算数据同化。然而，预处理、问题制定、代码生成、后处理和分析仍然非常耗时，可能会妨碍 SciML 在工业应用和数字双框架中的广泛适用性。在这里，我们将 SciML 的各个阶段集成在 ChatGPT 的保护伞下，以形成 CrunchGPT，它扮演着指挥者的角色，根据用户的简单提示编排 SciML 的整个工作流程。具体来说，我们提出了两个例子，展示了 CrunchGPT 在空气动力学中优化翼型的潜在用途，以及在交互模式下获得各种几何形状的流场，重点是验证阶段。为了演示 CrunchGPT 的流程，并创建一个可以促进更广阔视野的基础设施，我们构建了一个基于 Web 应用的指导用户界面，其中包括一个全面摘要报告的选项。总体目标是扩展 CrunchGPT，以处理计算力学、设计、优化和控制方面的各种问题，以及与 SciML 相关的一般科学计算任务，从而将其用作研究辅助工具，同时也用作教育工具。虽然这里的例子集中在流体力学，未来的版本将针对固体力学和材料科学，地球物理学，系统生物学和生物信息学。"
    },
    {
        "title": "CamemBERT-bio: a Tasty French Language Model Better for your Health",
        "url": "http://arxiv.org/abs/2306.15550v1",
        "pub_date": "2023-06-27",
        "summary": "Clinical data in hospitals are increasingly accessible for research through\nclinical data warehouses, however these documents are unstructured. It is\ntherefore necessary to extract information from medical reports to conduct\nclinical studies. Transfer learning with BERT-like models such as CamemBERT has\nallowed major advances, especially for named entity recognition. However, these\nmodels are trained for plain language and are less efficient on biomedical\ndata. This is why we propose a new French public biomedical dataset on which we\nhave continued the pre-training of CamemBERT. Thus, we introduce a first\nversion of CamemBERT-bio, a specialized public model for the French biomedical\ndomain that shows 2.54 points of F1 score improvement on average on different\nbiomedical named entity recognition tasks.",
        "translated": "医院的临床数据越来越多地可以通过临床数据仓库进行研究，但是这些文档是非结构化的。因此，有必要从医疗报告中提取信息进行临床研究。使用诸如 CamemBERT 之类的 BERT 模型的转移学习已经取得了重大进展，特别是对命名实体识别。然而，这些模型都是针对简单语言进行训练的，对生物医学数据的处理效率较低。这就是为什么我们提出了一个新的法国公共生物医学数据集，我们已经继续在 CamemBERT 的预训练。因此，我们引入了 CamemBERT-bio 的第一个版本，这是法国生物医学领域的专门公共模型，在不同的生物医学命名实体识别任务中平均显示 F1评分改善2.54分。"
    },
    {
        "title": "Paradigm Shift in Sustainability Disclosure Analysis: Empowering\n  Stakeholders with CHATREPORT, a Language Model-Based Tool",
        "url": "http://arxiv.org/abs/2306.15518v1",
        "pub_date": "2023-06-27",
        "summary": "This paper introduces a novel approach to enhance Large Language Models\n(LLMs) with expert knowledge to automate the analysis of corporate\nsustainability reports by benchmarking them against the Task Force for\nClimate-Related Financial Disclosures (TCFD) recommendations. Corporate\nsustainability reports are crucial in assessing organizations' environmental\nand social risks and impacts. However, analyzing these reports' vast amounts of\ninformation makes human analysis often too costly. As a result, only a few\nentities worldwide have the resources to analyze these reports, which could\nlead to a lack of transparency. While AI-powered tools can automatically\nanalyze the data, they are prone to inaccuracies as they lack domain-specific\nexpertise. This paper introduces a novel approach to enhance LLMs with expert\nknowledge to automate the analysis of corporate sustainability reports. We\nchristen our tool CHATREPORT, and apply it in a first use case to assess\ncorporate climate risk disclosures following the TCFD recommendations.\nCHATREPORT results from collaborating with experts in climate science, finance,\neconomic policy, and computer science, demonstrating how domain experts can be\ninvolved in developing AI tools. We make our prompt templates, generated data,\nand scores available to the public to encourage transparency.",
        "translated": "本文介绍了一种新颖的方法来增强大型语言模型(LLM)的专家知识，以自动化的分析公司可持续性报告的基准对气候相关的财务披露工作队(TCFD)的建议。企业可持续性报告对于评估组织的环境和社会风险及影响至关重要。然而，分析这些报告的海量信息往往使人工分析成本过高。因此，全世界只有少数几个实体有资源来分析这些报告，这可能导致缺乏透明度。虽然人工智能驱动的工具可以自动分析数据，但由于缺乏特定领域的专业知识，它们很容易出现错误。本文介绍了一种利用专家知识增强 LLM 的新方法，使企业可持续发展报告的分析自动化。我们将我们的工具命名为 CHATREPORT，并在第一个用例中应用它来评估遵循 TCFD 建议的企业气候风险披露。CHATREPORT 是与气候科学、金融、经济政策和计算机科学领域的专家合作的成果，展示了领域专家如何参与人工智能工具的开发。我们将提示模板、生成的数据和分数提供给公众，以鼓励透明度。"
    },
    {
        "title": "Using Large Language Models to Provide Explanatory Feedback to Human\n  Tutors",
        "url": "http://arxiv.org/abs/2306.15498v1",
        "pub_date": "2023-06-27",
        "summary": "Research demonstrates learners engaging in the process of producing\nexplanations to support their reasoning, can have a positive impact on\nlearning. However, providing learners real-time explanatory feedback often\npresents challenges related to classification accuracy, particularly in\ndomain-specific environments, containing situationally complex and nuanced\nresponses. We present two approaches for supplying tutors real-time feedback\nwithin an online lesson on how to give students effective praise. This\nwork-in-progress demonstrates considerable accuracy in binary classification\nfor corrective feedback of effective, or effort-based (F1 score = 0.811), and\nineffective, or outcome-based (F1 score = 0.350), praise responses. More\nnotably, we introduce progress towards an enhanced approach of providing\nexplanatory feedback using large language model-facilitated named entity\nrecognition, which can provide tutors feedback, not only while engaging in\nlessons, but can potentially suggest real-time tutor moves. Future work\ninvolves leveraging large language models for data augmentation to improve\naccuracy, while also developing an explanatory feedback interface.",
        "translated": "研究表明，学习者在产生解释的过程中支持自己的推理，可以对学习产生积极的影响。然而，为学习者提供实时的解释性反馈往往会带来与分类准确性相关的挑战，特别是在特定领域的环境中，包含情境复杂和微妙的反馈。我们提出了两种方法，以提供实时反馈的在线教学如何给予学生有效的表扬。这项正在进行的工作表明，对于有效的或基于努力的(F1评分 = 0.811)和无效的或基于结果的(F1评分 = 0.350)表扬反馈的纠正反馈的二元分类具有相当大的准确性。更值得注意的是，我们使用大型语言模型促进的命名实体识别引入了提供解释性反馈的强化方法，这种方法不仅可以在上课时提供导师反馈，而且可以潜在地提出实时导师动作。未来的工作包括利用大型语言模型进行数据增强以提高准确性，同时还要开发一个解释性反馈接口。"
    },
    {
        "title": "SE-PQA: Personalized Community Question Answering",
        "url": "http://arxiv.org/abs/2306.16261v1",
        "pub_date": "2023-06-28",
        "summary": "Personalization in Information Retrieval is a topic studied for a long time.\nNevertheless, there is still a lack of high-quality, real-world datasets to\nconduct large-scale experiments and evaluate models for personalized search.\nThis paper contributes to filling this gap by introducing SE-PQA (StackExchange\n- Personalized Question Answering), a new curated resource to design and\nevaluate personalized models related to the task of community Question\nAnswering (cQA). The contributed dataset includes more than 1 million queries\nand 2 million answers, annotated with a rich set of features modeling the\nsocial interactions among the users of a popular cQA platform. We describe the\ncharacteristics of SE-PQA and detail the features associated with questions and\nanswers. We also provide reproducible baseline methods for the cQA task based\non the resource, including deep learning models and personalization approaches.\nThe results of the preliminary experiments conducted show the appropriateness\nof SE-PQA to train effective cQA models; they also show that personalization\nremarkably improves the effectiveness of all the methods tested. Furthermore,\nwe show the benefits in terms of robustness and generalization of combining\ndata from multiple communities for personalization purposes.",
        "translated": "信息检索的个性化是一个长期研究的课题。尽管如此，仍然缺乏高质量的真实世界的数据集来进行大规模的实验和评估个性化检索模型。本文通过引入 SE-PQA 来填补这一空白。 SE-PQA 是一种新的策划资源，用于设计和评估与社区问答任务(cQA)相关的个性化模型。贡献的数据集包括超过100万个查询和200万个答案，并用一组丰富的特性对流行的 cQA 平台的用户之间的社交互动进行了建模。我们描述了 SE-PQA 的特征，并详细描述了与问答相关的特征。我们还为基于资源的 cQA 任务提供了可重复的基线方法，包括深度学习模型和个性化方法。初步实验结果表明，SE-PQA 方法训练有效的 cQA 模型是合适的，并且个性化显著提高了所有测试方法的有效性。此外，我们还展示了将来自多个社区的数据用于个性化目的的健壮性和通用性方面的好处。"
    },
    {
        "title": "Query Understanding in the Age of Large Language Models",
        "url": "http://arxiv.org/abs/2306.16004v1",
        "pub_date": "2023-06-28",
        "summary": "Querying, conversing, and controlling search and information-seeking\ninterfaces using natural language are fast becoming ubiquitous with the rise\nand adoption of large-language models (LLM). In this position paper, we\ndescribe a generic framework for interactive query-rewriting using LLMs. Our\nproposal aims to unfold new opportunities for improved and transparent intent\nunderstanding while building high-performance retrieval systems using LLMs. A\nkey aspect of our framework is the ability of the rewriter to fully specify the\nmachine intent by the search engine in natural language that can be further\nrefined, controlled, and edited before the final retrieval phase. The ability\nto present, interact, and reason over the underlying machine intent in natural\nlanguage has profound implications on transparency, ranking performance, and a\ndeparture from the traditional way in which supervised signals were collected\nfor understanding intents. We detail the concept, backed by initial\nexperiments, along with open questions for this interactive query understanding\nframework.",
        "translated": "随着大语言模型(LLM)的兴起和采用，使用自然语言进行查询、转换和控制搜索和信息搜索界面正迅速变得无处不在。在本文中，我们描述了一个使用 LLM 进行交互式查询重写的通用框架。我们的建议旨在开辟新的机会，以改善和透明的意图理解，同时建立使用 LLM 的高性能检索系统。我们框架的一个关键方面是重写器能够通过自然语言完全指定搜索引擎的机器意图，在最终检索阶段之前可以进一步细化、控制和编辑。在自然语言中呈现、交互和推理潜在机器意图的能力对透明度、排序性能有着深远的影响，并且背离了传统的为理解意图而收集监督信号的方式。我们详细介绍了这个概念，并进行了初步的实验，同时还提出了这个交互式查询理解框架的开放式问题。"
    },
    {
        "title": "Streamlining Social Media Information Retrieval for Public Health\n  Research with Deep Learning",
        "url": "http://arxiv.org/abs/2306.16001v1",
        "pub_date": "2023-06-28",
        "summary": "The utilization of social media in epidemic surveillance has been well\nestablished. Nonetheless, bias is often introduced when pre-defined lexicons\nare used to retrieve relevant corpus. This study introduces a framework aimed\nat curating extensive dictionaries of medical colloquialisms and Unified\nMedical Language System (UMLS) concepts. The framework comprises three modules:\na BERT-based Named Entity Recognition (NER) model that identifies medical\nentities from social media content, a deep-learning powered normalization\nmodule that standardizes the extracted entities, and a semi-supervised\nclustering module that assigns the most probable UMLS concept to each\nstandardized entity. We applied this framework to COVID-19-related tweets from\nFebruary 1, 2020, to April 30, 2022, generating a symptom dictionary (available\nat https://github.com/ningkko/UMLS_colloquialism/) composed of 9,249\nstandardized entities mapped to 876 UMLS concepts and 38,175 colloquial\nexpressions. This framework demonstrates encouraging potential in addressing\nthe constraints of keyword matching information retrieval in social media-based\npublic health research.",
        "translated": "社交媒体在流行病监测中的应用已经得到了很好的证实。然而，当预定义词汇用于检索相关语料时，常常会引入偏倚。这项研究介绍了一个框架，旨在管理广泛的医学术语和一体化医学语言系统(UMLS)概念词典。该框架由三个模块组成: 一个基于 BERT 的命名实体识别(NER)模型，该模型从社交媒体内容中识别医疗实体; 一个深度学习驱动的标准化模块，该模块标准化提取的实体; 以及一个半监督聚类模块，该模块为每个标准化实体分配最可能的 UMLS 概念。我们将这个框架应用于2020年2月1日至2022年4月30日期间与 COVID-19相关的推文，生成了一个症状词典(可在 https://github.com/ningkko/umls_colloquialism/获得) ，由映射到876个 UMLS 概念和38,175个口语表达的9,249个标准化实体组成。这个框架显示了在解决基于社交媒体的公共卫生研究中关键词匹配信息检索的限制方面令人鼓舞的潜力。"
    },
    {
        "title": "Disentangled Variational Auto-encoder Enhanced by Counterfactual Data\n  for Debiasing Recommendation",
        "url": "http://arxiv.org/abs/2306.15961v1",
        "pub_date": "2023-06-28",
        "summary": "Recommender system always suffers from various recommendation biases,\nseriously hindering its development. In this light, a series of debias methods\nhave been proposed in the recommender system, especially for two most common\nbiases, i.e., popularity bias and amplified subjective bias. However, exsisting\ndebias methods usually concentrate on correcting a single bias. Such\nsingle-functionality debiases neglect the bias-coupling issue in which the\nrecommended items are collectively attributed to multiple biases. Besides,\nprevious work cannot tackle the lacking supervised signals brought by sparse\ndata, yet which has become a commonplace in the recommender system. In this\nwork, we introduce a disentangled debias variational auto-encoder\nframework(DB-VAE) to address the single-functionality issue as well as a\ncounterfactual data enhancement method to mitigate the adverse effect due to\nthe data sparsity. In specific, DB-VAE first extracts two types of extreme\nitems only affected by a single bias based on the collier theory, which are\nrespectively employed to learn the latent representation of corresponding\nbiases, thereby realizing the bias decoupling. In this way, the exact unbiased\nuser representation can be learned by these decoupled bias representations.\nFurthermore, the data generation module employs Pearl's framework to produce\nmassive counterfactual data, making up the lacking supervised signals due to\nthe sparse data. Extensive experiments on three real-world datasets demonstrate\nthe effectiveness of our proposed model. Besides, the counterfactual data can\nfurther improve DB-VAE, especially on the dataset with low sparsity.",
        "translated": "推荐系统总是受到各种推荐偏见的困扰，严重阻碍了它的发展。有见及此，推荐系统中提出了一系列的偏差分析方法，特别是针对两种最常见的偏差，即受欢迎程度偏差和放大的主观偏差。然而，现有的偏倚矫正方法通常集中于纠正单一偏倚。这种单一功能的偏差忽略了偏差耦合问题，在这个问题中，推荐的项目被共同归因于多个偏差。此外，以往的研究未能解决稀疏数据所带来的缺乏监督的信号问题，但这已成为推荐系统研究中的一个常见问题。在这项工作中，我们介绍了一个解纠缠去偏差变分自动编码框架(DB-VAE) ，以解决单一功能的问题，以及一个反事实的数据增强方法，以减轻由于数据稀疏造成的不利影响。具体来说，DB-VAE 首先基于 Collier 理论提取两类仅受单一偏差影响的极值项，分别用于学习相应偏差的潜在表示，从而实现偏差解耦。这样，就可以通过这些解耦的偏差表示来学习精确的无偏用户表示。此外，数据生成模块利用 Pearl 的框架生成大量的反事实数据，弥补了由于数据稀疏而导致的监督信号的缺失。在三个真实世界数据集上的大量实验证明了我们提出的模型的有效性。此外，反事实数据可以进一步改善 DB-VAE，特别是对稀疏度较低的数据集。"
    },
    {
        "title": "Pb-Hash: Partitioned b-bit Hashing",
        "url": "http://arxiv.org/abs/2306.15944v1",
        "pub_date": "2023-06-28",
        "summary": "Many hashing algorithms including minwise hashing (MinHash), one permutation\nhashing (OPH), and consistent weighted sampling (CWS) generate integers of $B$\nbits. With $k$ hashes for each data vector, the storage would be $B\\times k$\nbits; and when used for large-scale learning, the model size would be\n$2^B\\times k$, which can be expensive. A standard strategy is to use only the\nlowest $b$ bits out of the $B$ bits and somewhat increase $k$, the number of\nhashes. In this study, we propose to re-use the hashes by partitioning the $B$\nbits into $m$ chunks, e.g., $b\\times m =B$. Correspondingly, the model size\nbecomes $m\\times 2^b \\times k$, which can be substantially smaller than the\noriginal $2^B\\times k$.\n  Our theoretical analysis reveals that by partitioning the hash values into\n$m$ chunks, the accuracy would drop. In other words, using $m$ chunks of $B/m$\nbits would not be as accurate as directly using $B$ bits. This is due to the\ncorrelation from re-using the same hash. On the other hand, our analysis also\nshows that the accuracy would not drop much for (e.g.,) $m=2\\sim 4$. In some\nregions, Pb-Hash still works well even for $m$ much larger than 4. We expect\nPb-Hash would be a good addition to the family of hashing methods/applications\nand benefit industrial practitioners.\n  We verify the effectiveness of Pb-Hash in machine learning tasks, for linear\nSVM models as well as deep learning models. Since the hashed data are\nessentially categorical (ID) features, we follow the standard practice of using\nembedding tables for each hash. With Pb-Hash, we need to design an effective\nstrategy to combine $m$ embeddings. Our study provides an empirical evaluation\non four pooling schemes: concatenation, max pooling, mean pooling, and product\npooling. There is no definite answer which pooling would be always better and\nwe leave that for future study.",
        "translated": "许多散列算法包括 minwise 散列(MinHash)、一个置换散列(OPH)和一致加权抽样(CWS)生成 $B $bit 的整数。对于每个数据向量使用 $k $散列，存储将是 $B 乘以 k $bit; 如果使用大规模学习，模型大小将是 $2 ^ B 乘以 k $，这可能是昂贵的。一个标准的策略是仅使用 $B $bit 中的最低 $b $bit，并稍微增加 $k $，即散列的数量。在这个研究中，我们建议通过将 $B $bit 分割成 $m $block 来重用散列，例如，$b 乘以 m = B $。相应地，模型大小变成 $m 乘以2 ^ b 乘以 k $，这可以大大小于原来的2 ^ B 乘以 k $。我们的理论分析表明，通过将散列值划分为 $m $块，准确性会下降。换句话说，使用 $m $块的 $B/m $bits 不会像直接使用 $B $bits 那样精确。这是由于重用相同哈希引起的相关性。另一方面，我们的分析也表明，对于(例如) $m = 2 sim 4 $，精度不会下降很多。在一些地区，Pb-Hash 甚至在价格远高于4美元的情况下仍然运行良好。我们期望 Pb-Hash 将是散列方法/应用系列的一个很好的补充，并有利于工业实践者。我们验证了 Pb-Hash 在机器学习任务、线性支持向量机模型和深度学习模型方面的有效性。由于散列数据本质上是分类(ID)特性，因此我们遵循对每个散列使用嵌入表的标准实践。使用 Pb-Hash，我们需要设计一个有效的策略来结合 $m $嵌入。我们的研究提供了一个实证评估的四个池方案: 连接，最大池，平均池，和产品池。没有明确的答案，哪一个池总是更好，我们留给未来的研究。"
    },
    {
        "title": "MultiZoo &amp; MultiBench: A Standardized Toolkit for Multimodal Deep\n  Learning",
        "url": "http://arxiv.org/abs/2306.16413v1",
        "pub_date": "2023-06-28",
        "summary": "Learning multimodal representations involves integrating information from\nmultiple heterogeneous sources of data. In order to accelerate progress towards\nunderstudied modalities and tasks while ensuring real-world robustness, we\nrelease MultiZoo, a public toolkit consisting of standardized implementations\nof &gt; 20 core multimodal algorithms and MultiBench, a large-scale benchmark\nspanning 15 datasets, 10 modalities, 20 prediction tasks, and 6 research areas.\nTogether, these provide an automated end-to-end machine learning pipeline that\nsimplifies and standardizes data loading, experimental setup, and model\nevaluation. To enable holistic evaluation, we offer a comprehensive methodology\nto assess (1) generalization, (2) time and space complexity, and (3) modality\nrobustness. MultiBench paves the way towards a better understanding of the\ncapabilities and limitations of multimodal models, while ensuring ease of use,\naccessibility, and reproducibility. Our toolkits are publicly available, will\nbe regularly updated, and welcome inputs from the community.",
        "translated": "学习多模态表示涉及到整合来自多个异构数据源的信息。为了在确保现实世界稳健性的同时加快未被研究的模式和任务的进展，我们发布了 MultiZoo，一个公共工具包，由 > 20个核心多模式算法的标准化实现和 MultiBench 组成，MultiBench 是一个跨越15个数据集，10个模式，20个预测任务和6个研究领域的大规模基准。总之，它们提供了一个自动化的端到端机器学习流水线，可以简化和标准化数据加载、实验设置和模型评估。为了实现整体评估，我们提供了一个综合的方法来评估(1)泛化，(2)时间和空间复杂性，和(3)模态鲁棒性。MultiBench 为更好地理解多模式模型的功能和局限性铺平了道路，同时确保了易用性、可访问性和可重复性。我们的工具包是公开可用的，将定期更新，并欢迎来自社区的输入。"
    },
    {
        "title": "Towards Language Models That Can See: Computer Vision Through the LENS\n  of Natural Language",
        "url": "http://arxiv.org/abs/2306.16410v1",
        "pub_date": "2023-06-28",
        "summary": "We propose LENS, a modular approach for tackling computer vision problems by\nleveraging the power of large language models (LLMs). Our system uses a\nlanguage model to reason over outputs from a set of independent and highly\ndescriptive vision modules that provide exhaustive information about an image.\nWe evaluate the approach on pure computer vision settings such as zero- and\nfew-shot object recognition, as well as on vision and language problems. LENS\ncan be applied to any off-the-shelf LLM and we find that the LLMs with LENS\nperform highly competitively with much bigger and much more sophisticated\nsystems, without any multimodal training whatsoever. We open-source our code at\nhttps://github.com/ContextualAI/lens and provide an interactive demo.",
        "translated": "我们提出 LENS，一种通过利用大型语言模型(LLM)解决计算机视觉问题的模块化方法。我们的系统使用一个语言模型来推理来自一组独立且高度描述性的视觉模块的输出，这些模块提供关于图像的详尽信息。我们评估的方法纯计算机视觉设置，如零和少拍摄物体识别，以及在视觉和语言问题。LENS 可以应用于任何现成的 LLM，我们发现 LENS 的 LLM 在更大和更复杂的系统中表现得非常有竞争力，没有任何多模态训练。我们 https://github.com/contextualai/lens 开源代码并提供交互式演示。"
    },
    {
        "title": "Towards Measuring the Representation of Subjective Global Opinions in\n  Language Models",
        "url": "http://arxiv.org/abs/2306.16388v1",
        "pub_date": "2023-06-28",
        "summary": "Large language models (LLMs) may not equitably represent diverse global\nperspectives on societal issues. In this paper, we develop a quantitative\nframework to evaluate whose opinions model-generated responses are more similar\nto. We first build a dataset, GlobalOpinionQA, comprised of questions and\nanswers from cross-national surveys designed to capture diverse opinions on\nglobal issues across different countries. Next, we define a metric that\nquantifies the similarity between LLM-generated survey responses and human\nresponses, conditioned on country. With our framework, we run three experiments\non an LLM trained to be helpful, honest, and harmless with Constitutional AI.\nBy default, LLM responses tend to be more similar to the opinions of certain\npopulations, such as those from the USA, and some European and South American\ncountries, highlighting the potential for biases. When we prompt the model to\nconsider a particular country's perspective, responses shift to be more similar\nto the opinions of the prompted populations, but can reflect harmful cultural\nstereotypes. When we translate GlobalOpinionQA questions to a target language,\nthe model's responses do not necessarily become the most similar to the\nopinions of speakers of those languages. We release our dataset for others to\nuse and build on. Our data is at\nhttps://huggingface.co/datasets/Anthropic/llm_global_opinions. We also provide\nan interactive visualization at https://llmglobalvalues.anthropic.com.",
        "translated": "大型语言模型(LLM)可能不能公平地代表关于社会问题的多样化的全球视角。在本文中，我们建立了一个定量的框架来评估谁的意见模型生成的反应更相似。我们首先建立一个数据集 GlobalOpinionQA，包括来自跨国调查的问题和答案，旨在收集不同国家对全球问题的不同意见。接下来，我们定义一个度量标准，量化 LLM 生成的调查答复和人类反应之间的相似性，以国家为条件。在我们的框架下，我们在一个训练有素的 LLM 上进行了三个实验，这个 LLM 被训练成有用的、诚实的和无害的人工智能。默认情况下，LLM 的反应往往与某些人群的观点更为相似，例如来自美国以及一些欧洲和南美国家的观点，突出了潜在的偏见。当我们提示模型考虑一个特定国家的观点时，反应会变得更加类似于提示人群的观点，但是反映出有害的文化刻板印象。当我们将 GlobalOpinionQA 问题翻译成目标语言时，模型的回答并不一定与使用这些语言的人的观点最为相似。我们将我们的数据集发布给其他人使用和构建。我们的数据处于 https://huggingface.co/datasets/anthropic/llm_global_opinions。我们还在 https://llmglobalvalues.anthropic.com 上提供了一个交互式可视化。"
    },
    {
        "title": "Multi-Site Clinical Federated Learning using Recursive and Attentive\n  Models and NVFlare",
        "url": "http://arxiv.org/abs/2306.16367v1",
        "pub_date": "2023-06-28",
        "summary": "The prodigious growth of digital health data has precipitated a mounting\ninterest in harnessing machine learning methodologies, such as natural language\nprocessing (NLP), to scrutinize medical records, clinical notes, and other\ntext-based health information. Although NLP techniques have exhibited\nsubstantial potential in augmenting patient care and informing clinical\ndecision-making, data privacy and adherence to regulations persist as critical\nconcerns. Federated learning (FL) emerges as a viable solution, empowering\nmultiple organizations to train machine learning models collaboratively without\ndisseminating raw data. This paper proffers a pragmatic approach to medical NLP\nby amalgamating FL, NLP models, and the NVFlare framework, developed by NVIDIA.\nWe introduce two exemplary NLP models, the Long-Short Term Memory (LSTM)-based\nmodel and Bidirectional Encoder Representations from Transformers (BERT), which\nhave demonstrated exceptional performance in comprehending context and\nsemantics within medical data. This paper encompasses the development of an\nintegrated framework that addresses data privacy and regulatory compliance\nchallenges while maintaining elevated accuracy and performance, incorporating\nBERT pretraining, and comprehensively substantiating the efficacy of the\nproposed approach.",
        "translated": "数字健康数据的巨大增长促使人们对利用机器学习方法(如自然语言处理(NLP))来仔细检查医疗记录、临床记录和其他基于文本的健康信息产生了越来越大的兴趣。尽管 NLP 技术在增强患者护理和为临床决策提供信息方面显示出巨大的潜力，但数据隐私和遵守规定仍然是关键问题。联邦学习(FL)作为一种可行的解决方案出现了，它赋予多个组织在不传播原始数据的情况下协同训练机器学习模型的权力。本文通过融合 FL、 NLP 模型和 NVFlare 框架，提出了一种实用的医学自然语言处理方法。我们介绍了两个典型的自然语言处理模型，基于长短期记忆(LSTM)的模型和来自变压器的双向编码器表示(BERT) ，它们在理解医学数据中的上下文和语义方面表现出优异的性能。本文包括开发一个综合框架，解决数据隐私和守规的挑战，同时保持提高的准确性和性能，结合 BERT 预训练，并全面证实拟议方法的有效性。"
    },
    {
        "title": "Representation Learning via Variational Bayesian Networks",
        "url": "http://arxiv.org/abs/2306.16326v1",
        "pub_date": "2023-06-28",
        "summary": "We present Variational Bayesian Network (VBN) - a novel Bayesian entity\nrepresentation learning model that utilizes hierarchical and relational side\ninformation and is particularly useful for modeling entities in the\n``long-tail'', where the data is scarce. VBN provides better modeling for\nlong-tail entities via two complementary mechanisms: First, VBN employs\ninformative hierarchical priors that enable information propagation between\nentities sharing common ancestors. Additionally, VBN models explicit relations\nbetween entities that enforce complementary structure and consistency, guiding\nthe learned representations towards a more meaningful arrangement in space.\nSecond, VBN represents entities by densities (rather than vectors), hence\nmodeling uncertainty that plays a complementary role in coping with data\nscarcity. Finally, we propose a scalable Variational Bayes optimization\nalgorithm that enables fast approximate Bayesian inference. We evaluate the\neffectiveness of VBN on linguistic, recommendations, and medical inference\ntasks. Our findings show that VBN outperforms other existing methods across\nmultiple datasets, and especially in the long-tail.",
        "translated": "我们提出了变分贝氏网路(vbN)——一种新的贝叶斯实体表示学习模型，它利用了层次和关系侧信息，特别适用于数据稀缺的“长尾”实体建模。VBN 通过两种互补的机制为长尾实体提供了更好的建模: 首先，VBN 使用了信息丰富的层次先验，这使得共享共同祖先的实体之间的信息传播成为可能。此外，VBN 模型明确的实体之间的关系，强制互补结构和一致性，指导学习表示更有意义的安排在空间。其次，VBN 通过密度(而不是向量)表示实体，因此建模不确定性在处理数据稀缺性方面起到补充作用。最后，我们提出了一个可扩展的变分贝叶斯优化算法，它可以实现快速的近似贝叶斯推断。我们评估 VBN 在语言、推荐和医学推理任务中的有效性。我们的研究结果表明，VBN 在跨多个数据集的性能优于其他现有的方法，特别是在长尾方面。"
    },
    {
        "title": "Taqyim: Evaluating Arabic NLP Tasks Using ChatGPT Models",
        "url": "http://arxiv.org/abs/2306.16322v1",
        "pub_date": "2023-06-28",
        "summary": "Large language models (LLMs) have demonstrated impressive performance on\nvarious downstream tasks without requiring fine-tuning, including ChatGPT, a\nchat-based model built on top of LLMs such as GPT-3.5 and GPT-4. Despite having\na lower training proportion compared to English, these models also exhibit\nremarkable capabilities in other languages. In this study, we assess the\nperformance of GPT-3.5 and GPT-4 models on seven distinct Arabic NLP tasks:\nsentiment analysis, translation, transliteration, paraphrasing, part of speech\ntagging, summarization, and diacritization. Our findings reveal that GPT-4\noutperforms GPT-3.5 on five out of the seven tasks. Furthermore, we conduct an\nextensive analysis of the sentiment analysis task, providing insights into how\nLLMs achieve exceptional results on a challenging dialectal dataset.\nAdditionally, we introduce a new Python interface\nhttps://github.com/ARBML/Taqyim that facilitates the evaluation of these tasks\neffortlessly.",
        "translated": "大型语言模型(LLM)已经在不需要微调的各种下游任务上展示了令人印象深刻的性能，包括 ChatGPT，一种基于聊天的模型，建立在 LLM 之上，如 GPT-3.5和 GPT-4。尽管与英语相比，这些模式的训练比例较低，但它们在其他语言方面也表现出显著的能力。在这项研究中，我们评估了 GPT-3.5和 GPT-4模型在七个不同的阿拉伯语 NLP 任务中的表现: 情感分析，翻译，音译，释义，部分语音标签，摘要和非字符化。我们的研究结果表明，GPT-4在七项任务中的五项上表现优于 GPT-3.5。此外，我们进行了广泛的情绪分析任务的分析，提供深入的见解，如何实现一个具有挑战性的方言数据集 LLM 异常的结果。此外，我们还引入了一个新的 Python 界面 https://github.com/arbml/taqyim  ，可以轻松地评估这些任务。"
    },
    {
        "title": "An Adversarial Multi-Task Learning Method for Chinese Text Correction\n  with Semantic Detection",
        "url": "http://arxiv.org/abs/2306.16313v1",
        "pub_date": "2023-06-28",
        "summary": "Text correction, especially the semantic correction of more widely used\nscenes, is strongly required to improve, for the fluency and writing efficiency\nof the text. An adversarial multi-task learning method is proposed to enhance\nthe modeling and detection ability of character polysemy in Chinese sentence\ncontext. Wherein, two models, the masked language model and scoring language\nmodel, are introduced as a pair of not only coupled but also adversarial\nlearning tasks. Moreover, the Monte Carlo tree search strategy and a policy\nnetwork are introduced to accomplish the efficient Chinese text correction task\nwith semantic detection. The experiments are executed on three datasets and\nfive comparable methods, and the experimental results show that our method can\nobtain good performance in Chinese text correction task for better semantic\nrationality.",
        "translated": "为了提高文本的流畅性和写作效率，文本校正尤其是应用较为广泛的场景的语义校正是亟待提高的。提出了一种对抗性多任务学习方法，以提高汉语句子语境中字符多义现象的建模和检测能力。其中，两个模型，掩蔽语言模型和评分语言模型，被引入作为一对不仅是耦合的，而且是对抗性的学习任务。此外，引入了蒙特卡罗树搜索策略和策略网络，实现了具有语义检测的高效中文文本校正任务。实验结果表明，该方法在中文文本校正任务中能够取得较好的效果，具有较好的语义合理性。"
    },
    {
        "title": "Leveraging GPT-4 for Food Effect Summarization to Enhance\n  Product-Specific Guidance Development via Iterative Prompting",
        "url": "http://arxiv.org/abs/2306.16275v1",
        "pub_date": "2023-06-28",
        "summary": "Food effect summarization from New Drug Application (NDA) is an essential\ncomponent of product-specific guidance (PSG) development and assessment.\nHowever, manual summarization of food effect from extensive drug application\nreview documents is time-consuming, which arouses a need to develop automated\nmethods. Recent advances in large language models (LLMs) such as ChatGPT and\nGPT-4, have demonstrated great potential in improving the effectiveness of\nautomated text summarization, but its ability regarding the accuracy in\nsummarizing food effect for PSG assessment remains unclear. In this study, we\nintroduce a simple yet effective approach, iterative prompting, which allows\none to interact with ChatGPT or GPT-4 more effectively and efficiently through\nmulti-turn interaction. Specifically, we propose a three-turn iterative\nprompting approach to food effect summarization in which the keyword-focused\nand length-controlled prompts are respectively provided in consecutive turns to\nrefine the quality of the generated summary. We conduct a series of extensive\nevaluations, ranging from automated metrics to FDA professionals and even\nevaluation by GPT-4, on 100 NDA review documents selected over the past five\nyears. We observe that the summary quality is progressively improved throughout\nthe process. Moreover, we find that GPT-4 performs better than ChatGPT, as\nevaluated by FDA professionals (43% vs. 12%) and GPT-4 (64% vs. 35%).\nImportantly, all the FDA professionals unanimously rated that 85% of the\nsummaries generated by GPT-4 are factually consistent with the golden reference\nsummary, a finding further supported by GPT-4 rating of 72% consistency. These\nresults strongly suggest a great potential for GPT-4 to draft food effect\nsummaries that could be reviewed by FDA professionals, thereby improving the\nefficiency of PSG assessment cycle and promoting the generic drug product\ndevelopment.",
        "translated": "新药应用中的食品效果总结是产品特异性指导(PSG)开发和评估的重要组成部分。然而，从广泛的药物应用审查文件中手工总结食品效应是一项耗时的工作，这就引起了开发自动化方法的需要。ChatGPT 和 GPT-4等大型语言模型(LLM)的最新进展显示了提高自动文本摘要有效性的巨大潜力，但其在总结 PSG 评估的食物效应准确性方面的能力尚不清楚。在这项研究中，我们介绍了一个简单而有效的方法，迭代提示，它允许一个人与 ChatGPT 或 GPT-4交互更有效和高效地通过多回合的交互。具体而言，我们提出了一种三回合迭代提示方法来进行食物效果总结，其中关键字重点和长度控制的提示分别在连续的回合中提供，以完善生成的总结的质量。我们进行了一系列广泛的评估，从自动化指标到 FDA 专业人员，甚至 GPT-4的评估，对过去五年中选定的100个 NDA 审查文件进行评估。我们观察到总结质量在整个过程中逐步得到改进。此外，我们发现 GPT-4的表现优于 ChatGPT，FDA 专业人员对此进行了评估(43% 比12%)和 GPT-4(64% 比35%)。重要的是，所有 FDA 专业人员一致认为 GPT-4产生的总结中有85% 与黄金参考总结实际上是一致的，这一发现得到了 GPT-4评分72% 一致性的进一步支持。这些结果强烈表明 GPT-4起草可供 FDA 专业人员审查的食品效应摘要的巨大潜力，从而提高 PSG 评估周期的效率，促进仿制药产品的开发。"
    },
    {
        "title": "Emotion Analysis of Tweets Banning Education in Afghanistan",
        "url": "http://arxiv.org/abs/2306.16268v1",
        "pub_date": "2023-06-28",
        "summary": "This paper introduces the first emotion annotated dataset for the Dari\nvariant of Persian spoken in Afghanistan. The LetHerLearn dataset contains\n7,600 tweets posted in reaction to the Taliban ban of women rights to education\nin 2022 and has been manually annotated according to Ekman emotion categories.\nWe here detail the data collection and annotation process, present relevant\ndataset statistics as well as initial experiments on the resulting dataset,\nbenchmarking a number of different neural architectures for the task of Dari\nemotion classification.",
        "translated": "本文介绍了第一个情绪注释数据集的达日变体的波斯语在阿富汗说。LetHerLearning 数据集包含7,600条针对塔利班2022年禁止妇女接受教育权而发布的推文，并根据 Ekman 情绪类别进行了人工注释。我们在这里详细介绍数据收集和注释的过程，提供相关的数据集统计数据，以及最终数据集的初步实验，并为达日情绪分类的任务建立了多种不同的神经结构。"
    },
    {
        "title": "CBBQ: A Chinese Bias Benchmark Dataset Curated with Human-AI\n  Collaboration for Large Language Models",
        "url": "http://arxiv.org/abs/2306.16244v1",
        "pub_date": "2023-06-28",
        "summary": "Holistically measuring societal biases of large language models is crucial\nfor detecting and reducing ethical risks in highly capable AI models. In this\nwork, we present a Chinese Bias Benchmark dataset that consists of over 100K\nquestions jointly constructed by human experts and generative language models,\ncovering stereotypes and societal biases in 14 social dimensions related to\nChinese culture and values. The curation process contains 4 essential steps:\nbias identification via extensive literature review, ambiguous context\ngeneration, AI-assisted disambiguous context generation, snd manual review \\&amp;\nrecomposition. The testing instances in the dataset are automatically derived\nfrom 3K+ high-quality templates manually authored with stringent quality\ncontrol. The dataset exhibits wide coverage and high diversity. Extensive\nexperiments demonstrate the effectiveness of the dataset in detecting model\nbias, with all 10 publicly available Chinese large language models exhibiting\nstrong bias in certain categories. Additionally, we observe from our\nexperiments that fine-tuned models could, to a certain extent, heed\ninstructions and avoid generating outputs that are morally harmful in some\ntypes, in the way of \"moral self-correction\". Our dataset and results are\npublicly available at\n\\href{https://github.com/YFHuangxxxx/CBBQ}{https://github.com/YFHuangxxxx/CBBQ},\noffering debiasing research opportunities to a widened community.",
        "translated": "全面衡量大型语言模型的社会偏见对于发现和减少高能人工智能模型中的伦理风险至关重要。在这项工作中，我们提出了一个中国偏见基准数据集，由人类专家和生成语言模型共同构建的超过10万个问题，涵盖了与中国文化和价值观相关的14个社会维度的刻板印象和社会偏见。策划过程包括4个基本步骤: 通过广泛的文献综述进行偏倚识别、模糊上下文生成、人工智能辅助的模糊上下文生成、以及人工审查和重组。数据集中的测试实例是自动从3K + 高质量模板中派生出来的，这些模板是通过严格的质量控制手工编写的。该数据集具有广泛的覆盖面和高度的多样性。大量的实验证明了该数据集在检测模型偏差方面的有效性，所有10个公开的中文大语言模型在某些类别中表现出强烈的偏差。此外，我们从实验中观察到，微调模型可以在一定程度上听从指令，避免产生在某些类型中对道德有害的输出，即“道德自我纠正”。我们的数据集和结果可以在 href { https://github.com/yfhuangxxxx/cbbq }{ https://github.com/yfhuangxxxx/cbbq }上公开获得，为更广泛的社区提供了减少偏见的研究机会。"
    },
    {
        "title": "Ducho: A Unified Framework for the Extraction of Multimodal Features in\n  Recommendation",
        "url": "http://arxiv.org/abs/2306.17125v1",
        "pub_date": "2023-06-29",
        "summary": "In multimodal-aware recommendation, the extraction of meaningful multimodal\nfeatures is at the basis of high-quality recommendations. Generally, each\nrecommendation framework implements its multimodal extraction procedures with\nspecific strategies and tools. This is limiting for two reasons: (i) different\nextraction strategies do not ease the interdependence among multimodal\nrecommendation frameworks; thus, they cannot be efficiently and fairly\ncompared; (ii) given the large plethora of pre-trained deep learning models\nmade available by different open source tools, model designers do not have\naccess to shared interfaces to extract features. Motivated by the outlined\naspects, we propose Ducho, a unified framework for the extraction of multimodal\nfeatures in recommendation. By integrating three widely-adopted deep learning\nlibraries as backends, namely, TensorFlow, PyTorch, and Transformers, we\nprovide a shared interface to extract and process features where each backend's\nspecific methods are abstracted to the end user. Noteworthy, the extraction\npipeline is easily configurable with a YAML-based file where the user can\nspecify, for each modality, the list of models (and their specific\nbackends/parameters) to perform the extraction. Finally, to make Ducho\naccessible to the community, we build a public Docker image equipped with a\nready-to-use CUDA environment and propose three demos to test its\nfunctionalities for different scenarios and tasks. The GitHub repository and\nthe documentation is accessible at this link:\nhttps://github.com/sisinflab/Ducho.",
        "translated": "在多模态推荐中，有意义的多模态特征的提取是高质量推荐的基础。通常，每个推荐框架使用特定的策略和工具实现其多模式提取过程。这种限制有两个原因: (i)不同的提取策略不能缓解多模式推荐框架之间的相互依赖性; 因此，它们不能有效和公平地进行比较; (ii)鉴于由不同的开源工具提供的大量预先训练的深度学习模型，模型设计者没有访问共享接口来提取特征。基于这些方面，我们提出了 Ducho，一个用于提取推荐中的多模态特征的统一框架。通过集成三个广泛采用的深度学习库作为后端，即 TensorFlow、 PyTorch 和 Transformers，我们提供了一个共享接口来提取和处理特性，其中每个后端的特定方法被抽象到最终用户。值得注意的是，提取管道很容易用基于 YAML 的文件进行配置，用户可以在该文件中为每种模式指定执行提取的模型列表(及其特定的后端/参数)。最后，为了使 Ducho 能够被社区所接受，我们建立了一个公共的 Docker 图像，配备了一个可以随时使用的 CUDA 环境，并提出了三个演示来测试它在不同场景和任务中的功能。GitHub 存储库和文档可以通过以下链接访问:  https://GitHub.com/sisinflab/ducho。"
    },
    {
        "title": "Re-Rank - Expand - Repeat: Adaptive Query Expansion for Document\n  Retrieval Using Words and Entities",
        "url": "http://arxiv.org/abs/2306.17082v1",
        "pub_date": "2023-06-29",
        "summary": "Sparse and dense pseudo-relevance feedback (PRF) approaches perform poorly on\nchallenging queries due to low precision in first-pass retrieval. However,\nrecent advances in neural language models (NLMs) can re-rank relevant documents\nto top ranks, even when few are in the re-ranking pool. This paper first\naddresses the problem of poor pseudo-relevance feedback by simply applying\nre-ranking prior to query expansion and re-executing this query. We find that\nthis change alone can improve the retrieval effectiveness of sparse and dense\nPRF approaches by 5-8%. Going further, we propose a new expansion model, Latent\nEntity Expansion (LEE), a fine-grained word and entity-based relevance\nmodelling incorporating localized features. Finally, we include an \"adaptive\"\ncomponent to the retrieval process, which iteratively refines the re-ranking\npool during scoring using the expansion model, i.e. we \"re-rank - expand -\nrepeat\". Using LEE, we achieve (to our knowledge) the best NDCG, MAP and R@1000\nresults on the TREC Robust 2004 and CODEC adhoc document datasets,\ndemonstrating a significant advancement in expansion effectiveness.",
        "translated": "稀疏和密集伪相关反馈(PRF)方法在挑战性查询中表现不佳，这是由于首次检索的精度较低。然而，神经语言模型(NLM)的最新进展可以将相关文档重新排列到最高级别，即使重新排列的文档很少。本文首先通过简单地在查询扩展之前重新排序并重新执行查询，解决了伪相关反馈较差的问题。我们发现单独这种改变可以提高稀疏和密集 PRF 方法的检索效率5-8% 。进一步，我们提出了一个新的扩展模型，潜在的实体扩展(LEE) ，一个细粒度的词和基于实体的相关性建模结合本地化特征。最后，我们在检索过程中加入了一个“自适应”组件，该组件在使用扩展模型进行评分期间迭代地改进重新排序池，即我们“重新排序-扩展-重复”。使用 LEE，我们在 TREC Robust 2004和 CODEC 特设文档数据集上获得了(据我们所知)最好的 NDCG，MAP 和 R@1000结果，表明在扩展有效性方面取得了显着进展。"
    },
    {
        "title": "Harnessing the Power of Hugging Face Transformers for Predicting Mental\n  Health Disorders in Social Networks",
        "url": "http://arxiv.org/abs/2306.16891v1",
        "pub_date": "2023-06-29",
        "summary": "Early diagnosis of mental disorders and intervention can facilitate the\nprevention of severe injuries and the improvement of treatment results. Using\nsocial media and pre-trained language models, this study explores how\nuser-generated data can be used to predict mental disorder symptoms. Our study\ncompares four different BERT models of Hugging Face with standard machine\nlearning techniques used in automatic depression diagnosis in recent\nliterature. The results show that new models outperform the previous approach\nwith an accuracy rate of up to 97%. Analyzing the results while complementing\npast findings, we find that even tiny amounts of data (like users' bio\ndescriptions) have the potential to predict mental disorders. We conclude that\nsocial media data is an excellent source of mental health screening, and\npre-trained models can effectively automate this critical task.",
        "translated": "对精神障碍的早期诊断和干预有助于预防严重创伤，提高治疗效果。利用社会媒体和预先训练的语言模型，这项研究探讨了如何使用用户生成的数据可以用来预测精神障碍症状。本研究比较了近年来文献中用于抑郁症自动诊断的标准机器学习技术和四种不同的“拥抱脸”BERT 模型。结果表明，新的模型优于以前的方法，准确率高达97% 。分析结果，同时补充过去的发现，我们发现，即使是微量的数据(如用户的生物描述)有可能预测精神障碍。我们的结论是，社会媒体数据是一个良好的来源，心理健康筛查，并预先训练的模型可以有效地自动化这一关键任务。"
    },
    {
        "title": "Computing all-vs-all MEMs in grammar-compressed text",
        "url": "http://arxiv.org/abs/2306.16815v1",
        "pub_date": "2023-06-29",
        "summary": "We describe a compression-aware method to compute all-vs-all maximal exact\nmatches (MEM) among strings of a repetitive collection $\\mathcal{T}$. The key\nconcept in our work is the construction of a fully-balanced grammar\n$\\mathcal{G}$ from $\\mathcal{T}$ that meets a property that we call\n\\emph{fix-free}: the expansions of the nonterminals that have the same height\nin the parse tree form a fix-free set (i.e., prefix-free and suffix-free). The\nfix-free property allows us to compute the MEMs of $\\mathcal{T}$ incrementally\nover $\\mathcal{G}$ using a standard suffix-tree-based MEM algorithm, which runs\non a subset of grammar rules at a time and does not decompress nonterminals. By\nmodifying the locally-consistent grammar of Christiansen et al 2020., we show\nhow we can build $\\mathcal{G}$ from $\\mathcal{T}$ in linear time and space. We\nalso demonstrate that our MEM algorithm runs on top of $\\mathcal{G}$ in $O(G\n+occ)$ time and uses $O(\\log G(G+occ))$ bits, where $G$ is the grammar size,\nand $occ$ is the number of MEMs in $\\mathcal{T}$. In the conclusions, we\ndiscuss how our idea can be modified to implement approximate pattern matching\nin compressed space.",
        "translated": "我们描述了一种感知压缩的方法来计算重复集合 $mathcal { T } $的字符串之间的全对全最大精确匹配(MEM)。我们工作中的关键概念是构造一个完全平衡的文法 $mathcal { G } $，它满足我们称之为 emph { fix-free }的属性: 在解析树中具有相同高度的非终端的扩展形成一个 fix-free 集(即，无前缀和无后缀)。无修复特性允许我们使用基于后缀树的标准 MEM 算法来计算 $mathcal { T } $在 $mathcal { G } $上的 MEM，该算法一次运行在一个语法规则子集上，并且不对非终端进行解压缩。通过修改 Christiansen 等人2020年的局部一致性语法。，我们展示了如何在线性时间和空间中从 $mathcal { T } $构建 $mathcal { G } $。我们还演示了我们的 MEM 算法在 $O (G + occ) $time 中运行在 $mathcal { G } $之上，并使用 $O (log G (G + occ)) $bit，其中 $G $是文法大小，$occ $是 $mathal { T } $中的 MEM 数目。在结论中，我们讨论了如何修改我们的想法以在压缩空间中实现近似模式匹配。"
    },
    {
        "title": "Transfer Learning with Semi-Supervised Dataset Annotation for Birdcall\n  Classification",
        "url": "http://arxiv.org/abs/2306.16760v1",
        "pub_date": "2023-06-29",
        "summary": "We present working notes on transfer learning with semi-supervised dataset\nannotation for the BirdCLEF 2023 competition, focused on identifying African\nbird species in recorded soundscapes. Our approach utilizes existing\noff-the-shelf models, BirdNET and MixIT, to address representation and labeling\nchallenges in the competition. We explore the embedding space learned by\nBirdNET and propose a process to derive an annotated dataset for supervised\nlearning. Our experiments involve various models and feature engineering\napproaches to maximize performance on the competition leaderboard. The results\ndemonstrate the effectiveness of our approach in classifying bird species and\nhighlight the potential of transfer learning and semi-supervised dataset\nannotation in similar tasks.",
        "translated": "我们为 BirdCLEF 2023比赛提交了关于半监督数据集注释的迁移学习的工作笔记，重点是在录制的音景中识别非洲鸟类物种。我们的方法利用现有的现成模型，BirdNET 和 MixIT，来解决竞争中的表示和标签挑战。我们探索了 BirdNET 学到的嵌入空间，并提出了一个为监督式学习推导注释数据集的过程。我们的实验包括各种模型和特征工程方法，以最大限度地提高在竞争排行榜上的表现。实验结果表明了该方法在鸟类分类中的有效性，并突出了转移学习和半监督数据集注释在类似任务中的潜力。"
    },
    {
        "title": "Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4,\n  and Human Tutors",
        "url": "http://arxiv.org/abs/2306.17156v1",
        "pub_date": "2023-06-29",
        "summary": "Generative AI and large language models hold great promise in enhancing\ncomputing education by powering next-generation educational technologies for\nintroductory programming. Recent works have studied these models for different\nscenarios relevant to programming education; however, these works are limited\nfor several reasons, as they typically consider already outdated models or only\nspecific scenario(s). Consequently, there is a lack of a systematic study that\nbenchmarks state-of-the-art models for a comprehensive set of programming\neducation scenarios. In our work, we systematically evaluate two models,\nChatGPT (based on GPT-3.5) and GPT-4, and compare their performance with human\ntutors for a variety of scenarios. We evaluate using five introductory Python\nprogramming problems and real-world buggy programs from an online platform, and\nassess performance using expert-based annotations. Our results show that GPT-4\ndrastically outperforms ChatGPT (based on GPT-3.5) and comes close to human\ntutors' performance for several scenarios. These results also highlight\nsettings where GPT-4 still struggles, providing exciting future directions on\ndeveloping techniques to improve the performance of these models.",
        "translated": "生成式人工智能和大型语言模型为下一代教育技术的入门编程提供动力，从而在加强计算机教育方面具有巨大的前景。最近的工作已经针对与编程教育相关的不同场景研究了这些模型; 然而，这些工作由于几个原因而受到限制，因为它们通常考虑已经过时的模型或者只考虑特定的场景。因此，缺乏一个系统的研究，基准国家的最先进的模型为一套全面的编程教育情景。在我们的工作中，我们系统地评估了两个模型，ChatGPT (基于 GPT-3.5)和 GPT-4，并比较了它们在各种情景下与人类导师的表现。我们使用五个入门级 Python 编程问题和来自在线平台的实际 bug 程序进行评估，并使用基于专家的注释评估性能。我们的研究结果表明，GPT-4的性能显著优于 ChatGPT (基于 GPT-3.5) ，并且在几种情况下接近于人类导师的性能。这些结果也突出了 GPT-4仍在努力的设置，为开发技术以改善这些模型的性能提供了令人兴奋的未来方向。"
    },
    {
        "title": "LLaVAR: Enhanced Visual Instruction Tuning for Text-Rich Image\n  Understanding",
        "url": "http://arxiv.org/abs/2306.17107v1",
        "pub_date": "2023-06-29",
        "summary": "Instruction tuning unlocks the superior capability of Large Language Models\n(LLM) to interact with humans. Furthermore, recent instruction-following\ndatasets include images as visual inputs, collecting responses for image-based\ninstructions. However, visual instruction-tuned models cannot comprehend\ntextual details within images well. This work enhances the current visual\ninstruction tuning pipeline with text-rich images (e.g., movie posters, book\ncovers, etc.). Specifically, we first use publicly available OCR tools to\ncollect results on 422K text-rich images from the LAION dataset. Moreover, we\nprompt text-only GPT-4 with recognized texts and image captions to generate 16K\nconversations, each containing question-answer pairs for text-rich images. By\ncombining our collected data with previous multi-modal instruction-following\ndata, our model, LLaVAR, substantially improves the LLaVA model's capability on\ntext-based VQA datasets (up to 20% accuracy improvement) while achieving an\naccuracy of 91.42% on ScienceQA. The GPT-4-based instruction-following\nevaluation also demonstrates the improvement of our model on both natural\nimages and text-rich images. Through qualitative analysis, LLaVAR shows\npromising interaction (e.g., reasoning, writing, and elaboration) skills with\nhumans based on the latest real-world online content that combines text and\nimages. We make our code/data/models publicly available at\nhttps://llavar.github.io/.",
        "translated": "指令调优解锁了大型语言模型(LLM)与人类交互的优越能力。此外，最近的指令跟踪数据集包括图像作为视觉输入，收集基于图像的指令的响应。然而，视觉教学调优模型不能很好地理解图像中的文本细节。这项工作通过文本丰富的图像(例如，电影海报、书籍封面等)增强了当前的可视化教学调优流程。具体来说，我们首先使用公开可用的 OCR 工具从 LAION 数据集中收集422K 文本丰富的图像的结果。此外，我们提示只有文本的 GPT-4与可识别的文本和图像标题生成16K 会话，每个包含文本丰富的图像的问题-答案对。通过将我们收集的数据与以前的多模态指令跟踪数据相结合，我们的模型 LLaVAR 大大提高了 LLaVA 模型对基于文本的 VQA 数据集的能力(提高了20% 的准确性) ，同时在 ScienceQA 上实现了91.42% 的准确性。基于 GPT-4的指令跟踪评估也证明了该模型对自然图像和文本丰富图像的改进。通过定性分析，LLaVAR 展示了基于结合文本和图像的最新现实世界在线内容与人类的互动(例如，推理、写作和阐述)技能。我们把我们的代码/数据/模型在 https://llavar.github.io/上公开。"
    },
    {
        "title": "LyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by\n  Whispering to ChatGPT",
        "url": "http://arxiv.org/abs/2306.17103v1",
        "pub_date": "2023-06-29",
        "summary": "We introduce LyricWhiz, a robust, multilingual, and zero-shot automatic\nlyrics transcription method achieving state-of-the-art performance on various\nlyrics transcription datasets, even in challenging genres such as rock and\nmetal. Our novel, training-free approach utilizes Whisper, a weakly supervised\nrobust speech recognition model, and GPT-4, today's most performant chat-based\nlarge language model. In the proposed method, Whisper functions as the \"ear\" by\ntranscribing the audio, while GPT-4 serves as the \"brain,\" acting as an\nannotator with a strong performance for contextualized output selection and\ncorrection. Our experiments show that LyricWhiz significantly reduces Word\nError Rate compared to existing methods in English and can effectively\ntranscribe lyrics across multiple languages. Furthermore, we use LyricWhiz to\ncreate the first publicly available, large-scale, multilingual lyrics\ntranscription dataset with a CC-BY-NC-SA copyright license, based on\nMTG-Jamendo, and offer a human-annotated subset for noise level estimation and\nevaluation. We anticipate that our proposed method and dataset will advance the\ndevelopment of multilingual lyrics transcription, a challenging and emerging\ntask.",
        "translated": "我们介绍 LyricWhiz，一个强大的，多语言，和零拍摄自动歌词转录方法实现最先进的表现在各种歌词转录数据集，甚至在具有挑战性的流派，如摇滚和金属。我们新颖的、无需训练的方法使用了 Whisper (一种弱监督的鲁棒语音识别模型)和 GPT-4(当今最高性能的基于聊天的大型语言模型)。在提出的方法中，Whisper 通过转录音频作为“耳朵”，而 GPT-4作为“大脑”，充当注释器，具有很强的上下文输出选择和校正性能。我们的实验表明，与现有的英语方法相比，LyricWhiz 显著降低了单词错误率，并能有效地转录多种语言的歌词。此外，我们使用 LyricWhiz 创建第一个公开可用的，大规模的，多语言的歌词转录数据集，具有 CC-BY-NC-SA 版权许可，基于 MTG-Jamendo，并提供用于噪声水平估计和评估的人类注释子集。我们期望我们提出的方法和数据集将推动多语言歌词转录的发展，这是一个具有挑战性和新兴的任务。"
    },
    {
        "title": "Concept-Oriented Deep Learning with Large Language Models",
        "url": "http://arxiv.org/abs/2306.17089v1",
        "pub_date": "2023-06-29",
        "summary": "Large Language Models (LLMs) have been successfully used in many\nnatural-language tasks and applications including text generation and AI\nchatbots. They also are a promising new technology for concept-oriented deep\nlearning (CODL). However, the prerequisite is that LLMs understand concepts and\nensure conceptual consistency. We discuss these in this paper, as well as major\nuses of LLMs for CODL including concept extraction from text, concept graph\nextraction from text, and concept learning. Human knowledge consists of both\nsymbolic (conceptual) knowledge and embodied (sensory) knowledge. Text-only\nLLMs, however, can represent only symbolic (conceptual) knowledge. Multimodal\nLLMs, on the other hand, are capable of representing the full range (conceptual\nand sensory) of human knowledge. We discuss conceptual understanding in\nvisual-language LLMs, the most important multimodal LLMs, and major uses of\nthem for CODL including concept extraction from image, concept graph extraction\nfrom image, and concept learning. While uses of LLMs for CODL are valuable\nstandalone, they are particularly valuable as part of LLM applications such as\nAI chatbots.",
        "translated": "大语言模型(LLM)已经成功地应用于许多自然语言任务和应用中，包括文本生成和人工智能聊天机器人。它们也是面向概念的深度学习(CODL)的一种有前途的新技术。然而，前提是 LLM 理解概念并确保概念的一致性。本文讨论了这些问题，以及 LLM 在 CODL 中的主要应用，包括从文本中提取概念，从文本中提取概念图，以及概念学习。人类知识包括符号(概念)知识和体现(感官)知识。然而，纯文本 LLM 只能表示符号(概念)知识。另一方面，多模式 LLM 能够表示人类知识的全部范围(概念和感官)。本文讨论了可视化语言 LLM 中的概念理解，即最重要的多模态 LLM，以及它们在 CODL 中的主要应用，包括从图像中提取概念、从图像中提取概念图和概念学习。虽然对 CODL 使用 LLM 是有价值的独立使用，但作为 LLM 应用程序(如 AI 聊天机器人)的一部分，它们尤其有价值。"
    },
    {
        "title": "The mapKurator System: A Complete Pipeline for Extracting and Linking\n  Text from Historical Maps",
        "url": "http://arxiv.org/abs/2306.17059v1",
        "pub_date": "2023-06-29",
        "summary": "Documents hold spatial focus and valuable locality characteristics. For\nexample, descriptions of listings in real estate or travel blogs contain\ninformation about specific local neighborhoods. This information is valuable to\ncharacterize how humans perceive their environment. However, the first step to\nmaking use of this information is to identify the spatial focus (e.g., a city)\nof a document. Traditional approaches for identifying the spatial focus of a\ndocument rely on detecting and disambiguating toponyms from the document. This\napproach requires a vocabulary set of location phrases and ad-hoc rules, which\nignore important words related to location. Recent topic modeling approaches\nusing large language models often consider a few topics, each with broad\ncoverage. In contrast, the spatial focus of a document can be a country, a\ncity, or even a neighborhood, which together, is much larger than the number of\ntopics considered in these approaches. Additionally, topic modeling methods are\noften applied to broad topics of news articles where context is easily\ndistinguishable. To identify the geographic focus of a document effectively, we\npresent a simple but effective Joint Embedding of multi-LocaLitY (JELLY), which\njointly learns representations with separate encoders of document and location.\nJELLY significantly outperforms state-of-the-art methods for identifying\nspatial focus from documents from a number of sources. We also demonstrate case\nstudies on the arithmetic of the learned representations, including identifying\ncities with similar locality characteristics and zero-shot learning to identify\ndocument spatial focus.",
        "translated": "文献具有空间聚焦性和地域性特征。例如，房地产或旅游博客中的列表描述包含有关特定当地社区的信息。这些信息对于描述人类如何感知周围环境很有价值。然而，利用这些信息的第一步是识别文档的空间焦点(例如，城市)。确定文件空间重点的传统方法依赖于从文件中检测和消除地名的歧义。这种方法需要一组位置短语和特别规则，这些规则忽略与位置相关的重要词汇。最近使用大型语言模型的主题建模方法通常考虑几个主题，每个主题都有广泛的涵盖范围。相比之下，一个文档的空间焦点可以是一个国家、一个城市，甚至是一个社区，它们加在一起要比这些方法中考虑的主题数量大得多。此外，主题建模方法通常应用于新闻文章中容易区分上下文的广泛主题。为了有效地识别文档的地理焦点，我们提出了一种简单而有效的多 LocaLitY (JELLY)联合嵌入方法，它通过文档和位置的单独编码器共同学习表示。JELLY 在从多个来源的文档中识别空间焦点方面的性能明显优于最先进的方法。我们还展示了学习表征算法的案例研究，包括识别具有相似地域特征的城市和零点学习识别文档空间焦点。"
    },
    {
        "title": "Towards Grammatical Tagging for the Legal Language of Cybersecurity",
        "url": "http://arxiv.org/abs/2306.17042v1",
        "pub_date": "2023-06-29",
        "summary": "Legal language can be understood as the language typically used by those\nengaged in the legal profession and, as such, it may come both in spoken or\nwritten form. Recent legislation on cybersecurity obviously uses legal language\nin writing, thus inheriting all its interpretative complications due to the\ntypical abundance of cases and sub-cases as well as to the general richness in\ndetail. This paper faces the challenge of the essential interpretation of the\nlegal language of cybersecurity, namely of the extraction of the essential\nParts of Speech (POS) from the legal documents concerning cybersecurity. The\nchallenge is overcome by our methodology for POS tagging of legal language. It\nleverages state-of-the-art open-source tools for Natural Language Processing\n(NLP) as well as manual analysis to validate the outcomes of the tools. As a\nresult, the methodology is automated and, arguably, general for any legal\nlanguage following minor tailoring of the preprocessing step. It is\ndemonstrated over the most relevant EU legislation on cybersecurity, namely on\nthe NIS 2 directive, producing the first, albeit essential, structured\ninterpretation of such a relevant document. Moreover, our findings indicate\nthat tools such as SpaCy and ClausIE reach their limits over the legal language\nof the NIS 2.",
        "translated": "法律语言可以被理解为从事法律职业的人通常使用的语言，因此，它可以是口头或书面形式。最近关于网络安全的立法显然使用了书面法律语言，从而继承了其所有解释性复杂性，这是由于典型的大量案例和子案例以及一般丰富的细节。本文面临着网络安全法律语言本质解释的挑战，即从网络安全法律文书中提取本质词语。我们的法律语言词性标注方法克服了这一挑战。它利用最先进的自然语言处理(NLP)开源工具以及手工分析来验证工具的结果。因此，这种方法是自动的，而且可以说，对于预处理步骤进行了少量裁剪之后的任何法律语言都是通用的。它体现在欧盟最相关的网络安全立法，即 NIS 2指令上，产生了对这样一个相关文件的第一个，尽管是必要的，结构化的解释。此外，我们的研究结果表明，工具，如 SpaCy 和 ClausIE 达到他们的限制，在法律语言的 NIS 2。"
    },
    {
        "title": "Exploring &amp; Exploiting High-Order Graph Structure for Sparse Knowledge\n  Graph Completion",
        "url": "http://arxiv.org/abs/2306.17034v1",
        "pub_date": "2023-06-29",
        "summary": "Sparse knowledge graph (KG) scenarios pose a challenge for previous Knowledge\nGraph Completion (KGC) methods, that is, the completion performance decreases\nrapidly with the increase of graph sparsity. This problem is also exacerbated\nbecause of the widespread existence of sparse KGs in practical applications. To\nalleviate this challenge, we present a novel framework, LR-GCN, that is able to\nautomatically capture valuable long-range dependency among entities to\nsupplement insufficient structure features and distill logical reasoning\nknowledge for sparse KGC. The proposed approach comprises two main components:\na GNN-based predictor and a reasoning path distiller. The reasoning path\ndistiller explores high-order graph structures such as reasoning paths and\nencodes them as rich-semantic edges, explicitly compositing long-range\ndependencies into the predictor. This step also plays an essential role in\ndensifying KGs, effectively alleviating the sparse issue. Furthermore, the path\ndistiller further distills logical reasoning knowledge from these mined\nreasoning paths into the predictor. These two components are jointly optimized\nusing a well-designed variational EM algorithm. Extensive experiments and\nanalyses on four sparse benchmarks demonstrate the effectiveness of our\nproposed method.",
        "translated": "稀疏知识图(KG)场景对以往的知识图完成(KGC)方法提出了挑战，即随着图稀疏度的增加，完成性能迅速下降。由于实际应用中普遍存在稀疏的幼稚园，这个问题更加严重。为了缓解这一挑战，我们提出了一个新的框架，LR-gcn，它能够自动捕获实体之间有价值的长期依赖，以补充不足的结构特征，并提取稀疏的逻辑推理知识。该方法包括两个主要部分: 基于 GNN 的预测器和推理路径提取器。推理路径提取器探索诸如推理路径之类的高阶图结构，并将它们编码为丰富的语义边，显式地将远程依赖组合到预测器中。此步骤亦有助增加幼稚园的密度，有效纾缓幼稚园人口稀少的问题。此外，路径蒸馏器进一步从这些挖掘的推理路径中提取逻辑推理知识到预测器中。这两个部分共同优化使用良好设计的变分 EM 算法。通过对四个稀疏基准测试的大量实验和分析，证明了该方法的有效性。"
    },
    {
        "title": "Classifying Crime Types using Judgment Documents from Social Media",
        "url": "http://arxiv.org/abs/2306.17020v1",
        "pub_date": "2023-06-29",
        "summary": "The task of determining crime types based on criminal behavior facts has\nbecome a very important and meaningful task in social science. But the problem\nfacing the field now is that the data samples themselves are unevenly\ndistributed, due to the nature of the crime itself. At the same time, data sets\nin the judicial field are less publicly available, and it is not practical to\nproduce large data sets for direct training. This article proposes a new\ntraining model to solve this problem through NLP processing methods. We first\npropose a Crime Fact Data Preprocessing Module (CFDPM), which can balance the\ndefects of uneven data set distribution by generating new samples. Then we use\na large open source dataset (CAIL-big) as our pretraining dataset and a small\ndataset collected by ourselves for Fine-tuning, giving it good generalization\nability to unfamiliar small datasets. At the same time, we use the improved\nBert model with dynamic masking to improve the model. Experiments show that the\nproposed method achieves state-of-the-art results on the present dataset. At\nthe same time, the effectiveness of module CFDPM is proved by experiments. This\narticle provides a valuable methodology contribution for classifying social\nscience texts such as criminal behaviors. Extensive experiments on public\nbenchmarks show that the proposed method achieves new state-of-the-art results.",
        "translated": "根据犯罪行为事实确定犯罪类型的任务已经成为社会科学中一项非常重要和有意义的任务。但现在该领域面临的问题是，由于犯罪本身的性质，数据样本本身的分布是不均匀的。与此同时，司法领域的数据集较少公开，为直接培训生产大型数据集是不切实际的。本文通过自然语言处理的方法，提出了一种新的训练模型来解决这个问题。我们首先提出了一个犯罪事实数据预处理模块(CFDPM) ，它通过生成新的样本来平衡数据集分布不均匀的缺陷。然后我们使用一个大的开源数据集(CAIL-big)作为我们的预训练数据集和一个我们自己收集的小数据集进行微调，使其具有对不熟悉的小数据集很好的泛化能力。同时，采用改进的带动态掩蔽的 Bert 模型对模型进行了改进。实验结果表明，该方法在目前的数据集上取得了较好的效果。同时，通过实验验证了 CFDPM 模块的有效性。本文为犯罪行为等社会科学文本的分类提供了有价值的方法论贡献。对公共基准测试的大量实验表明，该方法取得了较好的效果。"
    },
    {
        "title": "High-Quality Automatic Voice Over with Accurate Alignment: Supervision\n  through Self-Supervised Discrete Speech Units",
        "url": "http://arxiv.org/abs/2306.17005v1",
        "pub_date": "2023-06-29",
        "summary": "The goal of Automatic Voice Over (AVO) is to generate speech in sync with a\nsilent video given its text script. Recent AVO frameworks built upon\ntext-to-speech synthesis (TTS) have shown impressive results. However, the\ncurrent AVO learning objective of acoustic feature reconstruction brings in\nindirect supervision for inter-modal alignment learning, thus limiting the\nsynchronization performance and synthetic speech quality. To this end, we\npropose a novel AVO method leveraging the learning objective of self-supervised\ndiscrete speech unit prediction, which not only provides more direct\nsupervision for the alignment learning, but also alleviates the mismatch\nbetween the text-video context and acoustic features. Experimental results show\nthat our proposed method achieves remarkable lip-speech synchronization and\nhigh speech quality by outperforming baselines in both objective and subjective\nevaluations. Code and speech samples are publicly available.",
        "translated": "自动语音技术(AVO)的目标是根据文本脚本生成与无声视频同步的语音。最近建立在文本到语音合成(TTS)基础上的 AVO 框架已经显示出令人印象深刻的结果。然而，目前声学特征重构的 AVO 学习目标对多模态对齐学习带来了间接监督，从而限制了同步性能和合成语音质量。为此，我们提出了一种新的 AVO 方法，该方法利用自监督离散语音单元预测的学习目标，不仅为对齐学习提供了更直接的监督，而且减少了文本-视频上下文和声学特征之间的不匹配。实验结果表明，该方法在客观评价和主观评价方面均优于基线，实现了较好的唇语音同步，提高了语音质量。代码和语音样本是公开的。"
    },
    {
        "title": "MEMD-ABSA: A Multi-Element Multi-Domain Dataset for Aspect-Based\n  Sentiment Analysis",
        "url": "http://arxiv.org/abs/2306.16956v1",
        "pub_date": "2023-06-29",
        "summary": "Aspect-based sentiment analysis is a long-standing research interest in the\nfield of opinion mining, and in recent years, researchers have gradually\nshifted their focus from simple ABSA subtasks to end-to-end multi-element ABSA\ntasks. However, the datasets currently used in the research are limited to\nindividual elements of specific tasks, usually focusing on in-domain settings,\nignoring implicit aspects and opinions, and with a small data scale. To address\nthese issues, we propose a large-scale Multi-Element Multi-Domain dataset\n(MEMD) that covers the four elements across five domains, including nearly\n20,000 review sentences and 30,000 quadruples annotated with explicit and\nimplicit aspects and opinions for ABSA research. Meanwhile, we evaluate\ngenerative and non-generative baselines on multiple ABSA subtasks under the\nopen domain setting, and the results show that open domain ABSA as well as\nmining implicit aspects and opinions remain ongoing challenges to be addressed.\nThe datasets are publicly released at \\url{https://github.com/NUSTM/MEMD-ABSA}.",
        "translated": "基于方面的情绪分析是意见挖掘领域的一个长期研究热点，近年来研究者们已经逐渐从简单的 ABSA 子任务转向端到端的多元 ABSA 任务。然而，目前研究中使用的数据集仅限于特定任务的单个元素，通常侧重于领域内设置，忽略隐含的方面和意见，并且数据规模较小。为了解决这些问题，我们提出了一个大规模的多元素多领域数据集(MEMD) ，涵盖五个领域的四个元素，包括近20,000个评论句子和30,000个四元素注释明确和隐含的方面和意见的 ABSA 研究。同时，我们评估了开放领域环境下多个 ABSA 子任务的生成基线和非生成基线，结果表明，开放领域 ABSA 以及挖掘隐含的方面和意见仍然是有待解决的挑战。数据集在 url { https://github.com/nustm/memd-absa }公开发布。"
    },
    {
        "title": "Precision Anti-Cancer Drug Selection via Neural Ranking",
        "url": "http://arxiv.org/abs/2306.17771v1",
        "pub_date": "2023-06-30",
        "summary": "Personalized cancer treatment requires a thorough understanding of complex\ninteractions between drugs and cancer cell lines in varying genetic and\nmolecular contexts. To address this, high-throughput screening has been used to\ngenerate large-scale drug response data, facilitating data-driven computational\nmodels. Such models can capture complex drug-cell line interactions across\nvarious contexts in a fully data-driven manner. However, accurately\nprioritizing the most sensitive drugs for each cell line still remains a\nsignificant challenge. To address this, we developed neural ranking approaches\nthat leverage large-scale drug response data across multiple cell lines from\ndiverse cancer types. Unlike existing approaches that primarily utilize\nregression and classification techniques for drug response prediction, we\nformulated the objective of drug selection and prioritization as a drug ranking\nproblem. In this work, we proposed two neural listwise ranking methods that\nlearn latent representations of drugs and cell lines, and then use those\nrepresentations to score drugs in each cell line via a learnable scoring\nfunction. Specifically, we developed a neural listwise ranking method,\nList-One, on top of the existing method ListNet. Additionally, we proposed a\nnovel listwise ranking method, List-All, that focuses on all the sensitive\ndrugs instead of the top sensitive drug, unlike List-One. Our results\ndemonstrate that List-All outperforms the best baseline with significant\nimprovements of as much as 8.6% in hit@20 across 50% test cell lines.\nFurthermore, our analyses suggest that the learned latent spaces from our\nproposed methods demonstrate informative clustering structures and capture\nrelevant underlying biological features. Moreover, our comprehensive empirical\nevaluation provides a thorough and objective comparison of the performance of\ndifferent methods (including our proposed ones).",
        "translated": "个性化的癌症治疗需要彻底了解药物和癌细胞系在不同遗传和分子背景下的复杂相互作用。为了解决这个问题，high throughput 已经被用来产生大规模的药物反应数据，促进数据驱动的计算模型。这样的模型能够以完全数据驱动的方式捕获不同环境下复杂的药物-细胞系相互作用。然而，为每个细胞系准确地确定最敏感药物的优先顺序仍然是一个重大的挑战。为了解决这个问题，我们开发了神经排序方法，利用来自不同癌症类型的多个细胞系的大规模药物反应数据。与主要利用回归和分类技术进行药物反应预测的现有方法不同，我们将药物选择和优先排序作为一个药物排序问题来制定目标。在这项工作中，我们提出了两个神经列表排序方法，学习潜在表示的药物和细胞系，然后使用这些表示评分药物在每个细胞系通过可学习的评分函数。具体来说，我们在现有的 ListNet 方法之上开发了一个神经列表排序方法 List-One。此外，我们提出了一种新的列表排序方法，列表-所有，重点放在所有的敏感药物，而不是最敏感的药物，不同于列表-一。我们的研究结果表明，List-All 在50% 的测试细胞系中，hit@20的显著改善高达8.6% ，优于最佳基线。此外，我们的分析表明，从我们提出的方法学习潜在空间显示信息聚类结构和捕获相关的潜在生物学特征。此外，我们的综合实证评估为不同方法(包括我们提出的方法)的表现提供了一个彻底和客观的比较。"
    },
    {
        "title": "Outcome-based Evaluation of Systematic Review Automation",
        "url": "http://arxiv.org/abs/2306.17614v1",
        "pub_date": "2023-06-30",
        "summary": "Current methods of evaluating search strategies and automated citation\nscreening for systematic literature reviews typically rely on counting the\nnumber of relevant and not relevant publications. This established practice,\nhowever, does not accurately reflect the reality of conducting a systematic\nreview, because not all included publications have the same influence on the\nfinal outcome of the systematic review. More specifically, if an important\npublication gets excluded or included, this might significantly change the\noverall review outcome, while not including or excluding less influential\nstudies may only have a limited impact. However, in terms of evaluation\nmeasures, all inclusion and exclusion decisions are treated equally and,\ntherefore, failing to retrieve publications with little to no impact on the\nreview outcome leads to the same decrease in recall as failing to retrieve\ncrucial publications. We propose a new evaluation framework that takes into\naccount the impact of the reported study on the overall systematic review\noutcome. We demonstrate the framework by extracting review meta-analysis data\nand estimating outcome effects using predictions from ranking runs on\nsystematic reviews of interventions from CLEF TAR 2019 shared task. We further\nmeasure how closely the obtained outcomes are to the outcomes of the original\nreview if the arbitrary rankings were used. We evaluate 74 runs using the\nproposed framework and compare the results with those obtained using standard\nIR measures. We find that accounting for the difference in review outcomes\nleads to a different assessment of the quality of a system than if traditional\nevaluation measures were used. Our analysis provides new insights into the\nevaluation of retrieval results in the context of systematic review automation,\nemphasising the importance of assessing the usefulness of each document beyond\nbinary relevance.",
        "translated": "目前评估搜索策略和系统文献综述的自动引文筛选的方法通常依赖于计算相关和非相关出版物的数量。然而，这种既定做法并不能准确反映系统综述的实际情况，因为并非所有纳入的出版物对系统综述的最终结果都有同样的影响。更具体地说，如果一个重要的出版物被排除或纳入，这可能会显着改变总体评价结果，而不包括或排除影响力较小的研究可能只有有限的影响。然而，就评价措施而言，所有列入和排除决定都得到平等对待，因此，未能检索对审查结果影响不大或没有影响的出版物，导致回收率的下降与未能检索关键出版物的下降相同。我们提出一个新的评估框架，考虑到所报告的研究对整体系统综述结果的影响。我们通过从 CLEF TAR 2019共享任务中对干预措施的系统评价中提取评价荟萃分析数据并使用排名预测来估计结果效应来展示该框架。如果使用任意排名，我们进一步测量所得结果与原始评价结果的接近程度。我们使用提出的框架评估了74次运行，并将结果与使用标准红外测量获得的结果进行了比较。我们发现，与使用传统评价方法相比，考虑评价结果的差异会导致对系统质量的不同评价。我们的分析为在系统综述自动化背景下评估检索结果提供了新的见解，强调了评估每个文档的有用性超越二进制相关性的重要性。"
    },
    {
        "title": "Large Language Models are Effective Text Rankers with Pairwise Ranking\n  Prompting",
        "url": "http://arxiv.org/abs/2306.17563v1",
        "pub_date": "2023-06-30",
        "summary": "Ranking documents using Large Language Models (LLMs) by directly feeding the\nquery and candidate documents into the prompt is an interesting and practical\nproblem. However, there has been limited success so far, as researchers have\nfound it difficult to outperform fine-tuned baseline rankers on benchmark\ndatasets. We analyze pointwise and listwise ranking prompts used by existing\nmethods and argue that off-the-shelf LLMs do not fully understand these ranking\nformulations, possibly due to the nature of how LLMs are trained. In this\npaper, we propose to significantly reduce the burden on LLMs by using a new\ntechnique called Pairwise Ranking Prompting (PRP). Our results are the first in\nthe literature to achieve state-of-the-art ranking performance on standard\nbenchmarks using moderate-sized open-sourced LLMs. On TREC-DL2020, PRP based on\nthe Flan-UL2 model with 20B parameters outperforms the previous best approach\nin the literature, which is based on the blackbox commercial GPT-4 that has 50x\n(estimated) model size, by over 5% at NDCG@1. On TREC-DL2019, PRP is only\ninferior to the GPT-4 solution on the NDCG@5 and NDCG@10 metrics, while\noutperforming other existing solutions, such as InstructGPT which has 175B\nparameters, by over 10% for nearly all ranking metrics. Furthermore, we propose\nseveral variants of PRP to improve efficiency and show that it is possible to\nachieve competitive results even with linear complexity. We also discuss other\nbenefits of PRP, such as supporting both generation and scoring LLM APIs, as\nwell as being insensitive to input ordering.",
        "translated": "使用大型语言模型(LLM)对文档进行排序，将查询和候选文档直接输入到提示符中，这是一个有趣而实用的问题。然而，迄今为止取得的成功有限，因为研究人员发现很难在基准数据集上超越经过微调的基线排名。我们分析了现有方法使用的点式和列式排序提示，并认为现成的 LLM 不能完全理解这些排序公式，可能是由于 LLM 训练方式的性质。在本文中，我们提出了一种新的技术，即成对排序提示(PRP) ，来显著减少 LLM 的负担。我们的研究结果是文献中第一次使用中等规模的开源 LLM 在标准基准上实现最先进的排名性能。在 TREC-DL2020上，基于具有20B 参数的 Flan-UL2模型的 PRP 优于文献中以前的最佳方法，其基于具有50倍(估计)模型大小的黑盒商业 GPT-4，在 NDCG@1上超过5% 。在 TREC-DL2019上，PRP 在 NDCG@5和 NDCG@10指标上仅次于 GPT-4解决方案，而在几乎所有排名指标上，PRP 的表现优于其他现有解决方案，如具有175B 参数的翘楚 GPT，超过10% 。此外，我们提出了几个变种的 PRP，以提高效率，并表明可能实现的竞争结果，即使与线性复杂性。我们还讨论了 PRP 的其他好处，例如支持生成和评分 LLM API，以及对输入顺序不敏感。"
    },
    {
        "title": "Leveraging Watch-time Feedback for Short-Video Recommendations: A Causal\n  Labeling Framework",
        "url": "http://arxiv.org/abs/2306.17426v1",
        "pub_date": "2023-06-30",
        "summary": "With the proliferation of short video applications, the significance of short\nvideo recommendations has vastly increased. Unlike other recommendation\nscenarios, short video recommendation systems heavily rely on feedback from\nwatch time. Existing approaches simply treat watch time as a direct label,\nfailing to effectively harness its extensive semantics and introduce bias,\nthereby limiting the potential for modeling user interests based on watch time.\nTo overcome this challenge, we propose a framework named Debiasied\nMultiple-semantics-extracting Labeling (DML). DML constructs labels that\nencompass various semantics by utilizing quantiles derived from the\ndistribution of watch time, prioritizing relative order rather than absolute\nlabel values. This approach facilitates easier model learning while aligning\nwith the ranking objective of recommendations. Furthermore, we introduce a\nmethod inspired by causal adjustment to refine label definitions, thereby\nreducing the impact of bias on the label and directly mitigating bias at the\nlabel level. We substantiate the effectiveness of our DML framework through\nboth online and offline experiments. Extensive results demonstrate that our DML\ncould effectively leverage watch time to discover users' real interests,\nenhancing their engagement in our application.",
        "translated": "随着短视频应用程序的激增，短视频推荐的重要性大大增加。与其他推荐场景不同，短视频推荐系统严重依赖于观看时间的反馈。现有的方法只是简单地将手表时间作为一个直接标签，未能有效地利用其广泛的语义并引入偏见，从而限制了基于手表时间建模用户兴趣的潜力。为了克服这一挑战，我们提出了一个名为 Debiasied 多语义抽取标记(DML)的框架。DML 通过利用从手表时间分布派生的分位数构造包含各种语义的标签，优先考虑相对顺序而不是绝对标签值。这种方法促进了更容易的模型学习，同时与建议的排名目标保持一致。此外，我们引入了一个方法的启发，因果调整，以完善标签定义，从而减少偏见的影响，对标签和直接减轻偏见的标签水平。我们通过两个在线和离线的实验证实了我们的 DML 框架的有效性。大量的结果表明，我们的 DML 可以有效地利用观看时间来发现用户的真正兴趣，提高他们在我们的应用程序中的参与度。"
    },
    {
        "title": "Audio Embeddings as Teachers for Music Classification",
        "url": "http://arxiv.org/abs/2306.17424v1",
        "pub_date": "2023-06-30",
        "summary": "Music classification has been one of the most popular tasks in the field of\nmusic information retrieval. With the development of deep learning models, the\nlast decade has seen impressive improvements in a wide range of classification\ntasks. However, the increasing model complexity makes both training and\ninference computationally expensive. In this paper, we integrate the ideas of\ntransfer learning and feature-based knowledge distillation and systematically\ninvestigate using pre-trained audio embeddings as teachers to guide the\ntraining of low-complexity student networks. By regularizing the feature space\nof the student networks with the pre-trained embeddings, the knowledge in the\nteacher embeddings can be transferred to the students. We use various\npre-trained audio embeddings and test the effectiveness of the method on the\ntasks of musical instrument classification and music auto-tagging. Results show\nthat our method significantly improves the results in comparison to the\nidentical model trained without the teacher's knowledge. This technique can\nalso be combined with classical knowledge distillation approaches to further\nimprove the model's performance.",
        "translated": "音乐分类一直是音乐信息检索领域最受欢迎的课题之一。随着深度学习模型的发展，在过去的十年中，在广泛的分类任务方面取得了令人印象深刻的进步。然而，不断增长的模型复杂度使得训练和推理计算的开销都很大。本文结合迁移学习和基于特征的知识提取的思想，系统地研究了如何利用预先训练好的音频嵌入作为教师来指导低复杂度学生网络的训练。通过预训练嵌入规则化学生网络的特征空间，将教师嵌入中的知识传递给学生。我们使用各种预先训练的音频嵌入技术，测试这种方法在乐器分类法和音乐自动标签方面的效果。结果表明，与未经教师知识培训的同一模型相比，该方法显著提高了训练效果。该方法还可以与经典的知识提取方法相结合，进一步提高模型的性能。"
    },
    {
        "title": "SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen\n  LLMs",
        "url": "http://arxiv.org/abs/2306.17842v2",
        "pub_date": "2023-06-30",
        "summary": "In this work, we introduce Semantic Pyramid AutoEncoder (SPAE) for enabling\nfrozen LLMs to perform both understanding and generation tasks involving\nnon-linguistic modalities such as images or videos. SPAE converts between raw\npixels and interpretable lexical tokens (or words) extracted from the LLM's\nvocabulary. The resulting tokens capture both the semantic meaning and the\nfine-grained details needed for visual reconstruction, effectively translating\nthe visual content into a language comprehensible to the LLM, and empowering it\nto perform a wide array of multimodal tasks. Our approach is validated through\nin-context learning experiments with frozen PaLM 2 and GPT 3.5 on a diverse set\nof image understanding and generation tasks. Our method marks the first\nsuccessful attempt to enable a frozen LLM to generate image content while\nsurpassing state-of-the-art performance in image understanding tasks, under the\nsame setting, by over 25%.",
        "translated": "在这项工作中，我们介绍了语义金字塔自动编码器(SPAE) ，使冻结 LLM 执行理解和生成任务涉及非语言的形式，如图像或视频。SPAE 在原始像素和从 LLM 词汇表中提取的可解释词汇标记(或单词)之间进行转换。由此产生的标记捕获视觉重建所需的语义和细粒度细节，有效地将视觉内容翻译成 LLM 可理解的语言，并授权它执行大量多模态任务。我们的方法是通过在一组不同的图像理解和生成任务上使用冻结的 PaLM 2和 GPT 3.5进行上下文学习实验来验证的。我们的方法标志着第一次成功尝试使一个冻结的 LLM 能够生成图像内容，同时在图像理解任务中超过最先进的性能，在相同的设置下，超过25% 。"
    },
    {
        "title": "Statler: State-Maintaining Language Models for Embodied Reasoning",
        "url": "http://arxiv.org/abs/2306.17840v2",
        "pub_date": "2023-06-30",
        "summary": "Large language models (LLMs) provide a promising tool that enable robots to\nperform complex robot reasoning tasks. However, the limited context window of\ncontemporary LLMs makes reasoning over long time horizons difficult. Embodied\ntasks such as those that one might expect a household robot to perform\ntypically require that the planner consider information acquired a long time\nago (e.g., properties of the many objects that the robot previously encountered\nin the environment). Attempts to capture the world state using an LLM's\nimplicit internal representation is complicated by the paucity of task- and\nenvironment-relevant information available in a robot's action history, while\nmethods that rely on the ability to convey information via the prompt to the\nLLM are subject to its limited context window. In this paper, we propose\nStatler, a framework that endows LLMs with an explicit representation of the\nworld state as a form of ``memory'' that is maintained over time. Integral to\nStatler is its use of two instances of general LLMs -- a world-model reader and\na world-model writer -- that interface with and maintain the world state. By\nproviding access to this world state ``memory'', Statler improves the ability\nof existing LLMs to reason over longer time horizons without the constraint of\ncontext length. We evaluate the effectiveness of our approach on three\nsimulated table-top manipulation domains and a real robot domain, and show that\nit improves the state-of-the-art in LLM-based robot reasoning. Project website:\nhttps://statler-lm.github.io/",
        "translated": "大语言模型(LLM)为机器人执行复杂的机器人推理任务提供了有前途的工具。然而，当代 LLM 的有限的上下文窗口使得长时间的推理变得困难。具体的任务，比如人们可能期望家用机器人执行的任务，通常需要计划者考虑很久以前获得的信息(例如，机器人以前在环境中遇到的许多对象的属性)。使用 LLM 的隐式内部表示来捕捉世界状态的尝试由于机器人动作历史中缺乏与任务和环境相关的信息而变得复杂，而依赖于通过向 LLM 提示传递信息的能力的方法受制于其有限的上下文窗口。在本文中，我们提出了 Statler 框架，这个框架赋予 LLM 以世界状态的显式表示，作为一种随时间维护的“记忆”形式。对 Statler 而言，Integral 使用了两种常规 LLM ——一种是世界模式的阅读器，另一种是世界模式的写作器——它们与世界状态相互作用，并维持着世界状态。通过提供对这个世界状态“内存”的访问，Statler 提高了现有 LLM 在较长时间范围内进行推理的能力，而不受上下文长度的限制。通过对三个仿真桌面操作域和一个实际机器人域的仿真，评价了该方法的有效性，并表明该方法提高了基于 LLM 的机器人推理的技术水平。项目网址:  https://statler-lm.github.io/"
    },
    {
        "title": "Meta-Reasoning: Semantics-Symbol Deconstruction For Large Language\n  Models",
        "url": "http://arxiv.org/abs/2306.17820v1",
        "pub_date": "2023-06-30",
        "summary": "Symbolization methods in large language models (LLMs) have been shown\neffective to improve LLMs' reasoning ability. However, most of these approaches\nhinge on mapping natural languages to formal languages (e.g., Python, SQL) that\nare more syntactically complete and free of ambiguity. Although effective, they\ndepart from the natural language itself and deviate from the habits of human\nthinking, and instead cater more to the execution mindset of computers. In\ncontrast, we hope to simplify natural language by starting from the concept of\nsymbols in linguistics itself, so that LLMs can learn the common formulation\nand general solution of reasoning problems wrapped in different natural\nsemantics. From this consideration, we propose \\textbf{Meta-Reasoning}, which\nallows LLMs to automatically accomplish semantic-symbol deconstruction, i.e.,\nsemantic resolution, to maximally reduce different questions of certain\nreasoning tasks to similar natural language representation, thus gaining the\nability to learn by analogy and facilitating data-efficient in-context\nlearning. Our experiments show that the Meta-Reasoning paradigm saliently\nenhances LLMs' reasoning performance with fewer demonstrations. They can learn\nnot only reasoning chains but also general solutions to certain types of tasks.\nIn particular, for symbolic reasoning tasks, such as 7-step Tracking Shuffled\nObjects, GPT-3 (text-davinci-002) achieves over 99% accuracy with only one\nMeta-Reasoning demonstration, outperforming all current LLMs with the standard\nchain-of-thought prompting.",
        "translated": "大型语言模型中的符号化方法已被证明可以有效地提高语言模型的推理能力。然而，这些方法大多依赖于将自然语言映射到语法更完整、没有歧义的正式语言(例如 Python、 SQL)。虽然有效，但它们背离了自然语言本身，背离了人类思维的习惯，而更多地迎合了计算机的执行思维。相反，我们希望从语言学本身的符号概念入手，简化自然语言，使 LLM 能够学习不同自然语义包裹的推理问题的通用表达式和通用解决方案。基于这一考虑，我们提出了 textbf { Meta 推理} ，它允许 LLM 自动完成语义符号解构，即语义解析，以最大限度地减少某些推理任务的不同问题类似的自然语言表示，从而获得类比学习的能力，并促进数据高效的上下文学习。我们的实验表明，元推理范式显著提高了 LLM 的推理性能与较少的演示。他们不仅可以学习推理链条，还可以学习某些类型任务的一般解决方案。特别是对于符号推理任务，例如7步跟踪混乱对象，GPT-3(text-davinci-002)仅用一次元推理演示就达到了99% 以上的准确率，在标准的思维链提示下表现优于所有当前的 LLM。"
    },
    {
        "title": "A Massive Scale Semantic Similarity Dataset of Historical English",
        "url": "http://arxiv.org/abs/2306.17810v1",
        "pub_date": "2023-06-30",
        "summary": "A diversity of tasks use language models trained on semantic similarity data.\nWhile there are a variety of datasets that capture semantic similarity, they\nare either constructed from modern web data or are relatively small datasets\ncreated in the past decade by human annotators. This study utilizes a novel\nsource, newly digitized articles from off-copyright, local U.S. newspapers, to\nassemble a massive-scale semantic similarity dataset spanning 70 years from\n1920 to 1989 and containing nearly 400M positive semantic similarity pairs.\nHistorically, around half of articles in U.S. local newspapers came from\nnewswires like the Associated Press. While local papers reproduced articles\nfrom the newswire, they wrote their own headlines, which form abstractive\nsummaries of the associated articles. We associate articles and their headlines\nby exploiting document layouts and language understanding. We then use deep\nneural methods to detect which articles are from the same underlying source, in\nthe presence of substantial noise and abridgement. The headlines of reproduced\narticles form positive semantic similarity pairs. The resulting publicly\navailable HEADLINES dataset is significantly larger than most existing semantic\nsimilarity datasets and covers a much longer span of time. It will facilitate\nthe application of contrastively trained semantic similarity models to a\nvariety of tasks, including the study of semantic change across space and time.",
        "translated": "多种任务使用基于语义相似性数据的语言模型。虽然有各种各样的数据集可以捕获语义相似性，但它们要么是由现代网络数据构建的，要么是由人工注释者在过去十年中创建的相对较小的数据集。本研究利用来自美国本土报纸的一个新的来源，新近数字化的文章，收集了一个大规模的语义相似度数据集，这个数据集从1920年到1989年跨越了70年，包含了近400M 的正语义相似度对。从历史上看，美国地方报纸大约有一半的文章来自美联社等新闻通讯社。当地报纸转载新闻通讯社的文章，他们写自己的标题，形成相关文章的抽象摘要。我们通过利用文档布局和语言理解将文章和标题联系起来。然后，我们使用深度神经方法来检测哪些文章来自相同的潜在来源，在存在大量的噪音和删节。转载文章的标题形成正的语义相似对。由此产生的公开可用的 HEADLINES 数据集明显大于大多数现有的语义相似性数据集，并覆盖了更长的时间跨度。它将有助于对比训练语义相似性模型应用于各种任务，包括跨时空语义变化的研究。"
    },
    {
        "title": "Stay on topic with Classifier-Free Guidance",
        "url": "http://arxiv.org/abs/2306.17806v1",
        "pub_date": "2023-06-30",
        "summary": "Classifier-Free Guidance (CFG) has recently emerged in text-to-image\ngeneration as a lightweight technique to encourage prompt-adherence in\ngenerations. In this work, we demonstrate that CFG can be used broadly as an\ninference-time technique in pure language modeling. We show that CFG (1)\nimproves the performance of Pythia, GPT-2 and LLaMA-family models across an\narray of tasks: Q\\&amp;A, reasoning, code generation, and machine translation,\nachieving SOTA on LAMBADA with LLaMA-7B over PaLM-540B; (2) brings improvements\nequivalent to a model with twice the parameter-count; (3) can stack alongside\nother inference-time methods like Chain-of-Thought and Self-Consistency,\nyielding further improvements in difficult tasks; (4) can be used to increase\nthe faithfulness and coherence of assistants in challenging form-driven and\ncontent-driven prompts: in a human evaluation we show a 75\\% preference for\nGPT4All using CFG over baseline.",
        "translated": "无分类器指导(CFG)最近出现在文本到图像的生成作为一种轻量级技术，以鼓励在几代人中迅速遵守。在这项工作中，我们证明了 CFG 可以作为一种推理时间技术在纯语言建模中得到广泛的应用。我们展示了 CFG (1)在一系列任务中提高了 Pythia、 GPT-2和 Llama 家族模型的性能:A、推理、代码生成和机器翻译，在 LAMBADA 上用 LLaMA-7B 在 PaLM-540B 上实现 SOTA; (2)带来相当于参数计数两倍的模型的改进; (3)可以与其他推理时间方法(如思维链和自我一致性)叠加，在困难任务中产生进一步的改进;(4)可用于增加助手在具有挑战性的形式驱动和内容驱动的提示中的忠实性和一致性: 在人类评估中，我们显示使用 CFG 的 GPT4All 优于基线的75% 。"
    },
    {
        "title": "Towards Improving the Performance of Pre-Trained Speech Models for\n  Low-Resource Languages Through Lateral Inhibition",
        "url": "http://arxiv.org/abs/2306.17792v1",
        "pub_date": "2023-06-30",
        "summary": "With the rise of bidirectional encoder representations from Transformer\nmodels in natural language processing, the speech community has adopted some of\ntheir development methodologies. Therefore, the Wav2Vec models were introduced\nto reduce the data required to obtain state-of-the-art results. This work\nleverages this knowledge and improves the performance of the pre-trained speech\nmodels by simply replacing the fine-tuning dense layer with a lateral\ninhibition layer inspired by the biological process. Our experiments on\nRomanian, a low-resource language, show an average improvement of 12.5% word\nerror rate (WER) using the lateral inhibition layer. In addition, we obtain\nstate-of-the-art results on both the Romanian Speech Corpus and the Robin\nTechnical Acquisition Corpus with 1.78% WER and 29.64% WER, respectively.",
        "translated": "随着自然语言处理领域中变换器模型中双向编码器表示方法的兴起，语音社区采用了它们的一些开发方法。因此，我们引入了 Wav2Vec 模型，以减少获得最先进结果所需的数据。这项工作充分利用了这些知识，通过简单地用受生物过程启发的侧抑制层取代微调密集层，提高了预先训练好的语音模型的性能。我们在罗马尼亚语(一种资源匮乏的语言)上的实验表明，使用侧抑制层平均可以提高12.5% 的单词错误率。此外，我们在罗马尼亚语言语料库和罗宾技术习得语料库中分别获得了1.78% 和29.64% 的最新结果。"
    },
    {
        "title": "Should you marginalize over possible tokenizations?",
        "url": "http://arxiv.org/abs/2306.17757v1",
        "pub_date": "2023-06-30",
        "summary": "Autoregressive language models (LMs) map token sequences to probabilities.\nThe usual practice for computing the probability of any character string (e.g.\nEnglish sentences) is to first transform it into a sequence of tokens that is\nscored by the model. However, there are exponentially many token sequences that\nrepresent any given string. To truly compute the probability of a string one\nshould marginalize over all tokenizations, which is typically intractable.\nHere, we analyze whether the practice of ignoring the marginalization is\njustified. To this end, we devise an importance-sampling-based algorithm that\nallows us to compute estimates of the marginal probabilities and compare them\nto the default procedure in a range of state-of-the-art models and datasets.\nOur results show that the gap in log-likelihood is no larger than 0.5% in most\ncases, but that it becomes more pronounced for data with long complex words.",
        "translated": "自回归语言模型(LM)将标记序列映射到概率。计算任何字符串(例如英语句子)的概率的通常做法是首先将其转换为一系列由模型计分的标记。但是，表示任意给定字符串的令牌序列呈指数级增长。要真正计算字符串的概率，应该在所有标记化中边缘化，这通常是难以实现的。在这里，我们分析忽视边缘化的做法是否合理。为此，我们设计了一种基于重要性抽样的算法，它允许我们计算边际概率的估计值，并将其与一系列最先进的模型和数据集中的默认过程进行比较。我们的研究结果表明，在大多数情况下，对数似然的差距不大于0.5% ，但是对于含有较长复杂词的数据，这一差距变得更加明显。"
    },
    {
        "title": "Token-Event-Role Structure-based Multi-Channel Document-Level Event\n  Extraction",
        "url": "http://arxiv.org/abs/2306.17733v1",
        "pub_date": "2023-06-30",
        "summary": "Document-level event extraction is a long-standing challenging information\nretrieval problem involving a sequence of sub-tasks: entity extraction, event\ntype judgment, and event type-specific multi-event extraction. However,\naddressing the problem as multiple learning tasks leads to increased model\ncomplexity. Also, existing methods insufficiently utilize the correlation of\nentities crossing different events, resulting in limited event extraction\nperformance. This paper introduces a novel framework for document-level event\nextraction, incorporating a new data structure called token-event-role and a\nmulti-channel argument role prediction module. The proposed data structure\nenables our model to uncover the primary role of tokens in multiple events,\nfacilitating a more comprehensive understanding of event relationships. By\nleveraging the multi-channel prediction module, we transform entity and\nmulti-event extraction into a single task of predicting token-event pairs,\nthereby reducing the overall parameter size and enhancing model efficiency. The\nresults demonstrate that our approach outperforms the state-of-the-art method\nby 9.5 percentage points in terms of the F1 score, highlighting its superior\nperformance in event extraction. Furthermore, an ablation study confirms the\nsignificant value of the proposed data structure in improving event extraction\ntasks, further validating its importance in enhancing the overall performance\nof the framework.",
        "translated": "文档级事件提取是一个长期存在的具有挑战性的信息检索问题，涉及一系列子任务: 实体提取、事件类型判断和特定于事件类型的多事件提取。然而，将问题作为多个学习任务处理会导致模型复杂度的增加。此外，现有的方法没有充分利用跨不同事件的实体之间的相关性，导致事件提取性能有限。提出了一种新的文档级事件抽取框架，该框架结合了新的数据结构令牌-事件-角色和多通道参数角色预测模块。建议的数据结构使我们的模型能够揭示令牌在多个事件中的主要作用，促进对事件关系的更全面的理解。通过利用多通道预测模块，将实体和多事件提取转化为单一的预测令牌-事件对任务，从而减少了整体参数的大小，提高了模型的效率。结果表明，我们的方法优于国家的最先进的方法9.5个百分点的条件下的 F1得分，突出其优越的表现在事件提取。此外，消融研究证实了该数据结构在改善事件提取任务方面的重要价值，进一步验证了其在提高框架整体性能方面的重要性。"
    },
    {
        "title": "Improved NL2SQL based on Multi-layer Expert Network",
        "url": "http://arxiv.org/abs/2306.17727v1",
        "pub_date": "2023-06-30",
        "summary": "The Natural Language to SQL (NL2SQL) technique is used to convert natural\nlanguage queries into executable SQL statements. Typically, slot-filling is\nemployed as a classification method for multi-task cases to achieve this goal.\nHowever, slot-filling can result in inaccurate SQL statement generation due to\nnegative migration issues arising from different classification tasks. To\novercome this limitation, this study introduces a new approach called\nMulti-Layer Expert Generate SQL (MLEG-SQL), which utilizes a dedicated\nmulti-task hierarchical network. The lower layer of the network extracts\nsemantic features of natural language statements, while the upper layer builds\na specialized expert system for handling specific classification tasks. This\nhierarchical approach mitigates performance degradation resulting from\ndifferent task conflicts. The proposed method was evaluated on the WiKSQL\ndataset and was found to be effective in generating accurate SQL statements.",
        "translated": "自然语言到 SQL (NL2SQL)技术用于将自然语言查询转换为可执行 SQL 语句。通常，为了实现这一目标，多任务案例的分类方法是采用槽填充的方法。然而，由于不同分类任务产生的负迁移问题，插槽填充可能导致 SQL 语句生成不准确。为了克服这一局限性，本研究提出了一种新的多层专家生成 SQL (Multi-Layer Expert Generate SQL，MLEG-SQL)方法，该方法利用一个专用的多任务分层网络。网络的下层提取自然语言语句的语义特征，上层建立专门的专家系统来处理特定的分类任务。这种分层方法减轻了不同任务冲突导致的性能下降。在 WiKSQL 数据集上对该方法进行了评估，结果表明该方法能够有效地生成准确的 SQL 语句。"
    },
    {
        "title": "Beyond Neural-on-Neural Approaches to Speaker Gender Protection",
        "url": "http://arxiv.org/abs/2306.17700v1",
        "pub_date": "2023-06-30",
        "summary": "Recent research has proposed approaches that modify speech to defend against\ngender inference attacks. The goal of these protection algorithms is to control\nthe availability of information about a speaker's gender, a privacy-sensitive\nattribute. Currently, the common practice for developing and testing gender\nprotection algorithms is \"neural-on-neural\", i.e., perturbations are generated\nand tested with a neural network. In this paper, we propose to go beyond this\npractice to strengthen the study of gender protection. First, we demonstrate\nthe importance of testing gender inference attacks that are based on speech\nfeatures historically developed by speech scientists, alongside the\nconventionally used neural classifiers. Next, we argue that researchers should\nuse speech features to gain insight into how protective modifications change\nthe speech signal. Finally, we point out that gender-protection algorithms\nshould be compared with novel \"vocal adversaries\", human-executed voice\nadaptations, in order to improve interpretability and enable before-the-mic\nprotection.",
        "translated": "最近的研究已经提出了修改语音以防止性别推理攻击的方法。这些保护算法的目标是控制有关说话者性别的信息的可用性，这是一个对隐私敏感的属性。目前，开发和测试性别保护算法的常见做法是“神经元对神经元”，即用神经网络生成和测试扰动。本文建议超越这一实践，加强对性别保护的研究。首先，我们证明了测试性别推断攻击的重要性，这些攻击是基于语音科学家历史上发展出来的语音特征，以及常规使用的神经分类器。接下来，我们认为研究人员应该利用语音特征来深入了解保护性修饰如何改变语音信号。最后，我们指出，性别保护算法应该与新的“声音对手”，人类执行的语音适应性进行比较，以提高可解释性，使麦克风前的保护。"
    },
    {
        "title": "ChatGPT vs. Google: A Comparative Study of Search Performance and User\n  Experience",
        "url": "http://arxiv.org/abs/2307.01135v1",
        "pub_date": "2023-07-03",
        "summary": "The advent of ChatGPT, a large language model-powered chatbot, has prompted\nquestions about its potential implications for traditional search engines. In\nthis study, we investigate the differences in user behavior when employing\nsearch engines and chatbot tools for information-seeking tasks. We carry out a\nrandomized online experiment, dividing participants into two groups: one using\na ChatGPT-like tool and the other using a Google Search-like tool. Our findings\nreveal that the ChatGPT group consistently spends less time on all tasks, with\nno significant difference in overall task performance between the groups.\nNotably, ChatGPT levels user search performance across different education\nlevels and excels in answering straightforward questions and providing general\nsolutions but falls short in fact-checking tasks. Users perceive ChatGPT's\nresponses as having higher information quality compared to Google Search,\ndespite displaying a similar level of trust in both tools. Furthermore,\nparticipants using ChatGPT report significantly better user experiences in\nterms of usefulness, enjoyment, and satisfaction, while perceived ease of use\nremains comparable between the two tools. However, ChatGPT may also lead to\noverreliance and generate or replicate misinformation, yielding inconsistent\nresults. Our study offers valuable insights for search engine management and\nhighlights opportunities for integrating chatbot technologies into search\nengine designs.",
        "translated": "ChatGPT 是一个大型语言模型驱动的聊天机器人，它的出现引发了人们对其对传统搜索引擎潜在影响的质疑。在本研究中，我们探讨使用搜寻引擎与聊天机器人工具进行资讯搜寻时，使用者行为的差异。我们进行了一个随机的在线实验，将参与者分成两组: 一组使用类似 ChatGPT 的工具，另一组使用类似 Google 搜索的工具。我们的研究结果表明，ChatGPT 小组在所有任务上花费的时间一致较少，小组之间的整体任务表现没有显著差异。值得注意的是，ChatGPT 在不同教育水平的用户搜索性能水平，并擅长回答简单的问题和提供一般性的解决方案，但在事实检查任务中表现不佳。用户认为 ChatGPT 的回复比 Google 搜索的信息质量更高，尽管他们对这两个工具的信任程度相似。此外，使用 ChatGPT 的参与者报告显着更好的用户体验在有用性，享受和满意度方面，而易于使用的感知仍然是两个工具之间的可比性。然而，ChatGPT 也可能导致过度依赖和产生或重复错误信息，产生不一致的结果。我们的研究为搜索引擎管理提供了有价值的见解，并强调了将聊天机器人技术整合到搜索引擎设计中的机会。"
    },
    {
        "title": "OpenSiteRec: An Open Dataset for Site Recommendation",
        "url": "http://arxiv.org/abs/2307.00856v1",
        "pub_date": "2023-07-03",
        "summary": "As a representative information retrieval task, site recommendation, which\naims at predicting the optimal sites for a brand or an institution to open new\nbranches in an automatic data-driven way, is beneficial and crucial for brand\ndevelopment in modern business. However, there is no publicly available dataset\nso far and most existing approaches are limited to an extremely small scope of\nbrands, which seriously hinders the research on site recommendation. Therefore,\nwe collect, construct and release an open comprehensive dataset, namely\nOpenSiteRec, to facilitate and promote the research on site recommendation.\nSpecifically, OpenSiteRec leverages a heterogeneous graph schema to represent\nvarious types of real-world entities and relations in four international\nmetropolises. To evaluate the performance of the existing general methods on\nthe site recommendation task, we conduct benchmarking experiments of several\nrepresentative recommendation models on OpenSiteRec. Furthermore, we also\nhighlight the potential application directions to demonstrate the wide\napplicability of OpenSiteRec. We believe that our OpenSiteRec dataset is\nsignificant and anticipated to encourage the development of advanced methods\nfor site recommendation. OpenSiteRec is available online at\nhttps://OpenSiteRec.github.io/.",
        "translated": "网站推荐作为一项具有代表性的信息检索任务，旨在预测一个品牌或机构以自动数据驱动的方式开设新分支机构的最佳网站，对于现代商业中的品牌发展是有益的，也是至关重要的。然而，到目前为止还没有公开的数据集，大多数现有的方法仅限于极小范围的品牌，这严重阻碍了对网站推荐的研究。因此，我们收集、构建和发布一个开放的综合数据集，即 OpenSiteRec，以促进和推动网站推荐的研究。具体来说，OpenSiteRec 利用异构图模式来表示四个国际大都市中各种类型的现实世界实体和关系。为了评估现有的一般方法在站点推荐任务中的性能，我们在 OpenSiteRec 上对几种有代表性的推荐模型进行了基准测试实验。此外，我们还强调了潜在的应用程序方向，以展示 OpenSiteRec 的广泛适用性。我们相信我们的 OpenSiteRec 数据集是重要的，并且预计将鼓励开发用于网站推荐的高级方法。OpenSiteRec 可于网上 https://OpenSiteRec.github.io/下载。"
    },
    {
        "title": "Looks Can Be Deceiving: Linking User-Item Interactions and User's\n  Propensity Towards Multi-Objective Recommendations",
        "url": "http://arxiv.org/abs/2307.00654v1",
        "pub_date": "2023-07-02",
        "summary": "Multi-objective recommender systems (MORS) provide suggestions to users\naccording to multiple (and possibly conflicting) goals. When a system optimizes\nits results at the individual-user level, it tailors them on a user's\npropensity towards the different objectives. Hence, the capability to\nunderstand users' fine-grained needs towards each goal is crucial. In this\npaper, we present the results of a user study in which we monitored the way\nusers interacted with recommended items, as well as their self-proclaimed\npropensities towards relevance, novelty and diversity objectives. The study was\ndivided into several sessions, where users evaluated recommendation lists\noriginating from a relevance-only single-objective baseline as well as MORS. We\nshow that despite MORS-based recommendations attracted less selections, its\npresence in the early sessions is crucial for users' satisfaction in the later\nstages. Surprisingly, the self-proclaimed willingness of users to interact with\nnovel and diverse items is not always reflected in the recommendations they\naccept. Post-study questionnaires provide insights on how to deal with this\nmatter, suggesting that MORS-based results should be accompanied by elements\nthat allow users to understand the recommendations, so as to facilitate their\nacceptance.",
        "translated": "多目标推荐系统(MORS)根据多个(可能存在冲突的)目标向用户提供建议。当一个系统在个人用户层面优化其结果时，它会根据用户对不同目标的倾向来调整结果。因此，理解用户对每个目标的细粒度需求的能力是至关重要的。在本文中，我们介绍了一项用户研究的结果，其中我们监测了用户与推荐项目的互动方式，以及他们自称的相关性、新颖性和多样性目标的倾向。这项研究分为几个阶段，用户评估源自相关性单一目标基线的推荐名单以及 MORS。我们表明，尽管基于 MORS 的建议吸引了较少的选择，它在早期会议的存在是至关重要的用户满意度在后期阶段。令人惊讶的是，用户自称愿意与新颖和多样化的项目进行互动，但并不总是反映在他们接受的建议中。研究后调查问卷提供了关于如何处理这一问题的见解，建议以 MORS 为基础的结果应附有使用者能够理解建议的要素，以便于他们接受。"
    },
    {
        "title": "BioCPT: Contrastive Pre-trained Transformers with Large-scale PubMed\n  Search Logs for Zero-shot Biomedical Information Retrieval",
        "url": "http://arxiv.org/abs/2307.00589v1",
        "pub_date": "2023-07-02",
        "summary": "Information retrieval (IR) is essential in biomedical knowledge acquisition\nand clinical decision support. While recent progress has shown that language\nmodel encoders perform better semantic retrieval, training such models requires\nabundant query-article annotations that are difficult to obtain in biomedicine.\nAs a result, most biomedical IR systems only conduct lexical matching. In\nresponse, we introduce BioCPT, a first-of-its-kind Contrastively Pre-trained\nTransformer model for zero-shot biomedical IR. To train BioCPT, we collected an\nunprecedented scale of 255 million user click logs from PubMed. With such data,\nwe use contrastive learning to train a pair of closely-integrated retriever and\nre-ranker. Experimental results show that BioCPT sets new state-of-the-art\nperformance on five biomedical IR tasks, outperforming various baselines\nincluding much larger models such as GPT-3-sized cpt-text-XL. In addition,\nBioCPT also generates better biomedical article and sentence representations\nfor semantic evaluations. As such, BioCPT can be readily applied to various\nreal-world biomedical IR tasks. BioCPT API and code are publicly available at\nhttps://github.com/ncbi/BioCPT.",
        "translated": "信息检索(IR)在获取生物医学知识和临床决策支持方面是必不可少的。虽然最近的进展表明，语言模型编码器执行更好的语义检索，训练这种模型需要大量的查询文章注释，这是难以获得的生物医学。因此，大多数生物医学红外系统只进行词汇匹配。作为回应，我们介绍了 BioCPT，一种首创的对比性预训练变压器模型，用于生物医学红外线的零激发。为了培训 BioCPT，我们从 PubMed 收集了前所未有的2.55亿用户点击日志。利用这些数据，我们使用对比学习来训练一对紧密集成的检索器和重排序器。实验结果表明，BioCPT 在五个生物医学 IR 任务上设置了新的最先进的性能，超过了包括 GPT-3大小的 cpt-text-XL 等更大模型在内的各种基线。此外，BioCPT 还为语义评估生成更好的生物医学文章和句子表示。因此，BioCPT 可以很容易地应用于各种真实世界的生物医学红外任务。BioCPT 原料药和代码可在 https://github.com/ncbi/BioCPT 公开查阅。"
    },
    {
        "title": "HeGeL: A Novel Dataset for Geo-Location from Hebrew Text",
        "url": "http://arxiv.org/abs/2307.00509v1",
        "pub_date": "2023-07-02",
        "summary": "The task of textual geolocation - retrieving the coordinates of a place based\non a free-form language description - calls for not only grounding but also\nnatural language understanding and geospatial reasoning. Even though there are\nquite a few datasets in English used for geolocation, they are currently based\non open-source data (Wikipedia and Twitter), where the location of the\ndescribed place is mostly implicit, such that the location retrieval resolution\nis limited. Furthermore, there are no datasets available for addressing the\nproblem of textual geolocation in morphologically rich and resource-poor\nlanguages, such as Hebrew. In this paper, we present the Hebrew Geo-Location\n(HeGeL) corpus, designed to collect literal place descriptions and analyze\nlingual geospatial reasoning. We crowdsourced 5,649 literal Hebrew place\ndescriptions of various place types in three cities in Israel. Qualitative and\nempirical analysis show that the data exhibits abundant use of geospatial\nreasoning and requires a novel environmental representation.",
        "translated": "文本地理定位的任务——基于自由形式的语言描述检索地点的坐标——不仅需要基础，而且需要自然语言理解和地理空间推理。尽管英语中有相当多的数据集用于地理定位，但它们目前都是基于开源数据(维基百科和 Twitter) ，其中描述的位置大多是隐式的，因此位置检索的分辨率是有限的。此外，没有数据集可用于解决文本地理定位问题的形态丰富和资源贫乏的语言，如希伯来语。本文提出了希伯来文地理定位语料库(HeGeL) ，旨在收集文字地点描述并分析语言地理空间推理。我们在以色列的三个城市中众包了5649个不同地点类型的希伯来文地点描述。定性和实证分析表明，这些数据显示了地理空间推理的丰富应用，需要一种新的环境表示方法。"
    },
    {
        "title": "Trainable Transformer in Transformer",
        "url": "http://arxiv.org/abs/2307.01189v1",
        "pub_date": "2023-07-03",
        "summary": "Recent works attribute the capability of in-context learning (ICL) in large\npre-trained language models to implicitly simulating and fine-tuning an\ninternal model (e.g., linear or 2-layer MLP) during inference. However, such\nconstructions require large memory overhead, which makes simulation of more\nsophisticated internal models intractable. In this work, we propose an\nefficient construction, Transformer in Transformer (in short, TinT), that\nallows a transformer to simulate and fine-tune complex models internally during\ninference (e.g., pre-trained language models). In particular, we introduce\ninnovative approximation techniques that allow a TinT model with less than 2\nbillion parameters to simulate and fine-tune a 125 million parameter\ntransformer model within a single forward pass. TinT accommodates many common\ntransformer variants and its design ideas also improve the efficiency of past\ninstantiations of simple models inside transformers. We conduct end-to-end\nexperiments to validate the internal fine-tuning procedure of TinT on various\nlanguage modeling and downstream tasks. For example, even with a limited\none-step budget, we observe TinT for a OPT-125M model improves performance by\n4-16% absolute on average compared to OPT-125M. These findings suggest that\nlarge pre-trained language models are capable of performing intricate\nsubroutines. To facilitate further work, a modular and extensible codebase for\nTinT is included.",
        "translated": "近年来的研究表明，大型预训练语言模型中的上下文学习(ICL)能够在推理过程中隐含地模拟和微调内部模型(例如线性或两层 MLP)。然而，这样的构造需要很大的内存开销，这使得更复杂的内部模型的模拟变得难以实现。在这项工作中，我们提出了一个有效的结构，变压器中的变压器(简称 TinT) ，它允许变压器在推理期间内部模拟和微调复杂模型(例如，预先训练的语言模型)。特别是，我们介绍了创新的近似技术，允许一个 TinT 模型少于20亿参数模拟和微调一个1.25亿参数变压器模型在一个单一的前向通过。TinT 容纳了许多常见的变压器变种，其设计思想也提高了过去变压器内部简单模型实例化的效率。我们进行端到端的实验来验证 TinT 在各种语言建模和下游任务中的内部微调过程。例如，即使有一个有限的一步预算，我们观察到 TinT 的 OPT-125M 型号的性能比 OPT-125M 绝对平均提高4-16% 。这些发现表明，大型预训练语言模型能够执行复杂的子程序。为了方便进一步的工作，还包括了 TinT 的模块化和可扩展的代码库。"
    },
    {
        "title": "Improving Language Plasticity via Pretraining with Active Forgetting",
        "url": "http://arxiv.org/abs/2307.01163v2",
        "pub_date": "2023-07-03",
        "summary": "Pretrained language models (PLMs) are today the primary model for natural\nlanguage processing. Despite their impressive downstream performance, it can be\ndifficult to apply PLMs to new languages, a barrier to making their\ncapabilities universally accessible. While prior work has shown it possible to\naddress this issue by learning a new embedding layer for the new language,\ndoing so is both data and compute inefficient. We propose to use an active\nforgetting mechanism during pretraining, as a simple way of creating PLMs that\ncan quickly adapt to new languages. Concretely, by resetting the embedding\nlayer every K updates during pretraining, we encourage the PLM to improve its\nability of learning new embeddings within a limited number of updates, similar\nto a meta-learning effect. Experiments with RoBERTa show that models pretrained\nwith our forgetting mechanism not only demonstrate faster convergence during\nlanguage adaptation but also outperform standard ones in a low-data regime,\nparticularly for languages that are distant from English.",
        "translated": "预训练语言模型(PLM)是当今自然语言处理的主要模型。尽管 PLM 在下游的表现令人印象深刻，但是将 PLM 应用到新的语言中可能会很困难，这是使其功能普遍可访问的一个障碍。虽然之前的工作已经表明，可以通过为新语言学习一个新的嵌入层来解决这个问题，但是这样做会导致数据和计算效率低下。我们建议在预训练期间使用主动遗忘机制，作为创建能够快速适应新语言的 PLM 的一种简单方法。具体来说，通过在预训练期间每次 K 更新时重置嵌入层，我们鼓励 PLM 在有限的更新次数内提高其学习新嵌入的能力，类似于元学习效应。用 RoBERTa 进行的实验表明，使用遗忘机制进行预训练的模型不仅在语言适应过程中表现出更快的收敛速度，而且在低数据量情况下的性能优于标准模型，特别是对于远离英语的语言。"
    },
    {
        "title": "SCITUNE: Aligning Large Language Models with Scientific Multimodal\n  Instructions",
        "url": "http://arxiv.org/abs/2307.01139v1",
        "pub_date": "2023-07-03",
        "summary": "Instruction finetuning is a popular paradigm to align large language models\n(LLM) with human intent. Despite its popularity, this idea is less explored in\nimproving the LLMs to align existing foundation models with scientific\ndisciplines, concepts and goals. In this work, we present SciTune as a tuning\nframework to improve the ability of LLMs to follow scientific multimodal\ninstructions. To test our methodology, we use a human-generated scientific\ninstruction tuning dataset and train a large multimodal model LLaMA-SciTune\nthat connects a vision encoder and LLM for science-focused visual and language\nunderstanding. In comparison to the models that are finetuned with machine\ngenerated data only, LLaMA-SciTune surpasses human performance on average and\nin many sub-categories on the ScienceQA benchmark.",
        "translated": "指令微调是将大型语言模型(LLM)与人类意图结合起来的一种流行范式。尽管这个想法很受欢迎，但是在改进 LLM 以使现有的基础模型与科学分支、概念和目标保持一致方面，这个想法却很少被探索。在这项工作中，我们将 SciTune 作为一个调优框架来提高 LLM 遵循科学的多模态指令的能力。为了测试我们的方法，我们使用了一个人工生成的科学指令调优数据集，并训练了一个大型多模态模型 LLaMA-SciTune，该模型将视觉编码器和 LLM 连接起来，用于以科学为中心的视觉和语言理解。与仅与机器生成的数据进行微调的模型相比，LLaMA-SciTune 在 ScienceQA 基准上的平均表现和许多子类别中都超过了人类的表现。"
    },
    {
        "title": "Exploring the In-context Learning Ability of Large Language Model for\n  Biomedical Concept Linking",
        "url": "http://arxiv.org/abs/2307.01137v1",
        "pub_date": "2023-07-03",
        "summary": "The biomedical field relies heavily on concept linking in various areas such\nas literature mining, graph alignment, information retrieval,\nquestion-answering, data, and knowledge integration. Although large language\nmodels (LLMs) have made significant strides in many natural language processing\ntasks, their effectiveness in biomedical concept mapping is yet to be fully\nexplored. This research investigates a method that exploits the in-context\nlearning (ICL) capabilities of large models for biomedical concept linking. The\nproposed approach adopts a two-stage retrieve-and-rank framework. Initially,\nbiomedical concepts are embedded using language models, and then embedding\nsimilarity is utilized to retrieve the top candidates. These candidates'\ncontextual information is subsequently incorporated into the prompt and\nprocessed by a large language model to re-rank the concepts. This approach\nachieved an accuracy of 90.% in BC5CDR disease entity normalization and 94.7%\nin chemical entity normalization, exhibiting a competitive performance relative\nto supervised learning methods. Further, it showed a significant improvement,\nwith an over 20-point absolute increase in F1 score on an oncology matching\ndataset. Extensive qualitative assessments were conducted, and the benefits and\npotential shortcomings of using large language models within the biomedical\ndomain were discussed. were discussed.",
        "translated": "生物医学领域在很大程度上依赖于各个领域的概念联系，如文献挖掘、图表对齐、信息检索、问答、数据和知识整合。尽管大语言模型(LLM)在自然语言处理任务中取得了长足的进步，但它们在生物医学概念映射中的有效性仍有待充分探索。本研究探讨一种利用大型生物医学概念连结模型的语境学习(ICL)能力的方法。该方法采用两阶段的检索和排序框架。首先利用语言模型对生物医学概念进行嵌入，然后利用嵌入相似性检索最优候选概念。这些候选者的上下文信息随后被整合到提示符中，并由一个大型语言模型进行处理，以重新排列这些概念。这种方法的精度达到了90。在 bc5CDR 疾病实体正常化和94.7% 在化学实体正常化，表现出相对于监督式学习方法的竞争性能。此外，它显示了一个显着的改善，与超过20点绝对增加 F1评分的肿瘤匹配数据集。进行了广泛的定性评估，并讨论了在生物医学领域使用大型语言模型的好处和潜在的缺点。讨论过。"
    },
    {
        "title": "Iterative Zero-Shot LLM Prompting for Knowledge Graph Construction",
        "url": "http://arxiv.org/abs/2307.01128v1",
        "pub_date": "2023-07-03",
        "summary": "In the current digitalization era, capturing and effectively representing\nknowledge is crucial in most real-world scenarios. In this context, knowledge\ngraphs represent a potent tool for retrieving and organizing a vast amount of\ninformation in a properly interconnected and interpretable structure. However,\ntheir generation is still challenging and often requires considerable human\neffort and domain expertise, hampering the scalability and flexibility across\ndifferent application fields. This paper proposes an innovative knowledge graph\ngeneration approach that leverages the potential of the latest generative large\nlanguage models, such as GPT-3.5, that can address all the main critical issues\nin knowledge graph building. The approach is conveyed in a pipeline that\ncomprises novel iterative zero-shot and external knowledge-agnostic strategies\nin the main stages of the generation process. Our unique manifold approach may\nencompass significant benefits to the scientific community. In particular, the\nmain contribution can be summarized by: (i) an innovative strategy for\niteratively prompting large language models to extract relevant components of\nthe final graph; (ii) a zero-shot strategy for each prompt, meaning that there\nis no need for providing examples for \"guiding\" the prompt result; (iii) a\nscalable solution, as the adoption of LLMs avoids the need for any external\nresources or human expertise. To assess the effectiveness of our proposed\nmodel, we performed experiments on a dataset that covered a specific domain. We\nclaim that our proposal is a suitable solution for scalable and versatile\nknowledge graph construction and may be applied to different and novel\ncontexts.",
        "translated": "在当前的数字化时代，获取和有效地表示知识在大多数现实世界的场景中是至关重要的。在这种情况下，知识图表是一种有力的工具，用于检索和组织在适当相互关联和可解释的结构中的大量信息。然而，它们的生成仍然具有挑战性，往往需要相当多的人力和领域专业知识，阻碍了不同应用领域的可伸缩性和灵活性。本文提出了一种创新的知识图生成方法，该方法利用了最新的生成大型语言模型(如 GPT-3.5)的潜力，可以解决知识图生成中的所有关键问题。该方法在生成过程的主要阶段由新的迭代零冲击和外部知识不可知策略组成的管道中传递。我们独特的方法可能包括对科学界的重大利益。特别是，主要贡献可以总结为: (i)一个创新的策略，反复提示大型语言模型提取最终图表的相关组件; (ii)每个提示的零拍策略，这意味着没有必要提供“指导”提示结果的例子; (iii)一个可伸缩的解决方案，因为采用 LLM 避免了任何外部资源或人力专业知识的需要。为了评估我们提出的模型的有效性，我们在一个覆盖特定领域的数据集上进行了实验。我们认为，我们的建议是一个适当的解决方案，可扩展和通用的知识图构建，可以应用于不同的和新颖的背景。"
    },
    {
        "title": "Analyzing Multiple-Choice Reading and Listening Comprehension Tests",
        "url": "http://arxiv.org/abs/2307.01076v1",
        "pub_date": "2023-07-03",
        "summary": "Multiple-choice reading and listening comprehension tests are an important\npart of language assessment. Content creators for standard educational tests\nneed to carefully curate questions that assess the comprehension abilities of\ncandidates taking the tests. However, recent work has shown that a large number\nof questions in general multiple-choice reading comprehension datasets can be\nanswered without comprehension, by leveraging world knowledge instead. This\nwork investigates how much of a contextual passage needs to be read in\nmultiple-choice reading based on conversation transcriptions and listening\ncomprehension tests to be able to work out the correct answer. We find that\nautomated reading comprehension systems can perform significantly better than\nrandom with partial or even no access to the context passage. These findings\noffer an approach for content creators to automatically capture the trade-off\nbetween comprehension and world knowledge required for their proposed\nquestions.",
        "translated": "多项选择题阅读和听力测试是语言测试的重要组成部分。标准教育测试的内容创建者需要仔细策划评估参加测试的考生理解能力的问题。然而，最近的研究表明，在一般的多项选择阅读理解数据集中，大量的问题可以在不理解的情况下通过利用世界知识来回答。本研究旨在探讨在基于会话记录和听力理解测试的多项选择性阅读中，需要阅读多少篇上下文文章才能得出正确答案。我们发现，自动阅读理解系统在部分甚至不能访问上下文的情况下，比随机系统的表现要好得多。这些发现为内容创建者提供了一种方法，可以自动捕捉他们提出的问题所需的理解和世界知识之间的权衡。"
    },
    {
        "title": "Estimating Post-OCR Denoising Complexity on Numerical Texts",
        "url": "http://arxiv.org/abs/2307.01020v1",
        "pub_date": "2023-07-03",
        "summary": "Post-OCR processing has significantly improved over the past few years.\nHowever, these have been primarily beneficial for texts consisting of natural,\nalphabetical words, as opposed to documents of numerical nature such as\ninvoices, payslips, medical certificates, etc. To evaluate the OCR\npost-processing difficulty of these datasets, we propose a method to estimate\nthe denoising complexity of a text and evaluate it on several datasets of\nvarying nature, and show that texts of numerical nature have a significant\ndisadvantage. We evaluate the estimated complexity ranking with respect to the\nerror rates of modern-day denoising approaches to show the validity of our\nestimator.",
        "translated": "在过去的几年中，光学字符识别后处理技术有了显著的改进。然而，这些主要是有益的文本组成的自然，字母词，而不是数字性质的文件，如发票，工资单，医疗证明等。为了评估这些数据集的 OCR 后处理难度，我们提出了一种估计文本去噪复杂度的方法，并在几个不同性质的数据集上进行了评估，结果表明数字性质的文本有明显的缺点。我们评估估计的复杂度排名相对于现代去噪方法的错误率，以证明我们的估计器的有效性。"
    },
    {
        "title": "Visual Instruction Tuning with Polite Flamingo",
        "url": "http://arxiv.org/abs/2307.01003v1",
        "pub_date": "2023-07-03",
        "summary": "Recent research has demonstrated that the multi-task fine-tuning of\nmulti-modal Large Language Models (LLMs) using an assortment of annotated\ndownstream vision-language datasets significantly enhances their performance.\nYet, during this process, a side effect, which we termed as the \"multi-modal\nalignment tax\", surfaces. This side effect negatively impacts the model's\nability to format responses appropriately -- for instance, its \"politeness\" --\ndue to the overly succinct and unformatted nature of raw annotations, resulting\nin reduced human preference. In this paper, we introduce Polite Flamingo, a\nmulti-modal response rewriter that transforms raw annotations into a more\nappealing, \"polite\" format. Polite Flamingo is trained to reconstruct\nhigh-quality responses from their automatically distorted counterparts and is\nsubsequently applied to a vast array of vision-language datasets for response\nrewriting. After rigorous filtering, we generate the PF-1M dataset and further\nvalidate its value by fine-tuning a multi-modal LLM with it. Combined with\nnovel methodologies including U-shaped multi-stage tuning and multi-turn\naugmentation, the resulting model, Clever Flamingo, demonstrates its advantages\nin both multi-modal understanding and response politeness according to\nautomated and human evaluations.",
        "translated": "最近的研究表明，使用注释的下游视觉语言数据集对多模态大语言模型(LLM)进行多任务微调显著提高了它们的性能。然而，在这个过程中，一个副作用，我们称为“多式联运税”，表面。由于原始注释过于简洁和未格式化的特性，这种副作用会对模型适当格式化响应的能力产生负面影响——例如，它的“礼貌”，从而导致人的偏好降低。在本文中，我们介绍 Polite Flamingo，它是一个多模态响应重写器，可以将原始注释转换成更吸引人的“礼貌”格式。礼貌的火烈鸟训练重建高质量的反应，从他们的自动扭曲对应，随后应用于大量的视觉语言数据集反应重写。经过严格的滤波，我们产生 PF-1M 数据集，并进一步验证其价值，微调多模态 LLM 与它。结合 U 型多阶段调谐和多转弯增强等新方法，通过自动评估和人工评估，得到的 Clever Flamingo 模型在多模态理解和回应礼貌两方面都具有优势。"
    },
    {
        "title": "Towards Suicide Prevention from Bipolar Disorder with Temporal\n  Symptom-Aware Multitask Learning",
        "url": "http://arxiv.org/abs/2307.00995v1",
        "pub_date": "2023-07-03",
        "summary": "Bipolar disorder (BD) is closely associated with an increased risk of\nsuicide. However, while the prior work has revealed valuable insight into\nunderstanding the behavior of BD patients on social media, little attention has\nbeen paid to developing a model that can predict the future suicidality of a BD\npatient. Therefore, this study proposes a multi-task learning model for\npredicting the future suicidality of BD patients by jointly learning current\nsymptoms. We build a novel BD dataset clinically validated by psychiatrists,\nincluding 14 years of posts on bipolar-related subreddits written by 818 BD\npatients, along with the annotations of future suicidality and BD symptoms. We\nalso suggest a temporal symptom-aware attention mechanism to determine which\nsymptoms are the most influential for predicting future suicidality over time\nthrough a sequence of BD posts. Our experiments demonstrate that the proposed\nmodel outperforms the state-of-the-art models in both BD symptom identification\nand future suicidality prediction tasks. In addition, the proposed temporal\nsymptom-aware attention provides interpretable attention weights, helping\nclinicians to apprehend BD patients more comprehensively and to provide timely\nintervention by tracking mental state progression.",
        "translated": "躁郁症(BD)与自杀风险增加密切相关。然而，尽管先前的工作已经揭示了了解 BD 患者在社交媒体上的行为的有价值的洞察力，但是很少有人注意开发一个能够预测 BD 患者未来自杀行为的模型。因此，本研究提出了一个多任务学习模型，通过联合学习当前症状来预测 BD 患者未来的自杀行为。我们建立了一个由精神科医生临床验证的新型 BD 数据集，包括818名 BD 患者撰写的14年双相相关子版块的帖子，以及未来自杀和 BD 症状的注释。我们还提出了一个时间症状意识的注意机制，以确定哪些症状是最有影响的预测未来自杀随着时间的推移，通过一系列的 BD 职位。我们的实验表明，所提出的模型在 BD 症状识别和未来自杀预测任务方面都优于最先进的模型。此外，提出的时间症状意识注意力提供了可解释的注意力权重，帮助临床医生更全面地理解 BD 患者，并提供及时的干预，跟踪精神状态的进展。"
    },
    {
        "title": "Challenges in Domain-Specific Abstractive Summarization and How to\n  Overcome them",
        "url": "http://arxiv.org/abs/2307.00963v1",
        "pub_date": "2023-07-03",
        "summary": "Large Language Models work quite well with general-purpose data and many\ntasks in Natural Language Processing. However, they show several limitations\nwhen used for a task such as domain-specific abstractive text summarization.\nThis paper identifies three of those limitations as research problems in the\ncontext of abstractive text summarization: 1) Quadratic complexity of\ntransformer-based models with respect to the input text length; 2) Model\nHallucination, which is a model's ability to generate factually incorrect text;\nand 3) Domain Shift, which happens when the distribution of the model's\ntraining and test corpus is not the same. Along with a discussion of the open\nresearch questions, this paper also provides an assessment of existing\nstate-of-the-art techniques relevant to domain-specific text summarization to\naddress the research gaps.",
        "translated": "大型语言模型可以很好地处理通用数据和自然语言处理中的许多任务。但是，当用于特定于领域的抽象文本摘要等任务时，它们显示出一些限制。本文将其中的三个局限性作为抽象文本摘要的研究问题: 1)基于转换器的模型相对于输入文本长度的二次复杂性; 2)模型幻觉，即模型产生事实上不正确的文本的能力; 3)领域移位，当模型的训练和测试语料的分布不同时发生。在讨论开放性研究问题的同时，本文还评估了与特定领域文本摘要相关的现有最新技术，以弥补研究差距。"
    },
    {
        "title": "Improving Address Matching using Siamese Transformer Networks",
        "url": "http://arxiv.org/abs/2307.02300v1",
        "pub_date": "2023-07-05",
        "summary": "Matching addresses is a critical task for companies and post offices involved\nin the processing and delivery of packages. The ramifications of incorrectly\ndelivering a package to the wrong recipient are numerous, ranging from harm to\nthe company's reputation to economic and environmental costs. This research\nintroduces a deep learning-based model designed to increase the efficiency of\naddress matching for Portuguese addresses. The model comprises two parts: (i) a\nbi-encoder, which is fine-tuned to create meaningful embeddings of Portuguese\npostal addresses, utilized to retrieve the top 10 likely matches of the\nun-normalized target address from a normalized database, and (ii) a\ncross-encoder, which is fine-tuned to accurately rerank the 10 addresses\nobtained by the bi-encoder. The model has been tested on a real-case scenario\nof Portuguese addresses and exhibits a high degree of accuracy, exceeding 95%\nat the door level. When utilized with GPU computations, the inference speed is\nabout 4.5 times quicker than other traditional approaches such as BM25. An\nimplementation of this system in a real-world scenario would substantially\nincrease the effectiveness of the distribution process. Such an implementation\nis currently under investigation.",
        "translated": "配对地址是处理和交付包裹的公司和邮局的一项关键任务。错误地向错误的收件人发送包裹的后果是多方面的，从对公司声誉的损害到经济和环境成本。本研究引入了一个基于深度学习的模型，旨在提高葡萄牙语地址匹配的效率。该模型由两部分组成: (i)双编码器，其经过微调以创建有意义的葡萄牙邮政地址嵌入，用于从标准化数据库中检索非标准化目标地址的前10个可能匹配; (ii)交叉编码器，其经过微调以准确地重新排列双编码器获得的10个地址。该模型已经在葡萄牙地址的实际情况下进行了测试，并显示出高度的准确性，在门级超过95% 。当使用 GPU 计算时，推理速度比其他传统方法如 BM25快约4.5倍。在现实世界中实施这一系统将大大提高分配过程的有效性。这样的实施目前正在调查之中。"
    },
    {
        "title": "An Equivalent Graph Reconstruction Model and its Application in\n  Recommendation Prediction",
        "url": "http://arxiv.org/abs/2307.02183v1",
        "pub_date": "2023-07-05",
        "summary": "Recommendation algorithm plays an important role in recommendation system\n(RS), which predicts users' interests and preferences for some given items\nbased on their known information. Recently, a recommendation algorithm based on\nthe graph Laplacian regularization was proposed, which treats the prediction\nproblem of the recommendation system as a reconstruction issue of small samples\nof the graph signal under the same graph model. Such a technique takes into\naccount both known and unknown labeled samples information, thereby obtaining\ngood prediction accuracy. However, when the data size is large, solving the\nreconstruction model is computationally expensive even with an approximate\nstrategy. In this paper, we propose an equivalent reconstruction model that can\nbe solved exactly with extremely low computational cost. Finally, a final\nprediction algorithm is proposed. We find in the experiments that the proposed\nmethod significantly reduces the computational cost while maintaining a good\nprediction accuracy.",
        "translated": "推荐算法在推荐系统(RS)中起着重要作用，它根据用户的已知信息预测用户对某一特定项目的兴趣和偏好。最近，提出了一种基于图拉普拉斯正则化的推荐算法，将推荐系统的预测问题看作是同一图模型下图信号小样本的重构问题。这种方法同时考虑了已知和未知的标记样本信息，从而获得了较好的预测精度。然而，当数据量较大时，即使采用近似策略，求解重建模型的计算量也很大。在本文中，我们提出了一个等效重建模型，可以用极低的计算成本精确求解。最后，提出了最终的预测算法。实验结果表明，该方法在保持较高预测精度的同时，大大降低了计算量。"
    },
    {
        "title": "Generative Job Recommendations with Large Language Model",
        "url": "http://arxiv.org/abs/2307.02157v1",
        "pub_date": "2023-07-05",
        "summary": "The rapid development of online recruitment services has encouraged the\nutilization of recommender systems to streamline the job seeking process.\nPredominantly, current job recommendations deploy either collaborative\nfiltering or person-job matching strategies. However, these models tend to\noperate as \"black-box\" systems and lack the capacity to offer explainable\nguidance to job seekers. Moreover, conventional matching-based recommendation\nmethods are limited to retrieving and ranking existing jobs in the database,\nrestricting their potential as comprehensive career AI advisors. To this end,\nhere we present GIRL (GeneratIve job Recommendation based on Large language\nmodels), a novel approach inspired by recent advancements in the field of Large\nLanguage Models (LLMs). We initially employ a Supervised Fine-Tuning (SFT)\nstrategy to instruct the LLM-based generator in crafting suitable Job\nDescriptions (JDs) based on the Curriculum Vitae (CV) of a job seeker.\nMoreover, we propose to train a model which can evaluate the matching degree\nbetween CVs and JDs as a reward model, and we use Proximal Policy Optimization\n(PPO)-based Reinforcement Learning (RL) method to further fine-tine the\ngenerator. This aligns the generator with recruiter feedback, tailoring the\noutput to better meet employer preferences. In particular, GIRL serves as a job\nseeker-centric generative model, providing job suggestions without the need of\na candidate set. This capability also enhances the performance of existing job\nrecommendation models by supplementing job seeking features with generated\ncontent. With extensive experiments on a large-scale real-world dataset, we\ndemonstrate the substantial effectiveness of our approach. We believe that GIRL\nintroduces a paradigm-shifting approach to job recommendation systems,\nfostering a more personalized and comprehensive job-seeking experience.",
        "translated": "在线征聘服务的迅速发展鼓励利用推荐系统精简求职过程。当前的工作推荐主要采用协同过滤或人员-工作匹配策略。然而，这些模式往往作为“黑箱”系统运作，缺乏能力提供可解释的指导，以求职者。此外，传统的基于匹配的推荐方法仅限于检索和排序数据库中现有的工作，限制了它们作为综合职业人工智能顾问的潜力。为此，我们在这里介绍 GIRL (基于大型语言模型的 GeneratIve 工作推荐) ，这是一种受到大型语言模型(LLM)领域最新进展启发的新方法。我们最初采用监督微调(SFT)策略来指导基于 LLM 的生成器根据求职者的简历(CV)制定合适的工作描述(JDs)。此外，我们建议训练一个模型来评估简历和法律顾问之间的匹配程度作为报酬模型，并且我们使用基于最近策略优化(PPO)的强化学习(RL)方法来进一步细化生成器。这将使生成器与招聘人员的反馈保持一致，调整输出以更好地满足雇主的偏好。特别是，女孩是一个以求职者为中心的生成模型，提供工作建议而不需要候选人集。这一能力还通过用生成的内容补充求职特征，提高了现有职位推荐模式的绩效。通过在大规模真实世界数据集上的大量实验，我们证明了该方法的实质性有效性。我们认为，GIRL 在工作推荐系统中引入了一种范式转换的方法，培养了一种更加个性化和全面的求职体验。"
    },
    {
        "title": "Recommendation Unlearning via Influence Function",
        "url": "http://arxiv.org/abs/2307.02147v1",
        "pub_date": "2023-07-05",
        "summary": "Recommendation unlearning is an emerging task to serve users for erasing\nunusable data (e.g., some historical behaviors) from a well-trained recommender\nmodel. Existing methods process unlearning requests by fully or partially\nretraining the model after removing the unusable data. However, these methods\nare impractical due to the high computation cost of full retraining and the\nhighly possible performance damage of partial training. In this light, a\ndesired recommendation unlearning method should obtain a similar model as full\nretraining in a more efficient manner, i.e., achieving complete, efficient and\ninnocuous unlearning. In this work, we propose an Influence Function-based\nRecommendation Unlearning (IFRU) framework, which efficiently updates the model\nwithout retraining by estimating the influence of the unusable data on the\nmodel via the influence function. In the light that recent recommender models\nuse historical data for both the constructions of the optimization loss and the\ncomputational graph (e.g., neighborhood aggregation), IFRU jointly estimates\nthe direct influence of unusable data on optimization loss and the spillover\ninfluence on the computational graph to pursue complete unlearning.\nFurthermore, we propose an importance-based pruning algorithm to reduce the\ncost of the influence function. IFRU is innocuous and applicable to mainstream\ndifferentiable models. Extensive experiments demonstrate that IFRU achieves\nmore than250times acceleration compared to retraining-based methods with\nrecommendation performance comparable to full retraining.",
        "translated": "推荐取消学习是一个新兴的任务，它为用户从训练有素的推荐模型中删除不可用的数据(例如，一些历史行为)提供服务。现有方法在删除不可用数据之后，通过完全或部分重新训练模型来处理忘记请求。然而，由于完全再训练的计算量大，部分训练极有可能造成性能损失，这些方法都是不切实际的。因此，一个理想的推荐忘却方法应该获得一个类似于以一种更有效的方式完全再训练的模型，即，实现完全的、有效的和无害的忘却。在这项工作中，我们提出了一个基于影响函数的推荐去学习(IFRU)框架，它通过估计不可用数据对模型的影响来有效地更新模型而不需要再训练。鉴于最近的推荐模型使用历史数据构造优化损失和计算图(例如，邻域聚合) ，IFRU 联合估计不可用数据对优化损失的直接影响和溢出对计算图的影响，以追求完全忘却。此外，我们还提出了一种基于重要性的剪枝算法来降低影响函数的代价。IFRU 是无害的，适用于主流可微模型。大量的实验表明，与再培训方法相比，IFRU 实现了250倍以上的加速，推荐性能与完全再培训相当。"
    },
    {
        "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
        "url": "http://arxiv.org/abs/2307.02046v1",
        "pub_date": "2023-07-05",
        "summary": "With the prosperity of e-commerce and web applications, Recommender Systems\n(RecSys) have become an important component of our daily life, providing\npersonalized suggestions that cater to user preferences. While Deep Neural\nNetworks (DNNs) have made significant advancements in enhancing recommender\nsystems by modeling user-item interactions and incorporating textual side\ninformation, DNN-based methods still face limitations, such as difficulties in\nunderstanding users' interests and capturing textual side information,\ninabilities in generalizing to various recommendation scenarios and reasoning\non their predictions, etc. Meanwhile, the emergence of Large Language Models\n(LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), due to their\nremarkable abilities in fundamental responsibilities of language understanding\nand generation, as well as impressive generalization and reasoning\ncapabilities. As a result, recent studies have attempted to harness the power\nof LLMs to enhance recommender systems. Given the rapid evolution of this\nresearch direction in recommender systems, there is a pressing need for a\nsystematic overview that summarizes existing LLM-empowered recommender systems,\nto provide researchers in relevant fields with an in-depth understanding.\nTherefore, in this paper, we conduct a comprehensive review of LLM-empowered\nrecommender systems from various aspects including Pre-training, Fine-tuning,\nand Prompting. More specifically, we first introduce representative methods to\nharness the power of LLMs (as a feature encoder) for learning representations\nof users and items. Then, we review recent techniques of LLMs for enhancing\nrecommender systems from three paradigms, namely pre-training, fine-tuning, and\nprompting. Finally, we comprehensively discuss future directions in this\nemerging field.",
        "translated": "随着电子商务和网络应用程序的繁荣，推荐系统(RecSys)已成为我们日常生活的重要组成部分，提供个性化的建议，以迎合用户的喜好。虽然深度神经网络(DNN)通过建立用户-项目交互模型和结合文本侧信息在增强推荐系统方面取得了重大进展，但是基于 DNN 的方法仍然面临着局限性，如难以理解用户的兴趣和获取文本侧信息，无法推广到各种推荐场景和推理他们的预测等。同时，大语言模型(LLM)的出现，如 ChatGPT 和 GPT4的出现，使自然语言处理(NLP)和人工智能(AI)领域发生了革命性的变化，因为它们在语言理解和生成的基本责任方面具有非凡的能力，以及令人印象深刻的泛化和推理能力。因此，最近的研究试图利用 LLM 的力量来增强推荐系统。鉴于这一研究方向在推荐系统中的快速发展，迫切需要一个系统的概述，总结现有的 LLM 授权的推荐系统，为相关领域的研究人员提供了深入的了解。因此，本文从预训练、微调和激励三个方面对 LLM 授权的推荐系统进行了全面的综述。更具体地说，我们首先介绍一些代表性的方法来利用 LLM (作为一种特性编码器)的强大功能来学习用户和项目的表示。然后，我们从三个范例，即预训练、微调和激励，回顾了 LLM 最近用于增强推荐系统的技术。最后，我们全面讨论了这一新兴领域的未来发展方向。"
    },
    {
        "title": "LongNet: Scaling Transformers to 1,000,000,000 Tokens",
        "url": "http://arxiv.org/abs/2307.02486v1",
        "pub_date": "2023-07-05",
        "summary": "Scaling sequence length has become a critical demand in the era of large\nlanguage models. However, existing methods struggle with either computational\ncomplexity or model expressivity, rendering the maximum sequence length\nrestricted. In this work, we introduce LongNet, a Transformer variant that can\nscale sequence length to more than 1 billion tokens, without sacrificing the\nperformance on shorter sequences. Specifically, we propose dilated attention,\nwhich expands the attentive field exponentially as the distance grows. LongNet\nhas significant advantages: 1) it has a linear computation complexity and a\nlogarithm dependency between tokens; 2) it can be served as a distributed\ntrainer for extremely long sequences; 3) its dilated attention is a drop-in\nreplacement for standard attention, which can be seamlessly integrated with the\nexisting Transformer-based optimization. Experiments results demonstrate that\nLongNet yields strong performance on both long-sequence modeling and general\nlanguage tasks. Our work opens up new possibilities for modeling very long\nsequences, e.g., treating a whole corpus or even the entire Internet as a\nsequence.",
        "translated": "缩放序列长度已经成为大型语言模型时代的一个关键要求。然而，现有的方法要么计算复杂度，要么模型表现力，使最大序列长度受到限制。在这项工作中，我们引入了 LongNet，这是一个 Transformer 变体，它可以将序列长度扩展到超过10亿个令牌，而不会牺牲较短序列的性能。具体来说，我们提出了扩张注意，随着距离的增长，扩张注意领域呈指数级增长。LongNet 具有显著的优势: 1)它具有线性计算复杂度和令牌之间的对数依赖性; 2)它可以作为超长序列的分布式训练器; 3)它的分散注意力是标准注意力的替代品，可以与现有的基于 Transformer 的优化无缝集成。实验结果表明，LongNet 在长序列建模和一般语言任务上都有很好的性能。我们的工作为建立非常长的序列模型开辟了新的可能性，例如，将整个语料库甚至整个互联网作为一个序列处理。"
    },
    {
        "title": "Building Cooperative Embodied Agents Modularly with Large Language\n  Models",
        "url": "http://arxiv.org/abs/2307.02485v1",
        "pub_date": "2023-07-05",
        "summary": "Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website https://vis-www.cs.umass.edu/Co-LLM-Agents/.",
        "translated": "大型语言模型(LLM)在不同领域的单代理嵌入式任务中展示了令人印象深刻的规划能力。然而，它们在多代理协作中的计划和通信能力仍然不清楚，尽管这些是智能体化代理的关键技能。在本文中，我们提出了一个新的框架，利用 LLM 的多智能体协作和测试它在各种具体的环境。我们的框架使得具象化代理能够计划、沟通并与其他具象化代理或人类合作，有效地完成长期任务。我们展示了最近的 LLM，例如 GPT-4，可以超越强大的基于规划的方法，并且使用我们的框架展示出紧急的有效通信，而不需要微调或少镜头提示。我们还发现，使用自然语言进行交流的基于 LLM 的代理可以获得更多的信任，并且与人类进行更有效的合作。我们的研究强调了 LLM 在体现人工智能方面的潜力，并为未来多智能体协作的研究奠定了基础。视频可以在项目网站的 https://vis-www.cs.umass.edu/co-llm-agents/找到。"
    },
    {
        "title": "Reasoning or Reciting? Exploring the Capabilities and Limitations of\n  Language Models Through Counterfactual Tasks",
        "url": "http://arxiv.org/abs/2307.02477v1",
        "pub_date": "2023-07-05",
        "summary": "The impressive performance of recent language models across a wide range of\ntasks suggests that they possess a degree of abstract reasoning skills. Are\nthese skills general and transferable, or specialized to specific tasks seen\nduring pretraining? To disentangle these effects, we propose an evaluation\nframework based on \"counterfactual\" task variants that deviate from the default\nassumptions underlying standard tasks. Across a suite of 11 tasks, we observe\nnontrivial performance on the counterfactual variants, but nevertheless find\nthat performance substantially and consistently degrades compared to the\ndefault conditions. This suggests that while current LMs may possess abstract\ntask-solving skills to a degree, they often also rely on narrow,\nnon-transferable procedures for task-solving. These results motivate a more\ncareful interpretation of language model performance that teases apart these\naspects of behavior.",
        "translated": "最近的语言模型在广泛的任务中的令人印象深刻的表现表明，它们拥有一定程度的抽象推理技能。这些技能是通用的和可转移的，还是专门用于培训前的特定任务？为了理清这些影响，我们提出了一个基于“反事实”任务变量的评估框架，它偏离了标准任务的默认假设。在一组11个任务中，我们观察到反事实变量的非平凡性能，但是仍然发现性能与默认条件相比大幅度且持续地下降。这表明，虽然目前的 LM 可能在一定程度上拥有抽象的任务解决技能，但他们也常常依赖于狭窄的，不可转移的任务解决程序。这些结果促使人们对语言模型的表现进行更仔细的解释，从而分离出行为的这些方面。"
    },
    {
        "title": "Deductive Additivity for Planning of Natural Language Proofs",
        "url": "http://arxiv.org/abs/2307.02472v2",
        "pub_date": "2023-07-05",
        "summary": "Current natural language systems designed for multi-step claim validation\ntypically operate in two phases: retrieve a set of relevant premise statements\nusing heuristics (planning), then generate novel conclusions from those\nstatements using a large language model (deduction). The planning step often\nrequires expensive Transformer operations and does not scale to arbitrary\nnumbers of premise statements. In this paper, we investigate whether an\nefficient planning heuristic is possible via embedding spaces compatible with\ndeductive reasoning. Specifically, we evaluate whether embedding spaces exhibit\na property we call deductive additivity: the sum of premise statement\nembeddings should be close to embeddings of conclusions based on those\npremises. We explore multiple sources of off-the-shelf dense embeddings in\naddition to fine-tuned embeddings from GPT3 and sparse embeddings from BM25. We\nstudy embedding models both intrinsically, evaluating whether the property of\ndeductive additivity holds, and extrinsically, using them to assist planning in\nnatural language proof generation. Lastly, we create a dataset, Single-Step\nReasoning Contrast (SSRC), to further probe performance on various reasoning\ntypes. Our findings suggest that while standard embedding methods frequently\nembed conclusions near the sums of their premises, they fall short of being\neffective heuristics and lack the ability to model certain categories of\nreasoning.",
        "translated": "目前设计用于多步索赔验证的自然语言系统通常分为两个阶段: 使用启发式(规划)检索一组相关的前提陈述，然后使用大型语言模型(演绎)从这些陈述中生成新的结论。规划步骤通常需要开销很大的 Transformer 操作，并且不能扩展到任意数量的前提语句。在本文中，我们研究是否可以通过嵌入与演绎推理兼容的空间来实现有效的规划启发式。具体来说，我们评估嵌入空间是否具有一个我们称之为演绎可加性的性质: 前提陈述嵌入的总和应该接近于基于这些前提的结论的嵌入。除了来自 GPT3的微调嵌入和来自 BM25的稀疏嵌入，我们还探索了多种现成的稠密嵌入来源。我们研究嵌入模型的内在价值，评估演绎可加性的性质是否成立，以及外在地使用它们来协助规划自然语言的证明生成。最后，我们创建一个数据集，单步推理对比度(SSRC) ，以进一步探讨各种推理类型的性能。我们的研究结果表明，虽然标准的嵌入方法经常嵌入结论附近的前提总和，他们不是有效的启发式和缺乏能力建模某些类别的推理。"
    },
    {
        "title": "What Matters in Training a GPT4-Style Language Model with Multimodal\n  Inputs?",
        "url": "http://arxiv.org/abs/2307.02469v1",
        "pub_date": "2023-07-05",
        "summary": "Recent advancements in Large Language Models (LLMs) such as GPT4 have\ndisplayed exceptional multi-modal capabilities in following open-ended\ninstructions given images. However, the performance of these models heavily\nrelies on design choices such as network structures, training data, and\ntraining strategies, and these choices have not been extensively discussed in\nthe literature, making it difficult to quantify progress in this field. To\naddress this issue, this paper presents a systematic and comprehensive study,\nquantitatively and qualitatively, on training such models. We implement over 20\nvariants with controlled settings. Concretely, for network structures, we\ncompare different LLM backbones and model designs. For training data, we\ninvestigate the impact of data and sampling strategies. For instructions, we\nexplore the influence of diversified prompts on the instruction-following\nability of the trained models. For benchmarks, we contribute the first, to our\nbest knowledge, comprehensive evaluation set including both image and video\ntasks through crowd-sourcing. Based on our findings, we present Lynx, which\nperforms the most accurate multi-modal understanding while keeping the best\nmulti-modal generation ability compared to existing open-sourced GPT4-style\nmodels.",
        "translated": "最近在大型语言模型(LLM)方面的进展，例如 GPT4，已经显示了在给定图像的开放式指令下的异常多模态功能。然而，这些模型的性能很大程度上依赖于网络结构、训练数据和训练策略等设计选择，而这些选择在文献中没有得到广泛的讨论，因此难以量化该领域的进展。为了解决这一问题，本文从定量和定性两个方面对此类模型的训练进行了系统、全面的研究。我们实现了超过20种具有可控设置的变体。具体地，对于网络结构，我们比较了不同的 LLM 骨架和模型设计。对于训练数据，我们调查数据和抽样策略的影响。在教学方面，我们探讨了不同的提示对受训模型教学跟踪能力的影响。对于基准测试，我们提供了第一个，我们最好的知识，全面的评估集，包括图像和视频的任务，通过众包。基于我们的研究结果，我们提出 Lynx，执行最准确的多模态理解，同时保持最好的多模态生成能力相比，现有的开源 GPT4风格的模型。"
    },
    {
        "title": "An Exploratory Literature Study on Sharing and Energy Use of Language\n  Models for Source Code",
        "url": "http://arxiv.org/abs/2307.02443v1",
        "pub_date": "2023-07-05",
        "summary": "Large language models trained on source code can support a variety of\nsoftware development tasks, such as code recommendation and program repair.\nLarge amounts of data for training such models benefit the models' performance.\nHowever, the size of the data and models results in long training times and\nhigh energy consumption. While publishing source code allows for replicability,\nusers need to repeat the expensive training process if models are not shared.\nThe main goal of the study is to investigate if publications that trained\nlanguage models for software engineering (SE) tasks share source code and\ntrained artifacts. The second goal is to analyze the transparency on training\nenergy usage. We perform a snowballing-based literature search to find\npublications on language models for source code, and analyze their reusability\nfrom a sustainability standpoint.\n  From 494 unique publications, we identified 293 relevant publications that\nuse language models to address code-related tasks. Among them, 27% (79 out of\n293) make artifacts available for reuse. This can be in the form of tools or\nIDE plugins designed for specific tasks or task-agnostic models that can be\nfine-tuned for a variety of downstream tasks. Moreover, we collect insights on\nthe hardware used for model training, as well as training time, which together\ndetermine the energy consumption of the development process. We find that there\nare deficiencies in the sharing of information and artifacts for current\nstudies on source code models for software engineering tasks, with 40% of the\nsurveyed papers not sharing source code or trained artifacts. We recommend the\nsharing of source code as well as trained artifacts, to enable sustainable\nreproducibility. Moreover, comprehensive information on training times and\nhardware configurations should be shared for transparency on a model's carbon\nfootprint.",
        "translated": "对源代码进行培训的大型语言模型可以支持各种软件开发任务，例如代码推荐和程序修复。训练这些模型的大量数据有利于模型的性能。然而，数据和模型的大小导致训练时间长和能源消耗高。虽然发布源代码允许可复制性，但是如果不共享模型，用户需要重复代价高昂的培训过程。该研究的主要目的是调查软件工程(SE)任务的训练语言模型的出版物是否共享源代码和训练过的工件。第二个目标是分析培训能源使用的透明度。我们进行了一个滚雪球式的文献检索，寻找关于源代码语言模型的出版物，并从可持续性的角度分析它们的可重用性。从494个独特的出版物中，我们确定了293个使用语言模型处理与代码相关任务的相关出版物。其中，27% (293个中的79个)使工件可以重用。这可以采用为特定任务设计的工具或 IDE 插件的形式，或者可以针对各种下游任务进行微调的任务无关模型。此外，我们收集了用于模型训练的硬件以及训练时间的见解，这些共同决定了开发过程的能源消耗。我们发现，在软件工程任务的源代码模型的当前研究中，信息和工件的共享存在缺陷，40% 的被调查论文不共享源代码或受过训练的工件。我们建议共享源代码以及经过培训的工件，以实现可持续的可重复性。此外，培训时间和硬件配置的全面信息应该共享，以保证模型碳足印的透明度。"
    },
    {
        "title": "Exploring Continual Learning for Code Generation Models",
        "url": "http://arxiv.org/abs/2307.02435v1",
        "pub_date": "2023-07-05",
        "summary": "Large-scale code generation models such as Codex and CodeT5 have achieved\nimpressive performance. However, libraries are upgraded or deprecated very\nfrequently and re-training large-scale language models is computationally\nexpensive. Therefore, Continual Learning (CL) is an important aspect that\nremains underexplored in the code domain. In this paper, we introduce a\nbenchmark called CodeTask-CL that covers a wide range of tasks, including code\ngeneration, translation, summarization, and refinement, with different input\nand output programming languages. Next, on our CodeTask-CL benchmark, we\ncompare popular CL techniques from NLP and Vision domains. We find that\neffective methods like Prompt Pooling (PP) suffer from catastrophic forgetting\ndue to the unstable training of the prompt selection mechanism caused by stark\ndistribution shifts in coding tasks. We address this issue with our proposed\nmethod, Prompt Pooling with Teacher Forcing (PP-TF), that stabilizes training\nby enforcing constraints on the prompt selection mechanism and leads to a\n21.54% improvement over Prompt Pooling. Along with the benchmark, we establish\na training pipeline that can be used for CL on code models, which we believe\ncan motivate further development of CL methods for code models. Our code is\navailable at https://github.com/amazon-science/codetaskcl-pptf",
        "translated": "Codex 和 CodeT5等大规模代码生成模型已经取得了令人印象深刻的性能。然而，库的升级或弃用非常频繁，重新训练大规模的语言模型在计算上是昂贵的。因此，持续学习(CL)是一个重要的方面，在代码域中仍然没有得到充分的研究。在本文中，我们介绍了一个名为 CodeTask-CL 的基准测试，它涵盖了广泛的任务，包括代码生成、翻译、摘要和细化，使用不同的输入和输出编程语言。接下来，在我们的 CodeTask-CL 基准上，我们比较了来自 NLP 和 Vision 域的流行 CL 技术。我们发现，由于编码任务中的严格分布变化导致了对提示选择机制的不稳定训练，使得像提示合用(PP)这样的有效方法遭受了灾难性遗忘。我们通过我们提出的方法来解决这个问题，即通过对及时选择机制实施约束来稳定培训，并导致比及时汇集提高21.54% 。与基准一起，我们建立了一个可以用于代码模型上 CL 的培训管道，我们相信这可以促进代码模型 CL 方法的进一步开发。我们的代码可以在 https://github.com/amazon-science/codetaskcl-pptf 找到"
    },
    {
        "title": "Won't Get Fooled Again: Answering Questions with False Premises",
        "url": "http://arxiv.org/abs/2307.02394v1",
        "pub_date": "2023-07-05",
        "summary": "Pre-trained language models (PLMs) have shown unprecedented potential in\nvarious fields, especially as the backbones for question-answering (QA)\nsystems. However, they tend to be easily deceived by tricky questions such as\n\"How many eyes does the sun have?\". Such frailties of PLMs often allude to the\nlack of knowledge within them. In this paper, we find that the PLMs already\npossess the knowledge required to rebut such questions, and the key is how to\nactivate the knowledge. To systematize this observation, we investigate the\nPLMs' responses to one kind of tricky questions, i.e., the false premises\nquestions (FPQs). We annotate a FalseQA dataset containing 2365 human-written\nFPQs, with the corresponding explanations for the false premises and the\nrevised true premise questions. Using FalseQA, we discover that PLMs are\ncapable of discriminating FPQs by fine-tuning on moderate numbers (e.g., 256)\nof examples. PLMs also generate reasonable explanations for the false premise,\nwhich serve as rebuttals. Further replaying a few general questions during\ntraining allows PLMs to excel on FPQs and general questions simultaneously. Our\nwork suggests that once the rebuttal ability is stimulated, knowledge inside\nthe PLMs can be effectively utilized to handle FPQs, which incentivizes the\nresearch on PLM-based QA systems.",
        "translated": "预训练语言模型(PLM)在各个领域显示出前所未有的潜力，尤其是作为问答系统的骨干。然而，他们往往很容易被一些棘手的问题所欺骗，比如“太阳有多少只眼睛?”.PLM 的这些弱点往往暗示着它们缺乏知识。在本文中，我们发现 PLM 已经具备了反驳这些问题所需要的知识，关键是如何激活这些知识。为了系统化这一观察，我们调查了 PLM 对一类棘手问题的回答，即错误前提问题(FPQ)。我们注释了一个包含2365个人写的 FPQ 的 FalseQA 数据集，并对虚假前提和修订后的真实前提问题进行了相应的解释。通过使用 FalseQA，我们发现 PLM 能够通过对中等数量(例如256)的示例进行微调来区分 FPQ。PLM 还对错误的前提提供合理的解释，作为反驳。在培训期间进一步重复一些常规问题可以让 PLM 同时在 FPQ 和常规问题上表现出色。我们的工作表明，一旦反驳能力得到激发，PLM 内部的知识可以被有效地利用来处理 FPQ，这激励了基于 PLM 的 QA 系统的研究。"
    },
    {
        "title": "Causal Discovery with Language Models as Imperfect Experts",
        "url": "http://arxiv.org/abs/2307.02390v1",
        "pub_date": "2023-07-05",
        "summary": "Understanding the causal relationships that underlie a system is a\nfundamental prerequisite to accurate decision-making. In this work, we explore\nhow expert knowledge can be used to improve the data-driven identification of\ncausal graphs, beyond Markov equivalence classes. In doing so, we consider a\nsetting where we can query an expert about the orientation of causal\nrelationships between variables, but where the expert may provide erroneous\ninformation. We propose strategies for amending such expert knowledge based on\nconsistency properties, e.g., acyclicity and conditional independencies in the\nequivalence class. We then report a case study, on real data, where a large\nlanguage model is used as an imperfect expert.",
        "translated": "理解系统的因果关系是做出准确决策的基本前提。在这项工作中，我们探讨了如何利用专家知识，以改善数据驱动的因果图识别，超越马尔可夫等价类。在这样做的时候，我们考虑一个设置，在这个设置中，我们可以询问专家关于变量之间因果关系的方向，但是专家可能提供错误的信息。我们根据一致性属性，例如等价类中的非周期性和条件独立性，提出修正这类专家知识的策略。然后，我们报告一个案例研究，在真实的数据，其中一个大的语言模型被用作一个不完美的专家。"
    },
    {
        "title": "To be or not to be: a translation reception study of a literary text\n  translated into Dutch and Catalan using machine translation",
        "url": "http://arxiv.org/abs/2307.02358v1",
        "pub_date": "2023-07-05",
        "summary": "This article presents the results of a study involving the reception of a\nfictional story by Kurt Vonnegut translated from English into Catalan and Dutch\nin three conditions: machine-translated (MT), post-edited (PE) and translated\nfrom scratch (HT). 223 participants were recruited who rated the reading\nconditions using three scales: Narrative Engagement, Enjoyment and Translation\nReception. The results show that HT presented a higher engagement, enjoyment\nand translation reception in Catalan if compared to PE and MT. However, the\nDutch readers show higher scores in PE than in both HT and MT, and the highest\nengagement and enjoyments scores are reported when reading the original English\nversion. We hypothesize that when reading a fictional story in translation, not\nonly the condition and the quality of the translations is key to understand its\nreception, but also the participants reading patterns, reading language, and,\nperhaps language status in their own societies.",
        "translated": "本文介绍了库尔特 · 冯内古特(Kurt Vonnegut)的小说在机器翻译(MT)、后期编辑(PE)和从头翻译(HT)三种情况下对加泰罗尼亚语和荷兰语的接受研究结果。本研究选取223名参与者，采用叙事投入、享受和翻译接受三个量表对阅读条件进行评分。结果显示，与 PE 和 MT 相比，HT 在加泰罗尼亚语中表现出更高的参与度，享受度和翻译接受度。然而，荷兰读者在 PE 中的分数高于 HT 和 MT，并且在阅读原始英语版本时报告了最高的参与度和享受度分数。我们假设，当阅读翻译中的虚构故事时，不仅翻译的条件和质量是理解其接受的关键，而且参与者阅读模式，阅读语言，也许还有他们自己社会中的语言地位。"
    },
    {
        "title": "MultiVENT: Multilingual Videos of Events with Aligned Natural Text",
        "url": "http://arxiv.org/abs/2307.03153v1",
        "pub_date": "2023-07-06",
        "summary": "Everyday news coverage has shifted from traditional broadcasts towards a wide\nrange of presentation formats such as first-hand, unedited video footage.\nDatasets that reflect the diverse array of multimodal, multilingual news\nsources available online could be used to teach models to benefit from this\nshift, but existing news video datasets focus on traditional news broadcasts\nproduced for English-speaking audiences. We address this limitation by\nconstructing MultiVENT, a dataset of multilingual, event-centric videos\ngrounded in text documents across five target languages. MultiVENT includes\nboth news broadcast videos and non-professional event footage, which we use to\nanalyze the state of online news videos and how they can be leveraged to build\nrobust, factually accurate models. Finally, we provide a model for complex,\nmultilingual video retrieval to serve as a baseline for information retrieval\nusing MultiVENT.",
        "translated": "每天的新闻报道已经从传统的广播转向各种各样的报道形式，例如第一手的、未经编辑的视频素材。反映在线多模式、多语种新闻来源多样性的数据集可用于教导模式从这一转变中受益，但现有的新闻视频数据集侧重于为讲英语的受众制作的传统新闻广播。我们通过构建 MultiVENT 来解决这个限制，MultiVENT 是一个基于五种目标语言的文本文档的多语言、以事件为中心的视频数据集。MultiVENT 包括新闻广播视频和非专业事件视频，我们用它们来分析在线新闻视频的状态，以及如何利用它们来建立强大的、真实准确的模型。最后，我们提供了一个复杂的多语言视频检索模型，作为使用 MultivENT 进行信息检索检索的基准。"
    },
    {
        "title": "Track Mix Generation on Music Streaming Services using Transformers",
        "url": "http://arxiv.org/abs/2307.03045v1",
        "pub_date": "2023-07-06",
        "summary": "This paper introduces Track Mix, a personalized playlist generation system\nreleased in 2022 on the music streaming service Deezer. Track Mix automatically\ngenerates \"mix\" playlists inspired by initial music tracks, allowing users to\ndiscover music similar to their favorite content. To generate these mixes, we\nconsider a Transformer model trained on millions of track sequences from user\nplaylists. In light of the growing popularity of Transformers in recent years,\nwe analyze the advantages, drawbacks, and technical challenges of using such a\nmodel for mix generation on the service, compared to a more traditional\ncollaborative filtering approach. Since its release, Track Mix has been\ngenerating playlists for millions of users daily, enhancing their music\ndiscovery experience on Deezer.",
        "translated": "本文介绍了 TrackMix，一个2022年在音乐流媒体服务 Deezer 上发布的个性化播放列表生成系统。TrackMix 自动生成受初始音乐曲目启发的“混合”播放列表，允许用户发现与他们喜欢的内容相似的音乐。为了生成这些混音，我们考虑一个从用户播放列表中的数百万音轨序列中训练的 Transformer 模型。鉴于近年来变压器越来越受欢迎，我们分析了使用这种模式混合生成服务的优点，缺点和技术挑战，相比较更传统的协同过滤方法。自从发布以来，TrackMix 每天为数百万用户生成播放列表，增强了他们在 Deezer 上的音乐发现体验。"
    },
    {
        "title": "Improving Retrieval-Augmented Large Language Models via Data Importance\n  Learning",
        "url": "http://arxiv.org/abs/2307.03027v1",
        "pub_date": "2023-07-06",
        "summary": "Retrieval augmentation enables large language models to take advantage of\nexternal knowledge, for example on tasks like question answering and data\nimputation. However, the performance of such retrieval-augmented models is\nlimited by the data quality of their underlying retrieval corpus. In this\npaper, we propose an algorithm based on multilinear extension for evaluating\nthe data importance of retrieved data points. There are exponentially many\nterms in the multilinear extension, and one key contribution of this paper is a\npolynomial time algorithm that computes exactly, given a retrieval-augmented\nmodel with an additive utility function and a validation set, the data\nimportance of data points in the retrieval corpus using the multilinear\nextension of the model's utility function. We further proposed an even more\nefficient ({\\epsilon}, {\\delta})-approximation algorithm. Our experimental\nresults illustrate that we can enhance the performance of large language models\nby only pruning or reweighting the retrieval corpus, without requiring further\ntraining. For some tasks, this even allows a small model (e.g., GPT-JT),\naugmented with a search engine API, to outperform GPT-3.5 (without retrieval\naugmentation). Moreover, we show that weights based on multilinear extension\ncan be computed efficiently in practice (e.g., in less than ten minutes for a\ncorpus with 100 million elements).",
        "translated": "检索增强使大型语言模型能够利用外部知识，例如在问题回答和数据插补等任务上。然而，这种检索增强模型的性能受到其基础检索语料库数据质量的限制。本文提出了一种基于多线性可拓的检索点数据重要性评估算法。多线性扩展中的项数呈指数级增长，本文的一个重要贡献是提出了一种多项式时间算法，该算法利用模型的效用函数的多线性扩展，给定一个具有加性效用函数和验证集的检索增强模型，精确地计算了检索语料库中数据点的数据重要性。我们进一步提出了一个更有效的({ epsilon } ，{ delta })-近似演算法。实验结果表明，只需对检索语料进行剪枝或重新加权，就可以提高大型语言模型的性能，而不需要进一步的训练。对于某些任务，这甚至允许一个小型模型(例如，GPT-JT) ，通过一个搜索引擎 API 进行增强，其性能优于 GPT-3.5(没有检索增强)。此外，我们表明，基于多线性扩展的权重可以有效地计算在实践中(例如，在不到10分钟的一个语料库的1亿元素)。"
    },
    {
        "title": "A Meta-Evaluation of C/W/L/A Metrics: System Ranking Similarity, System\n  Ranking Consistency and Discriminative Power",
        "url": "http://arxiv.org/abs/2307.02936v1",
        "pub_date": "2023-07-06",
        "summary": "Recently, Moffat et al. proposed an analytic framework, namely C/W/L/A, for\noffline evaluation metrics. This framework allows information retrieval (IR)\nresearchers to design evaluation metrics through the flexible combination of\nuser browsing models and user gain aggregations. However, the statistical\nstability of C/W/L/A metrics with different aggregations is not yet\ninvestigated. In this study, we investigate the statistical stability of\nC/W/L/A metrics from the perspective of: (1) the system ranking similarity\namong aggregations, (2) the system ranking consistency of aggregations and (3)\nthe discriminative power of aggregations. More specifically, we combined\nvarious aggregation functions with the browsing model of Precision, Discounted\nCumulative Gain (DCG), Rank-Biased Precision (RBP), INST, Average Precision\n(AP) and Expected Reciprocal Rank (ERR), examing their performances in terms of\nsystem ranking similarity, system ranking consistency and discriminative power\non two offline test collections. Our experimental result suggests that, in\nterms of system ranking consistency and discriminative power, the aggregation\nfunction of expected rate of gain (ERG) has an outstanding performance while\nthe aggregation function of maximum relevance usually has an insufficient\nperformance. The result also suggests that Precision, DCG, RBP, INST and AP\nwith their canonical aggregation all have favourable performances in system\nranking consistency and discriminative power; but for ERR, replacing its\ncanonical aggregation with ERG can further strengthen the discriminative power\nwhile obtaining a system ranking list similar to the canonical version at the\nsame time.",
        "translated": "最近，Moffat 等人提出了一个分析框架，即 C/W/L/A，用于离线评估指标。这个框架允许信息检索研究人员通过灵活组合用户浏览模型和用户增益聚合来设计评估指标。然而，具有不同聚合的 C/W/L/A 指标的统计稳定性尚未得到研究。本研究从以下几个方面考察了 C/W/L/A 指标的统计稳定性: (1)系统对聚合之间的相似性进行排序; (2)系统对聚合的一致性进行排序; (3)聚合的判别能力。更具体地说，我们将各种聚合函数与精度、折扣累积增益(DCG)、有秩偏差的精度(RBP)、 INST、平均精度(AP)和期望互惠秩(ERR)的浏览模型相结合，考察了它们在两个离线测试集上的系统排序相似性、系统排序一致性和判别能力的表现。实验结果表明，在系统排序一致性和判别能力方面，期望增益率的聚合函数具有优异的性能，而最大相关度的聚合函数通常表现不佳。结果还表明，Precision、 DCG、 RBP、 INST 和 AP 以及它们的规范聚合在系统排序一致性和判别力方面都有良好的表现; 而 ERR 用 ERG 代替其规范聚合可以进一步增强判别力，同时获得类似于规范版本的系统排序列表。"
    },
    {
        "title": "PLIERS: a Popularity-Based Recommender System for Content Dissemination\n  in Online Social Networks",
        "url": "http://arxiv.org/abs/2307.02865v1",
        "pub_date": "2023-07-06",
        "summary": "In this paper, we propose a novel tag-based recommender system called PLIERS,\nwhich relies on the assumption that users are mainly interested in items and\ntags with similar popularity to those they already own. PLIERS is aimed at\nreaching a good tradeoff between algorithmic complexity and the level of\npersonalization of recommended items. To evaluate PLIERS, we performed a set of\nexperiments on real OSN datasets, demonstrating that it outperforms\nstate-of-the-art solutions in terms of personalization, relevance, and novelty\nof recommendations.",
        "translated": "在这篇文章中，我们提出了一个新的基于标签的推荐系统叫做 PLIERS，它基于这样一个假设: 用户主要对那些与他们已经拥有的东西相似的流行的项目和标签感兴趣。PLIERS 的目标是在算法复杂性和推荐项目的个性化水平之间取得良好的平衡。为了评估 PLIERS，我们在真实的 OSN 数据集上进行了一系列实验，证明它在个性化、相关性和推荐的新颖性方面优于最先进的解决方案。"
    },
    {
        "title": "Lost in the Middle: How Language Models Use Long Contexts",
        "url": "http://arxiv.org/abs/2307.03172v1",
        "pub_date": "2023-07-06",
        "summary": "While recent language models have the ability to take long contexts as input,\nrelatively little is known about how well the language models use longer\ncontext. We analyze language model performance on two tasks that require\nidentifying relevant information within their input contexts: multi-document\nquestion answering and key-value retrieval. We find that performance is often\nhighest when relevant information occurs at the beginning or end of the input\ncontext, and significantly degrades when models must access relevant\ninformation in the middle of long contexts. Furthermore, performance\nsubstantially decreases as the input context grows longer, even for explicitly\nlong-context models. Our analysis provides a better understanding of how\nlanguage models use their input context and provides new evaluation protocols\nfor future long-context models.",
        "translated": "虽然最近的语言模型能够将较长的上下文作为输入，但是对于语言模型如何更好地使用较长的上下文知之甚少。我们分析了语言模型在两个需要在其输入上下文中识别相关信息的任务上的表现: 多文档问题回答和关键值检索。我们发现，当相关信息出现在输入上下文的开头或结尾时，性能往往最高，而当模型必须在较长的上下文中访问相关信息时，性能则显著下降。此外，即使对于显式的长上下文模型，随着输入上下文的增长，性能也会大大降低。我们的分析提供了对语言模型如何使用其输入上下文的更好理解，并为未来的长上下文模型提供了新的评估协议。"
    },
    {
        "title": "Focused Transformer: Contrastive Training for Context Scaling",
        "url": "http://arxiv.org/abs/2307.03170v1",
        "pub_date": "2023-07-06",
        "summary": "Large language models have an exceptional capability to incorporate new\ninformation in a contextual manner. However, the full potential of such an\napproach is often restrained due to a limitation in the effective context\nlength. One solution to this issue is to endow an attention layer with access\nto an external memory, which comprises of (key, value) pairs. Yet, as the\nnumber of documents increases, the proportion of relevant keys to irrelevant\nones decreases, leading the model to focus more on the irrelevant keys. We\nidentify a significant challenge, dubbed the distraction issue, where keys\nlinked to different semantic values might overlap, making them hard to\ndistinguish. To tackle this problem, we introduce the Focused Transformer\n(FoT), a technique that employs a training process inspired by contrastive\nlearning. This novel approach enhances the structure of the (key, value) space,\nenabling an extension of the context length. Our method allows for fine-tuning\npre-existing, large-scale models to lengthen their effective context. This is\ndemonstrated by our fine-tuning of $3B$ and $7B$ OpenLLaMA checkpoints. The\nresulting models, which we name LongLLaMA, exhibit advancements in tasks\nrequiring a long context. We further illustrate that our LongLLaMA models\nadeptly manage a $256 k$ context length for passkey retrieval.",
        "translated": "大型语言模型具有以上下文方式合并新信息的特殊能力。然而，由于有效上下文长度的限制，这种方法的全部潜力往往受到限制。这个问题的一个解决方案是赋予注意层访问外部存储器的权限，外部存储器由(键，值)对组成。然而，随着文档数量的增加，相关键与不相关键的比例下降，导致模型更多地关注不相关键。我们确定了一个重大的挑战，称为分心问题，其中与不同语义值相关的键可能重叠，使它们难以区分。为了解决这个问题，我们引入了聚焦变压器(FoT) ，这是一种利用对比学习启发的训练过程的技术。这种新颖的方法增强了(键，值)空间的结构，支持上下文长度的扩展。我们的方法允许对预先存在的大规模模型进行微调，以延长它们的有效上下文。我们对 $3B $和 $7B $OpenLLaMA 检查点的微调就证明了这一点。所得到的模型(我们将其命名为 LongLLaMA)在需要长上下文的任务中表现出了进步。我们进一步说明，我们的 LongLLaMA 模型能够很好地管理256 k $的密钥检索上下文长度。"
    },
    {
        "title": "Distilling Large Vision-Language Model with Out-of-Distribution\n  Generalizability",
        "url": "http://arxiv.org/abs/2307.03135v1",
        "pub_date": "2023-07-06",
        "summary": "Large vision-language models have achieved outstanding performance, but their\nsize and computational requirements make their deployment on\nresource-constrained devices and time-sensitive tasks impractical. Model\ndistillation, the process of creating smaller, faster models that maintain the\nperformance of larger models, is a promising direction towards the solution.\nThis paper investigates the distillation of visual representations in large\nteacher vision-language models into lightweight student models using a small-\nor mid-scale dataset. Notably, this study focuses on open-vocabulary\nout-of-distribution (OOD) generalization, a challenging problem that has been\noverlooked in previous model distillation literature. We propose two principles\nfrom vision and language modality perspectives to enhance student's OOD\ngeneralization: (1) by better imitating teacher's visual representation space,\nand carefully promoting better coherence in vision-language alignment with the\nteacher; (2) by enriching the teacher's language representations with\ninformative and finegrained semantic attributes to effectively distinguish\nbetween different labels. We propose several metrics and conduct extensive\nexperiments to investigate their techniques. The results demonstrate\nsignificant improvements in zero-shot and few-shot student performance on\nopen-vocabulary out-of-distribution classification, highlighting the\neffectiveness of our proposed approaches. Our code will be released at\nhttps://github.com/xuanlinli17/large_vlm_distillation_ood",
        "translated": "大型视觉语言模型已经取得了出色的性能，但是它们的规模和计算需求使得它们在资源受限的设备和时间敏感的任务上的部署变得不切实际。模型精馏是创建更小、更快的模型以保持较大模型性能的过程，是解决这一问题的一个有希望的方向。本文研究了利用中小规模数据集将大型教师视觉语言模型中的视觉表征提炼为轻量级学生模型。值得注意的是，本研究的重点是开放词汇分布外(OOD)泛化，这是一个具有挑战性的问题，一直被忽视了以往的模型蒸馏文献。本文从视觉和语言情态两个角度提出了提高学生面向对象的概括能力的两个原则: (1)更好地模仿教师的视觉表征空间，小心翼翼地促进与教师视觉语言对齐的连贯性; (2)丰富教师的语言表征，使其具有信息丰富、细致入微的语义属性，有效地区分不同的标签。我们提出了几个指标，并进行了广泛的实验来研究他们的技术。研究结果表明，在开放词汇分布外分类中，零词镜头和少词镜头学生的表现都有显著的改善，突出了我们提出的方法的有效性。我们的代码会在 https://github.com/xuanlinli17/large_vlm_distillation_ood 公布"
    },
    {
        "title": "T-MARS: Improving Visual Representations by Circumventing Text Feature\n  Learning",
        "url": "http://arxiv.org/abs/2307.03132v1",
        "pub_date": "2023-07-06",
        "summary": "Large web-sourced multimodal datasets have powered a slew of new methods for\nlearning general-purpose visual representations, advancing the state of the art\nin computer vision and revolutionizing zero- and few-shot recognition. One\ncrucial decision facing practitioners is how, if at all, to curate these\never-larger datasets. For example, the creators of the LAION-5B dataset chose\nto retain only image-caption pairs whose CLIP similarity score exceeded a\ndesignated threshold. In this paper, we propose a new state-of-the-art data\nfiltering approach motivated by our observation that nearly 40% of LAION's\nimages contain text that overlaps significantly with the caption. Intuitively,\nsuch data could be wasteful as it incentivizes models to perform optical\ncharacter recognition rather than learning visual features. However, naively\nremoving all such data could also be wasteful, as it throws away images that\ncontain visual features (in addition to overlapping text). Our simple and\nscalable approach, T-MARS (Text Masking and Re-Scoring), filters out only those\npairs where the text dominates the remaining visual features -- by first\nmasking out the text and then filtering out those with a low CLIP similarity\nscore of the masked image. Experimentally, T-MARS outperforms the top-ranked\nmethod on the \"medium scale\" of DataComp (a data filtering benchmark) by a\nmargin of 6.5% on ImageNet and 4.7% on VTAB. Additionally, our systematic\nevaluation on various data pool sizes from 2M to 64M shows that the accuracy\ngains enjoyed by T-MARS linearly increase as data and compute are scaled\nexponentially. Code is available at https://github.com/locuslab/T-MARS.",
        "translated": "大型网络来源的多模态数据集为一系列学习通用视觉表征的新方法提供了动力，推进了计算机视觉的最新水平，并彻底改革了零镜头和少镜头识别。从业者面临的一个关键决定是如何管理这些越来越大的数据集。例如，LAION-5B 数据集的创建者选择只保留 CLIP 相似性评分超过指定阈值的图像-标题对。在本文中，我们提出了一个新的国家的最先进的数据过滤方法的动机是我们的观察，近40% 的 LAION 的图像包含文本，与标题重叠显着。直观地说，这样的数据可能是浪费的，因为它激励模型执行光学字符识别，而不是学习视觉特征。然而，天真地删除所有这些数据也可能是浪费，因为它会丢弃包含视觉特征的图像(除了重叠的文本)。我们简单且可扩展的方法，T-MARS (文本掩盖和重新评分) ，只过滤那些文本主导剩余视觉特征的对——首先掩盖文本，然后过滤那些掩盖图像的低 CLIP 相似度评分。在实验上，T-MARS 在“中等规模”的 DataComp (一个数据过滤基准)上的表现优于顶级方法，在 ImageNet 上优于6.5% ，在 VTAB 上优于4.7% 。此外，我们对从2M 到64M 的各种数据池大小的系统评估表明，随着数据和计算的指数级扩展，T-MARS 所享有的准确性增益呈线性增加。密码可于 https://github.com/locuslab/t-mars 索取。"
    },
    {
        "title": "BLEURT Has Universal Translations: An Analysis of Automatic Metrics by\n  Minimum Risk Training",
        "url": "http://arxiv.org/abs/2307.03131v1",
        "pub_date": "2023-07-06",
        "summary": "Automatic metrics play a crucial role in machine translation. Despite the\nwidespread use of n-gram-based metrics, there has been a recent surge in the\ndevelopment of pre-trained model-based metrics that focus on measuring sentence\nsemantics. However, these neural metrics, while achieving higher correlations\nwith human evaluations, are often considered to be black boxes with potential\nbiases that are difficult to detect. In this study, we systematically analyze\nand compare various mainstream and cutting-edge automatic metrics from the\nperspective of their guidance for training machine translation systems. Through\nMinimum Risk Training (MRT), we find that certain metrics exhibit robustness\ndefects, such as the presence of universal adversarial translations in BLEURT\nand BARTScore. In-depth analysis suggests two main causes of these robustness\ndeficits: distribution biases in the training datasets, and the tendency of the\nmetric paradigm. By incorporating token-level constraints, we enhance the\nrobustness of evaluation metrics, which in turn leads to an improvement in the\nperformance of machine translation systems. Codes are available at\n\\url{https://github.com/powerpuffpomelo/fairseq_mrt}.",
        "translated": "自动度量在机器翻译中起着至关重要的作用。尽管基于 n-gram 的度量标准得到了广泛的应用，但是最近在开发基于预训练模型的度量标准方面出现了一股浪潮，这些度量标准关注于测量句子语义。然而，这些神经指标，虽然与人类评估实现更高的相关性，往往被认为是具有难以检测的潜在偏差的黑盒子。在本研究中，我们系统地分析和比较了各种主流和前沿的自动化指标，从它们对培训机器翻译系统的指导的角度。通过最小风险训练(MRT) ，我们发现某些指标具有鲁棒性缺陷，如 BLEURT 和 BARTScore 中存在通用的对抗性翻译。深入分析表明这些健壮性缺陷的两个主要原因: 训练数据集中的分布偏差和度量范式的趋势。通过引入令牌级约束，我们增强了评估指标的鲁棒性，这反过来又导致了机器翻译系统性能的改善。密码可在网址{ https://github.com/powerpuffpomelo/fairseq_mrt }下载。"
    },
    {
        "title": "VisKoP: Visual Knowledge oriented Programming for Interactive Knowledge\n  Base Question Answering",
        "url": "http://arxiv.org/abs/2307.03130v1",
        "pub_date": "2023-07-06",
        "summary": "We present Visual Knowledge oriented Programming platform (VisKoP), a\nknowledge base question answering (KBQA) system that integrates human into the\nloop to edit and debug the knowledge base (KB) queries. VisKoP not only\nprovides a neural program induction module, which converts natural language\nquestions into knowledge oriented program language (KoPL), but also maps KoPL\nprograms into graphical elements. KoPL programs can be edited with simple\ngraphical operators, such as dragging to add knowledge operators and slot\nfilling to designate operator arguments. Moreover, VisKoP provides\nauto-completion for its knowledge base schema and users can easily debug the\nKoPL program by checking its intermediate results. To facilitate the practical\nKBQA on a million-entity-level KB, we design a highly efficient KoPL execution\nengine for the back-end. Experiment results show that VisKoP is highly\nefficient and user interaction can fix a large portion of wrong KoPL programs\nto acquire the correct answer. The VisKoP online demo\nhttps://demoviskop.xlore.cn (Stable release of this paper) and\nhttps://viskop.xlore.cn (Beta release with new features), highly efficient KoPL\nengine https://pypi.org/project/kopl-engine, and screencast video\nhttps://youtu.be/zAbJtxFPTXo are now publicly available.",
        "translated": "本文介绍了面向可视化知识编程平台(VisKoP) ，它是一个集成了人机交互的知识库问题回答系统(KBQA) ，可以对知识库查询进行编辑和调试。VisKoP 不仅提供了一个神经程序归纳模块，将自然语言问题转换为面向知识的程序语言(KoPL) ，而且还将 KoPL 程序映射为图形元素。KOPL 程序可以通过简单的图形运算符进行编辑，例如通过拖动来添加知识运算符，通过插槽填充来指定运算符参数。此外，VisKoP 为其知识库模式提供了自动完成功能，用户可以通过检查 KoPL 程序的中间结果来轻松调试 KoPL 程序。为了方便实际的百万实体级 KB 上的 KBQA，我们为后端设计了一个高效的 KOPL 执行引擎。实验结果表明，VisKoP 是高效的，用户交互可以修复大部分错误的 KOPL 程序，从而获得正确的答案。ViskoP 在线演示 https://demoviskop.xlore.cn (本文的稳定发布)和 https://VisKoP.xlore.cn (带有新功能的 Beta 发布)、高效的 KoPL 引擎 https://pypi.org/project/KoPL-engine 和视频 https://youtu.be/zabjtxfptxo 现已公开发布。"
    },
    {
        "title": "Extracting Multi-valued Relations from Language Models",
        "url": "http://arxiv.org/abs/2307.03122v1",
        "pub_date": "2023-07-06",
        "summary": "The widespread usage of latent language representations via pre-trained\nlanguage models (LMs) suggests that they are a promising source of structured\nknowledge. However, existing methods focus only on a single object per\nsubject-relation pair, even though often multiple objects are correct. To\novercome this limitation, we analyze these representations for their potential\nto yield materialized multi-object relational knowledge. We formulate the\nproblem as a rank-then-select task. For ranking candidate objects, we evaluate\nexisting prompting techniques and propose new ones incorporating domain\nknowledge. Among the selection methods, we find that choosing objects with a\nlikelihood above a learned relation-specific threshold gives a 49.5% F1 score.\nOur results highlight the difficulty of employing LMs for the multi-valued\nslot-filling task and pave the way for further research on extracting\nrelational knowledge from latent language representations.",
        "translated": "潜在语言表征通过预训练语言模型(LM)的广泛应用表明，它们是结构化知识的一个有前途的来源。然而，现有的方法只关注每个主题关系对中的一个对象，即使多个对象通常是正确的。为了克服这个限制，我们分析了这些表示，看它们产生物化多对象关系知识的潜力。我们把这个问题表述为一个排序然后选择的任务。为了对候选对象进行排序，我们评估了现有的提示技术，并结合领域知识提出了新的提示技术。在所有的选择方法中，我们发现选择一个可能性高于学习关系特定阈值的对象，F1得分为49.5% 。我们的研究结果突出了利用 LM 进行多值填充任务的难度，并为进一步研究从潜在语言表征中提取关系知识铺平了道路。"
    },
    {
        "title": "KoRC: Knowledge oriented Reading Comprehension Benchmark for Deep Text\n  Understanding",
        "url": "http://arxiv.org/abs/2307.03115v1",
        "pub_date": "2023-07-06",
        "summary": "Deep text understanding, which requires the connections between a given\ndocument and prior knowledge beyond its text, has been highlighted by many\nbenchmarks in recent years. However, these benchmarks have encountered two\nmajor limitations. On the one hand, most of them require human annotation of\nknowledge, which leads to limited knowledge coverage. On the other hand, they\nusually use choices or spans in the texts as the answers, which results in\nnarrow answer space. To overcome these limitations, we build a new challenging\nbenchmark named KoRc in this paper. Compared with previous benchmarks, KoRC has\ntwo advantages, i.e., broad knowledge coverage and flexible answer format.\nSpecifically, we utilize massive knowledge bases to guide annotators or large\nlanguage models (LLMs) to construct knowledgable questions. Moreover, we use\nlabels in knowledge bases rather than spans or choices as the final answers. We\ntest state-of-the-art models on KoRC and the experimental results show that the\nstrongest baseline only achieves 68.3% and 30.0% F1 measure in the\nin-distribution and out-of-distribution test set, respectively. These results\nindicate that deep text understanding is still an unsolved challenge. The\nbenchmark dataset, leaderboard, and baseline methods are released in\nhttps://github.com/THU-KEG/KoRC.",
        "translated": "深度文本理解需要将文件与文本之外的先前知识联系起来，近年来许多基准都强调了这一点。然而，这些基准测试遇到了两个主要的限制。一方面，它们大多需要人工对知识进行注释，导致知识覆盖面有限;。另一方面，他们通常使用选择或跨度在文本中作为答案，这导致了狭窄的答案空间。为了克服这些限制，我们在本文中构建了一个新的具有挑战性的基准，命名为 KoRc。与以往的基准相比，KoRC 有两个优势，即知识面广和答案形式灵活。具体来说，我们利用大量的知识库来指导注释者或者大型语言模型(LLM)来构建知识性问题。此外，我们在知识库中使用标签，而不是跨度或选择作为最终答案。我们在 KoRC 测试了最先进的模型，实验结果显示最强的基线在分布内和分布外测试集中分别只达到68.3% 和30.0% 的 f 1测量值。这些结果表明，深层文本理解仍然是一个未解决的挑战。基准数据集、排行榜和基准方法以 https://github.com/thu-keg/korc 形式发布。"
    },
    {
        "title": "A Survey on Evaluation of Large Language Models",
        "url": "http://arxiv.org/abs/2307.03109v1",
        "pub_date": "2023-07-06",
        "summary": "Large language models (LLMs) are gaining increasing popularity in both\nacademia and industry, owing to their unprecedented performance in various\napplications. As LLMs continue to play a vital role in both research and daily\nuse, their evaluation becomes increasingly critical, not only at the task\nlevel, but also at the society level for better understanding of their\npotential risks. Over the past years, significant efforts have been made to\nexamine LLMs from various perspectives. This paper presents a comprehensive\nreview of these evaluation methods for LLMs, focusing on three key dimensions:\nwhat to evaluate, where to evaluate, and how to evaluate. Firstly, we provide\nan overview from the perspective of evaluation tasks, encompassing general\nnatural language processing tasks, reasoning, medical usage, ethics,\neducations, natural and social sciences, agent applications, and other areas.\nSecondly, we answer the `where' and `how' questions by diving into the\nevaluation methods and benchmarks, which serve as crucial components in\nassessing performance of LLMs. Then, we summarize the success and failure cases\nof LLMs in different tasks. Finally, we shed light on several future challenges\nthat lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to\nresearchers in the realm of LLMs evaluation, thereby aiding the development of\nmore proficient LLMs. Our key point is that evaluation should be treated as an\nessential discipline to better assist the development of LLMs. We consistently\nmaintain the related open-source materials at:\nhttps://github.com/MLGroupJLU/LLM-eval-survey.",
        "translated": "大语言模型(LLM)因其在各种应用中的前所未有的性能，在学术界和工业界越来越受欢迎。随着 LLM 在研究和日常使用中继续发挥重要作用，它们的评估变得越来越重要，不仅在任务层面，而且在社会层面，以便更好地了解它们的潜在风险。在过去的几年中，人们从不同的角度对 LLM 进行了大量的研究。本文对这些评价方法进行了综述，重点介绍了三个关键的方面: 评价内容、评价地点和评价方法。首先，我们从评估任务的角度提供了一个概述，包括一般的自然语言处理任务，推理，医学使用，伦理，教育，自然和社会科学，代理应用程序，以及其他领域。其次，我们通过深入研究评价方法和基准来回答“在哪里”和“如何”的问题，这些方法和基准是评价 LLM 绩效的重要组成部分。然后，总结了 LLM 在不同任务中的成功与失败案例。最后，我们阐明了在 LLM 评估中面临的几个未来挑战。我们的目标是提供宝贵的见解，研究人员在领域的 LLM 评价，从而帮助发展更熟练的 LLM。我们的主要观点是，评价应被视为一门必不可少的学科，以更好地协助 LLM 的发展。我们一直将相关的开源材料保存在以下 https://github.com/mlgroupjlu/llm-eval-survey  :。"
    },
    {
        "title": "Efficient Domain Adaptation of Sentence Embeddings using Adapters",
        "url": "http://arxiv.org/abs/2307.03104v1",
        "pub_date": "2023-07-06",
        "summary": "Sentence embeddings enable us to capture the semantic similarity of short\ntexts. Most sentence embedding models are trained for general semantic textual\nsimilarity (STS) tasks. Therefore, to use sentence embeddings in a particular\ndomain, the model must be adapted to it in order to achieve good results.\nUsually, this is done by fine-tuning the entire sentence embedding model for\nthe domain of interest. While this approach yields state-of-the-art results,\nall of the model's weights are updated during fine-tuning, making this method\nresource-intensive. Therefore, instead of fine-tuning entire sentence embedding\nmodels for each target domain individually, we propose to train lightweight\nadapters. These domain-specific adapters do not require fine-tuning all\nunderlying sentence embedding model parameters. Instead, we only train a small\nnumber of additional parameters while keeping the weights of the underlying\nsentence embedding model fixed. Training domain-specific adapters allows always\nusing the same base model and only exchanging the domain-specific adapters to\nadapt sentence embeddings to a specific domain. We show that using adapters for\nparameter-efficient domain adaptation of sentence embeddings yields competitive\nperformance within 1% of a domain-adapted, entirely fine-tuned sentence\nembedding model while only training approximately 3.6% of the parameters.",
        "translated": "句子嵌入使我们能够捕捉短文的语义相似性。大多数句子嵌入模型都是针对一般的语义文本相似度(STS)任务进行训练的。因此，要在特定领域使用句子嵌入，必须对模型进行适应性调整，才能取得良好的效果。通常，这是通过为感兴趣的领域微调整整个句子嵌入模型来完成的。虽然这种方法可以产生最先进的结果，但是所有模型的权重都会在微调过程中更新，这使得这种方法需要大量资源。因此，我们建议训练轻量级适配器，而不是针对每个目标领域分别微调整整个句子嵌入模型。这些特定于域的适配器不需要对所有底层句子嵌入模型参数进行微调。相反，我们只训练少量的附加参数，同时保持潜在的句子嵌入模型的权重不变。训练领域特定的适配器总是允许使用相同的基本模型，并且只交换领域特定的适配器来适应特定领域的句子嵌入。我们发现使用适配器对句子嵌入进行参数有效的领域适应，在领域适应的完全微调的句子嵌入模型的1% 内产生竞争性能，而只训练大约3.6% 的参数。"
    },
    {
        "title": "A Network Resource Allocation Recommendation Method with An Improved\n  Similarity Measure",
        "url": "http://arxiv.org/abs/2307.03399v1",
        "pub_date": "2023-07-07",
        "summary": "Recommender systems have been acknowledged as efficacious tools for managing\ninformation overload. Nevertheless, conventional algorithms adopted in such\nsystems primarily emphasize precise recommendations and, consequently, overlook\nother vital aspects like the coverage, diversity, and novelty of items. This\napproach results in less exposure for long-tail items. In this paper, to\npersonalize the recommendations and allocate recommendation resources more\npurposively, a method named PIM+RA is proposed. This method utilizes a\nbipartite network that incorporates self-connecting edges and weights.\nFurthermore, an improved Pearson correlation coefficient is employed for better\nredistribution. The evaluation of PIM+RA demonstrates a significant enhancement\nnot only in accuracy but also in coverage, diversity, and novelty of the\nrecommendation. It leads to a better balance in recommendation frequency by\nproviding effective exposure to long-tail items, while allowing customized\nparameters to adjust the recommendation list bias.",
        "translated": "推荐系统已被公认为管理信息超载的有效工具。然而，在这样的系统中采用的传统算法主要强调精确的推荐，因此忽视了其他重要方面，如项目的覆盖面、多样性和新颖性。这种方法可以减少长尾项目的曝光。为了实现推荐的个性化，更有针对性地分配推荐资源，提出了一种基于 PIM + RA 的推荐资源分配方法。该方法利用了一个包含自连接边和权值的二分网络。此外，改进的皮尔逊相关系数被用于更好的再分配。PIM + RA 的评估不仅在准确性方面，而且在推荐的覆盖面、多样性和新颖性方面都有显著的提高。它通过提供对长尾项目的有效接触，同时允许定制的参数来调整推荐列表偏差，从而使推荐频率得到更好的平衡。"
    },
    {
        "title": "InfoSync: Information Synchronization across Multilingual\n  Semi-structured Tables",
        "url": "http://arxiv.org/abs/2307.03313v1",
        "pub_date": "2023-07-06",
        "summary": "Information Synchronization of semi-structured data across languages is\nchallenging. For instance, Wikipedia tables in one language should be\nsynchronized across languages. To address this problem, we introduce a new\ndataset InfoSyncC and a two-step method for tabular synchronization. InfoSync\ncontains 100K entity-centric tables (Wikipedia Infoboxes) across 14 languages,\nof which a subset (3.5K pairs) are manually annotated. The proposed method\nincludes 1) Information Alignment to map rows and 2) Information Update for\nupdating missing/outdated information for aligned tables across multilingual\ntables. When evaluated on InfoSync, information alignment achieves an F1 score\nof 87.91 (en &lt;-&gt; non-en). To evaluate information updation, we perform\nhuman-assisted Wikipedia edits on Infoboxes for 603 table pairs. Our approach\nobtains an acceptance rate of 77.28% on Wikipedia, showing the effectiveness of\nthe proposed method.",
        "translated": "跨语言的半结构化数据的信息同步具有挑战性。例如，一种语言中的 Wikipedia 表应该跨语言同步。为了解决这个问题，我们引入了一个新的数据集 InfoSyncC 和一个两步的表同步方法。InfoSync 包含100K 跨14种语言的以实体为中心的表(Wikipedia Infobox) ，其中一个子集(3.5 K 对)是手动注释的。该方法包括1)映射行的信息对齐和2)跨多语言表更新对齐表中缺失/过时信息的信息更新。当在 InfoSync 上进行评估时，信息对齐达到 F1分数87.91(en <-> non-en)。为了评估信息更新，我们在 Infobox 上对603个表对执行人工辅助的 Wikipedia 编辑。该方法在维基百科上的验收率为77.28% ，表明了该方法的有效性。"
    },
    {
        "title": "Structure Guided Multi-modal Pre-trained Transformer for Knowledge Graph\n  Reasoning",
        "url": "http://arxiv.org/abs/2307.03591v1",
        "pub_date": "2023-07-06",
        "summary": "Multimodal knowledge graphs (MKGs), which intuitively organize information in\nvarious modalities, can benefit multiple practical downstream tasks, such as\nrecommendation systems, and visual question answering. However, most MKGs are\nstill far from complete, which motivates the flourishing of MKG reasoning\nmodels. Recently, with the development of general artificial architectures, the\npretrained transformer models have drawn increasing attention, especially for\nmultimodal scenarios. However, the research of multimodal pretrained\ntransformer (MPT) for knowledge graph reasoning (KGR) is still at an early\nstage. As the biggest difference between MKG and other multimodal data, the\nrich structural information underlying the MKG still cannot be fully leveraged\nin existing MPT models. Most of them only utilize the graph structure as a\nretrieval map for matching images and texts connected with the same entity.\nThis manner hinders their reasoning performances. To this end, we propose the\ngraph Structure Guided Multimodal Pretrained Transformer for knowledge graph\nreasoning, termed SGMPT. Specifically, the graph structure encoder is adopted\nfor structural feature encoding. Then, a structure-guided fusion module with\ntwo different strategies, i.e., weighted summation and alignment constraint, is\nfirst designed to inject the structural information into both the textual and\nvisual features. To the best of our knowledge, SGMPT is the first MPT model for\nmultimodal KGR, which mines the structural information underlying the knowledge\ngraph. Extensive experiments on FB15k-237-IMG and WN18-IMG, demonstrate that\nour SGMPT outperforms existing state-of-the-art models, and prove the\neffectiveness of the designed strategies.",
        "translated": "多模态知识图(MKG)可以直观地组织各种形式的信息，有利于多种实际的下游任务，如推荐系统和可视化问题回答。然而，大多数 MKG 推理模型还远未完成，这促使了 MKG 推理模型的蓬勃发展。近年来，随着通用人工结构的发展，预训练变压器模型越来越受到重视，尤其是在多模态情况下。然而，用于知识图推理(KGR)的多模态预训练变压器(MPT)的研究还处于初级阶段。作为 MKG 和其他多模态数据的最大区别，MKG 所蕴含的丰富的结构信息仍然不能在现有的 MPT 模型中得到充分利用。它们大多数只是利用图结构作为检索映射来匹配与同一实体相连的图像和文本。这种方式妨碍了他们的推理能力。为此，我们提出了图结构引导的多模态预训练变压器的知识图推理，称为 SGMPT。具体地说，采用图结构编码器进行结构特征编码。然后，设计了一个结构引导的融合模块，该模块采用加权和约束和对齐约束两种不同的融合策略，将结构信息同时注入到文本特征和视觉特征中。据我们所知，SGMPT 是多模态 KGR 的第一个 MPT 模型，它挖掘知识图中的结构信息。在 FB15k-237-IMG 和 WN18-IMG 上的大量实验表明，我们的 SGMPT 性能优于现有的最先进的模型，并证明了所设计策略的有效性。"
    },
    {
        "title": "On the Efficacy of Sampling Adapters",
        "url": "http://arxiv.org/abs/2307.03749v1",
        "pub_date": "2023-07-07",
        "summary": "Sampling is a common strategy for generating text from probabilistic models,\nyet standard ancestral sampling often results in text that is incoherent or\nungrammatical. To alleviate this issue, various modifications to a model's\nsampling distribution, such as nucleus or top-k sampling, have been introduced\nand are now ubiquitously used in language generation systems. We propose a\nunified framework for understanding these techniques, which we term sampling\nadapters. Sampling adapters often lead to qualitatively better text, which\nraises the question: From a formal perspective, how are they changing the\n(sub)word-level distributions of language generation models? And why do these\nlocal changes lead to higher-quality text? We argue that the shift they enforce\ncan be viewed as a trade-off between precision and recall: while the model\nloses its ability to produce certain strings, its precision rate on desirable\ntext increases. While this trade-off is not reflected in standard metrics of\ndistribution quality (such as perplexity), we find that several\nprecision-emphasizing measures indeed indicate that sampling adapters can lead\nto probability distributions more aligned with the true distribution. Further,\nthese measures correlate with higher sequence-level quality scores,\nspecifically, Mauve.",
        "translated": "抽样是从概率模型生成文本的一种常见策略，然而标准的祖先抽样常常导致文本不连贯或不符合语法。为了缓解这一问题，对模型的抽样分布进行了各种修改，如核抽样或 top-k 抽样，这些修改已经被引入，并且现在在语言生成系统中普遍使用。我们提出了一个统一的框架来理解这些技术，我们称之为抽样适配器。采样适配器通常能产生质量更好的文本，这就提出了一个问题: 从形式角度来看，它们如何改变语言生成模型的(子)词级分布？为什么这些局部变化会导致更高质量的文本？我们认为，它们实施的转变可以被视为准确率召回率之间的一种权衡: 尽管模型失去了产生特定字符串的能力，但它对理想文本的精确度却有所提高。虽然这种权衡没有反映在分布质量的标准指标(如困惑)中，但我们发现，一些强调精度的指标确实表明，抽样适配器可以导致与真实分布更加一致的概率分布。此外，这些措施与更高的序列水平的质量得分相关，特别是，紫红色。"
    },
    {
        "title": "QIGen: Generating Efficient Kernels for Quantized Inference on Large\n  Language Models",
        "url": "http://arxiv.org/abs/2307.03738v1",
        "pub_date": "2023-07-07",
        "summary": "We present ongoing work on a new automatic code generation approach for\nsupporting quantized generative inference on LLMs such as LLaMA or OPT on\noff-the-shelf CPUs. Our approach is informed by the target architecture and a\nperformance model, including both hardware characteristics and method-specific\naccuracy constraints. Results on CPU-based inference for LLaMA models show that\nour approach can lead to high performance and high accuracy, comparing\nfavorably to the best existing open-source solution. A preliminary\nimplementation is available at https://github.com/IST-DASLab/QIGen.",
        "translated": "我们目前正在研究一种新的自动代码生成方法，用于支持 LLM 上的量化生成推理，如 LLaMA 或现成 CPU 上的 OPT。我们的方法受到目标体系结构和性能模型的影响，包括硬件特征和方法特定的精度约束。对 LLaMA 模型的基于 CPU 的推理结果表明，与现有的最佳开源解决方案相比，我们的方法可以获得更高的性能和更高的精度。初步的实施 https://github.com/ist-daslab/qigen 可供参考。"
    },
    {
        "title": "Improving Automatic Quotation Attribution in Literary Novels",
        "url": "http://arxiv.org/abs/2307.03734v1",
        "pub_date": "2023-07-07",
        "summary": "Current models for quotation attribution in literary novels assume varying\nlevels of available information in their training and test data, which poses a\nchallenge for in-the-wild inference. Here, we approach quotation attribution as\na set of four interconnected sub-tasks: character identification, coreference\nresolution, quotation identification, and speaker attribution. We benchmark\nstate-of-the-art models on each of these sub-tasks independently, using a large\ndataset of annotated coreferences and quotations in literary novels (the\nProject Dialogism Novel Corpus). We also train and evaluate models for the\nspeaker attribution task in particular, showing that a simple sequential\nprediction model achieves accuracy scores on par with state-of-the-art models.",
        "translated": "现有的文学小说引文归因模型在训练和测试数据中假定了不同程度的可用信息，这对野外推理提出了挑战。在这里，我们把引文归属作为四个相互关联的子任务来处理: 字符识别、共指解析、引文识别和说话人归属。我们使用文学小说(对话项目小说语料库)中带注释的参考文献和引文的大型数据集，独立地对这些子任务中的每个子任务进行最先进的模型基准测试。我们还特别针对说话人归因任务训练和评估模型，表明一个简单的顺序预测模型可以达到与最先进的模型相当的精度分数。"
    },
    {
        "title": "INT-FP-QSim: Mixed Precision and Formats For Large Language Models and\n  Vision Transformers",
        "url": "http://arxiv.org/abs/2307.03712v1",
        "pub_date": "2023-07-07",
        "summary": "The recent rise of large language models (LLMs) has resulted in increased\nefforts towards running LLMs at reduced precision. Running LLMs at lower\nprecision supports resource constraints and furthers their democratization,\nenabling users to run billion-parameter LLMs on their personal devices. To\nsupplement this ongoing effort, we propose INT-FP-QSim: an open-source\nsimulator that enables flexible evaluation of LLMs and vision transformers at\nvarious numerical precisions and formats. INT-FP-QSim leverages existing\nopen-source repositories such as TensorRT, QPytorch and AIMET for a combined\nsimulator that supports various floating point and integer formats. With the\nhelp of our simulator, we survey the impact of different numerical formats on\nthe performance of LLMs and vision transformers at 4-bit weights and 4-bit or\n8-bit activations. We also compare recently proposed methods like Adaptive\nBlock Floating Point, SmoothQuant, GPTQ and RPTQ on the model performances. We\nhope INT-FP-QSim will enable researchers to flexibly simulate models at various\nprecisions to support further research in quantization of LLMs and vision\ntransformers.",
        "translated": "最近大型语言模型(LLM)的兴起已经导致在降低 LLM 的精度方面付出了更多的努力。以较低的精度运行 LLM 支持资源约束并进一步实现其民主化，使用户能够在其个人设备上运行十亿参数的 LLM。为了补充正在进行的努力，我们提出了 INT-FP-QSim: 一个开源模拟器，可以灵活评估 LLM 和视觉转换器在各种数字精度和格式。INT-FP-QSim 利用现有的开放源码存储库，如 TensorRT、 QPytorch 和 AIMET，构建了一个支持各种浮点数和整数格式的组合模拟器。在我们的模拟器的帮助下，我们调查了不同的数字格式对 LLM 和视觉变换器在4位加权和4位或8位激活时的性能的影响。我们还比较了最近提出的自适应块浮点数、 SmoothQuant、 GPTQ 和 RPTQ 等方法对模型性能的影响。我们希望 INT-FP-QSim 能够使研究人员灵活地模拟不同精度的模型，以支持 LLM 和视觉变压器的量子化的进一步研究。"
    },
    {
        "title": "Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug\n  Trafficking Detection on Social Media",
        "url": "http://arxiv.org/abs/2307.03699v1",
        "pub_date": "2023-07-07",
        "summary": "Social media platforms such as Instagram and Twitter have emerged as critical\nchannels for drug marketing and illegal sale. Detecting and labeling online\nillicit drug trafficking activities becomes important in addressing this issue.\nHowever, the effectiveness of conventional supervised learning methods in\ndetecting drug trafficking heavily relies on having access to substantial\namounts of labeled data, while data annotation is time-consuming and\nresource-intensive. Furthermore, these models often face challenges in\naccurately identifying trafficking activities when drug dealers use deceptive\nlanguage and euphemisms to avoid detection. To overcome this limitation, we\nconduct the first systematic study on leveraging large language models (LLMs),\nsuch as ChatGPT, to detect illicit drug trafficking activities on social media.\nWe propose an analytical framework to compose \\emph{knowledge-informed\nprompts}, which serve as the interface that humans can interact with and use\nLLMs to perform the detection task. Additionally, we design a Monte Carlo\ndropout based prompt optimization method to further to improve performance and\ninterpretability. Our experimental findings demonstrate that the proposed\nframework outperforms other baseline language models in terms of drug\ntrafficking detection accuracy, showing a remarkable improvement of nearly\n12\\%. By integrating prior knowledge and the proposed prompts, ChatGPT can\neffectively identify and label drug trafficking activities on social networks,\neven in the presence of deceptive language and euphemisms used by drug dealers\nto evade detection. The implications of our research extend to social networks,\nemphasizing the importance of incorporating prior knowledge and scenario-based\nprompts into analytical tools to improve online security and public safety.",
        "translated": "Instagram 和 Twitter 等社交媒体平台已成为毒品营销和非法销售的重要渠道。侦测和标明网上非法非法毒品贸易活动对于解决这一问题变得非常重要。然而，传统监督式学习方法在检测非法毒品贸易方面的有效性在很大程度上依赖于能够获得大量的标记数据，而数据注释是耗费时间和资源密集型的。此外，当毒品贩子使用欺骗性语言和委婉语来逃避侦查时，这些模型往往在准确识别贩运活动方面面临挑战。为了克服这个限制，我们进行了第一个系统的研究，利用大型语言模型(LLMs) ，例如 chatgPT，来检测社交媒体上的非法非法毒品贸易活动。我们提出了一个分析框架来组成 emph {知识提示} ，它作为接口，人们可以交互和使用 LLM 来执行检测任务。此外，我们设计了一个基于蒙特卡罗辍学的快速优化方法，以进一步提高性能和可解释性。我们的实验结果显示，该框架在非法毒品贸易检测准确度方面优于其他基线语言模型，显著提高了近12% 。通过整合先前的知识和建议的提示，ChatgPT 可以有效地识别和标记社交网络上的非法毒品贸易活动，即使毒贩使用欺骗性语言和委婉语来逃避侦查。我们研究的影响延伸到社交网络，强调了将先前的知识和基于场景的提示纳入分析工具以改善在线安全和公共安全的重要性。"
    },
    {
        "title": "Testing the Predictions of Surprisal Theory in 11 Languages",
        "url": "http://arxiv.org/abs/2307.03667v2",
        "pub_date": "2023-07-07",
        "summary": "A fundamental result in psycholinguistics is that less predictable words take\na longer time to process. One theoretical explanation for this finding is\nSurprisal Theory (Hale, 2001; Levy, 2008), which quantifies a word's\npredictability as its surprisal, i.e. its negative log-probability given a\ncontext. While evidence supporting the predictions of Surprisal Theory have\nbeen replicated widely, most have focused on a very narrow slice of data:\nnative English speakers reading English texts. Indeed, no comprehensive\nmultilingual analysis exists. We address this gap in the current literature by\ninvestigating the relationship between surprisal and reading times in eleven\ndifferent languages, distributed across five language families. Deriving\nestimates from language models trained on monolingual and multilingual corpora,\nwe test three predictions associated with surprisal theory: (i) whether\nsurprisal is predictive of reading times; (ii) whether expected surprisal, i.e.\ncontextual entropy, is predictive of reading times; (iii) and whether the\nlinking function between surprisal and reading times is linear. We find that\nall three predictions are borne out crosslinguistically. By focusing on a more\ndiverse set of languages, we argue that these results offer the most robust\nlink to-date between information theory and incremental language processing\nacross languages.",
        "translated": "心理语言学的一个基本结果是，较难预测的单词需要更长的时间来处理。对这一发现的一个理论解释是惊喜理论(Hale，2001; Levy，2008) ，该理论将一个单词的可预测性量化为它的惊喜，即给定上下文的负对数概率。虽然支持意外理论预测的证据已被广泛复制，但大多数都集中在一个非常狭窄的数据片段: 以英语为母语的人阅读英语文本。事实上，并不存在全面的多语言分析。我们通过调查分布在五个语系中的十一种不同语言的惊奇和阅读时间之间的关系来解决当前文献中的这一差距。从单语言和多语言语料库训练的语言模型中得出估计，我们测试了与惊喜理论相关的三个预测: (i)惊喜是否可以预测阅读时间; (ii)预期的惊喜，即上下文熵，是否可以预测阅读时间; (iii)以及惊喜和阅读时间之间的联系函数是否是线性的。我们发现这三个预测都得到了跨语言的证实。通过关注更加多样化的语言集合，我们认为这些结果提供了迄今为止信息理论和跨语言增量语言处理之间最有力的联系。"
    },
    {
        "title": "The distribution of discourse relations within and across turns in\n  spontaneous conversation",
        "url": "http://arxiv.org/abs/2307.03645v1",
        "pub_date": "2023-07-07",
        "summary": "Time pressure and topic negotiation may impose constraints on how people\nleverage discourse relations (DRs) in spontaneous conversational contexts. In\nthis work, we adapt a system of DRs for written language to spontaneous\ndialogue using crowdsourced annotations from novice annotators. We then test\nwhether discourse relations are used differently across several types of\nmulti-utterance contexts. We compare the patterns of DR annotation within and\nacross speakers and within and across turns. Ultimately, we find that different\ndiscourse contexts produce distinct distributions of discourse relations, with\nsingle-turn annotations creating the most uncertainty for annotators.\nAdditionally, we find that the discourse relation annotations are of sufficient\nquality to predict from embeddings of discourse units.",
        "translated": "时间压力和话题协商可能会制约人们在自发会话语境中如何利用话语关系。在这项工作中，我们使用了一个书面语言的 DRs 系统，使其能够使用来自新手注释者的众包注释进行自发的对话。然后，我们测试语篇关系是否在不同类型的多话语语境中使用不同。我们比较了说话人内部和跨说话人的 DR 标注模式，以及说话人内部和跨说话人的 DR 标注模式。最终，我们发现不同的话语语境会产生不同的话语关系分布，单圈注释会给注释者带来最大的不确定性。另外，我们发现语篇关系注释具有足够的质量来预测语篇单位的嵌入。"
    },
    {
        "title": "Text Simplification of Scientific Texts for Non-Expert Readers",
        "url": "http://arxiv.org/abs/2307.03569v1",
        "pub_date": "2023-07-07",
        "summary": "Reading levels are highly individual and can depend on a text's language, a\nperson's cognitive abilities, or knowledge on a topic. Text simplification is\nthe task of rephrasing a text to better cater to the abilities of a specific\ntarget reader group. Simplification of scientific abstracts helps non-experts\nto access the core information by bypassing formulations that require domain or\nexpert knowledge. This is especially relevant for, e.g., cancer patients\nreading about novel treatment options. The SimpleText lab hosts the\nsimplification of scientific abstracts for non-experts (Task 3) to advance this\nfield. We contribute three runs employing out-of-the-box summarization models\n(two based on T5, one based on PEGASUS) and one run using ChatGPT with complex\nphrase identification.",
        "translated": "阅读水平是高度个人化的，可以取决于一篇文章的语言，一个人的认知能力，或对一个主题的知识。文本简化是指根据特定目标读者群体的能力对文本进行改写。科学摘要的简化有助于非专家通过绕过需要领域或专家知识的表述方式获取核心信息。这对于癌症患者阅读新的治疗方案尤其重要。SimpleText 实验室为非专家提供科学摘要的简化服务(Task 3) ，以推动这一领域的发展。我们使用开箱即用的摘要模型进行了三次运行(两次基于 T5，一次基于 PEGASUS) ，一次使用带有复杂短语识别的 ChatGPT。"
    },
    {
        "title": "DWReCO at CheckThat! 2023: Enhancing Subjectivity Detection through\n  Style-based Data Sampling",
        "url": "http://arxiv.org/abs/2307.03550v1",
        "pub_date": "2023-07-07",
        "summary": "This paper describes our submission for the subjectivity detection task at\nthe CheckThat! Lab. To tackle class imbalances in the task, we have generated\nadditional training materials with GPT-3 models using prompts of different\nstyles from a subjectivity checklist based on journalistic perspective. We used\nthe extended training set to fine-tune language-specific transformer models.\nOur experiments in English, German and Turkish demonstrate that different\nsubjective styles are effective across all languages. In addition, we observe\nthat the style-based oversampling is better than paraphrasing in Turkish and\nEnglish. Lastly, the GPT-3 models sometimes produce lacklustre results when\ngenerating style-based texts in non-English languages.",
        "translated": "本文介绍了我们在 CheckThat 提交的主观性检测任务！实验室。为了解决这项任务中班级失衡的问题，我们使用 GPT-3模型，从基于新闻视角的主观性检查表中使用不同风格的提示，生成了额外的培训材料。我们使用扩展训练集来微调特定于语言的转换器模型。我们在英语、德语和土耳其语中的实验表明，不同的主观风格在所有语言中都是有效的。此外，我们观察到基于风格的过采样比土耳其语和英语的释义更好。最后，GPT-3模型在生成非英语语言的基于风格的文本时，有时会产生黯淡的结果。"
    },
    {
        "title": "Large Language Models as Batteries-Included Zero-Shot ESCO Skills\n  Matchers",
        "url": "http://arxiv.org/abs/2307.03539v1",
        "pub_date": "2023-07-07",
        "summary": "Understanding labour market dynamics requires accurately identifying the\nskills required for and possessed by the workforce. Automation techniques are\nincreasingly being developed to support this effort. However, automatically\nextracting skills from job postings is challenging due to the vast number of\nexisting skills. The ESCO (European Skills, Competences, Qualifications and\nOccupations) framework provides a useful reference, listing over 13,000\nindividual skills. However, skills extraction remains difficult and accurately\nmatching job posts to the ESCO taxonomy is an open problem. In this work, we\npropose an end-to-end zero-shot system for skills extraction from job\ndescriptions based on large language models (LLMs). We generate synthetic\ntraining data for the entirety of ESCO skills and train a classifier to extract\nskill mentions from job posts. We also employ a similarity retriever to\ngenerate skill candidates which are then re-ranked using a second LLM. Using\nsynthetic data achieves an RP@10 score 10 points higher than previous distant\nsupervision approaches. Adding GPT-4 re-ranking improves RP@10 by over 22\npoints over previous methods. We also show that Framing the task as mock\nprogramming when prompting the LLM can lead to better performance than natural\nlanguage prompts, especially with weaker LLMs. We demonstrate the potential of\nintegrating large language models at both ends of skills matching pipelines.\nOur approach requires no human annotations and achieve extremely promising\nresults on skills extraction against ESCO.",
        "translated": "了解劳动力市场的动态需要准确地确定劳动力所需要和拥有的技能。越来越多的自动化技术正在被开发以支持这种努力。然而，由于现有技能数量庞大，自动从招聘信息中提取技能非常具有挑战性。欧洲技能，能力，资格和职业框架提供了一个有用的参考，列出了超过13,000个人的技能。然而，技能提取仍然困难和准确匹配的工作岗位，以教科文组织的分类是一个公开的问题。在这项工作中，我们提出了一个端到端的零拍摄系统的技能提取工作描述的基础上的大型语言模型(LLM)。我们生成的综合培训数据，为整个电子教科文组织的技能和培训分类器，以提取技能提到的职位。我们还使用一个相似性检索器来生成技能候选者，然后使用第二个 LLM 重新排序。使用合成数据实现了 RP@10得分比以前的远程监控方法高出10分。添加 GPT-4重新排序提高了超过22点的 RP@10比以前的方法。我们还展示了在提示 LLM 时将任务框架为模拟编程，可以比自然语言提示获得更好的性能，特别是对于较弱的 LLM。我们展示了在技能匹配管道的两端集成大型语言模型的潜力。我们的方法不需要人工注释，并取得非常有希望的结果对技能提取反对教科文组织。"
    },
    {
        "title": "Fairness and Diversity in Recommender Systems: A Survey",
        "url": "http://arxiv.org/abs/2307.04644v1",
        "pub_date": "2023-07-10",
        "summary": "Recommender systems are effective tools for mitigating information overload\nand have seen extensive applications across various domains. However, the\nsingle focus on utility goals proves to be inadequate in addressing real-world\nconcerns, leading to increasing attention to fairness-aware and diversity-aware\nrecommender systems. While most existing studies explore fairness and diversity\nindependently, we identify strong connections between these two domains. In\nthis survey, we first discuss each of them individually and then dive into\ntheir connections. Additionally, motivated by the concepts of user-level and\nitem-level fairness, we broaden the understanding of diversity to encompass not\nonly the item level but also the user level. With this expanded perspective on\nuser and item-level diversity, we re-interpret fairness studies from the\nviewpoint of diversity. This fresh perspective enhances our understanding of\nfairness-related work and paves the way for potential future research\ndirections. Papers discussed in this survey along with public code links are\navailable at\nhttps://github.com/YuyingZhao/Awesome-Fairness-and-Diversity-Papers-in-Recommender-Systems .",
        "translated": "推荐系统是缓解信息超载的有效工具，在各个领域得到了广泛的应用。然而，对效用目标的单一关注证明不足以解决现实世界的关切，从而导致对公平意识和多样性意识的推荐系统的日益关注。虽然现有的大多数研究都是独立地探讨公平性和多样性，但我们发现这两个领域之间存在着强烈的联系。在这个调查中，我们首先分别讨论他们，然后深入探讨他们之间的联系。此外，在用户层次和项目层次公平性概念的驱动下，我们拓宽了对多样性的理解，不仅包括项目层次，而且包括用户层次。本文从用户多样性和项目多样性的角度出发，重新解释了公平性研究。这一全新的视角加深了我们对公平相关工作的理解，为未来可能的研究方向铺平了道路。本调查所讨论的文件，连同公众守则的连结，可于 https://github.com/yuyingzhao/awesome-fairness-and-diversity-Papers-in-recommender-systems 下载。"
    },
    {
        "title": "InPars Toolkit: A Unified and Reproducible Synthetic Data Generation\n  Pipeline for Neural Information Retrieval",
        "url": "http://arxiv.org/abs/2307.04601v1",
        "pub_date": "2023-07-10",
        "summary": "Recent work has explored Large Language Models (LLMs) to overcome the lack of\ntraining data for Information Retrieval (IR) tasks. The generalization\nabilities of these models have enabled the creation of synthetic in-domain data\nby providing instructions and a few examples on a prompt. InPars and\nPromptagator have pioneered this approach and both methods have demonstrated\nthe potential of using LLMs as synthetic data generators for IR tasks. This\nmakes them an attractive solution for IR tasks that suffer from a lack of\nannotated data. However, the reproducibility of these methods was limited,\nbecause InPars' training scripts are based on TPUs -- which are not widely\naccessible -- and because the code for Promptagator was not released and its\nproprietary LLM is not publicly accessible. To fully realize the potential of\nthese methods and make their impact more widespread in the research community,\nthe resources need to be accessible and easy to reproduce by researchers and\npractitioners. Our main contribution is a unified toolkit for end-to-end\nreproducible synthetic data generation research, which includes generation,\nfiltering, training and evaluation. Additionally, we provide an interface to IR\nlibraries widely used by the community and support for GPU. Our toolkit not\nonly reproduces the InPars method and partially reproduces Promptagator, but\nalso provides a plug-and-play functionality allowing the use of different LLMs,\nexploring filtering methods and finetuning various reranker models on the\ngenerated data. We also made available all the synthetic data generated in this\nwork for the 18 different datasets in the BEIR benchmark which took more than\n2,000 GPU hours to be generated as well as the reranker models finetuned on the\nsynthetic data. Code and data are available at\nhttps://github.com/zetaalphavector/InPars",
        "translated": "最近的工作已经探索了大语言模型(LLM)来克服缺乏训练数据的信息检索(IR)任务。这些模型的泛化能力通过在提示符上提供指令和一些示例来创建合成的域内数据。InPars 和 Promptagator 是这种方法的先驱，两种方法都展示了将 LLM 用作 IR 任务的合成数据生成器的潜力。这使得它们成为缺乏注释数据的 IR 任务的有吸引力的解决方案。然而，这些方法的可重复性是有限的，因为 InPars 的培训脚本是基于 TPU 的——这不是广泛可访问的——而且因为 Promptagator 的代码没有发布，其专有的 LLM 也不是公开可访问的。为了充分发挥这些方法的潜力并使其影响在研究界更加广泛，研究人员和从业人员必须能够获得并容易复制这些资源。我们的主要贡献是为端到端可重复的综合数据生成研究提供了一个统一的工具包，其中包括生成、过滤、训练和评估。此外，我们还为社区广泛使用的 IR 库提供了一个接口，并支持 GPU。我们的工具包不仅重现了 InPars 方法并部分重现了 Promptagator，而且还提供了即插即用功能，允许使用不同的 LLM，探索过滤方法并在生成的数据上微调各种重新排名模型。我们还提供了所有的合成数据在这项工作中产生的18个不同的数据集在 BEIR 基准，需要超过2000个图形处理器小时以及重新排名模型的合成数据进行微调。代码和数据可在 https://github.com/zetaalphavector/inpars 查阅"
    },
    {
        "title": "A Semi-Automated Solution Approach Selection Tool for Any Use Case via\n  Scopus and OpenAI: a Case Study for AI/ML in Oncology",
        "url": "http://arxiv.org/abs/2307.04573v1",
        "pub_date": "2023-07-10",
        "summary": "In today's vast literature landscape, a manual review is very time-consuming.\nTo address this challenge, this paper proposes a semi-automated tool for\nsolution method review and selection. It caters to researchers, practitioners,\nand decision-makers while serving as a benchmark for future work. The tool\ncomprises three modules: (1) paper selection and scoring, using a keyword\nselection scheme to query Scopus API and compute relevancy; (2) solution method\nextraction in papers utilizing OpenAI API; (3) sensitivity analysis and\npost-analyzes. It reveals trends, relevant papers, and methods. AI in the\noncology case study and several use cases are presented with promising results,\ncomparing the tool to manual ground truth.",
        "translated": "在当今浩瀚的文学世界中，手工复习是非常耗时的。为了解决这个问题，本文提出了一个用于解决方案方法评审和选择的半自动化工具。它迎合了研究人员、从业人员和决策者的需要，同时作为未来工作的基准。该工具包括三个模块: (1)论文选择和评分，使用关键词选择方案查询 Scopus API 并计算相关性; (2)利用 OpenAI API 提取论文中的解决方案方法; (3)敏感度分析和事后分析。它揭示了趋势，相关论文和方法。AI 在肿瘤病例研究和几个用例提出了有希望的结果，比较工具手动地面真相。"
    },
    {
        "title": "Alleviating Matthew Effect of Offline Reinforcement Learning in\n  Interactive Recommendation",
        "url": "http://arxiv.org/abs/2307.04571v1",
        "pub_date": "2023-07-10",
        "summary": "Offline reinforcement learning (RL), a technology that offline learns a\npolicy from logged data without the need to interact with online environments,\nhas become a favorable choice in decision-making processes like interactive\nrecommendation. Offline RL faces the value overestimation problem. To address\nit, existing methods employ conservatism, e.g., by constraining the learned\npolicy to be close to behavior policies or punishing the rarely visited\nstate-action pairs. However, when applying such offline RL to recommendation,\nit will cause a severe Matthew effect, i.e., the rich get richer and the poor\nget poorer, by promoting popular items or categories while suppressing the less\npopular ones. It is a notorious issue that needs to be addressed in practical\nrecommender systems.\n  In this paper, we aim to alleviate the Matthew effect in offline RL-based\nrecommendation. Through theoretical analyses, we find that the conservatism of\nexisting methods fails in pursuing users' long-term satisfaction. It inspires\nus to add a penalty term to relax the pessimism on states with high entropy of\nthe logging policy and indirectly penalizes actions leading to less diverse\nstates. This leads to the main technical contribution of the work: Debiased\nmodel-based Offline RL (DORL) method. Experiments show that DORL not only\ncaptures user interests well but also alleviates the Matthew effect. The\nimplementation is available via https://github.com/chongminggao/DORL-codes.",
        "translated": "离线强化学习(off-line)是一种无需与在线环境交互就可以从记录的数据中学习策略的技术，已经成为诸如交互式推荐等决策过程中的一个有利选择。脱机 RL 面临价值高估问题。为了解决这个问题，现有的方法采用了保守主义，例如，通过限制学习政策接近行为政策或惩罚很少访问的国家行动对。然而，当把这种线下 RL 应用于推荐时，它会产生一种严重的马太效应，也就是说，富人变得更富，穷人变得更穷，通过推销受欢迎的项目或类别，同时压制不太受欢迎的项目或类别。这是一个臭名昭著的问题，需要解决的实际推荐系统。本文旨在减轻基于 RL 的离线推荐中的马太效应。通过理论分析，我们发现现有方法的保守性不足以追求用户的长期满意度。它启发我们增加一个惩罚项，以放松对伐木政策的高熵状态的悲观情绪，并间接惩罚导致较少多样性状态的行动。这导致了这项工作的主要技术贡献: 基于消偏模型的离线 RL (DORL)方法。实验表明，DORL 不仅能够很好地捕获用户的兴趣，而且减轻了马太效应。有关实施方案可透过 https://github.com/chongminggao/dorl-codes 提供。"
    },
    {
        "title": "Counterfactual Explanation for Fairness in Recommendation",
        "url": "http://arxiv.org/abs/2307.04386v1",
        "pub_date": "2023-07-10",
        "summary": "Fairness-aware recommendation eliminates discrimination issues to build\ntrustworthy recommendation systems.Explaining the causes of unfair\nrecommendations is critical, as it promotes fairness diagnostics, and thus\nsecures users' trust in recommendation models. Existing fairness explanation\nmethods suffer high computation burdens due to the large-scale search space and\nthe greedy nature of the explanation search process. Besides, they perform\nscore-based optimizations with continuous values, which are not applicable to\ndiscrete attributes such as gender and race. In this work, we adopt the novel\nparadigm of counterfactual explanation from causal inference to explore how\nminimal alterations in explanations change model fairness, to abandon the\ngreedy search for explanations. We use real-world attributes from Heterogeneous\nInformation Networks (HINs) to empower counterfactual reasoning on discrete\nattributes. We propose a novel Counterfactual Explanation for Fairness\n(CFairER) that generates attribute-level counterfactual explanations from HINs\nfor recommendation fairness. Our CFairER conducts off-policy reinforcement\nlearning to seek high-quality counterfactual explanations, with an attentive\naction pruning reducing the search space of candidate counterfactuals. The\ncounterfactual explanations help to provide rational and proximate explanations\nfor model fairness, while the attentive action pruning narrows the search space\nof attributes. Extensive experiments demonstrate our proposed model can\ngenerate faithful explanations while maintaining favorable recommendation\nperformance.",
        "translated": "公平意识的推荐消除了歧视问题，建立了可信赖的推荐系统。解释不公平推荐的原因是至关重要的，因为它促进了公平诊断，从而保证了用户对推荐模型的信任。现有的公平性解释方法由于搜索空间大和解释搜索过程的贪婪性，计算量大。此外，他们执行连续值的基于分数的优化，这不适用于离散的属性，如性别和种族。本文采用因果推理反事实解释的新范式，探讨解释的微小变化如何改变模型的公平性，摒弃对解释的贪婪追求。我们利用异构信息网络(HIN)中的真实世界属性对离散属性进行反事实推理。我们提出了一种新的推荐公平性反事实解释(CFairER)算法，该算法从 HIN 中生成推荐公平性的属性级反事实解释。我们的 CFairer 进行非政策强化学习，寻求高质量的反事实解释，通过专注的行动精简，减少候选反事实的搜索空间。反事实解释有助于为模型公平性提供合理的近似解释，而注意行为修剪则缩小了属性的搜索空间。大量的实验表明，我们提出的模型可以产生忠实的解释，同时保持良好的推荐性能。"
    },
    {
        "title": "Large Language Models as General Pattern Machines",
        "url": "http://arxiv.org/abs/2307.04721v1",
        "pub_date": "2023-07-10",
        "summary": "We observe that pre-trained large language models (LLMs) are capable of\nautoregressively completing complex token sequences -- from arbitrary ones\nprocedurally generated by probabilistic context-free grammars (PCFG), to more\nrich spatial patterns found in the Abstract Reasoning Corpus (ARC), a general\nAI benchmark, prompted in the style of ASCII art. Surprisingly, pattern\ncompletion proficiency can be partially retained even when the sequences are\nexpressed using tokens randomly sampled from the vocabulary. These results\nsuggest that without any additional training, LLMs can serve as general\nsequence modelers, driven by in-context learning. In this work, we investigate\nhow these zero-shot capabilities may be applied to problems in robotics -- from\nextrapolating sequences of numbers that represent states over time to complete\nsimple motions, to least-to-most prompting of reward-conditioned trajectories\nthat can discover and represent closed-loop policies (e.g., a stabilizing\ncontroller for CartPole). While difficult to deploy today for real systems due\nto latency, context size limitations, and compute costs, the approach of using\nLLMs to drive low-level control may provide an exciting glimpse into how the\npatterns among words could be transferred to actions.",
        "translated": "我们观察到，预先训练的大语言模型(LLM)能够自动回归地完成复杂的标记序列——从由概率上下文无关文法(PCFG)程序化生成的任意标记序列，到抽象推理语料库(ARC)中发现的更丰富的空间模式，ARC 是一个通用的人工智能基准，以 ASCII 艺术的风格提示。令人惊讶的是，即使使用从词汇表中随机抽样的标记来表示序列，模式完成熟练程度也可以部分保留。这些结果表明，没有任何额外的训练，LLM 可以作为一般序列建模，驱动在上下文学习。在这项工作中，我们研究了这些零射击能力如何应用于机器人技术中的问题——从外推代表状态随时间变化的数字序列以完成简单的运动，到最小到最大的奖励条件轨迹提示，这些轨迹可以发现并表示闭环策略(例如，CartPole 的稳定控制器)。尽管由于延迟、上下文大小限制和计算成本等原因，现在很难在真正的系统中部署，但是使用 LLM 来驱动低级控制的方法可以让人们对如何将语言中的模式转化为行动有一个令人兴奋的了解。"
    },
    {
        "title": "BeaverTails: Towards Improved Safety Alignment of LLM via a\n  Human-Preference Dataset",
        "url": "http://arxiv.org/abs/2307.04657v1",
        "pub_date": "2023-07-10",
        "summary": "In this paper, we introduce the BeaverTails dataset, aimed at fostering\nresearch on safety alignment in large language models (LLMs). This dataset\nuniquely separates annotations of helpfulness and harmlessness for\nquestion-answering pairs, thus offering distinct perspectives on these crucial\nattributes. In total, we have compiled safety meta-labels for 30,207\nquestion-answer (QA) pairs and gathered 30,144 pairs of expert comparison data\nfor both the helpfulness and harmlessness metrics. We further showcase\napplications of BeaverTails in content moderation and reinforcement learning\nwith human feedback (RLHF), emphasizing its potential for practical safety\nmeasures in LLMs. We believe this dataset provides vital resources for the\ncommunity, contributing towards the safe development and deployment of LLMs.\nOur project page is available at the following URL:\nhttps://sites.google.com/view/pku-beavertails.",
        "translated": "本文引入 BeaverTails 数据集，旨在促进大语言模型(LLM)中安全校准的研究。这个数据集独特地分离了问答对的有益和无害的注释，从而提供了关于这些关键属性的不同观点。我们总共编制了30,207对问答(QA)的安全元标签，并收集了30,144对专家对有益和无害指标的比较数据。我们进一步展示了 BeaverTails 在内容审核和人工反馈强化学习中的应用，强调了它在 LLM 中实际安全措施的潜力。我们相信这个数据集为社区提供了重要的资源，为 LLM 的安全开发和部署做出了贡献。我们的项目页面可以在以下网址找到:  https://sites.google.com/view/pku-beavertails。"
    },
    {
        "title": "Measuring Lexical Diversity in Texts: The Twofold Length Problem",
        "url": "http://arxiv.org/abs/2307.04626v1",
        "pub_date": "2023-07-10",
        "summary": "The impact of text length on the estimation of lexical diversity has captured\nthe attention of the scientific community for more than a century. Numerous\nindices have been proposed, and many studies have been conducted to evaluate\nthem, but the problem remains. This methodological review provides a critical\nanalysis not only of the most commonly used indices in language learning\nstudies, but also of the length problem itself, as well as of the methodology\nfor evaluating the proposed solutions. The analysis of three datasets of\nEnglish language-learners' texts revealed that indices that reduce all texts to\nthe same length using a probabilistic or an algorithmic approach solve the\nlength dependency problem; however, all these indices failed to address the\nsecond problem, which is their sensitivity to the parameter that determines the\nlength to which the texts are reduced. The paper concludes with recommendations\nfor optimizing lexical diversity analysis.",
        "translated": "一个多世纪以来，文本长度对词汇多样性估计的影响一直受到科学界的关注。已经提出了许多指标，并进行了许多研究来评价它们，但问题仍然存在。本文不仅对语言学习研究中最常用的指标，而且对长度问题本身以及评价所提出的解决方案的方法进行了批判性的分析。对英语学习者文本的三个数据集的分析表明，使用概率或算法方法将所有文本减少到相同长度的指数解决了长度依赖性问题; 然而，所有这些指数都未能解决第二个问题，即它们对决定文本减少长度的参数的敏感性。本文最后提出了优化词汇多样性分析的建议。"
    },
    {
        "title": "On the Computational Modeling of Meaning: Embodied Cognition Intertwined\n  with Emotion",
        "url": "http://arxiv.org/abs/2307.04518v1",
        "pub_date": "2023-07-10",
        "summary": "This document chronicles this author's attempt to explore how words come to\nmean what they do, with a particular focus on child language acquisition and\nwhat that means for models of language understanding.\\footnote{I say\n\\emph{historical} because I synthesize the ideas based on when I discovered\nthem and how those ideas influenced my later thinking.} I explain the setting\nfor child language learning, how embodiment -- being able to perceive and enact\nin the world, including knowledge of concrete and abstract concepts -- is\ncrucial, and how emotion and cognition relate to each other and the language\nlearning process. I end with what I think are some of the requirements for a\nlanguage-learning agent that learns language in a setting similar to that of\nchildren. This paper can act as a potential guide for ongoing and future work\nin modeling language.",
        "translated": "本文档记录了作者试图探索词汇如何意味着它们所做的事情，特别关注儿童语言习得以及这对语言理解模型意味着什么。脚注{我说 emph { history }是因为我是根据我什么时候发现这些想法以及这些想法是如何影响我以后的思考来综合这些想法的。}我解释了儿童语言学习的背景，具体化——能够在世界上感知和表现，包括具体和抽象概念的知识——是如何至关重要的，以及情感和认知如何相互关联和语言学习过程。最后，我想到了一个语言学习机构在类似于儿童的环境中学习语言的一些要求。这篇文章可以作为建模语言正在进行和未来工作的潜在指南。"
    },
    {
        "title": "Improving Factuality of Abstractive Summarization via Contrastive Reward\n  Learning",
        "url": "http://arxiv.org/abs/2307.04507v1",
        "pub_date": "2023-07-10",
        "summary": "Modern abstractive summarization models often generate summaries that contain\nhallucinated or contradictory information. In this paper, we propose a simple\nbut effective contrastive learning framework that incorporates recent\ndevelopments in reward learning and factuality metrics. Empirical studies\ndemonstrate that the proposed framework enables summarization models to learn\nfrom feedback of factuality metrics using contrastive reward learning, leading\nto more factual summaries by human evaluations. This suggests that further\nadvances in learning and evaluation algorithms can feed directly into providing\nmore factual summaries.",
        "translated": "现代抽象摘要模型经常生成包含幻觉或矛盾信息的摘要。在本文中，我们提出了一个简单而有效的对比学习框架，结合奖励学习和事实度量的最新发展。实证研究表明，该框架使总结模型能够利用对比奖励学习从真实性指标的反馈中学习，从而通过人工评估得到更加真实的总结。这表明，学习和评估算法的进一步发展可以直接用于提供更多的事实性摘要。"
    },
    {
        "title": "Enhancing Biomedical Text Summarization and Question-Answering: On the\n  Utility of Domain-Specific Pre-Training",
        "url": "http://arxiv.org/abs/2307.04412v1",
        "pub_date": "2023-07-10",
        "summary": "Biomedical summarization requires large datasets to train for text\ngeneration. We show that while transfer learning offers a viable option for\naddressing this challenge, an in-domain pre-training does not always offer\nadvantages in a BioASQ summarization task. We identify a suitable model\narchitecture and use it to show a benefit of a general-domain pre-training\nfollowed by a task-specific fine-tuning in the context of a BioASQ\nsummarization task, leading to a novel three-step fine-tuning approach that\nworks with only a thousand in-domain examples. Our results indicate that a\nLarge Language Model without domain-specific pre-training can have a\nsignificant edge in some domain-specific biomedical text generation tasks.",
        "translated": "生物医学摘要需要大量的数据集来训练文本生成。我们表明，虽然转移学习提供了一个可行的选择，以解决这一挑战，域内预训练并不总是提供优势，在 BioASQ 摘要任务。我们确定了一个合适的模型架构，并使用它来显示一般领域预训练的好处，然后在 BioASQ 摘要任务的背景下进行任务特定的微调，导致一种新颖的三步微调方法，仅使用一千个域内示例。我们的研究结果表明，一个没有领域特定的预训练的大语言模型可以在一些领域特定的生物医学文本生成任务中具有显著的优势。"
    },
    {
        "title": "TIM: Teaching Large Language Models to Translate with Comparison",
        "url": "http://arxiv.org/abs/2307.04408v1",
        "pub_date": "2023-07-10",
        "summary": "Open-sourced large language models (LLMs) have demonstrated remarkable\nefficacy in various tasks with instruction tuning. However, these models can\nsometimes struggle with tasks that require more specialized knowledge such as\ntranslation. One possible reason for such deficiency is that instruction tuning\naims to generate fluent and coherent text that continues from a given\ninstruction without being constrained by any task-specific requirements.\nMoreover, it can be more challenging for tuning smaller LLMs with lower-quality\ntraining data. To address this issue, we propose a novel framework using\nexamples in comparison to teach LLMs to learn translation. Our approach\ninvolves presenting the model with examples of correct and incorrect\ntranslations and using a preference loss to guide the model's learning. We\nevaluate our method on WMT2022 test sets and show that it outperforms existing\nmethods. Our findings offer a new perspective on fine-tuning LLMs for\ntranslation tasks and provide a promising solution for generating high-quality\ntranslations. Please refer to Github for more details:\nhttps://github.com/lemon0830/TIM.",
        "translated": "开源的大型语言模型(LLM)已经证明了在指令调优的各种任务中显著的效力。然而，这些模型有时可能难以完成需要更专业知识的任务，比如翻译。造成这种缺陷的一个可能的原因是，指令调优的目的是生成从给定指令继续的流畅和连贯的文本，而不受任何特定于任务的要求的限制。此外，使用较低质量的训练数据调优较小的 LLM 可能更具挑战性。为了解决这个问题，我们提出了一个新的框架，使用例子比较教学法学习翻译。我们的方法包括给模型提供正确和错误的翻译实例，并使用偏好损失来指导模型的学习。我们在 WMT2022测试集上对我们的方法进行了评估，结果表明它的性能优于现有的方法。我们的研究结果为翻译任务的微调 LLM 提供了一个新的视角，并为生成高质量的翻译提供了一个有希望的解决方案。详情请参阅 Github:  https://Github.com/lemon0830/tim。"
    },
    {
        "title": "Ethicist: Targeted Training Data Extraction Through Loss Smoothed Soft\n  Prompting and Calibrated Confidence Estimation",
        "url": "http://arxiv.org/abs/2307.04401v1",
        "pub_date": "2023-07-10",
        "summary": "Large pre-trained language models achieve impressive results across many\ntasks. However, recent works point out that pre-trained language models may\nmemorize a considerable fraction of their training data, leading to the privacy\nrisk of information leakage. In this paper, we propose a method named Ethicist\nfor targeted training data extraction through loss smoothed soft prompting and\ncalibrated confidence estimation, investigating how to recover the suffix in\nthe training data when given a prefix. To elicit memorization in the attacked\nmodel, we tune soft prompt embeddings while keeping the model fixed. We further\npropose a smoothing loss that smooths the loss distribution of the suffix\ntokens to make it easier to sample the correct suffix. In order to select the\nmost probable suffix from a collection of sampled suffixes and estimate the\nprediction confidence, we propose a calibrated confidence estimation method,\nwhich normalizes the confidence of the generated suffixes with a local\nestimation. We show that Ethicist significantly improves the extraction\nperformance on a recently proposed public benchmark. We also investigate\nseveral factors influencing the data extraction performance, including decoding\nstrategy, model scale, prefix length, and suffix length. Our code is available\nat https://github.com/thu-coai/Targeted-Data-Extraction.",
        "translated": "大型预训练语言模型在许多任务中都能取得令人印象深刻的结果。然而，最近的研究指出，预先训练的语言模型可能会记住相当一部分的训练数据，导致信息泄露的隐私风险。本文提出了一种基于损失平滑软提示和校准置信度估计的目标训练数据提取方法，研究了在给定前缀的情况下如何恢复训练数据中的后缀。为了在被攻击的模型中诱导记忆，我们在保持模型不变的情况下调整了软提示嵌入。我们进一步提出了一种平滑损失，平滑后缀标记的损失分布，使其更容易采样正确的后缀。为了从采样后缀集合中选择最可能的后缀并估计预测置信度，提出了一种校准的置信度估计方法，该方法通过局部估计对所生成后缀的置信度进行归一化。我们表明，Ethicist 显着提高了最近提出的公共基准的提取性能。我们还研究了几个影响数据提取性能的因素，包括解码策略、模型尺度、前缀长度和后缀长度。我们的代码可以在 https://github.com/thu-coai/targeted-data-extraction 找到。"
    },
    {
        "title": "Enhancing Cross-lingual Transfer via Phonemic Transcription Integration",
        "url": "http://arxiv.org/abs/2307.04361v1",
        "pub_date": "2023-07-10",
        "summary": "Previous cross-lingual transfer methods are restricted to orthographic\nrepresentation learning via textual scripts. This limitation hampers\ncross-lingual transfer and is biased towards languages sharing similar\nwell-known scripts. To alleviate the gap between languages from different\nwriting scripts, we propose PhoneXL, a framework incorporating phonemic\ntranscriptions as an additional linguistic modality beyond the traditional\northographic transcriptions for cross-lingual transfer. Particularly, we\npropose unsupervised alignment objectives to capture (1) local one-to-one\nalignment between the two different modalities, (2) alignment via\nmulti-modality contexts to leverage information from additional modalities, and\n(3) alignment via multilingual contexts where additional bilingual dictionaries\nare incorporated. We also release the first phonemic-orthographic alignment\ndataset on two token-level tasks (Named Entity Recognition and Part-of-Speech\nTagging) among the understudied but interconnected\nChinese-Japanese-Korean-Vietnamese (CJKV) languages. Our pilot study reveals\nphonemic transcription provides essential information beyond the orthography to\nenhance cross-lingual transfer and bridge the gap among CJKV languages, leading\nto consistent improvements on cross-lingual token-level tasks over\northographic-based multilingual PLMs.",
        "translated": "以往的跨语言迁移方法仅限于通过文本脚本进行正字法表征学习。这种限制阻碍了跨语言的传递，并且偏向于共享类似的众所周知的脚本的语言。为了缩小不同书写语言之间的差距，我们提出了 PhoneXL，这是一个包含音素转录的框架，作为传统正字法转录之外的一个额外情态，用于跨语言转换。特别是，我们提出无监督的对齐目标，以捕获(1)两种不同模式之间的局部一对一对齐，(2)通过多模式上下文对齐以利用来自其他模式的信息，以及(3)通过多语言上下文对齐，其中纳入了额外的双语词典。我们还在被研究但相互关联的汉语-日语-韩语-越南语(CJKV)语言中发布了关于两个标记级任务(命名实体识别和词性标记)的第一个音素-正字法对齐数据集。我们的初步研究显示，音位转录提供了正字法之外的重要信息，以增强跨语言转换并弥合 CJKV 语言之间的差距，导致跨语言令牌水平任务相对于基于正字法的多语言 PLM 的一致改进。"
    },
    {
        "title": "RLTF: Reinforcement Learning from Unit Test Feedback",
        "url": "http://arxiv.org/abs/2307.04349v1",
        "pub_date": "2023-07-10",
        "summary": "The goal of program synthesis, or code generation, is to generate executable\ncode based on given descriptions. Recently, there has been an increasing number\nof studies employing reinforcement learning (RL) to improve the performance of\nlarge language models (LLMs) for code. However, these RL methods have only used\noffline frameworks, limiting their exploration of new sample spaces.\nAdditionally, current approaches that utilize unit test signals are rather\nsimple, not accounting for specific error locations within the code. To address\nthese issues, we proposed RLTF, i.e., Reinforcement Learning from Unit Test\nFeedback, a novel online RL framework with unit test feedback of\nmulti-granularity for refining code LLMs. Our approach generates data in\nreal-time during training and simultaneously utilizes fine-grained feedback\nsignals to guide the model towards producing higher-quality code. Extensive\nexperiments show that RLTF achieves state-of-the-art performance on the APPS\nand the MBPP benchmarks. Our code can be found at:\nhttps://github.com/Zyq-scut/RLTF.",
        "translated": "程序合成或代码生成的目标是根据给定的描述生成可执行代码。最近，越来越多的研究使用强化学习(RL)来提高代码的大型语言模型(LLM)的性能。然而，这些 RL 方法只使用了离线框架，限制了它们对新样例空间的探索。此外，利用单元测试信号的当前方法相当简单，没有考虑到代码中特定的错误位置。为了解决这些问题，我们提出了 RLTF，即强化学习于单元测试反馈，这是一个新的在线 RL 框架，具有多粒度的单元测试反馈，用于细化代码 LLM。我们的方法在训练过程中实时生成数据，同时利用细粒度的反馈信号指导模型生成更高质量的代码。大量的实验表明，RLTF 在 APPS 和 MBPP 基准上达到了最先进的性能。我们的代码可以在 https://github.com/zyq-scut/rltf 找到。"
    },
    {
        "title": "Duncode Characters Shorter",
        "url": "http://arxiv.org/abs/2307.05414v1",
        "pub_date": "2023-07-11",
        "summary": "This paper investigates the employment of various encoders in text\ntransformation, converting characters into bytes. It discusses local encoders\nsuch as ASCII and GB-2312, which encode specific characters into shorter bytes,\nand universal encoders like UTF-8 and UTF-16, which can encode the complete\nUnicode set with greater space requirements and are gaining widespread\nacceptance. Other encoders, including SCSU, BOCU-1, and binary encoders,\nhowever, lack self-synchronizing capabilities. Duncode is introduced as an\ninnovative encoding method that aims to encode the entire Unicode character set\nwith high space efficiency, akin to local encoders. It has the potential to\ncompress multiple characters of a string into a Duncode unit using fewer bytes.\nDespite offering less self-synchronizing identification information, Duncode\nsurpasses UTF8 in terms of space efficiency. The application is available at\n\\url{https://github.com/laohur/duncode}. Additionally, we have developed a\nbenchmark for evaluating character encoders across different languages. It\nencompasses 179 languages and can be accessed at\n\\url{https://github.com/laohur/wiki2txt}.",
        "translated": "本文研究了各种编码器在文本转换中的应用，将字符转换为字节。本文讨论了本地编码器，如 ASCII 和 GB-2312，它们将特定字符编码成更短的字节; 还讨论了通用编码器，如 UTF-8和 UTF-16，它们可以对完整的 Unicode 集合进行更大的空间需求编码，并正在获得广泛的认可。但是，其他编码器，包括 SCSU、 BOCU-1和二进制编码器，缺乏自同步功能。Duncode 是一种创新的编码方法，旨在以高空间效率对整个 Unicode字符进行编码，类似于本地编码器。它可以使用更少的字节将字符串的多个字符压缩为 Duncode 单元。尽管 Duncode 提供的自同步识别信息较少，但在空间效率方面超过了 UTF8。申请表格可于网址{ https://github.com/laohur/duncode }下载。此外，我们还开发了一个评估跨不同语言字符编码器的基准。它包含179种语言，可以通过 url { https://github.com/laohur/wiki2txt }访问。"
    },
    {
        "title": "Temporal Graphs Anomaly Emergence Detection: Benchmarking For Social\n  Media Interactions",
        "url": "http://arxiv.org/abs/2307.05268v1",
        "pub_date": "2023-07-11",
        "summary": "Temporal graphs have become an essential tool for analyzing complex dynamic\nsystems with multiple agents. Detecting anomalies in temporal graphs is crucial\nfor various applications, including identifying emerging trends, monitoring\nnetwork security, understanding social dynamics, tracking disease outbreaks,\nand understanding financial dynamics. In this paper, we present a comprehensive\nbenchmarking study that compares 12 data-driven methods for anomaly detection\nin temporal graphs. We conduct experiments on two temporal graphs extracted\nfrom Twitter and Facebook, aiming to identify anomalies in group interactions.\nSurprisingly, our study reveals an unclear pattern regarding the best method\nfor such tasks, highlighting the complexity and challenges involved in anomaly\nemergence detection in large and dynamic systems. The results underscore the\nneed for further research and innovative approaches to effectively detect\nemerging anomalies in dynamic systems represented as temporal graphs.",
        "translated": "时态图已经成为分析多智能体复杂动态系统的重要工具。检测时间图中的异常对于各种应用程序至关重要，包括识别新出现的趋势、监测网络安全、理解社会动态、跟踪疾病爆发以及理解金融动态。在本文中，我们提出了一个全面的基准研究，比较12个数据驱动的方法在时间图中的异常检测。我们对从 Twitter 和 Facebook 上提取的两个时间图进行实验，旨在识别群体互动中的异常现象。令人惊讶的是，我们的研究揭示了一个关于此类任务的最佳方法的模式，突出了在大型和动态系统中异常出现检测所涉及的复杂性和挑战。这些结果强调需要进一步的研究和创新方法，以有效地检测以时间图表示的动态系统中出现的异常。"
    },
    {
        "title": "U-CREAT: Unsupervised Case Retrieval using Events extrAcTion",
        "url": "http://arxiv.org/abs/2307.05260v1",
        "pub_date": "2023-07-11",
        "summary": "The task of Prior Case Retrieval (PCR) in the legal domain is about\nautomatically citing relevant (based on facts and precedence) prior legal cases\nin a given query case. To further promote research in PCR, in this paper, we\npropose a new large benchmark (in English) for the PCR task: IL-PCR (Indian\nLegal Prior Case Retrieval) corpus. Given the complex nature of case relevance\nand the long size of legal documents, BM25 remains a strong baseline for\nranking the cited prior documents. In this work, we explore the role of events\nin legal case retrieval and propose an unsupervised retrieval method-based\npipeline U-CREAT (Unsupervised Case Retrieval using Events Extraction). We find\nthat the proposed unsupervised retrieval method significantly increases\nperformance compared to BM25 and makes retrieval faster by a considerable\nmargin, making it applicable to real-time case retrieval systems. Our proposed\nsystem is generic, we show that it generalizes across two different legal\nsystems (Indian and Canadian), and it shows state-of-the-art performance on the\nbenchmarks for both the legal systems (IL-PCR and COLIEE corpora).",
        "translated": "在法律领域中，先前案例检索(PCR)的任务是在给定的查询案例中自动引用相关的(基于事实和先例)先前的法律案例。为了进一步促进 PCR 的研究，本文提出了一个新的大型基准(英文)的 PCR 任务: IL-PCR (印度法律先例检索)语料库。鉴于案件相关性的复杂性和法律文件的长篇大论，BM25仍然是对所引用的先前文件进行排序的一个有力基准。本文探讨了事件在法律案例检索中的作用，提出了一种基于流水线 U-CREAT 的无监督检索方法。我们发现提出的无监督检索方法与 BM25相比，性能显著提高，检索速度大幅提高，适用于实时案例检索系统。我们提出的系统是通用的，我们表明它概括了两个不同的法律体系(印度和加拿大) ，并且它在两个法律体系(IL-PCR 和 COLIEE cora)的基准上显示了最先进的表现。"
    },
    {
        "title": "Generative Contrastive Graph Learning for Recommendation",
        "url": "http://arxiv.org/abs/2307.05100v1",
        "pub_date": "2023-07-11",
        "summary": "By treating users' interactions as a user-item graph, graph learning models\nhave been widely deployed in Collaborative Filtering(CF) based recommendation.\nRecently, researchers have introduced Graph Contrastive Learning(GCL)\ntechniques into CF to alleviate the sparse supervision issue, which first\nconstructs contrastive views by data augmentations and then provides\nself-supervised signals by maximizing the mutual information between\ncontrastive views. Despite the effectiveness, we argue that current GCL-based\nrecommendation models are still limited as current data augmentation\ntechniques, either structure augmentation or feature augmentation. First,\nstructure augmentation randomly dropout nodes or edges, which is easy to\ndestroy the intrinsic nature of the user-item graph. Second, feature\naugmentation imposes the same scale noise augmentation on each node, which\nneglects the unique characteristics of nodes on the graph. To tackle the above\nlimitations, we propose a novel Variational Graph Generative-Contrastive\nLearning(VGCL) framework for recommendation. Specifically, we leverage\nvariational graph reconstruction to estimate a Gaussian distribution of each\nnode, then generate multiple contrastive views through multiple samplings from\nthe estimated distributions, which builds a bridge between generative and\ncontrastive learning. Besides, the estimated variances are tailored to each\nnode, which regulates the scale of contrastive loss for each node on\noptimization. Considering the similarity of the estimated distributions, we\npropose a cluster-aware twofold contrastive learning, a node-level to encourage\nconsistency of a node's contrastive views and a cluster-level to encourage\nconsistency of nodes in a cluster. Finally, extensive experimental results on\nthree public datasets clearly demonstrate the effectiveness of the proposed\nmodel.",
        "translated": "通过将用户交互作为一个用户项目图，图形学习模型被广泛应用于基于协同过滤(CF)的推荐中。近年来，研究人员将图形对比学习(Graph Contrative Learning，GCL)技术引入到 CF 中，解决了对比视图稀疏监督问题。尽管有效，我们认为，目前基于 GCL 的推荐模型仍然是有限的，作为当前的数据增强技术，无论是结构增强或特征增强。首先，结构扩展随机丢弃节点或边，这很容易破坏用户项图的本质。其次，特征增强对每个节点进行相同尺度的噪声增强，忽略了图上节点的独特性。针对上述局限性，本文提出了一种新的变分图生成对比学习(VGCL)框架。具体来说，我们利用变分图重建来估计每个节点的正态分布，然后从估计的分布中通过多个样本生成多个对比视图，这在生成学习和对比学习之间架起了一座桥梁。此外，估计的方差是针对每个节点量身定制的，它调节了每个节点在优化时的对比损失规模。考虑到估计分布的相似性，我们提出了一种基于聚类的双重对比学习方法，一个节点级别用于增强节点对比视图的一致性，一个聚类级别用于增强聚类中节点的一致性。最后，在三个公共数据集上的大量实验结果清楚地表明了该模型的有效性。"
    },
    {
        "title": "Retrieval-augmented GPT-3.5-based Text-to-SQL Framework with\n  Sample-aware Prompting and Dynamic Revision Chain",
        "url": "http://arxiv.org/abs/2307.05074v1",
        "pub_date": "2023-07-11",
        "summary": "Text-to-SQL aims at generating SQL queries for the given natural language\nquestions and thus helping users to query databases. Prompt learning with large\nlanguage models (LLMs) has emerged as a recent approach, which designs prompts\nto lead LLMs to understand the input question and generate the corresponding\nSQL. However, it faces challenges with strict SQL syntax requirements. Existing\nwork prompts the LLMs with a list of demonstration examples (i.e. question-SQL\npairs) to generate SQL, but the fixed prompts can hardly handle the scenario\nwhere the semantic gap between the retrieved demonstration and the input\nquestion is large. In this paper, we propose a retrieval-augmented prompting\nmethod for a LLM-based Text-to-SQL framework, involving sample-aware prompting\nand a dynamic revision chain. Our approach incorporates sample-aware\ndemonstrations, which include the composition of SQL operators and fine-grained\ninformation related to the given question. To retrieve questions sharing\nsimilar intents with input questions, we propose two strategies for assisting\nretrieval. Firstly, we leverage LLMs to simplify the original questions,\nunifying the syntax and thereby clarifying the users' intentions. To generate\nexecutable and accurate SQLs without human intervention, we design a dynamic\nrevision chain which iteratively adapts fine-grained feedback from the\npreviously generated SQL. Experimental results on three Text-to-SQL benchmarks\ndemonstrate the superiority of our method over strong baseline models.",
        "translated": "Text-to-SQL 旨在为给定的自然语言问题生成 SQL 查询，从而帮助用户查询数据库。使用大型语言模型(LLM)进行快速学习是最近出现的一种方法，它通过设计提示来引导 LLM 理解输入问题并生成相应的 SQL。但是，它面临严格的 SQL 语法要求的挑战。现有的工作提示 LLM 使用一系列演示示例(即问题 -SQL 对)来生成 SQL，但是固定的提示很难处理检索到的演示与输入问题之间的语义差距很大的场景。本文针对基于 LLM 的文本到 SQL 框架提出了一种检索增强提示方法，该方法包括样本感知提示和动态修订链。我们的方法结合了示例感知演示，其中包括 SQL 操作符的组合和与给定问题相关的细粒度信息。为了检索与输入问题意图相似的问题，我们提出了两种辅助检索策略。首先，我们利用 LLM 来简化最初的问题，统一语法，从而澄清用户的意图。为了在不需要人工干预的情况下生成可执行和准确的 SQL，我们设计了一个动态修订链，它可以迭代地适应来自先前生成的 SQL 的细粒度反馈。在三个文本到 SQL 基准测试上的实验结果表明了该方法相对于强基线模型的优越性。"
    }
]
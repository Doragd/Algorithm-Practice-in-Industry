[
    {
        "title": "Exploring the Carbon Footprint of Hugging Face's ML Models: A Repository\n  Mining Study",
        "url": "http://arxiv.org/abs/2305.11164v1",
        "pub_date": "2023-05-18",
        "summary": "The rise of machine learning (ML) systems has exacerbated their carbon\nfootprint due to increased capabilities and model sizes. However, there is\nscarce knowledge on how the carbon footprint of ML models is actually measured,\nreported, and evaluated. In light of this, the paper aims to analyze the\nmeasurement of the carbon footprint of 1,417 ML models and associated datasets\non Hugging Face, which is the most popular repository for pretrained ML models.\nThe goal is to provide insights and recommendations on how to report and\noptimize the carbon efficiency of ML models. The study includes the first\nrepository mining study on the Hugging Face Hub API on carbon emissions. This\nstudy seeks to answer two research questions: (1) how do ML model creators\nmeasure and report carbon emissions on Hugging Face Hub?, and (2) what aspects\nimpact the carbon emissions of training ML models? The study yielded several\nkey findings. These include a decreasing proportion of carbon\nemissions-reporting models, a slight decrease in reported carbon footprint on\nHugging Face over the past 2 years, and a continued dominance of NLP as the\nmain application domain. Furthermore, the study uncovers correlations between\ncarbon emissions and various attributes such as model size, dataset size, and\nML application domains. These results highlight the need for software\nmeasurements to improve energy reporting practices and promote carbon-efficient\nmodel development within the Hugging Face community. In response to this issue,\ntwo classifications are proposed: one for categorizing models based on their\ncarbon emission reporting practices and another for their carbon efficiency.\nThe aim of these classification proposals is to foster transparency and\nsustainable model development within the ML community.",
        "translated": "机器学习(ML)系统的兴起加剧了它们的碳足印，原因是功能和模型尺寸的增加。然而，对于机器学习模型的碳足印实际上是如何测量、报告和评估的，我们知之甚少。有鉴于此，本文旨在分析“拥抱脸”上对1417个机器学习模型及相关数据集的碳足印测量结果。“拥抱脸”是最受欢迎的预训机器学习模型库。目标是就如何报告和优化机器学习模型的碳效率提供见解和建议。这项研究包括第一个关于碳排放的拥抱面中心 API 的知识库挖掘研究。这项研究试图回答两个研究问题: (1)机器学习模型的创建者如何测量和报告拥抱面部中心的碳排放量？以及(2)哪些方面影响训练机器学习模型的碳排放量？这项研究产生了几个关键的发现。其中包括碳排放报告模型的比例下降，过去两年“拥抱脸”上的报告碳足印略有下降，以及自然语言处理作为主要应用领域的持续主导地位。此外，该研究还揭示了碳排放与模型大小、数据集大小和机器学习应用领域等各种属性之间的相关性。这些结果突出了软件测量的必要性，以改善能源报告做法，并促进在拥抱面社区的碳效率模型开发。针对这一问题，提出了两种分类: 一种是根据其碳排放报告做法对模型进行分类，另一种是根据其碳效率进行分类。这些分类建议的目的是在 ML 社区内促进透明度和可持续的模型开发。"
    },
    {
        "title": "TOME: A Two-stage Approach for Model-based Retrieval",
        "url": "http://arxiv.org/abs/2305.11161v1",
        "pub_date": "2023-05-18",
        "summary": "Recently, model-based retrieval has emerged as a new paradigm in text\nretrieval that discards the index in the traditional retrieval model and\ninstead memorizes the candidate corpora using model parameters. This design\nemploys a sequence-to-sequence paradigm to generate document identifiers, which\nenables the complete capture of the relevance between queries and documents and\nsimplifies the classic indexretrieval-rerank pipeline. Despite its attractive\nqualities, there remain several major challenges in model-based retrieval,\nincluding the discrepancy between pre-training and fine-tuning, and the\ndiscrepancy between training and inference. To deal with the above challenges,\nwe propose a novel two-stage model-based retrieval approach called TOME, which\nmakes two major technical contributions, including the utilization of tokenized\nURLs as identifiers and the design of a two-stage generation architecture. We\nalso propose a number of training strategies to deal with the training\ndifficulty as the corpus size increases. Extensive experiments and analysis on\nMS MARCO and Natural Questions demonstrate the effectiveness of our proposed\napproach, and we investigate the scaling laws of TOME by examining various\ninfluencing factors.",
        "translated": "近年来，基于模型的检索已经成为文本检索的一种新范式，它抛弃了传统检索模型中的索引，而是利用模型参数记忆候选语料库。该设计采用序列到序列的方法生成文档标识符，能够完全捕获查询和文档之间的相关性，简化了经典的索引检索-重排序流水线。尽管基于模型的检索具有吸引人的优点，但仍然存在一些主要的挑战，包括预训练和微调之间的差异，以及训练和推理之间的差异。为了应对上述挑战，我们提出了一种新的基于两阶段模型的检索方法，称为 TOME，它做出了两个主要的技术贡献，包括使用标记化 URL 作为标识符和设计一个两阶段生成体系结构。随着语料库规模的增大，我们提出了一些训练策略来解决训练难度。大量的实验和分析 MS MARCO 和自然问题证明了我们提出的方法的有效性，我们研究了 TOME 的缩放规律通过检查各种影响因素。"
    },
    {
        "title": "Preference or Intent? Double Disentangled Collaborative Filtering",
        "url": "http://arxiv.org/abs/2305.11084v1",
        "pub_date": "2023-05-18",
        "summary": "People usually have different intents for choosing items, while their\npreferences under the same intent may also different. In traditional\ncollaborative filtering approaches, both intent and preference factors are\nusually entangled in the modeling process, which significantly limits the\nrobustness and interpretability of recommendation performances. For example,\nthe low-rating items are always treated as negative feedback while they\nactually could provide positive information about user intent. To this end, in\nthis paper, we propose a two-fold representation learning approach, namely\nDouble Disentangled Collaborative Filtering (DDCF), for personalized\nrecommendations. The first-level disentanglement is for separating the\ninfluence factors of intent and preference, while the second-level\ndisentanglement is performed to build independent sparse preference\nrepresentations under individual intent with limited computational complexity.\nSpecifically, we employ two variational autoencoder networks, intent\nrecognition network and preference decomposition network, to learn the intent\nand preference factors, respectively. In this way, the low-rating items will be\ntreated as positive samples for modeling intents while the negative samples for\nmodeling preferences. Finally, extensive experiments on three real-world\ndatasets and four evaluation metrics clearly validate the effectiveness and the\ninterpretability of DDCF.",
        "translated": "人们通常有不同的意图选择项目，而他们的偏好下，相同的意图也可能有所不同。在传统的协同过滤建模方法中，意图和偏好因素通常会在建模过程中纠缠在一起，这极大地限制了推荐性能的稳健性和可解释性。例如，低等级的项目总是被视为负面反馈，而实际上它们可以提供关于用户意图的正面信息。为此，在本文中，我们提出了一种双重表征学习方法，即双重分离协同过滤(DDCF) ，用于个性化推荐。第一级解缠是为了分离意图和偏好的影响因素，而第二级解缠是为了在计算复杂度有限的个体意图下构建独立的稀疏偏好表示。具体来说，我们使用两个变分自动编码器网络，意图识别网络和偏好分解网络，分别学习意图和偏好因素。这样，低等级的项目将被视为建模意图的正面样本，而负面样本将被视为建模偏好。最后，在三个实际数据集和四个评价指标上进行了广泛的实验，验证了 DDCF 的有效性和可解释性。"
    },
    {
        "title": "AMR4NLI: Interpretable and robust NLI measures from semantic graphs",
        "url": "http://arxiv.org/abs/2306.00936v1",
        "pub_date": "2023-06-01",
        "summary": "The task of natural language inference (NLI) asks whether a given premise\n(expressed in NL) entails a given NL hypothesis. NLI benchmarks contain human\nratings of entailment, but the meaning relationships driving these ratings are\nnot formalized. Can the underlying sentence pair relationships be made more\nexplicit in an interpretable yet robust fashion? We compare semantic structures\nto represent premise and hypothesis, including sets of contextualized\nembeddings and semantic graphs (Abstract Meaning Representations), and measure\nwhether the hypothesis is a semantic substructure of the premise, utilizing\ninterpretable metrics. Our evaluation on three English benchmarks finds value\nin both contextualized embeddings and semantic graphs; moreover, they provide\ncomplementary signals, and can be leveraged together in a hybrid model.",
        "translated": "自然语言推理的任务是询问一个给定的前提(用自然语言表示)是否包含一个给定的自然语言假设。NLI 基准包含人工赋值评级，但是驱动这些评级的意义关系并没有形式化。潜在的句子对关系是否可以以一种可解释的、强有力的方式更明确地表达出来？我们比较了表示前提和假设的语义结构，包括语境化嵌入和语义图集(抽象意义表示) ，并利用可解释的度量衡量假设是否是前提的语义子结构。我们对三个英语基准测试的评估发现了上下文嵌入和语义图的价值; 此外，它们提供了互补的信号，并且可以在混合模型中一起使用。"
    },
    {
        "title": "ACLM: A Selective-Denoising based Generative Data Augmentation Approach\n  for Low-Resource Complex NER",
        "url": "http://arxiv.org/abs/2306.00928v1",
        "pub_date": "2023-06-01",
        "summary": "Complex Named Entity Recognition (NER) is the task of detecting\nlinguistically complex named entities in low-context text. In this paper, we\npresent ACLM Attention-map aware keyword selection for Conditional Language\nModel fine-tuning), a novel data augmentation approach based on conditional\ngeneration to address the data scarcity problem in low-resource complex NER.\nACLM alleviates the context-entity mismatch issue, a problem existing NER data\naugmentation techniques suffer from and often generates incoherent\naugmentations by placing complex named entities in the wrong context. ACLM\nbuilds on BART and is optimized on a novel text reconstruction or denoising\ntask - we use selective masking (aided by attention maps) to retain the named\nentities and certain keywords in the input sentence that provide contextually\nrelevant additional knowledge or hints about the named entities. Compared with\nother data augmentation strategies, ACLM can generate more diverse and coherent\naugmentations preserving the true word sense of complex entities in the\nsentence. We demonstrate the effectiveness of ACLM both qualitatively and\nquantitatively on monolingual, cross-lingual, and multilingual complex NER\nacross various low-resource settings. ACLM outperforms all our neural baselines\nby a significant margin (1%-36%). In addition, we demonstrate the application\nof ACLM to other domains that suffer from data scarcity (e.g., biomedical). In\npractice, ACLM generates more effective and factual augmentations for these\ndomains than prior methods. Code: https://github.com/Sreyan88/ACLM",
        "translated": "复杂命名实体识别(NER)是在低语境文本中检测语言复杂命名实体的任务。针对低资源复杂 NER 中的数据稀缺问题，提出了一种基于条件生成的数据增强方法—— ACLM 注意图感知的条件语言模型关键词选择方法。ACLM 缓解了上下文-实体不匹配问题，这是现有的 NER 数据增强技术所面临的问题，并且通常通过将复杂的命名实体放置在错误的上下文中而产生不一致的增强。ACLM 建立在 BART 的基础上，针对一个新的文本重建或去噪任务进行优化——我们使用选择性掩蔽(通过注意力地图辅助)来保留输入句中的命名实体和某些关键字，这些关键字提供了与上下文相关的附加知识或关于命名实体的提示。与其他数据增强策略相比，ACLM 能够产生更多样化和连贯的增强，保持句子中复杂实体的真实词义。我们证明了 ACLM 在定性和定量上对不同低资源环境下的单语言、跨语言和多语言复杂 NER 的有效性。ACLM 比我们所有的神经基线都要好得多(1% -36%)。此外，我们还展示了 ACLM 在其他数据稀缺领域(如生物医学)的应用。在实践中，ACLM 为这些领域产生了比以前的方法更有效和实际的增强。密码:  https://github.com/sreyan88/aclm"
    },
    {
        "title": "SpotTarget: Rethinking the Effect of Target Edges for Link Prediction in\n  Graph Neural Networks",
        "url": "http://arxiv.org/abs/2306.00899v1",
        "pub_date": "2023-06-01",
        "summary": "Graph Neural Networks (GNNs) have demonstrated promising outcomes across\nvarious tasks, including node classification and link prediction. Despite their\nremarkable success in various high-impact applications, we have identified\nthree common pitfalls in message passing for link prediction. Particularly, in\nprevalent GNN frameworks (e.g., DGL and PyTorch-Geometric), the target edges\n(i.e., the edges being predicted) consistently exist as message passing edges\nin the graph during training. Consequently, this results in overfitting and\ndistribution shift, both of which adversely impact the generalizability to test\nthe target edges. Additionally, during test time, the failure to exclude the\ntest target edges leads to implicit test leakage caused by neighborhood\naggregation. In this paper, we analyze these three pitfalls and investigate the\nimpact of including or excluding target edges on the performance of nodes with\nvarying degrees during training and test phases. Our theoretical and empirical\nanalysis demonstrates that low-degree nodes are more susceptible to these\npitfalls. These pitfalls can have detrimental consequences when GNNs are\nimplemented in production systems. To systematically address these pitfalls, we\npropose SpotTarget, an effective and efficient GNN training framework. During\ntraining, SpotTarget leverages our insight regarding low-degree nodes and\nexcludes train target edges connected to at least one low-degree node. During\ntest time, it emulates real-world scenarios of GNN usage in production and\nexcludes all test target edges. Our experiments conducted on diverse real-world\ndatasets, demonstrate that SpotTarget significantly enhances GNNs, achieving up\nto a 15x increase in accuracy in sparse graphs. Furthermore, SpotTarget\nconsistently and dramatically improves the performance for low-degree nodes in\ndense graphs.",
        "translated": "图形神经网络(GNN)在各种任务中，包括节点分类和链路预测，都取得了很好的效果。尽管它们在各种高影响力的应用程序中取得了显著的成功，但是我们已经确定了链接预测中消息传递的三个常见缺陷。特别是，在流行的 GNN 框架(例如，DGL 和 PyTorch-Geometer)中，目标边(例如，被预测的边)在训练期间始终作为图中的消息传递边存在。因此，这会导致过拟合和分布偏移，这两者都会对测试目标边缘的通用性产生不利影响。此外，在测试时间内，未能排除测试目标边缘会导致由邻域聚合引起的隐式测试泄漏。在本文中，我们分析了这三个陷阱，并研究了在训练和测试阶段包含或排除目标边对不同程度的节点性能的影响。我们的理论和实证分析表明，低度节点更容易受到这些陷阱的影响。当 GNN 在生产系统中实现时，这些缺陷可能会产生有害的后果。为了系统地解决这些缺陷，我们提出了 SpotTarget，一个高效的 GNN 训练框架。在训练过程中，SpotTarget 利用我们对低度节点的洞察力，排除了连接到至少一个低度节点的训练目标边缘。在测试期间，它模拟生产中 GNN 使用的真实场景，并排除所有测试目标边缘。我们在不同的真实世界数据集上进行的实验表明，SpotTarget 显著地增强了 GNN，在稀疏图中实现了高达15倍的精度提高。此外，SpotTarget 持续而显著地改善了稠密图中低度节点的性能。"
    },
    {
        "title": "Topic-Guided Sampling For Data-Efficient Multi-Domain Stance Detection",
        "url": "http://arxiv.org/abs/2306.00765v1",
        "pub_date": "2023-06-01",
        "summary": "Stance Detection is concerned with identifying the attitudes expressed by an\nauthor towards a target of interest. This task spans a variety of domains\nranging from social media opinion identification to detecting the stance for a\nlegal claim. However, the framing of the task varies within these domains, in\nterms of the data collection protocol, the label dictionary and the number of\navailable annotations. Furthermore, these stance annotations are significantly\nimbalanced on a per-topic and inter-topic basis. These make multi-domain stance\ndetection a challenging task, requiring standardization and domain adaptation.\nTo overcome this challenge, we propose $\\textbf{T}$opic $\\textbf{E}$fficient\n$\\textbf{St}$anc$\\textbf{E}$ $\\textbf{D}$etection (TESTED), consisting of a\ntopic-guided diversity sampling technique and a contrastive objective that is\nused for fine-tuning a stance classifier. We evaluate the method on an existing\nbenchmark of $16$ datasets with in-domain, i.e. all topics seen and\nout-of-domain, i.e. unseen topics, experiments. The results show that our\nmethod outperforms the state-of-the-art with an average of $3.5$ F1 points\nincrease in-domain, and is more generalizable with an averaged increase of\n$10.2$ F1 on out-of-domain evaluation while using $\\leq10\\%$ of the training\ndata. We show that our sampling technique mitigates both inter- and per-topic\nclass imbalances. Finally, our analysis demonstrates that the contrastive\nlearning objective allows the model a more pronounced segmentation of samples\nwith varying labels.",
        "translated": "姿势检测是指识别作者对于感兴趣的目标所表达的态度。这项任务涉及从社交媒体舆论识别到检测法律诉求立场等多个领域。然而，在这些领域内，任务的框架在数据收集协议、标签字典和可用注释的数量方面有所不同。此外，这些立场注释在每个主题和主题间的基础上显著不平衡。这使得多域姿态检测成为一项具有挑战性的任务，需要标准化和域自适应。为了克服这个挑战，我们提出了 $textbf { T } $opic $textbf { E } $ffical$textbf { St } $anc $textbf { E } $textbf { D } $etection (TESTED) ，包括一个主题引导的多样性采样技术和一个用于微调立场分类器的对比目标。我们评估的方法，在一个现有的基准 $16 $数据集与域内，即所有主题看到和域外，即看不到的主题，实验。结果表明，我们的方法优于国家的最新技术，平均 $3.5 $F1点在域内增加，更具普遍性，平均增加 $10.2 $F1在域外评估，同时使用 $leq10% $的训练数据。我们展示了我们的抽样技术缓解了主题间和主题间的类不平衡。最后，我们的分析表明，对比学习的目标允许模型更明显的样本分割与不同的标签。"
    },
    {
        "title": "End-to-End Document Classification and Key Information Extraction using\n  Assignment Optimization",
        "url": "http://arxiv.org/abs/2306.00750v1",
        "pub_date": "2023-06-01",
        "summary": "We propose end-to-end document classification and key information extraction\n(KIE) for automating document processing in forms. Through accurate document\nclassification we harness known information from templates to enhance KIE from\nforms. We use text and layout encoding with a cosine similarity measure to\nclassify visually-similar documents. We then demonstrate a novel application of\nmixed integer programming by using assignment optimization to extract key\ninformation from documents. Our approach is validated on an in-house dataset of\nnoisy scanned forms. The best performing document classification approach\nachieved 0.97 f1 score. A mean f1 score of 0.94 for the KIE task suggests there\nis significant potential in applying optimization techniques. Abation results\nshow that the method relies on document preprocessing techniques to mitigate\nType II errors and achieve optimal performance.",
        "translated": "我们建议采用端到端文档分类及信息抽取，以自动处理表格内的文件。通过准确的文档分类，我们利用模板中的已知信息来增强表单中的知识工具教育。我们使用文本和布局编码，并采用余弦距离度量方法对视觉上相似的文档进行分类。然后我们展示了一个新的混合整数规划的应用，通过使用分配优化从文档中提取关键信息。我们的方法是在一个有噪声的扫描表单的内部数据集上进行验证的。表现最好的文档分类得分为0.97 f1。KIE 任务的平均 f1得分为0.94，表明应用优化技术有很大的潜力。消减结果表明，该方法依赖于文档预处理技术，以减轻 II 类错误，并取得最佳性能。"
    },
    {
        "title": "TopEx: Topic-based Explanations for Model Comparison",
        "url": "http://arxiv.org/abs/2306.00976v1",
        "pub_date": "2023-06-01",
        "summary": "Meaningfully comparing language models is challenging with current\nexplanation methods. Current explanations are overwhelming for humans due to\nlarge vocabularies or incomparable across models. We present TopEx, an\nexplanation method that enables a level playing field for comparing language\nmodels via model-agnostic topics. We demonstrate how TopEx can identify\nsimilarities and differences between DistilRoBERTa and GPT-2 on a variety of\nNLP tasks.",
        "translated": "对语言模型进行有意义的比较对于当前的解释方法来说是一个挑战。目前的解释对人类来说是压倒性的，因为词汇量很大，或者在不同的模型中是无法比较的。我们提出了 TopEx，一种解释方法，使一个公平的竞争环境比较语言模型通过模型不可知的主题。我们演示了 TopEx 如何在各种 NLP 任务中识别 DistilRoBERTa 和 GPT-2之间的相似点和不同点。"
    },
    {
        "title": "AWQ: Activation-aware Weight Quantization for LLM Compression and\n  Acceleration",
        "url": "http://arxiv.org/abs/2306.00978v1",
        "pub_date": "2023-06-01",
        "summary": "Large language models (LLMs) have shown excellent performance on various\ntasks, but the astronomical model size raises the hardware barrier for serving\n(memory size) and slows down token generation (memory bandwidth). In this\npaper, we propose Activation-aware Weight Quantization (AWQ), a\nhardware-friendly approach for LLM low-bit weight-only quantization. Our method\nis based on the observation that weights are not equally important: protecting\nonly 1% of salient weights can greatly reduce quantization error. We then\npropose to search for the optimal per-channel scaling that protects the salient\nweights by observing the activation, not weights. AWQ does not rely on any\nbackpropagation or reconstruction, so it can well preserve LLMs' generalization\nability on different domains and modalities, without overfitting to the\ncalibration set; it also does not rely on any data layout reordering,\nmaintaining the hardware efficiency. AWQ outperforms existing work on various\nlanguage modeling, common sense QA, and domain-specific benchmarks. Thanks to\nbetter generalization, it achieves excellent quantization performance for\ninstruction-tuned LMs and, for the first time, multi-modal LMs. We also\nimplement efficient tensor core kernels with reorder-free online dequantization\nto accelerate AWQ, achieving a 1.45x speedup over GPTQ and is 1.85x faster than\nthe cuBLAS FP16 implementation. Our method provides a turn-key solution to\ncompress LLMs to 3/4 bits for efficient deployment.",
        "translated": "大型语言模型(LLM)在各种任务中表现出了优异的性能，但是庞大的模型大小增加了服务的硬件障碍(内存大小) ，并减慢了令牌生成(内存带宽)。本文提出了一种基于激活感知的权重量化(AWQ)方法，用于 LLM 低比特权重量化。我们的方法是基于这样的观察: 重量并不同等重要，只保护显著重量的1% 就可以大大减少量化噪声。然后我们建议通过观察激活而不是权值来寻找保护显著权值的最佳通道尺度。AWQ 不依赖任何反向传播或重构，因此它可以很好地保持 LLM 在不同领域和模式下的泛化能力，而不会过度适应校准集; 它也不依赖任何数据布局重排序，保持硬件效率。AWQ 在各种语言建模、常识性 QA 和特定领域基准测试方面的表现优于现有的工作。由于更好的泛化，它实现了优良的量化性能的指令调谐 LM 和第一次，多模态 LM。我们还实现了高效的张量核心，无需重新排序的在线去量化来加速 AWQ，比 GPTQ 提高了1.45倍的速度，比 cuBLAS FP16实现快了1.85倍。我们的方法提供了一个交钥匙解决方案，可以将 LLM 压缩到3/4位，从而实现高效部署。"
    },
    {
        "title": "EEL: Efficiently Encoding Lattices for Reranking",
        "url": "http://arxiv.org/abs/2306.00947v1",
        "pub_date": "2023-06-01",
        "summary": "Standard decoding approaches for conditional text generation tasks typically\nsearch for an output hypothesis with high model probability, but this may not\nyield the best hypothesis according to human judgments of quality. Reranking to\noptimize for \"downstream\" metrics can better optimize for quality, but many\nmetrics of interest are computed with pre-trained language models, which are\nslow to apply to large numbers of hypotheses. We explore an approach for\nreranking hypotheses by using Transformers to efficiently encode lattices of\ngenerated outputs, a method we call EEL. With a single Transformer pass over\nthe entire lattice, we can approximately compute a contextualized\nrepresentation of each token as if it were only part of a single hypothesis in\nisolation. We combine this approach with a new class of token-factored\nrerankers (TFRs) that allow for efficient extraction of high reranker-scoring\nhypotheses from the lattice. Empirically, our approach incurs minimal\ndegradation error compared to the exponentially slower approach of encoding\neach hypothesis individually. When applying EEL with TFRs across three text\ngeneration tasks, our results show both substantial speedup compared to naive\nreranking and often better performance on downstream metrics than comparable\napproaches.",
        "translated": "条件文本生成任务的标准解码方法通常搜索具有高模型概率的输出假设，但这可能不会根据人类对质量的判断产生最佳假设。重新排序以优化“下游”指标可以更好地优化质量，但许多感兴趣的指标是使用预先训练的语言模型计算的，这些模型适用于大量假设的速度很慢。我们探索了一种重新排序假设的方法，通过使用变形金刚有效地编码生成的输出格子，一种方法，我们称之为 EEL。通过一个单变压器遍历整个格子，我们可以近似地计算每个标记的上下文化表示，就好像它只是孤立的单个假设的一部分一样。我们结合这种方法与一类新的令牌因子重排序(TFR) ，允许有效地提取高重排序得分假设从格。根据经验，我们的方法产生最小的退化误差相比，指数较慢的方法编码每个假设单独。在跨三个文本生成任务应用带 TFR 的 EEL 时，我们的结果显示，与初始重新排序相比，EEL 的速度大幅提高，而且下游指标的性能通常比可比方法更好。"
    },
    {
        "title": "Exposing Attention Glitches with Flip-Flop Language Modeling",
        "url": "http://arxiv.org/abs/2306.00946v1",
        "pub_date": "2023-06-01",
        "summary": "Why do large language models sometimes output factual inaccuracies and\nexhibit erroneous reasoning? The brittleness of these models, particularly when\nexecuting long chains of reasoning, currently seems to be an inevitable price\nto pay for their advanced capabilities of coherently synthesizing knowledge,\npragmatics, and abstract thought. Towards making sense of this fundamentally\nunsolved problem, this work identifies and analyzes the phenomenon of attention\nglitches, in which the Transformer architecture's inductive biases\nintermittently fail to capture robust reasoning. To isolate the issue, we\nintroduce flip-flop language modeling (FFLM), a parametric family of synthetic\nbenchmarks designed to probe the extrapolative behavior of neural language\nmodels. This simple generative task requires a model to copy binary symbols\nover long-range dependencies, ignoring the tokens in between. We find that\nTransformer FFLMs suffer from a long tail of sporadic reasoning errors, some of\nwhich we can eliminate using various regularization techniques. Our preliminary\nmechanistic analyses show why the remaining errors may be very difficult to\ndiagnose and resolve. We hypothesize that attention glitches account for (some\nof) the closed-domain hallucinations in natural LLMs.",
        "translated": "为什么大型语言模型有时会输出不准确的事实，并表现出错误的推理？这些模型的脆弱性，特别是在执行长链推理时，目前似乎是为其连贯综合知识、语用学和抽象思维的先进能力付出的不可避免的代价。为了理解这个根本上未解决的问题，本文识别并分析了注意小故障现象，其中变压器结构的感应偏差间歇性地不能捕获鲁棒性推理。为了隔离这个问题，我们引入了触发器语言建模(FFLM) ，这是一个参数化的合成基准，旨在探索神经语言模型的外推行为。这个简单的生成任务需要一个模型在远程依赖关系上复制二进制符号，忽略中间的标记。我们发现变压器 FFLM 存在很多零星的推理错误，我们可以使用各种正则化技术来消除其中的一些错误。我们的初步机理分析表明，为什么剩余的误差可能非常难以诊断和解决。我们假设在自然的 LLM 中，注意力失调可以解释(部分)闭域幻觉。"
    },
    {
        "title": "\"Let's not Quote out of Context\": Unified Vision-Language Pretraining\n  for Context Assisted Image Captioning",
        "url": "http://arxiv.org/abs/2306.00931v1",
        "pub_date": "2023-06-01",
        "summary": "Well-formed context aware image captions and tags in enterprise content such\nas marketing material are critical to ensure their brand presence and content\nrecall. Manual creation and updates to ensure the same is non trivial given the\nscale and the tedium towards this task. We propose a new unified\nVision-Language (VL) model based on the One For All (OFA) model, with a focus\non context-assisted image captioning where the caption is generated based on\nboth the image and its context. Our approach aims to overcome the\ncontext-independent (image and text are treated independently) nature of the\nexisting approaches. We exploit context by pretraining our model with datasets\nof three tasks: news image captioning where the news article is the context,\ncontextual visual entailment, and keyword extraction from the context. The\nsecond pretraining task is a new VL task, and we construct and release two\ndatasets for the task with 1.1M and 2.2K data instances. Our system achieves\nstate-of-the-art results with an improvement of up to 8.34 CIDEr score on the\nbenchmark news image captioning datasets. To the best of our knowledge, ours is\nthe first effort at incorporating contextual information in pretraining the\nmodels for the VL tasks.",
        "translated": "在企业内容(如营销材料)中形成良好的上下文感知图像标题和标签对于确保其品牌存在和内容召回至关重要。手工创建和更新，以确保相同的是不平凡的规模和乏味的这项任务。我们提出了一个新的统一的视觉语言(VL)模型的基础上的一个为所有(OFA)模型，重点是上下文辅助图像字幕生成的标题是基于图像和它的上下文。我们的方法旨在克服现有方法的上下文无关性(图像和文本是独立处理的)。我们利用上下文预训练我们的模型与三个任务的数据集: 新闻图像字幕，其中的新闻文章是上下文，上下文视觉暗示，和关键字提取从上下文。第二个预训练任务是一个新的 VL 任务，我们用1.1 M 和2.2 K 的数据实例构造并发布了两个任务数据集。我们的系统取得了最先进的成果，在基准的新闻图像字幕数据集上提高了高达8.34 CIDEr 得分。据我们所知，我们是第一次尝试将上下文信息合并到 VL 任务的模型预训练中。"
    },
    {
        "title": "Minding Language Models' (Lack of) Theory of Mind: A Plug-and-Play\n  Multi-Character Belief Tracker",
        "url": "http://arxiv.org/abs/2306.00924v1",
        "pub_date": "2023-06-01",
        "summary": "Theory of Mind (ToM)$\\unicode{x2014}$the ability to reason about the mental\nstates of other people$\\unicode{x2014}$is a key element of our social\nintelligence. Yet, despite their ever more impressive performance, large-scale\nneural language models still lack basic theory of mind capabilities\nout-of-the-box. We posit that simply scaling up models will not imbue them with\ntheory of mind due to the inherently symbolic and implicit nature of the\nphenomenon, and instead investigate an alternative: can we design a\ndecoding-time algorithm that enhances theory of mind of off-the-shelf neural\nlanguage models without explicit supervision? We present SymbolicToM, a\nplug-and-play approach to reason about the belief states of multiple characters\nin reading comprehension tasks via explicit symbolic representation. More\nconcretely, our approach tracks each entity's beliefs, their estimation of\nother entities' beliefs, and higher-order levels of reasoning, all through\ngraphical representations, allowing for more precise and interpretable\nreasoning than previous approaches. Empirical results on the well-known ToMi\nbenchmark (Le et al., 2019) demonstrate that SymbolicToM dramatically enhances\noff-the-shelf neural networks' theory of mind in a zero-shot setting while\nshowing robust out-of-distribution performance compared to supervised\nbaselines. Our work also reveals spurious patterns in existing theory of mind\nbenchmarks, emphasizing the importance of out-of-distribution evaluation and\nmethods that do not overfit a particular dataset.",
        "translated": "心理理论对他人心理状态进行推理的能力是我们社会智力的一个关键因素。然而，尽管大规模神经语言模型的表现越来越令人印象深刻，它们仍然缺乏开箱即用的思维能力的基本理论。我们假定，由于这种现象固有的象征性和隐含性，简单地扩大模型不会给它们灌输心智理论，而是研究另一种选择: 我们能否设计一种解码时间算法，在没有明确监督的情况下增强现成神经语言模型的心智理论？我们展示了 SymbolicToM，一种即插即用的方法，通过显式的符号表示来推断阅读理解任务中多个角色的信念状态。更具体地说，我们的方法跟踪每个实体的信念，他们对其他实体信念的估计，以及更高层次的推理，所有这些都通过图形表示，允许比以前的方法更精确和可解释的推理。著名的 ToMi 基准测试(Le et al。 ，2019)的实验结果表明，SymbolicToM 显著增强了现成的神经网络的心智理论，在零拍设置，同时显示出稳健的分布外性能相比，监督基线。我们的工作还揭示了现有心智基准理论中的虚假模式，强调了分布外评估的重要性，以及不适合特定数据集的方法。"
    },
    {
        "title": "T2IAT: Measuring Valence and Stereotypical Biases in Text-to-Image\n  Generation",
        "url": "http://arxiv.org/abs/2306.00905v1",
        "pub_date": "2023-06-01",
        "summary": "Warning: This paper contains several contents that may be toxic, harmful, or\noffensive.\n  In the last few years, text-to-image generative models have gained remarkable\nsuccess in generating images with unprecedented quality accompanied by a\nbreakthrough of inference speed. Despite their rapid progress, human biases\nthat manifest in the training examples, particularly with regard to common\nstereotypical biases, like gender and skin tone, still have been found in these\ngenerative models. In this work, we seek to measure more complex human biases\nexist in the task of text-to-image generations. Inspired by the well-known\nImplicit Association Test (IAT) from social psychology, we propose a novel\nText-to-Image Association Test (T2IAT) framework that quantifies the implicit\nstereotypes between concepts and valence, and those in the images. We replicate\nthe previously documented bias tests on generative models, including morally\nneutral tests on flowers and insects as well as demographic stereotypical tests\non diverse social attributes. The results of these experiments demonstrate the\npresence of complex stereotypical behaviors in image generations.",
        "translated": "警告: 本文件含有多种内容，可能是有毒的，有害的，或攻击性。在过去的几年中，文本到图像的生成模型在生成具有前所未有质量的图像方面取得了显著的成功，同时推理速度也有了突破。尽管进展迅速，但在这些生成模型中仍然发现了在训练实例中表现出来的人为偏见，特别是在性别和肤色等常见的陈规定型偏见方面。在这项工作中，我们试图测量更复杂的人类偏见存在于文本到图像的生成任务。受到来自社会心理学的著名隐含尺度(IAT)的启发，我们提出了一个新颖的文本-图像关联测试(t2IAT)框架，它量化了概念和效价之间以及图像中的内隐刻板印象。我们在生殖模型上重复之前记录的偏见测试，包括对花和昆虫的道德中立测试，以及对不同社会属性的人口统计学刻板印象测试。实验结果表明，在图像生成过程中存在复杂的刻板印象行为。"
    },
    {
        "title": "LLaVA-Med: Training a Large Language-and-Vision Assistant for\n  Biomedicine in One Day",
        "url": "http://arxiv.org/abs/2306.00890v1",
        "pub_date": "2023-06-01",
        "summary": "Conversational generative AI has demonstrated remarkable promise for\nempowering biomedical practitioners, but current investigations focus on\nunimodal text. Multimodal conversational AI has seen rapid progress by\nleveraging billions of image-text pairs from the public web, but such\ngeneral-domain vision-language models still lack sophistication in\nunderstanding and conversing about biomedical images. In this paper, we propose\na cost-efficient approach for training a vision-language conversational\nassistant that can answer open-ended research questions of biomedical images.\nThe key idea is to leverage a large-scale, broad-coverage biomedical\nfigure-caption dataset extracted from PubMed Central, use GPT-4 to\nself-instruct open-ended instruction-following data from the captions, and then\nfine-tune a large general-domain vision-language model using a novel curriculum\nlearning method. Specifically, the model first learns to align biomedical\nvocabulary using the figure-caption pairs as is, then learns to master\nopen-ended conversational semantics using GPT-4 generated instruction-following\ndata, broadly mimicking how a layperson gradually acquires biomedical\nknowledge. This enables us to train a Large Language and Vision Assistant for\nBioMedicine (LLaVA-Med) in less than 15 hours (with eight A100s). LLaVA-Med\nexhibits excellent multimodal conversational capability and can follow\nopen-ended instruction to assist with inquiries about a biomedical image. On\nthree standard biomedical visual question answering datasets, LLaVA-Med\noutperforms previous supervised state-of-the-art on certain metrics. To\nfacilitate biomedical multimodal research, we will release our\ninstruction-following data and the LLaVA-Med model.",
        "translated": "对话生成 AI 已经显示了赋予生物医学从业人员显着的前景，但目前的研究侧重于单一模式的文本。通过利用来自公共网络的数十亿个图像-文本对，多模式会话人工智能已经取得了迅速的进展，但是这种通用领域的视觉-语言模型在理解和对生物医学图像进行会话方面仍然缺乏先进性。本文针对生物医学图像的开放式研究问题，提出了一种具有成本效益的视觉语言会话助手培训方法。其关键思想是利用从 PubMed Central 提取的大规模、广泛覆盖的生物医学图形标题数据集，使用 GPT-4自我指导开放式教学——跟随标题中的数据，然后使用新的课程学习方法微调大型通用领域视觉语言模型。具体而言，该模型首先学习使用图标-标题对来校准生物医学词汇，然后学习使用 GPT-4生成的指令跟踪数据来掌握开放式会话语义，广泛地模仿外行如何逐渐获得生物医学知识。这使得我们能够在不到15个小时的时间内培训一个大型语言和视觉生物医学助手(LLaVA-Med)(有8个 A100s)。LLaVA-Med 具有优秀的多通道会话能力，可以遵循开放式指导，以协助有关生物医学图像的查询。在三个标准的生物医学视觉问答数据集上，LLaVA-Med 在某些指标上优于先前监督的最先进水平。为了促进生物医学多模式研究，我们将发布我们的指令跟踪数据和 LLaVA-Med 模型。"
    },
    {
        "title": "Fresh Content Needs More Attention: Multi-funnel Fresh Content\n  Recommendation",
        "url": "http://arxiv.org/abs/2306.01720v1",
        "pub_date": "2023-06-02",
        "summary": "Recommendation system serves as a conduit connecting users to an incredibly\nlarge, diverse and ever growing collection of contents. In practice, missing\ninformation on fresh (and tail) contents needs to be filled in order for them\nto be exposed and discovered by their audience. We here share our success\nstories in building a dedicated fresh content recommendation stack on a large\ncommercial platform. To nominate fresh contents, we built a multi-funnel\nnomination system that combines (i) a two-tower model with strong\ngeneralization power for coverage, and (ii) a sequence model with near\nreal-time update on user feedback for relevance. The multi-funnel setup\neffectively balances between coverage and relevance. An in-depth study uncovers\nthe relationship between user activity level and their proximity toward fresh\ncontents, which further motivates a contextual multi-funnel setup. Nominated\nfresh candidates are then scored and ranked by systems considering prediction\nuncertainty to further bootstrap content with less exposure. We evaluate the\nbenefits of the dedicated fresh content recommendation stack, and the\nmulti-funnel nomination system in particular, through user corpus co-diverted\nlive experiments. We conduct multiple rounds of live experiments on a\ncommercial platform serving billion of users demonstrating efficacy of our\nproposed methods.",
        "translated": "推荐系统作为一个渠道，连接用户到一个令人难以置信的庞大，多样化和不断增长的内容集合。在实践中，需要填补关于新鲜(和尾部)内容的缺失信息，以便它们被观众暴露和发现。我们在这里分享我们在一个大型商业平台上建立一个专门的新内容推荐堆栈的成功故事。为了提名新的内容，我们建立了一个多漏斗提名系统，该系统结合了(i)一个具有很强覆盖泛化能力的双塔模型和(ii)一个具有近实时更新用户反馈相关性的序列模型。多漏斗设置有效地平衡了覆盖率和相关性。深入的研究揭示了用户活动水平与其接近新鲜内容之间的关系，进一步激发了上下文多漏斗设置。提名的新鲜候选人，然后得分和排名的系统考虑预测不确定性，以进一步引导内容，较少的曝光。我们通过用户语料库共转向现场实验，评估了专用新鲜内容推荐堆栈的优点，尤其是多漏斗提名系统。我们在一个为数十亿用户服务的商业平台上进行多轮实验，证明我们提出的方法的有效性。"
    },
    {
        "title": "Pretrained Language Model based Web Search Ranking: From Relevance to\n  Satisfaction",
        "url": "http://arxiv.org/abs/2306.01599v1",
        "pub_date": "2023-06-02",
        "summary": "Search engine plays a crucial role in satisfying users' diverse information\nneeds. Recently, Pretrained Language Models (PLMs) based text ranking models\nhave achieved huge success in web search. However, many state-of-the-art text\nranking approaches only focus on core relevance while ignoring other dimensions\nthat contribute to user satisfaction, e.g., document quality, recency,\nauthority, etc. In this work, we focus on ranking user satisfaction rather than\nrelevance in web search, and propose a PLM-based framework, namely SAT-Ranker,\nwhich comprehensively models different dimensions of user satisfaction in a\nunified manner. In particular, we leverage the capacities of PLMs on both\ntextual and numerical inputs, and apply a multi-field input that modularizes\neach dimension of user satisfaction as an input field. Overall, SAT-Ranker is\nan effective, extensible, and data-centric framework that has huge potential\nfor industrial applications. On rigorous offline and online experiments,\nSAT-Ranker obtains remarkable gains on various evaluation sets targeting\ndifferent dimensions of user satisfaction. It is now fully deployed online to\nimprove the usability of our search engine.",
        "translated": "搜索引擎在满足用户多样化的信息需求方面起着至关重要的作用。近年来，基于预训练语言模型(PLM)的文本排序模型在网络搜索领域取得了巨大的成功。然而，许多最先进的文本排名方法只关注核心相关性，而忽略了有助于用户满意度的其他方面，如文档质量、最新性、权威性等。在这项工作中，我们的重点是排名用户满意度而不是相关性的网络搜索，并提出了一个基于 PLM 的框架，即 SAT-Ranker，它综合模型的不同维度的用户满意度在统一的方式。特别是，我们利用 PLM 在文本和数字输入方面的能力，并应用多领域的输入，将用户满意度的每个维度模块化，作为输入领域。总的来说，SAT-Ranker 是一个有效的、可扩展的、以数据为中心的框架，在工业应用方面具有巨大的潜力。在严格的离线和在线实验中，SAT-Ranker 在针对不同用户满意度维度的各种评价集上取得了显著的效果。它现在已经完全部署在网上，以提高我们的搜索引擎的可用性。"
    },
    {
        "title": "Influence Maximization with Fairness at Scale (Extended Version)",
        "url": "http://arxiv.org/abs/2306.01587v1",
        "pub_date": "2023-06-02",
        "summary": "In this paper, we revisit the problem of influence maximization with\nfairness, which aims to select k influential nodes to maximise the spread of\ninformation in a network, while ensuring that selected sensitive user\nattributes are fairly affected, i.e., are proportionally similar between the\noriginal network and the affected users. Recent studies on this problem focused\nonly on extremely small networks, hence the challenge remains on how to achieve\na scalable solution, applicable to networks with millions or billions of nodes.\nWe propose an approach that is based on learning node representations for fair\nspread from diffusion cascades, instead of the social connectivity s.t. we can\ndeal with very large graphs. We propose two data-driven approaches: (a)\nfairness-based participant sampling (FPS), and (b) fairness as context (FAC).\nSpread related user features, such as the probability of diffusing information\nto others, are derived from the historical information cascades, using a deep\nneural network. The extracted features are then used in selecting influencers\nthat maximize the influence spread, while being also fair with respect to the\nchosen sensitive attributes. In FPS, fairness and cascade length information\nare considered independently in the decision-making process, while FAC\nconsiders these information facets jointly and considers correlations between\nthem. The proposed algorithms are generic and represent the first policy-driven\nsolutions that can be applied to arbitrary sets of sensitive attributes at\nscale. We evaluate the performance of our solutions on a real-world public\ndataset (Sina Weibo) and on a hybrid real-synthethic dataset (Digg), which\nexhibit all the facets that we exploit, namely diffusion network, diffusion\ntraces, and user profiles. These experiments show that our methods outperform\nthe state-the-art solutions in terms of spread, fairness, and scalability.",
        "translated": "本文重新讨论了公平影响最大化问题，其目的是选择 k 个有影响的节点以使网络中的信息传播最大化，同时确保选择的敏感用户属性受到相当大的影响，即原始网络与受影响用户之间的比例相似。最近关于这个问题的研究只集中在极小的网络上，因此挑战仍然是如何实现一个可伸缩的解决方案，适用于拥有数百万或数十亿个节点的网络。我们提出了一种基于学习节点表示的扩散级联公平扩散方法，代替了社会连通性方法，我们可以处理非常大的图。我们提出两种数据驱动的方法: (a)基于公平的参与者抽样(FPS)和(b)作为上下文的公平(FAC)。传播相关的用户特征，如向他人传播信息的概率，是从历史信息级联，使用深度神经网络推导出来的。然后将提取的特征用于选择影响者，使影响扩散最大化，同时对所选择的敏感属性也是公平的。在 FPS 中，公平性和级联长度信息在决策过程中被独立地考虑，而 FAC 则联合考虑这些信息方面，并考虑它们之间的相关性。提出的算法是通用的，代表了第一个策略驱动的解决方案，可以应用于任意集的敏感属性在规模。我们在一个真实世界的公共数据集(新浪微博)和一个混合的真实合成数据集(Digg)上评估我们的解决方案的性能，这些数据集展示了我们利用的所有方面，即扩散网络、扩散轨迹和用户配置文件。这些实验表明，我们的方法在扩展性、公平性和可伸缩性方面优于最先进的解决方案。"
    },
    {
        "title": "Système de recommandations basé sur les contraintes pour les\n  simulations de gestion de crise",
        "url": "http://arxiv.org/abs/2306.01504v1",
        "pub_date": "2023-06-02",
        "summary": "In the context of the evacuation of populations, some citizens/volunteers may\nwant and be able to participate in the evacuation of populations in difficulty\nby coming to lend a hand to emergency/evacuation vehicles with their own\nvehicles. One way of framing these impulses of solidarity would be to be able\nto list in real-time the citizens/volunteers available with their vehicles\n(land, sea, air, etc.), to be able to geolocate them according to the risk\nareas to be evacuated, and adding them to the evacuation/rescue vehicles.\nBecause it is difficult to propose an effective real-time operational system on\nthe field in a real crisis situation, in this work, we propose to add a module\nfor recommending driver/vehicle pairs (with their specificities) to a system of\ncrisis management simulation. To do that, we chose to model and develop an\nontology-supported constraint-based recommender system for crisis management\nsimulations.",
        "translated": "在疏散人口方面，一些公民/志愿人员可能希望并能够参与疏散有困难的人口，他们可以用自己的车辆向紧急/疏散车辆伸出援手。构建这些团结冲动的一种方式是能够实时列出可用车辆(陆地、海洋、空中等)的公民/志愿者，能够根据疏散的危险区域对他们进行地理定位，并将他们添加到疏散/救援车辆中。由于在真实的危机情况下很难提出一个有效的现场实时操作系统，本文提出在危机管理模拟系统中增加一个推荐驾驶员/车辆配对(及其特殊性)的模块。为此，我们选择建模和开发一个本体支持的基于约束的危机管理模拟推荐系统。"
    },
    {
        "title": "Hierarchical Reinforcement Learning for Modeling User Novelty-Seeking\n  Intent in Recommender Systems",
        "url": "http://arxiv.org/abs/2306.01476v1",
        "pub_date": "2023-06-02",
        "summary": "Recommending novel content, which expands user horizons by introducing them\nto new interests, has been shown to improve users' long-term experience on\nrecommendation platforms \\cite{chen2021values}. Users however are not\nconstantly looking to explore novel content. It is therefore crucial to\nunderstand their novelty-seeking intent and adjust the recommendation policy\naccordingly. Most existing literature models a user's propensity to choose\nnovel content or to prefer a more diverse set of recommendations at individual\ninteractions. Hierarchical structure, on the other hand, exists in a user's\nnovelty-seeking intent, which is manifested as a static and intrinsic user\npreference for seeking novelty along with a dynamic session-based propensity.\nTo this end, we propose a novel hierarchical reinforcement learning-based\nmethod to model the hierarchical user novelty-seeking intent, and to adapt the\nrecommendation policy accordingly based on the extracted user novelty-seeking\npropensity. We further incorporate diversity and novelty-related measurement in\nthe reward function of the hierarchical RL (HRL) agent to encourage user\nexploration \\cite{chen2021values}. We demonstrate the benefits of explicitly\nmodeling hierarchical user novelty-seeking intent in recommendations through\nextensive experiments on simulated and real-world datasets. In particular, we\ndemonstrate that the effectiveness of our proposed hierarchical RL-based method\nlies in its ability to capture such hierarchically-structured intent. As a\nresult, the proposed HRL model achieves superior performance on several public\ndatasets, compared with state-of-art baselines.",
        "translated": "推荐新颖的内容，通过引入新的兴趣拓展用户的视野，已经被证明可以改善用户在推荐平台上的长期体验。然而，用户并不总是寻找新奇的内容。因此，必须了解其寻求新颖性的意图，并相应调整建议政策。大多数现有的文献模拟了用户在个人交互中选择新颖内容或更喜欢多样化推荐的倾向。另一方面，层次结构存在于用户的猎奇意图中，表现为一种静态的、内在的用户猎奇偏好以及一种基于会话的动态倾向。为此，我们提出了一种新的基于层次强化学习的方法来建立层次用户查新意图模型，并根据提取出的用户查新意图相应地调整推荐策略。我们进一步将多样性和新颖性相关度量纳入层次 RL (HRL)代理的奖励功能，以鼓励用户探索引用{ Chen 2021value }。我们通过在模拟和真实世界数据集上的大量实验，展示了在推荐中明确建模分层用户猎奇意图的好处。特别地，我们证明了我们提出的基于层次 RL 的方法的有效性在于它能够捕获这种层次结构的意图。结果表明，所提出的 HRL 模型在多个公共数据集上取得了优于现有基线的性能。"
    },
    {
        "title": "Multilingual Conceptual Coverage in Text-to-Image Models",
        "url": "http://arxiv.org/abs/2306.01735v1",
        "pub_date": "2023-06-02",
        "summary": "We propose \"Conceptual Coverage Across Languages\" (CoCo-CroLa), a technique\nfor benchmarking the degree to which any generative text-to-image system\nprovides multilingual parity to its training language in terms of tangible\nnouns. For each model we can assess \"conceptual coverage\" of a given target\nlanguage relative to a source language by comparing the population of images\ngenerated for a series of tangible nouns in the source language to the\npopulation of images generated for each noun under translation in the target\nlanguage. This technique allows us to estimate how well-suited a model is to a\ntarget language as well as identify model-specific weaknesses, spurious\ncorrelations, and biases without a-priori assumptions. We demonstrate how it\ncan be used to benchmark T2I models in terms of multilinguality, and how\ndespite its simplicity it is a good proxy for impressive generalization.",
        "translated": "我们提出了“跨语言的概念覆盖”(CoCo-CroLa) ，一种基准测试的程度，任何生成性文本到图像系统提供多语言平等的训练语言在有形名词方面。对于每个模型，我们可以通过比较源语言中一系列有形名词生成的图像的总体与目标语言中翻译下的每个名词生成的图像的总体来评估给定目标语言相对于源语言的“概念覆盖”。这种技术使我们能够估计模型与目标语言的匹配程度，并且在没有先验假设的情况下识别特定于模型的弱点、虚假的相关性和偏差。我们展示了如何使用它来基准 T2I 模型的多语言性，以及如何尽管它的简单性，它是一个令人印象深刻的推广良好的代理。"
    },
    {
        "title": "DocFormerv2: Local Features for Document Understanding",
        "url": "http://arxiv.org/abs/2306.01733v1",
        "pub_date": "2023-06-02",
        "summary": "We propose DocFormerv2, a multi-modal transformer for Visual Document\nUnderstanding (VDU). The VDU domain entails understanding documents (beyond\nmere OCR predictions) e.g., extracting information from a form, VQA for\ndocuments and other tasks. VDU is challenging as it needs a model to make sense\nof multiple modalities (visual, language and spatial) to make a prediction. Our\napproach, termed DocFormerv2 is an encoder-decoder transformer which takes as\ninput - vision, language and spatial features. DocFormerv2 is pre-trained with\nunsupervised tasks employed asymmetrically i.e., two novel document tasks on\nencoder and one on the auto-regressive decoder. The unsupervised tasks have\nbeen carefully designed to ensure that the pre-training encourages\nlocal-feature alignment between multiple modalities. DocFormerv2 when evaluated\non nine datasets shows state-of-the-art performance over strong baselines e.g.\nTabFact (4.3%), InfoVQA (1.4%), FUNSD (1%). Furthermore, to show generalization\ncapabilities, on three VQA tasks involving scene-text, Doc- Formerv2\noutperforms previous comparably-sized models and even does better than much\nlarger models (such as GIT2, PaLi and Flamingo) on some tasks. Extensive\nablations show that due to its pre-training, DocFormerv2 understands multiple\nmodalities better than prior-art in VDU.",
        "translated": "我们提出 DocFormerv2，一个用于可视化文档理解(VDU)的多模式转换器。VDU 领域需要理解文档(超越单纯的 OCR 预测) ，例如，从表单中提取信息，文档的 VQA 和其他任务。VDU 是具有挑战性的，因为它需要一个模型来理解多种形式(视觉、语言和空间)来做出预测。我们的方法，称为 DocFormerv2是一个编码器-解码器转换器，它采取作为输入-视觉，语言和空间特征。DocFormerv2预先训练了非对称使用的非监督任务，即编码器上的两个新的文档任务和自动回归解码器上的一个任务。这些无监督的任务经过精心设计，以确保预先培训鼓励多种模式之间的局部特征对齐。对9个数据集进行评估后，DocFormerv2显示出超过强基线的最先进性能，例如 TabFact (4.3%) ，InfoVQA (1.4%) ，FUNSD (1%)。此外，为了显示泛化能力，在涉及场景文本的三个 VQA 任务中，Doc-Formerv2在一些任务中表现优于以前的同等大小的模型，甚至优于更大的模型(如 GIT2、 PaLi 和 Flamingo)。广泛的消融表明，由于其预先培训，DocFormerv2了解多种形式更好地比先前的技术在 VDU。"
    },
    {
        "title": "Improving Generalization in Task-oriented Dialogues with Workflows and\n  Action Plans",
        "url": "http://arxiv.org/abs/2306.01729v1",
        "pub_date": "2023-06-02",
        "summary": "Task-oriented dialogue is difficult in part because it involves understanding\nuser intent, collecting information from the user, executing API calls, and\ngenerating helpful and fluent responses. However, for complex tasks one must\nalso correctly do all of these things over multiple steps, and in a specific\norder. While large pre-trained language models can be fine-tuned end-to-end to\ncreate multi-step task-oriented dialogue agents that generate fluent text, our\nexperiments confirm that this approach alone cannot reliably perform new\nmulti-step tasks that are unseen during training. To address these limitations,\nwe augment the dialogue contexts given to \\textmd{text2text} transformers with\nknown \\textit{valid workflow names} and \\textit{action plans}. Action plans\nconsist of sequences of actions required to accomplish a task, and are encoded\nas simple sequences of keywords (e.g. verify-identity, pull-up-account,\nreset-password, etc.). We perform extensive experiments on the Action-Based\nConversations Dataset (ABCD) with T5-small, base and large models, and show\nthat such models: a) are able to more readily generalize to unseen workflows by\nfollowing the provided plan, and b) are able to generalize to executing unseen\nactions if they are provided in the plan. In contrast, models are unable to\nfully accomplish new multi-step tasks when they are not provided action plan\ninformation, even when given new valid workflow names.",
        "translated": "面向任务的对话之所以困难，部分原因在于它涉及到理解用户的意图、从用户那里收集信息、执行 API 调用以及生成有用而流畅的响应。然而，对于复杂的任务，人们还必须在多个步骤中以特定的顺序正确地完成所有这些事情。虽然大型预先训练的语言模型可以进行端到端的微调，以创建多步骤任务导向的对话代理，生成流畅的文本，我们的实验证实，这种方法本身不能可靠地执行新的多步骤任务，在培训期间看不到。为了解决这些限制，我们使用已知的 texttit {有效的工作流名称}和 texttit {操作计划}增加了为 textmd { text2text }转换器提供的对话上下文。行动计划由完成任务所需的一系列行动组成，并被编码为简单的关键字序列(例如验证身份、上拉帐户、重置密码等)。我们在基于行动的对话数据集(ABCD)上对 T5-小型、基础和大型模型进行了广泛的实验，并表明这样的模型: a)能够通过遵循提供的计划更容易地推广到不可见的工作流，b)能够推广到执行不可见的行动，如果它们在计划中提供。相比之下，模型不能完全完成新的多步骤任务，如果没有提供行动计划信息，即使给出了新的有效工作流名称。"
    },
    {
        "title": "Distilling Efficient Language-Specific Models for Cross-Lingual Transfer",
        "url": "http://arxiv.org/abs/2306.01709v1",
        "pub_date": "2023-06-02",
        "summary": "Massively multilingual Transformers (MMTs), such as mBERT and XLM-R, are\nwidely used for cross-lingual transfer learning. While these are pretrained to\nrepresent hundreds of languages, end users of NLP systems are often interested\nonly in individual languages. For such purposes, the MMTs' language coverage\nmakes them unnecessarily expensive to deploy in terms of model size, inference\ntime, energy, and hardware cost. We thus propose to extract compressed,\nlanguage-specific models from MMTs which retain the capacity of the original\nMMTs for cross-lingual transfer. This is achieved by distilling the MMT\nbilingually, i.e., using data from only the source and target language of\ninterest. Specifically, we use a two-phase distillation approach, termed\nBiStil: (i) the first phase distils a general bilingual model from the MMT,\nwhile (ii) the second, task-specific phase sparsely fine-tunes the bilingual\n\"student\" model using a task-tuned variant of the original MMT as its\n\"teacher\". We evaluate this distillation technique in zero-shot cross-lingual\ntransfer across a number of standard cross-lingual benchmarks. The key results\nindicate that the distilled models exhibit minimal degradation in target\nlanguage performance relative to the base MMT despite being significantly\nsmaller and faster. Furthermore, we find that they outperform multilingually\ndistilled models such as DistilmBERT and MiniLMv2 while having a very modest\ntraining budget in comparison, even on a per-language basis. We also show that\nbilingual models distilled from MMTs greatly outperform bilingual models\ntrained from scratch. Our code and models are available at\nhttps://github.com/AlanAnsell/bistil.",
        "translated": "大规模多语言变换器(MMT) ，如 mBERT 和 XLM-R，被广泛用于跨语言迁移学习。虽然这些语言已经被预先训练成可以代表数百种语言，但是 NLP 系统的最终用户通常只对个别语言感兴趣。出于这样的目的，MMT 的语言覆盖率使得它们在模型大小、推理时间、能量和硬件成本方面的部署成本不必要地昂贵。因此，我们建议从 MMT 中提取压缩的、特定于语言的模型，这些模型保留了原始 MMT 的跨语言迁移能力。这是通过提取双语的 MMT 来实现的，也就是说，只使用感兴趣的源语言和目标语言的数据。具体而言，我们使用两阶段精馏方法，称为 BiStil: (i)第一阶段从 MMT 中提取一般的双语模型，而(ii)第二阶段，任务特定阶段使用原始 MMT 的任务调整变体作为其“老师”稀疏地微调双语“学生”模型。我们评估了这种蒸馏技术在零拍跨语言传输跨一些标准的跨语言基准。实验结果表明，相对于基本 MMT，提取出的模型尽管具有显著的更小和更快的性能，但是在目标语言性能方面表现出最小的退化。此外，我们发现它们的表现优于多语言蒸馏模型，如 DistilmBERT 和 MiniLMv2，同时具有非常有限的培训预算相比，即使在每种语言的基础上。我们还表明，从 MMT 中提炼出来的双语模型比从头开始训练的双语模型的表现要好得多。我们的代码和模型可在 https://github.com/alanansell/bistil 获得。"
    },
    {
        "title": "Resolving Interference When Merging Models",
        "url": "http://arxiv.org/abs/2306.01708v1",
        "pub_date": "2023-06-02",
        "summary": "Transfer learning - i.e., further fine-tuning a pre-trained model on a\ndownstream task - can confer significant advantages, including improved\ndownstream performance, faster convergence, and better sample efficiency. These\nadvantages have led to a proliferation of task-specific fine-tuned models,\nwhich typically can only perform a single task and do not benefit from one\nanother. Recently, model merging techniques have emerged as a solution to\ncombine multiple task-specific models into a single multitask model without\nperforming additional training. However, existing merging methods often ignore\nthe interference between parameters of different models, resulting in large\nperformance drops when merging multiple models. In this paper, we demonstrate\nthat prior merging techniques inadvertently lose valuable information due to\ntwo major sources of interference: (a) interference due to redundant parameter\nvalues and (b) disagreement on the sign of a given parameter's values across\nmodels. To address this, we propose our method, TrIm, Elect Sign &amp; Merge\n(TIES-Merging), which introduces three novel steps when merging models: (1)\nresetting parameters that only changed a small amount during fine-tuning, (2)\nresolving sign conflicts, and (3) merging only the parameters that are in\nalignment with the final agreed-upon sign. We find that TIES-Merging\noutperforms several existing methods in diverse settings covering a range of\nmodalities, domains, number of tasks, model sizes, architectures, and\nfine-tuning settings. We further analyze the impact of different types of\ninterference on model parameters, highlight the importance of resolving sign\ninterference. Our code is available at\nhttps://github.com/prateeky2806/ties-merging",
        "translated": "转移学习——即进一步微调下游任务的预先训练的模型——可以带来显著的优势，包括改善下游性能、加快收敛速度和提高采样效率。这些优势导致了特定于任务的微调模型的激增，这些模型通常只能执行单个任务，并且不能从彼此中受益。最近，模型合并技术已经成为一种解决方案，可以将多个任务特定的模型合并成一个单一的多任务模型，而不需要进行额外的训练。然而，现有的合并方法往往忽略了不同模型参数之间的干扰，导致合并多个模型时性能大幅度下降。在本文中，我们证明了先前的合并技术无意中失去了有价值的信息，由于两个主要的干扰来源: (a)由于冗余参数值的干扰和(b)在给定的参数值的符号不一致跨模型。为了解决这个问题，我们提出了我们的方法，TrIm，Elect Sign & Merge (TIES-Merging) ，它在合并模型时引入了三个新的步骤: (1)重置在微调过程中只改变了很少量的参数，(2)解决符号冲突，(3)只合并与最终达成一致的符号一致的参数。我们发现 TIES-Merging 在不同的设置中优于几种现有的方法，包括一系列模式、领域、任务数量、模型大小、架构和微调设置。进一步分析了不同类型的干扰对模型参数的影响，强调了解决符号干扰的重要性。我们的代码可以在 https://github.com/prateeky2806/ties-merging 找到"
    },
    {
        "title": "Learning Multi-step Reasoning from Arithmetic Task",
        "url": "http://arxiv.org/abs/2306.01707v1",
        "pub_date": "2023-06-02",
        "summary": "Mathematical reasoning is regarded as a necessary ability for Language Models\n(LMs). Recent works demonstrate large LMs' impressive performance in solving\nmath problems. The success is attributed to their Chain-of-Thought (CoT)\nreasoning abilities, i.e., the ability to decompose complex questions into\nstep-by-step reasoning chains, but such ability seems only to emerge from\nmodels with abundant parameters. This work investigates how to incorporate\nrelatively small LMs with the capabilities of multi-step reasoning. We propose\nto inject such abilities by continually pre-training LMs on a synthetic dataset\nMsAT, which stands for Multi-step Arithmetic Task. Our experiments on four math\nword problem datasets show the effectiveness of the proposed method in\nenhancing LMs' math reasoning abilities.",
        "translated": "数学推理被认为是语言模型(LM)的必备能力。最近的作品展示了大型 LM 在解决数学问题方面令人印象深刻的表现。这一成功归功于他们的思维链(Chain-of-Thought，CoT)推理能力，即将复杂问题分解为逐步推理链的能力，但这种能力似乎只出现在参数丰富的模型中。本文研究如何将相对较小的线性规划模型与多步推理能力结合起来。我们建议通过在一个合成数据集 MsAT 上连续预训练 LM 来注入这种能力，MsAT 表示多步算术任务。我们在四个数学词汇问题数据集上的实验表明了该方法在提高 LM 数学推理能力方面的有效性。"
    },
    {
        "title": "Fine-Grained Human Feedback Gives Better Rewards for Language Model\n  Training",
        "url": "http://arxiv.org/abs/2306.01693v1",
        "pub_date": "2023-06-02",
        "summary": "Language models (LMs) often exhibit undesirable text generation behaviors,\nincluding generating false, toxic, or irrelevant outputs. Reinforcement\nlearning from human feedback (RLHF) - where human preference judgments on LM\noutputs are transformed into a learning signal - has recently shown promise in\naddressing these issues. However, such holistic feedback conveys limited\ninformation on long text outputs; it does not indicate which aspects of the\noutputs influenced user preference; e.g., which parts contain what type(s) of\nerrors. In this paper, we use fine-grained human feedback (e.g., which sentence\nis false, which sub-sentence is irrelevant) as an explicit training signal. We\nintroduce Fine-Grained RLHF, a framework that enables training and learning\nfrom reward functions that are fine-grained in two respects: (1) density,\nproviding a reward after every segment (e.g., a sentence) is generated; and (2)\nincorporating multiple reward models associated with different feedback types\n(e.g., factual incorrectness, irrelevance, and information incompleteness). We\nconduct experiments on detoxification and long-form question answering to\nillustrate how learning with such reward functions leads to improved\nperformance, supported by both automatic and human evaluation. Additionally, we\nshow that LM behaviors can be customized using different combinations of\nfine-grained reward models. We release all data, collected human feedback, and\ncodes at https://FineGrainedRLHF.github.io.",
        "translated": "语言模型(LM)经常表现出不良的文本生成行为，包括生成错误的、有毒的或不相关的输出。人类反馈的强化学习——人类对 LM 输出的偏好判断被转化为一个学习信号——最近在解决这些问题方面显示出了希望。然而，这样的整体反馈传达了关于长文本输出的有限信息; 它没有指出输出的哪些方面影响了用户的偏好; 例如，哪些部分包含哪些类型的错误。在本文中，我们使用细粒度的人反馈(例如，哪个句子是错误的，哪个子句是不相关的)作为显性训练信号。我们介绍了细粒度 RLHF，一个框架，使培训和学习奖励功能的细粒度在两个方面: (1)密度，提供奖励后，每个部分(例如，一个句子)生成; 和(2)结合多个奖励模型与不同的反馈类型(例如，事实不正确，不相关性和信息不完整)。我们进行了解毒实验和长形式的问题回答，以说明如何学习与这种奖励功能导致提高绩效，支持自动和人类的评价。此外，我们表明，LM 行为可以定制使用细粒度奖励模型的不同组合。我们发布所有数据，收集人类反馈，并在 https://finegrainedrlhf.github.io 代码。"
    },
    {
        "title": "DiffusEmp: A Diffusion Model-Based Framework with Multi-Grained Control\n  for Empathetic Response Generation",
        "url": "http://arxiv.org/abs/2306.01657v1",
        "pub_date": "2023-06-02",
        "summary": "Empathy is a crucial factor in open-domain conversations, which naturally\nshows one's caring and understanding to others. Though several methods have\nbeen proposed to generate empathetic responses, existing works often lead to\nmonotonous empathy that refers to generic and safe expressions. In this paper,\nwe propose to use explicit control to guide the empathy expression and design a\nframework DiffusEmp based on conditional diffusion language model to unify the\nutilization of dialogue context and attribute-oriented control signals.\nSpecifically, communication mechanism, intent, and semantic frame are imported\nas multi-grained signals that control the empathy realization from coarse to\nfine levels. We then design a specific masking strategy to reflect the\nrelationship between multi-grained signals and response tokens, and integrate\nit into the diffusion model to influence the generative process. Experimental\nresults on a benchmark dataset EmpatheticDialogue show that our framework\noutperforms competitive baselines in terms of controllability, informativeness,\nand diversity without the loss of context-relatedness.",
        "translated": "移情是开放领域对话中的一个关键因素，它自然而然地表现出一个人对他人的关心和理解。虽然已经提出了一些方法来产生移情反应，现有的作品往往导致单调的移情，涉及通用和安全的表达。本文提出用显式控制来引导移情表达，并设计了一个基于条件扩散语言模型的扩散映射框架，统一了对话上下文和面向属性控制信号的利用。具体来说，引入交流机制、意图和语义框架作为多粒度信号，从粗到细控制移情实现。然后我们设计了一个特定的掩蔽策略来反映多粒度信号和响应标记之间的关系，并将其整合到扩散模型中以影响生成过程。在一个基准数据集 EmpatheticDialogue 上的实验结果表明，我们的框架在可控性、信息性和多样性方面优于竞争性基准，而且没有丧失上下文相关性。"
    },
    {
        "title": "Learning from Partially Annotated Data: Example-aware Creation of\n  Gap-filling Exercises for Language Learning",
        "url": "http://arxiv.org/abs/2306.01584v1",
        "pub_date": "2023-06-02",
        "summary": "Since performing exercises (including, e.g., practice tests) forms a crucial\ncomponent of learning, and creating such exercises requires non-trivial effort\nfrom the teacher. There is a great value in automatic exercise generation in\ndigital tools in education. In this paper, we particularly focus on automatic\ncreation of gapfilling exercises for language learning, specifically grammar\nexercises. Since providing any annotation in this domain requires human expert\neffort, we aim to avoid it entirely and explore the task of converting existing\ntexts into new gap-filling exercises, purely based on an example exercise,\nwithout explicit instruction or detailed annotation of the intended grammar\ntopics. We contribute (i) a novel neural network architecture specifically\ndesigned for aforementioned gap-filling exercise generation task, and (ii) a\nreal-world benchmark dataset for French grammar. We show that our model for\nthis French grammar gap-filling exercise generation outperforms a competitive\nbaseline classifier by 8% in F1 percentage points, achieving an average F1\nscore of 82%. Our model implementation and the dataset are made publicly\navailable to foster future research, thus offering a standardized evaluation\nand baseline solution of the proposed partially annotated data prediction task\nin grammar exercise creation.",
        "translated": "因为做练习(包括，例如，练习测试)是学习的重要组成部分，而创建这样的练习需要老师付出非凡的努力。数字化练习工具的自动生成在教育中具有重要的应用价值。在本文中，我们特别关注于语言学习中填空练习的自动生成，尤其是语法练习。由于在这个领域提供任何注释都需要人类专家的努力，我们的目标是完全避免它，并探索将现有文本转换为新的填补空白练习的任务，纯粹基于一个示例练习，没有明确的指示或预期的语法主题的详细注释。我们贡献了(i)一个新的神经网络架构，专门设计的上述缺口填补练习生成任务，和(ii)法语语法的现实世界基准数据集。我们表明，我们的模型为这个法语语法差距填补练习生成优于竞争性基线分类器8% 的 F1百分点，实现平均 F1得分为82% 。我们的模型实现和数据集是公开的，以促进未来的研究，从而提供了一个标准化的评价和基线解决方案的建议部分注释数据预测任务在语法练习创建。"
    },
    {
        "title": "EmoUS: Simulating User Emotions in Task-Oriented Dialogues",
        "url": "http://arxiv.org/abs/2306.01579v1",
        "pub_date": "2023-06-02",
        "summary": "Existing user simulators (USs) for task-oriented dialogue systems only model\nuser behaviour on semantic and natural language levels without considering the\nuser persona and emotions. Optimising dialogue systems with generic user\npolicies, which cannot model diverse user behaviour driven by different\nemotional states, may result in a high drop-off rate when deployed in the real\nworld. Thus, we present EmoUS, a user simulator that learns to simulate user\nemotions alongside user behaviour. EmoUS generates user emotions, semantic\nactions, and natural language responses based on the user goal, the dialogue\nhistory, and the user persona. By analysing what kind of system behaviour\nelicits what kind of user emotions, we show that EmoUS can be used as a probe\nto evaluate a variety of dialogue systems and in particular their effect on the\nuser's emotional state. Developing such methods is important in the age of\nlarge language model chat-bots and rising ethical concerns.",
        "translated": "现有的面向任务对话系统的用户模拟器(USs)只是在语义和自然语言层面上对用户行为进行建模，而没有考虑用户角色和情感。使用通用用户策略优化对话系统，不能模拟由不同情绪状态驱动的不同用户行为，在现实世界中部署时可能导致较高的下降率。因此，我们提出了 emoUS，一个用户模拟器，学习模拟用户的情绪以及用户的行为。基于用户目标、对话历史和用户角色，EmoUS 产生用户情绪、语义动作和自然语言反应。通过分析什么样的系统行为引发了什么样的用户情绪，我们表明，情绪美可以作为一个探测器来评估各种对话系统，特别是他们对用户的情绪状态的影响。在大型语言模型聊天机器人时代，开发这样的方法非常重要，同时也引起了越来越多的道德关注。"
    },
    {
        "title": "Learning Similarity among Users for Personalized Session-Based\n  Recommendation from hierarchical structure of User-Session-Item",
        "url": "http://arxiv.org/abs/2306.03040v1",
        "pub_date": "2023-06-05",
        "summary": "The task of the session-based recommendation is to predict the next\ninteraction of the user based on the anonymized user's behavior pattern. And\npersonalized version of this system is a promising research field due to its\navailability to deal with user information. However, there's a problem that the\nuser's preferences and historical sessions were not considered in the typical\nsession-based recommendation since it concentrates only on user-item\ninteraction. In addition, the existing personalized session-based\nrecommendation model has a limited capability in that it only considers the\npreference of the current user without considering those of similar users. It\nmeans there can be the loss of information included within the hierarchical\ndata structure of the user-session-item. To tackle with this problem, we\npropose USP-SBR(abbr. of User Similarity Powered - Session Based Recommender).\nTo model global historical sessions of users, we propose UserGraph that has two\ntypes of nodes - ItemNode and UserNode. We then connect the nodes with three\ntypes of edges. The first type of edges connects ItemNode as chronological\norder, and the second connects ItemNode to UserNode, and the last connects\nUserNode to ItemNode. With these user embeddings, we propose additional\ncontrastive loss, that makes users with similar intention be close to each\nother in the vector space. we apply graph neural network on these UserGraph and\nupdate nodes. Experimental results on two real-world datasets demonstrate that\nour method outperforms some state-of-the-art approaches.",
        "translated": "基于会话的推荐的任务是根据匿名用户的行为模式预测用户的下一次交互。而个性化版本的系统由于能够有效地处理用户信息，是一个很有前途的研究领域。然而，有一个问题，在典型的基于会话的推荐中没有考虑用户的首选项和历史会话，因为它只关注用户项交互。此外，现有的基于个性化会话的推荐模型能力有限，因为它只考虑当前用户的偏好，而不考虑相似用户的偏好。这意味着用户会话项的分层数据结构中包含的信息可能会丢失。为了解决这一问题，我们提出了 USP-SBR (abbr。基于用户相似度的动态会话推荐程序)。为了对用户的全局历史会话进行建模，我们提出了具有两种类型节点的 UserGraph —— ItemNode 和 UserNode。然后我们用三种边连接节点。第一种边以时间顺序连接 ItemNode，第二种边将 ItemNode 连接到 UserNode，最后一种边将 UserNode 连接到 ItemNode。通过这些用户嵌入，我们提出了额外的对比损失，使得具有相似意图的用户在向量空间中更加接近。我们将图形神经网络应用于这些用户图和更新节点。在两个实际数据集上的实验结果表明，我们的方法优于一些最先进的方法。"
    },
    {
        "title": "Gen-IR @ SIGIR 2023: The First Workshop on Generative Information\n  Retrieval",
        "url": "http://arxiv.org/abs/2306.02887v1",
        "pub_date": "2023-06-05",
        "summary": "Generative information retrieval (IR) has experienced substantial growth\nacross multiple research communities (e.g., information retrieval, computer\nvision, natural language processing, and machine learning), and has been highly\nvisible in the popular press. Theoretical, empirical, and actual user-facing\nproducts have been released that retrieve documents (via generation) or\ndirectly generate answers given an input request. We would like to investigate\nwhether end-to-end generative models are just another trend or, as some claim,\na paradigm change for IR. This necessitates new metrics, theoretical grounding,\nevaluation methods, task definitions, models, user interfaces, etc. The goal of\nthis workshop (https://coda.io/@sigir/gen-ir) is to focus on previously\nexplored Generative IR techniques like document retrieval and direct Grounded\nAnswer Generation, while also offering a venue for the discussion and\nexploration of how Generative IR can be applied to new domains like\nrecommendation systems, summarization, etc. The format of the workshop is\ninteractive, including roundtable and keynote sessions and tends to avoid the\none-sided dialogue of a mini-conference.",
        "translated": "生成信息检索在多个研究领域(如信息检索、计算机视觉、自然语言处理和机器学习)都经历了实质性的增长，并且在大众媒体上非常明显。理论、经验和实际的面向用户的产品已经发布，检索文档(通过生成)或直接生成给定输入请求的答案。我们想要研究的是，端到端的生成模型是否只是另一种趋势，或者，正如一些人声称的，一个范式变化的 IR。这就需要新的指标、理论基础、评估方法、任务定义、模型、用户界面等。这个研讨会( https://coda.io/@sigir/gen-IR )的目标是专注于先前探索的生成性信息检索技术，如文献检索和直接接地的答案生成，同时也为讨论和探索生成性信息检索如何应用于新的领域，如推荐系统，摘要等提供了场所。讲习班的形式是互动的，包括圆桌会议和主旨会议，往往避免小型会议的单方面对话。"
    },
    {
        "title": "Benchmarking Middle-Trained Language Models for Neural Search",
        "url": "http://arxiv.org/abs/2306.02867v1",
        "pub_date": "2023-06-05",
        "summary": "Middle training methods aim to bridge the gap between the Masked Language\nModel (MLM) pre-training and the final finetuning for retrieval. Recent models\nsuch as CoCondenser, RetroMAE, and LexMAE argue that the MLM task is not\nsufficient enough to pre-train a transformer network for retrieval and hence\npropose various tasks to do so. Intrigued by those novel methods, we noticed\nthat all these models used different finetuning protocols, making it hard to\nassess the benefits of middle training. We propose in this paper a benchmark of\nCoCondenser, RetroMAE, and LexMAE, under the same finetuning conditions. We\ncompare both dense and sparse approaches under various finetuning protocols and\nmiddle training on different collections (MS MARCO, Wikipedia or Tripclick). We\nuse additional middle training baselines, such as a standard MLM finetuning on\nthe retrieval collection, optionally augmented by a CLS predicting the passage\nterm frequency. For the sparse approach, our study reveals that there is almost\nno statistical difference between those methods: the more effective the\nfinetuning procedure is, the less difference there is between those models. For\nthe dense approach, RetroMAE using MS MARCO as middle-training collection shows\nexcellent results in almost all the settings. Finally, we show that middle\ntraining on the retrieval collection, thus adapting the language model to it,\nis a critical factor. Overall, a better experimental setup should be adopted to\nevaluate middle training methods. Code available at\nhttps://github.com/naver/splade/tree/benchmarch-SIGIR23",
        "translated": "中间训练方法旨在弥补蒙版语言模型(MLM)预训练和检索的最终微调之间的差距。最近的一些模型，如 CoCondenser，RotMAE 和 LexMAE 认为传销任务不足以预先训练一个变压器网络进行检索，因此提出了各种各样的任务来这样做。被这些新奇的方法所吸引，我们注意到所有这些模型使用不同的微调协议，使得评估中间训练的好处变得困难。在本文中，我们提出了一个基准的协同凝聚器，反向 MAE 和 LexMAE，在相同的微调条件下。我们比较了在各种微调协议和不同集合(MS MARCO，Wikipedia 或 Tripclick)的中间培训下的密集和稀疏方法。我们使用额外的中间训练基线，例如在检索集合上的标准 MLM 微调，可选地通过预测通过项频率的 CLS 加强。对于稀疏方法，我们的研究表明，这些方法之间几乎没有统计上的差异: 微调过程越有效，这些模型之间的差异就越小。对于密集的方法，使用 MS MARCO 作为中间训练收集在几乎所有的设置中都显示出优异的结果。最后，我们表明，中间训练的检索集，从而使语言模型适应它，是一个关键因素。总的来说，应该采用更好的实验设置来评价中间训练方法。Https://github.com/naver/splade/tree/benchmarch-sigir23提供密码"
    },
    {
        "title": "CTRL: Connect Tabular and Language Model for CTR Prediction",
        "url": "http://arxiv.org/abs/2306.02841v1",
        "pub_date": "2023-06-05",
        "summary": "Traditional click-through rate (CTR) prediction models convert the tabular\ndata into one-hot vectors and leverage the collaborative relations among\nfeatures for inferring user's preference over items. This modeling paradigm\ndiscards the essential semantic information. Though some recent works like P5\nand M6-Rec have explored the potential of using Pre-trained Language Models\n(PLMs) to extract semantic signals for CTR prediction, they are computationally\nexpensive and suffer from low efficiency. Besides, the beneficial collaborative\nrelations are not considered, hindering the recommendation performance. To\nsolve these problems, in this paper, we propose a novel framework\n\\textbf{CTRL}, which is industrial friendly and model-agnostic with high\ntraining and inference efficiency. Specifically, the original tabular data is\nfirst converted into textual data. Both tabular data and converted textual data\nare regarded as two different modalities and are separately fed into the\ncollaborative CTR model and pre-trained language model. A cross-modal knowledge\nalignment procedure is performed to fine-grained align and integrate the\ncollaborative and semantic signals, and the lightweight collaborative model can\nbe deployed online for efficient serving after fine-tuned with supervised\nsignals. Experimental results on three public datasets show that CTRL\noutperforms the SOTA CTR models significantly. Moreover, we further verify its\neffectiveness on a large-scale industrial recommender system.",
        "translated": "传统的点进率预测模型将表格数据转换为一个热点向量，并利用特征之间的协同关系来推断用户对项目的偏好。这种建模范式抛弃了基本的语义信息。虽然最近的一些工作，如 P5和 M6-Rec 已经探索了使用预训练语言模型(PLM)提取语义信号进行 CTR 预测的潜力，但是它们的计算成本高，效率低。此外，没有考虑到有益的协作关系，阻碍了推荐绩效的提高。为了解决这些问题，本文提出了一种新的框架 textbf { CTRL } ，该框架具有良好的工业友好性和模型无关性，并且具有较高的训练和推理效率。具体来说，首先将原始表格数据转换为文本数据。将表格数据和转换后的文本数据视为两种不同的模式，分别输入协同 CTR 模型和预训练语言模型。通过跨模态知识对齐过程对协作信号和语义信号进行细粒度对齐和集成，并对监督信号进行细调后，可以在线部署轻量级协作模型，实现高效服务。在三个公共数据集上的实验结果表明，CTRL 模型的性能明显优于 SOTA CTR 模型。此外，我们进一步验证了该方法在大规模工业推荐系统上的有效性。"
    },
    {
        "title": "Path-Specific Counterfactual Fairness for Recommender Systems",
        "url": "http://arxiv.org/abs/2306.02615v1",
        "pub_date": "2023-06-05",
        "summary": "Recommender systems (RSs) have become an indispensable part of online\nplatforms. With the growing concerns of algorithmic fairness, RSs are not only\nexpected to deliver high-quality personalized content, but are also demanded\nnot to discriminate against users based on their demographic information.\nHowever, existing RSs could capture undesirable correlations between sensitive\nfeatures and observed user behaviors, leading to biased recommendations. Most\nfair RSs tackle this problem by completely blocking the influences of sensitive\nfeatures on recommendations. But since sensitive features may also affect user\ninterests in a fair manner (e.g., race on culture-based preferences),\nindiscriminately eliminating all the influences of sensitive features\ninevitably degenerate the recommendations quality and necessary diversities. To\naddress this challenge, we propose a path-specific fair RS (PSF-RS) for\nrecommendations. Specifically, we summarize all fair and unfair correlations\nbetween sensitive features and observed ratings into two latent proxy\nmediators, where the concept of path-specific bias (PS-Bias) is defined based\non path-specific counterfactual inference. Inspired by Pearl's minimal change\nprinciple, we address the PS-Bias by minimally transforming the biased factual\nworld into a hypothetically fair world, where a fair RS model can be learned\naccordingly by solving a constrained optimization problem. For the technical\npart, we propose a feasible implementation of PSF-RS, i.e., PSF-VAE, with\nweakly-supervised variational inference, which robustly infers the latent\nmediators such that unfairness can be mitigated while necessary recommendation\ndiversities can be maximally preserved simultaneously. Experiments conducted on\nsemi-simulated and real-world datasets demonstrate the effectiveness of PSF-RS.",
        "translated": "推荐系统已经成为在线平台不可或缺的一部分。随着对算法公平性的日益关注，RSS 不仅被期望提供高质量的个性化内容，而且被要求不因用户的人口统计信息而歧视用户。然而，现有的 RSS 可能捕获敏感特性和观察到的用户行为之间不希望看到的相关性，从而导致有偏见的推荐。大多数公平的 RSS 通过完全阻止敏感特性对建议的影响来解决这个问题。但是，由于敏感特性也可能以公平的方式影响用户的兴趣(例如，基于文化的偏好的种族) ，不加区分地消除敏感特性的所有影响必然会降低推荐的质量和必要的多样性。为了应对这一挑战，我们提出了一个路径特定的公平 RS (PSF-RS)的建议。具体而言，我们将敏感特征和观察评分之间的所有公平和不公平的相关性总结为两个潜在的代理中介，其中路径特异性偏倚(PS-Bias)的概念是基于路径特异性反事实推断定义的。受珀尔的最小改变原则的启发，我们通过最小化地将有偏见的现实世界转化为一个假设的公平世界，在这个假设的公平世界中，通过解决一个受限制的最佳化问题，可以相应地学习一个公平的遥感模型，从而解决偏差问题。在技术部分，我们提出了一种可行的 PSF-RS 的实现方法，即弱监督变分推理 PSF-VAE，它可以强有力地推断出潜在的中介因子，从而在最大限度地保留必要的推荐多样性的同时，减少不公平性。在半模拟和真实数据集上进行的实验证明了 PSF-RS 算法的有效性。"
    },
    {
        "title": "RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems",
        "url": "http://arxiv.org/abs/2306.03091v1",
        "pub_date": "2023-06-05",
        "summary": "Large Language Models (LLMs) have greatly advanced code auto-completion\nsystems, with a potential for substantial productivity enhancements for\ndevelopers. However, current benchmarks mainly focus on single-file tasks,\nleaving an assessment gap for more complex, real-world, multi-file programming\nscenarios. To fill this gap, we introduce RepoBench, a new benchmark\nspecifically designed for evaluating repository-level code auto-completion\nsystems. RepoBench consists of three interconnected evaluation tasks:\nRepoBench-R (Retrieval), RepoBench-C (Code Completion), and RepoBench-P\n(Pipeline). Each task respectively measures the system's ability to retrieve\nthe most relevant code snippets from other files as cross-file context, predict\nthe next line of code with cross-file and in-file context, and handle complex\ntasks that require a combination of both retrieval and next-line prediction.\nRepoBench aims to facilitate a more complete comparison of performance and\nencouraging continuous improvement in auto-completion systems. RepoBench is\npublicly available at https://github.com/Leolty/repobench.",
        "translated": "大型语言模型(Large Language Model，LLM)具有非常先进的代码自动完成系统，对于开发人员来说，这有可能大大提高生产力。然而，当前的基准测试主要集中在单文件任务上，对于更复杂的、真实的、多文件编程场景留下了评估空白。为了填补这个空白，我们引入了 RepoBench，这是一个专门为评估存储库级代码自动完成系统而设计的新基准。RepoBench 由三个相互连接的评估任务组成: RepoBench-R (检索)、 RepoBench-C (代码完成)和 RepoBench-P (管道)。每个任务分别测量系统从其他文件中检索最相关代码片段作为跨文件上下文的能力，用跨文件和文件内上下文预测下一行代码的能力，以及处理需要检索和下一行预测相结合的复杂任务的能力。RepoBench 旨在促进更全面的性能比较，并鼓励自动完成系统的持续改进。RepoBench 可在 https://github.com/leolty/RepoBench 公开使用。"
    },
    {
        "title": "Is ChatGPT a Good Teacher Coach? Measuring Zero-Shot Performance For\n  Scoring and Providing Actionable Insights on Classroom Instruction",
        "url": "http://arxiv.org/abs/2306.03090v1",
        "pub_date": "2023-06-05",
        "summary": "Coaching, which involves classroom observation and expert feedback, is a\nwidespread and fundamental part of teacher training. However, the majority of\nteachers do not have access to consistent, high quality coaching due to limited\nresources and access to expertise. We explore whether generative AI could\nbecome a cost-effective complement to expert feedback by serving as an\nautomated teacher coach. In doing so, we propose three teacher coaching tasks\nfor generative AI: (A) scoring transcript segments based on classroom\nobservation instruments, (B) identifying highlights and missed opportunities\nfor good instructional strategies, and (C) providing actionable suggestions for\neliciting more student reasoning. We recruit expert math teachers to evaluate\nthe zero-shot performance of ChatGPT on each of these tasks for elementary math\nclassroom transcripts. Our results reveal that ChatGPT generates responses that\nare relevant to improving instruction, but they are often not novel or\ninsightful. For example, 82% of the model's suggestions point to places in the\ntranscript where the teacher is already implementing that suggestion. Our work\nhighlights the challenges of producing insightful, novel and truthful feedback\nfor teachers while paving the way for future research to address these\nobstacles and improve the capacity of generative AI to coach teachers.",
        "translated": "辅导，包括课堂观察和专家反馈，是教师培训的一个广泛而基本的组成部分。然而，由于资源和专业知识有限，大多数教师无法获得连贯、高质量的辅导。我们探讨生成式人工智能是否可以成为一个具有成本效益的专家反馈的补充，作为一个自动化的教师教练。在这样做时，我们提出了三个生成性人工智能的教师培训任务: (A)基于课堂观察工具评分成绩单片段，(B)识别优秀教学策略的亮点和错过的机会，以及(C)提供可行的建议，以引发更多的学生推理。我们招募数学专家教师来评估 ChatGPT 在小学数学课堂成绩单中每一项任务的“零打击”表现。我们的研究结果表明，ChatGPT 产生的反应与提高教学质量有关，但它们往往不是新颖或有见地的。例如，模型中82% 的建议指向成绩单中教师已经实施该建议的地方。我们的工作强调了为教师提供有见地、新颖和真实的反馈所面临的挑战，同时为未来的研究解决这些障碍和提高生成性人工智能指导教师的能力铺平了道路。"
    },
    {
        "title": "Sequential Monte Carlo Steering of Large Language Models using\n  Probabilistic Programs",
        "url": "http://arxiv.org/abs/2306.03081v1",
        "pub_date": "2023-06-05",
        "summary": "Even after fine-tuning and reinforcement learning, large language models\n(LLMs) can be difficult, if not impossible, to control reliably with prompts\nalone. We propose a new inference-time approach to enforcing syntactic and\nsemantic constraints on the outputs of LLMs, called sequential Monte Carlo\n(SMC) steering. The key idea is to specify language generation tasks as\nposterior inference problems in a class of discrete probabilistic sequence\nmodels, and replace standard decoding with sequential Monte Carlo inference.\nFor a computational cost similar to that of beam search, SMC can steer LLMs to\nsolve diverse tasks, including infilling, generation under syntactic\nconstraints, and prompt intersection. To facilitate experimentation with SMC\nsteering, we present a probabilistic programming library, LLaMPPL\n(https://github.com/probcomp/LLaMPPL), for concisely specifying new generation\ntasks as language model probabilistic programs, and automating steering of\nLLaMA-family Transformers.",
        "translated": "即使经过微调和强化学习，大型语言模型(LLM)也很难单靠提示符进行可靠控制。我们提出了一种新的推理时间方法，称为序贯蒙特卡罗(SMC)指导，以强制语法和语义约束的 LLM 的输出。其核心思想是在一类离散概率序列模型中将语言生成任务指定为后验推理问题，并用序贯蒙特卡罗推理代替标准译码。对于类似于波束搜索的计算代价，SMC 可以引导 LLM 解决不同的任务，包括填充、语法约束下的生成和快速交叉。为了方便 SMC 指导的实验，我们提出了一个概率编程库，LLaMPPL ( https://github.com/probcomp/LLaMPPL ) ，简明地指定新一代任务作为语言模型概率程序，并自动指导 LlaMA 家族变压器。"
    },
    {
        "title": "Machine Learning and Statistical Approaches to Measuring Similarity of\n  Political Parties",
        "url": "http://arxiv.org/abs/2306.03079v1",
        "pub_date": "2023-06-05",
        "summary": "Mapping political party systems to metric policy spaces is one of the major\nmethodological problems in political science. At present, in most political\nscience project this task is performed by domain experts relying on purely\nqualitative assessments, with all the attendant problems of subjectivity and\nlabor intensiveness. We consider how advances in natural language processing,\nincluding large transformer-based language models, can be applied to solve that\nissue. We apply a number of texts similarity measures to party political\nprograms, analyze how they correlate with each other, and -- in the absence of\na satisfactory benchmark -- evaluate them against other measures, including\nthose based on expert surveys, voting records, electoral patterns, and\ncandidate networks. Finally, we consider the prospects of relying on those\nmethods to correct, supplement, and eventually replace expert judgments.",
        "translated": "将政党系统映射到度量政策空间是政治学的主要方法论问题之一。目前，在大多数政治科学项目中，这项任务是由领域专家依靠纯粹的定性评估来完成的，伴随而来的问题包括主观性和劳动密集性。我们考虑如何应用自然语言处理的进步，包括基于大型转换器的语言模型，来解决这个问题。我们将大量的文本相似性度量方法应用于政党政治计划，分析它们之间的相互关系，并且——在缺乏令人满意的基准的情况下——根据其他度量方法对它们进行评估，包括那些基于专家调查、投票记录、选举模式和候选人网络的方法。最后，我们考虑依靠这些方法来纠正、补充并最终取代专家判断的前景。"
    },
    {
        "title": "SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight\n  Compression",
        "url": "http://arxiv.org/abs/2306.03078v1",
        "pub_date": "2023-06-05",
        "summary": "Recent advances in large language model (LLM) pretraining have led to\nhigh-quality LLMs with impressive abilities. By compressing such LLMs via\nquantization to 3-4 bits per parameter, they can fit into memory-limited\ndevices such as laptops and mobile phones, enabling personalized use. However,\nquantization down to 3-4 bits per parameter usually leads to moderate-to-high\naccuracy losses, especially for smaller models in the 1-10B parameter range,\nwhich are well-suited for edge deployments. To address this accuracy issue, we\nintroduce the Sparse-Quantized Representation (SpQR), a new compressed format\nand quantization technique which enables for the first time near-lossless\ncompression of LLMs across model scales, while reaching similar compression\nlevels to previous methods. SpQR works by identifying and isolating outlier\nweights, which cause particularly-large quantization errors, and storing them\nin higher precision, while compressing all other weights to 3-4 bits, and\nachieves relative accuracy losses of less than 1% in perplexity for\nhighly-accurate LLaMA and Falcon LLMs. This makes it possible to run 33B\nparameter LLM on a single 24 GB consumer GPU without any performance\ndegradation at 15% speedup thus making powerful LLMs available to consumer\nwithout any downsides. SpQR comes with efficient algorithms for both encoding\nweights into its format, as well as decoding them efficiently at runtime.\nSpecifically, we provide an efficient GPU inference algorithm for SpQR which\nyields faster inference than 16-bit baselines at similar accuracy, while\nenabling memory compression gains of more than 4x.",
        "translated": "大语言模型(LLM)预训练的最新进展导致了具有令人印象深刻的能力的高质量 LLM。通过量化将这种 LLM 压缩到每个参数3-4位，它们可以适用于内存有限的设备，如笔记本电脑和移动电话，从而实现个性化使用。然而，每个参数下降到3-4位的量化通常会导致中高精度的损失，特别是对于1-10B 参数范围内的较小模型，它们非常适合边缘部署。为了解决这个精度问题，我们引入了稀疏量化表示(SpQR) ，这是一种新的压缩格式和量化技术，它能够首次在模型尺度上对 LLM 进行近无损压缩，同时达到与以前的方法相似的压缩水平。SpQR 的工作原理是识别和隔离引起特别大量化误差的离群值权重，并以更高的精度存储它们，同时将所有其他权重压缩到3-4位，对于高精度 LLaMA 和 Falcon LLM，相对精度损失小于1% 。这使得在一个24GB 的消费者 GPU 上运行33B 参数 LLM 成为可能，而且在加速15% 的情况下性能没有任何下降，从而使得消费者可以在没有任何缺点的情况下使用功能强大的 LLM。SpQR 提供了有效的算法，既可以将权值编码成它的格式，也可以在运行时高效地解码它们。具体来说，我们为 SpQR 提供了一种高效的 GPU 推理算法，它在相似的精度下比16位基线产生更快的推理，同时使内存压缩增益超过4倍。"
    },
    {
        "title": "Interactive Editing for Text Summarization",
        "url": "http://arxiv.org/abs/2306.03067v1",
        "pub_date": "2023-06-05",
        "summary": "Summarizing lengthy documents is a common and essential task in our daily\nlives. Although recent advancements in neural summarization models can assist\nin crafting general-purpose summaries, human writers often have specific\nrequirements that call for a more customized approach. To address this need, we\nintroduce REVISE (Refinement and Editing via Iterative Summarization\nEnhancement), an innovative framework designed to facilitate iterative editing\nand refinement of draft summaries by human writers. Within our framework,\nwriters can effortlessly modify unsatisfactory segments at any location or\nlength and provide optional starting phrases -- our system will generate\ncoherent alternatives that seamlessly integrate with the existing summary. At\nits core, REVISE incorporates a modified fill-in-the-middle model with the\nencoder-decoder architecture while developing novel evaluation metrics tailored\nfor the summarization task. In essence, our framework empowers users to create\nhigh-quality, personalized summaries by effectively harnessing both human\nexpertise and AI capabilities, ultimately transforming the summarization\nprocess into a truly collaborative and adaptive experience.",
        "translated": "总结冗长的文件是我们日常生活中的一项共同而又必不可少的任务。虽然神经总结模型的最新进展可以帮助制作通用的总结，但人类作者往往有特定的需求，需要更加定制的方法。为了满足这一需求，我们引入了 REVISE (通过迭代摘要增强进行细化和编辑) ，这是一个创新的框架，旨在促进人类作者对摘要草稿的迭代编辑和细化。在我们的框架内，作者可以毫不费力地在任何位置或长度修改不满意的部分，并提供可选的起始短语——我们的系统将生成与现有摘要无缝集成的连贯备选方案。在其核心，REVISE 采用了修改的填充中间模型与编码器-解码器架构，同时开发新的评估指标定制的摘要任务。本质上，我们的框架通过有效利用人类专业知识和人工智能能力，使用户能够创建高质量的个性化摘要，最终将摘要过程转化为真正的协作和适应性体验。"
    },
    {
        "title": "Structured Voronoi Sampling",
        "url": "http://arxiv.org/abs/2306.03061v1",
        "pub_date": "2023-06-05",
        "summary": "Recently, there has been a growing interest in the development of\ngradient-based sampling algorithms for text generation, especially in the\ncontext of controlled generation. However, there exists a lack of theoretically\ngrounded and principled approaches for this task. In this paper, we take an\nimportant step toward building a principled approach for sampling from language\nmodels with gradient-based methods. We use discrete distributions given by\nlanguage models to define densities and develop an algorithm based on\nHamiltonian Monte Carlo to sample from them. We name our gradient-based\ntechnique Structured Voronoi Sampling (SVS). In an experimental setup where the\nreference distribution is known, we show that the empirical distribution of SVS\nsamples is closer to the reference distribution compared to alternative\nsampling schemes. Furthermore, in a controlled generation task, SVS is able to\ngenerate fluent and diverse samples while following the control targets\nsignificantly better than other methods.",
        "translated": "近年来，基于梯度的文本生成采样算法的研究越来越受到人们的关注，尤其是在控制生成的背景下。然而，这项工作缺乏理论基础和原则性的方法。在本文中，我们采取了一个重要的步骤，以建立一个原则性的方法从语言模型采样基于梯度的方法。我们使用语言模型给出的离散分布来定义密度，并开发一个基于 Hamiltonian Monte Carlo 的算法来取样。我们将基于梯度的技术命名为结构化 Voronoi 抽样(SVS)。在已知参考分布的实验装置中，我们发现 SVS 样本的经验分布比其他抽样方案更接近参考分布。此外，在控制生成任务中，SVS 能够生成流畅多样的样本，并且能够明显地更好地跟踪控制目标。"
    },
    {
        "title": "Analyzing Syntactic Generalization Capacity of Pre-trained Language\n  Models on Japanese Honorific Conversion",
        "url": "http://arxiv.org/abs/2306.03055v1",
        "pub_date": "2023-06-05",
        "summary": "Using Japanese honorifics is challenging because it requires not only\nknowledge of the grammatical rules but also contextual information, such as\nsocial relationships. It remains unclear whether pre-trained large language\nmodels (LLMs) can flexibly handle Japanese honorifics like humans. To analyze\nthis, we introduce an honorific conversion task that considers social\nrelationships among people mentioned in a conversation. We construct a Japanese\nhonorifics dataset from problem templates of various sentence structures to\ninvestigate the syntactic generalization capacity of GPT-3, one of the leading\nLLMs, on this task under two settings: fine-tuning and prompt learning. Our\nresults showed that the fine-tuned GPT-3 performed better in a context-aware\nhonorific conversion task than the prompt-based one. The fine-tuned model\ndemonstrated overall syntactic generalizability towards compound honorific\nsentences, except when tested with the data involving direct speech.",
        "translated": "使用敬称很有挑战性，因为它不仅需要语法规则的知识，还需要上下文信息，比如社会关系。目前还不清楚经过训练的大型语言模型(LLM)是否能像人类一样灵活地处理敬称。为了分析这一点，我们引入了一个敬语转换任务，考虑谈话中提到的人之间的社会关系。我们从不同句子结构的问题模板中构建了一个敬称数据集，在微调和及时学习两种设置下，研究了领先的语法模型之一 GPT-3的句法泛化能力。我们的研究结果表明，微调的 GPT-3在上下文感知的敬语转换任务中比基于提示的任务表现得更好。经过微调的模型显示了复合敬语句的整体句法泛化能力，除非使用直接引语的数据进行测试。"
    },
    {
        "title": "Benchmarking Large Language Models on CMExam -- A Comprehensive Chinese\n  Medical Exam Dataset",
        "url": "http://arxiv.org/abs/2306.03030v1",
        "pub_date": "2023-06-05",
        "summary": "Recent advancements in large language models (LLMs) have transformed the\nfield of question answering (QA). However, evaluating LLMs in the medical field\nis challenging due to the lack of standardized and comprehensive datasets. To\naddress this gap, we introduce CMExam, sourced from the Chinese National\nMedical Licensing Examination. CMExam consists of 60K+ multiple-choice\nquestions for standardized and objective evaluations, as well as solution\nexplanations for model reasoning evaluation in an open-ended manner. For\nin-depth analyses of LLMs, we invited medical professionals to label five\nadditional question-wise annotations, including disease groups, clinical\ndepartments, medical disciplines, areas of competency, and question difficulty\nlevels. Alongside the dataset, we further conducted thorough experiments with\nrepresentative LLMs and QA algorithms on CMExam. The results show that GPT-4\nhad the best accuracy of 61.5% and a weighted F1 score of 0.616. These results\nhighlight a great disparity when compared to human accuracy, which stood at\n71.6%. For explanation tasks, while LLMs could generate relevant reasoning and\ndemonstrate improved performance after finetuning, they fall short of a desired\nstandard, indicating ample room for improvement. To the best of our knowledge,\nCMExam is the first Chinese medical exam dataset to provide comprehensive\nmedical annotations. The experiments and findings of LLM evaluation also\nprovide valuable insights into the challenges and potential solutions in\ndeveloping Chinese medical QA systems and LLM evaluation pipelines. The dataset\nand relevant code are available at https://github.com/williamliujl/CMExam.",
        "translated": "大型语言模型(LLM)的最新进展已经改变了问答(QA)领域。然而，由于缺乏标准化和全面的数据集，评估 LLM 在医学领域是具有挑战性的。为了弥补这一差距，我们引入了来自中国国家医师执业资格考试的中国医师执业资格考试。CMExam 由60K + 多项选择题组成，用于标准化和客观的评估，以及开放式方式的模型推理评估的解决方案说明。对于 LLM 的深入分析，我们邀请医学专业人员标记另外五个明智的问题注释，包括疾病组，临床部门，医学学科，能力领域和问题难度水平。除了数据集，我们进一步在 CMExam 上进行了具有代表性的 LLM 和 QA 算法的全面实验。结果表明，GPT-4的最佳准确率为61.5% ，加权 F1得分为0.616。这些结果突出了一个巨大的差异，相比之下，人类的准确率为71.6% 。对于解释任务，虽然 LLM 可以生成相关的推理，并在微调后显示出改进的性能，但它们没有达到理想的标准，表明有足够的改进空间。据我们所知，中国医学考试是第一个提供全面医学注释的中国医学考试数据集。LLM 评价的实验和研究结果也为开发中国医疗质量保证体系和 LLM 评价管道提供了有价值的启示。数据集和相关代码可在 https://github.com/williamliujl/cmexam 查阅。"
    },
    {
        "title": "PokemonChat: Auditing ChatGPT for Pokémon Universe Knowledge",
        "url": "http://arxiv.org/abs/2306.03024v1",
        "pub_date": "2023-06-05",
        "summary": "The recently released ChatGPT model demonstrates unprecedented capabilities\nin zero-shot question-answering. In this work, we probe ChatGPT for its\nconversational understanding and introduce a conversational framework\n(protocol) that can be adopted in future studies. The Pok\\'emon universe serves\nas an ideal testing ground for auditing ChatGPT's reasoning capabilities due to\nits closed world assumption. After bringing ChatGPT's background knowledge (on\nthe Pok\\'emon universe) to light, we test its reasoning process when using\nthese concepts in battle scenarios. We then evaluate its ability to acquire new\nknowledge and include it in its reasoning process. Our ultimate goal is to\nassess ChatGPT's ability to generalize, combine features, and to acquire and\nreason over newly introduced knowledge from human feedback. We find that\nChatGPT has prior knowledge of the Pokemon universe, which can reason upon in\nbattle scenarios to a great extent, even when new information is introduced.\nThe model performs better with collaborative feedback and if there is an\ninitial phase of information retrieval, but also hallucinates occasionally and\nis susceptible to adversarial attacks.",
        "translated": "最近发布的 ChatGPT 模型展示了前所未有的零命中问题回答能力。在本文中，我们探讨了 ChatGPT 的会话理解，并介绍了一个可以在未来研究中采用的会话框架(协议)。由于其封闭的世界假设，宇宙上的 Pok’em 可以作为审核 ChatGPT 推理能力的理想试验场。在将 ChatGPT 的背景知识(关于宇宙中的 Pok’em)公之于众之后，我们在战斗场景中使用这些概念时测试它的推理过程。然后，我们评估它获取新知识的能力，并将其包括在推理过程中。我们的最终目标是评估 ChatGPT 的概括、结合特性的能力，以及从人类反馈中获取和推理新引入的知识的能力。我们发现 ChatGPT 拥有口袋妖怪世界的先验知识，即使在引入新信息的情况下，它也可以在很大程度上在战斗场景中进行推理。这种模式在协作反馈的情况下表现得更好，如果存在信息检索的初始阶段，但有时也会产生幻觉，容易受到敌对攻击。"
    },
    {
        "title": "On Manipulating Signals of User-Item Graph: A Jacobi Polynomial-based\n  Graph Collaborative Filtering",
        "url": "http://arxiv.org/abs/2306.03624v1",
        "pub_date": "2023-06-06",
        "summary": "Collaborative filtering (CF) is an important research direction in\nrecommender systems that aims to make recommendations given the information on\nuser-item interactions. Graph CF has attracted more and more attention in\nrecent years due to its effectiveness in leveraging high-order information in\nthe user-item bipartite graph for better recommendations. Specifically, recent\nstudies show the success of graph neural networks (GNN) for CF is attributed to\nits low-pass filtering effects. However, current researches lack a study of how\ndifferent signal components contributes to recommendations, and how to design\nstrategies to properly use them well. To this end, from the view of spectral\ntransformation, we analyze the important factors that a graph filter should\nconsider to achieve better performance. Based on the discoveries, we design\nJGCF, an efficient and effective method for CF based on Jacobi polynomial bases\nand frequency decomposition strategies. Extensive experiments on four widely\nused public datasets show the effectiveness and efficiency of the proposed\nmethods, which brings at most 27.06% performance gain on Alibaba-iFashion.\nBesides, the experimental results also show that JGCF is better at handling\nsparse datasets, which shows potential in making recommendations for cold-start\nusers.",
        "translated": "协同过滤(CF)是推荐系统的一个重要研究方向，其目的是根据用户项目交互的信息提供推荐。近年来，图形 CF 由于能够有效地利用用户项目二分图中的高阶信息来获得更好的建议而引起了越来越多的关注。具体来说，最近的研究表明，图神经网络(GNN)对 CF 的成功归功于其低通滤波效果。然而，目前的研究缺乏研究不同的信号成分如何有助于推荐，以及如何设计策略，以适当地使用它们。为此，本文从谱变换的角度出发，分析了图形滤波器要获得更好的性能所应考虑的重要因素。基于这些发现，我们设计了一种基于 Jacobi 多项式基和频率分解策略的高效率和有效的协同过滤方法。在四个广泛使用的公共数据集上进行了大量的实验，结果表明了该方法的有效性和高效性，在阿里巴巴-iFashion 平台上获得了最多27.06% 的性能提升。此外，实验结果还表明，JGCF 在处理稀疏数据集方面有较好的表现，可以为冷启动用户提供建议。"
    },
    {
        "title": "Rec4Ad: A Free Lunch to Mitigate Sample Selection Bias for Ads CTR\n  Prediction in Taobao",
        "url": "http://arxiv.org/abs/2306.03527v1",
        "pub_date": "2023-06-06",
        "summary": "Click-Through Rate (CTR) prediction serves as a fundamental component in\nonline advertising. A common practice is to train a CTR model on advertisement\n(ad) impressions with user feedback. Since ad impressions are purposely\nselected by the model itself, their distribution differs from the inference\ndistribution and thus exhibits sample selection bias (SSB) that affects model\nperformance. Existing studies on SSB mainly employ sample re-weighting\ntechniques which suffer from high variance and poor model calibration. Another\nline of work relies on costly uniform data that is inadequate to train\nindustrial models. Thus mitigating SSB in industrial models with a\nuniform-data-free framework is worth exploring. Fortunately, many platforms\ndisplay mixed results of organic items (i.e., recommendations) and sponsored\nitems (i.e., ads) to users, where impressions of ads and recommendations are\nselected by different systems but share the same user decision rationales.\nBased on the above characteristics, we propose to leverage recommendations\nsamples as a free lunch to mitigate SSB for ads CTR model (Rec4Ad). After\nelaborating data augmentation, Rec4Ad learns disentangled representations with\nalignment and decorrelation modules for enhancement. When deployed in Taobao\ndisplay advertising system, Rec4Ad achieves substantial gains in key business\nmetrics, with a lift of up to +6.6\\% CTR and +2.9\\% RPM.",
        "translated": "点进率预测是在线广告的一个基本组成部分。一个常见的做法是训练广告(广告)印象与用户反馈的点击率模型。由于广告印象是由模型本身有目的地选择的，它们的分布不同于推断分布，因此表现出影响模型性能的样本选择偏差(SSB)。现有的 SSB 研究主要采用样本重权重技术，存在方差大、模型校正差等问题。另一项工作依赖于昂贵的统一数据，这些数据不足以培训工业模型。因此，在无统一数据框架的工业模型中减少 SSB 是值得探索的。幸运的是，许多平台向用户显示有机项目(即推荐)和赞助项目(即广告)的混合结果，其中广告和推荐的印象由不同的系统选择，但共享相同的用户决策理由。基于上述特点，我们建议利用推荐样本作为免费午餐，以减轻 SSB 的广告点击率模型(Rec4Ad)。在详细阐述了数据增强之后，Rec4Ad 学习了利用对齐和去相关模块进行增强的解纠缠表示。在淘宝展示广告系统中部署 Rec4Ad 后，Rec4Ad 在关键业务指标上取得了实质性进展，点击率和转速分别提高了6.6% 和2.9% 。"
    },
    {
        "title": "COPR: Consistency-Oriented Pre-Ranking for Online Advertising",
        "url": "http://arxiv.org/abs/2306.03516v1",
        "pub_date": "2023-06-06",
        "summary": "Cascading architecture has been widely adopted in large-scale advertising\nsystems to balance efficiency and effectiveness. In this architecture, the\npre-ranking model is expected to be a lightweight approximation of the ranking\nmodel, which handles more candidates with strict latency requirements. Due to\nthe gap in model capacity, the pre-ranking and ranking models usually generate\ninconsistent ranked results, thus hurting the overall system effectiveness. The\nparadigm of score alignment is proposed to regularize their raw scores to be\nconsistent. However, it suffers from inevitable alignment errors and error\namplification by bids when applied in online advertising. To this end, we\nintroduce a consistency-oriented pre-ranking framework for online advertising,\nwhich employs a chunk-based sampling module and a plug-and-play rank alignment\nmodule to explicitly optimize consistency of ECPM-ranked results. A $\\Delta\nNDCG$-based weighting mechanism is adopted to better distinguish the importance\nof inter-chunk samples in optimization. Both online and offline experiments\nhave validated the superiority of our framework. When deployed in Taobao\ndisplay advertising system, it achieves an improvement of up to +12.3\\% CTR and\n+5.6\\% RPM.",
        "translated": "为了平衡效率和效果，级联体系结构在大规模广告系统中得到了广泛的应用。在这种体系结构中，预排序模型被期望是排序模型的轻量级近似，它处理具有严格延迟要求的更多候选者。由于模型容量的差距，预排序模型和排序模型通常会产生不一致的排序结果，从而影响系统的整体有效性。提出了分数对齐的范式，以规范他们的原始分数是一致的。然而，在网络广告中应用时，不可避免地会出现一致性错误和出价放大错误。为此，我们引入了一个面向一致性的在线广告预排序框架，该框架采用了基于块的抽样模块和即插即用的排序对齐模块来显式优化 ECPM 排序结果的一致性。为了更好地区分块间样本在优化中的重要性，采用了基于 $Delta NDCG 的加权机制。这两个在线和离线实验都验证了我们框架的优越性。在淘宝展示广告系统中，点击率和转速分别提高了12.3% 和5.6% 。"
    },
    {
        "title": "Generate-then-Retrieve: Intent-Aware FAQ Retrieval in Product Search",
        "url": "http://arxiv.org/abs/2306.03411v1",
        "pub_date": "2023-06-06",
        "summary": "Customers interacting with product search engines are increasingly\nformulating information-seeking queries. Frequently Asked Question (FAQ)\nretrieval aims to retrieve common question-answer pairs for a user query with\nquestion intent. Integrating FAQ retrieval in product search can not only\nempower users to make more informed purchase decisions, but also enhance user\nretention through efficient post-purchase support. Determining when an FAQ\nentry can satisfy a user's information need within product search, without\ndisrupting their shopping experience, represents an important challenge. We\npropose an intent-aware FAQ retrieval system consisting of (1) an intent\nclassifier that predicts when a user's information need can be answered by an\nFAQ; (2) a reformulation model that rewrites a query into a natural question.\nOffline evaluation demonstrates that our approach improves Hit@1 by 13% on\nretrieving ground-truth FAQs, while reducing latency by 95% compared to\nbaseline systems. These improvements are further validated by real user\nfeedback, where 71% of displayed FAQs on top of product search results received\nexplicit positive user feedback. Overall, our findings show promising\ndirections for integrating FAQ retrieval into product search at scale.",
        "translated": "与产品搜索引擎互动的客户越来越多地提出信息搜索查询。常见问题(FAQ)检索的目的是为具有问题意图的用户查询检索常见的问题-答案对。将常见问题检索整合到产品搜索中，不仅可以使用户做出更明智的购买决策，而且可以通过有效的购买后支持来提高用户保留率。在不影响用户购物体验的情况下，确定 FAQ 条目何时能够满足用户在产品搜索中的信息需求，是一个重要的挑战。我们提出了一个意图感知的 FAQ 检索系统，包括(1)意图分类器，预测何时用户的信息需求可以由 FAQ 回答; (2)重写模型，将查询重写成一个自然的问题。脱机评估表明，与基线系统相比，我们的方法在检索地面真相 FAQ 时将 Hit@1提高了13% ，同时减少了95% 的延迟。这些改进通过真实的用户反馈得到了进一步的验证，在产品搜索结果之上显示的 FAQ 中有71% 得到了明确的积极的用户反馈。总的来说，我们的研究结果为将 FAQ 检索整合到大规模的产品搜索中提供了有希望的方向。"
    },
    {
        "title": "Computational Technologies for Fashion Recommendation: A Survey",
        "url": "http://arxiv.org/abs/2306.03395v1",
        "pub_date": "2023-06-06",
        "summary": "Fashion recommendation is a key research field in computational fashion\nresearch and has attracted considerable interest in the computer vision,\nmultimedia, and information retrieval communities in recent years. Due to the\ngreat demand for applications, various fashion recommendation tasks, such as\npersonalized fashion product recommendation, complementary (mix-and-match)\nrecommendation, and outfit recommendation, have been posed and explored in the\nliterature. The continuing research attention and advances impel us to look\nback and in-depth into the field for a better understanding. In this paper, we\ncomprehensively review recent research efforts on fashion recommendation from a\ntechnological perspective. We first introduce fashion recommendation at a macro\nlevel and analyse its characteristics and differences with general\nrecommendation tasks. We then clearly categorize different fashion\nrecommendation efforts into several sub-tasks and focus on each sub-task in\nterms of its problem formulation, research focus, state-of-the-art methods, and\nlimitations. We also summarize the datasets proposed in the literature for use\nin fashion recommendation studies to give readers a brief illustration.\nFinally, we discuss several promising directions for future research in this\nfield. Overall, this survey systematically reviews the development of fashion\nrecommendation research. It also discusses the current limitations and gaps\nbetween academic research and the real needs of the fashion industry. In the\nprocess, we offer a deep insight into how the fashion industry could benefit\nfrom fashion recommendation technologies. the computational technologies of\nfashion recommendation.",
        "translated": "时尚推荐是计算时尚研究中的一个关键研究领域，近年来在计算机视觉、多媒体和信息检索社区引起了相当大的兴趣。由于应用需求的巨大，各种时尚推荐任务，如个性化的时尚产品推荐，补充(混搭)推荐，服装推荐，已提出和探讨的文献。持续的研究关注和进步促使我们回顾和深入到这一领域，以便更好地理解。本文从技术角度综述了近年来时尚推荐的研究成果。本文首先从宏观层面介绍了时尚推荐，并分析了它与一般推荐任务的特点和区别。然后，我们清楚地将不同的时尚推荐工作分为几个子任务，并根据其问题形成、研究重点、最先进的方法和局限性关注每个子任务。我们还总结了文献中提出的用于时尚推荐研究的数据集，以便给读者一个简要的说明。最后，我们讨论了这一领域未来研究的几个有希望的方向。总的来说，本调查系统地回顾了时尚推荐研究的发展。文章还讨论了当前学术研究与时尚产业实际需求之间的局限性和差距。在这个过程中，我们提供了一个深入的洞察时尚产业如何可以受益于时尚推荐技术。时尚推荐的计算技术。"
    },
    {
        "title": "CL-UZH at SemEval-2023 Task 10: Sexism Detection through Incremental\n  Fine-Tuning and Multi-Task Learning with Label Descriptions",
        "url": "http://arxiv.org/abs/2306.03907v1",
        "pub_date": "2023-06-06",
        "summary": "The widespread popularity of social media has led to an increase in hateful,\nabusive, and sexist language, motivating methods for the automatic detection of\nsuch phenomena. The goal of the SemEval shared task \\textit{Towards Explainable\nDetection of Online Sexism} (EDOS 2023) is to detect sexism in English social\nmedia posts (subtask A), and to categorize such posts into four coarse-grained\nsexism categories (subtask B), and eleven fine-grained subcategories (subtask\nC). In this paper, we present our submitted systems for all three subtasks,\nbased on a multi-task model that has been fine-tuned on a range of related\ntasks and datasets before being fine-tuned on the specific EDOS subtasks. We\nimplement multi-task learning by formulating each task as binary pairwise text\nclassification, where the dataset and label descriptions are given along with\nthe input text. The results show clear improvements over a fine-tuned\nDeBERTa-V3 serving as a baseline leading to $F_1$-scores of 85.9\\% in subtask A\n(rank 13/84), 64.8\\% in subtask B (rank 19/69), and 44.9\\% in subtask C\n(26/63).",
        "translated": "社交媒体的广泛流行导致了仇恨、辱骂和性别歧视语言的增加，激发了自动检测此类现象的方法。SemEval 共享任务的目标是检测英语社交媒体帖子中的性别歧视(子任务 A) ，并将这些帖子分为四个粗粒度的性别歧视类别(子任务 B)和十一个细粒度的子类别(子任务 C)。在本文中，我们提出了针对所有三个子任务的提交系统，该系统基于一个多任务模型，在针对特定的 EDOS 子任务进行微调之前，该模型已经在一系列相关任务和数据集上进行了微调。我们通过将每个任务表示为二进制成对文本分类来实现多任务学习，其中数据集和标签描述与输入文本一起给出。结果显示，与作为基线的微调 DeBERTa-V3相比，明显改善，子任务 A (排名13/84)的分数为85.9% ，子任务 B (排名19/69)为64.8% ，子任务 C 为44.9% (26/63)。"
    },
    {
        "title": "Utterance Classification with Logical Neural Network: Explainable AI for\n  Mental Disorder Diagnosis",
        "url": "http://arxiv.org/abs/2306.03902v1",
        "pub_date": "2023-06-06",
        "summary": "In response to the global challenge of mental health problems, we proposes a\nLogical Neural Network (LNN) based Neuro-Symbolic AI method for the diagnosis\nof mental disorders. Due to the lack of effective therapy coverage for mental\ndisorders, there is a need for an AI solution that can assist therapists with\nthe diagnosis. However, current Neural Network models lack explainability and\nmay not be trusted by therapists. The LNN is a Recurrent Neural Network\narchitecture that combines the learning capabilities of neural networks with\nthe reasoning capabilities of classical logic-based AI. The proposed system\nuses input predicates from clinical interviews to output a mental disorder\nclass, and different predicate pruning techniques are used to achieve\nscalability and higher scores. In addition, we provide an insight extraction\nmethod to aid therapists with their diagnosis. The proposed system addresses\nthe lack of explainability of current Neural Network models and provides a more\ntrustworthy solution for mental disorder diagnosis.",
        "translated": "针对心理健康问题的全球性挑战，我们提出了一种基于逻辑神经网络(LNN)的神经符号人工智能方法来诊断精神障碍。由于缺乏有效的治疗覆盖面的精神障碍，有一个人工智能解决方案的需要，可以帮助治疗师的诊断。然而，目前的神经网络模型缺乏可解释性，可能不被治疗师信任。神经网络是一种递归神经网络结构，它结合了神经网络的学习能力和经典的基于逻辑的人工智能的推理能力。该系统使用临床访谈中的输入谓词输出一个精神障碍类，并使用不同的谓词修剪技术来实现可扩展性和更高的分数。此外，我们提供了一个洞察力提取方法，以帮助治疗师与他们的诊断。该系统解决了目前神经网络模型的不可解释性问题，为精神疾病的诊断提供了一个更可靠的解决方案。"
    },
    {
        "title": "ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory",
        "url": "http://arxiv.org/abs/2306.03901v2",
        "pub_date": "2023-06-06",
        "summary": "Large language models (LLMs) with memory are computationally universal.\nHowever, mainstream LLMs are not taking full advantage of memory, and the\ndesigns are heavily influenced by biological brains. Due to their approximate\nnature and proneness to the accumulation of errors, conventional neural memory\nmechanisms cannot support LLMs to simulate complex reasoning. In this paper, we\nseek inspiration from modern computer architectures to augment LLMs with\nsymbolic memory for complex multi-hop reasoning. Such a symbolic memory\nframework is instantiated as an LLM and a set of SQL databases, where the LLM\ngenerates SQL instructions to manipulate the SQL databases. We validate the\neffectiveness of the proposed memory framework on a synthetic dataset requiring\ncomplex reasoning. The project website is available at\nhttps://chatdatabase.github.io/ .",
        "translated": "具有内存的大型语言模型(LLM)在计算上是通用的。然而，主流 LLM 并没有充分利用记忆的优势，而且设计受到生物大脑的严重影响。传统的神经记忆机制由于其近似特性和容易累积错误，不能支持 LLM 模拟复杂的推理过程。本文从现代计算机体系结构中寻找启示，用符号存储器增强复杂多跳推理的 LLM。这样的符号内存框架实例化为一个 LLM 和一组 SQL 数据库，LLM 在其中生成 SQL 指令来操作 SQL 数据库。在需要复杂推理的合成数据集上，验证了所提出的记忆框架的有效性。有关计划的网页可于 https://chatdatabase.github.io/下载。"
    },
    {
        "title": "Causal interventions expose implicit situation models for commonsense\n  language understanding",
        "url": "http://arxiv.org/abs/2306.03882v2",
        "pub_date": "2023-06-06",
        "summary": "Accounts of human language processing have long appealed to implicit\n``situation models'' that enrich comprehension with relevant but unstated world\nknowledge. Here, we apply causal intervention techniques to recent transformer\nmodels to analyze performance on the Winograd Schema Challenge (WSC), where a\nsingle context cue shifts interpretation of an ambiguous pronoun. We identify a\nrelatively small circuit of attention heads that are responsible for\npropagating information from the context word that guides which of the\ncandidate noun phrases the pronoun ultimately attends to. We then compare how\nthis circuit behaves in a closely matched ``syntactic'' control where the\nsituation model is not strictly necessary. These analyses suggest distinct\npathways through which implicit situation models are constructed to guide\npronoun resolution.",
        "translated": "长期以来，人类语言处理的描述一直呼吁隐含的“情境模型”，用相关但未陈述的世界知识丰富理解。在这里，我们将因果干预技术应用到最近的转换器模型中，以分析 Winograd 模式挑战(WSC)的表现，其中一个单一的上下文提示转移了对一个模棱两可的代词的解释。我们识别出一个相对较小的注意力回路，它负责从上下文词中传播信息，指导代词最终注意哪个候选名词短语。然后我们比较这个电路在一个紧密匹配的“语法”控制中的表现，在这个控制中情境模型并不是严格必要的。这些分析揭示了指导代词消解的内隐情境模型构建的不同途径。"
    },
    {
        "title": "Deductive Verification of Chain-of-Thought Reasoning",
        "url": "http://arxiv.org/abs/2306.03872v2",
        "pub_date": "2023-06-06",
        "summary": "Large Language Models (LLMs) significantly benefit from Chain-of-Thought\n(CoT) prompting in performing various reasoning tasks. While CoT allows models\nto produce more comprehensive reasoning processes, its emphasis on intermediate\nreasoning steps can inadvertently introduce hallucinations and accumulated\nerrors, thereby limiting models' ability to solve complex reasoning tasks.\nInspired by how humans engage in careful and meticulous deductive logical\nreasoning processes to solve tasks, we seek to enable language models to\nperform explicit and rigorous deductive reasoning, and also ensure the\ntrustworthiness of their reasoning process through self-verification. However,\ndirectly verifying the validity of an entire deductive reasoning process is\nchallenging, even with advanced models like ChatGPT. In light of this, we\npropose to decompose a reasoning verification process into a series of\nstep-by-step subprocesses, each only receiving their necessary context and\npremises. To facilitate this procedure, we propose Natural Program, a natural\nlanguage-based deductive reasoning format. Our approach enables models to\ngenerate precise reasoning steps where subsequent steps are more rigorously\ngrounded on prior steps. It also empowers language models to carry out\nreasoning self-verification in a step-by-step manner. By integrating this\nverification process into each deductive reasoning stage, we significantly\nenhance the rigor and trustfulness of generated reasoning steps. Along this\nprocess, we also improve the answer correctness on complex reasoning tasks.\nCode will be released at https://github.com/lz1oceani/verify_cot.",
        "translated": "大型语言模型(LLM)在执行各种推理任务时显著受益于思维链(CoT)的提示。虽然 CoT 允许模型产生更全面的推理过程，但它对中间推理步骤的强调可能无意中引入幻觉和累积错误，从而限制模型解决复杂推理任务的能力。我们受到人类如何小心谨慎地进行演绎逻辑推理过程来解决任务的启发，我们试图使语言模型能够执行明确而严格的演绎推理，并通过自我验证来确保其推理过程的可信度。然而，即使使用像 chatgPT 这样的高级模型，直接验证整个演绎推理过程的有效性也是具有挑战性的。鉴于此，我们建议将推理验证过程分解为一系列逐步的子过程，每个子过程只接收其必要的上下文和前提。为了方便这个过程，我们提出了自然程序，一种基于自然语言的演绎推理格式。我们的方法使模型能够产生精确的推理步骤，其中后续步骤更严格地基于先前的步骤。它还使语言模型能够按部就班地进行推理自我验证。通过将这个验证过程整合到每个演绎推理阶段，我们大大提高了生成推理步骤的严谨性和可信度。在这个过程中，我们还提高了复杂推理任务的正确答案。密码将在 https://github.com/lz1oceani/verify_cot 公布。"
    },
    {
        "title": "Correction of Errors in Preference Ratings from Automated Metrics for\n  Text Generation",
        "url": "http://arxiv.org/abs/2306.03866v1",
        "pub_date": "2023-06-06",
        "summary": "A major challenge in the field of Text Generation is evaluation: Human\nevaluations are cost-intensive, and automated metrics often display\nconsiderable disagreement with human judgments. In this paper, we propose a\nstatistical model of Text Generation evaluation that accounts for the\nerror-proneness of automated metrics when used to generate preference rankings\nbetween system outputs. We show that existing automated metrics are generally\nover-confident in assigning significant differences between systems in this\nsetting. However, our model enables an efficient combination of human and\nautomated ratings to remedy the error-proneness of the automated metrics. We\nshow that using this combination, we only require about 50% of the human\nannotations typically used in evaluations to arrive at robust and statistically\nsignificant results while yielding the same evaluation outcome as the pure\nhuman evaluation in 95% of cases. We showcase the benefits of approach for\nthree text generation tasks: dialogue systems, machine translation, and text\nsummarization.",
        "translated": "文本生成领域的一个主要挑战是评价: 人的评价是成本密集型的，自动化度量往往显示出与人的判断相当大的分歧。本文提出了一种文本生成评价的统计模型，该模型考虑了自动化度量在生成系统输出之间的偏好排序时的错误倾向性。我们表明，现有的自动化度量通常过于自信，以至于在这种设置中分配系统之间的显著差异。然而，我们的模型能够有效地结合人工评分和自动评分来纠正自动度量的错误倾向性。我们表明，使用这种组合，我们只需要通常用于评估的约50% 的人工注释来达到稳健和统计学显着的结果，同时在95% 的情况下产生与纯人类评估相同的评估结果。我们展示了这种方法在三个文本生成任务中的优点: 对话系统、机器翻译和文本摘要。"
    },
    {
        "title": "Iterative Translation Refinement with Large Language Models",
        "url": "http://arxiv.org/abs/2306.03856v1",
        "pub_date": "2023-06-06",
        "summary": "Large language models have shown surprising performances in understanding\ninstructions and performing natural language tasks. In this paper, we propose\niterative translation refinement to leverage the power of large language models\nfor more natural translation and post-editing. We show that by simply involving\na large language model in an iterative process, the output quality improves\nbeyond mere translation. Extensive test scenarios with GPT-3.5 reveal that\nalthough iterations reduce string-based metric scores, neural metrics indicate\ncomparable if not improved translation quality. Further, human evaluations\ndemonstrate that our method effectively reduces translationese compared to\ninitial GPT translations and even human references, especially for into-English\ndirections. Ablation studies underscore the importance of anchoring the\nrefinement process to the source input and a reasonable initial translation.",
        "translated": "大型语言模型在理解指令和执行自然语言任务方面表现出惊人的表现。在本文中，我们提出了迭代翻译细化，以利用大型语言模型的力量，更自然的翻译和后期编辑。我们表明，通过简单地在迭代过程中涉及一个大的语言模型，输出质量提高超过单纯的翻译。使用 GPT-3.5的大量测试场景显示，尽管迭代减少了基于字符串的度量得分，但神经度量表明，即使没有提高翻译质量，也可以进行比较。此外，人工评估表明，我们的方法有效地减少翻译相比，最初的 GPT 翻译，甚至人工参考，特别是进入英语方向。消融研究强调了将细化过程锚定在源输入和合理的初始翻译上的重要性。"
    },
    {
        "title": "From Key Points to Key Point Hierarchy: Structured and Expressive\n  Opinion Summarization",
        "url": "http://arxiv.org/abs/2306.03853v1",
        "pub_date": "2023-06-06",
        "summary": "Key Point Analysis (KPA) has been recently proposed for deriving fine-grained\ninsights from collections of textual comments. KPA extracts the main points in\nthe data as a list of concise sentences or phrases, termed key points, and\nquantifies their prevalence. While key points are more expressive than word\nclouds and key phrases, making sense of a long, flat list of key points, which\noften express related ideas in varying levels of granularity, may still be\nchallenging. To address this limitation of KPA, we introduce the task of\norganizing a given set of key points into a hierarchy, according to their\nspecificity. Such hierarchies may be viewed as a novel type of Textual\nEntailment Graph. We develop ThinkP, a high quality benchmark dataset of key\npoint hierarchies for business and product reviews, obtained by consolidating\nmultiple annotations. We compare different methods for predicting pairwise\nrelations between key points, and for inferring a hierarchy from these pairwise\npredictions. In particular, for the task of computing pairwise key point\nrelations, we achieve significant gains over existing strong baselines by\napplying directional distributional similarity methods to a novel\ndistributional representation of key points, and further boost performance via\nweak supervision.",
        "translated": "关键点分析(Key Point Analysis，KPA)最近被提议用于从文本注释集合中获得细粒度的见解。KPA 从数据中提取主要观点作为一个简洁的句子或短语列表，称为关键点，并量化其普遍性。虽然关键点比单词云和关键短语更能表达思想，但是要理解一个长长的、扁平的关键点列表可能仍然是一个挑战，因为这些关键点通常表达的是不同粒度级别的相关思想。为了解决 KPA 的这个局限性，我们引入了这样一个任务: 根据关键点的特殊性，将一组给定的关键点组织成一个层次结构。这种等级制度可以被视为一种新型的文字蕴涵图。我们开发 ThinkP，它是一个高质量的基准数据集，通过整合多个注释获得，用于业务和产品评论的关键点层次结构。我们比较了预测关键点之间成对关系的不同方法，以及从这些成对预测中推断层次结构的不同方法。特别是对于计算成对关键点关系的任务，我们通过将方向分布相似性方法应用于一种新的关键点分布表示，在现有的强基线上取得了显著的效果，并且通过弱监督进一步提高了性能。"
    },
    {
        "title": "LEACE: Perfect linear concept erasure in closed form",
        "url": "http://arxiv.org/abs/2306.03819v1",
        "pub_date": "2023-06-06",
        "summary": "Concept erasure aims to remove specified features from a representation. It\ncan be used to improve fairness (e.g. preventing a classifier from using gender\nor race) and interpretability (e.g. removing a concept to observe changes in\nmodel behavior). In this paper, we introduce LEAst-squares Concept Erasure\n(LEACE), a closed-form method which provably prevents all linear classifiers\nfrom detecting a concept while inflicting the least possible damage to the\nrepresentation. We apply LEACE to large language models with a novel procedure\ncalled \"concept scrubbing,\" which erases target concept information from every\nlayer in the network. We demonstrate the usefulness of our method on two tasks:\nmeasuring the reliance of language models on part-of-speech information, and\nreducing gender bias in BERT embeddings. Code is available at\nhttps://github.com/EleutherAI/concept-erasure.",
        "translated": "概念擦除的目的是从表示中去除特定的特征。它可以用来提高公平性(例如防止分类器使用性别或种族)和可解释性(例如移除观察模型行为变化的概念)。本文介绍了最小二乘概念擦除(LEACE)方法，这是一种可证明的闭式方法，它可以防止所有的线性分类器检测到一个概念，同时对表示造成最小可能的损害。我们将 LEACE 应用到大型语言模型中，使用了一种称为“概念擦除”的新方法，这种方法可以从网络的每一层删除目标概念信息。我们证明了我们的方法在两个任务上的有用性: 测量语言模型对词性信息的依赖性，以及减少 BERT 嵌入中的性别偏见。密码可于 https://github.com/eleutherai/concept-erasure 索取。"
    },
    {
        "title": "Prompt Space Optimizing Few-shot Reasoning Success with Large Language\n  Models",
        "url": "http://arxiv.org/abs/2306.03799v1",
        "pub_date": "2023-06-06",
        "summary": "Prompt engineering is an essential technique for enhancing the abilities of\nlarge language models (LLMs) by providing explicit and specific instructions.\nIt enables LLMs to excel in various tasks, such as arithmetic reasoning,\nquestion answering, summarization, relation extraction, machine translation,\nand sentiment analysis. Researchers have been actively exploring different\nprompt engineering strategies, such as Chain of Thought (CoT), Zero-CoT, and\nIn-context learning. However, an unresolved problem arises from the fact that\ncurrent approaches lack a solid theoretical foundation for determining optimal\nprompts. To address this issue in prompt engineering, we propose a new and\neffective approach called Prompt Space. Our methodology utilizes text\nembeddings to obtain basis vectors by matrix decomposition, and then constructs\na space for representing all prompts. Prompt Space significantly outperforms\nstate-of-the-art prompt paradigms on ten public reasoning benchmarks. Notably,\nwithout the help of the CoT method and the prompt \"Let's think step by step\",\nPrompt Space shows superior performance over the few-shot method. Overall, our\napproach provides a robust and fundamental theoretical framework for selecting\nsimple and effective prompts. This advancement marks a significant step towards\nimproving prompt engineering for a wide variety of applications in LLMs.",
        "translated": "提示工程是通过提供明确和具体的指令来提高大型语言模型(LLM)能力的一种基本技术。它使 LLM 能够胜任各种任务，例如算术推理、问题回答、总结、关系提取、机器翻译和情感分析。研究人员一直在积极探索不同的快速工程策略，如思维链(CoT) ，零 CoT 和在上下文中学习。然而，一个未解决的问题出现在这样一个事实上，即目前的方法缺乏确定最佳提示的坚实的理论基础。为了在快速工程中解决这个问题，我们提出了一种新的和有效的方法称为快速空间。我们的方法利用文本嵌入通过矩阵分解获得基向量，然后构造一个空间来表示所有的提示。Prompt Space 在10个公共推理基准上明显优于最先进的提示范例。值得注意的是，没有 CoT 方法和提示“让我们一步一步地思考”的帮助，Prompt Space 显示出优于少数镜头方法的性能。总的来说，我们的方法为选择简单有效的提示提供了一个强大的基础理论框架。这一进展标志着在改进 LLM 中各种应用的快速工程方面迈出了重要的一步。"
    },
    {
        "title": "MarineVRS: Marine Video Retrieval System with Explainability via\n  Semantic Understanding",
        "url": "http://arxiv.org/abs/2306.04593v1",
        "pub_date": "2023-06-07",
        "summary": "Building a video retrieval system that is robust and reliable, especially for\nthe marine environment, is a challenging task due to several factors such as\ndealing with massive amounts of dense and repetitive data, occlusion,\nblurriness, low lighting conditions, and abstract queries. To address these\nchallenges, we present MarineVRS, a novel and flexible video retrieval system\ndesigned explicitly for the marine domain. MarineVRS integrates\nstate-of-the-art methods for visual and linguistic object representation to\nenable efficient and accurate search and analysis of vast volumes of underwater\nvideo data. In addition, unlike the conventional video retrieval system, which\nonly permits users to index a collection of images or videos and search using a\nfree-form natural language sentence, our retrieval system includes an\nadditional Explainability module that outputs the segmentation masks of the\nobjects that the input query referred to. This feature allows users to identify\nand isolate specific objects in the video footage, leading to more detailed\nanalysis and understanding of their behavior and movements. Finally, with its\nadaptability, explainability, accuracy, and scalability, MarineVRS is a\npowerful tool for marine researchers and scientists to efficiently and\naccurately process vast amounts of data and gain deeper insights into the\nbehavior and movements of marine species.",
        "translated": "建立一个健壮可靠的视频检索系统，特别是对于海洋环境来说，是一个具有挑战性的任务，因为有几个因素，如处理大量密集和重复的数据，遮挡，模糊，低照明条件和抽象查询。为了应对这些挑战，我们提出了 MarineVRS，一个新颖的和灵活的视频检索系统，明确地为海洋领域设计。MarineVRS 集成了最先进的视觉和语言对象表示方法，能够高效、准确地搜索和分析海量水下视频数据。此外，与传统的视频检索系统不同，传统的视频检索系统只允许用户索引一组图像或视频并使用自由格式的自然语言句子进行搜索，我们的检索系统包括一个额外的可解释性模块，该模块输出输入查询引用的对象的分割掩码。这个功能允许用户识别和隔离视频画面中的特定物体，从而对它们的行为和动作进行更详细的分析和理解。最后，凭借其适应性、可解释性、准确性和可扩展性，MarineVRS 是海洋研究人员和科学家有效和准确地处理大量数据并获得对海洋物种行为和运动的更深刻见解的强大工具。"
    },
    {
        "title": "Constraint-based recommender system for crisis management simulations",
        "url": "http://arxiv.org/abs/2306.04553v1",
        "pub_date": "2023-06-07",
        "summary": "In the context of the evacuation of populations, some citizens/volunteers may\nwant and be able to participate in the evacuation of populations in difficulty\nby coming to lend a hand to emergency/evacuation vehicles with their own\nvehicles. One way of framing these impulses of solidarity would be to be able\nto list in real-time the citizens/volunteers available with their vehicles\n(land, sea, air, etc.), to be able to geolocate them according to the risk\nareas to be evacuated, and adding them to the evacuation/rescue vehicles.\nBecause it is difficult to propose an effective real-time operational system on\nthe field in a real crisis situation, in this work, we propose to add a module\nfor recommending driver/vehicle pairs (with their specificities) to a system of\ncrisis management simulation. To do that, we chose to model and develop an\nontology-supported constraint-based recommender system for crisis management\nsimulations.",
        "translated": "在疏散人口方面，一些公民/志愿人员可能希望并能够参与疏散有困难的人口，他们可以用自己的车辆向紧急/疏散车辆伸出援手。构建这些团结冲动的一种方式是能够实时列出可用车辆(陆地、海洋、空中等)的公民/志愿者，能够根据疏散的危险区域对他们进行地理定位，并将他们添加到疏散/救援车辆中。由于在真实的危机情况下很难提出一个有效的现场实时操作系统，本文提出在危机管理模拟系统中增加一个推荐驾驶员/车辆配对(及其特殊性)的模块。为此，我们选择建模和开发一个本体支持的基于约束的危机管理模拟推荐系统。"
    },
    {
        "title": "Embracing Uncertainty: Adaptive Vague Preference Policy Learning for\n  Multi-round Conversational Recommendation",
        "url": "http://arxiv.org/abs/2306.04487v1",
        "pub_date": "2023-06-07",
        "summary": "Conversational recommendation systems (CRS) effectively address information\nasymmetry by dynamically eliciting user preferences through multi-turn\ninteractions. Existing CRS widely assumes that users have clear preferences.\nUnder this assumption, the agent will completely trust the user feedback and\ntreat the accepted or rejected signals as strong indicators to filter items and\nreduce the candidate space, which may lead to the problem of over-filtering.\nHowever, in reality, users' preferences are often vague and volatile, with\nuncertainty about their desires and changing decisions during interactions.\n  To address this issue, we introduce a novel scenario called Vague Preference\nMulti-round Conversational Recommendation (VPMCR), which considers users' vague\nand volatile preferences in CRS.VPMCR employs a soft estimation mechanism to\nassign a non-zero confidence score for all candidate items to be displayed,\nnaturally avoiding the over-filtering problem. In the VPMCR setting, we\nintroduce an solution called Adaptive Vague Preference Policy Learning (AVPPL),\nwhich consists of two main components: Uncertainty-aware Soft Estimation (USE)\nand Uncertainty-aware Policy Learning (UPL). USE estimates the uncertainty of\nusers' vague feedback and captures their dynamic preferences using a\nchoice-based preferences extraction module and a time-aware decaying strategy.\nUPL leverages the preference distribution estimated by USE to guide the\nconversation and adapt to changes in users' preferences to make recommendations\nor ask for attributes.\n  Our extensive experiments demonstrate the effectiveness of our method in the\nVPMCR scenario, highlighting its potential for practical applications and\nimproving the overall performance and applicability of CRS in real-world\nsettings, particularly for users with vague or dynamic preferences.",
        "translated": "会话推荐系统(CRS)通过多回合交互动态引出用户偏好，从而有效地解决信息不对称问题。现有的 CRS 普遍假设用户有明确的偏好。在这种假设下，代理完全信任用户的反馈，将接受或拒绝的信号作为强指标来过滤项目，减少候选空间，从而可能导致过滤问题。然而，在现实中，用户的偏好往往是模糊和不稳定的，他们的愿望和交互过程中改变决定的不确定性。为了解决这一问题，我们引入了一种新的场景——模糊偏好多轮会话推荐(VPMCR) ，该场景考虑了 CRS 中用户的模糊和不稳定偏好。 VPMCR 采用了一种软估计机制，为所有待显示的候选项赋予一个非零置信度分数，自然避免了过滤问题。在 VPCR 设置中，我们引入了一个称为自适应模糊偏好策略学习(AdaptiveVague Preferences Policy Learning，AVPPL)的解决方案，该解决方案由两个主要组件组成: 不确定感知软估计(UUSE)和不确定感知策略学习(UPL)。USE 利用基于选择的偏好提取模块和时间感知衰减策略估计用户模糊反馈的不确定性，并获取用户的动态偏好。UPL 利用 USE 估计的偏好分布来引导对话，并适应用户偏好的变化来提出建议或请求属性。我们的广泛实验证明了我们的方法在 VPCR 场景中的有效性，突出了其实际应用的潜力，并提高了 CRS 在现实世界环境中的总体性能和适用性，特别是对于具有模糊或动态偏好的用户。"
    },
    {
        "title": "RD-Suite: A Benchmark for Ranking Distillation",
        "url": "http://arxiv.org/abs/2306.04455v1",
        "pub_date": "2023-06-07",
        "summary": "The distillation of ranking models has become an important topic in both\nacademia and industry. In recent years, several advanced methods have been\nproposed to tackle this problem, often leveraging ranking information from\nteacher rankers that is absent in traditional classification settings. To date,\nthere is no well-established consensus on how to evaluate this class of models.\nMoreover, inconsistent benchmarking on a wide range of tasks and datasets make\nit difficult to assess or invigorate advances in this field. This paper first\nexamines representative prior arts on ranking distillation, and raises three\nquestions to be answered around methodology and reproducibility. To that end,\nwe propose a systematic and unified benchmark, Ranking Distillation Suite\n(RD-Suite), which is a suite of tasks with 4 large real-world datasets,\nencompassing two major modalities (textual and numeric) and two applications\n(standard distillation and distillation transfer). RD-Suite consists of\nbenchmark results that challenge some of the common wisdom in the field, and\nthe release of datasets with teacher scores and evaluation scripts for future\nresearch. RD-Suite paves the way towards better understanding of ranking\ndistillation, facilities more research in this direction, and presents new\nchallenges.",
        "translated": "排序模型的提取已经成为学术界和工业界的一个重要课题。近年来，一些先进的方法被提出来解决这个问题，往往利用排名信息从教师排名，这是缺乏在传统的分类设置。到目前为止，对于如何评估这类模型还没有确定的共识。此外，对广泛的任务和数据集不一致的基准设定使得难以评估或激励这一领域的进展。本文首先考察了有代表性的等级精馏现有技术，并围绕方法论和可重复性提出了三个需要回答的问题。为此，我们提出了一个系统和统一的基准，秩序蒸馏套件(RD-Suite) ，这是一套任务与4个大型真实世界数据集，包括两个主要模式(文本和数字)和两个应用程序(标准蒸馏和蒸馏转移)。RD-Suite 包括挑战该领域常识的基准测试结果，以及发布包含教师成绩和未来研究评估脚本的数据集。RD-Suite 为更好地理解分级蒸馏铺平了道路，设备在这个方向上进行了更多的研究，并提出了新的挑战。"
    },
    {
        "title": "Modeling Dual Period-Varying Preferences for Takeaway Recommendation",
        "url": "http://arxiv.org/abs/2306.04370v1",
        "pub_date": "2023-06-07",
        "summary": "Takeaway recommender systems, which aim to accurately provide stores that\noffer foods meeting users' interests, have served billions of users in our\ndaily life. Different from traditional recommendation, takeaway recommendation\nfaces two main challenges: (1) Dual Interaction-Aware Preference Modeling.\nTraditional recommendation commonly focuses on users' single preferences for\nitems while takeaway recommendation needs to comprehensively consider users'\ndual preferences for stores and foods. (2) Period-Varying Preference Modeling.\nConventional recommendation generally models continuous changes in users'\npreferences from a session-level or day-level perspective. However, in\npractical takeaway systems, users' preferences vary significantly during the\nmorning, noon, night, and late night periods of the day. To address these\nchallenges, we propose a Dual Period-Varying Preference modeling (DPVP) for\ntakeaway recommendation. Specifically, we design a dual interaction-aware\nmodule, aiming to capture users' dual preferences based on their interactions\nwith stores and foods. Moreover, to model various preferences in different time\nperiods of the day, we propose a time-based decomposition module as well as a\ntime-aware gating mechanism. Extensive offline and online experiments\ndemonstrate that our model outperforms state-of-the-art methods on real-world\ndatasets and it is capable of modeling the dual period-varying preferences.\nMoreover, our model has been deployed online on Meituan Takeaway platform,\nleading to an average improvement in GMV (Gross Merchandise Value) of 0.70%.",
        "translated": "外卖推荐系统，旨在准确地提供商店，提供符合用户兴趣的食品，已服务于数十亿用户在我们的日常生活。与传统的推荐不同，外卖推荐面临着两个主要挑战: (1)双交互感知偏好建模。传统的推荐方式通常侧重于用户对商品的单一偏好，而外卖推荐方式则需要全面考虑用户对商店和食品的双重偏好。(变周期偏好模型。传统的推荐通常从会话级或日级的角度模拟用户偏好的持续变化。然而，在实际的外卖系统中，用户的偏好在白天的早上、中午、晚上和深夜各不相同。为了应对这些挑战，我们提出了一个外卖推荐的双周期变化偏好模型(DPVP)。具体来说，我们设计了一个双交互感知模块，旨在根据用户与商店和食物的交互来捕捉他们的双重偏好。此外，为了模拟一天中不同时段的各种偏好，我们提出了一个基于时间的分解模块以及一个时间感知的门控机制。大量的离线和在线实验表明，我们的模型优于现实世界数据集的最先进的方法，它能够建模的双周期变化的偏好。此外，我们的模型已经在美团外卖平台上进行了在线部署，导致平均商品总值(GMV)提高了0.70% 。"
    },
    {
        "title": "ModuleFormer: Learning Modular Large Language Models From Uncurated Data",
        "url": "http://arxiv.org/abs/2306.04640v1",
        "pub_date": "2023-06-07",
        "summary": "Large Language Models (LLMs) have achieved remarkable results. But existing\nmodels are expensive to train and deploy, and it is also difficult to expand\ntheir knowledge beyond pre-training data without forgetting previous knowledge.\nThis paper proposes a new neural network architecture, ModuleFormer, that\nleverages modularity to improve the efficiency and flexibility of large\nlanguage models. ModuleFormer is based on the Sparse Mixture of Experts (SMoE).\nUnlike the previous SMoE-based modular language model [Gururangan et al.,\n2021], which requires domain-labeled data to learn domain-specific experts,\nModuleFormer can induce modularity from uncurated data with its new load\nbalancing and load concentration losses. ModuleFormer is a modular architecture\nthat includes two different types of modules, new stick-breaking attention\nheads, and feedforward experts. Different modules are sparsely activated\nconditions on the input token during training and inference. In our experiment,\nwe found that the modular architecture enables three important abilities for\nlarge pre-trained language models: 1) Efficiency, since ModuleFormer only\nactivates a subset of its modules for each input token, thus it could achieve\nthe same performance as dense LLMs with more than two times throughput; 2)\nExtendability, ModuleFormer is more immune to catastrophic forgetting than\ndense LLMs and can be easily extended with new modules to learn new knowledge\nthat is not included in the training data; 3) Specialisation, finetuning\nModuleFormer could specialize a subset of modules to the finetuning task, and\nthe task-unrelated modules could be easily pruned for a lightweight deployment.",
        "translated": "大语言模型(LLM)已经取得了显著的成果。但现有模型的培训和部署成本很高，而且很难在不忘记先前知识的情况下扩展其知识范围，超出培训前的数据。本文提出了一种新的神经网络结构——模块化网络结构，该结构利用模块化来提高大型语言模型的效率和灵活性。基于稀疏混合专家算法(SMoE)的模块形成器。与以前基于 SMoE 的模块化语言模型[ Gururangan et al。 ，2021]不同，其需要领域标记的数据来学习领域特定的专家，ModuleForm 可以通过其新的负载平衡和负载集中损失来诱导未经策划的数据的模块化。ModuleForm 是一个模块化架构，包括两种不同类型的模块、新的分散注意力的头部和前馈专家。在训练和推理过程中，不同的模块在输入令牌上是稀疏激活的条件。在我们的实验中，我们发现模块化架构为大型预先训练的语言模型提供了三个重要的能力: 1)效率，因为模块化程序只为每个输入令牌激活其模块的一个子集，因此它可以达到与密集 LLM 相同的性能，吞吐量超过两倍; 2)可扩展性，模块化程序比密集 LLM 更能免疫灾难性遗忘，并且可以很容易地用新模块进行扩展，以学习未包含在训练数据中的新知识; 3)专业化，微调的模块化程序可以为微调任务专门化模块的一个子集，并且与任务无关的模块可以很容易地为。"
    },
    {
        "title": "Transformers as Statisticians: Provable In-Context Learning with\n  In-Context Algorithm Selection",
        "url": "http://arxiv.org/abs/2306.04637v1",
        "pub_date": "2023-06-07",
        "summary": "Neural sequence models based on the transformer architecture have\ndemonstrated remarkable \\emph{in-context learning} (ICL) abilities, where they\ncan perform new tasks when prompted with training and test examples, without\nany parameter update to the model. This work first provides a comprehensive\nstatistical theory for transformers to perform ICL. Concretely, we show that\ntransformers can implement a broad class of standard machine learning\nalgorithms in context, such as least squares, ridge regression, Lasso, learning\ngeneralized linear models, and gradient descent on two-layer neural networks,\nwith near-optimal predictive power on various in-context data distributions.\nUsing an efficient implementation of in-context gradient descent as the\nunderlying mechanism, our transformer constructions admit mild size bounds, and\ncan be learned with polynomially many pretraining sequences.\n  Building on these ``base'' ICL algorithms, intriguingly, we show that\ntransformers can implement more complex ICL procedures involving\n\\emph{in-context algorithm selection}, akin to what a statistician can do in\nreal life -- A \\emph{single} transformer can adaptively select different base\nICL algorithms -- or even perform qualitatively different tasks -- on different\ninput sequences, without any explicit prompting of the right algorithm or task.\nWe both establish this in theory by explicit constructions, and also observe\nthis phenomenon experimentally. In theory, we construct two general mechanisms\nfor algorithm selection with concrete examples: pre-ICL testing, and post-ICL\nvalidation. As an example, we use the post-ICL validation mechanism to\nconstruct a transformer that can perform nearly Bayes-optimal ICL on a\nchallenging task -- noisy linear models with mixed noise levels.\nExperimentally, we demonstrate the strong in-context algorithm selection\ncapabilities of standard transformer architectures.",
        "translated": "基于变压器结构的神经序列模型表现出了显著的移动{在上下文中学习}(ICL)能力，它们可以在训练和测试示例的提示下执行新的任务，而不需要对模型进行任何参数更新。这项工作首先为变压器执行 ICL 提供了一个全面的统计理论。具体来说，我们展示了变压器可以在上下文环境中实现一大类标准的机器学习算法，如最小二乘、岭回归、套索、学习广义线性模型，以及在两层神经网络上实现梯度下降法，对各种上下文数据分布具有近乎最优的预测能力。使用一个有效的实现在上下文中的梯度下降法作为底层机制，我们的变压器结构承认温和的大小界限，可以学习与多项式许多预训练序列。在这些“基本”ICL 算法的基础上，有趣的是，我们展示了变压器可以实现更复杂的 ICL 程序，包括 emph { in-context 算法选择} ，类似于统计学家在现实生活中可以做的——一个 emph { single }变压器可以自适应地选择不同的基本 ICL 算法——甚至可以执行定性上不同的任务——在不同的输入序列上，没有任何明确的正确算法或任务的提示。我们通过明确的结构在理论上建立了这种现象，并且通过实验观察了这种现象。在理论上，我们通过具体的实例构造了两种通用的算法选择机制: 前 ICL 测试和后 ICL 验证。作为一个例子，我们使用后 ICL 验证机制来构造一个变压器，可以执行接近贝叶斯最优的 ICL 在一个具有挑战性的任务-混合噪声水平的线性模型。实验表明，标准变压器结构具有很强的上下文算法选择能力。"
    },
    {
        "title": "On the Reliability of Watermarks for Large Language Models",
        "url": "http://arxiv.org/abs/2306.04634v1",
        "pub_date": "2023-06-07",
        "summary": "Large language models (LLMs) are now deployed to everyday use and positioned\nto produce large quantities of text in the coming decade. Machine-generated\ntext may displace human-written text on the internet and has the potential to\nbe used for malicious purposes, such as spearphishing attacks and social media\nbots. Watermarking is a simple and effective strategy for mitigating such harms\nby enabling the detection and documentation of LLM-generated text. Yet, a\ncrucial question remains: How reliable is watermarking in realistic settings in\nthe wild? There, watermarked text might be mixed with other text sources,\nparaphrased by human writers or other language models, and used for\napplications in a broad number of domains, both social and technical. In this\npaper, we explore different detection schemes, quantify their power at\ndetecting watermarks, and determine how much machine-generated text needs to be\nobserved in each scenario to reliably detect the watermark. We especially\nhighlight our human study, where we investigate the reliability of watermarking\nwhen faced with human paraphrasing. We compare watermark-based detection to\nother detection strategies, finding overall that watermarking is a reliable\nsolution, especially because of its sample complexity - for all attacks we\nconsider, the watermark evidence compounds the more examples are given, and the\nwatermark is eventually detected.",
        "translated": "大型语言模型(LLM)现在被部署到日常使用中，并定位于在未来十年生成大量文本。机器生成的文本可能取代互联网上人写的文本，并有可能被用于恶意目的，如鱼叉式钓鱼攻击和社交媒体机器人。水印是一种简单而有效的策略，通过检测和记录 LLM 生成的文本来减轻这种危害。然而，一个关键的问题仍然存在: 在野外的现实环境中，水印的可靠性如何？在那里，水印文本可能与其他文本来源混合，由人类作家或其他语言模型转述，并用于广泛的领域中的应用，包括社会和技术。在本文中，我们探讨了不同的检测方案，量化它们在检测水印方面的能力，并确定在每个场景中需要观察多少机器生成的文本才能可靠地检测水印。我们特别强调我们的人类研究，我们调查的可靠性水印时，面对人类释义。我们比较了基于水印的检测和其他检测策略，发现水印是一个可靠的解决方案，特别是因为它的样本复杂性-对于所有的攻击，我们考虑，水印证据复合越多的例子，并最终检测水印。"
    },
    {
        "title": "Revisiting Out-of-distribution Robustness in NLP: Benchmark, Analysis,\n  and LLMs Evaluations",
        "url": "http://arxiv.org/abs/2306.04618v1",
        "pub_date": "2023-06-07",
        "summary": "This paper reexamines the research on out-of-distribution (OOD) robustness in\nthe field of NLP. We find that the distribution shift settings in previous\nstudies commonly lack adequate challenges, hindering the accurate evaluation of\nOOD robustness. To address these issues, we propose a benchmark construction\nprotocol that ensures clear differentiation and challenging distribution\nshifts. Then we introduce BOSS, a Benchmark suite for Out-of-distribution\nrobustneSS evaluation covering 5 tasks and 20 datasets. Based on BOSS, we\nconduct a series of experiments on pre-trained language models for analysis and\nevaluation of OOD robustness. First, for vanilla fine-tuning, we examine the\nrelationship between in-distribution (ID) and OOD performance. We identify\nthree typical types that unveil the inner learning mechanism, which could\npotentially facilitate the forecasting of OOD robustness, correlating with the\nadvancements on ID datasets. Then, we evaluate 5 classic methods on BOSS and\nfind that, despite exhibiting some effectiveness in specific cases, they do not\noffer significant improvement compared to vanilla fine-tuning. Further, we\nevaluate 5 LLMs with various adaptation paradigms and find that when sufficient\nID data is available, fine-tuning domain-specific models outperform LLMs on ID\nexamples significantly. However, in the case of OOD instances, prioritizing\nLLMs with in-context learning yields better results. We identify that both\nfine-tuned small models and LLMs face challenges in effectively addressing\ndownstream tasks. The code is public at\n\\url{https://github.com/lifan-yuan/OOD_NLP}.",
        "translated": "本文重新审视了自然语言处理领域中分布外(OOD)鲁棒性的研究。我们发现在以往的研究中，分布移位设置通常缺乏足够的挑战，阻碍了面向对象的鲁棒性的准确评估。为了解决这些问题，我们提出了一个基准建设协议，以确保明确的差异和挑战性的分配转移。然后我们介绍了 BOSS，一个用于分布外鲁棒性评估的基准套件，包括5个任务和20个数据集。基于 BOSS 系统，我们对预训练语言模型进行了一系列的实验，用于分析和评估面向对象的鲁棒性。首先，对于普通的微调，我们研究分发内(ID)和 OOD 性能之间的关系。我们确定了三种典型的类型，揭示了内部学习机制，这可能有助于面向对象的鲁棒性预测，与 ID 数据集的进步相关。然后，我们对 BOSS 上的5种经典方法进行了评估，发现尽管它们在特定情况下显示出一些有效性，但与普通的微调相比，它们并没有提供显著的改进。此外，我们评估了5个具有不同适应范例的 LLM，发现当有足够的 ID 数据可用时，针对特定领域的微调模型在 ID 示例上的表现明显优于 LLM。但是，在面向对象的实例中，使用上下文内学习对 LLM 进行优先排序会产生更好的结果。我们发现，微调小型模型和 LLM 在有效处理下游任务方面都面临挑战。该代码在 url { https://github.com/lifan-yuan/ood_nlp }是公共的。"
    },
    {
        "title": "The Two Word Test: A Semantic Benchmark for Large Language Models",
        "url": "http://arxiv.org/abs/2306.04610v1",
        "pub_date": "2023-06-07",
        "summary": "Large Language Models (LLMs) have shown remarkable abilities recently,\nincluding passing advanced professional exams and demanding benchmark tests.\nThis performance has led many to suggest that they are close to achieving\nhumanlike or 'true' understanding of language, and even Artificial General\nIntelligence (AGI). Here, we provide a new open-source benchmark that can\nassess semantic abilities of LLMs using two-word phrases using a task that can\nbe performed relatively easily by humans without advanced training. Combining\nmultiple words into a single concept is a fundamental aspect of human language\nand intelligence. The test requires meaningfulness judgments of 1768 noun-noun\ncombinations that have been rated as meaningful (e.g., baby boy) or not\nmeaningful (e.g., goat sky). by 150 human raters. We provide versions of the\ntask that probe meaningfulness ratings on a 0-4 scale as well as binary\njudgments. We conducted a series of experiments using the TWT on GPT-4,\nGPT-3.5, and Bard, with both versions. Results demonstrated that, compared to\nhumans, all models perform poorly at rating meaningfulness of these phrases.\nGPT-3.5 and Bard are also unable to make binary discriminations between\nsensible and nonsense phrases as making sense. GPT-4 makes a substantial\nimprovement in binary discrimination of combinatorial phrases but is still\nsignificantly worse than human performance. The TWT can be used to understand\nthe limitations and weaknesses of current LLMs, and potentially improve them.\nThe test also reminds us that caution is warranted in attributing 'true\nunderstanding' or AGI to LLMs. TWT is available at:\nhttps://github.com/NickRiccardi/two-word-test",
        "translated": "大型语言模型(LLM)最近显示出非凡的能力，包括通过高级专业考试和苛刻的基准测试。这种表现使得许多人认为他们已经接近达到类人或“真正”理解语言，甚至人工通用智能(AGI)。在这里，我们提供了一个新的开源基准，可以使用两个词的短语来评估 LLM 的语义能力，使用的任务可以相对容易地由人类执行，而不需要高级培训。将多个单词组合成一个单一的概念是人类语言和智力的一个基本方面。这个测试需要对1768个名词和名词的组合进行有意义的判断，这些组合被认为是有意义的(比如，男婴)或者没有意义的(比如，山羊天空)。被150个人类评估员评估。我们提供了任务的版本，探讨有意义的评级在0-4尺度以及二元判断。我们使用行波管在 GPT-4、 GPT-3.5和巴德上进行了一系列的实验，两个版本都有。结果表明，与人类相比，所有的模型在评价这些短语的意义方面表现不佳。GPT-3.5和巴德也不能把明智的和无意义的短语作为有意义的二元区分。GPT-4在组合短语的二进制识别方面有显著改善，但仍明显低于人类的识别水平。行波管可以用来了解现有 LLM 的局限性和弱点，并可能改进它们。该测试还提醒我们，在将“真正的理解”或 AGI 归因于 LLM 时，谨慎是必要的。TWT 可在以下 https://github.com/nickriccardi/two-word-test 购买:"
    },
    {
        "title": "Language Models Get a Gender Makeover: Mitigating Gender Bias with\n  Few-Shot Data Interventions",
        "url": "http://arxiv.org/abs/2306.04597v1",
        "pub_date": "2023-06-07",
        "summary": "Societal biases present in pre-trained large language models are a critical\nissue as these models have been shown to propagate biases in countless\ndownstream applications, rendering them unfair towards specific groups of\npeople. Since large-scale retraining of these models from scratch is both time\nand compute-expensive, a variety of approaches have been previously proposed\nthat de-bias a pre-trained model. While the majority of current\nstate-of-the-art debiasing methods focus on changes to the training regime, in\nthis paper, we propose data intervention strategies as a powerful yet simple\ntechnique to reduce gender bias in pre-trained models. Specifically, we\nempirically show that by fine-tuning a pre-trained model on only 10 de-biased\n(intervened) training examples, the tendency to favor any gender is\nsignificantly reduced. Since our proposed method only needs a few training\nexamples, our few-shot debiasing approach is highly feasible and practical.\nThrough extensive experimentation, we show that our debiasing technique\nperforms better than competitive state-of-the-art baselines with minimal loss\nin language modeling ability.",
        "translated": "预先训练的大型语言模型中存在的社会偏见是一个关键问题，因为这些模型已被证明在无数下游应用程序中传播偏见，使它们对特定人群不公平。由于从头开始对这些模型进行大规模的再训练既耗费时间又耗费计算机资源，因此先前已经提出了各种方法来消除预训练模型的偏差。虽然目前大多数最先进的消除偏见的方法集中在训练体制的变化，在本文中，我们提出的数据干预策略作为一个强大而简单的技术，以减少预训练模型中的性别偏见。具体来说，我们的经验表明，通过微调一个预先训练的模型，只有10个无偏见(干预)训练的例子，倾向于任何性别显着降低。由于本文提出的方法只需要少量训练样本，因此本文提出的小镜头消偏方法具有很高的可行性和实用性。通过大量的实验，我们发现我们的去偏技术在语言建模能力损失最小的情况下比竞争性的最先进的基线表现得更好。"
    },
    {
        "title": "Gender, names and other mysteries: Towards the ambiguous for\n  gender-inclusive translation",
        "url": "http://arxiv.org/abs/2306.04573v1",
        "pub_date": "2023-06-07",
        "summary": "The vast majority of work on gender in MT focuses on 'unambiguous' inputs,\nwhere gender markers in the source language are expected to be resolved in the\noutput. Conversely, this paper explores the widespread case where the source\nsentence lacks explicit gender markers, but the target sentence contains them\ndue to richer grammatical gender. We particularly focus on inputs containing\nperson names.\n  Investigating such sentence pairs casts a new light on research into MT\ngender bias and its mitigation. We find that many name-gender co-occurrences in\nMT data are not resolvable with 'unambiguous gender' in the source language,\nand that gender-ambiguous examples can make up a large proportion of training\nexamples. From this, we discuss potential steps toward gender-inclusive\ntranslation which accepts the ambiguity in both gender and translation.",
        "translated": "在机器翻译领域，绝大多数关于性别的工作集中在“明确的”输入上，源语言中的性别标记预计将在输出中得到解决。相反，本文探讨了普遍存在的一种情况，即原句缺乏明确的性别标记，但是由于性丰富，目标句包含了这些性别标记。我们特别关注包含人名的输入。对这类句子对的研究为 MT 性别偏见的研究及其缓解提供了新的视角。我们发现，在机器翻译数据中，许多名称-性别同时出现的情况不能用源语言中的“明确的性别”来解决，而且性别模糊的例子可以构成很大比例的训练例子。从这一点出发，我们讨论了实现性别包容性翻译的可能步骤，即接受性别歧义和翻译歧义。"
    },
    {
        "title": "ChatGPT is fun, but it is not funny! Humor is still challenging Large\n  Language Models",
        "url": "http://arxiv.org/abs/2306.04563v1",
        "pub_date": "2023-06-07",
        "summary": "Humor is a central aspect of human communication that has not been solved for\nartificial agents so far. Large language models (LLMs) are increasingly able to\ncapture implicit and contextual information. Especially, OpenAI's ChatGPT\nrecently gained immense public attention. The GPT3-based model almost seems to\ncommunicate on a human level and can even tell jokes. Humor is an essential\ncomponent of human communication. But is ChatGPT really funny? We put ChatGPT's\nsense of humor to the test. In a series of exploratory experiments around\njokes, i.e., generation, explanation, and detection, we seek to understand\nChatGPT's capability to grasp and reproduce human humor. Since the model itself\nis not accessible, we applied prompt-based experiments. Our empirical evidence\nindicates that jokes are not hard-coded but mostly also not newly generated by\nthe model. Over 90% of 1008 generated jokes were the same 25 Jokes. The system\naccurately explains valid jokes but also comes up with fictional explanations\nfor invalid jokes. Joke-typical characteristics can mislead ChatGPT in the\nclassification of jokes. ChatGPT has not solved computational humor yet but it\ncan be a big leap toward \"funny\" machines.",
        "translated": "幽默是人类交流的一个核心方面，迄今为止人工智能还没有解决这个问题。大型语言模型(LLM)越来越能够捕获隐式信息和上下文信息。尤其是 OpenAI 的 ChatGPT 最近引起了公众的广泛关注。基于 GPT3的模型几乎可以在人类水平上交流，甚至可以讲笑话。幽默是人际交往的重要组成部分。但是聊天 GPT 真的有趣吗？我们测试了 ChatGPT 的幽默感。在一系列围绕笑话的探索性实验中，即生成、解释和发现，我们试图理解 ChatGPT 掌握和再现人类幽默的能力。由于模型本身不可访问，我们应用了基于提示的实验。我们的经验证明表明，笑话不是硬编码的，但大多数也不是模型新生成的。在1008个笑话中，超过90% 的笑话都是相同的25个。该系统准确地解释了有效的笑话，但同时也为无效的笑话提供了虚构的解释。笑话的典型特征会误导聊天 GPT 对笑话的分类。ChatGPT 还没有解决计算幽默问题，但是它可以向“有趣的”机器迈出一大步。"
    },
    {
        "title": "Multi-Task Training with In-Domain Language Models for Diagnostic\n  Reasoning",
        "url": "http://arxiv.org/abs/2306.04551v1",
        "pub_date": "2023-06-07",
        "summary": "Generative artificial intelligence (AI) is a promising direction for\naugmenting clinical diagnostic decision support and reducing diagnostic errors,\na leading contributor to medical errors. To further the development of clinical\nAI systems, the Diagnostic Reasoning Benchmark (DR.BENCH) was introduced as a\ncomprehensive generative AI framework, comprised of six tasks representing key\ncomponents in clinical reasoning. We present a comparative analysis of\nin-domain versus out-of-domain language models as well as multi-task versus\nsingle task training with a focus on the problem summarization task in DR.BENCH\n(Gao et al., 2023). We demonstrate that a multi-task, clinically trained\nlanguage model outperforms its general domain counterpart by a large margin,\nestablishing a new state-of-the-art performance, with a ROUGE-L score of 28.55.\nThis research underscores the value of domain-specific training for optimizing\nclinical diagnostic reasoning tasks.",
        "translated": "生成性人工智能(AI)是增强临床诊断决策支持和减少诊断错误的一个有前途的方向，是导致医疗错误的主要因素。为了进一步发展临床人工智能系统，将诊断推理基准(DR.BENCH)作为一个全面的生成性人工智能框架引入，该框架由代表临床推理关键组成部分的六个任务组成。我们提出了领域内与领域外语言模型以及多任务与单任务训练的比较分析，重点是 DR.BENCH 中的问题总结任务(Gao et al。 ，2023)。我们证明，一个多任务，临床训练的语言模型优于其一般领域的对应大幅度，建立一个新的最先进的表现，ROUGE-L 分数为28.55。本研究强调了领域特定训练对于优化临床诊断推理任务的价值。"
    },
    {
        "title": "Contrastive Bootstrapping for Label Refinement",
        "url": "http://arxiv.org/abs/2306.04544v1",
        "pub_date": "2023-06-07",
        "summary": "Traditional text classification typically categorizes texts into pre-defined\ncoarse-grained classes, from which the produced models cannot handle the\nreal-world scenario where finer categories emerge periodically for accurate\nservices. In this work, we investigate the setting where fine-grained\nclassification is done only using the annotation of coarse-grained categories\nand the coarse-to-fine mapping. We propose a lightweight contrastive\nclustering-based bootstrapping method to iteratively refine the labels of\npassages. During clustering, it pulls away negative passage-prototype pairs\nunder the guidance of the mapping from both global and local perspectives.\nExperiments on NYT and 20News show that our method outperforms the\nstate-of-the-art methods by a large margin.",
        "translated": "传统的文本分类通常将文本分类为预定义的粗粒度类，由此产生的模型无法处理现实场景，即定期出现更精细的类别以获得准确的服务。在这项工作中，我们研究的设置，细粒度分类是完成只使用粗粒度类别的注释和粗到细的映射。提出了一种基于轻量级对比聚类的自举算法来迭代细化文章标签。在聚类过程中，它在映射的指导下，从全局和局部两个角度抽取负的通道原型对。在《纽约时报》和《20世纪新闻》上的实验表明，我们的方法比最先进的方法有很大的优势。"
    },
    {
        "title": "Safe Collaborative Filtering",
        "url": "http://arxiv.org/abs/2306.05292v1",
        "pub_date": "2023-06-08",
        "summary": "Excellent tail performance is crucial for modern machine learning tasks, such\nas algorithmic fairness, class imbalance, and risk-sensitive decision making,\nas it ensures the effective handling of challenging samples within a dataset.\nTail performance is also a vital determinant of success for personalised\nrecommender systems to reduce the risk of losing users with low satisfaction.\nThis study introduces a \"safe\" collaborative filtering method that prioritises\nrecommendation quality for less-satisfied users rather than focusing on the\naverage performance. Our approach minimises the conditional value at risk\n(CVaR), which represents the average risk over the tails of users' loss. To\novercome computational challenges for web-scale recommender systems, we develop\na robust yet practical algorithm that extends the most scalable method,\nimplicit alternating least squares (iALS). Empirical evaluation on real-world\ndatasets demonstrates the excellent tail performance of our approach while\nmaintaining competitive computational efficiency.",
        "translated": "优秀的尾部性能对于现代机器学习任务至关重要，例如算法公平性、类不平衡性和风险敏感决策，因为它确保有效处理数据集中具有挑战性的样本。尾部性能也是个性化推荐系统成功的一个重要决定因素，可以降低用户满意度不高而流失的风险。这项研究引入了一种“安全”的协同过滤方法，优先考虑对不满意用户的推荐质量，而不是关注平均性能。我们的方法将条件风险值(CVaR)最小化，CVaR 代表用户损失尾部的平均风险。为了克服网络规模推荐系统的计算挑战，我们开发了一个强大而实用的算法，扩展了最可扩展的方法，隐式交替最小二乘(iALS)。对真实世界数据集的实证评估证明了该方法在保持竞争计算效率的同时具有优异的尾部性能。"
    },
    {
        "title": "RETA-LLM: A Retrieval-Augmented Large Language Model Toolkit",
        "url": "http://arxiv.org/abs/2306.05212v1",
        "pub_date": "2023-06-08",
        "summary": "Although Large Language Models (LLMs) have demonstrated extraordinary\ncapabilities in many domains, they still have a tendency to hallucinate and\ngenerate fictitious responses to user requests. This problem can be alleviated\nby augmenting LLMs with information retrieval (IR) systems (also known as\nretrieval-augmented LLMs). Applying this strategy, LLMs can generate more\nfactual texts in response to user input according to the relevant content\nretrieved by IR systems from external corpora as references. In addition, by\nincorporating external knowledge, retrieval-augmented LLMs can answer in-domain\nquestions that cannot be answered by solely relying on the world knowledge\nstored in parameters. To support research in this area and facilitate the\ndevelopment of retrieval-augmented LLM systems, we develop RETA-LLM, a\n{RET}reival-{A}ugmented LLM toolkit. In RETA-LLM, we create a complete pipeline\nto help researchers and users build their customized in-domain LLM-based\nsystems. Compared with previous retrieval-augmented LLM systems, RETA-LLM\nprovides more plug-and-play modules to support better interaction between IR\nsystems and LLMs, including {request rewriting, document retrieval, passage\nextraction, answer generation, and fact checking} modules. Our toolkit is\npublicly available at https://github.com/RUC-GSAI/YuLan-IR/tree/main/RETA-LLM.",
        "translated": "尽管大型语言模型(LLM)已经在许多领域展示了非凡的能力，但是它们仍然有产生幻觉和对用户请求产生虚构响应的倾向。这个问题可以通过使用信息检索(IR)系统(也称为检索增强 LLM)来增强 LLM 来缓解。应用这种策略，LLM 可以根据 IR 系统从外部语料库中检索到的相关内容作为参考，根据用户的输入生成更多的事实性文本。此外，通过合并外部知识，检索增强 LLM 可以回答领域内的问题，而这些问题不能仅仅依赖于存储在参数中的世界知识来回答。为了支持这一领域的研究和促进检索增强 LLM 系统的发展，我们开发了 RETA-LLM，一个{ RET } reval-{ A }增强 LLM 工具包。在 RETA-LLM 中，我们创建了一个完整的管道来帮助研究人员和用户构建他们定制的基于领域 LLM 的系统。与以前的检索增强 LLM 系统相比，RETA-LLM 提供了更多的即插即用模块，以支持 IR 系统和 LLM 之间更好的交互，包括{请求重写、文献检索、段落提取、答案生成和事实检查}模块。我们的工具包可以在 https://github.com/ruc-gsai/yulan-ir/tree/main/reta-llm 上公开获得。"
    },
    {
        "title": "Controllable Multi-Objective Re-ranking with Policy Hypernetworks",
        "url": "http://arxiv.org/abs/2306.05118v1",
        "pub_date": "2023-06-08",
        "summary": "Multi-stage ranking pipelines have become widely used strategies in modern\nrecommender systems, where the final stage aims to return a ranked list of\nitems that balances a number of requirements such as user preference,\ndiversity, novelty etc. Linear scalarization is arguably the most widely used\ntechnique to merge multiple requirements into one optimization objective, by\nsumming up the requirements with certain preference weights. Existing\nfinal-stage ranking methods often adopt a static model where the preference\nweights are determined during offline training and kept unchanged during online\nserving. Whenever a modification of the preference weights is needed, the model\nhas to be re-trained, which is time and resources inefficient. Meanwhile, the\nmost appropriate weights may vary greatly for different groups of targeting\nusers or at different time periods (e.g., during holiday promotions). In this\npaper, we propose a framework called controllable multi-objective re-ranking\n(CMR) which incorporates a hypernetwork to generate parameters for a re-ranking\nmodel according to different preference weights. In this way, CMR is enabled to\nadapt the preference weights according to the environment changes in an online\nmanner, without retraining the models. Moreover, we classify practical\nbusiness-oriented tasks into four main categories and seamlessly incorporate\nthem in a new proposed re-ranking model based on an Actor-Evaluator framework,\nwhich serves as a reliable real-world testbed for CMR. Offline experiments\nbased on the dataset collected from Taobao App showed that CMR improved several\npopular re-ranking models by using them as underlying models. Online A/B tests\nalso demonstrated the effectiveness and trustworthiness of CMR.",
        "translated": "多阶段排名管道已经成为现代推荐系统中广泛使用的策略，最后阶段的目标是返回一个项目的排名列表，以平衡一些需求，如用户偏好，多样性，新颖性等。线性标量可以说是最广泛使用的技术合并多个需求到一个优化目标，通过总结需求与一定的偏好权重。现有的最后阶段排序方法通常采用静态模型，在离线训练期间确定偏好权重，在线服务期间保持不变。当需要修改偏好权重时，模型必须重新训练，这是时间和资源效率低下的。与此同时，最合适的权重可能会因不同的目标用户群体或在不同的时间段(例如，在假日促销期间)而有很大差异。本文提出了一种可控的多目标重排序(CMR)框架，该框架结合了一个超网络，根据不同的偏好权重为重排序模型生成参数。通过这种方式，CMR 能够根据环境变化在线调整偏好权重，而不需要重新训练模型。此外，我们将面向业务的实际任务分为四个主要类别，并将它们无缝地纳入一个新提出的重新排序模型，该模型基于一个演员-评估者框架，作为一个可靠的现实世界的 CMR 测试平台。基于从淘宝应用收集的数据集的离线实验表明，CMR 通过使用它们作为基础模型改进了几个流行的重新排名模型。在线 A/B 测试也证明了 CMR 的有效性和可信性。"
    },
    {
        "title": "Attention Weighted Mixture of Experts with Contrastive Learning for\n  Personalized Ranking in E-commerce",
        "url": "http://arxiv.org/abs/2306.05011v1",
        "pub_date": "2023-06-08",
        "summary": "Ranking model plays an essential role in e-commerce search and\nrecommendation. An effective ranking model should give a personalized ranking\nlist for each user according to the user preference. Existing algorithms\nusually extract a user representation vector from the user behavior sequence,\nthen feed the vector into a feed-forward network (FFN) together with other\nfeatures for feature interactions, and finally produce a personalized ranking\nscore. Despite tremendous progress in the past, there is still room for\nimprovement. Firstly, the personalized patterns of feature interactions for\ndifferent users are not explicitly modeled. Secondly, most of existing\nalgorithms have poor personalized ranking results for long-tail users with few\nhistorical behaviors due to the data sparsity. To overcome the two challenges,\nwe propose Attention Weighted Mixture of Experts (AW-MoE) with contrastive\nlearning for personalized ranking. Firstly, AW-MoE leverages the MoE framework\nto capture personalized feature interactions for different users. To model the\nuser preference, the user behavior sequence is simultaneously fed into expert\nnetworks and the gate network. Within the gate network, one gate unit and one\nactivation unit are designed to adaptively learn the fine-grained activation\nvector for experts using an attention mechanism. Secondly, a random masking\nstrategy is applied to the user behavior sequence to simulate long-tail users,\nand an auxiliary contrastive loss is imposed to the output of the gate network\nto improve the model generalization for these users. This is validated by a\nhigher performance gain on the long-tail user test set. Experiment results on a\nJD real production dataset and a public dataset demonstrate the effectiveness\nof AW-MoE, which significantly outperforms state-of-art methods. Notably,\nAW-MoE has been successfully deployed in the JD e-commerce search engine, ...",
        "translated": "排名模型在电子商务搜索和推荐中起着至关重要的作用。一个有效的排名模型应该根据用户的偏好为每个用户提供一个个性化的排名列表。现有的算法通常从用户行为序列中提取用户表示向量，然后将该向量与其他特征一起反馈到前馈网络(FFN)中进行特征交互，最终产生个性化的排序得分。尽管过去取得了巨大的进步，但仍有改进的空间。首先，不同用户特征交互的个性化模式没有明确建模。其次，由于数据稀疏，现有算法对于长尾用户的个性化排序效果较差，历史行为较少。为了克服这两个挑战，我们提出了基于对比学习的专家注意加权混合排序方法(AW-MoE)。首先，AW-MoE 利用 MoE 框架为不同的用户捕获个性化的特征交互。为了建立用户偏好模型，将用户行为序列同时输入到专家网络和门网络中。在门网络中，设计了一个门单元和一个激活单元，利用注意机制为专家自适应地学习细粒度激活向量。其次，对用户行为序列采用随机掩蔽策略来模拟长尾用户，并对门网络的输出增加辅助对比度损失，以提高对长尾用户的模型泛化能力。这通过在长尾用户测试集上获得更高的性能增益来验证。在 JD 实际生产数据集和公开数据集上的实验结果证明了 AW-MoE 方法的有效性，其性能明显优于最先进的方法。值得注意的是，AW-MoE 已经成功地部署在 JD 电子商务搜索引擎，..。"
    },
    {
        "title": "Unified Embedding Based Personalized Retrieval in Etsy Search",
        "url": "http://arxiv.org/abs/2306.04833v1",
        "pub_date": "2023-06-07",
        "summary": "Embedding-based neural retrieval is a prevalent approach to address the\nsemantic gap problem which often arises in product search on tail queries. In\ncontrast, popular queries typically lack context and have a broad intent where\nadditional context from users historical interaction can be helpful. In this\npaper, we share our novel approach to address both: the semantic gap problem\nfollowed by an end to end trained model for personalized semantic retrieval. We\npropose learning a unified embedding model incorporating graph, transformer and\nterm-based embeddings end to end and share our design choices for optimal\ntradeoff between performance and efficiency. We share our learnings in feature\nengineering, hard negative sampling strategy, and application of transformer\nmodel, including a novel pre-training strategy and other tricks for improving\nsearch relevance and deploying such a model at industry scale. Our personalized\nretrieval model significantly improves the overall search experience, as\nmeasured by a 5.58% increase in search purchase rate and a 2.63% increase in\nsite-wide conversion rate, aggregated across multiple A/B tests - on live\ntraffic.",
        "translated": "基于嵌入式的神经检索是解决尾部查询产品搜索中经常出现的语义缺口问题的一种常用方法。相比之下，流行的查询通常缺乏上下文，并且具有广泛的意图，其中来自用户历史交互的额外上下文可能有所帮助。在本文中，我们分享了我们的新方法来解决这两个问题: 语义差距问题，然后是个性化语义检索的端到端训练模型。我们提出了一种结合图形、变换器和基于术语的嵌入端到端学习的统一嵌入模型，并共享我们的设计选择，以实现性能和效率之间的最优平衡。我们分享了我们在特征工程、硬负采样策略和变压器模型应用方面的经验，包括一种新的预训练策略和其他提高搜索相关性和在行业规模部署此类模型的技巧。我们的个性化检索模型显著改善了整体搜索体验，通过对实时流量进行多个 A/B 测试，搜索购买率增加了5.58% ，网站转换率增加了2.63% 。"
    },
    {
        "title": "MIMIC-IT: Multi-Modal In-Context Instruction Tuning",
        "url": "http://arxiv.org/abs/2306.05425v1",
        "pub_date": "2023-06-08",
        "summary": "High-quality instructions and responses are essential for the zero-shot\nperformance of large language models on interactive natural language tasks. For\ninteractive vision-language tasks involving intricate visual scenes, a large\nquantity of diverse and creative instruction-response pairs should be\nimperative to tune vision-language models (VLMs). Nevertheless, the current\navailability of vision-language instruction-response pairs in terms of\nquantity, diversity, and creativity remains limited, posing challenges to the\ngeneralization of interactive VLMs. Here we present MultI-Modal In-Context\nInstruction Tuning (MIMIC-IT), a dataset comprising 2.8 million multimodal\ninstruction-response pairs, with 2.2 million unique instructions derived from\nimages and videos. Each pair is accompanied by multi-modal in-context\ninformation, forming conversational contexts aimed at empowering VLMs in\nperception, reasoning, and planning. The instruction-response collection\nprocess, dubbed as Syphus, is scaled using an automatic annotation pipeline\nthat combines human expertise with GPT's capabilities. Using the MIMIC-IT\ndataset, we train a large VLM named Otter. Based on extensive evaluations\nconducted on vision-language benchmarks, it has been observed that Otter\ndemonstrates remarkable proficiency in multi-modal perception, reasoning, and\nin-context learning. Human evaluation reveals it effectively aligns with the\nuser's intentions. We release the MIMIC-IT dataset, instruction-response\ncollection pipeline, benchmarks, and the Otter model.",
        "translated": "高质量的指令和响应对于大型语言模型在交互式自然语言任务中的零点性能至关重要。对于涉及复杂视觉场景的交互式视觉语言任务，必须调优视觉语言模型(VLM)。然而，目前视觉-语言教学-反应对在数量、多样性和创造性方面的可用性仍然有限，对交互式 VLM 的普及提出了挑战。在这里，我们介绍了多模态上下文指令调优(MIMIC-IT) ，一个包含280万个多模态指令-响应对的数据集，其中有220万个来自图像和视频的独特指令。每一对都伴随着多模态的语境信息，形成旨在赋予 VLM 感知、推理和计划能力的会话语境。这个被称为 Syphus 的指令-响应收集过程使用一个自动注释管道进行扩展，该管道将人类的专业知识与 GPT 的功能结合在一起。使用 MIMIC-IT 数据集，我们训练了一个名为 Otter 的大型 VLM。基于对视觉语言基准的广泛评估，我们发现 Otter 在多模态知觉、推理和语境学习方面表现出显著的能力。人工评估显示它有效地与用户的意图保持一致。我们发布 MIMIC-IT 数据集、指令-响应收集管道、基准测试和 Otter 模型。"
    },
    {
        "title": "Mixture-of-Domain-Adapters: Decoupling and Injecting Domain Knowledge to\n  Pre-trained Language Models Memories",
        "url": "http://arxiv.org/abs/2306.05406v1",
        "pub_date": "2023-06-08",
        "summary": "Pre-trained language models (PLMs) demonstrate excellent abilities to\nunderstand texts in the generic domain while struggling in a specific domain.\nAlthough continued pre-training on a large domain-specific corpus is effective,\nit is costly to tune all the parameters on the domain. In this paper, we\ninvestigate whether we can adapt PLMs both effectively and efficiently by only\ntuning a few parameters. Specifically, we decouple the feed-forward networks\n(FFNs) of the Transformer architecture into two parts: the original pre-trained\nFFNs to maintain the old-domain knowledge and our novel domain-specific\nadapters to inject domain-specific knowledge in parallel. Then we adopt a\nmixture-of-adapters gate to fuse the knowledge from different domain adapters\ndynamically. Our proposed Mixture-of-Domain-Adapters (MixDA) employs a\ntwo-stage adapter-tuning strategy that leverages both unlabeled data and\nlabeled data to help the domain adaptation: i) domain-specific adapter on\nunlabeled data; followed by ii) the task-specific adapter on labeled data.\nMixDA can be seamlessly plugged into the pretraining-finetuning paradigm and\nour experiments demonstrate that MixDA achieves superior performance on\nin-domain tasks (GLUE), out-of-domain tasks (ChemProt, RCT, IMDB, Amazon), and\nknowledge-intensive tasks (KILT). Further analyses demonstrate the reliability,\nscalability, and efficiency of our method. The code is available at\nhttps://github.com/Amano-Aki/Mixture-of-Domain-Adapters.",
        "translated": "预训练语言模型(PLM)展示了在通用领域理解文本而在特定领域挣扎的卓越能力。尽管在特定于领域的大型语料库上进行持续的预训练是有效的，但是调优领域上的所有参数的成本是很高的。在本文中，我们研究是否可以适应 PLM 的有效性和有效性，只需调整几个参数。具体来说，我们将变压器结构的前馈网络(FFN)解耦为两部分: 原始的预先训练的 FFN 来维护旧的领域知识，以及我们新颖的领域特定适配器来并行注入领域特定的知识。然后采用混合适配器门来动态融合来自不同领域适配器的知识。我们提出的混合域适配器(MixDA)采用两阶段适配器调优策略，利用未标记数据和标记数据来帮助域适配: i)未标记数据上的域特定适配器; 随后 ii)标记数据上的任务特定适配器。MixDA 可以无缝地插入预训练-微调范式，我们的实验表明，MixDA 在域内任务(GLUE) ，域外任务(ChemProt，RCT，IMDB，Amazon)和知识密集型任务(KILT)上取得了优越的性能。进一步的分析证明了该方法的可靠性、可扩展性和有效性。密码可在 https://github.com/amano-aki/mixture-of-domain-adapters 查阅。"
    },
    {
        "title": "Modular Visual Question Answering via Code Generation",
        "url": "http://arxiv.org/abs/2306.05392v1",
        "pub_date": "2023-06-08",
        "summary": "We present a framework that formulates visual question answering as modular\ncode generation. In contrast to prior work on modular approaches to VQA, our\napproach requires no additional training and relies on pre-trained language\nmodels (LMs), visual models pre-trained on image-caption pairs, and fifty VQA\nexamples used for in-context learning. The generated Python programs invoke and\ncompose the outputs of the visual models using arithmetic and conditional\nlogic. Our approach improves accuracy on the COVR dataset by at least 3% and on\nthe GQA dataset by roughly 2% compared to the few-shot baseline that does not\nemploy code generation.",
        "translated": "我们提出了一个框架，制定可视化问题回答作为模块化代码生成。与之前关于 VQA 模块化方法的工作相比，我们的方法不需要额外的培训，并且依赖于预先训练的语言模型(LM) ，在图像-标题对上预先训练的可视化模型以及用于上下文学习的50个 VQA 示例。生成的 Python 程序使用算术和条件逻辑调用和组合可视化模型的输出。我们的方法在 COVR 数据集上提高了至少3% 的准确性，在 GQA 数据集上提高了大约2% 的准确性，相比之下，不使用代码生成的少镜头基线。"
    },
    {
        "title": "Utterance Emotion Dynamics in Children's Poems: Emotional Changes Across\n  Age",
        "url": "http://arxiv.org/abs/2306.05387v1",
        "pub_date": "2023-06-08",
        "summary": "Emerging psychopathology studies are showing that patterns of changes in\nemotional state -- emotion dynamics -- are associated with overall well-being\nand mental health. More recently, there has been some work in tracking emotion\ndynamics through one's utterances, allowing for data to be collected on a\nlarger scale across time and people. However, several questions about how\nemotion dynamics change with age, especially in children, and when determined\nthrough children's writing, remain unanswered. In this work, we use both a\nlexicon and a machine learning based approach to quantify characteristics of\nemotion dynamics determined from poems written by children of various ages. We\nshow that both approaches point to similar trends: consistent increasing\nintensities for some emotions (e.g., anger, fear, joy, sadness, arousal, and\ndominance) with age and a consistent decreasing valence with age. We also find\nincreasing emotional variability, rise rates (i.e., emotional reactivity), and\nrecovery rates (i.e., emotional regulation) with age. These results act as a\nuseful baselines for further research in how patterns of emotions expressed by\nchildren change with age, and their association with mental health.",
        "translated": "新兴的精神病理学研究表明，情绪状态的变化模式——情绪动力学——与整体幸福感和心理健康有关。最近，已经有一些工作通过一个人的话语跟踪情绪动态，允许跨越时间和人的更大规模的数据收集。然而，一些关于情绪动态如何随着年龄变化的问题，特别是在儿童中，以及当通过儿童的写作决定时，仍然没有答案。本研究采用词汇学习和机器学习相结合的方法，对不同年龄段儿童诗歌的情绪动力学特征进行量化研究。我们发现，这两种方法都指向相似的趋势: 随着年龄的增长，某些情绪(例如，愤怒、恐惧、喜悦、悲伤、觉醒和支配)的强度持续增加，而随着年龄的增长，情绪的效价持续下降。我们还发现，随着年龄的增长，情绪波动性、情绪反应性和恢复率都在增加。这些结果为进一步研究儿童表达的情绪模式如何随年龄变化及其与心理健康的关系提供了有用的基线。"
    },
    {
        "title": "The ADAIO System at the BEA-2023 Shared Task on Generating AI Teacher\n  Responses in Educational Dialogues",
        "url": "http://arxiv.org/abs/2306.05360v1",
        "pub_date": "2023-06-08",
        "summary": "This paper presents the ADAIO team's system entry in the Building Educational\nApplications (BEA) 2023 Shared Task on Generating AI Teacher Responses in\nEducational Dialogues. The task aims to assess the performance of\nstate-of-the-art generative models as AI teachers in producing suitable\nresponses within a student-teacher dialogue. Our system comprises evaluating\nvarious baseline models using OpenAI GPT-3 and designing diverse prompts to\nprompt the OpenAI models for teacher response generation. After the challenge,\nour system achieved second place by employing a few-shot prompt-based approach\nwith the OpenAI text-davinci-003 model. The results highlight the few-shot\nlearning capabilities of large-language models, particularly OpenAI's GPT-3, in\nthe role of AI teachers.",
        "translated": "本文介绍了 ADAIO 团队的系统条目在建筑教育应用(BEA)2023共同任务生成人工智能教师在教育对话中的反应。这项任务旨在评估最先进的生成模式作为人工智能教师在学生-教师对话中产生适当反应的表现。我们的系统包括使用 OpenAI GPT-3评估各种基线模型，并设计不同的提示以提示 OpenAI 模型用于教师反应生成。经过挑战，我们的系统取得了第二名，采用了几个镜头的提示为基础的方法与 OpenAI 文本达芬奇003模型。研究结果强调了大型语言模型(尤其是 OpenAI 的 GPT-3)在人工智能教师角色中的少量学习能力。"
    },
    {
        "title": "Advancing Italian Biomedical Information Extraction with Large Language\n  Models: Methodological Insights and Multicenter Practical Application",
        "url": "http://arxiv.org/abs/2306.05323v1",
        "pub_date": "2023-06-08",
        "summary": "The introduction of computerized medical records in hospitals has reduced\nburdensome operations like manual writing and information fetching. However,\nthe data contained in medical records are still far underutilized, primarily\nbecause extracting them from unstructured textual medical records takes time\nand effort. Information Extraction, a subfield of Natural Language Processing,\ncan help clinical practitioners overcome this limitation, using automated\ntext-mining pipelines. In this work, we created the first Italian\nneuropsychiatric Named Entity Recognition dataset, PsyNIT, and used it to\ndevelop a Large Language Model for this task. Moreover, we conducted several\nexperiments with three external independent datasets to implement an effective\nmulticenter model, with overall F1-score 84.77%, Precision 83.16%, Recall\n86.44%. The lessons learned are: (i) the crucial role of a consistent\nannotation process and (ii) a fine-tuning strategy that combines classical\nmethods with a \"few-shot\" approach. This allowed us to establish methodological\nguidelines that pave the way for future implementations in this field and allow\nItalian hospitals to tap into important research opportunities.",
        "translated": "医院采用计算机化病历减少了手工书写和信息提取等繁重的操作。然而，包含在医疗记录中的数据仍然没有得到充分利用，主要是因为从非结构化的文本医疗记录中提取数据需要时间和精力。信息抽取是自然语言处理的一个子领域，通过使用自动文本挖掘管道，可以帮助临床医生克服这一限制。在这项工作中，我们创建了第一个意大利神经精神病命名实体识别数据集，PsyNIT，并使用它来开发这项任务的大型语言模型。此外，我们利用三个独立的外部数据集进行了多个实验，实现了一个有效的多中心模型，F1总分为84.77% ，精度为83.16% ，召回率为86.44% 。从中学到的经验教训是: (i)一致的注释过程的关键作用; (ii)将经典方法与“少量拍摄”方法相结合的微调策略。这使我们能够制定方法指南，为今后在这一领域的实施铺平道路，并使意大利医院能够利用重要的研究机会。"
    },
    {
        "title": "KIT's Multilingual Speech Translation System for IWSLT 2023",
        "url": "http://arxiv.org/abs/2306.05320v1",
        "pub_date": "2023-06-08",
        "summary": "Many existing speech translation benchmarks focus on native-English speech in\nhigh-quality recording conditions, which often do not match the conditions in\nreal-life use-cases. In this paper, we describe our speech translation system\nfor the multilingual track of IWSLT 2023, which focuses on the translation of\nscientific conference talks. The test condition features accented input speech\nand terminology-dense contents. The tasks requires translation into 10\nlanguages of varying amounts of resources. In absence of training data from the\ntarget domain, we use a retrieval-based approach (kNN-MT) for effective\nadaptation (+0.8 BLEU for speech translation). We also use adapters to easily\nintegrate incremental training data from data augmentation, and show that it\nmatches the performance of re-training. We observe that cascaded systems are\nmore easily adaptable towards specific target domains, due to their separate\nmodules. Our cascaded speech system substantially outperforms its end-to-end\ncounterpart on scientific talk translation, although their performance remains\nsimilar on TED talks.",
        "translated": "许多现有的语音翻译基准主要集中在高质量录音条件下的英语母语语音上，而这些语音翻译基准往往与现实生活中的语音翻译条件不匹配。本文介绍了我们为 IWSLT 2023多语种赛道开发的演讲翻译系统，该系统主要用于科学会议演讲的翻译。测试条件的特点是重音输入语音和术语密集的内容。这些任务需要翻译成10种不同数量资源的语言。在没有来自目标域的训练数据的情况下，我们使用基于检索的方法(kNN-MT)进行有效的自适应(语音翻译 + 0.8 BLEU)。我们还使用适配器方便地集成了来自数据增强的增量训练数据，并表明它与再训练的性能相匹配。我们观察到级联系统由于其独立的模块，更容易适应特定的目标域。我们的级联语音系统在科学演讲翻译方面大大优于其端到端的对应系统，尽管它们在 TED 演讲中的表现仍然相似。"
    },
    {
        "title": "CUED at ProbSum 2023: Hierarchical Ensemble of Summarization Models",
        "url": "http://arxiv.org/abs/2306.05317v1",
        "pub_date": "2023-06-08",
        "summary": "In this paper, we consider the challenge of summarizing patients' medical\nprogress notes in a limited data setting. For the Problem List Summarization\n(shared task 1A) at the BioNLP Workshop 2023, we demonstrate that Clinical-T5\nfine-tuned to 765 medical clinic notes outperforms other extractive,\nabstractive and zero-shot baselines, yielding reasonable baseline systems for\nmedical note summarization. Further, we introduce Hierarchical Ensemble of\nSummarization Models (HESM), consisting of token-level ensembles of diverse\nfine-tuned Clinical-T5 models, followed by Minimum Bayes Risk (MBR) decoding.\nOur HESM approach lead to a considerable summarization performance boost, and\nwhen evaluated on held-out challenge data achieved a ROUGE-L of 32.77, which\nwas the best-performing system at the top of the shared task leaderboard.",
        "translated": "在本文中，我们考虑的挑战，总结病人的医疗进展记录在有限的数据设置。对于2023年 BioNLP 研讨会上的问题列表摘要(共享任务1A) ，我们证明临床 T5对765个医疗诊所笔记进行微调优于其他提取，抽象和零拍基线，产生合理的医疗笔记摘要基线系统。此外，我们还介绍了分层总结模型集成(HESM) ，其由不同的微调临床 T5模型的令牌级集成组成，然后是最小贝叶斯风险(MBR)解码。我们的 HESM 方法导致了相当大的总结性能提升，并且当在坚持的挑战数据上进行评估时，ROUGE-L 达到了32.77，这是共享任务排行榜上表现最好的系统。"
    },
    {
        "title": "Are fairness metric scores enough to assess discrimination biases in\n  machine learning?",
        "url": "http://arxiv.org/abs/2306.05307v1",
        "pub_date": "2023-06-08",
        "summary": "This paper presents novel experiments shedding light on the shortcomings of\ncurrent metrics for assessing biases of gender discrimination made by machine\nlearning algorithms on textual data. We focus on the Bios dataset, and our\nlearning task is to predict the occupation of individuals, based on their\nbiography. Such prediction tasks are common in commercial Natural Language\nProcessing (NLP) applications such as automatic job recommendations. We address\nan important limitation of theoretical discussions dealing with group-wise\nfairness metrics: they focus on large datasets, although the norm in many\nindustrial NLP applications is to use small to reasonably large linguistic\ndatasets for which the main practical constraint is to get a good prediction\naccuracy. We then question how reliable are different popular measures of bias\nwhen the size of the training set is simply sufficient to learn reasonably\naccurate predictions. Our experiments sample the Bios dataset and learn more\nthan 200 models on different sample sizes. This allows us to statistically\nstudy our results and to confirm that common gender bias indices provide\ndiverging and sometimes unreliable results when applied to relatively small\ntraining and test samples. This highlights the crucial importance of variance\ncalculations for providing sound results in this field.",
        "translated": "本文介绍了一些新颖的实验，揭示了目前机器学习算法对文本数据进行性别歧视偏差评估的指标存在的缺陷。我们的重点是生物数据集，我们的学习任务是预测个人的职业，根据他们的传记。这种预测任务在商业自然语言处理(NLP)应用程序(如自动工作推荐)中很常见。我们解决了关于群体公平性度量的理论讨论的一个重要局限性: 它们集中在大数据集上，尽管在许多工业 NLP 应用中的规范是使用小到合理的大语言数据集，其主要的实际限制是获得良好的预测精度。然后我们质疑当训练集的大小仅仅足以学习合理准确的预测时，不同的流行的偏倚测量方法的可靠性。我们的实验样本的 Bios 数据集和学习超过200个不同样本大小的模型。这使我们能够统计研究我们的结果，并确认共同的性别偏见指数提供不同的，有时不可靠的结果时，适用于相对较小的训练和测试样本。这突出了方差计算对于在这一领域提供可靠结果的至关重要性。"
    },
    {
        "title": "ToolAlpaca: Generalized Tool Learning for Language Models with 3000\n  Simulated Cases",
        "url": "http://arxiv.org/abs/2306.05301v1",
        "pub_date": "2023-06-08",
        "summary": "Enabling large language models to effectively utilize real-world tools is\ncrucial for achieving embodied intelligence. Existing approaches to tool\nlearning have primarily relied on either extremely large language models, such\nas GPT-4, to attain generalized tool-use abilities in a zero-shot manner, or\nhave utilized supervised learning to train limited types of tools on compact\nmodels. However, it remains uncertain whether smaller language models can\nachieve generalized tool-use abilities without specific tool-specific training.\nTo address this question, this paper introduces ToolAlpaca, a novel framework\ndesigned to automatically generate a tool-use corpus and learn generalized\ntool-use abilities on compact language models with minimal human intervention.\nSpecifically, ToolAlpaca first collects a comprehensive dataset by building a\nmulti-agent simulation environment, which contains 3938 tool-use instances from\nmore than 400 real-world tool APIs spanning 50 distinct categories.\nSubsequently, the constructed corpus is employed to fine-tune compact language\nmodels, resulting in two models, namely ToolAlpaca-7B and ToolAlpaca-13B,\nrespectively. Finally, we evaluate the ability of these models to utilize\npreviously unseen tools without specific training. Experimental results\ndemonstrate that ToolAlpaca achieves effective generalized tool-use\ncapabilities comparable to those of extremely large language models like\nGPT-3.5. This validation supports the notion that learning generalized tool-use\nabilities is feasible for compact language models.",
        "translated": "使大型语言模型能够有效地利用现实世界中的工具对于实现内嵌智能是至关重要的。现有的工具学习方法主要依赖于极其庞大的语言模型，如 GPT-4，以零打击的方式获得广义的工具使用能力，或者利用监督式学习在紧凑模型上训练有限类型的工具。然而，小型语言模型是否能够在没有特定工具训练的情况下实现工具使用能力的普遍化仍然是个未知数。为了解决这个问题，本文介绍了 ToolAlpaca，这是一个新的框架，它可以自动生成一个工具使用语料库，并在最少人工干预的情况下学习紧凑语言模型上的广义工具使用能力。具体来说，ToolAlpaca 首先通过构建一个多代理仿真环境来收集一个全面的数据集，该环境包含来自400多个实际工具 API 的3938个工具使用实例，这些 API 跨越50个不同的类别。然后，利用构建的语料库对紧凑语言模型进行微调，得到两个模型，分别为 ToolAlpaca-7B 和 ToolAlpaca-13B。最后，我们评估这些模型在没有特定训练的情况下利用以前看不见的工具的能力。实验结果表明，ToolAlpaca 实现了有效的广义工具使用能力，可以与 GPT-3.5这样的超大型语言模型相媲美。这种验证支持这样一种观点，即学习广义的工具使用能力对于紧凑的语言模型是可行的。"
    },
    {
        "title": "How Can Recommender Systems Benefit from Large Language Models: A Survey",
        "url": "http://arxiv.org/abs/2306.05817v1",
        "pub_date": "2023-06-09",
        "summary": "Recommender systems (RS) play important roles to match users' information\nneeds for Internet applications. In natural language processing (NLP) domains,\nlarge language model (LLM) has shown astonishing emergent abilities (e.g.,\ninstruction following, reasoning), thus giving rise to the promising research\ndirection of adapting LLM to RS for performance enhancements and user\nexperience improvements. In this paper, we conduct a comprehensive survey on\nthis research direction from an application-oriented view. We first summarize\nexisting research works from two orthogonal perspectives: where and how to\nadapt LLM to RS. For the \"WHERE\" question, we discuss the roles that LLM could\nplay in different stages of the recommendation pipeline, i.e., feature\nengineering, feature encoder, scoring/ranking function, and pipeline\ncontroller. For the \"HOW\" question, we investigate the training and inference\nstrategies, resulting in two fine-grained taxonomy criteria, i.e., whether to\ntune LLMs or not, and whether to involve conventional recommendation model\n(CRM) for inference. Detailed analysis and general development trajectories are\nprovided for both questions, respectively. Then, we highlight key challenges in\nadapting LLM to RS from three aspects, i.e., efficiency, effectiveness, and\nethics. Finally, we summarize the survey and discuss the future prospects. We\nalso actively maintain a GitHub repository for papers and other related\nresources in this rising direction:\n$\\href{https://github.com/CHIANGEL/Awesome-LLM-for-RecSys}{[GitHub\\;Link]}$.",
        "translated": "推荐系统(RS)在满足互联网应用的用户信息需求方面发挥着重要作用。在自然语言处理(NLP)领域，大语言模型(LLM)表现出惊人的涌现能力(如指令跟随、推理) ，从而引发了将 LLM 应用于 RS 以提高性能和改善用户体验的研究方向。本文从应用导向的角度对这一研究方向进行了全面综述。本文首先从两个正交的角度对现有的研究工作进行了总结: 在何处以及如何使 LLM 适应 RS。对于“ WHERE”问题，我们讨论 LLM 在推荐流水线的不同阶段可以扮演的角色，即特征工程、特征编码器、评分/排名函数和流水线控制器。对于“如何”问题，我们研究了训练和推理策略，产生了两个细粒度的分类标准，即是否调优 LLM，以及是否涉及传统的推荐模型(CRM)进行推理。对这两个问题分别提供了详细的分析和一般的开发轨迹。然后，从效率、有效性和道德三个方面，重点阐述了长期管理适应 RS 所面临的主要挑战。最后，对调查结果进行了总结，并对未来进行了展望。我们还积极地维护一个 gitHub 存储库，用于存放论文和其他相关资源，这是一个不断发展的方向: $href { https://GitHub.com/chiangel/awesome-llm-for-recsys }{[ gitHub; Link ]}} $。"
    },
    {
        "title": "Interactive Explanation with Varying Level of Details in an Explainable\n  Scientific Literature Recommender System",
        "url": "http://arxiv.org/abs/2306.05809v1",
        "pub_date": "2023-06-09",
        "summary": "Explainable recommender systems (RS) have traditionally followed a\none-size-fits-all approach, delivering the same explanation level of detail to\neach user, without considering their individual needs and goals. Further,\nexplanations in RS have so far been presented mostly in a static and\nnon-interactive manner. To fill these research gaps, we aim in this paper to\nadopt a user-centered, interactive explanation model that provides explanations\nwith different levels of detail and empowers users to interact with, control,\nand personalize the explanations based on their needs and preferences. We\nfollowed a user-centered approach to design interactive explanations with three\nlevels of detail (basic, intermediate, and advanced) and implemented them in\nthe transparent Recommendation and Interest Modeling Application (RIMA). We\nconducted a qualitative user study (N=14) to investigate the impact of\nproviding interactive explanations with varying level of details on the users'\nperception of the explainable RS. Our study showed qualitative evidence that\nfostering interaction and giving users control in deciding which explanation\nthey would like to see can meet the demands of users with different needs,\npreferences, and goals, and consequently can have positive effects on different\ncrucial aspects in explainable recommendation, including transparency, trust,\nsatisfaction, and user experience.",
        "translated": "可解释的推荐系统(RS)传统上遵循一种一刀切的方法，向每个用户提供相同的详细解释水平，而不考虑他们的个人需求和目标。此外，到目前为止，RS 中的解释大多是以静态和非交互的方式提出的。为了填补这些研究空白，本文的目标是采用一种以用户为中心的交互式解释模型，该模型提供不同层次的详细解释，并使用户能够根据自己的需求和偏好进行交互、控制和个性化解释。我们遵循以用户为中心的方法来设计具有三个细节层次(基础、中级和高级)的交互式解释，并在透明的推荐和兴趣建模应用程序(RIMA)中实现它们。我们进行了一项定性的用户研究(N = 14) ，以调查不同程度的细节提供交互式解释对用户感知可解释 RS 的影响。我们的研究显示，定性的证据表明，培养互动和让用户控制决定他们想要看到的解释可以满足不同需求，偏好和目标的用户的需求，因此可以对解释性推荐的不同关键方面产生积极的影响，包括透明度，信任，满意度和用户体验。"
    },
    {
        "title": "RankFormer: Listwise Learning-to-Rank Using Listwide Labels",
        "url": "http://arxiv.org/abs/2306.05808v1",
        "pub_date": "2023-06-09",
        "summary": "Web applications where users are presented with a limited selection of items\nhave long employed ranking models to put the most relevant results first. Any\nfeedback received from users is typically assumed to reflect a relative\njudgement on the utility of items, e.g. a user clicking on an item only implies\nit is better than items not clicked in the same ranked list. Hence, the\nobjectives optimized in Learning-to-Rank (LTR) tend to be pairwise or listwise.\n  Yet, by only viewing feedback as relative, we neglect the user's absolute\nfeedback on the list's overall quality, e.g. when no items in the selection are\nclicked. We thus reconsider the standard LTR paradigm and argue the benefits of\nlearning from this listwide signal. To this end, we propose the RankFormer as\nan architecture that, with a Transformer at its core, can jointly optimize a\nnovel listwide assessment objective and a traditional listwise LTR objective.\n  We simulate implicit feedback on public datasets and observe that the\nRankFormer succeeds in benefitting from listwide signals. Additionally, we\nconduct experiments in e-commerce on Amazon Search data and find the RankFormer\nto be superior to all baselines offline. An online experiment shows that\nknowledge distillation can be used to find immediate practical use for the\nRankFormer.",
        "translated": "在 Web 应用程序中，用户只能看到有限的条目，这种情况长期以来一直采用排名模型，将最相关的结果放在第一位。从用户收到的任何反馈通常被认为反映了对项目效用的相对判断，例如，用户点击一个项目只意味着它比没有在同一排名列表中点击的项目要好。因此，学习排名(Learning-to-Rank，LTR)中优化的目标往往是成对的或列表的。然而，由于只把反馈看作是相对的，我们忽略了用户对列表整体质量的绝对反馈，例如，当选择中没有项被点击的时候。因此，我们重新考虑标准的 LTR 范式，并讨论从这个列表范围的信号中学习的好处。为此，我们提出 RankForm 作为一种体系结构，其核心是一个 Transformer，可以联合优化一个新的列表范围评估目标和一个传统的列表式 LTR 目标。我们模拟公共数据集上的隐式反馈，并观察到 RankForm 成功地从列表宽信号中受益。此外，我们在亚马逊搜索数据上进行电子商务实验，发现排名前优于所有离线基线。一个在线实验表明，知识提取可以用来找到直接的实际应用的秩次前。"
    },
    {
        "title": "Customizing General-Purpose Foundation Models for Medical Report\n  Generation",
        "url": "http://arxiv.org/abs/2306.05642v1",
        "pub_date": "2023-06-09",
        "summary": "Medical caption prediction which can be regarded as a task of medical report\ngeneration (MRG), requires the automatic generation of coherent and accurate\ncaptions for the given medical images. However, the scarcity of labelled\nmedical image-report pairs presents great challenges in the development of deep\nand large-scale neural networks capable of harnessing the potential artificial\ngeneral intelligence power like large language models (LLMs). In this work, we\npropose customizing off-the-shelf general-purpose large-scale pre-trained\nmodels, i.e., foundation models (FMs), in computer vision and natural language\nprocessing with a specific focus on medical report generation. Specifically,\nfollowing BLIP-2, a state-of-the-art vision-language pre-training approach, we\nintroduce our encoder-decoder-based MRG model. This model utilizes a\nlightweight query Transformer to connect two FMs: the giant vision Transformer\nEVA-ViT-g and a bilingual LLM trained to align with human intentions (referred\nto as ChatGLM-6B). Furthermore, we conduct ablative experiments on the\ntrainable components of the model to identify the crucial factors for effective\ntransfer learning. Our findings demonstrate that unfreezing EVA-ViT-g to learn\nmedical image representations, followed by parameter-efficient training of\nChatGLM-6B to capture the writing styles of medical reports, is essential for\nachieving optimal results. Our best attempt (PCLmed Team) achieved the 4th and\nthe 2nd, respectively, out of 13 participating teams, based on the BERTScore\nand ROUGE-1 metrics, in the ImageCLEFmedical Caption 2023 Caption Prediction\nTask competition.",
        "translated": "医学字幕预测是医学报告生成的一项重要任务，它要求为给定的医学图像自动生成连贯、准确的医学字幕。然而，标记的医学图像-报告对的稀缺性给深度和大规模神经网络的发展提出了巨大的挑战，这些神经网络能够利用潜在的人工通用智能能力，如大语言模型(LLM)。在这项工作中，我们建议定制现成的通用大规模预训练模型，即基础模型(FM) ，在计算机视觉和自然语言处理，特别是医疗报告生成的重点。具体来说，在 BLIP-2(一种最先进的视觉语言预训练方法)之后，我们介绍了基于编码器-解码器的 MRG 模型。该模型使用一个轻量级查询 Transformer 连接两个 FM: 巨大的愿景跑车 EVA-ViT-g 和一个双语 LLM，后者经过训练以符合人类意图(称为 ChatGLM-6B)。此外，我们还对模型的可训练部分进行了烧蚀实验，以确定有效迁移学习的关键因素。我们的研究结果表明，将 EVA-ViT-g 解冻以学习医学图像表示，然后对 ChatGLM-6B 进行参数有效的训练以捕获医学报告的写作风格，对于实现最佳结果至关重要。根据 BERTScore 和 ROUGE-1指标，在 ImageCLEFMedical Caption 2023字幕预测任务竞赛中，我们的最佳尝试(PCLmed Team)分别在13个参赛团队中获得第4名和第2名。"
    },
    {
        "title": "Bayesian Knowledge-driven Critiquing with Indirect Evidence",
        "url": "http://arxiv.org/abs/2306.05636v1",
        "pub_date": "2023-06-09",
        "summary": "Conversational recommender systems (CRS) enhance the expressivity and\npersonalization of recommendations through multiple turns of user-system\ninteraction. Critiquing is a well-known paradigm for CRS that allows users to\niteratively refine recommendations by providing feedback about attributes of\nrecommended items. While existing critiquing methodologies utilize direct\nattributes of items to address user requests such as 'I prefer Western movies',\nthe opportunity of incorporating richer contextual and side information about\nitems stored in Knowledge Graphs (KG) into the critiquing paradigm has been\noverlooked. Employing this substantial knowledge together with a\nwell-established reasoning methodology paves the way for critique-based\nrecommenders to allow for complex knowledge-based feedback (e.g., 'I like\nmovies featuring war side effects on veterans') which may arise in natural\nuser-system conversations. In this work, we aim to increase the flexibility of\ncritique-based recommendation by integrating KGs and propose a novel Bayesian\ninference framework that enables reasoning with relational knowledge-based\nfeedback. We study and formulate the framework considering a Gaussian\nlikelihood and evaluate it on two well-known recommendation datasets with KGs.\nOur evaluations demonstrate the effectiveness of our framework in leveraging\nindirect KG-based feedback (i.e., preferred relational properties of items\nrather than preferred items themselves), often improving personalized\nrecommendations over a one-shot recommender by more than 15%. This work enables\na new paradigm for using rich knowledge content and reasoning over indirect\nevidence as a mechanism for critiquing interactions with CRS.",
        "translated": "会话推荐系统(CRS)通过多轮用户系统交互增强推荐的表达能力和个性化。批评是 CRS 的一个众所周知的范例，它允许用户通过提供关于推荐项目属性的反馈来迭代地完善推荐。虽然现有的批评方法利用项目的直接属性来满足用户的要求，例如“我更喜欢西部电影”，但是将知识图表(KG)中存储的项目的更丰富的上下文和侧面信息纳入批评范式的机会被忽视了。使用这些实质性的知识和一个完善的推理方法为基于评论的推荐者铺平了道路，以允许复杂的基于知识的反馈(例如，“我喜欢有退伍军人战争副作用的电影”) ，这可能出现在自然的用户系统对话中。在这项工作中，我们的目标是通过整合幼稚园来增加基于批判的推荐的灵活性，并提出一个新的贝叶斯推断框架，使推理与关系知识为基础的反馈。我们研究并制定了考虑高斯似然的框架，并在两个著名的 KG 推荐数据集上进行了评估。我们的评估表明，我们的框架在利用间接的基于 KG 的反馈(即，项目的首选关系属性，而不是首选项本身)方面的有效性，通常比一次性推荐提高个性化推荐超过15% 。这项工作为使用丰富的知识内容和推理间接证据作为一种机制批判与 CRS 的相互作用提供了一个新的范例。"
    },
    {
        "title": "Leveraging Large Language Models for Scalable Vector Graphics-Driven\n  Image Understanding",
        "url": "http://arxiv.org/abs/2306.06094v1",
        "pub_date": "2023-06-09",
        "summary": "Recently, large language models (LLMs) have made significant advancements in\nnatural language understanding and generation. However, their potential in\ncomputer vision remains largely unexplored. In this paper, we introduce a new,\nexploratory approach that enables LLMs to process images using the Scalable\nVector Graphics (SVG) format. By leveraging the XML-based textual descriptions\nof SVG representations instead of raster images, we aim to bridge the gap\nbetween the visual and textual modalities, allowing LLMs to directly understand\nand manipulate images without the need for parameterized visual components. Our\nmethod facilitates simple image classification, generation, and in-context\nlearning using only LLM capabilities. We demonstrate the promise of our\napproach across discriminative and generative tasks, highlighting its (i)\nrobustness against distribution shift, (ii) substantial improvements achieved\nby tapping into the in-context learning abilities of LLMs, and (iii) image\nunderstanding and generation capabilities with human guidance. Our code, data,\nand models can be found here https://github.com/mu-cai/svg-llm.",
        "translated": "近年来，大型语言模型(LLM)在自然语言理解和生成方面取得了显著的进展。然而，它们在计算机视觉方面的潜力在很大程度上仍未得到开发。在这篇文章中，我们介绍了一种新的探索性的方法，使 LLM 能够使用可缩放向量图形(SVG)格式来处理图像。通过利用基于 XML 的 SVG 表示的文本描述而不是栅格图像，我们的目标是弥合视觉和文本模式之间的差距，允许 LLM 直接理解和操作图像，而不需要参数化的视觉组件。我们的方法有助于简单的图像分类，生成，并在上下文学习使用 LLM 的能力。我们展示了我们在歧视性和生成性任务中的方法的前景，强调了其(i)对分布转移的稳健性，(ii)通过利用 LLM 的上下文学习能力实现的实质性改进，以及(iii)图像理解和生成能力与人类指导。我们的代码、数据和模型可以在这里找到 https://github.com/mu-cai/svg-llm。"
    },
    {
        "title": "Developing Speech Processing Pipelines for Police Accountability",
        "url": "http://arxiv.org/abs/2306.06086v1",
        "pub_date": "2023-06-09",
        "summary": "Police body-worn cameras have the potential to improve accountability and\ntransparency in policing. Yet in practice, they result in millions of hours of\nfootage that is never reviewed. We investigate the potential of large\npre-trained speech models for facilitating reviews, focusing on ASR and officer\nspeech detection in footage from traffic stops. Our proposed pipeline includes\ntraining data alignment and filtering, fine-tuning with resource constraints,\nand combining officer speech detection with ASR for a fully automated approach.\nWe find that (1) fine-tuning strongly improves ASR performance on officer\nspeech (WER=12-13%), (2) ASR on officer speech is much more accurate than on\ncommunity member speech (WER=43.55-49.07%), (3) domain-specific tasks like\nofficer speech detection and diarization remain challenging. Our work offers\npractical applications for reviewing body camera footage and general guidance\nfor adapting pre-trained speech models to noisy multi-speaker domains.",
        "translated": "警察身上佩戴的摄像头有可能改善警务工作的问责制和透明度。然而在实践中，他们导致数百万小时的镜头，从来没有审查。我们调查的潜力，大型预先训练的语音模型，以促进审查，侧重于 ASR 和官员的语音检测镜头从交通停止。我们提出的流水线包括训练数据对齐和过滤，与资源约束的微调，并结合官员语音检测和 ASR 为一个完全自动化的方法。我们发现: (1)微调有力地提高了官员语音的 ASR 性能(WER = 12-13%) ，(2)官员语音的 ASR 比社区成员语音的 ASR 更准确(WER = 43.55-49.07%) ，(3)官员语音检测和数字化等领域特定任务仍然具有挑战性。我们的工作提供了实际应用，审查身体摄像机镜头和一般指导适应预先训练的语音模型噪声多扬声器领域。"
    },
    {
        "title": "Trapping LLM Hallucinations Using Tagged Context Prompts",
        "url": "http://arxiv.org/abs/2306.06085v1",
        "pub_date": "2023-06-09",
        "summary": "Recent advances in large language models (LLMs), such as ChatGPT, have led to\nhighly sophisticated conversation agents. However, these models suffer from\n\"hallucinations,\" where the model generates false or fabricated information.\nAddressing this challenge is crucial, particularly with AI-driven platforms\nbeing adopted across various sectors. In this paper, we propose a novel method\nto recognize and flag instances when LLMs perform outside their domain\nknowledge, and ensuring users receive accurate information.\n  We find that the use of context combined with embedded tags can successfully\ncombat hallucinations within generative language models. To do this, we\nbaseline hallucination frequency in no-context prompt-response pairs using\ngenerated URLs as easily-tested indicators of fabricated data. We observed a\nsignificant reduction in overall hallucination when context was supplied along\nwith question prompts for tested generative engines. Lastly, we evaluated how\nplacing tags within contexts impacted model responses and were able to\neliminate hallucinations in responses with 98.88% effectiveness.",
        "translated": "大型语言模型(LLM)的最新进展，如 ChatGPT，已经导致了高度复杂的会话代理。然而，这些模型遭受“幻觉”，即模型产生虚假或捏造的信息。应对这一挑战至关重要，特别是在各个部门都在采用人工智能驱动的平台的情况下。在本文中，我们提出了一种新的方法来识别和标记实例时，LLM 执行领域外的知识，并确保用户接收准确的信息。我们发现使用上下文结合嵌入式标签可以成功地战胜生成语言模型中的幻觉。为此，我们使用生成的 URL 作为编造数据的容易测试的指标，对无上下文提示-响应对中的幻觉频率进行基线测试。我们观察到整体幻觉的显着减少时，上下文提供的问题提示测试生成引擎。最后，我们评估了在上下文中放置标签是如何影响模型反应的，并且能够以98.88% 的有效率消除反应中的幻觉。"
    },
    {
        "title": "Mind2Web: Towards a Generalist Agent for the Web",
        "url": "http://arxiv.org/abs/2306.06070v1",
        "pub_date": "2023-06-09",
        "summary": "We introduce Mind2Web, the first dataset for developing and evaluating\ngeneralist agents for the web that can follow language instructions to complete\ncomplex tasks on any website. Existing datasets for web agents either use\nsimulated websites or only cover a limited set of websites and tasks, thus not\nsuitable for generalist web agents. With over 2,000 open-ended tasks collected\nfrom 137 websites spanning 31 domains and crowdsourced action sequences for the\ntasks, Mind2Web provides three necessary ingredients for building generalist\nweb agents: 1) diverse domains, websites, and tasks, 2) use of real-world\nwebsites instead of simulated and simplified ones, and 3) a broad spectrum of\nuser interaction patterns. Based on Mind2Web, we conduct an initial exploration\nof using large language models (LLMs) for building generalist web agents. While\nthe raw HTML of real-world websites are often too large to be fed to LLMs, we\nshow that first filtering it with a small LM significantly improves the\neffectiveness and efficiency of LLMs. Our solution demonstrates a decent level\nof performance, even on websites or entire domains the model has never seen\nbefore, but there is still a substantial room to improve towards truly\ngeneralizable agents. We open-source our dataset, model implementation, and\ntrained models (https://osu-nlp-group.github.io/Mind2Web) to facilitate further\nresearch on building a generalist agent for the web.",
        "translated": "我们介绍 Mind2Web，第一个用于开发和评估通用网络代理的数据集，这些代理可以按照语言指令在任何网站上完成复杂的任务。现有的 Web 代理数据集要么使用模拟网站，要么只覆盖有限的一组网站和任务，因此不适合于通用 Web 代理。Mind2Web 从31个领域的137个网站中收集了超过2000个开放式任务，并为这些任务提供了众包的动作序列。 Mind2Web 为构建通用网络代理提供了三个必要的组成部分: 1)不同的领域、网站和任务; 2)使用真实世界的网站而不是模拟和简化的网站; 3)广泛的用户交互模式。基于 Mind2Web，我们对使用大型语言模型(LLM)构建通用 Web 代理进行了初步探索。虽然现实世界中网站的原始 HTML 通常太大而无法提供给 LLM，但我们表明，首先使用小型 LM 对其进行过滤可以显著提高 LLM 的有效性和效率。我们的解决方案展示了一个不错的性能水平，甚至在模型从未见过的网站或整个域上，但是仍然有很大的空间来改进真正可推广的代理。我们开源我们的数据集，模型实现，和训练有素的模型( https://osu-nlp-group.github.io/mind2web ) ，以促进进一步的研究建立一个通用的代理网站。"
    },
    {
        "title": "Assisting Language Learners: Automated Trans-Lingual Definition\n  Generation via Contrastive Prompt Learning",
        "url": "http://arxiv.org/abs/2306.06058v1",
        "pub_date": "2023-06-09",
        "summary": "The standard definition generation task requires to automatically produce\nmono-lingual definitions (e.g., English definitions for English words), but\nignores that the generated definitions may also consist of unfamiliar words for\nlanguage learners. In this work, we propose a novel task of Trans-Lingual\nDefinition Generation (TLDG), which aims to generate definitions in another\nlanguage, i.e., the native speaker's language. Initially, we explore the\nunsupervised manner of this task and build up a simple implementation of\nfine-tuning the multi-lingual machine translation model. Then, we develop two\nnovel methods, Prompt Combination and Contrastive Prompt Learning, for further\nenhancing the quality of the generation. Our methods are evaluated against the\nbaseline Pipeline method in both rich- and low-resource settings, and we\nempirically establish its superiority in generating higher-quality\ntrans-lingual definitions.",
        "translated": "标准的定义生成任务要求自动生成单语言定义(例如，英语单词的英语定义) ，但是忽略了生成的定义也可能包含语言学习者不熟悉的单词。在这项工作中，我们提出了一个新颖的任务跨语言定义生成(TLDG) ，其目的是生成另一种语言的定义，即母语说话人的语言。最初，我们探讨了这项任务的无监督方式，并建立了一个简单的实现，微调多语种机器翻译模型。然后，为了进一步提高生成的质量，我们开发了两种新的方法，即即时组合和对比即时学习。在资源丰富和资源少的情况下，我们对比基线流水线方法对我们的方法进行了评估，并且我们经验性地建立了它在产生更高质量的跨语言定义方面的优势。"
    },
    {
        "title": "FinGPT: Open-Source Financial Large Language Models",
        "url": "http://arxiv.org/abs/2306.06031v1",
        "pub_date": "2023-06-09",
        "summary": "Large language models (LLMs) have shown the potential of revolutionizing\nnatural language processing tasks in diverse domains, sparking great interest\nin finance. Accessing high-quality financial data is the first challenge for\nfinancial LLMs (FinLLMs). While proprietary models like BloombergGPT have taken\nadvantage of their unique data accumulation, such privileged access calls for\nan open-source alternative to democratize Internet-scale financial data.\n  In this paper, we present an open-source large language model, FinGPT, for\nthe finance sector. Unlike proprietary models, FinGPT takes a data-centric\napproach, providing researchers and practitioners with accessible and\ntransparent resources to develop their FinLLMs. We highlight the importance of\nan automatic data curation pipeline and the lightweight low-rank adaptation\ntechnique in building FinGPT. Furthermore, we showcase several potential\napplications as stepping stones for users, such as robo-advising, algorithmic\ntrading, and low-code development. Through collaborative efforts within the\nopen-source AI4Finance community, FinGPT aims to stimulate innovation,\ndemocratize FinLLMs, and unlock new opportunities in open finance. Two\nassociated code repos are \\url{https://github.com/AI4Finance-Foundation/FinGPT}\nand \\url{https://github.com/AI4Finance-Foundation/FinNLP}",
        "translated": "大型语言模型(LLM)显示了在不同领域革新自然语言处理任务的潜力，引起了人们对金融的极大兴趣。访问高质量的金融数据是金融 LLM (FinLLM)面临的第一个挑战。虽然像 BloombergGPT 这样的专有模型已经利用了它们独特的数据积累，但是这种特权访问需要一种开放源码的替代方案来使互联网规模的金融数据民主化。在本文中，我们为金融部门提出了一个开源的大型语言模型 FinGPT。与专有模型不同，FinGPT 采用以数据为中心的方法，为研究人员和从业人员提供可访问和透明的资源，以开发他们的 FinLLM。我们强调了自动数据管道和轻量级低级自适应技术在构建 FinGPT 中的重要性。此外，我们展示了几个潜在的应用程序作为用户的垫脚石，如机器人建议，算法交易和低代码开发。通过开源 AI4Finance 社区内部的协作努力，FinGPT 旨在激励创新，使 FinLLM 民主化，并在开放金融领域释放新的机遇。两个相关的代码回购是 url { https://github.com/ai4finance-foundation/fingpt }和 url { https://github.com/ai4finance-foundation/finnlp }"
    },
    {
        "title": "HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence\n  for Digital Medicine",
        "url": "http://arxiv.org/abs/2306.06029v1",
        "pub_date": "2023-06-09",
        "summary": "Providing high quality explanations for AI predictions based on machine\nlearning is a challenging and complex task. To work well it requires, among\nother factors: selecting a proper level of generality/specificity of the\nexplanation; considering assumptions about the familiarity of the explanation\nbeneficiary with the AI task under consideration; referring to specific\nelements that have contributed to the decision; making use of additional\nknowledge (e.g. expert evidence) which might not be part of the prediction\nprocess; and providing evidence supporting negative hypothesis. Finally, the\nsystem needs to formulate the explanation in a clearly interpretable, and\npossibly convincing, way. Given these considerations, ANTIDOTE fosters an\nintegrated vision of explainable AI, where low-level characteristics of the\ndeep learning process are combined with higher level schemes proper of the\nhuman argumentation capacity. ANTIDOTE will exploit cross-disciplinary\ncompetences in deep learning and argumentation to support a broader and\ninnovative view of explainable AI, where the need for high-quality explanations\nfor clinical cases deliberation is critical. As a first result of the project,\nwe publish the Antidote CasiMedicos dataset to facilitate research on\nexplainable AI in general, and argumentation in the medical domain in\nparticular.",
        "translated": "为基于机器学习的人工智能预测提供高质量的解释是一项具有挑战性和复杂性的任务。要做好这项工作，除了其他因素之外，还需要: 选择适当水平的解释的一般性/特异性; 考虑关于解释受益人对正在考虑的 AI 任务的熟悉程度的假设; 参考对决策有贡献的特定元素; 利用额外的知识(例如专家证据) ，这可能不是预测过程的一部分; 以及提供支持负面假设的证据。最后，系统需要以一种清晰可解释的、可能令人信服的方式来阐述解释。考虑到这些因素，ANTIDOTE 培养了一种可解释人工智能的综合视野，其中深度学习过程的低水平特征与适合人类论证能力的高水平方案相结合。ANTIDOTE 将利用深度学习和论证方面的跨学科能力，以支持对可解释 AI 的更广泛和创新的观点，其中对临床病例审议的高质量解释的需求是至关重要的。作为这个项目的第一个成果，我们发布了解毒剂 CasiMedicos 数据集，以促进对可解释人工智能的研究，特别是在医学领域的论证。"
    },
    {
        "title": "Automated Labeling of German Chest X-Ray Radiology Reports using Deep\n  Learning",
        "url": "http://arxiv.org/abs/2306.05997v1",
        "pub_date": "2023-06-09",
        "summary": "Radiologists are in short supply globally, and deep learning models offer a\npromising solution to address this shortage as part of clinical\ndecision-support systems. However, training such models often requires\nexpensive and time-consuming manual labeling of large datasets. Automatic label\nextraction from radiology reports can reduce the time required to obtain\nlabeled datasets, but this task is challenging due to semantically similar\nwords and missing annotated data. In this work, we explore the potential of\nweak supervision of a deep learning-based label prediction model, using a\nrule-based labeler. We propose a deep learning-based CheXpert label prediction\nmodel, pre-trained on reports labeled by a rule-based German CheXpert model and\nfine-tuned on a small dataset of manually labeled reports. Our results\ndemonstrate the effectiveness of our approach, which significantly outperformed\nthe rule-based model on all three tasks. Our findings highlight the benefits of\nemploying deep learning-based models even in scenarios with sparse data and the\nuse of the rule-based labeler as a tool for weak supervision.",
        "translated": "放射科医生在全球范围内供不应求，而深度学习模式作为临床决策支持系统的一部分，为解决这一短缺提供了一个有希望的解决方案。然而，训练这样的模型通常需要昂贵和耗时的大型数据集的手动标记。从放射学报告中自动提取标签可以减少获得标签数据集所需的时间，但是由于语义相似的单词和缺少注释数据，这项任务是具有挑战性的。在这项工作中，我们探讨了弱监督的潜力，一个基于深度学习的标签预测模型，使用基于规则的标签。我们提出了一个基于深度学习的 CheXpert 标签预测模型，该模型预先对基于规则的德国 CheXpert 模型标记的报告进行训练，并对手动标记的小数据集进行微调。我们的研究结果证明了我们的方法的有效性，它在所有三个任务上都明显优于基于规则的模型。我们的研究结果强调了使用基于深度学习的模型的好处，即使是在数据稀少的情况下，以及使用基于规则的标签器作为薄弱监督的工具。"
    },
    {
        "title": "Language Models Can Learn Exceptions to Syntactic Rules",
        "url": "http://arxiv.org/abs/2306.05969v1",
        "pub_date": "2023-06-09",
        "summary": "Artificial neural networks can generalize productively to novel contexts. Can\nthey also learn exceptions to those productive rules? We explore this question\nusing the case of restrictions on English passivization (e.g., the fact that\n\"The vacation lasted five days\" is grammatical, but \"*Five days was lasted by\nthe vacation\" is not). We collect human acceptability judgments for passive\nsentences with a range of verbs, and show that the probability distribution\ndefined by GPT-2, a language model, matches the human judgments with high\ncorrelation. We also show that the relative acceptability of a verb in the\nactive vs. passive voice is positively correlated with the relative frequency\nof its occurrence in those voices. These results provide preliminary support\nfor the entrenchment hypothesis, according to which learners track and uses the\ndistributional properties of their input to learn negative exceptions to rules.\nAt the same time, this hypothesis fails to explain the magnitude of\nunpassivizability demonstrated by certain individual verbs, suggesting that\nother cues to exceptionality are available in the linguistic input.",
        "translated": "人工神经网络可以有效地推广到新的上下文。他们是否也能学到这些生产规则的例外情况？我们使用限制英语被动语态的例子来探讨这个问题(例如，“假期持续了五天”是合法的，但“ * 五天被假期持续了”不是)。我们收集了一系列动词被动句的人类可接受性判断，结果表明，语言模型 gPT-2所定义的概率分布与人类的判断具有高度相关性。我们还发现动词在主动语态和被动语态中的相对可接受性与动词在主动语态和被动语态中出现的相对频率呈正相关。这些结果为固守假设提供了初步的支持，根据这一假设，学习者跟踪并利用其输入的分布特性来学习规则的负异常。同时，这一假设也未能解释某些个别动词所表现出的非被动性程度，这表明在语言输入中还存在其他的例外线索。"
    },
    {
        "title": "An Efficient Speech Separation Network Based on Recurrent Fusion Dilated\n  Convolution and Channel Attention",
        "url": "http://arxiv.org/abs/2306.05887v1",
        "pub_date": "2023-06-09",
        "summary": "We present an efficient speech separation neural network, ARFDCN, which\ncombines dilated convolutions, multi-scale fusion (MSF), and channel attention\nto overcome the limited receptive field of convolution-based networks and the\nhigh computational cost of transformer-based networks. The suggested network\narchitecture is encoder-decoder based. By using dilated convolutions with\ngradually increasing dilation value to learn local and global features and\nfusing them at adjacent stages, the model can learn rich feature content.\nMeanwhile, by adding channel attention modules to the network, the model can\nextract channel weights, learn more important features, and thus improve its\nexpressive power and robustness. Experimental results indicate that the model\nachieves a decent balance between performance and computational efficiency,\nmaking it a promising alternative to current mainstream models for practical\napplications.",
        "translated": "我们提出了一个有效的语音分离神经网络，ARFDCN，它结合了扩张卷积，多尺度融合(MSF)和信道注意力，以克服有限的接收领域的卷积为基础的网络和高计算成本的变压器为基础的网络。所建议的网络结构是基于编码器-解码器的。通过使用渐增扩张值的扩张卷积来学习局部和全局特征，并在相邻阶段进行融合，该模型可以学习到丰富的特征内容。同时，通过在网络中增加信道注意模块，该模型可以提取信道权重，学习更多的重要特征，从而提高其表达能力和鲁棒性。实验结果表明，该模型在性能和计算效率之间取得了较好的平衡，是目前主流模型在实际应用中的一种有前途的替代方案。"
    },
    {
        "title": "Weakly-Supervised Scientific Document Classification via\n  Retrieval-Augmented Multi-Stage Training",
        "url": "http://arxiv.org/abs/2306.07193v1",
        "pub_date": "2023-06-12",
        "summary": "Scientific document classification is a critical task for a wide range of\napplications, but the cost of obtaining massive amounts of human-labeled data\ncan be prohibitive. To address this challenge, we propose a weakly-supervised\napproach for scientific document classification using label names only. In\nscientific domains, label names often include domain-specific concepts that may\nnot appear in the document corpus, making it difficult to match labels and\ndocuments precisely. To tackle this issue, we propose WANDER, which leverages\ndense retrieval to perform matching in the embedding space to capture the\nsemantics of label names. We further design the label name expansion module to\nenrich the label name representations. Lastly, a self-training step is used to\nrefine the predictions. The experiments on three datasets show that WANDER\noutperforms the best baseline by 11.9% on average. Our code will be published\nat https://github.com/ritaranx/wander.",
        "translated": "科学文档分类对于广泛的应用来说是一个关键的任务，但是获取大量的人类标记数据的成本可能是高昂的。为了应对这一挑战，我们提出了一种弱监督的方法，用于只使用标签名称的科学文档分类。在科学领域，标签名称往往包括特定领域的概念，这些概念可能不会出现在文档语料库中，因此难以精确匹配标签和文档。为了解决这个问题，我们提出了 WANDER，它利用密集检索在嵌入空间中执行匹配来捕获标签名的语义。进一步设计了标签名扩展模块，丰富了标签名表示。最后，使用一个自我训练步骤来完善预测。在三个数据集上的实验结果表明，WANDER 平均比最佳基准线高出11.9% 。我们的代码会在 https://github.com/ritaranx/wander 公布。"
    },
    {
        "title": "Fair Learning to Rank with Distribution-free Risk Control",
        "url": "http://arxiv.org/abs/2306.07188v1",
        "pub_date": "2023-06-12",
        "summary": "Learning to Rank (LTR) methods are vital in online economies, affecting users\nand item providers. Fairness in LTR models is crucial to allocate exposure\nproportionally to item relevance. The deterministic ranking model can lead to\nunfair exposure distribution when items with the same relevance receive\nslightly different scores. Stochastic LTR models, incorporating the\nPlackett-Luce (PL) model, address fairness issues but have limitations in\ncomputational cost and performance guarantees. To overcome these limitations,\nwe propose FairLTR-RC, a novel post-hoc model-agnostic method. FairLTR-RC\nleverages a pretrained scoring function to create a stochastic LTR model,\neliminating the need for expensive training. Furthermore, FairLTR-RC provides\nfinite-sample guarantees on a user-specified utility using distribution-free\nrisk control framework. By additionally incorporating the Thresholded PL (TPL)\nmodel, we are able to achieve an effective trade-off between utility and\nfairness. Experimental results on several benchmark datasets demonstrate that\nFairLTR-RC significantly improves fairness in widely-used deterministic LTR\nmodels while guaranteeing a specified level of utility.",
        "translated": "学习排名(LTR)方法在网络经济中至关重要，它会影响用户和商品供应商。LTR 模型中的公平性对于按照项目相关性按比例分配暴露是至关重要的。确定性排序模型可能导致不公平的曝光分布，当项目相同的相关性得到略有不同的分数。结合 Plackett-Luce (PL)模型的随机 LTR 模型解决了公平性问题，但在计算成本和性能保证方面存在局限性。为了克服这些局限性，我们提出了一种新的事后模型无关方法 FairLTR-RC。FairLTR-RC 利用一个预先训练的评分函数来创建一个随机 LTR 模型，从而消除了对昂贵培训的需求。此外，FairLTR-RC 使用无分布风险控制框架为用户指定的公用事业提供有限样本保证。另外，通过引入阈限物流(TPL)模型，我们能够在效用和公平之间达到有效的平衡。在几个基准数据集上的实验结果表明，FairLTR-RC 在保证特定效用水平的同时，显著提高了广泛使用的确定性 LTR 模型的公平性。"
    },
    {
        "title": "Video-to-Music Recommendation using Temporal Alignment of Segments",
        "url": "http://arxiv.org/abs/2306.07187v1",
        "pub_date": "2023-06-12",
        "summary": "We study cross-modal recommendation of music tracks to be used as soundtracks\nfor videos. This problem is known as the music supervision task. We build on a\nself-supervised system that learns a content association between music and\nvideo. In addition to the adequacy of content, adequacy of structure is crucial\nin music supervision to obtain relevant recommendations. We propose a novel\napproach to significantly improve the system's performance using\nstructure-aware recommendation. The core idea is to consider not only the full\naudio-video clips, but rather shorter segments for training and inference. We\nfind that using semantic segments and ranking the tracks according to sequence\nalignment costs significantly improves the results. We investigate the impact\nof different ranking metrics and segmentation methods.",
        "translated": "我们研究跨模态的音乐曲目推荐作为视频配乐使用。这个问题被称为音乐监督任务。我们建立了一个自我监督系统，学习音乐和视频之间的内容关联。除了内容的充分性，结构的充分性在音乐监督中也是至关重要的，以获得相关的建议。我们提出了一种新的方法来显著提高系统的性能使用结构感知的推荐。其核心思想是不仅要考虑完整的音视频剪辑，而且要考虑训练和推理的较短片段。我们发现，使用语义片段并根据序列比对成本对音轨进行排序，可以显著提高搜索结果。我们研究了不同排序指标和分割方法的影响。"
    },
    {
        "title": "Adversarial Constrained Bidding via Minimax Regret Optimization with\n  Causality-Aware Reinforcement Learning",
        "url": "http://arxiv.org/abs/2306.07106v1",
        "pub_date": "2023-06-12",
        "summary": "The proliferation of the Internet has led to the emergence of online\nadvertising, driven by the mechanics of online auctions. In these repeated\nauctions, software agents participate on behalf of aggregated advertisers to\noptimize for their long-term utility. To fulfill the diverse demands, bidding\nstrategies are employed to optimize advertising objectives subject to different\nspending constraints. Existing approaches on constrained bidding typically rely\non i.i.d. train and test conditions, which contradicts the adversarial nature\nof online ad markets where different parties possess potentially conflicting\nobjectives. In this regard, we explore the problem of constrained bidding in\nadversarial bidding environments, which assumes no knowledge about the\nadversarial factors. Instead of relying on the i.i.d. assumption, our insight\nis to align the train distribution of environments with the potential test\ndistribution meanwhile minimizing policy regret. Based on this insight, we\npropose a practical Minimax Regret Optimization (MiRO) approach that\ninterleaves between a teacher finding adversarial environments for tutoring and\na learner meta-learning its policy over the given distribution of environments.\nIn addition, we pioneer to incorporate expert demonstrations for learning\nbidding strategies. Through a causality-aware policy design, we improve upon\nMiRO by distilling knowledge from the experts. Extensive experiments on both\nindustrial data and synthetic data show that our method, MiRO with\nCausality-aware reinforcement Learning (MiROCL), outperforms prior methods by\nover 30%.",
        "translated": "互联网的扩散导致了在线广告的出现，这是由在线拍卖的机制所驱动的。在这些重复的拍卖中，软件代理商代表广告主集合参与，以优化他们的长期效用。为了满足不同的需求，投标策略被用来优化受不同支出约束的广告目标。现有的限制性投标方法通常依赖于身份证培训和测试条件，这与在线广告市场的对抗性质相矛盾，因为在线广告市场中，不同的当事人拥有潜在的相互冲突的目标。在这方面，我们探讨了在不考虑竞争因素的情况下，在竞争性投标环境下的约束投标问题。我们的洞察力不是依赖于内部识别假设，而是使环境的列车分布与潜在的测试分布保持一致，同时最大限度地减少政策遗憾。基于这种观点，我们提出了一种实用的极大极小遗憾优化(Miniax Regret Optimation，MiRO)方法，该方法在教师寻找对抗性的辅导环境和学习者元学习策略之间进行交叉。此外，我们率先采用专家演示学习投标策略。通过一个因果关系感知策略设计，我们从专家那里提取知识来改进 MiRO。对工业数据和合成数据的大量实验表明，我们的方法，带有因果感知强化学习(miROCL)的 miRO，比之前的方法性能高出30% 以上。"
    },
    {
        "title": "Imbalanced Multi-label Classification for Business-related Text with\n  Moderately Large Label Spaces",
        "url": "http://arxiv.org/abs/2306.07046v1",
        "pub_date": "2023-06-12",
        "summary": "In this study, we compared the performance of four different methods for\nmulti label text classification using a specific imbalanced business dataset.\nThe four methods we evaluated were fine tuned BERT, Binary Relevance,\nClassifier Chains, and Label Powerset. The results show that fine tuned BERT\noutperforms the other three methods by a significant margin, achieving high\nvalues of accuracy, F1 Score, Precision, and Recall. Binary Relevance also\nperforms well on this dataset, while Classifier Chains and Label Powerset\ndemonstrate relatively poor performance. These findings highlight the\neffectiveness of fine tuned BERT for multi label text classification tasks, and\nsuggest that it may be a useful tool for businesses seeking to analyze complex\nand multifaceted texts.",
        "translated": "在这项研究中，我们比较了四种不同方法的性能，多标签文本分类使用特定的不平衡业务数据集。我们评估的四种方法是微调的 BERT、二进制相关性、分类器链和标签 Powerset。结果表明，精调误码率优于其他三种方法，具有较高的精度、 F1评分、精度和召回率。二进制相关性在这个数据集上也表现良好，而分类器链和标签 Powerset 表现出相对较差的性能。这些发现突出了微调 BERT 在多标签文本分类任务中的有效性，并表明它可能是企业寻求分析复杂和多方面文本的有用工具。"
    },
    {
        "title": "Data-Copilot: Bridging Billions of Data and Humans with Autonomous\n  Workflow",
        "url": "http://arxiv.org/abs/2306.07209v1",
        "pub_date": "2023-06-12",
        "summary": "Various industries such as finance, meteorology, and energy generate vast\namounts of heterogeneous data every day. There is a natural demand for humans\nto manage, process, and display data efficiently. However, it necessitates\nlabor-intensive efforts and a high level of expertise for these data-related\ntasks. Considering that large language models (LLMs) have showcased promising\ncapabilities in semantic understanding and reasoning, we advocate that the\ndeployment of LLMs could autonomously manage and process massive amounts of\ndata while displaying and interacting in a human-friendly manner. Based on this\nbelief, we propose Data-Copilot, an LLM-based system that connects numerous\ndata sources on one end and caters to diverse human demands on the other end.\nActing like an experienced expert, Data-Copilot autonomously transforms raw\ndata into visualization results that best match the user's intent.\nSpecifically, Data-Copilot autonomously designs versatile interfaces (tools)\nfor data management, processing, prediction, and visualization. In real-time\nresponse, it automatically deploys a concise workflow by invoking corresponding\ninterfaces step by step for the user's request. The interface design and\ndeployment processes are fully controlled by Data-Copilot itself, without human\nassistance. Besides, we create a Data-Copilot demo that links abundant data\nfrom different domains (stock, fund, company, economics, and live news) and\naccurately respond to diverse requests, serving as a reliable AI assistant.",
        "translated": "金融、气象和能源等不同行业每天都会产生大量异构数据。对人类来说，有效地管理、处理和显示数据是一种自然的需求。然而，对于这些与数据相关的任务，它需要劳动密集型的努力和高水平的专业知识。考虑到大型语言模型(LLM)在语义理解和推理方面表现出了很有前途的能力，我们主张 LLM 的部署可以自主地管理和处理大量的数据，同时以人性化的方式显示和交互。基于这一信念，我们提出了 Data-Copilot，一个基于 LLM 的系统，一端连接众多数据源，另一端满足不同的人类需求。Data-Copilot 像一位经验丰富的专家一样，自主地将原始数据转换为最符合用户意图的可视化结果。具体来说，Data-Copilot 自主设计用于数据管理、处理、预测和可视化的多功能接口(工具)。在实时响应中，它通过为用户的请求逐步调用相应的接口，自动部署一个简洁的工作流。接口设计和部署过程完全由 Data-Copilot 本身控制，无需人工协助。此外，我们创建了一个 Data-Copilot 演示，链接了来自不同领域(股票、基金、公司、经济和现场新闻)的大量数据，并准确地响应不同的请求，作为一个可靠的人工智能助手。"
    },
    {
        "title": "Valley: Video Assistant with Large Language model Enhanced abilitY",
        "url": "http://arxiv.org/abs/2306.07207v1",
        "pub_date": "2023-06-12",
        "summary": "Recently, several multi-modal models have been developed for joint image and\nlanguage understanding, which have demonstrated impressive chat abilities by\nutilizing advanced large language models (LLMs). The process of developing such\nmodels is straightforward yet effective. It involves pre-training an adaptation\nmodule to align the semantics of the vision encoder and language model,\nfollowed by fine-tuning on the instruction-following data. However, despite the\nsuccess of this pipeline in image and language understanding, its effectiveness\nin joint video and language understanding has not been widely explored. In this\npaper, we aim to develop a novel multi-modal foundation model capable of\nperceiving video, image, and language within a general framework. To achieve\nthis goal, we introduce Valley: Video Assistant with Large Language model\nEnhanced ability. Specifically, our proposed Valley model is designed with a\nsimple projection module that bridges video, image, and language modalities,\nand is further unified with a multi-lingual LLM. We also collect multi-source\nvision-text pairs and adopt a spatio-temporal pooling strategy to obtain a\nunified vision encoding of video and image input for pre-training. Furthermore,\nwe generate multi-task instruction-following video data, including multi-shot\ncaptions, long video descriptions, action recognition, causal relationship\ninference, etc. To obtain the instruction-following data, we design diverse\nrounds of task-oriented conversations between humans and videos, facilitated by\nChatGPT. Qualitative examples demonstrate that our proposed model has the\npotential to function as a highly effective multilingual video assistant that\ncan make complex video understanding scenarios easy. Code, data, and models\nwill be available at https://github.com/RupertLuo/Valley.",
        "translated": "最近，一些多模态模型已经被开发出来用于联合图像和语言理解，它们通过使用先进的大语言模型(LLM)展示了令人印象深刻的聊天能力。开发这种模型的过程是简单而有效的。它包括预先训练一个适应模块，以便对准视觉编码器和语言模型的语义，然后对指令跟踪数据进行微调。然而，尽管这条管道在图像和语言理解方面取得了成功，但它在联合视频和语言理解方面的有效性还没有得到广泛的探索。在本文中，我们的目标是开发一个新的多模态基础模型，能够感知视频，图像和语言在一个通用的框架内。为了实现这一目标，我们引入了谷: 视频助理与大语言模型增强能力。具体来说，我们提出的 Valley 模型设计了一个简单的投影模块，它连接了视频、图像和语言模式，并进一步与多语言 LLM 相结合。采集多源视觉文本对，采用时空合并策略，获得视频和图像输入的统一视觉编码，用于预训练。此外，还生成了多任务指令跟踪视频数据，包括多镜头字幕、长视频描述、动作识别、因果关系推理等。为了获得指令跟踪数据，我们设计了不同轮次的任务导向的人类和视频之间的对话，促进了 ChatGPT。定性的例子表明，我们提出的模型有潜力作为一个高效的多语言视频助理，可以使复杂的视频理解场景容易。代码、数据和模型将在 https://github.com/rupertluo/valley 提供。"
    },
    {
        "title": "RECAP: Retrieval-Enhanced Context-Aware Prefix Encoder for Personalized\n  Dialogue Response Generation",
        "url": "http://arxiv.org/abs/2306.07206v1",
        "pub_date": "2023-06-12",
        "summary": "Endowing chatbots with a consistent persona is essential to an engaging\nconversation, yet it remains an unresolved challenge. In this work, we propose\na new retrieval-enhanced approach for personalized response generation.\nSpecifically, we design a hierarchical transformer retriever trained on\ndialogue domain data to perform personalized retrieval and a context-aware\nprefix encoder that fuses the retrieved information to the decoder more\neffectively. Extensive experiments on a real-world dataset demonstrate the\neffectiveness of our model at generating more fluent and personalized\nresponses. We quantitatively evaluate our model's performance under a suite of\nhuman and automatic metrics and find it to be superior compared to\nstate-of-the-art baselines on English Reddit conversations.",
        "translated": "赋予聊天机器人一个一致的角色对于一个引人入胜的对话至关重要，然而这仍然是一个未解决的挑战。在这项工作中，我们提出了一个新的检索增强的方法来生成个性化的响应。具体地说，我们设计了一个基于对话域数据训练的分层变压器检索器来执行个性化检索，以及一个上下文感知的前缀编码器来更有效地将检索到的信息融合到解码器中。在真实世界数据集上的大量实验证明了我们的模型在产生更流畅和个性化响应方面的有效性。我们定量评估了我们的模型在一套人工和自动指标下的表现，发现它比英语 Reddit 会话的最先进的基线要好。"
    },
    {
        "title": "LTCR: Long-Text Chinese Rumor Detection Dataset",
        "url": "http://arxiv.org/abs/2306.07201v2",
        "pub_date": "2023-06-12",
        "summary": "False information can spread quickly on social media, negatively influencing\nthe citizens' behaviors and responses to social events. To better detect all of\nthe fake news, especially long texts which are harder to find completely, a\nLong-Text Chinese Rumor detection dataset named LTCR is proposed. The LTCR\ndataset provides a valuable resource for accurately detecting misinformation,\nespecially in the context of complex fake news related to COVID-19. The dataset\nconsists of 1,729 and 500 pieces of real and fake news, respectively. The\naverage lengths of real and fake news are approximately 230 and 152 characters.\nWe also propose \\method, Salience-aware Fake News Detection Model, which\nachieves the highest accuracy (95.85%), fake news recall (90.91%) and F-score\n(90.60%) on the dataset. (https://github.com/Enderfga/DoubleCheck)",
        "translated": "虚假信息可以在社交媒体上迅速传播，对公民的行为和对社会事件的反应产生负面影响。为了更好地检测所有的假新闻，特别是难以完全发现的长文本，提出了一种长文本中文谣言检测数据集 LTCR。LTCR 数据集为准确检测错误信息提供了有价值的资源，特别是在与2019冠状病毒疾病有关的复杂假新闻背景下。这个数据集包括1729条真实新闻和500条假新闻。真实和假新闻的平均长度大约是230和152个字符。本文还提出了基于显著性的假新闻检测模型，该模型对数据集的准确率最高(95.85%) ，对假新闻的召回率最高(90.91%) ，对假新闻的 F 分值最高(90.60%)。( https://github.com/enderfga/doublecheck )"
    },
    {
        "title": "A Survey of Vision-Language Pre-training from the Lens of Multimodal\n  Machine Translation",
        "url": "http://arxiv.org/abs/2306.07198v1",
        "pub_date": "2023-06-12",
        "summary": "Large language models such as BERT and the GPT series started a paradigm\nshift that calls for building general-purpose models via pre-training on large\ndatasets, followed by fine-tuning on task-specific datasets. There is now a\nplethora of large pre-trained models for Natural Language Processing and\nComputer Vision. Recently, we have seen rapid developments in the joint\nVision-Language space as well, where pre-trained models such as CLIP (Radford\net al., 2021) have demonstrated improvements in downstream tasks like image\ncaptioning and visual question answering. However, surprisingly there is\ncomparatively little work on exploring these models for the task of multimodal\nmachine translation, where the goal is to leverage image/video modality in\ntext-to-text translation. To fill this gap, this paper surveys the landscape of\nlanguage-and-vision pre-training from the lens of multimodal machine\ntranslation. We summarize the common architectures, pre-training objectives,\nand datasets from literature and conjecture what further is needed to make\nprogress on multimodal machine translation.",
        "translated": "像 BERT 和 GPT 系列这样的大型语言模型开启了一个范式转变，要求通过对大型数据集进行预训练来构建通用模型，然后对特定任务的数据集进行微调。现在有大量的自然语言处理和计算机视觉的大型预训练模型。最近，我们也看到了联合视觉语言空间的快速发展，其中预先训练的模型如 CLIP (Radford et al。 ，2021)已经在下游任务如图像字幕和视觉问题回答方面表现出改进。然而，令人惊讶的是，在多模态机器翻译的任务中，探索这些模型的工作相对较少，其目标是在文本到文本的翻译中利用图像/视频模态。为了填补这一空白，本文从多模态机器翻译的角度考察了语言和视觉预训的前景。我们总结了通用的体系结构、预训练目标和来自文献的数据集，并推测在多模式机器翻译方面还需要做些什么。"
    },
    {
        "title": "Large language models and (non-)linguistic recursion",
        "url": "http://arxiv.org/abs/2306.07195v1",
        "pub_date": "2023-06-12",
        "summary": "Recursion is one of the hallmarks of human language. While many design\nfeatures of language have been shown to exist in animal communication systems,\nrecursion has not. Previous research shows that GPT-4 is the first large\nlanguage model (LLM) to exhibit metalinguistic abilities (Begu\\v{s},\nD\\k{a}bkowski, and Rhodes 2023). Here, we propose several prompt designs aimed\nat eliciting and analyzing recursive behavior in LLMs, both linguistic and\nnon-linguistic. We demonstrate that when explicitly prompted, GPT-4 can both\nproduce and analyze recursive structures. Thus, we present one of the first\nstudies investigating whether meta-linguistic awareness of recursion -- a\nuniquely human cognitive property -- can emerge in transformers with a high\nnumber of parameters such as GPT-4.",
        "translated": "递归是人类语言的标志之一。虽然语言的许多设计特征已被证明存在于动物交流系统中，但递归却没有。以往的研究表明，GPT-4是第一个表现出元语言能力的大型语言模型(Begu v { s } ，D k { a } bkowski，and Rhodes 2023)。在这里，我们提出了几个快速的设计，旨在引发和分析递归行为的 LLM，无论是语言和非语言。我们演示了当显式提示时，GPT-4既可以产生递归结构，也可以分析递归结构。因此，我们提出的第一个研究之一，调查是否元语言意识的递归-一个独特的人类认知属性-可以出现在变压器与大量的参数，如 GPT-4。"
    },
    {
        "title": "The Effect of Masking Strategies on Knowledge Retention by Language\n  Models",
        "url": "http://arxiv.org/abs/2306.07185v1",
        "pub_date": "2023-06-12",
        "summary": "Language models retain a significant amount of world knowledge from their\npre-training stage. This allows knowledgeable models to be applied to\nknowledge-intensive tasks prevalent in information retrieval, such as ranking\nor question answering. Understanding how and which factual information is\nacquired by our models is necessary to build responsible models. However,\nlimited work has been done to understand the effect of pre-training tasks on\nthe amount of knowledge captured and forgotten by language models during\npre-training. Building a better understanding of knowledge acquisition is the\ngoal of this paper. Therefore, we utilize a selection of pre-training tasks to\ninfuse knowledge into our model. In the following steps, we test the model's\nknowledge retention by measuring its ability to answer factual questions. Our\nexperiments show that masking entities and principled masking of correlated\nspans based on pointwise mutual information lead to more factual knowledge\nbeing retained than masking random tokens. Our findings demonstrate that, like\nthe ability to perform a task, the (factual) knowledge acquired from being\ntrained on that task is forgotten when a model is trained to perform another\ntask (catastrophic forgetting) and how to prevent this phenomenon. To foster\nreproducibility, the code, as well as the data used in this paper, are openly\navailable.",
        "translated": "语言模型从培训前阶段就保留了大量的世界知识。这使得知识型模型能够应用于信息检索中普遍存在的知识密集型任务，例如排名或问答。要建立负责任的模型，就必须了解我们的模型是如何以及获取哪些事实信息的。然而，在理解培训前任务对语言模型在培训前捕获和遗忘的知识量的影响方面所做的工作有限。加深对知识获取的理解是本文的目的。因此，我们利用一个预训练任务的选择，将知识注入到我们的模型中。在接下来的步骤中，我们通过测量模型回答实际问题的能力来测试模型的知识保持能力。我们的实验表明，屏蔽实体和基于点间互信息的相关跨度的原则性屏蔽比屏蔽随机标记能够保留更多的事实知识。我们的研究结果表明，就像执行任务的能力一样，当一个模型被训练去执行另一个任务(灾难性遗忘)时，从该任务中获得的(事实)知识会被遗忘，以及如何防止这种现象的发生。为了提高可重复性，本文中使用的代码和数据都是公开的。"
    },
    {
        "title": "Augmenting Language Models with Long-Term Memory",
        "url": "http://arxiv.org/abs/2306.07174v1",
        "pub_date": "2023-06-12",
        "summary": "Existing large language models (LLMs) can only afford fix-sized inputs due to\nthe input length limit, preventing them from utilizing rich long-context\ninformation from past inputs. To address this, we propose a framework, Language\nModels Augmented with Long-Term Memory (LongMem), which enables LLMs to\nmemorize long history. We design a novel decoupled network architecture with\nthe original backbone LLM frozen as a memory encoder and an adaptive residual\nside-network as a memory retriever and reader. Such a decoupled memory design\ncan easily cache and update long-term past contexts for memory retrieval\nwithout suffering from memory staleness. Enhanced with memory-augmented\nadaptation training, LongMem can thus memorize long past context and use\nlong-term memory for language modeling. The proposed memory retrieval module\ncan handle unlimited-length context in its memory bank to benefit various\ndownstream tasks. Typically, LongMem can enlarge the long-form memory to 65k\ntokens and thus cache many-shot extra demonstration examples as long-form\nmemory for in-context learning. Experiments show that our method outperforms\nstrong long-context models on ChapterBreak, a challenging long-context modeling\nbenchmark, and achieves remarkable improvements on memory-augmented in-context\nlearning over LLMs. The results demonstrate that the proposed method is\neffective in helping language models to memorize and utilize long-form\ncontents. Our code is open-sourced at https://aka.ms/LongMem.",
        "translated": "由于输入长度的限制，现有的大型语言模型(LLM)只能提供固定大小的输入，这使得它们无法利用来自过去输入的丰富的长上下文信息。为了解决这个问题，我们提出了一个框架，即使用长期记忆增强的语言模型(LongMem) ，它使长期记忆能够记忆长期的历史。我们设计了一种新颖的解耦网络结构，其中原骨干 LLM 作为内存编码器，自适应残余网络作为内存检索器和读取器。这种解耦的内存设计可以轻松地缓存和更新长期的过去上下文，用于内存检索，而不会受到内存过时的影响。随着记忆增强适应训练的加强，LongMem 因此可以记住很长的过去的上下文，并使用长期记忆进行语言建模。提出的内存检索模块可以在其内存库中处理无限长的上下文，有利于各种下游任务。通常，LongMem 可以将长形式内存扩大到65k 令牌，从而缓存多镜头的额外示例作为长形式内存，用于上下文学习。实验结果表明，该方法优于一个具有挑战性的长上下文建模基准 ChapterBreak 的强大长上下文模型，并且在 LLM 上实现了对记忆增强的上下文学习的显著改进。结果表明，该方法能有效地帮助语言模型记忆和利用长形式的内容。我们的代码在 https://aka.ms/longmem 是开源的。"
    },
    {
        "title": "Prompt-based Extraction of Social Determinants of Health Using Few-shot\n  Learning",
        "url": "http://arxiv.org/abs/2306.07170v1",
        "pub_date": "2023-06-12",
        "summary": "Social determinants of health (SDOH) documented in the electronic health\nrecord through unstructured text are increasingly being studied to understand\nhow SDOH impacts patient health outcomes. In this work, we utilize the Social\nHistory Annotation Corpus (SHAC), a multi-institutional corpus of de-identified\nsocial history sections annotated for SDOH, including substance use,\nemployment, and living status information. We explore the automatic extraction\nof SDOH information with SHAC in both standoff and inline annotation formats\nusing GPT-4 in a one-shot prompting setting. We compare GPT-4 extraction\nperformance with a high-performing supervised approach and perform thorough\nerror analyses. Our prompt-based GPT-4 method achieved an overall 0.652 F1 on\nthe SHAC test set, similar to the 7th best-performing system among all teams in\nthe n2c2 challenge with SHAC.",
        "translated": "通过非结构化文本记录在电子健康记录中的健康的社会决定因素(SDOH)正在被越来越多地研究，以了解 SDOH 如何影响患者的健康结果。在这项工作中，我们利用社会历史注释语料库(SHAC) ，一个多机构语料库的去识别社会历史部分为 SDOH 注释，包括物质使用，就业和生活状态信息。我们使用 GPT-4在一次性提示设置中探索使用 SHAC 以对峙格式和内联注释格式自动提取 SDOH 信息。我们比较了 GPT-4提取性能和高性能的监督方法，并进行了彻底的误差分析。我们的基于提示的 GPT-4方法在 SHAC 测试集上获得了总体0.652 F1，类似于所有团队在 SHAC 的 n2c2挑战中排名第7的最佳系统。"
    },
    {
        "title": "Best-Case Retrieval Evaluation: Improving the Sensitivity of Reciprocal\n  Rank with Lexicographic Precision",
        "url": "http://arxiv.org/abs/2306.07908v1",
        "pub_date": "2023-06-13",
        "summary": "Across a variety of ranking tasks, researchers use reciprocal rank to measure\nthe effectiveness for users interested in exactly one relevant item. Despite\nits widespread use, evidence suggests that reciprocal rank is brittle when\ndiscriminating between systems. This brittleness, in turn, is compounded in\nmodern evaluation settings where current, high-precision systems may be\ndifficult to distinguish. We address the lack of sensitivity of reciprocal rank\nby introducing and connecting it to the concept of best-case retrieval, an\nevaluation method focusing on assessing the quality of a ranking for the most\nsatisfied possible user across possible recall requirements. This perspective\nallows us to generalize reciprocal rank and define a new preference-based\nevaluation we call lexicographic precision or lexiprecision. By mathematical\nconstruction, we ensure that lexiprecision preserves differences detected by\nreciprocal rank, while empirically improving sensitivity and robustness across\na broad set of retrieval and recommendation tasks.",
        "translated": "在各种排名任务中，研究人员使用互惠排名来衡量对一个相关项目感兴趣的用户的有效性。尽管它被广泛使用，但有证据表明，在区分不同体系时，互惠等级是脆弱的。这种脆性，反过来，在现代评估设置中，当前，高精度的系统可能难以区分复杂。我们通过引入并联系最佳案例检索的概念来解决相互排名缺乏敏感性的问题，最佳案例检索是一种评估方法，侧重于在可能的召回需求中为最满意的可能用户评估排名的质量。这种观点允许我们推广互惠等级，并定义一种新的基于偏好的评价，我们称之为词典精度或词汇精度。通过数学建构，我们确保词汇精确度保留了通过相互排名检测到的差异，同时经验性地提高了广泛的检索和推荐任务集的灵敏度和鲁棒性。"
    },
    {
        "title": "ReadProbe: A Demo of Retrieval-Enhanced Large Language Models to Support\n  Lateral Reading",
        "url": "http://arxiv.org/abs/2306.07875v1",
        "pub_date": "2023-06-13",
        "summary": "With the rapid growth and spread of online misinformation, people need tools\nto help them evaluate the credibility and accuracy of online information.\nLateral reading, a strategy that involves cross-referencing information with\nmultiple sources, may be an effective approach to achieving this goal. In this\npaper, we present ReadProbe, a tool to support lateral reading, powered by\ngenerative large language models from OpenAI and the Bing search engine. Our\ntool is able to generate useful questions for lateral reading, scour the web\nfor relevant documents, and generate well-attributed answers to help people\nbetter evaluate online information. We made a web-based application to\ndemonstrate how ReadProbe can help reduce the risk of being misled by false\ninformation. The code is available at\nhttps://github.com/DakeZhang1998/ReadProbe. An earlier version of our tool won\nthe first prize in a national AI misinformation hackathon.",
        "translated": "随着网络虚假信息的快速增长和传播，人们需要工具来帮助他们评估网络信息的可信度和准确性。横向阅读是一种涉及多源信息交叉引用的策略，可能是实现这一目标的有效途径。在这篇文章中，我们介绍了一个支持横向阅读的工具，由 OpenAI 和 Bing 搜索引擎生成的大型语言模型提供支持。我们的工具能够为横向阅读生成有用的问题，在网上搜索相关文档，并生成归属良好的答案，以帮助人们更好地评估在线信息。我们做了一个网络应用程序来演示如何通过阅读探索来帮助降低被错误信息误导的风险。密码可在 https://github.com/dakezhang1998/readprobe 查阅。我们工具的早期版本赢得了全国人工智能错误信息黑客马拉松一等奖。"
    },
    {
        "title": "KuaiSAR: A Unified Search And Recommendation Dataset",
        "url": "http://arxiv.org/abs/2306.07705v1",
        "pub_date": "2023-06-13",
        "summary": "The confluence of Search and Recommendation services is a vital aspect of\nonline content platforms like Kuaishou and TikTok. The integration of S&amp;R\nmodeling is a highly intuitive approach adopted by industry practitioners.\nHowever, there is a noticeable lack of research conducted in this area within\nthe academia, primarily due to the absence of publicly available datasets.\nConsequently, a substantial gap has emerged between academia and industry\nregarding research endeavors in this field. To bridge this gap, we introduce\nthe first large-scale, real-world dataset KuaiSAR of integrated Search And\nRecommendation behaviors collected from Kuaishou, a leading short-video app in\nChina with over 300 million daily active users. Previous research in this field\nhas predominantly employed publicly available datasets that are semi-synthetic\nand simulated, with artificially fabricated search behaviors. Distinct from\nprevious datasets, KuaiSAR records genuine user behaviors, the occurrence of\neach interaction within either search or recommendation service, and the users'\ntransitions between the two services. This work aids in joint modeling of S&amp;R,\nand the utilization of search data for recommenders (and recommendation data\nfor search engines). Additionally, due to the diverse feedback labels of\nuser-video interactions, KuaiSAR also supports a wide range of other tasks,\nincluding intent recommendation, multi-task learning, and long sequential\nmulti-behavior modeling etc. We believe this dataset will facilitate innovative\nresearch and enrich our understanding of S&amp;R services integration in real-world\napplications.",
        "translated": "搜索和推荐服务的融合是 Kuaishou 和 TikTok 等在线内容平台的一个重要方面。S & R 建模的集成是业界从业人员采用的一种高度直观的方法。然而，学术界在这一领域明显缺乏研究，主要是由于缺乏公开可用的数据集。因此，学术界和工业界在这一领域的研究工作出现了巨大的差距。为了弥补这一差距，我们介绍了第一个大规模的，真实世界的数据集 KuaiSAR 的集成搜索和推荐行为收集自 Kuaishou，一个领先的短视频应用程序在中国有超过3亿日活跃用户。以前在这个领域的研究主要使用公开可用的数据集，这些数据集是半合成的和模拟的，具有人为制造的搜索行为。与以前的数据集不同，KuaiSAR 记录了真实的用户行为、搜索或推荐服务中每个交互的发生情况以及用户在两个服务之间的转换。这项工作有助于 S & R 的联合建模，以及对推荐者的搜索数据(和搜索引擎的推荐数据)的利用。此外，由于用户与视频交互的反馈标签多种多样，KuaiSAR 还支持广泛的其他任务，包括意图推荐、多任务学习和长顺序多行为建模等。我们相信这个数据集将促进创新研究，并丰富我们对现实世界应用中的 S & R 服务集成的理解。"
    },
    {
        "title": "Practice with Graph-based ANN Algorithms on Sparse Data: Chi-square\n  Two-tower model, HNSW, Sign Cauchy Projections",
        "url": "http://arxiv.org/abs/2306.07607v1",
        "pub_date": "2023-06-13",
        "summary": "Sparse data are common. The traditional ``handcrafted'' features are often\nsparse. Embedding vectors from trained models can also be very sparse, for\nexample, embeddings trained via the ``ReLu'' activation function. In this\npaper, we report our exploration of efficient search in sparse data with\ngraph-based ANN algorithms (e.g., HNSW, or SONG which is the GPU version of\nHNSW), which are popular in industrial practice, e.g., search and ads\n(advertising).\n  We experiment with the proprietary ads targeting application, as well as\nbenchmark public datasets. For ads targeting, we train embeddings with the\nstandard ``cosine two-tower'' model and we also develop the ``chi-square\ntwo-tower'' model. Both models produce (highly) sparse embeddings when they are\nintegrated with the ``ReLu'' activation function. In EBR (embedding-based\nretrieval) applications, after we the embeddings are trained, the next crucial\ntask is the approximate near neighbor (ANN) search for serving. While there are\nmany ANN algorithms we can choose from, in this study, we focus on the\ngraph-based ANN algorithm (e.g., HNSW-type).\n  Sparse embeddings should help improve the efficiency of EBR. One benefit is\nthe reduced memory cost for the embeddings. The other obvious benefit is the\nreduced computational time for evaluating similarities, because, for\ngraph-based ANN algorithms such as HNSW, computing similarities is often the\ndominating cost. In addition to the effort on leveraging data sparsity for\nstorage and computation, we also integrate ``sign cauchy random projections''\n(SignCRP) to hash vectors to bits, to further reduce the memory cost and speed\nup the ANN search. In NIPS'13, SignCRP was proposed to hash the chi-square\nsimilarity, which is a well-adopted nonlinear kernel in NLP and computer\nvision. Therefore, the chi-square two-tower model, SignCRP, and HNSW are now\ntightly integrated.",
        "translated": "稀疏的数据很常见。传统的“手工制作”的特点往往是稀少的。从训练过的模型中嵌入向量也可能非常稀疏，例如，通过“ ReLu”激活函数训练的嵌入。在本文中，我们报告了在稀疏数据中使用基于图的神经网络算法(例如，HNSW，或 SONG，这是 HNSW 的 GPU 版本)进行有效搜索的探索，这在工业实践中很流行，例如，搜索和广告(广告)。我们尝试使用针对应用程序的专有广告，以及基准公共数据集。对于广告定位，我们使用标准的“余弦双塔”模型训练嵌入，同时开发了“卡方双塔”模型。这两种模式在与“ ReLu”激活函数集成时都会产生(高度)稀疏的嵌入。在基于嵌入的检索(EBR)应用中，嵌入训练完成后，接下来的关键任务是近似近邻(ANN)搜索服务。虽然有很多神经网络算法可供选择，但本文主要研究基于图的神经网络算法(如 HNSW 型)。稀疏嵌入有助于提高 EBR 的效率。一个好处是减少了嵌入的内存开销。另一个明显的好处是减少了评估相似性的计算时间，因为对于基于图的神经网络算法，如 HNSW，计算相似性往往是主要的代价。除了努力利用数据稀疏性进行存储和计算，我们还集成了“符号柯西随机投影”(SignCRP)来散列向量到位，以进一步降低内存成本和加速人工神经网络搜索。在 NIPS’13中，SignCRP 被提出来对卡方相似度进行散列，这是一种在自然语言处理和计算机视觉中广泛采用的非线性核。因此，卡方双塔模型 SignCRP 和 HNSW 现在紧密结合在一起。"
    },
    {
        "title": "Unified Off-Policy Learning to Rank: a Reinforcement Learning\n  Perspective",
        "url": "http://arxiv.org/abs/2306.07528v1",
        "pub_date": "2023-06-13",
        "summary": "Off-policy Learning to Rank (LTR) aims to optimize a ranker from data\ncollected by a deployed logging policy. However, existing off-policy learning\nto rank methods often make strong assumptions about how users generate the\nclick data, i.e., the click model, and hence need to tailor their methods\nspecifically under different click models. In this paper, we unified the\nranking process under general stochastic click models as a Markov Decision\nProcess (MDP), and the optimal ranking could be learned with offline\nreinforcement learning (RL) directly. Building upon this, we leverage offline\nRL techniques for off-policy LTR and propose the Click Model-Agnostic Unified\nOff-policy Learning to Rank (CUOLR) method, which could be easily applied to a\nwide range of click models. Through a dedicated formulation of the MDP, we show\nthat offline RL algorithms can adapt to various click models without complex\ndebiasing techniques and prior knowledge of the model. Results on various\nlarge-scale datasets demonstrate that CUOLR consistently outperforms the\nstate-of-the-art off-policy learning to rank algorithms while maintaining\nconsistency and robustness under different click models.",
        "translated": "非策略学习排序(Off-policy Learning to Rank，LTR)的目标是从已部署的日志策略收集的数据中优化排序器。然而，现有的对方法进行排序的非策略学习往往对用户如何生成点击数据(即点击模型)做出强有力的假设，因此需要在不同的点击模型下特别调整他们的方法。在本文中，我们将一般随机点击模型下的排名过程统一为一个马可夫决策过程(mDP) ，并且可以直接使用离线强化学习(RL)来学习最佳排名。在此基础上，我们利用离线 RL 技术进行非策略 LTR，并提出 Click 模型-不可知统一非策略学习排名(CUOLR)方法，该方法可以很容易地应用于广泛的点击模型。通过一个专门的公式的 MDP，我们表明离线 RL 算法可以适应各种点击模型没有复杂的消偏技术和先验知识的模型。在各种大规模数据集上的结果表明，在不同点击模型下，CUOLR 在排序算法方面始终优于最先进的非策略学习，同时保持了一致性和鲁棒性。"
    },
    {
        "title": "arXiVeri: Automatic table verification with GPT",
        "url": "http://arxiv.org/abs/2306.07968v1",
        "pub_date": "2023-06-13",
        "summary": "Without accurate transcription of numerical data in scientific documents, a\nscientist cannot draw accurate conclusions. Unfortunately, the process of\ncopying numerical data from one paper to another is prone to human error. In\nthis paper, we propose to meet this challenge through the novel task of\nautomatic table verification (AutoTV), in which the objective is to verify the\naccuracy of numerical data in tables by cross-referencing cited sources. To\nsupport this task, we propose a new benchmark, arXiVeri, which comprises\ntabular data drawn from open-access academic papers on arXiv. We introduce\nmetrics to evaluate the performance of a table verifier in two key areas: (i)\ntable matching, which aims to identify the source table in a cited document\nthat corresponds to a target table, and (ii) cell matching, which aims to\nlocate shared cells between a target and source table and identify their row\nand column indices accurately. By leveraging the flexible capabilities of\nmodern large language models (LLMs), we propose simple baselines for table\nverification. Our findings highlight the complexity of this task, even for\nstate-of-the-art LLMs like OpenAI's GPT-4. The code and benchmark will be made\npublicly available.",
        "translated": "没有科学文献中数字数据的准确记录，科学家就不能得出准确的结论。不幸的是，将数字数据从一张纸复制到另一张纸的过程容易出现人为错误。在本文中，我们提出通过自动表格验证(AutoTV)这一新的任务来迎接这一挑战，其目标是通过交叉引用来源来验证表格中数字数据的准确性。为了支持这个任务，我们提出了一个新的基准，arXiVeri，它包含从 arXiv 上的开放存取学术论文中提取的表格数据。我们引入指标来评估表验证器在两个关键领域的性能: (i)表匹配，其目的是识别与目标表对应的引用文档中的源表; 和(ii)单元格匹配，其目的是在目标和源表之间定位共享单元格，并准确识别其行和列索引。通过利用现代大型语言模型(LLM)的灵活性，我们为表验证提出了简单的基线。我们的发现强调了这项任务的复杂性，即使对于像 OpenAI 的 GPT-4这样的最先进的 LLM 也是如此。代码和基准将公开发布。"
    },
    {
        "title": "MOFI: Learning Image Representations from Noisy Entity Annotated Images",
        "url": "http://arxiv.org/abs/2306.07952v1",
        "pub_date": "2023-06-13",
        "summary": "We present MOFI, a new vision foundation model designed to learn image\nrepresentations from noisy entity annotated images. MOFI differs from previous\nwork in two key aspects: ($i$) pre-training data, and ($ii$) training recipe.\nRegarding data, we introduce a new approach to automatically assign entity\nlabels to images from noisy image-text pairs. Our approach involves employing a\nnamed entity recognition model to extract entities from the alt-text, and then\nusing a CLIP model to select the correct entities as labels of the paired\nimage. The approach is simple, does not require costly human annotation, and\ncan be readily scaled up to billions of image-text pairs mined from the web.\nThrough this method, we have created Image-to-Entities (I2E), a new large-scale\ndataset with 1 billion images and 2 million distinct entities, covering rich\nvisual concepts in the wild. Building upon the I2E dataset, we study different\ntraining recipes, including supervised pre-training, contrastive pre-training,\nand multi-task learning. For constrastive pre-training, we treat entity names\nas free-form text, and further enrich them with entity descriptions.\nExperiments show that supervised pre-training with large-scale fine-grained\nentity labels is highly effective for image retrieval tasks, and multi-task\ntraining further improves the performance. The final MOFI model achieves 86.66%\nmAP on the challenging GPR1200 dataset, surpassing the previous\nstate-of-the-art performance of 72.19% from OpenAI's CLIP model. Further\nexperiments on zero-shot and linear probe image classification also show that\nMOFI outperforms a CLIP model trained on the original image-text data,\ndemonstrating the effectiveness of the I2E dataset in learning strong image\nrepresentations.",
        "translated": "提出了一种新的视觉基础模型 MOFI，该模型旨在从噪声实体注释图像中学习图像表示。MOFI 与以往的工作有两个关键方面的不同: ($i $)培训前数据和($ii $)培训配方。对于数据，我们引入了一种新的方法来自动分配实体标签图像噪声的图像-文本对。我们的方法包括使用命名实体识别模型从替代文本中提取实体，然后使用 CLIP 模型选择正确的实体作为配对图像的标签。这种方法很简单，不需要昂贵的人工注释，而且可以很容易地扩大到从网络中挖掘出的数十亿图像-文本对。通过这种方法，我们创建了图像到实体(I2E) ，这是一个新的大规模数据集，包含10亿张图像和200万个不同的实体，覆盖了丰富的野外视觉概念。在 I2E 数据集的基础上，我们研究了不同的训练方法，包括监督预训练、对比预训练和多任务学习。在对比预训练中，我们将实体名称视为自由形式的文本，并用实体描述进一步丰富实体名称。实验表明，基于大规模细粒度实体标签的监督预训练对图像检索任务具有很高的效果，多任务训练进一步提高了性能。最终的 MOFI 模型在具有挑战性的 GPR1200数据集上达到了86.66% 的 mAP，超过了之前 OpenAI 的 CLIP 模型72.19% 的最先进性能。进一步的零拍和线性探针图像分类实验也表明，MOFI 优于对原始图像-文本数据进行训练的 CLIP 模型，证明了 I2E 数据集在学习强图像表示方面的有效性。"
    },
    {
        "title": "Questioning the Survey Responses of Large Language Models",
        "url": "http://arxiv.org/abs/2306.07951v1",
        "pub_date": "2023-06-13",
        "summary": "As large language models increase in capability, researchers have started to\nconduct surveys of all kinds on these models with varying scientific\nmotivations. In this work, we examine what we can learn from a model's survey\nresponses on the basis of the well-established American Community Survey (ACS)\nby the U.S. Census Bureau. Evaluating more than a dozen different models,\nvarying in size from a few hundred million to ten billion parameters, hundreds\nof thousands of times each on questions from the ACS, we systematically\nestablish two dominant patterns. First, smaller models have a significant\nposition and labeling bias, for example, towards survey responses labeled with\nthe letter \"A\". This A-bias diminishes, albeit slowly, as model size increases.\nSecond, when adjusting for this labeling bias through randomized answer\nordering, models still do not trend toward US population statistics or those of\nany cognizable population. Rather, models across the board trend toward\nuniformly random aggregate statistics over survey responses. This pattern is\nrobust to various different ways of prompting the model, including what is the\nde-facto standard. Our findings demonstrate that aggregate statistics of a\nlanguage model's survey responses lack the signals found in human populations.\nThis absence of statistical signal cautions about the use of survey responses\nfrom large language models at present time.",
        "translated": "随着大型语言模型能力的提高，研究人员开始以不同的科学动机对这些模型进行各种各样的调查。在这项工作中，我们研究我们可以从一个模型的调查反应的基础上，由美国人口普查局建立的美国社区调查(ACS)的学习。我们评估了十几个不同的模型，这些模型的大小从几亿到一百亿个参数不等，每个模型对 ACS 提出的问题进行了数十万次评估，我们系统地建立了两种主导模式。首先，较小的模型有一个重要的位置和标签偏见，例如，对标有字母“ A”的调查回答。随着模型尺寸的增加，这种 A 偏差会逐渐减小，尽管速度很慢。其次，当通过随机回答排序调整这种标记偏差时，模型仍然没有趋向于美国人口统计或任何可认知人口的统计。相反，模型全面趋向于统一随机总体统计超过调查答复。该模式对于提示模型的各种不同方式都是健壮的，包括什么是事实上的标准。我们的研究结果表明，一个语言模型的调查回答的总体统计缺乏在人口中发现的信号。这种缺乏统计信号的情况提醒人们注意目前使用来自大型语言模型的调查答复。"
    },
    {
        "title": "BoardgameQA: A Dataset for Natural Language Reasoning with Contradictory\n  Information",
        "url": "http://arxiv.org/abs/2306.07934v1",
        "pub_date": "2023-06-13",
        "summary": "Automated reasoning with unstructured natural text is a key requirement for\nmany potential applications of NLP and for developing robust AI systems.\nRecently, Language Models (LMs) have demonstrated complex reasoning capacities\neven without any finetuning. However, existing evaluation for automated\nreasoning assumes access to a consistent and coherent set of information over\nwhich models reason. When reasoning in the real-world, the available\ninformation is frequently inconsistent or contradictory, and therefore models\nneed to be equipped with a strategy to resolve such conflicts when they arise.\nOne widely-applicable way of resolving conflicts is to impose preferences over\ninformation sources (e.g., based on source credibility or information recency)\nand adopt the source with higher preference. In this paper, we formulate the\nproblem of reasoning with contradictory information guided by preferences over\nsources as the classical problem of defeasible reasoning, and develop a dataset\ncalled BoardgameQA for measuring the reasoning capacity of LMs in this setting.\nBoardgameQA also incorporates reasoning with implicit background knowledge, to\nbetter reflect reasoning problems in downstream applications. We benchmark\nvarious LMs on BoardgameQA and the results reveal a significant gap in the\nreasoning capacity of state-of-the-art LMs on this problem, showing that\nreasoning with conflicting information does not surface out-of-the-box in LMs.\nWhile performance can be improved with finetuning, it nevertheless remains\npoor.",
        "translated": "非结构化自然文本自动推理是自然语言处理许多潜在应用和开发健壮的人工智能系统的关键要求。最近，语言模型(LM)已经展示了复杂的推理能力，即使没有任何微调。然而，现有的自动推理评估假设模型能够获得一致和连贯的信息。在现实世界中进行推理时，可获得的信息往往不一致或相互矛盾，因此需要为模型配备一种战略，以便在出现这种冲突时解决这种冲突。一种广泛适用的解决冲突的方法是对信息来源强加偏好(例如，基于信息来源的可信度或信息的最新性) ，并以更高的偏好采用信息来源。在本文中，我们提出了由偏好引导的矛盾信息推理问题作为经典的可废止推理问题，并开发了一个名为 BoardgameQA 的数据集来测量在这种情况下 LM 的推理能力。BoardgameQA 还将推理与隐式背景知识结合起来，以更好地反映下游应用程序中的推理问题。我们在 BoardgameQA 上对各种 LM 进行了基准测试，结果显示在这个问题上最先进的 LM 在推理能力上存在显著的差距，表明在 LM 中，带有冲突信息的推理并不是开箱即用的。虽然通过微调可以提高性能，但它仍然很差。"
    },
    {
        "title": "WebGLM: Towards An Efficient Web-Enhanced Question Answering System with\n  Human Preferences",
        "url": "http://arxiv.org/abs/2306.07906v1",
        "pub_date": "2023-06-13",
        "summary": "We present WebGLM, a web-enhanced question-answering system based on the\nGeneral Language Model (GLM). Its goal is to augment a pre-trained large\nlanguage model (LLM) with web search and retrieval capabilities while being\nefficient for real-world deployments. To achieve this, we develop WebGLM with\nstrategies for the LLM-augmented retriever, bootstrapped generator, and human\npreference-aware scorer. Specifically, we identify and address the limitations\nof WebGPT (OpenAI), through which WebGLM is enabled with accuracy, efficiency,\nand cost-effectiveness advantages. In addition, we propose systematic criteria\nfor evaluating web-enhanced QA systems. We conduct multi-dimensional human\nevaluation and quantitative ablation studies, which suggest the outperformance\nof the proposed WebGLM designs over existing systems. WebGLM with the\n10-billion-parameter GLM (10B) is shown to perform better than the\nsimilar-sized WebGPT (13B) and even comparably to WebGPT (175B) in human\nevaluation. The code, demo, and data are at\n\\url{https://github.com/THUDM/WebGLM}.",
        "translated": "本文介绍了基于通用语言模型(GLM)的 Web 增强型问答系统 WebGLM。它的目标是增强一个预先训练的大型语言模型(LLM) ，该模型具有 Web 搜索和检索功能，同时对于现实世界的部署非常有效。为了实现这一点，我们使用 LLM 增强检索器、引导生成器和人类偏好感知记分器的策略来开发 WebGLM。具体来说，我们确定并解决了 WebGPT (OpenAI)的局限性，通过它，WebGLM 具有准确性、效率和成本效益方面的优势。此外，我们提出了评估网络增强 QA 系统的系统标准。我们进行了多维人体评估和定量消融研究，这表明所提出的 WebGLM 设计优于现有系统。具有100亿参数 GLM (10B)的 WebGLM 显示出比类似大小的 WebGPT (13B)更好的性能，甚至在人类评估中与 WebGPT (175B)相当。代码、演示和数据位于 url { https://github.com/thudm/webglm }。"
    },
    {
        "title": "Massively Multilingual Corpus of Sentiment Datasets and Multi-faceted\n  Sentiment Classification Benchmark",
        "url": "http://arxiv.org/abs/2306.07902v1",
        "pub_date": "2023-06-13",
        "summary": "Despite impressive advancements in multilingual corpora collection and model\ntraining, developing large-scale deployments of multilingual models still\npresents a significant challenge. This is particularly true for language tasks\nthat are culture-dependent. One such example is the area of multilingual\nsentiment analysis, where affective markers can be subtle and deeply ensconced\nin culture. This work presents the most extensive open massively multilingual\ncorpus of datasets for training sentiment models. The corpus consists of 79\nmanually selected datasets from over 350 datasets reported in the scientific\nliterature based on strict quality criteria. The corpus covers 27 languages\nrepresenting 6 language families. Datasets can be queried using several\nlinguistic and functional features. In addition, we present a multi-faceted\nsentiment classification benchmark summarizing hundreds of experiments\nconducted on different base models, training objectives, dataset collections,\nand fine-tuning strategies.",
        "translated": "尽管在多语言语料库收集和模型培训方面取得了令人印象深刻的进展，但开发大规模部署多语言模型仍然是一个重大挑战。对于依赖于文化的语言任务尤其如此。一个这样的例子是多语言情感分析领域，其中情感标记可以是微妙的，深深地隐藏在文化。这项工作提出了最广泛的开放大规模多语言数据集训练情感模型。该语料库包括79个手动选择的数据集，从超过350个数据集报告的科学文献基于严格的质量标准。语料库包括代表6个语系的27种语言。可以使用几种语言和函数特性查询数据集。此外，我们提出了一个多方面的情绪分类基准，总结了数百个实验进行了不同的基础模型，训练目标，数据集收集和微调策略。"
    },
    {
        "title": "Artificial Artificial Artificial Intelligence: Crowd Workers Widely Use\n  Large Language Models for Text Production Tasks",
        "url": "http://arxiv.org/abs/2306.07899v1",
        "pub_date": "2023-06-13",
        "summary": "Large language models (LLMs) are remarkable data annotators. They can be used\nto generate high-fidelity supervised training data, as well as survey and\nexperimental data. With the widespread adoption of LLMs, human gold--standard\nannotations are key to understanding the capabilities of LLMs and the validity\nof their results. However, crowdsourcing, an important, inexpensive way to\nobtain human annotations, may itself be impacted by LLMs, as crowd workers have\nfinancial incentives to use LLMs to increase their productivity and income. To\ninvestigate this concern, we conducted a case study on the prevalence of LLM\nusage by crowd workers. We reran an abstract summarization task from the\nliterature on Amazon Mechanical Turk and, through a combination of keystroke\ndetection and synthetic text classification, estimate that 33-46% of crowd\nworkers used LLMs when completing the task. Although generalization to other,\nless LLM-friendly tasks is unclear, our results call for platforms,\nresearchers, and crowd workers to find new ways to ensure that human data\nremain human, perhaps using the methodology proposed here as a stepping stone.\nCode/data: https://github.com/epfl-dlab/GPTurk",
        "translated": "大型语言模型(LLM)是非常出色的数据注释器。它们可以用来生成高保真的监督训练数据，以及调查和实验数据。随着 LLM 的广泛采用，人工黄金标准注释是理解 LLM 功能及其结果有效性的关键。然而，众包作为一种获取人工注释的重要而廉价的方式，可能本身就会受到 LLM 的影响，因为众包工作者有财务动机使用 LLM 来提高他们的生产力和收入。为了调查这一问题，我们进行了一个案例研究的普遍使用 LLM 的人群工作者。我们从亚马逊土耳其机器人的文献中重新运行了一个抽象的总结任务，并且通过组合击键检测和合成文本分类，估计33-46% 的人群工作者在完成任务时使用 LLM。尽管对其他不太适合 LLM 的任务的概括还不清楚，但我们的研究结果呼吁平台、研究人员和群体工作者找到新的方法来确保人类数据仍然是人类的，或许可以使用这里提出的方法作为垫脚石。代码/资料:  https://github.com/epfl-dlab/gpturk"
    },
    {
        "title": "GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio\n  Pretraining for Speech Emotion Recognition",
        "url": "http://arxiv.org/abs/2306.07848v1",
        "pub_date": "2023-06-13",
        "summary": "Contrastive Language-Audio Pretraining (CLAP) has recently exhibited\nimpressive success in diverse fields. In this paper, we propose GEmo-CLAP, a\nkind of efficient gender-attribute-enhanced CLAP model for speech emotion\nrecognition (SER). Specifically, we first build an effective emotion CLAP model\ntermed Emo-CLAP for SER, utilizing various self-supervised learning based\npre-trained models. Then, considering the importance of the gender attribute in\nspeech emotion modeling, two GEmo-CLAP approaches are further proposed to\nintegrate the emotion and gender information of speech signals, forming more\nreasonable objectives. Extensive experiments conducted on the IEMOCAP corpus\ndemonstrate that our proposed two GEmo-CLAP approaches consistently outperform\nthe baseline Emo-CLAP with different pre-trained models, while also achieving\nsuperior recognition performance compared with other state-of-the-art methods.",
        "translated": "对比语言-音频预训练(CLAP)最近在多个领域取得了令人瞩目的成功。本文提出了一种基于性别属性增强的语音情感识别模型 GEmo-CLAP。具体来说，我们首先利用各种基于预训练的自监督学习模型，建立了一个有效的情绪 CLAP 模型，称为情绪 CLAP 模型。然后，考虑到性别属性在语音情感建模中的重要性，进一步提出了两种 Gemo-CLAP 方法来整合语音信号的情感和性别信息，形成更加合理的目标。在 IEMOCAP 语料库上进行的大量实验表明，我们提出的两种 Gemo-CLAP 方法始终优于不同预训练模型的基线 Emo-CLAP，同时与其他最先进的方法相比，也获得了更好的识别性能。"
    },
    {
        "title": "Adversarial Capsule Networks for Romanian Satire Detection and Sentiment\n  Analysis",
        "url": "http://arxiv.org/abs/2306.07845v1",
        "pub_date": "2023-06-13",
        "summary": "Satire detection and sentiment analysis are intensively explored natural\nlanguage processing (NLP) tasks that study the identification of the satirical\ntone from texts and extracting sentiments in relationship with their targets.\nIn languages with fewer research resources, an alternative is to produce\nartificial examples based on character-level adversarial processes to overcome\ndataset size limitations. Such samples are proven to act as a regularization\nmethod, thus improving the robustness of models. In this work, we improve the\nwell-known NLP models (i.e., Convolutional Neural Networks, Long Short-Term\nMemory (LSTM), Bidirectional LSTM, Gated Recurrent Units (GRUs), and\nBidirectional GRUs) with adversarial training and capsule networks. The\nfine-tuned models are used for satire detection and sentiment analysis tasks in\nthe Romanian language. The proposed framework outperforms the existing methods\nfor the two tasks, achieving up to 99.08% accuracy, thus confirming the\nimprovements added by the capsule layers and the adversarial training in NLP\napproaches.",
        "translated": "讽刺检测和情感分析是自然语言处理(NLP)研究的重要课题，主要研究从文本中识别讽刺语气并提取与目标相关的情感。在研究资源较少的语言中，另一种方法是基于字符级对抗过程生成人工示例，以克服数据集大小的限制。这些样本被证明是一种正则化方法，从而提高了模型的鲁棒性。在这项工作中，我们改进了著名的 NLP 模型(即，卷积神经网络，长短期记忆(LSTM) ，双向 LSTM，门控回归单元(GRU) ，和双向 GRU)与对抗训练和胶囊网络。这些经过微调的模型被用于罗马尼亚语中的讽刺探测和情感分析任务。该框架比现有的方法更好地完成了这两个任务，达到了99.08% 的准确率，从而证实了胶囊层的改进和 NLP 方法中的对抗性训练。"
    },
    {
        "title": "Web of Things and Trends in Agriculture: A Systematic Literature Review",
        "url": "http://arxiv.org/abs/2306.09079v1",
        "pub_date": "2023-06-15",
        "summary": "In the past few years, the Web of Things (WOT) became a beneficial\ngame-changing technology within the Agriculture domain as it introduces\ninnovative and promising solutions to the Internet of Things (IoT) agricultural\napplications problems by providing its services. WOT provides the support for\nintegration, interoperability for heterogeneous devices, infrastructures,\nplatforms, and the emergence of various other technologies. The main aim of\nthis study is about understanding and providing a growing and existing research\ncontent, issues, and directions for the future regarding WOT-based agriculture.\nTherefore, a systematic literature review (SLR) of research articles is\npresented by categorizing the selected studies published between 2010 and 2020\ninto the following categories: research type, approaches, and their application\ndomains. Apart from reviewing the state-of-the-art articles on WOT solutions\nfor the agriculture field, a taxonomy of WOT-base agriculture application\ndomains has also been presented in this study. A model has also presented to\nshow the picture of WOT based Smart Agriculture. Lastly, the findings of this\nSLR and the research gaps in terms of open issues have been presented to\nprovide suggestions on possible future directions for the researchers for\nfuture research.",
        "translated": "在过去的几年里，物联网(WOT)在农业领域成为了一个有益的改变游戏规则的技术，因为它通过提供服务引入了创新的和有前途的解决物联网(IoT)农业应用问题的方案。WOT 为异构设备、基础设施、平台以及其他各种技术的出现提供了集成、互操作性的支持。这项研究的主要目的是了解和提供一个不断增长和现有的研究内容，问题和未来的方向，关于基于 WOT 的农业。因此，通过将2010年至2020年间发表的选定研究分为以下几类: 研究类型，方法及其应用领域，对研究文章进行了系统的文献回顾(SLR)。除了回顾有关农业领域 WOT 解决方案的最新文章外，本研究还提出了基于 WOT 的农业应用领域的分类。本文还提出了一个模型来展示基于 WOT 的智能农业的图景。最后，本文介绍了本次研究的结果以及在公开课题方面的研究差距，为研究人员今后的研究提供了可能的方向建议。"
    },
    {
        "title": "Fast and Examination-agnostic Reciprocal Recommendation in Matching\n  Markets",
        "url": "http://arxiv.org/abs/2306.09060v1",
        "pub_date": "2023-06-15",
        "summary": "In matching markets such as job posting and online dating platforms, the\nrecommender system plays a critical role in the success of the platform. Unlike\nstandard recommender systems that suggest items to users, reciprocal\nrecommender systems (RRSs) that suggest other users must take into account the\nmutual interests of users. In addition, ensuring that recommendation\nopportunities do not disproportionately favor popular users is essential for\nthe total number of matches and for fairness among users. Existing\nrecommendation methods in matching markets, however, face computational\nchallenges on large-scale platforms and depend on specific examination\nfunctions in the position-based model (PBM). In this paper, we introduce the\nreciprocal recommendation method based on the matching with transferable\nutility (TU matching) model in the context of ranking recommendations in\nmatching markets and propose a fast and examination-model-free algorithm.\nFurthermore, we evaluate our approach on experiments with synthetic data and\nreal-world data from an online dating platform in Japan. Our method performs\nbetter than or as well as existing methods in terms of the total number of\nmatches and works well even in a large-scale dataset for which one existing\nmethod does not work.",
        "translated": "在招聘和在线约会平台等匹配市场方面，推荐系统对平台的成功起着关键作用。不像标准的推荐系统，建议项目给用户，互惠推荐系统(RRS) ，建议其他用户必须考虑到用户的共同利益。此外，确保推荐机会不会不成比例地偏向受欢迎的用户，对于匹配的总数和用户之间的公平性至关重要。然而，现有的匹配市场推荐方法在大规模平台上面临计算挑战，并且依赖于基于位置模型(PBM)中的特定检验函数。本文在匹配市场推荐排序的背景下，介绍了基于匹配可转移效用(TU 匹配)模型的互惠推荐方法，并提出了一种快速、无检验模型的算法。此外，我们评估了我们的实验方法与合成数据和真实世界的数据从一个在线约会平台在日本。就匹配总数而言，我们的方法比现有方法执行得更好，甚至在一个现有方法无法工作的大规模数据集中也能很好地工作。"
    },
    {
        "title": "Mapping Researcher Activity based on Publication Data by means of\n  Transformers",
        "url": "http://arxiv.org/abs/2306.09049v1",
        "pub_date": "2023-06-15",
        "summary": "Modern performance on several natural language processing (NLP) tasks has\nbeen enhanced thanks to the Transformer-based pre-trained language model BERT.\nWe employ this concept to investigate a local publication database. Research\npapers are encoded and clustered to form a landscape view of the scientific\ntopics, in which research is active. Authors working on similar topics can be\nidentified by calculating the similarity between their papers. Based on this,\nwe define a similarity metric between authors. Additionally we introduce the\nconcept of self-similarity to indicate the topical variety of authors.",
        "translated": "现代自然语言处理(NLP)任务的性能得到了提高，这要归功于基于变压器的预训练语言模型 BERT。我们使用这个概念来调查一个本地出版物数据库。研究论文的编码和聚类形成了一个景观的科学主题，其中研究是活跃的。研究类似主题的作者可以通过计算他们论文之间的相似性来识别。在此基础上，我们定义了作者之间的相似度量。此外，我们还引入了自相似的概念，以表明作者的主题多样性。"
    },
    {
        "title": "RecFusion: A Binomial Diffusion Process for 1D Data for Recommendation",
        "url": "http://arxiv.org/abs/2306.08947v1",
        "pub_date": "2023-06-15",
        "summary": "In this paper we propose RecFusion, which comprise a set of diffusion models\nfor recommendation. Unlike image data which contain spatial correlations, a\nuser-item interaction matrix, commonly utilized in recommendation, lacks\nspatial relationships between users and items. We formulate diffusion on a 1D\nvector and propose binomial diffusion, which explicitly models binary user-item\ninteractions with a Bernoulli process. We show that RecFusion approaches the\nperformance of complex VAE baselines on the core recommendation setting (top-n\nrecommendation for binary non-sequential feedback) and the most common datasets\n(MovieLens and Netflix). Our proposed diffusion models that are specialized for\n1D and/or binary setups have implications beyond recommendation systems, such\nas in the medical domain with MRI and CT scans.",
        "translated": "在本文中，我们提出了 RecFusion，它包含了一组用于推荐的扩散模型。与包含空间相关性的图像数据不同，通常用于推荐的用户-项目交互矩阵缺乏用户和项目之间的空间关系。我们在一维向量上描述扩散，并提出二项式扩散，它明确地模拟与伯努利过程的二进制用户-项目交互。我们表明 RecFusion 在核心推荐设置(二进制非顺序反馈的前 n 推荐)和最常见的数据集(MovieLens 和 Netflix)上接近复杂 VAE 基线的性能。我们提出的扩散模型是专门为一维和/或二进制设置的影响超出推荐系统，如在医学领域的 MRI 和 CT 扫描。"
    },
    {
        "title": "Document Entity Retrieval with Massive and Noisy Pre-training",
        "url": "http://arxiv.org/abs/2306.08937v1",
        "pub_date": "2023-06-15",
        "summary": "Visually-Rich Document Entity Retrieval (VDER) is a type of machine learning\ntask that aims at recovering text spans in the documents for each of the\nentities in question. VDER has gained significant attention in recent years\nthanks to its broad applications in enterprise AI. Unfortunately, as document\nimages often contain personally identifiable information (PII), publicly\navailable data have been scarce, not only because of privacy constraints but\nalso the costs of acquiring annotations. To make things worse, each dataset\nwould often define its own sets of entities, and the non-overlapping entity\nspaces between datasets make it difficult to transfer knowledge between\ndocuments. In this paper, we propose a method to collect massive-scale, noisy,\nand weakly labeled data from the web to benefit the training of VDER models.\nSuch a method will generate a huge amount of document image data to compensate\nfor the lack of training data in many VDER settings. Moreover, the collected\ndataset named DocuNet would not need to be dependent on specific document types\nor entity sets, making it universally applicable to all VDER tasks. Empowered\nby DocuNet, we present a lightweight multimodal architecture named UniFormer,\nwhich can learn a unified representation from text, layout, and image crops\nwithout needing extra visual pertaining. We experiment with our methods on\npopular VDER models in various settings and show the improvements when this\nmassive dataset is incorporated with UniFormer on both classic entity retrieval\nand few-shot learning settings.",
        "translated": "可视化丰富文档实体检索(VDER)是一种机器学习任务，旨在恢复文档中涉及到的每个实体的文本跨度。VDER 由于在企业人工智能中的广泛应用，近年来受到了广泛的关注。遗憾的是，由于文档图像通常包含个人身份信息(pII) ，公开可用的数据很少，这不仅是因为隐私限制，还因为获取注释的成本。更糟糕的是，每个数据集通常会定义自己的实体集，而数据集之间不重叠的实体空间使得在文档之间传递知识变得非常困难。本文提出了一种从网络上收集大规模、有噪声和弱标记数据的方法，有利于 VDER 模型的训练。这种方法将产生大量的文档图像数据，以弥补许多 VDER 设置中训练数据的不足。此外，名为 DocuNet 的收集的数据集不需要依赖于特定的文档类型或实体集，这使得它普遍适用于所有 VDER 任务。在 DocuNet 的支持下，我们提出了一个轻量级的多模态体系结构，名为 UniForm，它可以从文本、布局和图像作物中学习统一的表示，而不需要额外的视觉修饰。我们在不同的设置下对流行的 VDER 模型进行了实验，结果表明，在经典的实体检索和少镜头学习设置下，将这个海量数据集与 UniForm 结合起来，可以得到改进。"
    },
    {
        "title": "SIGHT: A Large Annotated Dataset on Student Insights Gathered from\n  Higher Education Transcripts",
        "url": "http://arxiv.org/abs/2306.09343v1",
        "pub_date": "2023-06-15",
        "summary": "Lectures are a learning experience for both students and teachers. Students\nlearn from teachers about the subject material, while teachers learn from\nstudents about how to refine their instruction. However, online student\nfeedback is unstructured and abundant, making it challenging for teachers to\nlearn and improve. We take a step towards tackling this challenge. First, we\ncontribute a dataset for studying this problem: SIGHT is a large dataset of 288\nmath lecture transcripts and 15,784 comments collected from the Massachusetts\nInstitute of Technology OpenCourseWare (MIT OCW) YouTube channel. Second, we\ndevelop a rubric for categorizing feedback types using qualitative analysis.\nQualitative analysis methods are powerful in uncovering domain-specific\ninsights, however they are costly to apply to large data sources. To overcome\nthis challenge, we propose a set of best practices for using large language\nmodels (LLMs) to cheaply classify the comments at scale. We observe a striking\ncorrelation between the model's and humans' annotation: Categories with\nconsistent human annotations (&gt;$0.9$ inter-rater reliability, IRR) also display\nhigher human-model agreement (&gt;$0.7$), while categories with less consistent\nhuman annotations ($0.7$-$0.8$ IRR) correspondingly demonstrate lower\nhuman-model agreement ($0.3$-$0.5$). These techniques uncover useful student\nfeedback from thousands of comments, costing around $\\$0.002$ per comment. We\nconclude by discussing exciting future directions on using online student\nfeedback and improving automated annotation techniques for qualitative\nresearch.",
        "translated": "讲座对学生和老师来说都是一次学习的经历。学生向老师学习课程材料，而老师向学生学习如何改进教学。然而，在线学生的反馈是非结构化的和丰富的，这使得教师学习和提高具有挑战性。我们朝着应对这一挑战迈出了一步。首先，我们贡献了一个数据集来研究这个问题: SIGHT 是一个大型数据集，包括288份数学课堂讲稿和15,784条评论，这些评论来自麻省理工学院开放课程软件(MIT OCW) YouTube 频道。其次，我们开发了一个使用定性分析对反馈类型进行分类的标准。定性分析方法在揭示特定领域的见解方面非常强大，但是它们应用于大型数据源的成本很高。为了克服这一挑战，我们提出了一套使用大型语言模型(LLM)以低成本对注释进行大规模分类的最佳实践。我们观察到模型注释和人类注释之间存在显著的相关性: 具有一致的人类注释的类别(> 0.9 $评分者间可靠性，IRR)也显示出较高的人类模型一致性(> 0.7 $) ，而具有不一致的人类注释的类别($0.7 $- $0.8 $IRR)相应地显示出较低的人类模型一致性($0.3 $- $0.5 $)。这些技术可以从成千上万条评论中发现有用的学生反馈，每条评论的成本约为0.002美元。最后，我们讨论了使用在线学生反馈和改进质性研究自动注释技术的令人兴奋的未来发展方向。"
    },
    {
        "title": "PaReprop: Fast Parallelized Reversible Backpropagation",
        "url": "http://arxiv.org/abs/2306.09342v1",
        "pub_date": "2023-06-15",
        "summary": "The growing size of datasets and deep learning models has made faster and\nmemory-efficient training crucial. Reversible transformers have recently been\nintroduced as an exciting new method for extremely memory-efficient training,\nbut they come with an additional computation overhead of activation\nre-computation in the backpropagation phase. We present PaReprop, a fast\nParallelized Reversible Backpropagation algorithm that parallelizes the\nadditional activation re-computation overhead in reversible training with the\ngradient computation itself in backpropagation phase. We demonstrate the\neffectiveness of the proposed PaReprop algorithm through extensive benchmarking\nacross model families (ViT, MViT, Swin and RoBERTa), data modalities (Vision &amp;\nNLP), model sizes (from small to giant), and training batch sizes. Our\nempirical results show that PaReprop achieves up to 20% higher training\nthroughput than vanilla reversible training, largely mitigating the theoretical\noverhead of 25% lower throughput from activation recomputation in reversible\ntraining. Project page: https://tylerzhu.com/pareprop.",
        "translated": "不断增长的数据集和深度学习模型使得更快、更有效的训练变得至关重要。可逆变压器作为一种新兴的高效存储器训练方法，近年来得到了广泛的应用，但是在反向传播阶段，这种方法需要增加激活重计算的计算开销。本文提出了一种快速并行化可逆反向传播算法，它将可逆训练中的附加激活重计算开销与反向传播阶段的梯度计算本身并行化。我们通过跨模型家族(ViT，MViT，Swin 和 RoBERTa) ，数据模式(Vision & NLP) ，模型大小(从小到大)和训练批量大小的广泛基准测试来证明所提出的 PaReprop 算法的有效性。我们的实验结果表明，PaReprop 比普通可逆训练提高了20% 的训练吞吐量，大大降低了可逆训练中激活重计算吞吐量降低25% 的理论开销。项目主页:  https://tylerzhu.com/pareprop。"
    },
    {
        "title": "Span-Selective Linear Attention Transformers for Effective and Robust\n  Schema-Guided Dialogue State Tracking",
        "url": "http://arxiv.org/abs/2306.09340v1",
        "pub_date": "2023-06-15",
        "summary": "In schema-guided dialogue state tracking models estimate the current state of\na conversation using natural language descriptions of the service schema for\ngeneralization to unseen services. Prior generative approaches which decode\nslot values sequentially do not generalize well to variations in schema, while\ndiscriminative approaches separately encode history and schema and fail to\naccount for inter-slot and intent-slot dependencies. We introduce SPLAT, a\nnovel architecture which achieves better generalization and efficiency than\nprior approaches by constraining outputs to a limited prediction space. At the\nsame time, our model allows for rich attention among descriptions and history\nwhile keeping computation costs constrained by incorporating linear-time\nattention. We demonstrate the effectiveness of our model on the Schema-Guided\nDialogue (SGD) and MultiWOZ datasets. Our approach significantly improves upon\nexisting models achieving 85.3 JGA on the SGD dataset. Further, we show\nincreased robustness on the SGD-X benchmark: our model outperforms the more\nthan 30$\\times$ larger D3ST-XXL model by 5.0 points.",
        "translated": "在模式引导的对话中，状态跟踪模型使用服务模式的自然语言描述来估计会话的当前状态，以便将其泛化为看不见的服务。先前解码槽值的生成方法不能很好地推广到模式中的变化，而区分方法分别编码历史和模式，不能解释槽间和意向槽依赖关系。我们介绍了 SPLAT，这是一种新的体系结构，它通过将输出限制在有限的预测空间内，实现了比以前的方法更好的泛化和效率。同时，我们的模型允许在描述和历史之间有丰富的注意力，同时通过合并线性时间注意力来保持计算成本的约束。我们在模式引导对话(SGD)和 MultiWOZ 数据集上演示了我们的模型的有效性。我们的方法显著改进了在 SGD 数据集上实现85.3 JGA 的现有模型。此外，我们在 SGD-X 基准上显示出更强的鲁棒性: 我们的模型比价格超过30美元的大型 D3ST-XXL 模型高出5.0个百分点。"
    },
    {
        "title": "WizMap: Scalable Interactive Visualization for Exploring Large Machine\n  Learning Embeddings",
        "url": "http://arxiv.org/abs/2306.09328v1",
        "pub_date": "2023-06-15",
        "summary": "Machine learning models often learn latent embedding representations that\ncapture the domain semantics of their training data. These embedding\nrepresentations are valuable for interpreting trained models, building new\nmodels, and analyzing new datasets. However, interpreting and using embeddings\ncan be challenging due to their opaqueness, high dimensionality, and the large\nsize of modern datasets. To tackle these challenges, we present WizMap, an\ninteractive visualization tool to help researchers and practitioners easily\nexplore large embeddings. With a novel multi-resolution embedding summarization\nmethod and a familiar map-like interaction design, WizMap enables users to\nnavigate and interpret embedding spaces with ease. Leveraging modern web\ntechnologies such as WebGL and Web Workers, WizMap scales to millions of\nembedding points directly in users' web browsers and computational notebooks\nwithout the need for dedicated backend servers. WizMap is open-source and\navailable at the following public demo link: https://poloclub.github.io/wizmap.",
        "translated": "机器学习模型经常学习潜在的嵌入表示，捕获其训练数据的领域语义。这些嵌入式表示对于解释训练过的模型、建立新模型和分析新数据集是有价值的。然而，由于嵌入的不透明性、高维数和现代数据集的巨大规模，解释和使用嵌入可能是具有挑战性的。为了应对这些挑战，我们展示了 WizMap，这是一个交互式可视化工具，可以帮助研究人员和从业者轻松地探索大型嵌入。WizMap 提供了一种新颖的多分辨率嵌入摘要方法和一种常见的类似地图的交互设计，使用户可以轻松地导航和解释嵌入空间。利用 WebGL 和 Web Workers 等现代 Web 技术，WizMap 可以直接在用户的 Web 浏览器和计算笔记本中嵌入数百万个点，而不需要专用的后端服务器。WizMap 是开源的，可在以下公共演示链接下载:  https://poloclub.github.io/WizMap。"
    },
    {
        "title": "Lexical Speaker Error Correction: Leveraging Language Models for Speaker\n  Diarization Error Correction",
        "url": "http://arxiv.org/abs/2306.09313v1",
        "pub_date": "2023-06-15",
        "summary": "Speaker diarization (SD) is typically used with an automatic speech\nrecognition (ASR) system to ascribe speaker labels to recognized words. The\nconventional approach reconciles outputs from independently optimized ASR and\nSD systems, where the SD system typically uses only acoustic information to\nidentify the speakers in the audio stream. This approach can lead to speaker\nerrors especially around speaker turns and regions of speaker overlap. In this\npaper, we propose a novel second-pass speaker error correction system using\nlexical information, leveraging the power of modern language models (LMs). Our\nexperiments across multiple telephony datasets show that our approach is both\neffective and robust. Training and tuning only on the Fisher dataset, this\nerror correction approach leads to relative word-level diarization error rate\n(WDER) reductions of 15-30% on three telephony datasets: RT03-CTS, Callhome\nAmerican English and held-out portions of Fisher.",
        "translated": "说话人辨认(SD)通常与自动语音识别(ASR)系统一起使用，将说话人标签归属于已识别的单词。传统的方法协调独立优化的 ASR 和 SD 系统的输出，其中 SD 系统通常只使用声学信息来识别音频流中的扬声器。这种方法可能导致说话人误差，特别是在说话人转圈和说话人重叠区域周围。在本文中，我们利用现代语言模型(LMs)的能力，提出了一种新的利用词汇信息的二次说话人纠错系统。我们在多个电话数据集上的实验表明，我们的方法既有效又可靠。仅在 Fisher 数据集上进行训练和调整，这种错误纠正方法导致三个电话数据集: RT03-CTS，Callhome American English 和 Fisher 的保留部分的相对词级二值化错误率(WDER)降低15-30% 。"
    },
    {
        "title": "Semantic HELM: An Interpretable Memory for Reinforcement Learning",
        "url": "http://arxiv.org/abs/2306.09312v1",
        "pub_date": "2023-06-15",
        "summary": "Reinforcement learning agents deployed in the real world often have to cope\nwith partially observable environments. Therefore, most agents employ memory\nmechanisms to approximate the state of the environment. Recently, there have\nbeen impressive success stories in mastering partially observable environments,\nmostly in the realm of computer games like Dota 2, StarCraft II, or MineCraft.\nHowever, none of these methods are interpretable in the sense that it is not\ncomprehensible for humans how the agent decides which actions to take based on\nits inputs. Yet, human understanding is necessary in order to deploy such\nmethods in high-stake domains like autonomous driving or medical applications.\nWe propose a novel memory mechanism that operates on human language to\nilluminate the decision-making process. First, we use CLIP to associate visual\ninputs with language tokens. Then we feed these tokens to a pretrained language\nmodel that serves the agent as memory and provides it with a coherent and\ninterpretable representation of the past. Our memory mechanism achieves\nstate-of-the-art performance in environments where memorizing the past is\ncrucial to solve tasks. Further, we present situations where our memory\ncomponent excels or fails to demonstrate strengths and weaknesses of our new\napproach.",
        "translated": "部署在现实世界中的强化学习经常不得不应对部分可观测的环境。因此，大多数代理都使用内存机制来近似处理环境的状态。最近，在掌握部分可观察的环境方面有了令人印象深刻的成功故事，主要是在计算机游戏领域，如 Dota 2、 StarCraft II 或 MineCraft。然而，所有这些方法都无法解释，因为人类无法理解代理人如何根据其输入决定采取哪些行动。然而，人类的理解是必要的，为了部署这样的方法在高风险的领域，如自动驾驶或医疗应用程序。我们提出了一种新的记忆机制，运行在人类的语言，以说明决策过程。首先，我们使用 CLIP 将可视输入与语言标记关联起来。然后，我们将这些标记提供给一个预先训练好的语言模型，该模型为代理提供记忆，并为代理提供一个连贯的、可解释的过去表示。我们的记忆机制在记忆过去对解决任务至关重要的环境中取得了最先进的性能。此外，我们提出的情况下，我们的记忆组件优秀或未能证明我们的新方法的长处和弱点。"
    },
    {
        "title": "Matching Pairs: Attributing Fine-Tuned Models to their Pre-Trained Large\n  Language Models",
        "url": "http://arxiv.org/abs/2306.09308v1",
        "pub_date": "2023-06-15",
        "summary": "The wide applicability and adaptability of generative large language models\n(LLMs) has enabled their rapid adoption. While the pre-trained models can\nperform many tasks, such models are often fine-tuned to improve their\nperformance on various downstream applications. However, this leads to issues\nover violation of model licenses, model theft, and copyright infringement.\nMoreover, recent advances show that generative technology is capable of\nproducing harmful content which exacerbates the problems of accountability\nwithin model supply chains. Thus, we need a method to investigate how a model\nwas trained or a piece of text was generated and what their pre-trained base\nmodel was. In this paper we take the first step to address this open problem by\ntracing back the origin of a given fine-tuned LLM to its corresponding\npre-trained base model. We consider different knowledge levels and attribution\nstrategies, and find that we can correctly trace back 8 out of the 10 fine\ntuned models with our best method.",
        "translated": "生成式大型语言模型(LLM)的广泛适用性和适应性使它们得以迅速采用。虽然预先训练的模型可以执行许多任务，但这些模型通常经过微调，以提高它们在各种下游应用程序中的性能。然而，这导致了违反模型许可证、模型盗窃和盗版的问题。此外，最近的进展表明，生成技术能够产生有害的内容，这加剧了示范供应链中的问责问题。因此，我们需要一种方法来研究如何训练一个模型或一段文本生成，以及他们的预先训练的基础模型是什么。在本文中，我们采取的第一步，以解决这个开放的问题，追溯起源的一个给定的微调 LLM 相应的预训练的基础模型。我们考虑了不同的知识水平和归因策略，发现我们可以用我们最好的方法正确地追溯10个微调模型中的8个。"
    },
    {
        "title": "Quality and Efficiency of Manual Annotation: Pre-annotation Bias",
        "url": "http://arxiv.org/abs/2306.09307v1",
        "pub_date": "2023-06-15",
        "summary": "This paper presents an analysis of annotation using an automatic\npre-annotation for a mid-level annotation complexity task -- dependency syntax\nannotation. It compares the annotation efforts made by annotators using a\npre-annotated version (with a high-accuracy parser) and those made by fully\nmanual annotation. The aim of the experiment is to judge the final annotation\nquality when pre-annotation is used. In addition, it evaluates the effect of\nautomatic linguistically-based (rule-formulated) checks and another annotation\non the same data available to the annotators, and their influence on annotation\nquality and efficiency. The experiment confirmed that the pre-annotation is an\nefficient tool for faster manual syntactic annotation which increases the\nconsistency of the resulting annotation without reducing its quality.",
        "translated": "本文针对一个中级注释复杂性任务——依赖语法注释，提出了一种使用自动预注释的注释分析方法。它比较了使用预注释版本(带有高精度解析器)的注释者所做的注释工作和完全手动注释所做的注释工作。实验的目的是在使用预注释时判断最终的注释质量。此外，它还评估了基于语言的(规则制定的)自动检查和另一个注释对注释者可获得的相同数据的影响，以及它们对注释质量和效率的影响。实验结果表明，预注释是一种提高人工语法注释速度的有效工具，可以在不降低注释质量的前提下提高注释结果的一致性。"
    },
    {
        "title": "Propagating Knowledge Updates to LMs Through Distillation",
        "url": "http://arxiv.org/abs/2306.09306v1",
        "pub_date": "2023-06-15",
        "summary": "Modern language models have the capacity to store and use immense amounts of\nknowledge about real-world entities, but it remains unclear how to update their\nimplicit \"knowledge bases.'' While prior methods for updating knowledge in LMs\nsuccessfully inject facts, updated LMs then fail to make inferences based on\nthese injected facts. In this work, we demonstrate that a context\ndistillation-based approach can both impart knowledge about entities and\npropagate that knowledge to enable broader inferences. Our approach consists of\ntwo stages: transfer set generation and distillation on the transfer set. We\nfirst generate a transfer set by simply prompting a language model to generate\na continuation from the entity definition. Then, we update the model parameters\nso that the distribution of the LM (the student) matches the distribution of\nthe LM conditioned on the definition (the teacher) on the transfer set. Our\nexperiments demonstrate that this approach is more effective in propagating\nknowledge updates compared to fine-tuning and other gradient-based\nknowledge-editing methods without compromising performance in other contexts,\neven when injecting the definitions of up to 150 entities at once.",
        "translated": "现代语言模型有能力存储和使用关于现实世界实体的大量知识，但是如何更新它们隐含的“知识库”仍然不清楚先前更新 LM 知识的方法成功地注入了事实，但是更新后的 LM 无法根据这些注入的事实进行推断。在这项工作中，我们证明了一个基于上下文精馏的方法既可以传递关于实体的知识，又可以传播这些知识，以便能够进行更广泛的推论。我们的方法包括两个阶段: 转移集的产生和转移集上的精馏。我们首先通过简单地提示语言模型从实体定义生成延续来生成传输集。然后，我们更新模型参数，使 LM (学生)的分布与 LM 的分布匹配条件下的定义(教师)在转移集上。我们的实验表明，与微调和其他基于梯度的知识编辑方法相比，这种方法在传播知识更新方面更有效，而不会损害其他情况下的性能，即使一次注入多达150个实体的定义。"
    },
    {
        "title": "Can Language Models Teach Weaker Agents? Teacher Explanations Improve\n  Students via Theory of Mind",
        "url": "http://arxiv.org/abs/2306.09299v1",
        "pub_date": "2023-06-15",
        "summary": "Large Language Models (LLMs) perform complex reasoning by generating\nexplanations for their predictions. However, a complementary goal of\nexplanations is to also communicate useful knowledge that improves weaker\nagents. Hence, we investigate whether LLMs also make good teachers for weaker\nagents. In particular, we consider a student-teacher framework between two LLM\nagents and study if, when, and how the teacher should intervene with natural\nlanguage explanations to improve the student's performance. Since communication\nis expensive, we define a budget such that the teacher only communicates\nexplanations for a fraction of the data, after which the student should perform\nwell on its own. We decompose the teaching problem along four axes: (1) if\nteacher's test time intervention improve student predictions, (2) when it is\nworth explaining a data point, (3) how the teacher should personalize\nexplanations to better teach the student, and (4) if teacher explanations also\nimprove student performance on future unexplained data. We first show that\nteacher LLMs can indeed intervene on student reasoning to improve their\nperformance. Next, we propose a Theory of Mind approach, in which the teacher\nbuilds two few-shot mental models of the student. The first model defines an\nIntervention Function that simulates the utility of an intervention, allowing\nthe teacher to intervene when this utility is the highest and improving student\nperformance at lower budgets. The second model enables the teacher to\npersonalize explanations for a particular student and outperform unpersonalized\nteachers. We also demonstrate that in multi-turn interactions, teacher\nexplanations generalize and learning from explained data improves student\nperformance on future unexplained data. Finally, we also verify that misaligned\nteachers can lower student performance to random chance by intentionally\nmisleading them.",
        "translated": "大型语言模型(LLM)通过生成对其预测的解释来执行复杂的推理。然而，解释的一个补充目标是传达有用的知识，以改善较弱的代理。因此，我们研究 LLM 是否也可以成为弱者的好老师。特别地，我们考虑两个 LLM 代理之间的学生-教师框架，并研究教师是否、何时以及如何应该干预自然语言解释以提高学生的成绩。由于沟通是昂贵的，我们定义一个预算，使教师只传达一小部分数据的解释，在此之后，学生应该自己表现良好。我们将教学问题分解为四个方面: (1)教师的考试时间干预是否改善了学生的预测; (2)什么时候值得解释一个数据点; (3)教师应该如何个性化解释以更好地教育学生; (4)教师的解释是否也改善了学生对未来未解释数据的表现。我们首先证明教师 LLM 确实可以干预学生的推理，以提高他们的表现。接下来，我们提出一种心理理论的方法，在这种方法中，教师建立学生的两个短镜头心理模型。第一个模型定义了一个干预函数，它模拟了干预的效用，允许教师在效用最高时进行干预，并在较低的预算下提高学生的表现。第二种模式使教师能够针对特定学生进行个性化的解释，并胜过非个性化的教师。我们还证明，在多回合互动中，教师的解释概括和学习解释的数据提高了学生在未来的未解释数据的表现。最后，我们还验证了错位教师可以通过故意误导学生来降低学生的随机成绩。"
    },
    {
        "title": "GRM: Generative Relevance Modeling Using Relevance-Aware Sample\n  Estimation for Document Retrieval",
        "url": "http://arxiv.org/abs/2306.09938v1",
        "pub_date": "2023-06-16",
        "summary": "Recent studies show that Generative Relevance Feedback (GRF), using text\ngenerated by Large Language Models (LLMs), can enhance the effectiveness of\nquery expansion. However, LLMs can generate irrelevant information that harms\nretrieval effectiveness. To address this, we propose Generative Relevance\nModeling (GRM) that uses Relevance-Aware Sample Estimation (RASE) for more\naccurate weighting of expansion terms. Specifically, we identify similar real\ndocuments for each generated document and use a neural re-ranker to estimate\ntheir relevance. Experiments on three standard document ranking benchmarks show\nthat GRM improves MAP by 6-9% and R@1k by 2-4%, surpassing previous methods.",
        "translated": "最近的研究表明，使用大语言模型生成的文本的生成关联反馈可以提高查询扩展的有效性。然而，LLM 会产生不相关的信息，从而影响检索效率。为了解决这个问题，我们提出了生成相关性建模(GRM) ，它使用相关性感知的样本估计(RASE)来更准确地给扩展项加权。具体来说，我们为每个生成的文档识别相似的真实文档，并使用神经重新排序来估计它们的相关性。在三个标准文档排序基准上的实验表明，GRM 对 MAP 提高了6-9% ，对 R@1k 提高了2-4% ，超过了以往的排序方法。"
    },
    {
        "title": "Smart Sentiment Analysis-based Search Engine Classification Intelligence",
        "url": "http://arxiv.org/abs/2306.09777v1",
        "pub_date": "2023-06-16",
        "summary": "Search engines are widely used for finding information on the internet.\nHowever, there are limitations in the current search approach, such as\nproviding popular but not necessarily relevant results. This research addresses\nthe issue of polysemy in search results by implementing a search function that\ndetermines the sentimentality of the retrieved information. The study utilizes\na web crawler to collect data from the British Broadcasting Corporation (BBC)\nnews site, and the sentimentality of the news articles is determined using the\nSentistrength program. The results demonstrate that the proposed search\nfunction improves recall value while accurately retrieving nonpolysemous news.\nFurthermore, Sentistrength outperforms deep learning and clustering methods in\nclassifying search results. The methodology presented in this article can be\napplied to analyze the sentimentality and reputation of entities on the\ninternet.",
        "translated": "搜索引擎被广泛用于在互联网上查找信息。然而，目前的搜索方法存在一些局限性，比如提供受欢迎但不一定相关的结果。该研究通过实现一个决定检索信息多情性的搜索函数来解决搜索结果中的多义性问题。该研究利用网络爬虫从英国广播公司(英国广播公司)新闻网站收集数据，新闻文章的多愁善感程度是通过感知力程序确定的。实验结果表明，该搜索函数在准确检索非多义新闻的同时，提高了查全率。此外，感知强度在分类搜索结果方面优于深度学习和聚类方法。本文提出的方法可以用来分析互联网上实体的情感和声誉。"
    },
    {
        "title": "Online Distillation for Pseudo-Relevance Feedback",
        "url": "http://arxiv.org/abs/2306.09657v1",
        "pub_date": "2023-06-16",
        "summary": "Model distillation has emerged as a prominent technique to improve neural\nsearch models. To date, distillation taken an offline approach, wherein a new\nneural model is trained to predict relevance scores between arbitrary queries\nand documents. In this paper, we explore a departure from this offline\ndistillation strategy by investigating whether a model for a specific query can\nbe effectively distilled from neural re-ranking results (i.e., distilling in an\nonline setting). Indeed, we find that a lexical model distilled online can\nreasonably replicate the re-ranking of a neural model. More importantly, these\nmodels can be used as queries that execute efficiently on indexes. This second\nretrieval stage can enrich the pool of documents for re-ranking by identifying\ndocuments that were missed in the first retrieval stage. Empirically, we show\nthat this approach performs favourably when compared with established pseudo\nrelevance feedback techniques, dense retrieval methods, and sparse-dense\nensemble \"hybrid\" approaches.",
        "translated": "模型蒸馏技术已经成为改进神经搜索模型的一个突出技术。迄今为止，蒸馏采用离线方法，其中一个新的神经模型被训练来预测任意查询和文档之间的相关性得分。在本文中，我们通过研究一个特定查询的模型是否可以有效地从神经重新排序结果(即，在线设置中提取)中提取，来探索这种离线精馏策略的一个偏离。事实上，我们发现在线提取的词汇模型可以合理地复制神经模型的重新排序。更重要的是，这些模型可以用作在索引上高效执行的查询。这第二个检索阶段可以通过识别第一个检索阶段错过的文件来丰富重新排序的文件库。经验表明，与已有的伪关联反馈技术、密集检索方法和稀疏密集集合“混合”方法相比，这种方法表现得更好。"
    },
    {
        "title": "I Want This, Not That: Personalized Summarization of Scientific\n  Scholarly Texts",
        "url": "http://arxiv.org/abs/2306.09604v1",
        "pub_date": "2023-06-16",
        "summary": "In this paper, we present a proposal for an unsupervised algorithm, P-Summ,\nthat generates an extractive summary of scientific scholarly text to meet the\npersonal knowledge needs of the user. The method delves into the latent\nsemantic space of the document exposed by Weighted Non-negative Matrix\nFactorization, and scores sentences in consonance with the knowledge needs of\nthe user. The novelty of the algorithm lies in its ability to include desired\nknowledge and eliminate unwanted knowledge in the personal summary.\n  We also propose a multi-granular evaluation framework, which assesses the\nquality of generated personal summaries at three levels of granularity -\nsentence, terms and semantic. The framework uses system generated generic\nsummary instead of human generated summary as gold standard for evaluating the\nquality of personal summary generated by the algorithm. The effectiveness of\nthe algorithm at the semantic level is evaluated by taking into account the\nreference summary and the knowledge signals. We evaluate the performance of\nP-Summ algorithm over four data-sets consisting of scientific articles. Our\nempirical investigations reveal that the proposed method has the capability to\nmeet negative (or positive) knowledge preferences of the user.",
        "translated": "在本文中，我们提出了一个无监督算法，P-Summ，它生成一个提取摘要的科学学术文本，以满足用户的个人知识需求。该方法深入研究文档的潜在语义空间，通过加权非负矩阵分解，并根据用户的知识需求给句子打分。算法的新颖性在于它能够在个人摘要中包含所需的知识并消除不需要的知识。我们还提出了一个多粒度评估框架，该框架从句子、术语和语义三个粒度级别评估生成的个人摘要的质量。该框架采用系统生成的通用摘要代替人工生成的摘要作为评价算法生成的个人摘要质量的黄金标准。通过参考文献总结和知识信号，从语义层面对算法的有效性进行了评价。我们评估了 P-Summ 算法在四个由科学论文组成的数据集上的性能。实证研究表明，该方法能够满足用户的消极(或积极)知识偏好。"
    },
    {
        "title": "Just One Byte (per gradient): A Note on Low-Bandwidth Decentralized\n  Language Model Finetuning Using Shared Randomness",
        "url": "http://arxiv.org/abs/2306.10015v1",
        "pub_date": "2023-06-16",
        "summary": "Language model training in distributed settings is limited by the\ncommunication cost of gradient exchanges. In this short note, we extend recent\nwork from Malladi et al. (2023), using shared randomness to perform distributed\nfine-tuning with low bandwidth. The method is a natural decentralized extension\nof memory-efficient Simultaneous Perturbation Stochastic Approximation (SPSA).\nEach iteration, each machine seeds a Random Number Generator (RNG) to perform\nlocal reproducible perturbations on model weights and calculate and exchange\nscalar projected gradients, which are then used to update each model. By using\na (machine, sample) identifier as the random seed, each model can regenerate\none another's perturbations. As machines only exchange single-byte projected\ngradients, this is highly communication efficient. There are also potential\nprivacy benefits, as projected gradients may be calculated on different\ntraining data, and models never access the other's data. Our approach not only\ndrastically reduces communication bandwidth requirements but also accommodates\ndynamic addition or removal of machines during the training process and retains\nthe memory-efficient and inference-only advantages of recent work. We perform\nproof-of-concept experiments to demonstrate the potential usefulness of this\nmethod, building off of rich literature on distributed optimization and\nmemory-efficient training.",
        "translated": "分布式环境下的语言模型训练受到梯度交换通信成本的限制。在这个简短的说明中，我们扩展了 Malladi 等人(2023)最近的工作，使用共享随机性来执行低带宽的分布式微调。这种方法是记忆效率同步扰动随机逼近(SPSA)的自然分散扩展。每次迭代，每台机器播种一个随机数生成器(RNG) ，对模型权重执行局部可重复的扰动，并计算和交换标量投影梯度，然后用于更新每个模型。通过使用一个(机器，样本)标识符作为随机种子，每个模型可以重新生成彼此的扰动。由于机器只交换单字节投影渐变，这是高通信效率。还有潜在的隐私好处，因为预测的梯度可以在不同的训练数据上计算，而且模型永远不会访问其他人的数据。我们的方法不仅大大降低了通信带宽的要求，而且还可以在训练过程中动态添加或删除机器，并保留了最近工作的内存效率和推理优势。我们进行了概念验证实验，以证明这种方法的潜在有用性，建立在丰富的文献关于分布式优化和记忆效率培训。"
    },
    {
        "title": "MagicBrush: A Manually Annotated Dataset for Instruction-Guided Image\n  Editing",
        "url": "http://arxiv.org/abs/2306.10012v1",
        "pub_date": "2023-06-16",
        "summary": "Text-guided image editing is widely needed in daily life, ranging from\npersonal use to professional applications such as Photoshop. However, existing\nmethods are either zero-shot or trained on an automatically synthesized\ndataset, which contains a high volume of noise. Thus, they still require lots\nof manual tuning to produce desirable outcomes in practice. To address this\nissue, we introduce MagicBrush (https://osu-nlp-group.github.io/MagicBrush/),\nthe first large-scale, manually annotated dataset for instruction-guided real\nimage editing that covers diverse scenarios: single-turn, multi-turn,\nmask-provided, and mask-free editing. MagicBrush comprises over 10K manually\nannotated triples (source image, instruction, target image), which supports\ntrainining large-scale text-guided image editing models. We fine-tune\nInstructPix2Pix on MagicBrush and show that the new model can produce much\nbetter images according to human evaluation. We further conduct extensive\nexperiments to evaluate current image editing baselines from multiple\ndimensions including quantitative, qualitative, and human evaluations. The\nresults reveal the challenging nature of our dataset and the gap between\ncurrent baselines and real-world editing needs.",
        "translated": "从个人使用到 Photoshop 等专业应用，文本引导图像编辑在日常生活中被广泛需要。然而，现有的方法要么是零拍摄，要么是在一个自动合成的数据集上训练，这个数据集包含了大量的噪声。因此，它们仍然需要大量的手动调优，以便在实践中产生理想的结果。为了解决这个问题，我们引入了 MagicBrush ( https://osu-nlp-group.github.io/MagicBrush/) ，这是第一个用于指令引导的真实图像编辑的大规模手动注释数据集，涵盖了不同的场景: 单转、多转、掩码提供和无掩码编辑。MagicBrush 包含超过10K 的手动注释三元组(源图像、指令、目标图像) ，支持训练大规模的文本引导图像编辑模型。我们在 MagicBrush 上对 DirectPix2Pix 进行了微调，结果表明新的模型可以根据人的评价产生更好的图像。我们进一步进行广泛的实验，以评估目前的图像编辑基线从多个维度，包括定量，定性和人类的评价。结果揭示了我们的数据集的挑战性，以及当前基线和现实世界编辑需求之间的差距。"
    },
    {
        "title": "Investigating Prompting Techniques for Zero- and Few-Shot Visual\n  Question Answering",
        "url": "http://arxiv.org/abs/2306.09996v1",
        "pub_date": "2023-06-16",
        "summary": "Visual question answering (VQA) is a challenging task that requires the\nability to comprehend and reason with visual information. While recent\nvision-language models have made strides, they continue to struggle with\nzero-shot VQA, particularly in handling complex compositional questions and\nadapting to new domains i.e. knowledge-based reasoning. This paper explores the\nuse of various prompting strategies, focusing on the BLIP2 model, to enhance\nzero-shot VQA performance. We conduct a comprehensive investigation across\nseveral VQA datasets, examining the effectiveness of different question\ntemplates, the role of few-shot exemplars, the impact of chain-of-thought (CoT)\nreasoning, and the benefits of incorporating image captions as additional\nvisual cues. Despite the varied outcomes, our findings demonstrate that\ncarefully designed question templates and the integration of additional visual\ncues, like image captions, can contribute to improved VQA performance,\nespecially when used in conjunction with few-shot examples. However, we also\nidentify a limitation in the use of chain-of-thought rationalization, which\nnegatively affects VQA accuracy. Our study thus provides critical insights into\nthe potential of prompting for improving zero-shot VQA performance.",
        "translated": "视觉问题回答是一项具有挑战性的任务，需要对视觉信息进行理解和推理。虽然最近的视觉语言模型已经取得了长足的进步，但是它们仍然在与零射击 VQA 作斗争，特别是在处理复杂的组合问题和适应新的领域，即基于知识的推理方面。本文探讨了各种激励策略的使用，重点是 BLIP2模型，以提高零拍 VQA 的性能。我们对几个 VQA 数据集进行了全面的调查，检查了不同问题模板的有效性，少拍范例的作用，思维链(CoT)推理的影响，以及将图像标题作为额外的视觉线索的好处。尽管结果各不相同，但我们的研究结果表明，精心设计的问题模板和整合额外的视觉线索，如图像标题，可以有助于改善 VQA 的性能，特别是当与少数镜头的例子一起使用时。然而，我们也发现了思维链合理化使用的局限性，这对 VQA 的准确性产生了负面影响。因此，我们的研究提供了关键的见解，促进提高零拍 VQA 性能的潜力。"
    },
    {
        "title": "ClinicalGPT: Large Language Models Finetuned with Diverse Medical Data\n  and Comprehensive Evaluation",
        "url": "http://arxiv.org/abs/2306.09968v1",
        "pub_date": "2023-06-16",
        "summary": "Large language models have exhibited exceptional performance on various\nNatural Language Processing (NLP) tasks, leveraging techniques such as the\npre-training, and instruction fine-tuning. Despite these advances, their\neffectiveness in medical applications is limited, due to challenges such as\nfactual inaccuracies, reasoning abilities, and lack grounding in real-world\nexperience. In this study, we present ClinicalGPT, a language model explicitly\ndesigned and optimized for clinical scenarios. By incorporating extensive and\ndiverse real-world data, such as medical records, domain-specific knowledge,\nand multi-round dialogue consultations in the training process, ClinicalGPT is\nbetter prepared to handle multiple clinical task. Furthermore, we introduce a\ncomprehensive evaluation framework that includes medical knowledge\nquestion-answering, medical exams, patient consultations, and diagnostic\nanalysis of medical records. Our results demonstrate that ClinicalGPT\nsignificantly outperforms other models in these tasks, highlighting the\neffectiveness of our approach in adapting large language models to the critical\ndomain of healthcare.",
        "translated": "大型语言模型在各种自然语言处理(NLP)任务中表现出了卓越的性能，利用了预训练和指令微调等技术。尽管取得了这些进展，但由于事实不准确、推理能力差以及缺乏现实世界经验的基础等挑战，它们在医学应用中的有效性是有限的。在这项研究中，我们提出了 ClinicalGPT，一个明确设计和优化的语言模型临床情景。通过在培训过程中结合广泛和多样的现实世界数据，如医疗记录，特定领域的知识和多轮对话咨询，ClinicalGPT 更好地准备处理多个临床任务。此外，我们介绍了一个全面的评估框架，包括医学知识问答，医疗检查，病人会诊，和病历诊断分析。我们的研究结果表明 ClinicalGPT 在这些任务中显著优于其他模型，突出了我们的方法在调整大型语言模型以适应医疗保健的关键领域方面的有效性。"
    },
    {
        "title": "Trained Transformers Learn Linear Models In-Context",
        "url": "http://arxiv.org/abs/2306.09927v1",
        "pub_date": "2023-06-16",
        "summary": "Attention-based neural networks such as transformers have demonstrated a\nremarkable ability to exhibit in-context learning (ICL): Given a short prompt\nsequence of tokens from an unseen task, they can formulate relevant per-token\nand next-token predictions without any parameter updates. By embedding a\nsequence of labeled training data and unlabeled test data as a prompt, this\nallows for transformers to behave like supervised learning algorithms. Indeed,\nrecent work has shown that when training transformer architectures over random\ninstances of linear regression problems, these models' predictions mimic those\nof ordinary least squares.\n  Towards understanding the mechanisms underlying this phenomenon, we\ninvestigate the dynamics of ICL in transformers with a single linear\nself-attention layer trained by gradient flow on linear regression tasks. We\nshow that despite non-convexity, gradient flow with a suitable random\ninitialization finds a global minimum of the objective function. At this global\nminimum, when given a test prompt of labeled examples from a new prediction\ntask, the transformer achieves prediction error competitive with the best\nlinear predictor over the test prompt distribution. We additionally\ncharacterize the robustness of the trained transformer to a variety of\ndistribution shifts and show that although a number of shifts are tolerated,\nshifts in the covariate distribution of the prompts are not. Motivated by this,\nwe consider a generalized ICL setting where the covariate distributions can\nvary across prompts. We show that although gradient flow succeeds at finding a\nglobal minimum in this setting, the trained transformer is still brittle under\nmild covariate shifts.",
        "translated": "基于注意力的神经网络，如变压器，已经证明了显着的能力，表现在上下文学习(ICL) : 给定一个短暂的令牌序列从一个看不见的任务，他们可以制定相关的每个令牌和下一个令牌预测没有任何参数更新。通过嵌入一系列已标记的训练数据和未标记的测试数据作为提示，这允许变压器像监督式学习算法一样运行。事实上，最近的工作已经表明，当训练变压器架构在随机情况下的线性回归问题，这些模型的预测模拟那些一般最小平方法。为了理解这种现象的机制，我们研究了变压器中的 ICL 的动力学，这种变压器具有一个单一的线性自我注意层，通过梯度流对线性回归任务进行训练。结果表明，尽管存在非凸性，但梯度流在适当的随机初始化条件下仍能找到目标函数的全局最小值。在这个全局最小值下，当从一个新的预测任务中给出一个标记样本的测试提示时，变压器在测试提示分布上达到与最佳线性预测器竞争的预测误差。另外，我们描述了训练后的变压器对各种分布移位的鲁棒性，并且表明，虽然许多移位是可以容忍的，但是提示符的协变量分布的移位是不可以容忍的。基于此，我们考虑一个广义的 ICL 设置，其中协变量分布可以随提示而变化。我们表明，虽然梯度流成功地找到一个全局最小在这种设置，训练变压器仍然脆弱的轻度协变量移动。"
    },
    {
        "title": "Learning to Summarize and Answer Questions about a Virtual Robot's Past\n  Actions",
        "url": "http://arxiv.org/abs/2306.09922v1",
        "pub_date": "2023-06-16",
        "summary": "When robots perform long action sequences, users will want to easily and\nreliably find out what they have done. We therefore demonstrate the task of\nlearning to summarize and answer questions about a robot agent's past actions\nusing natural language alone. A single system with a large language model at\nits core is trained to both summarize and answer questions about action\nsequences given ego-centric video frames of a virtual robot and a question\nprompt. To enable training of question answering, we develop a method to\nautomatically generate English-language questions and answers about objects,\nactions, and the temporal order in which actions occurred during episodes of\nrobot action in the virtual environment. Training one model to both summarize\nand answer questions enables zero-shot transfer of representations of objects\nlearned through question answering to improved action summarization. %\ninvolving objects not seen in training to summarize.",
        "translated": "当机器人执行长动作序列时，用户将希望轻松可靠地找出他们做了什么。因此，我们演示的任务，学习总结和回答有关机器人代理人的过去的行动使用自然语言单独的问题。通过训练一个以大语言模型为核心的单一系统，在给定虚拟机器人以自我为中心的视频框架和问题提示的情况下，总结和回答关于动作序列的问题。为了实现问题回答的训练，我们开发了一种自动生成英语问答的方法，这些问答包括对象、动作以及虚拟环境中机器人动作过程中动作发生的时间顺序。训练一个同时总结和回答问题的模型可以使通过问题回答学到的对象的表示零拍转移到改进的动作总结。涉及培训中未见到的对象的百分比。"
    },
    {
        "title": "No Strong Feelings One Way or Another: Re-operationalizing Neutrality in\n  Natural Language Inference",
        "url": "http://arxiv.org/abs/2306.09918v1",
        "pub_date": "2023-06-16",
        "summary": "Natural Language Inference (NLI) has been a cornerstone task in evaluating\nlanguage models' inferential reasoning capabilities. However, the standard\nthree-way classification scheme used in NLI has well-known shortcomings in\nevaluating models' ability to capture the nuances of natural human reasoning.\nIn this paper, we argue that the operationalization of the neutral label in\ncurrent NLI datasets has low validity, is interpreted inconsistently, and that\nat least one important sense of neutrality is often ignored. We uncover the\ndetrimental impact of these shortcomings, which in some cases leads to\nannotation datasets that actually decrease performance on downstream tasks. We\ncompare approaches of handling annotator disagreement and identify flaws in a\nrecent NLI dataset that designs an annotator study based on a problematic\noperationalization. Our findings highlight the need for a more refined\nevaluation framework for NLI, and we hope to spark further discussion and\naction in the NLP community.",
        "translated": "自然语言推理(NLI)是评价语言模型推理能力的基础性工作。然而，在自然语言学习中使用的标准三向分类方案在评估模型捕捉人类自然推理细微差别的能力方面有着众所周知的缺陷。在本文中，我们认为在现有的 NLI 数据集中，中性标签的操作主义效度低，解释不一致，并且至少有一个重要的中性意义经常被忽略。我们发现了这些缺陷的有害影响，在某些情况下，这导致注释数据集实际上降低了下游任务的性能。我们比较了处理注释者不一致的方法，并在最近的一个基于有问题的操作主义设计注释者研究的 NLI 数据集中发现了缺陷。我们的研究结果强调了对 NLI 进一步完善评估框架的必要性，我们希望在 NLP 社区中引发进一步的讨论和行动。"
    },
    {
        "title": "Demystifying GPT Self-Repair for Code Generation",
        "url": "http://arxiv.org/abs/2306.09896v1",
        "pub_date": "2023-06-16",
        "summary": "Large Language Models (LLMs) have shown remarkable aptitude in code\ngeneration but still struggle on challenging programming tasks. Self-repair --\nin which the model debugs and fixes mistakes in its own code -- has recently\nbecome a popular way to boost performance in these settings. However, only very\nlimited studies on how and when self-repair works effectively exist in the\nliterature, and one might wonder to what extent a model is really capable of\nproviding accurate feedback on why the code is wrong when that code was\ngenerated by the same model. In this paper, we analyze GPT-3.5 and GPT-4's\nability to perform self-repair on APPS, a challenging dataset consisting of\ndiverse coding challenges. To do so, we first establish a new evaluation\nstrategy dubbed pass@t that measures the pass rate of the tasks against the\ntotal number of tokens sampled from the model, enabling a fair comparison to\npurely sampling-based approaches. With this evaluation strategy, we find that\nthe effectiveness of self-repair is only seen in GPT-4. We also observe that\nself-repair is bottlenecked by the feedback stage; using GPT-4 to give feedback\non the programs generated by GPT-3.5 and using expert human programmers to give\nfeedback on the programs generated by GPT-4, we unlock significant performance\ngains.",
        "translated": "大型语言模型(LLM)在代码生成方面显示出了非凡的才能，但是在具有挑战性的编程任务方面仍然举步维艰。自我修复(模型调试并修复自己代码中的错误)最近已经成为提高这些设置中性能的一种流行方式。然而，文献中关于自我修复如何以及何时起作用的研究非常有限，人们可能想知道，当代码由同一个模型生成时，一个模型究竟能在多大程度上提供准确的反馈，说明为什么代码是错误的。在本文中，我们分析了 GPT-3.5和 GPT-4对 APPS 进行自我修复的能力，APPS 是一个具有挑战性的数据集，由多种编码挑战组成。为此，我们首先建立一个称为 pass@t 的新评估策略，该策略根据从模型中抽样的令牌总数来度量任务的通过率，从而能够与纯粹基于抽样的方法进行公平的比较。通过这种评估策略，我们发现自我修复的有效性仅见于 GPT-4。我们还观察到自我修复受到反馈阶段的瓶颈; 使用 GPT-4对由 GPT-3.5生成的程序提供反馈，并使用专业的人类程序员对由 GPT-4生成的程序提供反馈，我们获得了显着的性能收益。"
    },
    {
        "title": "Revealing the impact of social circumstances on the selection of cancer\n  therapy through natural language processing of social work notes",
        "url": "http://arxiv.org/abs/2306.09877v1",
        "pub_date": "2023-06-16",
        "summary": "We aimed to investigate the impact of social circumstances on cancer therapy\nselection using natural language processing to derive insights from social\nworker documentation. We developed and employed a Bidirectional Encoder\nRepresentations from Transformers (BERT) based approach, using a hierarchical\nmulti-step BERT model (BERT-MS) to predict the prescription of targeted cancer\ntherapy to patients based solely on documentation by clinical social workers.\nOur corpus included free-text clinical social work notes, combined with\nmedication prescription information, for all patients treated for breast\ncancer. We conducted a feature importance analysis to pinpoint the specific\nsocial circumstances that impact cancer therapy selection. Using only social\nwork notes, we consistently predicted the administration of targeted therapies,\nsuggesting systematic differences in treatment selection exist due to\nnon-clinical factors. The UCSF-BERT model, pretrained on clinical text at UCSF,\noutperformed other publicly available language models with an AUROC of 0.675\nand a Macro F1 score of 0.599. The UCSF BERT-MS model, capable of leveraging\nmultiple pieces of notes, surpassed the UCSF-BERT model in both AUROC and\nMacro-F1. Our feature importance analysis identified several clinically\nintuitive social determinants of health (SDOH) that potentially contribute to\ndisparities in treatment. Our findings indicate that significant disparities\nexist among breast cancer patients receiving different types of therapies based\non social determinants of health. Social work reports play a crucial role in\nunderstanding these disparities in clinical decision-making.",
        "translated": "我们的目的是调查社会环境对癌症治疗选择的影响，使用自然语言处理，从社会工作者的文件中获得见解。我们开发并使用了基于变压器的双向编码器表示(BERT)方法，使用分层多步 BERT 模型(BERT-MS)来预测仅基于临床社会工作者的文档的针对患者的癌症治疗处方。我们的语料库包括自由文本临床社会工作笔记，结合药物处方信息，为所有患者治疗乳腺癌。我们进行了特征重要性分析，以确定影响癌症治疗选择的特定社会环境。仅使用社会工作笔记，我们始终预测靶向治疗的管理，表明治疗选择存在系统性差异，由于非临床因素。UCSF-BERT 模型在 UCSF 的临床文本上进行了预训练，其表现优于其他公开可用的语言模型，AUROC 为0.675，Macro F1评分为0.599。UCSF BERT-MS 模型能够利用多种音符，在 AUROC 和 Macro-F1中都超过了 UCSF BERT 模型。我们的特征重要性分析确定了几个临床直观的健康社会决定因素(SDOH) ，可能有助于差异的治疗。我们的研究结果表明，根据健康的社会决定因素，接受不同类型治疗的乳腺癌患者之间存在显著差异。社会工作报告在了解临床决策中的这些差异方面发挥着至关重要的作用。"
    },
    {
        "title": "Energy-Based Cross Attention for Bayesian Context Update in\n  Text-to-Image Diffusion Models",
        "url": "http://arxiv.org/abs/2306.09869v1",
        "pub_date": "2023-06-16",
        "summary": "Despite the remarkable performance of text-to-image diffusion models in image\ngeneration tasks, recent studies have raised the issue that generated images\nsometimes cannot capture the intended semantic contents of the text prompts,\nwhich phenomenon is often called semantic misalignment. To address this, here\nwe present a novel energy-based model (EBM) framework. Specifically, we first\nformulate EBMs of latent image representations and text embeddings in each\ncross-attention layer of the denoising autoencoder. Then, we obtain the\ngradient of the log posterior of context vectors, which can be updated and\ntransferred to the subsequent cross-attention layer, thereby implicitly\nminimizing a nested hierarchy of energy functions. Our latent EBMs further\nallow zero-shot compositional generation as a linear combination of\ncross-attention outputs from different contexts. Using extensive experiments,\nwe demonstrate that the proposed method is highly effective in handling various\nimage generation tasks, including multi-concept generation, text-guided image\ninpainting, and real and synthetic image editing.",
        "translated": "尽管文本-图像扩散模型在图像生成任务中表现突出，但近年来的研究提出了生成的图像有时不能捕捉到文本提示语的预期语义内容的问题，这种现象通常被称为语义错位。为了解决这个问题，我们提出了一个新的基于能量的模型(EBM)框架。具体地说，我们首先在去噪自动编码器的每个交叉注意层中建立潜在图像表示和文本嵌入的循证医学模型。然后，我们得到上下文向量的对数后验梯度，它可以被更新和转移到后续的交叉注意层，从而隐式地最小化嵌套的能量函数层次结构。我们的潜在的循证医学进一步允许零拍摄成分生成作为交叉注意输出的线性组合从不同的情境。通过大量的实验证明，该方法能够有效地处理多种图像生成任务，包括多概念生成、文本引导的图像修补以及真实和合成的图像编辑。"
    },
    {
        "title": "Visual Analysis of Large Multi-Field AMR Data on GPUs Using Interactive\n  Volume Lines",
        "url": "http://arxiv.org/abs/2306.11612v1",
        "pub_date": "2023-06-20",
        "summary": "To visually compare ensembles of volumes, dynamic volume lines (DVLs)\nrepresent each ensemble member as a 1D polyline. To compute these, the volume\ncells are sorted on a space-filling curve and scaled by the ensemble's local\nvariation. The resulting 1D plot can augment or serve as an alternative to a 3D\nvolume visualization free of visual clutter and occlusion. Interactively\ncomputing DVLs is challenging when the data is large, and the volume grid is\nnot structured/regular, as is often the case with computational fluid dynamics\nsimulations. We extend DVLs to support large-scale, multi-field adaptive mesh\nrefinement (AMR) data that can be explored interactively. Our GPU-based system\nupdates the DVL representation whenever the data or the alpha transfer function\nchanges. We demonstrate and evaluate our interactive prototype using large AMR\nvolumes from astrophysics simulations.",
        "translated": "为了可视化地比较体积的集合，动态体积线(DVL)将每个集合成员表示为一维折线。为了计算这些，体积单元按照皮亚诺曲线进行排序，并按照集合的局部变化进行缩放。由此产生的一维图可以增强或作为一个替代的三维体可视化免费的视觉杂乱和遮挡。当数据量很大时，交互式计算 DVL 是一个挑战，而且体积网格不是结构化/规则化的，就像计算流体力学模拟中经常出现的情况一样。我们扩展 DVL，以支持大规模，多领域的自适应网格细化(AMR)数据，可以互动探索。我们基于 GPU 的系统在数据或 alpha 传输函数发生变化时更新 DVL 表示。我们演示和评估我们的交互式原型使用天体物理学模拟的大量 AMR 卷。"
    },
    {
        "title": "Mining Interest Trends and Adaptively Assigning SampleWeight for\n  Session-based Recommendation",
        "url": "http://arxiv.org/abs/2306.11610v1",
        "pub_date": "2023-06-20",
        "summary": "Session-based Recommendation (SR) aims to predict users' next click based on\ntheir behavior within a short period, which is crucial for online platforms.\nHowever, most existing SR methods somewhat ignore the fact that user preference\nis not necessarily strongly related to the order of interactions. Moreover,\nthey ignore the differences in importance between different samples, which\nlimits the model-fitting performance. To tackle these issues, we put forward\nthe method, Mining Interest Trends and Adaptively Assigning Sample Weight,\nabbreviated as MTAW. Specifically, we model users' instant interest based on\ntheir present behavior and all their previous behaviors. Meanwhile, we\ndiscriminatively integrate instant interests to capture the changing trend of\nuser interest to make more personalized recommendations. Furthermore, we devise\na novel loss function that dynamically weights the samples according to their\nprediction difficulty in the current epoch. Extensive experimental results on\ntwo benchmark datasets demonstrate the effectiveness and superiority of our\nmethod.",
        "translated": "基于会话的推荐(SR)旨在根据用户的行为在短时间内预测用户的下一次点击，这对在线平台至关重要。然而，大多数现有的 SR 方法都忽略了一个事实，即用户偏好并不一定与交互顺序密切相关。此外，他们忽略了不同样本之间的重要性差异，这限制了模型拟合的性能。为了解决这些问题，我们提出了挖掘兴趣趋势和自适应分配样本权重的方法，简称 MTAW。具体来说，我们根据用户当前的行为和他们以前的所有行为来建立用户的即时兴趣模型。同时，我们有选择性地整合即时兴趣，捕捉用户兴趣的变化趋势，提出更加个性化的推荐。此外，我们设计了一个新的损失函数，动态权重的样本根据他们的预测困难在当前的纪元。在两个基准数据集上的大量实验结果表明了该方法的有效性和优越性。"
    },
    {
        "title": "Polytope: An Algorithm for Efficient Feature Extraction on Hypercubes",
        "url": "http://arxiv.org/abs/2306.11553v1",
        "pub_date": "2023-06-20",
        "summary": "Data extraction algorithms on data hypercubes, or datacubes, are\ntraditionally only capable of cutting boxes of data along the datacube axes.\nFor many use cases however, this is not a sufficient approach and returns more\ndata than users might actually need. This not only forces users to apply\npost-processing after extraction, but more importantly this consumes more I/O\nresources than is necessary. When considering very large datacubes from which\nusers only want to extract small non-rectangular subsets, the box approach does\nnot scale well. Indeed, with this traditional approach, I/O systems quickly\nreach capacity, trying to read and return unwanted data to users. In this\npaper, we propose a novel technique, based on computational geometry concepts,\nwhich instead carefully pre-selects the precise bytes of data which the user\nneeds in order to then only read those from the datacube. As we discuss later\non, this novel extraction method will considerably help scale access to large\npetabyte size data hypercubes in a variety of scientific fields.",
        "translated": "数据超立方体(或数据立方体)上的数据提取算法传统上只能沿着数据立方体轴切割数据框。然而，对于许多用例来说，这不是一种充分的方法，并且返回的数据超过了用户实际需要的数据。这不仅迫使用户在提取之后进行后处理，而且更重要的是，这会消耗比必需的更多的 I/O 资源。当考虑用户只想从中提取小的非矩形子集的非常大的数据立方体时，盒方法不能很好地伸缩。实际上，使用这种传统方法，I/O 系统可以快速达到容量，尝试读取并向用户返回不需要的数据。在本文中，我们提出了一种基于计算几何概念的新技术，它仔细地预先选择用户需要的精确字节数据，然后只从数据立方中读取这些数据。正如我们稍后讨论的，这种新颖的提取方法将大大有助于在各种科学领域对大型 PB 大小的数据超立方体进行扩展访问。"
    },
    {
        "title": "Generative Retrieval as Dense Retrieval",
        "url": "http://arxiv.org/abs/2306.11397v1",
        "pub_date": "2023-06-20",
        "summary": "Generative retrieval is a promising new neural retrieval paradigm that aims\nto optimize the retrieval pipeline by performing both indexing and retrieval\nwith a single transformer model. However, this new paradigm faces challenges\nwith updating the index and scaling to large collections. In this paper, we\nanalyze two prominent variants of generative retrieval and show that they can\nbe conceptually viewed as bi-encoders for dense retrieval. Specifically, we\nanalytically demonstrate that the generative retrieval process can be\ndecomposed into dot products between query and document vectors, similar to\ndense retrieval. This analysis leads us to propose a new variant of generative\nretrieval, called Tied-Atomic, which addresses the updating and scaling issues\nby incorporating techniques from dense retrieval. In experiments on two\ndatasets, NQ320k and the full MSMARCO, we confirm that this approach does not\nreduce retrieval effectiveness while enabling the model to scale to large\ncollections.",
        "translated": "生成检索是一种新兴的神经元检索方法，其目的是通过使用单个变换器模型对检索流水线进行索引和检索的优化。但是，这种新范例在更新索引和扩展到大型集合方面面临挑战。在本文中，我们分析了两个突出的变体生成检索，并表明它们可以被概念上看作是密集检索的双编码器。具体来说，我们分析表明，生成检索过程可以分解成点乘之间的查询和文档向量，类似于密集检索。这种分析促使我们提出了一种新的生成检索方法，称为 Tied-Atomic，它通过结合密集检索技术来解决更新和缩放问题。在对两个数据集(NQ320k 和 MSMARCO)的实验中，我们证实了这种方法不会降低检索效率，同时使模型能够扩展到大型数据集。"
    },
    {
        "title": "CAPRI: Context-Aware Interpretable Point-of-Interest Recommendation\n  Framework",
        "url": "http://arxiv.org/abs/2306.11395v1",
        "pub_date": "2023-06-20",
        "summary": "Point-of-Interest (POI ) recommendation systems have gained popularity for\ntheir unique ability to suggest geographical destinations with the\nincorporation of contextual information such as time, location, and user-item\ninteraction. Existing recommendation frameworks lack the contextual fusion\nrequired for POI systems. This paper presents CAPRI, a novel POI recommendation\nframework that effectively integrates context-aware models, such as GeoSoCa,\nLORE, and USG, and introduces a novel strategy for the efficient merging of\ncontextual information. CAPRI integrates an evaluation module that expands the\nevaluation scope beyond accuracy to include novelty, personalization,\ndiversity, and fairness. With an aim to establish a new industry standard for\nreproducible results in the realm of POI recommendation systems, we have made\nCAPRI openly accessible on GitHub, facilitating easy access and contribution to\nthe continued development and refinement of this innovative framework.",
        "translated": "兴趣点(POI)推荐系统由于其独特的推荐地理目的地的能力而受到欢迎，这种推荐系统结合了上下文信息，如时间、地点和用户项目交互。现有的建议框架缺乏 POI 系统所需的上下文融合。本文提出了一个新的 POI 推荐框架 CAPRI，它有效地集成了上下文感知模型，如 GeoSoCa、 LORE 和 USG，并介绍了一种有效合并上下文信息的新策略。CAPRI 整合了一个评估模块，扩大了评估范围，超越了准确性，包括新颖性，个性化，多样性和公平性。为了在 POI 推荐系统领域建立可重复性成果的新行业标准，我们使得 CAPRI 能够在 GitHub 上公开访问，便于访问并促进这一创新框架的持续发展和完善。"
    },
    {
        "title": "Lingua Manga: A Generic Large Language Model Centric System for Data\n  Curation",
        "url": "http://arxiv.org/abs/2306.11702v1",
        "pub_date": "2023-06-20",
        "summary": "Data curation is a wide-ranging area which contains many critical but\ntime-consuming data processing tasks. However, the diversity of such tasks\nmakes it challenging to develop a general-purpose data curation system. To\naddress this issue, we present Lingua Manga, a user-friendly and versatile\nsystem that utilizes pre-trained large language models. Lingua Manga offers\nautomatic optimization for achieving high performance and label efficiency\nwhile facilitating flexible and rapid development. Through three example\napplications with distinct objectives and users of varying levels of technical\nproficiency, we demonstrate that Lingua Manga can effectively assist both\nskilled programmers and low-code or even no-code users in addressing data\ncuration challenges.",
        "translated": "数据管理是一个涉及面很广的领域，其中包含许多关键但耗时的数据处理任务。然而，这些任务的多样性使得开发一个通用的数据管理系统具有挑战性。为了解决这个问题，我们提出了通用语言漫画，一个用户友好和通用的系统，利用预先训练的大型语言模型。通用漫画提供了自动优化，以实现高性能和标签效率，同时促进灵活和快速的开发。通过三个具有不同目标和不同技术熟练程度的用户的示例应用程序，我们证明了 Langua Manga 可以有效地帮助熟练的程序员和低代码甚至无代码用户解决数据管理方面的挑战。"
    },
    {
        "title": "DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT\n  Models",
        "url": "http://arxiv.org/abs/2306.11698v1",
        "pub_date": "2023-06-20",
        "summary": "Generative Pre-trained Transformer (GPT) models have exhibited exciting\nprogress in capabilities, capturing the interest of practitioners and the\npublic alike. Yet, while the literature on the trustworthiness of GPT models\nremains limited, practitioners have proposed employing capable GPT models for\nsensitive applications to healthcare and finance - where mistakes can be\ncostly. To this end, this work proposes a comprehensive trustworthiness\nevaluation for large language models with a focus on GPT-4 and GPT-3.5,\nconsidering diverse perspectives - including toxicity, stereotype bias,\nadversarial robustness, out-of-distribution robustness, robustness on\nadversarial demonstrations, privacy, machine ethics, and fairness. Based on our\nevaluations, we discover previously unpublished vulnerabilities to\ntrustworthiness threats. For instance, we find that GPT models can be easily\nmisled to generate toxic and biased outputs and leak private information in\nboth training data and conversation history. We also find that although GPT-4\nis usually more trustworthy than GPT-3.5 on standard benchmarks, GPT-4 is more\nvulnerable given jailbreaking system or user prompts, potentially due to the\nreason that GPT-4 follows the (misleading) instructions more precisely. Our\nwork illustrates a comprehensive trustworthiness evaluation of GPT models and\nsheds light on the trustworthiness gaps. Our benchmark is publicly available at\nhttps://decodingtrust.github.io/.",
        "translated": "生成式预训练变压器(GPT)模型在性能方面展示了令人兴奋的进步，吸引了从业者和公众的兴趣。然而，尽管关于 GPT 模型可信度的文献仍然有限，但从业人员已经提议，在医疗和金融领域的敏感应用中使用有能力的 GPT 模型——在这些领域，错误可能代价高昂。为此，这项工作提出了一个全面的大型语言模型的可信性评估，重点是 GPT-4和 GPT-3.5，考虑到不同的观点-包括毒性，刻板印象偏差，对抗性鲁棒性，分布外鲁棒性，对抗性示范的鲁棒性，隐私，机器伦理和公平。根据我们的评估，我们发现了以前未公布的可信度威胁的漏洞。例如，我们发现 GPT 模型很容易被误导，从而产生有毒和有偏见的输出，并在训练数据和对话历史中泄露私人信息。我们还发现，尽管 GPT-4在标准基准上通常比 GPT-3.5更值得信赖，但是在破解系统或用户提示下，GPT-4更容易受到攻击，这可能是由于 GPT-4更精确地遵循(误导性的)指令的原因。我们的工作阐述了 GPT 模型的全面可信性评估，并揭示了可信性差距。我们的基准 https://decodingtrust.github.io/已公开发售。"
    },
    {
        "title": "A Simple and Effective Pruning Approach for Large Language Models",
        "url": "http://arxiv.org/abs/2306.11695v1",
        "pub_date": "2023-06-20",
        "summary": "As their size increases, Large Languages Models (LLMs) are natural candidates\nfor network pruning methods: approaches that drop a subset of network weights\nwhile striving to preserve performance. Existing methods, however, require\neither retraining, which is rarely affordable for billion-scale LLMs, or\nsolving a weight reconstruction problem reliant on second-order information,\nwhich may also be computationally expensive. In this paper, we introduce a\nnovel, straightforward yet effective pruning method, termed Wanda (Pruning by\nWeights and activations), designed to induce sparsity in pretrained LLMs.\nMotivated by the recent observation of emergent large magnitude features in\nLLMs, our approach prune weights with the smallest magnitudes multiplied by the\ncorresponding input activations, on a per-output basis. Notably, Wanda requires\nno retraining or weight update, and the pruned LLM can be used as is. We\nconduct a thorough evaluation of our method on LLaMA across various language\nbenchmarks. Wanda significantly outperforms the established baseline of\nmagnitude pruning and competes favorably against recent methods involving\nintensive weight update. Code is available at\nhttps://github.com/locuslab/wanda.",
        "translated": "随着规模的增加，大型语言模型(LLM)自然成为网络裁剪方法的候选者: 这种方法在努力保持性能的同时减少了网络权重的子集。然而，现有的方法要么需要再培训(这对于十亿级的 LLM 来说是很难负担得起的) ，要么需要解决依赖于二阶信息的重构问题(这也可能是计算昂贵的)。在本文中，我们介绍了一种新颖的，直接而有效的修剪方法，称为万达(修剪的权重和激活) ，旨在诱导稀疏的预训练 LLM。受最近对 LLM 中出现的大幅度特征的观察的启发，我们的方法以每个输出为基础，用最小幅度的权重乘以相应的输入激活。值得注意的是，万达不需要再培训或体重更新，修剪后的 LLM 可以按原样使用。我们在不同的语言基准上对我们的 LLaMA 方法进行了全面的评估。万达明显优于既定的基准量修剪和竞争优势最近的方法涉及密集的体重更新。密码可于 https://github.com/locuslab/wanda 索取。"
    },
    {
        "title": "Harnessing the Power of Adversarial Prompting and Large Language Models\n  for Robust Hypothesis Generation in Astronomy",
        "url": "http://arxiv.org/abs/2306.11648v1",
        "pub_date": "2023-06-20",
        "summary": "This study investigates the application of Large Language Models (LLMs),\nspecifically GPT-4, within Astronomy. We employ in-context prompting, supplying\nthe model with up to 1000 papers from the NASA Astrophysics Data System, to\nexplore the extent to which performance can be improved by immersing the model\nin domain-specific literature. Our findings point towards a substantial boost\nin hypothesis generation when using in-context prompting, a benefit that is\nfurther accentuated by adversarial prompting. We illustrate how adversarial\nprompting empowers GPT-4 to extract essential details from a vast knowledge\nbase to produce meaningful hypotheses, signaling an innovative step towards\nemploying LLMs for scientific research in Astronomy.",
        "translated": "这项研究调查了大语言模型(LLM) ，特别是 GPT-4在天文学中的应用。我们采用了上下文提示的方式，向模型提供了多达1000篇来自美国宇航局天体物理数据系统的论文，以探索通过将模型沉浸在特定领域的文献中，可以在多大程度上提高性能。我们的研究结果表明，在使用上下文激励时，假设生成能力大大提高，而对抗性激励则进一步强调了这一点。我们举例说明对抗性的提示如何使 GPT-4能够从庞大的知识库中提取基本细节，从而产生有意义的假设，标志着在天文学科学研究中使用 LLM 的创新步骤。"
    },
    {
        "title": "Recent Advances in Direct Speech-to-text Translation",
        "url": "http://arxiv.org/abs/2306.11646v1",
        "pub_date": "2023-06-20",
        "summary": "Recently, speech-to-text translation has attracted more and more attention\nand many studies have emerged rapidly. In this paper, we present a\ncomprehensive survey on direct speech translation aiming to summarize the\ncurrent state-of-the-art techniques. First, we categorize the existing research\nwork into three directions based on the main challenges -- modeling burden,\ndata scarcity, and application issues. To tackle the problem of modeling\nburden, two main structures have been proposed, encoder-decoder framework\n(Transformer and the variants) and multitask frameworks. For the challenge of\ndata scarcity, recent work resorts to many sophisticated techniques, such as\ndata augmentation, pre-training, knowledge distillation, and multilingual\nmodeling. We analyze and summarize the application issues, which include\nreal-time, segmentation, named entity, gender bias, and code-switching.\nFinally, we discuss some promising directions for future work.",
        "translated": "近年来，语音翻译越来越受到人们的关注，许多研究也迅速兴起。本文对直接言语翻译进行了全面的综述，旨在总结目前的最新技术。首先，基于主要挑战——建模负担、数据稀缺性和应用问题，我们将现有的研究工作分为三个方向。为了解决建模负担问题，提出了两种主要的结构: 编解码框架和多任务框架。面对数据稀缺的挑战，最近的工作采用了许多复杂的技术，如数据增强、预训练、知识提取和多语言建模。我们分析和总结了这些应用问题，包括实时性、分割、命名实体、性别偏见和语码转换。最后，讨论了今后工作的一些有希望的方向。"
    },
    {
        "title": "Textbooks Are All You Need",
        "url": "http://arxiv.org/abs/2306.11644v1",
        "pub_date": "2023-06-20",
        "summary": "We introduce phi-1, a new large language model for code, with significantly\nsmaller size than competing models: phi-1 is a Transformer-based model with\n1.3B parameters, trained for 4 days on 8 A100s, using a selection of ``textbook\nquality\" data from the web (6B tokens) and synthetically generated textbooks\nand exercises with GPT-3.5 (1B tokens). Despite this small scale, phi-1 attains\npass@1 accuracy 50.6% on HumanEval and 55.5% on MBPP. It also displays\nsurprising emergent properties compared to phi-1-base, our model before our\nfinetuning stage on a dataset of coding exercises, and phi-1-small, a smaller\nmodel with 350M parameters trained with the same pipeline as phi-1 that still\nachieves 45% on HumanEval.",
        "translated": "我们介绍了 phi-1，一种新的大型代码语言模型，其大小明显小于竞争模型: phi-1是一种基于 Transformer 的模型，具有1.3 B 参数，在8个 A100s 上训练了4天，使用来自 Web 的选择的“教科书质量”数据(6B 令牌) ，并用 GPT-3.5(1B 令牌)综合生成教科书和练习。尽管规模很小，phi-1在 HumanEval 和 MBPP 上的准确率分别为50.6% 和55.5% 。与 phi-1-base (我们在编码练习数据集的微调阶段之前的模型)和 phi-1-small (一个较小的模型，具有350M 参数，与 phi-1使用相同的管道训练，在 HumanEval 上仍然达到45%)相比，它还显示出令人惊讶的紧急属性。"
    },
    {
        "title": "Improving Image Captioning Descriptiveness by Ranking and LLM-based\n  Fusion",
        "url": "http://arxiv.org/abs/2306.11593v1",
        "pub_date": "2023-06-20",
        "summary": "State-of-The-Art (SoTA) image captioning models often rely on the Microsoft\nCOCO (MS-COCO) dataset for training. This dataset contains annotations provided\nby human annotators, who typically produce captions averaging around ten\ntokens. However, this constraint presents a challenge in effectively capturing\ncomplex scenes and conveying detailed information. Furthermore, captioning\nmodels tend to exhibit bias towards the ``average'' caption, which captures\nonly the more general aspects. What would happen if we were able to\nautomatically generate longer captions, thereby making them more detailed?\nWould these captions, evaluated by humans, be more or less representative of\nthe image content compared to the original MS-COCO captions? In this paper, we\npresent a novel approach to address previous challenges by showcasing how\ncaptions generated from different SoTA models can be effectively fused,\nresulting in richer captions. Our proposed method leverages existing models\nfrom the literature, eliminating the need for additional training. Instead, it\nutilizes an image-text based metric to rank the captions generated by SoTA\nmodels for a given image. Subsequently, the top two captions are fused using a\nLarge Language Model (LLM). Experimental results demonstrate the effectiveness\nof our approach, as the captions generated by our model exhibit higher\nconsistency with human judgment when evaluated on the MS-COCO test set. By\ncombining the strengths of various SoTA models, our method enhances the quality\nand appeal of image captions, bridging the gap between automated systems and\nthe rich, informative nature of human-generated descriptions. This advance\nopens up new possibilities for generating captions that are more suitable for\nthe training of both vision-language and captioning models.",
        "translated": "最先进的(SoTA)图像字幕模型通常依赖于微软 COCO (MS-COCO)数据集进行训练。此数据集包含由人工注释器提供的注释，人工注释器通常生成平均约10个标记的标题。然而，这种约束在有效捕获复杂场景和传递详细信息方面提出了挑战。此外，字幕模型往往表现出偏向于“平均”字幕的倾向，它只捕获更一般的方面。如果我们能够自动生成更长的字幕，从而使它们更加详细，会发生什么？与原始的 MS-COCO 标题相比，这些由人类评估的标题是否更能代表图像内容？在本文中，我们通过展示如何有效地融合不同 SoTA 模型生成的字幕，从而产生更丰富的字幕，提出了一种新颖的方法来应对以前的挑战。我们提出的方法利用了文献中的现有模型，消除了额外培训的需要。相反，它使用一个基于图像文本的度量标准来对 SoTA 模型为给定图像生成的标题进行排序。随后，使用大型语言模型(LLM)将前两个标题融合在一起。实验结果证明了该方法的有效性，因为当在 MS-COCO 测试集上进行评估时，我们的模型生成的字幕与人类的判断具有更高的一致性。通过结合各种 SoTA 模型的优势，我们的方法提高了图像标题的质量和吸引力，弥合了自动化系统与人工生成描述的丰富信息性之间的差距。这一进步为生成更适合于视觉语言和字幕模型训练的字幕提供了新的可能性。"
    },
    {
        "title": "FAIR: A Causal Framework for Accurately Inferring Judgments Reversals",
        "url": "http://arxiv.org/abs/2306.11585v1",
        "pub_date": "2023-06-20",
        "summary": "Artificial intelligence researchers have made significant advances in legal\nintelligence in recent years. However, the existing studies have not focused on\nthe important value embedded in judgments reversals, which limits the\nimprovement of the efficiency of legal intelligence. In this paper, we propose\na causal Framework for Accurately Inferring case Reversals (FAIR), which models\nthe problem of judgments reversals based on real Chinese judgments. We mine the\ncauses of judgments reversals by causal inference methods and inject the\nobtained causal relationships into the neural network as a priori knowledge.\nAnd then, our framework is validated on a challenging dataset as a legal\njudgment prediction task. The experimental results show that our framework can\ntap the most critical factors in judgments reversal, and the obtained causal\nrelationships can effectively improve the neural network's performance. In\naddition, we discuss the generalization ability of large language models for\nlegal intelligence tasks using ChatGPT as an example. Our experiment has found\nthat the generalization ability of large language models still has defects, and\nmining causal relationships can effectively improve the accuracy and explain\nability of model predictions.",
        "translated": "近年来，人工智能研究者在法律智能方面取得了重大进展。然而，现有的研究并没有关注到判决书撤销所蕴含的重要价值，这限制了法律情报工作效率的提高。在本文中，我们提出了一个准确推断判例颠倒的因果框架(FAIR) ，该框架基于真实的中国判例对判例颠倒问题进行建模。我们利用因果推理方法挖掘判断反转的原因，并将所得到的因果关系作为先验知识注入到神经网络中。然后，我们的框架在一个具有挑战性的数据集上作为一个法律判决预测任务进行验证。实验结果表明，该框架能够挖掘出判断反转中最关键的因素，得到的因果关系能够有效地提高神经网络的性能。此外，本文还以 ChatGPT 为例，讨论了大型语言模型对法律情报任务的泛化能力。我们的实验发现，大型语言模型的泛化能力仍然存在缺陷，挖掘因果关系可以有效地提高模型预测的准确性和解释能力。"
    },
    {
        "title": "The Ecological Fallacy in Annotation: Modelling Human Label Variation\n  goes beyond Sociodemographics",
        "url": "http://arxiv.org/abs/2306.11559v1",
        "pub_date": "2023-06-20",
        "summary": "Many NLP tasks exhibit human label variation, where different annotators give\ndifferent labels to the same texts. This variation is known to depend, at least\nin part, on the sociodemographics of annotators. Recent research aims to model\nindividual annotator behaviour rather than predicting aggregated labels, and we\nwould expect that sociodemographic information is useful for these models. On\nthe other hand, the ecological fallacy states that aggregate group behaviour,\nsuch as the behaviour of the average female annotator, does not necessarily\nexplain individual behaviour. To account for sociodemographics in models of\nindividual annotator behaviour, we introduce group-specific layers to\nmulti-annotator models. In a series of experiments for toxic content detection,\nwe find that explicitly accounting for sociodemographic attributes in this way\ndoes not significantly improve model performance. This result shows that\nindividual annotation behaviour depends on much more than just\nsociodemographics.",
        "translated": "许多 NLP 任务表现出人工标签的变化，其中不同的注释者为相同的文本提供不同的标签。众所周知，这种差异至少在一定程度上取决于注释者的社会人口统计学特征。最近的研究旨在模拟个人注释者的行为，而不是预测聚合标签，我们期望社会人口信息对这些模型是有用的。另一方面，区群谬误指出，集体行为(例如一般女性注释者的行为)不一定能解释个人行为。为了解释个体注释者行为模型中的社会人口统计学特征，我们在多注释者模型中引入了群体特定层次。在一系列有毒物质含量检测的实验中，我们发现，以这种方式明确考虑社会人口属性并不能显著改善模型的性能。这一结果表明，个人注释行为不仅仅取决于社会人口统计学。"
    },
    {
        "title": "Hallucination is the last thing you need",
        "url": "http://arxiv.org/abs/2306.11520v1",
        "pub_date": "2023-06-20",
        "summary": "The legal profession necessitates a multidimensional approach that involves\nsynthesizing an in-depth comprehension of a legal issue with insightful\ncommentary based on personal experience, combined with a comprehensive\nunderstanding of pertinent legislation, regulation, and case law, in order to\ndeliver an informed legal solution. The present offering with generative AI\npresents major obstacles in replicating this, as current models struggle to\nintegrate and navigate such a complex interplay of understanding, experience,\nand fact-checking procedures. It is noteworthy that where generative AI outputs\nunderstanding and experience, which reflect the aggregate of various subjective\nviews on similar topics, this often deflects the model's attention from the\ncrucial legal facts, thereby resulting in hallucination. Hence, this paper\ndelves into the feasibility of three independent LLMs, each focused on\nunderstanding, experience, and facts, synthesising as one single ensemble model\nto effectively counteract the current challenges posed by the existing\nmonolithic generative AI models. We introduce an idea of mutli-length\ntokenisation to protect key information assets like common law judgements, and\nfinally we interrogate the most advanced publicly available models for legal\nhallucination, with some interesting results.",
        "translated": "法律专业需要一种多层面的方法，包括综合对法律问题的深入理解和根据个人经验作出的有见地的评论，再加上对相关立法、条例和判例法的全面理解，以便提供一个知情的法律解决方案。目前提供的生成性人工智能在复制这一点上存在重大障碍，因为目前的模型正在努力整合和导航这种理解、经验和事实核查程序的复杂相互作用。值得注意的是，当生成性 AI 输出理解和经验时，这些理解和经验反映了对类似主题的各种主观观点的集合，这往往会使模型的注意力偏离关键的法律事实，从而导致幻觉。因此，本文深入探讨了三个独立的 LLM 的可行性，每个 LLM 的重点是理解，经验和事实，综合为一个单一的集成模型，以有效地对抗现有的单片生成 AI 模型所带来的挑战。我们介绍了一个多长度标记的想法，以保护关键的信息资产，如普通法判决，最后我们询问了最先进的公开可用的模型的法律幻觉，一些有趣的结果。"
    },
    {
        "title": "Knowledge-based Multimodal Music Similarity",
        "url": "http://arxiv.org/abs/2306.12249v1",
        "pub_date": "2023-06-21",
        "summary": "Music similarity is an essential aspect of music retrieval, recommendation\nsystems, and music analysis. Moreover, similarity is of vital interest for\nmusic experts, as it allows studying analogies and influences among composers\nand historical periods. Current approaches to musical similarity rely mainly on\nsymbolic content, which can be expensive to produce and is not always readily\navailable. Conversely, approaches using audio signals typically fail to provide\nany insight about the reasons behind the observed similarity. This research\naddresses the limitations of current approaches by focusing on the study of\nmusical similarity using both symbolic and audio content. The aim of this\nresearch is to develop a fully explainable and interpretable system that can\nprovide end-users with more control and understanding of music similarity and\nclassification systems.",
        "translated": "音乐相似性是音乐检索、推荐系统和音乐分析的一个重要方面。此外，相似性对音乐专家来说至关重要，因为它允许研究作曲家和历史时期之间的类比和影响。目前音乐相似性的方法主要依靠符号内容，这可能是昂贵的生产，并不总是容易获得。相反，使用音频信号的方法通常不能提供任何有关观察到的相似性背后的原因的洞察力。本研究针对现有研究方法的局限性，集中研究音乐相似性的符号和音频内容。本研究的目的是开发一个完全可解释及可解释的系统，以提供最终使用者对音乐相似性及分类系统的更多控制及理解。"
    },
    {
        "title": "CompMix: A Benchmark for Heterogeneous Question Answering",
        "url": "http://arxiv.org/abs/2306.12235v1",
        "pub_date": "2023-06-21",
        "summary": "Fact-centric question answering (QA) often requires access to multiple,\nheterogeneous, information sources. By jointly considering several sources like\na knowledge base (KB), a text collection, and tables from the web, QA systems\ncan enhance their answer coverage and confidence. However, existing QA\nbenchmarks are mostly constructed with a single source of knowledge in mind.\nThis limits capabilities of these benchmarks to fairly evaluate QA systems that\ncan tap into more than one information repository. To bridge this gap, we\nrelease CompMix, a crowdsourced QA benchmark which naturally demands the\nintegration of a mixture of input sources. CompMix has a total of 9,410\nquestions, and features several complex intents like joins and temporal\nconditions. Evaluation of a range of QA systems on CompMix highlights the need\nfor further research on leveraging information from heterogeneous sources.",
        "translated": "以事实为中心的问答(QA)通常需要访问多种不同的信息源。通过联合考虑几个来源，如知识库(KB)、文本集合和来自 Web 的表格，QA 系统可以增强它们的答案覆盖范围和信心。然而，现有的质量保证基准大部分都是基于单一的知识来源构建的。这限制了这些基准测试公平评估能够利用多个信息存储库的 QA 系统的能力。为了弥合这一差距，我们发布了 CompMix，一个众包 QA 基准，它自然而然地要求集成多种输入源。CompMix 总共有9,410个问题，并且具有一些复杂的意图，比如连接和时态条件。对 CompMix 上一系列 QA 系统的评估突出表明，需要进一步研究如何利用来自不同来源的信息。"
    },
    {
        "title": "STAN: Stage-Adaptive Network for Multi-Task Recommendation by Learning\n  User Lifecycle-Based Representation",
        "url": "http://arxiv.org/abs/2306.12232v1",
        "pub_date": "2023-06-21",
        "summary": "Recommendation systems play a vital role in many online platforms, with their\nprimary objective being to satisfy and retain users. As directly optimizing\nuser retention is challenging, multiple evaluation metrics are often employed.\nExisting methods generally formulate the optimization of these evaluation\nmetrics as a multitask learning problem, but often overlook the fact that user\npreferences for different tasks are personalized and change over time.\nIdentifying and tracking the evolution of user preferences can lead to better\nuser retention. To address this issue, we introduce the concept of \"user\nlifecycle\", consisting of multiple stages characterized by users' varying\npreferences for different tasks. We propose a novel Stage-Adaptive Network\n(STAN) framework for modeling user lifecycle stages. STAN first identifies\nlatent user lifecycle stages based on learned user preferences, and then\nemploys the stage representation to enhance multi-task learning performance.\nOur experimental results using both public and industrial datasets demonstrate\nthat the proposed model significantly improves multi-task prediction\nperformance compared to state-of-the-art methods, highlighting the importance\nof considering user lifecycle stages in recommendation systems. Furthermore,\nonline A/B testing reveals that our model outperforms the existing model,\nachieving a significant improvement of 3.05% in staytime per user and 0.88% in\nCVR. These results indicate that our approach effectively improves the overall\nefficiency of the multi-task recommendation system.",
        "translated": "推荐系统在许多在线平台中发挥着至关重要的作用，其主要目标是满足和留住用户。由于直接优化用户保留是具有挑战性的，因此经常采用多种评估指标。现有的方法通常将这些评估指标的优化描述为一个多任务学习问题，但往往忽略了这样一个事实，即用户对不同任务的偏好是个性化的，并且随着时间的推移而改变。识别和跟踪用户偏好的演变可以更好地保留用户。为了解决这个问题，我们引入了“用户生命周期”的概念，由多个阶段组成，拥有属性是用户对不同任务的不同偏好。我们提出了一个新的阶段自适应网络(STAN)框架，用于建模用户生命周期阶段。STAN 首先根据学习用户的偏好识别潜在的用户生命周期阶段，然后采用阶段表示来提高多任务学习性能。我们使用公共数据集和工业数据集的实验结果表明，与最先进的方法相比，该模型显著提高了多任务预测性能，突出了在推荐系统中考虑用户生命周期阶段的重要性。此外，在线 A/B 测试表明，我们的模型优于现有的模型，实现了3.05% 的每个用户的停留时间和0.88% 的 CVR 显着改善。这些结果表明，该方法有效地提高了多任务推荐系统的整体效率。"
    },
    {
        "title": "Post-hoc Selection of Pareto-Optimal Solutions in Search and\n  Recommendation",
        "url": "http://arxiv.org/abs/2306.12165v1",
        "pub_date": "2023-06-21",
        "summary": "Information Retrieval (IR) and Recommender Systems (RS) tasks are moving from\ncomputing a ranking of final results based on a single metric to\nmulti-objective problems. Solving these problems leads to a set of\nPareto-optimal solutions, known as Pareto frontier, in which no objective can\nbe further improved without hurting the others. In principle, all the points on\nthe Pareto frontier are potential candidates to represent the best model\nselected with respect to the combination of two, or more, metrics. To our\nknowledge, there are no well-recognized strategies to decide which point should\nbe selected on the frontier. In this paper, we propose a novel, post-hoc,\ntheoretically-justified technique, named \"Population Distance from Utopia\"\n(PDU), to identify and select the one-best Pareto-optimal solution from the\nfrontier. In detail, PDU analyzes the distribution of the points by\ninvestigating how far each point is from its utopia point (the ideal\nperformance for the objectives). The possibility of considering fine-grained\nutopia points allows PDU to select solutions tailored to individual user\npreferences, a novel feature we call \"calibration\". We compare PDU against\nexisting state-of-the-art strategies through extensive experiments on tasks\nfrom both IR and RS. Experimental results show that PDU and combined with\ncalibration notably impact the solution selection. Furthermore, the results\nshow that the proposed framework selects a solution in a principled way,\nirrespective of its position on the frontier, thus overcoming the limits of\nother strategies.",
        "translated": "信息检索(IR)和推荐系统(RS)任务正在从计算基于单一指标的最终结果排序过渡到多目标问题。解决这些问题导致一组帕累托最优解，称为帕累托边界，其中任何目标都不能进一步改进而不损害其他目标。原则上，Pareto 前沿上的所有点都是潜在的候选者，可以代表就两个或更多指标的组合而选择的最佳模型。据我们所知，没有公认的战略来决定哪一点应该选择在前沿。本文提出了一种新的、事后的、理论证明的技术，称为“距离乌托邦的人口距离”(PDU) ，从前沿中识别和选择一个最佳的帕累托最优解。具体来说，PDU 通过调查每个点离它的乌托邦点(目标的理想性能)有多远来分析这些点的分布。考虑细粒度乌托邦点的可能性允许 PDU 选择适合个人用户偏好的解决方案，这个新特性我们称之为“校准”。通过对 IR 和 RS 任务的大量实验，我们比较了 PDU 和现有的最新策略。实验结果表明，PDU 和标定相结合对解决方案的选择有显著影响。此外，结果表明，所提出的框架以原则性的方式选择解决方案，而不考虑其在前沿的位置，从而克服了其他战略的局限性。"
    },
    {
        "title": "Visualizing Relation Between (De)Motivating Topics and Public Stance\n  toward COVID-19 Vaccine",
        "url": "http://arxiv.org/abs/2306.12118v1",
        "pub_date": "2023-06-21",
        "summary": "While social media plays a vital role in communication nowadays,\nmisinformation and trolls can easily take over the conversation and steer\npublic opinion on these platforms. We saw the effect of misinformation during\nthe {COVID-19} pandemic when public health officials faced significant\npush-back while trying to motivate the public to vaccinate. To tackle the\ncurrent and any future threats in emergencies and motivate the public towards a\ncommon goal, it is essential to understand how public motivation shifts and\nwhich topics resonate among the general population. In this study, we proposed\nan interactive visualization tool to inspect and analyze the topics that\nresonated among Twitter-sphere during the {COVID-19} pandemic and understand\nthe key factors that shifted public stance for vaccination. This tool can\neasily be generalized for any scenario for visual analysis and to increase the\ntransparency of social media data for researchers and the general population\nalike.",
        "translated": "尽管社交媒体在当今的交流中扮演着重要的角色，但是错误的信息和喷子很容易就能在这些平台上控制交流和引导公众舆论。在2019冠状病毒疾病大流行期间，我们看到了错误信息的影响，当时公共卫生官员在试图激励公众接种疫苗时面临重大阻力。为了应对当前和今后在紧急情况下的任何威胁，并推动公众实现一个共同目标，必须了解公众的动机如何转变，以及哪些主题在普通民众中产生共鸣。在这项研究中，我们提出了一个交互式可视化工具来检查和分析在2019冠状病毒疾病大流行期间在 twitter 领域引起共鸣的话题，并了解改变公众对疫苗接种立场的关键因素。这个工具可以很容易地推广到任何可视化分析的场景，并为研究人员和普通大众提高社交媒体数据的透明度。"
    },
    {
        "title": "VisoGender: A dataset for benchmarking gender bias in image-text pronoun\n  resolution",
        "url": "http://arxiv.org/abs/2306.12424v1",
        "pub_date": "2023-06-21",
        "summary": "We introduce VisoGender, a novel dataset for benchmarking gender bias in\nvision-language models. We focus on occupation-related gender biases, inspired\nby Winograd and Winogender schemas, where each image is associated with a\ncaption containing a pronoun relationship of subjects and objects in the scene.\nVisoGender is balanced by gender representation in professional roles,\nsupporting bias evaluation in two ways: i) resolution bias, where we evaluate\nthe difference between gender resolution accuracies for men and women and ii)\nretrieval bias, where we compare ratios of male and female professionals\nretrieved for a gender-neutral search query. We benchmark several\nstate-of-the-art vision-language models and find that they lack the reasoning\nabilities to correctly resolve gender in complex scenes. While the direction\nand magnitude of gender bias depends on the task and the model being evaluated,\ncaptioning models generally are more accurate and less biased than CLIP-like\nmodels. Dataset and code are available at https://github.com/oxai/visogender",
        "translated": "我们介绍了视觉性别，一个新的数据集的基准性别偏见的视觉语言模型。我们重点关注与职业相关的性别偏见，灵感来自 Winograd 和 Winosex 模式，其中每个图像都与一个包含场景中主体和客体的代词关系的标题相关联。Viso 性别通过专业角色中的性别代表性来平衡，支持偏倚评估有两种方式: i)解析偏倚，其中我们评估男性和女性性别解析准确性之间的差异以及 ii)检索偏倚，其中我们比较检索的男性和女性专业人员的比例进行性别中立的搜索查询。我们基准的几个国家的最先进的视觉语言模型，发现他们缺乏推理能力，以正确解决性别在复杂的场景。虽然性别偏见的方向和程度取决于被评估的任务和模型，但字幕模型一般比 CLIP 类模型更准确，偏见更少。数据集和代码可在 https://github.com/oxai/visogender 下载"
    },
    {
        "title": "LMFlow: An Extensible Toolkit for Finetuning and Inference of Large\n  Foundation Models",
        "url": "http://arxiv.org/abs/2306.12420v1",
        "pub_date": "2023-06-21",
        "summary": "Large foundation models have demonstrated a great ability to achieve general\nhuman-level intelligence far beyond traditional approaches. As the technique\nkeeps attracting attention from the AI community, more and more large\nfoundation models have become publically available. However, most of those\nmodels exhibit a major deficiency in specialized-task applications, where the\nstep of finetuning is still required for obtaining satisfactory performance. As\nthe number of available models and specialized tasks keeps growing, the job of\ngeneral finetuning becomes highly nontrivial. In this paper, we take the first\nstep to address this issue. We introduce an extensible and lightweight toolkit,\nLMFlow, which aims to simplify the finetuning and inference of general large\nfoundation models. LMFlow offers a complete finetuning workflow for a large\nfoundation model to support personalized training with limited computing\nresources. Furthermore, it supports continuous pretraining, instruction tuning,\nparameter-efficient finetuning, alignment tuning, and large model inference,\nalong with carefully designed and extensible APIs. This toolkit has been\nthoroughly tested and is available at https://github.com/OptimalScale/LMFlow.",
        "translated": "大型基础模型已经证明，它具有实现远远超出传统方法的一般人类水平智能的巨大能力。随着该技术不断受到人工智能界的关注，越来越多的大型基础模型被公开。然而，这些模型中的大多数都表现出专门任务应用程序的主要缺陷，在这些应用程序中，仍然需要进行微调以获得令人满意的性能。随着可用模型和专门任务的数量不断增加，一般微调工作变得非常重要。在本文中，我们采取第一步来解决这个问题。我们介绍了一个可扩展的轻量级工具包 LMFlow，旨在简化一般大型基础模型的微调和推理。LMFlow 为大型基础模型提供了完整的微调工作流，以支持计算资源有限的个性化培训。此外，它还支持连续预训练、指令调优、参数高效微调、对齐调优和大型模型推理，以及精心设计和可扩展的 API。这个工具包已经经过了彻底的测试，可以在 https://github.com/optimalscale/lmflow 上使用。"
    },
    {
        "title": "Solving Dialogue Grounding Embodied Task in a Simulated Environment\n  using Further Masked Language Modeling",
        "url": "http://arxiv.org/abs/2306.12387v1",
        "pub_date": "2023-06-21",
        "summary": "Enhancing AI systems with efficient communication skills that align with\nhuman understanding is crucial for their effective assistance to human users.\nProactive initiatives from the system side are needed to discern specific\ncircumstances and interact aptly with users to solve these scenarios. In this\nresearch, we opt for a collective building assignment taken from the Minecraft\ndataset. Our proposed method employs language modeling to enhance task\nunderstanding through state-of-the-art (SOTA) methods using language models.\nThese models focus on grounding multi-modal understandinging and task-oriented\ndialogue comprehension tasks. This focus aids in gaining insights into how well\nthese models interpret and respond to a variety of inputs and tasks. Our\nexperimental results provide compelling evidence of the superiority of our\nproposed method. This showcases a substantial improvement and points towards a\npromising direction for future research in this domain.",
        "translated": "加强人工智能系统，使其具有与人类理解相一致的高效沟通技能，对于有效协助人类用户至关重要。需要系统方面的主动行动来识别具体情况，并与用户适当地交互以解决这些场景。在这项研究中，我们选择了一个从 Minecraft 数据集中获取的集体建筑分配。我们提出的方法采用语言模型，通过使用语言模型的最新(SOTA)方法来增强任务理解。这些模型侧重于基础的多模态理解和任务导向的对话理解任务。这种关注有助于深入了解这些模型如何很好地解释和响应各种输入和任务。我们的实验结果为我们提出的方法的优越性提供了令人信服的证据。这表明了一个实质性的改进，并指出了该领域未来研究的一个有希望的方向。"
    },
    {
        "title": "Iterated Piecewise Affine (IPA) Approximation for Language Modeling",
        "url": "http://arxiv.org/abs/2306.12317v1",
        "pub_date": "2023-06-21",
        "summary": "In this work, we demonstrate the application of a simple first-order Taylor\nexpansion to approximate a generic function $F: R^{n \\times m} \\to R^{n \\times\nm}$ and utilize it in language modeling. To enhance the basic Taylor expansion,\nwe introduce iteration and piecewise modeling, leading us to name the algorithm\nthe Iterative Piecewise Affine (IPA) approximation. The final algorithm\nexhibits interesting resemblances to the Transformers decoder architecture. By\ncomparing parameter arrangements in IPA and Transformers, we observe a\nstrikingly similar performance, with IPA outperforming Transformers by 1.5\\% in\nthe next token prediction task with cross-entropy loss for smaller sequence\nlengths.",
        "translated": "在本文中，我们应用一个简单的一阶泰勒展开式将一般函数 $F: R ^ { n 乘以 m }逼近到 R ^ { n 乘以 m } $，并将其应用于语言建模。为了增强基本的泰勒展开，我们引入了迭代和分段建模，从而将该算法命名为迭代分段仿射(IPA)近似。最终的算法与变形金刚解码器结构有着有趣的相似之处。通过比较 IPA 和 Transformers 中的参数安排，我们观察到了惊人的相似性能，在交叉熵损失较小的序列长度的下一个令牌预测任务中，IPA 的性能优于 Transformers 1.5% 。"
    },
    {
        "title": "Medical ministrations through web scraping",
        "url": "http://arxiv.org/abs/2306.12310v1",
        "pub_date": "2023-06-21",
        "summary": "Web scraping is a technique that allows us to extract data from websites\nautomatically. in the field of medicine, web scraping can be used to collect\ninformation about medical procedures, treatments, and healthcare providers.\nthis information can be used to improve patient care, monitor the quality of\nhealthcare services, and identify areas for improvement. one area where web\nscraping can be particularly useful is in medical ministrations. medical\nministrations are the actions taken to provide medical care to patients, and\nweb scraping can help healthcare providers identify the most effective\nministrations for their patients. for example, healthcare providers can use web\nscraping to collect data about the symptoms and medical histories of their\npatients, and then use this information to determine the most appropriate\nministrations. they can also use web scraping to gather information about the\nlatest medical research and clinical trials, which can help them stay\nup-to-date with the latest treatments and procedures.",
        "translated": "网页抓取是一种允许我们从网站自动提取数据的技术。在医学领域，网络抓取可以用来收集关于医疗程序、治疗和医疗保健提供者的信息。这些信息可用于改善患者护理，监测医疗服务的质量，并确定需要改进的领域。网络抓取特别有用的一个领域是医疗管理。医疗管理是为病人提供医疗服务而采取的行动，网络抓取可以帮助医疗服务提供者为病人确定最有效的管理。例如，医疗保健提供者可以使用网络抓取来收集关于病人的症状和病史的数据，然后使用这些信息来确定最合适的服务。他们还可以使用网络搜索来收集最新的医学研究和临床试验的信息，这可以帮助他们了解最新的治疗方法和程序。"
    },
    {
        "title": "SIFTER: A Task-specific Alignment Strategy for Enhancing Sentence\n  Embeddings",
        "url": "http://arxiv.org/abs/2306.12280v1",
        "pub_date": "2023-06-21",
        "summary": "The paradigm of pre-training followed by fine-tuning on downstream tasks has\nbecome the mainstream method in natural language processing tasks. Although\npre-trained models have the advantage of generalization, their performance may\nstill vary significantly across different domain tasks. This is because the\ndata distribution in different domains varies. For example, the different parts\nof the sentence 'He married Smt. Dipali Ghosh in 1947 and led a very happy\nmarried life' may have different impact for downstream tasks. For similarity\ncalculations, words such as 'led' and 'life' are more important. On the other\nhand, for sentiment analysis, the word 'happy' is crucial. This indicates that\ndifferent downstream tasks have different levels of sensitivity to sentence\ncomponents. Our starting point is to scale information of the model and data\naccording to the specifics of downstream tasks, enhancing domain information of\nrelevant parts for these tasks and reducing irrelevant elements for different\ndomain tasks, called SIFTER. In the experimental part, we use the SIFTER to\nimprove SimCSE by constructing positive sample pairs based on enhancing the\nsentence stem and reducing the unimportant components in the sentence, and\nmaximize the similarity between three sentences. Similarly, SIFTER can improve\nthe gate mechanism of the LSTM model by short-circuiting the input gate of\nimportant words so that the LSTM model remembers the important parts of the\nsentence. Our experiments demonstrate that SIFTER outperforms the SimCSE and\nLSTM baselines.",
        "translated": "在自然语言处理任务中，预先训练后对下游任务进行微调已成为主流方法。尽管预先训练的模型具有泛化的优势，但是它们的性能在不同的领域任务之间仍然有很大的差异。这是因为不同域中的数据分布不同。例如，句子的不同部分‘他娶了 St。1947年迪帕里 · 高希和他的妻子过着非常幸福的婚姻生活’可能会对下游的工作产生不同的影响。对于相似度计算，“ led”和“ life”这样的单词更为重要。另一方面，对于情感分析来说，“快乐”这个词是至关重要的。这表明不同的下游任务对句子成分的敏感程度不同。我们的出发点是根据下游任务的具体情况来缩放模型和数据的信息，增强这些任务相关部分的领域信息，并减少不同领域任务(称为 SIFTER)的不相关元素。在实验部分，我们利用 SIFTER 算法对 SimCSE 算法进行改进，在增强句子主干和减少句子中不重要成分的基础上构造正样本对，使三个句子之间的相似性最大化。同样，SIFTER 可以通过短路重要词的输入门来改善 LSTM 模型的门机制，从而使 LSTM 模型记住句子的重要部分。我们的实验表明，SIFTER 优于 SimCSE 和 LSTM 基线。"
    },
    {
        "title": "Solving and Generating NPR Sunday Puzzles with Large Language Models",
        "url": "http://arxiv.org/abs/2306.12255v1",
        "pub_date": "2023-06-21",
        "summary": "We explore the ability of large language models to solve and generate puzzles\nfrom the NPR Sunday Puzzle game show using PUZZLEQA, a dataset comprising 15\nyears of on-air puzzles. We evaluate four large language models using PUZZLEQA,\nin both multiple choice and free response formats, and explore two prompt\nengineering techniques to improve free response performance: chain-of-thought\nreasoning and prompt summarization. We find that state-of-the-art large\nlanguage models can solve many PUZZLEQA puzzles: the best model, GPT-3.5,\nachieves 50.2% loose accuracy. However, in our few-shot puzzle generation\nexperiment, we find no evidence that models can generate puzzles: GPT-3.5\ngenerates puzzles with answers that do not conform to the generated rules.\nPuzzle generation remains a challenging task for future work.",
        "translated": "我们使用 PUZZLEQA (一个包含15年现场拼图的数据集)来探索大型语言模型解决和生成 NPR 周日拼图游戏节目中的拼图的能力。我们使用 PUZZLEQA 评估了四种大型语言模型，包括多项选择和自由响应格式，并探索了两种提高自由响应性能的快速工程技术: 思维链推理和快速总结。我们发现最先进的大型语言模型可以解决许多 PUZZLEQA 难题: 最好的模型 GPT-3.5可以达到50.2% 的松散精度。然而，在我们的几个镜头的谜题生成实验中，我们没有发现模型可以生成谜题的证据: GPT-3.5生成的谜题的答案不符合生成的规则。生成谜题仍然是未来工作的一项具有挑战性的任务。"
    },
    {
        "title": "Bidirectional End-to-End Learning of Retriever-Reader Paradigm for\n  Entity Linking",
        "url": "http://arxiv.org/abs/2306.12245v1",
        "pub_date": "2023-06-21",
        "summary": "Entity Linking (EL) is a fundamental task for Information Extraction and\nKnowledge Graphs. The general form of EL (i.e., end-to-end EL) aims to first\nfind mentions in the given input document and then link the mentions to\ncorresponding entities in a specific knowledge base. Recently, the paradigm of\nretriever-reader promotes the progress of end-to-end EL, benefiting from the\nadvantages of dense entity retrieval and machine reading comprehension.\nHowever, the existing study only trains the retriever and the reader separately\nin a pipeline manner, which ignores the benefit that the interaction between\nthe retriever and the reader can bring to the task. To advance the\nretriever-reader paradigm to perform more perfectly on end-to-end EL, we\npropose BEER$^2$, a Bidirectional End-to-End training framework for Retriever\nand Reader. Through our designed bidirectional end-to-end training, BEER$^2$\nguides the retriever and the reader to learn from each other, make progress\ntogether, and ultimately improve EL performance. Extensive experiments on\nbenchmarks of multiple domains demonstrate the effectiveness of our proposed\nBEER$^2$.",
        "translated": "实体连接(EL)是信息抽取和知识图表的基本任务。EL (即端到端 EL)的一般形式旨在首先查找给定输入文档中的提及，然后将提及链接到特定知识库中的相应实体。最近，检索-阅读器的范例推动了端到端 EL 的发展，受益于密集实体检索和机器阅读理解的优势。然而，现有的研究只是以流水线的方式分别训练检索者和读者，忽略了检索者和读者之间的交互可以给任务带来的好处。为了提高检索器-阅读器模式在端到端 EL 上的性能，我们提出了 BEER $^ 2 $，一个针对检索器和阅读器的双向端到端培训框架。通过我们设计的端到端双向培训，BEER $^ 2 $引导检索器和读取器相互学习，共同进步，最终提高 EL 性能。对多个领域的基准的广泛实验证明了我们提出的 BEER $^ 2 $的有效性。"
    },
    {
        "title": "Limits for Learning with Language Models",
        "url": "http://arxiv.org/abs/2306.12213v1",
        "pub_date": "2023-06-21",
        "summary": "With the advent of large language models (LLMs), the trend in NLP has been to\ntrain LLMs on vast amounts of data to solve diverse language understanding and\ngeneration tasks. The list of LLM successes is long and varied. Nevertheless,\nseveral recent papers provide empirical evidence that LLMs fail to capture\nimportant aspects of linguistic meaning. Focusing on universal quantification,\nwe provide a theoretical foundation for these empirical findings by proving\nthat LLMs cannot learn certain fundamental semantic properties including\nsemantic entailment and consistency as they are defined in formal semantics.\nMore generally, we show that LLMs are unable to learn concepts beyond the first\nlevel of the Borel Hierarchy, which imposes severe limits on the ability of\nLMs, both large and small, to capture many aspects of linguistic meaning. This\nmeans that LLMs will continue to operate without formal guarantees on tasks\nthat require entailments and deep linguistic understanding.",
        "translated": "随着大型语言模型(LLM)的出现，自然语言处理(NLP)的发展趋势是在大量数据上训练 LLM，以解决不同的语言理解和生成任务。LLM 的成功之处是多种多样的。尽管如此，最近的几篇论文提供了经验证明，认为 LLM 未能捕捉到语言意义的重要方面。关注全称量化，我们为这些实证研究结果提供了一个理论基础，通过证明 LLM 不能学习某些基本的语义属性，包括语义蕴含和一致性，因为它们是在形式语义学中定义的。更一般地，我们表明，长期语言模型无法学习概念超出第一层次的 Borel 层次，这对长期语言模型的能力，无论大小，捕捉语言意义的许多方面施加了严重的限制。这意味着 LLM 将继续在没有正式保证的情况下运行，而这些任务需要蕴含和深刻的语言理解。"
    },
    {
        "title": "Investigating Pre-trained Language Models on Cross-Domain Datasets, a\n  Step Closer to General AI",
        "url": "http://arxiv.org/abs/2306.12205v1",
        "pub_date": "2023-06-21",
        "summary": "Pre-trained language models have recently emerged as a powerful tool for\nfine-tuning a variety of language tasks. Ideally, when models are pre-trained\non large amount of data, they are expected to gain implicit knowledge. In this\npaper, we investigate the ability of pre-trained language models to generalize\nto different non-language tasks. In particular, we test them on tasks from\ndifferent domains such as computer vision, reasoning on hierarchical data, and\nprotein fold prediction. The four pre-trained models that we used, T5, BART,\nBERT, and GPT-2 achieve outstanding results. They all have similar performance\nand they outperform transformers that are trained from scratch by a large\nmargin. For instance, pre-trained language models perform better on the Listops\ndataset, with an average accuracy of 58.7\\%, compared to transformers trained\nfrom scratch, which have an average accuracy of 29.0\\%. The significant\nimprovement demonstrated across three types of datasets suggests that\npre-training on language helps the models to acquire general knowledge,\nbringing us a step closer to general AI. We also showed that reducing the\nnumber of parameters in pre-trained language models does not have a great\nimpact as the performance drops slightly when using T5-Small instead of\nT5-Base. In fact, when using only 2\\% of the parameters, we achieved a great\nimprovement compared to training from scratch. Finally, in contrast to prior\nwork, we find out that using pre-trained embeddings for the input layer is\nnecessary to achieve the desired results.",
        "translated": "预先训练的语言模型最近已经成为微调各种语言任务的强大工具。理想情况下，当模型在大量数据上进行预训练时，它们应该获得隐含的知识。本文研究了预训练语言模型对不同非语言任务的概括能力。特别是，我们在不同领域的任务中测试它们，例如计算机视觉、层次数据推理和蛋白质折叠预测。我们使用的四个预先训练的模型，T5、 BART、 BERT 和 GPT-2都取得了显著的效果。他们都有相似的性能，他们的表现优于变压器，从零开始训练的大幅度差距。例如，预先训练的语言模型在 Listops 数据集上表现得更好，平均准确率为58.7% ，而从头开始训练的变压器的平均准确率为29.0% 。三类数据集的显著改进表明，语言预训练有助于模型获得一般知识，使我们更接近一般人工智能。我们还发现，减少预训练语言模型中的参数数量不会产生很大的影响，因为当使用 T5-Small 而不是 T5-Base 时，性能会略有下降。事实上，当只使用2% 的参数时，与从头开始训练相比，我们取得了很大的进步。最后，与之前的工作相比，我们发现对输入层使用预训练嵌入对于达到预期的结果是必要的。"
    },
    {
        "title": "Data augmentation for recommender system: A semi-supervised approach\n  using maximum margin matrix factorization",
        "url": "http://arxiv.org/abs/2306.13050v1",
        "pub_date": "2023-06-22",
        "summary": "Collaborative filtering (CF) has become a popular method for developing\nrecommender systems (RS) where ratings of a user for new items is predicted\nbased on her past preferences and available preference information of other\nusers. Despite the popularity of CF-based methods, their performance is often\ngreatly limited by the sparsity of observed entries. In this study, we explore\nthe data augmentation and refinement aspects of Maximum Margin Matrix\nFactorization (MMMF), a widely accepted CF technique for the rating\npredictions, which have not been investigated before. We exploit the inherent\ncharacteristics of CF algorithms to assess the confidence level of individual\nratings and propose a semi-supervised approach for rating augmentation based on\nself-training. We hypothesize that any CF algorithm's predictions with low\nconfidence are due to some deficiency in the training data and hence, the\nperformance of the algorithm can be improved by adopting a systematic data\naugmentation strategy. We iteratively use some of the ratings predicted with\nhigh confidence to augment the training data and remove low-confidence entries\nthrough a refinement process. By repeating this process, the system learns to\nimprove prediction accuracy. Our method is experimentally evaluated on several\nstate-of-the-art CF algorithms and leads to informative rating augmentation,\nimproving the performance of the baseline approaches.",
        "translated": "推荐协同过滤(CF)已经成为开发推荐系统(RS)的一种流行方法，在这种系统中，用户对新项目的评分可以根据其过去的偏好和其他用户的可用偏好信息进行预测。尽管基于 CF 的方法很流行，但是它们的性能常常受到观察条目稀疏性的极大限制。在这项研究中，我们探讨了最大保证金矩阵分解(MMMF)的数据增强和细化方面，这是一种被广泛接受的用于评级预测的 CF 技术，以前从未被研究过。我们利用 CF 算法的固有特性来评估个体评分的置信水平，提出了一种基于自训练的评分增强半监督方法。我们假设任何 CF 算法的低置信度预测都是由于训练数据中的某些缺陷造成的，因此，通过采用系统的数据增强策略可以提高算法的性能。我们迭代地使用一些高置信度预测值来增加训练数据，并通过一个细化过程去除低置信度条目。通过重复这个过程，系统学会提高预测的准确性。我们的方法在几个最先进的 CF 算法上进行了实验评估，导致了信息量的增加，提高了基线方法的性能。"
    },
    {
        "title": "Efficient Partitioning Method of Large-Scale Public Safety\n  Spatio-Temporal Data based on Information Loss Constraints",
        "url": "http://arxiv.org/abs/2306.12857v1",
        "pub_date": "2023-06-22",
        "summary": "The storage, management, and application of massive spatio-temporal data are\nwidely applied in various practical scenarios, including public safety.\nHowever, due to the unique spatio-temporal distribution characteristics of\nre-al-world data, most existing methods have limitations in terms of the\nspatio-temporal proximity of data and load balancing in distributed storage.\nThere-fore, this paper proposes an efficient partitioning method of large-scale\npublic safety spatio-temporal data based on information loss constraints\n(IFL-LSTP). The IFL-LSTP model specifically targets large-scale spatio-temporal\npoint da-ta by combining the spatio-temporal partitioning module (STPM) with\nthe graph partitioning module (GPM). This approach can significantly reduce the\nscale of data while maintaining the model's accuracy, in order to improve the\npartitioning efficiency. It can also ensure the load balancing of distributed\nstorage while maintaining spatio-temporal proximity of the data partitioning\nresults. This method provides a new solution for distributed storage of\nmas-sive spatio-temporal data. The experimental results on multiple real-world\nda-tasets demonstrate the effectiveness and superiority of IFL-LSTP.",
        "translated": "海量时空数据的存储、管理和应用广泛应用于各种实际场景，包括公共安全。然而，由于现实世界数据独特的时空分布特性，现有的方法在数据的时空接近性和分布式存储中的负载均衡方面存在局限性。因此，本文提出了一种基于信息丢失约束的大规模公共安全时空数据有效分割方法(IFL-LSTP)。IFL-LSTP 模型通过将时空分区模块(STPM)与图分区模块(GPM)相结合，专门针对大规模的时空点数据。该方法可以在保持模型精度的同时显著降低数据规模，从而提高分区效率。在保持数据分区结果的时空接近性的同时，还可以保证分布式存储的负载平衡。该方法为海量时空数据的分布式存储提供了一种新的解决方案。在多个实际数据集上的实验结果表明了 IFL-LSTP 的有效性和优越性。"
    },
    {
        "title": "HypeRS: Building a Hypergraph-driven ensemble Recommender System",
        "url": "http://arxiv.org/abs/2306.12800v1",
        "pub_date": "2023-06-22",
        "summary": "Recommender systems are designed to predict user preferences over collections\nof items. These systems process users' previous interactions to decide which\nitems should be ranked higher to satisfy their desires. An ensemble recommender\nsystem can achieve great recommendation performance by effectively combining\nthe decisions generated by individual models. In this paper, we propose a novel\nensemble recommender system that combines predictions made by different models\ninto a unified hypergraph ranking framework. This is the first time that\nhypergraph ranking has been employed to model an ensemble of recommender\nsystems. Hypergraphs are generalizations of graphs where multiple vertices can\nbe connected via hyperedges, efficiently modeling high-order relations. We\ndifferentiate real and predicted connections between users and items by\nassigning different hyperedge weights to individual recommender systems. We\nperform experiments using four datasets from the fields of movie, music and\nnews media recommendation. The obtained results show that the ensemble\nhypergraph ranking method generates more accurate recommendations compared to\nthe individual models and a weighted hybrid approach. The assignment of\ndifferent hyperedge weights to the ensemble hypergraph further improves the\nperformance compared to a setting with identical hyperedge weights.",
        "translated": "推荐系统的目的是预测用户对项目集合的偏好。这些系统处理用户以前的交互，以决定哪些项目应该排名更高，以满足他们的愿望。一个集合推荐系统可以通过有效地结合单个模型产生的决策来实现很好的推荐性能。在这篇文章中，我们提出了一个新的集合推荐系统，它将不同模型的预测结合到一个统一的超图排序框架中。这是第一次使用超图排序来模拟推荐系统的集合。超图是通过超边连接多个顶点的图的推广，它有效地建立了高阶关系。我们通过为各个推荐系统分配不同的超边缘权重来区分用户和项目之间真实的和预测的联系。我们使用来自电影、音乐和新闻媒体推荐领域的四个数据集进行实验。结果表明，与单个模型和加权混合方法相比，集合超图排序方法能够产生更精确的推荐值。与具有相同超边权的设置相比，向集合超图分配不同的超边权进一步提高了性能。"
    },
    {
        "title": "On the Robustness of Generative Retrieval Models: An Out-of-Distribution\n  Perspective",
        "url": "http://arxiv.org/abs/2306.12756v1",
        "pub_date": "2023-06-22",
        "summary": "Recently, we have witnessed generative retrieval increasingly gaining\nattention in the information retrieval (IR) field, which retrieves documents by\ndirectly generating their identifiers. So far, much effort has been devoted to\ndeveloping effective generative retrieval models. There has been less attention\npaid to the robustness perspective. When a new retrieval paradigm enters into\nthe real-world application, it is also critical to measure the\nout-of-distribution (OOD) generalization, i.e., how would generative retrieval\nmodels generalize to new distributions. To answer this question, firstly, we\ndefine OOD robustness from three perspectives in retrieval problems: 1) The\nquery variations; 2) The unforeseen query types; and 3) The unforeseen tasks.\nBased on this taxonomy, we conduct empirical studies to analyze the OOD\nrobustness of several representative generative retrieval models against dense\nretrieval models. The empirical results indicate that the OOD robustness of\ngenerative retrieval models requires enhancement. We hope studying the OOD\nrobustness of generative retrieval models would be advantageous to the IR\ncommunity.",
        "translated": "最近，我们看到生成检索越来越受到信息检索(IR)领域的关注，它通过直接生成文档的标识符来检索文档。到目前为止，已经投入了大量的精力来开发有效的生成检索模型。人们对健壮性视角的关注较少。当一个新的检索范式进入现实世界的应用程序时，衡量分布外(OOD)泛化也是至关重要的，也就是说，生成检索模型如何泛化到新的分布。为了回答这个问题，我们首先从检索问题的三个方面定义了面向对象的鲁棒性: 1)查询变量; 2)不可预见的查询类型; 3)不可预见的任务。在此基础上，我们进行了实证研究，分析了几个代表性的生成检索模型对密集检索模型的面向对象的鲁棒性。实证结果表明，生成检索模型的面向对象的鲁棒性有待提高。我们希望研究生成式检索模型的面向对象的鲁棒性能对信息检索界有所帮助。"
    },
    {
        "title": "Vec2Vec: A Compact Neural Network Approach for Transforming Text\n  Embeddings with High Fidelity",
        "url": "http://arxiv.org/abs/2306.12689v1",
        "pub_date": "2023-06-22",
        "summary": "Vector embeddings have become ubiquitous tools for many language-related\ntasks. A leading embedding model is OpenAI's text-ada-002 which can embed\napproximately 6,000 words into a 1,536-dimensional vector. While powerful,\ntext-ada-002 is not open source and is only available via API. We trained a\nsimple neural network to convert open-source 768-dimensional MPNet embeddings\ninto text-ada-002 embeddings. We compiled a subset of 50,000 online food\nreviews. We calculated MPNet and text-ada-002 embeddings for each review and\ntrained a simple neural network to for 75 epochs. The neural network was\ndesigned to predict the corresponding text-ada-002 embedding for a given MPNET\nembedding. Our model achieved an average cosine similarity of 0.932 on 10,000\nunseen reviews in our held-out test dataset. We manually assessed the quality\nof our predicted embeddings for vector search over text-ada-002-embedded\nreviews. While not as good as real text-ada-002 embeddings, predicted\nembeddings were able to retrieve highly relevant reviews. Our final model,\nVec2Vec, is lightweight (&lt;80 MB) and fast. Future steps include training a\nneural network with a more sophisticated architecture and a larger dataset of\npaired embeddings to achieve greater performance. The ability to convert\nbetween and align embedding spaces may be helpful for interoperability,\nlimiting dependence on proprietary models, protecting data privacy, reducing\ncosts, and offline operations.",
        "translated": "向量嵌入已经成为许多语言相关任务的普遍工具。一个领先的嵌入模型是 OpenAI 的 text-ada-002，它可以将大约6,000个单词嵌入到1,536维的向量中。Text-ada-002虽然功能强大，但它不是开源的，只能通过 API 使用。我们训练了一个简单的神经网络来将开源的768维 MPNet 嵌入转换为 text-ada-002嵌入。我们收集了50,000份在线食品评论。我们计算了每个评论的 MPNet 和 text-ada-002嵌入，并将一个简单的神经网络训练到75个时代。针对给定的 MPNET 嵌入，设计神经网络对相应的 text-ada-002嵌入进行预测。在我们的测试数据集中，我们的模型在10,000个看不见的评论上达到了0.932的平均余弦距离。我们通过 text-ada-002嵌入式评论手动评估了我们预测的向量搜索嵌入的质量。虽然不如真正的 text-ada-002嵌入，但预测的嵌入能够检索高度相关的评论。我们最终的模型 Vec2Vec 是轻量级的(< 80MB)并且速度很快。未来的步骤包括训练具有更复杂结构和更大的配对嵌入数据集的神经网络，以实现更好的性能。在嵌入空间之间进行转换和对齐的能力可能有助于实现互操作性、限制对专有模型的依赖、保护数据隐私、降低成本和离线操作。"
    },
    {
        "title": "Semi-automated extraction of research topics and trends from NCI funding\n  in radiological sciences from 2000-2020",
        "url": "http://arxiv.org/abs/2306.13075v1",
        "pub_date": "2023-06-22",
        "summary": "Investigators, funders, and the public desire knowledge on topics and trends\nin publicly funded research but current efforts in manual categorization are\nlimited in scale and understanding. We developed a semi-automated approach to\nextract and name research topics, and applied this to \\$1.9B of NCI funding\nover 21 years in the radiological sciences to determine micro- and macro-scale\nresearch topics and funding trends. Our method relies on sequential clustering\nof existing biomedical-based word embeddings, naming using subject matter\nexperts, and visualization to discover trends at a macroscopic scale above\nindividual topics. We present results using 15 and 60 cluster topics, where we\nfound that 2D projection of grant embeddings reveals two dominant axes:\nphysics-biology and therapeutic-diagnostic. For our dataset, we found that\nfunding for therapeutics- and physics-based research have outpaced diagnostics-\nand biology-based research, respectively. We hope these results may (1) give\ninsight to funders on the appropriateness of their funding allocation, (2)\nassist investigators in contextualizing their work and explore neighboring\nresearch domains, and (3) allow the public to review where their tax dollars\nare being allocated.",
        "translated": "研究人员、资助者和公众希望了解公共资助研究的主题和趋势，但目前在人工分类方面的努力在规模和理解方面受到限制。我们开发了一种半自动化的方法来提取和命名研究主题，并将其应用于21年来 NCI 在放射科学领域的19亿美元资金，以确定微观和宏观研究主题和资金趋势。我们的方法依赖于现有的基于生物医学的单词嵌入的顺序聚类，使用主题专家命名，以及可视化来发现在个别主题之上的宏观趋势。我们使用15和60个聚类主题展示结果，其中我们发现赠款嵌入的二维投影揭示了两个主要轴: 物理-生物学和治疗-诊断。对于我们的数据集，我们发现基于治疗学和物理学的研究经费分别超过了基于诊断学和基于生物学的研究。我们希望这些结果可以(1)让资助者了解他们资金分配的适当性，(2)帮助调查人员将他们的工作背景化，并探索相邻的研究领域，(3)允许公众审查他们的税款分配在哪里。"
    },
    {
        "title": "Can LLMs Express Their Uncertainty? An Empirical Evaluation of\n  Confidence Elicitation in LLMs",
        "url": "http://arxiv.org/abs/2306.13063v1",
        "pub_date": "2023-06-22",
        "summary": "The task of empowering large language models (LLMs) to accurately express\ntheir confidence, referred to as confidence elicitation, is essential in\nensuring reliable and trustworthy decision-making processes. Previous methods,\nwhich primarily rely on model logits, have become less suitable for LLMs and\neven infeasible with the rise of closed-source LLMs (e.g., commercialized LLM\nAPIs). This leads to a growing need to explore the untapped area of\n\\emph{non-logit-based} approaches to estimate the uncertainty of LLMs. Hence,\nin this study, we investigate approaches for confidence elicitation that do not\nrequire model fine-tuning or access to proprietary information. We introduce\nthree categories of methods: verbalize-based, consistency-based, and their\nhybrid methods for benchmarking, and evaluate their performance across five\ntypes of datasets and four widely-used LLMs. Our analysis of these methods\nuncovers several key insights: 1) LLMs often exhibit a high degree of\noverconfidence when verbalizing their confidence; 2) Prompting strategies such\nas CoT, Top-K and Multi-step confidences improve calibration of verbalized\nconfidence; 3) Consistency-based methods outperform the verbalized confidences\nin most cases, with particularly notable improvements on the arithmetic\nreasoning task; 4) Hybrid methods consistently deliver the best performance\nover their baselines, thereby emerging as a promising state-of-the-art\napproach; 5) Despite these advancements, all investigated methods continue to\nstruggle with challenging tasks, such as those requiring professional\nknowledge, leaving significant scope for improvement of confidence elicitation.",
        "translated": "授权大型语言模型(LLM)准确表达其置信度(称为置信度激发)的任务对于确保可靠和可信的决策过程至关重要。以前的方法，主要依赖于模型 logit，已经变得不太适合 LLM，甚至随着封闭源 LLM (例如，商业化 LLM API)的兴起而变得不可行。这导致人们越来越需要探索 emph { non-logit-based }方法中尚未开发的领域来估计 LLM 的不确定性。因此，在这项研究中，我们调查了不需要模型微调或访问专有信息的信心获取方法。我们介绍了三类方法: 基于语言的、基于一致性的和它们的混合基准测试方法，并且评估了它们在五种类型的数据集和四种广泛使用的 LLM 中的性能。我们对这些方法的分析揭示了几个关键的见解: 1) LLM 在表达他们的信心时经常表现出高度的过度自信; 2)提示策略，如 CoT，Top-K 和 Multi-step 置信度改善了口头置信度的校准; 3)基于一致性的方法在大多数情况下优于口头置信度，在算术推理任务上有特别显着的改善; 4)混合方法始终在其基线上提供最佳性能，从而成为一种有希望的最先进的方法; 5)尽管有这些进步，所有被调查的方法继续与具有挑战性的任务斗争，例如那些需要专业知识的任务，留下显着的提高。"
    },
    {
        "title": "Named entity recognition in resumes",
        "url": "http://arxiv.org/abs/2306.13062v1",
        "pub_date": "2023-06-22",
        "summary": "Named entity recognition (NER) is used to extract information from various\ndocuments and texts such as names and dates. It is important to extract\neducation and work experience information from resumes in order to filter them.\nConsidering the fact that all information in a resume has to be entered to the\ncompanys system manually, automatizing this process will save time of the\ncompanies. In this study, a deep learning-based semi-automatic named entity\nrecognition system has been implemented with a focus on resumes in the field of\nIT. Firstly, resumes of employees from five different IT related fields has\nbeen annotated. Six transformer based pre-trained models have been adapted to\nnamed entity recognition problem using the annotated data. These models have\nbeen selected among popular models in the natural language processing field.\nThe obtained system can recognize eight different entity types which are city,\ndate, degree, diploma major, job title, language, country and skill. Models\nused in the experiments are compared using micro, macro and weighted F1 scores\nand the performance of the methods was evaluated. Taking these scores into\naccount for test set the best micro and weighted F1 score is obtained by\nRoBERTa and the best macro F1 score is obtained by Electra model.",
        "translated": "命名实体识别(NER)用于从各种文档和文本(如姓名和日期)中提取信息。从简历中提取教育和工作经验信息，对简历进行过滤是非常重要的。考虑到简历中的所有信息都必须手动输入到公司系统中，这个过程的自动化将节省公司的时间。本文以 IT 领域的简历为研究对象，实现了一个基于深度学习的半自动命名实体识别系统。首先，对来自五个不同 IT 相关领域的员工的简历进行了注释。针对基于注释数据的命名实体识别问题，提出了六种基于变压器的预训练模型。这些模型已经被自然语言处理领域的流行模型所选择。所获得的系统可以识别城市、日期、学位、文凭专业、职称、语言、国家和技能等八种不同的实体类型。利用微观、宏观和加权 F1评分对实验中使用的模型进行了比较，并对方法的性能进行了评价。将这些得分考虑进测试集，用 RoBERTa 得到最佳微观和加权 F1得分，用 Electra 模型得到最佳宏观 F1得分。"
    },
    {
        "title": "CamChoice: A Corpus of Multiple Choice Questions and Candidate Response\n  Distributions",
        "url": "http://arxiv.org/abs/2306.13047v1",
        "pub_date": "2023-06-22",
        "summary": "Multiple Choice examinations are a ubiquitous form of assessment that is used\nto measure the ability of candidates across various domains and tasks.\nMaintaining the quality of proposed questions is of great importance to test\ndesigners, and therefore newly proposed questions go through several pre-test\nevaluation stages before they can be deployed into real-world exams. This\nprocess is currently quite manual, which can lead to time lags in the question\ndevelopment cycle. Automating this process would lead to a large improvement in\nefficiency, however, current datasets do not contain sufficient pre-test\nanalysis information. In this paper, we introduce CamChoice; a multiple-choice\ncomprehension dataset with questions at different target levels, where\nquestions have the true candidate selected options distributions. We introduce\nthe task of candidate distribution matching, propose several evaluation metrics\nfor the task, and demonstrate that automatic systems trained on RACE++ can be\nleveraged as baselines for our task. We further demonstrate that these\nautomatic systems can be used for practical pre-test evaluation tasks such as\ndetecting underperforming distractors, where our detection systems can\nautomatically identify poor distractors that few candidates select. We release\nthe data publicly for future research.",
        "translated": "多项选择考试是一种普遍存在的评估形式，用于衡量候选人在不同领域和任务的能力。保持试题的质量对于考试设计人员来说是非常重要的，因此新提出的试题要经过几个试题前的评估阶段才能应用到现实考试中。这个过程目前是相当手工的，这可能会导致问题开发周期中的时间滞后。自动化这个过程将导致效率的大幅度提高，但是，目前的数据集不包含足够的预测试分析信息。在本文中，我们介绍了 CamChoice，这是一个多项选择理解数据集，包含不同目标层次的问题，其中问题具有真实的候选选项分布。我们介绍了候选分布匹配的任务，提出了该任务的几个评价指标，并证明了基于 RACE + + 的自动系统可以作为我们的任务的基线。我们进一步证明这些自动系统可以用于实际的测试前评估任务，例如检测表现不佳的干扰物，我们的检测系统可以自动识别很少候选人选择的差的干扰物。我们公开这些数据以便将来研究。"
    },
    {
        "title": "Towards Explainable Evaluation Metrics for Machine Translation",
        "url": "http://arxiv.org/abs/2306.13041v1",
        "pub_date": "2023-06-22",
        "summary": "Unlike classical lexical overlap metrics such as BLEU, most current\nevaluation metrics for machine translation (for example, COMET or BERTScore)\nare based on black-box large language models. They often achieve strong\ncorrelations with human judgments, but recent research indicates that the\nlower-quality classical metrics remain dominant, one of the potential reasons\nbeing that their decision processes are more transparent. To foster more\nwidespread acceptance of novel high-quality metrics, explainability thus\nbecomes crucial. In this concept paper, we identify key properties as well as\nkey goals of explainable machine translation metrics and provide a\ncomprehensive synthesis of recent techniques, relating them to our established\ngoals and properties. In this context, we also discuss the latest\nstate-of-the-art approaches to explainable metrics based on generative models\nsuch as ChatGPT and GPT4. Finally, we contribute a vision of next-generation\napproaches, including natural language explanations. We hope that our work can\nhelp catalyze and guide future research on explainable evaluation metrics and,\nmediately, also contribute to better and more transparent machine translation\nsystems.",
        "translated": "与经典的词汇重叠度量(如 BLEU)不同，目前大多数机器翻译评估度量(如 COMET 或 BERTScore)都基于黑盒大语言模型。它们往往与人类的判断有很强的相关性，但最近的研究表明，质量较低的经典指标仍然占主导地位，其中一个潜在的原因是它们的决策过程更加透明。为了促进更广泛地接受新颖的高质量度量，可解释性因此变得至关重要。在这篇概念文章中，我们确定了可解释的机器翻译度量的关键性质和关键目标，并提供了一个综合性的最新技术，它们与我们建立的目标和性质相关联。在这个上下文中，我们还讨论了基于 ChatGPT 和 GPT4等生成模型的可解释度量的最新技术。最后，我们展望了下一代方法，包括自然语言解释。我们希望我们的工作能够有助于促进和指导今后关于可解释的评估指标的研究，并且在中间阶段，还有助于更好和更透明的机器翻译系统。"
    },
    {
        "title": "Apolitical Intelligence? Auditing Delphi's responses on controversial\n  political issues in the US",
        "url": "http://arxiv.org/abs/2306.13000v1",
        "pub_date": "2023-06-22",
        "summary": "As generative language models are deployed in ever-wider contexts, concerns\nabout their political values have come to the forefront with critique from all\nparts of the political spectrum that the models are biased and lack neutrality.\nHowever, the question of what neutrality is and whether it is desirable remains\nunderexplored. In this paper, I examine neutrality through an audit of Delphi\n[arXiv:2110.07574], a large language model designed for crowdsourced ethics. I\nanalyse how Delphi responds to politically controversial questions compared to\ndifferent US political subgroups. I find that Delphi is poorly calibrated with\nrespect to confidence and exhibits a significant political skew. Based on these\nresults, I examine the question of neutrality from a data-feminist lens, in\nterms of how notions of neutrality shift power and further marginalise unheard\nvoices. These findings can hopefully contribute to a more reflexive debate\nabout the normative questions of alignment and what role we want generative\nmodels to play in society.",
        "translated": "随着生成语言模型被应用于更广泛的环境中，人们对其政治价值观的担忧已成为当务之急，政治光谱各方纷纷批评这些模型存在偏见，缺乏中立性。然而，什么是中立以及中立是否可取的问题仍然没有得到充分的探讨。在本文中，我通过对 Delphi [ arXiv: 2110.07574]的审计来检验中立性，这是一个为众包伦理学设计的大型语言模型。我分析了德尔菲如何回应政治上有争议的问题，并与美国不同的政治分组进行了比较。我发现，德尔福在信心方面的标准很差，而且显示出明显的政治倾斜。基于这些结果，我从数据女权主义的角度来审视中立的问题，中立的概念如何转移权力并进一步边缘化未被听到的声音。这些研究结果有望有助于就协调一致的规范性问题以及我们希望生成模式在社会中发挥什么作用进行更自反性的辩论。"
    },
    {
        "title": "Speech Emotion Diarization: Which Emotion Appears When?",
        "url": "http://arxiv.org/abs/2306.12991v1",
        "pub_date": "2023-06-22",
        "summary": "Speech Emotion Recognition (SER) typically relies on utterance-level\nsolutions. However, emotions conveyed through speech should be considered as\ndiscrete speech events with definite temporal boundaries, rather than\nattributes of the entire utterance. To reflect the fine-grained nature of\nspeech emotions, we propose a new task: Speech Emotion Diarization (SED). Just\nas Speaker Diarization answers the question of \"Who speaks when?\", Speech\nEmotion Diarization answers the question of \"Which emotion appears when?\". To\nfacilitate the evaluation of the performance and establish a common benchmark\nfor researchers, we introduce the Zaion Emotion Dataset (ZED), an openly\naccessible speech emotion dataset that includes non-acted emotions recorded in\nreal-life conditions, along with manually-annotated boundaries of emotion\nsegments within the utterance. We provide competitive baselines and open-source\nthe code and the pre-trained models.",
        "translated": "语音情感识别(SER)通常依赖于话语级别的解决方案。然而，通过言语传达的情感应被视为具有明确的时间界限的离散的言语事件，而不是整个话语的属性。为了反映言语情绪的细粒度特性，我们提出了一个新的任务: 言语情绪日化(SED)。正如“说话人日历化”回答了“谁在什么时候说话”这个问题一样言语情感日化回答了“什么情感在什么时候出现?”.为了便于评估表现，并为研究人员建立一个共同的基准，我们引入了 Zaion 情绪数据集(ZED) ，这是一个开放访问的语音情绪数据集，包括在现实生活条件下记录的非行为情绪，以及在话语中手动注释的情绪段的边界。我们提供有竞争力的基线和开源的代码和预先训练的模型。"
    },
    {
        "title": "Conversation Derailment Forecasting with Graph Convolutional Networks",
        "url": "http://arxiv.org/abs/2306.12982v1",
        "pub_date": "2023-06-22",
        "summary": "Online conversations are particularly susceptible to derailment, which can\nmanifest itself in the form of toxic communication patterns like disrespectful\ncomments or verbal abuse. Forecasting conversation derailment predicts signs of\nderailment in advance enabling proactive moderation of conversations. Current\nstate-of-the-art approaches to address this problem rely on sequence models\nthat treat dialogues as text streams. We propose a novel model based on a graph\nconvolutional neural network that considers dialogue user dynamics and the\ninfluence of public perception on conversation utterances. Through empirical\nevaluation, we show that our model effectively captures conversation dynamics\nand outperforms the state-of-the-art models on the CGA and CMV benchmark\ndatasets by 1.5\\% and 1.7\\%, respectively.",
        "translated": "在线对话特别容易出轨，这可能表现为有毒的交流模式，如无礼的评论或口头辱骂。预测会话脱轨可以提前预测脱轨的迹象，从而能够主动调节会话。目前解决这个问题的最先进的方法依赖于将对话视为文本流的序列模型。我们提出了一个基于图形卷积神经网络的新模型，该模型考虑了对话使用者的动态变化以及公众认知对会话话语的影响。通过实证评估，我们发现我们的模型有效地捕获了会话动态，并且在 CGA 和 CMV 基准数据集上分别优于最先进的模型1.5% 和1.7% 。"
    },
    {
        "title": "Tracking public attitudes toward ChatGPT on Twitter using sentiment\n  analysis and topic modeling",
        "url": "http://arxiv.org/abs/2306.12951v1",
        "pub_date": "2023-06-22",
        "summary": "ChatGPT sets a new record with the fastest-growing user base, as a chatbot\npowered by a large language model (LLM). While it demonstrates state-of-the-art\ncapabilities in a variety of language-generating tasks, it also raises\nwidespread public concerns regarding its societal impact. In this paper, we\nutilize natural language processing approaches to investigate the public\nattitudes towards ChatGPT by applying sentiment analysis and topic modeling\ntechniques to Twitter data. Our result shows that the overall sentiment is\nlargely neutral to positive, which also holds true across different occupation\ngroups. Among a wide range of topics mentioned in tweets, the most popular\ntopics are Artificial Intelligence, Search Engines, Education, Writing, and\nQuestion Answering.",
        "translated": "ChatGPT 作为一个由大型语言模型(LLM)驱动的聊天机器人，用增长最快的用户群创建了一个新的记录。虽然它在各种语言生成任务中展示了最先进的能力，但它也引起了公众对其社会影响的广泛关注。本文利用自然语言处理方法，通过对 Twitter 数据的情感分析和主题建模技术，研究公众对 ChatGPT 的态度。我们的结果表明，总体情绪在很大程度上是中性至积极的，这也适用于不同的职业群体。在众多的话题中，最受欢迎的话题是人工智能、搜索引擎、教育、写作和问答。"
    },
    {
        "title": "Quantizable Transformers: Removing Outliers by Helping Attention Heads\n  Do Nothing",
        "url": "http://arxiv.org/abs/2306.12929v1",
        "pub_date": "2023-06-22",
        "summary": "Transformer models have been widely adopted in various domains over the last\nyears, and especially large language models have advanced the field of AI\nsignificantly. Due to their size, the capability of these networks has\nincreased tremendously, but this has come at the cost of a significant increase\nin necessary compute. Quantization is one of the most effective ways to reduce\nthe computational time and memory consumption of neural networks. Many studies\nhave shown, however, that modern transformer models tend to learn strong\noutliers in their activations, making them difficult to quantize. To retain\nacceptable performance, the existence of these outliers requires activations to\nbe in higher bitwidth or the use of different numeric formats, extra\nfine-tuning, or other workarounds. We show that strong outliers are related to\nvery specific behavior of attention heads that try to learn a \"no-op\" or just a\npartial update of the residual. To achieve the exact zeros needed in the\nattention matrix for a no-update, the input to the softmax is pushed to be\nlarger and larger during training, causing outliers in other parts of the\nnetwork. Based on these observations, we propose two simple (independent)\nmodifications to the attention mechanism - clipped softmax and gated attention.\nWe empirically show that models pre-trained using our methods learn\nsignificantly smaller outliers while maintaining and sometimes even improving\nthe floating-point task performance. This enables us to quantize transformers\nto full INT8 quantization of the activations without any additional effort. We\ndemonstrate the effectiveness of our methods on both language models (BERT,\nOPT) and vision transformers.",
        "translated": "近年来，变压器模型在各个领域得到了广泛的应用，尤其是大型语言模型的应用极大地推动了人工智能的发展。由于它们的规模，这些网络的能力已经大大增加，但这是以必要的计算能力显著增加为代价的。量化是减少神经网络计算时间和内存消耗的有效方法之一。然而，许多研究表明，现代变压器模型往往学习强烈的异常值在其激活，使他们难以量化。为了保持可接受的性能，这些异常值的存在要求激活具有更高的位宽或使用不同的数字格式、额外的微调或其他变通方法。我们发现强异常值与注意力集中的非常具体的行为有关，这些行为试图学习一个“不可操作”或仅仅是残差的部分更新。为了获得注意矩阵中无更新所需的精确零点，在训练过程中，向软极大的输入被推得越来越大，从而在网络的其他部分产生异常值。基于这些观察，我们提出了两个简单的(独立的)修正注意机制-剪切软最大和门控注意。我们的经验表明，使用我们的方法预训练的模型学习显着较小的异常值，同时维护，有时甚至提高浮点任务的性能。这使我们能够量化变压器，以充分的 INT8量化的激活没有任何额外的努力。我们证明了我们的方法在语言模型(BERT，OPT)和视觉转换器上的有效性。"
    },
    {
        "title": "Fuzzification-based Feature Selection for Enhanced Website Content\n  Encryption",
        "url": "http://arxiv.org/abs/2306.13548v1",
        "pub_date": "2023-06-23",
        "summary": "We propose a novel approach that utilizes fuzzification theory to perform\nfeature selection on website content for encryption purposes. Our objective is\nto identify and select the most relevant features from the website by\nharnessing the principles of fuzzy logic. Fuzzification allows us to transform\nthe crisp website content into fuzzy representations, enabling a more nuanced\nanalysis of their characteristics. By considering the degree of membership of\neach feature in different fuzzy categories, we can evaluate their importance\nand relevance for encryption. This approach enables us to prioritize and focus\non the features that exhibit higher membership degrees, indicating their\nsignificance in the encryption process. By employing fuzzification-based\nfeature selection, we aim to enhance the effectiveness and efficiency of\nwebsite content encryption, ultimately improving the overall internet security.",
        "translated": "我们提出了一种新的方法，利用模糊化理论对网站内容进行特征选择，以达到加密的目的。我们的目标是通过利用模糊逻辑的原则，从网站中识别和选择最相关的特性。模糊化允许我们将清晰的网站内容转换为模糊表示，从而能够对其特征进行更细致入微的分析。通过考虑每个特征在不同模糊类别中的隶属度，我们可以评估它们对加密的重要性和相关性。这种方法使我们能够优先考虑和关注那些表现出更高的成员等级的特征，表明它们在加密过程中的重要性。采用基于模糊化的特征选择方法，提高网站内容加密的有效性和效率，最终提高网络的整体安全性。"
    },
    {
        "title": "OptMSM: Optimizing Multi-Scenario Modeling for Click-Through Rate\n  Prediction",
        "url": "http://arxiv.org/abs/2306.13382v1",
        "pub_date": "2023-06-23",
        "summary": "A large-scale industrial recommendation platform typically consists of\nmultiple associated scenarios, requiring a unified click-through rate (CTR)\nprediction model to serve them simultaneously. Existing approaches for\nmulti-scenario CTR prediction generally consist of two main modules: i) a\nscenario-aware learning module that learns a set of multi-functional\nrepresentations with scenario-shared and scenario-specific information from\ninput features, and ii) a scenario-specific prediction module that serves each\nscenario based on these representations. However, most of these approaches\nprimarily focus on improving the former module and neglect the latter module.\nThis can result in challenges such as increased model parameter size, training\ndifficulty, and performance bottlenecks for each scenario. To address these\nissues, we propose a novel framework called OptMSM (\\textbf{Opt}imizing\n\\textbf{M}ulti-\\textbf{S}cenario \\textbf{M}odeling). First, we introduce a\nsimplified yet effective scenario-enhanced learning module to alleviate the\naforementioned challenges. Specifically, we partition the input features into\nscenario-specific and scenario-shared features, which are mapped to specific\ninformation embedding encodings and a set of shared information embeddings,\nrespectively. By imposing an orthogonality constraint on the shared information\nembeddings to facilitate the disentanglement of shared information\ncorresponding to each scenario, we combine them with the specific information\nembeddings to obtain multi-functional representations. Second, we introduce a\nscenario-specific hypernetwork in the scenario-specific prediction module to\ncapture interactions within each scenario more effectively, thereby alleviating\nthe performance bottlenecks. Finally, we conduct extensive offline experiments\nand an online A/B test to demonstrate the effectiveness of OptMSM.",
        "translated": "一个大规模的工业推荐平台通常由多个相关场景组成，需要一个统一的点进率预测模型来同时为这些场景提供服务。现有的多场景 CTR 预测方法通常由两个主要模块组成: 一个场景感知学习模块，该模块从输入特征中学习一组具有场景共享和场景特定信息的多功能表示; 二个场景特定预测模块，该模块基于这些表示为每个场景提供服务。然而，这些方法大多集中于改进前一个模块，而忽略了后一个模块。这可能导致各种挑战，例如增加模型参数的大小、训练难度和每个场景的性能瓶颈。为了解决这些问题，我们提出了一个新的框架 OptMSM (textbf { Opt } imizingtextbf { M } ulti-textbf { S } cenario textbf { M } odeling)。首先，我们引入一个简化但有效的情景增强学习模块，以缓解上述挑战。具体来说，我们将输入特性划分为场景特定特性和场景共享特性，分别映射到特定信息嵌入编码和一组共享信息嵌入。通过对共享信息嵌入施加正交性约束，以促进对应于每个场景的共享信息的分离，将它们与特定的信息嵌入相结合，得到多功能表示。其次，在场景特定的预测模块中引入场景特定的超网络，以更有效地捕获每个场景中的交互，从而缓解性能瓶颈。最后，我们进行了大量的离线实验和在线 A/B 测试来验证 OptMSM 的有效性。"
    },
    {
        "title": "Human Activity Behavioural Pattern Recognition in Smarthome with\n  Long-hour Data Collection",
        "url": "http://arxiv.org/abs/2306.13374v1",
        "pub_date": "2023-06-23",
        "summary": "The research on human activity recognition has provided novel solutions to\nmany applications like healthcare, sports, and user profiling. Considering the\ncomplex nature of human activities, it is still challenging even after\neffective and efficient sensors are available. The existing works on human\nactivity recognition using smartphone sensors focus on recognizing basic human\nactivities like sitting, sleeping, standing, stair up and down and running.\nHowever, more than these basic activities is needed to analyze human\nbehavioural pattern. The proposed framework recognizes basic human activities\nusing deep learning models. Also, ambient sensors like PIR, pressure sensors,\nand smartphone-based sensors like accelerometers and gyroscopes are combined to\nmake it hybrid-sensor-based human activity recognition. The hybrid approach\nhelped derive more activities than the basic ones, which also helped derive\nhuman activity patterns or user profiling. User profiling provides sufficient\ninformation to identify daily living activity patterns and predict whether any\nanomaly exists. The framework provides the base for applications such as\nelderly monitoring when they are alone at home. The GRU model's accuracy of\n95\\% is observed to recognize the basic activities. Finally, Human activity\npatterns over time are recognized based on the duration and frequency of the\nactivities. It is observed that human activity pattern, like, morning walking\nduration, varies depending on the day of the week.",
        "translated": "人类活动识别的研究为许多应用提供了新颖的解决方案，如医疗保健、体育和用户侧写。考虑到人类活动的复杂性，即使在有效和高效的传感器可用之后，这仍然是具有挑战性的。现有的利用智能手机传感器进行人类活动识别的工作主要集中在识别基本的人类活动，如坐着、睡觉、站立、上下楼梯和跑步。然而，分析人类行为模式需要的不仅仅是这些基本活动。提议的框架使用深度学习模型识别基本的人类活动。此外，环境传感器如 PIR，压力传感器和智能手机传感器如加速度计和陀螺仪的组合，使其混合传感器为基础的人类活动识别。混合方法有助于派生出比基本方法更多的活动，这也有助于派生出人类活动模式或用户分析。用户分析提供了足够的信息来识别日常生活活动模式，并预测是否存在任何异常。该框架为应用程序提供了基础，例如独自在家的老年人监测。GRU 模型识别基本活动的准确率达到95% 。最后，随着时间的推移，人类活动模式的识别基于活动的持续时间和频率。据观察，人类的活动模式，如早晨步行时间，根据不同的一天的一周。"
    },
    {
        "title": "A Decade of Scholarly Research on Open Knowledge Graphs",
        "url": "http://arxiv.org/abs/2306.13186v1",
        "pub_date": "2023-06-22",
        "summary": "The proliferation of open knowledge graphs has led to a surge in scholarly\nresearch on the topic over the past decade. This paper presents a bibliometric\nanalysis of the scholarly literature on open knowledge graphs published between\n2013 and 2023. The study aims to identify the trends, patterns, and impact of\nresearch in this field, as well as the key topics and research questions that\nhave emerged. The work uses bibliometric techniques to analyze a sample of 4445\nscholarly articles retrieved from Scopus. The findings reveal an\never-increasing number of publications on open knowledge graphs published every\nyear, particularly in developed countries (+50 per year). These outputs are\npublished in highly-referred scholarly journals and conferences. The study\nidentifies three main research themes: (1) knowledge graph construction and\nenrichment, (2) evaluation and reuse, and (3) fusion of knowledge graphs into\nNLP systems. Within these themes, the study identifies specific tasks that have\nreceived considerable attention, including entity linking, knowledge graph\nembedding, and graph neural networks.",
        "translated": "在过去的十年中，开放知识图表的激增导致了关于这一主题的学术研究的激增。本文对2013-2023年间发表的关于开放知识图表的学术文献进行了文献计量分析。本研究旨在确定该领域研究的趋势、模式和影响，以及出现的关键主题和研究问题。这项工作使用文献计量学技术来分析从 Scopus 检索到的4445篇学术文章的样本。研究结果显示，每年出版的关于开放知识图表的出版物数量不断增加，尤其是在发达国家(每年增加50本)。这些成果发表在高度引用的学术期刊和会议上。本研究确定了三个主要的研究主题: (1)知识图的构建与丰富; (2)知识图的评价与重用; (3)知识图在自然语言处理系统中的融合。在这些主题中，研究确定了已经受到相当关注的具体任务，包括实体连接、知识图嵌入和图神经网络。"
    },
    {
        "title": "Bring Your Own Data! Self-Supervised Evaluation for Large Language\n  Models",
        "url": "http://arxiv.org/abs/2306.13651v1",
        "pub_date": "2023-06-23",
        "summary": "With the rise of Large Language Models (LLMs) and their ubiquitous deployment\nin diverse domains, measuring language model behavior on realistic data is\nimperative. For example, a company deploying a client-facing chatbot must\nensure that the model will not respond to client requests with profanity.\nCurrent evaluations approach this problem using small, domain-specific datasets\nwith human-curated labels. These evaluation sets are often sampled from a\nnarrow and simplified distribution, and data sources can unknowingly be leaked\ninto the training set which can lead to misleading evaluations. To bypass these\ndrawbacks, we propose a framework for self-supervised evaluation of LLMs by\nanalyzing their sensitivity or invariance to transformations on the input text.\nSelf-supervised evaluation can directly monitor LLM behavior on datasets\ncollected in the wild or streamed during live model deployment. We demonstrate\nself-supervised evaluation strategies for measuring closed-book knowledge,\ntoxicity, and long-range context dependence, in addition to sensitivity to\ngrammatical structure and tokenization errors. When comparisons to similar\nhuman-labeled benchmarks are available, we find strong correlations between\nself-supervised and human-supervised evaluations. The self-supervised paradigm\ncomplements current evaluation strategies that rely on labeled data.",
        "translated": "随着大型语言模型(LLM)的兴起以及它们在不同领域的广泛应用，测量语言模型在实际数据上的行为变得势在必行。例如，部署面向客户机的聊天机器人的公司必须确保该模型不会以脏话回应客户机请求。目前的评估方法这个问题使用小，领域特定的数据集与人类管理的标签。这些评价集通常是从狭窄和简化的分布中取样的，数据源可能在不知情的情况下泄漏到培训集中，从而导致误导性评价。为了克服这些缺点，我们通过分析 LLM 对输入文本变换的敏感性或不变性，提出了一种 LLM 的自监督评估框架。自监督评估可以直接监视野外收集的数据集或实时模型部署期间的流数据集上的 LLM 行为。除了对语法结构和标记错误的敏感性外，我们还展示了自我监督的评估策略，用于测量闭卷知识、毒性和长期上下文依赖性。当与类似的人类标记基准进行比较时，我们发现自我监督评价和人类监督评价之间存在很强的相关性。自我监督范式补充了当前依赖于标记数据的评估策略。"
    },
    {
        "title": "GKD: Generalized Knowledge Distillation for Auto-regressive Sequence\n  Models",
        "url": "http://arxiv.org/abs/2306.13649v1",
        "pub_date": "2023-06-23",
        "summary": "Knowledge distillation is commonly used for compressing neural networks to\nreduce their inference cost and memory footprint. However, current distillation\nmethods for auto-regressive models, such as generative language models (LMs),\nsuffer from two key issues: (1) distribution mismatch between output sequences\nduring training and the sequences generated by the student during its\ndeployment, and (2) model under-specification, where the student model may not\nbe expressive enough to fit the teacher's distribution. To address these\nissues, we propose Generalized Knowledge Distillation (GKD). GKD mitigates\ndistribution mismatch by sampling output sequences from the student during\ntraining. Furthermore, GKD handles model under-specification by optimizing\nalternative divergences, such as reverse KL, that focus on generating samples\nfrom the student that are likely under the teacher's distribution. We\ndemonstrate that GKD outperforms commonly-used approaches for distilling LLMs\non summarization, machine translation, and arithmetic reasoning tasks.",
        "translated": "知识提取通常用于压缩神经网络，以减少其推理成本和内存占用。然而，目前自回归模型的精馏方法，如生成语言模型(LM) ，存在两个关键问题: (1)训练过程中输出序列与学生在部署过程中生成的序列之间的分布不匹配; (2)模型规范不足，学生模型的表达能力可能不足以适应教师的分布。为了解决这些问题，我们提出了广义知识提取(GKD)。GKD 通过在培训期间对学生的输出序列进行采样来减少分布不匹配。此外，GKD 通过优化替代性差异(如逆向 KL)来处理模型欠规范问题，这些差异侧重于从可能处于教师分布之下的学生生成样本。我们证明了 GKD 在摘要、机器翻译和算术推理任务中优于常用的 LLM 提取方法。"
    },
    {
        "title": "Margin Maximization in Attention Mechanism",
        "url": "http://arxiv.org/abs/2306.13596v1",
        "pub_date": "2023-06-23",
        "summary": "Attention mechanism is a central component of the transformer architecture\nwhich led to the phenomenal success of large language models. However, the\ntheoretical principles underlying the attention mechanism are poorly\nunderstood, especially its nonconvex optimization dynamics. In this work, we\nexplore the seminal softmax-attention model $f(\\boldsymbol{X})=\\langle\n\\boldsymbol{Xv}, \\texttt{softmax}(\\boldsymbol{XWp})\\rangle$, where,\n$\\boldsymbol{X}$ is the token sequence and\n$(\\boldsymbol{v},\\boldsymbol{W},\\boldsymbol{p})$ are tunable parameters. We\nprove that running gradient descent on $\\boldsymbol{p}$, or equivalently\n$\\boldsymbol{W}$, converges in direction to a max-margin solution that\nseparates $\\textit{locally-optimal}$ tokens from non-optimal ones. This clearly\nformalizes attention as a token separation mechanism. Remarkably, our results\nare applicable to general data and precisely characterize $\\textit{optimality}$\nof tokens in terms of the value embeddings $\\boldsymbol{Xv}$ and problem\ngeometry. We also provide a broader regularization path analysis that\nestablishes the margin maximizing nature of attention even for nonlinear\nprediction heads. When optimizing $\\boldsymbol{v}$ and $\\boldsymbol{p}$\nsimultaneously with logistic loss, we identify conditions under which the\nregularization paths directionally converge to their respective hard-margin SVM\nsolutions where $\\boldsymbol{v}$ separates the input features based on their\nlabels. Interestingly, the SVM formulation of $\\boldsymbol{p}$ is influenced by\nthe support vector geometry of $\\boldsymbol{v}$. Finally, we verify our\ntheoretical findings via numerical experiments and provide insights.",
        "translated": "注意机制是变压器体系结构的核心组成部分，它导致了大型语言模型的显著成功。然而，注意机制的理论基础知之甚少，尤其是其非凸优化动力学。本文探讨了开创性的软最大注意模型 $f (粗体{ X }) = 长体粗体{ Xv } ，texttt { softmax }(粗体{ XWp }) range $，其中 $粗体{ X } $是标记序列，$(粗体{ W } ，粗体{ p }) $是可调参数。我们证明了运行在 $粗体符号{ p } $或等价的 $粗体符号{ W } $上的梯度下降法收敛于一个最大边界解，该解将 $textit {局部最优} $标记与非最优标记区分开来。这清楚地将注意力形式化为一种标记分离机制。值得注意的是，我们的结果适用于一般数据，并且精确地刻画了标记的 $textit { Optimality } $值嵌入 $粗体符号{ Xv } $和问题几何。我们还提供了一个更广泛的正则化路径分析，即使对于非线性预测头来说，也建立了注意力余量最大化的性质。在对符号{ v } $和符号{ p } $同时进行逻辑损失优化时，我们确定了正则化路径在哪些条件下定向收敛到它们各自的硬边值 SVM 解，其中符号{ v } $根据标签分离输入特征。有趣的是，$粗体符号{ p } $的 SVM 公式受到 $粗体符号{ v } $的支持向量几何形状的影响。最后，通过数值实验验证我们的理论发现，并提供见解。"
    },
    {
        "title": "System-Level Natural Language Feedback",
        "url": "http://arxiv.org/abs/2306.13588v1",
        "pub_date": "2023-06-23",
        "summary": "Natural language (NL) feedback contains rich information about the user\nexperience. Existing studies focus on an instance-level approach, where\nfeedback is used to refine specific examples, disregarding its system-wide\napplication. This paper proposes a general framework for unlocking the\nsystem-level use of NL feedback. We show how to use feedback to formalize\nsystem-level design decisions in a human-in-the-loop-process -- in order to\nproduce better models. In particular this is done through: (i) metric design\nfor tasks; and (ii) language model prompt design for refining model responses.\nWe conduct two case studies of this approach for improving search query\ngeneration and dialog response generation, demonstrating the effectiveness of\nthe use of system-level feedback. We show the combination of system-level\nfeedback and instance-level feedback brings further gains, and that human\nwritten instance-level feedback results in more grounded refinements than\nGPT-3.5 written ones, underlying the importance of human feedback for building\nsystems.",
        "translated": "自然语言(NL)反馈包含了丰富的用户体验信息。现有的研究集中在实例级方法上，在这种方法中，反馈被用来精炼具体的例子，而忽略了它在系统范围内的应用。本文提出了一个解锁系统级使用自然语言反馈的一般框架。我们展示了如何使用反馈在人在循环的过程中形式化系统级设计决策——以便产生更好的模型。具体来说，这是通过: (i)任务的度量设计; 和(ii)精炼模型响应的语言模型提示设计。我们对该方法进行了两个改进搜索查询生成和对话框响应生成的案例研究，证明了使用系统级反馈的有效性。我们展示了系统级反馈和实例级反馈的结合带来了进一步的收益，而且人工编写的实例级反馈比 GPT-3.5编写的反馈带来了更多的基础细化，这是人工反馈对构建系统的重要性的基础。"
    },
    {
        "title": "A Survey on Multimodal Large Language Models",
        "url": "http://arxiv.org/abs/2306.13549v1",
        "pub_date": "2023-06-23",
        "summary": "Multimodal Large Language Model (MLLM) recently has been a new rising\nresearch hotspot, which uses powerful Large Language Models (LLMs) as a brain\nto perform multimodal tasks. The surprising emergent capabilities of MLLM, such\nas writing stories based on images and OCR-free math reasoning, are rare in\ntraditional methods, suggesting a potential path to artificial general\nintelligence. In this paper, we aim to trace and summarize the recent progress\nof MLLM. First of all, we present the formulation of MLLM and delineate its\nrelated concepts. Then, we discuss the key techniques and applications,\nincluding Multimodal Instruction Tuning (M-IT), Multimodal In-Context Learning\n(M-ICL), Multimodal Chain of Thought (M-CoT), and LLM-Aided Visual Reasoning\n(LAVR). Finally, we discuss existing challenges and point out promising\nresearch directions. In light of the fact that the era of MLLM has only just\nbegun, we will keep updating this survey and hope it can inspire more research.\nAn associated GitHub link collecting the latest papers is available at\nhttps://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models.",
        "translated": "多模态大语言模型(MLLM)是近年来兴起的一个新的研究热点，它利用强大的大语言模型(LLM)作为大脑来执行多模态任务。MLLM 令人惊讶的突发性能力，如基于图像和无 OCR 的数学推理写作故事，在传统方法中是罕见的，这表明了一条通向人工通用智能的潜在道路。本文旨在追踪和总结 MLLM 的最新进展。首先，我们提出了 MLLM 的概念，并描述了它的相关概念。然后，我们讨论了多模态教学调优(M-IT)、多模态上下文学习(M-ICL)、多模态思维链(M-CoT)和 LLM 辅助视觉推理(LAVR)等关键技术和应用。最后，我们讨论了目前存在的挑战，并指出了有前途的研究方向。鉴于 MLLM 的时代才刚刚开始，我们将不断更新这一调查，希望能够激发更多的研究。收集最新论文的相关 GitHub 链接可在 https://GitHub.com/bradyfu/awesome-multimodal-large-language-models 获得。"
    },
    {
        "title": "Knowledge-Infused Self Attention Transformers",
        "url": "http://arxiv.org/abs/2306.13501v1",
        "pub_date": "2023-06-23",
        "summary": "Transformer-based language models have achieved impressive success in various\nnatural language processing tasks due to their ability to capture complex\ndependencies and contextual information using self-attention mechanisms.\nHowever, they are not without limitations. These limitations include\nhallucinations, where they produce incorrect outputs with high confidence, and\nalignment issues, where they generate unhelpful and unsafe outputs for human\nusers. These limitations stem from the absence of implicit and missing context\nin the data alone. To address this, researchers have explored augmenting these\nmodels with external knowledge from knowledge graphs to provide the necessary\nadditional context. However, the ad-hoc nature of existing methods makes it\ndifficult to properly analyze the effects of knowledge infusion on the many\nmoving parts or components of a transformer. This paper introduces a systematic\nmethod for infusing knowledge into different components of a transformer-based\nmodel. A modular framework is proposed to identify specific components within\nthe transformer architecture, such as the self-attention mechanism, encoder\nlayers, or the input embedding layer, where knowledge infusion can be applied.\nAdditionally, extensive experiments are conducted on the General Language\nUnderstanding Evaluation (GLUE) benchmark tasks, and the findings are reported.\nThis systematic approach aims to facilitate more principled approaches to\nincorporating knowledge into language model architectures.",
        "translated": "基于转换器的语言模型在各种自然语言处理任务中取得了令人印象深刻的成功，因为它们能够利用自我注意机制捕获复杂的依赖关系和上下文信息。然而，它们并非没有限制。这些限制包括幻觉，它们产生高度可信的错误输出，以及校准问题，它们为人类用户产生无益和不安全的输出。这些限制源于数据本身缺乏隐式的和缺失的上下文。为了解决这个问题，研究人员已经探索用来自知识图表的外部知识来增强这些模型，以提供必要的额外背景。然而，现有方法的特殊性使得很难正确分析知识输入对变压器的许多运动部件的影响。本文介绍了一种将知识注入到基于变压器的模型的不同组件中的系统方法。提出了一个模块化框架来识别变压器体系结构中的特定组件，如自注意机制、编码器层或输入嵌入层，其中可以应用知识注入。此外，本研究还对通用语言理解评估(GLUE)基准任务进行了广泛的实验研究，并对实验结果进行了报道。这种系统方法旨在促进将知识纳入语言模型体系结构的更有原则的方法。"
    },
    {
        "title": "Incorporating Graph Information in Transformer-based AMR Parsing",
        "url": "http://arxiv.org/abs/2306.13467v1",
        "pub_date": "2023-06-23",
        "summary": "Abstract Meaning Representation (AMR) is a Semantic Parsing formalism that\naims at providing a semantic graph abstraction representing a given text.\nCurrent approaches are based on autoregressive language models such as BART or\nT5, fine-tuned through Teacher Forcing to obtain a linearized version of the\nAMR graph from a sentence. In this paper, we present LeakDistill, a model and\nmethod that explores a modification to the Transformer architecture, using\nstructural adapters to explicitly incorporate graph information into the\nlearned representations and improve AMR parsing performance. Our experiments\nshow how, by employing word-to-node alignment to embed graph structural\ninformation into the encoder at training time, we can obtain state-of-the-art\nAMR parsing through self-knowledge distillation, even without the use of\nadditional data. We release the code at\n\\url{http://www.github.com/sapienzanlp/LeakDistill}.",
        "translated": "抽象意义表示(AMR)是一种语义分析形式主义，旨在提供表示给定文本的语义图抽象。目前的方法是基于自回归语言模型，如 BART 或 T5，通过教师强制微调，以获得一个句子的 AMR 图的线性化版本。在本文中，我们提出了 LeakDistill 模型和方法，该模型和方法探索了如何修改 Transformer 体系结构，使用结构适配器将图信息显式地合并到所学习的表示中，并提高 AMR 解析性能。实验结果表明，在训练时通过字节对齐将图结构信息嵌入到编码器中，即使不需要额外的数据，也可以通过自知识提取获得最新的 AMR 解析结果。我们在 url { http://www.github.com/sapienzanlp/leakdistill }发布代码。"
    },
    {
        "title": "Learning Descriptive Image Captioning via Semipermeable Maximum\n  Likelihood Estimation",
        "url": "http://arxiv.org/abs/2306.13460v1",
        "pub_date": "2023-06-23",
        "summary": "Image captioning aims to describe visual content in natural language. As 'a\npicture is worth a thousand words', there could be various correct descriptions\nfor an image. However, with maximum likelihood estimation as the training\nobjective, the captioning model is penalized whenever its prediction mismatches\nwith the label. For instance, when the model predicts a word expressing richer\nsemantics than the label, it will be penalized and optimized to prefer more\nconcise expressions, referred to as conciseness optimization. In contrast,\npredictions that are more concise than labels lead to richness optimization.\nSuch conflicting optimization directions could eventually result in the model\ngenerating general descriptions. In this work, we introduce Semipermeable\nMaxImum Likelihood Estimation (SMILE), which allows richness optimization while\nblocking conciseness optimization, thus encouraging the model to generate\nlonger captions with more details. Extensive experiments on two mainstream\nimage captioning datasets MSCOCO and Flickr30K demonstrate that SMILE\nsignificantly enhances the descriptiveness of generated captions. We further\nprovide in-depth investigations to facilitate a better understanding of how\nSMILE works.",
        "translated": "图像字幕的目的是用自然语言描述视觉内容。正如“一张图片胜过千言万语”一样，对于一张图片可以有各种各样正确的描述。然而，以最大似然估计为训练目标，当字幕模型的预测与标签不匹配时，字幕模型就会受到惩罚。例如，当模型预测一个表达比标签更丰富的语义的单词时，它将受到惩罚并优化以选择更简洁的表达式，称为简洁性优化。相反，比标签更简洁的预测会导致丰富性优化。这种冲突的优化方向可能最终导致模型产生一般的描述。在本文中，我们引入了半可渗透最大似然估计(SMILE) ，它允许在阻塞简洁性优化的同时进行丰富性优化，从而鼓励模型生成具有更多细节的更长的标题。在两个主流图像字幕数据集 MSCOCO 和 Flickr30K 上的大量实验表明，SMILE 显著提高了生成的字幕的描述性。我们进一步提供深入的调查，以便更好地了解 SMILE 如何工作。"
    },
    {
        "title": "Long-range Language Modeling with Self-retrieval",
        "url": "http://arxiv.org/abs/2306.13421v1",
        "pub_date": "2023-06-23",
        "summary": "Retrieval-augmented language models (LMs) have received much attention\nrecently. However, typically the retriever is not trained jointly as a native\ncomponent of the LM, but added to an already-pretrained LM, which limits the\nability of the LM and the retriever to adapt to one another. In this work, we\npropose the Retrieval-Pretrained Transformer (RPT), an architecture and\ntraining procedure for jointly training a retrieval-augmented LM from scratch\nfor the task of modeling long texts. Given a recently generated text chunk in a\nlong document, the LM computes query representations, which are then used to\nretrieve earlier chunks in the document, located potentially tens of thousands\nof tokens before. Information from retrieved chunks is fused into the LM\nrepresentations to predict the next target chunk. We train the retriever\ncomponent with a semantic objective, where the goal is to retrieve chunks that\nincrease the probability of the next chunk, according to a reference LM. We\nevaluate RPT on four long-range language modeling tasks, spanning books, code,\nand mathematical writing, and demonstrate that RPT improves retrieval quality\nand subsequently perplexity across the board compared to strong baselines.",
        "translated": "检索增强语言模型(LM)近年来受到了广泛的关注。然而，检索器通常不会作为 LM 的本机组件共同训练，而是添加到已经预先训练好的 LM 中，这限制了 LM 和检索器相互适应的能力。在这项工作中，我们提出了检索-预训练变压器(RPT) ，一个体系结构和训练过程，联合训练一个检索-增强 LM 从头开始建模长文本的任务。给定一个长文档中最近生成的文本块，LM 计算查询表示，然后使用这些查询表示来检索文档中可能存在数万个标记的早期块。来自检索块的信息被融合到 LM 表示中，以预测下一个目标块。我们使用语义目标训练检索器组件，其目标是根据引用 LM 检索增加下一个块的概率的块。我们评估了 RPT 在四个远程语言建模任务(跨书籍、代码和数学写作)上的表现，并证明与强基线相比，RPT 提高了检索质量并随后全面提高了困惑度。"
    },
    {
        "title": "Stress Testing BERT Anaphora Resolution Models for Reaction Extraction\n  in Chemical Patents",
        "url": "http://arxiv.org/abs/2306.13379v1",
        "pub_date": "2023-06-23",
        "summary": "The high volume of published chemical patents and the importance of a timely\nacquisition of their information gives rise to automating information\nextraction from chemical patents. Anaphora resolution is an important component\nof comprehensive information extraction, and is critical for extracting\nreactions. In chemical patents, there are five anaphoric relations of interest:\nco-reference, transformed, reaction associated, work up, and contained. Our\ngoal is to investigate how the performance of anaphora resolution models for\nreaction texts in chemical patents differs in a noise-free and noisy\nenvironment and to what extent we can improve the robustness against noise of\nthe model.",
        "translated": "由于已发表的化学专利数量庞大，加上及时取得这些专利的资料十分重要，因此化学专利的信息抽取便会自动化。回指消解是综合信息抽取的重要组成部分，对提取反应至关重要。在化学专利中，有五种兴趣回指关系: 共指关系、转换关系、反应关系、升级关系和包含关系。我们的目标是研究化学专利中反应文本的回指消解模型在无噪声和噪声环境中的性能差异，以及在多大程度上我们可以提高模型对噪声的鲁棒性。"
    },
    {
        "title": "Scalable Neural Contextual Bandit for Recommender Systems",
        "url": "http://arxiv.org/abs/2306.14834v1",
        "pub_date": "2023-06-26",
        "summary": "High-quality recommender systems ought to deliver both innovative and\nrelevant content through effective and exploratory interactions with users.\nYet, supervised learning-based neural networks, which form the backbone of many\nexisting recommender systems, only leverage recognized user interests, falling\nshort when it comes to efficiently uncovering unknown user preferences. While\nthere has been some progress with neural contextual bandit algorithms towards\nenabling online exploration through neural networks, their onerous\ncomputational demands hinder widespread adoption in real-world recommender\nsystems. In this work, we propose a scalable sample-efficient neural contextual\nbandit algorithm for recommender systems. To do this, we design an epistemic\nneural network architecture, Epistemic Neural Recommendation (ENR), that\nenables Thompson sampling at a large scale. In two distinct large-scale\nexperiments with real-world tasks, ENR significantly boosts click-through rates\nand user ratings by at least 9% and 6% respectively compared to\nstate-of-the-art neural contextual bandit algorithms. Furthermore, it achieves\nequivalent performance with at least 29% fewer user interactions compared to\nthe best-performing baseline algorithm. Remarkably, while accomplishing these\nimprovements, ENR demands orders of magnitude fewer computational resources\nthan neural contextual bandit baseline algorithms.",
        "translated": "高质量的推荐系统应该通过与用户有效和探索性的互动交付创新和相关的内容。然而，作为许多现有推荐系统骨干的基于监督学习的神经网络，只能利用已识别的用户兴趣，在有效发现未知用户偏好方面存在不足。虽然神经上下文强盗算法在通过神经网络实现在线探索方面取得了一些进展，但是它们繁重的计算需求阻碍了在现实世界中推荐系统的广泛采用。在这项工作中，我们提出了一个可扩展的样本效率神经上下文盗贼算法的推荐系统。为了做到这一点，我们设计了一个认知神经网络结构，认知神经推荐(ENR) ，使汤普森采样在大规模。在两个不同的大规模实验与现实世界的任务，ENR 显着提高点击率和用户评分至少9% 和6% 分别相比，国家的最先进的神经上下文土匪算法。此外，与性能最好的基线算法相比，它至少减少了29% 的用户交互，从而实现了相同的性能。值得注意的是，在完成这些改进的同时，ENR 所需的计算资源数量级比神经上下文强盗基线算法要少。"
    },
    {
        "title": "Reciprocal Sequential Recommendation",
        "url": "http://arxiv.org/abs/2306.14712v1",
        "pub_date": "2023-06-26",
        "summary": "Reciprocal recommender system (RRS), considering a two-way matching between\ntwo parties, has been widely applied in online platforms like online dating and\nrecruitment. Existing RRS models mainly capture static user preferences, which\nhave neglected the evolving user tastes and the dynamic matching relation\nbetween the two parties. Although dynamic user modeling has been well-studied\nin sequential recommender systems, existing solutions are developed in a\nuser-oriented manner. Therefore, it is non-trivial to adapt sequential\nrecommendation algorithms to reciprocal recommendation. In this paper, we\nformulate RRS as a distinctive sequence matching task, and further propose a\nnew approach ReSeq for RRS, which is short for Reciprocal Sequential\nrecommendation. To capture dual-perspective matching, we propose to learn\nfine-grained sequence similarities by co-attention mechanism across different\ntime steps. Further, to improve the inference efficiency, we introduce the\nself-distillation technique to distill knowledge from the fine-grained matching\nmodule into the more efficient student module. In the deployment stage, only\nthe efficient student module is used, greatly speeding up the similarity\ncomputation. Extensive experiments on five real-world datasets from two\nscenarios demonstrate the effectiveness and efficiency of the proposed method.\nOur code is available at https://github.com/RUCAIBox/ReSeq/.",
        "translated": "考虑双方双向匹配的互惠推荐系统已经广泛应用于在线约会和招聘等在线平台。现有的 RRS 模型主要捕捉静态用户偏好，忽略了用户偏好的演变和双方的动态匹配关系。尽管动态用户建模已经在顺序推荐系统中得到了很好的研究，但是现有的解决方案都是以面向用户的方式开发的。因此，将顺序推荐算法应用到互惠推荐中具有重要意义。本文将 RRS 作为一个独特的序列匹配任务，并进一步提出了一种新的 RRS 方法 ReSeq，即相互序列推荐的简称。为了捕获双视角匹配，我们提出了通过跨不同时间步长的共注意机制来学习细粒度序列相似性。进一步，为了提高推理效率，我们引入了自蒸馏技术，从细粒度匹配模块中提取知识到更高效的学生模块中。在部署阶段，只使用了有效的学生模块，大大加快了相似度计算的速度。通过对来自两个场景的五个真实世界数据集的大量实验，证明了该方法的有效性和高效性。我们的代码可以在 https://github.com/rucaibox/reseq/找到。"
    },
    {
        "title": "PTVD: A Large-Scale Plot-Oriented Multimodal Dataset Based on Television\n  Dramas",
        "url": "http://arxiv.org/abs/2306.14644v1",
        "pub_date": "2023-06-26",
        "summary": "Art forms such as movies and television (TV) dramas are reflections of the\nreal world, which have attracted much attention from the multimodal learning\ncommunity recently. However, existing corpora in this domain share three\nlimitations: (1) annotated in a scene-oriented fashion, they ignore the\ncoherence within plots; (2) their text lacks empathy and seldom mentions\nsituational context; (3) their video clips fail to cover long-form relationship\ndue to short duration. To address these fundamental issues, using 1,106 TV\ndrama episodes and 24,875 informative plot-focused sentences written by\nprofessionals, with the help of 449 human annotators, we constructed PTVD, the\nfirst plot-oriented multimodal dataset in the TV domain. It is also the first\nnon-English dataset of its kind. Additionally, PTVD contains more than 26\nmillion bullet screen comments (BSCs), powering large-scale pre-training. Next,\naiming to open-source a strong baseline for follow-up works, we developed the\nmultimodal algorithm that attacks different cinema/TV modelling problems with a\nunified architecture. Extensive experiments on three cognitive-inspired tasks\nyielded a number of novel observations (some of them being quite\ncounter-intuition), further validating the value of PTVD in promoting\nmultimodal research. The dataset and codes are released at\n\\url{https://ptvd.github.io/}.",
        "translated": "电影、电视剧等艺术形式是现实世界的反映，近年来引起了多模式学习社会的广泛关注。然而，该领域现有的语料库存在三个局限性: (1)以场景为导向的方式进行注释，忽视了情节的连贯性; (2)文本缺乏移情作用，很少提及情景语境; (3)视频片段由于篇幅短而无法涵盖长篇关系。为了解决这些基本问题，我们在449名人类注释者的帮助下，使用1,106个电视剧集和24,875个由专业人员撰写的信息丰富的情节集中的句子，构建了电视领域中第一个面向情节的多模式数据集 PTVD。它也是第一个非英语数据集的类型。此外，PTVD 包含超过2600万条弹幕评论(BSC) ，为大规模的预训提供动力。接下来，为了给后续工作提供一个强有力的开源基准，我们开发了多模态算法，用一个统一的体系结构来解决不同的影院/电视建模问题。对三个认知启发任务的广泛实验产生了许多新的观察结果(其中一些相当反直觉) ，进一步验证了 PTVD 在促进多模态研究中的价值。数据集和代码在 url { https://ptvd.github.io/}发布。"
    },
    {
        "title": "Multi-task Item-attribute Graph Pre-training for Strict Cold-start Item\n  Recommendation",
        "url": "http://arxiv.org/abs/2306.14462v1",
        "pub_date": "2023-06-26",
        "summary": "Recommendation systems suffer in the strict cold-start (SCS) scenario, where\nthe user-item interactions are entirely unavailable. The ID-based approaches\ncompletely fail to work. Cold-start recommenders, on the other hand, leverage\nitem contents to map the new items to the existing ones. However, the existing\nSCS recommenders explore item contents in coarse-grained manners that introduce\nnoise or information loss. Moreover, informative data sources other than item\ncontents, such as users' purchase sequences and review texts, are ignored. We\nexplore the role of the fine-grained item attributes in bridging the gaps\nbetween the existing and the SCS items and pre-train a knowledgeable\nitem-attribute graph for SCS item recommendation. Our proposed framework,\nColdGPT, models item-attribute correlations into an item-attribute graph by\nextracting fine-grained attributes from item contents. ColdGPT then transfers\nknowledge into the item-attribute graph from various available data sources,\ni.e., item contents, historical purchase sequences, and review texts of the\nexisting items, via multi-task learning. To facilitate the positive transfer,\nColdGPT designs submodules according to the natural forms of the data sources\nand coordinates the multiple pre-training tasks via unified\nalignment-and-uniformity losses. Our pre-trained item-attribute graph acts as\nan implicit, extendable item embedding matrix, which enables the SCS item\nembeddings to be easily acquired by inserting these items and propagating their\nattributes' embeddings. We carefully process three public datasets, i.e., Yelp,\nAmazon-home, and Amazon-sports, to guarantee the SCS setting for evaluation.\nExtensive experiments show that ColdGPT consistently outperforms the existing\nSCS recommenders by large margins and even surpasses models that are\npre-trained on 75-224 times more, cross-domain data on two out of four\ndatasets.",
        "translated": "推荐系统在严格的冷启动(SCS)场景中受到影响，其中用户-项交互是完全不可用的。基于 ID 的方法完全不起作用。另一方面，冷启动推荐器利用项目内容将新项目映射到现有项目。然而，现有的 SCS 推荐标准以粗粒度的方式探索项目内容，导致噪声或信息丢失。此外，项目内容以外的信息性数据源，如用户的购买顺序和评论文本，被忽略。本文探讨了细粒度项目属性在弥补现有项目与 SCS 项目之间差距方面的作用，并为 SCS 项目推荐预训练了一个知识型项目属性图。我们提出的框架 ColdGPT 通过从项目内容中提取细粒度属性，将项目-属性关系建模成项目-属性图。ColdGPT 然后通过多任务学习，将来自各种可用数据源的知识转移到项目属性图中，即项目内容、历史购买顺序和审查现有项目的文本。为了便于正向传输，ColdGPT 根据数据源的自然形式设计子模块，并通过统一的对齐和一致性损失协调多个预训练任务。我们的预训练项目属性图作为一个隐式的、可扩展的项目嵌入矩阵，通过插入这些项目并传播它们的属性嵌入，可以方便地获得 SCS 项目嵌入。我们仔细处理三个公共数据集，即 Yelp、 Amazon-home 和 Amazon-sports，以保证 SCS 设置用于评估。大量的实验表明，ColdGPT 始终优于现有的 SCS 推荐器，甚至超过预先训练75-224倍以上的模型，跨域数据在四个数据集中的两个。"
    },
    {
        "title": "Contrastive Multi-view Framework for Customer Lifetime Value Prediction",
        "url": "http://arxiv.org/abs/2306.14400v1",
        "pub_date": "2023-06-26",
        "summary": "Accurate customer lifetime value (LTV) prediction can help service providers\noptimize their marketing policies in customer-centric applications. However,\nthe heavy sparsity of consumption events and the interference of data variance\nand noise obstruct LTV estimation. Many existing LTV prediction methods\ndirectly train a single-view LTV predictor on consumption samples, which may\nyield inaccurate and even biased knowledge extraction. In this paper, we\npropose a contrastive multi-view framework for LTV prediction, which is a\nplug-and-play solution compatible with various backbone models. It synthesizes\nmultiple heterogeneous LTV regressors with complementary knowledge to improve\nmodel robustness and captures sample relatedness via contrastive learning to\nmitigate the dependency on data abundance. Concretely, we use a decomposed\nscheme that converts the LTV prediction problem into a combination of\nestimating consumption probability and payment amount. To alleviate the impact\nof noisy data on model learning, we propose a multi-view framework that jointly\noptimizes multiple types of regressors with diverse characteristics and\nadvantages to encode and fuse comprehensive knowledge. To fully exploit the\npotential of limited training samples, we propose a hybrid contrastive learning\nmethod to help capture the relatedness between samples in both classification\nand regression tasks. We conduct extensive experiments on a real-world game LTV\nprediction dataset and the results validate the effectiveness of our method. We\nhave deployed our solution online in Huawei's mobile game center and achieved\n32.26% of total payment amount gains.",
        "translated": "准确的客户生命周期价值(LTV)预测可以帮助服务提供商在以客户为中心的应用程序中优化其营销策略。然而，消耗事件的严重稀疏性以及数据方差和噪声的干扰阻碍了 LTV 估计。许多现有的 LTV 预测方法直接在消费样本上训练单视图 LTV 预测器，这可能会产生不准确甚至有偏差的知识提取。在本文中，我们提出了一个对比的多视图 LTV 预测框架，这是一个即插即用的解决方案，兼容各种骨干模型。它综合了多个具有互补知识的异构 LTV 回归子，提高了模型的鲁棒性，并通过对比学习获取样本相关性，减轻了对数据丰度的依赖性。具体地，我们使用了一个分解方案，将 LTV 预测问题转化为估计消费概率和支付金额的组合。为了减轻噪声数据对模型学习的影响，本文提出了一种多视图框架，该框架联合优化具有不同特征和优势的多类回归模型，对综合知识进行编码和融合。为了充分发挥有限训练样本的潜力，我们提出了一种混合对比学习方法，以帮助捕捉样本之间的相关性分类和回归任务。我们在一个真实的游戏 LTV 预测数据集上进行了广泛的实验，实验结果验证了我们方法的有效性。我们已经在华为的手机游戏中心部署了我们的在线解决方案，实现了总支付金额收益的32.26% 。"
    },
    {
        "title": "FunQA: Towards Surprising Video Comprehension",
        "url": "http://arxiv.org/abs/2306.14899v1",
        "pub_date": "2023-06-26",
        "summary": "Surprising videos, e.g., funny clips, creative performances, or visual\nillusions, attract significant attention. Enjoyment of these videos is not\nsimply a response to visual stimuli; rather, it hinges on the human capacity to\nunderstand (and appreciate) commonsense violations depicted in these videos. We\nintroduce FunQA, a challenging video question answering (QA) dataset\nspecifically designed to evaluate and enhance the depth of video reasoning\nbased on counter-intuitive and fun videos. Unlike most video QA benchmarks\nwhich focus on less surprising contexts, e.g., cooking or instructional videos,\nFunQA covers three previously unexplored types of surprising videos: 1)\nHumorQA, 2) CreativeQA, and 3) MagicQA. For each subset, we establish rigorous\nQA tasks designed to assess the model's capability in counter-intuitive\ntimestamp localization, detailed video description, and reasoning around\ncounter-intuitiveness. We also pose higher-level tasks, such as attributing a\nfitting and vivid title to the video, and scoring the video creativity. In\ntotal, the FunQA benchmark consists of 312K free-text QA pairs derived from\n4.3K video clips, spanning a total of 24 video hours. Extensive experiments\nwith existing VideoQA models reveal significant performance gaps for the FunQA\nvideos across spatial-temporal reasoning, visual-centered reasoning, and\nfree-text generation.",
        "translated": "令人惊讶的视频，例如，有趣的片段，创造性的表演，或视觉幻觉，吸引了大量的注意力。欣赏这些视频不仅仅是对视觉刺激的反应，而是取决于人类理解(和欣赏)这些视频中描述的违反常识的行为的能力。我们介绍 FunQA，一个具有挑战性的视频问题回答(QA)数据集，专门设计来评估和增强基于反直观和有趣的视频的视频推理深度。与大多数视频 QA 基准不同，FunQA 基准侧重于不那么令人惊讶的背景，例如烹饪或教学视频，FunQA 涵盖了三种以前未探索过的令人惊讶的视频类型: 1) HumorQA，2) CreativeQA，和3) MagicQA。对于每个子集，我们建立严格的 QA 任务，旨在评估模型在反直觉时间戳定位、详细视频描述和反直觉推理方面的能力。我们还提出了更高层次的任务，比如为视频赋予一个合适的、生动的标题，以及对视频创造性进行评分。FunQA 基准测试总共由312K 自由文本 QA 对组成，这些 QA 对来自4.3 K 视频剪辑，跨越总共24个视频小时。对现有 VideoQA 模型的大量实验表明，FunQA 视频在时空推理、以视觉为中心的推理和自由文本生成方面存在显著的性能差距。"
    },
    {
        "title": "InterCode: Standardizing and Benchmarking Interactive Coding with\n  Execution Feedback",
        "url": "http://arxiv.org/abs/2306.14898v2",
        "pub_date": "2023-06-26",
        "summary": "Humans write code in a fundamentally interactive manner and rely on constant\nexecution feedback to correct errors, resolve ambiguities, and decompose tasks.\nWhile LLMs have recently exhibited promising coding capabilities, current\ncoding benchmarks mostly consider a static instruction-to-code sequence\ntransduction process, which has the potential for error propagation and a\ndisconnect between the generated code and its final execution environment. To\naddress this gap, we introduce InterCode, a lightweight, flexible, and\neasy-to-use framework of interactive coding as a standard reinforcement\nlearning (RL) environment, with code as actions and execution feedback as\nobservations. Our framework is language and platform agnostic, uses\nself-contained Docker environments to provide safe and reproducible execution,\nand is compatible out-of-the-box with traditional seq2seq coding methods, while\nenabling the development of new methods for interactive code generation. We use\nInterCode to create two interactive code environments with Bash and SQL as\naction spaces, leveraging data from the static Spider and NL2Bash datasets. We\ndemonstrate InterCode's viability as a testbed by evaluating multiple\nstate-of-the-art LLMs configured with different prompting strategies such as\nReAct and Plan &amp; Solve. Our results showcase the benefits of interactive code\ngeneration and demonstrate that InterCode can serve as a challenging benchmark\nfor advancing code understanding and generation capabilities. InterCode is\ndesigned to be easily extensible and can even be used to incorporate new tasks\nsuch as Capture the Flag, a popular coding puzzle that is inherently multi-step\nand involves multiple programming languages. Project site with code and data:\nhttps://intercode-benchmark.github.io",
        "translated": "人类以基本的交互方式编写代码，并依赖于不断的执行反馈来纠正错误、解决模糊性和分解任务。虽然 LLM 最近展示了很有前途的编码能力，但目前的编码基准主要考虑的是静态指令-代码序列转换过程，这种过程有可能导致错误传播，并使生成的代码与其最终执行环境脱节。为了解决这个问题，我们引入了 InterCode，这是一个轻量级的、灵活的、易于使用的交互式编码框架，作为一个标准的强化学习(RL)环境，代码作为操作，执行反馈作为观察。我们的框架与语言和平台无关，使用自包含的 Docker 环境来提供安全和可重复的执行，并且与传统的 seq2seq 编码方法开箱即用兼容，同时支持开发用于交互式代码生成的新方法。我们使用 InterCode 创建两个交互式代码环境，使用 Bash 和 SQL 作为操作空间，利用来自静态 Spider 和 NL2Bash 数据集的数据。我们通过评估配置了不同激励策略(如 ReAct 和 Plan & Solve)的多个最先进的 LLM，展示了 InterCode 作为测试平台的可行性。我们的结果展示了交互式代码生成的好处，并证明了 InterCode 可以作为一个具有挑战性的基准来提高代码理解和生成能力。InterCode 被设计成易于扩展，甚至可以用来合并新的任务，比如 Capture the Flag，这是一种流行的编码难题，本质上是多步骤的，涉及多种编程语言。项目网站的代码和数据:  https://intercode-benchmark.github.io"
    },
    {
        "title": "LongCoder: A Long-Range Pre-trained Language Model for Code Completion",
        "url": "http://arxiv.org/abs/2306.14893v1",
        "pub_date": "2023-06-26",
        "summary": "In this paper, we introduce a new task for code completion that focuses on\nhandling long code input and propose a sparse Transformer model, called\nLongCoder, to address this task. LongCoder employs a sliding window mechanism\nfor self-attention and introduces two types of globally accessible tokens -\nbridge tokens and memory tokens - to improve performance and efficiency. Bridge\ntokens are inserted throughout the input sequence to aggregate local\ninformation and facilitate global interaction, while memory tokens are included\nto highlight important statements that may be invoked later and need to be\nmemorized, such as package imports and definitions of classes, functions, or\nstructures. We conduct experiments on a newly constructed dataset that contains\nlonger code context and the publicly available CodeXGLUE benchmark.\nExperimental results demonstrate that LongCoder achieves superior performance\non code completion tasks compared to previous models while maintaining\ncomparable efficiency in terms of computational resources during inference. All\nthe codes and data are available at https://github.com/microsoft/CodeBERT.",
        "translated": "在本文中，我们介绍了一个新的代码完成任务，重点是处理长代码输入，并提出了一个稀疏变压器模型，所谓的 LongCoder，以解决这一问题。LongCoder 采用滑动窗口机制来自我关注，并引入了两种全局可访问令牌——桥接令牌和内存令牌——以提高性能和效率。在整个输入序列中插入桥标记，以聚合本地信息并促进全局交互，同时包含内存标记，以突出显示可能稍后调用并需要记忆的重要语句，例如包导入和类、函数或结构的定义。我们在一个新构建的数据集上进行实验，该数据集包含更长的代码上下文和公开可用的 CodeXGLUE 基准。实验结果表明，与以前的模型相比，LongCoder 在代码完成任务方面取得了更好的性能，同时在推理过程中保持了可比的计算资源效率。所有的代码和数据都在 https://github.com/microsoft/codebert。"
    },
    {
        "title": "Composing Parameter-Efficient Modules with Arithmetic Operations",
        "url": "http://arxiv.org/abs/2306.14870v1",
        "pub_date": "2023-06-26",
        "summary": "As an efficient alternative to conventional full finetuning,\nparameter-efficient finetuning (PEFT) is becoming the prevailing method to\nadapt pretrained language models. In PEFT, a lightweight module is learned on\neach dataset while the underlying pretrained language model remains unchanged,\nresulting in multiple compact modules representing diverse skills when applied\nto various domains and tasks. In this paper, we propose to compose these\nparameter-efficient modules through linear arithmetic operations in the weight\nspace, thereby integrating different module capabilities. Specifically, we\nfirst define addition and negation operators for the module, and then further\ncompose these two basic operators to perform flexible arithmetic. Our approach\nrequires \\emph{no additional training} and enables highly flexible module\ncomposition. We apply different arithmetic operations to compose the\nparameter-efficient modules for (1) distribution generalization, (2)\nmulti-tasking, (3) unlearning, and (4) domain transfer. Additionally, we extend\nour approach to detoxify Alpaca-LoRA, the latest instruction-tuned large\nlanguage model based on LLaMA. Empirical results demonstrate that our approach\nproduces new and effective parameter-efficient modules that significantly\noutperform existing ones across all settings.",
        "translated": "参数有效微调(PEFT)作为传统全微调的一种有效替代方法，正在成为适应预训练语言模型的主流方法。在 PEFT 中，在每个数据集上学习一个轻量级模块，而底层的预训练语言模型保持不变，导致多个紧凑模块在应用于各种领域和任务时代表不同的技能。本文提出通过权值空间中的线性算术运算来组合这些参数有效的模块，从而集成不同的模块功能。具体地说，我们首先定义了模块的加法运算符和否定运算符，然后进一步组合这两个基本运算符来执行灵活的算术运算。我们的方法不需要额外的训练，并且支持高度灵活的模块组合。我们应用不同的算术运算来组成参数有效的模块: (1)分布泛化，(2)多任务，(3)去学习，和(4)域转移。此外，我们扩展了我们的方法来解毒羊驼-LoRA，最新的指令调优大型语言模型的基础上 LLaMA。实证结果表明，我们的方法产生了新的和有效的参数效率模块，在所有环境中都明显优于现有模块。"
    },
    {
        "title": "Enriching the NArabizi Treebank: A Multifaceted Approach to Supporting\n  an Under-Resourced Language",
        "url": "http://arxiv.org/abs/2306.14866v1",
        "pub_date": "2023-06-26",
        "summary": "In this paper we address the scarcity of annotated data for NArabizi, a\nRomanized form of North African Arabic used mostly on social media, which poses\nchallenges for Natural Language Processing (NLP). We introduce an enriched\nversion of NArabizi Treebank (Seddah et al., 2020) with three main\ncontributions: the addition of two novel annotation layers (named entity\nrecognition and offensive language detection) and a re-annotation of the\ntokenization, morpho-syntactic and syntactic layers that ensure annotation\nconsistency. Our experimental results, using different tokenization schemes,\nshowcase the value of our contributions and highlight the impact of working\nwith non-gold tokenization for NER and dependency parsing. To facilitate future\nresearch, we make these annotations publicly available. Our enhanced NArabizi\nTreebank paves the way for creating sophisticated language models and NLP tools\nfor this under-represented language.",
        "translated": "在本文中，我们解决了 NArabizi 注释数据的稀缺性，这是一种主要在社交媒体上使用的北非阿拉伯语的罗马化形式，给自然语言处理(NLP)带来了挑战。我们介绍了 NArabizi Treebank 的一个丰富版本(Seddah 等，2020) ，其中包含三个主要贡献: 添加两个新的注释层(命名实体识别和攻击性语言检测) ，以及重新注释标记化，形态句法和句法层，以确保注释一致性。我们的实验结果使用不同的标记化方案，展示了我们的贡献的价值，并强调了使用 NER 和依赖性解析的非黄金标记化的影响。为了方便未来的研究，我们将这些注释公开发布。我们增强的 NArabizi Treebank 为为这种代表性不足的语言创建复杂的语言模型和 NLP 工具铺平了道路。"
    },
    {
        "title": "HonestBait: Forward References for Attractive but Faithful Headline\n  Generation",
        "url": "http://arxiv.org/abs/2306.14828v1",
        "pub_date": "2023-06-26",
        "summary": "Current methods for generating attractive headlines often learn directly from\ndata, which bases attractiveness on the number of user clicks and views.\nAlthough clicks or views do reflect user interest, they can fail to reveal how\nmuch interest is raised by the writing style and how much is due to the event\nor topic itself. Also, such approaches can lead to harmful inventions by\nover-exaggerating the content, aggravating the spread of false information. In\nthis work, we propose HonestBait, a novel framework for solving these issues\nfrom another aspect: generating headlines using forward references (FRs), a\nwriting technique often used for clickbait. A self-verification process is\nincluded during training to avoid spurious inventions. We begin with a\npreliminary user study to understand how FRs affect user interest, after which\nwe present PANCO1, an innovative dataset containing pairs of fake news with\nverified news for attractive but faithful news headline generation. Automatic\nmetrics and human evaluations show that our framework yields more attractive\nresults (+11.25% compared to human-written verified news headlines) while\nmaintaining high veracity, which helps promote real information to fight\nagainst fake news.",
        "translated": "目前生成有吸引力的标题的方法通常直接从数据中学习，这种方法基于用户点击和浏览次数的吸引力。虽然点击或浏览确实反映了用户的兴趣，但它们可能无法揭示写作风格引起了多少兴趣，以及有多少是由于事件或主题本身引起的。此外，这种方法可能会导致有害的发明过分夸大的内容，加剧传播虚假信息。在这项工作中，我们提出了 HonestBait，一个从另一个方面解决这些问题的新框架: 使用前向引用(FRs)生成标题，这是一种常用于点击诱饵的写作技巧。培训期间包括自我验证过程，以避免虚假发明。我们从一个初步的用户研究开始，以了解 FRs 如何影响用户的兴趣，然后我们提出 PANCO1，一个创新的数据集，包含对虚假新闻与核实新闻吸引人，但忠实的新闻标题生成。自动测量和人工评估表明，我们的框架产生更有吸引力的结果(+ 11.25% 相比，人写验证新闻标题) ，同时保持高的准确性，这有助于促进真实信息打击假新闻。"
    },
    {
        "title": "Vietnamese multi-document summary using subgraph selection approach --\n  VLSP 2022 AbMuSu Shared Task",
        "url": "http://arxiv.org/abs/2306.14827v1",
        "pub_date": "2023-06-26",
        "summary": "Document summarization is a task to generate afluent, condensed summary for a\ndocument, andkeep important information. A cluster of documents serves as the\ninput for multi-document summarizing (MDS), while the cluster summary serves as\nthe output. In this paper, we focus on transforming the extractive MDS problem\ninto subgraph selection. Approaching the problem in the form of graphs helps to\ncapture simultaneously the relationship between sentences in the same document\nand between sentences in the same cluster based on exploiting the overall graph\nstructure and selected subgraphs. Experiments have been implemented on the\nVietnamese dataset published in VLSP Evaluation Campaign 2022. This model\ncurrently results in the top 10 participating teams reported on the ROUGH-2\n$F\\_1$ measure on the public test set.",
        "translated": "文档摘要是为文档生成丰富、简洁的摘要并保存重要信息的任务。文档集群作为多文档摘要(MDS)的输入，而集群摘要作为输出。本文主要研究如何将抽取 MDS 问题转化为子图选择问题。利用图的整体结构和选择的子图，以图的形式来处理问题，有助于同时捕捉同一文档中的句子之间的关系和同一簇中的句子之间的关系。在2022年 VLSP 评估运动中发布的越南数据集上进行了实验。这个模型目前的结果是公开测试集上 ROUGH-2 $F _ 1 $测量报告的前10个参与团队。"
    },
    {
        "title": "Kosmos-2: Grounding Multimodal Large Language Models to the World",
        "url": "http://arxiv.org/abs/2306.14824v2",
        "pub_date": "2023-06-26",
        "summary": "We introduce Kosmos-2, a Multimodal Large Language Model (MLLM), enabling new\ncapabilities of perceiving object descriptions (e.g., bounding boxes) and\ngrounding text to the visual world. Specifically, we represent refer\nexpressions as links in Markdown, i.e., ``[text span](bounding boxes)'', where\nobject descriptions are sequences of location tokens. Together with multimodal\ncorpora, we construct large-scale data of grounded image-text pairs (called\nGrIT) to train the model. In addition to the existing capabilities of MLLMs\n(e.g., perceiving general modalities, following instructions, and performing\nin-context learning), Kosmos-2 integrates the grounding capability into\ndownstream applications. We evaluate Kosmos-2 on a wide range of tasks,\nincluding (i) multimodal grounding, such as referring expression comprehension,\nand phrase grounding, (ii) multimodal referring, such as referring expression\ngeneration, (iii) perception-language tasks, and (iv) language understanding\nand generation. This work lays out the foundation for the development of\nEmbodiment AI and sheds light on the big convergence of language, multimodal\nperception, action, and world modeling, which is a key step toward artificial\ngeneral intelligence. Data, demo, and pretrained models are available at\nhttps://aka.ms/kosmos-2.",
        "translated": "我们引入了 Kosmos-2，一个多模态大型语言模型(MLLM) ，支持感知对象描述(例如，边界框)和将文本接地到视觉世界的新功能。具体来说，我们将引用表达式表示为 Markdown 中的链接，即“[ text span ](边界框)”，其中对象描述是位置标记的序列。结合多模态语料库，我们构建了大规模的接地图像-文本对(GrIT)数据来训练模型。除了 MLLM 的现有功能(例如，感知一般模式、遵循指令和执行上下文学习) ，Kosmos-2将接地功能集成到下游应用程序中。我们对 Kosmos-2进行了广泛的任务评估，包括(i)多模态基础，如指称表达理解和短语基础，(ii)多模态指称，如指称表达生成，(iii)感知语言任务，以及(iv)语言理解和生成。本文的工作为体验式人工智能的发展奠定了基础，并阐明了语言、多模态感知、动作和世界建模的大趋同性，这是人工一般智能的关键步骤。数据，演示和预先训练的模型可在 https://aka.ms/kosmos-2。"
    },
    {
        "title": "Label-Aware Hyperbolic Embeddings for Fine-grained Emotion\n  Classification",
        "url": "http://arxiv.org/abs/2306.14822v1",
        "pub_date": "2023-06-26",
        "summary": "Fine-grained emotion classification (FEC) is a challenging task.\nSpecifically, FEC needs to handle subtle nuance between labels, which can be\ncomplex and confusing. Most existing models only address text classification\nproblem in the euclidean space, which we believe may not be the optimal\nsolution as labels of close semantic (e.g., afraid and terrified) may not be\ndifferentiated in such space, which harms the performance. In this paper, we\npropose HypEmo, a novel framework that can integrate hyperbolic embeddings to\nimprove the FEC task. First, we learn label embeddings in the hyperbolic space\nto better capture their hierarchical structure, and then our model projects\ncontextualized representations to the hyperbolic space to compute the distance\nbetween samples and labels. Experimental results show that incorporating such\ndistance to weight cross entropy loss substantially improves the performance\nwith significantly higher efficiency. We evaluate our proposed model on two\nbenchmark datasets and found 4.8% relative improvement compared to the previous\nstate of the art with 43.2% fewer parameters and 76.9% less training time. Code\nis available at https: //github.com/dinobby/HypEmo.",
        "translated": "细粒度情绪分类(FEC)是一项具有挑战性的任务。具体来说，FEC 需要处理标签之间的细微差别，这可能是复杂和混乱的。大多数现有的模型只能解决欧几里德空间中的文本分类问题，我们认为这可能不是最佳的解决方案，因为在这样的空间中，封闭语义(例如，害怕和恐惧)的标签可能不会被区分，这会损害性能。在本文中，我们提出了一个新的框架 HypEmo，它可以集成双曲嵌入来改善 FEC 任务。首先，我们学习在双曲空间中嵌入标签，以便更好地捕捉它们的层次结构，然后我们的模型将上下文化的表示投射到双曲空间中，以计算样本和标签之间的距离。实验结果表明，这种距离加权交叉熵损失大大提高了性能，显著提高了效率。我们在两个基准数据集上评估了我们提出的模型，发现与先前的技术水平相比，参数减少了43.2% ，训练时间减少了76.9% ，相对改善了4.8% 。代码可在 https:// github.com/dinobby/hypemo 下载。"
    },
    {
        "title": "A Positive-Unlabeled Metric Learning Framework for Document-Level\n  Relation Extraction with Incomplete Labeling",
        "url": "http://arxiv.org/abs/2306.14806v1",
        "pub_date": "2023-06-26",
        "summary": "The goal of document-level relation extraction (RE) is to identify relations\nbetween entities that span multiple sentences. Recently, incomplete labeling in\ndocument-level RE has received increasing attention, and some studies have used\nmethods such as positive-unlabeled learning to tackle this issue, but there is\nstill a lot of room for improvement. Motivated by this, we propose a\npositive-augmentation and positive-mixup positive-unlabeled metric learning\nframework (P3M). Specifically, we formulate document-level RE as a metric\nlearning problem. We aim to pull the distance closer between entity pair\nembedding and their corresponding relation embedding, while pushing it farther\naway from the none-class relation embedding. Additionally, we adapt the\npositive-unlabeled learning to this loss objective. In order to improve the\ngeneralizability of the model, we use dropout to augment positive samples and\npropose a positive-none-class mixup method. Extensive experiments show that P3M\nimproves the F1 score by approximately 4-10 points in document-level RE with\nincomplete labeling, and achieves state-of-the-art results in fully labeled\nscenarios. Furthermore, P3M has also demonstrated robustness to prior\nestimation bias in incomplete labeled scenarios.",
        "translated": "文档级关系抽取(RE)的目标是识别跨越多个句子的实体之间的关系。近年来，文档级 RE 中的不完全标注问题受到越来越多的关注，一些研究已经采用了积极-未标注学习等方法来解决这一问题，但仍有很大的改进空间。基于此，我们提出了一个正增强和正混合的正未标记度量学习框架(P3M)。具体来说，我们将文档级 RE 作为一个度量学习问题来描述。我们的目标是拉近实体对嵌入与其对应关系嵌入之间的距离，同时使其远离非类关系嵌入。此外，我们调整正向未标记学习来适应这种损失目标。为了提高模型的泛化能力，我们使用辍学来增加正样本，并提出了一种正非类混合方法。大量的实验表明，P3M 在不完全标记的文档级 RE 中提高了 F1评分约4-10分，并在完全标记的场景中取得了最新的结果。此外，在不完全标记的情况下，P3M 也表现出对先前估计偏差的鲁棒性。"
    },
    {
        "title": "Unleashing the Power of User Reviews: Exploring Airline Choices at\n  Catania Airport, Italy",
        "url": "http://arxiv.org/abs/2306.15541v1",
        "pub_date": "2023-06-27",
        "summary": "This study aims to investigate the possible relationship between the\nmechanisms of social influence and the choice of airline, through the use of\nnew tools, with the aim of understanding whether they can contribute to a\nbetter understanding of the factors influencing the decisions of consumers in\nthe aviation sector. We have chosen to extract user reviews from well-known\nplatforms: Trustpilot, Google, and Twitter. By combining web scraping\ntechniques, we have been able to collect a comprehensive dataset comprising a\nwide range of user opinions, feedback, and ratings. We then refined the BERT\nmodel to focus on insightful sentiment in the context of airline reviews.\nThrough our analysis, we observed an intriguing trend of average negative\nsentiment scores across various airlines, giving us deeper insight into the\ndynamics between airlines and helping us identify key partnerships, popular\nroutes, and airlines that play a central role in the aeronautical ecosystem of\nCatania airport during the specified period. Our investigation led us to find\nthat, despite an airline having received prestigious awards as a low-cost\nleader in Europe for two consecutive years 2021 and 2022, the \"Catanese\" user\ntends to suffer the dominant position of other companies. Understanding the\nimpact of positive reviews and leveraging sentiment analysis can help airlines\nimprove their reputation, attract more customers, and ultimately gain a\ncompetitive edge in the marketplace.",
        "translated": "本研究旨在通过使用新工具，调查社会影响机制与航空公司选择之间的可能关系，以了解这些机制是否有助于更好地理解影响航空部门消费者决定的因素。我们选择从著名的平台提取用户评论: TrustPilot、 Google 和 Twitter。通过结合网络抓取技术，我们已经能够收集一个全面的数据集，包括广泛的用户意见，反馈和评级。然后，我们改进了 BERT 模型，将重点放在航空公司评论背景下的深刻情感上。通过我们的分析，我们发现了一个有趣的趋势，即不同航空公司的平均负面情绪得分，这使我们能够更深入地了解航空公司之间的动态，并帮助我们确定在特定时期内在卡塔尼亚机场航空生态系统中发挥核心作用的关键合作伙伴、热门航线和航空公司。我们的调查使我们发现，尽管一家航空公司在2021年和2022年连续两年获得欧洲低成本领先者的殊荣，但“卡塔尼亚”用户往往会受到其他公司的支配地位的影响。了解正面评价的影响力和利用情绪分析可以帮助航空公司提高他们的声誉，吸引更多的客户，并最终获得市场竞争优势。"
    },
    {
        "title": "Learning to Rank in Generative Retrieval",
        "url": "http://arxiv.org/abs/2306.15222v1",
        "pub_date": "2023-06-27",
        "summary": "Generative retrieval is a promising new paradigm in text retrieval that\ngenerates identifier strings of relevant passages as the retrieval target. This\nparadigm leverages powerful generation models and represents a new paradigm\ndistinct from traditional learning-to-rank methods. However, despite its rapid\ndevelopment, current generative retrieval methods are still limited. They\ntypically rely on a heuristic function to transform predicted identifiers into\na passage rank list, which creates a gap between the learning objective of\ngenerative retrieval and the desired passage ranking target. Moreover, the\ninherent exposure bias problem of text generation also persists in generative\nretrieval. To address these issues, we propose a novel framework, called LTRGR,\nthat combines generative retrieval with the classical learning-to-rank\nparadigm. Our approach involves training an autoregressive model using a\npassage rank loss, which directly optimizes the autoregressive model toward the\noptimal passage ranking. This framework only requires an additional training\nstep to enhance current generative retrieval systems and does not add any\nburden to the inference stage. We conducted experiments on three public\ndatasets, and our results demonstrate that LTRGR achieves state-of-the-art\nperformance among generative retrieval methods, indicating its effectiveness\nand robustness.",
        "translated": "生成检索是文本检索领域一个很有前途的新范式，它以相关段落的标识符串作为检索对象。这种模式利用了强大的生成模型，代表了一种有别于传统的学习排名方法的新模式。然而，尽管生成检索技术发展迅速，目前的生成检索方法仍然有限。它们通常依靠启发式函数将预测的标识符转换成一个段落等级列表，从而在生成检索的学习目标和期望的段落等级目标之间产生一个差距。此外，文本生成过程中固有的暴露偏差问题在生成检索中也存在。为了解决这些问题，我们提出了一个新的框架，称为 LTRGR，结合生成检索与经典的学习到秩范式。我们的方法包括训练一个自回归模型使用通过等级损失，直接优化自回归模型的最佳通过等级。该框架只需要一个额外的培训步骤，以加强目前的生成检索系统，并没有增加任何负担的推理阶段。我们在三个公共数据集上进行了实验，结果表明 LTRGR 在生成检索方法中取得了最好的性能，表明了其有效性和鲁棒性。"
    },
    {
        "title": "Off-Policy Evaluation of Ranking Policies under Diverse User Behavior",
        "url": "http://arxiv.org/abs/2306.15098v1",
        "pub_date": "2023-06-26",
        "summary": "Ranking interfaces are everywhere in online platforms. There is thus an ever\ngrowing interest in their Off-Policy Evaluation (OPE), aiming towards an\naccurate performance evaluation of ranking policies using logged data. A\nde-facto approach for OPE is Inverse Propensity Scoring (IPS), which provides\nan unbiased and consistent value estimate. However, it becomes extremely\ninaccurate in the ranking setup due to its high variance under large action\nspaces. To deal with this problem, previous studies assume either independent\nor cascade user behavior, resulting in some ranking versions of IPS. While\nthese estimators are somewhat effective in reducing the variance, all existing\nestimators apply a single universal assumption to every user, causing excessive\nbias and variance. Therefore, this work explores a far more general formulation\nwhere user behavior is diverse and can vary depending on the user context. We\nshow that the resulting estimator, which we call Adaptive IPS (AIPS), can be\nunbiased under any complex user behavior. Moreover, AIPS achieves the minimum\nvariance among all unbiased estimators based on IPS. We further develop a\nprocedure to identify the appropriate user behavior model to minimize the mean\nsquared error (MSE) of AIPS in a data-driven fashion. Extensive experiments\ndemonstrate that the empirical accuracy improvement can be significant,\nenabling effective OPE of ranking systems even under diverse user behavior.",
        "translated": "在线平台中，排序界面无处不在。因此，人们对非策略评估(OPE)越来越感兴趣，其目标是使用日志数据对策略进行准确的性能评估。OPE 的一个事实上的方法是反倾向评分(IPS) ，它提供了一个无偏和一致的价值估计。然而，它变得非常不准确的排名设置，由于其高方差下的大行动空间。为了解决这个问题，以前的研究假设独立或级联用户行为，导致一些排名版本的 IPS。虽然这些估计量在减少方差方面有一定的效果，但是所有现有的估计量都对每个用户适用一个统一的假设，从而导致过度的偏差和方差。因此，这项工作探索了一个更一般的公式，其中用户行为是多样的，可以根据用户上下文而变化。我们证明了所得到的估计量，我们称之为自适应 IPS (AIPS) ，在任何复杂的用户行为下都是无偏的。此外，AIPS 在所有基于 IPS 的无偏估计量之间实现了最小方差。我们进一步开发了一个程序，以确定适当的用户行为模型，从而以数据驱动的方式最大限度地减少 AIPS 的均方差。大量的实验表明，经验的准确性改善可以是显着的，使有效的排名系统的 OPE 即使在不同的用户行为。"
    },
    {
        "title": "Efficient High-Resolution Template Matching with Vector Quantized\n  Nearest Neighbour Fields",
        "url": "http://arxiv.org/abs/2306.15010v1",
        "pub_date": "2023-06-26",
        "summary": "Template matching is a fundamental problem in computer vision and has\napplications in various fields, such as object detection, image registration,\nand object tracking. The current state-of-the-art methods rely on\nnearest-neighbour (NN) matching in which the query feature space is converted\nto NN space by representing each query pixel with its NN in the template\npixels. The NN-based methods have been shown to perform better in occlusions,\nchanges in appearance, illumination variations, and non-rigid transformations.\nHowever, NN matching scales poorly with high-resolution data and high feature\ndimensions. In this work, we present an NN-based template-matching method which\nefficiently reduces the NN computations and introduces filtering in the NN\nfields to consider deformations. A vector quantization step first represents\nthe template with $k$ features, then filtering compares the template and query\ndistributions over the $k$ features. We show that state-of-the-art performance\nwas achieved in low-resolution data, and our method outperforms previous\nmethods at higher resolution showing the robustness and scalability of the\napproach.",
        "translated": "模板匹配是计算机视觉中的一个基本问题，在目标检测、图像配准和目标跟踪等领域有着广泛的应用。目前的方法主要依赖于最近邻(NN)匹配，通过在模板像素中表示每个查询像素及其神经网络，将查询特征空间转换为 NN 空间。基于神经网络的方法已被证明在遮挡、外观变化、光照变化和非刚性转换中表现更好。然而，高分辨率数据和高特征维数的神经网络匹配规模较小。本文提出了一种基于神经网络的模板匹配方法，该方法有效地减少了神经网络的计算量，并在神经网络中引入滤波以考虑变形。一个向量量化步骤首先表示具有 $k $特性的模板，然后过滤比较模板和查询发行版本中的 $k $特性。实验结果表明，该方法在低分辨率数据中取得了较好的性能，并且在较高分辨率下优于以往的方法，显示了该方法的鲁棒性和可扩展性。"
    },
    {
        "title": "SparseOptimizer: Sparsify Language Models through Moreau-Yosida\n  Regularization and Accelerate through Compiler Co-design",
        "url": "http://arxiv.org/abs/2306.15656v1",
        "pub_date": "2023-06-27",
        "summary": "This paper introduces SparseOptimizer, a novel deep learning optimizer that\nexploits Moreau-Yosida regularization to naturally induce sparsity in large\nlanguage models such as BERT, ALBERT and GPT. Key to the design of\nSparseOptimizer is an embedded shrinkage operator, which imparts sparsity\ndirectly within the optimization process. This operator, backed by a sound\ntheoretical framework, includes an analytical solution, thereby reinforcing the\noptimizer's robustness and efficacy. Crucially, SparseOptimizer's plug-and-play\nfunctionality eradicates the need for code modifications, making it a\nuniversally adaptable tool for a wide array of large language models. Empirical\nevaluations on benchmark datasets such as GLUE, RACE, SQuAD1, and SQuAD2\nconfirm that SparseBERT and SparseALBERT, when sparsified using\nSparseOptimizer, achieve performance comparable to their dense counterparts,\nBERT and ALBERT, while significantly reducing their parameter count. Further,\nthis work proposes an innovative optimizer-compiler co-design strategy,\ndemonstrating the potential of inference acceleration (\\textbf{3.37x},\n\\textbf{6.30x}, and \\textbf{7.15x} in comparison with Pytorch, TensorFlow, and\nLLVM generic compile, respectively) in SparseBERT when paired with an\nappropriately designed compiler. This study represents a significant step\nforward in the evolution of efficient, scalable, and high-performing large\nlanguage models, setting a precedent for future exploration and optimization in\nthis domain. The SparseOptimizer code and SparseALBERT model will be made\navailable upon paper acceptance.",
        "translated": "本文介绍了一种新型的深度学习优化器 SparseOptimizer，它利用 Moreau-Yosida 正则化在 BERT、 ALBERT 和 GPT 等大型语言模型中自然地引入稀疏性。稀疏优化器设计的关键是嵌入式收缩算子，它在优化过程中直接赋予稀疏性。这个操作符，由一个健全的理论框架支持，包括一个分析解决方案，从而增强了优化器的健壮性和有效性。至关重要的是，SparseOptimizer 的即插即用功能消除了对代码修改的需要，使其成为一个普遍适用于大量大型语言模型的工具。对基准数据集(如 GLUE、 RACE、 SQuAD1和 SQuAD2)的实证评估证实，当使用 SparseOptimizer 稀疏化时，SparseBERT 和 SparseALBERT 的性能可以与其密集对应的 BERT 和 ALBERT 相媲美，同时大大减少了它们的参数计数。此外，这项工作提出了一个创新的优化器-编译器协同设计策略，展示了推理加速的潜力(textbf {3.37 x } ，textbf {6.30 x } ，和 textbf {7.15 x } ，分别与 Pytorch，TensorFlow 和 LLVM 通用编译进行比较)在 SparseBERT 与适当设计的编译器配对时。这项研究代表了在高效、可扩展和高性能的大型语言模型的发展方面向前迈出的重要一步，为该领域未来的探索和优化开创了先例。SparseOptimizer 代码和 SparseALBERT 模型将在纸张验收时提供。"
    },
    {
        "title": "Style-transfer based Speech and Audio-visual Scene Understanding for\n  Robot Action Sequence Acquisition from Videos",
        "url": "http://arxiv.org/abs/2306.15644v1",
        "pub_date": "2023-06-27",
        "summary": "To realize human-robot collaboration, robots need to execute actions for new\ntasks according to human instructions given finite prior knowledge. Human\nexperts can share their knowledge of how to perform a task with a robot through\nmulti-modal instructions in their demonstrations, showing a sequence of\nshort-horizon steps to achieve a long-horizon goal. This paper introduces a\nmethod for robot action sequence generation from instruction videos using (1)\nan audio-visual Transformer that converts audio-visual features and instruction\nspeech to a sequence of robot actions called dynamic movement primitives (DMPs)\nand (2) style-transfer-based training that employs multi-task learning with\nvideo captioning and weakly-supervised learning with a semantic classifier to\nexploit unpaired video-action data. We built a system that accomplishes various\ncooking actions, where an arm robot executes a DMP sequence acquired from a\ncooking video using the audio-visual Transformer. Experiments with\nEpic-Kitchen-100, YouCookII, QuerYD, and in-house instruction video datasets\nshow that the proposed method improves the quality of DMP sequences by 2.3\ntimes the METEOR score obtained with a baseline video-to-action Transformer.\nThe model achieved 32% of the task success rate with the task knowledge of the\nobject.",
        "translated": "为了实现人机协作，机器人需要根据给定有限先验知识的人工指令执行新任务的操作。人类专家可以在演示中通过多模态指令与机器人分享他们如何执行任务的知识，展示一系列实现长期目标的短期步骤。本文介绍了一种利用(1)音视频转换器将音视频特征和指令语音转换为机器人动作序列即动态运动原语(DMP)的机器人动作序列生成方法，以及(2)基于样式转换的训练方法，该方法采用带视频字幕的多任务学习和带语义分类器的弱监督学习来利用未配对的视频动作数据。我们建立了一个系统，完成各种烹饪动作，其中一个手臂机器人执行一个 DMP 序列从烹饪视频获得使用视听变压器。Epic-Kitchen-100、 YouCookII、 QuerYD 和内部指令视频数据集的实验表明，该方法提高了 DMP 序列的质量，是基线视频到行动变压器获得的 METEOR 评分的2.3倍。该模型利用对象的任务知识实现了32% 的任务成功率。"
    },
    {
        "title": "Automatic Annotation of Direct Speech in Written French Narratives",
        "url": "http://arxiv.org/abs/2306.15634v2",
        "pub_date": "2023-06-27",
        "summary": "The automatic annotation of direct speech (AADS) in written text has been\noften used in computational narrative understanding. Methods based on either\nrules or deep neural networks have been explored, in particular for English or\nGerman languages. Yet, for French, our target language, not many works exist.\nOur goal is to create a unified framework to design and evaluate AADS models in\nFrench. For this, we consolidated the largest-to-date French narrative dataset\nannotated with DS per word; we adapted various baselines for sequence labelling\nor from AADS in other languages; and we designed and conducted an extensive\nevaluation focused on generalisation. Results show that the task still requires\nsubstantial efforts and emphasise characteristics of each baseline. Although\nthis framework could be improved, it is a step further to encourage more\nresearch on the topic.",
        "translated": "书面文本中直接引语的自动注释(AADS)在计算性叙事理解中得到了广泛的应用。基于规则或深层神经网络的方法已经被探索，特别是对于英语或德语。然而，对于我们的目标语言法语来说，没有多少作品存在。我们的目标是创建一个统一的框架来设计和评估法语 AADS 模型。为此，我们整合了迄今为止最大的法语叙事数据集，每个单词用 DS 注释; 我们调整了序列标签或其他语言的 AADS 的各种基线; 我们设计并进行了广泛的评估，重点是泛化。结果表明，这项任务仍然需要大量的努力，并强调每个基线的特点。虽然这个框架可以得到改进，但这是鼓励对这个主题进行更多研究的进一步步骤。"
    },
    {
        "title": "Constructing Multilingual Code Search Dataset Using Neural Machine\n  Translation",
        "url": "http://arxiv.org/abs/2306.15604v1",
        "pub_date": "2023-06-27",
        "summary": "Code search is a task to find programming codes that semantically match the\ngiven natural language queries. Even though some of the existing datasets for\nthis task are multilingual on the programming language side, their query data\nare only in English. In this research, we create a multilingual code search\ndataset in four natural and four programming languages using a neural machine\ntranslation model. Using our dataset, we pre-train and fine-tune the\nTransformer-based models and then evaluate them on multiple code search test\nsets. Our results show that the model pre-trained with all natural and\nprogramming language data has performed best in most cases. By applying\nback-translation data filtering to our dataset, we demonstrate that the\ntranslation quality affects the model's performance to a certain extent, but\nthe data size matters more.",
        "translated": "代码搜索是一项任务，用于查找在语义上匹配给定自然语言查询的编程代码。尽管用于此任务的一些现有数据集在编程语言方面是多语言的，但是它们的查询数据仅使用英语。在这项研究中，我们使用神经机器翻译模型，用四种自然语言和四种编程语言创建了一个多语言的代码搜索数据集。使用我们的数据集，我们预先训练和微调基于 Transformer 的模型，然后在多个代码搜索测试集上对它们进行评估。我们的结果表明，在大多数情况下，使用所有自然语言和编程语言数据预先训练的模型表现最好。通过对我们的数据集进行反向翻译数据过滤，我们发现翻译质量在一定程度上影响了模型的性能，但是数据的大小更重要。"
    },
    {
        "title": "Extending Context Window of Large Language Models via Positional\n  Interpolation",
        "url": "http://arxiv.org/abs/2306.15595v2",
        "pub_date": "2023-06-27",
        "summary": "We present Position Interpolation (PI) that extends the context window sizes\nof RoPE-based pretrained LLMs such as LLaMA models to up to 32768 with minimal\nfine-tuning (within 1000 steps), while demonstrating strong empirical results\non various tasks that require long context, including passkey retrieval,\nlanguage modeling, and long document summarization from LLaMA 7B to 65B.\nMeanwhile, the extended model by Position Interpolation preserve quality\nrelatively well on tasks within its original context window. To achieve this\ngoal, Position Interpolation linearly down-scales the input position indices to\nmatch the original context window size, rather than extrapolating beyond the\ntrained context length which may lead to catastrophically high attention scores\nthat completely ruin the self-attention mechanism. Our theoretical study shows\nthat the upper bound of interpolation is at least $\\sim 600 \\times$ smaller\nthan that of extrapolation, further demonstrating its stability. Models\nextended via Position Interpolation retain its original architecture and can\nreuse most pre-existing optimization and infrastructure.",
        "translated": "我们提出了位置插值(PI) ，扩展了基于 RoPE 的预训练 LLM (如 LLaMA 模型)的上下文窗口大小，以最小的微调(在1000个步骤内)达到32768，同时在需要长上下文的各种任务上展示了强大的经验结果，包括密钥检索，语言建模和从 LLaMA 7B 到65B 的长文档摘要。同时，通过位置插值的扩展模型在其原始上下文窗口中较好地保持了任务的质量。为了达到这个目标，位置插值线性地降低输入位置指数，以匹配原始上下文窗口大小，而不是外推超过训练的上下文长度，这可能导致灾难性的高注意分数，完全破坏了自我注意机制。我们的理论研究表明，插值的上界至少比外推的上界小600倍，进一步证明了插值的稳定性。通过位置插值扩展的模型保留了其原有的体系结构，并且可以重用大多数预先存在的优化和基础设施。"
    },
    {
        "title": "CrunchGPT: A chatGPT assisted framework for scientific machine learning",
        "url": "http://arxiv.org/abs/2306.15551v1",
        "pub_date": "2023-06-27",
        "summary": "Scientific Machine Learning (SciML) has advanced recently across many\ndifferent areas in computational science and engineering. The objective is to\nintegrate data and physics seamlessly without the need of employing elaborate\nand computationally taxing data assimilation schemes. However, preprocessing,\nproblem formulation, code generation, postprocessing and analysis are still\ntime consuming and may prevent SciML from wide applicability in industrial\napplications and in digital twin frameworks. Here, we integrate the various\nstages of SciML under the umbrella of ChatGPT, to formulate CrunchGPT, which\nplays the role of a conductor orchestrating the entire workflow of SciML based\non simple prompts by the user. Specifically, we present two examples that\ndemonstrate the potential use of CrunchGPT in optimizing airfoils in\naerodynamics, and in obtaining flow fields in various geometries in interactive\nmode, with emphasis on the validation stage. To demonstrate the flow of the\nCrunchGPT, and create an infrastructure that can facilitate a broader vision,\nwe built a webapp based guided user interface, that includes options for a\ncomprehensive summary report. The overall objective is to extend CrunchGPT to\nhandle diverse problems in computational mechanics, design, optimization and\ncontrols, and general scientific computing tasks involved in SciML, hence using\nit as a research assistant tool but also as an educational tool. While here the\nexamples focus in fluid mechanics, future versions will target solid mechanics\nand materials science, geophysics, systems biology and bioinformatics.",
        "translated": "科学机器学习(sciML)最近在许多不同的计算科学与工程领域取得了进展。我们的目标是无缝集成数据和物理，而不需要采用复杂的计算数据同化。然而，预处理、问题制定、代码生成、后处理和分析仍然非常耗时，可能会妨碍 SciML 在工业应用和数字双框架中的广泛适用性。在这里，我们将 SciML 的各个阶段集成在 ChatGPT 的保护伞下，以形成 CrunchGPT，它扮演着指挥者的角色，根据用户的简单提示编排 SciML 的整个工作流程。具体来说，我们提出了两个例子，展示了 CrunchGPT 在空气动力学中优化翼型的潜在用途，以及在交互模式下获得各种几何形状的流场，重点是验证阶段。为了演示 CrunchGPT 的流程，并创建一个可以促进更广阔视野的基础设施，我们构建了一个基于 Web 应用的指导用户界面，其中包括一个全面摘要报告的选项。总体目标是扩展 CrunchGPT，以处理计算力学、设计、优化和控制方面的各种问题，以及与 SciML 相关的一般科学计算任务，从而将其用作研究辅助工具，同时也用作教育工具。虽然这里的例子集中在流体力学，未来的版本将针对固体力学和材料科学，地球物理学，系统生物学和生物信息学。"
    },
    {
        "title": "CamemBERT-bio: a Tasty French Language Model Better for your Health",
        "url": "http://arxiv.org/abs/2306.15550v1",
        "pub_date": "2023-06-27",
        "summary": "Clinical data in hospitals are increasingly accessible for research through\nclinical data warehouses, however these documents are unstructured. It is\ntherefore necessary to extract information from medical reports to conduct\nclinical studies. Transfer learning with BERT-like models such as CamemBERT has\nallowed major advances, especially for named entity recognition. However, these\nmodels are trained for plain language and are less efficient on biomedical\ndata. This is why we propose a new French public biomedical dataset on which we\nhave continued the pre-training of CamemBERT. Thus, we introduce a first\nversion of CamemBERT-bio, a specialized public model for the French biomedical\ndomain that shows 2.54 points of F1 score improvement on average on different\nbiomedical named entity recognition tasks.",
        "translated": "医院的临床数据越来越多地可以通过临床数据仓库进行研究，但是这些文档是非结构化的。因此，有必要从医疗报告中提取信息进行临床研究。使用诸如 CamemBERT 之类的 BERT 模型的转移学习已经取得了重大进展，特别是对命名实体识别。然而，这些模型都是针对简单语言进行训练的，对生物医学数据的处理效率较低。这就是为什么我们提出了一个新的法国公共生物医学数据集，我们已经继续在 CamemBERT 的预训练。因此，我们引入了 CamemBERT-bio 的第一个版本，这是法国生物医学领域的专门公共模型，在不同的生物医学命名实体识别任务中平均显示 F1评分改善2.54分。"
    },
    {
        "title": "Paradigm Shift in Sustainability Disclosure Analysis: Empowering\n  Stakeholders with CHATREPORT, a Language Model-Based Tool",
        "url": "http://arxiv.org/abs/2306.15518v1",
        "pub_date": "2023-06-27",
        "summary": "This paper introduces a novel approach to enhance Large Language Models\n(LLMs) with expert knowledge to automate the analysis of corporate\nsustainability reports by benchmarking them against the Task Force for\nClimate-Related Financial Disclosures (TCFD) recommendations. Corporate\nsustainability reports are crucial in assessing organizations' environmental\nand social risks and impacts. However, analyzing these reports' vast amounts of\ninformation makes human analysis often too costly. As a result, only a few\nentities worldwide have the resources to analyze these reports, which could\nlead to a lack of transparency. While AI-powered tools can automatically\nanalyze the data, they are prone to inaccuracies as they lack domain-specific\nexpertise. This paper introduces a novel approach to enhance LLMs with expert\nknowledge to automate the analysis of corporate sustainability reports. We\nchristen our tool CHATREPORT, and apply it in a first use case to assess\ncorporate climate risk disclosures following the TCFD recommendations.\nCHATREPORT results from collaborating with experts in climate science, finance,\neconomic policy, and computer science, demonstrating how domain experts can be\ninvolved in developing AI tools. We make our prompt templates, generated data,\nand scores available to the public to encourage transparency.",
        "translated": "本文介绍了一种新颖的方法来增强大型语言模型(LLM)的专家知识，以自动化的分析公司可持续性报告的基准对气候相关的财务披露工作队(TCFD)的建议。企业可持续性报告对于评估组织的环境和社会风险及影响至关重要。然而，分析这些报告的海量信息往往使人工分析成本过高。因此，全世界只有少数几个实体有资源来分析这些报告，这可能导致缺乏透明度。虽然人工智能驱动的工具可以自动分析数据，但由于缺乏特定领域的专业知识，它们很容易出现错误。本文介绍了一种利用专家知识增强 LLM 的新方法，使企业可持续发展报告的分析自动化。我们将我们的工具命名为 CHATREPORT，并在第一个用例中应用它来评估遵循 TCFD 建议的企业气候风险披露。CHATREPORT 是与气候科学、金融、经济政策和计算机科学领域的专家合作的成果，展示了领域专家如何参与人工智能工具的开发。我们将提示模板、生成的数据和分数提供给公众，以鼓励透明度。"
    },
    {
        "title": "Using Large Language Models to Provide Explanatory Feedback to Human\n  Tutors",
        "url": "http://arxiv.org/abs/2306.15498v1",
        "pub_date": "2023-06-27",
        "summary": "Research demonstrates learners engaging in the process of producing\nexplanations to support their reasoning, can have a positive impact on\nlearning. However, providing learners real-time explanatory feedback often\npresents challenges related to classification accuracy, particularly in\ndomain-specific environments, containing situationally complex and nuanced\nresponses. We present two approaches for supplying tutors real-time feedback\nwithin an online lesson on how to give students effective praise. This\nwork-in-progress demonstrates considerable accuracy in binary classification\nfor corrective feedback of effective, or effort-based (F1 score = 0.811), and\nineffective, or outcome-based (F1 score = 0.350), praise responses. More\nnotably, we introduce progress towards an enhanced approach of providing\nexplanatory feedback using large language model-facilitated named entity\nrecognition, which can provide tutors feedback, not only while engaging in\nlessons, but can potentially suggest real-time tutor moves. Future work\ninvolves leveraging large language models for data augmentation to improve\naccuracy, while also developing an explanatory feedback interface.",
        "translated": "研究表明，学习者在产生解释的过程中支持自己的推理，可以对学习产生积极的影响。然而，为学习者提供实时的解释性反馈往往会带来与分类准确性相关的挑战，特别是在特定领域的环境中，包含情境复杂和微妙的反馈。我们提出了两种方法，以提供实时反馈的在线教学如何给予学生有效的表扬。这项正在进行的工作表明，对于有效的或基于努力的(F1评分 = 0.811)和无效的或基于结果的(F1评分 = 0.350)表扬反馈的纠正反馈的二元分类具有相当大的准确性。更值得注意的是，我们使用大型语言模型促进的命名实体识别引入了提供解释性反馈的强化方法，这种方法不仅可以在上课时提供导师反馈，而且可以潜在地提出实时导师动作。未来的工作包括利用大型语言模型进行数据增强以提高准确性，同时还要开发一个解释性反馈接口。"
    },
    {
        "title": "SE-PQA: Personalized Community Question Answering",
        "url": "http://arxiv.org/abs/2306.16261v1",
        "pub_date": "2023-06-28",
        "summary": "Personalization in Information Retrieval is a topic studied for a long time.\nNevertheless, there is still a lack of high-quality, real-world datasets to\nconduct large-scale experiments and evaluate models for personalized search.\nThis paper contributes to filling this gap by introducing SE-PQA (StackExchange\n- Personalized Question Answering), a new curated resource to design and\nevaluate personalized models related to the task of community Question\nAnswering (cQA). The contributed dataset includes more than 1 million queries\nand 2 million answers, annotated with a rich set of features modeling the\nsocial interactions among the users of a popular cQA platform. We describe the\ncharacteristics of SE-PQA and detail the features associated with questions and\nanswers. We also provide reproducible baseline methods for the cQA task based\non the resource, including deep learning models and personalization approaches.\nThe results of the preliminary experiments conducted show the appropriateness\nof SE-PQA to train effective cQA models; they also show that personalization\nremarkably improves the effectiveness of all the methods tested. Furthermore,\nwe show the benefits in terms of robustness and generalization of combining\ndata from multiple communities for personalization purposes.",
        "translated": "信息检索的个性化是一个长期研究的课题。尽管如此，仍然缺乏高质量的真实世界的数据集来进行大规模的实验和评估个性化检索模型。本文通过引入 SE-PQA 来填补这一空白。 SE-PQA 是一种新的策划资源，用于设计和评估与社区问答任务(cQA)相关的个性化模型。贡献的数据集包括超过100万个查询和200万个答案，并用一组丰富的特性对流行的 cQA 平台的用户之间的社交互动进行了建模。我们描述了 SE-PQA 的特征，并详细描述了与问答相关的特征。我们还为基于资源的 cQA 任务提供了可重复的基线方法，包括深度学习模型和个性化方法。初步实验结果表明，SE-PQA 方法训练有效的 cQA 模型是合适的，并且个性化显著提高了所有测试方法的有效性。此外，我们还展示了将来自多个社区的数据用于个性化目的的健壮性和通用性方面的好处。"
    },
    {
        "title": "Query Understanding in the Age of Large Language Models",
        "url": "http://arxiv.org/abs/2306.16004v1",
        "pub_date": "2023-06-28",
        "summary": "Querying, conversing, and controlling search and information-seeking\ninterfaces using natural language are fast becoming ubiquitous with the rise\nand adoption of large-language models (LLM). In this position paper, we\ndescribe a generic framework for interactive query-rewriting using LLMs. Our\nproposal aims to unfold new opportunities for improved and transparent intent\nunderstanding while building high-performance retrieval systems using LLMs. A\nkey aspect of our framework is the ability of the rewriter to fully specify the\nmachine intent by the search engine in natural language that can be further\nrefined, controlled, and edited before the final retrieval phase. The ability\nto present, interact, and reason over the underlying machine intent in natural\nlanguage has profound implications on transparency, ranking performance, and a\ndeparture from the traditional way in which supervised signals were collected\nfor understanding intents. We detail the concept, backed by initial\nexperiments, along with open questions for this interactive query understanding\nframework.",
        "translated": "随着大语言模型(LLM)的兴起和采用，使用自然语言进行查询、转换和控制搜索和信息搜索界面正迅速变得无处不在。在本文中，我们描述了一个使用 LLM 进行交互式查询重写的通用框架。我们的建议旨在开辟新的机会，以改善和透明的意图理解，同时建立使用 LLM 的高性能检索系统。我们框架的一个关键方面是重写器能够通过自然语言完全指定搜索引擎的机器意图，在最终检索阶段之前可以进一步细化、控制和编辑。在自然语言中呈现、交互和推理潜在机器意图的能力对透明度、排序性能有着深远的影响，并且背离了传统的为理解意图而收集监督信号的方式。我们详细介绍了这个概念，并进行了初步的实验，同时还提出了这个交互式查询理解框架的开放式问题。"
    },
    {
        "title": "Streamlining Social Media Information Retrieval for Public Health\n  Research with Deep Learning",
        "url": "http://arxiv.org/abs/2306.16001v1",
        "pub_date": "2023-06-28",
        "summary": "The utilization of social media in epidemic surveillance has been well\nestablished. Nonetheless, bias is often introduced when pre-defined lexicons\nare used to retrieve relevant corpus. This study introduces a framework aimed\nat curating extensive dictionaries of medical colloquialisms and Unified\nMedical Language System (UMLS) concepts. The framework comprises three modules:\na BERT-based Named Entity Recognition (NER) model that identifies medical\nentities from social media content, a deep-learning powered normalization\nmodule that standardizes the extracted entities, and a semi-supervised\nclustering module that assigns the most probable UMLS concept to each\nstandardized entity. We applied this framework to COVID-19-related tweets from\nFebruary 1, 2020, to April 30, 2022, generating a symptom dictionary (available\nat https://github.com/ningkko/UMLS_colloquialism/) composed of 9,249\nstandardized entities mapped to 876 UMLS concepts and 38,175 colloquial\nexpressions. This framework demonstrates encouraging potential in addressing\nthe constraints of keyword matching information retrieval in social media-based\npublic health research.",
        "translated": "社交媒体在流行病监测中的应用已经得到了很好的证实。然而，当预定义词汇用于检索相关语料时，常常会引入偏倚。这项研究介绍了一个框架，旨在管理广泛的医学术语和一体化医学语言系统(UMLS)概念词典。该框架由三个模块组成: 一个基于 BERT 的命名实体识别(NER)模型，该模型从社交媒体内容中识别医疗实体; 一个深度学习驱动的标准化模块，该模块标准化提取的实体; 以及一个半监督聚类模块，该模块为每个标准化实体分配最可能的 UMLS 概念。我们将这个框架应用于2020年2月1日至2022年4月30日期间与 COVID-19相关的推文，生成了一个症状词典(可在 https://github.com/ningkko/umls_colloquialism/获得) ，由映射到876个 UMLS 概念和38,175个口语表达的9,249个标准化实体组成。这个框架显示了在解决基于社交媒体的公共卫生研究中关键词匹配信息检索的限制方面令人鼓舞的潜力。"
    },
    {
        "title": "Disentangled Variational Auto-encoder Enhanced by Counterfactual Data\n  for Debiasing Recommendation",
        "url": "http://arxiv.org/abs/2306.15961v1",
        "pub_date": "2023-06-28",
        "summary": "Recommender system always suffers from various recommendation biases,\nseriously hindering its development. In this light, a series of debias methods\nhave been proposed in the recommender system, especially for two most common\nbiases, i.e., popularity bias and amplified subjective bias. However, exsisting\ndebias methods usually concentrate on correcting a single bias. Such\nsingle-functionality debiases neglect the bias-coupling issue in which the\nrecommended items are collectively attributed to multiple biases. Besides,\nprevious work cannot tackle the lacking supervised signals brought by sparse\ndata, yet which has become a commonplace in the recommender system. In this\nwork, we introduce a disentangled debias variational auto-encoder\nframework(DB-VAE) to address the single-functionality issue as well as a\ncounterfactual data enhancement method to mitigate the adverse effect due to\nthe data sparsity. In specific, DB-VAE first extracts two types of extreme\nitems only affected by a single bias based on the collier theory, which are\nrespectively employed to learn the latent representation of corresponding\nbiases, thereby realizing the bias decoupling. In this way, the exact unbiased\nuser representation can be learned by these decoupled bias representations.\nFurthermore, the data generation module employs Pearl's framework to produce\nmassive counterfactual data, making up the lacking supervised signals due to\nthe sparse data. Extensive experiments on three real-world datasets demonstrate\nthe effectiveness of our proposed model. Besides, the counterfactual data can\nfurther improve DB-VAE, especially on the dataset with low sparsity.",
        "translated": "推荐系统总是受到各种推荐偏见的困扰，严重阻碍了它的发展。有见及此，推荐系统中提出了一系列的偏差分析方法，特别是针对两种最常见的偏差，即受欢迎程度偏差和放大的主观偏差。然而，现有的偏倚矫正方法通常集中于纠正单一偏倚。这种单一功能的偏差忽略了偏差耦合问题，在这个问题中，推荐的项目被共同归因于多个偏差。此外，以往的研究未能解决稀疏数据所带来的缺乏监督的信号问题，但这已成为推荐系统研究中的一个常见问题。在这项工作中，我们介绍了一个解纠缠去偏差变分自动编码框架(DB-VAE) ，以解决单一功能的问题，以及一个反事实的数据增强方法，以减轻由于数据稀疏造成的不利影响。具体来说，DB-VAE 首先基于 Collier 理论提取两类仅受单一偏差影响的极值项，分别用于学习相应偏差的潜在表示，从而实现偏差解耦。这样，就可以通过这些解耦的偏差表示来学习精确的无偏用户表示。此外，数据生成模块利用 Pearl 的框架生成大量的反事实数据，弥补了由于数据稀疏而导致的监督信号的缺失。在三个真实世界数据集上的大量实验证明了我们提出的模型的有效性。此外，反事实数据可以进一步改善 DB-VAE，特别是对稀疏度较低的数据集。"
    },
    {
        "title": "Pb-Hash: Partitioned b-bit Hashing",
        "url": "http://arxiv.org/abs/2306.15944v1",
        "pub_date": "2023-06-28",
        "summary": "Many hashing algorithms including minwise hashing (MinHash), one permutation\nhashing (OPH), and consistent weighted sampling (CWS) generate integers of $B$\nbits. With $k$ hashes for each data vector, the storage would be $B\\times k$\nbits; and when used for large-scale learning, the model size would be\n$2^B\\times k$, which can be expensive. A standard strategy is to use only the\nlowest $b$ bits out of the $B$ bits and somewhat increase $k$, the number of\nhashes. In this study, we propose to re-use the hashes by partitioning the $B$\nbits into $m$ chunks, e.g., $b\\times m =B$. Correspondingly, the model size\nbecomes $m\\times 2^b \\times k$, which can be substantially smaller than the\noriginal $2^B\\times k$.\n  Our theoretical analysis reveals that by partitioning the hash values into\n$m$ chunks, the accuracy would drop. In other words, using $m$ chunks of $B/m$\nbits would not be as accurate as directly using $B$ bits. This is due to the\ncorrelation from re-using the same hash. On the other hand, our analysis also\nshows that the accuracy would not drop much for (e.g.,) $m=2\\sim 4$. In some\nregions, Pb-Hash still works well even for $m$ much larger than 4. We expect\nPb-Hash would be a good addition to the family of hashing methods/applications\nand benefit industrial practitioners.\n  We verify the effectiveness of Pb-Hash in machine learning tasks, for linear\nSVM models as well as deep learning models. Since the hashed data are\nessentially categorical (ID) features, we follow the standard practice of using\nembedding tables for each hash. With Pb-Hash, we need to design an effective\nstrategy to combine $m$ embeddings. Our study provides an empirical evaluation\non four pooling schemes: concatenation, max pooling, mean pooling, and product\npooling. There is no definite answer which pooling would be always better and\nwe leave that for future study.",
        "translated": "许多散列算法包括 minwise 散列(MinHash)、一个置换散列(OPH)和一致加权抽样(CWS)生成 $B $bit 的整数。对于每个数据向量使用 $k $散列，存储将是 $B 乘以 k $bit; 如果使用大规模学习，模型大小将是 $2 ^ B 乘以 k $，这可能是昂贵的。一个标准的策略是仅使用 $B $bit 中的最低 $b $bit，并稍微增加 $k $，即散列的数量。在这个研究中，我们建议通过将 $B $bit 分割成 $m $block 来重用散列，例如，$b 乘以 m = B $。相应地，模型大小变成 $m 乘以2 ^ b 乘以 k $，这可以大大小于原来的2 ^ B 乘以 k $。我们的理论分析表明，通过将散列值划分为 $m $块，准确性会下降。换句话说，使用 $m $块的 $B/m $bits 不会像直接使用 $B $bits 那样精确。这是由于重用相同哈希引起的相关性。另一方面，我们的分析也表明，对于(例如) $m = 2 sim 4 $，精度不会下降很多。在一些地区，Pb-Hash 甚至在价格远高于4美元的情况下仍然运行良好。我们期望 Pb-Hash 将是散列方法/应用系列的一个很好的补充，并有利于工业实践者。我们验证了 Pb-Hash 在机器学习任务、线性支持向量机模型和深度学习模型方面的有效性。由于散列数据本质上是分类(ID)特性，因此我们遵循对每个散列使用嵌入表的标准实践。使用 Pb-Hash，我们需要设计一个有效的策略来结合 $m $嵌入。我们的研究提供了一个实证评估的四个池方案: 连接，最大池，平均池，和产品池。没有明确的答案，哪一个池总是更好，我们留给未来的研究。"
    },
    {
        "title": "MultiZoo &amp; MultiBench: A Standardized Toolkit for Multimodal Deep\n  Learning",
        "url": "http://arxiv.org/abs/2306.16413v1",
        "pub_date": "2023-06-28",
        "summary": "Learning multimodal representations involves integrating information from\nmultiple heterogeneous sources of data. In order to accelerate progress towards\nunderstudied modalities and tasks while ensuring real-world robustness, we\nrelease MultiZoo, a public toolkit consisting of standardized implementations\nof &gt; 20 core multimodal algorithms and MultiBench, a large-scale benchmark\nspanning 15 datasets, 10 modalities, 20 prediction tasks, and 6 research areas.\nTogether, these provide an automated end-to-end machine learning pipeline that\nsimplifies and standardizes data loading, experimental setup, and model\nevaluation. To enable holistic evaluation, we offer a comprehensive methodology\nto assess (1) generalization, (2) time and space complexity, and (3) modality\nrobustness. MultiBench paves the way towards a better understanding of the\ncapabilities and limitations of multimodal models, while ensuring ease of use,\naccessibility, and reproducibility. Our toolkits are publicly available, will\nbe regularly updated, and welcome inputs from the community.",
        "translated": "学习多模态表示涉及到整合来自多个异构数据源的信息。为了在确保现实世界稳健性的同时加快未被研究的模式和任务的进展，我们发布了 MultiZoo，一个公共工具包，由 > 20个核心多模式算法的标准化实现和 MultiBench 组成，MultiBench 是一个跨越15个数据集，10个模式，20个预测任务和6个研究领域的大规模基准。总之，它们提供了一个自动化的端到端机器学习流水线，可以简化和标准化数据加载、实验设置和模型评估。为了实现整体评估，我们提供了一个综合的方法来评估(1)泛化，(2)时间和空间复杂性，和(3)模态鲁棒性。MultiBench 为更好地理解多模式模型的功能和局限性铺平了道路，同时确保了易用性、可访问性和可重复性。我们的工具包是公开可用的，将定期更新，并欢迎来自社区的输入。"
    },
    {
        "title": "Towards Language Models That Can See: Computer Vision Through the LENS\n  of Natural Language",
        "url": "http://arxiv.org/abs/2306.16410v1",
        "pub_date": "2023-06-28",
        "summary": "We propose LENS, a modular approach for tackling computer vision problems by\nleveraging the power of large language models (LLMs). Our system uses a\nlanguage model to reason over outputs from a set of independent and highly\ndescriptive vision modules that provide exhaustive information about an image.\nWe evaluate the approach on pure computer vision settings such as zero- and\nfew-shot object recognition, as well as on vision and language problems. LENS\ncan be applied to any off-the-shelf LLM and we find that the LLMs with LENS\nperform highly competitively with much bigger and much more sophisticated\nsystems, without any multimodal training whatsoever. We open-source our code at\nhttps://github.com/ContextualAI/lens and provide an interactive demo.",
        "translated": "我们提出 LENS，一种通过利用大型语言模型(LLM)解决计算机视觉问题的模块化方法。我们的系统使用一个语言模型来推理来自一组独立且高度描述性的视觉模块的输出，这些模块提供关于图像的详尽信息。我们评估的方法纯计算机视觉设置，如零和少拍摄物体识别，以及在视觉和语言问题。LENS 可以应用于任何现成的 LLM，我们发现 LENS 的 LLM 在更大和更复杂的系统中表现得非常有竞争力，没有任何多模态训练。我们 https://github.com/contextualai/lens 开源代码并提供交互式演示。"
    },
    {
        "title": "Towards Measuring the Representation of Subjective Global Opinions in\n  Language Models",
        "url": "http://arxiv.org/abs/2306.16388v1",
        "pub_date": "2023-06-28",
        "summary": "Large language models (LLMs) may not equitably represent diverse global\nperspectives on societal issues. In this paper, we develop a quantitative\nframework to evaluate whose opinions model-generated responses are more similar\nto. We first build a dataset, GlobalOpinionQA, comprised of questions and\nanswers from cross-national surveys designed to capture diverse opinions on\nglobal issues across different countries. Next, we define a metric that\nquantifies the similarity between LLM-generated survey responses and human\nresponses, conditioned on country. With our framework, we run three experiments\non an LLM trained to be helpful, honest, and harmless with Constitutional AI.\nBy default, LLM responses tend to be more similar to the opinions of certain\npopulations, such as those from the USA, and some European and South American\ncountries, highlighting the potential for biases. When we prompt the model to\nconsider a particular country's perspective, responses shift to be more similar\nto the opinions of the prompted populations, but can reflect harmful cultural\nstereotypes. When we translate GlobalOpinionQA questions to a target language,\nthe model's responses do not necessarily become the most similar to the\nopinions of speakers of those languages. We release our dataset for others to\nuse and build on. Our data is at\nhttps://huggingface.co/datasets/Anthropic/llm_global_opinions. We also provide\nan interactive visualization at https://llmglobalvalues.anthropic.com.",
        "translated": "大型语言模型(LLM)可能不能公平地代表关于社会问题的多样化的全球视角。在本文中，我们建立了一个定量的框架来评估谁的意见模型生成的反应更相似。我们首先建立一个数据集 GlobalOpinionQA，包括来自跨国调查的问题和答案，旨在收集不同国家对全球问题的不同意见。接下来，我们定义一个度量标准，量化 LLM 生成的调查答复和人类反应之间的相似性，以国家为条件。在我们的框架下，我们在一个训练有素的 LLM 上进行了三个实验，这个 LLM 被训练成有用的、诚实的和无害的人工智能。默认情况下，LLM 的反应往往与某些人群的观点更为相似，例如来自美国以及一些欧洲和南美国家的观点，突出了潜在的偏见。当我们提示模型考虑一个特定国家的观点时，反应会变得更加类似于提示人群的观点，但是反映出有害的文化刻板印象。当我们将 GlobalOpinionQA 问题翻译成目标语言时，模型的回答并不一定与使用这些语言的人的观点最为相似。我们将我们的数据集发布给其他人使用和构建。我们的数据处于 https://huggingface.co/datasets/anthropic/llm_global_opinions。我们还在 https://llmglobalvalues.anthropic.com 上提供了一个交互式可视化。"
    },
    {
        "title": "Multi-Site Clinical Federated Learning using Recursive and Attentive\n  Models and NVFlare",
        "url": "http://arxiv.org/abs/2306.16367v1",
        "pub_date": "2023-06-28",
        "summary": "The prodigious growth of digital health data has precipitated a mounting\ninterest in harnessing machine learning methodologies, such as natural language\nprocessing (NLP), to scrutinize medical records, clinical notes, and other\ntext-based health information. Although NLP techniques have exhibited\nsubstantial potential in augmenting patient care and informing clinical\ndecision-making, data privacy and adherence to regulations persist as critical\nconcerns. Federated learning (FL) emerges as a viable solution, empowering\nmultiple organizations to train machine learning models collaboratively without\ndisseminating raw data. This paper proffers a pragmatic approach to medical NLP\nby amalgamating FL, NLP models, and the NVFlare framework, developed by NVIDIA.\nWe introduce two exemplary NLP models, the Long-Short Term Memory (LSTM)-based\nmodel and Bidirectional Encoder Representations from Transformers (BERT), which\nhave demonstrated exceptional performance in comprehending context and\nsemantics within medical data. This paper encompasses the development of an\nintegrated framework that addresses data privacy and regulatory compliance\nchallenges while maintaining elevated accuracy and performance, incorporating\nBERT pretraining, and comprehensively substantiating the efficacy of the\nproposed approach.",
        "translated": "数字健康数据的巨大增长促使人们对利用机器学习方法(如自然语言处理(NLP))来仔细检查医疗记录、临床记录和其他基于文本的健康信息产生了越来越大的兴趣。尽管 NLP 技术在增强患者护理和为临床决策提供信息方面显示出巨大的潜力，但数据隐私和遵守规定仍然是关键问题。联邦学习(FL)作为一种可行的解决方案出现了，它赋予多个组织在不传播原始数据的情况下协同训练机器学习模型的权力。本文通过融合 FL、 NLP 模型和 NVFlare 框架，提出了一种实用的医学自然语言处理方法。我们介绍了两个典型的自然语言处理模型，基于长短期记忆(LSTM)的模型和来自变压器的双向编码器表示(BERT) ，它们在理解医学数据中的上下文和语义方面表现出优异的性能。本文包括开发一个综合框架，解决数据隐私和守规的挑战，同时保持提高的准确性和性能，结合 BERT 预训练，并全面证实拟议方法的有效性。"
    },
    {
        "title": "Representation Learning via Variational Bayesian Networks",
        "url": "http://arxiv.org/abs/2306.16326v1",
        "pub_date": "2023-06-28",
        "summary": "We present Variational Bayesian Network (VBN) - a novel Bayesian entity\nrepresentation learning model that utilizes hierarchical and relational side\ninformation and is particularly useful for modeling entities in the\n``long-tail'', where the data is scarce. VBN provides better modeling for\nlong-tail entities via two complementary mechanisms: First, VBN employs\ninformative hierarchical priors that enable information propagation between\nentities sharing common ancestors. Additionally, VBN models explicit relations\nbetween entities that enforce complementary structure and consistency, guiding\nthe learned representations towards a more meaningful arrangement in space.\nSecond, VBN represents entities by densities (rather than vectors), hence\nmodeling uncertainty that plays a complementary role in coping with data\nscarcity. Finally, we propose a scalable Variational Bayes optimization\nalgorithm that enables fast approximate Bayesian inference. We evaluate the\neffectiveness of VBN on linguistic, recommendations, and medical inference\ntasks. Our findings show that VBN outperforms other existing methods across\nmultiple datasets, and especially in the long-tail.",
        "translated": "我们提出了变分贝氏网路(vbN)——一种新的贝叶斯实体表示学习模型，它利用了层次和关系侧信息，特别适用于数据稀缺的“长尾”实体建模。VBN 通过两种互补的机制为长尾实体提供了更好的建模: 首先，VBN 使用了信息丰富的层次先验，这使得共享共同祖先的实体之间的信息传播成为可能。此外，VBN 模型明确的实体之间的关系，强制互补结构和一致性，指导学习表示更有意义的安排在空间。其次，VBN 通过密度(而不是向量)表示实体，因此建模不确定性在处理数据稀缺性方面起到补充作用。最后，我们提出了一个可扩展的变分贝叶斯优化算法，它可以实现快速的近似贝叶斯推断。我们评估 VBN 在语言、推荐和医学推理任务中的有效性。我们的研究结果表明，VBN 在跨多个数据集的性能优于其他现有的方法，特别是在长尾方面。"
    },
    {
        "title": "Taqyim: Evaluating Arabic NLP Tasks Using ChatGPT Models",
        "url": "http://arxiv.org/abs/2306.16322v1",
        "pub_date": "2023-06-28",
        "summary": "Large language models (LLMs) have demonstrated impressive performance on\nvarious downstream tasks without requiring fine-tuning, including ChatGPT, a\nchat-based model built on top of LLMs such as GPT-3.5 and GPT-4. Despite having\na lower training proportion compared to English, these models also exhibit\nremarkable capabilities in other languages. In this study, we assess the\nperformance of GPT-3.5 and GPT-4 models on seven distinct Arabic NLP tasks:\nsentiment analysis, translation, transliteration, paraphrasing, part of speech\ntagging, summarization, and diacritization. Our findings reveal that GPT-4\noutperforms GPT-3.5 on five out of the seven tasks. Furthermore, we conduct an\nextensive analysis of the sentiment analysis task, providing insights into how\nLLMs achieve exceptional results on a challenging dialectal dataset.\nAdditionally, we introduce a new Python interface\nhttps://github.com/ARBML/Taqyim that facilitates the evaluation of these tasks\neffortlessly.",
        "translated": "大型语言模型(LLM)已经在不需要微调的各种下游任务上展示了令人印象深刻的性能，包括 ChatGPT，一种基于聊天的模型，建立在 LLM 之上，如 GPT-3.5和 GPT-4。尽管与英语相比，这些模式的训练比例较低，但它们在其他语言方面也表现出显著的能力。在这项研究中，我们评估了 GPT-3.5和 GPT-4模型在七个不同的阿拉伯语 NLP 任务中的表现: 情感分析，翻译，音译，释义，部分语音标签，摘要和非字符化。我们的研究结果表明，GPT-4在七项任务中的五项上表现优于 GPT-3.5。此外，我们进行了广泛的情绪分析任务的分析，提供深入的见解，如何实现一个具有挑战性的方言数据集 LLM 异常的结果。此外，我们还引入了一个新的 Python 界面 https://github.com/arbml/taqyim  ，可以轻松地评估这些任务。"
    },
    {
        "title": "An Adversarial Multi-Task Learning Method for Chinese Text Correction\n  with Semantic Detection",
        "url": "http://arxiv.org/abs/2306.16313v1",
        "pub_date": "2023-06-28",
        "summary": "Text correction, especially the semantic correction of more widely used\nscenes, is strongly required to improve, for the fluency and writing efficiency\nof the text. An adversarial multi-task learning method is proposed to enhance\nthe modeling and detection ability of character polysemy in Chinese sentence\ncontext. Wherein, two models, the masked language model and scoring language\nmodel, are introduced as a pair of not only coupled but also adversarial\nlearning tasks. Moreover, the Monte Carlo tree search strategy and a policy\nnetwork are introduced to accomplish the efficient Chinese text correction task\nwith semantic detection. The experiments are executed on three datasets and\nfive comparable methods, and the experimental results show that our method can\nobtain good performance in Chinese text correction task for better semantic\nrationality.",
        "translated": "为了提高文本的流畅性和写作效率，文本校正尤其是应用较为广泛的场景的语义校正是亟待提高的。提出了一种对抗性多任务学习方法，以提高汉语句子语境中字符多义现象的建模和检测能力。其中，两个模型，掩蔽语言模型和评分语言模型，被引入作为一对不仅是耦合的，而且是对抗性的学习任务。此外，引入了蒙特卡罗树搜索策略和策略网络，实现了具有语义检测的高效中文文本校正任务。实验结果表明，该方法在中文文本校正任务中能够取得较好的效果，具有较好的语义合理性。"
    },
    {
        "title": "Leveraging GPT-4 for Food Effect Summarization to Enhance\n  Product-Specific Guidance Development via Iterative Prompting",
        "url": "http://arxiv.org/abs/2306.16275v1",
        "pub_date": "2023-06-28",
        "summary": "Food effect summarization from New Drug Application (NDA) is an essential\ncomponent of product-specific guidance (PSG) development and assessment.\nHowever, manual summarization of food effect from extensive drug application\nreview documents is time-consuming, which arouses a need to develop automated\nmethods. Recent advances in large language models (LLMs) such as ChatGPT and\nGPT-4, have demonstrated great potential in improving the effectiveness of\nautomated text summarization, but its ability regarding the accuracy in\nsummarizing food effect for PSG assessment remains unclear. In this study, we\nintroduce a simple yet effective approach, iterative prompting, which allows\none to interact with ChatGPT or GPT-4 more effectively and efficiently through\nmulti-turn interaction. Specifically, we propose a three-turn iterative\nprompting approach to food effect summarization in which the keyword-focused\nand length-controlled prompts are respectively provided in consecutive turns to\nrefine the quality of the generated summary. We conduct a series of extensive\nevaluations, ranging from automated metrics to FDA professionals and even\nevaluation by GPT-4, on 100 NDA review documents selected over the past five\nyears. We observe that the summary quality is progressively improved throughout\nthe process. Moreover, we find that GPT-4 performs better than ChatGPT, as\nevaluated by FDA professionals (43% vs. 12%) and GPT-4 (64% vs. 35%).\nImportantly, all the FDA professionals unanimously rated that 85% of the\nsummaries generated by GPT-4 are factually consistent with the golden reference\nsummary, a finding further supported by GPT-4 rating of 72% consistency. These\nresults strongly suggest a great potential for GPT-4 to draft food effect\nsummaries that could be reviewed by FDA professionals, thereby improving the\nefficiency of PSG assessment cycle and promoting the generic drug product\ndevelopment.",
        "translated": "新药应用中的食品效果总结是产品特异性指导(PSG)开发和评估的重要组成部分。然而，从广泛的药物应用审查文件中手工总结食品效应是一项耗时的工作，这就引起了开发自动化方法的需要。ChatGPT 和 GPT-4等大型语言模型(LLM)的最新进展显示了提高自动文本摘要有效性的巨大潜力，但其在总结 PSG 评估的食物效应准确性方面的能力尚不清楚。在这项研究中，我们介绍了一个简单而有效的方法，迭代提示，它允许一个人与 ChatGPT 或 GPT-4交互更有效和高效地通过多回合的交互。具体而言，我们提出了一种三回合迭代提示方法来进行食物效果总结，其中关键字重点和长度控制的提示分别在连续的回合中提供，以完善生成的总结的质量。我们进行了一系列广泛的评估，从自动化指标到 FDA 专业人员，甚至 GPT-4的评估，对过去五年中选定的100个 NDA 审查文件进行评估。我们观察到总结质量在整个过程中逐步得到改进。此外，我们发现 GPT-4的表现优于 ChatGPT，FDA 专业人员对此进行了评估(43% 比12%)和 GPT-4(64% 比35%)。重要的是，所有 FDA 专业人员一致认为 GPT-4产生的总结中有85% 与黄金参考总结实际上是一致的，这一发现得到了 GPT-4评分72% 一致性的进一步支持。这些结果强烈表明 GPT-4起草可供 FDA 专业人员审查的食品效应摘要的巨大潜力，从而提高 PSG 评估周期的效率，促进仿制药产品的开发。"
    },
    {
        "title": "Emotion Analysis of Tweets Banning Education in Afghanistan",
        "url": "http://arxiv.org/abs/2306.16268v1",
        "pub_date": "2023-06-28",
        "summary": "This paper introduces the first emotion annotated dataset for the Dari\nvariant of Persian spoken in Afghanistan. The LetHerLearn dataset contains\n7,600 tweets posted in reaction to the Taliban ban of women rights to education\nin 2022 and has been manually annotated according to Ekman emotion categories.\nWe here detail the data collection and annotation process, present relevant\ndataset statistics as well as initial experiments on the resulting dataset,\nbenchmarking a number of different neural architectures for the task of Dari\nemotion classification.",
        "translated": "本文介绍了第一个情绪注释数据集的达日变体的波斯语在阿富汗说。LetHerLearning 数据集包含7,600条针对塔利班2022年禁止妇女接受教育权而发布的推文，并根据 Ekman 情绪类别进行了人工注释。我们在这里详细介绍数据收集和注释的过程，提供相关的数据集统计数据，以及最终数据集的初步实验，并为达日情绪分类的任务建立了多种不同的神经结构。"
    },
    {
        "title": "CBBQ: A Chinese Bias Benchmark Dataset Curated with Human-AI\n  Collaboration for Large Language Models",
        "url": "http://arxiv.org/abs/2306.16244v1",
        "pub_date": "2023-06-28",
        "summary": "Holistically measuring societal biases of large language models is crucial\nfor detecting and reducing ethical risks in highly capable AI models. In this\nwork, we present a Chinese Bias Benchmark dataset that consists of over 100K\nquestions jointly constructed by human experts and generative language models,\ncovering stereotypes and societal biases in 14 social dimensions related to\nChinese culture and values. The curation process contains 4 essential steps:\nbias identification via extensive literature review, ambiguous context\ngeneration, AI-assisted disambiguous context generation, snd manual review \\&amp;\nrecomposition. The testing instances in the dataset are automatically derived\nfrom 3K+ high-quality templates manually authored with stringent quality\ncontrol. The dataset exhibits wide coverage and high diversity. Extensive\nexperiments demonstrate the effectiveness of the dataset in detecting model\nbias, with all 10 publicly available Chinese large language models exhibiting\nstrong bias in certain categories. Additionally, we observe from our\nexperiments that fine-tuned models could, to a certain extent, heed\ninstructions and avoid generating outputs that are morally harmful in some\ntypes, in the way of \"moral self-correction\". Our dataset and results are\npublicly available at\n\\href{https://github.com/YFHuangxxxx/CBBQ}{https://github.com/YFHuangxxxx/CBBQ},\noffering debiasing research opportunities to a widened community.",
        "translated": "全面衡量大型语言模型的社会偏见对于发现和减少高能人工智能模型中的伦理风险至关重要。在这项工作中，我们提出了一个中国偏见基准数据集，由人类专家和生成语言模型共同构建的超过10万个问题，涵盖了与中国文化和价值观相关的14个社会维度的刻板印象和社会偏见。策划过程包括4个基本步骤: 通过广泛的文献综述进行偏倚识别、模糊上下文生成、人工智能辅助的模糊上下文生成、以及人工审查和重组。数据集中的测试实例是自动从3K + 高质量模板中派生出来的，这些模板是通过严格的质量控制手工编写的。该数据集具有广泛的覆盖面和高度的多样性。大量的实验证明了该数据集在检测模型偏差方面的有效性，所有10个公开的中文大语言模型在某些类别中表现出强烈的偏差。此外，我们从实验中观察到，微调模型可以在一定程度上听从指令，避免产生在某些类型中对道德有害的输出，即“道德自我纠正”。我们的数据集和结果可以在 href { https://github.com/yfhuangxxxx/cbbq }{ https://github.com/yfhuangxxxx/cbbq }上公开获得，为更广泛的社区提供了减少偏见的研究机会。"
    },
    {
        "title": "Ducho: A Unified Framework for the Extraction of Multimodal Features in\n  Recommendation",
        "url": "http://arxiv.org/abs/2306.17125v1",
        "pub_date": "2023-06-29",
        "summary": "In multimodal-aware recommendation, the extraction of meaningful multimodal\nfeatures is at the basis of high-quality recommendations. Generally, each\nrecommendation framework implements its multimodal extraction procedures with\nspecific strategies and tools. This is limiting for two reasons: (i) different\nextraction strategies do not ease the interdependence among multimodal\nrecommendation frameworks; thus, they cannot be efficiently and fairly\ncompared; (ii) given the large plethora of pre-trained deep learning models\nmade available by different open source tools, model designers do not have\naccess to shared interfaces to extract features. Motivated by the outlined\naspects, we propose Ducho, a unified framework for the extraction of multimodal\nfeatures in recommendation. By integrating three widely-adopted deep learning\nlibraries as backends, namely, TensorFlow, PyTorch, and Transformers, we\nprovide a shared interface to extract and process features where each backend's\nspecific methods are abstracted to the end user. Noteworthy, the extraction\npipeline is easily configurable with a YAML-based file where the user can\nspecify, for each modality, the list of models (and their specific\nbackends/parameters) to perform the extraction. Finally, to make Ducho\naccessible to the community, we build a public Docker image equipped with a\nready-to-use CUDA environment and propose three demos to test its\nfunctionalities for different scenarios and tasks. The GitHub repository and\nthe documentation is accessible at this link:\nhttps://github.com/sisinflab/Ducho.",
        "translated": "在多模态推荐中，有意义的多模态特征的提取是高质量推荐的基础。通常，每个推荐框架使用特定的策略和工具实现其多模式提取过程。这种限制有两个原因: (i)不同的提取策略不能缓解多模式推荐框架之间的相互依赖性; 因此，它们不能有效和公平地进行比较; (ii)鉴于由不同的开源工具提供的大量预先训练的深度学习模型，模型设计者没有访问共享接口来提取特征。基于这些方面，我们提出了 Ducho，一个用于提取推荐中的多模态特征的统一框架。通过集成三个广泛采用的深度学习库作为后端，即 TensorFlow、 PyTorch 和 Transformers，我们提供了一个共享接口来提取和处理特性，其中每个后端的特定方法被抽象到最终用户。值得注意的是，提取管道很容易用基于 YAML 的文件进行配置，用户可以在该文件中为每种模式指定执行提取的模型列表(及其特定的后端/参数)。最后，为了使 Ducho 能够被社区所接受，我们建立了一个公共的 Docker 图像，配备了一个可以随时使用的 CUDA 环境，并提出了三个演示来测试它在不同场景和任务中的功能。GitHub 存储库和文档可以通过以下链接访问:  https://GitHub.com/sisinflab/ducho。"
    },
    {
        "title": "Re-Rank - Expand - Repeat: Adaptive Query Expansion for Document\n  Retrieval Using Words and Entities",
        "url": "http://arxiv.org/abs/2306.17082v1",
        "pub_date": "2023-06-29",
        "summary": "Sparse and dense pseudo-relevance feedback (PRF) approaches perform poorly on\nchallenging queries due to low precision in first-pass retrieval. However,\nrecent advances in neural language models (NLMs) can re-rank relevant documents\nto top ranks, even when few are in the re-ranking pool. This paper first\naddresses the problem of poor pseudo-relevance feedback by simply applying\nre-ranking prior to query expansion and re-executing this query. We find that\nthis change alone can improve the retrieval effectiveness of sparse and dense\nPRF approaches by 5-8%. Going further, we propose a new expansion model, Latent\nEntity Expansion (LEE), a fine-grained word and entity-based relevance\nmodelling incorporating localized features. Finally, we include an \"adaptive\"\ncomponent to the retrieval process, which iteratively refines the re-ranking\npool during scoring using the expansion model, i.e. we \"re-rank - expand -\nrepeat\". Using LEE, we achieve (to our knowledge) the best NDCG, MAP and R@1000\nresults on the TREC Robust 2004 and CODEC adhoc document datasets,\ndemonstrating a significant advancement in expansion effectiveness.",
        "translated": "稀疏和密集伪相关反馈(PRF)方法在挑战性查询中表现不佳，这是由于首次检索的精度较低。然而，神经语言模型(NLM)的最新进展可以将相关文档重新排列到最高级别，即使重新排列的文档很少。本文首先通过简单地在查询扩展之前重新排序并重新执行查询，解决了伪相关反馈较差的问题。我们发现单独这种改变可以提高稀疏和密集 PRF 方法的检索效率5-8% 。进一步，我们提出了一个新的扩展模型，潜在的实体扩展(LEE) ，一个细粒度的词和基于实体的相关性建模结合本地化特征。最后，我们在检索过程中加入了一个“自适应”组件，该组件在使用扩展模型进行评分期间迭代地改进重新排序池，即我们“重新排序-扩展-重复”。使用 LEE，我们在 TREC Robust 2004和 CODEC 特设文档数据集上获得了(据我们所知)最好的 NDCG，MAP 和 R@1000结果，表明在扩展有效性方面取得了显着进展。"
    },
    {
        "title": "Harnessing the Power of Hugging Face Transformers for Predicting Mental\n  Health Disorders in Social Networks",
        "url": "http://arxiv.org/abs/2306.16891v1",
        "pub_date": "2023-06-29",
        "summary": "Early diagnosis of mental disorders and intervention can facilitate the\nprevention of severe injuries and the improvement of treatment results. Using\nsocial media and pre-trained language models, this study explores how\nuser-generated data can be used to predict mental disorder symptoms. Our study\ncompares four different BERT models of Hugging Face with standard machine\nlearning techniques used in automatic depression diagnosis in recent\nliterature. The results show that new models outperform the previous approach\nwith an accuracy rate of up to 97%. Analyzing the results while complementing\npast findings, we find that even tiny amounts of data (like users' bio\ndescriptions) have the potential to predict mental disorders. We conclude that\nsocial media data is an excellent source of mental health screening, and\npre-trained models can effectively automate this critical task.",
        "translated": "对精神障碍的早期诊断和干预有助于预防严重创伤，提高治疗效果。利用社会媒体和预先训练的语言模型，这项研究探讨了如何使用用户生成的数据可以用来预测精神障碍症状。本研究比较了近年来文献中用于抑郁症自动诊断的标准机器学习技术和四种不同的“拥抱脸”BERT 模型。结果表明，新的模型优于以前的方法，准确率高达97% 。分析结果，同时补充过去的发现，我们发现，即使是微量的数据(如用户的生物描述)有可能预测精神障碍。我们的结论是，社会媒体数据是一个良好的来源，心理健康筛查，并预先训练的模型可以有效地自动化这一关键任务。"
    },
    {
        "title": "Computing all-vs-all MEMs in grammar-compressed text",
        "url": "http://arxiv.org/abs/2306.16815v1",
        "pub_date": "2023-06-29",
        "summary": "We describe a compression-aware method to compute all-vs-all maximal exact\nmatches (MEM) among strings of a repetitive collection $\\mathcal{T}$. The key\nconcept in our work is the construction of a fully-balanced grammar\n$\\mathcal{G}$ from $\\mathcal{T}$ that meets a property that we call\n\\emph{fix-free}: the expansions of the nonterminals that have the same height\nin the parse tree form a fix-free set (i.e., prefix-free and suffix-free). The\nfix-free property allows us to compute the MEMs of $\\mathcal{T}$ incrementally\nover $\\mathcal{G}$ using a standard suffix-tree-based MEM algorithm, which runs\non a subset of grammar rules at a time and does not decompress nonterminals. By\nmodifying the locally-consistent grammar of Christiansen et al 2020., we show\nhow we can build $\\mathcal{G}$ from $\\mathcal{T}$ in linear time and space. We\nalso demonstrate that our MEM algorithm runs on top of $\\mathcal{G}$ in $O(G\n+occ)$ time and uses $O(\\log G(G+occ))$ bits, where $G$ is the grammar size,\nand $occ$ is the number of MEMs in $\\mathcal{T}$. In the conclusions, we\ndiscuss how our idea can be modified to implement approximate pattern matching\nin compressed space.",
        "translated": "我们描述了一种感知压缩的方法来计算重复集合 $mathcal { T } $的字符串之间的全对全最大精确匹配(MEM)。我们工作中的关键概念是构造一个完全平衡的文法 $mathcal { G } $，它满足我们称之为 emph { fix-free }的属性: 在解析树中具有相同高度的非终端的扩展形成一个 fix-free 集(即，无前缀和无后缀)。无修复特性允许我们使用基于后缀树的标准 MEM 算法来计算 $mathcal { T } $在 $mathcal { G } $上的 MEM，该算法一次运行在一个语法规则子集上，并且不对非终端进行解压缩。通过修改 Christiansen 等人2020年的局部一致性语法。，我们展示了如何在线性时间和空间中从 $mathcal { T } $构建 $mathcal { G } $。我们还演示了我们的 MEM 算法在 $O (G + occ) $time 中运行在 $mathcal { G } $之上，并使用 $O (log G (G + occ)) $bit，其中 $G $是文法大小，$occ $是 $mathal { T } $中的 MEM 数目。在结论中，我们讨论了如何修改我们的想法以在压缩空间中实现近似模式匹配。"
    },
    {
        "title": "Transfer Learning with Semi-Supervised Dataset Annotation for Birdcall\n  Classification",
        "url": "http://arxiv.org/abs/2306.16760v1",
        "pub_date": "2023-06-29",
        "summary": "We present working notes on transfer learning with semi-supervised dataset\nannotation for the BirdCLEF 2023 competition, focused on identifying African\nbird species in recorded soundscapes. Our approach utilizes existing\noff-the-shelf models, BirdNET and MixIT, to address representation and labeling\nchallenges in the competition. We explore the embedding space learned by\nBirdNET and propose a process to derive an annotated dataset for supervised\nlearning. Our experiments involve various models and feature engineering\napproaches to maximize performance on the competition leaderboard. The results\ndemonstrate the effectiveness of our approach in classifying bird species and\nhighlight the potential of transfer learning and semi-supervised dataset\nannotation in similar tasks.",
        "translated": "我们为 BirdCLEF 2023比赛提交了关于半监督数据集注释的迁移学习的工作笔记，重点是在录制的音景中识别非洲鸟类物种。我们的方法利用现有的现成模型，BirdNET 和 MixIT，来解决竞争中的表示和标签挑战。我们探索了 BirdNET 学到的嵌入空间，并提出了一个为监督式学习推导注释数据集的过程。我们的实验包括各种模型和特征工程方法，以最大限度地提高在竞争排行榜上的表现。实验结果表明了该方法在鸟类分类中的有效性，并突出了转移学习和半监督数据集注释在类似任务中的潜力。"
    },
    {
        "title": "Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4,\n  and Human Tutors",
        "url": "http://arxiv.org/abs/2306.17156v1",
        "pub_date": "2023-06-29",
        "summary": "Generative AI and large language models hold great promise in enhancing\ncomputing education by powering next-generation educational technologies for\nintroductory programming. Recent works have studied these models for different\nscenarios relevant to programming education; however, these works are limited\nfor several reasons, as they typically consider already outdated models or only\nspecific scenario(s). Consequently, there is a lack of a systematic study that\nbenchmarks state-of-the-art models for a comprehensive set of programming\neducation scenarios. In our work, we systematically evaluate two models,\nChatGPT (based on GPT-3.5) and GPT-4, and compare their performance with human\ntutors for a variety of scenarios. We evaluate using five introductory Python\nprogramming problems and real-world buggy programs from an online platform, and\nassess performance using expert-based annotations. Our results show that GPT-4\ndrastically outperforms ChatGPT (based on GPT-3.5) and comes close to human\ntutors' performance for several scenarios. These results also highlight\nsettings where GPT-4 still struggles, providing exciting future directions on\ndeveloping techniques to improve the performance of these models.",
        "translated": "生成式人工智能和大型语言模型为下一代教育技术的入门编程提供动力，从而在加强计算机教育方面具有巨大的前景。最近的工作已经针对与编程教育相关的不同场景研究了这些模型; 然而，这些工作由于几个原因而受到限制，因为它们通常考虑已经过时的模型或者只考虑特定的场景。因此，缺乏一个系统的研究，基准国家的最先进的模型为一套全面的编程教育情景。在我们的工作中，我们系统地评估了两个模型，ChatGPT (基于 GPT-3.5)和 GPT-4，并比较了它们在各种情景下与人类导师的表现。我们使用五个入门级 Python 编程问题和来自在线平台的实际 bug 程序进行评估，并使用基于专家的注释评估性能。我们的研究结果表明，GPT-4的性能显著优于 ChatGPT (基于 GPT-3.5) ，并且在几种情况下接近于人类导师的性能。这些结果也突出了 GPT-4仍在努力的设置，为开发技术以改善这些模型的性能提供了令人兴奋的未来方向。"
    },
    {
        "title": "LLaVAR: Enhanced Visual Instruction Tuning for Text-Rich Image\n  Understanding",
        "url": "http://arxiv.org/abs/2306.17107v1",
        "pub_date": "2023-06-29",
        "summary": "Instruction tuning unlocks the superior capability of Large Language Models\n(LLM) to interact with humans. Furthermore, recent instruction-following\ndatasets include images as visual inputs, collecting responses for image-based\ninstructions. However, visual instruction-tuned models cannot comprehend\ntextual details within images well. This work enhances the current visual\ninstruction tuning pipeline with text-rich images (e.g., movie posters, book\ncovers, etc.). Specifically, we first use publicly available OCR tools to\ncollect results on 422K text-rich images from the LAION dataset. Moreover, we\nprompt text-only GPT-4 with recognized texts and image captions to generate 16K\nconversations, each containing question-answer pairs for text-rich images. By\ncombining our collected data with previous multi-modal instruction-following\ndata, our model, LLaVAR, substantially improves the LLaVA model's capability on\ntext-based VQA datasets (up to 20% accuracy improvement) while achieving an\naccuracy of 91.42% on ScienceQA. The GPT-4-based instruction-following\nevaluation also demonstrates the improvement of our model on both natural\nimages and text-rich images. Through qualitative analysis, LLaVAR shows\npromising interaction (e.g., reasoning, writing, and elaboration) skills with\nhumans based on the latest real-world online content that combines text and\nimages. We make our code/data/models publicly available at\nhttps://llavar.github.io/.",
        "translated": "指令调优解锁了大型语言模型(LLM)与人类交互的优越能力。此外，最近的指令跟踪数据集包括图像作为视觉输入，收集基于图像的指令的响应。然而，视觉教学调优模型不能很好地理解图像中的文本细节。这项工作通过文本丰富的图像(例如，电影海报、书籍封面等)增强了当前的可视化教学调优流程。具体来说，我们首先使用公开可用的 OCR 工具从 LAION 数据集中收集422K 文本丰富的图像的结果。此外，我们提示只有文本的 GPT-4与可识别的文本和图像标题生成16K 会话，每个包含文本丰富的图像的问题-答案对。通过将我们收集的数据与以前的多模态指令跟踪数据相结合，我们的模型 LLaVAR 大大提高了 LLaVA 模型对基于文本的 VQA 数据集的能力(提高了20% 的准确性) ，同时在 ScienceQA 上实现了91.42% 的准确性。基于 GPT-4的指令跟踪评估也证明了该模型对自然图像和文本丰富图像的改进。通过定性分析，LLaVAR 展示了基于结合文本和图像的最新现实世界在线内容与人类的互动(例如，推理、写作和阐述)技能。我们把我们的代码/数据/模型在 https://llavar.github.io/上公开。"
    },
    {
        "title": "LyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by\n  Whispering to ChatGPT",
        "url": "http://arxiv.org/abs/2306.17103v1",
        "pub_date": "2023-06-29",
        "summary": "We introduce LyricWhiz, a robust, multilingual, and zero-shot automatic\nlyrics transcription method achieving state-of-the-art performance on various\nlyrics transcription datasets, even in challenging genres such as rock and\nmetal. Our novel, training-free approach utilizes Whisper, a weakly supervised\nrobust speech recognition model, and GPT-4, today's most performant chat-based\nlarge language model. In the proposed method, Whisper functions as the \"ear\" by\ntranscribing the audio, while GPT-4 serves as the \"brain,\" acting as an\nannotator with a strong performance for contextualized output selection and\ncorrection. Our experiments show that LyricWhiz significantly reduces Word\nError Rate compared to existing methods in English and can effectively\ntranscribe lyrics across multiple languages. Furthermore, we use LyricWhiz to\ncreate the first publicly available, large-scale, multilingual lyrics\ntranscription dataset with a CC-BY-NC-SA copyright license, based on\nMTG-Jamendo, and offer a human-annotated subset for noise level estimation and\nevaluation. We anticipate that our proposed method and dataset will advance the\ndevelopment of multilingual lyrics transcription, a challenging and emerging\ntask.",
        "translated": "我们介绍 LyricWhiz，一个强大的，多语言，和零拍摄自动歌词转录方法实现最先进的表现在各种歌词转录数据集，甚至在具有挑战性的流派，如摇滚和金属。我们新颖的、无需训练的方法使用了 Whisper (一种弱监督的鲁棒语音识别模型)和 GPT-4(当今最高性能的基于聊天的大型语言模型)。在提出的方法中，Whisper 通过转录音频作为“耳朵”，而 GPT-4作为“大脑”，充当注释器，具有很强的上下文输出选择和校正性能。我们的实验表明，与现有的英语方法相比，LyricWhiz 显著降低了单词错误率，并能有效地转录多种语言的歌词。此外，我们使用 LyricWhiz 创建第一个公开可用的，大规模的，多语言的歌词转录数据集，具有 CC-BY-NC-SA 版权许可，基于 MTG-Jamendo，并提供用于噪声水平估计和评估的人类注释子集。我们期望我们提出的方法和数据集将推动多语言歌词转录的发展，这是一个具有挑战性和新兴的任务。"
    },
    {
        "title": "Concept-Oriented Deep Learning with Large Language Models",
        "url": "http://arxiv.org/abs/2306.17089v1",
        "pub_date": "2023-06-29",
        "summary": "Large Language Models (LLMs) have been successfully used in many\nnatural-language tasks and applications including text generation and AI\nchatbots. They also are a promising new technology for concept-oriented deep\nlearning (CODL). However, the prerequisite is that LLMs understand concepts and\nensure conceptual consistency. We discuss these in this paper, as well as major\nuses of LLMs for CODL including concept extraction from text, concept graph\nextraction from text, and concept learning. Human knowledge consists of both\nsymbolic (conceptual) knowledge and embodied (sensory) knowledge. Text-only\nLLMs, however, can represent only symbolic (conceptual) knowledge. Multimodal\nLLMs, on the other hand, are capable of representing the full range (conceptual\nand sensory) of human knowledge. We discuss conceptual understanding in\nvisual-language LLMs, the most important multimodal LLMs, and major uses of\nthem for CODL including concept extraction from image, concept graph extraction\nfrom image, and concept learning. While uses of LLMs for CODL are valuable\nstandalone, they are particularly valuable as part of LLM applications such as\nAI chatbots.",
        "translated": "大语言模型(LLM)已经成功地应用于许多自然语言任务和应用中，包括文本生成和人工智能聊天机器人。它们也是面向概念的深度学习(CODL)的一种有前途的新技术。然而，前提是 LLM 理解概念并确保概念的一致性。本文讨论了这些问题，以及 LLM 在 CODL 中的主要应用，包括从文本中提取概念，从文本中提取概念图，以及概念学习。人类知识包括符号(概念)知识和体现(感官)知识。然而，纯文本 LLM 只能表示符号(概念)知识。另一方面，多模式 LLM 能够表示人类知识的全部范围(概念和感官)。本文讨论了可视化语言 LLM 中的概念理解，即最重要的多模态 LLM，以及它们在 CODL 中的主要应用，包括从图像中提取概念、从图像中提取概念图和概念学习。虽然对 CODL 使用 LLM 是有价值的独立使用，但作为 LLM 应用程序(如 AI 聊天机器人)的一部分，它们尤其有价值。"
    },
    {
        "title": "The mapKurator System: A Complete Pipeline for Extracting and Linking\n  Text from Historical Maps",
        "url": "http://arxiv.org/abs/2306.17059v1",
        "pub_date": "2023-06-29",
        "summary": "Documents hold spatial focus and valuable locality characteristics. For\nexample, descriptions of listings in real estate or travel blogs contain\ninformation about specific local neighborhoods. This information is valuable to\ncharacterize how humans perceive their environment. However, the first step to\nmaking use of this information is to identify the spatial focus (e.g., a city)\nof a document. Traditional approaches for identifying the spatial focus of a\ndocument rely on detecting and disambiguating toponyms from the document. This\napproach requires a vocabulary set of location phrases and ad-hoc rules, which\nignore important words related to location. Recent topic modeling approaches\nusing large language models often consider a few topics, each with broad\ncoverage. In contrast, the spatial focus of a document can be a country, a\ncity, or even a neighborhood, which together, is much larger than the number of\ntopics considered in these approaches. Additionally, topic modeling methods are\noften applied to broad topics of news articles where context is easily\ndistinguishable. To identify the geographic focus of a document effectively, we\npresent a simple but effective Joint Embedding of multi-LocaLitY (JELLY), which\njointly learns representations with separate encoders of document and location.\nJELLY significantly outperforms state-of-the-art methods for identifying\nspatial focus from documents from a number of sources. We also demonstrate case\nstudies on the arithmetic of the learned representations, including identifying\ncities with similar locality characteristics and zero-shot learning to identify\ndocument spatial focus.",
        "translated": "文献具有空间聚焦性和地域性特征。例如，房地产或旅游博客中的列表描述包含有关特定当地社区的信息。这些信息对于描述人类如何感知周围环境很有价值。然而，利用这些信息的第一步是识别文档的空间焦点(例如，城市)。确定文件空间重点的传统方法依赖于从文件中检测和消除地名的歧义。这种方法需要一组位置短语和特别规则，这些规则忽略与位置相关的重要词汇。最近使用大型语言模型的主题建模方法通常考虑几个主题，每个主题都有广泛的涵盖范围。相比之下，一个文档的空间焦点可以是一个国家、一个城市，甚至是一个社区，它们加在一起要比这些方法中考虑的主题数量大得多。此外，主题建模方法通常应用于新闻文章中容易区分上下文的广泛主题。为了有效地识别文档的地理焦点，我们提出了一种简单而有效的多 LocaLitY (JELLY)联合嵌入方法，它通过文档和位置的单独编码器共同学习表示。JELLY 在从多个来源的文档中识别空间焦点方面的性能明显优于最先进的方法。我们还展示了学习表征算法的案例研究，包括识别具有相似地域特征的城市和零点学习识别文档空间焦点。"
    },
    {
        "title": "Towards Grammatical Tagging for the Legal Language of Cybersecurity",
        "url": "http://arxiv.org/abs/2306.17042v1",
        "pub_date": "2023-06-29",
        "summary": "Legal language can be understood as the language typically used by those\nengaged in the legal profession and, as such, it may come both in spoken or\nwritten form. Recent legislation on cybersecurity obviously uses legal language\nin writing, thus inheriting all its interpretative complications due to the\ntypical abundance of cases and sub-cases as well as to the general richness in\ndetail. This paper faces the challenge of the essential interpretation of the\nlegal language of cybersecurity, namely of the extraction of the essential\nParts of Speech (POS) from the legal documents concerning cybersecurity. The\nchallenge is overcome by our methodology for POS tagging of legal language. It\nleverages state-of-the-art open-source tools for Natural Language Processing\n(NLP) as well as manual analysis to validate the outcomes of the tools. As a\nresult, the methodology is automated and, arguably, general for any legal\nlanguage following minor tailoring of the preprocessing step. It is\ndemonstrated over the most relevant EU legislation on cybersecurity, namely on\nthe NIS 2 directive, producing the first, albeit essential, structured\ninterpretation of such a relevant document. Moreover, our findings indicate\nthat tools such as SpaCy and ClausIE reach their limits over the legal language\nof the NIS 2.",
        "translated": "法律语言可以被理解为从事法律职业的人通常使用的语言，因此，它可以是口头或书面形式。最近关于网络安全的立法显然使用了书面法律语言，从而继承了其所有解释性复杂性，这是由于典型的大量案例和子案例以及一般丰富的细节。本文面临着网络安全法律语言本质解释的挑战，即从网络安全法律文书中提取本质词语。我们的法律语言词性标注方法克服了这一挑战。它利用最先进的自然语言处理(NLP)开源工具以及手工分析来验证工具的结果。因此，这种方法是自动的，而且可以说，对于预处理步骤进行了少量裁剪之后的任何法律语言都是通用的。它体现在欧盟最相关的网络安全立法，即 NIS 2指令上，产生了对这样一个相关文件的第一个，尽管是必要的，结构化的解释。此外，我们的研究结果表明，工具，如 SpaCy 和 ClausIE 达到他们的限制，在法律语言的 NIS 2。"
    },
    {
        "title": "Exploring &amp; Exploiting High-Order Graph Structure for Sparse Knowledge\n  Graph Completion",
        "url": "http://arxiv.org/abs/2306.17034v1",
        "pub_date": "2023-06-29",
        "summary": "Sparse knowledge graph (KG) scenarios pose a challenge for previous Knowledge\nGraph Completion (KGC) methods, that is, the completion performance decreases\nrapidly with the increase of graph sparsity. This problem is also exacerbated\nbecause of the widespread existence of sparse KGs in practical applications. To\nalleviate this challenge, we present a novel framework, LR-GCN, that is able to\nautomatically capture valuable long-range dependency among entities to\nsupplement insufficient structure features and distill logical reasoning\nknowledge for sparse KGC. The proposed approach comprises two main components:\na GNN-based predictor and a reasoning path distiller. The reasoning path\ndistiller explores high-order graph structures such as reasoning paths and\nencodes them as rich-semantic edges, explicitly compositing long-range\ndependencies into the predictor. This step also plays an essential role in\ndensifying KGs, effectively alleviating the sparse issue. Furthermore, the path\ndistiller further distills logical reasoning knowledge from these mined\nreasoning paths into the predictor. These two components are jointly optimized\nusing a well-designed variational EM algorithm. Extensive experiments and\nanalyses on four sparse benchmarks demonstrate the effectiveness of our\nproposed method.",
        "translated": "稀疏知识图(KG)场景对以往的知识图完成(KGC)方法提出了挑战，即随着图稀疏度的增加，完成性能迅速下降。由于实际应用中普遍存在稀疏的幼稚园，这个问题更加严重。为了缓解这一挑战，我们提出了一个新的框架，LR-gcn，它能够自动捕获实体之间有价值的长期依赖，以补充不足的结构特征，并提取稀疏的逻辑推理知识。该方法包括两个主要部分: 基于 GNN 的预测器和推理路径提取器。推理路径提取器探索诸如推理路径之类的高阶图结构，并将它们编码为丰富的语义边，显式地将远程依赖组合到预测器中。此步骤亦有助增加幼稚园的密度，有效纾缓幼稚园人口稀少的问题。此外，路径蒸馏器进一步从这些挖掘的推理路径中提取逻辑推理知识到预测器中。这两个部分共同优化使用良好设计的变分 EM 算法。通过对四个稀疏基准测试的大量实验和分析，证明了该方法的有效性。"
    },
    {
        "title": "Classifying Crime Types using Judgment Documents from Social Media",
        "url": "http://arxiv.org/abs/2306.17020v1",
        "pub_date": "2023-06-29",
        "summary": "The task of determining crime types based on criminal behavior facts has\nbecome a very important and meaningful task in social science. But the problem\nfacing the field now is that the data samples themselves are unevenly\ndistributed, due to the nature of the crime itself. At the same time, data sets\nin the judicial field are less publicly available, and it is not practical to\nproduce large data sets for direct training. This article proposes a new\ntraining model to solve this problem through NLP processing methods. We first\npropose a Crime Fact Data Preprocessing Module (CFDPM), which can balance the\ndefects of uneven data set distribution by generating new samples. Then we use\na large open source dataset (CAIL-big) as our pretraining dataset and a small\ndataset collected by ourselves for Fine-tuning, giving it good generalization\nability to unfamiliar small datasets. At the same time, we use the improved\nBert model with dynamic masking to improve the model. Experiments show that the\nproposed method achieves state-of-the-art results on the present dataset. At\nthe same time, the effectiveness of module CFDPM is proved by experiments. This\narticle provides a valuable methodology contribution for classifying social\nscience texts such as criminal behaviors. Extensive experiments on public\nbenchmarks show that the proposed method achieves new state-of-the-art results.",
        "translated": "根据犯罪行为事实确定犯罪类型的任务已经成为社会科学中一项非常重要和有意义的任务。但现在该领域面临的问题是，由于犯罪本身的性质，数据样本本身的分布是不均匀的。与此同时，司法领域的数据集较少公开，为直接培训生产大型数据集是不切实际的。本文通过自然语言处理的方法，提出了一种新的训练模型来解决这个问题。我们首先提出了一个犯罪事实数据预处理模块(CFDPM) ，它通过生成新的样本来平衡数据集分布不均匀的缺陷。然后我们使用一个大的开源数据集(CAIL-big)作为我们的预训练数据集和一个我们自己收集的小数据集进行微调，使其具有对不熟悉的小数据集很好的泛化能力。同时，采用改进的带动态掩蔽的 Bert 模型对模型进行了改进。实验结果表明，该方法在目前的数据集上取得了较好的效果。同时，通过实验验证了 CFDPM 模块的有效性。本文为犯罪行为等社会科学文本的分类提供了有价值的方法论贡献。对公共基准测试的大量实验表明，该方法取得了较好的效果。"
    },
    {
        "title": "High-Quality Automatic Voice Over with Accurate Alignment: Supervision\n  through Self-Supervised Discrete Speech Units",
        "url": "http://arxiv.org/abs/2306.17005v1",
        "pub_date": "2023-06-29",
        "summary": "The goal of Automatic Voice Over (AVO) is to generate speech in sync with a\nsilent video given its text script. Recent AVO frameworks built upon\ntext-to-speech synthesis (TTS) have shown impressive results. However, the\ncurrent AVO learning objective of acoustic feature reconstruction brings in\nindirect supervision for inter-modal alignment learning, thus limiting the\nsynchronization performance and synthetic speech quality. To this end, we\npropose a novel AVO method leveraging the learning objective of self-supervised\ndiscrete speech unit prediction, which not only provides more direct\nsupervision for the alignment learning, but also alleviates the mismatch\nbetween the text-video context and acoustic features. Experimental results show\nthat our proposed method achieves remarkable lip-speech synchronization and\nhigh speech quality by outperforming baselines in both objective and subjective\nevaluations. Code and speech samples are publicly available.",
        "translated": "自动语音技术(AVO)的目标是根据文本脚本生成与无声视频同步的语音。最近建立在文本到语音合成(TTS)基础上的 AVO 框架已经显示出令人印象深刻的结果。然而，目前声学特征重构的 AVO 学习目标对多模态对齐学习带来了间接监督，从而限制了同步性能和合成语音质量。为此，我们提出了一种新的 AVO 方法，该方法利用自监督离散语音单元预测的学习目标，不仅为对齐学习提供了更直接的监督，而且减少了文本-视频上下文和声学特征之间的不匹配。实验结果表明，该方法在客观评价和主观评价方面均优于基线，实现了较好的唇语音同步，提高了语音质量。代码和语音样本是公开的。"
    },
    {
        "title": "MEMD-ABSA: A Multi-Element Multi-Domain Dataset for Aspect-Based\n  Sentiment Analysis",
        "url": "http://arxiv.org/abs/2306.16956v1",
        "pub_date": "2023-06-29",
        "summary": "Aspect-based sentiment analysis is a long-standing research interest in the\nfield of opinion mining, and in recent years, researchers have gradually\nshifted their focus from simple ABSA subtasks to end-to-end multi-element ABSA\ntasks. However, the datasets currently used in the research are limited to\nindividual elements of specific tasks, usually focusing on in-domain settings,\nignoring implicit aspects and opinions, and with a small data scale. To address\nthese issues, we propose a large-scale Multi-Element Multi-Domain dataset\n(MEMD) that covers the four elements across five domains, including nearly\n20,000 review sentences and 30,000 quadruples annotated with explicit and\nimplicit aspects and opinions for ABSA research. Meanwhile, we evaluate\ngenerative and non-generative baselines on multiple ABSA subtasks under the\nopen domain setting, and the results show that open domain ABSA as well as\nmining implicit aspects and opinions remain ongoing challenges to be addressed.\nThe datasets are publicly released at \\url{https://github.com/NUSTM/MEMD-ABSA}.",
        "translated": "基于方面的情绪分析是意见挖掘领域的一个长期研究热点，近年来研究者们已经逐渐从简单的 ABSA 子任务转向端到端的多元 ABSA 任务。然而，目前研究中使用的数据集仅限于特定任务的单个元素，通常侧重于领域内设置，忽略隐含的方面和意见，并且数据规模较小。为了解决这些问题，我们提出了一个大规模的多元素多领域数据集(MEMD) ，涵盖五个领域的四个元素，包括近20,000个评论句子和30,000个四元素注释明确和隐含的方面和意见的 ABSA 研究。同时，我们评估了开放领域环境下多个 ABSA 子任务的生成基线和非生成基线，结果表明，开放领域 ABSA 以及挖掘隐含的方面和意见仍然是有待解决的挑战。数据集在 url { https://github.com/nustm/memd-absa }公开发布。"
    },
    {
        "title": "Precision Anti-Cancer Drug Selection via Neural Ranking",
        "url": "http://arxiv.org/abs/2306.17771v1",
        "pub_date": "2023-06-30",
        "summary": "Personalized cancer treatment requires a thorough understanding of complex\ninteractions between drugs and cancer cell lines in varying genetic and\nmolecular contexts. To address this, high-throughput screening has been used to\ngenerate large-scale drug response data, facilitating data-driven computational\nmodels. Such models can capture complex drug-cell line interactions across\nvarious contexts in a fully data-driven manner. However, accurately\nprioritizing the most sensitive drugs for each cell line still remains a\nsignificant challenge. To address this, we developed neural ranking approaches\nthat leverage large-scale drug response data across multiple cell lines from\ndiverse cancer types. Unlike existing approaches that primarily utilize\nregression and classification techniques for drug response prediction, we\nformulated the objective of drug selection and prioritization as a drug ranking\nproblem. In this work, we proposed two neural listwise ranking methods that\nlearn latent representations of drugs and cell lines, and then use those\nrepresentations to score drugs in each cell line via a learnable scoring\nfunction. Specifically, we developed a neural listwise ranking method,\nList-One, on top of the existing method ListNet. Additionally, we proposed a\nnovel listwise ranking method, List-All, that focuses on all the sensitive\ndrugs instead of the top sensitive drug, unlike List-One. Our results\ndemonstrate that List-All outperforms the best baseline with significant\nimprovements of as much as 8.6% in hit@20 across 50% test cell lines.\nFurthermore, our analyses suggest that the learned latent spaces from our\nproposed methods demonstrate informative clustering structures and capture\nrelevant underlying biological features. Moreover, our comprehensive empirical\nevaluation provides a thorough and objective comparison of the performance of\ndifferent methods (including our proposed ones).",
        "translated": "个性化的癌症治疗需要彻底了解药物和癌细胞系在不同遗传和分子背景下的复杂相互作用。为了解决这个问题，high throughput 已经被用来产生大规模的药物反应数据，促进数据驱动的计算模型。这样的模型能够以完全数据驱动的方式捕获不同环境下复杂的药物-细胞系相互作用。然而，为每个细胞系准确地确定最敏感药物的优先顺序仍然是一个重大的挑战。为了解决这个问题，我们开发了神经排序方法，利用来自不同癌症类型的多个细胞系的大规模药物反应数据。与主要利用回归和分类技术进行药物反应预测的现有方法不同，我们将药物选择和优先排序作为一个药物排序问题来制定目标。在这项工作中，我们提出了两个神经列表排序方法，学习潜在表示的药物和细胞系，然后使用这些表示评分药物在每个细胞系通过可学习的评分函数。具体来说，我们在现有的 ListNet 方法之上开发了一个神经列表排序方法 List-One。此外，我们提出了一种新的列表排序方法，列表-所有，重点放在所有的敏感药物，而不是最敏感的药物，不同于列表-一。我们的研究结果表明，List-All 在50% 的测试细胞系中，hit@20的显著改善高达8.6% ，优于最佳基线。此外，我们的分析表明，从我们提出的方法学习潜在空间显示信息聚类结构和捕获相关的潜在生物学特征。此外，我们的综合实证评估为不同方法(包括我们提出的方法)的表现提供了一个彻底和客观的比较。"
    },
    {
        "title": "Outcome-based Evaluation of Systematic Review Automation",
        "url": "http://arxiv.org/abs/2306.17614v1",
        "pub_date": "2023-06-30",
        "summary": "Current methods of evaluating search strategies and automated citation\nscreening for systematic literature reviews typically rely on counting the\nnumber of relevant and not relevant publications. This established practice,\nhowever, does not accurately reflect the reality of conducting a systematic\nreview, because not all included publications have the same influence on the\nfinal outcome of the systematic review. More specifically, if an important\npublication gets excluded or included, this might significantly change the\noverall review outcome, while not including or excluding less influential\nstudies may only have a limited impact. However, in terms of evaluation\nmeasures, all inclusion and exclusion decisions are treated equally and,\ntherefore, failing to retrieve publications with little to no impact on the\nreview outcome leads to the same decrease in recall as failing to retrieve\ncrucial publications. We propose a new evaluation framework that takes into\naccount the impact of the reported study on the overall systematic review\noutcome. We demonstrate the framework by extracting review meta-analysis data\nand estimating outcome effects using predictions from ranking runs on\nsystematic reviews of interventions from CLEF TAR 2019 shared task. We further\nmeasure how closely the obtained outcomes are to the outcomes of the original\nreview if the arbitrary rankings were used. We evaluate 74 runs using the\nproposed framework and compare the results with those obtained using standard\nIR measures. We find that accounting for the difference in review outcomes\nleads to a different assessment of the quality of a system than if traditional\nevaluation measures were used. Our analysis provides new insights into the\nevaluation of retrieval results in the context of systematic review automation,\nemphasising the importance of assessing the usefulness of each document beyond\nbinary relevance.",
        "translated": "目前评估搜索策略和系统文献综述的自动引文筛选的方法通常依赖于计算相关和非相关出版物的数量。然而，这种既定做法并不能准确反映系统综述的实际情况，因为并非所有纳入的出版物对系统综述的最终结果都有同样的影响。更具体地说，如果一个重要的出版物被排除或纳入，这可能会显着改变总体评价结果，而不包括或排除影响力较小的研究可能只有有限的影响。然而，就评价措施而言，所有列入和排除决定都得到平等对待，因此，未能检索对审查结果影响不大或没有影响的出版物，导致回收率的下降与未能检索关键出版物的下降相同。我们提出一个新的评估框架，考虑到所报告的研究对整体系统综述结果的影响。我们通过从 CLEF TAR 2019共享任务中对干预措施的系统评价中提取评价荟萃分析数据并使用排名预测来估计结果效应来展示该框架。如果使用任意排名，我们进一步测量所得结果与原始评价结果的接近程度。我们使用提出的框架评估了74次运行，并将结果与使用标准红外测量获得的结果进行了比较。我们发现，与使用传统评价方法相比，考虑评价结果的差异会导致对系统质量的不同评价。我们的分析为在系统综述自动化背景下评估检索结果提供了新的见解，强调了评估每个文档的有用性超越二进制相关性的重要性。"
    },
    {
        "title": "Large Language Models are Effective Text Rankers with Pairwise Ranking\n  Prompting",
        "url": "http://arxiv.org/abs/2306.17563v1",
        "pub_date": "2023-06-30",
        "summary": "Ranking documents using Large Language Models (LLMs) by directly feeding the\nquery and candidate documents into the prompt is an interesting and practical\nproblem. However, there has been limited success so far, as researchers have\nfound it difficult to outperform fine-tuned baseline rankers on benchmark\ndatasets. We analyze pointwise and listwise ranking prompts used by existing\nmethods and argue that off-the-shelf LLMs do not fully understand these ranking\nformulations, possibly due to the nature of how LLMs are trained. In this\npaper, we propose to significantly reduce the burden on LLMs by using a new\ntechnique called Pairwise Ranking Prompting (PRP). Our results are the first in\nthe literature to achieve state-of-the-art ranking performance on standard\nbenchmarks using moderate-sized open-sourced LLMs. On TREC-DL2020, PRP based on\nthe Flan-UL2 model with 20B parameters outperforms the previous best approach\nin the literature, which is based on the blackbox commercial GPT-4 that has 50x\n(estimated) model size, by over 5% at NDCG@1. On TREC-DL2019, PRP is only\ninferior to the GPT-4 solution on the NDCG@5 and NDCG@10 metrics, while\noutperforming other existing solutions, such as InstructGPT which has 175B\nparameters, by over 10% for nearly all ranking metrics. Furthermore, we propose\nseveral variants of PRP to improve efficiency and show that it is possible to\nachieve competitive results even with linear complexity. We also discuss other\nbenefits of PRP, such as supporting both generation and scoring LLM APIs, as\nwell as being insensitive to input ordering.",
        "translated": "使用大型语言模型(LLM)对文档进行排序，将查询和候选文档直接输入到提示符中，这是一个有趣而实用的问题。然而，迄今为止取得的成功有限，因为研究人员发现很难在基准数据集上超越经过微调的基线排名。我们分析了现有方法使用的点式和列式排序提示，并认为现成的 LLM 不能完全理解这些排序公式，可能是由于 LLM 训练方式的性质。在本文中，我们提出了一种新的技术，即成对排序提示(PRP) ，来显著减少 LLM 的负担。我们的研究结果是文献中第一次使用中等规模的开源 LLM 在标准基准上实现最先进的排名性能。在 TREC-DL2020上，基于具有20B 参数的 Flan-UL2模型的 PRP 优于文献中以前的最佳方法，其基于具有50倍(估计)模型大小的黑盒商业 GPT-4，在 NDCG@1上超过5% 。在 TREC-DL2019上，PRP 在 NDCG@5和 NDCG@10指标上仅次于 GPT-4解决方案，而在几乎所有排名指标上，PRP 的表现优于其他现有解决方案，如具有175B 参数的翘楚 GPT，超过10% 。此外，我们提出了几个变种的 PRP，以提高效率，并表明可能实现的竞争结果，即使与线性复杂性。我们还讨论了 PRP 的其他好处，例如支持生成和评分 LLM API，以及对输入顺序不敏感。"
    },
    {
        "title": "Leveraging Watch-time Feedback for Short-Video Recommendations: A Causal\n  Labeling Framework",
        "url": "http://arxiv.org/abs/2306.17426v1",
        "pub_date": "2023-06-30",
        "summary": "With the proliferation of short video applications, the significance of short\nvideo recommendations has vastly increased. Unlike other recommendation\nscenarios, short video recommendation systems heavily rely on feedback from\nwatch time. Existing approaches simply treat watch time as a direct label,\nfailing to effectively harness its extensive semantics and introduce bias,\nthereby limiting the potential for modeling user interests based on watch time.\nTo overcome this challenge, we propose a framework named Debiasied\nMultiple-semantics-extracting Labeling (DML). DML constructs labels that\nencompass various semantics by utilizing quantiles derived from the\ndistribution of watch time, prioritizing relative order rather than absolute\nlabel values. This approach facilitates easier model learning while aligning\nwith the ranking objective of recommendations. Furthermore, we introduce a\nmethod inspired by causal adjustment to refine label definitions, thereby\nreducing the impact of bias on the label and directly mitigating bias at the\nlabel level. We substantiate the effectiveness of our DML framework through\nboth online and offline experiments. Extensive results demonstrate that our DML\ncould effectively leverage watch time to discover users' real interests,\nenhancing their engagement in our application.",
        "translated": "随着短视频应用程序的激增，短视频推荐的重要性大大增加。与其他推荐场景不同，短视频推荐系统严重依赖于观看时间的反馈。现有的方法只是简单地将手表时间作为一个直接标签，未能有效地利用其广泛的语义并引入偏见，从而限制了基于手表时间建模用户兴趣的潜力。为了克服这一挑战，我们提出了一个名为 Debiasied 多语义抽取标记(DML)的框架。DML 通过利用从手表时间分布派生的分位数构造包含各种语义的标签，优先考虑相对顺序而不是绝对标签值。这种方法促进了更容易的模型学习，同时与建议的排名目标保持一致。此外，我们引入了一个方法的启发，因果调整，以完善标签定义，从而减少偏见的影响，对标签和直接减轻偏见的标签水平。我们通过两个在线和离线的实验证实了我们的 DML 框架的有效性。大量的结果表明，我们的 DML 可以有效地利用观看时间来发现用户的真正兴趣，提高他们在我们的应用程序中的参与度。"
    },
    {
        "title": "Audio Embeddings as Teachers for Music Classification",
        "url": "http://arxiv.org/abs/2306.17424v1",
        "pub_date": "2023-06-30",
        "summary": "Music classification has been one of the most popular tasks in the field of\nmusic information retrieval. With the development of deep learning models, the\nlast decade has seen impressive improvements in a wide range of classification\ntasks. However, the increasing model complexity makes both training and\ninference computationally expensive. In this paper, we integrate the ideas of\ntransfer learning and feature-based knowledge distillation and systematically\ninvestigate using pre-trained audio embeddings as teachers to guide the\ntraining of low-complexity student networks. By regularizing the feature space\nof the student networks with the pre-trained embeddings, the knowledge in the\nteacher embeddings can be transferred to the students. We use various\npre-trained audio embeddings and test the effectiveness of the method on the\ntasks of musical instrument classification and music auto-tagging. Results show\nthat our method significantly improves the results in comparison to the\nidentical model trained without the teacher's knowledge. This technique can\nalso be combined with classical knowledge distillation approaches to further\nimprove the model's performance.",
        "translated": "音乐分类一直是音乐信息检索领域最受欢迎的课题之一。随着深度学习模型的发展，在过去的十年中，在广泛的分类任务方面取得了令人印象深刻的进步。然而，不断增长的模型复杂度使得训练和推理计算的开销都很大。本文结合迁移学习和基于特征的知识提取的思想，系统地研究了如何利用预先训练好的音频嵌入作为教师来指导低复杂度学生网络的训练。通过预训练嵌入规则化学生网络的特征空间，将教师嵌入中的知识传递给学生。我们使用各种预先训练的音频嵌入技术，测试这种方法在乐器分类法和音乐自动标签方面的效果。结果表明，与未经教师知识培训的同一模型相比，该方法显著提高了训练效果。该方法还可以与经典的知识提取方法相结合，进一步提高模型的性能。"
    },
    {
        "title": "SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen\n  LLMs",
        "url": "http://arxiv.org/abs/2306.17842v2",
        "pub_date": "2023-06-30",
        "summary": "In this work, we introduce Semantic Pyramid AutoEncoder (SPAE) for enabling\nfrozen LLMs to perform both understanding and generation tasks involving\nnon-linguistic modalities such as images or videos. SPAE converts between raw\npixels and interpretable lexical tokens (or words) extracted from the LLM's\nvocabulary. The resulting tokens capture both the semantic meaning and the\nfine-grained details needed for visual reconstruction, effectively translating\nthe visual content into a language comprehensible to the LLM, and empowering it\nto perform a wide array of multimodal tasks. Our approach is validated through\nin-context learning experiments with frozen PaLM 2 and GPT 3.5 on a diverse set\nof image understanding and generation tasks. Our method marks the first\nsuccessful attempt to enable a frozen LLM to generate image content while\nsurpassing state-of-the-art performance in image understanding tasks, under the\nsame setting, by over 25%.",
        "translated": "在这项工作中，我们介绍了语义金字塔自动编码器(SPAE) ，使冻结 LLM 执行理解和生成任务涉及非语言的形式，如图像或视频。SPAE 在原始像素和从 LLM 词汇表中提取的可解释词汇标记(或单词)之间进行转换。由此产生的标记捕获视觉重建所需的语义和细粒度细节，有效地将视觉内容翻译成 LLM 可理解的语言，并授权它执行大量多模态任务。我们的方法是通过在一组不同的图像理解和生成任务上使用冻结的 PaLM 2和 GPT 3.5进行上下文学习实验来验证的。我们的方法标志着第一次成功尝试使一个冻结的 LLM 能够生成图像内容，同时在图像理解任务中超过最先进的性能，在相同的设置下，超过25% 。"
    },
    {
        "title": "Statler: State-Maintaining Language Models for Embodied Reasoning",
        "url": "http://arxiv.org/abs/2306.17840v2",
        "pub_date": "2023-06-30",
        "summary": "Large language models (LLMs) provide a promising tool that enable robots to\nperform complex robot reasoning tasks. However, the limited context window of\ncontemporary LLMs makes reasoning over long time horizons difficult. Embodied\ntasks such as those that one might expect a household robot to perform\ntypically require that the planner consider information acquired a long time\nago (e.g., properties of the many objects that the robot previously encountered\nin the environment). Attempts to capture the world state using an LLM's\nimplicit internal representation is complicated by the paucity of task- and\nenvironment-relevant information available in a robot's action history, while\nmethods that rely on the ability to convey information via the prompt to the\nLLM are subject to its limited context window. In this paper, we propose\nStatler, a framework that endows LLMs with an explicit representation of the\nworld state as a form of ``memory'' that is maintained over time. Integral to\nStatler is its use of two instances of general LLMs -- a world-model reader and\na world-model writer -- that interface with and maintain the world state. By\nproviding access to this world state ``memory'', Statler improves the ability\nof existing LLMs to reason over longer time horizons without the constraint of\ncontext length. We evaluate the effectiveness of our approach on three\nsimulated table-top manipulation domains and a real robot domain, and show that\nit improves the state-of-the-art in LLM-based robot reasoning. Project website:\nhttps://statler-lm.github.io/",
        "translated": "大语言模型(LLM)为机器人执行复杂的机器人推理任务提供了有前途的工具。然而，当代 LLM 的有限的上下文窗口使得长时间的推理变得困难。具体的任务，比如人们可能期望家用机器人执行的任务，通常需要计划者考虑很久以前获得的信息(例如，机器人以前在环境中遇到的许多对象的属性)。使用 LLM 的隐式内部表示来捕捉世界状态的尝试由于机器人动作历史中缺乏与任务和环境相关的信息而变得复杂，而依赖于通过向 LLM 提示传递信息的能力的方法受制于其有限的上下文窗口。在本文中，我们提出了 Statler 框架，这个框架赋予 LLM 以世界状态的显式表示，作为一种随时间维护的“记忆”形式。对 Statler 而言，Integral 使用了两种常规 LLM ——一种是世界模式的阅读器，另一种是世界模式的写作器——它们与世界状态相互作用，并维持着世界状态。通过提供对这个世界状态“内存”的访问，Statler 提高了现有 LLM 在较长时间范围内进行推理的能力，而不受上下文长度的限制。通过对三个仿真桌面操作域和一个实际机器人域的仿真，评价了该方法的有效性，并表明该方法提高了基于 LLM 的机器人推理的技术水平。项目网址:  https://statler-lm.github.io/"
    },
    {
        "title": "Meta-Reasoning: Semantics-Symbol Deconstruction For Large Language\n  Models",
        "url": "http://arxiv.org/abs/2306.17820v1",
        "pub_date": "2023-06-30",
        "summary": "Symbolization methods in large language models (LLMs) have been shown\neffective to improve LLMs' reasoning ability. However, most of these approaches\nhinge on mapping natural languages to formal languages (e.g., Python, SQL) that\nare more syntactically complete and free of ambiguity. Although effective, they\ndepart from the natural language itself and deviate from the habits of human\nthinking, and instead cater more to the execution mindset of computers. In\ncontrast, we hope to simplify natural language by starting from the concept of\nsymbols in linguistics itself, so that LLMs can learn the common formulation\nand general solution of reasoning problems wrapped in different natural\nsemantics. From this consideration, we propose \\textbf{Meta-Reasoning}, which\nallows LLMs to automatically accomplish semantic-symbol deconstruction, i.e.,\nsemantic resolution, to maximally reduce different questions of certain\nreasoning tasks to similar natural language representation, thus gaining the\nability to learn by analogy and facilitating data-efficient in-context\nlearning. Our experiments show that the Meta-Reasoning paradigm saliently\nenhances LLMs' reasoning performance with fewer demonstrations. They can learn\nnot only reasoning chains but also general solutions to certain types of tasks.\nIn particular, for symbolic reasoning tasks, such as 7-step Tracking Shuffled\nObjects, GPT-3 (text-davinci-002) achieves over 99% accuracy with only one\nMeta-Reasoning demonstration, outperforming all current LLMs with the standard\nchain-of-thought prompting.",
        "translated": "大型语言模型中的符号化方法已被证明可以有效地提高语言模型的推理能力。然而，这些方法大多依赖于将自然语言映射到语法更完整、没有歧义的正式语言(例如 Python、 SQL)。虽然有效，但它们背离了自然语言本身，背离了人类思维的习惯，而更多地迎合了计算机的执行思维。相反，我们希望从语言学本身的符号概念入手，简化自然语言，使 LLM 能够学习不同自然语义包裹的推理问题的通用表达式和通用解决方案。基于这一考虑，我们提出了 textbf { Meta 推理} ，它允许 LLM 自动完成语义符号解构，即语义解析，以最大限度地减少某些推理任务的不同问题类似的自然语言表示，从而获得类比学习的能力，并促进数据高效的上下文学习。我们的实验表明，元推理范式显著提高了 LLM 的推理性能与较少的演示。他们不仅可以学习推理链条，还可以学习某些类型任务的一般解决方案。特别是对于符号推理任务，例如7步跟踪混乱对象，GPT-3(text-davinci-002)仅用一次元推理演示就达到了99% 以上的准确率，在标准的思维链提示下表现优于所有当前的 LLM。"
    },
    {
        "title": "A Massive Scale Semantic Similarity Dataset of Historical English",
        "url": "http://arxiv.org/abs/2306.17810v1",
        "pub_date": "2023-06-30",
        "summary": "A diversity of tasks use language models trained on semantic similarity data.\nWhile there are a variety of datasets that capture semantic similarity, they\nare either constructed from modern web data or are relatively small datasets\ncreated in the past decade by human annotators. This study utilizes a novel\nsource, newly digitized articles from off-copyright, local U.S. newspapers, to\nassemble a massive-scale semantic similarity dataset spanning 70 years from\n1920 to 1989 and containing nearly 400M positive semantic similarity pairs.\nHistorically, around half of articles in U.S. local newspapers came from\nnewswires like the Associated Press. While local papers reproduced articles\nfrom the newswire, they wrote their own headlines, which form abstractive\nsummaries of the associated articles. We associate articles and their headlines\nby exploiting document layouts and language understanding. We then use deep\nneural methods to detect which articles are from the same underlying source, in\nthe presence of substantial noise and abridgement. The headlines of reproduced\narticles form positive semantic similarity pairs. The resulting publicly\navailable HEADLINES dataset is significantly larger than most existing semantic\nsimilarity datasets and covers a much longer span of time. It will facilitate\nthe application of contrastively trained semantic similarity models to a\nvariety of tasks, including the study of semantic change across space and time.",
        "translated": "多种任务使用基于语义相似性数据的语言模型。虽然有各种各样的数据集可以捕获语义相似性，但它们要么是由现代网络数据构建的，要么是由人工注释者在过去十年中创建的相对较小的数据集。本研究利用来自美国本土报纸的一个新的来源，新近数字化的文章，收集了一个大规模的语义相似度数据集，这个数据集从1920年到1989年跨越了70年，包含了近400M 的正语义相似度对。从历史上看，美国地方报纸大约有一半的文章来自美联社等新闻通讯社。当地报纸转载新闻通讯社的文章，他们写自己的标题，形成相关文章的抽象摘要。我们通过利用文档布局和语言理解将文章和标题联系起来。然后，我们使用深度神经方法来检测哪些文章来自相同的潜在来源，在存在大量的噪音和删节。转载文章的标题形成正的语义相似对。由此产生的公开可用的 HEADLINES 数据集明显大于大多数现有的语义相似性数据集，并覆盖了更长的时间跨度。它将有助于对比训练语义相似性模型应用于各种任务，包括跨时空语义变化的研究。"
    },
    {
        "title": "Stay on topic with Classifier-Free Guidance",
        "url": "http://arxiv.org/abs/2306.17806v1",
        "pub_date": "2023-06-30",
        "summary": "Classifier-Free Guidance (CFG) has recently emerged in text-to-image\ngeneration as a lightweight technique to encourage prompt-adherence in\ngenerations. In this work, we demonstrate that CFG can be used broadly as an\ninference-time technique in pure language modeling. We show that CFG (1)\nimproves the performance of Pythia, GPT-2 and LLaMA-family models across an\narray of tasks: Q\\&amp;A, reasoning, code generation, and machine translation,\nachieving SOTA on LAMBADA with LLaMA-7B over PaLM-540B; (2) brings improvements\nequivalent to a model with twice the parameter-count; (3) can stack alongside\nother inference-time methods like Chain-of-Thought and Self-Consistency,\nyielding further improvements in difficult tasks; (4) can be used to increase\nthe faithfulness and coherence of assistants in challenging form-driven and\ncontent-driven prompts: in a human evaluation we show a 75\\% preference for\nGPT4All using CFG over baseline.",
        "translated": "无分类器指导(CFG)最近出现在文本到图像的生成作为一种轻量级技术，以鼓励在几代人中迅速遵守。在这项工作中，我们证明了 CFG 可以作为一种推理时间技术在纯语言建模中得到广泛的应用。我们展示了 CFG (1)在一系列任务中提高了 Pythia、 GPT-2和 Llama 家族模型的性能:A、推理、代码生成和机器翻译，在 LAMBADA 上用 LLaMA-7B 在 PaLM-540B 上实现 SOTA; (2)带来相当于参数计数两倍的模型的改进; (3)可以与其他推理时间方法(如思维链和自我一致性)叠加，在困难任务中产生进一步的改进;(4)可用于增加助手在具有挑战性的形式驱动和内容驱动的提示中的忠实性和一致性: 在人类评估中，我们显示使用 CFG 的 GPT4All 优于基线的75% 。"
    },
    {
        "title": "Towards Improving the Performance of Pre-Trained Speech Models for\n  Low-Resource Languages Through Lateral Inhibition",
        "url": "http://arxiv.org/abs/2306.17792v1",
        "pub_date": "2023-06-30",
        "summary": "With the rise of bidirectional encoder representations from Transformer\nmodels in natural language processing, the speech community has adopted some of\ntheir development methodologies. Therefore, the Wav2Vec models were introduced\nto reduce the data required to obtain state-of-the-art results. This work\nleverages this knowledge and improves the performance of the pre-trained speech\nmodels by simply replacing the fine-tuning dense layer with a lateral\ninhibition layer inspired by the biological process. Our experiments on\nRomanian, a low-resource language, show an average improvement of 12.5% word\nerror rate (WER) using the lateral inhibition layer. In addition, we obtain\nstate-of-the-art results on both the Romanian Speech Corpus and the Robin\nTechnical Acquisition Corpus with 1.78% WER and 29.64% WER, respectively.",
        "translated": "随着自然语言处理领域中变换器模型中双向编码器表示方法的兴起，语音社区采用了它们的一些开发方法。因此，我们引入了 Wav2Vec 模型，以减少获得最先进结果所需的数据。这项工作充分利用了这些知识，通过简单地用受生物过程启发的侧抑制层取代微调密集层，提高了预先训练好的语音模型的性能。我们在罗马尼亚语(一种资源匮乏的语言)上的实验表明，使用侧抑制层平均可以提高12.5% 的单词错误率。此外，我们在罗马尼亚语言语料库和罗宾技术习得语料库中分别获得了1.78% 和29.64% 的最新结果。"
    },
    {
        "title": "Should you marginalize over possible tokenizations?",
        "url": "http://arxiv.org/abs/2306.17757v1",
        "pub_date": "2023-06-30",
        "summary": "Autoregressive language models (LMs) map token sequences to probabilities.\nThe usual practice for computing the probability of any character string (e.g.\nEnglish sentences) is to first transform it into a sequence of tokens that is\nscored by the model. However, there are exponentially many token sequences that\nrepresent any given string. To truly compute the probability of a string one\nshould marginalize over all tokenizations, which is typically intractable.\nHere, we analyze whether the practice of ignoring the marginalization is\njustified. To this end, we devise an importance-sampling-based algorithm that\nallows us to compute estimates of the marginal probabilities and compare them\nto the default procedure in a range of state-of-the-art models and datasets.\nOur results show that the gap in log-likelihood is no larger than 0.5% in most\ncases, but that it becomes more pronounced for data with long complex words.",
        "translated": "自回归语言模型(LM)将标记序列映射到概率。计算任何字符串(例如英语句子)的概率的通常做法是首先将其转换为一系列由模型计分的标记。但是，表示任意给定字符串的令牌序列呈指数级增长。要真正计算字符串的概率，应该在所有标记化中边缘化，这通常是难以实现的。在这里，我们分析忽视边缘化的做法是否合理。为此，我们设计了一种基于重要性抽样的算法，它允许我们计算边际概率的估计值，并将其与一系列最先进的模型和数据集中的默认过程进行比较。我们的研究结果表明，在大多数情况下，对数似然的差距不大于0.5% ，但是对于含有较长复杂词的数据，这一差距变得更加明显。"
    },
    {
        "title": "Token-Event-Role Structure-based Multi-Channel Document-Level Event\n  Extraction",
        "url": "http://arxiv.org/abs/2306.17733v1",
        "pub_date": "2023-06-30",
        "summary": "Document-level event extraction is a long-standing challenging information\nretrieval problem involving a sequence of sub-tasks: entity extraction, event\ntype judgment, and event type-specific multi-event extraction. However,\naddressing the problem as multiple learning tasks leads to increased model\ncomplexity. Also, existing methods insufficiently utilize the correlation of\nentities crossing different events, resulting in limited event extraction\nperformance. This paper introduces a novel framework for document-level event\nextraction, incorporating a new data structure called token-event-role and a\nmulti-channel argument role prediction module. The proposed data structure\nenables our model to uncover the primary role of tokens in multiple events,\nfacilitating a more comprehensive understanding of event relationships. By\nleveraging the multi-channel prediction module, we transform entity and\nmulti-event extraction into a single task of predicting token-event pairs,\nthereby reducing the overall parameter size and enhancing model efficiency. The\nresults demonstrate that our approach outperforms the state-of-the-art method\nby 9.5 percentage points in terms of the F1 score, highlighting its superior\nperformance in event extraction. Furthermore, an ablation study confirms the\nsignificant value of the proposed data structure in improving event extraction\ntasks, further validating its importance in enhancing the overall performance\nof the framework.",
        "translated": "文档级事件提取是一个长期存在的具有挑战性的信息检索问题，涉及一系列子任务: 实体提取、事件类型判断和特定于事件类型的多事件提取。然而，将问题作为多个学习任务处理会导致模型复杂度的增加。此外，现有的方法没有充分利用跨不同事件的实体之间的相关性，导致事件提取性能有限。提出了一种新的文档级事件抽取框架，该框架结合了新的数据结构令牌-事件-角色和多通道参数角色预测模块。建议的数据结构使我们的模型能够揭示令牌在多个事件中的主要作用，促进对事件关系的更全面的理解。通过利用多通道预测模块，将实体和多事件提取转化为单一的预测令牌-事件对任务，从而减少了整体参数的大小，提高了模型的效率。结果表明，我们的方法优于国家的最先进的方法9.5个百分点的条件下的 F1得分，突出其优越的表现在事件提取。此外，消融研究证实了该数据结构在改善事件提取任务方面的重要价值，进一步验证了其在提高框架整体性能方面的重要性。"
    },
    {
        "title": "Improved NL2SQL based on Multi-layer Expert Network",
        "url": "http://arxiv.org/abs/2306.17727v1",
        "pub_date": "2023-06-30",
        "summary": "The Natural Language to SQL (NL2SQL) technique is used to convert natural\nlanguage queries into executable SQL statements. Typically, slot-filling is\nemployed as a classification method for multi-task cases to achieve this goal.\nHowever, slot-filling can result in inaccurate SQL statement generation due to\nnegative migration issues arising from different classification tasks. To\novercome this limitation, this study introduces a new approach called\nMulti-Layer Expert Generate SQL (MLEG-SQL), which utilizes a dedicated\nmulti-task hierarchical network. The lower layer of the network extracts\nsemantic features of natural language statements, while the upper layer builds\na specialized expert system for handling specific classification tasks. This\nhierarchical approach mitigates performance degradation resulting from\ndifferent task conflicts. The proposed method was evaluated on the WiKSQL\ndataset and was found to be effective in generating accurate SQL statements.",
        "translated": "自然语言到 SQL (NL2SQL)技术用于将自然语言查询转换为可执行 SQL 语句。通常，为了实现这一目标，多任务案例的分类方法是采用槽填充的方法。然而，由于不同分类任务产生的负迁移问题，插槽填充可能导致 SQL 语句生成不准确。为了克服这一局限性，本研究提出了一种新的多层专家生成 SQL (Multi-Layer Expert Generate SQL，MLEG-SQL)方法，该方法利用一个专用的多任务分层网络。网络的下层提取自然语言语句的语义特征，上层建立专门的专家系统来处理特定的分类任务。这种分层方法减轻了不同任务冲突导致的性能下降。在 WiKSQL 数据集上对该方法进行了评估，结果表明该方法能够有效地生成准确的 SQL 语句。"
    },
    {
        "title": "Beyond Neural-on-Neural Approaches to Speaker Gender Protection",
        "url": "http://arxiv.org/abs/2306.17700v1",
        "pub_date": "2023-06-30",
        "summary": "Recent research has proposed approaches that modify speech to defend against\ngender inference attacks. The goal of these protection algorithms is to control\nthe availability of information about a speaker's gender, a privacy-sensitive\nattribute. Currently, the common practice for developing and testing gender\nprotection algorithms is \"neural-on-neural\", i.e., perturbations are generated\nand tested with a neural network. In this paper, we propose to go beyond this\npractice to strengthen the study of gender protection. First, we demonstrate\nthe importance of testing gender inference attacks that are based on speech\nfeatures historically developed by speech scientists, alongside the\nconventionally used neural classifiers. Next, we argue that researchers should\nuse speech features to gain insight into how protective modifications change\nthe speech signal. Finally, we point out that gender-protection algorithms\nshould be compared with novel \"vocal adversaries\", human-executed voice\nadaptations, in order to improve interpretability and enable before-the-mic\nprotection.",
        "translated": "最近的研究已经提出了修改语音以防止性别推理攻击的方法。这些保护算法的目标是控制有关说话者性别的信息的可用性，这是一个对隐私敏感的属性。目前，开发和测试性别保护算法的常见做法是“神经元对神经元”，即用神经网络生成和测试扰动。本文建议超越这一实践，加强对性别保护的研究。首先，我们证明了测试性别推断攻击的重要性，这些攻击是基于语音科学家历史上发展出来的语音特征，以及常规使用的神经分类器。接下来，我们认为研究人员应该利用语音特征来深入了解保护性修饰如何改变语音信号。最后，我们指出，性别保护算法应该与新的“声音对手”，人类执行的语音适应性进行比较，以提高可解释性，使麦克风前的保护。"
    },
    {
        "title": "ChatGPT vs. Google: A Comparative Study of Search Performance and User\n  Experience",
        "url": "http://arxiv.org/abs/2307.01135v1",
        "pub_date": "2023-07-03",
        "summary": "The advent of ChatGPT, a large language model-powered chatbot, has prompted\nquestions about its potential implications for traditional search engines. In\nthis study, we investigate the differences in user behavior when employing\nsearch engines and chatbot tools for information-seeking tasks. We carry out a\nrandomized online experiment, dividing participants into two groups: one using\na ChatGPT-like tool and the other using a Google Search-like tool. Our findings\nreveal that the ChatGPT group consistently spends less time on all tasks, with\nno significant difference in overall task performance between the groups.\nNotably, ChatGPT levels user search performance across different education\nlevels and excels in answering straightforward questions and providing general\nsolutions but falls short in fact-checking tasks. Users perceive ChatGPT's\nresponses as having higher information quality compared to Google Search,\ndespite displaying a similar level of trust in both tools. Furthermore,\nparticipants using ChatGPT report significantly better user experiences in\nterms of usefulness, enjoyment, and satisfaction, while perceived ease of use\nremains comparable between the two tools. However, ChatGPT may also lead to\noverreliance and generate or replicate misinformation, yielding inconsistent\nresults. Our study offers valuable insights for search engine management and\nhighlights opportunities for integrating chatbot technologies into search\nengine designs.",
        "translated": "ChatGPT 是一个大型语言模型驱动的聊天机器人，它的出现引发了人们对其对传统搜索引擎潜在影响的质疑。在本研究中，我们探讨使用搜寻引擎与聊天机器人工具进行资讯搜寻时，使用者行为的差异。我们进行了一个随机的在线实验，将参与者分成两组: 一组使用类似 ChatGPT 的工具，另一组使用类似 Google 搜索的工具。我们的研究结果表明，ChatGPT 小组在所有任务上花费的时间一致较少，小组之间的整体任务表现没有显著差异。值得注意的是，ChatGPT 在不同教育水平的用户搜索性能水平，并擅长回答简单的问题和提供一般性的解决方案，但在事实检查任务中表现不佳。用户认为 ChatGPT 的回复比 Google 搜索的信息质量更高，尽管他们对这两个工具的信任程度相似。此外，使用 ChatGPT 的参与者报告显着更好的用户体验在有用性，享受和满意度方面，而易于使用的感知仍然是两个工具之间的可比性。然而，ChatGPT 也可能导致过度依赖和产生或重复错误信息，产生不一致的结果。我们的研究为搜索引擎管理提供了有价值的见解，并强调了将聊天机器人技术整合到搜索引擎设计中的机会。"
    },
    {
        "title": "OpenSiteRec: An Open Dataset for Site Recommendation",
        "url": "http://arxiv.org/abs/2307.00856v1",
        "pub_date": "2023-07-03",
        "summary": "As a representative information retrieval task, site recommendation, which\naims at predicting the optimal sites for a brand or an institution to open new\nbranches in an automatic data-driven way, is beneficial and crucial for brand\ndevelopment in modern business. However, there is no publicly available dataset\nso far and most existing approaches are limited to an extremely small scope of\nbrands, which seriously hinders the research on site recommendation. Therefore,\nwe collect, construct and release an open comprehensive dataset, namely\nOpenSiteRec, to facilitate and promote the research on site recommendation.\nSpecifically, OpenSiteRec leverages a heterogeneous graph schema to represent\nvarious types of real-world entities and relations in four international\nmetropolises. To evaluate the performance of the existing general methods on\nthe site recommendation task, we conduct benchmarking experiments of several\nrepresentative recommendation models on OpenSiteRec. Furthermore, we also\nhighlight the potential application directions to demonstrate the wide\napplicability of OpenSiteRec. We believe that our OpenSiteRec dataset is\nsignificant and anticipated to encourage the development of advanced methods\nfor site recommendation. OpenSiteRec is available online at\nhttps://OpenSiteRec.github.io/.",
        "translated": "网站推荐作为一项具有代表性的信息检索任务，旨在预测一个品牌或机构以自动数据驱动的方式开设新分支机构的最佳网站，对于现代商业中的品牌发展是有益的，也是至关重要的。然而，到目前为止还没有公开的数据集，大多数现有的方法仅限于极小范围的品牌，这严重阻碍了对网站推荐的研究。因此，我们收集、构建和发布一个开放的综合数据集，即 OpenSiteRec，以促进和推动网站推荐的研究。具体来说，OpenSiteRec 利用异构图模式来表示四个国际大都市中各种类型的现实世界实体和关系。为了评估现有的一般方法在站点推荐任务中的性能，我们在 OpenSiteRec 上对几种有代表性的推荐模型进行了基准测试实验。此外，我们还强调了潜在的应用程序方向，以展示 OpenSiteRec 的广泛适用性。我们相信我们的 OpenSiteRec 数据集是重要的，并且预计将鼓励开发用于网站推荐的高级方法。OpenSiteRec 可于网上 https://OpenSiteRec.github.io/下载。"
    },
    {
        "title": "Looks Can Be Deceiving: Linking User-Item Interactions and User's\n  Propensity Towards Multi-Objective Recommendations",
        "url": "http://arxiv.org/abs/2307.00654v1",
        "pub_date": "2023-07-02",
        "summary": "Multi-objective recommender systems (MORS) provide suggestions to users\naccording to multiple (and possibly conflicting) goals. When a system optimizes\nits results at the individual-user level, it tailors them on a user's\npropensity towards the different objectives. Hence, the capability to\nunderstand users' fine-grained needs towards each goal is crucial. In this\npaper, we present the results of a user study in which we monitored the way\nusers interacted with recommended items, as well as their self-proclaimed\npropensities towards relevance, novelty and diversity objectives. The study was\ndivided into several sessions, where users evaluated recommendation lists\noriginating from a relevance-only single-objective baseline as well as MORS. We\nshow that despite MORS-based recommendations attracted less selections, its\npresence in the early sessions is crucial for users' satisfaction in the later\nstages. Surprisingly, the self-proclaimed willingness of users to interact with\nnovel and diverse items is not always reflected in the recommendations they\naccept. Post-study questionnaires provide insights on how to deal with this\nmatter, suggesting that MORS-based results should be accompanied by elements\nthat allow users to understand the recommendations, so as to facilitate their\nacceptance.",
        "translated": "多目标推荐系统(MORS)根据多个(可能存在冲突的)目标向用户提供建议。当一个系统在个人用户层面优化其结果时，它会根据用户对不同目标的倾向来调整结果。因此，理解用户对每个目标的细粒度需求的能力是至关重要的。在本文中，我们介绍了一项用户研究的结果，其中我们监测了用户与推荐项目的互动方式，以及他们自称的相关性、新颖性和多样性目标的倾向。这项研究分为几个阶段，用户评估源自相关性单一目标基线的推荐名单以及 MORS。我们表明，尽管基于 MORS 的建议吸引了较少的选择，它在早期会议的存在是至关重要的用户满意度在后期阶段。令人惊讶的是，用户自称愿意与新颖和多样化的项目进行互动，但并不总是反映在他们接受的建议中。研究后调查问卷提供了关于如何处理这一问题的见解，建议以 MORS 为基础的结果应附有使用者能够理解建议的要素，以便于他们接受。"
    },
    {
        "title": "BioCPT: Contrastive Pre-trained Transformers with Large-scale PubMed\n  Search Logs for Zero-shot Biomedical Information Retrieval",
        "url": "http://arxiv.org/abs/2307.00589v1",
        "pub_date": "2023-07-02",
        "summary": "Information retrieval (IR) is essential in biomedical knowledge acquisition\nand clinical decision support. While recent progress has shown that language\nmodel encoders perform better semantic retrieval, training such models requires\nabundant query-article annotations that are difficult to obtain in biomedicine.\nAs a result, most biomedical IR systems only conduct lexical matching. In\nresponse, we introduce BioCPT, a first-of-its-kind Contrastively Pre-trained\nTransformer model for zero-shot biomedical IR. To train BioCPT, we collected an\nunprecedented scale of 255 million user click logs from PubMed. With such data,\nwe use contrastive learning to train a pair of closely-integrated retriever and\nre-ranker. Experimental results show that BioCPT sets new state-of-the-art\nperformance on five biomedical IR tasks, outperforming various baselines\nincluding much larger models such as GPT-3-sized cpt-text-XL. In addition,\nBioCPT also generates better biomedical article and sentence representations\nfor semantic evaluations. As such, BioCPT can be readily applied to various\nreal-world biomedical IR tasks. BioCPT API and code are publicly available at\nhttps://github.com/ncbi/BioCPT.",
        "translated": "信息检索(IR)在获取生物医学知识和临床决策支持方面是必不可少的。虽然最近的进展表明，语言模型编码器执行更好的语义检索，训练这种模型需要大量的查询文章注释，这是难以获得的生物医学。因此，大多数生物医学红外系统只进行词汇匹配。作为回应，我们介绍了 BioCPT，一种首创的对比性预训练变压器模型，用于生物医学红外线的零激发。为了培训 BioCPT，我们从 PubMed 收集了前所未有的2.55亿用户点击日志。利用这些数据，我们使用对比学习来训练一对紧密集成的检索器和重排序器。实验结果表明，BioCPT 在五个生物医学 IR 任务上设置了新的最先进的性能，超过了包括 GPT-3大小的 cpt-text-XL 等更大模型在内的各种基线。此外，BioCPT 还为语义评估生成更好的生物医学文章和句子表示。因此，BioCPT 可以很容易地应用于各种真实世界的生物医学红外任务。BioCPT 原料药和代码可在 https://github.com/ncbi/BioCPT 公开查阅。"
    },
    {
        "title": "HeGeL: A Novel Dataset for Geo-Location from Hebrew Text",
        "url": "http://arxiv.org/abs/2307.00509v1",
        "pub_date": "2023-07-02",
        "summary": "The task of textual geolocation - retrieving the coordinates of a place based\non a free-form language description - calls for not only grounding but also\nnatural language understanding and geospatial reasoning. Even though there are\nquite a few datasets in English used for geolocation, they are currently based\non open-source data (Wikipedia and Twitter), where the location of the\ndescribed place is mostly implicit, such that the location retrieval resolution\nis limited. Furthermore, there are no datasets available for addressing the\nproblem of textual geolocation in morphologically rich and resource-poor\nlanguages, such as Hebrew. In this paper, we present the Hebrew Geo-Location\n(HeGeL) corpus, designed to collect literal place descriptions and analyze\nlingual geospatial reasoning. We crowdsourced 5,649 literal Hebrew place\ndescriptions of various place types in three cities in Israel. Qualitative and\nempirical analysis show that the data exhibits abundant use of geospatial\nreasoning and requires a novel environmental representation.",
        "translated": "文本地理定位的任务——基于自由形式的语言描述检索地点的坐标——不仅需要基础，而且需要自然语言理解和地理空间推理。尽管英语中有相当多的数据集用于地理定位，但它们目前都是基于开源数据(维基百科和 Twitter) ，其中描述的位置大多是隐式的，因此位置检索的分辨率是有限的。此外，没有数据集可用于解决文本地理定位问题的形态丰富和资源贫乏的语言，如希伯来语。本文提出了希伯来文地理定位语料库(HeGeL) ，旨在收集文字地点描述并分析语言地理空间推理。我们在以色列的三个城市中众包了5649个不同地点类型的希伯来文地点描述。定性和实证分析表明，这些数据显示了地理空间推理的丰富应用，需要一种新的环境表示方法。"
    },
    {
        "title": "Trainable Transformer in Transformer",
        "url": "http://arxiv.org/abs/2307.01189v1",
        "pub_date": "2023-07-03",
        "summary": "Recent works attribute the capability of in-context learning (ICL) in large\npre-trained language models to implicitly simulating and fine-tuning an\ninternal model (e.g., linear or 2-layer MLP) during inference. However, such\nconstructions require large memory overhead, which makes simulation of more\nsophisticated internal models intractable. In this work, we propose an\nefficient construction, Transformer in Transformer (in short, TinT), that\nallows a transformer to simulate and fine-tune complex models internally during\ninference (e.g., pre-trained language models). In particular, we introduce\ninnovative approximation techniques that allow a TinT model with less than 2\nbillion parameters to simulate and fine-tune a 125 million parameter\ntransformer model within a single forward pass. TinT accommodates many common\ntransformer variants and its design ideas also improve the efficiency of past\ninstantiations of simple models inside transformers. We conduct end-to-end\nexperiments to validate the internal fine-tuning procedure of TinT on various\nlanguage modeling and downstream tasks. For example, even with a limited\none-step budget, we observe TinT for a OPT-125M model improves performance by\n4-16% absolute on average compared to OPT-125M. These findings suggest that\nlarge pre-trained language models are capable of performing intricate\nsubroutines. To facilitate further work, a modular and extensible codebase for\nTinT is included.",
        "translated": "近年来的研究表明，大型预训练语言模型中的上下文学习(ICL)能够在推理过程中隐含地模拟和微调内部模型(例如线性或两层 MLP)。然而，这样的构造需要很大的内存开销，这使得更复杂的内部模型的模拟变得难以实现。在这项工作中，我们提出了一个有效的结构，变压器中的变压器(简称 TinT) ，它允许变压器在推理期间内部模拟和微调复杂模型(例如，预先训练的语言模型)。特别是，我们介绍了创新的近似技术，允许一个 TinT 模型少于20亿参数模拟和微调一个1.25亿参数变压器模型在一个单一的前向通过。TinT 容纳了许多常见的变压器变种，其设计思想也提高了过去变压器内部简单模型实例化的效率。我们进行端到端的实验来验证 TinT 在各种语言建模和下游任务中的内部微调过程。例如，即使有一个有限的一步预算，我们观察到 TinT 的 OPT-125M 型号的性能比 OPT-125M 绝对平均提高4-16% 。这些发现表明，大型预训练语言模型能够执行复杂的子程序。为了方便进一步的工作，还包括了 TinT 的模块化和可扩展的代码库。"
    },
    {
        "title": "Improving Language Plasticity via Pretraining with Active Forgetting",
        "url": "http://arxiv.org/abs/2307.01163v2",
        "pub_date": "2023-07-03",
        "summary": "Pretrained language models (PLMs) are today the primary model for natural\nlanguage processing. Despite their impressive downstream performance, it can be\ndifficult to apply PLMs to new languages, a barrier to making their\ncapabilities universally accessible. While prior work has shown it possible to\naddress this issue by learning a new embedding layer for the new language,\ndoing so is both data and compute inefficient. We propose to use an active\nforgetting mechanism during pretraining, as a simple way of creating PLMs that\ncan quickly adapt to new languages. Concretely, by resetting the embedding\nlayer every K updates during pretraining, we encourage the PLM to improve its\nability of learning new embeddings within a limited number of updates, similar\nto a meta-learning effect. Experiments with RoBERTa show that models pretrained\nwith our forgetting mechanism not only demonstrate faster convergence during\nlanguage adaptation but also outperform standard ones in a low-data regime,\nparticularly for languages that are distant from English.",
        "translated": "预训练语言模型(PLM)是当今自然语言处理的主要模型。尽管 PLM 在下游的表现令人印象深刻，但是将 PLM 应用到新的语言中可能会很困难，这是使其功能普遍可访问的一个障碍。虽然之前的工作已经表明，可以通过为新语言学习一个新的嵌入层来解决这个问题，但是这样做会导致数据和计算效率低下。我们建议在预训练期间使用主动遗忘机制，作为创建能够快速适应新语言的 PLM 的一种简单方法。具体来说，通过在预训练期间每次 K 更新时重置嵌入层，我们鼓励 PLM 在有限的更新次数内提高其学习新嵌入的能力，类似于元学习效应。用 RoBERTa 进行的实验表明，使用遗忘机制进行预训练的模型不仅在语言适应过程中表现出更快的收敛速度，而且在低数据量情况下的性能优于标准模型，特别是对于远离英语的语言。"
    },
    {
        "title": "SCITUNE: Aligning Large Language Models with Scientific Multimodal\n  Instructions",
        "url": "http://arxiv.org/abs/2307.01139v1",
        "pub_date": "2023-07-03",
        "summary": "Instruction finetuning is a popular paradigm to align large language models\n(LLM) with human intent. Despite its popularity, this idea is less explored in\nimproving the LLMs to align existing foundation models with scientific\ndisciplines, concepts and goals. In this work, we present SciTune as a tuning\nframework to improve the ability of LLMs to follow scientific multimodal\ninstructions. To test our methodology, we use a human-generated scientific\ninstruction tuning dataset and train a large multimodal model LLaMA-SciTune\nthat connects a vision encoder and LLM for science-focused visual and language\nunderstanding. In comparison to the models that are finetuned with machine\ngenerated data only, LLaMA-SciTune surpasses human performance on average and\nin many sub-categories on the ScienceQA benchmark.",
        "translated": "指令微调是将大型语言模型(LLM)与人类意图结合起来的一种流行范式。尽管这个想法很受欢迎，但是在改进 LLM 以使现有的基础模型与科学分支、概念和目标保持一致方面，这个想法却很少被探索。在这项工作中，我们将 SciTune 作为一个调优框架来提高 LLM 遵循科学的多模态指令的能力。为了测试我们的方法，我们使用了一个人工生成的科学指令调优数据集，并训练了一个大型多模态模型 LLaMA-SciTune，该模型将视觉编码器和 LLM 连接起来，用于以科学为中心的视觉和语言理解。与仅与机器生成的数据进行微调的模型相比，LLaMA-SciTune 在 ScienceQA 基准上的平均表现和许多子类别中都超过了人类的表现。"
    },
    {
        "title": "Exploring the In-context Learning Ability of Large Language Model for\n  Biomedical Concept Linking",
        "url": "http://arxiv.org/abs/2307.01137v1",
        "pub_date": "2023-07-03",
        "summary": "The biomedical field relies heavily on concept linking in various areas such\nas literature mining, graph alignment, information retrieval,\nquestion-answering, data, and knowledge integration. Although large language\nmodels (LLMs) have made significant strides in many natural language processing\ntasks, their effectiveness in biomedical concept mapping is yet to be fully\nexplored. This research investigates a method that exploits the in-context\nlearning (ICL) capabilities of large models for biomedical concept linking. The\nproposed approach adopts a two-stage retrieve-and-rank framework. Initially,\nbiomedical concepts are embedded using language models, and then embedding\nsimilarity is utilized to retrieve the top candidates. These candidates'\ncontextual information is subsequently incorporated into the prompt and\nprocessed by a large language model to re-rank the concepts. This approach\nachieved an accuracy of 90.% in BC5CDR disease entity normalization and 94.7%\nin chemical entity normalization, exhibiting a competitive performance relative\nto supervised learning methods. Further, it showed a significant improvement,\nwith an over 20-point absolute increase in F1 score on an oncology matching\ndataset. Extensive qualitative assessments were conducted, and the benefits and\npotential shortcomings of using large language models within the biomedical\ndomain were discussed. were discussed.",
        "translated": "生物医学领域在很大程度上依赖于各个领域的概念联系，如文献挖掘、图表对齐、信息检索、问答、数据和知识整合。尽管大语言模型(LLM)在自然语言处理任务中取得了长足的进步，但它们在生物医学概念映射中的有效性仍有待充分探索。本研究探讨一种利用大型生物医学概念连结模型的语境学习(ICL)能力的方法。该方法采用两阶段的检索和排序框架。首先利用语言模型对生物医学概念进行嵌入，然后利用嵌入相似性检索最优候选概念。这些候选者的上下文信息随后被整合到提示符中，并由一个大型语言模型进行处理，以重新排列这些概念。这种方法的精度达到了90。在 bc5CDR 疾病实体正常化和94.7% 在化学实体正常化，表现出相对于监督式学习方法的竞争性能。此外，它显示了一个显着的改善，与超过20点绝对增加 F1评分的肿瘤匹配数据集。进行了广泛的定性评估，并讨论了在生物医学领域使用大型语言模型的好处和潜在的缺点。讨论过。"
    },
    {
        "title": "Iterative Zero-Shot LLM Prompting for Knowledge Graph Construction",
        "url": "http://arxiv.org/abs/2307.01128v1",
        "pub_date": "2023-07-03",
        "summary": "In the current digitalization era, capturing and effectively representing\nknowledge is crucial in most real-world scenarios. In this context, knowledge\ngraphs represent a potent tool for retrieving and organizing a vast amount of\ninformation in a properly interconnected and interpretable structure. However,\ntheir generation is still challenging and often requires considerable human\neffort and domain expertise, hampering the scalability and flexibility across\ndifferent application fields. This paper proposes an innovative knowledge graph\ngeneration approach that leverages the potential of the latest generative large\nlanguage models, such as GPT-3.5, that can address all the main critical issues\nin knowledge graph building. The approach is conveyed in a pipeline that\ncomprises novel iterative zero-shot and external knowledge-agnostic strategies\nin the main stages of the generation process. Our unique manifold approach may\nencompass significant benefits to the scientific community. In particular, the\nmain contribution can be summarized by: (i) an innovative strategy for\niteratively prompting large language models to extract relevant components of\nthe final graph; (ii) a zero-shot strategy for each prompt, meaning that there\nis no need for providing examples for \"guiding\" the prompt result; (iii) a\nscalable solution, as the adoption of LLMs avoids the need for any external\nresources or human expertise. To assess the effectiveness of our proposed\nmodel, we performed experiments on a dataset that covered a specific domain. We\nclaim that our proposal is a suitable solution for scalable and versatile\nknowledge graph construction and may be applied to different and novel\ncontexts.",
        "translated": "在当前的数字化时代，获取和有效地表示知识在大多数现实世界的场景中是至关重要的。在这种情况下，知识图表是一种有力的工具，用于检索和组织在适当相互关联和可解释的结构中的大量信息。然而，它们的生成仍然具有挑战性，往往需要相当多的人力和领域专业知识，阻碍了不同应用领域的可伸缩性和灵活性。本文提出了一种创新的知识图生成方法，该方法利用了最新的生成大型语言模型(如 GPT-3.5)的潜力，可以解决知识图生成中的所有关键问题。该方法在生成过程的主要阶段由新的迭代零冲击和外部知识不可知策略组成的管道中传递。我们独特的方法可能包括对科学界的重大利益。特别是，主要贡献可以总结为: (i)一个创新的策略，反复提示大型语言模型提取最终图表的相关组件; (ii)每个提示的零拍策略，这意味着没有必要提供“指导”提示结果的例子; (iii)一个可伸缩的解决方案，因为采用 LLM 避免了任何外部资源或人力专业知识的需要。为了评估我们提出的模型的有效性，我们在一个覆盖特定领域的数据集上进行了实验。我们认为，我们的建议是一个适当的解决方案，可扩展和通用的知识图构建，可以应用于不同的和新颖的背景。"
    },
    {
        "title": "Analyzing Multiple-Choice Reading and Listening Comprehension Tests",
        "url": "http://arxiv.org/abs/2307.01076v1",
        "pub_date": "2023-07-03",
        "summary": "Multiple-choice reading and listening comprehension tests are an important\npart of language assessment. Content creators for standard educational tests\nneed to carefully curate questions that assess the comprehension abilities of\ncandidates taking the tests. However, recent work has shown that a large number\nof questions in general multiple-choice reading comprehension datasets can be\nanswered without comprehension, by leveraging world knowledge instead. This\nwork investigates how much of a contextual passage needs to be read in\nmultiple-choice reading based on conversation transcriptions and listening\ncomprehension tests to be able to work out the correct answer. We find that\nautomated reading comprehension systems can perform significantly better than\nrandom with partial or even no access to the context passage. These findings\noffer an approach for content creators to automatically capture the trade-off\nbetween comprehension and world knowledge required for their proposed\nquestions.",
        "translated": "多项选择题阅读和听力测试是语言测试的重要组成部分。标准教育测试的内容创建者需要仔细策划评估参加测试的考生理解能力的问题。然而，最近的研究表明，在一般的多项选择阅读理解数据集中，大量的问题可以在不理解的情况下通过利用世界知识来回答。本研究旨在探讨在基于会话记录和听力理解测试的多项选择性阅读中，需要阅读多少篇上下文文章才能得出正确答案。我们发现，自动阅读理解系统在部分甚至不能访问上下文的情况下，比随机系统的表现要好得多。这些发现为内容创建者提供了一种方法，可以自动捕捉他们提出的问题所需的理解和世界知识之间的权衡。"
    },
    {
        "title": "Estimating Post-OCR Denoising Complexity on Numerical Texts",
        "url": "http://arxiv.org/abs/2307.01020v1",
        "pub_date": "2023-07-03",
        "summary": "Post-OCR processing has significantly improved over the past few years.\nHowever, these have been primarily beneficial for texts consisting of natural,\nalphabetical words, as opposed to documents of numerical nature such as\ninvoices, payslips, medical certificates, etc. To evaluate the OCR\npost-processing difficulty of these datasets, we propose a method to estimate\nthe denoising complexity of a text and evaluate it on several datasets of\nvarying nature, and show that texts of numerical nature have a significant\ndisadvantage. We evaluate the estimated complexity ranking with respect to the\nerror rates of modern-day denoising approaches to show the validity of our\nestimator.",
        "translated": "在过去的几年中，光学字符识别后处理技术有了显著的改进。然而，这些主要是有益的文本组成的自然，字母词，而不是数字性质的文件，如发票，工资单，医疗证明等。为了评估这些数据集的 OCR 后处理难度，我们提出了一种估计文本去噪复杂度的方法，并在几个不同性质的数据集上进行了评估，结果表明数字性质的文本有明显的缺点。我们评估估计的复杂度排名相对于现代去噪方法的错误率，以证明我们的估计器的有效性。"
    },
    {
        "title": "Visual Instruction Tuning with Polite Flamingo",
        "url": "http://arxiv.org/abs/2307.01003v1",
        "pub_date": "2023-07-03",
        "summary": "Recent research has demonstrated that the multi-task fine-tuning of\nmulti-modal Large Language Models (LLMs) using an assortment of annotated\ndownstream vision-language datasets significantly enhances their performance.\nYet, during this process, a side effect, which we termed as the \"multi-modal\nalignment tax\", surfaces. This side effect negatively impacts the model's\nability to format responses appropriately -- for instance, its \"politeness\" --\ndue to the overly succinct and unformatted nature of raw annotations, resulting\nin reduced human preference. In this paper, we introduce Polite Flamingo, a\nmulti-modal response rewriter that transforms raw annotations into a more\nappealing, \"polite\" format. Polite Flamingo is trained to reconstruct\nhigh-quality responses from their automatically distorted counterparts and is\nsubsequently applied to a vast array of vision-language datasets for response\nrewriting. After rigorous filtering, we generate the PF-1M dataset and further\nvalidate its value by fine-tuning a multi-modal LLM with it. Combined with\nnovel methodologies including U-shaped multi-stage tuning and multi-turn\naugmentation, the resulting model, Clever Flamingo, demonstrates its advantages\nin both multi-modal understanding and response politeness according to\nautomated and human evaluations.",
        "translated": "最近的研究表明，使用注释的下游视觉语言数据集对多模态大语言模型(LLM)进行多任务微调显著提高了它们的性能。然而，在这个过程中，一个副作用，我们称为“多式联运税”，表面。由于原始注释过于简洁和未格式化的特性，这种副作用会对模型适当格式化响应的能力产生负面影响——例如，它的“礼貌”，从而导致人的偏好降低。在本文中，我们介绍 Polite Flamingo，它是一个多模态响应重写器，可以将原始注释转换成更吸引人的“礼貌”格式。礼貌的火烈鸟训练重建高质量的反应，从他们的自动扭曲对应，随后应用于大量的视觉语言数据集反应重写。经过严格的滤波，我们产生 PF-1M 数据集，并进一步验证其价值，微调多模态 LLM 与它。结合 U 型多阶段调谐和多转弯增强等新方法，通过自动评估和人工评估，得到的 Clever Flamingo 模型在多模态理解和回应礼貌两方面都具有优势。"
    },
    {
        "title": "Towards Suicide Prevention from Bipolar Disorder with Temporal\n  Symptom-Aware Multitask Learning",
        "url": "http://arxiv.org/abs/2307.00995v1",
        "pub_date": "2023-07-03",
        "summary": "Bipolar disorder (BD) is closely associated with an increased risk of\nsuicide. However, while the prior work has revealed valuable insight into\nunderstanding the behavior of BD patients on social media, little attention has\nbeen paid to developing a model that can predict the future suicidality of a BD\npatient. Therefore, this study proposes a multi-task learning model for\npredicting the future suicidality of BD patients by jointly learning current\nsymptoms. We build a novel BD dataset clinically validated by psychiatrists,\nincluding 14 years of posts on bipolar-related subreddits written by 818 BD\npatients, along with the annotations of future suicidality and BD symptoms. We\nalso suggest a temporal symptom-aware attention mechanism to determine which\nsymptoms are the most influential for predicting future suicidality over time\nthrough a sequence of BD posts. Our experiments demonstrate that the proposed\nmodel outperforms the state-of-the-art models in both BD symptom identification\nand future suicidality prediction tasks. In addition, the proposed temporal\nsymptom-aware attention provides interpretable attention weights, helping\nclinicians to apprehend BD patients more comprehensively and to provide timely\nintervention by tracking mental state progression.",
        "translated": "躁郁症(BD)与自杀风险增加密切相关。然而，尽管先前的工作已经揭示了了解 BD 患者在社交媒体上的行为的有价值的洞察力，但是很少有人注意开发一个能够预测 BD 患者未来自杀行为的模型。因此，本研究提出了一个多任务学习模型，通过联合学习当前症状来预测 BD 患者未来的自杀行为。我们建立了一个由精神科医生临床验证的新型 BD 数据集，包括818名 BD 患者撰写的14年双相相关子版块的帖子，以及未来自杀和 BD 症状的注释。我们还提出了一个时间症状意识的注意机制，以确定哪些症状是最有影响的预测未来自杀随着时间的推移，通过一系列的 BD 职位。我们的实验表明，所提出的模型在 BD 症状识别和未来自杀预测任务方面都优于最先进的模型。此外，提出的时间症状意识注意力提供了可解释的注意力权重，帮助临床医生更全面地理解 BD 患者，并提供及时的干预，跟踪精神状态的进展。"
    },
    {
        "title": "Challenges in Domain-Specific Abstractive Summarization and How to\n  Overcome them",
        "url": "http://arxiv.org/abs/2307.00963v1",
        "pub_date": "2023-07-03",
        "summary": "Large Language Models work quite well with general-purpose data and many\ntasks in Natural Language Processing. However, they show several limitations\nwhen used for a task such as domain-specific abstractive text summarization.\nThis paper identifies three of those limitations as research problems in the\ncontext of abstractive text summarization: 1) Quadratic complexity of\ntransformer-based models with respect to the input text length; 2) Model\nHallucination, which is a model's ability to generate factually incorrect text;\nand 3) Domain Shift, which happens when the distribution of the model's\ntraining and test corpus is not the same. Along with a discussion of the open\nresearch questions, this paper also provides an assessment of existing\nstate-of-the-art techniques relevant to domain-specific text summarization to\naddress the research gaps.",
        "translated": "大型语言模型可以很好地处理通用数据和自然语言处理中的许多任务。但是，当用于特定于领域的抽象文本摘要等任务时，它们显示出一些限制。本文将其中的三个局限性作为抽象文本摘要的研究问题: 1)基于转换器的模型相对于输入文本长度的二次复杂性; 2)模型幻觉，即模型产生事实上不正确的文本的能力; 3)领域移位，当模型的训练和测试语料的分布不同时发生。在讨论开放性研究问题的同时，本文还评估了与特定领域文本摘要相关的现有最新技术，以弥补研究差距。"
    },
    {
        "title": "Improving Address Matching using Siamese Transformer Networks",
        "url": "http://arxiv.org/abs/2307.02300v1",
        "pub_date": "2023-07-05",
        "summary": "Matching addresses is a critical task for companies and post offices involved\nin the processing and delivery of packages. The ramifications of incorrectly\ndelivering a package to the wrong recipient are numerous, ranging from harm to\nthe company's reputation to economic and environmental costs. This research\nintroduces a deep learning-based model designed to increase the efficiency of\naddress matching for Portuguese addresses. The model comprises two parts: (i) a\nbi-encoder, which is fine-tuned to create meaningful embeddings of Portuguese\npostal addresses, utilized to retrieve the top 10 likely matches of the\nun-normalized target address from a normalized database, and (ii) a\ncross-encoder, which is fine-tuned to accurately rerank the 10 addresses\nobtained by the bi-encoder. The model has been tested on a real-case scenario\nof Portuguese addresses and exhibits a high degree of accuracy, exceeding 95%\nat the door level. When utilized with GPU computations, the inference speed is\nabout 4.5 times quicker than other traditional approaches such as BM25. An\nimplementation of this system in a real-world scenario would substantially\nincrease the effectiveness of the distribution process. Such an implementation\nis currently under investigation.",
        "translated": "配对地址是处理和交付包裹的公司和邮局的一项关键任务。错误地向错误的收件人发送包裹的后果是多方面的，从对公司声誉的损害到经济和环境成本。本研究引入了一个基于深度学习的模型，旨在提高葡萄牙语地址匹配的效率。该模型由两部分组成: (i)双编码器，其经过微调以创建有意义的葡萄牙邮政地址嵌入，用于从标准化数据库中检索非标准化目标地址的前10个可能匹配; (ii)交叉编码器，其经过微调以准确地重新排列双编码器获得的10个地址。该模型已经在葡萄牙地址的实际情况下进行了测试，并显示出高度的准确性，在门级超过95% 。当使用 GPU 计算时，推理速度比其他传统方法如 BM25快约4.5倍。在现实世界中实施这一系统将大大提高分配过程的有效性。这样的实施目前正在调查之中。"
    },
    {
        "title": "An Equivalent Graph Reconstruction Model and its Application in\n  Recommendation Prediction",
        "url": "http://arxiv.org/abs/2307.02183v1",
        "pub_date": "2023-07-05",
        "summary": "Recommendation algorithm plays an important role in recommendation system\n(RS), which predicts users' interests and preferences for some given items\nbased on their known information. Recently, a recommendation algorithm based on\nthe graph Laplacian regularization was proposed, which treats the prediction\nproblem of the recommendation system as a reconstruction issue of small samples\nof the graph signal under the same graph model. Such a technique takes into\naccount both known and unknown labeled samples information, thereby obtaining\ngood prediction accuracy. However, when the data size is large, solving the\nreconstruction model is computationally expensive even with an approximate\nstrategy. In this paper, we propose an equivalent reconstruction model that can\nbe solved exactly with extremely low computational cost. Finally, a final\nprediction algorithm is proposed. We find in the experiments that the proposed\nmethod significantly reduces the computational cost while maintaining a good\nprediction accuracy.",
        "translated": "推荐算法在推荐系统(RS)中起着重要作用，它根据用户的已知信息预测用户对某一特定项目的兴趣和偏好。最近，提出了一种基于图拉普拉斯正则化的推荐算法，将推荐系统的预测问题看作是同一图模型下图信号小样本的重构问题。这种方法同时考虑了已知和未知的标记样本信息，从而获得了较好的预测精度。然而，当数据量较大时，即使采用近似策略，求解重建模型的计算量也很大。在本文中，我们提出了一个等效重建模型，可以用极低的计算成本精确求解。最后，提出了最终的预测算法。实验结果表明，该方法在保持较高预测精度的同时，大大降低了计算量。"
    },
    {
        "title": "Generative Job Recommendations with Large Language Model",
        "url": "http://arxiv.org/abs/2307.02157v1",
        "pub_date": "2023-07-05",
        "summary": "The rapid development of online recruitment services has encouraged the\nutilization of recommender systems to streamline the job seeking process.\nPredominantly, current job recommendations deploy either collaborative\nfiltering or person-job matching strategies. However, these models tend to\noperate as \"black-box\" systems and lack the capacity to offer explainable\nguidance to job seekers. Moreover, conventional matching-based recommendation\nmethods are limited to retrieving and ranking existing jobs in the database,\nrestricting their potential as comprehensive career AI advisors. To this end,\nhere we present GIRL (GeneratIve job Recommendation based on Large language\nmodels), a novel approach inspired by recent advancements in the field of Large\nLanguage Models (LLMs). We initially employ a Supervised Fine-Tuning (SFT)\nstrategy to instruct the LLM-based generator in crafting suitable Job\nDescriptions (JDs) based on the Curriculum Vitae (CV) of a job seeker.\nMoreover, we propose to train a model which can evaluate the matching degree\nbetween CVs and JDs as a reward model, and we use Proximal Policy Optimization\n(PPO)-based Reinforcement Learning (RL) method to further fine-tine the\ngenerator. This aligns the generator with recruiter feedback, tailoring the\noutput to better meet employer preferences. In particular, GIRL serves as a job\nseeker-centric generative model, providing job suggestions without the need of\na candidate set. This capability also enhances the performance of existing job\nrecommendation models by supplementing job seeking features with generated\ncontent. With extensive experiments on a large-scale real-world dataset, we\ndemonstrate the substantial effectiveness of our approach. We believe that GIRL\nintroduces a paradigm-shifting approach to job recommendation systems,\nfostering a more personalized and comprehensive job-seeking experience.",
        "translated": "在线征聘服务的迅速发展鼓励利用推荐系统精简求职过程。当前的工作推荐主要采用协同过滤或人员-工作匹配策略。然而，这些模式往往作为“黑箱”系统运作，缺乏能力提供可解释的指导，以求职者。此外，传统的基于匹配的推荐方法仅限于检索和排序数据库中现有的工作，限制了它们作为综合职业人工智能顾问的潜力。为此，我们在这里介绍 GIRL (基于大型语言模型的 GeneratIve 工作推荐) ，这是一种受到大型语言模型(LLM)领域最新进展启发的新方法。我们最初采用监督微调(SFT)策略来指导基于 LLM 的生成器根据求职者的简历(CV)制定合适的工作描述(JDs)。此外，我们建议训练一个模型来评估简历和法律顾问之间的匹配程度作为报酬模型，并且我们使用基于最近策略优化(PPO)的强化学习(RL)方法来进一步细化生成器。这将使生成器与招聘人员的反馈保持一致，调整输出以更好地满足雇主的偏好。特别是，女孩是一个以求职者为中心的生成模型，提供工作建议而不需要候选人集。这一能力还通过用生成的内容补充求职特征，提高了现有职位推荐模式的绩效。通过在大规模真实世界数据集上的大量实验，我们证明了该方法的实质性有效性。我们认为，GIRL 在工作推荐系统中引入了一种范式转换的方法，培养了一种更加个性化和全面的求职体验。"
    },
    {
        "title": "Recommendation Unlearning via Influence Function",
        "url": "http://arxiv.org/abs/2307.02147v1",
        "pub_date": "2023-07-05",
        "summary": "Recommendation unlearning is an emerging task to serve users for erasing\nunusable data (e.g., some historical behaviors) from a well-trained recommender\nmodel. Existing methods process unlearning requests by fully or partially\nretraining the model after removing the unusable data. However, these methods\nare impractical due to the high computation cost of full retraining and the\nhighly possible performance damage of partial training. In this light, a\ndesired recommendation unlearning method should obtain a similar model as full\nretraining in a more efficient manner, i.e., achieving complete, efficient and\ninnocuous unlearning. In this work, we propose an Influence Function-based\nRecommendation Unlearning (IFRU) framework, which efficiently updates the model\nwithout retraining by estimating the influence of the unusable data on the\nmodel via the influence function. In the light that recent recommender models\nuse historical data for both the constructions of the optimization loss and the\ncomputational graph (e.g., neighborhood aggregation), IFRU jointly estimates\nthe direct influence of unusable data on optimization loss and the spillover\ninfluence on the computational graph to pursue complete unlearning.\nFurthermore, we propose an importance-based pruning algorithm to reduce the\ncost of the influence function. IFRU is innocuous and applicable to mainstream\ndifferentiable models. Extensive experiments demonstrate that IFRU achieves\nmore than250times acceleration compared to retraining-based methods with\nrecommendation performance comparable to full retraining.",
        "translated": "推荐取消学习是一个新兴的任务，它为用户从训练有素的推荐模型中删除不可用的数据(例如，一些历史行为)提供服务。现有方法在删除不可用数据之后，通过完全或部分重新训练模型来处理忘记请求。然而，由于完全再训练的计算量大，部分训练极有可能造成性能损失，这些方法都是不切实际的。因此，一个理想的推荐忘却方法应该获得一个类似于以一种更有效的方式完全再训练的模型，即，实现完全的、有效的和无害的忘却。在这项工作中，我们提出了一个基于影响函数的推荐去学习(IFRU)框架，它通过估计不可用数据对模型的影响来有效地更新模型而不需要再训练。鉴于最近的推荐模型使用历史数据构造优化损失和计算图(例如，邻域聚合) ，IFRU 联合估计不可用数据对优化损失的直接影响和溢出对计算图的影响，以追求完全忘却。此外，我们还提出了一种基于重要性的剪枝算法来降低影响函数的代价。IFRU 是无害的，适用于主流可微模型。大量的实验表明，与再培训方法相比，IFRU 实现了250倍以上的加速，推荐性能与完全再培训相当。"
    },
    {
        "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
        "url": "http://arxiv.org/abs/2307.02046v1",
        "pub_date": "2023-07-05",
        "summary": "With the prosperity of e-commerce and web applications, Recommender Systems\n(RecSys) have become an important component of our daily life, providing\npersonalized suggestions that cater to user preferences. While Deep Neural\nNetworks (DNNs) have made significant advancements in enhancing recommender\nsystems by modeling user-item interactions and incorporating textual side\ninformation, DNN-based methods still face limitations, such as difficulties in\nunderstanding users' interests and capturing textual side information,\ninabilities in generalizing to various recommendation scenarios and reasoning\non their predictions, etc. Meanwhile, the emergence of Large Language Models\n(LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), due to their\nremarkable abilities in fundamental responsibilities of language understanding\nand generation, as well as impressive generalization and reasoning\ncapabilities. As a result, recent studies have attempted to harness the power\nof LLMs to enhance recommender systems. Given the rapid evolution of this\nresearch direction in recommender systems, there is a pressing need for a\nsystematic overview that summarizes existing LLM-empowered recommender systems,\nto provide researchers in relevant fields with an in-depth understanding.\nTherefore, in this paper, we conduct a comprehensive review of LLM-empowered\nrecommender systems from various aspects including Pre-training, Fine-tuning,\nand Prompting. More specifically, we first introduce representative methods to\nharness the power of LLMs (as a feature encoder) for learning representations\nof users and items. Then, we review recent techniques of LLMs for enhancing\nrecommender systems from three paradigms, namely pre-training, fine-tuning, and\nprompting. Finally, we comprehensively discuss future directions in this\nemerging field.",
        "translated": "随着电子商务和网络应用程序的繁荣，推荐系统(RecSys)已成为我们日常生活的重要组成部分，提供个性化的建议，以迎合用户的喜好。虽然深度神经网络(DNN)通过建立用户-项目交互模型和结合文本侧信息在增强推荐系统方面取得了重大进展，但是基于 DNN 的方法仍然面临着局限性，如难以理解用户的兴趣和获取文本侧信息，无法推广到各种推荐场景和推理他们的预测等。同时，大语言模型(LLM)的出现，如 ChatGPT 和 GPT4的出现，使自然语言处理(NLP)和人工智能(AI)领域发生了革命性的变化，因为它们在语言理解和生成的基本责任方面具有非凡的能力，以及令人印象深刻的泛化和推理能力。因此，最近的研究试图利用 LLM 的力量来增强推荐系统。鉴于这一研究方向在推荐系统中的快速发展，迫切需要一个系统的概述，总结现有的 LLM 授权的推荐系统，为相关领域的研究人员提供了深入的了解。因此，本文从预训练、微调和激励三个方面对 LLM 授权的推荐系统进行了全面的综述。更具体地说，我们首先介绍一些代表性的方法来利用 LLM (作为一种特性编码器)的强大功能来学习用户和项目的表示。然后，我们从三个范例，即预训练、微调和激励，回顾了 LLM 最近用于增强推荐系统的技术。最后，我们全面讨论了这一新兴领域的未来发展方向。"
    },
    {
        "title": "LongNet: Scaling Transformers to 1,000,000,000 Tokens",
        "url": "http://arxiv.org/abs/2307.02486v1",
        "pub_date": "2023-07-05",
        "summary": "Scaling sequence length has become a critical demand in the era of large\nlanguage models. However, existing methods struggle with either computational\ncomplexity or model expressivity, rendering the maximum sequence length\nrestricted. In this work, we introduce LongNet, a Transformer variant that can\nscale sequence length to more than 1 billion tokens, without sacrificing the\nperformance on shorter sequences. Specifically, we propose dilated attention,\nwhich expands the attentive field exponentially as the distance grows. LongNet\nhas significant advantages: 1) it has a linear computation complexity and a\nlogarithm dependency between tokens; 2) it can be served as a distributed\ntrainer for extremely long sequences; 3) its dilated attention is a drop-in\nreplacement for standard attention, which can be seamlessly integrated with the\nexisting Transformer-based optimization. Experiments results demonstrate that\nLongNet yields strong performance on both long-sequence modeling and general\nlanguage tasks. Our work opens up new possibilities for modeling very long\nsequences, e.g., treating a whole corpus or even the entire Internet as a\nsequence.",
        "translated": "缩放序列长度已经成为大型语言模型时代的一个关键要求。然而，现有的方法要么计算复杂度，要么模型表现力，使最大序列长度受到限制。在这项工作中，我们引入了 LongNet，这是一个 Transformer 变体，它可以将序列长度扩展到超过10亿个令牌，而不会牺牲较短序列的性能。具体来说，我们提出了扩张注意，随着距离的增长，扩张注意领域呈指数级增长。LongNet 具有显著的优势: 1)它具有线性计算复杂度和令牌之间的对数依赖性; 2)它可以作为超长序列的分布式训练器; 3)它的分散注意力是标准注意力的替代品，可以与现有的基于 Transformer 的优化无缝集成。实验结果表明，LongNet 在长序列建模和一般语言任务上都有很好的性能。我们的工作为建立非常长的序列模型开辟了新的可能性，例如，将整个语料库甚至整个互联网作为一个序列处理。"
    },
    {
        "title": "Building Cooperative Embodied Agents Modularly with Large Language\n  Models",
        "url": "http://arxiv.org/abs/2307.02485v1",
        "pub_date": "2023-07-05",
        "summary": "Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website https://vis-www.cs.umass.edu/Co-LLM-Agents/.",
        "translated": "大型语言模型(LLM)在不同领域的单代理嵌入式任务中展示了令人印象深刻的规划能力。然而，它们在多代理协作中的计划和通信能力仍然不清楚，尽管这些是智能体化代理的关键技能。在本文中，我们提出了一个新的框架，利用 LLM 的多智能体协作和测试它在各种具体的环境。我们的框架使得具象化代理能够计划、沟通并与其他具象化代理或人类合作，有效地完成长期任务。我们展示了最近的 LLM，例如 GPT-4，可以超越强大的基于规划的方法，并且使用我们的框架展示出紧急的有效通信，而不需要微调或少镜头提示。我们还发现，使用自然语言进行交流的基于 LLM 的代理可以获得更多的信任，并且与人类进行更有效的合作。我们的研究强调了 LLM 在体现人工智能方面的潜力，并为未来多智能体协作的研究奠定了基础。视频可以在项目网站的 https://vis-www.cs.umass.edu/co-llm-agents/找到。"
    },
    {
        "title": "Reasoning or Reciting? Exploring the Capabilities and Limitations of\n  Language Models Through Counterfactual Tasks",
        "url": "http://arxiv.org/abs/2307.02477v1",
        "pub_date": "2023-07-05",
        "summary": "The impressive performance of recent language models across a wide range of\ntasks suggests that they possess a degree of abstract reasoning skills. Are\nthese skills general and transferable, or specialized to specific tasks seen\nduring pretraining? To disentangle these effects, we propose an evaluation\nframework based on \"counterfactual\" task variants that deviate from the default\nassumptions underlying standard tasks. Across a suite of 11 tasks, we observe\nnontrivial performance on the counterfactual variants, but nevertheless find\nthat performance substantially and consistently degrades compared to the\ndefault conditions. This suggests that while current LMs may possess abstract\ntask-solving skills to a degree, they often also rely on narrow,\nnon-transferable procedures for task-solving. These results motivate a more\ncareful interpretation of language model performance that teases apart these\naspects of behavior.",
        "translated": "最近的语言模型在广泛的任务中的令人印象深刻的表现表明，它们拥有一定程度的抽象推理技能。这些技能是通用的和可转移的，还是专门用于培训前的特定任务？为了理清这些影响，我们提出了一个基于“反事实”任务变量的评估框架，它偏离了标准任务的默认假设。在一组11个任务中，我们观察到反事实变量的非平凡性能，但是仍然发现性能与默认条件相比大幅度且持续地下降。这表明，虽然目前的 LM 可能在一定程度上拥有抽象的任务解决技能，但他们也常常依赖于狭窄的，不可转移的任务解决程序。这些结果促使人们对语言模型的表现进行更仔细的解释，从而分离出行为的这些方面。"
    },
    {
        "title": "Deductive Additivity for Planning of Natural Language Proofs",
        "url": "http://arxiv.org/abs/2307.02472v2",
        "pub_date": "2023-07-05",
        "summary": "Current natural language systems designed for multi-step claim validation\ntypically operate in two phases: retrieve a set of relevant premise statements\nusing heuristics (planning), then generate novel conclusions from those\nstatements using a large language model (deduction). The planning step often\nrequires expensive Transformer operations and does not scale to arbitrary\nnumbers of premise statements. In this paper, we investigate whether an\nefficient planning heuristic is possible via embedding spaces compatible with\ndeductive reasoning. Specifically, we evaluate whether embedding spaces exhibit\na property we call deductive additivity: the sum of premise statement\nembeddings should be close to embeddings of conclusions based on those\npremises. We explore multiple sources of off-the-shelf dense embeddings in\naddition to fine-tuned embeddings from GPT3 and sparse embeddings from BM25. We\nstudy embedding models both intrinsically, evaluating whether the property of\ndeductive additivity holds, and extrinsically, using them to assist planning in\nnatural language proof generation. Lastly, we create a dataset, Single-Step\nReasoning Contrast (SSRC), to further probe performance on various reasoning\ntypes. Our findings suggest that while standard embedding methods frequently\nembed conclusions near the sums of their premises, they fall short of being\neffective heuristics and lack the ability to model certain categories of\nreasoning.",
        "translated": "目前设计用于多步索赔验证的自然语言系统通常分为两个阶段: 使用启发式(规划)检索一组相关的前提陈述，然后使用大型语言模型(演绎)从这些陈述中生成新的结论。规划步骤通常需要开销很大的 Transformer 操作，并且不能扩展到任意数量的前提语句。在本文中，我们研究是否可以通过嵌入与演绎推理兼容的空间来实现有效的规划启发式。具体来说，我们评估嵌入空间是否具有一个我们称之为演绎可加性的性质: 前提陈述嵌入的总和应该接近于基于这些前提的结论的嵌入。除了来自 GPT3的微调嵌入和来自 BM25的稀疏嵌入，我们还探索了多种现成的稠密嵌入来源。我们研究嵌入模型的内在价值，评估演绎可加性的性质是否成立，以及外在地使用它们来协助规划自然语言的证明生成。最后，我们创建一个数据集，单步推理对比度(SSRC) ，以进一步探讨各种推理类型的性能。我们的研究结果表明，虽然标准的嵌入方法经常嵌入结论附近的前提总和，他们不是有效的启发式和缺乏能力建模某些类别的推理。"
    },
    {
        "title": "What Matters in Training a GPT4-Style Language Model with Multimodal\n  Inputs?",
        "url": "http://arxiv.org/abs/2307.02469v1",
        "pub_date": "2023-07-05",
        "summary": "Recent advancements in Large Language Models (LLMs) such as GPT4 have\ndisplayed exceptional multi-modal capabilities in following open-ended\ninstructions given images. However, the performance of these models heavily\nrelies on design choices such as network structures, training data, and\ntraining strategies, and these choices have not been extensively discussed in\nthe literature, making it difficult to quantify progress in this field. To\naddress this issue, this paper presents a systematic and comprehensive study,\nquantitatively and qualitatively, on training such models. We implement over 20\nvariants with controlled settings. Concretely, for network structures, we\ncompare different LLM backbones and model designs. For training data, we\ninvestigate the impact of data and sampling strategies. For instructions, we\nexplore the influence of diversified prompts on the instruction-following\nability of the trained models. For benchmarks, we contribute the first, to our\nbest knowledge, comprehensive evaluation set including both image and video\ntasks through crowd-sourcing. Based on our findings, we present Lynx, which\nperforms the most accurate multi-modal understanding while keeping the best\nmulti-modal generation ability compared to existing open-sourced GPT4-style\nmodels.",
        "translated": "最近在大型语言模型(LLM)方面的进展，例如 GPT4，已经显示了在给定图像的开放式指令下的异常多模态功能。然而，这些模型的性能很大程度上依赖于网络结构、训练数据和训练策略等设计选择，而这些选择在文献中没有得到广泛的讨论，因此难以量化该领域的进展。为了解决这一问题，本文从定量和定性两个方面对此类模型的训练进行了系统、全面的研究。我们实现了超过20种具有可控设置的变体。具体地，对于网络结构，我们比较了不同的 LLM 骨架和模型设计。对于训练数据，我们调查数据和抽样策略的影响。在教学方面，我们探讨了不同的提示对受训模型教学跟踪能力的影响。对于基准测试，我们提供了第一个，我们最好的知识，全面的评估集，包括图像和视频的任务，通过众包。基于我们的研究结果，我们提出 Lynx，执行最准确的多模态理解，同时保持最好的多模态生成能力相比，现有的开源 GPT4风格的模型。"
    },
    {
        "title": "An Exploratory Literature Study on Sharing and Energy Use of Language\n  Models for Source Code",
        "url": "http://arxiv.org/abs/2307.02443v1",
        "pub_date": "2023-07-05",
        "summary": "Large language models trained on source code can support a variety of\nsoftware development tasks, such as code recommendation and program repair.\nLarge amounts of data for training such models benefit the models' performance.\nHowever, the size of the data and models results in long training times and\nhigh energy consumption. While publishing source code allows for replicability,\nusers need to repeat the expensive training process if models are not shared.\nThe main goal of the study is to investigate if publications that trained\nlanguage models for software engineering (SE) tasks share source code and\ntrained artifacts. The second goal is to analyze the transparency on training\nenergy usage. We perform a snowballing-based literature search to find\npublications on language models for source code, and analyze their reusability\nfrom a sustainability standpoint.\n  From 494 unique publications, we identified 293 relevant publications that\nuse language models to address code-related tasks. Among them, 27% (79 out of\n293) make artifacts available for reuse. This can be in the form of tools or\nIDE plugins designed for specific tasks or task-agnostic models that can be\nfine-tuned for a variety of downstream tasks. Moreover, we collect insights on\nthe hardware used for model training, as well as training time, which together\ndetermine the energy consumption of the development process. We find that there\nare deficiencies in the sharing of information and artifacts for current\nstudies on source code models for software engineering tasks, with 40% of the\nsurveyed papers not sharing source code or trained artifacts. We recommend the\nsharing of source code as well as trained artifacts, to enable sustainable\nreproducibility. Moreover, comprehensive information on training times and\nhardware configurations should be shared for transparency on a model's carbon\nfootprint.",
        "translated": "对源代码进行培训的大型语言模型可以支持各种软件开发任务，例如代码推荐和程序修复。训练这些模型的大量数据有利于模型的性能。然而，数据和模型的大小导致训练时间长和能源消耗高。虽然发布源代码允许可复制性，但是如果不共享模型，用户需要重复代价高昂的培训过程。该研究的主要目的是调查软件工程(SE)任务的训练语言模型的出版物是否共享源代码和训练过的工件。第二个目标是分析培训能源使用的透明度。我们进行了一个滚雪球式的文献检索，寻找关于源代码语言模型的出版物，并从可持续性的角度分析它们的可重用性。从494个独特的出版物中，我们确定了293个使用语言模型处理与代码相关任务的相关出版物。其中，27% (293个中的79个)使工件可以重用。这可以采用为特定任务设计的工具或 IDE 插件的形式，或者可以针对各种下游任务进行微调的任务无关模型。此外，我们收集了用于模型训练的硬件以及训练时间的见解，这些共同决定了开发过程的能源消耗。我们发现，在软件工程任务的源代码模型的当前研究中，信息和工件的共享存在缺陷，40% 的被调查论文不共享源代码或受过训练的工件。我们建议共享源代码以及经过培训的工件，以实现可持续的可重复性。此外，培训时间和硬件配置的全面信息应该共享，以保证模型碳足印的透明度。"
    },
    {
        "title": "Exploring Continual Learning for Code Generation Models",
        "url": "http://arxiv.org/abs/2307.02435v1",
        "pub_date": "2023-07-05",
        "summary": "Large-scale code generation models such as Codex and CodeT5 have achieved\nimpressive performance. However, libraries are upgraded or deprecated very\nfrequently and re-training large-scale language models is computationally\nexpensive. Therefore, Continual Learning (CL) is an important aspect that\nremains underexplored in the code domain. In this paper, we introduce a\nbenchmark called CodeTask-CL that covers a wide range of tasks, including code\ngeneration, translation, summarization, and refinement, with different input\nand output programming languages. Next, on our CodeTask-CL benchmark, we\ncompare popular CL techniques from NLP and Vision domains. We find that\neffective methods like Prompt Pooling (PP) suffer from catastrophic forgetting\ndue to the unstable training of the prompt selection mechanism caused by stark\ndistribution shifts in coding tasks. We address this issue with our proposed\nmethod, Prompt Pooling with Teacher Forcing (PP-TF), that stabilizes training\nby enforcing constraints on the prompt selection mechanism and leads to a\n21.54% improvement over Prompt Pooling. Along with the benchmark, we establish\na training pipeline that can be used for CL on code models, which we believe\ncan motivate further development of CL methods for code models. Our code is\navailable at https://github.com/amazon-science/codetaskcl-pptf",
        "translated": "Codex 和 CodeT5等大规模代码生成模型已经取得了令人印象深刻的性能。然而，库的升级或弃用非常频繁，重新训练大规模的语言模型在计算上是昂贵的。因此，持续学习(CL)是一个重要的方面，在代码域中仍然没有得到充分的研究。在本文中，我们介绍了一个名为 CodeTask-CL 的基准测试，它涵盖了广泛的任务，包括代码生成、翻译、摘要和细化，使用不同的输入和输出编程语言。接下来，在我们的 CodeTask-CL 基准上，我们比较了来自 NLP 和 Vision 域的流行 CL 技术。我们发现，由于编码任务中的严格分布变化导致了对提示选择机制的不稳定训练，使得像提示合用(PP)这样的有效方法遭受了灾难性遗忘。我们通过我们提出的方法来解决这个问题，即通过对及时选择机制实施约束来稳定培训，并导致比及时汇集提高21.54% 。与基准一起，我们建立了一个可以用于代码模型上 CL 的培训管道，我们相信这可以促进代码模型 CL 方法的进一步开发。我们的代码可以在 https://github.com/amazon-science/codetaskcl-pptf 找到"
    },
    {
        "title": "Won't Get Fooled Again: Answering Questions with False Premises",
        "url": "http://arxiv.org/abs/2307.02394v1",
        "pub_date": "2023-07-05",
        "summary": "Pre-trained language models (PLMs) have shown unprecedented potential in\nvarious fields, especially as the backbones for question-answering (QA)\nsystems. However, they tend to be easily deceived by tricky questions such as\n\"How many eyes does the sun have?\". Such frailties of PLMs often allude to the\nlack of knowledge within them. In this paper, we find that the PLMs already\npossess the knowledge required to rebut such questions, and the key is how to\nactivate the knowledge. To systematize this observation, we investigate the\nPLMs' responses to one kind of tricky questions, i.e., the false premises\nquestions (FPQs). We annotate a FalseQA dataset containing 2365 human-written\nFPQs, with the corresponding explanations for the false premises and the\nrevised true premise questions. Using FalseQA, we discover that PLMs are\ncapable of discriminating FPQs by fine-tuning on moderate numbers (e.g., 256)\nof examples. PLMs also generate reasonable explanations for the false premise,\nwhich serve as rebuttals. Further replaying a few general questions during\ntraining allows PLMs to excel on FPQs and general questions simultaneously. Our\nwork suggests that once the rebuttal ability is stimulated, knowledge inside\nthe PLMs can be effectively utilized to handle FPQs, which incentivizes the\nresearch on PLM-based QA systems.",
        "translated": "预训练语言模型(PLM)在各个领域显示出前所未有的潜力，尤其是作为问答系统的骨干。然而，他们往往很容易被一些棘手的问题所欺骗，比如“太阳有多少只眼睛?”.PLM 的这些弱点往往暗示着它们缺乏知识。在本文中，我们发现 PLM 已经具备了反驳这些问题所需要的知识，关键是如何激活这些知识。为了系统化这一观察，我们调查了 PLM 对一类棘手问题的回答，即错误前提问题(FPQ)。我们注释了一个包含2365个人写的 FPQ 的 FalseQA 数据集，并对虚假前提和修订后的真实前提问题进行了相应的解释。通过使用 FalseQA，我们发现 PLM 能够通过对中等数量(例如256)的示例进行微调来区分 FPQ。PLM 还对错误的前提提供合理的解释，作为反驳。在培训期间进一步重复一些常规问题可以让 PLM 同时在 FPQ 和常规问题上表现出色。我们的工作表明，一旦反驳能力得到激发，PLM 内部的知识可以被有效地利用来处理 FPQ，这激励了基于 PLM 的 QA 系统的研究。"
    },
    {
        "title": "Causal Discovery with Language Models as Imperfect Experts",
        "url": "http://arxiv.org/abs/2307.02390v1",
        "pub_date": "2023-07-05",
        "summary": "Understanding the causal relationships that underlie a system is a\nfundamental prerequisite to accurate decision-making. In this work, we explore\nhow expert knowledge can be used to improve the data-driven identification of\ncausal graphs, beyond Markov equivalence classes. In doing so, we consider a\nsetting where we can query an expert about the orientation of causal\nrelationships between variables, but where the expert may provide erroneous\ninformation. We propose strategies for amending such expert knowledge based on\nconsistency properties, e.g., acyclicity and conditional independencies in the\nequivalence class. We then report a case study, on real data, where a large\nlanguage model is used as an imperfect expert.",
        "translated": "理解系统的因果关系是做出准确决策的基本前提。在这项工作中，我们探讨了如何利用专家知识，以改善数据驱动的因果图识别，超越马尔可夫等价类。在这样做的时候，我们考虑一个设置，在这个设置中，我们可以询问专家关于变量之间因果关系的方向，但是专家可能提供错误的信息。我们根据一致性属性，例如等价类中的非周期性和条件独立性，提出修正这类专家知识的策略。然后，我们报告一个案例研究，在真实的数据，其中一个大的语言模型被用作一个不完美的专家。"
    },
    {
        "title": "To be or not to be: a translation reception study of a literary text\n  translated into Dutch and Catalan using machine translation",
        "url": "http://arxiv.org/abs/2307.02358v1",
        "pub_date": "2023-07-05",
        "summary": "This article presents the results of a study involving the reception of a\nfictional story by Kurt Vonnegut translated from English into Catalan and Dutch\nin three conditions: machine-translated (MT), post-edited (PE) and translated\nfrom scratch (HT). 223 participants were recruited who rated the reading\nconditions using three scales: Narrative Engagement, Enjoyment and Translation\nReception. The results show that HT presented a higher engagement, enjoyment\nand translation reception in Catalan if compared to PE and MT. However, the\nDutch readers show higher scores in PE than in both HT and MT, and the highest\nengagement and enjoyments scores are reported when reading the original English\nversion. We hypothesize that when reading a fictional story in translation, not\nonly the condition and the quality of the translations is key to understand its\nreception, but also the participants reading patterns, reading language, and,\nperhaps language status in their own societies.",
        "translated": "本文介绍了库尔特 · 冯内古特(Kurt Vonnegut)的小说在机器翻译(MT)、后期编辑(PE)和从头翻译(HT)三种情况下对加泰罗尼亚语和荷兰语的接受研究结果。本研究选取223名参与者，采用叙事投入、享受和翻译接受三个量表对阅读条件进行评分。结果显示，与 PE 和 MT 相比，HT 在加泰罗尼亚语中表现出更高的参与度，享受度和翻译接受度。然而，荷兰读者在 PE 中的分数高于 HT 和 MT，并且在阅读原始英语版本时报告了最高的参与度和享受度分数。我们假设，当阅读翻译中的虚构故事时，不仅翻译的条件和质量是理解其接受的关键，而且参与者阅读模式，阅读语言，也许还有他们自己社会中的语言地位。"
    },
    {
        "title": "MultiVENT: Multilingual Videos of Events with Aligned Natural Text",
        "url": "http://arxiv.org/abs/2307.03153v1",
        "pub_date": "2023-07-06",
        "summary": "Everyday news coverage has shifted from traditional broadcasts towards a wide\nrange of presentation formats such as first-hand, unedited video footage.\nDatasets that reflect the diverse array of multimodal, multilingual news\nsources available online could be used to teach models to benefit from this\nshift, but existing news video datasets focus on traditional news broadcasts\nproduced for English-speaking audiences. We address this limitation by\nconstructing MultiVENT, a dataset of multilingual, event-centric videos\ngrounded in text documents across five target languages. MultiVENT includes\nboth news broadcast videos and non-professional event footage, which we use to\nanalyze the state of online news videos and how they can be leveraged to build\nrobust, factually accurate models. Finally, we provide a model for complex,\nmultilingual video retrieval to serve as a baseline for information retrieval\nusing MultiVENT.",
        "translated": "每天的新闻报道已经从传统的广播转向各种各样的报道形式，例如第一手的、未经编辑的视频素材。反映在线多模式、多语种新闻来源多样性的数据集可用于教导模式从这一转变中受益，但现有的新闻视频数据集侧重于为讲英语的受众制作的传统新闻广播。我们通过构建 MultiVENT 来解决这个限制，MultiVENT 是一个基于五种目标语言的文本文档的多语言、以事件为中心的视频数据集。MultiVENT 包括新闻广播视频和非专业事件视频，我们用它们来分析在线新闻视频的状态，以及如何利用它们来建立强大的、真实准确的模型。最后，我们提供了一个复杂的多语言视频检索模型，作为使用 MultivENT 进行信息检索检索的基准。"
    },
    {
        "title": "Track Mix Generation on Music Streaming Services using Transformers",
        "url": "http://arxiv.org/abs/2307.03045v1",
        "pub_date": "2023-07-06",
        "summary": "This paper introduces Track Mix, a personalized playlist generation system\nreleased in 2022 on the music streaming service Deezer. Track Mix automatically\ngenerates \"mix\" playlists inspired by initial music tracks, allowing users to\ndiscover music similar to their favorite content. To generate these mixes, we\nconsider a Transformer model trained on millions of track sequences from user\nplaylists. In light of the growing popularity of Transformers in recent years,\nwe analyze the advantages, drawbacks, and technical challenges of using such a\nmodel for mix generation on the service, compared to a more traditional\ncollaborative filtering approach. Since its release, Track Mix has been\ngenerating playlists for millions of users daily, enhancing their music\ndiscovery experience on Deezer.",
        "translated": "本文介绍了 TrackMix，一个2022年在音乐流媒体服务 Deezer 上发布的个性化播放列表生成系统。TrackMix 自动生成受初始音乐曲目启发的“混合”播放列表，允许用户发现与他们喜欢的内容相似的音乐。为了生成这些混音，我们考虑一个从用户播放列表中的数百万音轨序列中训练的 Transformer 模型。鉴于近年来变压器越来越受欢迎，我们分析了使用这种模式混合生成服务的优点，缺点和技术挑战，相比较更传统的协同过滤方法。自从发布以来，TrackMix 每天为数百万用户生成播放列表，增强了他们在 Deezer 上的音乐发现体验。"
    },
    {
        "title": "Improving Retrieval-Augmented Large Language Models via Data Importance\n  Learning",
        "url": "http://arxiv.org/abs/2307.03027v1",
        "pub_date": "2023-07-06",
        "summary": "Retrieval augmentation enables large language models to take advantage of\nexternal knowledge, for example on tasks like question answering and data\nimputation. However, the performance of such retrieval-augmented models is\nlimited by the data quality of their underlying retrieval corpus. In this\npaper, we propose an algorithm based on multilinear extension for evaluating\nthe data importance of retrieved data points. There are exponentially many\nterms in the multilinear extension, and one key contribution of this paper is a\npolynomial time algorithm that computes exactly, given a retrieval-augmented\nmodel with an additive utility function and a validation set, the data\nimportance of data points in the retrieval corpus using the multilinear\nextension of the model's utility function. We further proposed an even more\nefficient ({\\epsilon}, {\\delta})-approximation algorithm. Our experimental\nresults illustrate that we can enhance the performance of large language models\nby only pruning or reweighting the retrieval corpus, without requiring further\ntraining. For some tasks, this even allows a small model (e.g., GPT-JT),\naugmented with a search engine API, to outperform GPT-3.5 (without retrieval\naugmentation). Moreover, we show that weights based on multilinear extension\ncan be computed efficiently in practice (e.g., in less than ten minutes for a\ncorpus with 100 million elements).",
        "translated": "检索增强使大型语言模型能够利用外部知识，例如在问题回答和数据插补等任务上。然而，这种检索增强模型的性能受到其基础检索语料库数据质量的限制。本文提出了一种基于多线性可拓的检索点数据重要性评估算法。多线性扩展中的项数呈指数级增长，本文的一个重要贡献是提出了一种多项式时间算法，该算法利用模型的效用函数的多线性扩展，给定一个具有加性效用函数和验证集的检索增强模型，精确地计算了检索语料库中数据点的数据重要性。我们进一步提出了一个更有效的({ epsilon } ，{ delta })-近似演算法。实验结果表明，只需对检索语料进行剪枝或重新加权，就可以提高大型语言模型的性能，而不需要进一步的训练。对于某些任务，这甚至允许一个小型模型(例如，GPT-JT) ，通过一个搜索引擎 API 进行增强，其性能优于 GPT-3.5(没有检索增强)。此外，我们表明，基于多线性扩展的权重可以有效地计算在实践中(例如，在不到10分钟的一个语料库的1亿元素)。"
    },
    {
        "title": "A Meta-Evaluation of C/W/L/A Metrics: System Ranking Similarity, System\n  Ranking Consistency and Discriminative Power",
        "url": "http://arxiv.org/abs/2307.02936v1",
        "pub_date": "2023-07-06",
        "summary": "Recently, Moffat et al. proposed an analytic framework, namely C/W/L/A, for\noffline evaluation metrics. This framework allows information retrieval (IR)\nresearchers to design evaluation metrics through the flexible combination of\nuser browsing models and user gain aggregations. However, the statistical\nstability of C/W/L/A metrics with different aggregations is not yet\ninvestigated. In this study, we investigate the statistical stability of\nC/W/L/A metrics from the perspective of: (1) the system ranking similarity\namong aggregations, (2) the system ranking consistency of aggregations and (3)\nthe discriminative power of aggregations. More specifically, we combined\nvarious aggregation functions with the browsing model of Precision, Discounted\nCumulative Gain (DCG), Rank-Biased Precision (RBP), INST, Average Precision\n(AP) and Expected Reciprocal Rank (ERR), examing their performances in terms of\nsystem ranking similarity, system ranking consistency and discriminative power\non two offline test collections. Our experimental result suggests that, in\nterms of system ranking consistency and discriminative power, the aggregation\nfunction of expected rate of gain (ERG) has an outstanding performance while\nthe aggregation function of maximum relevance usually has an insufficient\nperformance. The result also suggests that Precision, DCG, RBP, INST and AP\nwith their canonical aggregation all have favourable performances in system\nranking consistency and discriminative power; but for ERR, replacing its\ncanonical aggregation with ERG can further strengthen the discriminative power\nwhile obtaining a system ranking list similar to the canonical version at the\nsame time.",
        "translated": "最近，Moffat 等人提出了一个分析框架，即 C/W/L/A，用于离线评估指标。这个框架允许信息检索研究人员通过灵活组合用户浏览模型和用户增益聚合来设计评估指标。然而，具有不同聚合的 C/W/L/A 指标的统计稳定性尚未得到研究。本研究从以下几个方面考察了 C/W/L/A 指标的统计稳定性: (1)系统对聚合之间的相似性进行排序; (2)系统对聚合的一致性进行排序; (3)聚合的判别能力。更具体地说，我们将各种聚合函数与精度、折扣累积增益(DCG)、有秩偏差的精度(RBP)、 INST、平均精度(AP)和期望互惠秩(ERR)的浏览模型相结合，考察了它们在两个离线测试集上的系统排序相似性、系统排序一致性和判别能力的表现。实验结果表明，在系统排序一致性和判别能力方面，期望增益率的聚合函数具有优异的性能，而最大相关度的聚合函数通常表现不佳。结果还表明，Precision、 DCG、 RBP、 INST 和 AP 以及它们的规范聚合在系统排序一致性和判别力方面都有良好的表现; 而 ERR 用 ERG 代替其规范聚合可以进一步增强判别力，同时获得类似于规范版本的系统排序列表。"
    },
    {
        "title": "PLIERS: a Popularity-Based Recommender System for Content Dissemination\n  in Online Social Networks",
        "url": "http://arxiv.org/abs/2307.02865v1",
        "pub_date": "2023-07-06",
        "summary": "In this paper, we propose a novel tag-based recommender system called PLIERS,\nwhich relies on the assumption that users are mainly interested in items and\ntags with similar popularity to those they already own. PLIERS is aimed at\nreaching a good tradeoff between algorithmic complexity and the level of\npersonalization of recommended items. To evaluate PLIERS, we performed a set of\nexperiments on real OSN datasets, demonstrating that it outperforms\nstate-of-the-art solutions in terms of personalization, relevance, and novelty\nof recommendations.",
        "translated": "在这篇文章中，我们提出了一个新的基于标签的推荐系统叫做 PLIERS，它基于这样一个假设: 用户主要对那些与他们已经拥有的东西相似的流行的项目和标签感兴趣。PLIERS 的目标是在算法复杂性和推荐项目的个性化水平之间取得良好的平衡。为了评估 PLIERS，我们在真实的 OSN 数据集上进行了一系列实验，证明它在个性化、相关性和推荐的新颖性方面优于最先进的解决方案。"
    },
    {
        "title": "Lost in the Middle: How Language Models Use Long Contexts",
        "url": "http://arxiv.org/abs/2307.03172v1",
        "pub_date": "2023-07-06",
        "summary": "While recent language models have the ability to take long contexts as input,\nrelatively little is known about how well the language models use longer\ncontext. We analyze language model performance on two tasks that require\nidentifying relevant information within their input contexts: multi-document\nquestion answering and key-value retrieval. We find that performance is often\nhighest when relevant information occurs at the beginning or end of the input\ncontext, and significantly degrades when models must access relevant\ninformation in the middle of long contexts. Furthermore, performance\nsubstantially decreases as the input context grows longer, even for explicitly\nlong-context models. Our analysis provides a better understanding of how\nlanguage models use their input context and provides new evaluation protocols\nfor future long-context models.",
        "translated": "虽然最近的语言模型能够将较长的上下文作为输入，但是对于语言模型如何更好地使用较长的上下文知之甚少。我们分析了语言模型在两个需要在其输入上下文中识别相关信息的任务上的表现: 多文档问题回答和关键值检索。我们发现，当相关信息出现在输入上下文的开头或结尾时，性能往往最高，而当模型必须在较长的上下文中访问相关信息时，性能则显著下降。此外，即使对于显式的长上下文模型，随着输入上下文的增长，性能也会大大降低。我们的分析提供了对语言模型如何使用其输入上下文的更好理解，并为未来的长上下文模型提供了新的评估协议。"
    },
    {
        "title": "Focused Transformer: Contrastive Training for Context Scaling",
        "url": "http://arxiv.org/abs/2307.03170v1",
        "pub_date": "2023-07-06",
        "summary": "Large language models have an exceptional capability to incorporate new\ninformation in a contextual manner. However, the full potential of such an\napproach is often restrained due to a limitation in the effective context\nlength. One solution to this issue is to endow an attention layer with access\nto an external memory, which comprises of (key, value) pairs. Yet, as the\nnumber of documents increases, the proportion of relevant keys to irrelevant\nones decreases, leading the model to focus more on the irrelevant keys. We\nidentify a significant challenge, dubbed the distraction issue, where keys\nlinked to different semantic values might overlap, making them hard to\ndistinguish. To tackle this problem, we introduce the Focused Transformer\n(FoT), a technique that employs a training process inspired by contrastive\nlearning. This novel approach enhances the structure of the (key, value) space,\nenabling an extension of the context length. Our method allows for fine-tuning\npre-existing, large-scale models to lengthen their effective context. This is\ndemonstrated by our fine-tuning of $3B$ and $7B$ OpenLLaMA checkpoints. The\nresulting models, which we name LongLLaMA, exhibit advancements in tasks\nrequiring a long context. We further illustrate that our LongLLaMA models\nadeptly manage a $256 k$ context length for passkey retrieval.",
        "translated": "大型语言模型具有以上下文方式合并新信息的特殊能力。然而，由于有效上下文长度的限制，这种方法的全部潜力往往受到限制。这个问题的一个解决方案是赋予注意层访问外部存储器的权限，外部存储器由(键，值)对组成。然而，随着文档数量的增加，相关键与不相关键的比例下降，导致模型更多地关注不相关键。我们确定了一个重大的挑战，称为分心问题，其中与不同语义值相关的键可能重叠，使它们难以区分。为了解决这个问题，我们引入了聚焦变压器(FoT) ，这是一种利用对比学习启发的训练过程的技术。这种新颖的方法增强了(键，值)空间的结构，支持上下文长度的扩展。我们的方法允许对预先存在的大规模模型进行微调，以延长它们的有效上下文。我们对 $3B $和 $7B $OpenLLaMA 检查点的微调就证明了这一点。所得到的模型(我们将其命名为 LongLLaMA)在需要长上下文的任务中表现出了进步。我们进一步说明，我们的 LongLLaMA 模型能够很好地管理256 k $的密钥检索上下文长度。"
    },
    {
        "title": "Distilling Large Vision-Language Model with Out-of-Distribution\n  Generalizability",
        "url": "http://arxiv.org/abs/2307.03135v1",
        "pub_date": "2023-07-06",
        "summary": "Large vision-language models have achieved outstanding performance, but their\nsize and computational requirements make their deployment on\nresource-constrained devices and time-sensitive tasks impractical. Model\ndistillation, the process of creating smaller, faster models that maintain the\nperformance of larger models, is a promising direction towards the solution.\nThis paper investigates the distillation of visual representations in large\nteacher vision-language models into lightweight student models using a small-\nor mid-scale dataset. Notably, this study focuses on open-vocabulary\nout-of-distribution (OOD) generalization, a challenging problem that has been\noverlooked in previous model distillation literature. We propose two principles\nfrom vision and language modality perspectives to enhance student's OOD\ngeneralization: (1) by better imitating teacher's visual representation space,\nand carefully promoting better coherence in vision-language alignment with the\nteacher; (2) by enriching the teacher's language representations with\ninformative and finegrained semantic attributes to effectively distinguish\nbetween different labels. We propose several metrics and conduct extensive\nexperiments to investigate their techniques. The results demonstrate\nsignificant improvements in zero-shot and few-shot student performance on\nopen-vocabulary out-of-distribution classification, highlighting the\neffectiveness of our proposed approaches. Our code will be released at\nhttps://github.com/xuanlinli17/large_vlm_distillation_ood",
        "translated": "大型视觉语言模型已经取得了出色的性能，但是它们的规模和计算需求使得它们在资源受限的设备和时间敏感的任务上的部署变得不切实际。模型精馏是创建更小、更快的模型以保持较大模型性能的过程，是解决这一问题的一个有希望的方向。本文研究了利用中小规模数据集将大型教师视觉语言模型中的视觉表征提炼为轻量级学生模型。值得注意的是，本研究的重点是开放词汇分布外(OOD)泛化，这是一个具有挑战性的问题，一直被忽视了以往的模型蒸馏文献。本文从视觉和语言情态两个角度提出了提高学生面向对象的概括能力的两个原则: (1)更好地模仿教师的视觉表征空间，小心翼翼地促进与教师视觉语言对齐的连贯性; (2)丰富教师的语言表征，使其具有信息丰富、细致入微的语义属性，有效地区分不同的标签。我们提出了几个指标，并进行了广泛的实验来研究他们的技术。研究结果表明，在开放词汇分布外分类中，零词镜头和少词镜头学生的表现都有显著的改善，突出了我们提出的方法的有效性。我们的代码会在 https://github.com/xuanlinli17/large_vlm_distillation_ood 公布"
    },
    {
        "title": "T-MARS: Improving Visual Representations by Circumventing Text Feature\n  Learning",
        "url": "http://arxiv.org/abs/2307.03132v1",
        "pub_date": "2023-07-06",
        "summary": "Large web-sourced multimodal datasets have powered a slew of new methods for\nlearning general-purpose visual representations, advancing the state of the art\nin computer vision and revolutionizing zero- and few-shot recognition. One\ncrucial decision facing practitioners is how, if at all, to curate these\never-larger datasets. For example, the creators of the LAION-5B dataset chose\nto retain only image-caption pairs whose CLIP similarity score exceeded a\ndesignated threshold. In this paper, we propose a new state-of-the-art data\nfiltering approach motivated by our observation that nearly 40% of LAION's\nimages contain text that overlaps significantly with the caption. Intuitively,\nsuch data could be wasteful as it incentivizes models to perform optical\ncharacter recognition rather than learning visual features. However, naively\nremoving all such data could also be wasteful, as it throws away images that\ncontain visual features (in addition to overlapping text). Our simple and\nscalable approach, T-MARS (Text Masking and Re-Scoring), filters out only those\npairs where the text dominates the remaining visual features -- by first\nmasking out the text and then filtering out those with a low CLIP similarity\nscore of the masked image. Experimentally, T-MARS outperforms the top-ranked\nmethod on the \"medium scale\" of DataComp (a data filtering benchmark) by a\nmargin of 6.5% on ImageNet and 4.7% on VTAB. Additionally, our systematic\nevaluation on various data pool sizes from 2M to 64M shows that the accuracy\ngains enjoyed by T-MARS linearly increase as data and compute are scaled\nexponentially. Code is available at https://github.com/locuslab/T-MARS.",
        "translated": "大型网络来源的多模态数据集为一系列学习通用视觉表征的新方法提供了动力，推进了计算机视觉的最新水平，并彻底改革了零镜头和少镜头识别。从业者面临的一个关键决定是如何管理这些越来越大的数据集。例如，LAION-5B 数据集的创建者选择只保留 CLIP 相似性评分超过指定阈值的图像-标题对。在本文中，我们提出了一个新的国家的最先进的数据过滤方法的动机是我们的观察，近40% 的 LAION 的图像包含文本，与标题重叠显着。直观地说，这样的数据可能是浪费的，因为它激励模型执行光学字符识别，而不是学习视觉特征。然而，天真地删除所有这些数据也可能是浪费，因为它会丢弃包含视觉特征的图像(除了重叠的文本)。我们简单且可扩展的方法，T-MARS (文本掩盖和重新评分) ，只过滤那些文本主导剩余视觉特征的对——首先掩盖文本，然后过滤那些掩盖图像的低 CLIP 相似度评分。在实验上，T-MARS 在“中等规模”的 DataComp (一个数据过滤基准)上的表现优于顶级方法，在 ImageNet 上优于6.5% ，在 VTAB 上优于4.7% 。此外，我们对从2M 到64M 的各种数据池大小的系统评估表明，随着数据和计算的指数级扩展，T-MARS 所享有的准确性增益呈线性增加。密码可于 https://github.com/locuslab/t-mars 索取。"
    },
    {
        "title": "BLEURT Has Universal Translations: An Analysis of Automatic Metrics by\n  Minimum Risk Training",
        "url": "http://arxiv.org/abs/2307.03131v1",
        "pub_date": "2023-07-06",
        "summary": "Automatic metrics play a crucial role in machine translation. Despite the\nwidespread use of n-gram-based metrics, there has been a recent surge in the\ndevelopment of pre-trained model-based metrics that focus on measuring sentence\nsemantics. However, these neural metrics, while achieving higher correlations\nwith human evaluations, are often considered to be black boxes with potential\nbiases that are difficult to detect. In this study, we systematically analyze\nand compare various mainstream and cutting-edge automatic metrics from the\nperspective of their guidance for training machine translation systems. Through\nMinimum Risk Training (MRT), we find that certain metrics exhibit robustness\ndefects, such as the presence of universal adversarial translations in BLEURT\nand BARTScore. In-depth analysis suggests two main causes of these robustness\ndeficits: distribution biases in the training datasets, and the tendency of the\nmetric paradigm. By incorporating token-level constraints, we enhance the\nrobustness of evaluation metrics, which in turn leads to an improvement in the\nperformance of machine translation systems. Codes are available at\n\\url{https://github.com/powerpuffpomelo/fairseq_mrt}.",
        "translated": "自动度量在机器翻译中起着至关重要的作用。尽管基于 n-gram 的度量标准得到了广泛的应用，但是最近在开发基于预训练模型的度量标准方面出现了一股浪潮，这些度量标准关注于测量句子语义。然而，这些神经指标，虽然与人类评估实现更高的相关性，往往被认为是具有难以检测的潜在偏差的黑盒子。在本研究中，我们系统地分析和比较了各种主流和前沿的自动化指标，从它们对培训机器翻译系统的指导的角度。通过最小风险训练(MRT) ，我们发现某些指标具有鲁棒性缺陷，如 BLEURT 和 BARTScore 中存在通用的对抗性翻译。深入分析表明这些健壮性缺陷的两个主要原因: 训练数据集中的分布偏差和度量范式的趋势。通过引入令牌级约束，我们增强了评估指标的鲁棒性，这反过来又导致了机器翻译系统性能的改善。密码可在网址{ https://github.com/powerpuffpomelo/fairseq_mrt }下载。"
    },
    {
        "title": "VisKoP: Visual Knowledge oriented Programming for Interactive Knowledge\n  Base Question Answering",
        "url": "http://arxiv.org/abs/2307.03130v1",
        "pub_date": "2023-07-06",
        "summary": "We present Visual Knowledge oriented Programming platform (VisKoP), a\nknowledge base question answering (KBQA) system that integrates human into the\nloop to edit and debug the knowledge base (KB) queries. VisKoP not only\nprovides a neural program induction module, which converts natural language\nquestions into knowledge oriented program language (KoPL), but also maps KoPL\nprograms into graphical elements. KoPL programs can be edited with simple\ngraphical operators, such as dragging to add knowledge operators and slot\nfilling to designate operator arguments. Moreover, VisKoP provides\nauto-completion for its knowledge base schema and users can easily debug the\nKoPL program by checking its intermediate results. To facilitate the practical\nKBQA on a million-entity-level KB, we design a highly efficient KoPL execution\nengine for the back-end. Experiment results show that VisKoP is highly\nefficient and user interaction can fix a large portion of wrong KoPL programs\nto acquire the correct answer. The VisKoP online demo\nhttps://demoviskop.xlore.cn (Stable release of this paper) and\nhttps://viskop.xlore.cn (Beta release with new features), highly efficient KoPL\nengine https://pypi.org/project/kopl-engine, and screencast video\nhttps://youtu.be/zAbJtxFPTXo are now publicly available.",
        "translated": "本文介绍了面向可视化知识编程平台(VisKoP) ，它是一个集成了人机交互的知识库问题回答系统(KBQA) ，可以对知识库查询进行编辑和调试。VisKoP 不仅提供了一个神经程序归纳模块，将自然语言问题转换为面向知识的程序语言(KoPL) ，而且还将 KoPL 程序映射为图形元素。KOPL 程序可以通过简单的图形运算符进行编辑，例如通过拖动来添加知识运算符，通过插槽填充来指定运算符参数。此外，VisKoP 为其知识库模式提供了自动完成功能，用户可以通过检查 KoPL 程序的中间结果来轻松调试 KoPL 程序。为了方便实际的百万实体级 KB 上的 KBQA，我们为后端设计了一个高效的 KOPL 执行引擎。实验结果表明，VisKoP 是高效的，用户交互可以修复大部分错误的 KOPL 程序，从而获得正确的答案。ViskoP 在线演示 https://demoviskop.xlore.cn (本文的稳定发布)和 https://VisKoP.xlore.cn (带有新功能的 Beta 发布)、高效的 KoPL 引擎 https://pypi.org/project/KoPL-engine 和视频 https://youtu.be/zabjtxfptxo 现已公开发布。"
    },
    {
        "title": "Extracting Multi-valued Relations from Language Models",
        "url": "http://arxiv.org/abs/2307.03122v1",
        "pub_date": "2023-07-06",
        "summary": "The widespread usage of latent language representations via pre-trained\nlanguage models (LMs) suggests that they are a promising source of structured\nknowledge. However, existing methods focus only on a single object per\nsubject-relation pair, even though often multiple objects are correct. To\novercome this limitation, we analyze these representations for their potential\nto yield materialized multi-object relational knowledge. We formulate the\nproblem as a rank-then-select task. For ranking candidate objects, we evaluate\nexisting prompting techniques and propose new ones incorporating domain\nknowledge. Among the selection methods, we find that choosing objects with a\nlikelihood above a learned relation-specific threshold gives a 49.5% F1 score.\nOur results highlight the difficulty of employing LMs for the multi-valued\nslot-filling task and pave the way for further research on extracting\nrelational knowledge from latent language representations.",
        "translated": "潜在语言表征通过预训练语言模型(LM)的广泛应用表明，它们是结构化知识的一个有前途的来源。然而，现有的方法只关注每个主题关系对中的一个对象，即使多个对象通常是正确的。为了克服这个限制，我们分析了这些表示，看它们产生物化多对象关系知识的潜力。我们把这个问题表述为一个排序然后选择的任务。为了对候选对象进行排序，我们评估了现有的提示技术，并结合领域知识提出了新的提示技术。在所有的选择方法中，我们发现选择一个可能性高于学习关系特定阈值的对象，F1得分为49.5% 。我们的研究结果突出了利用 LM 进行多值填充任务的难度，并为进一步研究从潜在语言表征中提取关系知识铺平了道路。"
    },
    {
        "title": "KoRC: Knowledge oriented Reading Comprehension Benchmark for Deep Text\n  Understanding",
        "url": "http://arxiv.org/abs/2307.03115v1",
        "pub_date": "2023-07-06",
        "summary": "Deep text understanding, which requires the connections between a given\ndocument and prior knowledge beyond its text, has been highlighted by many\nbenchmarks in recent years. However, these benchmarks have encountered two\nmajor limitations. On the one hand, most of them require human annotation of\nknowledge, which leads to limited knowledge coverage. On the other hand, they\nusually use choices or spans in the texts as the answers, which results in\nnarrow answer space. To overcome these limitations, we build a new challenging\nbenchmark named KoRc in this paper. Compared with previous benchmarks, KoRC has\ntwo advantages, i.e., broad knowledge coverage and flexible answer format.\nSpecifically, we utilize massive knowledge bases to guide annotators or large\nlanguage models (LLMs) to construct knowledgable questions. Moreover, we use\nlabels in knowledge bases rather than spans or choices as the final answers. We\ntest state-of-the-art models on KoRC and the experimental results show that the\nstrongest baseline only achieves 68.3% and 30.0% F1 measure in the\nin-distribution and out-of-distribution test set, respectively. These results\nindicate that deep text understanding is still an unsolved challenge. The\nbenchmark dataset, leaderboard, and baseline methods are released in\nhttps://github.com/THU-KEG/KoRC.",
        "translated": "深度文本理解需要将文件与文本之外的先前知识联系起来，近年来许多基准都强调了这一点。然而，这些基准测试遇到了两个主要的限制。一方面，它们大多需要人工对知识进行注释，导致知识覆盖面有限;。另一方面，他们通常使用选择或跨度在文本中作为答案，这导致了狭窄的答案空间。为了克服这些限制，我们在本文中构建了一个新的具有挑战性的基准，命名为 KoRc。与以往的基准相比，KoRC 有两个优势，即知识面广和答案形式灵活。具体来说，我们利用大量的知识库来指导注释者或者大型语言模型(LLM)来构建知识性问题。此外，我们在知识库中使用标签，而不是跨度或选择作为最终答案。我们在 KoRC 测试了最先进的模型，实验结果显示最强的基线在分布内和分布外测试集中分别只达到68.3% 和30.0% 的 f 1测量值。这些结果表明，深层文本理解仍然是一个未解决的挑战。基准数据集、排行榜和基准方法以 https://github.com/thu-keg/korc 形式发布。"
    },
    {
        "title": "A Survey on Evaluation of Large Language Models",
        "url": "http://arxiv.org/abs/2307.03109v1",
        "pub_date": "2023-07-06",
        "summary": "Large language models (LLMs) are gaining increasing popularity in both\nacademia and industry, owing to their unprecedented performance in various\napplications. As LLMs continue to play a vital role in both research and daily\nuse, their evaluation becomes increasingly critical, not only at the task\nlevel, but also at the society level for better understanding of their\npotential risks. Over the past years, significant efforts have been made to\nexamine LLMs from various perspectives. This paper presents a comprehensive\nreview of these evaluation methods for LLMs, focusing on three key dimensions:\nwhat to evaluate, where to evaluate, and how to evaluate. Firstly, we provide\nan overview from the perspective of evaluation tasks, encompassing general\nnatural language processing tasks, reasoning, medical usage, ethics,\neducations, natural and social sciences, agent applications, and other areas.\nSecondly, we answer the `where' and `how' questions by diving into the\nevaluation methods and benchmarks, which serve as crucial components in\nassessing performance of LLMs. Then, we summarize the success and failure cases\nof LLMs in different tasks. Finally, we shed light on several future challenges\nthat lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to\nresearchers in the realm of LLMs evaluation, thereby aiding the development of\nmore proficient LLMs. Our key point is that evaluation should be treated as an\nessential discipline to better assist the development of LLMs. We consistently\nmaintain the related open-source materials at:\nhttps://github.com/MLGroupJLU/LLM-eval-survey.",
        "translated": "大语言模型(LLM)因其在各种应用中的前所未有的性能，在学术界和工业界越来越受欢迎。随着 LLM 在研究和日常使用中继续发挥重要作用，它们的评估变得越来越重要，不仅在任务层面，而且在社会层面，以便更好地了解它们的潜在风险。在过去的几年中，人们从不同的角度对 LLM 进行了大量的研究。本文对这些评价方法进行了综述，重点介绍了三个关键的方面: 评价内容、评价地点和评价方法。首先，我们从评估任务的角度提供了一个概述，包括一般的自然语言处理任务，推理，医学使用，伦理，教育，自然和社会科学，代理应用程序，以及其他领域。其次，我们通过深入研究评价方法和基准来回答“在哪里”和“如何”的问题，这些方法和基准是评价 LLM 绩效的重要组成部分。然后，总结了 LLM 在不同任务中的成功与失败案例。最后，我们阐明了在 LLM 评估中面临的几个未来挑战。我们的目标是提供宝贵的见解，研究人员在领域的 LLM 评价，从而帮助发展更熟练的 LLM。我们的主要观点是，评价应被视为一门必不可少的学科，以更好地协助 LLM 的发展。我们一直将相关的开源材料保存在以下 https://github.com/mlgroupjlu/llm-eval-survey  :。"
    },
    {
        "title": "Efficient Domain Adaptation of Sentence Embeddings using Adapters",
        "url": "http://arxiv.org/abs/2307.03104v1",
        "pub_date": "2023-07-06",
        "summary": "Sentence embeddings enable us to capture the semantic similarity of short\ntexts. Most sentence embedding models are trained for general semantic textual\nsimilarity (STS) tasks. Therefore, to use sentence embeddings in a particular\ndomain, the model must be adapted to it in order to achieve good results.\nUsually, this is done by fine-tuning the entire sentence embedding model for\nthe domain of interest. While this approach yields state-of-the-art results,\nall of the model's weights are updated during fine-tuning, making this method\nresource-intensive. Therefore, instead of fine-tuning entire sentence embedding\nmodels for each target domain individually, we propose to train lightweight\nadapters. These domain-specific adapters do not require fine-tuning all\nunderlying sentence embedding model parameters. Instead, we only train a small\nnumber of additional parameters while keeping the weights of the underlying\nsentence embedding model fixed. Training domain-specific adapters allows always\nusing the same base model and only exchanging the domain-specific adapters to\nadapt sentence embeddings to a specific domain. We show that using adapters for\nparameter-efficient domain adaptation of sentence embeddings yields competitive\nperformance within 1% of a domain-adapted, entirely fine-tuned sentence\nembedding model while only training approximately 3.6% of the parameters.",
        "translated": "句子嵌入使我们能够捕捉短文的语义相似性。大多数句子嵌入模型都是针对一般的语义文本相似度(STS)任务进行训练的。因此，要在特定领域使用句子嵌入，必须对模型进行适应性调整，才能取得良好的效果。通常，这是通过为感兴趣的领域微调整整个句子嵌入模型来完成的。虽然这种方法可以产生最先进的结果，但是所有模型的权重都会在微调过程中更新，这使得这种方法需要大量资源。因此，我们建议训练轻量级适配器，而不是针对每个目标领域分别微调整整个句子嵌入模型。这些特定于域的适配器不需要对所有底层句子嵌入模型参数进行微调。相反，我们只训练少量的附加参数，同时保持潜在的句子嵌入模型的权重不变。训练领域特定的适配器总是允许使用相同的基本模型，并且只交换领域特定的适配器来适应特定领域的句子嵌入。我们发现使用适配器对句子嵌入进行参数有效的领域适应，在领域适应的完全微调的句子嵌入模型的1% 内产生竞争性能，而只训练大约3.6% 的参数。"
    },
    {
        "title": "A Network Resource Allocation Recommendation Method with An Improved\n  Similarity Measure",
        "url": "http://arxiv.org/abs/2307.03399v1",
        "pub_date": "2023-07-07",
        "summary": "Recommender systems have been acknowledged as efficacious tools for managing\ninformation overload. Nevertheless, conventional algorithms adopted in such\nsystems primarily emphasize precise recommendations and, consequently, overlook\nother vital aspects like the coverage, diversity, and novelty of items. This\napproach results in less exposure for long-tail items. In this paper, to\npersonalize the recommendations and allocate recommendation resources more\npurposively, a method named PIM+RA is proposed. This method utilizes a\nbipartite network that incorporates self-connecting edges and weights.\nFurthermore, an improved Pearson correlation coefficient is employed for better\nredistribution. The evaluation of PIM+RA demonstrates a significant enhancement\nnot only in accuracy but also in coverage, diversity, and novelty of the\nrecommendation. It leads to a better balance in recommendation frequency by\nproviding effective exposure to long-tail items, while allowing customized\nparameters to adjust the recommendation list bias.",
        "translated": "推荐系统已被公认为管理信息超载的有效工具。然而，在这样的系统中采用的传统算法主要强调精确的推荐，因此忽视了其他重要方面，如项目的覆盖面、多样性和新颖性。这种方法可以减少长尾项目的曝光。为了实现推荐的个性化，更有针对性地分配推荐资源，提出了一种基于 PIM + RA 的推荐资源分配方法。该方法利用了一个包含自连接边和权值的二分网络。此外，改进的皮尔逊相关系数被用于更好的再分配。PIM + RA 的评估不仅在准确性方面，而且在推荐的覆盖面、多样性和新颖性方面都有显著的提高。它通过提供对长尾项目的有效接触，同时允许定制的参数来调整推荐列表偏差，从而使推荐频率得到更好的平衡。"
    },
    {
        "title": "InfoSync: Information Synchronization across Multilingual\n  Semi-structured Tables",
        "url": "http://arxiv.org/abs/2307.03313v1",
        "pub_date": "2023-07-06",
        "summary": "Information Synchronization of semi-structured data across languages is\nchallenging. For instance, Wikipedia tables in one language should be\nsynchronized across languages. To address this problem, we introduce a new\ndataset InfoSyncC and a two-step method for tabular synchronization. InfoSync\ncontains 100K entity-centric tables (Wikipedia Infoboxes) across 14 languages,\nof which a subset (3.5K pairs) are manually annotated. The proposed method\nincludes 1) Information Alignment to map rows and 2) Information Update for\nupdating missing/outdated information for aligned tables across multilingual\ntables. When evaluated on InfoSync, information alignment achieves an F1 score\nof 87.91 (en &lt;-&gt; non-en). To evaluate information updation, we perform\nhuman-assisted Wikipedia edits on Infoboxes for 603 table pairs. Our approach\nobtains an acceptance rate of 77.28% on Wikipedia, showing the effectiveness of\nthe proposed method.",
        "translated": "跨语言的半结构化数据的信息同步具有挑战性。例如，一种语言中的 Wikipedia 表应该跨语言同步。为了解决这个问题，我们引入了一个新的数据集 InfoSyncC 和一个两步的表同步方法。InfoSync 包含100K 跨14种语言的以实体为中心的表(Wikipedia Infobox) ，其中一个子集(3.5 K 对)是手动注释的。该方法包括1)映射行的信息对齐和2)跨多语言表更新对齐表中缺失/过时信息的信息更新。当在 InfoSync 上进行评估时，信息对齐达到 F1分数87.91(en <-> non-en)。为了评估信息更新，我们在 Infobox 上对603个表对执行人工辅助的 Wikipedia 编辑。该方法在维基百科上的验收率为77.28% ，表明了该方法的有效性。"
    },
    {
        "title": "Structure Guided Multi-modal Pre-trained Transformer for Knowledge Graph\n  Reasoning",
        "url": "http://arxiv.org/abs/2307.03591v1",
        "pub_date": "2023-07-06",
        "summary": "Multimodal knowledge graphs (MKGs), which intuitively organize information in\nvarious modalities, can benefit multiple practical downstream tasks, such as\nrecommendation systems, and visual question answering. However, most MKGs are\nstill far from complete, which motivates the flourishing of MKG reasoning\nmodels. Recently, with the development of general artificial architectures, the\npretrained transformer models have drawn increasing attention, especially for\nmultimodal scenarios. However, the research of multimodal pretrained\ntransformer (MPT) for knowledge graph reasoning (KGR) is still at an early\nstage. As the biggest difference between MKG and other multimodal data, the\nrich structural information underlying the MKG still cannot be fully leveraged\nin existing MPT models. Most of them only utilize the graph structure as a\nretrieval map for matching images and texts connected with the same entity.\nThis manner hinders their reasoning performances. To this end, we propose the\ngraph Structure Guided Multimodal Pretrained Transformer for knowledge graph\nreasoning, termed SGMPT. Specifically, the graph structure encoder is adopted\nfor structural feature encoding. Then, a structure-guided fusion module with\ntwo different strategies, i.e., weighted summation and alignment constraint, is\nfirst designed to inject the structural information into both the textual and\nvisual features. To the best of our knowledge, SGMPT is the first MPT model for\nmultimodal KGR, which mines the structural information underlying the knowledge\ngraph. Extensive experiments on FB15k-237-IMG and WN18-IMG, demonstrate that\nour SGMPT outperforms existing state-of-the-art models, and prove the\neffectiveness of the designed strategies.",
        "translated": "多模态知识图(MKG)可以直观地组织各种形式的信息，有利于多种实际的下游任务，如推荐系统和可视化问题回答。然而，大多数 MKG 推理模型还远未完成，这促使了 MKG 推理模型的蓬勃发展。近年来，随着通用人工结构的发展，预训练变压器模型越来越受到重视，尤其是在多模态情况下。然而，用于知识图推理(KGR)的多模态预训练变压器(MPT)的研究还处于初级阶段。作为 MKG 和其他多模态数据的最大区别，MKG 所蕴含的丰富的结构信息仍然不能在现有的 MPT 模型中得到充分利用。它们大多数只是利用图结构作为检索映射来匹配与同一实体相连的图像和文本。这种方式妨碍了他们的推理能力。为此，我们提出了图结构引导的多模态预训练变压器的知识图推理，称为 SGMPT。具体地说，采用图结构编码器进行结构特征编码。然后，设计了一个结构引导的融合模块，该模块采用加权和约束和对齐约束两种不同的融合策略，将结构信息同时注入到文本特征和视觉特征中。据我们所知，SGMPT 是多模态 KGR 的第一个 MPT 模型，它挖掘知识图中的结构信息。在 FB15k-237-IMG 和 WN18-IMG 上的大量实验表明，我们的 SGMPT 性能优于现有的最先进的模型，并证明了所设计策略的有效性。"
    },
    {
        "title": "On the Efficacy of Sampling Adapters",
        "url": "http://arxiv.org/abs/2307.03749v1",
        "pub_date": "2023-07-07",
        "summary": "Sampling is a common strategy for generating text from probabilistic models,\nyet standard ancestral sampling often results in text that is incoherent or\nungrammatical. To alleviate this issue, various modifications to a model's\nsampling distribution, such as nucleus or top-k sampling, have been introduced\nand are now ubiquitously used in language generation systems. We propose a\nunified framework for understanding these techniques, which we term sampling\nadapters. Sampling adapters often lead to qualitatively better text, which\nraises the question: From a formal perspective, how are they changing the\n(sub)word-level distributions of language generation models? And why do these\nlocal changes lead to higher-quality text? We argue that the shift they enforce\ncan be viewed as a trade-off between precision and recall: while the model\nloses its ability to produce certain strings, its precision rate on desirable\ntext increases. While this trade-off is not reflected in standard metrics of\ndistribution quality (such as perplexity), we find that several\nprecision-emphasizing measures indeed indicate that sampling adapters can lead\nto probability distributions more aligned with the true distribution. Further,\nthese measures correlate with higher sequence-level quality scores,\nspecifically, Mauve.",
        "translated": "抽样是从概率模型生成文本的一种常见策略，然而标准的祖先抽样常常导致文本不连贯或不符合语法。为了缓解这一问题，对模型的抽样分布进行了各种修改，如核抽样或 top-k 抽样，这些修改已经被引入，并且现在在语言生成系统中普遍使用。我们提出了一个统一的框架来理解这些技术，我们称之为抽样适配器。采样适配器通常能产生质量更好的文本，这就提出了一个问题: 从形式角度来看，它们如何改变语言生成模型的(子)词级分布？为什么这些局部变化会导致更高质量的文本？我们认为，它们实施的转变可以被视为准确率召回率之间的一种权衡: 尽管模型失去了产生特定字符串的能力，但它对理想文本的精确度却有所提高。虽然这种权衡没有反映在分布质量的标准指标(如困惑)中，但我们发现，一些强调精度的指标确实表明，抽样适配器可以导致与真实分布更加一致的概率分布。此外，这些措施与更高的序列水平的质量得分相关，特别是，紫红色。"
    },
    {
        "title": "QIGen: Generating Efficient Kernels for Quantized Inference on Large\n  Language Models",
        "url": "http://arxiv.org/abs/2307.03738v1",
        "pub_date": "2023-07-07",
        "summary": "We present ongoing work on a new automatic code generation approach for\nsupporting quantized generative inference on LLMs such as LLaMA or OPT on\noff-the-shelf CPUs. Our approach is informed by the target architecture and a\nperformance model, including both hardware characteristics and method-specific\naccuracy constraints. Results on CPU-based inference for LLaMA models show that\nour approach can lead to high performance and high accuracy, comparing\nfavorably to the best existing open-source solution. A preliminary\nimplementation is available at https://github.com/IST-DASLab/QIGen.",
        "translated": "我们目前正在研究一种新的自动代码生成方法，用于支持 LLM 上的量化生成推理，如 LLaMA 或现成 CPU 上的 OPT。我们的方法受到目标体系结构和性能模型的影响，包括硬件特征和方法特定的精度约束。对 LLaMA 模型的基于 CPU 的推理结果表明，与现有的最佳开源解决方案相比，我们的方法可以获得更高的性能和更高的精度。初步的实施 https://github.com/ist-daslab/qigen 可供参考。"
    },
    {
        "title": "Improving Automatic Quotation Attribution in Literary Novels",
        "url": "http://arxiv.org/abs/2307.03734v1",
        "pub_date": "2023-07-07",
        "summary": "Current models for quotation attribution in literary novels assume varying\nlevels of available information in their training and test data, which poses a\nchallenge for in-the-wild inference. Here, we approach quotation attribution as\na set of four interconnected sub-tasks: character identification, coreference\nresolution, quotation identification, and speaker attribution. We benchmark\nstate-of-the-art models on each of these sub-tasks independently, using a large\ndataset of annotated coreferences and quotations in literary novels (the\nProject Dialogism Novel Corpus). We also train and evaluate models for the\nspeaker attribution task in particular, showing that a simple sequential\nprediction model achieves accuracy scores on par with state-of-the-art models.",
        "translated": "现有的文学小说引文归因模型在训练和测试数据中假定了不同程度的可用信息，这对野外推理提出了挑战。在这里，我们把引文归属作为四个相互关联的子任务来处理: 字符识别、共指解析、引文识别和说话人归属。我们使用文学小说(对话项目小说语料库)中带注释的参考文献和引文的大型数据集，独立地对这些子任务中的每个子任务进行最先进的模型基准测试。我们还特别针对说话人归因任务训练和评估模型，表明一个简单的顺序预测模型可以达到与最先进的模型相当的精度分数。"
    },
    {
        "title": "INT-FP-QSim: Mixed Precision and Formats For Large Language Models and\n  Vision Transformers",
        "url": "http://arxiv.org/abs/2307.03712v1",
        "pub_date": "2023-07-07",
        "summary": "The recent rise of large language models (LLMs) has resulted in increased\nefforts towards running LLMs at reduced precision. Running LLMs at lower\nprecision supports resource constraints and furthers their democratization,\nenabling users to run billion-parameter LLMs on their personal devices. To\nsupplement this ongoing effort, we propose INT-FP-QSim: an open-source\nsimulator that enables flexible evaluation of LLMs and vision transformers at\nvarious numerical precisions and formats. INT-FP-QSim leverages existing\nopen-source repositories such as TensorRT, QPytorch and AIMET for a combined\nsimulator that supports various floating point and integer formats. With the\nhelp of our simulator, we survey the impact of different numerical formats on\nthe performance of LLMs and vision transformers at 4-bit weights and 4-bit or\n8-bit activations. We also compare recently proposed methods like Adaptive\nBlock Floating Point, SmoothQuant, GPTQ and RPTQ on the model performances. We\nhope INT-FP-QSim will enable researchers to flexibly simulate models at various\nprecisions to support further research in quantization of LLMs and vision\ntransformers.",
        "translated": "最近大型语言模型(LLM)的兴起已经导致在降低 LLM 的精度方面付出了更多的努力。以较低的精度运行 LLM 支持资源约束并进一步实现其民主化，使用户能够在其个人设备上运行十亿参数的 LLM。为了补充正在进行的努力，我们提出了 INT-FP-QSim: 一个开源模拟器，可以灵活评估 LLM 和视觉转换器在各种数字精度和格式。INT-FP-QSim 利用现有的开放源码存储库，如 TensorRT、 QPytorch 和 AIMET，构建了一个支持各种浮点数和整数格式的组合模拟器。在我们的模拟器的帮助下，我们调查了不同的数字格式对 LLM 和视觉变换器在4位加权和4位或8位激活时的性能的影响。我们还比较了最近提出的自适应块浮点数、 SmoothQuant、 GPTQ 和 RPTQ 等方法对模型性能的影响。我们希望 INT-FP-QSim 能够使研究人员灵活地模拟不同精度的模型，以支持 LLM 和视觉变压器的量子化的进一步研究。"
    },
    {
        "title": "Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug\n  Trafficking Detection on Social Media",
        "url": "http://arxiv.org/abs/2307.03699v1",
        "pub_date": "2023-07-07",
        "summary": "Social media platforms such as Instagram and Twitter have emerged as critical\nchannels for drug marketing and illegal sale. Detecting and labeling online\nillicit drug trafficking activities becomes important in addressing this issue.\nHowever, the effectiveness of conventional supervised learning methods in\ndetecting drug trafficking heavily relies on having access to substantial\namounts of labeled data, while data annotation is time-consuming and\nresource-intensive. Furthermore, these models often face challenges in\naccurately identifying trafficking activities when drug dealers use deceptive\nlanguage and euphemisms to avoid detection. To overcome this limitation, we\nconduct the first systematic study on leveraging large language models (LLMs),\nsuch as ChatGPT, to detect illicit drug trafficking activities on social media.\nWe propose an analytical framework to compose \\emph{knowledge-informed\nprompts}, which serve as the interface that humans can interact with and use\nLLMs to perform the detection task. Additionally, we design a Monte Carlo\ndropout based prompt optimization method to further to improve performance and\ninterpretability. Our experimental findings demonstrate that the proposed\nframework outperforms other baseline language models in terms of drug\ntrafficking detection accuracy, showing a remarkable improvement of nearly\n12\\%. By integrating prior knowledge and the proposed prompts, ChatGPT can\neffectively identify and label drug trafficking activities on social networks,\neven in the presence of deceptive language and euphemisms used by drug dealers\nto evade detection. The implications of our research extend to social networks,\nemphasizing the importance of incorporating prior knowledge and scenario-based\nprompts into analytical tools to improve online security and public safety.",
        "translated": "Instagram 和 Twitter 等社交媒体平台已成为毒品营销和非法销售的重要渠道。侦测和标明网上非法非法毒品贸易活动对于解决这一问题变得非常重要。然而，传统监督式学习方法在检测非法毒品贸易方面的有效性在很大程度上依赖于能够获得大量的标记数据，而数据注释是耗费时间和资源密集型的。此外，当毒品贩子使用欺骗性语言和委婉语来逃避侦查时，这些模型往往在准确识别贩运活动方面面临挑战。为了克服这个限制，我们进行了第一个系统的研究，利用大型语言模型(LLMs) ，例如 chatgPT，来检测社交媒体上的非法非法毒品贸易活动。我们提出了一个分析框架来组成 emph {知识提示} ，它作为接口，人们可以交互和使用 LLM 来执行检测任务。此外，我们设计了一个基于蒙特卡罗辍学的快速优化方法，以进一步提高性能和可解释性。我们的实验结果显示，该框架在非法毒品贸易检测准确度方面优于其他基线语言模型，显著提高了近12% 。通过整合先前的知识和建议的提示，ChatgPT 可以有效地识别和标记社交网络上的非法毒品贸易活动，即使毒贩使用欺骗性语言和委婉语来逃避侦查。我们研究的影响延伸到社交网络，强调了将先前的知识和基于场景的提示纳入分析工具以改善在线安全和公共安全的重要性。"
    },
    {
        "title": "Testing the Predictions of Surprisal Theory in 11 Languages",
        "url": "http://arxiv.org/abs/2307.03667v2",
        "pub_date": "2023-07-07",
        "summary": "A fundamental result in psycholinguistics is that less predictable words take\na longer time to process. One theoretical explanation for this finding is\nSurprisal Theory (Hale, 2001; Levy, 2008), which quantifies a word's\npredictability as its surprisal, i.e. its negative log-probability given a\ncontext. While evidence supporting the predictions of Surprisal Theory have\nbeen replicated widely, most have focused on a very narrow slice of data:\nnative English speakers reading English texts. Indeed, no comprehensive\nmultilingual analysis exists. We address this gap in the current literature by\ninvestigating the relationship between surprisal and reading times in eleven\ndifferent languages, distributed across five language families. Deriving\nestimates from language models trained on monolingual and multilingual corpora,\nwe test three predictions associated with surprisal theory: (i) whether\nsurprisal is predictive of reading times; (ii) whether expected surprisal, i.e.\ncontextual entropy, is predictive of reading times; (iii) and whether the\nlinking function between surprisal and reading times is linear. We find that\nall three predictions are borne out crosslinguistically. By focusing on a more\ndiverse set of languages, we argue that these results offer the most robust\nlink to-date between information theory and incremental language processing\nacross languages.",
        "translated": "心理语言学的一个基本结果是，较难预测的单词需要更长的时间来处理。对这一发现的一个理论解释是惊喜理论(Hale，2001; Levy，2008) ，该理论将一个单词的可预测性量化为它的惊喜，即给定上下文的负对数概率。虽然支持意外理论预测的证据已被广泛复制，但大多数都集中在一个非常狭窄的数据片段: 以英语为母语的人阅读英语文本。事实上，并不存在全面的多语言分析。我们通过调查分布在五个语系中的十一种不同语言的惊奇和阅读时间之间的关系来解决当前文献中的这一差距。从单语言和多语言语料库训练的语言模型中得出估计，我们测试了与惊喜理论相关的三个预测: (i)惊喜是否可以预测阅读时间; (ii)预期的惊喜，即上下文熵，是否可以预测阅读时间; (iii)以及惊喜和阅读时间之间的联系函数是否是线性的。我们发现这三个预测都得到了跨语言的证实。通过关注更加多样化的语言集合，我们认为这些结果提供了迄今为止信息理论和跨语言增量语言处理之间最有力的联系。"
    },
    {
        "title": "The distribution of discourse relations within and across turns in\n  spontaneous conversation",
        "url": "http://arxiv.org/abs/2307.03645v1",
        "pub_date": "2023-07-07",
        "summary": "Time pressure and topic negotiation may impose constraints on how people\nleverage discourse relations (DRs) in spontaneous conversational contexts. In\nthis work, we adapt a system of DRs for written language to spontaneous\ndialogue using crowdsourced annotations from novice annotators. We then test\nwhether discourse relations are used differently across several types of\nmulti-utterance contexts. We compare the patterns of DR annotation within and\nacross speakers and within and across turns. Ultimately, we find that different\ndiscourse contexts produce distinct distributions of discourse relations, with\nsingle-turn annotations creating the most uncertainty for annotators.\nAdditionally, we find that the discourse relation annotations are of sufficient\nquality to predict from embeddings of discourse units.",
        "translated": "时间压力和话题协商可能会制约人们在自发会话语境中如何利用话语关系。在这项工作中，我们使用了一个书面语言的 DRs 系统，使其能够使用来自新手注释者的众包注释进行自发的对话。然后，我们测试语篇关系是否在不同类型的多话语语境中使用不同。我们比较了说话人内部和跨说话人的 DR 标注模式，以及说话人内部和跨说话人的 DR 标注模式。最终，我们发现不同的话语语境会产生不同的话语关系分布，单圈注释会给注释者带来最大的不确定性。另外，我们发现语篇关系注释具有足够的质量来预测语篇单位的嵌入。"
    },
    {
        "title": "Text Simplification of Scientific Texts for Non-Expert Readers",
        "url": "http://arxiv.org/abs/2307.03569v1",
        "pub_date": "2023-07-07",
        "summary": "Reading levels are highly individual and can depend on a text's language, a\nperson's cognitive abilities, or knowledge on a topic. Text simplification is\nthe task of rephrasing a text to better cater to the abilities of a specific\ntarget reader group. Simplification of scientific abstracts helps non-experts\nto access the core information by bypassing formulations that require domain or\nexpert knowledge. This is especially relevant for, e.g., cancer patients\nreading about novel treatment options. The SimpleText lab hosts the\nsimplification of scientific abstracts for non-experts (Task 3) to advance this\nfield. We contribute three runs employing out-of-the-box summarization models\n(two based on T5, one based on PEGASUS) and one run using ChatGPT with complex\nphrase identification.",
        "translated": "阅读水平是高度个人化的，可以取决于一篇文章的语言，一个人的认知能力，或对一个主题的知识。文本简化是指根据特定目标读者群体的能力对文本进行改写。科学摘要的简化有助于非专家通过绕过需要领域或专家知识的表述方式获取核心信息。这对于癌症患者阅读新的治疗方案尤其重要。SimpleText 实验室为非专家提供科学摘要的简化服务(Task 3) ，以推动这一领域的发展。我们使用开箱即用的摘要模型进行了三次运行(两次基于 T5，一次基于 PEGASUS) ，一次使用带有复杂短语识别的 ChatGPT。"
    },
    {
        "title": "DWReCO at CheckThat! 2023: Enhancing Subjectivity Detection through\n  Style-based Data Sampling",
        "url": "http://arxiv.org/abs/2307.03550v1",
        "pub_date": "2023-07-07",
        "summary": "This paper describes our submission for the subjectivity detection task at\nthe CheckThat! Lab. To tackle class imbalances in the task, we have generated\nadditional training materials with GPT-3 models using prompts of different\nstyles from a subjectivity checklist based on journalistic perspective. We used\nthe extended training set to fine-tune language-specific transformer models.\nOur experiments in English, German and Turkish demonstrate that different\nsubjective styles are effective across all languages. In addition, we observe\nthat the style-based oversampling is better than paraphrasing in Turkish and\nEnglish. Lastly, the GPT-3 models sometimes produce lacklustre results when\ngenerating style-based texts in non-English languages.",
        "translated": "本文介绍了我们在 CheckThat 提交的主观性检测任务！实验室。为了解决这项任务中班级失衡的问题，我们使用 GPT-3模型，从基于新闻视角的主观性检查表中使用不同风格的提示，生成了额外的培训材料。我们使用扩展训练集来微调特定于语言的转换器模型。我们在英语、德语和土耳其语中的实验表明，不同的主观风格在所有语言中都是有效的。此外，我们观察到基于风格的过采样比土耳其语和英语的释义更好。最后，GPT-3模型在生成非英语语言的基于风格的文本时，有时会产生黯淡的结果。"
    },
    {
        "title": "Large Language Models as Batteries-Included Zero-Shot ESCO Skills\n  Matchers",
        "url": "http://arxiv.org/abs/2307.03539v1",
        "pub_date": "2023-07-07",
        "summary": "Understanding labour market dynamics requires accurately identifying the\nskills required for and possessed by the workforce. Automation techniques are\nincreasingly being developed to support this effort. However, automatically\nextracting skills from job postings is challenging due to the vast number of\nexisting skills. The ESCO (European Skills, Competences, Qualifications and\nOccupations) framework provides a useful reference, listing over 13,000\nindividual skills. However, skills extraction remains difficult and accurately\nmatching job posts to the ESCO taxonomy is an open problem. In this work, we\npropose an end-to-end zero-shot system for skills extraction from job\ndescriptions based on large language models (LLMs). We generate synthetic\ntraining data for the entirety of ESCO skills and train a classifier to extract\nskill mentions from job posts. We also employ a similarity retriever to\ngenerate skill candidates which are then re-ranked using a second LLM. Using\nsynthetic data achieves an RP@10 score 10 points higher than previous distant\nsupervision approaches. Adding GPT-4 re-ranking improves RP@10 by over 22\npoints over previous methods. We also show that Framing the task as mock\nprogramming when prompting the LLM can lead to better performance than natural\nlanguage prompts, especially with weaker LLMs. We demonstrate the potential of\nintegrating large language models at both ends of skills matching pipelines.\nOur approach requires no human annotations and achieve extremely promising\nresults on skills extraction against ESCO.",
        "translated": "了解劳动力市场的动态需要准确地确定劳动力所需要和拥有的技能。越来越多的自动化技术正在被开发以支持这种努力。然而，由于现有技能数量庞大，自动从招聘信息中提取技能非常具有挑战性。欧洲技能，能力，资格和职业框架提供了一个有用的参考，列出了超过13,000个人的技能。然而，技能提取仍然困难和准确匹配的工作岗位，以教科文组织的分类是一个公开的问题。在这项工作中，我们提出了一个端到端的零拍摄系统的技能提取工作描述的基础上的大型语言模型(LLM)。我们生成的综合培训数据，为整个电子教科文组织的技能和培训分类器，以提取技能提到的职位。我们还使用一个相似性检索器来生成技能候选者，然后使用第二个 LLM 重新排序。使用合成数据实现了 RP@10得分比以前的远程监控方法高出10分。添加 GPT-4重新排序提高了超过22点的 RP@10比以前的方法。我们还展示了在提示 LLM 时将任务框架为模拟编程，可以比自然语言提示获得更好的性能，特别是对于较弱的 LLM。我们展示了在技能匹配管道的两端集成大型语言模型的潜力。我们的方法不需要人工注释，并取得非常有希望的结果对技能提取反对教科文组织。"
    },
    {
        "title": "Fairness and Diversity in Recommender Systems: A Survey",
        "url": "http://arxiv.org/abs/2307.04644v1",
        "pub_date": "2023-07-10",
        "summary": "Recommender systems are effective tools for mitigating information overload\nand have seen extensive applications across various domains. However, the\nsingle focus on utility goals proves to be inadequate in addressing real-world\nconcerns, leading to increasing attention to fairness-aware and diversity-aware\nrecommender systems. While most existing studies explore fairness and diversity\nindependently, we identify strong connections between these two domains. In\nthis survey, we first discuss each of them individually and then dive into\ntheir connections. Additionally, motivated by the concepts of user-level and\nitem-level fairness, we broaden the understanding of diversity to encompass not\nonly the item level but also the user level. With this expanded perspective on\nuser and item-level diversity, we re-interpret fairness studies from the\nviewpoint of diversity. This fresh perspective enhances our understanding of\nfairness-related work and paves the way for potential future research\ndirections. Papers discussed in this survey along with public code links are\navailable at\nhttps://github.com/YuyingZhao/Awesome-Fairness-and-Diversity-Papers-in-Recommender-Systems .",
        "translated": "推荐系统是缓解信息超载的有效工具，在各个领域得到了广泛的应用。然而，对效用目标的单一关注证明不足以解决现实世界的关切，从而导致对公平意识和多样性意识的推荐系统的日益关注。虽然现有的大多数研究都是独立地探讨公平性和多样性，但我们发现这两个领域之间存在着强烈的联系。在这个调查中，我们首先分别讨论他们，然后深入探讨他们之间的联系。此外，在用户层次和项目层次公平性概念的驱动下，我们拓宽了对多样性的理解，不仅包括项目层次，而且包括用户层次。本文从用户多样性和项目多样性的角度出发，重新解释了公平性研究。这一全新的视角加深了我们对公平相关工作的理解，为未来可能的研究方向铺平了道路。本调查所讨论的文件，连同公众守则的连结，可于 https://github.com/yuyingzhao/awesome-fairness-and-diversity-Papers-in-recommender-systems 下载。"
    },
    {
        "title": "InPars Toolkit: A Unified and Reproducible Synthetic Data Generation\n  Pipeline for Neural Information Retrieval",
        "url": "http://arxiv.org/abs/2307.04601v1",
        "pub_date": "2023-07-10",
        "summary": "Recent work has explored Large Language Models (LLMs) to overcome the lack of\ntraining data for Information Retrieval (IR) tasks. The generalization\nabilities of these models have enabled the creation of synthetic in-domain data\nby providing instructions and a few examples on a prompt. InPars and\nPromptagator have pioneered this approach and both methods have demonstrated\nthe potential of using LLMs as synthetic data generators for IR tasks. This\nmakes them an attractive solution for IR tasks that suffer from a lack of\nannotated data. However, the reproducibility of these methods was limited,\nbecause InPars' training scripts are based on TPUs -- which are not widely\naccessible -- and because the code for Promptagator was not released and its\nproprietary LLM is not publicly accessible. To fully realize the potential of\nthese methods and make their impact more widespread in the research community,\nthe resources need to be accessible and easy to reproduce by researchers and\npractitioners. Our main contribution is a unified toolkit for end-to-end\nreproducible synthetic data generation research, which includes generation,\nfiltering, training and evaluation. Additionally, we provide an interface to IR\nlibraries widely used by the community and support for GPU. Our toolkit not\nonly reproduces the InPars method and partially reproduces Promptagator, but\nalso provides a plug-and-play functionality allowing the use of different LLMs,\nexploring filtering methods and finetuning various reranker models on the\ngenerated data. We also made available all the synthetic data generated in this\nwork for the 18 different datasets in the BEIR benchmark which took more than\n2,000 GPU hours to be generated as well as the reranker models finetuned on the\nsynthetic data. Code and data are available at\nhttps://github.com/zetaalphavector/InPars",
        "translated": "最近的工作已经探索了大语言模型(LLM)来克服缺乏训练数据的信息检索(IR)任务。这些模型的泛化能力通过在提示符上提供指令和一些示例来创建合成的域内数据。InPars 和 Promptagator 是这种方法的先驱，两种方法都展示了将 LLM 用作 IR 任务的合成数据生成器的潜力。这使得它们成为缺乏注释数据的 IR 任务的有吸引力的解决方案。然而，这些方法的可重复性是有限的，因为 InPars 的培训脚本是基于 TPU 的——这不是广泛可访问的——而且因为 Promptagator 的代码没有发布，其专有的 LLM 也不是公开可访问的。为了充分发挥这些方法的潜力并使其影响在研究界更加广泛，研究人员和从业人员必须能够获得并容易复制这些资源。我们的主要贡献是为端到端可重复的综合数据生成研究提供了一个统一的工具包，其中包括生成、过滤、训练和评估。此外，我们还为社区广泛使用的 IR 库提供了一个接口，并支持 GPU。我们的工具包不仅重现了 InPars 方法并部分重现了 Promptagator，而且还提供了即插即用功能，允许使用不同的 LLM，探索过滤方法并在生成的数据上微调各种重新排名模型。我们还提供了所有的合成数据在这项工作中产生的18个不同的数据集在 BEIR 基准，需要超过2000个图形处理器小时以及重新排名模型的合成数据进行微调。代码和数据可在 https://github.com/zetaalphavector/inpars 查阅"
    },
    {
        "title": "A Semi-Automated Solution Approach Selection Tool for Any Use Case via\n  Scopus and OpenAI: a Case Study for AI/ML in Oncology",
        "url": "http://arxiv.org/abs/2307.04573v1",
        "pub_date": "2023-07-10",
        "summary": "In today's vast literature landscape, a manual review is very time-consuming.\nTo address this challenge, this paper proposes a semi-automated tool for\nsolution method review and selection. It caters to researchers, practitioners,\nand decision-makers while serving as a benchmark for future work. The tool\ncomprises three modules: (1) paper selection and scoring, using a keyword\nselection scheme to query Scopus API and compute relevancy; (2) solution method\nextraction in papers utilizing OpenAI API; (3) sensitivity analysis and\npost-analyzes. It reveals trends, relevant papers, and methods. AI in the\noncology case study and several use cases are presented with promising results,\ncomparing the tool to manual ground truth.",
        "translated": "在当今浩瀚的文学世界中，手工复习是非常耗时的。为了解决这个问题，本文提出了一个用于解决方案方法评审和选择的半自动化工具。它迎合了研究人员、从业人员和决策者的需要，同时作为未来工作的基准。该工具包括三个模块: (1)论文选择和评分，使用关键词选择方案查询 Scopus API 并计算相关性; (2)利用 OpenAI API 提取论文中的解决方案方法; (3)敏感度分析和事后分析。它揭示了趋势，相关论文和方法。AI 在肿瘤病例研究和几个用例提出了有希望的结果，比较工具手动地面真相。"
    },
    {
        "title": "Alleviating Matthew Effect of Offline Reinforcement Learning in\n  Interactive Recommendation",
        "url": "http://arxiv.org/abs/2307.04571v1",
        "pub_date": "2023-07-10",
        "summary": "Offline reinforcement learning (RL), a technology that offline learns a\npolicy from logged data without the need to interact with online environments,\nhas become a favorable choice in decision-making processes like interactive\nrecommendation. Offline RL faces the value overestimation problem. To address\nit, existing methods employ conservatism, e.g., by constraining the learned\npolicy to be close to behavior policies or punishing the rarely visited\nstate-action pairs. However, when applying such offline RL to recommendation,\nit will cause a severe Matthew effect, i.e., the rich get richer and the poor\nget poorer, by promoting popular items or categories while suppressing the less\npopular ones. It is a notorious issue that needs to be addressed in practical\nrecommender systems.\n  In this paper, we aim to alleviate the Matthew effect in offline RL-based\nrecommendation. Through theoretical analyses, we find that the conservatism of\nexisting methods fails in pursuing users' long-term satisfaction. It inspires\nus to add a penalty term to relax the pessimism on states with high entropy of\nthe logging policy and indirectly penalizes actions leading to less diverse\nstates. This leads to the main technical contribution of the work: Debiased\nmodel-based Offline RL (DORL) method. Experiments show that DORL not only\ncaptures user interests well but also alleviates the Matthew effect. The\nimplementation is available via https://github.com/chongminggao/DORL-codes.",
        "translated": "离线强化学习(off-line)是一种无需与在线环境交互就可以从记录的数据中学习策略的技术，已经成为诸如交互式推荐等决策过程中的一个有利选择。脱机 RL 面临价值高估问题。为了解决这个问题，现有的方法采用了保守主义，例如，通过限制学习政策接近行为政策或惩罚很少访问的国家行动对。然而，当把这种线下 RL 应用于推荐时，它会产生一种严重的马太效应，也就是说，富人变得更富，穷人变得更穷，通过推销受欢迎的项目或类别，同时压制不太受欢迎的项目或类别。这是一个臭名昭著的问题，需要解决的实际推荐系统。本文旨在减轻基于 RL 的离线推荐中的马太效应。通过理论分析，我们发现现有方法的保守性不足以追求用户的长期满意度。它启发我们增加一个惩罚项，以放松对伐木政策的高熵状态的悲观情绪，并间接惩罚导致较少多样性状态的行动。这导致了这项工作的主要技术贡献: 基于消偏模型的离线 RL (DORL)方法。实验表明，DORL 不仅能够很好地捕获用户的兴趣，而且减轻了马太效应。有关实施方案可透过 https://github.com/chongminggao/dorl-codes 提供。"
    },
    {
        "title": "Counterfactual Explanation for Fairness in Recommendation",
        "url": "http://arxiv.org/abs/2307.04386v1",
        "pub_date": "2023-07-10",
        "summary": "Fairness-aware recommendation eliminates discrimination issues to build\ntrustworthy recommendation systems.Explaining the causes of unfair\nrecommendations is critical, as it promotes fairness diagnostics, and thus\nsecures users' trust in recommendation models. Existing fairness explanation\nmethods suffer high computation burdens due to the large-scale search space and\nthe greedy nature of the explanation search process. Besides, they perform\nscore-based optimizations with continuous values, which are not applicable to\ndiscrete attributes such as gender and race. In this work, we adopt the novel\nparadigm of counterfactual explanation from causal inference to explore how\nminimal alterations in explanations change model fairness, to abandon the\ngreedy search for explanations. We use real-world attributes from Heterogeneous\nInformation Networks (HINs) to empower counterfactual reasoning on discrete\nattributes. We propose a novel Counterfactual Explanation for Fairness\n(CFairER) that generates attribute-level counterfactual explanations from HINs\nfor recommendation fairness. Our CFairER conducts off-policy reinforcement\nlearning to seek high-quality counterfactual explanations, with an attentive\naction pruning reducing the search space of candidate counterfactuals. The\ncounterfactual explanations help to provide rational and proximate explanations\nfor model fairness, while the attentive action pruning narrows the search space\nof attributes. Extensive experiments demonstrate our proposed model can\ngenerate faithful explanations while maintaining favorable recommendation\nperformance.",
        "translated": "公平意识的推荐消除了歧视问题，建立了可信赖的推荐系统。解释不公平推荐的原因是至关重要的，因为它促进了公平诊断，从而保证了用户对推荐模型的信任。现有的公平性解释方法由于搜索空间大和解释搜索过程的贪婪性，计算量大。此外，他们执行连续值的基于分数的优化，这不适用于离散的属性，如性别和种族。本文采用因果推理反事实解释的新范式，探讨解释的微小变化如何改变模型的公平性，摒弃对解释的贪婪追求。我们利用异构信息网络(HIN)中的真实世界属性对离散属性进行反事实推理。我们提出了一种新的推荐公平性反事实解释(CFairER)算法，该算法从 HIN 中生成推荐公平性的属性级反事实解释。我们的 CFairer 进行非政策强化学习，寻求高质量的反事实解释，通过专注的行动精简，减少候选反事实的搜索空间。反事实解释有助于为模型公平性提供合理的近似解释，而注意行为修剪则缩小了属性的搜索空间。大量的实验表明，我们提出的模型可以产生忠实的解释，同时保持良好的推荐性能。"
    },
    {
        "title": "Large Language Models as General Pattern Machines",
        "url": "http://arxiv.org/abs/2307.04721v1",
        "pub_date": "2023-07-10",
        "summary": "We observe that pre-trained large language models (LLMs) are capable of\nautoregressively completing complex token sequences -- from arbitrary ones\nprocedurally generated by probabilistic context-free grammars (PCFG), to more\nrich spatial patterns found in the Abstract Reasoning Corpus (ARC), a general\nAI benchmark, prompted in the style of ASCII art. Surprisingly, pattern\ncompletion proficiency can be partially retained even when the sequences are\nexpressed using tokens randomly sampled from the vocabulary. These results\nsuggest that without any additional training, LLMs can serve as general\nsequence modelers, driven by in-context learning. In this work, we investigate\nhow these zero-shot capabilities may be applied to problems in robotics -- from\nextrapolating sequences of numbers that represent states over time to complete\nsimple motions, to least-to-most prompting of reward-conditioned trajectories\nthat can discover and represent closed-loop policies (e.g., a stabilizing\ncontroller for CartPole). While difficult to deploy today for real systems due\nto latency, context size limitations, and compute costs, the approach of using\nLLMs to drive low-level control may provide an exciting glimpse into how the\npatterns among words could be transferred to actions.",
        "translated": "我们观察到，预先训练的大语言模型(LLM)能够自动回归地完成复杂的标记序列——从由概率上下文无关文法(PCFG)程序化生成的任意标记序列，到抽象推理语料库(ARC)中发现的更丰富的空间模式，ARC 是一个通用的人工智能基准，以 ASCII 艺术的风格提示。令人惊讶的是，即使使用从词汇表中随机抽样的标记来表示序列，模式完成熟练程度也可以部分保留。这些结果表明，没有任何额外的训练，LLM 可以作为一般序列建模，驱动在上下文学习。在这项工作中，我们研究了这些零射击能力如何应用于机器人技术中的问题——从外推代表状态随时间变化的数字序列以完成简单的运动，到最小到最大的奖励条件轨迹提示，这些轨迹可以发现并表示闭环策略(例如，CartPole 的稳定控制器)。尽管由于延迟、上下文大小限制和计算成本等原因，现在很难在真正的系统中部署，但是使用 LLM 来驱动低级控制的方法可以让人们对如何将语言中的模式转化为行动有一个令人兴奋的了解。"
    },
    {
        "title": "BeaverTails: Towards Improved Safety Alignment of LLM via a\n  Human-Preference Dataset",
        "url": "http://arxiv.org/abs/2307.04657v1",
        "pub_date": "2023-07-10",
        "summary": "In this paper, we introduce the BeaverTails dataset, aimed at fostering\nresearch on safety alignment in large language models (LLMs). This dataset\nuniquely separates annotations of helpfulness and harmlessness for\nquestion-answering pairs, thus offering distinct perspectives on these crucial\nattributes. In total, we have compiled safety meta-labels for 30,207\nquestion-answer (QA) pairs and gathered 30,144 pairs of expert comparison data\nfor both the helpfulness and harmlessness metrics. We further showcase\napplications of BeaverTails in content moderation and reinforcement learning\nwith human feedback (RLHF), emphasizing its potential for practical safety\nmeasures in LLMs. We believe this dataset provides vital resources for the\ncommunity, contributing towards the safe development and deployment of LLMs.\nOur project page is available at the following URL:\nhttps://sites.google.com/view/pku-beavertails.",
        "translated": "本文引入 BeaverTails 数据集，旨在促进大语言模型(LLM)中安全校准的研究。这个数据集独特地分离了问答对的有益和无害的注释，从而提供了关于这些关键属性的不同观点。我们总共编制了30,207对问答(QA)的安全元标签，并收集了30,144对专家对有益和无害指标的比较数据。我们进一步展示了 BeaverTails 在内容审核和人工反馈强化学习中的应用，强调了它在 LLM 中实际安全措施的潜力。我们相信这个数据集为社区提供了重要的资源，为 LLM 的安全开发和部署做出了贡献。我们的项目页面可以在以下网址找到:  https://sites.google.com/view/pku-beavertails。"
    },
    {
        "title": "Measuring Lexical Diversity in Texts: The Twofold Length Problem",
        "url": "http://arxiv.org/abs/2307.04626v1",
        "pub_date": "2023-07-10",
        "summary": "The impact of text length on the estimation of lexical diversity has captured\nthe attention of the scientific community for more than a century. Numerous\nindices have been proposed, and many studies have been conducted to evaluate\nthem, but the problem remains. This methodological review provides a critical\nanalysis not only of the most commonly used indices in language learning\nstudies, but also of the length problem itself, as well as of the methodology\nfor evaluating the proposed solutions. The analysis of three datasets of\nEnglish language-learners' texts revealed that indices that reduce all texts to\nthe same length using a probabilistic or an algorithmic approach solve the\nlength dependency problem; however, all these indices failed to address the\nsecond problem, which is their sensitivity to the parameter that determines the\nlength to which the texts are reduced. The paper concludes with recommendations\nfor optimizing lexical diversity analysis.",
        "translated": "一个多世纪以来，文本长度对词汇多样性估计的影响一直受到科学界的关注。已经提出了许多指标，并进行了许多研究来评价它们，但问题仍然存在。本文不仅对语言学习研究中最常用的指标，而且对长度问题本身以及评价所提出的解决方案的方法进行了批判性的分析。对英语学习者文本的三个数据集的分析表明，使用概率或算法方法将所有文本减少到相同长度的指数解决了长度依赖性问题; 然而，所有这些指数都未能解决第二个问题，即它们对决定文本减少长度的参数的敏感性。本文最后提出了优化词汇多样性分析的建议。"
    },
    {
        "title": "On the Computational Modeling of Meaning: Embodied Cognition Intertwined\n  with Emotion",
        "url": "http://arxiv.org/abs/2307.04518v1",
        "pub_date": "2023-07-10",
        "summary": "This document chronicles this author's attempt to explore how words come to\nmean what they do, with a particular focus on child language acquisition and\nwhat that means for models of language understanding.\\footnote{I say\n\\emph{historical} because I synthesize the ideas based on when I discovered\nthem and how those ideas influenced my later thinking.} I explain the setting\nfor child language learning, how embodiment -- being able to perceive and enact\nin the world, including knowledge of concrete and abstract concepts -- is\ncrucial, and how emotion and cognition relate to each other and the language\nlearning process. I end with what I think are some of the requirements for a\nlanguage-learning agent that learns language in a setting similar to that of\nchildren. This paper can act as a potential guide for ongoing and future work\nin modeling language.",
        "translated": "本文档记录了作者试图探索词汇如何意味着它们所做的事情，特别关注儿童语言习得以及这对语言理解模型意味着什么。脚注{我说 emph { history }是因为我是根据我什么时候发现这些想法以及这些想法是如何影响我以后的思考来综合这些想法的。}我解释了儿童语言学习的背景，具体化——能够在世界上感知和表现，包括具体和抽象概念的知识——是如何至关重要的，以及情感和认知如何相互关联和语言学习过程。最后，我想到了一个语言学习机构在类似于儿童的环境中学习语言的一些要求。这篇文章可以作为建模语言正在进行和未来工作的潜在指南。"
    },
    {
        "title": "Improving Factuality of Abstractive Summarization via Contrastive Reward\n  Learning",
        "url": "http://arxiv.org/abs/2307.04507v1",
        "pub_date": "2023-07-10",
        "summary": "Modern abstractive summarization models often generate summaries that contain\nhallucinated or contradictory information. In this paper, we propose a simple\nbut effective contrastive learning framework that incorporates recent\ndevelopments in reward learning and factuality metrics. Empirical studies\ndemonstrate that the proposed framework enables summarization models to learn\nfrom feedback of factuality metrics using contrastive reward learning, leading\nto more factual summaries by human evaluations. This suggests that further\nadvances in learning and evaluation algorithms can feed directly into providing\nmore factual summaries.",
        "translated": "现代抽象摘要模型经常生成包含幻觉或矛盾信息的摘要。在本文中，我们提出了一个简单而有效的对比学习框架，结合奖励学习和事实度量的最新发展。实证研究表明，该框架使总结模型能够利用对比奖励学习从真实性指标的反馈中学习，从而通过人工评估得到更加真实的总结。这表明，学习和评估算法的进一步发展可以直接用于提供更多的事实性摘要。"
    },
    {
        "title": "Enhancing Biomedical Text Summarization and Question-Answering: On the\n  Utility of Domain-Specific Pre-Training",
        "url": "http://arxiv.org/abs/2307.04412v1",
        "pub_date": "2023-07-10",
        "summary": "Biomedical summarization requires large datasets to train for text\ngeneration. We show that while transfer learning offers a viable option for\naddressing this challenge, an in-domain pre-training does not always offer\nadvantages in a BioASQ summarization task. We identify a suitable model\narchitecture and use it to show a benefit of a general-domain pre-training\nfollowed by a task-specific fine-tuning in the context of a BioASQ\nsummarization task, leading to a novel three-step fine-tuning approach that\nworks with only a thousand in-domain examples. Our results indicate that a\nLarge Language Model without domain-specific pre-training can have a\nsignificant edge in some domain-specific biomedical text generation tasks.",
        "translated": "生物医学摘要需要大量的数据集来训练文本生成。我们表明，虽然转移学习提供了一个可行的选择，以解决这一挑战，域内预训练并不总是提供优势，在 BioASQ 摘要任务。我们确定了一个合适的模型架构，并使用它来显示一般领域预训练的好处，然后在 BioASQ 摘要任务的背景下进行任务特定的微调，导致一种新颖的三步微调方法，仅使用一千个域内示例。我们的研究结果表明，一个没有领域特定的预训练的大语言模型可以在一些领域特定的生物医学文本生成任务中具有显著的优势。"
    },
    {
        "title": "TIM: Teaching Large Language Models to Translate with Comparison",
        "url": "http://arxiv.org/abs/2307.04408v1",
        "pub_date": "2023-07-10",
        "summary": "Open-sourced large language models (LLMs) have demonstrated remarkable\nefficacy in various tasks with instruction tuning. However, these models can\nsometimes struggle with tasks that require more specialized knowledge such as\ntranslation. One possible reason for such deficiency is that instruction tuning\naims to generate fluent and coherent text that continues from a given\ninstruction without being constrained by any task-specific requirements.\nMoreover, it can be more challenging for tuning smaller LLMs with lower-quality\ntraining data. To address this issue, we propose a novel framework using\nexamples in comparison to teach LLMs to learn translation. Our approach\ninvolves presenting the model with examples of correct and incorrect\ntranslations and using a preference loss to guide the model's learning. We\nevaluate our method on WMT2022 test sets and show that it outperforms existing\nmethods. Our findings offer a new perspective on fine-tuning LLMs for\ntranslation tasks and provide a promising solution for generating high-quality\ntranslations. Please refer to Github for more details:\nhttps://github.com/lemon0830/TIM.",
        "translated": "开源的大型语言模型(LLM)已经证明了在指令调优的各种任务中显著的效力。然而，这些模型有时可能难以完成需要更专业知识的任务，比如翻译。造成这种缺陷的一个可能的原因是，指令调优的目的是生成从给定指令继续的流畅和连贯的文本，而不受任何特定于任务的要求的限制。此外，使用较低质量的训练数据调优较小的 LLM 可能更具挑战性。为了解决这个问题，我们提出了一个新的框架，使用例子比较教学法学习翻译。我们的方法包括给模型提供正确和错误的翻译实例，并使用偏好损失来指导模型的学习。我们在 WMT2022测试集上对我们的方法进行了评估，结果表明它的性能优于现有的方法。我们的研究结果为翻译任务的微调 LLM 提供了一个新的视角，并为生成高质量的翻译提供了一个有希望的解决方案。详情请参阅 Github:  https://Github.com/lemon0830/tim。"
    },
    {
        "title": "Ethicist: Targeted Training Data Extraction Through Loss Smoothed Soft\n  Prompting and Calibrated Confidence Estimation",
        "url": "http://arxiv.org/abs/2307.04401v1",
        "pub_date": "2023-07-10",
        "summary": "Large pre-trained language models achieve impressive results across many\ntasks. However, recent works point out that pre-trained language models may\nmemorize a considerable fraction of their training data, leading to the privacy\nrisk of information leakage. In this paper, we propose a method named Ethicist\nfor targeted training data extraction through loss smoothed soft prompting and\ncalibrated confidence estimation, investigating how to recover the suffix in\nthe training data when given a prefix. To elicit memorization in the attacked\nmodel, we tune soft prompt embeddings while keeping the model fixed. We further\npropose a smoothing loss that smooths the loss distribution of the suffix\ntokens to make it easier to sample the correct suffix. In order to select the\nmost probable suffix from a collection of sampled suffixes and estimate the\nprediction confidence, we propose a calibrated confidence estimation method,\nwhich normalizes the confidence of the generated suffixes with a local\nestimation. We show that Ethicist significantly improves the extraction\nperformance on a recently proposed public benchmark. We also investigate\nseveral factors influencing the data extraction performance, including decoding\nstrategy, model scale, prefix length, and suffix length. Our code is available\nat https://github.com/thu-coai/Targeted-Data-Extraction.",
        "translated": "大型预训练语言模型在许多任务中都能取得令人印象深刻的结果。然而，最近的研究指出，预先训练的语言模型可能会记住相当一部分的训练数据，导致信息泄露的隐私风险。本文提出了一种基于损失平滑软提示和校准置信度估计的目标训练数据提取方法，研究了在给定前缀的情况下如何恢复训练数据中的后缀。为了在被攻击的模型中诱导记忆，我们在保持模型不变的情况下调整了软提示嵌入。我们进一步提出了一种平滑损失，平滑后缀标记的损失分布，使其更容易采样正确的后缀。为了从采样后缀集合中选择最可能的后缀并估计预测置信度，提出了一种校准的置信度估计方法，该方法通过局部估计对所生成后缀的置信度进行归一化。我们表明，Ethicist 显着提高了最近提出的公共基准的提取性能。我们还研究了几个影响数据提取性能的因素，包括解码策略、模型尺度、前缀长度和后缀长度。我们的代码可以在 https://github.com/thu-coai/targeted-data-extraction 找到。"
    },
    {
        "title": "Enhancing Cross-lingual Transfer via Phonemic Transcription Integration",
        "url": "http://arxiv.org/abs/2307.04361v1",
        "pub_date": "2023-07-10",
        "summary": "Previous cross-lingual transfer methods are restricted to orthographic\nrepresentation learning via textual scripts. This limitation hampers\ncross-lingual transfer and is biased towards languages sharing similar\nwell-known scripts. To alleviate the gap between languages from different\nwriting scripts, we propose PhoneXL, a framework incorporating phonemic\ntranscriptions as an additional linguistic modality beyond the traditional\northographic transcriptions for cross-lingual transfer. Particularly, we\npropose unsupervised alignment objectives to capture (1) local one-to-one\nalignment between the two different modalities, (2) alignment via\nmulti-modality contexts to leverage information from additional modalities, and\n(3) alignment via multilingual contexts where additional bilingual dictionaries\nare incorporated. We also release the first phonemic-orthographic alignment\ndataset on two token-level tasks (Named Entity Recognition and Part-of-Speech\nTagging) among the understudied but interconnected\nChinese-Japanese-Korean-Vietnamese (CJKV) languages. Our pilot study reveals\nphonemic transcription provides essential information beyond the orthography to\nenhance cross-lingual transfer and bridge the gap among CJKV languages, leading\nto consistent improvements on cross-lingual token-level tasks over\northographic-based multilingual PLMs.",
        "translated": "以往的跨语言迁移方法仅限于通过文本脚本进行正字法表征学习。这种限制阻碍了跨语言的传递，并且偏向于共享类似的众所周知的脚本的语言。为了缩小不同书写语言之间的差距，我们提出了 PhoneXL，这是一个包含音素转录的框架，作为传统正字法转录之外的一个额外情态，用于跨语言转换。特别是，我们提出无监督的对齐目标，以捕获(1)两种不同模式之间的局部一对一对齐，(2)通过多模式上下文对齐以利用来自其他模式的信息，以及(3)通过多语言上下文对齐，其中纳入了额外的双语词典。我们还在被研究但相互关联的汉语-日语-韩语-越南语(CJKV)语言中发布了关于两个标记级任务(命名实体识别和词性标记)的第一个音素-正字法对齐数据集。我们的初步研究显示，音位转录提供了正字法之外的重要信息，以增强跨语言转换并弥合 CJKV 语言之间的差距，导致跨语言令牌水平任务相对于基于正字法的多语言 PLM 的一致改进。"
    },
    {
        "title": "RLTF: Reinforcement Learning from Unit Test Feedback",
        "url": "http://arxiv.org/abs/2307.04349v1",
        "pub_date": "2023-07-10",
        "summary": "The goal of program synthesis, or code generation, is to generate executable\ncode based on given descriptions. Recently, there has been an increasing number\nof studies employing reinforcement learning (RL) to improve the performance of\nlarge language models (LLMs) for code. However, these RL methods have only used\noffline frameworks, limiting their exploration of new sample spaces.\nAdditionally, current approaches that utilize unit test signals are rather\nsimple, not accounting for specific error locations within the code. To address\nthese issues, we proposed RLTF, i.e., Reinforcement Learning from Unit Test\nFeedback, a novel online RL framework with unit test feedback of\nmulti-granularity for refining code LLMs. Our approach generates data in\nreal-time during training and simultaneously utilizes fine-grained feedback\nsignals to guide the model towards producing higher-quality code. Extensive\nexperiments show that RLTF achieves state-of-the-art performance on the APPS\nand the MBPP benchmarks. Our code can be found at:\nhttps://github.com/Zyq-scut/RLTF.",
        "translated": "程序合成或代码生成的目标是根据给定的描述生成可执行代码。最近，越来越多的研究使用强化学习(RL)来提高代码的大型语言模型(LLM)的性能。然而，这些 RL 方法只使用了离线框架，限制了它们对新样例空间的探索。此外，利用单元测试信号的当前方法相当简单，没有考虑到代码中特定的错误位置。为了解决这些问题，我们提出了 RLTF，即强化学习于单元测试反馈，这是一个新的在线 RL 框架，具有多粒度的单元测试反馈，用于细化代码 LLM。我们的方法在训练过程中实时生成数据，同时利用细粒度的反馈信号指导模型生成更高质量的代码。大量的实验表明，RLTF 在 APPS 和 MBPP 基准上达到了最先进的性能。我们的代码可以在 https://github.com/zyq-scut/rltf 找到。"
    },
    {
        "title": "Duncode Characters Shorter",
        "url": "http://arxiv.org/abs/2307.05414v1",
        "pub_date": "2023-07-11",
        "summary": "This paper investigates the employment of various encoders in text\ntransformation, converting characters into bytes. It discusses local encoders\nsuch as ASCII and GB-2312, which encode specific characters into shorter bytes,\nand universal encoders like UTF-8 and UTF-16, which can encode the complete\nUnicode set with greater space requirements and are gaining widespread\nacceptance. Other encoders, including SCSU, BOCU-1, and binary encoders,\nhowever, lack self-synchronizing capabilities. Duncode is introduced as an\ninnovative encoding method that aims to encode the entire Unicode character set\nwith high space efficiency, akin to local encoders. It has the potential to\ncompress multiple characters of a string into a Duncode unit using fewer bytes.\nDespite offering less self-synchronizing identification information, Duncode\nsurpasses UTF8 in terms of space efficiency. The application is available at\n\\url{https://github.com/laohur/duncode}. Additionally, we have developed a\nbenchmark for evaluating character encoders across different languages. It\nencompasses 179 languages and can be accessed at\n\\url{https://github.com/laohur/wiki2txt}.",
        "translated": "本文研究了各种编码器在文本转换中的应用，将字符转换为字节。本文讨论了本地编码器，如 ASCII 和 GB-2312，它们将特定字符编码成更短的字节; 还讨论了通用编码器，如 UTF-8和 UTF-16，它们可以对完整的 Unicode 集合进行更大的空间需求编码，并正在获得广泛的认可。但是，其他编码器，包括 SCSU、 BOCU-1和二进制编码器，缺乏自同步功能。Duncode 是一种创新的编码方法，旨在以高空间效率对整个 Unicode字符进行编码，类似于本地编码器。它可以使用更少的字节将字符串的多个字符压缩为 Duncode 单元。尽管 Duncode 提供的自同步识别信息较少，但在空间效率方面超过了 UTF8。申请表格可于网址{ https://github.com/laohur/duncode }下载。此外，我们还开发了一个评估跨不同语言字符编码器的基准。它包含179种语言，可以通过 url { https://github.com/laohur/wiki2txt }访问。"
    },
    {
        "title": "Temporal Graphs Anomaly Emergence Detection: Benchmarking For Social\n  Media Interactions",
        "url": "http://arxiv.org/abs/2307.05268v1",
        "pub_date": "2023-07-11",
        "summary": "Temporal graphs have become an essential tool for analyzing complex dynamic\nsystems with multiple agents. Detecting anomalies in temporal graphs is crucial\nfor various applications, including identifying emerging trends, monitoring\nnetwork security, understanding social dynamics, tracking disease outbreaks,\nand understanding financial dynamics. In this paper, we present a comprehensive\nbenchmarking study that compares 12 data-driven methods for anomaly detection\nin temporal graphs. We conduct experiments on two temporal graphs extracted\nfrom Twitter and Facebook, aiming to identify anomalies in group interactions.\nSurprisingly, our study reveals an unclear pattern regarding the best method\nfor such tasks, highlighting the complexity and challenges involved in anomaly\nemergence detection in large and dynamic systems. The results underscore the\nneed for further research and innovative approaches to effectively detect\nemerging anomalies in dynamic systems represented as temporal graphs.",
        "translated": "时态图已经成为分析多智能体复杂动态系统的重要工具。检测时间图中的异常对于各种应用程序至关重要，包括识别新出现的趋势、监测网络安全、理解社会动态、跟踪疾病爆发以及理解金融动态。在本文中，我们提出了一个全面的基准研究，比较12个数据驱动的方法在时间图中的异常检测。我们对从 Twitter 和 Facebook 上提取的两个时间图进行实验，旨在识别群体互动中的异常现象。令人惊讶的是，我们的研究揭示了一个关于此类任务的最佳方法的模式，突出了在大型和动态系统中异常出现检测所涉及的复杂性和挑战。这些结果强调需要进一步的研究和创新方法，以有效地检测以时间图表示的动态系统中出现的异常。"
    },
    {
        "title": "U-CREAT: Unsupervised Case Retrieval using Events extrAcTion",
        "url": "http://arxiv.org/abs/2307.05260v1",
        "pub_date": "2023-07-11",
        "summary": "The task of Prior Case Retrieval (PCR) in the legal domain is about\nautomatically citing relevant (based on facts and precedence) prior legal cases\nin a given query case. To further promote research in PCR, in this paper, we\npropose a new large benchmark (in English) for the PCR task: IL-PCR (Indian\nLegal Prior Case Retrieval) corpus. Given the complex nature of case relevance\nand the long size of legal documents, BM25 remains a strong baseline for\nranking the cited prior documents. In this work, we explore the role of events\nin legal case retrieval and propose an unsupervised retrieval method-based\npipeline U-CREAT (Unsupervised Case Retrieval using Events Extraction). We find\nthat the proposed unsupervised retrieval method significantly increases\nperformance compared to BM25 and makes retrieval faster by a considerable\nmargin, making it applicable to real-time case retrieval systems. Our proposed\nsystem is generic, we show that it generalizes across two different legal\nsystems (Indian and Canadian), and it shows state-of-the-art performance on the\nbenchmarks for both the legal systems (IL-PCR and COLIEE corpora).",
        "translated": "在法律领域中，先前案例检索(PCR)的任务是在给定的查询案例中自动引用相关的(基于事实和先例)先前的法律案例。为了进一步促进 PCR 的研究，本文提出了一个新的大型基准(英文)的 PCR 任务: IL-PCR (印度法律先例检索)语料库。鉴于案件相关性的复杂性和法律文件的长篇大论，BM25仍然是对所引用的先前文件进行排序的一个有力基准。本文探讨了事件在法律案例检索中的作用，提出了一种基于流水线 U-CREAT 的无监督检索方法。我们发现提出的无监督检索方法与 BM25相比，性能显著提高，检索速度大幅提高，适用于实时案例检索系统。我们提出的系统是通用的，我们表明它概括了两个不同的法律体系(印度和加拿大) ，并且它在两个法律体系(IL-PCR 和 COLIEE cora)的基准上显示了最先进的表现。"
    },
    {
        "title": "Generative Contrastive Graph Learning for Recommendation",
        "url": "http://arxiv.org/abs/2307.05100v1",
        "pub_date": "2023-07-11",
        "summary": "By treating users' interactions as a user-item graph, graph learning models\nhave been widely deployed in Collaborative Filtering(CF) based recommendation.\nRecently, researchers have introduced Graph Contrastive Learning(GCL)\ntechniques into CF to alleviate the sparse supervision issue, which first\nconstructs contrastive views by data augmentations and then provides\nself-supervised signals by maximizing the mutual information between\ncontrastive views. Despite the effectiveness, we argue that current GCL-based\nrecommendation models are still limited as current data augmentation\ntechniques, either structure augmentation or feature augmentation. First,\nstructure augmentation randomly dropout nodes or edges, which is easy to\ndestroy the intrinsic nature of the user-item graph. Second, feature\naugmentation imposes the same scale noise augmentation on each node, which\nneglects the unique characteristics of nodes on the graph. To tackle the above\nlimitations, we propose a novel Variational Graph Generative-Contrastive\nLearning(VGCL) framework for recommendation. Specifically, we leverage\nvariational graph reconstruction to estimate a Gaussian distribution of each\nnode, then generate multiple contrastive views through multiple samplings from\nthe estimated distributions, which builds a bridge between generative and\ncontrastive learning. Besides, the estimated variances are tailored to each\nnode, which regulates the scale of contrastive loss for each node on\noptimization. Considering the similarity of the estimated distributions, we\npropose a cluster-aware twofold contrastive learning, a node-level to encourage\nconsistency of a node's contrastive views and a cluster-level to encourage\nconsistency of nodes in a cluster. Finally, extensive experimental results on\nthree public datasets clearly demonstrate the effectiveness of the proposed\nmodel.",
        "translated": "通过将用户交互作为一个用户项目图，图形学习模型被广泛应用于基于协同过滤(CF)的推荐中。近年来，研究人员将图形对比学习(Graph Contrative Learning，GCL)技术引入到 CF 中，解决了对比视图稀疏监督问题。尽管有效，我们认为，目前基于 GCL 的推荐模型仍然是有限的，作为当前的数据增强技术，无论是结构增强或特征增强。首先，结构扩展随机丢弃节点或边，这很容易破坏用户项图的本质。其次，特征增强对每个节点进行相同尺度的噪声增强，忽略了图上节点的独特性。针对上述局限性，本文提出了一种新的变分图生成对比学习(VGCL)框架。具体来说，我们利用变分图重建来估计每个节点的正态分布，然后从估计的分布中通过多个样本生成多个对比视图，这在生成学习和对比学习之间架起了一座桥梁。此外，估计的方差是针对每个节点量身定制的，它调节了每个节点在优化时的对比损失规模。考虑到估计分布的相似性，我们提出了一种基于聚类的双重对比学习方法，一个节点级别用于增强节点对比视图的一致性，一个聚类级别用于增强聚类中节点的一致性。最后，在三个公共数据集上的大量实验结果清楚地表明了该模型的有效性。"
    },
    {
        "title": "Retrieval-augmented GPT-3.5-based Text-to-SQL Framework with\n  Sample-aware Prompting and Dynamic Revision Chain",
        "url": "http://arxiv.org/abs/2307.05074v1",
        "pub_date": "2023-07-11",
        "summary": "Text-to-SQL aims at generating SQL queries for the given natural language\nquestions and thus helping users to query databases. Prompt learning with large\nlanguage models (LLMs) has emerged as a recent approach, which designs prompts\nto lead LLMs to understand the input question and generate the corresponding\nSQL. However, it faces challenges with strict SQL syntax requirements. Existing\nwork prompts the LLMs with a list of demonstration examples (i.e. question-SQL\npairs) to generate SQL, but the fixed prompts can hardly handle the scenario\nwhere the semantic gap between the retrieved demonstration and the input\nquestion is large. In this paper, we propose a retrieval-augmented prompting\nmethod for a LLM-based Text-to-SQL framework, involving sample-aware prompting\nand a dynamic revision chain. Our approach incorporates sample-aware\ndemonstrations, which include the composition of SQL operators and fine-grained\ninformation related to the given question. To retrieve questions sharing\nsimilar intents with input questions, we propose two strategies for assisting\nretrieval. Firstly, we leverage LLMs to simplify the original questions,\nunifying the syntax and thereby clarifying the users' intentions. To generate\nexecutable and accurate SQLs without human intervention, we design a dynamic\nrevision chain which iteratively adapts fine-grained feedback from the\npreviously generated SQL. Experimental results on three Text-to-SQL benchmarks\ndemonstrate the superiority of our method over strong baseline models.",
        "translated": "Text-to-SQL 旨在为给定的自然语言问题生成 SQL 查询，从而帮助用户查询数据库。使用大型语言模型(LLM)进行快速学习是最近出现的一种方法，它通过设计提示来引导 LLM 理解输入问题并生成相应的 SQL。但是，它面临严格的 SQL 语法要求的挑战。现有的工作提示 LLM 使用一系列演示示例(即问题 -SQL 对)来生成 SQL，但是固定的提示很难处理检索到的演示与输入问题之间的语义差距很大的场景。本文针对基于 LLM 的文本到 SQL 框架提出了一种检索增强提示方法，该方法包括样本感知提示和动态修订链。我们的方法结合了示例感知演示，其中包括 SQL 操作符的组合和与给定问题相关的细粒度信息。为了检索与输入问题意图相似的问题，我们提出了两种辅助检索策略。首先，我们利用 LLM 来简化最初的问题，统一语法，从而澄清用户的意图。为了在不需要人工干预的情况下生成可执行和准确的 SQL，我们设计了一个动态修订链，它可以迭代地适应来自先前生成的 SQL 的细粒度反馈。在三个文本到 SQL 基准测试上的实验结果表明了该方法相对于强基线模型的优越性。"
    },
    {
        "title": "Empowering Cross-lingual Behavioral Testing of NLP Models with\n  Typological Features",
        "url": "http://arxiv.org/abs/2307.05454v1",
        "pub_date": "2023-07-11",
        "summary": "A challenge towards developing NLP systems for the world's languages is\nunderstanding how they generalize to typological differences relevant for\nreal-world applications. To this end, we propose M2C, a morphologically-aware\nframework for behavioral testing of NLP models. We use M2C to generate tests\nthat probe models' behavior in light of specific linguistic features in 12\ntypologically diverse languages. We evaluate state-of-the-art language models\non the generated tests. While models excel at most tests in English, we\nhighlight generalization failures to specific typological characteristics such\nas temporal expressions in Swahili and compounding possessives in Finish. Our\nfindings motivate the development of models that address these blind spots.",
        "translated": "为世界各语言开发 NLP 系统的一个挑战是理解它们如何概括与现实世界应用相关的类型差异。为此，我们提出了 M2C，一个形态感知的框架，用于 NLP 模型的行为测试。我们使用 M2C 生成测试，根据12种不同类型语言的特定语言特征来探测模型的行为。我们评估最先进的语言模型生成的测试。虽然模型在大多数英语测试中表现出色，但是我们强调的是对特定类型特征的概括性失败，例如斯瓦希里语的时间表达式和芬兰语的复合所有格。我们的研究结果促进了解决这些盲点的模型的发展。"
    },
    {
        "title": "ISLTranslate: Dataset for Translating Indian Sign Language",
        "url": "http://arxiv.org/abs/2307.05440v1",
        "pub_date": "2023-07-11",
        "summary": "Sign languages are the primary means of communication for many\nhard-of-hearing people worldwide. Recently, to bridge the communication gap\nbetween the hard-of-hearing community and the rest of the population, several\nsign language translation datasets have been proposed to enable the development\nof statistical sign language translation systems. However, there is a dearth of\nsign language resources for the Indian sign language. This resource paper\nintroduces ISLTranslate, a translation dataset for continuous Indian Sign\nLanguage (ISL) consisting of 31k ISL-English sentence/phrase pairs. To the best\nof our knowledge, it is the largest translation dataset for continuous Indian\nSign Language. We provide a detailed analysis of the dataset. To validate the\nperformance of existing end-to-end Sign language to spoken language translation\nsystems, we benchmark the created dataset with a transformer-based model for\nISL translation.",
        "translated": "手语是世界上许多重听人的主要交流方式。最近，为了弥补听力障碍群体和其他群体之间的沟通差距，一些手语翻译数据集已经被提出，以支持统计手语翻译系统的开发。然而，印度手语缺乏手语资源。本资源文章介绍了 ISLTranslate，一个由31kISL- 英语句子/短语对组成的连续印度手语(ISL)翻译数据集。据我们所知，它是最大的连续印度手语翻译数据集。我们提供了数据集的详细分析。为了验证现有端到端手语在口语翻译系统中的性能，我们使用基于转换器的 ISL 翻译模型对创建的数据集进行基准测试。"
    },
    {
        "title": "BLUEX: A benchmark based on Brazilian Leading Universities Entrance\n  eXams",
        "url": "http://arxiv.org/abs/2307.05410v1",
        "pub_date": "2023-07-11",
        "summary": "One common trend in recent studies of language models (LMs) is the use of\nstandardized tests for evaluation. However, despite being the fifth most spoken\nlanguage worldwide, few such evaluations have been conducted in Portuguese.\nThis is mainly due to the lack of high-quality datasets available to the\ncommunity for carrying out evaluations in Portuguese. To address this gap, we\nintroduce the Brazilian Leading Universities Entrance eXams (BLUEX), a dataset\nof entrance exams from the two leading universities in Brazil: UNICAMP and USP.\nThe dataset includes annotated metadata for evaluating the performance of NLP\nmodels on a variety of subjects. Furthermore, BLUEX includes a collection of\nrecently administered exams that are unlikely to be included in the training\ndata of many popular LMs as of 2023. The dataset is also annotated to indicate\nthe position of images in each question, providing a valuable resource for\nadvancing the state-of-the-art in multimodal language understanding and\nreasoning. We describe the creation and characteristics of BLUEX and establish\na benchmark through experiments with state-of-the-art LMs, demonstrating its\npotential for advancing the state-of-the-art in natural language understanding\nand reasoning in Portuguese. The data and relevant code can be found at\nhttps://github.com/Portuguese-Benchmark-Datasets/BLUEX",
        "translated": "最近语言模型研究的一个共同趋势是使用标准化测试进行评估。然而，尽管葡萄牙语是世界上第五大口语，但是很少用葡萄牙语进行这样的评估。这主要是由于社区缺乏用葡萄牙语进行评价的高质量数据集。为了弥补这一差距，我们引入了巴西一流大学入学考试(BLUEX) ，这是巴西两所一流大学(UnicAMP 和 USP)的入学考试数据集。该数据集包括评估 NLP 模型在各种主题上的性能的带注释的元数据。此外，BLUEX 还包括一系列最近实施的考试，到2023年，这些考试不太可能包括在许多流行的 LM 的培训数据中。该数据集还注释以指示图像在每个问题中的位置，为提高多模态语言理解和推理的最新水平提供了有价值的资源。我们描述了 BLUEX 的创建和特点，并通过最先进的 LM 实验建立了一个基准，展示了其在葡萄牙语自然语言理解和推理方面提高最先进水平的潜力。有关资料及密码可参阅 https://github.com/portuguese-benchmark-datasets/bluex"
    },
    {
        "title": "GujiBERT and GujiGPT: Construction of Intelligent Information Processing\n  Foundation Language Models for Ancient Texts",
        "url": "http://arxiv.org/abs/2307.05354v1",
        "pub_date": "2023-07-11",
        "summary": "In the context of the rapid development of large language models, we have\nmeticulously trained and introduced the GujiBERT and GujiGPT language models,\nwhich are foundational models specifically designed for intelligent information\nprocessing of ancient texts. These models have been trained on an extensive\ndataset that encompasses both simplified and traditional Chinese characters,\nallowing them to effectively handle various natural language processing tasks\nrelated to ancient books, including but not limited to automatic sentence\nsegmentation, punctuation, word segmentation, part-of-speech tagging, entity\nrecognition, and automatic translation. Notably, these models have exhibited\nexceptional performance across a range of validation tasks using publicly\navailable datasets. Our research findings highlight the efficacy of employing\nself-supervised methods to further train the models using classical text\ncorpora, thus enhancing their capability to tackle downstream tasks. Moreover,\nit is worth emphasizing that the choice of font, the scale of the corpus, and\nthe initial model selection all exert significant influence over the ultimate\nexperimental outcomes. To cater to the diverse text processing preferences of\nresearchers in digital humanities and linguistics, we have developed three\ndistinct categories comprising a total of nine model variations. We believe\nthat by sharing these foundational language models specialized in the domain of\nancient texts, we can facilitate the intelligent processing and scholarly\nexploration of ancient literary works and, consequently, contribute to the\nglobal dissemination of China's rich and esteemed traditional culture in this\nnew era.",
        "translated": "在大型语言模型快速发展的背景下，我们精心地训练和介绍了专门为古代文本智能信息处理而设计的基础模型——-古集 BERT 和古集 GPT 语言模型。这些模型已经在包括简体字和繁体字的大量数据集上进行了训练，使它们能够有效地处理与古籍有关的各种自然语言处理任务，包括但不限于自动句子分割、标点符号、分词、词性标注、实体识别和自动翻译。值得注意的是，这些模型在使用公开可用数据集的一系列验证任务中表现出了卓越的性能。我们的研究结果强调了使用自我监督方法进一步训练模型使用经典文本语料库的功效，从而提高他们处理下游任务的能力。此外，值得强调的是，字体的选择、语料库的规模和初始模型的选择都对最终的实验结果有显著的影响。为了满足数字人文学科和语言学研究者不同的文本处理偏好，我们开发了三个不同的类别，包括总共九个模型变体。我们相信，通过共享这些专门研究古代文本的基本语言模式，我们可以促进对古代文学作品的智能处理和学术探索，从而为新时期中国丰富而珍贵的传统文化在全球的传播做出贡献。"
    },
    {
        "title": "Explaining Competitive-Level Programming Solutions using LLMs",
        "url": "http://arxiv.org/abs/2307.05337v1",
        "pub_date": "2023-07-11",
        "summary": "In this paper, we approach competitive-level programming problem-solving as a\ncomposite task of reasoning and code generation. We propose a novel method to\nautomatically annotate natural language explanations to \\textit{&lt;problem,\nsolution&gt;} pairs. We show that despite poor performance in solving\ncompetitive-level programming problems, state-of-the-art LLMs exhibit a strong\ncapacity in describing and explaining solutions. Our explanation generation\nmethodology can generate a structured solution explanation for the problem\ncontaining descriptions and analysis. To evaluate the quality of the annotated\nexplanations, we examine their effectiveness in two aspects: 1) satisfying the\nhuman programming expert who authored the oracle solution, and 2) aiding LLMs\nin solving problems more effectively. The experimental results on the\nCodeContests dataset demonstrate that while LLM GPT3.5's and GPT-4's abilities\nin describing the solution are comparable, GPT-4 shows a better understanding\nof the key idea behind the solution.",
        "translated": "本文将竞争级规划问题的求解作为一个推理和代码生成的复合任务。我们提出了一种新的方法来自动注释自然语言的解释文本{ < 问题，解决方案 > }对。我们表明，尽管在解决竞争级别的规划问题方面表现不佳，但最先进的 LLM 在描述和解释解决方案方面表现出很强的能力。我们的解释生成方法可以为包含描述和分析的问题生成结构化的解决方案解释。为了评估注释解释的质量，我们从两个方面检查它们的有效性: 1)满足编写 Oracle 解决方案的人类编程专家的需求，2)帮助 LLM 更有效地解决问题。CodeContest 数据集上的实验结果表明，虽然 LLM GPT3.5和 GPT-4在描述解决方案方面的能力是可比的，但是 GPT-4更好地理解了解决方案背后的关键思想。"
    },
    {
        "title": "Unleashing Cognitive Synergy in Large Language Models: A Task-Solving\n  Agent through Multi-Persona Self-Collaboration",
        "url": "http://arxiv.org/abs/2307.05300v1",
        "pub_date": "2023-07-11",
        "summary": "Human intelligence thrives on the concept of cognitive synergy, where\ncollaboration and information integration among different cognitive processes\nyield superior outcomes compared to individual cognitive processes in\nisolation. Although Large Language Models (LLMs) have demonstrated promising\nperformance as general task-solving agents, they still struggle with tasks that\nrequire intensive domain knowledge and complex reasoning. In this work, we\npropose Solo Performance Prompting (SPP), which transforms a single LLM into a\ncognitive synergist by engaging in multi-turn self-collaboration with multiple\npersonas. A cognitive synergist refers to an intelligent agent that\ncollaborates with multiple minds, combining their individual strengths and\nknowledge, to enhance problem-solving and overall performance in complex tasks.\nBy dynamically identifying and simulating different personas based on task\ninputs, SPP unleashes the potential of cognitive synergy in LLMs. We have\ndiscovered that assigning multiple, fine-grained personas in LLMs elicits\nbetter problem-solving abilities compared to using a single or fixed number of\npersonas. We evaluate SPP on three challenging tasks: Trivia Creative Writing,\nCodenames Collaborative, and Logic Grid Puzzle, encompassing both\nknowledge-intensive and reasoning-intensive types. Unlike previous works, such\nas Chain-of-Thought, that solely enhance the reasoning abilities in LLMs, SPP\neffectively elicits internal knowledge acquisition abilities, reduces\nhallucination, and maintains strong reasoning capabilities. Code, data, and\nprompts can be found at:\nhttps://github.com/MikeWangWZHL/Solo-Performance-Prompting.git.",
        "translated": "人类的智力繁荣于认知协同的概念，其中不同认知过程之间的协作和信息整合产生了优于个体孤立的认知过程的结果。尽管大型语言模型(LLM)已经证明了作为通用任务解决代理具有良好的性能，但是它们仍然需要大量的领域知识和复杂的推理来完成任务。在这项工作中，我们提出了个人绩效激励(SPP) ，通过与多个人物角色进行多回合的自我协作，将单个 LLM 转化为一个认知协同器。认知协同主义是指智能代理人与多种思维协作，结合他们的个人优势和知识，以提高解决问题的能力和复杂任务的整体表现。通过基于任务输入动态识别和模拟不同的人物角色，SPP 释放了 LLM 中认知协同的潜力。我们发现，在 LLM 中分配多个细粒度的角色，与使用单个或固定数量的角色相比，可以获得更好的问题解决能力。我们评估 SPP 在三个具有挑战性的任务: 琐事创意写作，代号协作，和逻辑网格拼图，包括知识密集型和推理密集型。不像以前的作品，如思维链，单独增强 LLM 的推理能力，SPP 有效地引发内部知识获取能力，减少幻觉，并保持强大的推理能力。代码、数据和提示可以在以下 https://github.com/mikewangwzhl/solo-performance-prompting.git 找到。"
    },
    {
        "title": "Attribute Controlled Dialogue Prompting",
        "url": "http://arxiv.org/abs/2307.05228v1",
        "pub_date": "2023-07-11",
        "summary": "Prompt-tuning has become an increasingly popular parameter-efficient method\nfor adapting large pretrained language models to downstream tasks. However,\nboth discrete prompting and continuous prompting assume fixed prompts for all\ndata samples within a task, neglecting the fact that inputs vary greatly in\nsome tasks such as open-domain dialogue generation. In this paper, we present a\nnovel, instance-specific prompt-tuning algorithm for dialogue generation.\nSpecifically, we generate prompts based on instance-level control code, rather\nthan the conversation history, to explore their impact on controlled dialogue\ngeneration. Experiments on popular open-domain dialogue datasets, evaluated on\nboth automated metrics and human evaluation, demonstrate that our method is\nsuperior to prompting baselines and comparable to fine-tuning with only 5%-6%\nof total parameters.",
        "translated": "提示调优已成为一种日益流行的参数有效方法，用于调整大型预训练语言模型以适应下游任务。然而，离散提示和连续提示都假设一个任务中的所有数据样本都有固定的提示，而忽略了在某些任务中输入差异很大的事实，例如开放域对话生成。在本文中，我们提出了一个新颖的，特定于实例的对话生成提示调整算法。具体来说，我们基于实例级控制代码(而不是对话历史)生成提示，以探索它们对受控对话生成的影响。在流行的开放领域对话数据集上进行的实验表明，我们的方法优于提示基线，与总参数的5% -6% 的微调相当。"
    },
    {
        "title": "Mao-Zedong At SemEval-2023 Task 4: Label Represention Multi-Head\n  Attention Model With Contrastive Learning-Enhanced Nearest Neighbor Mechanism\n  For Multi-Label Text Classification",
        "url": "http://arxiv.org/abs/2307.05174v1",
        "pub_date": "2023-07-11",
        "summary": "The study of human values is essential in both practical and theoretical\ndomains. With the development of computational linguistics, the creation of\nlarge-scale datasets has made it possible to automatically recognize human\nvalues accurately. SemEval 2023 Task 4\\cite{kiesel:2023} provides a set of\narguments and 20 types of human values that are implicitly expressed in each\nargument. In this paper, we present our team's solution. We use the\nRoberta\\cite{liu_roberta_2019} model to obtain the word vector encoding of the\ndocument and propose a multi-head attention mechanism to establish connections\nbetween specific labels and semantic components. Furthermore, we use a\ncontrastive learning-enhanced K-nearest neighbor\nmechanism\\cite{su_contrastive_2022} to leverage existing instance information\nfor prediction. Our approach achieved an F1 score of 0.533 on the test set and\nranked fourth on the leaderboard.",
        "translated": "人类价值观的研究在实践和理论两个领域都是必不可少的。随着计算语言学技术的发展，大规模数据集的建立使得自动准确识别人类价值成为可能。SemEval 2023 Task 4 cite{ kiese: 2023}提供了一组参数和在每个参数中隐式表示的20种人工值。在本文中，我们提出了我们团队的解决方案。我们利用 Roberta 引用{ Liu _ Roberta _ 2019}模型获得文档的词向量编码，并提出了一种多头注意机制来建立特定标签与语义成分之间的联系。此外，我们使用一个对比学习增强的 K 最近邻机制引用{ su2022}来利用现有的实例信息进行预测。我们的方法在测试集上获得了0.533的 F1分数，在排行榜上排名第四。"
    },
    {
        "title": "Testing different Log Bases For Vector Model Weighting Technique",
        "url": "http://arxiv.org/abs/2307.06213v1",
        "pub_date": "2023-07-12",
        "summary": "Information retrieval systems retrieves relevant documents based on a query\nsubmitted by the user. The documents are initially indexed and the words in the\ndocuments are assigned weights using a weighting technique called TFIDF which\nis the product of Term Frequency (TF) and Inverse Document Frequency (IDF). TF\nrepresents the number of occurrences of a term in a document. IDF measures\nwhether the term is common or rare across all documents. It is computed by\ndividing the total number of documents in the system by the number of documents\ncontaining the term and then computing the logarithm of the quotient. By\ndefault, we use base 10 to calculate the logarithm. In this paper, we are going\nto test this weighting technique by using a range of log bases from 0.1 to\n100.0 to calculate the IDF. Testing different log bases for vector model\nweighting technique is to highlight the importance of understanding the\nperformance of the system at different weighting values. We use the documents\nof MED, CRAN, NPL, LISA, and CISI test collections that scientists assembled\nexplicitly for experiments in data information retrieval systems.",
        "translated": "信息检索系统根据用户提交的查询检索相关文件。文档最初被索引，文档中的单词通过一种称为 TFIDF 的加权技术被赋予权重，TFIDF 是术语频率(TF)和反向文档频率(IDF)的乘积。TF 表示一个术语在文档中出现的次数。以色列国防军衡量这个术语在所有文件中是常见还是罕见。它的计算方法是将系统中的文档总数除以包含该术语的文档数，然后计算商的对数。默认情况下，我们使用以10为基数来计算对数。在本文中，我们将测试这种加权技术，使用范围从0.1到100.0的对数基来计算 IDF。对矢量模型加权技术的不同测井基础进行测试，突出了了解不同加权值下系统性能的重要性。我们使用 MED、 CRAN、 NPL、 LISA 和 CISI 测试集的文档，这些文档是科学家们为了在数据信息检索系统中进行实验而明确收集的。"
    },
    {
        "title": "DDNAS: Discretized Differentiable Neural Architecture Search for Text\n  Classification",
        "url": "http://arxiv.org/abs/2307.06005v1",
        "pub_date": "2023-07-12",
        "summary": "Neural Architecture Search (NAS) has shown promising capability in learning\ntext representation. However, existing text-based NAS neither performs a\nlearnable fusion of neural operations to optimize the architecture, nor encodes\nthe latent hierarchical categorization behind text input. This paper presents a\nnovel NAS method, Discretized Differentiable Neural Architecture Search\n(DDNAS), for text representation learning and classification. With the\ncontinuous relaxation of architecture representation, DDNAS can use gradient\ndescent to optimize the search. We also propose a novel discretization layer\nvia mutual information maximization, which is imposed on every search node to\nmodel the latent hierarchical categorization in text representation. Extensive\nexperiments conducted on eight diverse real datasets exhibit that DDNAS can\nconsistently outperform the state-of-the-art NAS methods. While DDNAS relies on\nonly three basic operations, i.e., convolution, pooling, and none, to be the\ncandidates of NAS building blocks, its promising performance is noticeable and\nextensible to obtain further improvement by adding more different operations.",
        "translated": "神经结构搜索(NAS)在学习文本表示方面具有良好的应用前景。然而，现有的基于文本的 NAS 既没有执行可学习的神经操作融合来优化体系结构，也没有对文本输入背后潜在的层次分类进行编码。提出了一种新的用于文本表示学习和分类的 NAS 方法——离散可微神经结构搜索(DDNAS)。随着架构表示的不断放松，DDnAS 可以使用梯度下降法来优化搜索。提出了一种新的基于互信息最大化的离散化方法，该方法在每个搜索节点上对文本表示中的潜在层次分类进行建模。在八个不同的实际数据集上进行的大量实验表明，DDNAS 能够始终优于最先进的 NAS 方法。虽然 DDNAS 只依赖于三种基本操作，即卷积、池和无，作为 NAS 构建块的候选者，但是其有前途的性能是显而易见的，并且可以通过添加更多不同的操作来获得进一步的改进。"
    },
    {
        "title": "Contrastive Learning for Conversion Rate Prediction",
        "url": "http://arxiv.org/abs/2307.05974v1",
        "pub_date": "2023-07-12",
        "summary": "Conversion rate (CVR) prediction plays an important role in advertising\nsystems. Recently, supervised deep neural network-based models have shown\npromising performance in CVR prediction. However, they are data hungry and\nrequire an enormous amount of training data. In online advertising systems,\nalthough there are millions to billions of ads, users tend to click only a\nsmall set of them and to convert on an even smaller set. This data sparsity\nissue restricts the power of these deep models. In this paper, we propose the\nContrastive Learning for CVR prediction (CL4CVR) framework. It associates the\nsupervised CVR prediction task with a contrastive learning task, which can\nlearn better data representations exploiting abundant unlabeled data and\nimprove the CVR prediction performance. To tailor the contrastive learning task\nto the CVR prediction problem, we propose embedding masking (EM), rather than\nfeature masking, to create two views of augmented samples. We also propose a\nfalse negative elimination (FNE) component to eliminate samples with the same\nfeature as the anchor sample, to account for the natural property in user\nbehavior data. We further propose a supervised positive inclusion (SPI)\ncomponent to include additional positive samples for each anchor sample, in\norder to make full use of sparse but precious user conversion events.\nExperimental results on two real-world conversion datasets demonstrate the\nsuperior performance of CL4CVR. The source code is available at\nhttps://github.com/DongRuiHust/CL4CVR.",
        "translated": "转化率(CVR)预测在广告系统中起着重要作用。近年来，基于监督深层神经网络的 CVR 预测模型在 CVR 预测中表现出了良好的性能。然而，它们需要大量的数据，并且需要大量的训练数据。在在线广告系统中，尽管有数百万到数十亿的广告，用户往往只点击其中的一小部分，然后转换成更小的一部分。这种数据稀疏问题限制了这些深度模型的能力。本文提出了 CVR 预测的对比学习(CL4CVR)框架。该方法将有监督的 CVR 预测任务与对比学习任务相结合，利用大量未标记数据学习更好的数据表示，提高 CVR 预测性能。为了使对比学习任务适合于 CVR 预测问题，我们提出了嵌入掩蔽(EM)方法，而不是特征掩蔽方法，来创建增广样本的两个视图。我们还提出了一个假阴性消除(FNE)组件来消除具有与锚样本相同特征的样本，以解释用户行为数据的自然属性。我们进一步提出了一个监督正包含(SPI)组件，为每个锚样本包含额外的正样本，以充分利用稀疏但宝贵的用户转换事件。在两个实际转换数据集上的实验结果表明，CL4CVR 具有较好的性能。源代码可在 https://github.com/dongruihust/cl4cvr 下载。"
    },
    {
        "title": "Relational Extraction on Wikipedia Tables using Convolutional and Memory\n  Networks",
        "url": "http://arxiv.org/abs/2307.05827v1",
        "pub_date": "2023-07-11",
        "summary": "Relation extraction (RE) is the task of extracting relations between entities\nin text. Most RE methods extract relations from free-form running text and\nleave out other rich data sources, such as tables. We explore RE from the\nperspective of applying neural methods on tabularly organized data. We\nintroduce a new model consisting of Convolutional Neural Network (CNN) and\nBidirectional-Long Short Term Memory (BiLSTM) network to encode entities and\nlearn dependencies among them, respectively. We evaluate our model on a large\nand recent dataset and compare results with previous neural methods.\nExperimental results show that our model consistently outperforms the previous\nmodel for the task of relation extraction on tabular data. We perform\ncomprehensive error analyses and ablation study to show the contribution of\nvarious components of our model. Finally, we discuss the usefulness and\ntrade-offs of our approach, and provide suggestions for fostering further\nresearch.",
        "translated": "关系抽取是提取文本中实体之间的关系。大多数 RE 方法从自由格式的运行文本中提取关系，而忽略其他丰富的数据源，如表。我们从神经学方法应用于表格组织数据的角度探讨了 RE。我们引入了一个新的模型，它由卷积神经网络(CNN)和双向长期记忆(biLSTM)网络组成，分别对实体进行编码和学习它们之间的依赖关系。我们评估我们的模型在一个大型和最近的数据集，并比较结果与以前的神经方法。实验结果表明，该模型在表格数据的关系抽取任务上优于前一模型。我们进行了全面的误差分析和烧蚀研究，以显示我们的模型的各个组成部分的贡献。最后，我们讨论了我们的方法的有用性和权衡，并为促进进一步的研究提供建议。"
    },
    {
        "title": "Instruction Mining: High-Quality Instruction Data Selection for Large\n  Language Models",
        "url": "http://arxiv.org/abs/2307.06290v1",
        "pub_date": "2023-07-12",
        "summary": "Large language models typically undergo two training stages, pretraining and\nfinetuning. Despite that large-scale pretraining endows the model with strong\ncapabilities to generate natural language responses, these pretrained models\ncan still fail to understand human instructions at times. To enhance language\nmodels' ability of interpreting and responding to instructions, instruction\nfinetuning has emerged as a critical method in this area. Recent studies found\nthat large language models can be finetuned to perform well even with a small\namount of high-quality instruction-following data. However, the selection of\nhigh-quality datasets for finetuning language models still lacks clear\nguidelines to follow. In this paper, we propose InstructMining, a linear rule\nfor evaluating instruction-following data quality. We formulate InstructMining\nusing specific natural language indicators. To investigate the relationship\nbetween data quality and these indicators, we further conduct extensive\nfinetuning experiments. The experiment results are then applied to estimating\nparameters in InstructMining. To further investigate its performance, we use\nInstructMining to select high-quality data from unseen datasets. Results\ndemonstrate that InstructMining can help select relatively high-quality samples\nfrom various instruction-following datasets. Compared to models finetuned on\nunfiltered datasets, models finetuned on InstructMining selected datasets\nperform better on 42.5% cases.",
        "translated": "大型语言模型通常经历两个训练阶段，预训练和微调。尽管大规模的预训练赋予模型强大的能力来产生自然语言的反应，这些预训练的模型有时仍然不能理解人的指令。为了提高语言模型的口译能力和对指令的反应能力，指令微调已经成为这一领域的一种重要方法。最近的研究发现，即使使用少量高质量的指令跟踪数据，大型语言模型也可以进行微调，从而表现良好。然而，为微调语言模型选择高质量的数据集仍然缺乏明确的指导方针。在这篇文章中，我们提出了一个评估指令跟踪数据质量的线性规则—— DirectMining。我们使用特定的自然语言指示符来表达 DirectMining。为了研究数据质量与这些指标之间的关系，我们进一步进行了广泛的微调实验。然后将实验结果应用于指令挖掘中的参数估计。为了进一步研究它的性能，我们使用 DirectMining 从不可见的数据集中选择高质量的数据。实验结果表明，指令挖掘可以帮助从各种指令跟踪数据集中选择相对高质量的样本。与未经过滤数据集微调的模型相比，在 DirectMining 选择的数据集上微调的模型在42.5% 的情况下表现更好。"
    },
    {
        "title": "MMBench: Is Your Multi-modal Model an All-around Player?",
        "url": "http://arxiv.org/abs/2307.06281v1",
        "pub_date": "2023-07-12",
        "summary": "Large vision-language models have recently achieved remarkable progress,\nexhibiting great perception and reasoning abilities concerning visual\ninformation. However, how to effectively evaluate these large vision-language\nmodels remains a major obstacle, hindering future model development.\nTraditional benchmarks like VQAv2 or COCO Caption provide quantitative\nperformance measurements but suffer from a lack of fine-grained ability\nassessment and non-robust evaluation metrics. Recent subjective benchmarks,\nsuch as OwlEval, offer comprehensive evaluations of a model's abilities by\nincorporating human labor, but they are not scalable and display significant\nbias. In response to these challenges, we propose MMBench, a novel\nmulti-modality benchmark. MMBench methodically develops a comprehensive\nevaluation pipeline, primarily comprised of two elements. The first element is\na meticulously curated dataset that surpasses existing similar benchmarks in\nterms of the number and variety of evaluation questions and abilities. The\nsecond element introduces a novel CircularEval strategy and incorporates the\nuse of ChatGPT. This implementation is designed to convert free-form\npredictions into pre-defined choices, thereby facilitating a more robust\nevaluation of the model's predictions. MMBench is a systematically-designed\nobjective benchmark for robustly evaluating the various abilities of\nvision-language models. We hope MMBench will assist the research community in\nbetter evaluating their models and encourage future advancements in this\ndomain. Project page: https://opencompass.org.cn/mmbench.",
        "translated": "大型视觉语言模型近年来取得了显著的进展，显示出对视觉信息具有很强的感知和推理能力。然而，如何有效地评估这些大型视觉语言模型仍然是一个主要障碍，阻碍了未来模型的发展。像 VQAv2或 COCO Caption 这样的传统基准提供了定量的性能度量，但是缺乏细粒度的能力评估和不健壮的评估指标。最近的主观基准，例如 OwlEval，通过整合人工劳动，提供了对模型能力的全面评估，但是它们不可扩展，并且显示出明显的偏差。针对这些挑战，我们提出 MMBench，一个新颖的多模态基准。MMBench 有条不紊地开发了一个全面的评估管道，主要由两个要素组成。第一个要素是一个精心策划的数据集，它在评估问题和能力的数量和多样性方面超越了现有的类似基准。第二个元素引入了一个新的 CircularEval 策略，并结合了 ChatGPT 的使用。该实现旨在将自由形式的预测转换为预定义的选择，从而促进对模型预测的更强大的评估。MMBench 是一个系统设计的客观基准，用于稳健地评估视觉语言模型的各种能力。我们希望 MMBench 将帮助研究团体更好地评估他们的模型，并鼓励未来在这个领域的进步。项目主页:  https://opencompass.org.cn/mmbench。"
    },
    {
        "title": "Ashaar: Automatic Analysis and Generation of Arabic Poetry Using Deep\n  Learning Approaches",
        "url": "http://arxiv.org/abs/2307.06218v1",
        "pub_date": "2023-07-12",
        "summary": "Poetry holds immense significance within the cultural and traditional fabric\nof any nation. It serves as a vehicle for poets to articulate their emotions,\npreserve customs, and convey the essence of their culture. Arabic poetry is no\nexception, having played a cherished role in the heritage of the Arabic\ncommunity throughout history and maintaining its relevance in the present era.\nTypically, comprehending Arabic poetry necessitates the expertise of a linguist\nwho can analyze its content and assess its quality. This paper presents the\nintroduction of a framework called \\textit{Ashaar}\nhttps://github.com/ARBML/Ashaar, which encompasses a collection of datasets and\npre-trained models designed specifically for the analysis and generation of\nArabic poetry. The pipeline established within our proposed approach\nencompasses various aspects of poetry, such as meter, theme, and era\nclassification. It also incorporates automatic poetry diacritization, enabling\nmore intricate analyses like automated extraction of the \\textit{Arudi} style.\nAdditionally, we explore the feasibility of generating conditional poetry\nthrough the pre-training of a character-based GPT model. Furthermore, as part\nof this endeavor, we provide four datasets: one for poetry generation, another\nfor diacritization, and two for Arudi-style prediction. These datasets aim to\nfacilitate research and development in the field of Arabic poetry by enabling\nresearchers and enthusiasts to delve into the nuances of this rich literary\ntradition.",
        "translated": "诗歌在任何民族的文化和传统结构中都具有巨大的意义。它是诗人表达情感、维护风俗、传达文化精髓的工具。阿拉伯诗歌也不例外，它在整个历史过程中在阿拉伯社会的遗产中发挥了宝贵的作用，并在当今时代保持了其相关性。通常，理解阿拉伯诗歌需要语言学家的专业知识谁可以分析其内容和评估其质量。本文介绍了一个名为 textit { Ashaar } https://github.com/arbml/Ashaar 的框架，该框架包括一系列数据集和预先训练的模型，这些模型专门用于分析和生成阿拉伯诗歌。在我们提议的方法中建立的管道包括诗歌的各个方面，例如节拍、主题和时代分类。它还集成了自动诗歌变位，使更复杂的分析，如自动提取的文本{ Arudi }风格。此外，我们还探讨了通过基于字符的 GPT 模型的预训练生成条件诗的可行性。此外，作为这项工作的一部分，我们提供了四个数据集: 一个用于诗歌生成，另一个用于变位，两个用于 Arudi 风格的预测。这些数据集旨在促进阿拉伯诗歌领域的研究和发展，使研究人员和爱好者能够深入研究这一丰富的文学传统的细微差别。"
    },
    {
        "title": "Self-Adaptive Large Language Model (LLM)-Based Multiagent Systems",
        "url": "http://arxiv.org/abs/2307.06187v1",
        "pub_date": "2023-07-12",
        "summary": "In autonomic computing, self-adaptation has been proposed as a fundamental\nparadigm to manage the complexity of multiagent systems (MASs). This achieved\nby extending a system with support to monitor and adapt itself to achieve\nspecific concerns of interest. Communication in these systems is key given that\nin scenarios involving agent interaction, it enhances cooperation and reduces\ncoordination challenges by enabling direct, clear information exchange.\nHowever, improving the expressiveness of the interaction communication with\nMASs is not without challenges. In this sense, the interplay between\nself-adaptive systems and effective communication is crucial for future MAS\nadvancements. In this paper, we propose the integration of large language\nmodels (LLMs) such as GPT-based technologies into multiagent systems. We anchor\nour methodology on the MAPE-K model, which is renowned for its robust support\nin monitoring, analyzing, planning, and executing system adaptations in\nresponse to dynamic environments. We also present a practical illustration of\nthe proposed approach, in which we implement and assess a basic MAS-based\napplication. The approach significantly advances the state-of-the-art of\nself-adaptive systems by proposing a new paradigm for MAS self-adaptation of\nautonomous systems based on LLM capabilities.",
        "translated": "在自主计算中，自适应已被提出作为管理多智能体系统(MAS)复杂性的一个基本范式。这是通过扩大一个系统，并辅之以监测和调整系统，以实现人们关心的具体问题而实现的。这些系统中的通信非常关键，因为在涉及代理交互的场景中，通过实现直接、清晰的信息交换，它可以增强合作并减少协调方面的挑战。然而，提高与 MAS 交互沟通的表达能力并非没有挑战。从这个意义上说，自适应系统和有效通信之间的相互作用对未来 MAS 的发展至关重要。本文提出了将基于 GPT 技术的大型语言模型(LLM)集成到多智能体系统中。我们将我们的方法锚定在 MAPE-K 模型上，该模型以其在监视、分析、规划和执行响应动态环境的系统适应性方面的强大支持而闻名。我们还提出了一个实际的例子，提出的方法，其中我们实施和评估的基本 MAS 的应用程序。该方法提出了一种基于 LLM 能力的自适应系统 MAS 自适应新范式，极大地推动了自适应系统的发展。"
    },
    {
        "title": "Enhancing Portuguese Sign Language Animation with Dynamic Timing and\n  Mouthing",
        "url": "http://arxiv.org/abs/2307.06124v1",
        "pub_date": "2023-07-12",
        "summary": "Current signing avatars are often described as unnatural as they cannot\naccurately reproduce all the subtleties of synchronized body behaviors of a\nhuman signer. In this paper, we propose a new dynamic approach for transitions\nbetween signs, focusing on mouthing animations for Portuguese Sign Language.\nAlthough native signers preferred animations with dynamic transitions, we did\nnot find significant differences in comprehension and perceived naturalness\nscores. On the other hand, we show that including mouthing behaviors improved\ncomprehension and perceived naturalness for novice sign language learners.\nResults have implications in computational linguistics, human-computer\ninteraction, and synthetic animation of signing avatars.",
        "translated": "目前的签名化身往往被描述为不自然的，因为他们不能准确地再现所有细微的同步身体行为的人类签名。在本文中，我们提出了一个新的动态方法之间的转换，符号，重点是口型动画的葡萄牙手语。尽管本地签名者更喜欢动态过渡的动画，但是我们没有发现理解和感知自然性得分的显著差异。另一方面，我们表明，包括口语行为提高了理解和感知自然的新手手语学习者。结果对于签名化身的计算语言学、人机交互和合成动画都有意义。"
    },
    {
        "title": "VELMA: Verbalization Embodiment of LLM Agents for Vision and Language\n  Navigation in Street View",
        "url": "http://arxiv.org/abs/2307.06082v1",
        "pub_date": "2023-07-12",
        "summary": "Incremental decision making in real-world environments is one of the most\nchallenging tasks in embodied artificial intelligence. One particularly\ndemanding scenario is Vision and Language Navigation~(VLN) which requires\nvisual and natural language understanding as well as spatial and temporal\nreasoning capabilities. The embodied agent needs to ground its understanding of\nnavigation instructions in observations of a real-world environment like Street\nView. Despite the impressive results of LLMs in other research areas, it is an\nongoing problem of how to best connect them with an interactive visual\nenvironment. In this work, we propose VELMA, an embodied LLM agent that uses a\nverbalization of the trajectory and of visual environment observations as\ncontextual prompt for the next action. Visual information is verbalized by a\npipeline that extracts landmarks from the human written navigation instructions\nand uses CLIP to determine their visibility in the current panorama view. We\nshow that VELMA is able to successfully follow navigation instructions in\nStreet View with only two in-context examples. We further finetune the LLM\nagent on a few thousand examples and achieve 25%-30% relative improvement in\ntask completion over the previous state-of-the-art for two datasets.",
        "translated": "现实环境中的增量决策是体现人工智能中最具挑战性的任务之一。一个特别严格的场景是视觉和语言导航 ~ (VLN) ，它需要视觉和自然语言理解以及空间和时间推理能力。嵌入式代理需要将其对导航指令的理解建立在对街景等现实环境的观察之上。尽管 LLM 在其他研究领域取得了令人印象深刻的成果，但如何最好地将它们与交互式视觉环境联系起来仍然是一个持续存在的问题。在这项工作中，我们提出 VELMA，一个具体的 LLM 代理，使用语言化的轨迹和视觉环境观察作为上下文提示的下一个行动。视觉信息通过管道进行语言化，该管道从人工编写的导航指令中提取地标，并使用 CLIP 确定它们在当前全景视图中的可见性。我们展示了 VELMA 能够成功地遵循街景中的导航说明，只有两个上下文示例。我们在几千个例子中进一步调整 LLM 代理，在两个数据集的任务完成方面比先前的最先进水平提高了25% -30% 。"
    },
    {
        "title": "Interpreting deep embeddings for disease progression clustering",
        "url": "http://arxiv.org/abs/2307.06060v1",
        "pub_date": "2023-07-12",
        "summary": "We propose a novel approach for interpreting deep embeddings in the context\nof patient clustering. We evaluate our approach on a dataset of participants\nwith type 2 diabetes from the UK Biobank, and demonstrate clinically meaningful\ninsights into disease progression patterns.",
        "translated": "我们提出了一种新的方法来解释病人聚类背景下的深嵌入。我们对来自英国生物库的2型糖尿病参与者的数据集进行评估，并证明对疾病进展模式有临床意义的见解。"
    },
    {
        "title": "A Study on the Appropriate size of the Mongolian general corpus",
        "url": "http://arxiv.org/abs/2307.06050v1",
        "pub_date": "2023-07-12",
        "summary": "This study aims to determine the appropriate size of the Mongolian general\ncorpus. This study used the Heaps function and Type Token Ratio to determine\nthe appropriate size of the Mongolian general corpus. The sample corpus of\n906,064 tokens comprised texts from 10 domains of newspaper politics, economy,\nsociety, culture, sports, world articles and laws, middle and high school\nliterature textbooks, interview articles, and podcast transcripts. First, we\nestimated the Heaps function with this sample corpus. Next, we observed changes\nin the number of types and TTR values while increasing the number of tokens by\none million using the estimated Heaps function. As a result of observation, we\nfound that the TTR value hardly changed when the number of tokens exceeded from\n39 to 42 million. Thus, we conclude that an appropriate size for a Mongolian\ngeneral corpus is from 39 to 42 million tokens.",
        "translated": "本研究旨在确定蒙古语一般语料库的适当大小。本研究利用堆积函数和类型标记比率来确定蒙古语一般语料库的适当大小。906,064个令牌的样本语料库包括来自报纸政治，经济，社会，文化，体育，世界文章和法律，中学和高中文学教科书，访谈文章和播客成绩单的10个领域的文本。首先，我们利用这个样本语料库对堆函数进行了估计。接下来，我们观察到类型数量和 TTR 值的变化，同时使用估计的 Heaps 函数将令牌数量增加100万。通过观察，我们发现当令牌数量超过3900万个到4200万个时，TTR 值几乎没有变化。因此，我们得出结论，适当的大小为一个蒙古语一般语料库是从3900万至4200万令牌。"
    },
    {
        "title": "Pluggable Neural Machine Translation Models via Memory-augmented\n  Adapters",
        "url": "http://arxiv.org/abs/2307.06029v1",
        "pub_date": "2023-07-12",
        "summary": "Although neural machine translation (NMT) models perform well in the general\ndomain, it remains rather challenging to control their generation behavior to\nsatisfy the requirement of different users. Given the expensive training cost\nand the data scarcity challenge of learning a new model from scratch for each\nuser requirement, we propose a memory-augmented adapter to steer pretrained NMT\nmodels in a pluggable manner. Specifically, we construct a multi-granular\nmemory based on the user-provided text samples and propose a new adapter\narchitecture to combine the model representations and the retrieved results. We\nalso propose a training strategy using memory dropout to reduce spurious\ndependencies between the NMT model and the memory. We validate our approach on\nboth style- and domain-specific experiments and the results indicate that our\nmethod can outperform several representative pluggable baselines.",
        "translated": "尽管神经机器翻译(NMT)模型在一般领域表现良好，但是要控制它们的生成行为以满足不同用户的需求仍然是一个相当具有挑战性的问题。考虑到昂贵的培训成本和从头学习新模型以满足每个用户需求的数据稀缺性挑战，我们提出了一种内存增强适配器来以可插入的方式引导预先训练的 NMT 模型。具体来说，我们基于用户提供的文本样本构造了一个多粒度存储器，并提出了一种新的适配器结构来组合模型表示和检索结果。我们还提出了一种使用内存丢失的训练策略，以减少 NMT 模型与内存之间的虚假依赖。我们验证了我们的方法的风格和领域特定的实验和结果表明，我们的方法可以优于几个代表性的可插基线。"
    },
    {
        "title": "PolyLM: An Open Source Polyglot Large Language Model",
        "url": "http://arxiv.org/abs/2307.06018v1",
        "pub_date": "2023-07-12",
        "summary": "Large language models (LLMs) demonstrate remarkable ability to comprehend,\nreason, and generate following nature language instructions. However, the\ndevelopment of LLMs has been primarily focused on high-resource languages, such\nas English, thereby limiting their applicability and research in other\nlanguages. Consequently, we present PolyLM, a multilingual LLM trained on 640\nbillion (B) tokens, avaliable in two model sizes: 1.7B and 13B. To enhance its\nmultilingual capabilities, we 1) integrate bilingual data into training data;\nand 2) adopt a curriculum learning strategy that increases the proportion of\nnon-English data from 30% in the first stage to 60% in the final stage during\npre-training. Further, we propose a multilingual self-instruct method which\nautomatically generates 132.7K diverse multilingual instructions for model\nfine-tuning. To assess the model's performance, we collect several existing\nmultilingual tasks, including multilingual understanding, question answering,\ngeneration, and translation. Extensive experiments show that PolyLM surpasses\nother open-source models such as LLaMA and BLOOM on multilingual tasks while\nmaintaining comparable performance in English. Our models, alone with the\ninstruction data and multilingual benchmark, are available at:\n\\url{https://modelscope.cn/models/damo/nlp_polylm_13b_text_generation}.",
        "translated": "大型语言模型(LLM)具有非凡的理解、推理和生成自然语言指令的能力。然而，LLM 的发展主要集中在高资源语言上，如英语，从而限制了它们在其他语言中的适用性和研究。因此，我们提出 PolyLM，一个在6400亿(B)令牌上训练的多语言 LLM，可用于两种模型大小: 1.7 B 和13B。为加强其多语文能力，我们(1)将双语资料融入培训资料; 及(2)采用课程学习策略，在培训前期间，将非英语资料的比例由第一阶段的30% 增至最后阶段的60% 。进一步，我们提出了一种多语言自指令方法，它可以自动生成132.7 K 不同的多语言指令用于模型微调。为了评估模型的性能，我们收集了一些现有的多语言任务，包括多语言理解、问题回答、生成和翻译。大量实验表明，PolyLM 在多语言任务方面超过了其他开源模型，如 LLaMA 和 BLOOM，同时在英语方面保持了可比性。我们的模型，连同指令数据和多语言基准，可以在 url { https://modelscope.cn/models/damo/nlp_polylm_13b_text_generation }下载。"
    },
    {
        "title": "Parmesan: mathematical concept extraction for education",
        "url": "http://arxiv.org/abs/2307.06699v1",
        "pub_date": "2023-07-13",
        "summary": "Mathematics is a highly specialized domain with its own unique set of\nchallenges that has seen limited study in natural language processing. However,\nmathematics is used in a wide variety of fields and multidisciplinary research\nin many different domains often relies on an understanding of mathematical\nconcepts. To aid researchers coming from other fields, we develop a prototype\nsystem for searching for and defining mathematical concepts in context,\nfocusing on the field of category theory. This system, Parmesan, depends on\nnatural language processing components including concept extraction, relation\nextraction, definition extraction, and entity linking. In developing this\nsystem, we show that existing techniques cannot be applied directly to the\ncategory theory domain, and suggest hybrid techniques that do perform well,\nthough we expect the system to evolve over time. We also provide two cleaned\nmathematical corpora that power the prototype system, which are based on\njournal articles and wiki pages, respectively. The corpora have been annotated\nwith dependency trees, lemmas, and part-of-speech tags.",
        "translated": "数学是一个高度专业化的领域，它有自己独特的一套挑战，在自然语言处理方面的研究有限。然而，数学被广泛应用于各种领域，许多不同领域的多学科研究往往依赖于对数学概念的理解。为了帮助来自其他领域的研究人员，我们开发了一个在语境中搜索和定义数学概念的原型系统，侧重于范畴理论领域。该系统依赖于自然语言处理组件，包括概念提取、关系提取、定义提取和实体链接。在开发这个系统的过程中，我们发现现有的技术不能直接应用于范畴理论领域，并建议使用混合技术，尽管我们预计系统会随着时间的推移而发展。我们还提供了两个清洁的数学语料库，为原型系统提供动力，它们分别基于期刊文章和维基页面。语料库已经用依赖树、引理和词性标签进行了注释。"
    },
    {
        "title": "Going Beyond Local: Global Graph-Enhanced Personalized News\n  Recommendations",
        "url": "http://arxiv.org/abs/2307.06576v1",
        "pub_date": "2023-07-13",
        "summary": "Precisely recommending candidate news articles to users has always been a\ncore challenge for personalized news recommendation systems. Most recent works\nprimarily focus on using advanced natural language processing techniques to\nextract semantic information from rich textual data, employing content-based\nmethods derived from local historical news. However, this approach lacks a\nglobal perspective, failing to account for users' hidden motivations and\nbehaviors beyond semantic information. To address this challenge, we propose a\nnovel model called GLORY (Global-LOcal news Recommendation sYstem), which\ncombines global representations learned from other users with local\nrepresentations to enhance personalized recommendation systems. We accomplish\nthis by constructing a Global-aware Historical News Encoder, which includes a\nglobal news graph and employs gated graph neural networks to enrich news\nrepresentations, thereby fusing historical news representations by a historical\nnews aggregator. Similarly, we extend this approach to a Global Candidate News\nEncoder, utilizing a global entity graph and a candidate news aggregator to\nenhance candidate news representation. Evaluation results on two public news\ndatasets demonstrate that our method outperforms existing approaches.\nFurthermore, our model offers more diverse recommendations.",
        "translated": "准确地向用户推荐候选新闻一直是个性化新闻推荐系统的核心挑战。最近的作品主要集中在使用先进的自然语言处理技术从丰富的文本数据中提取语义信息，采用基于内容的方法从本地历史新闻中获取信息。然而，这种方法缺乏全局视角，没有考虑到用户隐藏的动机和超出语义信息的行为。为了应对这一挑战，我们提出了一种新的模型，即全球-本地新闻推荐系统，它将从其他用户那里学到的全球表示与本地表示结合起来，以增强个性化推荐系统。我们通过构建一个全球感知的历史新闻编码器来实现这一点，该编码器包括一个全球新闻图，并使用门限图神经网络来丰富新闻表示，从而通过一个历史新闻聚合器融合历史新闻表示。类似地，我们将此方法扩展到全局候选新闻编码器，利用全局实体图和候选新闻聚合器来增强候选新闻表示。对两个公共新闻数据集的评估结果表明，该方法的性能优于现有方法。此外，我们的模型提供了更多样化的建议。"
    },
    {
        "title": "Assessing the Ability of ChatGPT to Screen Articles for Systematic\n  Reviews",
        "url": "http://arxiv.org/abs/2307.06464v1",
        "pub_date": "2023-07-12",
        "summary": "By organizing knowledge within a research field, Systematic Reviews (SR)\nprovide valuable leads to steer research. Evidence suggests that SRs have\nbecome first-class artifacts in software engineering. However, the tedious\nmanual effort associated with the screening phase of SRs renders these studies\na costly and error-prone endeavor. While screening has traditionally been\nconsidered not amenable to automation, the advent of generative AI-driven\nchatbots, backed with large language models is set to disrupt the field. In\nthis report, we propose an approach to leverage these novel technological\ndevelopments for automating the screening of SRs. We assess the consistency,\nclassification performance, and generalizability of ChatGPT in screening\narticles for SRs and compare these figures with those of traditional\nclassifiers used in SR automation. Our results indicate that ChatGPT is a\nviable option to automate the SR processes, but requires careful considerations\nfrom developers when integrating ChatGPT into their SR tools.",
        "translated": "通过组织研究领域内的知识，系统评价(SR)为指导研究提供了有价值的线索。有证据表明，SR 已经成为软件工程中的一流工件。然而，与 SR 筛选阶段相关的繁琐的手工工作使得这些研究成本高昂且容易出错。虽然筛选传统上被认为不适合自动化，生成式人工智能驱动的聊天机器人的出现，大型语言模型的支持，将颠覆这一领域。在这份报告中，我们提出了一种方法，利用这些新的技术发展，自动筛选的 SR。我们评估了用于 SR 筛选文章的 ChatGPT 的一致性、分类性能和普遍性，并将这些数字与 SR 自动化中使用的传统分类器的数字进行了比较。我们的研究结果表明 ChatGPT 是自动化 SR 过程的可行选择，但是在将 ChatGPT 集成到 SR 工具中时需要开发人员仔细考虑。"
    },
    {
        "title": "In-context Autoencoder for Context Compression in a Large Language Model",
        "url": "http://arxiv.org/abs/2307.06945v1",
        "pub_date": "2023-07-13",
        "summary": "We propose the In-context Autoencoder (ICAE) for context compression in a\nlarge language model (LLM). The ICAE has two modules: a learnable encoder\nadapted with LoRA from an LLM for compressing a long context into a limited\nnumber of memory slots, and a fixed decoder which is the target LLM that can\ncondition on the memory slots for various purposes. We first pretrain the ICAE\nusing both autoencoding and language modeling objectives on massive text data,\nenabling it to generate memory slots that accurately and comprehensively\nrepresent the original context. Then, we fine-tune the pretrained ICAE on a\nsmall amount of instruct data to enhance its interaction with various prompts\nfor producing desirable responses. Our experimental results demonstrate that\nthe ICAE learned with our proposed pretraining and fine-tuning paradigm can\neffectively produce memory slots with $4\\times$ context compression, which can\nbe well conditioned on by the target LLM to respond to various prompts. The\npromising results demonstrate significant implications of the ICAE for its\nnovel approach to the long context problem and its potential to reduce\ncomputation and memory overheads for LLM inference in practice, suggesting\nfurther research effort in context management for an LLM. Our code and data\nwill be released shortly.",
        "translated": "我们提出了在大型语言模型(LLM)中使用上下文自动编码器(ICAE)进行上下文压缩。ICAE 有两个模块: 一个是可学习的编码器，它使用一个 LLM 改装而成，用于将一个较长的上下文压缩成有限数量的存储槽; 另一个是固定的解码器，它是目标 LLM，可以根据不同的目的对存储槽进行调整。我们首先使用自动编码和语言建模目标对大量文本数据进行 ICAE 预训练，使其能够生成准确和全面地表示原始上下文的内存插槽。然后，我们在少量的指令数据上对预先训练的 ICAE 进行微调，以增强其与各种提示的交互作用，从而产生理想的响应。我们的实验结果表明，通过我们提出的预训练和微调范例学习的 ICAE 可以有效地产生4倍于 $context 压缩的记忆槽，这可以很好地由目标 LLM 来响应各种提示。这些令人鼓舞的研究结果显示了 ICAE 对于长上下文问题的新方法的重要意义，以及它在实践中减少长上下文推理的计算和内存开销的潜力，这表明了长上下文管理的进一步研究工作。我们的代码和数据很快就会公布。"
    },
    {
        "title": "mBLIP: Efficient Bootstrapping of Multilingual Vision-LLMs",
        "url": "http://arxiv.org/abs/2307.06930v1",
        "pub_date": "2023-07-13",
        "summary": "Modular vision-language models (Vision-LLMs) align pretrained image encoders\nwith (pretrained) large language models (LLMs), representing a computationally\nmuch more efficient alternative to end-to-end training of large vision-language\nmodels from scratch, which is prohibitively expensive for most. Vision-LLMs\ninstead post-hoc condition LLMs to `understand' the output of an image encoder.\nWith the abundance of readily available high-quality English image-text data as\nwell as monolingual English LLMs, the research focus has been on English-only\nVision-LLMs. Multilingual vision-language models are still predominantly\nobtained via expensive end-to-end pretraining, resulting in comparatively\nsmaller models, trained on limited multilingual image data supplemented with\ntext-only multilingual corpora. In this work, we present mBLIP, the first\nmultilingual Vision-LLM, which we obtain in a computationally efficient manner\n-- on consumer hardware using only a few million training examples -- by\nleveraging a pretrained multilingual LLM. To this end, we \\textit{re-align} an\nimage encoder previously tuned to an English LLM to a new, multilingual LLM --\nfor this, we leverage multilingual data from a mix of vision-and-language\ntasks, which we obtain by machine-translating high-quality English data to 95\nlanguages. On the IGLUE benchmark, mBLIP yields results competitive with\nstate-of-the-art models. Moreover, in image captioning on XM3600, mBLIP\n(zero-shot) even outperforms PaLI-X (a model with 55B parameters). Compared to\nthese very large multilingual vision-language models trained from scratch, we\nobtain mBLIP by training orders of magnitude fewer parameters on magnitudes\nless data. We release our model and code at\n\\url{https://github.com/gregor-ge/mBLIP}.",
        "translated": "模块化视觉语言模型(Vision-LLM)将预先训练的图像编码器与(预先训练的)大型语言模型(LLM)对齐，代表了从头开始对大型视觉语言模型进行端到端训练的计算效率更高的替代方案，这对大多数人来说是昂贵的。Vision-LLM 代替事后条件 LLM 来“理解”图像编码器的输出。随着大量高质量的英文图像文本数据以及单语种英语 LLM 的出现，研究的重点已经转移到了纯英语的 Vision LLM 上。多语言视觉语言模型仍然主要通过昂贵的端到端预训练获得，导致相对较小的模型，用有限的多语言图像数据补充文本多语言语料库进行训练。在这项工作中，我们介绍了 mBLIP，第一个多语言 Vision-LLM，我们通过利用预先训练好的多语言 LLM，在消费者硬件上使用几百万个训练例子，以计算效率高的方式获得它。为此，我们将一个先前调整为英语 LLM 的图像编码器发送给一个新的多语言 LLM ——为此，我们从视觉和语言任务的混合中利用多语言数据，我们通过机器将高质量的英语数据翻译成95种语言来获得这些数据。在 IGLUE 基准上，mBLIP 产生的结果与最先进的模型具有竞争力。此外，在 XM3600上的图像字幕中，mBLIP (零拍摄)甚至优于 Pali-X (一种具有55B 参数的模型)。与这些从头开始训练的非常大的多语言视觉语言模型相比，我们通过在更小的数据量上训练更少的参数来获得 mBLIP 数量级。我们在 url { https://github.com/gregor-ge/mblip }发布我们的模型和代码。"
    },
    {
        "title": "DRAGON: A Dialogue-Based Robot for Assistive Navigation with Visual\n  Language Grounding",
        "url": "http://arxiv.org/abs/2307.06924v1",
        "pub_date": "2023-07-13",
        "summary": "Persons with visual impairments (PwVI) have difficulties understanding and\nnavigating spaces around them. Current wayfinding technologies either focus\nsolely on navigation or provide limited communication about the environment.\nMotivated by recent advances in visual-language grounding and semantic\nnavigation, we propose DRAGON, a guiding robot powered by a dialogue system and\nthe ability to associate the environment with natural language. By\nunderstanding the commands from the user, DRAGON is able to guide the user to\nthe desired landmarks on the map, describe the environment, and answer\nquestions from visual observations. Through effective utilization of dialogue,\nthe robot can ground the user's free-form descriptions to landmarks in the\nenvironment, and give the user semantic information through spoken language. We\nconduct a user study with blindfolded participants in an everyday indoor\nenvironment. Our results demonstrate that DRAGON is able to communicate with\nthe user smoothly, provide a good guiding experience, and connect users with\ntheir surrounding environment in an intuitive manner.",
        "translated": "视觉障碍者(PwVI)在理解和导航周围空间方面存在困难。目前的导航技术要么只关注导航，要么只提供有限的环境信息。受视觉语言基础和语义导航技术的最新进展的启发，我们提出了一种基于对话系统和自然语言与环境关联能力的导航机器人 DRAON。通过理解来自用户的命令，DRAON 能够引导用户到达地图上所需的地标，描述环境，并回答来自视觉观察的问题。通过有效地利用对话，机器人可以将用户自由形式的描述基于环境中的地标，并通过口头语言赋予用户语义信息。我们在日常室内环境中对蒙眼的参与者进行用户研究。我们的研究结果表明，龙能够与用户顺利沟通，提供良好的指导体验，并连接用户与他们的周围环境在一个直观的方式。"
    },
    {
        "title": "LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT",
        "url": "http://arxiv.org/abs/2307.06917v1",
        "pub_date": "2023-07-13",
        "summary": "Knowledge Graphs (KG) provide us with a structured, flexible, transparent,\ncross-system, and collaborative way of organizing our knowledge and data across\nvarious domains in society and industrial as well as scientific disciplines.\nKGs surpass any other form of representation in terms of effectiveness.\nHowever, Knowledge Graph Engineering (KGE) requires in-depth experiences of\ngraph structures, web technologies, existing models and vocabularies, rule\nsets, logic, as well as best practices. It also demands a significant amount of\nwork. Considering the advancements in large language models (LLMs) and their\ninterfaces and applications in recent years, we have conducted comprehensive\nexperiments with ChatGPT to explore its potential in supporting KGE. In this\npaper, we present a selection of these experiments and their results to\ndemonstrate how ChatGPT can assist us in the development and management of KGs.",
        "translated": "知识图表为我们提供了一个结构化的、灵活的、透明的、跨系统的和协作的方式来组织我们在社会、工业和科学分支各个领域的知识和数据。就成效而言，幼稚园超越任何其他形式的代表。然而，知识图形工程(KGE)需要对图形结构、 Web 技术、现有模型和词汇、规则集、逻辑以及最佳实践有深入的了解。它还需要大量的工作。考虑到近年来大语言模型(LLM)及其接口和应用的发展，我们使用 ChatGPT 进行了全面的实验，以探索其在支持 KGE 方面的潜力。在本文中，我们提出了这些实验的选择和他们的结果，以说明如何 ChatGPT 可以帮助我们在幼儿园的发展和管理。"
    },
    {
        "title": "Generating Benchmarks for Factuality Evaluation of Language Models",
        "url": "http://arxiv.org/abs/2307.06908v1",
        "pub_date": "2023-07-13",
        "summary": "Before deploying a language model (LM) within a given domain, it is important\nto measure its tendency to generate factually incorrect information in that\ndomain. Existing factual generation evaluation methods focus on facts sampled\nfrom the LM itself, and thus do not control the set of evaluated facts and\nmight under-represent rare and unlikely facts. We propose FACTOR: Factual\nAssessment via Corpus TransfORmation, a scalable approach for evaluating LM\nfactuality. FACTOR automatically transforms a factual corpus of interest into a\nbenchmark evaluating an LM's propensity to generate true facts from the corpus\nvs. similar but incorrect statements. We use our framework to create two\nbenchmarks: Wiki-FACTOR and News-FACTOR. We show that: (i) our benchmark scores\nincrease with model size and improve when the LM is augmented with retrieval;\n(ii) benchmark score correlates with perplexity, but the two metrics do not\nalways agree on model ranking; and (iii) when perplexity and benchmark score\ndisagree, the latter better reflects factuality in open-ended generation, as\nmeasured by human annotators. We make our data and code publicly available in\nhttps://github.com/AI21Labs/factor.",
        "translated": "在给定领域中部署语言模型(LM)之前，测量它在该领域中生成事实上不正确的信息的趋势是非常重要的。现有的事实生成评估方法侧重于从长期管理本身取样的事实，因此不能控制被评估的事实集，可能会低估罕见和不可能的事实。我们提出因子: 通过语料库转换的事实评价，一个可扩展的方法来评价 LM 的事实。FACTOR 自动将感兴趣的事实语料库转换为一个基准，用于评估 LM 是否倾向于从语料库中生成真实事实，以及是否存在类似但不正确的语句。我们使用我们的框架来创建两个基准测试: Wiki-Factor 和 News-Factor。我们表明: (i)我们的基准分数随着模型大小增加而增加，并且当 LM 增加检索时提高; (ii)基准分数与困惑相关，但是两个指标并不总是在模型排名上达成一致; 和(iii)当困惑和基准分数不一致时，后者更好地反映了开放式代中的事实，如人类注释者所测量的。我们将我们的数据和代码以 https://github.com/ai21labs/factor 的形式公开。"
    },
    {
        "title": "DecompEval: Evaluating Generated Texts as Unsupervised Decomposed\n  Question Answering",
        "url": "http://arxiv.org/abs/2307.06869v1",
        "pub_date": "2023-07-13",
        "summary": "Existing evaluation metrics for natural language generation (NLG) tasks face\nthe challenges on generalization ability and interpretability. Specifically,\nmost of the well-performed metrics are required to train on evaluation datasets\nof specific NLG tasks and evaluation dimensions, which may cause over-fitting\nto task-specific datasets. Furthermore, existing metrics only provide an\nevaluation score for each dimension without revealing the evidence to interpret\nhow this score is obtained. To deal with these challenges, we propose a simple\nyet effective metric called DecompEval. This metric formulates NLG evaluation\nas an instruction-style question answering task and utilizes instruction-tuned\npre-trained language models (PLMs) without training on evaluation datasets,\naiming to enhance the generalization ability. To make the evaluation process\nmore interpretable, we decompose our devised instruction-style question about\nthe quality of generated texts into the subquestions that measure the quality\nof each sentence. The subquestions with their answers generated by PLMs are\nthen recomposed as evidence to obtain the evaluation result. Experimental\nresults show that DecompEval achieves state-of-the-art performance in untrained\nmetrics for evaluating text summarization and dialogue generation, which also\nexhibits strong dimension-level / task-level generalization ability and\ninterpretability.",
        "translated": "现有的自然语言生成(NLG)任务评估指标面临着泛化能力和可解释性的挑战。具体来说，大多数执行良好的指标都需要在特定 NLG 任务和评估维度的评估数据集上进行训练，这可能会导致对特定任务数据集的过度拟合。此外，现有的指标只提供每个维度的评估分数，而不显示证据来解释这个分数是如何获得的。为了应对这些挑战，我们提出了一个简单而有效的度量方法，称为 DecopEval。该指标将 NLG 评价定义为一种指令式的问答任务，利用指令调整的预训练语言模型(PLM) ，不对评价数据集进行训练，以提高泛化能力。为了使评估过程更易于理解，我们将我们设计的关于生成文本质量的教学风格问题分解为衡量每个句子质量的子问题。然后将 PLM 生成的子问题及其答案作为证据重新组合，以获得评估结果。实验结果表明，在未经训练的文本摘要和对话生成评估指标方面，该算法具有较强的维度/任务级泛化能力和可解释性。"
    },
    {
        "title": "Prompts Should not be Seen as Secrets: Systematically Measuring Prompt\n  Extraction Attack Success",
        "url": "http://arxiv.org/abs/2307.06865v1",
        "pub_date": "2023-07-13",
        "summary": "The generations of large language models are commonly controlled through\nprompting techniques, where a user's query to the model is prefixed with a\nprompt that aims to guide the model's behaviour on the query. The prompts used\nby companies to guide their models are often treated as secrets, to be hidden\nfrom the user making the query. They have even been treated as commodities to\nbe bought and sold. However, there has been anecdotal evidence showing that the\nprompts can be extracted by a user even when they are kept secret. In this\npaper, we present a framework for systematically measuring the success of\nprompt extraction attacks. In experiments with multiple sources of prompts and\nmultiple underlying language models, we find that simple text-based attacks can\nin fact reveal prompts with high probability.",
        "translated": "一代代的大型语言模型通常是通过提示技术来控制的，在用户对模型的查询前面加上一个提示，目的是指导模型在查询中的行为。公司用来指导他们的模型的提示通常被视为秘密，对于提出查询的用户来说是隐藏的。它们甚至被当作可以买卖的商品。然而，有轶事证据显示，即使提示是保密的，用户也可以提取它们。在本文中，我们提出了一个框架，系统地衡量成功的即时提取攻击。在多源提示和多底层语言模型的实验中，我们发现简单的基于文本的攻击实际上可以以很高的概率显示提示。"
    },
    {
        "title": "Personalization for BERT-based Discriminative Speech Recognition\n  Rescoring",
        "url": "http://arxiv.org/abs/2307.06832v1",
        "pub_date": "2023-07-13",
        "summary": "Recognition of personalized content remains a challenge in end-to-end speech\nrecognition. We explore three novel approaches that use personalized content in\na neural rescoring step to improve recognition: gazetteers, prompting, and a\ncross-attention based encoder-decoder model. We use internal de-identified\nen-US data from interactions with a virtual voice assistant supplemented with\npersonalized named entities to compare these approaches. On a test set with\npersonalized named entities, we show that each of these approaches improves\nword error rate by over 10%, against a neural rescoring baseline. We also show\nthat on this test set, natural language prompts can improve word error rate by\n7% without any training and with a marginal loss in generalization. Overall,\ngazetteers were found to perform the best with a 10% improvement in word error\nrate (WER), while also improving WER on a general test set by 1%.",
        "translated": "个性化内容的识别仍然是端到端语音识别中的一个挑战。我们探讨了三种新的方法，使用个性化内容的神经重建步骤，以提高识别: 地名录，提示，和交叉注意为基础的编码器-解码器模型。我们使用来自虚拟语音助手和个性化命名实体的交互的内部去识别的 en-US 数据来比较这些方法。在一个具有个性化命名实体的测试集中，我们表明，相对于神经评分基线，这些方法中的每一种都将单词错误率提高了10% 以上。我们还表明，在这个测试集上，自然语言提示可以提高7% 的错误率，没有任何训练，并在泛化的边际损失。总的来说，地名录表现最好，词语错误率(WER)提高了10% ，而一般测试集的 WER 也提高了1% 。"
    },
    {
        "title": "Negated Complementary Commonsense using Large Language Models",
        "url": "http://arxiv.org/abs/2307.06794v1",
        "pub_date": "2023-07-13",
        "summary": "Larger language models, such as GPT-3, have shown to be excellent in many\ntasks. However, we demonstrate that out-of-ordinary questions can throw the\nmodel off guard. This work focuses on finding answers to negated complementary\nquestions in commonsense scenarios. We illustrate how such questions adversely\naffect the model responses. We propose a model-agnostic methodology to improve\nthe performance in negated complementary scenarios. Our method outperforms\nfew-shot generation from GPT-3 (by more than 11 points) and, more importantly,\nhighlights the significance of studying the response of large language models\nin negated complementary questions. The code, data, and experiments are\navailable under: https://github.com/navidre/negated_complementary_commonsense.",
        "translated": "较大的语言模型，例如 GPT-3，已经证明在许多任务中表现出色。然而，我们证明了不寻常的问题可以使模型猝不及防。这项工作的重点是在常识情景下寻找否定的补充问题的答案。我们举例说明这些问题如何对模型响应产生不利影响。我们提出了一种模型无关的方法来提高在否定互补情景下的性能。我们的方法比 GPT-3的少镜头生成法(多11分)更有效，更重要的是，它突出了研究大语言模型在否定补语问题中的反应的意义。代码、数据和实验可以通过以下 https://github.com/navidre/negated_complementary_commonsense 获得:。"
    },
    {
        "title": "Why Guided Dialog Policy Learning performs well? Understanding the role\n  of adversarial learning and its alternative",
        "url": "http://arxiv.org/abs/2307.06721v1",
        "pub_date": "2023-07-13",
        "summary": "Dialog policies, which determine a system's action based on the current state\nat each dialog turn, are crucial to the success of the dialog. In recent years,\nreinforcement learning (RL) has emerged as a promising option for dialog policy\nlearning (DPL). In RL-based DPL, dialog policies are updated according to\nrewards. The manual construction of fine-grained rewards, such as\nstate-action-based ones, to effectively guide the dialog policy is challenging\nin multi-domain task-oriented dialog scenarios with numerous state-action pair\ncombinations. One way to estimate rewards from collected data is to train the\nreward estimator and dialog policy simultaneously using adversarial learning\n(AL). Although this method has demonstrated superior performance\nexperimentally, it is fraught with the inherent problems of AL, such as mode\ncollapse. This paper first identifies the role of AL in DPL through detailed\nanalyses of the objective functions of dialog policy and reward estimator.\nNext, based on these analyses, we propose a method that eliminates AL from\nreward estimation and DPL while retaining its advantages. We evaluate our\nmethod using MultiWOZ, a multi-domain task-oriented dialog corpus.",
        "translated": "对话策略根据每个对话回合的当前状态确定系统的操作，对于对话的成功至关重要。近年来，强化学习学习已成为对话策略学习(dPL)的一个有前途的选择。在基于 RL 的 DPL 中，对话策略根据奖励更新。在多领域任务导向的对话场景中，基于状态-行为的对话策略等细粒度奖励的人工构建是一个挑战。一种从收集的数据中估计报酬的方法是使用对抗学习(AL)同时训练报酬估计器和对话策略。虽然这种方法在实验上表现出了优越的性能，但它仍然存在着 AL 固有的问题，如模式崩溃。本文首先通过对对话策略和报酬估计的目标函数的详细分析，明确了 AL 在 DPL 中的作用。接下来，在这些分析的基础上，我们提出了一种在保留其优点的前提下消除 AL 在报酬估计和 DPL 中的影响的方法。我们使用面向多领域任务的对话语料库 MultiWOZ 来评估我们的方法。"
    },
    {
        "title": "Streaming CTR Prediction: Rethinking Recommendation Task for Real-World\n  Streaming Data",
        "url": "http://arxiv.org/abs/2307.07509v1",
        "pub_date": "2023-07-14",
        "summary": "The Click-Through Rate (CTR) prediction task is critical in industrial\nrecommender systems, where models are usually deployed on dynamic streaming\ndata in practical applications. Such streaming data in real-world recommender\nsystems face many challenges, such as distribution shift, temporal\nnon-stationarity, and systematic biases, which bring difficulties to the\ntraining and utilizing of recommendation models. However, most existing studies\napproach the CTR prediction as a classification task on static datasets,\nassuming that the train and test sets are independent and identically\ndistributed (a.k.a, i.i.d. assumption). To bridge this gap, we formulate the\nCTR prediction problem in streaming scenarios as a Streaming CTR Prediction\ntask. Accordingly, we propose dedicated benchmark settings and metrics to\nevaluate and analyze the performance of the models in streaming data. To better\nunderstand the differences compared to traditional CTR prediction tasks, we\ndelve into the factors that may affect the model performance, such as parameter\nscale, normalization, regularization, etc. The results reveal the existence of\nthe ''streaming learning dilemma'', whereby the same factor may have different\neffects on model performance in the static and streaming scenarios. Based on\nthe findings, we propose two simple but inspiring methods (i.e., tuning key\nparameters and exemplar replay) that significantly improve the effectiveness of\nthe CTR models in the new streaming scenario. We hope our work will inspire\nfurther research on streaming CTR prediction and help improve the robustness\nand adaptability of recommender systems.",
        "translated": "在工业推荐系统中，点进率(CTR)预测任务是至关重要的，在实际应用中，模型通常部署在动态流数据上。现实推荐系统中的流数据面临着分布偏移、时间非平稳性和系统偏差等问题，给推荐模型的训练和应用带来了困难。然而，大多数现有的研究将 CTR 预测作为静态数据集上的分类任务，假设训练和测试集是独立的和同一分布的(又称为 i.i.d. 假设)。为了弥补这一差距，我们将流场景中的 CTR 预测问题作为一个流 CTR 预测任务。因此，我们提出了专门的基准设置和指标来评估和分析流数据模型的性能。为了更好地理解与传统 CTR 预测任务相比的差异，我们深入研究了可能影响模型性能的因素，如参数尺度、归一化、正则化等。研究结果揭示了“流式学习困境”的存在，即在静态和流式场景中，同一因素对模型性能的影响可能不同。基于这些发现，我们提出了两种简单但是鼓舞人心的方法(即调整关键参数和示例重放) ，可以显著提高 CTR 模型在新的流场景中的有效性。我们希望我们的工作能够对流媒体点击率预测的进一步研究有所启发，并有助于提高推荐系统的鲁棒性和适应性。"
    },
    {
        "title": "PiTL: Cross-modal Retrieval with Weakly-supervised Vision-language\n  Pre-training via Prompting",
        "url": "http://arxiv.org/abs/2307.07341v1",
        "pub_date": "2023-07-14",
        "summary": "Vision-language (VL) Pre-training (VLP) has shown to well generalize VL\nmodels over a wide range of VL downstream tasks, especially for cross-modal\nretrieval. However, it hinges on a huge amount of image-text pairs, which\nrequires tedious and costly curation. On the contrary, weakly-supervised VLP\n(W-VLP) explores means with object tags generated by a pre-trained object\ndetector (OD) from images. Yet, they still require paired information, i.e.\nimages and object-level annotations, as supervision to train an OD.\n  To further reduce the amount of supervision, we propose Prompts-in-The-Loop\n(PiTL) that prompts knowledge from large language models (LLMs) to describe\nimages. Concretely, given a category label of an image, e.g. refinery, the\nknowledge, e.g. a refinery could be seen with large storage tanks, pipework,\nand ..., extracted by LLMs is used as the language counterpart. The knowledge\nsupplements, e.g. the common relations among entities most likely appearing in\na scene. We create IN14K, a new VL dataset of 9M images and 1M descriptions of\n14K categories from ImageNet21K with PiTL. Empirically, the VL models\npre-trained with PiTL-generated pairs are strongly favored over other W-VLP\nworks on image-to-text (I2T) and text-to-image (T2I) retrieval tasks, with less\nsupervision. The results reveal the effectiveness of PiTL-generated pairs for\nVLP.",
        "translated": "视觉语言(VL)预训练(VLP)已被证明可以在 VL 下游任务的广泛范围内很好地推广 VL 模型，特别是在跨模式检索方面。然而，它依赖于大量的图像-文本对，这需要乏味和昂贵的管理。相反，弱监督 VLP (W-VLP)利用预先训练的目标检测器(OD)从图像中生成目标标记来探索目标检测方法。然而，他们仍然需要成对的信息，即图像和对象级注释，作为培训 OD 的监督。为了进一步减少监督的数量，我们提出了循环提示(Prompts-in-The-Loop，PiTL) ，它提示来自大型语言模型(LLM)的知识来描述图像。具体来说，给定一个图像的类别标签，例如精炼厂，知识，例如精炼厂可以看到大型存储罐，管道系统，和... ，由 LLM 提取被用作语言对应物。知识的补充，例如最可能出现在场景中的实体之间的共同关系。我们使用 PiTL 从 ImageNet21K 创建了 IN14K，这是一个包含9M 图像和1M 描述14K 类别的新的 VL 数据集。经验表明，在图像到文本(I2T)和文本到图像(T2I)的检索任务中，预先使用 PiTL 生成对训练的 VL 模型比其他 W-VLP 模型更受青睐，而且监督更少。结果表明，PiTL 生成的对对于 VLP 是有效的。"
    },
    {
        "title": "Hybrid moderation in the newsroom: Recommending featured posts to\n  content moderators",
        "url": "http://arxiv.org/abs/2307.07317v1",
        "pub_date": "2023-07-14",
        "summary": "Online news outlets are grappling with the moderation of user-generated\ncontent within their comment section. We present a recommender system based on\nranking class probabilities to support and empower the moderator in choosing\nfeatured posts, a time-consuming task. By combining user and textual content\nfeatures we obtain an optimal classification F1-score of 0.44 on the test set.\nFurthermore, we observe an optimum mean NDCG@5 of 0.87 on a large set of\nvalidation articles. As an expert evaluation, content moderators assessed the\noutput of a random selection of articles by choosing comments to feature based\non the recommendations, which resulted in a NDCG score of 0.83. We conclude\nthat first, adding text features yields the best score and second, while\nchoosing featured content remains somewhat subjective, content moderators found\nsuitable comments in all but one evaluated recommendations. We end the paper by\nanalyzing our best-performing model, a step towards transparency and\nexplainability in hybrid content moderation.",
        "translated": "在线新闻机构正在努力克服其评论部分的用户生成内容。我们提出了一个推荐系统的基础上排名类概率，以支持和授权主持人选择特色职位，一个耗时的任务。通过结合用户和文本内容特征，我们得到了测试集上的最佳分类 F1得分为0.44。此外，我们观察到最佳平均 NDCG@5为0.87在大量的验证文章。作为一项专家评估，内容主持人根据推荐选择评论来评估随机选择的文章的输出，结果导致 NDCG 得分为0.83。我们得出的结论是: 首先，添加文本特性得分最高，其次，尽管选择特色内容仍然有些主观，但内容审核人员在所有评估的建议中都找到了合适的评论，只有一条除外。最后，我们分析了我们的最佳性能模型，这是在混合内容审核中实现透明性和可解释性的一个步骤。"
    },
    {
        "title": "Learning to Retrieve In-Context Examples for Large Language Models",
        "url": "http://arxiv.org/abs/2307.07164v1",
        "pub_date": "2023-07-14",
        "summary": "Large language models (LLMs) have demonstrated their ability to learn\nin-context, allowing them to perform various tasks based on a few input-output\nexamples. However, the effectiveness of in-context learning is heavily reliant\non the quality of the selected examples. In this paper, we propose a novel\nframework to iteratively train dense retrievers that can identify high-quality\nin-context examples for LLMs. Our framework initially trains a reward model\nbased on LLM feedback to evaluate the quality of candidate examples, followed\nby knowledge distillation to train a bi-encoder based dense retriever. Our\nexperiments on a suite of 30 tasks demonstrate that our framework significantly\nenhances in-context learning performance. Furthermore, we show the\ngeneralization ability of our framework to unseen tasks during training. An\nin-depth analysis reveals that our model improves performance by retrieving\nexamples with similar patterns, and the gains are consistent across LLMs of\nvarying sizes.",
        "translated": "大型语言模型(LLM)已经证明了它们在上下文中学习的能力，允许它们基于一些输入输出示例执行各种任务。然而，语境学习的有效性在很大程度上取决于所选范例的质量。在本文中，我们提出了一个新的框架，以迭代训练密集检索，可以识别高质量的上下文中的例子 LLM。我们的框架首先训练一个基于 LLM 反馈的奖励模型来评估候选样本的质量，然后通过知识提取来训练一个基于双编码器的密集检索器。我们在一组30个任务上的实验表明，我们的框架显著提高了在上下文中的学习性能。此外，我们还展示了我们的框架在训练过程中对未知任务的泛化能力。深入的分析表明，我们的模型通过检索具有相似模式的示例来提高性能，并且在不同大小的 LLM 之间增益是一致的。"
    },
    {
        "title": "Digital Health Discussion Through Articles Published Until the Year\n  2021: A Digital Topic Modeling Approach",
        "url": "http://arxiv.org/abs/2307.07130v1",
        "pub_date": "2023-07-14",
        "summary": "The digital health industry has grown in popularity since the 2010s, but\nthere has been limited analysis of the topics discussed in the field across\nacademic disciplines. This study aims to analyze the research trends of digital\nhealth-related articles published on the Web of Science until 2021, in order to\nunderstand the concentration, scope, and characteristics of the research.\n15,950 digital health-related papers from the top 10 academic fields were\nanalyzed using the Web of Science. The papers were grouped into three domains:\npublic health, medicine, and electrical engineering and computer science\n(EECS). Two time periods (2012-2016 and 2017-2021) were compared using Latent\nDirichlet Allocation (LDA) for topic modeling. The number of topics was\ndetermined based on coherence score, and topic compositions were compared using\na homogeneity test. The number of optimal topics varied across domains and time\nperiods. For public health, the first and second halves had 13 and 19 topics,\nrespectively. Medicine had 14 and 25 topics, and EECS had 7 and 21 topics. Text\nanalysis revealed shared topics among the domains, but with variations in\ncomposition. The homogeneity test confirmed significant differences between the\ngroups (p&lt;2.2e-16). Six dominant themes emerged, including journal article\nmethodology, information technology, medical issues, population demographics,\nsocial phenomena, and healthcare. Digital health research is expanding and\nevolving, particularly in relation to Covid-19, where topics such as depression\nand mental disorders, education, and physical activity have gained prominence.\nThere was no bias in topic composition among the three domains, but other\nfields like kinesiology or psychology could contribute to future digital health\nresearch. Exploring expanded topics that reflect people's needs for digital\nhealth over time will be crucial.",
        "translated": "自2010年代以来，数字健康产业越来越受欢迎，但是对跨学科领域讨论的主题的分析却很有限。本研究旨在分析截至2021年发表在科学网上的数位健康相关论文的研究趋势，以了解研究的集中度、范围与特色。15,950篇来自前十大学术领域的数字健康相关论文使用科学网络进行了分析。论文分为三个领域: 公共卫生、医学、电子工程和计算机科学(EECS)。使用主题建模隐含狄利克雷分布比较了两个时间段(2012-2016和2017-2021)。根据连贯性得分确定话题数量，并使用同质性测验比较话题组成。最佳主题的数量因领域和时间段而异。在公共卫生方面，第一部分和第二部分分别有13个和19个主题。医学有14和25个主题，EECS 有7和21个主题。文本分析揭示了域之间共享的主题，但是组成方式有所不同。同质性检验证实两组之间存在显著差异(p < 2.2e-16)。出现了六大主题，包括期刊论文方法论、信息技术、医学问题、人口统计学、社会现象和医疗保健。数字健康研究正在扩大和发展，特别是在2019冠状病毒疾病方面，如抑郁症和精神障碍、教育和体育活动等主题已经获得突出地位。这三个领域的主题构成没有偏差，但其他领域，如人体运动学或心理学，可以为未来的数字健康研究做出贡献。随着时间的推移，探索反映人们对数字健康需求的扩展主题将是至关重要的。"
    },
    {
        "title": "Population Expansion for Training Language Models with Private Federated\n  Learning",
        "url": "http://arxiv.org/abs/2307.07477v1",
        "pub_date": "2023-07-14",
        "summary": "Federated learning (FL) combined with differential privacy (DP) offers\nmachine learning (ML) training with distributed devices and with a formal\nprivacy guarantee. With a large population of devices, FL with DP produces a\nperformant model in a timely manner. However, for applications with a smaller\npopulation, not only does the model utility degrade as the DP noise is\ninversely proportional to population, but also the training latency increases\nsince waiting for enough clients to become available from a smaller pool is\nslower. In this work, we thus propose expanding the population based on domain\nadaptation techniques to speed up the training and improves the final model\nquality when training with small populations. We empirically demonstrate that\nour techniques can improve the utility by 13% to 30% on real-world language\nmodeling datasets.",
        "translated": "联邦学习(FL)结合差分隐私(DP)提供机器学习(ML)培训，使用分布式设备，并有正式的隐私保障。由于设备数量庞大，使用 DP 的 FL 可以及时生成性能模型。然而，对于人口较少的应用程序，不仅由于 DP 噪声与人口成反比，模型效用降低，而且由于等待足够的客户从较小的池变得可用较慢，培训延迟增加。在这项工作中，我们提出扩大基于领域适应技术的人口，以加快训练和提高最终的模型质量时，训练小人口。我们的经验证明，我们的技术可以提高13% 至30% 的实用性，对真实世界的语言建模数据集。"
    },
    {
        "title": "Towards spoken dialect identification of Irish",
        "url": "http://arxiv.org/abs/2307.07436v1",
        "pub_date": "2023-07-14",
        "summary": "The Irish language is rich in its diversity of dialects and accents. This\ncompounds the difficulty of creating a speech recognition system for the\nlow-resource language, as such a system must contend with a high degree of\nvariability with limited corpora. A recent study investigating dialect bias in\nIrish ASR found that balanced training corpora gave rise to unequal dialect\nperformance, with performance for the Ulster dialect being consistently worse\nthan for the Connacht or Munster dialects. Motivated by this, the present\nexperiments investigate spoken dialect identification of Irish, with a view to\nincorporating such a system into the speech recognition pipeline. Two acoustic\nclassification models are tested, XLS-R and ECAPA-TDNN, in conjunction with a\ntext-based classifier using a pretrained Irish-language BERT model. The\nECAPA-TDNN, particularly a model pretrained for language identification on the\nVoxLingua107 dataset, performed best overall, with an accuracy of 73%. This was\nfurther improved to 76% by fusing the model's outputs with the text-based\nmodel. The Ulster dialect was most accurately identified, with an accuracy of\n94%, however the model struggled to disambiguate between the Connacht and\nMunster dialects, suggesting a more nuanced approach may be necessary to\nrobustly distinguish between the dialects of Irish.",
        "translated": "爱尔兰语的方言和口音丰富多彩。这加大了为低资源语言创建语音识别系统的难度，因为这样的系统必须与有限语料库的高度可变性相抗衡。最近一项研究调查了爱尔兰 ASR 中的方言偏见，发现平衡的训练语料库导致了不平等的方言表现，阿尔斯特方言的表现一直比康奈特或明斯特方言差。基于此，本实验对爱尔兰方言口语识别进行了研究，以期将这一系统纳入到语音识别流水线中。两个声学分类模型被测试，XLS-R 和 ECAPA-TDNN，结合基于文本的分类器使用预先训练的爱尔兰语 BERT 模型。ECAPA-TDNN，特别是一个在 VoxLangua107数据集上进行语言识别预训练的模型，总体表现最好，准确率为73% 。通过将模型的输出与基于文本的模型融合，这一比例进一步提高到76% 。阿尔斯特方言被最准确地识别出来，准确率达到94% ，然而这个模型很难在康纳特方言和明斯特方言之间消除歧义，这表明一个更微妙的方法可能是必要的，以便有力地区分爱尔兰方言。"
    },
    {
        "title": "HuCurl: Human-induced Curriculum Discovery",
        "url": "http://arxiv.org/abs/2307.07412v1",
        "pub_date": "2023-07-14",
        "summary": "We introduce the problem of curriculum discovery and describe a curriculum\nlearning framework capable of discovering effective curricula in a curriculum\nspace based on prior knowledge about sample difficulty. Using annotation\nentropy and loss as measures of difficulty, we show that (i): the\ntop-performing discovered curricula for a given model and dataset are often\nnon-monotonic as opposed to monotonic curricula in existing literature, (ii):\nthe prevailing easy-to-hard or hard-to-easy transition curricula are often at\nthe risk of underperforming, and (iii): the curricula discovered for smaller\ndatasets and models perform well on larger datasets and models respectively.\nThe proposed framework encompasses some of the existing curriculum learning\napproaches and can discover curricula that outperform them across several NLP\ntasks.",
        "translated": "介绍了课程发现问题，描述了一个基于样本难度的先验知识，能够在课程空间中发现有效课程的课程学习框架。使用注释熵和损失作为难度的度量标准，我们表明: (i) : 针对给定模型和数据集的最佳发现课程通常是非单调的，而不是现有文献中的单调课程，(ii) : 流行的易于变难或难以变易的过渡课程通常处于表现不佳的风险，以及(iii) : 针对较小的数据集和模型发现的课程分别在较大的数据集和模型上表现良好。建议的框架包括一些现有的课程学习方法，可以发现课程表现优于他们在几个自然语言处理任务。"
    },
    {
        "title": "Rank Your Summaries: Enhancing Bengali Text Summarization via\n  Ranking-based Approach",
        "url": "http://arxiv.org/abs/2307.07392v1",
        "pub_date": "2023-07-14",
        "summary": "With the increasing need for text summarization techniques that are both\nefficient and accurate, it becomes crucial to explore avenues that enhance the\nquality and precision of pre-trained models specifically tailored for\nsummarizing Bengali texts. When it comes to text summarization tasks, there are\nnumerous pre-trained transformer models at one's disposal. Consequently, it\nbecomes quite a challenge to discern the most informative and relevant summary\nfor a given text among the various options generated by these pre-trained\nsummarization models. This paper aims to identify the most accurate and\ninformative summary for a given text by utilizing a simple but effective\nranking-based approach that compares the output of four different pre-trained\nBengali text summarization models. The process begins by carrying out\npreprocessing of the input text that involves eliminating unnecessary elements\nsuch as special characters and punctuation marks. Next, we utilize four\npre-trained summarization models to generate summaries, followed by applying a\ntext ranking algorithm to identify the most suitable summary. Ultimately, the\nsummary with the highest ranking score is chosen as the final one. To evaluate\nthe effectiveness of this approach, the generated summaries are compared\nagainst human-annotated summaries using standard NLG metrics such as BLEU,\nROUGE, BERTScore, WIL, WER, and METEOR. Experimental results suggest that by\nleveraging the strengths of each pre-trained transformer model and combining\nthem using a ranking-based approach, our methodology significantly improves the\naccuracy and effectiveness of the Bengali text summarization.",
        "translated": "随着对既高效又准确的文本摘要技术的需求日益增加，探索提高专门用于摘要孟加拉语文本的预先训练的模型的质量和精确度的途径变得至关重要。当涉及到文本摘要任务时，有许多预先训练好的变压器模型可供使用。因此，在这些经过训练的摘要模型所产生的各种选择中，要辨别出某一特定文本的信息量最大和相关性最高的摘要是一项相当大的挑战。本文旨在通过使用一种简单而有效的基于排序的方法，比较四种不同的预先训练的孟加拉语文本摘要模型的输出，从而确定给定文本的最准确和信息最丰富的摘要。该过程首先对输入文本进行预处理，包括删除不必要的元素，例如特殊字符和句读。接下来，我们利用四个预先训练的摘要模型来生成摘要，然后应用文本排序算法来确定最合适的摘要。最终，得分最高的总结被选为最终的总结。为了评估这种方法的有效性，使用标准的 NLG 指标(如 BLEU，ROUGE，BERTScore，WIL，WER 和 METEOR)将生成的摘要与人类注释的摘要进行比较。实验结果表明，通过利用每个预先训练的变压器模型的优势，并结合使用基于排序的方法，我们的方法显着提高孟加拉语文本摘要的准确性和有效性。"
    },
    {
        "title": "Composition-contrastive Learning for Sentence Embeddings",
        "url": "http://arxiv.org/abs/2307.07380v1",
        "pub_date": "2023-07-14",
        "summary": "Vector representations of natural language are ubiquitous in search\napplications. Recently, various methods based on contrastive learning have been\nproposed to learn textual representations from unlabelled data; by maximizing\nalignment between minimally-perturbed embeddings of the same text, and\nencouraging a uniform distribution of embeddings across a broader corpus.\nDifferently, we propose maximizing alignment between texts and a composition of\ntheir phrasal constituents. We consider several realizations of this objective\nand elaborate the impact on representations in each case. Experimental results\non semantic textual similarity tasks show improvements over baselines that are\ncomparable with state-of-the-art approaches. Moreover, this work is the first\nto do so without incurring costs in auxiliary training objectives or additional\nnetwork parameters.",
        "translated": "自然语言的矢量表示在搜索应用中无处不在。最近，人们提出了各种基于对比学习的方法来从未标记的数据中学习文本表示; 通过最大化同一文本的最小干扰嵌入之间的对齐，并鼓励在更广泛的语料库中统一分布嵌入。不同的是，我们建议最大限度地使文本与其短语成分的组合保持一致。我们考虑了这一目标的几个实现，并详细阐述了每种情况下对表述的影响。对语义文本相似性任务的实验结果表明，与基线相比，可以与最新的方法进行比较。此外，这项工作是第一次这样做，而不产生成本的辅助培训目标或额外的网络参数。"
    },
    {
        "title": "A scoping review on multimodal deep learning in biomedical images and\n  texts",
        "url": "http://arxiv.org/abs/2307.07362v1",
        "pub_date": "2023-07-14",
        "summary": "Computer-assisted diagnostic and prognostic systems of the future should be\ncapable of simultaneously processing multimodal data. Multimodal deep learning\n(MDL), which involves the integration of multiple sources of data, such as\nimages and text, has the potential to revolutionize the analysis and\ninterpretation of biomedical data. However, it only caught researchers'\nattention recently. To this end, there is a critical need to conduct a\nsystematic review on this topic, identify the limitations of current work, and\nexplore future directions. In this scoping review, we aim to provide a\ncomprehensive overview of the current state of the field and identify key\nconcepts, types of studies, and research gaps with a focus on biomedical images\nand texts joint learning, mainly because these two were the most commonly\navailable data types in MDL research. This study reviewed the current uses of\nmultimodal deep learning on five tasks: (1) Report generation, (2) Visual\nquestion answering, (3) Cross-modal retrieval, (4) Computer-aided diagnosis,\nand (5) Semantic segmentation. Our results highlight the diverse applications\nand potential of MDL and suggest directions for future research in the field.\nWe hope our review will facilitate the collaboration of natural language\nprocessing (NLP) and medical imaging communities and support the next\ngeneration of decision-making and computer-assisted diagnostic system\ndevelopment.",
        "translated": "未来的计算机辅助诊断和预测系统应该能够同时处理多模态数据。多模态深度学习(MDL)涉及图像和文本等多种数据源的集成，具有革命性的生物医学数据分析和解释的潜力。然而，它只是最近才引起研究人员的注意。为此，我们迫切需要就这个课题开展一次系统综述，找出当前工作的局限性，并探讨未来的发展方向。在这个范围审查中，我们的目标是提供该领域当前状况的全面概述，并确定关键概念，研究类型和研究差距，重点是生物医学图像和文本联合学习，主要是因为这两个是 MDL 研究中最常用的数据类型。这项研究回顾了目前多模态深度学习在以下五个任务中的应用: (1)报告生成，(2)视觉问题回答，(3)跨模态检索，(4)电脑辅助诊断，和(5)语义分割。我们的研究结果突出了 MDL 的多样化应用和潜力，并为该领域的未来研究提供了方向。我们希望我们的综述将促进自然语言处理(NLP)和医学成像社区的合作，并支持下一代决策和计算机辅助诊断系统的发展。"
    },
    {
        "title": "Gloss Attention for Gloss-free Sign Language Translation",
        "url": "http://arxiv.org/abs/2307.07361v1",
        "pub_date": "2023-07-14",
        "summary": "Most sign language translation (SLT) methods to date require the use of gloss\nannotations to provide additional supervision information, however, the\nacquisition of gloss is not easy. To solve this problem, we first perform an\nanalysis of existing models to confirm how gloss annotations make SLT easier.\nWe find that it can provide two aspects of information for the model, 1) it can\nhelp the model implicitly learn the location of semantic boundaries in\ncontinuous sign language videos, 2) it can help the model understand the sign\nlanguage video globally. We then propose \\emph{gloss attention}, which enables\nthe model to keep its attention within video segments that have the same\nsemantics locally, just as gloss helps existing models do. Furthermore, we\ntransfer the knowledge of sentence-to-sentence similarity from the natural\nlanguage model to our gloss attention SLT network (GASLT) to help it understand\nsign language videos at the sentence level. Experimental results on multiple\nlarge-scale sign language datasets show that our proposed GASLT model\nsignificantly outperforms existing methods. Our code is provided in\n\\url{https://github.com/YinAoXiong/GASLT}.",
        "translated": "迄今为止，大多数手语翻译(SLT)方法都需要使用注释来提供额外的监督信息，然而，获得注释并不容易。为了解决这个问题，我们首先对现有模型进行分析，以确认光泽注释如何使 SLT 更容易。我们发现它可以为模型提供两方面的信息: 1)它可以帮助模型隐式地学习连续手语视频中语义边界的位置; 2)它可以帮助模型全局地理解手语视频。然后我们提出了静态注意力{注意力注意力} ，这使得模型能够在局部具有相同语义的视频片段中保持注意力，就像注意力注意力帮助现有的模型那样。此外，我们将自然语言模型中的句子相似性知识转移到注意力集中的 SLT 网络(GASLT)中，帮助它在句子水平上理解手语视频。在多个大规模手语数据集上的实验结果表明，我们提出的 GASLT 模型明显优于现有的方法。我们的代码在 url { https://github.com/yinaoxiong/gaslt }中提供。"
    },
    {
        "title": "How Different Is Stereotypical Bias Across Languages?",
        "url": "http://arxiv.org/abs/2307.07331v1",
        "pub_date": "2023-07-14",
        "summary": "Recent studies have demonstrated how to assess the stereotypical bias in\npre-trained English language models. In this work, we extend this branch of\nresearch in multiple different dimensions by systematically investigating (a)\nmono- and multilingual models of (b) different underlying architectures with\nrespect to their bias in (c) multiple different languages. To that end, we make\nuse of the English StereoSet data set (Nadeem et al., 2021), which we\nsemi-automatically translate into German, French, Spanish, and Turkish. We find\nthat it is of major importance to conduct this type of analysis in a\nmultilingual setting, as our experiments show a much more nuanced picture as\nwell as notable differences from the English-only analysis. The main takeaways\nfrom our analysis are that mGPT-2 (partly) shows surprising anti-stereotypical\nbehavior across languages, English (monolingual) models exhibit the strongest\nbias, and the stereotypes reflected in the data set are least present in\nTurkish models. Finally, we release our codebase alongside the translated data\nsets and practical guidelines for the semi-automatic translation to encourage a\nfurther extension of our work to other languages.",
        "translated": "最近的研究已经证明了如何评估预先训练的英语语言模型中的定型偏见。在这项工作中，我们通过系统地调查(a)不同底层架构的单语言和多语言模型(b)关于它们在(c)多种不同语言中的偏见来扩展多个不同维度的研究分支。为此，我们使用英语 StereoSet 数据集(Nadeem et al。 ，2021) ，我们半自动地将其翻译成德语、法语、西班牙语和土耳其语。我们发现在一个多语言环境下进行这种分析是非常重要的，因为我们的实验显示了一个更加微妙的图片以及与纯英语分析的显著差异。我们分析的主要结论是 mGPT-2(部分)表现出令人惊讶的跨语言反刻板印象行为，英语(单语言)模型表现出最强的偏见，数据集中反映的刻板印象在土耳其模型中最少。最后，我们发布了我们的代码库以及翻译数据集和半自动翻译的实用指南，以鼓励我们的工作进一步扩展到其他语言。"
    },
    {
        "title": "Using Large Language Models for Zero-Shot Natural Language Generation\n  from Knowledge Graphs",
        "url": "http://arxiv.org/abs/2307.07312v1",
        "pub_date": "2023-07-14",
        "summary": "In any system that uses structured knowledge graph (KG) data as its\nunderlying knowledge representation, KG-to-text generation is a useful tool for\nturning parts of the graph data into text that can be understood by humans.\nRecent work has shown that models that make use of pretraining on large amounts\nof text data can perform well on the KG-to-text task even with relatively small\nsets of training data on the specific graph-to-text task. In this paper, we\nbuild on this concept by using large language models to perform zero-shot\ngeneration based on nothing but the model's understanding of the triple\nstructure from what it can read. We show that ChatGPT achieves near\nstate-of-the-art performance on some measures of the WebNLG 2020 challenge, but\nfalls behind on others. Additionally, we compare factual, counter-factual and\nfictional statements, and show that there is a significant connection between\nwhat the LLM already knows about the data it is parsing and the quality of the\noutput text.",
        "translated": "在任何使用结构化知识图(KG)数据作为其底层知识表示的系统中，KG 到文本的生成是一种有用的工具，可以将图形数据的一部分转换成人们可以理解的文本。最近的研究表明，利用对大量文本数据进行预训练的模型能够很好地完成 KG-to-text 任务，即使在具体的图形-文本任务中只有相对较小的训练数据集。在本文中，我们建立在这个概念的基础上，使用大型语言模型来执行零镜头生成，仅仅基于模型对三重结构的理解。我们展示了 ChatGPT 在 WebNLG 2020挑战的某些指标上取得了接近最先进的性能，但在其他指标上却落后了。此外，我们比较了事实陈述、反事实陈述和虚构陈述，并表明 LLM 已经知道的解析数据与输出文本的质量之间存在显著的联系。"
    },
    {
        "title": "Leveraging Recommender Systems to Reduce Content Gaps on Peer Production\n  Platforms",
        "url": "http://arxiv.org/abs/2307.08669v1",
        "pub_date": "2023-07-17",
        "summary": "Peer production platforms like Wikipedia commonly suffer from content gaps.\nPrior research suggests recommender systems can help solve this problem, by\nguiding editors towards underrepresented topics. However, it remains unclear\nwhether this approach would result in less relevant recommendations, leading to\nreduced overall engagement with recommended items. To answer this question, we\nfirst conducted offline analyses (Study 1) on SuggestBot, a task-routing\nrecommender system for Wikipedia, then did a three-month controlled experiment\n(Study 2). Our results show that presenting users with articles from\nunderrepresented topics increased the proportion of work done on those articles\nwithout significantly reducing overall recommendation uptake. We discuss the\nimplications of our results, including how ignoring the article discovery\nprocess can artificially narrow recommendations. We draw parallels between this\nphenomenon and the common issue of ``filter bubbles'' to show how any platform\nthat employs recommender systems is susceptible to it.",
        "translated": "像维基百科这样的同行生产平台通常受到内容空白的困扰。先前的研究表明，推荐系统可以帮助解决这个问题，通过引导编辑向代表性不足的主题。然而，目前还不清楚这种方法是否会导致相关性较低的建议，从而减少对推荐项目的总体参与。为了回答这个问题，我们首先对维基百科的任务路由推荐系统——暗示机器人进行了离线分析(研究1) ，然后进行了为期三个月的对照实验(研究2)。我们的研究结果表明，向用户提供来自代表性不足的主题的文章，增加了在这些文章上完成的工作的比例，而没有显著降低总体推荐的吸收。我们讨论我们的结果的含义，包括忽略文章发现过程如何能够人为地缩小推荐范围。我们将这种现象与常见的“过滤气泡”现象进行比较，以说明任何使用推荐系统的平台都容易受到它的影响。"
    },
    {
        "title": "Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language\n  Models",
        "url": "http://arxiv.org/abs/2307.08303v1",
        "pub_date": "2023-07-17",
        "summary": "Dense retrieval (DR) converts queries and documents into dense embeddings and\nmeasures the similarity between queries and documents in vector space. One of\nthe challenges in DR is the lack of domain-specific training data. While DR\nmodels can learn from large-scale public datasets like MS MARCO through\ntransfer learning, evidence shows that not all DR models and domains can\nbenefit from transfer learning equally. Recently, some researchers have\nresorted to large language models (LLMs) to improve the zero-shot and few-shot\nDR models. However, the hard prompts or human-written prompts utilized in these\nworks cannot guarantee the good quality of generated weak queries. To tackle\nthis, we propose soft prompt tuning for augmenting DR (SPTAR): For each task,\nwe leverage soft prompt-tuning to optimize a task-specific soft prompt on\nlimited ground truth data and then prompt the LLMs to tag unlabeled documents\nwith weak queries, yielding enough weak document-query pairs to train\ntask-specific dense retrievers. We design a filter to select high-quality\nexample document-query pairs in the prompt to further improve the quality of\nweak tagged queries. To the best of our knowledge, there is no prior work\nutilizing soft prompt tuning to augment DR models. The experiments demonstrate\nthat SPTAR outperforms the unsupervised baselines BM25 and the recently\nproposed LLMs-based augmentation method for DR.",
        "translated": "密集检索(DR)将查询和文档转换为密集嵌入，并在向量空间中度量查询和文档之间的相似性。DR 面临的挑战之一是缺乏特定领域的培训数据。尽管 DR 模型可以通过转移学习从 MS MARCO 这样的大规模公共数据集中学习，但有证据表明，并非所有 DR 模型和域都能平等地从转移学习中受益。近年来，一些研究者采用大语言模型(LLM)来改进零镜头和少镜头 DR 模型。但是，这些工作中使用的硬提示或人工编写的提示不能保证生成的弱查询的良好质量。为了解决这个问题，我们提出了增强 DR (SPTAR)的软提示调优: 对于每个任务，我们利用软提示调优来优化有限的地面真实数据上的任务特定的软提示，然后提示 LLM 用弱查询标记未标记的文档，产生足够的弱文档查询对来训练任务特定的密集检索器。为了进一步提高弱标记查询的质量，我们设计了一个过滤器，在提示中选择高质量的示例文档-查询对。据我们所知，没有先前的工作利用软及时调整，以增强 DR 模型。实验结果表明，SPTAR 的性能优于无监督基线 BM25和最近提出的基于 LLM 的 DR 增强方法。"
    },
    {
        "title": "Measuring Item Global Residual Value for Fair Recommendation",
        "url": "http://arxiv.org/abs/2307.08259v1",
        "pub_date": "2023-07-17",
        "summary": "In the era of information explosion, numerous items emerge every day,\nespecially in feed scenarios. Due to the limited system display slots and user\nbrowsing attention, various recommendation systems are designed not only to\nsatisfy users' personalized information needs but also to allocate items'\nexposure. However, recent recommendation studies mainly focus on modeling user\npreferences to present satisfying results and maximize user interactions, while\npaying little attention to developing item-side fair exposure mechanisms for\nrational information delivery. This may lead to serious resource allocation\nproblems on the item side, such as the Snowball Effect. Furthermore, unfair\nexposure mechanisms may hurt recommendation performance. In this paper, we call\nfor a shift of attention from modeling user preferences to developing fair\nexposure mechanisms for items. We first conduct empirical analyses of feed\nscenarios to explore exposure problems between items with distinct uploaded\ntimes. This points out that unfair exposure caused by the time factor may be\nthe major cause of the Snowball Effect. Then, we propose to explicitly model\nitem-level customized timeliness distribution, Global Residual Value (GRV), for\nfair resource allocation. This GRV module is introduced into recommendations\nwith the designed Timeliness-aware Fair Recommendation Framework (TaFR).\nExtensive experiments on two datasets demonstrate that TaFR achieves consistent\nimprovements with various backbone recommendation models. By modeling item-side\ncustomized Global Residual Value, we achieve a fairer distribution of resources\nand, at the same time, improve recommendation performance.",
        "translated": "在信息爆炸的时代，每天都会出现大量的条目，特别是在提要场景中。由于系统显示时隙和用户浏览注意力的限制，各种推荐系统不仅要满足用户的个性化信息需求，还要分配项目的曝光量。然而，最近的推荐研究主要集中在建模用户偏好以呈现令人满意的结果和最大化用户交互，而很少关注开发项目侧公平曝光机制以合理的信息传递。这可能会在项目方面导致严重的资源分配问题，比如雪球效应。此外，不公平的曝光机制可能会损害推荐性能。在本文中，我们呼吁将注意力从建模用户偏好转移到开发项目的公平曝光机制。我们首先进行饲料情景的实证分析，以探讨不同上传时间的项目之间的暴露问题。由此指出，时间因素造成的不公平曝光可能是雪球效应的主要原因。然后，为了实现资源的公平分配，我们提出了项目级定制时间分配的显式模型——全局剩余价值(GRV)。这个 GRV 模块被引入到建议中，并设计了时间感知的公平推荐框架(TaFR)。在两个数据集上的大量实验表明，TaFR 与各种骨干推荐模型实现了一致的改进。通过对项目端定制的全局剩余价值建模，我们实现了更公平的资源分配，同时提高了推荐性能。"
    },
    {
        "title": "Data Discovery for the SDGs: A Systematic Rule-based Approach",
        "url": "http://arxiv.org/abs/2307.07983v1",
        "pub_date": "2023-07-16",
        "summary": "In 2015, the United Nations put forward 17 Sustainable Development Goals\n(SDGs) to be achieved by 2030, where data has been promoted as a focus to\ninnovating sustainable development and as a means to measuring progress towards\nachieving the SDGs. In this study, we propose a systematic approach towards\ndiscovering data types and sources that can be used for SDG research. The\nproposed method integrates a systematic mapping approach using manual\nqualitative coding over a corpus of SDG-related research literature followed by\nan automated process that applies rules to perform data entity extraction\ncomputationally. This approach is exemplified by an analysis of literature\nrelating to SDG 7, the results of which are also presented in this paper. The\npaper concludes with a discussion of the approach and suggests future work to\nextend the method with more advance NLP and machine learning techniques.",
        "translated": "2015年，联合国提出了到2030年实现17个可持续发展目标，并将其中的数据作为创新可持续发展的重点和衡量实现可持续发展目标进展的手段。在这项研究中，我们提出了一个系统的方法来发现可用于 SDG 研究的数据类型和来源。提出的方法集成了一个系统的映射方法，使用手工定性编码的 SDG 相关的研究文献语料库，然后是一个自动化的过程，应用规则执行数据实体提取计算。本文通过对 SDG 7相关文献的分析，说明了这种方法的可行性，并给出了分析结果。文章最后对该方法进行了讨论，并提出了进一步扩展该方法的工作，以期使用更先进的自然语言处理和机器学习技术。"
    },
    {
        "title": "Opinion mining using Double Channel CNN for Recommender System",
        "url": "http://arxiv.org/abs/2307.07798v1",
        "pub_date": "2023-07-15",
        "summary": "Much unstructured data has been produced with the growth of the Internet and\nsocial media. A significant volume of textual data includes users' opinions\nabout products in online stores and social media. By exploring and categorizing\nthem, helpful information can be acquired, including customer satisfaction,\nuser feedback about a particular event, predicting the sale of a specific\nproduct, and other similar cases. In this paper, we present an approach for\nsentiment analysis with a deep learning model and use it to recommend products.\nA two-channel convolutional neural network model has been used for opinion\nmining, which has five layers and extracts essential features from the data. We\nincreased the number of comments by applying the SMOTE algorithm to the initial\ndataset and balanced the data. Then we proceed to cluster the aspects. We also\nassign a weight to each cluster using tensor decomposition algorithms that\nimprove the recommender system's performance. Our proposed method has reached\n91.6% accuracy, significantly improved compared to previous aspect-based\napproaches.",
        "translated": "随着互联网和社交媒体的发展，许多非结构化数据已经产生。大量的文本数据包括用户对在线商店和社交媒体上的产品的意见。通过探索和分类，可以获得有用的信息，包括客户满意度，用户对特定事件的反馈，预测特定产品的销售，以及其他类似的情况。本文提出了一种基于深度学习模型的情感分析方法，并用于产品推荐。一个双通道的卷积神经网络模型已经被用于意见挖掘，它有五个层次，并从数据中提取基本特征。我们通过对初始数据集应用 SMOTE 算法来增加评论的数量并平衡数据。然后我们继续对这些方面进行聚类。我们还使用张量分解算法为每个集群赋予一个权重，以提高推荐系统的性能。我们提出的方法已经达到91.6% 的准确率，显着改善相比，以前的方面为基础的方法。"
    },
    {
        "title": "AlpaGasus: Training A Better Alpaca with Fewer Data",
        "url": "http://arxiv.org/abs/2307.08701v1",
        "pub_date": "2023-07-17",
        "summary": "Large language models~(LLMs) obtain instruction-following capability through\ninstruction-finetuning (IFT) on supervised instruction/response data. However,\nwidely used IFT datasets (e.g., Alpaca's 52k data) surprisingly contain many\nlow-quality instances with incorrect or irrelevant responses, which are\nmisleading and detrimental to IFT. In this paper, we propose a simple and\neffective data selection strategy that automatically identifies and removes\nlow-quality data using a strong LLM (e.g., ChatGPT). To this end, we introduce\nAlpaGasus, which is finetuned on only 9k high-quality data filtered from the\n52k Alpaca data. AlpaGasus significantly outperforms the original Alpaca as\nevaluated by GPT-4 on multiple test sets and its 13B variant matches $&gt;90\\%$\nperformance of its teacher LLM (i.e., Text-Davinci-003) on test tasks. It also\nprovides 5.7x faster training, reducing the training time for a 7B variant from\n80 minutes (for Alpaca) to 14 minutes \\footnote{We apply IFT for the same\nnumber of epochs as Alpaca(7B) but on fewer data, using 4$\\times$NVIDIA A100\n(80GB) GPUs and following the original Alpaca setting and hyperparameters.}.\nOverall, AlpaGasus demonstrates a novel data-centric IFT paradigm that can be\ngenerally applied to instruction-tuning data, leading to faster training and\nbetter instruction-following models. Our project page is available at:\n\\url{https://lichang-chen.github.io/AlpaGasus/}.",
        "translated": "大语言模型 ~ (LLM)通过指令微调(IFT)在有监督的指令/响应数据上获得指令跟踪能力。然而，广泛使用的 IFT 数据集(例如，Alpaca 的52k 数据)令人惊讶地包含了许多低质量的实例，这些实例有不正确或不相关的响应，这些都是误导和有害于 IFT 的。在本文中，我们提出了一个简单有效的数据选择策略，使用一个强 LLM (如 ChatGPT)自动识别和删除低质量数据。为此，我们引入了 AlpaGasus，它只对从52k 羊驼数据中筛选出的9k 高质量数据进行微调。根据 gPT-4的评估，阿尔帕加索斯在多个测试集上的表现明显优于原来的 Alpaca，其13b 变体在测试任务上与其教师 LLM (即 Text-Davinci-003)的表现相当，达到了90% 以上。它还提供了5.7倍的快速训练，将7B 变体的训练时间从80分钟(对于羊驼)减少到14分钟脚注{我们对与羊驼(7B)相同的时代应用 IFT，但数据较少，使用4美元乘以 $NVIDIA A100(80 GB) GPU，并遵循原始的羊驼设置和超参数。}.总的来说，AlpaGasus 展示了一种新的以数据为中心的 IFT 范式，该范式可以普遍应用于指令调优数据，导致更快的训练和更好的指令跟踪模型。我们的项目页面可在以下网址获得: url { https://lichang-chen.github.io/alpagasus/}。"
    },
    {
        "title": "COLLIE: Systematic Construction of Constrained Text Generation Tasks",
        "url": "http://arxiv.org/abs/2307.08689v1",
        "pub_date": "2023-07-17",
        "summary": "Text generation under constraints have seen increasing interests in natural\nlanguage processing, especially with the rapidly improving capabilities of\nlarge language models. However, existing benchmarks for constrained generation\nusually focus on fixed constraint types (e.g.,generate a sentence containing\ncertain words) that have proved to be easy for state-of-the-art models like\nGPT-4. We present COLLIE, a grammar-based framework that allows the\nspecification of rich, compositional constraints with diverse generation levels\n(word, sentence, paragraph, passage) and modeling challenges (e.g.,language\nunderstanding, logical reasoning, counting, semantic planning). We also develop\ntools for automatic extraction of task instances given a constraint structure\nand a raw text corpus. Using COLLIE, we compile the COLLIE-v1 dataset with 2080\ninstances comprising 13 constraint structures. We perform systematic\nexperiments across five state-of-the-art instruction-tuned language models and\nanalyze their performances to reveal shortcomings. COLLIE is designed to be\nextensible and lightweight, and we hope the community finds it useful to\ndevelop more complex constraints and evaluations in the future.",
        "translated": "约束条件下的文本生成已经成为自然语言处理领域的研究热点，尤其是随着大型语言模型能力的迅速提高。然而，现有的约束生成基准通常侧重于固定的约束类型(例如，生成包含特定单词的句子) ，这些类型对于 GPT-4等最先进的模型来说已被证明是容易的。我们介绍了 COLLIE，一个基于语法的框架，它允许规范丰富的、具有不同生成级别(词、句子、段落、段落)的组合约束和建模挑战(例如，语言理解、逻辑推理、计数、语义规划)。我们还开发了工具来自动提取任务实例给出了一个约束结构和原始文本语料库。使用 COLLIE，我们编译了包含13个约束结构的2080个实例的 COLLIE-v1数据集。我们对五种最先进的教学调整语言模型进行了系统的实验，并分析了它们的表现，以揭示其不足之处。COLLIE 的设计是可扩展的和轻量级的，我们希望社区能够发现在将来开发更复杂的约束和评估是有用的。"
    },
    {
        "title": "Do Models Explain Themselves? Counterfactual Simulatability of Natural\n  Language Explanations",
        "url": "http://arxiv.org/abs/2307.08678v1",
        "pub_date": "2023-07-17",
        "summary": "Large language models (LLMs) are trained to imitate humans to explain human\ndecisions. However, do LLMs explain themselves? Can they help humans build\nmental models of how LLMs process different inputs? To answer these questions,\nwe propose to evaluate $\\textbf{counterfactual simulatability}$ of natural\nlanguage explanations: whether an explanation can enable humans to precisely\ninfer the model's outputs on diverse counterfactuals of the explained input.\nFor example, if a model answers \"yes\" to the input question \"Can eagles fly?\"\nwith the explanation \"all birds can fly\", then humans would infer from the\nexplanation that it would also answer \"yes\" to the counterfactual input \"Can\npenguins fly?\". If the explanation is precise, then the model's answer should\nmatch humans' expectations.\n  We implemented two metrics based on counterfactual simulatability: precision\nand generality. We generated diverse counterfactuals automatically using LLMs.\nWe then used these metrics to evaluate state-of-the-art LLMs (e.g., GPT-4) on\ntwo tasks: multi-hop factual reasoning and reward modeling. We found that LLM's\nexplanations have low precision and that precision does not correlate with\nplausibility. Therefore, naively optimizing human approvals (e.g., RLHF) may\nnot be a sufficient solution.",
        "translated": "大型语言模型(LLM)被训练成模仿人类来解释人类的决策。然而，LLM 能够解释自己吗？它们能否帮助人类建立 LLM 如何处理不同输入的心理模型？为了回答这些问题，我们建议评估自然语言解释的 $textbf {反事实模拟性} $: 一种解释是否能够使人类精确地推断出模型对所解释输入的不同反事实的输出。例如，如果一个模型对输入问题“老鹰能飞吗?”通过解释“所有的鸟都能飞”，那么人类就会从解释中推断出，对于反事实输入“企鹅能飞吗?”，它也会回答“是的”.如果解释是精确的，那么模型的答案应该符合人类的期望。我们实现了两个基于反事实模拟性的度量: 精度和通用性。我们使用 LLM 自动生成不同的反事实。然后，我们使用这些指标来评估最先进的 LLM (例如，GPT-4)在两个任务上的效果: 多跳事实推理和奖励建模。我们发现 LLM 的解释精度较低，精度与合理性不相关。因此，天真地优化人工审批(例如，RLHF)可能不是一个充分的解决方案。"
    },
    {
        "title": "Multilingual Speech-to-Speech Translation into Multiple Target Languages",
        "url": "http://arxiv.org/abs/2307.08655v1",
        "pub_date": "2023-07-17",
        "summary": "Speech-to-speech translation (S2ST) enables spoken communication between\npeople talking in different languages. Despite a few studies on multilingual\nS2ST, their focus is the multilinguality on the source side, i.e., the\ntranslation from multiple source languages to one target language. We present\nthe first work on multilingual S2ST supporting multiple target languages.\nLeveraging recent advance in direct S2ST with speech-to-unit and vocoder, we\nequip these key components with multilingual capability. Speech-to-masked-unit\n(S2MU) is the multilingual extension of S2U, which applies masking to units\nwhich don't belong to the given target language to reduce the language\ninterference. We also propose multilingual vocoder which is trained with\nlanguage embedding and the auxiliary loss of language identification. On\nbenchmark translation testsets, our proposed multilingual model shows superior\nperformance than bilingual models in the translation from English into $16$\ntarget languages.",
        "translated": "语音对语音翻译(S2ST)使用不同语言交谈的人们能够进行口语交流。尽管有关多语言 S2ST 的研究很少，但他们的重点是源语言的多语性，即从多种源语言到一种目标语言的翻译。我们介绍了第一个支持多种目标语言的多语言 S2ST 的工作。利用最近在直接 S2ST 语音到单元和声码器方面的进展，我们为这些关键部件配备了多语言能力。语音屏蔽单元(S2MU)是 S2U 的多语种扩展，它对不属于给定目标语言的单元进行屏蔽，以减少语言干扰。我们还提出了多语言声码器的语言嵌入训练和辅助损失的语言识别。在基准翻译测试集方面，我们提出的多语言模式在从英语翻译成16美元的目标语言方面表现出比双语模式更好的性能。"
    },
    {
        "title": "Retentive Network: A Successor to Transformer for Large Language Models",
        "url": "http://arxiv.org/abs/2307.08621v1",
        "pub_date": "2023-07-17",
        "summary": "In this work, we propose Retentive Network (RetNet) as a foundation\narchitecture for large language models, simultaneously achieving training\nparallelism, low-cost inference, and good performance. We theoretically derive\nthe connection between recurrence and attention. Then we propose the retention\nmechanism for sequence modeling, which supports three computation paradigms,\ni.e., parallel, recurrent, and chunkwise recurrent. Specifically, the parallel\nrepresentation allows for training parallelism. The recurrent representation\nenables low-cost $O(1)$ inference, which improves decoding throughput, latency,\nand GPU memory without sacrificing performance. The chunkwise recurrent\nrepresentation facilitates efficient long-sequence modeling with linear\ncomplexity, where each chunk is encoded parallelly while recurrently\nsummarizing the chunks. Experimental results on language modeling show that\nRetNet achieves favorable scaling results, parallel training, low-cost\ndeployment, and efficient inference. The intriguing properties make RetNet a\nstrong successor to Transformer for large language models. Code will be\navailable at https://aka.ms/retnet.",
        "translated": "在这项工作中，我们提出了保留网络(RetNet)作为大型语言模型的基础架构，同时实现了训练并行性、低成本推理和良好的性能。我们从理论上推导出循环和注意之间的联系。然后我们提出了序列建模的保持机制，它支持三种计算范式，即并行、循环和分块循环。具体来说，并行表示允许训练并行性。经常性表示支持低成本 $O (1) $推理，这在不牺牲性能的情况下提高了解码吞吐量、延迟和 GPU 内存。分块递归表示有利于线性复杂度的高效长序列建模，其中每个分块被并行编码，同时递归地汇总分块。语言建模实验结果表明，RetNet 具有良好的缩放效果、并行训练、低成本部署和高效推理能力。这些有趣的特性使 RetNet 成为大型语言模型的 Transformer 的强有力的继承者。密码将在 https://aka.ms/retnet 公布。"
    },
    {
        "title": "Multimodal Diffusion Segmentation Model for Object Segmentation from\n  Manipulation Instructions",
        "url": "http://arxiv.org/abs/2307.08597v1",
        "pub_date": "2023-07-17",
        "summary": "In this study, we aim to develop a model that comprehends a natural language\ninstruction (e.g., \"Go to the living room and get the nearest pillow to the\nradio art on the wall\") and generates a segmentation mask for the target\neveryday object. The task is challenging because it requires (1) the\nunderstanding of the referring expressions for multiple objects in the\ninstruction, (2) the prediction of the target phrase of the sentence among the\nmultiple phrases, and (3) the generation of pixel-wise segmentation masks\nrather than bounding boxes. Studies have been conducted on languagebased\nsegmentation methods; however, they sometimes mask irrelevant regions for\ncomplex sentences. In this paper, we propose the Multimodal Diffusion\nSegmentation Model (MDSM), which generates a mask in the first stage and\nrefines it in the second stage. We introduce a crossmodal parallel feature\nextraction mechanism and extend diffusion probabilistic models to handle\ncrossmodal features. To validate our model, we built a new dataset based on the\nwell-known Matterport3D and REVERIE datasets. This dataset consists of\ninstructions with complex referring expressions accompanied by real indoor\nenvironmental images that feature various target objects, in addition to\npixel-wise segmentation masks. The performance of MDSM surpassed that of the\nbaseline method by a large margin of +10.13 mean IoU.",
        "translated": "在这项研究中，我们的目标是开发一个能够理解自然语言指令的模型(例如，“去客厅，找到离墙上的收音机艺术品最近的枕头”) ，并为目标日常对象生成一个分割面具。这项任务具有挑战性，因为它需要(1)理解指令中多个对象的指称表达式，(2)在多个短语中预测句子的目标短语，以及(3)生成像素分割掩码而不是边界框。基于语言的分割方法已经得到了研究，但是，它们有时会掩盖复杂句子中不相关的区域。本文提出了多模态扩散分割模型(MDSM) ，在第一阶段生成掩模，在第二阶段对掩模进行细化。提出了一种交叉模式并行特征提取机制，扩展了扩散概率模型来处理交叉模式特征。为了验证我们的模型，我们基于众所周知的 Matterport3D 和 REVERIE 数据集构建了一个新的数据集。这个数据集包括指令与复杂的参考表达式伴随着真实的室内环境图像，特征各种目标对象，除了像素分割掩码。结果表明，MDSM 方法的平均输入量大大超过基线方法 + 10.13的平均输入量。"
    },
    {
        "title": "Syntax-Aware Complex-Valued Neural Machine Translation",
        "url": "http://arxiv.org/abs/2307.08586v1",
        "pub_date": "2023-07-17",
        "summary": "Syntax has been proven to be remarkably effective in neural machine\ntranslation (NMT). Previous models obtained syntax information from syntactic\nparsing tools and integrated it into NMT models to improve translation\nperformance. In this work, we propose a method to incorporate syntax\ninformation into a complex-valued Encoder-Decoder architecture. The proposed\nmodel jointly learns word-level and syntax-level attention scores from the\nsource side to the target side using an attention mechanism. Importantly, it is\nnot dependent on specific network architectures and can be directly integrated\ninto any existing sequence-to-sequence (Seq2Seq) framework. The experimental\nresults demonstrate that the proposed method can bring significant improvements\nin BLEU scores on two datasets. In particular, the proposed method achieves a\ngreater improvement in BLEU scores in translation tasks involving language\npairs with significant syntactic differences.",
        "translated": "语法在神经机器翻译(NMT)中已被证明是非常有效的。先前的模型从句法分析工具中获取语法信息，并将其集成到 NMT 模型中以提高翻译性能。在这项工作中，我们提出了一种方法来合并语法信息到一个复数值编解码器的体系结构。该模型利用注意机制从源端到目标端联合学习词水平和句法水平的注意得分。重要的是，它不依赖于特定的网络架构，可以直接集成到任何现有的序列到序列(Seq2Seq)框架中。实验结果表明，该方法可以显著改善两个数据集的 BLEU 评分。特别是，该方法在涉及具有显著句法差异的语言对的翻译任务中，实现了 BLEU 分数的较大提高。"
    },
    {
        "title": "The Resume Paradox: Greater Language Differences, Smaller Pay Gaps",
        "url": "http://arxiv.org/abs/2307.08580v1",
        "pub_date": "2023-07-17",
        "summary": "Over the past decade, the gender pay gap has remained steady with women\nearning 84 cents for every dollar earned by men on average. Many studies\nexplain this gap through demand-side bias in the labor market represented\nthrough employers' job postings. However, few studies analyze potential bias\nfrom the worker supply-side. Here, we analyze the language in millions of US\nworkers' resumes to investigate how differences in workers' self-representation\nby gender compare to differences in earnings. Across US occupations, language\ndifferences between male and female resumes correspond to 11% of the variation\nin gender pay gap. This suggests that females' resumes that are semantically\nsimilar to males' resumes may have greater wage parity. However, surprisingly,\noccupations with greater language differences between male and female resumes\nhave lower gender pay gaps. A doubling of the language difference between\nfemale and male resumes results in an annual wage increase of $2,797 for the\naverage female worker. This result holds with controls for gender-biases of\nresume text and we find that per-word bias poorly describes the variance in\nwage gap. The results demonstrate that textual data and self-representation are\nvaluable factors for improving worker representations and understanding\nemployment inequities.",
        "translated": "在过去十年中，男女工资差距保持稳定，平均而言，妇女的收入相当于男子每赚1美元的84美分。许多研究通过雇主的招聘广告所代表的劳动力市场的需求方偏见来解释这种差距。然而，很少有研究分析来自工人供给方的潜在偏见。在这里，我们分析了数百万美国员工的简历中的语言，以调查员工自我表现的性别差异与收入差异之间的关系。在整个美国职业中，男性和女性简历的语言差异相当于性别薪酬差异的11% 。这表明，女性简历在语义上与男性简历相似，可能会有更大的工资平等。然而，令人惊讶的是，男女简历语言差异较大的职业性别薪酬差距较小。女性和男性简历的语言差异加倍，导致女性工人的平均年工资增加2797美元。这一结果与简历文本性别偏见的控制方法一致，并且我们发现单词偏见不能很好地描述工资差距的变化。结果表明，文本数据和自我表征是提高工人表征和理解就业不平等的有价值的因素。"
    },
    {
        "title": "Discovering collective narratives shifts in online discussions",
        "url": "http://arxiv.org/abs/2307.08541v1",
        "pub_date": "2023-07-17",
        "summary": "Narrative is a foundation of human cognition and decision making. Because\nnarratives play a crucial role in societal discourses and spread of\nmisinformation and because of the pervasive use of social media, the narrative\ndynamics on social media can have profound societal impact. Yet, systematic and\ncomputational understanding of online narratives faces critical challenge of\nthe scale and dynamics; how can we reliably and automatically extract\nnarratives from massive amount of texts? How do narratives emerge, spread, and\ndie? Here, we propose a systematic narrative discovery framework that fill this\ngap by combining change point detection, semantic role labeling (SRL), and\nautomatic aggregation of narrative fragments into narrative networks. We\nevaluate our model with synthetic and empirical data two-Twitter corpora about\nCOVID-19 and 2017 French Election. Results demonstrate that our approach can\nrecover major narrative shifts that correspond to the major events.",
        "translated": "叙事是人类认知和决策的基础。由于叙事在社会话语和错误信息的传播中发挥着至关重要的作用，并且由于社会媒体的普遍使用，社会媒体上的叙事动态可以产生深远的社会影响。然而，对网络叙事的系统性和计算性的理解面临着规模和动态性的严峻挑战; 我们如何才能可靠和自动地从大量的文本中提取叙事？故事是如何产生、传播和消亡的？在这里，我们提出了一个系统的叙述发现框架，通过结合变点检测、语义角色标注(SRL)和叙述片段自动聚合到叙述网络中来填补这一空白。我们利用综合和实证数据对模型进行评估，这些数据包括关于2019冠状病毒疾病和2017年法国大选的 twitter 语料库。结果表明，我们的方法可以恢复对应于主要事件的主要叙述转移。"
    },
    {
        "title": "Latent Jailbreak: A Benchmark for Evaluating Text Safety and Output\n  Robustness of Large Language Models",
        "url": "http://arxiv.org/abs/2307.08487v1",
        "pub_date": "2023-07-17",
        "summary": "Researchers have invested considerable effort into ensuring that large\nlanguage models (LLMs) align with human values, using various training\ntechniques, such as instruction tuning and Reinforcement Learning from Human or\nAI Feedback (RLHF/RLAIF), to guard against text unsafety. However, these\ndefenses remain incredibly vulnerable to some jailbreak attacks, which can\ncause the model to become overly defensive to sensitive topics or still\ngenerate harmful content, leaving the model performance particularly fragile.\nTherefore, to comprehensively study text safety and output robustness, we\npropose a latent jailbreak prompt dataset, each involving malicious instruction\nembedding. Specifically, we instruct the model to complete a regular task, such\nas translation, where the text to be translated contains malicious\ninstructions. To further analyze the safety and robustness, we design a\nhierarchical annotation framework. We present a systematic analysis of the\nsafety and robustness of LLMs concerning the position of explicit normal\ninstructions, word replacement (verbs in explicit normal instructions, target\ngroups in malicious instructions, cue words in malicious instructions), and\ninstruction replacement (different explicit normal instructions). Our results\nshow that current LLMs not only have a preference for certain instruction\nverbs, but also exhibit different jailbreak rates for different instruction\nverbs in explicit normal instructions. In other words, the probability of\ngenerating unsafe content by the model will be reinforced to varying degrees\ndepending on the instruction verb in explicit normal instructions. Code and\ndata are available at https://github.com/qiuhuachuan/latent-jailbreak.",
        "translated": "研究人员投入了大量精力来确保大型语言模型(LLMs)与人类价值观保持一致，使用各种训练技术，如指令调优和人工或人工智能反馈(Human or AI Feeback，RLHF/RLAIF)的强化学习，以防止文本不安全。然而，这些防御系统在一些越狱攻击面前仍然非常脆弱，这可能导致模型对敏感话题过度防御，或者仍然生成有害的内容，使得模型的性能特别脆弱。因此，为了全面研究文本安全性和输出鲁棒性，我们提出了一个潜在的越狱提示数据集，每个数据集都包含恶意指令嵌入。具体来说，我们指示模型完成一个常规任务，比如翻译，其中要翻译的文本包含恶意指令。为了进一步分析其安全性和鲁棒性，我们设计了一个层次化的注释框架。我们对 LLM 的安全性和鲁棒性进行了系统的分析，涉及显式正常指令的位置，单词替换(显式正常指令中的动词，恶意指令中的目标组，恶意指令中的提示词)和指令替换(不同的显式正常指令)。结果表明，当前的 LLM 不仅对某些指令动词有偏好，而且对不同指令动词在显式正规指令中的越狱率也有所不同。换句话说，该模型生成不安全内容的可能性将根据显式规范指令中的指令动词而不同程度地增强。代码和数据可在 https://github.com/qiuhuachuan/latent-jailbreak 查阅。"
    },
    {
        "title": "Deep Neural Aggregation for Recommending Items to Group of Users",
        "url": "http://arxiv.org/abs/2307.09447v1",
        "pub_date": "2023-07-18",
        "summary": "Modern society devotes a significant amount of time to digital interaction.\nMany of our daily actions are carried out through digital means. This has led\nto the emergence of numerous Artificial Intelligence tools that assist us in\nvarious aspects of our lives. One key tool for the digital society is\nRecommender Systems, intelligent systems that learn from our past actions to\npropose new ones that align with our interests. Some of these systems have\nspecialized in learning from the behavior of user groups to make\nrecommendations to a group of individuals who want to perform a joint task. In\nthis article, we analyze the current state of Group Recommender Systems and\npropose two new models that use emerging Deep Learning architectures.\nExperimental results demonstrate the improvement achieved by employing the\nproposed models compared to the state-of-the-art models using four different\ndatasets. The source code of the models, as well as that of all the experiments\nconducted, is available in a public repository.",
        "translated": "现代社会在数字互动上投入了大量的时间。我们的许多日常行动是通过数字手段进行的。这导致了许多人工智能工具的出现，这些工具可以在我们生活的各个方面帮助我们。数字社会的一个关键工具是推荐系统，这种智能系统从我们过去的行为中吸取教训，提出符合我们利益的新建议。其中一些系统专门从用户群体的行为中学习，以便向希望执行联合任务的个人群体提出建议。在本文中，我们分析了组推荐系统的现状，并提出了两个新的模型，使用新兴的深度学习架构。实验结果表明，与使用四个不同数据集的最新模型相比，采用所提出的模型可以取得更好的效果。模型的源代码以及所有实验的源代码都可以在公共存储库中获得。"
    },
    {
        "title": "Zero-shot Query Reformulation for Conversational Search",
        "url": "http://arxiv.org/abs/2307.09384v1",
        "pub_date": "2023-07-18",
        "summary": "As the popularity of voice assistants continues to surge, conversational\nsearch has gained increased attention in Information Retrieval. However, data\nsparsity issues in conversational search significantly hinder the progress of\nsupervised conversational search methods. Consequently, researchers are\nfocusing more on zero-shot conversational search approaches. Nevertheless,\nexisting zero-shot methods face three primary limitations: they are not\nuniversally applicable to all retrievers, their effectiveness lacks sufficient\nexplainability, and they struggle to resolve common conversational ambiguities\ncaused by omission. To address these limitations, we introduce a novel\nZero-shot Query Reformulation (ZeQR) framework that reformulates queries based\non previous dialogue contexts without requiring supervision from conversational\nsearch data. Specifically, our framework utilizes language models designed for\nmachine reading comprehension tasks to explicitly resolve two common\nambiguities: coreference and omission, in raw queries. In comparison to\nexisting zero-shot methods, our approach is universally applicable to any\nretriever without additional adaptation or indexing. It also provides greater\nexplainability and effectively enhances query intent understanding because\nambiguities are explicitly and proactively resolved. Through extensive\nexperiments on four TREC conversational datasets, we demonstrate the\neffectiveness of our method, which consistently outperforms state-of-the-art\nbaselines.",
        "translated": "随着语音助手越来越受欢迎，对话搜索在信息检索中也得到了越来越多的关注。然而，会话搜索中的数据稀疏问题严重阻碍了监督会话搜索方法的发展。因此，研究人员更多地关注于零拍会话搜索方法。然而，现有的“零打击”方法存在三个主要的局限性: 它们不能普遍适用于所有检索器; 它们的有效性缺乏足够的解释性; 以及它们难以解决由于省略造成的常见会话模糊。为了解决这些局限性，我们引入了一个新的 Zero-shot 查询重构(ZeQR)框架，该框架基于以前的对话上下文重构查询，而不需要对会话搜索数据进行监督。具体来说，我们的框架利用为机器阅读理解任务设计的语言模型，明确地解决了原始查询中两个常见的歧义: 共引用和省略。与现有的零拍摄方法相比，我们的方法是普遍适用于任何检索没有额外的自适应或索引。它还提供了更大的可解释性，并有效地增强了查询意图的理解，因为歧义是显式和主动解决的。通过对四个 TREC 会话数据集的大量实验，我们证明了该方法的有效性，它始终优于最先进的基线。"
    },
    {
        "title": "ESMC: Entire Space Multi-Task Model for Post-Click Conversion Rate via\n  Parameter Constraint",
        "url": "http://arxiv.org/abs/2307.09193v1",
        "pub_date": "2023-07-18",
        "summary": "Large-scale online recommender system spreads all over the Internet being in\ncharge of two basic tasks: Click-Through Rate (CTR) and Post-Click Conversion\nRate (CVR) estimations. However, traditional CVR estimators suffer from\nwell-known Sample Selection Bias and Data Sparsity issues. Entire space models\nwere proposed to address the two issues via tracing the decision-making path of\n\"exposure_click_purchase\". Further, some researchers observed that there are\npurchase-related behaviors between click and purchase, which can better draw\nthe user's decision-making intention and improve the recommendation\nperformance. Thus, the decision-making path has been extended to\n\"exposure_click_in-shop action_purchase\" and can be modeled with conditional\nprobability approach. Nevertheless, we observe that the chain rule of\nconditional probability does not always hold. We report Probability Space\nConfusion (PSC) issue and give a derivation of difference between ground-truth\nand estimation mathematically. We propose a novel Entire Space Multi-Task Model\nfor Post-Click Conversion Rate via Parameter Constraint (ESMC) and two\nalternatives: Entire Space Multi-Task Model with Siamese Network (ESMS) and\nEntire Space Multi-Task Model in Global Domain (ESMG) to address the PSC issue.\nSpecifically, we handle \"exposure_click_in-shop action\" and \"in-shop\naction_purchase\" separately in the light of characteristics of in-shop action.\nThe first path is still treated with conditional probability while the second\none is treated with parameter constraint strategy. Experiments on both offline\nand online environments in a large-scale recommendation system illustrate the\nsuperiority of our proposed methods over state-of-the-art models. The\nreal-world datasets will be released.",
        "translated": "大规模的在线推荐系统遍布整个互联网，负责两个基本任务: 点进率(ctrr)和点击后转换率(CVR)估算。然而，传统的 CVR 估计受到众所周知的样本选择偏差和数据稀疏问题。整个空间模型通过追踪“曝光-点击-购买”的决策路径来解决这两个问题。此外，一些研究者发现点击和购买之间存在着购买相关行为，这种行为可以更好地提取用户的决策意图，提高推荐性能。因此，决策路径已经扩展到“曝光 _ click _ in-shop action _ buy”，并且可以用条件概率方法进行建模。然而，我们观察到条件概率的连锁规则并不总是成立。我们报告了概率空间混淆(pSC)问题，并从数学上推导出地面真实度和估计之间的差异。针对 PSC 问题，提出了一种新的基于参数约束的全空间多任务模型(ESMC)和两种替代方案: 基于暹罗网络的全空间多任务模型(ESMS)和基于全局域的全空间多任务模型(ESMG)。具体来说，我们根据店内操作的特点分别处理“曝光 _ 点击 _ 店内操作”和“店内操作 _ 购买”。第一个路径仍然用条件概率处理，而第二个路径用参数约束策略处理。在一个大规模推荐系统的离线和在线环境中的实验表明了我们提出的方法相对于最先进的模型的优越性。真实世界的数据集将被发布。"
    },
    {
        "title": "Jean-Luc Picard at Touché 2023: Comparing Image Generation, Stance\n  Detection and Feature Matching for Image Retrieval for Arguments",
        "url": "http://arxiv.org/abs/2307.09172v1",
        "pub_date": "2023-07-18",
        "summary": "Participating in the shared task \"Image Retrieval for arguments\", we used\ndifferent pipelines for image retrieval containing Image Generation, Stance\nDetection, Preselection and Feature Matching. We submitted four different runs\nwith different pipeline layout and compare them to given baseline. Our\npipelines perform similarly to the baseline.",
        "translated": "参与共享任务“参数的图像检索”，我们使用不同的管道进行图像检索，包括图像生成、姿态检测、预选和特征匹配。我们提交了四个不同的运行与不同的管道布局，并比较他们给定的基线。我们的管道执行与基线类似的操作。"
    },
    {
        "title": "Modeling Orders of User Behaviors via Differentiable Sorting: A\n  Multi-task Framework to Predicting User Post-click Conversion",
        "url": "http://arxiv.org/abs/2307.09089v1",
        "pub_date": "2023-07-18",
        "summary": "User post-click conversion prediction is of high interest to researchers and\ndevelopers. Recent studies employ multi-task learning to tackle the selection\nbias and data sparsity problem, two severe challenges in post-click behavior\nprediction, by incorporating click data. However, prior works mainly focused on\npointwise learning and the orders of labels (i.e., click and post-click) are\nnot well explored, which naturally poses a listwise learning problem. Inspired\nby recent advances on differentiable sorting, in this paper, we propose a novel\nmulti-task framework that leverages orders of user behaviors to predict user\npost-click conversion in an end-to-end approach. Specifically, we define an\naggregation operator to combine predicted outputs of different tasks to a\nunified score, then we use the computed scores to model the label relations via\ndifferentiable sorting. Extensive experiments on public and industrial datasets\nshow the superiority of our proposed model against competitive baselines.",
        "translated": "用户点击后的转换预测是研究人员和开发人员非常感兴趣的。最近的研究采用多任务学习来解决选择偏差和数据稀疏问题，这两个严峻的挑战后点击行为预测，通过整合点击数据。然而，以前的作品主要集中在点式学习和标签的顺序(即，点击和后点击)没有很好的探索，这自然造成了一个列表式学习问题。受可微分排序最新进展的启发，本文提出了一种新的多任务框架，该框架利用用户行为的顺序来预测端到端的用户点击后转换。具体来说，我们定义了一个聚合算子，将不同任务的预测输出结合到一个统一的得分中，然后使用计算得到的得分通过可微排序来建模标签关系。在公共和工业数据集上的大量实验表明了我们提出的模型对竞争基线的优越性。"
    },
    {
        "title": "Overthinking the Truth: Understanding how Language Models Process False\n  Demonstrations",
        "url": "http://arxiv.org/abs/2307.09476v1",
        "pub_date": "2023-07-18",
        "summary": "Modern language models can imitate complex patterns through few-shot\nlearning, enabling them to complete challenging tasks without fine-tuning.\nHowever, imitation can also lead models to reproduce inaccuracies or harmful\ncontent if present in the context. We study harmful imitation through the lens\nof a model's internal representations, and identify two related phenomena:\noverthinking and false induction heads. The first phenomenon, overthinking,\nappears when we decode predictions from intermediate layers, given correct vs.\nincorrect few-shot demonstrations. At early layers, both demonstrations induce\nsimilar model behavior, but the behavior diverges sharply at some \"critical\nlayer\", after which the accuracy given incorrect demonstrations progressively\ndecreases. The second phenomenon, false induction heads, are a possible\nmechanistic cause of overthinking: these are heads in late layers that attend\nto and copy false information from previous demonstrations, and whose ablation\nreduces overthinking. Beyond scientific understanding, our results suggest that\nstudying intermediate model computations could be a promising avenue for\nunderstanding and guarding against harmful model behaviors.",
        "translated": "现代语言模型可以通过少量的学习来模仿复杂的模式，使它们能够在不进行微调的情况下完成具有挑战性的任务。然而，模仿也可能导致模型复制不准确或有害的内容，如果存在于上下文中。我们通过模型内部表征的透镜来研究有害的模仿，并识别出两个相关的现象: 过度思考和错误的归纳头。第一个现象，过度思考，出现在我们从中间层解码预测时，给出正确的和不正确的少数几个镜头的演示。在早期阶段，两个演示都诱发了相似的模型行为，但是在某个“关键层”行为发生了急剧的分歧，在此之后，给出的不正确演示的准确性逐渐降低。第二种现象，错误的归纳头，是过度思考的一个可能的机械原因: 这些头处于后期层次，参与并复制来自先前演示的错误信息，它们的消融减少了过度思考。除了科学的理解，我们的研究结果表明，研究中间模型计算可能是一个有前途的途径，理解和防止有害的模型行为。"
    },
    {
        "title": "ChatSpot: Bootstrapping Multimodal LLMs via Precise Referring\n  Instruction Tuning",
        "url": "http://arxiv.org/abs/2307.09474v1",
        "pub_date": "2023-07-18",
        "summary": "Human-AI interactivity is a critical aspect that reflects the usability of\nmultimodal large language models (MLLMs). However, existing end-to-end MLLMs\nonly allow users to interact with them through language instructions, leading\nto the limitation of the interactive accuracy and efficiency. In this study, we\npresent precise referring instructions that utilize diverse reference\nrepresentations such as points and boxes as referring prompts to refer to the\nspecial region. This enables MLLMs to focus on the region of interest and\nachieve finer-grained interaction. Based on precise referring instruction, we\npropose ChatSpot, a unified end-to-end multimodal large language model that\nsupports diverse forms of interactivity including mouse clicks, drag-and-drop,\nand drawing boxes, which provides a more flexible and seamless interactive\nexperience. We also construct a multi-grained vision-language\ninstruction-following dataset based on existing datasets and GPT-4 generating.\nFurthermore, we design a series of evaluation tasks to assess the effectiveness\nof region recognition and interaction. Experimental results showcase ChatSpot's\npromising performance.",
        "translated": "人机交互是反映多模态大语言模型(MLLM)可用性的一个重要方面。然而，现有的端到端 MLLM 仅允许用户通过语言指令与其交互，从而限制了交互的准确性和效率。在这项研究中，我们提出了精确的参考指令，利用不同的参考表示，如点和框作为参考提示指特殊区域。这使得 MLLM 能够专注于感兴趣的区域并实现更细粒度的交互。在精确引用指令的基础上，我们提出了 ChatSpot，一个统一的端到端多通道大型语言模型，支持多种形式的交互，包括鼠标点击、拖放和绘图框，它提供了更加灵活和无缝的交互体验。在已有数据集和 GPT-4生成的基础上，构建了一个多粒度的视觉语言指令跟踪数据集。此外，我们设计了一系列的评估任务来评估区域识别和交互的有效性。实验结果展示了 ChatSpot 良好的性能。"
    },
    {
        "title": "A comparative analysis of SRGAN models",
        "url": "http://arxiv.org/abs/2307.09456v2",
        "pub_date": "2023-07-18",
        "summary": "In this study, we evaluate the performance of multiple state-of-the-art SRGAN\n(Super Resolution Generative Adversarial Network) models, ESRGAN, Real-ESRGAN\nand EDSR, on a benchmark dataset of real-world images which undergo degradation\nusing a pipeline. Our results show that some models seem to significantly\nincrease the resolution of the input images while preserving their visual\nquality, this is assessed using Tesseract OCR engine. We observe that EDSR-BASE\nmodel from huggingface outperforms the remaining candidate models in terms of\nboth quantitative metrics and subjective visual quality assessments with least\ncompute overhead. Specifically, EDSR generates images with higher peak\nsignal-to-noise ratio (PSNR) and structural similarity index (SSIM) values and\nare seen to return high quality OCR results with Tesseract OCR engine. These\nfindings suggest that EDSR is a robust and effective approach for single-image\nsuper-resolution and may be particularly well-suited for applications where\nhigh-quality visual fidelity is critical and optimized compute.",
        "translated": "在这项研究中，我们评估了多个最先进的 SRGAN (超分辨率生成对抗网络)模型的性能，ESRGAN，Real-esrGAN 和 EDSR，在一个基准数据集的真实世界的图像经历了使用管道的退化。我们的结果表明，一些模型似乎显着提高分辨率的输入图像，同时保持其视觉质量，这是评估使用 Tesseract OCR 引擎。我们观察到来自拥抱脸的 EDSR-BASE 模型在定量指标和主观视觉质量评估方面都优于其他候选模型，计算开销最小。具体来说，EDSR 生成的图像具有更高的峰值信噪比(pSNR)和结构相似性指数(SSIM)值，并被视为能够使用 Tesseract 光学字符识别引擎返回高质量的光学字符识别结果。这些发现表明，EDSR 是一个健壮的和有效的方法为单一图像超分辨率，可能特别适合于高品质的视觉保真度是关键和优化计算的应用程序。"
    },
    {
        "title": "Pseudo Outlier Exposure for Out-of-Distribution Detection using\n  Pretrained Transformers",
        "url": "http://arxiv.org/abs/2307.09455v2",
        "pub_date": "2023-07-18",
        "summary": "For real-world language applications, detecting an out-of-distribution (OOD)\nsample is helpful to alert users or reject such unreliable samples. However,\nmodern over-parameterized language models often produce overconfident\npredictions for both in-distribution (ID) and OOD samples. In particular,\nlanguage models suffer from OOD samples with a similar semantic representation\nto ID samples since these OOD samples lie near the ID manifold. A rejection\nnetwork can be trained with ID and diverse outlier samples to detect test OOD\nsamples, but explicitly collecting auxiliary OOD datasets brings an additional\nburden for data collection. In this paper, we propose a simple but effective\nmethod called Pseudo Outlier Exposure (POE) that constructs a surrogate OOD\ndataset by sequentially masking tokens related to ID classes. The surrogate OOD\nsample introduced by POE shows a similar representation to ID data, which is\nmost effective in training a rejection network. Our method does not require any\nexternal OOD data and can be easily implemented within off-the-shelf\nTransformers. A comprehensive comparison with state-of-the-art algorithms\ndemonstrates POE's competitiveness on several text classification benchmarks.",
        "translated": "对于真实世界的语言应用程序，检测分布外(OOD)样本有助于警告用户或拒绝这种不可靠的样本。然而，现代过度参数化的语言模型通常会对分布式样本(ID)和面向对象设计样本(OOD)产生过度自信的预测。特别是，语言模型受到与 ID 示例具有类似语义表示的 OOD 示例的影响，因为这些 OOD 示例位于 ID 流形附近。一个拒绝网络可以训练 ID 和不同的异常样本来检测测试 OOD 样本，但是显式地收集辅助 OOD 数据集会给数据收集带来额外的负担。本文提出了一种简单而有效的伪异常暴露方法，该方法通过顺序屏蔽与 ID 类相关的令牌来构造代理 OOD 数据集。POE 引入的代理 OOD 样本显示了与 ID 数据类似的表示，这在训练拒绝网络中是最有效的。我们的方法不需要任何外部 OOD 数据，可以很容易地在现成的变压器内实现。与最先进的算法进行了全面的比较，证明了 POE 在几个文本分类基准上的竞争力。"
    },
    {
        "title": "Let's ViCE! Mimicking Human Cognitive Behavior in Image Generation\n  Evaluation",
        "url": "http://arxiv.org/abs/2307.09416v2",
        "pub_date": "2023-07-18",
        "summary": "Research in Image Generation has recently made significant progress,\nparticularly boosted by the introduction of Vision-Language models which are\nable to produce high-quality visual content based on textual inputs. Despite\nongoing advancements in terms of generation quality and realism, no methodical\nframeworks have been defined yet to quantitatively measure the quality of the\ngenerated content and the adherence with the prompted requests: so far, only\nhuman-based evaluations have been adopted for quality satisfaction and for\ncomparing different generative methods. We introduce a novel automated method\nfor Visual Concept Evaluation (ViCE), i.e. to assess consistency between a\ngenerated/edited image and the corresponding prompt/instructions, with a\nprocess inspired by the human cognitive behaviour. ViCE combines the strengths\nof Large Language Models (LLMs) and Visual Question Answering (VQA) into a\nunified pipeline, aiming to replicate the human cognitive process in quality\nassessment. This method outlines visual concepts, formulates image-specific\nverification questions, utilizes the Q&amp;A system to investigate the image, and\nscores the combined outcome. Although this brave new hypothesis of mimicking\nhumans in the image evaluation process is in its preliminary assessment stage,\nresults are promising and open the door to a new form of automatic evaluation\nwhich could have significant impact as the image generation or the image target\nediting tasks become more and more sophisticated.",
        "translated": "图像生成方面的研究最近取得了重大进展，特别是由于引入了视觉语言模型，这些模型能够基于文本输入生成高质量的视觉内容。尽管在生成质量和现实性方面不断取得进展，但尚未确定任何方法框架来定量衡量生成内容的质量和遵守提出的要求的情况: 迄今为止，只采用了基于人的评价，以满足质量要求和比较不同的生成方法。本文介绍了一种新的视觉概念评价(ViCE)的自动化方法，即通过人类认知行为启发的过程来评价生成/编辑的图像与相应的提示/指令之间的一致性。ViCE 将大语言模型(LLM)和可视化问答(VQA)的优势结合成一个统一的流水线，旨在复制质量评估中的人类认知过程。这种方法概述了视觉概念，制定了图像特定的验证问题，利用问答系统调查图像，并得分的综合结果。虽然这个在图像评估过程中模仿人类的大胆新假设还处于初步评估阶段，但是结果是有希望的，并且打开了一种新的自动评估形式的大门，随着图像生成或图像目标编辑任务变得越来越复杂，这种自动评估形式可能会产生重大影响。"
    },
    {
        "title": "Multi-Modal Discussion Transformer: Integrating Text, Images and Graph\n  Transformers to Detect Hate Speech on Social Media",
        "url": "http://arxiv.org/abs/2307.09312v1",
        "pub_date": "2023-07-18",
        "summary": "We present the Multi-Modal Discussion Transformer (mDT), a novel multi-modal\ngraph-based transformer model for detecting hate speech in online social\nnetworks. In contrast to traditional text-only methods, our approach to\nlabelling a comment as hate speech centers around the holistic analysis of text\nand images. This is done by leveraging graph transformers to capture the\ncontextual relationships in the entire discussion that surrounds a comment,\nwith interwoven fusion layers to combine text and image embeddings instead of\nprocessing different modalities separately. We compare the performance of our\nmodel to baselines that only process text; we also conduct extensive ablation\nstudies. We conclude with future work for multimodal solutions to deliver\nsocial value in online contexts, arguing that capturing a holistic view of a\nconversation greatly advances the effort to detect anti-social behavior.",
        "translated": "提出了一种新的基于多模态图的在线社交网络仇恨语音检测模型——多模态讨论转换器(mDT)。与传统的纯文本方法相反，我们将评论标记为仇恨言论的方法围绕着对文本和图像的整体分析。这是通过利用图形转换器来捕获围绕评论的整个讨论中的上下文关系，使用交织的融合层来结合文本和图像嵌入，而不是分别处理不同的模式。我们将模型的性能与只处理文本的基线进行比较; 我们还进行了广泛的消融研究。最后，我们总结了未来多模式解决方案在网络环境中传递社会价值的工作，认为捕捉对话的整体视角大大促进了检测反社会行为的努力。"
    },
    {
        "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models",
        "url": "http://arxiv.org/abs/2307.09288v2",
        "pub_date": "2023-07-18",
        "summary": "In this work, we develop and release Llama 2, a collection of pretrained and\nfine-tuned large language models (LLMs) ranging in scale from 7 billion to 70\nbillion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for\ndialogue use cases. Our models outperform open-source chat models on most\nbenchmarks we tested, and based on our human evaluations for helpfulness and\nsafety, may be a suitable substitute for closed-source models. We provide a\ndetailed description of our approach to fine-tuning and safety improvements of\nLlama 2-Chat in order to enable the community to build on our work and\ncontribute to the responsible development of LLMs.",
        "translated": "在这项工作中，我们开发并发布了 Llama2，这是一个经过预先训练和微调的大型语言模型(LLM)的集合，范围从70亿到700亿个参数。我们的微调 LLM (称为 Llama2-Chat)针对对话用例进行了优化。在我们测试的大多数基准测试中，我们的模型表现优于开源聊天模型，而且基于我们对有用性和安全性的人工评估，它可能是封闭源模型的合适替代品。我们详细介绍了我们对美洲驼2-Chat 进行微调和安全改进的方法，以使社区能够在我们的工作基础上，为美洲驼2-Chat 的负责任发展做出贡献。"
    },
    {
        "title": "Improving Text Semantic Similarity Modeling through a 3D Siamese Network",
        "url": "http://arxiv.org/abs/2307.09274v1",
        "pub_date": "2023-07-18",
        "summary": "Siamese networks have gained popularity as a method for modeling text\nsemantic similarity. Traditional methods rely on pooling operation to compress\nthe semantic representations from Transformer blocks in encoding, resulting in\ntwo-dimensional semantic vectors and the loss of hierarchical semantic\ninformation from Transformer blocks. Moreover, this limited structure of\nsemantic vectors is akin to a flattened landscape, which restricts the methods\nthat can be applied in downstream modeling, as they can only navigate this flat\nterrain. To address this issue, we propose a novel 3D Siamese network for text\nsemantic similarity modeling, which maps semantic information to a\nhigher-dimensional space. The three-dimensional semantic tensors not only\nretains more precise spatial and feature domain information but also provides\nthe necessary structural condition for comprehensive downstream modeling\nstrategies to capture them. Leveraging this structural advantage, we introduce\nseveral modules to reinforce this 3D framework, focusing on three aspects:\nfeature extraction, attention, and feature fusion. Our extensive experiments on\nfour text semantic similarity benchmarks demonstrate the effectiveness and\nefficiency of our 3D Siamese Network.",
        "translated": "暹罗网络作为一种文本语义相似度建模方法已经得到了广泛的应用。传统的方法依赖于合用操作来压缩编码过程中来自 Transformer 块的语义表示，这会导致二维语义向量，并且会丢失来自 Transformer 块的分层语义信息。此外，这种有限的语义向量结构类似于一个平坦的地形，这限制了可以应用于下游建模的方法，因为它们只能在这个平坦的地形中导航。为了解决这个问题，我们提出了一个新的3D 暹罗网络文本语义相似度建模，它映射语义信息到一个更高维的空间。三维语义张量不仅保留了更精确的空间和特征域信息，而且为下游综合建模策略提供了必要的结构条件。利用这一结构优势，我们引入了几个模块来加强这一三维框架，重点放在三个方面: 特征提取、注意力和特征融合。我们在四个文本语义相似度基准上的广泛实验证明了我们的3D 暹罗网络的有效性和效率。"
    },
    {
        "title": "Linearized Relative Positional Encoding",
        "url": "http://arxiv.org/abs/2307.09270v1",
        "pub_date": "2023-07-18",
        "summary": "Relative positional encoding is widely used in vanilla and linear\ntransformers to represent positional information. However, existing encoding\nmethods of a vanilla transformer are not always directly applicable to a linear\ntransformer, because the latter requires a decomposition of the query and key\nrepresentations into separate kernel functions. Nevertheless, principles for\ndesigning encoding methods suitable for linear transformers remain\nunderstudied. In this work, we put together a variety of existing linear\nrelative positional encoding approaches under a canonical form and further\npropose a family of linear relative positional encoding algorithms via unitary\ntransformation. Our formulation leads to a principled framework that can be\nused to develop new relative positional encoding methods that preserve linear\nspace-time complexity. Equipped with different models, the proposed linearized\nrelative positional encoding (LRPE) family derives effective encoding for\nvarious applications. Experiments show that compared with existing methods,\nLRPE achieves state-of-the-art performance in language modeling, text\nclassification, and image classification. Meanwhile, it emphasizes a general\nparadigm for designing broadly more relative positional encoding methods that\nare applicable to linear transformers. The code is available at\nhttps://github.com/OpenNLPLab/Lrpe.",
        "translated": "相对位置编码广泛应用于普通变换器和线性变换器中，用于表示位置信息。然而，普通变换器的现有编码方法并不总是直接适用于线性变换器，因为后者需要将查询和键表示分解为单独的内核函数。然而，设计适用于线性变压器的编码方法的原则仍然没有得到充分的研究。在这项工作中，我们把各种现有的线性相对位置编码方法放在一个规范形式下，并进一步提出了一系列线性相对位置编码算法通过幺正。我们的公式导致了一个原则性的框架，可以用来开发新的相对位置编码方法，保持线性时空复杂度。本文提出的线性化相对位置编码(LRPE)族在不同模型的配置下，得到了适用于各种应用场合的有效编码。实验表明，与现有方法相比，LRPE 在语言建模、文本分类和图像分类等方面取得了较好的性能。同时，强调了设计更广泛的适用于线性变压器的相对位置编码方法的一般范例。密码可在 https://github.com/opennlplab/lrpe 查阅。"
    },
    {
        "title": "UniMatch: A Unified User-Item Matching Framework for the Multi-purpose\n  Merchant Marketing",
        "url": "http://arxiv.org/abs/2307.09989v1",
        "pub_date": "2023-07-19",
        "summary": "When doing private domain marketing with cloud services, the merchants\nusually have to purchase different machine learning models for the multiple\nmarketing purposes, leading to a very high cost. We present a unified user-item\nmatching framework to simultaneously conduct item recommendation and user\ntargeting with just one model. We empirically demonstrate that the above\nconcurrent modeling is viable via modeling the user-item interaction matrix\nwith the multinomial distribution, and propose a bidirectional bias-corrected\nNCE loss for the implementation. The proposed loss function guides the model to\nlearn the user-item joint probability $p(u,i)$ instead of the conditional\nprobability $p(i|u)$ or $p(u|i)$ through correcting both the users and items'\nbiases caused by the in-batch negative sampling. In addition, our framework is\nmodel-agnostic enabling a flexible adaptation of different model architectures.\nExtensive experiments demonstrate that our framework results in significant\nperformance gains in comparison with the state-of-the-art methods, with greatly\nreduced cost on computing resources and daily maintenance.",
        "translated": "在使用云服务进行私有领域营销时，商家通常需要购买不同的机器学习模型，以满足多种营销目的，从而导致非常高的成本。我们提出了一个统一的用户项目匹配框架，同时进行项目推荐和用户定位只有一个模型。通过对多项式分布的用户-项目交互矩阵进行建模，实验表明上述并行建模是可行的，并提出了一种双向偏差修正的 NCE 损失实现方法。提出的损失函数指导模型通过修正批内负抽样引起的用户和物品的偏差来学习用户-物品联合概率 $p (u，i) $，而不是条件概率的 $p (i | u) $或 $p (u | i) $。此外，我们的框架是模型无关的，可以灵活地适应不同的模型架构。大量的实验表明，与最先进的方法相比，我们的框架可以显著提高性能，大大降低了计算资源和日常维护的成本。"
    },
    {
        "title": "Our Model Achieves Excellent Performance on MovieLens: What Does it\n  Mean?",
        "url": "http://arxiv.org/abs/2307.09985v1",
        "pub_date": "2023-07-19",
        "summary": "A typical benchmark dataset for recommender system (RecSys) evaluation\nconsists of user-item interactions generated on a platform within a time\nperiod. The interaction generation mechanism partially explains why a user\ninteracts with (e.g.,like, purchase, rate) an item, and the context of when a\nparticular interaction happened. In this study, we conduct a meticulous\nanalysis on the MovieLens dataset and explain the potential impact on using the\ndataset for evaluating recommendation algorithms. We make a few main findings\nfrom our analysis. First, there are significant differences in user\ninteractions at the different stages when a user interacts with the MovieLens\nplatform. The early interactions largely define the user portrait which affect\nthe subsequent interactions. Second, user interactions are highly affected by\nthe candidate movies that are recommended by the platform's internal\nrecommendation algorithm(s). Removal of interactions that happen nearer to the\nlast few interactions of a user leads to increasing difficulty in learning user\npreference, thus deteriorating recommendation accuracy. Third, changing the\norder of user interactions makes it more difficult for sequential algorithms to\ncapture the progressive interaction process. Based on these findings, we\nfurther discuss the discrepancy between the interaction generation mechanism\nthat is employed by the MovieLens system and that of typical real world\nrecommendation scenarios. In summary, models that achieve excellent\nrecommendation accuracy on the MovieLens dataset may not demonstrate superior\nperformance in practice for at least two kinds of differences: (i) the\ndifferences in the contexts of user-item interaction generation, and (ii) the\ndifferences in user knowledge about the item collections.",
        "translated": "一个典型的推荐系统评估基准数据集(RecSys)包括在一段时间内在平台上生成的用户项目交互。交互生成机制部分地解释了用户为什么要与某个项目进行交互(例如，购买，定价) ，以及特定交互何时发生的上下文。在这项研究中，我们对 MovieLens 数据集进行了细致的分析，并解释了使用数据集评估推荐算法的潜在影响。我们从分析中得出了一些主要结论。首先，在用户与 MovieLens 平台交互的不同阶段，用户交互存在显著差异。早期的交互很大程度上定义了影响后续交互的用户肖像。其次，用户交互受到平台内部推荐算法推荐的候选电影的高度影响。删除发生在用户最后几次交互附近的交互会增加学习用户偏好的难度，从而降低推荐的准确性。第三，改变用户交互的顺序使得序列算法难以捕获渐进的交互过程。在此基础上，我们进一步讨论了 MovieLens 系统所采用的交互生成机制与真实世界中典型推荐场景的交互生成机制之间的差异。总之，在 MovieLens 数据集上实现卓越的推荐准确性的模型可能在实践中并不能表现出至少两种差异的优异性能: (i)用户项目交互生成上下文的差异，以及(ii)用户对项目集合的知识差异。"
    },
    {
        "title": "Who Provides the Largest Megaphone? The Role of Google News in Promoting\n  Russian State-Affiliated News Sources",
        "url": "http://arxiv.org/abs/2307.09834v1",
        "pub_date": "2023-07-19",
        "summary": "The Internet has not only digitized but also democratized information access\nacross the globe. This gradual but path-breaking move to online information\npropagation has resulted in search engines playing an increasingly prominent\nrole in shaping access to human knowledge. When an Internet user enters a\nquery, the search engine sorts through the hundreds of billions of possible\nwebpages to determine what to show. Google dominates the search engine market,\nwith Google Search surpassing 80% market share globally every year of the last\ndecade. Only in Russia and China do Google competitors claim more market share,\nwith approximately 60% of Internet users in Russia preferring Yandex (compared\nto 40% in favor of Google) and more than 80% of China's Internet users\naccessing Baidu as of 2022. Notwithstanding this long-standing regional\nvariation in Internet search providers, there is limited research showing how\nthese providers compare in terms of propagating state-sponsored information.\nOur study fills this research gap by focusing on Russian cyberspace and\nexamining how Google and Yandex's search algorithms rank content from Russian\nstate-controlled media (hereon, RSM) outlets. This question is timely and of\npractical interest given widespread reports indicating that RSM outlets have\nactively engaged in promoting Kremlin propaganda in the lead-up to, and in the\naftermath of, the Russian invasion of Ukraine in February 2022.",
        "translated": "互联网不仅使全球信息获取数字化，而且使其民主化。这一渐进但开创性的在线信息传播方式使得搜索引擎在形成获取人类知识的途径方面发挥着日益突出的作用。当一个互联网用户输入一个查询，搜索引擎排序通过数千亿可能的网页，以确定显示什么。谷歌在搜索引擎市场占据主导地位，在过去十年中，谷歌搜索在全球的市场份额每年都超过80% 。只有在俄罗斯和中国，谷歌的竞争对手才能获得更大的市场份额，截至2022年，俄罗斯大约60% 的互联网用户更喜欢 Yandex (相比之下，有40% 的用户支持谷歌) ，超过80% 的中国互联网用户访问百度。尽管互联网搜索提供商长期存在地区差异，但关于这些提供商在传播国家资助信息方面的比较研究有限。我们的研究通过关注俄罗斯的网络空间，以及研究谷歌和 Yandex 的搜索算法如何对俄罗斯国有媒体(以下简称 RSM)的内容进行排序，填补了这一研究空白。鉴于广泛的报道表明，俄罗斯联邦安全机构在2022年2月俄罗斯入侵乌克兰之前和之后积极参与宣传克里姆林宫的宣传活动，这个问题是及时和具有实际意义的。"
    },
    {
        "title": "DisCover: Disentangled Music Representation Learning for Cover Song\n  Identification",
        "url": "http://arxiv.org/abs/2307.09775v1",
        "pub_date": "2023-07-19",
        "summary": "In the field of music information retrieval (MIR), cover song identification\n(CSI) is a challenging task that aims to identify cover versions of a query\nsong from a massive collection. Existing works still suffer from high\nintra-song variances and inter-song correlations, due to the entangled nature\nof version-specific and version-invariant factors in their modeling. In this\nwork, we set the goal of disentangling version-specific and version-invariant\nfactors, which could make it easier for the model to learn invariant music\nrepresentations for unseen query songs. We analyze the CSI task in a\ndisentanglement view with the causal graph technique, and identify the\nintra-version and inter-version effects biasing the invariant learning. To\nblock these effects, we propose the disentangled music representation learning\nframework (DisCover) for CSI. DisCover consists of two critical components: (1)\nKnowledge-guided Disentanglement Module (KDM) and (2) Gradient-based\nAdversarial Disentanglement Module (GADM), which block intra-version and\ninter-version biased effects, respectively. KDM minimizes the mutual\ninformation between the learned representations and version-variant factors\nthat are identified with prior domain knowledge. GADM identifies\nversion-variant factors by simulating the representation transitions between\nintra-song versions, and exploits adversarial distillation for effect blocking.\nExtensive comparisons with best-performing methods and in-depth analysis\ndemonstrate the effectiveness of DisCover and the and necessity of\ndisentanglement for CSI.",
        "translated": "在音乐信息检索(MIR)领域，翻唱歌曲识别(CSI)是一项具有挑战性的任务，其目标是从大量的收藏中识别出一首查询歌曲的翻唱版本。现有作品由于版本特异性因素和版本不变性因素的纠缠性，仍然存在着高度的内部歌曲变异和内部歌曲相关性。本文设定了版本不变因子和版本不变因子的分离目标，使得模型更容易学习未知查询歌曲的不变音乐表示。本文运用因果图技术对 CSI 任务进行了解缠分析，识别出内版本效应和内版本效应对不变学习的影响。为了阻止这些效应，我们提出了一个用于 CSI 的分离音乐表征学习框架(DisCover)。DisCover 由两个关键组成部分组成: (1)知识引导的解缠模块(KDM)和(2)基于梯度的对抗性解缠模块(GADM) ，它们分别阻止内部版本效应和内部版本效应。KDM 最小化了学习表示和版本变异因子之间的相互信息，这些因子与先前的领域知识一致。GADM 通过模拟歌曲内部版本之间的表示转换来识别版本变异因素，并利用对抗精馏来阻断效果。通过与最佳方法的广泛比较和深入分析，证明了 DisCover 的有效性以及 CSI 解纠缠的必要性。"
    },
    {
        "title": "Information Retrieval Meets Large Language Models: A Strategic Report\n  from Chinese IR Community",
        "url": "http://arxiv.org/abs/2307.09751v1",
        "pub_date": "2023-07-19",
        "summary": "The research field of Information Retrieval (IR) has evolved significantly,\nexpanding beyond traditional search to meet diverse user information needs.\nRecently, Large Language Models (LLMs) have demonstrated exceptional\ncapabilities in text understanding, generation, and knowledge inference,\nopening up exciting avenues for IR research. LLMs not only facilitate\ngenerative retrieval but also offer improved solutions for user understanding,\nmodel evaluation, and user-system interactions. More importantly, the\nsynergistic relationship among IR models, LLMs, and humans forms a new\ntechnical paradigm that is more powerful for information seeking. IR models\nprovide real-time and relevant information, LLMs contribute internal knowledge,\nand humans play a central role of demanders and evaluators to the reliability\nof information services. Nevertheless, significant challenges exist, including\ncomputational costs, credibility concerns, domain-specific limitations, and\nethical considerations. To thoroughly discuss the transformative impact of LLMs\non IR research, the Chinese IR community conducted a strategic workshop in\nApril 2023, yielding valuable insights. This paper provides a summary of the\nworkshop's outcomes, including the rethinking of IR's core values, the mutual\nenhancement of LLMs and IR, the proposal of a novel IR technical paradigm, and\nopen challenges.",
        "translated": "信息检索搜索(IR)的研究领域已经发生了显著的变化，超越了传统的搜索，以满足不同的用户信息需求。最近，大语言模型(LLM)在文本理解、生成和知识推理方面展示了非凡的能力，为 IR 研究开辟了令人兴奋的途径。LLM 不仅促进了生成检索，而且为用户理解、模型评估和用户系统交互提供了改进的解决方案。更重要的是，IR 模型、 LLM 和人类之间的协同关系形成了一种新的技术范式，这种范式在信息搜索方面更加强大。IR 模型提供实时和相关的信息，LLM 提供内部知识，人在信息服务的可靠性中扮演着需求者和评估者的中心角色。尽管如此，仍然存在重大的挑战，包括计算成本、可信度问题、特定领域的局限性和伦理考虑。为了深入讨论 LLM 对国际关系研究的变革性影响，中国国际关系界于2023年4月举办了一次战略研讨会，提出了宝贵的见解。本文提供了研讨会成果的总结，包括重新思考 IR 的核心价值，LLM 和 IR 的相互增强，一个新的 IR 技术范式的提议，以及开放的挑战。"
    },
    {
        "title": "DialogStudio: Towards Richest and Most Diverse Unified Dataset\n  Collection for Conversational AI",
        "url": "http://arxiv.org/abs/2307.10172v2",
        "pub_date": "2023-07-19",
        "summary": "Despite advancements in conversational AI, language models encounter\nchallenges to handle diverse conversational tasks, and existing dialogue\ndataset collections often lack diversity and comprehensiveness. To tackle these\nissues, we introduce DialogStudio: the largest and most diverse collection of\ndialogue datasets, unified under a consistent format while preserving their\noriginal information. Our collection encompasses data from open-domain\ndialogues, task-oriented dialogues, natural language understanding,\nconversational recommendation, dialogue summarization, and knowledge-grounded\ndialogues, making it an incredibly rich and diverse resource for dialogue\nresearch and model training. To further enhance the utility of DialogStudio, we\nidentify the licenses for each dataset and design domain-aware prompts for\nselected dialogues to facilitate instruction-aware fine-tuning. Furthermore, we\ndevelop conversational AI models using the dataset collection, and our\nexperiments in both zero-shot and few-shot learning scenarios demonstrate the\nsuperiority of DialogStudio. To improve transparency and support dataset and\ntask-based research, as well as language model pre-training, all datasets,\nlicenses, codes, and models associated with DialogStudio are made publicly\naccessible at https://github.com/salesforce/DialogStudio",
        "translated": "尽管人工智能在会话方面取得了进展，但语言模型在处理不同的会话任务时仍面临挑战，现有的对话数据集往往缺乏多样性和全面性。为了解决这些问题，我们引入了 DialogStudio: 最大和最多样化的对话数据集合，统一在一致的格式下，同时保留其原始信息。我们的收集包括来自开放领域对话、任务导向对话、自然语言理解、会话推荐、对话总结和基于知识的对话的数据，使其成为对话研究和模型培训的极其丰富和多样化的资源。为了进一步增强 DialogStudio 的实用性，我们为每个数据集确定许可证，并为选定的对话设计域感知提示，以促进指令感知的微调。此外，我们利用数据集合开发了会话式人工智能模型，我们在零镜头和少镜头学习场景中的实验证明了 DialogStudio 的优越性。为了提高透明度，支持数据集和基于任务的研究，以及语言模型预训练，所有与 dialogStudio 相关的数据集、许可证、代码和模型都可以在 https://github.com/salesforce/DialogStudio 上公开获取"
    },
    {
        "title": "Challenges and Applications of Large Language Models",
        "url": "http://arxiv.org/abs/2307.10169v1",
        "pub_date": "2023-07-19",
        "summary": "Large Language Models (LLMs) went from non-existent to ubiquitous in the\nmachine learning discourse within a few years. Due to the fast pace of the\nfield, it is difficult to identify the remaining challenges and already\nfruitful application areas. In this paper, we aim to establish a systematic set\nof open problems and application successes so that ML researchers can\ncomprehend the field's current state more quickly and become productive.",
        "translated": "大语言模型(LLM)在短短几年内就从不存在变成了机器学习话语中的普遍存在。由于该领域的速度很快，很难确定剩余的挑战和已经取得丰硕成果的应用领域。在本文中，我们的目标是建立一套系统的开放问题和应用成功，使机器学习的研究人员能够更快地了解该领域的现状，并成为富有成效的。"
    },
    {
        "title": "LLMs as Workers in Human-Computational Algorithms? Replicating\n  Crowdsourcing Pipelines with LLMs",
        "url": "http://arxiv.org/abs/2307.10168v2",
        "pub_date": "2023-07-19",
        "summary": "LLMs have shown promise in replicating human-like behavior in crowdsourcing\ntasks that were previously thought to be exclusive to human abilities. However,\ncurrent efforts focus mainly on simple atomic tasks. We explore whether LLMs\ncan replicate more complex crowdsourcing pipelines. We find that modern LLMs\ncan simulate some of crowdworkers' abilities in these \"human computation\nalgorithms,\" but the level of success is variable and influenced by requesters'\nunderstanding of LLM capabilities, the specific skills required for sub-tasks,\nand the optimal interaction modality for performing these sub-tasks. We reflect\non human and LLMs' different sensitivities to instructions, stress the\nimportance of enabling human-facing safeguards for LLMs, and discuss the\npotential of training humans and LLMs with complementary skill sets. Crucially,\nwe show that replicating crowdsourcing pipelines offers a valuable platform to\ninvestigate (1) the relative strengths of LLMs on different tasks (by\ncross-comparing their performances on sub-tasks) and (2) LLMs' potential in\ncomplex tasks, where they can complete part of the tasks while leaving others\nto humans.",
        "translated": "LLM 已经显示出在众包任务中复制类似人类行为的前景，这些任务以前被认为是人类能力独有的。然而，目前的工作主要集中在简单的原子任务上。我们探讨 LLM 能否复制更复杂的众包管道。我们发现现代 LLM 可以在这些“人工计算算法”中模拟一些众包工作者的能力，但是成功的程度是可变的，并且受到请求者对 LLM 能力的理解、子任务所需的特定技能以及执行这些子任务的最佳交互方式的影响。我们反思了人类和 LLM 对指令的不同敏感性，强调了为 LLM 提供面向人类的保障的重要性，并讨论了用互补技能集培训人类和 LLM 的潜力。至关重要的是，我们表明，复制众包管道提供了一个有价值的平台来调查(1) LLM 在不同任务上的相对优势(通过交叉比较他们在子任务上的表现)和(2) LLM 在复杂任务中的潜力，在那里他们可以完成一部分任务，而把其他任务留给人类。"
    },
    {
        "title": "Exploring Transformer Extrapolation",
        "url": "http://arxiv.org/abs/2307.10156v1",
        "pub_date": "2023-07-19",
        "summary": "Length extrapolation has attracted considerable attention recently since it\nallows transformers to be tested on longer sequences than those used in\ntraining. Previous research has shown that this property can be attained by\nusing carefully designed Relative Positional Encodings (RPEs). While these\nmethods perform well on a variety of corpora, the conditions for length\nextrapolation have yet to be investigated. This paper attempts to determine\nwhat types of RPEs allow for length extrapolation through a thorough\nmathematical and empirical analysis. We discover that a transformer is certain\nto possess this property as long as the series that corresponds to the RPE's\nexponential converges. Two practices are derived from the conditions and\nexamined in language modeling tasks on a variety of corpora. As a bonus from\nthe conditions, we derive a new Theoretical Receptive Field (TRF) to measure\nthe receptive field of RPEs without taking any training steps. Extensive\nexperiments are conducted on the Wikitext-103, Books, Github, and WikiBook\ndatasets to demonstrate the viability of our discovered conditions. We also\ncompare TRF to Empirical Receptive Field (ERF) across different models, showing\nconsistently matched trends on the aforementioned datasets. The code is\navailable at https://github.com/OpenNLPLab/Rpe.",
        "translated": "长度外推最近引起了相当大的关注，因为它允许变压器在比训练中使用的更长的序列上进行测试。以往的研究表明，这一特性可以通过使用精心设计的相对位置编码(RPE)来实现。虽然这些方法在各种语料库中表现良好，但长度外推的条件仍有待研究。本文试图确定什么类型的 RPE 允许长度外推通过一个彻底的数学和实证分析。我们发现，只要对应于 RPE 指数收敛的级数，变压器就一定具有这一性质。两个实践来源于条件和检查的语言建模任务的各种语料库。作为一个额外的条件，我们推导出一个新的理论接受场(TRF) ，以测量接受领域的 RPE 没有采取任何训练步骤。在 Wikitext-103、 Books、 Github 和 WikiBook 数据集上进行了广泛的实验，以证明我们发现的条件的可行性。我们还比较了不同模型的 TRF 和经验接受场(ERF) ，在上述数据集上显示了一致匹配的趋势。密码可在 https://github.com/opennlplab/rpe 查阅。"
    },
    {
        "title": "Gradient Sparsification For Masked Fine-Tuning of Transformers",
        "url": "http://arxiv.org/abs/2307.10098v1",
        "pub_date": "2023-07-19",
        "summary": "Fine-tuning pretrained self-supervised language models is widely adopted for\ntransfer learning to downstream tasks. Fine-tuning can be achieved by freezing\ngradients of the pretrained network and only updating gradients of a newly\nadded classification layer, or by performing gradient updates on all\nparameters. Gradual unfreezing makes a trade-off between the two by gradually\nunfreezing gradients of whole layers during training. This has been an\neffective strategy to trade-off between storage and training speed with\ngeneralization performance. However, it is not clear whether gradually\nunfreezing layers throughout training is optimal, compared to sparse variants\nof gradual unfreezing which may improve fine-tuning performance. In this paper,\nwe propose to stochastically mask gradients to regularize pretrained language\nmodels for improving overall fine-tuned performance. We introduce GradDrop and\nvariants thereof, a class of gradient sparsification methods that mask\ngradients during the backward pass, acting as gradient noise. GradDrop is\nsparse and stochastic unlike gradual freezing. Extensive experiments on the\nmultilingual XGLUE benchmark with XLMR-Large show that GradDrop is competitive\nagainst methods that use additional translated data for intermediate\npretraining and outperforms standard fine-tuning and gradual unfreezing. A\npost-analysis shows how GradDrop improves performance with languages it was not\ntrained on, such as under-resourced languages.",
        "translated": "微调预训练自监督语言模型被广泛应用于向下游任务的迁移学习。微调可以通过冻结预训练网络的梯度和只更新新增分类层的梯度，或者通过对所有参数执行梯度更新来实现。在训练过程中，通过逐渐解冻整个层面的梯度，逐渐解冻在两者之间进行权衡。这是一个有效的策略，以权衡存储和训练速度与泛化性能。然而，目前还不清楚是否在整个训练过程中逐渐解冻层是最佳的，相比之下，逐渐解冻的稀疏变体可以提高微调性能。在本文中，我们提出随机掩盖梯度来规范预训练的语言模型，以提高整体的微调性能。我们介绍一类梯度稀疏化方法，它在后向通过过程中掩盖梯度，充当梯度噪声。与逐渐冻结不同，gradDrop 是稀疏和随机的。使用 XLMR-Large 对多语言 XGLUE 基准进行的大量实验表明，与使用额外的翻译数据进行中间预训练的方法相比，gradDrop 具有竞争力，并且优于标准的微调和逐步解冻。事后分析显示，GrandDrop 如何利用未经培训的语言(例如资源不足的语言)提高性能。"
    },
    {
        "title": "Android in the Wild: A Large-Scale Dataset for Android Device Control",
        "url": "http://arxiv.org/abs/2307.10088v1",
        "pub_date": "2023-07-19",
        "summary": "There is a growing interest in device-control systems that can interpret\nhuman natural language instructions and execute them on a digital device by\ndirectly controlling its user interface. We present a dataset for\ndevice-control research, Android in the Wild (AITW), which is orders of\nmagnitude larger than current datasets. The dataset contains human\ndemonstrations of device interactions, including the screens and actions, and\ncorresponding natural language instructions. It consists of 715k episodes\nspanning 30k unique instructions, four versions of Android (v10-13),and eight\ndevice types (Pixel 2 XL to Pixel 6) with varying screen resolutions. It\ncontains multi-step tasks that require semantic understanding of language and\nvisual context. This dataset poses a new challenge: actions available through\nthe user interface must be inferred from their visual appearance. And, instead\nof simple UI element-based actions, the action space consists of precise\ngestures (e.g., horizontal scrolls to operate carousel widgets). We organize\nour dataset to encourage robustness analysis of device-control systems, i.e.,\nhow well a system performs in the presence of new task descriptions, new\napplications, or new platform versions. We develop two agents and report\nperformance across the dataset. The dataset is available at\nhttps://github.com/google-research/google-research/tree/master/android_in_the_wild.",
        "translated": "设备控制系统能够解释人类自然语言指令，并通过直接控制用户界面在数字设备上执行这些指令，这引起了人们越来越多的兴趣。我们为设备控制研究提供了一个数据集，名为“荒野中的安卓”(Android in the Wild，AITW) ，它的数量级大于当前的数据集。数据集包含设备交互的人工演示，包括屏幕和操作，以及相应的自然语言指令。它包括715k 集，跨越30k 独特的指令，四个版本的 Android (v10-13) ，以及八种不同屏幕分辨率的设备类型(Pixel 2 XL to Pixel 6)。它包含多步骤的任务，需要语言和视觉上下文的语义理解。这个数据集提出了一个新的挑战: 通过用户界面可用的操作必须从它们的视觉外观中推断出来。而且，不是简单的基于 UI 元素的操作，操作空间由精确的手势组成(例如，用于操作 carousel 小部件的水平滚动)。我们组织数据集是为了鼓励对设备控制系统进行健壮性分析，例如，在新任务描述、新应用程序或新平台版本出现的情况下，系统的表现如何。我们开发两个代理并跨数据集报告性能。数据集可在 https://github.com/google-research/google-research/tree/master/android_in_the_wild 下载。"
    },
    {
        "title": "An Empirical Study on Fertility Proposals Using Multi-Grined Topic\n  Analysis Methods",
        "url": "http://arxiv.org/abs/2307.10025v1",
        "pub_date": "2023-07-19",
        "summary": "Fertility issues are closely related to population security, in 60 years\nChina's population for the first time in a negative growth trend, the change of\nfertility policy is of great concern to the community. 2023 ``two sessions\"\nproposal ``suggests that the country in the form of legislation, the birth of\nthe registration of the cancellation of the marriage restriction\" This topic\nwas once a hot topic on the Internet, and ``unbundling\" the relationship\nbetween birth registration and marriage has become the focus of social debate.\nIn this paper, we adopt co-occurrence semantic analysis, topic analysis and\nsentiment analysis to conduct multi-granularity semantic analysis of microblog\ncomments. It is found that the discussion on the proposal of ``removing\nmarriage restrictions from birth registration\" involves the individual, society\nand the state at three dimensions, and is detailed into social issues such as\npersonal behaviour, social ethics and law, and national policy, with people's\nsentiment inclined to be negative in most of the topics. Based on this, eight\nproposals were made to provide a reference for governmental decision making and\nto form a reference method for researching public opinion on political issues.",
        "translated": "生育问题与人口安全密切相关，60年来中国人口首次出现负增长趋势，生育政策的变化引起了社会的高度关注。2023年“两会”提案“建议国家以立法的形式，取消出生登记对结婚的限制”这一话题曾经是互联网上的热门话题，而“分拆”出生登记与结婚的关系也成为社会争论的焦点。本文采用共现语义分析、话题分析和情感分析对微博评论进行了多粒度语义分析。研究发现，对“出生登记取消婚姻限制”提案的讨论涉及个人、社会和国家三个维度，具体涉及个人行为、社会伦理和法律、国家政策等社会问题，多数话题的民意倾向于负面。在此基础上，提出八点建议，为政府决策提供参考，为研究政治舆论提供参考方法。"
    },
    {
        "title": "Generating Mathematical Derivations with Large Language Models",
        "url": "http://arxiv.org/abs/2307.09998v1",
        "pub_date": "2023-07-19",
        "summary": "The derivation of mathematical results in specialised fields using Large\nLanguage Models (LLMs) is an emerging research direction that can help identify\nmodels' limitations, and potentially support mathematical discovery. In this\npaper, we leverage a symbolic engine to generate derivations of equations at\nscale, and investigate the capabilities of LLMs when deriving goal equations\nfrom premises. Specifically, we employ in-context learning for GPT and\nfine-tune a range of T5 models to compare the robustness and generalisation of\npre-training strategies to specialised models. Empirical results show that\nfine-tuned FLAN-T5-large (MathT5) outperforms GPT models on all static and\nout-of-distribution test sets in terms of absolute performance. However, an\nin-depth analysis reveals that the fine-tuned models are more sensitive to\nperturbations involving unseen symbols and (to a lesser extent) changes to\nequation structure. In addition, we analyse 1.7K equations and over 200\nderivations to highlight common reasoning errors such as the inclusion of\nincorrect, irrelevant, and redundant equations, along with the tendency to skip\nderivation steps. Finally, we explore the suitability of existing metrics for\nevaluating mathematical derivations finding evidence that, while they capture\ngeneral properties such as sensitivity to perturbations, they fail to highlight\nfine-grained reasoning errors and essential differences between models.\nOverall, this work demonstrates that training models on synthetic data can\nimprove their mathematical capabilities beyond larger architectures.",
        "translated": "使用大语言模型(LLM)在专业领域推导数学结果是一个新兴的研究方向，可以帮助识别模型的局限性，并可能支持数学发现。在本文中，我们利用一个符号引擎产生方程的推导在规模，并研究 LLM 的能力，当推导的目标方程从前提。具体来说，我们使用 GPT 的上下文学习，并对一系列 T5模型进行微调，以比较训练前策略与专门模型的稳健性和泛化性。实验结果表明，在所有静态测试集和分布外测试集上，微调 FLAN-T5-large (MathT5)模型的绝对性能均优于 GPT 模型。然而，一个深入的分析表明，微调模型更敏感的扰动，包括看不见的符号和(在较小程度上)方程结构的变化。此外，我们分析了1.7 K 方程和200多个推导，以突出常见的推理错误，如包括不正确的，不相关的，冗余的方程，以及跳过推导步骤的倾向。最后，我们探索现有指标评估数学推导的适用性，发现证据表明，虽然它们捕获一般性质，如对扰动的敏感性，但它们不能突出细粒度的推理错误和模型之间的本质差异。总的来说，这项工作表明，合成数据的训练模型可以提高它们的数学能力超越更大的体系结构。"
    },
    {
        "title": "GUIDO: A Hybrid Approach to Guideline Discovery &amp; Ordering from Natural\n  Language Texts",
        "url": "http://arxiv.org/abs/2307.09959v1",
        "pub_date": "2023-07-19",
        "summary": "Extracting workflow nets from textual descriptions can be used to simplify\nguidelines or formalize textual descriptions of formal processes like business\nprocesses and algorithms. The task of manually extracting processes, however,\nrequires domain expertise and effort. While automatic process model extraction\nis desirable, annotating texts with formalized process models is expensive.\nTherefore, there are only a few machine-learning-based extraction approaches.\nRule-based approaches, in turn, require domain specificity to work well and can\nrarely distinguish relevant and irrelevant information in textual descriptions.\nIn this paper, we present GUIDO, a hybrid approach to the process model\nextraction task that first, classifies sentences regarding their relevance to\nthe process model, using a BERT-based sentence classifier, and second, extracts\na process model from the sentences classified as relevant, using dependency\nparsing. The presented approach achieves significantly better results than a\npure rule-based approach. GUIDO achieves an average behavioral similarity score\nof $0.93$. Still, in comparison to purely machine-learning-based approaches,\nthe annotation costs stay low.",
        "translated": "从文本描述中提取工作流网络可用于简化指南或形式化正式流程(如业务流程和算法)的文本描述。然而，手动提取过程的任务需要领域专业知识和努力。虽然自动过程模型提取是可取的，但是使用形式化过程模型对文本进行注释是昂贵的。因此，基于机器学习的抽取方法很少。反过来，基于规则的方法需要领域特异性才能很好地工作，并且很少能够在文本描述中区分相关和不相关的信息。本文提出了一种过程模型抽取任务的混合方法 GUIDO，它首先根据句子与过程模型的相关性对句子进行分类，使用基于 BERT 的句子分类器，然后使用依赖解析从相关的句子中抽取过程模型。与纯规则方法相比，本文提出的方法获得了更好的结果。GUIDO 的平均行为相似性得分为 $0.93 $。尽管如此，与纯机器学习方法相比，注释成本仍然很低。"
    },
    {
        "title": "Large Language Models can accomplish Business Process Management Tasks",
        "url": "http://arxiv.org/abs/2307.09923v1",
        "pub_date": "2023-07-19",
        "summary": "Business Process Management (BPM) aims to improve organizational activities\nand their outcomes by managing the underlying processes. To achieve this, it is\noften necessary to consider information from various sources, including\nunstructured textual documents. Therefore, researchers have developed several\nBPM-specific solutions that extract information from textual documents using\nNatural Language Processing techniques. These solutions are specific to their\nrespective tasks and cannot accomplish multiple process-related problems as a\ngeneral-purpose instrument. However, in light of the recent emergence of Large\nLanguage Models (LLMs) with remarkable reasoning capabilities, such a\ngeneral-purpose instrument with multiple applications now appears attainable.\nIn this paper, we illustrate how LLMs can accomplish text-related BPM tasks by\napplying a specific LLM to three exemplary tasks: mining imperative process\nmodels from textual descriptions, mining declarative process models from\ntextual descriptions, and assessing the suitability of process tasks from\ntextual descriptions for robotic process automation. We show that, without\nextensive configuration or prompt engineering, LLMs perform comparably to or\nbetter than existing solutions and discuss implications for future BPM research\nas well as practical usage.",
        "translated": "业务流程管理(Business Process Management，BPM)旨在通过管理底层流程来改进组织活动及其结果。为了实现这一点，通常需要考虑来自各种来源的信息，包括非结构化文本文档。因此，研究人员已经开发了几个 BPM 特定的解决方案，它们使用自然语言处理技术从文本文档中提取信息。这些解决方案针对其各自的任务，不能作为通用工具来完成多个与过程相关的问题。然而，考虑到最近出现的具有显著推理能力的大语言模型(LLM) ，这样一个具有多种应用的通用工具现在似乎是可以实现的。本文阐述了 LLM 如何通过将一个特定的 LLM 应用于三个示例任务来完成与文本相关的 BPM 任务: 从文本描述中挖掘命令式过程模型，从文本描述中挖掘声明式过程模型，以及从文本描述中评估过程任务对机器人过程自动化的适用性。我们表明，没有广泛的配置或及时的工程，LLM 的性能相当于或优于现有的解决方案，并讨论了对未来的 BPM 研究和实际应用的影响。"
    },
    {
        "title": "Investigating the Factual Knowledge Boundary of Large Language Models\n  with Retrieval Augmentation",
        "url": "http://arxiv.org/abs/2307.11019v1",
        "pub_date": "2023-07-20",
        "summary": "Knowledge-intensive tasks (e.g., open-domain question answering (QA)) require\na substantial amount of factual knowledge and often rely on external\ninformation for assistance. Recently, large language models (LLMs) (e.g.,\nChatGPT), have demonstrated impressive prowess in solving a wide range of tasks\nwith world knowledge, including knowledge-intensive tasks. However, it remains\nunclear how well LLMs are able to perceive their factual knowledge boundaries,\nparticularly how they behave when incorporating retrieval augmentation. In this\nstudy, we present an initial analysis of the factual knowledge boundaries of\nLLMs and how retrieval augmentation affects LLMs on open-domain QA. Specially,\nwe focus on three primary research questions and analyze them by examining QA\nperformance, priori judgement and posteriori judgement of LLMs. We show\nevidence that LLMs possess unwavering confidence in their capabilities to\nrespond to questions and the accuracy of their responses. Furthermore,\nretrieval augmentation proves to be an effective approach in enhancing LLMs'\nawareness of knowledge boundaries, thereby improving their judgemental\nabilities. Additionally, we also find that LLMs have a propensity to rely on\nthe provided retrieval results when formulating answers, while the quality of\nthese results significantly impacts their reliance. The code to reproduce this\nwork is available at https://github.com/RUCAIBox/LLM-Knowledge-Boundary.",
        "translated": "知识密集型任务(例如，开放领域的问题回答(QA))需要大量的实际知识，并且常常依赖于外部信息的帮助。最近，大型语言模型(LLM)(例如 ChatGPT)已经展示了在解决包括知识密集型任务在内的广泛的世界知识任务方面令人印象深刻的能力。然而，尚不清楚 LLM 如何能够感知他们的事实知识边界，特别是他们如何行为时，结合检索增强。在这项研究中，我们提出了一个初步分析的事实知识边界的 LLM 和检索增强如何影响开放域 QA 的 LLM。特别针对三个主要的研究问题，分别从质量保证绩效、先验判断和后验判断三个方面进行了分析。我们展示的证据表明，LLM 拥有毫不动摇的信心，他们的能力，以回应问题和准确性的回答。此外，检索增强被证明是一种有效的方法，提高 LLM 的知识边界意识，从而提高其判断能力。此外，我们还发现 LLM 在构建答案时倾向于依赖提供的检索结果，而这些结果的质量显著影响其依赖性。复制这项工作的代码可在 https://github.com/rucaibox/llm-knowledge-boundary 找到。"
    },
    {
        "title": "Enhancing Job Recommendation through LLM-based Generative Adversarial\n  Networks",
        "url": "http://arxiv.org/abs/2307.10747v1",
        "pub_date": "2023-07-20",
        "summary": "Recommending suitable jobs to users is a critical task in online recruitment\nplatforms, as it can enhance users' satisfaction and the platforms'\nprofitability. While existing job recommendation methods encounter challenges\nsuch as the low quality of users' resumes, which hampers their accuracy and\npractical effectiveness. With the rapid development of large language models\n(LLMs), utilizing the rich external knowledge encapsulated within them, as well\nas their powerful capabilities of text processing and reasoning, is a promising\nway to complete users' resumes for more accurate recommendations. However,\ndirectly leveraging LLMs to enhance recommendation results is not a\none-size-fits-all solution, as LLMs may suffer from fabricated generation and\nfew-shot problems, which degrade the quality of resume completion. In this\npaper, we propose a novel LLM-based approach for job recommendation. To\nalleviate the limitation of fabricated generation for LLMs, we extract accurate\nand valuable information beyond users' self-description, which helps the LLMs\nbetter profile users for resume completion. Specifically, we not only extract\nusers' explicit properties (e.g., skills, interests) from their\nself-description but also infer users' implicit characteristics from their\nbehaviors for more accurate and meaningful resume completion. Nevertheless,\nsome users still suffer from few-shot problems, which arise due to scarce\ninteraction records, leading to limited guidance for the models in generating\nhigh-quality resumes. To address this issue, we propose aligning unpaired\nlow-quality with high-quality generated resumes by Generative Adversarial\nNetworks (GANs), which can refine the resume representations for better\nrecommendation results. Extensive experiments on three large real-world\nrecruitment datasets demonstrate the effectiveness of our proposed method.",
        "translated": "向用户推荐合适的工作是在线招聘平台的一项关键任务，因为它可以提高用户的满意度和平台的盈利能力。现有的求职推荐方法存在着用户简历质量低下等问题，影响了求职推荐的准确性和实用性。随着大型语言模型(LLM)的迅速发展，利用其中包含的丰富的外部知识，以及它们强大的文本处理和推理能力，是一种有前途的方式来完成用户的简历，以获得更准确的推荐。然而，直接利用 LLM 来提高推荐结果并不是一个一刀切的解决方案，因为 LLM 可能会遇到虚构的生成和少镜头问题，这会降低简历完成的质量。本文提出了一种新的基于 LLM 的职位推荐方法。为了解决 LLM 虚构生成的局限性，我们提取了用户自我描述以外的准确而有价值的信息，帮助 LLM 更好地描述用户的简历完成情况。具体来说，我们不仅从用户的自我描述中提取用户的外显属性(如技能、兴趣) ，而且从用户的行为中推断出用户的内隐特征，以便更准确、更有意义地完成简历。尽管如此，一些用户仍然受到由于缺乏交互记录而产生的“少投”问题的困扰，导致对模型生成高质量简历的指导有限。为了解决这个问题，我们建议将不成对的低质量简历与生成对抗网络(GANs)生成的高质量简历进行对齐，这样可以改进简历表示以获得更好的推荐结果。通过对三个大型实际招聘数据集的大量实验证明了该方法的有效性。"
    },
    {
        "title": "A Constraint-based Recommender System via RDF Knowledge Graphs",
        "url": "http://arxiv.org/abs/2307.10702v1",
        "pub_date": "2023-07-20",
        "summary": "Knowledge graphs, represented in RDF, are able to model entities and their\nrelations by means of ontologies. The use of knowledge graphs for information\nmodeling has attracted interest in recent years. In recommender systems, items\nand users can be mapped and integrated into the knowledge graph, which can\nrepresent more links and relationships between users and items.\nConstraint-based recommender systems are based on the idea of explicitly\nexploiting deep recommendation knowledge through constraints to identify\nrelevant recommendations. When combined with knowledge graphs, a\nconstraint-based recommender system gains several benefits in terms of\nconstraint sets. In this paper, we investigate and propose the construction of\na constraint-based recommender system via RDF knowledge graphs applied to the\nvehicle purchase/sale domain. The results of our experiments show that the\nproposed approach is able to efficiently identify recommendations in accordance\nwith user preferences.",
        "translated": "以 RDF 为代表的知识图能够通过本体对实体及其关系进行建模。近年来，知识图在信息建模中的应用越来越受到人们的关注。在推荐系统中，项目和用户可以映射并集成到知识图中，表示用户和项目之间更多的联系和关系。基于约束的推荐系统基于通过约束明确利用深度推荐知识来识别相关推荐的思想。当与知识图相结合时，基于约束的推荐系统在约束集方面获得了一些好处。在这篇文章中，我们研究并提出了一个基于约束的推荐系统的构建方法，该方法通过 RDF 知识图应用于汽车购买/销售领域。我们的实验结果表明，提出的方法能够有效地识别推荐根据用户的喜好。"
    },
    {
        "title": "A Personalized Recommender System Based-on Knowledge Graph Embeddings",
        "url": "http://arxiv.org/abs/2307.10680v1",
        "pub_date": "2023-07-20",
        "summary": "Knowledge graphs have proven to be effective for modeling entities and their\nrelationships through the use of ontologies. The recent emergence in interest\nfor using knowledge graphs as a form of information modeling has led to their\nincreased adoption in recommender systems. By incorporating users and items\ninto the knowledge graph, these systems can better capture the implicit\nconnections between them and provide more accurate recommendations. In this\npaper, we investigate and propose the construction of a personalized\nrecommender system via knowledge graphs embedding applied to the vehicle\npurchase/sale domain. The results of our experimentation demonstrate the\nefficacy of the proposed method in providing relevant recommendations that are\nconsistent with individual users.",
        "translated": "通过使用本体论，已经证明知识图对于建模实体及其关系是有效的。最近出现的兴趣，使用知识图表作为一种形式的信息建模，导致它们越来越多地采用推荐系统。通过将用户和项目合并到知识图中，这些系统可以更好地捕捉它们之间的隐含联系，并提供更准确的建议。在这篇文章中，我们研究并提出了一个个性化的推荐系统，通过知识图嵌入应用于汽车购买/销售领域。我们的实验结果证明了提出的方法在提供与个人用户一致的相关建议方面的有效性。"
    },
    {
        "title": "Language-Enhanced Session-Based Recommendation with Decoupled\n  Contrastive Learning",
        "url": "http://arxiv.org/abs/2307.10650v1",
        "pub_date": "2023-07-20",
        "summary": "Session-based recommendation techniques aim to capture dynamic user behavior\nby analyzing past interactions. However, existing methods heavily rely on\nhistorical item ID sequences to extract user preferences, leading to challenges\nsuch as popular bias and cold-start problems. In this paper, we propose a\nhybrid multimodal approach for session-based recommendation to address these\nchallenges. Our approach combines different modalities, including textual\ncontent and item IDs, leveraging the complementary nature of these modalities\nusing CatBoost. To learn universal item representations, we design a language\nrepresentation-based item retrieval architecture that extracts features from\nthe textual content utilizing pre-trained language models. Furthermore, we\nintroduce a novel Decoupled Contrastive Learning method to enhance the\neffectiveness of the language representation. This technique decouples the\nsequence representation and item representation space, facilitating\nbidirectional alignment through dual-queue contrastive learning.\nSimultaneously, the momentum queue provides a large number of negative samples,\neffectively enhancing the effectiveness of contrastive learning. Our approach\nyielded competitive results, securing a 5th place ranking in KDD CUP 2023 Task\n1. We have released the source code and pre-trained models associated with this\nwork.",
        "translated": "基于会话的推荐技术旨在通过分析过去的交互来捕获动态用户行为。然而，现有的方法严重依赖于历史项目 ID 序列来提取用户偏好，导致诸如流行偏见和冷启动问题等挑战。在本文中，我们提出了一种基于会话的推荐混合多模式方法来应对这些挑战。我们的方法结合了不同的模式，包括文本内容和项目 ID，利用这些模式的互补性使用 CatBoost。为了学习通用的项目表示，我们设计了一个基于语言表示的项目检索体系结构，该体系结构利用预训练语言模型从文本内容中提取特征。此外，我们还引入了一种新的解耦对比学习方法来提高语言表征的有效性。该技术将序列表示和项表示空间解耦，通过双队列对比学习实现双向对齐。同时，动量队列提供了大量的负样本，有效地提高了对比学习的有效性。我们的方法产生了有竞争力的结果，在 KDD CUP 2023任务1中获得了第5名的排名。我们已经发布了与此工作相关的源代码和预先训练的模型。"
    },
    {
        "title": "L-Eval: Instituting Standardized Evaluation for Long Context Language\n  Models",
        "url": "http://arxiv.org/abs/2307.11088v1",
        "pub_date": "2023-07-20",
        "summary": "Recently, there has been growing interest in extending the context length of\ninstruction-following models in order to effectively process single-turn long\ninput (e.g. summarizing a paper) and conversations with more extensive\nhistories. While proprietary models such as GPT-4 and Claude have demonstrated\nconsiderable advancements in handling tens of thousands of tokens of context,\nopen-sourced models are still in the early stages of experimentation. It also\nremains unclear whether developing these long context models can offer\nsubstantial gains on practical downstream tasks over retrieval-based methods or\nmodels simply trained on chunked contexts. To address this challenge, we\npropose to institute standardized evaluation for long context language models.\nConcretely, we develop L-Eval which contains 411 long documents and over 2,000\nquery-response pairs manually annotated and checked by the authors encompassing\nareas such as law, finance, school lectures, lengthy conversations, news,\nlong-form novels, and meetings. L-Eval also adopts diverse evaluation methods\nand instruction styles, enabling a more reliable assessment of Long Context\nLanguage Models (LCLMs). Our findings indicate that while open-source models\ntypically lag behind their commercial counterparts, they still exhibit\nimpressive performance. LLaMA2 achieves the best results (win 45\\% vs\nturbo-16k) on open-ended tasks with only 4k context length and ChatGLM2\nachieves the best results on closed-ended tasks with 8k input tokens. We\nrelease our new evaluation suite, code, and all generation results including\npredictions from all open-sourced LCLMs, GPT4-32k, Cluade-100k at\n{\\url{https://github.com/OpenLMLab/LEval}}.",
        "translated": "近年来，人们越来越关注扩展指令跟踪模型的上下文长度，以便有效地处理具有更广泛历史的单圈长输入(例如总结论文)和会话。虽然像 GPT-4和 Claude 这样的专有模型在处理数以万计的上下文标记方面已经显示出相当大的进步，但是开源模型仍然处于试验的早期阶段。目前还不清楚开发这些长上下文模型是否能够在实际的下游任务中比基于检索的方法或仅仅在分块上下文中训练的模型提供实质性的收益。为了应对这一挑战，我们建议对长语境语言模型进行标准化评估。具体来说，我们开发了 L-Eval，其中包含411个长文档和超过2000个查询-回复对，由作者手工注释和检查，涉及的领域包括法律、金融、学校讲座、长谈话、新闻、长篇小说和会议。L-Eval 还采用了多种评估方法和指令风格，从而能够对长语境语言模型(LCLM)进行更可靠的评估。我们的研究结果表明，尽管开源模型通常落后于商业模型，但它们仍然表现出令人印象深刻的性能。LLaMA2在只有4k 上下文长度的开放式任务中获得最佳结果(45% vs turbo-16k) ，ChatGLM2在8k 输入令牌的封闭式任务中获得最佳结果。我们发布了新的评估套件、代码和所有生成的结果，包括来自所有开源的 LCLM、 GPT4-32k、 Cluade-100k 的预测，地址为{ url { https://github.com/openlmlab/leval }。"
    },
    {
        "title": "Embroid: Unsupervised Prediction Smoothing Can Improve Few-Shot\n  Classification",
        "url": "http://arxiv.org/abs/2307.11031v1",
        "pub_date": "2023-07-20",
        "summary": "Recent work has shown that language models' (LMs) prompt-based learning\ncapabilities make them well suited for automating data labeling in domains\nwhere manual annotation is expensive. The challenge is that while writing an\ninitial prompt is cheap, improving a prompt is costly -- practitioners often\nrequire significant labeled data in order to evaluate the impact of prompt\nmodifications. Our work asks whether it is possible to improve prompt-based\nlearning without additional labeled data. We approach this problem by\nattempting to modify the predictions of a prompt, rather than the prompt\nitself. Our intuition is that accurate predictions should also be consistent:\nsamples which are similar under some feature representation should receive the\nsame prompt prediction. We propose Embroid, a method which computes multiple\nrepresentations of a dataset under different embedding functions, and uses the\nconsistency between the LM predictions for neighboring samples to identify\nmispredictions. Embroid then uses these neighborhoods to create additional\npredictions for each sample, and combines these predictions with a simple\nlatent variable graphical model in order to generate a final corrected\nprediction. In addition to providing a theoretical analysis of Embroid, we\nconduct a rigorous empirical evaluation across six different LMs and up to 95\ndifferent tasks. We find that (1) Embroid substantially improves performance\nover original prompts (e.g., by an average of 7.3 points on GPT-JT), (2) also\nrealizes improvements for more sophisticated prompting strategies (e.g.,\nchain-of-thought), and (3) can be specialized to domains like law through the\nembedding functions.",
        "translated": "最近的研究表明，语言模型(LM)基于提示的学习能力使得它们非常适合在手动注释代价昂贵的领域中自动化数据标记。挑战在于，虽然编写初始提示符的成本很低，但改进提示符的成本很高——从业人员通常需要重要的标记数据来评估提示修改的影响。我们的工作要求是否有可能改善提示为基础的学习没有额外的标记数据。我们通过试图修改一个提示的预测而不是提示本身来处理这个问题。我们的直觉是，精确的预测也应该是一致的: 在某些特征表示下相似的样本应该得到相同的及时预测。我们提出了 Embroid 方法，该方法在不同的嵌入函数下计算一个数据集的多重表示，并利用相邻样本的 LM 预测之间的一致性来识别错误预测。Embroid 然后使用这些邻域为每个样本创建额外的预测，并将这些预测与一个简单的潜变量图形模型结合起来，以生成最终的修正预测。除了对 Embroid 进行理论分析之外，我们还对6种不同的长期管理模式和多达95种不同的任务进行了严格的实证评估。我们发现(1) Embroid 大大提高了原始提示的性能(例如，在 GPT-JT 上平均提高了7.3分) ，(2)也实现了对更复杂的提示策略(例如，思维链)的改进，(3)可以通过嵌入功能专门化到法律等领域。"
    },
    {
        "title": "\"It Felt Like Having a Second Mind\": Investigating Human-AI\n  Co-creativity in Prewriting with Large Language Models",
        "url": "http://arxiv.org/abs/2307.10811v1",
        "pub_date": "2023-07-20",
        "summary": "Prewriting is the process of discovering and developing ideas before a first\ndraft, which requires divergent thinking and often implies unstructured\nstrategies such as diagramming, outlining, free-writing, etc. Although large\nlanguage models (LLMs) have been demonstrated to be useful for a variety of\ntasks including creative writing, little is known about how users would\ncollaborate with LLMs to support prewriting. The preferred collaborative role\nand initiative of LLMs during such a creativity process is also unclear. To\ninvestigate human-LLM collaboration patterns and dynamics during prewriting, we\nconducted a three-session qualitative study with 15 participants in two\ncreative tasks: story writing and slogan writing. The findings indicated that\nduring collaborative prewriting, there appears to be a three-stage iterative\nHuman-AI Co-creativity process that includes Ideation, Illumination, and\nImplementation stages. This collaborative process champions the human in a\ndominant role, in addition to mixed and shifting levels of initiative that\nexist between humans and LLMs. This research also reports on collaboration\nbreakdowns that occur during this process, user perceptions of using existing\nLLMs during Human-AI Co-creativity, and discusses design implications to\nsupport this co-creativity process.",
        "translated": "预写是在初稿之前发现和发展想法的过程，它需要发散性思维，通常意味着非结构化的策略，如制图、提纲、自由写作等。尽管大型语言模型(LLM)已经被证明对于包括创造性写作在内的各种任务是有用的，但是很少有人知道用户如何与 LLM 协作以支持预写。在这样一个创造性过程中，长期管理模式的首选协作作用和主动性也不清楚。为了研究写作前期的人类-LLM 协作模式和动态，我们对15名参与者进行了三个阶段的定性研究，分别完成了两个创造性任务: 故事写作和口号写作。研究结果表明，在协作预写阶段，人类-人工智能的协同创造过程似乎有三个阶段的迭代，包括构思、启发和实施阶段。除了人类和 LLM 之间存在的混合和不断变化的主动性水平之外，这种协作过程还捍卫了人类的主导地位。本研究还报告了在这个过程中发生的协作破裂，用户在人工智能协同创造过程中使用现有 LLM 的感知，并讨论了支持这个协同创造过程的设计含义。"
    },
    {
        "title": "Integrating Pretrained ASR and LM to Perform Sequence Generation for\n  Spoken Language Understanding",
        "url": "http://arxiv.org/abs/2307.11005v1",
        "pub_date": "2023-07-20",
        "summary": "There has been an increased interest in the integration of pretrained speech\nrecognition (ASR) and language models (LM) into the SLU framework. However,\nprior methods often struggle with a vocabulary mismatch between pretrained\nmodels, and LM cannot be directly utilized as they diverge from its NLU\nformulation. In this study, we propose a three-pass end-to-end (E2E) SLU system\nthat effectively integrates ASR and LM subnetworks into the SLU formulation for\nsequence generation tasks. In the first pass, our architecture predicts ASR\ntranscripts using the ASR subnetwork. This is followed by the LM subnetwork,\nwhich makes an initial SLU prediction. Finally, in the third pass, the\ndeliberation subnetwork conditions on representations from the ASR and LM\nsubnetworks to make the final prediction. Our proposed three-pass SLU system\nshows improved performance over cascaded and E2E SLU models on two benchmark\nSLU datasets, SLURP and SLUE, especially on acoustically challenging\nutterances.",
        "translated": "将预训练语音识别(ASR)和语言模型(LM)集成到 SLU 框架中已经引起了人们越来越多的兴趣。然而，先前的方法往往与预先训练的模型之间的词汇不匹配斗争，并且 LM 不能直接使用，因为它们偏离其 NLU 公式。在这项研究中，我们提出了一个三通端到端(E2E) SLU 系统，有效地将 ASR 和 LM 子网融入序列生成任务的 SLU 公式。首先，我们的体系结构使用 ASR 子网络预测 ASR 转录。然后是 LM 子网络，它进行初始 SLU 预测。最后，在第三阶段，考虑子网条件对来自 ASR 和 LM 子网的表示做出最终的预测。我们提出的三通 SLU 系统在两个基准的 SLU 数据集 SLURP 和 SLUE 上显示出比级联和 E2E SLU 模型更好的性能，特别是在具有声学挑战性的语句上。"
    },
    {
        "title": "MASR: Metadata Aware Speech Representation",
        "url": "http://arxiv.org/abs/2307.10982v1",
        "pub_date": "2023-07-20",
        "summary": "In the recent years, speech representation learning is constructed primarily\nas a self-supervised learning (SSL) task, using the raw audio signal alone,\nwhile ignoring the side-information that is often available for a given speech\nrecording. In this paper, we propose MASR, a Metadata Aware Speech\nRepresentation learning framework, which addresses the aforementioned\nlimitations. MASR enables the inclusion of multiple external knowledge sources\nto enhance the utilization of meta-data information. The external knowledge\nsources are incorporated in the form of sample-level pair-wise similarity\nmatrices that are useful in a hard-mining loss. A key advantage of the MASR\nframework is that it can be combined with any choice of SSL method. Using MASR\nrepresentations, we perform evaluations on several downstream tasks such as\nlanguage identification, speech recognition and other non-semantic tasks such\nas speaker and emotion recognition. In these experiments, we illustrate\nsignificant performance improvements for the MASR over other established\nbenchmarks. We perform a detailed analysis on the language identification task\nto provide insights on how the proposed loss function enables the\nrepresentations to separate closely related languages.",
        "translated": "近年来，语音表征学习主要是作为一种自监督学习(SSL)任务来构建的，它只使用原始的音频信号，而忽略了给定语音记录中经常可用的旁信息。在本文中，我们提出了一个元数据感知的语音表示学习框架 MASR，它解决了上述局限性。MASR 能够纳入多个外部知识来源，以提高元数据信息的利用率。外部知识源以样本水平成对相似矩阵的形式被合并，这对于难以挖掘的损失是有用的。MASR 框架的一个关键优点是它可以与任何选择的 SSL 方法相结合。利用 MASR 表示，我们对语言识别、语音识别以及说话人和情感识别等非语义任务进行了评估。在这些实验中，我们说明了 MASR 相对于其他已建立的基准的显著性能改进。我们对语言识别任务进行了详细的分析，以提供深刻的见解，建议的损失函数如何使表征分离密切相关的语言。"
    },
    {
        "title": "Identical and Fraternal Twins: Fine-Grained Semantic Contrastive\n  Learning of Sentence Representations",
        "url": "http://arxiv.org/abs/2307.10932v1",
        "pub_date": "2023-07-20",
        "summary": "The enhancement of unsupervised learning of sentence representations has been\nsignificantly achieved by the utility of contrastive learning. This approach\nclusters the augmented positive instance with the anchor instance to create a\ndesired embedding space. However, relying solely on the contrastive objective\ncan result in sub-optimal outcomes due to its inability to differentiate subtle\nsemantic variations between positive pairs. Specifically, common data\naugmentation techniques frequently introduce semantic distortion, leading to a\nsemantic margin between the positive pair. While the InfoNCE loss function\noverlooks the semantic margin and prioritizes similarity maximization between\npositive pairs during training, leading to the insensitive semantic\ncomprehension ability of the trained model. In this paper, we introduce a novel\nIdentical and Fraternal Twins of Contrastive Learning (named IFTCL) framework,\ncapable of simultaneously adapting to various positive pairs generated by\ndifferent augmentation techniques. We propose a \\textit{Twins Loss} to preserve\nthe innate margin during training and promote the potential of data enhancement\nin order to overcome the sub-optimal issue. We also present proof-of-concept\nexperiments combined with the contrastive objective to prove the validity of\nthe proposed Twins Loss. Furthermore, we propose a hippocampus queue mechanism\nto restore and reuse the negative instances without additional calculation,\nwhich further enhances the efficiency and performance of the IFCL. We verify\nthe IFCL framework on nine semantic textual similarity tasks with both English\nand Chinese datasets, and the experimental results show that IFCL outperforms\nstate-of-the-art methods.",
        "translated": "对比学习能显著提高句子表征的非监督式学习。这种方法将增强的正实例与锚实例聚集在一起，以创建所需的嵌入空间。然而，仅仅依靠对比目标可能会导致次优结果，因为它不能区分正对之间微妙的语义变化。具体来说，常见的数据增强技术经常引入语义失真，导致正对之间的语义边界。在训练过程中，InfoNCE 丢失函数忽略了语义边界，优先考虑正对之间的相似性最大化，导致训练模型的语义理解能力不敏感。本文介绍了一种新的对比学习同兄弟双胞胎(IFTCL)框架，该框架能够同时适应不同增强技术产生的各种正对。我们提出了一个文本{孪生损失} ，以保留先天边际训练和促进潜力的数据增强，以克服次优问题。我们还提出了概念验证实验结合对比的目标，以证明所提出的双子损失的有效性。此外，我们提出了一个海马排队机制来恢复和重用负面实例而不需要额外的计算，这进一步提高了 IFCL 的效率和性能。实验结果表明，该框架的语义相似度优于现有的语义相似度分析方法。"
    },
    {
        "title": "MediaGPT : A Large Language Model Target Chinese Media",
        "url": "http://arxiv.org/abs/2307.10930v1",
        "pub_date": "2023-07-20",
        "summary": "The development of large language models (LLMs) has seen rapid progress in\nrecent years. One of the most widely used LLMs is the Generative Pre-trained\nTransformer (GPT) series, which has been applied in various fields, including\nthe media domain. However, in practical applications, the differences between\nthe media's use cases and the general-purpose applications of LLMs have become\nincreasingly apparent, especially Chinese. As a result, there is a growing need\nto develop LLM that are specifically tailored to the unique requirements of the\nmedia domain. In this paper, we present MediaGPT, a large language model\ntraining on variety of media data and addressing the practical needs of Chinese\nmedia. We have designed a diverse set of task instruction types to cater to the\nspecific requirements of the domain. To further validate the effectiveness of\nour proposed LLM, we have constructed unique datasets that are tailored to the\nmedia domain and have also developed verification methods that are specifically\ndesigned for generative-type tasks. By doing so, we aim to bridge the gap\nbetween the general-purpose LLM and the requirements of the media domain, and\nto pave the way for more effective and efficient use of LLM in this field. This\npaper aims to explore the challenges and opportunities of developing LLM for\nmedia applications and to propose potential solutions for addressing these\nchallenges.",
        "translated": "近年来，大型语言模型(LLM)的发展迅速。最广泛使用的 LLM 之一是产生式预训练变压器(GPT)系列，它已经应用于各个领域，包括媒体领域。然而，在实际应用中，媒体的用例和 LLM 的通用应用之间的差异越来越明显，尤其是中文。因此，越来越需要开发专门针对媒体领域独特需求的 LLM。在本文中，我们介绍了 MediaGPT，这是一个针对多种媒体数据的大型语言模型培训，满足了中国媒体的实际需求。我们已经设计了一组不同的任务指令类型，以满足领域的特定需求。为了进一步验证我们提出的 LLM 的有效性，我们已经构建了适合媒体领域的独特数据集，并且还开发了专门为生成类型任务设计的验证方法。通过这样做，我们的目标是弥合通用 LLM 与媒体领域的需求之间的差距，并为 LLM 在该领域更有效和高效的应用铺平道路。本文旨在探讨开发媒体应用的 LLM 所面临的挑战和机遇，并提出应对这些挑战的潜在解决方案。"
    },
    {
        "title": "FLASK: Fine-grained Language Model Evaluation based on Alignment Skill\n  Sets",
        "url": "http://arxiv.org/abs/2307.10928v1",
        "pub_date": "2023-07-20",
        "summary": "Evaluation of Large Language Models (LLMs) is challenging because aligning to\nhuman values requires the composition of multiple skills and the required set\nof skills varies depending on the instruction. Recent studies have evaluated\nthe performance of LLMs in two ways, (1) automatic evaluation on several\nindependent benchmarks and (2) human or machined-based evaluation giving an\noverall score to the response. However, both settings are coarse-grained\nevaluations, not considering the nature of user instructions that require\ninstance-wise skill composition, which limits the interpretation of the true\ncapabilities of LLMs. In this paper, we introduce FLASK (Fine-grained Language\nModel Evaluation based on Alignment SKill Sets), a fine-grained evaluation\nprotocol that can be used for both model-based and human-based evaluation which\ndecomposes coarse-level scoring to an instance-wise skill set-level.\nSpecifically, we define 12 fine-grained skills needed for LLMs to follow\nopen-ended user instructions and construct an evaluation set by allocating a\nset of skills for each instance. Additionally, by annotating the target domains\nand difficulty level for each instance, FLASK provides a holistic view with a\ncomprehensive analysis of a model's performance depending on skill, domain, and\ndifficulty. Through using FLASK, we compare multiple open-sourced and\nproprietary LLMs and observe highly-correlated findings between model-based and\nhuman-based evaluations. FLASK enables developers to more accurately measure\nthe model performance and how it can be improved by analyzing factors that make\nLLMs proficient in particular skills. For practitioners, FLASK can be used to\nrecommend suitable models for particular situations through comprehensive\ncomparison among various LLMs. We release the evaluation data and code\nimplementation at https://github.com/kaistAI/FLASK.",
        "translated": "评估大型语言模型(LLM)是具有挑战性的，因为与人类价值观保持一致需要多种技能的组合，并且所需的技能组合取决于指令。最近的研究从两个方面评价 LLM 的性能: (1)对几个独立基准的自动评价; (2)给出响应的总体评分的人工或机器评价。但是，这两个设置都是粗粒度评估，没有考虑到需要实例技能组合的用户指令的性质，这限制了对 LLM 真正功能的解释。本文介绍了一种基于对齐技能集的细粒度语言模型评估协议 FLASK，它可以同时用于基于模型和基于人的评估，将粗粒度评分分解为一个实例级的技能集。具体来说，我们定义了 LLM 遵循开放式用户指令所需的12种细粒度技能，并通过为每个实例分配一组技能来构建评估集。此外，通过对每个实例的目标领域和难度级别进行注释，FLASK 提供了一个全面的视图，包括根据技能、领域和难度对模型性能的全面分析。通过使用 FLASK，我们比较了多个开源和专有 LLM，并观察了基于模型和基于人的评估之间高度相关的结果。FLASK 使开发人员能够更准确地度量模型性能，以及如何通过分析使 LLM 精通特定技能的因素来改进模型性能。对于从业者来说，FLASK 可以通过各种 LLM 之间的综合比较来为特定情况推荐合适的模型。我们在 https://github.com/kaistai/flask 发布评估数据和代码实现。"
    },
    {
        "title": "FigCaps-HF: A Figure-to-Caption Generative Framework and Benchmark with\n  Human Feedback",
        "url": "http://arxiv.org/abs/2307.10867v1",
        "pub_date": "2023-07-20",
        "summary": "Captions are crucial for understanding scientific visualizations and\ndocuments. Existing captioning methods for scientific figures rely on\nfigure-caption pairs extracted from documents for training, many of which fall\nshort with respect to metrics like helpfulness, explainability, and\nvisual-descriptiveness [15] leading to generated captions being misaligned with\nreader preferences. To enable the generation of high-quality figure captions,\nwe introduce FigCaps-HF a new framework for figure-caption generation that can\nincorporate domain expert feedback in generating captions optimized for reader\npreferences. Our framework comprises of 1) an automatic method for evaluating\nquality of figure-caption pairs, 2) a novel reinforcement learning with human\nfeedback (RLHF) method to optimize a generative figure-to-caption model for\nreader preferences. We demonstrate the effectiveness of our simple learning\nframework by improving performance over standard fine-tuning across different\ntypes of models. In particular, when using BLIP as the base model, our RLHF\nframework achieves a mean gain of 35.7%, 16.9%, and 9% in ROUGE, BLEU, and\nMeteor, respectively. Finally, we release a large-scale benchmark dataset with\nhuman feedback on figure-caption pairs to enable further evaluation and\ndevelopment of RLHF techniques for this problem.",
        "translated": "字幕对于理解科学可视化和文档至关重要。现有的科学数字字幕方法依赖于从培训文档中提取的数字字幕对，其中许多在有用性、可解释性和视觉描述性等指标方面存在缺陷[15] ，导致生成的字幕与读者偏好不一致。为了能够生成高质量的图形标题，我们引入了 FigCaps-HF 一个新的图形标题生成框架，该框架可以结合领域专家的反馈来生成针对读者偏好优化的标题。我们的框架包括: 1)一个自动评估图字对质量的方法，2)一个新的人工反馈强化学习(RLHF)方法，以优化生成图字对字幕模型，满足读者的偏好。我们通过在不同类型的模型之间进行标准微调来提高性能，从而证明了我们简单学习框架的有效性。特别地，当使用 BLIP 作为基本模型时，我们的 RLHF 框架在 ROUGE、 BLEU 和 Meetor 中分别获得了35.7% 、16.9% 和9% 的平均增益。最后，我们发布了一个大规模的基准数据集与人类反馈的图形-字幕对，使进一步的评估和发展 RLHF 技术的这一问题。"
    },
    {
        "title": "Alleviating the Long-Tail Problem in Conversational Recommender Systems",
        "url": "http://arxiv.org/abs/2307.11650v1",
        "pub_date": "2023-07-21",
        "summary": "Conversational recommender systems (CRS) aim to provide the recommendation\nservice via natural language conversations. To develop an effective CRS,\nhigh-quality CRS datasets are very crucial. However, existing CRS datasets\nsuffer from the long-tail issue, \\ie a large proportion of items are rarely (or\neven never) mentioned in the conversations, which are called long-tail items.\nAs a result, the CRSs trained on these datasets tend to recommend frequent\nitems, and the diversity of the recommended items would be largely reduced,\nmaking users easier to get bored.\n  To address this issue, this paper presents \\textbf{LOT-CRS}, a novel\nframework that focuses on simulating and utilizing a balanced CRS dataset (\\ie\ncovering all the items evenly) for improving \\textbf{LO}ng-\\textbf{T}ail\nrecommendation performance of CRSs. In our approach, we design two pre-training\ntasks to enhance the understanding of simulated conversation for long-tail\nitems, and adopt retrieval-augmented fine-tuning with label smoothness strategy\nto further improve the recommendation of long-tail items. Extensive experiments\non two public CRS datasets have demonstrated the effectiveness and\nextensibility of our approach, especially on long-tail recommendation.",
        "translated": "会话推荐系统(CRS)旨在通过自然语言会话提供推荐服务。为了建立一个有效的 CRS，高质量的 CRS 数据集是至关重要的。然而，现有的 CRS 数据集受到长尾问题的困扰，即大部分项目很少(甚至从未)在对话中被提及，这被称为长尾项目。因此，在这些数据集上训练的 CRS 倾向于推荐频繁项目，推荐项目的多样性将大大减少，使用户更容易感到厌烦。为了解决这个问题，本文提出了一个新的框架 textbf { LOT-CRS } ，该框架致力于模拟和利用一个平衡的 CRS 数据集(即均匀地覆盖所有项目) ，以提高 CRS 的 textbf { LO } ng-textbf { T } ail 推荐性能。该方法设计了两个预训练任务来提高对长尾条目模拟会话的理解，并采用标签平滑策略进行检索增强的微调以进一步提高长尾条目的推荐。在两个公共 CRS 数据集上的大量实验已经证明了该方法的有效性和可扩展性，尤其是在长尾推荐上。"
    },
    {
        "title": "Identifying document similarity using a fast estimation of the\n  Levenshtein Distance based on compression and signatures",
        "url": "http://arxiv.org/abs/2307.11496v1",
        "pub_date": "2023-07-21",
        "summary": "Identifying document similarity has many applications, e.g., source code\nanalysis or plagiarism detection. However, identifying similarities is not\ntrivial and can be time complex. For instance, the Levenshtein Distance is a\ncommon metric to define the similarity between two documents but has quadratic\nruntime which makes it impractical for large documents where large starts with\na few hundred kilobytes. In this paper, we present a novel concept that allows\nestimating the Levenshtein Distance: the algorithm first compresses documents\nto signatures (similar to hash values) using a user-defined compression ratio.\nSignatures can then be compared against each other (some constrains apply)\nwhere the outcome is the estimated Levenshtein Distance. Our evaluation shows\npromising results in terms of runtime efficiency and accuracy. In addition, we\nintroduce a significance score allowing examiners to set a threshold and\nidentify related documents.",
        "translated": "识别文档相似性有很多应用，如源代码分析或剽窃检测。然而，识别相似性并非易事，而且可能是时间复杂的。例如，莱文斯坦距离是定义两个文档之间相似性的一个常用指标，但是它有二次运行时，这使得它不适用于大型文档，因为大型文档以几百 kb 开头。在本文中，我们提出了一个新的概念，允许估计莱文斯坦距离: 算法首先压缩文件的签名(类似于哈希值)使用用户定义的压缩比。然后可以将签名相互比较(适用一些约束) ，其结果是估计的莱文斯坦距离。我们的评估在运行效率和准确性方面显示了有希望的结果。此外，我们还引入了一个显著性分数，允许考官设置一个阈值并识别相关文档。"
    },
    {
        "title": "Analysis of Elephant Movement in Sub-Saharan Africa: Ecological,\n  Climatic, and Conservation Perspectives",
        "url": "http://arxiv.org/abs/2307.11325v1",
        "pub_date": "2023-07-21",
        "summary": "The interaction between elephants and their environment has profound\nimplications for both ecology and conservation strategies. This study presents\nan analytical approach to decipher the intricate patterns of elephant movement\nin Sub-Saharan Africa, concentrating on key ecological drivers such as seasonal\nvariations and rainfall patterns. Despite the complexities surrounding these\ninfluential factors, our analysis provides a holistic view of elephant\nmigratory behavior in the context of the dynamic African landscape. Our\ncomprehensive approach enables us to predict the potential impact of these\necological determinants on elephant migration, a critical step in establishing\ninformed conservation strategies. This projection is particularly crucial given\nthe impacts of global climate change on seasonal and rainfall patterns, which\ncould substantially influence elephant movements in the future. The findings of\nour work aim to not only advance the understanding of movement ecology but also\nfoster a sustainable coexistence of humans and elephants in Sub-Saharan Africa.\nBy predicting potential elephant routes, our work can inform strategies to\nminimize human-elephant conflict, effectively manage land use, and enhance\nanti-poaching efforts. This research underscores the importance of integrating\nmovement ecology and climatic variables for effective wildlife management and\nconservation planning.",
        "translated": "大象与环境之间的相互作用对生态学和保护策略都有深远的影响。这项研究提供了一种分析方法来破译大象在撒哈拉以南非洲中错综复杂的运动模式，重点是关键的生态驱动因素，如季节变化和降雨模式。尽管围绕这些影响因素的复杂性，我们的分析提供了一个动态非洲景观背景下大象迁徙行为的整体观点。我们的综合方法使我们能够预测这些生态决定因素对大象迁徙的潜在影响，这是制定知情保护战略的关键一步。考虑到全球气候变化对季节和降雨模式的影响，这一预测尤为重要，因为季节和降雨模式可能对大象今后的活动产生重大影响。我们的研究结果不仅旨在加深对运动生态学的理解，也希望促进人类和大象在撒哈拉以南非洲中的可持续共存。通过预测潜在的大象路线，我们的工作可以为减少人象冲突、有效管理土地使用和加强反偷猎努力的战略提供信息。这项研究强调了整合运动生态学和气候变量对有效野生动物管理和保护规划的重要性。"
    },
    {
        "title": "Jina Embeddings: A Novel Set of High-Performance Sentence Embedding\n  Models",
        "url": "http://arxiv.org/abs/2307.11224v1",
        "pub_date": "2023-07-20",
        "summary": "Jina Embeddings constitutes a set of high-performance sentence embedding\nmodels adept at translating various textual inputs into numerical\nrepresentations, thereby capturing the semantic essence of the text. While\nthese models are not exclusively designed for text generation, they excel in\napplications such as dense retrieval and semantic textual similarity. This\npaper details the development of Jina Embeddings, starting with the creation of\na high-quality pairwise and triplet dataset. It underlines the crucial role of\ndata cleaning in dataset preparation, gives in-depth insights into the model\ntraining process, and concludes with a comprehensive performance evaluation\nusing the Massive Textual Embedding Benchmark (MTEB).",
        "translated": "《吉娜嵌入》构建了一套高性能的句子嵌入模型，该模型善于将各种文本输入转换为数字表示，从而捕捉到文本的语义本质。虽然这些模型不是专门为文本生成而设计的，但它们在密集检索和语义文本相似性等应用方面表现出色。本文详细介绍了 Jina Embeddings 的开发，首先创建了一个高质量的成对和三联体数据集。它强调了数据清理在数据集准备中的关键作用，对模型训练过程提供了深入的见解，并使用海量文本嵌入基准(MTEB)进行了全面的性能评估。"
    },
    {
        "title": "RCVaR: an Economic Approach to Estimate Cyberattacks Costs using Data\n  from Industry Reports",
        "url": "http://arxiv.org/abs/2307.11140v1",
        "pub_date": "2023-07-20",
        "summary": "Digitization increases business opportunities and the risk of companies being\nvictims of devastating cyberattacks. Therefore, managing risk exposure and\ncybersecurity strategies is essential for digitized companies that want to\nsurvive in competitive markets. However, understanding company-specific risks\nand quantifying their associated costs is not trivial. Current approaches fail\nto provide individualized and quantitative monetary estimations of\ncybersecurity impacts. Due to limited resources and technical expertise, SMEs\nand even large companies are affected and struggle to quantify their\ncyberattack exposure. Therefore, novel approaches must be placed to support the\nunderstanding of the financial loss due to cyberattacks. This article\nintroduces the Real Cyber Value at Risk (RCVaR), an economical approach for\nestimating cybersecurity costs using real-world information from public\ncybersecurity reports. RCVaR identifies the most significant cyber risk factors\nfrom various sources and combines their quantitative results to estimate\nspecific cyberattacks costs for companies. Furthermore, RCVaR extends current\nmethods to achieve cost and risk estimations based on historical real-world\ndata instead of only probability-based simulations. The evaluation of the\napproach on unseen data shows the accuracy and efficiency of the RCVaR in\npredicting and managing cyber risks. Thus, it shows that the RCVaR is a\nvaluable addition to cybersecurity planning and risk management processes.",
        "translated": "数字化增加了商业机会和公司成为毁灭性网络攻击受害者的风险。因此，管理风险暴露和网络安全战略对于希望在竞争市场中生存的数字化公司至关重要。然而，理解公司特有的风险并量化其相关成本并非易事。目前的方法无法对网络安全影响提供个性化和定量的货币估计。由于资源和技术专长有限，中小企业甚至大公司都受到影响，难以量化其遭受网络攻击的风险。因此，必须采取新的方法来支持对网络攻击造成的财务损失的理解。本文介绍了真实网络风险价值(RCVaR) ，这是一种利用公共网络安全报告中的真实信息来估算网络安全成本的经济方法。RCVaR 从各种来源确定了最重要的网络风险因素，并结合它们的定量结果来估计公司的具体网络攻击成本。此外，RCVaR 扩展了现有的方法来实现基于历史真实世界数据的成本和风险估计，而不仅仅是基于概率的模拟。对未知数据方法的评估显示了 RCVaR 在预测和管理网络风险方面的准确性和有效性。因此，它表明，RCVaR 是一个有价值的网络安全规划和风险管理过程的补充。"
    },
    {
        "title": "OUTFOX: LLM-generated Essay Detection through In-context Learning with\n  Adversarially Generated Examples",
        "url": "http://arxiv.org/abs/2307.11729v1",
        "pub_date": "2023-07-21",
        "summary": "Large Language Models (LLMs) have achieved human-level fluency in text\ngeneration, making it difficult to distinguish between human-written and\nLLM-generated texts. This poses a growing risk of misuse of LLMs and demands\nthe development of detectors to identify LLM-generated texts. However, existing\ndetectors degrade detection accuracy by simply paraphrasing LLM-generated\ntexts. Furthermore, the effectiveness of these detectors in real-life\nsituations, such as when students use LLMs for writing homework assignments\n(e.g., essays) and quickly learn how to evade these detectors, has not been\nexplored. In this paper, we propose OUTFOX, a novel framework that improves the\nrobustness of LLM-generated-text detectors by allowing both the detector and\nthe attacker to consider each other's output and apply this to the domain of\nstudent essays. In our framework, the attacker uses the detector's prediction\nlabels as examples for in-context learning and adversarially generates essays\nthat are harder to detect. While the detector uses the adversarially generated\nessays as examples for in-context learning to learn to detect essays from a\nstrong attacker. Our experiments show that our proposed detector learned\nin-context from the attacker improves the detection performance on the attacked\ndataset by up to +41.3 point F1-score. While our proposed attacker can\ndrastically degrade the performance of the detector by up to -57.0 point\nF1-score compared to the paraphrasing method.",
        "translated": "大语言模型(LLM)在文本生成方面已经达到了人类水平的流畅程度，因此很难区分人工编写的文本和 LLM 生成的文本。这提出了滥用 LLM 的越来越大的风险，并要求开发检测器来识别 LLM 生成的文本。然而，现有的检测器通过简单地解释 LLM 生成的文本降低了检测的准确性。此外，这些检测器在现实生活中的有效性，如当学生使用 LLM 写作业(例如，论文) ，并迅速学会如何规避这些检测器，还没有被探索。在本文中，我们提出了一种新的框架 OUTFOX，通过允许检测器和攻击者考虑彼此的输出，并将其应用到学生论文领域，提高了 LLM 生成文本检测器的鲁棒性。在我们的框架中，攻击者使用检测器的预测标签作为上下文学习的例子，并且对抗性地生成更难检测的文章。而检测器则使用对手生成的论文作为上下文学习的例子来学习如何检测来自强攻击者的论文。我们的实验表明，我们提出的检测器在上下文中学习攻击者提高了检测性能的攻击数据集达到 + 41.3点 F1得分。虽然我们提出的攻击者可以大大降低性能的检测器高达 -57.0点的 F1评分相比，释义方法。"
    },
    {
        "title": "Enhancing CLIP with GPT-4: Harnessing Visual Descriptions as Prompts",
        "url": "http://arxiv.org/abs/2307.11661v1",
        "pub_date": "2023-07-21",
        "summary": "Contrastive pretrained large Vision-Language Models (VLMs) like CLIP have\nrevolutionized visual representation learning by providing good performance on\ndownstream datasets. VLMs are 0-shot adapted to a downstream dataset by\ndesigning prompts that are relevant to the dataset. Such prompt engineering\nmakes use of domain expertise and a validation dataset. Meanwhile, recent\ndevelopments in generative pretrained models like GPT-4 mean they can be used\nas advanced internet search tools. They can also be manipulated to provide\nvisual information in any structure. In this work, we show that GPT-4 can be\nused to generate text that is visually descriptive and how this can be used to\nadapt CLIP to downstream tasks. We show considerable improvements in 0-shot\ntransfer accuracy on specialized fine-grained datasets like EuroSAT (~7%), DTD\n(~7%), SUN397 (~4.6%), and CUB (~3.3%) when compared to CLIP's default prompt.\nWe also design a simple few-shot adapter that learns to choose the best\npossible sentences to construct generalizable classifiers that outperform the\nrecently proposed CoCoOP by ~2% on average and by over 4% on 4 specialized\nfine-grained datasets. We will release the code, prompts, and auxiliary text\ndataset upon acceptance.",
        "translated": "对比预训练的大型视觉语言模型(VLMs) ，如 CLIP，通过在下游数据集上提供良好的性能，彻底改变了视觉表示学习。VLM 是通过设计与数据集相关的提示来适应下游数据集的0-shot。这种迅速的工程利用领域专业知识和验证数据集。与此同时，GPT-4等生成预训练模型的最新发展意味着它们可以用作先进的互联网搜索工具。它们也可以被操纵以在任何结构中提供视觉信息。在这项工作中，我们展示了 GPT-4可以用来生成可视化描述性的文本，以及如何使用它来使 CLIP 适应下游任务。与 CLIP 的默认提示符相比，我们在 EuroSAT (? 7%) ，DTD (? 7%) ，SUN397(? 4.6%)和 CUB (? 3.3%)等专门的细粒度数据集上显示出0镜头传输准确性的显着改善。我们还设计了一个简单的小镜头适配器，学习选择最佳可能的句子来构建可推广的分类器，平均比最近提出的 CoCoOP 高出约2% ，在4个专门的细粒度数据集上高出4% 以上。接受后，我们将发布代码、提示和辅助文本数据集。"
    },
    {
        "title": "OxfordTVG-HIC: Can Machine Make Humorous Captions from Images?",
        "url": "http://arxiv.org/abs/2307.11636v1",
        "pub_date": "2023-07-21",
        "summary": "This paper presents OxfordTVG-HIC (Humorous Image Captions), a large-scale\ndataset for humour generation and understanding. Humour is an abstract,\nsubjective, and context-dependent cognitive construct involving several\ncognitive factors, making it a challenging task to generate and interpret.\nHence, humour generation and understanding can serve as a new task for\nevaluating the ability of deep-learning methods to process abstract and\nsubjective information. Due to the scarcity of data, humour-related generation\ntasks such as captioning remain under-explored. To address this gap,\nOxfordTVG-HIC offers approximately 2.9M image-text pairs with humour scores to\ntrain a generalizable humour captioning model. Contrary to existing captioning\ndatasets, OxfordTVG-HIC features a wide range of emotional and semantic\ndiversity resulting in out-of-context examples that are particularly conducive\nto generating humour. Moreover, OxfordTVG-HIC is curated devoid of offensive\ncontent. We also show how OxfordTVG-HIC can be leveraged for evaluating the\nhumour of a generated text. Through explainability analysis of the trained\nmodels, we identify the visual and linguistic cues influential for evoking\nhumour prediction (and generation). We observe qualitatively that these cues\nare aligned with the benign violation theory of humour in cognitive psychology.",
        "translated": "本文介绍了用于幽默产生和理解的大规模数据集 OxfordTVG-HIC (幽默图像标题)。幽默是一种抽象的、主观的、与语境相关的认知结构，涉及多种认知因素，其产生和解释是一项具有挑战性的任务。因此，幽默的产生和理解可以成为评价深度学习方法处理抽象和主观信息能力的新课题。由于缺乏数据，与幽默相关的生成任务，如字幕仍然探索不足。为了弥补这一差距，OxfordTVG-HIC 提供了大约290万个带有幽默分数的图像-文本对，以训练一个可推广的幽默字幕模型。与现有的字幕数据集相反，OxfordTVG-HIC 具有广泛的情感和语义多样性，导致脱离上下文的例子，特别有利于产生幽默。此外，牛津 TVG-HIC 的策划没有令人反感的内容。我们还展示了如何利用 OxfordTVG-HIC 来评估生成文本的幽默感。通过对训练后的模型进行可解释性分析，我们识别了影响幽默预测(和生成)的视觉和语言线索。我们定性地观察到，这些线索与认知心理学中幽默的良性违反理论是一致的。"
    },
    {
        "title": "CausE: Towards Causal Knowledge Graph Embedding",
        "url": "http://arxiv.org/abs/2307.11610v2",
        "pub_date": "2023-07-21",
        "summary": "Knowledge graph embedding (KGE) focuses on representing the entities and\nrelations of a knowledge graph (KG) into the continuous vector spaces, which\ncan be employed to predict the missing triples to achieve knowledge graph\ncompletion (KGC). However, KGE models often only briefly learn structural\ncorrelations of triple data and embeddings would be misled by the trivial\npatterns and noisy links in real-world KGs. To address this issue, we build the\nnew paradigm of KGE in the context of causality and embedding disentanglement.\nWe further propose a Causality-enhanced knowledge graph Embedding (CausE)\nframework. CausE employs causal intervention to estimate the causal effect of\nthe confounder embeddings and design new training objectives to make stable\npredictions. Experimental results demonstrate that CausE could outperform the\nbaseline models and achieve state-of-the-art KGC performance. We release our\ncode in https://github.com/zjukg/CausE.",
        "translated": "知识图嵌入(KGE)是在连续向量空间中表示知识图(KG)的实体和关系，用来预测缺失的三元组，从而实现知识图的完备化(KGC)。然而，KGE 模型往往只是简单地学习三元数据的结构关联，嵌入会被现实 KG 中的琐碎模式和噪声链接所误导。为了解决这一问题，我们在因果关系和嵌入解纠缠的语境中构建了 KGE 的新范式。我们进一步提出了一个因果增强的知识图嵌入(CausE)框架。CausE 采用因果干预来估计混杂因素嵌入的因果效应，并设计新的训练目标来做出稳定的预测。实验结果表明，CausE 的性能优于基线模型，达到了最先进的 KGC 性能。我们以 https://github.com/zjukg/cause 的形式发布代码。"
    },
    {
        "title": "A Change of Heart: Improving Speech Emotion Recognition through\n  Speech-to-Text Modality Conversion",
        "url": "http://arxiv.org/abs/2307.11584v1",
        "pub_date": "2023-07-21",
        "summary": "Speech Emotion Recognition (SER) is a challenging task. In this paper, we\nintroduce a modality conversion concept aimed at enhancing emotion recognition\nperformance on the MELD dataset. We assess our approach through two\nexperiments: first, a method named Modality-Conversion that employs automatic\nspeech recognition (ASR) systems, followed by a text classifier; second, we\nassume perfect ASR output and investigate the impact of modality conversion on\nSER, this method is called Modality-Conversion++. Our findings indicate that\nthe first method yields substantial results, while the second method\noutperforms state-of-the-art (SOTA) speech-based approaches in terms of SER\nweighted-F1 (WF1) score on the MELD dataset. This research highlights the\npotential of modality conversion for tasks that can be conducted in alternative\nmodalities.",
        "translated": "语音情感识别(SER)是一项具有挑战性的任务。本文提出了一种模态转换概念，旨在提高 MELD 数据集的情绪识别性能。我们通过两个实验对我们的方法进行了评估: 第一个是采用自动语音识别(ASR)系统的模态转换方法，然后是文本分类器; 第二个是假设完全 ASR 输出，研究模态转换对 SER 的影响，这个方法叫做模态转换 + + 。我们的研究结果表明，第一种方法产生了实质性的结果，而第二种方法在 MELD 数据集上的 SER 加权 F1(WF1)评分方面优于最先进的(SOTA)基于语音的方法。这项研究强调了模式转换对于可以用替代模式进行的任务的潜力。"
    },
    {
        "title": "Advancing Visual Grounding with Scene Knowledge: Benchmark and Method",
        "url": "http://arxiv.org/abs/2307.11558v1",
        "pub_date": "2023-07-21",
        "summary": "Visual grounding (VG) aims to establish fine-grained alignment between vision\nand language. Ideally, it can be a testbed for vision-and-language models to\nevaluate their understanding of the images and texts and their reasoning\nabilities over their joint space. However, most existing VG datasets are\nconstructed using simple description texts, which do not require sufficient\nreasoning over the images and texts. This has been demonstrated in a recent\nstudy~\\cite{luo2022goes}, where a simple LSTM-based text encoder without\npretraining can achieve state-of-the-art performance on mainstream VG datasets.\nTherefore, in this paper, we propose a novel benchmark of \\underline{S}cene\n\\underline{K}nowledge-guided \\underline{V}isual \\underline{G}rounding (SK-VG),\nwhere the image content and referring expressions are not sufficient to ground\nthe target objects, forcing the models to have a reasoning ability on the\nlong-form scene knowledge. To perform this task, we propose two approaches to\naccept the triple-type input, where the former embeds knowledge into the image\nfeatures before the image-query interaction; the latter leverages linguistic\nstructure to assist in computing the image-text matching. We conduct extensive\nexperiments to analyze the above methods and show that the proposed approaches\nachieve promising results but still leave room for improvement, including\nperformance and interpretability. The dataset and code are available at\n\\url{https://github.com/zhjohnchan/SK-VG}.",
        "translated": "视觉基础(VG)旨在建立视觉和语言之间的细粒度对齐。理想情况下，它可以作为视觉和语言模型的试验台，以评估它们对图像和文本的理解以及它们在联合空间上的推理能力。然而，现有的 VG 数据集大多使用简单的描述文本构造，不需要对图像和文本进行充分的推理。这已经在最近的一项研究中得到了证实，该研究引用{ luo2022goes } ，其中一个简单的基于 LSTM 的文本编码器不需要预先训练就可以在主流 VG 数据集上实现最先进的性能。因此，本文提出了一种新的基准下划线{ S }场景下划线{ K }知识引导下划线{ V }等值下划线{ G }舍入(SK-VG)算法，其中图像内容和引用表达式不足以将目标物体置于地面，迫使模型具有对长形场景知识的推理能力。为了完成这一任务，我们提出了两种接受三类输入的方法，前者在图像-查询交互之前将知识嵌入到图像特征中; 后者利用语言结构来协助计算图像-文本匹配。我们进行了广泛的实验来分析上述方法，并表明所提出的方法取得了令人满意的结果，但仍然有改进的余地，包括性能和可解释性。数据集和代码可在 url { https://github.com/zhjohnchan/sk-vg }获得。"
    },
    {
        "title": "Bridging Vision and Language Encoders: Parameter-Efficient Tuning for\n  Referring Image Segmentation",
        "url": "http://arxiv.org/abs/2307.11545v1",
        "pub_date": "2023-07-21",
        "summary": "Parameter Efficient Tuning (PET) has gained attention for reducing the number\nof parameters while maintaining performance and providing better hardware\nresource savings, but few studies investigate dense prediction tasks and\ninteraction between modalities. In this paper, we do an investigation of\nefficient tuning problems on referring image segmentation. We propose a novel\nadapter called Bridger to facilitate cross-modal information exchange and\ninject task-specific information into the pre-trained model. We also design a\nlightweight decoder for image segmentation. Our approach achieves comparable or\nsuperior performance with only 1.61\\% to 3.38\\% backbone parameter updates,\nevaluated on challenging benchmarks. The code is available at\n\\url{https://github.com/kkakkkka/ETRIS}.",
        "translated": "参数有效调优(PET)在保持性能和提供更好的硬件资源节约的同时减少参数数量已经受到关注，但很少有研究探讨密集的预测任务和模式之间的相互作用。在本文中，我们研究了参考图像分割的有效调谐问题。我们提出了一个新的适配器称为桥梁，以促进跨模态信息交换和注入任务特定的信息到预先训练的模型。我们还为图像分割设计了一个轻量级解码器。我们的方法实现了可比或优越的性能，只有1.61% 至3.38% 的骨干参数更新，评估具有挑战性的基准。该代码可在 url { https://github.com/kkakkkka/etris }获得。"
    },
    {
        "title": "IndigoVX: Where Human Intelligence Meets AI for Optimal Decision Making",
        "url": "http://arxiv.org/abs/2307.11516v1",
        "pub_date": "2023-07-21",
        "summary": "This paper defines a new approach for augmenting human intelligence with AI\nfor optimal goal solving. Our proposed AI, Indigo, is an acronym for Informed\nNumerical Decision-making through Iterative Goal-Oriented optimization. When\ncombined with a human collaborator, we term the joint system IndigoVX, for\nVirtual eXpert. The system is conceptually simple. We envisage this method\nbeing applied to games or business strategies, with the human providing\nstrategic context and the AI offering optimal, data-driven moves. Indigo\noperates through an iterative feedback loop, harnessing the human expert's\ncontextual knowledge and the AI's data-driven insights to craft and refine\nstrategies towards a well-defined goal. Using a quantified three-score schema,\nthis hybridization allows the combined team to evaluate strategies and refine\ntheir plan, while adapting to challenges and changes in real-time.",
        "translated": "本文定义了一种用人工智能增强人类智能的新方法，用于最优目标求解。我们提出的人工智能，靛蓝，是通过迭代目标导向优化知情数值决策的缩写。当与人类合作者结合时，我们将联合系统靛蓝 VX 称为 Virtual eXpert。这个系统在概念上很简单。我们设想这种方法被应用于游戏或商业战略，人类提供战略背景和人工智能提供最佳的，数据驱动的行动。靛蓝通过一个迭代反馈回路运作，利用人类专家的背景知识和人工智能的数据驱动的洞察力来制定和完善战略，以实现一个明确的目标。使用一个量化的三分模式，这种混合允许合并的团队评估策略和完善他们的计划，同时适应实时的挑战和变化。"
    },
    {
        "title": "Incorporating Human Translator Style into English-Turkish Literary\n  Machine Translation",
        "url": "http://arxiv.org/abs/2307.11457v1",
        "pub_date": "2023-07-21",
        "summary": "Although machine translation systems are mostly designed to serve in the\ngeneral domain, there is a growing tendency to adapt these systems to other\ndomains like literary translation. In this paper, we focus on English-Turkish\nliterary translation and develop machine translation models that take into\naccount the stylistic features of translators. We fine-tune a pre-trained\nmachine translation model by the manually-aligned works of a particular\ntranslator. We make a detailed analysis of the effects of manual and automatic\nalignments, data augmentation methods, and corpus size on the translations. We\npropose an approach based on stylistic features to evaluate the style of a\ntranslator in the output translations. We show that the human translator style\ncan be highly recreated in the target machine translations by adapting the\nmodels to the style of the translator.",
        "translated": "尽管机器翻译系统大多被设计用于一般领域，但是将这些系统应用于文学翻译等其他领域的趋势正在增长。本文以英语-土耳其文学翻译为研究对象，建立了考虑译者文体特征的机器翻译模式。我们通过特定翻译者的手动对齐工作来微调预先训练好的机器翻译模型。我们详细分析了手动和自动对齐、数据增强方法以及语料库大小对翻译的影响。本文提出了一种基于文体特征的翻译风格评估方法。实验结果表明，在目标机器翻译中，通过调整翻译模型使之适应译者的翻译风格，可以高度重现译者的翻译风格。"
    },
    {
        "title": "Topic Identification For Spontaneous Speech: Enriching Audio Features\n  With Embedded Linguistic Information",
        "url": "http://arxiv.org/abs/2307.11450v1",
        "pub_date": "2023-07-21",
        "summary": "Traditional topic identification solutions from audio rely on an automatic\nspeech recognition system (ASR) to produce transcripts used as input to a\ntext-based model. These approaches work well in high-resource scenarios, where\nthere are sufficient data to train both components of the pipeline. However, in\nlow-resource situations, the ASR system, even if available, produces\nlow-quality transcripts, leading to a bad text-based classifier. Moreover,\nspontaneous speech containing hesitations can further degrade the performance\nof the ASR model. In this paper, we investigate alternatives to the standard\ntext-only solutions by comparing audio-only and hybrid techniques of jointly\nutilising text and audio features. The models evaluated on spontaneous Finnish\nspeech demonstrate that purely audio-based solutions are a viable option when\nASR components are not available, while the hybrid multi-modal solutions\nachieve the best results.",
        "translated": "传统的音频主题识别解决方案依赖于一个自动语音识别系统(ASR) ，以产生文本输入到基于文本的模型。这些方法在高资源场景中运行良好，在这些场景中有足够的数据来训练管道的两个组件。然而，在资源不足的情况下，ASR 系统即使可用，也会产生低质量的文本，从而导致基于文本的分类器出现问题。此外，含有犹豫的自发语音会进一步降低 ASR 模型的性能。本文通过比较纯音频和混合技术联合使用文本和音频特征，探讨了标准纯文本解决方案的替代方案。在自发芬兰语言评估的模型表明，纯音频为基础的解决方案是一个可行的选择时，ASR 组件不可用，而混合多模态解决方案取得最佳效果。"
    },
    {
        "title": "HeteFedRec: Federated Recommender Systems with Model Heterogeneity",
        "url": "http://arxiv.org/abs/2307.12810v1",
        "pub_date": "2023-07-24",
        "summary": "Owing to the nature of privacy protection, federated recommender systems\n(FedRecs) have garnered increasing interest in the realm of on-device\nrecommender systems. However, most existing FedRecs only allow participating\nclients to collaboratively train a recommendation model of the same public\nparameter size. Training a model of the same size for all clients can lead to\nsuboptimal performance since clients possess varying resources. For example,\nclients with limited training data may prefer to train a smaller recommendation\nmodel to avoid excessive data consumption, while clients with sufficient data\nwould benefit from a larger model to achieve higher recommendation accuracy. To\naddress the above challenge, this paper introduces HeteFedRec, a novel FedRec\nframework that enables the assignment of personalized model sizes to\nparticipants. In HeteFedRec, we present a heterogeneous recommendation model\naggregation strategy, including a unified dual-task learning mechanism and a\ndimensional decorrelation regularization, to allow knowledge aggregation among\nrecommender models of different sizes. Additionally, a relation-based ensemble\nknowledge distillation method is proposed to effectively distil knowledge from\nheterogeneous item embeddings. Extensive experiments conducted on three\nreal-world recommendation datasets demonstrate the effectiveness and efficiency\nof HeteFedRec in training federated recommender systems under heterogeneous\nsettings.",
        "translated": "由于隐私保护的特性，联邦推荐系统(FedRecs)在设备上推荐系统领域引起了越来越多的兴趣。然而，大多数现有的 FedRecs 只允许参与的客户协同训练相同公共参数大小的推荐模型。由于客户拥有不同的资源，为所有客户训练同样大小的模型可能导致次优性能。例如，培训数据有限的客户可能更愿意培训较小的推荐模型，以避免过多的数据消耗，而数据充足的客户将受益于较大的模型，以实现更高的推荐准确性。为了解决上述问题，本文介绍了一种新的 FedRec 框架 HeteFedRec，它可以为参与者分配个性化的模型大小。在 HeteFedRec 中，我们提出了一种异构推荐模型聚合策略，包括一个统一的双任务学习机制和一个维度去相关正则化，允许不同规模的推荐模型之间进行知识聚合。此外，提出了一种基于关系的集成知识提取方法，有效地从异构项嵌入中提取知识。在三个实际推荐数据集上进行的大量实验证明了 HeteFedRec 在异构环境下训练联邦推荐系统的有效性和高效性。"
    },
    {
        "title": "RRAML: Reinforced Retrieval Augmented Machine Learning",
        "url": "http://arxiv.org/abs/2307.12798v1",
        "pub_date": "2023-07-24",
        "summary": "The emergence of large language models (LLMs) has revolutionized machine\nlearning and related fields, showcasing remarkable abilities in comprehending,\ngenerating, and manipulating human language. However, their conventional usage\nthrough API-based text prompt submissions imposes certain limitations in terms\nof context constraints and external source availability. To address these\nchallenges, we propose a novel framework called Reinforced Retrieval Augmented\nMachine Learning (RRAML). RRAML integrates the reasoning capabilities of LLMs\nwith supporting information retrieved by a purpose-built retriever from a vast\nuser-provided database. By leveraging recent advancements in reinforcement\nlearning, our method effectively addresses several critical challenges.\nFirstly, it circumvents the need for accessing LLM gradients. Secondly, our\nmethod alleviates the burden of retraining LLMs for specific tasks, as it is\noften impractical or impossible due to restricted access to the model and the\ncomputational intensity involved. Additionally we seamlessly link the\nretriever's task with the reasoner, mitigating hallucinations and reducing\nirrelevant, and potentially damaging retrieved documents. We believe that the\nresearch agenda outlined in this paper has the potential to profoundly impact\nthe field of AI, democratizing access to and utilization of LLMs for a wide\nrange of entities.",
        "translated": "大型语言模型(LLM)的出现给机器学习及其相关领域带来了革命性的变化，展示了理解、生成和操纵人类语言的卓越能力。然而，它们通过基于 API 的文本提示提交的传统使用方式在上下文约束和外部源可用性方面带来了某些限制。为了应对这些挑战，我们提出了一个新的框架，称为增强检索增强机器学习(RRAML)。RRAML 将 LLM 的推理能力与支持信息集成在一起，这些信息由一个专门构建的检索器从一个巨大的用户提供的数据库中检索出来。通过利用最近在强化学习方面的进展，我们的方法有效地解决了几个关键的挑战。首先，它绕过了访问 LLM 梯度的需要。其次，我们的方法减轻了对特定任务再训练 LLM 的负担，因为由于对模型的访问受到限制以及所涉及的计算强度，再训练 LLM 常常是不切实际或不可能的。此外，我们将寻回者的任务与推理程序无缝地连接起来，减少幻觉，减少不相关的、可能具有破坏性的寻回文档。我们认为，本文件概述的研究议程有可能对人工智能领域产生深刻影响，使广大实体获得和利用有限制药物的机会民主化。"
    },
    {
        "title": "Unbiased Delayed Feedback Label Correction for Conversion Rate\n  Prediction",
        "url": "http://arxiv.org/abs/2307.12756v1",
        "pub_date": "2023-07-24",
        "summary": "Conversion rate prediction is critical to many online applications such as\ndigital display advertising. To capture dynamic data distribution, industrial\nsystems often require retraining models on recent data daily or weekly.\nHowever, the delay of conversion behavior usually leads to incorrect labeling,\nwhich is called delayed feedback problem. Existing work may fail to introduce\nthe correct information about false negative samples due to data sparsity and\ndynamic data distribution. To directly introduce the correct feedback label\ninformation, we propose an Unbiased delayed feedback Label Correction framework\n(ULC), which uses an auxiliary model to correct labels for observed negative\nfeedback samples. Firstly, we theoretically prove that the label-corrected loss\nis an unbiased estimate of the oracle loss using true labels. Then, as there\nare no ready training data for label correction, counterfactual labeling is\nused to construct artificial training data. Furthermore, since counterfactual\nlabeling utilizes only partial training data, we design an embedding-based\nalternative training method to enhance performance. Comparative experiments on\nboth public and private datasets and detailed analyses show that our proposed\napproach effectively alleviates the delayed feedback problem and consistently\noutperforms the previous state-of-the-art methods.",
        "translated": "转化率预测是许多在线应用程序，如数字显示广告的关键。为了捕获动态数据分布，工业系统通常需要每天或每周对最近的数据进行再训练。然而，转换行为的延迟通常会导致不正确的标记，这就是所谓的延迟反馈问题。由于数据稀疏和数据分布的动态性，现有的工作可能无法引入正确的假阴性样本信息。为了直接引入正确的反馈标签信息，我们提出了一种无偏的延迟反馈标签校正框架(ULC) ，它使用一个辅助模型对观测到的负反馈样本进行标签校正。首先，我们从理论上证明了标签校正损失是使用真实标签对甲骨文损失进行的无偏估计。然后，由于没有现成的训练数据用于标签校正，采用反事实标注来构造人工训练数据。此外，由于反事实标注只利用部分训练数据，我们设计了一个基于嵌入的替代训练方法来提高性能。对公共和私人数据集的比较实验和详细的分析表明，我们提出的方法有效地缓解了延迟反馈问题，并始终优于以前的国家最先进的方法。"
    },
    {
        "title": "Self-refining of Pseudo Labels for Music Source Separation with Noisy\n  Labeled Data",
        "url": "http://arxiv.org/abs/2307.12576v1",
        "pub_date": "2023-07-24",
        "summary": "Music source separation (MSS) faces challenges due to the limited\navailability of correctly-labeled individual instrument tracks. With the push\nto acquire larger datasets to improve MSS performance, the inevitability of\nencountering mislabeled individual instrument tracks becomes a significant\nchallenge to address. This paper introduces an automated technique for refining\nthe labels in a partially mislabeled dataset. Our proposed self-refining\ntechnique, employed with a noisy-labeled dataset, results in only a 1% accuracy\ndegradation in multi-label instrument recognition compared to a classifier\ntrained on a clean-labeled dataset. The study demonstrates the importance of\nrefining noisy-labeled data in MSS model training and shows that utilizing the\nrefined dataset leads to comparable results derived from a clean-labeled\ndataset. Notably, upon only access to a noisy dataset, MSS models trained on a\nself-refined dataset even outperform those trained on a dataset refined with a\nclassifier trained on clean labels.",
        "translated": "音乐源分离(MSS)面临的挑战，由于有限的可用性正确标记的个人乐器轨道。随着获取更大数据集以提高 MSS 性能的推进，不可避免地会遇到标记错误的单个仪器轨迹成为一个重大的挑战。本文介绍了一种在部分错误标注的数据集中精炼标签的自动化技术。我们提出的自我精炼技术，使用噪声标记数据集，结果只有1% 的准确性降低多标签仪器识别相比，清洁标记数据集训练的分类器。该研究证明了在 MSS 模型训练中精化带噪标记数据的重要性，并表明利用精化数据集可以得到从干净标记数据集得到的可比结果。值得注意的是，在只访问一个有噪声的数据集，MSS 模型训练在一个自我完善的数据集，甚至优于那些训练在一个数据集上训练的分类器训练在干净的标签。"
    },
    {
        "title": "FaFCNN: A General Disease Classification Framework Based on Feature\n  Fusion Neural Networks",
        "url": "http://arxiv.org/abs/2307.12518v1",
        "pub_date": "2023-07-24",
        "summary": "There are two fundamental problems in applying deep learning/machine learning\nmethods to disease classification tasks, one is the insufficient number and\npoor quality of training samples; another one is how to effectively fuse\nmultiple source features and thus train robust classification models. To\naddress these problems, inspired by the process of human learning knowledge, we\npropose the Feature-aware Fusion Correlation Neural Network (FaFCNN), which\nintroduces a feature-aware interaction module and a feature alignment module\nbased on domain adversarial learning. This is a general framework for disease\nclassification, and FaFCNN improves the way existing methods obtain sample\ncorrelation features. The experimental results show that training using\naugmented features obtained by pre-training gradient boosting decision tree\nyields more performance gains than random-forest based methods. On the\nlow-quality dataset with a large amount of missing data in our setup, FaFCNN\nobtains a consistently optimal performance compared to competitive baselines.\nIn addition, extensive experiments demonstrate the robustness of the proposed\nmethod and the effectiveness of each component of the model\\footnote{Accepted\nin IEEE SMC2023}.",
        "translated": "将深度学习/机器学习方法应用于疾病分类任务中存在两个基本问题: 一是训练样本数量不足，质量差; 二是如何有效地融合多源特征，从而训练出鲁棒的分类模型。针对这些问题，受人类学习知识过程的启发，本文提出了基于领域对抗学习的特征感知融合相关神经网络(FaFCNN) ，该网络引入了一个特征感知交互模块和一个特征对齐模块。这是一个通用的疾病分类框架，并且 FaFCNN 改进了现有方法获取样本相关特征的方法。实验结果表明，使用预训练梯度提升决策树获得的增强特征进行训练比基于随机森林的方法获得更多的性能增益。在低质量的数据集与大量的缺失数据在我们的设置，FAFCNN 获得了一致的最佳性能相比，竞争的基线。此外，大量的实验证明了该方法的鲁棒性和模型脚注{接受在 IEEE SMC2023}中的每个组件的有效性。"
    },
    {
        "title": "3D-LLM: Injecting the 3D World into Large Language Models",
        "url": "http://arxiv.org/abs/2307.12981v1",
        "pub_date": "2023-07-24",
        "summary": "Large language models (LLMs) and Vision-Language Models (VLMs) have been\nproven to excel at multiple tasks, such as commonsense reasoning. Powerful as\nthese models can be, they are not grounded in the 3D physical world, which\ninvolves richer concepts such as spatial relationships, affordances, physics,\nlayout, and so on. In this work, we propose to inject the 3D world into large\nlanguage models and introduce a whole new family of 3D-LLMs. Specifically,\n3D-LLMs can take 3D point clouds and their features as input and perform a\ndiverse set of 3D-related tasks, including captioning, dense captioning, 3D\nquestion answering, task decomposition, 3D grounding, 3D-assisted dialog,\nnavigation, and so on. Using three types of prompting mechanisms that we\ndesign, we are able to collect over 300k 3D-language data covering these tasks.\nTo efficiently train 3D-LLMs, we first utilize a 3D feature extractor that\nobtains 3D features from rendered multi- view images. Then, we use 2D VLMs as\nour backbones to train our 3D-LLMs. By introducing a 3D localization mechanism,\n3D-LLMs can better capture 3D spatial information. Experiments on ScanQA show\nthat our model outperforms state-of-the-art baselines by a large margin (e.g.,\nthe BLEU-1 score surpasses state-of-the-art score by 9%). Furthermore,\nexperiments on our held-in datasets for 3D captioning, task composition, and\n3D-assisted dialogue show that our model outperforms 2D VLMs. Qualitative\nexamples also show that our model could perform more tasks beyond the scope of\nexisting LLMs and VLMs. Project Page: : https://vis-www.cs.umass.edu/3dllm/.",
        "translated": "大型语言模型(LLM)和视觉语言模型(VLM)已被证明能够胜任多种任务，例如常识推理。尽管这些模型非常强大，但它们并不基于3D 物理世界，而3D 物理世界包含更丰富的概念，如空间关系、可启示性、物理学、布局等。在这项工作中，我们建议将3D 世界注入到大型语言模型中，并引入一个全新的3D-LLM 系列。具体来说，3D-LLM 可以将3D 点云及其特征作为输入，并执行一组不同的3D 相关任务，包括字幕、密集字幕、3D 问题回答、任务分解、3D 接地、3D 辅助对话、导航等。使用我们设计的三种类型的提示机制，我们能够收集超过30万的3D 语言数据涵盖这些任务。为了有效地训练3D-LLM，我们首先利用一个3D 特征提取器从渲染的多视图图像中提取3D 特征。然后，我们使用2D VLM 作为我们的骨干训练我们的3D-LLM。通过引入三维定位机制，三维 LLM 可以更好地捕获三维空间信息。在 ScanQA 上的实验表明，我们的模型比最先进的基线表现好很多(例如，BLEU-1评分比最先进的评分高出9%)。此外，在我们的3D 字幕、任务组合和3D 辅助对话的固定数据集上的实验表明，我们的模型优于2D VLM。定性示例还表明，我们的模型可以执行超出现有 LLM 和 VLM 范围的更多任务。项目网页: :  https://vis-www.cs.umass.edu/3dllm/。"
    },
    {
        "title": "Evaluating the Ripple Effects of Knowledge Editing in Language Models",
        "url": "http://arxiv.org/abs/2307.12976v1",
        "pub_date": "2023-07-24",
        "summary": "Modern language models capture a large body of factual knowledge. However,\nsome facts can be incorrectly induced or become obsolete over time, resulting\nin factually incorrect generations. This has led to the development of various\nediting methods that allow updating facts encoded by the model. Evaluation of\nthese methods has primarily focused on testing whether an individual fact has\nbeen successfully injected, and if similar predictions for other subjects have\nnot changed. Here we argue that such evaluation is limited, since injecting one\nfact (e.g. ``Jack Depp is the son of Johnny Depp'') introduces a ``ripple\neffect'' in the form of additional facts that the model needs to update\n(e.g.``Jack Depp is the sibling of Lily-Rose Depp''). To address this issue, we\npropose a novel set of evaluation criteria that consider the implications of an\nedit on related facts. Using these criteria, we then construct \\ripple{}, a\ndiagnostic benchmark of 5K factual edits, capturing a variety of types of\nripple effects. We evaluate prominent editing methods on \\ripple{}, showing\nthat current methods fail to introduce consistent changes in the model's\nknowledge. In addition, we find that a simple in-context editing baseline\nobtains the best scores on our benchmark, suggesting a promising research\ndirection for model editing.",
        "translated": "现代语言模型捕捉了大量的事实知识。然而，随着时间的推移，一些事实可能被错误地归纳出来或者变得过时，从而导致事实上的错误产生。这导致了各种编辑方法的开发，这些方法允许更新由模型编码的事实。这些方法的评估主要集中在测试个别事实是否已成功注射，以及对其他受试者的类似预测是否没有改变。在这里，我们认为这样的评估是有限的，因为注入一个事实(例如“杰克 · 德普是约翰尼 · 德普的儿子”)会引入一个“连锁反应”，即模型需要更新的额外事实(例如“杰克 · 德普是莉莉-罗斯 · 德普的兄弟姐妹”)。为了解决这个问题，我们提出了一套新的评估标准，考虑编辑对相关事实的影响。使用这些标准，我们然后构建涟漪{} ，5K 实际编辑的诊断基准，捕获各种类型的涟漪效应。我们评估的涟漪{}突出的编辑方法，表明目前的方法不能引入一致的变化模型的知识。此外，我们发现一个简单的上下文编辑基线获得最好的分数在我们的基准，提出了一个有希望的研究方向模型编辑。"
    },
    {
        "title": "Leveraging Label Variation in Large Language Models for Zero-Shot Text\n  Classification",
        "url": "http://arxiv.org/abs/2307.12973v1",
        "pub_date": "2023-07-24",
        "summary": "The zero-shot learning capabilities of large language models (LLMs) make them\nideal for text classification without annotation or supervised training. Many\nstudies have shown impressive results across multiple tasks. While tasks, data,\nand results differ widely, their similarities to human annotation can aid us in\ntackling new tasks with minimal expenses. We evaluate using 5 state-of-the-art\nLLMs as \"annotators\" on 5 different tasks (age, gender, topic, sentiment\nprediction, and hate speech detection), across 4 languages: English, French,\nGerman, and Spanish. No single model excels at all tasks, across languages, or\nacross all labels within a task. However, aggregation techniques designed for\nhuman annotators perform substantially better than any one individual model.\nOverall, though, LLMs do not rival even simple supervised models, so they do\nnot (yet) replace the need for human annotation. We also discuss the tradeoffs\nbetween speed, accuracy, cost, and bias when it comes to aggregated model\nlabeling versus human annotation.",
        "translated": "大型语言模型(LLM)的零点学习能力使它们成为无需注释或监督训练的文本分类的理想选择。许多研究表明，在多个任务中都取得了令人印象深刻的结果。虽然任务、数据和结果差别很大，但它们与人工注释的相似性可以帮助我们以最小的开销处理新任务。我们使用5种最先进的 LLM 作为5种不同任务(年龄，性别，主题，情绪预测和仇恨言论检测)的“注释者”，跨越4种语言: 英语，法语，德语和西班牙语。没有任何一个模型在所有任务、跨语言或任务中的所有标签方面都表现出色。然而，为人工注释者设计的聚合技术比任何一个单独的模型都要好得多。不过，总体而言，LLM 甚至不能与简单的监督模型相媲美，因此它们还不能取代人工注释的需要。当涉及到聚合模型标注和人工注释时，我们还讨论了速度、准确性、成本和偏差之间的权衡。"
    },
    {
        "title": "Aligning Large Language Models with Human: A Survey",
        "url": "http://arxiv.org/abs/2307.12966v1",
        "pub_date": "2023-07-24",
        "summary": "Large Language Models (LLMs) trained on extensive textual corpora have\nemerged as leading solutions for a broad array of Natural Language Processing\n(NLP) tasks. Despite their notable performance, these models are prone to\ncertain limitations such as misunderstanding human instructions, generating\npotentially biased content, or factually incorrect (hallucinated) information.\nHence, aligning LLMs with human expectations has become an active area of\ninterest within the research community. This survey presents a comprehensive\noverview of these alignment technologies, including the following aspects. (1)\nData collection: the methods for effectively collecting high-quality\ninstructions for LLM alignment, including the use of NLP benchmarks, human\nannotations, and leveraging strong LLMs. (2) Training methodologies: a detailed\nreview of the prevailing training methods employed for LLM alignment. Our\nexploration encompasses Supervised Fine-tuning, both Online and Offline human\npreference training, along with parameter-efficient training mechanisms. (3)\nModel Evaluation: the methods for evaluating the effectiveness of these\nhuman-aligned LLMs, presenting a multifaceted approach towards their\nassessment. In conclusion, we collate and distill our findings, shedding light\non several promising future research avenues in the field. This survey,\ntherefore, serves as a valuable resource for anyone invested in understanding\nand advancing the alignment of LLMs to better suit human-oriented tasks and\nexpectations. An associated GitHub link collecting the latest papers is\navailable at https://github.com/GaryYufei/AlignLLMHumanSurvey.",
        "translated": "大型语言模型(LLM)已经成为自然语言处理(NLP)任务的主要解决方案。尽管这些模型具有显著的性能，但是它们容易受到某些限制，例如误解人类指令、产生潜在的偏见内容或事实上不正确的(幻觉)信息。因此，使 LLM 符合人类的期望已经成为研究界的一个活跃的兴趣领域。本调查全面概述了这些校准技术，包括以下几个方面。(1)数据收集: 有效收集 LLM 校准高质量指令的方法，包括使用 NLP 基准、人工注释和利用强 LLM。(2)培训方法: 详细审查长期管理联盟采用的现行培训方法。我们的探索包括有监督的微调，两个在线和离线的人类偏好训练，以及参数有效的训练机制。(3)模型评估: 评估这些与人类一致的 LLM 的有效性的方法，提出了一个多方面的方法来评估它们。总之，我们整理并提炼了我们的发现，阐明了该领域未来几个有希望的研究途径。因此，对于那些致力于理解和推进 LLM 的一致性以更好地适应以人为本的任务和期望的人来说，这个调查是一个宝贵的资源。收集最新论文的相关 GitHub 链接可在 https://GitHub.com/garyyufei/alignllmhumansurvey 获得。"
    },
    {
        "title": "RLCD: Reinforcement Learning from Contrast Distillation for Language\n  Model Alignment",
        "url": "http://arxiv.org/abs/2307.12950v1",
        "pub_date": "2023-07-24",
        "summary": "We propose Reinforcement Learning from Contrast Distillation (RLCD), a method\nfor aligning language models to follow natural language principles without\nusing human feedback. RLCD trains a preference model using simulated preference\npairs that contain both a high-quality and low-quality example, generated using\ncontrasting positive and negative prompts. The preference model is then used to\nimprove a base unaligned language model via reinforcement learning.\nEmpirically, RLCD outperforms RLAIF (Bai et al., 2022b) and context\ndistillation (Huang et al., 2022) baselines across three diverse alignment\ntasks--harmlessness, helpfulness, and story outline generation--and on both 7B\nand 30B model scales for preference data simulation.",
        "translated": "我们从对比蒸馏(rLCD)中提出了强化学习，这是一种无需人工反馈就能使语言模型遵循自然语言原则的方法。RLCD 使用包含高质量和低质量示例的模拟偏好对训练偏好模型，该模型使用对比的正面和负面提示生成。然后使用偏好模型通过强化学习来改进基本的未对齐语言模型。经验表明，RLCD 在三种不同的校准任务(无害性，有益性和故事大纲生成)中以及在偏好数据模拟的7B 和30B 模型尺度上都优于 RLAIF (Pak et al。 ，2022b)和上下文精馏(Huang et al。 ，2022)基线。"
    },
    {
        "title": "Boosting Punctuation Restoration with Data Generation and Reinforcement\n  Learning",
        "url": "http://arxiv.org/abs/2307.12949v1",
        "pub_date": "2023-07-24",
        "summary": "Punctuation restoration is an important task in automatic speech recognition\n(ASR) which aim to restore the syntactic structure of generated ASR texts to\nimprove readability. While punctuated texts are abundant from written\ndocuments, the discrepancy between written punctuated texts and ASR texts\nlimits the usability of written texts in training punctuation restoration\nsystems for ASR texts. This paper proposes a reinforcement learning method to\nexploit in-topic written texts and recent advances in large pre-trained\ngenerative language models to bridge this gap. The experiments show that our\nmethod achieves state-of-the-art performance on the ASR test set on two\nbenchmark datasets for punctuation restoration.",
        "translated": "标点恢复是自动语音识别(ASR)中的一项重要任务，其目的是恢复生成的 ASR 文本的句法结构以提高可读性。虽然标点文本与书面文本相比具有丰富的内容，但书面标点文本与 ASR 文本之间的差异限制了书面文本在 ASR 文本标点恢复系统训练中的可用性。这篇文章提出了一种强化学习的方法来利用主题内的书面文本和大型预先训练的生成语言模型的最新进展来弥补这一差距。实验结果表明，该方法在两个基准数据集上的标点恢复 ASR 测试集上取得了较好的性能。"
    },
    {
        "title": "Rule By Example: Harnessing Logical Rules for Explainable Hate Speech\n  Detection",
        "url": "http://arxiv.org/abs/2307.12935v1",
        "pub_date": "2023-07-24",
        "summary": "Classic approaches to content moderation typically apply a rule-based\nheuristic approach to flag content. While rules are easily customizable and\nintuitive for humans to interpret, they are inherently fragile and lack the\nflexibility or robustness needed to moderate the vast amount of undesirable\ncontent found online today. Recent advances in deep learning have demonstrated\nthe promise of using highly effective deep neural models to overcome these\nchallenges. However, despite the improved performance, these data-driven models\nlack transparency and explainability, often leading to mistrust from everyday\nusers and a lack of adoption by many platforms. In this paper, we present Rule\nBy Example (RBE): a novel exemplar-based contrastive learning approach for\nlearning from logical rules for the task of textual content moderation. RBE is\ncapable of providing rule-grounded predictions, allowing for more explainable\nand customizable predictions compared to typical deep learning-based\napproaches. We demonstrate that our approach is capable of learning rich rule\nembedding representations using only a few data examples. Experimental results\non 3 popular hate speech classification datasets show that RBE is able to\noutperform state-of-the-art deep learning classifiers as well as the use of\nrules in both supervised and unsupervised settings while providing explainable\nmodel predictions via rule-grounding.",
        "translated": "内容审核的经典方法通常应用基于规则的启发式方法来标记内容。虽然规则很容易定制，人们可以凭直觉来解释，但它们本质上是脆弱的，缺乏必要的灵活性或健壮性来缓和当今在线发现的大量不受欢迎的内容。深度学习的最新进展已经证明了使用高效的深度神经模型来克服这些挑战的前景。然而，尽管性能有所提高，但这些数据驱动模型缺乏透明度和可解释性，常常导致日常用户的不信任，以及许多平台缺乏采用。本文提出了一种新的基于范例的对比学习方法，用于从逻辑规则中学习文本内容调节任务。RBE 能够提供基于规则的预测，与典型的基于深度学习的方法相比，它允许更多可解释和可定制的预测。我们证明了我们的方法能够学习丰富的规则嵌入表示只使用少数数据示例。实验结果表明，RBE 能够胜过最先进的深度学习分类器，并能够在监督和非监督环境下使用规则，同时通过规则基础提供可解释的模型预测。"
    },
    {
        "title": "Corrections of Zipf's and Heaps' Laws Derived from Hapax Rate Models",
        "url": "http://arxiv.org/abs/2307.12896v2",
        "pub_date": "2023-07-24",
        "summary": "The article introduces corrections to Zipf's and Heaps' laws based on\nsystematic models of the hapax rate. The derivation rests on two assumptions:\nThe first one is the standard urn model which predicts that marginal frequency\ndistributions for shorter texts look as if word tokens were sampled blindly\nfrom a given longer text. The second assumption posits that the rate of hapaxes\nis a simple function of the text size. Four such functions are discussed: the\nconstant model, the Davis model, the linear model, and the logistic model. It\nis shown that the logistic model yields the best fit.",
        "translated": "本文在哈帕克斯率系统模型的基础上，介绍了对齐普夫定律和希普斯定律的修正。这种推导基于两个假设: 第一个假设是标准的 urn 模型，该模型预测较短文本的边际频率分布看起来好像是从给定的较长文本中盲目地抽取单词标记。第二个假设假定哈帕克斯率是文本大小的一个简单函数。讨论了常数模型、戴维斯模型、线性模型和逻辑斯蒂模型。结果表明，逻辑模型的拟合效果最好。"
    },
    {
        "title": "A Real-World WebAgent with Planning, Long Context Understanding, and\n  Program Synthesis",
        "url": "http://arxiv.org/abs/2307.12856v1",
        "pub_date": "2023-07-24",
        "summary": "Pre-trained large language models (LLMs) have recently achieved better\ngeneralization and sample efficiency in autonomous web navigation. However, the\nperformance on real-world websites has still suffered from (1) open domainness,\n(2) limited context length, and (3) lack of inductive bias on HTML. We\nintroduce WebAgent, an LLM-driven agent that can complete the tasks on real\nwebsites following natural language instructions. WebAgent plans ahead by\ndecomposing instructions into canonical sub-instructions, summarizes long HTML\ndocuments into task-relevant snippets, and acts on websites via generated\nPython programs from those. We design WebAgent with Flan-U-PaLM, for grounded\ncode generation, and HTML-T5, new pre-trained LLMs for long HTML documents\nusing local and global attention mechanisms and a mixture of long-span\ndenoising objectives, for planning and summarization. We empirically\ndemonstrate that our recipe improves the success on a real website by over 50%,\nand that HTML-T5 is the best model to solve HTML-based tasks; achieving 14.9%\nhigher success rate than prior SoTA on the MiniWoB web navigation benchmark and\nbetter accuracy on offline task planning evaluation.",
        "translated": "预训练的大语言模型(LLM)在自主网页导航中取得了较好的泛化能力和样本效率。然而，真实网站的性能仍然受到以下因素的影响: (1)开放领域，(2)有限的上下文长度，(3)缺乏对 HTML 的归纳偏见。我们介绍了 WebAgent，一个 LLM 驱动的代理，它可以按照自然语言指令在真实的网站上完成任务。WebAgent 通过将指令分解为规范的子指令来提前计划，将长 HTML 文档总结为与任务相关的片段，并通过从这些子指令生成的 Python 程序在网站上进行操作。我们使用 Flan-U-PaLM 设计 WebAgent，用于基础代码生成，使用 HTML-T5，新的预先训练的 LLM，用于长 HTML 文档，使用局部和全局注意机制以及混合的大跨度去噪目标，用于计划和总结。我们的经验证明，我们的配方提高了50% 以上的成功在一个真正的网站，HTML-T5是最好的模型，以解决基于 HTML 的任务，实现14.9% 的成功率比以前的 SoTA 在 MiniWoB 网络导航基准和更好的准确性离线任务规划评估。"
    },
    {
        "title": "Joint Dropout: Improving Generalizability in Low-Resource Neural Machine\n  Translation through Phrase Pair Variables",
        "url": "http://arxiv.org/abs/2307.12835v1",
        "pub_date": "2023-07-24",
        "summary": "Despite the tremendous success of Neural Machine Translation (NMT), its\nperformance on low-resource language pairs still remains subpar, partly due to\nthe limited ability to handle previously unseen inputs, i.e., generalization.\nIn this paper, we propose a method called Joint Dropout, that addresses the\nchallenge of low-resource neural machine translation by substituting phrases\nwith variables, resulting in significant enhancement of compositionality, which\nis a key aspect of generalization. We observe a substantial improvement in\ntranslation quality for language pairs with minimal resources, as seen in BLEU\nand Direct Assessment scores. Furthermore, we conduct an error analysis, and\nfind Joint Dropout to also enhance generalizability of low-resource NMT in\nterms of robustness and adaptability across different domains",
        "translated": "尽管神经机器翻译(NMT)取得了巨大的成功，但它在低资源语言对上的表现仍然不尽如人意，部分原因是由于处理以前看不见的输入(即泛化)的能力有限。在本文中，我们提出了一种称为联合丢失的方法，通过用变量替换短语来解决低资源神经机器翻译的挑战，从而显著提高合成性，这是泛化的一个关键方面。我们观察到在资源最少的语言对翻译质量的实质性改善，如在 BLEU 和直接评估分数。此外，我们还进行了误差分析，发现联合丢失还可以提高低资源 NMT 在不同领域的鲁棒性和适应性方面的通用性"
    },
    {
        "title": "Mitigating Mainstream Bias in Recommendation via Cost-sensitive Learning",
        "url": "http://arxiv.org/abs/2307.13632v1",
        "pub_date": "2023-07-25",
        "summary": "Mainstream bias, where some users receive poor recommendations because their\npreferences are uncommon or simply because they are less active, is an\nimportant aspect to consider regarding fairness in recommender systems.\nExisting methods to mitigate mainstream bias do not explicitly model the\nimportance of these non-mainstream users or, when they do, it is in a way that\nis not necessarily compatible with the data and recommendation model at hand.\nIn contrast, we use the recommendation utility as a more generic and implicit\nproxy to quantify mainstreamness, and propose a simple user-weighting approach\nto incorporate it into the training process while taking the cost of potential\nrecommendation errors into account. We provide extensive experimental results\nshowing that quantifying mainstreamness via utility is better able at\nidentifying non-mainstream users, and that they are indeed better served when\ntraining the model in a cost-sensitive way. This is achieved with negligible or\nno loss in overall recommendation accuracy, meaning that the models learn a\nbetter balance across users. In addition, we show that research of this kind,\nwhich evaluates recommendation quality at the individual user level, may not be\nreliable if not using enough interactions when assessing model performance.",
        "translated": "主流偏见是关于推荐系统公平性的一个重要方面。主流偏见是一些用户因为他们的偏好不常见或者仅仅是因为他们不太活跃而得到的推荐不好。现有的减轻主流偏见的方法没有明确地模拟这些非主流用户的重要性，或者当他们这样做时，它不一定与手头的数据和推荐模型兼容。相比之下，我们使用推荐实用程序作为一个更通用和隐含的代理来量化主流性，并提出一个简单的用户加权方法，将其纳入培训过程，同时考虑潜在的推荐错误的成本。我们提供了广泛的实验结果，表明通过效用量化主流用户更能识别非主流用户，并且在以成本敏感的方式训练模型时，他们确实得到了更好的服务。这是在总体推荐准确性方面可以忽略不计或没有损失的情况下实现的，这意味着模型在用户之间学习到了更好的平衡。此外，我们发现这种在个人用户层面评估推荐质量的研究，如果在评估模型性能时没有使用足够的交互，可能是不可靠的。"
    },
    {
        "title": "Gaussian Graph with Prototypical Contrastive Learning in E-Commerce\n  Bundle Recommendation",
        "url": "http://arxiv.org/abs/2307.13468v1",
        "pub_date": "2023-07-25",
        "summary": "Bundle recommendation aims to provide a bundle of items to satisfy the user\npreference on e-commerce platform. Existing successful solutions are based on\nthe contrastive graph learning paradigm where graph neural networks (GNNs) are\nemployed to learn representations from user-level and bundle-level graph views\nwith a contrastive learning module to enhance the cooperative association\nbetween different views. Nevertheless, they ignore the uncertainty issue which\nhas a significant impact in real bundle recommendation scenarios due to the\nlack of discriminative information caused by highly sparsity or diversity. We\nfurther suggest that their instancewise contrastive learning fails to\ndistinguish the semantically similar negatives (i.e., sampling bias issue),\nresulting in performance degradation. In this paper, we propose a novel\nGaussian Graph with Prototypical Contrastive Learning (GPCL) framework to\novercome these challenges. In particular, GPCL embeds each user/bundle/item as\na Gaussian distribution rather than a fixed vector. We further design a\nprototypical contrastive learning module to capture the contextual information\nand mitigate the sampling bias issue. Extensive experiments demonstrate that\nbenefiting from the proposed components, we achieve new state-of-the-art\nperformance compared to previous methods on several public datasets. Moreover,\nGPCL has been deployed on real-world e-commerce platform and achieved\nsubstantial improvements.",
        "translated": "Bundle 推荐的目的是提供一组项目，以满足电子商务平台上的用户偏好。现有的成功解决方案都是基于对比图学习范式，利用图神经网络(GNN)通过对比学习模块从用户级和捆绑级图视图中学习表示，以增强不同视图之间的协同关联。然而，他们忽略了不确定性问题，由于高度稀疏或多样性导致缺乏区分信息，这在真正的捆绑推荐场景中具有重大影响。我们进一步认为他们的实例对比学习不能区分语义上相似的否定(例如，抽样偏差问题) ，导致性能下降。本文提出了一种新的基于原型对比学习(GPCL)框架的高斯图来克服这些挑战。特别是，GPCL 将每个用户/捆绑包/项目嵌入为一个正态分布，而不是一个固定的向量。我们进一步设计了一个原型的对比学习模块来捕捉上下文信息和减轻抽样偏差问题。大量的实验表明，受益于提出的组件，我们实现了新的最先进的性能比以前的方法在几个公共数据集。此外，GPCL 已经部署在现实世界的电子商务平台上，并取得了实质性的改进。"
    },
    {
        "title": "Comprehensive Review on Semantic Information Retrieval and Ontology\n  Engineering",
        "url": "http://arxiv.org/abs/2307.13427v1",
        "pub_date": "2023-07-25",
        "summary": "Situation awareness is a crucial cognitive skill that enables individuals to\nperceive, comprehend, and project the current state of their environment\naccurately. It involves being conscious of relevant information, understanding\nits meaning, and using that understanding to make well-informed decisions.\nAwareness systems often need to integrate new knowledge and adapt to changing\nenvironments. Ontology reasoning facilitates knowledge integration and\nevolution, allowing for seamless updates and expansions of the ontology. With\nthe consideration of above, we are providing a quick review on semantic\ninformation retrieval and ontology engineering to understand the emerging\nchallenges and future research. In the review we have found that the ontology\nreasoning addresses the limitations of traditional systems by providing a\nformal, flexible, and scalable framework for knowledge representation,\nreasoning, and inference.",
        "translated": "情境意识是一种重要的认知技能，它使个体能够准确地感知、理解和投射环境的当前状态。它包括意识到相关信息，理解其含义，并利用这种理解做出明智的决定。认识系统往往需要整合新的知识并适应不断变化的环境。本体推理促进了知识的集成和演化，允许本体的无缝更新和扩展。综上所述，我们正在对语义信息检索和本体工程进行快速回顾，以了解新出现的挑战和未来的研究。在本文中，我们发现本体论推理解决了传统系统的局限性，为知识表示、推理和推理提供了一个形式化的、灵活的、可扩展的框架。"
    },
    {
        "title": "An End-to-End Workflow using Topic Segmentation and Text Summarisation\n  Methods for Improved Podcast Comprehension",
        "url": "http://arxiv.org/abs/2307.13394v1",
        "pub_date": "2023-07-25",
        "summary": "The consumption of podcast media has been increasing rapidly. Due to the\nlengthy nature of podcast episodes, users often carefully select which ones to\nlisten to. Although episode descriptions aid users by providing a summary of\nthe entire podcast, they do not provide a topic-by-topic breakdown. This study\nexplores the combined application of topic segmentation and text summarisation\nmethods to investigate how podcast episode comprehension can be improved. We\nhave sampled 10 episodes from Spotify's English-Language Podcast Dataset and\nemployed TextTiling and TextSplit to segment them. Moreover, three text\nsummarisation models, namely T5, BART, and Pegasus, were applied to provide a\nvery short title for each segment. The segmentation part was evaluated using\nour annotated sample with the $P_k$ and WindowDiff ($WD$) metrics. A survey was\nalso rolled out ($N=25$) to assess the quality of the generated summaries. The\nTextSplit algorithm achieved the lowest mean for both evaluation metrics\n($\\bar{P_k}=0.41$ and $\\bar{WD}=0.41$), while the T5 model produced the best\nsummaries, achieving a relevancy score only $8\\%$ less to the one achieved by\nthe human-written titles.",
        "translated": "播客媒体的消费量一直在迅速增长。由于播客节目的冗长性，用户经常会仔细选择要听的节目。虽然情节描述通过提供整个播客的摘要来帮助用户，但是它们不提供逐个主题的细分。本研究探讨了主题分割与文本摘要相结合的方法，以研究如何提高播客节目的理解能力。我们从 Spotify 的英语播客数据集中抽取了10集，并使用 TextTling 和 TextSplit 对它们进行分类。此外，三个文本摘要模型，即 T5、 BART 和 Pegasus，被用来为每个段提供一个非常简短的标题。分割部分使用我们的带注释的样本，使用 $P _ k $和 WindowDiff ($WD $)指标进行评估。还展开了一项调查($N = 25 $) ，以评估生成的摘要的质量。TextSplit 算法获得了两个评估指标的最低平均值($bar { P _ k } = 0.41 $和 $bar { WD } = 0.41 $) ，而 T5模型产生了最好的摘要，相关性得分仅比人写标题低8% 。"
    },
    {
        "title": "Embedding Models for Supervised Automatic Extraction and Classification\n  of Named Entities in Scientific Acknowledgements",
        "url": "http://arxiv.org/abs/2307.13377v1",
        "pub_date": "2023-07-25",
        "summary": "Acknowledgments in scientific papers may give an insight into aspects of the\nscientific community, such as reward systems, collaboration patterns, and\nhidden research trends. The aim of the paper is to evaluate the performance of\ndifferent embedding models for the task of automatic extraction and\nclassification of acknowledged entities from the acknowledgment text in\nscientific papers. We trained and implemented a named entity recognition (NER)\ntask using the Flair NLP framework. The training was conducted using three\ndefault Flair NER models with four differently-sized corpora and different\nversions of the Flair NLP framework. The Flair Embeddings model trained on the\nmedium corpus with the latest FLAIR version showed the best accuracy of 0.79.\nExpanding the size of a training corpus from very small to medium size\nmassively increased the accuracy of all training algorithms, but further\nexpansion of the training corpus did not bring further improvement. Moreover,\nthe performance of the model slightly deteriorated. Our model is able to\nrecognize six entity types: funding agency, grant number, individuals,\nuniversity, corporation, and miscellaneous. The model works more precisely for\nsome entity types than for others; thus, individuals and grant numbers showed a\nvery good F1-Score over 0.9. Most of the previous works on acknowledgment\nanalysis were limited by the manual evaluation of data and therefore by the\namount of processed data. This model can be applied for the comprehensive\nanalysis of acknowledgment texts and may potentially make a great contribution\nto the field of automated acknowledgment analysis.",
        "translated": "科学论文中的致谢可以让我们深入了解科学界的各个方面，比如奖励制度、合作模式和隐藏的研究趋势。本文的目的是评价不同嵌入模型对科技论文中确认文本中已知实体的自动提取和分类的性能。我们使用 Flair NLP 框架训练并实现了一个命名实体识别(NER)任务。培训是使用三个默认的 Flair NER 模型进行的，其中有四个不同大小的语料库和不同版本的 Flair NLP 框架。使用最新的 FLAIR 版本在中等语料库上进行训练的 FLAIR 嵌入模型显示了0.79的最佳精度。将训练语料库的大小从非常小扩展到中等大小，大大提高了所有训练算法的准确性，但是训练语料库的进一步扩展并没有带来进一步的改善。此外，该模型的性能略有下降。我们的模型能够识别六种实体类型: 资助机构、拨款号码、个人、大学、公司和杂项。该模型对于某些实体类型比对其他类型更精确; 因此，个人和拨款数量显示了非常好的 F1-得分超过0.9。以前关于确认分析的大多数工作受到人工评价数据的限制，因此也受到处理数据量的限制。该模型可以应用于自动确认文本的综合分析，并可能对自动确认分析领域做出重要贡献。"
    },
    {
        "title": "Evaluating Large Language Models for Radiology Natural Language\n  Processing",
        "url": "http://arxiv.org/abs/2307.13693v1",
        "pub_date": "2023-07-25",
        "summary": "The rise of large language models (LLMs) has marked a pivotal shift in the\nfield of natural language processing (NLP). LLMs have revolutionized a\nmultitude of domains, and they have made a significant impact in the medical\nfield. Large language models are now more abundant than ever, and many of these\nmodels exhibit bilingual capabilities, proficient in both English and Chinese.\nHowever, a comprehensive evaluation of these models remains to be conducted.\nThis lack of assessment is especially apparent within the context of radiology\nNLP. This study seeks to bridge this gap by critically evaluating thirty two\nLLMs in interpreting radiology reports, a crucial component of radiology NLP.\nSpecifically, the ability to derive impressions from radiologic findings is\nassessed. The outcomes of this evaluation provide key insights into the\nperformance, strengths, and weaknesses of these LLMs, informing their practical\napplications within the medical domain.",
        "translated": "大语言模型(LLM)的出现标志着自然语言处理(NLP)领域的一个关键性转变。LLM 使许多领域发生了革命性的变化，并在医学领域产生了重大影响。现在的大型语言模型比以往任何时候都更加丰富，其中许多模型展示了双语能力，精通英语和中文。然而，这些模型的综合评估仍有待进行。这种评估的缺乏在放射学 NLP 的背景下尤其明显。这项研究试图通过批判性地评估32个 LLM 来解释放射学报告，这是放射学 NLP 的一个关键组成部分，从而弥补这一差距。具体来说，是评估从放射学检查结果中获得印象的能力。这项评估的结果提供了这些 LLM 的性能，优势和弱点的关键见解，通知他们在医学领域的实际应用。"
    },
    {
        "title": "ARB: Advanced Reasoning Benchmark for Large Language Models",
        "url": "http://arxiv.org/abs/2307.13692v1",
        "pub_date": "2023-07-25",
        "summary": "Large Language Models (LLMs) have demonstrated remarkable performance on\nvarious quantitative reasoning and knowledge benchmarks. However, many of these\nbenchmarks are losing utility as LLMs get increasingly high scores, despite not\nyet reaching expert performance in these domains. We introduce ARB, a novel\nbenchmark composed of advanced reasoning problems in multiple fields. ARB\npresents a more challenging test than prior benchmarks, featuring problems in\nmathematics, physics, biology, chemistry, and law. As a subset of ARB, we\nintroduce a challenging set of math and physics problems which require advanced\nsymbolic reasoning and domain knowledge. We evaluate recent models such as\nGPT-4 and Claude on ARB and demonstrate that current models score well below\n50% on more demanding tasks. In order to improve both automatic and assisted\nevaluation capabilities, we introduce a rubric-based evaluation approach,\nallowing GPT-4 to score its own intermediate reasoning steps. Further, we\nconduct a human evaluation of the symbolic subset of ARB, finding promising\nagreement between annotators and GPT-4 rubric evaluation scores.",
        "translated": "大语言模型(LLM)在各种定量推理和知识基准测试中表现出了显著的性能。然而，尽管 LLM 在这些领域尚未达到专家级的性能，但随着 LLM 得分越来越高，许多基准测试正在失去效用。我们介绍了 ARB，一个新的基准组成的高级推理问题在多个领域。ARB 提出了一个更具挑战性的测试比以前的基准，具有在数学，物理，生物，化学和法律的问题。作为 ARB 的一个子集，我们引入了一组具有挑战性的数学和物理问题，这些问题需要先进的符号推理和领域知识。我们评估最近的模型，如 GPT-4和克劳德的 ARB 和表明，目前的模型得分远远低于50% ，更苛刻的任务。为了提高自动评估和辅助评估的能力，我们引入了一种基于标准的评估方法，允许 GPT-4评分自己的中间推理步骤。进一步，我们对 ARB 的符号子集进行了人工评估，发现注释者和 GPT-4标记评分之间有希望达成一致。"
    },
    {
        "title": "A Comprehensive Evaluation and Analysis Study for Chinese Spelling Check",
        "url": "http://arxiv.org/abs/2307.13655v1",
        "pub_date": "2023-07-25",
        "summary": "With the development of pre-trained models and the incorporation of phonetic\nand graphic information, neural models have achieved high scores in Chinese\nSpelling Check (CSC). However, it does not provide a comprehensive reflection\nof the models' capability due to the limited test sets. In this study, we\nabstract the representative model paradigm, implement it with nine structures\nand experiment them on comprehensive test sets we constructed with different\npurposes. We perform a detailed analysis of the results and find that: 1)\nFusing phonetic and graphic information reasonably is effective for CSC. 2)\nModels are sensitive to the error distribution of the test set, which reflects\nthe shortcomings of models and reveals the direction we should work on. 3)\nWhether or not the errors and contexts have been seen has a significant impact\non models. 4) The commonly used benchmark, SIGHAN, can not reliably evaluate\nmodels' performance.",
        "translated": "随着预训练模型的发展以及语音和图形信息的融合，神经模型在汉语拼写检查中取得了较高的成绩。然而，由于测试集有限，它并没有提供模型能力的全面反映。在本研究中，我们抽象出具有代表性的模型范式，用九种结构来实现它，并在不同目的的综合测试集上进行实验。我们对结果进行了详细的分析，发现: 1)语音信息和图形信息的合理融合对 CSC 是有效的。2)模型对测试集的误差分布比较敏感，反映了模型的不足，指出了我们应该努力的方向。3)错误和上下文是否被发现对模型有显著的影响。4)常用的基准 SIGHAN 不能可靠地评估模型的表现。"
    },
    {
        "title": "Contributions to the Improvement of Question Answering Systems in the\n  Biomedical Domain",
        "url": "http://arxiv.org/abs/2307.13631v1",
        "pub_date": "2023-07-25",
        "summary": "This thesis work falls within the framework of question answering (QA) in the\nbiomedical domain where several specific challenges are addressed, such as\nspecialized lexicons and terminologies, the types of treated questions, and the\ncharacteristics of targeted documents. We are particularly interested in\nstudying and improving methods that aim at finding accurate and short answers\nto biomedical natural language questions from a large scale of biomedical\ntextual documents in English. QA aims at providing inquirers with direct, short\nand precise answers to their natural language questions. In this Ph.D. thesis,\nwe propose four contributions to improve the performance of QA in the\nbiomedical domain. In our first contribution, we propose a machine\nlearning-based method for question type classification to determine the types\nof given questions which enable to a biomedical QA system to use the\nappropriate answer extraction method. We also propose an another machine\nlearning-based method to assign one or more topics (e.g., pharmacological,\ntest, treatment, etc.) to given questions in order to determine the semantic\ntypes of the expected answers which are very useful in generating specific\nanswer retrieval strategies. In the second contribution, we first propose a\ndocument retrieval method to retrieve a set of relevant documents that are\nlikely to contain the answers to biomedical questions from the MEDLINE\ndatabase. We then present a passage retrieval method to retrieve a set of\nrelevant passages to questions. In the third contribution, we propose specific\nanswer extraction methods to generate both exact and ideal answers. Finally, in\nthe fourth contribution, we develop a fully automated semantic biomedical QA\nsystem called SemBioNLQA which is able to deal with a variety of natural\nlanguage questions and to generate appropriate answers by providing both exact\nand ideal answers.",
        "translated": "本论文的工作属于生物医学领域中的问题回答(QA)框架，其中涉及到一些具体的挑战，如专门的词汇和术语，被处理问题的类型，以及目标文档的特征。我们特别感兴趣的是研究和改进方法，旨在从大量的英文生物医学文本文件中找到准确和简短的生物医学自然语言问题的答案。质素保证的目的是为查询者提供直接、简短和准确的答案，以回答他们的自然语言问题。在这篇博士论文中，我们提出四个贡献，以改善质量保证在生物医学领域的表现。在我们的第一个贡献中，我们提出了一个基于机器学习的问题类型分类方法，以确定给定问题的类型，使生物医学问答系统能够使用适当的答案提取方法。我们还提出了另一种基于机器学习的方法，为给定的问题分配一个或多个主题(例如，药理学，测试，治疗等) ，以确定期望回答的语义类型，这对于产生特定的回答检索策略非常有用。在第二个贡献中，我们首先提出了一种文献检索的方法来检索一组相关文档，这些文档可能包含来自 MEDLINE 数据库的生物医学问题的答案。然后，我们提出了一个短文检索方法来检索一组相关的段落的问题。在第三个贡献中，我们提出了具体的答案抽取方法来生成准确和理想的答案。最后，在第四个贡献中，我们开发了一个全自动的语义生物医学 QA 系统，称为 SemBioNLQA，它能够处理各种自然语言问题，并通过提供准确和理想的答案来产生适当的答案。"
    },
    {
        "title": "GPT-3 Models are Few-Shot Financial Reasoners",
        "url": "http://arxiv.org/abs/2307.13617v2",
        "pub_date": "2023-07-25",
        "summary": "Financial analysis is an important tool for evaluating company performance.\nPractitioners work to answer financial questions to make profitable investment\ndecisions, and use advanced quantitative analyses to do so. As a result,\nFinancial Question Answering (QA) is a question answering task that requires\ndeep reasoning about numbers. Furthermore, it is unknown how well pre-trained\nlanguage models can reason in the financial domain. The current\nstate-of-the-art requires a retriever to collect relevant facts about the\nfinancial question from the text and a generator to produce a valid financial\nprogram and a final answer. However, recently large language models like GPT-3\nhave achieved state-of-the-art performance on wide variety of tasks with just a\nfew shot examples. We run several experiments with GPT-3 and find that a\nseparate retrieval model and logic engine continue to be essential components\nto achieving SOTA performance in this task, particularly due to the precise\nnature of financial questions and the complex information stored in financial\ndocuments. With this understanding, our refined prompt-engineering approach on\nGPT-3 achieves near SOTA accuracy without any fine-tuning.",
        "translated": "财务分析是评价公司绩效的重要工具。从业人员回答财务问题，以作出有利可图的投资决策，并使用先进的定量分析这样做。因此，金融问答(QA)是一个需要对数字进行深入推理的问答任务。此外，我们还不知道预先训练好的语言模型在金融领域的推理能力如何。当前最先进的技术要求检索器从文本中收集有关财务问题的相关事实，并通过生成器生成有效的财务程序和最终答案。然而，最近像 GPT-3这样的大型语言模型仅仅通过几个镜头示例就在各种各样的任务中取得了最先进的性能。我们使用 GPT-3进行了几个实验，发现单独的检索模型和逻辑引擎仍然是实现 SOTA 性能的重要组成部分，特别是由于财务问题的精确性和存储在财务文档中的复杂信息。有了这样的理解，我们在 GPT-3上的改进的快速工程方法在没有任何微调的情况下实现了接近 SOTA 的精度。"
    },
    {
        "title": "XDLM: Cross-lingual Diffusion Language Model for Machine Translation",
        "url": "http://arxiv.org/abs/2307.13560v1",
        "pub_date": "2023-07-25",
        "summary": "Recently, diffusion models have excelled in image generation tasks and have\nalso been applied to neural language processing (NLP) for controllable text\ngeneration. However, the application of diffusion models in a cross-lingual\nsetting is less unexplored. Additionally, while pretraining with diffusion\nmodels has been studied within a single language, the potential of\ncross-lingual pretraining remains understudied. To address these gaps, we\npropose XDLM, a novel Cross-lingual diffusion model for machine translation,\nconsisting of pretraining and fine-tuning stages. In the pretraining stage, we\npropose TLDM, a new training objective for mastering the mapping between\ndifferent languages; in the fine-tuning stage, we build up the translation\nsystem based on the pretrained model. We evaluate the result on several machine\ntranslation benchmarks and outperformed both diffusion and Transformer\nbaselines.",
        "translated": "近年来，扩散模型在图像生成任务方面表现出色，并被应用于神经语言处理(NLP)中进行可控的文本生成。然而，扩散模型在跨语言环境中的应用还有待探索。此外，虽然扩散模型的预训练已经在单一语言中进行了研究，但是跨语言预训练的潜力仍然没有得到充分的研究。为了弥补这些差距，我们提出了一种新的机器翻译跨语言扩散模型 XDLM，它由预训练和微调阶段组成。在预训练阶段，我们提出了 TLDM 这一新的训练目标，用于掌握不同语言之间的映射关系; 在微调阶段，我们建立了基于预训练模型的翻译系统。我们在几个机器翻译基准上对结果进行了评估，优于扩散基准和变压器基准。"
    },
    {
        "title": "FacTool: Factuality Detection in Generative AI -- A Tool Augmented\n  Framework for Multi-Task and Multi-Domain Scenarios",
        "url": "http://arxiv.org/abs/2307.13528v2",
        "pub_date": "2023-07-25",
        "summary": "The emergence of generative pre-trained models has facilitated the synthesis\nof high-quality text, but it has also posed challenges in identifying factual\nerrors in the generated text. In particular: (1) A wider range of tasks now\nface an increasing risk of containing factual errors when handled by generative\nmodels. (2) Generated texts tend to be lengthy and lack a clearly defined\ngranularity for individual facts. (3) There is a scarcity of explicit evidence\navailable during the process of fact checking. With the above challenges in\nmind, in this paper, we propose FacTool, a task and domain agnostic framework\nfor detecting factual errors of texts generated by large language models (e.g.,\nChatGPT). Experiments on four different tasks (knowledge-based QA, code\ngeneration, mathematical reasoning, and scientific literature review) show the\nefficacy of the proposed method. We release the code of FacTool associated with\nChatGPT plugin interface at https://github.com/GAIR-NLP/factool .",
        "translated": "生成性预先训练模型的出现促进了高质量文本的合成，但也对查明生成文本中的事实错误提出了挑战。特别是: (1)更广泛的任务现在面临着越来越多的风险，包含事实错误时，处理生成模型。(2)生成的文本往往冗长，缺乏对个别事实的明确界定的粒度。(3)事实核查过程中明确的证据不足。考虑到上述挑战，本文提出了 FacTool，一个任务和领域不可知性框架，用于检测大型语言模型(如 ChatGPT)生成的文本中的实际错误。在四个不同的任务(基于知识的 QA、代码生成、数学推理和科学文献综述)上的实验表明了该方法的有效性。我们在 https://github.com/gair-nlp/FacTool 发布了与 ChatGPT 插件界面相关的 FacTool 代码。"
    },
    {
        "title": "Zshot: An Open-source Framework for Zero-Shot Named Entity Recognition\n  and Relation Extraction",
        "url": "http://arxiv.org/abs/2307.13497v1",
        "pub_date": "2023-07-25",
        "summary": "The Zero-Shot Learning (ZSL) task pertains to the identification of entities\nor relations in texts that were not seen during training. ZSL has emerged as a\ncritical research area due to the scarcity of labeled data in specific domains,\nand its applications have grown significantly in recent years. With the advent\nof large pretrained language models, several novel methods have been proposed,\nresulting in substantial improvements in ZSL performance. There is a growing\ndemand, both in the research community and industry, for a comprehensive ZSL\nframework that facilitates the development and accessibility of the latest\nmethods and pretrained models.In this study, we propose a novel ZSL framework\ncalled Zshot that aims to address the aforementioned challenges. Our primary\nobjective is to provide a platform that allows researchers to compare different\nstate-of-the-art ZSL methods with standard benchmark datasets. Additionally, we\nhave designed our framework to support the industry with readily available APIs\nfor production under the standard SpaCy NLP pipeline. Our API is extendible and\nevaluable, moreover, we include numerous enhancements such as boosting the\naccuracy with pipeline ensembling and visualization utilities available as a\nSpaCy extension.",
        "translated": "零镜头学习(ZSL)任务涉及识别在训练期间没有看到的文本中的实体或关系。由于特定领域标记数据的稀缺性，ZSL 已经成为一个重要的研究领域，近年来其应用得到了显著的发展。随着大型预训练语言模型的出现，人们提出了几种新的方法，从而大大提高了 ZSL 的性能。无论是在研究界还是在工业界，对一个全面的 ZSL 框架的需求都在不断增长，这个框架可以促进最新方法和预先训练的模型的开发和可访问性。在这项研究中，我们提出了一个新的 ZSL 框架，称为 Zshot，旨在解决上述挑战。我们的主要目标是提供一个平台，允许研究人员比较不同的国家的最先进的 ZSL 方法与标准的基准数据集。此外，我们还设计了我们的框架，以支持业界在标准 SpaCy NLP 流水线下生产随时可用的 API。我们的 API 是可扩展和可评估的，此外，我们还包括许多增强功能，比如通过管道集成和可视化实用程序(作为 SpaCy 扩展)提高精度。"
    },
    {
        "title": "Holistic Exploration on Universal Decompositional Semantic Parsing:\n  Architecture, Data Augmentation, and LLM Paradigm",
        "url": "http://arxiv.org/abs/2307.13424v1",
        "pub_date": "2023-07-25",
        "summary": "In this paper, we conduct a holistic exploration of the Universal\nDecompositional Semantic (UDS) Parsing. We first introduce a cascade model for\nUDS parsing that decomposes the complex parsing task into semantically\nappropriate subtasks. Our approach outperforms the prior models, while\nsignificantly reducing inference time. We also incorporate syntactic\ninformation and further optimized the architecture. Besides, different ways for\ndata augmentation are explored, which further improve the UDS Parsing. Lastly,\nwe conduct experiments to investigate the efficacy of ChatGPT in handling the\nUDS task, revealing that it excels in attribute parsing but struggles in\nrelation parsing, and using ChatGPT for data augmentation yields suboptimal\nresults. Our code is available at https://github.com/hexuandeng/HExp4UDS.",
        "translated": "在本文中，我们对通用分解语义(UDS)分析进行了全面的探索。我们首先介绍一个 UDS 解析的级联模型，该模型将复杂的解析任务分解为语义相应的子任务。我们的方法优于先前的模型，同时显著减少推理时间。我们还整合了语法信息，并进一步优化了体系结构。此外，还探索了不同的数据增强方法，进一步完善了 UDS 解析。最后，我们进行了实验来研究 ChatGPT 在处理 UDS 任务中的功效，发现它擅长属性解析，但在关系解析方面存在困难，并且使用 ChatGPT 进行数据增强会产生次优结果。我们的代码可以在 https://github.com/hexuandeng/hexp4uds 找到。"
    },
    {
        "title": "Towards Resolving Word Ambiguity with Word Embeddings",
        "url": "http://arxiv.org/abs/2307.13417v1",
        "pub_date": "2023-07-25",
        "summary": "Ambiguity is ubiquitous in natural language. Resolving ambiguous meanings is\nespecially important in information retrieval tasks. While word embeddings\ncarry semantic information, they fail to handle ambiguity well. Transformer\nmodels have been shown to handle word ambiguity for complex queries, but they\ncannot be used to identify ambiguous words, e.g. for a 1-word query.\nFurthermore, training these models is costly in terms of time, hardware\nresources, and training data, prohibiting their use in specialized environments\nwith sensitive data. Word embeddings can be trained using moderate hardware\nresources. This paper shows that applying DBSCAN clustering to the latent space\ncan identify ambiguous words and evaluate their level of ambiguity. An\nautomatic DBSCAN parameter selection leads to high-quality clusters, which are\nsemantically coherent and correspond well to the perceived meanings of a given\nword.",
        "translated": "歧义在自然语言中无处不在。在信息检索任务中，解决模棱两可的含义尤为重要。虽然单词嵌入具有语义信息，但它们不能很好地处理歧义。转换器模型已经被证明可以处理复杂查询中的单词歧义，但是它们不能用于识别歧义单词，例如对于一个单词查询。此外，培训这些模型在时间、硬件资源和培训数据方面代价高昂，禁止在专门的环境中使用敏感数据。可以使用适当的硬件资源来训练字嵌入。研究表明，将 DBSCAN 聚类应用到潜在空间中，可以识别歧义词并评估其歧义程度。自动选择 DBSCAN 参数可以产生高质量的聚类，这些聚类在语义上是一致的，并且能够很好地对应给定单词的感知意义。"
    },
    {
        "title": "ChatGPT and Persuasive Technologies for the Management and Delivery of\n  Personalized Recommendations in Hotel Hospitality",
        "url": "http://arxiv.org/abs/2307.14298v1",
        "pub_date": "2023-07-26",
        "summary": "Recommender systems have become indispensable tools in the hotel hospitality\nindustry, enabling personalized and tailored experiences for guests. Recent\nadvancements in large language models (LLMs), such as ChatGPT, and persuasive\ntechnologies, have opened new avenues for enhancing the effectiveness of those\nsystems. This paper explores the potential of integrating ChatGPT and\npersuasive technologies for automating and improving hotel hospitality\nrecommender systems. First, we delve into the capabilities of ChatGPT, which\ncan understand and generate human-like text, enabling more accurate and\ncontext-aware recommendations. We discuss the integration of ChatGPT into\nrecommender systems, highlighting the ability to analyze user preferences,\nextract valuable insights from online reviews, and generate personalized\nrecommendations based on guest profiles. Second, we investigate the role of\npersuasive technology in influencing user behavior and enhancing the persuasive\nimpact of hotel recommendations. By incorporating persuasive techniques, such\nas social proof, scarcity and personalization, recommender systems can\neffectively influence user decision-making and encourage desired actions, such\nas booking a specific hotel or upgrading their room. To investigate the\nefficacy of ChatGPT and persuasive technologies, we present a pilot experi-ment\nwith a case study involving a hotel recommender system. We aim to study the\nimpact of integrating ChatGPT and persua-sive techniques on user engagement,\nsatisfaction, and conversion rates. The preliminary results demonstrate the\npotential of these technologies in enhancing the overall guest experience and\nbusiness performance. Overall, this paper contributes to the field of hotel\nhospitality by exploring the synergistic relationship between LLMs and\npersuasive technology in recommender systems, ultimately influencing guest\nsatisfaction and hotel revenue.",
        "translated": "推荐系统已成为酒店款待业不可或缺的工具，为客人提供个性化和量身定制的体验。大型语言模型(LLM)(如 ChatGPT)和说服技术的最新进展为提高这些系统的有效性开辟了新的途径。本文探讨了集成 ChatGPT 和说服技术的潜力，以自动化和改进酒店接待推荐系统。首先，我们深入研究 ChatGPT 的功能，它可以理解和生成类似于人类的文本，从而实现更准确和上下文感知的建议。我们讨论了 ChatGPT 与推荐系统的集成，强调了分析用户偏好的能力，从在线评论中提取有价值的见解，以及基于客户档案生成个性化推荐的能力。其次，我们调查了游说工程在影响用户行为和提高酒店推荐的说服力方面的作用。通过引入说服性技术，例如社交证明、稀缺性和个性化，推荐系统可以有效地影响用户的决策，并鼓励用户采取预期的行动，例如预订特定的酒店或升级他们的房间。为了研究 ChatgPT 和说服技术的有效性，我们提出了一个涉及一家酒店推荐系统的案例研究试点实验。我们的目标是研究整合 ChatGPT 和说服技术对用户参与度、满意度和转化率的影响。初步结果显示了这些技术在提高整体客户体验和业务性能方面的潜力。总的来说，本文通过探索推荐系统中 LLM 和游说工程之间的协同关系，最终影响客人满意度和酒店收入，为酒店服务领域做出了贡献。"
    },
    {
        "title": "Large Language Models are Competitive Near Cold-start Recommenders for\n  Language- and Item-based Preferences",
        "url": "http://arxiv.org/abs/2307.14225v1",
        "pub_date": "2023-07-26",
        "summary": "Traditional recommender systems leverage users' item preference history to\nrecommend novel content that users may like. However, modern dialog interfaces\nthat allow users to express language-based preferences offer a fundamentally\ndifferent modality for preference input. Inspired by recent successes of\nprompting paradigms for large language models (LLMs), we study their use for\nmaking recommendations from both item-based and language-based preferences in\ncomparison to state-of-the-art item-based collaborative filtering (CF) methods.\nTo support this investigation, we collect a new dataset consisting of both\nitem-based and language-based preferences elicited from users along with their\nratings on a variety of (biased) recommended items and (unbiased) random items.\nAmong numerous experimental results, we find that LLMs provide competitive\nrecommendation performance for pure language-based preferences (no item\npreferences) in the near cold-start case in comparison to item-based CF\nmethods, despite having no supervised training for this specific task\n(zero-shot) or only a few labels (few-shot). This is particularly promising as\nlanguage-based preference representations are more explainable and scrutable\nthan item-based or vector-based representations.",
        "translated": "传统的推荐系统利用用户的项目偏好历史来推荐用户可能喜欢的新内容。然而，允许用户表达基于语言的偏好的现代对话界面为偏好输入提供了一种完全不同的模式。受最近大型语言模型(LLM)激励范式的成功启发，我们研究了它们与最先进的基于项目的协同过滤(CF)方法相比，在基于项目和基于语言偏好的推荐中的应用。为了支持这项调查，我们收集了一个新的数据集，包括从用户那里得到的基于项目和基于语言的偏好，以及他们对各种(有偏见的)推荐项目和(无偏见的)随机项目的评分。在众多的实验结果中，我们发现 LLM 与基于项目的 CF 方法相比，在近乎冷启动的情况下为纯语言偏好(无项目偏好)提供了有竞争力的推荐性能，尽管没有针对这个特定任务的监督培训(零拍)或只有少数标签(少拍)。这是特别有希望的，因为基于语言的偏好表示比基于项目或基于向量的表示更易于解释和审查。"
    },
    {
        "title": "A Probabilistic Position Bias Model for Short-Video Recommendation Feeds",
        "url": "http://arxiv.org/abs/2307.14059v1",
        "pub_date": "2023-07-26",
        "summary": "Modern web-based platforms show ranked lists of recommendations to users,\nattempting to maximise user satisfaction or business metrics. Typically, the\ngoal of such systems boils down to maximising the exposure probability for\nitems that are deemed \"reward-maximising\" according to a metric of interest.\nThis general framing comprises streaming applications, as well as e-commerce or\njob recommendations, and even web search. Position bias or user models can be\nused to estimate exposure probabilities for each use-case, specifically\ntailored to how users interact with the presented rankings. A unifying factor\nin these diverse problem settings is that typically only one or several items\nwill be engaged with (clicked, streamed,...) before a user leaves the ranked\nlist. Short-video feeds on social media platforms diverge from this general\nframing in several ways, most notably that users do not tend to leave the feed\nafter e.g. liking a post. Indeed, seemingly infinite feeds invite users to\nscroll further down the ranked list. For this reason, existing position bias or\nuser models tend to fall short in such settings, as they do not accurately\ncapture users' interaction modalities.\n  In this work, we propose a novel and probabilistically sound personalised\nposition bias model for feed recommendations. We focus on a 1st-level feed in a\nhierarchical structure, where users may enter a 2nd-level feed via any given\n1st-level item. We posit that users come to the platform with a scrolling\nbudget drawn according to some distribution, and show how the survival function\nof said distribution can be used to obtain closed-form estimates for\npersonalised exposure probabilities. Empirical insights from a large-scale\nsocial media platform show how our probabilistic position bias model more\naccurately captures empirical exposure than existing models, and paves the way\nfor unbiased evaluation and learning-to-rank.",
        "translated": "现代的基于网络的平台向用户显示排名列表的建议，试图最大限度地提高用户满意度或业务指标。通常，这类系统的目标可归结为，根据兴趣度量，将被视为“回报最大化”的项目的曝光概率最大化。这种通用框架包括流媒体应用程序、电子商务或工作推荐，甚至网络搜索。位置偏差或用户模型可以用来估计每个用例的暴露概率，特别是针对用户如何与提供的排名互动。在这些不同的问题设置中，一个统一的因素是，在用户离开排名列表之前，通常只有一个或几个项目要处理(单击、流化、 ...)。社交媒体平台上的短视频订阅在几个方面与这种一般框架有所不同，最明显的是用户往往不会在喜欢某个帖子之后离开订阅。事实上，似乎无限的提要邀请用户向下滚动排名列表。由于这个原因，现有的位置偏差或用户模型往往不能在这样的设置，因为他们不能准确地捕捉用户的交互模式。在这项工作中，我们提出了一个新颖的和概率合理的个性化位置偏差模型的饲料推荐。我们关注的是层次结构中的第一级提要，用户可以通过任何给定的第一级条目输入第二级提要。我们假设用户来到平台，根据一些分布绘制滚动预算，并展示了如何使用该分布的生存函数来获得个性化暴露概率的封闭式估计。来自大型社交媒体平台的经验性见解表明，我们的概率位置偏差模型比现有模型更准确地捕捉了经验暴露，并为无偏评估和学习排名铺平了道路。"
    },
    {
        "title": "Multi-view Hypergraph Contrastive Policy Learning for Conversational\n  Recommendation",
        "url": "http://arxiv.org/abs/2307.14024v1",
        "pub_date": "2023-07-26",
        "summary": "Conversational recommendation systems (CRS) aim to interactively acquire user\npreferences and accordingly recommend items to users. Accurately learning the\ndynamic user preferences is of crucial importance for CRS. Previous works learn\nthe user preferences with pairwise relations from the interactive conversation\nand item knowledge, while largely ignoring the fact that factors for a\nrelationship in CRS are multiplex. Specifically, the user likes/dislikes the\nitems that satisfy some attributes (Like/Dislike view). Moreover social\ninfluence is another important factor that affects user preference towards the\nitem (Social view), while is largely ignored by previous works in CRS. The user\npreferences from these three views are inherently different but also correlated\nas a whole. The user preferences from the same views should be more similar\nthan that from different views. The user preferences from Like View should be\nsimilar to Social View while different from Dislike View. To this end, we\npropose a novel model, namely Multi-view Hypergraph Contrastive Policy Learning\n(MHCPL). Specifically, MHCPL timely chooses useful social information according\nto the interactive history and builds a dynamic hypergraph with three types of\nmultiplex relations from different views. The multiplex relations in each view\nare successively connected according to their generation order.",
        "translated": "会话推荐系统(CRS)旨在交互式地获取用户偏好，从而向用户推荐项目。准确地了解动态用户偏好对 CRS 至关重要。以往的研究主要是从交互式会话和项目知识中了解成对关系的用户偏好，而忽略了 CRS 中影响关系的因素是多元的这一事实。具体来说，用户喜欢/不喜欢满足某些属性的项(Like/Dislike 视图)。此外，社会影响力是影响用户对商品偏好的另一个重要因素(社会视图) ，而以往的研究大多忽略了社会影响力。来自这三个视图的用户首选项在本质上是不同的，但作为一个整体也是相关的。来自相同视图的用户首选项应该比来自不同视图的用户首选项更加相似。来自 Like View 的用户首选项应该类似于 Social View，而不同于 Dislike View。为此，我们提出了一个新的模型，即多视图超图对比策略学习(MHCPL)。具体来说，MHCPL 根据交互历史及时选择有用的社会信息，从不同角度构建了三类多元关系的动态超图。每个视图中的多路复用关系根据它们的生成顺序依次连接。"
    },
    {
        "title": "Domain Disentanglement with Interpolative Data Augmentation for\n  Dual-Target Cross-Domain Recommendation",
        "url": "http://arxiv.org/abs/2307.13910v1",
        "pub_date": "2023-07-26",
        "summary": "The conventional single-target Cross-Domain Recommendation (CDR) aims to\nimprove the recommendation performance on a sparser target domain by\ntransferring the knowledge from a source domain that contains relatively richer\ninformation. By contrast, in recent years, dual-target CDR has been proposed to\nimprove the recommendation performance on both domains simultaneously. However,\nto this end, there are two challenges in dual-target CDR: (1) how to generate\nboth relevant and diverse augmented user representations, and (2) how to\neffectively decouple domain-independent information from domain-specific\ninformation, in addition to domain-shared information, to capture comprehensive\nuser preferences. To address the above two challenges, we propose a\nDisentanglement-based framework with Interpolative Data Augmentation for\ndual-target Cross-Domain Recommendation, called DIDA-CDR. In DIDA-CDR, we first\npropose an interpolative data augmentation approach to generating both relevant\nand diverse augmented user representations to augment sparser domain and\nexplore potential user preferences. We then propose a disentanglement module to\neffectively decouple domain-specific and domain-independent information to\ncapture comprehensive user preferences. Both steps significantly contribute to\ncapturing more comprehensive user preferences, thereby improving the\nrecommendation performance on each domain. Extensive experiments conducted on\nfive real-world datasets show the significant superiority of DIDA-CDR over the\nstate-of-the-art methods.",
        "translated": "传统的单目标跨域推荐(CDR)是通过从信息相对丰富的源域传递知识来提高稀疏目标域的推荐性能。相比之下，近年来，双目标 CDR 被提出来同时提高两个领域的推荐性能。然而，为此，在双目标 CDR 中存在两个挑战: (1)如何生成相关的和多样化的增强用户表示，(2)如何有效地将独立于领域的信息与特定于领域的信息解耦，以及领域共享信息，以获取全面的用户偏好。为了解决上述两个问题，我们提出了一个基于分离的双目标跨域推荐系统框架 DIDA-CDR。在 DIDA-CDR，我们首先提出一种内插数据增强方法，用于生成相关的和多样化的增强用户表示，以增强稀疏域，并探索潜在的用户偏好。然后，我们提出了一个解缠模块，以有效地解耦领域特定的和独立于领域的信息，以捕获全面的用户偏好。这两个步骤都有助于获取更全面的用户偏好，从而提高每个域的推荐性能。在五个实际数据集上进行的大量实验表明，DIDA-CDR 比最先进的方法具有显著的优越性。"
    },
    {
        "title": "On (Normalised) Discounted Cumulative Gain as an Offline Evaluation\n  Metric for Top-$n$ Recommendation",
        "url": "http://arxiv.org/abs/2307.15053v1",
        "pub_date": "2023-07-27",
        "summary": "Approaches to recommendation are typically evaluated in one of two ways: (1)\nvia a (simulated) online experiment, often seen as the gold standard, or (2)\nvia some offline evaluation procedure, where the goal is to approximate the\noutcome of an online experiment. Several offline evaluation metrics have been\nadopted in the literature, inspired by ranking metrics prevalent in the field\nof Information Retrieval. (Normalised) Discounted Cumulative Gain (nDCG) is one\nsuch metric that has seen widespread adoption in empirical studies, and higher\n(n)DCG values have been used to present new methods as the state-of-the-art in\ntop-$n$ recommendation for many years.\n  Our work takes a critical look at this approach, and investigates when we can\nexpect such metrics to approximate the gold standard outcome of an online\nexperiment. We formally present the assumptions that are necessary to consider\nDCG an unbiased estimator of online reward and provide a derivation for this\nmetric from first principles, highlighting where we deviate from its\ntraditional uses in IR. Importantly, we show that normalising the metric\nrenders it inconsistent, in that even when DCG is unbiased, ranking competing\nmethods by their normalised DCG can invert their relative order. Through a\ncorrelation analysis between off- and on-line experiments conducted on a\nlarge-scale recommendation platform, we show that our unbiased DCG estimates\nstrongly correlate with online reward, even when some of the metric's inherent\nassumptions are violated. This statement no longer holds for its normalised\nvariant, suggesting that nDCG's practical utility may be limited.",
        "translated": "推荐方法通常以两种方式之一进行评估: (1)通过(模拟)在线实验，通常被视为黄金标准，或者(2)通过一些离线评估程序，其目标是接近在线实验的结果。文献中已经采用了一些离线评估指标，这些指标的灵感来自于信息检索领域中流行的排名指标。(标准化)贴现累计增益(nDCG)是在实证研究中得到广泛采用的这样的指标之一，更高的(n) DCG 值已被用于多年来作为最高 $n $推荐的最先进的方法来呈现新的方法。我们的工作对这种方法进行了批判性的研究，并调查了什么时候我们可以期望这些指标接近在线实验的黄金标准结果。我们正式提出的假设是必要的，认为 DCG 是一个在线奖励的无偏估计，并提供了从第一原则的这个度量的推导，突出了我们偏离其在 IR 中的传统用途。重要的是，我们表明标准化度量使其不一致，即使当 DCG 是无偏的，排名竞争方法的标准化 DCG 可以颠倒他们的相对顺序。通过一个在大规模推荐平台上进行的离线和在线实验之间的相关性分析，我们表明，我们的无偏 DCG 估计与在线奖励强烈相关，即使一些度量的固有假设被违反。这种说法不再适用于其标准化变体，表明 nDCG 的实际用途可能是有限的。"
    },
    {
        "title": "The Effect of Third Party Implementations on Reproducibility",
        "url": "http://arxiv.org/abs/2307.14956v1",
        "pub_date": "2023-07-27",
        "summary": "Reproducibility of recommender systems research has come under scrutiny\nduring recent years. Along with works focusing on repeating experiments with\ncertain algorithms, the research community has also started discussing various\naspects of evaluation and how these affect reproducibility. We add a novel\nangle to this discussion by examining how unofficial third-party\nimplementations could benefit or hinder reproducibility. Besides giving a\ngeneral overview, we thoroughly examine six third-party implementations of a\npopular recommender algorithm and compare them to the official version on five\npublic datasets. In the light of our alarming findings we aim to draw the\nattention of the research community to this neglected aspect of\nreproducibility.",
        "translated": "近年来，推荐系统研究的可重复性受到密切关注。除了重点研究某些算法的重复实验外，研究团体还开始讨论评估的各个方面以及这些方面如何影响重复性。我们通过研究非官方的第三方实施如何有利于或阻碍可重复性，为这一讨论增加了一个新的视角。除了给出一个大致的概述，我们还彻底检查了流行的推荐算法的六个第三方实现，并将它们与五个公共数据集的官方版本进行了比较。鉴于我们令人震惊的发现，我们的目的是提请研究界注意这个被忽视的重现性方面。"
    },
    {
        "title": "Widespread Flaws in Offline Evaluation of Recommender Systems",
        "url": "http://arxiv.org/abs/2307.14951v1",
        "pub_date": "2023-07-27",
        "summary": "Even though offline evaluation is just an imperfect proxy of online\nperformance -- due to the interactive nature of recommenders -- it will\nprobably remain the primary way of evaluation in recommender systems research\nfor the foreseeable future, since the proprietary nature of production\nrecommenders prevents independent validation of A/B test setups and\nverification of online results. Therefore, it is imperative that offline\nevaluation setups are as realistic and as flawless as they can be.\nUnfortunately, evaluation flaws are quite common in recommender systems\nresearch nowadays, due to later works copying flawed evaluation setups from\ntheir predecessors without questioning their validity. In the hope of improving\nthe quality of offline evaluation of recommender systems, we discuss four of\nthese widespread flaws and why researchers should avoid them.",
        "translated": "即使离线评估只是在线性能的一个不完美的代理——由于推荐系统的互动性——在可预见的未来，它可能仍然是推荐系统研究的主要评估方式，因为生产推荐系统的专有性质阻碍了 A/B 测试设置的独立验证和在线结果的验证。因此，离线评估设置必须尽可能的现实和完美。不幸的是，评估缺陷是当今推荐系统研究中相当普遍的，由于后来的工作抄袭了前人有缺陷的评估设置，而没有质疑它们的有效性。为了提高推荐系统离线评估的质量，我们讨论了其中四个普遍存在的缺陷以及为什么研究人员应该避免这些缺陷。"
    },
    {
        "title": "Scaling Session-Based Transformer Recommendations using Optimized\n  Negative Sampling and Loss Functions",
        "url": "http://arxiv.org/abs/2307.14906v1",
        "pub_date": "2023-07-27",
        "summary": "This work introduces TRON, a scalable session-based Transformer Recommender\nusing Optimized Negative-sampling. Motivated by the scalability and performance\nlimitations of prevailing models such as SASRec and GRU4Rec+, TRON integrates\ntop-k negative sampling and listwise loss functions to enhance its\nrecommendation accuracy. Evaluations on relevant large-scale e-commerce\ndatasets show that TRON improves upon the recommendation quality of current\nmethods while maintaining training speeds similar to SASRec. A live A/B test\nyielded an 18.14% increase in click-through rate over SASRec, highlighting the\npotential of TRON in practical settings. For further research, we provide\naccess to our source code at https://github.com/otto-de/TRON and an anonymized\ndataset at https://github.com/otto-de/recsys-dataset.",
        "translated": "本文介绍了 TRON，一个可扩展的基于会话的变压器优化负采样推荐器。由于 SASRec 和 GRU4Rec + 等主流模型的可扩展性和性能限制，TRON 集成了 top-k 负采样和列表损失功能，以提高其推荐的准确性。对相关大规模电子商务数据集的评估表明，TRON 在保持与 SASRec 类似的训练速度的同时，提高了现有方法的推荐质量。现场 A/B 测试的点进率比 SASrec 增加了18.14% ，突出了 TRON 在实际环境中的潜力。为了进一步研究，我们在 https://github.com/otto-de/tron 提供源代码访问，在 https://github.com/otto-de/recsys-dataset 提供匿名数据集访问。"
    },
    {
        "title": "Integrating Offline Reinforcement Learning with Transformers for\n  Sequential Recommendation",
        "url": "http://arxiv.org/abs/2307.14450v1",
        "pub_date": "2023-07-26",
        "summary": "We consider the problem of sequential recommendation, where the current\nrecommendation is made based on past interactions. This recommendation task\nrequires efficient processing of the sequential data and aims to provide\nrecommendations that maximize the long-term reward. To this end, we train a\nfarsighted recommender by using an offline RL algorithm with the policy network\nin our model architecture that has been initialized from a pre-trained\ntransformer model. The pre-trained model leverages the superb ability of the\ntransformer to process sequential information. Compared to prior works that\nrely on online interaction via simulation, we focus on implementing a fully\noffline RL framework that is able to converge in a fast and stable way. Through\nextensive experiments on public datasets, we show that our method is robust\nacross various recommendation regimes, including e-commerce and movie\nsuggestions. Compared to state-of-the-art supervised learning algorithms, our\nalgorithm yields recommendations of higher quality, demonstrating the clear\nadvantage of combining RL and transformers.",
        "translated": "我们考虑顺序推荐的问题，其中当前的推荐是基于过去的交互作用。这项推荐任务需要有效地处理顺序数据，目的是提供建议，最大限度地实现长期回报。为此，我们在模型结构中使用策略网络的离线 RL 算法来训练一个有远见的推荐器，该模型已经从一个预先训练好的变压器模型初始化。预先训练的模型利用变压器处理顺序信息的卓越能力。与以往依赖于通过仿真进行在线交互的工作相比，我们侧重于实现一个完全离线的 RL 框架，该框架能够快速、稳定地收敛。通过对公共数据集的大量实验，我们发现我们的方法在不同的推荐机制下都是稳健的，包括电子商务和电影推荐。与最先进的监督式学习算法相比，我们的算法产生了更高质量的推荐，展示了结合 RL 和变压器的明显优势。"
    },
    {
        "title": "A Geometric Notion of Causal Probing",
        "url": "http://arxiv.org/abs/2307.15054v1",
        "pub_date": "2023-07-27",
        "summary": "Large language models rely on real-valued representations of text to make\ntheir predictions. These representations contain information learned from the\ndata that the model has trained on, including knowledge of linguistic\nproperties and forms of demographic bias, e.g., based on gender. A growing body\nof work has considered information about concepts such as these using\northogonal projections onto subspaces of the representation space. We\ncontribute to this body of work by proposing a formal definition of intrinsic\ninformation in a subspace of a language model's representation space. We\npropose a counterfactual approach that avoids the failure mode of spurious\ncorrelations (Kumar et al., 2022) by treating components in the subspace and\nits orthogonal complement independently. We show that our counterfactual notion\nof information in a subspace is optimizing by an causal concept subspace.\nFurthermore, this intervention allows us to attempt concept controlled\ngeneration by manipulating the value of the conceptual component of a\nrepresentation. Empirically, we find that R-LACE (Ravfogel et al., 2022)\nreturns a one-dimensional subspace containing roughly half of total concept\ninformation under our framework. Our causal controlled intervention shows that,\nfor at least one model, the subspace returned by R-LACE can be used to\nmanipulate the concept value of the generated word with precision.",
        "translated": "大型语言模型依赖于文本的实值表示来进行预测。这些表征包含从该模型已经训练过的数据中学到的信息，包括语言特性的知识和人口偏见的形式，例如基于性别的偏见。越来越多的工作已经考虑了有关概念的信息，例如使用表示空间的子空间上的正交投影。我们通过在语言模型表示空间的子空间中提出内在信息的形式化定义来为这一工作做出贡献。我们提出了一种反事实的方法，通过独立处理子空间及其正交补，避免了虚假相关的失败模式(Kumar et al。 ，2022)。我们证明了我们的反事实概念的信息在子空间是优化的因果概念子空间。此外，这种干预允许我们通过操纵表示的概念组件的值来尝试概念控制的生成。根据经验，我们发现 R-LACE (Ravfogel 等，2022)返回一个一维子空间，其中包含我们框架下大约一半的概念信息。我们的因果控制干预表明，对于至少一个模型，R-LACE 返回的子空间可以用来精确地操纵生成的单词的概念值。"
    },
    {
        "title": "Matching Patients to Clinical Trials with Large Language Models",
        "url": "http://arxiv.org/abs/2307.15051v1",
        "pub_date": "2023-07-27",
        "summary": "Clinical trials are vital in advancing drug development and evidence-based\nmedicine, but their success is often hindered by challenges in patient\nrecruitment. In this work, we investigate the potential of large language\nmodels (LLMs) to assist individual patients and referral physicians in\nidentifying suitable clinical trials from an extensive selection. Specifically,\nwe introduce TrialGPT, a novel architecture employing LLMs to predict\ncriterion-level eligibility with detailed explanations, which are then\naggregated for ranking and excluding candidate clinical trials based on\nfree-text patient notes. We evaluate TrialGPT on three publicly available\ncohorts of 184 patients and 18,238 annotated clinical trials. The experimental\nresults demonstrate several key findings: First, TrialGPT achieves high\ncriterion-level prediction accuracy with faithful explanations. Second, the\naggregated trial-level TrialGPT scores are highly correlated with expert\neligibility annotations. Third, these scores prove effective in ranking\nclinical trials and exclude ineligible candidates. Our error analysis suggests\nthat current LLMs still make some mistakes due to limited medical knowledge and\ndomain-specific context understanding. Nonetheless, we believe the explanatory\ncapabilities of LLMs are highly valuable. Future research is warranted on how\nsuch AI assistants can be integrated into the routine trial matching workflow\nin real-world settings to improve its efficiency.",
        "translated": "临床试验在推进药物开发和循证医学方面至关重要，但它们的成功往往受到招募患者方面的挑战的阻碍。在这项工作中，我们调查的潜力，大型语言模型(LLM) ，以协助个别患者和转诊医生确定适当的临床试验，从广泛的选择。具体而言，我们引入了 TrialGPT，这是一种使用 LLM 预测标准水平资格的新架构，具有详细的解释，然后根据自由文本患者笔记对候选临床试验进行排序和排除。我们评估了 TrialGPT 在184名患者和18,238名注释临床试验的三个公开队列中的应用。实验结果证明了以下几个关键发现: 首先，TrialGPT 通过忠实的解释达到了较高的准则级预测精度。其次，试验级别的 TrialGPT 总分与专家资格注释高度相关。第三，这些分数证明在排列临床试验和排除不合格的候选人有效。我们的错误分析表明，目前的 LLM 仍然会犯一些错误，由于有限的医学知识和特定领域的上下文理解。尽管如此，我们相信 LLM 的解释能力是非常有价值的。未来的研究有必要探讨如何将这些人工智能助手集成到现实环境中的常规试验匹配工作流程中，以提高其效率。"
    },
    {
        "title": "Universal and Transferable Adversarial Attacks on Aligned Language\n  Models",
        "url": "http://arxiv.org/abs/2307.15043v1",
        "pub_date": "2023-07-27",
        "summary": "Because \"out-of-the-box\" large language models are capable of generating a\ngreat deal of objectionable content, recent work has focused on aligning these\nmodels in an attempt to prevent undesirable generation. While there has been\nsome success at circumventing these measures -- so-called \"jailbreaks\" against\nLLMs -- these attacks have required significant human ingenuity and are brittle\nin practice. In this paper, we propose a simple and effective attack method\nthat causes aligned language models to generate objectionable behaviors.\nSpecifically, our approach finds a suffix that, when attached to a wide range\nof queries for an LLM to produce objectionable content, aims to maximize the\nprobability that the model produces an affirmative response (rather than\nrefusing to answer). However, instead of relying on manual engineering, our\napproach automatically produces these adversarial suffixes by a combination of\ngreedy and gradient-based search techniques, and also improves over past\nautomatic prompt generation methods.\n  Surprisingly, we find that the adversarial prompts generated by our approach\nare quite transferable, including to black-box, publicly released LLMs.\nSpecifically, we train an adversarial attack suffix on multiple prompts (i.e.,\nqueries asking for many different types of objectionable content), as well as\nmultiple models (in our case, Vicuna-7B and 13B). When doing so, the resulting\nattack suffix is able to induce objectionable content in the public interfaces\nto ChatGPT, Bard, and Claude, as well as open source LLMs such as LLaMA-2-Chat,\nPythia, Falcon, and others. In total, this work significantly advances the\nstate-of-the-art in adversarial attacks against aligned language models,\nraising important questions about how such systems can be prevented from\nproducing objectionable information. Code is available at\ngithub.com/llm-attacks/llm-attacks.",
        "translated": "由于“开箱即用”的大型语言模型能够生成大量令人反感的内容，因此最近的工作重点是调整这些模型，以防止不良的生成。虽然在规避这些措施——针对 LLM 的所谓“越狱”——方面取得了一些成功，但这些攻击需要大量人类的聪明才智，而且在实践中非常脆弱。在本文中，我们提出了一种简单有效的攻击方法，使对齐的语言模型产生令人反感的行为。具体来说，我们的方法发现一个后缀，当附加到一个 LLM 的大范围查询以产生令人反感的内容时，目的是最大限度地提高模型产生肯定回应(而不是拒绝回答)的可能性。然而，我们的方法不依赖于手工工程，而是通过贪婪和基于梯度的搜索技术的组合自动生成这些对抗性后缀，并且比过去的自动提示生成方法有所改进。令人惊讶的是，我们发现由我们的方法产生的对抗性提示是可以相当转移的，包括黑盒，公开发布的 LLM。具体来说，我们在多个提示符(即询问许多不同类型的令人反感的内容的查询)以及多个模型(在我们的例子中，Vicuna-7B 和13B)上训练一个对抗性攻击后缀。当这样做时，产生的攻击后缀能够在公共界面中引入不良内容到 ChatGPT、巴德和克劳德，以及开源 LLM，如 Llama-2-Chat、 Pythia、 Falcon 和其他。总的来说，这项工作大大推进了针对统一语言模型的对抗性攻击的最先进水平，提出了如何防止这类系统产生令人反感的信息的重要问题。密码可于 github.com/llm-attacks/llm-attacks 索取。"
    },
    {
        "title": "SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark",
        "url": "http://arxiv.org/abs/2307.15020v1",
        "pub_date": "2023-07-27",
        "summary": "Large language models (LLMs) have shown the potential to be integrated into\nhuman daily lives. Therefore, user preference is the most critical criterion\nfor assessing LLMs' performance in real-world scenarios. However, existing\nbenchmarks mainly focus on measuring models' accuracy using multi-choice\nquestions, which limits the understanding of their capabilities in real\napplications. We fill this gap by proposing a comprehensive Chinese benchmark\nSuperCLUE, named after another popular Chinese LLM benchmark CLUE. SuperCLUE\nencompasses three sub-tasks: actual users' queries and ratings derived from an\nLLM battle platform (CArena), open-ended questions with single and\nmultiple-turn dialogues (OPEN), and closed-ended questions with the same stems\nas open-ended single-turn ones (CLOSE). Our study shows that accuracy on\nclosed-ended questions is insufficient to reflect human preferences achieved on\nopen-ended ones. At the same time, they can complement each other to predict\nactual user preferences. We also demonstrate that GPT-4 is a reliable judge to\nautomatically evaluate human preferences on open-ended questions in a Chinese\ncontext. Our benchmark will be released at https://www.CLUEbenchmarks.com",
        "translated": "大型语言模型(LLM)已经显示出融入人类日常生活的潜力。因此，用户偏好是评估 LLM 在真实场景中性能的最关键的标准。然而，现有的基准测试主要集中在使用多项选择题来测量模型的精度，这限制了对它们在实际应用中的能力的理解。我们通过提出一个全面的中文基准 SuperCLUE 来填补这个空白，它是以另一个流行的中文 LLM 基准 CLUE 命名的。SuperCLUE 包括三个子任务: 实际用户的查询和来自 LLM 战斗平台(CArena)的评分，单回合和多回合对话的开放式问题(OPEN) ，以及与单回合开放式问题(CLOSE)具有相同主干的封闭式问题。我们的研究表明，封闭式问题的准确性不足以反映人类对开放式问题的偏好。同时，它们可以相辅相成，预测实际的用户偏好。我们还证明了 GPT-4是一个可靠的判断标准，能够自动评估中国人在开放式问题上的偏好。我们的基准将于 https://www.cluebenchmarks.com 公布"
    },
    {
        "title": "Gzip versus bag-of-words for text classification with KNN",
        "url": "http://arxiv.org/abs/2307.15002v1",
        "pub_date": "2023-07-27",
        "summary": "The effectiveness of compression distance in KNN-based text classification\n('gzip') has recently garnered lots of attention. In this note, we show that\nsimilar or better effectiveness can be achieved with simpler means, and text\ncompression may not be necessary. Indeed, we find that a simple 'bag-of-words'\nmatching can achieve similar or better accuracy, and is more efficient.",
        "translated": "压缩距离在基于 KNN 的文本分类(‘ gzip’)中的有效性最近引起了广泛的关注。在本说明中，我们展示了用更简单的方法可以达到类似或更好的效果，并且文本压缩可能没有必要。事实上，我们发现，一个简单的“词袋”匹配可以达到类似或更好的准确性，而且更有效率。"
    },
    {
        "title": "Scaling TransNormer to 175 Billion Parameters",
        "url": "http://arxiv.org/abs/2307.14995v1",
        "pub_date": "2023-07-27",
        "summary": "We present TransNormerLLM, the first linear attention-based Large Language\nModel (LLM) that outperforms conventional softmax attention-based models in\nterms of both accuracy and efficiency. TransNormerLLM evolves from the previous\nlinear attention architecture TransNormer by making advanced modifications that\ninclude positional embedding, linear attention acceleration, gating mechanism,\ntensor normalization, inference acceleration and stabilization. Specifically,\nwe use LRPE together with an exponential decay to avoid attention dilution\nissues while allowing the model to retain global interactions between tokens.\nAdditionally, we propose Lightning Attention, a cutting-edge technique that\naccelerates linear attention by more than twice in runtime and reduces memory\nusage by a remarkable four times. To further enhance the performance of\nTransNormer, we leverage a gating mechanism to smooth training and a new tensor\nnormalization scheme to accelerate the model, resulting in an impressive\nacceleration of over 20%. Furthermore, we have developed a robust inference\nalgorithm that ensures numerical stability and consistent inference speed,\nregardless of the sequence length, showcasing superior efficiency during both\ntraining and inference stages. Scalability is at the heart of our model's\ndesign, enabling seamless deployment on large-scale clusters and facilitating\nexpansion to even more extensive models, all while maintaining outstanding\nperformance metrics. Rigorous validation of our model design is achieved\nthrough a series of comprehensive experiments on our self-collected corpus,\nboasting a size exceeding 6TB and containing over 2 trillion tokens. To ensure\ndata quality and relevance, we implement a new self-cleaning strategy to filter\nour collected data. Our pre-trained models will be released to foster community\nadvancements in efficient LLMs.",
        "translated": "我们提出了 TransNormerLLM，这是第一个基于注意力的线性大语言模型(LLM) ，在准确性和效率方面都优于传统的基于注意力的软模型。TransNormerLLM 通过对传统的线性注意力结构 TransNormer 进行改进，包括位置嵌入、线性注意力加速、门控机制、张量归一化、推理加速和稳定化。具体来说，我们将 LRPE 与指数衰减结合使用，以避免注意力稀释问题，同时允许模型保留令牌之间的全局交互。此外，我们还提出了“闪电注意”，这是一种在运行时加速线性注意力两倍以上并显著减少内存使用四倍的尖端技术。为了进一步提高 TransNormer 的性能，我们利用了一个门控机制来平滑训练和一个新的张量归一化方案来加速模型，结果令人印象深刻的加速超过20% 。此外，我们已经开发了一个强大的推理算法，可以确保数值稳定性和一致的推理速度，无论序列长度如何，在训练和推理阶段都显示出卓越的效率。可伸缩性是我们模型设计的核心，支持在大规模集群上进行无缝部署，并促进扩展到更广泛的模型，同时保持出色的性能指标。我们的模型设计的严格验证是通过在我们自收集的语料库上进行的一系列综合实验来实现的，其大小超过6TB，包含超过2万亿令牌。为了确保数据的质量和相关性，我们实施了一个新的自我清洁策略来过滤我们收集的数据。我们预先培训的模型将被发布，以促进社区在有效的 LLM 方面的进步。"
    },
    {
        "title": "Incrementally-Computable Neural Networks: Efficient Inference for\n  Dynamic Inputs",
        "url": "http://arxiv.org/abs/2307.14988v1",
        "pub_date": "2023-07-27",
        "summary": "Deep learning often faces the challenge of efficiently processing dynamic\ninputs, such as sensor data or user inputs. For example, an AI writing\nassistant is required to update its suggestions in real time as a document is\nedited. Re-running the model each time is expensive, even with compression\ntechniques like knowledge distillation, pruning, or quantization. Instead, we\ntake an incremental computing approach, looking to reuse calculations as the\ninputs change. However, the dense connectivity of conventional architectures\nposes a major obstacle to incremental computation, as even minor input changes\ncascade through the network and restrict information reuse. To address this, we\nuse vector quantization to discretize intermediate values in the network, which\nfilters out noisy and unnecessary modifications to hidden neurons, facilitating\nthe reuse of their values. We apply this approach to the transformers\narchitecture, creating an efficient incremental inference algorithm with\ncomplexity proportional to the fraction of the modified inputs. Our experiments\nwith adapting the OPT-125M pre-trained language model demonstrate comparable\naccuracy on document classification while requiring 12.1X (median) fewer\noperations for processing sequences of atomic edits.",
        "translated": "深度学习经常面临有效处理动态输入(如传感器数据或用户输入)的挑战。例如，人工智能写作助手需要在编辑文档时实时更新其建议。每次重新运行模型都是昂贵的，即使使用压缩技术，如知识蒸馏、修剪或量化。相反，我们采用增量计算方法，希望在输入发生变化时重用计算。然而，传统体系结构的密集连通性对增量计算构成了主要障碍，因为即使是很小的输入变化也会通过网络级联而限制信息重用。为了解决这个问题，我们使用向量量化离散网络中的中间值，过滤掉对隐藏神经元的噪声和不必要的修改，促进它们值的重用。我们将这种方法应用于变形金刚体系结构，创建了一个高效的增量式推理算法，其复杂度与修改后的输入的比例成正比。我们采用 OPT-125M 预先训练的语言模型进行的实验表明，在处理原子编辑序列时，文档分类的准确性相当，但需要的操作次数减少了12.1倍(中位数)。"
    },
    {
        "title": "PanGu-Coder2: Boosting Large Language Models for Code with Ranking\n  Feedback",
        "url": "http://arxiv.org/abs/2307.14936v1",
        "pub_date": "2023-07-27",
        "summary": "Large Language Models for Code (Code LLM) are flourishing. New and powerful\nmodels are released on a weekly basis, demonstrating remarkable performance on\nthe code generation task. Various approaches have been proposed to boost the\ncode generation performance of pre-trained Code LLMs, such as supervised\nfine-tuning, instruction tuning, reinforcement learning, etc. In this paper, we\npropose a novel RRTF (Rank Responses to align Test&amp;Teacher Feedback) framework,\nwhich can effectively and efficiently boost pre-trained large language models\nfor code generation. Under this framework, we present PanGu-Coder2, which\nachieves 62.20% pass@1 on the OpenAI HumanEval benchmark. Furthermore, through\nan extensive evaluation on CoderEval and LeetCode benchmarks, we show that\nPanGu-Coder2 consistently outperforms all previous Code LLMs.",
        "translated": "代码的大语言模型(CodeLLM)正在蓬勃发展。新的和强大的模型每周发布一次，在代码生成任务中展示了非凡的性能。为了提高预训练码 LLM 的代码生成性能，人们提出了多种方法，例如监督微调、指令微调、强化学习等。在本文中，我们提出了一个新的 RRTF (秩序响应对齐测试和教师反馈)框架，它可以有效和高效地增强预训练的代码生成大语言模型。在这个框架下，我们展示了 PanGu-Coder2，它在 OpenAI HumanEval 基准测试中达到了62.20% 的成功率。此外，通过对 CoderEval 和 LeetCode 基准的广泛评估，我们表明 PanGu-Coder2始终优于以前的所有代码 LLM。"
    },
    {
        "title": "ARC-NLP at PAN 2023: Transition-Focused Natural Language Inference for\n  Writing Style Detection",
        "url": "http://arxiv.org/abs/2307.14913v1",
        "pub_date": "2023-07-27",
        "summary": "The task of multi-author writing style detection aims at finding any\npositions of writing style change in a given text document. We formulate the\ntask as a natural language inference problem where two consecutive paragraphs\nare paired. Our approach focuses on transitions between paragraphs while\ntruncating input tokens for the task. As backbone models, we employ different\nTransformer-based encoders with warmup phase during training. We submit the\nmodel version that outperforms baselines and other proposed model versions in\nour experiments. For the easy and medium setups, we submit transition-focused\nnatural language inference based on DeBERTa with warmup training, and the same\nmodel without transition for the hard setup.",
        "translated": "多作者写作风格检测的任务是在给定的文本文档中寻找写作风格变化的任何位置。我们将任务表述为一个自然语言推理问题，其中两个连续的段落是成对的。我们的方法主要关注段落之间的转换，同时截断任务的输入标记。作为骨干模型，我们采用不同的变压器为基础的编码器与热身阶段的训练。在我们的实验中，我们提交了优于基线和其他提议的模型版本的模型版本。对于简单和中等的设置，我们提出了基于 DeBERTa 的过渡聚焦自然语言推理和热身训练，以及相同的模型没有过渡的硬设置。"
    },
    {
        "title": "ARC-NLP at PAN 2023: Hierarchical Long Text Classification for Trigger\n  Detection",
        "url": "http://arxiv.org/abs/2307.14912v1",
        "pub_date": "2023-07-27",
        "summary": "Fanfiction, a popular form of creative writing set within established\nfictional universes, has gained a substantial online following. However,\nensuring the well-being and safety of participants has become a critical\nconcern in this community. The detection of triggering content, material that\nmay cause emotional distress or trauma to readers, poses a significant\nchallenge. In this paper, we describe our approach for the Trigger Detection\nshared task at PAN CLEF 2023, where we want to detect multiple triggering\ncontent in a given Fanfiction document. For this, we build a hierarchical model\nthat uses recurrence over Transformer-based language models. In our approach,\nwe first split long documents into smaller sized segments and use them to\nfine-tune a Transformer model. Then, we extract feature embeddings from the\nfine-tuned Transformer model, which are used as input in the training of\nmultiple LSTM models for trigger detection in a multi-label setting. Our model\nachieves an F1-macro score of 0.372 and F1-micro score of 0.736 on the\nvalidation set, which are higher than the baseline results shared at PAN CLEF\n2023.",
        "translated": "同人小说，一种流行的创造性写作形式，建立在虚构的宇宙，已经获得了大量的网上追随者。然而，确保参与者的福祉和安全已成为这个社区的一个关键问题。触发内容的检测，可能导致情绪困扰或读者创伤的材料，提出了一个重大的挑战。在本文中，我们描述了我们在 PAN CLEF 2023上的触发检测共享任务的方法，我们希望在给定的同人小说文档中检测多个触发内容。为此，我们构建了一个层次模型，该模型在基于 Transformer 的语言模型上使用递归。在我们的方法中，我们首先将长文档分割成较小的段，并使用它们来微调 Transformer 模型。然后，我们从微调变压器模型中提取特征嵌入，将其作为多个 LSTM 模型的训练输入，用于多标签环境下的触发检测。我们的模型在验证集上实现了0.372的 F1-宏观评分和0.736的 F1-微观评分，这高于在 PAN CLEF 2023上共享的基线结果。"
    },
    {
        "title": "Framework to Automatically Determine the Quality of Open Data Catalogs",
        "url": "http://arxiv.org/abs/2307.15464v1",
        "pub_date": "2023-07-28",
        "summary": "Data catalogs play a crucial role in modern data-driven organizations by\nfacilitating the discovery, understanding, and utilization of diverse data\nassets. However, ensuring their quality and reliability is complex, especially\nin open and large-scale data environments. This paper proposes a framework to\nautomatically determine the quality of open data catalogs, addressing the need\nfor efficient and reliable quality assessment mechanisms. Our framework can\nanalyze various core quality dimensions, such as accuracy, completeness,\nconsistency, scalability, and timeliness, offer several alternatives for the\nassessment of compatibility and similarity across such catalogs as well as the\nimplementation of a set of non-core quality dimensions such as provenance,\nreadability, and licensing. The goal is to empower data-driven organizations to\nmake informed decisions based on trustworthy and well-curated data assets. The\nsource code that illustrates our approach can be downloaded from\nhttps://www.github.com/jorge-martinez-gil/dataq/.",
        "translated": "数据目录通过促进不同数据资产的发现、理解和利用，在现代数据驱动组织中发挥着至关重要的作用。然而，确保它们的质量和可靠性是复杂的，特别是在开放和大规模的数据环境中。本文提出了一个自动确定开放数据目录质量的框架，满足了建立高效、可靠的质量评估机制的需要。我们的框架可以分析各种核心质量维度，例如准确性，完整性，一致性，可伸缩性和及时性，为评估这些目录之间的兼容性和相似性以及实现一组非核心质量维度，例如出处，可读性和许可证提供了几种替代方案。目标是授权数据驱动的组织根据可信赖和良好管理的数据资产做出明智的决策。说明我们方法的源代码可以从 https://www.github.com/jorge-martinez-gil/dataq/下载。"
    },
    {
        "title": "Toward Transparent Sequence Models with Model-Based Tree Markov Model",
        "url": "http://arxiv.org/abs/2307.15367v1",
        "pub_date": "2023-07-28",
        "summary": "In this study, we address the interpretability issue in complex, black-box\nMachine Learning models applied to sequence data. We introduce the Model-Based\ntree Hidden Semi-Markov Model (MOB-HSMM), an inherently interpretable model\naimed at detecting high mortality risk events and discovering hidden patterns\nassociated with the mortality risk in Intensive Care Units (ICU). This model\nleverages knowledge distilled from Deep Neural Networks (DNN) to enhance\npredictive performance while offering clear explanations. Our experimental\nresults indicate the improved performance of Model-Based trees (MOB trees) via\nemploying LSTM for learning sequential patterns, which are then transferred to\nMOB trees. Integrating MOB trees with the Hidden Semi-Markov Model (HSMM) in\nthe MOB-HSMM enables uncovering potential and explainable sequences using\navailable information.",
        "translated": "在这项研究中，我们解决了复杂的，黑盒机器学习模型应用于序列数据的可解释性问题。我们介绍了基于模型的树隐藏半马尔可夫模型(MOB-HSMM) ，这是一个固有的可解释模型，旨在检测高死亡率风险事件并发现与重症监护病房(ICU)死亡风险相关的隐藏模式。该模型利用从深度神经网络(DNN)中提取的知识来增强预测性能，同时提供清晰的解释。实验结果表明，利用 LSTM 学习序列模式，可以提高基于模型树(MOB 树)的性能，并将序列模式转化为 MOB 树。在 MOB-HSMM 中集成 MOB 树和隐半马尔可夫模型(HSMM) ，可以利用现有信息揭示潜在的、可解释的序列。"
    },
    {
        "title": "Staging E-Commerce Products for Online Advertising using Retrieval\n  Assisted Image Generation",
        "url": "http://arxiv.org/abs/2307.15326v1",
        "pub_date": "2023-07-28",
        "summary": "Online ads showing e-commerce products typically rely on the product images\nin a catalog sent to the advertising platform by an e-commerce platform. In the\nbroader ads industry such ads are called dynamic product ads (DPA). It is\ncommon for DPA catalogs to be in the scale of millions (corresponding to the\nscale of products which can be bought from the e-commerce platform). However,\nnot all product images in the catalog may be appealing when directly\nre-purposed as an ad image, and this may lead to lower click-through rates\n(CTRs). In particular, products just placed against a solid background may not\nbe as enticing and realistic as a product staged in a natural environment. To\naddress such shortcomings of DPA images at scale, we propose a generative\nadversarial network (GAN) based approach to generate staged backgrounds for\nun-staged product images. Generating the entire staged background is a\nchallenging task susceptible to hallucinations. To get around this, we\nintroduce a simpler approach called copy-paste staging using retrieval assisted\nGANs. In copy paste staging, we first retrieve (from the catalog) staged\nproducts similar to the un-staged input product, and then copy-paste the\nbackground of the retrieved product in the input image. A GAN based in-painting\nmodel is used to fill the holes left after this copy-paste operation. We show\nthe efficacy of our copy-paste staging method via offline metrics, and human\nevaluation. In addition, we show how our staging approach can enable animations\nof moving products leading to a video ad from a product image.",
        "translated": "显示电子商务产品的在线广告通常依赖于电子商务平台发送到广告平台的目录中的产品图像。在更广泛的广告行业，这样的广告被称为动态产品广告(DPA)。DPA 目录的规模通常是数百万(相当于可以从电子商务平台购买的产品的规模)。然而，并非所有的产品图像在目录可能是吸引人的时候，直接重新作为一个广告图像，这可能导致较低的点击率(CTR)。特别是，产品只是放置在一个坚实的背景可能不会像一个诱人的和现实的产品阶段在自然环境中。针对 DPA 图像在尺度上存在的缺陷，提出了一种基于生成对抗网络(GAN)的非阶段性产品图像阶段性背景生成方法。生成整个舞台背景是一项很有挑战性的任务，很容易产生幻觉。为了解决这个问题，我们引入了一种更简单的方法，即使用检索辅助 GAN 的复制粘贴暂存。在复制粘贴阶段中，我们首先检索(从目录)阶段性产品，类似于非阶段性输入产品，然后复制粘贴输入图像中被检索产品的背景。一个基于 GAN 的内绘模型被用来填补这个复制粘贴操作后留下的漏洞。我们通过离线指标和人类评估展示了我们的复制粘贴分期方法的有效性。此外，我们还展示了我们的分段方法如何能够实现从产品图像导向视频广告的移动产品的动画。"
    },
    {
        "title": "Reconciling the accuracy-diversity trade-off in recommendations",
        "url": "http://arxiv.org/abs/2307.15142v1",
        "pub_date": "2023-07-27",
        "summary": "In recommendation settings, there is an apparent trade-off between the goals\nof accuracy (to recommend items a user is most likely to want) and diversity\n(to recommend items representing a range of categories). As such, real-world\nrecommender systems often explicitly incorporate diversity separately from\naccuracy. This approach, however, leaves a basic question unanswered: Why is\nthere a trade-off in the first place?\n  We show how the trade-off can be explained via a user's consumption\nconstraints -- users typically only consume a few of the items they are\nrecommended. In a stylized model we introduce, objectives that account for this\nconstraint induce diverse recommendations, while objectives that do not account\nfor this constraint induce homogeneous recommendations. This suggests that\naccuracy and diversity appear misaligned because standard accuracy metrics do\nnot consider consumption constraints. Our model yields precise and\ninterpretable characterizations of diversity in different settings, giving\npractical insights into the design of diverse recommendations.",
        "translated": "在推荐设置中，在准确性目标(推荐用户最可能想要的项目)和多样性目标(推荐代表一系列类别的项目)之间存在明显的权衡。因此，现实世界中的推荐系统通常明确地将多样性与准确性分开。然而，这种方法留下了一个基本问题没有得到解答: 为什么首先要进行权衡？我们将展示如何通过用户的消费约束来解释这种权衡——用户通常只消费推荐的几个项目。在我们引入的程式化模型中，解释这种约束的目标会产生不同的建议，而不解释这种约束的目标会产生同质的建议。这表明准确性和多样性似乎不一致，因为标准的准确性指标没有考虑消费约束。我们的模型产生了不同环境下多样性的精确和可解释的特征，为不同建议的设计提供了实用的见解。"
    },
    {
        "title": "Uncertainty in Natural Language Generation: From Theory to Applications",
        "url": "http://arxiv.org/abs/2307.15703v1",
        "pub_date": "2023-07-28",
        "summary": "Recent advances of powerful Language Models have allowed Natural Language\nGeneration (NLG) to emerge as an important technology that can not only perform\ntraditional tasks like summarisation or translation, but also serve as a\nnatural language interface to a variety of applications. As such, it is crucial\nthat NLG systems are trustworthy and reliable, for example by indicating when\nthey are likely to be wrong; and supporting multiple views, backgrounds and\nwriting styles -- reflecting diverse human sub-populations. In this paper, we\nargue that a principled treatment of uncertainty can assist in creating systems\nand evaluation protocols better aligned with these goals. We first present the\nfundamental theory, frameworks and vocabulary required to represent\nuncertainty. We then characterise the main sources of uncertainty in NLG from a\nlinguistic perspective, and propose a two-dimensional taxonomy that is more\ninformative and faithful than the popular aleatoric/epistemic dichotomy.\nFinally, we move from theory to applications and highlight exciting research\ndirections that exploit uncertainty to power decoding, controllable generation,\nself-assessment, selective answering, active learning and more.",
        "translated": "强大的语言模型的最新进展使得自然语言生成(Natural Language Generation，NLG)成为一种重要的技术，它不仅可以执行诸如摘要或翻译之类的传统任务，而且还可以作为各种应用程序的自然语言接口。因此，至关重要的是 NLG 系统是值得信赖和可靠的，例如通过指出它们什么时候可能是错误的; 支持多种观点、背景和写作风格——反映不同的人类子群体。在本文中，我们认为，一个原则性的处理不确定性可以帮助创建系统和评估协议更好地符合这些目标。我们首先介绍表示不确定性所需的基本理论、框架和词汇。然后，我们从语言学的角度描述了 NLG 中不确定性的主要来源，并提出了一个二维分类法，它比流行的任意/认知二分法更加信息丰富和忠实。最后，我们从理论转向应用，并强调令人兴奋的研究方向，利用不确定性的功率解码，可控生成，自我评估，选择性应答，主动学习等。"
    },
    {
        "title": "Scaling Data Generation in Vision-and-Language Navigation",
        "url": "http://arxiv.org/abs/2307.15644v1",
        "pub_date": "2023-07-28",
        "summary": "Recent research in language-guided visual navigation has demonstrated a\nsignificant demand for the diversity of traversable environments and the\nquantity of supervision for training generalizable agents. To tackle the common\ndata scarcity issue in existing vision-and-language navigation datasets, we\npropose an effective paradigm for generating large-scale data for learning,\nwhich applies 1200+ photo-realistic environments from HM3D and Gibson datasets\nand synthesizes 4.9 million instruction trajectory pairs using fully-accessible\nresources on the web. Importantly, we investigate the influence of each\ncomponent in this paradigm on the agent's performance and study how to\nadequately apply the augmented data to pre-train and fine-tune an agent. Thanks\nto our large-scale dataset, the performance of an existing agent can be pushed\nup (+11% absolute with regard to previous SoTA) to a significantly new best of\n80% single-run success rate on the R2R test split by simple imitation learning.\nThe long-lasting generalization gap between navigating in seen and unseen\nenvironments is also reduced to less than 1% (versus 8% in the previous best\nmethod). Moreover, our paradigm also facilitates different models to achieve\nnew state-of-the-art navigation results on CVDN, REVERIE, and R2R in continuous\nenvironments.",
        "translated": "语言引导视觉导航的研究表明，对可穿越环境的多样性和对可推广智能体培训的监督数量提出了很高的要求。为了解决现有视觉和语言导航数据集中常见的数据稀缺问题，我们提出了一个有效的范例来生成用于学习的大规模数据，该范例应用来自 HM3D 和 Gibson 数据集的1200 + 照片现实环境，并使用完全可访问的网络资源合成了490万个指令轨迹对。重要的是，我们调查了这个范式中的每个组件对代理性能的影响，并研究了如何充分应用增强数据来预训练和微调代理。由于我们的大规模数据集，通过简单的模仿学习，现有代理的性能可以提高(相对于以前的 SoTA 绝对值增加11%) ，达到 R2R 测试80% 单次运行成功率的显着新的最佳水平。在看得见和看不见的环境中导航之间的长期普遍性差距也减少到不到1% (相比之下，以前的最佳方法为8%)。此外，我们的范式还促进不同的模型，以实现新的国家的最先进的导航结果在 CVDN，REVERIE 和 R2R 在连续的环境。"
    },
    {
        "title": "Robust Distortion-free Watermarks for Language Models",
        "url": "http://arxiv.org/abs/2307.15593v1",
        "pub_date": "2023-07-28",
        "summary": "We propose a methodology for planting watermarks in text from an\nautoregressive language model that are robust to perturbations without changing\nthe distribution over text up to a certain maximum generation budget. We\ngenerate watermarked text by mapping a sequence of random numbers -- which we\ncompute using a randomized watermark key -- to a sample from the language\nmodel. To detect watermarked text, any party who knows the key can align the\ntext to the random number sequence. We instantiate our watermark methodology\nwith two sampling schemes: inverse transform sampling and exponential minimum\nsampling. We apply these watermarks to three language models -- OPT-1.3B,\nLLaMA-7B and Alpaca-7B -- to experimentally validate their statistical power\nand robustness to various paraphrasing attacks. Notably, for both the OPT-1.3B\nand LLaMA-7B models, we find we can reliably detect watermarked text ($p \\leq\n0.01$) from $35$ tokens even after corrupting between $40$-$50$\\% of the tokens\nvia random edits (i.e., substitutions, insertions or deletions). For the\nAlpaca-7B model, we conduct a case study on the feasibility of watermarking\nresponses to typical user instructions. Due to the lower entropy of the\nresponses, detection is more difficult: around $25\\%$ of the responses -- whose\nmedian length is around $100$ tokens -- are detectable with $p \\leq 0.01$, and\nthe watermark is also less robust to certain automated paraphrasing attacks we\nimplement.",
        "translated": "我们提出了一种在文本中植入水印的方法，该方法基于一种自回归语言模型，能够在不改变文本分布的情况下抵抗干扰，并且具有一定的最大生成预算。我们通过将一系列随机数字映射到语言模型中的样本来生成带水印的文本——我们使用一个随机水印键来计算这些随机数字。为了检测带水印的文本，任何知道密钥的人都可以将文本与随机数序列对齐。我们用两种抽样方案实例化我们的水印方法: 逆变换抽样和指数最小抽样。我们将这些水印应用于三种语言模型—— OPT-1.3 B、 LLaMA-7B 和 Alpaca-7B ——以实验验证它们对各种解释攻击的统计能力和鲁棒性。值得注意的是，对于 OPT-1.3 B 和 LLaMA-7B 模型，我们发现即使通过随机编辑损坏 $40 $- $50 $% 的令牌(即，替换，插入或删除) ，我们也可以从 $35 $令牌可靠地检测水印文本($p leq 0.01 $)。对于 Alpaca-7B 模型，我们进行了水印响应典型用户指令的可行性的案例研究。由于响应的熵较低，检测更加困难: 大约25% 的响应——其中值长度约为100美元 $令牌——可以用 $p leq 0.01 $检测到，并且水印对于我们实现的某些自动转述攻击也不太稳定。"
    },
    {
        "title": "When to generate hedges in peer-tutoring interactions",
        "url": "http://arxiv.org/abs/2307.15582v1",
        "pub_date": "2023-07-28",
        "summary": "This paper explores the application of machine learning techniques to predict\nwhere hedging occurs in peer-tutoring interactions. The study uses a\nnaturalistic face-to-face dataset annotated for natural language turns,\nconversational strategies, tutoring strategies, and nonverbal behaviours. These\nelements are processed into a vector representation of the previous turns,\nwhich serves as input to several machine learning models. Results show that\nembedding layers, that capture the semantic information of the previous turns,\nsignificantly improves the model's performance. Additionally, the study\nprovides insights into the importance of various features, such as\ninterpersonal rapport and nonverbal behaviours, in predicting hedges by using\nShapley values for feature explanation. We discover that the eye gaze of both\nthe tutor and the tutee has a significant impact on hedge prediction. We\nfurther validate this observation through a follow-up ablation study.",
        "translated": "本文探讨了应用机器学习技术来预测模糊限制发生在同伴辅导交互中的位置。这项研究使用了一个自然的面对面数据集，注释了自然语言转换、会话策略、辅导策略和非语言行为。这些元素被处理成前轮的向量表示，作为几个机器学习模型的输入。结果显示，嵌入层捕捉了前一个转弯的语义信息，显著提高了模型的性能。此外，本研究还提供了各种特征的重要性，如人际关系和非语言行为，在预测模糊限制语使用沙普利值的特征解释。我们发现导师和老师的眼睛注视对套期保值预测有显著的影响。我们通过随访消融研究进一步验证了这一观察结果。"
    },
    {
        "title": "All-for-One and One-For-All: Deep learning-based feature fusion for\n  Synthetic Speech Detection",
        "url": "http://arxiv.org/abs/2307.15555v1",
        "pub_date": "2023-07-28",
        "summary": "Recent advances in deep learning and computer vision have made the synthesis\nand counterfeiting of multimedia content more accessible than ever, leading to\npossible threats and dangers from malicious users. In the audio field, we are\nwitnessing the growth of speech deepfake generation techniques, which solicit\nthe development of synthetic speech detection algorithms to counter possible\nmischievous uses such as frauds or identity thefts. In this paper, we consider\nthree different feature sets proposed in the literature for the synthetic\nspeech detection task and present a model that fuses them, achieving overall\nbetter performances with respect to the state-of-the-art solutions. The system\nwas tested on different scenarios and datasets to prove its robustness to\nanti-forensic attacks and its generalization capabilities.",
        "translated": "深度学习和计算机视觉方面的最新进展使多媒体内容的合成和伪造比以往任何时候都更容易获得，导致恶意用户可能造成的威胁和危险。在音频领域，我们目睹了语音深度伪造生成技术的发展，这些技术要求开发合成语音检测算法来对付欺诈或身份盗窃等可能的恶意使用。在本文中，我们考虑了文献中提出的三种不同的合成语音检测任务的特征集，并提出了一个模型来融合它们，从而在最先进的解决方案方面获得了更好的性能。该系统在不同的场景和数据集上进行了测试，以证明其对反取证攻击的鲁棒性和泛化能力。"
    },
    {
        "title": "'What are you referring to?' Evaluating the Ability of Multi-Modal\n  Dialogue Models to Process Clarificational Exchanges",
        "url": "http://arxiv.org/abs/2307.15554v1",
        "pub_date": "2023-07-28",
        "summary": "Referential ambiguities arise in dialogue when a referring expression does\nnot uniquely identify the intended referent for the addressee. Addressees\nusually detect such ambiguities immediately and work with the speaker to repair\nit using meta-communicative, Clarificational Exchanges (CE): a Clarification\nRequest (CR) and a response. Here, we argue that the ability to generate and\nrespond to CRs imposes specific constraints on the architecture and objective\nfunctions of multi-modal, visually grounded dialogue models. We use the SIMMC\n2.0 dataset to evaluate the ability of different state-of-the-art model\narchitectures to process CEs, with a metric that probes the contextual updates\nthat arise from them in the model. We find that language-based models are able\nto encode simple multi-modal semantic information and process some CEs,\nexcelling with those related to the dialogue history, whilst multi-modal models\ncan use additional learning objectives to obtain disentangled object\nrepresentations, which become crucial to handle complex referential ambiguities\nacross modalities overall.",
        "translated": "当一个引用表达式不能唯一地标识对收件人的预期引用时，在对话中就会出现引用歧义。收件人通常会立即发现这种歧义，并与说话人合作，使用元交际、澄清交流(CE) : 澄清请求(CR)和回应来修复这种歧义。在这里，我们认为，产生和响应 CR 的能力对多模态、视觉基础的对话模型的架构和目标功能施加了特定的限制。我们使用 SIMMC 2.0数据集来评估不同最先进的模型架构处理 CEs 的能力，并使用一个度量来探测模型中由它们产生的上下文更新。我们发现基于语言的模型能够编码简单的多模态语义信息和处理一些 CEs，优于那些与对话历史相关的模型，而多模态模型可以使用额外的学习目标来获得分离的对象表示，这对于处理跨模态的复杂的指称模糊是至关重要的。"
    },
    {
        "title": "Oracle Computability and Turing Reducibility in the Calculus of\n  Inductive Constructions",
        "url": "http://arxiv.org/abs/2307.15543v1",
        "pub_date": "2023-07-28",
        "summary": "We develop synthetic notions of oracle computability and Turing reducibility\nin the Calculus of Inductive Constructions (CIC), the constructive type theory\nunderlying the Coq proof assistant. As usual in synthetic approaches, we employ\na definition of oracle computations based on meta-level functions rather than\nobject-level models of computation, relying on the fact that in constructive\nsystems such as CIC all definable functions are computable by construction.\nSuch an approach lends itself well to machine-checked proofs, which we carry\nout in Coq.\n  There is a tension in finding a good synthetic rendering of the higher-order\nnotion of oracle computability. On the one hand, it has to be informative\nenough to prove central results, ensuring that all notions are faithfully\ncaptured. On the other hand, it has to be restricted enough to benefit from\naxioms for synthetic computability, which usually concern first-order objects.\nDrawing inspiration from a definition by Andrej Bauer based on continuous\nfunctions in the effective topos, we use a notion of sequential continuity to\ncharacterise valid oracle computations.\n  As main technical results, we show that Turing reducibility forms an upper\nsemilattice, transports decidability, and is strictly more expressive than\ntruth-table reducibility, and prove that whenever both a predicate $p$ and its\ncomplement are semi-decidable relative to an oracle $q$, then $p$\nTuring-reduces to $q$.",
        "translated": "我们发展了归纳构造演算(CIC)中的甲骨文可计算性和图灵可约性的综合概念，构造型理论是 Coq 证明的基础。通常在综合方法中，我们使用基于元水平函数的预言计算的定义，而不是基于对象水平的计算模型，依赖于这样一个事实，即在构造性系统中，例如 CIC，所有可定义的函数都可以通过构造来计算。这种方法很适合于机器检查证明，我们在 Coq 中实现这一点。在寻找一个很好的高阶 Oracle 可计算性概念的综合呈现时，存在着一种张力。一方面，它必须有足够的信息来证明中心结果，确保所有的概念都被忠实地捕获。另一方面，它必须受到足够的限制，以便受益于合成可计算性的公理，这通常涉及到一阶对象。从 Andrej Bauer 基于有效拓扑中连续函数的定义中获得灵感，我们使用序列连续性的概念来描述有效的预言计算。作为主要的技术结果，我们证明了图灵可约性形成了一个上半格，传输可约性，并且比真表可约性更具表达性，并且证明了当一个谓词 $p $及其补语相对于一个 Oracle $q $都是半可约的时候，那么 $p $图灵-减少到 $q $。"
    },
    {
        "title": "The Road to Quality is Paved with Good Revisions: A Detailed Evaluation\n  Methodology for Revision Policies in Incremental Sequence Labelling",
        "url": "http://arxiv.org/abs/2307.15508v1",
        "pub_date": "2023-07-28",
        "summary": "Incremental dialogue model components produce a sequence of output prefixes\nbased on incoming input. Mistakes can occur due to local ambiguities or to\nwrong hypotheses, making the ability to revise past outputs a desirable\nproperty that can be governed by a policy. In this work, we formalise and\ncharacterise edits and revisions in incremental sequence labelling and propose\nmetrics to evaluate revision policies. We then apply our methodology to profile\nthe incremental behaviour of three Transformer-based encoders in various tasks,\npaving the road for better revision policies.",
        "translated": "增量对话模型组件根据输入产生一系列输出前缀。错误可能由于当地的模糊性或错误的假设而发生，使得修订过去产出的能力成为可以由政策管理的理想财产。在这项工作中，我们正式和特点编辑和修订的增量序列标签，并提出衡量标准，以评估修订政策。然后，我们应用我们的方法来描述三个变压器为基础的编码器在各种任务中的增量行为，为更好的修订策略铺平道路。"
    },
    {
        "title": "Exploring Format Consistency for Instruction Tuning",
        "url": "http://arxiv.org/abs/2307.15504v1",
        "pub_date": "2023-07-28",
        "summary": "Instruction tuning has emerged as a promising approach to enhancing large\nlanguage models in following human instructions. It is shown that increasing\nthe diversity and number of instructions in the training data can consistently\nenhance generalization performance, which facilitates a recent endeavor to\ncollect various instructions and integrate existing instruction tuning datasets\ninto larger collections. However, different users have their unique ways of\nexpressing instructions, and there often exist variations across different\ndatasets in the instruction styles and formats, i.e., format inconsistency. In\nthis work, we study how format inconsistency may impact the performance of\ninstruction tuning. We propose a framework called \"Unified Instruction Tuning\"\n(UIT), which calls OpenAI APIs for automatic format transfer among different\ninstruction tuning datasets. We show that UIT successfully improves the\ngeneralization performance on unseen instructions, which highlights the\nimportance of format consistency for instruction tuning. To make the UIT\nframework more practical, we further propose a novel perplexity-based denoising\nmethod to reduce the noise of automatic format transfer. We also train a\nsmaller offline model that achieves comparable format transfer capability than\nOpenAI APIs to reduce costs in practice.",
        "translated": "指令调优已经成为一种很有前途的方法，可以在遵循人类指令的过程中增强大型语言模型。结果表明，增加训练数据中指令的多样性和数量可以持续地提高泛化性能，这有助于近年来收集各种指令并将现有的指令调优数据集集成到更大的数据集中。然而，不同的用户有其独特的指令表达方式，不同的数据集在指令风格和格式上往往存在差异，即格式不一致。在这项工作中，我们研究了格式不一致如何影响指令调优的性能。我们提出了一个名为“统一指令调优”(UIT)的框架，它调用 OpenAI API 来实现不同指令调优数据集之间的自动格式转换。我们表明 UIT 成功地提高了未知指令的泛化性能，这突出了指令调优中格式一致性的重要性。为了使 UIT 框架更加实用，我们进一步提出了一种新的基于困惑的去噪方法，以降低自动格式转换的噪声。我们还培训了一个较小的离线模型，它实现了与 OpenAI API 相当的格式传输能力，从而在实践中降低了成本。"
    },
    {
        "title": "ETHER: Aligning Emergent Communication for Hindsight Experience Replay",
        "url": "http://arxiv.org/abs/2307.15494v1",
        "pub_date": "2023-07-28",
        "summary": "Natural language instruction following is paramount to enable collaboration\nbetween artificial agents and human beings. Natural language-conditioned\nreinforcement learning (RL) agents have shown how natural languages'\nproperties, such as compositionality, can provide a strong inductive bias to\nlearn complex policies. Previous architectures like HIGhER combine the benefit\nof language-conditioning with Hindsight Experience Replay (HER) to deal with\nsparse rewards environments. Yet, like HER, HIGhER relies on an oracle\npredicate function to provide a feedback signal highlighting which linguistic\ndescription is valid for which state. This reliance on an oracle limits its\napplication. Additionally, HIGhER only leverages the linguistic information\ncontained in successful RL trajectories, thus hurting its final performance and\ndata-efficiency. Without early successful trajectories, HIGhER is no better\nthan DQN upon which it is built. In this paper, we propose the Emergent Textual\nHindsight Experience Replay (ETHER) agent, which builds on HIGhER and addresses\nboth of its limitations by means of (i) a discriminative visual referential\ngame, commonly studied in the subfield of Emergent Communication (EC), used\nhere as an unsupervised auxiliary task and (ii) a semantic grounding scheme to\nalign the emergent language with the natural language of the\ninstruction-following benchmark. We show that the referential game's agents\nmake an artificial language emerge that is aligned with the natural-like\nlanguage used to describe goals in the BabyAI benchmark and that it is\nexpressive enough so as to also describe unsuccessful RL trajectories and thus\nprovide feedback to the RL agent to leverage the linguistic, structured\ninformation contained in all trajectories. Our work shows that EC is a viable\nunsupervised auxiliary task for RL and provides missing pieces to make HER more\nwidely applicable.",
        "translated": "遵循自然语言指令对于人工智能体和人类之间的协作至关重要。自然语言条件强化学习(RL)代理已经展示了自然语言的属性，如合成性，如何能够提供一个强大的归纳偏好来学习复杂的政策。以前的架构如 HIGhER 结合了语言条件作用和事后体验重放(HIGER)来处理稀疏的奖励环境。然而，与 HER 一样，HIghER 依赖于 oracle 谓词函数来提供反馈信号，突出哪个描写语法学对哪个状态有效。这种对先知的依赖限制了它的应用。此外，HIGhER 只利用成功的 RL 轨迹中包含的语言信息，从而损害其最终性能和数据效率。如果没有早期的成功轨迹，HIGhER 并不比构建它的 DQN 更好。本文提出了一种基于 HIGhER 的应急文本后见之明体验重放(ETHER)代理，该代理通过以下两种方式来解决其局限性: (1)应急通信(EC)子领域中常用的区分性视觉参照游戏，作为一个无监督的辅助任务; (2)语义基础方案，使应急语言与指令跟踪基准的自然语言保持一致。我们展示了参考游戏的代理使一种人工语言出现，这种语言与 BabyAI 基准中用于描述目标的类似自然的语言保持一致，并且它具有足够的表达能力，以便也描述不成功的 RL 轨迹，从而向 RL 代理提供反馈，以利用包含在所有轨迹中的语言结构化信息。我们的工作表明，EC 是一个可行的无监督辅助任务的 RL，并提供缺失的部分，使她更广泛地适用。"
    },
    {
        "title": "HAGRID: A Human-LLM Collaborative Dataset for Generative\n  Information-Seeking with Attribution",
        "url": "http://arxiv.org/abs/2307.16883v1",
        "pub_date": "2023-07-31",
        "summary": "The rise of large language models (LLMs) had a transformative impact on\nsearch, ushering in a new era of search engines that are capable of generating\nsearch results in natural language text, imbued with citations for supporting\nsources. Building generative information-seeking models demands openly\naccessible datasets, which currently remain lacking. In this paper, we\nintroduce a new dataset, HAGRID (Human-in-the-loop Attributable Generative\nRetrieval for Information-seeking Dataset) for building end-to-end generative\ninformation-seeking models that are capable of retrieving candidate quotes and\ngenerating attributed explanations. Unlike recent efforts that focus on human\nevaluation of black-box proprietary search engines, we built our dataset atop\nthe English subset of MIRACL, a publicly available information retrieval\ndataset. HAGRID is constructed based on human and LLM collaboration. We first\nautomatically collect attributed explanations that follow an in-context\ncitation style using an LLM, i.e. GPT-3.5. Next, we ask human annotators to\nevaluate the LLM explanations based on two criteria: informativeness and\nattributability. HAGRID serves as a catalyst for the development of\ninformation-seeking models with better attribution capabilities.",
        "translated": "大型语言模型(LLM)的兴起对搜索产生了变革性的影响，开创了一个新时代的搜索引擎，这些搜索引擎能够以自然语言文本生成搜索结果，并充满了对支持来源的引用。建立生成式信息搜索模型需要公开可访问的数据集，目前仍然缺乏这种数据集。本文引入了一个新的数据集—— HAGRID (Human-In-the-loop Attriable Generative Retrieval for Information-looking Dataset) ，用于构建端到端的生成性信息搜索模型，该模型能够检索候选引文并生成属性解释。与最近关注人类对黑盒专有搜索引擎评估的努力不同，我们将数据集建立在 MIRACL 的英文子集之上，MIRACL 是一个公开的信息检索数据集。HAGRID 是基于人与 LLM 协作构建的。我们首先使用 LLM (即 GPT-3.5)自动收集遵循上下文引用风格的属性解释。接下来，我们要求人工注释者基于两个标准来评估 LLM 的解释: 信息性和归属性。HAGRID 是发展具有更好归因能力的信息搜寻模式的催化剂。"
    },
    {
        "title": "Metric@CustomerN: Evaluating Metrics at a Customer Level in E-Commerce",
        "url": "http://arxiv.org/abs/2307.16832v1",
        "pub_date": "2023-07-31",
        "summary": "Accuracy measures such as Recall, Precision, and Hit Rate have been a\nstandard way of evaluating Recommendation Systems. The assumption is to use a\nfixed Top-N to represent them. We propose that median impressions viewed from\nhistorical sessions per diner be used as a personalized value for N. We present\npreliminary exploratory results and list future steps to improve upon and\nevaluate the efficacy of these personalized metrics.",
        "translated": "精确度指标，如召回率、精确度和命中率，已经成为评估推荐系统的标准方法。假设使用一个固定的 Top-N 来表示它们。我们建议从每个用餐者的历史会议中观察到的中位印象可以作为 N 的个性化值。我们提出了初步的探索性结果，并列出了未来的步骤，以改善和评估这些个性化指标的有效性。"
    },
    {
        "title": "Defense of Adversarial Ranking Attack in Text Retrieval: Benchmark and\n  Baseline via Detection",
        "url": "http://arxiv.org/abs/2307.16816v1",
        "pub_date": "2023-07-31",
        "summary": "Neural ranking models (NRMs) have undergone significant development and have\nbecome integral components of information retrieval (IR) systems.\nUnfortunately, recent research has unveiled the vulnerability of NRMs to\nadversarial document manipulations, potentially exploited by malicious search\nengine optimization practitioners. While progress in adversarial attack\nstrategies aids in identifying the potential weaknesses of NRMs before their\ndeployment, the defensive measures against such attacks, like the detection of\nadversarial documents, remain inadequately explored. To mitigate this gap, this\npaper establishes a benchmark dataset to facilitate the investigation of\nadversarial ranking defense and introduces two types of detection tasks for\nadversarial documents. A comprehensive investigation of the performance of\nseveral detection baselines is conducted, which involve examining the\nspamicity, perplexity, and linguistic acceptability, and utilizing supervised\nclassifiers. Experimental results demonstrate that a supervised classifier can\neffectively mitigate known attacks, but it performs poorly against unseen\nattacks. Furthermore, such classifier should avoid using query text to prevent\nlearning the classification on relevance, as it might lead to the inadvertent\ndiscarding of relevant documents.",
        "translated": "神经排序模型(NRM)经历了重大的发展，已成为信息检索系统(IR)不可或缺的组成部分。不幸的是，最近的研究揭示了非注册搜索引擎优化在对抗性文件操纵方面的脆弱性，这可能被恶意的非注册机构从业者利用。尽管对抗性攻击策略的进展有助于在部署 NRM 之前发现其潜在的弱点，但防御此类攻击的措施，如检测对抗性文件，仍然没有得到充分的探索。为了弥补这一差距，本文建立了一个基准数据集，以方便对抗性排序防御的调查，并介绍了两种类型的检测任务的对抗性文档。本文对几种检测基线的性能进行了全面的研究，包括检测基线的垃圾性、困惑性和语言可接受性，以及使用有监督的分类器。实验结果表明，监督分类器能够有效地减轻已知攻击，但对于不可见攻击效果较差。此外，这种分类器应避免使用查询文本，以防止根据相关性学习分类，因为这可能导致无意中丢弃相关文档。"
    },
    {
        "title": "Lexically-Accelerated Dense Retrieval",
        "url": "http://arxiv.org/abs/2307.16779v1",
        "pub_date": "2023-07-31",
        "summary": "Retrieval approaches that score documents based on learned dense vectors\n(i.e., dense retrieval) rather than lexical signals (i.e., conventional\nretrieval) are increasingly popular. Their ability to identify related\ndocuments that do not necessarily contain the same terms as those appearing in\nthe user's query (thereby improving recall) is one of their key advantages.\nHowever, to actually achieve these gains, dense retrieval approaches typically\nrequire an exhaustive search over the document collection, making them\nconsiderably more expensive at query-time than conventional lexical approaches.\nSeveral techniques aim to reduce this computational overhead by approximating\nthe results of a full dense retriever. Although these approaches reasonably\napproximate the top results, they suffer in terms of recall -- one of the key\nadvantages of dense retrieval. We introduce 'LADR' (Lexically-Accelerated Dense\nRetrieval), a simple-yet-effective approach that improves the efficiency of\nexisting dense retrieval models without compromising on retrieval\neffectiveness. LADR uses lexical retrieval techniques to seed a dense retrieval\nexploration that uses a document proximity graph. We explore two variants of\nLADR: a proactive approach that expands the search space to the neighbors of\nall seed documents, and an adaptive approach that selectively searches the\ndocuments with the highest estimated relevance in an iterative fashion. Through\nextensive experiments across a variety of dense retrieval models, we find that\nLADR establishes a new dense retrieval effectiveness-efficiency Pareto frontier\namong approximate k nearest neighbor techniques. Further, we find that when\ntuned to take around 8ms per query in retrieval latency on our hardware, LADR\nconsistently achieves both precision and recall that are on par with an\nexhaustive search on standard benchmarks.",
        "translated": "基于学习密集向量(即密集检索)而非词汇信号(即常规检索)对文档进行评分的检索方法越来越流行。它们能够识别出与用户查询中出现的不一定包含相同术语的相关文档(从而提高召回率) ，这是它们的主要优势之一。然而，为了实际获得这些收益，密集检索方法通常需要对文档集进行彻底搜索，这使得它们在查询时比传统的词法方法昂贵得多。一些技术旨在通过近似一个完全密集的检索器的结果来减少这种计算开销。尽管这些方法可以合理地接近最高的结果，但它们在回忆方面受到影响——这是密集检索的关键优势之一。我们介绍了“ LADR”(词汇加速密集检索) ，一种简单而有效的方法，提高了现有的密集检索模型的效率，而不影响检索的有效性。LADR 使用词汇检索技术来引导使用文档接近图的密集检索探索。我们探索了 LADR 的两种变体: 一种积极主动的方法，将搜索空间扩展到所有种子文档的邻居，以及一种自适应的方法，以迭代的方式选择性地搜索具有最高估计相关性的文档。通过对各种密集检索模型的大量实验，我们发现 LADR 在近似 k 最近邻技术中建立了一种新的密集检索有效性——帕累托前沿。此外，我们发现，当硬件上的检索延迟调整到每个查询大约需要8毫秒时，LADR 始终如一地实现了这两个准确率召回率，与标准基准的详尽搜索相当。"
    },
    {
        "title": "AsdKB: A Chinese Knowledge Base for the Early Screening and Diagnosis of\n  Autism Spectrum Disorder",
        "url": "http://arxiv.org/abs/2307.16773v1",
        "pub_date": "2023-07-31",
        "summary": "To easily obtain the knowledge about autism spectrum disorder and help its\nearly screening and diagnosis, we create AsdKB, a Chinese knowledge base on\nautism spectrum disorder. The knowledge base is built on top of various\nsources, including 1) the disease knowledge from SNOMED CT and ICD-10 clinical\ndescriptions on mental and behavioural disorders, 2) the diagnostic knowledge\nfrom DSM-5 and different screening tools recommended by social organizations\nand medical institutes, and 3) the expert knowledge on professional physicians\nand hospitals from the Web. AsdKB contains both ontological and factual\nknowledge, and is accessible as Linked Data at https://w3id.org/asdkb/. The\npotential applications of AsdKB are question answering, auxiliary diagnosis,\nand expert recommendation, and we illustrate them with a prototype which can be\naccessed at http://asdkb.org.cn/.",
        "translated": "为了更容易地获得有关自闭症光谱的知识，并帮助其早期筛查和诊断，我们创建了 asdkB，这是一个关于自闭症光谱的中文知识库。知识库建立在各种来源的基础之上，包括1) SNOMED CT 和 ICD-10对精神和行为障碍的临床描述的疾病知识，2) DSM-5的诊断知识和社会组织和医疗机构推荐的不同筛查工具，以及3)来自网络的专业医生和医院的专家知识。AsdkB 包含本体论知识和事实知识，并且可以作为 https://w3id.org/AsdKB/的关联数据访问。AsdkB 的潜在应用包括回答问题、辅助诊断和专家推荐，我们用一个可以在 http://AsdKB.org.cn/访问的原型来说明这些应用。"
    },
    {
        "title": "Virtual Prompt Injection for Instruction-Tuned Large Language Models",
        "url": "http://arxiv.org/abs/2307.16888v1",
        "pub_date": "2023-07-31",
        "summary": "We present Virtual Prompt Injection (VPI) for instruction-tuned Large\nLanguage Models (LLMs). VPI allows an attacker-specified virtual prompt to\nsteer the model behavior under specific trigger scenario without any explicit\ninjection in model input. For instance, if an LLM is compromised with the\nvirtual prompt \"Describe Joe Biden negatively.\" for Joe Biden-related\ninstructions, then any service deploying this model will propagate biased views\nwhen handling user queries related to Joe Biden. VPI is especially harmful for\ntwo primary reasons. Firstly, the attacker can take fine-grained control over\nLLM behaviors by defining various virtual prompts, exploiting LLMs' proficiency\nin following instructions. Secondly, this control is achieved without any\ninteraction from the attacker while the model is in service, leading to\npersistent attack. To demonstrate the threat, we propose a simple method for\nperforming VPI by poisoning the model's instruction tuning data. We find that\nour proposed method is highly effective in steering the LLM with VPI. For\nexample, by injecting only 52 poisoned examples (0.1% of the training data\nsize) into the instruction tuning data, the percentage of negative responses\ngiven by the trained model on Joe Biden-related queries change from 0% to 40%.\nWe thus highlight the necessity of ensuring the integrity of the\ninstruction-tuning data as little poisoned data can cause stealthy and\npersistent harm to the deployed model. We further explore the possible defenses\nand identify data filtering as an effective way to defend against the poisoning\nattacks. Our project page is available at https://poison-llm.github.io.",
        "translated": "我们为指令调优的大型语言模型(LLM)提供了虚拟提示注入(VPI)。VPI 允许攻击者指定的虚拟提示在特定的触发器场景下引导模型行为，而不需要在模型输入中显式注入。例如，如果虚拟提示符“负面描述乔 · 拜登”破坏了 LLM对于与乔 · 拜登相关的指令，那么任何部署此模型的服务在处理与乔 · 拜登相关的用户查询时都会传播有偏见的视图。VPI 尤其有害，主要有两个原因。首先，攻击者可以通过定义各种虚拟提示来获得对 LLM 行为的细粒度控制，利用 LLM 熟练执行下列指令的能力。其次，这种控制是在模型服务期间在没有任何来自攻击者的交互的情况下实现的，从而导致持久性攻击。为了演示这种威胁，我们提出了一种简单的方法，通过中毒模型的指令调优数据来执行 VPI。我们发现我们提出的方法是非常有效的指导 LLM 与 VPI。例如，通过只向指令调优数据中注入52个有毒示例(训练数据大小的0.1%) ，训练模型对 Joe Biden 相关查询给出的负面回答的百分比从0% 变为40% 。因此，我们强调了确保指令调优数据完整性的必要性，因为有毒数据很少会对已部署的模型造成隐形和持久的损害。我们进一步探讨了可能的防御措施，并确定数据过滤是防范中毒攻击的一种有效方法。我们的项目页面可在 https://poison-llm.github.io 下载。"
    },
    {
        "title": "Contrastive Learning for API Aspect Analysis",
        "url": "http://arxiv.org/abs/2307.16878v1",
        "pub_date": "2023-07-31",
        "summary": "We present a novel approach - CLAA - for API aspect detection in API reviews\nthat utilizes transformer models trained with a supervised contrastive loss\nobjective function. We evaluate CLAA using performance and impact analysis. For\nperformance analysis, we utilized a benchmark dataset on developer discussions\ncollected from Stack Overflow and compare the results to those obtained using\nstate-of-the-art transformer models. Our experiments show that contrastive\nlearning can significantly improve the performance of transformer models in\ndetecting aspects such as Performance, Security, Usability, and Documentation.\nFor impact analysis, we performed empirical and developer study. On a randomly\nselected and manually labeled 200 online reviews, CLAA achieved 92% accuracy\nwhile the SOTA baseline achieved 81.5%. According to our developer study\ninvolving 10 participants, the use of 'Stack Overflow + CLAA' resulted in\nincreased accuracy and confidence during API selection. Replication package:\nhttps://github.com/shahariar-shibli/Contrastive-Learning-for-API-Aspect-Analysis",
        "translated": "我们提出了一种新的方法-CLAA-API 方面检测的 API 审查，利用变压器模型训练与监督对比损耗目标函数。我们使用性能和影响分析来评估 CLAA。对于性能分析，我们使用了从 Stack Overflow 收集的关于开发人员讨论的基准数据集，并将结果与使用最先进的转换器模型获得的结果进行比较。我们的实验表明，对比学习可以显著提高变压器模型在检测性能、安全性、可用性和文档等方面的性能。对于影响分析，我们进行了实证研究和开发人员研究。在随机选择并手动标记的200篇在线评论中，CLAA 达到了92% 的准确率，而 SOTA 基线达到了81.5% 。根据我们涉及10个参与者的开发人员研究，使用“ Stack Overflow + CLAA”可以提高 API 选择的准确性和可信度。复制包:  https://github.com/shahariar-shibli/contrastive-learning-for-api-aspect-analysis"
    },
    {
        "title": "Evaluating Correctness and Faithfulness of Instruction-Following Models\n  for Question Answering",
        "url": "http://arxiv.org/abs/2307.16877v1",
        "pub_date": "2023-07-31",
        "summary": "Retriever-augmented instruction-following models are attractive alternatives\nto fine-tuned approaches for information-seeking tasks such as question\nanswering (QA). By simply prepending retrieved documents in its input along\nwith an instruction, these models can be adapted to various information domains\nand tasks without additional fine-tuning. While the model responses tend to be\nnatural and fluent, the additional verbosity makes traditional QA evaluation\nmetrics such as exact match (EM) and F1 unreliable for accurately quantifying\nmodel performance.\n  In this work, we investigate the performance of instruction-following models\nacross three information-seeking QA tasks. We use both automatic and human\nevaluation to evaluate these models along two dimensions: 1) how well they\nsatisfy the user's information need (correctness), and 2) whether they produce\na response based on the provided knowledge (faithfulness). Guided by human\nevaluation and analysis, we highlight the shortcomings of traditional metrics\nfor both correctness and faithfulness. We then propose simple token-overlap\nbased and model-based metrics that reflect the true performance of these\nmodels. Our analysis reveals that instruction-following models are competitive,\nand sometimes even outperform fine-tuned models for correctness. However, these\nmodels struggle to stick to the provided knowledge and often hallucinate in\ntheir responses. We hope our work encourages a more holistic evaluation of\ninstruction-following models for QA. Our code and data is available at\nhttps://github.com/McGill-NLP/instruct-qa",
        "translated": "对于诸如问答(QA)这样的信息搜索任务，检索增强的指令跟踪模型是有吸引力的替代方法。通过简单地在输入中预先输入检索到的文档以及指令，这些模型可以适应各种信息领域和任务，而不需要进行额外的微调。虽然模型响应趋向于自然和流畅，但是额外的冗长使得传统的 QA 评估指标如精确匹配(EM)和 F1不可靠，无法准确量化模型性能。在这项工作中，我们研究了在三个信息寻求 QA 任务中指令跟踪模型的表现。我们使用自动评价和人工评价两个维度来评价这些模型: 1)它们在多大程度上满足了用户的信息需求(正确性) ，2)它们是否产生了基于所提供的知识的响应(忠实性)。在人工评估和分析的指导下，我们强调了传统度量在正确性和忠实性方面的缺点。然后，我们提出了简单的基于令牌重叠和基于模型的度量标准，这些度量标准反映了这些模型的真实性能。我们的分析表明，指令跟踪模型是竞争性的，有时甚至在正确性方面优于微调模型。然而，这些模型很难坚持所提供的知识，并且经常在他们的反应中产生幻觉。我们希望我们的工作能够鼓励对质量保证(QA)的教学跟踪模式进行更全面的评估。我们的代码和数据可以在 https://github.com/mcgill-nlp/instruct-qa 找到"
    },
    {
        "title": "DoDo Learning: DOmain-DemOgraphic Transfer in Language Models for\n  Detecting Abuse Targeted at Public Figures",
        "url": "http://arxiv.org/abs/2307.16811v1",
        "pub_date": "2023-07-31",
        "summary": "Public figures receive a disproportionate amount of abuse on social media,\nimpacting their active participation in public life. Automated systems can\nidentify abuse at scale but labelling training data is expensive, complex and\npotentially harmful. So, it is desirable that systems are efficient and\ngeneralisable, handling both shared and specific aspects of online abuse. We\nexplore the dynamics of cross-group text classification in order to understand\nhow well classifiers trained on one domain or demographic can transfer to\nothers, with a view to building more generalisable abuse classifiers. We\nfine-tune language models to classify tweets targeted at public figures across\nDOmains (sport and politics) and DemOgraphics (women and men) using our novel\nDODO dataset, containing 28,000 labelled entries, split equally across four\ndomain-demographic pairs. We find that (i) small amounts of diverse data are\nhugely beneficial to generalisation and model adaptation; (ii) models transfer\nmore easily across demographics but models trained on cross-domain data are\nmore generalisable; (iii) some groups contribute more to generalisability than\nothers; and (iv) dataset similarity is a signal of transferability.",
        "translated": "公众人物在社交媒体上受到的虐待不成比例，影响了他们积极参与公共生活。自动化系统可以识别大规模的滥用，但是给培训数据贴标签是昂贵、复杂和潜在有害的。因此，我们希望系统是有效和普遍的，处理共享和具体方面的网上滥用。我们探讨了跨组文本分类的动态性，以了解在一个领域或人口统计学上受训的分类器如何能够转移到其他领域，以期建立更具普遍性的滥用分类器。我们使用我们的新型 DODO 数据集(包含28,000个标记条目)对语言模型进行微调，以分类针对不同领域(体育和政治)和人口统计学(女性和男性)的公众人物的推文，在四个领域-人口统计学对中平均分配。我们发现(i)少量不同的数据对于推广和模型适应非常有益; (ii)模型在人口统计学上更容易转移，但是在跨领域数据上训练的模型更容易推广; (iii)一些群体比其他群体对普遍性贡献更大; 和(iv)数据集相似性是可转移性的信号。"
    },
    {
        "title": "Structural Transfer Learning in NL-to-Bash Semantic Parsers",
        "url": "http://arxiv.org/abs/2307.16795v1",
        "pub_date": "2023-07-31",
        "summary": "Large-scale pre-training has made progress in many fields of natural language\nprocessing, though little is understood about the design of pre-training\ndatasets. We propose a methodology for obtaining a quantitative understanding\nof structural overlap between machine translation tasks. We apply our\nmethodology to the natural language to Bash semantic parsing task (NLBash) and\nshow that it is largely reducible to lexical alignment. We also find that there\nis strong structural overlap between NLBash and natural language to SQL.\nAdditionally, we perform a study varying compute expended during pre-training\non the English to German machine translation task and find that more compute\nexpended during pre-training does not always correspond semantic\nrepresentations with stronger transfer to NLBash.",
        "translated": "大规模的预训练已经在自然语言处理的许多领域取得了进展，尽管对预训练数据集的设计知之甚少。我们提出了一种方法来获得定量理解的结构重叠之间的机器翻译任务。我们将我们的方法应用于自然语言的 Bash 语义解析任务(NLBash) ，并表明它在很大程度上可以简化为词法对齐。我们还发现，NLBash 和 SQL 的自然语言之间存在很强的结构重叠。此外，我们对英语到德语机器翻译任务的预训练期间花费的不同计算进行了研究，发现预训练期间花费的更多计算并不总是与语义表示相对应，并且对 NLBash 的转换更强。"
    },
    {
        "title": "ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world\n  APIs",
        "url": "http://arxiv.org/abs/2307.16789v1",
        "pub_date": "2023-07-31",
        "summary": "Despite the advancements of open-source large language models (LLMs) and\ntheir variants, e.g., LLaMA and Vicuna, they remain significantly limited in\nperforming higher-level tasks, such as following human instructions to use\nexternal tools (APIs). This is because current instruction tuning largely\nfocuses on basic language tasks instead of the tool-use domain. This is in\ncontrast to state-of-the-art (SOTA) LLMs, e.g., ChatGPT, which have\ndemonstrated excellent tool-use capabilities but are unfortunately closed\nsource. To facilitate tool-use capabilities within open-source LLMs, we\nintroduce ToolLLM, a general tool-use framework of data construction, model\ntraining and evaluation. We first present ToolBench, an instruction-tuning\ndataset for tool use, which is created automatically using ChatGPT.\nSpecifically, we collect 16,464 real-world RESTful APIs spanning 49 categories\nfrom RapidAPI Hub, then prompt ChatGPT to generate diverse human instructions\ninvolving these APIs, covering both single-tool and multi-tool scenarios.\nFinally, we use ChatGPT to search for a valid solution path (chain of API\ncalls) for each instruction. To make the searching process more efficient, we\ndevelop a novel depth-first search-based decision tree (DFSDT), enabling LLMs\nto evaluate multiple reasoning traces and expand the search space. We show that\nDFSDT significantly enhances the planning and reasoning capabilities of LLMs.\nFor efficient tool-use assessment, we develop an automatic evaluator: ToolEval.\nWe fine-tune LLaMA on ToolBench and obtain ToolLLaMA. Our ToolEval reveals that\nToolLLaMA demonstrates a remarkable ability to execute complex instructions and\ngeneralize to unseen APIs, and exhibits comparable performance to ChatGPT. To\nmake the pipeline more practical, we devise a neural API retriever to recommend\nappropriate APIs for each instruction, negating the need for manual API\nselection.",
        "translated": "尽管开源大型语言模型(LLM)及其变体(例如 LLaMA 和 Vicuna)取得了进展，但它们在执行更高级别的任务(例如遵循人工指令使用外部工具(API))方面仍然受到显着限制。这是因为当前的指令调优主要集中在基本语言任务上，而不是工具使用领域。这与最先进的(SOTA) LLM 形成了对比，例如 ChatGPT，它已经展示了出色的工具使用能力，但不幸的是它是封闭源代码。为了促进开放源代码 LLM 中的工具使用能力，我们介绍了 ToolLLM，一个通用的数据构建、模型培训和评估的工具使用框架。我们首先介绍 ToolBench，这是一个用于工具使用的指令调优数据集，它是使用 ChatGPT 自动创建的。具体来说，我们从 RapidAPI Hub 收集了16,464个现实世界的 RESTful API，跨越49个类别，然后提示 ChatGPT 生成涉及这些 API 的各种人工指令，涵盖单工具和多工具场景。最后，我们使用 ChatGPT 为每条指令搜索有效的解决方案路径(API 调用链)。为了提高搜索效率，我们提出了一种新的基于深度优先搜索的决策树(DFSDT) ，使得 LLM 能够评估多个推理轨迹并扩展搜索空间。我们表明，DFSDT 显著提高了 LLM 的规划和推理能力。为了有效地进行工具使用评估，我们开发了一个自动评估器: ToolEval。在 ToolBench 上对 LLaMA 进行微调，得到 ToolLLaMA。我们的 ToolEval 表明，ToolLLaMA 显示了执行复杂指令和泛化为看不见的 API 的非凡能力，并且显示出与 ChatGPT 相当的性能。为了使管道更加实用，我们设计了一个神经 API 检索器，为每条指令推荐适当的 API，从而消除了手动选择 API 的需要。"
    },
    {
        "title": "KoBBQ: Korean Bias Benchmark for Question Answering",
        "url": "http://arxiv.org/abs/2307.16778v1",
        "pub_date": "2023-07-31",
        "summary": "The BBQ (Bias Benchmark for Question Answering) dataset enables the\nevaluation of the social biases that language models (LMs) exhibit in\ndownstream tasks. However, it is challenging to adapt BBQ to languages other\nthan English as social biases are culturally dependent. In this paper, we\ndevise a process to construct a non-English bias benchmark dataset by\nleveraging the English BBQ dataset in a culturally adaptive way and present the\nKoBBQ dataset for evaluating biases in Question Answering (QA) tasks in Korean.\nWe identify samples from BBQ into three classes: Simply-Translated (can be used\ndirectly after cultural translation), Target-Modified (requires localization in\ntarget groups), and Sample-Removed (does not fit Korean culture). We further\nenhance the cultural relevance to Korean culture by adding four new categories\nof bias specific to Korean culture and newly creating samples based on Korean\nliterature. KoBBQ consists of 246 templates and 4,740 samples across 12\ncategories of social bias. Using KoBBQ, we measure the accuracy and bias scores\nof several state-of-the-art multilingual LMs. We demonstrate the differences in\nthe bias of LMs in Korean and English, clarifying the need for hand-crafted\ndata considering cultural differences.",
        "translated": "BBQ (问题回答的偏见基准)数据集可以评估语言模型(LMs)在下游任务中表现出来的社会偏见。然而，由于社会偏见在文化上是相互依赖的，因此要使 BBQ 适应英语以外的语言是一个挑战。本文采用文化适应的方法构建了一个非英语偏倚基准数据集，并提出了韩语问答任务偏倚评估的 KoBBQ 数据集。我们将 BBQ 中的样本分为三类: 简单翻译(可以在文化翻译后直接使用)、目标修改(需要在目标群体中本地化)和样本删除(不适合韩国文化)。我们进一步加强了与韩国文化的文化相关性，增加了四类新的韩国文化特有的偏见，并在韩国文学的基础上创造了新的样本。KoBBQ 由246个模板和4740个样本组成，涉及12类社会偏见。使用 KoBBQ，我们测量了几种最先进的多语言 LM 的准确性和偏倚得分。我们展示了韩语和英语中 LMs 偏好的差异，阐明了考虑文化差异手工制作数据的必要性。"
    },
    {
        "title": "TimePool: Visually Answer \"Which and When\" Questions On Univariate Time\n  Series",
        "url": "http://arxiv.org/abs/2308.00682v1",
        "pub_date": "2023-08-01",
        "summary": "When exploring time series datasets, analysts often pose \"which and when\"\nquestions. For example, with world life expectancy data over one hundred years,\nthey may inquire about the top 10 countries in life expectancy and the time\nperiod when they achieved this status, or which countries have had longer life\nexpectancy than Ireland and when. This paper proposes TimePool, a new\nvisualization prototype, to address this need for univariate time series\nanalysis. It allows users to construct interactive \"which and when\" queries and\nvisually explore the results for insights.",
        "translated": "在研究时间序列数据集时，分析师经常提出“何时何地”的问题。例如，在世界预期寿命数据超过100年的情况下，他们可能会询问预期寿命最长的10个国家及其达到这一地位的时间，或哪些国家的预期寿命比爱尔兰长，以及何时达到这一地位。本文提出了一种新的可视化原型 TimePool，以满足单变量时间序列分析的需要。它允许用户构建交互式的“何时何地”查询，并可视化地探索结果以获得洞察力。"
    },
    {
        "title": "Explainable Graph Spectral Clustering of Text Documents",
        "url": "http://arxiv.org/abs/2308.00504v1",
        "pub_date": "2023-08-01",
        "summary": "Spectral clustering methods are known for their ability to represent clusters\nof diverse shapes, densities etc. However, results of such algorithms, when\napplied e.g. to text documents, are hard to explain to the user, especially due\nto embedding in the spectral space which has no obvious relation to document\ncontents. Therefore there is an urgent need to elaborate methods for explaining\nthe outcome of the clustering. This paper presents a contribution towards this\ngoal. We present a proposal of explanation of results of combinatorial\nLaplacian based graph spectral clustering. It is based on showing (approximate)\nequivalence of combinatorial Laplacian embedding, $K$-embedding (proposed in\nthis paper) and term vector space embedding. Hence a bridge is constructed\nbetween the textual contents and the clustering results. We provide theoretical\nbackground for this approach. We performed experimental study showing that\n$K$-embedding approximates well Laplacian embedding under favourable block\nmatrix conditions and show that approximation is good enough under other\nconditions.",
        "translated": "SVD 方法因其能够表示不同形状、密度等的集群而闻名。然而，当这些算法应用于文本文档时，特别是嵌入在与文档内容没有明显关系的谱空间中时，其结果很难向用户解释。因此，迫切需要阐明解释聚类结果的方法。本文为此目标做出了贡献。我们提出了一个解释组合拉普拉斯图 SVD 结果的建议。该算法基于组合拉普拉斯嵌入、 $K $嵌入(本文提出)和项向量空间嵌入的近似等价性。因此，在文本内容和聚类结果之间建立了一个桥梁。我们为这种方法提供了理论背景。实验研究表明，在有利的分块矩阵条件下，$K $嵌入能很好地逼近 Laplacian 嵌入，并且在其他条件下也能很好地逼近。"
    },
    {
        "title": "On the Effects of Regional Spelling Conventions in Retrieval Models",
        "url": "http://arxiv.org/abs/2308.00480v1",
        "pub_date": "2023-08-01",
        "summary": "One advantage of neural ranking models is that they are meant to generalise\nwell in situations of synonymity i.e. where two words have similar or identical\nmeanings. In this paper, we investigate and quantify how well various ranking\nmodels perform in a clear-cut case of synonymity: when words are simply\nexpressed in different surface forms due to regional differences in spelling\nconventions (e.g., color vs colour). We first explore the prevalence of\nAmerican and British English spelling conventions in datasets used for the\npre-training, training and evaluation of neural retrieval methods, and find\nthat American spelling conventions are far more prevalent. Despite these biases\nin the training data, we find that retrieval models often generalise well in\nthis case of synonymity. We explore the effect of document spelling\nnormalisation in retrieval and observe that all models are affected by\nnormalising the document's spelling. While they all experience a drop in\nperformance when normalised to a different spelling convention than that of the\nquery, we observe varied behaviour when the document is normalised to share the\nquery spelling convention: lexical models show improvements, dense retrievers\nremain unaffected, and re-rankers exhibit contradictory behaviour.",
        "translated": "神经排序模型的一个优点是，它们可以很好地概括同义词的情况，即两个词有相似或相同的意思。在本文中，我们调查和量化各种排名模型在一个明确的同义性情况下表现如何: 当单词只是表示在不同的表面形式，由于拼写惯例的区域差异(例如，颜色与颜色)。我们首先探讨了美国和英国英语拼写惯例在用于神经检索方法的预训练、培训和评估的数据集中的普遍性，发现美国的拼写惯例更为普遍。尽管在训练数据中存在这些偏差，我们发现在这种同义性的情况下，检索模型往往能够很好地推广。我们探讨了文档拼写规范化在检索中的作用，并观察到所有模型都受到文档拼写规范化的影响。虽然他们都经历了性能下降时，规范化的不同拼写约定比查询，我们观察到不同的行为时，文档规范化，共享查询拼写约定: 词汇模型显示改进，密集检索仍然没有受到影响，重新排序表现出矛盾的行为。"
    },
    {
        "title": "Generative Query Reformulation for Effective Adhoc Search",
        "url": "http://arxiv.org/abs/2308.00415v1",
        "pub_date": "2023-08-01",
        "summary": "Performing automatic reformulations of a user's query is a popular paradigm\nused in information retrieval (IR) for improving effectiveness -- as\nexemplified by the pseudo-relevance feedback approaches, which expand the query\nin order to alleviate the vocabulary mismatch problem. Recent advancements in\ngenerative language models have demonstrated their ability in generating\nresponses that are relevant to a given prompt. In light of this success, we\nseek to study the capacity of such models to perform query reformulation and\nhow they compare with long-standing query reformulation methods that use\npseudo-relevance feedback. In particular, we investigate two representative\nquery reformulation frameworks, GenQR and GenPRF. GenQR directly reformulates\nthe user's input query, while GenPRF provides additional context for the query\nby making use of pseudo-relevance feedback information. For each reformulation\nmethod, we leverage different techniques, including fine-tuning and direct\nprompting, to harness the knowledge of language models. The reformulated\nqueries produced by the generative models are demonstrated to markedly benefit\nthe effectiveness of a state-of-the-art retrieval pipeline on four TREC test\ncollections (varying from TREC 2004 Robust to the TREC 2019 Deep Learning).\nFurthermore, our results indicate that our studied generative models can\noutperform various statistical query expansion approaches while remaining\ncomparable to other existing complex neural query reformulation models, with\nthe added benefit of being simpler to implement.",
        "translated": "对用户的查询进行自动重新编排是信息检索(IR)中用来提高效率的一种流行的范例——例如伪相关反馈方法，它扩展查询以减轻词汇不匹配问题。生成语言模型的最新进展表明，它们能够生成与给定提示相关的响应。鉴于这一成功，我们试图研究这些模型执行查询重构的能力，以及它们如何与使用伪相关反馈的长期存在的查询重构方法进行比较。特别地，我们研究了两个有代表性的查询重构框架: GenQR 和 GenPRF。GenQR 直接重构用户的输入查询，而 GenPRF 通过利用伪相关反馈信息为查询提供额外的上下文。对于每种重新表述方法，我们利用不同的技术，包括微调和直接提示，来利用语言模型的知识。由生成模型产生的重新制定的查询被证明显着有益于四个 TREC 测试集合(从 TREC 2004 Robust 到 TREC 2019 Deep Learning)上的最先进的检索流水线的有效性。此外，我们的研究结果表明，我们研究的生成模型可以优于各种统计查询扩展方法，同时保持与其他现有的复杂神经查询重构模型的可比性，更简单的实现的好处。"
    },
    {
        "title": "Challenging the Myth of Graph Collaborative Filtering: a Reasoned and\n  Reproducibility-driven Analysis",
        "url": "http://arxiv.org/abs/2308.00404v1",
        "pub_date": "2023-08-01",
        "summary": "The success of graph neural network-based models (GNNs) has significantly\nadvanced recommender systems by effectively modeling users and items as a\nbipartite, undirected graph. However, many original graph-based works often\nadopt results from baseline papers without verifying their validity for the\nspecific configuration under analysis. Our work addresses this issue by\nfocusing on the replicability of results. We present a code that successfully\nreplicates results from six popular and recent graph recommendation models\n(NGCF, DGCF, LightGCN, SGL, UltraGCN, and GFCF) on three common benchmark\ndatasets (Gowalla, Yelp 2018, and Amazon Book). Additionally, we compare these\ngraph models with traditional collaborative filtering models that historically\nperformed well in offline evaluations. Furthermore, we extend our study to two\nnew datasets (Allrecipes and BookCrossing) that lack established setups in\nexisting literature. As the performance on these datasets differs from the\nprevious benchmarks, we analyze the impact of specific dataset characteristics\non recommendation accuracy. By investigating the information flow from users'\nneighborhoods, we aim to identify which models are influenced by intrinsic\nfeatures in the dataset structure. The code to reproduce our experiments is\navailable at: https://github.com/sisinflab/Graph-RSs-Reproducibility.",
        "translated": "基于图神经网络模型(GNN)的成功，通过有效地将用户和项目建模为一个二分的、无向的图，极大地提高了推荐系统的性能。然而，许多原始的基于图形的作品往往采用基线文件的结果，而不验证其有效性的具体配置分析。我们的工作通过关注结果的可复制性来解决这个问题。我们提供了一个代码，成功地在三个常见的基准数据集(Gowalla，Yelp 2018和 Amazon Book)上复制来自六个流行的和最近的图形推荐模型(NGCF，DGCF，LightGCN，SGL，UltraGCN 和 GFCF)的结果。此外，我们将这些图表模型与传统的协同过滤模型进行比较，传统的模型在离线评估中表现良好。此外，我们的研究扩展到两个新的数据集(所有食谱和图书交叉) ，缺乏现有文献中已建立的设置。由于这些数据集的性能不同于以前的基准测试，我们分析了特定数据集特征对推荐准确性的影响。通过研究来自用户邻域的信息流，我们的目标是识别哪些模型受到数据集结构内在特征的影响。重现我们实验的代码可以在以下 https://github.com/sisinflab/graph-rss-reproducibility 找到。"
    },
    {
        "title": "CodeBPE: Investigating Subtokenization Options for Large Language Model\n  Pretraining on Source Code",
        "url": "http://arxiv.org/abs/2308.00683v1",
        "pub_date": "2023-08-01",
        "summary": "Recent works have widely adopted large language model pretraining for source\ncode, suggested source code-specific pretraining objectives and investigated\nthe applicability of various Transformer-based language model architectures for\nsource code. This work investigates another important aspect of such models,\nnamely the effect of different subtokenization options, and aims at identifying\nmost effective and length-efficient subtokenizations, taking into account code\nspecifics. We propose subtokenziation that reduces average length by 17%\nwithout downstream performance drop, and show that a carefully chosen\nsubtokenization may improve quality by 0.5-2%, possibly with some length\nincrease.",
        "translated": "最近的工作已经广泛采用大语言模型对源代码进行预训练，提出了特定于源代码的预训练目标，并研究了各种基于 former 的语言模型体系结构对源代码的适用性。这项工作研究了这些模型的另一个重要方面，即不同子标记选项的影响，目的是确定最有效和长度效率的子标记，同时考虑到代码的特殊性。我们提出子标记化，减少了17% 的平均长度没有下游性能下降，并表明一个仔细选择的子标记化可以提高质量的0.5 -2% ，可能有一些长度增加。"
    },
    {
        "title": "Tool Documentation Enables Zero-Shot Tool-Usage with Large Language\n  Models",
        "url": "http://arxiv.org/abs/2308.00675v1",
        "pub_date": "2023-08-01",
        "summary": "Today, large language models (LLMs) are taught to use new tools by providing\na few demonstrations of the tool's usage. Unfortunately, demonstrations are\nhard to acquire, and can result in undesirable biased usage if the wrong\ndemonstration is chosen. Even in the rare scenario that demonstrations are\nreadily available, there is no principled selection protocol to determine how\nmany and which ones to provide. As tasks grow more complex, the selection\nsearch grows combinatorially and invariably becomes intractable. Our work\nprovides an alternative to demonstrations: tool documentation. We advocate the\nuse of tool documentation, descriptions for the individual tool usage, over\ndemonstrations. We substantiate our claim through three main empirical findings\non 6 tasks across both vision and language modalities. First, on existing\nbenchmarks, zero-shot prompts with only tool documentation are sufficient for\neliciting proper tool usage, achieving performance on par with few-shot\nprompts. Second, on a newly collected realistic tool-use dataset with hundreds\nof available tool APIs, we show that tool documentation is significantly more\nvaluable than demonstrations, with zero-shot documentation significantly\noutperforming few-shot without documentation. Third, we highlight the benefits\nof tool documentations by tackling image generation and video tracking using\njust-released unseen state-of-the-art models as tools. Finally, we highlight\nthe possibility of using tool documentation to automatically enable new\napplications: by using nothing more than the documentation of GroundingDino,\nStable Diffusion, XMem, and SAM, LLMs can re-invent the functionalities of the\njust-released Grounded-SAM and Track Anything models.",
        "translated": "今天，大型语言模型(LLM)通过提供一些工具使用示例来学习如何使用新工具。不幸的是，演示很难获得，如果选择了错误的演示，可能会导致不良的偏见使用。即使在演示可以随时获得的罕见情况下，也没有原则性的选择协议来确定要提供多少和哪些演示。随着任务变得更加复杂，选择搜索以组合方式增长，并且总是变得难以处理。我们的工作提供了演示的替代方案: 工具文档。我们提倡使用工具文档，对个别工具使用的描述，而不是演示。我们通过视觉和语言模式的6个任务的三个主要实证结果来证实我们的主张。首先，在现有的基准测试中，只有工具文档的零拍提示足以引出正确的工具使用，实现与少拍提示同等的性能。其次，在一个新收集的具有数百个可用工具 API 的现实工具使用数据集上，我们表明工具文档比演示更有价值，零拍文档的性能明显优于没有文档的少拍文档。第三，我们通过使用刚刚发布的看不见的最先进的模型作为工具来处理图像生成和视频跟踪，从而强调工具文档的好处。最后，我们强调了使用工具文档自动启用新应用程序的可能性: 通过仅仅使用 GroundingDino、稳定扩散、 XMem 和 SAM 的文档，LLM 可以重新发明刚刚发布的 GroundingSAM 和 Track Anything 模型的功能。"
    },
    {
        "title": "JIANG: Chinese Open Foundation Language Model",
        "url": "http://arxiv.org/abs/2308.00624v1",
        "pub_date": "2023-08-01",
        "summary": "With the advancements in large language model technology, it has showcased\ncapabilities that come close to those of human beings across various tasks.\nThis achievement has garnered significant interest from companies and\nscientific research institutions, leading to substantial investments in the\nresearch and development of these models. While numerous large models have\nemerged during this period, the majority of them have been trained primarily on\nEnglish data. Although they exhibit decent performance in other languages, such\nas Chinese, their potential remains limited due to factors like vocabulary\ndesign and training corpus. Consequently, their ability to fully express their\ncapabilities in Chinese falls short. To address this issue, we introduce the\nmodel named JIANG (Chinese pinyin of ginger) specifically designed for the\nChinese language. We have gathered a substantial amount of Chinese corpus to\ntrain the model and have also optimized its structure. The extensive\nexperimental results demonstrate the excellent performance of our model.",
        "translated": "随着大型语言模型技术的进步，它展示了在各种任务中接近人类的能力。这一成就引起了公司和科研机构的极大兴趣，导致对这些模型的研究和开发进行了大量投资。虽然在此期间出现了许多大型模型，但其中大多数主要是接受英文数据培训。虽然他们在汉语等其他语言中表现出色，但由于词汇设计和训练语料库等因素，他们的潜力仍然有限。因此，他们用汉语充分表达自己能力的能力不足。为了解决这个问题，我们介绍了专门为汉语设计的姜(汉语拼音)模型。我们收集了大量的中文语料对该模型进行训练，并对其结构进行了优化。广泛的实验结果表明，该模型具有良好的性能。"
    },
    {
        "title": "Unimodal Intermediate Training for Multimodal Meme Sentiment\n  Classification",
        "url": "http://arxiv.org/abs/2308.00528v1",
        "pub_date": "2023-08-01",
        "summary": "Internet Memes remain a challenging form of user-generated content for\nautomated sentiment classification. The availability of labelled memes is a\nbarrier to developing sentiment classifiers of multimodal memes. To address the\nshortage of labelled memes, we propose to supplement the training of a\nmultimodal meme classifier with unimodal (image-only and text-only) data. In\nthis work, we present a novel variant of supervised intermediate training that\nuses relatively abundant sentiment-labelled unimodal data. Our results show a\nstatistically significant performance improvement from the incorporation of\nunimodal text data. Furthermore, we show that the training set of labelled\nmemes can be reduced by 40% without reducing the performance of the downstream\nmodel.",
        "translated": "对于自动情绪分类来说，网络用户生成内容仍然是一种具有挑战性的形式。标记模因的可获得性是开发多模态模因情感分类器的一个障碍。为了解决标记模因的不足，我们建议用单模态(只有图像和文本)数据补充多模态模因分类器的训练。在这项工作中，我们提出了一个监督中间训练的新变种，使用相对丰富的情绪标记单峰数据。我们的研究结果显示，从统计学上来说，单模态文本数据的整合显著提高了性能。此外，我们表明，标记模因的训练集可以减少40% ，而不会降低下游模型的性能。"
    },
    {
        "title": "Retrieval Augmented Generation and Representative Vector Summarization\n  for large unstructured textual data in Medical Education",
        "url": "http://arxiv.org/abs/2308.00479v1",
        "pub_date": "2023-08-01",
        "summary": "Large Language Models are increasingly being used for various tasks including\ncontent generation and as chatbots. Despite their impressive performances in\ngeneral tasks, LLMs need to be aligned when applying for domain specific tasks\nto mitigate the problems of hallucination and producing harmful answers.\nRetrieval Augmented Generation (RAG) allows to easily attach and manipulate a\nnon-parametric knowledgebases to LLMs. Applications of RAG in the field of\nmedical education are discussed in this paper. A combined extractive and\nabstractive summarization method for large unstructured textual data using\nrepresentative vectors is proposed.",
        "translated": "大型语言模型越来越多地被用于各种任务，包括内容生成和聊天机器人。尽管 LLM 在一般任务中的表现令人印象深刻，但是在应用领域特定任务时需要调整 LLM，以减轻幻觉和产生有害答案的问题。检索增强生成(RAG)可以方便地将非参数知识库附加到 LLM，并对其进行操作。本文讨论了 RAG 在医学教育领域中的应用。针对大型非结构化文本数据，提出了一种基于代表向量的抽象与抽象相结合的文摘方法。"
    },
    {
        "title": "Structural Embeddings of Tools for Large Language Models",
        "url": "http://arxiv.org/abs/2308.00447v1",
        "pub_date": "2023-08-01",
        "summary": "It is evident that the current state of Large Language Models (LLMs)\nnecessitates the incorporation of external tools. The lack of straightforward\nalgebraic and logical reasoning is well documented and prompted researchers to\ndevelop frameworks which allow LLMs to operate via external tools. The\nontological nature of tool utilization for a specific task can be well\nformulated with a Directed Acyclic Graph (DAG). The central aim of the paper is\nto highlight the importance of graph based approaches to LLM-tool interaction\nin near future. We propose an exemplary framework to guide the orchestration of\nexponentially increasing numbers of external tools with LLMs,where objectives\nand functionalities of tools are graph encoded hierarchically. Assuming that\ntextual segments of a Chain-of-Thought (CoT) can be imagined as a tool as\ndefined here, the graph based framework can pave new avenues in that particular\ndirection as well.",
        "translated": "很明显，大型语言模型(LLM)的当前状态需要引入外部工具。缺乏简单的代数和逻辑推理已经被很好地记录下来，并促使研究人员开发出允许 LLM 通过外部工具进行操作的框架。特定任务工具使用的本体性可以用有向无环图(DAG)很好地描述。本文的主要目的是强调基于图的方法在近期内对 LLM 工具交互的重要性。我们提出了一个示例性的框架来指导指数级增长的外部工具与 LLM 的编排，其中工具的目标和功能是分层图形编码的。假设思维链(Chain-of-Thought，CoT)的文本片段可以想象为这里定义的工具，基于图的框架也可以为这个特定方向铺平新的道路。"
    },
    {
        "title": "SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step\n  Reasoning",
        "url": "http://arxiv.org/abs/2308.00436v2",
        "pub_date": "2023-08-01",
        "summary": "The recent progress in large language models (LLMs), especially the invention\nof chain-of-thoughts (CoT) prompting, makes it possible to solve reasoning\nproblems. However, even the strongest LLMs are still struggling with more\ncomplicated problems that require non-linear thinking and multi-step reasoning.\nIn this work, we explore whether LLMs have the ability to recognize their own\nerrors, without resorting to external resources. In particular, we investigate\nwhether they can be used to identify individual errors within a step-by-step\nreasoning. To this end, we propose a zero-shot verification scheme to recognize\nsuch errors. We then use this verification scheme to improve question-answering\nperformance, by using it to perform weighted voting on different generated\nanswers. We test the method on three math datasets-GSM8K, MathQA, and MATH-and\nfind that it successfully recognizes errors and, in turn, increases final\npredictive performance.",
        "translated": "大语言模型(LLM)的最新进展，特别是思维链(CoT)激励的发明，使得解决推理问题成为可能。然而，即使是最强大的 LLM 仍然挣扎在更复杂的问题，需要非线性思维和多步推理。在这项工作中，我们探讨 LLM 是否有能力识别自己的错误，而不依赖于外部资源。特别是，我们研究它们是否可以用来识别一个逐步推理中的个别错误。为此，我们提出了一种零拍验证方案来识别这类错误。然后我们使用这个验证方案来提高问答的性能，通过使用它对不同的生成的答案进行加权投票。我们在三个数学数据集-GSM8K，MathQA 和 MATH 上测试了该方法，发现它成功地识别了错误，进而提高了最终的预测性能。"
    },
    {
        "title": "Discourse-Aware Text Simplification: From Complex Sentences to Linked\n  Propositions",
        "url": "http://arxiv.org/abs/2308.00425v1",
        "pub_date": "2023-08-01",
        "summary": "Sentences that present a complex syntax act as a major stumbling block for\ndownstream Natural Language Processing applications whose predictive quality\ndeteriorates with sentence length and complexity. The task of Text\nSimplification (TS) may remedy this situation. It aims to modify sentences in\norder to make them easier to process, using a set of rewriting operations, such\nas reordering, deletion, or splitting. State-of-the-art syntactic TS approaches\nsuffer from two major drawbacks: first, they follow a very conservative\napproach in that they tend to retain the input rather than transforming it, and\nsecond, they ignore the cohesive nature of texts, where context spread across\nclauses or sentences is needed to infer the true meaning of a statement. To\naddress these problems, we present a discourse-aware TS approach that splits\nand rephrases complex English sentences within the semantic context in which\nthey occur. Based on a linguistically grounded transformation stage that uses\nclausal and phrasal disembedding mechanisms, complex sentences are transformed\ninto shorter utterances with a simple canonical structure that can be easily\nanalyzed by downstream applications. With sentence splitting, we thus address a\nTS task that has hardly been explored so far. Moreover, we introduce the notion\nof minimality in this context, as we aim to decompose source sentences into a\nset of self-contained minimal semantic units. To avoid breaking down the input\ninto a disjointed sequence of statements that is difficult to interpret because\nimportant contextual information is missing, we incorporate the semantic\ncontext between the split propositions in the form of hierarchical structures\nand semantic relationships. In that way, we generate a semantic hierarchy of\nminimal propositions that leads to a novel representation of complex assertions\nthat puts a semantic layer on top of the simplified sentences.",
        "translated": "呈现复杂句法的句子是下游自然语言处理应用程序的主要绊脚石，它的预测质量随着句子长度和复杂性而恶化。文本简化(TS)的任务可以纠正这种情况。它的目的是修改句子，使它们更容易处理，使用一套重写操作，如重新排序，删除，或拆分。最先进的句法 TS 方法有两个主要缺点: 第一，它们遵循一种非常保守的方法，因为它们倾向于保留输入而不是转换输入; 第二，它们忽视了文本的连贯性，在这种情况下，需要分布在各个分句或句子之间的上下文来推断一个陈述的真正含义。为了解决这些问题，我们提出了一种基于语篇感知的 TS 方法，该方法在复杂英语句子出现的语义上下文中对复杂句子进行拆分和重组。基于语言学基础上的转换阶段，使用分句和短语分解机制，复杂句被转换成具有简单规范结构的短句，可以方便地通过下游应用程序进行分析。通过句子分裂，我们解决了一个迄今为止几乎没有被探索过的 TS 任务。此外，我们还引入了极小性的概念，因为我们的目标是将源语句分解成一组自包含的极小语义单位。为了避免因为缺少重要的上下文信息而将输入分解成一系列不连贯的语句，我们以层次结构和语义关系的形式将语义上下文合并在分裂命题之间。通过这种方式，我们生成了一个最小命题的语义层次结构，这导致了复杂断言的一种新的表示方法，这种方法在简化的句子之上放置了一个语义层。"
    },
    {
        "title": "ZRIGF: An Innovative Multimodal Framework for Zero-Resource\n  Image-Grounded Dialogue Generation",
        "url": "http://arxiv.org/abs/2308.00400v2",
        "pub_date": "2023-08-01",
        "summary": "Image-grounded dialogue systems benefit greatly from integrating visual\ninformation, resulting in high-quality response generation. However, current\nmodels struggle to effectively utilize such information in zero-resource\nscenarios, mainly due to the disparity between image and text modalities. To\novercome this challenge, we propose an innovative multimodal framework, called\nZRIGF, which assimilates image-grounded information for dialogue generation in\nzero-resource situations. ZRIGF implements a two-stage learning strategy,\ncomprising contrastive pre-training and generative pre-training. Contrastive\npre-training includes a text-image matching module that maps images and texts\ninto a unified encoded vector space, along with a text-assisted masked image\nmodeling module that preserves pre-training visual features and fosters further\nmultimodal feature alignment. Generative pre-training employs a multimodal\nfusion module and an information transfer module to produce insightful\nresponses based on harmonized multimodal representations. Comprehensive\nexperiments conducted on both text-based and image-grounded dialogue datasets\ndemonstrate ZRIGF's efficacy in generating contextually pertinent and\ninformative responses. Furthermore, we adopt a fully zero-resource scenario in\nthe image-grounded dialogue dataset to demonstrate our framework's robust\ngeneralization capabilities in novel domains. The code is available at\nhttps://github.com/zhangbo-nlp/ZRIGF.",
        "translated": "基于图像的对话系统从整合视觉信息中获益匪浅，从而产生高质量的响应。然而，目前的模型很难有效地利用这些信息在零资源的情况下，主要是由于图像和文本模式之间的差异。为了克服这一挑战，我们提出了一个创新的多模式框架，称为 ZRIGF，它吸收图像为基础的对话生成信息在零资源的情况下。ZRIGF 实施两阶段学习策略，包括对比性预训练和生成性预训练。对比预训练包括文本-图像匹配模块，该模块将图像和文本映射到统一编码的向量空间，以及文本辅助掩蔽图像建模模块，该模块保留预训练的视觉特征，并促进进一步的多模态特征对齐。生成式预训练使用多模态融合模块和信息传递模块来产生基于协调多模态表示的有见地的响应。在基于文本和基于图像的对话数据集上进行的综合实验证明了 ZRIGF 在产生上下文相关和信息性反应方面的功效。此外，我们在基于图像的对话数据集中采用了一个完全零资源的场景来展示我们的框架在新领域中的鲁棒泛化能力。密码可在 https://github.com/zhangbo-nlp/zrigf 查阅。"
    },
    {
        "title": "Tackling Hallucinations in Neural Chart Summarization",
        "url": "http://arxiv.org/abs/2308.00399v1",
        "pub_date": "2023-08-01",
        "summary": "Hallucinations in text generation occur when the system produces text that is\nnot grounded in the input. In this work, we tackle the problem of\nhallucinations in neural chart summarization. Our analysis shows that the\ntarget side of chart summarization training datasets often contains additional\ninformation, leading to hallucinations. We propose a natural language inference\n(NLI) based method to preprocess the training data and show through human\nevaluation that our method significantly reduces hallucinations. We also found\nthat shortening long-distance dependencies in the input sequence and adding\nchart-related information like title and legends improves the overall\nperformance.",
        "translated": "当系统生成的文本没有接地于输入时，就会出现文本生成中的幻觉。在这项工作中，我们处理幻觉的问题，在神经图表摘要。我们的分析表明，图表总结训练数据集的目标侧往往包含额外的信息，导致幻觉。我们提出了一种基于自然语言推理(NLI)的训练数据预处理方法，并通过人工评估表明该方法显著减少了幻觉。我们还发现，缩短输入序列中的长距离依赖关系并添加与图表相关的信息，如标题和图例，可以提高整体性能。"
    },
    {
        "title": "Masked and Swapped Sequence Modeling for Next Novel Basket\n  Recommendation in Grocery Shopping",
        "url": "http://arxiv.org/abs/2308.01308v1",
        "pub_date": "2023-08-02",
        "summary": "Next basket recommendation (NBR) is the task of predicting the next set of\nitems based on a sequence of already purchased baskets. It is a recommendation\ntask that has been widely studied, especially in the context of grocery\nshopping. In next basket recommendation (NBR), it is useful to distinguish\nbetween repeat items, i.e., items that a user has consumed before, and explore\nitems, i.e., items that a user has not consumed before. Most NBR work either\nignores this distinction or focuses on repeat items. We formulate the next\nnovel basket recommendation (NNBR) task, i.e., the task of recommending a\nbasket that only consists of novel items, which is valuable for both real-world\napplication and NBR evaluation. We evaluate how existing NBR methods perform on\nthe NNBR task and find that, so far, limited progress has been made w.r.t. the\nNNBR task. To address the NNBR task, we propose a simple bi-directional\ntransformer basket recommendation model (BTBR), which is focused on directly\nmodeling item-to-item correlations within and across baskets instead of\nlearning complex basket representations. To properly train BTBR, we propose and\ninvestigate several masking strategies and training objectives: (i) item-level\nrandom masking, (ii) item-level select masking, (iii) basket-level all masking,\n(iv) basket-level explore masking, and (v) joint masking. In addition, an\nitem-basket swapping strategy is proposed to enrich the item interactions\nwithin the same baskets. We conduct extensive experiments on three open\ndatasets with various characteristics. The results demonstrate the\neffectiveness of BTBR and our masking and swapping strategies for the NNBR\ntask. BTBR with a properly selected masking and swapping strategy can\nsubstantially improve NNBR performance.",
        "translated": "下一个篮子推荐(NBR)是基于已购买篮子序列预测下一组项目的任务。这是一个被广泛研究的推荐任务，特别是在杂货店购物的背景下。在下一个购物篮推荐(NBR)中，区分重复项(即用户以前消费过的项)和探索项(即用户以前没有消费过的项)是有用的。大多数 NBR 工作要么忽略了这种区别，要么侧重于重复项。我们制定了下一个新颖的篮子推荐(NNBR)任务，即推荐一个只包含新颖项目的篮子，这对于实际应用和 NBR 评估都是有价值的。我们评估了现有的 NBR 方法对 NNBR 任务的执行情况，发现到目前为止，NNBR 任务的进展有限。为了解决 NNBR 任务，我们提出了一个简单的双向变压器篮子推荐模型(BTBR) ，该模型的重点是直接建模篮子内部和跨篮子的项目相关性，而不是学习复杂的篮子表示。为了正确训练 BTBR，我们提出并研究了几种掩蔽策略和训练目标: (i)项目级随机掩蔽，(ii)项目级选择掩蔽，(iii)篮子级全掩蔽，(iv)篮子级探索掩蔽和(v)联合掩蔽。此外，本文还提出了一种项目-篮子交换策略，以丰富同一篮子内的项目交互。我们在三个具有不同特征的开放数据集上进行了广泛的实验。实验结果证明了 BTBR 和我们的掩蔽和交换策略对 NNBR 任务的有效性。通过合理选择屏蔽和交换策略，BTBR 可以大大提高 NNBR 的性能。"
    },
    {
        "title": "A Survey on Popularity Bias in Recommender Systems",
        "url": "http://arxiv.org/abs/2308.01118v1",
        "pub_date": "2023-08-02",
        "summary": "Recommender systems help people find relevant content in a personalized way.\nOne main promise of such systems is that they are able to increase the\nvisibility of items in the long tail, i.e., the lesser-known items in a\ncatalogue. Existing research, however, suggests that in many situations today's\nrecommendation algorithms instead exhibit a popularity bias, meaning that they\noften focus on rather popular items in their recommendations. Such a bias may\nnot only lead to limited value of the recommendations for consumers and\nproviders in the short run, but it may also cause undesired reinforcement\neffects over time. In this paper, we discuss the potential reasons for\npopularity bias and we review existing approaches to detect, quantify and\nmitigate popularity bias in recommender systems. Our survey therefore includes\nboth an overview of the computational metrics used in the literature as well as\na review of the main technical approaches to reduce the bias. We furthermore\ncritically discuss today's literature, where we observe that the research is\nalmost entirely based on computational experiments and on certain assumptions\nregarding the practical effects of including long-tail items in the\nrecommendations.",
        "translated": "推荐系统帮助人们以个性化的方式找到相关内容。这种系统的一个主要前景是，它们能够增加长尾项目的可见性，即目录中不太为人所知的项目。然而，现有的研究表明，在许多情况下，今天的推荐算法反而表现出一种受欢迎程度的偏差，这意味着它们往往把重点放在推荐中相当受欢迎的项目上。这种偏见不仅可能在短期内导致建议对消费者和提供者的价值有限，而且还可能随着时间的推移造成不希望看到的强化效应。在本文中，我们讨论了流行偏差的潜在原因，我们回顾了现有的方法来检测，量化和减轻流行偏差的推荐系统。因此，我们的调查既包括文献中使用的计算指标的概述，也包括减少偏倚的主要技术方法的回顾。我们进一步批判性地讨论了当今的文献，在这些文献中，我们观察到研究几乎完全基于计算实验和关于在推荐中包含长尾项目的实际效果的某些假设。"
    },
    {
        "title": "Towards Better Query Classification with Multi-Expert Knowledge\n  Condensation in JD Ads Search",
        "url": "http://arxiv.org/abs/2308.01098v1",
        "pub_date": "2023-08-02",
        "summary": "Search query classification, as an effective way to understand user intents,\nis of great importance in real-world online ads systems. To ensure a lower\nlatency, a shallow model (e.g. FastText) is widely used for efficient online\ninference. However, the representation ability of the FastText model is\ninsufficient, resulting in poor classification performance, especially on some\nlow-frequency queries and tailed categories. Using a deeper and more complex\nmodel (e.g. BERT) is an effective solution, but it will cause a higher online\ninference latency and more expensive computing costs. Thus, how to juggle both\ninference efficiency and classification performance is obviously of great\npractical importance. To overcome this challenge, in this paper, we propose\nknowledge condensation (KC), a simple yet effective knowledge distillation\nframework to boost the classification performance of the online FastText model\nunder strict low latency constraints. Specifically, we propose to train an\noffline BERT model to retrieve more potentially relevant data. Benefiting from\nits powerful semantic representation, more relevant labels not exposed in the\nhistorical data will be added into the training set for better FastText model\ntraining. Moreover, a novel distribution-diverse multi-expert learning strategy\nis proposed to further improve the mining ability of relevant data. By training\nmultiple BERT models from different data distributions, it can respectively\nperform better at high, middle, and low-frequency search queries. The model\nensemble from multi-distribution makes its retrieval ability more powerful. We\nhave deployed two versions of this framework in JD search, and both offline\nexperiments and online A/B testing from multiple datasets have validated the\neffectiveness of the proposed approach.",
        "translated": "搜索查询分类作为理解用户意图的一种有效方法，在实际的网络广告系统中具有重要意义。为了确保较低的延迟，浅层模型(例如 FastText)被广泛用于高效的在线推理。然而，FastText 模型的表示能力不足，导致分类性能较差，特别是在一些低频查询和尾部分类上。使用更深入、更复杂的模型(例如 BERT)是一种有效的解决方案，但它会导致更高的在线推理延迟和更昂贵的计算成本。因此，如何兼顾推理效率和分类性能显然具有重要的现实意义。为了克服这一挑战，本文提出了一种简单而有效的知识提取框架——知识浓缩(KC) ，以提高在线快文本模型在严格的低延迟约束下的分类性能。具体来说，我们建议训练一个离线 BERT 模型来检索更多潜在的相关数据。得益于其强大的语义表示，历史数据中未公开的更多相关标签将被添加到训练集中，以便更好地进行 FastText 模型训练。此外，为了进一步提高相关数据的挖掘能力，提出了一种新的分布式多专家学习策略。通过训练来自不同数据分布的多个 BERT 模型，它可以分别在高、中、低频搜索查询中表现得更好。多分布的模型集成使其检索能力更加强大。我们已经在 JD 搜索中部署了该框架的两个版本，离线实验和来自多个数据集的在线 A/B 测试都验证了该方法的有效性。"
    },
    {
        "title": "Rethinking Similarity Search: Embracing Smarter Mechanisms over Smarter\n  Data",
        "url": "http://arxiv.org/abs/2308.00909v1",
        "pub_date": "2023-08-02",
        "summary": "In this vision paper, we propose a shift in perspective for improving the\neffectiveness of similarity search. Rather than focusing solely on enhancing\nthe data quality, particularly machine learning-generated embeddings, we\nadvocate for a more comprehensive approach that also enhances the underpinning\nsearch mechanisms. We highlight three novel avenues that call for a\nredefinition of the similarity search problem: exploiting implicit data\nstructures and distributions, engaging users in an iterative feedback loop, and\nmoving beyond a single query vector. These novel pathways have gained relevance\nin emerging applications such as large-scale language models, video clip\nretrieval, and data labeling. We discuss the corresponding research challenges\nposed by these new problem areas and share insights from our preliminary\ndiscoveries.",
        "translated": "在这份愿景文件中，我们建议转变观点，以提高最近邻搜索的有效性。我们不仅仅关注于提高数据质量，特别是机器学习产生的嵌入，我们提倡一种更加全面的方法，同时也增强了基础的搜索机制。我们重点介绍了三种需要重新定义最近邻搜索问题的新途径: 利用隐式数据结构和分布，让用户参与到迭代反馈循环中，以及超越单个查询向量。这些新颖的途径已经在新兴的应用中获得相关性，例如大规模的语言模型、视频剪辑检索和数据标记。我们讨论了这些新问题领域带来的相应研究挑战，并分享了我们的初步发现。"
    },
    {
        "title": "User-Controllable Recommendation via Counterfactual Retrospective and\n  Prospective Explanations",
        "url": "http://arxiv.org/abs/2308.00894v1",
        "pub_date": "2023-08-02",
        "summary": "Modern recommender systems utilize users' historical behaviors to generate\npersonalized recommendations. However, these systems often lack user\ncontrollability, leading to diminished user satisfaction and trust in the\nsystems. Acknowledging the recent advancements in explainable recommender\nsystems that enhance users' understanding of recommendation mechanisms, we\npropose leveraging these advancements to improve user controllability. In this\npaper, we present a user-controllable recommender system that seamlessly\nintegrates explainability and controllability within a unified framework. By\nproviding both retrospective and prospective explanations through\ncounterfactual reasoning, users can customize their control over the system by\ninteracting with these explanations.\n  Furthermore, we introduce and assess two attributes of controllability in\nrecommendation systems: the complexity of controllability and the accuracy of\ncontrollability. Experimental evaluations on MovieLens and Yelp datasets\nsubstantiate the effectiveness of our proposed framework. Additionally, our\nexperiments demonstrate that offering users control options can potentially\nenhance recommendation accuracy in the future. Source code and data are\navailable at \\url{https://github.com/chrisjtan/ucr}.",
        "translated": "现代推荐系统利用用户的历史行为来生成个性化的推荐。然而，这些系统往往缺乏用户可控性，导致用户对系统的满意度和信任度降低。鉴于可解释推荐系统的最新进展，增强了用户对推荐机制的理解，我们建议利用这些进展来提高用户的可控性。在本文中，我们提出了一个用户可控的推荐系统，它在一个统一的框架内无缝地整合了可解释性和可控性。通过反事实推理提供回顾性和前瞻性解释，用户可以通过与这些解释交互来定制他们对系统的控制。此外，我们还介绍和评估了推荐系统中可控性的两个属性: 可控性的复杂性和可控性的准确性。对 MovieLens 和 Yelp 数据集的实验评估证实了我们提出的框架的有效性。此外，我们的实验表明，提供用户控制选项可能会在未来提高推荐的准确性。源代码和数据可在 url { https://github.com/chrisjtan/ucr }获得。"
    },
    {
        "title": "More Context, Less Distraction: Visual Classification by Inferring and\n  Conditioning on Contextual Attributes",
        "url": "http://arxiv.org/abs/2308.01313v1",
        "pub_date": "2023-08-02",
        "summary": "CLIP, as a foundational vision language model, is widely used in zero-shot\nimage classification due to its ability to understand various visual concepts\nand natural language descriptions. However, how to fully leverage CLIP's\nunprecedented human-like understanding capabilities to achieve better zero-shot\nclassification is still an open question. This paper draws inspiration from the\nhuman visual perception process: a modern neuroscience view suggests that in\nclassifying an object, humans first infer its class-independent attributes\n(e.g., background and orientation) which help separate the foreground object\nfrom the background, and then make decisions based on this information.\nInspired by this, we observe that providing CLIP with contextual attributes\nimproves zero-shot classification and mitigates reliance on spurious features.\nWe also observe that CLIP itself can reasonably infer the attributes from an\nimage. With these observations, we propose a training-free, two-step zero-shot\nclassification method named PerceptionCLIP. Given an image, it first infers\ncontextual attributes (e.g., background) and then performs object\nclassification conditioning on them. Our experiments show that PerceptionCLIP\nachieves better generalization, group robustness, and better interpretability.\nFor example, PerceptionCLIP with ViT-L/14 improves the worst group accuracy by\n16.5% on the Waterbirds dataset and by 3.5% on CelebA.",
        "translated": "CLIP 作为一种基本的视觉语言模型，由于能够理解各种视觉概念和自然语言描述，因此被广泛地应用于零镜头图像分类中。然而，如何充分利用 CLIP 前所未有的类人理解能力来实现更好的零拍分类仍然是一个悬而未决的问题。这篇论文的灵感来自于人类的视知觉过程: 现代神经科学的观点认为，在对一个物体进行分类时，人类首先推断其独立于类别的属性(例如，背景和方向) ，这些属性有助于将前景物体从背景中分离出来，然后根据这些信息做出决策。受此启发，我们观察到为 CLIP 提供上下文属性可以改进零镜头分类并减少对伪特性的依赖。我们还观察到，CLIP 本身可以合理地从图像中推断出属性。根据这些观测结果，我们提出了一种无需训练的两步零拍分类方法 PerceptionCLIP。给定一个图像，它首先推断上下文属性(例如，背景) ，然后对它们执行对象分类条件。实验结果表明，感知 CLIP 具有更好的泛化能力、群体鲁棒性和更好的可解释性。例如，使用 ViT-L/14的 PerceptionCLIP 在 Waterbird 数据集上提高了最差的组准确率16.5% ，在 CelebA 上提高了3.5% 。"
    },
    {
        "title": "Fighting Fire with Fire: Can ChatGPT Detect AI-generated Text?",
        "url": "http://arxiv.org/abs/2308.01284v1",
        "pub_date": "2023-08-02",
        "summary": "Large language models (LLMs) such as ChatGPT are increasingly being used for\nvarious use cases, including text content generation at scale. Although\ndetection methods for such AI-generated text exist already, we investigate\nChatGPT's performance as a detector on such AI-generated text, inspired by\nworks that use ChatGPT as a data labeler or annotator. We evaluate the\nzero-shot performance of ChatGPT in the task of human-written vs. AI-generated\ntext detection, and perform experiments on publicly available datasets. We\nempirically investigate if ChatGPT is symmetrically effective in detecting\nAI-generated or human-written text. Our findings provide insight on how ChatGPT\nand similar LLMs may be leveraged in automated detection pipelines by simply\nfocusing on solving a specific aspect of the problem and deriving the rest from\nthat solution. All code and data is available at\n\\url{https://github.com/AmritaBh/ChatGPT-as-Detector}.",
        "translated": "诸如 ChatGPT 之类的大型语言模型(LLM)正越来越多地用于各种用例，包括大规模生成文本内容。虽然这种人工智能生成的文本的检测方法已经存在，但是受到使用 ChatGPT 作为数据标签器或注释器的作品的启发，我们研究了 ChatGPT 作为这种人工智能生成文本的检测器的性能。我们评估了 ChatGPT 在人工编写和人工智能生成文本检测任务中的零拍性能，并在公开可用的数据集上进行了实验。我们实证研究 ChatGPT 是否对称有效地检测人工智能生成或人写的文本。我们的研究结果提供了 ChatGPT 和类似 LLM 如何在自动检测流水线中被利用的洞察力，它们仅仅关注于解决问题的特定方面，并从该解决方案中获得其余部分。所有代码和数据都可以在 url { https://github.com/amritabh/chatgpt-as-detector }获得。"
    },
    {
        "title": "Exploring the psychology of GPT-4's Moral and Legal Reasoning",
        "url": "http://arxiv.org/abs/2308.01264v1",
        "pub_date": "2023-08-02",
        "summary": "Large language models have been used as the foundation of highly\nsophisticated artificial intelligences, capable of delivering human-like\nresponses to probes about legal and moral issues. However, these models are\nunreliable guides to their own inner workings, and even the engineering teams\nbehind their creation are unable to explain exactly how they came to develop\nall of the capabilities they currently have. The emerging field of machine\npsychology seeks to gain insight into the processes and concepts that these\nmodels possess. In this paper, we employ the methods of psychology to probe\ninto GPT-4's moral and legal reasoning. More specifically, we investigate the\nsimilarities and differences between GPT-4 and humans when it comes to\nintentionality ascriptions, judgments about causation, the morality of\ndeception, moral foundations, the impact of moral luck on legal judgments, the\nconcept of consent, and rule violation judgments. We find high correlations\nbetween human and AI responses, but also several significant systematic\ndifferences between them. We conclude with a discussion of the philosophical\nimplications of our findings.",
        "translated": "大型语言模型已被用作高度复杂的人工智能的基础，能够对法律和道德问题的探讨做出类似人类的反应。然而，这些模型对于它们自己的内部工作方式是不可靠的指导，甚至它们创建背后的工程团队也无法准确地解释它们是如何开发出目前所拥有的所有功能的。机器心理学的新兴领域试图深入了解这些模型所拥有的过程和概念。本文运用心理学的方法对 GPT-4的道德法律推理进行了探讨。更具体地说，我们调查了 GPT-4和人类在意向性归因、因果关系判断、欺骗的道德、道德基础、道德运气对法律判断的影响、同意的概念和违反规则的判断等方面的相似性和差异性。我们发现人类和 AI 反应之间有很高的相关性，但是它们之间也有一些显著的系统差异。最后，我们讨论一下我们发现的哲学意义。"
    },
    {
        "title": "XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in\n  Large Language Models",
        "url": "http://arxiv.org/abs/2308.01263v1",
        "pub_date": "2023-08-02",
        "summary": "Without proper safeguards, large language models will readily follow\nmalicious instructions and generate toxic content. This motivates safety\nefforts such as red-teaming and large-scale feedback learning, which aim to\nmake models both helpful and harmless. However, there is a tension between\nthese two objectives, since harmlessness requires models to refuse complying\nwith unsafe prompts, and thus not be helpful. Recent anecdotal evidence\nsuggests that some models may have struck a poor balance, so that even clearly\nsafe prompts are refused if they use similar language to unsafe prompts or\nmention sensitive topics. In this paper, we introduce a new test suite called\nXSTest to identify such eXaggerated Safety behaviours in a structured and\nsystematic way. In its current form, XSTest comprises 200 safe prompts across\nten prompt types that well-calibrated models should not refuse to comply with.\nWe describe XSTest's creation and composition, and use the test suite to\nhighlight systematic failure modes in a recently-released state-of-the-art\nlanguage model.",
        "translated": "如果没有适当的保护措施，大型语言模型将很容易遵循恶意指令并生成有毒内容。这促进了安全工作，如红色团队和大规模反馈学习，其目的是使模型既有益又无害。然而，这两个目标之间有一种紧张关系，因为无害性要求模型拒绝服从不安全的提示，因此没有帮助。最近的轶事证据表明，一些模型可能没有达到平衡，因此，即使是明显安全的提示，如果使用与不安全提示相似的语言或提到敏感话题，也会被拒绝。在本文中，我们引入了一个新的测试套件，称为 XSTest，以识别这种夸大的安全行为在一个结构化和系统化的方式。在目前的形式下，XSTest 包括10个提示类型的200个安全提示，经过良好校准的模型不应该拒绝遵守。我们描述了 XSTest 的创建和组成，并使用测试套件在最近发布的最先进的语言模型中突出显示系统故障模式。"
    },
    {
        "title": "Evaluating Instruction-Tuned Large Language Models on Code Comprehension\n  and Generation",
        "url": "http://arxiv.org/abs/2308.01240v1",
        "pub_date": "2023-08-02",
        "summary": "In this work, we evaluate 10 open-source instructed LLMs on four\nrepresentative code comprehension and generation tasks. We have the following\nmain findings. First, for the zero-shot setting, instructed LLMs are very\ncompetitive on code comprehension and generation tasks and sometimes even\nbetter than small SOTA models specifically fine-tuned on each downstream task.\nWe also find that larger instructed LLMs are not always better on code-related\ntasks. Second, for the few-shot setting, we find that adding demonstration\nexamples substantially helps instructed LLMs perform better on most code\ncomprehension and generation tasks; however, the examples would sometimes\ninduce unstable or even worse performance. Furthermore, we find widely-used\nBM25-based shot selection strategy significantly outperforms the basic random\nselection or fixed selection only on generation problems. Third, for the\nfine-tuning setting, we find that fine-tuning could further improve the model\nperformance on downstream code comprehension and generation tasks compared to\nthe zero-shot/one-shot performance. In addition, after being fine-tuned on the\nsame downstream task dataset, instructed LLMs outperform both the small SOTA\nmodels and similar-scaled LLMs without instruction tuning. Based on our\nfindings, we further present practical implications on model and usage\nrecommendation, performance and cost trade-offs, and future direction.",
        "translated": "在这项工作中，我们评估了10个开源指导 LLM 在四个代表性的代码理解和生成任务。我们有以下主要发现。首先，对于零拍设置，指示 LLM 在代码理解和生成任务方面非常具有竞争力，有时甚至优于针对每个下游任务进行微调的小型 SOTA 模型。我们还发现，在代码相关的任务中，较大的指令 LLM 并不总是更好。其次，对于少数镜头设置，我们发现添加演示示例大大有助于指导 LLM 在大多数代码理解和生成任务中执行得更好; 然而，示例有时会导致性能不稳定甚至更差。此外，我们发现广泛使用的基于 BM25的镜头选择策略仅在生成问题上明显优于基本随机选择或固定选择。第三，对于微调设置，我们发现与0-shot/one-shot 性能相比，微调可以进一步改善下游代码理解和生成任务的模型性能。此外，在相同的下游任务数据集上进行了微调之后，指令 LLM 的表现优于小型 SOTA 模型和无指令微调的类似尺度 LLM。基于我们的发现，我们进一步提出了模型和使用建议、性能和成本权衡以及未来发展方向的实际意义。"
    },
    {
        "title": "Grounded Image Text Matching with Mismatched Relation Reasoning",
        "url": "http://arxiv.org/abs/2308.01236v1",
        "pub_date": "2023-08-02",
        "summary": "This paper introduces Grounded Image Text Matching with Mismatched Relation\n(GITM-MR), a novel visual-linguistic joint task that evaluates the relation\nunderstanding capabilities of transformer-based pre-trained models. GITM-MR\nrequires a model to first determine if an expression describes an image, then\nlocalize referred objects or ground the mismatched parts of the text. We\nprovide a benchmark for evaluating pre-trained models on this task, with a\nfocus on the challenging settings of limited data and out-of-distribution\nsentence lengths. Our evaluation demonstrates that pre-trained models lack data\nefficiency and length generalization ability. To address this, we propose the\nRelation-sensitive Correspondence Reasoning Network (RCRN), which incorporates\nrelation-aware reasoning via bi-directional message propagation guided by\nlanguage structure. RCRN can be interpreted as a modular program and delivers\nstrong performance in both length generalization and data efficiency.",
        "translated": "本文介绍了基于不匹配关系的接地图像文本匹配(GITM-MR) ，这是一种新颖的视觉语言联合任务，用于评估基于变压器的预训练模型的关系理解能力。GITM-MR 需要一个模型来首先确定一个表达式是否描述了一个图像，然后定位引用的对象或者接地文本中不匹配的部分。我们提供了一个基准来评估预先训练的模型在这项任务，重点是有限的数据和超出分布的句子长度的具有挑战性的设置。我们的评估表明，预训练模型缺乏数据效率和长度泛化能力。为了解决这个问题，我们提出了关系敏感的通信推理网络(RCRN) ，它通过语言结构引导的双向消息传播，结合了关系敏感的推理。RCRN 可以解释为一个模块化的程序，并提供强大的性能在长度泛化和数据效率。"
    },
    {
        "title": "Do Multilingual Language Models Think Better in English?",
        "url": "http://arxiv.org/abs/2308.01223v1",
        "pub_date": "2023-08-02",
        "summary": "Translate-test is a popular technique to improve the performance of\nmultilingual language models. This approach works by translating the input into\nEnglish using an external machine translation system, and running inference\nover the translated input. However, these improvements can be attributed to the\nuse of a separate translation system, which is typically trained on large\namounts of parallel data not seen by the language model. In this work, we\nintroduce a new approach called self-translate, which overcomes the need of an\nexternal translation system by leveraging the few-shot translation capabilities\nof multilingual language models. Experiments over 5 tasks show that\nself-translate consistently outperforms direct inference, demonstrating that\nlanguage models are unable to leverage their full multilingual potential when\nprompted in non-English languages. Our code is available at\nhttps://github.com/juletx/self-translate.",
        "translated": "翻译测试是提高多语言模型性能的一种常用技术。这种方法通过使用外部机器翻译系统将输入翻译成英语，并对翻译后的输入进行推理。然而，这些改进可归因于使用了一个单独的翻译系统，该系统通常使用语言模型没有看到的大量并行数据进行培训。在这项工作中，我们介绍了一种新的方法称为自译，它克服了外部翻译系统的需要，利用多语言模型的几个镜头的翻译能力。实验结果表明，自我翻译的表现一致优于直接推理，表明语言模型不能充分发挥其多语言潜力时，提示在非英语语言。我们的代码可以在 https://github.com/juletx/self-translate 找到。"
    },
    {
        "title": "Global Hierarchical Neural Networks using Hierarchical Softmax",
        "url": "http://arxiv.org/abs/2308.01210v1",
        "pub_date": "2023-08-02",
        "summary": "This paper presents a framework in which hierarchical softmax is used to\ncreate a global hierarchical classifier. The approach is applicable for any\nclassification task where there is a natural hierarchy among classes. We show\nempirical results on four text classification datasets. In all datasets the\nhierarchical softmax improved on the regular softmax used in a flat classifier\nin terms of macro-F1 and macro-recall. In three out of four datasets\nhierarchical softmax achieved a higher micro-accuracy and macro-precision.",
        "translated": "本文提出了一种利用层次软件 max 构造全局层次分类器的框架。该方法适用于类之间存在自然层次结构的任何分类任务。我们给出了四个文本分类数据集的实证结果。在所有的数据集中，分层软极大值在宏 F1和宏召回方面都比平面分类器中使用的正则软极大值有所改进。在四个数据集中有三个数据集的分层软件 max 实现了更高的微观精度和宏观精度。"
    },
    {
        "title": "Arithmetic with Language Models: from Memorization to Computation",
        "url": "http://arxiv.org/abs/2308.01154v1",
        "pub_date": "2023-08-02",
        "summary": "A better understanding of the emergent computation and problem-solving\ncapabilities of recent large language models is of paramount importance to\nfurther improve them and broaden their applicability. This work investigates\nhow a language model, trained to predict the next token, can perform arithmetic\ncomputations generalizing beyond training data. Binary addition and\nmultiplication constitute a good testbed for this purpose, since they require a\nvery small vocabulary and exhibit relevant input/output discontinuities making\nsmooth input interpolation ineffective for novel data. We successfully trained\na light language model to learn these tasks and ran a number of experiments to\ninvestigate the extrapolation capabilities and internal information processing.\nOur findings support the hypotheses that the language model works as an\nEncoding-Regression-Decoding machine where the computation takes place in the\nvalue space once the input token representation is mapped to an appropriate\ninternal representation.",
        "translated": "更好地理解当前大型语言模型的紧急计算和问题解决能力对于进一步改进和扩大其适用性至关重要。这项工作研究了一个语言模型，训练预测下一个标记，可以执行算术计算一般超越训练数据。二进制加法和乘法是这方面的一个很好的试验平台，因为它们需要非常小的词汇量，并且表现出相关的输入/输出不连续性，使得平滑的输入插值对新数据无效。我们成功地训练了一个轻语言模型来学习这些任务，并进行了大量的实验来研究外推能力和内部信息处理。我们的研究结果支持这样的假设，即语言模型作为一个编码-回归-解码机工作，一旦输入令牌表示映射到适当的内部表示，计算就在值空间中进行。"
    },
    {
        "title": "ADS-Cap: A Framework for Accurate and Diverse Stylized Captioning with\n  Unpaired Stylistic Corpora",
        "url": "http://arxiv.org/abs/2308.01143v1",
        "pub_date": "2023-08-02",
        "summary": "Generating visually grounded image captions with specific linguistic styles\nusing unpaired stylistic corpora is a challenging task, especially since we\nexpect stylized captions with a wide variety of stylistic patterns. In this\npaper, we propose a novel framework to generate Accurate and Diverse Stylized\nCaptions (ADS-Cap). Our ADS-Cap first uses a contrastive learning module to\nalign the image and text features, which unifies paired factual and unpaired\nstylistic corpora during the training process. A conditional variational\nauto-encoder is then used to automatically memorize diverse stylistic patterns\nin latent space and enhance diversity through sampling. We also design a simple\nbut effective recheck module to boost style accuracy by filtering\nstyle-specific captions. Experimental results on two widely used stylized image\ncaptioning datasets show that regarding consistency with the image, style\naccuracy and diversity, ADS-Cap achieves outstanding performances compared to\nvarious baselines. We finally conduct extensive analyses to understand the\neffectiveness of our method. Our code is available at\nhttps://github.com/njucckevin/ADS-Cap.",
        "translated": "使用不成对的文体语料库生成具有特定语言风格的视觉接地的图像标题是一项具有挑战性的任务，尤其是因为我们期望具有多种文体模式的程式化标题。在本文中，我们提出了一个新的框架来生成准确和多样化的风格化字幕(ADS-Cap)。我们的 ADS-Cap 首先使用对比学习模块来校准图像和文本特征，在训练过程中统一了成对的事实和不成对的风格语料库。然后使用条件变分自动编码器自动记忆潜在空间中不同的文体模式，并通过采样增强多样性。我们还设计了一个简单而有效的复查模块，通过过滤特定风格的标题来提高风格的准确性。实验结果表明，在与图像的一致性、风格的准确性和多样性方面，ADS-Cap 与各种基线相比，具有优异的性能。最后，我们进行了广泛的分析，以了解我们的方法的有效性。我们的代码可以在 https://github.com/njucckevin/ads-cap 找到。"
    },
    {
        "title": "MAP: A Model-agnostic Pretraining Framework for Click-through Rate\n  Prediction",
        "url": "http://arxiv.org/abs/2308.01737v1",
        "pub_date": "2023-08-03",
        "summary": "With the widespread application of personalized online services,\nclick-through rate (CTR) prediction has received more and more attention and\nresearch. The most prominent features of CTR prediction are its multi-field\ncategorical data format, and vast and daily-growing data volume. The large\ncapacity of neural models helps digest such massive amounts of data under the\nsupervised learning paradigm, yet they fail to utilize the substantial data to\nits full potential, since the 1-bit click signal is not sufficient to guide the\nmodel to learn capable representations of features and instances. The\nself-supervised learning paradigm provides a more promising pretrain-finetune\nsolution to better exploit the large amount of user click logs, and learn more\ngeneralized and effective representations. However, self-supervised learning\nfor CTR prediction is still an open question, since current works on this line\nare only preliminary and rudimentary. To this end, we propose a Model-agnostic\npretraining (MAP) framework that applies feature corruption and recovery on\nmulti-field categorical data, and more specifically, we derive two practical\nalgorithms: masked feature prediction (MFP) and replaced feature detection\n(RFD). MFP digs into feature interactions within each instance through masking\nand predicting a small portion of input features, and introduces noise\ncontrastive estimation (NCE) to handle large feature spaces. RFD further turns\nMFP into a binary classification mode through replacing and detecting changes\nin input features, making it even simpler and more effective for CTR\npretraining. Our extensive experiments on two real-world large-scale datasets\n(i.e., Avazu, Criteo) demonstrate the advantages of these two methods on\nseveral strong backbones (e.g., DCNv2, DeepFM), and achieve new\nstate-of-the-art performance in terms of both effectiveness and efficiency for\nCTR prediction.",
        "translated": "随着个性化网上服务的广泛应用，点进率预测越来越受到重视和研究。CTR 预测最突出的特点是它的多领域分类数据格式，以及海量和日益增长的数据量。神经模型的巨大容量有助于在监督式学习范式下消化如此大量的数据，但它们未能充分利用大量的数据，因为1位点击信号不足以指导模型学习特征和实例的能力表示。自监督学习范式为更好地利用大量的用户点击日志，学习更广泛、更有效的表示提供了一种更有前途的预训练-微调解决方案。然而，自我监督学习的 CTR 预测仍然是一个悬而未决的问题，因为目前在这方面的工作只是初步的和初步的。为此，我们提出了一个模型无关预训练(model-agnotic pretraining，MAP)框架，该框架将特征损坏和恢复应用于多领域分类数据，更具体地说，我们推导出两种实用算法: 掩盖特征预测(mFP)和替换特征提取(RFD)。MFP 通过屏蔽和预测一小部分输入特征，深入挖掘每个实例中的特征交互，并引入噪声对比估计(NCE)来处理较大的特征空间。RFD 通过替换和检测输入特征的变化，进一步将 MFP 转化为二进制分类模式，使 CTR 预训练更加简单有效。我们在两个真实世界的大规模数据集(例如，Avazu，Criteo)上的广泛实验证明了这两种方法在几个强骨干(例如，dCNv2，DeepFM)上的优势，并在有效性和效率方面实现了新的最先进的 CTR 预测性能。"
    },
    {
        "title": "Evaluating ChatGPT text-mining of clinical records for obesity\n  monitoring",
        "url": "http://arxiv.org/abs/2308.01666v1",
        "pub_date": "2023-08-03",
        "summary": "Background: Veterinary clinical narratives remain a largely untapped resource\nfor addressing complex diseases. Here we compare the ability of a large\nlanguage model (ChatGPT) and a previously developed regular expression (RegexT)\nto identify overweight body condition scores (BCS) in veterinary narratives.\nMethods: BCS values were extracted from 4,415 anonymised clinical narratives\nusing either RegexT or by appending the narrative to a prompt sent to ChatGPT\ncoercing the model to return the BCS information. Data were manually reviewed\nfor comparison. Results: The precision of RegexT was higher (100%, 95% CI\n94.81-100%) than the ChatGPT (89.3%; 95% CI82.75-93.64%). However, the recall\nof ChatGPT (100%. 95% CI 96.18-100%) was considerably higher than that of\nRegexT (72.6%, 95% CI 63.92-79.94%). Limitations: Subtle prompt engineering is\nneeded to improve ChatGPT output. Conclusions: Large language models create\ndiverse opportunities and, whilst complex, present an intuitive interface to\ninformation but require careful implementation to avoid unpredictable errors.",
        "translated": "背景: 兽医临床说明仍然是一个很大程度上尚未开发的资源，以解决复杂的疾病。在这里，我们比较了大型语言模型(ChatGPT)和以前开发的正则表达式(RegexT)在兽医叙述中识别超重身体状况评分(BCS)的能力。方法: 使用 RegexT 或通过将叙述附加到强制模型返回 BCS 信息的 ChatGPT 提示中，从4,415个匿名临床叙述中提取 BCS 值。数据进行人工审查以进行比较。结果: RegexT 的精密度(100% ，95% CI 94.81-100%)高于 ChatGPT (89.3% ，95% CI 82.75-93.64%)。然而，回收 ChatGPT (100% 。95% CI 96.18-100% 显著高于 RegexT (72.6% ，95% CI 63.92-79.94%)。限制: 需要微妙的提示工程来提高 ChatGPT 的输出。结论: 大型语言模型创建了多种多样的机会，虽然复杂，但是提供了直观的信息接口，但是需要仔细的实现以避免不可预测的错误。"
    },
    {
        "title": "Fast Slate Policy Optimization: Going Beyond Plackett-Luce",
        "url": "http://arxiv.org/abs/2308.01566v1",
        "pub_date": "2023-08-03",
        "summary": "An increasingly important building block of large scale machine learning\nsystems is based on returning slates; an ordered lists of items given a query.\nApplications of this technology include: search, information retrieval and\nrecommender systems. When the action space is large, decision systems are\nrestricted to a particular structure to complete online queries quickly. This\npaper addresses the optimization of these large scale decision systems given an\narbitrary reward function. We cast this learning problem in a policy\noptimization framework and propose a new class of policies, born from a novel\nrelaxation of decision functions. This results in a simple, yet efficient\nlearning algorithm that scales to massive action spaces. We compare our method\nto the commonly adopted Plackett-Luce policy class and demonstrate the\neffectiveness of our approach on problems with action space sizes in the order\nof millions.",
        "translated": "大规模机器学习系统的一个越来越重要的组成部分是基于返回板岩; 给定查询的项目的有序列表。这项技术的应用包括: 搜索、信息检索和推荐系统。当操作空间较大时，为了快速完成在线查询，决策系统被限制在一个特定的结构中。本文研究了给定任意报酬函数的大规模决策系统的优化问题。我们把这个学习问题放在一个策略优化框架中，提出了一类新的策略，它是由一种新的松弛决策函数产生的。这导致了一个简单而有效的学习算法，可以扩展到大量的操作空间。我们将我们的方法与普遍采用的 Plackett-Luce 策略类进行了比较，并证明了我们的方法在处理动作空间大小为百万的问题时的有效性。"
    },
    {
        "title": "Density Weighting for Multi-Interest Personalized Recommendation",
        "url": "http://arxiv.org/abs/2308.01563v1",
        "pub_date": "2023-08-03",
        "summary": "Using multiple user representations (MUR) to model user behavior instead of a\nsingle user representation (SUR) has been shown to improve personalization in\nrecommendation systems. However, the performance gains observed with MUR can be\nsensitive to the skewness in the item and/or user interest distribution. When\nthe data distribution is highly skewed, the gains observed by learning multiple\nrepresentations diminish since the model dominates on head items/interests,\nleading to poor performance on tail items. Robustness to data sparsity is\ntherefore essential for MUR-based approaches to achieve good performance for\nrecommendations. Yet, research in MUR and data imbalance have largely been done\nindependently. In this paper, we delve deeper into the shortcomings of MUR\ninferred from imbalanced data distributions. We make several contributions: (1)\nUsing synthetic datasets, we demonstrate the sensitivity of MUR with respect to\ndata imbalance, (2) To improve MUR for tail items, we propose an iterative\ndensity weighting scheme (IDW) with user tower calibration to mitigate the\neffect of training over long-tail distribution on personalization, and (3)\nThrough extensive experiments on three real-world benchmarks, we demonstrate\nIDW outperforms other alternatives that address data imbalance.",
        "translated": "使用多用户表示(MUR)代替单用户表示(SUR)来模拟用户行为已被证明可以改善推荐系统中的个性化。然而，使用 MUR 观察到的性能提升可能对项目和/或用户兴趣分布的偏差敏感。当数据分布高度倾斜时，由于模型主导头项/兴趣，学习多个表示所观察到的增益减小，导致尾项性能差。因此，对于基于 MUR 的方法来说，数据稀疏性的健壮性对于实现良好的建议性能至关重要。然而，MUR 和数据不平衡的研究在很大程度上是独立完成的。在本文中，我们深入研究了不平衡数据分布推断出的 MUR 的缺点。我们做出了以下贡献: (1)使用合成数据集，我们证明了 MUR 对数据不平衡的敏感性; (2)为了改善尾部项目的 MUR，我们提出了一种迭代密度加权方案(IDW) ，通过用户塔校准来减轻训练对长尾分布对个性化的影响; (3)通过对三个现实世界基准的广泛实验，我们证明了 IDW 优于其他解决数据不平衡的方案。"
    },
    {
        "title": "Reasoning in Large Language Models Through Symbolic Math Word Problems",
        "url": "http://arxiv.org/abs/2308.01906v1",
        "pub_date": "2023-08-03",
        "summary": "Large language models (LLMs) have revolutionized NLP by solving downstream\ntasks with little to no labeled data. Despite their versatile abilities, the\nlarger question of their ability to reason remains ill-understood. This paper\naddresses reasoning in math word problems (MWPs) by studying symbolic versions\nof the numeric problems, since a symbolic expression is a \"concise explanation\"\nof the numeric answer. We create and use a symbolic version of the SVAMP\ndataset and find that GPT-3's davinci-002 model also has good zero-shot\naccuracy on symbolic MWPs. To evaluate the faithfulness of the model's\nreasoning, we go beyond accuracy and additionally evaluate the alignment\nbetween the final answer and the outputted reasoning, which correspond to\nnumeric and symbolic answers respectively for MWPs. We explore a self-prompting\napproach to encourage the symbolic reasoning to align with the numeric answer,\nthus equipping the LLM with the ability to provide a concise and verifiable\nreasoning and making it more interpretable. Surprisingly, self-prompting also\nimproves the symbolic accuracy to be higher than both the numeric and symbolic\naccuracies, thus providing an ensembling effect. The SVAMP_Sym dataset will be\nreleased for future research on symbolic math problems.",
        "translated": "大语言模型(LLM)通过解决几乎没有标记数据的下游任务，彻底改变了自然语言处理(NLP)。尽管他们拥有多才多艺的能力，但他们理性思考的能力这个更大的问题仍然没有得到充分的理解。本文通过研究数字问题的符号化形式来解决数字问题中的推理问题，因为符号表达式是对数字答案的“简明解释”。我们创建并使用了一个 SVAMP 数据集的符号化版本，发现 GPT-3的 Davinci-002模型对符号化 MWP 也有很好的零拍精度。为了评价模型推理的准确性，我们超越了准确性的范畴，进一步评价了最终答案和输出推理之间的一致性，它们分别对应于 MWP 的数值答案和符号答案。我们探索了一种自我激励的方法，以鼓励符号推理与数值答案保持一致，从而使 LLM 具备提供简洁和可验证推理的能力，并使其更易于解释。令人惊讶的是，自我提示还提高了符号的准确性，使其高于数字和符号的准确性，从而提供了一种集成效果。SVAMP _ Sym 数据集将被发布，用于符号数学问题的进一步研究。"
    },
    {
        "title": "How many preprints have actually been printed and why: a case study of\n  computer science preprints on arXiv",
        "url": "http://arxiv.org/abs/2308.01899v1",
        "pub_date": "2023-08-03",
        "summary": "Preprints play an increasingly critical role in academic communities. There\nare many reasons driving researchers to post their manuscripts to preprint\nservers before formal submission to journals or conferences, but the use of\npreprints has also sparked considerable controversy, especially surrounding the\nclaim of priority. In this paper, a case study of computer science preprints\nsubmitted to arXiv from 2008 to 2017 is conducted to quantify how many\npreprints have eventually been printed in peer-reviewed venues. Among those\npublished manuscripts, some are published under different titles and without an\nupdate to their preprints on arXiv. In the case of these manuscripts, the\ntraditional fuzzy matching method is incapable of mapping the preprint to the\nfinal published version. In view of this issue, we introduce a semantics-based\nmapping method with the employment of Bidirectional Encoder Representations\nfrom Transformers (BERT). With this new mapping method and a plurality of data\nsources, we find that 66% of all sampled preprints are published under\nunchanged titles and 11% are published under different titles and with other\nmodifications. A further analysis was then performed to investigate why these\npreprints but not others were accepted for publication. Our comparison reveals\nthat in the field of computer science, published preprints feature adequate\nrevisions, multiple authorship, detailed abstract and introduction, extensive\nand authoritative references and available source code.",
        "translated": "预印本在学术界扮演着越来越重要的角色。有很多原因驱使研究人员在正式提交给期刊或会议之前将他们的手稿发布到预印本服务器上，但预印本的使用也引发了相当大的争议，特别是围绕着优先权的主张。本文对2008年至2017年提交给 arXiv 的计算机科学预印本进行了个案研究，以量化有多少预印本最终在同行评审的场所打印。在这些已出版的手稿中，有些以不同的标题出版，并且没有在 arXiv 上更新它们的预印本。对于这些稿件，传统的模糊匹配方法不能将预印本映射到最终出版的版本。针对这一问题，本文提出了一种基于语义的映射方法，该方法采用变压器双向编码表示(BERT)。利用这种新的映射方法和多个数据源，我们发现66% 的样本预印本以不变的标题出版，11% 的样本以不同的标题和其他修改的标题出版。然后进行了进一步的分析，以调查为什么这些预印本而不是其他的被接受出版。我们的比较表明，在计算机科学领域，已发表的预印本具有适当的修订、多作者、详细的摘要和介绍、广泛和权威的参考资料和可用的源代码。"
    },
    {
        "title": "Athena 2.0: Discourse and User Modeling in Open Domain Dialogue",
        "url": "http://arxiv.org/abs/2308.01887v1",
        "pub_date": "2023-08-03",
        "summary": "Conversational agents are consistently growing in popularity and many people\ninteract with them every day. While many conversational agents act as personal\nassistants, they can have many different goals. Some are task-oriented, such as\nproviding customer support for a bank or making a reservation. Others are\ndesigned to be empathetic and to form emotional connections with the user. The\nAlexa Prize Challenge aims to create a socialbot, which allows the user to\nengage in coherent conversations, on a range of popular topics that will\ninterest the user. Here we describe Athena 2.0, UCSC's conversational agent for\nAmazon's Socialbot Grand Challenge 4. Athena 2.0 utilizes a novel\nknowledge-grounded discourse model that tracks the entity links that Athena\nintroduces into the dialogue, and uses them to constrain named-entity\nrecognition and linking, and coreference resolution. Athena 2.0 also relies on\na user model to personalize topic selection and other aspects of the\nconversation to individual users.",
        "translated": "会话代理人越来越受欢迎，许多人每天都与他们互动。虽然许多会话代理充当私人助理，但他们可以有许多不同的目标。有些是面向任务的，例如为银行提供客户支持或预订。另一些则是为了与用户产生共鸣和建立情感联系而设计的。Alexa 奖励挑战赛的目标是创建一个社交机器人，它允许用户参与连贯的对话，在一系列的流行话题，将感兴趣的用户。在这里，我们描述雅典娜2.0，UCSC 的对话代理亚马逊的社交机器人大挑战4。雅典娜2.0采用了一种新颖的基于知识的话语模型，追踪雅典娜在对话中引入的实体联系，并用它们来约束命名实体识别和联系，以及共指消解。Athena 2.0还依赖于一个用户模型来为单个用户个性化主题选择和对话的其他方面。"
    },
    {
        "title": "Thespian: Multi-Character Text Role-Playing Game Agents",
        "url": "http://arxiv.org/abs/2308.01872v1",
        "pub_date": "2023-08-03",
        "summary": "Text-adventure games and text role-playing games are grand challenges for\nreinforcement learning game playing agents. Text role-playing games are\nopen-ended environments where an agent must faithfully play a particular\ncharacter. We consider the distinction between characters and actors, where an\nactor agent has the ability to play multiple characters. We present a framework\nwe call a thespian agent that can learn to emulate multiple characters along\nwith a soft prompt that can be used to direct it as to which character to play\nat any time. We further describe an attention mechanism that allows the agent\nto learn new characters that are based on previously learned characters in a\nfew-shot fashion. We show that our agent outperforms the state of the art agent\nframework in multi-character learning and few-shot learning.",
        "translated": "文字冒险游戏和文字角色扮演游戏对于强化学习游戏代理来说是巨大的挑战。文本角色扮演游戏是一种开放式的环境，代理必须忠实地扮演特定的角色。我们考虑角色和演员之间的区别，其中演员代理具有扮演多个角色的能力。我们提出了一个框架，我们称之为悲剧代理，可以学习模拟多个字符以及一个软提示，可以用来指导它在任何时候扮演哪个角色。我们进一步描述了一种注意机制，该机制允许代理以几个镜头的方式学习基于先前学习的角色的新角色。结果表明，我们的 Agent 在多角色学习和少镜头学习方面优于目前最先进的 Agent 框架。"
    },
    {
        "title": "Tag Prediction of Competitive Programming Problems using Deep Learning\n  Techniques",
        "url": "http://arxiv.org/abs/2308.01863v1",
        "pub_date": "2023-08-03",
        "summary": "In the past decade, the amount of research being done in the fields of\nmachine learning and deep learning, predominantly in the area of natural\nlanguage processing (NLP), has risen dramatically. A well-liked method for\ndeveloping programming abilities like logic building and problem solving is\ncompetitive programming. It can be tough for novices and even veteran\nprogrammers to traverse the wide collection of questions due to the massive\nnumber of accessible questions and the variety of themes, levels of difficulty,\nand questions offered. In order to help programmers find questions that are\nappropriate for their knowledge and interests, there is a need for an automated\nmethod. This can be done using automated tagging of the questions using Text\nClassification. Text classification is one of the important tasks widely\nresearched in the field of Natural Language Processing. In this paper, we\npresent a way to use text classification techniques to determine the domain of\na competitive programming problem. A variety of models, including are\nimplemented LSTM, GRU, and MLP. The dataset has been scraped from Codeforces, a\nmajor competitive programming website. A total of 2400 problems were scraped\nand preprocessed, which we used as a dataset for our training and testing of\nmodels. The maximum accuracy reached using our model is 78.0% by MLP(Multi\nLayer Perceptron).",
        "translated": "在过去的十年里，机器学习和深度学习领域的研究数量急剧上升，主要集中在自然语言处理(NLP)领域。竞争性编程是培养逻辑构建和解决问题等编程能力的一种很受欢迎的方法。由于存在大量易于理解的问题以及提供的主题、难度级别和问题的多样性，对于新手甚至是资深程序员来说，遍历大量的问题集是很困难的。为了帮助程序员找到适合他们的知识和兴趣的问题，需要一个自动化的方法。这可以通过使用文本分类对问题进行自动标记来实现。文本分类是自然语言处理领域广泛研究的重要课题之一。本文提出了一种利用文本分类技术确定竞争规划问题域的方法。各种模型，包括实现的 LSTM、 GRU 和 MLP。这个数据集是从一个主要的竞争性编程网站 Codeforces 上刮下来的。总共有2400个问题被提取和预处理，我们用它们作为模型训练和测试的数据集。使用我们的模型所达到的最大精度是78.0% 的 MLP (多层感知器)。"
    },
    {
        "title": "Wider and Deeper LLM Networks are Fairer LLM Evaluators",
        "url": "http://arxiv.org/abs/2308.01862v1",
        "pub_date": "2023-08-03",
        "summary": "Measuring the quality of responses generated by LLMs is a challenging task,\nparticularly when it comes to evaluating whether the response is aligned with\nhuman preference. A novel approach involves using the LLM itself to make\nevaluation and stabilizing the results through multiple independent\nevaluations, similar to a single-layer narrow LLM network. This network\nconsists of a fixed number of neurons, with each neuron being the same LLM. In\nthis paper, we draw upon the extensive research on deep neural networks to\nexplore whether deeper and wider networks can lead to fairer evaluations.\nSpecifically, inspired by the observation that different neurons in a neural\nnetwork are responsible for detecting different concepts, we first adaptively\ngenerate as many neuron roles as possible for each evaluation sample. Each\nperspective corresponds to the role of a specific LLM neuron in the first\nlayer. In subsequent layers, we follow the idea that higher layers in deep\nnetworks are responsible for more comprehensive features, each layer receives\nrepresentations from all neurons in the previous layer, integrating the locally\nlearned evaluation information to obtain a more comprehensive evaluation\nresult. Interestingly, this network design resembles the process of academic\npaper reviewing. To validate the effectiveness of our method, we construct the\nlargest and most diverse English evaluation benchmark LLMEval$^2$ for LLM\nevaluators, comprising 15 tasks, 8 abilities, and 2,553 samples. Experimental\nresults demonstrate that a wider network (involving many reviewers) with 2\nlayers (one round of discussion) performs the best, improving kappa correlation\ncoefficient from 0.28 to 0.34. We also leverage WideDeep to aid in the\nassessment of Chinese LLMs, which has accelerated the evaluation time by 4.6\ntimes, resulting in a 60% cost saving. WideDeep achieves a remarkable 93%\nagreement level among humans.",
        "translated": "测量 LLM 产生的反应质量是一项具有挑战性的任务，特别是在评估反应是否与人类偏好一致时。一种新的方法涉及使用 LLM 本身进行评估和稳定的结果，通过多个独立的评估，类似于单层窄 LLM 网络。这个网络由固定数量的神经元组成，每个神经元是相同的 LLM。在本文中，我们利用深层神经网络的广泛研究，以探讨是否更深和更广的网络可以导致更公平的评价。具体来说，受到神经网络中不同神经元负责检测不同概念的观察的启发，我们首先自适应地为每个评估样本生成尽可能多的神经元角色。每个视角对应于第一层特定 LLM 神经元的作用。在后续层中，我们遵循深层网络的高层负责更全面的特征的思想，每一层接收来自前一层所有神经元的表示，整合局部学习的评价信息以获得更全面的评价结果。有趣的是，这个网络设计类似于学术论文审阅的过程。为了验证我们的方法的有效性，我们为 LLM 评估者构建了最大和最多样化的英语评估基准 LLMEval $^ 2 $，包括15个任务，8个能力和2,553个样本。实验结果表明，一个更广泛的网络(包括许多评论者)的2层(一轮讨论)表现最好，提高卡伯相关系数从0.28到0.34。我们还利用 WideDeep 来帮助评估中国的 LLM，这使得评估时间加快了4.6倍，节省了60% 的成本。WideDeep 在人类之间达到了93% 的一致性水平。"
    },
    {
        "title": "ClassEval: A Manually-Crafted Benchmark for Evaluating LLMs on\n  Class-level Code Generation",
        "url": "http://arxiv.org/abs/2308.01861v1",
        "pub_date": "2023-08-03",
        "summary": "In this work, we make the first attempt to evaluate LLMs in a more\nchallenging code generation scenario, i.e. class-level code generation. We\nfirst manually construct the first class-level code generation benchmark\nClassEval of 100 class-level Python code generation tasks with approximately\n500 person-hours. Based on it, we then perform the first study of 11\nstate-of-the-art LLMs on class-level code generation. Based on our results, we\nhave the following main findings. First, we find that all existing LLMs show\nmuch worse performance on class-level code generation compared to on standalone\nmethod-level code generation benchmarks like HumanEval; and the method-level\ncoding ability cannot equivalently reflect the class-level coding ability among\nLLMs. Second, we find that GPT-4 and GPT-3.5 still exhibit dominate superior\nthan other LLMs on class-level code generation, and the second-tier models\nincludes Instruct-Starcoder, Instruct-Codegen, and Wizardcoder with very\nsimilar performance. Third, we find that generating the entire class all at\nonce (i.e. holistic generation strategy) is the best generation strategy only\nfor GPT-4 and GPT-3.5, while method-by-method generation (i.e. incremental and\ncompositional) is better strategies for the other models with limited ability\nof understanding long instructions and utilizing the middle information.\nLastly, we find the limited model ability of generating method-dependent code\nand discuss the frequent error types in generated classes. Our benchmark is\navailable at https://github.com/FudanSELab/ClassEval.",
        "translated": "在这项工作中，我们首次尝试在更具挑战性的代码生成场景(即类级代码生成)中评估 LLM。我们首先手动构建第一个类级代码生成基准 ClassEval，它包含100个类级 Python 代码生成任务，大约500人/小时。在此基础上，我们对11种最先进的 LLM 类级代码生成进行了首次研究。根据我们的研究结果，我们有以下主要发现。首先，我们发现所有现有的 LLM 在类级代码生成方面的性能都比单独的方法级代码生成基准(如 HumanEval)差得多，而且方法级编码能力不能等效地反映 LLM 之间的类级编码能力。其次，我们发现 GPT-4和 GPT-3.5在类级代码生成方面仍然显示出优于其他 LLM 的优势，并且第二层模型包括具有非常相似性能的指令-星码器，指令-编码器和向导码器。第三，我们发现对于 GPT-4和 GPT-3.5而言，同时生成整个类(即整体生成策略)是最佳生成策略，而对于理解长指令和利用中间信息能力有限的其他模型而言，逐方法生成(即增量和组合)是更好的策略。最后，我们发现了生成方法相关代码的有限模型能力，并讨论了生成类中的频繁错误类型。我们的基准 https://github.com/fudanselab/classeval 现已发售。"
    },
    {
        "title": "Curricular Transfer Learning for Sentence Encoded Tasks",
        "url": "http://arxiv.org/abs/2308.01849v1",
        "pub_date": "2023-08-03",
        "summary": "Fine-tuning language models in a downstream task is the standard approach for\nmany state-of-the-art methodologies in the field of NLP. However, when the\ndistribution between the source task and target task drifts, \\textit{e.g.},\nconversational environments, these gains tend to be diminished. This article\nproposes a sequence of pre-training steps (a curriculum) guided by \"data\nhacking\" and grammar analysis that allows further gradual adaptation between\npre-training distributions. In our experiments, we acquire a considerable\nimprovement from our method compared to other known pre-training approaches for\nthe MultiWoZ task.",
        "translated": "在下游任务中对语言模型进行微调是自然语言处理领域中许多最先进方法的标准方法。然而，当源任务和目标任务之间的分布发生漂移时，会话环境，这些收益趋于减少。本文提出了一系列由“数据黑客”和语法分析指导的培训前步骤(课程) ，允许在培训前分布之间进一步逐步适应。在我们的实验中，相对于其他已知的 MultiWoZ 任务的预训练方法，我们从我们的方法中获得了相当大的改进。"
    },
    {
        "title": "XNLP: An Interactive Demonstration System for Universal Structured NLP",
        "url": "http://arxiv.org/abs/2308.01846v1",
        "pub_date": "2023-08-03",
        "summary": "Structured Natural Language Processing (XNLP) is an important subset of NLP\nthat entails understanding the underlying semantic or syntactic structure of\ntexts, which serves as a foundational component for many downstream\napplications. Despite certain recent efforts to explore universal solutions for\nspecific categories of XNLP tasks, a comprehensive and effective approach for\nunifying all XNLP tasks long remains underdeveloped. In the meanwhile, while\nXNLP demonstration systems are vital for researchers exploring various XNLP\ntasks, existing platforms can be limited to, e.g., supporting few XNLP tasks,\nlacking interactivity and universalness. To this end, we propose an advanced\nXNLP demonstration platform, where we propose leveraging LLM to achieve\nuniversal XNLP, with one model for all with high generalizability. Overall, our\nsystem advances in multiple aspects, including universal XNLP modeling, high\nperformance, interpretability, scalability, and interactivity, providing a\nunified platform for exploring diverse XNLP tasks in the community. XNLP is\nonline: https://xnlp.haofei.vip",
        "translated": "结构化自然语言处理(XNLP)是自然语言处理的一个重要子集，它需要理解文本的潜在语义或句法结构，是许多下游应用的基础组件。尽管最近做出了一些努力来探索针对特定类别的 XNLP 任务的通用解决方案，但是长期以来统一所有 XNLP 任务的全面而有效的方法仍然不够完善。同时，虽然 XNLP 演示系统对于研究人员探索各种 XNLP 任务至关重要，但现有的平台可能仅限于支持少量 XNLP 任务，缺乏交互性和通用性。为此，我们提出了一个先进的 XNLP 演示平台，其中我们建议利用 LLM 来实现通用的 XNLP，一个模型对所有人都具有高度的通用性。总体而言，我们的系统在多个方面取得了进展，包括通用的 XNLP 建模、高性能、可解释性、可扩展性和交互性，为探索社区中不同的 XNLP 任务提供了一个统一的平台。XnLP 在线:  https://XNLP.haofei.vip"
    },
    {
        "title": "The Capability of Large Language Models to Measure Psychiatric\n  Functioning",
        "url": "http://arxiv.org/abs/2308.01834v1",
        "pub_date": "2023-08-03",
        "summary": "The current work investigates the capability of Large language models (LLMs)\nthat are explicitly trained on large corpuses of medical knowledge (Med-PaLM 2)\nto predict psychiatric functioning from patient interviews and clinical\ndescriptions without being trained to do so. To assess this, n = 145 depression\nand n =115 PTSD assessments and n = 46 clinical case studies across high\nprevalence/high comorbidity disorders (Depressive, Anxiety, Psychotic, trauma\nand stress, Addictive disorders) were analyzed using prompts to extract\nestimated clinical scores and diagnoses. Results demonstrate that Med-PaLM 2 is\ncapable of assessing psychiatric functioning across a range of psychiatric\nconditions with the strongest performance being the prediction of depression\nscores based on standardized assessments (Accuracy range= 0.80 - 0.84) which\nwere statistically indistinguishable from human clinical raters t(1,144) =\n1.20; p = 0.23. Results show the potential for general clinical language models\nto flexibly predict psychiatric risk based on free descriptions of functioning\nfrom both patients and clinicians.",
        "translated": "目前的工作调查了大型语言模型(LLM)的能力，这些模型在大型医学知识库(Med-PaLM 2)上进行了明确的培训，以从患者访谈和临床描述中预测精神功能，而没有经过培训。为了评估这一点，使用提示来分析 n = 145个抑郁症和 n = 115个 PTSD 评估以及 n = 46个高患病率/高合并症(抑郁症，焦虑症，精神病，创伤和压力，成瘾性疾病)的临床病例研究，以提取估计的临床评分和诊断。结果表明，Med-PaLM 2能够评估一系列精神疾病的精神功能，最强的表现是基于标准化评估(准确性范围 = 0.80-0.84)预测抑郁评分，其与人类临床评分者 t (1,144) = 1.20; p = 0.23。结果表明，一般临床语言模型的潜力，灵活预测精神风险的基础上自由描述的功能从患者和临床医生。"
    },
    {
        "title": "Adaptive Preferential Attached kNN Graph With Distribution-Awareness",
        "url": "http://arxiv.org/abs/2308.02442v1",
        "pub_date": "2023-08-04",
        "summary": "Graph-based kNN algorithms have garnered widespread popularity for machine\nlearning tasks, due to their simplicity and effectiveness. However, the\nconventional kNN graph's reliance on a fixed value of k can hinder its\nperformance, especially in scenarios involving complex data distributions.\nMoreover, like other classification models, the presence of ambiguous samples\nalong decision boundaries often presents a challenge, as they are more prone to\nincorrect classification. To address these issues, we propose the Preferential\nAttached k-Nearest Neighbors Graph (paNNG), which combines adaptive kNN with\ndistribution-based graph construction. By incorporating distribution\ninformation, paNNG can significantly improve performance for ambiguous samples\nby \"pulling\" them towards their original classes and hence enable enhanced\noverall accuracy and generalization capability. Through rigorous evaluations on\ndiverse benchmark datasets, paNNG outperforms state-of-the-art algorithms,\nshowcasing its adaptability and efficacy across various real-world scenarios.",
        "translated": "基于图的 kNN 算法由于其简单性和有效性，在机器学习任务中得到了广泛的应用。然而，传统的 kNN 图依赖于一个固定的 k 值可能会阻碍其性能，特别是在涉及复杂数据分布的情况下。此外，像其他分类模型一样，沿决策边界存在模糊样本往往是一个挑战，因为它们更容易出现不正确的分类。为了解决这些问题，我们提出了一种结合自适应 kNN 和基于分布的图结构的偏好附加 k- 最近邻图(paNNG)。通过合并分布信息，paNNG 可以通过将模糊样本“拉向”其原始类来显著提高其性能，从而提高整体准确性和泛化能力。通过对不同基准数据集的严格评估，paNNG 优于最先进的算法，展示了其在各种真实场景中的适应性和有效性。"
    },
    {
        "title": "RAHNet: Retrieval Augmented Hybrid Network for Long-tailed Graph\n  Classification",
        "url": "http://arxiv.org/abs/2308.02335v1",
        "pub_date": "2023-08-04",
        "summary": "Graph classification is a crucial task in many real-world multimedia\napplications, where graphs can represent various multimedia data types such as\nimages, videos, and social networks. Previous efforts have applied graph neural\nnetworks (GNNs) in balanced situations where the class distribution is\nbalanced. However, real-world data typically exhibit long-tailed class\ndistributions, resulting in a bias towards the head classes when using GNNs and\nlimited generalization ability over the tail classes. Recent approaches mainly\nfocus on re-balancing different classes during model training, which fails to\nexplicitly introduce new knowledge and sacrifices the performance of the head\nclasses. To address these drawbacks, we propose a novel framework called\nRetrieval Augmented Hybrid Network (RAHNet) to jointly learn a robust feature\nextractor and an unbiased classifier in a decoupled manner. In the feature\nextractor training stage, we develop a graph retrieval module to search for\nrelevant graphs that directly enrich the intra-class diversity for the tail\nclasses. Moreover, we innovatively optimize a category-centered supervised\ncontrastive loss to obtain discriminative representations, which is more\nsuitable for long-tailed scenarios. In the classifier fine-tuning stage, we\nbalance the classifier weights with two weight regularization techniques, i.e.,\nMax-norm and weight decay. Experiments on various popular benchmarks verify the\nsuperiority of the proposed method against state-of-the-art approaches.",
        "translated": "图形分类是许多实际多媒体应用中的关键任务，在这些应用中，图形可以表示各种多媒体数据类型，如图像、视频和社交网络。先前的研究已经将图神经网络(GNN)应用于类别分布均衡的平衡情况。然而，真实世界的数据通常表现出长尾类分布，导致在使用 GNN 时偏向于头类，并且对尾类的泛化能力有限。最近的方法主要集中在模型训练过程中重新平衡不同的类，这种方法不能明确地引入新的知识，而且牺牲了头类的性能。针对这些缺点，提出了一种新的检索增强混合网络(RAHNet)框架，以解耦的方式联合学习鲁棒特征提取器和无偏分类器。在特征提取训练阶段，我们开发了一个图检索模块来搜索相关图，直接丰富了尾部类的类内多样性。此外，我们创新性地优化了一个以类别为中心的监督对比度损失，以获得更适合于长尾场景的区分性表示。在分类器微调阶段，采用最大范数和权重衰减两种权重正则化技术来平衡分类器权重。在各种流行基准上的实验验证了该方法相对于最先进方法的优越性。"
    },
    {
        "title": "Learning to Select the Relevant History Turns in Conversational Question\n  Answering",
        "url": "http://arxiv.org/abs/2308.02294v1",
        "pub_date": "2023-08-04",
        "summary": "The increasing demand for the web-based digital assistants has given a rapid\nrise in the interest of the Information Retrieval (IR) community towards the\nfield of conversational question answering (ConvQA). However, one of the\ncritical aspects of ConvQA is the effective selection of conversational history\nturns to answer the question at hand. The dependency between relevant history\nselection and correct answer prediction is an intriguing but under-explored\narea. The selected relevant context can better guide the system so as to where\nexactly in the passage to look for an answer. Irrelevant context, on the other\nhand, brings noise to the system, thereby resulting in a decline in the model's\nperformance. In this paper, we propose a framework, DHS-ConvQA (Dynamic History\nSelection in Conversational Question Answering), that first generates the\ncontext and question entities for all the history turns, which are then pruned\non the basis of similarity they share in common with the question at hand. We\nalso propose an attention-based mechanism to re-rank the pruned terms based on\ntheir calculated weights of how useful they are in answering the question. In\nthe end, we further aid the model by highlighting the terms in the re-ranked\nconversational history using a binary classification task and keeping the\nuseful terms (predicted as 1) and ignoring the irrelevant terms (predicted as\n0). We demonstrate the efficacy of our proposed framework with extensive\nexperimental results on CANARD and QuAC -- the two popularly utilized datasets\nin ConvQA. We demonstrate that selecting relevant turns works better than\nrewriting the original question. We also investigate how adding the irrelevant\nhistory turns negatively impacts the model's performance and discuss the\nresearch challenges that demand more attention from the IR community.",
        "translated": "对网络数字助理的需求日益增长，使得信息检索对会话问答领域的兴趣迅速上升。然而，ConvQA 的一个关键方面是有效地选择会话历史转折来回答手头的问题。相关历史选择和正确答案预测之间的依赖性是一个有趣但尚未探索的领域。所选择的相关上下文可以更好地指导系统，以便在文章中准确地寻找答案。另一方面，不相关的环境给系统带来噪声，从而导致模型性能的下降。本文提出了会话问答中的动态历史选择(DHS-ConvQA)框架，该框架首先生成所有历史转折的上下文和问题实体，然后根据这些上下文和问题实体与当前问题的相似性对它们进行剪枝。我们还提出了一种基于注意力的机制，根据修剪后的术语在回答问题时的有用程度的计算权重对它们进行重新排序。最后，通过使用二进制分类任务突出重新排序的会话历史中的术语，并保留有用术语(预测为1)而忽略不相关术语(预测为0) ，我们进一步帮助该模型。我们通过 CANARD 和 QuAC 这两个在 ConvQA 中广泛使用的数据集的大量实验结果证明了我们提出的框架的有效性。我们证明，选择相关的回合比重写原来的问题更有效。我们还调查了添加不相关历史如何对模型的性能产生负面影响，并讨论了需要国际关系社区更多关注的研究挑战。"
    },
    {
        "title": "Optimally Computing Compressed Indexing Arrays Based on the Compact\n  Directed Acyclic Word Graph",
        "url": "http://arxiv.org/abs/2308.02269v1",
        "pub_date": "2023-08-04",
        "summary": "In this paper, we present the first study of the computational complexity of\nconverting an automata-based text index structure, called the Compact Directed\nAcyclic Word Graph (CDAWG), of size $e$ for a text $T$ of length $n$ into other\ntext indexing structures for the same text, suitable for highly repetitive\ntexts: the run-length BWT of size $r$, the irreducible PLCP array of size $r$,\nand the quasi-irreducible LPF array of size $e$, as well as the lex-parse of\nsize $O(r)$ and the LZ77-parse of size $z$, where $r, z \\le e$. As main\nresults, we showed that the above structures can be optimally computed from\neither the CDAWG for $T$ stored in read-only memory or its self-index version\nof size $e$ without a text in $O(e)$ worst-case time and words of working\nspace. To obtain the above results, we devised techniques for enumerating a\nparticular subset of suffixes in the lexicographic and text orders using the\nforward and backward search on the CDAWG by extending the results by\nBelazzougui et al. in 2015.",
        "translated": "本文首次研究了基于自动机的文本索引结构(CDAWG)的计算复杂性，该索引结构称为紧凑型有向无环词图(CDAWG) ，对于一个长度为 $n $的文本，它的大小为 $e $，适用于同一文本的其他文本索引结构: 长度为 $r $的游程 BWT，大小为 $r $的不可约 PLCP 数组，大小为 $e $的准不可约 LPF 数组，以及大小为 $O (r) $的 lex-parse 和大小为 $z $的 LZ77-parse，其中 $r，z le $。我们的主要结果表明，上述结构可以从存储在只读内存中的 $t $的 CDAWG 或其大小为 $e $的自索引版本中进行优化计算，而不需要在 $o (e) $最坏情况下的时间和工作空间中的单词。为了获得上述结果，我们通过扩展 Belazzougui 等人2015年的结果，设计了使用 CDAWG 上的正向和反向搜索来枚举词典和文本顺序中特定后缀子集的技术。"
    },
    {
        "title": "Finding Tori: Self-supervised Learning for Analyzing Korean Folk Song",
        "url": "http://arxiv.org/abs/2308.02249v1",
        "pub_date": "2023-08-04",
        "summary": "In this paper, we introduce a computational analysis of the field recording\ndataset of approximately 700 hours of Korean folk songs, which were recorded\naround 1980-90s. Because most of the songs were sung by non-expert musicians\nwithout accompaniment, the dataset provides several challenges. To address this\nchallenge, we utilized self-supervised learning with convolutional neural\nnetwork based on pitch contour, then analyzed how the musical concept of tori,\na classification system defined by a specific scale, ornamental notes, and an\nidiomatic melodic contour, is captured by the model. The experimental result\nshows that our approach can better capture the characteristics of tori compared\nto traditional pitch histograms. Using our approaches, we have examined how\nmusical discussions proposed in existing academia manifest in the actual field\nrecordings of Korean folk songs.",
        "translated": "本文对1980年代至1990年代前后大约700小时的韩国民歌实地录音资料进行了计算机分析。由于大多数歌曲都是由非专业音乐家在没有伴奏的情况下演唱的，这个数据集提供了一些挑战。为了应对这个挑战，我们利用基于音高轮廓的自我监督学习卷积神经网络，然后分析了 tori 的音乐概念，一个由特定音阶、装饰音符和惯用旋律轮廓定义的分类方案，是如何被模型捕捉到的。实验结果表明，与传统的基音直方图相比，该方法能够更好地捕捉基音的环面特征。运用我们的研究方法，我们考察了现有学术界提出的音乐讨论是如何在韩国民歌的实地录音中表现出来的。"
    },
    {
        "title": "MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities",
        "url": "http://arxiv.org/abs/2308.02490v1",
        "pub_date": "2023-08-04",
        "summary": "We propose MM-Vet, an evaluation benchmark that examines large multimodal\nmodels (LMMs) on complicated multimodal tasks. Recent LMMs have shown various\nintriguing abilities, such as solving math problems written on the blackboard,\nreasoning about events and celebrities in news images, and explaining visual\njokes. Rapid model advancements pose challenges to evaluation benchmark\ndevelopment. Problems include: (1) How to systematically structure and evaluate\nthe complicated multimodal tasks; (2) How to design evaluation metrics that\nwork well across question and answer types; and (3) How to give model insights\nbeyond a simple performance ranking. To this end, we present MM-Vet, designed\nbased on the insight that the intriguing ability to solve complicated tasks is\noften achieved by a generalist model being able to integrate different core\nvision-language (VL) capabilities. MM-Vet defines 6 core VL capabilities and\nexamines the 16 integrations of interest derived from the capability\ncombination. For evaluation metrics, we propose an LLM-based evaluator for\nopen-ended outputs. The evaluator enables the evaluation across different\nquestion types and answer styles, resulting in a unified scoring metric. We\nevaluate representative LMMs on MM-Vet, providing insights into the\ncapabilities of different LMM system paradigms and models. Code and data are\navailable at https://github.com/yuweihao/MM-Vet.",
        "translated": "我们提出了 MM-Vet，一个评估基准，它检查复杂多模态任务上的大型多模态模型(LMM)。最近的 LMM 显示了各种各样有趣的能力，比如解决写在黑板上的数学问题，推理新闻图片中的事件和名人，以及解释视觉笑话。模型的快速发展对评价基准的开发提出了挑战。问题包括: (1)如何系统地构建和评估复杂的多模式任务; (2)如何设计跨问题和答案类型的评估指标; (3)如何给出超越简单绩效排名的模型洞察力。为此，我们提出 MM-Vet，设计的基础上的洞察力，有趣的能力，以解决复杂的任务往往是通用模型，能够集成不同的核心视觉语言(VL)的能力。MM-Vet 定义了6个核心 VL 能力，并检查了从能力组合中衍生出来的16个感兴趣的集成。对于评估指标，我们提出了一个基于 LLM 的开放式输出评估器。评估器允许跨不同的问题类型和答案风格进行评估，从而产生一个统一的评分指标。我们评估 MM-Vet 上的代表性 LMM，提供对不同 LMM 系统范例和模型的能力的见解。代码和数据可在 https://github.com/yuweihao/mm-vet 查阅。"
    },
    {
        "title": "Adapting the NICT-JLE Corpus for Disfluency Detection Models",
        "url": "http://arxiv.org/abs/2308.02482v1",
        "pub_date": "2023-08-04",
        "summary": "The detection of disfluencies such as hesitations, repetitions and false\nstarts commonly found in speech is a widely studied area of research. With a\nstandardised process for evaluation using the Switchboard Corpus, model\nperformance can be easily compared across approaches. This is not the case for\ndisfluency detection research on learner speech, however, where such datasets\nhave restricted access policies, making comparison and subsequent development\nof improved models more challenging. To address this issue, this paper\ndescribes the adaptation of the NICT-JLE corpus, containing approximately 300\nhours of English learners' oral proficiency tests, to a format that is suitable\nfor disfluency detection model training and evaluation. Points of difference\nbetween the NICT-JLE and Switchboard corpora are explored, followed by a\ndetailed overview of adaptations to the tag set and meta-features of the\nNICT-JLE corpus. The result of this work provides a standardised train, heldout\nand test set for use in future research on disfluency detection for learner\nspeech.",
        "translated": "检测语音中常见的犹豫、重复和错误开始等不流畅现象是一个被广泛研究的领域。通过使用总机语料库的标准化评估过程，可以很容易地比较不同方法的模型性能。然而，对学习者语音的不流畅性检测研究并非如此，因为这些数据集限制了访问策略，使得对改进模型的比较和后续开发更具挑战性。为了解决这个问题，本文描述了 NICT-JLE 语料库，包含了大约300小时的英语学习者口语水平测试，以一种适合于不流利检测模型训练和评估的格式。探讨了 NICT-JLE 和总机语料库之间的差异点，随后详细概述了对 NICT-JLE 语料库的标记集和元特征的适应。本研究的结果提供了一个标准化的训练、拒绝和测试集，以供将来研究学习者语音的不流畅性检测时使用。"
    },
    {
        "title": "Towards Generalist Foundation Model for Radiology",
        "url": "http://arxiv.org/abs/2308.02463v1",
        "pub_date": "2023-08-04",
        "summary": "In this study, we aim to initiate the development of Radiology Foundation\nModel, termed as RadFM.We consider the construction of foundational models from\nthe perspectives of data, model design, and evaluation thoroughly. Our\ncontribution can be concluded as follows: (i), we construct a large-scale\nMedical Multi-modal Dataset, MedMD, consisting of 16M 2D and 3D medical scans.\nTo the best of our knowledge, this is the first multi-modal dataset containing\n3D medical scans. (ii), We propose an architecture that enables visually\nconditioned generative pre-training, allowing for the integration of text input\ninterleaved with 2D or 3D medical scans to generate response for diverse\nradiologic tasks. The model was initially pre-trained on MedMD and subsequently\ndomain-specific fine-tuned on RadMD, a radiologic cleaned version of MedMD,\ncontaining 3M radiologic visual-language pairs. (iii), we propose a new\nevaluation benchmark that comprises five tasks, aiming to comprehensively\nassess the capability of foundation models in handling practical clinical\nproblems. Our experimental results confirm that RadFM significantly outperforms\nexisting multi-modal foundation models. The codes, data, and model checkpoint\nwill all be made publicly available to promote further research and development\nin the field.",
        "translated": "本研究旨在发展放射学基础模型(RadFM) ，从数据、模型设计、评估等角度深入考虑基础模型的建立。我们的贡献可以归纳如下: (i)我们构建了一个大规模的医学多模态数据集 MedMD，包括16M 二维和三维医学扫描。据我们所知，这是第一个包含3D 医学扫描的多模态数据集。(ii) ，我们提出了一种体系结构，可以实现视觉条件生成性预训练，允许将文本输入与2D 或3D 医学扫描交错集成，以产生对不同放射学任务的响应。该模型最初在 MedMD 上进行预训练，随后在 RadMD 上进行领域特定的微调，RadMD 是 MedMD 的放射清洗版，包含3M 放射学视觉语言对。(iii)我们提出一个新的评估基准，包括五个任务，旨在全面评估基础模型处理实际临床问题的能力。实验结果表明，RadFM 模型的性能明显优于现有的多模态地基模型。这些代码、数据和模型检查点将全部公开，以促进该领域的进一步研究和开发。"
    },
    {
        "title": "From Military to Healthcare: Adopting and Expanding Ethical Principles\n  for Generative Artificial Intelligence",
        "url": "http://arxiv.org/abs/2308.02448v1",
        "pub_date": "2023-08-04",
        "summary": "In 2020, the U.S. Department of Defense officially disclosed a set of ethical\nprinciples to guide the use of Artificial Intelligence (AI) technologies on\nfuture battlefields. Despite stark differences, there are core similarities\nbetween the military and medical service. Warriors on battlefields often face\nlife-altering circumstances that require quick decision-making. Medical\nproviders experience similar challenges in a rapidly changing healthcare\nenvironment, such as in the emergency department or during surgery treating a\nlife-threatening condition. Generative AI, an emerging technology designed to\nefficiently generate valuable information, holds great promise. As computing\npower becomes more accessible and the abundance of health data, such as\nelectronic health records, electrocardiograms, and medical images, increases,\nit is inevitable that healthcare will be revolutionized by this technology.\nRecently, generative AI has captivated the research community, leading to\ndebates about its application in healthcare, mainly due to concerns about\ntransparency and related issues. Meanwhile, concerns about the potential\nexacerbation of health disparities due to modeling biases have raised notable\nethical concerns regarding the use of this technology in healthcare. However,\nthe ethical principles for generative AI in healthcare have been understudied,\nand decision-makers often fail to consider the significance of generative AI.\nIn this paper, we propose GREAT PLEA ethical principles, encompassing\ngovernance, reliability, equity, accountability, traceability, privacy,\nlawfulness, empathy, and autonomy, for generative AI in healthcare. We aim to\nproactively address the ethical dilemmas and challenges posed by the\nintegration of generative AI in healthcare.",
        "translated": "2020年，美国国防部正式公布了一套伦理原则，用于指导未来战场上人工智能(AI)技术的使用。尽管存在明显的差异，军队和医疗服务之间有着核心的相似之处。战场上的勇士经常面临改变生活的情况，需要迅速作出决定。医疗服务提供者在快速变化的医疗环境中也会遇到类似的挑战，例如在急诊科或外科手术治疗危及生命的疾病时。生成式人工智能是一种新兴技术，旨在有效地生成有价值的信息，具有很大的前景。随着计算能力变得更容易获得，以及电子健康记录、心电图和医学图像等健康数据的丰富性增加，这项技术将不可避免地给医疗保健带来革命性变化。最近，生成性人工智能已经吸引了研究界的注意力，引发了关于其在医疗保健中的应用的争论，主要是由于对透明度和相关问题的关注。与此同时，由于模型偏差而引起的健康差异的潜在恶化引起了人们对在医疗保健中使用这种技术的显著的伦理关注。然而，医疗卫生领域生殖性人工智能的伦理原则一直被忽视，决策者往往没有考虑到生殖性人工智能的重要性。在本文中，我们提出了 GREAT PLEA 伦理原则，包括治理，可靠性，公平性，问责制，可追溯性，隐私，合法性，移情和自主性，生殖人工智能在医疗保健。我们的目标是积极主动地解决生殖人工智能在医疗保健中的整合所带来的伦理困境和挑战。"
    },
    {
        "title": "Text2KGBench: A Benchmark for Ontology-Driven Knowledge Graph Generation\n  from Text",
        "url": "http://arxiv.org/abs/2308.02357v1",
        "pub_date": "2023-08-04",
        "summary": "The recent advances in large language models (LLM) and foundation models with\nemergent capabilities have been shown to improve the performance of many NLP\ntasks. LLMs and Knowledge Graphs (KG) can complement each other such that LLMs\ncan be used for KG construction or completion while existing KGs can be used\nfor different tasks such as making LLM outputs explainable or fact-checking in\nNeuro-Symbolic manner. In this paper, we present Text2KGBench, a benchmark to\nevaluate the capabilities of language models to generate KGs from natural\nlanguage text guided by an ontology. Given an input ontology and a set of\nsentences, the task is to extract facts from the text while complying with the\ngiven ontology (concepts, relations, domain/range constraints) and being\nfaithful to the input sentences. We provide two datasets (i) Wikidata-TekGen\nwith 10 ontologies and 13,474 sentences and (ii) DBpedia-WebNLG with 19\nontologies and 4,860 sentences. We define seven evaluation metrics to measure\nfact extraction performance, ontology conformance, and hallucinations by LLMs.\nFurthermore, we provide results for two baseline models, Vicuna-13B and\nAlpaca-LoRA-13B using automatic prompt generation from test cases. The baseline\nresults show that there is room for improvement using both Semantic Web and\nNatural Language Processing techniques.",
        "translated": "大语言模型(LLM)和具有紧急能力的基础模型的最新进展已被证明可以提高许多 NLP 任务的性能。学习模式和知识图表可以相辅相成，使学习模式可以用于幼稚园的建造或竣工，而现有的幼稚园则可以用于不同的工作，例如使学习模式的输出可以解释或以 Neuro-Symbolic 的方式进行事实核查。在本文中，我们提出了 Text2KGBench，一个基准来评估语言模型的能力，从自然语言文本的本体指导下生成 KG。给定一个输入本体和一组句子，任务是从文本中提取事实，同时遵守给定的本体(概念、关系、领域/范围约束)和忠实于输入句子。我们提供了两个数据集(i) Wikidata-TekGen，包含10个本体和13,474个句子; (ii) DBpedia-WebNLG，包含19个本体和4,860个句子。我们定义了七个评估指标来度量事实提取性能、本体一致性和 LLM 的幻觉。此外，我们提供了两个基线模型，Vicuna-13B 和 Alpaca-LoRA-13B 使用测试用例自动提示生成的结果。基准结果表明，使用语义 Web 和自然语言处理技术还有改进的空间。"
    },
    {
        "title": "Dataflow Dialogue Generation",
        "url": "http://arxiv.org/abs/2308.02323v1",
        "pub_date": "2023-08-04",
        "summary": "We demonstrate task-oriented dialogue generation within the dataflow dialogue\nparadigm. We show an example of agenda driven dialogue generation for the\nMultiWOZ domain, and an example of generation without an agenda for the\nSMCalFlow domain, where we show an improvement in the accuracy of the\ntranslation of user requests to dataflow expressions when the generated\ndialogues are used to augment the translation training dataset.",
        "translated": "我们在数据流对话范式中演示了面向任务的对话生成。我们展示了 MultiWOZ 域的议程驱动对话生成的例子，以及 SMCalFlow 域的无议程生成的例子，其中我们显示了当生成的对话用于扩充翻译培训数据集时，将用户请求翻译成数据流表达式的准确性的提高。"
    },
    {
        "title": "Redundancy Aware Multi-Reference Based Gainwise Evaluation of Extractive\n  Summarization",
        "url": "http://arxiv.org/abs/2308.02270v1",
        "pub_date": "2023-08-04",
        "summary": "While very popular for evaluating extractive summarization task, the ROUGE\nmetric has long been criticized for its lack of semantic awareness and its\nignorance about the ranking quality of the summarizer. Thanks to previous\nresearch that has addressed these issues by proposing a gain-based automated\nmetric called Sem-nCG, which is both rank and semantic aware. However, Sem-nCG\ndoes not consider the amount of redundancy present in a model-generated summary\nand currently does not support evaluation with multiple reference summaries.\nUnfortunately, addressing both these limitations simultaneously is not trivial.\nTherefore, in this paper, we propose a redundancy-aware Sem-nCG metric and\ndemonstrate how this new metric can be used to evaluate model summaries against\nmultiple references. We also explore different ways of incorporating redundancy\ninto the original metric through extensive experiments. Experimental results\ndemonstrate that the new redundancy-aware metric exhibits a higher correlation\nwith human judgments than the original Sem-nCG metric for both single and\nmultiple reference scenarios.",
        "translated": "ROUGE 度量在评价抽取摘要任务时非常流行，但长期以来一直受到批评，认为它缺乏语义意识，忽视了摘要器的排序质量。由于以前的研究已经解决了这些问题，提出了一个基于增益的自动化度量称为 Sem-nCG，这是既有等级和语义感知。然而，Sem-nCG 不考虑模型生成的摘要中存在的冗余量，目前不支持使用多个参考摘要进行评估。不幸的是，同时解决这两个限制并非易事。因此，在本文中，我们提出了一个冗余感知的 Sem-nCG 度量，并演示了如何使用这个新的度量来评估多个参考文献的模型摘要。我们还通过广泛的实验探索了将冗余合并到原始度量中的不同方法。实验结果表明，对于单个和多个参考场景，新的冗余感知度量与人类判断的相关性均高于原来的 Sem-nCG 度量。"
    },
    {
        "title": "Efficient Monaural Speech Enhancement using Spectrum Attention Fusion",
        "url": "http://arxiv.org/abs/2308.02263v1",
        "pub_date": "2023-08-04",
        "summary": "Speech enhancement is a demanding task in automated speech processing\npipelines, focusing on separating clean speech from noisy channels. Transformer\nbased models have recently bested RNN and CNN models in speech enhancement,\nhowever at the same time they are much more computationally expensive and\nrequire much more high quality training data, which is always hard to come by.\nIn this paper, we present an improvement for speech enhancement models that\nmaintains the expressiveness of self-attention while significantly reducing\nmodel complexity, which we have termed Spectrum Attention Fusion. We carefully\nconstruct a convolutional module to replace several self-attention layers in a\nspeech Transformer, allowing the model to more efficiently fuse spectral\nfeatures. Our proposed model is able to achieve comparable or better results\nagainst SOTA models but with significantly smaller parameters (0.58M) on the\nVoice Bank + DEMAND dataset.",
        "translated": "在自动语音处理流水线中，语音增强是一项要求很高的任务，重点是将清晰的语音从嘈杂的信道中分离出来。基于变压器的模型最近在语音增强上打败了 RNN 和 CNN 模型，但同时它们的计算成本更高，需要更高质量的训练数据，而这些数据总是很难获得。在本文中，我们提出了一个改进的语音增强模型，保持自我注意的表达能力，同时大大降低模型的复杂性，我们称之为频谱注意融合。我们仔细构造了一个卷积模块来代替语音变压器中的几个自我注意层，使模型能够更有效地融合频谱特征。我们提出的模型能够实现可比较或更好的结果与 SOTA 模型，但与显着较小的参数(0.58 M)在语音银行 + DEMAND 数据集。"
    },
    {
        "title": "Sinhala-English Parallel Word Dictionary Dataset",
        "url": "http://arxiv.org/abs/2308.02234v1",
        "pub_date": "2023-08-04",
        "summary": "Parallel datasets are vital for performing and evaluating any kind of\nmultilingual task. However, in the cases where one of the considered language\npairs is a low-resource language, the existing top-down parallel data such as\ncorpora are lacking in both tally and quality due to the dearth of human\nannotation. Therefore, for low-resource languages, it is more feasible to move\nin the bottom-up direction where finer granular pairs such as dictionary\ndatasets are developed first. They may then be used for mid-level tasks such as\nsupervised multilingual word embedding alignment. These in turn can later guide\nhigher-level tasks in the order of aligning sentence or paragraph text corpora\nused for Machine Translation (MT). Even though more approachable than\ngenerating and aligning a massive corpus for a low-resource language, for the\nsame reason of apathy from larger research entities, even these finer granular\ndata sets are lacking for some low-resource languages. We have observed that\nthere is no free and open dictionary data set for the low-resource language,\nSinhala. Thus, in this work, we introduce three parallel English-Sinhala word\ndictionaries (En-Si-dict-large, En-Si-dict-filtered, En-Si-dict-FastText) which\nhelp in multilingual Natural Language Processing (NLP) tasks related to English\nand Sinhala languages. In this paper, we explain the dataset creation pipeline\nas well as the experimental results of the tests we have carried out to verify\nthe quality of the data sets. The data sets and the related scripts are\navailable at https://github.com/kasunw22/sinhala-para-dict.",
        "translated": "并行数据集对于执行和评估任何类型的多语言任务都是至关重要的。然而，在考虑的语言对之一是低资源语言的情况下，由于缺乏人工注释，现有的自顶向下的并行数据(如语料库)在计数和质量方面都存在缺陷。因此，对于资源较少的语言来说，首先开发字典数据集等更精细的粒度对的方法是自底向上的。然后它们可以用于中级任务，例如监督的多语言单词嵌入对齐。这些反过来又可以指导更高层次的任务按照对齐句子或段落文本语料库的顺序用于机器翻译(MT)。尽管比为一种低资源语言生成和调整一个大规模语料库更容易接近，但出于同样的原因，大型研究实体对此漠不关心，对于一些低资源语言来说，即使是这些更精细的粒度数据集也是缺乏的。我们已经观察到，没有免费和开放的字典数据集为低资源语言，僧伽罗。因此，在这项工作中，我们介绍了三个平行的英语-僧伽罗语词典(En-Si-dict-large，En-Si-dict-filter，En-Si-dict-FastText) ，它们可以帮助处理与英语和僧伽罗语相关的多语言自然语言处理(NLP)任务。本文介绍了数据集的创建流程，以及为验证数据集质量而进行的测试的实验结果。数据集和相关脚本可在 https://github.com/kasunw22/sinhala-para-dict 查阅。"
    },
    {
        "title": "Randomized algorithms for precise measurement of differentially-private,\n  personalized recommendations",
        "url": "http://arxiv.org/abs/2308.03735v1",
        "pub_date": "2023-08-07",
        "summary": "Personalized recommendations form an important part of today's internet\necosystem, helping artists and creators to reach interested users, and helping\nusers to discover new and engaging content. However, many users today are\nskeptical of platforms that personalize recommendations, in part due to\nhistorically careless treatment of personal data and data privacy. Now,\nbusinesses that rely on personalized recommendations are entering a new\nparadigm, where many of their systems must be overhauled to be privacy-first.\nIn this article, we propose an algorithm for personalized recommendations that\nfacilitates both precise and differentially-private measurement. We consider\nadvertising as an example application, and conduct offline experiments to\nquantify how the proposed privacy-preserving algorithm affects key metrics\nrelated to user experience, advertiser value, and platform revenue compared to\nthe extremes of both (private) non-personalized and non-private, personalized\nimplementations.",
        "translated": "个性化推荐构成了当今互联网生态系统的重要组成部分，它帮助艺术家和创作者接触到感兴趣的用户，并帮助用户发现新的和有吸引力的内容。然而，今天许多用户对个性化推荐的平台持怀疑态度，部分原因是历史上对个人数据和数据隐私的粗心处理。现在，依赖个性化推荐的企业正在进入一个新的范式，它们的许多系统必须进行彻底改造，以实现隐私优先。在本文中，我们提出了一种个性化推荐的算法，它可以促进精确和差异私有测量。我们将广告作为一个示例应用程序，并进行离线实验，以量化所提议的隐私保护算法如何影响与用户体验，广告客户价值和平台收入相关的关键指标，与(私有)非个性化和非私有，个性化实现的极端情况相比。"
    },
    {
        "title": "Labeling without Seeing? Blind Annotation for Privacy-Preserving Entity\n  Resolution",
        "url": "http://arxiv.org/abs/2308.03734v1",
        "pub_date": "2023-08-07",
        "summary": "The entity resolution problem requires finding pairs across datasets that\nbelong to different owners but refer to the same entity in the real world. To\ntrain and evaluate solutions (either rule-based or machine-learning-based) to\nthe entity resolution problem, generating a ground truth dataset with entity\npairs or clusters is needed. However, such a data annotation process involves\nhumans as domain oracles to review the plaintext data for all candidate record\npairs from different parties, which inevitably infringes the privacy of data\nowners, especially in privacy-sensitive cases like medical records. To the best\nof our knowledge, there is no prior work on privacy-preserving ground truth\ndataset generation, especially in the domain of entity resolution. We propose a\nnovel blind annotation protocol based on homomorphic encryption that allows\ndomain oracles to collaboratively label ground truths without sharing data in\nplaintext with other parties. In addition, we design a domain-specific\neasy-to-use language that hides the sophisticated underlying homomorphic\nencryption layer. Rigorous proof of the privacy guarantee is provided and our\nempirical experiments via an annotation simulator indicate the feasibility of\nour privacy-preserving protocol (f-measure on average achieves more than 90\\%\ncompared with the real ground truths).",
        "translated": "实体解析问题需要在属于不同所有者但在现实世界中引用相同实体的数据集之间找到对。为了训练和评估实体分辨率问题的解决方案(基于规则或基于机器学习) ，需要生成带有实体对或聚类的地面真实数据集。然而，这样的数据注释过程需要人类作为领域预言者来审查来自不同方面的所有候选记录对的明文数据，这不可避免地侵犯了数据所有者的隐私，特别是在医疗记录等对隐私敏感的情况下。据我们所知，目前还没有关于保护隐私的地面真实数据集生成的研究，特别是在实体解析领域。我们提出了一种新的基于同态加密的盲注协议，允许域预言者协同标记地面真相，而不需要与其他方共享明文数据。此外，我们还设计了一种特定领域的易于使用的语言，隐藏了复杂的底层同态加密。通过注释模拟器的实验验证了本文提出的隐私保护协议的可行性(与真实基本事实相比，f 测度平均达到90% 以上)。"
    },
    {
        "title": "Multi-View Graph Convolutional Network for Multimedia Recommendation",
        "url": "http://arxiv.org/abs/2308.03588v1",
        "pub_date": "2023-08-07",
        "summary": "Multimedia recommendation has received much attention in recent years. It\nmodels user preferences based on both behavior information and item multimodal\ninformation. Though current GCN-based methods achieve notable success, they\nsuffer from two limitations: (1) Modality noise contamination to the item\nrepresentations. Existing methods often mix modality features and behavior\nfeatures in a single view (e.g., user-item view) for propagation, the noise in\nthe modality features may be amplified and coupled with behavior features. In\nthe end, it leads to poor feature discriminability; (2) Incomplete user\npreference modeling caused by equal treatment of modality features. Users often\nexhibit distinct modality preferences when purchasing different items. Equally\nfusing each modality feature ignores the relative importance among different\nmodalities, leading to the suboptimal user preference modeling. To tackle the\nabove issues, we propose a novel Multi-View Graph Convolutional Network for the\nmultimedia recommendation. Specifically, to avoid modality noise contamination,\nthe modality features are first purified with the aid of item behavior\ninformation. Then, the purified modality features of items and behavior\nfeatures are enriched in separate views, including the user-item view and the\nitem-item view. In this way, the distinguishability of features is enhanced.\nMeanwhile, a behavior-aware fuser is designed to comprehensively model user\npreferences by adaptively learning the relative importance of different\nmodality features. Furthermore, we equip the fuser with a self-supervised\nauxiliary task. This task is expected to maximize the mutual information\nbetween the fused multimodal features and behavior features, so as to capture\ncomplementary and supplementary preference information simultaneously.\nExtensive experiments on three public datasets demonstrate the effectiveness of\nour methods.",
        "translated": "多媒体推荐近年来受到了广泛的关注。它基于行为信息和项目多通道信息建模用户首选项。虽然目前基于 GCN 的方法取得了显著的成功，但它们仍然存在两个局限性: (1)对项目表示的模态噪声污染。现有的方法往往混合模态特征和行为特征在一个单一的视图(例如，用户项目视图)传播，噪声的模态特征可能被放大，并与行为特征耦合。结果表明: (2)模态特征的平等处理导致了用户偏好建模的不完全性。用户在购买不同商品时，通常会表现出不同的模式偏好。同样地融合每个模态特征忽略了不同模态之间的相对重要性，导致用户偏好建模次优。为了解决上述问题，我们提出了一种新的多视图图卷积网络的多媒体推荐。具体来说，为了避免情态噪声污染，首先借助项目行为信息对情态特征进行净化。在此基础上，分别从用户项目视图和项目项目视图两个视图对项目的纯化情态特征和行为特征进行了丰富。通过这种方式，特征的可区分性得到了增强。同时，设计了一个行为感知融合器，通过自适应学习不同情态特征的相对重要性，对用户偏好进行综合建模。此外，我们还设置了一个自我监督的辅助任务。该任务期望最大化融合多模态特征和行为特征之间的相互信息，以便同时捕获互补和补充的偏好信息。在三个公共数据集上的大量实验证明了我们方法的有效性。"
    },
    {
        "title": "TeraHAC: Hierarchical Agglomerative Clustering of Trillion-Edge Graphs",
        "url": "http://arxiv.org/abs/2308.03578v1",
        "pub_date": "2023-08-07",
        "summary": "We introduce TeraHAC, a $(1+\\epsilon)$-approximate hierarchical agglomerative\nclustering (HAC) algorithm which scales to trillion-edge graphs. Our algorithm\nis based on a new approach to computing $(1+\\epsilon)$-approximate HAC, which\nis a novel combination of the nearest-neighbor chain algorithm and the notion\nof $(1+\\epsilon)$-approximate HAC. Our approach allows us to partition the\ngraph among multiple machines and make significant progress in computing the\nclustering within each partition before any communication with other partitions\nis needed.\n  We evaluate TeraHAC on a number of real-world and synthetic graphs of up to 8\ntrillion edges. We show that TeraHAC requires over 100x fewer rounds compared\nto previously known approaches for computing HAC. It is up to 8.3x faster than\nSCC, the state-of-the-art distributed algorithm for hierarchical clustering,\nwhile achieving 1.16x higher quality. In fact, TeraHAC essentially retains the\nquality of the celebrated HAC algorithm while significantly improving the\nrunning time.",
        "translated": "我们介绍 TeraHAC，一个 $(1 + epsilon) $- 近似层次聚集聚类(HAC)算法，它可以扩展到万亿边图。我们的算法是基于计算 $(1 + epsilon) $- 近似 HAC 的新方法，这是最近邻链算法和 $(1 + epsilon) $- 近似 HAC 概念的新组合。我们的方法允许我们在多个机器之间划分图，并且在需要与其他分区通信之前，在每个分区内的集群计算方面取得重大进展。我们评估 TeraHAC 在现实世界和多达8万亿条边的合成图的数量。我们展示了与以前已知的计算 HAC 的方法相比，TeraHAC 需要的子弹数量减少了100多倍。它比最先进的分层集群分散式演算法 SCC 快了8.3倍，同时质量提高了1.16倍。实际上，TeraHAC 基本上保留了著名 HAC 算法的质量，同时显著提高了运行时间。"
    },
    {
        "title": "Global cognitive graph properties dynamics of hippocampal formation",
        "url": "http://arxiv.org/abs/2308.03563v1",
        "pub_date": "2023-08-07",
        "summary": "In the present study we have used a set of methods and metrics to build a\ngraph of relative neural connections in a hippocampus of a rodent. A set of\ngraphs was built on top of time-sequenced data and analyzed in terms of\ndynamics of a connection genesis. The analysis has shown that during the\nprocess of a rodent exploring a novel environment, the relations between\nneurons constantly change which indicates that globally memory is constantly\nupdated even for known areas of space. Even if some neurons gain cognitive\nspecialization, the global network though remains relatively stable.\nAdditionally we suggest a set of methods for building a graph of cognitive\nneural network.",
        "translated": "在目前的研究中，我们已经使用了一套方法和指标来建立一个图表的相关神经连接在啮齿动物的海马。在时间序列数据的基础上建立了一组图，并根据连接起源的动力学进行了分析。分析表明，在啮齿动物探索新环境的过程中，神经元之间的关系不断变化，这表明即使对于已知的空间区域，全局记忆也在不断更新。即使一些神经元获得了认知专门化，整体网络仍然保持相对稳定。此外，本文还提出了一套构建认知神经网络图的方法。"
    },
    {
        "title": "What about translation? New coding system for content analysis on the\n  perception of literary translation around the political transformation in\n  1989 in Hungary as a classification problem on an unbalanced dataset",
        "url": "http://arxiv.org/abs/2308.03742v1",
        "pub_date": "2023-08-07",
        "summary": "To track trends in the perception of literary translation around the\npolitical transformation in 1989 in Hungary, a coding system was developed on\nthe paragraphs of the 1980-1999 issues of the literary journal Alf\\\"old. This\npaper describes how we trained BERT models to carry over the coding system to\nthe 1980-1999 issues of the literary journal Nagyvil\\'ag. We use extensive\nhyperparameter tuning, loss functions robust to label unbalance, 10-fold\ncross-validation for precise evaluations and a model ensemble for prediction,\nmanual validation on the predict set, a new calibration method to better\npredict label counts for sections of the Nagyvil\\'ag corpus, and to study the\nrelations between labels, we construct label relation networks.",
        "translated": "为了追踪1989年匈牙利政治变革前后文学翻译观念的变化趋势，在1980-1999年期的文学杂志《 Alf”old 》上发展了一套编码系统。本文介绍了我们如何训练 BERT 模型，以便将编码系统延伸到1980-1999年的文学期刊《 Nagyvil‘ ag 》。我们使用广泛的超参数调整，强大的损失函数标记不平衡，10倍交叉验证精确评估和预测模型集合，手动验证预测集，一个新的校准方法，以更好地预测标签计数的 Nagyvil’ag 语料库的部分，并研究标签之间的关系，我们建立标签关系网络。"
    },
    {
        "title": "AgentBench: Evaluating LLMs as Agents",
        "url": "http://arxiv.org/abs/2308.03688v1",
        "pub_date": "2023-08-07",
        "summary": "Large Language Models (LLMs) are becoming increasingly smart and autonomous,\ntargeting real-world pragmatic missions beyond traditional NLP tasks. As a\nresult, there has been an urgent need to evaluate LLMs as agents on challenging\ntasks in interactive environments. We present AgentBench, a multi-dimensional\nevolving benchmark that currently consists of 8 distinct environments to assess\nLLM-as-Agent's reasoning and decision-making abilities in a multi-turn\nopen-ended generation setting. Our extensive test over 25 LLMs (including APIs\nand open-sourced models) shows that, while top commercial LLMs present a strong\nability of acting as agents in complex environments, there is a significant\ndisparity in performance between them and open-sourced competitors. It also\nserves as a component of an ongoing project with wider coverage and deeper\nconsideration towards systematic LLM evaluation. Datasets, environments, and an\nintegrated evaluation package for AgentBench are released at\nhttps://github.com/THUDM/AgentBench",
        "translated": "大语言模型(LLM)正变得越来越智能和自治，目标是超越传统 NLP 任务的现实世界的实用任务。因此，迫切需要评估 LLM 作为代理在交互环境中具有挑战性的任务。我们提出了 Agent Bench，一个多维演进的基准，目前由8个不同的环境组成，以评估 LLM 作为 Agent 的推理和决策能力在多回合开放式生成设置。我们对25个 LLM (包括 API 和开源模型)进行了广泛的测试，结果显示，尽管顶级商业 LLM 具有在复杂环境中充当代理的强大能力，但它们与开源竞争对手之间的性能存在显著差异。它还作为一个正在进行的项目的一个组成部分，对系统的长期管理评价具有更广泛的覆盖面和更深入的考虑。数据集、环境和一个针对 AgentBench 的集成评估包将在 https://github.com/thudm/AgentBench 发布"
    },
    {
        "title": "Detecting Spells in Fantasy Literature with a Transformer Based\n  Artificial Intelligence",
        "url": "http://arxiv.org/abs/2308.03660v1",
        "pub_date": "2023-08-07",
        "summary": "Transformer architectures and models have made significant progress in\nlanguage-based tasks. In this area, is BERT one of the most widely used and\nfreely available transformer architecture. In our work, we use BERT for\ncontext-based phrase recognition of magic spells in the Harry Potter novel\nseries. Spells are a common part of active magic in fantasy novels. Typically,\nspells are used in a specific context to achieve a supernatural effect. A\nseries of investigations were conducted to see if a Transformer architecture\ncould recognize such phrases based on their context in the Harry Potter saga.\nFor our studies a pre-trained BERT model was used and fine-tuned utilising\ndifferent datasets and training methods to identify the searched context. By\nconsidering different approaches for sequence classification as well as token\nclassification, it is shown that the context of spells can be recognised.\nAccording to our investigations, the examined sequence length for fine-tuning\nand validation of the model plays a significant role in context recognition.\nBased on this, we have investigated whether spells have overarching properties\nthat allow a transfer of the neural network models to other fantasy universes\nas well. The application of our model showed promising results and is worth to\nbe deepened in subsequent studies.",
        "translated": "变压器体系结构和模型在基于语言的任务中取得了重大进展。在这方面，BERT 是目前应用最广泛、可免费获得的变压器结构之一。在我们的工作中，我们使用 BERT 来识别基于上下文的哈利波特系列小说中的魔法咒语。咒语是奇幻小说中常见的魔法。一般来说，咒语是在特定的环境中使用，以达到超自然的效果。人们进行了一系列的调查，看看变形金刚架构能否根据哈利波特传奇中的上下文识别这些短语。在我们的研究中，使用了预先训练好的 BERT 模型，并利用不同的数据集和训练方法来识别搜索的上下文。通过考虑序列分类和标记分类的不同方法，表明可以识别咒语的上下文。根据我们的调查，被检查的序列长度为微调和验证模型在上下文识别中起着重要的作用。在此基础上，我们研究了咒语是否具有支配性质，允许将神经网络模型转移到其他幻想宇宙中。该模型的应用取得了良好的效果，值得进一步深入研究。"
    },
    {
        "title": "Emotionally Numb or Empathetic? Evaluating How LLMs Feel Using\n  EmotionBench",
        "url": "http://arxiv.org/abs/2308.03656v1",
        "pub_date": "2023-08-07",
        "summary": "Recently, the community has witnessed the advancement of Large Language\nModels (LLMs), which have shown remarkable performance on various downstream\ntasks. Led by powerful models like ChatGPT and Claude, LLMs are revolutionizing\nhow users engage with software, assuming more than mere tools but intelligent\nassistants. Consequently, evaluating LLMs' anthropomorphic capabilities becomes\nincreasingly important in contemporary discourse. Utilizing the emotion\nappraisal theory from psychology, we propose to evaluate the empathy ability of\nLLMs, i.e., how their feelings change when presented with specific situations.\nAfter a careful and comprehensive survey, we collect a dataset containing over\n400 situations that have proven effective in eliciting the eight emotions\ncentral to our study. Categorizing the situations into 36 factors, we conduct a\nhuman evaluation involving more than 1,200 subjects worldwide. With the human\nevaluation results as references, our evaluation includes five LLMs, covering\nboth commercial and open-source models, including variations in model sizes,\nfeaturing the latest iterations, such as GPT-4 and LLaMA 2. A conclusion can be\ndrawn from the results that, despite several misalignments, LLMs can generally\nrespond appropriately to certain situations. Nevertheless, they fall short in\nalignment with the emotional behaviors of human beings and cannot establish\nconnections between similar situations. Our collected dataset of situations,\nthe human evaluation results, and the code of our testing framework, dubbed\nEmotionBench, is made publicly in https://github.com/CUHK-ARISE/EmotionBench.\nWe aspire to contribute to the advancement of LLMs regarding better alignment\nwith the emotional behaviors of human beings, thereby enhancing their utility\nand applicability as intelligent assistants.",
        "translated": "最近，社区见证了大语言模型(LLM)的进步，它在各种下游任务中表现出了显著的性能。在 ChatGPT 和 Claude 等强大模型的带领下，LLM 正在彻底改变用户使用软件的方式，它不仅仅假设用户使用工具，还假设用户使用智能助手。因此，评价 LLM 的拟人能力在当代语篇中变得越来越重要。利用心理学中的情绪评价理论，我们提出评价 LLM 的移情能力，即当他们面对特定情境时，他们的情绪是如何变化的。经过仔细和全面的调查，我们收集了超过400种情况的数据集，这些情况已经证明能够有效地激发我们研究的八种情绪。我们将情况分为36个因素，对全世界1200多个受试者进行人体评估。以人类评估结果为参考，我们的评估包括五个 LLM，涵盖了商业模型和开源模型，包括模型大小的变化，具有最新的迭代，如 GPT-4和 LLaMA 2。从结果中可以得出一个结论，尽管有几个失调，LLM 通常可以适当地响应某些情况。然而，它们不符合人类的情感行为，也不能在类似的情况之间建立联系。我们收集的情况数据集，人类评估结果，以及我们测试框架的代码，被称为 emotionBench，都是以 https://github.com/cuhk-arise/EmotionBench 的形式公开的。我们渴望为 LLM 的进步做出贡献，使其更好地与人类的情感行为保持一致，从而提高其作为智能助手的实用性和适用性。"
    },
    {
        "title": "KITLM: Domain-Specific Knowledge InTegration into Language Models for\n  Question Answering",
        "url": "http://arxiv.org/abs/2308.03638v1",
        "pub_date": "2023-08-07",
        "summary": "Large language models (LLMs) have demonstrated remarkable performance in a\nwide range of natural language tasks. However, as these models continue to grow\nin size, they face significant challenges in terms of computational costs.\nAdditionally, LLMs often lack efficient domain-specific understanding, which is\nparticularly crucial in specialized fields such as aviation and healthcare. To\nboost the domain-specific understanding, we propose, KITLM, a novel knowledge\nbase integration approach into language model through relevant information\ninfusion. By integrating pertinent knowledge, not only the performance of the\nlanguage model is greatly enhanced, but the model size requirement is also\nsignificantly reduced while achieving comparable performance. Our proposed\nknowledge-infused model surpasses the performance of both GPT-3.5-turbo and the\nstate-of-the-art knowledge infusion method, SKILL, achieving over 1.5 times\nimprovement in exact match scores on the MetaQA. KITLM showed a similar\nperformance boost in the aviation domain with AeroQA. The drastic performance\nimprovement of KITLM over the existing methods can be attributed to the\ninfusion of relevant knowledge while mitigating noise. In addition, we release\ntwo curated datasets to accelerate knowledge infusion research in specialized\nfields: a) AeroQA, a new benchmark dataset designed for multi-hop\nquestion-answering within the aviation domain, and b) Aviation Corpus, a\ndataset constructed from unstructured text extracted from the National\nTransportation Safety Board reports. Our research contributes to advancing the\nfield of domain-specific language understanding and showcases the potential of\nknowledge infusion techniques in improving the performance of language models\non question-answering.",
        "translated": "大型语言模型(LLM)已经在很多自然语言任务中表现出了显著的性能。然而，随着这些模型规模的不断扩大，它们在计算成本方面面临着巨大的挑战。此外，LLM 通常缺乏有效的领域特定理解，这在航空和医疗保健等专业领域尤为关键。为了提高对特定领域的理解，我们建议 KITLM 采用一种新颖的知识库整合方法，通过相关的信息输入将知识库整合到语言模型中。通过集成相关知识，不仅大大提高了语言模型的性能，而且在实现可比性的同时，大大减少了模型的规模需求。我们提出的知识注入模型超过了 GPT-3.5-turbo 和最先进的知识注入方法 SKILL 的性能，在 MetaQA 上实现了超过1.5倍的精确匹配分数提高。KITLM 在航空领域的 AeroQA 也有类似的性能提升。KITLM 算法相对于现有算法性能的显著提高归功于在消除噪声的同时注入了相关的知识。此外，我们还发布了两个策划数据集，以加速专业领域的知识输入研究: a) AeroQA，一个新的基准数据集，设计用于航空领域内的多跳问题回答; b)航空语料库，一个从国家运输安全委员会报告中提取的非结构化文本构建的数据集。我们的研究有助于推进领域特定语言理解领域，并展示了知识输入技术在提高问答语言模型的表现方面的潜力。"
    },
    {
        "title": "MedMine: Examining Pre-trained Language Models on Medication Mining",
        "url": "http://arxiv.org/abs/2308.03629v2",
        "pub_date": "2023-08-07",
        "summary": "Automatic medication mining from clinical and biomedical text has become a\npopular topic due to its real impact on healthcare applications and the recent\ndevelopment of powerful language models (LMs). However, fully-automatic\nextraction models still face obstacles to be overcome such that they can be\ndeployed directly into clinical practice for better impacts. Such obstacles\ninclude their imbalanced performances on different entity types and clinical\nevents. In this work, we examine current state-of-the-art pre-trained language\nmodels (PLMs) on such tasks, via fine-tuning including the monolingual model\nMed7 and multilingual large language model (LLM) XLM-RoBERTa. We compare their\nadvantages and drawbacks using historical medication mining shared task data\nsets from n2c2-2018 challenges. We report the findings we get from these\nfine-tuning experiments such that they can facilitate future research on\naddressing them, for instance, how to combine their outputs, merge such models,\nor improve their overall accuracy by ensemble learning and data augmentation.\nMedMine is part of the M3 Initiative \\url{https://github.com/HECTA-UoM/M3}",
        "translated": "从临床和生物医学文本中自动挖掘药物已成为一个热门的话题，由于其对医疗保健应用的实际影响和强大的语言模型(LM)的最新发展。然而，全自动提取模型仍然面临着需要克服的障碍，因为它们可以直接部署到临床实践中以获得更好的效果。这些障碍包括它们在不同实体类型和临床事件上的不平衡表现。在这项工作中，我们检查目前最先进的预训练语言模型(PLM)对这些任务，通过微调包括单语言模型 Med7和多语言大语言模型(LLM) XLM-RoBERTa。我们使用来自 n2c2-2018挑战的历史药物挖掘共享任务数据集来比较它们的优缺点。我们报告从这些微调实验中得到的发现，这样它们可以促进未来解决这些问题的研究，例如，如何结合它们的输出，合并这些模型，或通过集成学习和数据增强提高它们的整体准确性。MedMine 是 M3 https://github.com/hecta-uom/m3的一部分"
    },
    {
        "title": "Negative Lexical Constraints in Neural Machine Translation",
        "url": "http://arxiv.org/abs/2308.03601v1",
        "pub_date": "2023-08-07",
        "summary": "This paper explores negative lexical constraining in English to Czech neural\nmachine translation. Negative lexical constraining is used to prohibit certain\nwords or expressions in the translation produced by the neural translation\nmodel. We compared various methods based on modifying either the decoding\nprocess or the training data. The comparison was performed on two tasks:\nparaphrasing and feedback-based translation refinement. We also studied to\nwhich extent these methods \"evade\" the constraints presented to the model\n(usually in the dictionary form) by generating a different surface form of a\ngiven constraint.We propose a way to mitigate the issue through training with\nstemmed negative constraints to counter the model's ability to induce a variety\nof the surface forms of a word that can result in bypassing the constraint. We\ndemonstrate that our method improves the constraining, although the problem\nstill persists in many cases.",
        "translated": "本文探讨了英捷神经机器翻译中的负词汇约束。在神经翻译模型的翻译过程中，负词汇约束是用来禁止某些词或表达的。我们比较了基于修改译码过程或训练数据的各种方法。对两个任务进行比较: 释义和基于反馈的翻译细化。我们还研究了这些方法在多大程度上通过生成给定约束的不同表面形式来“规避”模型(通常以字典形式)所呈现的约束。我们提出了一种通过训练来缓解问题的方法，通过消极约束来对抗模型诱导各种表面形式的能力，可以导致绕过约束。我们展示了我们的方法改进了约束，尽管问题在许多情况下仍然存在。"
    },
    {
        "title": "WIKITIDE: A Wikipedia-Based Timestamped Definition Pairs Dataset",
        "url": "http://arxiv.org/abs/2308.03582v1",
        "pub_date": "2023-08-07",
        "summary": "A fundamental challenge in the current NLP context, dominated by language\nmodels, comes from the inflexibility of current architectures to 'learn' new\ninformation. While model-centric solutions like continual learning or\nparameter-efficient fine tuning are available, the question still remains of\nhow to reliably identify changes in language or in the world. In this paper, we\npropose WikiTiDe, a dataset derived from pairs of timestamped definitions\nextracted from Wikipedia. We argue that such resource can be helpful for\naccelerating diachronic NLP, specifically, for training models able to scan\nknowledge resources for core updates concerning a concept, an event, or a named\nentity. Our proposed end-to-end method is fully automatic, and leverages a\nbootstrapping algorithm for gradually creating a high-quality dataset. Our\nresults suggest that bootstrapping the seed version of WikiTiDe leads to better\nfine-tuned models. We also leverage fine-tuned models in a number of downstream\ntasks, showing promising results with respect to competitive baselines.",
        "translated": "在当前由语言模型主导的 NLP 环境中，一个根本性的挑战来自于当前体系结构在“学习”新信息方面的不灵活性。虽然像持续学习或参数高效微调这样的以模型为中心的解决方案是可用的，但问题仍然是如何可靠地识别语言或世界中的变化。在本文中，我们提出了 WikiTiDe，一个从维基百科中提取的时间戳定义对派生出来的数据集。我们认为，这样的资源可以有助于加速历时自然语言处理，特别是培训模型，能够扫描知识资源的核心更新有关的概念，事件，或命名的实体。我们提出的端到端方法是完全自动的，并利用自举算法逐步创建高质量的数据集。我们的研究结果表明，引导 WikiTiDe 的种子版本可以得到更好的调优模型。我们还在一些下游任务中利用微调模型，在竞争基线方面显示出有希望的结果。"
    },
    {
        "title": "Towards Controllable Natural Language Inference through Lexical\n  Inference Types",
        "url": "http://arxiv.org/abs/2308.03581v1",
        "pub_date": "2023-08-07",
        "summary": "Explainable natural language inference aims to provide a mechanism to produce\nexplanatory (abductive) inference chains which ground claims to their\nsupporting premises. A recent corpus called EntailmentBank strives to advance\nthis task by explaining the answer to a question using an entailment tree\n\\cite{dalvi2021explaining}. They employ the T5 model to directly generate the\ntree, which can explain how the answer is inferred. However, it lacks the\nability to explain and control the generation of intermediate steps, which is\ncrucial for the multi-hop inference process. % One recent corpus,\nEntailmentBank, aims to push this task forward by explaining an answer to a\nquestion according to an entailment tree \\cite{dalvi2021explaining}. They\nemploy T5 to generate the tree directly, which can explain how the answer is\ninferred but cannot explain how the intermediate is generated, which is\nessential to the multi-hop inference process. In this work, we focus on\nproposing a controlled natural language inference architecture for\nmulti-premise explanatory inference. To improve control and enable explanatory\nanalysis over the generation, we define lexical inference types based on\nAbstract Meaning Representation (AMR) graph and modify the architecture of T5\nto learn a latent sentence representation (T5 bottleneck) conditioned on said\ntype information. We also deliver a dataset of approximately 5000 annotated\nexplanatory inference steps, with well-grounded lexical-symbolic operations.\nExperimental results indicate that the inference typing induced at the T5\nbottleneck can help T5 to generate a conclusion under explicit control.",
        "translated": "可解释的自然语言推理旨在提供一种机制，以产生解释性(溯因)推理链条，这些链条将主张建立在其支持前提之上。最近的一个名为 EntailmentBank 的语料库试图通过使用一个蕴涵树引用{ dalvi2021description }来解释问题的答案，从而推进这项任务。他们使用 T5模型直接生成树，这可以解释如何推断出答案。然而，它缺乏解释和控制中间步骤生成的能力，这对于多跳推理过程是至关重要的。% 最近的一个语料库，EntailmentBank，旨在通过解释一个问题的答案来推进这项任务。它们使用 T5直接生成树，这可以解释如何推断出答案，但不能解释如何生成中间层，这对于多跳推理过程是必不可少的。在这项工作中，我们重点提出了一个控制自然语言推理架构的多前提解释性推理。为了提高控制能力并实现生成过程中的解释性分析，我们定义了基于抽象意义表示(AMR)图的词汇推理类型，并修改了 T5的结构来学习基于类型信息的潜在句子表示(T5瓶颈)。我们还提供了大约5000个带注释的解释性推理步骤的数据集，这些步骤都有充分的词汇-符号操作。实验结果表明，在 T5瓶颈处诱发的推理类型可以帮助 T5在显性控制下得出结论。"
    },
    {
        "title": "Topological Interpretations of GPT-3",
        "url": "http://arxiv.org/abs/2308.03565v2",
        "pub_date": "2023-08-07",
        "summary": "This is an experiential study of investigating a consistent method for\nderiving the correlation between sentence vector and semantic meaning of a\nsentence. We first used three state-of-the-art word/sentence embedding methods\nincluding GPT-3, Word2Vec, and Sentence-BERT, to embed plain text sentence\nstrings into high dimensional spaces. Then we compute the pairwise distance\nbetween any possible combination of two sentence vectors in an embedding space\nand map them into a matrix. Based on each distance matrix, we compute the\ncorrelation of distances of a sentence vector with respect to the other\nsentence vectors in an embedding space. Then we compute the correlation of each\npair of the distance matrices. We observed correlations of the same sentence in\ndifferent embedding spaces and correlations of different sentences in the same\nembedding space. These observations are consistent with our hypothesis and take\nus to the next stage.",
        "translated": "这是一个经验研究，探讨一致的方法来推导之间的相关性，句子向量和语义的一个句子。我们首先使用三种最先进的单词/句子嵌入方法，包括 GPT-3、 Word2Vec 和 Sentence-BERT，将纯文本句子字符串嵌入到高维空间中。然后计算嵌入空间中两个句子向量的任意可能组合之间的成对距离，并将它们映射到矩阵中。基于每个距离矩阵，我们计算嵌入空间中一个句子向量相对于其他句子向量的距离的相关性。然后我们计算每对距离矩阵的相关性。我们观察到同一个句子在不同的嵌入空间中的相关性，以及不同的句子在同一个嵌入空间中的相关性。这些观察结果与我们的假设一致，并将我们带入下一个阶段。"
    },
    {
        "title": "Your Negative May not Be True Negative: Boosting Image-Text Matching\n  with False Negative Elimination",
        "url": "http://arxiv.org/abs/2308.04380v1",
        "pub_date": "2023-08-08",
        "summary": "Most existing image-text matching methods adopt triplet loss as the\noptimization objective, and choosing a proper negative sample for the triplet\nof &lt;anchor, positive, negative&gt; is important for effectively training the\nmodel, e.g., hard negatives make the model learn efficiently and effectively.\nHowever, we observe that existing methods mainly employ the most similar\nsamples as hard negatives, which may not be true negatives. In other words, the\nsamples with high similarity but not paired with the anchor may reserve\npositive semantic associations, and we call them false negatives. Repelling\nthese false negatives in triplet loss would mislead the semantic representation\nlearning and result in inferior retrieval performance. In this paper, we\npropose a novel False Negative Elimination (FNE) strategy to select negatives\nvia sampling, which could alleviate the problem introduced by false negatives.\nSpecifically, we first construct the distributions of positive and negative\nsamples separately via their similarities with the anchor, based on the\nfeatures extracted from image and text encoders. Then we calculate the false\nnegative probability of a given sample based on its similarity with the anchor\nand the above distributions via the Bayes' rule, which is employed as the\nsampling weight during negative sampling process. Since there may not exist any\nfalse negative in a small batch size, we design a memory module with momentum\nto retain a large negative buffer and implement our negative sampling strategy\nspanning over the buffer. In addition, to make the model focus on hard\nnegatives, we reassign the sampling weights for the simple negatives with a\ncut-down strategy. The extensive experiments are conducted on Flickr30K and\nMS-COCO, and the results demonstrate the superiority of our proposed false\nnegative elimination strategy. The code is available at\nhttps://github.com/LuminosityX/FNE.",
        "translated": "现有的图像-文本匹配方法大多采用三元组丢失作为优化目标，为“锚”、“正”、“负”三元组选择合适的负样本对于有效地训练模型至关重要，例如，硬负样本可以使模型有效地学习。然而，我们观察到，现有的方法主要使用最相似的样本作为硬负，这可能不是真正的负。换句话说，具有高度相似性但不与锚配对的样本可能保留正的语义关联，我们称之为假否定。在三联体丢失中排斥这些假否定会误导语义表征学习，导致提取效果不佳。本文提出了一种新的通过抽样来选择否定的假否定消除(FNE)策略，这种策略可以缓解假否定带来的问题。具体来说，我们首先根据从图像和文本编码器中提取的特征，通过与锚点的相似性分别构造正样本和负样本的分布。然后，我们根据样本与锚点的相似性，以及上述分布，通过贝叶斯规则计算出假负概率，这个规则在负抽样过程中被用作抽样权重。由于在小批量情况下可能不存在任何假阴性，我们设计了一个具有动量的存储模块来保留一个较大的阴性缓冲区，并在缓冲区上实现了负采样策略。此外，为了使模型集中在硬负面，我们重新分配权重的简单负面与削减策略。在 Flickr30K 和 MS-COCO 上进行了广泛的实验，实验结果表明了我们提出的假阴性消除策略的优越性。密码可在 https://github.com/luminosityx/fne 查阅。"
    },
    {
        "title": "Unifying Two-Stream Encoders with Transformers for Cross-Modal Retrieval",
        "url": "http://arxiv.org/abs/2308.04343v1",
        "pub_date": "2023-08-08",
        "summary": "Most existing cross-modal retrieval methods employ two-stream encoders with\ndifferent architectures for images and texts, \\textit{e.g.}, CNN for images and\nRNN/Transformer for texts. Such discrepancy in architectures may induce\ndifferent semantic distribution spaces and limit the interactions between\nimages and texts, and further result in inferior alignment between images and\ntexts. To fill this research gap, inspired by recent advances of Transformers\nin vision tasks, we propose to unify the encoder architectures with\nTransformers for both modalities. Specifically, we design a cross-modal\nretrieval framework purely based on two-stream Transformers, dubbed\n\\textbf{Hierarchical Alignment Transformers (HAT)}, which consists of an image\nTransformer, a text Transformer, and a hierarchical alignment module. With such\nidentical architectures, the encoders could produce representations with more\nsimilar characteristics for images and texts, and make the interactions and\nalignments between them much easier. Besides, to leverage the rich semantics,\nwe devise a hierarchical alignment scheme to explore multi-level\ncorrespondences of different layers between images and texts. To evaluate the\neffectiveness of the proposed HAT, we conduct extensive experiments on two\nbenchmark datasets, MSCOCO and Flickr30K. Experimental results demonstrate that\nHAT outperforms SOTA baselines by a large margin. Specifically, on two key\ntasks, \\textit{i.e.}, image-to-text and text-to-image retrieval, HAT achieves\n7.6\\% and 16.7\\% relative score improvement of Recall@1 on MSCOCO, and 4.4\\%\nand 11.6\\% on Flickr30k respectively. The code is available at\n\\url{https://github.com/LuminosityX/HAT}.",
        "translated": "现有的跨模态检索方法大多采用不同结构的双流编码器进行图像和文本检索，文本检索采用文本编码器，图像检索采用文本编码器，文本检索采用文本编码器。建筑中的这种差异可能会导致不同的语义分布空间，限制图像与文本之间的互动，进而导致图像与文本之间的对齐性较差。为了填补这一研究空白，受到变形金刚在视觉任务方面的最新进展的启发，我们建议将编码器架构与变形金刚的两种模式统一起来。具体来说，我们设计了一个纯粹基于双流转换器的跨模式检索框架，称为 textbf {分层对齐转换器(HAT)} ，它由一个图像转换器、一个文本转换器和一个分层对齐模块组成。使用这种相同的结构，编码器可以为图像和文本生成具有更多相似特征的表示，并使它们之间的交互和对齐更加容易。此外，为了利用丰富的语义，我们设计了一个层次对齐方案来探索图像和文本之间不同层次的多层次对应。为了评估提出的 HAT 的有效性，我们在两个基准数据集上进行了广泛的实验，MSCOCO 和 Flickr30K。实验结果表明，HAT 的性能大大优于 SOTA 基线。具体来说，在两个关键任务，即 texttit {即}、图像到文本和文本到图像检索上，HAT 在 MSCOCO 上分别达到7.6% 和16.7% 的 Recall@1相对分数提高，在 Flickr30k 上分别达到4.4% 和11.6% 。该代码可在 url { https://github.com/luminosityx/hat }获得。"
    },
    {
        "title": "Advancing Natural-Language Based Audio Retrieval with PaSST and Large\n  Audio-Caption Data Sets",
        "url": "http://arxiv.org/abs/2308.04258v1",
        "pub_date": "2023-08-08",
        "summary": "This work presents a text-to-audio-retrieval system based on pre-trained text\nand spectrogram transformers. Our method projects recordings and textual\ndescriptions into a shared audio-caption space in which related examples from\ndifferent modalities are close. Through a systematic analysis, we examine how\neach component of the system influences retrieval performance. As a result, we\nidentify two key components that play a crucial role in driving performance:\nthe self-attention-based audio encoder for audio embedding and the utilization\nof additional human-generated and synthetic data sets during pre-training. We\nfurther experimented with augmenting ClothoV2 captions with available keywords\nto increase their variety; however, this only led to marginal improvements. Our\nsystem ranked first in the 2023's DCASE Challenge, and it outperforms the\ncurrent state of the art on the ClothoV2 benchmark by 5.6 pp. mAP@10.",
        "translated": "本文提出了一个基于预训练文本和谱图变换器的文本-音频检索系统。我们的方法将录音和文本描述投射到一个共享的音频标题空间中，其中来自不同形式的相关例子非常接近。通过系统分析，我们研究了系统的每个组成部分如何影响检索性能。因此，我们确定了两个关键组成部分，发挥关键作用的驱动性能: 自我注意为基础的音频编码器的音频嵌入和利用额外的人类生成和合成数据集在预训练。我们进一步试验用可用的关键字增加 ClothoV2标题，以增加其多样性; 然而，这只导致了微小的改进。我们的系统在2023年的 DCASE 挑战赛中排名第一，比 ClothoV2基准测试的当前最先进水平高出5.6页。MAP@10."
    },
    {
        "title": "UniRecSys: A Unified Framework for Personalized, Group, Package, and\n  Package-to-Group Recommendations",
        "url": "http://arxiv.org/abs/2308.04247v1",
        "pub_date": "2023-08-08",
        "summary": "Recommender systems aim to enhance the overall user experience by providing\ntailored recommendations for a variety of products and services. These systems\nhelp users make more informed decisions, leading to greater user satisfaction\nwith the platform. However, the implementation of these systems largely depends\non the context, which can vary from recommending an item or package to a user\nor a group. This requires careful exploration of several models during the\ndeployment, as there is no comprehensive and unified approach that deals with\nrecommendations at different levels. Furthermore, these individual models must\nbe closely attuned to their generated recommendations depending on the context\nto prevent significant variation in their generated recommendations. In this\npaper, we propose a novel unified recommendation framework that addresses all\nfour recommendation tasks, namely personalized, group, package, or\npackage-to-group recommendation, filling the gap in the current research\nlandscape. The proposed framework can be integrated with most of the\ntraditional matrix factorization-based collaborative filtering models. The idea\nis to enhance the formulation of the existing approaches by incorporating\ncomponents focusing on the exploitation of the group and package latent\nfactors. These components also help in exploiting a rich latent representation\nof the user/item by enforcing them to align closely with their corresponding\ngroup/package representation. We consider two prominent CF techniques,\nRegularized Matrix Factorization and Maximum Margin Matrix factorization, as\nthe baseline models and demonstrate their customization to various\nrecommendation tasks. Experiment results on two publicly available datasets are\nreported, comparing them to other baseline approaches that consider individual\nrating feedback for group or package recommendations.",
        "translated": "推荐系统旨在通过为各种产品和服务提供量身定制的推荐，提高总体用户体验。这些系统可以帮助用户做出更明智的决定，从而提高用户对平台的满意度。然而，这些系统的实现在很大程度上取决于上下文，上下文可能从向用户或组推荐某个项目或包有所不同。这需要在部署过程中仔细探讨若干模型，因为没有全面和统一的方法处理不同级别的建议。此外，这些单独的模型必须与它们生成的建议密切协调，这取决于上下文，以防止它们生成的建议发生重大变化。在本文中，我们提出了一个新的统一的推荐框架，解决所有四个推荐任务，即个性化，小组，包，或包对小组的推荐，填补了目前的研究领域的空白。提出的框架可以与大多数传统的基于矩阵分解的协同过滤模型集成。其想法是通过纳入侧重于利用群体和整合潜在因素的组成部分，加强现有办法的拟订。这些组件还有助于利用用户/项的丰富潜在表示形式，强制它们与相应的组/包表示形式紧密对齐。我们考虑了两种著名的 CF 技术，正规化矩阵分解和最大保证金矩阵分解，作为基准模型，并展示了它们对各种推荐任务的定制。报告了两个公开数据集的实验结果，并将其与其他基线方法进行了比较，这些方法考虑了小组或一揽子建议的个人评级反馈。"
    },
    {
        "title": "OpinionConv: Conversational Product Search with Grounded Opinions",
        "url": "http://arxiv.org/abs/2308.04226v1",
        "pub_date": "2023-08-08",
        "summary": "When searching for products, the opinions of others play an important role in\nmaking informed decisions. Subjective experiences about a product can be a\nvaluable source of information. This is also true in sales conversations, where\na customer and a sales assistant exchange facts and opinions about products.\nHowever, training an AI for such conversations is complicated by the fact that\nlanguage models do not possess authentic opinions for their lack of real-world\nexperience. We address this problem by leveraging product reviews as a rich\nsource of product opinions to ground conversational AI in true subjective\nnarratives. With OpinionConv, we develop the first conversational AI for\nsimulating sales conversations. To validate the generated conversations, we\nconduct several user studies showing that the generated opinions are perceived\nas realistic. Our assessors also confirm the importance of opinions as an\ninformative basis for decision-making.",
        "translated": "在搜索产品时，他人的意见在做出明智的决定时起着重要作用。关于产品的主观经验可以成为有价值的信息来源。在销售对话中也是如此，客户和销售助理交换关于产品的事实和意见。然而，由于缺乏真实世界的经验，语言模型并不拥有真实的观点，这使得训练人工智能进行这种对话变得更加复杂。我们通过利用产品评论作为丰富的产品意见来源，以真正的主观叙事为基础来解决这个问题。通过 OpinionConv，我们开发了第一个用于模拟销售对话的会话 AI。为了验证生成的对话，我们进行了几个用户研究，表明生成的意见被认为是现实的。我们的评估人员也确认了意见作为决策的信息基础的重要性。"
    },
    {
        "title": "SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore",
        "url": "http://arxiv.org/abs/2308.04430v1",
        "pub_date": "2023-08-08",
        "summary": "The legality of training language models (LMs) on copyrighted or otherwise\nrestricted data is under intense debate. However, as we show, model performance\nsignificantly degrades if trained only on low-risk text (e.g., out-of-copyright\nbooks or government documents), due to its limited size and domain coverage. We\npresent SILO, a new language model that manages this risk-performance tradeoff\nduring inference. SILO is built by (1) training a parametric LM on Open License\nCorpus (OLC), a new corpus we curate with 228B tokens of public domain and\npermissively licensed text and (2) augmenting it with a more general and easily\nmodifiable nonparametric datastore (e.g., containing copyrighted books or news)\nthat is only queried during inference. The datastore allows use of high-risk\ndata without training on it, supports sentence-level data attribution, and\nenables data producers to opt out from the model by removing content from the\nstore. These capabilities can foster compliance with data-use regulations such\nas the fair use doctrine in the United States and the GDPR in the European\nUnion. Our experiments show that the parametric LM struggles on domains not\ncovered by OLC. However, access to the datastore greatly improves out of domain\nperformance, closing 90% of the performance gap with an LM trained on the Pile,\na more diverse corpus with mostly high-risk text. We also analyze which\nnonparametric approach works best, where the remaining errors lie, and how\nperformance scales with datastore size. Our results suggest that it is possible\nto build high quality language models while mitigating their legal risk.",
        "translated": "在版权保护或其他受限制的数据上训练语言模型(LM)的合法性正处于激烈的争论之中。然而，如我们所示，模型性能显着降低，如果训练只在低风险的文本(例如，版权过期的书籍或政府文件) ，由于其有限的大小和领域覆盖。我们提出了 SILO，一种新的语言模型，在推理过程中管理这种风险-性能权衡。SILO 是通过(1)在开放许可语料库(OLC)上训练一个参数化 LM 来构建的，这是一个新的语料库，我们用公共领域的228B 令牌和允许许可的文本来管理它，(2)用一个更通用、更容易修改的非参数数据存储(例如，包含有版权的书籍或新闻)来扩充它，这个数据存储只有在推理过程中才会被查询。数据存储允许不经过培训就使用高风险数据，支持句子级数据属性，并允许数据生产者通过从存储中删除内容来选择退出模型。这些能力可以促进遵守数据使用条例，如美国的公平使用原则和欧洲联盟的 GDPR。我们的实验表明，参数 LM 在 OLC 不覆盖的区域上挣扎。然而，对数据存储的访问大大提高了域外性能，使用在 Pile 上训练的 LM 弥补了90% 的性能差距，LM 是一个更加多样化的语料库，其中大部分是高风险文本。我们还分析了哪种非参数方法最有效，其余的错误在哪里，以及性能如何随着数据存储大小而变化。我们的研究结果表明，建立高质量的语言模型，同时降低其法律风险是可能的。"
    },
    {
        "title": "A Bi-directional Multi-hop Inference Model for Joint Dialog Sentiment\n  Classification and Act Recognition",
        "url": "http://arxiv.org/abs/2308.04424v1",
        "pub_date": "2023-08-08",
        "summary": "The joint task of Dialog Sentiment Classification (DSC) and Act Recognition\n(DAR) aims to predict the sentiment label and act label for each utterance in a\ndialog simultaneously. However, current methods encode the dialog context in\nonly one direction, which limits their ability to thoroughly comprehend the\ncontext. Moreover, these methods overlook the explicit correlations between\nsentiment and act labels, which leads to an insufficient ability to capture\nrich sentiment and act clues and hinders effective and accurate reasoning. To\naddress these issues, we propose a Bi-directional Multi-hop Inference Model\n(BMIM) that leverages a feature selection network and a bi-directional\nmulti-hop inference network to iteratively extract and integrate rich sentiment\nand act clues in a bi-directional manner. We also employ contrastive learning\nand dual learning to explicitly model the correlations of sentiment and act\nlabels. Our experiments on two widely-used datasets show that BMIM outperforms\nstate-of-the-art baselines by at least 2.6% on F1 score in DAR and 1.4% on F1\nscore in DSC. Additionally, Our proposed model not only improves the\nperformance but also enhances the interpretability of the joint sentiment and\nact prediction task.",
        "translated": "对话情感分类(DSC)和行为识别(DAR)的联合任务旨在同时预测对话中每个话语的情感标签和行为标签。但是，当前的方法只在一个方向上对对话框上下文进行编码，这限制了它们彻底理解上下文的能力。此外，这些方法忽视了情绪与行为标签之间的明显相关性，导致捕捉丰富情绪和行为线索的能力不足，阻碍了有效和准确的推理。为了解决这些问题，我们提出了一种双向多跳推理模型(BMIM) ，该模型利用特征选择网络和双向多跳推理网络，以双向方式迭代提取和整合丰富的情感和行为线索。我们还使用对比学习和双重学习来明确建模情感和行为标签的相关性。我们在两个广泛使用的数据集上的实验表明，BMIM 在 DAR 中的 F1评分至少比最先进的基线高2.6% ，在 DSC 中的 F1评分高1.4% 。此外，本文提出的模型不仅改善了性能，而且提高了联合情感和行为预测任务的可解释性。"
    },
    {
        "title": "Character-level NMT and language similarity",
        "url": "http://arxiv.org/abs/2308.04398v1",
        "pub_date": "2023-08-08",
        "summary": "We explore the effectiveness of character-level neural machine translation\nusing Transformer architecture for various levels of language similarity and\nsize of the training dataset on translation between Czech and Croatian, German,\nHungarian, Slovak, and Spanish. We evaluate the models using automatic MT\nmetrics and show that translation between similar languages benefits from\ncharacter-level input segmentation, while for less related languages,\ncharacter-level vanilla Transformer-base often lags behind subword-level\nsegmentation. We confirm previous findings that it is possible to close the gap\nby finetuning the already trained subword-level models to character-level.",
        "translated": "我们探索了使用 Transformer 架构的字符级神经机器翻译对捷克语和克罗地亚语，德语，匈牙利语，斯洛伐克语和西班牙语之间的翻译的不同语言相似性和训练数据集的大小的有效性。我们使用自动机器翻译度量对模型进行了评估，结果表明相似语言之间的翻译从字符级输入分割中获益，而对于相关性较低的语言，字符级别的普通变压器基通常滞后于子词级别的分割。我们证实了先前的发现，通过将已经训练好的子词水平模型微调到字符水平来缩小差距是可能的。"
    },
    {
        "title": "Learning Evaluation Models from Large Language Models for Sequence\n  Generation",
        "url": "http://arxiv.org/abs/2308.04386v1",
        "pub_date": "2023-08-08",
        "summary": "Large language models achieve state-of-the-art performance on sequence\ngeneration evaluation, but typically have a large number of parameters. This is\na computational challenge as presented by applying their evaluation capability\nat scale. To overcome the challenge, in this paper, we propose \\textbf{ECT}, an\n\\textbf{e}valuation \\textbf{c}apability \\textbf{t}ransfer method, to transfer\nthe evaluation capability from LLMs to relatively lightweight language models.\nBased on the proposed ECT, we learn various evaluation models from ChatGPT, and\nemploy them as reward models to improve sequence generation models via\nreinforcement learning and reranking approaches. Experimental results on\nmachine translation, text style transfer, and summarization tasks demonstrate\nthe effectiveness of our ECT. Notably, applying the learned evaluation models\nto sequence generation models results in better generated sequences as\nevaluated by commonly used metrics and ChatGPT.",
        "translated": "大型语言模型在序列生成计算方面实现了最先进的性能，但是通常具有大量的参数。这是一个计算方面的挑战，正如在规模上应用它们的评估能力所提出的那样。为了克服这一挑战，本文提出了 textbf { ECT } ，一种 textbf { e }赋值 textbf { c }能力 textbf { t }转移方法，将 LLM 中的赋值能力转移到相对轻量级的语言模型中。基于提出的 ECT，我们从 chatgPT 中学习各种评估模型，并将它们作为奖励模型，通过强化学习和重新排序的方法来改进序列生成模型。机器翻译、文本风格转换和摘要任务的实验结果证明了该方法的有效性。值得注意的是，将学习评估模型应用到序列生成模型中，通过常用的度量标准和 ChatGPT 进行评估，可以得到更好的生成序列。"
    },
    {
        "title": "Unmasking Nationality Bias: A Study of Human Perception of Nationalities\n  in AI-Generated Articles",
        "url": "http://arxiv.org/abs/2308.04346v1",
        "pub_date": "2023-08-08",
        "summary": "We investigate the potential for nationality biases in natural language\nprocessing (NLP) models using human evaluation methods. Biased NLP models can\nperpetuate stereotypes and lead to algorithmic discrimination, posing a\nsignificant challenge to the fairness and justice of AI systems. Our study\nemploys a two-step mixed-methods approach that includes both quantitative and\nqualitative analysis to identify and understand the impact of nationality bias\nin a text generation model. Through our human-centered quantitative analysis,\nwe measure the extent of nationality bias in articles generated by AI sources.\nWe then conduct open-ended interviews with participants, performing qualitative\ncoding and thematic analysis to understand the implications of these biases on\nhuman readers. Our findings reveal that biased NLP models tend to replicate and\namplify existing societal biases, which can translate to harm if used in a\nsociotechnical setting. The qualitative analysis from our interviews offers\ninsights into the experience readers have when encountering such articles,\nhighlighting the potential to shift a reader's perception of a country. These\nfindings emphasize the critical role of public perception in shaping AI's\nimpact on society and the need to correct biases in AI systems.",
        "translated": "我们使用人类评价方法研究了自然语言处理(NLP)模型中潜在的民族偏差。有偏见的自然语言处理(NLP)模型会延续刻板印象，导致算法歧视，对人工智能系统的公平性和正义性构成重大挑战。我们的研究采用了两步混合方法，包括定量和定性分析来识别和理解文本生成模型中国籍偏见的影响。通过我们以人为中心的定量分析，我们衡量了人工智能源生成的文章中民族偏见的程度。然后，我们对参与者进行开放式访谈，进行定性编码和主题分析，以理解这些偏见对人类读者的影响。我们的研究结果表明，有偏见的自然语言处理模型往往复制和扩大现有的社会偏见，这可以转化为危害，如果在社会技术环境中使用。我们采访的定性分析提供了读者遇到这类文章时的体验，突出了改变读者对一个国家的看法的潜力。这些发现强调了公众认知在塑造人工智能对社会的影响中的关键作用，以及纠正人工智能系统中的偏见的必要性。"
    },
    {
        "title": "Towards an AI to Win Ghana's National Science and Maths Quiz",
        "url": "http://arxiv.org/abs/2308.04333v1",
        "pub_date": "2023-08-08",
        "summary": "Can an AI win Ghana's National Science and Maths Quiz (NSMQ)? That is the\nquestion we seek to answer in the NSMQ AI project, an open-source project that\nis building AI to compete live in the NSMQ and win. The NSMQ is an annual live\nscience and mathematics competition for senior secondary school students in\nGhana in which 3 teams of 2 students compete by answering questions across\nbiology, chemistry, physics, and math in 5 rounds over 5 progressive stages\nuntil a winning team is crowned for that year. The NSMQ is an exciting live\nquiz competition with interesting technical challenges across speech-to-text,\ntext-to-speech, question-answering, and human-computer interaction. In this\nongoing work that began in January 2023, we give an overview of the project,\ndescribe each of the teams, progress made thus far, and the next steps toward\nour planned launch and debut of the AI in October for NSMQ 2023. An AI that\nconquers this grand challenge can have real-world impact on education such as\nenabling millions of students across Africa to have one-on-one learning support\nfrom this AI.",
        "translated": "人工智能能否赢得加纳国家科学和数学测验(NSMQ) ？这就是我们在 NSMQ AI 项目中试图回答的问题。 NSMQ AI 是一个开源项目，正在构建 AI，以便在 NSMQ 中进行现场竞争并获胜。NSMQ 是一年一度的加纳高中生科学和数学竞赛，由3组2名学生组成，在5个循序渐进的阶段中分5轮回答生物、化学、物理和数学问题，直到获胜的队伍获得当年的冠军。NSMQ 是一个令人兴奋的现场测验比赛，有趣的技术挑战跨越语音到文本，文本到语音，问答和人机交互。在这项始于2023年1月的持续工作中，我们给出了该项目的概述，描述了每个团队，迄今为止取得的进展，以及我们计划在2023年10月 NSMQ 上发布和首次亮相 AI 的下一步。一个人工智能克服了这个巨大的挑战，可以对现实世界的教育产生影响，比如让非洲数百万学生从这个人工智能中得到一对一的学习支持。"
    },
    {
        "title": "Deep Learning-Based Knowledge Injection for Metaphor Detection: A\n  Comprehensive Review",
        "url": "http://arxiv.org/abs/2308.04306v1",
        "pub_date": "2023-08-08",
        "summary": "The history of metaphor research also marks the evolution of knowledge\ninfusion research. With the continued advancement of deep learning techniques\nin recent years, the natural language processing community has shown great\ninterest in applying knowledge to successful results in metaphor recognition\ntasks. Although there has been a gradual increase in the number of approaches\ninvolving knowledge injection in the field of metaphor recognition, there is a\nlack of a complete review article on knowledge injection based approaches.\nTherefore, the goal of this paper is to provide a comprehensive review of\nresearch advances in the application of deep learning for knowledge injection\nin metaphor recognition tasks. In this paper, we systematically summarize and\ngeneralize the mainstream knowledge and knowledge injection principles, as well\nas review the datasets, evaluation metrics, and benchmark models used in\nmetaphor recognition tasks. Finally, we explore the current issues facing\nknowledge injection methods and provide an outlook on future research\ndirections.",
        "translated": "隐喻研究的历史也标志着知识灌输研究的演进。近年来，随着深度学习技术的不断发展，自然语言处理领域对将知识应用于隐喻识别任务的成功结果表现出了浓厚的兴趣。在隐喻识别领域，涉及知识注入的研究方法逐渐增多，但对于基于知识注入的研究方法却缺乏完整的综述。因此，本文旨在综述深度学习知识注入在隐喻识别任务中的应用研究进展。本文系统地总结和归纳了隐喻识别的主流知识和知识注入原理，并对隐喻识别任务中使用的数据集、评价指标和基准模型进行了综述。最后，探讨了知识注入方法面临的问题，并对未来的研究方向进行了展望。"
    },
    {
        "title": "Comparative Analysis of the wav2vec 2.0 Feature Extractor",
        "url": "http://arxiv.org/abs/2308.04286v1",
        "pub_date": "2023-08-08",
        "summary": "Automatic speech recognition (ASR) systems typically use handcrafted feature\nextraction pipelines. To avoid their inherent information loss and to achieve\nmore consistent modeling from speech to transcribed text, neural raw waveform\nfeature extractors (FEs) are an appealing approach. Also the wav2vec 2.0 model,\nwhich has recently gained large popularity, uses a convolutional FE which\noperates directly on the speech waveform. However, it is not yet studied\nextensively in the literature. In this work, we study its capability to replace\nthe standard feature extraction methods in a connectionist temporal\nclassification (CTC) ASR model and compare it to an alternative neural FE. We\nshow that both are competitive with traditional FEs on the LibriSpeech\nbenchmark and analyze the effect of the individual components. Furthermore, we\nanalyze the learned filters and show that the most important information for\nthe ASR system is obtained by a set of bandpass filters.",
        "translated": "自动语音识别(ASR)系统通常使用手工特征提取管道。为了避免其固有的信息丢失，实现从语音到转录文本更一致的建模，神经原始波形特征提取器(FEs)是一种很有吸引力的方法。此外，最近大受欢迎的 wave 2vec 2.0模型使用了直接对语音波形进行处理的卷积有限元。然而，它在文献中还没有得到广泛的研究。在这项工作中，我们研究了它的能力，以取代标准的特征提取方法在一个连接时间分类(CTC) ASR 模型，并比较了它与一个替代的神经有限元。我们表明，这两个是竞争对手的传统 FEs 上的 LibriLanguage 基准，并分析各个组件的影响。此外，我们分析了所学习的滤波器，并表明对于 ASR 系统来说，最重要的信息是由一组带通滤波器获得的。"
    },
    {
        "title": "In-Context Alignment: Chat with Vanilla Language Models Before\n  Fine-Tuning",
        "url": "http://arxiv.org/abs/2308.04275v1",
        "pub_date": "2023-08-08",
        "summary": "In this note, we explore inference-time alignment through in-context\nlearning. We consider a vanilla pretrained language model Llama-2 before any\nfine-tuning and retrieve an average of 9 demonstration alignment examples when\nthe model is prompted to follow chat-style instructions. Compared to direct\nprompting, the in-context alignment without changing model weights leads to a\n7x increase in win-rate w.r.t. the text-davinci-003 model from OpenAI, making\nthe vanilla language model comparable to strong baselines with alignment\nfine-tuning.",
        "translated": "在这篇文章中，我们通过上下文学习来探索推理时间校准。在进行任何微调之前，我们考虑一个普通的预训练语言模型 Llama-2，并在提示模型遵循聊天风格指令时检索平均9个演示对齐示例。与直接提示相比，在不改变模型权重的情况下进行上下文对齐，使 OpenAI 的 text-davinci-003模型的胜率提高了7倍，使得普通的语言模型可以与具有对齐微调的强基线相媲美。"
    },
    {
        "title": "CLASSLA-Stanza: The Next Step for Linguistic Processing of South Slavic\n  Languages",
        "url": "http://arxiv.org/abs/2308.04255v1",
        "pub_date": "2023-08-08",
        "summary": "We present CLASSLA-Stanza, a pipeline for automatic linguistic annotation of\nthe South Slavic languages, which is based on the Stanza natural language\nprocessing pipeline. We describe the main improvements in CLASSLA-Stanza with\nrespect to Stanza, and give a detailed description of the model training\nprocess for the latest 2.1 release of the pipeline. We also report performance\nscores produced by the pipeline for different languages and varieties.\nCLASSLA-Stanza exhibits consistently high performance across all the supported\nlanguages and outperforms or expands its parent pipeline Stanza at all the\nsupported tasks. We also present the pipeline's new functionality enabling\nefficient processing of web data and the reasons that led to its\nimplementation.",
        "translated": "我们介绍了 CLASSLA-Stanza，一个基于 Stanza 自然语言处理流水线的南斯拉夫语支自动语言注释流水线。我们描述了 CLASSLA-Stanza 相对于 Stanza 的主要改进，并详细描述了管道最新2.1版本的模型培训过程。我们还报告了该流水线针对不同语言和品种产生的性能得分。CLASSLA-Stanza 在所有受支持的语言中表现出持续的高性能，并且在所有受支持的任务中都优于或扩展了其父流水线 Stanza。我们还介绍了流水线的新功能，它能够有效地处理 Web 数据，以及导致其实现的原因。"
    },
    {
        "title": "Dual Intents Graph Modeling for User-centric Group Discovery",
        "url": "http://arxiv.org/abs/2308.05013v1",
        "pub_date": "2023-08-09",
        "summary": "Online groups have become increasingly prevalent, providing users with space\nto share experiences and explore interests. Therefore, user-centric group\ndiscovery task, i.e., recommending groups to users can help both users' online\nexperiences and platforms' long-term developments. Existing recommender methods\ncan not deal with this task as modeling user-group participation into a\nbipartite graph overlooks their item-side interests. Although there exist a few\nworks attempting to address this task, they still fall short in fully\npreserving the social context and ensuring effective interest representation\nlearning.\n  In this paper, we focus on exploring the intents that motivate users to\nparticipate in groups, which can be categorized into different types, like the\nsocial-intent and the personal interest-intent. The former refers to users\njoining a group affected by their social links, while the latter relates to\nusers joining groups with like-minded people for self-enjoyment. To comprehend\ndifferent intents, we propose a novel model, DiRec, that first models each\nintent separately and then fuses them together for predictions. Specifically,\nfor social-intent, we introduce the hypergraph structure to model the\nrelationship between groups and members, leading to a richer understanding of\nthe social context. As for interest-intent, we employ novel structural\nrefinement on the interactive graph to uncover more intricate user behaviors\nand group interests, realizing better representation learning of interests.\nFurthermore, we also observe the intent overlapping in real-world scenarios and\ndevise a novel self-supervised learning loss that encourages such alignment for\nfinal recommendations. Extensive experiments on three public datasets show the\nsignificant improvement of DiRec over the state-of-the-art methods.",
        "translated": "在线小组已经变得越来越普遍，为用户提供了分享经验和探索兴趣的空间。因此，以用户为中心的群组发现任务，即向用户推荐群组，可以帮助用户的在线体验和平台的长期发展。现有的推荐方法无法处理这个任务，因为将用户组参与建模成二分图忽略了它们的项目侧兴趣。虽然有一些工作试图解决这一任务，但他们仍然不能充分保存的社会背景和确保有效的兴趣表征学习。本文着重探讨了激发用户参与群体的意图，这些意图可以分为社会意图和个人兴趣意图。前者是指使用者加入一个受其社交联系影响的群组，而后者是指使用者加入与志同道合者的群组以自娱自乐。为了理解不同的意图，我们提出了一个新的模型，DiRec，它首先分别模拟每个意图，然后将它们融合在一起进行预测。具体地说，对于社会意图，我们引入超图结构来建模群体和成员之间的关系，从而更加丰富地理解社会背景。对于兴趣意图，我们在交互图上采用了新颖的结构细化，以揭示更复杂的用户行为和群体兴趣，实现更好的兴趣表示学习。此外，我们还观察到在现实世界的情况下意图重叠，并设计了一种新的自我监督学习丢失，鼓励这种调整为最终的建议。在三个公共数据集上的大量实验表明，DiRec 相对于最先进的方法有显著的改进。"
    },
    {
        "title": "LLaMA-E: Empowering E-commerce Authoring with Multi-Aspect Instruction\n  Following",
        "url": "http://arxiv.org/abs/2308.04913v1",
        "pub_date": "2023-08-09",
        "summary": "E-commerce authoring involves creating attractive, abundant, and targeted\npromotional content to drive product sales. The emergence of large language\nmodels (LLMs) introduces an innovative paradigm, offering a unified solution to\naddress various authoring tasks within this scenario. However, mainstream LLMs\ntrained on general corpora with common sense knowledge reveal limitations in\nfitting complex and personalized features unique to e-commerce products and\ncustomers. Furthermore, LLMs like GPT-3.5 necessitate remote accessibility,\nraising concerns about safeguarding voluminous customer privacy data during\ntransmission. This paper proposes the LLaMA-E, the unified and customized\ninstruction-following language models focusing on diverse e-commerce authoring\ntasks. Specifically, the domain experts create the seed instruction set from\nthe tasks of ads generation, query-enhanced product title rewriting, product\nclassification, purchase intent speculation, and general Q&amp;A. These tasks\nenable the models to comprehensively understand precise e-commerce authoring\nknowledge by interleaving features covering typical service aspects of\ncustomers, sellers, and platforms. The GPT-3.5 is introduced as a teacher\nmodel, which expands the seed instructions to form a training set for the\nLLaMA-E models with various scales. The experimental results show that the\nproposed LLaMA-E models achieve state-of-the-art results in quantitative and\nqualitative evaluations, also exhibiting the advantage in zero-shot scenes. To\nthe best of our knowledge, this study is the first to serve the LLMs to\nspecific e-commerce authoring scenarios.",
        "translated": "电子商务创作涉及创造有吸引力的，丰富的，有针对性的促销内容，以推动产品销售。大型语言模型(LLM)的出现引入了一个创新的范例，提供了一个统一的解决方案来处理这个场景中的各种创作任务。然而，主流的基于常识知识的通用语料库训练的 LLM 在适应电子商务产品和客户特有的复杂和个性化特征方面显示出局限性。此外，像 GPT-3.5这样的 LLM 需要远程访问，这引起了人们对在传输过程中保护大量客户隐私数据的担忧。本文提出了面向不同电子商务创作任务的统一定制的指令遵循语言模型 LLaMA-E。具体来说，领域专家从广告生成、查询增强的产品标题重写、产品分类、购买意图推测和一般问答等任务中创建种子指令集。这些任务使模型能够通过交叉覆盖客户、销售商和平台的典型服务方面的特性，全面理解精确的电子商务创作知识。GPT-3.5是作为一个教师模型引入的，它扩展了种子指令，形成了具有不同规模的 LLaMA-E 模型的训练集。实验结果表明，所提出的 LLaMA-E 模型在定量和定性评价方面都取得了较好的效果，在零镜头场景方面也显示出了优势。据我们所知，这项研究是第一个为 LLM 服务的特定电子商务创作场景。"
    },
    {
        "title": "Parallel Knowledge Enhancement based Framework for Multi-behavior\n  Recommendation",
        "url": "http://arxiv.org/abs/2308.04807v1",
        "pub_date": "2023-08-09",
        "summary": "Multi-behavior recommendation algorithms aim to leverage the multiplex\ninteractions between users and items to learn users' latent preferences. Recent\nmulti-behavior recommendation frameworks contain two steps: fusion and\nprediction. In the fusion step, advanced neural networks are used to model the\nhierarchical correlations between user behaviors. In the prediction step,\nmultiple signals are utilized to jointly optimize the model with a multi-task\nlearning (MTL) paradigm. However, recent approaches have not addressed the\nissue caused by imbalanced data distribution in the fusion step, resulting in\nthe learned relationships being dominated by high-frequency behaviors. In the\nprediction step, the existing methods use a gate mechanism to directly\naggregate expert information generated by coupling input, leading to negative\ninformation transfer. To tackle these issues, we propose a Parallel Knowledge\nEnhancement Framework (PKEF) for multi-behavior recommendation. Specifically,\nwe enhance the hierarchical information propagation in the fusion step using\nparallel knowledge (PKF). Meanwhile, in the prediction step, we decouple the\nrepresentations to generate expert information and introduce a projection\nmechanism during aggregation to eliminate gradient conflicts and alleviate\nnegative transfer (PME). We conduct comprehensive experiments on three\nreal-world datasets to validate the effectiveness of our model. The results\nfurther demonstrate the rationality and effectiveness of the designed PKF and\nPME modules. The source code and datasets are available at\nhttps://github.com/MC-CV/PKEF.",
        "translated": "多行为推荐算法旨在利用用户和项目之间的多重交互来了解用户的潜在偏好。最近的多行为推荐框架包含两个步骤: 融合和预测。在融合步骤中，采用先进的神经网络对用户行为之间的层次关系进行建模。在预测步骤中，利用多个信号与多任务学习(MTL)范式联合优化模型。然而，最近的方法还没有解决由于融合步骤中数据分布不平衡所引起的问题，导致学习关系被高频行为所主导。在预测步骤中，现有的方法采用门机制直接聚合由耦合输入产生的专家信息，导致负信息传递。为了解决这些问题，我们提出了一个用于多行为推荐的并行知识增强框架(PKEF)。具体地说，我们在融合步骤中使用并行知识(PKF)来增强层次信息的传播。同时，在预测步骤中，对表示进行解耦，生成专家信息，并在聚合过程中引入投影机制，消除梯度冲突，减轻负迁移(PME)。为了验证模型的有效性，我们在三个实际数据集上进行了综合实验。仿真结果进一步验证了所设计的 PKF 模块和 PME 模块的合理性和有效性。源代码和数据集可在 https://github.com/mc-cv/pkef 下载。"
    },
    {
        "title": "DiVa: An Iterative Framework to Harvest More Diverse and Valid Labels\n  from User Comments for Music",
        "url": "http://arxiv.org/abs/2308.04805v1",
        "pub_date": "2023-08-09",
        "summary": "Towards sufficient music searching, it is vital to form a complete set of\nlabels for each song. However, current solutions fail to resolve it as they\ncannot produce diverse enough mappings to make up for the information missed by\nthe gold labels. Based on the observation that such missing information may\nalready be presented in user comments, we propose to study the automated music\nlabeling in an essential but under-explored setting, where the model is\nrequired to harvest more diverse and valid labels from the users' comments\ngiven limited gold labels. To this end, we design an iterative framework (DiVa)\nto harvest more $\\underline{\\text{Di}}$verse and $\\underline{\\text{Va}}$lid\nlabels from user comments for music. The framework makes a classifier able to\nform complete sets of labels for songs via pseudo-labels inferred from\npre-trained classifiers and a novel joint score function. The experiment on a\ndensely annotated testing set reveals the superiority of the Diva over\nstate-of-the-art solutions in producing more diverse labels missed by the gold\nlabels. We hope our work can inspire future research on automated music\nlabeling.",
        "translated": "对于足够的音乐搜索，为每首歌建立一套完整的标签是至关重要的。然而，当前的解决方案无法解决这个问题，因为它们不能产生足够多样化的映射来弥补黄金标签错过的信息。基于观察到这些缺失的信息可能已经出现在用户的评论中，我们建议在一个必要但探索不足的环境中研究自动化音乐标签，该模型需要从用户给予有限的黄金标签的评论中收集更多样化和有效的标签。为此，我们设计了一个迭代框架(DiVa) ，从用户音乐注释中收集更多的 $下划线{ text { Di } $verse 和 $下划线{ text { Va }} $睑标签。该框架使得分类器能够通过预先训练的分类器推导出的伪标签和一种新的联合得分函数来形成完整的歌曲标签集。在一个密集注释的测试集上进行的实验揭示了 Diva 相对于最先进的解决方案在生产更多样化的标签方面的优越性，这些标签被黄金标签忽略了。我们希望我们的工作能够对未来自动化音乐标签的研究有所启发。"
    },
    {
        "title": "Entire Space Cascade Delayed Feedback Modeling for Effective Conversion\n  Rate Prediction",
        "url": "http://arxiv.org/abs/2308.04768v1",
        "pub_date": "2023-08-09",
        "summary": "Conversion rate (CVR) prediction is an essential task for large-scale\ne-commerce platforms. However, refund behaviors frequently occur after\nconversion in online shopping systems, which drives us to pay attention to\neffective conversion for building healthier shopping services. This paper\ndefines the probability of item purchasing without any subsequent refund as an\neffective conversion rate (ECVR). A simple paradigm for ECVR prediction is to\ndecompose it into two sub-tasks: CVR prediction and post-conversion refund rate\n(RFR) prediction. However, RFR prediction suffers from data sparsity (DS) and\nsample selection bias (SSB) issues, as the refund behaviors are only available\nafter user purchase. Furthermore, there is delayed feedback in both conversion\nand refund events and they are sequentially dependent, named cascade delayed\nfeedback (CDF), which significantly harms data freshness for model training.\nPrevious studies mainly focus on tackling DS and SSB or delayed feedback for a\nsingle event. To jointly tackle these issues in ECVR prediction, we propose an\nEntire space CAscade Delayed feedback modeling (ECAD) method. Specifically,\nECAD deals with DS and SSB by constructing two tasks including CVR prediction\nand conversion \\&amp; refund rate (CVRFR) prediction using the entire space\nmodeling framework. In addition, it carefully schedules auxiliary tasks to\nleverage both conversion and refund time within data to alleviate CDF.\nExperimental results on the offline industrial dataset and online A/B testing\ndemonstrate the effectiveness of ECAD. In addition, ECAD has been deployed in\none of the recommender systems in Alibaba, contributing to a significant\nimprovement of ECVR.",
        "translated": "转化率(CVR)预测是大型电子商务平台的一项基本任务。然而，在网上购物系统中，退款行为经常发生在转换后，这促使我们关注有效的转换，以建立更健康的购物服务。本文将不随后退款的物品购买概率定义为有效转换率(ECVR)。ECVR 预测的一个简单范例是将其分解为两个子任务: CVR 预测和转换后退款率(RFR)预测。然而，RFR 预测存在数据稀疏性(DS)和样本选择偏差(SSB)问题，因为退款行为只能在用户购买之后才能得到。此外，在转换事件和退款事件中都存在延迟反馈，并且它们是相互依赖的，称为级联延迟反馈(CDF) ，这严重损害了模型训练的数据新鲜度。以往的研究主要集中在处理 DS 和 SSB 或单个事件的延迟反馈。为了共同解决 ECVR 预测中的这些问题，我们提出了一种全空间级联延迟反馈建模(ECAD)方法。具体来说，ECAD 利用整个空间建模框架构造了 CVR 预测和转换退款率(CVRFR)预测两个任务来处理 DS 和 SSB。此外，它仔细地安排辅助任务，以利用数据中的转换和退款时间来缓解 CDF。离线工业数据集和在线 A/B 测试的实验结果证明了 ECAD 的有效性。此外，阿里巴巴其中一个推荐系统已采用 ECAD，有助显著改善 ECVR。"
    },
    {
        "title": "Constructing Holistic Spatio-Temporal Scene Graph for Video Semantic\n  Role Labeling",
        "url": "http://arxiv.org/abs/2308.05081v1",
        "pub_date": "2023-08-09",
        "summary": "Video Semantic Role Labeling (VidSRL) aims to detect the salient events from\ngiven videos, by recognizing the predict-argument event structures and the\ninterrelationships between events. While recent endeavors have put forth\nmethods for VidSRL, they can be mostly subject to two key drawbacks, including\nthe lack of fine-grained spatial scene perception and the insufficiently\nmodeling of video temporality. Towards this end, this work explores a novel\nholistic spatio-temporal scene graph (namely HostSG) representation based on\nthe existing dynamic scene graph structures, which well model both the\nfine-grained spatial semantics and temporal dynamics of videos for VidSRL.\nBuilt upon the HostSG, we present a nichetargeting VidSRL framework. A\nscene-event mapping mechanism is first designed to bridge the gap between the\nunderlying scene structure and the high-level event semantic structure,\nresulting in an overall hierarchical scene-event (termed ICE) graph structure.\nWe further perform iterative structure refinement to optimize the ICE graph,\nsuch that the overall structure representation can best coincide with end task\ndemand. Finally, three subtask predictions of VidSRL are jointly decoded, where\nthe end-to-end paradigm effectively avoids error propagation. On the benchmark\ndataset, our framework boosts significantly over the current best-performing\nmodel. Further analyses are shown for a better understanding of the advances of\nour methods.",
        "translated": "视频语义角色标注(VidSRL)是通过识别预测论元事件结构和事件之间的相互关系来检测给定视频中的显著事件。虽然最近的研究已经提出了 VidSRL 的实现方法，但是这些方法仍然存在两个主要的缺陷，即缺乏细粒度的空间场景感知和对视频时间性的建模不足。为此，本文在已有的动态场景图结构的基础上，探索了一种新的整体时空场景图(即 HostSG)表示方法，该方法能够很好地模拟 VidSRL 中视频的细粒度空间语义和时间动态。在 HostSG 的基础上，我们提供了一个针对不同目标的 VidSRL 框架。首先设计了一种场景事件映射机制，以弥补底层场景结构和高层事件语义结构之间的差距，从而形成一个整体层次化的场景事件(ICE)图形结构。我们进一步进行迭代结构优化以优化 ICE 图，使整体结构表示能够最好地符合最终任务的需求。最后，VidSRL 的三个子任务预测被联合解码，其中端到端范式有效地避免了错误传播。在基准数据集上，我们的框架比当前性能最好的模型有了显著的提升。进一步的分析显示了更好的理解我们的方法的进步。"
    },
    {
        "title": "RadGraph2: Modeling Disease Progression in Radiology Reports via\n  Hierarchical Information Extraction",
        "url": "http://arxiv.org/abs/2308.05046v1",
        "pub_date": "2023-08-09",
        "summary": "We present RadGraph2, a novel dataset for extracting information from\nradiology reports that focuses on capturing changes in disease state and device\nplacement over time. We introduce a hierarchical schema that organizes entities\nbased on their relationships and show that using this hierarchy during training\nimproves the performance of an information extraction model. Specifically, we\npropose a modification to the DyGIE++ framework, resulting in our model HGIE,\nwhich outperforms previous models in entity and relation extraction tasks. We\ndemonstrate that RadGraph2 enables models to capture a wider variety of\nfindings and perform better at relation extraction compared to those trained on\nthe original RadGraph dataset. Our work provides the foundation for developing\nautomated systems that can track disease progression over time and develop\ninformation extraction models that leverage the natural hierarchy of labels in\nthe medical domain.",
        "translated": "我们提出了 RadGraph2，一个从放射学报告中提取信息的新型数据集，其重点是捕捉疾病状态的变化以及随着时间的推移设备的放置。我们引入了一个层次模式，它根据实体之间的关系来组织实体，并表明在培训中使用这个层次模式可以提高信息抽取模型的性能。具体来说，我们建议对 DyGIE + + 框架进行修改，从而得到我们的模型 HGIE，它在实体和关系提取任务方面优于以前的模型。我们证明，与在原始 RadGraph2数据集上训练的模型相比，RadGraph2使模型能够捕获更广泛的发现，并且在关系提取方面表现得更好。我们的工作为开发自动化系统提供了基础，这些系统可以随着时间的推移跟踪疾病的进展，并开发信息抽取模型，利用医学领域标签的自然层次结构。"
    },
    {
        "title": "AspectMMKG: A Multi-modal Knowledge Graph with Aspect-aware Entities",
        "url": "http://arxiv.org/abs/2308.04992v1",
        "pub_date": "2023-08-09",
        "summary": "Multi-modal knowledge graphs (MMKGs) combine different modal data (e.g., text\nand image) for a comprehensive understanding of entities. Despite the recent\nprogress of large-scale MMKGs, existing MMKGs neglect the multi-aspect nature\nof entities, limiting the ability to comprehend entities from various\nperspectives. In this paper, we construct AspectMMKG, the first MMKG with\naspect-related images by matching images to different entity aspects.\nSpecifically, we collect aspect-related images from a knowledge base, and\nfurther extract aspect-related sentences from the knowledge base as queries to\nretrieve a large number of aspect-related images via an online image search\nengine. Finally, AspectMMKG contains 2,380 entities, 18,139 entity aspects, and\n645,383 aspect-related images. We demonstrate the usability of AspectMMKG in\nentity aspect linking (EAL) downstream task and show that previous EAL models\nachieve a new state-of-the-art performance with the help of AspectMMKG. To\nfacilitate the research on aspect-related MMKG, we further propose an\naspect-related image retrieval (AIR) model, that aims to correct and expand\naspect-related images in AspectMMKG. We train an AIR model to learn the\nrelationship between entity image and entity aspect-related images by\nincorporating entity image, aspect, and aspect image information. Experimental\nresults indicate that the AIR model could retrieve suitable images for a given\nentity w.r.t different aspects.",
        "translated": "多模态知识图(MMKGs)将不同的模态数据(例如文本和图像)组合在一起，以便全面理解实体。尽管大型 MMKG 近年来取得了一些进展，但现有的 MMKG 忽视了实体的多面性，限制了从多个角度理解实体的能力。本文通过对不同实体方面的图像进行匹配，构造了第一个具有方面相关图像的 MMKG-AspectMMKG。具体来说，我们从知识库中收集与方面相关的图像，并进一步从知识库中提取与方面相关的句子作为查询，通过在线图像搜索引擎检索大量与方面相关的图像。最后，AspectMMKG 包含2,380个实体、18,139个实体方面和645,383个与方面相关的图像。我们证明了 AspectMMKG 在实体方面连接(EAL)下游任务中的可用性，并表明以前的 EAL 模型在 AspectMMKG 的帮助下取得了新的最佳性能。为了方便对 AspectMMKG 的研究，我们进一步提出了一种 AIR 模型，用于校正和扩展 AspectMMKG 中与 AspectMMKG 相关的图像。我们训练一个 AIR 模型来学习实体图像和实体体相关图像之间的关系，通过合并实体图像、体和体的图像信息。实验结果表明，AIR 模型能够在给定实体的不同方面提取出合适的图像。"
    },
    {
        "title": "Exploring Multilingual Text Data Distillation",
        "url": "http://arxiv.org/abs/2308.04982v1",
        "pub_date": "2023-08-09",
        "summary": "With the rise of deep learning, large datasets and complex models have become\ncommon, requiring significant computing power. To address this, data\ndistillation has emerged as a technique to quickly train models with lower\nmemory and time requirements. However, data distillation on text-based datasets\nhasn't been explored much because of the challenges rising due to its discrete\nnature. Additionally, existing dataset distillation methods often struggle to\ngeneralize to new architectures. In the paper, we propose several data\ndistillation techniques for multilingual text classification datasets using\nlanguage-model-based learning methods. We conduct experiments to analyze their\nperformance in terms of classification strength, and cross-architecture\ngeneralization. Furthermore, we investigate the language-specific fairness of\nthe data summaries generated by these methods. Our approach builds upon\nexisting techniques, enhancing cross-architecture generalization in the text\ndata distillation domain.",
        "translated": "随着深度学习的兴起，大型数据集和复杂模型已经变得普遍，需要大量的计算能力。为了解决这个问题，数据提取已经成为一种快速训练具有较低内存和时间要求的模型的技术。然而，基于文本的数据集的数据提取还没有得到很多的研究，因为它的离散性质带来了挑战。此外，现有的数据集提取方法通常难以推广到新的体系结构。本文利用基于语言模型的学习方法，提出了多语种文本分类数据集的数据提取技术。我们通过实验分析了它们在分类强度和跨体系结构泛化方面的性能。此外，我们还研究了这些方法生成的数据摘要的语言特定的公平性。我们的方法建立在现有技术的基础上，增强了文本数据精馏领域中的跨体系结构泛化。"
    },
    {
        "title": "Performance Analysis of Transformer Based Models (BERT, ALBERT and\n  RoBERTa) in Fake News Detection",
        "url": "http://arxiv.org/abs/2308.04950v1",
        "pub_date": "2023-08-09",
        "summary": "Fake news is fake material in a news media format but is not processed\nproperly by news agencies. The fake material can provoke or defame significant\nentities or individuals or potentially even for the personal interests of the\ncreators, causing problems for society. Distinguishing fake news and real news\nis challenging due to limited of domain knowledge and time constraints.\nAccording to the survey, the top three areas most exposed to hoaxes and\nmisinformation by residents are in Banten, DKI Jakarta and West Java. The model\nof transformers is referring to an approach in the field of artificial\nintelligence (AI) in natural language processing utilizing the deep learning\narchitectures. Transformers exercise a powerful attention mechanism to process\ntext in parallel and produce rich and contextual word representations. A\nprevious study indicates a superior performance of a transformer model known as\nBERT over and above non transformer approach. However, some studies suggest the\nperformance can be improved with the use of improved BERT models known as\nALBERT and RoBERTa. However, the modified BERT models are not well explored for\ndetecting fake news in Bahasa Indonesia. In this research, we explore those\ntransformer models and found that ALBERT outperformed other models with 87.6%\naccuracy, 86.9% precision, 86.9% F1-score, and 174.5 run-time (s/epoch)\nrespectively. Source code available at:\nhttps://github.com/Shafna81/fakenewsdetection.git",
        "translated": "假新闻是以新闻媒体形式出现的假新闻，但新闻机构没有对其进行适当处理。虚假材料可以挑衅或诽谤重要实体或个人，甚至可能是为了创作者的个人利益，造成社会问题。由于领域知识的有限和时间的限制，区分虚假新闻和真实新闻是一项具有挑战性的工作。调查显示，最容易受到居民恶作剧和错误信息影响的三个地区分别位于万丹、 DKI 雅加达和西爪哇。变压器模型是自然语言处理领域中利用深度学习体系结构的人工智能(AI)方法。变形金刚运用强大的注意力机制，平行处理文本，产生丰富的上下文词语表征。以往的研究表明，一种称为 BERT 的变压器模型优于非变压器方法的性能。然而，一些研究表明，使用改进的 BERT 模型 ALBERT 和 RoBERTa 可以提高性能。然而，改进后的 BERT 模型在检测印尼语中的假新闻方面还没有得到很好的研究。在本研究中，我们探讨了这些变压器模型，发现 ALBERT 的准确率为87.6% ，准确率为86.9% ，F1得分为86.9% ，运行时间为174.5(s/epoch)。源代码可在以下 https://github.com/shafna81/fakenewsdetection.git 获得:"
    },
    {
        "title": "Extrapolating Large Language Models to Non-English by Aligning Languages",
        "url": "http://arxiv.org/abs/2308.04948v1",
        "pub_date": "2023-08-09",
        "summary": "Due to the unbalanced training data distribution, the language ability of\nlarge language models (LLMs) is often biased towards English. In this paper, we\npropose to empower pre-trained LLMs on non-English languages by building\nsemantic alignment across languages. We perform instruction-tuning on LLaMA\nwith both translation task data and cross-lingual general task data to obtain\ncross-lingual models (x-LLaMA). Experiment results on cross-lingual benchmark\nXQUAD and MLQA show that x-LLaMA models outperform the English\ninstruction-tuned counterpart (Alpaca) by 42.50% on average on six non-English\nlanguages. Further experiments on Chinese benchmark C-Eval show that x-LLaMA\nachieves significant improvement on Chinese humanities tasks, outperforming\nAlpaca by 8.2%. We also discover that incorporating non-English text on the\ntarget side of translation data is particularly effective for boosting\nnon-English ability. Besides, we find that semantic alignment within LLM can be\nfurther strengthened as translation task data scales up and we present the\nformulation of the underlying scaling law. Evaluation results on translation\ndataset Flores-101 show that \\method outperforms previous LLaMA-based models in\nall evaluated directions. Code and data will be available at:\nhttps://github.com/OwenNJU/x-LLM.",
        "translated": "由于训练数据分布不均衡，大型语言模型(LLM)的语言能力往往偏向于英语。在本文中，我们提出通过建立跨语言的语义对齐来增强非英语语言的预训练 LLM。我们利用翻译任务数据和跨语言一般任务数据对 LLaMA 进行指令调优，以获得跨语言模型(x-LLaMA)。跨语言基准 XQUAD 和 MLQA 的实验结果表明，x-LLaMA 模型在6种非英语语言中的平均性能比英语指令优化模型(Alpaca)高出42.50% 。中文基准 C-Eval 的进一步实验表明，x-llaMA 在中文人文学科任务方面取得了显著进步，比 Alpaca 高出8.2% 。我们还发现，将非英语文本纳入翻译数据的目标侧对于提高非英语能力尤为有效。此外，我们发现随着翻译任务数据规模的扩大，LLM 中的语义对齐可以得到进一步加强，并且我们提出了潜在的尺度规律。对翻译数据集 Flores-101的评估结果表明，该方法在所有评估方向上都优于以往基于 LLaMA 的模型。密码及资料可于以下 https://github.com/owennju/x-llm 索取:。"
    },
    {
        "title": "LLMeBench: A Flexible Framework for Accelerating LLMs Benchmarking",
        "url": "http://arxiv.org/abs/2308.04945v1",
        "pub_date": "2023-08-09",
        "summary": "The recent development and success of Large Language Models (LLMs)\nnecessitate an evaluation of their performance across diverse NLP tasks in\ndifferent languages. Although several frameworks have been developed and made\npublicly available, their customization capabilities for specific tasks and\ndatasets are often complex for different users. In this study, we introduce the\nLLMeBench framework. Initially developed to evaluate Arabic NLP tasks using\nOpenAI's GPT and BLOOM models; it can be seamlessly customized for any NLP task\nand model, regardless of language. The framework also features zero- and\nfew-shot learning settings. A new custom dataset can be added in less than 10\nminutes, and users can use their own model API keys to evaluate the task at\nhand. The developed framework has been already tested on 31 unique NLP tasks\nusing 53 publicly available datasets within 90 experimental setups, involving\napproximately 296K data points. We plan to open-source the framework for the\ncommunity (https://github.com/qcri/LLMeBench/). A video demonstrating the\nframework is available online (https://youtu.be/FkQn4UjYA0s).",
        "translated": "大语言模型(LLM)的最新发展和成功需要评估它们在不同语言的不同 NLP 任务中的性能。虽然已经开发了几个框架并向公众开放，但是对于不同的用户来说，它们针对特定任务和数据集的定制功能往往很复杂。在本研究中，我们介绍 LLMeBench 框架。最初开发用于评估使用 OpenAI 的 GPT 和 BLOOM 模型的阿拉伯语 NLP 任务; 它可以无缝定制任何 NLP 任务和模型，不管语言如何。该框架还具有零镜头和少镜头学习设置。可以在不到10分钟的时间内添加新的自定义数据集，用户可以使用自己的模型 API 键来计算手头的任务。开发的框架已经在31个独特的自然语言处理任务上进行了测试，使用了90个实验设置中的53个公开可用的数据集，涉及大约296K 的数据点。我们计划为社区( https://github.com/qcri/llmebench/)开源。该框架的视频可在网上获得( https://youtu.be/fkqn4ujya0s )。"
    },
    {
        "title": "Integrating large language models and active inference to understand eye\n  movements in reading and dyslexia",
        "url": "http://arxiv.org/abs/2308.04941v1",
        "pub_date": "2023-08-09",
        "summary": "We present a novel computational model employing hierarchical active\ninference to simulate reading and eye movements. The model characterizes\nlinguistic processing as inference over a hierarchical generative model,\nfacilitating predictions and inferences at various levels of granularity, from\nsyllables to sentences.\n  Our approach combines the strengths of large language models for realistic\ntextual predictions and active inference for guiding eye movements to\ninformative textual information, enabling the testing of predictions. The model\nexhibits proficiency in reading both known and unknown words and sentences,\nadhering to the distinction between lexical and nonlexical routes in dual-route\ntheories of reading. Notably, our model permits the exploration of maladaptive\ninference effects on eye movements during reading, such as in dyslexia. To\nsimulate this condition, we attenuate the contribution of priors during the\nreading process, leading to incorrect inferences and a more fragmented reading\nstyle, characterized by a greater number of shorter saccades. This alignment\nwith empirical findings regarding eye movements in dyslexic individuals\nhighlights the model's potential to aid in understanding the cognitive\nprocesses underlying reading and eye movements, as well as how reading deficits\nassociated with dyslexia may emerge from maladaptive predictive processing.\n  In summary, our model represents a significant advancement in comprehending\nthe intricate cognitive processes involved in reading and eye movements, with\npotential implications for understanding and addressing dyslexia through the\nsimulation of maladaptive inference. It may offer valuable insights into this\ncondition and contribute to the development of more effective interventions for\ntreatment.",
        "translated": "我们提出了一个新的计算模型，采用分层主动推理来模拟阅读和眼球运动。这个模型将语言处理描述为一个层次生成模型的推理过程，在从音节到句子的不同粒度级别上为预测和推理提供便利。我们的方法结合了现实的文本预测的大型语言模型的优势和指导眼睛运动的信息文本信息的主动推理，使测试预测成为可能。该模型遵循双路径阅读理论中词汇路径和非词汇路径的区别，对已知和未知的词语和句子都表现出熟练的阅读能力。值得注意的是，我们的模型允许探索阅读过程中眼球运动的适应不良的推理效应，如阅读障碍。为了模拟这种情况，我们在阅读过程中减弱了前置拥有属性的影响，导致不正确的推理和更零碎的阅读风格，更多的短视扫视。这与阅读障碍个体眼球运动的实验结果一致突出了该模型有助于理解阅读和眼球运动背后的认知过程的潜力，以及与阅读障碍相关的阅读缺陷如何可能从适应不良的预测处理中出现。总之，我们的模型在理解阅读和眼球运动中涉及的复杂认知过程方面取得了重大进展，通过模拟适应不良推理对理解和解决阅读障碍具有潜在的意义。它可以为这种情况提供有价值的见解，并有助于制定更有效的治疗干预措施。"
    },
    {
        "title": "Unsupervised Out-of-Distribution Dialect Detection with Mahalanobis\n  Distance",
        "url": "http://arxiv.org/abs/2308.04886v1",
        "pub_date": "2023-08-09",
        "summary": "Dialect classification is used in a variety of applications, such as machine\ntranslation and speech recognition, to improve the overall performance of the\nsystem. In a real-world scenario, a deployed dialect classification model can\nencounter anomalous inputs that differ from the training data distribution,\nalso called out-of-distribution (OOD) samples. Those OOD samples can lead to\nunexpected outputs, as dialects of those samples are unseen during model\ntraining. Out-of-distribution detection is a new research area that has\nreceived little attention in the context of dialect classification. Towards\nthis, we proposed a simple yet effective unsupervised Mahalanobis distance\nfeature-based method to detect out-of-distribution samples. We utilize the\nlatent embeddings from all intermediate layers of a wav2vec 2.0\ntransformer-based dialect classifier model for multi-task learning. Our\nproposed approach outperforms other state-of-the-art OOD detection methods\nsignificantly.",
        "translated": "方言分类被广泛应用于机器翻译、语音识别等领域，提高了系统的整体性能。在实际场景中，部署的方言分类模型可能会遇到与训练数据分布不同的异常输入，也称为分布外(OOD)样本。这些 OOD 样本可能导致意外的输出，因为这些样本的方言在模型训练期间是看不见的。分布外检测是一个新的研究领域，在方言分类的背景下很少受到关注。为此，我们提出了一种简单而有效的基于无监督马氏距离特征的方法来检测分布外样本。我们利用了基于 wave 2vec 2.0转换器的方言分类器模型中所有中间层的潜在嵌入来进行多任务学习。我们提出的方法明显优于其他最先进的 OOD 检测方法。"
    },
    {
        "title": "SSLRec: A Self-Supervised Learning Library for Recommendation",
        "url": "http://arxiv.org/abs/2308.05697v1",
        "pub_date": "2023-08-10",
        "summary": "Self-supervised learning (SSL) has gained significant interest in recent\nyears as a solution to address the challenges posed by sparse and noisy data in\nrecommender systems. Despite the growing number of SSL algorithms designed to\nprovide state-of-the-art performance in various recommendation scenarios (e.g.,\ngraph collaborative filtering, sequential recommendation, social\nrecommendation, KG-enhanced recommendation), there is still a lack of unified\nframeworks that integrate recommendation algorithms across different domains.\nSuch a framework could serve as the cornerstone for self-supervised\nrecommendation algorithms, unifying the validation of existing methods and\ndriving the design of new ones. To address this gap, we introduce SSLRec, a\nnovel benchmark platform that provides a standardized, flexible, and\ncomprehensive framework for evaluating various SSL-enhanced recommenders. The\nSSLRec library features a modular architecture that allows users to easily\nevaluate state-of-the-art models and a complete set of data augmentation and\nself-supervised toolkits to help create SSL recommendation models with specific\nneeds. Furthermore, SSLRec simplifies the process of training and evaluating\ndifferent recommendation models with consistent and fair settings. Our SSLRec\nplatform covers a comprehensive set of state-of-the-art SSL-enhanced\nrecommendation models across different scenarios, enabling researchers to\nevaluate these cutting-edge models and drive further innovation in the field.\nOur implemented SSLRec framework is available at the source code repository\nhttps://github.com/HKUDS/SSLRec.",
        "translated": "自监督学习(SSL)作为一种解决推荐系统中数据稀疏和噪声问题的方法，近年来引起了人们的极大兴趣。尽管有越来越多的 SSL 算法被设计用来在各种推荐场景中提供最先进的性能(例如，图形协同过滤、顺序推荐、社交推荐、 KG 增强推荐) ，但是仍然缺乏统一的框架来整合不同领域的推荐算法。这样一个框架可以作为自监督推荐算法的基石，统一现有方法的验证，并推动新方法的设计。为了弥补这一差距，我们引入了 SSLRec，这是一个新颖的基准平台，它为评估各种 SSL 增强的推荐程序提供了一个标准化、灵活和全面的框架。SSLRec 库采用模块化架构，允许用户轻松评估最先进的模型，并提供一整套数据增强和自我监督工具包，帮助创建具有特定需求的 SSL 推荐模型。此外，SSLRec 通过一致和公平的设置简化了不同推荐模型的培训和评估过程。我们的 SSLRec 平台涵盖了不同场景下一整套最先进的 SSL 增强推荐模型，使研究人员能够评估这些尖端模型并推动该领域的进一步创新。我们已实施的 SSlrec 架构可在原始码储存库 https://github.com/hkuds/SSLRec 找到。"
    },
    {
        "title": "Finding Already Debunked Narratives via Multistage Retrieval: Enabling\n  Cross-Lingual, Cross-Dataset and Zero-Shot Learning",
        "url": "http://arxiv.org/abs/2308.05680v1",
        "pub_date": "2023-08-10",
        "summary": "The task of retrieving already debunked narratives aims to detect stories\nthat have already been fact-checked. The successful detection of claims that\nhave already been debunked not only reduces the manual efforts of professional\nfact-checkers but can also contribute to slowing the spread of misinformation.\nMainly due to the lack of readily available data, this is an understudied\nproblem, particularly when considering the cross-lingual task, i.e. the\nretrieval of fact-checking articles in a language different from the language\nof the online post being checked. This paper fills this gap by (i) creating a\nnovel dataset to enable research on cross-lingual retrieval of already debunked\nnarratives, using tweets as queries to a database of fact-checking articles;\n(ii) presenting an extensive experiment to benchmark fine-tuned and\noff-the-shelf multilingual pre-trained Transformer models for this task; and\n(iii) proposing a novel multistage framework that divides this cross-lingual\ndebunk retrieval task into refinement and re-ranking stages. Results show that\nthe task of cross-lingual retrieval of already debunked narratives is\nchallenging and off-the-shelf Transformer models fail to outperform a strong\nlexical-based baseline (BM25). Nevertheless, our multistage retrieval framework\nis robust, outperforming BM25 in most scenarios and enabling cross-domain and\nzero-shot learning, without significantly harming the model's performance.",
        "translated": "检索已经被揭穿的故事的任务旨在发现已经经过事实核查的故事。成功发现已被揭穿的索赔不仅减少了专业事实核查人员的人工努力，而且还有助于减缓错误信息的传播。主要由于缺乏现成的数据，这是一个未被充分研究的问题，特别是在考虑跨语言任务时，即检索事实核查文章的语言不同于被检查的在线帖子的语言。本文通过以下方式填补了这一空白: (i)创建一个新的数据集，以便对已经揭穿的叙述进行跨语言检索的研究，使用 tweet 作为事实检查文章数据库的查询; (ii)提出一个广泛的实验，以基准微调和现成的多语言预先训练的变压器模型进行这项任务; (iii)提出一个新的多阶段框架，将这个跨语言揭穿的检索任务划分为细化和重新排序阶段。结果表明，跨语言检索已经被揭穿的叙事是一项具有挑战性的任务，现有的变压器模型不能胜过基于词汇的强基线(BM25)。尽管如此，我们的多阶段检索框架是健壮的，在大多数情况下表现优于 BM25，并且支持跨域和零拍学习，而不会显著损害模型的性能。"
    },
    {
        "title": "LASIGE and UNICAGE solution to the NASA LitCoin NLP Competition",
        "url": "http://arxiv.org/abs/2308.05609v1",
        "pub_date": "2023-08-10",
        "summary": "Biomedical Natural Language Processing (NLP) tends to become cumbersome for\nmost researchers, frequently due to the amount and heterogeneity of text to be\nprocessed. To address this challenge, the industry is continuously developing\nhighly efficient tools and creating more flexible engineering solutions. This\nwork presents the integration between industry data engineering solutions for\nefficient data processing and academic systems developed for Named Entity\nRecognition (LasigeUnicage\\_NER) and Relation Extraction (BiOnt). Our design\nreflects an integration of those components with external knowledge in the form\nof additional training data from other datasets and biomedical ontologies. We\nused this pipeline in the 2022 LitCoin NLP Challenge, where our team\nLasigeUnicage was awarded the 7th Prize out of approximately 200 participating\nteams, reflecting a successful collaboration between the academia (LASIGE) and\nthe industry (Unicage). The software supporting this work is available at\n\\url{https://github.com/lasigeBioTM/Litcoin-Lasige_Unicage}.",
        "translated": "生物医学自然语言处理(NLP)往往成为大多数研究人员的麻烦，往往是由于数量和文本的异质性处理。为了应对这一挑战，该行业正在不断开发高效的工具，并创建更加灵活的工程解决方案。这项工作介绍了工业数据工程解决方案之间的集成有效的数据处理和学术系统开发的命名实体识别(LasigeUnicage _ NER)和关系提取(BiOnt)。我们的设计反映了这些组件与外部知识的集成，以来自其他数据集和生物医学本体的额外训练数据的形式。我们在2022年 LitCoin NLP 挑战赛中使用了这个管道，我们的团队 LasigeUnicage 在大约200个参赛团队中获得了第七名，这反映了学术界(LASIGE)和业界(Unicage)之间的成功合作。支持这项工作的软件可以在 url { https://github.com/lasigebiotm/litcoin-lasige_unicage }获得。"
    },
    {
        "title": "Multi-domain Recommendation with Embedding Disentangling and Domain\n  Alignment",
        "url": "http://arxiv.org/abs/2308.05508v1",
        "pub_date": "2023-08-10",
        "summary": "Multi-domain recommendation (MDR) aims to provide recommendations for\ndifferent domains (e.g., types of products) with overlapping users/items and is\ncommon for platforms such as Amazon, Facebook, and LinkedIn that host multiple\nservices. Existing MDR models face two challenges: First, it is difficult to\ndisentangle knowledge that generalizes across domains (e.g., a user likes cheap\nitems) and knowledge specific to a single domain (e.g., a user likes blue\nclothing but not blue cars). Second, they have limited ability to transfer\nknowledge across domains with small overlaps. We propose a new MDR method named\nEDDA with two key components, i.e., embedding disentangling recommender and\ndomain alignment, to tackle the two challenges respectively. In particular, the\nembedding disentangling recommender separates both the model and embedding for\nthe inter-domain part and the intra-domain part, while most existing MDR\nmethods only focus on model-level disentangling. The domain alignment leverages\nrandom walks from graph processing to identify similar user/item pairs from\ndifferent domains and encourages similar user/item pairs to have similar\nembeddings, enhancing knowledge transfer. We compare EDDA with 12\nstate-of-the-art baselines on 3 real datasets. The results show that EDDA\nconsistently outperforms the baselines on all datasets and domains. All\ndatasets and codes are available at https://github.com/Stevenn9981/EDDA.",
        "translated": "多域名推荐(MDR)的目的是为不同领域(例如，产品类型)的重叠用户/项目提供推荐，这种推荐在亚马逊、 Facebook 和 LinkedIn 等提供多种服务的平台上很常见。现有的 MDR 模型面临两个挑战: 首先，很难区分跨领域概括的知识(例如，用户喜欢廉价商品)和特定于单个领域的知识(例如，用户喜欢蓝色衣服但不喜欢蓝色汽车)。其次，他们跨领域传递知识的能力有限，重叠的领域很小。我们提出了一种新的 MDR 方法 EDDA，该方法由两个关键部分组成，即嵌入分离推荐和域对齐，分别解决了这两个难题。特别是嵌入式解缠推荐器将域间部分和域内部分的模型和嵌入分离开来，而现有的 MDR 方法大多只关注模型级的解缠。领域对齐利用图形处理中的随机游走来识别来自不同领域的相似用户/项目对，并鼓励相似的用户/项目对具有相似的嵌入，增强知识转移。我们比较了3个实际数据集上的 EDDA 和12个最先进的基线。结果表明，EDDA 在所有数据集和域上的性能均优于基线。所有数据集和代码都可以在 https://github.com/stevenn9981/edda 获得。"
    },
    {
        "title": "Bringing order into the realm of Transformer-based language models for\n  artificial intelligence and law",
        "url": "http://arxiv.org/abs/2308.05502v1",
        "pub_date": "2023-08-10",
        "summary": "Transformer-based language models (TLMs) have widely been recognized to be a\ncutting-edge technology for the successful development of deep-learning-based\nsolutions to problems and applications that require natural language processing\nand understanding. Like for other textual domains, TLMs have indeed pushed the\nstate-of-the-art of AI approaches for many tasks of interest in the legal\ndomain. Despite the first Transformer model being proposed about six years ago,\nthere has been a rapid progress of this technology at an unprecedented rate,\nwhereby BERT and related models represent a major reference, also in the legal\ndomain. This article provides the first systematic overview of TLM-based\nmethods for AI-driven problems and tasks in the legal sphere. A major goal is\nto highlight research advances in this field so as to understand, on the one\nhand, how the Transformers have contributed to the success of AI in supporting\nlegal processes, and on the other hand, what are the current limitations and\nopportunities for further research development.",
        "translated": "基于转换器的语言模型(TLM)已被广泛认为是一种成功开发基于深度学习的解决方案的尖端技术，用于解决需要自然语言处理和理解的问题和应用程序。与其他文本领域一样，TLM 确实推动了人工智能方法在法律领域的许多有意义的任务中的最先进水平。尽管第一个变压器模型是在大约六年前提出的，但是这项技术已经以前所未有的速度得到了迅速的发展，其中 BERT 和相关的模型是一个主要的参考，也是在法律领域。本文提供了第一个系统的概述 TLM 为基础的方法人工智能驱动的问题和任务在法律领域。我们的一个主要目标，是突出这个领域的研究进展，以便一方面了解变形金刚对人工智能在支援法律程序方面的成功作出了何种贡献，另一方面了解目前进一步研究发展的局限和机会。"
    },
    {
        "title": "EXPRESSO: A Benchmark and Analysis of Discrete Expressive Speech\n  Resynthesis",
        "url": "http://arxiv.org/abs/2308.05725v1",
        "pub_date": "2023-08-10",
        "summary": "Recent work has shown that it is possible to resynthesize high-quality speech\nbased, not on text, but on low bitrate discrete units that have been learned in\na self-supervised fashion and can therefore capture expressive aspects of\nspeech that are hard to transcribe (prosody, voice styles, non-verbal\nvocalization). The adoption of these methods is still limited by the fact that\nmost speech synthesis datasets are read, severely limiting spontaneity and\nexpressivity. Here, we introduce Expresso, a high-quality expressive speech\ndataset for textless speech synthesis that includes both read speech and\nimprovised dialogues rendered in 26 spontaneous expressive styles. We\nillustrate the challenges and potentials of this dataset with an expressive\nresynthesis benchmark where the task is to encode the input in low-bitrate\nunits and resynthesize it in a target voice while preserving content and style.\nWe evaluate resynthesis quality with automatic metrics for different\nself-supervised discrete encoders, and explore tradeoffs between quality,\nbitrate and invariance to speaker and style. All the dataset, evaluation\nmetrics and baseline models are open source",
        "translated": "最近的研究表明，有可能重新合成高质量的语音，不是基于文本，而是基于低比特率的离散单位，这些单位已经通过自我监督的方式学习，因此可以捕获难以转录的语音表达方面(韵律，语音风格，非语言发音)。采用这些方法仍然受到大多数语音合成数据集被阅读的限制，严重限制了自发性和表达性。在这里，我们介绍 Expresso，一个高质量的无文本语音合成表达语音数据集，包括阅读语音和即兴对话，呈现在26种自发表达风格。我们说明了这个数据集的挑战和潜力与一个表达式重合成基准，其中的任务是编码在低比特率单位的输入和重合成在一个目标语音，同时保留内容和风格。对不同自监督离散编码器的重合成质量进行了自动度量评估，并探讨了质量、比特率和对说话人和风格的不变性之间的权衡。所有的数据集、评估指标和基线模型都是开源的"
    },
    {
        "title": "A Preliminary Study of the Intrinsic Relationship between Complexity and\n  Alignment",
        "url": "http://arxiv.org/abs/2308.05696v1",
        "pub_date": "2023-08-10",
        "summary": "Training large language models (LLMs) with open-domain instruction data has\nyielded remarkable success in aligning to end tasks and user preferences.\nExtensive research has highlighted that enhancing the quality and diversity of\ninstruction data consistently improves performance. However, the impact of data\ncomplexity, as a crucial metric, remains relatively unexplored in three\naspects: (1) scaling law, where the sustainability of performance improvements\nwith increasing complexity is uncertain, (2) additional tokens, whether the\nimprovement brought by complexity comes from introducing more training tokens,\nand (3) curriculum tuning, where the potential advantages of incorporating\ninstructions ranging from easy to difficult are not yet fully understood. In\nthis paper, we propose \\textit{tree-instruct} to systematically enhance the\ncomplexity of instruction data in a controllable manner. This approach adds a\nspecified number of nodes into the instruction semantic tree, yielding new\ninstruction data based on the modified tree. By adjusting the number of added\nnodes, we can control the difficulty level in the modified instruction data.\nOur preliminary experiments reveal the following insights: (1) Increasing\ncomplexity consistently leads to sustained performance improvements. For\ninstance, using 1,000 instruction data and 10 nodes resulted in a substantial\n24\\% increase in win rate. (2) Under the same token budget, a few complex\ninstructions outperform diverse yet simple instructions. (3) Curriculum\ninstruction tuning might not yield the anticipated results; focusing on\nincreasing complexity appears to be the key.",
        "translated": "使用开放领域指令数据训练大型语言模型(LLM)已经在调整终端任务和用户偏好方面取得了显著的成功。广泛的研究强调指出，提高教学数据的质量和多样性可持续地改善教学效果。然而，数据复杂性作为一个关键指标的影响在三个方面仍然相对未被探索: (1)尺度法，其中随着复杂性的增加性能改进的可持续性是不确定的; (2)额外的标记，复杂性带来的改进是否来自引入更多的训练标记; (3)课程调整，其中纳入指令从容易到难的潜在优势尚未完全理解。在本文中，我们提出文本{树指令}系统地增强指令数据的复杂性在一个可控的方式。该方法将指定数量的节点添加到指令语义树中，并基于修改后的树生成新的指令数据。通过调整增加的节点数，可以控制修改后的指令数据的难度等级。我们的初步实验揭示了以下见解: (1)不断增加的复杂性导致持续的性能改善。例如，使用1,000个指令数据和10个节点可以使中奖率大幅提高24% 。(2)在同样的象征性预算下，少数复杂指令的表现优于多样而简单的指令。(3)课程教学调整未必能达到预期效果，关键在于增加课程复杂性。"
    },
    {
        "title": "AST-MHSA : Code Summarization using Multi-Head Self-Attention",
        "url": "http://arxiv.org/abs/2308.05646v1",
        "pub_date": "2023-08-10",
        "summary": "Code summarization aims to generate concise natural language descriptions for\nsource code. The prevailing approaches adopt transformer-based encoder-decoder\narchitectures, where the Abstract Syntax Tree (AST) of the source code is\nutilized for encoding structural information. However, ASTs are much longer\nthan the corresponding source code, and existing methods ignore this size\nconstraint by directly feeding the entire linearized AST into the encoders.\nThis simplistic approach makes it challenging to extract truly valuable\ndependency relations from the overlong input sequence and leads to significant\ncomputational overhead due to self-attention applied to all nodes in the AST.\n  To address this issue effectively and efficiently, we present a model,\nAST-MHSA that uses multi-head attention to extract the important semantic\ninformation from the AST. The model consists of two main components: an encoder\nand a decoder. The encoder takes as input the abstract syntax tree (AST) of the\ncode and generates a sequence of hidden states. The decoder then takes these\nhidden states as input and generates a natural language summary of the code.\n  The multi-head attention mechanism allows the model to learn different\nrepresentations of the input code, which can be combined to generate a more\ncomprehensive summary. The model is trained on a dataset of code and summaries,\nand the parameters of the model are optimized to minimize the loss between the\ngenerated summaries and the ground-truth summaries.",
        "translated": "代码摘要的目的是为源代码生成简洁的自然语言描述。流行的方法采用基于变压器的编码器-解码器架构，其中源代码的抽象语法树(AST)用于编码结构信息。然而，AST 要比相应的源代码长得多，而且现有的方法忽略了这个大小限制，直接将整个线性化的 AST 提供给编码器。这种简单的方法使得从超长的输入序列中提取真正有价值的依赖关系变得非常困难，并且由于自注意应用于 AST 中的所有节点而导致大量的计算开销。为了有效地解决这个问题，我们提出了一个模型，AST-MHSA，它使用多头注意力从 AST 中提取重要的语义信息。该模型由两个主要部分组成: 一个编码器和一个解码器。编码器以代码的抽象语法树(AST)作为输入，并生成一系列隐藏状态。然后，解码器将这些隐藏状态作为输入，并生成代码的自然语言摘要。多头注意机制允许模型学习输入代码的不同表示形式，这些表示形式可以组合起来生成更全面的摘要。该模型基于代码和摘要的数据集进行训练，并对模型参数进行优化，使得生成的摘要与地面真实性摘要之间的损失最小。"
    },
    {
        "title": "IIHT: Medical Report Generation with Image-to-Indicator Hierarchical\n  Transformer",
        "url": "http://arxiv.org/abs/2308.05633v1",
        "pub_date": "2023-08-10",
        "summary": "Automated medical report generation has become increasingly important in\nmedical analysis. It can produce computer-aided diagnosis descriptions and thus\nsignificantly alleviate the doctors' work. Inspired by the huge success of\nneural machine translation and image captioning, various deep learning methods\nhave been proposed for medical report generation. However, due to the inherent\nproperties of medical data, including data imbalance and the length and\ncorrelation between report sequences, the generated reports by existing methods\nmay exhibit linguistic fluency but lack adequate clinical accuracy. In this\nwork, we propose an image-to-indicator hierarchical transformer (IIHT)\nframework for medical report generation. It consists of three modules, i.e., a\nclassifier module, an indicator expansion module and a generator module. The\nclassifier module first extracts image features from the input medical images\nand produces disease-related indicators with their corresponding states. The\ndisease-related indicators are subsequently utilised as input for the indicator\nexpansion module, incorporating the \"data-text-data\" strategy. The\ntransformer-based generator then leverages these extracted features along with\nimage features as auxiliary information to generate final reports. Furthermore,\nthe proposed IIHT method is feasible for radiologists to modify disease\nindicators in real-world scenarios and integrate the operations into the\nindicator expansion module for fluent and accurate medical report generation.\nExtensive experiments and comparisons with state-of-the-art methods under\nvarious evaluation metrics demonstrate the great performance of the proposed\nmethod.",
        "translated": "自动化医疗报告生成在医学分析中越来越重要。它可以产生电脑辅助诊断的描述，从而大大减轻医生的工作。受到神经机器翻译和图像字幕的巨大成功的启发，各种深度学习方法被提出来用于医疗报告的生成。然而，由于医学数据的固有属性，包括数据不平衡和报告序列的长度和相关性，现有方法生成的报告可能表现出语言流畅性，但缺乏足够的临床准确性。在这项工作中，我们提出了一个图像到指示器层次转换器(IIHT)框架，用于医疗报告的生成。它由三个模块组成，即分类器模块、指示器扩展模块和生成器模块。分类器模块首先从输入的医学图像中提取图像特征，生成相应状态的疾病相关指标。随后，将疾病相关指标作为指标扩展模块的输入，纳入“数据-文本-数据”战略。然后，基于转换器的生成器利用这些提取的特征以及图像特征作为辅助信息来生成最终报告。此外，提出的 IIHT 方法是可行的，放射科医生可以在现实世界的情况下修改疾病指标，并将操作集成到指标扩展模块，以生成流畅和准确的医疗报告。在各种评价指标下进行了大量的实验，并与现有的评价方法进行了比较，结果表明该方法具有良好的性能。"
    },
    {
        "title": "You Only Prompt Once: On the Capabilities of Prompt Learning on Large\n  Language Models to Tackle Toxic Content",
        "url": "http://arxiv.org/abs/2308.05596v1",
        "pub_date": "2023-08-10",
        "summary": "The spread of toxic content online is an important problem that has adverse\neffects on user experience online and in our society at large. Motivated by the\nimportance and impact of the problem, research focuses on developing solutions\nto detect toxic content, usually leveraging machine learning (ML) models\ntrained on human-annotated datasets. While these efforts are important, these\nmodels usually do not generalize well and they can not cope with new trends\n(e.g., the emergence of new toxic terms). Currently, we are witnessing a shift\nin the approach to tackling societal issues online, particularly leveraging\nlarge language models (LLMs) like GPT-3 or T5 that are trained on vast corpora\nand have strong generalizability. In this work, we investigate how we can use\nLLMs and prompt learning to tackle the problem of toxic content, particularly\nfocusing on three tasks; 1) Toxicity Classification, 2) Toxic Span Detection,\nand 3) Detoxification. We perform an extensive evaluation over five model\narchitectures and eight datasets demonstrating that LLMs with prompt learning\ncan achieve similar or even better performance compared to models trained on\nthese specific tasks. We find that prompt learning achieves around 10\\%\nimprovement in the toxicity classification task compared to the baselines,\nwhile for the toxic span detection task we find better performance to the best\nbaseline (0.643 vs. 0.640 in terms of $F_1$-score). Finally, for the\ndetoxification task, we find that prompt learning can successfully reduce the\naverage toxicity score (from 0.775 to 0.213) while preserving semantic meaning.",
        "translated": "网上有毒内容的传播是一个重要问题，它对用户的网上体验和整个社会产生了不利影响。受到问题的重要性和影响的激励，研究集中于开发检测有毒内容的解决方案，通常利用机器学习(ML)模型训练的人类注释数据集。尽管这些努力很重要，但这些模型通常不能很好地推广，也无法应对新的趋势(例如，新的有毒术语的出现)。目前，我们正在见证一种在线处理社会问题的方法的转变，特别是利用大型语言模型(LLM) ，如 GPT-3或 T5，这些模型在大型语料库中受过培训，具有很强的普遍性。在这项工作中，我们调查我们如何使用 LLM 和及时学习来解决有毒内容的问题，特别是集中在三个任务上: 1)毒性分类，2)毒性范围检测，和3)解毒。我们对五个模型架构和八个数据集进行了广泛的评估，结果表明，与针对这些特定任务训练的模型相比，具有快速学习能力的 LLM 可以获得相似甚至更好的性能。我们发现，与基线相比，快速学习在毒性分类任务中取得了大约10% 的改善，而对于毒性跨度检测任务，我们发现表现更好，达到最佳基线(0.643比0.640在 $F _ 1 $- 评分方面)。最后，对于解毒任务，我们发现及时学习可以成功地降低平均毒性评分(从0.775到0.213) ，同时保持语义。"
    },
    {
        "title": "Do Language Models Refer?",
        "url": "http://arxiv.org/abs/2308.05576v1",
        "pub_date": "2023-08-10",
        "summary": "What do language models (LMs) do with language? Everyone agrees that they\nproduce sequences of (mostly) coherent sentences. But are they saying anything\nwith those strings or simply babbling in a convincing simulacrum of language\nuse? This is a vague question, and there are many ways of making it precise.\nHere we will address one aspect of the question, namely, whether LMs' words\nrefer: that is, whether the outputs of LMs achieve \"word-to-world\" connections.\nThere is prima facie reason to think they do not since LMs do not interact with\nthe world in the way that ordinary language users do. Drawing on insights from\nthe externalist tradition in philosophy of language, we argue that appearances\nare misleading and that there is good reason to think that LMs can refer.",
        "translated": "语言模型(LM)如何处理语言？每个人都同意他们产生连贯的句子序列(大部分)。但是他们是在用这些字符串说话，还是仅仅在使用一种令人信服的模拟语言？这是一个模糊的问题，有很多方法可以使它更加精确。在这里，我们将讨论这个问题的一个方面，即语言生成模式的词是否指代: 即语言生成模式的输出是否实现了“词与世界”的连接。我们有初步的理由认为它们不会，因为 LM 不像普通语言使用者那样与世界互动。借鉴语言哲学中外在主义传统的见解，我们认为表象具有误导性，并且有充分的理由认为 LM 可以指称。"
    },
    {
        "title": "Exploring Linguistic Similarity and Zero-Shot Learning for Multilingual\n  Translation of Dravidian Languages",
        "url": "http://arxiv.org/abs/2308.05574v1",
        "pub_date": "2023-08-10",
        "summary": "Current research in zero-shot translation is plagued by several issues such\nas high compute requirements, increased training time and off target\ntranslations. Proposed remedies often come at the cost of additional data or\ncompute requirements. Pivot based neural machine translation is preferred over\na single-encoder model for most settings despite the increased training and\nevaluation time. In this work, we overcome the shortcomings of zero-shot\ntranslation by taking advantage of transliteration and linguistic similarity.\nWe build a single encoder-decoder neural machine translation system for\nDravidian-Dravidian multilingual translation and perform zero-shot translation.\nWe compare the data vs zero-shot accuracy tradeoff and evaluate the performance\nof our vanilla method against the current state of the art pivot based method.\nWe also test the theory that morphologically rich languages require large\nvocabularies by restricting the vocabulary using an optimal transport based\ntechnique. Our model manages to achieves scores within 3 BLEU of large-scale\npivot-based models when it is trained on 50\\% of the language directions.",
        "translated": "目前零拍翻译研究存在着计算要求高、训练时间长和翻译偏离目标等问题。提出的补救措施往往以牺牲额外的数据或计算需求为代价。尽管增加了训练和评估时间，但在大多数情况下，枢轴神经机器翻译优于单一编码器模型。本文利用音译和语言相似性，克服了零拍翻译的不足。我们建立了一个单一的编码器-解码器神经机器翻译系统，并进行了零拍翻译。我们比较了数据与零拍摄精度的折衷，并评估了我们的香草方法与基于枢轴的方法的当前状态的性能。我们还验证了形态学丰富的语言需要大量词汇的理论，通过使用最佳传输技术来限制词汇量。我们的模型设法达到3BLEU 内的大规模枢轴为基础的模型分数时，它是在50% 的语言方向训练。"
    },
    {
        "title": "A Large Language Model Enhanced Conversational Recommender System",
        "url": "http://arxiv.org/abs/2308.06212v1",
        "pub_date": "2023-08-11",
        "summary": "Conversational recommender systems (CRSs) aim to recommend high-quality items\nto users through a dialogue interface. It usually contains multiple sub-tasks,\nsuch as user preference elicitation, recommendation, explanation, and item\ninformation search. To develop effective CRSs, there are some challenges: 1)\nhow to properly manage sub-tasks; 2) how to effectively solve different\nsub-tasks; and 3) how to correctly generate responses that interact with users.\nRecently, Large Language Models (LLMs) have exhibited an unprecedented ability\nto reason and generate, presenting a new opportunity to develop more powerful\nCRSs. In this work, we propose a new LLM-based CRS, referred to as LLMCRS, to\naddress the above challenges. For sub-task management, we leverage the\nreasoning ability of LLM to effectively manage sub-task. For sub-task solving,\nwe collaborate LLM with expert models of different sub-tasks to achieve the\nenhanced performance. For response generation, we utilize the generation\nability of LLM as a language interface to better interact with users.\nSpecifically, LLMCRS divides the workflow into four stages: sub-task detection,\nmodel matching, sub-task execution, and response generation. LLMCRS also\ndesigns schema-based instruction, demonstration-based instruction, dynamic\nsub-task and model matching, and summary-based generation to instruct LLM to\ngenerate desired results in the workflow. Finally, to adapt LLM to\nconversational recommendations, we also propose to fine-tune LLM with\nreinforcement learning from CRSs performance feedback, referred to as RLPF.\nExperimental results on benchmark datasets show that LLMCRS with RLPF\noutperforms the existing methods.",
        "translated": "会话推荐系统(CRS)旨在通过对话界面向用户推荐高质量的项目。它通常包含多个子任务，如用户首选项启发、推荐、解释和项目信息搜索。要开发有效的 CRS，存在一些挑战: 1)如何正确地管理子任务; 2)如何有效地解决不同的子任务; 3)如何正确地生成与用户交互的响应。最近，大语言模型(LLM)表现出了前所未有的推理和生成能力，为开发更强大的 CRS 提供了新的机遇。在这项工作中，我们提出了一个新的基于 LLM 的 CRS，称为 LLMCRS，以解决上述挑战。对于子任务管理，我们利用 LLM 的推理能力来有效地管理子任务。对于子任务求解，我们将 LLM 与不同子任务的专家模型进行协作，以获得更好的性能。对于响应生成，我们利用 LLM 作为语言接口的生成能力来更好地与用户交互。LLMCRS 将工作流划分为四个阶段: 子任务检测、模型匹配、子任务执行和响应生成。LLMCRS 还设计了基于模式的指令、基于演示的指令、动态子任务和模型匹配以及基于摘要的生成，以指导 LLM 在工作流中生成期望的结果。最后，为了使 LLM 适应会话建议，我们还建议使用来自 CRSS 性能反馈的强化学习(称为 RLPF)对 LLM 进行微调。在基准数据集上的实验结果表明，带有 RLPF 的 LLMCRS 方法的性能优于现有的方法。"
    },
    {
        "title": "Identification of the Relevance of Comments in Codes Using Bag of Words\n  and Transformer Based Models",
        "url": "http://arxiv.org/abs/2308.06144v1",
        "pub_date": "2023-08-11",
        "summary": "The Forum for Information Retrieval (FIRE) started a shared task this year\nfor classification of comments of different code segments. This is binary text\nclassification task where the objective is to identify whether comments given\nfor certain code segments are relevant or not. The BioNLP-IISERB group at the\nIndian Institute of Science Education and Research Bhopal (IISERB) participated\nin this task and submitted five runs for five different models. The paper\npresents the overview of the models and other significant findings on the\ntraining corpus. The methods involve different feature engineering schemes and\ntext classification techniques. The performance of the classical bag of words\nmodel and transformer-based models were explored to identify significant\nfeatures from the given training corpus. We have explored different classifiers\nviz., random forest, support vector machine and logistic regression using the\nbag of words model. Furthermore, the pre-trained transformer based models like\nBERT, RoBERT and ALBERT were also used by fine-tuning them on the given\ntraining corpus. The performance of different such models over the training\ncorpus were reported and the best five models were implemented on the given\ntest corpus. The empirical results show that the bag of words model outperforms\nthe transformer based models, however, the performance of our runs are not\nreasonably well in both training and test corpus. This paper also addresses the\nlimitations of the models and scope for further improvement.",
        "translated": "信息检索论坛(FIRE)今年开始了一项共享任务，对不同代码段的注释进行分类。这是一个二进制文本分类任务，其目标是确定为某些代码段提供的注释是否相关。印度科学教育与研究博帕尔研究所(IISERB)的 BioNLP-IISERB 小组参与了这项任务，并提交了五个不同模型的运行结果。本文对这些模型进行了综述，并对培训语料库中的其他重要发现进行了分析。该方法包括不同的特征工程方案和文本分类技术。研究了经典词袋模型和基于变换器的词袋模型的性能，以识别给定训练语料中的重要特征。我们使用词袋模型探索了不同的分类器，包括随机森林、支持向量机和 Logit模型。此外，在给定的训练语料上，还对基于预训练变压器的 BERT、 RoBERT 和 ALBERT 等模型进行了微调。报告了不同模型在训练语料库上的表现，并在给定的测试语料库上实现了最佳的五种模型。实证结果表明，词袋模型的性能优于基于变压器的模型，然而，我们的运行性能不合理良好的训练和测试语料库。本文还讨论了模型的局限性和进一步改进的范围。"
    },
    {
        "title": "Toward a Better Understanding of Loss Functions for Collaborative\n  Filtering",
        "url": "http://arxiv.org/abs/2308.06091v1",
        "pub_date": "2023-08-11",
        "summary": "Collaborative filtering (CF) is a pivotal technique in modern recommender\nsystems. The learning process of CF models typically consists of three\ncomponents: interaction encoder, loss function, and negative sampling. Although\nmany existing studies have proposed various CF models to design sophisticated\ninteraction encoders, recent work shows that simply reformulating the loss\nfunctions can achieve significant performance gains. This paper delves into\nanalyzing the relationship among existing loss functions. Our mathematical\nanalysis reveals that the previous loss functions can be interpreted as\nalignment and uniformity functions: (i) the alignment matches user and item\nrepresentations, and (ii) the uniformity disperses user and item distributions.\nInspired by this analysis, we propose a novel loss function that improves the\ndesign of alignment and uniformity considering the unique patterns of datasets\ncalled Margin-aware Alignment and Weighted Uniformity (MAWU). The key novelty\nof MAWU is two-fold: (i) margin-aware alignment (MA) mitigates\nuser/item-specific popularity biases, and (ii) weighted uniformity (WU) adjusts\nthe significance between user and item uniformities to reflect the inherent\ncharacteristics of datasets. Extensive experimental results show that MF and\nLightGCN equipped with MAWU are comparable or superior to state-of-the-art CF\nmodels with various loss functions on three public datasets.",
        "translated": "协同过滤(CF)是现代推荐系统中的一项关键技术。CF 模型的学习过程通常由三部分组成: 交互编码器、损耗函数和负采样。虽然许多现有的研究已经提出了各种 CF 模型来设计复杂的交互编码器，最近的工作表明，简单地重新制定损失函数可以取得显著的性能增益。本文深入分析了现有损失函数之间的关系。我们的数学分析表明，先前的损失函数可以解释为对齐和一致性函数: (i)对齐匹配用户和项目表示，和(ii)一致性分散用户和项目分布。受此分析的启发，我们提出了一种新的损失函数，改进了排列和均匀性的设计，考虑到独特的模式数据集称为边缘感知排列和加权均匀性(MAWU)。MAWU 的关键新颖性有两个方面: (i)边际感知对齐(MA)减轻用户/项目特定的流行偏见，和(ii)加权一致性(WU)调整用户和项目一致性之间的显着性以反映数据集的固有特征。大量的实验结果表明，配备 MAWU 的 MF 和 LightGCN 在三个公共数据集上具有各种损失函数，与最先进的 CF 模型相比具有可比性或优越性。"
    },
    {
        "title": "Deep Context Interest Network for Click-Through Rate Prediction",
        "url": "http://arxiv.org/abs/2308.06037v1",
        "pub_date": "2023-08-11",
        "summary": "Click-Through Rate (CTR) prediction, estimating the probability of a user\nclicking on an item, is essential in industrial applications, such as online\nadvertising. Many works focus on user behavior modeling to improve CTR\nprediction performance. However, most of those methods only model users'\npositive interests from users' click items while ignoring the context\ninformation, which is the display items around the clicks, resulting in\ninferior performance. In this paper, we highlight the importance of context\ninformation on user behavior modeling and propose a novel model named Deep\nContext Interest Network (DCIN), which integrally models the click and its\ndisplay context to learn users' context-aware interests. DCIN consists of three\nkey modules: 1) Position-aware Context Aggregation Module (PCAM), which\nperforms aggregation of display items with an attention mechanism; 2)\nFeedback-Context Fusion Module (FCFM), which fuses the representation of clicks\nand display contexts through non-linear feature interaction; 3) Interest\nMatching Module (IMM), which activates interests related with the target item.\nMoreover, we provide our hands-on solution to implement our DCIN model on\nlarge-scale industrial systems. The significant improvements in both offline\nand online evaluations demonstrate the superiority of our proposed DCIN method.\nNotably, DCIN has been deployed on our online advertising system serving the\nmain traffic, which brings 1.5% CTR and 1.5% RPM lift.",
        "translated": "点进率(ctrl)预测，估计用户点击一个项目的概率，在工业应用中是必不可少的，比如在线广告。许多工作集中在用户行为建模，以提高点击率预测性能。然而，这些方法大多只是从用户的点击项目建模用户的积极兴趣，而忽略了上下文信息，即点击周围的显示项目，导致性能较差。本文强调了上下文信息在用户行为建模中的重要性，提出了一种新的模型——深度上下文兴趣网络(Deep Context Interest Network，DCIN)。DCIN 由三个关键模块组成: 1)位置感知上下文聚合模块(PCAM) ，利用注意机制对显示项目进行聚合; 2)反馈上下文融合模块(FCFM) ，通过非线性特征交互融合点击表示和显示上下文; 3)兴趣匹配模块(IMM) ，激活与目标项目相关的兴趣。此外，我们提供了我们的实际解决方案，以实现我们的 DCIN 模型的大规模工业系统。离线和在线评估的显著改进证明了我们提出的 DCIN 方法的优越性。值得注意的是，DCIN 已经部署在我们的在线广告系统服务的主要流量，这带来了1.5% 的点击率和1.5% 的转速提升。"
    },
    {
        "title": "Designing a User Contextual Profile Ontology: A Focus on the Vehicle\n  Sales Domain",
        "url": "http://arxiv.org/abs/2308.06018v1",
        "pub_date": "2023-08-11",
        "summary": "In the digital age, it is crucial to understand and tailor experiences for\nusers interacting with systems and applications. This requires the creation of\nuser contextual profiles that combine user profiles with contextual\ninformation. However, there is a lack of research on the integration of\ncontextual information with different user profiles. This study aims to address\nthis gap by designing a user contextual profile ontology that considers both\nuser profiles and contextual information on each profile. Specifically, we\npresent a design and development of the user contextual profile ontology with a\nfocus on the vehicle sales domain. Our designed ontology serves as a structural\nfoundation for standardizing the representation of user profiles and contextual\ninformation, enhancing the system's ability to capture user preferences and\ncontextual information of the user accurately. Moreover, we illustrate a case\nstudy using the User Contextual Profile Ontology in generating personalized\nrecommendations for vehicle sales domain.",
        "translated": "在数字时代，理解和定制用户与系统和应用程序交互的体验至关重要。这需要创建将用户配置文件与上下文信息组合在一起的用户上下文配置文件。然而，目前对于上下文信息与不同用户概况的整合研究还很缺乏。本研究旨在通过设计一个同时考虑用户概要和每个概要上的上下文信息的用户上下文概要本体来弥补这一差距。具体来说，我们提出了一个以汽车销售领域为重点的用户上下文概要本体的设计和开发。我们设计的本体论为标准化用户配置文件和上下文信息的表示提供了结构基础，提高了系统准确捕获用户偏好和上下文信息的能力。此外，我们举例说明了一个案例研究，使用用户上下文概要本体生成个性化推荐的汽车销售领域。"
    },
    {
        "title": "Self-Alignment with Instruction Backtranslation",
        "url": "http://arxiv.org/abs/2308.06259v1",
        "pub_date": "2023-08-11",
        "summary": "We present a scalable method to build a high quality instruction following\nlanguage model by automatically labelling human-written text with corresponding\ninstructions. Our approach, named instruction backtranslation, starts with a\nlanguage model finetuned on a small amount of seed data, and a given web\ncorpus. The seed model is used to construct training examples by generating\ninstruction prompts for web documents (self-augmentation), and then selecting\nhigh quality examples from among these candidates (self-curation). This data is\nthen used to finetune a stronger model. Finetuning LLaMa on two iterations of\nour approach yields a model that outperforms all other LLaMa-based models on\nthe Alpaca leaderboard not relying on distillation data, demonstrating highly\neffective self-alignment.",
        "translated": "我们提出了一种可扩展的方法来建立一个高质量的指令遵循语言模型，通过自动标记人写的文本与相应的指令。我们的方法被命名为指令反向翻译，它从一个基于少量种子数据的语言模型和一个给定的 Web 语料库开始。利用种子模型为网络文档生成指令提示(自增强) ，然后从这些候选者中选择高质量的例子(自策划) ，从而构建训练样本。然后使用这些数据来微调一个更强的模型。通过对我们的方法进行两次迭代，微调 LlaMa 产生的模型在不依赖蒸馏数据的 Alpaca 排行榜上优于所有其它基于 LlaMa 的模型，显示出高度有效的自我调整。"
    },
    {
        "title": "KETM:A Knowledge-Enhanced Text Matching method",
        "url": "http://arxiv.org/abs/2308.06235v1",
        "pub_date": "2023-08-11",
        "summary": "Text matching is the task of matching two texts and determining the\nrelationship between them, which has extensive applications in natural language\nprocessing tasks such as reading comprehension, and Question-Answering systems.\nThe mainstream approach is to compute text representations or to interact with\nthe text through attention mechanism, which is effective in text matching\ntasks. However, the performance of these models is insufficient for texts that\nrequire commonsense knowledge-based reasoning. To this end, in this paper, We\nintroduce a new model for text matching called the Knowledge Enhanced Text\nMatching model (KETM), to enrich contextual representations with real-world\ncommon-sense knowledge from external knowledge sources to enhance our model\nunderstanding and reasoning. First, we use Wiktionary to retrieve the text word\ndefinitions as our external knowledge. Secondly, we feed text and knowledge to\nthe text matching module to extract their feature vectors. The text matching\nmodule is used as an interaction module by integrating the encoder layer, the\nco-attention layer, and the aggregation layer. Specifically, the interaction\nprocess is iterated several times to obtain in-depth interaction information\nand extract the feature vectors of text and knowledge by multi-angle pooling.\nThen, we fuse text and knowledge using a gating mechanism to learn the ratio of\ntext and knowledge fusion by a neural network that prevents noise generated by\nknowledge. After that, experimental validation on four datasets are carried\nout, and the experimental results show that our proposed model performs well on\nall four datasets, and the performance of our method is improved compared to\nthe base model without adding external knowledge, which validates the\neffectiveness of our proposed method. The code is available at\nhttps://github.com/1094701018/KETM",
        "translated": "文本匹配是匹配两个文本并确定它们之间的关系的任务，在自然语言处理任务，如阅读理解和问答系统中有广泛的应用。主流的方法是计算文本表征或通过注意机制与文本交互，这在文本匹配任务中是有效的。然而，对于需要基于常识的知识推理的文本来说，这些模型的性能是不够的。为此，本文提出了一种新的文本匹配模型——知识增强型文本匹配模型(KETM) ，该模型利用外部知识来源的现实世界常识知识丰富上下文表示，增强模型的理解和推理能力。首先，我们使用 Wiktionary 检索文本单词定义作为我们的外部知识。其次，将文本和知识输入到文本匹配模块中，提取文本和知识的特征向量;。文本匹配模块通过集成编码器层、共注意层和聚合层作为交互模块。通过多次迭代获取深入的交互信息，采用多角度汇聚的方法提取文本和知识的特征向量。然后，利用门控机制对文本和知识进行融合，通过神经网络学习文本和知识的融合比例，防止知识产生噪声。然后，对四个数据集进行了实验验证，实验结果表明，该模型在四个数据集上都表现出良好的性能，与基本模型相比，在不增加外部知识的情况下，该方法的性能得到了提高，从而验证了该方法的有效性。密码可在 https://github.com/1094701018/ketm 查阅"
    },
    {
        "title": "Thinking Like an Expert:Multimodal Hypergraph-of-Thought (HoT) Reasoning\n  to boost Foundation Modals",
        "url": "http://arxiv.org/abs/2308.06207v1",
        "pub_date": "2023-08-11",
        "summary": "Reasoning ability is one of the most crucial capabilities of a foundation\nmodel, signifying its capacity to address complex reasoning tasks.\nChain-of-Thought (CoT) technique is widely regarded as one of the effective\nmethods for enhancing the reasoning ability of foundation models and has\ngarnered significant attention. However, the reasoning process of CoT is\nlinear, step-by-step, similar to personal logical reasoning, suitable for\nsolving general and slightly complicated problems. On the contrary, the\nthinking pattern of an expert owns two prominent characteristics that cannot be\nhandled appropriately in CoT, i.e., high-order multi-hop reasoning and\nmultimodal comparative judgement. Therefore, the core motivation of this paper\nis transcending CoT to construct a reasoning paradigm that can think like an\nexpert. The hyperedge of a hypergraph could connect various vertices, making it\nnaturally suitable for modelling high-order relationships. Inspired by this,\nthis paper innovatively proposes a multimodal Hypergraph-of-Thought (HoT)\nreasoning paradigm, which enables the foundation models to possess the\nexpert-level ability of high-order multi-hop reasoning and multimodal\ncomparative judgement. Specifically, a textual hypergraph-of-thought is\nconstructed utilizing triple as the primary thought to model higher-order\nrelationships, and a hyperedge-of-thought is generated through multi-hop\nwalking paths to achieve multi-hop inference. Furthermore, we devise a visual\nhypergraph-of-thought to interact with the textual hypergraph-of-thought via\nCross-modal Co-Attention Graph Learning for multimodal comparative\nverification. Experimentations on the ScienceQA benchmark demonstrate the\nproposed HoT-based T5 outperforms CoT-based GPT3.5 and chatGPT, which is on par\nwith CoT-based GPT4 with a lower model size.",
        "translated": "推理能力是一个基础模型最关键的能力之一，表明了其处理复杂推理任务的能力。思维链(CoT)技术被广泛认为是提高基础模型推理能力的有效方法之一，受到人们的重视。然而，科技推理的过程是线性的，一步一步的，类似于个人的逻辑推理，适合解决一般的和稍微复杂的问题。相反，专家的思维模式具有两个显著特征，即高阶多跳推理和多模态比较判断。因此，本文的核心动机是超越 CoT，构建一个能够像专家一样思考的推理范式。超图的超边可以连接不同的顶点，使其自然地适合于建模高阶关系。受此启发，本文创新性地提出了一种多模态超图思维(Hypergraph-of-Thought，HoT)推理范式，使基础模型具有专家级的高阶多跳推理能力和多模态比较判断能力。具体地说，利用三元组作为主要思想来建立高阶关系的文本思维超图，并通过多跳步行路径生成文本思维超图来实现多跳推理。此外，我们还设计了一个视觉思维超图，通过跨模态共注意图学习与文本思维超图进行交互，用于多模态比较验证。在 ScienceQA 基准上的实验证明，提出的基于 HoT 的 T5优于基于 CoT 的 GPT3.5和 chatGPT，后者与基于 CoT 的 GPT4具有较低的模型大小相当。"
    },
    {
        "title": "Weakly Supervised Text Classification on Free Text Comments in\n  Patient-Reported Outcome Measures",
        "url": "http://arxiv.org/abs/2308.06199v1",
        "pub_date": "2023-08-11",
        "summary": "Free text comments (FTC) in patient-reported outcome measures (PROMs) data\nare typically analysed using manual methods, such as content analysis, which is\nlabour-intensive and time-consuming. Machine learning analysis methods are\nlargely unsupervised, necessitating post-analysis interpretation. Weakly\nsupervised text classification (WSTC) can be a valuable method of analysis to\nclassify domain-specific text data in which there is limited labelled data. In\nthis paper, we apply five WSTC techniques to FTC in PROMs data to identify\nhealth-related quality of life (HRQoL) themes reported by colorectal cancer\npatients. The WSTC methods label all the themes mentioned in the FTC. The\nresults showed moderate performance on the PROMs data, mainly due to the\nprecision of the models, and variation between themes. Evaluation of the\nclassification performance illustrated the potential and limitations of keyword\nbased WSTC to label PROMs FTC when labelled data is limited.",
        "translated": "患者报告的结果测量(PROM)数据中的自由文本评论(FTC)通常使用人工方法进行分析，如内容分析，这是劳动密集型和耗时的。机器学习分析方法在很大程度上是无监督的，需要分析后的解释。弱监督文本分类(WSTC)是一种有价值的分析方法，可用于分类领域特定的文本数据，其中有限的标记数据。在这篇文章中，我们将五种 WSTC 技术应用于 PROMs 数据中的 FTC，以识别大肠癌患者报告的与健康相关的生活质量(HRQoL)主题。WSTC 方法标记 FTC 中提到的所有主题。结果表明，由于模型的精度和主题间的差异，PROM 数据的性能适中。对分类性能的评估说明了在标记数据有限的情况下，基于关键字的 WSTC 标记 PROM FTC 的潜力和局限性。"
    },
    {
        "title": "Assessing Guest Nationality Composition from Hotel Reviews",
        "url": "http://arxiv.org/abs/2308.06175v1",
        "pub_date": "2023-08-11",
        "summary": "Many hotels target guest acquisition efforts to specific markets in order to\nbest anticipate individual preferences and needs of their guests. Likewise,\nsuch strategic positioning is a prerequisite for efficient marketing budget\nallocation. Official statistics report on the number of visitors from different\ncountries, but no fine-grained information on the guest composition of\nindividual businesses exists. There is, however, growing interest in such data\nfrom competitors, suppliers, researchers and the general public. We demonstrate\nhow machine learning can be leveraged to extract references to guest\nnationalities from unstructured text reviews in order to dynamically assess and\nmonitor the dynamics of guest composition of individual businesses. In\nparticular, we show that a rather simple architecture of pre-trained embeddings\nand stacked LSTM layers provides a better performance-runtime tradeoff than\nmore complex state-of-the-art language models.",
        "translated": "许多酒店针对特定的市场进行客户收购，以便最好地预测客人的个人喜好和需求。同样，这样的战略定位是有效的营销预算分配的先决条件。官方统计数据报告了来自不同国家的游客人数，但没有关于个别企业客户构成的细致信息。然而，竞争对手、供应商、研究人员和普通大众对此类数据的兴趣日益浓厚。我们展示了如何利用机器学习从非结构化的文本评论中提取对来宾国籍的引用，以便动态评估和监视各个业务的来宾组合的动态。特别是，我们展示了一个相当简单的预训练嵌入和堆叠 LSTM 层的架构，与更复杂的最先进的语言模型相比，它提供了更好的性能-运行时折衷。"
    },
    {
        "title": "Task Conditioned BERT for Joint Intent Detection and Slot-filling",
        "url": "http://arxiv.org/abs/2308.06165v1",
        "pub_date": "2023-08-11",
        "summary": "Dialogue systems need to deal with the unpredictability of user intents to\ntrack dialogue state and the heterogeneity of slots to understand user\npreferences. In this paper we investigate the hypothesis that solving these\nchallenges as one unified model will allow the transfer of parameter support\ndata across the different tasks. The proposed principled model is based on a\nTransformer encoder, trained on multiple tasks, and leveraged by a rich input\nthat conditions the model on the target inferences. Conditioning the\nTransformer encoder on multiple target inferences over the same corpus, i.e.,\nintent and multiple slot types, allows learning richer language interactions\nthan a single-task model would be able to. In fact, experimental results\ndemonstrate that conditioning the model on an increasing number of dialogue\ninference tasks leads to improved results: on the MultiWOZ dataset, the joint\nintent and slot detection can be improved by 3.2\\% by conditioning on intent,\n10.8\\% by conditioning on slot and 14.4\\% by conditioning on both intent and\nslots. Moreover, on real conversations with Farfetch costumers, the proposed\nconditioned BERT can achieve high joint-goal and intent detection performance\nthroughout a dialogue.",
        "translated": "对话系统需要处理用户意图的不可预测性，以跟踪对话状态和时隙的异质性，以了解用户偏好。在本文中，我们研究的假设，解决这些挑战作为一个统一的模型将允许在不同的任务之间的参数支持数据的转移。提出的原理模型基于一个跑车编码器，训练多个任务，并利用丰富的输入条件模型的目标推断。在同一个语料库中，根据多个目标推理(即意图和多个插槽类型)来调节 Transformer 编码器，可以学习比单任务模型更丰富的语言交互。实验结果表明，该模型对越来越多的对话推理任务进行条件化处理可以得到更好的结果: 在 MultiWOZ 数据集上，通过对意图的条件化处理，联合意图和时隙检测能够提高3.2% ，通过对时隙的条件化处理能够提高10.8% ，通过对意图和时隙的条件化处理能够提高14.4% 。此外，在与远程客户的真实对话中，提出的条件误码率可以在整个对话过程中实现较高的联合目标和意图检测性能。"
    },
    {
        "title": "Improving Joint Speech-Text Representations Without Alignment",
        "url": "http://arxiv.org/abs/2308.06125v1",
        "pub_date": "2023-08-11",
        "summary": "The last year has seen astonishing progress in text-prompted image generation\npremised on the idea of a cross-modal representation space in which the text\nand image domains are represented jointly. In ASR, this idea has found\napplication as joint speech-text encoders that can scale to the capacities of\nvery large parameter models by being trained on both unpaired speech and text.\nWhile these methods show promise, they have required special treatment of the\nsequence-length mismatch inherent in speech and text, either by up-sampling\nheuristics or an explicit alignment model. In this work, we offer evidence that\njoint speech-text encoders naturally achieve consistent representations across\nmodalities by disregarding sequence length, and argue that consistency losses\ncould forgive length differences and simply assume the best alignment. We show\nthat such a loss improves downstream WER in both a large-parameter monolingual\nand multilingual system.",
        "translated": "去年，基于跨模态表示空间的文本提示图像生成技术取得了惊人的进展。在 ASR 中，这种思想作为联合语音文本编码器得到了应用，它可以通过对非成对语音和文本进行训练来扩展非常大的参数模型的容量。虽然这些方法显示了希望，但它们需要特别处理语音和文本中固有的序列长度不匹配，无论是通过上采样启发式或显式比对模型。在这项工作中，我们提供的证据表明，联合语音文本编码器自然实现一致的表示跨模式无视序列长度，并认为一致性损失可以原谅长度差异，只是假定最佳比对。我们表明，这样的损失改善下游水资源利用率在一个大参数单语言和多语言系统。"
    },
    {
        "title": "Lip2Vec: Efficient and Robust Visual Speech Recognition via\n  Latent-to-Latent Visual to Audio Representation Mapping",
        "url": "http://arxiv.org/abs/2308.06112v1",
        "pub_date": "2023-08-11",
        "summary": "Visual Speech Recognition (VSR) differs from the common perception tasks as\nit requires deeper reasoning over the video sequence, even by human experts.\nDespite the recent advances in VSR, current approaches rely on labeled data to\nfully train or finetune their models predicting the target speech. This hinders\ntheir ability to generalize well beyond the training set and leads to\nperformance degeneration under out-of-distribution challenging scenarios.\nUnlike previous works that involve auxiliary losses or complex training\nprocedures and architectures, we propose a simple approach, named Lip2Vec that\nis based on learning a prior model. Given a robust visual speech encoder, this\nnetwork maps the encoded latent representations of the lip sequence to their\ncorresponding latents from the audio pair, which are sufficiently invariant for\neffective text decoding. The generated audio representation is then decoded to\ntext using an off-the-shelf Audio Speech Recognition (ASR) model. The proposed\nmodel compares favorably with fully-supervised learning methods on the LRS3\ndataset achieving 26 WER. Unlike SoTA approaches, our model keeps a reasonable\nperformance on the VoxCeleb test set. We believe that reprogramming the VSR as\nan ASR task narrows the performance gap between the two and paves the way for\nmore flexible formulations of lip reading.",
        "translated": "视觉语音识别(VSR)不同于一般的感知任务，它需要对视频序列进行更深层次的推理，即使是人类专家也不例外。尽管 VSR 最近取得了一些进步，但目前的方法依赖于标记数据来完全训练或调整预测目标语言的模型。这阻碍了他们在训练集之外进行推广的能力，并导致在分布外挑战情景下的性能退化。不像以前的工作，涉及辅助损失或复杂的训练过程和架构，我们提出了一个简单的方法，命名为 Lip2Vec，这是基于学习先前的模型。给定一个鲁棒的可视语音编码器，该网络将唇序列的编码潜在表示映射到音频对的相应潜在表示，这对有效的文本解码是充分不变的。然后使用现成的音频语音识别(ASR)模型将生成的音频表示解码为文本。该模型与全监督学习方法相比，在 LRS3数据集上获得了26个 WER。与 SoTA 方法不同，我们的模型在 VoxCeleb 测试集上保持了合理的性能。我们相信，将 VSR 重新编程为 ASR 任务，可以缩小两者之间的性能差距，为更灵活的唇读公式铺平道路。"
    },
    {
        "title": "Cross-Attribute Matrix Factorization Model with Shared User Embedding",
        "url": "http://arxiv.org/abs/2308.07284v1",
        "pub_date": "2023-08-14",
        "summary": "Over the past few years, deep learning has firmly established its prowess\nacross various domains, including computer vision, speech recognition, and\nnatural language processing. Motivated by its outstanding success, researchers\nhave been directing their efforts towards applying deep learning techniques to\nrecommender systems. Neural collaborative filtering (NCF) and Neural Matrix\nFactorization (NeuMF) refreshes the traditional inner product in matrix\nfactorization with a neural architecture capable of learning complex and\ndata-driven functions. While these models effectively capture user-item\ninteractions, they overlook the specific attributes of both users and items.\nThis can lead to robustness issues, especially for items and users that belong\nto the \"long tail\". Such challenges are commonly recognized in recommender\nsystems as a part of the cold-start problem. A direct and intuitive approach to\naddress this issue is by leveraging the features and attributes of the items\nand users themselves. In this paper, we introduce a refined NeuMF model that\nconsiders not only the interaction between users and items, but also acrossing\nassociated attributes. Moreover, our proposed architecture features a shared\nuser embedding, seamlessly integrating with user embeddings to imporve the\nrobustness and effectively address the cold-start problem. Rigorous experiments\non both the Movielens and Pinterest datasets demonstrate the superiority of our\nCross-Attribute Matrix Factorization model, particularly in scenarios\ncharacterized by higher dataset sparsity.",
        "translated": "在过去的几年里，深度学习已经牢固地确立了它在各个领域的实力，包括计算机视觉，语音识别和自然语言处理。由于其卓越的成功，研究人员一直致力于将深度学习技术应用于推荐系统。神经协同过滤(nCF)和神经矩阵分解(NeuMF)为传统的内部产品提供了新的矩阵分解，具有能够学习复杂和数据驱动功能的神经结构。虽然这些模型有效地捕获了用户-项交互，但它们忽略了用户和项的特定属性。这可能导致健壮性问题，特别是对于属于“长尾”的项和用户。这种挑战在推荐系统中被普遍认为是冷启动问题的一部分。解决这个问题的一个直接和直观的方法是利用项目和用户本身的特性和属性。在本文中，我们介绍了一个改进的 NeuMF 模型，它不仅考虑了用户和项目之间的交互，而且还考虑了相关属性之间的交互。此外，我们提出的体系结构具有共享用户嵌入的特点，与用户嵌入无缝集成，以提高健壮性和有效地解决冷启动问题。在 Movielens 和 Pinterest 数据集上的严格实验证明了我们的交叉属性矩阵分解模型的优越性，特别是在数据集稀疏性更高的情况下拥有属性。"
    },
    {
        "title": "EasyEdit: An Easy-to-use Knowledge Editing Framework for Large Language\n  Models",
        "url": "http://arxiv.org/abs/2308.07269v1",
        "pub_date": "2023-08-14",
        "summary": "Large Language Models (LLMs) usually suffer from knowledge cutoff or fallacy\nissues, which means they are unaware of unseen events or generate text with\nincorrect facts owing to the outdated/noisy data. To this end, many knowledge\nediting approaches for LLMs have emerged -- aiming to subtly inject/edit\nupdated knowledge or adjust undesired behavior while minimizing the impact on\nunrelated inputs. Nevertheless, due to significant differences among various\nknowledge editing methods and the variations in task setups, there is no\nstandard implementation framework available for the community, which hinders\npractitioners to apply knowledge editing to applications. To address these\nissues, we propose EasyEdit, an easy-to-use knowledge editing framework for\nLLMs. It supports various cutting-edge knowledge editing approaches and can be\nreadily apply to many well-known LLMs such as T5, GPT-J, LlaMA, etc.\nEmpirically, we report the knowledge editing results on LlaMA-2 with EasyEdit,\ndemonstrating that knowledge editing surpasses traditional fine-tuning in terms\nof reliability and generalization. We have released the source code on GitHub\nat https://github.com/zjunlp/EasyEdit, along with Google Colab tutorials and\ncomprehensive documentation for beginners to get started. Besides, we present\nan online system for real-time knowledge editing, and a demo video at\nhttp://knowlm.zjukg.cn/easyedit.mp4.",
        "translated": "大型语言模型(LLM)通常存在知识截断或谬误问题，这意味着由于过时/噪声数据，它们不知道看不见的事件或生成具有不正确事实的文本。为此，许多 LLM 的知识编辑方法已经出现——旨在巧妙地注入/编辑更新的知识或调整不希望的行为，同时尽量减少对不相关输入的影响。然而，由于各种知识编辑方法之间的显著差异和任务设置的差异，社区没有可用的标准实现框架，这阻碍了从业人员将知识编辑应用于应用程序。为了解决这些问题，我们提出了 EasyEdit，一个用于 LLM 的易于使用的知识编辑框架。它支持各种前沿的知识编辑方法，可以很容易地应用于许多著名的 LLM，如 T5，GPT-J，LlaMA 等。实证结果表明，知识编辑在可靠性和泛化性方面优于传统的微调。我们已经在 https://GitHub.com/zjunlp/easyedit 上发布了 GitHub 的源代码，同时还发布了 Google Colab 教程和全面的文档供初学者入门。此外，我们还提供了一个实时知识编辑的在线系统，以及一个 http://knowlm.zjukg.cn/easyedit.mp4演示视频。"
    },
    {
        "title": "MM-GEF: Multi-modal representation meet collaborative filtering",
        "url": "http://arxiv.org/abs/2308.07222v1",
        "pub_date": "2023-08-14",
        "summary": "In modern e-commerce, item content features in various modalities offer\naccurate yet comprehensive information to recommender systems. The majority of\nprevious work either focuses on learning effective item representation during\nmodelling user-item interactions, or exploring item-item relationships by\nanalysing multi-modal features. Those methods, however, fail to incorporate the\ncollaborative item-user-item relationships into the multi-modal feature-based\nitem structure. In this work, we propose a graph-based item structure\nenhancement method MM-GEF: Multi-Modal recommendation with Graph Early-Fusion,\nwhich effectively combines the latent item structure underlying multi-modal\ncontents with the collaborative signals. Instead of processing the content\nfeature in different modalities separately, we show that the early-fusion of\nmulti-modal features provides significant improvement. MM-GEF learns refined\nitem representations by injecting structural information obtained from both\nmulti-modal and collaborative signals. Through extensive experiments on four\npublicly available datasets, we demonstrate systematical improvements of our\nmethod over state-of-the-art multi-modal recommendation methods.",
        "translated": "在现代电子商务中，各种形式的项目内容特征为推荐系统提供了准确而全面的信息。以往的研究主要集中在建立用户-项目交互模型的过程中学习有效的项目表示，或者通过分析多模态特征来探索项目-项目关系。然而，这些方法未能将协同项目-用户-项目关系融入到基于多模态特征的项目结构中。本文提出了一种基于图形的项目结构增强方法 MM-GEF: 结合图形早期融合的多模态推荐方法，该方法有效地将多模态内容的潜在项目结构与协作信号结合起来。研究表明，多模态特征的早期融合能够显著改善多模态特征的内容特征，而不是分别对不同模态的内容特征进行处理。通过注入从多模态信号和协作信号中获得的结构信息，MM-GEF 学习精细项表示。通过对四个公开数据集的大量实验，我们证明了我们的方法比最先进的多模态推荐方法有系统的改进。"
    },
    {
        "title": "gSASRec: Reducing Overconfidence in Sequential Recommendation Trained\n  with Negative Sampling",
        "url": "http://arxiv.org/abs/2308.07192v1",
        "pub_date": "2023-08-14",
        "summary": "A large catalogue size is one of the central challenges in training\nrecommendation models: a large number of items makes them memory and\ncomputationally inefficient to compute scores for all items during training,\nforcing these models to deploy negative sampling. However, negative sampling\nincreases the proportion of positive interactions in the training data, and\ntherefore models trained with negative sampling tend to overestimate the\nprobabilities of positive interactions a phenomenon we call overconfidence.\nWhile the absolute values of the predicted scores or probabilities are not\nimportant for the ranking of retrieved recommendations, overconfident models\nmay fail to estimate nuanced differences in the top-ranked items, resulting in\ndegraded performance. In this paper, we show that overconfidence explains why\nthe popular SASRec model underperforms when compared to BERT4Rec. This is\ncontrary to the BERT4Rec authors explanation that the difference in performance\nis due to the bi-directional attention mechanism. To mitigate overconfidence,\nwe propose a novel Generalised Binary Cross-Entropy Loss function (gBCE) and\ntheoretically prove that it can mitigate overconfidence. We further propose the\ngSASRec model, an improvement over SASRec that deploys an increased number of\nnegatives and the gBCE loss. We show through detailed experiments on three\ndatasets that gSASRec does not exhibit the overconfidence problem. As a result,\ngSASRec can outperform BERT4Rec (e.g. +9.47% NDCG on the MovieLens-1M dataset),\nwhile requiring less training time (e.g. -73% training time on MovieLens-1M).\nMoreover, in contrast to BERT4Rec, gSASRec is suitable for large datasets that\ncontain more than 1 million items.",
        "translated": "大目录规模是培训推荐模型的核心挑战之一: 大量的项目使得它们在计算培训期间所有项目的分数时内存和计算效率低下，迫使这些模型部署负抽样。然而，负抽样增加了训练数据中正相互作用的比例，因此用负抽样训练的模型倾向于高估正相互作用的概率，我们称之为过度自信现象。虽然预测分数或概率的绝对值对于检索推荐的排名并不重要，但过度自信的模型可能无法估计排名最高的项目的细微差异，导致性能下降。在本文中，我们表明，过度自信解释了为什么流行的 SASRec 模型表现不如 BERT4Rec。这与 BERT4Rec 的作者解释的性能差异是由于双向注意机制相反。为了减轻过度自信，我们提出了一种新的广义二元交叉熵损失函数(gBCE) ，并从理论上证明了它可以减轻过度自信。我们进一步提出了 gSASRec 模型，这是对 SASRec 模型的一个改进，它部署了更多的负片和 gBCE 损失。通过对三个数据集的详细实验，我们发现 gSASRec 不存在过度自信问题。因此，gSASRec 的性能优于 BERT4Rec (例如，在 MovieLens-1M 数据集上 + 9.47% NDCG) ，同时需要较少的训练时间(例如，在 MovieLens-1M 上 -73% 的训练时间)。此外，与 BERT4Rec 不同，gSASRec 适用于包含超过100万个项目的大型数据集。"
    },
    {
        "title": "Natural Language is All a Graph Needs",
        "url": "http://arxiv.org/abs/2308.07134v1",
        "pub_date": "2023-08-14",
        "summary": "The emergence of large-scale pre-trained language models, such as ChatGPT,\nhas revolutionized various research fields in artificial intelligence.\nTransformers-based large language models (LLMs) have gradually replaced CNNs\nand RNNs to unify fields of computer vision and natural language processing.\nCompared with the data that exists relatively independently such as images,\nvideos or texts, graph is a type of data that contains rich structural and\nrelational information. Meanwhile, natural language, as one of the most\nexpressive mediums, excels in describing complex structures. However, existing\nwork on incorporating graph learning problems into the generative language\nmodeling framework remains very limited. As the importance of language models\ncontinues to grow, it becomes essential to explore whether LLMs can also\nreplace GNNs as the foundational model for graphs. In this paper, we propose\nInstructGLM (Instruction-finetuned Graph Language Model), systematically design\nhighly scalable prompts based on natural language instructions, and use natural\nlanguage to describe the geometric structure and node features of the graph for\ninstruction tuning an LLMs to perform learning and inference on graphs in a\ngenerative manner. Our method exceeds all competitive GNN baselines on\nogbn-arxiv, Cora and PubMed datasets, which demonstrates the effectiveness of\nour method and sheds light on generative language models replacing GNNs as the\nfoundation model for graph machine learning.",
        "translated": "大规模预训练语言模型(如 ChatGPT)的出现，彻底改变了人工智能的各个研究领域。基于变换器的大语言模型(LLM)逐渐取代了 CNN 和 RNN，统一了计算机视觉和自然语言处理领域。与图像、视频、文本等相对独立存在的数据相比，图形是一种包含丰富的结构信息和关系信息的数据类型。同时，自然语言作为最具表现力的语言媒介之一，在描述复杂结构方面表现得尤为突出。然而，现有的将图学习问题纳入生成语言建模框架的工作仍然非常有限。随着语言模型的重要性不断增长，探索 LLM 是否也可以取代 GNN 作为图形的基础模型变得至关重要。本文提出了指令微调图语言模型，系统地设计了基于自然语言指令的高度可扩展的提示符，并利用自然语言描述了指令微调图的几何结构和节点特征，以生成的方式对图进行学习和推理。我们的方法超越了 ogbn-arxiv，Cora 和 PubMed 数据集上所有竞争性的 GNN 基线，这证明了我们的方法的有效性，并揭示了代替 GNN 的生成语言模型作为图形机器学习的基础模型。"
    },
    {
        "title": "Platypus: Quick, Cheap, and Powerful Refinement of LLMs",
        "url": "http://arxiv.org/abs/2308.07317v1",
        "pub_date": "2023-08-14",
        "summary": "We present $\\textbf{Platypus}$, a family of fine-tuned and merged Large\nLanguage Models (LLMs) that achieves the strongest performance and currently\nstands at first place in HuggingFace's Open LLM Leaderboard as of the release\ndate of this work. In this work we describe (1) our curated dataset\n$\\textbf{Open-Platypus}$, that is a subset of other open datasets and which\n$\\textit{we release to the public}$ (2) our process of fine-tuning and merging\nLoRA modules in order to conserve the strong prior of pretrained LLMs, while\nbringing specific domain knowledge to the surface (3) our efforts in checking\nfor test data leaks and contamination in the training data, which can inform\nfuture research. Specifically, the Platypus family achieves strong performance\nin quantitative LLM metrics across model sizes, topping the global Open LLM\nleaderboard while using just a fraction of the fine-tuning data and overall\ncompute that are required for other state-of-the-art fine-tuned LLMs. In\nparticular, a 13B Platypus model can be trained on $\\textit{a single}$ A100 GPU\nusing 25k questions in 5 hours. This is a testament of the quality of our\nOpen-Platypus dataset, and opens opportunities for more improvements in the\nfield. Project page: https://platypus-llm.github.io",
        "translated": "我们展示 $textbf { Platypus } $，一个经过微调和合并的大型语言模型(LLM)家族，它实现了最强的性能，目前在 HuggingFace 的 Open LLM 排行榜上排名第一。在这项工作中，我们描述(1)我们策划的数据集 $textbf { Open-Platypus } $，这是其他开放数据集的一个子集，并且 $texttit {我们向公众发布} $(2)我们微调和合并 LoRA 模块的过程，以保存预先训练的 LLM 的强大优先级，同时将特定的领域知识带到表面(3)我们努力检查测试数据泄漏和培训数据中的污染，这可以为未来的研究提供信息。具体而言，Platypus 系列在不同模型尺寸的定量 LLM 指标方面取得了强大的性能，在全球 Open LLM 排行榜上名列前茅，同时只使用了其他最先进的微调 LLM 所需的微调数据和总体计算的一小部分。特别是，一个13B 鸭嘴兽模型可以在 $textit { a single } $A100图形处理器上用25k 问题在5小时内进行培训。这证明了我们的开放鸭嘴兽数据集的质量，并为该领域的更多改进提供了机会。项目主页:  https://platypus-llm.github.io"
    },
    {
        "title": "LLM Self Defense: By Self Examination, LLMs Know They Are Being Tricked",
        "url": "http://arxiv.org/abs/2308.07308v2",
        "pub_date": "2023-08-14",
        "summary": "Large language models (LLMs) have skyrocketed in popularity in recent years\ndue to their ability to generate high-quality text in response to human\nprompting. However, these models have been shown to have the potential to\ngenerate harmful content in response to user prompting (e.g., giving users\ninstructions on how to commit crimes). There has been a focus in the literature\non mitigating these risks, through methods like aligning models with human\nvalues through reinforcement learning. However, it has been shown that even\naligned language models are susceptible to adversarial attacks that bypass\ntheir restrictions on generating harmful text. We propose a simple approach to\ndefending against these attacks by having a large language model filter its own\nresponses. Our current results show that even if a model is not fine-tuned to\nbe aligned with human values, it is possible to stop it from presenting harmful\ncontent to users by validating the content using a language model.",
        "translated": "大语言模型(LLM)近年来迅速流行起来，因为它们能够根据人类的提示生成高质量的文本。然而，这些模型已经被证明有潜力产生有害的内容回应用户的提示(例如，给用户如何犯罪的指示)。通过诸如通过强化学习调整模型与人类价值观之类的方法，文献中一直关注如何减轻这些风险。然而，研究表明，即使是对齐的语言模型也容易受到对抗性攻击，这些攻击绕过了它们对生成有害文本的限制。我们提出了一个简单的方法来防御这些攻击，通过一个大型的语言模型过滤自己的反应。我们目前的研究结果表明，即使一个模型没有经过微调以便与人类的价值观保持一致，也有可能通过使用语言模型验证内容来阻止它向用户呈现有害的内容。"
    },
    {
        "title": "Neural Authorship Attribution: Stylometric Analysis on Large Language\n  Models",
        "url": "http://arxiv.org/abs/2308.07305v1",
        "pub_date": "2023-08-14",
        "summary": "Large language models (LLMs) such as GPT-4, PaLM, and Llama have\nsignificantly propelled the generation of AI-crafted text. With rising concerns\nabout their potential misuse, there is a pressing need for AI-generated-text\nforensics. Neural authorship attribution is a forensic effort, seeking to trace\nAI-generated text back to its originating LLM. The LLM landscape can be divided\ninto two primary categories: proprietary and open-source. In this work, we\ndelve into these emerging categories of LLMs, focusing on the nuances of neural\nauthorship attribution. To enrich our understanding, we carry out an empirical\nanalysis of LLM writing signatures, highlighting the contrasts between\nproprietary and open-source models, and scrutinizing variations within each\ngroup. By integrating stylometric features across lexical, syntactic, and\nstructural aspects of language, we explore their potential to yield\ninterpretable results and augment pre-trained language model-based classifiers\nutilized in neural authorship attribution. Our findings, based on a range of\nstate-of-the-art LLMs, provide empirical insights into neural authorship\nattribution, paving the way for future investigations aimed at mitigating the\nthreats posed by AI-generated misinformation.",
        "translated": "大型语言模型(LLM) ，如 GPT-4、 PalM 和 Llama，极大地推动了人工智能文本的生成。随着人们越来越担心它们可能被滥用，迫切需要人工智能生成的文本取证。神经作者归属是一个法医的努力，寻求跟踪人工智能生成的文本回到其原始 LLM。LLM 的前景可以分为两个主要类别: 专有的和开源的。在这项工作中，我们深入研究这些新兴类别的 LLM，重点是神经作者归因的细微差别。为了丰富我们的理解，我们对 LLM 的写作签名进行了实证分析，强调了专有模型和开源模型之间的对比，并仔细研究了每个群体内部的差异。通过整合语言的词汇、句法和结构方面的文体特征，我们探索了它们产生可解释结果的潜力，并增强了神经作者归因中使用的预先训练的基于语言模型的分类器。我们的研究结果基于一系列最先进的 LLM，为神经作者归因提供了经验性的见解，为未来旨在减轻人工智能产生的错误信息所构成的威胁的研究铺平了道路。"
    },
    {
        "title": "The Devil is in the Errors: Leveraging Large Language Models for\n  Fine-grained Machine Translation Evaluation",
        "url": "http://arxiv.org/abs/2308.07286v1",
        "pub_date": "2023-08-14",
        "summary": "Automatic evaluation of machine translation (MT) is a critical tool driving\nthe rapid iterative development of MT systems. While considerable progress has\nbeen made on estimating a single scalar quality score, current metrics lack the\ninformativeness of more detailed schemes that annotate individual errors, such\nas Multidimensional Quality Metrics (MQM). In this paper, we help fill this gap\nby proposing AutoMQM, a prompting technique which leverages the reasoning and\nin-context learning capabilities of large language models (LLMs) and asks them\nto identify and categorize errors in translations. We start by evaluating\nrecent LLMs, such as PaLM and PaLM-2, through simple score prediction\nprompting, and we study the impact of labeled data through in-context learning\nand finetuning. We then evaluate AutoMQM with PaLM-2 models, and we find that\nit improves performance compared to just prompting for scores (with\nparticularly large gains for larger models) while providing interpretability\nthrough error spans that align with human annotations.",
        "translated": "机器翻译的自动评估是推动机器翻译系统快速迭代开发的关键工具。虽然在估计单个标量质量得分方面已经取得了相当大的进展，但是目前的指标缺乏注释单个错误的更详细方案的信息性，例如多维质量指标(MQM)。在本文中，我们提出了 AutoMQM，一种利用大型语言模型(LLM)的推理和上下文学习能力的提示技术，并要求它们识别和分类翻译中的错误。我们首先通过简单的分数预测提示来评估最近的 LLM，如 PaLM 和 PaLM-2，然后通过上下文学习和微调来研究标记数据的影响。然后，我们使用 PaLM-2模型评估 AutoMQM，我们发现与仅仅提示得分(对于较大的模型具有特别大的增益)相比，它提高了性能，同时通过与人工注释一致的错误范围提供了可解释性。"
    },
    {
        "title": "Comparison between parameter-efficient techniques and full fine-tuning:\n  A case study on multilingual news article classification",
        "url": "http://arxiv.org/abs/2308.07282v1",
        "pub_date": "2023-08-14",
        "summary": "Adapters and Low-Rank Adaptation (LoRA) are parameter-efficient fine-tuning\ntechniques designed to make the training of language models more efficient.\nPrevious results demonstrated that these methods can even improve performance\non some classification tasks. This paper complements the existing research by\ninvestigating how these techniques influence the classification performance and\ncomputation costs compared to full fine-tuning when applied to multilingual\ntext classification tasks (genre, framing, and persuasion techniques detection;\nwith different input lengths, number of predicted classes and classification\ndifficulty), some of which have limited training data. In addition, we conduct\nin-depth analyses of their efficacy across different training scenarios\n(training on the original multilingual data; on the translations into English;\nand on a subset of English-only data) and different languages. Our findings\nprovide valuable insights into the applicability of the parameter-efficient\nfine-tuning techniques, particularly to complex multilingual and multilabel\nclassification tasks.",
        "translated": "适配器和低秩自适应(LoRA)是一种参数有效的微调技术，旨在提高语言模型的训练效率。以往的研究结果表明，这些方法甚至可以提高一些分类任务的性能。本文通过研究这些技术在多语言文本分类任务(体裁、框架和说服技术检测; 不同的输入长度、预测类数量和分类困难)中对分类性能和计算成本的影响，与完全微调相比，其中一些训练数据有限。此外，我们对不同训练场景(对原始多语言数据的训练; 对翻译成英语的训练; 以及对一部分纯英语数据的训练)和不同语言的训练效果进行了深入分析。我们的研究结果提供了有价值的见解，参数效率微调技术的适用性，特别是对复杂的多语言和多标签分类任务。"
    },
    {
        "title": "Dialogue for Prompting: a Policy-Gradient-Based Discrete Prompt\n  Optimization for Few-shot Learning",
        "url": "http://arxiv.org/abs/2308.07272v1",
        "pub_date": "2023-08-14",
        "summary": "Prompt-based pre-trained language models (PLMs) paradigm have succeeded\nsubstantially in few-shot natural language processing (NLP) tasks. However,\nprior discrete prompt optimization methods require expert knowledge to design\nthe base prompt set and identify high-quality prompts, which is costly,\ninefficient, and subjective. Meanwhile, existing continuous prompt optimization\nmethods improve the performance by learning the ideal prompts through the\ngradient information of PLMs, whose high computational cost, and low\nreadability and generalizability are often concerning. To address the research\ngap, we propose a Dialogue-comprised Policy-gradient-based Discrete Prompt\nOptimization ($DP_2O$) method. We first design a multi-round dialogue alignment\nstrategy for readability prompt set generation based on GPT-4. Furthermore, we\npropose an efficient prompt screening metric to identify high-quality prompts\nwith linear complexity. Finally, we construct a reinforcement learning (RL)\nframework based on policy gradients to match the prompts to inputs optimally.\nBy training a policy network with only 0.67% of the PLM parameter size on the\ntasks in the few-shot setting, $DP_2O$ outperforms the state-of-the-art (SOTA)\nmethod by 1.52% in accuracy on average on four open-source datasets. Moreover,\nsubsequent experiments also demonstrate that $DP_2O$ has good universality,\nrobustness, and generalization ability.",
        "translated": "基于提示的预训练语言模型(PLM)范式在短镜头自然语言处理(NLP)任务中取得了很大的成功。然而，现有的离散提示优化方法需要专家知识来设计基本提示集和识别高质量的提示，这是昂贵的、低效的和主观的。同时，现有的连续提示优化方法通过利用 PLM 的梯度信息来学习理想提示，提高了系统的性能。针对这一问题，本文提出了一种基于对话包含策略梯度的离散提示优化方法($DP _ 2O $)。我们首先设计了一个基于 GPT-4的多轮对话对齐策略，用于可读性提示集的生成。此外，我们提出了一个有效的快速筛选度量，以识别高质量的提示与线性复杂度。最后，我们建立一个基于策略梯度的强化学习框架，使提示与输入最佳匹配。通过训练一个仅有0.67% PLM 参数大小的策略网络，$DP _ 2O $比最先进的(SOTA)方法在四个开源数据集上的平均准确率提高了1.52% 。此外，后续的实验还证明了 $DP _ 2O $具有良好的通用性、鲁棒性和泛化能力。"
    },
    {
        "title": "ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate",
        "url": "http://arxiv.org/abs/2308.07201v1",
        "pub_date": "2023-08-14",
        "summary": "Text evaluation has historically posed significant challenges, often\ndemanding substantial labor and time cost. With the emergence of large language\nmodels (LLMs), researchers have explored LLMs' potential as alternatives for\nhuman evaluation. While these single-agent-based approaches show promise,\nexperimental results suggest that further advancements are needed to bridge the\ngap between their current effectiveness and human-level evaluation quality.\nRecognizing that best practices of human evaluation processes often involve\nmultiple human annotators collaborating in the evaluation, we resort to a\nmulti-agent debate framework, moving beyond single-agent prompting strategies.\nThe multi-agent-based approach enables a group of LLMs to synergize with an\narray of intelligent counterparts, harnessing their distinct capabilities and\nexpertise to enhance efficiency and effectiveness in handling intricate tasks.\nIn this paper, we construct a multi-agent referee team called ChatEval to\nautonomously discuss and evaluate the quality of generated responses from\ndifferent models on open-ended questions and traditional natural language\ngeneration (NLG) tasks. Our analysis shows that ChatEval transcends mere\ntextual scoring, offering a human-mimicking evaluation process for reliable\nassessments. Our code is available at https://github.com/chanchimin/ChatEval.",
        "translated": "文本评价在历史上一直是一个重大的挑战，往往需要大量的人力和时间成本。随着大型语言模型(LLM)的出现，研究者们开始探索 LLM 作为人类评价替代品的潜力。虽然这些基于单一主体的方法显示出希望，但实验结果表明，需要进一步改进，以弥合其目前的有效性与人的评价质量之间的差距。认识到人类评价过程的最佳做法往往涉及多个人类注释者在评价中协作，我们采用多主体辩论框架，超越单主体激励战略。基于多代理的方法使一组 LLM 能够与一系列智能对应方协同作用，利用它们独特的能力和专门知识来提高处理复杂任务的效率和有效性。本文构建了一个名为 ChatEval 的多智能体裁判团队，用于自主讨论和评估开放式问题和传统自然语言生成(NLG)任务中不同模型生成的回答的质量。我们的分析表明 ChatEval 超越了单纯的文本评分，为可靠的评估提供了一个模仿人类的评估过程。我们的代码可以在 https://github.com/chanchimin/chateval 找到。"
    },
    {
        "title": "Incorporating Annotator Uncertainty into Representations of Discourse\n  Relations",
        "url": "http://arxiv.org/abs/2308.07179v1",
        "pub_date": "2023-08-14",
        "summary": "Annotation of discourse relations is a known difficult task, especially for\nnon-expert annotators. In this paper, we investigate novice annotators'\nuncertainty on the annotation of discourse relations on spoken conversational\ndata. We find that dialogue context (single turn, pair of turns within speaker,\nand pair of turns across speakers) is a significant predictor of confidence\nscores. We compute distributed representations of discourse relations from\nco-occurrence statistics that incorporate information about confidence scores\nand dialogue context. We perform a hierarchical clustering analysis using these\nrepresentations and show that weighting discourse relation representations with\ninformation about confidence and dialogue context coherently models our\nannotators' uncertainty about discourse relation labels.",
        "translated": "话语关系的注释是一个众所周知的难题，尤其是对非专家注释者而言。本文研究了口语会话数据中新手注释者对话语关系注释的不确定性。我们发现对话语境(单圈，说话者内部的一对转弯，说话者之间的一对转弯)是自信得分的重要预测因子。我们根据共现统计数据计算话语关系的分布式表示，这些统计数据包含了关于置信度分数和对话上下文的信息。我们利用这些表征进行了层次聚类分析，结果表明，加权话语关系表征与信心信息和对话上下文相关性模型我们的注释者的不确定性话语关系标签。"
    },
    {
        "title": "OctoPack: Instruction Tuning Code Large Language Models",
        "url": "http://arxiv.org/abs/2308.07124v1",
        "pub_date": "2023-08-14",
        "summary": "Finetuning large language models (LLMs) on instructions leads to vast\nperformance improvements on natural language tasks. We apply instruction tuning\nusing code, leveraging the natural structure of Git commits, which pair code\nchanges with human instructions. We compile CommitPack: 4 terabytes of Git\ncommits across 350 programming languages. We benchmark CommitPack against other\nnatural and synthetic code instructions (xP3x, Self-Instruct, OASST) on the 16B\nparameter StarCoder model, and achieve state-of-the-art performance among\nmodels not trained on OpenAI outputs, on the HumanEval Python benchmark (46.2%\npass@1). We further introduce HumanEvalPack, expanding the HumanEval benchmark\nto a total of 3 coding tasks (Code Repair, Code Explanation, Code Synthesis)\nacross 6 languages (Python, JavaScript, Java, Go, C++, Rust). Our models,\nOctoCoder and OctoGeeX, achieve the best performance across HumanEvalPack among\nall permissive models, demonstrating CommitPack's benefits in generalizing to a\nwider set of languages and natural coding tasks. Code, models and data are\nfreely available at https://github.com/bigcode-project/octopack.",
        "translated": "在指令上微调大型语言模型(LLM)可以大大提高自然语言任务的性能。我们使用代码应用指令调优，利用 Git 提交的自然结构，将代码更改与人工指令结合起来。我们编译 CommitPack: 跨350种编程语言提交4TB 的 Git。我们在16B 参数 StarCoder 模型上对比其他自然和合成代码指令(xP3x，Self-翘，OASST) ，并在 HumanEval Python 基准(46.2% pass@1)上在未接受 OpenAI 输出培训的模型中实现最先进的性能。我们进一步介绍 HumanEvalPack，将 HumanEval 基准扩展到6种语言(Python、 JavaScript、 Java、 Go、 C + + 、 Rust)的总共3个编码任务(代码修复、代码解释、代码合成)。我们的模型 OctoCoder 和 OctoGeeX 在所有许可模型中在 HumanEvalPack 中取得了最好的性能，展示了 Committee Pack 在泛化到更广泛的语言集和自然编码任务方面的优势。代码、模型和数据可在 https://github.com/bigcode-project/octopack 免费获得。"
    },
    {
        "title": "Investigation Toward The Economic Feasibility of Personalized Medicine\n  For Healthcare Service Providers: The Case of Bladder Cancer",
        "url": "http://arxiv.org/abs/2308.07924v1",
        "pub_date": "2023-08-15",
        "summary": "In today's complex healthcare landscape, the pursuit of delivering optimal\npatient care while navigating intricate economic dynamics poses a significant\nchallenge for healthcare service providers (HSPs). In this already complex\ndynamics, the emergence of clinically promising personalized medicine based\ntreatment aims to revolutionize medicine. While personalized medicine holds\ntremendous potential for enhancing therapeutic outcomes, its integration within\nresource-constrained HSPs presents formidable challenges. In this study, we\ninvestigate the economic feasibility of implementing personalized medicine. The\ncentral objective is to strike a balance between catering to individual patient\nneeds and making economically viable decisions. Unlike conventional binary\napproaches to personalized treatment, we propose a more nuanced perspective by\ntreating personalization as a spectrum. This approach allows for greater\nflexibility in decision-making and resource allocation. To this end, we propose\na mathematical framework to investigate our proposal, focusing on Bladder\nCancer (BC) as a case study. Our results show that while it is feasible to\nintroduce personalized medicine, a highly efficient but highly expensive one\nwould be short-lived relative to its less effective but cheaper alternative as\nthe latter can be provided to a larger cohort of patients, optimizing the HSP's\nobjective better.",
        "translated": "在当今复杂的医疗保健环境中，追求提供最佳的患者护理，同时驾驭复杂的经济动态，对医疗保健服务提供商(HSP)提出了重大挑战。在这个已经存在的复动力学中，临床上有前途的基于个体化医学的治疗方法的出现，旨在彻底改变医学。虽然个体化医学在提高治疗效果方面具有巨大的潜力，但在资源有限的热点卫生服务中的整合却面临着巨大的挑战。在这项研究中，我们探讨实施个体化医学的经济可行性。中心目标是在满足个别病人的需要和作出经济上可行的决定之间取得平衡。与传统的个性化治疗的二元方法不同，我们提出了一个更加细致入微的视角，将个性化视为一个光谱。这种方法允许在决策和资源分配方面有更大的灵活性。为此，我们提出了一个数学框架来调查我们的建议，重点是膀胱癌(BC)作为一个案例研究。我们的研究结果表明，虽然引入个体化医学是可行的，但是相对于其效率较低但成本较低的替代品，高效但高昂的替代品将是短命的，因为后者可以提供给更多的患者，从而更好地优化 HSP 的目标。"
    },
    {
        "title": "Synthesizing Political Zero-Shot Relation Classification via Codebook\n  Knowledge, NLI, and ChatGPT",
        "url": "http://arxiv.org/abs/2308.07876v1",
        "pub_date": "2023-08-15",
        "summary": "Recent supervised models for event coding vastly outperform pattern-matching\nmethods. However, their reliance solely on new annotations disregards the vast\nknowledge within expert databases, hindering their applicability to\nfine-grained classification. To address these limitations, we explore zero-shot\napproaches for political event ontology relation classification, by leveraging\nknowledge from established annotation codebooks. Our study encompasses both\nChatGPT and a novel natural language inference (NLI) based approach named ZSP.\nZSP adopts a tree-query framework that deconstructs the task into context,\nmodality, and class disambiguation levels. This framework improves\ninterpretability, efficiency, and adaptability to schema changes. By conducting\nextensive experiments on our newly curated datasets, we pinpoint the\ninstability issues within ChatGPT and highlight the superior performance of\nZSP. ZSP achieves an impressive 40% improvement in F1 score for fine-grained\nRootcode classification. ZSP demonstrates competitive performance compared to\nsupervised BERT models, positioning it as a valuable tool for event record\nvalidation and ontology development. Our work underscores the potential of\nleveraging transfer learning and existing expertise to enhance the efficiency\nand scalability of research in the field.",
        "translated": "最新的事件编码监督模型远远优于模式匹配方法。然而，它们仅仅依赖于新的注释忽视了专家数据库中的大量知识，阻碍了它们对细粒度分类的适用性。为了解决这些局限性，我们通过利用已建立的注释代码书中的知识，探索政治事件本体关系分类的零打击方法。我们的研究包括 ChatGPT 和一种新的基于自然语言推理(NLI)的方法 ZSP。ZSP 采用树查询框架，将任务分解为上下文、模式和类消除歧义级别。该框架提高了模式更改的可解释性、效率和适应性。通过对我们新收集的数据集进行广泛的实验，我们找出了 ChatGPT 中的不稳定性问题，并突出了 ZSP 的优越性能。ZSP 为细粒度的 Rootcode 分类在 F1分数上取得了令人印象深刻的40% 的改进。与有监督的 BERT 模型相比，ZSP 具有竞争性能，将其定位为事件记录验证和本体开发的有价值的工具。我们的工作强调了利用转移学习和现有专门知识来提高该领域研究的效率和可扩展性的潜力。"
    },
    {
        "title": "Impression-Aware Recommender Systems",
        "url": "http://arxiv.org/abs/2308.07857v1",
        "pub_date": "2023-08-15",
        "summary": "Novel data sources bring new opportunities to improve the quality of\nrecommender systems. Impressions are a novel data source containing past\nrecommendations (shown items) and traditional interactions. Researchers may use\nimpressions to refine user preferences and overcome the current limitations in\nrecommender systems research. The relevance and interest of impressions have\nincreased over the years; hence, the need for a review of relevant work on this\ntype of recommenders. We present a systematic literature review on recommender\nsystems using impressions, focusing on three fundamental angles in research:\nrecommenders, datasets, and evaluation methodologies. We provide three\ncategorizations of papers describing recommenders using impressions, present\neach reviewed paper in detail, describe datasets with impressions, and analyze\nthe existing evaluation methodologies. Lastly, we present open questions and\nfuture directions of interest, highlighting aspects missing in the literature\nthat can be addressed in future works.",
        "translated": "新的数据源为提高推荐系统的质量带来了新的机遇。印象是一个新的数据源，包含过去的建议(显示的项目)和传统的交互。研究人员可以利用印象来改善用户偏好，克服目前推荐系统研究中的局限性。这些年来，印象的相关性和兴趣有所增加; 因此，需要审查关于这类建议的相关工作。我们提出了一个系统的文献综述推荐系统使用印象，侧重于三个基本角度的研究: 推荐，数据集和评估方法。我们提供了三种使用印象描述推荐者的论文分类，详细介绍每篇评论论文，用印象描述数据集，并分析现有的评估方法。最后，我们提出了开放的问题和未来的兴趣方向，突出了文献中缺失的方面，可以在未来的工作中解决。"
    },
    {
        "title": "Dynamic Embedding Size Search with Minimum Regret for Streaming\n  Recommender System",
        "url": "http://arxiv.org/abs/2308.07760v1",
        "pub_date": "2023-08-15",
        "summary": "With the continuous increase of users and items, conventional recommender\nsystems trained on static datasets can hardly adapt to changing environments.\nThe high-throughput data requires the model to be updated in a timely manner\nfor capturing the user interest dynamics, which leads to the emergence of\nstreaming recommender systems. Due to the prevalence of deep learning-based\nrecommender systems, the embedding layer is widely adopted to represent the\ncharacteristics of users, items, and other features in low-dimensional vectors.\nHowever, it has been proved that setting an identical and static embedding size\nis sub-optimal in terms of recommendation performance and memory cost,\nespecially for streaming recommendations. To tackle this problem, we first\nrethink the streaming model update process and model the dynamic embedding size\nsearch as a bandit problem. Then, we analyze and quantify the factors that\ninfluence the optimal embedding sizes from the statistics perspective. Based on\nthis, we propose the \\textbf{D}ynamic \\textbf{E}mbedding \\textbf{S}ize\n\\textbf{S}earch (\\textbf{DESS}) method to minimize the embedding size selection\nregret on both user and item sides in a non-stationary manner. Theoretically,\nwe obtain a sublinear regret upper bound superior to previous methods.\nEmpirical results across two recommendation tasks on four public datasets also\ndemonstrate that our approach can achieve better streaming recommendation\nperformance with lower memory cost and higher time efficiency.",
        "translated": "随着用户和项目的不断增加，传统的基于静态数据集的推荐系统难以适应不断变化的环境。高吞吐量数据要求模型及时更新，以捕捉用户兴趣动态，从而导致流式推荐系统的出现。由于基于深度学习的推荐系统的普及，嵌入层被广泛采用来在低维向量中表示用户、项目等特征。然而，已经证明，设置一个相同的静态嵌入大小在推荐性能和内存成本方面是次优的，特别是对于流式推荐。为了解决这个问题，我们首先重新考虑了流模型更新过程，并将动态嵌入大小搜索模型建模为盗贼问题。然后，从统计学的角度对影响最优嵌入规模的因素进行了分析和量化。在此基础上，提出了一种动态 textbf { D }嵌入 textbf { E }嵌入 textbf { S } ize textbf { S } earch (textbf { DESS })方法，以非平稳方式最小化用户端和项目端的嵌入大小选择遗憾。从理论上，我们得到了一个次线性后悔上界优于以往的方法。对四个公共数据集的两个推荐任务的实验结果也表明，该方法能够以较低的内存开销和较高的时间效率获得较好的流推荐性能。"
    },
    {
        "title": "Self-Supervised Dynamic Hypergraph Recommendation based on\n  Hyper-Relational Knowledge Graph",
        "url": "http://arxiv.org/abs/2308.07752v1",
        "pub_date": "2023-08-15",
        "summary": "Knowledge graphs (KGs) are commonly used as side information to enhance\ncollaborative signals and improve recommendation quality. In the context of\nknowledge-aware recommendation (KGR), graph neural networks (GNNs) have emerged\nas promising solutions for modeling factual and semantic information in KGs.\nHowever, the long-tail distribution of entities leads to sparsity in\nsupervision signals, which weakens the quality of item representation when\nutilizing KG enhancement. Additionally, the binary relation representation of\nKGs simplifies hyper-relational facts, making it challenging to model complex\nreal-world information. Furthermore, the over-smoothing phenomenon results in\nindistinguishable representations and information loss. To address these\nchallenges, we propose the SDK (Self-Supervised Dynamic Hypergraph\nRecommendation based on Hyper-Relational Knowledge Graph) framework. This\nframework establishes a cross-view hypergraph self-supervised learning\nmechanism for KG enhancement. Specifically, we model hyper-relational facts in\nKGs to capture interdependencies between entities under complete semantic\nconditions. With the refined representation, a hypergraph is dynamically\nconstructed to preserve features in the deep vector space, thereby alleviating\nthe over-smoothing problem. Furthermore, we mine external supervision signals\nfrom both the global perspective of the hypergraph and the local perspective of\ncollaborative filtering (CF) to guide the model prediction process. Extensive\nexperiments conducted on different datasets demonstrate the superiority of the\nSDK framework over state-of-the-art models. The results showcase its ability to\nalleviate the effects of over-smoothing and supervision signal sparsity.",
        "translated": "知识图作为辅助信息被广泛用于增强协作信号和提高推荐质量。在知识感知推荐(KGR)的背景下，图形神经网络(GNN)已经成为幼儿园建立事实和语义信息模型的有希望的解决方案。然而，实体的长尾分布导致监督信号的稀疏性，使得 KG 增强的项目表示质量下降。此外，KGs 的二进制关系表示简化了超关系事实，使得对复杂的现实世界信息进行建模具有挑战性。此外，过度平滑现象导致不可区分的表示和信息损失。针对这些挑战，本文提出了基于超关系知识图的自监督动态超图推荐(SDK)框架。该框架建立了一种用于 KG 增强的跨视图超图自监督学习机制。具体来说，我们在 KG 中建立超关系事实模型，以在完全语义条件下捕获实体之间的相互依赖性。该方法通过动态构造超图来保留深向量空间中的特征，从而解决了超图的过平滑问题。此外，我们从超图的全局视角和协同过滤的局部视角来挖掘外部监督信号，以指导模型的预测过程。在不同数据集上进行的大量实验表明，SDK 框架优于最先进的模型。实验结果表明，该算法能够有效缓解过平滑和监控信号稀疏的影响。"
    },
    {
        "title": "RAVEN: In-Context Learning with Retrieval Augmented Encoder-Decoder\n  Language Models",
        "url": "http://arxiv.org/abs/2308.07922v1",
        "pub_date": "2023-08-15",
        "summary": "In this paper, we investigate the in-context learning ability of\nretrieval-augmented encoder-decoder language models. We first conduct a\ncomprehensive analysis of the state-of-the-art ATLAS model and identify its\nlimitations in in-context learning, primarily due to a mismatch between\npretraining and testing, as well as a restricted context length. To address\nthese issues, we propose RAVEN, a model that combines retrieval-augmented\nmasked language modeling and prefix language modeling. We further introduce\nFusion-in-Context Learning to enhance the few-shot performance by enabling the\nmodel to leverage more in-context examples without requiring additional\ntraining or model modifications. Through extensive experiments, we demonstrate\nthat RAVEN significantly outperforms ATLAS and achieves results comparable to\nthe most advanced language models in certain scenarios, despite having\nsubstantially fewer parameters. Our work underscores the potential of\nretrieval-augmented encoder-decoder language models for in-context learning and\nencourages further research in this direction.",
        "translated": "本文研究了检索增强型编译码语言模型的语境学习能力。我们首先对最先进的 ATLAS 模型进行了全面的分析，并确定了其在上下文学习中的局限性，这主要是由于预训练和测试之间的不匹配以及上下文长度的限制。为了解决这些问题，我们提出了 RAVEN 模型，该模型结合了检索增强的掩蔽语言建模和前缀语言建模。我们进一步引入融合在上下文学习，通过使模型能够利用更多的在上下文中的例子，而不需要额外的训练或模型修改，来增强少镜头的性能。通过大量的实验，我们证明 RAVEN 的性能明显优于 ATLAS，并且在某些场景中取得了与最先进的语言模型相当的结果，尽管其参数大大减少。我们的工作强调了检索增强的编解码语言模型在上下文学习中的潜力，并鼓励在这个方向上进行进一步的研究。"
    },
    {
        "title": "Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with\n  Code-based Self-Verification",
        "url": "http://arxiv.org/abs/2308.07921v1",
        "pub_date": "2023-08-15",
        "summary": "Recent progress in large language models (LLMs) like GPT-4 and PaLM-2 has\nbrought significant advancements in addressing math reasoning problems. In\nparticular, OpenAI's latest version of GPT-4, known as GPT-4 Code Interpreter,\nshows remarkable performance on challenging math datasets. In this paper, we\nexplore the effect of code on enhancing LLMs' reasoning capability by\nintroducing different constraints on the \\textit{Code Usage Frequency} of GPT-4\nCode Interpreter. We found that its success can be largely attributed to its\npowerful skills in generating and executing code, evaluating the output of code\nexecution, and rectifying its solution when receiving unreasonable outputs.\nBased on this insight, we propose a novel and effective prompting method,\nexplicit \\uline{c}ode-based \\uline{s}elf-\\uline{v}erification~(CSV), to further\nboost the mathematical reasoning potential of GPT-4 Code Interpreter. This\nmethod employs a zero-shot prompt on GPT-4 Code Interpreter to encourage it to\nuse code to self-verify its answers. In instances where the verification state\nregisters as ``False'', the model shall automatically amend its solution,\nanalogous to our approach of rectifying errors during a mathematics\nexamination. Furthermore, we recognize that the states of the verification\nresult indicate the confidence of a solution, which can improve the\neffectiveness of majority voting. With GPT-4 Code Interpreter and CSV, we\nachieve an impressive zero-shot accuracy on MATH dataset \\textbf{(53.9\\% $\\to$\n84.3\\%)}.",
        "translated": "最近在大型语言模型(LLM)方面的进展，如 GPT-4和 PalM-2，在解决数学推理问题方面带来了显著的进步。尤其值得一提的是，OpenAI 最新版本的 GPT-4，即 GPT-4代码解释器，在具有挑战性的数学数据集上表现出了非凡的性能。本文通过对 GPT-4代码解释器的文本{代码使用频率}引入不同的约束条件，探讨了代码对提高 LLM 推理能力的作用。我们发现它的成功很大程度上归功于它在生成和执行代码、评估代码执行的输出以及在接收到不合理的输出时纠正其解决方案等方面的强大技能。基于这一认识，我们提出了一种新颖有效的提示方法——显式 uline { c }-ode-Based uline { s }-self-uline { v }验证 ~ (CSV) ，以进一步提高 GPT-4代码解释器的数学推理能力。这种方法在 GPT-4代码解释器上使用了一个零拍提示，以鼓励它使用代码来自我验证它的答案。在验证状态为“假”的情况下，模型将自动修正其解，类似于我们在数学考试中纠正错误的方法。此外，我们认识到，核查结果的状态表明了对解决方案的信心，这可以提高多数表决的有效性。使用 GPT-4代码解释器和 CSV，我们在 MATH 数据集 textbf {(53.9% $to $84.3%)}上实现了令人印象深刻的零拍准确率。"
    },
    {
        "title": "Through the Lens of Core Competency: Survey on Evaluation of Large\n  Language Models",
        "url": "http://arxiv.org/abs/2308.07902v1",
        "pub_date": "2023-08-15",
        "summary": "From pre-trained language model (PLM) to large language model (LLM), the\nfield of natural language processing (NLP) has witnessed steep performance\ngains and wide practical uses. The evaluation of a research field guides its\ndirection of improvement. However, LLMs are extremely hard to thoroughly\nevaluate for two reasons. First of all, traditional NLP tasks become inadequate\ndue to the excellent performance of LLM. Secondly, existing evaluation tasks\nare difficult to keep up with the wide range of applications in real-world\nscenarios. To tackle these problems, existing works proposed various benchmarks\nto better evaluate LLMs. To clarify the numerous evaluation tasks in both\nacademia and industry, we investigate multiple papers concerning LLM\nevaluations. We summarize 4 core competencies of LLM, including reasoning,\nknowledge, reliability, and safety. For every competency, we introduce its\ndefinition, corresponding benchmarks, and metrics. Under this competency\narchitecture, similar tasks are combined to reflect corresponding ability,\nwhile new tasks can also be easily added into the system. Finally, we give our\nsuggestions on the future direction of LLM's evaluation.",
        "translated": "从预训练语言模型(PLM)到大型语言模型(LLM) ，自然语言处理(NLP)领域取得了巨大的性能提高和广泛的实际应用。对某一研究领域的评价指导其改进方向。然而，LLM 非常难以彻底评估，原因有二。首先，传统的自然语言处理任务由于 LLM 的优良性能而变得不足。其次，现有的评估任务很难跟上实际场景中的广泛应用。为了解决这些问题，现有的工作提出了各种基准，以更好地评估有限责任合约。为了阐明学术界和工业界的众多评价任务，我们调查了多篇关于 LLM 评价的论文。我们总结了 LLM 的4个核心能力，包括推理、知识、可靠性和安全性。对于每个能力，我们介绍它的定义、相应的基准和度量。在这个胜任力架构下，类似的任务可以结合起来反映相应的能力，而新的任务也可以很容易地添加到系统中。最后，本文对 LLM 未来的评价方向提出了建议。"
    },
    {
        "title": "The Regular Expression Inference Challenge",
        "url": "http://arxiv.org/abs/2308.07899v1",
        "pub_date": "2023-08-15",
        "summary": "We propose \\emph{regular expression inference (REI)} as a challenge for\ncode/language modelling, and the wider machine learning community. REI is a\nsupervised machine learning (ML) and program synthesis task, and poses the\nproblem of finding minimal regular expressions from examples: Given two finite\nsets of strings $P$ and $N$ and a cost function $\\text{cost}(\\cdot)$, the task\nis to generate an expression $r$ that accepts all strings in $P$ and rejects\nall strings in $N$, while no other such expression $r'$ exists with\n$\\text{cost}(r')&lt;\\text{cost}(r)$.\n  REI has advantages as a challenge problem: (i) regular expressions are\nwell-known, widely used, and a natural idealisation of code; (ii) REI's\nasymptotic worst-case complexity is well understood; (iii) REI has a small\nnumber of easy to understand parameters (e.g.~$P$ or $N$ cardinality, string\nlengths of examples, or the cost function); this lets us easily finetune\nREI-hardness; (iv) REI is an unsolved problem for deep learning based ML.\n  Recently, an REI solver was implemented on GPUs, using program synthesis\ntechniques. This enabled, for the first time, fast generation of minimal\nexpressions for complex REI instances. Building on this advance, we generate\nand publish the first large-scale datasets for REI, and devise and evaluate\nseveral initial heuristic and machine learning baselines.\n  We invite the community to participate and explore ML methods that learn to\nsolve REI problems. We believe that progress in REI directly translates to\ncode/language modelling.",
        "translated": "我们建议将 emph {正则表达式推理(REI)}作为代码/语言建模以及更广泛的机器学习社区的一个挑战。REI 是一个监督式学习(ML)和程序合成任务，并提出了从示例中寻找最小正则表达式的问题: 给定两个有限的字符串集 $P $和 $N $以及一个成本函数 $text { Cost }(cdot) $，任务是生成一个表达式 $r $，它接受 $p $中的所有字符串并拒绝 $N $中的所有字符串，而没有其他这样的表达式 $r’$存在于 $text { Cost }(r’) < text { Cost }(r) $中。REI 作为一个具有挑战性的问题具有优势: (i)正则表达式是众所周知的，广泛使用的，代码的自然理想化; (ii) REI 的渐近最坏情况的复杂性是很好的理解; (iii) REI 有少量容易理解的参数(例如 ~ $P $或 $N $基数，字符串长度的例子，或成本函数) ; 这让我们很容易微调 REI 硬度; (iv) REI 是基于机器学习的深度学习的一个未解决的问题。最近，一个 REI 求解器被实现在 GPU 上，使用程序综合技术。这首次为复杂 REI 实例快速生成了最小表达式。在此基础上，我们生成并发布了 REI 的第一个大规模数据集，并设计和评估了几个初始启发式和机器学习基线。我们邀请社区参与并探索机器学习方法，学习如何解决 REI 问题。我们相信 REI 的进步直接转化为代码/语言建模。"
    },
    {
        "title": "Link-Context Learning for Multimodal LLMs",
        "url": "http://arxiv.org/abs/2308.07891v1",
        "pub_date": "2023-08-15",
        "summary": "The ability to learn from context with novel concepts, and deliver\nappropriate responses are essential in human conversations. Despite current\nMultimodal Large Language Models (MLLMs) and Large Language Models (LLMs) being\ntrained on mega-scale datasets, recognizing unseen images or understanding\nnovel concepts in a training-free manner remains a challenge. In-Context\nLearning (ICL) explores training-free few-shot learning, where models are\nencouraged to ``learn to learn\" from limited tasks and generalize to unseen\ntasks. In this work, we propose link-context learning (LCL), which emphasizes\n\"reasoning from cause and effect\" to augment the learning capabilities of\nMLLMs. LCL goes beyond traditional ICL by explicitly strengthening the causal\nrelationship between the support set and the query set. By providing\ndemonstrations with causal links, LCL guides the model to discern not only the\nanalogy but also the underlying causal associations between data points, which\nempowers MLLMs to recognize unseen images and understand novel concepts more\neffectively. To facilitate the evaluation of this novel approach, we introduce\nthe ISEKAI dataset, comprising exclusively of unseen generated image-label\npairs designed for link-context learning. Extensive experiments show that our\nLCL-MLLM exhibits strong link-context learning capabilities to novel concepts\nover vanilla MLLMs. Code and data will be released at\nhttps://github.com/isekai-portal/Link-Context-Learning.",
        "translated": "能够从上下文中学习新的概念，并提供适当的反应是人类对话中必不可少的。尽管目前的多模态大语言模型(MLLM)和大语言模型(LLM)正在大规模的数据集上进行训练，但是识别看不见的图像或者以一种不需要训练的方式理解新概念仍然是一个挑战。在上下文学习(ICL)探索无训练的少镜头学习，其中模型被鼓励从有限的任务“学习学习”，并推广到看不见的任务。本文提出了链接语境学习(LCL) ，它强调“因果推理”，以增强多语言模型的学习能力。LCL 超越了传统的 ICL，它显式地加强了支持集和查询集之间的因果关系。通过提供因果关系的演示，LCL 引导模型不仅能够识别类比，而且能够识别数据点之间潜在的因果关系，这使得 MLLM 能够识别看不见的图像，更有效地理解新概念。为了便于评估这种新方法，我们引入 ISEKAI 数据集，包括专门为链接上下文学习设计的未见生成的图像标签对。广泛的实验表明，我们的 LCL-MLLM 展示了强大的链接上下文学习能力的新概念超过普通的 MLLM。代码和数据将在 https://github.com/isekai-portal/link-context-learning 公布。"
    },
    {
        "title": "A Comprehensive Study on Knowledge Graph Embedding over Relational\n  Patterns Based on Rule Learning",
        "url": "http://arxiv.org/abs/2308.07889v1",
        "pub_date": "2023-08-15",
        "summary": "Knowledge Graph Embedding (KGE) has proven to be an effective approach to\nsolving the Knowledge Graph Completion (KGC) task. Relational patterns which\nrefer to relations with specific semantics exhibiting graph patterns are an\nimportant factor in the performance of KGE models. Though KGE models'\ncapabilities are analyzed over different relational patterns in theory and a\nrough connection between better relational patterns modeling and better\nperformance of KGC has been built, a comprehensive quantitative analysis on KGE\nmodels over relational patterns remains absent so it is uncertain how the\ntheoretical support of KGE to a relational pattern contributes to the\nperformance of triples associated to such a relational pattern. To address this\nchallenge, we evaluate the performance of 7 KGE models over 4 common relational\npatterns on 2 benchmarks, then conduct an analysis in theory, entity frequency,\nand part-to-whole three aspects and get some counterintuitive conclusions.\nFinally, we introduce a training-free method Score-based Patterns Adaptation\n(SPA) to enhance KGE models' performance over various relational patterns. This\napproach is simple yet effective and can be applied to KGE models without\nadditional training. Our experimental results demonstrate that our method\ngenerally enhances performance over specific relational patterns. Our source\ncode is available from GitHub at\nhttps://github.com/zjukg/Comprehensive-Study-over-Relational-Patterns.",
        "translated": "知识图嵌入(KGE)已被证明是解决知识图完成(KGC)任务的有效方法。关系模式是表示图形模式的特定语义关系，是影响 KGE 模型性能的一个重要因素。虽然从理论上分析了 KGE 模型在不同关系模式下的性能，并在更好的关系模式建模和 KGC 更好的性能之间建立了粗略的联系，但是对 KGE 模型在关系模式下的性能的全面定量分析仍然缺乏，因此 KGE 对关系模式的理论支持如何有助于这种关系模式的三元组的性能还不确定。为了应对这一挑战，我们在2个基准上对7个 KGE 模型在4种常见关系模式下的表现进行了评估，然后从理论、实体频率和部分对整体三个方面进行了分析，得出了一些违反直觉的结论。最后，我们介绍了一种基于分数的模式适应(SPA)的免训练方法，以提高 KGE 模型在各种关系模式下的性能。该方法简单有效，不需要额外的训练即可应用于 KGE 模型。我们的实验结果表明，我们的方法通常能够提高特定关系模式的性能。我们的源代码可以从 gitHub  https://GitHub.com/zjukg/comprehensive-study-over-relational-patterns 获得。"
    },
    {
        "title": "Emotion Embeddings $\\unicode{x2014}$ Learning Stable and Homogeneous\n  Abstractions from Heterogeneous Affective Datasets",
        "url": "http://arxiv.org/abs/2308.07871v1",
        "pub_date": "2023-08-15",
        "summary": "Human emotion is expressed in many communication modalities and media formats\nand so their computational study is equally diversified into natural language\nprocessing, audio signal analysis, computer vision, etc. Similarly, the large\nvariety of representation formats used in previous research to describe\nemotions (polarity scales, basic emotion categories, dimensional approaches,\nappraisal theory, etc.) have led to an ever proliferating diversity of\ndatasets, predictive models, and software tools for emotion analysis. Because\nof these two distinct types of heterogeneity, at the expressional and\nrepresentational level, there is a dire need to unify previous work on\nincreasingly diverging data and label types. This article presents such a\nunifying computational model. We propose a training procedure that learns a\nshared latent representation for emotions, so-called emotion embeddings,\nindependent of different natural languages, communication modalities, media or\nrepresentation label formats, and even disparate model architectures.\nExperiments on a wide range of heterogeneous affective datasets indicate that\nthis approach yields the desired interoperability for the sake of reusability,\ninterpretability and flexibility, without penalizing prediction quality. Code\nand data are archived under https://doi.org/10.5281/zenodo.7405327 .",
        "translated": "人类情感以多种交流方式和媒介形式表达，因此其计算机研究也同样多样化，包括自然语言处理、音频信号分析、计算机视觉等。类似地，在以前的研究中用于描述情绪的大量表示格式(极性尺度，基本情绪类别，维度方法，评估理论等)导致了情绪分析的数据集，预测模型和软件工具的不断增加的多样性。由于这两种不同类型的异质性，在表达和表示层面上，迫切需要统一以前关于日益分化的数据和标签类型的工作。这篇文章提出了一个统一的计算模型。我们提出了一个训练程序，学习共享的潜在表征情绪，所谓的情绪嵌入，独立于不同的自然语言，交流方式，媒体或表征标签格式，甚至完全不同的模型架构。在大量异构情感数据集上的实验表明，该方法在不影响预测质量的前提下，达到了预期的互操作性，具有可重用性、可解释性和灵活性。代码和数据在 https://doi.org/10.5281/zenodo.7405327下存档。"
    },
    {
        "title": "Informed Named Entity Recognition Decoding for Generative Language\n  Models",
        "url": "http://arxiv.org/abs/2308.07791v1",
        "pub_date": "2023-08-15",
        "summary": "Ever-larger language models with ever-increasing capabilities are by now\nwell-established text processing tools. Alas, information extraction tasks such\nas named entity recognition are still largely unaffected by this progress as\nthey are primarily based on the previous generation of encoder-only transformer\nmodels. Here, we propose a simple yet effective approach, Informed Named Entity\nRecognition Decoding (iNERD), which treats named entity recognition as a\ngenerative process. It leverages the language understanding capabilities of\nrecent generative models in a future-proof manner and employs an informed\ndecoding scheme incorporating the restricted nature of information extraction\ninto open-ended text generation, improving performance and eliminating any risk\nof hallucinations. We coarse-tune our model on a merged named entity corpus to\nstrengthen its performance, evaluate five generative language models on eight\nnamed entity recognition datasets, and achieve remarkable results, especially\nin an environment with an unknown entity class set, demonstrating the\nadaptability of the approach.",
        "translated": "越来越大的语言模型具有越来越强的功能，现在已经成为成熟的文本处理工具。遗憾的是，命名实体识别等信息抽取任务仍然基本上没有受到这一进展的影响，因为它们主要基于上一代只有编码器的变压器模型。在这里，我们提出了一种简单而有效的方法，知情命名实体识别解码(iNERD) ，它将命名实体识别视为一个生成过程。它充分利用了最新生成模型的语言理解能力，并采用了一种知情的解码方案，将信息抽取的受限性质纳入开放式文本生成，提高了性能，消除了任何产生幻觉的风险。在合并的命名实体语料库上对模型进行了粗调，增强了模型的性能，对8个命名实体识别数据集上的5个生成语言模型进行了评估，取得了显著的效果，特别是在未知实体类集的情况下，说明了该方法的适用性。"
    },
    {
        "title": "Enhancing Visually-Rich Document Understanding via Layout Structure\n  Modeling",
        "url": "http://arxiv.org/abs/2308.07777v1",
        "pub_date": "2023-08-15",
        "summary": "In recent years, the use of multi-modal pre-trained Transformers has led to\nsignificant advancements in visually-rich document understanding. However,\nexisting models have mainly focused on features such as text and vision while\nneglecting the importance of layout relationship between text nodes. In this\npaper, we propose GraphLayoutLM, a novel document understanding model that\nleverages the modeling of layout structure graph to inject document layout\nknowledge into the model. GraphLayoutLM utilizes a graph reordering algorithm\nto adjust the text sequence based on the graph structure. Additionally, our\nmodel uses a layout-aware multi-head self-attention layer to learn document\nlayout knowledge. The proposed model enables the understanding of the spatial\narrangement of text elements, improving document comprehension. We evaluate our\nmodel on various benchmarks, including FUNSD, XFUND and CORD, and achieve\nstate-of-the-art results among these datasets. Our experimental results\ndemonstrate that our proposed method provides a significant improvement over\nexisting approaches and showcases the importance of incorporating layout\ninformation into document understanding models. We also conduct an ablation\nstudy to investigate the contribution of each component of our model. The\nresults show that both the graph reordering algorithm and the layout-aware\nmulti-head self-attention layer play a crucial role in achieving the best\nperformance.",
        "translated": "近年来，使用多模式预先训练的变形金刚已经导致在视觉丰富的文档理解的重大进展。然而，现有的模型主要侧重于文本和视觉等特征，而忽视了文本节点间布局关系的重要性。本文提出了一种新的文档理解模型 GraphLayoutLM，该模型利用布局结构图的建模，将文档布局知识注入到模型中。GraphLayoutLM 利用图的重排序算法来调整基于图结构的文本序列。此外，我们的模型使用布局感知的多头自我关注层来学习文档布局知识。该模型可以帮助理解文本元素的空间排列，提高文档的理解能力。我们在各种基准测试上评估我们的模型，包括 FUNSD、 XFEND 和 CORD，并在这些数据集中实现最先进的结果。我们的实验结果表明，我们提出的方法提供了一个显着的改进，对现有的方法和显示的重要性，结合布局信息到文档理解模型。我们还进行了消融研究，以调查我们的模型的每个组成部分的贡献。结果表明，图的重排序算法和布局感知的多头自注意层在获得最佳性能方面起着至关重要的作用。"
    },
    {
        "title": "A Bi-Step Grounding Paradigm for Large Language Models in Recommendation\n  Systems",
        "url": "http://arxiv.org/abs/2308.08434v1",
        "pub_date": "2023-08-16",
        "summary": "As the focus on Large Language Models (LLMs) in the field of recommendation\nintensifies, the optimization of LLMs for recommendation purposes (referred to\nas LLM4Rec) assumes a crucial role in augmenting their effectiveness in\nproviding recommendations. However, existing approaches for LLM4Rec often\nassess performance using restricted sets of candidates, which may not\naccurately reflect the models' overall ranking capabilities. In this paper, our\nobjective is to investigate the comprehensive ranking capacity of LLMs and\npropose a two-step grounding framework known as BIGRec (Bi-step Grounding\nParadigm for Recommendation). It initially grounds LLMs to the recommendation\nspace by fine-tuning them to generate meaningful tokens for items and\nsubsequently identifies appropriate actual items that correspond to the\ngenerated tokens. By conducting extensive experiments on two datasets, we\nsubstantiate the superior performance, capacity for handling few-shot\nscenarios, and versatility across multiple domains exhibited by BIGRec.\nFurthermore, we observe that the marginal benefits derived from increasing the\nquantity of training samples are modest for BIGRec, implying that LLMs possess\nthe limited capability to assimilate statistical information, such as\npopularity and collaborative filtering, due to their robust semantic priors.\nThese findings also underline the efficacy of integrating diverse statistical\ninformation into the LLM4Rec framework, thereby pointing towards a potential\navenue for future research. Our code and data are available at\nhttps://github.com/SAI990323/Grounding4Rec.",
        "translated": "随着推荐领域对大型语言模型(LLM)的关注的加强，为推荐目的对 LLM 进行优化(称为 LLM4Rec)在增强其提供推荐的有效性方面扮演着至关重要的角色。然而，现有的 LLM4Rec 方法通常使用受限制的候选集来评估性能，这可能不能准确地反映模型的整体排名能力。在本文中，我们的目标是研究 LLM 的综合排序能力，并提出一个两步接地框架称为 BIGRec (双步接地推荐范式)。最初，通过对 LLM 进行微调，为项目生成有意义的令牌，并随后识别与生成的令牌相对应的适当的实际项目，将 LLM 置于推荐空间。通过在两个数据集上进行广泛的实验，我们证实了 BIGRec 的优越性能、处理少镜头场景的能力以及跨多个领域的通用性。此外，我们观察到增加训练样本数量所产生的边际效益对于 BIGrec 来说是适度的，这意味着 LLM 具有有限的能力来吸收统计信息，例如流行性和协同过滤，由于它们强大的语义先验。这些研究结果还强调了将不同的统计信息纳入 LLM4Rec 框架的有效性，从而为今后的研究指明了一个潜在的途径。我们的代码和数据可以在 https://github.com/sai990323/grounding4rec 找到。"
    },
    {
        "title": "Knowledge-Enhanced Multi-Label Few-Shot Product Attribute-Value\n  Extraction",
        "url": "http://arxiv.org/abs/2308.08413v1",
        "pub_date": "2023-08-16",
        "summary": "Existing attribute-value extraction (AVE) models require large quantities of\nlabeled data for training. However, new products with new attribute-value pairs\nenter the market every day in real-world e-Commerce. Thus, we formulate AVE in\nmulti-label few-shot learning (FSL), aiming to extract unseen attribute value\npairs based on a small number of training examples. We propose a\nKnowledge-Enhanced Attentive Framework (KEAF) based on prototypical networks,\nleveraging the generated label description and category information to learn\nmore discriminative prototypes. Besides, KEAF integrates with hybrid attention\nto reduce noise and capture more informative semantics for each class by\ncalculating the label-relevant and query-related weights. To achieve\nmulti-label inference, KEAF further learns a dynamic threshold by integrating\nthe semantic information from both the support set and the query set. Extensive\nexperiments with ablation studies conducted on two datasets demonstrate that\nKEAF outperforms other SOTA models for information extraction in FSL. The code\ncan be found at: https://github.com/gjiaying/KEAF",
        "translated": "现有的属性值提取(AVE)模型需要大量的标记数据进行训练。然而，在现实的电子商务中，每天都有新的属性-价值对产品进入市场。因此，我们在多标签少镜头学习(FSL)中构造 AVE，目的是在少量训练样本的基础上提取不可见的属性值对。我们提出了一个基于原型网络的知识增强注意框架(KEAF) ，利用生成的标签描述和类别信息来学习更多的区分原型。此外，KEAF 与混合注意相结合，通过计算与标签相关和查询相关的权重来降低噪声并为每个类捕获更多的信息语义。为了实现多标签推理，KEAF 进一步通过集成来自支持集和查询集的语义信息来学习动态阈值。在两个数据集上进行的消融研究的广泛实验表明，在 FSL 中，KEAF 的性能优于其他 SOTA 模型的信息抽取。密码可在以下 https://github.com/gjiaying/keaf 找到:"
    },
    {
        "title": "Content-based Recommendation Engine for Video Streaming Platform",
        "url": "http://arxiv.org/abs/2308.08406v1",
        "pub_date": "2023-08-16",
        "summary": "Recommendation engine suggest content, product or services to the user by\nusing machine learning algorithm. This paper proposed a content-based\nrecommendation engine for providing video suggestion to the user based on their\nprevious interests and choices. We will use TF-IDF text vectorization method to\ndetermine the relevance of words in a document. Then we will find out the\nsimilarity between each content by calculating cosine similarity between them.\nFinally, engine will recommend videos to the users based on the obtained\nsimilarity score value. In addition, we will measure the engine's performance\nby computing precision, recall, and F1 core of the proposed system.",
        "translated": "推荐引擎使用机器学习算法向用户推荐内容、产品或服务。提出了一种基于内容的视频推荐引擎，可以根据用户的兴趣和选择向用户提供视频建议。我们将使用 TF-IDF 文本矢量化方法来确定文档中的词的相关性。然后我们将通过计算每个内容之间的余弦距离来找出它们之间的相似性。最后，引擎根据得到的相似度评分值向用户推荐视频。此外，我们将通过计算精度、召回率和 F1核心来测量发动机的性能。"
    },
    {
        "title": "Advancing continual lifelong learning in neural information retrieval:\n  definition, dataset, framework, and empirical evaluation",
        "url": "http://arxiv.org/abs/2308.08378v1",
        "pub_date": "2023-08-16",
        "summary": "Continual learning refers to the capability of a machine learning model to\nlearn and adapt to new information, without compromising its performance on\npreviously learned tasks. Although several studies have investigated continual\nlearning methods for information retrieval tasks, a well-defined task\nformulation is still lacking, and it is unclear how typical learning strategies\nperform in this context. To address this challenge, a systematic task\nformulation of continual neural information retrieval is presented, along with\na multiple-topic dataset that simulates continuous information retrieval. A\ncomprehensive continual neural information retrieval framework consisting of\ntypical retrieval models and continual learning strategies is then proposed.\nEmpirical evaluations illustrate that the proposed framework can successfully\nprevent catastrophic forgetting in neural information retrieval and enhance\nperformance on previously learned tasks. The results indicate that\nembedding-based retrieval models experience a decline in their continual\nlearning performance as the topic shift distance and dataset volume of new\ntasks increase. In contrast, pretraining-based models do not show any such\ncorrelation. Adopting suitable learning strategies can mitigate the effects of\ntopic shift and data augmentation.",
        "translated": "连续学习是指机器学习模型学习和适应新信息的能力，而不影响其在以前学习的任务中的表现。尽管一些研究已经调查了信息检索任务的持续学习方法，但是仍然缺乏一个明确的任务表述，而且还不清楚在这种情况下典型的学习策略是如何执行的。为了应对这一挑战，我们提出了一个连续神经信息检索的系统性任务制定，以及一个模拟连续信息检索的多主题数据集。然后提出了一个由典型的检索模型和持续学习策略组成的全面的连续神经信息检索框架。经验性评估表明，提出的框架能够成功地防止神经信息检索中的灾难性遗忘，并提高先前学习任务的表现。结果表明，随着新任务的主题转移距离和数据量的增加，嵌入式检索模型的连续学习性能有所下降。相比之下，基于预训练的模型没有显示任何这样的相关性。采用合适的学习策略可以减轻话题转移和数据增强的影响。"
    },
    {
        "title": "Is Meta-Learning the Right Approach for the Cold-Start Problem in\n  Recommender Systems?",
        "url": "http://arxiv.org/abs/2308.08354v1",
        "pub_date": "2023-08-16",
        "summary": "Recommender systems have become fundamental building blocks of modern online\nproducts and services, and have a substantial impact on user experience. In the\npast few years, deep learning methods have attracted a lot of research, and are\nnow heavily used in modern real-world recommender systems. Nevertheless,\ndealing with recommendations in the cold-start setting, e.g., when a user has\ndone limited interactions in the system, is a problem that remains far from\nsolved. Meta-learning techniques, and in particular optimization-based\nmeta-learning, have recently become the most popular approaches in the academic\nresearch literature for tackling the cold-start problem in deep learning models\nfor recommender systems. However, current meta-learning approaches are not\npractical for real-world recommender systems, which have billions of users and\nitems, and strict latency requirements. In this paper we show that it is\npossible to obtaining similar, or higher, performance on commonly used\nbenchmarks for the cold-start problem without using meta-learning techniques.\nIn more detail, we show that, when tuned correctly, standard and widely adopted\ndeep learning models perform just as well as newer meta-learning models. We\nfurther show that an extremely simple modular approach using common\nrepresentation learning techniques, can perform comparably to meta-learning\ntechniques specifically designed for the cold-start setting while being much\nmore easily deployable in real-world applications.",
        "translated": "推荐系统已经成为现代在线产品和服务的基本组成部分，并对用户体验产生重大影响。在过去的几年中，深度学习方法引起了人们的广泛研究，并且在现代推荐系统中得到了广泛的应用。然而，在冷启动设置中处理建议，例如，当用户在系统中进行了有限的交互时，仍然是一个远未解决的问题。元学习技术，尤其是基于优化的元学习，最近已经成为学术研究文献中最流行的方法，用于解决推荐系统深度学习模型中的冷启动问题。然而，目前的元学习方法并不适用于现实世界的推荐系统，因为它有数十亿的用户和项目，并且有严格的延迟要求。在本文中，我们展示了在不使用元学习技术的情况下，在常用的冷启动问题基准上获得类似或更高的性能是可能的。更详细地说，我们表明，当正确地调整，标准和广泛采用的深度学习模型执行一样以及新的元学习模型。我们进一步展示了一种使用通用表示学习技术的极其简单的模块化方法，可以与专门为冷启动设置设计的元学习技术进行比较，同时在实际应用中更容易部署。"
    },
    {
        "title": "Time Travel in LLMs: Tracing Data Contamination in Large Language Models",
        "url": "http://arxiv.org/abs/2308.08493v1",
        "pub_date": "2023-08-16",
        "summary": "Data contamination, i.e., the presence of test data from downstream tasks in\nthe training data of large language models (LLMs), is a potential major issue\nin understanding LLMs' effectiveness on other tasks. We propose a\nstraightforward yet effective method for identifying data contamination within\nLLMs. At its core, our approach starts by identifying potential contamination\nin individual instances that are drawn from a small random sample; using this\ninformation, our approach then assesses if an entire dataset partition is\ncontaminated. To estimate contamination of individual instances, we employ\n\"guided instruction:\" a prompt consisting of the dataset name, partition type,\nand the initial segment of a reference instance, asking the LLM to complete it.\nAn instance is flagged as contaminated if the LLM's output either exactly or\nclosely matches the latter segment of the reference. To understand if an entire\npartition is contaminated, we propose two ideas. The first idea marks a dataset\npartition as contaminated if the average overlap score with the reference\ninstances (as measured by ROUGE or BLEURT) is statistically significantly\nbetter with the guided instruction vs. a general instruction that does not\ninclude the dataset and partition name. The second idea marks a dataset as\ncontaminated if a classifier based on GPT-4 with in-context learning prompting\nmarks multiple instances as contaminated. Our best method achieves an accuracy\nbetween 92% and 100% in detecting if an LLM is contaminated with seven\ndatasets, containing train and test/validation partitions, when contrasted with\nmanual evaluation by human expert. Further, our findings indicate that GPT-4 is\ncontaminated with AG News, WNLI, and XSum datasets.",
        "translated": "数据污染，即在大语言模型(LLM)的训练数据中存在来自下游任务的测试数据，是理解 LLM 在其他任务中的有效性的一个潜在的主要问题。我们提出了一个简单而有效的方法来识别 LLM 中的数据污染。在其核心，我们的方法开始识别从一个小的随机样本中抽取的个别实例中的潜在污染; 使用这些信息，我们的方法然后评估整个数据集分区是否被污染。为了估计单个实例的污染，我们使用了“引导指令”: 一个由数据集名称、分区类型和引用实例的初始段组成的提示，要求 LLM 完成它。如果 LLM 的输出与引用的后一部分完全匹配或非常匹配，则将实例标记为受污染。为了理解整个分区是否被污染，我们提出了两个想法。第一个想法是，如果与参考实例的平均重叠得分(通过 ROUGE 或 BLEURT 测量)在统计学上与不包括数据集和分区名称的一般指令相比，引导指令更好，则将数据集分区标记为受污染。第二个想法是，如果基于 GPT-4的分类器使用上下文学习提示将多个实例标记为受污染，则将数据集标记为受污染。我们的最佳方法在检测 LLM 是否受到7个数据集(包括训练和测试/验证分区)的污染时，与人工专家的人工评估相比，准确率达到92% 至100% 。此外，我们的研究结果表明，GPT-4受到 AG News、 WNLI 和 XSum 数据集的污染。"
    },
    {
        "title": "Mitigating the Exposure Bias in Sentence-Level Grapheme-to-Phoneme (G2P)\n  Transduction",
        "url": "http://arxiv.org/abs/2308.08442v1",
        "pub_date": "2023-08-16",
        "summary": "Text-to-Text Transfer Transformer (T5) has recently been considered for the\nGrapheme-to-Phoneme (G2P) transduction. As a follow-up, a tokenizer-free\nbyte-level model based on T5 referred to as ByT5, recently gave promising\nresults on word-level G2P conversion by representing each input character with\nits corresponding UTF-8 encoding. Although it is generally understood that\nsentence-level or paragraph-level G2P can improve usability in real-world\napplications as it is better suited to perform on heteronyms and linking sounds\nbetween words, we find that using ByT5 for these scenarios is nontrivial. Since\nByT5 operates on the character level, it requires longer decoding steps, which\ndeteriorates the performance due to the exposure bias commonly observed in\nauto-regressive generation models. This paper shows that the performance of\nsentence-level and paragraph-level G2P can be improved by mitigating such\nexposure bias using our proposed loss-based sampling method.",
        "translated": "文本到文本转换转换器(T5)最近被考虑用于字音转换(G2P)。作为后续，一个基于 T5(被称为 ByT5)的无标记器字节级模型，最近通过用相应的 UTF-8编码表示每个输入字符，在字级 G2P 转换上给出了有希望的结果。尽管人们普遍认为句子级别或段落级别的 G2P 可以提高现实世界中应用程序的可用性，因为它更适合于执行异名和词与词之间的连音，但我们发现，在这些场景中使用 ByT5是不平凡的。由于 ByT5工作在字符级，它需要较长的解码步骤，这会由于在自动回归生成模型中常见的暴露偏差而使性能恶化。本文提出的基于损失的抽样方法可以减小句子级和段落级 G2P 的暴露偏差，从而提高 G2P 的性能。"
    },
    {
        "title": "SummHelper: Collaborative Human-Computer Summarization",
        "url": "http://arxiv.org/abs/2308.08363v1",
        "pub_date": "2023-08-16",
        "summary": "Current approaches for text summarization are predominantly automatic, with\nrather limited space for human intervention and control over the process. In\nthis paper, we introduce SummHelper, a 2-phase summarization assistant designed\nto foster human-machine collaboration. The initial phase involves content\nselection, where the system recommends potential content, allowing users to\naccept, modify, or introduce additional selections. The subsequent phase,\ncontent consolidation, involves SummHelper generating a coherent summary from\nthese selections, which users can then refine using visual mappings between the\nsummary and the source text. Small-scale user studies reveal the effectiveness\nof our application, with participants being especially appreciative of the\nbalance between automated guidance and opportunities for personal input.",
        "translated": "目前的文本摘要方法主要是自动的，人工干预和控制过程的空间相当有限。在本文中，我们介绍了 SummHelper，它是一个两阶段摘要助手，旨在促进人机协作。最初的阶段包括内容选择，在这个阶段系统推荐潜在的内容，允许用户接受、修改或引入额外的选择。随后的阶段，内容整合，涉及到 SummHelper 从这些选择中生成一致的摘要，然后用户可以使用摘要和源文本之间的可视化映射来细化这些摘要。小规模的用户研究揭示了我们的应用程序的有效性，参与者特别欣赏自动化指导和个人输入机会之间的平衡。"
    },
    {
        "title": "Detoxify Language Model Step-by-Step",
        "url": "http://arxiv.org/abs/2308.08295v1",
        "pub_date": "2023-08-16",
        "summary": "Detoxification for LLMs is challenging since it requires models to avoid\ngenerating harmful content while maintaining the generation capability. To\nensure the safety of generations, previous detoxification methods detoxify the\nmodels by changing the data distributions or constraining the generations from\ndifferent aspects in a single-step manner. However, these approaches will\ndramatically affect the generation quality of LLMs, e.g., discourse coherence\nand semantic consistency, since language models tend to generate along the\ntoxic prompt while detoxification methods work in the opposite direction. To\nhandle such a conflict, we decompose the detoxification process into different\nsub-steps, where the detoxification is concentrated in the input stage and the\nsubsequent continual generation is based on the non-toxic prompt. Besides, we\nalso calibrate the strong reasoning ability of LLMs by designing a Detox-Chain\nto connect the above sub-steps in an orderly manner, which allows LLMs to\ndetoxify the text step-by-step. Automatic and human evaluation on two\nbenchmarks reveals that by training with Detox-Chain, six LLMs scaling from 1B\nto 33B can obtain significant detoxification and generation improvement. Our\ncode and data are available at https://github.com/CODINNLG/Detox-CoT. Warning:\nexamples in the paper may contain uncensored offensive content.",
        "translated": "解毒的 LLM 是具有挑战性的，因为它需要模型，以避免产生有害的内容，同时保持生成能力。为了确保世代的安全，以往的解毒方法通过改变数据分布或从不同方面一步限制世代来解毒模型。然而，这些方法将显著影响 LLM 的生成质量，例如，语篇连贯性和语义一致性，因为语言模型往往沿着有毒提示生成，而解毒方法的工作方向相反。为了处理这种冲突，我们将解毒过程分解为不同的子步骤，其中解毒集中在输入阶段，随后的连续产生基于无毒提示。此外，我们还通过设计一个排毒链来校准 LLM 的强大推理能力，使得 LLM 能够有序地连接上述子步骤，从而使得 LLM 能够一步一步地对文本进行排毒。对两个基准的自动和人工评估显示，通过排毒链培训，6个 LLM 从1B 升级到33B，可以获得显著的排毒和生成改善。我们的代码和数据可以在 https://github.com/codinnlg/detox-cot 找到。警告: 文件中的例子可能包含未经审查的冒犯性内容。"
    },
    {
        "title": "Pre-training with Large Language Model-based Document Expansion for\n  Dense Passage Retrieval",
        "url": "http://arxiv.org/abs/2308.08285v1",
        "pub_date": "2023-08-16",
        "summary": "In this paper, we systematically study the potential of pre-training with\nLarge Language Model(LLM)-based document expansion for dense passage retrieval.\nConcretely, we leverage the capabilities of LLMs for document expansion, i.e.\nquery generation, and effectively transfer expanded knowledge to retrievers\nusing pre-training strategies tailored for passage retrieval. These strategies\ninclude contrastive learning and bottlenecked query generation. Furthermore, we\nincorporate a curriculum learning strategy to reduce the reliance on LLM\ninferences. Experimental results demonstrate that pre-training with LLM-based\ndocument expansion significantly boosts the retrieval performance on\nlarge-scale web-search tasks. Our work shows strong zero-shot and out-of-domain\nretrieval abilities, making it more widely applicable for retrieval when\ninitializing with no human-labeled data.",
        "translated": "本文系统地研究了基于大语言模型(LLM)的文档扩展预训练在密集段检索中的潜力。具体来说，我们利用 LLM 的能力进行文档扩展，即查询生成，并有效地将扩展的知识传递给检索器，使用为文档检索量身定制的预训练策略。这些策略包括对比学习和瓶颈查询生成。此外，我们加入了课程学习策略，以减少对 LLM 推理的依赖。实验结果表明，基于 LLM 的文档扩展预训练显著提高了大规模网络搜索任务的检索性能。我们的工作显示了强大的零拍和域外检索能力，使其更广泛地适用于检索时，初始化没有人类标记的数据。"
    },
    {
        "title": "Benchmarking Neural Network Generalization for Grammar Induction",
        "url": "http://arxiv.org/abs/2308.08253v1",
        "pub_date": "2023-08-16",
        "summary": "How well do neural networks generalize? Even for grammar induction tasks,\nwhere the target generalization is fully known, previous works have left the\nquestion open, testing very limited ranges beyond the training set and using\ndifferent success criteria. We provide a measure of neural network\ngeneralization based on fully specified formal languages. Given a model and a\nformal grammar, the method assigns a generalization score representing how well\na model generalizes to unseen samples in inverse relation to the amount of data\nit was trained on. The benchmark includes languages such as $a^nb^n$,\n$a^nb^nc^n$, $a^nb^mc^{n+m}$, and Dyck-1 and 2. We evaluate selected\narchitectures using the benchmark and find that networks trained with a Minimum\nDescription Length objective (MDL) generalize better and using less data than\nnetworks trained using standard loss functions. The benchmark is available at\nhttps://github.com/taucompling/bliss.",
        "translated": "神经网络的概括能力如何？即使对于目标泛化已经完全知道的语法归纳任务，以前的工作也没有解决这个问题，测试训练集以外的非常有限的范围，并使用不同的成功标准。本文提出了一种基于完全特定形式语言的神经网络泛化方法。给定一个模型和一个形式文法，该方法分配一个泛化分数，该分数表示一个模型泛化到不可见样本的程度，与它所训练的数据量成反比。基准测试包括 $a ^ nb ^ n $、 $a ^ nb ^ nc ^ n $、 $a ^ nb ^ mc ^ { n + m } $以及 Dyck-1和2等语言。我们使用基准来评估选定的体系结构，发现使用最小描述长度目标(MDL)训练的网络比使用标准损失函数训练的网络更好地概括和使用更少的数据。基准指数可在 https://github.com/taucompling/bliss 下载。"
    },
    {
        "title": "TEST: Text Prototype Aligned Embedding to Activate LLM's Ability for\n  Time Series",
        "url": "http://arxiv.org/abs/2308.08241v1",
        "pub_date": "2023-08-16",
        "summary": "This work summarizes two strategies for completing time-series (TS) tasks\nusing today's language model (LLM): LLM-for-TS, design and train a fundamental\nlarge model for TS data; TS-for-LLM, enable the pre-trained LLM to handle TS\ndata. Considering the insufficient data accumulation, limited resources, and\nsemantic context requirements, this work focuses on TS-for-LLM methods, where\nwe aim to activate LLM's ability for TS data by designing a TS embedding method\nsuitable for LLM. The proposed method is named TEST. It first tokenizes TS,\nbuilds an encoder to embed them by instance-wise, feature-wise, and\ntext-prototype-aligned contrast, and then creates prompts to make LLM more open\nto embeddings, and finally implements TS tasks. Experiments are carried out on\nTS classification and forecasting tasks using 8 LLMs with different structures\nand sizes. Although its results cannot significantly outperform the current\nSOTA models customized for TS tasks, by treating LLM as the pattern machine, it\ncan endow LLM's ability to process TS data without compromising the language\nability. This paper is intended to serve as a foundational work that will\ninspire further research.",
        "translated": "本文总结了利用当今语言模型完成时间序列(TS)任务的两种策略: 针对 TS 的 LLM，设计并训练一个基本的大型 TS 数据模型; 针对 LLM 的 TS，使预先训练好的 LLM 能够处理 TS 数据。考虑到数据积累不足、资源有限以及语义上下文需求，本文主要研究了基于 TS 的 LLM 方法，通过设计一种适合 LLM 的 TS 嵌入方法来激活 LLM 对 TS 数据的处理能力。该方法被命名为 TEST。它首先标记 TS，构建一个编码器通过实例、特性和文本原型对齐对比来嵌入它们，然后创建提示以使 LLM 更加开放地嵌入，最后实现 TS 任务。利用8种不同结构和尺寸的微分方程对 TS 分类和预测任务进行了实验研究。虽然其结果不能明显优于目前为 TS 任务定制的 SOTA 模型，但是通过将 LLM 视为模式机器，它可以赋予 LLM 处理 TS 数据的能力而不损害语言能力。本文的目的是作为一项基础性工作，将激励进一步的研究。"
    },
    {
        "title": "MemoChat: Tuning LLMs to Use Memos for Consistent Long-Range Open-Domain\n  Conversation",
        "url": "http://arxiv.org/abs/2308.08239v1",
        "pub_date": "2023-08-16",
        "summary": "We propose MemoChat, a pipeline for refining instructions that enables large\nlanguage models (LLMs) to effectively employ self-composed memos for\nmaintaining consistent long-range open-domain conversations. We demonstrate a\nlong-range open-domain conversation through iterative\n\"memorization-retrieval-response\" cycles. This requires us to carefully design\ntailored tuning instructions for each distinct stage. The instructions are\nreconstructed from a collection of public datasets to teach the LLMs to\nmemorize and retrieve past dialogues with structured memos, leading to enhanced\nconsistency when participating in future conversations. We invite experts to\nmanually annotate a test set designed to evaluate the consistency of long-range\nconversations questions. Experiments on three testing scenarios involving both\nopen-source and API-accessible chatbots at scale verify the efficacy of\nMemoChat, which outperforms strong baselines.",
        "translated": "我们提出了 MemoChat，这是一个精炼指令的管道，它使得大型语言模型(LLM)能够有效地使用自组织的备忘录来维护一致的远程开放域对话。我们通过迭代的“记忆-检索-反应”周期来演示一个长距离的开放领域会话。这要求我们仔细地为每个不同的阶段设计量身定制的调优指令。这些指令是从一组公共数据集中重新构建的，用于教授 LLM 使用结构化备忘录记忆和检索过去的对话，从而在参与未来的对话时提高一致性。我们邀请专家手动注释一个测试集，该测试集旨在评估远程会话问题的一致性。在开源和 API 访问聊天机器人的三个测试场景中进行的大规模实验验证了 MemoChat 的功效，其性能优于强基线。"
    },
    {
        "title": "MUSE: Music Recommender System with Shuffle Play Recommendation\n  Enhancement",
        "url": "http://arxiv.org/abs/2308.09649v1",
        "pub_date": "2023-08-18",
        "summary": "Recommender systems have become indispensable in music streaming services,\nenhancing user experiences by personalizing playlists and facilitating the\nserendipitous discovery of new music. However, the existing recommender systems\noverlook the unique challenges inherent in the music domain, specifically\nshuffle play, which provides subsequent tracks in a random sequence. Based on\nour observation that the shuffle play sessions hinder the overall training\nprocess of music recommender systems mainly due to the high unique transition\nrates of shuffle play sessions, we propose a Music Recommender System with\nShuffle Play Recommendation Enhancement (MUSE). MUSE employs the\nself-supervised learning framework that maximizes the agreement between the\noriginal session and the augmented session, which is augmented by our novel\nsession augmentation method, called transition-based augmentation. To further\nfacilitate the alignment of the representations between the two views, we\ndevise two fine-grained matching strategies, i.e., item- and similarity-based\nmatching strategies. Through rigorous experiments conducted across diverse\nenvironments, we demonstrate MUSE's efficacy over 12 baseline models on a\nlarge-scale Music Streaming Sessions Dataset (MSSD) from Spotify. The source\ncode of MUSE is available at \\url{https://github.com/yunhak0/MUSE}.",
        "translated": "在音乐流媒体服务中，推荐系统已经变得不可或缺，它通过个性化播放列表和促进偶然发现新音乐来增强用户体验。然而，现有的推荐系统忽略了音乐领域固有的独特挑战，特别是随机播放，它以随机序列提供后续曲目。根据我们的观察，主要由于洗牌游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游。MUSE 采用自我监督学习框架，最大限度地提高了原始会话和扩展会话之间的一致性，并通过我们新颖的会话扩展方法(称为基于转换的扩展)进行了扩展。为了进一步促进两个视图之间的匹配，我们设计了两种细粒度匹配策略，即基于项目和相似性的匹配策略。通过在不同环境中进行的严格实验，我们在来自 Spotify 的大规模音乐流媒体会话数据集(MSSD)上证明了 MUSE 超过12个基线模型的功效。MUSE 的源代码可以在 url { https://github.com/yunhak0/MUSE }找到。"
    },
    {
        "title": "ReCon: Reducing Congestion in Job Recommendation using Optimal Transport",
        "url": "http://arxiv.org/abs/2308.09516v1",
        "pub_date": "2023-08-18",
        "summary": "Recommender systems may suffer from congestion, meaning that there is an\nunequal distribution of the items in how often they are recommended. Some items\nmay be recommended much more than others. Recommenders are increasingly used in\ndomains where items have limited availability, such as the job market, where\ncongestion is especially problematic: Recommending a vacancy -- for which\ntypically only one person will be hired -- to a large number of job seekers may\nlead to frustration for job seekers, as they may be applying for jobs where\nthey are not hired. This may also leave vacancies unfilled and result in job\nmarket inefficiency.\n  We propose a novel approach to job recommendation called ReCon, accounting\nfor the congestion problem. Our approach is to use an optimal transport\ncomponent to ensure a more equal spread of vacancies over job seekers, combined\nwith a job recommendation model in a multi-objective optimization problem. We\nevaluated our approach on two real-world job market datasets. The evaluation\nresults show that ReCon has good performance on both congestion-related (e.g.,\nCongestion) and desirability (e.g., NDCG) measures.",
        "translated": "推荐系统可能会受到拥塞的影响，这意味着在推荐的频率方面存在不平等的项目分布。有些项目可能比其他项目更值得推荐。推荐人越来越多地用于项目有限的领域，例如就业市场，那里的拥挤问题特别严重: 向大量求职者推荐一个空缺职位——通常只会雇用一个人——可能会使求职者感到沮丧，因为他们可能正在申请没有被雇用的工作。这也可能导致职位空缺无人填补，从而导致就业市场效率低下。我们提出了一种新的工作推荐方法，称为 ReCon，解决了拥塞问题。我们的方法是采用最佳交通组合，以确保职位空缺与求职者之间的差距更为均等，并结合多目标最佳化问题的职位推荐模式。我们在两个真实的就业市场数据集上评估了我们的方法。评估结果显示，ReCon 在拥塞相关(例如拥塞)和可取性(例如 NDCG)两方面均有良好的表现。"
    },
    {
        "title": "Attention Calibration for Transformer-based Sequential Recommendation",
        "url": "http://arxiv.org/abs/2308.09419v1",
        "pub_date": "2023-08-18",
        "summary": "Transformer-based sequential recommendation (SR) has been booming in recent\nyears, with the self-attention mechanism as its key component. Self-attention\nhas been widely believed to be able to effectively select those informative and\nrelevant items from a sequence of interacted items for next-item prediction via\nlearning larger attention weights for these items. However, this may not always\nbe true in reality. Our empirical analysis of some representative\nTransformer-based SR models reveals that it is not uncommon for large attention\nweights to be assigned to less relevant items, which can result in inaccurate\nrecommendations. Through further in-depth analysis, we find two factors that\nmay contribute to such inaccurate assignment of attention weights: sub-optimal\nposition encoding and noisy input. To this end, in this paper, we aim to\naddress this significant yet challenging gap in existing works. To be specific,\nwe propose a simple yet effective framework called Attention Calibration for\nTransformer-based Sequential Recommendation (AC-TSR). In AC-TSR, a novel\nspatial calibrator and adversarial calibrator are designed respectively to\ndirectly calibrates those incorrectly assigned attention weights. The former is\ndevised to explicitly capture the spatial relationships (i.e., order and\ndistance) among items for more precise calculation of attention weights. The\nlatter aims to redistribute the attention weights based on each item's\ncontribution to the next-item prediction. AC-TSR is readily adaptable and can\nbe seamlessly integrated into various existing transformer-based SR models.\nExtensive experimental results on four benchmark real-world datasets\ndemonstrate the superiority of our proposed ACTSR via significant\nrecommendation performance enhancements. The source code is available at\nhttps://github.com/AIM-SE/AC-TSR.",
        "translated": "基于变压器的顺序推荐(SR)近年来兴起，自注意机制是其关键组成部分。人们普遍认为，自我注意能够有效地从一系列相互作用的项目中选择信息丰富的相关项目，通过学习这些项目的较大注意权重来进行下一个项目的预测。然而，这在现实中可能并不总是正确的。我们对一些有代表性的基于变压器的 SR 模型的实证分析表明，将大的注意力权重分配给相关性较低的项目并不罕见，这可能导致不准确的推荐。通过进一步的深入分析，我们发现了两个可能导致注意力权重分配不准确的因素: 次优位置编码和噪声输入。为此，在本文中，我们的目标是解决这一重大但具有挑战性的差距，在现有的工作。具体来说，我们提出了一个简单而有效的框架，称为基于变压器的顺序推荐注意力校正(AC-TSR)。在 AC-TSR 中，分别设计了一种新的空间校正器和对抗校正器来直接校正那些不正确分配的注意权重。前者旨在明确地捕捉项目之间的空间关系(即顺序和距离) ，以便更精确地计算注意力权重。后者的目的是重新分配注意权重的基础上，每个项目的贡献，下一个项目的预测。AC-TSR 很容易适应，可以无缝地集成到各种现有的基于变压器的 SR 模型中。在四个基准的真实世界数据集上的大量实验结果显示了我们提出的 ACTSR 通过显著的推荐性能增强的优越性。源代码可在 https://github.com/aim-se/ac-tsr 下载。"
    },
    {
        "title": "SHARK: A Lightweight Model Compression Approach for Large-scale\n  Recommender Systems",
        "url": "http://arxiv.org/abs/2308.09395v1",
        "pub_date": "2023-08-18",
        "summary": "Increasing the size of embedding layers has shown to be effective in\nimproving the performance of recommendation models, yet gradually causing their\nsizes to exceed terabytes in industrial recommender systems, and hence the\nincrease of computing and storage costs. To save resources while maintaining\nmodel performances, we propose SHARK, the model compression practice we have\nsummarized in the recommender system of industrial scenarios. SHARK consists of\ntwo main components. First, we use the novel first-order component of Taylor\nexpansion as importance scores to prune the number of embedding tables (feature\nfields). Second, we introduce a new row-wise quantization method to apply\ndifferent quantization strategies to each embedding. We conduct extensive\nexperiments on both public and industrial datasets, demonstrating that each\ncomponent of our proposed SHARK framework outperforms previous approaches. We\nconduct A/B tests in multiple models on Kuaishou, such as short video,\ne-commerce, and advertising recommendation models. The results of the online\nA/B test showed SHARK can effectively reduce the memory footprint of the\nembedded layer. For the short-video scenarios, the compressed model without any\nperformance drop significantly saves 70% storage and thousands of machines,\nimproves 30\\% queries per second (QPS), and has been deployed to serve hundreds\nof millions of users and process tens of billions of requests every day.",
        "translated": "在工业推荐系统中，增加嵌入层的大小可以有效地提高推荐模型的性能，但是会逐渐导致其大小超过 TB，从而增加计算和存储成本。为了在保持模型性能的同时节省资源，我们提出了 SHARK，这是我们在工业场景推荐系统中总结的模型压缩实践。鲨鱼由两个主要部分组成。首先，我们利用泰勒展开的一阶分量作为重要性分数来裁剪嵌入表(特征域)的数目。其次，我们介绍了一种新的行量化方法，对每个嵌入应用不同的量化策略。我们在公共和工业数据集上进行了广泛的实验，证明了我们提出的 SHARK 框架的每个组件都优于以前的方法。我们在 Kuaishou 进行多种模式的 A/B 测试，例如短片、电子商务和广告推荐模式。在线 A/B 测试结果表明，SHARK 可以有效地减少嵌入层的内存占用。对于短视频场景，没有任何性能下降的压缩模型显著地节省了70% 的存储和数千台机器，提高了每秒30% 的查询(QPS) ，并且已经被部署用于服务数亿用户和每天处理数百亿个请求。"
    },
    {
        "title": "How Discriminative Are Your Qrels? How To Study the Statistical\n  Significance of Document Adjudication Methods",
        "url": "http://arxiv.org/abs/2308.09340v1",
        "pub_date": "2023-08-18",
        "summary": "Creating test collections for offline retrieval evaluation requires human\neffort to judge documents' relevance. This expensive activity motivated much\nwork in developing methods for constructing benchmarks with fewer assessment\ncosts. In this respect, adjudication methods actively decide both which\ndocuments and the order in which experts review them, in order to better\nexploit the assessment budget or to lower it. Researchers evaluate the quality\nof those methods by measuring the correlation between the known gold ranking of\nsystems under the full collection and the observed ranking of systems under the\nlower-cost one. This traditional analysis ignores whether and how the low-cost\njudgements impact on the statistically significant differences among systems\nwith respect to the full collection. We fill this void by proposing a novel\nmethodology to evaluate how the low-cost adjudication methods preserve the\npairwise significant differences between systems as the full collection. In\nother terms, while traditional approaches look for stability in answering the\nquestion \"is system A better than system B?\", our proposed approach looks for\nstability in answering the question \"is system A significantly better than\nsystem B?\", which is the ultimate questions researchers need to answer to\nguarantee the generalisability of their results. Among other results, we found\nthat the best methods in terms of ranking of systems correlation do not always\nmatch those preserving statistical significance.",
        "translated": "为离线检索评估创建测试集需要人力来判断文档的相关性。这项昂贵的活动促使人们开展大量工作，制定方法以构建评估成本较低的基准。在这方面，裁定方法积极决定哪些文件和专家审查这些文件的顺序，以便更好地利用或降低评估预算。研究人员评估这些方法的质量，通过测量之间的相关性已知黄金排名的系统下的全部收集和观察排名的系统下的低成本之一。这种传统的分析忽略了低成本判断是否以及如何影响各系统在完整收集方面的统计显著差异。为了填补这一空白，我们提出了一种新的方法来评估低成本的判决方法如何保持系统之间的成对显著差异作为完整的集合。换句话说，虽然传统方法在回答“系统 A 比系统 B 更好吗?”在回答“系统 A 是否明显优于系统 B?”这个问题时，我们提出的方法寻求稳定性这是研究人员需要回答的最终问题，以保证他们的结果的普遍性。除了其他结果之外，我们发现在系统相关性排序方面的最佳方法并不总是与那些保持统计显著性的方法相匹配。"
    },
    {
        "title": "Graph of Thoughts: Solving Elaborate Problems with Large Language Models",
        "url": "http://arxiv.org/abs/2308.09687v1",
        "pub_date": "2023-08-18",
        "summary": "We introduce Graph of Thoughts (GoT): a framework that advances prompting\ncapabilities in large language models (LLMs) beyond those offered by paradigms\nsuch as Chain-ofThought or Tree of Thoughts (ToT). The key idea and primary\nadvantage of GoT is the ability to model the information generated by an LLM as\nan arbitrary graph, where units of information (\"LLM thoughts\") are vertices,\nand edges correspond to dependencies between these vertices. This approach\nenables combining arbitrary LLM thoughts into synergistic outcomes, distilling\nthe essence of whole networks of thoughts, or enhancing thoughts using feedback\nloops. We illustrate that GoT offers advantages over state of the art on\ndifferent tasks, for example increasing the quality of sorting by 62% over ToT,\nwhile simultaneously reducing costs by &gt;31%. We ensure that GoT is extensible\nwith new thought transformations and thus can be used to spearhead new\nprompting schemes. This work brings the LLM reasoning closer to human thinking\nor brain mechanisms such as recurrence, both of which form complex networks.",
        "translated": "我们介绍了思维图(Graph of Thinking，GoT) : 一个框架，它提高了大型语言模型(LLM)的提示功能，超越了思维链或思维树(Tree of Thinking，ToT)等范式所提供的功能。GoT 的关键思想和主要优点是能够将 LLM 生成的信息建模为任意图形，其中信息单元(“ LLM 思想”)是顶点，边对应于这些顶点之间的依赖关系。这种方法可以将任意的 LLM 思想结合成协同的结果，提炼整个思想网络的精髓，或者使用反馈回路来增强思想。我们举例说明 GoT 在不同的任务上比最先进的技术更有优势，例如比 ToT 提高排序质量62% ，同时降低成本 > 31% 。我们确保 GoT 具有新的思想转换的可扩展性，因此可以用来领导新的激励方案。这项工作使 LLM 推理更接近于人类的思维或大脑机制，如复发，这两者都形成复杂的网络。"
    },
    {
        "title": "OCR Language Models with Custom Vocabularies",
        "url": "http://arxiv.org/abs/2308.09671v1",
        "pub_date": "2023-08-18",
        "summary": "Language models are useful adjuncts to optical models for producing accurate\noptical character recognition (OCR) results. One factor which limits the power\nof language models in this context is the existence of many specialized domains\nwith language statistics very different from those implied by a general\nlanguage model - think of checks, medical prescriptions, and many other\nspecialized document classes. This paper introduces an algorithm for\nefficiently generating and attaching a domain specific word based language\nmodel at run time to a general language model in an OCR system. In order to\nbest use this model the paper also introduces a modified CTC beam search\ndecoder which effectively allows hypotheses to remain in contention based on\npossible future completion of vocabulary words. The result is a substantial\nreduction in word error rate in recognizing material from specialized domains.",
        "translated": "语言模型是光学模型的有用辅助工具，可以产生精确的光学字符识别(OCR)结果。在这种情况下，限制语言模型能力的一个因素是存在许多具有语言统计数据的专门领域，这些领域与一般语言模型所隐含的统计数据非常不同——想想检查、医疗处方和许多其他专门的文档类。本文介绍了一种在 OCR 系统中高效生成基于领域特定词的语言模型并将其附加到通用语言模型的算法。为了更好地利用这一模型，本文还介绍了一种改进的 CTC 波束搜索解码器，该解码器有效地允许基于未来可能完成的词汇的假设继续存在争议。其结果是在识别来自专门领域的材料时，词语错误率大大降低。"
    },
    {
        "title": "Red-Teaming Large Language Models using Chain of Utterances for\n  Safety-Alignment",
        "url": "http://arxiv.org/abs/2308.09662v1",
        "pub_date": "2023-08-18",
        "summary": "Larger language models (LLMs) have taken the world by storm with their\nmassive multi-tasking capabilities simply by optimizing over a next-word\nprediction objective. With the emergence of their properties and encoded\nknowledge, the risk of LLMs producing harmful outputs increases, making them\nunfit for scalable deployment for the public. In this work, we propose a new\nsafety evaluation benchmark RED-EVAL that carries out red-teaming. We show that\neven widely deployed models are susceptible to the Chain of Utterances-based\n(CoU) prompting, jailbreaking closed source LLM-based systems such as GPT-4 and\nChatGPT to unethically respond to more than 65% and 73% of harmful queries. We\nalso demonstrate the consistency of the RED-EVAL across 8 open-source LLMs in\ngenerating harmful responses in more than 86% of the red-teaming attempts.\nNext, we propose RED-INSTRUCT--An approach for the safety alignment of LLMs. It\nconstitutes two phases: 1) HARMFULQA data collection: Leveraging CoU prompting,\nwe collect a dataset that consists of 1.9K harmful questions covering a wide\nrange of topics, 9.5K safe and 7.3K harmful conversations from ChatGPT; 2)\nSAFE-ALIGN: We demonstrate how the conversational dataset can be used for the\nsafety alignment of LLMs by minimizing the negative log-likelihood over helpful\nresponses and penalizing over harmful responses by gradient accent over sample\nloss. Our model STARLING, a fine-tuned Vicuna-7B, is observed to be more safely\naligned when evaluated on RED-EVAL and HHH benchmarks while preserving the\nutility of the baseline models (TruthfulQA, MMLU, and BBH).",
        "translated": "更大的语言模型(LLM)仅仅通过对下一个单词的预测目标进行优化，就以其巨大的多任务处理能力席卷了全世界。随着它们的属性和编码知识的出现，LLM 产生有害输出的风险增加，使它们不适合为公众进行可扩展的部署。在这项工作中，我们提出了一个新的安全评估基准 RED-EVAL，实现了红队。我们表明，即使是广泛部署的模型也容易受到基于话语链(Chain of Uterances-based，CoU)的提示，越狱的封闭源 LLM 系统，如 GPT-4和 ChatGPT，不道德地响应超过65% 和73% 的有害查询。我们还证明了 RED-EVAL 在8个开源 LLM 中的一致性，在超过86% 的红队尝试中产生了有害的反应。接下来，我们提出 RED-INstrucCT ——一种 LLM 的安全校准方法。它包括两个阶段: 1) HARMFULQA 数据收集: 利用 CoU 提示，我们收集了一个包含1.9 K 有害问题的数据集，涵盖广泛的主题，9.5 K 安全和7.3 K 有害会话来自 ChatGPT; 2) SAFE-ALIGN: 我们演示了如何通过最小化有益响应的负对数可能性和通过样本丢失的梯度重音惩罚有害响应，会话数据集可以用于 LLM 的安全校准。在 RED-EVAL 和 HHH 基准上评估时，我们的模型 STARling 是一种经过微调的 Vicuna-7B，观察到更安全地对齐，同时保留了基线模型(TruthfulQA，MMLU 和 BBH)的实用性。"
    },
    {
        "title": "Tree-of-Mixed-Thought: Combining Fast and Slow Thinking for Multi-hop\n  Visual Reasoning",
        "url": "http://arxiv.org/abs/2308.09658v2",
        "pub_date": "2023-08-18",
        "summary": "There emerges a promising trend of using large language models (LLMs) to\ngenerate code-like plans for complex inference tasks such as visual reasoning.\nThis paradigm, known as LLM-based planning, provides flexibility in problem\nsolving and endows better interpretability. However, current research is mostly\nlimited to basic scenarios of simple questions that can be straightforward\nanswered in a few inference steps. Planning for the more challenging multi-hop\nvisual reasoning tasks remains under-explored. Specifically, under multi-hop\nreasoning situations, the trade-off between accuracy and the complexity of\nplan-searching becomes prominent. The prevailing algorithms either address the\nefficiency issue by employing the fast one-stop generation or adopt a complex\niterative generation method to improve accuracy. Both fail to balance the need\nfor efficiency and performance. Drawing inspiration from the dual system of\ncognition in the human brain, the fast and the slow think processes, we propose\na hierarchical plan-searching algorithm that integrates the one-stop reasoning\n(fast) and the Tree-of-thought (slow). Our approach succeeds in performance\nwhile significantly saving inference steps. Moreover, we repurpose the PTR and\nthe CLEVER datasets, developing a systematic framework for evaluating the\nperformance and efficiency of LLMs-based plan-search algorithms under reasoning\ntasks at different levels of difficulty. Extensive experiments demonstrate the\nsuperiority of our proposed algorithm in terms of performance and efficiency.\nThe dataset and code will be release soon.",
        "translated": "使用大型语言模型(LLM)为复杂的推理任务(如视觉推理)生成类似代码的计划是一个很有前景的趋势。这种模式被称为基于 LLM 的规划，它提供了解决问题的灵活性，并赋予了更好的可解释性。然而，目前的研究大多局限于简单问题的基本情景，这些问题可以通过几个推理步骤直接得到答案。对于更具挑战性的多跳视觉推理任务的规划仍然缺乏探索。具体来说，在多跳推理的情况下，计划搜索的精度和复杂性之间的权衡变得突出。目前流行的算法要么采用快速一站式生成来解决效率问题，要么采用复杂的迭代生成方法来提高精度。两者都未能平衡对效率和性能的需求。本文从人类大脑的双重认知系统——快速和慢速思维过程中得到启发，提出了一种结合一站式推理(快速)和思维树(慢速)的分层计划搜索算法。我们的方法在性能上取得了成功，同时显著地节省了推理步骤。此外，我们重新定义了 PTR 和 CLEVER 数据集，建立了一个系统框架，用于评估基于 LLM 的计划搜索算法在不同难度推理任务下的性能和效率。大量的实验证明了该算法在性能和效率方面的优越性。数据集和代码将很快发布。"
    },
    {
        "title": "ChatHaruhi: Reviving Anime Character in Reality via Large Language Model",
        "url": "http://arxiv.org/abs/2308.09597v1",
        "pub_date": "2023-08-18",
        "summary": "Role-playing chatbots built on large language models have drawn interest, but\nbetter techniques are needed to enable mimicking specific fictional characters.\nWe propose an algorithm that controls language models via an improved prompt\nand memories of the character extracted from scripts. We construct ChatHaruhi,\na dataset covering 32 Chinese / English TV / anime characters with over 54k\nsimulated dialogues. Both automatic and human evaluations show our approach\nimproves role-playing ability over baselines. Code and data are available at\nhttps://github.com/LC1332/Chat-Haruhi-Suzumiya .",
        "translated": "基于大型语言模型的角色扮演聊天机器人引起了人们的兴趣，但是需要更好的技术来模仿特定的虚构人物。我们提出了一个算法，通过一个改进的提示和记忆的字符提取脚本控制语言模型。我们构建了 ChatHaruhi 数据集，该数据集涵盖了32个中文/英文电视/动画角色和超过54k 的模拟对话。自动评估和人工评估都表明，我们的方法提高了基线角色扮演能力。代码和数据可在 https://github.com/lc1332/chat-haruhi-suzumiya 查阅。"
    },
    {
        "title": "WizardMath: Empowering Mathematical Reasoning for Large Language Models\n  via Reinforced Evol-Instruct",
        "url": "http://arxiv.org/abs/2308.09583v1",
        "pub_date": "2023-08-18",
        "summary": "Large language models (LLMs), such as GPT-4, have shown remarkable\nperformance in natural language processing (NLP) tasks, including challenging\nmathematical reasoning. However, most existing open-source models are only\npre-trained on large-scale internet data and without math-related optimization.\nIn this paper, we present WizardMath, which enhances the mathematical reasoning\nabilities of Llama-2, by applying our proposed Reinforcement Learning from\nEvol-Instruct Feedback (RLEIF) method to the domain of math. Through extensive\nexperiments on two mathematical reasoning benchmarks, namely GSM8k and MATH, we\nreveal the extraordinary capabilities of our model. WizardMath surpasses all\nother open-source LLMs by a substantial margin. Furthermore, our model even\noutperforms ChatGPT-3.5, Claude Instant-1, PaLM-2 and Minerva on GSM8k,\nsimultaneously surpasses Text-davinci-002, PaLM-1 and GPT-3 on MATH. More\ndetails and model weights are public at https://github.com/nlpxucan/WizardLM\nand https://huggingface.co/WizardLM.",
        "translated": "大型语言模型(LLM) ，如 GPT-4，在自然语言处理(NLP)任务中表现出显著的性能，包括具有挑战性的数学推理。然而，大多数现有的开源模型只是针对大规模互联网数据进行了预先训练，并且没有进行与数学相关的优化。在这篇论文中，我们提出了 WizardMath，它通过将我们提出的从进化指令反馈(Evol-direct Feeback，RLEIF)方法到数学领域的强化学习，增强了美洲驼 -2的数学推理能力。通过对 GSM8k 和 MATH 两个数学推理基准的大量实验，揭示了该模型的非凡能力。WizardMath 远远超过其他所有开源 LLM。此外，我们的模型甚至在 GSM8k 上超过 ChatgPT-3.5，Claude Instant-1，palM-2和密涅瓦，在 MATH 上同时超过 Text-davinci-002，palM-1和 gPT-3。更多的细节和重量模型在 https://github.com/nlpxucan/wizardlm 和 https://huggingface.co/wizardlm 上公开。"
    },
    {
        "title": "PUMGPT: A Large Vision-Language Model for Product Understanding",
        "url": "http://arxiv.org/abs/2308.09568v1",
        "pub_date": "2023-08-18",
        "summary": "Recent developments of multi-modal large language models have demonstrated\nits strong ability in solving vision-language tasks. In this paper, we focus on\nthe product understanding task, which plays an essential role in enhancing\nonline shopping experience. Product understanding task includes a variety of\nsub-tasks, which require models to respond diverse queries based on multi-modal\nproduct information. Traditional methods design distinct model architectures\nfor each sub-task. On the contrary, we present PUMGPT, a large vision-language\nmodel aims at unifying all product understanding tasks under a singular model\nstructure. To bridge the gap between vision and text representations, we\npropose Layer-wise Adapters (LA), an approach that provides enhanced alignment\nwith fewer visual tokens and enables parameter-efficient fine-tuning. Moreover,\nthe inherent parameter-efficient fine-tuning ability allows PUMGPT to be\nreadily adapted to new product understanding tasks and emerging products. We\ndesign instruction templates to generate diverse product instruction datasets.\nSimultaneously, we utilize open-domain datasets during training to improve the\nperformance of PUMGPT and its generalization ability. Through extensive\nevaluations, PUMGPT demonstrates its superior performance across multiple\nproduct understanding tasks, including product captioning, category\nquestion-answering, attribute extraction, attribute question-answering, and\neven free-form question-answering about products.",
        "translated": "近年来，多模态大语言模型的发展已经证明了其在解决视觉语言任务方面的强大能力。本文主要研究产品理解任务对提高网上购物体验的作用。产品理解任务包括各种子任务，需要模型基于多模态产品信息响应各种查询。传统方法为每个子任务设计不同的模型架构。相反，我们提出了一个大型的视觉语言模型 PUMGPT，目的是在一个奇异的模型结构下统一所有的产品理解任务。为了消除视觉和文本表示之间的差距，我们提出了分层适配器(Layer-wise Adapters，LA) ，这种方法通过更少的可视标记提供增强的对齐，并支持参数高效的微调。此外，固有的参数高效微调能力使得 PUMGPT 能够很容易地适应新的产品理解任务和新出现的产品。我们设计指令模板来生成不同的产品指令数据集。同时，在训练过程中利用开放域数据集提高 PUMGPT 的性能和泛化能力。通过广泛的评估，PUMGPT 在产品字幕、类别问答、属性提取、属性问答、甚至自由形式的产品问答等多种产品理解任务中表现出了优越的性能。"
    },
    {
        "title": "Semantic relatedness in DBpedia: A comparative and experimental\n  assessment",
        "url": "http://arxiv.org/abs/2308.09502v1",
        "pub_date": "2023-08-18",
        "summary": "Evaluating semantic relatedness of Web resources is still an open challenge.\nThis paper focuses on knowledge-based methods, which represent an alternative\nto corpus-based approaches, and rely in general on the availability of\nknowledge graphs. In particular, we have selected 10 methods from the existing\nliterature, that have been organized according to it adjacent resources, triple\npatterns, and triple weights-based methods. They have been implemented and\nevaluated by using DBpedia as reference RDF knowledge graph. Since DBpedia is\ncontinuously evolving, the experimental results provided by these methods in\nthe literature are not comparable. For this reason, in this work, such methods\nhave been experimented by running them all at once on the same DBpedia release\nand against 14 well-known golden datasets. On the basis of the correlation\nvalues with human judgment obtained according to the experimental results,\nweighting the RDF triples in combination with evaluating all the directed paths\nlinking the compared resources is the best strategy in order to compute\nsemantic relatedness in DBpedia.",
        "translated": "评价 Web 资源的语义相关性仍然是一个公开的挑战。本文主要研究基于知识的方法，它代表了基于语料库的方法的一种替代方法，并且通常依赖于知识图的可用性。特别是，我们从现有的文献中选择了10种方法，这些方法已经根据相邻的资源、三重模式和三重权重方法进行了组织。使用 DBpedia 作为参考 RDF 知识图，实现并评估了它们。由于 DBpedia 是不断发展的，这些方法在文献中提供的实验结果是不可比较的。出于这个原因，在这项工作中，通过在同一个 DBpedia 发行版和14个著名的黄金数据集上同时运行所有这些方法进行了实验。在实验结果与人类判断相关性的基础上，对 RDF 三元组进行加权，并结合所有连接被比较资源的有向路径进行评估，是 DBpedia 中计算语义相关性的最佳策略。"
    },
    {
        "title": "Predictive Authoring for Brazilian Portuguese Augmentative and\n  Alternative Communication",
        "url": "http://arxiv.org/abs/2308.09497v1",
        "pub_date": "2023-08-18",
        "summary": "Individuals with complex communication needs (CCN) often rely on augmentative\nand alternative communication (AAC) systems to have conversations and\ncommunique their wants. Such systems allow message authoring by arranging\npictograms in sequence. However, the difficulty of finding the desired item to\ncomplete a sentence can increase as the user's vocabulary increases. This paper\nproposes using BERTimbau, a Brazilian Portuguese version of BERT, for pictogram\nprediction in AAC systems. To finetune BERTimbau, we constructed an AAC corpus\nfor Brazilian Portuguese to use as a training corpus. We tested different\napproaches to representing a pictogram for prediction: as a word (using\npictogram captions), as a concept (using a dictionary definition), and as a set\nof synonyms (using related terms). We also evaluated the usage of images for\npictogram prediction. The results demonstrate that using embeddings computed\nfrom the pictograms' caption, synonyms, or definitions have a similar\nperformance. Using synonyms leads to lower perplexity, but using captions leads\nto the highest accuracies. This paper provides insight into how to represent a\npictogram for prediction using a BERT-like model and the potential of using\nimages for pictogram prediction.",
        "translated": "具有复杂沟通需求的个体通常依赖于扩大性和替代性沟通系统(AAC)来进行交流和表达他们的需求。这样的系统允许通过按顺序排列象形文字来创作信息。然而，随着使用者词汇量的增加，找到所需要的项目来完成一个句子的难度会增加。本文提出在 AAC 系统中使用 BERTimbau，一个巴西葡萄牙语的 BERT 版本，进行象形图的预测。为了调整 BERTimbau，我们构建了一个 AAC 语料库，供巴西葡萄牙语作为培训语料库使用。我们测试了表示用于预测的象形图的不同方法: 作为一个单词(使用象形图标题) ，作为一个概念(使用字典定义) ，以及作为一组同义词(使用相关术语)。我们还评估了图像在象形文字预测中的应用。结果表明，使用从象形文字的标题、同义词或定义计算得到的嵌入具有相似的性能。使用同义词可以减少困惑，但使用标题可以获得最高的准确性。本文深入探讨了如何使用 BERT 类模型来表示用于预测的象形文字，以及利用图像进行象形文字预测的潜力。"
    },
    {
        "title": "Artificial-Spiking Hierarchical Networks for Vision-Language\n  Representation Learning",
        "url": "http://arxiv.org/abs/2308.09455v1",
        "pub_date": "2023-08-18",
        "summary": "With the success of self-supervised learning, multimodal foundation models\nhave rapidly adapted a wide range of downstream tasks driven by vision and\nlanguage (VL) pretraining. State-of-the-art methods achieve impressive\nperformance by pre-training on large-scale datasets. However, bridging the\nsemantic gap between the two modalities remains a nonnegligible challenge for\nVL tasks. In this work, we propose an efficient computation framework for\nmultimodal alignment by introducing a novel visual semantic module to further\nimprove the performance of the VL tasks. Specifically, we propose a flexible\nmodel, namely Artificial-Spiking Hierarchical Networks (ASH-Nets), which\ncombines the complementary advantages of Artificial neural networks (ANNs) and\nSpiking neural networks (SNNs) to enrich visual semantic representations. In\nparticular, a visual concrete encoder and a semantic abstract encoder are\nconstructed to learn continuous and discrete latent variables to enhance the\nflexibility of semantic encoding. Considering the spatio-temporal properties of\nSNNs modeling, we introduce a contrastive learning method to optimize the\ninputs of similar samples. This can improve the computational efficiency of the\nhierarchical network, while the augmentation of hard samples is beneficial to\nthe learning of visual representations. Furthermore, the Spiking to Text\nUni-Alignment Learning (STUA) pre-training method is proposed, which only\nrelies on text features to enhance the encoding ability of abstract semantics.\nWe validate the performance on multiple well-established downstream VL tasks.\nExperiments show that the proposed ASH-Nets achieve competitive results.",
        "translated": "随着自监督学习的成功，多模态基础模型已经迅速适应了视觉和语言(VL)预训练驱动的大范围下游任务。通过对大规模数据集进行预训练，最先进的方法取得了令人印象深刻的性能。然而，对于 VL 任务来说，消除两种模式之间的语义差异仍然是一个不可忽视的挑战。为了进一步提高 VL 任务的性能，本文引入了一种新的视觉语义模块，提出了一种高效的多模态对齐计算框架。具体来说，我们提出了一个灵活的模型，即人工扣分层网络(ASH-Nets) ，它结合了人工神经网络(ANN)和扣分神经网络(SNN)的互补优势，丰富了视觉语义表示。特别是构造了可视化具体编码器和语义抽象编码器来学习连续和离散的潜变量，以增强语义编码的灵活性。考虑到 SNN 建模的时空特性，我们引入了一种对比学习方法来优化相似样本的输入。这可以提高层次网络的计算效率，而增加硬样本有利于视觉表征的学习。在此基础上，提出了针对文本的单一对齐学习(STUA)预训练方法，该方法仅依靠文本特征来提高抽象语义的编码能力。我们验证了在多个建立良好的下游 VL 任务上的性能。实验结果表明，所提出的 ASH 网络具有较强的竞争力。"
    },
    {
        "title": "Leveraging Large Language Models for Pre-trained Recommender Systems",
        "url": "http://arxiv.org/abs/2308.10837v1",
        "pub_date": "2023-08-21",
        "summary": "Recent advancements in recommendation systems have shifted towards more\ncomprehensive and personalized recommendations by utilizing large language\nmodels (LLM). However, effectively integrating LLM's commonsense knowledge and\nreasoning abilities into recommendation systems remains a challenging problem.\nIn this paper, we propose RecSysLLM, a novel pre-trained recommendation model\nbased on LLMs. RecSysLLM retains LLM reasoning and knowledge while integrating\nrecommendation domain knowledge through unique designs of data, training, and\ninference. This allows RecSysLLM to leverage LLMs' capabilities for\nrecommendation tasks in an efficient, unified framework. We demonstrate the\neffectiveness of RecSysLLM on benchmarks and real-world scenarios. RecSysLLM\nprovides a promising approach to developing unified recommendation systems by\nfully exploiting the power of pre-trained language models.",
        "translated": "推荐系统的最新进展已经通过使用大型语言模型(LLM)转向更全面和个性化的推荐。然而，有效地将 LLM 的常识知识和推理能力集成到推荐系统中仍然是一个具有挑战性的问题。本文提出了一种新的基于 LLM 的预训练推荐模型 RecSysLLM。RecSysLLM 保留 LLM 推理和知识，同时通过独特的数据、训练和推理设计整合推荐领域知识。这使 RecSysLLM 能够在一个高效、统一的框架中利用 LLM 的推荐任务功能。我们展示了 RecSysLLM 在基准测试和真实场景中的有效性。RecSysLLM 通过充分利用预训练语言模型的功能，为开发统一推荐系统提供了一种有前途的方法。"
    },
    {
        "title": "Enhancing Recommender Systems with Large Language Model Reasoning Graphs",
        "url": "http://arxiv.org/abs/2308.10835v1",
        "pub_date": "2023-08-21",
        "summary": "Recommendation systems aim to provide users with relevant suggestions, but\noften lack interpretability and fail to capture higher-level semantic\nrelationships between user behaviors and profiles. In this paper, we propose a\nnovel approach that leverages large language models (LLMs) to construct\npersonalized reasoning graphs. These graphs link a user's profile and\nbehavioral sequences through causal and logical inferences, representing the\nuser's interests in an interpretable way. Our approach, LLM reasoning graphs\n(LLMRG), has four components: chained graph reasoning, divergent extension,\nself-verification and scoring, and knowledge base self-improvement. The\nresulting reasoning graph is encoded using graph neural networks, which serves\nas additional input to improve conventional recommender systems, without\nrequiring extra user or item information. Our approach demonstrates how LLMs\ncan enable more logical and interpretable recommender systems through\npersonalized reasoning graphs. LLMRG allows recommendations to benefit from\nboth engineered recommendation systems and LLM-derived reasoning graphs. We\ndemonstrate the effectiveness of LLMRG on benchmarks and real-world scenarios\nin enhancing base recommendation models.",
        "translated": "推荐系统的目的是为用户提供相关的建议，但往往缺乏可解释性，无法捕获用户行为和配置文件之间的更高层次的语义关系。本文提出了一种利用大语言模型(LLM)构造个性化推理图的新方法。这些图表通过因果和逻辑推断将用户的配置文件和行为序列联系起来，以可解释的方式表示用户的兴趣。我们的方法，LLM 推理图(LLMRG) ，有四个组成部分: 链图推理，发散扩展，自我验证和评分，和知识库自我完善。由此产生的推理图使用图神经网络进行编码，作为额外的输入来改进传统的推荐系统，而不需要额外的用户或项目信息。我们的方法演示了 LLM 如何通过个性化推理图实现更具逻辑性和可解释性的推荐系统。LLMRG 允许建议从工程推荐系统和 LLM 衍生的推理图中受益。我们展示了 LLMRG 在基准测试和真实场景中增强基础推荐模型的有效性。"
    },
    {
        "title": "DynED: Dynamic Ensemble Diversification in Data Stream Classification",
        "url": "http://arxiv.org/abs/2308.10807v1",
        "pub_date": "2023-08-21",
        "summary": "Ensemble methods are commonly used in classification due to their remarkable\nperformance. Achieving high accuracy in a data stream environment is a\nchallenging task considering disruptive changes in the data distribution, also\nknown as concept drift. A greater diversity of ensemble components is known to\nenhance prediction accuracy in such settings. Despite the diversity of\ncomponents within an ensemble, not all contribute as expected to its overall\nperformance. This necessitates a method for selecting components that exhibit\nhigh performance and diversity. We present a novel ensemble construction and\nmaintenance approach based on MMR (Maximal Marginal Relevance) that dynamically\ncombines the diversity and prediction accuracy of components during the process\nof structuring an ensemble. The experimental results on both four real and 11\nsynthetic datasets demonstrate that the proposed approach (DynED) provides a\nhigher average mean accuracy compared to the five state-of-the-art baselines.",
        "translated": "集成方法由于其显著的性能，在分类中得到了广泛的应用。在数据流环境中实现高精度是一项具有挑战性的任务，考虑到数据分布的破坏性变化，也称为概念漂移。众所周知，集合分量的更大多样性可以提高这种情况下的预测精度。尽管一个集合中的组件多种多样，但并非所有组件都如预期的那样对其整体性能有贡献。这就需要一种方法来选择具有高性能和多样性的组件。提出了一种基于最大边际相关(MMR)的集成构建和维护方法，该方法在集成构建过程中动态地综合了组件的多样性和预测精度。在4个实际数据集和11个合成数据集上的实验结果表明，与5个最先进的基线相比，该方法提供了更高的平均精度。"
    },
    {
        "title": "LSCPM: communities in massive real-world Link Streams by Clique\n  Percolation Method",
        "url": "http://arxiv.org/abs/2308.10801v1",
        "pub_date": "2023-08-21",
        "summary": "Community detection is a popular approach to understand the organization of\ninteractions in static networks. For that purpose, the Clique Percolation\nMethod (CPM), which involves the percolation of k-cliques, is a well-studied\ntechnique that offers several advantages. Besides, studying interactions that\noccur over time is useful in various contexts, which can be modeled by the link\nstream formalism. The Dynamic Clique Percolation Method (DCPM) has been\nproposed for extending CPM to temporal networks.\n  However, existing implementations are unable to handle massive datasets. We\npresent a novel algorithm that adapts CPM to link streams, which has the\nadvantage that it allows us to speed up the computation time with respect to\nthe existing DCPM method. We evaluate it experimentally on real datasets and\nshow that it scales to massive link streams. For example, it allows to obtain a\ncomplete set of communities in under twenty-five minutes for a dataset with\nthirty million links, what the state of the art fails to achieve even after a\nweek of computation. We further show that our method provides communities\nsimilar to DCPM, but slightly more aggregated. We exhibit the relevance of the\nobtained communities in real world cases, and show that they provide\ninformation on the importance of vertices in the link streams.",
        "translated": "社区检测是理解静态网络中交互组织的一种流行方法。为此，集团渗透法(CPM) ，其中涉及到 k 集团的渗透，是一个良好的研究技术，提供了几个优点。此外，研究随时间发生的交互作用在各种情况下都是有用的，这可以用链接流形式主义来模拟。提出了一种将动态团体渗流方法(DCPM)推广到时态网络的方法。但是，现有的实现无法处理大量数据集。我们提出了一个新的算法，适应 CPM 链接流，它的优点是，它允许我们加快计算时间相对于现有的 DCPM 方法。我们在实际数据集上对它进行了实验评估，结果表明它可以扩展到大量的链接流。例如，它允许在不到25分钟的时间内为一个有3000万个链接的数据集获得一套完整的社区，这是目前最先进的技术即使经过一周的计算也无法做到的。我们进一步展示了我们的方法提供了类似于 DCPM 的社区，但是稍微聚合了一些。我们展示了获得的社区在现实世界的情况下的相关性，并表明他们提供了关于链路流中顶点的重要性的信息。"
    },
    {
        "title": "A Topology-aware Analysis of Graph Collaborative Filtering",
        "url": "http://arxiv.org/abs/2308.10778v1",
        "pub_date": "2023-08-21",
        "summary": "The successful integration of graph neural networks into recommender systems\n(RSs) has led to a novel paradigm in collaborative filtering (CF), graph\ncollaborative filtering (graph CF). By representing user-item data as an\nundirected, bipartite graph, graph CF utilizes short- and long-range\nconnections to extract collaborative signals that yield more accurate user\npreferences than traditional CF methods. Although the recent literature\nhighlights the efficacy of various algorithmic strategies in graph CF, the\nimpact of datasets and their topological features on recommendation performance\nis yet to be studied. To fill this gap, we propose a topology-aware analysis of\ngraph CF. In this study, we (i) take some widely-adopted recommendation\ndatasets and use them to generate a large set of synthetic sub-datasets through\ntwo state-of-the-art graph sampling methods, (ii) measure eleven of their\nclassical and topological characteristics, and (iii) estimate the accuracy\ncalculated on the generated sub-datasets considering four popular and recent\ngraph-based RSs (i.e., LightGCN, DGCF, UltraGCN, and SVD-GCN). Finally, the\ninvestigation presents an explanatory framework that reveals the linear\nrelationships between characteristics and accuracy measures. The results,\nstatistically validated under different graph sampling settings, confirm the\nexistence of solid dependencies between topological characteristics and\naccuracy in the graph-based recommendation, offering a new perspective on how\nto interpret graph CF.",
        "translated": "图形神经网络与推荐系统(RSs)的成功整合为协同过滤(CF)、图形协同过滤(graph CF)提供了一种新的范式。通过将用户项目数据表示为一个无向的二分图，图 CF 利用短距离和长距离的连接来提取协作信号，从而产生比传统 CF 方法更准确的用户偏好。虽然最近的文献强调了各种算法策略在图 CF 中的有效性，但是数据集及其拓扑特征对推荐性能的影响还有待研究。为了填补这个空白，我们提出了一个图形 CF 的拓扑感知分析。在这项研究中，我们(i)采用一些广泛采用的推荐数据集，并使用它们通过两种最先进的图形采样方法来生成一个大型的合成子数据集，(ii)测量它们的11个经典和拓扑特征，以及(iii)估计在生成的子数据集上计算的精度，考虑到四个流行的和最近的基于图形的 RS (即 LightGCN，DGCF，UltraGCN 和 SVD-GCN)。最后，研究提出了一个解释框架，揭示了特征和精度测量之间的线性关系。研究结果在不同的图形抽样设置下进行了统计验证，证实了基于图形的推荐中拓扑特征和精度之间存在着固有的依赖关系，为如何解释图形 CF 提供了一个新的视角。"
    },
    {
        "title": "Giraffe: Adventures in Expanding Context Lengths in LLMs",
        "url": "http://arxiv.org/abs/2308.10882v1",
        "pub_date": "2023-08-21",
        "summary": "Modern large language models (LLMs) that rely on attention mechanisms are\ntypically trained with fixed context lengths which enforce upper limits on the\nlength of input sequences that they can handle at evaluation time. To use these\nmodels on sequences longer than the train-time context length, one might employ\ntechniques from the growing family of context length extrapolation methods --\nmost of which focus on modifying the system of positional encodings used in the\nattention mechanism to indicate where tokens or activations are located in the\ninput sequence. We conduct a wide survey of existing methods of context length\nextrapolation on a base LLaMA or LLaMA 2 model, and introduce some of our own\ndesign as well -- in particular, a new truncation strategy for modifying the\nbasis for the position encoding.\n  We test these methods using three new evaluation tasks (FreeFormQA,\nAlteredNumericQA, and LongChat-Lines) as well as perplexity, which we find to\nbe less fine-grained as a measure of long context performance of LLMs. We\nrelease the three tasks publicly as datasets on HuggingFace. We discover that\nlinear scaling is the best method for extending context length, and show that\nfurther gains can be achieved by using longer scales at evaluation time. We\nalso discover promising extrapolation capabilities in the truncated basis. To\nsupport further research in this area, we release three new 13B parameter\nlong-context models which we call Giraffe: 4k and 16k context models trained\nfrom base LLaMA-13B, and a 32k context model trained from base LLaMA2-13B. We\nalso release the code to replicate our results.",
        "translated": "现代大型语言模型(LLM)依赖于注意力机制，通常训练有固定的上下文长度，强制上限的输入序列的长度，他们可以处理在评估时间。为了将这些模型用于比训练时间上下文长度更长的序列，人们可能会采用来自不断增长的上下文长度外推方法家族的技术——其中大多数侧重于修改注意机制中使用的位置编码系统，以指示令牌或激活在输入序列中的位置。我们对现有的基于 LLaMA 或 LLaMA 2模型的上下文长度外推方法进行了广泛的调查，并介绍了我们自己的一些设计——特别是一种修改位置编码基准的新的截断策略。我们使用三个新的评估任务(FreeFormQA，AlteredNumericQA 和 LongChat-Lines)以及困惑来测试这些方法，我们发现作为 LLM 的长上下文性能的度量，它们的细粒度较小。我们在 HuggingFace 上将这三个任务作为数据集公开发布。我们发现线性尺度是扩展上下文长度的最佳方法，并表明在评估时使用较长尺度可以获得进一步的增益。我们还发现在截断的基础上有前途的外推能力。为了支持该领域的进一步研究，我们发布了三个新的13B 参数长背景模型，我们称之为 Giraffe: 从基地 LLaMA-13B 训练的4k 和16k 背景模型，以及从基地 LLaMA2-13B 训练的32k 背景模型。我们还发布代码来复制我们的结果。"
    },
    {
        "title": "Analyzing Transformer Dynamics as Movement through Embedding Space",
        "url": "http://arxiv.org/abs/2308.10874v1",
        "pub_date": "2023-08-21",
        "summary": "Transformer language models exhibit intelligent behaviors such as\nunderstanding natural language, recognizing patterns, acquiring knowledge,\nreasoning, planning, reflecting and using tools. This paper explores how their\nunderlying mechanics give rise to intelligent behaviors. We adopt a systems\napproach to analyze Transformers in detail and develop a mathematical framework\nthat frames their dynamics as movement through embedding space. This novel\nperspective provides a principled way of thinking about the problem and reveals\nimportant insights related to the emergence of intelligence:\n  1. At its core the Transformer is a Embedding Space walker, mapping\nintelligent behavior to trajectories in this vector space.\n  2. At each step of the walk, it composes context into a single composite\nvector whose location in Embedding Space defines the next step.\n  3. No learning actually occurs during decoding; in-context learning and\ngeneralization are simply the result of different contexts composing into\ndifferent vectors.\n  4. Ultimately the knowledge, intelligence and skills exhibited by the model\nare embodied in the organization of vectors in Embedding Space rather than in\nspecific neurons or layers. These abilities are properties of this\norganization.\n  5. Attention's contribution boils down to the association-bias it lends to\nvector composition and which influences the aforementioned organization.\nHowever, more investigation is needed to ascertain its significance.\n  6. The entire model is composed from two principal operations: data\nindependent filtering and data dependent aggregation. This generalization\nunifies Transformers with other sequence models and across modalities.\n  Building upon this foundation we formalize and test a semantic space theory\nwhich posits that embedding vectors represent semantic concepts and find some\nevidence of its validity.",
        "translated": "变换器语言模型具有理解自然语言、识别模式、获取知识、推理、规划、反思和使用工具等智能行为。本文探讨了它们潜在的力学如何产生智能行为。我们采用系统方法对变压器进行了详细的分析，并建立了一个数学框架，通过嵌入空间将变压器的动力学框架定义为运动。这个新颖的视角提供了一个原则性的思考问题的方式，并揭示了与智力出现有关的重要见解: 1。在它的核心变压器是一个嵌入式空间行走，映射智能行为的轨迹在这个向量空间。2.在遍历的每一步，它将上下文组合成一个合成向量，该向量在嵌入空间中的位置定义了下一步。3.在解码过程中并没有真正的学习过程，语境中的学习和泛化只是不同语境组成不同向量的结果。4.该模型所展示的知识、智力和技能最终体现在嵌入空间的向量组织中，而不是在特定的神经元或层中。这些能力是这个组织的属性。5.注意力的贡献可以归结为它给向量组合带来的关联偏差，这种偏差影响了上述组织。然而，需要更多的调查来确定其意义。6.整个模型由两个主要操作组成: 独立于数据的过滤和依赖于数据的聚合。这种泛化将 Transformers 与其他序列模型和跨模式统一起来。在此基础上，对嵌入向量表示语义概念的语义空间理论进行了形式化的形式化验证。"
    },
    {
        "title": "LatEval: An Interactive LLMs Evaluation Benchmark with Incomplete\n  Information from Lateral Thinking Puzzles",
        "url": "http://arxiv.org/abs/2308.10855v1",
        "pub_date": "2023-08-21",
        "summary": "With the continuous evolution and refinement of LLMs, they are endowed with\nimpressive logical reasoning or vertical thinking capabilities. But can they\nthink out of the box? Do they possess proficient lateral thinking abilities?\nFollowing the setup of Lateral Thinking Puzzles, we propose a novel evaluation\nbenchmark, LatEval, which assesses the model's lateral thinking within an\ninteractive framework. In our benchmark, we challenge LLMs with 2 aspects: the\nquality of questions posed by the model and the model's capability to integrate\ninformation for problem-solving. We find that nearly all LLMs struggle with\nemploying lateral thinking during interactions. For example, even the most\nadvanced model, GPT-4, exhibits the advantage to some extent, yet still\nmaintain a noticeable gap when compared to human. This evaluation benchmark\nprovides LLMs with a highly challenging and distinctive task that is crucial to\nan effective AI assistant.",
        "translated": "随着 LLM 的不断发展和完善，它们被赋予了令人印象深刻的逻辑推理或纵向思维能力。但他们能跳出思维定势吗？他们是否具备熟练的水平思考能力？随着水平思考拼图的设置，我们提出了一个新的评估基准，LatEval，它在一个交互式框架内评估模型的水平思考。在我们的基准测试中，我们从两个方面挑战 LLM: 模型提出的问题的质量和模型为解决问题而集成信息的能力。我们发现，几乎所有的 LLM 都难以在交互过程中使用水平思考。例如，即使是最先进的型号，GPT-4，在一定程度上展示了优势，但仍然保持了明显的差距，相比于人类。这一评估基准为长期管理人员提供了一项具有高度挑战性和独特性的任务，对于有效的人工智能助理至关重要。"
    },
    {
        "title": "AgentVerse: Facilitating Multi-Agent Collaboration and Exploring\n  Emergent Behaviors in Agents",
        "url": "http://arxiv.org/abs/2308.10848v1",
        "pub_date": "2023-08-21",
        "summary": "Autonomous agents empowered by Large Language Models (LLMs) have undergone\nsignificant improvements, enabling them to generalize across a broad spectrum\nof tasks. However, in real-world scenarios, cooperation among individuals is\noften required to enhance the efficiency and effectiveness of task\naccomplishment. Hence, inspired by human group dynamics, we propose a\nmulti-agent framework \\framework that can collaboratively and dynamically\nadjust its composition as a greater-than-the-sum-of-its-parts system. Our\nexperiments demonstrate that \\framework framework can effectively deploy\nmulti-agent groups that outperform a single agent. Furthermore, we delve into\nthe emergence of social behaviors among individual agents within a group during\ncollaborative task accomplishment. In view of these behaviors, we discuss some\npossible strategies to leverage positive ones and mitigate negative ones for\nimproving the collaborative potential of multi-agent groups. Our codes for\n\\framework will soon be released at\n\\url{https://github.com/OpenBMB/AgentVerse}.",
        "translated": "由大型语言模型(LLM)授权的自治代理已经经历了重大的改进，使它们能够在广泛的任务范围内进行泛化。然而，在现实世界中，为了提高任务完成的效率和有效性，往往需要个体之间的合作。因此，受人类群体动力学的启发，我们提出了一个多智能体框架，该框架可以协作并动态地调整其组成，使其成为一个大于其各部分之和的系统。我们的实验表明，框架框架可以有效地部署多代理组，其性能优于单个代理。此外，本研究还探讨了群体中个体主体在协作任务完成过程中社会行为的产生。针对这些行为，我们讨论了一些可能的策略，以利用积极的和减轻消极的，以提高多智能体群体的协作潜力。我们的框架代码将很快在 url { https://github.com/openbmb/agentverse }发布。"
    },
    {
        "title": "Instruction Tuning for Large Language Models: A Survey",
        "url": "http://arxiv.org/abs/2308.10792v1",
        "pub_date": "2023-08-21",
        "summary": "This paper surveys research works in the quickly advancing field of\ninstruction tuning (IT), a crucial technique to enhance the capabilities and\ncontrollability of large language models (LLMs). Instruction tuning refers to\nthe process of further training LLMs on a dataset consisting of\n\\textsc{(instruction, output)} pairs in a supervised fashion, which bridges the\ngap between the next-word prediction objective of LLMs and the users' objective\nof having LLMs adhere to human instructions. In this work, we make a systematic\nreview of the literature, including the general methodology of IT, the\nconstruction of IT datasets, the training of IT models, and applications to\ndifferent modalities, domains and applications, along with an analysis on\naspects that influence the outcome of IT (e.g., generation of instruction\noutputs, size of the instruction dataset, etc). We also review the potential\npitfalls of IT along with criticism against it, along with efforts pointing out\ncurrent deficiencies of existing strategies and suggest some avenues for\nfruitful research.",
        "translated": "本文综述了教学调优(IT)这一提高大型语言模型(LLM)能力和可控性的关键技术在快速发展的领域中的研究工作。指令调优是指在一个由 textsc {(指令，输出)}对组成的数据集上进一步训练 LLM 的过程，该过程以有监督的方式连接 LLM 的下一个单词预测目标和用户让 LLM 遵守人类指令的目标之间的差距。在这项工作中，我们对文献进行了系统综述，包括信息技术的一般方法、信息技术数据集的构建、信息技术模型的训练、不同模式、领域和应用的应用，以及对影响信息技术结果的各个方面的分析(例如，指令输出的生成、指令数据集的大小等)。我们还回顾了信息技术的潜在缺陷，并对其提出了批评，同时指出了现有战略的缺陷，并提出了一些富有成效的研究途径。"
    },
    {
        "title": "Zero- and Few-Shot Prompting with LLMs: A Comparative Study with\n  Fine-tuned Models for Bangla Sentiment Analysis",
        "url": "http://arxiv.org/abs/2308.10783v1",
        "pub_date": "2023-08-21",
        "summary": "The rapid expansion of the digital world has propelled sentiment analysis\ninto a critical tool across diverse sectors such as marketing, politics,\ncustomer service, and healthcare. While there have been significant\nadvancements in sentiment analysis for widely spoken languages, low-resource\nlanguages, such as Bangla, remain largely under-researched due to resource\nconstraints. Furthermore, the recent unprecedented performance of Large\nLanguage Models (LLMs) in various applications highlights the need to evaluate\nthem in the context of low-resource languages. In this study, we present a\nsizeable manually annotated dataset encompassing 33,605 Bangla news tweets and\nFacebook comments. We also investigate zero- and few-shot in-context learning\nwith several language models, including Flan-T5, GPT-4, and Bloomz, offering a\ncomparative analysis against fine-tuned models. Our findings suggest that\nmonolingual transformer-based models consistently outperform other models, even\nin zero and few-shot scenarios. To foster continued exploration, we intend to\nmake this dataset and our research tools publicly available to the broader\nresearch community. In the spirit of further research, we plan to make this\ndataset and our experimental resources publicly accessible to the wider\nresearch community.",
        "translated": "数字世界的迅速扩张，已将情绪分析推进为一种关键工具，横跨市场营销、政治、客户服务和医疗等多个领域。虽然在广泛使用的语言情感分析方面取得了重大进展，但由于资源的限制，孟加拉语等资源匮乏的语言在很大程度上仍然没有得到充分的研究。此外，最近大型语言模型(LLM)在各种应用程序中的前所未有的性能突出表明，需要在资源较少的语言环境中对它们进行评估。在这项研究中，我们提出了一个相当大的手动注释数据集，包括33,605孟加拉国新闻推特和 Facebook 评论。我们还使用几种语言模型(包括 Flan-T5、 GPT-4和 Bloomz)调查了零拍摄和少拍摄的上下文学习，提供了针对微调模型的比较分析。我们的研究结果表明，单语言变压器为基础的模型始终优于其他模型，即使在零和少镜头的情况下。为了促进继续探索，我们打算将这个数据集和我们的研究工具公开提供给更广泛的研究团体。本着进一步研究的精神，我们计划将这个数据集和我们的实验资源向更广泛的研究团体公开。"
    },
    {
        "title": "DepreSym: A Depression Symptom Annotated Corpus and the Role of LLMs as\n  Assessors of Psychological Markers",
        "url": "http://arxiv.org/abs/2308.10758v1",
        "pub_date": "2023-08-21",
        "summary": "Computational methods for depression detection aim to mine traces of\ndepression from online publications posted by Internet users. However,\nsolutions trained on existing collections exhibit limited generalisation and\ninterpretability. To tackle these issues, recent studies have shown that\nidentifying depressive symptoms can lead to more robust models. The eRisk\ninitiative fosters research on this area and has recently proposed a new\nranking task focused on developing search methods to find sentences related to\ndepressive symptoms. This search challenge relies on the symptoms specified by\nthe Beck Depression Inventory-II (BDI-II), a questionnaire widely used in\nclinical practice. Based on the participant systems' results, we present the\nDepreSym dataset, consisting of 21580 sentences annotated according to their\nrelevance to the 21 BDI-II symptoms. The labelled sentences come from a pool of\ndiverse ranking methods, and the final dataset serves as a valuable resource\nfor advancing the development of models that incorporate depressive markers\nsuch as clinical symptoms. Due to the complex nature of this relevance\nannotation, we designed a robust assessment methodology carried out by three\nexpert assessors (including an expert psychologist). Additionally, we explore\nhere the feasibility of employing recent Large Language Models (ChatGPT and\nGPT4) as potential assessors in this complex task. We undertake a comprehensive\nexamination of their performance, determine their main limitations and analyze\ntheir role as a complement or replacement for human annotators.",
        "translated": "抑郁症检测的计算方法旨在从互联网用户发布的在线出版物中挖掘抑郁症的痕迹。然而，在现有集合上训练的解决方案表现出有限的一般性和可解释性。为了解决这些问题，最近的研究表明，确定抑郁症状可以导致更强大的模型。电子风险倡议促进了这一领域的研究，最近提出了一项新的排名任务，重点是开发搜索方法，找到与抑郁症状有关的句子。这种搜索挑战依赖于贝克抑郁量表 II (BDI-II)所规定的症状，这是一种在临床实践中广泛使用的问卷。基于参与者系统的结果，我们提出 DepreSym 数据集，包括21580个句子注释根据他们的相关性21 BDI-II 症状。标记的句子来自一个不同的排序方法的池，最终的数据集作为一个有价值的资源，促进模型的发展，包括抑郁症标志物，如临床症状。由于这个相关性注释的复杂性，我们设计了一个由三位专家评估员(包括一位专家心理学家)执行的健壮的评估方法。此外，我们在这里探讨了在这个复杂的任务中使用最近的大语言模型(ChatGPT 和 GPT4)作为潜在评估者的可行性。我们对它们的表现进行了全面的考察，确定了它们的主要局限性，并分析了它们作为人类注释者的补充或替代者的作用。"
    },
    {
        "title": "WanJuan: A Comprehensive Multimodal Dataset for Advancing English and\n  Chinese Large Models",
        "url": "http://arxiv.org/abs/2308.10755v2",
        "pub_date": "2023-08-21",
        "summary": "The rise in popularity of ChatGPT and GPT-4 has significantly accelerated the\ndevelopment of large models, leading to the creation of numerous impressive\nlarge language models(LLMs) and multimodal large language models (MLLMs). These\ncutting-edge models owe their remarkable performance to high-quality data.\nHowever, the details of the training data used in leading paradigms are often\nkept confidential. This lack of transparency, coupled with the scarcity of\nopen-source data, impedes further developments within the community. As a\nresponse, this paper presents \"Wan Juan\", a large-scale multimodal dataset\ncomposed of both Chinese and English data, collected from a wide range of web\nsources. The dataset incorporates text, image-text, and video modalities, with\na total volume exceeding 2TB. It was utilized in the training of InternLM, a\nmodel that demonstrated significant advantages in multi-dimensional evaluations\nwhen compared to models of a similar scale. All data can be accessed at\nhttps://opendatalab.org.cn/WanJuan1.0.",
        "translated": "ChatGPT 和 GPT-4的流行显著加速了大型模型的开发，导致了大量令人印象深刻的大型语言模型(LLM)和多模态大型语言模型(MLLM)的创建。这些尖端模型的出色表现归功于高质量的数据。然而，领先范式中使用的培训数据的细节往往是保密的。这种缺乏透明度，加上缺乏开源数据，阻碍了社区内部的进一步发展。作为回应，本文提出了“万卷”，一个由中英文数据组成的大规模多模式数据集，从广泛的网络来源收集。该数据集包含文本、图像-文本和视频模式，总体积超过2TB。它被用于 InternLM 的培训，这一模式与类似规模的模式相比，在多维评价方面显示出显著的优势。所有资料均可在 https://opendatalab.org.cn/wanjuan1.0查阅。"
    },
    {
        "title": "Systematic Offensive Stereotyping (SOS) Bias in Language Models",
        "url": "http://arxiv.org/abs/2308.10684v1",
        "pub_date": "2023-08-21",
        "summary": "Research has shown that language models (LMs) are socially biased. However,\ntoxicity and offensive stereotyping bias in LMs are understudied. In this\npaper, we investigate the systematic offensive stereotype (SOS) bias in LMs. We\npropose a method to measure it. Then, we validate the SOS bias and investigate\nthe effectiveness of debias methods from the literature on removing it.\nFinally, we investigate the impact of the SOS bias in LMs on their performance\nand their fairness on the task of hate speech detection. Our results suggest\nthat all the inspected LMs are SOS biased. The results suggest that the SOS\nbias in LMs is reflective of the hate experienced online by the inspected\nmarginalized groups. The results indicate that removing the SOS bias in LMs,\nusing a popular debias method from the literature, leads to worse SOS bias\nscores. Finally, Our results show no strong evidence that the SOS bias in LMs\nis impactful on their performance on hate speech detection. On the other hand,\nthere is evidence that the SOS bias in LMs is impactful on their fairness.",
        "translated": "研究表明，语言模型(LM)具有社会偏见。然而，毒性和攻击性刻板印象偏见的 LM 是不足的。本文研究了系统性攻击性刻板印象(SOS)偏向在语言习得中的作用。我们提出了一种测量它的方法。然后，我们验证了 SOS 偏倚，并从文献中探讨了去偏方法在消除 SOS 偏倚方面的有效性。最后，我们研究了 LM 中 SOS 偏差对其性能和公平性对仇恨语音检测任务的影响。我们的结果表明，所有检查的 LM 是 SOS 偏见。研究结果表明，LM 中的 SOS 偏好反映了被调查的边缘化群体在网络上所经历的仇恨。结果表明，使用文献中流行的偏差分析方法去除 LM 中的 SOS 偏差会导致 SOS 偏差分数的降低。最后，我们的结果表明，没有强有力的证据表明，SOS 偏差的 LM 是影响其性能的仇恨语音检测。另一方面，有证据表明，长期模型中的 SOS 偏差对其公平性有影响。"
    },
    {
        "title": "LibriWASN: A Data Set for Meeting Separation, Diarization, and\n  Recognition with Asynchronous Recording Devices",
        "url": "http://arxiv.org/abs/2308.10682v1",
        "pub_date": "2023-08-21",
        "summary": "We present LibriWASN, a data set whose design follows closely the LibriCSS\nmeeting recognition data set, with the marked difference that the data is\nrecorded with devices that are randomly positioned on a meeting table and whose\nsampling clocks are not synchronized. Nine different devices, five smartphones\nwith a single recording channel and four microphone arrays, are used to record\na total of 29 channels. Other than that, the data set follows closely the\nLibriCSS design: the same LibriSpeech sentences are played back from eight\nloudspeakers arranged around a meeting table and the data is organized in\nsubsets with different percentages of speech overlap. LibriWASN is meant as a\ntest set for clock synchronization algorithms, meeting separation, diarization\nand transcription systems on ad-hoc wireless acoustic sensor networks. Due to\nits similarity to LibriCSS, meeting transcription systems developed for the\nformer can readily be tested on LibriWASN. The data set is recorded in two\ndifferent rooms and is complemented with ground-truth diarization information\nof who speaks when.",
        "translated": "我们提出了 LibriWASN，这是一个数据集，其设计紧密遵循 LibriCSS 会议识别数据集，其显着差异是数据是用随机放置在会议桌上的设备记录的，其采样时钟不同步。九个不同的设备，五个智能手机与一个记录通道和四个麦克风阵列，被用来记录总共29个通道。除此之外，数据集严格遵循 LibriCSS 的设计: 同样的 LibriLanguage 语句从布置在会议桌周围的八个扬声器中回放，数据被组织成具有不同百分比的语音重叠的子集。LibriWASN 是无线声传感器网络时钟同步算法、会议分离、可变化和转录系统的测试集。由于其与 LibriCSS 的相似性，为前者开发的会议转录系统可以很容易地在 LibriWASN 上进行测试。数据集记录在两个不同的房间，并辅之以地面真相记录信息，说明谁在何时发言。"
    },
    {
        "title": "Multi-event Video-Text Retrieval",
        "url": "http://arxiv.org/abs/2308.11551v1",
        "pub_date": "2023-08-22",
        "summary": "Video-Text Retrieval (VTR) is a crucial multi-modal task in an era of massive\nvideo-text data on the Internet. A plethora of work characterized by using a\ntwo-stream Vision-Language model architecture that learns a joint\nrepresentation of video-text pairs has become a prominent approach for the VTR\ntask. However, these models operate under the assumption of bijective\nvideo-text correspondences and neglect a more practical scenario where video\ncontent usually encompasses multiple events, while texts like user queries or\nwebpage metadata tend to be specific and correspond to single events. This\nestablishes a gap between the previous training objective and real-world\napplications, leading to the potential performance degradation of earlier\nmodels during inference. In this study, we introduce the Multi-event Video-Text\nRetrieval (MeVTR) task, addressing scenarios in which each video contains\nmultiple different events, as a niche scenario of the conventional Video-Text\nRetrieval Task. We present a simple model, Me-Retriever, which incorporates key\nevent video representation and a new MeVTR loss for the MeVTR task.\nComprehensive experiments show that this straightforward framework outperforms\nother models in the Video-to-Text and Text-to-Video tasks, effectively\nestablishing a robust baseline for the MeVTR task. We believe this work serves\nas a strong foundation for future studies. Code is available at\nhttps://github.com/gengyuanmax/MeVTR.",
        "translated": "视频文本检索(VTR)是互联网上海量视频文本数据时代的一项重要的多模态检索任务。过多的工作拥有属性使用双流的视觉语言模型架构，学习视频文本对的联合表示，已经成为视频录像任务的一个突出方法。然而，这些模型是在双向视频文本对应的假设下运作的，忽略了一种更实际的情况，即视频内容通常包含多个事件，而用户查询或网页元数据等文本往往是具体的，对应单个事件。这在以前的培训目标和现实世界应用程序之间建立了一个差距，导致在推断过程中早期模型的潜在性能下降。本文将多事件视频文本检索任务作为传统视频文本检索任务的一个小生境场景进行介绍。我们提出了一个简单的模型，我-检索，其中包含关键事件视频表示和一个新的 MeVTR 损失的 MeVTR 任务。综合实验表明，该框架在视频到文本和文本到视频任务中的性能优于其他模型，有效地为 MeVTR 任务建立了稳健的基线。我们相信这项工作为以后的研究奠定了坚实的基础。密码可于 https://github.com/gengyuanmax/mevtr 索取。"
    },
    {
        "title": "L^2R: Lifelong Learning for First-stage Retrieval with\n  Backward-Compatible Representations",
        "url": "http://arxiv.org/abs/2308.11512v1",
        "pub_date": "2023-08-22",
        "summary": "First-stage retrieval is a critical task that aims to retrieve relevant\ndocument candidates from a large-scale collection. While existing retrieval\nmodels have achieved impressive performance, they are mostly studied on static\ndata sets, ignoring that in the real-world, the data on the Web is continuously\ngrowing with potential distribution drift. Consequently, retrievers trained on\nstatic old data may not suit new-coming data well and inevitably produce\nsub-optimal results. In this work, we study lifelong learning for first-stage\nretrieval, especially focusing on the setting where the emerging documents are\nunlabeled since relevance annotation is expensive and may not keep up with data\nemergence. Under this setting, we aim to develop model updating with two goals:\n(1) to effectively adapt to the evolving distribution with the unlabeled\nnew-coming data, and (2) to avoid re-inferring all embeddings of old documents\nto efficiently update the index each time the model is updated.\n  We first formalize the task and then propose a novel Lifelong Learning method\nfor the first-stage Retrieval, namely L^2R. L^2R adopts the typical memory\nmechanism for lifelong learning, and incorporates two crucial components: (1)\nselecting diverse support negatives for model training and memory updating for\neffective model adaptation, and (2) a ranking alignment objective to ensure the\nbackward-compatibility of representations to save the cost of index rebuilding\nwithout hurting the model performance. For evaluation, we construct two new\nbenchmarks from LoTTE and Multi-CPR datasets to simulate the document\ndistribution drift in realistic retrieval scenarios. Extensive experiments show\nthat L^2R significantly outperforms competitive lifelong learning baselines.",
        "translated": "第一阶段检索是一项关键任务，其目的是从大规模的文档集合中检索相关的候选文档。虽然现有的检索模型已经取得了令人印象深刻的性能，但它们大多是在静态数据集上进行研究，忽略了在现实世界中，Web 上的数据随着潜在的分布漂移而不断增长。因此，对静态旧数据进行训练的检索器可能不能很好地适应新数据，并不可避免地产生次优结果。在这项工作中，我们研究了第一阶段检索的终身学习，特别关注于新出现的文档没有标记的情况，因为相关注释的成本很高，可能跟不上数据出现的速度。在这种情况下，我们的目标是开发模型更新有两个目标: (1)有效地适应演化的分布与未标记的新来的数据，(2)避免重新推断所有嵌入的旧文档，以有效地更新索引每次模型更新。我们首先将任务形式化，然后为第一阶段的检索提出一种新的终身学习方法，即 L ^ 2R。L ^ 2R 采用了典型的终身学习记忆机制，包含两个关键组成部分: (1)选择不同的支持否定来进行模型训练和记忆更新，以便有效地进行模型适应; (2)排序对齐目标来确保表示的向后兼容性，以节省索引重建的成本，同时不损害模型的性能。为了进行评估，我们从 LoTTE 和 Multi-CPR 数据集中构建了两个新的基准来模拟真实检索场景中的文档分布漂移。大量实验表明，L ^ 2R 的表现明显优于竞争性的终身学习基线。"
    },
    {
        "title": "Pre-training with Aspect-Content Text Mutual Prediction for Multi-Aspect\n  Dense Retrieval",
        "url": "http://arxiv.org/abs/2308.11474v1",
        "pub_date": "2023-08-22",
        "summary": "Grounded on pre-trained language models (PLMs), dense retrieval has been\nstudied extensively on plain text. In contrast, there has been little research\non retrieving data with multiple aspects using dense models. In the scenarios\nsuch as product search, the aspect information plays an essential role in\nrelevance matching, e.g., category: Electronics, Computers, and Pet Supplies. A\ncommon way of leveraging aspect information for multi-aspect retrieval is to\nintroduce an auxiliary classification objective, i.e., using item contents to\npredict the annotated value IDs of item aspects. However, by learning the value\nembeddings from scratch, this approach may not capture the various semantic\nsimilarities between the values sufficiently. To address this limitation, we\nleverage the aspect information as text strings rather than class IDs during\npre-training so that their semantic similarities can be naturally captured in\nthe PLMs. To facilitate effective retrieval with the aspect strings, we propose\nmutual prediction objectives between the text of the item aspect and content.\nIn this way, our model makes more sufficient use of aspect information than\nconducting undifferentiated masked language modeling (MLM) on the concatenated\ntext of aspects and content. Extensive experiments on two real-world datasets\n(product and mini-program search) show that our approach can outperform\ncompetitive baselines both treating aspect values as classes and conducting the\nsame MLM for aspect and content strings. Code and related dataset will be\navailable at the URL \\footnote{https://github.com/sunxiaojie99/ATTEMPT}.",
        "translated": "基于预训练语言模型(PLM)的密集检索已经在纯文本上得到了广泛的研究。相比之下，使用密集模型检索多方面数据的研究很少。在诸如产品搜索这样的场景中，方面信息在相关性匹配中扮演着重要的角色，例如，类别: 电子产品、计算机和宠物用品。利用方面信息进行多方面检索的一种常见方法是引入一个辅助分类目标，即使用项目内容来预测项目方面的注释值 ID。然而，通过从头学习值嵌入，这种方法可能无法充分捕获值之间的各种语义相似性。为了解决这个限制，我们在预训练期间利用方面信息作为文本字符串而不是类 ID，这样它们的语义相似性可以自然地在 PLM 中捕获。为了方便有效的检索与方面字符串，我们提出了项目方面的文本和内容之间的相互预测目标。通过这种方式，我们的模型比对方面和内容的连接文本进行无区别掩蔽语言建模(MLM)更充分地利用了方面信息。对两个真实世界数据集(产品和小程序搜索)的大量实验表明，我们的方法可以胜过将方面值作为类处理以及对方面和内容字符串执行相同的传销的竞争性基线。代码和相关数据集可在网址脚注{ https://github.com/sunxiaojie99/attempt }查阅。"
    },
    {
        "title": "On the Opportunities and Challenges of Offline Reinforcement Learning\n  for Recommender Systems",
        "url": "http://arxiv.org/abs/2308.11336v1",
        "pub_date": "2023-08-22",
        "summary": "Reinforcement learning serves as a potent tool for modeling dynamic user\ninterests within recommender systems, garnering increasing research attention\nof late. However, a significant drawback persists: its poor data efficiency,\nstemming from its interactive nature. The training of reinforcement\nlearning-based recommender systems demands expensive online interactions to\namass adequate trajectories, essential for agents to learn user preferences.\nThis inefficiency renders reinforcement learning-based recommender systems a\nformidable undertaking, necessitating the exploration of potential solutions.\nRecent strides in offline reinforcement learning present a new perspective.\nOffline reinforcement learning empowers agents to glean insights from offline\ndatasets and deploy learned policies in online settings. Given that recommender\nsystems possess extensive offline datasets, the framework of offline\nreinforcement learning aligns seamlessly. Despite being a burgeoning field,\nworks centered on recommender systems utilizing offline reinforcement learning\nremain limited. This survey aims to introduce and delve into offline\nreinforcement learning within recommender systems, offering an inclusive review\nof existing literature in this domain. Furthermore, we strive to underscore\nprevalent challenges, opportunities, and future pathways, poised to propel\nresearch in this evolving field.",
        "translated": "强化学习是在推荐系统中建立动态用户兴趣模型的有力工具，最近得到了越来越多的研究关注。然而，一个显著的缺点仍然存在: 由于其交互性质，其数据效率较低。基于强化学习的推荐系统的培训需要昂贵的在线交互以积累足够的轨迹，这对于代理学习用户偏好至关重要。这种低效率使得基于强化学习的推荐系统成为一项艰巨的任务，需要探索潜在的解决方案。线下强化学习的最新进展展示了一个新的视角。离线强化学习使代理能够从离线数据集中收集见解，并在线环境中部署学到的策略。由于推荐系统拥有大量的离线数据集，因此离线强化学习框架无缝衔接。尽管这是一个新兴领域，但利用离线强化学习的推荐系统仍然有限。本调查旨在介绍并深入研究推荐系统中的离线强化学习，对这一领域的现有文献进行全面回顾。此外，我们努力强调普遍的挑战，机会和未来的路径，准备推动这个不断发展的领域的研究。"
    },
    {
        "title": "Test Time Embedding Normalization for Popularity Bias Mitigation",
        "url": "http://arxiv.org/abs/2308.11288v1",
        "pub_date": "2023-08-22",
        "summary": "Popularity bias is a widespread problem in the field of recommender systems,\nwhere popular items tend to dominate recommendation results. In this work, we\npropose 'Test Time Embedding Normalization' as a simple yet effective strategy\nfor mitigating popularity bias, which surpasses the performance of the previous\nmitigation approaches by a significant margin. Our approach utilizes the\nnormalized item embedding during the inference stage to control the influence\nof embedding magnitude, which is highly correlated with item popularity.\nThrough extensive experiments, we show that our method combined with the\nsampled softmax loss effectively reduces popularity bias compare to previous\napproaches for bias mitigation. We further investigate the relationship between\nuser and item embeddings and find that the angular similarity between\nembeddings distinguishes preferable and non-preferable items regardless of\ntheir popularity. The analysis explains the mechanism behind the success of our\napproach in eliminating the impact of popularity bias. Our code is available at\nhttps://github.com/ml-postech/TTEN.",
        "translated": "在推荐系统领域，流行度偏差是一个普遍存在的问题，在这个领域中，流行项目往往占据推荐结果的主导地位。在这项工作中，我们提出了“测试时间嵌入规范化”作为一个简单而有效的策略，以减轻流行偏差，这超过了以前的缓解方法的性能显着差距。该方法在推理阶段利用归一化项目嵌入来控制项目嵌入量的影响，项目嵌入量与项目知名度高度相关。通过大量的实验，我们发现与以往的偏差抑制方法相比，我们的方法结合采样软最大损失有效地降低了流行偏差。我们进一步研究了用户与项目嵌入之间的关系，发现无论项目受欢迎程度如何，用户与项目嵌入之间的角度相似度都能区分出优选项目和非优选项目。该分析解释了我们的方法在消除流行偏见影响方面取得成功背后的机制。我们的代码可以在 https://github.com/ml-postech/tten 找到。"
    },
    {
        "title": "StoryBench: A Multifaceted Benchmark for Continuous Story Visualization",
        "url": "http://arxiv.org/abs/2308.11606v1",
        "pub_date": "2023-08-22",
        "summary": "Generating video stories from text prompts is a complex task. In addition to\nhaving high visual quality, videos need to realistically adhere to a sequence\nof text prompts whilst being consistent throughout the frames. Creating a\nbenchmark for video generation requires data annotated over time, which\ncontrasts with the single caption used often in video datasets. To fill this\ngap, we collect comprehensive human annotations on three existing datasets, and\nintroduce StoryBench: a new, challenging multi-task benchmark to reliably\nevaluate forthcoming text-to-video models. Our benchmark includes three video\ngeneration tasks of increasing difficulty: action execution, where the next\naction must be generated starting from a conditioning video; story\ncontinuation, where a sequence of actions must be executed starting from a\nconditioning video; and story generation, where a video must be generated from\nonly text prompts. We evaluate small yet strong text-to-video baselines, and\nshow the benefits of training on story-like data algorithmically generated from\nexisting video captions. Finally, we establish guidelines for human evaluation\nof video stories, and reaffirm the need of better automatic metrics for video\ngeneration. StoryBench aims at encouraging future research efforts in this\nexciting new area.",
        "translated": "从文本提示生成视频故事是一项复杂的任务。除了具有高视觉质量，视频需要现实地坚持一系列的文本提示，同时在整个框架一致。为视频生成创建基准需要随着时间的推移对数据进行注释，这与视频数据集中经常使用的单个标题形成了对比。为了填补这个空白，我们在三个现有数据集上收集了全面的人工注释，并引入 StoryBench: 一个新的、具有挑战性的多任务基准，可以可靠地评估即将推出的文本到视频模型。我们的基准测试包括三个越来越难的视频生成任务: 动作执行，其中下一个动作必须从一个条件视频开始生成; 故事延续，其中一系列动作必须从一个条件视频开始执行; 以及故事生成，其中一个视频必须只由文本提示生成。我们评估了小而强的文本到视频基线，并展示了对现有视频标题生成的类故事数据进行训练的好处。最后，我们建立了视频故事的人类评价指南，并重申了更好的视频生成自动度量的需要。StoryBench 旨在鼓励未来在这个令人兴奋的新领域的研究工作。"
    },
    {
        "title": "Tryage: Real-time, intelligent Routing of User Prompts to Large Language\n  Model",
        "url": "http://arxiv.org/abs/2308.11601v1",
        "pub_date": "2023-08-22",
        "summary": "The introduction of the transformer architecture and the self-attention\nmechanism has led to an explosive production of language models trained on\nspecific downstream tasks and data domains. With over 200, 000 models in the\nHugging Face ecosystem, users grapple with selecting and optimizing models to\nsuit multifaceted workflows and data domains while addressing computational,\nsecurity, and recency concerns. There is an urgent need for machine learning\nframeworks that can eliminate the burden of model selection and customization\nand unleash the incredible power of the vast emerging model library for end\nusers. Here, we propose a context-aware routing system, Tryage, that leverages\na language model router for optimal selection of expert models from a model\nlibrary based on analysis of individual input prompts. Inspired by the thalamic\nrouter in the brain, Tryage employs a perceptive router to predict down-stream\nmodel performance on prompts and, then, makes a routing decision using an\nobjective function that integrates performance predictions with user goals and\nconstraints that are incorporated through flags (e.g., model size, model\nrecency). Tryage allows users to explore a Pareto front and automatically\ntrade-off between task accuracy and secondary goals including minimization of\nmodel size, recency, security, verbosity, and readability. Across heterogeneous\ndata sets that include code, text, clinical data, and patents, the Tryage\nframework surpasses Gorilla and GPT3.5 turbo in dynamic model selection\nidentifying the optimal model with an accuracy of 50.9% , compared to 23.6% by\nGPT 3.5 Turbo and 10.8% by Gorilla. Conceptually, Tryage demonstrates how\nrouting models can be applied to program and control the behavior of\nmulti-model LLM systems to maximize efficient use of the expanding and evolving\nlanguage model ecosystem.",
        "translated": "由于采用了变压器结构和自我关注机制，爆炸性地产生了针对具体下游任务和数据领域的语言模型。拥抱脸生态系统中有超过200,000个模型，用户需要努力选择和优化模型，以适应多方面的工作流和数据领域，同时解决计算、安全和近期问题。机器学习框架迫切需要能够消除模型选择和定制的负担，并为终端用户释放出巨大的新兴模型库的不可思议的力量。在这里，我们提出了一个上下文感知的路由系统，Tryage，它利用一个语言模型路由器从一个模型库中优化选择专家模型，这个模型库基于对单个输入提示的分析。受到大脑中丘脑路由器的启发，Tryage 使用了一个感知路由器来预测下游模型在提示下的性能，然后，使用一个目标函数来做出路由决策，这个目标函数将性能预测与通过标志(例如，模型大小，模型近期)整合的用户目标和约束相结合。Tryage 允许用户探索 Pareto 前端，并自动在任务准确性和次要目标(包括最小化模型大小、最新性、安全性、冗长性和可读性)之间进行权衡。在包括代码，文本，临床数据和专利在内的异构数据集中，Tryage 框架在动态模型选择方面超过了 Gorilla 和 GPT3.5 Turbo，识别最佳模型的准确率为50.9% ，而 GPT 3.5 Turbo 为23.6% ，Gorilla 为10.8% 。从概念上讲，Tryage 演示了如何应用路由模型来编程和控制多模型 LLM 系统的行为，以最大限度地有效利用不断扩展和演化的语言模型生态系统。"
    },
    {
        "title": "SeamlessM4T-Massively Multilingual &amp; Multimodal Machine Translation",
        "url": "http://arxiv.org/abs/2308.11596v1",
        "pub_date": "2023-08-22",
        "summary": "What does it take to create the Babel Fish, a tool that can help individuals\ntranslate speech between any two languages? While recent breakthroughs in\ntext-based models have pushed machine translation coverage beyond 200\nlanguages, unified speech-to-speech translation models have yet to achieve\nsimilar strides. More specifically, conventional speech-to-speech translation\nsystems rely on cascaded systems that perform translation progressively,\nputting high-performing unified systems out of reach. To address these gaps, we\nintroduce SeamlessM4T, a single model that supports speech-to-speech\ntranslation, speech-to-text translation, text-to-speech translation,\ntext-to-text translation, and automatic speech recognition for up to 100\nlanguages. To build this, we used 1 million hours of open speech audio data to\nlearn self-supervised speech representations with w2v-BERT 2.0. Subsequently,\nwe created a multimodal corpus of automatically aligned speech translations.\nFiltered and combined with human-labeled and pseudo-labeled data, we developed\nthe first multilingual system capable of translating from and into English for\nboth speech and text. On FLEURS, SeamlessM4T sets a new standard for\ntranslations into multiple target languages, achieving an improvement of 20%\nBLEU over the previous SOTA in direct speech-to-text translation. Compared to\nstrong cascaded models, SeamlessM4T improves the quality of into-English\ntranslation by 1.3 BLEU points in speech-to-text and by 2.6 ASR-BLEU points in\nspeech-to-speech. Tested for robustness, our system performs better against\nbackground noises and speaker variations in speech-to-text tasks compared to\nthe current SOTA model. Critically, we evaluated SeamlessM4T on gender bias and\nadded toxicity to assess translation safety. Finally, all contributions in this\nwork are open-sourced at this https\nhttps://github.com/facebookresearch/seamless_communication.",
        "translated": "怎样才能创建 Babel Fish，一个可以帮助个人在任何两种语言之间翻译语言的工具？尽管基于文本的翻译模型最近取得了突破，使机器翻译覆盖范围超过了200种语言，但是统一的语音到语音翻译模型还没有取得类似的进展。更具体地说，传统的语音到语音翻译系统依赖于逐步执行翻译的级联系统，这使得高性能的统一系统无法实现。为了解决这些差距，我们引入了 Seamless M4T，这是一个单一模型，支持语音到语音翻译、语音到文本翻译、语音到语音翻译、语音到文本翻译以及多达100种语言的自动语音识别。为了构建这个系统，我们使用了100万小时的开放语音音频数据来学习 w2v-BERT 2.0的自我监督语音表示。随后，我们创建了一个自动对齐语音翻译的多模态语料库。经过过滤并结合人类标记和伪标记数据，我们开发了第一个能够将语音和文本从英语翻译成英语的多语言系统。在 FLEURS，Seamless m4T 为翻译成多种目标语言设定了新的标准，在直接语音到文本的翻译中，比之前的 SOTA 提高了20% 的 BLEU。与强级联模型相比，Seamless M4T 在语音到文本的转换中提高了1.3个 BLEU 点，在语音到语音的转换中提高了2.6个 ASR-BLEU 点。通过鲁棒性测试，与现有的 SOTA 模型相比，我们的系统在语音到文本任务中对背景噪声和说话人变化有更好的抵抗能力。重要的是，我们评估了 Seamless M4T 的性别偏见和附加毒性，以评估翻译安全性。最后，这项工作的所有贡献都在这个 https  https://github.com/facebookresearch/seamless_communication 开源。"
    },
    {
        "title": "Using ChatGPT as a CAT tool in Easy Language translation",
        "url": "http://arxiv.org/abs/2308.11563v1",
        "pub_date": "2023-08-22",
        "summary": "This study sets out to investigate the feasibility of using ChatGPT to\ntranslate citizen-oriented administrative texts into German Easy Language, a\nsimplified, controlled language variety that is adapted to the needs of people\nwith reading impairments. We use ChatGPT to translate selected texts from\nwebsites of German public authorities using two strategies, i.e. linguistic and\nholistic. We analyse the quality of the generated texts based on different\ncriteria, such as correctness, readability, and syntactic complexity. The\nresults indicated that the generated texts are easier than the standard texts,\nbut that they still do not fully meet the established Easy Language standards.\nAdditionally, the content is not always rendered correctly.",
        "translated": "本研究旨在探讨使用 ChatGPT 将面向公民的行政文本翻译成德语简易语言的可行性。德语简易语言是一种简化的、可控制的语言变体，适用于有阅读障碍者的需求。我们使用 ChatGPT 翻译从德国公共当局网站选择的文本，使用两种策略，即语言和整体。我们根据不同的标准，如正确性、可读性和句法复杂性，分析生成的文本的质量。结果表明，生成的文本比标准文本容易，但仍不完全符合既定的易语言标准。此外，内容并不总是呈现正确。"
    },
    {
        "title": "BELB: a Biomedical Entity Linking Benchmark",
        "url": "http://arxiv.org/abs/2308.11537v1",
        "pub_date": "2023-08-22",
        "summary": "Biomedical entity linking (BEL) is the task of grounding entity mentions to a\nknowledge base. It plays a vital role in information extraction pipelines for\nthe life sciences literature. We review recent work in the field and find that,\nas the task is absent from existing benchmarks for biomedical text mining,\ndifferent studies adopt different experimental setups making comparisons based\non published numbers problematic. Furthermore, neural systems are tested\nprimarily on instances linked to the broad coverage knowledge base UMLS,\nleaving their performance to more specialized ones, e.g. genes or variants,\nunderstudied. We therefore developed BELB, a Biomedical Entity Linking\nBenchmark, providing access in a unified format to 11 corpora linked to 7\nknowledge bases and spanning six entity types: gene, disease, chemical,\nspecies, cell line and variant. BELB greatly reduces preprocessing overhead in\ntesting BEL systems on multiple corpora offering a standardized testbed for\nreproducible experiments. Using BELB we perform an extensive evaluation of six\nrule-based entity-specific systems and three recent neural approaches\nleveraging pre-trained language models. Our results reveal a mixed picture\nshowing that neural approaches fail to perform consistently across entity\ntypes, highlighting the need of further studies towards entity-agnostic models.",
        "translated": "生物医学实体连接(BEL)是基础实体向知识库提交的任务。它在生命科学文献的信息抽取管道中起着至关重要的作用。我们回顾了该领域最近的工作，发现由于现有的生物医学文本挖掘基准中没有这项任务，不同的研究采用了不同的实验设置，使得基于已发表数据的比较存在问题。此外，神经系统主要在与广泛覆盖的知识库 UMLS 相关的实例上进行测试，将它们的性能留给更专业的实例，例如基因或变异，以备不时之需。因此，我们开发了 BELB，一个生物医学实体连接基准，以统一的格式提供与7个知识库连接的11个语料库的访问，跨越6个实体类型: 基因，疾病，化学，物种，细胞系和变体。BELB 大大降低了在多语料库上测试 BEL 系统的预处理开销，为可重复性实验提供了标准化的测试平台。使用 BELB，我们对六个基于规则的实体特定系统和三种利用预训练语言模型的最新神经方法进行了广泛的评估。我们的研究结果揭示了一个混合的图像，显示神经方法不能在实体类型之间一致地执行，突出了对实体无关模型的进一步研究的需要。"
    },
    {
        "title": "Empowering Refugee Claimants and their Lawyers: Using Machine Learning\n  to Examine Decision-Making in Refugee Law",
        "url": "http://arxiv.org/abs/2308.11531v1",
        "pub_date": "2023-08-22",
        "summary": "Our project aims at helping and supporting stakeholders in refugee status\nadjudications, such as lawyers, judges, governing bodies, and claimants, in\norder to make better decisions through data-driven intelligence and increase\nthe understanding and transparency of the refugee application process for all\ninvolved parties. This PhD project has two primary objectives: (1) to retrieve\npast cases, and (2) to analyze legal decision-making processes on a dataset of\nCanadian cases. In this paper, we present the current state of our work, which\nincludes a completed experiment on part (1) and ongoing efforts related to part\n(2). We believe that NLP-based solutions are well-suited to address these\nchallenges, and we investigate the feasibility of automating all steps\ninvolved. In addition, we introduce a novel benchmark for future NLP research\nin refugee law. Our methodology aims to be inclusive to all end-users and\nstakeholders, with expected benefits including reduced time-to-decision, fairer\nand more transparent outcomes, and improved decision quality.",
        "translated": "我们的项目旨在帮助和支持律师、法官、理事机构和申请人等难民地位裁决利益攸关方，以便通过数据驱动的情报作出更好的决定，并提高所有有关各方对难民申请程序的理解和透明度。这个博士项目有两个主要目标: (1)检索过去的案件，(2)分析加拿大案件数据集的法律决策过程。在本文中，我们介绍了我们的工作现状，其中包括一个完整的第(1)部分的实验和正在进行的努力相关的第(2)部分。我们相信基于 NLP 的解决方案非常适合解决这些挑战，并且我们研究了将所有相关步骤自动化的可行性。此外，我们还介绍了一个新的基准，为未来难民法的自然语言处理研究。我们的方法旨在包容所有最终用户和利益相关者，预期的好处包括缩短决策时间，更公平和更透明的结果，以及提高决策质量。"
    },
    {
        "title": "Unsupervised Prototype Adapter for Vision-Language Models",
        "url": "http://arxiv.org/abs/2308.11507v1",
        "pub_date": "2023-08-22",
        "summary": "Recently, large-scale pre-trained vision-language models (e.g. CLIP and\nALIGN) have demonstrated remarkable effectiveness in acquiring transferable\nvisual representations. To leverage the valuable knowledge encoded within these\nmodels for downstream tasks, several fine-tuning approaches, including prompt\ntuning methods and adapter-based methods, have been developed to adapt\nvision-language models effectively with supervision. However, these methods\nrely on the availability of annotated samples, which can be labor-intensive and\ntime-consuming to acquire, thus limiting scalability. To address this issue, in\nthis work, we design an unsupervised fine-tuning approach for vision-language\nmodels called Unsupervised Prototype Adapter (UP-Adapter). Specifically, for\nthe unannotated target datasets, we leverage the text-image aligning capability\nof CLIP to automatically select the most confident samples for each class.\nUtilizing these selected samples, we generate class prototypes, which serve as\nthe initialization for the learnable prototype model. After fine-tuning, the\nprototype model prediction is combined with the original CLIP's prediction by a\nresidual connection to perform downstream recognition tasks. Our extensive\nexperimental results on image recognition and domain generalization show that\nthe proposed unsupervised method outperforms 8-shot CoOp, 8-shot Tip-Adapter,\nand also the state-of-the-art UPL method by large margins.",
        "translated": "最近，大规模的预训练视觉语言模型(例如 CLIP 和 ALIGN)在获取可转移视觉表征方面显示出显著的效果。为了将这些模型中编码的有价值的知识用于下游任务，已经开发了几种微调方法，包括快速调优方法和基于适配器的方法，以便在监督下有效地调整可视化语言模型。然而，这些方法依赖于注释样本的可用性，这可能是劳动密集型和耗时获取，从而限制了可伸缩性。为了解决这个问题，在这项工作中，我们设计了一个视觉语言模型的无监督微调方法称为无监督原型适配器(UP-Adapter)。具体来说，对于未注释的目标数据集，我们利用 CLIP 的文本-图像对齐功能为每个类自动选择最有信心的样本。利用这些样本，我们生成了类原型，作为可学习原型模型的初始化。经过微调，原型模型预测与原始 CLIP 预测通过残差连接相结合，执行下游识别任务。我们在图像识别和域泛化方面的大量实验结果表明，该方法比8镜头 CoOp、8镜头 Tip-Adapter 以及最先进的 UPL 方法具有更大的优势。"
    },
    {
        "title": "Can Authorship Representation Learning Capture Stylistic Features?",
        "url": "http://arxiv.org/abs/2308.11490v1",
        "pub_date": "2023-08-22",
        "summary": "Automatically disentangling an author's style from the content of their\nwriting is a longstanding and possibly insurmountable problem in computational\nlinguistics. At the same time, the availability of large text corpora furnished\nwith author labels has recently enabled learning authorship representations in\na purely data-driven manner for authorship attribution, a task that ostensibly\ndepends to a greater extent on encoding writing style than encoding content.\nHowever, success on this surrogate task does not ensure that such\nrepresentations capture writing style since authorship could also be correlated\nwith other latent variables, such as topic. In an effort to better understand\nthe nature of the information these representations convey, and specifically to\nvalidate the hypothesis that they chiefly encode writing style, we\nsystematically probe these representations through a series of targeted\nexperiments. The results of these experiments suggest that representations\nlearned for the surrogate authorship prediction task are indeed sensitive to\nwriting style. As a consequence, authorship representations may be expected to\nbe robust to certain kinds of data shift, such as topic drift over time.\nAdditionally, our findings may open the door to downstream applications that\nrequire stylistic representations, such as style transfer.",
        "translated": "自动将作者的风格与其作品的内容区分开来是一个长期存在的问题，在计算语言学中可能是无法克服的。与此同时，带有作者标签的大型文本语料库的出现，使得最近能够以纯粹数据驱动的方式学习作者身份表示，以获得作者身份归属，这项任务表面上更大程度上取决于编码写作风格，而不是编码内容。但是，这个代理任务的成功并不能确保这种表示捕获写作风格，因为作者身份也可能与其他潜在变量(如主题)相关联。为了更好地理解这些表征所传达的信息的本质，特别是验证它们主要编码写作风格的假设，我们通过一系列有针对性的实验系统地探索了这些表征。这些实验结果表明，替代作者身份预测任务所学到的表征确实对写作风格敏感。因此，可以期望作者身份表示对某些类型的数据转移(如主题随时间变化)具有鲁棒性。此外，我们的研究结果可能为需要风格表示的下游应用程序打开大门，例如风格转移。"
    },
    {
        "title": "Large Language Models Sensitivity to The Order of Options in\n  Multiple-Choice Questions",
        "url": "http://arxiv.org/abs/2308.11483v1",
        "pub_date": "2023-08-22",
        "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nvarious NLP tasks. However, previous works have shown these models are\nsensitive towards prompt wording, and few-shot demonstrations and their order,\nposing challenges to fair assessment of these models. As these models become\nmore powerful, it becomes imperative to understand and address these\nlimitations. In this paper, we focus on LLMs robustness on the task of\nmultiple-choice questions -- commonly adopted task to study reasoning and\nfact-retrieving capability of LLMs. Investigating the sensitivity of LLMs\ntowards the order of options in multiple-choice questions, we demonstrate a\nconsiderable performance gap of approximately 13% to 75% in LLMs on different\nbenchmarks, when answer options are reordered, even when using demonstrations\nin a few-shot setting. Through a detailed analysis, we conjecture that this\nsensitivity arises when LLMs are uncertain about the prediction between the\ntop-2/3 choices, and specific options placements may favor certain prediction\nbetween those top choices depending on the question caused by positional bias.\nWe also identify patterns in top-2 choices that amplify or mitigate the model's\nbias toward option placement. We found that for amplifying bias, the optimal\nstrategy involves positioning the top two choices as the first and last\noptions. Conversely, to mitigate bias, we recommend placing these choices among\nthe adjacent options. To validate our conjecture, we conduct various\nexperiments and adopt two approaches to calibrate LLMs' predictions, leading to\nup to 8 percentage points improvement across different models and benchmarks.",
        "translated": "大语言模型(LLM)已经在各种 NLP 任务中展示了非凡的能力。然而，以往的工作表明，这些模型是敏感的迅速措辞，并很少拍摄示范及其秩序，构成了挑战，公平评估这些模型。随着这些模型变得越来越强大，理解和解决这些局限性就变得势在必行。本文重点研究了 LLM 对多项选择题任务的鲁棒性问题——常用的研究 LLM 推理和事实检索能力的任务。研究了 LLM 对多项选择题中选项顺序的敏感性，我们证明了在不同基准上 LLM 的相当大的性能差距约为13% 至75% ，当回答选项被重新排序时，即使在几个镜头的情况下使用演示。通过详细的分析，我们推测，当 LLM 对前2/3选择之间的预测不确定时，这种敏感性就会出现，并且根据位置偏差引起的问题，具体的选择放置可能有利于这些顶级选择之间的某些预测。我们还确定了在前2个选择中放大或减轻模型对期权配置的偏见的模式。我们发现，为了放大偏差，最优策略包括将前两个选择定位为第一个和最后一个选择。相反，为了减轻偏倚，我们建议将这些选择放在相邻的选项中。为了验证我们的猜想，我们进行了各种实验，并采用了两种方法来校准 LLM 的预测，在不同的模型和基准测试中，最多可以提高8个百分点。"
    },
    {
        "title": "SONAR: Sentence-Level Multimodal and Language-Agnostic Representations",
        "url": "http://arxiv.org/abs/2308.11466v2",
        "pub_date": "2023-08-22",
        "summary": "We introduce SONAR, a new multilingual and multimodal fixed-size sentence\nembedding space. Our single text encoder, covering 200 languages, substantially\noutperforms existing sentence embeddings such as LASER3 and LabSE on the xsim\nand xsim++ multilingual similarity search tasks. Speech segments can be\nembedded in the same SONAR embedding space using language-specific speech\nencoders trained in a teacher-student setting on speech transcription data. Our\nencoders outperform existing speech encoders on similarity search tasks. We\nalso provide a text decoder for 200 languages, which allows us to perform\ntext-to-text and speech-to-text machine translation, including for zero-shot\nlanguage and modality combinations. Our text-to-text results are competitive\ncompared to the state-of-the-art NLLB~1B model, despite the fixed-size\nbottleneck representation. Our zero-shot speech-to-text translation results\ncompare favorably with strong supervised baselines such as Whisper.",
        "translated": "本文介绍了一种新的多语种多通道固定大小句子嵌入空间 SONAR。我们的单一文本编码器，涵盖了200种语言，在 xsim 和 xsim + + 多语言最近邻搜索任务上大大优于现有的句子嵌入，如 LASER3和 LabSE。语音片段可以嵌入到相同的声纳嵌入空间使用特定语言的语音编码器训练师生设置的语音转录数据。我们的编码器在最近邻搜索任务上比现有的语音编码器表现更好。我们还提供了一个200种语言的文本解码器，它允许我们执行文本到文本和语音到文本的机器翻译，包括零拍语言和情态组合。与最先进的 NLLB ~ 1B 模型相比，我们的文本到文本结果是有竞争力的，尽管有固定大小的瓶颈表示。我们的零拍摄语音到文本的翻译结果比较良好的强监督基线，如低语。"
    },
    {
        "title": "Learning from Negative User Feedback and Measuring Responsiveness for\n  Sequential Recommenders",
        "url": "http://arxiv.org/abs/2308.12256v1",
        "pub_date": "2023-08-23",
        "summary": "Sequential recommenders have been widely used in industry due to their\nstrength in modeling user preferences. While these models excel at learning a\nuser's positive interests, less attention has been paid to learning from\nnegative user feedback. Negative user feedback is an important lever of user\ncontrol, and comes with an expectation that recommenders should respond quickly\nand reduce similar recommendations to the user. However, negative feedback\nsignals are often ignored in the training objective of sequential retrieval\nmodels, which primarily aim at predicting positive user interactions. In this\nwork, we incorporate explicit and implicit negative user feedback into the\ntraining objective of sequential recommenders in the retrieval stage using a\n\"not-to-recommend\" loss function that optimizes for the log-likelihood of not\nrecommending items with negative feedback. We demonstrate the effectiveness of\nthis approach using live experiments on a large-scale industrial recommender\nsystem. Furthermore, we address a challenge in measuring recommender\nresponsiveness to negative feedback by developing a counterfactual simulation\nframework to compare recommender responses between different user actions,\nshowing improved responsiveness from the modeling change.",
        "translated": "由于序列推荐器在建模用户偏好方面的优势，它在工业中得到了广泛的应用。虽然这些模型擅长于学习用户的积极兴趣，但很少注意从消极的用户反馈中学习。负面的用户反馈是用户控制的一个重要杠杆，并且伴随着一个期望，即推荐应该快速响应并减少对用户的类似推荐。然而，在序贯检索模型的训练目标中，负反馈信号往往被忽略，而序贯检索模型的训练目标主要是预测正向用户交互。在这项工作中，我们将显性和隐性的负面用户反馈纳入顺序推荐者在检索阶段的训练目标中，使用一个“不推荐”的损失函数，该函数优化了不推荐负面反馈项目的对数可能性。我们通过在大规模工业推荐系统上的实验证明了这种方法的有效性。此外，我们通过开发一个反事实模拟框架来比较不同用户行为之间的推荐响应，从而解决了测量推荐响应负面反馈的挑战，显示了来自建模更改的更好响应。"
    },
    {
        "title": "LLMRec: Benchmarking Large Language Models on Recommendation Task",
        "url": "http://arxiv.org/abs/2308.12241v1",
        "pub_date": "2023-08-23",
        "summary": "Recently, the fast development of Large Language Models (LLMs) such as\nChatGPT has significantly advanced NLP tasks by enhancing the capabilities of\nconversational models. However, the application of LLMs in the recommendation\ndomain has not been thoroughly investigated. To bridge this gap, we propose\nLLMRec, a LLM-based recommender system designed for benchmarking LLMs on\nvarious recommendation tasks. Specifically, we benchmark several popular\noff-the-shelf LLMs, such as ChatGPT, LLaMA, ChatGLM, on five recommendation\ntasks, including rating prediction, sequential recommendation, direct\nrecommendation, explanation generation, and review summarization. Furthermore,\nwe investigate the effectiveness of supervised finetuning to improve LLMs'\ninstruction compliance ability. The benchmark results indicate that LLMs\ndisplayed only moderate proficiency in accuracy-based tasks such as sequential\nand direct recommendation. However, they demonstrated comparable performance to\nstate-of-the-art methods in explainability-based tasks. We also conduct\nqualitative evaluations to further evaluate the quality of contents generated\nby different models, and the results show that LLMs can truly understand the\nprovided information and generate clearer and more reasonable results. We\naspire that this benchmark will serve as an inspiration for researchers to\ndelve deeper into the potential of LLMs in enhancing recommendation\nperformance. Our codes, processed data and benchmark results are available at\nhttps://github.com/williamliujl/LLMRec.",
        "translated": "近年来，大型语言模型(LLM)的快速发展，如 ChatGPT，通过增强会话模型的能力，极大地提高了自然语言处理任务的性能。然而，LLM 在推荐领域中的应用还没有得到充分的研究。为了弥补这一差距，我们提出了 LLmrec，这是一个基于 LLM 的推荐系统，旨在对不同推荐任务的 LLM 进行基准测试。具体来说，我们对几个流行的现成 LLM (如 ChatGPT、 LLaMA、 ChatGLM)进行了基准测试，这些 LLM 涉及5个推荐任务，包括评分预测、顺序推荐、直接推荐、解释生成和评论摘要。此外，我们还研究了监督微调对提高 LLM 指令遵从能力的有效性。基准测试结果表明，LLM 在基于准确性的任务(如顺序推荐和直接推荐)中只表现出中等的熟练程度。然而，在基于可解释性的任务中，他们表现出了与最先进的方法相当的性能。我们还进行了定性评价，以进一步评价由不同模型生成的内容的质量，结果表明，LLM 可以真正理解所提供的信息，并产生更清晰和更合理的结果。我们希望这个基准能够激励研究人员更深入地研究 LLM 在提高推荐性能方面的潜力。我们的代码、处理过的数据和基准测试结果可在 https://github.com/williamliujl/llmrec 查阅。"
    },
    {
        "title": "Counterfactual Graph Augmentation for Consumer Unfairness Mitigation in\n  Recommender Systems",
        "url": "http://arxiv.org/abs/2308.12083v1",
        "pub_date": "2023-08-23",
        "summary": "In recommendation literature, explainability and fairness are becoming two\nprominent perspectives to consider. However, prior works have mostly addressed\nthem separately, for instance by explaining to consumers why a certain item was\nrecommended or mitigating disparate impacts in recommendation utility. None of\nthem has leveraged explainability techniques to inform unfairness mitigation.\nIn this paper, we propose an approach that relies on counterfactual\nexplanations to augment the set of user-item interactions, such that using them\nwhile inferring recommendations leads to fairer outcomes. Modeling user-item\ninteractions as a bipartite graph, our approach augments the latter by\nidentifying new user-item edges that not only can explain the original\nunfairness by design, but can also mitigate it. Experiments on two public data\nsets show that our approach effectively leads to a better trade-off between\nfairness and recommendation utility compared with state-of-the-art mitigation\nprocedures. We further analyze the characteristics of added edges to highlight\nkey unfairness patterns. Source code available at\nhttps://github.com/jackmedda/RS-BGExplainer/tree/cikm2023.",
        "translated": "在推荐文献中，可解释性和公平性正成为两个需要考虑的重要方面。然而，以前的工作大多是单独处理这些问题，例如向消费者解释为什么要推荐某个项目，或者减轻推荐实用程序中的不同影响。它们都没有利用可解释性技术来缓解不公平性。在本文中，我们提出了一种方法，依赖于反事实的解释，以增加用户项目的交互集，使用他们，而推断建议导致更公平的结果。将用户-项目交互建模为二分图，我们的方法通过识别新的用户-项目边缘来扩展后者，这些边缘不仅可以通过设计来解释原始的不公平，而且还可以减轻它。在两个公共数据集上的实验表明，与最先进的缓解过程相比，我们的方法有效地在公平性和推荐效用之间取得了更好的平衡。我们进一步分析了附加边缘的特征，以突出关键的不公平模式。源代码可在 https://github.com/jackmedda/rs-bgexplainer/tree/cikm2023下载。"
    },
    {
        "title": "Hybrid Retrieval and Multi-stage Text Ranking Solution at TREC 2022 Deep\n  Learning Track",
        "url": "http://arxiv.org/abs/2308.12039v1",
        "pub_date": "2023-08-23",
        "summary": "Large-scale text retrieval technology has been widely used in various\npractical business scenarios. This paper presents our systems for the TREC 2022\nDeep Learning Track. We explain the hybrid text retrieval and multi-stage text\nranking method adopted in our solution. The retrieval stage combined the two\nstructures of traditional sparse retrieval and neural dense retrieval. In the\nranking stage, in addition to the full interaction-based ranking model built on\nlarge pre-trained language model, we also proposes a lightweight sub-ranking\nmodule to further enhance the final text ranking performance. Evaluation\nresults demonstrate the effectiveness of our proposed approach. Our models\nachieve the 1st and 4th rank on the test set of passage ranking and document\nranking respectively.",
        "translated": "大规模文本检索技术已广泛应用于各种实际业务场景。本文介绍了我们的 TREC 2022深度学习跟踪系统。阐述了该方案中采用的混合文本检索和多阶段文本排序方法。检索阶段结合了传统的稀疏检索和神经密集检索两种结构。在排序阶段，除了建立在大型预训练语言模型基础上的基于交互的排序模型外，还提出了一个轻量级的子排序模块，进一步提高了最终的文本排序性能。评估结果证明了我们提出的方法的有效性。我们的模型在文章排序测试集和文档排序测试集上分别排名第一和第四。"
    },
    {
        "title": "LKPNR: LLM and KG for Personalized News Recommendation Framework",
        "url": "http://arxiv.org/abs/2308.12028v1",
        "pub_date": "2023-08-23",
        "summary": "Accurately recommending candidate news articles to users is a basic challenge\nfaced by personalized news recommendation systems. Traditional methods are\nusually difficult to grasp the complex semantic information in news texts,\nresulting in unsatisfactory recommendation results. Besides, these traditional\nmethods are more friendly to active users with rich historical behaviors.\nHowever, they can not effectively solve the \"long tail problem\" of inactive\nusers. To address these issues, this research presents a novel general\nframework that combines Large Language Models (LLM) and Knowledge Graphs (KG)\ninto semantic representations of traditional methods. In order to improve\nsemantic understanding in complex news texts, we use LLMs' powerful text\nunderstanding ability to generate news representations containing rich semantic\ninformation. In addition, our method combines the information about news\nentities and mines high-order structural information through multiple hops in\nKG, thus alleviating the challenge of long tail distribution. Experimental\nresults demonstrate that compared with various traditional models, the\nframework significantly improves the recommendation effect. The successful\nintegration of LLM and KG in our framework has established a feasible path for\nachieving more accurate personalized recommendations in the news field. Our\ncode is available at https://github.com/Xuan-ZW/LKPNR.",
        "translated": "准确地向用户推荐候选新闻是个性化新闻推荐系统面临的一个基本挑战。传统方法通常难以掌握新闻文本中复杂的语义信息，导致推荐结果不理想。此外，这些传统方法对具有丰富历史行为的活动用户更加友好。但是，它们不能有效地解决非活动用户的“长尾问题”。为了解决这些问题，本研究提出了一个新的通用框架，将大语言模型(LLM)和知识图(KG)结合到传统方法的语义表示中。为了提高复杂新闻文本的语义理解能力，我们利用 LLM 强大的文本理解能力来生成包含丰富语义信息的新闻表示。此外，我们的方法结合了新闻实体的信息，通过 KG 中的多跳挖掘出高阶结构信息，从而缓解了长尾分布的挑战。实验结果表明，与各种传统模型相比，该框架显著提高了推荐效果。LLM 和 KG 在我们的框架中的成功整合为在新闻领域实现更准确的个性化推荐确立了一条可行的途径。我们的代码可以在 https://github.com/xuan-zw/lkpnr 找到。"
    },
    {
        "title": "D4: Improving LLM Pretraining via Document De-Duplication and\n  Diversification",
        "url": "http://arxiv.org/abs/2308.12284v1",
        "pub_date": "2023-08-23",
        "summary": "Over recent years, an increasing amount of compute and data has been poured\ninto training large language models (LLMs), usually by doing one-pass learning\non as many tokens as possible randomly selected from large-scale web corpora.\nWhile training on ever-larger portions of the internet leads to consistent\nperformance improvements, the size of these improvements diminishes with scale,\nand there has been little work exploring the effect of data selection on\npre-training and downstream performance beyond simple de-duplication methods\nsuch as MinHash. Here, we show that careful data selection (on top of\nde-duplicated data) via pre-trained model embeddings can speed up training (20%\nefficiency gains) and improves average downstream accuracy on 16 NLP tasks (up\nto 2%) at the 6.7B model scale. Furthermore, we show that repeating data\nintelligently consistently outperforms baseline training (while repeating\nrandom data performs worse than baseline training). Our results indicate that\nclever data selection can significantly improve LLM pre-training, calls into\nquestion the common practice of training for a single epoch on as much data as\npossible, and demonstrates a path to keep improving our models past the limits\nof randomly sampling web data.",
        "translated": "近年来，越来越多的计算机和数据被投入到训练大型语言模型(LLM)中，通常是通过对从大规模 Web 语料库中随机选取的尽可能多的令牌进行一次性学习。虽然在互联网上越来越大的部分进行培训导致持续的性能改善，但这些改善的规模随着规模的缩小而减小，除了简单的去重复方法如 MinHash 之外，很少有工作探索数据选择对培训前和下游性能的影响。在这里，我们表明，通过预先训练的模型嵌入，仔细的数据选择(在去重复数据之上)可以加速训练(20% 的效率增益) ，并在6.7 B 模型尺度下提高16个 NLP 任务(高达2%)的平均下游准确性。此外，我们表明，重复数据智能一贯优于基线训练(而重复随机数据执行差于基线训练)。我们的研究结果表明，聪明的数据选择可以显着改善 LLM 预训练，对尽可能多的数据进行单个时代的训练的常见做法提出了质疑，并且展示了一种途径来保持改进我们的模型超过随机采样网络数据的限制。"
    },
    {
        "title": "Simple is Better and Large is Not Enough: Towards Ensembling of\n  Foundational Language Models",
        "url": "http://arxiv.org/abs/2308.12272v1",
        "pub_date": "2023-08-23",
        "summary": "Foundational Language Models (FLMs) have advanced natural language processing\n(NLP) research. Current researchers are developing larger FLMs (e.g., XLNet,\nT5) to enable contextualized language representation, classification, and\ngeneration. While developing larger FLMs has been of significant advantage, it\nis also a liability concerning hallucination and predictive uncertainty.\nFundamentally, larger FLMs are built on the same foundations as smaller FLMs\n(e.g., BERT); hence, one must recognize the potential of smaller FLMs which can\nbe realized through an ensemble. In the current research, we perform a reality\ncheck on FLMs and their ensemble on benchmark and real-world datasets. We\nhypothesize that the ensembling of FLMs can influence the individualistic\nattention of FLMs and unravel the strength of coordination and cooperation of\ndifferent FLMs. We utilize BERT and define three other ensemble techniques:\n{Shallow, Semi, and Deep}, wherein the Deep-Ensemble introduces a\nknowledge-guided reinforcement learning approach. We discovered that the\nsuggested Deep-Ensemble BERT outperforms its large variation i.e. BERTlarge, by\na factor of many times using datasets that show the usefulness of NLP in\nsensitive fields, such as mental health.",
        "translated": "基础语言模型(FLM)具有先进的自然语言处理(NLP)研究。目前的研究人员正在开发更大的 FLM (如 XLNet、 T5) ，以支持上下文语言表示、分类和生成。虽然开发较大的 FLM 具有显著的优势，但它也是一个与幻觉和预测不确定性有关的不利因素。从根本上说，较大的 FLM 与较小的 FLM (例如 BERT)建立在相同的基础上; 因此，人们必须认识到较小的 FLM 的潜力，这可以通过一个集合来实现。在目前的研究中，我们对基准和真实世界的数据集上的 FLM 及其集成进行了实际检验。我们假设外语学习者的集合能够影响外语学习者的个体化注意力，并揭示不同外语学习者之间协调与合作的力量。我们利用 BERT 并定义了其他三种集合技术: {浅、半、深} ，其中 Deep-Ensemble 引入了一种知识导向的强化学习方法。我们发现，建议的深度集合 BERT 比它的大变化，即 BERTlarge，通过多次使用数据集，显示 NLP 在敏感领域的有用性，如心理健康的一个因素。"
    },
    {
        "title": "Prompt2Model: Generating Deployable Models from Natural Language\n  Instructions",
        "url": "http://arxiv.org/abs/2308.12261v1",
        "pub_date": "2023-08-23",
        "summary": "Large language models (LLMs) enable system builders today to create competent\nNLP systems through prompting, where they only need to describe the task in\nnatural language and provide a few examples. However, in other ways, LLMs are a\nstep backward from traditional special-purpose NLP models; they require\nextensive computational resources for deployment and can be gated behind APIs.\nIn this paper, we propose Prompt2Model, a general-purpose method that takes a\nnatural language task description like the prompts provided to LLMs, and uses\nit to train a special-purpose model that is conducive to deployment. This is\ndone through a multi-step process of retrieval of existing datasets and\npretrained models, dataset generation using LLMs, and supervised fine-tuning on\nthese retrieved and generated datasets. Over three tasks, we demonstrate that\ngiven the same few-shot prompt as input, Prompt2Model trains models that\noutperform the results of a strong LLM, gpt-3.5-turbo, by an average of 20%\nwhile being up to 700 times smaller. We also show that this data can be used to\nobtain reliable performance estimates of model performance, enabling model\ndevelopers to assess model reliability before deployment. Prompt2Model is\navailable open-source at https://github.com/neulab/prompt2model.",
        "translated": "如今，大语言模型(LLM)使得系统构建者能够通过提示创建合格的 NLP 系统，只需要用自然语言描述任务并提供一些示例。然而，在其他方面，LLM 比传统的专用 NLP 模型倒退了一步; 它们需要大量的计算资源进行部署，并且可以封闭在 API 之后。在本文中，我们提出了 Prompt2Model，这是一种通用方法，它采用类似于提供给 LLM 的提示的自然语言任务描述，并使用它来训练一个有利于部署的专用模型。这是通过检索现有数据集和预训练模型，使用 LLM 生成数据集，并对这些检索和生成的数据集进行监督微调的多步骤过程完成的。在三个任务中，我们演示了给出与输入相同的小镜头提示，Prompt2Model 训练的模型比强大的 LLM，gpt-3.5-turbo 的结果表现好20% ，同时比强大的 LLM 小700倍。我们还表明，这些数据可以用来获得模型性能的可靠性能评估，使模型开发人员能够在部署前评估模型的可靠性。Prompt2Model 可以在 https://github.com/neulab/Prompt2Model 上使用开源软件。"
    },
    {
        "title": "How to Protect Copyright Data in Optimization of Large Language Models?",
        "url": "http://arxiv.org/abs/2308.12247v1",
        "pub_date": "2023-08-23",
        "summary": "Large language models (LLMs) and generative AI have played a transformative\nrole in computer research and applications. Controversy has arisen as to\nwhether these models output copyrighted data, which can occur if the data the\nmodels are trained on is copyrighted. LLMs are built on the transformer neural\nnetwork architecture, which in turn relies on a mathematical computation called\nAttention that uses the softmax function.\n  In this paper, we show that large language model training and optimization\ncan be seen as a softmax regression problem. We then establish a method of\nefficiently performing softmax regression, in a way that prevents the\nregression function from generating copyright data. This establishes a\ntheoretical method of training large language models in a way that avoids\ngenerating copyright data.",
        "translated": "大语言模型(LLM)和生成式人工智能在计算机研究和应用中发挥了变革性的作用。关于这些模型是否输出受版权保护的数据，已经出现了争议，如果这些模型所使用的数据是受版权保护的，就可能出现这种情况。LLM 建立在变压器神经网络结构之上，而变压器神经网络结构又依赖于一种名为“注意力”的数学计算，该计算利用了柔性最大激活函数。在本文中，我们表明，大型语言模型的训练和优化可以看作是一个软极大回归问题。然后，我们建立了一种有效执行软最大回归的方法，以防止回归函数生成版权数据。这建立了一种理论方法，用于训练大型语言模型，避免产生版权数据。"
    },
    {
        "title": "Diffusion Language Models Can Perform Many Tasks with Scaling and\n  Instruction-Finetuning",
        "url": "http://arxiv.org/abs/2308.12219v1",
        "pub_date": "2023-08-23",
        "summary": "The recent surge of generative AI has been fueled by the generative power of\ndiffusion probabilistic models and the scalable capabilities of large language\nmodels. Despite their potential, it remains elusive whether diffusion language\nmodels can solve general language tasks comparable to their autoregressive\ncounterparts. This paper demonstrates that scaling diffusion models w.r.t.\ndata, sizes, and tasks can effectively make them strong language learners. We\nbuild competent diffusion language models at scale by first acquiring knowledge\nfrom massive data via masked language modeling pretraining thanks to their\nintrinsic connections. We then reprogram pretrained masked language models into\ndiffusion language models via diffusive adaptation, wherein task-specific\nfinetuning and instruction finetuning are explored to unlock their versatility\nin solving general language tasks. Experiments show that scaling diffusion\nlanguage models consistently improves performance across downstream language\ntasks. We further discover that instruction finetuning can elicit zero-shot and\nfew-shot in-context learning abilities that help tackle many unseen tasks by\nfollowing natural language instructions, and show promise in advanced and\nchallenging abilities such as reasoning",
        "translated": "扩散概率模型的生成能力和大型语言模型的可扩展能力推动了最近生成式人工智能的兴起。尽管扩散语言模型具有潜力，但它能否解决与自回归语言模型相当的一般语言任务，仍然是个难以捉摸的问题。本文论证了尺度扩散模型可以有效地使他们成为强大的语言学习者。我们首先通过掩蔽语言建模预训练从海量数据中获取知识，利用它们之间的内在联系，建立大规模有效的扩散语言模型。然后，我们通过扩散适应将预先训练的掩蔽语言模型重新编程为扩散语言模型，其中任务特定微调和指令微调被探索以释放它们在解决一般语言任务中的通用性。实验表明，尺度扩散语言模型可以持续提高下游语言任务的性能。我们进一步发现，指令微调可以产生零击和少击的上下文学习能力，通过遵循自然语言指令帮助解决许多看不见的任务，并显示出在高级和具有挑战性的能力，如推理的承诺"
    },
    {
        "title": "The Challenges of Machine Learning for Trust and Safety: A Case Study on\n  Misinformation Detection",
        "url": "http://arxiv.org/abs/2308.12215v1",
        "pub_date": "2023-08-23",
        "summary": "We examine the disconnect between scholarship and practice in applying\nmachine learning to trust and safety problems, using misinformation detection\nas a case study. We systematize literature on automated detection of\nmisinformation across a corpus of 270 well-cited papers in the field. We then\nexamine subsets of papers for data and code availability, design missteps,\nreproducibility, and generalizability. We find significant shortcomings in the\nliterature that call into question claimed performance and practicality.\nDetection tasks are often meaningfully distinct from the challenges that online\nservices actually face. Datasets and model evaluation are often\nnon-representative of real-world contexts, and evaluation frequently is not\nindependent of model training. Data and code availability is poor. Models do\nnot generalize well to out-of-domain data. Based on these results, we offer\nrecommendations for evaluating machine learning applications to trust and\nsafety problems. Our aim is for future work to avoid the pitfalls that we\nidentify.",
        "translated": "我们以错误信息检测为案例，研究机器学习应用于信任和安全问题时，学术和实践之间的脱节。我们系统化了关于自动检测错误信息的文献，这些文献涵盖了该领域270篇被引用的论文。然后我们检查论文子集的数据和代码可用性、设计错误、可重复性和可推广性。我们发现文献中的重大缺陷，对声称的性能和实用性提出质疑。检测任务往往与在线服务实际面临的挑战有意义地不同。数据集和模型评价往往不能代表现实世界的情况，评价往往不独立于模型训练。数据和代码可用性很差。模型不能很好地泛化域外数据。基于这些结果，我们提出了评估机器学习应用的信任和安全问题的建议。我们的目标是今后的工作，以避免我们确定的陷阱。"
    },
    {
        "title": "Curriculum Learning with Adam: The Devil Is in the Wrong Details",
        "url": "http://arxiv.org/abs/2308.12202v1",
        "pub_date": "2023-08-23",
        "summary": "Curriculum learning (CL) posits that machine learning models -- similar to\nhumans -- may learn more efficiently from data that match their current\nlearning progress. However, CL methods are still poorly understood and, in\nparticular for natural language processing (NLP), have achieved only limited\nsuccess. In this paper, we explore why. Starting from an attempt to replicate\nand extend a number of recent curriculum methods, we find that their results\nare surprisingly brittle when applied to NLP. A deep dive into the\n(in)effectiveness of the curricula in some scenarios shows us why: when\ncurricula are employed in combination with the popular Adam optimisation\nalgorithm, they oftentimes learn to adapt to suboptimally chosen optimisation\nparameters for this algorithm. We present a number of different case studies\nwith different common hand-crafted and automated CL approaches to illustrate\nthis phenomenon, and we find that none of them outperforms optimisation with\nonly Adam with well-chosen hyperparameters. As such, our results contribute to\nunderstanding why CL methods work, but at the same time urge caution when\nclaiming positive results.",
        "translated": "课程学习(CL)假定机器学习模型——类似于人类——可以更有效地从与他们当前学习进度相匹配的数据中学习。然而，CL 方法仍然很少被理解，特别是在自然语言处理(NLP)方面，只取得了有限的成功。在本文中，我们将探讨其中的原因。从试图复制和扩展一些最近的课程方法开始，我们发现它们的结果是惊人的脆弱，当应用到自然语言处理。深入研究课程在某些情况下的有效性可以告诉我们为什么: 当课程与流行的亚当优化算法结合使用时，他们经常学会适应这种算法的次优选择优化参数。我们提出了一些不同的案例研究与不同的常见手工制作和自动化 CL 方法来说明这一现象，我们发现没有一个优化只有亚当与精心选择的超参数。因此，我们的结果有助于理解为什么 CL 方法工作，但同时敦促谨慎时，声称积极的结果。"
    },
    {
        "title": "Evaluation of Faithfulness Using the Longest Supported Subsequence",
        "url": "http://arxiv.org/abs/2308.12157v1",
        "pub_date": "2023-08-23",
        "summary": "As increasingly sophisticated language models emerge, their trustworthiness\nbecomes a pivotal issue, especially in tasks such as summarization and\nquestion-answering. Ensuring their responses are contextually grounded and\nfaithful is challenging due to the linguistic diversity and the myriad of\npossible answers. In this paper, we introduce a novel approach to evaluate\nfaithfulness of machine-generated text by computing the longest noncontinuous\nsubstring of the claim that is supported by the context, which we refer to as\nthe Longest Supported Subsequence (LSS). Using a new human-annotated dataset,\nwe finetune a model to generate LSS. We introduce a new method of evaluation\nand demonstrate that these metrics correlate better with human ratings when LSS\nis employed, as opposed to when it is not. Our proposed metric demonstrates an\n18% enhancement over the prevailing state-of-the-art metric for faithfulness on\nour dataset. Our metric consistently outperforms other metrics on a\nsummarization dataset across six different models. Finally, we compare several\npopular Large Language Models (LLMs) for faithfulness using this metric. We\nrelease the human-annotated dataset built for predicting LSS and our fine-tuned\nmodel for evaluating faithfulness.",
        "translated": "随着越来越复杂的语言模型的出现，它们的可信度成为一个关键问题，特别是在总结和问答等任务中。由于语言的多样性和无数可能的答案，确保他们的回答是基于上下文的和忠实的是具有挑战性的。本文通过计算上下文支持的权利要求的最长非连续子串(称为最长支持子序列(LSS)) ，提出了一种新的评估机器生成文本忠实性的方法。使用一个新的人工注释数据集，我们微调一个模型来生成 LSS。我们介绍了一种新的评估方法，并证明了这些指标与人类评级更好地相关时，LSS 的使用，而不是当它不是。我们提出的度量标准表明，在数据集忠实度方面，比目前流行的最先进的度量标准提高了18% 。我们的指标在六个不同模型的汇总数据集上始终优于其他指标。最后，我们比较了几个流行的大型语言模型(LLM)使用这个度量的忠实性。我们发布了用于预测 LSS 的人工注释数据集，以及用于评估忠诚度的微调模型。"
    },
    {
        "title": "Semantic Change Detection for the Romanian Language",
        "url": "http://arxiv.org/abs/2308.12131v1",
        "pub_date": "2023-08-23",
        "summary": "Automatic semantic change methods try to identify the changes that appear\nover time in the meaning of words by analyzing their usage in diachronic\ncorpora. In this paper, we analyze different strategies to create static and\ncontextual word embedding models, i.e., Word2Vec and ELMo, on real-world\nEnglish and Romanian datasets. To test our pipeline and determine the\nperformance of our models, we first evaluate both word embedding models on an\nEnglish dataset (SEMEVAL-CCOHA). Afterward, we focus our experiments on a\nRomanian dataset, and we underline different aspects of semantic changes in\nthis low-resource language, such as meaning acquisition and loss. The\nexperimental results show that, depending on the corpus, the most important\nfactors to consider are the choice of model and the distance to calculate a\nscore for detecting semantic change.",
        "translated": "自动语义变化方法通过分析词汇在历时语料库中的使用情况，识别词义随时间的变化。在本文中，我们分析了在现实世界的英语和罗马尼亚语数据集上创建静态和上下文嵌入模型的不同策略，即 Word2Vec 和 ELMo。为了测试我们的流水线并确定模型的性能，我们首先在一个英语数据集(SEMEVAL-CCOHA)上评估两个单词嵌入模型。之后，我们将实验集中在一个罗马尼亚数据集上，并强调了这种低资源语言中语义变化的不同方面，如意义获取和丢失。实验结果表明，根据语料库的不同，检测语义变化最重要的因素是模型的选择和计算得分的距离。"
    },
    {
        "title": "Instruction Position Matters in Sequence Generation with Large Language\n  Models",
        "url": "http://arxiv.org/abs/2308.12097v1",
        "pub_date": "2023-08-23",
        "summary": "Large language models (LLMs) are capable of performing conditional sequence\ngeneration tasks, such as translation or summarization, through instruction\nfine-tuning. The fine-tuning data is generally sequentially concatenated from a\nspecific task instruction, an input sentence, and the corresponding response.\nConsidering the locality modeled by the self-attention mechanism of LLMs, these\nmodels face the risk of instruction forgetting when generating responses for\nlong input sentences. To mitigate this issue, we propose enhancing the\ninstruction-following capability of LLMs by shifting the position of task\ninstructions after the input sentences. Theoretical analysis suggests that our\nstraightforward method can alter the model's learning focus, thereby\nemphasizing the training of instruction-following capabilities. Concurrently,\nexperimental results demonstrate that our approach consistently outperforms\ntraditional settings across various model scales (1B / 7B / 13B) and different\nsequence generation tasks (translation and summarization), without any\nadditional data or annotation costs. Notably, our method significantly improves\nthe zero-shot performance on conditional sequence generation, e.g., up to 9.7\nBLEU points on WMT zero-shot translation tasks.",
        "translated": "大型语言模型(LLM)能够通过指令微调来执行条件序列生成任务，比如翻译或摘要。微调数据通常按顺序连接特定的任务指令、输入句和相应的响应。考虑到 LLM 的自我注意机制所建立的局部性，这些模型在产生长句输入反应时面临着指令遗忘的风险。为了解决这一问题，我们提出通过在输入句子后移动任务指令的位置来提高 LLM 的指令跟踪能力。理论分析表明，我们的直接方法可以改变模型的学习重点，从而强调教学跟踪能力的培训。同时，实验结果表明，我们的方法在不同的模型尺度(1B/7B/13B)和不同的序列生成任务(翻译和摘要)中始终优于传统设置，而没有任何额外的数据或注释成本。值得注意的是，我们的方法显著提高了条件序列生成的零拍性能，例如，在 WMT 零拍翻译任务中最多可以达到9.7个 BLEU 点。"
    },
    {
        "title": "On Popularity Bias of Multimodal-aware Recommender Systems: a\n  Modalities-driven Analysis",
        "url": "http://arxiv.org/abs/2308.12911v1",
        "pub_date": "2023-08-24",
        "summary": "Multimodal-aware recommender systems (MRSs) exploit multimodal content (e.g.,\nproduct images or descriptions) as items' side information to improve\nrecommendation accuracy. While most of such methods rely on factorization\nmodels (e.g., MFBPR) as base architecture, it has been shown that MFBPR may be\naffected by popularity bias, meaning that it inherently tends to boost the\nrecommendation of popular (i.e., short-head) items at the detriment of niche\n(i.e., long-tail) items from the catalog. Motivated by this assumption, in this\nwork, we provide one of the first analyses on how multimodality in\nrecommendation could further amplify popularity bias. Concretely, we evaluate\nthe performance of four state-of-the-art MRSs algorithms (i.e., VBPR, MMGCN,\nGRCN, LATTICE) on three datasets from Amazon by assessing, along with\nrecommendation accuracy metrics, performance measures accounting for the\ndiversity of recommended items and the portion of retrieved niche items. To\nbetter investigate this aspect, we decide to study the separate influence of\neach modality (i.e., visual and textual) on popularity bias in different\nevaluation dimensions. Results, which demonstrate how the single modality may\naugment the negative effect of popularity bias, shed light on the importance to\nprovide a more rigorous analysis of the performance of such models.",
        "translated": "多通道感知推荐系统(MRS)利用多通道内容(例如，产品图片或描述)作为项目的侧信息来提高推荐的准确性。虽然大多数此类方法依赖于因子分解模型(例如，MFBPR)作为基础架构，但已经表明，MFBPR 可能受到流行偏差的影响，这意味着它本质上倾向于推荐流行(例如，短头)项目，而不利于目录中的利基(例如，长尾)项目。在这个假设的激励下，本文首先分析了推荐中的多模态如何进一步放大流行偏差。具体而言，我们通过评估来自亚马逊的三个数据集上的四个最先进的 MRS 算法(即 vbPR，MMGCN，GRCN，latTICE)的性能，以及推荐准确性指标，考虑推荐项目多样性的性能指标和检索的利基项目的比例。为了更好地研究这一方面，我们决定在不同的评价维度上分别研究每种情态(即视觉和文本)对流行偏差的影响。结果表明，单一模式如何可能增加流行偏见的负面影响，阐明了重要性，以提供一个更严格的分析这些模型的表现。"
    },
    {
        "title": "Towards Communication-Efficient Model Updating for On-Device\n  Session-Based Recommendation",
        "url": "http://arxiv.org/abs/2308.12777v1",
        "pub_date": "2023-08-24",
        "summary": "On-device recommender systems recently have garnered increasing attention due\nto their advantages of providing prompt response and securing privacy. To stay\ncurrent with evolving user interests, cloud-based recommender systems are\nperiodically updated with new interaction data. However, on-device models\nstruggle to retrain themselves because of limited onboard computing resources.\nAs a solution, we consider the scenario where the model retraining occurs on\nthe server side and then the updated parameters are transferred to edge devices\nvia network communication. While this eliminates the need for local retraining,\nit incurs a regular transfer of parameters that significantly taxes network\nbandwidth. To mitigate this issue, we develop an efficient approach based on\ncompositional codes to compress the model update. This approach ensures the\non-device model is updated flexibly with minimal additional parameters whilst\nutilizing previous knowledge. The extensive experiments conducted on multiple\nsession-based recommendation models with distinctive architectures demonstrate\nthat the on-device model can achieve comparable accuracy to the retrained\nserver-side counterpart through transferring an update 60x smaller in size. The\ncodes are available at \\url{https://github.com/xiaxin1998/ODUpdate}.",
        "translated": "设备上推荐系统最近受到越来越多的关注，因为它们具有提供快速响应和保护隐私的优点。为了与不断变化的用户兴趣保持同步，基于云的推荐系统定期更新新的交互数据。然而，由于机载计算资源有限，在设备上的模型很难进行再培训。作为解决方案，我们考虑在服务器端进行模型再训练，然后通过网络通信将更新后的参数传输到边缘设备。虽然这消除了对本地再培训的需要，但它引起定期参数传输，大大增加了网络带宽的负担。为了解决这一问题，我们提出了一种基于复合代码的模型更新压缩方法。这种方法确保在设备上的模型更新灵活，最小的额外参数，同时利用以前的知识。在具有独特体系结构的多会话推荐模型上进行的大量实验表明，设备上模型可以通过传输小60倍的更新来达到与再训练的服务器端模型相当的精度。这些代码可以在 url { https://github.com/xiaxin1998/odupdate }获得。"
    },
    {
        "title": "On the Consistency of Average Embeddings for Item Recommendation",
        "url": "http://arxiv.org/abs/2308.12767v1",
        "pub_date": "2023-08-24",
        "summary": "A prevalent practice in recommender systems consists of averaging item\nembeddings to represent users or higher-level concepts in the same embedding\nspace. This paper investigates the relevance of such a practice. For this\npurpose, we propose an expected precision score, designed to measure the\nconsistency of an average embedding relative to the items used for its\nconstruction. We subsequently analyze the mathematical expression of this score\nin a theoretical setting with specific assumptions, as well as its empirical\nbehavior on real-world data from music streaming services. Our results\nemphasize that real-world averages are less consistent for recommendation,\nwhich paves the way for future research to better align real-world embeddings\nwith assumptions from our theoretical setting.",
        "translated": "在推荐系统中，一个流行的实践是在相同的嵌入空间中平均条目嵌入来表示用户或者更高层次的概念。本文探讨了这种实践的相关性。为此，我们提出了一个期望精度得分，设计用来衡量平均嵌入的一致性相对于其构造所使用的项目。随后，我们分析了这个乐谱的数学表达式在一个理论设置与具体的假设，以及它的经验行为对现实世界的数据从音乐流媒体服务。我们的研究结果强调，现实世界的平均值与推荐的一致性较差，这为以后的研究更好地将现实世界的嵌入与我们理论设置的假设结合起来铺平了道路。"
    },
    {
        "title": "Video Recommendation Using Social Network Analysis and User Viewing\n  Patterns",
        "url": "http://arxiv.org/abs/2308.12743v1",
        "pub_date": "2023-08-24",
        "summary": "With the meteoric rise of video-on-demand (VOD) platforms, users face the\nchallenge of sifting through an expansive sea of content to uncover shows that\nclosely match their preferences. To address this information overload dilemma,\nVOD services have increasingly incorporated recommender systems powered by\nalgorithms that analyze user behavior and suggest personalized content.\nHowever, a majority of existing recommender systems depend on explicit user\nfeedback in the form of ratings and reviews, which can be difficult and\ntime-consuming to collect at scale. This presents a key research gap, as\nleveraging users' implicit feedback patterns could provide an alternative\navenue for building effective video recommendation models, circumventing the\nneed for explicit ratings. However, prior literature lacks sufficient\nexploration into implicit feedback-based recommender systems, especially in the\ncontext of modeling video viewing behavior. Therefore, this paper aims to\nbridge this research gap by proposing a novel video recommendation technique\nthat relies solely on users' implicit feedback in the form of their content\nviewing percentages.",
        "translated": "随着视频点播(VOD)平台的迅速崛起，用户面临的挑战是筛选海量的内容，以发现与他们的喜好非常匹配的节目。为了解决这个信息超载难题，视频点播服务已经越来越多地采用了推荐系统，这些推荐系统由分析用户行为和推荐个性化内容的算法提供支持。然而，大多数现有的推荐系统依赖于以评级和审查形式提供的明确的用户反馈，大规模收集这些反馈可能既困难又费时。这提出了一个关键的研究差距，因为利用用户的隐性反馈模式可以为建立有效的视频推荐模型提供一个替代途径，绕过显性评级的需要。然而，以往的文献对基于隐式反馈的推荐系统缺乏足够的探索，尤其是在视频观看行为建模的背景下。因此，本文旨在通过提出一种新的视频推荐技术来弥补这一研究差距，该技术仅仅依赖于用户内容观看百分比形式的内隐反馈。"
    },
    {
        "title": "Out of the Box Thinking: Improving Customer Lifetime Value Modelling via\n  Expert Routing and Game Whale Detection",
        "url": "http://arxiv.org/abs/2308.12729v1",
        "pub_date": "2023-08-24",
        "summary": "Customer lifetime value (LTV) prediction is essential for mobile game\npublishers trying to optimize the advertising investment for each user\nacquisition based on the estimated worth. In mobile games, deploying\nmicrotransactions is a simple yet effective monetization strategy, which\nattracts a tiny group of game whales who splurge on in-game purchases. The\npresence of such game whales may impede the practicality of existing LTV\nprediction models, since game whales' purchase behaviours always exhibit varied\ndistribution from general users. Consequently, identifying game whales can open\nup new opportunities to improve the accuracy of LTV prediction models. However,\nlittle attention has been paid to applying game whale detection in LTV\nprediction, and existing works are mainly specialized for the long-term LTV\nprediction with the assumption that the high-quality user features are\navailable, which is not applicable in the UA stage. In this paper, we propose\nExpLTV, a novel multi-task framework to perform LTV prediction and game whale\ndetection in a unified way. In ExpLTV, we first innovatively design a deep\nneural network-based game whale detector that can not only infer the intrinsic\norder in accordance with monetary value, but also precisely identify high\nspenders (i.e., game whales) and low spenders. Then, by treating the game whale\ndetector as a gating network to decide the different mixture patterns of LTV\nexperts assembling, we can thoroughly leverage the shared information and\nscenario-specific information (i.e., game whales modelling and low spenders\nmodelling). Finally, instead of separately designing a purchase rate estimator\nfor two tasks, we design a shared estimator that can preserve the inner task\nrelationships. The superiority of ExpLTV is further validated via extensive\nexperiments on three industrial datasets.",
        "translated": "客户生命周期价值(LTV)预测是手机游戏发行商基于估计价值优化每次用户获取广告投资的关键。在手机游戏中，部署微交易是一种简单而有效的货币化策略，它吸引了一小群游戏巨头在游戏中大肆消费。这种游戏鲸鱼的存在可能会阻碍现有 LTV 预测模型的实用性，因为游戏鲸鱼的购买行为总是表现出不同于一般用户的分布。因此，识别猎鲸可以为提高 LTV 预测模型的准确性开辟新的机会。然而，现有的工作主要是专门用于长期的按揭成数预测，假设有高质量的用户功能，这在 UA 阶段是不适用的。在本文中，我们提出了一个新的多任务框架 ExpLTV，以统一的方式执行 LTV 预测和游戏鲸鱼检测。在 ExpLTV 中，我们首先创新性地设计了一个基于深度神经网络的游戏鲸探测器，它不仅可以根据货币价值推断内在顺序，而且还可以精确地识别高消费者(即，游戏鲸)和低消费者。然后，通过把游戏鲸鱼探测器当作一个门控网络来决定不同的 LTV 专家组合的混合模式，我们可以充分利用共享的信息和特定场景的信息(例如，游戏鲸鱼模型和低消费者模型)。最后，我们设计了一个能够保持内部任务关系的共享估计器，而不是分别设计两个任务的购买率估计器。通过在三个工业数据集上的大量实验，进一步验证了 ExpLTV 的优越性。"
    },
    {
        "title": "Qwen-VL: A Frontier Large Vision-Language Model with Versatile Abilities",
        "url": "http://arxiv.org/abs/2308.12966v1",
        "pub_date": "2023-08-24",
        "summary": "We introduce the Qwen-VL series, a set of large-scale vision-language models\ndesigned to perceive and understand both text and images. Comprising Qwen-VL\nand Qwen-VL-Chat, these models exhibit remarkable performance in tasks like\nimage captioning, question answering, visual localization, and flexible\ninteraction. The evaluation covers a wide range of tasks including zero-shot\ncaptioning, visual or document visual question answering, and grounding. We\ndemonstrate the Qwen-VL outperforms existing Large Vision Language Models\n(LVLMs). We present their architecture, training, capabilities, and\nperformance, highlighting their contributions to advancing multimodal\nartificial intelligence. Code, demo and models are available at\nhttps://github.com/QwenLM/Qwen-VL.",
        "translated": "我们介绍了 Qwen-VL 系列，这是一套大规模的视觉语言模型，旨在感知和理解文本和图像。这些模型由 Qwen-VL 和 Qwen-VL-Chat 组成，在图像字幕、问答、视觉定位和灵活交互等任务中表现出显著的性能。评估涵盖了广泛的任务，包括零镜头字幕，视觉或文件的视觉问题回答，和基础。我们展示了 Qwen-VL 优于现有的大型视觉语言模型(LVLM)。我们介绍了他们的架构，培训，能力和表现，突出他们的贡献，推进多模态人工智能。代码，演示和模型可在 https://github.com/qwenlm/qwen-vl 下载。"
    },
    {
        "title": "Code Llama: Open Foundation Models for Code",
        "url": "http://arxiv.org/abs/2308.12950v1",
        "pub_date": "2023-08-24",
        "summary": "We release Code Llama, a family of large language models for code based on\nLlama 2 providing state-of-the-art performance among open models, infilling\ncapabilities, support for large input contexts, and zero-shot instruction\nfollowing ability for programming tasks. We provide multiple flavors to cover a\nwide range of applications: foundation models (Code Llama), Python\nspecializations (Code Llama - Python), and instruction-following models (Code\nLlama - Instruct) with 7B, 13B and 34B parameters each. All models are trained\non sequences of 16k tokens and show improvements on inputs with up to 100k\ntokens. 7B and 13B Code Llama and Code Llama - Instruct variants support\ninfilling based on surrounding content. Code Llama reaches state-of-the-art\nperformance among open models on several code benchmarks, with scores of up to\n53% and 55% on HumanEval and MBPP, respectively. Notably, Code Llama - Python\n7B outperforms Llama 2 70B on HumanEval and MBPP, and all our models outperform\nevery other publicly available model on MultiPL-E. We release Code Llama under\na permissive license that allows for both research and commercial use.",
        "translated": "我们发布了 Code Llama，一个基于 Llama 2的大型语言模型家族，为开放模型、填充功能、大输入上下文支持以及编程任务的零击指令跟踪能力提供了最先进的性能。我们提供多种风格以涵盖广泛的应用程序: 基础模型(Code Llama)、 Python 专门化(Code Llama-Python)和指令遵循模型(Code Llama-Direct) ，每个模型都有7B、13B 和34B 参数。所有模型都在16k 令牌的序列上进行训练，并显示对最多100k 令牌的输入的改进。7B 和13B 代码美洲驼和代码美洲驼-指令变体支持基于周围内容的填充。Code Llama 在几个代码基准上达到了开放模型中的最高水平，在 HumanEval 和 MBPP 上分别达到了53% 和55% 。值得注意的是，代码 Llama-Python 7B 在 HumanEval 和 MBPP 上优于 Llama 270B，我们所有的模型在 MultiPL-E 上都优于其他所有公开可用的模型。我们发布代码美洲驼在一个允许的许可证，允许研究和商业使用。"
    },
    {
        "title": "Can Linguistic Knowledge Improve Multimodal Alignment in Vision-Language\n  Pretraining?",
        "url": "http://arxiv.org/abs/2308.12898v1",
        "pub_date": "2023-08-24",
        "summary": "The multimedia community has shown a significant interest in perceiving and\nrepresenting the physical world with multimodal pretrained neural network\nmodels, and among them, the visual-language pertaining (VLP) is, currently, the\nmost captivating topic. However, there have been few endeavors dedicated to the\nexploration of 1) whether essential linguistic knowledge (e.g., semantics and\nsyntax) can be extracted during VLP, and 2) how such linguistic knowledge\nimpact or enhance the multimodal alignment. In response, here we aim to\nelucidate the impact of comprehensive linguistic knowledge, including semantic\nexpression and syntactic structure, on multimodal alignment. Specifically, we\ndesign and release the SNARE, the first large-scale multimodal alignment\nprobing benchmark, to detect the vital linguistic components, e.g., lexical,\nsemantic, and syntax knowledge, containing four tasks: Semantic structure,\nNegation logic, Attribute ownership, and Relationship composition. Based on our\nproposed probing benchmarks, our holistic analyses of five advanced VLP models\nillustrate that the VLP model: i) shows insensitivity towards complex syntax\nstructures and relies on content words for sentence comprehension; ii)\ndemonstrates limited comprehension of combinations between sentences and\nnegations; iii) faces challenges in determining the presence of actions or\nspatial relationships within visual information and struggles with verifying\nthe correctness of triple combinations. We make our benchmark and code\navailable at \\url{https://github.com/WangFei-2019/SNARE/}.",
        "translated": "多媒体社区对用多模态预训练神经网络模型来感知和表征物理世界表现出了浓厚的兴趣，其中视觉语言属性(VLP)是目前最吸引人的话题。然而，在 VLP 过程中是否可以提取必要的语言知识(例如语义和句法) ，以及这些语言知识如何影响或增强多模态对齐等方面的研究很少。作为回应，本文旨在阐明综合语言知识(包括语义表达和句法结构)对多模态对齐的影响。具体来说，我们设计并发布了 SNARE，这是第一个大规模的多模态对齐探测基准，用于检测重要的语言成分，如词汇、语义和句法知识，包含四个任务: 语义结构、否定逻辑、属性所有权和关系组合。基于我们提出的探究基准，我们对五个先进的 VLP 模型的整体分析表明，VLP 模型: i)表现出对复杂句法结构的不敏感，依赖于句子理解的内容词; ii)表现出对句子和否定之间的组合的有限理解; iii)在确定视觉信息中是否存在动作或空间关系方面面临挑战，并努力验证三重组合的正确性。我们在 url { https://github.com/wangfei-2019/snare/}提供基准测试和代码。"
    },
    {
        "title": "Beyond Document Page Classification: Design, Datasets, and Challenges",
        "url": "http://arxiv.org/abs/2308.12896v1",
        "pub_date": "2023-08-24",
        "summary": "This paper highlights the need to bring document classification benchmarking\ncloser to real-world applications, both in the nature of data tested ($X$:\nmulti-channel, multi-paged, multi-industry; $Y$: class distributions and label\nset variety) and in classification tasks considered ($f$: multi-page document,\npage stream, and document bundle classification, ...). We identify the lack of\npublic multi-page document classification datasets, formalize different\nclassification tasks arising in application scenarios, and motivate the value\nof targeting efficient multi-page document representations. An experimental\nstudy on proposed multi-page document classification datasets demonstrates that\ncurrent benchmarks have become irrelevant and need to be updated to evaluate\ncomplete documents, as they naturally occur in practice. This reality check\nalso calls for more mature evaluation methodologies, covering calibration\nevaluation, inference complexity (time-memory), and a range of realistic\ndistribution shifts (e.g., born-digital vs. scanning noise, shifting page\norder). Our study ends on a hopeful note by recommending concrete avenues for\nfuture improvements.}",
        "translated": "这篇文章强调需要使文档分类基准测试更接近于现实世界的应用，无论是在测试数据的性质($X $: 多通道，多页面，多行业; $Y $: 类分布和标签集多样性)还是在分类任务中考虑($f $: 多页面文档，页面流和文档包分类，...)。我们发现缺乏公开的多页文档分类数据集，将应用场景中出现的不同分类任务形式化，并激发针对有效的多页文档表示的价值。对拟议的多页文档分类数据集进行的一项实验研究表明，当前的基准已经变得无关紧要，需要更新以评估完整的文件，因为它们在实践中自然会出现。这种现实性检查还需要更成熟的评估方法，包括校准评估、推断复杂性(时间记忆)和一系列现实的分布变化(例如，天生数字与扫描噪音、页面顺序变化)。我们的研究以一个充满希望的结尾，提出了未来改进的具体途径。}"
    },
    {
        "title": "Large Language Models Vote: Prompting for Rare Disease Identification",
        "url": "http://arxiv.org/abs/2308.12890v1",
        "pub_date": "2023-08-24",
        "summary": "The emergence of generative Large Language Models (LLMs) emphasizes the need\nfor accurate and efficient prompting approaches. LLMs are often applied in\nFew-Shot Learning (FSL) contexts, where tasks are executed with minimal\ntraining data. FSL has become popular in many Artificial Intelligence (AI)\nsubdomains, including AI for health. Rare diseases, affecting a small fraction\nof the population, inherently require FSL techniques due to limited data\navailability, though manual data collection and annotation is costly and\ntime-consuming. In this paper, we propose Models-Vote Prompting (MVP), a\nflexible prompting approach for improving the performance of LLM queries in FSL\nsettings. MVP works by prompting numerous LLMs to perform the same tasks and\nthen conducting a majority vote on the resulting outputs. This method achieves\nimproved results to any one model in the ensemble on one-shot rare disease\nidentification and classification tasks. We also release a novel rare disease\ndataset for FSL, available to those who agreed to the MIMIC-IV Data Use\nAgreement (DUA). Furthermore, in using MVP, each model is prompted multiple\ntimes, substantially increasing the time needed for manual annotation, and to\naddress this, we assess the feasibility of using JSON for automating generative\nLLM evaluation.",
        "translated": "生成式大语言模型(LLM)的出现强调了对准确有效的提示方法的需求。LLM 通常应用于极少数镜头学习(FSL)环境中，在这种环境中，任务是以最少的训练数据来执行的。FSL 已经在许多人工智能(AI)子域中流行起来，包括用于健康的 AI。影响一小部分人群的罕见疾病，由于数据可用性有限，固有地需要 FSL 技术，尽管手工数据收集和注释成本高昂且耗时。在本文中，我们提出了模型投票提示(MVP) ，一种灵活的提示方法，以提高性能的 LLM 查询在 FSL 设置。MVP 的工作原理是提示众多 LLM 执行相同的任务，然后对结果进行多数表决。该方法在一次性进行罕见病识别和分类任务时，对集合中的任意一个模型都取得了改进的结果。我们还为 FSL 发布了一个新的罕见疾病数据集，提供给那些同意 MIMIC-IV 数据使用协议(DUA)的人。此外，在使用 MVP 时，每个模型都会被多次提示，这大大增加了手动注释所需的时间，为了解决这个问题，我们评估了使用 JSON 自动生成 LLM 计算的可行性。"
    },
    {
        "title": "Inducing Causal Structure for Abstractive Text Summarization",
        "url": "http://arxiv.org/abs/2308.12888v1",
        "pub_date": "2023-08-24",
        "summary": "The mainstream of data-driven abstractive summarization models tends to\nexplore the correlations rather than the causal relationships. Among such\ncorrelations, there can be spurious ones which suffer from the language prior\nlearned from the training corpus and therefore undermine the overall\neffectiveness of the learned model. To tackle this issue, we introduce a\nStructural Causal Model (SCM) to induce the underlying causal structure of the\nsummarization data. We assume several latent causal factors and non-causal\nfactors, representing the content and style of the document and summary.\nTheoretically, we prove that the latent factors in our SCM can be identified by\nfitting the observed training data under certain conditions. On the basis of\nthis, we propose a Causality Inspired Sequence-to-Sequence model (CI-Seq2Seq)\nto learn the causal representations that can mimic the causal factors, guiding\nus to pursue causal information for summary generation. The key idea is to\nreformulate the Variational Auto-encoder (VAE) to fit the joint distribution of\nthe document and summary variables from the training corpus. Experimental\nresults on two widely used text summarization datasets demonstrate the\nadvantages of our approach.",
        "translated": "数据驱动的抽象摘要模型的主流趋向于探索相关性，而不是因果关系。在这些相关性中，可能存在一些虚假的相关性，这些相关性受到事先从培训语料库中学到的语言的影响，因此会破坏所学模型的整体有效性。为了解决这个问题，我们引入了一个结构性因果模型(SCM)来归纳总结数据的潜在因果结构。我们假设几个潜在的因果因素和非因果因素，代表的内容和风格的文件和总结。从理论上证明了在一定条件下，通过拟合观测训练数据可以识别供应链管理中的潜在因素。在此基础上，我们提出了一个受因果关系启发的序列到序列模型(CI-Seq2Seq)来学习可以模拟因果因素的因果表征，指导我们追求因果信息以进行摘要生成。其核心思想是对变分自动编码器(VAE)进行重构，以适应训练语料中文档和汇总变量的联合分布。在两个广泛使用的文本摘要数据集上的实验结果证明了该方法的优越性。"
    },
    {
        "title": "Text Similarity from Image Contents using Statistical and Semantic\n  Analysis Techniques",
        "url": "http://arxiv.org/abs/2308.12842v1",
        "pub_date": "2023-08-24",
        "summary": "Plagiarism detection is one of the most researched areas among the Natural\nLanguage Processing(NLP) community. A good plagiarism detection covers all the\nNLP methods including semantics, named entities, paraphrases etc. and produces\ndetailed plagiarism reports. Detection of Cross Lingual Plagiarism requires\ndeep knowledge of various advanced methods and algorithms to perform effective\ntext similarity checking. Nowadays the plagiarists are also advancing\nthemselves from hiding the identity from being catch in such offense. The\nplagiarists are bypassed from being detected with techniques like paraphrasing,\nsynonym replacement, mismatching citations, translating one language to\nanother. Image Content Plagiarism Detection (ICPD) has gained importance,\nutilizing advanced image content processing to identify instances of plagiarism\nto ensure the integrity of image content. The issue of plagiarism extends\nbeyond textual content, as images such as figures, graphs, and tables also have\nthe potential to be plagiarized. However, image content plagiarism detection\nremains an unaddressed challenge. Therefore, there is a critical need to\ndevelop methods and systems for detecting plagiarism in image content. In this\npaper, the system has been implemented to detect plagiarism form contents of\nImages such as Figures, Graphs, Tables etc. Along with statistical algorithms\nsuch as Jaccard and Cosine, introducing semantic algorithms such as LSA, BERT,\nWordNet outperformed in detecting efficient and accurate plagiarism.",
        "translated": "剽窃检测是自然语言处理(NLP)社区中研究最多的领域之一。一个好的剽窃检测覆盖了所有的 NLP 方法，包括语义，命名实体，释义等，并产生详细的剽窃报告。跨语言剽窃的检测需要对各种先进的方法和算法有深入的了解，才能进行有效的文本相似性检测。如今，剽窃者们也在努力提高自己，避免在这种犯罪行为中被抓住。这些剽窃者被忽略了，因为他们没有被检测出来，比如释义、同义词替换、不匹配的引用、把一种语言翻译成另一种语言。图像内容剽窃检测技术(ICPD)利用先进的图像内容处理技术对剽窃案例进行识别，以保证图像内容的完整性。剽窃的问题超出了文本内容，因为图形、图形和表格等图像也有可能被剽窃。然而，图像内容剽窃检测仍然是一个未解决的挑战。因此，迫切需要开发检测图像内容剽窃的方法和系统。本文实现了图形、图形、表格等图像内容的剽窃检测系统。与 Jaccard 和 Cosine 等统计算法一起，引入了 LSA、 BERT、 WordNet 等语义算法，在检测有效和准确的剽窃方面表现出色。"
    },
    {
        "title": "Use of LLMs for Illicit Purposes: Threats, Prevention Measures, and\n  Vulnerabilities",
        "url": "http://arxiv.org/abs/2308.12833v1",
        "pub_date": "2023-08-24",
        "summary": "Spurred by the recent rapid increase in the development and distribution of\nlarge language models (LLMs) across industry and academia, much recent work has\ndrawn attention to safety- and security-related threats and vulnerabilities of\nLLMs, including in the context of potentially criminal activities.\nSpecifically, it has been shown that LLMs can be misused for fraud,\nimpersonation, and the generation of malware; while other authors have\nconsidered the more general problem of AI alignment. It is important that\ndevelopers and practitioners alike are aware of security-related problems with\nsuch models. In this paper, we provide an overview of existing - predominantly\nscientific - efforts on identifying and mitigating threats and vulnerabilities\narising from LLMs. We present a taxonomy describing the relationship between\nthreats caused by the generative capabilities of LLMs, prevention measures\nintended to address such threats, and vulnerabilities arising from imperfect\nprevention measures. With our work, we hope to raise awareness of the\nlimitations of LLMs in light of such security concerns, among both experienced\ndevelopers and novel users of such technologies.",
        "translated": "由于最近大型语言模型(LLM)在行业和学术界的发展和分布迅速增加，许多最近的工作已经引起了人们对 LLM 的安全和安保相关威胁和脆弱性的关注，包括在潜在犯罪活动的背景下。具体来说，已经证明 LLM 可能被误用于欺诈、模拟和恶意软件的生成; 而其他作者已经考虑了更普遍的人工智能对齐问题。重要的是，开发人员和从业人员都意识到这种模型存在与安全相关的问题。在本文中，我们提供了一个现有的概述-主要是科学-努力确定和减轻威胁和脆弱性所产生的长期管理模式。我们提出了一个分类法，描述由 LLM 的生成能力造成的威胁、旨在应对这些威胁的预防措施和不完善的预防措施所产生的脆弱性之间的关系。通过我们的工作，我们希望提高经验丰富的开发人员和此类技术的新用户对 LLM 在安全方面的局限性的认识。"
    },
    {
        "title": "WavMark: Watermarking for Audio Generation",
        "url": "http://arxiv.org/abs/2308.12770v1",
        "pub_date": "2023-08-24",
        "summary": "Recent breakthroughs in zero-shot voice synthesis have enabled imitating a\nspeaker's voice using just a few seconds of recording while maintaining a high\nlevel of realism. Alongside its potential benefits, this powerful technology\nintroduces notable risks, including voice fraud and speaker impersonation.\nUnlike the conventional approach of solely relying on passive methods for\ndetecting synthetic data, watermarking presents a proactive and robust defence\nmechanism against these looming risks. This paper introduces an innovative\naudio watermarking framework that encodes up to 32 bits of watermark within a\nmere 1-second audio snippet. The watermark is imperceptible to human senses and\nexhibits strong resilience against various attacks. It can serve as an\neffective identifier for synthesized voices and holds potential for broader\napplications in audio copyright protection. Moreover, this framework boasts\nhigh flexibility, allowing for the combination of multiple watermark segments\nto achieve heightened robustness and expanded capacity. Utilizing 10 to\n20-second audio as the host, our approach demonstrates an average Bit Error\nRate (BER) of 0.48\\% across ten common attacks, a remarkable reduction of over\n2800\\% in BER compared to the state-of-the-art watermarking tool. See\nhttps://aka.ms/wavmark for demos of our work.",
        "translated": "最近在零拍摄声音合成方面的突破使得模仿说话人的声音只需要几秒钟的录音，同时保持高水平的真实感。除了潜在的好处，这项强大的技术还带来了显著的风险，包括语音欺诈和模仿说话人。不像传统的方法，仅仅依靠被动的方法来检测合成数据，水印提出了一个主动和健壮的防御机制对这些迫在眉睫的风险。本文介绍了一种创新的音频水印框架，它可以在1秒钟的音频片段内编码多达32位的水印。水印是人类感官无法察觉的，对各种攻击具有很强的抵抗力。它可以作为合成声音的有效标识符，在音频版权保护方面具有更广泛的应用潜力。此外，该框架具有很高的灵活性，允许组合多个水印段，以实现更高的鲁棒性和扩展能力。利用10到20秒的音频作为主机，我们的方法展示了一个平均比特错误率(BER)为0.48% 的10种常见的攻击，显着降低了2800% 以上的比特错误率相比，国家的最先进的水印工具。看看我们工作的演示 https://aka.ms/wavmark。"
    },
    {
        "title": "Real-time Detection of AI-Generated Speech for DeepFake Voice Conversion",
        "url": "http://arxiv.org/abs/2308.12734v1",
        "pub_date": "2023-08-24",
        "summary": "There are growing implications surrounding generative AI in the speech domain\nthat enable voice cloning and real-time voice conversion from one individual to\nanother. This technology poses a significant ethical threat and could lead to\nbreaches of privacy and misrepresentation, thus there is an urgent need for\nreal-time detection of AI-generated speech for DeepFake Voice Conversion. To\naddress the above emerging issues, the DEEP-VOICE dataset is generated in this\nstudy, comprised of real human speech from eight well-known figures and their\nspeech converted to one another using Retrieval-based Voice Conversion.\nPresenting as a binary classification problem of whether the speech is real or\nAI-generated, statistical analysis of temporal audio features through t-testing\nreveals that there are significantly different distributions. Hyperparameter\noptimisation is implemented for machine learning models to identify the source\nof speech. Following the training of 208 individual machine learning models\nover 10-fold cross validation, it is found that the Extreme Gradient Boosting\nmodel can achieve an average classification accuracy of 99.3% and can classify\nspeech in real-time, at around 0.004 milliseconds given one second of speech.\nAll data generated for this study is released publicly for future research on\nAI speech detection.",
        "translated": "围绕语音领域的生成性人工智能有着越来越多的含义，它能够实现语音克隆和实时语音从一个人到另一个人的转换。这项技术构成了重大的道德威胁，并可能导致侵犯隐私和不正当手法引诱，因此迫切需要实时检测人工智能生成的深度伪造语音转换语音。为了解决上述问题，本研究采用基于检索的语音转换技术，生成了由八个知名人物的真实人类语音组成的 DEEP-VOICE 数据集。通过 t 检验对时间音频特征进行统计分析，发现时间音频特征具有明显不同的分布特征。超参数优化用于机器学习模型识别语音源。通过对208个机器学习模型进行10倍交叉验证的训练，我们发现极限梯度提升模型可以达到99.3% 的平均分类准确率，并且可以实时地对语音进行分类，在给定一秒钟的语音时间内，分类时间约为0.004毫秒。本研究所产生的所有数据均公开发表，以供未来人工智能语音检测的研究之用。"
    },
    {
        "title": "On the Practicality of Dynamic Updates in Fast Searchable Encryption",
        "url": "http://arxiv.org/abs/2308.13486v1",
        "pub_date": "2023-08-25",
        "summary": "Searchable encrypted (SE) indexing systems are a useful tool for utilizing\ncloud services to store and manage sensitive information. However, much of the\nwork on SE systems to date has remained theoretical. In order to make them of\npractical use, more work is needed to develop optimal protocols and working\nmodels for them. This includes, in particular, the creation of a working update\nmodel in order to maintain an encrypted index of a dynamic document set such as\nan email inbox. I have created a working, real-world end-to-end SE\nimplementation that satisfies these needs, including the first empirical\nperformance evaluation of the dynamic SE update operation. In doing so, I show\na viable path to move from the theoretical concepts described by previous\nresearchers to a future production-worthy implementation and identify issues\nfor follow-on investigation.",
        "translated": "可搜索加密(SE)索引系统是利用云服务存储和管理敏感信息的有用工具。然而，迄今为止关于 SE 系统的大部分工作仍然停留在理论层面。为了使它们具有实际应用价值，需要开发更多的工作来为它们开发最优协议和工作模型。这尤其包括创建工作更新模型，以维护动态文档集(如电子邮件收件箱)的加密索引。我已经创建了一个工作的、真实的端到端 SE 实现来满足这些需求，包括对动态 SE 更新操作的第一次经验性性能评估。在这样做的过程中，我展示了一条可行的路径，从以前的研究人员描述的理论概念转移到未来值得生产的实现，并确定后续调查的问题。"
    },
    {
        "title": "Leveraging Knowledge and Reinforcement Learning for Enhanced Reliability\n  of Language Models",
        "url": "http://arxiv.org/abs/2308.13467v1",
        "pub_date": "2023-08-25",
        "summary": "The Natural Language Processing(NLP) community has been using crowd sourcing\ntechniques to create benchmark datasets such as General Language Understanding\nand Evaluation(GLUE) for training modern Language Models such as BERT. GLUE\ntasks measure the reliability scores using inter annotator metrics i.e. Cohens\nKappa. However, the reliability aspect of LMs has often been overlooked. To\ncounter this problem, we explore a knowledge-guided LM ensembling approach that\nleverages reinforcement learning to integrate knowledge from ConceptNet and\nWikipedia as knowledge graph embeddings. This approach mimics human annotators\nresorting to external knowledge to compensate for information deficits in the\ndatasets. Across nine GLUE datasets, our research shows that ensembling\nstrengthens reliability and accuracy scores, outperforming state of the art.",
        "translated": "自然语言处理(NLP)社区一直在使用众包技术来创建基准数据集，如通用语言理解和评估(GLUE) ，用于培训现代语言模型，如 BERT。GLUE 任务使用注释器间指标(即 Cohen Kappa)来度量可靠性得分。然而，LM 的可靠性方面往往被忽视。为了解决这个问题，我们探索了一种知识引导的 LM 集成方法，该方法利用强化学习将概念网和维基百科的知识集成为知识图表嵌入。这种方法模仿人类注释者求助于外部知识来弥补数据集中的信息缺陷。在九个 GLUE 数据集中，我们的研究表明，集合增强了可靠性和准确性得分，表现优于最先进的水平。"
    },
    {
        "title": "A Bayesian Active Learning Approach to Comparative Judgement",
        "url": "http://arxiv.org/abs/2308.13292v1",
        "pub_date": "2023-08-25",
        "summary": "Assessment is a crucial part of education. Traditional marking is a source of\ninconsistencies and unconscious bias, placing a high cognitive load on the\nassessors. An approach to address these issues is comparative judgement (CJ).\nIn CJ, the assessor is presented with a pair of items and is asked to select\nthe better one. Following a series of comparisons, a rank is derived using a\nranking model, for example, the BTM, based on the results. While CJ is\nconsidered a reliable method for marking, there are concerns around\ntransparency, and the ideal number of pairwise comparisons to generate a\nreliable estimation of the rank order is not known. Additionally, there have\nbeen attempts to generate a method of selecting pairs that should be compared\nnext in an informative manner, but some existing methods are known to have\ncreated their own bias within results inflating the reliability metric used. As\na result, a random selection approach is usually deployed.\n  We propose a novel Bayesian approach to CJ (BCJ) for determining the ranks of\ncompared items alongside a new way to select the pairs to present to the\nmarker(s) using active learning (AL), addressing the key shortcomings of\ntraditional CJ. Furthermore, we demonstrate how the entire approach may provide\ntransparency by providing the user insights into how it is making its decisions\nand, at the same time, being more efficient. Results from our experiments\nconfirm that the proposed BCJ combined with entropy-driven AL pair-selection\nmethod is superior to other alternatives. We also find that the more\ncomparisons done, the more accurate BCJ becomes, which solves the issue the\ncurrent method has of the model deteriorating if too many comparisons are\nperformed. As our approach can generate the complete predicted rank\ndistribution for an item, we also show how this can be utilised in devising a\npredicted grade, guided by the assessor.",
        "translated": "评估是教育的重要组成部分。传统的评分是不一致和无意识偏见的根源，给评分员带来了高认知负担。解决这些问题的方法是比较判断(CJ)。在 CJ 中，评估员面前有一对项目，并被要求选择较好的一个。在一系列的比较之后，使用排名模型(例如 BTM)根据结果得出一个排名。虽然 CJ 被认为是一种可靠的评分方法，但透明度方面也存在一些问题，而产生可靠的排名顺序估计的理想的成对比较数目尚不清楚。此外，已经有人尝试产生一种选择配对的方法，接下来应该以信息性方式进行比较，但是已知的一些现有方法在夸大所使用的可靠性度量的结果中产生了自己的偏差。因此，通常采用随机选择方法。我们提出了一种新的贝叶斯方法(BCJ)来确定比较项目的等级，同时提出了一种新的方法来选择对提交给标记(s)使用主动学习(AL) ，解决了传统 CJ 的关键缺陷。此外，我们还展示了整个方法如何提供透明度，为用户提供如何做出决策的洞察力，同时提高效率。实验结果表明，所提出的 BCJ 结合熵驱动的 AL 对选择方法优于其他方法。我们还发现，进行的比较越多，BCJ 的精度就越高，这解决了目前的方法存在的问题，如果进行太多的比较，模型的退化。由于我们的方法可以产生一个项目的完整的预测等级分布，我们也展示了如何使用这可以设计一个预测等级，由评估者指导。"
    },
    {
        "title": "Learning and Optimization of Implicit Negative Feedback for Industrial\n  Short-video Recommender System",
        "url": "http://arxiv.org/abs/2308.13249v1",
        "pub_date": "2023-08-25",
        "summary": "Short-video recommendation is one of the most important recommendation\napplications in today's industrial information systems. Compared with other\nrecommendation tasks, the enormous amount of feedback is the most typical\ncharacteristic. Specifically, in short-video recommendation, the\neasiest-to-collect user feedback is from the skipping behaviors, which leads to\ntwo critical challenges for the recommendation model. First, the skipping\nbehavior reflects implicit user preferences, and thus it is challenging for\ninterest extraction. Second, the kind of special feedback involves multiple\nobjectives, such as total watching time, which is also very challenging. In\nthis paper, we present our industrial solution in Kuaishou, which serves\nbillion-level users every day. Specifically, we deploy a feedback-aware\nencoding module which well extracts user preference taking the impact of\ncontext into consideration. We further design a multi-objective prediction\nmodule which well distinguishes the relation and differences among different\nmodel objectives in the short-video recommendation. We conduct extensive online\nA/B testing, along with detailed and careful analysis, which verifies the\neffectiveness of our solution.",
        "translated": "短视频推荐是当今工业信息系统中最重要的推荐应用之一。与其他推荐任务相比，大量的反馈是最典型的特征。具体来说，在短视频推荐中，最容易收集的用户反馈来自跳跃行为，这给推荐模型带来了两个关键的挑战。首先，跳跃行为反映了隐式用户偏好，因此对兴趣提取具有挑战性。其次，这种特殊的反馈涉及多个目标，如总观看时间，这也是非常具有挑战性的。在本文中，我们介绍了我们在 Kuaishou 的工业解决方案，这个方案每天为数十亿用户提供服务。具体来说，我们部署了一个反馈感知的编码模块，该模块在考虑上下文影响的情况下很好地提取了用户偏好。进一步设计了一个多目标预测模块，可以很好地区分短视频推荐中不同模型目标之间的关系和差异。我们进行了广泛的在线 A/B 测试，并进行了详细和仔细的分析，从而验证了我们的解决方案的有效性。"
    },
    {
        "title": "Optimizing Group-Fair Plackett-Luce Ranking Models for Relevance and\n  Ex-Post Fairness",
        "url": "http://arxiv.org/abs/2308.13242v1",
        "pub_date": "2023-08-25",
        "summary": "In learning-to-rank (LTR), optimizing only the relevance (or the expected\nranking utility) can cause representational harm to certain categories of\nitems. Moreover, if there is implicit bias in the relevance scores, LTR models\nmay fail to optimize for true relevance. Previous works have proposed efficient\nalgorithms to train stochastic ranking models that achieve fairness of exposure\nto the groups ex-ante (or, in expectation), which may not guarantee\nrepresentation fairness to the groups ex-post, that is, after realizing a\nranking from the stochastic ranking model. Typically, ex-post fairness is\nachieved by post-processing, but previous work does not train stochastic\nranking models that are aware of this post-processing.\n  In this paper, we propose a novel objective that maximizes expected relevance\nonly over those rankings that satisfy given representation constraints to\nensure ex-post fairness. Building upon recent work on an efficient sampler for\nex-post group-fair rankings, we propose a group-fair Plackett-Luce model and\nshow that it can be efficiently optimized for our objective in the LTR\nframework.\n  Experiments on three real-world datasets show that our group-fair algorithm\nguarantees fairness alongside usually having better relevance compared to the\nLTR baselines. In addition, our algorithm also achieves better relevance than\npost-processing baselines, which also ensures ex-post fairness. Further, when\nimplicit bias is injected into the training data, our algorithm typically\noutperforms existing LTR baselines in relevance.",
        "translated": "在学习排序(LTR)中，仅优化相关性(或期望排序效用)可能会对某些类别的项目造成代表性损害。此外，如果相关分数存在隐性偏差，LTR 模型可能无法优化真实相关性。以往的研究提出了训练随机排序模型的有效算法，这些算法在实现了随机排序模型的排序之后，可以实现对事前(或期望中)暴露于群体的公平性，但不能保证事后群体的表示公平性。通常情况下，事后公平是通过后处理来实现的，但是以前的工作并没有训练出能够意识到这种后处理的随机排序模型。在本文中，我们提出了一个新的目标，最大化期望相关性只有在那些排名满足给定的表示约束，以确保事后公平性。在最近的工作的基础上，我们提出了一个集团公平 Plackett-Luce 模型，并表明它可以有效地优化我们的目标在 LTR 框架。在三个实际数据集上的实验表明，我们的群体公平算法在保证公平性的同时，通常具有比 LTR 基线更好的相关性。此外，该算法还比后处理基线具有更好的相关性，同时也保证了后处理的公平性。此外，当隐式偏差注入到训练数据，我们的算法通常优于现有的 LTR 基线的相关性。"
    },
    {
        "title": "ChatGPT as Data Augmentation for Compositional Generalization: A Case\n  Study in Open Intent Detection",
        "url": "http://arxiv.org/abs/2308.13517v1",
        "pub_date": "2023-08-25",
        "summary": "Open intent detection, a crucial aspect of natural language understanding,\ninvolves the identification of previously unseen intents in user-generated\ntext. Despite the progress made in this field, challenges persist in handling\nnew combinations of language components, which is essential for compositional\ngeneralization. In this paper, we present a case study exploring the use of\nChatGPT as a data augmentation technique to enhance compositional\ngeneralization in open intent detection tasks. We begin by discussing the\nlimitations of existing benchmarks in evaluating this problem, highlighting the\nneed for constructing datasets for addressing compositional generalization in\nopen intent detection tasks. By incorporating synthetic data generated by\nChatGPT into the training process, we demonstrate that our approach can\neffectively improve model performance. Rigorous evaluation of multiple\nbenchmarks reveals that our method outperforms existing techniques and\nsignificantly enhances open intent detection capabilities. Our findings\nunderscore the potential of large language models like ChatGPT for data\naugmentation in natural language understanding tasks.",
        "translated": "开放意图检测是自然语言理解的一个重要方面，它涉及到在用户生成的文本中识别以前看不到的意图。尽管在这个领域取得了进展，但是在处理新的语言组件组合方面仍然存在挑战，这对于组合泛化是必不可少的。在本文中，我们提出了一个案例研究，探讨使用 ChatGPT 作为数据增强技术，以提高组合泛化的开放意图检测任务。我们首先讨论了现有基准在评估这个问题时的局限性，强调了在开放意图检测任务中构建数据集以解决组合泛化问题的必要性。通过将 ChatGPT 生成的合成数据整合到训练过程中，我们证明了我们的方法可以有效地提高模型的性能。对多个基准测试的严格评估表明，我们的方法优于现有技术，并显著提高了开放意图检测能力。我们的研究结果强调了像 ChatGPT 这样的大型语言模型在自然语言理解任务中用于数据增强的潜力。"
    },
    {
        "title": "Training and Meta-Evaluating Machine Translation Evaluation Metrics at\n  the Paragraph Level",
        "url": "http://arxiv.org/abs/2308.13506v1",
        "pub_date": "2023-08-25",
        "summary": "As research on machine translation moves to translating text beyond the\nsentence level, it remains unclear how effective automatic evaluation metrics\nare at scoring longer translations. In this work, we first propose a method for\ncreating paragraph-level data for training and meta-evaluating metrics from\nexisting sentence-level data. Then, we use these new datasets to benchmark\nexisting sentence-level metrics as well as train learned metrics at the\nparagraph level. Interestingly, our experimental results demonstrate that using\nsentence-level metrics to score entire paragraphs is equally as effective as\nusing a metric designed to work at the paragraph level. We speculate this\nresult can be attributed to properties of the task of reference-based\nevaluation as well as limitations of our datasets with respect to capturing all\ntypes of phenomena that occur in paragraph-level translations.",
        "translated": "随着机器翻译研究向超越句子水平的文本翻译发展，目前尚不清楚自动评估指标在评估较长翻译时的有效性。在这项工作中，我们首先提出了一种方法来创建段落级数据的训练和元评价指标从现有的句子级数据。然后，我们使用这些新的数据集来对现有的句子水平指标进行基准测试，并在段落水平上训练学习指标。有趣的是，我们的实验结果表明，使用句子级别的度量标准来评分整个段落与使用设计用于段落级别的度量标准同样有效。我们推测这个结果可以归因于基于参考的评估任务的特性以及我们的数据集在捕获段落级翻译中发生的所有类型的现象方面的局限性。"
    },
    {
        "title": "Ngambay-French Neural Machine Translation (sba-Fr)",
        "url": "http://arxiv.org/abs/2308.13497v1",
        "pub_date": "2023-08-25",
        "summary": "In Africa, and the world at large, there is an increasing focus on developing\nNeural Machine Translation (NMT) systems to overcome language barriers. NMT for\nLow-resource language is particularly compelling as it involves learning with\nlimited labelled data. However, obtaining a well-aligned parallel corpus for\nlow-resource languages can be challenging. The disparity between the\ntechnological advancement of a few global languages and the lack of research on\nNMT for local languages in Chad is striking. End-to-end NMT trials on\nlow-resource Chad languages have not been attempted. Additionally, there is a\ndearth of online and well-structured data gathering for research in Natural\nLanguage Processing, unlike some African languages. However, a guided approach\nfor data gathering can produce bitext data for many Chadian language\ntranslation pairs with well-known languages that have ample data. In this\nproject, we created the first sba-Fr Dataset, which is a corpus of\nNgambay-to-French translations, and fine-tuned three pre-trained models using\nthis dataset. Our experiments show that the M2M100 model outperforms other\nmodels with high BLEU scores on both original and original+synthetic data. The\npublicly available bitext dataset can be used for research purposes.",
        "translated": "在非洲乃至全世界，开发神经机器翻译(NMT)系统以克服语言障碍越来越受到重视。低资源语言的 NMT 尤其引人注目，因为它涉及到使用有限的标记数据进行学习。然而，为低资源语言获得一个良好对齐的并行语料库可能具有挑战性。一些全球语言的技术进步与乍得当地语言的国家语言管理缺乏研究之间的差距是惊人的。尚未尝试对资源匮乏的乍得语言进行 NMT 端到端试验。此外，与一些非洲语言不同，自然语言处理领域的研究缺乏在线和结构良好的数据收集。然而，数据收集的指导方法可以为许多乍得语言的翻译对生成双文本数据，这些翻译对使用的是具有大量数据的著名语言。在这个项目中，我们创建了第一个 sba-Fr 数据集，它是 Ngambay-to-French 翻译的语料库，并使用这个数据集对三个预先训练好的模型进行了微调。实验表明，M2M100模型在原始数据和原始 + 合成数据上均优于其他 BLEU 评分较高的模型。公开可用的双文本数据集可用于研究目的。"
    },
    {
        "title": "Prompting a Large Language Model to Generate Diverse Motivational\n  Messages: A Comparison with Human-Written Messages",
        "url": "http://arxiv.org/abs/2308.13479v1",
        "pub_date": "2023-08-25",
        "summary": "Large language models (LLMs) are increasingly capable and prevalent, and can\nbe used to produce creative content. The quality of content is influenced by\nthe prompt used, with more specific prompts that incorporate examples generally\nproducing better results. On from this, it could be seen that using\ninstructions written for crowdsourcing tasks (that are specific and include\nexamples to guide workers) could prove effective LLM prompts. To explore this,\nwe used a previous crowdsourcing pipeline that gave examples to people to help\nthem generate a collectively diverse corpus of motivational messages. We then\nused this same pipeline to generate messages using GPT-4, and compared the\ncollective diversity of messages from: (1) crowd-writers, (2) GPT-4 using the\npipeline, and (3 &amp; 4) two baseline GPT-4 prompts. We found that the LLM prompts\nusing the crowdsourcing pipeline caused GPT-4 to produce more diverse messages\nthan the two baseline prompts. We also discuss implications from messages\ngenerated by both human writers and LLMs.",
        "translated": "大型语言模型(LLM)越来越有能力和普遍，可以用来生成创造性的内容。内容的质量受所使用的提示的影响，更具体的提示包括通常产生更好结果的示例。从这一点可以看出，使用为众包任务编写的指令(具体并包括指导工人的例子)可以证明有效的 LLM 提示。为了探索这个问题，我们使用了以前的众包渠道，给人们提供了例子，帮助他们产生一个集体多样化的动机信息语料库。然后，我们使用相同的管道使用 GPT-4生成消息，并比较了来自以下方面的消息集合多样性: (1)群体作家，(2)使用管道的 GPT-4，(3 & 4)两个基线 GPT-4提示。我们发现，使用众包管道的 LLM 提示使 GPT-4产生比两个基线提示更多样化的信息。我们还讨论了由人类作者和 LLM 生成的消息的含义。"
    },
    {
        "title": "ARTIST: ARTificial Intelligence for Simplified Text",
        "url": "http://arxiv.org/abs/2308.13458v1",
        "pub_date": "2023-08-25",
        "summary": "Complex text is a major barrier for many citizens when accessing public\ninformation and knowledge. While often done manually, Text Simplification is a\nkey Natural Language Processing task that aims for reducing the linguistic\ncomplexity of a text while preserving the original meaning. Recent advances in\nGenerative Artificial Intelligence (AI) have enabled automatic text\nsimplification both on the lexical and syntactical levels. However, as\napplications often focus on English, little is understood about the\neffectiveness of Generative AI techniques on low-resource languages such as\nDutch. For this reason, we carry out empirical studies to understand the\nbenefits and limitations of applying generative technologies for text\nsimplification and provide the following outcomes: 1) the design and\nimplementation for a configurable text simplification pipeline that\norchestrates state-of-the-art generative text simplification models, domain and\nreader adaptation, and visualisation modules; 2) insights and lessons learned,\nshowing the strengths of automatic text simplification while exposing the\nchallenges in handling cultural and commonsense knowledge. These outcomes\nrepresent a first step in the exploration of Dutch text simplification and shed\nlight on future endeavours both for research and practice.",
        "translated": "复杂的文本是许多公民获取公共信息和知识的主要障碍。文本简化是自然语言处理中的一个关键任务，它的目标是在保持原始意义的同时降低文本的语言复杂性。生成性人工智能(AI)的最新进展使得词汇和句法层面的文本自动简化成为可能。然而，由于应用程序往往侧重于英语，对于生成 AI 技术在荷兰语等低资源语言上的有效性了解甚少。为此，我们进行了实证研究，以了解应用生成技术进行文本简化的好处和局限性，并提供以下结果: 1)可配置的文本简化流水线的设计和实施，协调国家的最先进的生成文本简化模型，领域和读者适应，和可视化模块; 2)见解和经验教训，显示自动文本简化的优势，同时揭示处理文化和常识知识的挑战。这些成果是探索荷兰案文简化的第一步，并为今后的研究和实践工作指明了方向。"
    },
    {
        "title": "The Poison of Alignment",
        "url": "http://arxiv.org/abs/2308.13449v1",
        "pub_date": "2023-08-25",
        "summary": "From the perspective of content safety issues, alignment has shown to limit\nlarge language models' (LLMs) harmful content generation. This intentional\nmethod of reinforcing models to not respond to certain user inputs seem to be\npresent in many modern open-source instruction tuning datasets such as\nOpenAssistant or Guanaco. We introduce a novel insight to an instruction-tuned\nmodel's performance affected by the presence of alignment in supervised\nfine-tuning dataset. To be specific, we noticed that alignment acts as if it is\npoisoning the instruction dataset. Experimentally, we demonstrate that aligned\nanswers significantly worsen the performance of the resulting fine-tuned\nmodel's on various reasoning benchmarks such as Big Bench (BBH), Massive\nMultitask Language Understanding (MMLU), Human Eval, and Discrete Reasoning\nOver Paragraphs (DROP), performing worse than the counterpart tuned without\nalignment by 4-33%.",
        "translated": "从内容安全问题的角度来看，对齐限制了大型语言模型(LLM)有害内容的生成。这种有意加强模型以不响应某些用户输入的方法似乎出现在许多现代开源指令调优数据集中，如 OpenAssistant 或 Guanaco。我们介绍了一个新的洞察指令调谐模型的性能影响的存在，在监督微调数据集。具体来说，我们注意到对齐的行为就好像是在毒害指令数据集。在实验中，我们证明了一致的答案显著地恶化了由此产生的微调模型在各种推理基准上的表现，例如 Big Bench (BBH) ，Massive MultitTask Language understand (MMLU) ，Human Eval，和 DROP (段落离散推理) ，表现比没有一致的对应者差4-33% 。"
    },
    {
        "title": "EntropyRank: Unsupervised Keyphrase Extraction via Side-Information\n  Optimization for Language Model-based Text Compression",
        "url": "http://arxiv.org/abs/2308.13399v1",
        "pub_date": "2023-08-25",
        "summary": "We propose an unsupervised method to extract keywords and keyphrases from\ntexts based on a pre-trained language model (LM) and Shannon's information\nmaximization. Specifically, our method extracts phrases having the highest\nconditional entropy under the LM. The resulting set of keyphrases turns out to\nsolve a relevant information-theoretic problem: if provided as side\ninformation, it leads to the expected minimal binary code length in compressing\nthe text using the LM and an entropy encoder. Alternately, the resulting set is\nan approximation via a causal LM to the set of phrases that minimize the\nentropy of the text when conditioned upon it. Empirically, the method provides\nresults comparable to the most commonly used methods in various keyphrase\nextraction benchmark challenges.",
        "translated": "提出了一种基于预训练语言模型(LM)和 Shannon 信息最大化的无监督关键词和关键词提取方法。具体来说，我们的方法提取的短语具有最高的条件熵。最终得到的关键词集合解决了一个相关的信息理论问题: 如果作为边信息提供，它将导致使用 LM 和熵编码器压缩文本时所期望的最小二进制码长度。或者，结果集是通过一个因果 LM 近似到一组短语，最小化的熵的文本时，它的条件。根据经验，该方法提供的结果与各种关键词提取基准测试中最常用的方法相当。"
    },
    {
        "title": "Do-Not-Answer: A Dataset for Evaluating Safeguards in LLMs",
        "url": "http://arxiv.org/abs/2308.13387v1",
        "pub_date": "2023-08-25",
        "summary": "With the rapid evolution of large language models (LLMs), new and\nhard-to-predict harmful capabilities are emerging. This requires developers to\nbe able to identify risks through the evaluation of \"dangerous capabilities\" in\norder to responsibly deploy LLMs. In this work, we collect the first\nopen-source dataset to evaluate safeguards in LLMs, and deploy safer\nopen-source LLMs at a low cost. Our dataset is curated and filtered to consist\nonly of instructions that responsible language models should not follow. We\nannotate and assess the responses of six popular LLMs to these instructions.\nBased on our annotation, we proceed to train several BERT-like classifiers, and\nfind that these small classifiers can achieve results that are comparable with\nGPT-4 on automatic safety evaluation. Warning: this paper contains example data\nthat may be offensive, harmful, or biased.",
        "translated": "随着大型语言模型(LLM)的迅速发展，新的难以预测的有害功能正在出现。这要求开发人员能够通过评估“危险能力”来识别风险，以便负责任地部署 LLM。在这项工作中，我们收集了第一个开源数据集来评估 LLM 中的安全措施，并以较低的成本部署更安全的开源 LLM。我们的数据集被精心策划和过滤，以便只包含负责任的语言模型不应该遵循的指令。我们注释并评估六个流行的 LLM 对这些指令的响应。在此基础上，我们对几个类 BERT 分类器进行了训练，发现这些小分类器在自动安全性评价方面可以取得与 GPT-4相当的结果。警告: 本文包含的示例数据可能是冒犯性的、有害的或有偏见的。"
    },
    {
        "title": "Assessing Keyness using Permutation Tests",
        "url": "http://arxiv.org/abs/2308.13383v1",
        "pub_date": "2023-08-25",
        "summary": "We propose a resampling-based approach for assessing keyness in corpus\nlinguistics based on suggestions by Gries (2006, 2022). Traditional approaches\nbased on hypothesis tests (e.g. Likelihood Ratio) model the copora as\nindependent identically distributed samples of tokens. This model does not\naccount for the often observed uneven distribution of occurences of a word\nacross a corpus. When occurences of a word are concentrated in few documents,\nlarge values of LLR and similar scores are in fact much more likely than\naccounted for by the token-by-token sampling model, leading to false positives.\n  We replace the token-by-token sampling model by a model where corpora are\nsamples of documents rather than tokens, which is much closer to the way\ncorpora are actually assembled. We then use a permutation approach to\napproximate the distribution of a given keyness score under the null hypothesis\nof equal frequencies and obtain p-values for assessing significance. We do not\nneed any assumption on how the tokens are organized within or across documents,\nand the approach works with basically *any* keyness score. Hence, appart from\nobtaining more accurate p-values for scores like LLR, we can also assess\nsignificance for e.g. the logratio which has been proposed as a measure of\neffect size.\n  An efficient implementation of the proposed approach is provided in the `R`\npackage `keyperm` available from github.",
        "translated": "根据格里斯的建议，我们提出了一种基于重采样的方法来评估文本语料库的关键性(2006,2022)。传统的基于假设检验的方法(如似然比)把协变量作为标记的独立同分布样本进行建模。这个模型没有考虑到经常观察到的一个词在语料库中出现的不均匀分布。当一个单词的出现集中在少数文档中时，大的 LLR 值和类似的分数实际上比逐字令牌抽样模型更有可能导致误报。我们用一个语料库是文档样本而不是令牌样本的模型来代替逐令牌抽样模型，这种模型更接近语料库的实际组装方式。然后，在等频率的无效假设下，我们使用排列方法来近似给定关键度分数的分布，并获得用于评估显著性的 p 值。我们不需要任何关于令牌如何在文档内或跨文档组织的假设，并且该方法基本上可以使用任何 * keyness 评分。因此，除了为 LLR 这样的分数获得更准确的 p 值之外，我们还可以评估显着性，例如作为效应大小度量的偏移量。在 github 提供的‘ R’包‘ keyperm’中提供了所提出方法的有效实现。"
    },
    {
        "title": "TRIVEA: Transparent Ranking Interpretation using Visual Explanation of\n  Black-Box Algorithmic Rankers",
        "url": "http://arxiv.org/abs/2308.14622v1",
        "pub_date": "2023-08-28",
        "summary": "Ranking schemes drive many real-world decisions, like, where to study, whom\nto hire, what to buy, etc. Many of these decisions often come with high\nconsequences. For example, a university can be deemed less prestigious if not\nfeatured in a top-k list, and consumers might not even explore products that do\nnot get recommended to buyers. At the heart of most of these decisions are\nopaque ranking schemes, which dictate the ordering of data entities, but their\ninternal logic is inaccessible or proprietary. Drawing inferences about the\nranking differences is like a guessing game to the stakeholders, like, the\nrankees (i.e., the entities who are ranked, like product companies) and the\ndecision-makers (i.e., who use the rankings, like buyers). In this paper, we\naim to enable transparency in ranking interpretation by using algorithmic\nrankers that learn from available data and by enabling human reasoning about\nthe learned ranking differences using explainable AI (XAI) methods. To realize\nthis aim, we leverage the exploration-explanation paradigm of human-data\ninteraction to let human stakeholders explore subsets and groupings of complex\nmulti-attribute ranking data using visual explanations of model fit and\nattribute influence on rankings. We realize this explanation paradigm for\ntransparent ranking interpretation in TRIVEA, a visual analytic system that is\nfueled by: i) visualizations of model fit derived from algorithmic rankers that\nlearn the associations between attributes and rankings from available data and\nii) visual explanations derived from XAI methods that help abstract important\npatterns, like, the relative influence of attributes in different ranking\nranges. Using TRIVEA, end users not trained in data science have the agency to\ntransparently reason about the global and local behavior of the rankings\nwithout the need to open black-box ranking models and develop confidence in the\nresulting attribute-based inferences. We demonstrate the efficacy of TRIVEA\nusing multiple usage scenarios and subjective feedback from researchers with\ndiverse domain expertise. Keywords: Visual Analytics, Learning-to-Rank,\nExplainable ML, Ranking",
        "translated": "排名方案驱动着许多现实世界的决定，比如，在哪里学习，雇佣谁，买什么等等。许多这样的决定往往伴随着严重的后果。例如，一所大学如果没有进入前 K 名单，就可能被认为不那么有声望，消费者甚至可能不会去探索那些没有被推荐给买家的产品。这些决策的核心是不透明的排序方案，它们规定了数据实体的顺序，但是它们的内部逻辑是不可访问的或专有的。对于利益相关者来说，对排名差异进行推断就像是猜谜游戏，比如，排名(也就是被排名的实体，比如产品公司)和决策者(也就是使用排名的实体，比如买家)。在本文中，我们的目标是通过使用算法排名学习可用的数据和使人类推理学习排名差异使排名解释透明度使用可解释的人工智能(XAI)方法。为了实现这一目标，我们利用人-数据交互的探索-解释范式，让人类利益相关者利用模型拟合和属性对排名影响的可视化解释来探索复杂多属性排名数据的子集和分组。在 TRIVEA，我们意识到了透明排名解释的这种解释范式，这是一个视觉分析系统，其推动力来自: i)来自算法排名的模型拟合可视化，从可用数据中学习属性和排名之间的关联; ii)来自 XAI 方法的视觉解释，帮助抽象重要模式，如不同排名范围中属性的相对影响。使用 TRIVEA，没有接受过数据科学培训的终端用户可以透明地对排名的全球和本地行为进行推理，而不需要打开黑盒排名模型，并建立对结果基于属性的推断的信心。我们使用多种使用场景和来自不同领域专家的主观反馈证明了 TRIVEA 的有效性。关键词: 可视化分析，学习排名，可解释的机器学习，排名"
    },
    {
        "title": "Fairness Through Domain Awareness: Mitigating Popularity Bias For Music\n  Discovery",
        "url": "http://arxiv.org/abs/2308.14601v1",
        "pub_date": "2023-08-28",
        "summary": "As online music platforms grow, music recommender systems play a vital role\nin helping users navigate and discover content within their vast musical\ndatabases. At odds with this larger goal, is the presence of popularity bias,\nwhich causes algorithmic systems to favor mainstream content over, potentially\nmore relevant, but niche items. In this work we explore the intrinsic\nrelationship between music discovery and popularity bias. To mitigate this\nissue we propose a domain-aware, individual fairness-based approach which\naddresses popularity bias in graph neural network (GNNs) based recommender\nsystems. Our approach uses individual fairness to reflect a ground truth\nlistening experience, i.e., if two songs sound similar, this similarity should\nbe reflected in their representations. In doing so, we facilitate meaningful\nmusic discovery that is robust to popularity bias and grounded in the music\ndomain. We apply our BOOST methodology to two discovery based tasks, performing\nrecommendations at both the playlist level and user level. Then, we ground our\nevaluation in the cold start setting, showing that our approach outperforms\nexisting fairness benchmarks in both performance and recommendation of\nlesser-known content. Finally, our analysis explains why our proposed\nmethodology is a novel and promising approach to mitigating popularity bias and\nimproving the discovery of new and niche content in music recommender systems.",
        "translated": "随着在线音乐平台的发展，音乐推荐系统在帮助用户浏览和发现其庞大的音乐数据库中的内容方面发挥着至关重要的作用。与这个更大的目标不一致的是流行偏见的存在，它导致算法系统偏爱主流内容，而不是潜在的更相关的，但是小众的项目。在这项工作中，我们探讨音乐发现和流行偏见之间的内在关系。为了解决这一问题，我们提出了一种基于领域感知的、基于个体公平性的方法，该方法解决了基于图神经网络(GNN)的推荐系统中的流行偏差问题。我们的方法使用个人的公平性来反映一个基本的真理倾听经验，也就是说，如果两首歌听起来相似，这种相似性应该反映在他们的表述中。这样做，我们促进了有意义的音乐发现，这是强大的流行偏见，并在音乐领域的基础。我们将 BOOST 方法应用于两个基于发现的任务，在播放列表级别和用户级别执行建议。然后，我们在冷启动环境下进行评估，结果表明我们的方法在性能和推荐不太知名的内容方面都优于现有的公平性基准。最后，我们的分析解释了为什么我们提出的方法是一个新颖和有前途的方法，以减少流行偏见和改善发现新的和利基内容的音乐推荐系统。"
    },
    {
        "title": "Efficient and Accurate Tree Detection from 3D Point Clouds through Paid\n  Crowdsourcing",
        "url": "http://arxiv.org/abs/2308.14499v1",
        "pub_date": "2023-08-28",
        "summary": "Accurate tree detection is of growing importance in applications such as\nurban planning, forest inventory, and environmental monitoring. In this\narticle, we present an approach to creating tree maps by annotating them in 3D\npoint clouds. Point cloud representations allow the precise identification of\ntree positions, particularly stem locations, and their heights. Our method\nleverages human computational power through paid crowdsourcing, employing a web\ntool designed to enable even non-experts to effectively tackle the task. The\nprimary focus of this paper is to discuss the web tool's development and\nstrategies to ensure high-quality tree annotations despite encountering noise\nin the crowdsourced data. Following our methodology, we achieve quality\nmeasures surpassing 90% for various challenging test sets of diverse\ncomplexities. We emphasize that our tree map creation process, including\ninitial point cloud collection, can be completed within 1-2 days.",
        "translated": "精确的树木检测在城市规划、森林调查和环境监测等方面的应用越来越重要。在本文中，我们提出了一种通过在3D 点云中注释来创建树图的方法。点云表示允许精确识别树木位置，特别是树干位置及其高度。我们的方法通过付费众包利用人类的计算能力，使用一个网络工具，即使是非专家也可以有效地处理任务。本文的主要目的是讨论在众包数据中遇到噪声的情况下，如何开发和实现高质量的树注释。按照我们的方法，我们为不同复杂性的各种具有挑战性的测试集实现了超过90% 的质量测量。我们强调，我们的树图创建过程，包括初始点云收集，可以在1-2天内完成。"
    },
    {
        "title": "Bridging the KB-Text Gap: Leveraging Structured Knowledge-aware\n  Pre-training for KBQA",
        "url": "http://arxiv.org/abs/2308.14436v1",
        "pub_date": "2023-08-28",
        "summary": "Knowledge Base Question Answering (KBQA) aims to answer natural language\nquestions with factual information such as entities and relations in KBs.\nHowever, traditional Pre-trained Language Models (PLMs) are directly\npre-trained on large-scale natural language corpus, which poses challenges for\nthem in understanding and representing complex subgraphs in structured KBs. To\nbridge the gap between texts and structured KBs, we propose a Structured\nKnowledge-aware Pre-training method (SKP). In the pre-training stage, we\nintroduce two novel structured knowledge-aware tasks, guiding the model to\neffectively learn the implicit relationship and better representations of\ncomplex subgraphs. In downstream KBQA task, we further design an efficient\nlinearization strategy and an interval attention mechanism, which assist the\nmodel to better encode complex subgraphs and shield the interference of\nirrelevant subgraphs during reasoning respectively. Detailed experiments and\nanalyses on WebQSP verify the effectiveness of SKP, especially the significant\nimprovement in subgraph retrieval (+4.08% H@10).",
        "translated": "知识库问题解答(KBQA)的目的是利用知识库中的实体和关系等事实信息来回答自然语言问题。然而，传统的预训练语言模型直接在大规模的自然语言语料库上进行预训练，这对它们在结构化知识库中理解和表示复杂子图提出了挑战。为了弥合文本和结构化知识库之间的差距，我们提出了一种结构化知识感知的预训练方法(SKP)。在预训练阶段，我们引入了两个新的结构化知识感知任务，引导模型有效地学习复杂子图的隐含关系和更好的表示。在后续的 KBQA 任务中，我们进一步设计了有效的线性化策略和区间注意机制，分别帮助模型更好地编码复杂子图和屏蔽推理过程中不相关子图的干扰。通过对 WebQSP 的详细实验和分析，验证了 SKP 的有效性，尤其是子图检索的显著改善(+ 4.08% H@10)。"
    },
    {
        "title": "Can Transformer and GNN Help Each Other?",
        "url": "http://arxiv.org/abs/2308.14355v1",
        "pub_date": "2023-08-28",
        "summary": "Although Transformer has achieved great success in natural language process\nand computer vision, it has difficulty generalizing to medium and large-scale\ngraph data for two important reasons: (i) High complexity. (ii) Failing to\ncapture the complex and entangled structure information. In graph\nrepresentation learning, Graph Neural Networks(GNNs) can fuse the graph\nstructure and node attributes but have limited receptive fields. Therefore, we\nquestion whether can we combine Transformers and GNNs to help each other. In\nthis paper, we propose a new model named TransGNN where the Transformer layer\nand GNN layer are used alternately to improve each other. Specifically, to\nexpand the receptive field and disentangle the information aggregation from\nedges, we propose using Transformer to aggregate more relevant nodes'\ninformation to improve the message passing of GNNs. Besides, to capture the\ngraph structure information, we utilize positional encoding and make use of the\nGNN layer to fuse the structure into node attributes, which improves the\nTransformer in graph data. We also propose to sample the most relevant nodes\nfor Transformer and two efficient samples update strategies to lower the\ncomplexity. At last, we theoretically prove that TransGNN is more expressive\nthan GNNs only with extra linear complexity. The experiments on eight datasets\ncorroborate the effectiveness of TransGNN on node and graph classification\ntasks.",
        "translated": "变压器在自然语言处理和计算机视觉方面取得了巨大的成功，但由于两个重要原因，变压器难以推广到中大规模的图形数据: (1)复杂度高。(ii)未能捕捉到复杂和纠缠的结构信息。在图表示学习中，图神经网络能够融合图的结构和节点属性，但接受域有限。因此，我们质疑我们是否可以结合变形金刚和 GNN 来互相帮助。在本文中，我们提出了一个新的模型 TransGNN，其中变压器层和 GNN 层交替使用，以改善对方。具体来说，为了扩展接收域，解决信息聚合与边的分离问题，我们提出了使用 Transformer 来聚合更多相关节点的信息，以改善 GNN 的消息传递。此外，为了获取图的结构信息，我们利用位置编码，利用 GNN 层将结构融合到节点属性中，从而提高了图数据的转换效率。我们还提出了采样变压器最相关的节点和两个有效的样本更新策略，以降低复杂性。最后，我们从理论上证明了 TransGNN 比 GNN 具有更高的线性复杂度。在8个数据集上的实验证实了 TransGNN 在节点和图分类任务上的有效性。"
    },
    {
        "title": "Fine-Tuning Llama 2 Large Language Models for Detecting Online Sexual\n  Predatory Chats and Abusive Texts",
        "url": "http://arxiv.org/abs/2308.14683v1",
        "pub_date": "2023-08-28",
        "summary": "Detecting online sexual predatory behaviours and abusive language on social\nmedia platforms has become a critical area of research due to the growing\nconcerns about online safety, especially for vulnerable populations such as\nchildren and adolescents. Researchers have been exploring various techniques\nand approaches to develop effective detection systems that can identify and\nmitigate these risks. Recent development of large language models (LLMs) has\nopened a new opportunity to address this problem more effectively. This paper\nproposes an approach to detection of online sexual predatory chats and abusive\nlanguage using the open-source pretrained Llama 2 7B-parameter model, recently\nreleased by Meta GenAI. We fine-tune the LLM using datasets with different\nsizes, imbalance degrees, and languages (i.e., English, Roman Urdu and Urdu).\nBased on the power of LLMs, our approach is generic and automated without a\nmanual search for a synergy between feature extraction and classifier design\nsteps like conventional methods in this domain. Experimental results show a\nstrong performance of the proposed approach, which performs proficiently and\nconsistently across three distinct datasets with five sets of experiments. This\nstudy's outcomes indicate that the proposed method can be implemented in\nreal-world applications (even with non-English languages) for flagging sexual\npredators, offensive or toxic content, hate speech, and discriminatory language\nin online discussions and comments to maintain respectful internet or digital\ncommunities. Furthermore, it can be employed for solving text classification\nproblems with other potential applications such as sentiment analysis, spam and\nphishing detection, sorting legal documents, fake news detection, language\nidentification, user intent recognition, text-based product categorization,\nmedical record analysis, and resume screening.",
        "translated": "由于人们日益关注网络安全，特别是儿童和青少年等弱势群体的网络安全，在社交媒体平台上发现网上性掠夺行为和辱骂性语言已成为一个关键的研究领域。研究人员一直在探索各种技术和方法，以开发能够识别和减轻这些风险的有效检测系统。大型语言模型(LLM)的最新发展为更有效地解决这一问题提供了新的机遇。本文提出了一种利用 Meta GenAI 最近发布的开源预训练的美洲驼27B 参数模型来检测网上性侵犯聊天和侮辱性语言的方法。我们使用不同大小、不平衡程度和语言(即英语、罗马乌尔都语和乌尔都语)的数据集对 LLM 进行微调。基于 LLM 的强大功能，我们的方法是通用的和自动化的，没有手动搜索之间的协同特征提取和分类器设计步骤，如传统的方法在这个领域。实验结果表明，该方法具有很强的性能，能够在三个不同的数据集上通过五组实验来熟练地、一致地执行。这项研究的结果表明，提出的方法可以实施在现实世界的应用程序(甚至与非英语语言)标记性侵犯者，攻击性或有毒内容，仇恨言论，歧视性语言的在线讨论和评论，以维持尊重互联网或数字社区。此外，它还可以用于解决其他潜在应用如情感分析、垃圾邮件和钓鱼检测、法律文件分类、假新闻检测、语言识别、用户意图识别、基于文本的产品分类、病历分析和简历筛选等文本分类问题。"
    },
    {
        "title": "ANER: Arabic and Arabizi Named Entity Recognition using\n  Transformer-Based Approach",
        "url": "http://arxiv.org/abs/2308.14669v1",
        "pub_date": "2023-08-28",
        "summary": "One of the main tasks of Natural Language Processing (NLP), is Named Entity\nRecognition (NER). It is used in many applications and also can be used as an\nintermediate step for other tasks. We present ANER, a web-based named entity\nrecognizer for the Arabic, and Arabizi languages. The model is built upon BERT,\nwhich is a transformer-based encoder. It can recognize 50 different entity\nclasses, covering various fields. We trained our model on the WikiFANE\\_Gold\ndataset which consists of Wikipedia articles. We achieved an F1 score of\n88.7\\%, which beats CAMeL Tools' F1 score of 83\\% on the ANERcorp dataset,\nwhich has only 4 classes. We also got an F1 score of 77.7\\% on the\nNewsFANE\\_Gold dataset which contains out-of-domain data from News articles.\nThe system is deployed on a user-friendly web interface that accepts users'\ninputs in Arabic, or Arabizi. It allows users to explore the entities in the\ntext by highlighting them. It can also direct users to get information about\nentities through Wikipedia directly. We added the ability to do NER using our\nmodel, or CAMeL Tools' model through our website. ANER is publicly accessible\nat \\url{http://www.aner.online}. We also deployed our model on HuggingFace at\nhttps://huggingface.co/boda/ANER, to allow developers to test and use it.",
        "translated": "自然语言处理(NLP)的主要任务之一是命名实体识别(NER)。它在许多应用程序中使用，也可以用作其他任务的中间步骤。我们介绍了 ANER，一个基于网络的阿拉伯语和阿拉伯语命名实体识别器。该模型是建立在 BERT 基础上的，BERT 是一种基于变压器的编码器。它可以识别50个不同的实体类，涵盖不同的领域。我们在由 Wikipedia 文章组成的 WikiFANE _ Gold 数据集上训练我们的模型。我们获得了88.7% 的 F1评分，这打败了 CAMEL 工具在 ANERcorp 数据集上的83% 的 F1评分，ANERcorp 数据集只有4个类。我们还在 NewsFANE _ Gold 数据集中获得了77.7% 的 F1得分，该数据集包含来自 News 文章的域外数据。该系统部署在一个用户友好的网络界面，接受用户的输入阿拉伯语，或阿拉伯语。它允许用户通过突出显示文本中的实体来浏览它们。它还可以指导用户直接通过 Wikipedia 获取有关实体的信息。我们增加了能力做 NER 使用我们的模型，或 CAMEL 工具的模型通过我们的网站。ANER 可以通过 url { http://www.ANER.online }公开访问。我们还在 HuggingFace  https://HuggingFace.co/boda/aner 部署了我们的模型，以允许开发人员测试和使用它。"
    },
    {
        "title": "Joint Multiple Intent Detection and Slot Filling with Supervised\n  Contrastive Learning and Self-Distillation",
        "url": "http://arxiv.org/abs/2308.14654v1",
        "pub_date": "2023-08-28",
        "summary": "Multiple intent detection and slot filling are two fundamental and crucial\ntasks in spoken language understanding. Motivated by the fact that the two\ntasks are closely related, joint models that can detect intents and extract\nslots simultaneously are preferred to individual models that perform each task\nindependently. The accuracy of a joint model depends heavily on the ability of\nthe model to transfer information between the two tasks so that the result of\none task can correct the result of the other. In addition, since a joint model\nhas multiple outputs, how to train the model effectively is also challenging.\nIn this paper, we present a method for multiple intent detection and slot\nfilling by addressing these challenges. First, we propose a bidirectional joint\nmodel that explicitly employs intent information to recognize slots and slot\nfeatures to detect intents. Second, we introduce a novel method for training\nthe proposed joint model using supervised contrastive learning and\nself-distillation. Experimental results on two benchmark datasets MixATIS and\nMixSNIPS show that our method outperforms state-of-the-art models in both\ntasks. The results also demonstrate the contributions of both bidirectional\ndesign and the training method to the accuracy improvement. Our source code is\navailable at https://github.com/anhtunguyen98/BiSLU",
        "translated": "多意图检测和时隙填充是口语理解中的两个基本和关键的任务。由于这两个任务密切相关，能够同时检测意图和提取时隙的联合模型优于独立执行每个任务的单个模型。联合模型的准确性在很大程度上取决于模型在两个任务之间传递信息的能力，以便一个任务的结果能够纠正另一个任务的结果。另外，由于联合模型具有多个输出，如何有效地训练模型也是一个挑战。在本文中，我们提出了一种多意图检测和槽填充的方法，以解决这些挑战。首先，我们提出了一个双向联合模型，该模型显式地利用意图信息来识别插槽和插槽特征来检测意图。其次，提出了一种基于监督对比学习和自精馏的联合模型训练方法。在两个基准数据集 MixATIS 和 MixSNIPS 上的实验结果表明，该方法在这两个任务中的性能都优于最先进的模型。结果还表明了双向设计和训练方法对提高精度的贡献。我们的源代码可以在 https://github.com/anhtunguyen98/bislu 找到"
    },
    {
        "title": "Challenges of GPT-3-based Conversational Agents for Healthcare",
        "url": "http://arxiv.org/abs/2308.14641v2",
        "pub_date": "2023-08-28",
        "summary": "The potential to provide patients with faster information access while\nallowing medical specialists to concentrate on critical tasks makes medical\ndomain dialog agents appealing. However, the integration of large-language\nmodels (LLMs) into these agents presents certain limitations that may result in\nserious consequences. This paper investigates the challenges and risks of using\nGPT-3-based models for medical question-answering (MedQA). We perform several\nevaluations contextualized in terms of standard medical principles. We provide\na procedure for manually designing patient queries to stress-test high-risk\nlimitations of LLMs in MedQA systems. Our analysis reveals that LLMs fail to\nrespond adequately to these queries, generating erroneous medical information,\nunsafe recommendations, and content that may be considered offensive.",
        "translated": "为病人提供更快速的信息访问，同时允许医疗专家集中精力处理关键任务的潜力使得医疗领域对话代理具有吸引力。然而，将大语言模型(LLM)集成到这些代理中会带来一定的局限性，这可能会导致严重的后果。本文调查了使用基于 GPT-3的模型进行医学问答(MedQA)的挑战和风险。我们根据标准医学原则进行了几项评估。我们提供了一个手动设计患者查询的程序，以压力测试 MedQA 系统中 LLM 的高风险限制。我们的分析表明 LLM 没有对这些查询作出充分的响应，产生了错误的医疗信息、不安全的建议和可能被认为是冒犯性的内容。"
    },
    {
        "title": "Breaking the Bank with ChatGPT: Few-Shot Text Classification for Finance",
        "url": "http://arxiv.org/abs/2308.14634v1",
        "pub_date": "2023-08-28",
        "summary": "We propose the use of conversational GPT models for easy and quick few-shot\ntext classification in the financial domain using the Banking77 dataset. Our\napproach involves in-context learning with GPT-3.5 and GPT-4, which minimizes\nthe technical expertise required and eliminates the need for expensive GPU\ncomputing while yielding quick and accurate results. Additionally, we fine-tune\nother pre-trained, masked language models with SetFit, a recent contrastive\nlearning technique, to achieve state-of-the-art results both in full-data and\nfew-shot settings. Our findings show that querying GPT-3.5 and GPT-4 can\noutperform fine-tuned, non-generative models even with fewer examples. However,\nsubscription fees associated with these solutions may be considered costly for\nsmall organizations. Lastly, we find that generative models perform better on\nthe given task when shown representative samples selected by a human expert\nrather than when shown random ones. We conclude that a) our proposed methods\noffer a practical solution for few-shot tasks in datasets with limited label\navailability, and b) our state-of-the-art results can inspire future work in\nthe area.",
        "translated": "我们建议使用会话 GPT 模型，在金融领域使用 Banking77数据集进行简单快速的短镜头文本分类。我们的方法包括使用 GPT-3.5和 GPT-4进行上下文学习，这最大限度地减少了所需的技术专业知识，并消除了对昂贵的 GPU 计算的需求，同时产生了快速和准确的结果。此外，我们微调其他预先训练，掩盖语言模型与 SetFit，一个最近的对比学习技术，以实现国家的最先进的结果，在全数据和少拍摄设置。我们的研究结果表明，查询 GPT-3.5和 GPT-4即使使用更少的示例，其性能也会优于经过微调的非生成模型。然而，与这些解决方案相关的订阅费用对于小型组织来说可能被认为是昂贵的。最后，我们发现生成模型在人类专家选择的具有代表性的样本中比随机样本中表现得更好。我们的结论是: a)我们提出的方法提供了一个实用的解决方案，在有限的数据集拍摄任务的标签可用性，b)我们的国家的最先进的结果可以激励未来的工作在这个领域。"
    },
    {
        "title": "AI in the Gray: Exploring Moderation Policies in Dialogic Large Language\n  Models vs. Human Answers in Controversial Topics",
        "url": "http://arxiv.org/abs/2308.14608v1",
        "pub_date": "2023-08-28",
        "summary": "The introduction of ChatGPT and the subsequent improvement of Large Language\nModels (LLMs) have prompted more and more individuals to turn to the use of\nChatBots, both for information and assistance with decision-making. However,\nthe information the user is after is often not formulated by these ChatBots\nobjectively enough to be provided with a definite, globally accepted answer.\n  Controversial topics, such as \"religion\", \"gender identity\", \"freedom of\nspeech\", and \"equality\", among others, can be a source of conflict as partisan\nor biased answers can reinforce preconceived notions or promote disinformation.\nBy exposing ChatGPT to such debatable questions, we aim to understand its level\nof awareness and if existing models are subject to socio-political and/or\neconomic biases. We also aim to explore how AI-generated answers compare to\nhuman ones. For exploring this, we use a dataset of a social media platform\ncreated for the purpose of debating human-generated claims on polemic subjects\namong users, dubbed Kialo.\n  Our results show that while previous versions of ChatGPT have had important\nissues with controversial topics, more recent versions of ChatGPT\n(gpt-3.5-turbo) are no longer manifesting significant explicit biases in\nseveral knowledge areas. In particular, it is well-moderated regarding economic\naspects. However, it still maintains degrees of implicit libertarian leaning\ntoward right-winged ideals which suggest the need for increased moderation from\nthe socio-political point of view. In terms of domain knowledge on\ncontroversial topics, with the exception of the \"Philosophical\" category,\nChatGPT is performing well in keeping up with the collective human level of\nknowledge. Finally, we see that sources of Bing AI have slightly more tendency\nto the center when compared to human answers. All the analyses we make are\ngeneralizable to other types of biases and domains.",
        "translated": "ChatGPT 的引入和随后对大型语言模型(LLM)的改进促使越来越多的人转向使用 ChatBots，以获取信息和帮助决策。然而，用户所需要的信息通常不是由这些聊天机器人客观地制定的，不足以提供一个明确的、全球公认的答案。有争议的话题，如“宗教”、“性别认同”、“言论自由”和“平等”等，可能成为冲突的根源，因为党派或有偏见的答案可能会强化先入为主的观念或助长虚假信息。通过让 ChatGPT 接触这些有争议的问题，我们旨在了解其认识水平，以及现有模式是否受到社会政治和/或经济偏见的影响。我们还打算探索人工智能生成的答案与人类的答案之间的比较。为了探索这个问题，我们使用了一个社交媒体平台的数据集，该平台被命名为 Kialo，目的是对用户之间的争论话题进行辩论。我们的研究结果表明，虽然以前版本的 ChatGPT 在有争议的话题上存在重要问题，但是最近版本的 ChatGPT (gpt-3.5-turbo)在几个知识领域不再显示出明显的偏见。特别是，在经济方面，它是很有节制的。然而，它仍然保持着一定程度的隐性自由意志主义倾向于右翼理想，这表明从社会政治的角度来看，需要增加温和。就有争议话题的领域知识而言，除了“哲学”范畴外，ChatGPT 在与人类集体知识水平保持一致方面表现良好。最后，我们看到，与人类的答案相比，Bing AI 的来源稍微更倾向于中心。我们所做的所有分析都可以推广到其他类型的偏差和领域。"
    },
    {
        "title": "Spoken Language Intelligence of Large Language Models for Language\n  Learning",
        "url": "http://arxiv.org/abs/2308.14536v1",
        "pub_date": "2023-08-28",
        "summary": "People have long hoped for a conversational system that can assist in\nreal-life situations, and recent progress on large language models (LLMs) is\nbringing this idea closer to reality. While LLMs are often impressive in\nperformance, their efficacy in real-world scenarios that demand expert\nknowledge remains unclear. LLMs are believed to hold the most potential and\nvalue in education, especially in the development of Artificial intelligence\n(AI) based virtual teachers capable of facilitating language learning. Our\nfocus is centered on evaluating the efficacy of LLMs in the realm of education,\nspecifically in the areas of spoken language learning which encompass\nphonetics, phonology, and second language acquisition. We introduce a new\nmultiple-choice question dataset to evaluate the effectiveness of LLMs in the\naforementioned scenarios, including understanding and application of spoken\nlanguage knowledge. In addition, we investigate the influence of various\nprompting techniques such as zero- and few-shot method (prepending the question\nwith question-answer exemplars), chain-of-thought (CoT, think step-by-step),\nin-domain exampler and external tools (Google, Wikipedia). We conducted\nlarge-scale evaluation on popular LLMs (20 distinct models) using these\nmethods. We achieved significant performance improvements compared to the\nzero-shot baseline in the practical questions reasoning (GPT-3.5, 49.1% -&gt;\n63.1%; LLaMA2-70B-Chat, 42.2% -&gt; 48.6%). We found that models of different\nsizes have good understanding of concepts in phonetics, phonology, and second\nlanguage acquisition, but show limitations in reasoning for real-world\nproblems. Additionally, we also explore preliminary findings on conversational\ncommunication.",
        "translated": "长期以来，人们一直希望有一个能够在现实生活中提供帮助的会话系统，而最近在大型语言模型(LLM)方面的进展使这一想法更接近现实。虽然 LLM 在性能方面往往令人印象深刻，但它们在需要专家知识的现实世界场景中的功效仍不清楚。LLM 被认为在教育领域最具潜力和价值，尤其是在开发基于人工智能(AI)的虚拟教师以促进语言学习方面。我们的重点是评估 LLM 在教育领域的功效，特别是在包括语音学、音韵学和第二语言习得的口语学习领域。我们引入一个新的多项选择题数据集来评估 LLM 在上述情景中的有效性，包括口语知识的理解和应用。此外，我们调查了各种提示技巧的影响，如零和少数拍摄方法(提前问题与问题-答案范例) ，思维链(CoT，一步一步地思考) ，领域内的例子和外部工具(谷歌，维基百科)。我们使用这些方法对流行的 LLM (20种不同的模型)进行了大规模的评估。与实际问题推理中的零射击基线相比，我们取得了显着的性能改善(GPT-3.5,49.1%-> 63.1% ; LLaMA2-70B-Chat，42.2%-> 48.6%)。我们发现不同大小的模型对语音学、音系学和第二语言习得的概念有很好的理解，但是对于现实世界的问题在推理方面有局限性。此外，我们还探讨了会话交际的初步发现。"
    },
    {
        "title": "A Multi-Task Semantic Decomposition Framework with Task-specific\n  Pre-training for Few-Shot NER",
        "url": "http://arxiv.org/abs/2308.14533v1",
        "pub_date": "2023-08-28",
        "summary": "The objective of few-shot named entity recognition is to identify named\nentities with limited labeled instances. Previous works have primarily focused\non optimizing the traditional token-wise classification framework, while\nneglecting the exploration of information based on NER data characteristics. To\naddress this issue, we propose a Multi-Task Semantic Decomposition Framework\nvia Joint Task-specific Pre-training (MSDP) for few-shot NER. Drawing\ninspiration from demonstration-based and contrastive learning, we introduce two\nnovel pre-training tasks: Demonstration-based Masked Language Modeling (MLM)\nand Class Contrastive Discrimination. These tasks effectively incorporate\nentity boundary information and enhance entity representation in Pre-trained\nLanguage Models (PLMs). In the downstream main task, we introduce a multi-task\njoint optimization framework with the semantic decomposing method, which\nfacilitates the model to integrate two different semantic information for\nentity classification. Experimental results of two few-shot NER benchmarks\ndemonstrate that MSDP consistently outperforms strong baselines by a large\nmargin. Extensive analyses validate the effectiveness and generalization of\nMSDP.",
        "translated": "少镜头命名实体识别的目标是识别具有有限标记实例的命名实体。以往的工作主要集中在优化传统的标记分类框架，而忽视了基于 NER 数据特征的信息探索。针对这一问题，提出了一种基于联合任务特定预训练(MSDP)的多任务语义分解框架。借鉴基于演示和对比学习的方法，我们介绍了两种新颖的预训练任务: 基于演示的掩蔽语言建模(MLM)和类别对比鉴别。这些任务有效地整合了实体边界信息，增强了预训练语言模型(PLM)中的实体表示。在下游的主要任务中，我们引入了一个基于语义分解的多任务联合优化框架，该框架有利于模型集成两种不同的语义信息进行实体分类。两个短镜头 NER 基准测试的实验结果表明，MSDP 的性能始终大大优于强基准测试。广泛的分析验证了 MSDP 的有效性和推广性。"
    },
    {
        "title": "LongBench: A Bilingual, Multitask Benchmark for Long Context\n  Understanding",
        "url": "http://arxiv.org/abs/2308.14508v1",
        "pub_date": "2023-08-28",
        "summary": "Although large language models (LLMs) demonstrate impressive performance for\nmany language tasks, most of them can only handle texts a few thousand tokens\nlong, limiting their applications on longer sequence inputs, such as books,\nreports, and codebases. Recent works have proposed methods to improve LLMs'\nlong context capabilities by extending context windows and more sophisticated\nmemory mechanisms. However, comprehensive benchmarks tailored for evaluating\nlong context understanding are lacking. In this paper, we introduce LongBench,\nthe first bilingual, multi-task benchmark for long context understanding,\nenabling a more rigorous evaluation of long context understanding. LongBench\ncomprises 21 datasets across 6 task categories in both English and Chinese,\nwith an average length of 6,711 words (English) and 13,386 characters\n(Chinese). These tasks cover key long-text application areas including\nsingle-doc QA, multi-doc QA, summarization, few-shot learning, synthetic tasks,\nand code completion. All datasets in LongBench are standardized into a unified\nformat, allowing for effortless automatic evaluation of LLMs. Upon\ncomprehensive evaluation of 8 LLMs on LongBench, we find that: (1) Commercial\nmodel (GPT-3.5-Turbo-16k) outperforms other open-sourced models, but still\nstruggles on longer contexts. (2) Scaled position embedding and fine-tuning on\nlonger sequences lead to substantial improvement on long context understanding.\n(3) Context compression technique such as retrieval brings improvement for\nmodel with weak ability on long contexts, but the performance still lags behind\nmodels that have strong long context understanding capability. The code and\ndatasets are available at https://github.com/THUDM/LongBench.",
        "translated": "尽管大型语言模型(LLM)在许多语言任务中表现出了令人印象深刻的性能，但大多数 LLM 只能处理几千个令牌长度的文本，从而限制了它们在较长序列输入(如图书、报告和代码库)上的应用。最近的研究提出了通过扩展上下文窗口和更复杂的记忆机制来提高 LLM 的长上下文能力的方法。然而，缺乏专门用于评估长上下文理解的综合基准。在本文中，我们介绍了 LongBench，这是第一个用于长语境理解的双语多任务基准测试，使得对长语境理解的评估更加严格。LongBench 由21个数据集组成，包括6个任务类别的中英文数据，平均长度为6711个单词(英文)和13386个字符(中文)。这些任务涵盖了关键的长文本应用领域，包括单文档 QA、多文档 QA、摘要、少镜头学习、综合任务和代码完成。LongBench 中的所有数据集都标准化为一种统一的格式，从而可以轻松地自动评估 LLM。在对 LongBench 上的8个 LLM 进行综合评估后，我们发现: (1)商业模型(GPT-3.5-Turbo-16k)优于其他开源模型，但仍然在更长的环境中挣扎。(2)对长序列进行尺度位置嵌入和微调，可以显著提高对长上下文的理解能力。(3)检索等上下文压缩技术对能力较弱的长上下文模型进行了改进，但其性能仍落后于能力较强的长上下文理解模型。代码和数据集可在 https://github.com/thudm/longbench 下载。"
    },
    {
        "title": "Multimodal Detection of Social Spambots in Twitter using Transformers",
        "url": "http://arxiv.org/abs/2308.14484v1",
        "pub_date": "2023-08-28",
        "summary": "Although not all bots are malicious, the vast majority of them are\nresponsible for spreading misinformation and manipulating the public opinion\nabout several issues, i.e., elections and many more. Therefore, the early\ndetection of social spambots is crucial. Although there have been proposed\nmethods for detecting bots in social media, there are still substantial\nlimitations. For instance, existing research initiatives still extract a large\nnumber of features and train traditional machine learning algorithms or use\nGloVe embeddings and train LSTMs. However, feature extraction is a tedious\nprocedure demanding domain expertise. Also, language models based on\ntransformers have been proved to be better than LSTMs. Other approaches create\nlarge graphs and train graph neural networks requiring in this way many hours\nfor training and access to computational resources. To tackle these\nlimitations, this is the first study employing only the user description field\nand images of three channels denoting the type and content of tweets posted by\nthe users. Firstly, we create digital DNA sequences, transform them to 3d\nimages, and apply pretrained models of the vision domain, including\nEfficientNet, AlexNet, VGG16, etc. Next, we propose a multimodal approach,\nwhere we use TwHIN-BERT for getting the textual representation of the user\ndescription field and employ VGG16 for acquiring the visual representation for\nthe image modality. We propose three different fusion methods, namely\nconcatenation, gated multimodal unit, and crossmodal attention, for fusing the\ndifferent modalities and compare their performances. Extensive experiments\nconducted on the Cresci '17 dataset demonstrate valuable advantages of our\nintroduced approaches over state-of-the-art ones reaching Accuracy up to\n99.98%.",
        "translated": "虽然不是所有的机器人都是恶意的，但是它们中的绝大多数都要对传播错误信息和操纵公众对一些问题的看法负责，比如选举等等。因此，及早发现社交垃圾邮件机器人是至关重要的。尽管已经有人提出了在社交媒体中检测机器人的方法，但仍然存在很大的局限性。例如，现有的研究计划仍然提取大量的特征，训练传统的机器学习算法，或者使用 GloVe 嵌入技术训练 LSTM。然而，特征提取是一个繁琐的过程，需要领域专家。此外，基于变换器的语言模型已被证明比 LSTM 更好。其他方法创建大型图形并训练图形神经网络，这种方法需要许多小时的训练和访问计算资源。为了解决这些局限性，这是第一个仅使用用户描述字段和表示用户发布的 tweet 类型和内容的三个渠道的图像的研究。首先，我们创建数字 DNA 序列，将它们转换成三维图像，并应用视觉领域的预训练模型，包括 EfficientNet、 AlexNet、 VGG16等。接下来，我们提出了一种多模态方法，其中我们使用 TwHIN-BERT 来获得用户描述字段的文本表示，并使用 VGG16来获得图像模态的可视化表示。我们提出了三种不同的融合方法，即级联法、门控多模态单元法和交叉模态注意法，用于不同模态的融合并比较它们的性能。在 Cresci’17数据集上进行的大量实验表明，我们引入的方法比最先进的方法具有宝贵的优势，准确率高达99.98% 。"
    },
    {
        "title": "Robust Long-Tailed Learning via Label-Aware Bounded CVaR",
        "url": "http://arxiv.org/abs/2308.15405v1",
        "pub_date": "2023-08-29",
        "summary": "Data in the real-world classification problems are always imbalanced or\nlong-tailed, wherein the majority classes have the most of the samples that\ndominate the model training. In such setting, the naive model tends to have\npoor performance on the minority classes. Previously, a variety of loss\nmodifications have been proposed to address the long-tailed leaning problem,\nwhile these methods either treat the samples in the same class\nindiscriminatingly or lack a theoretical guarantee. In this paper, we propose\ntwo novel approaches based on CVaR (Conditional Value at Risk) to improve the\nperformance of long-tailed learning with a solid theoretical ground.\nSpecifically, we firstly introduce a Label-Aware Bounded CVaR (LAB-CVaR) loss\nto overcome the pessimistic result of the original CVaR, and further design the\noptimal weight bounds for LAB-CVaR theoretically. Based on LAB-CVaR, we\nadditionally propose a LAB-CVaR with logit adjustment (LAB-CVaR-logit) loss to\nstabilize the optimization process, where we also offer the theoretical\nsupport. Extensive experiments on real-world datasets with long-tailed label\ndistributions verify the superiority of our proposed methods.",
        "translated": "现实分类问题中的数据总是不平衡的或者是长尾的，其中大多数类都有大多数样本，这些样本在模型训练中占主导地位。在这种情况下，幼稚的模式往往对少数阶层表现不佳。此前，针对长尾倾斜问题，人们提出了各种损失修正方法，但这些方法要么不加区别地对待同类样本，要么缺乏理论保证。本文提出了两种基于条件风险价值(CVaR)的改进方法，以提高长尾学习的性能。具体来说，我们首先引入标签感知有界 CVaR (LAB-CVaR)损失来克服原有 CVaR 的悲观结果，并从理论上进一步设计 LAB-CVaR 的最优权重界。在 LAB-CVaR 的基础上，提出了一种带有 logit 调整损失的 LAB-CVaR (LAB-CVaR- logit)来稳定优化过程，并给出了理论支持。在具有长尾标签分布的真实世界数据集上的大量实验验证了我们提出的方法的优越性。"
    },
    {
        "title": "A Multi-Perspective Learning to Rank Approach to Support Children's\n  Information Seeking in the Classroom",
        "url": "http://arxiv.org/abs/2308.15265v1",
        "pub_date": "2023-08-29",
        "summary": "We introduce a novel re-ranking model that aims to augment the functionality\nof standard search engines to support classroom search activities for children\n(ages 6 to 11). This model extends the known listwise learning-to-rank\nframework by balancing risk and reward. Doing so enables the model to\nprioritize Web resources of high educational alignment, appropriateness, and\nadequate readability by analyzing the URLs, snippets, and page titles of Web\nresources retrieved by a given mainstream search engine. Experimental results,\nincluding an ablation study and comparisons with existing baselines, showcase\nthe correctness of the proposed model. The outcomes of this work demonstrate\nthe value of considering multiple perspectives inherent to the classroom\nsetting, e.g., educational alignment, readability, and objectionability, when\napplied to the design of algorithms that can better support children's\ninformation discovery.",
        "translated": "我们引入了一个新的重新排序模型，旨在增强标准搜索引擎的功能，以支持儿童(6至11岁)的课堂搜索活动。该模型通过平衡风险和报酬扩展了已知的列表式学习-排名框架。这样做使模型能够通过分析给定主流搜索引擎检索到的 Web 资源的 URL、片段和页面标题，优先考虑具有高教育一致性、适当性和足够可读性的 Web 资源。实验结果，包括烧蚀研究和与现有基线的比较，表明了该模型的正确性。这项工作的结果表明，当应用于能够更好地支持儿童信息发现的算法设计时，考虑课堂环境固有的多视角的价值，例如，教育一致性、可读性和反对性。"
    },
    {
        "title": "Knowledge-based Multiple Adaptive Spaces Fusion for Recommendation",
        "url": "http://arxiv.org/abs/2308.15244v1",
        "pub_date": "2023-08-29",
        "summary": "Since Knowledge Graphs (KGs) contain rich semantic information, recently\nthere has been an influx of KG-enhanced recommendation methods. Most of\nexisting methods are entirely designed based on euclidean space without\nconsidering curvature. However, recent studies have revealed that a tremendous\ngraph-structured data exhibits highly non-euclidean properties. Motivated by\nthese observations, in this work, we propose a knowledge-based multiple\nadaptive spaces fusion method for recommendation, namely MCKG. Unlike existing\nmethods that solely adopt a specific manifold, we introduce the unified space\nthat is compatible with hyperbolic, euclidean and spherical spaces.\nFurthermore, we fuse the multiple unified spaces in an attention manner to\nobtain the high-quality embeddings for better knowledge propagation. In\naddition, we propose a geometry-aware optimization strategy which enables the\npull and push processes benefited from both hyperbolic and spherical spaces.\nSpecifically, in hyperbolic space, we set smaller margins in the area near to\nthe origin, which is conducive to distinguishing between highly similar\npositive items and negative ones. At the same time, we set larger margins in\nthe area far from the origin to ensure the model has sufficient error\ntolerance. The similar manner also applies to spherical spaces. Extensive\nexperiments on three real-world datasets demonstrate that the MCKG has a\nsignificant improvement over state-of-the-art recommendation methods. Further\nablation experiments verify the importance of multi-space fusion and\ngeometry-aware optimization strategy, justifying the rationality and\neffectiveness of MCKG.",
        "translated": "由于知识图表(Knowledge Graphs，KGs)包含丰富的语义信息，最近涌现了大量增强了 KG 的推荐方法。现有的方法大多是完全基于欧氏空间而不考虑曲率的。然而，最近的研究表明，大量的图结构数据表现出高度的非欧几里德性质。在此基础上，本文提出了一种基于知识的多自适应空间融合推荐方法 MCKG。不像现有的方法，只采用一个特定的流形，我们引入统一的空间，是兼容的双曲，欧几里德和球面空间。此外，我们以注意的方式融合多个统一空间，以获得高质量的嵌入，更好地传播知识。此外，我们提出了一个几何感知的优化策略，使拉和推进程都受益于双曲空间和球面空间。具体来说，在双曲空间中，我们在靠近原点的区域设置较小的空白，这有助于区分高度相似的正面项目和负面项目。同时，在远离原点的区域设置了较大的边界，以保证模型具有足够的误差容忍度。类似的方法也适用于球面空间。在三个真实世界数据集上的大量实验表明，MCKG 比最先进的推荐方法有显著的改进。进一步的烧蚀实验验证了多空间融合和几何感知优化策略的重要性，验证了 MCKG 算法的合理性和有效性。"
    },
    {
        "title": "Classification-Aware Neural Topic Model Combined With Interpretable\n  Analysis -- For Conflict Classification",
        "url": "http://arxiv.org/abs/2308.15232v1",
        "pub_date": "2023-08-29",
        "summary": "A large number of conflict events are affecting the world all the time. In\norder to analyse such conflict events effectively, this paper presents a\nClassification-Aware Neural Topic Model (CANTM-IA) for Conflict Information\nClassification and Topic Discovery. The model provides a reliable\ninterpretation of classification results and discovered topics by introducing\ninterpretability analysis. At the same time, interpretation is introduced into\nthe model architecture to improve the classification performance of the model\nand to allow interpretation to focus further on the details of the data.\nFinally, the model architecture is optimised to reduce the complexity of the\nmodel.",
        "translated": "大量的冲突事件一直在影响着世界。为了有效地分析这类冲突事件，本文提出了一种用于冲突信息分类和主题发现的分类感知神经主题模型(CANTM-IA)。该模型通过引入可解释性分析，为分类结果和发现的主题提供了可靠的解释。同时，在模型体系结构中引入了解释，以提高模型的分类性能，并允许解释进一步侧重于数据的细节。最后，对模型结构进行了优化，降低了模型的复杂性。"
    },
    {
        "title": "Providing Previously Unseen Users Fair Recommendations Using Variational\n  Autoencoders",
        "url": "http://arxiv.org/abs/2308.15230v1",
        "pub_date": "2023-08-29",
        "summary": "An emerging definition of fairness in machine learning requires that models\nare oblivious to demographic user information, e.g., a user's gender or age\nshould not influence the model. Personalized recommender systems are\nparticularly prone to violating this definition through their explicit user\nfocus and user modelling. Explicit user modelling is also an aspect that makes\nmany recommender systems incapable of providing hitherto unseen users with\nrecommendations. We propose novel approaches for mitigating discrimination in\nVariational Autoencoder-based recommender systems by limiting the encoding of\ndemographic information. The approaches are capable of, and evaluated on,\nproviding users that are not represented in the training data with fair\nrecommendations.",
        "translated": "机器学习中公平性的一个新兴定义要求模型不受人口统计学用户信息的影响，例如，用户的性别或年龄不应该影响模型。个性化推荐系统通过明确的用户焦点和用户建模特别容易违反这一定义。显式用户建模也是一个方面，使得许多推荐系统无法向迄今为止看不见的用户提供推荐。我们提出了新的方法，以减少歧视的变化自动编码器为基础的推荐系统，通过限制人口统计信息的编码。这些方法能够为培训数据中没有代表的用户提供公平的建议，并对其进行评估。"
    },
    {
        "title": "ParaGuide: Guided Diffusion Paraphrasers for Plug-and-Play Textual Style\n  Transfer",
        "url": "http://arxiv.org/abs/2308.15459v1",
        "pub_date": "2023-08-29",
        "summary": "Textual style transfer is the task of transforming stylistic properties of\ntext while preserving meaning. Target \"styles\" can be defined in numerous ways,\nranging from single attributes (e.g, formality) to authorship (e.g,\nShakespeare). Previous unsupervised style-transfer approaches generally rely on\nsignificant amounts of labeled data for only a fixed set of styles or require\nlarge language models. In contrast, we introduce a novel diffusion-based\nframework for general-purpose style transfer that can be flexibly adapted to\narbitrary target styles at inference time. Our parameter-efficient approach,\nParaGuide, leverages paraphrase-conditioned diffusion models alongside\ngradient-based guidance from both off-the-shelf classifiers and strong existing\nstyle embedders to transform the style of text while preserving semantic\ninformation. We validate the method on the Enron Email Corpus, with both human\nand automatic evaluations, and find that it outperforms strong baselines on\nformality, sentiment, and even authorship style transfer.",
        "translated": "语篇风格转换是在保持语篇意义的同时转换语篇的风格特征的过程。目标“风格”可以通过多种方式定义，从单一属性(例如，形式)到作者(例如，莎士比亚)。以前的无监督样式转换方法通常只依赖于一组固定样式或需要大型语言模型的大量标记数据。相比之下，我们提出了一个新的基于扩散的通用风格转移框架，它可以在推理时灵活地适应任意目标风格。我们的参数高效方法，ParaGuide，利用释义条件的扩散模型和基于梯度的指导，从现成的分类器和强大的现有风格嵌入器来转换文本的风格，同时保留语义信息。通过对安然电子邮件语料库的人工和自动评估，验证了该方法的有效性，结果表明该方法在形式、情感甚至作者风格转换方面都优于强基线方法。"
    },
    {
        "title": "When Do Program-of-Thoughts Work for Reasoning?",
        "url": "http://arxiv.org/abs/2308.15452v1",
        "pub_date": "2023-08-29",
        "summary": "The reasoning capabilities of Large Language Models (LLMs) play a pivotal\nrole in the realm of embodied artificial intelligence. Although there are\neffective methods like program-of-thought prompting for LLMs which uses\nprogramming language to tackle complex reasoning tasks, the specific impact of\ncode data on the improvement of reasoning capabilities remains under-explored.\nTo address this gap, we propose complexity-impacted reasoning score (CIRS),\nwhich combines structural and logical attributes, to measure the correlation\nbetween code and reasoning abilities. Specifically, we use the abstract syntax\ntree to encode the structural information and calculate logical complexity by\nconsidering the difficulty and the cyclomatic complexity. Through an empirical\nanalysis, we find not all code data of complexity can be learned or understood\nby LLMs. Optimal level of complexity is critical to the improvement of\nreasoning abilities by program-aided prompting. Then we design an\nauto-synthesizing and stratifying algorithm, and apply it to instruction\ngeneration for mathematical reasoning and code data filtering for code\ngeneration tasks. Extensive results demonstrates the effectiveness of our\nproposed approach. Code will be integrated into the EasyInstruct framework at\nhttps://github.com/zjunlp/EasyInstruct.",
        "translated": "大语言模型(LLM)的推理能力在具体化人工智能领域起着举足轻重的作用。虽然有一些有效的方法，比如用程序语言来处理复杂推理任务的 LLM 程序思想提示，但是代码数据对提高推理能力的具体影响仍然没有得到充分的研究。为了解决这一问题，我们提出了结构属性和逻辑属性相结合的复杂性影响推理得分(CIRS)方法来度量代码和推理能力之间的相关性。具体来说，我们使用抽象语法树对结构信息进行编码，并通过考虑难度和循环复杂度来计算逻辑复杂度。通过实证分析，我们发现并非所有复杂度的代码数据都能被 LLM 学习或理解。最佳的复杂度水平是提高程序辅助推理能力的关键。然后设计了一种自动综合分层算法，并将其应用于数学推理的指令生成和代码生成任务的代码数据过滤。广泛的结果证明了我们提出的方法的有效性。代码将被集成到易于指令框架的 https://github.com/zjunlp/EasyInstruct。"
    },
    {
        "title": "Vulgar Remarks Detection in Chittagonian Dialect of Bangla",
        "url": "http://arxiv.org/abs/2308.15448v1",
        "pub_date": "2023-08-29",
        "summary": "The negative effects of online bullying and harassment are increasing with\nInternet popularity, especially in social media. One solution is using natural\nlanguage processing (NLP) and machine learning (ML) methods for the automatic\ndetection of harmful remarks, but these methods are limited in low-resource\nlanguages like the Chittagonian dialect of Bangla.This study focuses on\ndetecting vulgar remarks in social media using supervised ML and deep learning\nalgorithms.Logistic Regression achieved promising accuracy (0.91) while simple\nRNN with Word2vec and fastTex had lower accuracy (0.84-0.90), highlighting the\nissue that NN algorithms require more data.",
        "translated": "随着互联网的普及，尤其是在社交媒体上，网络欺凌和骚扰的负面影响正在增加。一种解决方案是使用自然语言处理(NLP)和机器学习(ML)方法来自动检测有害言论，但这些方法在资源匮乏的语言中受到限制，如孟加拉吉大哥方言。本研究致力于利用有监督的机器学习和深度学习算法来检测社交媒体中的粗俗评论。Logit模型的精确度(0.91)有希望，而使用 Word2vec 和 fastTex 的简单 RNN 的精确度(0.84-0.90)较低，突出了神经网络算法需要更多数据的问题。"
    },
    {
        "title": "Characterizing Learning Curves During Language Model Pre-Training:\n  Learning, Forgetting, and Stability",
        "url": "http://arxiv.org/abs/2308.15419v1",
        "pub_date": "2023-08-29",
        "summary": "How do language models learn to make predictions during pre-training? To\nstudy this question, we extract learning curves from five autoregressive\nEnglish language model pre-training runs, for 1M tokens in context. We observe\nthat the language models generate short repetitive phrases before learning to\ngenerate longer and more coherent text. We quantify the final surprisal,\nwithin-run variability, age of acquisition, forgettability, and cross-run\nvariability of learning curves for individual tokens in context. More frequent\ntokens reach lower final surprisals, exhibit less variability within and across\npre-training runs, are learned earlier, and are less likely to be \"forgotten\"\nduring pre-training. Higher n-gram probabilities further accentuate these\neffects. Independent of the target token, shorter and more frequent contexts\ncorrelate with marginally more stable and quickly acquired predictions. Effects\nof part-of-speech are also small, although nouns tend to be acquired later and\nless stably than verbs, adverbs, and adjectives. Our work contributes to a\nbetter understanding of language model pre-training dynamics and informs the\ndeployment of stable language models in practice.",
        "translated": "语言模型是如何在训练前做出预测的？为了研究这个问题，我们从五个自回归英语语言模型的预训练中提取学习曲线。我们观察到语言模型在学习生成更长更连贯的文本之前会生成短的重复短语。我们量化最后的惊喜，内部运行的可变性，年龄的获取，遗忘性和交叉运行的学习曲线的个人令牌在上下文中的可变性。更频繁的令牌达到较低的最终惊喜，表现出较少的变异性内部和跨培训前运行，学习较早，并不太可能被“忘记”在培训前。较高的 n-gram 概率进一步强调了这些效应。与目标标记无关，更短和更频繁的上下文与略微更稳定和快速获得的预测相关。虽然名词的习得比动词、副词和形容词晚，而且不那么稳定，但是词性的影响也很小。我们的工作有助于更好地理解语言模型培训前的动态，并通知在实践中部署稳定的语言模型。"
    },
    {
        "title": "Rethinking Machine Ethics -- Can LLMs Perform Moral Reasoning through\n  the Lens of Moral Theories?",
        "url": "http://arxiv.org/abs/2308.15399v1",
        "pub_date": "2023-08-29",
        "summary": "Making moral judgments is an essential step toward developing ethical AI\nsystems. Prevalent approaches are mostly implemented in a bottom-up manner,\nwhich uses a large set of annotated data to train models based on crowd-sourced\nopinions about morality. These approaches have been criticized for potentially\novergeneralizing a limited group of annotators' moral stances and lacking\nexplainability. In contrast, top-down approaches make moral judgments grounded\nin a set of principles. However, it remains conceptual due to the incapability\nof previous language models and the unsolved debate among moral principles. In\nthis study, we propose a flexible framework to steer Large Language Models\n(LLMs) to perform moral reasoning with well-established moral theories from\ninterdisciplinary research. The theory-guided top-down framework can\nincorporate various moral theories. Our experiments demonstrate the\neffectiveness of the proposed framework on datasets derived from moral\ntheories. Furthermore, we show the alignment between different moral theories\nand existing morality datasets. Our analysis exhibits the potentials and flaws\nin existing resources (models and datasets) in developing explainable moral\njudgment-making systems.",
        "translated": "做出道德判断是发展道德人工智能系统的重要一步。流行的方法大多是以自下而上的方式实现的，它使用大量注释数据来训练基于众包的道德观点的模型。这些方法被批评为可能过度概括了有限的一组注释者的道德立场和缺乏解释性。相比之下，自上而下的方法使道德判断建立在一套原则的基础上。然而，由于以往语言模式的不足和道德原则之间尚未解决的争论，它仍然是概念性的。在这项研究中，我们提出了一个灵活的框架来引导大语言模型(LLMs) ，以便利用科际整合中已经建立起来的道德理论来进行道德推理。以理论为指导的自上而下的框架可以包含各种道德理论。我们的实验证明了该框架对源于道德理论的数据集的有效性。此外，我们还展示了不同道德理论与现有道德数据集之间的一致性。我们的分析揭示了现有资源(模型和数据集)在开发可解释的道德判断系统方面的潜力和缺陷。"
    },
    {
        "title": "Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation",
        "url": "http://arxiv.org/abs/2308.15363v1",
        "pub_date": "2023-08-29",
        "summary": "Large language models (LLMs) have emerged as a new paradigm for Text-to-SQL\ntask. However, the absence of a systematical benchmark inhibits the development\nof designing effective, efficient and economic LLM-based Text-to-SQL solutions.\nTo address this challenge, in this paper, we first conduct a systematical and\nextensive comparison over existing prompt engineering methods, including\nquestion representation, example selection and example organization, and with\nthese experimental results, we elaborates their pros and cons. Based on these\nfindings, we propose a new integrated solution, named DAIL-SQL, which refreshes\nthe Spider leaderboard with 86.6% execution accuracy and sets a new bar.\nTowards an efficient and economic LLM-based Text-to-SQL solution, we emphasize\nthe token efficiency in prompt engineering and compare the prior studies under\nthis metric. Additionally, we investigate open-source LLMs in in-context\nlearning, and further enhance their performance with task-specific supervised\nfine-tuning. Our explorations highlight open-source LLMs' potential in\nText-to-SQL, as well as the advantages and disadvantages of the task-specific\nsupervised fine-tuning. We hope that our work provides a deeper understanding\nof Text-to-SQL with LLMs, and inspire further investigations and broad\napplications.",
        "translated": "大型语言模型(LLM)已经成为文本到 SQL 任务的一种新范式。然而，系统基准的缺乏阻碍了设计有效、高效和经济的基于 LLM 的文本到 SQL 解决方案的发展。为了应对这一挑战，本文首先对现有的快速工程方法进行了系统的、广泛的比较，包括问题表示、实例选择和实例组织，并结合实验结果阐述了它们的优缺点。基于这些发现，我们提出了一个新的集成解决方案，命名为 DAIL-SQL，它刷新了 Spider 的排行榜，执行准确率达到86.6% ，并设置了一个新的条形码。针对一种高效、经济的基于 LLM 的文本到 SQL 解决方案，我们强调了快速工程中的令牌效率，并比较了以往在这一指标下的研究成果。此外，我们还研究了开源 LLM 在上下文学习中的应用，并通过特定任务的监督微调来进一步提高它们的性能。我们的探索突出了开源 LLM 在 Text-to-SQL 中的潜力，以及特定于任务的监督微调的优缺点。我们希望我们的工作能够提供对 LLM 中的文本到 SQL 的更深入的理解，并启发进一步的研究和广泛的应用。"
    },
    {
        "title": "Historical patterns of rice farming explain modern-day language use in\n  China and Japan more than modernization and urbanization",
        "url": "http://arxiv.org/abs/2308.15352v1",
        "pub_date": "2023-08-29",
        "summary": "We used natural language processing to analyze a billion words to study\ncultural differences on Weibo, one of China's largest social media platforms.\nWe compared predictions from two common explanations about cultural differences\nin China (economic development and urban-rural differences) against the\nless-obvious legacy of rice versus wheat farming. Rice farmers had to\ncoordinate shared irrigation networks and exchange labor to cope with higher\nlabor requirements. In contrast, wheat relied on rainfall and required half as\nmuch labor. We test whether this legacy made southern China more\ninterdependent. Across all word categories, rice explained twice as much\nvariance as economic development and urbanization. Rice areas used more words\nreflecting tight social ties, holistic thought, and a cautious, prevention\norientation. We then used Twitter data comparing prefectures in Japan, which\nlargely replicated the results from China. This provides crucial evidence of\nthe rice theory in a different nation, language, and platform.",
        "translated": "我们使用自然语言处理分析了十亿个单词，研究了中国最大的社交媒体平台之一微博上的文化差异。我们比较了对中国文化差异(经济发展和城乡差异)的两种常见解释的预测，以及不那么明显的水稻与小麦种植的遗留问题。水稻种植者必须协调共享灌溉网络和交换劳动力，以应对更高的劳动力需求。相比之下，小麦依赖降雨，需要的劳动力只有原来的一半。我们测试这一遗产是否使中国南方更加相互依存。在所有词类中，大米解释的差异是经济发展和城市化的两倍。稻区使用更多的词反映了紧密的社会关系，整体思维，以及谨慎的预防取向。然后，我们使用 Twitter 数据对日本各县进行比较，结果与中国的结果基本一致。这为不同国家、不同语言、不同平台的稻米理论提供了关键证据。"
    },
    {
        "title": "A Framework for Responsible Development of Automated Student Feedback\n  with Generative AI",
        "url": "http://arxiv.org/abs/2308.15334v1",
        "pub_date": "2023-08-29",
        "summary": "Providing rich feedback to students is essential for supporting student\nlearning. Recent advances in generative AI, particularly within large language\nmodelling (LLM), provide the opportunity to deliver repeatable, scalable and\ninstant automatically generated feedback to students, making abundant a\npreviously scarce and expensive learning resource. Such an approach is feasible\nfrom a technical perspective due to these recent advances in Artificial\nIntelligence (AI) and Natural Language Processing (NLP); while the potential\nupside is a strong motivator, doing so introduces a range of potential ethical\nissues that must be considered as we apply these technologies. The\nattractiveness of AI systems is that they can effectively automate the most\nmundane tasks; but this risks introducing a \"tyranny of the majority\", where\nthe needs of minorities in the long tail are overlooked because they are\ndifficult to automate.\n  Developing machine learning models that can generate valuable and authentic\nfeedback requires the input of human domain experts. The choices we make in\ncapturing this expertise -- whose, which, when, and how -- will have\nsignificant consequences for the nature of the resulting feedback. How we\nmaintain our models will affect how that feedback remains relevant given\ntemporal changes in context, theory, and prior learning profiles of student\ncohorts. These questions are important from an ethical perspective; but they\nare also important from an operational perspective. Unless they can be\nanswered, our AI generated systems will lack the trust necessary for them to be\nuseful features in the contemporary learning environment.\n  This article will outline the frontiers of automated feedback, identify the\nethical issues involved in the provision of automated feedback and present a\nframework to assist academics to develop such systems responsibly.",
        "translated": "为学生提供丰富的反馈对于支持学生学习至关重要。生成式人工智能的最新进展，特别是在大型语言建模(LLM)领域，提供了向学生提供可重复、可扩展和即时自动生成的反馈的机会，使得丰富的学习资源成为以前稀缺和昂贵的学习资源。由于人工智能(AI)和自然语言处理(NLP)的最新进展，这种方法从技术角度来看是可行的; 尽管潜在的优势是一个强大的动力，但这样做会引入一系列潜在的伦理问题，在我们应用这些技术时必须考虑到。人工智能系统的吸引力在于，它们能够有效地将最平凡的任务自动化，但这可能会引入一种“多数人暴政”，在这种情况下，处于长尾的少数群体的需求被忽视，因为它们很难自动化。开发能够产生有价值和真实反馈的机器学习模型需要人类领域专家的投入。我们在获取这种专业知识时所做的选择——其中的专业知识、其中的专业知识、其中的专业知识、其中的专业知识以及其中的专业知识——将对结果反馈的性质产生重大影响。我们如何维护我们的模型将影响如何反馈仍然相关的时间变化的情况下，理论和先前的学生队列的学习概况。这些问题从道德角度来看很重要，但从操作角度来看也很重要。除非这些问题能够得到解决，否则我们的人工智能生成系统将缺乏必要的信任，无法成为当代学习环境中有用的功能。本文将概述自动反馈的前沿，确定提供自动反馈涉及的伦理问题，并提出一个框架，以协助学术界负责任地开发此类系统。"
    },
    {
        "title": "TaskLAMA: Probing the Complex Task Understanding of Language Models",
        "url": "http://arxiv.org/abs/2308.15299v1",
        "pub_date": "2023-08-29",
        "summary": "Structured Complex Task Decomposition (SCTD) is the problem of breaking down\na complex real-world task (such as planning a wedding) into a directed acyclic\ngraph over individual steps that contribute to achieving the task, with edges\nspecifying temporal dependencies between them. SCTD is an important component\nof assistive planning tools, and a challenge for commonsense reasoning systems.\nWe probe how accurately SCTD can be done with the knowledge extracted from\nLarge Language Models (LLMs). We introduce a high-quality human-annotated\ndataset for this problem and novel metrics to fairly assess performance of LLMs\nagainst several baselines. Our experiments reveal that LLMs are able to\ndecompose complex tasks into individual steps effectively, with a relative\nimprovement of 15% to 280% over the best baseline. We also propose a number of\napproaches to further improve their performance, with a relative improvement of\n7% to 37% over the base model. However, we find that LLMs still struggle to\npredict pairwise temporal dependencies, which reveals a gap in their\nunderstanding of complex tasks.",
        "translated": "结构化复杂任务分解(sCTD)是把一个复杂的现实世界任务(比如计划婚礼)分解成一个有向无环图，每个步骤都有助于完成任务，边缘指定它们之间的时间依赖关系。SCTD 是辅助规划工具的重要组成部分，也是常识推理系统面临的挑战。我们探讨如何准确地使用从大型语言模型(LLM)中提取的知识来完成 SCTD。针对这个问题，我们引入了一个高质量的人工注释数据集，并引入了新的度量方法来公平地评估 LLM 在几个基线上的性能。我们的实验表明 LLM 能够有效地将复杂任务分解为单个步骤，相对于最佳基线提高了15% 到280% 。我们还提出了一些方法来进一步提高它们的性能，相对于基本模型的改进率为7% 到37% 。然而，我们发现 LLM 仍然难以预测成对的时间依赖，这揭示了他们对复杂任务的理解存在差距。"
    },
    {
        "title": "KGConv, a Conversational Corpus grounded in Wikidata",
        "url": "http://arxiv.org/abs/2308.15298v1",
        "pub_date": "2023-08-29",
        "summary": "We present KGConv, a large, conversational corpus of 71k conversations where\neach question-answer pair is grounded in a Wikidata fact. Conversations contain\non average 8.6 questions and for each Wikidata fact, we provide multiple\nvariants (12 on average) of the corresponding question using templates, human\nannotations, hand-crafted rules and a question rewriting neural model. We\nprovide baselines for the task of Knowledge-Based, Conversational Question\nGeneration. KGConv can further be used for other generation and analysis tasks\nsuch as single-turn question generation from Wikidata triples, question\nrewriting, question answering from conversation or from knowledge graphs and\nquiz generation.",
        "translated": "我们提出 KGConv，一个大型的，会话语料库的71k 会话，其中每个问题-答案对是基于一个 Wikidata 的事实。对话平均包含8.6个问题，对于每个 Wikidata 事实，我们使用模板、人工注释、手工制作的规则和问题重写神经模型提供相应问题的多个变体(平均12个)。我们为基于知识的会话问题生成任务提供基线。KGConv 可以进一步用于其他生成和分析任务，如来自 Wikidata 三元组的单回合问题生成、问题重写、来自会话或来自知识图表的问题回答和问题生成。"
    },
    {
        "title": "Adaptive Multi-Modalities Fusion in Sequential Recommendation Systems",
        "url": "http://arxiv.org/abs/2308.15980v1",
        "pub_date": "2023-08-30",
        "summary": "In sequential recommendation, multi-modal information (e.g., text or image)\ncan provide a more comprehensive view of an item's profile. The optimal stage\n(early or late) to fuse modality features into item representations is still\ndebated. We propose a graph-based approach (named MMSR) to fuse modality\nfeatures in an adaptive order, enabling each modality to prioritize either its\ninherent sequential nature or its interplay with other modalities. MMSR\nrepresents each user's history as a graph, where the modality features of each\nitem in a user's history sequence are denoted by cross-linked nodes. The edges\nbetween homogeneous nodes represent intra-modality sequential relationships,\nand the ones between heterogeneous nodes represent inter-modality\ninterdependence relationships. During graph propagation, MMSR incorporates dual\nattention, differentiating homogeneous and heterogeneous neighbors. To\nadaptively assign nodes with distinct fusion orders, MMSR allows each node's\nrepresentation to be asynchronously updated through an update gate. In\nscenarios where modalities exhibit stronger sequential relationships, the\nupdate gate prioritizes updates among homogeneous nodes. Conversely, when the\ninterdependent relationships between modalities are more pronounced, the update\ngate prioritizes updates among heterogeneous nodes. Consequently, MMSR\nestablishes a fusion order that spans a spectrum from early to late modality\nfusion. In experiments across six datasets, MMSR consistently outperforms\nstate-of-the-art models, and our graph propagation methods surpass other graph\nneural networks. Additionally, MMSR naturally manages missing modalities.",
        "translated": "在顺序推荐中，多模态信息(例如文本或图像)可以提供一个更全面的项目配置文件视图。最佳阶段(早期或晚期)融合情态特征的项目表示仍然存在争议。我们提出了一种基于图形的方法(命名为 MMSR) ，以自适应的顺序融合模态特征，使每个模态优先考虑其固有的顺序性质或其与其他模态的相互作用。MMSR 将每个用户的历史表示为一个图，其中用户历史序列中每个项目的模态特征由交叉链接的节点表示。同质节点之间的边表示模态内部的顺序关系，异质节点之间的边表示模态间的相互依赖关系。在图的传播过程中，MMSR 融合了双重注意，区分了同质和异质邻居。为了自适应地分配具有不同融合顺序的节点，MMSR 允许通过更新门异步更新每个节点的表示。在模式表现出更强的顺序关系的场景中，更新门优先更新同质节点。相反，当模式之间的相互依赖关系更加明显时，更新门优先考虑异构节点之间的更新。因此，MMSR 建立了一个从早期到晚期的融合序列。在跨六个数据集的实验中，MMSR 始终优于最先进的模型，我们的图传播方法优于其他图神经网络。此外，MMSR 自然会管理缺失的模式。"
    },
    {
        "title": "Denoising Attention for Query-aware User Modeling in Personalized Search",
        "url": "http://arxiv.org/abs/2308.15968v1",
        "pub_date": "2023-08-30",
        "summary": "The personalization of search results has gained increasing attention in the\npast few years, thanks to the development of Neural Networks-based approaches\nfor Information Retrieval and the importance of personalization in many search\nscenarios. Recent works have proposed to build user models at query time by\nleveraging the Attention mechanism, which allows weighing the contribution of\nthe user-related information w.r.t. the current query. This approach allows\ntaking into account the diversity of the user's interests by giving more\nimportance to those related to the current search performed by the user.\n  In this paper, we first discuss some shortcomings of the standard Attention\nformulation when employed for personalization. In particular, we focus on\nissues related to its normalization mechanism and its inability to entirely\nfilter out noisy user-related information. Then, we introduce the Denoising\nAttention mechanism: an Attention variant that directly tackles the above\nshortcomings by adopting a robust normalization scheme and introducing a\nfiltering mechanism. The reported experimental evaluation shows the benefits of\nthe proposed approach over other Attention-based variants.",
        "translated": "由于基于神经网络的信息检索搜索方法的发展，以及个性化搜索在许多搜索场景中的重要性，搜索结果的个性化在过去几年中得到了越来越多的关注。最近的工作已经提出利用注意机制在查询时建立用户模型，这种机制允许权衡用户相关信息对当前查询的贡献。这种方法考虑到了用户兴趣的多样性，更加重视与用户当前搜索相关的内容。在本文中，我们首先讨论了标准注意力公式在用于个性化时的一些缺陷。特别是，我们关注的问题有关的规范化机制和它不能完全过滤出噪声用户相关信息。然后，我们介绍了去噪注意机制: 一种通过采用鲁棒归一化方案和引入过滤机制直接克服上述缺点的注意变体。报告的实验评估显示了提出的方法优于其他注意力为基础的变体。"
    },
    {
        "title": "DRGame: Diversified Recommendation for Multi-category Video Games with\n  Balanced Implicit Preferences",
        "url": "http://arxiv.org/abs/2308.15823v1",
        "pub_date": "2023-08-30",
        "summary": "The growing popularity of subscription services in video game consumption has\nemphasized the importance of offering diversified recommendations. Providing\nusers with a diverse range of games is essential for ensuring continued\nengagement and fostering long-term subscriptions. However, existing\nrecommendation models face challenges in effectively handling highly imbalanced\nimplicit feedback in gaming interactions. Additionally, they struggle to take\ninto account the distinctive characteristics of multiple categories and the\nlatent user interests associated with these categories. In response to these\nchallenges, we propose a novel framework, named DRGame, to obtain diversified\nrecommendation. It is centered on multi-category video games, consisting of two\n{components}: Balance-driven Implicit Preferences Learning for data\npre-processing and Clustering-based Diversified Recommendation {Module} for\nfinal prediction. The first module aims to achieve a balanced representation of\nimplicit feedback in game time, thereby discovering a comprehensive view of\nplayer interests across different categories. The second module adopts\ncategory-aware representation learning to cluster and select players and games\nbased on balanced implicit preferences, and then employs asymmetric neighbor\naggregation to achieve diversified recommendations. Experimental results on a\nreal-world dataset demonstrate the superiority of our proposed method over\nexisting approaches in terms of game diversity recommendations.",
        "translated": "视频游戏消费中的订阅服务越来越受欢迎，这强调了提供多样化建议的重要性。为用户提供多种多样的游戏对于确保持续参与和促进长期订阅至关重要。然而，现有的推荐模型在有效处理博弈交互中高度不平衡的隐式反馈方面面临挑战。此外，他们努力考虑到多个类别的独特特征和与这些类别相关的潜在用户兴趣。针对这些挑战，我们提出了一个新的框架，名为 DRGame，以获得多样化的推荐。它是以多类别视频游戏为中心，包括两个{组件} : 平衡驱动的内隐偏好学习的数据预处理和聚类的多样化推荐{模块}的最终预测。第一个模块的目的是在游戏时间内实现内隐反馈的平衡表示，从而发现不同类别的玩家兴趣的综合视图。第二个模块采用类别感知的表示学习方法，基于平衡内隐偏好进行聚类和选择博弈者和博弈者，然后采用非对称邻居聚集方法实现多样化的推荐。在一个真实世界的数据集上的实验结果证明了我们提出的方法在游戏多样性建议方面优于现有的方法。"
    },
    {
        "title": "Knowledge-grounded Natural Language Recommendation Explanation",
        "url": "http://arxiv.org/abs/2308.15813v1",
        "pub_date": "2023-08-30",
        "summary": "Explanations accompanied by a recommendation can assist users in\nunderstanding the decision made by recommendation systems, which in turn\nincreases a user's confidence and trust in the system. Recently, research has\nfocused on generating natural language explanations in a human-readable format.\nThus far, the proposed approaches leverage item reviews written by users, which\nare often subjective, sparse in language, and unable to account for new items\nthat have not been purchased or reviewed before. Instead, we aim to generate\nfact-grounded recommendation explanations that are objectively described with\nitem features while implicitly considering a user's preferences, based on the\nuser's purchase history. To achieve this, we propose a knowledge graph (KG)\napproach to natural language explainable recommendation. Our approach draws on\nuser-item features through a novel collaborative filtering-based KG\nrepresentation to produce fact-grounded, personalized explanations, while\njointly learning user-item representations for recommendation scoring.\nExperimental results show that our approach consistently outperforms previous\nstate-of-the-art models on natural language explainable recommendation.",
        "translated": "附有推荐的解释可以帮助用户理解推荐系统所做的决定，这反过来又增加了用户对系统的信心和信任。最近，研究集中在以人类可读的格式生成自然语言解释。到目前为止，提议的方法利用了用户写的项目审查，这些审查往往是主观的，语言稀疏，并且无法解释以前没有购买或审查过的新项目。相反，我们的目标是生成基于事实的推荐解释，客观地描述项目特征，同时隐含地考虑用户的偏好，基于用户的购买历史。为此，我们提出了一种基于知识图(KG)的自然语言可解释推荐方法。我们的方法通过一种新的基于协作过滤的 KG 表示来利用用户项目的特征来产生基于事实的、个性化的解释，同时联合学习用户项目表示来进行推荐评分。实验结果表明，我们的方法在自然语言可解释推荐方面始终优于以前的最先进的模型。"
    },
    {
        "title": "Fragment and Integrate Network (FIN): A Novel Spatial-Temporal Modeling\n  Based on Long Sequential Behavior for Online Food Ordering Click-Through Rate\n  Prediction",
        "url": "http://arxiv.org/abs/2308.15703v1",
        "pub_date": "2023-08-30",
        "summary": "Spatial-temporal information has been proven to be of great significance for\nclick-through rate prediction tasks in online Location-Based Services (LBS),\nespecially in mainstream food ordering platforms such as DoorDash, Uber Eats,\nMeituan, and Ele.me. Modeling user spatial-temporal preferences with sequential\nbehavior data has become a hot topic in recommendation systems and online\nadvertising. However, most of existing methods either lack the representation\nof rich spatial-temporal information or only handle user behaviors with limited\nlength, e.g. 100. In this paper, we tackle these problems by designing a new\nspatial-temporal modeling paradigm named Fragment and Integrate Network (FIN).\nFIN consists of two networks: (i) Fragment Network (FN) extracts Multiple\nSub-Sequences (MSS) from lifelong sequential behavior data, and captures the\nspecific spatial-temporal representation by modeling each MSS respectively.\nHere both a simplified attention and a complicated attention are adopted to\nbalance the performance gain and resource consumption. (ii) Integrate Network\n(IN) builds a new integrated sequence by utilizing spatial-temporal interaction\non MSS and captures the comprehensive spatial-temporal representation by\nmodeling the integrated sequence with a complicated attention. Both public\ndatasets and production datasets have demonstrated the accuracy and scalability\nof FIN. Since 2022, FIN has been fully deployed in the recommendation\nadvertising system of Ele.me, one of the most popular online food ordering\nplatforms in China, obtaining 5.7% improvement on Click-Through Rate (CTR) and\n7.3% increase on Revenue Per Mille (RPM).",
        "translated": "时空信息已被证明对于在线基于位置服务(LBS)的点进率预测任务具有重要意义，特别是在主流食品订购平台如 DoorDash、 Uber Eats、美团和 Ele.me 中。利用序列行为数据建立用户时空偏好模型已成为推荐系统和在线广告研究的热点。然而，大多数现有的方法要么缺乏丰富的时空信息的表示，要么只能处理有限长度的用户行为，例如100。针对这些问题，本文设计了一种新的时空建模范式——分段集成网络(FIN)。FIN 由两个网络组成: (1)片段网络(FN)从终身序列行为数据中提取多个子序列(MSS) ，分别对每个子序列进行建模，获取特定的时空表示。这里采用了简化注意和复杂注意来平衡性能增益和资源消耗。(2)综合网络(IN)利用 MSS 上的时空相互作用建立一个新的综合序列，通过对综合序列进行复杂注意力建模来获取综合的时空表示。公共数据集和生产数据集都证明了 FIN 的准确性和可扩展性。自2022年以来，中国最受欢迎的在线食品订购平台之一饿了么的推荐广告系统中已经全面部署了财务识别系统，点进率点击率提高了5.7% ，每公里收入提高了7.3% 。"
    },
    {
        "title": "Quantifying Uncertainty in Answers from any Language Model via Intrinsic\n  and Extrinsic Confidence Assessment",
        "url": "http://arxiv.org/abs/2308.16175v1",
        "pub_date": "2023-08-30",
        "summary": "We introduce BSDetector, a method for detecting bad and speculative answers\nfrom a pretrained Large Language Model by estimating a numeric confidence score\nfor any output it generated. Our uncertainty quantification technique works for\nany LLM accessible only via a black-box API, and combines intrinsic and\nextrinsic assessments of confidence into a single trustworthiness estimate for\nany LLM response to a given prompt. Our method is extremely general and can\napplied to all of the best LLMs available today (whose training data remains\nunknown). By expending a bit of extra computation, users of any LLM API can now\nget the same response as they would ordinarily, as well as a confidence\nestimate that caution when not to trust this response. Experiments on both\nclosed and open-form Question-Answer benchmarks reveal that BSDetector more\naccurately identifies incorrect LLM responses than alternative uncertainty\nestimation procedures (for both GPT-3 and ChatGPT). By sampling multiple\nresponses from the LLM and considering the one with the highest confidence\nscore, we can additionally obtain more accurate responses from the same LLM,\nwithout any extra training steps.",
        "translated": "我们介绍了 BSDetector，一种从预先训练好的大型语言模型中检测错误和推测性答案的方法，它通过估计所生成的任何输出的数值置信度得分。我们的不确定性量化技术适用于任何只能通过黑盒 API 访问的 LLM，并将内在和外在的置信度评估结合成对给定提示的任何 LLM 响应的单个可信度估计。我们的方法是非常一般的，可以应用于当今所有最好的 LLM (其训练数据仍然未知)。通过增加一点额外的计算，任何 LLM API 的用户现在都可以得到与通常相同的响应，同时还可以得到一个可信度估计，以防万一不相信这个响应。在封闭式和开放式问答基准上的实验表明，BSDetector 比替代的不确定性估计程序(GPT-3和 ChatGPT)更准确地识别不正确的 LLM 响应。通过从 LLM 中抽样多个响应，并考虑置信度最高的响应，我们可以从同一 LLM 中获得更准确的响应，而不需要任何额外的训练步骤。"
    },
    {
        "title": "Jais and Jais-chat: Arabic-Centric Foundation and Instruction-Tuned Open\n  Generative Large Language Models",
        "url": "http://arxiv.org/abs/2308.16149v1",
        "pub_date": "2023-08-30",
        "summary": "We introduce Jais and Jais-chat, new state-of-the-art Arabic-centric\nfoundation and instruction-tuned open generative large language models (LLMs).\nThe models are based on the GPT-3 decoder-only architecture and are pretrained\non a mixture of Arabic and English texts, including source code in various\nprogramming languages. With 13 billion parameters, they demonstrate better\nknowledge and reasoning capabilities in Arabic than any existing open Arabic\nand multilingual models by a sizable margin, based on extensive evaluation.\nMoreover, the models are competitive in English compared to English-centric\nopen models of similar size, despite being trained on much less English data.\nWe provide a detailed description of the training, the tuning, the safety\nalignment, and the evaluation of the models. We release two open versions of\nthe model -- the foundation Jais model, and an instruction-tuned Jais-chat\nvariant -- with the aim of promoting research on Arabic LLMs. Available at\nhttps://huggingface.co/inception-mbzuai/jais-13b-chat",
        "translated": "我们介绍了 Jais 和 Jais-chat、新的以阿拉伯语为中心的最新基础和指令调优的开放生成大型语言模型(LLM)。这些模型是基于 GPT-3解码器架构，并预先训练了阿拉伯语和英语文本的混合，包括各种编程语言的源代码。它们拥有130亿个参数，在广泛评估的基础上，比任何现有的开放式阿拉伯文和多语言模型都显示出更好的阿拉伯文知识和推理能力。此外，与以英语为中心的类似规模的开放式模型相比，这些模型在英语方面具有竞争力，尽管它们所使用的英语数据要少得多。我们提供了训练，调整，安全校准和模型的评估的详细描述。我们发布了该模型的两个开放版本—— Jais 基础模型和一个经过指令调优的 Jais-chat 变体——目的是促进对阿拉伯语 LLM 的研究。Https://huggingface.co/inception-mbzuai/jais-13b-chat 有售"
    },
    {
        "title": "LM-Infinite: Simple On-the-Fly Length Generalization for Large Language\n  Models",
        "url": "http://arxiv.org/abs/2308.16137v1",
        "pub_date": "2023-08-30",
        "summary": "In recent years, there have been remarkable advancements in the performance\nof Transformer-based Large Language Models (LLMs) across various domains. As\nthese LLMs are deployed for increasingly complex tasks, they often face the\nneeds to conduct longer reasoning processes or understanding larger contexts.\nIn these situations, the length generalization failure of LLMs on long\nsequences become more prominent. Most pre-training schemes truncate training\nsequences to a fixed length (such as 2048 for LLaMa). LLMs often struggle to\ngenerate fluent texts, let alone carry out downstream tasks, after longer\ncontexts, even with relative positional encoding which is designed to cope with\nthis problem. Common solutions such as finetuning on longer corpora often\ninvolves daunting hardware and time costs and requires careful training process\ndesign. To more efficiently leverage the generation capacity of existing LLMs,\nwe theoretically and empirically investigate the main out-of-distribution (OOD)\nfactors contributing to this problem. Inspired by this diagnosis, we propose a\nsimple yet effective solution for on-the-fly length generalization,\nLM-Infinite, which involves only a $\\Lambda$-shaped attention mask and a\ndistance limit while requiring no parameter updates or learning. We find it\napplicable to a variety of LLMs using relative-position encoding methods.\nLM-Infinite is computational efficient with $O(n)$ time and space, and\ndemonstrates consistent fluency and generation quality to as long as 32k tokens\non ArXiv and OpenWebText2 datasets, with 2.72x decoding speedup. On downstream\ntask such as passkey retrieval, it continues to work on inputs much longer than\ntraining lengths where vanilla models fail immediately.",
        "translated": "近年来，跨不同领域的基于 Transform- 的大型语言模型(LLM)在性能方面取得了显著的进展。由于这些 LLM 用于日益复杂的任务，它们往往需要进行更长的推理过程或理解更大的上下文。在这种情况下，长序列上 LLM 的长度泛化失败问题更加突出。大多数预训练方案将训练序列截断为固定长度(如 LLaMa 的2048)。LLM 通常难以生成流畅的文本，更不用说在更长的上下文之后执行下游任务，即使使用相对位置编码也是为了解决这个问题而设计的。常见的解决方案，例如在较长的语料库上进行微调，往往涉及令人生畏的硬件和时间成本，并需要仔细的培训过程设计。为了更有效地利用现有 LLM 的发电能力，我们从理论和实证上研究了造成这一问题的主要分布外因素(OOD)。受到这个诊断的启发，我们提出了一个简单而有效的解决方案，在飞行长度泛化，LM-无限，其中只涉及 $Lambda $形状的注意面具和距离限制，同时不需要参数更新或学习。我们发现它适用于各种 LLM 使用相对位置编码方法。LM-Inlimited 计算效率高，时间和空间为 $O (n) $，并且在 ArXiv 和 OpenWebText2数据集上展示了长达32k 令牌的一致流畅性和生成质量，解码加速比为2.72 x。在下游任务，如密钥检索，它继续工作的输入远远长于训练长度，即普通模型立即失败。"
    },
    {
        "title": "Response: Emergent analogical reasoning in large language models",
        "url": "http://arxiv.org/abs/2308.16118v1",
        "pub_date": "2023-08-30",
        "summary": "In their recent Nature Human Behaviour paper, \"Emergent analogical reasoning\nin large language models,\" (Webb, Holyoak, and Lu, 2023) the authors argue that\n\"large language models such as GPT-3 have acquired an emergent ability to find\nzero-shot solutions to a broad range of analogy problems.\" In this response, we\nprovide counterexamples of the letter string analogies. In our tests, GPT-3\nfails to solve even the easiest variants of the problems presented in the\noriginal paper. Zero-shot reasoning is an extraordinary claim that requires\nextraordinary evidence. We do not see that evidence in our experiments. To\nstrengthen claims of humanlike reasoning such as zero-shot reasoning, it is\nimportant that the field develop approaches that rule out data memorization.",
        "translated": "在他们最近的《自然人类行为》论文《大型语言模型中的应急类比推理》(Webb，Holyoak，and Lu，2023)中，作者认为“大型语言模型，如 GPT-3，已经获得了一种应急能力，可以找到广泛类比问题的零打击解决方案。”在这个回答中，我们提供了字母字符串类比的反例。在我们的测试中，GPT-3甚至不能解决原始论文中提出的问题的最简单的变体。零射击推理是一个非同寻常的主张，需要非同寻常的证据。我们在实验中没有看到这样的证据。为了加强类似人类推理的主张，如零拍推理，重要的是该领域开发的方法，排除数据记忆。"
    },
    {
        "title": "Grandma Karl is 27 years old -- research agenda for pseudonymization of\n  research data",
        "url": "http://arxiv.org/abs/2308.16109v1",
        "pub_date": "2023-08-30",
        "summary": "Accessibility of research data is critical for advances in many research\nfields, but textual data often cannot be shared due to the personal and\nsensitive information which it contains, e.g names or political opinions.\nGeneral Data Protection Regulation (GDPR) suggests pseudonymization as a\nsolution to secure open access to research data, but we need to learn more\nabout pseudonymization as an approach before adopting it for manipulation of\nresearch data. This paper outlines a research agenda within pseudonymization,\nnamely need of studies into the effects of pseudonymization on unstructured\ndata in relation to e.g. readability and language assessment, as well as the\neffectiveness of pseudonymization as a way of protecting writer identity, while\nalso exploring different ways of developing context-sensitive algorithms for\ndetection, labelling and replacement of personal information in unstructured\ndata. The recently granted project on pseudonymization Grandma Karl is 27 years\nold addresses exactly those challenges.",
        "translated": "研究数据的可获得性对许多研究领域的进展至关重要，但文本数据往往由于其中包含的个人和敏感信息，例如姓名或政治观点而无法共享。通用数据保护条例(GDPR)建议将假名化作为一种安全开放获取研究数据的解决方案，但在采用假名化作为操纵研究数据的一种方法之前，我们需要了解更多关于假名化的信息。本文概述了笔名化的研究议程，即需要研究笔名化对非结构化数据的影响，例如可读性和语言评估，以及笔名化作为一种保护作者身份的有效方法，同时探索不同的方法来开发上下文敏感算法，以检测、标记和替换非结构化数据中的个人信息。最近授予的项目化名奶奶卡尔是27岁，正是解决这些挑战。"
    },
    {
        "title": "Impact of Visual Context on Noisy Multimodal NMT: An Empirical Study for\n  English to Indian Languages",
        "url": "http://arxiv.org/abs/2308.16075v1",
        "pub_date": "2023-08-30",
        "summary": "The study investigates the effectiveness of utilizing multimodal information\nin Neural Machine Translation (NMT). While prior research focused on using\nmultimodal data in low-resource scenarios, this study examines how image\nfeatures impact translation when added to a large-scale, pre-trained unimodal\nNMT system. Surprisingly, the study finds that images might be redundant in\nthis context. Additionally, the research introduces synthetic noise to assess\nwhether images help the model deal with textual noise. Multimodal models\nslightly outperform text-only models in noisy settings, even with random\nimages. The study's experiments translate from English to Hindi, Bengali, and\nMalayalam, outperforming state-of-the-art benchmarks significantly.\nInterestingly, the effect of visual context varies with source text noise: no\nvisual context works best for non-noisy translations, cropped image features\nare optimal for low noise, and full image features work better in high-noise\nscenarios. This sheds light on the role of visual context, especially in noisy\nsettings, opening up a new research direction for Noisy Neural Machine\nTranslation in multimodal setups. The research emphasizes the importance of\ncombining visual and textual information for improved translation in various\nenvironments.",
        "translated": "本研究旨在探讨多模态资讯在神经机器翻译中的应用效果。虽然先前的研究侧重于在低资源情况下使用多模态数据，但本研究考察了图像特征如何影响大规模、预先训练的单模态 NMT 系统的翻译。令人惊讶的是，研究发现图像在这种情况下可能是多余的。此外，本研究还引入合成噪声来评估图像是否有助于模型处理文本噪声。在嘈杂环境下，即使是随机图像，多模态模型的性能也略胜于纯文本模型。这项研究的实验从英语翻译成印地语、孟加拉语和马拉雅拉姆语，表现明显优于最先进的基准。有趣的是，视觉上下文的效果随着源文本噪声的不同而不同: 对于无噪声的翻译，没有视觉上下文效果最好; 对于低噪声的翻译，裁剪后的图像特征效果最好; 对于高噪声的场景，完整的图像特征效果更好。这为研究多通道环境下的噪声神经机器翻译提供了新的研究方向。该研究强调了视觉信息和文本信息相结合对于在不同环境下改进翻译的重要性。"
    },
    {
        "title": "Conti Inc.: Understanding the Internal Discussions of a large\n  Ransomware-as-a-Service Operator with Machine Learning",
        "url": "http://arxiv.org/abs/2308.16061v1",
        "pub_date": "2023-08-30",
        "summary": "Ransomware-as-a-service (RaaS) is increasing the scale and complexity of\nransomware attacks. Understanding the internal operations behind RaaS has been\na challenge due to the illegality of such activities. The recent chat leak of\nthe Conti RaaS operator, one of the most infamous ransomware operators on the\ninternational scene, offers a key opportunity to better understand the inner\nworkings of such organizations. This paper analyzes the main topic discussions\nin the Conti chat leak using machine learning techniques such as Natural\nLanguage Processing (NLP) and Latent Dirichlet Allocation (LDA), as well as\nvisualization strategies. Five discussion topics are found: 1) Business, 2)\nTechnical, 3) Internal tasking/Management, 4) Malware, and 5) Customer\nService/Problem Solving. Moreover, the distribution of topics among Conti\nmembers shows that only 4% of individuals have specialized discussions while\nalmost all individuals (96%) are all-rounders, meaning that their discussions\nrevolve around the five topics. The results also indicate that a significant\nproportion of Conti discussions are non-tech related. This study thus\nhighlights that running such large RaaS operations requires a workforce skilled\nbeyond technical abilities, with individuals involved in various tasks, from\nmanagement to customer service or problem solving. The discussion topics also\nshow that the organization behind the Conti RaaS oper5086933ator shares\nsimilarities with a large firm. We conclude that, although RaaS represents an\nexample of specialization in the cybercrime industry, only a few members are\nspecialized in one topic, while the rest runs and coordinates the RaaS\noperation.",
        "translated": "勒索软件即服务(RaaS)正在增加勒索软件攻击的规模和复杂性。由于此类活动的非法性，理解 RaaS 背后的内部操作一直是一个挑战。Conti RaaS 操作员是国际上最臭名昭著的勒索软件操作员之一，最近的聊天泄露事件为更好地了解这类组织的内部运作提供了一个关键机会。本文使用自然语言处理(NLP)和隐含狄利克雷分布(LDA)等机器学习技术，以及可视化策略，分析了 Conti 聊天泄露中的主要话题讨论。5个讨论主题: 1)业务，2)技术，3)内部任务/管理，4)恶意软件，和5)客户服务/问题解决。此外，Conti 成员之间的话题分布表明，只有4% 的个人有专门的讨论，而几乎所有的个人(96%)都是全面的，这意味着他们的讨论围绕着五个话题。研究结果还表明，很大一部分 Conti 讨论与技术无关。因此，这项研究强调，运行如此大规模的 RaaS 业务需要一支技术能力超越技术能力的员工队伍，其中包括从管理到客户服务或解决问题等各种任务的个人。讨论主题还表明，Conti RaaS oper5086933ator 背后的组织与大型公司有相似之处。我们得出的结论是，虽然 RaaS 代表了网络犯罪行业的专业化的一个例子，但只有少数成员专门处理一个主题，而其他成员运行和协调 RaaS 操作。"
    },
    {
        "title": "Text-to-OverpassQL: A Natural Language Interface for Complex Geodata\n  Querying of OpenStreetMap",
        "url": "http://arxiv.org/abs/2308.16060v1",
        "pub_date": "2023-08-30",
        "summary": "We present Text-to-OverpassQL, a task designed to facilitate a natural\nlanguage interface for querying geodata from OpenStreetMap (OSM). The Overpass\nQuery Language (OverpassQL) allows users to formulate complex database queries\nand is widely adopted in the OSM ecosystem. Generating Overpass queries from\nnatural language input serves multiple use-cases. It enables novice users to\nutilize OverpassQL without prior knowledge, assists experienced users with\ncrafting advanced queries, and enables tool-augmented large language models to\naccess information stored in the OSM database. In order to assess the\nperformance of current sequence generation models on this task, we propose\nOverpassNL, a dataset of 8,352 queries with corresponding natural language\ninputs. We further introduce task specific evaluation metrics and ground the\nevaluation of the Text-to-OverpassQL task by executing the queries against the\nOSM database. We establish strong baselines by finetuning sequence-to-sequence\nmodels and adapting large language models with in-context examples. The\ndetailed evaluation reveals strengths and weaknesses of the considered learning\nstrategies, laying the foundations for further research into the\nText-to-OverpassQL task.",
        "translated": "我们介绍了 Text-to-OverpassQL，这是一个旨在促进从 OpenStreetMap (OSM)查询地理数据的自然语言接口的任务。Overpass Query Language (OverpassQL)允许用户规划复杂的数据库查询，并被 OSM 生态系统广泛采用。从自然语言输入生成 Overpass 查询服务于多个用例。它使新手用户能够在没有事先知识的情况下利用 OverpassQL，帮助有经验的用户设计高级查询，并使工具增强的大型语言模型能够访问存储在 OSM 数据库中的信息。为了评估当前序列生成模型在这个任务上的性能，我们提出 OverpassNL，一个包含8,352个查询和相应的自然语言输入的数据集。我们进一步引入特定于任务的评估指标，并通过对 OSM 数据库执行查询来基础化 Text-to-OverpassQL 任务的评估。我们通过调整序列到序列模型和使用上下文示例来调整大型语言模型来建立强大的基线。详细的评估揭示了所考虑的学习策略的优缺点，为进一步研究文本-超越 QL 任务奠定了基础。"
    },
    {
        "title": "AsyncET: Asynchronous Learning for Knowledge Graph Entity Typing with\n  Auxiliary Relations",
        "url": "http://arxiv.org/abs/2308.16055v1",
        "pub_date": "2023-08-30",
        "summary": "Knowledge graph entity typing (KGET) is a task to predict the missing entity\ntypes in knowledge graphs (KG). Previously, KG embedding (KGE) methods tried to\nsolve the KGET task by introducing an auxiliary relation, 'hasType', to model\nthe relationship between entities and their types. However, a single auxiliary\nrelation has limited expressiveness for diverse entity-type patterns. We\nimprove the expressiveness of KGE methods by introducing multiple auxiliary\nrelations in this work. Similar entity types are grouped to reduce the number\nof auxiliary relations and improve their capability to model entity-type\npatterns with different granularities. With the presence of multiple auxiliary\nrelations, we propose a method adopting an Asynchronous learning scheme for\nEntity Typing, named AsyncET, which updates the entity and type embeddings\nalternatively to keep the learned entity embedding up-to-date and informative\nfor entity type prediction. Experiments are conducted on two commonly used KGET\ndatasets to show that the performance of KGE methods on the KGET task can be\nsubstantially improved by the proposed multiple auxiliary relations and\nasynchronous embedding learning. Furthermore, our method has a significant\nadvantage over state-of-the-art methods in model sizes and time complexity.",
        "translated": "知识图实体分类(KGET)是一项预测知识图中缺失实体类型的任务。以前，KG 嵌入(KGE)方法试图通过引入辅助关系“ hasType”来建模实体及其类型之间的关系来解决 KGET 任务。然而，对于不同的实体类型模式，单个辅助关系的表达能力是有限的。通过引入多个辅助关系，提高了 KGE 方法的表达能力。对相似的实体类型进行分组，以减少辅助关系的数量，并提高它们对具有不同粒度的实体类型模式进行建模的能力。针对多个辅助关系的存在，提出了一种基于实体分类的异步学习方法 AsyncET，该方法交替更新实体嵌入和类型嵌入，使学习到的实体嵌入更新，为实体类型预测提供信息。在两个常用的 KGET 数据集上进行了实验，实验结果表明，提出的多个辅助关系和异步嵌入学习可以显著提高 KGE 方法在 KGET 任务中的性能。此外，我们的方法在模型大小和时间复杂度方面比最先进的方法有明显的优势。"
    },
    {
        "title": "FPTQ: Fine-grained Post-Training Quantization for Large Language Models",
        "url": "http://arxiv.org/abs/2308.15987v1",
        "pub_date": "2023-08-30",
        "summary": "In the era of large-scale language models, the substantial parameter size\nposes significant challenges for deployment. Being a prevalent compression\ntechnique, quantization has emerged as the mainstream practice to tackle this\nissue, which is mainly centered on two recipes W8A8 and W4A16 (i.e. weights and\nactivations in such bit widths). In this study, we propose a novel W4A8\npost-training quantization method for the available open-sourced LLMs, which\ncombines the advantages of both two recipes. Therefore, we can leverage the\nbenefit in the I/O utilization of 4-bit weight quantization and the\nacceleration due to 8-bit matrix computation. Nevertheless, the W4A8 faces\nnotorious performance degradation. As a remedy, we involve layerwise activation\nquantization strategies which feature a novel logarithmic equalization for most\nintractable layers, and we combine them with fine-grained weight quantization.\nWithout whistles and bells, we eliminate the necessity for further fine-tuning\nand obtain the state-of-the-art W4A8 quantized performance on BLOOM, LLaMA, and\nLLaMA-2 on standard benchmarks. We confirm that the W4A8 quantization is\nachievable for the deployment of large language models, fostering their\nwide-spreading real-world applications.",
        "translated": "在大规模语言模型时代，大量的参数大小对部署提出了严峻的挑战。作为一种流行的压缩技术，量化已经成为解决这个问题的主流实践，其主要集中在两个配方 W8A8和 W4A16(即这种位宽度的权重和激活)。在这项研究中，我们提出了一种新颖的 W4A8训练后量化方法对现有的开源 LLM，它结合了两个配方的优点。因此，我们可以利用4位权重量化在 I/O 利用方面的好处，以及由于8位矩阵计算所带来的加速。然而，W4A8面临着臭名昭著的性能下降。作为补救，我们涉及分层激活量化策略，其特点是一种新的对数均衡最棘手的层，我们结合他们与细粒度权量化。如果没有花哨的功能，我们就不需要进行进一步的微调，并且可以在 BLOOM、 LLaMA 和 LLaMA-2上获得最先进的 W4A8量化性能。我们确认，W4A8量化是可以实现的部署大型语言模型，促进其广泛传播的现实世界的应用。"
    },
    {
        "title": "Co-evolving Vector Quantization for ID-based Recommendation",
        "url": "http://arxiv.org/abs/2308.16761v1",
        "pub_date": "2023-08-31",
        "summary": "Category information plays a crucial role in enhancing the quality and\npersonalization of recommendations. Nevertheless, the availability of item\ncategory information is not consistently present, particularly in the context\nof ID-based recommendations. In this work, we propose an alternative approach\nto automatically learn and generate entity (i.e., user and item) categorical\ninformation at different levels of granularity, specifically for ID-based\nrecommendation. Specifically, we devise a co-evolving vector quantization\nframework, namely COVE, which enables the simultaneous learning and refinement\nof code representation and entity embedding in an end-to-end manner, starting\nfrom the randomly initialized states. With its high adaptability, COVE can be\neasily integrated into existing recommendation models. We validate the\neffectiveness of COVE on various recommendation tasks including list\ncompletion, collaborative filtering, and click-through rate prediction, across\ndifferent recommendation models. We will publish the code and data for other\nresearchers to reproduce our work.",
        "translated": "分类信息在提高推荐的质量和个性化方面起着至关重要的作用。尽管如此，项目类别信息的可用性并不一致，特别是在基于 ID 的推荐上下文中。在这项工作中，我们提出了一种替代方法，自动学习和生成实体(即，用户和项目)的分类信息在不同的粒度级别，特别是为基于 ID 的推荐。具体来说，我们设计了一个共同发展的向量量化框架，即 COVE，它能够同时学习和细化代码表示和实体嵌入的端到端方式，从随机初始化状态开始。COVE 具有很强的适应性，可以很容易地集成到现有的推荐模型中。我们验证了 COVE 在不同推荐模型中对各种推荐任务的有效性，包括列表完成、协同过滤和点进率预测。我们将公布代码和数据，供其他研究人员复制我们的工作。"
    },
    {
        "title": "Context Aware Query Rewriting for Text Rankers using LLM",
        "url": "http://arxiv.org/abs/2308.16753v1",
        "pub_date": "2023-08-31",
        "summary": "Query rewriting refers to an established family of approaches that are\napplied to underspecified and ambiguous queries to overcome the vocabulary\nmismatch problem in document ranking. Queries are typically rewritten during\nquery processing time for better query modelling for the downstream ranker.\nWith the advent of large-language models (LLMs), there have been initial\ninvestigations into using generative approaches to generate pseudo documents to\ntackle this inherent vocabulary gap. In this work, we analyze the utility of\nLLMs for improved query rewriting for text ranking tasks. We find that there\nare two inherent limitations of using LLMs as query re-writers -- concept drift\nwhen using only queries as prompts and large inference costs during query\nprocessing. We adopt a simple, yet surprisingly effective, approach called\ncontext aware query rewriting (CAR) to leverage the benefits of LLMs for query\nunderstanding. Firstly, we rewrite ambiguous training queries by context-aware\nprompting of LLMs, where we use only relevant documents as context.Unlike\nexisting approaches, we use LLM-based query rewriting only during the training\nphase. Eventually, a ranker is fine-tuned on the rewritten queries instead of\nthe original queries during training. In our extensive experiments, we find\nthat fine-tuning a ranker using re-written queries offers a significant\nimprovement of up to 33% on the passage ranking task and up to 28% on the\ndocument ranking task when compared to the baseline performance of using\noriginal queries.",
        "translated": "查询重写是指一系列已建立的方法，这些方法应用于指定不足和模糊的查询，以克服文档排序中的词汇表不匹配问题。查询通常在查询处理期间重写，以便为下游排名建立更好的查询模型。随着大语言模型(LLM)的出现，人们开始研究使用生成方法生成伪文档来解决这一固有的词汇差距。在这项工作中，我们分析了 LLM 的效用改进查询重写的文本排序任务。我们发现使用 LLM 作为查询重写器有两个固有的局限性——仅使用查询作为提示时的概念漂移和查询处理期间的大推理成本。我们采用了一种简单但是非常有效的方法，称为上下文感知查询重写(CAR) ，以利用 LLM 对查询理解的好处。首先，我们通过 LLM 的上下文感知提示重写模糊训练查询，其中我们只使用相关文档作为上下文。与现有的方法不同，我们只在训练阶段使用基于 LLM 的查询重写。最终，在训练期间，对重写查询而不是原始查询对排名进行微调。在我们的大量实验中，我们发现使用重写查询对排名进行微调，与使用原始查询的基线性能相比，在段落排名任务和文档排名任务上分别提供了高达33% 和高达28% 的显著改善。"
    },
    {
        "title": "Concentrating on the Impact: Consequence-based Explanations in\n  Recommender Systems",
        "url": "http://arxiv.org/abs/2308.16708v1",
        "pub_date": "2023-08-31",
        "summary": "Recommender systems assist users in decision-making, where the presentation\nof recommended items and their explanations are critical factors for enhancing\nthe overall user experience. Although various methods for generating\nexplanations have been proposed, there is still room for improvement,\nparticularly for users who lack expertise in a specific item domain. In this\nstudy, we introduce the novel concept of \\textit{consequence-based\nexplanations}, a type of explanation that emphasizes the individual impact of\nconsuming a recommended item on the user, which makes the effect of following\nrecommendations clearer. We conducted an online user study to examine our\nassumption about the appreciation of consequence-based explanations and their\nimpacts on different explanation aims in recommender systems. Our findings\nhighlight the importance of consequence-based explanations, which were\nwell-received by users and effectively improved user satisfaction in\nrecommender systems. These results provide valuable insights for designing\nengaging explanations that can enhance the overall user experience in\ndecision-making.",
        "translated": "推荐系统协助用户作出决策，推荐项目的列报及其说明是提高用户总体体验的关键因素。虽然已经提出了各种产生解释的方法，但仍有改进的余地，特别是对于缺乏特定项目领域专门知识的用户。在这项研究中，我们引入了文本(基于结果的解释)的新概念，一种强调消费推荐项目对用户的个人影响的解释类型，这使得以下推荐的效果更加清晰。我们进行了一项在线用户研究，以检验我们的假设关于鉴赏的结果为基础的解释及其对不同的解释目的在推荐系统的影响。我们的研究结果强调了基于结果的解释的重要性，这些解释得到了用户的好评，有效地提高了推荐系统中用户的满意度。这些结果为设计引人入胜的解释提供了有价值的见解，可以提高整体用户在决策过程中的体验。"
    },
    {
        "title": "Towards Long-Tailed Recognition for Graph Classification via\n  Collaborative Experts",
        "url": "http://arxiv.org/abs/2308.16609v1",
        "pub_date": "2023-08-31",
        "summary": "Graph classification, aiming at learning the graph-level representations for\neffective class assignments, has received outstanding achievements, which\nheavily relies on high-quality datasets that have balanced class distribution.\nIn fact, most real-world graph data naturally presents a long-tailed form,\nwhere the head classes occupy much more samples than the tail classes, it thus\nis essential to study the graph-level classification over long-tailed data\nwhile still remaining largely unexplored. However, most existing long-tailed\nlearning methods in visions fail to jointly optimize the representation\nlearning and classifier training, as well as neglect the mining of the\nhard-to-classify classes. Directly applying existing methods to graphs may lead\nto sub-optimal performance, since the model trained on graphs would be more\nsensitive to the long-tailed distribution due to the complex topological\ncharacteristics. Hence, in this paper, we propose a novel long-tailed\ngraph-level classification framework via Collaborative Multi-expert Learning\n(CoMe) to tackle the problem. To equilibrate the contributions of head and tail\nclasses, we first develop balanced contrastive learning from the view of\nrepresentation learning, and then design an individual-expert classifier\ntraining based on hard class mining. In addition, we execute gated fusion and\ndisentangled knowledge distillation among the multiple experts to promote the\ncollaboration in a multi-expert framework. Comprehensive experiments are\nperformed on seven widely-used benchmark datasets to demonstrate the\nsuperiority of our method CoMe over state-of-the-art baselines.",
        "translated": "图分类以学习有效的类别分配的图级表示为目标，已经取得了突出的成就，它严重依赖于具有均衡类别分布的高质量数据集。事实上，大多数真实世界的图形数据自然地呈现出长尾形式，其中头类比尾类占据更多的样本，因此研究长尾数据的图级分类是必要的，同时仍然保持大部分未被探索。然而，现有的视觉长尾学习方法大多未能将表示学习和分类器训练结合起来进行优化，也忽视了难分类类的挖掘。将已有的方法直接应用于图，由于复杂的拓扑特性，使得图上训练的模型对长尾分布更加敏感，可能会导致性能的次优化。为此，本文提出了一种基于协同多专家学习(CoMe)的长尾图级分类框架来解决这一问题。为了均衡头类和尾类的贡献，我们首先从表示学习的角度出发发展了均衡对比学习，然后设计了一种基于硬类挖掘的个体-专家分类器训练方法。此外，我们在多个专家之间进行门限融合和分离知识提取，以促进多专家框架下的协作。在七个广泛使用的基准数据集上进行了全面的实验，证明了我们的方法 CoMe 相对于最先进的基准线的优越性。"
    },
    {
        "title": "Recommender AI Agent: Integrating Large Language Models for Interactive\n  Recommendations",
        "url": "http://arxiv.org/abs/2308.16505v1",
        "pub_date": "2023-08-31",
        "summary": "Recommender models excel at providing domain-specific item recommendations by\nleveraging extensive user behavior data. Despite their ability to act as\nlightweight domain experts, they struggle to perform versatile tasks such as\nproviding explanations and engaging in conversations. On the other hand, large\nlanguage models (LLMs) represent a significant step towards artificial general\nintelligence, showcasing remarkable capabilities in instruction comprehension,\ncommonsense reasoning, and human interaction. However, LLMs lack the knowledge\nof domain-specific item catalogs and behavioral patterns, particularly in areas\nthat diverge from general world knowledge, such as online e-commerce.\nFinetuning LLMs for each domain is neither economic nor efficient.\n  In this paper, we bridge the gap between recommender models and LLMs,\ncombining their respective strengths to create a versatile and interactive\nrecommender system. We introduce an efficient framework called RecAgent, which\nemploys LLMs as the brain and recommender models as tools. We first outline a\nminimal set of essential tools required to transform LLMs into RecAgent. We\nthen propose an efficient workflow within RecAgent for task execution,\nincorporating key components such as a memory bus, dynamic\ndemonstration-augmented task planning, and reflection. RecAgent enables\ntraditional recommender systems, such as those ID-based matrix factorization\nmodels, to become interactive systems with a natural language interface through\nthe integration of LLMs. Experimental results on several public datasets show\nthat RecAgent achieves satisfying performance as a conversational recommender\nsystem, outperforming general-purpose LLMs.",
        "translated": "推荐器模型通过利用广泛的用户行为数据，擅长提供特定于领域的项目推荐。尽管他们有能力扮演轻量级领域专家的角色，但他们很难完成多种任务，例如提供解释和参与对话。另一方面，大型语言模型(LLM)代表了人工通用智能的重要一步，展示了在教学理解、常识推理和人际互动方面的卓越能力。然而，LLM 缺乏领域特定项目目录和行为模式的知识，特别是在与一般世界知识不同的领域，如在线电子商务。每个域的微调 LLM 既不经济也不有效。在本文中，我们将建议模型和 LLM 模型之间的差距连接起来，结合它们各自的优势，创建一个通用的、交互式的推荐系统。我们引入了一个名为 RecAgent 的高效框架，它使用 LLM 作为大脑，使用推荐模型作为工具。我们首先概述了将 LLM 转换为 RecAgent 所需的一组基本工具。然后，我们在 RecAgent 中提出了一个高效的任务执行工作流，其中包含了一些关键组件，如内存总线、动态演示增强的任务规划和反射。RecAgent 通过集成 LLM，使传统的推荐系统(如基于 ID 的矩阵分解模型)成为具有自然语言界面的交互式系统。在几个公共数据集上的实验结果表明，RecAgent 作为会话推荐系统获得了令人满意的性能，优于通用 LLM。"
    },
    {
        "title": "PointLLM: Empowering Large Language Models to Understand Point Clouds",
        "url": "http://arxiv.org/abs/2308.16911v1",
        "pub_date": "2023-08-31",
        "summary": "The unprecedented advancements in Large Language Models (LLMs) have created a\nprofound impact on natural language processing but are yet to fully embrace the\nrealm of 3D understanding. This paper introduces PointLLM, a preliminary effort\nto fill this gap, thereby enabling LLMs to understand point clouds and offering\na new avenue beyond 2D visual data. PointLLM processes colored object point\nclouds with human instructions and generates contextually appropriate\nresponses, illustrating its grasp of point clouds and common sense.\nSpecifically, it leverages a point cloud encoder with a powerful LLM to\neffectively fuse geometric, appearance, and linguistic information. We collect\na novel dataset comprising 660K simple and 70K complex point-text instruction\npairs to enable a two-stage training strategy: initially aligning latent spaces\nand subsequently instruction-tuning the unified model. To rigorously evaluate\nour model's perceptual abilities and its generalization capabilities, we\nestablish two benchmarks: Generative 3D Object Classification and 3D Object\nCaptioning, assessed through three different methods, including human\nevaluation, GPT-4/ChatGPT evaluation, and traditional metrics. Experiment\nresults show that PointLLM demonstrates superior performance over existing 2D\nbaselines. Remarkably, in human-evaluated object captioning tasks, PointLLM\noutperforms human annotators in over 50% of the samples. Codes, datasets, and\nbenchmarks are available at https://github.com/OpenRobotLab/PointLLM .",
        "translated": "大型语言模型(LLM)的前所未有的进步对自然语言处理产生了深远的影响，但尚未完全包含3D 理解领域。本文介绍了 PointLLM，这是填补这一空白的初步尝试，从而使 LLM 能够理解点云，并提供了一种超越2D 可视数据的新途径。PointLLM 使用人工指令处理彩色对象点云，并生成与上下文相适应的响应，说明其对点云和常识的理解。具体来说，它利用一个带有强大 LLM 的点云编码器来有效地融合几何、外观和语言信息。我们收集了一个包含660K 简单指令和70K 复杂点文本指令对的新数据集，实现了一个两阶段的训练策略: 首先对齐潜在空间，然后对统一模型进行指令调整。为了严格评估我们的模型的感知能力和泛化能力，我们建立了两个基准: 生成性3D 对象分类和3D 对象字幕，通过三种不同的方法进行评估，包括人类评估，GPT-4/ChatGPT 评估和传统指标。实验结果表明，PointLLM 的性能优于现有的二维基线。值得注意的是，在人工评估的对象字幕任务中，PointLLM 在超过50% 的示例中优于人工注释器。代码、数据集和基准测试可以在 https://github.com/openrobotlab/pointllm 中获得。"
    },
    {
        "title": "Transformers as Support Vector Machines",
        "url": "http://arxiv.org/abs/2308.16898v1",
        "pub_date": "2023-08-31",
        "summary": "Since its inception in \"Attention Is All You Need\", transformer architecture\nhas led to revolutionary advancements in NLP. The attention layer within the\ntransformer admits a sequence of input tokens $X$ and makes them interact\nthrough pairwise similarities computed as softmax$(XQK^\\top X^\\top)$, where\n$(K,Q)$ are the trainable key-query parameters. In this work, we establish a\nformal equivalence between the optimization geometry of self-attention and a\nhard-margin SVM problem that separates optimal input tokens from non-optimal\ntokens using linear constraints on the outer-products of token pairs. This\nformalism allows us to characterize the implicit bias of 1-layer transformers\noptimized with gradient descent: (1) Optimizing the attention layer with\nvanishing regularization, parameterized by $(K,Q)$, converges in direction to\nan SVM solution minimizing the nuclear norm of the combined parameter\n$W=KQ^\\top$. Instead, directly parameterizing by $W$ minimizes a Frobenius norm\nobjective. We characterize this convergence, highlighting that it can occur\ntoward locally-optimal directions rather than global ones. (2) Complementing\nthis, we prove the local/global directional convergence of gradient descent\nunder suitable geometric conditions. Importantly, we show that\nover-parameterization catalyzes global convergence by ensuring the feasibility\nof the SVM problem and by guaranteeing a benign optimization landscape devoid\nof stationary points. (3) While our theory applies primarily to linear\nprediction heads, we propose a more general SVM equivalence that predicts the\nimplicit bias with nonlinear heads. Our findings are applicable to arbitrary\ndatasets and their validity is verified via experiments. We also introduce\nseveral open problems and research directions. We believe these findings\ninspire the interpretation of transformers as a hierarchy of SVMs that\nseparates and selects optimal tokens.",
        "translated": "自从在“注意力是你所需要的一切”中成立以来，变压器结构已经导致了自然语言处理的革命性进展。转换器中的注意层允许一系列输入令牌 $X $，并使它们通过计算为 softmax $(XQK ^ top X ^ top) $的成对相似性进行交互，其中 $(K，Q) $是可训练的键查询参数。在这项工作中，我们建立了自我注意的优化几何和一个硬边界 SVM 问题之间的形式等价性，该问题使用令牌对的外积上的线性约束来区分最优输入令牌和非最优令牌。这种形式使我们能够描述用梯度下降法优化的单层变压器的隐式偏差: (1)用消失正则化优化注意层，参数为 $(K，Q) $，收敛于方向上的支持向量机解，最小化组合参数的核范数 $W = KQ ^ top $。相反，通过 $W $直接参数化最小化 Frobenius 规范目标。我们描述了这种收敛的特点，强调它可以朝着局部最优方向发生，而不是全局最优方向。(2)作为补充，我们证明了在适当的几何条件下梯度下降法的局部/全局方向收敛性。重要的是，我们表明，过参数化催化全局收敛的支持向量机问题的可行性，并保证良性优化景观没有驻点。(3)虽然我们的理论主要应用于线性预测，但我们提出了一个更一般的支持向量机等价模型来预测非线性头部的隐含偏差。我们的研究结果适用于任意数据集，并通过实验验证了其有效性。本文还介绍了几个开放性问题和研究方向。我们相信这些发现启发了变压器的解释作为一个层次的支持向量机，分离和选择最佳令牌。"
    },
    {
        "title": "TouchStone: Evaluating Vision-Language Models by Language Models",
        "url": "http://arxiv.org/abs/2308.16890v1",
        "pub_date": "2023-08-31",
        "summary": "Large vision-language models (LVLMs) have recently witnessed rapid\nadvancements, exhibiting a remarkable capacity for perceiving, understanding,\nand processing visual information by connecting visual receptor with large\nlanguage models (LLMs). However, current assessments mainly focus on\nrecognizing and reasoning abilities, lacking direct evaluation of\nconversational skills and neglecting visual storytelling abilities. In this\npaper, we propose an evaluation method that uses strong LLMs as judges to\ncomprehensively evaluate the various abilities of LVLMs. Firstly, we construct\na comprehensive visual dialogue dataset TouchStone, consisting of open-world\nimages and questions, covering five major categories of abilities and 27\nsubtasks. This dataset not only covers fundamental recognition and\ncomprehension but also extends to literary creation. Secondly, by integrating\ndetailed image annotations we effectively transform the multimodal input\ncontent into a form understandable by LLMs. This enables us to employ advanced\nLLMs for directly evaluating the quality of the multimodal dialogue without\nrequiring human intervention. Through validation, we demonstrate that powerful\nLVLMs, such as GPT-4, can effectively score dialogue quality by leveraging\ntheir textual capabilities alone, aligning with human preferences. We hope our\nwork can serve as a touchstone for LVLMs' evaluation and pave the way for\nbuilding stronger LVLMs. The evaluation code is available at\nhttps://github.com/OFA-Sys/TouchStone.",
        "translated": "大型视觉语言模型(LVLM)近年来发展迅速，通过将视觉受体与大型语言模型(LLM)连接起来，显示出显著的感知、理解和处理视觉信息的能力。然而，目前的评价主要集中在识别和推理能力上，缺乏对会话技巧的直接评价，忽视了视觉叙事能力。本文提出了一种利用强 LLM 作为评判标准来综合评价 LVLM 的各种能力的评价方法。首先，我们构建了一个全面的视觉对话数据集 TouchStone，该数据集由开放世界的图像和问题组成，涵盖了五大类能力和27个子任务。这个数据集不仅涵盖了基本的认识和理解，而且延伸到文学创作。其次，通过集成详细的图像注释，有效地将多模态输入内容转换为 LLM 可以理解的形式。这使我们能够使用高级 LLM 直接评估多式联运对话的质量，而无需人工干预。通过验证，我们证明了强大的 LVLM，如 GPT-4，可以有效地评分对话质量，利用他们的文本能力单独，与人的偏好。我们希望我们的工作能够成为 LVLM 评估的试金石，并为建立更强大的 LVLM 铺平道路。评估守则可于 https://github.com/ofa-sys/touchstone 索取。"
    },
    {
        "title": "The Belebele Benchmark: a Parallel Reading Comprehension Dataset in 122\n  Language Variants",
        "url": "http://arxiv.org/abs/2308.16884v1",
        "pub_date": "2023-08-31",
        "summary": "We present Belebele, a multiple-choice machine reading comprehension (MRC)\ndataset spanning 122 language variants. Significantly expanding the language\ncoverage of natural language understanding (NLU) benchmarks, this dataset\nenables the evaluation of text models in high-, medium-, and low-resource\nlanguages. Each question is based on a short passage from the Flores-200\ndataset and has four multiple-choice answers. The questions were carefully\ncurated to discriminate between models with different levels of general\nlanguage comprehension. The English dataset on its own proves difficult enough\nto challenge state-of-the-art language models. Being fully parallel, this\ndataset enables direct comparison of model performance across all languages. We\nuse this dataset to evaluate the capabilities of multilingual masked language\nmodels (MLMs) and large language models (LLMs). We present extensive results\nand find that despite significant cross-lingual transfer in English-centric\nLLMs, much smaller MLMs pretrained on balanced multilingual data still\nunderstand far more languages. We also observe that larger vocabulary size and\nconscious vocabulary construction correlate with better performance on\nlow-resource languages. Overall, Belebele opens up new avenues for evaluating\nand analyzing the multilingual capabilities of NLP systems.",
        "translated": "我们展示了 Belebele，一个跨越122种语言变体的多选择机器阅读理解(MRC)数据集。该数据集显著扩展了自然语言理解(NLU)基准的语言覆盖范围，使得能够评估高、中、低资源语言中的文本模型。每个问题都基于 Flores-200数据集中的一个短文，并有四个选择题答案。这些问题被精心策划，以区分不同水平的一般语言理解模型。事实证明，英语数据集本身就很难挑战最先进的语言模型。这个数据集完全并行，可以直接比较所有语言的模型性能。我们使用这个数据集来评估多语言掩蔽语言模型(MLM)和大语言模型(LLM)的能力。我们提出了广泛的结果，并发现尽管在以英语为中心的传销中存在显著的跨语言迁移，但是在平衡的多语言数据上预先训练的小得多的传销仍然能够理解更多的语言。我们还观察到，较大的词汇量和有意识的词汇构建与较好的表现在低资源语言。总的来说，Belebele 为评估和分析 NLP 系统的多语言能力开辟了新的途径。"
    },
    {
        "title": "The Gender-GAP Pipeline: A Gender-Aware Polyglot Pipeline for Gender\n  Characterisation in 55 Languages",
        "url": "http://arxiv.org/abs/2308.16871v1",
        "pub_date": "2023-08-31",
        "summary": "Gender biases in language generation systems are challenging to mitigate. One\npossible source for these biases is gender representation disparities in the\ntraining and evaluation data. Despite recent progress in documenting this\nproblem and many attempts at mitigating it, we still lack shared methodology\nand tooling to report gender representation in large datasets. Such\nquantitative reporting will enable further mitigation, e.g., via data\naugmentation. This paper describes the Gender-GAP Pipeline (for Gender-Aware\nPolyglot Pipeline), an automatic pipeline to characterize gender representation\nin large-scale datasets for 55 languages. The pipeline uses a multilingual\nlexicon of gendered person-nouns to quantify the gender representation in text.\nWe showcase it to report gender representation in WMT training data and\ndevelopment data for the News task, confirming that current data is skewed\ntowards masculine representation. Having unbalanced datasets may indirectly\noptimize our systems towards outperforming one gender over the others. We\nsuggest introducing our gender quantification pipeline in current datasets and,\nideally, modifying them toward a balanced representation.",
        "translated": "语言生成系统中的性别偏见很难减轻。造成这些偏见的一个可能原因是培训和评价数据中的性别代表性差异。尽管最近在记录这一问题方面取得了进展，并为减轻这一问题作出了许多努力，但我们仍然缺乏共同的方法和工具，无法在大型数据集中报告性别代表情况。这样的定量报告将能够进一步减轻影响，例如，通过数据增强。本文描述了性别差异管道(性别意识多语言管道) ，一个自动管道表征性别表示在大规模数据集为55种语言。该流水线使用一个多语言词典的性别人称名词来量化文本中的性别表示。我们展示了它在 WMT 培训数据和新闻任务的发展数据中报告性别代表性，证实目前的数据倾向于男性代表性。拥有不平衡的数据集可能会间接地优化我们的系统，从而超越一个性别。我们建议在当前的数据集中引入我们的性别量化流水线，并在理想的情况下对它们进行修改，以实现均衡的表示。"
    },
    {
        "title": "Can Programming Languages Boost Each Other via Instruction Tuning?",
        "url": "http://arxiv.org/abs/2308.16824v1",
        "pub_date": "2023-08-31",
        "summary": "When human programmers have mastered a programming language, it would be\neasier when they learn a new programming language. In this report, we focus on\nexploring whether programming languages can boost each other during the\ninstruction fine-tuning phase of code large language models. We conduct\nextensive experiments of 8 popular programming languages (Python, JavaScript,\nTypeScript, C, C++, Java, Go, HTML) on StarCoder. Results demonstrate that\nprogramming languages can significantly improve each other. For example,\nCodeM-Python 15B trained on Python is able to increase Java by an absolute\n17.95% pass@1 on HumanEval-X. More surprisingly, we found that CodeM-HTML 7B\ntrained on the HTML corpus can improve Java by an absolute 15.24% pass@1. Our\ntraining data is released at https://github.com/NL2Code/CodeM.",
        "translated": "当人类程序员掌握了一种编程语言时，学习一种新的编程语言会更容易。在本报告中，我们着重探讨编程语言能否在代码大语言模型的指令微调阶段相互促进。我们在 StarCoder 上对8种流行的编程语言(Python、 JavaScript、 TypeScript、 C、 C + + 、 Java、 Go、 HTML)进行了广泛的实验。结果表明，编程语言可以显著改善彼此。例如，在 Python 上进行培训的 CodeM-Python 15B 能够在 HumanEval-X 上增加 Java 绝对17.95% 的传递@1。更令人惊讶的是，我们发现，在 HTML 语料库上训练的 CodeM-HTML 7B 可以提高 Java 的绝对15.24% pass@1。我们的训练数据 https://github.com/nl2code/codem 公布。"
    },
    {
        "title": "Simple LLM Prompting is State-of-the-Art for Robust and Multilingual\n  Dialogue Evaluation",
        "url": "http://arxiv.org/abs/2308.16797v1",
        "pub_date": "2023-08-31",
        "summary": "Despite significant research effort in the development of automatic dialogue\nevaluation metrics, little thought is given to evaluating dialogues other than\nin English. At the same time, ensuring metrics are invariant to semantically\nsimilar responses is also an overlooked topic. In order to achieve the desired\nproperties of robustness and multilinguality for dialogue evaluation metrics,\nwe propose a novel framework that takes advantage of the strengths of current\nevaluation models with the newly-established paradigm of prompting Large\nLanguage Models (LLMs). Empirical results show our framework achieves state of\nthe art results in terms of mean Spearman correlation scores across several\nbenchmarks and ranks first place on both the Robust and Multilingual tasks of\nthe DSTC11 Track 4 \"Automatic Evaluation Metrics for Open-Domain Dialogue\nSystems\", proving the evaluation capabilities of prompted LLMs.",
        "translated": "尽管在开发自动对话评价指标方面做了大量的研究工作，但除了英语以外，很少有人考虑对话的评价问题。同时，确保度量对语义相似的响应是不变的也是一个被忽视的主题。为了实现对话评估指标的鲁棒性和多语言性，我们提出了一种新的框架，该框架利用了现有评估模型的优势，并采用了新建立的提示大语言模型(LLM)范式。实证结果表明，我们的框架在多个基准的 Spearman 平均相关分数方面达到了最高水平，并且在 DSTC11第4轨“开放领域对话系统的自动评估指标”的稳健性和多语言任务方面排名第一，证明了提示 LLM 的评估能力。"
    },
    {
        "title": "Towards Multilingual Automatic Dialogue Evaluation",
        "url": "http://arxiv.org/abs/2308.16795v1",
        "pub_date": "2023-08-31",
        "summary": "The main limiting factor in the development of robust multilingual dialogue\nevaluation metrics is the lack of multilingual data and the limited\navailability of open sourced multilingual dialogue systems. In this work, we\npropose a workaround for this lack of data by leveraging a strong multilingual\npretrained LLM and augmenting existing English dialogue data using Machine\nTranslation. We empirically show that the naive approach of finetuning a\npretrained multilingual encoder model with translated data is insufficient to\noutperform the strong baseline of finetuning a multilingual model with only\nsource data. Instead, the best approach consists in the careful curation of\ntranslated data using MT Quality Estimation metrics, excluding low quality\ntranslations that hinder its performance.",
        "translated": "制定强有力的多语种对话评价指标的主要限制因素是缺乏多语种数据以及开源多语种对话系统的可用性有限。在这项工作中，我们提出了一个解决这种数据缺乏的办法，利用一个强大的多语言预训练 LLM 和扩大现有的英语对话数据使用机器翻译。我们经验表明，用翻译数据微调预先训练的多语言编码器模型的幼稚方法不足以胜过仅用源数据微调多语言模型的强基线。相反，最好的方法是使用 MT 质量评估指标仔细管理翻译数据，排除阻碍其性能的低质量翻译。"
    },
    {
        "title": "Enhancing PLM Performance on Labour Market Tasks via Instruction-based\n  Finetuning and Prompt-tuning with Rules",
        "url": "http://arxiv.org/abs/2308.16770v1",
        "pub_date": "2023-08-31",
        "summary": "The increased digitization of the labour market has given researchers,\neducators, and companies the means to analyze and better understand the labour\nmarket. However, labour market resources, although available in high volumes,\ntend to be unstructured, and as such, research towards methodologies for the\nidentification, linking, and extraction of entities becomes more and more\nimportant. Against the backdrop of this quest for better labour market\nrepresentations, resource constraints and the unavailability of large-scale\nannotated data cause a reliance on human domain experts. We demonstrate the\neffectiveness of prompt-based tuning of pre-trained language models (PLM) in\nlabour market specific applications. Our results indicate that cost-efficient\nmethods such as PTR and instruction tuning without exemplars can significantly\nincrease the performance of PLMs on downstream labour market applications\nwithout introducing additional model layers, manual annotations, and data\naugmentation.",
        "translated": "劳动力市场日益数字化，为研究人员、教育工作者和公司提供了分析和更好地了解劳动力市场的手段。然而，劳动力市场的资源，虽然大量可用，往往是非结构化的，因此，研究方法学的识别，联系和提取的实体变得越来越重要。在这种寻求更好的劳动力市场代表性的背景下，资源限制和缺乏大规模附加说明的数据造成对人类领域专家的依赖。我们证明了在劳动力市场的具体应用中，对预先培训的语言模型(PLM)进行即时调整的有效性。我们的研究结果表明，成本效益的方法，如 PTR 和指令调优没有范例可以显着提高 PLM 在下游劳动力市场应用的性能，而不需要引入额外的模型层，手动注释和数据增强。"
    },
    {
        "title": "Ladder-of-Thought: Using Knowledge as Steps to Elevate Stance Detection",
        "url": "http://arxiv.org/abs/2308.16763v1",
        "pub_date": "2023-08-31",
        "summary": "Chain-of-Thought Prompting (CoT) reinforces the reasoning capabilities of\nLarge Language Models (LLMs) through the generation of intermediate rationales.\nHowever, these enhancements predominantly benefit large-scale models, leaving\nsmall LMs without significant performance improvements when directly applying\nCoT. Despite the advanced reasoning capabilities of LLMs, CoT relies primarily\non their pre-trained internal knowledge. The external knowledge that is\npreviously unknown to the model remains unexploited. This omission becomes\npronounced in tasks such as stance detection, where the external background\nknowledge plays a pivotal role. Additionally, the large-scale architecture of\nLLMs inevitably present efficiency challenges during deployment. To address\nthese challenges, we introduce the Ladder-of-Thought (LoT) for stance\ndetection. Grounded in a dual-phase Cascaded Optimization framework, LoT\ndirects the model to incorporate high-quality external knowledge, enhancing the\nintermediate rationales it generates. These bolstered rationales subsequently\nserve as the foundation for more precise predictions - akin to how a ladder\nfacilitates reaching elevated goals. LoT achieves a balance between efficiency\nand accuracy, making it an adaptable and efficient framework for stance\ndetection. Our empirical evaluations underscore LoT's effectiveness, marking a\n16% improvement over ChatGPT and a 10% enhancement compared to ChatGPT with\nCoT.",
        "translated": "思维链提示(CoT)通过生成中间原理来加强大型语言模型(LLM)的推理能力。然而，这些增强主要有利于大规模模型，使得小型 LM 在直接应用 CoT 时没有显著的性能改进。尽管 LLM 具有先进的推理能力，CoT 主要依赖于它们预先训练好的内部知识。模型以前未知的外部知识仍然没有得到开发。这种遗漏在诸如姿态检测这样的任务中变得明显，在这些任务中，外部背景知识起着关键作用。此外，LLM 的大规模体系结构在部署过程中不可避免地会出现效率挑战。为了应对这些挑战，我们引入了用于姿态检测的思想阶梯(Ladder-of-Thought，LoT)。在双阶段级联优化框架的基础上，LoT 引导模型吸收高质量的外部知识，增强其产生的中间原理。这些得到支持的理由随后成为更精确预测的基础——类似于梯子如何促进达到更高的目标。LoT 实现了效率和准确性之间的平衡，使其成为一个适应性强、高效的姿态检测框架。我们的实证评估强调了 LoT 的有效性，与使用 CoT 的 ChatGPT 相比，改善了16% ，提高了10% 。"
    },
    {
        "title": "NeMig -- A Bilingual News Collection and Knowledge Graph about Migration",
        "url": "http://arxiv.org/abs/2309.00550v1",
        "pub_date": "2023-09-01",
        "summary": "News recommendation plays a critical role in shaping the public's worldviews\nthrough the way in which it filters and disseminates information about\ndifferent topics. Given the crucial impact that media plays in opinion\nformation, especially for sensitive topics, understanding the effects of\npersonalized recommendation beyond accuracy has become essential in today's\ndigital society. In this work, we present NeMig, a bilingual news collection on\nthe topic of migration, and corresponding rich user data. In comparison to\nexisting news recommendation datasets, which comprise a large variety of\nmonolingual news, NeMig covers articles on a single controversial topic,\npublished in both Germany and the US. We annotate the sentiment polarization of\nthe articles and the political leanings of the media outlets, in addition to\nextracting subtopics and named entities disambiguated through Wikidata. These\nfeatures can be used to analyze the effects of algorithmic news curation beyond\naccuracy-based performance, such as recommender biases and the creation of\nfilter bubbles. We construct domain-specific knowledge graphs from the news\ntext and metadata, thus encoding knowledge-level connections between articles.\nImportantly, while existing datasets include only click behavior, we collect\nuser socio-demographic and political information in addition to explicit click\nfeedback. We demonstrate the utility of NeMig through experiments on the tasks\nof news recommenders benchmarking, analysis of biases in recommenders, and news\ntrends analysis. NeMig aims to provide a useful resource for the news\nrecommendation community and to foster interdisciplinary research into the\nmultidimensional effects of algorithmic news curation.",
        "translated": "新闻推荐通过过滤和传播不同话题的信息，在塑造公众的世界观方面发挥着关键作用。鉴于媒体在舆论形成方面的关键影响，尤其是对敏感话题的影响，在当今数字社会中，了解个性化推荐的准确性以外的影响已变得至关重要。在这项工作中，我们介绍了 NeMig，一个关于迁移话题的双语新闻集合，以及相应的丰富的用户数据。与现有的包含大量单语新闻的新闻推荐数据集相比，NeMig 涵盖了在德国和美国发表的有争议话题的文章。我们注意到文章的情绪两极分化和媒体机构的政治倾向，除了提取副主题和通过 Wikidata 消除歧义的命名实体。这些特征可以用来分析算法新闻管理的影响，而不仅仅是基于准确性的性能，比如推荐偏差和过滤气泡的产生。我们从新闻文本和元数据中构建特定领域的知识图，从而编码文章之间的知识级联系。重要的是，虽然现有的数据集只包括点击行为，我们收集用户的社会人口和政治信息，除了明确的点击反馈。我们通过对新闻推荐者基准测试任务、推荐者偏差分析和新闻趋势分析的实验来展示 NeMig 的实用性。NeMig 旨在为新闻推荐社区提供有用的资源，并培养科际整合对算法新闻策划的多维效果的理解。"
    },
    {
        "title": "General and Practical Tuning Method for Off-the-Shelf Graph-Based Index:\n  SISAP Indexing Challenge Report by Team UTokyo",
        "url": "http://arxiv.org/abs/2309.00472v1",
        "pub_date": "2023-09-01",
        "summary": "Despite the efficacy of graph-based algorithms for Approximate Nearest\nNeighbor (ANN) searches, the optimal tuning of such systems remains unclear.\nThis study introduces a method to tune the performance of off-the-shelf\ngraph-based indexes, focusing on the dimension of vectors, database size, and\nentry points of graph traversal. We utilize a black-box optimization algorithm\nto perform integrated tuning to meet the required levels of recall and Queries\nPer Second (QPS). We applied our approach to Task A of the SISAP 2023 Indexing\nChallenge and got second place in the 10M and 30M tracks. It improves\nperformance substantially compared to brute force methods. This research offers\na universally applicable tuning method for graph-based indexes, extending\nbeyond the specific conditions of the competition to broader uses.",
        "translated": "尽管基于图的算法对于近似最近邻(ANN)搜索有效，但是这种系统的最优调整仍然不清楚。本文介绍了一种基于现成图形索引的性能优化方法，重点研究了向量的维数、数据库的大小以及图形遍历的入口点。我们利用一个黑盒优化算法来执行集成调优，以满足召回和每秒查询(QPS)的要求。我们将我们的方法应用到 SISAP 2023索引挑战的任务 A 中，并在10M 和30M 轨道中获得第二名。与蛮力方法相比，它大大提高了性能。这项研究为基于图的索引提供了一种普遍适用的调整方法，超越了竞争的具体条件，扩展到更广泛的用途。"
    },
    {
        "title": "Explainable Active Learning for Preference Elicitation",
        "url": "http://arxiv.org/abs/2309.00356v1",
        "pub_date": "2023-09-01",
        "summary": "Gaining insights into the preferences of new users and subsequently\npersonalizing recommendations necessitate managing user interactions\nintelligently, namely, posing pertinent questions to elicit valuable\ninformation effectively. In this study, our focus is on a specific scenario of\nthe cold-start problem, where the recommendation system lacks adequate user\npresence or access to other users' data is restricted, obstructing employing\nuser profiling methods utilizing existing data in the system. We employ Active\nLearning (AL) to solve the addressed problem with the objective of maximizing\ninformation acquisition with minimal user effort. AL operates for selecting\ninformative data from a large unlabeled set to inquire an oracle to label them\nand eventually updating a machine learning (ML) model. We operate AL in an\nintegrated process of unsupervised, semi-supervised, and supervised ML within\nan explanatory preference elicitation process. It harvests user feedback (given\nfor the system's explanations on the presented items) over informative samples\nto update an underlying ML model estimating user preferences. The designed user\ninteraction facilitates personalizing the system by incorporating user feedback\ninto the ML model and also enhances user trust by refining the system's\nexplanations on recommendations. We implement the proposed preference\nelicitation methodology for food recommendation. We conducted human experiments\nto assess its efficacy in the short term and also experimented with several AL\nstrategies over synthetic user profiles that we created for two food datasets,\naiming for long-term performance analysis. The experimental results demonstrate\nthe efficiency of the proposed preference elicitation with limited user-labeled\ndata while also enhancing user trust through accurate explanations.",
        "translated": "要深入了解新用户的偏好并随后对建议进行个性化，就必须智能地管理用户交互，即提出相关问题以有效地获取有价值的信息。在这项研究中，我们的重点是冷启动问题的一个特定场景，其中推荐系统缺乏足够的用户存在或访问其他用户的数据受到限制，阻碍使用用户剖析方法利用现有的数据在系统中。我们使用主动学习(AL)来解决所提出的问题，目标是以最小的用户努力最大化信息获取。AL 操作从一个大的未标记集合中选择信息性数据来查询一个 Oracle 来标记它们，并最终更新一个机器学习(ML)模型。我们在一个无监督，半监督和监督的解释性偏好启发过程中的一个综合过程中操作 AL。它通过信息样本收集用户反馈(给出系统对提供的项目的解释) ，以更新潜在的机器学习模型，估计用户偏好。设计的用户交互通过将用户反馈整合到机器学习模型中来促进系统的个性化，同时通过完善系统对推荐的解释来增强用户的信任。我们实施建议的食品推荐偏好激发方法。我们进行了人体实验来评估它的短期效果，并且还对我们为两个食品数据集创建的合成用户档案进行了几个 AL 策略的实验，旨在进行长期性能分析。实验结果表明，在用户标签数据有限的情况下，提出的偏好引导方法能够有效地提高用户的信任度。"
    },
    {
        "title": "Towards Contrastive Learning in Music Video Domain",
        "url": "http://arxiv.org/abs/2309.00347v1",
        "pub_date": "2023-09-01",
        "summary": "Contrastive learning is a powerful way of learning multimodal representations\nacross various domains such as image-caption retrieval and audio-visual\nrepresentation learning. In this work, we investigate if these findings\ngeneralize to the domain of music videos. Specifically, we create a dual\nen-coder for the audio and video modalities and train it using a bidirectional\ncontrastive loss. For the experiments, we use an industry dataset containing\n550 000 music videos as well as the public Million Song Dataset, and evaluate\nthe quality of learned representations on the downstream tasks of music tagging\nand genre classification. Our results indicate that pre-trained networks\nwithout contrastive fine-tuning outperform our contrastive learning approach\nwhen evaluated on both tasks. To gain a better understanding of the reasons\ncontrastive learning was not successful for music videos, we perform a\nqualitative analysis of the learned representations, revealing why contrastive\nlearning might have difficulties uniting embeddings from two modalities. Based\non these findings, we outline possible directions for future work. To\nfacilitate the reproducibility of our results, we share our code and the\npre-trained model.",
        "translated": "对比学习是一种跨多种领域学习多模态表征的有效方法，如图像标题检索和视听表征学习。在这项工作中，我们调查这些发现是否推广到音乐视频领域。具体来说，我们为音频和视频模式创建一个双编码器，并使用双向对比度损失训练它。在实验中，我们使用了一个包含55万个音乐视频的行业数据集和公开的百万歌曲数据集，并评估了音乐标签和流派分类下游任务的学习表征的质量。我们的结果表明，预先训练的网络没有对比微调优于我们的对比学习方法时，评估两个任务。为了更好地理解音乐视频对比学习不成功的原因，我们对学习表征进行了定性分析，揭示了为什么对比学习可能难以将嵌入式与两种模式结合起来。基于这些发现，我们概述了今后工作的可能方向。为了促进结果的可重复性，我们共享我们的代码和预先训练的模型。"
    },
    {
        "title": "Point-Bind &amp; Point-LLM: Aligning Point Cloud with Multi-modality for 3D\n  Understanding, Generation, and Instruction Following",
        "url": "http://arxiv.org/abs/2309.00615v1",
        "pub_date": "2023-09-01",
        "summary": "We introduce Point-Bind, a 3D multi-modality model aligning point clouds with\n2D image, language, audio, and video. Guided by ImageBind, we construct a joint\nembedding space between 3D and multi-modalities, enabling many promising\napplications, e.g., any-to-3D generation, 3D embedding arithmetic, and 3D\nopen-world understanding. On top of this, we further present Point-LLM, the\nfirst 3D large language model (LLM) following 3D multi-modal instructions. By\nparameter-efficient fine-tuning techniques, Point-LLM injects the semantics of\nPoint-Bind into pre-trained LLMs, e.g., LLaMA, which requires no 3D instruction\ndata, but exhibits superior 3D and multi-modal question-answering capacity. We\nhope our work may cast a light on the community for extending 3D point clouds\nto multi-modality applications. Code is available at\nhttps://github.com/ZiyuGuo99/Point-Bind_Point-LLM.",
        "translated": "我们介绍点绑定(Point-Bind) ，这是一个将点云与2D 图像、语言、音频和视频对齐的3D 多模态模型。在 ImageBind 的指导下，我们构建了一个3D 和多模式之间的联合嵌入空间，使得许多有前途的应用，例如，任意到3D 的生成，3D 嵌入算法，和3D 开放世界的理解。在此基础上，我们进一步介绍了 Point-LLM，它是第一个遵循3D 多模态指令的3D 大语言模型(LLM)。通过参数有效的微调技术，Point-LLM 将 Point-Bind 的语义注入到事先训练好的 LLM 中，例如 LlaMA，它不需要3D 指令数据，但展现出卓越的3D 和多模态问答能力。我们希望我们的工作可以给社区带来光明，将3D 点云扩展到多模态应用。密码可于 https://github.com/ziyuguo99/point-bind_point-llm 索取。"
    },
    {
        "title": "Baseline Defenses for Adversarial Attacks Against Aligned Language\n  Models",
        "url": "http://arxiv.org/abs/2309.00614v1",
        "pub_date": "2023-09-01",
        "summary": "As Large Language Models quickly become ubiquitous, their security\nvulnerabilities are critical to understand. Recent work shows that text\noptimizers can produce jailbreaking prompts that bypass moderation and\nalignment. Drawing from the rich body of work on adversarial machine learning,\nwe approach these attacks with three questions: What threat models are\npractically useful in this domain? How do baseline defense techniques perform\nin this new domain? How does LLM security differ from computer vision?\n  We evaluate several baseline defense strategies against leading adversarial\nattacks on LLMs, discussing the various settings in which each is feasible and\neffective. Particularly, we look at three types of defenses: detection\n(perplexity based), input preprocessing (paraphrase and retokenization), and\nadversarial training. We discuss white-box and gray-box settings and discuss\nthe robustness-performance trade-off for each of the defenses considered.\nSurprisingly, we find much more success with filtering and preprocessing than\nwe would expect from other domains, such as vision, providing a first\nindication that the relative strengths of these defenses may be weighed\ndifferently in these domains.",
        "translated": "随着大型语言模型迅速变得无处不在，理解它们的安全漏洞至关重要。最近的工作表明，文本优化器可以产生越狱提示，绕过适度和对齐。从对抗性机器学习的大量工作中，我们带着三个问题来处理这些攻击: 什么样的威胁模型在这个领域实际上是有用的？基线防御技术在这个新领域中表现如何？LLM 安全性与计算机视觉有何不同？我们评估了几种针对 LLM 的主要对手攻击的基线防御策略，讨论了每种策略可行和有效的各种设置。特别地，我们研究了三种类型的防御: 检测(基于困惑)、输入预处理(释义和重新标记)和对抗性训练。我们讨论了白盒和灰盒设置，并讨论了所考虑的每种防御的健壮性-性能权衡。令人惊讶的是，我们发现在过滤和预处理方面比我们在其他领域(如视觉)预期的要成功得多，这首次表明这些防御的相对优势在这些领域可能会有所不同。"
    },
    {
        "title": "CPSP: Learning Speech Concepts From Phoneme Supervision",
        "url": "http://arxiv.org/abs/2309.00424v1",
        "pub_date": "2023-09-01",
        "summary": "For fine-grained generation and recognition tasks such as\nminimally-supervised text-to-speech (TTS), voice conversion (VC), and automatic\nspeech recognition (ASR), the intermediate representation extracted from speech\nshould contain information that is between text coding and acoustic coding. The\nlinguistic content is salient, while the paralinguistic information such as\nspeaker identity and acoustic details should be removed. However, existing\nmethods for extracting fine-grained intermediate representations from speech\nsuffer from issues of excessive redundancy and dimension explosion.\nAdditionally, existing contrastive learning methods in the audio field focus on\nextracting global descriptive information for downstream audio classification\ntasks, making them unsuitable for TTS, VC, and ASR tasks. To address these\nissues, we propose a method named Contrastive Phoneme-Speech Pretraining\n(CPSP), which uses three encoders, one decoder, and contrastive learning to\nbring phoneme and speech into a joint multimodal space, learning how to connect\nphoneme and speech at the frame level. The CPSP model is trained on 210k speech\nand phoneme text pairs, achieving minimally-supervised TTS, VC, and ASR. The\nproposed CPSP method offers a promising solution for fine-grained generation\nand recognition downstream tasks in speech processing. We provide a website\nwith audio samples.",
        "translated": "对于细粒度的生成和识别任务，如最小监督文本到语音(TTS)、语音转换(VC)和自动语音识别(ASR) ，从语音中提取的中间表示应该包含介于文本编码和声学编码之间的信息。语言内容是突出的，而副语言信息，如说话人身份和声学细节应删除。然而，现有的从语音中提取细粒度中间表示的方法存在冗余度过大和维数爆炸等问题。此外，现有的音频领域对比学习方法侧重于提取下游音频分类任务的全局描述信息，这使得它们不适合 TTS、 VC 和 ASR 任务。为了解决这些问题，我们提出了一种名为对比音素-语音预训练(CPSP)的方法，该方法使用三个编码器、一个解码器和对比学习将音素和语音带入一个联合的多模态空间，学习如何在帧级连接音素和语音。CPSP 模型基于210k 语音和音素文本对进行训练，实现了最小监督 TTS、 VC 和 ASR。提出的 CPSP 方法为语音处理中的细粒度生成和识别下游任务提供了一种有前途的解决方案。我们提供了一个音频样本网站。"
    },
    {
        "title": "Satisfiability Checking of Multi-Variable TPTL with Unilateral Intervals\n  Is PSPACE-Complete",
        "url": "http://arxiv.org/abs/2309.00386v1",
        "pub_date": "2023-09-01",
        "summary": "We investigate the decidability of the ${0,\\infty}$ fragment of Timed\nPropositional Temporal Logic (TPTL). We show that the satisfiability checking\nof TPTL$^{0,\\infty}$ is PSPACE-complete. Moreover, even its 1-variable fragment\n(1-TPTL$^{0,\\infty}$) is strictly more expressive than Metric Interval Temporal\nLogic (MITL) for which satisfiability checking is EXPSPACE complete. Hence, we\nhave a strictly more expressive logic with computationally easier\nsatisfiability checking. To the best of our knowledge, TPTL$^{0,\\infty}$ is the\nfirst multi-variable fragment of TPTL for which satisfiability checking is\ndecidable without imposing any bounds/restrictions on the timed words (e.g.\nbounded variability, bounded time, etc.). The membership in PSPACE is obtained\nby a reduction to the emptiness checking problem for a new \"non-punctual\"\nsubclass of Alternating Timed Automata with multiple clocks called Unilateral\nVery Weak Alternating Timed Automata (VWATA$^{0,\\infty}$) which we prove to be\nin PSPACE. We show this by constructing a simulation equivalent\nnon-deterministic timed automata whose number of clocks is polynomial in the\nsize of the given VWATA$^{0,\\infty}$.",
        "translated": "我们研究了时间命题时态逻辑(TPTL)的 ${0，infty } $片段的可判定性。我们证明了 TPTL $^ {0，infty } $的可满足性检查是 PSPACE 完全的。此外，即使它的1变量片段(1-TPTL $^ {0，infty } $)严格地比度量区间时序逻辑(MITL)更具表现力，对于这种时序逻辑，可满足性检查是 EXPSPACE 完成的。因此，我们有一个严格的更易于表达的逻辑与计算更容易满足性检查。据我们所知，TPTL $^ {0，infty } $是 TPTL 的第一个多变量片段，其可满足性检查是可决定的，而不对定时词施加任何界限/限制(例如有界变异性、有界时间等)。PSPACE 的成员资格是通过一个新的“非准时”子类交替定时自动机的空性检查问题得到的，该子类具有多个时钟，称为单边非常弱的交替定时自动机(vwata $^ {0，infty } $) ，我们在 PSPACE 证明了它的存在。我们通过构造一个仿真等价的非确定性时间自动机来证明这一点，该自动机的时钟数目在给定的 VwatA $^ {0，infty } $的大小下是多项式的。"
    },
    {
        "title": "BatchPrompt: Accomplish more with less",
        "url": "http://arxiv.org/abs/2309.00384v1",
        "pub_date": "2023-09-01",
        "summary": "Many LLMs are trained to perform zero-shot or few-shot inference using\ninstruction-based prompts. Crafting prompts for these LLMs typically requires\nthe user to provide a detailed task description, examples of context and\ncompletion, and single example of context for inference. This regular prompt\nbaseline is referred to as SinglePrompt in this paper. However, for NLP tasks\nwhere each data point for inference is not necessarily lengthy, the token count\nfor instructions and few-shot examples in the prompt may be considerably larger\nthan that of the data point, resulting in lower token-resource utilization\ncompared with encoder-based models like fine-tuned BERT. This cost-efficiency\nissue, affecting inference speed and compute budget, counteracts the many\nbenefits LLMs have to offer. This paper aims to alleviate the preceding problem\nby batching multiple data points into a single prompt, a prompting strategy we\nrefer to as BatchPrompt. This strategy increases the density of data points,\nwhich in turn leads to improved token utilization. Applying BatchPrompt\nnaively, however, is very challenging due to significant performance\ndegradation, as observed in our experiments. We also noticed varying inference\noutcomes for the same data point appearing in different positions within a\nprompt. To address the quality issue while remain high token-resource\nutilization, we introduce Batch Permutation and Ensembling for BatchPrompt, a\nsimple way that recovers labeling quality through majority votes from data\npoints placed in varying positions in a batch at the price of more token usage.\nTo counterbalance the additional token usage caused by the voting process, we\nfurther propose Self-reflection-guided EArly Stopping, which can terminate the\nvoting process early for data points the LLM confidently handles.",
        "translated": "许多 LLM 经过训练，使用基于指令的提示执行零镜头或少镜头推理。为这些 LLM 制作提示符通常需要用户提供详细的任务描述、上下文示例和完成示例，以及用于推断的单个上下文示例。这个常规提示基线在本文中称为 SinglePrompt。然而，对于 NLP 任务，每个用于推理的数据点不一定都很长，提示中指令的令牌计数和少量示例可能比数据点的令牌计数大得多，与基于编码器的模型(如微调 BERT)相比，导致令牌资源利用率较低。这个影响推理速度和计算预算的成本效率问题抵消了 LLM 必须提供的许多好处。本文旨在通过将多个数据点批处理到单个提示符(我们称之为 BatchPrompt 的提示策略)来缓解前面的问题。这种策略增加了数据点的密度，从而提高了令牌的利用率。然而，正如我们在实验中观察到的那样，由于显著的性能下降，天真地应用 BatchPrompt 是非常具有挑战性的。我们还注意到，同一数据点在提示符内不同位置出现的推理结果也不同。为了在保持高令牌资源利用率的同时解决质量问题，我们为 BatchPrompt 引入了批处理排列和集成，这是一种简单的方法，通过从一批中不同位置的数据点的多数投票恢复标记质量，代价是更多的令牌使用。为了平衡投票过程所造成的额外令牌使用，我们进一步提出了自反射引导的提前停止算法，该算法可以提前终止 LLM 自信处理的数据点的投票过程。"
    },
    {
        "title": "Long-Term Memorability On Advertisements",
        "url": "http://arxiv.org/abs/2309.00378v1",
        "pub_date": "2023-09-01",
        "summary": "Marketers spend billions of dollars on advertisements but to what end? At the\npurchase time, if customers cannot recognize a brand for which they saw an ad,\nthe money spent on the ad is essentially wasted. Despite its importance in\nmarketing, until now, there has been no study on the memorability of ads in the\nML literature. Most studies have been conducted on short-term recall (&lt;5 mins)\non specific content types like object and action videos. On the other hand, the\nadvertising industry only cares about long-term memorability (a few hours or\nlonger), and advertisements are almost always highly multimodal, depicting a\nstory through its different modalities (text, images, and videos). With this\nmotivation, we conduct the first large scale memorability study consisting of\n1203 participants and 2205 ads covering 276 brands. Running statistical tests\nover different participant subpopulations and ad-types, we find many\ninteresting insights into what makes an ad memorable - both content and human\nfactors. For example, we find that brands which use commercials with fast\nmoving scenes are more memorable than those with slower scenes (p=8e-10) and\nthat people who use ad-blockers remember lower number of ads than those who\ndon't (p=5e-3). Further, with the motivation of simulating the memorability of\nmarketing materials for a particular audience, ultimately helping create one,\nwe present a novel model, Sharingan, trained to leverage real-world knowledge\nof LLMs and visual knowledge of visual encoders to predict the memorability of\na content. We test our model on all the prominent memorability datasets in\nliterature (both images and videos) and achieve state of the art across all of\nthem. We conduct extensive ablation studies across memory types, modality,\nbrand, and architectural choices to find insights into what drives memory.",
        "translated": "营销人员在广告上花费了数十亿美元，但最终目的是什么呢？在购买时，如果顾客不能认出他们看到广告的品牌，那么花在广告上的钱基本上就是浪费了。尽管它在市场营销中的重要性，到目前为止，还没有研究在机器学习文献中广告的可记忆性。大多数研究都是针对特定的内容类型(如对象和动作视频)进行短期回忆(小于5分钟)。另一方面，广告业只关心长期的可记性(几个小时或更长时间) ，而且广告几乎总是高度多模式的，通过不同的模式(文本、图像和视频)来描述一个故事。基于这个动机，我们进行了第一次大规模的记忆力研究，包括1203名参与者和2205个广告，覆盖276个品牌。通过对不同的参与者亚群和广告类型进行统计测试，我们发现了许多有趣的见解，让广告令人难忘——包括内容和人为因素。例如，我们发现使用快速移动场景广告的品牌比使用慢速场景广告的品牌更容易记住(p = 8e-10) ，使用广告拦截器的人比不使用广告拦截器的人记住的广告数量更少(p = 5e-3)。此外，为了模拟特定受众对营销材料的可记忆性，最终帮助创建一个受众，我们提出了一个新颖的模型，Sharingan，训练利用现实世界的 LLM 知识和可视化编码器的视觉知识来预测内容的可记忆性。我们测试我们的模型在所有突出的文学记忆数据集(包括图像和视频) ，并实现在所有他们的艺术状态。我们进行了广泛的消融研究跨记忆类型，形态，品牌和建筑的选择，以找到什么驱动记忆的见解。"
    },
    {
        "title": "When Do Discourse Markers Affect Computational Sentence Understanding?",
        "url": "http://arxiv.org/abs/2309.00368v1",
        "pub_date": "2023-09-01",
        "summary": "The capabilities and use cases of automatic natural language processing (NLP)\nhave grown significantly over the last few years. While much work has been\ndevoted to understanding how humans deal with discourse connectives, this\nphenomenon is understudied in computational systems. Therefore, it is important\nto put NLP models under the microscope and examine whether they can adequately\ncomprehend, process, and reason within the complexity of natural language. In\nthis chapter, we introduce the main mechanisms behind automatic sentence\nprocessing systems step by step and then focus on evaluating discourse\nconnective processing. We assess nine popular systems in their ability to\nunderstand English discourse connectives and analyze how context and language\nunderstanding tasks affect their connective comprehension. The results show\nthat NLP systems do not process all discourse connectives equally well and that\nthe computational processing complexity of different connective kinds is not\nalways consistently in line with the presumed complexity order found in human\nprocessing. In addition, while humans are more inclined to be influenced during\nthe reading procedure but not necessarily in the final comprehension\nperformance, discourse connectives have a significant impact on the final\naccuracy of NLP systems. The richer knowledge of connectives a system learns,\nthe more negative effect inappropriate connectives have on it. This suggests\nthat the correct explicitation of discourse connectives is important for\ncomputational natural language processing.",
        "translated": "自动自然语言处理(NLP)的能力和用例在过去几年中有了显著的增长。虽然许多工作致力于理解人类如何处理话语连接词，但这种现象在计算机系统中被低估了。因此，将自然语言处理模型放在显微镜下观察它们是否能够在自然语言的复杂性中充分地理解、处理和推理是非常重要的。在本章中，我们逐步介绍了自动句子处理系统背后的主要机制，然后重点评价语篇连接加工。我们评估了九个常用系统理解英语语篇连接词的能力，并分析了语境和语言理解任务如何影响他们的连接词理解。结果表明，自然语言处理系统并不能同等地处理所有语篇连接词，不同连接类型的计算处理复杂度并不总是与人类处理中假定的复杂度顺序一致。此外，虽然人类在阅读过程中更容易受到影响，但不一定影响最终的理解成绩，语篇连接词对自然语言处理系统的最终准确性有重要影响。系统学到的关联词知识越丰富，不恰当的关联词对系统的负面影响就越大。这表明语篇连接词的正确表达对计算自然语言处理具有重要意义。"
    },
    {
        "title": "Large Content And Behavior Models To Understand, Simulate, And Optimize\n  Content And Behavior",
        "url": "http://arxiv.org/abs/2309.00359v1",
        "pub_date": "2023-09-01",
        "summary": "Shannon, in his seminal paper introducing information theory, divided the\ncommunication into three levels: technical, semantic, and effectivenss. While\nthe technical level is concerned with accurate reconstruction of transmitted\nsymbols, the semantic and effectiveness levels deal with the inferred meaning\nand its effect on the receiver. Thanks to telecommunications, the first level\nproblem has produced great advances like the internet. Large Language Models\n(LLMs) make some progress towards the second goal, but the third level still\nremains largely untouched. The third problem deals with predicting and\noptimizing communication for desired receiver behavior. LLMs, while showing\nwide generalization capabilities across a wide range of tasks, are unable to\nsolve for this. One reason for the underperformance could be a lack of\n\"behavior tokens\" in LLMs' training corpora. Behavior tokens define receiver\nbehavior over a communication, such as shares, likes, clicks, purchases,\nretweets, etc. While preprocessing data for LLM training, behavior tokens are\noften removed from the corpora as noise. Therefore, in this paper, we make some\ninitial progress towards reintroducing behavior tokens in LLM training. The\ntrained models, other than showing similar performance to LLMs on content\nunderstanding tasks, show generalization capabilities on behavior simulation,\ncontent simulation, behavior understanding, and behavior domain adaptation.\nUsing a wide range of tasks on two corpora, we show results on all these\ncapabilities. We call these models Large Content and Behavior Models (LCBMs).\nFurther, to spur more research on LCBMs, we release our new Content Behavior\nCorpus (CBC), a repository containing communicator, message, and corresponding\nreceiver behavior.",
        "translated": "香农在他介绍信息理论的开创性论文中，将交流分为三个层次: 技术层次、语义层次和有效层次。而技术层面涉及到传输符号的精确重建，语义层面和有效性层面涉及到推断的意义及其对接收者的影响。多亏了电信，第一层次的问题已经产生了巨大的进步，如互联网。大型语言模型(LLM)在实现第二个目标方面取得了一些进展，但是第三个层次仍然基本未被触及。第三个问题涉及预测和优化期望的接收机行为的通信。LLM 虽然在广泛的任务范围内显示了广泛的泛化能力，但是无法解决这个问题。表现不佳的一个原因可能是 LLM 培训语料库中缺乏“行为标记”。行为标记定义通信中的接收方行为，如共享、喜欢、点击、购买、转发等。在对 LLM 训练数据进行预处理时，行为标记常常作为噪声从语料库中去除。因此，本文在 LLM 训练中重新引入行为标记方面取得了一些初步的进展。经过训练的模型除了在内容理解任务上表现出与 LLM 相似的性能外，还表现出在行为模拟、内容模拟、行为理解和行为域适应方面的泛化能力。在两个语料库上使用广泛的任务，我们显示所有这些功能的结果。我们称这些模型为大内容和行为模型(LCBM)。此外，为了促进对 LCBM 的更多研究，我们发布了新的内容行为语料库(CBC) ，这是一个包含通信者、消息和相应的接收者行为的存储库。"
    },
    {
        "title": "Comparative Topic Modeling for Determinants of Divergent Report Results\n  Applied to Macular Degeneration Studies",
        "url": "http://arxiv.org/abs/2309.00312v1",
        "pub_date": "2023-09-01",
        "summary": "Topic modeling and text mining are subsets of Natural Language Processing\nwith relevance for conducting meta-analysis (MA) and systematic review (SR).\nFor evidence synthesis, the above NLP methods are conventionally used for\ntopic-specific literature searches or extracting values from reports to\nautomate essential phases of SR and MA. Instead, this work proposes a\ncomparative topic modeling approach to analyze reports of contradictory results\non the same general research question. Specifically, the objective is to find\ntopics exhibiting distinct associations with significant results for an outcome\nof interest by ranking them according to their proportional occurrence and\nconsistency of distribution across reports of significant results. The proposed\nmethod was tested on broad-scope studies addressing whether supplemental\nnutritional compounds significantly benefit macular degeneration (MD). Eight\ncompounds were identified as having a particular association with reports of\nsignificant results for benefitting MD. Six of these were further supported in\nterms of effectiveness upon conducting a follow-up literature search for\nvalidation (omega-3 fatty acids, copper, zeaxanthin, lutein, zinc, and\nnitrates). The two not supported by the follow-up literature search (niacin and\nmolybdenum) also had the lowest scores under the proposed methods ranking\nsystem, suggesting that the proposed method's score for a given topic is a\nviable proxy for its degree of association with the outcome of interest. These\nresults underpin the proposed methods potential to add specificity in\nunderstanding effects from broad-scope reports, elucidate topics of interest\nfor future research, and guide evidence synthesis in a systematic and scalable\nway.",
        "translated": "主题建模和文本挖掘是自然语言处理的子集，与进行元分析和系统综述分析相关。对于证据合成，上述自然语言处理方法通常用于特定主题的文献检索或从报告中提取值，以实现 SR 和 MA 基本阶段的自动化。相反，本文提出了一种比较主题建模方法来分析同一个一般性研究问题上相互矛盾的结果报告。具体而言，目标是通过根据重大结果报告的出现比例和分布一致性对这些主题进行排序，找出与感兴趣的结果有明显关联的主题。该方法已经在广泛的研究中进行了测试，以确定补充营养化合物是否对老年黄斑变性(MD)有显著的益处。八个化合物被确定为具有特定的关联报告的重大结果有利于 MD。其中6个在进行后续文献检索验证(ω-3脂肪酸，铜，玉米黄质，叶黄素，锌和硝酸盐)后，在有效性方面得到进一步支持。后续文献检索(烟酸和钼)不支持的两个也在所提出的方法排名系统下得分最低，表明所提出的方法对于给定主题的得分是与感兴趣的结果相关程度的可行代理。这些结果支持了所提出的方法，这些方法有可能增加理解广泛报告效应的特异性，阐明未来研究感兴趣的主题，并以系统和可扩展的方式指导证据综合。"
    },
    {
        "title": "Enhancing the vocal range of single-speaker singing voice synthesis with\n  melody-unsupervised pre-training",
        "url": "http://arxiv.org/abs/2309.00284v1",
        "pub_date": "2023-09-01",
        "summary": "The single-speaker singing voice synthesis (SVS) usually underperforms at\npitch values that are out of the singer's vocal range or associated with\nlimited training samples. Based on our previous work, this work proposes a\nmelody-unsupervised multi-speaker pre-training method conducted on a\nmulti-singer dataset to enhance the vocal range of the single-speaker, while\nnot degrading the timbre similarity. This pre-training method can be deployed\nto a large-scale multi-singer dataset, which only contains audio-and-lyrics\npairs without phonemic timing information and pitch annotation. Specifically,\nin the pre-training step, we design a phoneme predictor to produce the\nframe-level phoneme probability vectors as the phonemic timing information and\na speaker encoder to model the timbre variations of different singers, and\ndirectly estimate the frame-level f0 values from the audio to provide the pitch\ninformation. These pre-trained model parameters are delivered into the\nfine-tuning step as prior knowledge to enhance the single speaker's vocal\nrange. Moreover, this work also contributes to improving the sound quality and\nrhythm naturalness of the synthesized singing voices. It is the first to\nintroduce a differentiable duration regulator to improve the rhythm naturalness\nof the synthesized voice, and a bi-directional flow model to improve the sound\nquality. Experimental results verify that the proposed SVS system outperforms\nthe baseline on both sound quality and naturalness.",
        "translated": "单说话人歌唱声音合成(SVS)通常在超出歌唱者声音范围或与有限的训练样本相关的音高值时表现不佳。在前人工作的基础上，本文提出了一种基于多歌手数据集的旋律无监督多人预训练方法，该方法在不降低音色相似度的前提下，提高了单人的发声范围。这种预训练方法可以部署到一个大规模的多歌手数据集中，该数据集只包含音频和歌词对，没有音素时间信息和音高标注。具体来说，在预训练阶段，我们设计了一个音素预测器来产生帧级音素概率矢量作为音素计时信息，一个说话人编码器来模拟不同歌手的音色变化，并直接从音频中估计帧级 f0值来提供音高信息。这些预先训练好的模型参数作为先验知识传递到微调步骤中，以增强单个说话人的声音范围。此外，这项工作还有助于提高合成歌声的音质和节奏自然度。首次引入可微分持续时间调节器来改善合成语音的节奏自然度，并引入双向流模型来改善语音质量。实验结果表明，所提出的 SVS 系统在声音质量和自然度方面均优于基线。"
    },
    {
        "title": "Fairness of Exposure in Dynamic Recommendation",
        "url": "http://arxiv.org/abs/2309.02322v1",
        "pub_date": "2023-09-05",
        "summary": "Exposure bias is a well-known issue in recommender systems where the exposure\nis not fairly distributed among items in the recommendation results. This is\nespecially problematic when bias is amplified over time as a few items (e.g.,\npopular ones) are repeatedly over-represented in recommendation lists and\nusers' interactions with those items will amplify bias towards those items over\ntime resulting in a feedback loop. This issue has been extensively studied in\nthe literature in static recommendation environment where a single round of\nrecommendation result is processed to improve the exposure fairness. However,\nless work has been done on addressing exposure bias in a dynamic recommendation\nsetting where the system is operating over time, the recommendation model and\nthe input data are dynamically updated with ongoing user feedback on\nrecommended items at each round. In this paper, we study exposure bias in a\ndynamic recommendation setting. Our goal is to show that existing bias\nmitigation methods that are designed to operate in a static recommendation\nsetting are unable to satisfy fairness of exposure for items in long run. In\nparticular, we empirically study one of these methods and show that repeatedly\napplying this method fails to fairly distribute exposure among items in long\nrun. To address this limitation, we show how this method can be adapted to\neffectively operate in a dynamic recommendation setting and achieve exposure\nfairness for items in long run. Experiments on a real-world dataset confirm\nthat our solution is superior in achieving long-term exposure fairness for the\nitems while maintaining the recommendation accuracy.",
        "translated": "在推荐系统中，曝光偏差是一个众所周知的问题，在推荐结果中，曝光不公平地分布在各个项目中。当一些项目(例如，流行项目)在推荐列表中反复出现偏差时，这个问题尤其严重，用户与这些项目的互动会随着时间的推移放大对这些项目的偏差，导致反馈循环。这个问题在静态推荐环境中已经得到了广泛的研究，在静态推荐环境中，只需处理一轮推荐结果就可以提高曝光的公平性。然而，在动态推荐环境中解决暴露偏差的工作较少，在这种环境中，系统随着时间的推移在运行，推荐模型和输入数据随着每一轮用户对推荐项目的持续反馈而动态更新。在本文中，我们研究了动态推荐环境下的暴露偏差。我们的目标是表明，现有的偏差缓解方法，设计在一个静态的建议设置，无法满足项目的公平性的曝光长期运行。特别是，我们对其中一种方法进行了实证研究，结果表明，长期重复使用这种方法不能公平地分配项目间的曝光量。为了解决这个问题，我们展示了如何使用这种方法在动态推荐设置中进行有效操作，并实现项目的长期曝光公平性。在实际数据集上的实验证实了我们的解决方案在保持推荐准确性的同时实现了项目的长期曝光公平性方面具有优越性。"
    },
    {
        "title": "STGIN: Spatial-Temporal Graph Interaction Network for Large-scale POI\n  Recommendation",
        "url": "http://arxiv.org/abs/2309.02251v1",
        "pub_date": "2023-09-05",
        "summary": "In Location-Based Services, Point-Of-Interest(POI) recommendation plays a\ncrucial role in both user experience and business opportunities. Graph neural\nnetworks have been proven effective in providing personalized POI\nrecommendation services. However, there are still two critical challenges.\nFirst, existing graph models attempt to capture users' diversified interests\nthrough a unified graph, which limits their ability to express interests in\nvarious spatial-temporal contexts. Second, the efficiency limitations of graph\nconstruction and graph sampling in large-scale systems make it difficult to\nadapt quickly to new real-time interests. To tackle the above challenges, we\npropose a novel Spatial-Temporal Graph Interaction Network. Specifically, we\nconstruct subgraphs of spatial, temporal, spatial-temporal, and global views\nrespectively to precisely characterize the user's interests in various\ncontexts. In addition, we design an industry-friendly framework to track the\nuser's latest interests. Extensive experiments on the real-world dataset show\nthat our method outperforms state-of-the-art models. This work has been\nsuccessfully deployed in a large e-commerce platform, delivering a 1.1% CTR and\n6.3% RPM improvement.",
        "translated": "在基于位置的服务中，兴趣点(POI)推荐在用户体验和商业机会中都扮演着至关重要的角色。图形神经网络在提供个性化 POI 推荐服务方面已被证明是有效的。然而，仍然存在两个关键的挑战。首先，现有的图模型试图通过一个统一的图来捕捉用户的多样化兴趣，这限制了用户在各种时空背景下表达兴趣的能力。其次，在大规模系统中，由于图的构造和采样效率的限制，很难快速适应新的实时需求。为了解决上述问题，我们提出了一种新的时空图交互网络。具体来说，我们分别构造了空间、时间、空间-时间和全局视图的子图，以精确表征用户在不同情境下的兴趣。此外，我们还设计了一个行业友好的框架来跟踪用户的最新兴趣。在真实世界数据集上的大量实验表明，我们的方法优于最先进的模型。这项工作已经成功地部署在一个大型电子商务平台，提供了1.1% 的点击率和6.3% 的 RPM 改进。"
    },
    {
        "title": "TensorBank:Tensor Lakehouse for Foundation Model Training",
        "url": "http://arxiv.org/abs/2309.02094v1",
        "pub_date": "2023-09-05",
        "summary": "Storing and streaming high dimensional data for foundation model training\nbecame a critical requirement with the rise of foundation models beyond natural\nlanguage. In this paper we introduce TensorBank, a petabyte scale tensor\nlakehouse capable of streaming tensors from Cloud Object Store (COS) to GPU\nmemory at wire speed based on complex relational queries. We use Hierarchical\nStatistical Indices (HSI) for query acceleration. Our architecture allows to\ndirectly address tensors on block level using HTTP range reads. Once in GPU\nmemory, data can be transformed using PyTorch transforms. We provide a generic\nPyTorch dataset type with a corresponding dataset factory translating\nrelational queries and requested transformations as an instance. By making use\nof the HSI, irrelevant blocks can be skipped without reading them as those\nindices contain statistics on their content at different hierarchical\nresolution levels. This is an opinionated architecture powered by open\nstandards and making heavy use of open-source technology. Although, hardened\nfor production use using geospatial-temporal data, this architecture\ngeneralizes to other use case like computer vision, computational neuroscience,\nbiological sequence analysis and more.",
        "translated": "随着基础模型超越自然语言的兴起，为基础模型训练存储和流媒体高维数据成为一个关键的需求。本文介绍了 TensorBank，一个基于复杂关系查询的 PB 级张量湖库，它能够以线速将张量从云对象存储(COS)传输到 GPU 存储器。我们使用层次统计指数(HSI)来加速查询。我们的架构允许直接地址张量块级使用 HTTP 范围读取。一旦进入 GPU 内存，就可以使用 PyTorch 转换对数据进行转换。我们提供了一个通用的 PyTorch 数据集类型和一个相应的数据集工厂，将关系查询和请求的转换转换为实例。通过使用 HSI，可以跳过不相关的块，而无需阅读它们，因为这些索引包含不同层次分辨率级别的内容统计信息。这是一个由开放标准和大量使用开源技术驱动的固执己见的架构。尽管这种架构已经硬化，可以使用地理时空数据进行生产使用，但它还是可以推广到其他用例，比如计算机视觉、计算神经科学、生物序列分析等等。"
    },
    {
        "title": "MvFS: Multi-view Feature Selection for Recommender System",
        "url": "http://arxiv.org/abs/2309.02064v1",
        "pub_date": "2023-09-05",
        "summary": "Feature selection, which is a technique to select key features in recommender\nsystems, has received increasing research attention. Recently, Adaptive Feature\nSelection (AdaFS) has shown remarkable performance by adaptively selecting\nfeatures for each data instance, considering that the importance of a given\nfeature field can vary significantly across data. However, this method still\nhas limitations in that its selection process could be easily biased to major\nfeatures that frequently occur. To address these problems, we propose\nMulti-view Feature Selection (MvFS), which selects informative features for\neach instance more effectively. Most importantly, MvFS employs a multi-view\nnetwork consisting of multiple sub-networks, each of which learns to measure\nthe feature importance of a part of data with different feature patterns. By\ndoing so, MvFS promotes a more balanced feature selection process mitigating\nthe bias problem towards dominant patterns. Moreover, MvFS adopts an effective\nimportance score modeling strategy which is applied independently to each field\nwithout incurring dependency among features. Experimental results on real-world\ndatasets demonstrate the effectiveness of MvFS compared to state-of-the-art\nbaselines.",
        "translated": "特征选择作为推荐系统中的一种关键特征选择技术，越来越受到研究者的重视。最近，自适应特征选择(AdaFS)通过为每个数据实例自适应地选择特征来表现出显著的性能，考虑到给定特征字段的重要性在不同数据之间可能有显著的差异。然而，这种方法仍然有局限性，因为它的选择过程很容易偏向于频繁出现的主要特征。为了解决这些问题，我们提出了多视图特征选择(MvFS) ，它能够更有效地为每个实例选择信息特征。最重要的是，MvFS 使用一个由多个子网络组成的多视图网络，每个子网络学习测量具有不同特征模式的部分数据的特征重要性。通过这样做，MvFS 促进了一个更加平衡的特征选择过程，减轻了对主导模式的偏见问题。此外，MvFS 采用了一种有效的重要性评分建模策略，该策略可以独立地应用于各个领域，而不会引起特征之间的依赖性。在真实世界数据集上的实验结果表明，与最先进的基线相比，MvFS 是有效的。"
    },
    {
        "title": "Scenario-Aware Hierarchical Dynamic Network for Multi-Scenario\n  Recommendation",
        "url": "http://arxiv.org/abs/2309.02061v1",
        "pub_date": "2023-09-05",
        "summary": "Click-Through Rate (CTR) prediction is a fundamental technique in\nrecommendation and advertising systems. Recent studies have shown that\nimplementing multi-scenario recommendations contributes to strengthening\ninformation sharing and improving overall performance. However, existing\nmulti-scenario models only consider coarse-grained explicit scenario modeling\nthat depends on pre-defined scenario identification from manual prior rules,\nwhich is biased and sub-optimal. To address these limitations, we propose a\nScenario-Aware Hierarchical Dynamic Network for Multi-Scenario Recommendations\n(HierRec), which perceives implicit patterns adaptively and conducts explicit\nand implicit scenario modeling jointly. In particular, HierRec designs a basic\nscenario-oriented module based on the dynamic weight to capture\nscenario-specific information. Then the hierarchical explicit and implicit\nscenario-aware modules are proposed to model hybrid-grained scenario\ninformation. The multi-head implicit modeling design contributes to perceiving\ndistinctive patterns from different perspectives. Our experiments on two public\ndatasets and real-world industrial applications on a mainstream online\nadvertising platform demonstrate that our HierRec outperforms existing models\nsignificantly.",
        "translated": "点进率预测是推荐和广告系统中的一项基本技术。最近的研究表明，执行多方案建议有助于加强信息共享和改善总体业绩。然而，现有的多场景模型只考虑粗粒度的显式场景建模，而粗粒度的显式场景建模依赖于人工先验规则中预定义的场景识别，这是有偏差的、次优的。针对这些局限性，提出了一种基于场景感知的多场景推荐层次动态网络(HierRec) ，该网络能够自适应地感知隐式模式，并联合进行显式和隐式场景建模。特别地，HierRec 设计了一个基于动态权重的面向场景的基本模块来捕获特定于场景的信息。然后提出了分层的显式和隐式情景感知模块，对混合粒度情景信息进行建模。多头隐式建模设计有助于从不同的角度感知不同的模式。我们在两个公共数据集和一个主流在线广告平台上的实际工业应用程序上的实验表明，我们的 HierRec 显著优于现有模型。"
    },
    {
        "title": "Cognitive Architectures for Language Agents",
        "url": "http://arxiv.org/abs/2309.02427v1",
        "pub_date": "2023-09-05",
        "summary": "Recent efforts have incorporated large language models (LLMs) with external\nresources (e.g., the Internet) or internal control flows (e.g., prompt\nchaining) for tasks requiring grounding or reasoning. However, these efforts\nhave largely been piecemeal, lacking a systematic framework for constructing a\nfully-fledged language agent. To address this challenge, we draw on the rich\nhistory of agent design in symbolic artificial intelligence to develop a\nblueprint for a new wave of cognitive language agents. We first show that LLMs\nhave many of the same properties as production systems, and recent efforts to\nimprove their grounding or reasoning mirror the development of cognitive\narchitectures built around production systems. We then propose Cognitive\nArchitectures for Language Agents (CoALA), a conceptual framework to\nsystematize diverse methods for LLM-based reasoning, grounding, learning, and\ndecision making as instantiations of language agents in the framework. Finally,\nwe use the CoALA framework to highlight gaps and propose actionable directions\ntoward more capable language agents in the future.",
        "translated": "最近的努力已经将大型语言模型(LLM)与外部资源(例如，互联网)或内部控制流(例如，快速链接)结合起来，用于需要基础或推理的任务。然而，这些努力在很大程度上是零敲碎打的，缺乏构建一个完全成熟的语言代理的系统框架。为了应对这一挑战，我们借鉴了符号人工智能中代理设计的丰富历史，为新一波认知语言代理开辟了蓝图。我们首先展示了 LLM 与生产系统具有许多相同的属性，最近改进它们的基础或推理的努力反映了围绕生产系统构建的认知结构的发展。然后，我们提出了语言代理的认知架构(coALA) ，这个概念框架系统化了基于 LLM 的推理、基础、学习和决策的各种方法，作为框架中语言代理的实例化。最后，我们使用 CoALA 框架来突出差距，并提出可操作的方向，以便在未来更有能力的语言代理。"
    },
    {
        "title": "Substitution-based Semantic Change Detection using Contextual Embeddings",
        "url": "http://arxiv.org/abs/2309.02403v2",
        "pub_date": "2023-09-05",
        "summary": "Measuring semantic change has thus far remained a task where methods using\ncontextual embeddings have struggled to improve upon simpler techniques relying\nonly on static word vectors. Moreover, many of the previously proposed\napproaches suffer from downsides related to scalability and ease of\ninterpretation. We present a simplified approach to measuring semantic change\nusing contextual embeddings, relying only on the most probable substitutes for\nmasked terms. Not only is this approach directly interpretable, it is also far\nmore efficient in terms of storage, achieves superior average performance\nacross the most frequently cited datasets for this task, and allows for more\nnuanced investigation of change than is possible with static word vectors.",
        "translated": "到目前为止，测量语义变化仍然是一个任务，使用上下文嵌入的方法努力改进仅仅依赖于静态词向量的简单技术。此外，先前提出的许多方法都存在与可伸缩性和易于解释相关的缺点。我们提出了一个简化的方法来衡量语义变化使用上下文嵌入，只依赖于最可能的替代掩盖术语。这种方法不仅可以直接解释，而且在存储方面效率更高，在这项任务中实现了在最常引用的数据集中的优异平均性能，并且允许比静态词向量更细微的变化调查。"
    },
    {
        "title": "nanoT5: A PyTorch Framework for Pre-training and Fine-tuning T5-style\n  Models with Limited Resources",
        "url": "http://arxiv.org/abs/2309.02373v1",
        "pub_date": "2023-09-05",
        "summary": "State-of-the-art language models like T5 have revolutionized the NLP\nlandscape, but their computational demands hinder a large portion of the\nresearch community. To address this challenge, we present nanoT5, a\nspecially-optimized PyTorch framework for efficient pre-training and\nfine-tuning of T5 models. Drawing on insights from optimizer differences and\nprioritizing efficiency, nanoT5 allows a T5-Base model to be pre-trained on a\nsingle GPU in just 16 hours, without any loss in performance. With the\nintroduction of this open-source framework, we hope to widen the accessibility\nto language modelling research and cater to the community's demand for more\nuser-friendly T5 (Encoder-Decoder) implementations. Our contributions,\nincluding configurations, codebase, software/hardware insights, and pre-trained\nmodels, are available to the public, aiming to strike a balance between\nresearch accessibility and resource constraints in NLP.",
        "translated": "像 T5这样的最先进的语言模型已经彻底改变了自然语言处理领域，但是它们的计算需求阻碍了研究界的很大一部分。为了应对这一挑战，我们提出了 nanT5，一个特别优化的 PyTorch 框架，用于有效地预训练和微调 T5模型。基于对优化器差异和优先级效率的洞察，nanT5允许 T5-Base 模型在仅仅16小时内在单个 GPU 上进行预训练，而不会造成任何性能损失。随着这个开源框架的引入，我们希望扩大对语言建模研究的可访问性，并满足社区对更加用户友好的 T5(编解码器)实现的需求。我们的贡献，包括配置，代码库，软件/硬件见解和预先训练的模型，对公众开放，旨在取得研究可及性和资源约束之间的平衡自然语言处理。"
    },
    {
        "title": "Weigh Your Own Words: Improving Hate Speech Counter Narrative Generation\n  via Attention Regularization",
        "url": "http://arxiv.org/abs/2309.02311v1",
        "pub_date": "2023-09-05",
        "summary": "Recent computational approaches for combating online hate speech involve the\nautomatic generation of counter narratives by adapting Pretrained\nTransformer-based Language Models (PLMs) with human-curated data. This process,\nhowever, can produce in-domain overfitting, resulting in models generating\nacceptable narratives only for hatred similar to training data, with little\nportability to other targets or to real-world toxic language. This paper\nintroduces novel attention regularization methodologies to improve the\ngeneralization capabilities of PLMs for counter narratives generation.\nOverfitting to training-specific terms is then discouraged, resulting in more\ndiverse and richer narratives. We experiment with two attention-based\nregularization techniques on a benchmark English dataset. Regularized models\nproduce better counter narratives than state-of-the-art approaches in most\ncases, both in terms of automatic metrics and human evaluation, especially when\nhateful targets are not present in the training data. This work paves the way\nfor better and more flexible counter-speech generation models, a task for which\ndatasets are highly challenging to produce.",
        "translated": "针对网络仇恨言论的最新计算方法包括通过使用基于预训练变压器的语言模型(PLM)和人类策划的数据来自动生成反叙事。然而，这个过程可能会产生域内过度拟合，导致模型产生可接受的叙述，只针对与训练数据类似的仇恨，几乎不可移植到其他目标或现实世界的有毒语言。本文介绍了一种新的注意力正则化方法，以提高反叙事生成中 PLM 的泛化能力。然后，不鼓励过度使用特定于训练的术语，从而导致更多样化和更丰富的叙述。我们在一个基准的英语数据集上实验了两种基于注意力的正则化技术。在大多数情况下，正规化模型比最先进的方法产生更好的反叙述，无论是在自动度量标准方面还是在人类评估方面，特别是在训练数据中没有仇恨目标的情况下。这项工作为更好和更灵活的反语言生成模型铺平了道路，这是一项数据集生成极具挑战性的任务。"
    },
    {
        "title": "PromptTTS 2: Describing and Generating Voices with Text Prompt",
        "url": "http://arxiv.org/abs/2309.02285v1",
        "pub_date": "2023-09-05",
        "summary": "Speech conveys more information than just text, as the same word can be\nuttered in various voices to convey diverse information. Compared to\ntraditional text-to-speech (TTS) methods relying on speech prompts (reference\nspeech) for voice variability, using text prompts (descriptions) is more\nuser-friendly since speech prompts can be hard to find or may not exist at all.\nTTS approaches based on the text prompt face two challenges: 1) the one-to-many\nproblem, where not all details about voice variability can be described in the\ntext prompt, and 2) the limited availability of text prompt datasets, where\nvendors and large cost of data labeling are required to write text prompt for\nspeech. In this work, we introduce PromptTTS 2 to address these challenges with\na variation network to provide variability information of voice not captured by\ntext prompts, and a prompt generation pipeline to utilize the large language\nmodels (LLM) to compose high quality text prompts. Specifically, the variation\nnetwork predicts the representation extracted from the reference speech (which\ncontains full information about voice) based on the text prompt representation.\nFor the prompt generation pipeline, it generates text prompts for speech with a\nspeech understanding model to recognize voice attributes (e.g., gender, speed)\nfrom speech and a large language model to formulate text prompt based on the\nrecognition results. Experiments on a large-scale (44K hours) speech dataset\ndemonstrate that compared to the previous works, PromptTTS 2 generates voices\nmore consistent with text prompts and supports the sampling of diverse voice\nvariability, thereby offering users more choices on voice generation.\nAdditionally, the prompt generation pipeline produces high-quality prompts,\neliminating the large labeling cost. The demo page of PromptTTS 2 is available\nonline\\footnote{https://speechresearch.github.io/prompttts2}.",
        "translated": "语音传递的信息不仅仅是文字，因为同一个词可以用不同的语音来传递不同的信息。相对于传统的依靠语音提示(参考语音)进行语音变化的文本到语音(TTS)方法，使用文本提示(描述)更加方便用户，因为语音提示可能很难找到，也可能根本不存在。基于文本提示的 TTS 方法面临两个挑战: 1)一对多问题，其中并非所有关于语音可变性的细节都可以在文本提示中描述; 2)文本提示数据集的有限可用性，其中供应商和数据标签的巨大成本需要为语音编写文本提示。在这项工作中，我们引入 PromptTTS 2来解决这些挑战，使用变化网络提供未被文本提示捕获的语音的可变性信息，以及利用大语言模型(LLM)构成高质量文本提示的快速生成流水线。具体来说，变异网络基于文本提示表示预测从参考语音(包含关于语音的全部信息)中提取的表示。对于提示生成流水线，采用语音理解模型识别语音中的语音属性(如性别、速度)生成语音文本提示，采用大语言模型根据识别结果制定语音文本提示。在一个大规模(44K 小时)语音数据集上的实验表明，与以前的工作相比，PromptTTS 2生成的语音更符合文本提示，并支持不同语音变异性的采样，从而为用户提供更多的语音生成选择。此外，快速生成管道产生高质量的提示，消除了大量的标签成本。PrompttTS2的演示页面可在线脚注{ https://speechresearch.github.io/prompttts2}下载。"
    },
    {
        "title": "Dialog Action-Aware Transformer for Dialog Policy Learning",
        "url": "http://arxiv.org/abs/2309.02240v1",
        "pub_date": "2023-09-05",
        "summary": "Recent works usually address Dialog policy learning DPL by training a\nreinforcement learning (RL) agent to determine the best dialog action. However,\nexisting works on deep RL require a large volume of agent-user interactions to\nachieve acceptable performance. In this paper, we propose to make full use of\nthe plain text knowledge from the pre-trained language model to accelerate the\nRL agent's learning speed. Specifically, we design a dialog action-aware\ntransformer encoder (DaTrans), which integrates a new fine-tuning procedure\nnamed masked last action task to encourage DaTrans to be dialog-aware and\ndistils action-specific features. Then, DaTrans is further optimized in an RL\nsetting with ongoing interactions and evolves through exploration in the dialog\naction space toward maximizing long-term accumulated rewards. The effectiveness\nand efficiency of the proposed model are demonstrated with both simulator\nevaluation and human evaluation.",
        "translated": "最近的作品通常通过训练一个强化学习代理来决定最好的对话操作来解决对话策略学习 DPL 的问题。然而，现有的深层 RL 工作需要大量的代理-用户交互来实现可接受的性能。本文提出充分利用预训练语言模型中的纯文本知识来加快 RL 代理的学习速度。具体来说，我们设计了一个支持对话动作的转换编码器(DaTrans) ，它集成了一个名为掩盖上一个动作任务的新的微调过程，以鼓励 DaTrans 支持对话动作，并提取特定于动作的特性。然后，DATAN 在 RL 环境中进一步优化，不断进行交互，并通过在对话行动空间中的探索发展，以最大化长期累积的回报。通过模拟器评估和人工评估，验证了该模型的有效性和高效性。"
    },
    {
        "title": "Augmenting Black-box LLMs with Medical Textbooks for Clinical Question\n  Answering",
        "url": "http://arxiv.org/abs/2309.02233v1",
        "pub_date": "2023-09-05",
        "summary": "Large-scale language models (LLMs), such as ChatGPT, are capable of\ngenerating human-like responses for various downstream tasks, such as\ntask-oriented dialogues and question answering. However, applying LLMs to\nmedical domains remains challenging due to their inability to leverage\ndomain-specific knowledge. In this study, we present the Large-scale Language\nModels Augmented with Medical Textbooks (LLM-AMT), which integrates\nauthoritative medical textbooks as the cornerstone of its design, enhancing its\nproficiency in the specialized domain through plug-and-play modules, comprised\nof a Hybrid Textbook Retriever, supplemented by the Query Augmenter and the LLM\nReader. Experimental evaluation on three open-domain medical question-answering\ntasks reveals a substantial enhancement in both the professionalism and\naccuracy of the LLM responses when utilizing LLM-AMT, exhibiting an improvement\nranging from 11.4% to 13.2%. Despite being 100 times smaller, we found that\nmedical textbooks as the retrieval corpus serves as a more valuable external\nknowledge source than Wikipedia in the medical domain. Our experiments show\nthat textbook augmentation results in a performance improvement ranging from\n9.7% to 12.2% over Wikipedia augmentation.",
        "translated": "大规模语言模型(LLM) ，比如 ChatGPT，能够为各种下游任务生成类似人类的响应，比如面向任务的对话和问题回答。然而，将 LLM 应用于医学领域仍然具有挑战性，因为它们无法利用特定领域的知识。在这项研究中，我们提出了大规模的语言模型与医学教科书增强(LLM-AMT) ，其中集成了权威的医学教科书作为其设计的基石，通过即插即用模块提高其在专业领域的熟练程度，由混合教科书检索，查询增强器和 LLM 阅读器补充。对三个开放领域医学问答任务的实验评估显示，当使用 LLM-AMT 时，LLM 反应的专业性和准确性均有显著提高，提高幅度为11.4% 至13.2% 。尽管比维基百科小100倍，我们发现作为检索语料库的医学教科书在医学领域比维基百科更具有外部知识来源的价值。我们的实验表明，教科书增强的性能提高范围从9.7% 至12.2% 的维基百科增强。"
    },
    {
        "title": "Leveraging BERT Language Models for Multi-Lingual ESG Issue\n  Identification",
        "url": "http://arxiv.org/abs/2309.02189v1",
        "pub_date": "2023-09-05",
        "summary": "Environmental, Social, and Governance (ESG) has been used as a metric to\nmeasure the negative impacts and enhance positive outcomes of companies in\nareas such as the environment, society, and governance. Recently, investors\nhave increasingly recognized the significance of ESG criteria in their\ninvestment choices, leading businesses to integrate ESG principles into their\noperations and strategies. The Multi-Lingual ESG Issue Identification (ML-ESG)\nshared task encompasses the classification of news documents into 35 distinct\nESG issue labels. In this study, we explored multiple strategies harnessing\nBERT language models to achieve accurate classification of news documents\nacross these labels. Our analysis revealed that the RoBERTa classifier emerged\nas one of the most successful approaches, securing the second-place position\nfor the English test dataset, and sharing the fifth-place position for the\nFrench test dataset. Furthermore, our SVM-based binary model tailored for the\nChinese language exhibited exceptional performance, earning the second-place\nrank on the test dataset.",
        "translated": "环境、社会和治理(ESG)已被用作衡量公司在环境、社会和治理等领域的负面影响和增强积极成果的指标。最近，投资者越来越认识到环境、社会和治理标准在其投资选择中的重要性，导致企业将环境、社会和治理原则纳入其经营和战略。多语言 ESG 问题识别(ML-ESG)共享任务包括将新闻文档分类为35个不同的 ESG 问题标签。在这项研究中，我们探索了多种策略，利用 BERT 语言模型来实现跨这些标签的新闻文档的准确分类。我们的分析表明，RoBERTa 分类器成为最成功的方法之一，确保了英语测试数据集的第二位置，并共享法语测试数据集的第五位置。此外，我们的基于支持向量机的二进制模型为中国语言显示了出色的性能，赢得了第二名的测试数据集。"
    },
    {
        "title": "Incorporating Dictionaries into a Neural Network Architecture to Extract\n  COVID-19 Medical Concepts From Social Media",
        "url": "http://arxiv.org/abs/2309.02188v1",
        "pub_date": "2023-09-05",
        "summary": "We investigate the potential benefit of incorporating dictionary information\ninto a neural network architecture for natural language processing. In\nparticular, we make use of this architecture to extract several concepts\nrelated to COVID-19 from an on-line medical forum. We use a sample from the\nforum to manually curate one dictionary for each concept. In addition, we use\nMetaMap, which is a tool for extracting biomedical concepts, to identify a\nsmall number of semantic concepts. For a supervised concept extraction task on\nthe forum data, our best model achieved a macro $F_1$ score of 90\\%. A major\ndifficulty in medical concept extraction is obtaining labelled data from which\nto build supervised models. We investigate the utility of our models to\ntransfer to data derived from a different source in two ways. First for\nproducing labels via weak learning and second to perform concept extraction.\nThe dataset we use in this case comprises COVID-19 related tweets and we\nachieve an $F_1$ score 81\\% for symptom concept extraction trained on weakly\nlabelled data. The utility of our dictionaries is compared with a COVID-19\nsymptom dictionary that was constructed directly from Twitter. Further\nexperiments that incorporate BERT and a COVID-19 version of BERTweet\ndemonstrate that the dictionaries provide a commensurate result. Our results\nshow that incorporating small domain dictionaries to deep learning models can\nimprove concept extraction tasks. Moreover, models built using dictionaries\ngeneralize well and are transferable to different datasets on a similar task.",
        "translated": "我们研究了将字典信息合并到自然语言处理的神经网络结构中的潜在好处。特别是，我们利用这个架构从一个在线医学论坛中提取出几个与2019冠状病毒疾病相关的概念。我们使用论坛中的一个示例为每个概念手动编纂一本字典。此外，我们使用 MetaMap (一种提取生物医学概念的工具)来识别少量的语义概念。对于论坛数据的有监督的概念抽取任务，我们的最佳模型得到了90% 的宏观 F _ 1分。医学概念提取的一个主要困难是获得标记数据，从而建立监督模型。我们研究了我们的模型的实用性，以两种方式传输到来自不同来源的数据。首先通过弱学习生成标签，然后进行概念提取。我们在这个案例中使用的数据集包含与2019冠状病毒疾病相关的 tweet，在弱标记数据的症状概念提取训练中，我们获得了81% 的得分。我们的字典的实用性与直接从 Twitter 构建的2019冠状病毒疾病症状字典进行了比较。将 BERT 和 BERTweet 的2019冠状病毒疾病版本结合起来的进一步实验表明，字典提供了一个相称的结果。我们的研究结果表明，将小领域词典与深度学习模型相结合可以改善概念提取任务。此外，使用字典建立的模型可以很好地推广，并且可以在相似的任务中转移到不同的数据集。"
    },
    {
        "title": "Advancing Text-to-GLOSS Neural Translation Using a Novel Hyper-parameter\n  Optimization Technique",
        "url": "http://arxiv.org/abs/2309.02162v1",
        "pub_date": "2023-09-05",
        "summary": "In this paper, we investigate the use of transformers for Neural Machine\nTranslation of text-to-GLOSS for Deaf and Hard-of-Hearing communication. Due to\nthe scarcity of available data and limited resources for text-to-GLOSS\ntranslation, we treat the problem as a low-resource language task. We use our\nnovel hyper-parameter exploration technique to explore a variety of\narchitectural parameters and build an optimal transformer-based architecture\nspecifically tailored for text-to-GLOSS translation. The study aims to improve\nthe accuracy and fluency of Neural Machine Translation generated GLOSS. This is\nachieved by examining various architectural parameters including layer count,\nattention heads, embedding dimension, dropout, and label smoothing to identify\nthe optimal architecture for improving text-to-GLOSS translation performance.\nThe experiments conducted on the PHOENIX14T dataset reveal that the optimal\ntransformer architecture outperforms previous work on the same dataset. The\nbest model reaches a ROUGE (Recall-Oriented Understudy for Gisting Evaluation)\nscore of 55.18% and a BLEU-1 (BiLingual Evaluation Understudy 1) score of\n63.6%, outperforming state-of-the-art results on the BLEU1 and ROUGE score by\n8.42 and 0.63 respectively.",
        "translated": "本文主要研究变压器在聋人和听力障碍者文本到 GLOSS 的神经机器翻译中的应用。由于可用数据的稀缺性以及文本到 GLOSS 的翻译资源的有限性，我们把这个问题看作是一个低资源的语言任务。我们使用我们新颖的超参数探索技术来探索各种各样的体系结构参数，并建立一个最佳的基于转换器的体系结构，专门为文本到 GLOSS 的翻译。本研究旨在提高神经机器翻译生成 GLOSS 的准确性和流畅性。这是通过检查各种体系结构参数来实现的，包括层数、注意力集中、嵌入维度、丢失和标签平滑，以确定提高文本到 GLOSS 翻译性能的最佳体系结构。在 PHOENIX14T 数据集上进行的实验表明，最优变压器结构优于同一数据集上以往的工作。最佳模型达到 ROUGE (面向召回的代课评估)评分为55.18% ，BLEU-1(双语评估代课评估1)评分为63.6% ，分别优于 BLEU1和 ROUGE 评分的最新结果8.42和0.63。"
    },
    {
        "title": "Impression-Informed Multi-Behavior Recommender System: A Hierarchical\n  Graph Attention Approach",
        "url": "http://arxiv.org/abs/2309.03169v1",
        "pub_date": "2023-09-06",
        "summary": "While recommender systems have significantly benefited from implicit\nfeedback, they have often missed the nuances of multi-behavior interactions\nbetween users and items. Historically, these systems either amalgamated all\nbehaviors, such as \\textit{impression} (formerly \\textit{view}),\n\\textit{add-to-cart}, and \\textit{buy}, under a singular 'interaction' label,\nor prioritized only the target behavior, often the \\textit{buy} action,\ndiscarding valuable auxiliary signals. Although recent advancements tried\naddressing this simplification, they primarily gravitated towards optimizing\nthe target behavior alone, battling with data scarcity. Additionally, they\ntended to bypass the nuanced hierarchy intrinsic to behaviors. To bridge these\ngaps, we introduce the \\textbf{H}ierarchical \\textbf{M}ulti-behavior\n\\textbf{G}raph Attention \\textbf{N}etwork (HMGN). This pioneering framework\nleverages attention mechanisms to discern information from both inter and\nintra-behaviors while employing a multi-task Hierarchical Bayesian Personalized\nRanking (HBPR) for optimization. Recognizing the need for scalability, our\napproach integrates a specialized multi-behavior sub-graph sampling technique.\nMoreover, the adaptability of HMGN allows for the seamless inclusion of\nknowledge metadata and time-series data. Empirical results attest to our\nmodel's prowess, registering a notable performance boost of up to 64\\% in\nNDCG@100 metrics over conventional graph neural network methods.",
        "translated": "虽然推荐系统显著受益于隐式反馈，但它们往往忽略了用户和项目之间多行为交互的细微差别。从历史上看，这些系统要么将所有行为合并在一个单一的“交互”标签下，比如 texttit { image }(以前的 texttit { view })、 texttit { add-to-cart }和 texttit { buy } ，要么仅优先考虑目标行为，通常是 texttit { buy }操作，丢弃有价值的辅助信号。虽然最近的进展试图解决这种简化，他们主要倾向于优化单独的目标行为，与数据稀缺作斗争。此外，他们倾向于绕过行为固有的微妙等级制度。为了弥补这些差距，我们引入了 textbf { H }层次 textbf { M }多行为 textbf { G } raph 注意 textbf { N }网络(HMGN)。这个开创性的框架利用注意力机制从行为间和行为内识别信息，同时采用多任务层次贝叶斯个性化排名(HBPR)进行优化。认识到可伸缩性的需要，我们的方法集成了一个专门的多行为子图抽样技术。此外，HMGN 的适应性允许知识元数据和时间序列数据的无缝包含。实验结果证明了我们的模型的威力，在 NDCG@100指标中比传统的图形神经网络方法显著提高了高达64% 的性能。"
    },
    {
        "title": "Helper Recommendation with seniority control in Online Health Community",
        "url": "http://arxiv.org/abs/2309.02978v1",
        "pub_date": "2023-09-06",
        "summary": "Online health communities (OHCs) are forums where patients with similar\nconditions communicate their experiences and provide moral support. Social\nsupport in OHCs plays a crucial role in easing and rehabilitating patients.\nHowever, many time-sensitive questions from patients often remain unanswered\ndue to the multitude of threads and the random nature of patient visits in\nOHCs. To address this issue, it is imperative to propose a recommender system\nthat assists solution seekers in finding appropriate problem helpers.\nNevertheless, developing a recommendation algorithm to enhance social support\nin OHCs remains an under-explored area. Traditional recommender systems cannot\nbe directly adapted due to the following obstacles. First, unlike user-item\nlinks in traditional recommender systems, it is hard to model the social\nsupport behind helper-seeker links in OHCs since they are formed based on\nvarious heterogeneous reasons. Second, it is difficult to distinguish the\nimpact of historical activities in characterizing patients. Third, it is\nsignificantly challenging to ensure that the recommended helpers possess\nsufficient expertise to assist the seekers. To tackle the aforementioned\nchallenges, we develop a Monotonically regularIzed diseNTangled Variational\nAutoencoders (MINT) model to strengthen social support in OHCs.",
        "translated": "在线健康社区(OHC)是患有相似疾病的患者交流经验并提供精神支持的论坛。社会支持在减轻病人的痛苦和使病人康复方面发挥着至关重要的作用。然而，许多来自患者的时间敏感问题往往仍然没有得到回答，由于线程的多样性和随机性的患者访问在健康中心。为了解决这个问题，我们必须提出一个推荐系统，协助寻求解决方案的人士寻找合适的问题帮助者。尽管如此，开发一种推荐算法来加强办公室的社会支持仍然是一个尚未探索的领域。由于以下障碍，传统的推荐系统不能直接适应。首先，与传统推荐系统中的用户项链接不同，OHC 中寻求帮助者链接背后的社会支持很难建模，因为它们是基于各种不同的原因形成的。其次，很难区分历史活动对患者特征的影响。第三，要确保被推荐的助手具备足够的专业知识来协助求助者，是一项极具挑战性的工作。为了应对上述挑战，我们开发了一个单调正则化的 diseNTangled 变量自动编码器(MINT)模型，以加强 OHC 的社会支持。"
    },
    {
        "title": "Prompt-based Effective Input Reformulation for Legal Case Retrieval",
        "url": "http://arxiv.org/abs/2309.02962v1",
        "pub_date": "2023-09-06",
        "summary": "Legal case retrieval plays an important role for legal practitioners to\neffectively retrieve relevant cases given a query case. Most existing neural\nlegal case retrieval models directly encode the whole legal text of a case to\ngenerate a case representation, which is then utilised to conduct a nearest\nneighbour search for retrieval. Although these straightforward methods have\nachieved improvement over conventional statistical methods in retrieval\naccuracy, two significant challenges are identified in this paper: (1) Legal\nfeature alignment: the usage of the whole case text as the input will generally\nincorporate redundant and noisy information because, from the legal\nperspective, the determining factor of relevant cases is the alignment of key\nlegal features instead of whole text matching; (2) Legal context preservation:\nfurthermore, since the existing text encoding models usually have an input\nlength limit shorter than the case, the whole case text needs to be truncated\nor divided into paragraphs, which leads to the loss of the global context of\nlegal information. In this paper, a novel legal case retrieval framework,\nPromptCase, is proposed to tackle these challenges. Firstly, legal facts and\nlegal issues are identified and formally defined as the key features\nfacilitating legal case retrieval based on a thorough study of the definition\nof relevant cases from a legal perspective. Secondly, with the determining\nlegal features, a prompt-based encoding scheme is designed to conduct an\neffective encoding with language models. Extensive zero-shot experiments have\nbeen conducted on two benchmark datasets in legal case retrieval, which\ndemonstrate the superior retrieval effectiveness of the proposed PromptCase.\nThe code has been released on https://github.com/yanran-tang/PromptCase.",
        "translated": "法律案件检索对于法律从业人员在查询案件中有效地检索相关案件具有重要作用。大多数现有的神经网络案例检索模型直接对案例的全部法律文本进行编码，生成案例表示，然后利用该表示进行最近邻搜索进行检索。虽然这些简单易行的方法在检索精度方面比传统的统计方法有所提高，但本文指出了两个重大挑战: (1)法律特征对齐: 使用整个案例文本作为输入通常会包含冗余和噪声信息，因为从法律角度来看，相关案例的决定因素是关键法律特征的对齐，而不是整个文本匹配; (2)法律上下文保存: 此外，由于现有的文本编码模型通常有一个输入长度限制短于案例，整个案例文本需要被截断或分割成段落，这导致法律信息的全。本文提出了一个新的法律案例检索框架 PromptCase 来解决这些挑战。首先，从法律角度对相关案例的定义进行深入研究，确定法律事实和法律问题，并将其正式定义为便于法律案例检索的关键特征。其次，根据确定的法律特征，设计了一种基于提示的编码方案，利用语言模型进行有效的编码。在法律案例检索的两个基准数据集上进行了广泛的零拍实验，结果表明提出的 PromptCase 检索方法具有较好的检索效果。密码已经在 https://github.com/yanran-tang/promptcase 上发布了。"
    },
    {
        "title": "Tidying Up the Conversational Recommender Systems' Biases",
        "url": "http://arxiv.org/abs/2309.02550v1",
        "pub_date": "2023-09-05",
        "summary": "The growing popularity of language models has sparked interest in\nconversational recommender systems (CRS) within both industry and research\ncircles. However, concerns regarding biases in these systems have emerged.\nWhile individual components of CRS have been subject to bias studies, a\nliterature gap remains in understanding specific biases unique to CRS and how\nthese biases may be amplified or reduced when integrated into complex CRS\nmodels. In this paper, we provide a concise review of biases in CRS by\nsurveying recent literature. We examine the presence of biases throughout the\nsystem's pipeline and consider the challenges that arise from combining\nmultiple models. Our study investigates biases in classic recommender systems\nand their relevance to CRS. Moreover, we address specific biases in CRS,\nconsidering variations with and without natural language understanding\ncapabilities, along with biases related to dialogue systems and language\nmodels. Through our findings, we highlight the necessity of adopting a holistic\nperspective when dealing with biases in complex CRS models.",
        "translated": "语言模型的日益普及引起了业界和研究界对会话推荐系统(CRS)的兴趣。然而，关于这些系统中的偏差的担忧已经出现。虽然 CRS 的各个组成部分已经进行了偏倚研究，但是在理解 CRS 独有的特定偏倚以及如何将这些偏倚整合到复杂的 CRS 模型中时如何放大或减少方面仍然存在文献差距。在本文中，我们通过查阅最近的文献，对 CRS 中的偏倚进行了简要的综述。我们检查了整个系统管道中存在的偏差，并考虑了组合多个模型所带来的挑战。我们的研究调查了经典推荐系统中的偏差及其与 CRS 的相关性。此外，我们处理 CRS 中的特定偏差，考虑有或没有自然语言理解能力的差异，以及与对话系统和语言模型相关的偏差。通过我们的发现，我们强调了在处理复杂 CRS 模型中的偏差时采用整体观点的必要性。"
    },
    {
        "title": "Gender-specific Machine Translation with Large Language Models",
        "url": "http://arxiv.org/abs/2309.03175v1",
        "pub_date": "2023-09-06",
        "summary": "Decoder-only Large Language Models (LLMs) have demonstrated potential in\nmachine translation (MT), albeit with performance slightly lagging behind\ntraditional encoder-decoder Neural Machine Translation (NMT) systems. However,\nLLMs offer a unique advantage: the ability to control the properties of the\noutput through prompts. In this study, we harness this flexibility to explore\nLLaMa's capability to produce gender-specific translations for languages with\ngrammatical gender. Our results indicate that LLaMa can generate\ngender-specific translations with competitive accuracy and gender bias\nmitigation when compared to NLLB, a state-of-the-art multilingual NMT system.\nFurthermore, our experiments reveal that LLaMa's translations are robust,\nshowing significant performance drops when evaluated against opposite-gender\nreferences in gender-ambiguous datasets but maintaining consistency in less\nambiguous contexts. This research provides insights into the potential and\nchallenges of using LLMs for gender-specific translations and highlights the\nimportance of in-context learning to elicit new tasks in LLMs.",
        "translated": "仅解码器的大语言模型(LLM)在机器翻译(MT)方面已经显示出潜力，尽管其性能稍稍落后于传统的编解码器神经机器翻译(NMT)系统。然而，LLM 提供了一个独特的优势: 通过提示控制输出属性的能力。在这项研究中，我们利用这种灵活性来探索 LlaMa 为具有性的语言提供针对不同性别的翻译的能力。我们的研究结果表明，与 NLLB (一种最先进的多语种 NMT 系统)相比，LLaMa 可以生成具有竞争力的准确性和性别偏见缓解的特定性别翻译。此外，我们的实验表明，LLaMa 的翻译是稳健的，显示出显着的性能下降时，评估对性别不明确的数据集中的异性参考，但保持一致性在较少模糊的情况下。这项研究提供了深入了解的潜力和挑战，使用语言学习模式的性别特定的翻译，并强调了在上下文学习的重要性，以引发新的任务在语言学习模式。"
    },
    {
        "title": "GPT-InvestAR: Enhancing Stock Investment Strategies through Annual\n  Report Analysis with Large Language Models",
        "url": "http://arxiv.org/abs/2309.03079v1",
        "pub_date": "2023-09-06",
        "summary": "Annual Reports of publicly listed companies contain vital information about\ntheir financial health which can help assess the potential impact on Stock\nprice of the firm. These reports are comprehensive in nature, going up to, and\nsometimes exceeding, 100 pages. Analysing these reports is cumbersome even for\na single firm, let alone the whole universe of firms that exist. Over the\nyears, financial experts have become proficient in extracting valuable\ninformation from these documents relatively quickly. However, this requires\nyears of practice and experience. This paper aims to simplify the process of\nassessing Annual Reports of all the firms by leveraging the capabilities of\nLarge Language Models (LLMs). The insights generated by the LLM are compiled in\na Quant styled dataset and augmented by historical stock price data. A Machine\nLearning model is then trained with LLM outputs as features. The walkforward\ntest results show promising outperformance wrt S&amp;P500 returns. This paper\nintends to provide a framework for future work in this direction. To facilitate\nthis, the code has been released as open source.",
        "translated": "上市公司的年度报告包含了关于其财务健康状况的重要信息，这些信息有助于评估对公司股票价格的潜在影响。这些报告本质上是全面的，长达100页，有时甚至超过100页。分析这些报告甚至对于一家公司来说都是很麻烦的，更不用说对于整个存在的公司来说了。多年来，金融专家已经成为相对快速地从这些文件中提取有价值信息的专家。然而，这需要多年的实践和经验。本文旨在通过利用大语言模型(LLM)的能力来简化评估所有公司年度报告的过程。LLM 产生的洞察力被编译成一个定量风格的数据集，并通过历史股票价格数据得到增强。然后用 LLM 输出作为特征对机器学习模型进行训练。前瞻性测试结果显示，标准普尔500指数的回报率有望超过预期。本文旨在为今后这方面的工作提供一个框架。为了实现这一点，代码已经作为开放源码发布。"
    },
    {
        "title": "J-Guard: Journalism Guided Adversarially Robust Detection of\n  AI-generated News",
        "url": "http://arxiv.org/abs/2309.03164v1",
        "pub_date": "2023-09-06",
        "summary": "The rapid proliferation of AI-generated text online is profoundly reshaping\nthe information landscape. Among various types of AI-generated text,\nAI-generated news presents a significant threat as it can be a prominent source\nof misinformation online. While several recent efforts have focused on\ndetecting AI-generated text in general, these methods require enhanced\nreliability, given concerns about their vulnerability to simple adversarial\nattacks. Furthermore, due to the eccentricities of news writing, applying these\ndetection methods for AI-generated news can produce false positives,\npotentially damaging the reputation of news organizations. To address these\nchallenges, we leverage the expertise of an interdisciplinary team to develop a\nframework, J-Guard, capable of steering existing supervised AI text detectors\nfor detecting AI-generated news while boosting adversarial robustness. By\nincorporating stylistic cues inspired by the unique journalistic attributes,\nJ-Guard effectively distinguishes between real-world journalism and\nAI-generated news articles. Our experiments on news articles generated by a\nvast array of AI models, including ChatGPT (GPT3.5), demonstrate the\neffectiveness of J-Guard in enhancing detection capabilities while maintaining\nan average performance decrease of as low as 7% when faced with adversarial\nattacks.",
        "translated": "人工智能生成的在线文本的快速增长正在深刻地重塑信息格局。在各种类型的人工智能生成的文本中，人工智能生成的新闻是一个重大的威胁，因为它可以成为网上错误信息的一个突出来源。虽然最近的一些努力主要集中在检测 AI 生成的文本，但这些方法需要提高可靠性，因为人们担心它们容易受到简单的对手攻击。此外，由于新闻写作的特殊性，对人工智能生成的新闻应用这些检测方法可能产生假阳性，有可能损害新闻机构的声誉。为了应对这些挑战，我们利用跨学科团队的专业知识来开发一个框架 J-Guard，该框架能够指导现有的受监督的 AI 文本检测器来检测 AI 生成的新闻，同时增强对手的鲁棒性。通过结合独特的新闻属性所激发的文体线索，J-Guard 有效地区分了现实世界的新闻和人工智能生成的新闻文章。我们对大量 AI 模型(包括 ChatGPT (GPT3.5))生成的新闻文章进行的实验证明了 J-Guard 在增强检测能力方面的有效性，同时在面对对手攻击时保持平均性能下降低至7% 。"
    },
    {
        "title": "Everyone Deserves A Reward: Learning Customized Human Preferences",
        "url": "http://arxiv.org/abs/2309.03126v1",
        "pub_date": "2023-09-06",
        "summary": "Reward models (RMs) are crucial in aligning large language models (LLMs) with\nhuman preferences for improving interaction quality. However, the real world is\npluralistic, which leads to diversified human preferences based on different\nreligions, politics, cultures, etc. Moreover, each individual can have their\nown unique preferences on various topics. Neglecting the diversity of human\npreferences, current LLM training processes only use a general reward model,\nwhich is below satisfaction for customized or personalized application\nscenarios. To explore customized preference learning, we collect a\ndomain-specific preference (DSP) dataset, which collects preferred responses to\neach given query from four practical domains. Besides, from the perspective of\ndata efficiency, we proposed a three-stage customized RM learning scheme, whose\neffectiveness is empirically verified on both general preference datasets and\nour DSP set. Furthermore, we test multiple training and data strategies on the\nthree learning stages, and have found several ways to better preserve the\ngeneral preferring ability while training the customized RMs, especially\ngeneral preference enrichment and customized preference imitation learning. The\nDSP dataset and code are available at https://github.com/Linear95/DSP.",
        "translated": "奖励模型(RM)在使大型语言模型(LLM)与人类偏好保持一致以提高交互质量方面至关重要。然而，现实世界是多元的，不同的宗教、政治、文化等因素导致了人类偏好的多元化。此外，每个人都可以对不同的主题有自己独特的偏好。由于忽略了人类偏好的多样性，目前的 LLM 培训过程只使用了一个通用的奖励模型，这个模型对于定制或个性化的应用场景来说是不满意的。为了探索自定义偏好学习，我们收集了一个领域特定偏好(DSP)数据集，该数据集收集了来自四个实际领域对每个给定查询的偏好响应。此外，从数据效率的角度出发，我们提出了一个三阶段定制的 RM 学习方案，该方案的有效性在一般偏好数据集和我们的 DSP 集上都得到了实验验证。此外，我们在三个学习阶段对多种训练策略和数据策略进行了测试，发现了几种更好地保持一般偏好能力的方法，尤其是一般偏好充实和定制偏好模仿学习。数字信号处理器的数据集和代码可在 https://github.com/linear95/DSP 获得。"
    },
    {
        "title": "Knowledge Solver: Teaching LLMs to Search for Domain Knowledge from\n  Knowledge Graphs",
        "url": "http://arxiv.org/abs/2309.03118v1",
        "pub_date": "2023-09-06",
        "summary": "Large language models (LLMs), such as ChatGPT and GPT-4, are versatile and\ncan solve different tasks due to their emergent ability and generalizability.\nHowever, LLMs sometimes lack domain-specific knowledge to perform tasks, which\nwould also cause hallucination during inference. In some previous works,\nadditional modules like graph neural networks (GNNs) are trained on retrieved\nknowledge from external knowledge bases, aiming to mitigate the problem of\nlacking domain-specific knowledge. However, incorporating additional modules:\n1) would need retraining additional modules when encountering novel domains; 2)\nwould become a bottleneck since LLMs' strong abilities are not fully utilized\nfor retrieval. In this paper, we propose a paradigm, termed Knowledge Solver\n(KSL), to teach LLMs to search for essential knowledge from external knowledge\nbases by harnessing their own strong generalizability. Specifically, we design\na simple yet effective prompt to transform retrieval into a multi-hop decision\nsequence, which empowers LLMs with searching knowledge ability in zero-shot\nmanner. Additionally, KSL is able to provide complete retrieval paths and\ntherefore increase explainability of LLMs' reasoning processes. We conduct\nexperiments on three datasets: CommonsenseQA, OpenbookQA, and MedQA-USMLE, and\nfound that our approach improves LLM baseline performance by a relatively large\nmargin.",
        "translated": "大型语言模型(LLM) ，例如 ChatGPT 和 GPT-4，由于它们的涌现能力和泛化能力，可以通用地解决不同的任务。然而，LLM 有时缺乏特定领域的知识来执行任务，这也会在推理过程中引起幻觉。在以往的工作中，为了解决领域特定知识缺乏的问题，对图神经网络(GNN)等附加模块进行了从外部知识库中检索知识的训练。然而，加入额外的模块: 1)将需要再培训额外的模块时，遇到新的领域; 2)将成为一个瓶颈，因为 LLM 的强大能力没有充分利用检索。在本文中，我们提出了一个范式，称为知识求解器(KSL) ，教导 LLM 从外部知识库中寻找必要的知识，通过利用他们自己的强大的普遍性。具体而言，我们设计了一个简单而有效的提示，将检索转换成多跳决策序列，使得 LLM 具有零拍搜索知识的能力。此外，KSL 能够提供完整的检索路径，从而提高 LLM 推理过程的可解释性。我们在三个数据集上进行了实验: CommonsenseQA、 OpenbookQA 和 MedQA-USMLE，发现我们的方法相对大幅度地提高了 LLM 基线性能。"
    },
    {
        "title": "ContrastWSD: Enhancing Metaphor Detection with Word Sense Disambiguation\n  Following the Metaphor Identification Procedure",
        "url": "http://arxiv.org/abs/2309.03103v1",
        "pub_date": "2023-09-06",
        "summary": "This paper presents ContrastWSD, a RoBERTa-based metaphor detection model\nthat integrates the Metaphor Identification Procedure (MIP) and Word Sense\nDisambiguation (WSD) to extract and contrast the contextual meaning with the\nbasic meaning of a word to determine whether it is used metaphorically in a\nsentence. By utilizing the word senses derived from a WSD model, our model\nenhances the metaphor detection process and outperforms other methods that rely\nsolely on contextual embeddings or integrate only the basic definitions and\nother external knowledge. We evaluate our approach on various benchmark\ndatasets and compare it with strong baselines, indicating the effectiveness in\nadvancing metaphor detection.",
        "translated": "本文提出了一种基于 RoBERTa 的隐喻检测模型，该模型集成了隐喻识别程序(MIP)和词义消歧(WSD) ，通过提取上下文意义和词的基本意义进行对比来判断是否在句子中使用隐喻。通过利用 WSD 模型中的词义，我们的模型增强了隐喻检测过程，并优于其他仅依赖于上下文嵌入或仅集成基本定义和其他外部知识的方法。我们在不同的基准数据集上评估我们的方法，并将其与强基线进行比较，表明该方法在提高隐喻检测方面的有效性。"
    },
    {
        "title": "A Multimodal Analysis of Influencer Content on Twitter",
        "url": "http://arxiv.org/abs/2309.03064v1",
        "pub_date": "2023-09-06",
        "summary": "Influencer marketing involves a wide range of strategies in which brands\ncollaborate with popular content creators (i.e., influencers) to leverage their\nreach, trust, and impact on their audience to promote and endorse products or\nservices. Because followers of influencers are more likely to buy a product\nafter receiving an authentic product endorsement rather than an explicit direct\nproduct promotion, the line between personal opinions and commercial content\npromotion is frequently blurred. This makes automatic detection of regulatory\ncompliance breaches related to influencer advertising (e.g., misleading\nadvertising or hidden sponsorships) particularly difficult. In this work, we\n(1) introduce a new Twitter (now X) dataset consisting of 15,998 influencer\nposts mapped into commercial and non-commercial categories for assisting in the\nautomatic detection of commercial influencer content; (2) experiment with an\nextensive set of predictive models that combine text and visual information\nshowing that our proposed cross-attention approach outperforms state-of-the-art\nmultimodal models; and (3) conduct a thorough analysis of strengths and\nlimitations of our models. We show that multimodal modeling is useful for\nidentifying commercial posts, reducing the amount of false positives, and\ncapturing relevant context that aids in the discovery of undisclosed commercial\nposts.",
        "translated": "影响者营销涉及一系列广泛的策略，其中品牌与流行内容创造者(即影响者)合作，利用他们的影响力、信任和对受众的影响来推广和认可产品或服务。由于影响者的追随者更有可能在收到真实的产品代言后购买产品，而不是直接进行产品推广，因此个人观点和商业内容推广之间的界限经常变得模糊。这使得自动检测与影响者广告(例如误导性广告或隐藏赞助)有关的守规违规行为变得尤为困难。在这项工作中，我们(1)介绍了一个新的 Twitter (现在的 X)数据集，包括15,998个影响者帖子映射到商业和非商业类别，以协助自动检测商业影响者的内容; (2)实验与一个广泛的预测模型，结合文本和视觉信息，显示我们提出的交叉注意方法优于国家的最先进的多模式模型; (3)进行了我们的模型的优势和局限性的彻底分析。我们表明，多模态建模是有用的，以确定商业职位，减少虚假肯定的数量，并捕捉相关的背景，有助于发现未披露的商业职位。"
    },
    {
        "title": "Persona-aware Generative Model for Code-mixed Language",
        "url": "http://arxiv.org/abs/2309.02915v1",
        "pub_date": "2023-09-06",
        "summary": "Code-mixing and script-mixing are prevalent across online social networks and\nmultilingual societies. However, a user's preference toward code-mixing depends\non the socioeconomic status, demographics of the user, and the local context,\nwhich existing generative models mostly ignore while generating code-mixed\ntexts. In this work, we make a pioneering attempt to develop a persona-aware\ngenerative model to generate texts resembling real-life code-mixed texts of\nindividuals. We propose a Persona-aware Generative Model for Code-mixed\nGeneration, PARADOX, a novel Transformer-based encoder-decoder model that\nencodes an utterance conditioned on a user's persona and generates code-mixed\ntexts without monolingual reference data. We propose an alignment module that\nre-calibrates the generated sequence to resemble real-life code-mixed texts.\nPARADOX generates code-mixed texts that are semantically more meaningful and\nlinguistically more valid. To evaluate the personification capabilities of\nPARADOX, we propose four new metrics -- CM BLEU, CM Rouge-1, CM Rouge-L and CM\nKS. On average, PARADOX achieves 1.6 points better CM BLEU, 47% better\nperplexity and 32% better semantic coherence than the non-persona-based\ncounterparts.",
        "translated": "在线社交网络和多语言社会中，语码混合和脚本混合现象十分普遍。然而，用户对混合编码的偏好取决于用户的社会经济地位、人口统计学特征和当地环境，现有的生成模型在生成混合编码文本时大多忽略了这些因素。在这项工作中，我们做了一个开创性的尝试，开发了一个人物感知生成模型，以生成类似于现实生活中个人混合编码文本的文本。我们提出了一个人格感知的代码混合生成生成模型，PARADOX，一个新颖的基于变压器的编码器-解码器模型，编码一个以用户的人格为条件的话语，并生成没有单语参考数据的代码混合文本。我们提出了一个对齐模块，重新校准生成的序列，以类似于真实的混合编码文本。PARADOX 生成的代码混合文本在语义上更有意义，在语言上更有效。为了评估 PARADOX 的人格化能力，我们提出了四个新指标—— CM BLEU、 CM Rouge-1、 CM Rouge-L 和 CM KS。PARADOX 平均比非基于人物角色的同类算法高出1.6个百分点的 CM BLEU、47% 的困惑度和32% 的语义一致性。"
    },
    {
        "title": "Leave no Place Behind: Improved Geolocation in Humanitarian Documents",
        "url": "http://arxiv.org/abs/2309.02914v1",
        "pub_date": "2023-09-06",
        "summary": "Geographical location is a crucial element of humanitarian response,\noutlining vulnerable populations, ongoing events, and available resources.\nLatest developments in Natural Language Processing may help in extracting vital\ninformation from the deluge of reports and documents produced by the\nhumanitarian sector. However, the performance and biases of existing\nstate-of-the-art information extraction tools are unknown. In this work, we\ndevelop annotated resources to fine-tune the popular Named Entity Recognition\n(NER) tools Spacy and roBERTa to perform geotagging of humanitarian texts. We\nthen propose a geocoding method FeatureRank which links the candidate locations\nto the GeoNames database. We find that not only does the humanitarian-domain\ndata improves the performance of the classifiers (up to F1 = 0.92), but it also\nalleviates some of the bias of the existing tools, which erroneously favor\nlocations in the Western countries. Thus, we conclude that more resources from\nnon-Western documents are necessary to ensure that off-the-shelf NER systems\nare suitable for the deployment in the humanitarian sector.",
        "translated": "地理位置是人道主义反应的一个关键因素，概述了脆弱的人口、正在发生的事件和可用的资源。自然语言处理方面的最新发展可能有助于从人道主义部门编写的大量报告和文件中提取重要信息。然而，现有最先进的信息抽取工具的性能和偏差还不得而知。在这项工作中，我们开发注释资源来微调流行的命名实体识别(NER)工具 Spacy 和 roBERTa 来执行人道主义文本的地理标记。然后，我们提出了一种地理编码方法 FeatureRank，它将候选位置链接到 GeoNames 数据库。我们发现，人道主义领域的数据不仅提高了分类器的性能(高达 F1 = 0.92) ，而且还减轻了现有工具的一些偏差，这些偏差错误地偏向于西方国家的位置。因此，我们得出结论认为，需要从非西方文件中获得更多资源，以确保现成的 NER 系统适合在人道主义部门部署。"
    },
    {
        "title": "On the Challenges of Building Datasets for Hate Speech Detection",
        "url": "http://arxiv.org/abs/2309.02912v1",
        "pub_date": "2023-09-06",
        "summary": "Detection of hate speech has been formulated as a standalone application of\nNLP and different approaches have been adopted for identifying the target\ngroups, obtaining raw data, defining the labeling process, choosing the\ndetection algorithm, and evaluating the performance in the desired setting.\nHowever, unlike other downstream tasks, hate speech suffers from the lack of\nlarge-sized, carefully curated, generalizable datasets owing to the highly\nsubjective nature of the task. In this paper, we first analyze the issues\nsurrounding hate speech detection through a data-centric lens. We then outline\na holistic framework to encapsulate the data creation pipeline across seven\nbroad dimensions by taking the specific example of hate speech towards sexual\nminorities. We posit that practitioners would benefit from following this\nframework as a form of best practice when creating hate speech datasets in the\nfuture.",
        "translated": "仇恨语音检测是自然语言处理的一个绿色软体，在识别目标群体、获取原始数据、定义标记过程、选择检测算法以及评估所需环境下的性能等方面都采用了不同的方法。然而，与其他下游任务不同，仇恨言论由于任务的高度主观性而缺乏大型的、精心策划的、可概括的数据集。在本文中，我们首先通过一个以数据为中心的透镜来分析围绕仇恨言论检测的问题。然后，我们以针对性少数群体的仇恨言论的具体例子为例，概述了一个整体框架，将数据创建管道概括为七个广泛层面。我们假设，从业人员将受益于遵循这一框架作为一种形式的最佳实践，在创建仇恨言论数据集的未来。"
    },
    {
        "title": "Extending Transductive Knowledge Graph Embedding Models for Inductive\n  Logical Relational Inference",
        "url": "http://arxiv.org/abs/2309.03773v1",
        "pub_date": "2023-09-07",
        "summary": "Many downstream inference tasks for knowledge graphs, such as relation\nprediction, have been handled successfully by knowledge graph embedding\ntechniques in the transductive setting. To address the inductive setting\nwherein new entities are introduced into the knowledge graph at inference time,\nmore recent work opts for models which learn implicit representations of the\nknowledge graph through a complex function of a network's subgraph structure,\noften parametrized by graph neural network architectures. These come at the\ncost of increased parametrization, reduced interpretability and limited\ngeneralization to other downstream inference tasks. In this work, we bridge the\ngap between traditional transductive knowledge graph embedding approaches and\nmore recent inductive relation prediction models by introducing a generalized\nform of harmonic extension which leverages representations learned through\ntransductive embedding methods to infer representations of new entities\nintroduced at inference time as in the inductive setting. This harmonic\nextension technique provides the best such approximation, can be implemented\nvia an efficient iterative scheme, and can be employed to answer a family of\nconjunctive logical queries over the knowledge graph, further expanding the\ncapabilities of transductive embedding methods. In experiments on a number of\nlarge-scale knowledge graph embedding benchmarks, we find that this approach\nfor extending the functionality of transductive knowledge graph embedding\nmodels to perform knowledge graph completion and answer logical queries in the\ninductive setting is competitive with--and in some scenarios\noutperforms--several state-of-the-art models derived explicitly for such\ninductive tasks.",
        "translated": "知识图的许多下游推理任务，如关系预测，已成功地处理了知识图嵌入技术在传导设置。为了解决在推理时向知识图中引入新实体的归纳设置问题，最近的工作选择了通过网络子图结构的复杂函数学习知识图的隐式表示的模型，通常由图神经网络结构参数化。这些都是以增加参数化、降低可解释性和限制对其他下游推理任务的推广为代价的。在这项工作中，我们通过引入一种广义形式的调和扩展来弥补传统的传导性知识图嵌入方法和最近的归纳关系预测模型之间的差距，它利用通过传导性嵌入方法学到的表示来推断在推理时间引入的新实体的表示，如在归纳环境中。这种调和扩展技术提供了最佳的近似，可以通过一个有效的迭代方案来实现，并且可以用来回答知识图上的一系列合取逻辑查询，进一步扩展了传导嵌入方法的能力。在一些大规模的知识图嵌入基准的实验中，我们发现这种扩展传导性知识图嵌入模型功能的方法在归纳环境中执行知识图的完成和回答逻辑查询，与在某些情况下优于为这种归纳任务明确导出的几种最先进的模型竞争。"
    },
    {
        "title": "VideolandGPT: A User Study on a Conversational Recommender System",
        "url": "http://arxiv.org/abs/2309.03645v1",
        "pub_date": "2023-09-07",
        "summary": "This paper investigates how large language models (LLMs) can enhance\nrecommender systems, with a specific focus on Conversational Recommender\nSystems that leverage user preferences and personalised candidate selections\nfrom existing ranking models. We introduce VideolandGPT, a recommender system\nfor a Video-on-Demand (VOD) platform, Videoland, which uses ChatGPT to select\nfrom a predetermined set of contents, considering the additional context\nindicated by users' interactions with a chat interface. We evaluate ranking\nmetrics, user experience, and fairness of recommendations, comparing a\npersonalised and a non-personalised version of the system, in a between-subject\nuser study. Our results indicate that the personalised version outperforms the\nnon-personalised in terms of accuracy and general user satisfaction, while both\nversions increase the visibility of items which are not in the top of the\nrecommendation lists. However, both versions present inconsistent behavior in\nterms of fairness, as the system may generate recommendations which are not\navailable on Videoland.",
        "translated": "本文研究了大语言模型(LLM)如何增强推荐系统，重点研究了对话式推荐系统，该系统利用用户偏好和现有排名模型中的个性化候选人选择。我们介绍 VideolandGPT，一个视频点播(Video-on-Demand，VOD)平台的推荐系统，Videoland 使用 ChatgPT 从预先确定的内容集中进行选择，考虑到用户与聊天界面的交互所显示的额外上下文。我们评估排名指标，用户体验和推荐的公平性，比较个性化和非个性化的系统版本，在一个主题之间的用户研究。我们的研究结果表明，个性化版本在准确性和一般用户满意度方面优于非个性化版本，而两个版本都增加了不在推荐列表顶部的项目的可见性。然而，两个版本在公平性方面表现出不一致的行为，因为系统可能会生成在 Videoland 上无法获得的推荐。"
    },
    {
        "title": "Evaluating ChatGPT as a Recommender System: A Rigorous Approach",
        "url": "http://arxiv.org/abs/2309.03613v1",
        "pub_date": "2023-09-07",
        "summary": "Recent popularity surrounds large AI language models due to their impressive\nnatural language capabilities. They contribute significantly to\nlanguage-related tasks, including prompt-based learning, making them valuable\nfor various specific tasks. This approach unlocks their full potential,\nenhancing precision and generalization. Research communities are actively\nexploring their applications, with ChatGPT receiving recognition. Despite\nextensive research on large language models, their potential in recommendation\nscenarios still needs to be explored. This study aims to fill this gap by\ninvestigating ChatGPT's capabilities as a zero-shot recommender system. Our\ngoals include evaluating its ability to use user preferences for\nrecommendations, reordering existing recommendation lists, leveraging\ninformation from similar users, and handling cold-start situations. We assess\nChatGPT's performance through comprehensive experiments using three datasets\n(MovieLens Small, Last.FM, and Facebook Book). We compare ChatGPT's performance\nagainst standard recommendation algorithms and other large language models,\nsuch as GPT-3.5 and PaLM-2. To measure recommendation effectiveness, we employ\nwidely-used evaluation metrics like Mean Average Precision (MAP), Recall,\nPrecision, F1, normalized Discounted Cumulative Gain (nDCG), Item Coverage,\nExpected Popularity Complement (EPC), Average Coverage of Long Tail (ACLT),\nAverage Recommendation Popularity (ARP), and Popularity-based Ranking-based\nEqual Opportunity (PopREO). Through thoroughly exploring ChatGPT's abilities in\nrecommender systems, our study aims to contribute to the growing body of\nresearch on the versatility and potential applications of large language\nmodels. Our experiment code is available on the GitHub repository:\nhttps://github.com/sisinflab/Recommender-ChatGPT",
        "translated": "由于大型人工智能语言模型令人印象深刻的自然语言能力，它们最近很受欢迎。他们对语言相关的任务有很大贡献，包括快速学习，使他们对各种特定的任务有价值。这种方法充分发挥了它们的潜力，提高了精度和泛化能力。研究团体正在积极探索他们的应用，ChatGPT 得到了认可。尽管对大型语言模型进行了广泛的研究，但它们在推荐场景中的潜力仍然需要探索。这项研究旨在通过调查 chatgPT 作为零推荐系统的能力来填补这一空白。我们的目标包括评估其使用用户偏好推荐的能力，重新排序现有的推荐列表，利用来自相似用户的信息，以及处理冷启动情况。我们通过使用三个数据集(MovieLens Small、 Last.FM 和 Facebook Book)的综合实验来评估 ChatGPT 的性能。我们比较了 ChatGPT 与标准推荐算法和其他大型语言模型(如 GPT-3.5和 PaLM-2)的性能。为了衡量推荐的有效性，我们采用了广泛使用的评估指标，如平均平均精度(MAP) ，召回，精度，F1，标准化的贴现累积增益(nDCG) ，项目覆盖率，预期受欢迎程度补充(EPC) ，长尾平均覆盖率(ACLT) ，平均推荐受欢迎程度(ARP)和基于受欢迎程度的排名的平等机会(PopREO)。通过深入研究 ChatGPT 在推荐系统中的能力，我们的研究旨在促进越来越多的大型语言模型的通用性和潜在应用的研究。我们的实验代码可以在 GitHub 存储库中找到:  https://GitHub.com/sisinflab/recommender-chatgpt"
    },
    {
        "title": "Learning Compact Compositional Embeddings via Regularized Pruning for\n  Recommendation",
        "url": "http://arxiv.org/abs/2309.03518v1",
        "pub_date": "2023-09-07",
        "summary": "Latent factor models are the dominant backbones of contemporary recommender\nsystems (RSs) given their performance advantages, where a unique vector\nembedding with a fixed dimensionality (e.g., 128) is required to represent each\nentity (commonly a user/item). Due to the large number of users and items on\ne-commerce sites, the embedding table is arguably the least memory-efficient\ncomponent of RSs. For any lightweight recommender that aims to efficiently\nscale with the growing size of users/items or to remain applicable in\nresource-constrained settings, existing solutions either reduce the number of\nembeddings needed via hashing, or sparsify the full embedding table to switch\noff selected embedding dimensions. However, as hash collision arises or\nembeddings become overly sparse, especially when adapting to a tighter memory\nbudget, those lightweight recommenders inevitably have to compromise their\naccuracy. To this end, we propose a novel compact embedding framework for RSs,\nnamely Compositional Embedding with Regularized Pruning (CERP). Specifically,\nCERP represents each entity by combining a pair of embeddings from two\nindependent, substantially smaller meta-embedding tables, which are then\njointly pruned via a learnable element-wise threshold. In addition, we\ninnovatively design a regularized pruning mechanism in CERP, such that the two\nsparsified meta-embedding tables are encouraged to encode information that is\nmutually complementary. Given the compatibility with agnostic latent factor\nmodels, we pair CERP with two popular recommendation models for extensive\nexperiments, where results on two real-world datasets under different memory\nbudgets demonstrate its superiority against state-of-the-art baselines. The\ncodebase of CERP is available in https://github.com/xurong-liang/CERP.",
        "translated": "潜在因素模型是当代推荐系统(RS)的主要骨干，因为它们具有性能优势，其中需要一个嵌入固定维度(例如128)的独特向量来表示每个实体(通常是一个用户/项目)。由于电子商务网站上有大量的用户和项目，嵌入式表可以说是 RSS 中内存效率最低的组件。对于任何旨在随着用户/项目规模的增长而有效扩展的轻量级推荐器，或者在资源受限的环境中仍然适用的推荐器，现有的解决方案要么通过散列减少所需的嵌入数量，要么通过稀疏整个嵌入表来关闭选定的嵌入维度。然而，随着散列冲突的出现或嵌入变得过于稀疏，特别是在适应更紧凑的内存预算时，那些轻量级推荐程序不可避免地要牺牲它们的准确性。为此，我们提出了一种新的紧凑型 RS 嵌入框架，即正则修剪组合嵌入(CERP)。具体来说，CERP 通过组合来自两个独立的、相当小的元嵌入表的一对嵌入来表示每个实体，然后通过一个可学习的元素明智阈值对这两个元嵌入表进行联合修剪。此外，我们在 CERP 中创新地设计了一个规范化的剪枝机制，使得两个稀疏化元嵌入表能够编码相互补充的信息。考虑到与不可知潜在因素模型的兼容性，我们将 CERP 与两个流行的推荐模型配对进行广泛的实验，其中在不同内存预算下的两个真实世界数据集上的结果表明其优于最先进的基线。CERP 的代码库有 https://github.com/xurong-liang/CERP。"
    },
    {
        "title": "Behind Recommender Systems: the Geography of the ACM RecSys Community",
        "url": "http://arxiv.org/abs/2309.03512v1",
        "pub_date": "2023-09-07",
        "summary": "The amount and dissemination rate of media content accessible online is\nnowadays overwhelming. Recommender Systems filter this information into\nmanageable streams or feeds, adapted to our personal needs or preferences. It\nis of utter importance that algorithms employed to filter information do not\ndistort or cut out important elements from our perspectives of the world. Under\nthis principle, it is essential to involve diverse views and teams from the\nearliest stages of their design and development. This has been highlighted, for\ninstance, in recent European Union regulations such as the Digital Services\nAct, via the requirement of risk monitoring, including the risk of\ndiscrimination, and the AI Act, through the requirement to involve people with\ndiverse backgrounds in the development of AI systems. We look into the\ngeographic diversity of the recommender systems research community,\nspecifically by analyzing the affiliation countries of the authors who\ncontributed to the ACM Conference on Recommender Systems (RecSys) during the\nlast 15 years. This study has been carried out in the framework of the\nDiversity in AI - DivinAI project, whose main objective is the long-term\nmonitoring of diversity in AI forums through a set of indexes.",
        "translated": "如今，在线可获得的媒体内容的数量和传播速度是压倒性的。推荐系统将这些信息过滤到可管理的流或提要中，以适应我们的个人需求或偏好。至关重要的是，用于过滤信息的算法不会从我们的世界观扭曲或删除重要元素。根据这一原则，从设计和开发的最初阶段开始，就必须让不同的视图和团队参与进来。例如，欧洲联盟最近的条例强调了这一点，例如《数字服务法》要求进行风险监测，包括歧视风险; 《大赦法》要求让具有不同背景的人参与大赦系统的开发。我们研究推荐系统研究社区的地理多样性，特别是通过分析在过去15年中为 ACM 推荐系统会议(RecSys)做出贡献的作者的联系国。这项研究是在人工智能多样性 DivinAI 项目的框架内进行的，其主要目标是通过一套指标对人工智能论坛的多样性进行长期监测。"
    },
    {
        "title": "ImageBind-LLM: Multi-modality Instruction Tuning",
        "url": "http://arxiv.org/abs/2309.03905v1",
        "pub_date": "2023-09-07",
        "summary": "We present ImageBind-LLM, a multi-modality instruction tuning method of large\nlanguage models (LLMs) via ImageBind. Existing works mainly focus on language\nand image instruction tuning, different from which, our ImageBind-LLM can\nrespond to multi-modality conditions, including audio, 3D point clouds, video,\nand their embedding-space arithmetic by only image-text alignment training.\nDuring training, we adopt a learnable bind network to align the embedding space\nbetween LLaMA and ImageBind's image encoder. Then, the image features\ntransformed by the bind network are added to word tokens of all layers in\nLLaMA, which progressively injects visual instructions via an attention-free\nand zero-initialized gating mechanism. Aided by the joint embedding of\nImageBind, the simple image-text training enables our model to exhibit superior\nmulti-modality instruction-following capabilities. During inference, the\nmulti-modality inputs are fed into the corresponding ImageBind encoders, and\nprocessed by a proposed visual cache model for further cross-modal embedding\nenhancement. The training-free cache model retrieves from three million image\nfeatures extracted by ImageBind, which effectively mitigates the\ntraining-inference modality discrepancy. Notably, with our approach,\nImageBind-LLM can respond to instructions of diverse modalities and demonstrate\nsignificant language generation quality. Code is released at\nhttps://github.com/OpenGVLab/LLaMA-Adapter.",
        "translated": "我们介绍了 ImageBind-LLM，一种通过 ImageBind 对大型语言模型(LLM)进行多模态指令调优的方法。现有的工作主要集中在语言和图像指令调优方面，与之不同的是，我们的 ImageBind-LLM 仅通过图像-文本对齐训练就可以响应多模态条件，包括音频、三维点云、视频及其嵌入空间算法。在训练过程中，我们采用了一种可学习的绑定网络来校准 LLaMA 和 ImageBind 的图像编码器之间的嵌入空间。然后，将经过绑定网络转换的图像特征添加到 LLaMA 中所有层的字标记中，通过无注意和零初始化的门控机制逐步注入视觉指令。借助于 ImageBind 的联合嵌入，简单的图像-文本训练使我们的模型显示出优越的多模态指令跟踪能力。在推理过程中，多模态输入被反馈到相应的 ImageBind 编码器中，并通过提出的可视化缓存模型进行处理，以进一步增强跨模态嵌入。无需训练的缓存模型从 ImageBind 提取的300万个图像特征中检索，有效地缓解了训练-推理模式的差异。值得注意的是，通过我们的方法，ImageBind-LLM 可以响应不同模式的指令，并显示出显著的语言生成质量。代码在 https://github.com/opengvlab/llama-adapter 发布。"
    },
    {
        "title": "A Function Interpretation Benchmark for Evaluating Interpretability\n  Methods",
        "url": "http://arxiv.org/abs/2309.03886v1",
        "pub_date": "2023-09-07",
        "summary": "Labeling neural network submodules with human-legible descriptions is useful\nfor many downstream tasks: such descriptions can surface failures, guide\ninterventions, and perhaps even explain important model behaviors. To date,\nmost mechanistic descriptions of trained networks have involved small models,\nnarrowly delimited phenomena, and large amounts of human labor. Labeling all\nhuman-interpretable sub-computations in models of increasing size and\ncomplexity will almost certainly require tools that can generate and validate\ndescriptions automatically. Recently, techniques that use learned models\nin-the-loop for labeling have begun to gain traction, but methods for\nevaluating their efficacy are limited and ad-hoc. How should we validate and\ncompare open-ended labeling tools? This paper introduces FIND (Function\nINterpretation and Description), a benchmark suite for evaluating the building\nblocks of automated interpretability methods. FIND contains functions that\nresemble components of trained neural networks, and accompanying descriptions\nof the kind we seek to generate. The functions are procedurally constructed\nacross textual and numeric domains, and involve a range of real-world\ncomplexities, including noise, composition, approximation, and bias. We\nevaluate new and existing methods that use language models (LMs) to produce\ncode-based and language descriptions of function behavior. We find that an\noff-the-shelf LM augmented with only black-box access to functions can\nsometimes infer their structure, acting as a scientist by forming hypotheses,\nproposing experiments, and updating descriptions in light of new data. However,\nLM-based descriptions tend to capture global function behavior and miss local\ncorruptions. These results show that FIND will be useful for characterizing the\nperformance of more sophisticated interpretability methods before they are\napplied to real-world models.",
        "translated": "用人类易读的描述标记神经网络子模块对于许多下游任务是有用的: 这样的描述可以表面故障，指导干预，甚至可以解释重要的模型行为。迄今为止，大多数训练网络的机械描述都涉及到小模型、狭义的现象和大量的人工劳动。在规模和复杂性不断增加的模型中标记所有人类可解释的子计算几乎肯定需要能够自动生成和验证描述的工具。最近，使用循环学习模型进行标记的技术已经开始获得吸引力，但是评估其有效性的方法是有限的和特别的。我们应该如何验证和比较开放式标签工具？本文介绍了 FIND (函数解释和描述) ，一个评估自动解释方法的基准组件。FIND 包含类似于经过训练的神经网络的组件的函数，以及我们寻求生成的那类函数的附带描述。这些函数是跨文本和数值域的程序构造，涉及一系列真实世界的复杂性，包括噪声、合成、近似和偏差。我们评估使用语言模型(LM)生成基于代码的函数行为描述和语言描述的新方法和现有方法。我们发现，一个现成的 LM，只通过黑盒访问功能，有时可以推断出它们的结构，作为一个科学家，形成假设，提出实验，并根据新的数据更新描述。但是，基于 LM 的描述往往捕获全局函数行为，而忽略了局部损坏。这些结果表明，FIND 将有助于表征更复杂的可解释性方法的性能之前，他们被应用到现实世界的模型。"
    },
    {
        "title": "Zero-Shot Audio Captioning via Audibility Guidance",
        "url": "http://arxiv.org/abs/2309.03884v1",
        "pub_date": "2023-09-07",
        "summary": "The task of audio captioning is similar in essence to tasks such as image and\nvideo captioning. However, it has received much less attention. We propose\nthree desiderata for captioning audio -- (i) fluency of the generated text,\n(ii) faithfulness of the generated text to the input audio, and the somewhat\nrelated (iii) audibility, which is the quality of being able to be perceived\nbased only on audio. Our method is a zero-shot method, i.e., we do not learn to\nperform captioning. Instead, captioning occurs as an inference process that\ninvolves three networks that correspond to the three desired qualities: (i) A\nLarge Language Model, in our case, for reasons of convenience, GPT-2, (ii) A\nmodel that provides a matching score between an audio file and a text, for\nwhich we use a multimodal matching network called ImageBind, and (iii) A text\nclassifier, trained using a dataset we collected automatically by instructing\nGPT-4 with prompts designed to direct the generation of both audible and\ninaudible sentences. We present our results on the AudioCap dataset,\ndemonstrating that audibility guidance significantly enhances performance\ncompared to the baseline, which lacks this objective.",
        "translated": "音频字幕的任务与图像和视频字幕的任务在本质上是相似的。然而，它受到的关注要少得多。我们提出了字幕音频的三个必要条件——(i)生成文本的流畅性，(ii)生成文本对输入音频的忠实性，以及有些相关的(iii)可听性，这是仅基于音频就能感知到的质量。我们的方法是零拍摄方法，也就是说，我们不学习执行字幕。相反，字幕发生作为一个推理过程，涉及三个网络，对应于三个所需的质量: (i)大型语言模型，在我们的情况下，为了方便起见，GPT-2，(ii)提供音频文件和文本之间的匹配分数的模型，我们使用称为 ImageBind 的多模式匹配网络，和(iii)使用数据集进行训练的文本分类器，我们通过指示 GPT-4来自动收集，提示旨在指导生成听得见和听不见的句子。我们在 AudioCap 数据集上展示了我们的结果，证明了与缺乏这一目标的基线相比，可听性指导显著提高了性能。"
    },
    {
        "title": "DoLa: Decoding by Contrasting Layers Improves Factuality in Large\n  Language Models",
        "url": "http://arxiv.org/abs/2309.03883v1",
        "pub_date": "2023-09-07",
        "summary": "Despite their impressive capabilities, large language models (LLMs) are prone\nto hallucinations, i.e., generating content that deviates from facts seen\nduring pretraining. We propose a simple decoding strategy for reducing\nhallucinations with pretrained LLMs that does not require conditioning on\nretrieved external knowledge nor additional fine-tuning. Our approach obtains\nthe next-token distribution by contrasting the differences in logits obtained\nfrom projecting the later layers versus earlier layers to the vocabulary space,\nexploiting the fact that factual knowledge in an LLMs has generally been shown\nto be localized to particular transformer layers. We find that this Decoding by\nContrasting Layers (DoLa) approach is able to better surface factual knowledge\nand reduce the generation of incorrect facts. DoLa consistently improves the\ntruthfulness across multiple choices tasks and open-ended generation tasks, for\nexample improving the performance of LLaMA family models on TruthfulQA by\n12-17% absolute points, demonstrating its potential in making LLMs reliably\ngenerate truthful facts.",
        "translated": "尽管大型语言模型(LLM)具有令人印象深刻的能力，但它们容易产生幻觉，即生成的内容偏离了预训练期间看到的事实。我们提出了一个简单的解码策略，以减少预先训练的 LLM 幻觉，不需要条件对检索的外部知识或额外的微调。我们的方法通过对比在词汇空间中投影较晚层与较早层所获得的 logit 的差异来获得下一个令牌分布，利用 LLM 中的事实知识通常被证明局部化到特定的变压器层的事实。我们发现这种对比层解码(DoLa)方法能够更好地表现事实知识，并减少不正确事实的产生。DoLa 不断提高多选择任务和开放式生成任务的真实性，例如在 TruthfulQA 上将 LLaMA 家族模型的性能提高12-17% 的绝对点，表明其在使 LLM 可靠地生成真实事实方面的潜力。"
    },
    {
        "title": "On Large Language Models' Selection Bias in Multi-Choice Questions",
        "url": "http://arxiv.org/abs/2309.03882v1",
        "pub_date": "2023-09-07",
        "summary": "Multi-choice questions (MCQs) serve as a common yet important task format in\nthe research of large language models (LLMs). Our work shows that LLMs exhibit\nan inherent \"selection bias\" in MCQs, which refers to LLMs' preferences to\nselect options located at specific positions (like \"Option C\"). This bias is\nprevalent across various LLMs, making their performance vulnerable to option\nposition changes in MCQs. We identify that one primary cause resulting in\nselection bias is option numbering, i.e., the ID symbols A/B/C/D associated\nwith the options. To mitigate selection bias, we propose a new method called\nPriDe. PriDe first decomposes the observed model prediction distribution into\nan intrinsic prediction over option contents and a prior distribution over\noption IDs. It then estimates the prior by permutating option contents on a\nsmall number of test samples, which is used to debias the subsequent test\nsamples. We demonstrate that, as a label-free, inference-time method, PriDe\nachieves a more effective and computation-efficient debiasing than strong\nbaselines. We further show that the priors estimated by PriDe generalize well\nacross different domains, highlighting its practical potential in broader\nscenarios.",
        "translated": "多项选择题是大型语言模型研究中一种常见而又重要的任务形式。我们的工作表明，LLM 在 MCQs 中表现出一种固有的“选择偏差”，即 LLM 偏好选择位于特定位置的选项(如“选项 C”)。这种偏差在不同的 LLM 中普遍存在，使得它们的表现容易受到 MCQ 中期权头寸变化的影响。我们发现导致选择偏差的一个主要原因是选项编号，即与选项相关的 ID 符号 A/B/C/D。为了减小选择偏差，我们提出了一种新的方法 PriDe。PriDe 首先将观测到的模型预测分布分解为期权内容的内在预测和期权 ID 的先验分布。然后通过置换少量测试样本的期权内容来估计先验，从而使后续的测试样本偏差降低。我们证明，作为一种无标签，推断时间的方法，PriDe 实现了更有效和计算效率的消偏比强基线。我们进一步表明 PriDe 估计的先验在不同的领域有很好的推广，突出了它在更广泛的情况下的实际潜力。"
    },
    {
        "title": "Introducing \"Forecast Utterance\" for Conversational Data Science",
        "url": "http://arxiv.org/abs/2309.03877v1",
        "pub_date": "2023-09-07",
        "summary": "Envision an intelligent agent capable of assisting users in conducting\nforecasting tasks through intuitive, natural conversations, without requiring\nin-depth knowledge of the underlying machine learning (ML) processes. A\nsignificant challenge for the agent in this endeavor is to accurately\ncomprehend the user's prediction goals and, consequently, formulate precise ML\ntasks. In this paper, we take a pioneering step towards this ambitious goal by\nintroducing a new concept called Forecast Utterance and then focus on the\nautomatic and accurate interpretation of users' prediction goals from these\nutterances. Specifically, we frame the task as a slot-filling problem, where\neach slot corresponds to a specific aspect of the goal prediction task. We then\nemploy two zero-shot methods for solving the slot-filling task, namely: 1)\nEntity Extraction (EE), and 2) Question-Answering (QA) techniques. Our\nexperiments, conducted with three meticulously crafted data sets, validate the\nviability of our ambitious goal and demonstrate the effectiveness of both EE\nand QA techniques in interpreting Forecast Utterances.",
        "translated": "设想一个智能代理能够通过直观、自然的对话帮助用户进行预测任务，而不需要深入了解基础机器学习(ML)过程。在这种努力中，代理面临的一个重大挑战是准确地理解用户的预测目标，从而制定出精确的机器学习任务。在本文中，我们通过引入一个叫做预测语句的新概念，向这个雄心勃勃的目标迈出了开创性的一步，然后着重于从这些语句中自动和准确地解释用户的预测目标。具体来说，我们将任务框架为一个槽填充问题，其中每个槽对应于目标预测任务的特定方面。然后，我们采用两种零拍方法来解决填槽任务，即: 1)实体提取(EE)和2)问题回答(QA)技术。我们用三个精心制作的数据集进行了实验，验证了我们雄心勃勃的目标的可行性，并证明了 EE 和 QA 技术在解释预测语句方面的有效性。"
    },
    {
        "title": "OpinionGPT: Modelling Explicit Biases in Instruction-Tuned LLMs",
        "url": "http://arxiv.org/abs/2309.03876v1",
        "pub_date": "2023-09-07",
        "summary": "Instruction-tuned Large Language Models (LLMs) have recently showcased\nremarkable ability to generate fitting responses to natural language\ninstructions. However, an open research question concerns the inherent biases\nof trained models and their responses. For instance, if the data used to tune\nan LLM is dominantly written by persons with a specific political bias, we\nmight expect generated answers to share this bias. Current research work seeks\nto de-bias such models, or suppress potentially biased answers. With this\ndemonstration, we take a different view on biases in instruction-tuning: Rather\nthan aiming to suppress them, we aim to make them explicit and transparent. To\nthis end, we present OpinionGPT, a web demo in which users can ask questions\nand select all biases they wish to investigate. The demo will answer this\nquestion using a model fine-tuned on text representing each of the selected\nbiases, allowing side-by-side comparison. To train the underlying model, we\nidentified 11 different biases (political, geographic, gender, age) and derived\nan instruction-tuning corpus in which each answer was written by members of one\nof these demographics. This paper presents OpinionGPT, illustrates how we\ntrained the bias-aware model and showcases the web application (available at\nhttps://opiniongpt.informatik.hu-berlin.de).",
        "translated": "指令调整的大型语言模型(LLM)最近显示了对自然语言指令产生适当响应的显著能力。然而，一个开放的研究问题涉及训练模型的固有偏差及其反应。例如，如果用于调整 LLM 的数据主要是由具有特定政治偏见的人撰写的，我们可能期望生成的答案分享这种偏见。目前的研究工作试图消除这些模型的偏见，或压制潜在的偏见答案。通过这个演示，我们对教学调优中的偏差有了不同的看法: 我们的目标不是抑制偏差，而是使偏差变得明确和透明。为此，我们展示了 OpinionGPT，这是一个网络演示，用户可以在其中提出问题，并选择他们希望调查的所有偏见。演示将使用一个模型来回答这个问题，该模型对表示每个选定偏差的文本进行了微调，允许并排比较。为了训练潜在的模型，我们确定了11种不同的偏见(政治，地理，性别，年龄) ，并得出了一个指令调优语料库，其中每个答案都是由这些人口统计学的成员写的。本文介绍了 OpinionGPT，说明了我们如何训练偏见感知模型，并展示了 web 应用程序(可在 https://OpinionGPT.informatik.hu-berlin.de 下载)。"
    },
    {
        "title": "FLM-101B: An Open LLM and How to Train It with $100K Budget",
        "url": "http://arxiv.org/abs/2309.03852v1",
        "pub_date": "2023-09-07",
        "summary": "Large language models (LLMs) have achieved remarkable success in NLP and\nmultimodal tasks. Despite these successes, their development faces two main\nchallenges: (i) high computational cost; and (ii) difficulty in conducting fair\nand objective evaluations. LLMs are prohibitively expensive, making it feasible\nfor only a few major players to undertake their training, thereby constraining\nboth research and application opportunities. This underscores the importance of\ncost-effective LLM training. In this paper, we utilize a growth strategy to\nsignificantly reduce LLM training cost. We demonstrate that an LLM with 101B\nparameters and 0.31TB tokens can be trained on a $100K budget. We also adopt a\nsystematic evaluation paradigm for the IQ evaluation of LLMs, in complement to\nexisting evaluations that focus more on knowledge-oriented abilities. We\nintroduce our benchmark including evaluations on important aspects of\nintelligence including symbolic mapping, itrule understanding, pattern mining,\nand anti-interference. Such evaluations minimize the potential impact of\nmemorization. Experimental results show that our model FLM-101B, trained with a\nbudget of $100K, achieves comparable performance to powerful and well-known\nmodels, eg GPT-3 and GLM-130B, especially in the IQ benchmark evaluations with\ncontexts unseen in training data. The checkpoint of FLM-101B will be\nopen-sourced at https://huggingface.co/CofeAI/FLM-101B.",
        "translated": "大语言模型(LLM)在自然语言处理和多模态任务中取得了显著的成功。尽管取得了这些成功，但它们的发展仍然面临两个主要挑战: (1)计算成本高; (2)难以进行公正和客观的评估。LLM 的费用高得令人望而却步，使得只有少数主要参与者能够进行培训，从而限制了研究和应用机会。这突出了成本效益的 LLM 培训的重要性。在本文中，我们利用增长策略来显著降低 LLM 培训成本。我们演示了一个具有101B 参数和0.31 TB 令牌的 LLM 可以在10万美元的预算下进行培训。我们还采用了一个系统的评价范式的智商评价的 LLM，以补充现有的评价，更侧重于知识导向的能力。我们介绍了我们的基准，包括对智能的重要方面的评估，包括符号映射、规则理解、模式挖掘和抗干扰。这种评价尽量减少记忆的潜在影响。实验结果表明，我们的模型 FLM-101B，用10万美元的预算培训，实现了可比的性能，强大和著名的模型，如 GPT-3和 GLM-130B，特别是在 IQ 基准评估与背景不可见的训练数据。FLM-101B 的检查点将在 https://huggingface.co/cofeai/FLM-101B 开源。"
    },
    {
        "title": "Uncovering Drift in Textual Data: An Unsupervised Method for Detecting\n  and Mitigating Drift in Machine Learning Models",
        "url": "http://arxiv.org/abs/2309.03831v1",
        "pub_date": "2023-09-07",
        "summary": "Drift in machine learning refers to the phenomenon where the statistical\nproperties of data or context, in which the model operates, change over time\nleading to a decrease in its performance. Therefore, maintaining a constant\nmonitoring process for machine learning model performance is crucial in order\nto proactively prevent any potential performance regression. However,\nsupervised drift detection methods require human annotation and consequently\nlead to a longer time to detect and mitigate the drift. In our proposed\nunsupervised drift detection method, we follow a two step process. Our first\nstep involves encoding a sample of production data as the target distribution,\nand the model training data as the reference distribution. In the second step,\nwe employ a kernel-based statistical test that utilizes the maximum mean\ndiscrepancy (MMD) distance metric to compare the reference and target\ndistributions and estimate any potential drift. Our method also identifies the\nsubset of production data that is the root cause of the drift. The models\nretrained using these identified high drift samples show improved performance\non online customer experience quality metrics.",
        "translated": "机器学习中的漂移现象是指模型所处的数据或上下文的统计特性随着时间的推移而改变，从而导致其性能的下降。因此，为了预防任何潜在的性能回归，对机器学习模型的性能保持一个恒定的监控过程是至关重要的。然而，监督漂移检测方法需要人工注释，从而导致较长的时间来检测和缓解漂移。在我们提出的无监督漂移检测方法中，我们遵循两步过程。我们的第一步包括将生产数据样本编码为目标分布，并将模型训练数据编码为参考分布。在第二步中，我们使用基于核的统计检验，利用最大平均差距(MMD)距离度量来比较参考和目标分布，并估计任何潜在的漂移。我们的方法还确定了生产数据的子集，这是漂移的根本原因。使用这些识别出的高漂移样本重新训练的模型表明，在线客户体验质量指标的性能有所改善。"
    },
    {
        "title": "USA: Universal Sentiment Analysis Model &amp; Construction of Japanese\n  Sentiment Text Classification and Part of Speech Dataset",
        "url": "http://arxiv.org/abs/2309.03787v1",
        "pub_date": "2023-09-07",
        "summary": "Sentiment analysis is a pivotal task in the domain of natural language\nprocessing. It encompasses both text-level sentiment polarity classification\nand word-level Part of Speech(POS) sentiment polarity determination. Such\nanalysis challenges models to understand text holistically while also\nextracting nuanced information. With the rise of Large Language Models(LLMs),\nnew avenues for sentiment analysis have opened. This paper proposes enhancing\nperformance by leveraging the Mutual Reinforcement Effect(MRE) between\nindividual words and the overall text. It delves into how word polarity\ninfluences the overarching sentiment of a passage. To support our research, we\nannotated four novel Sentiment Text Classification and Part of Speech(SCPOS)\ndatasets, building upon existing sentiment classification datasets.\nFurthermore, we developed a Universal Sentiment Analysis(USA) model, with a\n7-billion parameter size. Experimental results revealed that our model\nsurpassed the performance of gpt-3.5-turbo across all four datasets,\nunderscoring the significance of MRE in sentiment analysis.",
        "translated": "情感分析是自然语言处理领域中的一项关键任务。它包括文本级情感极性分类和词级词性词性(POS)情感极性确定。这种分析要求模型在提取细微信息的同时全面理解文本。随着大语言模型(LLM)的兴起，情感分析的新途径已经开辟。本文提出通过利用单个词与整体文本之间的互强化效应(MRE)来提高表现力。它深入探讨了词的极性如何影响一段文章的总体情感。为了支持我们的研究，我们注释了四个新的情感文本分类和言语部分(SCPOS)数据集，在现有的情感分类数据集的基础上。此外，我们开发了一个通用情绪分析(美国)模型，具有70亿个参数的大小。实验结果表明，我们的模型在所有四个数据集中都超过了 gpt-3.5-turbo 的性能，强调了 MRE 在情绪分析中的重要性。"
    },
    {
        "title": "Provider Fairness and Beyond-Accuracy Trade-offs in Recommender Systems",
        "url": "http://arxiv.org/abs/2309.04250v1",
        "pub_date": "2023-09-08",
        "summary": "Recommender systems, while transformative in online user experiences, have\nraised concerns over potential provider-side fairness issues. These systems may\ninadvertently favor popular items, thereby marginalizing less popular ones and\ncompromising provider fairness. While previous research has recognized\nprovider-side fairness issues, the investigation into how these biases affect\nbeyond-accuracy aspects of recommendation systems - such as diversity, novelty,\ncoverage, and serendipity - has been less emphasized. In this paper, we address\nthis gap by introducing a simple yet effective post-processing re-ranking model\nthat prioritizes provider fairness, while simultaneously maintaining user\nrelevance and recommendation quality. We then conduct an in-depth evaluation of\nthe model's impact on various aspects of recommendation quality across multiple\ndatasets. Specifically, we apply the post-processing algorithm to four distinct\nrecommendation models across four varied domain datasets, assessing the\nimprovement in each metric, encompassing both accuracy and beyond-accuracy\naspects. This comprehensive analysis allows us to gauge the effectiveness of\nour approach in mitigating provider biases. Our findings underscore the\neffectiveness of the adopted method in improving provider fairness and\nrecommendation quality. They also provide valuable insights into the trade-offs\ninvolved in achieving fairness in recommender systems, contributing to a more\nnuanced understanding of this complex issue.",
        "translated": "推荐系统虽然在线用户体验方面具有变革性，但也引起了对潜在的供应方公平性问题的关注。这些系统可能会在不经意间偏袒受欢迎的产品，从而使不太受欢迎的产品边缘化，损害供应商的公平性。虽然以前的研究已经认识到了提供者方面的公平问题，但是对于这些偏见如何影响推荐系统的准确性以外的方面的调查——例如多样性、新颖性、覆盖面和意外发现——却没有得到足够的重视。在本文中，我们通过引入一个简单而有效的后处理重新排序模型来解决这一差距，该模型优先考虑提供者的公平性，同时保持用户相关性和推荐质量。然后，我们对模型在多个数据集中对推荐质量的各个方面的影响进行了深入的评估。具体而言，我们将后处理算法应用于四个不同领域数据集的四个不同的推荐模型，评估每个指标的改进，包括准确性和超准确性方面。这种全面的分析使我们能够衡量我们的方法在减轻提供者偏见方面的有效性。我们的研究结果强调了所采用的方法在提高提供者公平性和推荐质量方面的有效性。它们还为推荐系统实现公平所涉及的权衡提供了宝贵的见解，有助于对这一复杂问题有更加细致入微的理解。"
    },
    {
        "title": "Offline Recommender System Evaluation under Unobserved Confounding",
        "url": "http://arxiv.org/abs/2309.04222v1",
        "pub_date": "2023-09-08",
        "summary": "Off-Policy Estimation (OPE) methods allow us to learn and evaluate\ndecision-making policies from logged data. This makes them an attractive choice\nfor the offline evaluation of recommender systems, and several recent works\nhave reported successful adoption of OPE methods to this end. An important\nassumption that makes this work is the absence of unobserved confounders:\nrandom variables that influence both actions and rewards at data collection\ntime. Because the data collection policy is typically under the practitioner's\ncontrol, the unconfoundedness assumption is often left implicit, and its\nviolations are rarely dealt with in the existing literature.\n  This work aims to highlight the problems that arise when performing\noff-policy estimation in the presence of unobserved confounders, specifically\nfocusing on a recommendation use-case. We focus on policy-based estimators,\nwhere the logging propensities are learned from logged data. We characterise\nthe statistical bias that arises due to confounding, and show how existing\ndiagnostics are unable to uncover such cases. Because the bias depends directly\non the true and unobserved logging propensities, it is non-identifiable. As the\nunconfoundedness assumption is famously untestable, this becomes especially\nproblematic. This paper emphasises this common, yet often overlooked issue.\nThrough synthetic data, we empirically show how na\\\"ive propensity estimation\nunder confounding can lead to severely biased metric estimates that are allowed\nto fly under the radar. We aim to cultivate an awareness among researchers and\npractitioners of this important problem, and touch upon potential research\ndirections towards mitigating its effects.",
        "translated": "离线策略估计(Off-Policy Festival，OPE)方法允许我们从日志数据中学习和评估决策策略。这使它们成为离线评估推荐系统的一个有吸引力的选择，并且最近的一些工作报告了为此成功地采用了 OPE 方法。一个重要的假设，使这一工作是没有未观察到的混杂因素: 随机变量影响行动和奖励的数据收集时间。由于数据收集策略通常是在从业者的控制之下，不混淆假设往往是隐含的，其违反很少在现有的文献中处理。这项工作旨在强调在存在未观察到的混杂因素的情况下执行非策略估计时出现的问题，特别是关注建议用例。我们主要关注基于策略的估计器，其中从日志数据中学习日志倾向。我们描述了由于混淆而产生的统计偏差，并说明了现有的诊断方法是如何无法发现这些病例的。由于偏差直接取决于真实和未观察到的测井倾向，它是不可识别的。由于不混淆假设是出了名的不可检验，这变得特别成问题。这篇文章强调了这个常见的，但经常被忽视的问题。通过合成数据，我们经验性地说明了在混杂条件下的简单倾向估计是如何导致严重偏差的度量估计的，这些度量估计是允许在雷达下飞行的。我们的目标是培养研究人员和从业人员对这一重要问题的认识，并探讨减轻其影响的潜在研究方向。"
    },
    {
        "title": "Receiving an algorithmic recommendation based on documentary filmmaking\n  techniques",
        "url": "http://arxiv.org/abs/2309.04184v1",
        "pub_date": "2023-09-08",
        "summary": "This article analyzes the reception of a novel algorithmic recommendation of\ndocumentary films by a panel of moviegoers of the T{\\\"e}nk platform. In order\nto propose an alternative to recommendations based on a thematic\nclassification, the director or the production period, a set of metadata has\nbeen elaborated within the framework of this experimentation in order to\ncharacterize the great variety of ``documentary filmmaking dispositifs'' . The\ngoal is to investigate the different ways in which the platform's film lovers\nappropriate a personalized recommendation of 4 documentaries with similar or\nsimilar filmmaking dispositifs. To conclude, the contributions and limits of\nthis proof of concept are discussed in order to sketch out avenues of\nreflection for improving the instrumented mediation of documentary films.",
        "translated": "本文分析了一个新的算法推荐的接收纪录片的电影观众小组的 T {“ e } nk 平台。为了提出一个基于主题分类、导演或制作时期的建议的替代方案，在这个实验的框架内制定了一套元数据，以描述各种各样的“纪录片制作材料”。我们的目标是调查平台的电影爱好者使用不同的方式来适应个性化推荐的4部具有相似或类似电影制作配置的纪录片。最后，本文讨论了这一概念证明的贡献和局限性，以便为完善纪录片的工具性中介提供思考的途径。"
    },
    {
        "title": "A Long-Tail Friendly Representation Framework for Artist and Music\n  Similarity",
        "url": "http://arxiv.org/abs/2309.04182v1",
        "pub_date": "2023-09-08",
        "summary": "The investigation of the similarity between artists and music is crucial in\nmusic retrieval and recommendation, and addressing the challenge of the\nlong-tail phenomenon is increasingly important. This paper proposes a Long-Tail\nFriendly Representation Framework (LTFRF) that utilizes neural networks to\nmodel the similarity relationship. Our approach integrates music, user,\nmetadata, and relationship data into a unified metric learning framework, and\nemploys a meta-consistency relationship as a regular term to introduce the\nMulti-Relationship Loss. Compared to the Graph Neural Network (GNN), our\nproposed framework improves the representation performance in long-tail\nscenarios, which are characterized by sparse relationships between artists and\nmusic. We conduct experiments and analysis on the AllMusic dataset, and the\nresults demonstrate that our framework provides a favorable generalization of\nartist and music representation. Specifically, on similar artist/music\nrecommendation tasks, the LTFRF outperforms the baseline by 9.69%/19.42% in Hit\nRatio@10, and in long-tail cases, the framework achieves 11.05%/14.14% higher\nthan the baseline in Consistent@10.",
        "translated": "研究艺术家与音乐之间的相似性在音乐检索和推荐中至关重要，解决长尾现象带来的挑战越来越重要。提出了一种利用神经网络建立相似关系模型的长尾友好表示框架(LTFRF)。我们的方法将音乐、用户、元数据和关系数据集成到一个统一的度量学习框架中，并使用元一致性关系作为引入多关系丢失的常规术语。与图形神经网络(GNN)相比，我们提出的框架提高了长尾场景的表现性能，这种场景是艺术家和音乐之间的稀疏关系的拥有属性。我们对 AllMusic 数据集进行了实验和分析，结果表明我们的框架提供了一个良好的艺术家和音乐表示的一般化。具体来说，在类似的艺术家/音乐推荐任务中，LTFRF 在点击率为10的情况下比基准高出9.69%/19.42% ，在长尾情况下，该框架比基准的一致性为10的情况下高出11.05%/14.14% 。"
    },
    {
        "title": "PRISTA-Net: Deep Iterative Shrinkage Thresholding Network for Coded\n  Diffraction Patterns Phase Retrieval",
        "url": "http://arxiv.org/abs/2309.04171v1",
        "pub_date": "2023-09-08",
        "summary": "The problem of phase retrieval (PR) involves recovering an unknown image from\nlimited amplitude measurement data and is a challenge nonlinear inverse problem\nin computational imaging and image processing. However, many of the PR methods\nare based on black-box network models that lack interpretability and\nplug-and-play (PnP) frameworks that are computationally complex and require\ncareful parameter tuning. To address this, we have developed PRISTA-Net, a deep\nunfolding network (DUN) based on the first-order iterative shrinkage\nthresholding algorithm (ISTA). This network utilizes a learnable nonlinear\ntransformation to address the proximal-point mapping sub-problem associated\nwith the sparse priors, and an attention mechanism to focus on phase\ninformation containing image edges, textures, and structures. Additionally, the\nfast Fourier transform (FFT) is used to learn global features to enhance local\ninformation, and the designed logarithmic-based loss function leads to\nsignificant improvements when the noise level is low. All parameters in the\nproposed PRISTA-Net framework, including the nonlinear transformation,\nthreshold parameters, and step size, are learned end-to-end instead of being\nmanually set. This method combines the interpretability of traditional methods\nwith the fast inference ability of deep learning and is able to handle noise at\neach iteration during the unfolding stage, thus improving recovery quality.\nExperiments on Coded Diffraction Patterns (CDPs) measurements demonstrate that\nour approach outperforms the existing state-of-the-art methods in terms of\nqualitative and quantitative evaluations. Our source codes are available at\n\\emph{https://github.com/liuaxou/PRISTA-Net}.",
        "translated": "相位恢复问题涉及到从有限幅度的测量数据中恢复未知图像，是计算成像和图像处理中的一个具有挑战性的非线性反问题。然而，许多 PR 方法是基于缺乏可解释性的黑盒网络模型和即插即用(PnP)框架，这些框架计算复杂，需要仔细的参数调整。为了解决这个问题，我们开发了 PRISTA-Net，一个基于一阶迭代收缩阈值算法(ISTA)的深层展开网络(DUN)。该网络利用可学习的非线性变换来解决与稀疏先验相关的近似点映射子问题，并利用注意力机制来关注包含图像边缘、纹理和结构的相位信息。此外，快速傅里叶变换(FFT)用于学习全局特征以增强局部信息，而设计的基于对数的损耗函数在噪声水平较低时有显著改善。所提出的 PRISTA-Net 框架中的所有参数，包括非线性变换、阈值参数和步长，都是端到端学习的，而不需要手动设置。该方法结合了传统方法的可解释性和深度学习的快速推理能力，能够在展开阶段处理每次迭代中的噪声，从而提高恢复质量。对编码衍射模式(CDP)测量的实验表明，我们的方法在定性和定量评价方面优于现有的最先进的方法。我们的源代码可以在 emph { https://github.com/liuaxou/prista-net }找到。"
    },
    {
        "title": "Measuring and Improving Chain-of-Thought Reasoning in Vision-Language\n  Models",
        "url": "http://arxiv.org/abs/2309.04461v1",
        "pub_date": "2023-09-08",
        "summary": "Vision-language models (VLMs) have recently demonstrated strong efficacy as\nvisual assistants that can parse natural queries about the visual content and\ngenerate human-like outputs. In this work, we explore the ability of these\nmodels to demonstrate human-like reasoning based on the perceived information.\nTo address a crucial concern regarding the extent to which their reasoning\ncapabilities are fully consistent and grounded, we also measure the reasoning\nconsistency of these models. We achieve this by proposing a chain-of-thought\n(CoT) based consistency measure. However, such an evaluation requires a\nbenchmark that encompasses both high-level inference and detailed reasoning\nchains, which is costly. We tackle this challenge by proposing a\nLLM-Human-in-the-Loop pipeline, which notably reduces cost while simultaneously\nensuring the generation of a high-quality dataset. Based on this pipeline and\nthe existing coarse-grained annotated dataset, we build the CURE benchmark to\nmeasure both the zero-shot reasoning performance and consistency of VLMs. We\nevaluate existing state-of-the-art VLMs, and find that even the best-performing\nmodel is unable to demonstrate strong visual reasoning capabilities and\nconsistency, indicating that substantial efforts are required to enable VLMs to\nperform visual reasoning as systematically and consistently as humans. As an\nearly step, we propose a two-stage training framework aimed at improving both\nthe reasoning performance and consistency of VLMs. The first stage involves\nemploying supervised fine-tuning of VLMs using step-by-step reasoning samples\nautomatically generated by LLMs. In the second stage, we further augment the\ntraining process by incorporating feedback provided by LLMs to produce\nreasoning chains that are highly consistent and grounded. We empirically\nhighlight the effectiveness of our framework in both reasoning performance and\nconsistency.",
        "translated": "视觉语言模型(VLM)作为视觉辅助工具，能够解析有关视觉内容的自然查询并产生类似于人类的输出，近年来已经显示出强大的功效。在这项工作中，我们探讨了这些模型的能力，证明类人推理的基础上的感知信息。为了解决关于他们的推理能力在多大程度上是完全一致和基础的关键问题，我们还测量了这些模型的推理一致性。我们通过提出一个基于思想链(CoT)的一致性度量来实现这一点。然而，这样的评估需要一个基准，包括高级推理和详细推理链，这是昂贵的。我们通过提出一个 LLM-Human-in-the-Loop 流水线来解决这个挑战，它显著地降低了成本，同时确保生成高质量的数据集。基于这个流水线和现有的粗粒度注释数据集，我们构建了 CURE 基准测试来度量 VLM 的零镜头推理性能和一致性。我们评估了现有的最先进的 VLM，发现即使是表现最好的模型也无法证明强大的视觉推理能力和一致性，这表明需要大量的努力才能使 VLM 像人类一样系统和一致地执行视觉推理。作为第一步，我们提出了一个两阶段的训练框架，旨在提高 VLM 的推理性能和一致性。第一阶段涉及使用监督微调的 VLM 使用一步一步的推理样本自动生成的 LLM。在第二阶段，我们进一步加强训练过程，通过合并 LLM 提供的反馈来产生高度一致和基础的推理链。我们从经验上强调了我们的框架在推理性能和一致性方面的有效性。"
    },
    {
        "title": "CSPRD: A Financial Policy Retrieval Dataset for Chinese Stock Market",
        "url": "http://arxiv.org/abs/2309.04389v1",
        "pub_date": "2023-09-08",
        "summary": "In recent years, great advances in pre-trained language models (PLMs) have\nsparked considerable research focus and achieved promising performance on the\napproach of dense passage retrieval, which aims at retrieving relative passages\nfrom massive corpus with given questions. However, most of existing datasets\nmainly benchmark the models with factoid queries of general commonsense, while\nspecialised fields such as finance and economics remain unexplored due to the\ndeficiency of large-scale and high-quality datasets with expert annotations. In\nthis work, we propose a new task, policy retrieval, by introducing the Chinese\nStock Policy Retrieval Dataset (CSPRD), which provides 700+ prospectus passages\nlabeled by experienced experts with relevant articles from 10k+ entries in our\ncollected Chinese policy corpus. Experiments on lexical, embedding and\nfine-tuned bi-encoder models show the effectiveness of our proposed CSPRD yet\nalso suggests ample potential for improvement. Our best performing baseline\nachieves 56.1% MRR@10, 28.5% NDCG@10, 37.5% Recall@10 and 80.6% Precision@10 on\ndev set.",
        "translated": "近年来，预训练语言模型(PLM)在密文检索方面取得了很大的进展，在密文检索方面取得了令人瞩目的成绩。然而，现有的大多数数据集主要以一般常识的事实性查询作为模型的基准，而由于缺乏具有专家注释的大规模和高质量数据集，金融和经济等专业领域仍然未被探索。在这项工作中，我们提出了一个新的任务，政策检索，通过引入中国股票政策检索数据集(CSPRD) ，该数据集提供了700多个由经验丰富的专家标记的招股说明书段落和我们收集的中国政策语料库中10k + 条目的相关文章。在词法，嵌入和微调双编码器模型的实验表明，我们提出的 CSPRD 的有效性，但也提出了充分的改进潜力。我们最好的基准在开发设备上达到56.1% MRR@10,28.5% NDCG@10,37.5% Recall@10和80.6% Precision@10。"
    },
    {
        "title": "MoEController: Instruction-based Arbitrary Image Manipulation with\n  Mixture-of-Expert Controllers",
        "url": "http://arxiv.org/abs/2309.04372v1",
        "pub_date": "2023-09-08",
        "summary": "Diffusion-model-based text-guided image generation has recently made\nastounding progress, producing fascinating results in open-domain image\nmanipulation tasks. Few models, however, currently have complete zero-shot\ncapabilities for both global and local image editing due to the complexity and\ndiversity of image manipulation tasks. In this work, we propose a method with a\nmixture-of-expert (MOE) controllers to align the text-guided capacity of\ndiffusion models with different kinds of human instructions, enabling our model\nto handle various open-domain image manipulation tasks with natural language\ninstructions. First, we use large language models (ChatGPT) and conditional\nimage synthesis models (ControlNet) to generate a large number of global image\ntransfer dataset in addition to the instruction-based local image editing\ndataset. Then, using an MOE technique and task-specific adaptation training on\na large-scale dataset, our conditional diffusion model can edit images globally\nand locally. Extensive experiments demonstrate that our approach performs\nsurprisingly well on various image manipulation tasks when dealing with\nopen-domain images and arbitrary human instructions. Please refer to our\nproject page: [https://oppo-mente-lab.github.io/moe_controller/]",
        "translated": "基于扩散模型的文本引导图像生成技术近年来取得了惊人的进展，在开放领域的图像处理任务中取得了令人瞩目的成果。然而，由于图像处理任务的复杂性和多样性，目前很少有模型具有全局和局部图像编辑的完全零拍摄能力。本文提出了一种基于混合专家(MOE)控制器的扩散模型文本引导能力与不同人工指令的匹配方法，使模型能够用自然语言指令处理各种开放领域的图像处理任务。首先，我们使用大语言模型(ChatGPT)和条件图像合成模型(ControlNet)来生成大量的全局图像传输数据集，以及基于指令的局部图像编辑数据集。然后，使用 MOE 技术和针对大规模数据集的任务特定适应训练，我们的条件扩散模型可以对图像进行全局和局部编辑。大量的实验表明，在处理开放域图像和任意人工指令时，我们的方法在各种图像处理任务中表现出令人惊讶的良好性能。请参阅我们的专题网页: [ https://oppo-mente-lab.github.io/moe_controller/]"
    },
    {
        "title": "Beyond Static Datasets: A Deep Interaction Approach to LLM Evaluation",
        "url": "http://arxiv.org/abs/2309.04369v1",
        "pub_date": "2023-09-08",
        "summary": "Large Language Models (LLMs) have made progress in various real-world tasks,\nwhich stimulates requirements for the evaluation of LLMs. Existing LLM\nevaluation methods are mainly supervised signal-based which depends on static\ndatasets and cannot evaluate the ability of LLMs in dynamic real-world\nscenarios where deep interaction widely exists. Other LLM evaluation methods\nare human-based which are costly and time-consuming and are incapable of\nlarge-scale evaluation of LLMs. To address the issues above, we propose a novel\nDeep Interaction-based LLM-evaluation framework. In our proposed framework,\nLLMs' performances in real-world domains can be evaluated from their deep\ninteraction with other LLMs in elaborately designed evaluation tasks.\nFurthermore, our proposed framework is a general evaluation method that can be\napplied to a host of real-world tasks such as machine translation and code\ngeneration. We demonstrate the effectiveness of our proposed method through\nextensive experiments on four elaborately designed evaluation tasks.",
        "translated": "大型语言模型(LLM)已经在各种现实世界的任务中取得了进展，这刺激了对 LLM 的评估需求。现有的 LLM 评价方法主要是基于监督信号的，依赖于静态数据集，不能评价 LLM 在广泛存在深度交互的动态现实场景中的能力。其他 LLM 评价方法是以人为本的，费时费钱，不能对 LLM 进行大规模的评价。为了解决上述问题，我们提出了一种新的基于深度交互的 LLM 评估框架。在我们提出的框架中，在精心设计的评估任务中，LLM 可以通过与其他 LLM 的深度交互来评估它们在现实世界中的表现。此外，我们提出的框架是一个通用的评估方法，可以应用于一系列的现实世界的任务，如机器翻译和代码生成。通过对四个精心设计的评估任务的大量实验，验证了该方法的有效性。"
    },
    {
        "title": "Encoding Multi-Domain Scientific Papers by Ensembling Multiple CLS\n  Tokens",
        "url": "http://arxiv.org/abs/2309.04333v1",
        "pub_date": "2023-09-08",
        "summary": "Many useful tasks on scientific documents, such as topic classification and\ncitation prediction, involve corpora that span multiple scientific domains.\nTypically, such tasks are accomplished by representing the text with a vector\nembedding obtained from a Transformer's single CLS token. In this paper, we\nargue that using multiple CLS tokens could make a Transformer better specialize\nto multiple scientific domains. We present Multi2SPE: it encourages each of\nmultiple CLS tokens to learn diverse ways of aggregating token embeddings, then\nsums them up together to create a single vector representation. We also propose\nour new multi-domain benchmark, Multi-SciDocs, to test scientific paper vector\nencoders under multi-domain settings. We show that Multi2SPE reduces error by\nup to 25 percent in multi-domain citation prediction, while requiring only a\nnegligible amount of computation in addition to one BERT forward pass.",
        "translated": "科学文献的许多有用的任务，如主题分类和引文预测，涉及跨越多个科学领域的语料库。通常，这些任务是通过使用从 Transformer 的单个 CLS 标记获得的向量嵌入来表示文本来完成的。在本文中，我们认为使用多个 CLS 令牌可以使一个 Transformer 更好地专用于多个科学领域。我们介绍 Multi2SPE: 它鼓励多个 CLS 令牌中的每一个学习聚合令牌嵌入的不同方法，然后将它们总结在一起以创建单个向量表示。我们还提出了新的多领域基准，Multi-SciDocs，用于在多领域设置下测试科学论文矢量编码器。我们表明 Multi2SPE 在多域引文预测中减少了高达25% 的误差，而且除了一个 BERT 前向通道外只需要可以忽略不计的计算量。"
    },
    {
        "title": "Fuzzy Fingerprinting Transformer Language-Models for Emotion Recognition\n  in Conversations",
        "url": "http://arxiv.org/abs/2309.04292v1",
        "pub_date": "2023-09-08",
        "summary": "Fuzzy Fingerprints have been successfully used as an interpretable text\nclassification technique, but, like most other techniques, have been largely\nsurpassed in performance by Large Pre-trained Language Models, such as BERT or\nRoBERTa. These models deliver state-of-the-art results in several Natural\nLanguage Processing tasks, namely Emotion Recognition in Conversations (ERC),\nbut suffer from the lack of interpretability and explainability. In this paper,\nwe propose to combine the two approaches to perform ERC, as a means to obtain\nsimpler and more interpretable Large Language Models-based classifiers. We\npropose to feed the utterances and their previous conversational turns to a\npre-trained RoBERTa, obtaining contextual embedding utterance representations,\nthat are then supplied to an adapted Fuzzy Fingerprint classification module.\nWe validate our approach on the widely used DailyDialog ERC benchmark dataset,\nin which we obtain state-of-the-art level results using a much lighter model.",
        "translated": "模糊指纹作为一种可解释的文本分类技术已经得到了成功的应用，但是与其他大多数技术一样，它在性能上已经被大型预训练语言模型(BERT 或 RoBERTa)所超越。这些模型在几个自然语言处理任务中提供了最先进的结果，即会话中的情绪识别(ERC) ，但缺乏可解释性和可解释性。本文提出将这两种方法结合起来实现 ERC，以获得更简单、更易于解释的基于大语言模型的分类器。我们提出将话语和它们之前的会话转向提供给一个预先训练好的 RoBERTa，获得上下文嵌入的话语表示，然后提供给一个自适应的模糊指纹分类模块。我们在广泛使用的 DailyDialog ERC 基准数据集上验证了我们的方法，在该数据集中，我们使用更轻量级的模型获得了最先进的结果。"
    },
    {
        "title": "From Sparse to Dense: GPT-4 Summarization with Chain of Density\n  Prompting",
        "url": "http://arxiv.org/abs/2309.04269v1",
        "pub_date": "2023-09-08",
        "summary": "Selecting the ``right'' amount of information to include in a summary is a\ndifficult task. A good summary should be detailed and entity-centric without\nbeing overly dense and hard to follow. To better understand this tradeoff, we\nsolicit increasingly dense GPT-4 summaries with what we refer to as a ``Chain\nof Density'' (CoD) prompt. Specifically, GPT-4 generates an initial\nentity-sparse summary before iteratively incorporating missing salient entities\nwithout increasing the length. Summaries generated by CoD are more abstractive,\nexhibit more fusion, and have less of a lead bias than GPT-4 summaries\ngenerated by a vanilla prompt. We conduct a human preference study on 100 CNN\nDailyMail articles and find that that humans prefer GPT-4 summaries that are\nmore dense than those generated by a vanilla prompt and almost as dense as\nhuman written summaries. Qualitative analysis supports the notion that there\nexists a tradeoff between informativeness and readability. 500 annotated CoD\nsummaries, as well as an extra 5,000 unannotated summaries, are freely\navailable on HuggingFace\n(https://huggingface.co/datasets/griffin/chain_of_density).",
        "translated": "选择要包含在摘要中的“正确”数量的信息是一项困难的任务。一个好的总结应该是详细的和以实体为中心的，而不是过于密集和难以遵循。为了更好地理解这种权衡，我们通过我们称为“密度链”(CoD)提示征求越来越密集的 GPT-4摘要。具体来说，GPT-4在迭代合并缺失的显著实体而不增加长度之前，生成一个初始实体稀疏摘要。由 CoD 生成的摘要比普通提示生成的 GPT-4摘要更抽象，表现出更多的融合，并且具有更少的先导偏差。我们对100篇 CNN 每日邮报的文章进行了人类偏好研究，发现人类更喜欢 GPT-4摘要，这些摘要比香草提示生成的摘要更密集，几乎与人类书面摘要一样密集。定性分析支持在信息性和可读性之间存在权衡的观点。500个带注释的 CoD 摘要，以及另外5000个未带注释的摘要，都可以在 HuggingFace ( https://HuggingFace.co/datasets/griffin/chain_of_density )上免费获得。"
    },
    {
        "title": "UQ at #SMM4H 2023: ALEX for Public Health Analysis with Social Media",
        "url": "http://arxiv.org/abs/2309.04213v1",
        "pub_date": "2023-09-08",
        "summary": "As social media becomes increasingly popular, more and more activities\nrelated to public health emerge. Current techniques for public health analysis\ninvolve popular models such as BERT and large language models (LLMs). However,\nthe costs of training in-domain LLMs for public health are especially\nexpensive. Furthermore, such kinds of in-domain datasets from social media are\ngenerally imbalanced. To tackle these challenges, the data imbalance issue can\nbe overcome by data augmentation and balanced training. Moreover, the ability\nof the LLMs can be effectively utilized by prompting the model properly. In\nthis paper, a novel ALEX framework is proposed to improve the performance of\npublic health analysis on social media by adopting an LLMs explanation\nmechanism. Results show that our ALEX model got the best performance among all\nsubmissions in both Task 2 and Task 4 with a high score in Task 1 in Social\nMedia Mining for Health 2023 (SMM4H)[1]. Our code has been released at https://\ngithub.com/YanJiangJerry/ALEX.",
        "translated": "随着社交媒体的日益普及，与公共卫生相关的活动越来越多。目前公共卫生分析的技术包括诸如 BERT 和大语言模型(LLM)等流行模型。然而，为公共卫生培训领域内的 LLM 的费用特别昂贵。此外，来自社交媒体的这类域内数据集通常是不平衡的。为了应对这些挑战，数据不平衡问题可以通过数据增强和平衡训练来克服。此外，通过适当地提示模型，可以有效地利用 LLM 的能力。本文提出了一种新的 ALEX 框架，通过引入 LLM 解释机制来提高社交媒体上公共卫生分析的性能。结果表明，我们的 ALEX 模型在任务2和任务4的所有提交中获得了最好的表现，在健康社会媒体挖掘2023(SMM4H)的任务1中获得了高分[1]。我们的代码已经在 https:// github.com/yanjiangjerry/alex 发布。"
    },
    {
        "title": "The CALLA Dataset: Probing LLMs' Interactive Knowledge Acquisition from\n  Chinese Medical Literature",
        "url": "http://arxiv.org/abs/2309.04198v1",
        "pub_date": "2023-09-08",
        "summary": "The application of Large Language Models (LLMs) to the medical domain has\nstimulated the interest of researchers. Recent studies have focused on\nconstructing Instruction Fine-Tuning (IFT) data through medical knowledge\ngraphs to enrich the interactive medical knowledge of LLMs. However, the\nmedical literature serving as a rich source of medical knowledge remains\nunexplored. Our work introduces the CALLA dataset to probe LLMs' interactive\nknowledge acquisition from Chinese medical literature. It assesses the\nproficiency of LLMs in mastering medical knowledge through a free-dialogue\nfact-checking task. We identify a phenomenon called the ``fact-following\nresponse``, where LLMs tend to affirm facts mentioned in questions and display\na reluctance to challenge them. To eliminate the inaccurate evaluation caused\nby this phenomenon, for the golden fact, we artificially construct test data\nfrom two perspectives: one consistent with the fact and one inconsistent with\nthe fact. Drawing from the probing experiment on the CALLA dataset, we conclude\nthat IFT data highly correlated with the medical literature corpus serves as a\npotent catalyst for LLMs, enabling themselves to skillfully employ the medical\nknowledge acquired during the pre-training phase within interactive scenarios,\nenhancing accuracy. Furthermore, we design a framework for automatically\nconstructing IFT data based on medical literature and discuss some real-world\napplications.",
        "translated": "大语言模型(LLM)在医学领域的应用激发了研究人员的兴趣。最近的研究集中在通过医学知识图构建教学微调(IFT)数据，以丰富 LLM 的交互式医学知识。然而，作为医学知识的丰富来源的医学文献仍然没有被探索。本研究引入 CALLA 数据集，探讨 LLM 在中国医学文献中的交互式知识获取。它通过一个自由对话的事实核查任务来评估法学硕士掌握医学知识的熟练程度。我们发现了一种被称为“事实跟踪反应”的现象，即 LLM 倾向于确认问题中提到的事实，并表现出不愿质疑它们的态度。为了消除这种现象造成的不准确评价，对于黄金事实，我们人为地从两个角度构建测试数据: 一个与事实一致，一个与事实不一致。从 CALLA 数据集的探索性实验中，我们得出结论: 与医学文献语料库高度相关的 IFT 数据是 LLM 的有力催化剂，使他们能够在交互式场景中巧妙地利用培训前阶段获得的医学知识，提高准确性。此外，我们还设计了一个基于医学文献自动构建 IFT 数据的框架，并讨论了一些实际应用。"
    },
    {
        "title": "Knowledge-tuning Large Language Models with Structured Medical Knowledge\n  Bases for Reliable Response Generation in Chinese",
        "url": "http://arxiv.org/abs/2309.04175v1",
        "pub_date": "2023-09-08",
        "summary": "Large Language Models (LLMs) have demonstrated remarkable success in diverse\nnatural language processing (NLP) tasks in general domains. However, LLMs\nsometimes generate responses with the hallucination about medical facts due to\nlimited domain knowledge. Such shortcomings pose potential risks in the\nutilization of LLMs within medical contexts. To address this challenge, we\npropose knowledge-tuning, which leverages structured medical knowledge bases\nfor the LLMs to grasp domain knowledge efficiently and facilitate reliable\nresponse generation. We also release cMedKnowQA, a Chinese medical knowledge\nquestion-answering dataset constructed from medical knowledge bases to assess\nthe medical knowledge proficiency of LLMs. Experimental results show that the\nLLMs which are knowledge-tuned with cMedKnowQA, can exhibit higher levels of\naccuracy in response generation compared with vanilla instruction-tuning and\noffer a new reliable way for the domain adaptation of LLMs.",
        "translated": "大语言模型(LLM)在一般领域的多种自然语言处理(NLP)任务中取得了显著的成功。然而，由于领域知识有限，LLM 有时会产生对医学事实的幻觉。这些缺点对在医疗环境中使用 LLM 构成潜在风险。为了应对这一挑战，我们提出了知识调整，它利用结构化医学知识库的 LLM 有效地掌握领域知识，并促进可靠的反应生成。我们还发布了 cMedKnowQA，这是一个由医学知识库构建的中文医学知识问答数据集，用于评估 LLM 的医学知识水平。实验结果表明，采用 cMedKnowQA 进行知识调优的 LLM 在响应生成方面比传统的指令调优方法具有更高的准确性，为 LLM 的领域适应提供了一种新的可靠的方法。"
    },
    {
        "title": "D2WFP: A Novel Protocol for Forensically Identifying, Extracting, and\n  Analysing Deep and Dark Web Browsing Activities",
        "url": "http://arxiv.org/abs/2309.05537v1",
        "pub_date": "2023-09-11",
        "summary": "The use of the un-indexed web, commonly known as the deep web and dark web,\nto commit or facilitate criminal activity has drastically increased over the\npast decade. The dark web is an in-famously dangerous place where all kinds of\ncriminal activities take place [1-2], despite advances in web forensics\ntechniques, tools, and methodologies, few studies have formally tackled the\ndark and deep web forensics and the technical differences in terms of\ninvestigative techniques and artefacts identification and extraction. This\nresearch proposes a novel and comprehensive protocol to guide and assist\ndigital forensics professionals in investigating crimes committed on or via the\ndeep and dark web, The protocol named D2WFP establishes a new sequential\napproach for performing investigative activities by observing the order of\nvolatility and implementing a systemic approach covering all browsing related\nhives and artefacts which ultimately resulted into improv-ing the accuracy and\neffectiveness. Rigorous quantitative and qualitative research has been\nconducted by assessing D2WFP following a scientifically-sound and comprehensive\nprocess in different scenarios and the obtained results show an apparent\nincrease in the number of artefacts re-covered when adopting D2WFP which\noutperform any current industry or opensource browsing forensics tools. The\nsecond contribution of D2WFP is the robust formulation of artefact correlation\nand cross-validation within D2WFP which enables digital forensics professionals\nto better document and structure their analysis of host-based deep and dark web\nbrowsing artefacts.",
        "translated": "在过去十年中，使用未编制索引的网络(通常称为深网和暗网)从事或协助犯罪活动的情况急剧增加。尽管网络取证技术、工具和方法取得了进步，但很少有研究正式解决黑暗和深度网络取证以及在调查技术和人工物品识别和提取方面的技术差异。这项研究提出了一个新颖而全面的协议，以指导和协助数位鑑识专业人员调查犯罪或通过深和暗网，该协议命名为 D2粮食计划署建立了一个新的顺序方法进行调查活动，通过观察波动的顺序和实施一个系统的方法，涵盖所有浏览相关的蜂巢和人工制品，最终导致提高准确性和有效性。通过在不同情景下采用科学合理和全面的过程对 D2WFP 进行严格的定量和质性研究评估，得到的结果显示，在采用比当前任何行业或开源浏览取证工具表现更好的 D2WFP 时，发现的文物数量明显增加。D2WFP 的第二个贡献是在 D2WFP 内部对人工制品的相关性和交叉验证进行了有力的描述，这使得数位鑑识专业人员能够更好地记录和构建他们对基于主机的深度和暗度网络浏览人工制品的分析。"
    },
    {
        "title": "Re-formalization of Individual Fairness",
        "url": "http://arxiv.org/abs/2309.05521v1",
        "pub_date": "2023-09-11",
        "summary": "The notion of individual fairness is a formalization of an ethical principle,\n\"Treating like cases alike,\" which has been argued such as by Aristotle. In a\nfairness-aware machine learning context, Dwork et al. firstly formalized the\nnotion. In their formalization, a similar pair of data in an unfair space\nshould be mapped to similar positions in a fair space. We propose to\nre-formalize individual fairness by the statistical independence conditioned by\nindividuals. This re-formalization has the following merits. First, our\nformalization is compatible with that of Dwork et al. Second, our formalization\nenables to combine individual fairness with the fairness notion, equalized odds\nor sufficiency, as well as statistical parity. Third, though their\nformalization implicitly assumes a pre-process approach for making fair\nprediction, our formalization is applicable to an in-process or post-process\napproach.",
        "translated": "个人公平的概念是道德原则的形式化，“像对待案件一样对待案件”，这已经被亚里士多德论证过。在公平感知的机器学习环境中，Dwork 等人首先形式化了这个概念。在形式化过程中，不公平空间中的相似对数据应该映射到公平空间中的相似位置。我们提出以个体为条件的统计独立性来重新形式化个体公平。这种重新形式化有以下优点。首先，我们的形式化与 Dwork 等人的形式化是兼容的。其次，我们的形式化能够将个体公平性与公平概念、均衡优势或充分性以及统计平价结合起来。第三，虽然它们的形式化隐含地假定了一种预处理方法来做出公平的预测，但是我们的形式化适用于处理中或处理后的方法。"
    },
    {
        "title": "Towards Content-based Pixel Retrieval in Revisited Oxford and Paris",
        "url": "http://arxiv.org/abs/2309.05438v1",
        "pub_date": "2023-09-11",
        "summary": "This paper introduces the first two pixel retrieval benchmarks. Pixel\nretrieval is segmented instance retrieval. Like semantic segmentation extends\nclassification to the pixel level, pixel retrieval is an extension of image\nretrieval and offers information about which pixels are related to the query\nobject. In addition to retrieving images for the given query, it helps users\nquickly identify the query object in true positive images and exclude false\npositive images by denoting the correlated pixels. Our user study results show\npixel-level annotation can significantly improve the user experience.\n  Compared with semantic and instance segmentation, pixel retrieval requires a\nfine-grained recognition capability for variable-granularity targets. To this\nend, we propose pixel retrieval benchmarks named PROxford and PRParis, which\nare based on the widely used image retrieval datasets, ROxford and RParis.\nThree professional annotators label 5,942 images with two rounds of\ndouble-checking and refinement. Furthermore, we conduct extensive experiments\nand analysis on the SOTA methods in image search, image matching, detection,\nsegmentation, and dense matching using our pixel retrieval benchmarks. Results\nshow that the pixel retrieval task is challenging to these approaches and\ndistinctive from existing problems, suggesting that further research can\nadvance the content-based pixel-retrieval and thus user search experience. The\ndatasets can be downloaded from\n\\href{https://github.com/anguoyuan/Pixel_retrieval-Segmented_instance_retrieval}{this\nlink}.",
        "translated": "本文介绍了前两个像素检索基准。像素检索是分段实例检索。像语义分割将分类扩展到像素级一样，像素检索是图像检索的一个扩展，提供关于哪些像素与查询对象相关的信息。除了为给定的查询检索图像，它帮助用户快速识别查询对象的真正正面图像和排除假正面图像通过表示相关的像素。我们的用户研究结果显示像素级注释可以显著改善用户体验。与语义分割和实例分割相比，像素检索需要对变粒度目标进行细粒度识别。为此，我们提出了基于广泛使用的图像检索数据集 ROxford 和 RParis 的像素检索基准 PROxford 和 PRParis。三位专业的注释人员对5942幅图像进行了两轮复核和细化。在此基础上，利用我们的像素检索基准对 SOTA 方法在图像搜索、图像匹配、检测、分割和密集匹配方面进行了广泛的实验和分析。结果表明，像素检索任务对这些方法具有挑战性，并且与现有的问题有所区别，表明进一步的研究可以提高基于内容的像素检索，从而提高用户的搜索体验。数据集可以从 href { https://github.com/anguoyuan/pixel_retrieval-segmented_instance_retrieval }{ this link }下载。"
    },
    {
        "title": "Formalizing Multimedia Recommendation through Multimodal Deep Learning",
        "url": "http://arxiv.org/abs/2309.05273v1",
        "pub_date": "2023-09-11",
        "summary": "Recommender systems (RSs) offer personalized navigation experiences on online\nplatforms, but recommendation remains a challenging task, particularly in\nspecific scenarios and domains. Multimodality can help tap into richer\ninformation sources and construct more refined user/item profiles for\nrecommendations. However, existing literature lacks a shared and universal\nschema for modeling and solving the recommendation problem through the lens of\nmultimodality. This work aims to formalize a general multimodal schema for\nmultimedia recommendation. It provides a comprehensive literature review of\nmultimodal approaches for multimedia recommendation from the last eight years,\noutlines the theoretical foundations of a multimodal pipeline, and demonstrates\nits rationale by applying it to selected state-of-the-art approaches. The work\nalso conducts a benchmarking analysis of recent algorithms for multimedia\nrecommendation within Elliot, a rigorous framework for evaluating recommender\nsystems. The main aim is to provide guidelines for designing and implementing\nthe next generation of multimodal approaches in multimedia recommendation.",
        "translated": "推荐系统(RS)在在线平台上提供个性化的导航体验，但是推荐仍然是一个具有挑战性的任务，特别是在特定的场景和领域。多模式可以帮助挖掘更丰富的信息来源，并为推荐建立更精确的用户/项目配置文件。然而，现有的文献缺乏一个共享和通用的模式来建模和解决推荐问题的多模态的镜头。这项工作的目的是形式化的一般多模式模式的多媒体推荐。它提供了过去八年来多模式多媒体推荐方法的综合文献回顾，概述了多模式管道的理论基础，并通过将其应用于选定的最新方法来论证其理论基础。这项工作还对 Elliot 中的多媒体推荐算法进行了基准分析，Elliot 是一个评估推荐系统的严格框架。主要目的是为设计和实施下一代多媒体推荐多模式方法提供指导。"
    },
    {
        "title": "Generating Natural Language Queries for More Effective Systematic Review\n  Screening Prioritisation",
        "url": "http://arxiv.org/abs/2309.05238v1",
        "pub_date": "2023-09-11",
        "summary": "Screening prioritisation in medical systematic reviews aims to rank the set\nof documents retrieved by complex Boolean queries. The goal is to prioritise\nthe most important documents so that subsequent review steps can be carried out\nmore efficiently and effectively. The current state of the art uses the final\ntitle of the review to rank documents using BERT-based neural neural rankers.\nHowever, the final title is only formulated at the end of the review process,\nwhich makes this approach impractical as it relies on ex post facto\ninformation. At the time of screening, only a rough working title is available,\nwith which the BERT-based ranker achieves is significantly worse than the final\ntitle. In this paper, we explore alternative sources of queries for screening\nprioritisation, such as the Boolean query used to retrieve the set of documents\nto be screened, and queries generated by instruction-based generative large\nlanguage models such as ChatGPT and Alpaca. Our best approach is not only\npractical based on the information available at screening time, but is similar\nin effectiveness with the final title.",
        "translated": "在医学系统评价中，筛选优先级的目的是对复杂布尔查询检索到的文档集进行排序。目标是确定最重要文件的优先次序，以便以后的审查步骤能够更有效率和效力地进行。目前的技术水平使用评论的最终标题来使用 BERT 神经元排序器对文档进行排序。然而，最后的标题只是在审查进程结束时拟订的，这使得这种做法不切实际，因为它依赖事后提供的信息。在筛选时，只有一个粗略的工作标题可用，其中基于 BERT 的排名达到的显着差于最终标题。在本文中，我们探讨了用于筛选优先级的查询的其他来源，例如用于检索待筛选文档集的布尔查询，以及基于指令的生成式大语言模型(如 chatgPT 和 Alpaca)生成的查询。我们的最佳方法不仅基于筛选时可获得的信息是切实可行的，而且与最终标题的有效性相似。"
    },
    {
        "title": "Hypothesis Search: Inductive Reasoning with Language Models",
        "url": "http://arxiv.org/abs/2309.05660v1",
        "pub_date": "2023-09-11",
        "summary": "Inductive reasoning is a core problem-solving capacity: humans can identify\nunderlying principles from a few examples, which can then be robustly\ngeneralized to novel scenarios. Recent work has evaluated large language models\n(LLMs) on inductive reasoning tasks by directly prompting them yielding \"in\ncontext learning.\" This can work well for straightforward inductive tasks, but\nperforms very poorly on more complex tasks such as the Abstraction and\nReasoning Corpus (ARC). In this work, we propose to improve the inductive\nreasoning ability of LLMs by generating explicit hypotheses at multiple levels\nof abstraction: we prompt the LLM to propose multiple abstract hypotheses about\nthe problem, in natural language, then implement the natural language\nhypotheses as concrete Python programs. These programs can be directly verified\nby running on the observed examples and generalized to novel inputs. Because of\nthe prohibitive cost of generation with state-of-the-art LLMs, we consider a\nmiddle step to filter the set of hypotheses that will be implemented into\nprograms: we either ask the LLM to summarize into a smaller set of hypotheses,\nor ask human annotators to select a subset of the hypotheses. We verify our\npipeline's effectiveness on the ARC visual inductive reasoning benchmark, its\nvariant 1D-ARC, and string transformation dataset SyGuS. On a random 40-problem\nsubset of ARC, our automated pipeline using LLM summaries achieves 27.5%\naccuracy, significantly outperforming the direct prompting baseline (accuracy\nof 12.5%). With the minimal human input of selecting from LLM-generated\ncandidates, the performance is boosted to 37.5%. (And we argue this is a lower\nbound on the performance of our approach without filtering.) Our ablation\nstudies show that abstract hypothesis generation and concrete program\nrepresentations are both beneficial for LLMs to perform inductive reasoning\ntasks.",
        "translated": "归纳推理是解决问题的核心能力: 人类可以从一些例子中识别出潜在的原则，然后将这些原则强有力地推广到新的场景中。最近的研究已经评估了大型语言模型(LLMs)在归纳推理任务中的表现，直接提示它们产生“在上下文环境中学习”这对于简单的归纳任务可以很好地工作，但是对于更复杂的任务(如抽象和推理语料库(ARC))则表现得非常糟糕。在这项工作中，我们建议通过在多个抽象层次上生成明确的假设来提高 LLM 的归纳推理能力: 我们提示 LLM 用自然语言提出关于问题的多个抽象假设，然后将自然语言假设作为具体的 Python 程序来实现。这些程序可以通过运行观察到的例子直接验证，并推广到新的输入。由于使用最先进的 LLM 生成的成本过高，我们考虑采取中间步骤来过滤将被实现到程序中的一组假设: 我们要么请 LLM 总结成一个较小的假设集，要么请人类注释者选择假设的一个子集。我们验证了流水线在 ARC 视觉归纳推理基准、1D-ARC 变量和字符串转换数据集 SyGuS 上的有效性。在 ARC 的一个随机的40个问题子集上，我们使用 LLM 摘要的自动流水线达到了27.5% 的准确率，明显优于直接提示基线(准确率为12.5%)。通过最少的人工输入从 LLM 生成的候选者中进行选择，性能提高到37.5% 。(我们认为这是不经过过滤的方法的性能下限。)我们的消融研究表明，抽象假设生成和具体的程序表示都有利于 LLM 执行归纳推理任务。"
    },
    {
        "title": "MAmmoTH: Building Math Generalist Models through Hybrid Instruction\n  Tuning",
        "url": "http://arxiv.org/abs/2309.05653v1",
        "pub_date": "2023-09-11",
        "summary": "We introduce MAmmoTH, a series of open-source large language models (LLMs)\nspecifically tailored for general math problem-solving. The MAmmoTH models are\ntrained on MathInstruct, our meticulously curated instruction tuning dataset.\nMathInstruct is compiled from 13 math datasets with intermediate rationales,\nsix of which have rationales newly curated by us. It presents a unique hybrid\nof chain-of-thought (CoT) and program-of-thought (PoT) rationales, and also\nensures extensive coverage of diverse fields in math. The hybrid of CoT and PoT\nnot only unleashes the potential of tool use but also allows different thought\nprocesses for different math problems. As a result, the MAmmoTH series\nsubstantially outperform existing open-source models on nine mathematical\nreasoning datasets across all scales with an average accuracy gain between 13%\nand 29%. Remarkably, our MAmmoTH-7B model reaches 35% on MATH (a\ncompetition-level dataset), which exceeds the best open-source 7B model\n(WizardMath) by 25%, and the MAmmoTH-34B model achieves 46% accuracy on MATH,\neven surpassing GPT-4's CoT result. Our work underscores the importance of\ndiverse problem coverage and the use of hybrid rationales in developing\nsuperior math generalist models.",
        "translated": "我们介绍了 MAmmoTH，一系列专门为一般数学问题解决而设计的开源大型语言模型(LLM)。MAmmoTH 模型是在 MathDirect 上进行训练的，这是我们精心策划的指令调优数据集。数学教学是由13个数学数据集与中间的基本原理，其中六个有基本原理新策划我们。它提出了一个独特的混合的思想链(CoT)和程序的思想(PoT)的基本原理，也确保广泛的覆盖范围的不同领域的数学。CoT 和 PoT 的混合不仅释放了工具使用的潜力，而且允许不同的数学问题的不同思维过程。因此，MAmmoTH 系列在所有范围内的9个数学推理数据集上大大优于现有的开源模型，平均准确率提高了13% 至29% 。值得注意的是，我们的 MAmmoTH-7B 模型在 MATH (竞争级数据集)上达到35% ，比最好的开源7B 模型(WizardMath)高出25% ，而 MAmmoTH-34B 模型在 MATH 上达到46% 的准确性，甚至超过了 GPT-4的 CoT 结果。我们的工作强调了不同的问题覆盖面的重要性，以及在开发优秀的数学通才模型中使用混合理论的重要性。"
    },
    {
        "title": "Effective Proxy for Human Labeling: Ensemble Disagreement Scores in\n  Large Language Models for Industrial NLP",
        "url": "http://arxiv.org/abs/2309.05619v1",
        "pub_date": "2023-09-11",
        "summary": "Large language models (LLMs) have demonstrated significant capability to\ngeneralize across a large number of NLP tasks. For industry applications, it is\nimperative to assess the performance of the LLM on unlabeled production data\nfrom time to time to validate for a real-world setting. Human labeling to\nassess model error requires considerable expense and time delay. Here we\ndemonstrate that ensemble disagreement scores work well as a proxy for human\nlabeling for language models in zero-shot, few-shot, and fine-tuned settings,\nper our evaluation on keyphrase extraction (KPE) task. We measure fidelity of\nthe results by comparing to true error measured from human labeled ground\ntruth. We contrast with the alternative of using another LLM as a source of\nmachine labels, or silver labels. Results across various languages and domains\nshow disagreement scores provide a better estimation of model performance with\nmean average error (MAE) as low as 0.4% and on average 13.8% better than using\nsilver labels.",
        "translated": "大型语言模型(LLM)显示了在大量 NLP 任务中进行泛化的显著能力。对于工业应用程序，必须时不时地评估 LLM 对未标记的生产数据的性能，以验证实际设置。人工标记评估模型误差需要相当大的费用和时间延迟。在这里，我们证明了集合分歧得分作为人类标记语言模型在零拍摄，少拍摄和微调设置，根据我们的评估关键词提取(KPE)任务的代理工作。我们测量结果的保真度通过比较从人类标记的地面真理测量的真实误差。我们与使用另一个 LLM 作为机器标签或银标签来源的替代方法进行了对比。不同语言和领域的结果显示，不一致分数提供了更好的模型性能估计，平均误差(MAE)低至0.4% ，平均比使用银标签好13.8% 。"
    },
    {
        "title": "Incorporating Pre-trained Model Prompting in Multimodal Stock Volume\n  Movement Prediction",
        "url": "http://arxiv.org/abs/2309.05608v1",
        "pub_date": "2023-09-11",
        "summary": "Multimodal stock trading volume movement prediction with stock-related news\nis one of the fundamental problems in the financial area. Existing multimodal\nworks that train models from scratch face the problem of lacking universal\nknowledge when modeling financial news. In addition, the models ability may be\nlimited by the lack of domain-related knowledge due to insufficient data in the\ndatasets. To handle this issue, we propose the Prompt-based MUltimodal Stock\nvolumE prediction model (ProMUSE) to process text and time series modalities.\nWe use pre-trained language models for better comprehension of financial news\nand adopt prompt learning methods to leverage their capability in universal\nknowledge to model textual information. Besides, simply fusing two modalities\ncan cause harm to the unimodal representations. Thus, we propose a novel\ncross-modality contrastive alignment while reserving the unimodal heads beside\nthe fusion head to mitigate this problem. Extensive experiments demonstrate\nthat our proposed ProMUSE outperforms existing baselines. Comprehensive\nanalyses further validate the effectiveness of our architecture compared to\npotential variants and learning mechanisms.",
        "translated": "利用股票相关信息进行多模式股票交易量运动预测是金融领域的基本问题之一。现有的从零开始训练模型的多模式作品在建立金融新闻模型时面临缺乏通用知识的问题。此外，由于数据集中的数据不足，缺乏与领域相关的知识可能会限制模型的建模能力。为了处理这个问题，我们提出了基于 Prompt 的多通道股票交易量预测模型(ProMUSE)来处理文本和时间序列模式。我们使用预先训练好的语言模型来更好地理解财经新闻，并采用快速学习的方法来利用他们在通用知识方面的能力来模拟文本信息。此外，简单地融合两种模式可能会对单峰表示造成损害。因此，我们提出了一种新的交叉模态对比对准，同时保留融合头旁边的单峰头，以减轻这个问题。大量的实验表明，我们提出的 ProMUSE 优于现有的基线。综合分析进一步验证了我们的架构相对于潜在变量和学习机制的有效性。"
    },
    {
        "title": "Memory Injections: Correcting Multi-Hop Reasoning Failures during\n  Inference in Transformer-Based Language Models",
        "url": "http://arxiv.org/abs/2309.05605v1",
        "pub_date": "2023-09-11",
        "summary": "Answering multi-hop reasoning questions requires retrieving and synthesizing\ninformation from diverse sources. Large Language Models (LLMs) struggle to\nperform such reasoning consistently. Here we propose an approach to pinpoint\nand rectify multi-hop reasoning failures through targeted memory injections on\nLLM attention heads. First, we analyze the per-layer activations of GPT-2\nmodels in response to single and multi-hop prompts. We then propose a mechanism\nthat allows users to inject pertinent prompt-specific information, which we\nrefer to as \"memories,\" at critical LLM locations during inference. By thus\nenabling the LLM to incorporate additional relevant information during\ninference, we enhance the quality of multi-hop prompt completions. We show\nempirically that a simple, efficient, and targeted memory injection into a key\nattention layer can often increase the probability of the desired next token in\nmulti-hop tasks, by up to 424%.",
        "translated": "回答多跳推理问题需要从不同来源检索和综合信息。大型语言模型(LLM)很难始终如一地执行这样的推理。在这里，我们提出了一种方法来精确定位和纠正多跳推理失败的有针对性的记忆注入 LLM 注意头。首先，我们分析了 GPT-2模型对单跳和多跳提示的每层激活。然后，我们提出一种机制，允许用户在推理过程中在关键的 LLM 位置注入相关的特定于提示符的信息，我们称之为“记忆”。通过使 LLM 能够在推理过程中包含额外的相关信息，我们提高了多跳提示完成的质量。我们的实验表明，在多跳任务中，一个简单、有效和有针对性的注意关键层注入记忆通常可以提高期望下一个令牌的概率，最高可达424% 。"
    },
    {
        "title": "ITI-GEN: Inclusive Text-to-Image Generation",
        "url": "http://arxiv.org/abs/2309.05569v1",
        "pub_date": "2023-09-11",
        "summary": "Text-to-image generative models often reflect the biases of the training\ndata, leading to unequal representations of underrepresented groups. This study\ninvestigates inclusive text-to-image generative models that generate images\nbased on human-written prompts and ensure the resulting images are uniformly\ndistributed across attributes of interest. Unfortunately, directly expressing\nthe desired attributes in the prompt often leads to sub-optimal results due to\nlinguistic ambiguity or model misrepresentation. Hence, this paper proposes a\ndrastically different approach that adheres to the maxim that \"a picture is\nworth a thousand words\". We show that, for some attributes, images can\nrepresent concepts more expressively than text. For instance, categories of\nskin tones are typically hard to specify by text but can be easily represented\nby example images. Building upon these insights, we propose a novel approach,\nITI-GEN, that leverages readily available reference images for Inclusive\nText-to-Image GENeration. The key idea is learning a set of prompt embeddings\nto generate images that can effectively represent all desired attribute\ncategories. More importantly, ITI-GEN requires no model fine-tuning, making it\ncomputationally efficient to augment existing text-to-image models. Extensive\nexperiments demonstrate that ITI-GEN largely improves over state-of-the-art\nmodels to generate inclusive images from a prompt. Project page:\nhttps://czhang0528.github.io/iti-gen.",
        "translated": "文本-图像生成模型往往反映训练数据的偏差，导致代表性不足的群体表征不平等。本研究探讨了基于人工书写提示生成图像的包容性文本-图像生成模型，并确保生成的图像均匀地分布在感兴趣的属性之间。不幸的是，在提示中直接表达想要的属性往往导致次优结果，这是由于语言模糊或模型不正当手法引诱。因此，本文提出了一个截然不同的方法，坚持“一幅图片胜过千言万语”的格言。我们表明，对于某些属性，图像可以比文本更好地表达概念。例如，皮肤色调的类别通常很难通过文本指定，但可以很容易地用示例图像表示。在这些见解的基础上，我们提出了一个新颖的方法，ITI-GEN，利用现成的参考图像的包容性文本到图像生成。其关键思想是学习一组提示嵌入，以生成能够有效表示所有期望属性类别的图像。更重要的是，ITI-GEN 不需要对模型进行微调，这使得增强现有文本到图像模型的计算效率更高。大量的实验表明，ITI-GEN 在很大程度上改善了最先进的模型，从一个提示生成包容性图像。项目主页:  https://czhang0528.github.io/iti-gen。"
    },
    {
        "title": "An Empirical Study of NetOps Capability of Pre-Trained Large Language\n  Models",
        "url": "http://arxiv.org/abs/2309.05557v2",
        "pub_date": "2023-09-11",
        "summary": "Large language models (LLMs) can respond to human language queries and have\nshown powerful potential applications in network operations (NetOps). Thanks to\nthe large amount of commonsense knowledge inherent, LLMs achieve much better\ninference accuracy than traditional models and emerge with strong abilities in\ngeneralization, reasoning, and code generation. These abilities may have a\ncrucial boost to automated and intelligent NetOps. However, it remains\nunder-explored how well LLMs perform in various NetOps tasks. In this work, we\nmake a systematic assessment of the capabilities, strengths, and limitations of\nselected LLMs in the field of NetOps. The evaluation is conducted on a\ncollection of 5,732 questions about NetOps, encompassing 26 publicly available\ngeneral-domain LLMs, including ChatGPT, LLaMA, Falcon, etc. We also finetune\nsome of these LLMs with our collected NetOps corpus and evaluate the resulting\nmodels. The evaluation method follows the widely adopted benchmarks for\ngeneral-domain LLMs, combined with Chain-of-Thought Prompts and\nRetrieval-Augmented Generation. The results show that only GPT-4 achieves high\naccuracy equivalent to passing the NetOps certification exam for humans, while\nall the other LLMs have much lower accuracy. However, some open models like\nLLaMA 2 still demonstrate significant potential. Furthermore, we evaluate the\nimpact of factors such as model parameters, prompt engineering, instruction\nfine-tuning etc. This work shall be treated as the initial effort to systematic\nevaluation of LLMs in NetOps, and a more rigorous study is required for\nproduction use. The evaluation code and dataset will be released to benefit\nfuture research.",
        "translated": "大型语言模型(LLM)可以响应人类语言查询，在网络操作(NetOps)中显示出强大的潜在应用。由于固有的大量常识性知识，LLM 比传统模型获得了更好的推理精度，并且在泛化、推理和代码生成方面具有很强的能力。这些能力可能对自动化和智能网络操作系统起到至关重要的推动作用。然而，对 LLM 在各种 NetOps 任务中的表现仍然缺乏足够的了解。在这项工作中，我们做了一个系统的评估的能力，优势和局限性的选定 LLM 在 NetOps 领域。该评估针对5732个关于 NetOps 的问题，包括26个公开可用的通用域 LLM，包括 ChatGPT、 LLaMA、 Falcon 等。我们还使用收集的 NetOps 语料库对其中的一些 LLM 进行微调，并评估所得到的模型。该评价方法遵循广泛采用的通用领域 LLM 基准，结合思想链提示和检索增强生成。结果表明，只有 GPT-4达到了相当于人类通过 NetOps 认证考试的高精度，而所有其他 LLM 的精度要低得多。然而，一些像 LLaMA2这样的开放模型仍然显示出巨大的潜力。此外，我们还评估了模型参数、及时工程、教学微调等因素的影响。这项工作应被视为对 NetOps 中的 LLM 进行系统评估的初步努力，并需要进行更严格的生产使用研究。评估代码和数据集将公布，以利于未来的研究。"
    },
    {
        "title": "Kani: A Lightweight and Highly Hackable Framework for Building Language\n  Model Applications",
        "url": "http://arxiv.org/abs/2309.05542v1",
        "pub_date": "2023-09-11",
        "summary": "Language model applications are becoming increasingly popular and complex,\noften including features like tool usage and retrieval augmentation. However,\nexisting frameworks for such applications are often opinionated, deciding for\ndevelopers how their prompts ought to be formatted and imposing limitations on\ncustomizability and reproducibility. To solve this we present Kani: a\nlightweight, flexible, and model-agnostic open-source framework for building\nlanguage model applications. Kani helps developers implement a variety of\ncomplex features by supporting the core building blocks of chat interaction:\nmodel interfacing, chat management, and robust function calling. All Kani core\nfunctions are easily overridable and well documented to empower developers to\ncustomize functionality for their own needs. Kani thus serves as a useful tool\nfor researchers, hobbyists, and industry professionals alike to accelerate\ntheir development while retaining interoperability and fine-grained control.",
        "translated": "语言模型应用程序正变得越来越流行和复杂，通常包括工具使用和检索增强等特性。然而，用于这些应用程序的现有框架往往固执己见，决定开发人员应该如何设置提示的格式，并对可定制性和可重复性施加限制。为了解决这个问题，我们提出了 Kani: 一个轻量级的、灵活的、与模型无关的开源框架，用于构建语言模型应用程序。Kani 通过支持聊天交互的核心构件来帮助开发人员实现各种复杂的特性: 模型接口、聊天管理和健壮的函数调用。所有 Kani 核心功能都很容易被覆盖，并且有很好的文档记录，使开发人员能够根据自己的需要定制功能。因此，Kani 可以作为研究人员、业余爱好者和行业专业人员的一个有用的工具来加速他们的开发，同时保留互操作性和细粒度控制。"
    },
    {
        "title": "PAI-Diffusion: Constructing and Serving a Family of Open Chinese\n  Diffusion Models for Text-to-image Synthesis on the Cloud",
        "url": "http://arxiv.org/abs/2309.05534v1",
        "pub_date": "2023-09-11",
        "summary": "Text-to-image synthesis for the Chinese language poses unique challenges due\nto its large vocabulary size, and intricate character relationships. While\nexisting diffusion models have shown promise in generating images from textual\ndescriptions, they often neglect domain-specific contexts and lack robustness\nin handling the Chinese language. This paper introduces PAI-Diffusion, a\ncomprehensive framework that addresses these limitations. PAI-Diffusion\nincorporates both general and domain-specific Chinese diffusion models,\nenabling the generation of contextually relevant images. It explores the\npotential of using LoRA and ControlNet for fine-grained image style transfer\nand image editing, empowering users with enhanced control over image\ngeneration. Moreover, PAI-Diffusion seamlessly integrates with Alibaba Cloud's\nMachine Learning Platform for AI, providing accessible and scalable solutions.\nAll the Chinese diffusion model checkpoints, LoRAs, and ControlNets, including\ndomain-specific ones, are publicly available. A user-friendly Chinese WebUI and\nthe diffusers-api elastic inference toolkit, also open-sourced, further\nfacilitate the easy deployment of PAI-Diffusion models in various environments,\nmaking it a valuable resource for Chinese text-to-image synthesis.",
        "translated": "汉语文本-图像合成因其词汇量大、字符关系复杂等特点而面临着独特的挑战。现有的扩散模型在利用文本描述生成图像方面表现出良好的应用前景，但它们往往忽视了特定领域的语境，缺乏对汉语语言处理的鲁棒性。本文介绍了 PAI 扩散，这是一个解决这些局限性的综合框架。PAI 扩散结合了一般和领域特定的中文扩散模型，使生成上下文相关的图像。它探索了使用 LoRA 和 ControlNet 进行细粒度图像样式传输和图像编辑的潜力，增强了用户对图像生成的控制。此外，PAI-Defusion 与阿里巴巴云计算的人工智能机器学习平台无缝集成，提供易于访问和可扩展的解决方案。所有的中文扩散模型检查点、 LoRA 和 ControlNet，包括特定领域的检查点，都是公开的。一个方便用户使用的中文 WebUI 和扩散器 API 弹性推理工具包(也是开源的)进一步促进了 PAI 扩散模型在各种环境中的易于部署，使其成为中文文本到图像合成的宝贵资源。"
    },
    {
        "title": "NExT-GPT: Any-to-Any Multimodal LLM",
        "url": "http://arxiv.org/abs/2309.05519v1",
        "pub_date": "2023-09-11",
        "summary": "While recently Multimodal Large Language Models (MM-LLMs) have made exciting\nstrides, they mostly fall prey to the limitation of only input-side multimodal\nunderstanding, without the ability to produce content in multiple modalities.\nAs we humans always perceive the world and communicate with people through\nvarious modalities, developing any-to-any MM-LLMs capable of accepting and\ndelivering content in any modality becomes essential to human-level AI. To fill\nthe gap, we present an end-to-end general-purpose any-to-any MM-LLM system,\nNExT-GPT. We connect an LLM with multimodal adaptors and different diffusion\ndecoders, enabling NExT-GPT to perceive inputs and generate outputs in\narbitrary combinations of text, images, videos, and audio. By leveraging the\nexisting well-trained highly-performing encoders and decoders, NExT-GPT is\ntuned with only a small amount of parameter (1%) of certain projection layers,\nwhich not only benefits low-cost training and also facilitates convenient\nexpansion to more potential modalities. Moreover, we introduce a\nmodality-switching instruction tuning (MosIT) and manually curate a\nhigh-quality dataset for MosIT, based on which NExT-GPT is empowered with\ncomplex cross-modal semantic understanding and content generation. Overall, our\nresearch showcases the promising possibility of building an AI agent capable of\nmodeling universal modalities, paving the way for more human-like AI research\nin the community.",
        "translated": "虽然最近多模态大语言模型(MM-LLM)已经取得了令人兴奋的进展，但是它们大多数都受制于只有输入端多模态理解的局限性，无法以多种方式生成内容。由于我们人类总是通过各种方式感知世界和与人交流，开发任意对任意 MM-LLM 能够接受和传递任意方式的内容成为人类级 AI 的关键。为了填补这个空白，我们提出了一个端到端的通用任意 MM-LLM 系统 NExT-GPT。我们将 LLM 与多模态适配器和不同的扩散解码器连接起来，使 NExT-GPT 能够以文本、图像、视频和音频的任意组合来感知输入和生成输出。通过利用现有经过良好培训的高性能编码器和解码器，NExT-GPT 仅用某些投影层的少量参数(1%)进行调整，这不仅有利于低成本培训，而且有利于方便地扩展到更多潜在的模式。此外，我们还引入了模态切换指令调优(MosIT) ，并手动为 MosIT 策划了一个高质量的数据集，基于该数据集，NExT-GPT 具有复杂的跨模态语义理解和内容生成能力。总的来说，我们的研究展示了建立一个能够建模通用模式的人工智能代理的可能性，为在社区中进行更多类似人类的人工智能研究铺平了道路。"
    },
    {
        "title": "Human Action Co-occurrence in Lifestyle Vlogs using Graph Link\n  Prediction",
        "url": "http://arxiv.org/abs/2309.06219v1",
        "pub_date": "2023-09-12",
        "summary": "We introduce the task of automatic human action co-occurrence identification,\ni.e., determine whether two human actions can co-occur in the same interval of\ntime. We create and make publicly available the ACE (Action Co-occurrencE)\ndataset, consisting of a large graph of ~12k co-occurring pairs of visual\nactions and their corresponding video clips. We describe graph link prediction\nmodels that leverage visual and textual information to automatically infer if\ntwo actions are co-occurring. We show that graphs are particularly well suited\nto capture relations between human actions, and the learned graph\nrepresentations are effective for our task and capture novel and relevant\ninformation across different data domains. The ACE dataset and the code\nintroduced in this paper are publicly available at\nhttps://github.com/MichiganNLP/vlog_action_co-occurrence.",
        "translated": "本文介绍了人类行为共现识别的任务，即确定两个人类行为是否可以在同一时间间隔内共现。我们创建并公开可用的 ACE (动作共同出现 E)数据集，包括约12k 共同出现的视觉动作对及其相应的视频剪辑的大图。我们描述了图形链接预测模型，它利用视觉和文本信息自动推断两个动作是否同时发生。我们表明，图表特别适合于捕获人类行为之间的关系，学习图表示是有效的，为我们的任务和捕获新的和相关的信息跨不同的数据领域。本文介绍的 ACE 数据集和代码可在 https://github.com/michigannlp/vlog_action_co-occurrence 公开查阅。"
    },
    {
        "title": "HAMUR: Hyper Adapter for Multi-Domain Recommendation",
        "url": "http://arxiv.org/abs/2309.06217v1",
        "pub_date": "2023-09-12",
        "summary": "Multi-Domain Recommendation (MDR) has gained significant attention in recent\nyears, which leverages data from multiple domains to enhance their performance\nconcurrently.However, current MDR models are confronted with two limitations.\nFirstly, the majority of these models adopt an approach that explicitly shares\nparameters between domains, leading to mutual interference among them.\nSecondly, due to the distribution differences among domains, the utilization of\nstatic parameters in existing methods limits their flexibility to adapt to\ndiverse domains. To address these challenges, we propose a novel model Hyper\nAdapter for Multi-Domain Recommendation (HAMUR). Specifically, HAMUR consists\nof two components: (1). Domain-specific adapter, designed as a pluggable module\nthat can be seamlessly integrated into various existing multi-domain backbone\nmodels, and (2). Domain-shared hyper-network, which implicitly captures shared\ninformation among domains and dynamically generates the parameters for the\nadapter. We conduct extensive experiments on two public datasets using various\nbackbone networks. The experimental results validate the effectiveness and\nscalability of the proposed model.",
        "translated": "多域推荐(MDR)近年来受到了广泛的关注，它利用来自多个域的数据来同时提高它们的性能。然而，当前的 MDR 模型面临两个限制。首先，这些模型中的大多数都采用了域之间显式共享参数的方法，导致了域之间的相互干扰。其次，由于领域之间的分布差异，现有方法中静态参数的使用限制了它们适应不同领域的灵活性。为了应对这些挑战，我们提出了一种新型的多域推荐超级适配器(HAMUR)模型。具体来说，HAMUR 由两部分组成: (1)。特定于领域的适配器，设计为可插拔模块，可以无缝集成到各种现有的多领域主干模型，以及(2)。域共享超网络，它隐式地捕获域之间的共享信息并动态地生成适配器的参数。我们使用不同的骨干网络对两个公共数据集进行了广泛的实验。实验结果验证了该模型的有效性和可扩展性。"
    },
    {
        "title": "Improving and Evaluating the Detection of Fragmentation in News\n  Recommendations with the Clustering of News Story Chains",
        "url": "http://arxiv.org/abs/2309.06192v1",
        "pub_date": "2023-09-12",
        "summary": "News recommender systems play an increasingly influential role in shaping\ninformation access within democratic societies. However, tailoring\nrecommendations to users' specific interests can result in the divergence of\ninformation streams. Fragmented access to information poses challenges to the\nintegrity of the public sphere, thereby influencing democracy and public\ndiscourse. The Fragmentation metric quantifies the degree of fragmentation of\ninformation streams in news recommendations. Accurate measurement of this\nmetric requires the application of Natural Language Processing (NLP) to\nidentify distinct news events, stories, or timelines. This paper presents an\nextensive investigation of various approaches for quantifying Fragmentation in\nnews recommendations. These approaches are evaluated both intrinsically, by\nmeasuring performance on news story clustering, and extrinsically, by assessing\nthe Fragmentation scores of different simulated news recommender scenarios. Our\nfindings demonstrate that agglomerative hierarchical clustering coupled with\nSentenceBERT text representation is substantially better at detecting\nFragmentation than earlier implementations. Additionally, the analysis of\nsimulated scenarios yields valuable insights and recommendations for\nstakeholders concerning the measurement and interpretation of Fragmentation.",
        "translated": "新闻推荐系统在塑造民主社会的信息获取方面发挥着日益重要的作用。然而，根据用户的具体兴趣裁剪建议可能导致信息流的分歧。分散的信息获取对公共领域的完整性构成挑战，从而影响到民主政体和公共话语。碎片度量用于量化新闻推荐中信息流碎片化的程度。准确测量这个指标需要应用自然语言处理(NLP)来识别不同的新闻事件、故事或时间轴。本文提出了一个广泛的调查各种方法来量化碎片在新闻推荐。这些方法通过测量新闻故事聚类的表现来进行内部评估，通过评估不同模拟新闻推荐场景的碎片化得分来进行外部评估。我们的研究结果表明，凝聚层次聚类与句子 BERT 文本表示相结合在检测碎片方面比早期的实现要好得多。此外，对模拟情景的分析为利益攸关方提供了关于衡量和解释不成体系问题的宝贵见解和建议。"
    },
    {
        "title": "AKEM: Aligning Knowledge Base to Queries with Ensemble Model for Entity\n  Recognition and Linking",
        "url": "http://arxiv.org/abs/2309.06175v1",
        "pub_date": "2023-09-12",
        "summary": "This paper presents a novel approach to address the Entity Recognition and\nLinking Challenge at NLPCC 2015. The task involves extracting named entity\nmentions from short search queries and linking them to entities within a\nreference Chinese knowledge base. To tackle this problem, we first expand the\nexisting knowledge base and utilize external knowledge to identify candidate\nentities, thereby improving the recall rate. Next, we extract features from the\ncandidate entities and utilize Support Vector Regression and Multiple Additive\nRegression Tree as scoring functions to filter the results. Additionally, we\napply rules to further refine the results and enhance precision. Our method is\ncomputationally efficient and achieves an F1 score of 0.535.",
        "translated": "本文提出了一种新的方法来解决实体识别和链接的挑战在2015年全国 LPCC。该任务包括从短期搜索查询中提取命名实体，并将它们链接到参考中文知识库中的实体。为了解决这个问题，我们首先扩展现有的知识库，利用外部知识来识别候选实体，从而提高召回率。接下来，我们从候选实体中提取特征，并利用支持向量回归和多重加性回归树作为评分函数来过滤结果。此外，我们应用规则来进一步细化结果和提高精度。该方法计算效率高，F1得分为0.535。"
    },
    {
        "title": "Annotating Data for Fine-Tuning a Neural Ranker? Current Active Learning\n  Strategies are not Better than Random Selection",
        "url": "http://arxiv.org/abs/2309.06131v1",
        "pub_date": "2023-09-12",
        "summary": "Search methods based on Pretrained Language Models (PLM) have demonstrated\ngreat effectiveness gains compared to statistical and early neural ranking\nmodels. However, fine-tuning PLM-based rankers requires a great amount of\nannotated training data. Annotating data involves a large manual effort and\nthus is expensive, especially in domain specific tasks. In this paper we\ninvestigate fine-tuning PLM-based rankers under limited training data and\nbudget. We investigate two scenarios: fine-tuning a ranker from scratch, and\ndomain adaptation starting with a ranker already fine-tuned on general data,\nand continuing fine-tuning on a target dataset. We observe a great variability\nin effectiveness when fine-tuning on different randomly selected subsets of\ntraining data. This suggests that it is possible to achieve effectiveness gains\nby actively selecting a subset of the training data that has the most positive\neffect on the rankers. This way, it would be possible to fine-tune effective\nPLM rankers at a reduced annotation budget. To investigate this, we adapt\nexisting Active Learning (AL) strategies to the task of fine-tuning PLM rankers\nand investigate their effectiveness, also considering annotation and\ncomputational costs. Our extensive analysis shows that AL strategies do not\nsignificantly outperform random selection of training subsets in terms of\neffectiveness. We further find that gains provided by AL strategies come at the\nexpense of more assessments (thus higher annotation costs) and AL strategies\nunderperform random selection when comparing effectiveness given a fixed\nannotation cost. Our results highlight that ``optimal'' subsets of training\ndata that provide high effectiveness at low annotation cost do exist, but\ncurrent mainstream AL strategies applied to PLM rankers are not capable of\nidentifying them.",
        "translated": "基于预训练语言模型(PLM)的搜索方法与统计和早期的神经排序模型相比已经显示出很大的有效性。然而，微调基于 PLM 的排名需要大量注释的训练数据。注释数据涉及大量的手工操作，因此成本很高，特别是在特定于领域的任务中。本文研究了在有限的训练数据和预算下基于 PLM 的排序器的微调问题。我们研究了两种情况: 从头开始对排名进行微调，从已经对一般数据进行微调的排名开始进行域适应，并继续对目标数据集进行微调。当对不同的随机选择的训练数据子集进行微调时，我们观察到有效性的巨大变化。这表明，有可能通过积极选择对排名有最积极影响的训练数据子集来实现效率增益。这样，就有可能在减少注释预算的情况下微调有效的 PLM 排名。为了研究这一问题，我们将现有的主动学习(AL)策略应用到 PLM 排名的微调任务中，并考虑到注释和计算成本，研究了它们的有效性。我们广泛的分析表明，AL 策略在效果方面并不显著优于随机选择的训练子集。我们进一步发现，AL 策略提供的收益是以牺牲更多的评估为代价的(因此更高的注释成本) ，并且在比较固定注释成本下的有效性时，AL 策略表现不如随机选择。我们的研究结果强调，确实存在以低注释成本提供高效率的“最佳”训练数据子集，但目前应用于 PLM 排名的主流 AL 策略无法识别它们。"
    },
    {
        "title": "Cited Text Spans for Citation Text Generation",
        "url": "http://arxiv.org/abs/2309.06365v1",
        "pub_date": "2023-09-12",
        "summary": "Automatic related work generation must ground their outputs to the content of\nthe cited papers to avoid non-factual hallucinations, but due to the length of\nscientific documents, existing abstractive approaches have conditioned only on\nthe cited paper \\textit{abstracts}. We demonstrate that the abstract is not\nalways the most appropriate input for citation generation and that models\ntrained in this way learn to hallucinate. We propose to condition instead on\nthe \\textit{cited text span} (CTS) as an alternative to the abstract. Because\nmanual CTS annotation is extremely time- and labor-intensive, we experiment\nwith automatic, ROUGE-based labeling of candidate CTS sentences, achieving\nsufficiently strong performance to substitute for expensive human annotations,\nand we propose a human-in-the-loop, keyword-based CTS retrieval approach that\nmakes generating citation texts grounded in the full text of cited papers both\npromising and practical.",
        "translated": "自动生成的相关工作必须以所引文件的内容为基础，以避免出现非事实性的幻觉，但由于科学文件的长度，现有的抽象方法只以所引文件的文本为条件。我们证明，摘要并不总是最适合引文生成的输入，以这种方式训练的模型学习幻觉。我们建议以文本{引用的文本跨度}(CTS)作为抽象的替代条件。由于手工 CTS 注释耗费大量时间和人力，我们对候选 CTS 句子进行了基于 ROUGE 的自动标注实验，取得了足够强的性能来代替昂贵的人工注释，并提出了一种基于人在回路的关键字的 CTS 检索方法，该方法使得基于引文全文的引文文本生成具有前景和实用性。"
    },
    {
        "title": "Learning to Predict Concept Ordering for Common Sense Generation",
        "url": "http://arxiv.org/abs/2309.06363v1",
        "pub_date": "2023-09-12",
        "summary": "Prior work has shown that the ordering in which concepts are shown to a\ncommonsense generator plays an important role, affecting the quality of the\ngenerated sentence. However, it remains a challenge to determine the optimal\nordering of a given set of concepts such that a natural sentence covering all\nthe concepts could be generated from a pretrained generator. To understand the\nrelationship between the ordering of the input concepts and the quality of the\ngenerated sentences, we conduct a systematic study considering multiple\nlanguage models (LMs) and concept ordering strategies. We find that BART-large\nmodel consistently outperforms all other LMs considered in this study when\nfine-tuned using the ordering of concepts as they appear in CommonGen training\ndata as measured using multiple evaluation metrics. Moreover, the larger\nGPT3-based large language models (LLMs) variants do not necessarily outperform\nmuch smaller LMs on this task, even when fine-tuned on task-specific training\ndata. Interestingly, human annotators significantly reorder input concept sets\nwhen manually writing sentences covering those concepts, and this ordering\nprovides the best sentence generations independently of the LM used for the\ngeneration, outperforming a probabilistic concept ordering baseline",
        "translated": "先前的工作已经表明，概念在常识生成器中的排序起着重要作用，影响生成句的质量。然而，确定一组特定概念的最佳顺序仍然是一个挑战，这样一个涵盖所有概念的自然句可以从预先训练的生成器生成。为了理解输入概念的排序与生成句子的质量之间的关系，我们从多语言模型和概念排序策略两个方面进行了系统的研究。我们发现 BART-large 模型在使用多个评估指标对 CommonGen 训练数据中出现的概念进行微调时，始终优于本研究中考虑的所有其他 LM。此外，更大的基于 GPT3的大型语言模型(LLM)变体不一定在这个任务上胜过更小的 LLM，即使在特定任务的训练数据上进行了微调。有趣的是，人类注释者在手工书写涵盖这些概念的句子时，会显著地重新排序输入概念集，并且这种排序提供了独立于用于生成的 LM 的最佳句子生成，优于概率概念排序基线"
    },
    {
        "title": "Re-Reading Improves Reasoning in Language Models",
        "url": "http://arxiv.org/abs/2309.06275v1",
        "pub_date": "2023-09-12",
        "summary": "Reasoning presents a significant and challenging issue for Large Language\nModels (LLMs). The predominant focus of research has revolved around developing\ndiverse prompting strategies to guide and structure the reasoning processes of\nLLMs. However, these approaches based on decoder-only causal language models\noften operate the input question in a single forward pass, potentially missing\nthe rich, back-and-forth interactions inherent in human reasoning. Scant\nattention has been paid to a critical dimension, i.e., the input question\nitself embedded within the prompts. In response, we introduce a deceptively\nsimple yet highly effective prompting strategy, termed question \"re-reading\".\nDrawing inspiration from human learning and problem-solving, re-reading entails\nrevisiting the question information embedded within input prompts. This\napproach aligns seamlessly with the cognitive principle of reinforcement,\nenabling LLMs to extract deeper insights, identify intricate patterns,\nestablish more nuanced connections, and ultimately enhance their reasoning\ncapabilities across various tasks. Experiments conducted on a series of\nreasoning benchmarks serve to underscore the effectiveness and generality of\nour method. Moreover, our findings demonstrate that our approach seamlessly\nintegrates with various language models, though-eliciting prompting methods,\nand ensemble techniques, further underscoring its versatility and compatibility\nin the realm of LLMs.",
        "translated": "对于大型语言模型(LLM)来说，推理是一个重要且具有挑战性的问题。研究的主要焦点围绕着发展不同的激励策略来指导和构建 LLM 的推理过程。然而，这些基于只有解码器的因果语言模型的方法往往在一个单一的向前传递操作输入问题，潜在地缺少人类推理固有的丰富的来回交互作用。很少有人注意到一个关键的维度，也就是说，输入问题本身嵌入在提示中。作为回应，我们引入了一个看似简单但却非常有效的激励策略，称之为问题“重读”。从人类学习和解决问题中获得灵感，重读需要重新审视输入提示中嵌入的问题信息。这种方法与强化的认知原则无缝地结合在一起，使 LLM 能够提取更深层次的见解，识别复杂的模式，建立更微妙的连接，并最终增强它们在各种任务中的推理能力。在一系列推理基准上进行的实验突出了我们方法的有效性和普遍性。此外，我们的研究结果表明，我们的方法无缝集成与各种语言模型，虽然引出提示方法，和集成技术，进一步强调其多功能性和兼容性领域的 LLM。"
    },
    {
        "title": "The first step is the hardest: Pitfalls of Representing and Tokenizing\n  Temporal Data for Large Language Models",
        "url": "http://arxiv.org/abs/2309.06236v1",
        "pub_date": "2023-09-12",
        "summary": "Large Language Models (LLMs) have demonstrated remarkable generalization\nacross diverse tasks, leading individuals to increasingly use them as personal\nassistants and universal computing engines. Nevertheless, a notable obstacle\nemerges when feeding numerical/temporal data into these models, such as data\nsourced from wearables or electronic health records. LLMs employ tokenizers in\ntheir input that break down text into smaller units. However, tokenizers are\nnot designed to represent numerical values and might struggle to understand\nrepetitive patterns and context, treating consecutive values as separate tokens\nand disregarding their temporal relationships. Here, we discuss recent works\nthat employ LLMs for human-centric tasks such as in mobile health sensing and\npresent a case study showing that popular LLMs tokenize temporal data\nincorrectly. To address that, we highlight potential solutions such as prompt\ntuning with lightweight embedding layers as well as multimodal adapters, that\ncan help bridge this \"modality gap\". While the capability of language models to\ngeneralize to other modalities with minimal or no finetuning is exciting, this\npaper underscores the fact that their outputs cannot be meaningful if they\nstumble over input nuances.",
        "translated": "大型语言模型(LLM)已经在不同的任务中表现出了显著的泛化能力，导致个人越来越多地将它们用作个人助理和通用计算引擎。然而，在将数值/时间数据输入这些模型时，出现了一个显著的障碍，例如来自可穿戴设备或电子健康记录的数据。LLM 在它们的输入中使用标记，将文本分解成更小的单元。然而，标记并不是为了表示数值而设计的，并且可能难以理解重复的模式和上下文，将连续的值作为单独的标记处理，并忽略它们的时间关系。在这里，我们讨论最近的工作，使用 LLM 的人为中心的任务，如在移动健康传感，并提出了一个案例研究表明，流行的 LLM 标记时间数据错误。为了解决这个问题，我们强调了一些潜在的解决方案，比如使用轻量级嵌入层以及多通道适配器进行快速调优，这些解决方案可以帮助消除这种“通道差距”。虽然语言模型的能力推广到其他形式的最低限度或没有微调是令人兴奋的，本文强调的事实是，他们的输出不可能是有意义的，如果他们绊倒了输入的细微差别。"
    },
    {
        "title": "Glancing Future for Simultaneous Machine Translation",
        "url": "http://arxiv.org/abs/2309.06179v1",
        "pub_date": "2023-09-12",
        "summary": "Simultaneous machine translation (SiMT) outputs translation while reading the\nsource sentence. Unlike conventional sequence-to-sequence (seq2seq) training,\nexisting SiMT methods adopt the prefix-to-prefix (prefix2prefix) training,\nwhere the model predicts target tokens based on partial source tokens. However,\nthe prefix2prefix training diminishes the ability of the model to capture\nglobal information and introduces forced predictions due to the absence of\nessential source information. Consequently, it is crucial to bridge the gap\nbetween the prefix2prefix training and seq2seq training to enhance the\ntranslation capability of the SiMT model. In this paper, we propose a novel\nmethod that glances future in curriculum learning to achieve the transition\nfrom the seq2seq training to prefix2prefix training. Specifically, we gradually\nreduce the available source information from the whole sentence to the prefix\ncorresponding to that latency. Our method is applicable to a wide range of SiMT\nmethods and experiments demonstrate that our method outperforms strong\nbaselines.",
        "translated": "同步机器翻译(SiMT)在读取原句时输出翻译结果。与传统的序列到序列(seq2seq)训练不同，现有的 SiMT 方法采用前缀到前缀(prefix2prefix)训练，其中模型基于部分源标记预测目标标记。然而，前缀2前缀训练降低了模型捕获全局信息的能力，并且由于缺乏必要的源信息而引入了强制预测。因此，缩小前缀2前缀训练和 seq2seq 训练之间的差距对于提高 SiMT 模型的翻译能力至关重要。本文提出了一种在课程学习中展望未来的新方法，实现了由 seq2seq 训练向前缀2训练的过渡。具体来说，我们逐渐减少可用的来源信息从整个句子的前缀相应的延迟。我们的方法适用于大范围的 SiMT 方法和实验表明，我们的方法优于强基线。"
    },
    {
        "title": "Overview of GUA-SPA at IberLEF 2023: Guarani-Spanish Code Switching\n  Analysis",
        "url": "http://arxiv.org/abs/2309.06163v1",
        "pub_date": "2023-09-12",
        "summary": "We present the first shared task for detecting and analyzing code-switching\nin Guarani and Spanish, GUA-SPA at IberLEF 2023. The challenge consisted of\nthree tasks: identifying the language of a token, NER, and a novel task of\nclassifying the way a Spanish span is used in the code-switched context. We\nannotated a corpus of 1500 texts extracted from news articles and tweets,\naround 25 thousand tokens, with the information for the tasks. Three teams took\npart in the evaluation phase, obtaining in general good results for Task 1, and\nmore mixed results for Tasks 2 and 3.",
        "translated": "我们提出了第一个共享的任务，检测和分析语码转换在瓜拉尼和西班牙语，GUA-SPA 在 IberLEF 2023。这个挑战包括三个任务: 识别标记的语言，NER，以及一个新颖的任务，分类西班牙语跨度在代码转换上下文中的使用方式。我们注释了从新闻文章和 tweet 中提取的1500个文本，大约25000个标记，以及任务的信息。三个团队参与了评估阶段，在任务1中获得了总体良好的结果，在任务2和3中获得了更多的混合结果。"
    },
    {
        "title": "Prompting4Debugging: Red-Teaming Text-to-Image Diffusion Models by\n  Finding Problematic Prompts",
        "url": "http://arxiv.org/abs/2309.06135v1",
        "pub_date": "2023-09-12",
        "summary": "Text-to-image diffusion models, e.g. Stable Diffusion (SD), lately have shown\nremarkable ability in high-quality content generation, and become one of the\nrepresentatives for the recent wave of transformative AI. Nevertheless, such\nadvance comes with an intensifying concern about the misuse of this generative\ntechnology, especially for producing copyrighted or NSFW (i.e. not safe for\nwork) images. Although efforts have been made to filter inappropriate\nimages/prompts or remove undesirable concepts/styles via model fine-tuning, the\nreliability of these safety mechanisms against diversified problematic prompts\nremains largely unexplored. In this work, we propose Prompting4Debugging (P4D)\nas a debugging and red-teaming tool that automatically finds problematic\nprompts for diffusion models to test the reliability of a deployed safety\nmechanism. We demonstrate the efficacy of our P4D tool in uncovering new\nvulnerabilities of SD models with safety mechanisms. Particularly, our result\nshows that around half of prompts in existing safe prompting benchmarks which\nwere originally considered \"safe\" can actually be manipulated to bypass many\ndeployed safety mechanisms, including concept removal, negative prompt, and\nsafety guidance. Our findings suggest that, without comprehensive testing, the\nevaluations on limited safe prompting benchmarks can lead to a false sense of\nsafety for text-to-image models.",
        "translated": "文本到图像的扩散模型，如稳定扩散(SD) ，最近显示出显著的能力，在高质量的内容生成，并成为最近一波的变革人工智能的代表之一。然而，这样的进步伴随着对滥用这种生成技术的日益关注，尤其是用于制作有版权的或 NSFW (即对工作不安全)的图像。虽然已经努力通过模型微调过滤不适当的图像/提示或去除不良的概念/样式，但是这些安全机制对于各种有问题的提示的可靠性仍然基本上没有被探索。在这项工作中，我们提出 Prompting4Debug (P4D)作为一个调试和红色团队工具，自动发现有问题的提示扩散模型，以测试部署的安全机制的可靠性。我们证明了我们的 P4D 工具在发现具有安全机制的 SD 模型的新漏洞方面的有效性。特别是，我们的研究结果表明，在现有的安全提示基准中，大约一半的提示原本被认为是“安全”的，但实际上可以被操纵来绕过许多已部署的安全机制，包括概念删除、负面提示和安全指导。我们的研究结果表明，没有全面的测试，有限的安全提示基准的评价可能会导致文本到图像模型的安全错误感。"
    },
    {
        "title": "Résumé Parsing as Hierarchical Sequence Labeling: An Empirical Study",
        "url": "http://arxiv.org/abs/2309.07015v1",
        "pub_date": "2023-09-13",
        "summary": "Extracting information from r\\'esum\\'es is typically formulated as a\ntwo-stage problem, where the document is first segmented into sections and then\neach section is processed individually to extract the target entities. Instead,\nwe cast the whole problem as sequence labeling in two levels -- lines and\ntokens -- and study model architectures for solving both tasks simultaneously.\nWe build high-quality r\\'esum\\'e parsing corpora in English, French, Chinese,\nSpanish, German, Portuguese, and Swedish. Based on these corpora, we present\nexperimental results that demonstrate the effectiveness of the proposed models\nfor the information extraction task, outperforming approaches introduced in\nprevious work. We conduct an ablation study of the proposed architectures. We\nalso analyze both model performance and resource efficiency, and describe the\ntrade-offs for model deployment in the context of a production environment.",
        "translated": "从简历中提取信息通常被描述为一个两阶段的问题，首先将文档分成几个部分，然后分别处理每个部分以提取目标实体。相反，我们将整个问题转换为两个层次的序列标记——行和标记——并研究同时解决这两个任务的模型体系结构。我们用英语、法语、汉语、西班牙语、德语、葡萄牙语和瑞典语构建高质量的简历解析语料库。基于这些语料库，我们展示了实验结果，证明了所提出的模型对信息抽取任务的有效性，表现优于以前工作中介绍的方法。我们对建议的结构进行了消融研究。我们还分析了模型性能和资源效率，并描述了在生产环境中模型部署的权衡。"
    },
    {
        "title": "Modeling Dislocation Dynamics Data Using Semantic Web Technologies",
        "url": "http://arxiv.org/abs/2309.06930v1",
        "pub_date": "2023-09-13",
        "summary": "Research in the field of Materials Science and Engineering focuses on the\ndesign, synthesis, properties, and performance of materials. An important class\nof materials that is widely investigated are crystalline materials, including\nmetals and semiconductors. Crystalline material typically contains a distinct\ntype of defect called \"dislocation\". This defect significantly affects various\nmaterial properties, including strength, fracture toughness, and ductility.\nResearchers have devoted a significant effort in recent years to understanding\ndislocation behavior through experimental characterization techniques and\nsimulations, e.g., dislocation dynamics simulations. This paper presents how\ndata from dislocation dynamics simulations can be modeled using semantic web\ntechnologies through annotating data with ontologies. We extend the already\nexisting Dislocation Ontology by adding missing concepts and aligning it with\ntwo other domain-related ontologies (i.e., the Elementary Multi-perspective\nMaterial Ontology and the Materials Design Ontology) allowing for representing\nthe dislocation simulation data efficiently. Moreover, we show a real-world use\ncase by representing the discrete dislocation dynamics data as a knowledge\ngraph (DisLocKG) that illustrates the relationship between them. We also\ndeveloped a SPARQL endpoint that brings extensive flexibility to query\nDisLocKG.",
        "translated": "材料科学与工程领域的研究集中于材料的设计、合成、性能和性能。一类被广泛研究的重要材料是晶体材料，包括金属和半导体。晶体材料通常含有一种不同类型的缺陷，称为“位错”。这种缺陷会严重影响各种材料的性能，包括强度、断裂韧性和延展性。近年来，研究人员通过实验角色塑造技术和模拟，例如位错动力学模拟，致力于理解位错行为。本文介绍了如何利用语义网技术，通过本体注释数据，对位错动力学仿真数据进行建模。我们通过添加缺失的概念并将其与其他两个领域相关的本体(即初等多视角材料本体和材料设计本体)对齐，扩展了已有的位错本体，从而有效地表示位错模拟数据。此外，通过将离散位错动力学数据表示为一个知识图(DisLocKG)来说明它们之间的关系，我们展示了一个真实的用例。我们还开发了一个 SPARQL 端点，它为查询 DisLocKG 带来了广泛的灵活性。"
    },
    {
        "title": "Multi-behavior Recommendation with SVD Graph Neural Networks",
        "url": "http://arxiv.org/abs/2309.06912v1",
        "pub_date": "2023-09-13",
        "summary": "Graph Neural Networks (GNNs) has been extensively employed in the field of\nrecommender systems, offering users personalized recommendations and yielding\nremarkable outcomes. Recently, GNNs incorporating contrastive learning have\ndemonstrated promising performance in handling sparse data problem of\nrecommendation system. However, existing contrastive learning methods still\nhave limitations in addressing the cold-start problem and resisting noise\ninterference especially for multi-behavior recommendation. To mitigate the\naforementioned issues, the present research posits a GNNs based multi-behavior\nrecommendation model MB-SVD that utilizes Singular Value Decomposition (SVD)\ngraphs to enhance model performance. In particular, MB-SVD considers user\npreferences under different behaviors, improving recommendation effectiveness\nwhile better addressing the cold-start problem. Our model introduces an\ninnovative methodology, which subsume multi-behavior contrastive learning\nparadigm to proficiently discern the intricate interconnections among\nheterogeneous manifestations of user behavior and generates SVD graphs to\nautomate the distillation of crucial multi-behavior self-supervised information\nfor robust graph augmentation. Furthermore, the SVD based framework reduces the\nembedding dimensions and computational load. Thorough experimentation showcases\nthe remarkable performance of our proposed MB-SVD approach in multi-behavior\nrecommendation endeavors across diverse real-world datasets.",
        "translated": "图形神经网络(GNN)已经广泛应用于推荐系统领域，为用户提供个性化的推荐，并取得了显著的成果。近年来，引入对比学习的 GNN 在处理推荐系统的稀疏数据问题方面表现出良好的性能。然而，现有的对比学习方法在解决冷启动问题和抵抗噪声干扰方面仍然存在局限性，特别是对于多行为推荐方法。为了缓解上述问题，本研究提出了一个基于 GNN 的多行为推荐模型 MB-SVD，该模型利用奇异值分解(SVD)图增强模型性能。特别地，MB-SVD 考虑了不同行为下的用户偏好，在更好地解决冷启动问题的同时提高了推荐的有效性。我们的模型引入了一种创新的方法，它包含了多行为对比学习范式，能够熟练地识别用户行为异构表现之间错综复杂的相互关系，并生成奇异值分解图，以自动提取关键的多行为自监督信息，用于鲁棒图增强。此外，基于奇异值分解的框架降低了嵌入维数和计算量。全面的实验展示了我们提出的 MB-SVD 方法在不同现实世界数据集的多行为推荐努力中的显著性能。"
    },
    {
        "title": "Towards the TopMost: A Topic Modeling System Toolkit",
        "url": "http://arxiv.org/abs/2309.06908v1",
        "pub_date": "2023-09-13",
        "summary": "Topic models have been proposed for decades with various applications and\nrecently refreshed by the neural variational inference. However, these topic\nmodels adopt totally distinct dataset, implementation, and evaluation settings,\nwhich hinders their quick utilization and fair comparisons. This greatly\nhinders the research progress of topic models. To address these issues, in this\npaper we propose a Topic Modeling System Toolkit (TopMost). Compared to\nexisting toolkits, TopMost stands out by covering a wider range of topic\nmodeling scenarios including complete lifecycles with dataset pre-processing,\nmodel training, testing, and evaluations. The highly cohesive and decoupled\nmodular design of TopMost enables quick utilization, fair comparisons, and\nflexible extensions of different topic models. This can facilitate the research\nand applications of topic models. Our code, tutorials, and documentation are\navailable at https://github.com/bobxwu/topmost.",
        "translated": "主题模型已经提出了几十年的各种应用和最近更新的神经变分推理。然而，这些主题模型采用完全不同的数据集、实现和评估设置，阻碍了它们的快速利用和公平比较。这极大地阻碍了课题模型的研究进展。为了解决这些问题，本文提出了一个主题建模系统工具包(TopMost)。与现有的工具箱相比，TopMost 的突出之处在于它涵盖了更广泛的主题建模场景，包括具有数据集预处理、模型训练、测试和评估的完整生命周期。TopMost 的高度内聚和解耦模块化设计使得不同主题模型的快速利用、公平比较和灵活扩展成为可能。这可以促进主题模型的研究和应用。我们的代码、教程和文档可以在 https://github.com/bobxwu/topmost 上找到。"
    },
    {
        "title": "ProMap: Datasets for Product Mapping in E-commerce",
        "url": "http://arxiv.org/abs/2309.06882v1",
        "pub_date": "2023-09-13",
        "summary": "The goal of product mapping is to decide, whether two listings from two\ndifferent e-shops describe the same products. Existing datasets of matching and\nnon-matching pairs of products, however, often suffer from incomplete product\ninformation or contain only very distant non-matching products. Therefore,\nwhile predictive models trained on these datasets achieve good results on them,\nin practice, they are unusable as they cannot distinguish very similar but\nnon-matching pairs of products. This paper introduces two new datasets for\nproduct mapping: ProMapCz consisting of 1,495 Czech product pairs and ProMapEn\nconsisting of 1,555 English product pairs of matching and non-matching products\nmanually scraped from two pairs of e-shops. The datasets contain both images\nand textual descriptions of the products, including their specifications,\nmaking them one of the most complete datasets for product mapping.\nAdditionally, the non-matching products were selected in two phases, creating\ntwo types of non-matches -- close non-matches and medium non-matches. Even the\nmedium non-matches are pairs of products that are much more similar than\nnon-matches in other datasets -- for example, they still need to have the same\nbrand and similar name and price. After simple data preprocessing, several\nmachine learning algorithms were trained on these and two the other datasets to\ndemonstrate the complexity and completeness of ProMap datasets. ProMap datasets\nare presented as a golden standard for further research of product mapping\nfilling the gaps in existing ones.",
        "translated": "产品映射的目标是决定来自两个不同电子商店的两个列表是否描述了相同的产品。然而，现有的匹配和非匹配产品对数据集往往存在产品信息不完整的问题，或者只包含非常遥远的非匹配产品。因此，虽然对这些数据集进行训练的预测模型在这些数据集上取得了良好的结果，但在实践中，它们是不可用的，因为它们无法区分非常相似但不匹配的产品对。本文介绍了两个新的产品地图数据集: 由1,495对捷克产品组成的 ProMapCz 和由从两对电子商店手工刮取的1,555对匹配和不匹配产品组成的英文产品组成的 ProMapEn。这些数据集包含产品的图像和文本描述，包括它们的规范，使它们成为产品映射最完整的数据集之一。此外，非匹配产品分两个阶段进行选择，产生两种类型的非匹配——近似非匹配和中等非匹配。即使是中度不匹配的产品对也比其他数据集中的不匹配产品对更相似——例如，它们仍然需要具有相同的品牌和相似的名称和价格。在简单的数据预处理后，对这两个数据集和另外两个数据集进行了机器学习算法训练，以验证 ProMap 数据集的复杂性和完整性。ProMap 数据集是进一步研究产品地图填补现有空白的黄金标准。"
    },
    {
        "title": "RAIN: Your Language Models Can Align Themselves without Finetuning",
        "url": "http://arxiv.org/abs/2309.07124v1",
        "pub_date": "2023-09-13",
        "summary": "Large language models (LLMs) often demonstrate inconsistencies with human\npreferences. Previous research gathered human preference data and then aligned\nthe pre-trained models using reinforcement learning or instruction tuning, the\nso-called finetuning step. In contrast, aligning frozen LLMs without any extra\ndata is more appealing. This work explores the potential of the latter setting.\nWe discover that by integrating self-evaluation and rewind mechanisms,\nunaligned LLMs can directly produce responses consistent with human preferences\nvia self-boosting. We introduce a novel inference method, Rewindable\nAuto-regressive INference (RAIN), that allows pre-trained LLMs to evaluate\ntheir own generation and use the evaluation results to guide backward rewind\nand forward generation for AI safety. Notably, RAIN operates without the need\nof extra data for model alignment and abstains from any training, gradient\ncomputation, or parameter updates; during the self-evaluation phase, the model\nreceives guidance on which human preference to align with through a\nfixed-template prompt, eliminating the need to modify the initial prompt.\nExperimental results evaluated by GPT-4 and humans demonstrate the\neffectiveness of RAIN: on the HH dataset, RAIN improves the harmlessness rate\nof LLaMA 30B over vanilla inference from 82% to 97%, while maintaining the\nhelpfulness rate. Under the leading adversarial attack llm-attacks on Vicuna\n33B, RAIN establishes a new defense baseline by reducing the attack success\nrate from 94% to 19%.",
        "translated": "大型语言模型(LLM)经常表现出与人类偏好的不一致性。先前的研究收集人类偏好数据，然后使用强化学习或指令调整(即所谓的微调步骤)对预先训练的模型进行校准。相比之下，不使用任何额外数据对齐冻结的 LLM 更有吸引力。这项工作探索了后一种设置的潜力。我们发现，通过整合自我评价和倒带机制，不一致的 LLM 可以通过自我提升直接产生与人类偏好一致的反应。介绍了一种新的推理方法——可逆自回归推理(RAIN) ，该方法允许预训练的 LLM 评估自己的生成，并利用评估结果指导人工智能安全的倒退和正向生成。值得注意的是，RAIN 不需要额外的数据来进行模型对齐，并且不需要任何训练，梯度计算或参数更新; 在自我评估阶段，模型通过固定模板提示符接受指导，消除了修改初始提示符的需要。GPT-4和人体实验结果证明了 RAIN 的有效性: 在 HH 数据集上，RAIN 使 LLaMA 30B 的无害率从香草推断的82% 提高到97% ，同时保持了有益率。在针对骆驼33B 的主要对手攻击中，RAIN 通过将攻击成功率从94% 降低到19% ，建立了一个新的防御基线。"
    },
    {
        "title": "Sight Beyond Text: Multi-Modal Training Enhances LLMs in Truthfulness\n  and Ethics",
        "url": "http://arxiv.org/abs/2309.07120v1",
        "pub_date": "2023-09-13",
        "summary": "Multi-modal large language models (MLLMs) are trained based on large language\nmodels (LLM), with an enhanced capability to comprehend multi-modal inputs and\ngenerate textual responses. While they excel in multi-modal tasks, the pure NLP\nabilities of MLLMs are often underestimated and left untested. In this study,\nwe get out of the box and unveil an intriguing characteristic of MLLMs -- our\npreliminary results suggest that visual instruction tuning, a prevailing\nstrategy for transitioning LLMs into MLLMs, unexpectedly and interestingly\nhelps models attain both improved truthfulness and ethical alignment in the\npure NLP context. For example, a visual-instruction-tuned LLaMA2 7B model\nsurpasses the performance of the LLaMA2-chat 7B model, fine-tuned with over one\nmillion human annotations, on TruthfulQA-mc and Ethics benchmarks. Further\nanalysis reveals that the improved alignment can be attributed to the superior\ninstruction quality inherent to visual-text data. In releasing our code at\ngithub.com/UCSC-VLAA/Sight-Beyond-Text, we aspire to foster further exploration\ninto the intrinsic value of visual-text synergies and, in a broader scope,\nmulti-modal interactions in alignment research.",
        "translated": "多模态大语言模型(MLLM)是基于大语言模型(LLM)进行训练的，具有更强的理解多模态输入和产生文本响应的能力。虽然他们擅长多模态任务，但是 MLLM 的纯自然语言处理能力常常被低估，未经测试。在这项研究中，我们打开盒子，揭示了 MLLM 的一个有趣的特征——我们的初步结果表明，视觉教学调整，一个普遍的策略过渡到 MLLM 的 LLM，意外和有趣的帮助模型获得改善的真实性和伦理一致性在纯 NLP 的背景下。例如，可视化指令调优的 LLaMA27B 模型超过了在 TruthfulQA-mc 和道德基准上用超过100万人工注释进行微调的 LLaMA2-chat 7B 模型的性能。进一步的分析表明，改进的对齐可以归因于优越的教学质量固有的视觉文本数据。在 github.com/ucsc-vlaa/sight-beyond-text 发布我们的代码时，我们渴望促进对视觉文本协同作用的内在价值的进一步探索，以及在更广泛的范围内，对齐研究中的多模式互动。"
    },
    {
        "title": "Mitigating Hallucinations and Off-target Machine Translation with\n  Source-Contrastive and Language-Contrastive Decoding",
        "url": "http://arxiv.org/abs/2309.07098v1",
        "pub_date": "2023-09-13",
        "summary": "Hallucinations and off-target translation remain unsolved problems in machine\ntranslation, especially for low-resource languages and massively multilingual\nmodels. In this paper, we introduce methods to mitigate both failure cases with\na modified decoding objective, without requiring retraining or external models.\nIn source-contrastive decoding, we search for a translation that is probable\ngiven the correct input, but improbable given a random input segment,\nhypothesising that hallucinations will be similarly probable given either. In\nlanguage-contrastive decoding, we search for a translation that is probable,\nbut improbable given the wrong language indicator token. In experiments on\nM2M-100 (418M) and SMaLL-100, we find that these methods effectively suppress\nhallucinations and off-target translations, improving chrF2 by 1.7 and 1.4\npoints on average across 57 tested translation directions. In a proof of\nconcept on English--German, we also show that we can suppress off-target\ntranslations with the Llama 2 chat models, demonstrating the applicability of\nthe method to machine translation with LLMs. We release our source code at\nhttps://github.com/ZurichNLP/ContraDecode.",
        "translated": "幻觉和脱靶翻译仍然是机器翻译中尚未解决的问题，特别是在低资源语言和大规模多语言模型中。在本文中，我们介绍的方法，以减轻这两种失败的情况与一个修改的解码目标，无需再训练或外部模型。在源码对比译码中，我们寻找一种翻译，这种翻译在输入正确的情况下是可能的，但在随机输入的情况下是不可能的，我们假设幻觉在输入正确的情况下也是同样可能的。在语言对比译码中，我们寻找一种可能性大，但是由于语言指示符错误而不可能的译文。在 M2M-100(418M)和 SMALL-100的实验中，我们发现这些方法有效地抑制了幻觉和脱靶翻译，在57个测试翻译方向上平均提高了 chrF21.7和1.4个点。在关于英语-德语的概念证明中，我们还证明了我们可以用 Llama2聊天模型来抑制脱靶翻译，证明了该方法对 LLM 机器翻译的适用性。我们在 https://github.com/zurichnlp/contradecode 发布源代码。"
    },
    {
        "title": "Can Whisper perform speech-based in-context learning",
        "url": "http://arxiv.org/abs/2309.07081v1",
        "pub_date": "2023-09-13",
        "summary": "This paper investigates the in-context learning abilities of the Whisper\nautomatic speech recognition (ASR) models released by OpenAI. A novel\nspeech-based in-context learning (SICL) approach is proposed for test-time\nadaptation, which can reduce the word error rates (WERs) with only a small\nnumber of labelled speech samples without gradient descent. Language-level\nadaptation experiments using Chinese dialects showed that when applying SICL to\nisolated word ASR, consistent and considerable relative WER reductions can be\nachieved using Whisper models of any size on two dialects, which is on average\n32.3%. A k-nearest-neighbours-based in-context example selection technique can\nbe applied to further improve the efficiency of SICL, which can increase the\naverage relative WER reduction to 36.4%. The findings are verified using\nspeaker adaptation or continuous speech recognition tasks, and both achieved\nconsiderable relative WER reductions. Detailed quantitative analyses are also\nprovided to shed light on SICL's adaptability to phonological variances and\ndialect-specific lexical nuances.",
        "translated": "本文研究了 OpenAI 发布的 Whisper 自动语音识别(ASR)模型的语境学习能力。针对测试时间适应问题，提出了一种新的基于语音的上下文学习(sICL)方法，该方法只需少量没有梯度下降法的标记语音样本，就可以降低单词错误率(WER)。使用汉语方言进行的语言水平适应实验表明，当将 SICL 应用于孤立词 ASR 时，在两种方言上使用任意大小的 Whisper 模型均可实现一致且相对较大的 WER 降低，平均降低率为32.3% 。基于 k 最近邻的上下文示例选择技术可以进一步提高 SICL 的效率，使平均相对 WER 降低达到36.4% 。这些发现通过使用说话人适应或连续语音识别任务得到了验证，并且都取得了相当大的相对 WER 降低。本文还对 SICL 在语音变异和方言词汇细微差别方面的适应性进行了详细的定量分析。"
    },
    {
        "title": "SafetyBench: Evaluating the Safety of Large Language Models with\n  Multiple Choice Questions",
        "url": "http://arxiv.org/abs/2309.07045v1",
        "pub_date": "2023-09-13",
        "summary": "With the rapid development of Large Language Models (LLMs), increasing\nattention has been paid to their safety concerns. Consequently, evaluating the\nsafety of LLMs has become an essential task for facilitating the broad\napplications of LLMs. Nevertheless, the absence of comprehensive safety\nevaluation benchmarks poses a significant impediment to effectively assess and\nenhance the safety of LLMs. In this work, we present SafetyBench, a\ncomprehensive benchmark for evaluating the safety of LLMs, which comprises\n11,435 diverse multiple choice questions spanning across 7 distinct categories\nof safety concerns. Notably, SafetyBench also incorporates both Chinese and\nEnglish data, facilitating the evaluation in both languages. Our extensive\ntests over 25 popular Chinese and English LLMs in both zero-shot and few-shot\nsettings reveal a substantial performance advantage for GPT-4 over its\ncounterparts, and there is still significant room for improving the safety of\ncurrent LLMs. We believe SafetyBench will enable fast and comprehensive\nevaluation of LLMs' safety, and foster the development of safer LLMs. Data and\nevaluation guidelines are available at https://github.com/thu-coai/SafetyBench.\nSubmission entrance and leaderboard are available at\nhttps://llmbench.ai/safety.",
        "translated": "随着大型语言模型(LLM)的迅速发展，其安全性越来越受到人们的关注。因此，评价有限元模型的安全性已成为促进有限元模型广泛应用的重要任务。然而，缺乏全面的安全评估基准，严重阻碍了有效评估和加强长期管理措施的安全。在这项工作中，我们提出了 SafetyBench，一个全面的基准，用于评估 LLM 的安全性，它包括11,435个不同的选择题，跨越7个不同类别的安全问题。值得注意的是，SafetyBench 还整合了中文和英文数据，便于用两种语言进行评估。我们对25种流行的中文和英文 LLM 进行了广泛的测试，包括零射击和少射击设置，结果显示 GPT-4相对于同类产品具有显著的性能优势，目前 LLM 的安全性还有很大的提高空间。我们相信 SafetyBench 将能够对 LLM 的安全性进行快速和全面的评估，并促进更安全 LLM 的发展。数据及评估指引可于 https://github.com/thu-coai/safetybench 索取。参赛门票及排行榜于 https://llmbench.ai/safety 备取。"
    },
    {
        "title": "How (Not) to Use Sociodemographic Information for Subjective NLP Tasks",
        "url": "http://arxiv.org/abs/2309.07034v1",
        "pub_date": "2023-09-13",
        "summary": "Annotators' sociodemographic backgrounds (i.e., the individual compositions\nof their gender, age, educational background, etc.) have a strong impact on\ntheir decisions when working on subjective NLP tasks, such as hate speech\ndetection. Often, heterogeneous backgrounds result in high disagreements. To\nmodel this variation, recent work has explored sociodemographic prompting, a\ntechnique, which steers the output of prompt-based models towards answers that\nhumans with specific sociodemographic profiles would give. However, the\navailable NLP literature disagrees on the efficacy of this technique -- it\nremains unclear, for which tasks and scenarios it can help and evaluations are\nlimited to specific tasks only. We address this research gap by presenting the\nlargest and most comprehensive study of sociodemographic prompting today.\nConcretely, we evaluate several prompt formulations across seven datasets and\nsix instruction-tuned model families. We find that (1) while sociodemographic\nprompting can be beneficial for improving zero-shot learning in subjective NLP\ntasks, (2) its outcomes largely vary for different model types, sizes, and\ndatasets, (3) are subject to large variance with regards to prompt\nformulations. Thus, sociodemographic prompting is not a reliable proxy for\ntraditional data annotation with a sociodemographically heterogeneous group of\nannotators. Instead, we propose (4) to use it for identifying ambiguous\ninstances resulting in more informed annotation efforts.",
        "translated": "注释者的社会人口背景(即，他们的性别、年龄、教育背景等的个人构成)对他们在处理主观 NLP 任务时的决策有很大的影响，例如仇恨语音检测。通常，异质背景会导致很大的分歧。为了模拟这种变化，最近的工作已经探索了社会人口学的提示，一种技术，它引导基于提示的模型输出到具有特定社会人口学特征的人会给出的答案。然而，现有的自然语言处理文献对这种技术的有效性持有不同意见——目前还不清楚，它对哪些任务和场景有帮助，并且评估仅限于特定的任务。我们通过展示当今社会人口学领域规模最大、最全面的研究来弥补这一研究差距。具体来说，我们评估了七个数据集和六个指令调优模型族中的几个提示公式。我们发现(1)虽然社会人口统计学提示可以有利于改善主观 NLP 任务中的零击学习，(2)其结果在不同的模型类型，大小和数据集中差异很大，(3)受到很大的方差关于及时公式。因此，社会人口学提示不是传统数据注释与社会人口学异质性的注释者群体的可靠代理。相反，我们建议(4)使用它来识别模棱两可的实例，从而产生更明智的注释工作。"
    },
    {
        "title": "Beyond original Research Articles Categorization via NLP",
        "url": "http://arxiv.org/abs/2309.07020v1",
        "pub_date": "2023-09-13",
        "summary": "This work proposes a novel approach to text categorization -- for unknown\ncategories -- in the context of scientific literature, using Natural Language\nProcessing techniques. The study leverages the power of pre-trained language\nmodels, specifically SciBERT, to extract meaningful representations of\nabstracts from the ArXiv dataset. Text categorization is performed using the\nK-Means algorithm, and the optimal number of clusters is determined based on\nthe Silhouette score. The results demonstrate that the proposed approach\ncaptures subject information more effectively than the traditional arXiv\nlabeling system, leading to improved text categorization. The approach offers\npotential for better navigation and recommendation systems in the rapidly\ngrowing landscape of scientific research literature.",
        "translated": "这项工作提出了一个新的方法，文本分类-未知类别-在科学文献的背景下，使用自然语言处理技术。这项研究利用预先训练的语言模型，特别是 SciBERT 的力量，从 ArXiv 数据集中提取有意义的摘要表示。使用 K-Means 算法进行文本分类，并根据剪影得分确定最佳聚类数。实验结果表明，该方法比传统的 arXiv 标注系统更有效地获取主题信息，从而改进了文本分类。这种方法为在迅速增长的科学研究文献领域建立更好的导航和推荐系统提供了潜力。"
    },
    {
        "title": "OYXOY: A Modern NLP Test Suite for Modern Greek",
        "url": "http://arxiv.org/abs/2309.07009v1",
        "pub_date": "2023-09-13",
        "summary": "This paper serves as a foundational step towards the development of a\nlinguistically motivated and technically relevant evaluation suite for Greek\nNLP. We initiate this endeavor by introducing four expert-verified evaluation\ntasks, specifically targeted at natural language inference, word sense\ndisambiguation (through example comparison or sense selection) and metaphor\ndetection. More than language-adapted replicas of existing tasks, we contribute\ntwo innovations which will resonate with the broader resource and evaluation\ncommunity. Firstly, our inference dataset is the first of its kind, marking not\njust \\textit{one}, but rather \\textit{all} possible inference labels,\naccounting for possible shifts due to e.g. ambiguity or polysemy. Secondly, we\ndemonstrate a cost-efficient method to obtain datasets for under-resourced\nlanguages. Using ChatGPT as a language-neutral parser, we transform the\nDictionary of Standard Modern Greek into a structured format, from which we\nderive the other three tasks through simple projections. Alongside each task,\nwe conduct experiments using currently available state of the art machinery.\nOur experimental baselines affirm the challenging nature of our tasks and\nhighlight the need for expedited progress in order for the Greek NLP ecosystem\nto keep pace with contemporary mainstream research.",
        "translated": "本文为希腊语自然语言处理的语言动机和技术相关的评价套件的发展提供了基础性的一步。我们通过引入四个经过专家验证的评估任务，特别针对自然语言推理、词义消歧(通过例子比较或意义选择)和隐喻检测。除了对现有任务进行适应语言的复制外，我们还提出了两项创新，这些创新将引起更广泛的资源和评价界的共鸣。首先，我们的推理数据集是同类数据集中的第一个，它不仅标记文本{1} ，而且标记文本{所有}可能的推理标签，解释由于歧义或多义性而可能发生的变化。其次，我们展示了一个成本效益的方法来获取数据集的资源不足的语言。使用 ChatGPT 作为语言中立的解析器，我们将标准现代希腊语词典转换为结构化格式，从中通过简单的投影派生出其他三个任务。除了每项任务，我们还使用当前最先进的机器进行实验。我们的实验基线证实了我们任务的挑战性，并强调需要加快进展，以便希腊自然语言处理生态系统跟上当代主流研究的步伐。"
    },
    {
        "title": "Unsupervised Contrast-Consistent Ranking with Language Models",
        "url": "http://arxiv.org/abs/2309.06991v1",
        "pub_date": "2023-09-13",
        "summary": "Language models contain ranking-based knowledge and are powerful solvers of\nin-context ranking tasks. For instance, they may have parametric knowledge\nabout the ordering of countries by size or may be able to rank reviews by\nsentiment. Recent work focuses on pairwise, pointwise, and listwise prompting\ntechniques to elicit a language model's ranking knowledge. However, we find\nthat even with careful calibration and constrained decoding, prompting-based\ntechniques may not always be self-consistent in the rankings they produce. This\nmotivates us to explore an alternative approach that is inspired by an\nunsupervised probing method called Contrast-Consistent Search (CCS). The idea\nis to train a probing model guided by a logical constraint: a model's\nrepresentation of a statement and its negation must be mapped to contrastive\ntrue-false poles consistently across multiple statements. We hypothesize that\nsimilar constraints apply to ranking tasks where all items are related via\nconsistent pairwise or listwise comparisons. To this end, we extend the binary\nCCS method to Contrast-Consistent Ranking (CCR) by adapting existing ranking\nmethods such as the Max-Margin Loss, Triplet Loss, and Ordinal Regression\nobjective. Our results confirm that, for the same language model, CCR probing\noutperforms prompting and even performs on a par with prompting much larger\nlanguage models.",
        "translated": "语言模型包含基于排序的知识，是上下文排序任务的强大解决方案。例如，它们可能具有按大小排列国家顺序的参数知识，或者可能能够按情绪对审评进行排序。最近的工作集中在成对提示、点提示和列表提示技术，以引出语言模型的排序知识。然而，我们发现，即使仔细校准和约束解码，提示为基础的技术可能并不总是自我一致的排名，他们产生的。这促使我们探索一种替代方法，这种方法受到一种称为对比一致性搜索(CCS)的无监督探测方法的启发。其思想是训练一个由逻辑约束引导的探测模型: 一个模型对一个语句的表示及其否定必须映射到多个语句之间的对比性真假极点。我们假设类似的约束适用于所有项目通过一致的成对或列表比较相关的排序任务。为此，我们将二进制 CCS 方法扩展到对比一致性排序(CCR) ，通过适应现有的排序方法，如最大边际损失，三元组损失和有序回归目标。我们的研究结果证实，对于相同的语言模型，CCR 探测的性能优于提示，甚至与提示更大的语言模型相当。"
    },
    {
        "title": "Ambiguity-Aware In-Context Learning with Large Language Models",
        "url": "http://arxiv.org/abs/2309.07900v1",
        "pub_date": "2023-09-14",
        "summary": "In-context learning (ICL) i.e. showing LLMs only a few task-specific\ndemonstrations has led to downstream gains with no task-specific fine-tuning\nrequired. However, LLMs are sensitive to the choice of prompts, and therefore a\ncrucial research question is how to select good demonstrations for ICL. One\neffective strategy is leveraging semantic similarity between the ICL\ndemonstrations and test inputs by using a text retriever, which however is\nsub-optimal as that does not consider the LLM's existing knowledge about that\ntask. From prior work (Min et al., 2022), we already know that labels paired\nwith the demonstrations bias the model predictions. This leads us to our\nhypothesis whether considering LLM's existing knowledge about the task,\nespecially with respect to the output label space can help in a better\ndemonstration selection strategy. Through extensive experimentation on three\ntext classification tasks, we find that it is beneficial to not only choose\nsemantically similar ICL demonstrations but also to choose those demonstrations\nthat help resolve the inherent label ambiguity surrounding the test example.\nInterestingly, we find that including demonstrations that the LLM previously\nmis-classified and also fall on the test example's decision boundary, brings\nthe most performance gain.",
        "translated": "在上下文学习(ICL) ，即显示 LLM 只有少数任务特定的演示，导致下游收益，没有任务特定的微调需要。然而，LLM 对提示符的选择比较敏感，因此如何为 ICL 选择好的示例是一个关键的研究问题。一个有效的策略是通过使用文本检索器来利用 ICL 演示和测试输入之间的语义相似性，但这是次优的，因为它不考虑 LLM 关于该任务的现有知识。从以前的工作(Min et al。 ，2022) ，我们已经知道标签与演示配对会使模型预测产生偏差。这就引出了我们的假设，即考虑 LLM 关于任务的现有知识，特别是关于输出标签空间的知识，是否有助于更好的演示选择策略。通过对三个文本分类任务的大量实验，我们发现不仅选择语义相似的 ICL 示例，而且选择那些有助于解决测试示例中固有的标签歧义的示例都是有益的。有趣的是，我们发现，包括 LLM 之前错误分类的示例，以及测试示例的决策边界，会带来最大的性能提升。"
    },
    {
        "title": "NineRec: A Benchmark Dataset Suite for Evaluating Transferable\n  Recommendation",
        "url": "http://arxiv.org/abs/2309.07705v1",
        "pub_date": "2023-09-14",
        "summary": "Learning a recommender system model from an item's raw modality features\n(such as image, text, audio, etc.), called MoRec, has attracted growing\ninterest recently. One key advantage of MoRec is that it can easily benefit\nfrom advances in other fields, such as natural language processing (NLP) and\ncomputer vision (CV). Moreover, it naturally supports transfer learning across\ndifferent systems through modality features, known as transferable recommender\nsystems, or TransRec.\n  However, so far, TransRec has made little progress, compared to\ngroundbreaking foundation models in the fields of NLP and CV. The lack of\nlarge-scale, high-quality recommendation datasets poses a major obstacle. To\nthis end, we introduce NineRec, a TransRec dataset suite that includes a\nlarge-scale source domain recommendation dataset and nine diverse target domain\nrecommendation datasets. Each item in NineRec is represented by a text\ndescription and a high-resolution cover image. With NineRec, we can implement\nTransRec models in an end-to-end training manner instead of using pre-extracted\ninvariant features. We conduct a benchmark study and empirical analysis of\nTransRec using NineRec, and our findings provide several valuable insights. To\nsupport further research, we make our code, datasets, benchmarks, and\nleaderboards publicly available at\nhttps://github.com/anonymous?ninerec/NineRec.",
        "translated": "从一个项目的原始形态特征(例如图像、文本、音频等)中学习一个叫做 MoRec 的推荐系统模型，最近引起了人们越来越多的兴趣。MoRec 的一个关键优势是，它可以很容易地受益于其他领域的进步，如自然语言处理(NLP)和计算机视觉(CV)。此外，它通过模态特性自然地支持跨不同系统的转移学习，称为可转移推荐系统，或 TransRec。然而，迄今为止，与自然语言处理(NLP)和连续变形(CV)领域的突破性基础模型相比，TransRec 的进展甚微。缺乏大规模、高质量的推荐数据集是一个主要障碍。为此，我们介绍了 NineRec，这是一个 TransRec 数据集套件，包括一个大规模的源域推荐数据集和九个不同的目标域推荐数据集。NineRec 中的每个条目都由一个文本描述和一个高分辨率的封面图像表示。使用 NineRec，我们可以通过端到端的训练方式实现 TransRec 模型，而不必使用预提取的不变特征。我们使用 NineRec 对 TransRec 进行了基准研究和实证分析，我们的发现提供了一些有价值的见解。为了支持进一步的研究，我们将我们的代码、数据集、基准和排行榜公布于 https://github.com/anonymous?ninerec/ninerec。"
    },
    {
        "title": "A Conversation is Worth A Thousand Recommendations: A Survey of Holistic\n  Conversational Recommender Systems",
        "url": "http://arxiv.org/abs/2309.07682v1",
        "pub_date": "2023-09-14",
        "summary": "Conversational recommender systems (CRS) generate recommendations through an\ninteractive process. However, not all CRS approaches use human conversations as\ntheir source of interaction data; the majority of prior CRS work simulates\ninteractions by exchanging entity-level information. As a result, claims of\nprior CRS work do not generalise to real-world settings where conversations\ntake unexpected turns, or where conversational and intent understanding is not\nperfect. To tackle this challenge, the research community has started to\nexamine holistic CRS, which are trained using conversational data collected\nfrom real-world scenarios. Despite their emergence, such holistic approaches\nare under-explored.\n  We present a comprehensive survey of holistic CRS methods by summarizing the\nliterature in a structured manner. Our survey recognises holistic CRS\napproaches as having three components: 1) a backbone language model, the\noptional use of 2) external knowledge, and/or 3) external guidance. We also\ngive a detailed analysis of CRS datasets and evaluation methods in real\napplication scenarios. We offer our insight as to the current challenges of\nholistic CRS and possible future trends.",
        "translated": "会话推荐系统(CRS)通过一个交互式的过程产生推荐。然而，并非所有的 CRS 方法都使用人类对话作为交互数据的来源; 以前的大多数 CRS 工作都是通过交换实体级信息来模拟交互的。因此，先前 CRS 工作的主张并没有概括到现实世界的环境中，那里的对话会出现意想不到的转折，或者对话和意图的理解并不完美。为了应对这一挑战，研究团体已经开始研究整体 CRS，使用从现实世界情景中收集的会话数据对 CRS 进行培训。尽管这些方法已经出现，但人们对它们的探索还不够。我们提出了一个综合调查的整体 CRS 方法，通过结构化的方式总结文献。我们的调查认为整体 CRS 方法有三个组成部分: 1)骨干语言模型，可选择的外部知识使用，和/或3)外部指导。本文还详细分析了 CRS 数据集及其在实际应用场景中的评价方法。我们提供我们的洞察力，目前的挑战，整体 CRS 和可能的未来趋势。"
    },
    {
        "title": "Feature Engineering in Learning-to-Rank for Community Question Answering\n  Task",
        "url": "http://arxiv.org/abs/2309.07610v1",
        "pub_date": "2023-09-14",
        "summary": "Community question answering (CQA) forums are Internet-based platforms where\nusers ask questions about a topic and other expert users try to provide\nsolutions. Many CQA forums such as Quora, Stackoverflow, Yahoo!Answer,\nStackExchange exist with a lot of user-generated data. These data are leveraged\nin automated CQA ranking systems where similar questions (and answers) are\npresented in response to the query of the user. In this work, we empirically\ninvestigate a few aspects of this domain. Firstly, in addition to traditional\nfeatures like TF-IDF, BM25 etc., we introduce a BERT-based feature that\ncaptures the semantic similarity between the question and answer. Secondly,\nmost of the existing research works have focused on features extracted only\nfrom the question part; features extracted from answers have not been explored\nextensively. We combine both types of features in a linear fashion. Thirdly,\nusing our proposed concepts, we conduct an empirical investigation with\ndifferent rank-learning algorithms, some of which have not been used so far in\nCQA domain. On three standard CQA datasets, our proposed framework achieves\nstate-of-the-art performance. We also analyze importance of the features we use\nin our investigation. This work is expected to guide the practitioners to\nselect a better set of features for the CQA retrieval task.",
        "translated": "社区问答(CQA)论坛是一个基于互联网的平台，用户可以在这个平台上就某个主题提出问题，其他专家用户可以尝试提供解决方案。许多 CQA 论坛，如 Quora，Stackoverflow，Yahoo! Answer，StackExchange，都存在大量用户生成的数据。这些数据在自动化的 CQA 排序系统中被利用，在这些系统中，相似的问题(和答案)被用来响应用户的查询。在这项工作中，我们实证调查了这个领域的几个方面。首先，除了传统的特征如 TF-IDF、 BM25等之外，我们还引入了一个基于 BERT 的特征来捕捉问题和答案之间的语义相似性。其次，现有的研究大多集中在问题部分的特征提取上，从答案中提取的特征还没有得到广泛的研究。我们以线性方式结合了这两种类型的特性。第三，利用我们提出的概念，我们对不同的排序学习算法进行了实证研究，其中一些算法在 CQA 领域还没有得到应用。在三个标准的 CQA 数据集上，我们提出的框架实现了最先进的性能。我们还分析了我们在调查中使用的特性的重要性。这项工作可望指导从业人员为 CQA 检索任务选择一组更好的特性。"
    },
    {
        "title": "Zero-shot Audio Topic Reranking using Large Language Models",
        "url": "http://arxiv.org/abs/2309.07606v1",
        "pub_date": "2023-09-14",
        "summary": "The Multimodal Video Search by Examples (MVSE) project investigates using\nvideo clips as the query term for information retrieval, rather than the more\ntraditional text query. This enables far richer search modalities such as\nimages, speaker, content, topic, and emotion. A key element for this process is\nhighly rapid, flexible, search to support large archives, which in MVSE is\nfacilitated by representing video attributes by embeddings. This work aims to\nmitigate any performance loss from this rapid archive search by examining\nreranking approaches. In particular, zero-shot reranking methods using large\nlanguage models are investigated as these are applicable to any video archive\naudio content. Performance is evaluated for topic-based retrieval on a publicly\navailable video archive, the BBC Rewind corpus. Results demonstrate that\nreranking can achieve improved retrieval ranking without the need for any\ntask-specific training data.",
        "translated": "多模式视频示例搜索(multimodalVideo Search by example，MVSE)项目研究使用视频剪辑作为信息检索的查询词，而不是更传统的文本查询。这使得搜索模式更加丰富，如图像、演讲者、内容、主题和情感。这个过程的一个关键因素是高速、灵活的搜索，以支持大型的档案，在 MVSE 中，通过嵌入来表示视频属性，方便了搜索。这项工作旨在通过检查重新排序方法来减轻这种快速归档搜索的性能损失。特别是使用大型语言模型的零镜头重新排序方法，因为这些方法适用于任何视频档案音频内容。性能评估的主题为基础的检索公开可用的视频档案，英国广播公司倒带语料库。结果表明，重新排序可以在不需要任何特定任务的训练数据的情况下实现改进的检索排序。"
    },
    {
        "title": "MMICL: Empowering Vision-language Model with Multi-Modal In-Context\n  Learning",
        "url": "http://arxiv.org/abs/2309.07915v1",
        "pub_date": "2023-09-14",
        "summary": "Starting from the resurgence of deep learning, vision-language models (VLMs)\nbenefiting from large language models (LLMs) have never been so popular.\nHowever, while LLMs can utilize extensive background knowledge and task\ninformation with in-context learning, most VLMs still struggle with\nunderstanding complex multi-modal prompts with multiple images. The issue can\ntraced back to the architectural design of VLMs or pre-training data.\nSpecifically, the current VLMs primarily emphasize utilizing multi-modal data\nwith a single image some, rather than multi-modal prompts with interleaved\nmultiple images and text. Even though some newly proposed VLMs could handle\nuser prompts with multiple images, pre-training data does not provide more\nsophisticated multi-modal prompts than interleaved image and text crawled from\nthe web. We propose MMICL to address the issue by considering both the model\nand data perspectives. We introduce a well-designed architecture capable of\nseamlessly integrating visual and textual context in an interleaved manner and\nMIC dataset to reduce the gap between the training data and the complex user\nprompts in real-world applications, including: 1) multi-modal context with\ninterleaved images and text, 2) textual references for each image, and 3)\nmulti-image data with spatial, logical, or temporal relationships. Our\nexperiments confirm that MMICL achieves new stat-of-the-art zero-shot and\nfew-shot performance on a wide range of general vision-language tasks,\nespecially for complex reasoning benchmarks including MME and MMBench. Our\nanalysis demonstrates that MMICL effectively deals with the challenge of\ncomplex multi-modal prompt understanding. The experiments on ScienceQA-IMG also\nshow that MMICL successfully alleviates the issue of language bias in VLMs,\nwhich we believe is the reason behind the advanced performance of MMICL.",
        "translated": "从深度学习的复苏开始，受益于大型语言模型(LLM)的视觉语言模型(VLM)从未如此流行过。然而，虽然 LLM 可以利用广泛的背景知识和任务信息进行上下文学习，但大多数 VLM 仍然难以理解复杂的多模态提示与多图像。这个问题可以追溯到 VLM 的架构设计或预训练数据。具体而言，目前的 VLM 主要强调利用单个图像的多模态数据，而不是利用交错的多个图像和文本的多模态提示。尽管一些新提出的 VLM 可以处理多个图像的用户提示，但是预训练数据并不能提供比从网络上抓取的交错图像和文本更复杂的多模态提示。我们建议 MMICL 通过考虑模型和数据透视图来解决这个问题。我们引入了一个设计良好的体系结构，能够以交错的方式无缝集成视觉和文本上下文和 MIC 数据集，以减少训练数据和真实世界应用中的复杂用户提示之间的差距，包括: 1)多模态上下文与交错的图像和文本，2)每个图像的文本参考，3)多图像数据与空间，逻辑或时间关系。我们的实验证实，MMICL 在广泛的一般视觉语言任务中，尤其是在 MME 和 MMBench 等复杂的推理基准测试中，实现了最先进的零镜头和少镜头性能。我们的分析表明，MMICL 有效地应对了复杂的多模态及时理解的挑战。在 ScienceQA-IMG 上的实验也表明，MMICL 成功地缓解了 VLM 中的语言偏差问题，我们认为这是 MMICL 性能提高的原因。"
    },
    {
        "title": "Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language\n  Models that Follow Instructions",
        "url": "http://arxiv.org/abs/2309.07875v1",
        "pub_date": "2023-09-14",
        "summary": "Training large language models to follow instructions makes them perform\nbetter on a wide range of tasks, generally becoming more helpful. However, a\nperfectly helpful model will follow even the most malicious instructions and\nreadily generate harmful content. In this paper, we raise concerns over the\nsafety of models that only emphasize helpfulness, not safety, in their\ninstruction-tuning. We show that several popular instruction-tuned models are\nhighly unsafe. Moreover, we show that adding just 3% safety examples (a few\nhundred demonstrations) in the training set when fine-tuning a model like LLaMA\ncan substantially improve their safety. Our safety-tuning does not make models\nsignificantly less capable or helpful as measured by standard benchmarks.\nHowever, we do find a behavior of exaggerated safety, where too much\nsafety-tuning makes models refuse to respond to reasonable prompts that\nsuperficially resemble unsafe ones. Our study sheds light on trade-offs in\ntraining LLMs to follow instructions and exhibit safe behavior.",
        "translated": "训练大型语言模型来遵循指令可以使它们在广泛的任务中表现得更好，通常会变得更有帮助。然而，一个非常有用的模型甚至会遵循最恶意的指令，并容易生成有害的内容。在这篇文章中，我们提出了对模型的安全性的关注，只强调有益性，而不是安全性，在他们的教学调整。我们展示了几个流行的指令调优模型是非常不安全的。此外，我们表明，只要在训练集中添加3% 的安全示例(几百个示例) ，就可以对 LLaMA 这样的模型进行微调，从而大大提高它们的安全性。我们的安全调整不会使模型的能力或帮助明显降低，以标准基准衡量。然而，我们确实发现了一种夸大安全的行为，过多的安全调整使得模型拒绝对表面上类似于不安全的合理提示做出反应。我们的研究揭示了训练 LLM 时遵守指令和展示安全行为的权衡。"
    },
    {
        "title": "Agents: An Open-source Framework for Autonomous Language Agents",
        "url": "http://arxiv.org/abs/2309.07870v1",
        "pub_date": "2023-09-14",
        "summary": "Recent advances on large language models (LLMs) enable researchers and\ndevelopers to build autonomous language agents that can automatically solve\nvarious tasks and interact with environments, humans, and other agents using\nnatural language interfaces. We consider language agents as a promising\ndirection towards artificial general intelligence and release Agents, an\nopen-source library with the goal of opening up these advances to a wider\nnon-specialist audience. Agents is carefully engineered to support important\nfeatures including planning, memory, tool usage, multi-agent communication, and\nfine-grained symbolic control. Agents is user-friendly as it enables\nnon-specialists to build, customize, test, tune, and deploy state-of-the-art\nautonomous language agents without much coding. The library is also\nresearch-friendly as its modularized design makes it easily extensible for\nresearchers. Agents is available at https://github.com/aiwaves-cn/agents.",
        "translated": "大型语言模型(LLM)的最新进展使研究人员和开发人员能够构建自主语言代理，这些代理能够自动解决各种任务，并使用自然语言接口与环境、人类和其他代理进行交互。我们认为语言代理是人工通用智能和发布代理的一个有希望的方向，一个开源图书馆的目标是向更广泛的非专业读者开放这些进步。代理被精心设计以支持重要特性，包括计划、内存、工具使用、多代理通信和细粒度符号控制。代理是用户友好的，因为它使非专业人员能够构建、定制、测试、调优和部署最先进的自主语言代理，而无需编写大量代码。该图书馆也是研究友好的，因为它的模块化设计使其易于扩展为研究人员。Https://github.com/aiwaves-cn/Agents 有特工。"
    },
    {
        "title": "The Rise and Potential of Large Language Model Based Agents: A Survey",
        "url": "http://arxiv.org/abs/2309.07864v1",
        "pub_date": "2023-09-14",
        "summary": "For a long time, humanity has pursued artificial intelligence (AI) equivalent\nto or surpassing the human level, with AI agents considered a promising vehicle\nfor this pursuit. AI agents are artificial entities that sense their\nenvironment, make decisions, and take actions. Many efforts have been made to\ndevelop intelligent AI agents since the mid-20th century. However, these\nefforts have mainly focused on advancement in algorithms or training strategies\nto enhance specific capabilities or performance on particular tasks. Actually,\nwhat the community lacks is a sufficiently general and powerful model to serve\nas a starting point for designing AI agents that can adapt to diverse\nscenarios. Due to the versatile and remarkable capabilities they demonstrate,\nlarge language models (LLMs) are regarded as potential sparks for Artificial\nGeneral Intelligence (AGI), offering hope for building general AI agents. Many\nresearch efforts have leveraged LLMs as the foundation to build AI agents and\nhave achieved significant progress. We start by tracing the concept of agents\nfrom its philosophical origins to its development in AI, and explain why LLMs\nare suitable foundations for AI agents. Building upon this, we present a\nconceptual framework for LLM-based agents, comprising three main components:\nbrain, perception, and action, and the framework can be tailored to suit\ndifferent applications. Subsequently, we explore the extensive applications of\nLLM-based agents in three aspects: single-agent scenarios, multi-agent\nscenarios, and human-agent cooperation. Following this, we delve into agent\nsocieties, exploring the behavior and personality of LLM-based agents, the\nsocial phenomena that emerge when they form societies, and the insights they\noffer for human society. Finally, we discuss a range of key topics and open\nproblems within the field.",
        "translated": "长期以来，人类一直在追求与人类相当或超越人类水平的人工智能(AI) ，人工智能代理被认为是这一追求的有希望的载体。人工智能代理是感知环境、做出决策和采取行动的人工实体。自20世纪中叶以来，人们为开发智能人工智能代理付出了许多努力。然而，这些努力主要集中在算法或训练策略的进步，以提高特定任务的特定能力或性能。事实上，社区所缺乏的是一个足够通用和强大的模型，作为设计人工智能代理的起点，可以适应不同的情况。大语言模型(LLM)是人工通用智能(AGI)的潜在火花，为构建通用人工智能代理提供了希望。许多研究工作利用 LLM 作为构建 AI 代理的基础，并取得了重大进展。我们从追溯智能体概念的哲学起源到它在人工智能领域的发展，并解释为什么 LLM 是适合人工智能智能的基础。在此基础上，我们为基于 LLM 的代理提供了一个概念框架，包括三个主要组成部分: 大脑、感知和行动，并且框架可以根据不同的应用进行调整。随后，我们探讨了基于 LLM 的代理在单代理场景、多代理场景和人-代理协作三个方面的广泛应用。接下来，我们深入研究代理社会，探索基于 LLM 的代理人的行为和个性，他们形成社会时出现的社会现象，以及他们为人类社会提供的洞察力。最后，我们将讨论该领域的一系列关键主题和未解决的问题。"
    },
    {
        "title": "CiwaGAN: Articulatory information exchange",
        "url": "http://arxiv.org/abs/2309.07861v1",
        "pub_date": "2023-09-14",
        "summary": "Humans encode information into sounds by controlling articulators and decode\ninformation from sounds using the auditory apparatus. This paper introduces\nCiwaGAN, a model of human spoken language acquisition that combines\nunsupervised articulatory modeling with an unsupervised model of information\nexchange through the auditory modality. While prior research includes\nunsupervised articulatory modeling and information exchange separately, our\nmodel is the first to combine the two components. The paper also proposes an\nimproved articulatory model with more interpretable internal representations.\nThe proposed CiwaGAN model is the most realistic approximation of human spoken\nlanguage acquisition using deep learning. As such, it is useful for cognitively\nplausible simulations of the human speech act.",
        "translated": "人类通过控制发音器将信息编码成声音，并利用听觉器官从声音中解码信息。本文介绍了 CiwaGAN 模型，该模型通过听觉模式将无监督的发音建模和无监督的信息交换模型结合起来。以往的研究分别包括无监督发音建模和信息交换，而我们的模型是第一个将两者结合起来的模型。本文还提出了一种具有更多可解释内部表征的改进发音模型。提出的 CiwaGAN 模型是使用深度学习进行人类口语习得的最现实的近似模型。因此，它是有用的认知似是而非的模拟人类言语行为。"
    },
    {
        "title": "ExpertQA: Expert-Curated Questions and Attributed Answers",
        "url": "http://arxiv.org/abs/2309.07852v1",
        "pub_date": "2023-09-14",
        "summary": "As language models are adapted by a more sophisticated and diverse set of\nusers, the importance of guaranteeing that they provide factually correct\ninformation supported by verifiable sources is critical across fields of study\n&amp; professions. This is especially the case for high-stakes fields, such as\nmedicine and law, where the risk of propagating false information is high and\ncan lead to undesirable societal consequences. Previous work studying\nfactuality and attribution has not focused on analyzing these characteristics\nof language model outputs in domain-specific scenarios. In this work, we\npresent an evaluation study analyzing various axes of factuality and\nattribution provided in responses from a few systems, by bringing domain\nexperts in the loop. Specifically, we first collect expert-curated questions\nfrom 484 participants across 32 fields of study, and then ask the same experts\nto evaluate generated responses to their own questions. We also ask experts to\nrevise answers produced by language models, which leads to ExpertQA, a\nhigh-quality long-form QA dataset with 2177 questions spanning 32 fields, along\nwith verified answers and attributions for claims in the answers.",
        "translated": "随着语言模型被更加复杂和多样化的用户群所调整，保证它们提供由可验证来源支持的事实上正确的信息的重要性在各个学习和专业领域都是至关重要的。医学和法律等高风险领域的情况尤其如此，这些领域传播虚假信息的风险很高，可能导致不良的社会后果。以往研究事实和归因的工作没有重点分析特定领域情景下语言模型输出的这些特征。在这项工作中，我们提出了一个评价研究分析各种轴的真实性和归因提供了一些系统的响应，通过让领域专家在回路。具体来说，我们首先从32个研究领域的484名参与者那里收集由专家策划的问题，然后让同一批专家评估他们对自己问题的回答。我们还要求专家修改由语言模型产生的答案，从而产生了一个高质量的长形式 QA 数据集，包含2177个跨越32个领域的问题，以及经过验证的答案和答案中声明的归属。"
    },
    {
        "title": "CATfOOD: Counterfactual Augmented Training for Improving Out-of-Domain\n  Performance and Calibration",
        "url": "http://arxiv.org/abs/2309.07822v1",
        "pub_date": "2023-09-14",
        "summary": "In recent years, large language models (LLMs) have shown remarkable\ncapabilities at scale, particularly at generating text conditioned on a prompt.\nIn our work, we investigate the use of LLMs to augment training data of small\nlanguage models~(SLMs) with automatically generated counterfactual~(CF)\ninstances -- i.e. minimally altered inputs -- in order to improve\nout-of-domain~(OOD) performance of SLMs in the extractive question\nanswering~(QA) setup. We show that, across various LLM generators, such data\naugmentation consistently enhances OOD performance and improves model\ncalibration for both confidence-based and rationale-augmented calibrator\nmodels. Furthermore, these performance improvements correlate with higher\ndiversity of CF instances in terms of their surface form and semantic content.\nFinally, we show that CF augmented models which are easier to calibrate also\nexhibit much lower entropy when assigning importance, indicating that\nrationale-augmented calibrators prefer concise explanations.",
        "translated": "近年来，大型语言模型(LLM)在大规模应用方面表现出了显著的能力，特别是在根据提示语生成文本方面。在我们的工作中，我们研究了利用 LLM 来增强小语言模型 ~ (SLM)的训练数据与自动生成的反事实 ~ (CF)实例-即最小改变的输入-以改善提取问答 ~ (QA)设置中的小语言模型 ~ (SLM)的域外 ~ (OOD)性能。我们表明，在各种 LLM 发生器，这样的数据增强始终提高面向对象的性能和改善模型校准的置信度和基本原理增强校准模型。此外，这些性能改进与 CF 实例在表面形式和语义内容方面的更高多样性相关联。最后，我们表明，CF 增强模型，更容易校准也表现出更低的熵分配重要性，表明理论基础增强校准更喜欢简明的解释。"
    },
    {
        "title": "Text Classification of Cancer Clinical Trial Eligibility Criteria",
        "url": "http://arxiv.org/abs/2309.07812v1",
        "pub_date": "2023-09-14",
        "summary": "Automatic identification of clinical trials for which a patient is eligible\nis complicated by the fact that trial eligibility is stated in natural\nlanguage. A potential solution to this problem is to employ text classification\nmethods for common types of eligibility criteria. In this study, we focus on\nseven common exclusion criteria in cancer trials: prior malignancy, human\nimmunodeficiency virus, hepatitis B, hepatitis C, psychiatric illness,\ndrug/substance abuse, and autoimmune illness. Our dataset consists of 764 phase\nIII cancer trials with these exclusions annotated at the trial level. We\nexperiment with common transformer models as well as a new pre-trained clinical\ntrial BERT model. Our results demonstrate the feasibility of automatically\nclassifying common exclusion criteria. Additionally, we demonstrate the value\nof a pre-trained language model specifically for clinical trials, which yields\nthe highest average performance across all criteria.",
        "translated": "自动识别患者有资格参加的临床试验是复杂的，因为试验资格是用自然语言陈述的。这个问题的一个可能的解决方案是对常见类型的资格标准采用文本分类方法。在这项研究中，我们关注癌症试验中的七个常见排除标准: 既往恶性肿瘤、人类免疫缺陷病毒、乙型肝炎、丙型肝炎、精神疾病、药物/物质滥用和自身免疫性疾病。我们的数据集包括764个 III 期癌症试验，在试验水平注释了这些排除。我们试验与共同的变压器模型以及一个新的预先训练的临床试验 BERT 模型。我们的结果证明了自动分类常见排除标准的可行性。此外，我们证明了一个预先训练的语言模型的价值，特别是临床试验，这产生了最高的平均性能在所有标准。"
    },
    {
        "title": "Pop Quiz! Do Pre-trained Code Models Possess Knowledge of Correct API\n  Names?",
        "url": "http://arxiv.org/abs/2309.07804v1",
        "pub_date": "2023-09-14",
        "summary": "Recent breakthroughs in pre-trained code models, such as CodeBERT and Codex,\nhave shown their superior performance in various downstream tasks. The\ncorrectness and unambiguity of API usage among these code models are crucial\nfor achieving desirable program functionalities, requiring them to learn\nvarious API fully qualified names structurally and semantically. Recent studies\nreveal that even state-of-the-art pre-trained code models struggle with\nsuggesting the correct APIs during code generation. However, the reasons for\nsuch poor API usage performance are barely investigated. To address this\nchallenge, we propose using knowledge probing as a means of interpreting code\nmodels, which uses cloze-style tests to measure the knowledge stored in models.\nOur comprehensive study examines a code model's capability of understanding API\nfully qualified names from two different perspectives: API call and API import.\nSpecifically, we reveal that current code models struggle with understanding\nAPI names, with pre-training strategies significantly affecting the quality of\nAPI name learning. We demonstrate that natural language context can assist code\nmodels in locating Python API names and generalize Python API name knowledge to\nunseen data. Our findings provide insights into the limitations and\ncapabilities of current pre-trained code models, and suggest that incorporating\nAPI structure into the pre-training process can improve automated API usage and\ncode representations. This work provides significance for advancing code\nintelligence practices and direction for future studies. All experiment\nresults, data and source code used in this work are available at\n\\url{https://doi.org/10.5281/zenodo.7902072}.",
        "translated": "最近在预训练代码模型方面的突破，如 CodeBERT 和 Codex，已经显示了它们在各种下游任务中的优越性能。这些代码模型中 API 使用的正确性和明确性对于实现理想的程序功能至关重要，需要它们从结构和语义上学习各种 API 完全限定名。最近的研究表明，即使是最先进的预先训练的代码模型，在代码生成过程中也很难提出正确的 API。然而，对于 API 使用性能如此差的原因几乎没有进行过调查。为了解决这个问题，我们建议使用知识探测作为解释代码模型的一种手段，它使用完形填空式测试来度量模型中存储的知识。我们的全面研究从两个不同的角度检查了代码模型理解 API 完全限定名的能力: API 调用和 API 导入。具体来说，我们揭示了当前的代码模型在理解 API 名称方面的困难，预训练策略显著地影响了 API 名称学习的质量。我们演示了自然语言上下文可以帮助代码模型定位 Python API 名称，并将 Python API 名称知识推广到未见数据。我们的研究结果提供了当前预训练代码模型的局限性和能力的见解，并建议将 API 结构纳入预训练过程可以提高自动化的 API 使用和代码表示。本文的工作为进一步推进代码智能实践提供了重要意义，并为今后的研究提供了方向。所有的实验结果、数据和源代码都可以在 url { https://doi.org/10.5281/zenodo.7902072}上找到。"
    },
    {
        "title": "When do Generative Query and Document Expansions Fail? A Comprehensive\n  Study Across Methods, Retrievers, and Datasets",
        "url": "http://arxiv.org/abs/2309.08541v1",
        "pub_date": "2023-09-15",
        "summary": "Using large language models (LMs) for query or document expansion can improve\ngeneralization in information retrieval. However, it is unknown whether these\ntechniques are universally beneficial or only effective in specific settings,\nsuch as for particular retrieval models, dataset domains, or query types. To\nanswer this, we conduct the first comprehensive analysis of LM-based expansion.\nWe find that there exists a strong negative correlation between retriever\nperformance and gains from expansion: expansion improves scores for weaker\nmodels, but generally harms stronger models. We show this trend holds across a\nset of eleven expansion techniques, twelve datasets with diverse distribution\nshifts, and twenty-four retrieval models. Through qualitative error analysis,\nwe hypothesize that although expansions provide extra information (potentially\nimproving recall), they add additional noise that makes it difficult to discern\nbetween the top relevant documents (thus introducing false positives). Our\nresults suggest the following recipe: use expansions for weaker models or when\nthe target dataset significantly differs from training corpus in format;\notherwise, avoid expansions to keep the relevance signal clear.",
        "translated": "使用大型语言模型(LMs)进行查询或文档扩展可以提高信息检索的泛化能力。但是，目前还不清楚这些技术是否普遍有益，或者仅在特定的环境中有效，例如对于特定的检索模型、数据集域或查询类型。为了回答这个问题，我们首先对基于 LM 的扩展进行了全面的分析。我们发现在检索性能和扩展收益之间存在强烈的负相关: 扩展提高了较弱模型的分数，但通常会损害较强模型。我们展示了这种趋势在11种扩展技术、12种不同分布变化的数据集和24种检索模型中都有效。通过定性错误分析，我们假设，尽管扩展提供了额外的信息(可能提高召回率) ，但它们增加了额外的噪音，使得难以辨别顶级相关文档(因此引入了假阳性)。我们的研究结果建议采用以下方法: 对较弱的模型使用扩展，或者当目标数据集在格式上明显不同于训练语料集时使用扩展; 否则，避免使用扩展以保持相关信号清晰。"
    },
    {
        "title": "SilverRetriever: Advancing Neural Passage Retrieval for Polish Question\n  Answering",
        "url": "http://arxiv.org/abs/2309.08469v1",
        "pub_date": "2023-09-15",
        "summary": "Modern open-domain question answering systems often rely on accurate and\nefficient retrieval components to find passages containing the facts necessary\nto answer the question. Recently, neural retrievers have gained popularity over\nlexical alternatives due to their superior performance. However, most of the\nwork concerns popular languages such as English or Chinese. For others, such as\nPolish, few models are available. In this work, we present SilverRetriever, a\nneural retriever for Polish trained on a diverse collection of manually or\nweakly labeled datasets. SilverRetriever achieves much better results than\nother Polish models and is competitive with larger multilingual models.\nTogether with the model, we open-source five new passage retrieval datasets.",
        "translated": "现代开放领域的问答系统往往依赖于准确而有效的检索组件来寻找包含回答问题所必需的事实的段落。近年来，神经检索器由于其优越的性能而越来越受到人们的欢迎。然而，大部分的工作涉及流行语言，如英语或汉语。对于波兰人等其他国家来说，几乎没有什么型号可供选择。在这项工作中，我们介绍了 SilverRetriever，一个神经检索波兰训练在一个手动或弱标记数据集的不同集合。SilverRetriever 比其他波兰语模型获得了更好的结果，并且与更大的多语言模型具有竞争力。结合该模型，我们开源了五个新的文章检索数据集。"
    },
    {
        "title": "Explaining Search Result Stances to Opinionated People",
        "url": "http://arxiv.org/abs/2309.08460v1",
        "pub_date": "2023-09-15",
        "summary": "People use web search engines to find information before forming opinions,\nwhich can lead to practical decisions with different levels of impact. The\ncognitive effort of search can leave opinionated users vulnerable to cognitive\nbiases, e.g., the confirmation bias. In this paper, we investigate whether\nstance labels and their explanations can help users consume more diverse search\nresults. We automatically classify and label search results on three topics\n(i.e., intellectual property rights, school uniforms, and atheism) as against,\nneutral, and in favor, and generate explanations for these labels. In a user\nstudy (N =203), we then investigate whether search result stance bias (balanced\nvs biased) and the level of explanation (plain text, label only, label and\nexplanation) influence the diversity of search results clicked. We find that\nstance labels and explanations lead to a more diverse search result\nconsumption. However, we do not find evidence for systematic opinion change\namong users in this context. We believe these results can help designers of\nsearch engines to make more informed design decisions.",
        "translated": "人们在形成意见之前使用网络搜索引擎来查找信息，这可能导致不同程度影响的实际决策。搜索的认知努力会使固执己见的用户容易受到认知偏差的影响，例如，确认偏差。在本文中，我们调查是否立场标签和他们的解释可以帮助用户消费更多样化的搜索结果。我们自动分类和标签搜索结果的三个主题(即，知识产权，校服，和无神论)反对，中立和赞成，并生成这些标签的解释。在一项用户研究(N = 203)中，我们然后调查搜索结果立场偏差(平衡与偏见)和解释水平(纯文本，仅标签，标签和解释)是否影响点击搜索结果的多样性。我们发现，立场标签和解释导致了更多样化的搜索结果消费。然而，在这种情况下，我们没有发现用户意见系统性变化的证据。我们相信这些结果可以帮助搜索引擎的设计者做出更明智的设计决策。"
    },
    {
        "title": "FedDCSR: Federated Cross-domain Sequential Recommendation via\n  Disentangled Representation Learning",
        "url": "http://arxiv.org/abs/2309.08420v1",
        "pub_date": "2023-09-15",
        "summary": "Cross-domain Sequential Recommendation (CSR) which leverages user sequence\ndata from multiple domains has received extensive attention in recent years.\nHowever, the existing CSR methods require sharing origin user data across\ndomains, which violates the General Data Protection Regulation (GDPR). Thus, it\nis necessary to combine federated learning (FL) and CSR to fully utilize\nknowledge from different domains while preserving data privacy. Nonetheless,\nthe sequence feature heterogeneity across different domains significantly\nimpacts the overall performance of FL. In this paper, we propose FedDCSR, a\nnovel federated cross-domain sequential recommendation framework via\ndisentangled representation learning. Specifically, to address the sequence\nfeature heterogeneity across domains, we introduce an approach called\ninter-intra domain sequence representation disentanglement (SRD) to disentangle\nthe user sequence features into domain-shared and domain-exclusive features. In\naddition, we design an intra domain contrastive infomax (CIM) strategy to learn\nricher domain-exclusive features of users by performing data augmentation on\nuser sequences. Extensive experiments on three real-world scenarios demonstrate\nthat FedDCSR achieves significant improvements over existing baselines.",
        "translated": "跨域序列推荐(CSR)利用多域的用户序列数据，近年来受到了广泛的关注。然而，现有的 CSR 方法要求跨域共享原始用户数据，这违反了一般数据保护规则(GDPR)。因此，有必要将联邦学习(FL)和 CSR 结合起来，充分利用不同领域的知识，同时保护数据隐私。尽管如此，不同领域的序列特征异质性显著影响了 FL 的整体性能。本文提出了一种基于分离表示学习的联邦跨域序列推荐框架 FedDCSR。为了解决域间序列特征异质性问题，提出了一种域内序列表示解纠缠(SRD)方法，将用户序列特征分解为域共享特征和域独占特征。此外，我们还设计了一个域内对比信息增强(CIM)策略，通过对用户序列进行数据增强来学习用户更丰富的域外特征。在三个真实场景中的大量实验表明，FedDCSR 比现有的基线有了显著的改进。"
    },
    {
        "title": "Structural Self-Supervised Objectives for Transformers",
        "url": "http://arxiv.org/abs/2309.08272v1",
        "pub_date": "2023-09-15",
        "summary": "This thesis focuses on improving the pre-training of natural language models\nusing unsupervised raw data to make them more efficient and aligned with\ndownstream applications.\n  In the first part, we introduce three alternative pre-training objectives to\nBERT's Masked Language Modeling (MLM), namely Random Token Substitution (RTS),\nCluster-based Random Token Substitution (C-RTS), and Swapped Language Modeling\n(SLM). These objectives involve token swapping instead of masking, with RTS and\nC-RTS aiming to predict token originality and SLM predicting the original token\nvalues. Results show that RTS and C-RTS require less pre-training time while\nmaintaining performance comparable to MLM. Surprisingly, SLM outperforms MLM on\ncertain tasks despite using the same computational budget.\n  In the second part, we proposes self-supervised pre-training tasks that align\nstructurally with downstream applications, reducing the need for labeled data.\nWe use large corpora like Wikipedia and CC-News to train models to recognize if\ntext spans originate from the same paragraph or document in several ways. By\ndoing continuous pre-training, starting from existing models like RoBERTa,\nELECTRA, DeBERTa, BART, and T5, we demonstrate significant performance\nimprovements in tasks like Fact Verification, Answer Sentence Selection, and\nSummarization. These improvements are especially pronounced when limited\nannotation data is available. The proposed objectives also achieve\nstate-of-the-art results on various benchmark datasets, including FEVER (dev\nset), ASNQ, WikiQA, and TREC-QA, as well as enhancing the quality of summaries.\nImportantly, these techniques can be easily integrated with other methods\nwithout altering the internal structure of Transformer models, making them\nversatile for various NLP applications.",
        "translated": "本文主要研究如何利用无监督的原始数据来改进自然语言模型的预训练，使其更加有效并与下游应用相一致。在第一部分中，我们介绍了三种可供选择的预训练目标，即随机令牌替换(RTS)、基于集群的随机令牌替换(C-RTS)和交换语言建模(SLM)。这些目标包括令牌交换而不是掩码，RTS 和 C-RTS 旨在预测令牌原始性，SLM 预测原始令牌值。结果表明，RTS 和 C-RTS 需要较少的训练前时间，同时保持性能相当于传销。令人惊讶的是，尽管使用相同的计算预算，SLM 在某些任务上的表现优于 MLM。在第二部分中，我们提出了自我监督的预训练任务，它们在结构上与下游应用程序保持一致，从而减少对标记数据的需求。我们使用像 Wikipedia 和 CC-News 这样的大型语料库来训练模型识别文本跨度是否以多种方式来源于同一段落或文档。通过进行连续的预训练，从现有的模型如 roBERTa，ELECTRA，deberTa，BART 和 t5开始，我们展示了在事实验证，答案句子选择和总结等任务中显著的性能改进。当有限的注释数据可用时，这些改进尤其明显。提出的目标还可以在各种基准数据集上实现最先进的结果，包括 FEVER (dev set)、 ASNQ、 WikiQA 和 TREC-QA，以及提高摘要的质量。重要的是，这些技术可以很容易地与其他方法集成，而不需要改变变压器模型的内部结构，使它们适用于各种 NLP 应用。"
    },
    {
        "title": "Sparse Autoencoders Find Highly Interpretable Features in Language\n  Models",
        "url": "http://arxiv.org/abs/2309.08600v1",
        "pub_date": "2023-09-15",
        "summary": "One of the roadblocks to a better understanding of neural networks' internals\nis \\textit{polysemanticity}, where neurons appear to activate in multiple,\nsemantically distinct contexts. Polysemanticity prevents us from identifying\nconcise, human-understandable explanations for what neural networks are doing\ninternally. One hypothesised cause of polysemanticity is\n\\textit{superposition}, where neural networks represent more features than they\nhave neurons by assigning features to an overcomplete set of directions in\nactivation space, rather than to individual neurons. Here, we attempt to\nidentify those directions, using sparse autoencoders to reconstruct the\ninternal activations of a language model. These autoencoders learn sets of\nsparsely activating features that are more interpretable and monosemantic than\ndirections identified by alternative approaches, where interpretability is\nmeasured by automated methods. Ablating these features enables precise model\nediting, for example, by removing capabilities such as pronoun prediction,\nwhile disrupting model behaviour less than prior techniques. This work\nindicates that it is possible to resolve superposition in language models using\na scalable, unsupervised method. Our method may serve as a foundation for\nfuture mechanistic interpretability work, which we hope will enable greater\nmodel transparency and steerability.",
        "translated": "要更好地理解神经网络的内部结构，其中一个障碍是 text (多义性) ，即神经元似乎在多种不同的语义上下文中被激活。多义性使我们无法对神经网络的内部活动作出简明易懂的解释。多义性的一个假设原因是文本{叠加} ，其中神经网络通过将特征分配给激活空间中的过度完整的方向集合，而不是分配给单个神经元，从而代表比它们具有的神经元更多的特征。在这里，我们尝试识别这些方向，使用稀疏自动编码器来重建语言模型的内部激活。这些自动编码器学习的稀疏激活特征集，更易于解释和单一语义的方向识别的替代方法，其中可解释性是由自动化方法测量。消除这些特征可以实现精确的模型编辑，例如，通过消除代词预测等功能，同时破坏模型行为少于先前的技术。这项工作表明，使用一种可扩展的，无监督的方法来解决语言模型中的叠加问题是可能的。我们的方法可以作为未来机械可解释性工作的基础，我们希望这将使更大的模型透明度和可操纵性。"
    },
    {
        "title": "\"Merge Conflicts!\" Exploring the Impacts of External Distractors to\n  Parametric Knowledge Graphs",
        "url": "http://arxiv.org/abs/2309.08594v1",
        "pub_date": "2023-09-15",
        "summary": "Large language models (LLMs) acquire extensive knowledge during pre-training,\nknown as their parametric knowledge. However, in order to remain up-to-date and\nalign with human instructions, LLMs inevitably require external knowledge\nduring their interactions with users. This raises a crucial question: How will\nLLMs respond when external knowledge interferes with their parametric\nknowledge? To investigate this question, we propose a framework that\nsystematically elicits LLM parametric knowledge and introduces external\nknowledge. Specifically, we uncover the impacts by constructing a parametric\nknowledge graph to reveal the different knowledge structures of LLMs, and\nintroduce external knowledge through distractors of varying degrees, methods,\npositions, and formats. Our experiments on both black-box and open-source\nmodels demonstrate that LLMs tend to produce responses that deviate from their\nparametric knowledge, particularly when they encounter direct conflicts or\nconfounding changes of information within detailed contexts. We also find that\nwhile LLMs are sensitive to the veracity of external knowledge, they can still\nbe distracted by unrelated information. These findings highlight the risk of\nhallucination when integrating external knowledge, even indirectly, during\ninteractions with current LLMs. All the data and results are publicly\navailable.",
        "translated": "大型语言模型(LLM)在预训练过程中获得了广泛的知识，称为参数知识。然而，为了保持最新并与人工指令保持一致，LLM 在与用户交互过程中不可避免地需要外部知识。这就提出了一个关键问题: 当外部知识干扰 LLM 的参数化知识时，LLM 将如何应对？为了研究这个问题，我们提出了一个框架，系统地引出 LLM 参数化知识并引入外部知识。具体来说，我们通过构建一个参数化知识图来揭示 LLM 的不同知识结构，并通过不同程度、不同方法、不同位置和不同格式的干扰物来引入外部知识。我们在黑箱模型和开源模型上的实验表明，LLM 倾向于产生偏离其参数知识的响应，特别是当它们遇到直接冲突或在详细情况下混淆信息的变化时。我们还发现，虽然 LLM 对外部知识的准确性很敏感，但它们仍然可以被不相关的信息分散注意力。这些发现强调了在与当前 LLM 相互作用过程中整合外部知识(即使是间接的)产生幻觉的风险。所有的数据和结果都是公开的。"
    },
    {
        "title": "Are Multilingual LLMs Culturally-Diverse Reasoners? An Investigation\n  into Multicultural Proverbs and Sayings",
        "url": "http://arxiv.org/abs/2309.08591v1",
        "pub_date": "2023-09-15",
        "summary": "Large language models (LLMs) are highly adept at question answering and\nreasoning tasks, but when reasoning in situational context, human expectations\nvary depending on the relevant cultural common ground. As human languages are\nassociated with diverse cultures, LLMs should also be culturally-diverse\nreasoners. In this paper, we study the ability of a wide range of\nstate-of-the-art multilingual LLMs (mLLMs) to reason with proverbs and sayings\nin a conversational context. Our experiments reveal that: (1) mLLMs 'knows'\nlimited proverbs and memorizing proverbs does not mean understanding them\nwithin a conversational context; (2) mLLMs struggle to reason with figurative\nproverbs and sayings, and when asked to select the wrong answer (instead of\nasking it to select the correct answer); and (3) there is a \"culture gap\" in\nmLLMs when reasoning about proverbs and sayings translated from other\nlanguages. We construct and release our evaluation dataset MAPS (MulticultrAl\nProverbs and Sayings) for proverb understanding with conversational context for\nsix different languages.",
        "translated": "大语言模型(LLM)非常善于回答问题和推理任务，但在情景语境中推理时，人类的期望取决于相关的文化共同点。由于人类语言与不同的文化有关，LLM 也应该是文化多样性的推理者。在本文中，我们研究了一系列最先进的多语言母语(mLLM)在会话语境中对谚语和谚语进行推理的能力。我们的实验表明: (1) mLLM“知道”有限的谚语，并且记住谚语并不意味着在会话语境中理解它们; (2) mLLM 努力推理比喻性的谚语和谚语，当被要求选择错误的答案时(而不是要求它选择正确的答案) ; (3)当推理从其他语言翻译过来的谚语和谚语时，mLLM 存在“文化差异”。我们构建并发布了针对六种不同语言的会话语境的谚语理解评价数据集 MAPS。"
    },
    {
        "title": "Neural Machine Translation Models Can Learn to be Few-shot Learners",
        "url": "http://arxiv.org/abs/2309.08590v1",
        "pub_date": "2023-09-15",
        "summary": "The emergent ability of Large Language Models to use a small number of\nexamples to learn to perform in novel domains and tasks, also called in-context\nlearning (ICL). In this work, we show that a much smaller model can be trained\nto perform ICL by fine-tuning towards a specialized training objective,\nexemplified on the task of domain adaptation for neural machine translation.\nWith this capacity for ICL, the model can take advantage of relevant few-shot\nexamples to adapt its output towards the domain. We compare the quality of this\ndomain adaptation to traditional supervised techniques and ICL with a\n40B-parameter Large Language Model. Our approach allows efficient batch\ninference on a mix of domains and outperforms state-of-the-art baselines in\nterms of both translation quality and immediate adaptation rate, i.e. the\nability to reproduce a specific term after being shown a single example.",
        "translated": "大语言模型使用少量例子来学习在新的领域和任务中执行的突发能力，也称为上下文学习(ICL)。在这项工作中，我们表明，一个更小的模型可以训练执行 ICL 通过微调到一个专门的训练目标，例如领域适应的任务神经机器翻译。利用 ICL 的这种能力，该模型可以利用相关的少镜头示例来适应该领域的输出。我们比较了这个领域的质量适应传统的监督技术和 ICL 与40B 参数的大语言模型。我们的方法允许在多个域的混合上进行有效的批量推断，并且在翻译质量和即时适应率方面优于最先进的基线，即在显示单个示例之后重现特定术语的能力。"
    },
    {
        "title": "Chain-of-Thought Reasoning is a Policy Improvement Operator",
        "url": "http://arxiv.org/abs/2309.08589v1",
        "pub_date": "2023-09-15",
        "summary": "Large language models have astounded the world with fascinating new\ncapabilities. However, they currently lack the ability to teach themselves new\nskills, relying instead on being trained on large amounts of human-generated\ndata. We introduce SECToR (Self-Education via Chain-of-Thought Reasoning), a\nproof-of-concept demonstration that language models can successfully teach\nthemselves new skills using chain-of-thought reasoning. Inspired by previous\nwork in both reinforcement learning (Silver et al., 2017) and human cognition\n(Kahneman, 2011), SECToR first uses chain-of-thought reasoning to slowly think\nits way through problems. SECToR then fine-tunes the model to generate those\nsame answers, this time without using chain-of-thought reasoning. Language\nmodels trained via SECToR autonomously learn to add up to 29-digit numbers\nwithout any access to any ground truth examples beyond an initial supervised\nfine-tuning phase consisting only of numbers with 6 or fewer digits. Our\ncentral hypothesis is that chain-of-thought reasoning can act as a policy\nimprovement operator, analogously to how Monte-Carlo Tree Search is used in\nAlphaZero. We hope that this research can lead to new directions in which\nlanguage models can learn to teach themselves without the need for human\ndemonstrations.",
        "translated": "大型语言模型以其引人入胜的新功能震惊了世界。然而，他们目前缺乏自学新技能的能力，只能依靠大量人工生成的数据进行训练。我们介绍了 SECTR (通过思维链推理进行自我教育) ，这是一个概念验证演示，表明语言模型可以通过思维链推理成功地教会自己新的技能。受先前在强化学习和人类认知方面的研究(Silver et al。 ，2017)和 Kahneman，2011)的启发，SECTOR 首先使用思维链推理来缓慢地思考问题。然后，SECTR 对模型进行微调，以生成相同的答案，这一次不使用思维链推理。通过 SECTOR 培训的语言模型自主学习加起来多达29位数字，除了最初的监督微调阶段只包括6位或更少数字的数字，没有任何访问任何地面真理的例子。我们的中心假设是，思维链推理可以作为政策改进的操作者，类似于 AlphaZero 使用蒙特卡洛树搜索的方式。我们希望这项研究能够为语言模型学习自学而不需要人工示范带来新的方向。"
    },
    {
        "title": "ICLEF: In-Context Learning with Expert Feedback for Explainable Style\n  Transfer",
        "url": "http://arxiv.org/abs/2309.08583v1",
        "pub_date": "2023-09-15",
        "summary": "While state-of-the-art language models excel at the style transfer task,\ncurrent work does not address explainability of style transfer systems.\nExplanations could be generated using large language models such as GPT-3.5 and\nGPT-4, but the use of such complex systems is inefficient when smaller, widely\ndistributed, and transparent alternatives are available. We propose a framework\nto augment and improve a formality style transfer dataset with explanations via\nmodel distillation from ChatGPT. To further refine the generated explanations,\nwe propose a novel way to incorporate scarce expert human feedback using\nin-context learning (ICLEF: In-Context Learning from Expert Feedback) by\nprompting ChatGPT to act as a critic to its own outputs. We use the resulting\ndataset of 9,960 explainable formality style transfer instances (e-GYAFC) to\nshow that current openly distributed instruction-tuned models (and, in some\nsettings, ChatGPT) perform poorly on the task, and that fine-tuning on our\nhigh-quality dataset leads to significant improvements as shown by automatic\nevaluation. In human evaluation, we show that models much smaller than ChatGPT\nfine-tuned on our data align better with expert preferences. Finally, we\ndiscuss two potential applications of models fine-tuned on the explainable\nstyle transfer task: interpretable authorship verification and interpretable\nadversarial attacks on AI-generated text detectors.",
        "translated": "虽然最先进的语言模型擅长于风格转换任务，但目前的工作并没有解决风格转换系统的可解释性问题。可以使用大型语言模型(如 GPT-3.5和 GPT-4)生成解释，但是如果有更小的、广泛分布的、透明的替代方案，这种复杂系统的使用效率就会很低。我们提出了一个框架来扩充和改进形式样式传输数据集的解释通过模型精馏从 ChatGPT。为了进一步完善生成的解释，我们提出了一种新颖的方法，通过促使 ChatGPT 对其自身的输出进行批评，使用上下文学习(ICLEF: 从专家反馈中进行上下文学习)来整合稀缺的专家人类反馈。我们使用9,960个可解释的形式转移实例(e-GYAFC)的结果数据集来显示当前公开分布的指令调优模型(在一些设置中，ChatGPT)在任务上表现不佳，并且对我们的高质量数据集的微调导致显着的改进，如自动评估所示。在人工评估中，我们发现比 ChatGPT 小得多的模型在我们的数据上进行了微调，更好地符合专家的偏好。最后，我们讨论了模型在解释性文体转移任务中的两个潜在应用: 可解释的作者身份验证和对 AI 生成的文本检测器的可解释的对抗性攻击。"
    },
    {
        "title": "Casteist but Not Racist? Quantifying Disparities in Large Language Model\n  Bias between India and the West",
        "url": "http://arxiv.org/abs/2309.08573v1",
        "pub_date": "2023-09-15",
        "summary": "Large Language Models (LLMs), now used daily by millions of users, can encode\nsocietal biases, exposing their users to representational harms. A large body\nof scholarship on LLM bias exists but it predominantly adopts a Western-centric\nframe and attends comparatively less to bias levels and potential harms in the\nGlobal South. In this paper, we quantify stereotypical bias in popular LLMs\naccording to an Indian-centric frame and compare bias levels between the Indian\nand Western contexts. To do this, we develop a novel dataset which we call\nIndian-BhED (Indian Bias Evaluation Dataset), containing stereotypical and\nanti-stereotypical examples for caste and religion contexts. We find that the\nmajority of LLMs tested are strongly biased towards stereotypes in the Indian\ncontext, especially as compared to the Western context. We finally investigate\nInstruction Prompting as a simple intervention to mitigate such bias and find\nthat it significantly reduces both stereotypical and anti-stereotypical biases\nin the majority of cases for GPT-3.5. The findings of this work highlight the\nneed for including more diverse voices when evaluating LLMs.",
        "translated": "大型语言模型(LLM) ，现在每天被数百万用户使用，可以编码社会偏见，暴露他们的用户代表性的伤害。存在大量关于 LLM 偏见的学术研究，但它主要采用以西方为中心的框架，对全球南方的偏见水平和潜在危害的关注相对较少。在本文中，我们根据印度中心主义的框架来量化流行的 LLM 中的刻板偏见，并比较印度和西方语境中的偏见水平。为了做到这一点，我们开发了一个新的数据集，我们称之为印度-BhED (印度偏见评估数据集) ，包含刻板印象和反刻板印象的例子种姓和宗教背景。我们发现，大多数测试的 LLM 都强烈偏向于印度语境中的刻板印象，特别是与西方语境相比。我们最后调查了指导提示作为一个简单的干预措施，以减轻这种偏见，并发现它显着减少了在 GPT-3.5的大多数情况下的刻板印象和反刻板印象偏见。这项工作的发现强调了在评估 LLM 时需要包括更多不同的声音。"
    },
    {
        "title": "How Transferable are Attribute Controllers on Pretrained Multilingual\n  Translation Models?",
        "url": "http://arxiv.org/abs/2309.08565v1",
        "pub_date": "2023-09-15",
        "summary": "Customizing machine translation models to comply with fine-grained attributes\nsuch as formality has seen tremendous progress recently. However, current\napproaches mostly rely on at least some supervised data with attribute\nannotation. Data scarcity therefore remains a bottleneck to democratizing such\ncustomization possibilities to a wider range of languages, lower-resource ones\nin particular. Given recent progress in pretrained massively multilingual\ntranslation models, we use them as a foundation to transfer the attribute\ncontrolling capabilities to languages without supervised data. In this work, we\npresent a comprehensive analysis of transferring attribute controllers based on\na pretrained NLLB-200 model. We investigate both training- and inference-time\ncontrol techniques under various data scenarios, and uncover their relative\nstrengths and weaknesses in zero-shot performance and domain robustness. We\nshow that both paradigms are complementary, as shown by consistent improvements\non 5 zero-shot directions. Moreover, a human evaluation on a real low-resource\nlanguage, Bengali, confirms our findings on zero-shot transfer to new target\nlanguages. The code is\n$\\href{https://github.com/dannigt/attribute-controller-transfer}{\\text{here}}$.",
        "translated": "定制机器翻译模型以符合细粒度的属性，如形式，最近看到了巨大的进展。然而，目前的方法大多依赖于至少一些带有属性标注的监督数据。因此，数据稀缺仍然是将这种定制可能性大众化到更广泛的语言，特别是资源较少的语言的一个瓶颈。鉴于最近在预先训练的大规模多语言翻译模型方面取得的进展，我们将其作为一个基础，在没有监督数据的情况下将属性控制能力转移到语言中。在这项工作中，我们提出了一个全面的分析传递属性控制器的基础上预先训练的 NLLB-200模型。我们研究了不同数据场景下的训练和推断时间控制技术，并揭示了它们在零点击性能和域鲁棒性方面的相对优缺点。我们表明，这两个范例是互补的，如在5个零拍方向的一致改进所示。此外，一个真正的低资源语言，孟加拉语的人类评估，证实了我们的发现，零零迁移到新的目标语言。代码是 $href { https://github.com/dannigt/attribute-controller-transfer }{ text { here }} $。"
    },
    {
        "title": "Augmenting conformers with structured state space models for online\n  speech recognition",
        "url": "http://arxiv.org/abs/2309.08551v1",
        "pub_date": "2023-09-15",
        "summary": "Online speech recognition, where the model only accesses context to the left,\nis an important and challenging use case for ASR systems. In this work, we\ninvestigate augmenting neural encoders for online ASR by incorporating\nstructured state-space sequence models (S4), which are a family of models that\nprovide a parameter-efficient way of accessing arbitrarily long left context.\nWe perform systematic ablation studies to compare variants of S4 models and\npropose two novel approaches that combine them with convolutions. We find that\nthe most effective design is to stack a small S4 using real-valued recurrent\nweights with a local convolution, allowing them to work complementarily. Our\nbest model achieves WERs of 4.01%/8.53% on test sets from Librispeech,\noutperforming Conformers with extensively tuned convolution.",
        "translated": "在线语音识别，其中模型只访问左侧的上下文，是一个重要的和具有挑战性的 ASR 系统的用例。在这项工作中，我们研究增强神经编码器的在线 ASR 结合结构化状态空间序列模型(S4) ，这是一个家族的模型，提供了一个参数有效的方式访问任意长的左侧上下文。我们进行了系统的消融研究，以比较 S4模型的变体，并提出了两种新的方法，结合它们与卷积。我们发现最有效的设计是使用实值递归权重和局部卷积来叠加一个小的 S4，允许它们互补工作。我们最好的模型在来自 Librispeech 的测试集上达到了4.01%/8.53% 的 WER，通过广泛调整卷积超过了 Conformers。"
    },
    {
        "title": "Predictive Uncertainty-based Bias Mitigation in Ranking",
        "url": "http://arxiv.org/abs/2309.09833v1",
        "pub_date": "2023-09-18",
        "summary": "Societal biases that are contained in retrieved documents have received\nincreased interest. Such biases, which are often prevalent in the training data\nand learned by the model, can cause societal harms, by misrepresenting certain\ngroups, and by enforcing stereotypes. Mitigating such biases demands algorithms\nthat balance the trade-off between maximized utility for the user with fairness\nobjectives, which incentivize unbiased rankings. Prior work on bias mitigation\noften assumes that ranking scores, which correspond to the utility that a\ndocument holds for a user, can be accurately determined. In reality, there is\nalways a degree of uncertainty in the estimate of expected document utility.\nThis uncertainty can be approximated by viewing ranking models through a\nBayesian perspective, where the standard deterministic score becomes a\ndistribution.\n  In this work, we investigate whether uncertainty estimates can be used to\ndecrease the amount of bias in the ranked results, while minimizing loss in\nmeasured utility. We introduce a simple method that uses the uncertainty of the\nranking scores for an uncertainty-aware, post hoc approach to bias mitigation.\nWe compare our proposed method with existing baselines for bias mitigation with\nrespect to the utility-fairness trade-off, the controllability of methods, and\ncomputational costs. We show that an uncertainty-based approach can provide an\nintuitive and flexible trade-off that outperforms all baselines without\nadditional training requirements, allowing for the post hoc use of this\napproach on top of arbitrary retrieval models.",
        "translated": "检索到的文件中包含的社会偏见越来越受到关注。这样的偏见，通常在培训数据中普遍存在，并被模型学习到，通过歪曲特定群体和强制执行刻板印象，可能造成社会危害。减轻这种偏见需要算法，平衡之间的权衡最大效用的用户和公平的目标，激励无偏排名。先前关于减少偏差的工作通常假设排名分数，这对应于一个文档为用户持有的效用，可以被准确地确定。实际上，在预期文档效用的估计中总是存在一定程度的不确定性。这种不确定性可以通过贝叶斯透视图查看排名模型来近似化，其中标准的确定性得分成为一个分布。在这项工作中，我们研究是否不确定性估计可以用来减少排名结果中的偏差量，同时最小化测量效用的损失。我们介绍了一个简单的方法，使用不确定性的排名得分的不确定性的不确定性，事后的方法来减轻偏见。在效用-公平权衡、方法的可控性和计算成本方面，我们将提出的方法与现有的减少偏差的基线进行了比较。我们展示了一个基于不确定性的方法可以提供一个直观和灵活的权衡，在没有额外的训练要求的情况下优于所有的基线，允许在任意检索模型之上事后使用这种方法。"
    },
    {
        "title": "How Much Freedom Does An Effectiveness Metric Really Have?",
        "url": "http://arxiv.org/abs/2309.09477v1",
        "pub_date": "2023-09-18",
        "summary": "It is tempting to assume that because effectiveness metrics have free choice\nto assign scores to search engine result pages (SERPs) there must thus be a\nsimilar degree of freedom as to the relative order that SERP pairs can be put\ninto. In fact that second freedom is, to a considerable degree, illusory.\nThat's because if one SERP in a pair has been given a certain score by a\nmetric, fundamental ordering constraints in many cases then dictate that the\nscore for the second SERP must be either not less than, or not greater than,\nthe score assigned to the first SERP. We refer to these fixed relationships as\ninnate pairwise SERP orderings. Our first goal in this work is to describe and\ndefend those pairwise SERP relationship constraints, and tabulate their\nrelative occurrence via both exhaustive and empirical experimentation.\n  We then consider how to employ such innate pairwise relationships in IR\nexperiments, leading to a proposal for a new measurement paradigm.\nSpecifically, we argue that tables of results in which many different metrics\nare listed for champion versus challenger system comparisons should be avoided;\nand that instead a single metric be argued for in principled terms, with any\nrelationships identified by that metric then reinforced via an assessment of\nthe innate relationship as to whether other metrics - indeed, all other metrics\n- are likely to yield the same system-vs-system outcome.",
        "translated": "因为有效性指标可以自由选择为搜索引擎结果页(SERP)分配分数，所以必须有与 SERP 对可以放入的相对顺序相似的自由度。事实上，第二自由在很大程度上是虚幻的。这是因为，如果一对 SERP 中的一个已经通过度量给出了一个特定的分数，那么在许多情况下，基本排序约束就会要求第二个 SERP 的分数必须不小于或不大于分配给第一个 SERP 的分数。我们将这些固定关系称为固有的成对 SERP 排序。我们在这项工作的第一个目标是描述和捍卫这些成对的 SERP 关系约束，并通过详尽的和经验的实验制表他们的相对发生。然后我们考虑如何在 IR 实验中使用这种内在的成对关系，从而提出了一个新的测量范式。具体而言，我们认为应该避免列出许多不同指标用于冠军与挑战者系统比较的结果表; 相反，应该用原则性的术语来论证单个指标，该指标确定的任何关系随后通过评估其他指标(实际上，所有其他指标)是否可能产生相同的系统与系统结果。"
    },
    {
        "title": "Selecting which Dense Retriever to use for Zero-Shot Search",
        "url": "http://arxiv.org/abs/2309.09403v1",
        "pub_date": "2023-09-18",
        "summary": "We propose the new problem of choosing which dense retrieval model to use\nwhen searching on a new collection for which no labels are available, i.e. in a\nzero-shot setting. Many dense retrieval models are readily available. Each\nmodel however is characterized by very differing search effectiveness -- not\njust on the test portion of the datasets in which the dense representations\nhave been learned but, importantly, also across different datasets for which\ndata was not used to learn the dense representations. This is because dense\nretrievers typically require training on a large amount of labeled data to\nachieve satisfactory search effectiveness in a specific dataset or domain.\nMoreover, effectiveness gains obtained by dense retrievers on datasets for\nwhich they are able to observe labels during training, do not necessarily\ngeneralise to datasets that have not been observed during training. This is\nhowever a hard problem: through empirical experimentation we show that methods\ninspired by recent work in unsupervised performance evaluation with the\npresence of domain shift in the area of computer vision and machine learning\nare not effective for choosing highly performing dense retrievers in our setup.\nThe availability of reliable methods for the selection of dense retrieval\nmodels in zero-shot settings that do not require the collection of labels for\nevaluation would allow to streamline the widespread adoption of dense\nretrieval. This is therefore an important new problem we believe the\ninformation retrieval community should consider. Implementation of methods,\nalong with raw result files and analysis scripts are made publicly available at\nhttps://www.github.com/anonymized.",
        "translated": "我们提出了一个新的问题，即在搜索一个没有标签可用的新集合时，选择使用哪个密集检索模型，即在零镜头设置中。许多密集的检索模型很容易获得。然而，每个模型的搜索效率拥有属性都有很大的不同——不仅仅是在已经学习了密集表示的数据集的测试部分，更重要的是，在不同的数据集中，数据并没有被用来学习密集表示。这是因为密集检索器通常需要对大量标记数据进行培训，以便在特定数据集或域中获得满意的搜索效果。此外，密集检索器在他们能够在训练期间观察到标签的数据集上获得的有效性增益，不一定概括为在训练期间没有观察到的数据集。然而，这是一个困难的问题: 通过经验实验，我们表明，在计算机视觉和机器学习领域存在领域移位的情况下，受最近的无监督性能评估工作的启发，在我们的设置中选择高性能密集检索器的方法是不有效的。在不需要收集标签进行评价的零拍摄环境中选择密集检索模型的可靠方法的提供，将有助于简化密集检索的广泛采用。因此，这是一个重要的新问题，我们认为信息检索应该加以考虑。方法的实现，以及原始结果文件和分析脚本都可以在 https://www.github.com/anonymized 上公开获得。"
    },
    {
        "title": "ChatGPT Hallucinates when Attributing Answers",
        "url": "http://arxiv.org/abs/2309.09401v1",
        "pub_date": "2023-09-17",
        "summary": "Can ChatGPT provide evidence to support its answers? Does the evidence it\nsuggests actually exist and does it really support its answer? We investigate\nthese questions using a collection of domain-specific knowledge-based\nquestions, specifically prompting ChatGPT to provide both an answer and\nsupporting evidence in the form of references to external sources. We also\ninvestigate how different prompts impact answers and evidence. We find that\nChatGPT provides correct or partially correct answers in about half of the\ncases (50.6% of the times), but its suggested references only exist 14% of the\ntimes. We further provide insights on the generated references that reveal\ncommon traits among the references that ChatGPT generates, and show how even if\na reference provided by the model does exist, this reference often does not\nsupport the claims ChatGPT attributes to it. Our findings are important because\n(1) they are the first systematic analysis of the references created by ChatGPT\nin its answers; (2) they suggest that the model may leverage good quality\ninformation in producing correct answers, but is unable to attribute real\nevidence to support its answers. Prompts, raw result files and manual analysis\nare made publicly available.",
        "translated": "ChatGPT 能否提供证据来支持其答案？它所暗示的证据真的存在吗? 它真的支持它的答案吗？我们使用一组特定于领域的基于知识的问题来研究这些问题，特别是提示 ChatGPT 以引用外部来源的形式提供答案和支持证据。我们还调查了不同的提示如何影响答案和证据。我们发现在大约一半的案例中(50.6%) ChatGPT 提供了正确或部分正确的答案，但是建议的参考文献只有14% 。我们进一步提供对生成的引用的见解，这些引用揭示了 ChatGPT 生成的引用中的共同特征，并展示了即使模型提供的引用确实存在，该引用通常也不支持 ChatGPT 属性。我们的发现很重要，因为(1)它们是 ChatGPT 在其答案中创建的参考文献的第一个系统分析; (2)它们表明模型可以利用良好的质量信息来产生正确的答案，但是无法提供真实的证据来支持其答案。提示、原始结果文件和手动分析都是公开的。"
    },
    {
        "title": "Towards Debiasing Frame Length Bias in Text-Video Retrieval via Causal\n  Intervention",
        "url": "http://arxiv.org/abs/2309.09311v1",
        "pub_date": "2023-09-17",
        "summary": "Many studies focus on improving pretraining or developing new backbones in\ntext-video retrieval. However, existing methods may suffer from the learning\nand inference bias issue, as recent research suggests in other\ntext-video-related tasks. For instance, spatial appearance features on action\nrecognition or temporal object co-occurrences on video scene graph generation\ncould induce spurious correlations. In this work, we present a unique and\nsystematic study of a temporal bias due to frame length discrepancy between\ntraining and test sets of trimmed video clips, which is the first such attempt\nfor a text-video retrieval task, to the best of our knowledge. We first\nhypothesise and verify the bias on how it would affect the model illustrated\nwith a baseline study. Then, we propose a causal debiasing approach and perform\nextensive experiments and ablation studies on the Epic-Kitchens-100, YouCook2,\nand MSR-VTT datasets. Our model overpasses the baseline and SOTA on nDCG, a\nsemantic-relevancy-focused evaluation metric which proves the bias is\nmitigated, as well as on the other conventional metrics.",
        "translated": "许多研究集中在改进文本视频检索的预训练或开发新的骨干。然而，正如最近的研究表明，现有的方法可能会受到学习和推理偏差问题，在其他文本视频相关的任务。例如，动作识别中的空间表象特征或视频场景图生成中的时间对象共现都可能产生伪相关。在这项工作中，我们提出了一个独特的和系统的研究时间偏差由于帧长度差异训练和测试集之间的修剪视频剪辑，这是第一次这样的尝试，文本视频检索任务，以我们的知识。我们首先假设并验证了基线研究对模型的影响。然后，我们提出了一个因果消偏方法，并进行了广泛的实验和消融研究的 Epic-Kitchens-100，YouCook2和 MSR-VTT 数据集。我们的模型超越了 nDCG 的基线和 SOTA，nDCG 是一个关注语义相关性的评估指标，它证明了偏差得到了缓解，同时也超越了其他常规指标。"
    },
    {
        "title": "An Empirical Study of Scaling Instruct-Tuned Large Multimodal Models",
        "url": "http://arxiv.org/abs/2309.09958v1",
        "pub_date": "2023-09-18",
        "summary": "Visual instruction tuning has recently shown encouraging progress with\nopen-source large multimodal models (LMM) such as LLaVA and MiniGPT-4. However,\nmost existing studies of open-source LMM are performed using models with 13B\nparameters or smaller. In this paper we present an empirical study of scaling\nLLaVA up to 33B and 65B/70B, and share our findings from our explorations in\nimage resolution, data mixing and parameter-efficient training methods such as\nLoRA/QLoRA. These are evaluated by their impact on the multi-modal and language\ncapabilities when completing real-world tasks in the wild.\n  We find that scaling LMM consistently enhances model performance and improves\nlanguage capabilities, and performance of LoRA/QLoRA tuning of LMM are\ncomparable to the performance of full-model fine-tuning. Additionally, the\nstudy highlights the importance of higher image resolutions and mixing\nmultimodal-language data to improve LMM performance, and visual instruction\ntuning can sometimes improve LMM's pure language capability. We hope that this\nstudy makes state-of-the-art LMM research at a larger scale more accessible,\nthus helping establish stronger baselines for future research. Code and\ncheckpoints will be made public.",
        "translated": "可视化指令调优最近在开源大型多模态模型(LMM)方面取得了令人鼓舞的进展，例如 LLaVA 和 MiniGPT-4。然而，现有的大多数开源 LMM 的研究都是使用13B 参数或更小的模型进行的。在本文中，我们提出了一个实证研究的尺度 LLaVA 高达33B 和65B/70B，并分享我们的发现，从图像分辨率的探索，数据混合和参数有效的训练方法，如 LoRA/QLoRA。在野外完成真实世界的任务时，通过它们对多模态和语言能力的影响来评估它们。我们发现可伸缩 LMM 一致地提高了模型性能和语言能力，并且 LMM 的 LoRA/QLoRA 调优性能与全模型调优性能相当。此外，该研究还强调了提高图像分辨率和混合多模态语言数据以提高 LMM 性能的重要性，可视化指令调优有时可以提高 LMM 的纯语言能力。我们希望这项研究能够使最先进的 LMM 研究在更大的范围内更容易获得，从而为未来的研究建立更强大的基线。密码和检查站将公之于众。"
    },
    {
        "title": "How to Generate Popular Post Headlines on Social Media?",
        "url": "http://arxiv.org/abs/2309.09949v1",
        "pub_date": "2023-09-18",
        "summary": "Posts, as important containers of user-generated-content pieces on social\nmedia, are of tremendous social influence and commercial value. As an integral\ncomponents of a post, the headline has a decisive contribution to the post's\npopularity. However, current mainstream method for headline generation is still\nmanually writing, which is unstable and requires extensive human effort. This\ndrives us to explore a novel research question: Can we automate the generation\nof popular headlines on social media? We collect more than 1 million posts of\n42,447 celebrities from public data of Xiaohongshu, which is a well-known\nsocial media platform in China. We then conduct careful observations on the\nheadlines of these posts. Observation results demonstrate that trends and\npersonal styles are widespread in headlines on social medias and have\nsignificant contribution to posts's popularity. Motivated by these insights, we\npresent MEBART, which combines Multiple preference-Extractors with\nBidirectional and Auto-Regressive Transformers (BART), capturing trends and\npersonal styles to generate popular headlines on social medias. We perform\nextensive experiments on real-world datasets and achieve state-of-the-art\nperformance compared with several advanced baselines. In addition, ablation and\ncase studies demonstrate that MEBART advances in capturing trends and personal\nstyles.",
        "translated": "帖子作为社交媒体上用户生成内容的重要容器，具有巨大的社会影响力和商业价值。作为一篇文章不可或缺的组成部分，标题对文章的受欢迎程度起着决定性的作用。然而，目前主流的标题生成方法仍然是手工书写，这是不稳定的，需要广泛的人工努力。这促使我们探索一个新颖的研究问题: 我们能够自动生成社会媒体上的热门标题吗？我们从 Xiaohongshu 的公共数据中收集了超过100万条关于42447名名人的帖子，这是中国著名的社交媒体平台。然后我们对这些帖子的标题进行仔细的观察。观察结果表明，趋势和个人风格在社交媒体的标题中普遍存在，并对帖子的受欢迎程度有重要贡献。在这些见解的激励下，我们展示了 MEBART，它结合了双向和自动回归变压器(BART)的多重偏好提取器，捕捉趋势和个人风格，在社交媒体上产生流行的标题。我们在真实世界的数据集上进行广泛的实验，并与几个高级基线相比取得了最先进的性能。此外，消融和案例研究表明，MEBART 在捕捉趋势和个人风格的进步。"
    },
    {
        "title": "Speaker attribution in German parliamentary debates with QLoRA-adapted\n  large language models",
        "url": "http://arxiv.org/abs/2309.09902v1",
        "pub_date": "2023-09-18",
        "summary": "The growing body of political texts opens up new opportunities for rich\ninsights into political dynamics and ideologies but also increases the workload\nfor manual analysis. Automated speaker attribution, which detects who said what\nto whom in a speech event and is closely related to semantic role labeling, is\nan important processing step for computational text analysis. We study the\npotential of the large language model family Llama 2 to automate speaker\nattribution in German parliamentary debates from 2017-2021. We fine-tune Llama\n2 with QLoRA, an efficient training strategy, and observe our approach to\nachieve competitive performance in the GermEval 2023 Shared Task On Speaker\nAttribution in German News Articles and Parliamentary Debates. Our results shed\nlight on the capabilities of large language models in automating speaker\nattribution, revealing a promising avenue for computational analysis of\npolitical discourse and the development of semantic role labeling systems.",
        "translated": "越来越多的政治文本为深入了解政治动态和意识形态提供了新的机会，但也增加了手工分析的工作量。自动说话人归属是计算文本分析的一个重要处理步骤，它检测在语音事件中谁对谁说了什么，并与语义角色标注密切相关。我们研究了大语言模型家族 Llama2在2017-2021年德国议会辩论中自动分配发言者的潜力。我们用 QLoRA 对美洲驼2号进行微调，这是一种有效的培训策略，并在德国新闻文章和议会辩论中观察我们在 GermEval 2023共同任务中实现竞争性表现的方法。我们的研究结果揭示了大型语言模型在说话人归属自动化方面的能力，为政治话语的计算分析和语义角色标注系统的发展提供了一条有希望的途径。"
    },
    {
        "title": "Not Enough Labeled Data? Just Add Semantics: A Data-Efficient Method for\n  Inferring Online Health Texts",
        "url": "http://arxiv.org/abs/2309.09877v1",
        "pub_date": "2023-09-18",
        "summary": "User-generated texts available on the web and social platforms are often long\nand semantically challenging, making them difficult to annotate. Obtaining\nhuman annotation becomes increasingly difficult as problem domains become more\nspecialized. For example, many health NLP problems require domain experts to be\na part of the annotation pipeline. Thus, it is crucial that we develop\nlow-resource NLP solutions able to work with this set of limited-data problems.\nIn this study, we employ Abstract Meaning Representation (AMR) graphs as a\nmeans to model low-resource Health NLP tasks sourced from various online health\nresources and communities. AMRs are well suited to model online health texts as\nthey can represent multi-sentence inputs, abstract away from complex\nterminology, and model long-distance relationships between co-referring tokens.\nAMRs thus improve the ability of pre-trained language models to reason about\nhigh-complexity texts. Our experiments show that we can improve performance on\n6 low-resource health NLP tasks by augmenting text embeddings with semantic\ngraph embeddings. Our approach is task agnostic and easy to merge into any\nstandard text classification pipeline. We experimentally validate that AMRs are\nuseful in the modeling of complex texts by analyzing performance through the\nlens of two textual complexity measures: the Flesch Kincaid Reading Level and\nSyntactic Complexity. Our error analysis shows that AMR-infused language models\nperform better on complex texts and generally show less predictive variance in\nthe presence of changing complexity.",
        "translated": "在网络和社交平台上提供的用户生成的文本通常很长，在语义上也很有挑战性，这使得它们很难注释。随着问题域变得更加专门化，获取人工注释变得越来越困难。例如，许多健康 NLP 问题要求领域专家成为注释管道的一部分。因此，开发能够处理这组有限数据问题的低资源 NLP 解决方案是至关重要的。在本研究中，我们使用抽象意义表示(AMR)图作为一种模型来源于各种在线健康资源和社区的低资源健康自然语言处理任务的手段。AMR 非常适合为在线健康文本建模，因为它们可以表示多句输入，从复杂的术语中抽象出来，并建模共同引用标记之间的远程关系。AMR 因此提高了预训练语言模型对高复杂度文本进行推理的能力。实验结果表明，文本嵌入和语义图嵌入相结合可以提高6种低资源健康 NLP 任务的性能。我们的方法是任务不可知的，并且很容易合并到任何标准的文本分类管道中。通过分析金凯德阅读水平和句法复杂度这两个文本复杂度指标的表现，实验验证了 AMR 在复杂文本建模中的有效性。我们的错误分析表明，基于 AMR 的语言模型在复杂文本中表现得更好，并且在复杂度变化的情况下表现出更少的预测方差。"
    },
    {
        "title": "Instruction-Following Speech Recognition",
        "url": "http://arxiv.org/abs/2309.09843v1",
        "pub_date": "2023-09-18",
        "summary": "Conventional end-to-end Automatic Speech Recognition (ASR) models primarily\nfocus on exact transcription tasks, lacking flexibility for nuanced user\ninteractions. With the advent of Large Language Models (LLMs) in speech\nprocessing, more organic, text-prompt-based interactions have become possible.\nHowever, the mechanisms behind these models' speech understanding and\n\"reasoning\" capabilities remain underexplored. To study this question from the\ndata perspective, we introduce instruction-following speech recognition,\ntraining a Listen-Attend-Spell model to understand and execute a diverse set of\nfree-form text instructions. This enables a multitude of speech recognition\ntasks -- ranging from transcript manipulation to summarization -- without\nrelying on predefined command sets. Remarkably, our model, trained from scratch\non Librispeech, interprets and executes simple instructions without requiring\nLLMs or pre-trained speech modules. It also offers selective transcription\noptions based on instructions like \"transcribe first half and then turn off\nlistening,\" providing an additional layer of privacy and safety compared to\nexisting LLMs. Our findings highlight the significant potential of\ninstruction-following training to advance speech foundation models.",
        "translated": "传统的端到端自动语音识别(ASR)模型主要关注精确的转录任务，缺乏细微差别的用户交互的灵活性。随着大语言模型(LLM)在语音处理中的出现，更有机的、基于文本提示的交互成为可能。然而，这些模型的语音理解和“推理”能力背后的机制仍然没有得到充分的探索。为了从数据的角度研究这个问题，我们引入了指令跟踪语音识别，训练了一个“听-听-拼写”模型来理解和执行一组形式多样的自由文本指令。这可以实现大量的语音识别任务——从文本操作到摘要——而不依赖于预定义的命令集。值得注意的是，我们的模型，从头开始在 Librispeech 上训练，解释和执行简单的指令，而不需要 LLM 或预先训练的语音模块。它还提供了基于“转录前半部分，然后关闭监听”指令的选择性转录选项，与现有的 LLM 相比，提供了一个额外的隐私和安全层。我们的研究结果强调了指令跟踪训练在推进言语基础模型方面的重要潜力。"
    },
    {
        "title": "HypR: A comprehensive study for ASR hypothesis revising with a reference\n  corpus",
        "url": "http://arxiv.org/abs/2309.09838v2",
        "pub_date": "2023-09-18",
        "summary": "With the development of deep learning, automatic speech recognition (ASR) has\nmade significant progress. To further enhance the performance, revising\nrecognition results is one of the lightweight but efficient manners. Various\nmethods can be roughly classified into N-best reranking methods and error\ncorrection models. The former aims to select the hypothesis with the lowest\nerror rate from a set of candidates generated by ASR for a given input speech.\nThe latter focuses on detecting recognition errors in a given hypothesis and\ncorrecting these errors to obtain an enhanced result. However, we observe that\nthese studies are hardly comparable to each other as they are usually evaluated\non different corpora, paired with different ASR models, and even use different\ndatasets to train the models. Accordingly, we first concentrate on releasing an\nASR hypothesis revising (HypR) dataset in this study. HypR contains several\ncommonly used corpora (AISHELL-1, TED-LIUM 2, and LibriSpeech) and provides 50\nrecognition hypotheses for each speech utterance. The checkpoint models of the\nASR are also published. In addition, we implement and compare several classic\nand representative methods, showing the recent research progress in revising\nspeech recognition results. We hope the publicly available HypR dataset can\nbecome a reference benchmark for subsequent research and promote the school of\nresearch to an advanced level.",
        "translated": "随着深度学习的发展，自动语音识别技术(ASR)取得了长足的进步。为了进一步提高识别性能，修正识别结果是一种轻量级而有效的方法。各种方法大致可分为 N 种最佳重新排序方法和误差修正模型。前者的目的是从一组由 ASR 产生的候选语音中选择出误码率最低的假设。后者侧重于在给定的假设中检测识别错误并纠正这些错误以获得增强的结果。然而，我们观察到这些研究很难相互比较，因为它们通常在不同的语料库中进行评估，与不同的 ASR 模型配对，甚至使用不同的数据集来训练模型。因此，在本研究中，我们首先集中于发布一个 ASR 假设修正(HypR)数据集。HypR 包含几个常用的语料库(AISHELL-1、 TED-LIUM 2和 LibriLanguage) ，并为每个语音语句提供50个识别假设。ASR 的检查点模型也被发布。此外，我们实现并比较了几种经典的和有代表性的语音识别方法，展示了修正语音识别结果的最新研究进展。我们希望公开的 HypR 数据集能够成为后续研究的参考基准，并将研究学派推向更高的水平。"
    },
    {
        "title": "RECAP: Retrieval-Augmented Audio Captioning",
        "url": "http://arxiv.org/abs/2309.09836v1",
        "pub_date": "2023-09-18",
        "summary": "We present RECAP (REtrieval-Augmented Audio CAPtioning), a novel and\neffective audio captioning system that generates captions conditioned on an\ninput audio and other captions similar to the audio retrieved from a datastore.\nAdditionally, our proposed method can transfer to any domain without the need\nfor any additional fine-tuning. To generate a caption for an audio sample, we\nleverage an audio-text model CLAP to retrieve captions similar to it from a\nreplaceable datastore, which are then used to construct a prompt. Next, we feed\nthis prompt to a GPT-2 decoder and introduce cross-attention layers between the\nCLAP encoder and GPT-2 to condition the audio for caption generation.\nExperiments on two benchmark datasets, Clotho and AudioCaps, show that RECAP\nachieves competitive performance in in-domain settings and significant\nimprovements in out-of-domain settings. Additionally, due to its capability to\nexploit a large text-captions-only datastore in a \\textit{training-free}\nfashion, RECAP shows unique capabilities of captioning novel audio events never\nseen during training and compositional audios with multiple events. To promote\nresearch in this space, we also release 150,000+ new weakly labeled captions\nfor AudioSet, AudioCaps, and Clotho.",
        "translated": "我们提出 RECAP (检索-增强音频字幕) ，一个新颖和有效的音频字幕系统，生成字幕条件的输入音频和其他类似的从数据存储检索的音频标题。此外，我们提出的方法可以转移到任何领域，而不需要任何额外的微调。为了为音频样本生成标题，我们利用音频文本模型 CLAP 从可替换的数据存储中检索类似的标题，然后使用这些标题构造提示符。接下来，我们将此提示提供给 GPT-2解码器，并在 CLAP 编码器和 GPT-2之间引入交叉注意层，以调节音频以生成标题。在 Clotho 和 AudioCaps 两个基准数据集上的实验表明，RECAP 在域内设置方面取得了具有竞争力的性能，在域外设置方面也取得了显著的改进。此外，由于 RECAP 能够以文本{无训练}的方式利用大型纯文本标题数据存储，它显示了在训练期间从未见过的新颖音频事件标题的独特能力，以及具有多个事件的合成音频。为了促进这方面的研究，我们还为 AudioSet、 AudioCaps 和 Clotho 发布了150,000多个新的弱标签字幕。"
    },
    {
        "title": "Task Selection and Assignment for Multi-modal Multi-task Dialogue Act\n  Classification with Non-stationary Multi-armed Bandits",
        "url": "http://arxiv.org/abs/2309.09832v1",
        "pub_date": "2023-09-18",
        "summary": "Multi-task learning (MTL) aims to improve the performance of a primary task\nby jointly learning with related auxiliary tasks. Traditional MTL methods\nselect tasks randomly during training. However, both previous studies and our\nresults suggest that such the random selection of tasks may not be helpful, and\ncan even be harmful to performance. Therefore, new strategies for task\nselection and assignment in MTL need to be explored. This paper studies the\nmulti-modal, multi-task dialogue act classification task, and proposes a method\nfor selecting and assigning tasks based on non-stationary multi-armed bandits\n(MAB) with discounted Thompson Sampling (TS) using Gaussian priors. Our\nexperimental results show that in different training stages, different tasks\nhave different utility. Our proposed method can effectively identify the task\nutility, actively avoid useless or harmful tasks, and realise the task\nassignment during training. Our proposed method is significantly superior in\nterms of UAR and F1 to the single-task and multi-task baselines with p-values &lt;\n0.05. Further analysis of experiments indicates that for the dataset with the\ndata imbalance problem, our proposed method has significantly higher stability\nand can obtain consistent and decent performance for minority classes. Our\nproposed method is superior to the current state-of-the-art model.",
        "translated": "多任务学习(MTL)的目的是通过与相关辅助任务的联合学习来提高主要任务的绩效。传统的 MTL 方法在训练过程中随机选择任务。然而，以前的研究和我们的结果都表明，这种任务的随机选择可能没有帮助，甚至可能有害的表现。因此，有必要探索新的任务选择和任务分配策略。研究了多模态、多任务对话行为分类任务，提出了一种基于高斯先验的非平稳多武装土匪(MAB)任务选择和分配方法。实验结果表明，在不同的训练阶段，不同的任务有不同的效用。该方法能够有效地识别任务效用，主动避免无用或有害的任务，实现训练过程中的任务分配。我们提出的方法在 UAR 和 F1方面明显优于单任务和多任务基线，p 值 < 0.05。进一步的实验分析表明，对于存在数据不平衡问题的数据集，本文提出的方法具有较高的稳定性，能够获得少数类的一致性和良好的性能。我们提出的方法优于目前最先进的模型。"
    },
    {
        "title": "Efficient Avoidance of Vulnerabilities in Auto-completed Smart Contract\n  Code Using Vulnerability-constrained Decoding",
        "url": "http://arxiv.org/abs/2309.09826v1",
        "pub_date": "2023-09-18",
        "summary": "Auto-completing code enables developers to speed up coding significantly.\nRecent advances in transformer-based large language model (LLM) technologies\nhave been applied to code synthesis. However, studies show that many of such\nsynthesized codes contain vulnerabilities. We propose a novel\nvulnerability-constrained decoding approach to reduce the amount of vulnerable\ncode generated by such models. Using a small dataset of labeled vulnerable\nlines of code, we fine-tune an LLM to include vulnerability labels when\ngenerating code, acting as an embedded classifier. Then, during decoding, we\ndeny the model to generate these labels to avoid generating vulnerable code. To\nevaluate the method, we chose to automatically complete Ethereum Blockchain\nsmart contracts (SCs) as the case study due to the strict requirements of SC\nsecurity. We first fine-tuned the 6-billion-parameter GPT-J model using 186,397\nEthereum SCs after removing the duplication from 2,217,692 SCs. The fine-tuning\ntook more than one week using ten GPUs. The results showed that our fine-tuned\nmodel could synthesize SCs with an average BLEU (BiLingual Evaluation\nUnderstudy) score of 0.557. However, many codes in the auto-completed SCs were\nvulnerable. Using the code before the vulnerable line of 176 SCs containing\ndifferent types of vulnerabilities to auto-complete the code, we found that\nmore than 70% of the auto-completed codes were insecure. Thus, we further\nfine-tuned the model on other 941 vulnerable SCs containing the same types of\nvulnerabilities and applied vulnerability-constrained decoding. The fine-tuning\ntook only one hour with four GPUs. We then auto-completed the 176 SCs again and\nfound that our approach could identify 62% of the code to be generated as\nvulnerable and avoid generating 67% of them, indicating the approach could\nefficiently and effectively avoid vulnerabilities in the auto-completed code.",
        "translated": "自动完成代码使开发人员能够显著加快编码速度。基于变换器的大语言模型(LLM)技术的最新进展已经被应用到代码合成中。然而，研究表明，许多这样的合成代码包含漏洞。我们提出了一种新的漏洞约束译码方法，以减少这类模型产生的漏洞代码量。我们使用一个标有易受攻击代码行的小数据集，作为嵌入式分类器，在生成代码时对 LLM 进行微调，使其包含易受攻击的标签。然后，在解码过程中，我们拒绝生成这些标签的模型，以避免生成易受攻击的代码。为了评价该方法，我们选择自动完成以太区块链智能合同(SC)作为案例研究，因为供应链安全的严格要求。我们首先在去除2,217,692个 SC 的重复后，使用186,397个以太粒子对60亿参数的 GPT-J 模型进行了微调。使用10个 GPU 进行微调花了一个多星期的时间。结果表明，我们的微调模型能够合成平均 BLEU (双语评估替代学习)分数为0.557的 SC。然而，自动完成的 SC 中的许多代码是易受攻击的。通过对176个包含不同漏洞类型的 SC 的漏洞行之前的代码进行自动补全，我们发现70% 以上的自动补全代码是不安全的。因此，我们进一步微调了模型的其他941个脆弱的 SC 包含相同类型的脆弱性和应用的脆弱性约束解码。对四个 GPU 的微调只花了一个小时。然后，我们再次自动完成了176个 SC，发现我们的方法可以确定62% 的代码生成为脆弱的，并避免生成其中的67% ，这表明该方法可以有效地避免自动完成的代码中的脆弱性。"
    },
    {
        "title": "AMuRD: Annotated Multilingual Receipts Dataset for Cross-lingual Key\n  Information Extraction and Classification",
        "url": "http://arxiv.org/abs/2309.09800v1",
        "pub_date": "2023-09-18",
        "summary": "Key information extraction involves recognizing and extracting text from\nscanned receipts, enabling retrieval of essential content, and organizing it\ninto structured documents. This paper presents a novel multilingual dataset for\nreceipt extraction, addressing key challenges in information extraction and\nitem classification. The dataset comprises $47,720$ samples, including\nannotations for item names, attributes like (price, brand, etc.), and\nclassification into $44$ product categories. We introduce the InstructLLaMA\napproach, achieving an F1 score of $0.76$ and an accuracy of $0.68$ for key\ninformation extraction and item classification. We provide code, datasets, and\ncheckpoints.\\footnote{\\url{https://github.com/Update-For-Integrated-Business-AI/AMuRD}}.",
        "translated": "关键的信息抽取包括从扫描的收据中识别和提取文本，检索重要内容，并将其组织成结构化文档。本文提出了一个新的多语言数据集，用于收据提取，解决信息抽取和项目分类中的关键挑战。该数据集包含47,720美元的样本，包括商品名称、属性(价格、品牌等)的注释，以及44美元产品类别的分类。我们引入了 DirectllaMA 方法，对于关键信息抽取和项目分类，F1得分为0.76美元，准确度为0.68美元。我们提供代码、数据集和检查点。{ url { https://github.com/update-for-integrated-business-ai/amurd }}."
    },
    {
        "title": "Interactive Distillation of Large Single-Topic Corpora of Scientific\n  Papers",
        "url": "http://arxiv.org/abs/2309.10772v1",
        "pub_date": "2023-09-19",
        "summary": "Highly specific datasets of scientific literature are important for both\nresearch and education. However, it is difficult to build such datasets at\nscale. A common approach is to build these datasets reductively by applying\ntopic modeling on an established corpus and selecting specific topics. A more\nrobust but time-consuming approach is to build the dataset constructively in\nwhich a subject matter expert (SME) handpicks documents. This method does not\nscale and is prone to error as the dataset grows. Here we showcase a new tool,\nbased on machine learning, for constructively generating targeted datasets of\nscientific literature. Given a small initial \"core\" corpus of papers, we build\na citation network of documents. At each step of the citation network, we\ngenerate text embeddings and visualize the embeddings through dimensionality\nreduction. Papers are kept in the dataset if they are \"similar\" to the core or\nare otherwise pruned through human-in-the-loop selection. Additional insight\ninto the papers is gained through sub-topic modeling using SeNMFk. We\ndemonstrate our new tool for literature review by applying it to two different\nfields in machine learning.",
        "translated": "高度特定的科学文献数据集对研究和教育都很重要。然而，很难大规模地建立这样的数据集。一种常见的方法是通过在已建立的语料库上应用主题建模并选择特定的主题来简化地构建这些数据集。一个更健壮但耗时的方法是建设性地构建数据集，其中由主题专家(SME)精选文档。此方法不可伸缩，并且随着数据集的增长容易出错。在这里，我们展示了一个新的工具，基于机器学习，建设性地生成有针对性的数据集的科学文献。给定一个小型的初始“核心”论文语料库，我们建立一个文献引用网络。在引用网络的每一个步骤中，我们生成文本嵌入，并通过降维将嵌入可视化。如果论文与核心内容“相似”，或者通过人在回路中的选择进行修剪，那么论文就会保存在数据集中。通过使用 SeNMFk 进行子主题建模，可以进一步了解论文。通过将其应用于机器学习的两个不同领域，我们展示了我们新的文献综述工具。"
    },
    {
        "title": "MelodyGLM: Multi-task Pre-training for Symbolic Melody Generation",
        "url": "http://arxiv.org/abs/2309.10738v1",
        "pub_date": "2023-09-19",
        "summary": "Pre-trained language models have achieved impressive results in various music\nunderstanding and generation tasks. However, existing pre-training methods for\nsymbolic melody generation struggle to capture multi-scale, multi-dimensional\nstructural information in note sequences, due to the domain knowledge\ndiscrepancy between text and music. Moreover, the lack of available large-scale\nsymbolic melody datasets limits the pre-training improvement. In this paper, we\npropose MelodyGLM, a multi-task pre-training framework for generating melodies\nwith long-term structure. We design the melodic n-gram and long span sampling\nstrategies to create local and global blank infilling tasks for modeling the\nlocal and global structures in melodies. Specifically, we incorporate pitch\nn-grams, rhythm n-grams, and their combined n-grams into the melodic n-gram\nblank infilling tasks for modeling the multi-dimensional structures in\nmelodies. To this end, we have constructed a large-scale symbolic melody\ndataset, MelodyNet, containing more than 0.4 million melody pieces. MelodyNet\nis utilized for large-scale pre-training and domain-specific n-gram lexicon\nconstruction. Both subjective and objective evaluations demonstrate that\nMelodyGLM surpasses the standard and previous pre-training methods. In\nparticular, subjective evaluations show that, on the melody continuation task,\nMelodyGLM achieves average improvements of 0.82, 0.87, 0.78, and 0.94 in\nconsistency, rhythmicity, structure, and overall quality, respectively.\nNotably, MelodyGLM nearly matches the quality of human-composed melodies on the\nmelody inpainting task.",
        "translated": "经过训练的语言模型在各种音乐理解和生成任务中取得了令人印象深刻的成果。然而，现有的符号旋律产生的预训练方法由于文本和音乐在领域知识上的差异，很难捕捉到音符序列中多尺度、多维度的结构信息。此外，由于缺乏大规模的符号旋律数据集，限制了训练前的改进。在本文中，我们提出了 MelodyGLM，一个多任务预训练框架，用于生成具有长期结构的旋律。我们设计旋律 n-gram 和大跨度采样策略，创建局部和全局空白填充任务，以建立旋律中局部和全局结构的模型。具体来说，我们将音高 n-gram、节奏 n-gram 及其组合 n-gram 合并到旋律 n-gram 空白填充任务中，以建立旋律中的多维结构模型。为此，我们建立了一个大规模的符号旋律数据库 MelodyNet，其中包含了超过40万个旋律片段。MelodyNet 用于大规模的预训练和领域特定的 n 元词典构建。主观和客观的评价表明，旋律 GLM 超过了标准和以往的预训练方法。特别是主观评价表明，旋律延续任务中，旋律 GLM 在一致性、节奏性、结构性和整体质量方面的平均提高分别为0.82、0.87、0.78和0.94。值得注意的是，MelodyGLM 在旋律修饰任务中几乎匹配人工创作的旋律的质量。"
    },
    {
        "title": "Large language models can accurately predict searcher preferences",
        "url": "http://arxiv.org/abs/2309.10621v1",
        "pub_date": "2023-09-19",
        "summary": "Relevance labels, which indicate whether a search result is valuable to a\nsearcher, are key to evaluating and optimising search systems. The best way to\ncapture the true preferences of users is to ask them for their careful feedback\non which results would be useful, but this approach does not scale to produce a\nlarge number of labels. Getting relevance labels at scale is usually done with\nthird-party labellers, who judge on behalf of the user, but there is a risk of\nlow-quality data if the labeller doesn't understand user needs. To improve\nquality, one standard approach is to study real users through interviews, user\nstudies and direct feedback, find areas where labels are systematically\ndisagreeing with users, then educate labellers about user needs through judging\nguidelines, training and monitoring. This paper introduces an alternate\napproach for improving label quality. It takes careful feedback from real\nusers, which by definition is the highest-quality first-party gold data that\ncan be derived, and develops an large language model prompt that agrees with\nthat data.\n  We present ideas and observations from deploying language models for\nlarge-scale relevance labelling at Bing, and illustrate with data from TREC. We\nhave found large language models can be effective, with accuracy as good as\nhuman labellers and similar capability to pick the hardest queries, best runs,\nand best groups. Systematic changes to the prompts make a difference in\naccuracy, but so too do simple paraphrases. To measure agreement with real\nsearchers needs high-quality ``gold'' labels, but with these we find that\nmodels produce better labels than third-party workers, for a fraction of the\ncost, and these labels let us train notably better rankers.",
        "translated": "相关标签是评估和优化搜索系统的关键，它表明搜索结果是否对搜索者有价值。捕捉用户真实偏好的最佳方法是请求他们仔细反馈哪些结果是有用的，但是这种方法不会产生大量的标签。获得相关标签的规模通常是与第三方标签，谁代表用户的判断，但有一个风险，低质量的数据，如果标签不了解用户的需求。为了提高质量，一个标准的方法是通过访谈、用户研究和直接反馈来研究真正的用户，找出标签系统性地与用户意见不一致的地方，然后通过判断指南、培训和监督来教育标签商了解用户需求。本文介绍了一种提高标签质量的替代方法。它从真正的用户那里获得仔细的反馈，从定义上来说，这是可以派生出来的最高质量的第一方黄金数据，并开发一个大型的语言模型提示符来与这些数据保持一致。我们提出的想法和观察从部署语言模型的大规模相关性标签在必应，并说明了从 TREC 的数据。我们已经发现，大型语言模型可以非常有效，其准确性与人类标签器一样好，并且具有挑选最难的查询、最佳运行和最佳组的类似功能。对提示语进行系统的改动会在准确性上有所不同，但简单的意译也会有所不同。为了衡量与真正的搜索者的一致性，需要高质量的“黄金”标签，但是通过这些标签，我们发现模特们比第三方工作者生产出更好的标签，只花费了一小部分成本，而且这些标签让我们培训了明显更好的排名者。"
    },
    {
        "title": "A Hierarchical Neural Framework for Classification and its Explanation\n  in Large Unstructured Legal Documents",
        "url": "http://arxiv.org/abs/2309.10563v1",
        "pub_date": "2023-09-19",
        "summary": "Automatic legal judgment prediction and its explanation suffer from the\nproblem of long case documents exceeding tens of thousands of words, in\ngeneral, and having a non-uniform structure. Predicting judgments from such\ndocuments and extracting their explanation becomes a challenging task, more so\non documents with no structural annotation. We define this problem as \"scarce\nannotated legal documents\" and explore their lack of structural information and\ntheir long lengths with a deep learning-based classification framework which we\ncall MESc; \"Multi-stage Encoder-based Supervised with-clustering\"; for judgment\nprediction. Specifically, we divide a document into parts to extract their\nembeddings from the last four layers of a custom fine-tuned Large Language\nModel, and try to approximate their structure through unsupervised clustering.\nWhich we use in another set of transformer encoder layers to learn the\ninter-chunk representations. We explore the adaptability of LLMs with\nmulti-billion parameters (GPT-Neo, and GPT-J) to legal texts and their\nintra-domain(legal) transfer learning capacity. Alongside this, we compare\ntheir performance with MESc and the impact of combining embeddings from their\nlast layers. For such hierarchical models, we also propose an explanation\nextraction algorithm named ORSE; Occlusion sensitivity-based Relevant Sentence\nExtractor;",
        "translated": "法律判决自动预测及其解释一般都存在案件文件长度超过万字、结构不统一等问题。从这些文献中预测判断并提取其解释成为一项具有挑战性的任务，对于没有结构性注释的文献更是如此。我们将这个问题定义为“稀缺的注释法律文件”，并通过一个基于深度学习的分类框架，即 MESc; “基于多级编码器的带聚类监督”，来探索它们缺乏结构信息和长度的判断预测。具体来说，我们将一个文档分成几个部分，从定制的微调大语言模型的最后四层中提取它们的嵌入，并尝试通过无监督聚类来近似它们的结构。我们在另一组转换器编码器层中使用它来学习块间表示。我们探讨了具有数十亿参数的 LLM (GPT-Neo 和 GPT-J)对法律文本的适应性及其域内(法律)迁移学习能力。除此之外，我们还比较了它们与 MESc 的性能以及组合最后一层嵌入的影响。对于这样的层次模型，我们还提出了一种解释提取算法 ORSE，基于遮挡敏感度的相关句子提取算法;"
    },
    {
        "title": "Proposal for an Organic Web, The missing link between the Web and the\n  Semantic Web, Part 1",
        "url": "http://arxiv.org/abs/2309.10531v1",
        "pub_date": "2023-09-19",
        "summary": "A huge amount of information is produced in digital form. The Semantic Web\nstems from the realisation that dealing efficiently with this production\nrequires getting better at interlinking digital informational resources\ntogether. Its focus is on linking data. Linking data isn't enough. We need to\nprovide infrastructural support for linking all sorts of informational\nresources including resources whose understanding and fine interlinking\nrequires domain-specific human expertise. At times when many problems scale to\nplanetary dimensions, it is essential to scale coordination of information\nprocessing and information production, without giving up on expertise and depth\nof analysis, nor forcing languages and formalisms onto thinkers,\ndecision-makers and innovators that are only suitable to some forms of\nintelligence. This article makes a proposal in this direction and in line with\nthe idea of interlinking championed by the Semantic Web.",
        "translated": "大量的信息以数字形式产生。语义网源于这样一种认识，即有效地处理这种产品需要更好地将数字信息资源连接在一起。它的重点是链接数据。链接数据是不够的。我们需要提供基础设施支持，将各种信息资源联系起来，包括那些需要特定领域的人类专门知识才能理解和精细联系的资源。当许多问题扩大到地球层面时，必须扩大信息处理和信息生产的协调，同时不放弃专门知识和分析深度，也不将语言和形式主义强加给只适合某些形式的智力的思想家、决策者和创新者。本文在这个方向上提出了一个建议，并且与语义 Web 所倡导的互连思想保持一致。"
    },
    {
        "title": "SlimPajama-DC: Understanding Data Combinations for LLM Training",
        "url": "http://arxiv.org/abs/2309.10818v1",
        "pub_date": "2023-09-19",
        "summary": "This paper aims to understand the impacts of various data combinations (e.g.,\nweb text, wikipedia, github, books) on the training of large language models\nusing SlimPajama. SlimPajama is a rigorously deduplicated, multi-source\ndataset, which has been refined and further deduplicated to 627B tokens from\nthe extensive 1.2T tokens RedPajama dataset contributed by Together. We've\ntermed our research as SlimPajama-DC, an empirical analysis designed to uncover\nfundamental characteristics and best practices associated with employing\nSlimPajama in the training of large language models. During our research with\nSlimPajama, two pivotal observations emerged: (1) Global deduplication vs.\nlocal deduplication. We analyze and discuss how global (across different\nsources of datasets) and local (within the single source of dataset)\ndeduplications affect the performance of trained models. (2) Proportions of\nhigh-quality/highly-deduplicated multi-source datasets in the combination. To\nstudy this, we construct six configurations of SlimPajama dataset and train\nindividual ones using 1.3B Cerebras-GPT model with Alibi and SwiGLU. Our best\nconfiguration outperforms the 1.3B model trained on RedPajama using the same\nnumber of training tokens by a significant margin. All our 1.3B models are\ntrained on Cerebras 16$\\times$ CS-2 cluster with a total of 80 PFLOP/s in bf16\nmixed precision. We further extend our discoveries (such as increasing data\ndiversity is crucial after global deduplication) on a 7B model with large\nbatch-size training. Our models and the separate SlimPajama-DC datasets are\navailable at: https://huggingface.co/MBZUAI-LLM and\nhttps://huggingface.co/datasets/cerebras/SlimPajama-627B.",
        "translated": "本文旨在了解各种数据组合(如网络文本、维基百科、 github、图书)对使用 SlimPajama 训练大型语言模型的影响。SlimPajama 是一个严格的重复数据集，多源数据集已经被完善，并从由 Together 提供的广泛的1.2 T 令牌 RedPajama 数据集进一步重复到627B 令牌。我们称我们的研究为 SlimPajama-DC，这是一个实证分析，旨在揭示与使用 SlimPajama 训练大型语言模型相关的基本特征和最佳实践。在我们使用 SlimPajama 进行的研究中，出现了两个关键的观察结果: (1)全局重复数据删除和局部重复数据删除。我们分析和讨论全局(跨不同数据集来源)和局部(在单个数据集来源内)重复数据删除如何影响训练模型的性能。(2)组合中高质量/高重复度多源数据集的比例。为了研究这个问题，我们构建了6个 SlimPajama 数据集的构型，并使用1.3 B 的 Cerebras-GPT 模型与 Alibi 和 SwiGLU 相结合来训练个体的构型。我们的最佳配置比使用相同数量的训练令牌在 RedPajama 上训练的1.3 B 型号要好得多。我们所有的1.3 B 型号都是在 Cerebras 16美元乘以 $CS-2集群上训练的，总共80 PFLOP/s，bf16混合精度。我们进一步扩展了我们的发现(例如，在全球重复数据删除之后，增加数据多样性是至关重要的)在大批量训练的7B 模型上。我们的模型和单独的 Slimpajama-DC 数据集可以在以下 https://huggingface.co/mbzuai-llm 和 https://huggingface.co/datasets/cerebras/slimpajama-627b 获得。"
    },
    {
        "title": "Natural Language Embedded Programs for Hybrid Language Symbolic\n  Reasoning",
        "url": "http://arxiv.org/abs/2309.10814v1",
        "pub_date": "2023-09-19",
        "summary": "How can we perform computations over natural language representations to\nsolve tasks that require symbolic and numeric reasoning? We propose natural\nlanguage embedded programs (NLEP) as a unifying framework for addressing\nmath/symbolic reasoning, natural language understanding, and instruction\nfollowing tasks. Our approach prompts a language model to generate full Python\nprograms that define functions over data structures which contain natural\nlanguage representations of structured knowledge. A Python interpreter then\nexecutes the generated code and prints the output. Despite using a task-general\nprompt, we find that this approach can improve upon strong baselines across a\nrange of different tasks including math and symbolic reasoning, text\nclassification, question answering, and instruction following. We further find\nthe generated programs are often interpretable and enable post-hoc verification\nof the intermediate reasoning steps.",
        "translated": "我们如何在自然语言表示上执行计算来解决需要符号和数字推理的任务？我们提出自然语言嵌入式程序(NLEP)作为解决数学/符号推理、自然语言理解和指令跟踪任务的统一框架。我们的方法提示语言模型生成完整的 Python 程序，这些程序在包含结构化知识的自然语言表示的数据结构上定义函数。然后，Python 解释器执行生成的代码并打印输出。尽管使用了任务一般提示，我们发现这种方法可以改善强大的基线跨一系列不同的任务，包括数学和符号推理，文本分类，问题回答和指令跟踪。我们进一步发现生成的程序通常是可解释的，并且能够对中间推理步骤进行事后验证。"
    },
    {
        "title": "Modeling interdisciplinary interactions among Physics, Mathematics &amp;\n  Computer Science",
        "url": "http://arxiv.org/abs/2309.10811v1",
        "pub_date": "2023-09-19",
        "summary": "Interdisciplinarity has over the recent years have gained tremendous\nimportance and has become one of the key ways of doing cutting edge research.\nIn this paper we attempt to model the citation flow across three different\nfields -- Physics (PHY), Mathematics (MA) and Computer Science (CS). For\ninstance, is there a specific pattern in which these fields cite one another?\nWe carry out experiments on a dataset comprising more than 1.2 million articles\ntaken from these three fields. We quantify the citation interactions among\nthese three fields through temporal bucket signatures. We present numerical\nmodels based on variants of the recently proposed relay-linking framework to\nexplain the citation dynamics across the three disciplines. These models make a\nmodest attempt to unfold the underlying principles of how citation links could\nhave been formed across the three fields over time.",
        "translated": "近年来，科际整合已获得极大的重视，并已成为进行前沿研究的主要方法之一。本文试图对物理学、数学和计算机科学三个不同领域的引文流进行建模。例如，是否存在一种特定的模式，这些字段在其中相互引用？我们对来自这三个领域的超过120万篇文章的数据集进行了实验。我们通过时间桶签名来量化这三个领域之间的引文交互作用。我们提出了基于最近提出的中继连接框架的变体的数值模型，以解释跨三个学科的引文动态。这些模型做了一个小小的尝试，揭示了引文链接如何随着时间的推移在这三个领域形成的基本原理。"
    },
    {
        "title": "Semantic Text Compression for Classification",
        "url": "http://arxiv.org/abs/2309.10809v1",
        "pub_date": "2023-09-19",
        "summary": "We study semantic compression for text where meanings contained in the text\nare conveyed to a source decoder, e.g., for classification. The main motivator\nto move to such an approach of recovering the meaning without requiring exact\nreconstruction is the potential resource savings, both in storage and in\nconveying the information to another node. Towards this end, we propose\nsemantic quantization and compression approaches for text where we utilize\nsentence embeddings and the semantic distortion metric to preserve the meaning.\nOur results demonstrate that the proposed semantic approaches result in\nsubstantial (orders of magnitude) savings in the required number of bits for\nmessage representation at the expense of very modest accuracy loss compared to\nthe semantic agnostic baseline. We compare the results of proposed approaches\nand observe that resource savings enabled by semantic quantization can be\nfurther amplified by semantic clustering. Importantly, we observe the\ngeneralizability of the proposed methodology which produces excellent results\non many benchmark text classification datasets with a diverse array of\ncontexts.",
        "translated": "我们研究文本的语义压缩，其中包含的意义传达给源解码器，例如，分类。采用这种不需要精确重建就能恢复意义的方法的主要动机是在存储和向另一个节点传输信息方面潜在的资源节省。为此，我们提出了利用句子嵌入和语义失真度量来保持文本意义的语义量化和压缩方法。我们的研究结果表明，与语义不可知基线相比，提出的语义方法在消息表示所需的比特数方面节省了大量(数量级) ，但代价是非常小的准确性损失。我们比较了提出的方法的结果，发现语义量化节省的资源可以通过语义聚类进一步放大。重要的是，我们观察到提出的方法的普遍性，产生了良好的结果在许多基准文本分类数据与不同的上下文阵列。"
    },
    {
        "title": "Language as the Medium: Multimodal Video Classification through text\n  only",
        "url": "http://arxiv.org/abs/2309.10783v1",
        "pub_date": "2023-09-19",
        "summary": "Despite an exciting new wave of multimodal machine learning models, current\napproaches still struggle to interpret the complex contextual relationships\nbetween the different modalities present in videos. Going beyond existing\nmethods that emphasize simple activities or objects, we propose a new\nmodel-agnostic approach for generating detailed textual descriptions that\ncaptures multimodal video information. Our method leverages the extensive\nknowledge learnt by large language models, such as GPT-3.5 or Llama2, to reason\nabout textual descriptions of the visual and aural modalities, obtained from\nBLIP-2, Whisper and ImageBind. Without needing additional finetuning of\nvideo-text models or datasets, we demonstrate that available LLMs have the\nability to use these multimodal textual descriptions as proxies for ``sight''\nor ``hearing'' and perform zero-shot multimodal classification of videos\nin-context. Our evaluations on popular action recognition benchmarks, such as\nUCF-101 or Kinetics, show these context-rich descriptions can be successfully\nused in video understanding tasks. This method points towards a promising new\nresearch direction in multimodal classification, demonstrating how an interplay\nbetween textual, visual and auditory machine learning models can enable more\nholistic video understanding.",
        "translated": "尽管多模态机器学习模型出现了令人兴奋的新浪潮，但目前的方法仍然难以解释视频中不同模式之间复杂的语境关系。除了强调简单活动或对象的现有方法之外，我们提出了一种新的模型无关方法，用于生成捕获多模态视频信息的详细文本描述。我们的方法利用大型语言模型(如 GPT-3.5或 Llama2)所学到的广泛知识，对从 BLIP-2，Whisper 和 ImageBind 获得的视觉和听觉模式的文本描述进行推理。无需对视频文本模型或数据集进行额外的微调，我们证明可用的 LLM 能够使用这些多模态文本描述作为“视觉”或“听觉”的代理，并在上下文中对视频进行零拍摄多模态分类。我们对流行的动作识别基准，如 UCF-101或动力学的评估表明，这些上下文丰富的描述可以成功地用于视频理解任务。该方法为多模态分类提供了一个新的研究方向，展示了文本、视觉和听觉机器学习模型之间的相互作用如何能够实现更全面的视频理解。"
    },
    {
        "title": "FRASIMED: a Clinical French Annotated Resource Produced through\n  Crosslingual BERT-Based Annotation Projection",
        "url": "http://arxiv.org/abs/2309.10770v1",
        "pub_date": "2023-09-19",
        "summary": "Natural language processing (NLP) applications such as named entity\nrecognition (NER) for low-resource corpora do not benefit from recent advances\nin the development of large language models (LLMs) where there is still a need\nfor larger annotated datasets. This research article introduces a methodology\nfor generating translated versions of annotated datasets through crosslingual\nannotation projection. Leveraging a language agnostic BERT-based approach, it\nis an efficient solution to increase low-resource corpora with few human\nefforts and by only using already available open data resources. Quantitative\nand qualitative evaluations are often lacking when it comes to evaluating the\nquality and effectiveness of semi-automatic data generation strategies. The\nevaluation of our crosslingual annotation projection approach showed both\neffectiveness and high accuracy in the resulting dataset. As a practical\napplication of this methodology, we present the creation of French Annotated\nResource with Semantic Information for Medical Entities Detection (FRASIMED),\nan annotated corpus comprising 2'051 synthetic clinical cases in French. The\ncorpus is now available for researchers and practitioners to develop and refine\nFrench natural language processing (NLP) applications in the clinical field\n(https://zenodo.org/record/8355629), making it the largest open annotated\ncorpus with linked medical concepts in French.",
        "translated": "自然语言处理(NLP)应用程序，如低资源语料库的命名实体识别(NER) ，不能从大型语言模型(LLM)的发展中获益，因为大型语言模型仍然需要更大的注释数据集。本文介绍了一种通过跨语言注释投影生成注释数据集翻译版本的方法。利用一种基于 BERT 的语言无关方法，它是一种有效的解决方案，可以用很少的人力资源增加低资源的语料库，并且只使用已有的开放数据资源。在评价半自动数据生成战略的质量和有效性时，往往缺乏定量和定性评价。对我们的跨语言注释投影方法的评估表明，在所得到的数据集中，该方法既有效又具有较高的准确性。作为这种方法的一个实际应用，我们介绍了用于医疗实体检测(FRASIMED)的语义信息创建的法语注释资源，这是一个包含2’051个法语合成临床病例的注释语料库。该语料库现在可供研究人员和从业人员开发和完善法语自然语言处理(nLP)应用在临床领域( https://zenodo.org/record/8355629) ，使其成为最大的开放注释语料库与相关的法语医学概念。"
    },
    {
        "title": "Evaluating large language models' ability to understand metaphor and\n  sarcasm using a screening test for Asperger syndrome",
        "url": "http://arxiv.org/abs/2309.10744v1",
        "pub_date": "2023-09-19",
        "summary": "Metaphors and sarcasm are precious fruits of our highly-evolved social\ncommunication skills. However, children with Asperger syndrome are known to\nhave difficulties in comprehending sarcasm, even if they possess a certain\nlevel of verbal IQ sufficient for understanding metaphors. Given that, a\nscreening test that scores the ability to understand metaphor and sarcasm has\nbeen used to differentiate Asperger syndrome from other symptoms exhibiting\nakin external behaviors (e.g., attention-deficit/hyperactivity disorder). This\nstudy uses the standardized test to examine the capability of recent large\nlanguage models (LLMs) in understanding human nuanced communication. The\nresults divulged that, whereas their ability to comprehend metaphors has been\nimproved with the increase of the number of model parameters, the improvement\nin sarcasm understanding was not observed. This implies that an alternative\napproach is imperative to imbue LLMs with the capacity to grasp sarcasm, which\nhas been associated with the amygdala, a pivotal cerebral region for emotional\nlearning, in the case of humans.",
        "translated": "隐喻和讽刺是我们高度进化的社交技巧的宝贵成果。然而，有阿斯伯格综合征的孩子在理解讽刺方面有困难，即使他们有一定程度的语言智商足以理解隐喻。有鉴于此，一项评分理解隐喻和讽刺能力的筛选测试已经被用来区分阿斯伯格综合征和其他表现出类似外部行为的症状(例如，注意力缺陷/多动障碍)。这项研究使用考试来检验最近的大型语言模型(LLM)在理解人类微妙交流方面的能力。结果表明，随着模型参数的增加，学生对隐喻的理解能力有所提高，但对讽刺的理解能力没有明显的提高。这意味着一个替代的方法是必要的，以灌输 LLM 的能力，掌握讽刺，这已与杏仁核，一个关键的大脑区域的情绪学习，在人类的情况下。"
    },
    {
        "title": "OpenBA: An Open-sourced 15B Bilingual Asymmetric seq2seq Model\n  Pre-trained from Scratch",
        "url": "http://arxiv.org/abs/2309.10706v1",
        "pub_date": "2023-09-19",
        "summary": "Large language models (LLMs) with billions of parameters have demonstrated\noutstanding performance on various natural language processing tasks. This\nreport presents OpenBA, an open-sourced 15B bilingual asymmetric seq2seq model,\nto contribute an LLM variant to the Chinese-oriented open-source model\ncommunity. We enhance OpenBA with effective and efficient techniques as well as\nadopt a three-stage training strategy to train the model from scratch. Our\nsolution can also achieve very competitive performance with only 380B tokens,\nwhich is better than LLaMA-70B on the BELEBELE benchmark, BLOOM-176B on the\nMMLU benchmark, GLM-130B on the C-Eval (hard) benchmark. This report provides\nthe main details to pre-train an analogous model, including pre-training data\nprocessing, Bilingual Flan data collection, the empirical observations that\ninspire our model architecture design, training objectives of different stages,\nand other enhancement techniques. We have refactored our code to follow the\ndesign principles of the Huggingface Transformers Library, making it more\nconvenient for developers to use, and released checkpoints of different\ntraining stages at https://huggingface.co/openBA. More details of our project\nare available at https://github.com/OpenNLG/openBA.git.",
        "translated": "具有数十亿参数的大型语言模型(LLM)在各种自然语言处理任务中表现出了出色的性能。本报告介绍了 OpenBA，一个开源的15B 双语非对称 seq2seq 模型，为面向中国的开源模型社区贡献了一个 LLM 变体。我们使用有效的技术增强 OpenBA，并采用三阶段培训策略从头开始培训模型。我们的解决方案也可以实现非常具有竞争力的性能，只有380B 令牌，这是优于 LLaMA-70B 的 BELEBELE 基准，BLOOM-176B 的 MMLU 基准，GLM-130B 的 C-Eval (硬)基准。该报告提供了预训练类似模型的主要细节，包括预训练数据处理、双语 Flan 数据收集、启发我们的模型架构设计的实证观察、不同阶段的训练目标以及其他增强技术。我们已经重构了我们的代码，以遵循 Huggingface 变形金刚库的设计原则，使它更便于开发人员使用，并在 https://Huggingface.co/openba 发布了不同培训阶段的检查点。有关计划的详情，请浏览 https://github.com/opennlg/openba.git。"
    },
    {
        "title": "Bravo MaRDI: A Wikibase Powered Knowledge Graph on Mathematics",
        "url": "http://arxiv.org/abs/2309.11484v1",
        "pub_date": "2023-09-20",
        "summary": "Mathematical world knowledge is a fundamental component of Wikidata. However,\nto date, no expertly curated knowledge graph has focused specifically on\ncontemporary mathematics. Addressing this gap, the Mathematical Research Data\nInitiative (MaRDI) has developed a comprehensive knowledge graph that links\nmultimodal research data in mathematics. This encompasses traditional research\ndata items like datasets, software, and publications and includes semantically\nadvanced objects such as mathematical formulas and hypotheses. This paper\ndetails the abilities of the MaRDI knowledge graph, which is based on Wikibase,\nleading up to its inaugural public release, codenamed Bravo, available on\nhttps://portal.mardi4nfdi.de.",
        "translated": "数学世界知识是 Wikidata 的基本组成部分。然而，到目前为止，还没有专家策划的知识图表专门集中在当代数学。为了弥补这一差距，数学研究数据计划(MaRDI)开发了一个综合性的知识图表，将数学中的多模态研究数据联系起来。这包括传统的研究数据项，如数据集、软件和出版物，并包括语义高级对象，如数学公式和假设。本文详细介绍了基于维基百科的 MaRDI 知识图谱的功能，最终发布了代号为 Bravo 的首个公开发布版，可在 https://portal.mardi4nfdi.de 上使用。"
    },
    {
        "title": "Retrieving Supporting Evidence for Generative Question Answering",
        "url": "http://arxiv.org/abs/2309.11392v1",
        "pub_date": "2023-09-20",
        "summary": "Current large language models (LLMs) can exhibit near-human levels of\nperformance on many natural language-based tasks, including open-domain\nquestion answering. Unfortunately, at this time, they also convincingly\nhallucinate incorrect answers, so that responses to questions must be verified\nagainst external sources before they can be accepted at face value. In this\npaper, we report two simple experiments to automatically validate generated\nanswers against a corpus. We base our experiments on questions and passages\nfrom the MS MARCO (V1) test collection, and a retrieval pipeline consisting of\nsparse retrieval, dense retrieval and neural rerankers. In the first\nexperiment, we validate the generated answer in its entirety. After presenting\na question to an LLM and receiving a generated answer, we query the corpus with\nthe combination of the question + generated answer. We then present the LLM\nwith the combination of the question + generated answer + retrieved answer,\nprompting it to indicate if the generated answer can be supported by the\nretrieved answer. In the second experiment, we consider the generated answer at\na more granular level, prompting the LLM to extract a list of factual\nstatements from the answer and verifying each statement separately. We query\nthe corpus with each factual statement and then present the LLM with the\nstatement and the corresponding retrieved evidence. The LLM is prompted to\nindicate if the statement can be supported and make necessary edits using the\nretrieved material. With an accuracy of over 80%, we find that an LLM is\ncapable of verifying its generated answer when a corpus of supporting material\nis provided. However, manual assessment of a random sample of questions reveals\nthat incorrect generated answers are missed by this verification process. While\nthis verification process can reduce hallucinations, it can not entirely\neliminate them.",
        "translated": "当前的大型语言模型(LLM)在许多基于自然语言的任务中表现出接近人类水平的性能，包括开放领域的问答。不幸的是，在这个时候，他们也令人信服地幻想不正确的答案，因此对问题的答复必须经过外部来源的核实，才能被表面上接受。在本文中，我们报告了两个简单的实验，以自动验证生成的答案对语料库。我们的实验基于 MS MARCO (V1)测试集中的问题和段落，以及由稀疏检索、密集检索和神经重新排序组成的检索管道。在第一个实验中，我们完整地验证了生成的答案。在向 LLM 提出问题并收到生成的答案之后，我们使用问题 + 生成的答案的组合来查询语料库。然后，我们将问题 + 生成的答案 + 检索到的答案的组合呈现给 LLM，提示它指出检索到的答案是否支持生成的答案。在第二个实验中，我们在更细粒度的层次上考虑生成的答案，提示 LLM 从答案中提取一个事实陈述列表，并分别验证每个陈述。我们使用每个事实语句查询语料库，然后将语句和相应的检索证据呈现给 LLM。提示 LLM 指示是否可以支持该语句，并使用检索到的材料进行必要的编辑。我们发现，当提供一个支持材料的语料库时，LLM 能够验证其生成的答案，准确率超过80% 。然而，手工评估随机抽样的问题表明，错误生成的答案是错过了这个验证过程。虽然这种验证过程可以减少幻觉，但不能完全消除它们。"
    },
    {
        "title": "Long-tail Augmented Graph Contrastive Learning for Recommendation",
        "url": "http://arxiv.org/abs/2309.11177v1",
        "pub_date": "2023-09-20",
        "summary": "Graph Convolutional Networks (GCNs) has demonstrated promising results for\nrecommender systems, as they can effectively leverage high-order relationship.\nHowever, these methods usually encounter data sparsity issue in real-world\nscenarios. To address this issue, GCN-based recommendation methods employ\ncontrastive learning to introduce self-supervised signals. Despite their\neffectiveness, these methods lack consideration of the significant degree\ndisparity between head and tail nodes. This can lead to non-uniform\nrepresentation distribution, which is a crucial factor for the performance of\ncontrastive learning methods. To tackle the above issue, we propose a novel\nLong-tail Augmented Graph Contrastive Learning (LAGCL) method for\nrecommendation. Specifically, we introduce a learnable long-tail augmentation\napproach to enhance tail nodes by supplementing predicted neighbor information,\nand generate contrastive views based on the resulting augmented graph. To make\nthe data augmentation schema learnable, we design an auto drop module to\ngenerate pseudo-tail nodes from head nodes and a knowledge transfer module to\nreconstruct the head nodes from pseudo-tail nodes. Additionally, we employ\ngenerative adversarial networks to ensure that the distribution of the\ngenerated tail/head nodes matches that of the original tail/head nodes.\nExtensive experiments conducted on three benchmark datasets demonstrate the\nsignificant improvement in performance of our model over the state-of-the-arts.\nFurther analyses demonstrate the uniformity of learned representations and the\nsuperiority of LAGCL on long-tail performance. Code is publicly available at\nhttps://github.com/im0qianqian/LAGCL",
        "translated": "图卷积网络(GCNs)在推荐系统中表现出了良好的效果，因为它们可以有效地利用高阶关系。然而，这些方法在实际场景中通常会遇到数据稀疏问题。为了解决这个问题，基于 GCN 的推荐方法采用对比学习的方法引入自监督信号。这些方法虽然有效，但缺乏对头尾节点之间显著程度差异的考虑。这可能导致非均匀表示分布，这是对比学习方法性能的一个关键因素。为了解决上述问题，我们提出了一种新的长尾增强图形对比学习(LAGCL)的推荐方法。具体地说，我们引入了一种可学习的长尾增广方法，通过补充预测邻居信息来增强尾节点，并基于所得到的增广图生成对比视图。为了使数据增强模式易于学习，我们设计了一个自动删除模块来从头节点生成伪尾节点，以及一个知识转移模块来从伪尾节点重构头节点。此外，我们使用生成对抗网络来确保生成的尾部/头部节点的分布与原始的尾部/头部节点的分布相匹配。在三个基准数据集上进行的大量实验表明，我们的模型在性能方面的显著改进超过了最先进的技术。进一步的分析表明学习表征的一致性和 LAGCL 在长尾性能上的优越性。代码可在 https://github.com/im0qianqian/lagcl 公开查阅"
    },
    {
        "title": "Artificial Intelligence-Enabled Intelligent Assistant for Personalized\n  and Adaptive Learning in Higher Education",
        "url": "http://arxiv.org/abs/2309.10892v1",
        "pub_date": "2023-09-19",
        "summary": "This paper presents a novel framework, Artificial Intelligence-Enabled\nIntelligent Assistant (AIIA), for personalized and adaptive learning in higher\neducation. The AIIA system leverages advanced AI and Natural Language\nProcessing (NLP) techniques to create an interactive and engaging learning\nplatform. This platform is engineered to reduce cognitive load on learners by\nproviding easy access to information, facilitating knowledge assessment, and\ndelivering personalized learning support tailored to individual needs and\nlearning styles. The AIIA's capabilities include understanding and responding\nto student inquiries, generating quizzes and flashcards, and offering\npersonalized learning pathways. The research findings have the potential to\nsignificantly impact the design, implementation, and evaluation of AI-enabled\nVirtual Teaching Assistants (VTAs) in higher education, informing the\ndevelopment of innovative educational tools that can enhance student learning\noutcomes, engagement, and satisfaction. The paper presents the methodology,\nsystem architecture, intelligent services, and integration with Learning\nManagement Systems (LMSs) while discussing the challenges, limitations, and\nfuture directions for the development of AI-enabled intelligent assistants in\neducation.",
        "translated": "本文提出了一个新的框架，人工智能启用智能助手(人工智能助手) ，为个性化和在线机机器学习的高等教育。AIIA 系统利用先进的人工智能和自然语言处理(NLP)技术，创建了一个互动和参与式的学习平台。该平台旨在通过提供便捷的信息获取途径，促进知识评估，提供针对个人需求和学习风格的个性化学习支持，从而减轻学习者的认知负担。AIIA 的能力包括理解和回应学生的询问，生成测验和抽认卡，以及提供个性化的学习途径。研究结果有可能显着影响高等教育中人工智能虚拟教学助理(VTA)的设计，实施和评估，为开发创新的教育工具提供信息，这些工具可以提高学生的学习成果，参与度和满意度。本文介绍了人工智能辅助教学的方法、系统结构、智能服务以及与学习管理系统(LMS)的集成，讨论了人工智能辅助教学的挑战、局限性和未来发展方向。"
    },
    {
        "title": "Classifying Organizations for Food System Ontologies using Natural\n  Language Processing",
        "url": "http://arxiv.org/abs/2309.10880v1",
        "pub_date": "2023-09-19",
        "summary": "Our research explores the use of natural language processing (NLP) methods to\nautomatically classify entities for the purpose of knowledge graph population\nand integration with food system ontologies. We have created NLP models that\ncan automatically classify organizations with respect to categories associated\nwith environmental issues as well as Standard Industrial Classification (SIC)\ncodes, which are used by the U.S. government to characterize business\nactivities. As input, the NLP models are provided with text snippets retrieved\nby the Google search engine for each organization, which serves as a textual\ndescription of the organization that is used for learning. Our experimental\nresults show that NLP models can achieve reasonably good performance for these\ntwo classification tasks, and they rely on a general framework that could be\napplied to many other classification problems as well. We believe that NLP\nmodels represent a promising approach for automatically harvesting information\nto populate knowledge graphs and aligning the information with existing\nontologies through shared categories and concepts.",
        "translated": "我们的研究探讨了利用自然语言处理(NLP)方法来自动分类实体的目的是知识图的人口和集成与食品系统本体。我们已经创建了自然语言处理模型，可以根据与环境问题相关的类别自动对组织进行分类，还有标准产业分类(SIC)代码，美国政府使用这些代码来描述商业活动。作为输入，NLP 模型提供了 Google 搜索引擎为每个组织检索的文本片段，这些文本片段作为用于学习的组织的文本描述。实验结果表明，自然语言处理模型能够较好地处理这两种分类任务，并且它们依赖于一个通用的框架，这个框架也可以应用于许多其他的分类问题。我们认为，NLP 模型代表了一个有前途的方法，自动获取信息，填充知识图，并与现有的本体通过共享类别和概念的信息。"
    },
    {
        "title": "DreamLLM: Synergistic Multimodal Comprehension and Creation",
        "url": "http://arxiv.org/abs/2309.11499v1",
        "pub_date": "2023-09-20",
        "summary": "This paper presents DreamLLM, a learning framework that first achieves\nversatile Multimodal Large Language Models (MLLMs) empowered with frequently\noverlooked synergy between multimodal comprehension and creation. DreamLLM\noperates on two fundamental principles. The first focuses on the generative\nmodeling of both language and image posteriors by direct sampling in the raw\nmultimodal space. This approach circumvents the limitations and information\nloss inherent to external feature extractors like CLIP, and a more thorough\nmultimodal understanding is obtained. Second, DreamLLM fosters the generation\nof raw, interleaved documents, modeling both text and image contents, along\nwith unstructured layouts. This allows DreamLLM to learn all conditional,\nmarginal, and joint multimodal distributions effectively. As a result, DreamLLM\nis the first MLLM capable of generating free-form interleaved content.\nComprehensive experiments highlight DreamLLM's superior performance as a\nzero-shot multimodal generalist, reaping from the enhanced learning synergy.",
        "translated": "本文介绍了 DreamLLM，这是一个学习框架，它首先实现了通用的多模态大语言模型(MLLM) ，它赋予了多模态理解和创造之间经常被忽视的协同作用。DreamLLM 基于两个基本原则运作。第一部分着重于在原始多模态空间中通过直接采样建立语言和图像后像的生成模型。该方法克服了 CLIP 等外部特征提取器固有的局限性和信息丢失问题，获得了更为全面的多模态理解。其次，DreamLLM 支持生成原始的、交错的文档，对文本和图像内容以及非结构化布局进行建模。这允许 DreamLLM 有效地学习所有条件分布、边际分布和联合多模态分布。因此，DreamLLM 是第一个能够生成自由格式交错内容的 MLLM。全面的实验突出了 DreamLLM 作为一个零拍摄多模态通才的卓越表现，从增强的学习协同收获。"
    },
    {
        "title": "Chain-of-Verification Reduces Hallucination in Large Language Models",
        "url": "http://arxiv.org/abs/2309.11495v1",
        "pub_date": "2023-09-20",
        "summary": "Generation of plausible yet incorrect factual information, termed\nhallucination, is an unsolved issue in large language models. We study the\nability of language models to deliberate on the responses they give in order to\ncorrect their mistakes. We develop the Chain-of-Verification (CoVe) method\nwhereby the model first (i) drafts an initial response; then (ii) plans\nverification questions to fact-check its draft; (iii) answers those questions\nindependently so the answers are not biased by other responses; and (iv)\ngenerates its final verified response. In experiments, we show CoVe decreases\nhallucinations across a variety of tasks, from list-based questions from\nWikidata, closed book MultiSpanQA and longform text generation.",
        "translated": "在大型语言模型中，生成似是而非但不正确的事实信息(称为幻觉)是一个尚未解决的问题。我们研究了语言模型为了纠正自己的错误而仔细思考自己的反应的能力。我们开发了验证链(CoVe)方法，模型首先(i)起草一个初始响应; 然后(ii)计划验证问题以事实核查其草案; (iii)独立回答这些问题，以便答案不会受到其他响应的偏见; 以及(iv)产生其最终验证响应。在实验中，我们展示了 CoVe 在多种任务中减少幻觉，从 Wikidata 的基于列表的问题，闭卷的 MultiSpanQA 和长形式的文本生成。"
    },
    {
        "title": "Text2Reward: Automated Dense Reward Function Generation for\n  Reinforcement Learning",
        "url": "http://arxiv.org/abs/2309.11489v2",
        "pub_date": "2023-09-20",
        "summary": "Designing reward functions is a longstanding challenge in reinforcement\nlearning (RL); it requires specialized knowledge or domain data, leading to\nhigh costs for development. To address this, we introduce Text2Reward, a\ndata-free framework that automates the generation of dense reward functions\nbased on large language models (LLMs). Given a goal described in natural\nlanguage, Text2Reward generates dense reward functions as an executable program\ngrounded in a compact representation of the environment. Unlike inverse RL and\nrecent work that uses LLMs to write sparse reward codes, Text2Reward produces\ninterpretable, free-form dense reward codes that cover a wide range of tasks,\nutilize existing packages, and allow iterative refinement with human feedback.\nWe evaluate Text2Reward on two robotic manipulation benchmarks (ManiSkill2,\nMetaWorld) and two locomotion environments of MuJoCo. On 13 of the 17\nmanipulation tasks, policies trained with generated reward codes achieve\nsimilar or better task success rates and convergence speed than expert-written\nreward codes. For locomotion tasks, our method learns six novel locomotion\nbehaviors with a success rate exceeding 94%. Furthermore, we show that the\npolicies trained in the simulator with our method can be deployed in the real\nworld. Finally, Text2Reward further improves the policies by refining their\nreward functions with human feedback. Video results are available at\nhttps://text-to-reward.github.io",
        "translated": "设计奖励功能是强化学习领域(RL)的一个长期挑战，它需要专业知识或领域数据，导致开发成本高昂。为了解决这个问题，我们引入了 Text2Reward，这是一个无数据框架，可以自动生成基于大型语言模型(LLM)的密集奖励函数。给定一个用自然语言描述的目标，Text2Reward 作为一个基于环境紧凑表示的可执行程序生成密集的奖励函数。不像逆 RL 和最近的工作，使用 LLM 编写稀疏奖励代码，Text2Reward 产生可解释的，自由形式的密集奖励代码，涵盖广泛的任务，利用现有的包，并允许迭代细化与人类反馈。我们在两个机器人操作基准(ManiSkill2，MetaWorld)和 MuJoCo 的两个运动环境上评估 Text2Reward。在17个操作任务中的13个任务中，使用生成的奖励代码训练的策略与专家编写的奖励代码获得相似或更好的任务成功率和收敛速度。对于运动任务，我们的方法学习六种新的运动行为，成功率超过94% 。此外，我们的方法在模拟器中训练出来的策略可以在现实世界中部署。最后，Text2Reward 通过使用人工反馈来完善其奖励功能，从而进一步改进了策略。视像结果可于 https://text-to-reward.github.io 下载"
    },
    {
        "title": "Controlled Generation with Prompt Insertion for Natural Language\n  Explanations in Grammatical Error Correction",
        "url": "http://arxiv.org/abs/2309.11439v1",
        "pub_date": "2023-09-20",
        "summary": "In Grammatical Error Correction (GEC), it is crucial to ensure the user's\ncomprehension of a reason for correction. Existing studies present tokens,\nexamples, and hints as to the basis for correction but do not directly explain\nthe reasons for corrections. Although methods that use Large Language Models\n(LLMs) to provide direct explanations in natural language have been proposed\nfor various tasks, no such method exists for GEC. Generating explanations for\nGEC corrections involves aligning input and output tokens, identifying\ncorrection points, and presenting corresponding explanations consistently.\nHowever, it is not straightforward to specify a complex format to generate\nexplanations, because explicit control of generation is difficult with prompts.\nThis study introduces a method called controlled generation with Prompt\nInsertion (PI) so that LLMs can explain the reasons for corrections in natural\nlanguage. In PI, LLMs first correct the input text, and then we automatically\nextract the correction points based on the rules. The extracted correction\npoints are sequentially inserted into the LLM's explanation output as prompts,\nguiding the LLMs to generate explanations for the correction points. We also\ncreate an Explainable GEC (XGEC) dataset of correction reasons by annotating\nNUCLE, CoNLL2013, and CoNLL2014. Although generations from GPT-3 and ChatGPT\nusing original prompts miss some correction points, the generation control\nusing PI can explicitly guide to describe explanations for all correction\npoints, contributing to improved performance in generating correction reasons.",
        "translated": "在语法错误纠正(GEC)中，确保用户对纠错原因的理解是至关重要的。现有的研究提供了关于修正基础的标记、例子和提示，但没有直接解释修正的原因。尽管已经有人提出了用大语言模型(LLM)直接解释自然语言的方法来解决各种任务，但是 GEC 还没有这样的方法。生成对 GEC 校正的解释包括对齐输入和输出标记，确定校正点，并一致地提出相应的解释。然而，指定一种复杂的格式来生成解释并不简单，因为提示符很难对生成进行显式控制。本文介绍了一种利用提示插入(PI)进行控制生成的方法，使 LLM 能够解释自然语言中修正的原因。在 PI 中，LLM 首先对输入文本进行校正，然后根据规则自动提取校正点。提取的修正点作为提示依次插入到 LLM 的解释输出中，指导 LLM 为修正点生成解释。我们还通过注释 NUCLE，CoNLL2013和 CoNLL2014创建了可解释的 GEC (XGEC)纠正原因数据集。尽管使用原始提示的 GPT-3和 ChatGPT 的几代错过了一些修正点，但使用 PI 的生成控制可以明确地指导描述所有修正点的解释，有助于提高生成修正原因的性能。"
    },
    {
        "title": "You Only Look at Screens: Multimodal Chain-of-Action Agents",
        "url": "http://arxiv.org/abs/2309.11436v2",
        "pub_date": "2023-09-20",
        "summary": "Autonomous user interface (UI) agents aim to facilitate task automation by\ninteracting with the user interface without manual intervention. Recent studies\nhave investigated eliciting the capabilities of large language models (LLMs)\nfor effective engagement in diverse environments. To align with the\ninput-output requirement of LLMs, existing approaches are developed under a\nsandbox setting where they rely on external tools and application-specific APIs\nto parse the environment into textual elements and interpret the predicted\nactions. Consequently, those approaches often grapple with inference\ninefficiency and error propagation risks. To mitigate the challenges, we\nintroduce Auto-UI, a multimodal solution that directly interacts with the\ninterface, bypassing the need for environment parsing or reliance on\napplication-dependent APIs. Moreover, we propose a chain-of-action technique --\nleveraging a series of intermediate previous action histories and future action\nplans -- to help the agent decide what action to execute. We evaluate our\napproach on a new device-control benchmark AITW with 30K unique instructions,\nspanning multi-step tasks such as application operation, web searching, and web\nshopping. Experimental results show that Auto-UI achieves state-of-the-art\nperformance with an action type prediction accuracy of 90% and an overall\naction success rate of 74%. Code is publicly available at\nhttps://github.com/cooelf/Auto-UI.",
        "translated": "自主用户界面(UI)代理旨在通过与用户界面交互而不需要人工干预来实现任务自动化。最近的研究调查了大型语言模型(LLM)在不同环境中有效参与的能力。为了与 LLM 的输入输出需求保持一致，现有的方法是在沙箱设置下开发的，它们依赖于外部工具和特定于应用程序的 API，将环境解析为文本元素并解释预测的操作。因此，这些方法常常要与推理效率低下和错误传播风险作斗争。为了减轻这些挑战，我们引入了 Auto-UI，这是一个直接与接口交互的多模式解决方案，它绕过了对环境解析的需要或对依赖于应用程序的 API 的依赖。此外，我们提出了一种行动链技术——利用一系列中间的以前的行动历史和未来的行动计划——来帮助代理决定执行什么行动。我们评估我们的方法在一个新的设备控制基准 AITW 与30K 独特的指令，跨越多步骤的任务，如应用程序操作，网络搜索和网络购物。实验结果表明，自动用户界面的动作类型预测准确率达到90% ，整体动作成功率达到74% 。代码可在 https://github.com/cooelf/auto-ui 公开查阅。"
    },
    {
        "title": "Kosmos-2.5: A Multimodal Literate Model",
        "url": "http://arxiv.org/abs/2309.11419v1",
        "pub_date": "2023-09-20",
        "summary": "We present Kosmos-2.5, a multimodal literate model for machine reading of\ntext-intensive images. Pre-trained on large-scale text-intensive images,\nKosmos-2.5 excels in two distinct yet cooperative transcription tasks: (1)\ngenerating spatially-aware text blocks, where each block of text is assigned\nits spatial coordinates within the image, and (2) producing structured text\noutput that captures styles and structures into the markdown format. This\nunified multimodal literate capability is achieved through a shared Transformer\narchitecture, task-specific prompts, and flexible text representations. We\nevaluate Kosmos-2.5 on end-to-end document-level text recognition and\nimage-to-markdown text generation. Furthermore, the model can be readily\nadapted for any text-intensive image understanding task with different prompts\nthrough supervised fine-tuning, making it a general-purpose tool for real-world\napplications involving text-rich images. This work also paves the way for the\nfuture scaling of multimodal large language models.",
        "translated": "我们提出 Kosmos-2.5，一个文本密集型图像机器阅读的多模式文字模型。Kosmos-2.5在大规模文本密集型图像上经过预先训练，擅长两种不同但合作的转录任务: (1)生成空间感知的文本块，其中每个文本块在图像中分配其空间坐标; (2)生成结构化文本输出，捕捉样式和结构到标记格式。这种统一的多模式文字能力是通过共享的 Transformer 体系结构、特定于任务的提示和灵活的文本表示实现的。我们评估 Kosmos-2.5对端到端文档级文本识别和图像到降价文本生成的影响。此外，该模型可以很容易地适应任何文本密集型的图像理解任务与不同的提示，通过监督微调，使其成为一个通用的工具，涉及文本丰富的图像真实世界的应用。这项工作还为将来扩展多模态大语言模型铺平了道路。"
    },
    {
        "title": "Safurai 001: New Qualitative Approach for Code LLM Evaluation",
        "url": "http://arxiv.org/abs/2309.11385v1",
        "pub_date": "2023-09-20",
        "summary": "This paper presents Safurai-001, a new Large Language Model (LLM) with\nsignificant potential in the domain of coding assistance. Driven by recent\nadvancements in coding LLMs, Safurai-001 competes in performance with the\nlatest models like WizardCoder [Xu et al., 2023], PanguCoder [Shen et al.,\n2023] and Phi-1 [Gunasekar et al., 2023] but aims to deliver a more\nconversational interaction. By capitalizing on the progress in data engineering\n(including latest techniques of data transformation and prompt engineering) and\ninstruction tuning, this new model promises to stand toe-to-toe with recent\nclosed and open source developments. Recognizing the need for an efficacious\nevaluation metric for coding LLMs, this paper also introduces GPT4-based\nMultiParameters, an evaluation benchmark that harnesses varied parameters to\npresent a comprehensive insight into the models functioning and performance.\nOur assessment shows that Safurai-001 can outperform GPT-3.5 by 1.58% and\nWizardCoder by 18.78% in the Code Readability parameter and more.",
        "translated": "本文介绍了 Safurai-001，一种新的大型语言模型(LLM) ，它在编码辅助领域具有很大的潜力。在编码 LLM 的最新进展的驱动下，Safurai-001与 WizardCoder [ Xu 等，2023] ，PanguCoder [ Shen 等，2023]和 Phi-1[ Gunasekar 等，2023]等最新型号竞争性能，但旨在提供更多的对话交互。通过利用数据工程(包括数据转换和快速工程的最新技术)和指令调优的进展，这种新模型有望与最近的封闭和开源开发相抗衡。认识到编码 LLM 需要一个有效的评估指标，本文还介绍了基于 GPT4的多参数，一个评估基准，利用不同的参数，提出了一个全面的洞察模型的功能和性能。我们的评估表明，Safurai-001在代码可读性参数方面比 GPT-3.5高出1.58% ，比 WizardCoder 高出18.78% ，甚至更多。"
    },
    {
        "title": "Long-Form End-to-End Speech Translation via Latent Alignment\n  Segmentation",
        "url": "http://arxiv.org/abs/2309.11384v1",
        "pub_date": "2023-09-20",
        "summary": "Current simultaneous speech translation models can process audio only up to a\nfew seconds long. Contemporary datasets provide an oracle segmentation into\nsentences based on human-annotated transcripts and translations. However, the\nsegmentation into sentences is not available in the real world. Current speech\nsegmentation approaches either offer poor segmentation quality or have to trade\nlatency for quality. In this paper, we propose a novel segmentation approach\nfor a low-latency end-to-end speech translation. We leverage the existing\nspeech translation encoder-decoder architecture with ST CTC and show that it\ncan perform the segmentation task without supervision or additional parameters.\nTo the best of our knowledge, our method is the first that allows an actual\nend-to-end simultaneous speech translation, as the same model is used for\ntranslation and segmentation at the same time. On a diverse set of language\npairs and in- and out-of-domain data, we show that the proposed approach\nachieves state-of-the-art quality at no additional computational cost.",
        "translated": "目前的同步语音翻译模型只能处理几秒钟的音频。当代数据集提供了基于人工注释的文本和翻译的句子的甲骨文分割。然而，在现实世界中，对句子的分割是不可行的。目前的语音分割方法要么提供较差的分割质量，要么不得不用延迟来换取质量。本文提出了一种新的低延迟端到端语音翻译的分割方法。我们利用现有的基于 ST CTC 的语音翻译编译码器结构，表明它可以在不需要监督和额外参数的情况下完成分割任务。据我们所知，我们的方法是第一个允许实际的端到端同步语音翻译，因为同一模型用于翻译和分割在同一时间。在不同的语言对和领域内外的数据集上，我们表明所提出的方法在不增加计算成本的情况下达到了最先进的质量。"
    },
    {
        "title": "Discuss Before Moving: Visual Language Navigation via Multi-expert\n  Discussions",
        "url": "http://arxiv.org/abs/2309.11382v1",
        "pub_date": "2023-09-20",
        "summary": "Visual language navigation (VLN) is an embodied task demanding a wide range\nof skills encompassing understanding, perception, and planning. For such a\nmultifaceted challenge, previous VLN methods totally rely on one model's own\nthinking to make predictions within one round. However, existing models, even\nthe most advanced large language model GPT4, still struggle with dealing with\nmultiple tasks by single-round self-thinking. In this work, drawing inspiration\nfrom the expert consultation meeting, we introduce a novel zero-shot VLN\nframework. Within this framework, large models possessing distinct abilities\nare served as domain experts. Our proposed navigation agent, namely DiscussNav,\ncan actively discuss with these experts to collect essential information before\nmoving at every step. These discussions cover critical navigation subtasks like\ninstruction understanding, environment perception, and completion estimation.\nThrough comprehensive experiments, we demonstrate that discussions with domain\nexperts can effectively facilitate navigation by perceiving\ninstruction-relevant information, correcting inadvertent errors, and sifting\nthrough in-consistent movement decisions. The performances on the\nrepresentative VLN task R2R show that our method surpasses the leading\nzero-shot VLN model by a large margin on all metrics. Additionally, real-robot\nexperiments display the obvious advantages of our method over single-round\nself-thinking.",
        "translated": "视觉语言导航(VLN)是一项具体的任务，需要广泛的技能，包括理解，感知和计划。对于这样一个多方面的挑战，以前的 VLN 方法完全依赖于一个模型自己的想法，在一个回合内作出预测。然而，现有的模型，即使是最先进的大型语言模型 GPT4，仍然难以通过单轮自我思考处理多个任务。在这项工作中，借鉴专家咨询会议的灵感，我们介绍了一种新颖的零拍 VLN 框架。在这个框架中，具有独特能力的大型模型被用作领域专家。我们提出的导航代理，即讨论导航，可以积极地与这些专家讨论，以收集基本信息，然后再移动每一步。这些讨论包括关键的导航子任务，如指令理解、环境感知和完成评估。通过全面的实验，我们证明了与领域专家的讨论可以通过感知指令相关的信息、纠正无意的错误和筛选不一致的运动决策来有效地促进导航。在具有代表性的 VLN 任务 R2R 上的性能表明，该方法在所有指标上都大大超过了领先的零炮 VLN 模型。此外，真实机器人实验显示了我们的方法明显优于单轮自我思考。"
    },
    {
        "title": "Studying Lobby Influence in the European Parliament",
        "url": "http://arxiv.org/abs/2309.11381v1",
        "pub_date": "2023-09-20",
        "summary": "We present a method based on natural language processing (NLP), for studying\nthe influence of interest groups (lobbies) in the law-making process in the\nEuropean Parliament (EP). We collect and analyze novel datasets of lobbies'\nposition papers and speeches made by members of the EP (MEPs). By comparing\nthese texts on the basis of semantic similarity and entailment, we are able to\ndiscover interpretable links between MEPs and lobbies. In the absence of a\nground-truth dataset of such links, we perform an indirect validation by\ncomparing the discovered links with a dataset, which we curate, of retweet\nlinks between MEPs and lobbies, and with the publicly disclosed meetings of\nMEPs. Our best method achieves an AUC score of 0.77 and performs significantly\nbetter than several baselines. Moreover, an aggregate analysis of the\ndiscovered links, between groups of related lobbies and political groups of\nMEPs, correspond to the expectations from the ideology of the groups (e.g.,\ncenter-left groups are associated with social causes). We believe that this\nwork, which encompasses the methodology, datasets, and results, is a step\ntowards enhancing the transparency of the intricate decision-making processes\nwithin democratic institutions.",
        "translated": "本文提出了一种基于自然语言处理(NLP)的方法，用于研究利益集团(游说团体)在欧洲议会立法过程中的影响。我们收集和分析游说团体的立场文件和欧洲议会议员的发言的新数据集。通过比较这些文本的基础上的语义相似性和蕴涵，我们能够发现可解释的链接之间的欧洲议会议员和游说。在没有这种链接的地面真相数据集的情况下，我们通过将发现的链接与我们管理的欧洲议会议员和游说团体之间的转发链接的数据集以及与公开披露的欧洲议会议员会议进行比较来进行间接验证。我们最好的方法达到了0.77的 AUC 评分，并且比几个基线表现得更好。此外，对相关游说团体和欧洲议会议员政治团体之间已发现的联系进行的总体分析，符合这些团体意识形态的预期(例如，中左翼团体与社会原因有关)。我们相信，这项工作，其中包括方法，数据集和结果，是一个步骤，以提高民主机构内复杂的决策过程的透明度。"
    },
    {
        "title": "Improving VTE Identification through Adaptive NLP Model Selection and\n  Clinical Expert Rule-based Classifier from Radiology Reports",
        "url": "http://arxiv.org/abs/2309.12273v1",
        "pub_date": "2023-09-21",
        "summary": "Rapid and accurate identification of Venous thromboembolism (VTE), a severe\ncardiovascular condition including deep vein thrombosis (DVT) and pulmonary\nembolism (PE), is important for effective treatment. Leveraging Natural\nLanguage Processing (NLP) on radiology reports, automated methods have shown\npromising advancements in identifying VTE events from retrospective data\ncohorts or aiding clinical experts in identifying VTE events from radiology\nreports. However, effectively training Deep Learning (DL) and the NLP models is\nchallenging due to limited labeled medical text data, the complexity and\nheterogeneity of radiology reports, and data imbalance. This study proposes\nnovel method combinations of DL methods, along with data augmentation, adaptive\npre-trained NLP model selection, and a clinical expert NLP rule-based\nclassifier, to improve the accuracy of VTE identification in unstructured\n(free-text) radiology reports. Our experimental results demonstrate the model's\nefficacy, achieving an impressive 97\\% accuracy and 97\\% F1 score in predicting\nDVT, and an outstanding 98.3\\% accuracy and 98.4\\% F1 score in predicting PE.\nThese findings emphasize the model's robustness and its potential to\nsignificantly contribute to VTE research.",
        "translated": "静脉血栓栓塞症(vTE)是一种严重的心血管疾病，包括深静脉血栓(DVT)和肺栓塞(PE) ，快速而准确地鉴别 VTE 对于有效的治疗非常重要。利用放射学报告的自然语言处理(NLP) ，自动化方法在从回顾性数据队列中识别 VTE 事件或帮助临床专家从放射学报告中识别 VTE 事件方面显示出有希望的进展。然而，有效地训练深度学习(DL)和自然语言处理(NLP)模型是具有挑战性的，因为有限的标记的医学文本数据，复杂性和异质性的放射学报告，以及数据不平衡。本研究提出了 DL 方法的新方法组合，以及数据增强，自适应预训练 NLP 模型选择和基于 NLP 规则的临床专家分类器，以提高非结构化(自由文本)放射学报告中 VTE 识别的准确性。我们的实验结果证明了该模型的有效性，在预测 DVT 方面达到了令人印象深刻的97% 的准确率和97% 的 F1评分，在预测 PE 方面达到了令人印象深刻的98.3% 的准确率和98.4% 的 F1评分。这些发现强调了该模型的稳健性及其对职业教育研究的显著贡献的潜力。"
    },
    {
        "title": "Towards Robust and Truly Large-Scale Audio-Sheet Music Retrieval",
        "url": "http://arxiv.org/abs/2309.12158v1",
        "pub_date": "2023-09-21",
        "summary": "A range of applications of multi-modal music information retrieval is centred\naround the problem of connecting large collections of sheet music (images) to\ncorresponding audio recordings, that is, identifying pairs of audio and score\nexcerpts that refer to the same musical content. One of the typical and most\nrecent approaches to this task employs cross-modal deep learning architectures\nto learn joint embedding spaces that link the two distinct modalities - audio\nand sheet music images. While there has been steady improvement on this front\nover the past years, a number of open problems still prevent large-scale\nemployment of this methodology. In this article we attempt to provide an\ninsightful examination of the current developments on audio-sheet music\nretrieval via deep learning methods. We first identify a set of main challenges\non the road towards robust and large-scale cross-modal music retrieval in real\nscenarios. We then highlight the steps we have taken so far to address some of\nthese challenges, documenting step-by-step improvement along several\ndimensions. We conclude by analysing the remaining challenges and present ideas\nfor solving these, in order to pave the way to a unified and robust methodology\nfor cross-modal music retrieval.",
        "translated": "多模态音乐信息检索的一系列应用集中于将大量乐谱(图像)与相应的录音相连接的问题，即识别指向相同音乐内容的成对音频和乐谱摘录。其中一个典型的和最新的方法，这项任务使用跨模态深度学习架构来学习联合嵌入空间，连接两个不同的模式-音频和乐谱图像。虽然过去几年这方面的情况稳步改善，但仍有一些公开的问题妨碍大规模采用这一方法。本文试图通过深度学习的方法对音频片段音乐检索的研究现状进行深入的考察。我们首先确定了在实际场景中实现健壮的大规模跨模态音乐检索的一系列主要挑战。然后，我们强调迄今为止我们为应对其中一些挑战而采取的步骤，记录了几个方面的逐步改进。最后，我们分析了剩余的挑战，并提出了解决这些问题的想法，以便为跨模态音乐检索铺平道路。"
    },
    {
        "title": "Self-Supervised Contrastive Learning for Robust Audio-Sheet Music\n  Retrieval Systems",
        "url": "http://arxiv.org/abs/2309.12134v1",
        "pub_date": "2023-09-21",
        "summary": "Linking sheet music images to audio recordings remains a key problem for the\ndevelopment of efficient cross-modal music retrieval systems. One of the\nfundamental approaches toward this task is to learn a cross-modal embedding\nspace via deep neural networks that is able to connect short snippets of audio\nand sheet music. However, the scarcity of annotated data from real musical\ncontent affects the capability of such methods to generalize to real retrieval\nscenarios. In this work, we investigate whether we can mitigate this limitation\nwith self-supervised contrastive learning, by exposing a network to a large\namount of real music data as a pre-training step, by contrasting randomly\naugmented views of snippets of both modalities, namely audio and sheet images.\nThrough a number of experiments on synthetic and real piano data, we show that\npre-trained models are able to retrieve snippets with better precision in all\nscenarios and pre-training configurations. Encouraged by these results, we\nemploy the snippet embeddings in the higher-level task of cross-modal piece\nidentification and conduct more experiments on several retrieval\nconfigurations. In this task, we observe that the retrieval quality improves\nfrom 30% up to 100% when real music data is present. We then conclude by\narguing for the potential of self-supervised contrastive learning for\nalleviating the annotated data scarcity in multi-modal music retrieval models.",
        "translated": "将乐谱图像与音频记录联系起来仍然是开发高效的跨模态音乐检索系统的关键问题。实现这一任务的一个基本方法是通过深度神经网络学习跨模式嵌入空间，该网络能够连接音频和乐谱的短片段。然而，来自真实音乐内容的注释数据的稀缺性影响了这种方法推广到真实检索场景的能力。在这项工作中，我们调查是否可以通过自我监督对比学习来减轻这种局限性，通过将网络暴露于大量的真实音乐数据作为训练前的一个步骤，通过对比两种模式的片段(即音频和表格图像)的随机增强视图。通过对合成和真实钢琴数据的大量实验，我们表明，预训练模型能够在所有场景和预训练配置中以更高的精度检索片段。在这些结果的鼓舞下，我们将片段嵌入应用于更高层次的跨模态片段识别任务，并在几种检索配置上进行了更多的实验。在这个任务中，我们观察到，当真实音乐数据存在时，检索质量从30% 提高到100% 。最后，我们讨论了自我监督对比学习在缓解多模态音乐检索模型中注释数据稀缺性方面的潜力。"
    },
    {
        "title": "Passage Summarization with Recurrent Models for Audio-Sheet Music\n  Retrieval",
        "url": "http://arxiv.org/abs/2309.12111v1",
        "pub_date": "2023-09-21",
        "summary": "Many applications of cross-modal music retrieval are related to connecting\nsheet music images to audio recordings. A typical and recent approach to this\nis to learn, via deep neural networks, a joint embedding space that correlates\nshort fixed-size snippets of audio and sheet music by means of an appropriate\nsimilarity structure. However, two challenges that arise out of this strategy\nare the requirement of strongly aligned data to train the networks, and the\ninherent discrepancies of musical content between audio and sheet music\nsnippets caused by local and global tempo differences. In this paper, we\naddress these two shortcomings by designing a cross-modal recurrent network\nthat learns joint embeddings that can summarize longer passages of\ncorresponding audio and sheet music. The benefits of our method are that it\nonly requires weakly aligned audio-sheet music pairs, as well as that the\nrecurrent network handles the non-linearities caused by tempo variations\nbetween audio and sheet music. We conduct a number of experiments on synthetic\nand real piano data and scores, showing that our proposed recurrent method\nleads to more accurate retrieval in all possible configurations.",
        "translated": "跨模态音乐检索的许多应用都与将乐谱图像与音频记录相连接有关。一个典型的和最近的方法是通过深度神经网络学习一个联合嵌入空间，通过一个适当的相似结构将固定大小的音频片段和乐谱片段相关联。然而，这种策略带来的两个挑战是，训练网络需要强烈对齐的数据，以及音频和乐谱片段之间由于本地和全球节奏差异造成的内在音乐内容差异。在本文中，我们通过设计一个跨模式的循环网络来解决这两个缺点，该网络学习联合嵌入，可以总结相应的音频和乐谱的较长段落。我们的方法的好处是，它只需要弱对齐的音频片段音乐对，以及周期性网络处理由音频和片段音乐之间的节奏变化引起的非线性。我们对合成的和真实的钢琴数据和乐谱进行了大量的实验，结果表明我们提出的递归方法在所有可能的配置中导致了更准确的检索。"
    },
    {
        "title": "Unveiling Optimal SDG Pathways: An Innovative Approach Leveraging Graph\n  Pruning and Intent Graph for Effective Recommendations",
        "url": "http://arxiv.org/abs/2309.11741v1",
        "pub_date": "2023-09-21",
        "summary": "The recommendation of appropriate development pathways, also known as\necological civilization patterns for achieving Sustainable Development Goals\n(namely, sustainable development patterns), are of utmost importance for\npromoting ecological, economic, social, and resource sustainability in a\nspecific region. To achieve this, the recommendation process must carefully\nconsider the region's natural, environmental, resource, and economic\ncharacteristics. However, current recommendation algorithms in the field of\ncomputer science fall short in adequately addressing the spatial heterogeneity\nrelated to environment and sparsity of regional historical interaction data,\nwhich limits their effectiveness in recommending sustainable development\npatterns. To overcome these challenges, this paper proposes a method called\nUser Graph after Pruning and Intent Graph (UGPIG). Firstly, we utilize the\nhigh-density linking capability of the pruned User Graph to address the issue\nof spatial heterogeneity neglect in recommendation algorithms. Secondly, we\nconstruct an Intent Graph by incorporating the intent network, which captures\nthe preferences for attributes including environmental elements of target\nregions. This approach effectively alleviates the problem of sparse historical\ninteraction data in the region. Through extensive experiments, we demonstrate\nthat UGPIG outperforms state-of-the-art recommendation algorithms like KGCN,\nKGAT, and KGIN in sustainable development pattern recommendations, with a\nmaximum improvement of 9.61% in Top-3 recommendation performance.",
        "translated": "为实现可持续发展目标(即可持续发展模式)建议适当的发展道路，也称为生态文明模式，对于促进特定区域的生态、经济、社会和资源可持续性至关重要。要做到这一点，推荐过程必须仔细考虑该地区的自然、环境、资源和经济特点。然而，目前计算机科学领域的推荐算法不能充分解决与环境有关的空间异质性和区域历史相互作用数据的稀缺性，这限制了它们推荐可持续发展模式的有效性。为了克服这些挑战，本文提出了一种修剪后的用户图(UserGraph)方法。首先，我们利用剪枝用户图的高密度连接能力来解决推荐算法中空间异构性被忽略的问题。其次，结合意向网络构建意向图，获取包括目标区域环境要素在内的属性偏好。该方法有效地解决了区域内历史交互数据稀疏的问题。通过广泛的实验，我们证明 UGPIG 在可持续发展模式推荐中优于 KGCN，KGAT 和 KGIN 等最先进的推荐算法，在 Top-3推荐性能中最大提高了9.61% 。"
    },
    {
        "title": "LLM-Grounder: Open-Vocabulary 3D Visual Grounding with Large Language\n  Model as an Agent",
        "url": "http://arxiv.org/abs/2309.12311v1",
        "pub_date": "2023-09-21",
        "summary": "3D visual grounding is a critical skill for household robots, enabling them\nto navigate, manipulate objects, and answer questions based on their\nenvironment. While existing approaches often rely on extensive labeled data or\nexhibit limitations in handling complex language queries, we propose\nLLM-Grounder, a novel zero-shot, open-vocabulary, Large Language Model\n(LLM)-based 3D visual grounding pipeline. LLM-Grounder utilizes an LLM to\ndecompose complex natural language queries into semantic constituents and\nemploys a visual grounding tool, such as OpenScene or LERF, to identify objects\nin a 3D scene. The LLM then evaluates the spatial and commonsense relations\namong the proposed objects to make a final grounding decision. Our method does\nnot require any labeled training data and can generalize to novel 3D scenes and\narbitrary text queries. We evaluate LLM-Grounder on the ScanRefer benchmark and\ndemonstrate state-of-the-art zero-shot grounding accuracy. Our findings\nindicate that LLMs significantly improve the grounding capability, especially\nfor complex language queries, making LLM-Grounder an effective approach for 3D\nvision-language tasks in robotics. Videos and interactive demos can be found on\nthe project website https://chat-with-nerf.github.io/ .",
        "translated": "3D 视觉接地是家用机器人的关键技能，使他们能够导航，操纵物体，并根据环境回答问题。虽然现有的方法往往依赖于大量的标记数据或表现出处理复杂的语言查询的局限性，我们提出了 LLM-Grounder，一种新颖的零拍摄，开放词汇表，大语言模型(LLM)为基础的三维可视化接地管道。LLM-Grounder 利用 LLM 将复杂的自然语言查询分解为语义成分，并使用 OpenScene 或 LERF 等可视化基础工具来识别3D 场景中的对象。然后，LLM 评估被提议对象之间的空间关系和常识关系，从而做出最终的接地决策。该方法不需要任何标记的训练数据，可以推广到新的三维场景和任意文本查询。我们评估 LLM 的扫描参考基准地面和展示国家的最先进的零射击接地精度。我们的研究结果表明，LLM 显著提高了接地能力，特别是对于复杂的语言查询，使 LLM-Grounder 成为机器人三维视觉语言任务的一种有效方法。视频和互动演示可在项目网站 https://chat-with-nerf.github.io/找到。"
    },
    {
        "title": "Rehearsal: Simulating Conflict to Teach Conflict Resolution",
        "url": "http://arxiv.org/abs/2309.12309v1",
        "pub_date": "2023-09-21",
        "summary": "Interpersonal conflict is an uncomfortable but unavoidable fact of life.\nNavigating conflict successfully is a skill -- one that can be learned through\ndeliberate practice -- but few have access to effective training or feedback.\nTo expand this access, we introduce Rehearsal, a system that allows users to\nrehearse conflicts with a believable simulated interlocutor, explore\ncounterfactual \"what if?\" scenarios to identify alternative conversational\npaths, and learn through feedback on how and when to apply specific conflict\nstrategies. Users can utilize Rehearsal to practice handling a variety of\npredefined conflict scenarios, from office disputes to relationship issues, or\nthey can choose to create their own. To enable Rehearsal, we develop IRP\nprompting, a method of conditioning output of a large language model on the\ninfluential Interest-Rights-Power (IRP) theory from conflict resolution.\nRehearsal uses IRP to generate utterances grounded in conflict resolution\ntheory, guiding users towards counterfactual conflict resolution strategies\nthat help de-escalate difficult conversations. In a between-subjects\nevaluation, 40 participants engaged in an actual conflict with a confederate\nafter training. Compared to a control group with lecture material covering the\nsame IRP theory, participants with simulated training from Rehearsal\nsignificantly improved their performance in the unaided conflict: they reduced\ntheir use of escalating competitive strategies by an average of 67%, while\ndoubling their use of cooperative strategies. Overall, Rehearsal highlights the\npotential effectiveness of language models as tools for learning and practicing\ninterpersonal skills.",
        "translated": "人际冲突是生活中一个令人不舒服但又不可避免的事实。成功地驾驭冲突是一种技能——一种可以通过深思熟虑的练习来学习的技能——但很少有人能够获得有效的培训或反馈。为了扩大这种访问，我们引入了“预演”系统，该系统允许用户与可信的模拟对话者预演冲突，探索反事实的“如果发生了会怎样?”通过反馈学习如何以及何时应用特定的冲突策略。用户可以利用彩排来练习处理各种预定义的冲突场景，从办公室争端到关系问题，或者他们可以选择创建自己的冲突场景。为了实现彩排，我们开发了 IRP 激励，这是一种基于利益-权利-权力(IRP)理论从冲突解决的角度来调节大语言模型输出的方法。彩排使用 IRP 产生基于冲突解决理论的话语，引导用户采用反事实的冲突解决策略，帮助缓解困难的对话。在一项研究对象间的评估中，40名参与者在训练后与一名同盟者发生了实际冲突。与采用相同 IRP 理论的课程材料的对照组相比，采用预演模拟训练的参与者在无助冲突中的表现明显提高: 他们平均减少了67% 使用逐步升级的竞争策略，同时将合作策略的使用增加了一倍。总的来说，《预演》强调了语言模型作为学习和实践人际交往技能的工具的潜在有效性。"
    },
    {
        "title": "LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models",
        "url": "http://arxiv.org/abs/2309.12307v1",
        "pub_date": "2023-09-21",
        "summary": "We present LongLoRA, an efficient fine-tuning approach that extends the\ncontext sizes of pre-trained large language models (LLMs), with limited\ncomputation cost. Typically, training LLMs with long context sizes is\ncomputationally expensive, requiring extensive training hours and GPU\nresources. For example, training on the context length of 8192 needs 16x\ncomputational costs in self-attention layers as that of 2048. In this paper, we\nspeed up the context extension of LLMs in two aspects. On the one hand,\nalthough dense global attention is needed during inference, fine-tuning the\nmodel can be effectively and efficiently done by sparse local attention. The\nproposed shift short attention effectively enables context extension, leading\nto non-trivial computation saving with similar performance to fine-tuning with\nvanilla attention. Particularly, it can be implemented with only two lines of\ncode in training, while being optional in inference. On the other hand, we\nrevisit the parameter-efficient fine-tuning regime for context expansion.\nNotably, we find that LoRA for context extension works well under the premise\nof trainable embedding and normalization. LongLoRA demonstrates strong\nempirical results on various tasks on LLaMA2 models from 7B/13B to 70B.\nLongLoRA adopts LLaMA2 7B from 4k context to 100k, or LLaMA2 70B to 32k on a\nsingle 8x A100 machine. LongLoRA extends models' context while retaining their\noriginal architectures, and is compatible with most existing techniques, like\nFlashAttention-2. In addition, to make LongLoRA practical, we collect a\ndataset, LongQA, for supervised fine-tuning. It contains more than 3k long\ncontext question-answer pairs.",
        "translated": "我们提出了 LongLoRA，一种有效的微调方法，扩展了预先训练的大型语言模型(LLM)的上下文大小，计算成本有限。通常，训练具有较长上下文大小的 LLM 在计算上是昂贵的，需要大量的训练时间和 GPU 资源。例如，8192的上下文长度训练需要16倍于2048的自我注意层次的计算成本。本文从两个方面加速了 LLM 的上下文扩展。一方面，虽然在推理过程中需要密集的全局注意力，但是通过稀疏的局部注意力可以有效地对模型进行微调。提出的转移短注意力有效地支持上下文扩展，从而节省了大量计算，其性能与普通注意力的微调类似。特别是，它可以在训练中仅用两行代码实现，而在推理中是可选的。另一方面，我们重新考虑了上下文扩展的参数有效微调机制。值得注意的是，我们发现上下文扩展的 LoRA 在可训练嵌入和规范化的前提下运行良好。在7B/13B 到70B 的 LLaMA2模型上，LongLoRA 对各种任务的实证结果都很强。LongLoRA 在单台8xA100机器上采用从4k 到100k 的 LLaMA27B，或者从 LLaMA270B 到32k。LongLoRA 扩展了模型的上下文，同时保留了它们的原始架构，并且与大多数现有技术兼容，比如闪光注意 -2。此外，为了使 LongLoRA 切实可行，我们收集了一个数据集 LongQA，用于监督微调。它包含超过3k 长的上下文问答对。"
    },
    {
        "title": "Reranking for Natural Language Generation from Logical Forms: A Study\n  based on Large Language Models",
        "url": "http://arxiv.org/abs/2309.12294v1",
        "pub_date": "2023-09-21",
        "summary": "Large language models (LLMs) have demonstrated impressive capabilities in\nnatural language generation. However, their output quality can be inconsistent,\nposing challenges for generating natural language from logical forms (LFs).\nThis task requires the generated outputs to embody the exact semantics of LFs,\nwithout missing any LF semantics or creating any hallucinations. In this work,\nwe tackle this issue by proposing a novel generate-and-rerank approach. Our\napproach involves initially generating a set of candidate outputs by prompting\nan LLM and subsequently reranking them using a task-specific reranker model. In\naddition, we curate a manually collected dataset to evaluate the alignment\nbetween different ranking metrics and human judgements. The chosen ranking\nmetrics are utilized to enhance the training and evaluation of the reranker\nmodel. By conducting extensive experiments on three diverse datasets, we\ndemonstrate that the candidates selected by our reranker outperform those\nselected by baseline methods in terms of semantic consistency and fluency, as\nmeasured by three comprehensive metrics. Our findings provide strong evidence\nfor the effectiveness of our approach in improving the quality of generated\noutputs.",
        "translated": "大型语言模型(LLM)在自然语言生成方面展示了令人印象深刻的能力。然而，它们的输出质量可能是不一致的，这对从逻辑形式(LF)生成自然语言提出了挑战。这个任务需要生成的输出体现 LF 的确切语义，而不丢失任何 LF 语义或创建任何幻觉。在这项工作中，我们通过提出一种新颖的生成和重新排序方法来解决这个问题。我们的方法首先通过提示 LLM 生成一组候选输出，然后使用特定于任务的重新排序模型对它们进行重新排序。此外，我们策划了一个手动收集的数据集，以评估不同排名指标和人类判断之间的一致性。所选择的排名指标被用来加强训练和评价的重新排名模型。通过在三个不同的数据集上进行广泛的实验，我们证明了我们的重新排序选择的候选人在语义一致性和流畅性方面优于基线方法选择的候选人，通过三个综合指标来衡量。我们的研究结果为我们的方法在提高产出质量方面的有效性提供了强有力的证据。"
    },
    {
        "title": "The Reversal Curse: LLMs trained on \"A is B\" fail to learn \"B is A\"",
        "url": "http://arxiv.org/abs/2309.12288v1",
        "pub_date": "2023-09-21",
        "summary": "We expose a surprising failure of generalization in auto-regressive large\nlanguage models (LLMs). If a model is trained on a sentence of the form \"A is\nB\", it will not automatically generalize to the reverse direction \"B is A\".\nThis is the Reversal Curse. For instance, if a model is trained on \"Olaf Scholz\nwas the ninth Chancellor of Germany\", it will not automatically be able to\nanswer the question, \"Who was the ninth Chancellor of Germany?\". Moreover, the\nlikelihood of the correct answer (\"Olaf Scholz\") will not be higher than for a\nrandom name. Thus, models exhibit a basic failure of logical deduction and do\nnot generalize a prevalent pattern in their training set (i.e. if \"A is B''\noccurs, \"B is A\" is more likely to occur). We provide evidence for the Reversal\nCurse by finetuning GPT-3 and Llama-1 on fictitious statements such as \"Uriah\nHawthorne is the composer of 'Abyssal Melodies'\" and showing that they fail to\ncorrectly answer \"Who composed 'Abyssal Melodies?'\". The Reversal Curse is\nrobust across model sizes and model families and is not alleviated by data\naugmentation. We also evaluate ChatGPT (GPT-3.5 and GPT-4) on questions about\nreal-world celebrities, such as \"Who is Tom Cruise's mother? [A: Mary Lee\nPfeiffer]\" and the reverse \"Who is Mary Lee Pfeiffer's son?\". GPT-4 correctly\nanswers questions like the former 79% of the time, compared to 33% for the\nlatter. This shows a failure of logical deduction that we hypothesize is caused\nby the Reversal Curse. Code is available at\nhttps://github.com/lukasberglund/reversal_curse.",
        "translated": "我们揭示了在自回归大语言模型(LLM)中泛化的一个令人惊讶的失败。如果一个模型被训练在“ A 是 B”的句子上，它不会自动推广到相反的方向“ B 是 A”。这是逆转诅咒。例如，如果一个模特接受了“奥拉夫•肖尔茨是第九个德国总理”的训练，它不会自动回答“谁是第九个德国总理?”.此外，正确答案(“ Olaf Scholz”)的可能性不会高于随机名称。因此，模型表现出逻辑推理的基本失败，并且没有在它们的训练集中推广一个流行的模式(例如，如果“ A 是 B”发生，“ B 是 A”更有可能发生)。我们通过微调 GPT-3和 Llama-1的虚构陈述，如“尤赖亚 · 霍桑是‘深渊旋律’的作曲家”，并显示他们未能正确回答“谁创作了‘深渊旋律’?”.逆转诅咒是健壮的模型大小和模型族，并没有减轻数据增加。我们也评估 ChatGPT (GPT-3.5和 GPT-4)对于真实世界名人的问题，比如“谁是汤姆 · 克鲁斯的母亲?”？[ A: Mary Lee Pfeiffer ]”和相反的“谁是 Mary Lee Pfeiffer 的儿子?”.GPT-4正确回答前者的概率为79% ，而后者为33% 。这表明逻辑推理的失败，我们假设是由逆转诅咒造成的。密码可于 https://github.com/lukasberglund/reversal_curse 索取。"
    },
    {
        "title": "MetaMath: Bootstrap Your Own Mathematical Questions for Large Language\n  Models",
        "url": "http://arxiv.org/abs/2309.12284v1",
        "pub_date": "2023-09-21",
        "summary": "Large language models (LLMs) have pushed the limits of natural language\nunderstanding and exhibited excellent problem-solving ability. Despite the\ngreat success, most existing open-source LLMs (\\eg, LLaMA-2) are still far away\nfrom satisfactory for solving mathematical problem due to the complex reasoning\nprocedures. To bridge this gap, we propose \\emph{MetaMath}, a fine-tuned\nlanguage model that specializes in mathematical reasoning. Specifically, we\nstart by bootstrapping mathematical questions by rewriting the question from\nmultiple perspectives without extra knowledge, which results in a new dataset\ncalled {MetaMathQA}. Then we fine-tune the LLaMA-2 models on MetaMathQA.\nExperimental results on two popular benchmarks (\\ie, GSM8K and MATH) for\nmathematical reasoning demonstrate that MetaMath outperforms a suite of\nopen-source LLMs by a significant margin. Our MetaMath-7B model achieves\n$66.4\\%$ on GSM8K and $19.4\\%$ on MATH, exceeding the state-of-the-art models\nof the same size by $11.5\\%$ and $8.7\\%$. Particularly, {MetaMath-70B} achieves\nan accuracy of $82.3\\%$ on {GSM8K}, slightly better than {GPT-3.5-Turbo}. We\nrelease the {MetaMathQA} dataset, the {MetaMath} models with different model\nsizes and the training code for public use.",
        "translated": "大型语言模型(LLM)已经突破了自然语言理解的极限，展现出优秀的问题解决能力。尽管已经取得了巨大的成功，但是由于复杂的推理过程，大多数现有的开源 LLM (如 LLaMA-2)在解决数学问题方面仍然远远不能令人满意。为了弥合这一差距，我们提出了 emph { MetaMath } ，这是一个专门用于数学推理的微调语言模型。具体来说，我们通过从多个角度重写数学问题来引导数学问题，而不需要额外的知识，这会产生一个名为{ MetaMathQA }的新数据集。然后在 MetaMathQA 上对 LLaMA-2模型进行微调。在两个流行的数学推理基准(即 GSM8K 和 MATH)上的实验结果表明，MetaMath 的性能明显优于一组开源 LLM。我们的 MetaMath-7B 模型在 GSM8K 上达到66.4% ，在 MATH 上达到19.4% ，超过同等规模的最先进模型11.5% 和8.7% 。特别地，{ MetaMath-70B }在{ GSM8K }上达到82.3% 的准确率，略好于{ GPT-3.5-Turbo }。我们发布{ MetaMathQA }数据集、具有不同模型大小的{ MetaMath}模型以及供公众使用的培训代码。"
    },
    {
        "title": "Inspire the Large Language Model by External Knowledge on BioMedical\n  Named Entity Recognition",
        "url": "http://arxiv.org/abs/2309.12278v1",
        "pub_date": "2023-09-21",
        "summary": "Large language models (LLMs) have demonstrated dominating performance in many\nNLP tasks, especially on generative tasks. However, they often fall short in\nsome information extraction tasks, particularly those requiring domain-specific\nknowledge, such as Biomedical Named Entity Recognition (NER). In this paper,\ninspired by Chain-of-thought, we leverage the LLM to solve the Biomedical NER\nstep-by-step: break down the NER task into entity span extraction and entity\ntype determination. Additionally, for entity type determination, we inject\nentity knowledge to address the problem that LLM's lack of domain knowledge\nwhen predicting entity category. Experimental results show a significant\nimprovement in our two-step BioNER approach compared to previous few-shot LLM\nbaseline. Additionally, the incorporation of external knowledge significantly\nenhances entity category determination performance.",
        "translated": "大语言模型(LLM)在许多 NLP 任务中表现出了主导性能，特别是在生成任务中。然而，它们在一些信息抽取任务中往往达不到要求，特别是那些需要特定领域知识的任务，例如生物医学命名实体识别(Biomedical Named tity 識，NER)。在本文中，受思想链的启发，我们利用 LLM 来逐步解决生物医学 NER 问题: 将 NER 任务分解为实体跨度提取和实体类型确定。此外，对于实体类型的确定，我们注入实体知识来解决 LLM 在预测实体类别时缺乏领域知识的问题。实验结果显示，我们的两步 BioNER 方法显着改善，相比以前的少拍 LLM 基线。此外，外部知识的加入显著提高了实体类别确定的绩效。"
    },
    {
        "title": "LLMR: Real-time Prompting of Interactive Worlds using Large Language\n  Models",
        "url": "http://arxiv.org/abs/2309.12276v1",
        "pub_date": "2023-09-21",
        "summary": "We present Large Language Model for Mixed Reality (LLMR), a framework for the\nreal-time creation and modification of interactive Mixed Reality experiences\nusing LLMs. LLMR leverages novel strategies to tackle difficult cases where\nideal training data is scarce, or where the design goal requires the synthesis\nof internal dynamics, intuitive analysis, or advanced interactivity. Our\nframework relies on text interaction and the Unity game engine. By\nincorporating techniques for scene understanding, task planning,\nself-debugging, and memory management, LLMR outperforms the standard GPT-4 by\n4x in average error rate. We demonstrate LLMR's cross-platform interoperability\nwith several example worlds, and evaluate it on a variety of creation and\nmodification tasks to show that it can produce and edit diverse objects, tools,\nand scenes. Finally, we conducted a usability study (N=11) with a diverse set\nthat revealed participants had positive experiences with the system and would\nuse it again.",
        "translated": "我们提出了混合现实的大语言模型(LLMR) ，一个实时创建和修改交互式混合现实体验使用 LLM 的框架。LLMR 利用新颖的策略来解决理想训练数据稀缺的困难情况，或者设计目标需要综合内部动力学、直观分析或高级交互性的情况。我们的框架依赖于文本交互和 Unity 游戏引擎。通过结合场景理解、任务规划、自调试和内存管理等技术，LLMR 的平均错误率比标准 GPT-4高出4倍。我们用几个示例世界演示了 LLMR 的跨平台互操作性，并在各种创建和修改任务中对其进行评估，以表明它可以生成和编辑不同的对象、工具和场景。最后，我们进行了一项可用性研究(N = 11) ，结果显示参与者对该系统有积极的体验，并且还会再次使用它。"
    },
    {
        "title": "The Cambridge Law Corpus: A Corpus for Legal AI Research",
        "url": "http://arxiv.org/abs/2309.12269v1",
        "pub_date": "2023-09-21",
        "summary": "We introduce the Cambridge Law Corpus (CLC), a corpus for legal AI research.\nIt consists of over 250 000 court cases from the UK. Most cases are from the\n21st century, but the corpus includes cases as old as the 16th century. This\npaper presents the first release of the corpus, containing the raw text and\nmeta-data. Together with the corpus, we provide annotations on case outcomes\nfor 638 cases, done by legal experts. Using our annotated data, we have trained\nand evaluated case outcome extraction with GPT-3, GPT-4 and RoBERTa models to\nprovide benchmarks. We include an extensive legal and ethical discussion to\naddress the potentially sensitive nature of this material. As a consequence,\nthe corpus will only be released for research purposes under certain\nrestrictions.",
        "translated": "我们介绍了剑桥法律语料库(CLC) ，一个用于法律人工智能研究的语料库。它包括超过250000个来自英国的法庭案件。大多数案例来自21世纪，但是语料库中包括了16世纪的案例。本文介绍了语料库的第一个版本，包含原始文本和元数据。与语料库一起，我们为638个案例提供了由法律专家完成的案例结果注释。使用我们的注释数据，我们已经用 GPT-3、 GPT-4和 RoBERTa 模型训练和评估了病例结果提取，以提供基准测试。我们包括一个广泛的法律和道德讨论，以处理这种材料的潜在敏感性质。因此，在某些限制下，语料库只能用于研究目的。"
    },
    {
        "title": "Diffusion Augmentation for Sequential Recommendation",
        "url": "http://arxiv.org/abs/2309.12858v1",
        "pub_date": "2023-09-22",
        "summary": "Sequential recommendation (SRS) has become the technical foundation in many\napplications recently, which aims to recommend the next item based on the\nuser's historical interactions. However, sequential recommendation often faces\nthe problem of data sparsity, which widely exists in recommender systems.\nBesides, most users only interact with a few items, but existing SRS models\noften underperform these users. Such a problem, named the long-tail user\nproblem, is still to be resolved. Data augmentation is a distinct way to\nalleviate these two problems, but they often need fabricated training\nstrategies or are hindered by poor-quality generated interactions. To address\nthese problems, we propose a Diffusion Augmentation for Sequential\nRecommendation (DiffuASR) for a higher quality generation. The augmented\ndataset by DiffuASR can be used to train the sequential recommendation models\ndirectly, free from complex training procedures. To make the best of the\ngeneration ability of the diffusion model, we first propose a diffusion-based\npseudo sequence generation framework to fill the gap between image and sequence\ngeneration. Then, a sequential U-Net is designed to adapt the diffusion noise\nprediction model U-Net to the discrete sequence generation task. At last, we\ndevelop two guide strategies to assimilate the preference between generated and\norigin sequences. To validate the proposed DiffuASR, we conduct extensive\nexperiments on three real-world datasets with three sequential recommendation\nmodels. The experimental results illustrate the effectiveness of DiffuASR. As\nfar as we know, DiffuASR is one pioneer that introduce the diffusion model to\nthe recommendation.",
        "translated": "序贯推荐(SRS)已经成为许多应用程序的技术基础，其目的是根据用户的历史交互情况推荐下一个项目。然而，在推荐系统中，顺序推荐常常面临数据稀疏的问题。此外，大多数用户只与少数几个项目交互，但现有的 SRS 模型往往表现不佳。这样一个被称为长尾用户问题的问题仍有待解决。数据增强是缓解这两个问题的一种独特方式，但它们往往需要编造的培训策略，或受到低质量生成的交互作用的阻碍。为了解决这些问题，我们提出了一种扩散增强的序列推荐(区分 ASR)为更高的质量生成。区分扩展数据集可以直接用于训练序列推荐模型，避免了复杂的训练过程。为了充分利用扩散模型的生成能力，我们首先提出了一种基于扩散的伪序列生成框架，以填补图像和序列生成之间的空白。然后，设计了一个序列 U-Net，使扩散噪声预测模型 U-Net 适应离散序列生成任务。最后，我们提出了两种引导策略来同化生成序列和起源序列之间的偏好。为了验证所提出的 DISUASR，我们使用三个连续的推荐模型在三个真实世界的数据集上进行了广泛的实验。实验结果表明了该方法的有效性。据我们所知，DISUASR 是将扩散模型引入推荐系统的先驱者之一。"
    },
    {
        "title": "Enhancing Graph Collaborative Filtering via Uniformly Co-Clustered\n  Intent Modeling",
        "url": "http://arxiv.org/abs/2309.12723v1",
        "pub_date": "2023-09-22",
        "summary": "Graph-based collaborative filtering has emerged as a powerful paradigm for\ndelivering personalized recommendations. Despite their demonstrated\neffectiveness, these methods often neglect the underlying intents of users,\nwhich constitute a pivotal facet of comprehensive user interests. Consequently,\na series of approaches have arisen to tackle this limitation by introducing\nindependent intent representations. However, these approaches fail to capture\nthe intricate relationships between intents of different users and the\ncompatibility between user intents and item properties.\n  To remedy the above issues, we propose a novel method, named uniformly\nco-clustered intent modeling. Specifically, we devise a uniformly contrastive\nintent modeling module to bring together the embeddings of users with similar\nintents and items with similar properties. This module aims to model the\nnuanced relations between intents of different users and properties of\ndifferent items, especially those unreachable to each other on the user-item\ngraph. To model the compatibility between user intents and item properties, we\ndesign the user-item co-clustering module, maximizing the mutual information of\nco-clusters of users and items. This approach is substantiated through\ntheoretical validation, establishing its efficacy in modeling compatibility to\nenhance the mutual information between user and item representations.\nComprehensive experiments on various real-world datasets verify the\neffectiveness of the proposed framework.",
        "translated": "基于图表的协同过滤已经成为提供个性化建议的强大范例。尽管这些方法被证明是有效的，但它们往往忽视了用户的潜在意图，而这些意图构成了全面用户兴趣的关键方面。因此，通过引入独立的意图表示，出现了一系列的方法来解决这一局限性。但是，这些方法无法捕获不同用户意图之间的复杂关系以及用户意图和项属性之间的兼容性。为了解决上述问题，我们提出了一种新的方法，称为统一协聚类意图建模。具体来说，我们设计了一个统一的对比意图建模模块，将具有相似意图和具有相似属性的项目的用户嵌入到一起。该模块旨在建立不同用户的意图和不同项目属性之间的细微差别关系，特别是用户项目图上彼此无法达到的关系。为了建立用户意图与项目属性之间的相容性模型，设计了用户-项目共聚类模块，最大化了用户与项目共聚类的互信息。通过理论验证，验证了该方法在建模相容性方面的有效性，增强了用户与项目表征之间的相互信息。在各种真实世界数据集上的综合实验验证了该框架的有效性。"
    },
    {
        "title": "KuaiSim: A Comprehensive Simulator for Recommender Systems",
        "url": "http://arxiv.org/abs/2309.12645v1",
        "pub_date": "2023-09-22",
        "summary": "Reinforcement Learning (RL)-based recommender systems (RSs) have garnered\nconsiderable attention due to their ability to learn optimal recommendation\npolicies and maximize long-term user rewards. However, deploying RL models\ndirectly in online environments and generating authentic data through A/B tests\ncan pose challenges and require substantial resources. Simulators offer an\nalternative approach by providing training and evaluation environments for RS\nmodels, reducing reliance on real-world data. Existing simulators have shown\npromising results but also have limitations such as simplified user feedback,\nlacking consistency with real-world data, the challenge of simulator\nevaluation, and difficulties in migration and expansion across RSs. To address\nthese challenges, we propose KuaiSim, a comprehensive user environment that\nprovides user feedback with multi-behavior and cross-session responses. The\nresulting simulator can support three levels of recommendation problems: the\nrequest level list-wise recommendation task, the whole-session level sequential\nrecommendation task, and the cross-session level retention optimization task.\nFor each task, KuaiSim also provides evaluation protocols and baseline\nrecommendation algorithms that further serve as benchmarks for future research.\nWe also restructure existing competitive simulators on the KuaiRand Dataset and\ncompare them against KuaiSim to future assess their performance and behavioral\ndifferences. Furthermore, to showcase KuaiSim's flexibility in accommodating\ndifferent datasets, we demonstrate its versatility and robustness when\ndeploying it on the ML-1m dataset.",
        "translated": "基于强化学习(rL)的推荐系统(RSs)因其学习最佳推荐策略和最大化长期用户回报的能力而受到广泛关注。然而，直接在在线环境中部署 RL 模型和通过 A/B 测试生成真实数据可能会带来挑战，并且需要大量资源。模拟器提供了一种替代方法，为 RS 模型提供训练和评估环境，减少对真实世界数据的依赖。现有的模拟器已经显示出良好的效果，但也存在一些局限性，如简化的用户反馈，缺乏与真实世界数据的一致性，模拟器评估的挑战，以及跨 RSS 迁移和扩展的困难。为了应对这些挑战，我们提出 KuaiSim，一个全面的用户环境，它提供用户多行为和跨会话响应的反馈。所得到的模拟器可以支持三个级别的推荐问题: 请求级列表式推荐任务、全会话级顺序推荐任务和跨会话级保持优化任务。对于每个任务，KuaiSim 还提供评估协议和基线推荐算法，进一步作为未来研究的基准。我们还重组了 KuaiRand 数据集上现有的竞争模拟器，并将它们与 KuaiSim 进行比较，以便将来评估它们的性能和行为差异。此外，为了展示 KuaiSim 在容纳不同数据集方面的灵活性，我们在 ML-1m 数据集上部署它时展示了它的通用性和鲁棒性。"
    },
    {
        "title": "Modeling Spatiotemporal Periodicity and Collaborative Signal for\n  Local-Life Service Recommendation",
        "url": "http://arxiv.org/abs/2309.12565v1",
        "pub_date": "2023-09-22",
        "summary": "Online local-life service platforms provide services like nearby daily\nessentials and food delivery for hundreds of millions of users. Different from\nother types of recommender systems, local-life service recommendation has the\nfollowing characteristics: (1) spatiotemporal periodicity, which means a user's\npreferences for items vary from different locations at different times. (2)\nspatiotemporal collaborative signal, which indicates similar users have similar\npreferences at specific locations and times. However, most existing methods\neither focus on merely the spatiotemporal contexts in sequences, or model the\nuser-item interactions without spatiotemporal contexts in graphs. To address\nthis issue, we design a new method named SPCS in this paper. Specifically, we\npropose a novel spatiotemporal graph transformer (SGT) layer, which explicitly\nencodes relative spatiotemporal contexts, and aggregates the information from\nmulti-hop neighbors to unify spatiotemporal periodicity and collaborative\nsignal. With extensive experiments on both public and industrial datasets, this\npaper validates the state-of-the-art performance of SPCS.",
        "translated": "在线本地生活服务平台为数亿用户提供附近日常必需品和送餐等服务。与其他类型的推荐系统不同，本地生活服务推荐系统具有以下特点: (1)时空周期性，即用户在不同时间、不同地点对物品的偏好有所不同。(2)时空协作信号，表明相似用户在特定的时间和地点有相似的偏好。然而，大多数现有的方法要么仅仅关注序列中的时空上下文，要么在图中建立没有时空上下文的用户-项目交互模型。针对这一问题，本文设计了一种新的方法 SPCS。提出了一种新的时空图转换器(SGT)层，该层对相关的时空上下文进行显式编码，并对多跳邻居的信息进行聚合，以统一时空周期性和协同信号。通过在公共数据集和工业数据集上的大量实验，验证了 SPCS 的最新性能。"
    },
    {
        "title": "Dynamic ASR Pathways: An Adaptive Masking Approach Towards Efficient\n  Pruning of A Multilingual ASR Model",
        "url": "http://arxiv.org/abs/2309.13018v1",
        "pub_date": "2023-09-22",
        "summary": "Neural network pruning offers an effective method for compressing a\nmultilingual automatic speech recognition (ASR) model with minimal performance\nloss. However, it entails several rounds of pruning and re-training needed to\nbe run for each language. In this work, we propose the use of an adaptive\nmasking approach in two scenarios for pruning a multilingual ASR model\nefficiently, each resulting in sparse monolingual models or a sparse\nmultilingual model (named as Dynamic ASR Pathways). Our approach dynamically\nadapts the sub-network, avoiding premature decisions about a fixed sub-network\nstructure. We show that our approach outperforms existing pruning methods when\ntargeting sparse monolingual models. Further, we illustrate that Dynamic ASR\nPathways jointly discovers and trains better sub-networks (pathways) of a\nsingle multilingual model by adapting from different sub-network\ninitializations, thereby reducing the need for language-specific pruning.",
        "translated": "神经网络剪枝为压缩多语言自动语音识别(ASR)模型提供了一种有效的方法，其性能损失最小。然而，它需要对每种语言进行几轮修剪和再培训。在这项工作中，我们建议在两个场景中使用自适应掩蔽方法来有效地修剪多语言 ASR 模型，每个都导致稀疏的单语言模型或稀疏的多语言模型(称为动态 ASR 路径)。我们的方法动态地适应子网络，避免了关于固定子网络结构的过早决策。我们表明，我们的方法优于现有的剪枝方法时，针对稀疏的单语言模型。进一步，我们说明动态 ASR 路径通过适应不同的子网络初始化，共同发现和训练单个多语言模型的更好的子网络(路径) ，从而减少特定语言修剪的需要。"
    },
    {
        "title": "ReConcile: Round-Table Conference Improves Reasoning via Consensus among\n  Diverse LLMs",
        "url": "http://arxiv.org/abs/2309.13007v1",
        "pub_date": "2023-09-22",
        "summary": "Large Language Models (LLMs) still struggle with complex reasoning tasks.\nMotivated by the society of minds (Minsky, 1988), we propose ReConcile, a\nmulti-model multi-agent framework designed as a round table conference among\ndiverse LLM agents to foster diverse thoughts and discussion for improved\nconsensus. ReConcile enhances the reasoning capabilities of LLMs by holding\nmultiple rounds of discussion, learning to convince other agents to improve\ntheir answers, and employing a confidence-weighted voting mechanism. In each\nround, ReConcile initiates discussion between agents via a 'discussion prompt'\nthat consists of (a) grouped answers and explanations generated by each agent\nin the previous round, (b) their uncertainties, and (c) demonstrations of\nanswer-rectifying human explanations, used for convincing other agents. This\ndiscussion prompt enables each agent to revise their responses in light of\ninsights from other agents. Once a consensus is reached and the discussion\nends, ReConcile determines the final answer by leveraging the confidence of\neach agent in a weighted voting scheme. We implement ReConcile with ChatGPT,\nBard, and Claude2 as the three agents. Our experimental results on various\nbenchmarks demonstrate that ReConcile significantly enhances the reasoning\nperformance of the agents (both individually and as a team), surpassing prior\nsingle-agent and multi-agent baselines by 7.7% and also outperforming GPT-4 on\nsome of these datasets. We also experiment with GPT-4 itself as one of the\nagents in ReConcile and demonstrate that its initial performance also improves\nby absolute 10.0% through discussion and feedback from other agents. Finally,\nwe also analyze the accuracy after every round and observe that ReConcile\nachieves better and faster consensus between agents, compared to a multi-agent\ndebate baseline. Our code is available at: https://github.com/dinobby/ReConcile",
        "translated": "大型语言模型(LLM)仍然需要完成复杂的推理任务。在思想社会(Minsky，1988)的激励下，我们提出了 ReConcile，一个多模型多代理框架，设计为不同 LLM 代理之间的圆桌会议，以促进多样化的思想和讨论，以改善共识。通过举行多轮讨论，学习说服其他代理改进他们的答案，以及采用信心加权投票机制，ReConcile 增强了 LLM 的推理能力。在每一轮中，ReConcile 通过一个“讨论提示”在代理之间发起讨论，包括(a)前一轮中每个代理产生的分组答案和解释，(b)他们的不确定性，和(c)用于说服其他代理的回答-纠正人类解释的示范。这个讨论提示使每个代理人能够根据其他代理人的见解修改他们的答复。一旦达成共识，讨论结束，通过利用每个代理人对加权投票方案的信心，调解决定最终答案。我们使用 ChatGPT、 Bard 和 Claude2作为三个代理来实现和解。我们在各种基准上的实验结果表明，ReConcile 显着提高了代理(单独和作为一个团队)的推理性能，超过以前的单代理和多代理基线7.7% ，并且在其中一些数据集上优于 GPT-4。我们还将 GPT-4本身作为 ReConcile 中的代理之一进行了实验，通过讨论和其他代理的反馈，证明其初始性能也提高了绝对10.0% 。最后，我们还分析了每一轮之后的准确性，并观察到，与多代理辩论基线相比，ReConcile 在代理之间达成了更好、更快的共识。我们的代码可以在以下 https://github.com/dinobby/reconcile 找到"
    },
    {
        "title": "Audience-specific Explanations for Machine Translation",
        "url": "http://arxiv.org/abs/2309.12998v1",
        "pub_date": "2023-09-22",
        "summary": "In machine translation, a common problem is that the translation of certain\nwords even if translated can cause incomprehension of the target language\naudience due to different cultural backgrounds. A solution to solve this\nproblem is to add explanations for these words. In a first step, we therefore\nneed to identify these words or phrases. In this work we explore techniques to\nextract example explanations from a parallel corpus. However, the sparsity of\nsentences containing words that need to be explained makes building the\ntraining dataset extremely difficult. In this work, we propose a semi-automatic\ntechnique to extract these explanations from a large parallel corpus.\nExperiments on English-&gt;German language pair show that our method is able to\nextract sentence so that more than 10% of the sentences contain explanation,\nwhile only 1.9% of the original sentences contain explanations. In addition,\nexperiments on English-&gt;French and English-&gt;Chinese language pairs also show\nsimilar conclusions. This is therefore an essential first automatic step to\ncreate a explanation dataset. Furthermore we show that the technique is robust\nfor all three language pairs.",
        "translated": "在机器翻译中，一个常见的问题是，由于不同的文化背景，即使翻译了某些词语，也会造成目标语受众的不理解。解决这个问题的一个办法是增加对这些词的解释。因此，在第一步中，我们需要识别这些单词或短语。在这项工作中，我们探索的技术，以提取示例解释从一个平行的语料库。然而，包含需要解释的单词的句子的稀疏性使得建立训练数据集极其困难。在这项工作中，我们提出了一个半自动的技术，以提取这些解释从一个大型并行语料库。对英语-德语对的实验表明，该方法能够提取出10% 以上的句子含有解释成分，而原始句子中只有1.9% 含有解释成分。此外，英语-> 法语和英语-> 汉语对的实验也得出了类似的结论。因此，这是创建解释数据集必不可少的第一个自动步骤。此外，我们表明，该技术是鲁棒的所有三个语言对。"
    },
    {
        "title": "Nested Event Extraction upon Pivot Element Recogniton",
        "url": "http://arxiv.org/abs/2309.12960v1",
        "pub_date": "2023-09-22",
        "summary": "Nested Event Extraction (NEE) aims to extract complex event structures where\nan event contains other events as its arguments recursively. Nested events\ninvolve a kind of Pivot Elements (PEs) that simultaneously act as arguments of\nouter events and as triggers of inner events, and thus connect them into nested\nstructures. This special characteristic of PEs brings challenges to existing\nNEE methods, as they cannot well cope with the dual identities of PEs.\nTherefore, this paper proposes a new model, called PerNee, which extracts\nnested events mainly based on recognizing PEs. Specifically, PerNee first\nrecognizes the triggers of both inner and outer events and further recognizes\nthe PEs via classifying the relation type between trigger pairs. In order to\nobtain better representations of triggers and arguments to further improve NEE\nperformance, it incorporates the information of both event types and argument\nroles into PerNee through prompt learning. Since existing NEE datasets (e.g.,\nGenia11) are limited to specific domains and contain a narrow range of event\ntypes with nested structures, we systematically categorize nested events in\ngeneric domain and construct a new NEE dataset, namely ACE2005-Nest.\nExperimental results demonstrate that PerNee consistently achieves\nstate-of-the-art performance on ACE2005-Nest, Genia11 and Genia13.",
        "translated": "嵌套事件提取(NEE)旨在提取复杂的事件结构，其中事件包含其他事件作为递归参数。嵌套事件涉及到一种枢轴元素(PE) ，它同时作为外部事件的参数和内部事件的触发器，从而将它们连接到嵌套结构中。PE 的这种特殊性质给现有的 NEE 方法带来了挑战，因为它们不能很好地处理 PE 的双重身份。因此，本文提出了一种新的事件提取模型—— PerNee，该模型主要基于对事件的识别来提取嵌套事件。具体来说，PerNee 首先识别内部和外部事件的触发器，并通过对触发器对之间的关系类型进行分类来进一步识别 PE。为了更好地表示触发器和论元，进一步提高 NEE 的性能，它通过快速学习将事件类型和论元角色的信息整合到 PerNee 中。由于现有的 NEE 数据集(例如 Genia11)仅限于特定的域，并且包含具有嵌套结构的狭窄范围的事件类型，因此我们系统地将嵌套事件在通用域中进行分类，并构建一个新的 NEE 数据集，即 ACE2005-Nest。实验结果表明，PerNee 在 ACE2005-Nest、 Genia11和 Genia13上始终达到最先进的性能。"
    },
    {
        "title": "Self-Explanation Prompting Improves Dialogue Understanding in Large\n  Language Models",
        "url": "http://arxiv.org/abs/2309.12940v1",
        "pub_date": "2023-09-22",
        "summary": "Task-oriented dialogue (TOD) systems facilitate users in executing various\nactivities via multi-turn dialogues, but Large Language Models (LLMs) often\nstruggle to comprehend these intricate contexts. In this study, we propose a\nnovel \"Self-Explanation\" prompting strategy to enhance the comprehension\nabilities of LLMs in multi-turn dialogues. This task-agnostic approach requires\nthe model to analyze each dialogue utterance before task execution, thereby\nimproving performance across various dialogue-centric tasks. Experimental\nresults from six benchmark datasets confirm that our method consistently\noutperforms other zero-shot prompts and matches or exceeds the efficacy of\nfew-shot prompts, demonstrating its potential as a powerful tool in enhancing\nLLMs' comprehension in complex dialogue tasks.",
        "translated": "面向任务的对话(TOD)系统方便用户通过多回合对话执行各种活动，但大语言模型(LLM)往往难以理解这些复杂的上下文。在这项研究中，我们提出了一种新的“自我解释”激励策略，以提高多回合对话中的语言习得能力。这种任务无关的方法要求模型在任务执行之前分析每个对话语句，从而提高各种以对话为中心的任务的性能。六个基准数据集的实验结果证实，我们的方法始终优于其他零拍提示和匹配或超过少拍提示的功效，表明其作为一个强大的工具在提高复杂对话任务的 LLM 的理解潜力。"
    },
    {
        "title": "TopRoBERTa: Topology-Aware Authorship Attribution of Deepfake Texts",
        "url": "http://arxiv.org/abs/2309.12934v1",
        "pub_date": "2023-09-22",
        "summary": "Recent advances in Large Language Models (LLMs) have enabled the generation\nof open-ended high-quality texts, that are non-trivial to distinguish from\nhuman-written texts. We refer to such LLM-generated texts as \\emph{deepfake\ntexts}. There are currently over 11K text generation models in the huggingface\nmodel repo. As such, users with malicious intent can easily use these\nopen-sourced LLMs to generate harmful texts and misinformation at scale. To\nmitigate this problem, a computational method to determine if a given text is a\ndeepfake text or not is desired--i.e., Turing Test (TT). In particular, in this\nwork, we investigate the more general version of the problem, known as\n\\emph{Authorship Attribution (AA)}, in a multi-class setting--i.e., not only\ndetermining if a given text is a deepfake text or not but also being able to\npinpoint which LLM is the author. We propose \\textbf{TopRoBERTa} to improve\nexisting AA solutions by capturing more linguistic patterns in deepfake texts\nby including a Topological Data Analysis (TDA) layer in the RoBERTa model. We\nshow the benefits of having a TDA layer when dealing with noisy, imbalanced,\nand heterogeneous datasets, by extracting TDA features from the reshaped\n$pooled\\_output$ of RoBERTa as input. We use RoBERTa to capture contextual\nrepresentations (i.e., semantic and syntactic linguistic features), while using\nTDA to capture the shape and structure of data (i.e., linguistic structures).\nFinally, \\textbf{TopRoBERTa}, outperforms the vanilla RoBERTa in 2/3 datasets,\nachieving up to 7\\% increase in Macro F1 score.",
        "translated": "大型语言模型(LLM)的最新进展使得开放式高质量文本的产生成为可能，这些文本与人类书写的文本有着不可忽视的区别。我们将 LLM 生成的文本称为 emph { deep false text }。目前在拥抱脸模型回购中有超过11K 的文本生成模型。因此，具有恶意意图的用户可以很容易地使用这些开源 LLM 大规模地生成有害的文本和错误信息。为了缓解这个问题，需要一个计算方法来确定给定的文本是否为深度伪造文本——即图灵测试(Turing Test，TT)。特别是，在这项工作中，我们研究了更一般的问题版本，称为 emph { Authorship Attritribute (AA)} ，在一个多类设置中——即，不仅确定给定的文本是否是一个深度伪造的文本，而且能够确定哪个 LLM 是作者。我们提出 textbf { TopRoBERTa }通过在 RoBERTa 模型中包含一个拓扑数据分析(TDA)层来捕获深度伪造文本中更多的语言模式，从而改进现有的 AA 解决方案。我们展示了在处理噪声、不平衡和异构数据集时使用 TDA 层的好处，方法是从重新形状化的 $pool _ output $作为输入的 RoBERTa 中提取 TDA 特性。我们使用 RoBERTa 来捕获上下文表示(即语义和句法语言特征) ，同时使用 TDA 来捕获数据的形状和结构(即语言结构)。最后，textbf { TopRoBERTa }在2/3数据集中的性能优于传统的 RoBERTa，宏 F1得分提高了7% 。"
    },
    {
        "title": "On Separate Normalization in Self-supervised Transformers",
        "url": "http://arxiv.org/abs/2309.12931v1",
        "pub_date": "2023-09-22",
        "summary": "Self-supervised training methods for transformers have demonstrated\nremarkable performance across various domains. Previous transformer-based\nmodels, such as masked autoencoders (MAE), typically utilize a single\nnormalization layer for both the [CLS] symbol and the tokens. We propose in\nthis paper a simple modification that employs separate normalization layers for\nthe tokens and the [CLS] symbol to better capture their distinct\ncharacteristics and enhance downstream task performance. Our method aims to\nalleviate the potential negative effects of using the same normalization\nstatistics for both token types, which may not be optimally aligned with their\nindividual roles. We empirically show that by utilizing a separate\nnormalization layer, the [CLS] embeddings can better encode the global\ncontextual information and are distributed more uniformly in its anisotropic\nspace. When replacing the conventional normalization layer with the two\nseparate layers, we observe an average 2.7% performance improvement over the\nimage, natural language, and graph domains.",
        "translated": "变压器自监督训练方法在各个领域都表现出了显著的性能。以前的基于转换器的模型，例如掩码自动编码器(MAE) ，通常为[ CLS ]符号和令牌使用单个标准化层。我们提出了一个简单的修改，使用单独的标准化层的令牌和[ CLS ]符号，以更好地捕捉其独特的特点，并提高下游任务的性能。我们的方法旨在减轻对两种令牌类型使用相同的标准化统计信息的潜在负面影响，这些统计信息可能与它们各自的角色不能最佳地保持一致。实验结果表明，[ CLS ]嵌入通过使用一个单独的归一化层，可以更好地编码全局上下文信息，并且在其各向异性空间中分布更均匀。当用两个独立的层代替传统的规范化层时，我们观察到平均比图像、自然语言和图形域的性能提高了2.7% 。"
    },
    {
        "title": "ProtoEM: A Prototype-Enhanced Matching Framework for Event Relation\n  Extraction",
        "url": "http://arxiv.org/abs/2309.12892v1",
        "pub_date": "2023-09-22",
        "summary": "Event Relation Extraction (ERE) aims to extract multiple kinds of relations\namong events in texts. However, existing methods singly categorize event\nrelations as different classes, which are inadequately capturing the intrinsic\nsemantics of these relations. To comprehensively understand their intrinsic\nsemantics, in this paper, we obtain prototype representations for each type of\nevent relation and propose a Prototype-Enhanced Matching (ProtoEM) framework\nfor the joint extraction of multiple kinds of event relations. Specifically,\nProtoEM extracts event relations in a two-step manner, i.e., prototype\nrepresenting and prototype matching. In the first step, to capture the\nconnotations of different event relations, ProtoEM utilizes examples to\nrepresent the prototypes corresponding to these relations. Subsequently, to\ncapture the interdependence among event relations, it constructs a dependency\ngraph for the prototypes corresponding to these relations and utilized a Graph\nNeural Network (GNN)-based module for modeling. In the second step, it obtains\nthe representations of new event pairs and calculates their similarity with\nthose prototypes obtained in the first step to evaluate which types of event\nrelations they belong to. Experimental results on the MAVEN-ERE dataset\ndemonstrate that the proposed ProtoEM framework can effectively represent the\nprototypes of event relations and further obtain a significant improvement over\nbaseline models.",
        "translated": "事件关系抽取的目的是提取文本中事件之间的多种关系。然而，现有的方法将事件关系单独归类为不同的类，不能充分地捕获这些关系的内在语义。为了全面理解事件关系的内在语义，本文提出了一种基于原型增强匹配(ProtoEM)的多类事件关系联合提取框架。具体来说，ProtoEM 以两步的方式提取事件关系，即原型表示和原型匹配。在第一步，为了捕捉不同事件关系的内涵，ProtoEM 利用实例来表示与这些关系相对应的原型。然后，为了捕获事件关系之间的相互依赖关系，为这些关系对应的原型构造依赖图，并利用基于图神经网络(GNN)的模块进行建模。在第二步中，它获得新事件对的表示，并计算它们与第一步中获得的原型的相似性，以评估它们属于哪种类型的事件关系。在 MAVEN-ere 数据集上的实验结果表明，所提出的 ProtoEM 框架能够有效地表示事件关系的原型，并且比基线模型进一步获得了显著的改进。"
    },
    {
        "title": "Affect Recognition in Conversations Using Large Language Models",
        "url": "http://arxiv.org/abs/2309.12881v1",
        "pub_date": "2023-09-22",
        "summary": "Affect recognition, encompassing emotions, moods, and feelings, plays a\npivotal role in human communication. In the realm of conversational artificial\nintelligence (AI), the ability to discern and respond to human affective cues\nis a critical factor for creating engaging and empathetic interactions. This\nstudy delves into the capacity of large language models (LLMs) to recognise\nhuman affect in conversations, with a focus on both open-domain chit-chat\ndialogues and task-oriented dialogues. Leveraging three diverse datasets,\nnamely IEMOCAP, EmoWOZ, and DAIC-WOZ, covering a spectrum of dialogues from\ncasual conversations to clinical interviews, we evaluated and compared LLMs'\nperformance in affect recognition. Our investigation explores the zero-shot and\nfew-shot capabilities of LLMs through in-context learning (ICL) as well as\ntheir model capacities through task-specific fine-tuning. Additionally, this\nstudy takes into account the potential impact of automatic speech recognition\n(ASR) errors on LLM predictions. With this work, we aim to shed light on the\nextent to which LLMs can replicate human-like affect recognition capabilities\nin conversations.",
        "translated": "情感识别包括情绪、情绪和感觉，在人类交流中起着关键作用。在会话人工智能(AI)领域，识别和响应人类情感线索的能力是创造有吸引力和移情互动的关键因素。本研究探讨了大型语言模型(LLM)在会话中识别人类情感的能力，重点研究了开放领域的闲聊对话和任务导向的对话。我们利用三个不同的数据集，即 IEMOCAP，emoWOZ 和 DAIC-WOZ，涵盖了从随意谈话到临床访谈的一系列对话，评估和比较 LLM 在情感识别方面的表现。我们的研究通过上下文学习(ICL)探索了 LLM 的零射击和少射击能力，并通过任务特定的微调探索了 LLM 的模型能力。此外，本研究还考虑了自动语音识别(ASR)错误对 LLM 预测的潜在影响。通过这项工作，我们的目标是揭示 LLM 在多大程度上可以复制人类的情感识别能力在会话。"
    },
    {
        "title": "AnglE-Optimized Text Embeddings",
        "url": "http://arxiv.org/abs/2309.12871v1",
        "pub_date": "2023-09-22",
        "summary": "High-quality text embedding is pivotal in improving semantic textual\nsimilarity (STS) tasks, which are crucial components in Large Language Model\n(LLM) applications. However, a common challenge existing text embedding models\nface is the problem of vanishing gradients, primarily due to their reliance on\nthe cosine function in the optimization objective, which has saturation zones.\nTo address this issue, this paper proposes a novel angle-optimized text\nembedding model called AnglE. The core idea of AnglE is to introduce angle\noptimization in a complex space. This novel approach effectively mitigates the\nadverse effects of the saturation zone in the cosine function, which can impede\ngradient and hinder optimization processes. To set up a comprehensive STS\nevaluation, we experimented on existing short-text STS datasets and a newly\ncollected long-text STS dataset from GitHub Issues. Furthermore, we examine\ndomain-specific STS scenarios with limited labeled data and explore how AnglE\nworks with LLM-annotated data. Extensive experiments were conducted on various\ntasks including short-text STS, long-text STS, and domain-specific STS tasks.\nThe results show that AnglE outperforms the state-of-the-art (SOTA) STS models\nthat ignore the cosine saturation zone. These findings demonstrate the ability\nof AnglE to generate high-quality text embeddings and the usefulness of angle\noptimization in STS.",
        "translated": "高质量的文本嵌入是提高语义文本相似度(STS)任务的关键，而语义文本相似度是大语言模型(LLM)应用的关键组成部分。然而，现有的文本嵌入模型面临的一个共同挑战是梯度的消失问题，这主要是由于它们在优化目标中依赖余弦函数，而且存在饱和区域。为了解决这个问题，本文提出了一种新的角度优化的文本嵌入模型，称为角度。角度优化的核心思想是在复杂空间中引入角度优化。这种新方法有效地缓解了余弦函数中饱和区域的不利影响，这种不利影响会阻碍梯度，阻碍优化过程。为了建立一个全面的 STS 评估，我们在现有的短文本 STS 数据集和 GitHub 新收集的长文本 STS 数据集上进行了实验。此外，我们研究了具有有限标记数据的特定于领域的 STS 场景，并探讨了 AnglE 如何使用 LLM 注释数据。在各种任务上进行了广泛的实验，包括短文本 STS、长文本 STS 和领域特定的 STS 任务。结果表明，倾角模型优于忽略余弦饱和区的最新 STS 模型。这些研究结果表明，角度优化能够产生高质量的文本嵌入和有用的角度优化在 STS。"
    },
    {
        "title": "Cluster Language Model for Improved E-Commerce Retrieval and Ranking:\n  Leveraging Query Similarity and Fine-Tuning for Personalized Results",
        "url": "http://arxiv.org/abs/2309.14323v1",
        "pub_date": "2023-09-25",
        "summary": "This paper proposes a novel method to improve the accuracy of product search\nin e-commerce by utilizing a cluster language model. The method aims to address\nthe limitations of the bi-encoder architecture while maintaining a minimal\nadditional training burden. The approach involves labeling top products for\neach query, generating semantically similar query clusters using the K-Means\nclustering algorithm, and fine-tuning a global language model into cluster\nlanguage models on individual clusters. The parameters of each cluster language\nmodel are fine-tuned to learn local manifolds in the feature space efficiently,\ncapturing the nuances of various query types within each cluster. The inference\nis performed by assigning a new query to its respective cluster and utilizing\nthe corresponding cluster language model for retrieval. The proposed method\nresults in more accurate and personalized retrieval results, offering a\nsuperior alternative to the popular bi-encoder based retrieval models in\nsemantic search.",
        "translated": "提出了一种利用聚类语言模型提高电子商务中产品搜索准确性的新方法。该方法旨在解决双编码器体系结构的局限性，同时保持最小的额外训练负担。这种方法包括为每个查询标记顶级产品，使用 K平均算法算法生成语义相似的查询集群，以及在单个集群上将全球语言模型微调为集群语言模型。对每个集群语言模型的参数进行微调，以有效地学习特征空间中的局部流形，捕获每个集群中各种查询类型的细微差别。推理是通过为其各自的集群分配一个新的查询并利用相应的集群语言模型进行检索来完成的。该方法提高了检索结果的准确性和个性化程度，为语义检索中常用的基于双编码器的检索模型提供了一种更好的选择。"
    },
    {
        "title": "Framework based on complex networks to model and mine patient pathways",
        "url": "http://arxiv.org/abs/2309.14208v1",
        "pub_date": "2023-09-25",
        "summary": "The automatic discovery of a model to represent the history of encounters of\na group of patients with the healthcare system -- the so-called ``pathway of\npatients'' -- is a new field of research that supports clinical and\norganisational decisions to improve the quality and efficiency of the treatment\nprovided. The pathways of patients with chronic conditions tend to vary\nsignificantly from one person to another, have repetitive tasks, and demand the\nanalysis of multiple perspectives (interventions, diagnoses, medical\nspecialities, among others) influencing the results. Therefore, modelling and\nmining those pathways is still a challenging task. In this work, we propose a\nframework comprising: (i) a pathway model based on a multi-aspect graph, (ii) a\nnovel dissimilarity measurement to compare pathways taking the elapsed time\ninto account, and (iii) a mining method based on traditional centrality\nmeasures to discover the most relevant steps of the pathways. We evaluated the\nframework using the study cases of pregnancy and diabetes, which revealed its\nusefulness in finding clusters of similar pathways, representing them in an\neasy-to-interpret way, and highlighting the most significant patterns according\nto multiple perspectives.",
        "translated": "自动发现一个模型来代表一组病人与医疗系统相遇的历史——所谓的“病人之路”——是一个新的研究领域，支持临床和组织决策，以提高所提供治疗的质量和效率。慢性病患者的路径往往因人而异，具有重复性的任务，需要对影响结果的多种视角(干预、诊断、医学专业等)进行分析。因此，建模和挖掘这些路径仍然是一项具有挑战性的任务。在这项工作中，我们提出了一个框架，包括: (i)一个基于多方面图的路径模型，(ii)一个新的不相似性测量来比较路径，考虑到消耗的时间，和(iii)基于传统中心性措施的挖掘方法来发现最相关的步骤的路径。我们使用妊娠和糖尿病的研究病例评估了该框架，这揭示了其在发现类似途径集群方面的有用性，以易于解释的方式表示它们，并根据多种视角突出最显着的模式。"
    },
    {
        "title": "Comprehensive Overview of Named Entity Recognition: Models,\n  Domain-Specific Applications and Challenges",
        "url": "http://arxiv.org/abs/2309.14084v1",
        "pub_date": "2023-09-25",
        "summary": "In the domain of Natural Language Processing (NLP), Named Entity Recognition\n(NER) stands out as a pivotal mechanism for extracting structured insights from\nunstructured text. This manuscript offers an exhaustive exploration into the\nevolving landscape of NER methodologies, blending foundational principles with\ncontemporary AI advancements. Beginning with the rudimentary concepts of NER,\nthe study spans a spectrum of techniques from traditional rule-based strategies\nto the contemporary marvels of transformer architectures, particularly\nhighlighting integrations such as BERT with LSTM and CNN. The narrative\naccentuates domain-specific NER models, tailored for intricate areas like\nfinance, legal, and healthcare, emphasizing their specialized adaptability.\nAdditionally, the research delves into cutting-edge paradigms including\nreinforcement learning, innovative constructs like E-NER, and the interplay of\nOptical Character Recognition (OCR) in augmenting NER capabilities. Grounding\nits insights in practical realms, the paper sheds light on the indispensable\nrole of NER in sectors like finance and biomedicine, addressing the unique\nchallenges they present. The conclusion outlines open challenges and avenues,\nmarking this work as a comprehensive guide for those delving into NER research\nand applications.",
        "translated": "在自然语言处理(NLP)领域，命名实体识别(NER)是从非结构化文本中提取结构化见解的关键机制。这份手稿提供了一个不断发展的 NER 方法景观详尽的探索，融合了基础原则与当代人工智能的进步。从 NER 的基本概念开始，这项研究跨越了一系列技术，从传统的基于规则的策略到当代变压器架构的奇迹，特别强调了诸如 BERT 与 LSTM 和 CNN 的集成。叙述强调了领域特定的 NER 模型，为金融、法律和医疗等复杂领域量身定制，强调了它们的专门适应性。此外，这项研究还深入研究了前沿范例，包括强化学习、创新结构，如 E-NER，以及光学字符识别(OCR)在增强 NER 能力方面的相互作用。基于其在实践领域的见解，该文件阐明了 NER 在金融和生物医学等部门不可或缺的作用，解决他们提出的独特挑战。结论概述了开放的挑战和途径，标志着这项工作作为一个全面的指南，为那些深入研究 NER 的研究和应用。"
    },
    {
        "title": "Diversify and Conquer: Bandits and Diversity for an Enhanced E-commerce\n  Homepage Experience",
        "url": "http://arxiv.org/abs/2309.14046v1",
        "pub_date": "2023-09-25",
        "summary": "In the realm of e-commerce, popular platforms utilize widgets to recommend\nadvertisements and products to their users. However, the prevalence of mobile\ndevice usage on these platforms introduces a unique challenge due to the\nlimited screen real estate available. Consequently, the positioning of relevant\nwidgets becomes pivotal in capturing and maintaining customer engagement. Given\nthe restricted screen size of mobile devices, widgets placed at the top of the\ninterface are more prominently displayed and thus attract greater user\nattention. Conversely, widgets positioned further down the page require users\nto scroll, resulting in reduced visibility and subsequent lower impression\nrates. Therefore it becomes imperative to place relevant widgets on top.\nHowever, selecting relevant widgets to display is a challenging task as the\nwidgets can be heterogeneous, widgets can be introduced or removed at any given\ntime from the platform. In this work, we model the vertical widget reordering\nas a contextual multi-arm bandit problem with delayed batch feedback. The\nobjective is to rank the vertical widgets in a personalized manner. We present\na two-stage ranking framework that combines contextual bandits with a diversity\nlayer to improve the overall ranking. We demonstrate its effectiveness through\noffline and online A/B results, conducted on proprietary data from Myntra, a\nmajor fashion e-commerce platform in India.",
        "translated": "在电子商务领域，流行的平台利用小部件向用户推荐广告和产品。然而，移动设备在这些平台上的普及带来了一个独特的挑战，因为有限的屏幕空间可用。因此，相关小部件的定位成为获取和维护客户参与的关键。由于移动设备屏幕尺寸有限，放置在界面顶部的小部件显示得更加突出，因此吸引了更多用户的注意力。相反，位于页面下方的小部件需要用户滚动，导致可见度降低和随后的印象率降低。因此，将相关的小部件放在顶部变得势在必行。然而，选择要显示的相关小部件是一项具有挑战性的任务，因为小部件可以是异构的，可以在平台的任何给定时间引入或删除小部件。在这项工作中，我们模型垂直部件重新排序作为一个上下文多臂强盗问题与延迟批量反馈。目标是以个性化的方式对垂直小部件进行排名。我们提出了一个两阶段的排名框架，结合上下文土匪与多样性层，以提高整体排名。我们通过线下和线上的 A/B 结果来展示它的有效性，这些结果是基于 Myntra 的专有数据进行的，这是印度主要的时尚电子商务平台。"
    },
    {
        "title": "Multiple Relations Classification using Imbalanced Predictions\n  Adaptation",
        "url": "http://arxiv.org/abs/2309.13718v1",
        "pub_date": "2023-09-24",
        "summary": "The relation classification task assigns the proper semantic relation to a\npair of subject and object entities; the task plays a crucial role in various\ntext mining applications, such as knowledge graph construction and entities\ninteraction discovery in biomedical text. Current relation classification\nmodels employ additional procedures to identify multiple relations in a single\nsentence. Furthermore, they overlook the imbalanced predictions pattern. The\npattern arises from the presence of a few valid relations that need positive\nlabeling in a relatively large predefined relations set. We propose a multiple\nrelations classification model that tackles these issues through a customized\noutput architecture and by exploiting additional input features. Our findings\nsuggest that handling the imbalanced predictions leads to significant\nimprovements, even on a modest training design. The results demonstrate\nsuperiority performance on benchmark datasets commonly used in relation\nclassification. To the best of our knowledge, this work is the first that\nrecognizes the imbalanced predictions within the relation classification task.",
        "translated": "关系分类任务将合适的语义关系分配给一对主体和客体实体，在生物医学文本中的知识图构建和实体交互发现等多种文本挖掘应用中起着至关重要的作用。目前的关系分类模型采用附加的程序来识别一个句子中的多个关系。此外，他们忽视了不平衡的预测模式。这种模式是由于在一个相对较大的预定义关系集中存在一些需要正标号的有效关系而产生的。我们提出了一个多关系分类模型，通过定制的输出结构和利用额外的输入功能来解决这些问题。我们的研究结果表明，处理不平衡的预测导致显着的改善，即使在一个适度的训练设计。实验结果表明，该算法对于关系分类中常用的基准数据集具有优越性能。据我们所知，这项工作是第一次认识到不平衡的预测内的关系分类任务。"
    },
    {
        "title": "DeepSpeed-VisualChat: Multi-Round Multi-Image Interleave Chat via\n  Multi-Modal Causal Attention",
        "url": "http://arxiv.org/abs/2309.14327v1",
        "pub_date": "2023-09-25",
        "summary": "Most of the existing multi-modal models, hindered by their incapacity to\nadeptly manage interleaved image-and-text inputs in multi-image, multi-round\ndialogues, face substantial constraints in resource allocation for training and\ndata accessibility, impacting their adaptability and scalability across varied\ninteraction realms. To address this, we present the DeepSpeed-VisualChat\nframework, designed to optimize Large Language Models (LLMs) by incorporating\nmulti-modal capabilities, with a focus on enhancing the proficiency of Large\nVision and Language Models in handling interleaved inputs. Our framework is\nnotable for (1) its open-source support for multi-round and multi-image\ndialogues, (2) introducing an innovative multi-modal causal attention\nmechanism, and (3) utilizing data blending techniques on existing datasets to\nassure seamless interactions in multi-round, multi-image conversations.\nCompared to existing frameworks, DeepSpeed-VisualChat shows superior\nscalability up to 70B parameter language model size, representing a significant\nadvancement in multi-modal language models and setting a solid foundation for\nfuture explorations.",
        "translated": "大多数现有的多模式模型，由于无法在多图像、多轮对话中妥善管理交错的图像和文本输入，在培训和数据访问的资源分配方面面临严重限制，影响了它们在不同交互领域的适应性和可伸缩性。为了解决这个问题，我们提出了 DeepSpeed-VisualChat 框架，该框架旨在通过整合多模态功能来优化大型语言模型(LLM) ，重点是提高大型视觉和语言模型在处理交叉输入方面的熟练程度。我们的框架值得注意的是(1)它对多轮和多图像对话的开源支持，(2)引入创新的多模态因果注意机制，以及(3)利用现有数据集上的数据混合技术，以确保在多轮、多图像对话中的无缝交互。与现有框架相比，DeepSpeed-VisualChat 显示出高达70B 参数语言模型大小的可扩展性，代表了多模态语言模型的重大进步，并为未来的探索奠定了坚实的基础。"
    },
    {
        "title": "Towards General-Purpose Text-Instruction-Guided Voice Conversion",
        "url": "http://arxiv.org/abs/2309.14324v1",
        "pub_date": "2023-09-25",
        "summary": "This paper introduces a novel voice conversion (VC) model, guided by text\ninstructions such as \"articulate slowly with a deep tone\" or \"speak in a\ncheerful boyish voice\". Unlike traditional methods that rely on reference\nutterances to determine the attributes of the converted speech, our model adds\nversatility and specificity to voice conversion. The proposed VC model is a\nneural codec language model which processes a sequence of discrete codes,\nresulting in the code sequence of converted speech. It utilizes text\ninstructions as style prompts to modify the prosody and emotional information\nof the given speech. In contrast to previous approaches, which often rely on\nemploying separate encoders like prosody and content encoders to handle\ndifferent aspects of the source speech, our model handles various information\nof speech in an end-to-end manner. Experiments have demonstrated the impressive\ncapabilities of our model in comprehending instructions and delivering\nreasonable results.",
        "translated": "本文介绍了一种新颖的语音转换(VC)模型，该模型以“用深沉的语调缓慢地表达”或“用欢快的孩子般的声音说话”等文本指令为指导。与传统的依靠参考话语来确定转换后的语音属性的方法不同，我们的模型增加了语音转换的通用性和特异性。本文提出的 VC 模型是一种神经编解码语言模型，它对一系列离散码进行处理，得到转换后的语音码序列。它利用文本指令作为语体提示，修改给定语音的韵律和情感信息。与以前的方法相比，我们的模型通常依赖于使用单独的编码器，如韵律编码器和内容编码器来处理源语音的不同方面，我们的模型以端到端的方式处理各种语音信息。实验表明，我们的模型在理解指令和提供合理的结果方面具有令人印象深刻的能力。"
    },
    {
        "title": "Physics of Language Models: Part 3.1, Knowledge Storage and Extraction",
        "url": "http://arxiv.org/abs/2309.14316v1",
        "pub_date": "2023-09-25",
        "summary": "Large language models can store extensive world knowledge, often extractable\nthrough question-answering (e.g., \"What is Abraham Lincoln's birthday?\").\nHowever, it's unclear whether the model answers questions based on exposure to\nexact/similar questions during training, or if it genuinely extracts knowledge\nfrom the source (e.g., Wikipedia biographies).\n  In this paper, we conduct an in-depth study of this problem using a\ncontrolled set of semi-synthetic biography data. We uncover a relationship\nbetween the model's knowledge extraction ability and different diversity\nmeasures of the training data. We conduct (nearly) linear probing, revealing a\nstrong correlation between this relationship and whether the model (nearly)\nlinearly encodes the knowledge attributes at the hidden embedding of the entity\nnames, or across the embeddings of other tokens in the training text.",
        "translated": "大型语言模型可以存储广泛的世界知识，通常可以通过问答提取(例如，“亚伯拉罕 · 林肯的生日是什么?”).然而，目前还不清楚该模型是否基于在培训期间接触到的确切/类似的问题来回答问题，或者它是否真正从源头(例如，维基百科传记)提取知识。本文利用一组半合成传记数据对这一问题进行了深入的研究。我们揭示了模型的知识提取能力与训练数据的不同多样性度量之间的关系。我们进行了(近似)线性探测，揭示了这种关系与模型(近似)在实体名称的隐藏嵌入或在训练文本中嵌入其他标记时是否对知识属性进行线性编码之间的强相关性。"
    },
    {
        "title": "OmniEvent: A Comprehensive, Fair, and Easy-to-Use Toolkit for Event\n  Understanding",
        "url": "http://arxiv.org/abs/2309.14258v1",
        "pub_date": "2023-09-25",
        "summary": "Event understanding aims at understanding the content and relationship of\nevents within texts, which covers multiple complicated information extraction\ntasks: event detection, event argument extraction, and event relation\nextraction. To facilitate related research and application, we present an event\nunderstanding toolkit OmniEvent, which features three desiderata: (1)\nComprehensive. OmniEvent supports mainstream modeling paradigms of all the\nevent understanding tasks and the processing of 15 widely-used English and\nChinese datasets. (2) Fair. OmniEvent carefully handles the inconspicuous\nevaluation pitfalls reported in Peng et al. (2023), which ensures fair\ncomparisons between different models. (3) Easy-to-use. OmniEvent is designed to\nbe easily used by users with varying needs. We provide off-the-shelf models\nthat can be directly deployed as web services. The modular framework also\nenables users to easily implement and evaluate new event understanding models\nwith OmniEvent. The toolkit (https://github.com/THU-KEG/OmniEvent) is publicly\nreleased along with the demonstration website and video\n(https://omnievent.xlore.cn/).",
        "translated": "事件理解旨在理解文本中事件的内容和关系，包括多种复杂的信息抽取任务: 事件检测、事件参数提取和事件关系提取。为了方便相关的研究和应用，我们提出了一个事件理解工具包 OmniEvent，它有三个特点: (1)综合。OmniEvent 支持所有事件理解任务的主流建模范式，以及对15个广泛使用的中英文数据集的处理。(2)公平。OmniEvent 仔细处理了 Peng 等人(2023)报道的不显眼的评估陷阱，这确保了不同模型之间的公平比较。(3)易于使用。OmniEvent 旨在方便有不同需求的用户使用。我们提供可以直接部署为 Web 服务的现成模型。模块化框架还允许用户使用 OmniEvent 轻松实现和评估新的事件理解模型。该工具包( https://github.com/thu-keg/omnievent )与演示网站和视频( https://omnievent.xlore.cn/)一起公开发布。"
    },
    {
        "title": "Urdu Poetry Generated by Using Deep Learning Techniques",
        "url": "http://arxiv.org/abs/2309.14233v1",
        "pub_date": "2023-09-25",
        "summary": "This study provides Urdu poetry generated using different deep-learning\ntechniques and algorithms. The data was collected through the Rekhta website,\ncontaining 1341 text files with several couplets. The data on poetry was not\nfrom any specific genre or poet. Instead, it was a collection of mixed Urdu\npoems and Ghazals. Different deep learning techniques, such as the model\napplied Long Short-term Memory Networks (LSTM) and Gated Recurrent Unit (GRU),\nhave been used. Natural Language Processing (NLP) may be used in machine\nlearning to understand, analyze, and generate a language humans may use and\nunderstand. Much work has been done on generating poetry for different\nlanguages using different techniques. The collection and use of data were also\ndifferent for different researchers. The primary purpose of this project is to\nprovide a model that generates Urdu poems by using data completely, not by\nsampling data. Also, this may generate poems in pure Urdu, not Roman Urdu, as\nin the base paper. The results have shown good accuracy in the poems generated\nby the model.",
        "translated": "本研究提供了使用不同深度学习技术和算法生成的乌尔都语诗歌。这些数据是通过 Rekhta 网站收集的，其中包含1341个文本文件和几个对联。有关诗歌的资料并非来自任何特定的体裁或诗人。相反，它是一个混合乌尔都语诗歌和加扎尔语的集合。采用了不同的深度学习技术，如应用长短期记忆网络(LSTM)和门限回归单元(GRU)的模型。自然语言处理(NLP)可用于机器学习，以理解、分析和生成人类可以使用和理解的语言。在使用不同的技术为不同的语言创作诗歌方面已经做了很多工作。不同的研究者对数据的收集和使用也有所不同。该项目的主要目的是提供一个完全使用数据而不是采样数据生成乌尔都语诗歌的模型。此外，这可能产生纯乌尔都语诗歌，而不是罗马乌尔都语，在基础文件。结果表明，该模型生成的诗歌具有较好的准确性。"
    },
    {
        "title": "Autonomous Vehicles an overview on system, cyber security, risks,\n  issues, and a way forward",
        "url": "http://arxiv.org/abs/2309.14213v1",
        "pub_date": "2023-09-25",
        "summary": "This chapter explores the complex realm of autonomous cars, analyzing their\nfundamental components and operational characteristics. The initial phase of\nthe discussion is elucidating the internal mechanics of these automobiles,\nencompassing the crucial involvement of sensors, artificial intelligence (AI)\nidentification systems, control mechanisms, and their integration with\ncloud-based servers within the framework of the Internet of Things (IoT). It\ndelves into practical implementations of autonomous cars, emphasizing their\nutilization in forecasting traffic patterns and transforming the dynamics of\ntransportation. The text also explores the topic of Robotic Process Automation\n(RPA), illustrating the impact of autonomous cars on different businesses\nthrough the automation of tasks. The primary focus of this investigation lies\nin the realm of cybersecurity, specifically in the context of autonomous\nvehicles. A comprehensive analysis will be conducted to explore various risk\nmanagement solutions aimed at protecting these vehicles from potential threats\nincluding ethical, environmental, legal, professional, and social dimensions,\noffering a comprehensive perspective on their societal implications. A\nstrategic plan for addressing the challenges and proposing strategies for\neffectively traversing the complex terrain of autonomous car systems,\ncybersecurity, hazards, and other concerns are some resources for acquiring an\nunderstanding of the intricate realm of autonomous cars and their ramifications\nin contemporary society, supported by a comprehensive compilation of resources\nfor additional investigation.\n  Keywords: RPA, Cyber Security, AV, Risk, Smart Cars",
        "translated": "本章探讨了自动驾驶汽车的复杂领域，分析了自动驾驶汽车的基本组成和运行特点。讨论的最初阶段是阐明这些汽车的内部机制，包括传感器、人工智能(AI)识别系统、控制机制的关键参与，以及它们在物联网(IoT)框架内与基于云的服务器的集成。研究了自动驾驶汽车的实际应用，强调了自动驾驶汽车在交通模式预测和交通动力学转换中的应用。本文还探讨了机器人过程自动化(RPA)的主题，说明了自动驾驶汽车通过任务自动化对不同业务的影响。本次调查的主要重点在于网络安全领域，特别是在自动驾驶汽车的情况下。将进行全面的分析，以探讨各种风险管理解决方案，旨在保护这些车辆的潜在威胁，包括道德，环境，法律，专业和社会层面，提供了一个全面的视角，对其社会影响。一项应对挑战并提出有效穿越自动驾驶汽车系统、网络安全、危险和其他关切的复杂地形的战略计划是一些资源，用于了解自动驾驶汽车的复杂领域及其在当代社会中的影响，辅之以用于进一步调查的综合资源汇编。关键词: RPA，Cyber Security，AV，Risk，Smart Cars"
    },
    {
        "title": "Only 5\\% Attention Is All You Need: Efficient Long-range Document-level\n  Neural Machine Translation",
        "url": "http://arxiv.org/abs/2309.14174v1",
        "pub_date": "2023-09-25",
        "summary": "Document-level Neural Machine Translation (DocNMT) has been proven crucial\nfor handling discourse phenomena by introducing document-level context\ninformation. One of the most important directions is to input the whole\ndocument directly to the standard Transformer model. In this case, efficiency\nbecomes a critical concern due to the quadratic complexity of the attention\nmodule. Existing studies either focus on the encoder part, which cannot be\ndeployed on sequence-to-sequence generation tasks, e.g., Machine Translation\n(MT), or suffer from a significant performance drop. In this work, we keep the\ntranslation performance while gaining 20\\% speed up by introducing extra\nselection layer based on lightweight attention that selects a small portion of\ntokens to be attended. It takes advantage of the original attention to ensure\nperformance and dimension reduction to accelerate inference. Experimental\nresults show that our method could achieve up to 95\\% sparsity (only 5\\% tokens\nattended) approximately, and save 93\\% computation cost on the attention module\ncompared with the original Transformer, while maintaining the performance.",
        "translated": "文档层次的神经机器翻译(DocNMT)通过引入文档层次的上下文信息来处理语篇现象已被证明是至关重要的。其中一个最重要的方向是将整个文档直接输入到标准的 Transformer 模型中。在这种情况下，效率成为一个关键的问题，由于二次复杂性的注意模块。现有的研究要么集中在编码器部分，这不能部署在序列到序列的生成任务，如机器翻译(机器翻译) ，或遭受显着的性能下降。在这项工作中，我们在保持翻译性能的同时，通过引入基于轻量级注意力的额外选择层来选择一小部分要参与的令牌，提高了20% 的翻译速度。它利用最初的注意力来确保性能和维度减化，从而加速推理。实验结果表明，该方法在保持原变压器性能的同时，注意模块的稀疏度可达95% 左右(注意模块只有5% 的注意模块) ，节省了93% 的计算开销。"
    },
    {
        "title": "Towards End-User Development for IoT: A Case Study on Semantic Parsing\n  of Cooking Recipes for Programming Kitchen Devices",
        "url": "http://arxiv.org/abs/2309.14165v1",
        "pub_date": "2023-09-25",
        "summary": "Semantic parsing of user-generated instructional text, in the way of enabling\nend-users to program the Internet of Things (IoT), is an underexplored area. In\nthis study, we provide a unique annotated corpus which aims to support the\ntransformation of cooking recipe instructions to machine-understandable\ncommands for IoT devices in the kitchen. Each of these commands is a tuple\ncapturing the semantics of an instruction involving a kitchen device in terms\nof \"What\", \"Where\", \"Why\" and \"How\". Based on this corpus, we developed machine\nlearning-based sequence labelling methods, namely conditional random fields\n(CRF) and a neural network model, in order to parse recipe instructions and\nextract our tuples of interest from them. Our results show that while it is\nfeasible to train semantic parsers based on our annotations, most\nnatural-language instructions are incomplete, and thus transforming them into\nformal meaning representation, is not straightforward.",
        "translated": "对用户生成的教学文本进行语义分析，使最终用户能够编写物联网(IoT)程序，是一个尚未开发的领域。在这项研究中，我们提供了一个独特的注释语料库，旨在支持厨房物联网设备中的烹饪配方指令向机器可理解命令的转换。这些命令中的每一个都是一个元组，它捕获涉及厨房设备的指令的语义，包括“什么”、“在哪里”、“为什么”和“如何”。在此基础上，我们开发了基于机器学习的序列标记方法，即条件随机场(CRF)和神经网络模型，以解析配方指令并从中提取出我们感兴趣的元组。我们的研究结果表明，虽然基于注释训练语义分析器是可行的，但大多数自然语言指令是不完整的，因此将它们转化为形式意义表示并不简单。"
    },
    {
        "title": "Examining Temporal Bias in Abusive Language Detection",
        "url": "http://arxiv.org/abs/2309.14146v1",
        "pub_date": "2023-09-25",
        "summary": "The use of abusive language online has become an increasingly pervasive\nproblem that damages both individuals and society, with effects ranging from\npsychological harm right through to escalation to real-life violence and even\ndeath. Machine learning models have been developed to automatically detect\nabusive language, but these models can suffer from temporal bias, the\nphenomenon in which topics, language use or social norms change over time. This\nstudy aims to investigate the nature and impact of temporal bias in abusive\nlanguage detection across various languages and explore mitigation methods. We\nevaluate the performance of models on abusive data sets from different time\nperiods. Our results demonstrate that temporal bias is a significant challenge\nfor abusive language detection, with models trained on historical data showing\na significant drop in performance over time. We also present an extensive\nlinguistic analysis of these abusive data sets from a diachronic perspective,\naiming to explore the reasons for language evolution and performance decline.\nThis study sheds light on the pervasive issue of temporal bias in abusive\nlanguage detection across languages, offering crucial insights into language\nevolution and temporal bias mitigation.",
        "translated": "在网上使用辱骂性语言已成为一个日益普遍的问题，对个人和社会造成损害，其影响范围从心理伤害直至升级到现实生活中的暴力甚至死亡。机器学习模型已经被开发出来用于自动检测辱骂性语言，但是这些模型可能会受到时间偏差的影响，即话题、语言使用或社会规范随着时间的推移而改变的现象。本研究旨在探讨时间偏差在不同语言中的性质和影响，并探讨缓解方法。我们从不同的时间段评估滥用数据集模型的性能。我们的研究结果表明，时间偏差是一个重大的挑战，滥用语言的检测，与历史数据训练的模型显示，随着时间的推移显着下降的性能。我们还从历时的角度对这些滥用数据集进行了广泛的语言学分析，旨在探讨语言进化和语言表现下降的原因。本研究揭示了跨语言时间偏差检测中的普遍问题，为语言演化和时间偏差缓解提供了重要的见解。"
    },
    {
        "title": "On the Relation between Internal Language Model and Sequence\n  Discriminative Training for Neural Transducers",
        "url": "http://arxiv.org/abs/2309.14130v1",
        "pub_date": "2023-09-25",
        "summary": "Internal language model (ILM) subtraction has been widely applied to improve\nthe performance of the RNN-Transducer with external language model (LM) fusion\nfor speech recognition. In this work, we show that sequence discriminative\ntraining has a strong correlation with ILM subtraction from both theoretical\nand empirical points of view. Theoretically, we derive that the global optimum\nof maximum mutual information (MMI) training shares a similar formula as ILM\nsubtraction. Empirically, we show that ILM subtraction and sequence\ndiscriminative training achieve similar performance across a wide range of\nexperiments on Librispeech, including both MMI and minimum Bayes risk (MBR)\ncriteria, as well as neural transducers and LMs of both full and limited\ncontext. The benefit of ILM subtraction also becomes much smaller after\nsequence discriminative training. We also provide an in-depth study to show\nthat sequence discriminative training has a minimal effect on the commonly used\nzero-encoder ILM estimation, but a joint effect on both encoder and prediction\n+ joint network for posterior probability reshaping including both ILM and\nblank suppression.",
        "translated": "内部语言模型(ILM)减法已被广泛应用于语音识别中，以提高外部语言模型(LM)融合的 RNN 传感器的性能。本文从理论和实证的角度证明了序列判别训练与 ILM 减法有很强的相关性。从理论上推导出最大互信息(MMI)训练的全局最优解与 ILM 减法具有相似的公式。根据经验，我们发现 ILM 减法和序列鉴别训练在 Librispeech 的一系列实验中取得了相似的效果，包括 MMI 和最小贝叶斯风险(MBR)标准，以及完整和有限背景下的神经传感器和线性模型。经过序列判别训练后，ILM 减法的效益也变得很小。我们还提供了一个深入的研究，表明序列判别训练对常用的零编码器 ILM 估计的影响最小，但对编码器和预测 + 联合网络的后验概率重塑包括 ILM 和空白抑制的联合影响。"
    },
    {
        "title": "RankVicuna: Zero-Shot Listwise Document Reranking with Open-Source Large\n  Language Models",
        "url": "http://arxiv.org/abs/2309.15088v1",
        "pub_date": "2023-09-26",
        "summary": "Researchers have successfully applied large language models (LLMs) such as\nChatGPT to reranking in an information retrieval context, but to date, such\nwork has mostly been built on proprietary models hidden behind opaque API\nendpoints. This approach yields experimental results that are not reproducible\nand non-deterministic, threatening the veracity of outcomes that build on such\nshaky foundations. To address this significant shortcoming, we present\nRankVicuna, the first fully open-source LLM capable of performing high-quality\nlistwise reranking in a zero-shot setting. Experimental results on the TREC\n2019 and 2020 Deep Learning Tracks show that we can achieve effectiveness\ncomparable to zero-shot reranking with GPT-3.5 with a much smaller 7B parameter\nmodel, although our effectiveness remains slightly behind reranking with GPT-4.\nWe hope our work provides the foundation for future research on reranking with\nmodern LLMs. All the code necessary to reproduce our results is available at\nhttps://github.com/castorini/rank_llm.",
        "translated": "研究人员已经成功地应用了大型语言模型(LLM) ，比如 ChatgPT，来在信息检索上下文中重新排序，但迄今为止，这些工作大多建立在隐藏在不透明 API 端点之后的专有模型上。这种方法产生的实验结果是不可重复和不确定的，威胁到建立在如此不稳定基础上的结果的准确性。为了解决这一重大缺陷，我们提出了 RankVicuna，第一个完全开源的 LLM 能够执行高质量的列表重新排序在一个零拍设置。TREC 2019年和2020年深度学习跟踪的实验结果表明，我们可以实现与 GPT-3.5的零击重新排名相当的有效性，但是7B 参数模型要小得多，尽管我们的有效性略微落后于 GPT-4的重新排名。我们希望我们的工作能够为今后利用现代 LLM 重新排序的研究提供基础。复制我们的结果所需的所有代码都可以在 https://github.com/castorini/rank_llm 上找到。"
    },
    {
        "title": "The Role of Document Embedding in Research Paper Recommender Systems: To\n  Breakdown or to Bolster Disciplinary Borders?",
        "url": "http://arxiv.org/abs/2309.14984v1",
        "pub_date": "2023-09-26",
        "summary": "In the extensive recommender systems literature, novelty and diversity have\nbeen identified as key properties of useful recommendations. However, these\nproperties have received limited attention in the specific sub-field of\nresearch paper recommender systems. In this work, we argue for the importance\nof offering novel and diverse research paper recommendations to scientists.\nThis approach aims to reduce siloed reading, break down filter bubbles, and\npromote interdisciplinary research. We propose a novel framework for evaluating\nthe novelty and diversity of research paper recommendations that leverages\nmethods from network analysis and natural language processing. Using this\nframework, we show that the choice of representational method within a larger\nresearch paper recommendation system can have a measurable impact on the nature\nof downstream recommendations, specifically on their novelty and diversity. We\nintroduce a novel paper embedding method, which we demonstrate offers more\ninnovative and diverse recommendations without sacrificing precision, compared\nto other state-of-the-art baselines.",
        "translated": "在广泛的推荐系统文献中，新颖性和多样性已被确定为有用推荐的关键属性。然而，这些特性在研究论文推荐系统的具体分支领域受到了有限的关注。在这项工作中，我们论证了向科学家提供新颖和多样化的研究论文建议的重要性。这种方法的目的是减少竖井读数，打破过滤气泡，并促进科际整合。我们提出了一个新的框架来评估新颖性和多样性的研究论文建议，利用网络分析和自然语言处理的方法。使用这个框架，我们表明在一个更大的研究论文推荐系统中选择代表性方法可以对下游推荐的性质产生可测量的影响，特别是对它们的新颖性和多样性。我们介绍了一种新的论文嵌入方法，我们证明提供了更多的创新和不同的建议，而不牺牲精度，相比其他国家的最先进的基线。"
    },
    {
        "title": "Modeling Multi-aspect Preferences and Intents for Multi-behavioral\n  Sequential Recommendation",
        "url": "http://arxiv.org/abs/2309.14938v1",
        "pub_date": "2023-09-26",
        "summary": "Multi-behavioral sequential recommendation has recently attracted increasing\nattention. However, existing methods suffer from two major limitations.\nFirstly, user preferences and intents can be described in fine-grained detail\nfrom multiple perspectives; yet, these methods fail to capture their\nmulti-aspect nature. Secondly, user behaviors may contain noises, and most\nexisting methods could not effectively deal with noises. In this paper, we\npresent an attentive recurrent model with multiple projections to capture\nMulti-Aspect preferences and INTents (MAINT in short). To extract multi-aspect\npreferences from target behaviors, we propose a multi-aspect projection\nmechanism for generating multiple preference representations from multiple\naspects. To extract multi-aspect intents from multi-typed behaviors, we propose\na behavior-enhanced LSTM and a multi-aspect refinement attention mechanism. The\nattention mechanism can filter out noises and generate multiple intent\nrepresentations from different aspects. To adaptively fuse user preferences and\nintents, we propose a multi-aspect gated fusion mechanism. Extensive\nexperiments conducted on real-world datasets have demonstrated the\neffectiveness of our model.",
        "translated": "多行为序贯推荐近年来受到越来越多的关注。然而，现有的方法存在两个主要的局限性。首先，可以从多个角度细致地描述用户偏好和意图; 然而，这些方法无法捕捉到它们的多方面特性。其次，用户行为可能含有噪声，现有的方法大多不能有效地处理噪声。在本文中，我们提出了一个具有多个投影的注意递归模型来捕获多方面的偏好和意图(MAINT)。为了从目标行为中提取多方面偏好，提出了一种多方面投影机制，用于从多方面生成多方面偏好表示。为了从多类型行为中提取多方面意图，我们提出了一种行为增强的 LSTM 和一种多方面细化注意机制。注意机制可以滤除噪声，从不同方面产生多个意图表示。为了自适应地融合用户偏好和意图，我们提出了一种多方面门控融合机制。在真实世界数据集上进行的大量实验已经证明了我们模型的有效性。"
    },
    {
        "title": "REFORM: Removing False Correlation in Multi-level Interaction for CTR\n  Prediction",
        "url": "http://arxiv.org/abs/2309.14891v1",
        "pub_date": "2023-09-26",
        "summary": "Click-through rate (CTR) prediction is a critical task in online advertising\nand recommendation systems, as accurate predictions are essential for user\ntargeting and personalized recommendations. Most recent cutting-edge methods\nprimarily focus on investigating complex implicit and explicit feature\ninteractions. However, these methods neglect the issue of false correlations\ncaused by confounding factors or selection bias. This problem is further\nmagnified by the complexity and redundancy of these interactions. We propose a\nCTR prediction framework that removes false correlation in multi-level feature\ninteraction, termed REFORM. The proposed REFORM framework exploits a wide range\nof multi-level high-order feature representations via a two-stream stacked\nrecurrent structure while eliminating false correlations. The framework has two\nkey components: I. The multi-level stacked recurrent (MSR) structure enables\nthe model to efficiently capture diverse nonlinear interactions from feature\nspaces of different levels, and the richer representations lead to enhanced CTR\nprediction accuracy. II. The false correlation elimination (FCE) module further\nleverages Laplacian kernel mapping and sample reweighting methods to eliminate\nfalse correlations concealed within the multi-level features, allowing the\nmodel to focus on the true causal effects. Extensive experiments based on four\nchallenging CTR datasets and our production dataset demonstrate that the\nproposed REFORM model achieves state-of-the-art performance. Codes, models and\nour dataset will be released at https://github.com/yansuoyuli/REFORM.",
        "translated": "点进率预测是在线广告和推荐系统中的一项关键任务，因为精确的预测对于用户定位和个性化推荐至关重要。最近的尖端方法主要集中在研究复杂的隐式和显式的特征交互作用。然而，这些方法忽略了由混杂因素或选择偏差引起的错误相关问题。这些交互的复杂性和冗余性进一步放大了这个问题。我们提出了一个 CTR 预测框架，消除了多层次特征交互中的虚假相关性，称为 REFORM。提出的 REFORM 框架在消除虚假相关性的同时，通过双流叠加的递归结构利用了广泛的多层次高阶特征表示。该框架有两个关键组件: I。多级叠加递归(MSR)结构使模型能够有效地从不同级别的特征空间中捕获不同的非线性相互作用，更丰富的表示能够提高 CTR 预测的准确性。二。虚假相关消除(FCE)模块进一步利用拉普拉斯核映射和样本重新加权方法消除隐藏在多级特征中的虚假相关性，使模型能够关注真实的因果效应。基于四个具有挑战性的 CTR 数据集和我们的生产数据集的大量实验表明，所提出的 REFORM 模型实现了最先进的性能。代码，模型和我们的数据集将在 https://github.com/yansuoyuli/reform 发布。"
    },
    {
        "title": "ALEX: Towards Effective Graph Transfer Learning with Noisy Labels",
        "url": "http://arxiv.org/abs/2309.14673v1",
        "pub_date": "2023-09-26",
        "summary": "Graph Neural Networks (GNNs) have garnered considerable interest due to their\nexceptional performance in a wide range of graph machine learning tasks.\nNevertheless, the majority of GNN-based approaches have been examined using\nwell-annotated benchmark datasets, leading to suboptimal performance in\nreal-world graph learning scenarios. To bridge this gap, the present paper\ninvestigates the problem of graph transfer learning in the presence of label\nnoise, which transfers knowledge from a noisy source graph to an unlabeled\ntarget graph. We introduce a novel technique termed Balance Alignment and\nInformation-aware Examination (ALEX) to address this challenge. ALEX first\nemploys singular value decomposition to generate different views with crucial\nstructural semantics, which help provide robust node representations using\ngraph contrastive learning. To mitigate both label shift and domain shift, we\nestimate a prior distribution to build subgraphs with balanced label\ndistributions. Building on this foundation, an adversarial domain discriminator\nis incorporated for the implicit domain alignment of complex multi-modal\ndistributions. Furthermore, we project node representations into a different\nspace, optimizing the mutual information between the projected features and\nlabels. Subsequently, the inconsistency of similarity structures is evaluated\nto identify noisy samples with potential overfitting. Comprehensive experiments\non various benchmark datasets substantiate the outstanding superiority of the\nproposed ALEX in different settings.",
        "translated": "图形神经网络(GNN)因其在各种图形机器学习任务中的出色表现而引起了人们的极大兴趣。然而，大多数基于 GNN 的方法已经使用注释良好的基准数据集进行了检验，导致在真实世界的图形学习场景中性能不理想。为了弥补这一差距，本文研究了在标签噪声存在的情况下图的传递学习问题，即将知识从一个有噪声的源图传递到一个未标记的目标图。我们介绍了一种新的技术称为平衡校准和信息感知检查(ALEX) ，以解决这一挑战。ALex 首先使用奇异值分解生成具有关键结构语义的不同视图，这有助于利用图形对比学习提供鲁棒的节点表示。为了减轻标签移位和域移位，我们估计先验分布来构建具有平衡标签分布的子图。在此基础上，提出了一种用于复杂多模态分布的隐式区域比对的对抗性区域鉴别器。此外，我们将节点表示投射到一个不同的空间，优化了投射特征和标签之间的相互信息。然后，对相似结构的不一致性进行评估，以识别具有潜在过拟合的噪声样本。对各种基准数据集的综合实验证实了 ALEX 在不同设置下的显著优越性。"
    },
    {
        "title": "Attention Satisfies: A Constraint-Satisfaction Lens on Factual Errors of\n  Language Models",
        "url": "http://arxiv.org/abs/2309.15098v1",
        "pub_date": "2023-09-26",
        "summary": "We investigate the internal behavior of Transformer-based Large Language\nModels (LLMs) when they generate factually incorrect text. We propose modeling\nfactual queries as Constraint Satisfaction Problems and use this framework to\ninvestigate how the model interacts internally with factual constraints.\nSpecifically, we discover a strong positive relation between the model's\nattention to constraint tokens and the factual accuracy of its responses. In\nour curated suite of 11 datasets with over 40,000 prompts, we study the task of\npredicting factual errors with the Llama-2 family across all scales (7B, 13B,\n70B). We propose SAT Probe, a method probing self-attention patterns, that can\npredict constraint satisfaction and factual errors, and allows early error\nidentification. The approach and findings demonstrate how using the mechanistic\nunderstanding of factuality in LLMs can enhance reliability.",
        "translated": "我们研究了基于变压器的大型语言模型(LLM)在生成事实上不正确的文本时的内部行为。我们建议将事实查询建模为约束补偿问题，并使用这个框架来研究模型内部如何与事实约束相互作用。具体而言，我们发现模型对约束标记的注意与其响应的事实准确性之间存在强烈的正相关关系。在我们策划的包含超过40,000个提示的11个数据集的套件中，我们研究了预测所有尺度(7B，13B，70B)的骆驼 -2家族的事实错误的任务。我们提出了“ SAT 探测器”，一种探测自我注意模式的方法，它可以预测约束补偿和事实错误，并允许早期识别错误。该方法和研究结果表明，在 LLM 中使用对事实的机械理解可以提高可靠性。"
    },
    {
        "title": "VideoDirectorGPT: Consistent Multi-scene Video Generation via LLM-Guided\n  Planning",
        "url": "http://arxiv.org/abs/2309.15091v1",
        "pub_date": "2023-09-26",
        "summary": "Although recent text-to-video (T2V) generation methods have seen significant\nadvancements, most of these works focus on producing short video clips of a\nsingle event with a single background (i.e., single-scene videos). Meanwhile,\nrecent large language models (LLMs) have demonstrated their capability in\ngenerating layouts and programs to control downstream visual modules such as\nimage generation models. This raises an important question: can we leverage the\nknowledge embedded in these LLMs for temporally consistent long video\ngeneration? In this paper, we propose VideoDirectorGPT, a novel framework for\nconsistent multi-scene video generation that uses the knowledge of LLMs for\nvideo content planning and grounded video generation. Specifically, given a\nsingle text prompt, we first ask our video planner LLM (GPT-4) to expand it\ninto a 'video plan', which involves generating the scene descriptions, the\nentities with their respective layouts, the background for each scene, and\nconsistency groupings of the entities and backgrounds. Next, guided by this\noutput from the video planner, our video generator, Layout2Vid, has explicit\ncontrol over spatial layouts and can maintain temporal consistency of\nentities/backgrounds across scenes, while only trained with image-level\nannotations. Our experiments demonstrate that VideoDirectorGPT framework\nsubstantially improves layout and movement control in both single- and\nmulti-scene video generation and can generate multi-scene videos with visual\nconsistency across scenes, while achieving competitive performance with SOTAs\nin open-domain single-scene T2V generation. We also demonstrate that our\nframework can dynamically control the strength for layout guidance and can also\ngenerate videos with user-provided images. We hope our framework can inspire\nfuture work on better integrating the planning ability of LLMs into consistent\nlong video generation.",
        "translated": "虽然最近的文本到视频(T2V)生成方法已经取得了显著的进步，但是这些工作大多集中在生成单一背景(即单一场景视频)的单个事件的短视频剪辑。与此同时，最近的大型语言模型(LLM)已经展示了它们生成布局和程序的能力，以控制下游的可视化模块，如图像生成模型。这就提出了一个重要的问题: 我们能否利用这些 LLM 中嵌入的知识进行时间上一致的长视频生成？本文提出了一种基于视频内容规划和接地视频生成的一致性多场景视频生成框架 VideoDirectorGPT。具体来说，给定一个单一的文本提示，我们首先要求我们的视频规划 LLM (GPT-4)将其扩展为一个“视频规划”，其中包括生成场景描述，实体及其各自的布局，每个场景的背景，以及实体和背景的一致性分组。接下来，在视频规划器输出的指导下，我们的视频生成器 Layout2Vid 具有对空间布局的明确控制，并且可以保持场景中实体/背景的时间一致性，同时只用图像级注释进行训练。我们的实验表明，VideoDirectorGPT 框架在单场景和多场景视频生成中大大改善了布局和运动控制，可以生成视觉一致性跨场景的多场景视频，同时在开放域单场景 T2V 生成中实现了与 SOTA 的竞争性能。我们还演示了我们的框架可以动态控制布局指导的强度，并且还可以使用用户提供的图像生成视频。我们希望我们的框架能够启发未来的工作，更好地将 LLM 的规划能力集成到一致的长视频生成中。"
    },
    {
        "title": "Making PPO even better: Value-Guided Monte-Carlo Tree Search decoding",
        "url": "http://arxiv.org/abs/2309.15028v1",
        "pub_date": "2023-09-26",
        "summary": "Inference-time search algorithms such as Monte-Carlo Tree Search (MCTS) may\nseem unnecessary when generating natural language text based on\nstate-of-the-art reinforcement learning such as Proximal Policy Optimization\n(PPO). In this paper, we demonstrate that it is possible to get extra mileage\nout of PPO by integrating MCTS on top. The key idea is not to throw out the\nvalue network, a byproduct of PPO training for evaluating partial output\nsequences, when decoding text out of the policy network. More concretely, we\npresent a novel value-guided decoding algorithm called PPO-MCTS, which can\nintegrate the value network from PPO to work closely with the policy network\nduring inference-time generation. Compared to prior approaches based on MCTS\nfor controlled text generation, the key strength of our approach is to reduce\nthe fundamental mismatch of the scoring mechanisms of the partial outputs\nbetween training and test. Evaluation on four text generation tasks demonstrate\nthat PPO-MCTS greatly improves the preferability of generated text compared to\nthe standard practice of using only the PPO policy. Our results demonstrate the\npromise of search algorithms even on top of the aligned language models from\nPPO, and the under-explored benefit of the value network.",
        "translated": "推理时间搜索算法，如蒙特卡洛树搜索(MCTS) ，在基于最先进的强化学习(如最近策略优化(PPO))生成自然语言文本时似乎没有必要。在本文中，我们证明了有可能获得额外的里程 PPO 积分 MCTS 顶部。其核心思想是在解码策略网络中的文本时，不要抛弃价值网络，价值网络是用于评估部分输出序列的 PPO 训练的副产品。更具体地说，我们提出了一种新的值引导译码算法 PPO-MCTS，该算法能够在推理时间生成过程中将 PPO 中的值网络与策略网络紧密结合起来。与已有的基于 MCTS 的受控文本生成方法相比，该方法的主要优点是减少了训练和测试之间部分输出评分机制的基本不匹配。对四个文本生成任务的评估表明，与仅使用 PPO 策略的标准实践相比，PPO-MCTS 大大提高了生成文本的偏好性。我们的研究结果显示了搜索算法的前景，甚至从 PPO 的对齐语言模型之上，以及价值网络的未充分开发的好处。"
    },
    {
        "title": "Large Language Model Alignment: A Survey",
        "url": "http://arxiv.org/abs/2309.15025v1",
        "pub_date": "2023-09-26",
        "summary": "Recent years have witnessed remarkable progress made in large language models\n(LLMs). Such advancements, while garnering significant attention, have\nconcurrently elicited various concerns. The potential of these models is\nundeniably vast; however, they may yield texts that are imprecise, misleading,\nor even detrimental. Consequently, it becomes paramount to employ alignment\ntechniques to ensure these models to exhibit behaviors consistent with human\nvalues.\n  This survey endeavors to furnish an extensive exploration of alignment\nmethodologies designed for LLMs, in conjunction with the extant capability\nresearch in this domain. Adopting the lens of AI alignment, we categorize the\nprevailing methods and emergent proposals for the alignment of LLMs into outer\nand inner alignment. We also probe into salient issues including the models'\ninterpretability, and potential vulnerabilities to adversarial attacks. To\nassess LLM alignment, we present a wide variety of benchmarks and evaluation\nmethodologies. After discussing the state of alignment research for LLMs, we\nfinally cast a vision toward the future, contemplating the promising avenues of\nresearch that lie ahead.\n  Our aspiration for this survey extends beyond merely spurring research\ninterests in this realm. We also envision bridging the gap between the AI\nalignment research community and the researchers engrossed in the capability\nexploration of LLMs for both capable and safe LLMs.",
        "translated": "近年来，大型语言模型(LLM)取得了显著的进展。这些进展虽然引起了广泛的关注，但同时也引发了各种担忧。不可否认，这些模型的潜力是巨大的; 然而，它们可能产生不精确、误导甚至有害的文本。因此，使用校准技术来确保这些模型表现出与人类价值观一致的行为变得至关重要。这项调查致力于提供一个广泛的探索对准方法设计的 LLM，结合现有的能力研究在这个领域。本文采用人工智能对准的视角，将有限元对准的主要方法和应急方案分为外对准和内对准两类。我们还探讨了一些突出的问题，包括模型的可解释性，以及对抗性攻击的潜在弱点。为了评估 LLM 的一致性，我们提出了各种各样的基准和评估方法。在讨论了 LLM 的校准研究状态之后，我们最终展望了未来，思考了前方研究的有希望的途径。我们对这项调查的期望不仅仅是激发这个领域的研究兴趣。我们还设想在人工智能校准研究社区和全神贯注于 LLM 能力探索的研究人员之间架起一座桥梁，以实现能力和安全的 LLM。"
    },
    {
        "title": "Question-Answering Approach to Evaluate Legal Summaries",
        "url": "http://arxiv.org/abs/2309.15016v1",
        "pub_date": "2023-09-26",
        "summary": "Traditional evaluation metrics like ROUGE compare lexical overlap between the\nreference and generated summaries without taking argumentative structure into\naccount, which is important for legal summaries. In this paper, we propose a\nnovel legal summarization evaluation framework that utilizes GPT-4 to generate\na set of question-answer pairs that cover main points and information in the\nreference summary. GPT-4 is then used to generate answers based on the\ngenerated summary for the questions from the reference summary. Finally, GPT-4\ngrades the answers from the reference summary and the generated summary. We\nexamined the correlation between GPT-4 grading with human grading. The results\nsuggest that this question-answering approach with GPT-4 can be a useful tool\nfor gauging the quality of the summary.",
        "translated": "像 ROUGE 这样的传统评价指标比较了参考文献和生成的摘要之间的词汇重叠，而没有考虑论证结构，这对法律摘要很重要。在本文中，我们提出了一个新的法律摘要评价框架，它利用 GPT-4生成一组问答对，覆盖参考文献摘要中的要点和信息。然后使用 GPT-4根据参考摘要中生成的问题摘要生成答案。最后，GPT-4根据参考摘要和生成的摘要对答案进行评分。我们研究了 GPT-4分级与人类分级之间的相关性。结果表明，GPT-4的问答方法可以作为一个有用的工具来衡量总结的质量。"
    },
    {
        "title": "Updated Corpora and Benchmarks for Long-Form Speech Recognition",
        "url": "http://arxiv.org/abs/2309.15013v1",
        "pub_date": "2023-09-26",
        "summary": "The vast majority of ASR research uses corpora in which both the training and\ntest data have been pre-segmented into utterances. In most real-word ASR\nuse-cases, however, test audio is not segmented, leading to a mismatch between\ninference-time conditions and models trained on segmented utterances. In this\npaper, we re-release three standard ASR corpora - TED-LIUM 3, Gigapeech, and\nVoxPopuli-en - with updated transcription and alignments to enable their use\nfor long-form ASR research. We use these reconstituted corpora to study the\ntrain-test mismatch problem for transducers and attention-based\nencoder-decoders (AEDs), confirming that AEDs are more susceptible to this\nissue. Finally, we benchmark a simple long-form training for these models,\nshowing its efficacy for model robustness under this domain shift.",
        "translated": "绝大多数 ASR 研究使用语料库，其中训练数据和测试数据都被预先分割成话语。然而，在大多数实际的 ASR 用例中，测试音频没有分段，导致推理时间条件和分段话语训练模型之间的不匹配。在本文中，我们重新发布了三个标准的 ASR cora-TED-LIUM 3，Gigapeech 和 VoxPopuli-en，并更新了转录和比对，以使其能够用于长形式的 ASR 研究。我们使用这些重建的语料库来研究传感器和基于注意的编解码器(AEDs)的训练测试失配问题，证实了 AEDs 更容易受到这个问题的影响。最后，我们对这些模型进行了一个简单的长形式训练，显示了它在这种领域转移下对模型鲁棒性的有效性。"
    },
    {
        "title": "Automating question generation from educational text",
        "url": "http://arxiv.org/abs/2309.15004v1",
        "pub_date": "2023-09-26",
        "summary": "The use of question-based activities (QBAs) is wide-spread in education,\ntraditionally forming an integral part of the learning and assessment process.\nIn this paper, we design and evaluate an automated question generation tool for\nformative and summative assessment in schools. We present an expert survey of\none hundred and four teachers, demonstrating the need for automated generation\nof QBAs, as a tool that can significantly reduce the workload of teachers and\nfacilitate personalized learning experiences. Leveraging the recent\nadvancements in generative AI, we then present a modular framework employing\ntransformer based language models for automatic generation of multiple-choice\nquestions (MCQs) from textual content. The presented solution, with distinct\nmodules for question generation, correct answer prediction, and distractor\nformulation, enables us to evaluate different language models and generation\ntechniques. Finally, we perform an extensive quantitative and qualitative\nevaluation, demonstrating trade-offs in the use of different techniques and\nmodels.",
        "translated": "以问题为基础的活动(QBA)在教育中广泛使用，传统上构成了学习和评估过程的一个组成部分。本文设计并评估了一个用于学校形成性和总结性评估的自动问题生成工具。我们对104名教师进行了专家调查，结果显示，QBA 需要自动生成，这种工具可以显著减少教师的工作量，促进个性化的学习体验。利用生成式人工智能的最新进展，我们提出了一个模块化框架，使用基于转换器的语言模型，从文本内容自动生成多项选择题(MCQs)。提出的解决方案，具有独特的模块问题生成，正确的答案预测和干扰公式，使我们能够评估不同的语言模型和生成技术。最后，我们进行了广泛的定量和定性评估，展示了在使用不同的技术和模型方面的权衡。"
    },
    {
        "title": "Interactively Learning Social Media Representations Improves News Source\n  Factuality Detection",
        "url": "http://arxiv.org/abs/2309.14966v1",
        "pub_date": "2023-09-26",
        "summary": "The rise of social media has enabled the widespread propagation of fake news,\ntext that is published with an intent to spread misinformation and sway\nbeliefs. Rapidly detecting fake news, especially as new events arise, is\nimportant to prevent misinformation.\n  While prior works have tackled this problem using supervised learning\nsystems, automatedly modeling the complexities of the social media landscape\nthat enables the spread of fake news is challenging. On the contrary, having\nhumans fact check all news is not scalable. Thus, in this paper, we propose to\napproach this problem interactively, where humans can interact to help an\nautomated system learn a better social media representation quality. On real\nworld events, our experiments show performance improvements in detecting\nfactuality of news sources, even after few human interactions.",
        "translated": "社交媒体的兴起使假新闻得以广泛传播，这些假新闻发布的目的是传播错误信息和动摇信仰。迅速发现假新闻，尤其是新事件发生时，对于防止错误信息非常重要。虽然之前的工作已经使用监督式学习系统解决了这个问题，但是自动模拟社交媒体的复杂性使得假新闻的传播成为一种挑战。相反，让人类事实检查所有的新闻是不可扩展的。因此，在本文中，我们建议交互式地处理这个问题，其中人类可以互动，以帮助自动化系统学习更好的社会媒体表示质量。在真实世界的事件中，我们的实验表明，即使在很少的人类互动之后，在检测新闻来源的真实性方面，性能也有所提高。"
    },
    {
        "title": "Robustness of the Random Language Model",
        "url": "http://arxiv.org/abs/2309.14913v1",
        "pub_date": "2023-09-26",
        "summary": "The Random Language Model (De Giuli 2019) is an ensemble of stochastic\ncontext-free grammars, quantifying the syntax of human and computer languages.\nThe model suggests a simple picture of first language learning as a type of\nannealing in the vast space of potential languages. In its simplest\nformulation, it implies a single continuous transition to grammatical syntax,\nat which the symmetry among potential words and categories is spontaneously\nbroken. Here this picture is scrutinized by considering its robustness against\nexplicit symmetry breaking, an inevitable component of learning in the real\nworld. It is shown that the scenario is robust to such symmetry breaking.\nComparison with human data on the clustering coefficient of syntax networks\nsuggests that the observed transition is equivalent to that normally\nexperienced by children at age 24 months.",
        "translated": "随机语言模型(De Giuli 2019)是随机上下文无关语法的集合，量化了人类和计算机语言的语法。该模型提出了一个简单的图片，第一语言学习作为一种退火在广阔的潜在语言空间。在其最简单的表述中，它意味着向语法句法的单一连续过渡，在这个过渡中，潜在词汇和范畴之间的对称性自发地被打破。在这里，我们仔细审视这幅图片，考虑它对抗明显对称性破缺的稳健性，这是现实世界中学习的一个不可避免的组成部分。结果表明，这种情况对这种对称性破缺是稳健的。与人类关于句法网络集聚系数的数据进行比较表明，观察到的转变相当于24个月大的儿童通常经历的转变。"
    },
    {
        "title": "Temporal graph models fail to capture global temporal dynamics",
        "url": "http://arxiv.org/abs/2309.15730v1",
        "pub_date": "2023-09-27",
        "summary": "A recently released Temporal Graph Benchmark is analyzed in the context of\nDynamic Link Property Prediction. We outline our observations and propose a\ntrivial optimization-free baseline of \"recently popular nodes\" outperforming\nother methods on all medium and large-size datasets in the Temporal Graph\nBenchmark. We propose two measures based on Wasserstein distance which can\nquantify the strength of short-term and long-term global dynamics of datasets.\nBy analyzing our unexpectedly strong baseline, we show how standard negative\nsampling evaluation can be unsuitable for datasets with strong temporal\ndynamics. We also show how simple negative-sampling can lead to model\ndegeneration during training, resulting in impossible to rank, fully saturated\npredictions of temporal graph networks. We propose improved negative sampling\nschemes for both training and evaluation and prove their usefulness. We conduct\na comparison with a model trained non-contrastively without negative sampling.\nOur results provide a challenging baseline and indicate that temporal graph\nnetwork architectures need deep rethinking for usage in problems with\nsignificant global dynamics, such as social media, cryptocurrency markets or\ne-commerce. We open-source the code for baselines, measures and proposed\nnegative sampling schemes.",
        "translated": "在动态链接属性预测的背景下，分析了最近发布的时态图基准。我们概述了我们的观察，并提出了一个“最近流行的节点”在时态图基准中的所有中型和大型数据集的表现优于其他方法的无优化基线。我们提出了两种基于 Wasserstein 距离的度量方法，可以量化短期和长期全局动态数据集的强度。通过分析我们意想不到的强基线，我们展示了标准的负抽样评估如何不适合具有强时间动态的数据集。我们还展示了简单的负采样如何在训练过程中导致模型退化，从而导致不可能对时间图网络进行排序和完全饱和的预测。我们提出了改进的负抽样方案用于训练和评估，并证明了它们的有效性。我们进行了一个比较与模型训练非对比没有负面抽样。我们的研究结果提供了一个具有挑战性的基线，并表明时间图网络架构需要深入反思使用的问题与重大的全球动态，如社会媒体，加密货币市场或电子商务。我们开放源码的基线，措施和建议的负面抽样方案的代码。"
    },
    {
        "title": "Cold &amp; Warm Net: Addressing Cold-Start Users in Recommender Systems",
        "url": "http://arxiv.org/abs/2309.15646v1",
        "pub_date": "2023-09-27",
        "summary": "Cold-start recommendation is one of the major challenges faced by recommender\nsystems (RS). Herein, we focus on the user cold-start problem. Recently,\nmethods utilizing side information or meta-learning have been used to model\ncold-start users. However, it is difficult to deploy these methods to\nindustrial RS. There has not been much research that pays attention to the user\ncold-start problem in the matching stage. In this paper, we propose Cold &amp; Warm\nNet based on expert models who are responsible for modeling cold-start and\nwarm-up users respectively. A gate network is applied to incorporate the\nresults from two experts. Furthermore, dynamic knowledge distillation acting as\na teacher selector is introduced to assist experts in better learning user\nrepresentation. With comprehensive mutual information, features highly relevant\nto user behavior are selected for the bias net which explicitly models user\nbehavior bias. Finally, we evaluate our Cold &amp; Warm Net on public datasets in\ncomparison to models commonly applied in the matching stage and it outperforms\nother models on all user types. The proposed model has also been deployed on an\nindustrial short video platform and achieves a significant increase in app\ndwell time and user retention rate.",
        "translated": "冷启动推荐是推荐系统(RS)面临的主要挑战之一。在这里，我们重点讨论用户冷启动问题。最近，利用边缘信息或元学习的方法被用来对冷启动用户进行建模。然而，将这些方法应用到工业 RS 中是困难的。在匹配阶段，关于用户冷启动问题的研究并不多见。本文提出了基于专家模型的冷暖网，分别对冷启动用户和预热用户进行建模。应用一个门网络来合并两位专家的结果。此外，动态知识提取作为教师选择引入，以帮助专家更好地学习用户表示。在综合互信息的基础上，选择与用户行为高度相关的特征作为偏差网络，明确建立用户行为偏差模型。最后，我们在公共数据集上评估了我们的冷暖网，并与匹配阶段常用的模型进行了比较，它在所有用户类型上都优于其他模型。该模型已经部署在一个工业短视频平台上，实现了应用程序停留时间和用户保留率的显著增加。"
    },
    {
        "title": "Identifiability Matters: Revealing the Hidden Recoverable Condition in\n  Unbiased Learning to Rank",
        "url": "http://arxiv.org/abs/2309.15560v1",
        "pub_date": "2023-09-27",
        "summary": "The application of Unbiased Learning to Rank (ULTR) is widespread in modern\nsystems for training unbiased ranking models from biased click logs. The key is\nto explicitly model a generation process for user behavior and fit click data\nbased on examination hypothesis. Previous research found empirically that the\ntrue latent relevance can be recovered in most cases as long as the clicks are\nperfectly fitted. However, we demonstrate that this is not always achievable,\nresulting in a significant reduction in ranking performance. In this work, we\naim to answer if or when the true relevance can be recovered from click data,\nwhich is a foundation issue for ULTR field. We first define a ranking model as\nidentifiable if it can recover the true relevance up to a scaling\ntransformation, which is enough for pairwise ranking objective. Then we explore\nan equivalent condition for identifiability that can be novely expressed as a\ngraph connectivity test problem: if and only if a graph (namely identifiability\ngraph, or IG) constructed on the underlying structure of the dataset is\nconnected, we can guarantee that the relevance can be correctly recovered. When\nthe IG is not connected, there may be bad cases leading to poor ranking\nperformance. To address this issue, we propose two methods, namely node\nintervention and node merging, to modify the dataset and restore connectivity\nof the IG. Empirical results obtained on a simulation dataset and two LTR\nbenchmark datasets confirm the validity of our proposed theorems and show the\neffectiveness of our methods in mitigating data bias when the relevance model\nis unidentifiable.",
        "translated": "无偏学习排序(ULTR)在现代系统中广泛应用，用于训练有偏点击日志中的无偏排序模型。关键在于为用户行为建立明确的生成过程模型，并根据考试假设对点击数据进行拟合。以往的研究经验表明，在大多数情况下，只要点击完全吻合，真正的潜在相关性就可以恢复。然而，我们证明这并不总是可以实现的，导致排名性能的显著下降。在这项工作中，我们的目标是回答是否或何时可以从点击数据中恢复真正的相关性，这是 ULTR 领域的一个基础问题。我们首先定义一个可识别的排序模型，如果它能够恢复真正的相关性直到一个缩放转换，这是足够的成对排序目标。然后我们探索了一个可识别性的等价条件，这个等价条件可以新颖地表示为一个图连通性测试问题: 当且仅当构造在数据集底层结构上的一个图(即可识别性图或 IG)被连通时，我们可以保证相关性可以被正确地恢复。当 IG 没有连接时，可能会出现导致排名表现不佳的糟糕情况。为了解决这个问题，我们提出了两种方法，即节点干预和节点合并，来修改数据集和恢复 IG 的连通性。在一个模拟数据集和两个 LTR 基准数据集上得到的实验结果证实了我们提出的定理的有效性，并且证明了我们的方法在相关模型不可识别时减少数据偏差的有效性。"
    },
    {
        "title": "Automatic Feature Fairness in Recommendation via Adversaries",
        "url": "http://arxiv.org/abs/2309.15418v1",
        "pub_date": "2023-09-27",
        "summary": "Fairness is a widely discussed topic in recommender systems, but its\npractical implementation faces challenges in defining sensitive features while\nmaintaining recommendation accuracy. We propose feature fairness as the\nfoundation to achieve equitable treatment across diverse groups defined by\nvarious feature combinations. This improves overall accuracy through balanced\nfeature generalizability. We introduce unbiased feature learning through\nadversarial training, using adversarial perturbation to enhance feature\nrepresentation. The adversaries improve model generalization for\nunder-represented features. We adapt adversaries automatically based on two\nforms of feature biases: frequency and combination variety of feature values.\nThis allows us to dynamically adjust perturbation strengths and adversarial\ntraining weights. Stronger perturbations are applied to feature values with\nfewer combination varieties to improve generalization, while higher weights for\nlow-frequency features address training imbalances. We leverage the Adaptive\nAdversarial perturbation based on the widely-applied Factorization Machine\n(AAFM) as our backbone model. In experiments, AAFM surpasses strong baselines\nin both fairness and accuracy measures. AAFM excels in providing item- and\nuser-fairness for single- and multi-feature tasks, showcasing their versatility\nand scalability. To maintain good accuracy, we find that adversarial\nperturbation must be well-managed: during training, perturbations should not\noverly persist and their strengths should decay.",
        "translated": "在推荐系统中，公平性是一个广泛讨论的话题，但其实际实现在定义敏感特性的同时保持推荐的准确性方面面临挑战。我们建议将特征公平作为实现不同特征组合定义的不同群体之间公平待遇的基础。这通过均衡的特征泛化提高了整体的准确性。我们通过对抗训练引入无偏特征学习，利用对抗摄动来增强特征表示。对手改进了表示不足的特征的模型泛化。我们基于两种形式的特征偏差自动适应对手: 频率和特征值的组合变化。这允许我们动态调整扰动强度和对抗性训练权重。较强的扰动被应用于具有较少组合变量的特征值，以提高泛化能力，而较高的低频特征权值则解决了训练不平衡问题。我们利用基于广泛应用的因子分解机(AAFM)的自适应对抗扰动作为骨干模型。在实验中，AAFM 在公平性和准确性方面都超过了强基线。AAFM 擅长为单特征和多特征任务提供项目公平性和用户公平性，展示了它们的通用性和可伸缩性。为了保持良好的准确性，我们发现对抗性扰动必须得到很好的管理: 在训练期间，扰动不应该过度持续，它们的强度应该衰减。"
    },
    {
        "title": "Frequency and cardinality recovery from sketched data: a novel approach\n  bridging Bayesian and frequentist views",
        "url": "http://arxiv.org/abs/2309.15408v1",
        "pub_date": "2023-09-27",
        "summary": "We study how to recover the frequency of a symbol in a large discrete data\nset, using only a compressed representation, or sketch, of those data obtained\nvia random hashing. This is a classical problem in computer science, with\nvarious algorithms available, such as the count-min sketch. However, these\nalgorithms often assume that the data are fixed, leading to overly conservative\nand potentially inaccurate estimates when dealing with randomly sampled data.\nIn this paper, we consider the sketched data as a random sample from an unknown\ndistribution, and then we introduce novel estimators that improve upon existing\napproaches. Our method combines Bayesian nonparametric and classical\n(frequentist) perspectives, addressing their unique limitations to provide a\nprincipled and practical solution. Additionally, we extend our method to\naddress the related but distinct problem of cardinality recovery, which\nconsists of estimating the total number of distinct objects in the data set. We\nvalidate our method on synthetic and real data, comparing its performance to\nstate-of-the-art alternatives.",
        "translated": "我们研究如何在一个大的离散数据集中恢复一个符号的频率，只使用一个压缩的表示，或草图，这些数据通过随机散列获得。这是计算机科学中的一个经典问题，有各种可用的算法，比如 count-min 示意图。然而，这些算法往往假定数据是固定的，导致过度保守和潜在的不准确的估计时，处理随机采样的数据。在本文中，我们把草图数据看作是来自未知分布的随机样本，然后引入新的估计量来改进现有的估计方法。我们的方法结合贝叶斯非参数和经典(频率)观点，解决其独特的局限性，提供了一个原则和实际的解决方案。此外，我们还扩展了我们的方法来解决基数恢复的相关但不同的问题，这个问题包括估计数据集中不同对象的总数。我们验证了我们的方法合成和真实的数据，比较其性能的国家最先进的选择。"
    },
    {
        "title": "Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard\n  Parameter Sharing",
        "url": "http://arxiv.org/abs/2309.15826v1",
        "pub_date": "2023-09-27",
        "summary": "Recent works in end-to-end speech-to-text translation (ST) have proposed\nmulti-tasking methods with soft parameter sharing which leverage machine\ntranslation (MT) data via secondary encoders that map text inputs to an\neventual cross-modal representation. In this work, we instead propose a ST/MT\nmulti-tasking framework with hard parameter sharing in which all model\nparameters are shared cross-modally. Our method reduces the speech-text\nmodality gap via a pre-processing stage which converts speech and text inputs\ninto two discrete token sequences of similar length -- this allows models to\nindiscriminately process both modalities simply using a joint vocabulary. With\nexperiments on MuST-C, we demonstrate that our multi-tasking framework improves\nattentional encoder-decoder, Connectionist Temporal Classification (CTC),\ntransducer, and joint CTC/attention models by an average of +0.5 BLEU without\nany external MT data. Further, we show that this framework incorporates\nexternal MT data, yielding +0.8 BLEU, and also improves transfer learning from\npre-trained textual models, yielding +1.8 BLEU.",
        "translated": "近年来，端到端语音文本翻译(ST)研究者提出了一种软参数共享的多任务方法，该方法利用机器翻译(MT)数据通过二级编码器将文本输入映射到最终的跨模态表示。本文提出了一个具有硬参数共享的 ST/MT 多任务框架，其中所有模型参数都是跨模态共享的。该方法通过一个预处理阶段将语音和文本输入转换成两个长度相似的离散标记序列，从而缩小了语音-文本模式差异——这使得模型可以简单地使用一个联合词汇来不加区分地处理这两种模式。通过在 MuST-C 上的实验，我们证明了我们的多任务框架在没有任何外部 MT 数据的情况下，平均 + 0.5 BLEU 改善了注意力编码器-解码器，连接主义时间分类(CTC) ，传感器和联合 CTC/注意力模型。此外，我们表明，该框架结合了外部 MT 数据，产生 + 0.8 BLEU，并且还改进了从预训练的文本模型的转移学习，产生 + 1.8 BLEU。"
    },
    {
        "title": "Lyra: Orchestrating Dual Correction in Automated Theorem Proving",
        "url": "http://arxiv.org/abs/2309.15806v1",
        "pub_date": "2023-09-27",
        "summary": "Large Language Models (LLMs) present an intriguing avenue for exploration in\nthe field of formal theorem proving. Nevertheless, their full potential,\nparticularly concerning the mitigation of hallucinations and refinement through\nprover error messages, remains an area that has yet to be thoroughly\ninvestigated. To enhance the effectiveness of LLMs in the field, we introduce\nthe Lyra, a new framework that employs two distinct correction mechanisms: Tool\nCorrection (TC) and Conjecture Correction (CC). To implement Tool Correction in\nthe post-processing of formal proofs, we leverage prior knowledge to utilize\npredefined prover tools (e.g., Sledgehammer) for guiding the replacement of\nincorrect tools. Tool Correction significantly contributes to mitigating\nhallucinations, thereby improving the overall accuracy of the proof. In\naddition, we introduce Conjecture Correction, an error feedback mechanism\ndesigned to interact with prover to refine formal proof conjectures with prover\nerror messages. Compared to the previous refinement framework, the proposed\nConjecture Correction refines generation with instruction but does not collect\npaired (generation, error &amp; refinement) prompts. Our method has achieved\nstate-of-the-art (SOTA) performance on both miniF2F validation (48.0% -&gt; 55.3%)\nand test (45.5% -&gt; 51.2%). We also present 3 IMO problems solved by Lyra. We\nbelieve Tool Correction (post-process for hallucination mitigation) and\nConjecture Correction (subgoal adjustment from interaction with environment)\ncould provide a promising avenue for future research in this field.",
        "translated": "大语言模型(LLM)为形式定理证明领域提供了一个有趣的探索途径。然而，它们的全部潜力，特别是关于通过证明错误消息减轻幻觉和提炼的潜力，仍然是一个有待彻底研究的领域。为了提高 LLM 在该领域的有效性，我们引入了 Lyra，这是一个新的框架，它采用了两种不同的校正机制: 工具校正(TC)和猜想校正(CC)。为了在形式证明的后处理中实现工具更正，我们利用先前的知识来利用预定义的证明工具(例如，大锤)来指导替换不正确的工具。工具修正显著有助于减轻幻觉，从而提高整体准确性的证据。此外，我们还介绍了猜想修正，一种错误反馈机制，旨在与证明程序交互，用证明程序的错误信息细化形式证明猜想。与之前的精化框架相比，提出的猜想修正精化生成指令，但不收集成对(生成，错误和精化)提示。我们的方法在 miniF2F 验证(48.0%-> 55.3%)和测试(45.5%-> 51.2%)方面都取得了最先进的(SOTA)性能。我们还提出了天琴解决的3个 IMO 问题。我们相信，工具校正(减轻幻觉的后处理)和推测校正(与环境相互作用的子目标调整)可以为这一领域的未来研究提供一个有希望的途径。"
    },
    {
        "title": "Exploring Speech Recognition, Translation, and Understanding with\n  Discrete Speech Units: A Comparative Study",
        "url": "http://arxiv.org/abs/2309.15800v1",
        "pub_date": "2023-09-27",
        "summary": "Speech signals, typically sampled at rates in the tens of thousands per\nsecond, contain redundancies, evoking inefficiencies in sequence modeling.\nHigh-dimensional speech features such as spectrograms are often used as the\ninput for the subsequent model. However, they can still be redundant. Recent\ninvestigations proposed the use of discrete speech units derived from\nself-supervised learning representations, which significantly compresses the\nsize of speech data. Applying various methods, such as de-duplication and\nsubword modeling, can further compress the speech sequence length. Hence,\ntraining time is significantly reduced while retaining notable performance. In\nthis study, we undertake a comprehensive and systematic exploration into the\napplication of discrete units within end-to-end speech processing models.\nExperiments on 12 automatic speech recognition, 3 speech translation, and 1\nspoken language understanding corpora demonstrate that discrete units achieve\nreasonably good results in almost all the settings. We intend to release our\nconfigurations and trained models to foster future research efforts.",
        "translated": "语音信号，通常以每秒数万的速度采样，包含冗余，引起序列建模效率低下。高维语音特征，如声谱图，经常被用作后续模型的输入。然而，它们仍可能是多余的。最近的研究提出使用离散的语音单元来源于自我监督的学习表示，这大大压缩了语音数据的大小。采用去重复和子词建模等多种方法可以进一步压缩语音序列长度。因此，训练时间大大减少，同时保持显著的性能。在这项研究中，我们对离散单元在端到端语音处理模型中的应用进行了全面和系统的探索。在12个自动语音识别、3个语音翻译和1个口语语料库上的实验表明，离散单元在几乎所有情况下都取得了较好的效果。我们打算发布我们的配置和训练有素的模型，以促进未来的研究工作。"
    },
    {
        "title": "Large Language Model Routing with Benchmark Datasets",
        "url": "http://arxiv.org/abs/2309.15789v1",
        "pub_date": "2023-09-27",
        "summary": "There is a rapidly growing number of open-source Large Language Models (LLMs)\nand benchmark datasets to compare them. While some models dominate these\nbenchmarks, no single model typically achieves the best accuracy in all tasks\nand use cases. In this work, we address the challenge of selecting the best LLM\nout of a collection of models for new tasks. We propose a new formulation for\nthe problem, in which benchmark datasets are repurposed to learn a \"router\"\nmodel for this LLM selection, and we show that this problem can be reduced to a\ncollection of binary classification tasks. We demonstrate the utility and\nlimitations of learning model routers from various benchmark datasets, where we\nconsistently improve performance upon using any single model for all tasks.",
        "translated": "有越来越多的开源大型语言模型(LLM)和基准数据集来比较它们。虽然有些模型占据了这些基准测试的主导地位，但在所有任务和用例中，没有一个模型通常能够达到最佳的准确性。在这项工作中，我们解决了从新任务的模型集合中选择最佳 LLM 的挑战。我们提出了一个新的问题公式，其中基准数据集被重新用来学习一个“路由器”模型的 LLM 选择，我们表明这个问题可以减少到一个二进制分类任务的集合。我们展示了从各种基准数据集中学习模型路由器的实用性和局限性，在这些数据集中，我们通过对所有任务使用任何单一模型来持续提高性能。"
    },
    {
        "title": "Question answering using deep learning in low resource Indian language\n  Marathi",
        "url": "http://arxiv.org/abs/2309.15779v1",
        "pub_date": "2023-09-27",
        "summary": "Precise answers are extracted from a text for a given input question in a\nquestion answering system. Marathi question answering system is created in\nrecent studies by using ontology, rule base and machine learning based\napproaches. Recently transformer models and transfer learning approaches are\nused to solve question answering challenges. In this paper we investigate\ndifferent transformer models for creating a reading comprehension-based Marathi\nquestion answering system. We have experimented on different pretrained Marathi\nlanguage multilingual and monolingual models like Multilingual Representations\nfor Indian Languages (MuRIL), MahaBERT, Indic Bidirectional Encoder\nRepresentations from Transformers (IndicBERT) and fine-tuned it on a Marathi\nreading comprehension-based data set. We got the best accuracy in a MuRIL\nmultilingual model with an EM score of 0.64 and F1 score of 0.74 by fine tuning\nthe model on the Marathi dataset.",
        "translated": "在问答系统中，对于给定的输入问题，从文本中提取准确的答案。马拉地问答系统是近年来利用本体论、规则库和基于机器学习的方法创建的一种问答系统。最近变压器模型和传递学习方法被用来解决问题回答的挑战。本文研究了创建基于阅读理解的马拉地语问答系统的不同转换器模型。我们已经在不同的预先训练的马拉地语多语言和单语言模型上进行了实验，比如印度语言多语言表示法(muRIL)、 MahaBERT、来自变形金刚的印度双向编码器表示法(indBERT) ，并在基于马拉地语阅读理解的数据集上进行了微调。通过对 Marathi 数据集上的模型进行微调，我们得到了多语言 MuRIL 模型中 EM 得分为0.64，F1得分为0.74的最佳准确度。"
    },
    {
        "title": "Experience and Evidence are the eyes of an excellent summarizer! Towards\n  Knowledge Infused Multi-modal Clinical Conversation Summarization",
        "url": "http://arxiv.org/abs/2309.15739v1",
        "pub_date": "2023-09-27",
        "summary": "With the advancement of telemedicine, both researchers and medical\npractitioners are working hand-in-hand to develop various techniques to\nautomate various medical operations, such as diagnosis report generation. In\nthis paper, we first present a multi-modal clinical conversation summary\ngeneration task that takes a clinician-patient interaction (both textual and\nvisual information) and generates a succinct synopsis of the conversation. We\npropose a knowledge-infused, multi-modal, multi-tasking medical domain\nidentification and clinical conversation summary generation\n(MM-CliConSummation) framework. It leverages an adapter to infuse knowledge and\nvisual features and unify the fused feature vector using a gated mechanism.\nFurthermore, we developed a multi-modal, multi-intent clinical conversation\nsummarization corpus annotated with intent, symptom, and summary. The extensive\nset of experiments, both quantitatively and qualitatively, led to the following\nfindings: (a) critical significance of visuals, (b) more precise and medical\nentity preserving summary with additional knowledge infusion, and (c) a\ncorrelation between medical department identification and clinical synopsis\ngeneration. Furthermore, the dataset and source code are available at\nhttps://github.com/NLP-RL/MM-CliConSummation.",
        "translated": "随着远程医疗的发展，研究人员和医务人员正携手合作，开发各种技术，以自动化各种医疗操作，如诊断报告生成。在本文中，我们首先提出了一个多模态的临床会话摘要生成任务，采用临床医生-患者的互动(文本和视觉信息) ，并生成一个简洁的会话概要。我们提出了一个知识注入、多模态、多任务的医学领域识别和临床会话摘要生成(MM-CliConsum)框架。它利用适配器来注入知识和可视化特征，并使用门控机制统一融合特征向量。此外，我们开发了一个多模式，多意图临床会话摘要语料库注释意图，症状和总结。广泛的一系列定量和定性实验导致了以下发现: (a)视觉的关键意义，(b)更精确的医疗实体保存总结与额外的知识输入，以及(c)医疗部门识别与临床概要生成之间的相关性。此外，数据集和源代码也可以在 https://github.com/nlp-rl/mm-cliconsummation 中找到。"
    },
    {
        "title": "ChatGPT-BCI: Word-Level Neural State Classification Using GPT, EEG, and\n  Eye-Tracking Biomarkers in Semantic Inference Reading Comprehension",
        "url": "http://arxiv.org/abs/2309.15714v1",
        "pub_date": "2023-09-27",
        "summary": "With the recent explosion of large language models (LLMs), such as Generative\nPretrained Transformers (GPT), the need to understand the ability of humans and\nmachines to comprehend semantic language meaning has entered a new phase. This\nrequires interdisciplinary research that bridges the fields of cognitive\nscience and natural language processing (NLP). This pilot study aims to provide\ninsights into individuals' neural states during a semantic relation\nreading-comprehension task. We propose jointly analyzing LLMs, eye-gaze, and\nelectroencephalographic (EEG) data to study how the brain processes words with\nvarying degrees of relevance to a keyword during reading. We also use a feature\nengineering approach to improve the fixation-related EEG data classification\nwhile participants read words with high versus low relevance to the keyword.\nThe best validation accuracy in this word-level classification is over 60\\%\nacross 12 subjects. Words of high relevance to the inference keyword had\nsignificantly more eye fixations per word: 1.0584 compared to 0.6576 when\nexcluding no-fixation words, and 1.5126 compared to 1.4026 when including them.\nThis study represents the first attempt to classify brain states at a word\nlevel using LLM knowledge. It provides valuable insights into human cognitive\nabilities and the realm of Artificial General Intelligence (AGI), and offers\nguidance for developing potential reading-assisted technologies.",
        "translated": "随着大型语言模型(LLM)如生成预训练变换器(GPT)的迅猛发展，理解人类和机器理解语义语言意义的能力的需求已经进入了一个新的阶段。这需要在认知科学和自然语言处理(nLP)领域之间架起一座桥梁的科际整合。本研究旨在探讨个体在语义关系阅读理解任务中的神经状态。我们建议共同分析 LLM、眼睛凝视和脑电图(EEG)数据，以研究大脑在阅读过程中如何处理与关键词不同程度相关的单词。我们还使用特征工程的方法来改善与注视相关的脑电数据分类，同时参与者阅读与关键字相关性高或低的词语。这个词级分类的最佳验证准确率在12个受试者中超过60% 。与推断关键词高度相关的词汇每个词汇的眼睛注视明显更多: 1.0584比0.6576排除不注视的词汇，1.5126比1.4026包括他们。这项研究代表了首次尝试在词汇水平上使用 LLM 知识对大脑状态进行分类。它为人类认知能力和人工智能(AGI)领域提供了有价值的见解，并为开发潜在的阅读辅助技术提供了指导。"
    },
    {
        "title": "HyPoradise: An Open Baseline for Generative Speech Recognition with\n  Large Language Models",
        "url": "http://arxiv.org/abs/2309.15701v1",
        "pub_date": "2023-09-27",
        "summary": "Advancements in deep neural networks have allowed automatic speech\nrecognition (ASR) systems to attain human parity on several publicly available\nclean speech datasets. However, even state-of-the-art ASR systems experience\nperformance degradation when confronted with adverse conditions, as a\nwell-trained acoustic model is sensitive to variations in the speech domain,\ne.g., background noise. Intuitively, humans address this issue by relying on\ntheir linguistic knowledge: the meaning of ambiguous spoken terms is usually\ninferred from contextual cues thereby reducing the dependency on the auditory\nsystem. Inspired by this observation, we introduce the first open-source\nbenchmark to utilize external large language models (LLMs) for ASR error\ncorrection, where N-best decoding hypotheses provide informative elements for\ntrue transcription prediction. This approach is a paradigm shift from the\ntraditional language model rescoring strategy that can only select one\ncandidate hypothesis as the output transcription. The proposed benchmark\ncontains a novel dataset, HyPoradise (HP), encompassing more than 334,000 pairs\nof N-best hypotheses and corresponding accurate transcriptions across prevalent\nspeech domains. Given this dataset, we examine three types of error correction\ntechniques based on LLMs with varying amounts of labeled\nhypotheses-transcription pairs, which gains a significant word error rate (WER)\nreduction. Experimental evidence demonstrates the proposed technique achieves a\nbreakthrough by surpassing the upper bound of traditional re-ranking based\nmethods. More surprisingly, LLM with reasonable prompt and its generative\ncapability can even correct those tokens that are missing in N-best list. We\nmake our results publicly accessible for reproducible pipelines with released\npre-trained models, thus providing a new evaluation paradigm for ASR error\ncorrection with LLMs.",
        "translated": "深度神经网络的进步使得自动语音识别(ASR)系统能够在几个公开的清晰语音数据集上实现人类的平价。然而，即使是最先进的 ASR 系统在面对不利条件时也会出现性能下降，因为训练有素的声学模型对语音域的变化(例如背景噪声)很敏感。直觉上，人类通过依赖语言知识来解决这个问题: 含糊不清的口语术语的意义通常是从语境线索中推断出来的，从而减少了对听觉系统的依赖。受这一观察的启发，我们引入了第一个利用外部大语言模型(LLM)校正 ASR 错误的开源基准，其中 N 最佳解码假说为真正的转录预测提供了信息元素。这种方法是从传统的语言模型重新分类策略，只能选择一个候选假设作为输出转录的范式转变。提出的基准包含一个新的数据集，HyPoradise (HP) ，包含超过334,000对 N- 最佳假设和相应的准确转录跨流行语言领域。鉴于这个数据集，我们检查三种类型的错误纠正技术基于 LLM 与不同数量的标记假设-转录对，其中获得了显着的字错误率(WER)降低。实验结果表明，该方法突破了传统重排序方法的上限，取得了突破性进展。更令人惊讶的是，具有合理提示和生成能力的 LLM 甚至可以纠正 N-best 列表中缺少的令牌。我们使我们的研究结果可以通过发布预先训练的模型对可重复的管道进行公开访问，从而为 LLM 的 ASR 误差校正提供了一个新的评估范式。"
    },
    {
        "title": "Enhancing End-to-End Conversational Speech Translation Through Target\n  Language Context Utilization",
        "url": "http://arxiv.org/abs/2309.15686v1",
        "pub_date": "2023-09-27",
        "summary": "Incorporating longer context has been shown to benefit machine translation,\nbut the inclusion of context in end-to-end speech translation (E2E-ST) remains\nunder-studied. To bridge this gap, we introduce target language context in\nE2E-ST, enhancing coherence and overcoming memory constraints of extended audio\nsegments. Additionally, we propose context dropout to ensure robustness to the\nabsence of context, and further improve performance by adding speaker\ninformation. Our proposed contextual E2E-ST outperforms the isolated\nutterance-based E2E-ST approach. Lastly, we demonstrate that in conversational\nspeech, contextual information primarily contributes to capturing context\nstyle, as well as resolving anaphora and named entities.",
        "translated": "结合较长的上下文已被证明有利于机器翻译，但在端到端语音翻译(E2E-ST)中包含上下文仍然是一个研究课题。为了弥补这一差距，我们在 E2E-ST 中引入目标语语境，增强连贯性，克服扩展音频片段的记忆约束。此外，我们提出了上下文丢失，以确保鲁棒性的上下文缺失，并进一步提高性能，增加说话人的信息。我们提出的上下文 E2E-ST 优于基于孤立话语的 E2E-ST 方法。最后，我们发现在会话语言中，语境信息主要有助于捕捉语境风格，以及解析回指和命名实体。"
    },
    {
        "title": "Speech collage: code-switched audio generation by collaging monolingual\n  corpora",
        "url": "http://arxiv.org/abs/2309.15674v1",
        "pub_date": "2023-09-27",
        "summary": "Designing effective automatic speech recognition (ASR) systems for\nCode-Switching (CS) often depends on the availability of the transcribed CS\nresources. To address data scarcity, this paper introduces Speech Collage, a\nmethod that synthesizes CS data from monolingual corpora by splicing audio\nsegments. We further improve the smoothness quality of audio generation using\nan overlap-add approach. We investigate the impact of generated data on speech\nrecognition in two scenarios: using in-domain CS text and a zero-shot approach\nwith synthesized CS text. Empirical results highlight up to 34.4% and 16.2%\nrelative reductions in Mixed-Error Rate and Word-Error Rate for in-domain and\nzero-shot scenarios, respectively. Lastly, we demonstrate that CS augmentation\nbolsters the model's code-switching inclination and reduces its monolingual\nbias.",
        "translated": "设计有效的语音自动识别(ASR)系统往往取决于转录的 CS 资源的可用性。为了解决数据稀缺的问题，本文介绍了语音拼贴技术，这是一种通过拼接音频片段从单语语料库中合成 CS 数据的方法。我们进一步提高了音频生成的平滑质量使用重叠-添加的方法。我们研究了在两种情况下生成的数据对语音识别的影响: 使用域内 CS 文本和使用合成 CS 文本的零拍方法。实证结果表明，在域内和零镜头情景下，混合错误率和单词错误率分别相对降低了34.4% 和16.2% 。最后，我们证明了 CS 增强提高了模型的语码转换倾向，减少了模型的单语偏差。"
    },
    {
        "title": "Decoding the Workplace &amp; EOR: An Employee Survey Analysis by Data\n  Science Techniques and Visualization",
        "url": "http://arxiv.org/abs/2309.16329v1",
        "pub_date": "2023-09-28",
        "summary": "This research study explores the new dynamics of employee-organi-zation\nrelationships (EOR) [6] using advanced data science methodologies and presents\nfindings through accessible visualizations. Leveraging a dataset pro-cured from\na comprehensive nationwide big employee survey, this study employs innovative\nstrategy for theoretical researcher by using our state-of-the-art\nvisual-ization. The results present insightful visualizations encapsulating\ndemographic analysis, workforce satisfaction, work environment scrutiny, and\nthe employee's view via word cloud interpretations and burnout predictions.\n  The study underscores the profound implications of data science across\nvarious management sectors, enhancing understanding of workplace dynamics and\npro-moting mutual growth and satisfaction. This multifaceted approach caters to\na diverse array of readers, from researchers in sociology and management to\nfirms seeking detailed understanding of their workforce's satisfaction,\nemphasizing on practicality and interpretability.\n  The research encourages proactive measures to improve workplace\nenviron-ments, boost employee satisfaction, and foster healthier, more\nproductive organ-izations. It serves as a resourceful tool for those committed\nto these objectives, manifesting the transformative potential of data science\nin driving insightful nar-ratives about workplace dynamics and\nemployee-organization relationships. In essence, this research unearths\nvaluable insights to aid management, HR profes-sionals, and companies",
        "translated": "本研究利用先进的数据科学方法探索员工-组织关系的新动态(EOR)[6] ，并通过可视化展示研究结果。本研究利用来自全国大型员工综合调查的数据集，运用我们最先进的可视化技术，为理论研究者提供创新策略。研究结果提供了有见地的可视化，包括人口统计分析、员工满意度、工作环境审查以及员工通过文字云解释和职业倦怠预测的观点。这项研究强调了数据科学对各个管理部门的深远影响，加强了对工作场所动态的理解，促进了相互成长和满意度。这种多方面的方法迎合了不同的读者阵列，从社会学和管理学的研究人员到企业寻求详细了解其员工的满意度，强调实用性和可解释性。这项研究鼓励采取积极主动的措施来改善工作环境，提高员工的满意度，并培养更健康、更高效的组织机构。对于那些致力于实现这些目标的人来说，它是一个足智多谋的工具，体现了数据科学在推动有关工作场所动态和员工-组织关系的深刻叙述方面的变革潜力。从本质上说，这项研究发现了有价值的洞察力的援助管理，人力资源专业人士和公司"
    },
    {
        "title": "Multi-Granularity Click Confidence Learning via Self-Distillation in\n  Recommendation",
        "url": "http://arxiv.org/abs/2309.16322v1",
        "pub_date": "2023-09-28",
        "summary": "Recommendation systems rely on historical clicks to learn user interests and\nprovide appropriate items. However, current studies tend to treat clicks\nequally, which may ignore the assorted intensities of user interests in\ndifferent clicks. In this paper, we aim to achieve multi-granularity Click\nconfidence Learning via Self-Distillation in recommendation (CLSD). Due to the\nlack of supervised signals in click confidence, we first apply self-supervised\nlearning to obtain click confidence scores via a global self-distillation\nmethod. After that, we define a local confidence function to adapt confidence\nscores at the user group level, since the confidence distributions can be\nvaried among user groups. With the combination of multi-granularity confidence\nlearning, we can distinguish the quality of clicks and model user interests\nmore accurately without involving extra data and model structures. The\nsignificant improvements over different backbones on industrial offline and\nonline experiments in a real-world recommender system prove the effectiveness\nof our model. Recently, CLSD has been deployed on a large-scale recommender\nsystem, affecting over 400 million users.",
        "translated": "推荐系统依赖于历史点击来了解用户的兴趣并提供适当的项目。然而，目前的研究倾向于平等对待点击，这可能忽略了不同点击中用户兴趣的不同强度。在本文中，我们的目标是通过 Self-Distillation 实现多粒度 Click 置信学习(clSD)。由于点击置信度缺乏监督信号，我们首先采用自监督学习方法，通过一种全局自蒸馏方法获得点击置信度评分。然后，我们定义了一个局部置信度函数来适应用户组级别的置信度分数，因为置信度分布可以在用户组之间变化。结合多粒度置信度学习，可以在不涉及额外数据和模型结构的情况下更准确地区分点击质量和用户兴趣模型。在现实世界的工业离线和在线实验中，对不同骨干推荐系统的重大改进证明了我们模型的有效性。最近，「康体通自订车辆登记号码」已大规模投入服务，受影响的推荐系统超过四亿。"
    },
    {
        "title": "Analytical Modelling of Raw Data for Flow-Guided In-body Nanoscale\n  Localization",
        "url": "http://arxiv.org/abs/2309.16034v1",
        "pub_date": "2023-09-27",
        "summary": "Advancements in nanotechnology and material science are paving the way toward\nnanoscale devices that combine sensing, computing, data and energy storage, and\nwireless communication. In precision medicine, these nanodevices show promise\nfor disease diagnostics, treatment, and monitoring from within the patients'\nbloodstreams. Assigning the location of a sensed biological event with the\nevent itself, which is the main proposition of flow-guided in-body nanoscale\nlocalization, would be immensely beneficial from the perspective of precision\nmedicine. The nanoscale nature of the nanodevices and the challenging\nenvironment that the bloodstream represents, result in current flow-guided\nlocalization approaches being constrained in their communication and\nenergy-related capabilities. The communication and energy constraints of the\nnanodevices result in different features of raw data for flow-guided\nlocalization, in turn affecting its performance. An analytical modeling of the\neffects of imperfect communication and constrained energy causing intermittent\noperation of the nanodevices on the raw data produced by the nanodevices would\nbe beneficial. Hence, we propose an analytical model of raw data for\nflow-guided localization, where the raw data is modeled as a function of\ncommunication and energy-related capabilities of the nanodevice. We evaluate\nthe model by comparing its output with the one obtained through the utilization\nof a simulator for objective evaluation of flow-guided localization, featuring\ncomparably higher level of realism. Our results across a number of scenarios\nand heterogeneous performance metrics indicate high similarity between the\nmodel and simulator-generated raw datasets.",
        "translated": "纳米技术和材料科学的进步为纳米级设备的发展铺平了道路，这些设备将传感、计算、数据和能量存储以及无线通信结合在一起。在精准医学上，这些纳米设备显示了在病人血液中进行疾病诊断、治疗和监测的前景。将感应生物事件的位置与事件本身分配，这是流引导体内纳米尺度定位的主要命题，从精准医学的角度来看，将是非常有益的。纳米器件的纳米尺度特性和血液所代表的具有挑战性的环境，导致目前的流引导定位方法在其通信和能源相关能力方面受到限制。纳米器件的通信和能量约束导致了用于流引导定位的原始数据具有不同的特征，从而影响了其性能。对不完全通信和能量受限导致纳米器件间歇运行对纳米器件产生的原始数据的影响进行分析建模将是有益的。因此，我们提出了一个用于流引导定位的原始数据的分析模型，其中原始数据被建模为纳米器件的通信和能量相关功能的函数。我们通过比较模型的输出和通过使用模拟器对流引导定位进行客观评价所得到的输出来评价该模型，该模型具有相对较高的实际水平。我们在许多场景和异构性能指标中的结果表明，模型和模拟器生成的原始数据集之间具有很高的相似性。"
    },
    {
        "title": "Demystifying CLIP Data",
        "url": "http://arxiv.org/abs/2309.16671v1",
        "pub_date": "2023-09-28",
        "summary": "Contrastive Language-Image Pre-training (CLIP) is an approach that has\nadvanced research and applications in computer vision, fueling modern\nrecognition systems and generative models. We believe that the main ingredient\nto the success of CLIP is its data and not the model architecture or\npre-training objective. However, CLIP only provides very limited information\nabout its data and how it has been collected, leading to works that aim to\nreproduce CLIP's data by filtering with its model parameters. In this work, we\nintend to reveal CLIP's data curation approach and in our pursuit of making it\nopen to the community introduce Metadata-Curated Language-Image Pre-training\n(MetaCLIP). MetaCLIP takes a raw data pool and metadata (derived from CLIP's\nconcepts) and yields a balanced subset over the metadata distribution. Our\nexperimental study rigorously isolates the model and training settings,\nconcentrating solely on data. MetaCLIP applied to CommonCrawl with 400M\nimage-text data pairs outperforms CLIP's data on multiple standard benchmarks.\nIn zero-shot ImageNet classification, MetaCLIP achieves 70.8% accuracy,\nsurpassing CLIP's 68.3% on ViT-B models. Scaling to 1B data, while maintaining\nthe same training budget, attains 72.4%. Our observations hold across various\nmodel sizes, exemplified by ViT-H achieving 80.5%, without any\nbells-and-whistles. Curation code and training data distribution on metadata is\nmade available at https://github.com/facebookresearch/MetaCLIP.",
        "translated": "对比语言-图像预训练(CLIP)是一种在计算机视觉领域有着广泛研究和应用的方法，为现代识别系统和生成模型的发展提供了动力。我们相信 CLIP 成功的主要因素是它的数据，而不是模型架构或预训练目标。然而，CLIP 只提供了非常有限的关于其数据以及如何收集数据的信息，导致了旨在通过使用其模型参数进行过滤来重现 CLIP 数据的工作。在这项工作中，我们打算揭示 CLIP 的数据管理方法，并在我们的追求，使其向社区开放介绍元数据管理语言图像预训练(MetaCLIP)。MetaCLIP 采用原始数据池和元数据(源自 CLIP 的概念) ，并在元数据分布上生成一个平衡的子集。我们的实验研究严格地隔离了模型和训练设置，只关注数据。MetaCLIP 应用于具有400M 图像-文本数据对的 CommonCrawl，在多个标准基准上优于 CLIP 的数据。在零拍 ImageNet 分类中，MetaCLIP 达到了70.8% 的准确率，超过了在 ViT-B 模型中 CLIP 的68.3% 。扩展到1B 数据，同时保持相同的培训预算，达到72.4% 。我们的观察结果适用于不同的模型尺寸，以 ViT-H 达到80.5% 为例，没有任何花里胡哨的东西。有关元数据的管理编码及培训资料分发已于 https://github.com/facebookresearch/metaclip 备妥。"
    },
    {
        "title": "MindShift: Leveraging Large Language Models for Mental-States-Based\n  Problematic Smartphone Use Intervention",
        "url": "http://arxiv.org/abs/2309.16639v1",
        "pub_date": "2023-09-28",
        "summary": "Problematic smartphone use negatively affects physical and mental health.\nDespite the wide range of prior research, existing persuasive techniques are\nnot flexible enough to provide dynamic persuasion content based on users'\nphysical contexts and mental states. We first conduct a Wizard-of-Oz study\n(N=12) and an interview study (N=10) to summarize the mental states behind\nproblematic smartphone use: boredom, stress, and inertia. This informs our\ndesign of four persuasion strategies: understanding, comforting, evoking, and\nscaffolding habits. We leverage large language models (LLMs) to enable the\nautomatic and dynamic generation of effective persuasion content. We develop\nMindShift, a novel LLM-powered problematic smartphone use intervention\ntechnique. MindShift takes users' in-the-moment physical contexts, mental\nstates, app usage behaviors, users' goals &amp; habits as input, and generates\nhigh-quality and flexible persuasive content with appropriate persuasion\nstrategies. We conduct a 5-week field experiment (N=25) to compare MindShift\nwith baseline techniques. The results show that MindShift significantly\nimproves intervention acceptance rates by 17.8-22.5% and reduces smartphone use\nfrequency by 12.1-14.4%. Moreover, users have a significant drop in smartphone\naddiction scale scores and a rise in self-efficacy. Our study sheds light on\nthe potential of leveraging LLMs for context-aware persuasion in other behavior\nchange domains.",
        "translated": "智能手机使用问题对身心健康有负面影响。尽管已有的研究范围很广，但现有的说服技术不够灵活，不能根据用户的物理环境和心理状态提供动态的说服内容。我们首先进行了一项绿野仙踪研究(N = 12)和一项访谈研究(N = 10)来总结有问题的智能手机使用背后的心理状态: 无聊、压力和惰性。这为我们设计四种说服策略提供了依据: 理解、安慰、唤起和搭建习惯。我们利用大型语言模型(LLM)来自动和动态地生成有效的说服内容。我们开发了 MindShift，一种新的 LLM 驱动的有问题的智能手机使用干预技术。MindShift 以用户当时的物理环境、心理状态、应用程序使用行为、用户的目标和习惯作为输入，通过适当的说服策略生成高质量和灵活的说服内容。我们进行了一个为期5周的现场实验(N = 25)来比较 MindShift 和基线技术。结果显示，MindShift 显著提高了干预接受率17.8% -22.5% ，降低了智能手机使用频率12.1% -14.4% 。此外，用户的智能手机成瘾量表得分显著下降，自我效能感上升。我们的研究揭示了在其他行为改变领域利用 LLM 进行上下文感知劝说的潜力。"
    },
    {
        "title": "Stress Testing Chain-of-Thought Prompting for Large Language Models",
        "url": "http://arxiv.org/abs/2309.16621v1",
        "pub_date": "2023-09-28",
        "summary": "This report examines the effectiveness of Chain-of-Thought (CoT) prompting in\nimproving the multi-step reasoning abilities of large language models (LLMs).\nInspired by previous studies \\cite{Min2022RethinkingWork}, we analyze the\nimpact of three types of CoT prompt perturbations, namely CoT order, CoT\nvalues, and CoT operators on the performance of GPT-3 on various tasks. Our\nfindings show that incorrect CoT prompting leads to poor performance on\naccuracy metrics. Correct values in the CoT is crucial for predicting correct\nanswers. Moreover, incorrect demonstrations, where the CoT operators or the CoT\norder are wrong, do not affect the performance as drastically when compared to\nthe value based perturbations. This research deepens our understanding of CoT\nprompting and opens some new questions regarding the capability of LLMs to\nlearn reasoning in context.",
        "translated": "本研究旨在探讨思维链激励(CoT)在提高大型语言模型(LLM)多步推理能力方面的有效性。受前人研究的启发，我们分析了三种类型的 CoT 提示扰动，即 CoT 顺序、 CoT 值和 CoT 算子对 GPT-3在各种任务中的性能的影响。我们的研究结果表明，不正确的 CoT 提示会导致准确性指标表现不佳。正确的 CoT 值对预测正确答案至关重要。此外，与基于值的扰动相比，不正确的演示(CoT 运算符或 CoT 顺序错误)对性能的影响并不显著。本研究加深了我们对 CoT 提示的理解，并对 LLM 在语境中学习推理的能力提出了一些新的问题。"
    },
    {
        "title": "Qwen Technical Report",
        "url": "http://arxiv.org/abs/2309.16609v1",
        "pub_date": "2023-09-28",
        "summary": "Large language models (LLMs) have revolutionized the field of artificial\nintelligence, enabling natural language processing tasks that were previously\nthought to be exclusive to humans. In this work, we introduce Qwen, the first\ninstallment of our large language model series. Qwen is a comprehensive\nlanguage model series that encompasses distinct models with varying parameter\ncounts. It includes Qwen, the base pretrained language models, and Qwen-Chat,\nthe chat models finetuned with human alignment techniques. The base language\nmodels consistently demonstrate superior performance across a multitude of\ndownstream tasks, and the chat models, particularly those trained using\nReinforcement Learning from Human Feedback (RLHF), are highly competitive. The\nchat models possess advanced tool-use and planning capabilities for creating\nagent applications, showcasing impressive performance even when compared to\nbigger models on complex tasks like utilizing a code interpreter. Furthermore,\nwe have developed coding-specialized models, Code-Qwen and Code-Qwen-Chat, as\nwell as mathematics-focused models, Math-Qwen-Chat, which are built upon base\nlanguage models. These models demonstrate significantly improved performance in\ncomparison with open-source models, and slightly fall behind the proprietary\nmodels.",
        "translated": "大型语言模型(LLM)已经彻底改变了人工智能领域，使自然语言处理任务，以前被认为是人类独有的。在这项工作中，我们介绍 Qwen，我们的大型语言模型系列的第一部分。Qwen 是一个全面的语言模型系列，它包含不同的模型和不同的参数计数。它包括 Qwen，基础预训练语言模型，和 Qwen-Chat，聊天模型与人类对齐技术的微调。基础语言模型一贯表现出在众多下游任务中的优异表现，而聊天模型，尤其是那些使用人类反馈(Human Feeback，RLHF)强化学习训练的聊天模型，具有很强的竞争力。聊天模型具有创建代理应用程序的高级工具使用和规划能力，即使与使用代码解释器等复杂任务的大型模型相比，也能展示出令人印象深刻的性能。此外，我们还开发了专门的编码模型，代码 Qwen 和代码 Qwen 聊天，以及数学为中心的模型，数学 Qwen 聊天，这是建立在基础语言模型。与开源模型相比，这些模型的性能显著提高，略微落后于专有模型。"
    },
    {
        "title": "Unlikelihood Tuning on Negative Samples Amazingly Improves Zero-Shot\n  Translation",
        "url": "http://arxiv.org/abs/2309.16599v1",
        "pub_date": "2023-09-28",
        "summary": "Zero-shot translation (ZST), which is generally based on a multilingual\nneural machine translation model, aims to translate between unseen language\npairs in training data. The common practice to guide the zero-shot language\nmapping during inference is to deliberately insert the source and target\nlanguage IDs, e.g., &lt;EN&gt; for English and &lt;DE&gt; for German. Recent studies have\nshown that language IDs sometimes fail to navigate the ZST task, making them\nsuffer from the off-target problem (non-target language words exist in the\ngenerated translation) and, therefore, difficult to apply the current\nmultilingual translation model to a broad range of zero-shot language\nscenarios. To understand when and why the navigation capabilities of language\nIDs are weakened, we compare two extreme decoder input cases in the ZST\ndirections: Off-Target (OFF) and On-Target (ON) cases. By contrastively\nvisualizing the contextual word representations (CWRs) of these cases with\nteacher forcing, we show that 1) the CWRs of different languages are\neffectively distributed in separate regions when the sentence and ID are\nmatched (ON setting), and 2) if the sentence and ID are unmatched (OFF\nsetting), the CWRs of different languages are chaotically distributed. Our\nanalyses suggest that although they work well in ideal ON settings, language\nIDs become fragile and lose their navigation ability when faced with off-target\ntokens, which commonly exist during inference but are rare in training\nscenarios. In response, we employ unlikelihood tuning on the negative (OFF)\nsamples to minimize their probability such that the language IDs can\ndiscriminate between the on- and off-target tokens during training. Experiments\nspanning 40 ZST directions show that our method reduces the off-target ratio by\n-48.0% on average, leading to a +9.1 BLEU improvement with only an extra +0.3%\ntuning cost.",
        "translated": "零镜头翻译是一种基于多语言神经机器翻译模型的翻译方法，主要用于训练数据中看不见的语言对之间的翻译。在推理过程中指导零拍语言映射的常见做法是有意地插入源语言和目标语言 ID，例如，英语为 < EN > ，德语为 < DE > 。最近的研究表明，语言 ID 有时无法导航 ZST 任务，使他们遭受脱靶问题(非目标语言词存在于生成的翻译中) ，因此，难以应用当前的多语言翻译模型到广泛的零拍摄语言场景。为了理解何时以及为什么语言 ID 的导航能力被削弱，我们比较了 ZST 方向的两种极端解码器输入情况: OFF-Target (OFF)和 ON-Target (ON)情况。结果表明: 1)当句子和 ID 匹配时(ON 设置) ，不同语言的语境词表征有效地分布在不同的区域; 2)当句子和 ID 不匹配时(OFF 设置) ，不同语言的语境词表征是混沌分布的。我们的分析表明，尽管语言 ID 在理想的 ON 设置中工作得很好，但是当面对脱靶标记时，它们会变得脆弱并失去导航能力，而脱靶标记通常存在于推理过程中，但是在训练场景中很少出现。作为响应，我们对负(OFF)样本进行非似然调优，以最小化它们的概率，从而使语言 ID 能够在训练期间区分开目标标记和非目标标记。跨越40个 ZST 方向的实验表明，我们的方法平均降低了48.0% 的脱靶率，导致了 + 9.1 BLEU 的改进，只有额外的 + 0.3% 的调谐成本。"
    },
    {
        "title": "GPT-Fathom: Benchmarking Large Language Models to Decipher the\n  Evolutionary Path towards GPT-4 and Beyond",
        "url": "http://arxiv.org/abs/2309.16583v1",
        "pub_date": "2023-09-28",
        "summary": "With the rapid advancement of large language models (LLMs), there is a\npressing need for a comprehensive evaluation suite to assess their capabilities\nand limitations. Existing LLM leaderboards often reference scores reported in\nother papers without consistent settings and prompts, which may inadvertently\nencourage cherry-picking favored settings and prompts for better results. In\nthis work, we introduce GPT-Fathom, an open-source and reproducible LLM\nevaluation suite built on top of OpenAI Evals. We systematically evaluate 10+\nleading LLMs as well as OpenAI's legacy models on 20+ curated benchmarks across\n7 capability categories, all under aligned settings. Our retrospective study on\nOpenAI's earlier models offers valuable insights into the evolutionary path\nfrom GPT-3 to GPT-4. Currently, the community is eager to know how GPT-3\nprogressively improves to GPT-4, including technical details like whether\nadding code data improves LLM's reasoning capability, which aspects of LLM\ncapability can be improved by SFT and RLHF, how much is the alignment tax, etc.\nOur analysis sheds light on many of these questions, aiming to improve the\ntransparency of advanced LLMs.",
        "translated": "随着大型语言模型(LLM)的快速发展，迫切需要一个全面的评估套件来评估它们的能力和局限性。现有的 LLM 排行榜经常引用其他论文中没有一致设置和提示的分数，这可能会在不经意间鼓励挑选最喜欢的设置和提示，以获得更好的结果。在这项工作中，我们介绍了 GPT-Fathom，这是一个建立在 OpenAI 评估之上的开源且可重现的 LLM 评估套件。我们系统地评估了10 + 领先的 LLM 以及 OpenAI 的遗留模型，评估了7个能力类别中20 + 策划的基准测试，所有测试都在一致的设置下进行。我们对 OpenAI 早期模型的回顾性研究为从 GPT-3到 GPT-4的进化路径提供了有价值的见解。目前，社区渴望知道 GPT-3如何逐步改进到 GPT-4，包括技术细节，如添加代码数据是否改进 LLM 的推理能力，哪些方面的 LLM 能力可以通过 SFT 和 RLHF 改进，多少是比对税，等等。我们的分析揭示了许多这样的问题，旨在提高高级 LLM 的透明度。"
    },
    {
        "title": "A Benchmark for Learning to Translate a New Language from One Grammar\n  Book",
        "url": "http://arxiv.org/abs/2309.16575v1",
        "pub_date": "2023-09-28",
        "summary": "Large language models (LLMs) can perform impressive feats with in-context\nlearning or lightweight finetuning. It is natural to wonder how well these\nmodels adapt to genuinely new tasks, but how does one find tasks that are\nunseen in internet-scale training sets? We turn to a field that is explicitly\nmotivated and bottlenecked by a scarcity of web data: low-resource languages.\nIn this paper, we introduce MTOB (Machine Translation from One Book), a\nbenchmark for learning to translate between English and Kalamang -- a language\nwith less than 200 speakers and therefore virtually no presence on the web --\nusing several hundred pages of field linguistics reference materials. This task\nframing is novel in that it asks a model to learn a language from a single\nhuman-readable book of grammar explanations, rather than a large mined corpus\nof in-domain data, more akin to L2 learning than L1 acquisition. We demonstrate\nthat baselines using current LLMs are promising but fall short of human\nperformance, achieving 44.7 chrF on Kalamang to English translation and 45.8\nchrF on English to Kalamang translation, compared to 51.6 and 57.0 chrF by a\nhuman who learned Kalamang from the same reference materials. We hope that MTOB\nwill help measure LLM capabilities along a new dimension, and that the methods\ndeveloped to solve it could help expand access to language technology for\nunderserved communities by leveraging qualitatively different kinds of data\nthan traditional machine translation.",
        "translated": "大型语言模型(LLM)可以通过上下文学习或轻量级微调来执行令人印象深刻的功能。人们自然想知道，这些模型对真正的新任务适应得有多好，但如何才能找到在互联网规模的训练集中看不到的任务呢？我们转向一个由于网络数据稀缺而受到明确激励和瓶颈的领域: 低资源语言。在这篇论文中，我们介绍了 MTOB (一本书的机器翻译) ，一个学习英语和 Kalamang 之间翻译的基准——这种语言只有不到200个使用者，因此在网络上几乎没有存在——使用几百页的实地语言学参考资料。这种任务框架是新颖的，因为它要求一个模型从一本人类可读的语法解释书中学习一门语言，而不是从一个大型的领域内数据挖掘语料库中学习，这更类似于 L2学习而不是 L1习得。我们证明了使用当前 LLM 的基线是有希望的，但是低于人类的表现，在 Kalamang 到英语的翻译中达到44.7 chrF，在英语到 Kalamang 的翻译中达到45.8 chrF，相比之下，一个从相同的参考资料中学习卡拉芒的人类则分别达到了51.6和57.0 chrF。我们希望 MTOB 将有助于沿着一个新的维度衡量 LLM 的能力，并且为解决这个问题而开发的方法可以通过利用与传统机器翻译相比在质量上不同的数据类型来帮助服务不足的社区扩大获得语言技术的途径。"
    },
    {
        "title": "The ARRT of Language-Models-as-a-Service: Overview of a New Paradigm and\n  its Challenges",
        "url": "http://arxiv.org/abs/2309.16573v1",
        "pub_date": "2023-09-28",
        "summary": "Some of the most powerful language models currently are proprietary systems,\naccessible only via (typically restrictive) web or software programming\ninterfaces. This is the Language-Models-as-a-Service (LMaaS) paradigm.\nContrasting with scenarios where full model access is available, as in the case\nof open-source models, such closed-off language models create specific\nchallenges for evaluating, benchmarking, and testing them. This paper has two\ngoals: on the one hand, we delineate how the aforementioned challenges act as\nimpediments to the accessibility, replicability, reliability, and\ntrustworthiness (ARRT) of LMaaS. We systematically examine the issues that\narise from a lack of information about language models for each of these four\naspects. We shed light on current solutions, provide some recommendations, and\nhighlight the directions for future advancements. On the other hand, it serves\nas a one-stop-shop for the extant knowledge about current, major LMaaS,\noffering a synthesized overview of the licences and capabilities their\ninterfaces offer.",
        "translated": "目前一些最强大的语言模型是专有系统，只能通过(通常是限制性的) Web 或软件编程接口访问。这就是语言模型即服务(LMaaS)范例。与可以访问完整模型的场景(如开源模型)相比，这种封闭的语言模型为评估、基准测试和测试它们带来了特定的挑战。本文有两个目标: 一方面，我们描述了上述挑战是如何阻碍 LMaaS 的可访问性、可复制性、可靠性和可信性(ARRT)的。我们系统地研究了由于缺乏关于这四个方面的语言模型的信息而产生的问题。我们阐述了当前的解决方案，提供了一些建议，并强调了未来发展的方向。另一方面，它可以作为一站式服务器，提供有关当前主要 LMaaS 的现有知识，并提供其接口所提供的许可证和功能的综合概述。"
    },
    {
        "title": "Unsupervised Fact Verification by Language Model Distillation",
        "url": "http://arxiv.org/abs/2309.16540v1",
        "pub_date": "2023-09-28",
        "summary": "Unsupervised fact verification aims to verify a claim using evidence from a\ntrustworthy knowledge base without any kind of data annotation. To address this\nchallenge, algorithms must produce features for every claim that are both\nsemantically meaningful, and compact enough to find a semantic alignment with\nthe source information. In contrast to previous work, which tackled the\nalignment problem by learning over annotated corpora of claims and their\ncorresponding labels, we propose SFAVEL (Self-supervised Fact Verification via\nLanguage Model Distillation), a novel unsupervised framework that leverages\npre-trained language models to distil self-supervised features into\nhigh-quality claim-fact alignments without the need for annotations. This is\nenabled by a novel contrastive loss function that encourages features to attain\nhigh-quality claim and evidence alignments whilst preserving the semantic\nrelationships across the corpora. Notably, we present results that achieve a\nnew state-of-the-art on the standard FEVER fact verification benchmark (+8%\naccuracy) with linear evaluation.",
        "translated": "无监督事实验证的目的是使用来自可信知识库的证据来验证索赔，而不需要任何数据注释。为了解决这个问题，算法必须为每个声明生成既有语义意义又足够紧凑的特性，以便找到与源信息的语义对齐。与以前的工作相反，解决了对齐问题，通过学习注释索赔语料库及其相应的标签，我们提出了 SFAVEL (自监督的事实验证通过语言模型蒸馏) ，一个新颖的无监督框架，利用预先训练的语言模型，提取自监督的特征到高质量的索赔事实对齐而不需要注释。这是由一个新的对比损失功能，鼓励功能，以获得高质量的索赔和证据对齐，同时保持语料库的语义关系。值得注意的是，我们提出的结果，实现了一个新的国家的最先进的标准 FEVER 事实验证基准(+ 8% 的准确性)与线性评估。"
    },
    {
        "title": "KLoB: a Benchmark for Assessing Knowledge Locating Methods in Language\n  Models",
        "url": "http://arxiv.org/abs/2309.16535v1",
        "pub_date": "2023-09-28",
        "summary": "Recently, Locate-Then-Edit paradigm has emerged as one of the main approaches\nin changing factual knowledge stored in the Language models. However, there is\na lack of research on whether present locating methods can pinpoint the exact\nparameters embedding the desired knowledge. Moreover, although many researchers\nhave questioned the validity of locality hypothesis of factual knowledge, no\nmethod is provided to test the a hypothesis for more in-depth discussion and\nresearch. Therefore, we introduce KLoB, a benchmark examining three essential\nproperties that a reliable knowledge locating method should satisfy. KLoB can\nserve as a benchmark for evaluating existing locating methods in language\nmodels, and can contributes a method to reassessing the validity of locality\nhypothesis of factual knowledge. Our is publicly available at\n\\url{https://github.com/juyiming/KLoB}.",
        "translated": "近年来，定位-然后编辑范式已经成为改变语言模型中存储的事实知识的主要方法之一。然而，目前的定位方法能否精确定位嵌入期望知识的参数，还缺乏研究。此外，虽然许多研究者对事实知识的局部性假设的有效性提出了质疑，但没有提供检验这一假设的方法，以便进行更深入的讨论和研究。因此，我们介绍了 KLoB，这是一个基准测试，检查了一个可靠的知识定位方法应该满足的三个基本属性。KLoB 可以作为评价语言模型中现有定位方法的基准，也可以为重新评价事实知识的定位假设的有效性提供一种方法。我们可以在 url { https://github.com/juyiming/klob }上公开获得。"
    },
    {
        "title": "Toward Robust Recommendation via Real-time Vicinal Defense",
        "url": "http://arxiv.org/abs/2309.17278v1",
        "pub_date": "2023-09-29",
        "summary": "Recommender systems have been shown to be vulnerable to poisoning attacks,\nwhere malicious data is injected into the dataset to cause the recommender\nsystem to provide biased recommendations. To defend against such attacks,\nvarious robust learning methods have been proposed. However, most methods are\nmodel-specific or attack-specific, making them lack generality, while other\nmethods, such as adversarial training, are oriented towards evasion attacks and\nthus have a weak defense strength in poisoning attacks.\n  In this paper, we propose a general method, Real-time Vicinal Defense (RVD),\nwhich leverages neighboring training data to fine-tune the model before making\na recommendation for each user. RVD works in the inference phase to ensure the\nrobustness of the specific sample in real-time, so there is no need to change\nthe model structure and training process, making it more practical. Extensive\nexperimental results demonstrate that RVD effectively mitigates targeted\npoisoning attacks across various models without sacrificing accuracy. Moreover,\nthe defensive effect can be further amplified when our method is combined with\nother strategies.",
        "translated": "推荐系统已被证明容易受到中毒攻击，恶意数据被注入数据集，导致推荐系统提供有偏见的推荐。为了抵御这种攻击，人们提出了各种鲁棒学习方法。然而，大多数方法是模型特定的或攻击特定的，缺乏一般性，而其他方法，如对抗性训练，面向规避攻击，因此在中毒攻击防御力量薄弱。在本文中，我们提出了一个通用的方法，即实时邻域防御(RVD) ，它利用相邻的训练数据来微调模型，然后为每个用户提出一个建议。RVD 工作在推理阶段，以保证特定样本的实时鲁棒性，因此不需要改变模型结构和训练过程，使其更加实用。大量的实验结果表明，RVD 在不牺牲精度的情况下，有效地减轻了各种模型中的靶向中毒攻击。此外，当我们的方法与其他策略相结合时，防御效应可以进一步放大。"
    },
    {
        "title": "SAppKG: Mobile App Recommendation Using Knowledge Graph and Side\n  Information-A Secure Framework",
        "url": "http://arxiv.org/abs/2309.17115v1",
        "pub_date": "2023-09-29",
        "summary": "Due to the rapid development of technology and the widespread usage of\nsmartphones, the number of mobile applications is exponentially growing.\nFinding a suitable collection of apps that aligns with users needs and\npreferences can be challenging. However, mobile app recommender systems have\nemerged as a helpful tool in simplifying this process. But there is a drawback\nto employing app recommender systems. These systems need access to user data,\nwhich is a serious security violation. While users seek accurate opinions, they\ndo not want to compromise their privacy in the process. We address this issue\nby developing SAppKG, an end-to-end user privacy-preserving knowledge graph\narchitecture for mobile app recommendation based on knowledge graph models such\nas SAppKG-S and SAppKG-D, that utilized the interaction data and side\ninformation of app attributes. We tested the proposed model on real-world data\nfrom the Google Play app store, using precision, recall, mean absolute\nprecision, and mean reciprocal rank. We found that the proposed model improved\nresults on all four metrics. We also compared the proposed model to baseline\nmodels and found that it outperformed them on all four metrics.",
        "translated": "由于技术的快速发展和智能手机的广泛使用，移动应用程序的数量呈指数增长。找到一个适合用户需求和偏好的应用程序集合是一个挑战。然而，移动应用程序推荐系统已经成为简化这一过程的有用工具。但是使用应用程序推荐系统有一个缺点。这些系统需要访问用户数据，这是一个严重的安全问题。虽然用户寻求准确的意见，他们不想在这个过程中损害他们的隐私。我们通过开发 SAppKG 来解决这个问题，SAppKG 是一个基于 SAppKG-S 和 SAppKG-D 等知识图模型的、用于移动应用推荐的端到端用户隐私保护知识图架构，它利用了应用属性的交互数据和侧信息。我们使用精确度、召回率、平均绝对精确度和平均倒数排名测试了来自 Google Play 应用程序商店的现实数据。我们发现，提出的模型改善了所有四个指标的结果。我们还将提出的模型与基线模型进行了比较，发现它在所有四个指标上都优于基线模型。"
    },
    {
        "title": "Aligning the Capabilities of Large Language Models with the Context of\n  Information Retrieval via Contrastive Feedback",
        "url": "http://arxiv.org/abs/2309.17078v1",
        "pub_date": "2023-09-29",
        "summary": "Information Retrieval (IR), the process of finding information to satisfy\nuser's information needs, plays an essential role in modern people's lives.\nRecently, large language models (LLMs) have demonstrated remarkable\ncapabilities across various tasks, some of which are important for IR.\nNonetheless, LLMs frequently confront the issue of generating responses that\nlack specificity. This has limited the overall effectiveness of LLMs for IR in\nmany cases. To address these issues, we present an unsupervised alignment\nframework called Reinforcement Learning from Contrastive Feedback (RLCF), which\nempowers LLMs to generate both high-quality and context-specific responses that\nsuit the needs of IR tasks. Specifically, we construct contrastive feedback by\ncomparing each document with its similar documents, and then propose a reward\nfunction named Batched-MRR to teach LLMs to generate responses that captures\nthe fine-grained information that distinguish documents from their similar\nones. To demonstrate the effectiveness of RLCF, we conducted experiments in two\ntypical applications of LLMs in IR, i.e., data augmentation and summarization.\nThe experimental results show that RLCF can effectively improve the performance\nof LLMs in IR context.",
        "translated": "信息检索(IR)是发现信息以满足用户信息需求的过程，在现代人的生活中扮演着重要的角色。最近，大型语言模型(LLM)已经在各种任务中展示了显著的能力，其中一些对于 IR 很重要。尽管如此，LLM 经常面临产生缺乏特异性的反应的问题。这在许多情况下限制了对于 IR 的 LLM 的总体有效性。为了解决这些问题，我们提出了一个称为对比反馈(rLCF)强化学习的无监督校准框架，该框架授权 LLM 生成高质量和上下文特定的响应，以满足 IR 任务的需求。具体来说，我们通过比较每个文档与其相似的文档来构建对比反馈，然后提出一个名为批处理 MRR 的奖励函数来教 LLM 生成响应，这些响应捕获细粒度的信息，从而区分文档与其相似的文档。为了验证 RLCF 的有效性，我们对 LLM 在红外图像处理中的两种典型应用进行了实验，即数据增强和归纳。实验结果表明，RLCF 可以有效地改善红外环境下 LLM 的性能。"
    },
    {
        "title": "Beyond Co-occurrence: Multi-modal Session-based Recommendation",
        "url": "http://arxiv.org/abs/2309.17037v1",
        "pub_date": "2023-09-29",
        "summary": "Session-based recommendation is devoted to characterizing preferences of\nanonymous users based on short sessions. Existing methods mostly focus on\nmining limited item co-occurrence patterns exposed by item ID within sessions,\nwhile ignoring what attracts users to engage with certain items is rich\nmulti-modal information displayed on pages. Generally, the multi-modal\ninformation can be classified into two categories: descriptive information\n(e.g., item images and description text) and numerical information (e.g.,\nprice). In this paper, we aim to improve session-based recommendation by\nmodeling the above multi-modal information holistically. There are mainly three\nissues to reveal user intent from multi-modal information: (1) How to extract\nrelevant semantics from heterogeneous descriptive information with different\nnoise? (2) How to fuse these heterogeneous descriptive information to\ncomprehensively infer user interests? (3) How to handle probabilistic influence\nof numerical information on user behaviors? To solve above issues, we propose a\nnovel multi-modal session-based recommendation (MMSBR) that models both\ndescriptive and numerical information under a unified framework. Specifically,\na pseudo-modality contrastive learning is devised to enhance the representation\nlearning of descriptive information. Afterwards, a hierarchical pivot\ntransformer is presented to fuse heterogeneous descriptive information.\nMoreover, we represent numerical information with Gaussian distribution and\ndesign a Wasserstein self-attention to handle the probabilistic influence mode.\nExtensive experiments on three real-world datasets demonstrate the\neffectiveness of the proposed MMSBR. Further analysis also proves that our\nMMSBR can alleviate the cold-start problem in SBR effectively.",
        "translated": "基于会话的推荐主要用于描述基于短会话的匿名用户的偏好。现有的方法主要集中在挖掘会话中项目 ID 所暴露的有限项目共现模式，而忽略了页面上显示的丰富的多模态信息会吸引用户参与某些项目。一般来说，多模态信息可以分为两类: 描述性信息(如商品图片和描述文本)和数字信息(如价格)。本文旨在通过对上述多模态信息进行整体建模来改进基于会话的推荐。从多模态信息中提取用户意图主要有三个问题: (1)如何从具有不同噪声的异构描述信息中提取相关语义;？(2)如何融合这些异构的描述性信息，全面推断用户兴趣？(如何处理数字信息对用户行为的概率影响？为了解决上述问题，我们提出了一种新的基于会话的多模态推荐(MMSBR) ，它在一个统一的框架下对描述性信息和数值信息进行建模。为了提高描述性信息的表征学习，提出了一种伪模态对比学习方法。然后，提出了一种分层的枢轴变压器来融合异构描述信息。此外，我们用正态分布表示数值信息，并设计了一个沃瑟斯坦自我注意来处理概率影响模式。在三个实际数据集上的大量实验证明了该 MMSBR 算法的有效性。进一步的分析也证明了我们的 MMSBR 可以有效地缓解 SBR 中的冷启动问题。"
    },
    {
        "title": "Hallucination Reduction in Long Input Text Summarization",
        "url": "http://arxiv.org/abs/2309.16781v1",
        "pub_date": "2023-09-28",
        "summary": "Hallucination in text summarization refers to the phenomenon where the model\ngenerates information that is not supported by the input source document.\nHallucination poses significant obstacles to the accuracy and reliability of\nthe generated summaries. In this paper, we aim to reduce hallucinated outputs\nor hallucinations in summaries of long-form text documents. We have used the\nPubMed dataset, which contains long scientific research documents and their\nabstracts. We have incorporated the techniques of data filtering and joint\nentity and summary generation (JAENS) in the fine-tuning of the Longformer\nEncoder-Decoder (LED) model to minimize hallucinations and thereby improve the\nquality of the generated summary. We have used the following metrics to measure\nfactual consistency at the entity level: precision-source, and F1-target. Our\nexperiments show that the fine-tuned LED model performs well in generating the\npaper abstract. Data filtering techniques based on some preprocessing steps\nreduce entity-level hallucinations in the generated summaries in terms of some\nof the factual consistency metrics.",
        "translated": "文本摘要中的幻觉是指模型生成的信息不受输入源文档支持的现象。幻觉对生成的摘要的准确性和可靠性造成了重大障碍。在本文中，我们的目的是减少幻觉输出或幻觉的摘要长形式的文本文件。我们使用了 PubMed 数据集，其中包含长的科学研究文档及其摘要。我们已经将数据过滤和联合实体和摘要生成(JAENS)的技术结合到 LongformEncoder-Decder (LED)模型的微调中，以最小化幻觉，从而提高生成摘要的质量。我们使用以下指标来度量实体级别的实际一致性: 精度-源和 F1-目标。实验表明，微调 LED 模型在生成论文摘要方面表现良好。基于一些预处理步骤的数据过滤技术可以减少生成的摘要中某些事实一致性度量的实体级错觉。"
    },
    {
        "title": "Efficient Streaming Language Models with Attention Sinks",
        "url": "http://arxiv.org/abs/2309.17453v1",
        "pub_date": "2023-09-29",
        "summary": "Deploying Large Language Models (LLMs) in streaming applications such as\nmulti-round dialogue, where long interactions are expected, is urgently needed\nbut poses two major challenges. Firstly, during the decoding stage, caching\nprevious tokens' Key and Value states (KV) consumes extensive memory. Secondly,\npopular LLMs cannot generalize to longer texts than the training sequence\nlength. Window attention, where only the most recent KVs are cached, is a\nnatural approach -- but we show that it fails when the text length surpasses\nthe cache size. We observe an interesting phenomenon, namely attention sink,\nthat keeping the KV of initial tokens will largely recover the performance of\nwindow attention. In this paper, we first demonstrate that the emergence of\nattention sink is due to the strong attention scores towards initial tokens as\na ``sink'' even if they are not semantically important. Based on the above\nanalysis, we introduce StreamingLLM, an efficient framework that enables LLMs\ntrained with a finite length attention window to generalize to infinite\nsequence lengths without any fine-tuning. We show that StreamingLLM can enable\nLlama-2, MPT, Falcon, and Pythia to perform stable and efficient language\nmodeling with up to 4 million tokens and more. In addition, we discover that\nadding a placeholder token as a dedicated attention sink during pre-training\ncan further improve streaming deployment. In streaming settings, StreamingLLM\noutperforms the sliding window recomputation baseline by up to 22.2x speedup.\nCode and datasets are provided at https://github.com/mit-han-lab/streaming-llm.",
        "translated": "在流媒体应用程序中部署大型语言模型(LLM) ，比如多轮对话(其中需要进行长时间的交互) ，是迫切需要的，但也带来了两个主要挑战。首先，在解码阶段，缓存以前令牌的键和值状态(KV)消耗大量内存。其次，流行的 LLM 不能推广到比训练序列长度更长的文本。窗口关注(只缓存最新的 KV)是一种自然的方法——但是我们表明，当文本长度超过缓存大小时，这种方法就失败了。我们观察到一个有趣的现象，即注意沉降，即保持初始标记的 KV 将在很大程度上恢复窗口注意的表现。在本文中，我们首先论证了注意汇的出现是由于初始标记作为“汇”的注意得分较高，即使它们在语义上并不重要。在上述分析的基础上，我们引入了 StreamingLLM，这是一个有效的框架，可以使用有限长度的注意窗口训练 LLM，不需要任何微调就可以将序列长度推广到无限长度。我们展示了 StreamingLLM 可以使 Llama-2、 MPT、 Falcon 和 Pythia 执行稳定有效的语言建模，最多可以获得400万个标记或更多。此外，我们发现在预训练期间添加占位符令牌作为专用注意力接收器可以进一步改进流部署。在流设置中，StreamingLLM 的性能比滑动窗口重新计算基线高出22.2倍的加速比。Https://github.com/mit-han-lab/streaming-llm 提供代码和数据集。"
    },
    {
        "title": "ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving",
        "url": "http://arxiv.org/abs/2309.17452v1",
        "pub_date": "2023-09-29",
        "summary": "Large language models have made significant progress in various language\ntasks, yet they still struggle with complex mathematics. In this paper, we\npropose ToRA a series of Tool-integrated Reasoning Agents designed to solve\nchallenging mathematical problems by seamlessly integrating natural language\nreasoning with the utilization of external tools (e.g., computation libraries\nand symbolic solvers), thereby amalgamating the analytical prowess of language\nand the computational efficiency of tools. To train ToRA, we curate interactive\ntool-use trajectories on mathematical datasets, apply imitation learning on the\nannotations, and propose output space shaping to further refine models'\nreasoning behavior. As a result, ToRA models significantly outperform\nopen-source models on 10 mathematical reasoning datasets across all scales with\n13%-19% absolute improvements on average. Notably, ToRA-7B reaches 44.6% on the\ncompetition-level dataset MATH, surpassing the best open-source model\nWizardMath-70B by 22% absolute. ToRA-34B is also the first open-source model\nthat achieves an accuracy exceeding 50% on MATH, which significantly\noutperforms GPT-4's CoT result, and is competitive with GPT-4 solving problems\nwith programs. Additionally, we conduct a comprehensive analysis of the\nbenefits and remaining challenges of tool interaction for mathematical\nreasoning, providing valuable insights for future research.",
        "translated": "大型语言模型已经在各种语言任务中取得了显著的进步，但是它们仍然在与复杂的数学作斗争。在本文中，我们提出了 ToRA 一系列工具集成推理代理，旨在解决具有挑战性的数学问题，通过无缝集成自然语言推理与利用外部工具(例如，计算库和符号求解器) ，从而融合语言的分析能力和工具的计算效率。为了训练 ToRA，我们对数学数据集上的交互式工具使用轨迹进行规划，对注释进行仿真学习，并提出输出空间整形以进一步细化模型的推理行为。因此，ToRA 模型在所有范围内的10个数学推理数据集上显著优于开源模型，平均绝对改进率为13% -19% 。值得注意的是，ToRA-7B 在竞争级数据集 MATH 上达到44.6% ，绝对值比最好的开源模型 WizardMath-70B 高出22% 。ToRA-34B 也是第一个在 MATH 上达到超过50% 准确率的开源模型，其性能明显优于 GPT-4的 CoT 结果，并且与 GPT-4用程序解决问题具有竞争力。此外，我们对数学推理工具交互的好处和仍然存在的挑战进行了全面的分析，为未来的研究提供了有价值的见解。"
    },
    {
        "title": "A Large Language Model Approach to Educational Survey Feedback Analysis",
        "url": "http://arxiv.org/abs/2309.17447v1",
        "pub_date": "2023-09-29",
        "summary": "This paper assesses the potential for the large language models (LLMs) GPT-4\nand GPT-3.5 to aid in deriving insight from education feedback surveys.\nExploration of LLM use cases in education has focused on teaching and learning,\nwith less exploration of capabilities in education feedback analysis. Survey\nanalysis in education involves goals such as finding gaps in curricula or\nevaluating teachers, often requiring time-consuming manual processing of\ntextual responses. LLMs have the potential to provide a flexible means of\nachieving these goals without specialized machine learning models or\nfine-tuning. We demonstrate a versatile approach to such goals by treating them\nas sequences of natural language processing (NLP) tasks including\nclassification (multi-label, multi-class, and binary), extraction, thematic\nanalysis, and sentiment analysis, each performed by LLM. We apply these\nworkflows to a real-world dataset of 2500 end-of-course survey comments from\nbiomedical science courses, and evaluate a zero-shot approach (i.e., requiring\nno examples or labeled training data) across all tasks, reflecting education\nsettings, where labeled data is often scarce. By applying effective prompting\npractices, we achieve human-level performance on multiple tasks with GPT-4,\nenabling workflows necessary to achieve typical goals. We also show the\npotential of inspecting LLMs' chain-of-thought (CoT) reasoning for providing\ninsight that may foster confidence in practice. Moreover, this study features\ndevelopment of a versatile set of classification categories, suitable for\nvarious course types (online, hybrid, or in-person) and amenable to\ncustomization. Our results suggest that LLMs can be used to derive a range of\ninsights from survey text.",
        "translated": "本文评估了大型语言模型(LLM) GPT-4和 GPT-3.5在帮助从教育反馈调查中获得洞察力方面的潜力。对教育中 LLM 用例的探索主要集中在教学和学习上，对教育反馈分析能力的探索较少。教育调查分析的目标包括发现课程中的差距或评价教师，往往需要耗费时间的手工处理文本答复。LLM 有可能提供一种灵活的方法来实现这些目标，而不需要专门的机器学习模型或微调。我们展示了一种通用的方法来实现这些目标，将它们看作自然语言处理(NLP)任务的序列，包括分类(多标签、多类和二进制)、提取、主题分析和情感分析，每个任务都由 LLM 执行。我们将这些工作流程应用于生物医学科学课程的2500条课程结束调查评论的现实世界数据集，并评估所有任务中的“零打击”方法(即不需要例子或标记的培训数据) ，反映标记数据往往稀缺的教育环境。通过应用有效的激励实践，我们使用 GPT-4在多个任务上实现了人类水平的性能，使得实现典型目标所必需的工作流成为可能。我们还展示了检查 LLM 的思维链(CoT)推理的潜力，以提供洞察力，可能培养实践中的信心。此外，这项研究的特点是开发了一套多功能的分类类别，适用于各种类型的课程(在线，混合，或面对面) ，并适合于定制。我们的研究结果表明，LLM 可以用来从调查文本中获得一系列见解。"
    },
    {
        "title": "L2CEval: Evaluating Language-to-Code Generation Capabilities of Large\n  Language Models",
        "url": "http://arxiv.org/abs/2309.17446v1",
        "pub_date": "2023-09-29",
        "summary": "Recently, large language models (LLMs), especially those that are pretrained\non code, have demonstrated strong capabilities in generating programs from\nnatural language inputs in a few-shot or even zero-shot manner. Despite\npromising results, there is a notable lack of a comprehensive evaluation of\nthese models language-to-code generation capabilities. Existing studies often\nfocus on specific tasks, model architectures, or learning paradigms, leading to\na fragmented understanding of the overall landscape. In this work, we present\nL2CEval, a systematic evaluation of the language-to-code generation\ncapabilities of LLMs on 7 tasks across the domain spectrum of semantic parsing,\nmath reasoning and Python programming, analyzing the factors that potentially\naffect their performance, such as model size, pretraining data, instruction\ntuning, and different prompting methods. In addition to assessing model\nperformance, we measure confidence calibration for the models and conduct human\nevaluations of the output programs. This enables us to identify and analyze the\ntypical failure modes across various tasks and models. L2CEval offers a\ncomprehensive understanding of the capabilities and limitations of LLMs in\nlanguage-to-code generation. We also release the evaluation framework and all\nmodel outputs, hoping to lay the groundwork for further future research in this\ndomain.",
        "translated": "最近，大型语言模型(LLM) ，尤其是那些经过代码预训练的模型，已经展示了强大的能力，可以通过少量输入甚至零输入的方式从自然语言输入生成程序。尽管取得了一些有希望的结果，但是对于这些模型的语言到代码的生成能力还缺乏全面的评估。现有的研究往往集中在特定的任务、模型架构或者学习范式上，导致对整体环境的理解支离破碎。在这项工作中，我们提出了 L2CEval，一个系统的评估语言到代码的生成能力 LLM 的7个任务的领域范围的语义解析，数学推理和 Python 编程，分析潜在影响他们的性能的因素，如模型大小，预训练数据，指令调优，和不同的提示方法。除了评估模型的性能，我们还测量模型的置信度校准，并对输出程序进行人工评估。这使我们能够识别和分析各种任务和模型中的典型故障模式。L2CEval 提供了对 LLM 在语言到代码生成中的能力和局限性的全面理解。我们也发布了评估框架和所有的模型输出，希望能够为今后该领域的进一步研究奠定基础。"
    },
    {
        "title": "LLM-grounded Video Diffusion Models",
        "url": "http://arxiv.org/abs/2309.17444v1",
        "pub_date": "2023-09-29",
        "summary": "Text-conditioned diffusion models have emerged as a promising tool for neural\nvideo generation. However, current models still struggle with intricate\nspatiotemporal prompts and often generate restricted or incorrect motion (e.g.,\neven lacking the ability to be prompted for objects moving from left to right).\nTo address these limitations, we introduce LLM-grounded Video Diffusion (LVD).\nInstead of directly generating videos from the text inputs, LVD first leverages\na large language model (LLM) to generate dynamic scene layouts based on the\ntext inputs and subsequently uses the generated layouts to guide a diffusion\nmodel for video generation. We show that LLMs are able to understand complex\nspatiotemporal dynamics from text alone and generate layouts that align closely\nwith both the prompts and the object motion patterns typically observed in the\nreal world. We then propose to guide video diffusion models with these layouts\nby adjusting the attention maps. Our approach is training-free and can be\nintegrated into any video diffusion model that admits classifier guidance. Our\nresults demonstrate that LVD significantly outperforms its base video diffusion\nmodel and several strong baseline methods in faithfully generating videos with\nthe desired attributes and motion patterns.",
        "translated": "文本条件扩散模型已经成为神经视频生成的一种有前途的工具。然而，目前的模型仍然挣扎于复杂的时空提示，并且经常产生受限制或不正确的运动(例如，甚至缺乏提示物体从左向右移动的能力)。为了解决这些限制，我们引入了基于 LLM 的视频扩散(LVD)。LVD 首先利用大型语言模型(LLM)生成基于文本输入的动态场景布局，然后使用生成的布局指导视频生成的扩散模型，而不是直接从文本输入生成视频。我们证明 LLM 能够仅从文本中理解复杂的时空动力学，并生成与现实世界中典型观察到的提示和对象运动模式紧密对应的布局。然后，我们建议通过调整注意力映射来指导这些布局的视频扩散模型。我们的方法是免训练的，可以集成到任何视频扩散模型，允许分类器指导。我们的研究结果表明，LVD 在忠实地生成具有所需属性和运动模式的视频方面显著优于其基本的视频扩散模型和几种强基线方法。"
    },
    {
        "title": "CRAFT: Customizing LLMs by Creating and Retrieving from Specialized\n  Toolsets",
        "url": "http://arxiv.org/abs/2309.17428v1",
        "pub_date": "2023-09-29",
        "summary": "Large language models (LLMs) are often augmented with tools to solve complex\ntasks. By generating code snippets and executing them through task-specific\nApplication Programming Interfaces (APIs), they can offload certain functions\nto dedicated external modules, such as image encoding and performing\ncalculations. However, most existing approaches to augment LLMs with tools are\nconstrained by general-purpose APIs and lack the flexibility for tailoring them\nto specific tasks. In this work, we present CRAFT, a general tool creation and\nretrieval framework for LLMs. It creates toolsets specifically curated for the\ntasks and equips LLMs with a component that retrieves tools from these sets to\nenhance their capability to solve complex tasks. For each task, we collect\nspecific code solutions by prompting GPT-4 to solve the training examples.\nFollowing a validation step ensuring the correctness, these solutions are\nabstracted into code snippets to enhance reusability, and deduplicated for\nhigher quality. At inference time, the language model retrieves snippets from\nthe toolsets and then executes them or generates the output conditioning on the\nretrieved snippets. Our method is designed to be flexible and offers a\nplug-and-play approach to adapt off-the-shelf LLMs to unseen domains and\nmodalities, without any finetuning. Experiments on vision-language, tabular\nprocessing, and mathematical reasoning tasks show that our approach achieves\nsubstantial improvements compared to strong baselines. In addition, our\nin-depth analysis reveals that: (1) consistent performance improvement can be\nachieved by scaling up the number of tools and the capability of the backbone\nmodels; (2) each component of our approach contributes to the performance\ngains; (3) the created tools are well-structured and reliable with low\ncomplexity and atomicity. The code is available at\n\\url{https://github.com/lifan-yuan/CRAFT}.",
        "translated": "大型语言模型(LLM)经常被用来解决复杂任务的工具所增强。通过生成代码片段并通过特定于任务的应用程序编程接口(API)执行它们，它们可以将某些函数卸载到专用的外部模块，例如图像编码和执行计算。然而，用工具增强 LLM 的大多数现有方法都受到通用 API 的限制，缺乏根据特定任务裁剪它们的灵活性。在这项工作中，我们提出了 CRAFT，一个通用的工具创建和检索框架的 LLM。它创建专门为任务管理的工具集，并为 LLM 配备一个组件，该组件从这些工具集中检索工具，以增强它们解决复杂任务的能力。对于每个任务，我们通过提示 GPT-4解决培训示例来收集特定的代码解决方案。在确保正确性的验证步骤之后，这些解决方案被抽象为代码片段以提高可重用性，并且为了更高的质量而删除重复数据。在推理时，语言模型从工具集中检索代码段，然后执行它们，或者对检索到的代码段生成输出条件。我们的方法被设计成灵活的，并且提供了一种即插即用的方法来适应现成的 LLM 到不可见的领域和模式，而不需要任何微调。在视觉语言、表格处理和数学推理任务上的实验表明，与强基线相比，我们的方法取得了显著的改进。此外，我们深入的分析表明: (1)通过增加工具的数量和骨干模型的能力，可以实现持续的性能改进; (2)我们方法的每个组成部分都有助于性能提高; (3)创建的工具结构良好，可靠，低复杂性和原子性。该代码可在 url { https://github.com/lifan-yuan/craft }获得。"
    },
    {
        "title": "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
        "url": "http://arxiv.org/abs/2309.17421v1",
        "pub_date": "2023-09-29",
        "summary": "Large multimodal models (LMMs) extend large language models (LLMs) with\nmulti-sensory skills, such as visual understanding, to achieve stronger generic\nintelligence. In this paper, we analyze the latest model, GPT-4V(ision), to\ndeepen the understanding of LMMs. The analysis focuses on the intriguing tasks\nthat GPT-4V can perform, containing test samples to probe the quality and\ngenericity of GPT-4V's capabilities, its supported inputs and working modes,\nand the effective ways to prompt the model. In our approach to exploring\nGPT-4V, we curate and organize a collection of carefully designed qualitative\nsamples spanning a variety of domains and tasks. Observations from these\nsamples demonstrate that GPT-4V's unprecedented ability in processing\narbitrarily interleaved multimodal inputs and the genericity of its\ncapabilities together make GPT-4V a powerful multimodal generalist system.\nFurthermore, GPT-4V's unique capability of understanding visual markers drawn\non input images can give rise to new human-computer interaction methods such as\nvisual referring prompting. We conclude the report with in-depth discussions on\nthe emerging application scenarios and the future research directions for\nGPT-4V-based systems. We hope that this preliminary exploration will inspire\nfuture research on the next-generation multimodal task formulation, new ways to\nexploit and enhance LMMs to solve real-world problems, and gaining better\nunderstanding of multimodal foundation models.",
        "translated": "大型多模态模型(LMM)通过视觉理解等多感官技能扩展了大型语言模型(LLM) ，以实现更强的通用智能。在本文中，我们分析了最新的模型，GPT-4V (vision) ，以加深对 LMM 的理解。分析集中在 GPT-4V 能够执行的有趣的任务上，包含测试样本来探测 GPT-4V 能力的质量和通用性，它支持的输入和工作模式，以及提示模型的有效方法。在我们探索 GPT-4V 的方法中，我们策划并组织了一系列精心设计的定性样本，这些样本跨越了不同的领域和任务。从这些样本的观察表明，GPT-4V 的前所未有的能力，在处理任意交错的多模态输入及其能力的一般性一起使 GPT-4V 成为一个强大的多模态通用系统。此外，GPT-4V 独特的理解输入图像上的视觉标记的能力，可以产生新的人机交互方法，例如视觉提示。在报告的最后，我们对基于 GPT-4V 系统的新兴应用场景和未来研究方向进行了深入的讨论。我们希望这个初步的探索将激励未来对下一代多模态任务制定、利用和增强 LMM 以解决现实世界问题的新方法的研究，以及更好地理解多模态基础模型。"
    },
    {
        "title": "Intuitive or Dependent? Investigating LLMs' Robustness to Conflicting\n  Prompts",
        "url": "http://arxiv.org/abs/2309.17415v1",
        "pub_date": "2023-09-29",
        "summary": "This paper explores the robustness of LLMs' preference to their internal\nmemory or the given prompt, which may contain contrasting information in\nreal-world applications due to noise or task settings. To this end, we\nestablish a quantitative benchmarking framework and conduct the role playing\nintervention to control LLMs' preference. In specific, we define two types of\nrobustness, factual robustness targeting the ability to identify the correct\nfact from prompts or memory, and decision style to categorize LLMs' behavior in\nmaking consistent choices -- assuming there is no definitive \"right\" answer --\nintuitive, dependent, or rational based on cognitive theory. Our findings,\nderived from extensive experiments on seven open-source and closed-source LLMs,\nreveal that these models are highly susceptible to misleading prompts,\nespecially for instructing commonsense knowledge. While detailed instructions\ncan mitigate the selection of misleading answers, they also increase the\nincidence of invalid responses. After Unraveling the preference, we intervene\ndifferent sized LLMs through specific style of role instruction, showing their\nvarying upper bound of robustness and adaptivity.",
        "translated": "本文探讨了 LLM 偏好对内存或给定提示的鲁棒性，在现实应用中，由于噪声或任务设置，LLM 偏好可能包含对比信息。为此，我们建立了一个量化基准框架，并进行了角色扮演干预，以控制有限责任模型的偏好。具体来说，我们定义了两种类型的稳健性，针对从提示或记忆中识别正确事实的能力的事实稳健性，以及基于认知理论对 LLM 在做出一致选择时的行为进行分类的决策风格——假设没有明确的“正确”答案——直觉的、依赖的或理性的。我们的研究结果来自于对七个开源和闭源 LLM 的大量实验，揭示了这些模型非常容易受到误导性提示的影响，特别是在指导常识性知识方面。虽然详细的说明可以减少误导性答案的选择，但也增加了无效答案的发生率。在揭示偏好之后，我们通过特定的角色指令风格介入不同大小的 LLM，显示它们不同的鲁棒性和适应性上限。"
    },
    {
        "title": "Can Sensitive Information Be Deleted From LLMs? Objectives for Defending\n  Against Extraction Attacks",
        "url": "http://arxiv.org/abs/2309.17410v1",
        "pub_date": "2023-09-29",
        "summary": "Pretrained language models sometimes possess knowledge that we do not wish\nthem to, including memorized personal information and knowledge that could be\nused to harm people. They can also output toxic or harmful text. To mitigate\nthese safety and informational issues, we propose an attack-and-defense\nframework for studying the task of deleting sensitive information directly from\nmodel weights. We study direct edits to model weights because (1) this approach\nshould guarantee that particular deleted information is never extracted by\nfuture prompt attacks, and (2) it should protect against whitebox attacks,\nwhich is necessary for making claims about safety/privacy in a setting where\npublicly available model weights could be used to elicit sensitive information.\nOur threat model assumes that an attack succeeds if the answer to a sensitive\nquestion is located among a set of B generated candidates, based on scenarios\nwhere the information would be insecure if the answer is among B candidates.\nExperimentally, we show that even state-of-the-art model editing methods such\nas ROME struggle to truly delete factual information from models like GPT-J, as\nour whitebox and blackbox attacks can recover \"deleted\" information from an\nedited model 38% of the time. These attacks leverage two key observations: (1)\nthat traces of deleted information can be found in intermediate model hidden\nstates, and (2) that applying an editing method for one question may not delete\ninformation across rephrased versions of the question. Finally, we provide new\ndefense methods that protect against some extraction attacks, but we do not\nfind a single universally effective defense method. Our results suggest that\ntruly deleting sensitive information is a tractable but difficult problem,\nsince even relatively low attack success rates have potentially severe societal\nimplications for real-world deployment of language models.",
        "translated": "预先训练的语言模型有时拥有我们不希望他们拥有的知识，包括记忆的个人信息和可能用来伤害人的知识。它们还可以输出有毒或有害的文本。为了缓解这些安全和信息问题，我们提出了一个攻防框架，用于研究直接从模型权重中删除敏感信息的任务。我们研究对模型权重的直接编辑，因为(1)这种方法应该保证特定删除的信息永远不会被未来的提示攻击提取，(2)它应该防止白盒攻击，这对于在一个公开可用的模型权重可用于引发敏感信息的设置中声称安全/隐私是必要的。我们的威胁模型假设，如果一个敏感问题的答案位于一组 B 生成的候选者之中，那么攻击就会成功，这是基于如果答案位于 B 候选者之中，那么信息将是不安全的。实验表明，即使是最先进的模型编辑方法，比如 ROME，也很难从 GPT-J 这样的模型中真正删除事实信息，因为我们的白盒和黑盒攻击可以在38% 的时间里从编辑过的模型中恢复“删除”的信息。这些攻击利用了两个关键的观察: (1)在中间模型隐藏状态下可以找到被删除信息的踪迹; (2)对一个问题应用编辑方法可能不会在问题的改写版本中删除信息。最后，我们提供了新的防御方法来抵御一些抽取攻击，但是我们没有找到一个单一的普遍有效的防御方法。我们的研究结果表明，真正删除敏感信息是一个容易处理但困难的问题，因为即使相对较低的攻击成功率也可能对现实世界中语言模型的部署产生严重的社会影响。"
    },
    {
        "title": "Overview of the BioLaySumm 2023 Shared Task on Lay Summarization of\n  Biomedical Research Articles",
        "url": "http://arxiv.org/abs/2309.17332v1",
        "pub_date": "2023-09-29",
        "summary": "This paper presents the results of the shared task on Lay Summarisation of\nBiomedical Research Articles (BioLaySumm), hosted at the BioNLP Workshop at ACL\n2023. The goal of this shared task is to develop abstractive summarisation\nmodels capable of generating \"lay summaries\" (i.e., summaries that are\ncomprehensible to non-technical audiences) in both a controllable and\nnon-controllable setting. There are two subtasks: 1) Lay Summarisation, where\nthe goal is for participants to build models for lay summary generation only,\ngiven the full article text and the corresponding abstract as input; and 2)\nReadability-controlled Summarisation, where the goal is for participants to\ntrain models to generate both the technical abstract and the lay summary, given\nan article's main text as input. In addition to overall results, we report on\nthe setup and insights from the BioLaySumm shared task, which attracted a total\nof 20 participating teams across both subtasks.",
        "translated": "本文介绍了在2023年美国学术期刊会议(ACL 2023)上举办的 BionLP 研讨会上共同完成的关于生物医学研究文章平面总结的任务(BioLaySumm)的结果。这个共享任务的目标是开发抽象的摘要模型，能够在可控和不可控的环境下生成“非技术受众可以理解的摘要”(即摘要)。这里有两个子任务: 1)进行总结，目标是让参与者建立模型，只生成非专业的总结，给定文章的全文和相应的摘要作为输入; 2)可读性控制的总结，目标是让参与者训练模型生成技术摘要和非专业的总结，给定文章的主要文本作为输入。除了总体结果之外，我们还报告了 BioLaySumm 共享任务的设置和见解，这两个子任务共吸引了20个参与团队。"
    },
    {
        "title": "CORec-Cri: How collaborative and social technologies can help to\n  contextualize crises?",
        "url": "http://arxiv.org/abs/2310.02143v1",
        "pub_date": "2023-10-03",
        "summary": "Crisis situations can present complex and multifaceted challenges, often\nrequiring the involvement of multiple organizations and stakeholders with\nvarying areas of expertise, responsibilities, and resources. Acquiring accurate\nand timely information about impacted areas is crucial to effectively respond\nto these crises. In this paper, we investigate how collaborative and social\ntechnologies help to contextualize crises, including identifying impacted areas\nand real-time needs. To this end, we define CORec-Cri (Contextulized\nOntology-based Recommender system for crisis management) based on existing\nwork. Our motivation for this approach is two-fold: first, effective\ncollaboration among stakeholders is essential for efficient and coordinated\ncrisis response; second, social computing facilitates interaction, information\nflow, and collaboration among stakeholders. We detail the key components of our\nsystem design, highlighting its potential to support decision-making, resource\nallocation, and communication among stakeholders. Finally, we provide examples\nof how our system can be applied to contextualize crises to improve crisis\nmanagement.",
        "translated": "危机情况可能带来复杂和多方面的挑战，往往需要多个组织和利益相关者的参与，这些组织和利益相关者具有不同的专业知识、责任和资源领域。获得关于受影响地区的准确和及时的信息对于有效应对这些危机至关重要。在本文中，我们研究了协作和社会技术如何帮助将危机情境化，包括识别受影响的领域和实时需求。为此，我们在现有工作的基础上定义了 COrec-cri (基于上下文本体的危机管理推荐系统)。我们采用这种方法的动机是双重的: 首先，利益相关者之间的有效协作对于有效和协调的危机应对至关重要; 其次，社会计算促进了利益相关者之间的交互、信息流和协作。我们详细介绍了系统设计的关键组成部分，强调了系统支持决策、资源分配和利益相关者之间沟通的潜力。最后，我们举例说明我们的系统如何应用于情境化的危机，以改善危机管理。"
    },
    {
        "title": "Online Multimedia Verification with Computational Tools and OSINT:\n  Russia-Ukraine Conflict Case Studies",
        "url": "http://arxiv.org/abs/2310.01978v1",
        "pub_date": "2023-10-03",
        "summary": "This paper investigates the use of computational tools and Open-Source\nIntelligence (OSINT) techniques for verifying online multimedia content, with a\nspecific focus on real-world cases from the Russia-Ukraine conflict. Over a\nnine-month period from April to December 2022, we examine verification\nworkflows, tools, and case studies published by \\faktiskbar. Our study\nshowcases the effectiveness of diverse resources, including AI tools,\ngeolocation tools, internet archives, and social media monitoring platforms, in\nenabling journalists and fact-checkers to efficiently process and corroborate\nevidence, ensuring the dissemination of accurate information. This research\nunderscores the vital role of computational tools and OSINT techniques in\npromoting evidence-based reporting and combatting misinformation. We also touch\non the current limitations of available tools and prospects for future\ndevelopments in multimedia verification.",
        "translated": "本文研究了使用计算工具和开放来源情报(OSINT)技术来验证在线多媒体内容，特别关注俄罗斯-乌克兰冲突中的现实案例。在2022年4月至12月的9个月期间，我们研究了 faktiskbar 发布的验证工作流、工具和案例研究。我们的研究展示了包括人工智能工具，地理定位工具，互联网档案和社交媒体监测平台在内的各种资源的有效性，使记者和事实核查人员能够有效地处理和证实证据，确保传播准确的信息。这项研究强调了计算工具和 OSINT 技术在促进循证报告和打击错误信息方面的重要作用。我们还谈到现有工具的当前局限性以及多媒体核查的未来发展前景。"
    },
    {
        "title": "DANI: Fast Diffusion Aware Network Inference with Preserving Topological\n  Structure Property",
        "url": "http://arxiv.org/abs/2310.01696v1",
        "pub_date": "2023-10-02",
        "summary": "The fast growth of social networks and their data access limitations in\nrecent years has led to increasing difficulty in obtaining the complete\ntopology of these networks. However, diffusion information over these networks\nis available, and many algorithms have been proposed to infer the underlying\nnetworks using this information. The previously proposed algorithms only focus\non inferring more links and ignore preserving the critical topological\ncharacteristics of the underlying social networks. In this paper, we propose a\nnovel method called DANI to infer the underlying network while preserving its\nstructural properties. It is based on the Markov transition matrix derived from\ntime series cascades, as well as the node-node similarity that can be observed\nin the cascade behavior from a structural point of view. In addition, the\npresented method has linear time complexity (increases linearly with the number\nof nodes, number of cascades, and square of the average length of cascades),\nand its distributed version in the MapReduce framework is also scalable. We\napplied the proposed approach to both real and synthetic networks. The\nexperimental results showed that DANI has higher accuracy and lower run time\nwhile maintaining structural properties, including modular structure, degree\ndistribution, connected components, density, and clustering coefficients, than\nwell-known network inference methods.",
        "translated": "近年来，社交网络的快速发展及其数据访问限制使得获得这些网络的完整拓扑结构变得越来越困难。然而，这些网络上的扩散信息是可利用的，许多算法已被提出来推断基础网络使用这些信息。先前提出的算法只关注于推断更多的链接，而忽略了保持底层社会网络的关键拓扑特征。在本文中，我们提出了一种新的方法称为 DANI 推断的基础网络，同时保留其结构性质。它基于从时间序列级联推导出的马尔可夫转移矩阵，以及从结构角度观察到的级联行为中的节点-节点相似性。此外，该方法具有线性时间复杂度(随节点数、级联数和平均级联长度的平方而线性增加) ，在 MapReduce 框架下的分布式版本也具有可扩展性。我们将提出的方法应用于实际网络和合成网络。实验结果表明，DANI 在保持结构特性(包括模块化结构、度分布、连通分量、密度和聚类系数)的同时，具有较高的精度和较低的运行时间。"
    },
    {
        "title": "Towards Efficient and Effective Adaptation of Large Language Models for\n  Sequential Recommendation",
        "url": "http://arxiv.org/abs/2310.01612v1",
        "pub_date": "2023-10-02",
        "summary": "In recent years, with large language models (LLMs) achieving state-of-the-art\nperformance in context understanding, increasing efforts have been dedicated to\ndeveloping LLM-enhanced sequential recommendation (SR) methods. Considering\nthat most existing LLMs are not specifically optimized for recommendation\ntasks, adapting them for SR becomes a critical step in LLM-enhanced SR methods.\nThough numerous adaptation methods have been developed, it still remains a\nsignificant challenge to adapt LLMs for SR both efficiently and effectively. To\naddress this challenge, in this paper, we introduce a novel side sequential\nnetwork adaptation method, denoted as SSNA, for LLM enhanced SR. SSNA features\nthree key designs to allow both efficient and effective LLM adaptation. First,\nSSNA learns adapters separate from LLMs, while fixing all the pre-trained\nparameters within LLMs to allow efficient adaptation. In addition, SSNA adapts\nthe top-a layers of LLMs jointly, and integrates adapters sequentially for\nenhanced effectiveness (i.e., recommendation performance). We compare SSNA\nagainst five state-of-the-art baseline methods on five benchmark datasets using\nthree LLMs. The experimental results demonstrate that SSNA significantly\noutperforms all the baseline methods in terms of recommendation performance,\nand achieves substantial improvement over the best-performing baseline methods\nat both run-time and memory efficiency during training. Our analysis shows the\neffectiveness of integrating adapters in a sequential manner. Our parameter\nstudy demonstrates the effectiveness of jointly adapting the top-a layers of\nLLMs.",
        "translated": "近年来，随着大型语言模型(LLM)在上下文理解方面实现了最先进的性能，人们越来越多地致力于开发 LLM 增强的顺序推荐(SR)方法。考虑到大多数现有的 LLM 并没有专门针对推荐任务进行优化，因此将它们适应于 SR 成为 LLM 增强 SR 方法中的一个关键步骤。尽管已经开发出了许多适应方法，但是如何有效和高效地使 LLM 适应 SR 仍然是一个巨大的挑战。为了解决这一问题，本文提出了一种新的边序贯网络自适应方法，称为 SSNA，用于 LLM 增强的 SR。SSNA 具有三个关键设计，以便能够高效和有效地进行 LLM 适应。首先，SSNA 学习与 LLM 分离的适配器，同时固定 LLM 中所有预先训练的参数以允许有效的适配。此外，SSNA 还联合适用 LLM 的顶层，并按顺序集成适配器以提高效率(即推荐性能)。我们使用三个 LLM 对五个基准数据集上的五种最先进的基线方法与 SSNA 进行了比较。实验结果表明，SSNA 在推荐性能方面明显优于所有的基线方法，并且在训练过程中在运行时和内存效率方面都比性能最好的基线方法有显著的提高。我们的分析显示了以顺序方式集成适配器的有效性。我们的参数研究证明了联合适应的有效性顶层的 LLM。"
    },
    {
        "title": "Causality-informed Rapid Post-hurricane Building Damage Detection in\n  Large Scale from InSAR Imagery",
        "url": "http://arxiv.org/abs/2310.01565v1",
        "pub_date": "2023-10-02",
        "summary": "Timely and accurate assessment of hurricane-induced building damage is\ncrucial for effective post-hurricane response and recovery efforts. Recently,\nremote sensing technologies provide large-scale optical or Interferometric\nSynthetic Aperture Radar (InSAR) imagery data immediately after a disastrous\nevent, which can be readily used to conduct rapid building damage assessment.\nCompared to optical satellite imageries, the Synthetic Aperture Radar can\npenetrate cloud cover and provide more complete spatial coverage of damaged\nzones in various weather conditions. However, these InSAR imageries often\ncontain highly noisy and mixed signals induced by co-occurring or co-located\nbuilding damage, flood, flood/wind-induced vegetation changes, as well as\nanthropogenic activities, making it challenging to extract accurate building\ndamage information. In this paper, we introduced an approach for rapid\npost-hurricane building damage detection from InSAR imagery. This approach\nencoded complex causal dependencies among wind, flood, building damage, and\nInSAR imagery using a holistic causal Bayesian network. Based on the causal\nBayesian network, we further jointly inferred the large-scale unobserved\nbuilding damage by fusing the information from InSAR imagery with prior\nphysical models of flood and wind, without the need for ground truth labels.\nFurthermore, we validated our estimation results in a real-world devastating\nhurricane -- the 2022 Hurricane Ian. We gathered and annotated building damage\nground truth data in Lee County, Florida, and compared the introduced method's\nestimation results with the ground truth and benchmarked it against\nstate-of-the-art models to assess the effectiveness of our proposed method.\nResults show that our method achieves rapid and accurate detection of building\ndamage, with significantly reduced processing time compared to traditional\nmanual inspection methods.",
        "translated": "及时和准确地评估飓风引起的建筑物损坏对于飓风后有效的反应和恢复工作至关重要。最近，遥感技术可以在灾难性事件发生后立即提供大规模的光学或干涉合成孔径雷达(inSAR)图像数据，这些数据可以很容易地用于进行快速的建筑物损害评估。与光学卫星图像相比，合成孔径雷达可以穿透云层，在各种天气条件下提供更完整的受损区域空间覆盖。然而，这些 InSAR 图像往往包含高噪声和混合信号，这些信号是由同时发生或同地发生的建筑物损坏、洪水、洪水/风引起的植被变化以及人为活动引起的，因此提取准确的建筑物损坏信息具有挑战性。本文介绍了一种基于 InSAR 图像的飓风后建筑物损伤快速检测方法。这种方法使用整体因果贝氏网路编码了风、洪水、建筑物损坏和干涉合成孔径雷达图像之间复杂的因果关系。基于因果贝氏网路，我们进一步联合推断大规模未观测到的建筑物损坏，方法是将来自干涉合成孔径雷达图像的信息与先前的洪水和风的物理模型相融合，而不需要地面真实性标签。此外，我们验证了我们的估计结果在一个现实世界的破坏性飓风-2022年飓风伊恩。我们收集并注释了佛罗里达州李县的建筑损坏地面真实数据，并将引入的方法的估计结果与地面真实数据进行比较，并将其与最先进的模型进行比较，以评估我们提出的方法的有效性。结果表明，与传统的人工检测方法相比，该方法能够快速、准确地检测建筑物损伤，大大缩短了处理时间。"
    },
    {
        "title": "Contrastive Post-training Large Language Models on Data Curriculum",
        "url": "http://arxiv.org/abs/2310.02263v1",
        "pub_date": "2023-10-03",
        "summary": "Alignment serves as an important step to steer large language models (LLMs)\ntowards human preferences. In this paper, we explore contrastive post-training\ntechniques for alignment by automatically constructing preference pairs from\nmultiple models of varying strengths (e.g., InstructGPT, ChatGPT and GPT-4). We\ncarefully compare the contrastive techniques of SLiC and DPO to SFT baselines\nand find that DPO provides a step-function improvement even after continueing\nSFT saturates. We also explore a data curriculum learning scheme for\ncontrastive post-training, which starts by learning from \"easier\" pairs and\ntransitioning to \"harder\" ones, which further improves alignment. Finally, we\nscale up our experiments to train with more data and larger models like Orca.\nRemarkably, contrastive post-training further improves the performance of Orca,\nalready a state-of-the-art instruction learning model tuned with GPT-4 outputs,\nto exceed that of ChatGPT.",
        "translated": "对齐是将大型语言模型(LLM)引向人类偏好的一个重要步骤。在本文中，我们通过自动构建多个不同优势模型的偏好对来探索对比性的排序后训练技术(例如，DirectGPT，ChatGPT 和 GPT-4)。我们仔细比较了 SLiC 和 DPO 与 SFT 基线的对比技术，发现即使在 SFT 饱和后，DPO 仍然提供了阶跃功能的改善。我们还探索了一个数据课程学习方案的对比后训练，其中开始学习从“更容易”对和过渡到“更难”的，这将进一步改善调整。最后，我们扩大了实验规模，用更多的数据和更大的模型(如虎鲸)进行训练。值得注意的是，对比后培训进一步提高了 Orca 的性能，已经是一个国家的最先进的教学学习模式调整了 GPT-4输出，超过了 ChatGPT。"
    },
    {
        "title": "Generalizable Long-Horizon Manipulations with Large Language Models",
        "url": "http://arxiv.org/abs/2310.02264v1",
        "pub_date": "2023-10-03",
        "summary": "This work introduces a framework harnessing the capabilities of Large\nLanguage Models (LLMs) to generate primitive task conditions for generalizable\nlong-horizon manipulations with novel objects and unseen tasks. These task\nconditions serve as guides for the generation and adjustment of Dynamic\nMovement Primitives (DMP) trajectories for long-horizon task execution. We\nfurther create a challenging robotic manipulation task suite based on Pybullet\nfor long-horizon task evaluation. Extensive experiments in both simulated and\nreal-world environments demonstrate the effectiveness of our framework on both\nfamiliar tasks involving new objects and novel but related tasks, highlighting\nthe potential of LLMs in enhancing robotic system versatility and adaptability.\nProject website: https://object814.github.io/Task-Condition-With-LLM/",
        "translated": "这项工作介绍了一个框架，利用大型语言模型(LLM)的能力，以生成原始的任务条件，可推广的长期操作与新的对象和看不见的任务。这些任务条件作为指导生成和调整的动态运动原语(DMP)轨迹的长期任务执行。我们进一步创建了一个基于 Pybullet 的具有挑战性的机器人操作任务套件，用于长期任务评估。在模拟和现实环境中的大量实验证明了我们的框架在涉及新对象的熟悉任务和新颖但相关的任务上的有效性，突出了 LLM 在增强机器人系统通用性和适应性方面的潜力。项目网页:  https://object814.github.io/task-condition-with-llm/"
    },
    {
        "title": "MathVista: Evaluating Mathematical Reasoning of Foundation Models in\n  Visual Contexts",
        "url": "http://arxiv.org/abs/2310.02255v1",
        "pub_date": "2023-10-03",
        "summary": "Although Large Language Models (LLMs) and Large Multimodal Models (LMMs)\nexhibit impressive skills in various domains, their ability for mathematical\nreasoning within visual contexts has not been formally examined. Equipping LLMs\nand LMMs with this capability is vital for general-purpose AI assistants and\nshowcases promising potential in education, data analysis, and scientific\ndiscovery. To bridge this gap, we present MathVista, a benchmark designed to\namalgamate challenges from diverse mathematical and visual tasks. We first\ntaxonomize the key task types, reasoning skills, and visual contexts from the\nliterature to guide our selection from 28 existing math-focused and visual\nquestion answering datasets. Then, we construct three new datasets, IQTest,\nFunctionQA, and PaperQA, to accommodate for missing types of visual contexts.\nThe problems featured often require deep visual understanding beyond OCR or\nimage captioning, and compositional reasoning with rich domain-specific tools,\nthus posing a notable challenge to existing models. We conduct a comprehensive\nevaluation of 11 prominent open-source and proprietary foundation models (LLMs,\nLLMs augmented with tools, and LMMs), and early experiments with GPT-4V. The\nbest-performing model, Multimodal Bard, achieves only 58% of human performance\n(34.8% vs 60.3%), indicating ample room for further improvement. Given this\nsignificant gap, MathVista fuels future research in the development of\ngeneral-purpose AI agents capable of tackling mathematically intensive and\nvisually rich real-world tasks. Preliminary tests show that MathVista also\npresents challenges to GPT-4V, underscoring the benchmark's importance. The\nproject is available at https://mathvista.github.io/.",
        "translated": "尽管大型语言模型(LLM)和大型多模态模型(LMM)在各个领域展示了令人印象深刻的技能，但是它们在视觉上下文中的数学推理能力还没有得到正式的检验。为 LLM 和 LMM 配备这种能力对于通用 AI 助手至关重要，并展示了在教育、数据分析和科学发现方面的潜力。为了弥补这一差距，我们提出 MathVista，一个基准，旨在融合不同的数学和视觉任务的挑战。我们首先对文献中的关键任务类型、推理技巧和视觉上下文进行分类，以指导我们从现有的28个以数学为中心的可视化问答数据集中进行选择。然后，我们构造了三个新的数据集: IQTest、 FunctionQA 和 PaperQA，以适应缺失类型的视觉上下文。这些问题往往需要超越 OCR 或图像字幕的深入视觉理解，以及使用丰富的领域特定工具进行组合推理，从而对现有模型提出了显著的挑战。我们对11个著名的开源和专有基础模型(LLM、工具增强的 LLM 和 LMM)进行了全面评估，并对 GPT-4V 进行了早期实验。表现最好的模型 MultimodalBard 仅达到人类表现的58% (34.8% 比60.3%) ，表明进一步改进的空间很大。鉴于这一巨大的差距，MathVista 推动了未来开发通用 AI 代理的研究，这些代理能够处理数学密集型和视觉丰富的现实世界任务。初步测试显示 MathVista 也对 GPT-4V 提出了挑战，突出了基准的重要性。该项目可在 https://mathvista.github.io/下载。"
    },
    {
        "title": "Harnessing Pre-Trained Sentence Transformers for Offensive Language\n  Detection in Indian Languages",
        "url": "http://arxiv.org/abs/2310.02249v1",
        "pub_date": "2023-10-03",
        "summary": "In our increasingly interconnected digital world, social media platforms have\nemerged as powerful channels for the dissemination of hate speech and offensive\ncontent. This work delves into the domain of hate speech detection, placing\nspecific emphasis on three low-resource Indian languages: Bengali, Assamese,\nand Gujarati. The challenge is framed as a text classification task, aimed at\ndiscerning whether a tweet contains offensive or non-offensive content.\nLeveraging the HASOC 2023 datasets, we fine-tuned pre-trained BERT and SBERT\nmodels to evaluate their effectiveness in identifying hate speech. Our findings\nunderscore the superiority of monolingual sentence-BERT models, particularly in\nthe Bengali language, where we achieved the highest ranking. However, the\nperformance in Assamese and Gujarati languages signifies ongoing opportunities\nfor enhancement. Our goal is to foster inclusive online spaces by countering\nhate speech proliferation.",
        "translated": "在我们日益相互关联的数字世界中，社交媒体平台已成为传播仇恨言论和攻击性内容的有力渠道。这项工作深入研究了仇恨言论检测领域，特别强调了三种资源匮乏的印度语言: 孟加拉语、阿萨姆语和 Gujarati 语。这项挑战被设定为一项文本分类任务，目的是辨别一条推文是否包含攻击性内容。利用 HASOC 2023数据集，我们对预先训练好的 BERT 和 SBERT 模型进行了微调，以评估它们在识别仇恨言论方面的有效性。我们的研究结果强调了单语句子—— BERT 模型的优越性，尤其是在我们获得最高排名的孟加拉语。然而，在阿萨姆语和 Gujarati 语言的表现意味着不断提高的机会。我们的目标是通过打击仇恨言论的扩散来促进包容性网络空间。"
    },
    {
        "title": "Who's Harry Potter? Approximate Unlearning in LLMs",
        "url": "http://arxiv.org/abs/2310.02238v2",
        "pub_date": "2023-10-03",
        "summary": "Large language models (LLMs) are trained on massive internet corpora that\noften contain copyrighted content. This poses legal and ethical challenges for\nthe developers and users of these models, as well as the original authors and\npublishers. In this paper, we propose a novel technique for unlearning a subset\nof the training data from a LLM, without having to retrain it from scratch.\n  We evaluate our technique on the task of unlearning the Harry Potter books\nfrom the Llama2-7b model (a generative language model recently open-sourced by\nMeta). While the model took over 184K GPU-hours to pretrain, we show that in\nabout 1 GPU hour of finetuning, we effectively erase the model's ability to\ngenerate or recall Harry Potter-related content, while its performance on\ncommon benchmarks (such as Winogrande, Hellaswag, arc, boolq and piqa) remains\nalmost unaffected. We make our fine-tuned model publicly available on\nHuggingFace for community evaluation. To the best of our knowledge, this is the\nfirst paper to present an effective technique for unlearning in generative\nlanguage models.\n  Our technique consists of three main components: First, we use a reinforced\nmodel that is further trained on the target data to identify the tokens that\nare most related to the unlearning target, by comparing its logits with those\nof a baseline model. Second, we replace idiosyncratic expressions in the target\ndata with generic counterparts, and leverage the model's own predictions to\ngenerate alternative labels for every token. These labels aim to approximate\nthe next-token predictions of a model that has not been trained on the target\ndata. Third, we finetune the model on these alternative labels, which\neffectively erases the original text from the model's memory whenever it is\nprompted with its context.",
        "translated": "大型语言模型(LLM)是在通常包含有版权内容的大型互联网语料库上进行训练的。这对这些模型的开发人员和用户以及原始作者和出版商提出了法律和道德上的挑战。在本文中，我们提出了一种新的技术，从 LLM 中去除训练数据的子集，而不必从头再训练它。我们在从 Llama2-7b 模型(Meta 最近开源的生成语言模型)中删除哈利波特系列的任务中评估了我们的技术。虽然该模型需要184k 图形处理器时间进行预训练，但我们表明，在大约1个图形处理器时间的微调中，我们有效地抹去了该模型生成或回忆与《哈利波特》相关内容的能力，而其在通用基准(如 Winogrande、 Hellaswag、 Arc、 boolq 和 piqa)上的表现几乎没有受到影响。我们在 HuggingFace 上公开我们的微调模型，用于社区评估。据我们所知，这是第一篇在生成语言模型中提出有效忘却学习技术的论文。我们的技术由三个主要组成部分组成: 首先，通过比较其 logit 与基线模型的 logit，我们使用对目标数据进一步训练的强化模型来识别与忘记目标最相关的令牌。其次，我们将目标数据中的特殊表达式替换为通用对应表达式，并利用模型自己的预测为每个令牌生成替代标签。这些标签的目的是接近未经目标数据训练的模型的下一个令牌预测。第三，我们在这些替代标签上微调模型，这有效地将原始文本从模型的内存中删除，无论它何时被提示到其上下文。"
    },
    {
        "title": "Automatic Quality Assessment of Wikipedia Articles -- A Systematic\n  Literature Review",
        "url": "http://arxiv.org/abs/2310.02235v1",
        "pub_date": "2023-10-03",
        "summary": "Wikipedia is the world's largest online encyclopedia, but maintaining article\nquality through collaboration is challenging. Wikipedia designed a quality\nscale, but with such a manual assessment process, many articles remain\nunassessed. We review existing methods for automatically measuring the quality\nof Wikipedia articles, identifying and comparing machine learning algorithms,\narticle features, quality metrics, and used datasets, examining 149 distinct\nstudies, and exploring commonalities and gaps in them. The literature is\nextensive, and the approaches follow past technological trends. However,\nmachine learning is still not widely used by Wikipedia, and we hope that our\nanalysis helps future researchers change that reality.",
        "translated": "维基百科是世界上最大的在线百科全书，但是通过协作来保持文章质量是具有挑战性的。维基百科设计了一个质量量表，但使用这样一个手工评估过程，许多文章仍然没有得到评估。我们回顾了现有的自动测量 Wikipedia 文章质量的方法，识别和比较机器学习算法，文章特征，质量指标和使用的数据集，检查了149个不同的研究，并探索其中的共性和差距。文献是广泛的，方法遵循过去的技术趋势。然而，机器学习仍然没有被维基百科广泛应用，我们希望我们的分析能够帮助未来的研究人员改变这一现实。"
    },
    {
        "title": "Extraction of Medication and Temporal Relation from Clinical Text by\n  Harnessing Different Deep Learning Models",
        "url": "http://arxiv.org/abs/2310.02229v1",
        "pub_date": "2023-10-03",
        "summary": "Clinical texts, represented in electronic medical records (EMRs), contain\nrich medical information and are essential for disease prediction, personalised\ninformation recommendation, clinical decision support, and medication pattern\nmining and measurement. Relation extractions between medication mentions and\ntemporal information can further help clinicians better understand the\npatients' treatment history. To evaluate the performances of deep learning (DL)\nand large language models (LLMs) in medication extraction and temporal\nrelations classification, we carry out an empirical investigation of\n\\textbf{MedTem} project using several advanced learning structures including\nBiLSTM-CRF and CNN-BiLSTM for a clinical domain named entity recognition (NER),\nand BERT-CNN for temporal relation extraction (RE), in addition to the\nexploration of different word embedding techniques. Furthermore, we also\ndesigned a set of post-processing roles to generate structured output on\nmedications and the temporal relation. Our experiments show that CNN-BiLSTM\nslightly wins the BiLSTM-CRF model on the i2b2-2009 clinical NER task yielding\n75.67, 77.83, and 78.17 for precision, recall, and F1 scores using Macro\nAverage. BERT-CNN model also produced reasonable evaluation scores 64.48,\n67.17, and 65.03 for P/R/F1 using Macro Avg on the temporal relation extraction\ntest set from i2b2-2012 challenges. Code and Tools from MedTem will be hosted\nat \\url{https://github.com/HECTA-UoM/MedTem}",
        "translated": "以电子病历(EMR)为代表的临床文本包含丰富的医学信息，对于疾病预测、个性化信息推荐、临床决策支持以及药物模式挖掘和测量至关重要。药物提示与时间信息之间的关系提取可以进一步帮助临床医生更好地了解患者的治疗历史。为了评价深度学习(DL)和大语言模型(LLM)在药物提取和时间关系分类中的表现，我们使用几种先进的学习结构，包括临床领域实体识别(NER)的 BiLSTM-CRF 和 CNN-BiLSTM，以及时间关系提取(RE)的 BERT-CNN，对 textbf { MedTem }项目进行了实证研究，并探索了不同的词嵌入技术。此外，我们还设计了一组后处理角色来生成药物和时间关系的结构化输出。我们的实验表明，CNN-BiLSTM 在 i2b2-2009临床 NER 任务中轻微赢得 BiLSTM-CRF 模型，使用宏平均对精确度，召回和 F1评分产生75.67,77.83和78.17。BERT-CNN 模型还对 i2b2-2012挑战的时间关系提取测试集使用 Macro Avg 对 P/R/F1产生了合理的评估分数64.48,67.17和65.03。来自 MedTem 的代码和工具将托管在 url { https://github.com/hecta-uom/MedTem }"
    },
    {
        "title": "Think before you speak: Training Language Models With Pause Tokens",
        "url": "http://arxiv.org/abs/2310.02226v1",
        "pub_date": "2023-10-03",
        "summary": "Language models generate responses by producing a series of tokens in\nimmediate succession: the $(K+1)^{th}$ token is an outcome of manipulating $K$\nhidden vectors per layer, one vector per preceding token. What if instead we\nwere to let the model manipulate say, $K+10$ hidden vectors, before it outputs\nthe $(K+1)^{th}$ token? We operationalize this idea by performing training and\ninference on language models with a (learnable) $\\textit{pause}$ token, a\nsequence of which is appended to the input prefix. We then delay extracting the\nmodel's outputs until the last pause token is seen, thereby allowing the model\nto process extra computation before committing to an answer. We empirically\nevaluate $\\textit{pause-training}$ on decoder-only models of 1B and 130M\nparameters with causal pretraining on C4, and on downstream tasks covering\nreasoning, question-answering, general understanding and fact recall. Our main\nfinding is that inference-time delays show gains when the model is both\npre-trained and finetuned with delays. For the 1B model, we witness gains on 8\nof 9 tasks, most prominently, a gain of $18\\%$ EM score on the QA task of\nSQuAD, $8\\%$ on CommonSenseQA and $1\\%$ accuracy on the reasoning task of\nGSM8k. Our work raises a range of conceptual and practical future research\nquestions on making delayed next-token prediction a widely applicable new\nparadigm.",
        "translated": "语言模型通过连续生成一系列令牌来产生响应: $(K + 1) ^ { th } $令牌是每层操作 $K $隐藏向量的结果，每前一个令牌操作一个向量。如果我们让模型在输出 $(K + 1) ^ { th } $令牌之前操作 $K + 10 $隐藏向量，会怎么样呢？我们通过在语言模型上使用一个(可学习的) $textit { stop } $标记执行训练和推理来实现这个想法，该标记的序列被添加到输入前缀。然后，我们延迟提取模型的输出，直到看到最后一个暂停令牌，从而允许模型在提交答案之前处理额外的计算。在 C4上进行因果预训练的1B 和130M 参数的纯解码器模型上，以及在推理、问答、一般理解和事实回忆等下游任务上，我们进行了实证评估。我们的主要发现是，推理时间延迟显示增益时，模型是预训练和微调与延迟。对于1B 模型，我们见证了9个任务中的8个任务的收益，最显著的是，SQUAD 的 QA 任务收益 $18% $EM 评分，CommonSenseQA 收益 $8% ，GSM8k 的推理任务收益 $1% 。我们的工作提出了一系列的概念和实际的未来研究问题，使延迟下一个令牌预测一个广泛适用的新范式。"
    },
    {
        "title": "Can Language Models be Instructed to Protect Personal Information?",
        "url": "http://arxiv.org/abs/2310.02224v1",
        "pub_date": "2023-10-03",
        "summary": "Large multimodal language models have proven transformative in numerous\napplications. However, these models have been shown to memorize and leak\npre-training data, raising serious user privacy and information security\nconcerns. While data leaks should be prevented, it is also crucial to examine\nthe trade-off between the privacy protection and model utility of proposed\napproaches. In this paper, we introduce PrivQA -- a multimodal benchmark to\nassess this privacy/utility trade-off when a model is instructed to protect\nspecific categories of personal information in a simulated scenario. We also\npropose a technique to iteratively self-moderate responses, which significantly\nimproves privacy. However, through a series of red-teaming experiments, we find\nthat adversaries can also easily circumvent these protections with simple\njailbreaking methods through textual and/or image inputs. We believe PrivQA has\nthe potential to support the development of new models with improved privacy\nprotections, as well as the adversarial robustness of these protections. We\nrelease the entire PrivQA dataset at https://llm-access-control.github.io/.",
        "translated": "大型多模态语言模型在许多应用中已被证明具有变革性。然而，这些模型已经被证明能够记忆和泄露训练前的数据，引起了严重的用户隐私和信息安全问题。虽然应当防止数据泄露，但也必须审查隐私保护与拟议方法的示范效用之间的权衡。在本文中，我们介绍 PrivQA ——一个多模式基准，用于在模拟场景中指示模型保护特定类别的个人信息时，评估这种隐私/效用权衡。我们还提出了一种迭代自我调节响应的技术，它可以显著提高隐私性。然而，通过一系列红队实验，我们发现对手也可以通过简单的破解方法，通过文本和/或图像输入，轻易地绕过这些保护。我们相信 PrivQA 有潜力支持开发具有更好的隐私保护的新模式，以及这些保护的对抗性。我们在 https://llm-access-control.github.io/公布整个 PrivQA 数据集。"
    },
    {
        "title": "Language Models Represent Space and Time",
        "url": "http://arxiv.org/abs/2310.02207v1",
        "pub_date": "2023-10-03",
        "summary": "The capabilities of large language models (LLMs) have sparked debate over\nwhether such systems just learn an enormous collection of superficial\nstatistics or a coherent model of the data generating process -- a world model.\nWe find evidence for the latter by analyzing the learned representations of\nthree spatial datasets (world, US, NYC places) and three temporal datasets\n(historical figures, artworks, news headlines) in the Llama-2 family of models.\nWe discover that LLMs learn linear representations of space and time across\nmultiple scales. These representations are robust to prompting variations and\nunified across different entity types (e.g. cities and landmarks). In addition,\nwe identify individual ``space neurons'' and ``time neurons'' that reliably\nencode spatial and temporal coordinates. Our analysis demonstrates that modern\nLLMs acquire structured knowledge about fundamental dimensions such as space\nand time, supporting the view that they learn not merely superficial\nstatistics, but literal world models.",
        "translated": "大型语言模型(LLM)的功能已经引发了关于这些系统是否只是学习大量表面统计数据的集合或者是一个数据生成过程的连贯模型——一个世界模型的争论。我们通过分析三个空间数据集(世界，美国，纽约城的地方)和三个时间数据集(历史人物，艺术品，新闻标题)在美洲驼 -2家族模型的学习表示发现后者的证据。我们发现 LLM 学习多尺度空间和时间的线性表示。这些表示对于提示不同的实体类型(例如城市和地标)之间的差异和统一是健壮的。此外，我们确定个别的“空间神经元”和“时间神经元”，可靠地编码空间和时间坐标。我们的分析表明，现代 LLM 获得了关于空间和时间等基本维度的结构化知识，支持这样的观点，即它们学习的不仅仅是表面的统计，而是文字世界模型。"
    },
    {
        "title": "Retrieval meets Long Context Large Language Models",
        "url": "http://arxiv.org/abs/2310.03025v1",
        "pub_date": "2023-10-04",
        "summary": "Extending the context window of large language models (LLMs) is getting\npopular recently, while the solution of augmenting LLMs with retrieval has\nexisted for years. The natural questions are: i) Retrieval-augmentation versus\nlong context window, which one is better for downstream tasks? ii) Can both\nmethods be combined to get the best of both worlds? In this work, we answer\nthese questions by studying both solutions using two state-of-the-art\npretrained LLMs, i.e., a proprietary 43B GPT and LLaMA2-70B. Perhaps\nsurprisingly, we find that LLM with 4K context window using simple\nretrieval-augmentation at generation can achieve comparable performance to\nfinetuned LLM with 16K context window via positional interpolation on long\ncontext tasks, while taking much less computation. More importantly, we\ndemonstrate that retrieval can significantly improve the performance of LLMs\nregardless of their extended context window sizes. Our best model,\nretrieval-augmented LLaMA2-70B with 32K context window, outperforms\nGPT-3.5-turbo-16k and Davinci003 in terms of average score on seven long\ncontext tasks including question answering and query-based summarization. It\nalso outperforms its non-retrieval LLaMA2-70B-32k baseline by a margin, while\nbeing much faster at generation. Our study provides general insights on the\nchoice of retrieval-augmentation versus long context extension of LLM for\npractitioners.",
        "translated": "扩展大型语言模型上下文窗口是近年来的研究热点，而扩展大型语言模型上下文窗口的检索方法已经存在多年。自然的问题是: i)检索-增强与长上下文窗口，哪一个更适合下游任务？Ii)这两种方法可以结合起来，以获得最好的两个世界？在这项工作中，我们通过研究两种解决方案来回答这些问题，使用两种最先进的预训练 LLM，即专有的43B GPT 和 LLaMA2-70B。也许令人惊讶的是，我们发现4K 上下文窗口的 LLM 通过在长上下文任务上的位置插值，在生成时使用简单的检索增强，可以达到与16K 上下文窗口的微调 LLM 相当的性能，而且计算量小得多。更重要的是，我们证明了检索可以显著提高 LLM 的性能，而不管它们的扩展上下文窗口大小如何。我们的最佳模型，具有32K 上下文窗口的检索增强 LLaMA2-70B，在7个长上下文任务(包括问题回答和基于查询的摘要)的平均得分方面优于 GPT-3.5-turbo-16k 和 Davinci003。它也优于其非检索 LLaMA2-70B-32k 基线的一个边缘，同时在生成速度更快。我们的研究为从业者选择检索增强与长语境扩展 LLM 提供了一般性的见解。"
    },
    {
        "title": "Potential Factors Leading to Popularity Unfairness in Recommender\n  Systems: A User-Centered Analysis",
        "url": "http://arxiv.org/abs/2310.02961v1",
        "pub_date": "2023-10-04",
        "summary": "Popularity bias is a well-known issue in recommender systems where few\npopular items are over-represented in the input data, while majority of other\nless popular items are under-represented. This disparate representation often\nleads to bias in exposure given to the items in the recommendation results.\nExtensive research examined this bias from item perspective and attempted to\nmitigate it by enhancing the recommendation of less popular items. However, a\nrecent research has revealed the impact of this bias on users. Users with\ndifferent degree of tolerance toward popular items are not fairly served by the\nrecommendation system: users interested in less popular items receive more\npopular items in their recommendations, while users interested in popular items\nare recommended what they want. This is mainly due to the popularity bias that\npopular items are over-recommended. In this paper, we aim at investigating the\nfactors leading to this user-side unfairness of popularity bias in recommender\nsystems. In particular, we investigate two factors: 1) the relationship between\nthis unfairness and users' interest toward items' categories (e.g., movie\ngenres), 2) the relationship between this unfairness and the diversity of the\npopularity group in users' profile (the degree to which the user is interested\nin items with different degree of popularity). Experiments on a movie\nrecommendation dataset using multiple recommendation algorithms show that these\ntwo factors are significantly correlated with the degree of popularity\nunfairness in the recommendation results.",
        "translated": "在推荐系统中，流行度偏差是一个众所周知的问题，在这个系统中，很少有流行项目在输入数据中被过度表示，而大多数其他不太流行的项目被过度表示。这种不同的表示方式常常导致对推荐结果中的项目的暴露存在偏差。广泛的研究从项目的角度考察了这种偏见，并试图通过提高不太受欢迎的项目的推荐来减轻这种偏见。然而，最近的一项研究揭示了这种偏见对用户的影响。对流行项目有不同程度容忍度的用户不能公平地得到推荐系统的服务: 对不那么流行的项目感兴趣的用户会在他们的推荐中得到更受欢迎的项目，而对流行项目感兴趣的用户会得到他们想要的推荐。这主要是由于流行偏见，即热门项目被过分推荐。本文旨在研究导致推荐系统中用户侧流行偏差不公平的因素。具体而言，我们研究了两个因素: 1)这种不公平与用户对项目类别(如电影类型)的兴趣之间的关系; 2)这种不公平与用户资料中流行组的多样性(用户对不同流行程度的项目的兴趣程度)之间的关系。在一个电影推荐数据集上使用多种推荐算法进行的实验表明，这两个因素与推荐结果中的流行度不公平程度显著相关。"
    },
    {
        "title": "Auto-FP: An Experimental Study of Automated Feature Preprocessing for\n  Tabular Data",
        "url": "http://arxiv.org/abs/2310.02540v1",
        "pub_date": "2023-10-04",
        "summary": "Classical machine learning models, such as linear models and tree-based\nmodels, are widely used in industry. These models are sensitive to data\ndistribution, thus feature preprocessing, which transforms features from one\ndistribution to another, is a crucial step to ensure good model quality.\nManually constructing a feature preprocessing pipeline is challenging because\ndata scientists need to make difficult decisions about which preprocessors to\nselect and in which order to compose them. In this paper, we study how to\nautomate feature preprocessing (Auto-FP) for tabular data. Due to the large\nsearch space, a brute-force solution is prohibitively expensive. To address\nthis challenge, we interestingly observe that Auto-FP can be modelled as either\na hyperparameter optimization (HPO) or a neural architecture search (NAS)\nproblem. This observation enables us to extend a variety of HPO and NAS\nalgorithms to solve the Auto-FP problem. We conduct a comprehensive evaluation\nand analysis of 15 algorithms on 45 public ML datasets. Overall,\nevolution-based algorithms show the leading average ranking. Surprisingly, the\nrandom search turns out to be a strong baseline. Many surrogate-model-based and\nbandit-based search algorithms, which achieve good performance for HPO and NAS,\ndo not outperform random search for Auto-FP. We analyze the reasons for our\nfindings and conduct a bottleneck analysis to identify the opportunities to\nimprove these algorithms. Furthermore, we explore how to extend Auto-FP to\nsupport parameter search and compare two ways to achieve this goal. In the end,\nwe evaluate Auto-FP in an AutoML context and discuss the limitations of popular\nAutoML tools. To the best of our knowledge, this is the first study on\nautomated feature preprocessing. We hope our work can inspire researchers to\ndevelop new algorithms tailored for Auto-FP.",
        "translated": "经典的机器学习模型，如线性模型和基于树的模型，在工业中得到了广泛的应用。这些模型对数据分布非常敏感，特征预处理将特征从一个分布转换到另一个分布，是保证模型质量的关键步骤。手工构建一个特征预处理流水线是具有挑战性的，因为数据科学家需要做出困难的决定，选择哪些预处理器，以及以何种顺序组成它们。本文研究了表格数据的特征预处理(Auto-FP)自动化问题。由于搜索空间很大，使用暴力解决方案的成本高得令人望而却步。为了解决这个问题，我们有趣地观察到 Auto-FP 可以被建模为超参数优化(HPO)或神经结构搜索(NAS)问题。这种观察使我们能够扩展各种 HPO 和 NAS 算法来解决 Auto-FP 问题。我们对45个公共机器学习数据集上的15种算法进行了全面的评估和分析。总的来说，基于进化的算法显示了领先的平均排名。令人惊讶的是，随机搜索结果是一个强大的基线。许多基于代理模型和强盗的搜索算法对 HPO 和 NAS 都有很好的性能，但是对 Auto-FP 的性能不如随机搜索。我们分析了我们发现的原因，并进行了瓶颈分析，以确定改进这些算法的机会。此外，我们还探讨了如何扩展 Auto-FP 以支持参数搜索，并比较了两种实现这一目标的方法。最后，我们在 AutoML 环境下对 Auto-FP 进行了评估，并讨论了当前流行的 AutoML 工具的局限性。据我们所知，这是第一次研究自动特征预处理。我们希望我们的工作可以激励研究人员开发新的算法专为自动 FP。"
    },
    {
        "title": "Shaping the Epochal Individuality and Generality: The Temporal Dynamics\n  of Uncertainty and Prediction Error in Musical Improvisation",
        "url": "http://arxiv.org/abs/2310.02518v1",
        "pub_date": "2023-10-04",
        "summary": "Musical improvisation, much like spontaneous speech, reveals intricate facets\nof the improviser's state of mind and emotional character. However, the\nspecific musical components that reveal such individuality remain largely\nunexplored. Within the framework of brain's statistical learning and predictive\nprocessing, this study examined the temporal dynamics of uncertainty and\nsurprise (prediction error) in a piece of musical improvisation. This study\nemployed the HBSL model to analyze a corpus of 456 Jazz improvisations,\nspanning 1905 to 2009, from 78 distinct Jazz musicians. The results indicated\ndistinctive temporal patterns of surprise and uncertainty, especially in pitch\nand pitch-rhythm sequences, revealing era-specific features from the early 20th\nto the 21st centuries. Conversely, rhythm sequences exhibited a consistent\ndegree of uncertainty across eras. Further, the acoustic properties remain\nunchanged across different periods. These findings highlight the importance of\nhow temporal dynamics of surprise and uncertainty in improvisational music\nchange over periods, profoundly influencing the distinctive methodologies\nartists adopt for improvisation in each era. Further, it is suggested that the\ndevelopment of improvisational music can be attributed to the brain's adaptive\nstatistical learning mechanisms, which constantly refine internal models to\nmirror the cultural and emotional nuances of their respective epochs. This\nstudy unravels the evolutionary trajectory of improvisational music and\nhighlights the nuanced shifts artists employ to resonate with the cultural and\nemotional landscapes of their times.",
        "translated": "音乐即兴，就像自发的演讲，揭示了即兴表演者精神状态和情感特征的复杂方面。然而，具体的音乐成分，揭示这种个性仍然在很大程度上未被探索。在大脑统计学习和预测处理的框架内，这项研究检查了一块音乐即兴中不确定性和惊讶(预测错误)的时间动态。这项研究采用 HBSL 模型分析了从1905年到2009年间78位不同的爵士音乐家的456首即兴爵士乐作品。研究结果表明，从20世纪初到21世纪，特别是在音高和音高-节奏序列中，时间上的惊奇和不确定性具有明显的时间模式，揭示了特定时代的特征。相反，节奏序列表现出跨时代的一致程度的不确定性。此外，不同时期的声学特性保持不变。这些发现强调了即兴音乐中惊喜和不确定性的时间动态如何在不同时期发生变化的重要性，深刻地影响了艺术家在每个时代即兴创作中采用的独特方法。此外，即兴音乐的发展可以归因于大脑的适应性统计学习机制，这种机制不断完善内部模型，以反映各自时代的文化和情感细微差别。这项研究揭示了即兴音乐的进化轨迹，并强调了艺术家运用微妙的转变与他们所处时代的文化和情感景观产生共鸣。"
    },
    {
        "title": "Linear Recurrent Units for Sequential Recommendation",
        "url": "http://arxiv.org/abs/2310.02367v1",
        "pub_date": "2023-10-03",
        "summary": "State-of-the-art sequential recommendation relies heavily on\nself-attention-based recommender models. Yet such models are computationally\nexpensive and often too slow for real-time recommendation. Furthermore, the\nself-attention operation is performed at a sequence-level, thereby making\nlow-cost incremental inference challenging. Inspired by recent advances in\nefficient language modeling, we propose linear recurrent units for sequential\nrecommendation (LRURec). Similar to recurrent neural networks, LRURec offers\nrapid inference and can achieve incremental inference on sequential inputs. By\ndecomposing the linear recurrence operation and designing recursive\nparallelization in our framework, LRURec provides the additional benefits of\nreduced model size and parallelizable training. Moreover, we optimize the\narchitecture of LRURec by implementing a series of modifications to address the\nlack of non-linearity and improve training dynamics. To validate the\neffectiveness of our proposed LRURec, we conduct extensive experiments on\nmultiple real-world datasets and compare its performance against\nstate-of-the-art sequential recommenders. Experimental results demonstrate the\neffectiveness of LRURec, which consistently outperforms baselines by a\nsignificant margin. Results also highlight the efficiency of LRURec with our\nparallelized training paradigm and fast inference on long sequences, showing\nits potential to further enhance user experience in sequential recommendation.",
        "translated": "最先进的顺序推荐在很大程度上依赖于基于自我注意的推荐模型。然而，这样的模型在计算上是昂贵的，而且对于实时推荐来说往往太慢了。此外，自我注意操作是在序列级上执行的，因此使得低成本的增量推理具有挑战性。受到最近在有效语言建模方面的进展的启发，我们提出了用于顺序推荐的线性递归单元(LRURec)。类似于递归神经网络，LRURec 提供了快速推理，并可以实现对顺序输入的增量推理。通过在我们的框架中分解线性递归操作和设计递归并行，LRURec 提供了减少模型大小和可并行训练的额外好处。此外，我们通过实现一系列的修改来优化 LRURec 的体系结构，以解决缺乏非线性和改善训练动态性的问题。为了验证我们提出的 LRURec 的有效性，我们在多个真实世界的数据集上进行了广泛的实验，并将其性能与最先进的顺序推荐进行了比较。实验结果证明了 LRURec 算法的有效性，该算法的性能一直大大优于基线算法。结果还突出了 LRURec 的效率与我们的并行训练范式和快速推理的长序列，显示了它的潜力，进一步提高用户体验的顺序推荐。"
    },
    {
        "title": "LanguageMPC: Large Language Models as Decision Makers for Autonomous\n  Driving",
        "url": "http://arxiv.org/abs/2310.03026v1",
        "pub_date": "2023-10-04",
        "summary": "Existing learning-based autonomous driving (AD) systems face challenges in\ncomprehending high-level information, generalizing to rare events, and\nproviding interpretability. To address these problems, this work employs Large\nLanguage Models (LLMs) as a decision-making component for complex AD scenarios\nthat require human commonsense understanding. We devise cognitive pathways to\nenable comprehensive reasoning with LLMs, and develop algorithms for\ntranslating LLM decisions into actionable driving commands. Through this\napproach, LLM decisions are seamlessly integrated with low-level controllers by\nguided parameter matrix adaptation. Extensive experiments demonstrate that our\nproposed method not only consistently surpasses baseline approaches in\nsingle-vehicle tasks, but also helps handle complex driving behaviors even\nmulti-vehicle coordination, thanks to the commonsense reasoning capabilities of\nLLMs. This paper presents an initial step toward leveraging LLMs as effective\ndecision-makers for intricate AD scenarios in terms of safety, efficiency,\ngeneralizability, and interoperability. We aspire for it to serve as\ninspiration for future research in this field. Project page:\nhttps://sites.google.com/view/llm-mpc",
        "translated": "现有的基于学习的自主驾驶(AD)系统在理解高层次信息、概括罕见事件和提供可解释性方面面临挑战。为了解决这些问题，本文使用大型语言模型(LLM)作为复杂 AD 场景的决策组件，这些场景需要人类的常识性理解。我们设计认知路径，使综合推理与 LLM，并开发算法，将 LLM 的决策转化为可操作的驾驶命令。通过这种方法，通过引导参数矩阵自适应，将 LLM 决策与底层控制器无缝集成。大量的实验表明，我们提出的方法不仅在单车任务中始终优于基线方法，而且由于 LLM 的常识推理能力，还有助于处理复杂的驾驶行为，甚至多车协调。本文提出了利用 LLM 作为错综复杂的 AD 场景的有效决策者的初始步骤，涉及到安全性、效率、通用性和互操作性。我们希望它能为今后这一领域的研究提供启示。项目主页:  https://sites.google.com/view/llm-mpc"
    },
    {
        "title": "Zero Resource Code-switched Speech Benchmark Using Speech Utterance\n  Pairs For Multiple Spoken Languages",
        "url": "http://arxiv.org/abs/2310.03018v1",
        "pub_date": "2023-10-04",
        "summary": "We introduce a new zero resource code-switched speech benchmark designed to\ndirectly assess the code-switching capabilities of self-supervised speech\nencoders. We showcase a baseline system of language modeling on discrete units\nto demonstrate how the code-switching abilities of speech encoders can be\nassessed in a zero-resource manner. Our experiments encompass a variety of\nwell-known speech encoders, including Wav2vec 2.0, HuBERT, XLSR, etc. We\nexamine the impact of pre-training languages and model size on benchmark\nperformance. Notably, though our results demonstrate that speech encoders with\nmultilingual pre-training, exemplified by XLSR, outperform monolingual variants\n(Wav2vec 2.0, HuBERT) in code-switching scenarios, there is still substantial\nroom for improvement in their code-switching linguistic abilities.",
        "translated": "本文介绍了一种新的零资源编码转换语音基准，旨在直接评估自监督语音编码器的编码转换能力。我们展示了一个基于离散单元的语言建模系统，以演示如何以零资源的方式评估语音编码器的编码转换能力。我们的实验包括各种著名的语音编码器，包括韦2vec 2.0，HuBERT，XLSR 等。我们研究了预训练语言和模型大小对基准测试性能的影响。值得注意的是，尽管我们的研究结果表明，具有多语言预训练的语音编码器(以 XLSR 为例)在语码转换场景中优于单语言变体(Wav2vec 2.0，HuBERT) ，但它们的语码转换语言能力仍有很大的提高空间。"
    },
    {
        "title": "Multimodal Question Answering for Unified Information Extraction",
        "url": "http://arxiv.org/abs/2310.03017v1",
        "pub_date": "2023-10-04",
        "summary": "Multimodal information extraction (MIE) aims to extract structured\ninformation from unstructured multimedia content. Due to the diversity of tasks\nand settings, most current MIE models are task-specific and data-intensive,\nwhich limits their generalization to real-world scenarios with diverse task\nrequirements and limited labeled data. To address these issues, we propose a\nnovel multimodal question answering (MQA) framework to unify three MIE tasks by\nreformulating them into a unified span extraction and multi-choice QA pipeline.\nExtensive experiments on six datasets show that: 1) Our MQA framework\nconsistently and significantly improves the performances of various\noff-the-shelf large multimodal models (LMM) on MIE tasks, compared to vanilla\nprompting. 2) In the zero-shot setting, MQA outperforms previous\nstate-of-the-art baselines by a large margin. In addition, the effectiveness of\nour framework can successfully transfer to the few-shot setting, enhancing LMMs\non a scale of 10B parameters to be competitive or outperform much larger\nlanguage models such as ChatGPT and GPT-4. Our MQA framework can serve as a\ngeneral principle of utilizing LMMs to better solve MIE and potentially other\ndownstream multimodal tasks.",
        "translated": "多模式信息抽取的目的是从非结构化的多媒体内容中提取结构化信息。由于任务和设置的多样性，目前大多数 MIE 模型都是任务特定的和数据密集型的，这限制了它们对具有不同任务需求和有限标记数据的现实世界场景的推广。为了解决这些问题，我们提出了一种新的多模态问题回答(MQA)框架，将三个 MIE 任务重新整合为一个统一的跨度提取和多选择问题回答流水线。在六个数据集上的大量实验表明: 1)与传统的提示相比，我们的 MQA 框架持续且显著地提高了各种现成的大型多模态模型(LMM)在 MIE 任务上的性能。2)在零射击设置中，MQA 的表现大大优于以前的最先进的基线。此外，我们的框架的有效性可以成功地转移到少镜头设置，在10B 参数范围内增强 LMM，使其具有竞争力或超过更大的语言模型，如 ChatGPT 和 GPT-4。我们的 MQA 框架可以作为利用 LMM 更好地解决 MIE 和潜在的其他下游多模态任务的一般原则。"
    },
    {
        "title": "Understanding In-Context Learning in Transformers and LLMs by Learning\n  to Learn Discrete Functions",
        "url": "http://arxiv.org/abs/2310.03016v1",
        "pub_date": "2023-10-04",
        "summary": "In order to understand the in-context learning phenomenon, recent works have\nadopted a stylized experimental framework and demonstrated that Transformers\ncan learn gradient-based learning algorithms for various classes of real-valued\nfunctions. However, the limitations of Transformers in implementing learning\nalgorithms, and their ability to learn other forms of algorithms are not well\nunderstood. Additionally, the degree to which these capabilities are confined\nto attention-based models is unclear. Furthermore, it remains to be seen\nwhether the insights derived from these stylized settings can be extrapolated\nto pretrained Large Language Models (LLMs). In this work, we take a step\ntowards answering these questions by demonstrating the following: (a) On a\ntest-bed with a variety of Boolean function classes, we find that Transformers\ncan nearly match the optimal learning algorithm for 'simpler' tasks, while\ntheir performance deteriorates on more 'complex' tasks. Additionally, we find\nthat certain attention-free models perform (almost) identically to Transformers\non a range of tasks. (b) When provided a teaching sequence, i.e. a set of\nexamples that uniquely identifies a function in a class, we show that\nTransformers learn more sample-efficiently. Interestingly, our results show\nthat Transformers can learn to implement two distinct algorithms to solve a\nsingle task, and can adaptively select the more sample-efficient algorithm\ndepending on the sequence of in-context examples. (c) Lastly, we show that\nextant LLMs, e.g. LLaMA-2, GPT-4, can compete with nearest-neighbor baselines\non prediction tasks that are guaranteed to not be in their training set.",
        "translated": "为了理解上下文学习现象，最近的工作采用了一个程式化的实验框架，并证明了变压器可以学习基于梯度的各类实值函数的学习算法。然而，变形金刚在实现学习算法的局限性，以及他们学习其他形式的算法的能力还没有得到很好的理解。此外，这些能力局限于基于注意力的模型的程度还不清楚。此外，从这些程式化设置中得出的见解是否可以推广到预先训练的大型语言模型(LLM)还有待观察。在这项工作中，我们通过展示以下内容向回答这些问题迈出了一步: (a)在一个包含各种布尔函数类的测试平台上，我们发现《变形金刚》几乎可以匹配“简单”任务的最佳学习算法，而在更“复杂”的任务中，它们的表现会下降。此外，我们发现某些无注意力模型在一系列任务中的表现(几乎)与变形金刚相同。(b)当提供一个教学序列，即唯一标识一个函数的一组例子，我们表明，变形金刚学习更有效率的样本。有趣的是，我们的结果表明，变形金刚可以学习实现两个不同的算法来解决一个单一的任务，并可以自适应地选择更有效的采样算法取决于序列的上下文示例。(c)最后，我们证明现有的 LLM，例如 LLaMA-2，GPT-4，可以在预测任务上与最近邻基线竞争，这些任务保证不在它们的训练集中。"
    },
    {
        "title": "From Words to Watts: Benchmarking the Energy Costs of Large Language\n  Model Inference",
        "url": "http://arxiv.org/abs/2310.03003v1",
        "pub_date": "2023-10-04",
        "summary": "Large language models (LLMs) have exploded in popularity due to their new\ngenerative capabilities that go far beyond prior state-of-the-art. These\ntechnologies are increasingly being leveraged in various domains such as law,\nfinance, and medicine. However, these models carry significant computational\nchallenges, especially the compute and energy costs required for inference.\nInference energy costs already receive less attention than the energy costs of\ntraining LLMs -- despite how often these large models are called on to conduct\ninference in reality (e.g., ChatGPT). As these state-of-the-art LLMs see\nincreasing usage and deployment in various domains, a better understanding of\ntheir resource utilization is crucial for cost-savings, scaling performance,\nefficient hardware usage, and optimal inference strategies.\n  In this paper, we describe experiments conducted to study the computational\nand energy utilization of inference with LLMs. We benchmark and conduct a\npreliminary analysis of the inference performance and inference energy costs of\ndifferent sizes of LLaMA -- a recent state-of-the-art LLM -- developed by Meta\nAI on two generations of popular GPUs (NVIDIA V100 \\&amp; A100) and two datasets\n(Alpaca and GSM8K) to reflect the diverse set of tasks/benchmarks for LLMs in\nresearch and practice. We present the results of multi-node, multi-GPU\ninference using model sharding across up to 32 GPUs. To our knowledge, our work\nis the one of the first to study LLM inference performance from the perspective\nof computational and energy resources at this scale.",
        "translated": "大型语言模型(LLM)由于其新的生成能力远远超出了先前的最先进水平而大受欢迎。这些技术在法律、金融和医学等各个领域的应用越来越广泛。然而，这些模型带来了重大的计算挑战，特别是推理所需的计算和能源成本。推理能源成本已经比训练 LLM 的能源成本得到更少的关注——尽管这些大型模型在现实中进行推理的频率很高(例如，ChatGPT)。随着这些最先进的 LLM 在各个领域的使用和部署不断增加，更好地理解它们的资源利用对于节省成本、扩展性能、高效的硬件使用和最佳推理策略至关重要。在本文中，我们描述了用 LLM 研究推理的计算和能量利用的实验。我们对不同尺寸的 LLaMA ——一种最新的最先进的 LLM ——的推断性能和推断能量成本进行了基准测试和初步分析，这种 LLM 是由 Meta AI 公司在两代流行的图形处理器(NVIDIA V100和 A100)和两个数据集(Alpaca 和 GSM8K)上开发的，以反映 LLM 在研究和实践中的不同任务/基准集。我们提出的结果，多节点，多 GPU 推理使用模型分片跨多达32个图形处理器。据我们所知，我们的工作是第一个研究 LLM 推理性能从计算和能源资源的角度在这个规模。"
    },
    {
        "title": "ECoFLaP: Efficient Coarse-to-Fine Layer-Wise Pruning for Vision-Language\n  Models",
        "url": "http://arxiv.org/abs/2310.02998v1",
        "pub_date": "2023-10-04",
        "summary": "Large Vision-Language Models (LVLMs) can understand the world comprehensively\nby integrating rich information from different modalities, achieving remarkable\nperformance improvements on various multimodal downstream tasks. However,\ndeploying LVLMs is often problematic due to their massive computational/energy\ncosts and carbon consumption. Such issues make it infeasible to adopt\nconventional iterative global pruning, which is costly due to computing the\nHessian matrix of the entire large model for sparsification. Alternatively,\nseveral studies have recently proposed layer-wise pruning approaches to avoid\nthe expensive computation of global pruning and efficiently compress model\nweights according to their importance within a layer. However, these methods\noften suffer from suboptimal model compression due to their lack of a global\nperspective. To address this limitation in recent efficient pruning methods for\nlarge models, we propose Efficient Coarse-to-Fine Layer-Wise Pruning (ECoFLaP),\na two-stage coarse-to-fine weight pruning approach for LVLMs. We first\ndetermine the sparsity ratios of different layers or blocks by leveraging the\nglobal importance score, which is efficiently computed based on the\nzeroth-order approximation of the global model gradients. Then, the multimodal\nmodel performs local layer-wise unstructured weight pruning based on\nglobally-informed sparsity ratios. We validate our proposed method across\nvarious multimodal and unimodal models and datasets, demonstrating significant\nperformance improvements over prevalent pruning techniques in the high-sparsity\nregime.",
        "translated": "大型视觉语言模型(LVLM)可以通过集成来自不同模式的丰富信息来全面了解世界，在各种多模式下游任务中实现显著的性能改进。然而，部署 LVLM 往往是有问题的，因为它们庞大的计算/能源成本和碳消耗。这些问题使得采用传统的迭代全局修剪是不可行的，由于计算整个大型稀疏模型的 Hessian 矩阵，这是昂贵的。另外，一些研究最近提出了分层剪枝方法，以避免全局剪枝的昂贵计算和有效地压缩模型权重根据他们的重要性在一个层。然而，这些方法往往受到次优模型压缩，由于他们缺乏全局的视角。为了解决目前大型模型的高效剪枝方法中的这一局限性，我们提出了高效粗细分层剪枝(ECoFLaP) ，一种用于 LVLM 的两阶段粗细权重剪枝方法。我们首先利用全局重要性得分确定不同层或块的稀疏比率，该得分是基于全局模型梯度的零阶近似有效计算的。然后，多模态模型基于全局通知稀疏比率进行局部分层非结构化权重剪枝。我们验证了我们提出的方法在各种多模态和单模态模型和数据集，证明了显着的性能改善，在高稀疏度的制度下流行的修剪技术。"
    },
    {
        "title": "Kosmos-G: Generating Images in Context with Multimodal Large Language\n  Models",
        "url": "http://arxiv.org/abs/2310.02992v1",
        "pub_date": "2023-10-04",
        "summary": "Recent advancements in text-to-image (T2I) and vision-language-to-image\n(VL2I) generation have made significant strides. However, the generation from\ngeneralized vision-language inputs, especially involving multiple images,\nremains under-explored. This paper presents Kosmos-G, a model that leverages\nthe advanced perception capabilities of Multimodal Large Language Models\n(MLLMs) to tackle the aforementioned challenge. Our approach aligns the output\nspace of MLLM with CLIP using the textual modality as an anchor and performs\ncompositional instruction tuning on curated data. Kosmos-G demonstrates a\nunique capability of zero-shot multi-entity subject-driven generation. Notably,\nthe score distillation instruction tuning requires no modifications to the\nimage decoder. This allows for a seamless substitution of CLIP and effortless\nintegration with a myriad of U-Net techniques ranging from fine-grained\ncontrols to personalized image decoder variants. We posit Kosmos-G as an\ninitial attempt towards the goal of \"image as a foreign language in image\ngeneration.\"",
        "translated": "文本到图像(T2I)和视觉语言到图像(VL2I)生成技术的最新进展已经取得了重大进展。然而，从广义的视觉语言输入，特别是涉及多个图像的生成，仍然探索不足。本文提出了 Kosmos-G 模型，该模型利用了多模态大语言模型(MLLM)的先进感知能力来应对上述挑战。我们的方法将 MLLM 的输出空间与 CLIP 对齐，使用文本模式作为锚点，并对策划好的数据执行组合指令调优。Kosmos-G 展示了一种独特的零拍摄多实体主题驱动生成能力。值得注意的是，分数蒸馏指令调优不需要修改图像解码器。这使得 CLIP 的无缝替代和与无数的 U-Net 技术的轻松集成成为可能，从细粒度控制到个性化的图像解码变体。我们假定 Kosmos-G 是朝着“在图像生成中将图像作为一种外语”这一目标的初步尝试"
    },
    {
        "title": "xVal: A Continuous Number Encoding for Large Language Models",
        "url": "http://arxiv.org/abs/2310.02989v1",
        "pub_date": "2023-10-04",
        "summary": "Large Language Models have not yet been broadly adapted for the analysis of\nscientific datasets due in part to the unique difficulties of tokenizing\nnumbers. We propose xVal, a numerical encoding scheme that represents any real\nnumber using just a single token. xVal represents a given real number by\nscaling a dedicated embedding vector by the number value. Combined with a\nmodified number-inference approach, this strategy renders the model end-to-end\ncontinuous when considered as a map from the numbers of the input string to\nthose of the output string. This leads to an inductive bias that is generally\nmore suitable for applications in scientific domains. We empirically evaluate\nour proposal on a number of synthetic and real-world datasets. Compared with\nexisting number encoding schemes, we find that xVal is more token-efficient and\ndemonstrates improved generalization.",
        "translated": "大型语言模型尚未广泛适用于科学数据集的分析，部分原因是数字标记的独特困难。我们提出了 xVal，一种数字编码模式，它仅使用一个标记来表示任何实数。XVal 通过按数值缩放专用嵌入向量来表示给定的实数。结合修改后的数字推理方法，当将模型视为从输入字符串的数字到输出字符串的数字的映射时，该策略呈现端到端的连续性。这导致了归纳偏差，通常更适合于科学领域的应用。我们根据经验评估我们的建议在一些合成和真实世界的数据集。与现有的数字编码方案相比，我们发现 xVal 具有更高的令牌效率，并显示出更好的泛化能力。"
    },
    {
        "title": "Scaling Laws for Associative Memories",
        "url": "http://arxiv.org/abs/2310.02984v1",
        "pub_date": "2023-10-04",
        "summary": "Learning arguably involves the discovery and memorization of abstract rules.\nThe aim of this paper is to study associative memory mechanisms. Our model is\nbased on high-dimensional matrices consisting of outer products of embeddings,\nwhich relates to the inner layers of transformer language models. We derive\nprecise scaling laws with respect to sample size and parameter size, and\ndiscuss the statistical efficiency of different estimators, including\noptimization-based algorithms. We provide extensive numerical experiments to\nvalidate and interpret theoretical results, including fine-grained\nvisualizations of the stored memory associations.",
        "translated": "可以说，学习包括发现和记忆抽象的规则。本文旨在研究联想记忆的机制。我们的模型是基于高维矩阵组成的外部产品的嵌入，这涉及到内层的变压器语言模型。我们推导了样本量和参数量的精确尺度律，并讨论了不同估计量的统计效率，包括基于优化的算法。我们提供广泛的数值实验来验证和解释理论结果，包括存储记忆关联的细粒度可视化。"
    },
    {
        "title": "DSPy: Compiling Declarative Language Model Calls into Self-Improving\n  Pipelines",
        "url": "http://arxiv.org/abs/2310.03714v1",
        "pub_date": "2023-10-05",
        "summary": "The ML community is rapidly exploring techniques for prompting language\nmodels (LMs) and for stacking them into pipelines that solve complex tasks.\nUnfortunately, existing LM pipelines are typically implemented using hard-coded\n\"prompt templates\", i.e. lengthy strings discovered via trial and error. Toward\na more systematic approach for developing and optimizing LM pipelines, we\nintroduce DSPy, a programming model that abstracts LM pipelines as text\ntransformation graphs, i.e. imperative computational graphs where LMs are\ninvoked through declarative modules. DSPy modules are parameterized, meaning\nthey can learn (by creating and collecting demonstrations) how to apply\ncompositions of prompting, finetuning, augmentation, and reasoning techniques.\nWe design a compiler that will optimize any DSPy pipeline to maximize a given\nmetric. We conduct two case studies, showing that succinct DSPy programs can\nexpress and optimize sophisticated LM pipelines that reason about math word\nproblems, tackle multi-hop retrieval, answer complex questions, and control\nagent loops. Within minutes of compiling, a few lines of DSPy allow GPT-3.5 and\nllama2-13b-chat to self-bootstrap pipelines that outperform standard few-shot\nprompting (generally by over 25% and 65%, respectively) and pipelines with\nexpert-created demonstrations (by up to 5-46% and 16-40%, respectively). On top\nof that, DSPy programs compiled to open and relatively small LMs like\n770M-parameter T5 and llama2-13b-chat are competitive with approaches that rely\non expert-written prompt chains for proprietary GPT-3.5. DSPy is available at\nhttps://github.com/stanfordnlp/dspy",
        "translated": "机器学习社区正在快速探索提示语言模型(LM)的技术，并将它们叠加到解决复杂任务的管道中。不幸的是，现有的 LM 管道通常使用硬编码的“提示模板”实现，即通过试错发现的冗长字符串。为了更系统地开发和优化 LM 管道，我们引入了 DSPy，一种将 LM 管道抽象为文本转换图的编程模型，即命令式计算图，其中通过声明性模块调用 LM。DSPy 模块是参数化的，这意味着它们可以学习(通过创建和收集演示)如何应用提示、微调、增强和推理技术的组合。我们设计了一个编译器，它可以优化任何 DSPy 流水线以最大化给定的度量。我们进行了两个案例研究，表明简洁的 DSPy 程序可以表达和优化复杂的 LM 管道，这些管道可以推理数学词汇问题、处理多跳检索、回答复杂问题和控制代理循环。在编译后的几分钟内，几行 DSPy 允许 GPT-3.5和 llama2-13b-chat 与自引导管道交谈，这些管道的性能优于标准的少镜头提示(通常分别超过25% 和65%)和专家创建的演示管道(分别高达5-46% 和16-40%)。最重要的是，编译成开放和相对较小的 LM 的 DSPy 程序，如770M 参数 T5和 llama2-13b-chat，与依赖专家编写的 GPT-3.5专有提示链的方法相比具有竞争力。数码影像处理系统可于 https://github.com/stanfordnlp/DSPy 使用"
    },
    {
        "title": "FASER: Binary Code Similarity Search through the use of Intermediate\n  Representations",
        "url": "http://arxiv.org/abs/2310.03605v1",
        "pub_date": "2023-10-05",
        "summary": "Being able to identify functions of interest in cross-architecture software\nis useful whether you are analysing for malware, securing the software supply\nchain or conducting vulnerability research. Cross-Architecture Binary Code\nSimilarity Search has been explored in numerous studies and has used a wide\nrange of different data sources to achieve its goals. The data sources\ntypically used draw on common structures derived from binaries such as function\ncontrol flow graphs or binary level call graphs, the output of the disassembly\nprocess or the outputs of a dynamic analysis approach. One data source which\nhas received less attention is binary intermediate representations. Binary\nIntermediate representations possess two interesting properties: they are cross\narchitecture by their very nature and encode the semantics of a function\nexplicitly to support downstream usage. Within this paper we propose Function\nas a String Encoded Representation (FASER) which combines long document\ntransformers with the use of intermediate representations to create a model\ncapable of cross architecture function search without the need for manual\nfeature engineering, pre-training or a dynamic analysis step. We compare our\napproach against a series of baseline approaches for two tasks; A general\nfunction search task and a targeted vulnerability search task. Our approach\ndemonstrates strong performance across both tasks, performing better than all\nbaseline approaches.",
        "translated": "无论你是在分析恶意软件、保护软件供应链还是进行漏洞研究，能够识别跨架构软件中感兴趣的功能都是有用的。交叉架构二进制代码最近邻搜索已经在许多研究中得到了探索，并且已经使用了广泛的不同数据源来实现其目标。通常使用的数据源利用从二进制文件派生的公共结构，如函数控制流图或二进制级调用图、反汇编过程的输出或动态分析方法的输出。一种受到较少关注的数据源是二进制中间表示。二进制中间表示具有两个有趣的特性: 它们本质上是跨架构的，并且显式地对函数的语义进行编码以支持下游的使用。在本文中，我们提出了功能作为一个字符串编码表示(FASER) ，它结合了长文档转换器和中间表示的使用，创建了一个能够跨体系结构的功能搜索模型，而不需要人工特征工程，预训练或动态分析步骤。我们比较了我们的方法与一系列的基线方法的两个任务: 一个一般的功能搜索任务和一个有针对性的漏洞搜索任务。我们的方法在两个任务中都表现出很强的性能，比所有的基线方法都要好。"
    },
    {
        "title": "TPDR: A Novel Two-Step Transformer-based Product and Class Description\n  Match and Retrieval Method",
        "url": "http://arxiv.org/abs/2310.03491v1",
        "pub_date": "2023-10-05",
        "summary": "There is a niche of companies responsible for intermediating the purchase of\nlarge batches of varied products for other companies, for which the main\nchallenge is to perform product description standardization, i.e., matching an\nitem described by a client with a product described in a catalog. The problem\nis complex since the client's product description may be: (1) potentially\nnoisy; (2) short and uninformative (e.g., missing information about model and\nsize); and (3) cross-language. In this paper, we formalize this problem as a\nranking task: given an initial client product specification (query), return the\nmost appropriate standardized descriptions (response). In this paper, we\npropose TPDR, a two-step Transformer-based Product and Class Description\nRetrieval method that is able to explore the semantic correspondence between IS\nand SD, by exploiting attention mechanisms and contrastive learning. First,\nTPDR employs the transformers as two encoders sharing the embedding vector\nspace: one for encoding the IS and another for the SD, in which corresponding\npairs (IS, SD) must be close in the vector space. Closeness is further enforced\nby a contrastive learning mechanism leveraging a specialized loss function.\nTPDR also exploits a (second) re-ranking step based on syntactic features that\nare very important for the exact matching (model, dimension) of certain\nproducts that may have been neglected by the transformers. To evaluate our\nproposal, we consider 11 datasets from a real company, covering different\napplication contexts. Our solution was able to retrieve the correct\nstandardized product before the 5th ranking position in 71% of the cases and\nits correct category in the first position in 80% of the situations. Moreover,\nthe effectiveness gains over purely syntactic or semantic baselines reach up to\n3.7 times, solving cases that none of the approaches in isolation can do by\nthemselves.",
        "translated": "有一些公司负责为其他公司提供大批量不同产品的中介服务，其主要挑战是实现产品说明标准化，即将客户描述的产品与目录中描述的产品进行匹配。这个问题很复杂，因为客户的产品描述可能是: (1)潜在的噪音; (2)简短和无信息(例如，缺少关于型号和大小的信息) ; (3)跨语言。在本文中，我们将这个问题形式化为一个排序任务: 给定一个初始的客户端产品规范(查询) ，返回最合适的标准化描述(响应)。本文提出了一种基于两步变换的产品和类描述检索方法 TPDR，该方法利用注意机制和对比学习，能够探索 IS 和 SD 之间的语义对应关系。首先，TPDR 使用变形金刚作为共享嵌入向量空间的两个编码器: 一个用于编码 IS，另一个用于编码 SD，其中相应的对(IS，SD)在向量空间中必须非常接近。亲密性通过利用专门的损失功能的对比学习机制得到进一步加强。TPDR 还利用了基于句法特征的(第二)重新排序步骤，这些特征对于某些可能被变形金刚忽略的产品的精确匹配(模型、尺寸)非常重要。为了评估我们的提议，我们考虑了来自一家真实公司的11个数据集，涵盖了不同的应用环境。我们的解决方案能够在71% 的情况下检索到排名第5的正确标准化产品，在80% 的情况下检索到排名第一的正确类别。此外，在纯句法或语义基线上的有效性增加达到3.7倍，解决了孤立的方法无法独立完成的情况。"
    },
    {
        "title": "Personalized Transformer-based Ranking for e-Commerce at Yandex",
        "url": "http://arxiv.org/abs/2310.03481v1",
        "pub_date": "2023-10-05",
        "summary": "Personalizing the user experience with high-quality recommendations based on\nuser activities is vital for e-commerce platforms. This is particularly\nimportant in scenarios where the user's intent is not explicit, such as on the\nhomepage. Recently, personalized embedding-based systems have significantly\nimproved the quality of recommendations and search results in the e-commerce\ndomain. However, most of these works focus on enhancing the retrieval stage.\n  In this paper, we demonstrate that features produced by retrieval-focused\ndeep learning models are sub-optimal for ranking stage in e-commerce\nrecommendations. To address this issue, we propose a two-stage training process\nthat fine-tunes two-tower models to achieve optimal ranking performance. We\nprovide a detailed description of our transformer-based two-tower model\narchitecture, which is specifically designed for personalization in e-commerce.\n  Additionally, we introduce a novel technique for debiasing context in offline\nmodels and report significant improvements in ranking performance when using\nweb-search queries for e-commerce recommendations. Our model has been\nsuccessfully deployed at Yandex and has delivered strong performance in online\nA/B testing.",
        "translated": "通过基于用户活动的高质量推荐使用户体验个性化对于电子商务平台至关重要。这在用户的意图不明确的场景中尤其重要，例如在主页上。近年来，基于个性化嵌入的系统显著提高了电子商务领域推荐和搜索结果的质量。然而，这些工作大多集中在提高检索阶段。本文证明了以检索为中心的深度学习模型所产生的特征在电子商务推荐的排序阶段是次优的。为了解决这个问题，我们提出了一个两阶段的训练过程，微调双塔模型，以实现最佳的排序性能。我们提供了我们的基于变压器的双塔模型架构的详细描述，这是专门为电子商务中的个性化设计的。此外，我们还介绍了一种新的技术来消除离线模型中的上下文偏差，并报告了在使用网络搜索查询进行电子商务推荐时排名性能的显著改善。我们的模型已成功应用于 Yandex 市场，并在在线 A/B 测试方面表现出色。"
    },
    {
        "title": "Amazon Books Rating prediction &amp; Recommendation Model",
        "url": "http://arxiv.org/abs/2310.03200v1",
        "pub_date": "2023-10-04",
        "summary": "This paper uses the dataset of Amazon to predict the books ratings listed on\nAmazon website. As part of this project, we predicted the ratings of the books,\nand also built a recommendation cluster. This recommendation cluster provides\nthe recommended books based on the column's values from dataset, for instance,\ncategory, description, author, price, reviews etc. This paper provides a flow\nof handling big data files, data engineering, building models and providing\npredictions. The models predict book ratings column using various PySpark\nMachine Learning APIs. Additionally, we used hyper-parameters and parameters\ntuning. Also, Cross Validation and TrainValidationSplit were used for\ngeneralization. Finally, we performed a comparison between Binary\nClassification and Multiclass Classification in their accuracies. We converted\nour label from multiclass to binary to see if we could find any difference\nbetween the two classifications. As a result, we found out that we get higher\naccuracy in binary classification than in multiclass classification.",
        "translated": "本文利用亚马逊的数据集对亚马逊网站上的图书排名进行预测。作为这个项目的一部分，我们预测了书籍的评分，并且建立了一个推荐集群。这个推荐集群根据数据集中列的值提供推荐书籍，例如，类别、描述、作者、价格、评论等。本文提供了处理大数据文件、数据工程、建立模型和提供预测的流程。这些模型使用各种 PySpark 机器学习 API 预测图书评级专栏。此外，我们使用超参数和参数调整。此外，交叉验证和 TrainValidationSplit 也用于推广。最后，我们比较了二进制分类和多元分类的精确度。我们将我们的标签从多类转换为二进制，看看我们是否能找到这两种分类之间的任何区别。因此，我们发现在二进制分类中，我们得到了比多元分类更高的精确度。"
    },
    {
        "title": "Improved Baselines with Visual Instruction Tuning",
        "url": "http://arxiv.org/abs/2310.03744v1",
        "pub_date": "2023-10-05",
        "summary": "Large multimodal models (LMM) have recently shown encouraging progress with\nvisual instruction tuning. In this note, we show that the fully-connected\nvision-language cross-modal connector in LLaVA is surprisingly powerful and\ndata-efficient. With simple modifications to LLaVA, namely, using\nCLIP-ViT-L-336px with an MLP projection and adding academic-task-oriented VQA\ndata with simple response formatting prompts, we establish stronger baselines\nthat achieve state-of-the-art across 11 benchmarks. Our final 13B checkpoint\nuses merely 1.2M publicly available data, and finishes full training in ~1 day\non a single 8-A100 node. We hope this can make state-of-the-art LMM research\nmore accessible. Code and model will be publicly available.",
        "translated": "大型多模态模型(LMM)最近在可视化指令调优方面取得了令人鼓舞的进展。在本文中，我们展示了 LLaVA 中完全连接的视觉语言跨模式连接器的惊人的强大和数据效率。通过对 LLaVA 的简单修改，即使用 CLIP-ViT-L-336px 和 MLP 投影，并添加面向学术任务的 VQA 数据和简单的响应格式化提示，我们建立了更强大的基线，在11个基准上实现了最先进的水平。我们最后的13B 检查点仅使用1.2 M 公开可用的数据，并在一个8-A100节点上完成约1天的完整训练。我们希望这可以使最先进的 LMM 研究更容易获得。代码和模型将公开可用。"
    },
    {
        "title": "MathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical\n  Reasoning",
        "url": "http://arxiv.org/abs/2310.03731v1",
        "pub_date": "2023-10-05",
        "summary": "The recently released GPT-4 Code Interpreter has demonstrated remarkable\nproficiency in solving challenging math problems, primarily attributed to its\nability to seamlessly reason with natural language, generate code, execute\ncode, and continue reasoning based on the execution output. In this paper, we\npresent a method to fine-tune open-source language models, enabling them to use\ncode for modeling and deriving math equations and, consequently, enhancing\ntheir mathematical reasoning abilities. We propose a method of generating novel\nand high-quality datasets with math problems and their code-based solutions,\nreferred to as MathCodeInstruct. Each solution interleaves natural language,\ncode, and execution results. We also introduce a customized supervised\nfine-tuning and inference approach. This approach yields the MathCoder models,\na family of models capable of generating code-based solutions for solving\nchallenging math problems. Impressively, the MathCoder models achieve\nstate-of-the-art scores among open-source LLMs on the MATH (45.2%) and GSM8K\n(83.9%) datasets, substantially outperforming other open-source alternatives.\nNotably, the MathCoder model not only surpasses ChatGPT-3.5 and PaLM-2 on GSM8K\nand MATH but also outperforms GPT-4 on the competition-level MATH dataset. The\ndataset and models will be released at https://github.com/mathllm/MathCoder.",
        "translated": "最近发布的 GPT-4代码解释器在解决具有挑战性的数学问题方面表现出了卓越的能力，这主要归功于它能够与自然语言进行无缝推理，生成代码，执行代码，并根据执行输出继续推理。在本文中，我们提出了一种微调开源语言模型的方法，使它们能够使用代码来建模和推导数学方程，从而提高它们的数学推理能力。我们提出了一种用数学问题及其基于代码的解决方案生成新的高质量数据集的方法，称为 MathCodeDirect。每个解决方案都交错使用自然语言、代码和执行结果。我们还介绍了一种定制的监督微调和推理方法。这种方法产生了 MathCoder 模型，这是一系列能够生成基于代码的解决方案来解决具有挑战性的数学问题的模型。令人印象深刻的是，MathCoder 模型在 MATH (45.2%)和 GSM8K (83.9%)数据集的开源 LLM 中取得了最先进的分数，大大优于其他开源替代方案。值得注意的是，MathCoder 模型不仅在 GSM8K 和 MATH 上超过 ChatGPT-3.5和 PaLM-2，而且在竞争级 MATH 数据集上优于 GPT-4。数据集和模型将在 https://github.com/mathllm/mathcoder 发布。"
    },
    {
        "title": "Modular Speech-to-Text Translation for Zero-Shot Cross-Modal Transfer",
        "url": "http://arxiv.org/abs/2310.03724v1",
        "pub_date": "2023-10-05",
        "summary": "Recent research has shown that independently trained encoders and decoders,\ncombined through a shared fixed-size representation, can achieve competitive\nperformance in speech-to-text translation. In this work, we show that this type\nof approach can be further improved with multilingual training. We observe\nsignificant improvements in zero-shot cross-modal speech translation, even\noutperforming a supervised approach based on XLSR for several languages.",
        "translated": "最近的研究表明，独立训练的编码器和解码器，通过共享固定大小的表示结合，可以实现竞争性能的语音文本翻译。在这项工作中，我们表明，这种类型的方法可以进一步改善与多语言培训。我们观察到零拍跨模态语音翻译的显著改进，甚至超过了基于 XLSR 的监督方法在几种语言中的表现。"
    },
    {
        "title": "A Long Way to Go: Investigating Length Correlations in RLHF",
        "url": "http://arxiv.org/abs/2310.03716v1",
        "pub_date": "2023-10-05",
        "summary": "Great successes have been reported using Reinforcement Learning from Human\nFeedback (RLHF) to align large language models. Open-source preference datasets\nand reward models have enabled wider experimentation beyond generic chat\nsettings, particularly to make systems more \"helpful\" for tasks like web\nquestion answering, summarization, and multi-turn dialogue. When optimizing for\nhelpfulness, RLHF has been consistently observed to drive models to produce\nlonger outputs. This paper demonstrates that optimizing for response length is\na significant factor behind RLHF's reported improvements in these settings.\nFirst, we study the relationship between reward and length for reward models\ntrained on three open-source preference datasets for helpfulness. Here, length\ncorrelates strongly with reward, and improvements in reward score are driven in\nlarge part by shifting the distribution over output lengths. We then explore\ninterventions during both RL and reward model learning to see if we can achieve\nthe same downstream improvements as RLHF without increasing length. While our\ninterventions mitigate length increases, they aren't uniformly effective across\nsettings. Furthermore, we find that even running RLHF with a reward based\nsolely on length can reproduce most of the downstream improvements over the\ninitial policy model, showing that reward models in these settings have a long\nway to go.",
        "translated": "据报道，利用人类反馈的强化学习来调整大型语言模型已经取得了巨大的成功。开源的偏好数据集和奖励模型使得实验的范围更广，超越了一般的聊天设置，特别是使系统更“有帮助”的任务，如网络问题回答，总结和多回合对话。当优化的帮助，RLHF 一直观察到驱动模型，以产生更长的输出。这篇论文表明，响应长度的优化是 RLHF 在这些设置中报道的改进背后的一个重要因素。首先，我们研究了在三个开源偏好数据集上训练的奖励模型与奖励长度之间的关系。在这里，长度与报酬密切相关，报酬分数的提高在很大程度上是通过改变输出长度的分布来驱动的。然后，我们探索在 RL 和奖励模型学习期间的干预措施，看看我们是否能够在不增加长度的情况下实现与 RLHF 相同的下游改善。虽然我们的干预措施减少了长度的增加，但它们在不同环境下并非一致有效。此外，我们发现，即使运行仅基于长度的奖励 RLHF 也可以重现最初策略模型的大部分下游改进，表明在这些设置中的奖励模型还有很长的路要走。"
    },
    {
        "title": "Agent Instructs Large Language Models to be General Zero-Shot Reasoners",
        "url": "http://arxiv.org/abs/2310.03710v1",
        "pub_date": "2023-10-05",
        "summary": "We introduce a method to improve the zero-shot reasoning abilities of large\nlanguage models on general language understanding tasks. Specifically, we build\nan autonomous agent to instruct the reasoning process of large language models.\nWe show this approach further unleashes the zero-shot reasoning abilities of\nlarge language models to more tasks. We study the performance of our method on\na wide set of datasets spanning generation, classification, and reasoning. We\nshow that our method generalizes to most tasks and obtains state-of-the-art\nzero-shot performance on 20 of the 29 datasets that we evaluate. For instance,\nour method boosts the performance of state-of-the-art large language models by\na large margin, including Vicuna-13b (13.3%), Llama-2-70b-chat (23.2%), and\nGPT-3.5 Turbo (17.0%). Compared to zero-shot chain of thought, our improvement\nin reasoning is striking, with an average increase of 10.5%. With our method,\nLlama-2-70b-chat outperforms zero-shot GPT-3.5 Turbo by 10.2%.",
        "translated": "本文介绍了一种提高大型语言模型在一般语言理解任务中零点推理能力的方法。具体来说，我们构建了一个自主智能体来指导大型语言模型的推理过程。我们展示了这种方法进一步释放了大型语言模型对更多任务的零拍推理能力。我们研究了我们的方法在跨生成、分类和推理的广泛数据集上的性能。我们展示了我们的方法可以推广到大多数任务，并且在我们评估的29个数据集中的20个上获得了最先进的零拍性能。例如，我们的方法大大提高了最先进的大型语言模型的性能，包括 Vicuna-13b (13.3%) ，Llama-2-70b-chat (23.2%)和 GPT-3.5 Turbo (17.0%)。相对于零打击思维链，我们在推理方面的进步是惊人的，平均增长了10.5% 。使用我们的方法，Llama-2-70b-chat 比 GPT-3.5 Turbo 提高了10.2% 的性能。"
    },
    {
        "title": "Fine-tuning Aligned Language Models Compromises Safety, Even When Users\n  Do Not Intend To!",
        "url": "http://arxiv.org/abs/2310.03693v1",
        "pub_date": "2023-10-05",
        "summary": "Optimizing large language models (LLMs) for downstream use cases often\ninvolves the customization of pre-trained LLMs through further fine-tuning.\nMeta's open release of Llama models and OpenAI's APIs for fine-tuning GPT-3.5\nTurbo on custom datasets also encourage this practice. But, what are the safety\ncosts associated with such custom fine-tuning? We note that while existing\nsafety alignment infrastructures can restrict harmful behaviors of LLMs at\ninference time, they do not cover safety risks when fine-tuning privileges are\nextended to end-users. Our red teaming studies find that the safety alignment\nof LLMs can be compromised by fine-tuning with only a few adversarially\ndesigned training examples. For instance, we jailbreak GPT-3.5 Turbo's safety\nguardrails by fine-tuning it on only 10 such examples at a cost of less than\n$0.20 via OpenAI's APIs, making the model responsive to nearly any harmful\ninstructions. Disconcertingly, our research also reveals that, even without\nmalicious intent, simply fine-tuning with benign and commonly used datasets can\nalso inadvertently degrade the safety alignment of LLMs, though to a lesser\nextent. These findings suggest that fine-tuning aligned LLMs introduces new\nsafety risks that current safety infrastructures fall short of addressing --\neven if a model's initial safety alignment is impeccable, it is not necessarily\nto be maintained after custom fine-tuning. We outline and critically analyze\npotential mitigations and advocate for further research efforts toward\nreinforcing safety protocols for the custom fine-tuning of aligned LLMs.",
        "translated": "为下游用例优化大型语言模型(LLM)通常需要通过进一步的微调对预先训练好的 LLM 进行定制。Meta 公开发布的美洲驼模型和 OpenAI 用于在定制数据集上微调 GPT-3.5 Turbo 的 API 也鼓励了这种做法。但是，与这种定制微调相关的安全成本是多少呢？我们注意到，虽然现有的安全校准基础设施可以在推断时限制 LLM 的有害行为，但是当微调特权扩展到最终用户时，它们并不涵盖安全风险。我们的红色团队研究发现，LLM 的安全校准可能会受到微调，只有几个对抗性设计的训练例子。例如，我们破解了 GPT-3.5 Turbo 的安全护栏，通过 OpenAI 的 API，我们只花了不到0.20美元就对10个这样的例子进行了微调，使得这个模型能够响应几乎所有有害的指令。令人不安的是，我们的研究还表明，即使没有恶意，简单的微调良性和常用的数据集也可能在不经意间降低 LLM 的安全校准，尽管程度较小。这些发现表明，微调一致的 LLM 引入了新的安全风险，而当前的安全基础设施没有解决这些风险——即使一个模型的初始安全一致性是无可挑剔的，也不一定要在定制的微调之后进行维护。我们概述并批判性地分析了潜在的缓解措施，并主张进一步研究加强定制微调定向 LLM 的安全协议。"
    },
    {
        "title": "DecoderLens: Layerwise Interpretation of Encoder-Decoder Transformers",
        "url": "http://arxiv.org/abs/2310.03686v1",
        "pub_date": "2023-10-05",
        "summary": "In recent years, many interpretability methods have been proposed to help\ninterpret the internal states of Transformer-models, at different levels of\nprecision and complexity. Here, to analyze encoder-decoder Transformers, we\npropose a simple, new method: DecoderLens. Inspired by the LogitLens (for\ndecoder-only Transformers), this method involves allowing the decoder to\ncross-attend representations of intermediate encoder layers instead of using\nthe final encoder output, as is normally done in encoder-decoder models. The\nmethod thus maps previously uninterpretable vector representations to\nhuman-interpretable sequences of words or symbols. We report results from the\nDecoderLens applied to models trained on question answering, logical reasoning,\nspeech recognition and machine translation. The DecoderLens reveals several\nspecific subtasks that are solved at low or intermediate layers, shedding new\nlight on the information flow inside the encoder component of this important\nclass of models.",
        "translated": "近年来，人们提出了许多解释变压器模型内部状态的方法，这些方法在不同的精度和复杂程度上都有助于解释变压器模型的内部状态。在这里，为了分析编码器-解码器变压器，我们提出了一个简单的，新的方法: 解码镜头。受 LogitLens (仅用于解码器变压器)的启发，这种方法涉及允许解码器交叉参与中间编码器层的表示，而不是使用最终的编码器输出，正如通常在编码器-解码器模型中所做的那样。因此，该方法将以前无法解释的矢量表示映射到人类可解释的单词或符号序列。我们报告的结果来自解码镜头应用于模型培训的问题回答，逻辑推理，语音识别和机器翻译。DecoderLens 揭示了几个在低层或中间层解决的特定子任务，为这类重要模型的编码器组件内部的信息流提供了新的亮点。"
    },
    {
        "title": "GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction",
        "url": "http://arxiv.org/abs/2310.03668v1",
        "pub_date": "2023-10-05",
        "summary": "Large Language Models (LLMs) combined with instruction tuning have made\nsignificant progress when generalizing to unseen tasks. However, they have been\nless successful in Information Extraction (IE), lagging behind task-specific\nmodels. Typically, IE tasks are characterized by complex annotation guidelines\nwhich describe the task and give examples to humans. Previous attempts to\nleverage such information have failed, even with the largest models, as they\nare not able to follow the guidelines out-of-the-box. In this paper we propose\nGoLLIE (Guideline-following Large Language Model for IE), a model able to\nimprove zero-shot results on unseen IE tasks by virtue of being fine-tuned to\ncomply with annotation guidelines. Comprehensive evaluation empirically\ndemonstrates that GoLLIE is able to generalize to and follow unseen guidelines,\noutperforming previous attempts at zero-shot information extraction. The\nablation study shows that detailed guidelines is key for good results.",
        "translated": "结合指令调优的大型语言模型(LLM)在泛化到未知任务时取得了显著的进展。然而，他们在信息抽取(IE)方面不太成功，落后于特定任务模型。通常，IE 任务是拥有属性复杂的注释指南，用于描述任务并给出示例。以前利用这些信息的尝试都失败了，即使是最大的模型，因为它们不能遵循开箱即用的指导方针。在本文中，我们提出了 GoLLIE (指导原则遵循的 IE 大语言模型) ，这是一个能够通过调整以符合注释指导原则来改进未知 IE 任务的零命中结果的模型。综合评估经验表明，GoLLIE 能够概括和遵循看不见的指导方针，表现优于以往零信息抽取的尝试。消融研究表明，详细的指导方针是取得良好效果的关键。"
    },
    {
        "title": "MapperGPT: Large Language Models for Linking and Mapping Entities",
        "url": "http://arxiv.org/abs/2310.03666v1",
        "pub_date": "2023-10-05",
        "summary": "Aligning terminological resources, including ontologies, controlled\nvocabularies, taxonomies, and value sets is a critical part of data integration\nin many domains such as healthcare, chemistry, and biomedical research. Entity\nmapping is the process of determining correspondences between entities across\nthese resources, such as gene identifiers, disease concepts, or chemical entity\nidentifiers. Many tools have been developed to compute such mappings based on\ncommon structural features and lexical information such as labels and synonyms.\nLexical approaches in particular often provide very high recall, but low\nprecision, due to lexical ambiguity. As a consequence of this, mapping efforts\noften resort to a labor intensive manual mapping refinement through a human\ncurator.\n  Large Language Models (LLMs), such as the ones employed by ChatGPT, have\ngeneralizable abilities to perform a wide range of tasks, including\nquestion-answering and information extraction. Here we present MapperGPT, an\napproach that uses LLMs to review and refine mapping relationships as a\npost-processing step, in concert with existing high-recall methods that are\nbased on lexical and structural heuristics.\n  We evaluated MapperGPT on a series of alignment tasks from different domains,\nincluding anatomy, developmental biology, and renal diseases. We devised a\ncollection of tasks that are designed to be particularly challenging for\nlexical methods. We show that when used in combination with high-recall\nmethods, MapperGPT can provide a substantial improvement in accuracy, beating\nstate-of-the-art (SOTA) methods such as LogMap.",
        "translated": "对齐术语资源，包括本体论、受控词汇表、分类法和价值集，是医疗、化学和生物医学研究等许多领域数据集成的关键部分。实体映射是确定跨越这些资源的实体之间的对应关系的过程，例如基因标识符、疾病概念或化学实体标识符。人们已经开发了许多工具来计算这种基于常见结构特征和词汇信息(如标签和同义词)的映射。特别是词汇方法往往提供非常高的回忆，但准确性低，由于词汇歧义。因此，映射工作通常依赖于通过人工管理员进行的劳动密集型手工映射细化。大型语言模型(LLM) ，例如 ChatgPT 所使用的模型，具有广泛的能力来执行广泛的任务，包括问答和信息抽取。在这里，我们提出了 MapperGPT，一种使用 LLM 作为后处理步骤审查和细化映射关系的方法，与现有的基于词汇和结构启发式的高召回方法相一致。我们评估了 MapperGPT 在不同领域的一系列排列任务，包括解剖学、发育生物学和肾脏疾病。我们设计了一系列的任务，这些任务对于词汇方法来说是特别具有挑战性的。我们表明，当与高召回率方法结合使用时，MapperGPT 可以在准确性方面提供实质性的改进，优于最先进的(SOTA)方法，如 LogMap。"
    },
    {
        "title": "Policy-Gradient Training of Language Models for Ranking",
        "url": "http://arxiv.org/abs/2310.04407v1",
        "pub_date": "2023-10-06",
        "summary": "Text retrieval plays a crucial role in incorporating factual knowledge for\ndecision making into language processing pipelines, ranging from chat-based web\nsearch to question answering systems. Current state-of-the-art text retrieval\nmodels leverage pre-trained large language models (LLMs) to achieve competitive\nperformance, but training LLM-based retrievers via typical contrastive losses\nrequires intricate heuristics, including selecting hard negatives and using\nadditional supervision as learning signals. This reliance on heuristics stems\nfrom the fact that the contrastive loss itself is heuristic and does not\ndirectly optimize the downstream metrics of decision quality at the end of the\nprocessing pipeline. To address this issue, we introduce Neural PG-RANK, a\nnovel training algorithm that learns to rank by instantiating a LLM as a\nPlackett-Luce ranking policy. Neural PG-RANK provides a principled method for\nend-to-end training of retrieval models as part of larger decision systems via\npolicy gradient, with little reliance on complex heuristics, and it effectively\nunifies the training objective with downstream decision-making quality. We\nconduct extensive experiments on various text retrieval benchmarks. The results\ndemonstrate that when the training objective aligns with the evaluation setup,\nNeural PG-RANK yields remarkable in-domain performance improvement, with\nsubstantial out-of-domain generalization to some critical datasets employed in\ndownstream question answering tasks.",
        "translated": "从基于聊天的网络搜索到问答系统，文本检索在将用于决策的事实知识整合到语言处理流程中起着至关重要的作用。目前最先进的文本检索模型利用预先训练的大语言模型(LLM)来实现竞争性能，但是通过典型的对比损失训练基于 LLM 的检索器需要复杂的启发式方法，包括选择硬负片和使用额外的监督作为学习信号。这种对启发式方法的依赖源于这样一个事实，即对比性损失本身是启发式的，并不直接优化处理流水线末端的决策质量的下游度量。为了解决这个问题，我们引入了神经 PG-RANK，一种新的训练算法，通过实例化 LLM 作为 Plackett-Luce 排序策略来学习排序。神经元 PG-RANK 提供了一种基于策略梯度的检索模型端到端训练的原则方法，很少依赖于复杂的启发式算法，有效地将训练目标与下游决策质量相结合。我们对各种文本检索基准进行了广泛的实验。结果表明，当训练目标与评估设置一致时，神经元 PG-RANK 在领域内性能显著提高，在下游问答任务中使用的一些关键数据集具有实质性的域外泛化能力。"
    },
    {
        "title": "On the Embedding Collapse when Scaling up Recommendation Models",
        "url": "http://arxiv.org/abs/2310.04400v1",
        "pub_date": "2023-10-06",
        "summary": "Recent advances in deep foundation models have led to a promising trend of\ndeveloping large recommendation models to leverage vast amounts of available\ndata. However, we experiment to scale up existing recommendation models and\nobserve that the enlarged models do not improve satisfactorily. In this\ncontext, we investigate the embedding layers of enlarged models and identify a\nphenomenon of embedding collapse, which ultimately hinders scalability, wherein\nthe embedding matrix tends to reside in a low-dimensional subspace. Through\nempirical and theoretical analysis, we demonstrate that the feature interaction\nmodule specific to recommendation models has a two-sided effect. On the one\nhand, the interaction restricts embedding learning when interacting with\ncollapsed embeddings, exacerbating the collapse issue. On the other hand,\nfeature interaction is crucial in mitigating the fitting of spurious features,\nthereby improving scalability. Based on this analysis, we propose a simple yet\neffective multi-embedding design incorporating embedding-set-specific\ninteraction modules to capture diverse patterns and reduce collapse. Extensive\nexperiments demonstrate that this proposed design provides consistent\nscalability for various recommendation models.",
        "translated": "深基础模型的最新进展导致了开发大型推荐模型以利用大量现有数据的大有希望的趋势。然而，我们试验扩大现有的推荐模型，并观察到扩大后的模型没有令人满意的改进。在这种背景下，我们研究了扩展模型的嵌入层，发现了嵌入坍塌现象，这种现象最终阻碍了嵌入矩阵的可扩展性，其中嵌入矩阵倾向于驻留在低维子空间中。通过实证和理论分析，我们证明了推荐模型特有的特征交互模块具有双重效应。一方面，在嵌入学习与崩溃嵌入学习相互作用的过程中，交互作用限制了嵌入学习，加剧了崩溃问题。另一方面，特征交互对于减少虚假特征的拟合，从而提高可扩展性是至关重要的。在此基础上，我们提出了一种简单而有效的多嵌入设计方案，该方案结合了嵌入集特定的交互模块来捕获不同的模式并减少崩溃。大量的实验表明，该设计为各种推荐模型提供了一致的可扩展性。"
    },
    {
        "title": "Workload-aware and Learned Z-Indexes",
        "url": "http://arxiv.org/abs/2310.04268v1",
        "pub_date": "2023-10-06",
        "summary": "In this paper, a learned and workload-aware variant of a Z-index, which\njointly optimizes storage layout and search structures, as a viable solution\nfor the above challenges of spatial indexing. Specifically, we first formulate\na cost function to measure the performance of a Z-index on a dataset for a\nrange-query workload. Then, we optimize the Z-index structure by minimizing the\ncost function through adaptive partitioning and ordering for index\nconstruction. Moreover, we design a novel page-skipping mechanism to improve\nits query performance by reducing access to irrelevant data pages. Our\nextensive experiments show that our index improves range query time by 40% on\naverage over the baselines, while always performing better or comparably to\nstate-of-the-art spatial indexes. Additionally, our index maintains good point\nquery performance while providing favourable construction time and index size\ntradeoffs.",
        "translated": "在本文中，一个学习和工作负载感知的 Z 索引变体，它联合优化存储布局和搜索结构，作为一个可行的解决方案，以上空间索引的挑战。具体来说，我们首先制定一个成本函数来度量范围查询工作负载的数据集上 Z 索引的性能。然后，通过自适应划分和排序，最小化成本函数，优化 Z 指标结构。此外，我们还设计了一种新的跳页机制，通过减少对不相关数据页的访问来提高其查询性能。我们的大量实验表明，我们的索引比基线平均提高了40% 的范围查询时间，同时总是表现得比最先进的空间索引更好或更好。此外，我们的索引保持了良好的点查询性能，同时提供了有利的构造时间和索引大小权衡。"
    },
    {
        "title": "Lending Interaction Wings to Recommender Systems with Conversational\n  Agents",
        "url": "http://arxiv.org/abs/2310.04230v1",
        "pub_date": "2023-10-06",
        "summary": "Recommender systems trained on offline historical user behaviors are\nembracing conversational techniques to online query user preference. Unlike\nprior conversational recommendation approaches that systemically combine\nconversational and recommender parts through a reinforcement learning\nframework, we propose CORE, a new offline-training and online-checking paradigm\nthat bridges a COnversational agent and REcommender systems via a unified\nuncertainty minimization framework. It can benefit any recommendation platform\nin a plug-and-play style. Here, CORE treats a recommender system as an offline\nrelevance score estimator to produce an estimated relevance score for each\nitem; while a conversational agent is regarded as an online relevance score\nchecker to check these estimated scores in each session. We define uncertainty\nas the summation of unchecked relevance scores. In this regard, the\nconversational agent acts to minimize uncertainty via querying either\nattributes or items. Based on the uncertainty minimization framework, we derive\nthe expected certainty gain of querying each attribute and item, and develop a\nnovel online decision tree algorithm to decide what to query at each turn.\nExperimental results on 8 industrial datasets show that CORE could be\nseamlessly employed on 9 popular recommendation approaches. We further\ndemonstrate that our conversational agent could communicate as a human if\nempowered by a pre-trained large language model.",
        "translated": "对离线历史用户行为进行培训的推荐系统正在采用在线查询用户偏好的会话技术。与之前的会话推荐方法不同，这种方法通过一个强化学习框架系统地结合了会话和推荐部分，我们提出了 CORE，一种新的离线培训和在线检查范式，它通过一个统一的不确定性最小化框架连接了会话代理和推荐系统。它可以使任何即插即用的推荐平台受益。在这里，CORE 将推荐系统视为离线相关性评分估计器，为每个项目产生一个估计的相关性评分，而会话代理则被视为在线相关性评分检查器，在每个会话中检查这些估计的评分。我们将不确定性定义为未检查相关性得分的总和。在这方面，会话代理通过查询属性或项目来最小化不确定性。在不确定性最小化框架的基础上，推导了查询每个属性和项目的期望确定性增益，并提出了一种新的在线决策树算法来决定每轮查询内容。对8个工业数据集的实验结果表明，CORE 可以无缝地应用于9种流行的推荐方法。我们进一步证明了我们的会话代理可以像人一样交流，如果预先训练的大型语言模型授权。"
    },
    {
        "title": "Keyword Augmented Retrieval: Novel framework for Information Retrieval\n  integrated with speech interface",
        "url": "http://arxiv.org/abs/2310.04205v1",
        "pub_date": "2023-10-06",
        "summary": "Retrieving answers in a quick and low cost manner without hallucinations from\na combination of structured and unstructured data using Language models is a\nmajor hurdle which prevents employment of Language models in knowledge\nretrieval automation. This becomes accentuated when one wants to integrate a\nspeech interface. Besides, for commercial search and chatbot applications,\ncomplete reliance on commercial large language models (LLMs) like GPT 3.5 etc.\ncan be very costly. In this work, authors have addressed this problem by first\ndeveloping a keyword based search framework which augments discovery of the\ncontext to be provided to the large language model. The keywords in turn are\ngenerated by LLM and cached for comparison with keywords generated by LLM\nagainst the query raised. This significantly reduces time and cost to find the\ncontext within documents. Once the context is set, LLM uses that to provide\nanswers based on a prompt tailored for Q&amp;A. This research work demonstrates\nthat use of keywords in context identification reduces the overall inference\ntime and cost of information retrieval. Given this reduction in inference time\nand cost with the keyword augmented retrieval framework, a speech based\ninterface for user input and response readout was integrated. This allowed a\nseamless interaction with the language model.",
        "translated": "以快速和低成本的方式从结构化和非结构化数据化的语言模型中检索答案而不产生幻觉，是阻碍在知识检索自动化中使用语言模型的一个主要障碍。当一个人想要整合一个语音界面时，这个问题就会变得更加突出。此外，对于商业搜索和聊天机器人应用程序，完全依赖商业大型语言模型(LLM) ，如 GPT 3.5等，可能会非常昂贵。在这项工作中，作者解决了这个问题，首先开发了一个基于关键字的搜索框架，增加了发现上下文提供给大型语言模型。关键字依次由 LLM 生成并缓存，以便与 LLM 生成的关键字对所引发的查询进行比较。这大大减少了在文档中查找上下文的时间和成本。一旦设置了上下文，LLM 就会根据为问答而量身定制的提示提供答案。这项研究表明，在上下文识别中使用关键词可以减少整体推理时间和信息检索成本。考虑到关键字增强检索框架减少了推理时间和成本，集成了一个用于用户输入和响应读出的基于语音的界面。这允许与语言模型进行无缝交互。"
    },
    {
        "title": "RECOMP: Improving Retrieval-Augmented LMs with Compression and Selective\n  Augmentation",
        "url": "http://arxiv.org/abs/2310.04408v1",
        "pub_date": "2023-10-06",
        "summary": "Retrieving documents and prepending them in-context at inference time\nimproves performance of language model (LMs) on a wide range of tasks. However,\nthese documents, often spanning hundreds of words, make inference substantially\nmore expensive. We propose compressing the retrieved documents into textual\nsummaries prior to in-context integration. This not only reduces the\ncomputational costs but also relieves the burden of LMs to identify relevant\ninformation in long retrieved documents. We present two compressors -- an\nextractive compressor which selects useful sentences from retrieved documents\nand an abstractive compressor which generates summaries by synthesizing\ninformation from multiple documents. Both compressors are trained to improve\nLMs' performance on end tasks when the generated summaries are prepended to the\nLMs' input, while keeping the summary concise.If the retrieved documents are\nirrelevant to the input or offer no additional information to LM, our\ncompressor can return an empty string, implementing selective augmentation.We\nevaluate our approach on language modeling task and open domain question\nanswering task. We achieve a compression rate of as low as 6% with minimal loss\nin performance for both tasks, significantly outperforming the off-the-shelf\nsummarization models. We show that our compressors trained for one LM can\ntransfer to other LMs on the language modeling task and provide summaries\nlargely faithful to the retrieved documents.",
        "translated": "在推理时在上下文中检索文档并预置它们可以提高语言模型(LM)在多种任务中的性能。然而，这些文档往往跨越数百字，使得推理的成本大大增加。我们建议在上下文集成之前将检索到的文档压缩成文本摘要。这不仅降低了计算成本，而且减轻了 LM 在长期检索的文档中识别相关信息的负担。我们提出了两种压缩器——一种是从检索到的文档中选择有用的句子的抽象压缩器，另一种是通过综合多个文档中的信息生成摘要的抽象压缩器。当生成的摘要被预先输入到 LM 的输入中时，这两个压缩器都被训练来提高 LM 在最终任务中的性能，同时保持摘要的简洁。如果检索到的文档与输入无关或者没有向 LM 提供额外的信息，我们的压缩器可以返回一个空字符串，实现选择性增强。我们评估了我们在语言建模任务和开放域问题回答任务中的方法。我们实现了低至6% 的压缩率，在两个任务的性能损失最小，明显优于现成的摘要模型。我们表明，我们的压缩器训练的一个 LM 可以转移到其他 LM 的语言建模任务，并提供摘要很大程度上忠实于检索到的文档。"
    },
    {
        "title": "Language Agent Tree Search Unifies Reasoning Acting and Planning in\n  Language Models",
        "url": "http://arxiv.org/abs/2310.04406v1",
        "pub_date": "2023-10-06",
        "summary": "While large language models (LLMs) have demonstrated impressive performance\non a range of decision-making tasks, they rely on simple acting processes and\nfall short of broad deployment as autonomous agents. We introduce LATS\n(Language Agent Tree Search), a general framework that synergizes the\ncapabilities of LLMs in planning, acting, and reasoning. Drawing inspiration\nfrom Monte Carlo tree search in model-based reinforcement learning, LATS\nemploys LLMs as agents, value functions, and optimizers, repurposing their\nlatent strengths for enhanced decision-making. What is crucial in this method\nis the use of an environment for external feedback, which offers a more\ndeliberate and adaptive problem-solving mechanism that moves beyond the\nlimitations of existing techniques. Our experimental evaluation across diverse\ndomains, such as programming, HotPotQA, and WebShop, illustrates the\napplicability of LATS for both reasoning and acting. In particular, LATS\nachieves 94.4\\% for programming on HumanEval with GPT-4 and an average score of\n75.9 for web browsing on WebShop with GPT-3.5, demonstrating the effectiveness\nand generality of our method.",
        "translated": "虽然大型语言模型(LLM)在一系列决策任务中表现出了令人印象深刻的性能，但它们依赖于简单的行为过程，不能像自主代理那样广泛部署。我们介绍 LATS (Language Agent Tree Search，语言代理树搜索) ，这是一个通用框架，它协同了 LLM 在计划、行动和推理方面的能力。LATS 从基于模型的强化学习中的蒙特卡罗树搜索中获得灵感，使用 LLM 作为代理、价值函数和优化器，重新利用它们的潜在优势来增强决策。这种方法的关键是利用外部反馈的环境，这种环境提供了一种更加深思熟虑和适应性更强的问题解决机制，超越了现有技术的局限性。我们在不同领域(如编程、 HotPotQA 和 WebShop)进行的实验性评估说明了 LATS 在推理和行为方面的适用性。特别是在 HumanEval 上使用 GPT-4编程的 LATS 达到了94.4% ，在 WebShop 上使用 GPT-3.5浏览网页的平均得分为75.9，证明了该方法的有效性和通用性。"
    },
    {
        "title": "Improving Stability in Simultaneous Speech Translation: A\n  Revision-Controllable Decoding Approach",
        "url": "http://arxiv.org/abs/2310.04399v1",
        "pub_date": "2023-10-06",
        "summary": "Simultaneous Speech-to-Text translation serves a critical role in real-time\ncrosslingual communication. Despite the advancements in recent years,\nchallenges remain in achieving stability in the translation process, a concern\nprimarily manifested in the flickering of partial results. In this paper, we\npropose a novel revision-controllable method designed to address this issue.\nOur method introduces an allowed revision window within the beam search pruning\nprocess to screen out candidate translations likely to cause extensive\nrevisions, leading to a substantial reduction in flickering and, crucially,\nproviding the capability to completely eliminate flickering. The experiments\ndemonstrate the proposed method can significantly improve the decoding\nstability without compromising substantially on the translation quality.",
        "translated": "同声翻译在实时跨语言交际中起着至关重要的作用。尽管近年来取得了一些进展，但在实现翻译过程的稳定性方面仍然存在挑战，这种担忧主要表现在部分结果的闪烁不定上。在本文中，我们提出了一种新的修正控制方法来解决这个问题。我们的方法在波束搜索修剪过程中引入了允许的修订窗口，以筛选出可能导致广泛修订的候选翻译，从而大大减少闪烁，并且至关重要的是提供完全消除闪烁的能力。实验结果表明，该方法能够在不影响译码质量的前提下显著提高译码的稳定性。"
    },
    {
        "title": "Hermes: Unlocking Security Analysis of Cellular Network Protocols by\n  Synthesizing Finite State Machines from Natural Language Specifications",
        "url": "http://arxiv.org/abs/2310.04381v1",
        "pub_date": "2023-10-06",
        "summary": "In this paper, we present Hermes, an end-to-end framework to automatically\ngenerate formal representations from natural language cellular specifications.\nWe first develop a neural constituency parser, NEUTREX, to process\ntransition-relevant texts and extract transition components (i.e., states,\nconditions, and actions). We also design a domain-specific language to\ntranslate these transition components to logical formulas by leveraging\ndependency parse trees. Finally, we compile these logical formulas to generate\ntransitions and create the formal model as finite state machines. To\ndemonstrate the effectiveness of Hermes, we evaluate it on 4G NAS, 5G NAS, and\n5G RRC specifications and obtain an overall accuracy of 81-87%, which is a\nsubstantial improvement over the state-of-the-art. Our security analysis of the\nextracted models uncovers 3 new vulnerabilities and identifies 19 previous\nattacks in 4G and 5G specifications, and 7 deviations in commercial 4G\nbasebands.",
        "translated": "在本文中，我们提出了 Hermes，一个端到端的框架来自动生成自然语言细胞规范的形式化表示。我们首先开发了一个神经选区解析器 NEUTREX，用于处理与过渡相关的文本并提取过渡组件(即状态、条件和行为)。我们还设计了一个领域特定语言，利用依赖解析树将这些转换组件转换为逻辑公式。最后，我们编译这些逻辑公式来产生转换，并创建形式化模型作为有限状态机。为了证明 Hermes 的有效性，我们根据4G NAS，5G NAS 和5G RRC 规范对其进行评估，并获得81-87% 的总体准确率，这是对最先进技术的重大改进。我们对提取的模型进行的安全分析发现了3个新的漏洞，并确定了19个以前在4G 和5G 规范中的攻击，以及7个在商业4G 基带中的偏差。"
    },
    {
        "title": "Amortizing intractable inference in large language models",
        "url": "http://arxiv.org/abs/2310.04363v1",
        "pub_date": "2023-10-06",
        "summary": "Autoregressive large language models (LLMs) compress knowledge from their\ntraining data through next-token conditional distributions. This limits\ntractable querying of this knowledge to start-to-end autoregressive sampling.\nHowever, many tasks of interest -- including sequence continuation, infilling,\nand other forms of constrained generation -- involve sampling from intractable\nposterior distributions. We address this limitation by using amortized Bayesian\ninference to sample from these intractable posteriors. Such amortization is\nalgorithmically achieved by fine-tuning LLMs via diversity-seeking\nreinforcement learning algorithms: generative flow networks (GFlowNets). We\nempirically demonstrate that this distribution-matching paradigm of LLM\nfine-tuning can serve as an effective alternative to maximum-likelihood\ntraining and reward-maximizing policy optimization. As an important\napplication, we interpret chain-of-thought reasoning as a latent variable\nmodeling problem and demonstrate that our approach enables data-efficient\nadaptation of LLMs to tasks that require multi-step rationalization and tool\nuse.",
        "translated": "自回归大语言模型(LLM)通过下标记条件分布从训练数据中压缩知识。这将易处理的此知识查询限制为从头到尾的自回归采样。然而，许多感兴趣的任务-包括序列延续，填充，和其他形式的约束生成-涉及从棘手的后验分布抽样。我们通过使用分期贝叶斯推断从这些棘手的后视镜中提取样本来解决这个问题。这种摊销是通过算法实现的，通过生成流网络(GFlowNets)这种寻求多样性的强化学习算法对 LLM 进行微调。我们的实验表明，这种分布匹配的 LLM 微调范式可以作为一个有效的替代最大似然训练和奖励最大化的政策优化。作为一个重要的应用，我们将思维链推理解释为一个潜在的变量建模问题，并证明我们的方法使 LLM 能够高效地适应需要多步合理化和工具使用的任务。"
    },
    {
        "title": "Transferring speech-generic and depression-specific knowledge for\n  Alzheimer's disease detection",
        "url": "http://arxiv.org/abs/2310.04358v1",
        "pub_date": "2023-10-06",
        "summary": "The detection of Alzheimer's disease (AD) from spontaneous speech has\nattracted increasing attention while the sparsity of training data remains an\nimportant issue. This paper handles the issue by knowledge transfer,\nspecifically from both speech-generic and depression-specific knowledge. The\npaper first studies sequential knowledge transfer from generic foundation\nmodels pretrained on large amounts of speech and text data. A block-wise\nanalysis is performed for AD diagnosis based on the representations extracted\nfrom different intermediate blocks of different foundation models. Apart from\nthe knowledge from speech-generic representations, this paper also proposes to\nsimultaneously transfer the knowledge from a speech depression detection task\nbased on the high comorbidity rates of depression and AD. A parallel knowledge\ntransfer framework is studied that jointly learns the information shared\nbetween these two tasks. Experimental results show that the proposed method\nimproves AD and depression detection, and produces a state-of-the-art F1 score\nof 0.928 for AD diagnosis on the commonly used ADReSSo dataset.",
        "translated": "阿尔茨海默病(AD)的自发言语检测已引起越来越多的关注，而训练数据的稀疏性仍然是一个重要问题。本文通过知识转移的方法来处理这个问题，特别是从语音通用知识和抑郁特异性知识两方面。本文首先研究了基于大量语音和文本数据预训练的通用基础模型的序列知识转移问题。基于从不同基础模型的不同中间块提取的表示，对 AD 诊断进行了分块分析。除了语音通用表征的知识外，本文还提出了基于抑郁症和 AD 的高共病率的语音抑郁检测任务的知识同时转移。研究了一个并行的知识转移框架，该框架联合学习这两个任务之间共享的信息。实验结果表明，该方法改善了 AD 和抑郁症的检测，并在常用的 ADReSSo 数据集上产生了0.928的最先进的 F1评分用于 AD 诊断。"
    },
    {
        "title": "Large-Scale Korean Text Dataset for Classifying Biased Speech in\n  Real-World Online Services",
        "url": "http://arxiv.org/abs/2310.04313v1",
        "pub_date": "2023-10-06",
        "summary": "With the growth of online services, the need for advanced text classification\nalgorithms, such as sentiment analysis and biased text detection, has become\nincreasingly evident. The anonymous nature of online services often leads to\nthe presence of biased and harmful language, posing challenges to maintaining\nthe health of online communities. This phenomenon is especially relevant in\nSouth Korea, where large-scale hate speech detection algorithms have not yet\nbeen broadly explored. In this paper, we introduce a new comprehensive,\nlarge-scale dataset collected from a well-known South Korean SNS platform. Our\nproposed dataset provides annotations including (1) Preferences, (2)\nProfanities, and (3) Nine types of Bias for the text samples, enabling\nmulti-task learning for simultaneous classification of user-generated texts.\nLeveraging state-of-the-art BERT-based language models, our approach surpasses\nhuman-level accuracy across diverse classification tasks, as measured by\nvarious metrics. Beyond academic contributions, our work can provide practical\nsolutions for real-world hate speech and bias mitigation, contributing directly\nto the improvement of online community health. Our work provides a robust\nfoundation for future research aiming to improve the quality of online\ndiscourse and foster societal well-being. All source codes and datasets are\npublicly accessible at https://github.com/Dasol-Choi/KoMultiText.",
        "translated": "随着在线服务的增长，对情感分析和偏向文本检测等高级文本分类算法的需求越来越明显。在线服务的匿名性质往往导致存在偏见和有害的语言，对维护在线社区的健康构成挑战。这种现象在韩国尤其重要，因为在韩国，大规模的仇恨言论检测算法还没有得到广泛的研究。在本文中，我们介绍了一个新的综合性，大规模的数据集收集从著名的韩国 SNS 平台。我们提出的数据集提供注释，包括(1)偏好，(2)亵渎，和(3)文本样本的九种类型的偏见，使多任务学习同时分类用户生成的文本。利用最先进的基于 BERT 的语言模型，我们的方法在不同的分类任务中超越了人类水平的准确性，这是通过各种度量来衡量的。除了学术贡献，我们的工作可以为现实世界的仇恨言论和减少偏见提供实用的解决方案，直接有助于改善在线社区健康。我们的工作为未来旨在提高网络话语质量和促进社会福祉的研究提供了坚实的基础。所有源代码和数据集都可以在 https://github.com/dasol-choi/komultitext 上公开获取。"
    },
    {
        "title": "A Comprehensive Evaluation of Large Language Models on Benchmark\n  Biomedical Text Processing Tasks",
        "url": "http://arxiv.org/abs/2310.04270v1",
        "pub_date": "2023-10-06",
        "summary": "Recently, Large Language Models (LLM) have demonstrated impressive capability\nto solve a wide range of tasks. However, despite their success across various\ntasks, no prior work has investigated their capability in the biomedical domain\nyet. To this end, this paper aims to evaluate the performance of LLMs on\nbenchmark biomedical tasks. For this purpose, we conduct a comprehensive\nevaluation of 4 popular LLMs in 6 diverse biomedical tasks across 26 datasets.\nTo the best of our knowledge, this is the first work that conducts an extensive\nevaluation and comparison of various LLMs in the biomedical domain.\nInterestingly, we find based on our evaluation that in biomedical datasets that\nhave smaller training sets, zero-shot LLMs even outperform the current\nstate-of-the-art fine-tuned biomedical models. This suggests that pretraining\non large text corpora makes LLMs quite specialized even in the biomedical\ndomain. We also find that not a single LLM can outperform other LLMs in all\ntasks, with the performance of different LLMs may vary depending on the task.\nWhile their performance is still quite poor in comparison to the biomedical\nmodels that were fine-tuned on large training sets, our findings demonstrate\nthat LLMs have the potential to be a valuable tool for various biomedical tasks\nthat lack large annotated data.",
        "translated": "最近，大型语言模型(LLM)已经展示了令人印象深刻的能力，以解决广泛的任务。然而，尽管他们在各种任务中取得了成功，但是还没有任何先前的工作研究他们在生物医学领域的能力。为此，本文旨在评估 LLM 在基准生物医学任务中的性能。为此，我们对26个数据集中的6个不同生物医学任务中的4个常用 LLM 进行了综合评估。据我们所知，这是第一个在生物医学领域对各种 LLM 进行广泛评估和比较的工作。有趣的是，我们发现，基于我们的评估，在具有较小训练集的生物医学数据集中，零点 LLM 甚至优于目前最先进的微调生物医学模型。这表明对大文本语料库的预训练使得 LLM 即使在生物医学领域也相当专业化。我们还发现，在所有任务中，没有一个 LLM 的性能优于其他 LLM，不同 LLM 的性能可能因任务而异。虽然与在大型训练集上进行了微调的生物医学模型相比，它们的表现仍然很差，但我们的研究结果表明 LLM 有可能成为缺乏大量注释数据的各种生物医学任务的有价值的工具。"
    },
    {
        "title": "Written and spoken corpus of real and fake social media postings about\n  COVID-19",
        "url": "http://arxiv.org/abs/2310.04237v1",
        "pub_date": "2023-10-06",
        "summary": "This study investigates the linguistic traits of fake news and real news.\nThere are two parts to this study: text data and speech data. The text data for\nthis study consisted of 6420 COVID-19 related tweets re-filtered from Patwa et\nal. (2021). After cleaning, the dataset contained 3049 tweets, with 2161\nlabeled as 'real' and 888 as 'fake'. The speech data for this study was\ncollected from TikTok, focusing on COVID-19 related videos. Research assistants\nfact-checked each video's content using credible sources and labeled them as\n'Real', 'Fake', or 'Questionable', resulting in a dataset of 91 real entries\nand 109 fake entries from 200 TikTok videos with a total word count of 53,710\nwords. The data was analysed using the Linguistic Inquiry and Word Count (LIWC)\nsoftware to detect patterns in linguistic data. The results indicate a set of\nlinguistic features that distinguish fake news from real news in both written\nand speech data. This offers valuable insights into the role of language in\nshaping trust, social media interactions, and the propagation of fake news.",
        "translated": "本研究考察了假新闻和真新闻的语言特点。本研究分为两部分: 文本数据和语音数据。这项研究的文本数据包括从 Patwa 等人(2021)重新过滤的6420条与2019冠状病毒疾病相关的推文。经过清理后，数据集包含3049条 tweet，其中2161条被标记为“真实”，888条被标记为“假”。这项研究的语音数据来自 TikTok，主要集中在与2019冠状病毒疾病相关的视频上。研究助理使用可靠的来源对每个视频的内容进行事实核查，并将它们标记为“真实”、“假”或“可疑”，结果得到了来自200个 TikTok 视频的91个真实条目和109个假条目的数据集，总字数为53,710个单词。数据分析使用语言查询和词计数(LIWC)软件检测模式的语言数据。研究结果表明，无论是在书面还是言语数据中，都存在一系列区分假新闻和真新闻的语言特征。这为语言在塑造信任、社交媒体互动和传播假新闻方面的作用提供了有价值的见解。"
    },
    {
        "title": "Sequential Tag Recommendation",
        "url": "http://arxiv.org/abs/2310.05423v1",
        "pub_date": "2023-10-09",
        "summary": "With the development of Internet technology and the expansion of social\nnetworks, online platforms have become an important way for people to obtain\ninformation. The introduction of tags facilitates information categorization\nand retrieval. Meanwhile, the development of tag recommendation systems not\nonly enables users to input tags more efficiently, but also improves the\nquality of tags. However, current tag recommendation methods only consider the\ncontent of the current post and do not take into account the influence of user\npreferences. Since the main body of tag recommendation is the user, it is very\nnecessary to obtain the user's tagging habits. Therefore, this paper proposes a\ntag recommendation algorithm (MLP4STR) based on the dynamic preference of\nuser's behavioral sequence, which models the user's historical post information\nand historical tag information to obtain the user's dynamic interest changes. A\npure MLP structure across feature dimensions is used in sequence modeling to\nmodel the interaction between tag content and post content to fully extract the\nuser's interests. Finally tag recommendation is performed.",
        "translated": "随着互联网技术的发展和社交网络的扩张，网络平台已经成为人们获取信息的重要途径。标签的引入促进了信息的分类和检索。同时，标签推荐系统的开发不仅使用户能够更有效地输入标签，而且提高了标签的质量。然而，当前的标签推荐方法只考虑当前帖子的内容，而没有考虑用户偏好的影响。由于标签推荐的主体是用户，因此了解用户的标签习惯是非常必要的。为此，本文提出了一种基于用户行为序列动态偏好的标签推荐算法(MLP4STR) ，该算法对用户的历史发帖信息和历史标签信息进行建模，获取用户兴趣的动态变化。序列建模采用跨特征维的纯 MLP 结构，建立标签内容与发布内容之间的交互模型，充分提取用户兴趣。最后执行标记推荐。"
    },
    {
        "title": "Augmented Embeddings for Custom Retrievals",
        "url": "http://arxiv.org/abs/2310.05380v1",
        "pub_date": "2023-10-09",
        "summary": "Information retrieval involves selecting artifacts from a corpus that are\nmost relevant to a given search query. The flavor of retrieval typically used\nin classical applications can be termed as homogeneous and relaxed, where\nqueries and corpus elements are both natural language (NL) utterances\n(homogeneous) and the goal is to pick most relevant elements from the corpus in\nthe Top-K, where K is large, such as 10, 25, 50 or even 100 (relaxed).\nRecently, retrieval is being used extensively in preparing prompts for large\nlanguage models (LLMs) to enable LLMs to perform targeted tasks. These new\napplications of retrieval are often heterogeneous and strict -- the queries and\nthe corpus contain different kinds of entities, such as NL and code, and there\nis a need for improving retrieval at Top-K for small values of K, such as K=1\nor 3 or 5. Current dense retrieval techniques based on pretrained embeddings\nprovide a general-purpose and powerful approach for retrieval, but they are\noblivious to task-specific notions of similarity of heterogeneous artifacts. We\nintroduce Adapted Dense Retrieval, a mechanism to transform embeddings to\nenable improved task-specific, heterogeneous and strict retrieval. Adapted\nDense Retrieval works by learning a low-rank residual adaptation of the\npretrained black-box embedding. We empirically validate our approach by showing\nimprovements over the state-of-the-art general-purpose embeddings-based\nbaseline.",
        "translated": "信息检索包括从语料库中选择与给定搜索查询最相关的工件。经典应用程序中常用的检索风格可以被称为同质和放松，其中查询和语料库元素都是自然语言(NL)语句(同质) ，目标是从 Top-K 语料库中挑选最相关的元素，其中 K 是大的，如10,25,50甚至100(放松)。最近，检索被广泛用于准备大型语言模型(LLM)的提示，以使 LLM 能够执行目标任务。这些检索的新应用程序通常是异构和严格的——查询和语料库包含不同种类的实体，如 NL 和代码，并且有必要改进 Top-K 对小值 K 的检索，如 K = 1或3或5。目前基于预训练嵌入的密集检索技术为检索提供了一种通用和强大的方法，但它们忽略了异构伪影相似性的任务特定概念。我们介绍了自适应密集检索，一种转换嵌入的机制，使改进的任务特定，异构和严格的检索。通过学习预先训练的黑盒嵌入的低秩剩余适应性，实现了自适应稠密检索。我们通过显示比最先进的基于通用嵌入的基准线有所改进，从而经验性地验证了我们的方法。"
    },
    {
        "title": "A Knowledge Graph-Based Search Engine for Robustly Finding Doctors and\n  Locations in the Healthcare Domain",
        "url": "http://arxiv.org/abs/2310.05258v1",
        "pub_date": "2023-10-08",
        "summary": "Efficiently finding doctors and locations is an important search problem for\npatients in the healthcare domain, for which traditional information retrieval\nmethods tend not to work optimally. In the last ten years, knowledge graphs\n(KGs) have emerged as a powerful way to combine the benefits of gleaning\ninsights from semi-structured data using semantic modeling, natural language\nprocessing techniques like information extraction, and robust querying using\nstructured query languages like SPARQL and Cypher. In this short paper, we\npresent a KG-based search engine architecture for robustly finding doctors and\nlocations in the healthcare domain. Early results demonstrate that our approach\ncan lead to significantly higher coverage for complex queries without degrading\nquality.",
        "translated": "对于医疗领域的患者而言，有效地找到医生和位置是一个重要的搜索问题，而传统的信息检索方法往往不能最佳地解决这个问题。在过去的十年里，知识图表(KGs)已经成为一种强有力的方式，它结合了从半结构化数据中收集见解的好处，包括语义建模、自然语言处理技术(如信息抽取) ，以及使用结构化查询语言(如 SPARQL 和 Cypher)的健壮查询。在这篇简短的论文中，我们提出了一个基于 KG 的搜索引擎体系结构，用于在医疗领域中稳健地查找医生和位置。早期的结果表明，我们的方法可以在不降低质量的情况下显著提高复杂查询的覆盖率。"
    },
    {
        "title": "GMMFormer: Gaussian-Mixture-Model based Transformer for Efficient\n  Partially Relevant Video Retrieval",
        "url": "http://arxiv.org/abs/2310.05195v1",
        "pub_date": "2023-10-08",
        "summary": "Given a text query, partially relevant video retrieval (PRVR) seeks to find\nuntrimmed videos containing pertinent moments in a database. For PRVR, clip\nmodeling is essential to capture the partial relationship between texts and\nvideos. Current PRVR methods adopt scanning-based clip construction to achieve\nexplicit clip modeling, which is information-redundant and requires a large\nstorage overhead. To solve the efficiency problem of PRVR methods, this paper\nproposes GMMFormer, a \\textbf{G}aussian-\\textbf{M}ixture-\\textbf{M}odel based\nTrans\\textbf{former} which models clip representations implicitly. During frame\ninteractions, we incorporate Gaussian-Mixture-Model constraints to focus each\nframe on its adjacent frames instead of the whole video. Then generated\nrepresentations will contain multi-scale clip information, achieving implicit\nclip modeling. In addition, PRVR methods ignore semantic differences between\ntext queries relevant to the same video, leading to a sparse embedding space.\nWe propose a query diverse loss to distinguish these text queries, making the\nembedding space more intensive and contain more semantic information. Extensive\nexperiments on three large-scale video datasets (\\ie, TVR, ActivityNet\nCaptions, and Charades-STA) demonstrate the superiority and efficiency of\nGMMFormer.",
        "translated": "给定一个文本查询，部分相关视频检索(PRVR)寻找数据库中包含相关时刻的未修剪视频。对于 PRVR，剪辑建模对于捕捉文本和视频之间的部分关系至关重要。目前的 PRVR 方法采用基于扫描的剪辑结构来实现显式剪辑建模，这种方法信息冗余，存储开销大。为了解决 PRVR 方法的效率问题，本文提出了一种基于 Trans textbf { form }模型的隐式剪辑表示方法 GMMForm。在帧间相互作用过程中，我们引入高斯混合模型约束，使每帧聚焦在相邻帧上，而不是整个视频。然后生成的表示将包含多尺度的剪辑信息，实现隐式剪辑建模。此外，PRVR 方法忽略相同视频文本查询之间的语义差异，导致嵌入空间稀疏。我们提出了一个多样化的查询丢失来区分这些文本查询，使嵌入空间更密集，包含更多的语义信息。通过对三个大规模视频数据集(TVR、 ActivityNet Captions 和 Charades-STA)的大量实验，证明了 GMMformer 的优越性和有效性。"
    },
    {
        "title": "From Data to Dialogue: Leveraging the Structure of Knowledge Graphs for\n  Conversational Exploratory Search",
        "url": "http://arxiv.org/abs/2310.05150v1",
        "pub_date": "2023-10-08",
        "summary": "Exploratory search is an open-ended information retrieval process that aims\nat discovering knowledge about a topic or domain rather than searching for a\nspecific answer or piece of information. Conversational interfaces are\nparticularly suitable for supporting exploratory search, allowing users to\nrefine queries and examine search results through interactive dialogues. In\naddition to conversational search interfaces, knowledge graphs are also useful\nin supporting information exploration due to their rich semantic representation\nof data items. In this study, we demonstrate the synergistic effects of\ncombining knowledge graphs and conversational interfaces for exploratory\nsearch, bridging the gap between structured and unstructured information\nretrieval. To this end, we propose a knowledge-driven dialogue system for\nexploring news articles by asking natural language questions and using the\ngraph structure to navigate between related topics. Based on a user study with\n54 participants, we empirically evaluate the effectiveness of the graph-based\nexploratory search and discuss design implications for developing such systems.",
        "translated": "探索性搜索是一种开放式的信息检索过程，旨在发现关于某个主题或领域的知识，而不是搜索特定的答案或信息。会话界面特别适合于支持探索性搜索，允许用户通过交互式对话精炼查询和检查搜索结果。除了会话搜索接口之外，知识图也有助于支持信息探索，因为它们对数据项有丰富的语义表示。在这项研究中，我们展示了结合知识图表和会话界面进行探索性搜索的协同效应，弥合了结构化和非结构化信息检索之间的差距。为此，我们提出了一个知识驱动的对话系统，通过提出自然语言问题和使用图形结构导航相关话题来探索新闻文章。基于一项有54名参与者的用户研究，我们对基于图的探索性搜索的有效性进行了实证评估，并讨论了开发这类系统的设计意义。"
    },
    {
        "title": "Few-Shot Spoken Language Understanding via Joint Speech-Text Models",
        "url": "http://arxiv.org/abs/2310.05919v1",
        "pub_date": "2023-10-09",
        "summary": "Recent work on speech representation models jointly pre-trained with text has\ndemonstrated the potential of improving speech representations by encoding\nspeech and text in a shared space. In this paper, we leverage such shared\nrepresentations to address the persistent challenge of limited data\navailability in spoken language understanding tasks. By employing a pre-trained\nspeech-text model, we find that models fine-tuned on text can be effectively\ntransferred to speech testing data. With as little as 1 hour of labeled speech\ndata, our proposed approach achieves comparable performance on spoken language\nunderstanding tasks (specifically, sentiment analysis and named entity\nrecognition) when compared to previous methods using speech-only pre-trained\nmodels fine-tuned on 10 times more data. Beyond the proof-of-concept study, we\nalso analyze the latent representations. We find that the bottom layers of\nspeech-text models are largely task-agnostic and align speech and text\nrepresentations into a shared space, while the top layers are more\ntask-specific.",
        "translated": "最近关于与文本联合预训练的语音表示模型的工作已经证明了通过在共享空间中编码语音和文本来改进语音表示的潜力。在本文中，我们利用这种共享表示来解决口语理解任务中有限数据可用性的持续挑战。通过使用预先训练好的语音文本模型，我们发现对文本进行微调的模型可以有效地转换为语音测试数据。只需1小时的标记语音数据，我们提出的方法在口语理解任务(具体来说，情感分析和命名实体识别)方面取得了可比的性能，与之前的方法相比，只使用语音预先训练的模型在10倍以上的数据进行微调。除了概念验证研究，我们还分析了潜在的表征。我们发现语音-文本模型的底层基本上是任务无关的，语音和文本表示在一个共享空间中对齐，而顶层则更具有任务特异性。"
    },
    {
        "title": "FireAct: Toward Language Agent Fine-tuning",
        "url": "http://arxiv.org/abs/2310.05915v1",
        "pub_date": "2023-10-09",
        "summary": "Recent efforts have augmented language models (LMs) with external tools or\nenvironments, leading to the development of language agents that can reason and\nact. However, most of these agents rely on few-shot prompting techniques with\noff-the-shelf LMs. In this paper, we investigate and argue for the overlooked\ndirection of fine-tuning LMs to obtain language agents. Using a setup of\nquestion answering (QA) with a Google search API, we explore a variety of base\nLMs, prompting methods, fine-tuning data, and QA tasks, and find language\nagents are consistently improved after fine-tuning their backbone LMs. For\nexample, fine-tuning Llama2-7B with 500 agent trajectories generated by GPT-4\nleads to a 77% HotpotQA performance increase. Furthermore, we propose FireAct,\na novel approach to fine-tuning LMs with trajectories from multiple tasks and\nprompting methods, and show having more diverse fine-tuning data can further\nimprove agents. Along with other findings regarding scaling effects,\nrobustness, generalization, efficiency and cost, our work establishes\ncomprehensive benefits of fine-tuning LMs for agents, and provides an initial\nset of experimental designs, insights, as well as open questions toward\nlanguage agent fine-tuning.",
        "translated": "最近的努力已经通过外部工具或环境增强了语言模型(LM) ，导致了能够推理和行动的语言代理的发展。然而，这些代理大多依赖于现成的 LM 的少拍提示技术。本文探讨并论证了微调 LM 以获得语言代理这一被忽视的方向。使用带有 Google 搜索 API 的问答(QA)设置，我们探索了各种基本 LM、提示方法、微调数据和 QA 任务，发现语言代理在微调其主干 LM 之后得到了持续的改进。例如，使用 GPT-4生成的500个代理轨迹对 Llama2-7B 进行微调，可以提高 HotpotQA 性能77% 。此外，我们提出了 FireAct，一种新颖的方法来微调来自多个任务的轨迹和提示方法的 LM，并表明拥有更多样化的微调数据可以进一步改善代理。除了其他关于缩放效应、稳健性、泛化、效率和成本的发现，我们的工作还为代理建立了微调 LM 的综合效益，并提供了一套初步的实验设计、见解，以及针对语言代理微调的开放性问题。"
    },
    {
        "title": "NEFTune: Noisy Embeddings Improve Instruction Finetuning",
        "url": "http://arxiv.org/abs/2310.05914v2",
        "pub_date": "2023-10-09",
        "summary": "We show that language model finetuning can be improved, sometimes\ndramatically, with a simple augmentation. NEFTune adds noise to the embedding\nvectors during training. Standard finetuning of LLaMA-2-7B using Alpaca\nachieves 29.79% on AlpacaEval, which rises to 64.69% using noisy embeddings.\nNEFTune also improves over strong baselines on modern instruction datasets.\nModels trained with Evol-Instruct see a 10% improvement, with ShareGPT an 8%\nimprovement, and with OpenPlatypus an 8% improvement. Even powerful models\nfurther refined with RLHF such as LLaMA-2-Chat benefit from additional training\nwith NEFTune.",
        "translated": "我们展示了语言模型的微调可以通过简单的扩展得到改善，有时甚至是显著的改善。NEFTune 在训练过程中给嵌入向量增加了噪声。使用 Alpaca 进行的 LlaMA-2-7B 标准微调在 AlpacaEval 上达到29.79% ，在使用噪声嵌入时则上升到64.69% 。NEFTune 还可以改进现代教学数据集的强基线。使用 Evol-翘课训练的模型有10% 的改善，ShareGPT 有8% 的改善，OpenPlatypus 有8% 的改善。甚至强大的模型进一步完善与 RLHF，如 LLaMA-2-聊天受益于更多的培训与 NEFTune。"
    },
    {
        "title": "SALMON: Self-Alignment with Principle-Following Reward Models",
        "url": "http://arxiv.org/abs/2310.05910v1",
        "pub_date": "2023-10-09",
        "summary": "Supervised Fine-Tuning (SFT) on response demonstrations combined with\nReinforcement Learning from Human Feedback (RLHF) constitutes a powerful\nparadigm for aligning LLM-based AI agents. However, a significant limitation of\nsuch an approach is its dependency on high-quality human annotations, making\nits application to intricate tasks challenging due to difficulties in obtaining\nconsistent response demonstrations and in-distribution response preferences.\nThis paper presents a novel approach, namely SALMON (Self-ALignMent with\nprinciple-fOllowiNg reward models), to align base language models with minimal\nhuman supervision, using only a small set of human-defined principles, yet\nachieving superior performance. Central to our approach is a\nprinciple-following reward model. Trained on synthetic preference data, this\nmodel can generate reward scores based on arbitrary human-defined principles.\nBy merely adjusting these principles during the RL training phase, we gain full\ncontrol over the preferences with the reward model, subsequently influencing\nthe behavior of the RL-trained policies, and eliminating the reliance on the\ncollection of online human preferences. Applying our method to the LLaMA-2-70b\nbase language model, we developed an AI assistant named Dromedary-2. With only\n6 exemplars for in-context learning and 31 human-defined principles,\nDromedary-2 significantly surpasses the performance of several state-of-the-art\nAI systems, including LLaMA-2-Chat-70b, on various benchmark datasets. We have\nopen-sourced the code and model weights to encourage further research into\naligning LLM-based AI agents with enhanced supervision efficiency, improved\ncontrollability, and scalable oversight.",
        "translated": "针对反应演示的监督微调(SFT)结合来自人类反馈的强化学习(rlHF)构成了基于 LLM 的人工智能代理调整的强大范例。然而，这种方法的一个重大局限性是它依赖于高质量的人工注释，由于难以获得一致的响应演示和分布式响应偏好，使得它在复杂任务中的应用具有挑战性。本文提出了一种新的方法，即 SALMON (Self-AlignMent with rule-fOllowiNg 奖励模型) ，在最少人工监督的情况下对基础语言模型进行校准，只使用一小组人工定义的原则，但是可以获得更好的性能。我们的方法的核心是一个遵循原则的奖励模型。该模型以综合偏好数据为基础，根据任意的人类自定义原则生成奖励得分。通过在 RL 训练阶段仅仅调整这些原则，我们就可以通过奖励模型获得对偏好的完全控制，从而影响 RL 训练政策的行为，消除对在线人类偏好集合的依赖。将该方法应用于 LLaMA-2-70b 基本语言模型，开发了一种人工智能辅助系统 Dromedary-2。Dromedary-2只有6个上下文学习的范例和31个人类定义的原则，在各种基准数据集上显著超过了包括 LLaMA-2-Chat-70b 在内的几个最先进的 AI 系统的性能。我们已经开源的代码和模型权重，以鼓励进一步研究调整基于 LLM 的人工智能代理与提高监督效率，改善可控性和可扩展的监督。"
    },
    {
        "title": "A Meta-Learning Perspective on Transformers for Causal Language Modeling",
        "url": "http://arxiv.org/abs/2310.05884v1",
        "pub_date": "2023-10-09",
        "summary": "The Transformer architecture has become prominent in developing large causal\nlanguage models. However, mechanisms to explain its capabilities are not well\nunderstood. Focused on the training process, here we establish a meta-learning\nview of the Transformer architecture when trained for the causal language\nmodeling task, by explicating an inner optimization process that may happen\nwithin the Transformer. Further, from within the inner optimization, we\ndiscover and theoretically analyze a special characteristic of the norms of\nlearned token representations within Transformer-based causal language models.\nOur analysis is supported by experiments conducted on pre-trained large\nlanguage models and real-world data.",
        "translated": "在开发大型因果语言模型时，Transformer 体系结构已经变得非常突出。然而，解释其能力的机制尚未得到很好的理解。关注于训练过程，在这里我们建立了一个变压器架构的元学习视图，当为因果语言建模任务进行训练时，通过解释变压器内部可能发生的内部优化过程。进一步，从内部优化的角度，我们发现并从理论上分析了变压器因果语言模型中学习标记表示规范的一个特殊性质。我们的分析得到了在预先训练的大型语言模型和真实世界数据上进行的实验的支持。"
    },
    {
        "title": "Controllable Chest X-Ray Report Generation from Longitudinal\n  Representations",
        "url": "http://arxiv.org/abs/2310.05881v1",
        "pub_date": "2023-10-09",
        "summary": "Radiology reports are detailed text descriptions of the content of medical\nscans. Each report describes the presence/absence and location of relevant\nclinical findings, commonly including comparison with prior exams of the same\npatient to describe how they evolved. Radiology reporting is a time-consuming\nprocess, and scan results are often subject to delays. One strategy to speed up\nreporting is to integrate automated reporting systems, however clinical\ndeployment requires high accuracy and interpretability. Previous approaches to\nautomated radiology reporting generally do not provide the prior study as\ninput, precluding comparison which is required for clinical accuracy in some\ntypes of scans, and offer only unreliable methods of interpretability.\nTherefore, leveraging an existing visual input format of anatomical tokens, we\nintroduce two novel aspects: (1) longitudinal representation learning -- we\ninput the prior scan as an additional input, proposing a method to align,\nconcatenate and fuse the current and prior visual information into a joint\nlongitudinal representation which can be provided to the multimodal report\ngeneration model; (2) sentence-anatomy dropout -- a training strategy for\ncontrollability in which the report generator model is trained to predict only\nsentences from the original report which correspond to the subset of anatomical\nregions given as input. We show through in-depth experiments on the MIMIC-CXR\ndataset how the proposed approach achieves state-of-the-art results while\nenabling anatomy-wise controllable report generation.",
        "translated": "放射学报告是对医学扫描内容的详细文本描述。每份报告都描述了相关临床发现的存在/不存在和位置，通常包括与同一患者之前的检查进行比较，以描述它们是如何演变的。放射学报告是一个耗时的过程，扫描结果往往受到延误。加速报告的一个策略是整合自动报告系统，然而临床部署需要高度的准确性和可解释性。以前的自动放射学报告方法通常不提供先前的研究作为输入，排除了在某些类型的扫描中为临床准确性所需的比较，并且只提供不可靠的可解释性方法。因此，利用现有的解剖标记的视觉输入格式，我们引入了两个新颖的方面: (1)纵向表示学习——我们输入先前的扫描作为额外的输入，提出了一种方法来对齐，连接和融合当前和先前的视觉信息到一个联合纵向表示，可以提供给多模态报告生成模型; (2)句子-解剖辍学——可控性的训练策略，其中报告生成器模型被训练为只预测来自原始报告的句子，对应于输入的解剖区域子集。通过在 MIMIC-CXR 数据集上的深入实验，我们展示了所提出的方法如何实现最先进的结果，同时支持按解剖方式可控的报告生成。"
    },
    {
        "title": "ViCor: Bridging Visual Understanding and Commonsense Reasoning with\n  Large Language Models",
        "url": "http://arxiv.org/abs/2310.05872v1",
        "pub_date": "2023-10-09",
        "summary": "In our work, we explore the synergistic capabilities of pre-trained\nvision-and-language models (VLMs) and large language models (LLMs) for visual\ncommonsense reasoning (VCR). We categorize the problem of VCR into visual\ncommonsense understanding (VCU) and visual commonsense inference (VCI). For\nVCU, which involves perceiving the literal visual content, pre-trained VLMs\nexhibit strong cross-dataset generalization. On the other hand, in VCI, where\nthe goal is to infer conclusions beyond image content, VLMs face difficulties.\nWe find that a baseline where VLMs provide perception results (image captions)\nto LLMs leads to improved performance on VCI. However, we identify a challenge\nwith VLMs' passive perception, which often misses crucial context information,\nleading to incorrect or uncertain reasoning by LLMs. To mitigate this issue, we\nsuggest a collaborative approach where LLMs, when uncertain about their\nreasoning, actively direct VLMs to concentrate on and gather relevant visual\nelements to support potential commonsense inferences. In our method, named\nViCor, pre-trained LLMs serve as problem classifiers to analyze the problem\ncategory, VLM commanders to leverage VLMs differently based on the problem\nclassification, and visual commonsense reasoners to answer the question. VLMs\nwill perform visual recognition and understanding. We evaluate our framework on\ntwo VCR benchmark datasets and outperform all other methods that do not require\nin-domain supervised fine-tuning.",
        "translated": "在我们的工作中，我们探讨了预先训练的视觉和语言模型(VLMs)和大型语言模型(LLMs)的视觉常识推理(VCR)的协同能力。我们将 VCR 问题分为视觉常识理解(VCU)和视觉常识推理(VCI)两类。对于 VCU，它涉及感知文字的视觉内容，预训练的 VLM 表现出强大的跨数据集泛化。另一方面，在 VCI 中，目标是推断图像内容之外的结论，VLM 面临困难。我们发现 VLM 向 LLM 提供感知结果(图像说明)的基线可以提高 VCI 的性能。然而，我们确定了一个挑战与 VLM 的被动感知，这往往错过关键的上下文信息，导致不正确或不确定的推理的 LLM。为了缓解这个问题，我们建议采用一种协作方法，当 LLM 对其推理不确定时，主动引导 VLM 集中精力并收集相关的视觉元素以支持潜在的常识推理。在我们的方法 ViCor 中，预先训练的 LLM 作为问题分类器来分析问题类别，VLM 指挥官根据问题分类不同地利用 VLM，以及可视化的常识推理器来回答问题。VLM 将执行视觉识别和理解。我们评估我们的框架上的两个 VCR 基准数据集和优于所有其他方法，不需要在领域内监督微调。"
    },
    {
        "title": "Rephrase, Augment, Reason: Visual Grounding of Questions for\n  Vision-Language Models",
        "url": "http://arxiv.org/abs/2310.05861v1",
        "pub_date": "2023-10-09",
        "summary": "An increasing number of vision-language tasks can be handled with little to\nno training, i.e., in a zero and few-shot manner, by marrying large language\nmodels (LLMs) to vision encoders, resulting in large vision-language models\n(LVLMs). While this has huge upsides, such as not requiring training data or\ncustom architectures, how an input is presented to a LVLM can have a major\nimpact on zero-shot model performance. In particular, inputs phrased in an\nunderspecified way can result in incorrect answers due to factors like missing\nvisual information, complex implicit reasoning, or linguistic ambiguity.\nTherefore, adding visually grounded information to the input as a preemptive\nclarification should improve model performance by reducing underspecification,\ne.g., by localizing objects and disambiguating references. Similarly, in the\nVQA setting, changing the way questions are framed can make them easier for\nmodels to answer. To this end, we present Rephrase, Augment and Reason\n(RepARe), a gradient-free framework that extracts salient details about the\nimage using the underlying LVLM as a captioner and reasoner, in order to\npropose modifications to the original question. We then use the LVLM's\nconfidence over a generated answer as an unsupervised scoring function to\nselect the rephrased question most likely to improve zero-shot performance.\nFocusing on two visual question answering tasks, we show that RepARe can result\nin a 3.85% (absolute) increase in zero-shot performance on VQAv2 and a 6.41%\npoint increase on A-OKVQA. Additionally, we find that using gold answers for\noracle question candidate selection achieves a substantial gain in VQA accuracy\nby up to 14.41%. Through extensive analysis, we demonstrate that outputs from\nRepARe increase syntactic complexity, and effectively utilize vision-language\ninteraction and the frozen language model in LVLMs.",
        "translated": "越来越多的视觉语言任务可以在几乎没有训练的情况下处理，例如，通过将大型语言模型(LLM)与视觉编码器结合，从而产生大型视觉语言模型(LVLM)。虽然这样做有很多好处，比如不需要训练数据或自定义架构，但是如何将输入呈现给 LVLM 可以对零射击模型的性能产生重大影响。特别是，由于缺少视觉信息、复杂的隐含推理或语言模糊等因素，以不明确的方式表达的输入可能导致错误的答案。因此，在输入中添加可视化的基础信息作为先发制人的澄清，可以通过减少规范不足(例如，通过本地化对象和消除引用的歧义)来提高模型性能。类似地，在 VQA 设置中，改变问题的框架方式可以使模型更容易回答问题。为此，我们提出了重新措辞，增强和理由(RepARE) ，一个无梯度框架，使用底层 LVLM 作为标题和推理，提取图像的显着细节，以提出对原始问题的修改。然后，我们使用 LVLM 对生成的答案的置信度作为一个无监督的评分函数来选择最有可能提高零拍性能的改写问题。通过对两个视觉问答任务的分析，我们发现，在 VQAv2上，RepAR 可以使零射击性能提高3.85% (绝对值) ，在 A-OKVQA 上提高6.41个百分点。此外，我们发现，使用黄金答案的甲骨文问题候选人选择实现了在 VQA 的准确率大幅增加高达14.41% 。通过广泛的分析，我们发现 RepAR 的输出增加了语法的复杂性，并且有效地利用了 LVLM 中的视觉语言交互和冻结语言模型。"
    },
    {
        "title": "Improving Summarization with Human Edits",
        "url": "http://arxiv.org/abs/2310.05857v1",
        "pub_date": "2023-10-09",
        "summary": "Recent work has shown the promise of learning with human feedback paradigms\nto produce human-determined high-quality text. Existing works use human\nfeedback to train large language models (LLMs) in general domain abstractive\nsummarization and have obtained summary quality exceeding traditional\nlikelihood training. In this paper, we focus on a less explored form of human\nfeedback -- Human Edits. We propose Sequence Alignment (un)Likelihood Training\n(SALT), a novel technique to use both the human-edited and model-generated data\ntogether in the training loop. In addition, we demonstrate simulating Human\nEdits with ground truth summaries coming from existing training data --\nImitation edits, along with the model-generated summaries obtained after the\ntraining, to reduce the need for expensive human-edit data. In our experiments,\nwe extend human feedback exploration from general domain summarization to\nmedical domain summarization. Our results demonstrate the effectiveness of SALT\nto improve the summary quality with Human and Imitation Edits.",
        "translated": "最近的研究表明，使用人类反馈范式学习可以产生由人类决定的高质量文本。现有的研究利用人工反馈训练一般领域的抽象摘要中的大语言模型(LLM) ，获得了超过传统似然训练的摘要质量。在这篇文章中，我们关注的是一种较少被探索的人类反馈形式——人类编辑。我们提出了序列比对似然训练(sALT) ，一种在训练回路中同时使用人工编辑和模型生成数据的新技术。此外，我们还演示了使用来自现有训练数据的地面真相摘要来模拟 Human Edits ——模拟编辑，以及在训练后获得的模型生成的摘要，以减少对昂贵的人工编辑数据的需求。在我们的实验中，我们将人类反馈探索从一般领域总结扩展到医学领域总结。我们的研究结果证明了 SALT 通过人工编辑和模仿编辑提高摘要质量的有效性。"
    },
    {
        "title": "GraphLLM: Boosting Graph Reasoning Ability of Large Language Model",
        "url": "http://arxiv.org/abs/2310.05845v1",
        "pub_date": "2023-10-09",
        "summary": "The advancement of Large Language Models (LLMs) has remarkably pushed the\nboundaries towards artificial general intelligence (AGI), with their\nexceptional ability on understanding diverse types of information, including\nbut not limited to images and audio. Despite this progress, a critical gap\nremains in empowering LLMs to proficiently understand and reason on graph data.\nRecent studies underscore LLMs' underwhelming performance on fundamental graph\nreasoning tasks. In this paper, we endeavor to unearth the obstacles that\nimpede LLMs in graph reasoning, pinpointing the common practice of converting\ngraphs into natural language descriptions (Graph2Text) as a fundamental\nbottleneck. To overcome this impediment, we introduce GraphLLM, a pioneering\nend-to-end approach that synergistically integrates graph learning models with\nLLMs. This synergy equips LLMs with the ability to proficiently interpret and\nreason on graph data, harnessing the superior expressive power of graph\nlearning models. Our empirical evaluations across four fundamental graph\nreasoning tasks validate the effectiveness of GraphLLM. The results exhibit a\nsubstantial average accuracy enhancement of 54.44%, alongside a noteworthy\ncontext reduction of 96.45% across various graph reasoning tasks.",
        "translated": "大语言模型(LLM)的发展极大地推动了人工通用智能(AGI)的发展，因为 LLM 在理解不同类型的信息(包括但不限于图像和音频)方面具有非凡的能力。尽管取得了这些进展，但在授权 LLM 熟练理解和推理图形数据方面仍存在一个关键差距。最近的研究强调 LLM 在基本图形推理任务中表现不佳。在本文中，我们致力于挖掘图形推理中影响 LLM 的障碍，指出将图形转换为自然语言描述(Graph2Text)的常见做法是图形推理的一个根本瓶颈。为了克服这一障碍，我们引入了 GraphLLM，这是一种开创性的端到端方法，它协同地将图形学习模型与 LLM 集成在一起。这种协同作用使 LLM 具有熟练解释和推理图形数据的能力，利用图形学习模型的优越表达能力。通过对四个基本图论任务的实验评估，验证了 GraphLLM 的有效性。结果显示，在各种图形推理任务中，平均准确率显著提高了54.44% ，同时显著减少了96.45% 的上下文。"
    },
    {
        "title": "Efficient Retrieval of Images with Irregular Patterns using\n  Morphological Image Analysis: Applications to Industrial and Healthcare\n  datasets",
        "url": "http://arxiv.org/abs/2310.06566v1",
        "pub_date": "2023-10-10",
        "summary": "Image retrieval is the process of searching and retrieving images from a\ndatabase based on their visual content and features. Recently, much attention\nhas been directed towards the retrieval of irregular patterns within industrial\nor medical images by extracting features from the images, such as deep\nfeatures, colour-based features, shape-based features and local features. This\nhas applications across a spectrum of industries, including fault inspection,\ndisease diagnosis, and maintenance prediction. This paper proposes an image\nretrieval framework to search for images containing similar irregular patterns\nby extracting a set of morphological features (DefChars) from images; the\ndatasets employed in this paper contain wind turbine blade images with defects,\nchest computerised tomography scans with COVID-19 infection, heatsink images\nwith defects, and lake ice images. The proposed framework was evaluated with\ndifferent feature extraction methods (DefChars, resized raw image, local binary\npattern, and scale-invariant feature transforms) and distance metrics to\ndetermine the most efficient parameters in terms of retrieval performance\nacross datasets. The retrieval results show that the proposed framework using\nthe DefChars and the Manhattan distance metric achieves a mean average\nprecision of 80% and a low standard deviation of 0.09 across classes of\nirregular patterns, outperforming alternative feature-metric combinations\nacross all datasets. Furthermore, the low standard deviation between each class\nhighlights DefChars' capability for a reliable image retrieval task, even in\nthe presence of class imbalances or small-sized datasets.",
        "translated": "图像检索是根据图像的视觉内容和特征从数据库中搜索和检索图像的过程。近年来，通过提取图像的深部特征、基于颜色的特征、基于形状的特征和局部特征等特征来检索工业或医学图像中的不规则图案已成为研究的热点。这在许多行业都有应用，包括故障检查、疾病诊断和维护预测。本文提出了一个图像检索框架，通过从图像中提取一组形态特征(DefChars)来搜索包含类似不规则图案的图像，所使用的数据集包括有缺陷的风力涡轮叶片图像、有2019冠状病毒疾病感染的胸部计算机断层扫描图像、有缺陷的散热片图像和湖冰图像。使用不同的特征提取方法(DefChars，调整大小的原始图像，局部二进制模式和尺度不变特征转换)和距离度量来评估所提出的框架，以确定跨数据集检索性能方面最有效的参数。检索结果显示，使用 DefChars 和曼哈顿距离度量的提议框架在不规则模式类别中实现了80% 的平均精度和0.09的低标准差，在所有数据集中表现优于替代特征度量组合。此外，每个类之间的低标准差突出了 DefChars 的可靠图像检索任务的能力，即使在存在类不平衡或小型数据集的情况下。"
    },
    {
        "title": "A Multi-facet Paradigm to Bridge Large Language Model and Recommendation",
        "url": "http://arxiv.org/abs/2310.06491v1",
        "pub_date": "2023-10-10",
        "summary": "Large Language Models (LLMs) have garnered considerable attention in\nrecommender systems. To achieve LLM-based recommendation, item indexing and\ngeneration grounding are two essential steps, bridging between recommendation\nitems and natural language. Item indexing assigns a unique identifier to\nrepresent each item in natural language, and generation grounding grounds the\ngenerated token sequences to in-corpus items. However, previous works suffer\nfrom inherent limitations in the two steps. For item indexing, existing\nID-based identifiers (e.g., numeric IDs) and description-based identifiers\n(e.g., titles) often compromise semantic richness or uniqueness. Moreover,\ngeneration grounding might inadvertently produce out-of-corpus identifiers.\nWorse still, autoregressive generation heavily relies on the initial token's\nquality. To combat these issues, we propose a novel multi-facet paradigm,\nnamely TransRec, to bridge the LLMs to recommendation. Specifically, TransRec\nemploys multi-facet identifiers that incorporate ID, title, and attribute,\nachieving both distinctiveness and semantics. Additionally, we introduce a\nspecialized data structure for TransRec to guarantee the in-corpus identifier\ngeneration and adopt substring indexing to encourage LLMs to generate from any\nposition. We implement TransRec on two backbone LLMs, i.e., BART-large and\nLLaMA-7B. Empirical results on three real-world datasets under diverse settings\n(e.g., full training and few-shot training with warm- and cold-start testings)\nattest to the superiority of TransRec.",
        "translated": "大型语言模型(LLM)已经在推荐系统中引起了相当大的关注。为了实现基于 LLM 的推荐，建立推荐条目索引和生成基础是建立推荐条目和自然语言之间的桥梁的两个基本步骤。条目索引分配一个唯一标识符来表示自然语言中的每个条目，并且生成基础将生成的标记序列基于语料库中的条目。然而，以往的作品在这两个步骤中存在着固有的局限性。对于项目索引，现有的基于 ID 的标识符(例如，数字 ID)和基于描述的标识符(例如，标题)通常会损害语义丰富性或唯一性。此外，生成接地可能会在不经意间产生语料库外标识符。更糟糕的是，自回归生成严重依赖于初始令牌的质量。为了解决这些问题，我们提出了一个新的多方面的范式，即 TransRec，桥梁 LLM 的推荐。具体来说，TransRec 使用了包含 ID、 title 和属性的多方面标识符，从而实现了区别性和语义。此外，我们还为 TransRec 引入了一个专门的数据结构，以保证在语料库中生成标识符，并采用子串索引来鼓励 LLM 从任何位置生成标识符。我们在两个主干 LLM 上实现 TransRec，即 BART-large 和 LLaMA-7B。在三个不同环境下的实际数据集上的实验结果证明了 TransRec 的优越性。"
    },
    {
        "title": "Topological RANSAC for instance verification and retrieval without\n  fine-tuning",
        "url": "http://arxiv.org/abs/2310.06486v1",
        "pub_date": "2023-10-10",
        "summary": "This paper presents an innovative approach to enhancing explainable image\nretrieval, particularly in situations where a fine-tuning set is unavailable.\nThe widely-used SPatial verification (SP) method, despite its efficacy, relies\non a spatial model and the hypothesis-testing strategy for instance\nrecognition, leading to inherent limitations, including the assumption of\nplanar structures and neglect of topological relations among features. To\naddress these shortcomings, we introduce a pioneering technique that replaces\nthe spatial model with a topological one within the RANSAC process. We propose\nbio-inspired saccade and fovea functions to verify the topological consistency\namong features, effectively circumventing the issues associated with SP's\nspatial model. Our experimental results demonstrate that our method\nsignificantly outperforms SP, achieving state-of-the-art performance in\nnon-fine-tuning retrieval. Furthermore, our approach can enhance performance\nwhen used in conjunction with fine-tuned features. Importantly, our method\nretains high explainability and is lightweight, offering a practical and\nadaptable solution for a variety of real-world applications.",
        "translated": "本文提出了一种增强可解释图像检索的创新方法，特别是在无法获得微调集的情况下。广泛使用的空间验证(SP)方法尽管有效，但依赖于空间模型和假设检验策略，如识别，导致固有的局限性，包括假设平面结构和忽视特征之间的拓扑关系。为了解决这些缺点，我们引入了一种开创性的技术，在 RANSAC 过程中用拓扑模型取代空间模型。我们提出了基于仿生启发的扫视和中心凹函数来验证特征之间的拓扑一致性，有效地规避了 SP 空间模型的相关问题。我们的实验结果表明，我们的方法明显优于 SP，在非微调检索中实现了最先进的性能。此外，当与微调特性一起使用时，我们的方法可以提高性能。重要的是，我们的方法保持了很高的可解释性，并且是轻量级的，为各种实际应用提供了实用和适应性强的解决方案。"
    },
    {
        "title": "Query-dominant User Interest Network for Large-Scale Search Ranking",
        "url": "http://arxiv.org/abs/2310.06444v1",
        "pub_date": "2023-10-10",
        "summary": "Historical behaviors have shown great effect and potential in various\nprediction tasks, including recommendation and information retrieval. The\noverall historical behaviors are various but noisy while search behaviors are\nalways sparse. Most existing approaches in personalized search ranking adopt\nthe sparse search behaviors to learn representation with bottleneck, which do\nnot sufficiently exploit the crucial long-term interest. In fact, there is no\ndoubt that user long-term interest is various but noisy for instant search, and\nhow to exploit it well still remains an open problem.\n  To tackle this problem, in this work, we propose a novel model named\nQuery-dominant user Interest Network (QIN), including two cascade units to\nfilter the raw user behaviors and reweigh the behavior subsequences.\nSpecifically, we propose a relevance search unit (RSU), which aims to search a\nsubsequence relevant to the query first and then search the sub-subsequences\nrelevant to the target item. These items are then fed into an attention unit\ncalled Fused Attention Unit (FAU). It should be able to calculate attention\nscores from the ID field and attribute field separately, and then adaptively\nfuse the item embedding and content embedding based on the user engagement of\npast period. Extensive experiments and ablation studies on real-world datasets\ndemonstrate the superiority of our model over state-of-the-art methods. The QIN\nnow has been successfully deployed on Kuaishou search, an online video search\nplatform, and obtained 7.6% improvement on CTR.",
        "translated": "历史行为在各种预测任务中显示出巨大的效果和潜力，包括推荐和信息检索。整体的历史行为是多样的，但是有噪声，而搜索行为总是稀疏的。大多数现有的个性化检索排名方法采用稀疏搜索行为来学习带有瓶颈的表示，这种方法没有充分利用关键的长期兴趣。事实上，毫无疑问，用户对即时搜索的长期兴趣是多种多样的，但是噪音很大，如何很好地利用它仍然是一个悬而未决的问题。为了解决这一问题，本文提出了一种新的查询主导用户兴趣网络(QIN)模型，该模型包括两个级联单元，用于过滤原始用户行为和重新权衡行为子序列。具体来说，我们提出了一种相关搜索单元(RSU) ，它的目的是先搜索与查询相关的子序列，然后再搜索与目标项相关的子子序列。然后，这些物品被输入一个称为“融合注意力单元”(FAU)的注意力单元。它应该能够分别从 ID 字段和属性字段计算注意力得分，然后根据用户过去一段时间的参与度自适应地融合项目嵌入和内容嵌入。对真实世界数据集的大量实验和消融研究表明，我们的模型优于最先进的方法。QIN 现已成功部署在快手搜索(一个在线视频搜索平台)上，点击率提高了7.6% 。"
    },
    {
        "title": "Harnessing Administrative Data Inventories to Create a Reliable\n  Transnational Reference Database for Crop Type Monitoring",
        "url": "http://arxiv.org/abs/2310.06393v1",
        "pub_date": "2023-10-10",
        "summary": "With leaps in machine learning techniques and their applicationon Earth\nobservation challenges has unlocked unprecedented performance across the\ndomain. While the further development of these methods was previously limited\nby the availability and volume of sensor data and computing resources, the lack\nof adequate reference data is now constituting new bottlenecks. Since creating\nsuch ground-truth information is an expensive and error-prone task, new ways\nmust be devised to source reliable, high-quality reference data on large\nscales. As an example, we showcase E URO C ROPS, a reference dataset for crop\ntype classification that aggregates and harmonizes administrative data surveyed\nin different countries with the goal of transnational interoperability.",
        "translated": "随着机器学习技术的飞跃及其在地球观测领域的应用，挑战已经解锁了整个领域前所未有的表现。虽然这些方法的进一步发展以前受到传感器数据和计算资源的可用性和数量的限制，但缺乏足够的参考数据现在构成了新的瓶颈。由于创建这样的地面真相信息是一项昂贵和容易出错的任务，必须设计新的方法来大规模获取可靠、高质量的参考数据。作为一个例子，我们展示了欧洲作物类型分类的参考数据集——欧洲作物类型分类的参考数据集，该数据集汇集和统一了在不同国家调查的行政数据，目的是实现跨国互操作性。"
    },
    {
        "title": "LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios\n  via Prompt Compression",
        "url": "http://arxiv.org/abs/2310.06839v1",
        "pub_date": "2023-10-10",
        "summary": "In long context scenarios, large language models (LLMs) face three main\nchallenges: higher computational/financial cost, longer latency, and inferior\nperformance. Some studies reveal that the performance of LLMs depends on both\nthe density and the position of the key information (question relevant) in the\ninput prompt. Inspired by these findings, we propose LongLLMLingua for prompt\ncompression towards improving LLMs' perception of the key information to\nsimultaneously address the three challenges. We conduct evaluation on a wide\nrange of long context scenarios including single-/multi-document QA, few-shot\nlearning, summarization, synthetic tasks, and code completion. The experimental\nresults show that LongLLMLingua compressed prompt can derive higher performance\nwith much less cost. The latency of the end-to-end system is also reduced. For\nexample, on NaturalQuestions benchmark, LongLLMLingua gains a performance boost\nof up to 17.1% over the original prompt with ~4x fewer tokens as input to\nGPT-3.5-Turbo. It can derive cost savings of \\$28.5 and \\$27.4 per 1,000\nsamples from the LongBench and ZeroScrolls benchmark, respectively.\nAdditionally, when compressing prompts of ~10k tokens at a compression rate of\n2x-10x, LongLLMLingua can speed up the end-to-end latency by 1.4x-3.8x. Our\ncode is available at https://aka.ms/LLMLingua.",
        "translated": "在长语境场景中，大型语言模型(LLM)面临三个主要挑战: 较高的计算/财务成本、较长的延迟和较差的性能。一些研究表明，LLM 的性能取决于输入提示中关键信息(问题相关)的密度和位置。受这些发现的启发，我们建议使用 LongLLMLingua 进行快速压缩，以改善 LLM 对关键信息的感知，从而同时解决这三个挑战。我们对大范围的长上下文场景进行评估，包括单/多文档 QA、少镜头学习、摘要、综合任务和代码完成。实验结果表明，LongLLMLingua 压缩提示可以以更低的成本获得更高的性能。同时也降低了端到端系统的延迟。例如，在 NaturalQuestions 基准测试中，LongLLMLingua 的性能比原来的提示符提高了17.1% ，而作为 GPT-3.5-Turbo 输入的令牌减少了约4倍。它可以从 LongBench 和 ZeroScroll 基准中分别节省每1000个样本28.5美元和27.4美元的成本。此外，当以2x-10x 的压缩速率压缩约10k 个令牌时，LongLLMLingua 可以将端到端延迟提高1.4 x-3.8 x。我们的代码可以在 https://aka.ms/llmlingua 找到。"
    },
    {
        "title": "Generating and Evaluating Tests for K-12 Students with Language Model\n  Simulations: A Case Study on Sentence Reading Efficiency",
        "url": "http://arxiv.org/abs/2310.06837v1",
        "pub_date": "2023-10-10",
        "summary": "Developing an educational test can be expensive and time-consuming, as each\nitem must be written by experts and then evaluated by collecting hundreds of\nstudent responses. Moreover, many tests require multiple distinct sets of\nquestions administered throughout the school year to closely monitor students'\nprogress, known as parallel tests. In this study, we focus on tests of silent\nsentence reading efficiency, used to assess students' reading ability over\ntime. To generate high-quality parallel tests, we propose to fine-tune large\nlanguage models (LLMs) to simulate how previous students would have responded\nto unseen items. With these simulated responses, we can estimate each item's\ndifficulty and ambiguity. We first use GPT-4 to generate new test items\nfollowing a list of expert-developed rules and then apply a fine-tuned LLM to\nfilter the items based on criteria from psychological measurements. We also\npropose an optimal-transport-inspired technique for generating parallel tests\nand show the generated tests closely correspond to the original test's\ndifficulty and reliability based on crowdworker responses. Our evaluation of a\ngenerated test with 234 students from grades 2 to 8 produces test scores highly\ncorrelated (r=0.93) to those of a standard test form written by human experts\nand evaluated across thousands of K-12 students.",
        "translated": "开发一个教育测试可能是昂贵和耗时的，因为每个项目必须由专家撰写，然后通过收集数百名学生的反馈进行评估。此外，许多测试需要在整个学年中进行多组不同的问题，以密切监测学生的进展，即所谓的平行测试。在这项研究中，我们重点测试无声句子的阅读效率，用来评估学生的阅读能力随着时间的推移。为了生成高质量的并行测试，我们建议对大型语言模型(LLM)进行微调，以模拟以前的学生对看不见的项目的反应。通过这些模拟反应，我们可以估计每个项目的难度和模糊性。我们首先使用 GPT-4根据专家开发的规则列表生成新的测试项，然后应用一个微调的 LLM 根据心理测量的标准过滤项。我们还提出了一种基于最佳传输激励的并行测试生成技术，并基于众工响应显示所生成的测试与原始测试的难度和可靠性密切相关。我们对2至8年级234名学生的生成测试的评估产生的测试分数与人类专家编写的标准测试表格高度相关(r = 0.93) ，并在数千名 K-12学生中进行评估。"
    },
    {
        "title": "Lemur: Harmonizing Natural Language and Code for Language Agents",
        "url": "http://arxiv.org/abs/2310.06830v1",
        "pub_date": "2023-10-10",
        "summary": "We introduce Lemur and Lemur-Chat, openly accessible language models\noptimized for both natural language and coding capabilities to serve as the\nbackbone of versatile language agents. The evolution from language chat models\nto functional language agents demands that models not only master human\ninteraction, reasoning, and planning but also ensure grounding in the relevant\nenvironments. This calls for a harmonious blend of language and coding\ncapabilities in the models. Lemur and Lemur-Chat are proposed to address this\nnecessity, demonstrating balanced proficiencies in both domains, unlike\nexisting open-source models that tend to specialize in either. Through\nmeticulous pre-training using a code-intensive corpus and instruction\nfine-tuning on text and code data, our models achieve state-of-the-art averaged\nperformance across diverse text and coding benchmarks among open-source models.\nComprehensive experiments demonstrate Lemur's superiority over existing\nopen-source models and its proficiency across various agent tasks involving\nhuman communication, tool usage, and interaction under fully- and partially-\nobservable environments. The harmonization between natural and programming\nlanguages enables Lemur-Chat to significantly narrow the gap with proprietary\nmodels on agent abilities, providing key insights into developing advanced\nopen-source agents adept at reasoning, planning, and operating seamlessly\nacross environments. https://github.com/OpenLemur/Lemur",
        "translated": "我们介绍了 Lemur 和 Lemur-Chat，这两种开放访问的语言模型针对自然语言和编码能力进行了优化，作为多功能语言代理的骨干。从语言聊天模型到功能语言代理的演化要求模型不仅要掌握人类交互、推理和计划，而且要确保在相关环境中建立基础。这就要求模型中语言和编码能力的和谐融合。Lemur 和 Lemur-Chat 被提议解决这一必要性，展示两个领域的平衡熟练程度，不像现有的开源模型倾向于专注于这两个领域。通过使用代码密集型语料库和对文本和代码数据进行指令微调的一丝不苟的预训练，我们的模型在开源模型的不同文本和编码基准之间实现了最先进的平均性能。综合实验证明了 Lemur 相对于现有开源模型的优越性，以及它在涉及人类交流、工具使用和在完全和部分可观察环境下的交互的各种代理任务中的熟练程度。自然语言和编程语言之间的协调使得 Lemur-Chat 能够显著缩小与代理能力专有模型之间的差距，为开发擅长推理、规划和跨环境无缝操作的高级开源代理提供关键见解。Https://github.com/openlemur/lemur"
    },
    {
        "title": "Teaching Language Models to Hallucinate Less with Synthetic Tasks",
        "url": "http://arxiv.org/abs/2310.06827v1",
        "pub_date": "2023-10-10",
        "summary": "Large language models (LLMs) frequently hallucinate on abstractive\nsummarization tasks such as document-based question-answering, meeting\nsummarization, and clinical report generation, even though all necessary\ninformation is included in context. However, optimizing LLMs to hallucinate\nless on these tasks is challenging, as hallucination is hard to efficiently\nevaluate at each optimization step. In this work, we show that reducing\nhallucination on a synthetic task can also reduce hallucination on real-world\ndownstream tasks. Our method, SynTra, first designs a synthetic task where\nhallucinations are easy to elicit and measure. It next optimizes the LLM's\nsystem message via prefix-tuning on the synthetic task, and finally transfers\nthe system message to realistic, hard-to-optimize tasks. Across three realistic\nabstractive summarization tasks, SynTra reduces hallucination for two\n13B-parameter LLMs using only a synthetic retrieval task for supervision. We\nalso find that optimizing the system message rather than the model weights can\nbe critical; fine-tuning the entire model on the synthetic task can\ncounterintuitively increase hallucination. Overall, SynTra demonstrates that\nthe extra flexibility of working with synthetic data can help mitigate\nundesired behaviors in practice.",
        "translated": "大型语言模型(LLM)经常在抽象的摘要任务上产生幻觉，例如基于文档的问题回答、会议摘要和临床报告生成，即使所有必要的信息都包含在上下文中。然而，优化 LLM 以减少这些任务上的幻觉是具有挑战性的，因为幻觉很难在每个优化步骤中有效地进行评估。在这项工作中，我们表明，减少幻觉合成任务也可以减少幻觉现实世界的下游任务。我们的方法 SynTra 首先设计了一个合成任务幻觉很容易诱发和测量。接下来通过对合成任务的前缀调优优化 LLM 的系统消息，最后将系统消息传输到实际的、难以优化的任务。在三个真实的抽象摘要任务中，SynTra 减少了两个13B 参数 LLM 的幻觉，只使用一个用于监督的综合检索任务。我们还发现，优化系统消息而不是模型权重可能是至关重要的; 在合成任务上微调整整个模型可能会反直觉地增加幻觉。总的来说，SynTra 证明了使用合成数据的额外灵活性可以帮助减轻实际中不希望出现的行为。"
    },
    {
        "title": "Mistral 7B",
        "url": "http://arxiv.org/abs/2310.06825v1",
        "pub_date": "2023-10-10",
        "summary": "We introduce Mistral 7B v0.1, a 7-billion-parameter language model engineered\nfor superior performance and efficiency. Mistral 7B outperforms Llama 2 13B\nacross all evaluated benchmarks, and Llama 1 34B in reasoning, mathematics, and\ncode generation. Our model leverages grouped-query attention (GQA) for faster\ninference, coupled with sliding window attention (SWA) to effectively handle\nsequences of arbitrary length with a reduced inference cost. We also provide a\nmodel fine-tuned to follow instructions, Mistral 7B -- Instruct, that surpasses\nthe Llama 2 13B -- Chat model both on human and automated benchmarks. Our\nmodels are released under the Apache 2.0 license.",
        "translated": "我们介绍 Mistral7B v0.1，这是一个70亿参数的语言模型，为了更好的性能和效率而设计。西北风7B 在所有评估基准测试中优于喇嘛213B，在推理、数学和代码生成方面优于喇嘛134B。该模型利用分组查询注意(GQA)加快推理速度，结合滑动窗口注意(SWA)有效处理任意长度的序列，降低推理成本。我们还提供了一个模型，经过微调，以遵循指示，西北风7B ——指令，超过了美洲驼213B ——聊天模型的人类和自动化基准。我们的模型是在 Apache 2.0许可下发布的。"
    },
    {
        "title": "Text Embeddings Reveal (Almost) As Much As Text",
        "url": "http://arxiv.org/abs/2310.06816v1",
        "pub_date": "2023-10-10",
        "summary": "How much private information do text embeddings reveal about the original\ntext? We investigate the problem of embedding \\textit{inversion},\nreconstructing the full text represented in dense text embeddings. We frame the\nproblem as controlled generation: generating text that, when reembedded, is\nclose to a fixed point in latent space. We find that although a na\\\"ive model\nconditioned on the embedding performs poorly, a multi-step method that\niteratively corrects and re-embeds text is able to recover $92\\%$ of\n$32\\text{-token}$ text inputs exactly. We train our model to decode text\nembeddings from two state-of-the-art embedding models, and also show that our\nmodel can recover important personal information (full names) from a dataset of\nclinical notes. Our code is available on Github:\n\\href{https://github.com/jxmorris12/vec2text}{github.com/jxmorris12/vec2text}.",
        "translated": "文本嵌入揭示了原始文本的多少私人信息？我们研究了文本嵌入问题，重建了密文嵌入中表示的全文。我们把这个问题定义为受控的生成: 生成的文本在重新嵌入时，接近潜在空间中的一个固定点。我们发现，虽然一个以嵌入为条件的简单模型性能较差，但是一个迭代校正和重新嵌入文本的多步方法能够准确地恢复 $32文本{-标记} $文本输入中的 $92% 。我们训练我们的模型从两个最先进的嵌入模型中解码文本嵌入，并且还表明我们的模型可以从临床记录的数据集中恢复重要的个人信息(全名)。我们的代码可以在 Github 上找到: href { https://Github.com/jxmorris12/vec2text }{ Github.com/jxmorris12/vec2text }。"
    },
    {
        "title": "Advancing Transformer's Capabilities in Commonsense Reasoning",
        "url": "http://arxiv.org/abs/2310.06803v1",
        "pub_date": "2023-10-10",
        "summary": "Recent advances in general purpose pre-trained language models have shown\ngreat potential in commonsense reasoning. However, current works still perform\npoorly on standard commonsense reasoning benchmarks including the Com2Sense\nDataset. We argue that this is due to a disconnect with current cutting-edge\nmachine learning methods. In this work, we aim to bridge the gap by introducing\ncurrent ML-based methods to improve general purpose pre-trained language models\nin the task of commonsense reasoning. Specifically, we experiment with and\nsystematically evaluate methods including knowledge transfer, model ensemble,\nand introducing an additional pairwise contrastive objective. Our best model\noutperforms the strongest previous works by ~15\\% absolute gains in Pairwise\nAccuracy and ~8.7\\% absolute gains in Standard Accuracy.",
        "translated": "通用预训练语言模型的最新进展显示了常识推理的巨大潜力。然而，目前的工作仍然表现不佳的标准常识推理基准，包括 Com2Sense 数据集。我们认为，这是由于与当前尖端的机器学习方法脱节。在这项工作中，我们的目标是通过引入现有的基于机器学习的方法来改善通用的预训练语言模型在常识推理任务中的差距。具体来说，我们试验和系统评价方法，包括知识转移，模型集成，并引入了一个额外的成对对比的目标。我们最好的模型比以前最强的作品在成对精度上增加了15% 的绝对增益，在标准精度上增加了8.7% 的绝对增益。"
    },
    {
        "title": "OpenWebMath: An Open Dataset of High-Quality Mathematical Web Text",
        "url": "http://arxiv.org/abs/2310.06786v1",
        "pub_date": "2023-10-10",
        "summary": "There is growing evidence that pretraining on high quality, carefully\nthought-out tokens such as code or mathematics plays an important role in\nimproving the reasoning abilities of large language models. For example,\nMinerva, a PaLM model finetuned on billions of tokens of mathematical documents\nfrom arXiv and the web, reported dramatically improved performance on problems\nthat require quantitative reasoning. However, because all known open source web\ndatasets employ preprocessing that does not faithfully preserve mathematical\nnotation, the benefits of large scale training on quantitive web documents are\nunavailable to the research community. We introduce OpenWebMath, an open\ndataset inspired by these works containing 14.7B tokens of mathematical\nwebpages from Common Crawl. We describe in detail our method for extracting\ntext and LaTeX content and removing boilerplate from HTML documents, as well as\nour methods for quality filtering and deduplication. Additionally, we run\nsmall-scale experiments by training 1.4B parameter language models on\nOpenWebMath, showing that models trained on 14.7B tokens of our dataset surpass\nthe performance of models trained on over 20x the amount of general language\ndata. We hope that our dataset, openly released on the Hugging Face Hub, will\nhelp spur advances in the reasoning abilities of large language models.",
        "translated": "越来越多的证据表明，对高质量、经过深思熟虑的标记(如代码或数学)的预训练在提高大型语言模型的推理能力方面发挥着重要作用。例如，Minerva，一个基于来自 arXiv 和网络的数十亿个数学文档标记的 PalM 模型，报告显示在需要定量推理的问题上性能显著提高。然而，由于所有已知的开源网络数据集使用的预处理并不能忠实地保存数学符号，因此研究界无法获得大规模培训量化网络文档的好处。我们介绍 OpenWebMath，这是一个受这些作品启发的开放数据集，其中包含来自 Common Crawl 的14.7 B 数学网页标记。我们详细描述了我们提取文本和 LaTeX 内容和从 HTML 文档中去除样板的方法，以及我们的质量过滤和重复数据删除方法。此外，我们通过在 OpenWebMath 上训练1.4 B 参数语言模型来进行小规模实验，表明在我们的数据集的14.7 B 令牌上训练的模型超过在超过20倍的一般语言数据量上训练的模型的性能。我们希望，我们的数据集，公开发布在拥抱面枢纽，将有助于刺激进步的推理能力的大型语言模型。"
    },
    {
        "title": "Uni3D: Exploring Unified 3D Representation at Scale",
        "url": "http://arxiv.org/abs/2310.06773v1",
        "pub_date": "2023-10-10",
        "summary": "Scaling up representations for images or text has been extensively\ninvestigated in the past few years and has led to revolutions in learning\nvision and language. However, scalable representation for 3D objects and scenes\nis relatively unexplored. In this work, we present Uni3D, a 3D foundation model\nto explore the unified 3D representation at scale. Uni3D uses a 2D initialized\nViT end-to-end pretrained to align the 3D point cloud features with the\nimage-text aligned features. Via the simple architecture and pretext task,\nUni3D can leverage abundant 2D pretrained models as initialization and\nimage-text aligned models as the target, unlocking the great potential of 2D\nmodels and scaling-up strategies to the 3D world. We efficiently scale up Uni3D\nto one billion parameters, and set new records on a broad range of 3D tasks,\nsuch as zero-shot classification, few-shot classification, open-world\nunderstanding and part segmentation. We show that the strong Uni3D\nrepresentation also enables applications such as 3D painting and retrieval in\nthe wild. We believe that Uni3D provides a new direction for exploring both\nscaling up and efficiency of the representation in 3D domain.",
        "translated": "在过去的几年中，对图像或文本的放大表示进行了广泛的研究，并导致了学习视觉和语言的革命。然而，对于3D 对象和场景的可扩展表示相对来说还是未知的。在这项工作中，我们提出了 Uni3D，一个三维基础模型，以探索统一的三维表示在尺度上。Uni3D 使用一个2D 初始化的 ViT 端到端预先训练来使3D 点云特征与图像-文本对齐的特征对齐。通过简单的架构和借口任务，Uni3D 可以利用丰富的2D 预训练模型作为初始化和图像-文本对齐模型作为目标，释放2D 模型的巨大潜力和3D 世界的扩展策略。我们有效地将 Uni3D 扩展到十亿个参数，并在广泛的3D 任务中创建新的记录，例如零镜头分类、少镜头分类、开放世界理解和部件分割。我们表明，强大的 Uni3D 表示还支持应用程序，如3D 绘制和检索在野外。我们相信 Uni3D 为探索3D 领域表示的尺度和效率提供了一个新的方向。"
    },
    {
        "title": "SWE-bench: Can Language Models Resolve Real-World GitHub Issues?",
        "url": "http://arxiv.org/abs/2310.06770v1",
        "pub_date": "2023-10-10",
        "summary": "Language models have outpaced our ability to evaluate them effectively, but\nfor their future development it is essential to study the frontier of their\ncapabilities. We consider real-world software engineering to be a rich,\nsustainable, and challenging testbed for evaluating the next generation of\nlanguage models. We therefore introduce SWE-bench, an evaluation framework\nincluding $2,294$ software engineering problems drawn from real GitHub issues\nand corresponding pull requests across $12$ popular Python repositories. Given\na codebase along with a description of an issue to be resolved, a language\nmodel is tasked with editing the codebase to address the issue. Resolving\nissues in SWE-bench frequently requires understanding and coordinating changes\nacross multiple functions, classes, and even files simultaneously, calling for\nmodels to interact with execution environments, process extremely long contexts\nand perform complex reasoning that goes far beyond traditional code generation.\nOur evaluations show that both state-of-the-art proprietary models and our\nfine-tuned model SWE-Llama can resolve only the simplest issues. Claude 2 and\nGPT-4 solve a mere $4.8$% and $1.7$% of instances respectively, even when\nprovided with an oracle retriever. Advances on SWE-bench represent steps\ntowards LMs that are more practical, intelligent, and autonomous.",
        "translated": "语言模型已经超越了我们有效评估它们的能力，但是为了它们未来的发展，研究它们能力的前沿是必不可少的。我们认为现实世界的软件工程是评估下一代语言模型的一个丰富的、可持续的和具有挑战性的测试平台。因此，我们介绍了 SWE-bench，这是一个评估框架，包括从真实的 GitHub 问题中提取的价值2,294美元的软件工程问题，以及对价值12美元的流行 Python 存储库的相应拉请求。给定一个代码库以及要解决的问题的描述，语言模型的任务是编辑代码库以解决问题。在 SWE-bench 中解决问题通常需要同时理解和协调多个函数、类甚至文件之间的变化，要求模型与执行环境交互，处理极长的上下文，并执行远远超出传统代码生成的复杂推理。我们的评估表明，最先进的专利模型和我们的微调模型 SWE-Llama 只能解决最简单的问题。Claude 2和 GPT-4分别解决了4.8 $% 和1.7 $% 的实例，即使提供了 Oracle 检索器。SWE-bench 的进展代表了实现更加实用、智能和自治的 LM 的步骤。"
    },
    {
        "title": "InstructRetro: Instruction Tuning post Retrieval-Augmented Pretraining",
        "url": "http://arxiv.org/abs/2310.07713v1",
        "pub_date": "2023-10-11",
        "summary": "Pretraining auto-regressive large language models (LLMs) with retrieval\ndemonstrates better perplexity and factual accuracy by leveraging external\ndatabases. However, the size of existing pretrained retrieval-augmented LLM is\nstill limited (e.g., Retro has 7.5B parameters), which limits the effectiveness\nof instruction tuning and zero-shot generalization. In this work, we introduce\nRetro 48B, the largest LLM pretrained with retrieval before instruction tuning.\nSpecifically, we continue to pretrain the 43B GPT model on additional 100\nbillion tokens using the Retro augmentation method by retrieving from 1.2\ntrillion tokens. The obtained foundation model, Retro 48B, largely outperforms\nthe original 43B GPT in terms of perplexity. After instruction tuning on Retro,\nInstructRetro demonstrates significant improvement over the instruction tuned\nGPT on zero-shot question answering (QA) tasks. Specifically, the average\nimprovement of InstructRetro is 7% over its GPT counterpart across 8 short-form\nQA tasks, and 10% over GPT across 4 challenging long-form QA tasks.\nSurprisingly, we find that one can ablate the encoder from InstructRetro\narchitecture and directly use its decoder backbone, while achieving comparable\nresults. We hypothesize that pretraining with retrieval makes its decoder good\nat incorporating context for QA. Our results highlights the promising direction\nto obtain a better GPT decoder for QA through continued pretraining with\nretrieval before instruction tuning.",
        "translated": "预训练的自回归大语言模型(LLM)检索表明更好的困惑和事实的准确性，利用外部数据库。然而，现有的预训练检索增强 LLM 的规模仍然是有限的(例如，Retro 有7.5 B 参数) ，这限制了指令调优和零镜头泛化的有效性。在这项工作中，我们介绍了 Retro 48B，最大的 LLM 预先训练与检索之前的指令调优。具体来说，我们继续使用 Retro 增强方法从1.2万亿个令牌中检索，对额外的1000亿个令牌预训练43B GPT 模型。所得到的基础模型，复古48B，大大优于原来的43B GPT 在困惑方面。在 Retro 上的指令调优之后，翘课显示了在零命中问题回答(QA)任务上指令调优 GPT 的显著改进。具体来说，在8个短形式的 QA 任务中，翘课教师的平均改进比 GPT 提高了7% ，在4个具有挑战性的长形式 QA 任务中，比 GPT 提高了10% 。令人惊讶的是，我们发现人们可以烧蚀的教学复古体系结构的编码器，并直接使用其解码器骨干，同时实现可比的结果。我们假设带检索的预训练使其译码器能够很好地结合上下文进行 QA。我们的研究结果强调了在指令调整之前通过持续的预训练和检索来获得更好的 GPT 解码器的有希望的方向。"
    },
    {
        "title": "Retrieve Anything To Augment Large Language Models",
        "url": "http://arxiv.org/abs/2310.07554v1",
        "pub_date": "2023-10-11",
        "summary": "Large language models (LLMs) face significant challenges stemming from the\ninherent limitations in knowledge, memory, alignment, and action. These\nchallenges cannot be addressed by LLMs alone, but should rely on assistance\nfrom the external world, such as knowledge base, memory store, demonstration\nexamples, and tools. Retrieval augmentation stands as a vital mechanism for\nbridging the gap between LLMs and the external assistance. However,\nconventional methods encounter two pressing issues. On one hand, the\ngeneral-purpose retrievers are not properly optimized for the retrieval\naugmentation of LLMs. On the other hand, the task-specific retrievers lack the\nrequired versatility, hindering their performance across the diverse retrieval\naugmentation scenarios.\n  In this work, we present a novel approach, the LLM Embedder, which\ncomprehensively support the diverse needs of LLMs' retrieval augmentation with\none unified embedding model. Training such an unified model is non-trivial, as\nvarious retrieval tasks aim to capture distinct semantic relationships, often\nsubject to mutual interference. To address this challenge, we systematically\noptimize our training methodology. This includes reward formulation based on\nLLMs' feedback, the stabilization of knowledge distillation, multi-task\nfine-tuning with explicit instructions, and the use of homogeneous in-batch\nnegative sampling. These optimization strategies contribute to the outstanding\nempirical performance of the LLM-Embedder. Notably, it yields remarkable\nenhancements in retrieval augmentation for LLMs, surpassing both\ngeneral-purpose and task-specific retrievers in various evaluation scenarios.\nThis project is made publicly available at\nhttps://github.com/FlagOpen/FlagEmbedding.",
        "translated": "大型语言模型(LLM)面临着来自知识、记忆、对齐和操作方面固有限制的重大挑战。这些挑战不能由 LLM 单独解决，而应该依赖外部世界的帮助，例如知识库、内存存储、演示示例和工具。检索增强是弥合长期有限管理模式与外部援助之间差距的一个重要机制。然而，传统的方法遇到了两个紧迫的问题。一方面，通用检索器没有针对 LLM 的检索增强进行适当的优化。另一方面，特定于任务的检索器缺乏所需的通用性，这阻碍了它们在各种检索增强场景中的性能。在这项工作中，我们提出了一种新的方法，LLM 嵌入器，全面支持检索扩充的不同需求与一个统一的嵌入模型。训练这样一个统一的模型是不平凡的，因为各种检索任务的目的是捕获不同的语义关系，往往受到相互干扰。为了应对这一挑战，我们系统地优化了培训方法。这包括基于 LLM 反馈的奖励制定、知识提取的稳定性、多任务的显式指令微调以及均匀批内负抽样的使用。这些优化策略有助于 LLM-Embedder 出色的经验性能。值得注意的是，它在 LLM 的检索增强方面产生了显著的增强，在各种评估场景中超过了通用检索器和特定于任务的检索器。这个项目在 https://github.com/flagopen/flagembedding 公开发布。"
    },
    {
        "title": "GMOCAT: A Graph-Enhanced Multi-Objective Method for Computerized\n  Adaptive Testing",
        "url": "http://arxiv.org/abs/2310.07477v1",
        "pub_date": "2023-10-11",
        "summary": "Computerized Adaptive Testing(CAT) refers to an online system that adaptively\nselects the best-suited question for students with various abilities based on\ntheir historical response records. Most CAT methods only focus on the quality\nobjective of predicting the student ability accurately, but neglect concept\ndiversity or question exposure control, which are important considerations in\nensuring the performance and validity of CAT. Besides, the students' response\nrecords contain valuable relational information between questions and knowledge\nconcepts. The previous methods ignore this relational information, resulting in\nthe selection of sub-optimal test questions. To address these challenges, we\npropose a Graph-Enhanced Multi-Objective method for CAT (GMOCAT). Firstly,\nthree objectives, namely quality, diversity and novelty, are introduced into\nthe Scalarized Multi-Objective Reinforcement Learning framework of CAT, which\nrespectively correspond to improving the prediction accuracy, increasing the\nconcept diversity and reducing the question exposure. We use an Actor-Critic\nRecommender to select questions and optimize three objectives simultaneously by\nthe scalarization function. Secondly, we utilize the graph neural network to\nlearn relation-aware embeddings of questions and concepts. These embeddings are\nable to aggregate neighborhood information in the relation graphs between\nquestions and concepts. We conduct experiments on three real-world educational\ndatasets, and show that GMOCAT not only outperforms the state-of-the-art\nmethods in the ability prediction, but also achieve superior performance in\nimproving the concept diversity and alleviating the question exposure. Our code\nis available at https://github.com/justarter/GMOCAT.",
        "translated": "计算机自适应测试(CAT)是指根据学生的历史回答记录，自适应地为具有不同能力的学生选择最适合的问题的在线系统。大多数计算机辅助测试(CAT)方法只着眼于准确预测学生能力的质量目标，而忽视了概念多样性或问题暴露控制，这是保证计算机辅助测试(CAT)成绩和有效性的重要因素。此外，学生的回答记录还包含了问题与知识概念之间有价值的关系信息。以前的方法忽略了这些关系信息，导致了次优测试题的选择。为了应对这些挑战，我们提出了一种基于图增强的多目标 CAT (GMOCAT)方法。首先，在计算机辅助测试的标量化多目标强化学习框架中引入质量、多样性和新颖性三个目标，分别对应于提高预测精度、增加概念多样性和减少问题暴露。我们使用一个行为者-批评者推荐系统来选择问题，并通过标量化函数同时优化三个目标。其次，利用图神经网络学习问题和概念的关系感知嵌入。这些嵌入能够在问题和概念之间的关系图中聚合邻域信息。我们在三个实际教育数据集上进行了实验，结果表明，GMOCAT 不仅在能力预测方面优于最先进的方法，而且在提高概念多样性和减少问题暴露方面也取得了较好的效果。我们的代码可以在 https://github.com/justarter/gmocat 找到。"
    },
    {
        "title": "Preliminary Results of a Scientometric Analysis of the German\n  Information Retrieval Community 2020-2023",
        "url": "http://arxiv.org/abs/2310.07346v1",
        "pub_date": "2023-10-11",
        "summary": "The German Information Retrieval community is located in two different\nsub-fields: Information and computer science. There are no current studies that\ninvestigate these communities on a scientometric level. Available studies only\nfocus on the information scientific part of the community. We generated a data\nset of 401 recent IR-related publications extracted from six core IR\nconferences from a mainly computer scientific background. We analyze this data\nset at the institutional and researcher level. The data set is publicly\nreleased, and we also demonstrate a mapping use case.",
        "translated": "德国信息检索社区位于两个不同的子领域: 信息和计算机科学。目前还没有科学计量学水平的研究来调查这些社区。现有的研究只集中在社区的信息科学部分。我们从主要计算机科学背景的六个核心国际关系会议中提取了401个最近与国际关系有关的出版物，生成了一个数据集。我们在机构和研究人员层面上分析这些数据集。数据集是公开发布的，我们还演示了一个映射用例。"
    },
    {
        "title": "A Completely Locale-independent Session-based Recommender System by\n  Leveraging Trained Model",
        "url": "http://arxiv.org/abs/2310.07281v1",
        "pub_date": "2023-10-11",
        "summary": "In this paper, we propose a solution that won the 10th prize in the KDD Cup\n2023 Challenge Task 2 (Next Product Recommendation for Underrepresented\nLanguages/Locales). Our approach involves two steps: (i) Identify candidate\nitem sets based on co-visitation, and (ii) Re-ranking the items using LightGBM\nwith locale-independent features, including session-based features and product\nsimilarity. The experiment demonstrated that the locale-independent model\nperformed consistently well across different test locales, and performed even\nbetter when incorporating data from other locales into the training.",
        "translated": "在本文中，我们提出了一个解决方案，赢得了在 KDD 杯2023挑战任务2(下一个产品推荐为代表性不足的语言/地区)第10名。我们的方法包括两个步骤: (i)基于共同访问确定候选项集，和(ii)使用与地区无关的特性(包括基于会话的特性和产品相似性)重新排序使用 LightGBM 的项。实验表明，区域无关模型在不同的测试区域表现一致，并且在将其他区域的数据融入训练时表现更好。"
    },
    {
        "title": "To Build Our Future, We Must Know Our Past: Contextualizing Paradigm\n  Shifts in Natural Language Processing",
        "url": "http://arxiv.org/abs/2310.07715v1",
        "pub_date": "2023-10-11",
        "summary": "NLP is in a period of disruptive change that is impacting our methodologies,\nfunding sources, and public perception. In this work, we seek to understand how\nto shape our future by better understanding our past. We study factors that\nshape NLP as a field, including culture, incentives, and infrastructure by\nconducting long-form interviews with 26 NLP researchers of varying seniority,\nresearch area, institution, and social identity. Our interviewees identify\ncyclical patterns in the field, as well as new shifts without historical\nparallel, including changes in benchmark culture and software infrastructure.\nWe complement this discussion with quantitative analysis of citation,\nauthorship, and language use in the ACL Anthology over time. We conclude by\ndiscussing shared visions, concerns, and hopes for the future of NLP. We hope\nthat this study of our field's past and present can prompt informed discussion\nof our community's implicit norms and more deliberate action to consciously\nshape the future.",
        "translated": "NLP 正处于一个颠覆性变革的时期，这种变革正在影响我们的方法论、资金来源和公众观念。在这项工作中，我们寻求了解如何通过更好地理解我们的过去来塑造我们的未来。我们通过对26位资历、研究领域、机构和社会认同不同的自然语言处理研究者进行长期访谈，研究影响自然语言处理领域的因素，包括文化、激励和基础设施。我们的受访者确定了该领域的周期性模式，以及没有历史相似性的新变化，包括基准文化和软件基础设施的变化。我们通过对 ACL 选集中的引文、作者和语言使用的定量分析来补充这个讨论。最后，我们讨论了 NLP 未来的共同愿景、关注点和希望。我们希望这项对我们这个领域的过去和现在的研究能够促进对我们社会的隐性规范的知情讨论，并且能够采取更有意识的行动来有意识地塑造未来。"
    },
    {
        "title": "Found in the Middle: Permutation Self-Consistency Improves Listwise\n  Ranking in Large Language Models",
        "url": "http://arxiv.org/abs/2310.07712v1",
        "pub_date": "2023-10-11",
        "summary": "Large language models (LLMs) exhibit positional bias in how they use context,\nwhich especially complicates listwise ranking. To address this, we propose\npermutation self-consistency, a form of self-consistency over ranking list\noutputs of black-box LLMs. Our key idea is to marginalize out different list\norders in the prompt to produce an order-independent ranking with less\npositional bias. First, given some input prompt, we repeatedly shuffle the list\nin the prompt and pass it through the LLM while holding the instructions the\nsame. Next, we aggregate the resulting sample of rankings by computing the\ncentral ranking closest in distance to all of them, marginalizing out prompt\norder biases in the process. Theoretically, we prove the robustness of our\nmethod, showing convergence to the true ranking in the presence of random\nperturbations. Empirically, on five list-ranking datasets in sorting and\npassage reranking, our approach improves scores from conventional inference by\nup to 7-18% for GPT-3.5 and 8-16% for LLaMA v2 (70B), surpassing the previous\nstate of the art in passage reranking. Our code is at\nhttps://github.com/castorini/perm-sc.",
        "translated": "大型语言模型(LLM)在如何使用上下文方面表现出位置偏差，这尤其使列表排序复杂化。为了解决这个问题，我们提出了排列自洽，一种黑盒 LLM 排序列表输出的自洽形式。我们的关键思想是在提示中边缘化不同的列表订单，以产生一个位置偏差较小的订单独立的排名。首先，给定一些输入提示符，我们在提示符中重复洗牌列表，并通过 LLM 传递它，同时保留相同的指令。接下来，我们通过计算距离所有排名最近的中心排名来聚合最终的排名样本，在这个过程中排除快速排序的偏差。从理论上证明了该方法的鲁棒性，在存在随机扰动的情况下，证明了该方法的收敛性。经验上，在排序和通过重新排序的五个列表排名数据集中，我们的方法将 GPT-3.5的常规推断分数提高了7-18% ，LLaMA v2(70B)的分数提高了8-16% ，超过了以前的艺术状态在通过重新排序。我们的代码是 https://github.com/castorini/perm-sc。"
    },
    {
        "title": "DiPmark: A Stealthy, Efficient and Resilient Watermark for Large\n  Language Models",
        "url": "http://arxiv.org/abs/2310.07710v1",
        "pub_date": "2023-10-11",
        "summary": "Watermarking techniques offer a promising way to secure data via embedding\ncovert information into the data. A paramount challenge in the domain lies in\npreserving the distribution of original data during watermarking. Our research\nextends and refines existing watermarking framework, placing emphasis on the\nimportance of a distribution-preserving (DiP) watermark. Contrary to the\ncurrent strategies, our proposed DiPmark preserves the original token\ndistribution during watermarking (stealthy), is detectable without access to\nthe language model API or weights (efficient), and is robust to moderate\nchanges of tokens (resilient). This is achieved by incorporating a novel\nreweight strategy, combined with a hash function that assigns unique\n\\textit{i.i.d.} ciphers based on the context. The empirical benchmarks of our\napproach underscore its stealthiness, efficiency, and resilience, making it a\nrobust solution for watermarking tasks that demand impeccable quality\npreservation.",
        "translated": "水印技术通过在数据中嵌入隐蔽信息，为数据安全提供了一种有前途的方法。该领域最大的挑战在于在水印过程中保持原始数据的分布。我们的研究扩展和完善了现有的水印框架，强调了分布保持(DiP)水印的重要性。与目前的策略相反，我们提出的 DiPmark 在水印(隐形)期间保留了原始的令牌分布，在不访问语言模型 API 或权重(有效)的情况下可检测，并且对令牌的适度变化(弹性)具有鲁棒性。这是通过结合一种新的重新加权策略实现的，该策略结合了一个哈希函数，该函数根据上下文分配唯一的文本{ i.i.d. }密码。我们方法的经验基准突出了它的隐蔽性、效率和弹性，使其成为一个强大的水印任务解决方案，需要无可挑剔的质量保存。"
    },
    {
        "title": "MatFormer: Nested Transformer for Elastic Inference",
        "url": "http://arxiv.org/abs/2310.07707v1",
        "pub_date": "2023-10-11",
        "summary": "Transformer models are deployed in a wide range of settings, from\nmulti-accelerator clusters to standalone mobile phones. The diverse inference\nconstraints in these scenarios necessitate practitioners to train foundation\nmodels such as PaLM 2, Llama, &amp; ViTs as a series of models of varying sizes.\nDue to significant training costs, only a select few model sizes are trained\nand supported, limiting more fine-grained control over relevant tradeoffs,\nincluding latency, cost, and accuracy. This work introduces MatFormer, a nested\nTransformer architecture designed to offer elasticity in a variety of\ndeployment constraints. Each Feed Forward Network (FFN) block of a MatFormer\nmodel is jointly optimized with a few nested smaller FFN blocks. This training\nprocedure allows for the Mix'n'Match of model granularities across layers --\ni.e., a trained universal MatFormer model enables extraction of hundreds of\naccurate smaller models, which were never explicitly optimized. We empirically\ndemonstrate MatFormer's effectiveness across different model classes (decoders\n&amp; encoders), modalities (language &amp; vision), and scales (up to 2.6B\nparameters). We find that a 2.6B decoder-only MatFormer language model (MatLM)\nallows us to extract smaller models spanning from 1.5B to 2.6B, each exhibiting\ncomparable validation loss and one-shot downstream evaluations to their\nindependently trained counterparts. Furthermore, we observe that smaller\nencoders extracted from a universal MatFormer-based ViT (MatViT) encoder\npreserve the metric-space structure for adaptive large-scale retrieval.\nFinally, we showcase that speculative decoding with the accurate and consistent\nsubmodels extracted from MatFormer can further reduce inference latency.",
        "translated": "从多加速器集群到独立移动电话，变压器模型被广泛应用于各种设置中。这些场景中不同的推理约束要求从业人员将基础模型如 PalM 2、 Llama 和 ViTs 作为一系列不同大小的模型进行培训。由于大量的培训成本，只有少数选定的模型大小得到了培训和支持，限制了对相关权衡(包括延迟、成本和准确性)的更细粒度控制。这项工作介绍了 MatForm，这是一个嵌套的 Transformer 体系结构，旨在在各种部署约束中提供灵活性。每个前馈网络(FFN)块的一个 MatForm 模型是联合优化的一些嵌套的较小的 FFN 块。这个训练过程允许跨层的模型粒度的混合和匹配——例如，一个经过训练的通用 MatForm 模型能够提取数百个精确的小模型，这些模型从未被明确地优化过。我们通过经验证明 MatForm 在不同的模型类(解码器和编码器) ，模式(语言和视觉)和尺度(高达2.6 B 参数)中的有效性。我们发现，一个2.6 B 解码器的 MatForm 语言模型(MatLM)允许我们提取范围从1.5 B 到2.6 B 的较小模型，每个模型都表现出与其独立训练的对应物相当的验证损失和一次性下游评估。此外，我们观察到较小的编码器提取的通用 MatForm-based ViT (MatViT)编码器保留度量空间结构的自适应大规模检索。最后，我们展示了使用从 MatForm 中提取的准确和一致的子模型进行推理解码可以进一步减少推理延迟。"
    },
    {
        "title": "Ferret: Refer and Ground Anything Anywhere at Any Granularity",
        "url": "http://arxiv.org/abs/2310.07704v1",
        "pub_date": "2023-10-11",
        "summary": "We introduce Ferret, a new Multimodal Large Language Model (MLLM) capable of\nunderstanding spatial referring of any shape or granularity within an image and\naccurately grounding open-vocabulary descriptions. To unify referring and\ngrounding in the LLM paradigm, Ferret employs a novel and powerful hybrid\nregion representation that integrates discrete coordinates and continuous\nfeatures jointly to represent a region in the image. To extract the continuous\nfeatures of versatile regions, we propose a spatial-aware visual sampler, adept\nat handling varying sparsity across different shapes. Consequently, Ferret can\naccept diverse region inputs, such as points, bounding boxes, and free-form\nshapes. To bolster the desired capability of Ferret, we curate GRIT, a\ncomprehensive refer-and-ground instruction tuning dataset including 1.1M\nsamples that contain rich hierarchical spatial knowledge, with 95K hard\nnegative data to promote model robustness. The resulting model not only\nachieves superior performance in classical referring and grounding tasks, but\nalso greatly outperforms existing MLLMs in region-based and\nlocalization-demanded multimodal chatting. Our evaluations also reveal a\nsignificantly improved capability of describing image details and a remarkable\nalleviation in object hallucination. Code and data will be available at\nhttps://github.com/apple/ml-ferret",
        "translated": "我们介绍了 Ferret，一个新的多模态大语言模型(MLLM) ，它能够理解图像中任何形状或粒度的空间指称，并且能够准确地基于开放词汇表描述。为了在 LLM 范式中统一引用和接地，Ferret 采用了一种新颖而强大的混合区域表示方法，该方法集离散坐标和连续特征于一体，共同表示图像中的一个区域。为了提取多功能区域的连续特征，我们提出了一个空间感知的视觉采样器，擅长处理不同形状的不同稀疏性。因此，雪貂可以接受不同的区域输入，如点，边界框，和自由形状。为了提高 Ferret 的预期能力，我们策划了 GRIT，一个全面的参考和地面指令调优数据集，包括110万个样本，其中包含丰富的分层空间知识，以及95K 硬负数据，以提高模型的鲁棒性。该模型不仅在经典查询和接地任务中取得了较好的性能，而且在基于区域和本地化需求的多通道聊天中也大大优于现有的多通道聊天模型。我们的评估还显示，显着提高了描述图像细节的能力，并显着减轻对象的幻觉。代码和数据将在 https://github.com/apple/ml-ferret 公布"
    },
    {
        "title": "Knowledge-enhanced Memory Model for Emotional Support Conversation",
        "url": "http://arxiv.org/abs/2310.07700v1",
        "pub_date": "2023-10-11",
        "summary": "The prevalence of mental disorders has become a significant issue, leading to\nthe increased focus on Emotional Support Conversation as an effective\nsupplement for mental health support. Existing methods have achieved compelling\nresults, however, they still face three challenges: 1) variability of emotions,\n2) practicality of the response, and 3) intricate strategy modeling. To address\nthese challenges, we propose a novel knowledge-enhanced Memory mODEl for\nemotional suppoRt coNversation (MODERN). Specifically, we first devise a\nknowledge-enriched dialogue context encoding to perceive the dynamic emotion\nchange of different periods of the conversation for coherent user state\nmodeling and select context-related concepts from ConceptNet for practical\nresponse generation. Thereafter, we implement a novel memory-enhanced strategy\nmodeling module to model the semantic patterns behind the strategy categories.\nExtensive experiments on a widely used large-scale dataset verify the\nsuperiority of our model over cutting-edge baselines.",
        "translated": "精神障碍的流行已成为一个重要的问题，导致越来越重视情绪支持对话作为一个有效的补充精神健康支持。现有的方法已经取得了引人注目的成果，然而，它们仍然面临三个挑战: 1)情绪的可变性，2)反应的实用性，3)复杂的策略建模。为了应对这些挑战，我们提出了一个新颖的知识增强的情绪支持对话记忆模型(MODERN)。具体来说，我们首先设计了一个知识丰富的对话上下文编码来感知不同时段对话的动态情绪变化，用于连贯的用户状态建模，并从概念网中选择与上下文相关的概念进行实际的响应生成。然后，我们实现了一个新的记忆增强策略建模模块来模拟策略类别背后的语义模式。在一个广泛使用的大规模数据集上的大量实验验证了我们的模型相对于最前沿基线的优越性。"
    },
    {
        "title": "Composite Backdoor Attacks Against Large Language Models",
        "url": "http://arxiv.org/abs/2310.07676v1",
        "pub_date": "2023-10-11",
        "summary": "Large language models (LLMs) have demonstrated superior performance compared\nto previous methods on various tasks, and often serve as the foundation models\nfor many researches and services. However, the untrustworthy third-party LLMs\nmay covertly introduce vulnerabilities for downstream tasks. In this paper, we\nexplore the vulnerability of LLMs through the lens of backdoor attacks.\nDifferent from existing backdoor attacks against LLMs, ours scatters multiple\ntrigger keys in different prompt components. Such a Composite Backdoor Attack\n(CBA) is shown to be stealthier than implanting the same multiple trigger keys\nin only a single component. CBA ensures that the backdoor is activated only\nwhen all trigger keys appear. Our experiments demonstrate that CBA is effective\nin both natural language processing (NLP) and multimodal tasks. For instance,\nwith $3\\%$ poisoning samples against the LLaMA-7B model on the Emotion dataset,\nour attack achieves a $100\\%$ Attack Success Rate (ASR) with a False Triggered\nRate (FTR) below $2.06\\%$ and negligible model accuracy degradation. The unique\ncharacteristics of our CBA can be tailored for various practical scenarios,\ne.g., targeting specific user groups. Our work highlights the necessity of\nincreased security research on the trustworthiness of foundation LLMs.",
        "translated": "大语言模型(LLM)在各种任务中的性能优于以往的方法，常常作为许多研究和服务的基础模型。但是，不可信的第三方 LLM 可能会秘密地为下游任务引入漏洞。本文从后门攻击的角度探讨 LLM 的脆弱性。与现有针对 LLM 的后门攻击不同，我们将多个触发键分散在不同的提示组件中。这样的复合后门攻击(CBA)被证明比只在单个组件中植入相同的多个触发键要隐蔽得多。CBA 确保后门只有在所有触发键出现时才被激活。我们的实验表明，CBA 在自然语言处理(NLP)和多模态任务中都是有效的。例如，在情感数据集中对 LLaMA-7B 模型进行3% 的中毒样本，我们的攻击获得了100% 的攻击成功率(ASR) ，错误触发率(FTR)低于2.06% ，模型精度降低可以忽略不计。我们的 CBA 的独特特征可以根据不同的实际情况进行调整，例如，针对特定的用户群。我们的工作强调了加强基金会 LLM 可信度安全性研究的必要性。"
    },
    {
        "title": "Well Begun is Half Done: Generator-agnostic Knowledge Pre-Selection for\n  Knowledge-Grounded Dialogue",
        "url": "http://arxiv.org/abs/2310.07659v2",
        "pub_date": "2023-10-11",
        "summary": "Accurate knowledge selection is critical in knowledge-grounded dialogue\nsystems. Towards a closer look at it, we offer a novel perspective to organize\nexisting literature, i.e., knowledge selection coupled with, after, and before\ngeneration. We focus on the third under-explored category of study, which can\nnot only select knowledge accurately in advance, but has the advantage to\nreduce the learning, adjustment, and interpretation burden of subsequent\nresponse generation models, especially LLMs. We propose GATE, a\ngenerator-agnostic knowledge selection method, to prepare knowledge for\nsubsequent response generation models by selecting context-related knowledge\namong different knowledge structures and variable knowledge requirements.\nExperimental results demonstrate the superiority of GATE, and indicate that\nknowledge selection before generation is a lightweight yet effective way to\nfacilitate LLMs (e.g., ChatGPT) to generate more informative responses.",
        "translated": "在基于知识的对话系统中，准确的知识选择至关重要。为了更仔细地研究它，我们提供了一个新颖的视角来组织现有的文献，即，知识选择加上后代和前代。我们重点研究了第三类未被探索的研究，它不仅能够提前准确地选择知识，而且有利于减少后续反应生成模型，特别是 LLM 的学习，调整和解释负担。提出了一种基于生成器无关的知识选择方法 GATE，通过在不同的知识结构和可变的知识需求之间选择与上下文相关的知识，为后续的响应生成模型准备知识。实验结果证明了 GATE 的优越性，并表明生成前知识选择是一种轻量级的有效方法，可以促进 LLM (如 ChatGPT)生成更多的信息响应。"
    },
    {
        "title": "Audio-Visual Neural Syntax Acquisition",
        "url": "http://arxiv.org/abs/2310.07654v1",
        "pub_date": "2023-10-11",
        "summary": "We study phrase structure induction from visually-grounded speech. The core\nidea is to first segment the speech waveform into sequences of word segments,\nand subsequently induce phrase structure using the inferred segment-level\ncontinuous representations. We present the Audio-Visual Neural Syntax Learner\n(AV-NSL) that learns phrase structure by listening to audio and looking at\nimages, without ever being exposed to text. By training on paired images and\nspoken captions, AV-NSL exhibits the capability to infer meaningful phrase\nstructures that are comparable to those derived by naturally-supervised text\nparsers, for both English and German. Our findings extend prior work in\nunsupervised language acquisition from speech and grounded grammar induction,\nand present one approach to bridge the gap between the two topics.",
        "translated": "我们研究视觉接地语言的短语结构归纳。其核心思想是首先将语音波形分割成词段序列，然后利用推断的词段级连续表示方法归纳出短语结构。本文介绍了一种通过听音频和看图像来学习短语结构的视听神经句法学习者(AV-NSL) ，他们从未接触过文本。通过对配对图像和口语说明的训练，AV-NSL 展示了推断有意义的短语结构的能力，这些结构可以与自然监督文本解析器得出的短语结构进行比较，对于英语和德语都是如此。我们的研究结果扩展了先前的无监督语言习得研究，包括言语习得和接地语法归纳，并提出了一种弥合这两个主题之间差距的方法。"
    },
    {
        "title": "Fine-Tuning LLaMA for Multi-Stage Text Retrieval",
        "url": "http://arxiv.org/abs/2310.08319v1",
        "pub_date": "2023-10-12",
        "summary": "The effectiveness of multi-stage text retrieval has been solidly demonstrated\nsince before the era of pre-trained language models. However, most existing\nstudies utilize models that predate recent advances in large language models\n(LLMs). This study seeks to explore potential improvements that\nstate-of-the-art LLMs can bring. We conduct a comprehensive study, fine-tuning\nthe latest LLaMA model both as a dense retriever (RepLLaMA) and as a pointwise\nreranker (RankLLaMA) for both passage retrieval and document retrieval using\nthe MS MARCO datasets. Our findings demonstrate that the effectiveness of large\nlanguage models indeed surpasses that of smaller models. Additionally, since\nLLMs can inherently handle longer contexts, they can represent entire documents\nholistically, obviating the need for traditional segmenting and pooling\nstrategies. Furthermore, evaluations on BEIR demonstrate that our\nRepLLaMA-RankLLaMA pipeline exhibits strong zero-shot effectiveness. Model\ncheckpoints from this study are available on HuggingFace.",
        "translated": "在预训练语言模型出现之前，多阶段文本检索的有效性就已经得到了充分的证明。然而，大多数现有的研究所使用的模型早于大型语言模型(LLM)的最新进展。这项研究旨在探索最先进的 LLM 可以带来的潜在改善。我们进行了一项全面的研究，对最新的 LLaMA 模型进行了微调，既作为一个密集检索器(RepLLaMA) ，也作为一个点态重新排序器(RankLLaMA) ，用于使用 MS MARCO 数据集进行通道检索和文献检索。我们的研究结果表明，大型语言模型的有效性确实超过了小型语言模型。此外，由于 LLM 可以固有地处理较长的上下文，它们可以全面地表示整个文档，从而避免了传统的分段和池策略的需要。此外，对 BEIR 的评估表明，我们的 RepLLaMA-RankLLaMA 管道具有很强的零激发效率。这项研究的模型检查点可以在 HuggingFace 上找到。"
    },
    {
        "title": "On Using GUI Interaction Data to Improve Text Retrieval-based Bug\n  Localization",
        "url": "http://arxiv.org/abs/2310.08083v1",
        "pub_date": "2023-10-12",
        "summary": "One of the most important tasks related to managing bug reports is localizing\nthe fault so that a fix can be applied. As such, prior work has aimed to\nautomate this task of bug localization by formulating it as an information\nretrieval problem, where potentially buggy files are retrieved and ranked\naccording to their textual similarity with a given bug report. However, there\nis often a notable semantic gap between the information contained in bug\nreports and identifiers or natural language contained within source code files.\nFor user-facing software, there is currently a key source of information that\ncould aid in bug localization, but has not been thoroughly investigated -\ninformation from the GUI.\n  We investigate the hypothesis that, for end user-facing applications,\nconnecting information in a bug report with information from the GUI, and using\nthis to aid in retrieving potentially buggy files, can improve upon existing\ntechniques for bug localization. To examine this phenomenon, we conduct a\ncomprehensive empirical study that augments four baseline techniques for bug\nlocalization with GUI interaction information from a reproduction scenario to\n(i) filter out potentially irrelevant files, (ii) boost potentially relevant\nfiles, and (iii) reformulate text-retrieval queries. To carry out our study, we\nsource the current largest dataset of fully-localized and reproducible real\nbugs for Android apps, with corresponding bug reports, consisting of 80 bug\nreports from 39 popular open-source apps. Our results illustrate that\naugmenting traditional techniques with GUI information leads to a marked\nincrease in effectiveness across multiple metrics, including a relative\nincrease in Hits@10 of 13-18%. Additionally, through further analysis, we find\nthat our studied augmentations largely complement existing techniques.",
        "translated": "与管理 bug 报告相关的最重要的任务之一是对错误进行本地化，以便应用修复程序。因此，之前的工作旨在将 bug 定位任务自动化，将其作为一个信息检索问题来处理，在这个问题中，可能存在 bug 的文件被检索出来，并根据它们与给定 bug 报告的文本相似性进行排序。但是，bug 报告中包含的信息与源代码文件中包含的标识符或自然语言之间往往存在显著的语义差异。对于面向用户的软件，目前有一个关键的信息源可以帮助 bug 定位，但是还没有被彻底研究-来自 GUI 的信息。我们研究的假设是，对于面向终端用户的应用程序，将 bug 报告中的信息与来自 GUI 的信息连接起来，并使用这些信息来帮助检索可能存在 bug 的文件，可以改进现有的 bug 定位技术。为了研究这一现象，我们进行了一项全面的实证研究，增加了四个基线技术，用于 bug 定位和 GUI 交互信息，从复制场景到(i)过滤掉潜在的不相关文件，(ii)增强潜在的相关文件，和(iii)重新制定文本检索查询。为了开展我们的研究，我们为 Android 应用程序提供了当前最大的本地化和可重现的真实 bug 数据集，以及相应的 bug 报告，包括来自39个流行的开源应用程序的80个 bug 报告。我们的研究结果表明，使用 GUI 信息增强传统技术可以显著提高多个指标的有效性，包括 Hits@10的相对增加13-18% 。此外，通过进一步的分析，我们发现我们研究的增强在很大程度上补充了现有的技术。"
    },
    {
        "title": "Rethinking Negative Pairs in Code Search",
        "url": "http://arxiv.org/abs/2310.08069v1",
        "pub_date": "2023-10-12",
        "summary": "Recently, contrastive learning has become a key component in fine-tuning code\nsearch models for software development efficiency and effectiveness. It pulls\ntogether positive code snippets while pushing negative samples away given\nsearch queries. Among contrastive learning, InfoNCE is the most widely used\nloss function due to its better performance. However, the following problems in\nnegative samples of InfoNCE may deteriorate its representation learning: 1) The\nexistence of false negative samples in large code corpora due to duplications.\n2). The failure to explicitly differentiate between the potential relevance of\nnegative samples. As an example, a bubble sorting algorithm example is less\n``negative'' than a file saving function for the quick sorting algorithm query.\nIn this paper, we tackle the above problems by proposing a simple yet effective\nSoft-InfoNCE loss that inserts weight terms into InfoNCE. In our proposed loss\nfunction, we apply three methods to estimate the weights of negative pairs and\nshow that the vanilla InfoNCE loss is a special case of Soft-InfoNCE.\nTheoretically, we analyze the effects of Soft-InfoNCE on controlling the\ndistribution of learnt code representations and on deducing a more precise\nmutual information estimation. We furthermore discuss the superiority of\nproposed loss functions with other design alternatives. Extensive experiments\ndemonstrate the effectiveness of Soft-InfoNCE and weights estimation methods\nunder state-of-the-art code search models on a large-scale public dataset\nconsisting of six programming languages. Source code is available at\n\\url{https://github.com/Alex-HaochenLi/Soft-InfoNCE}.",
        "translated": "目前，对比学习已经成为微调代码搜索模型以提高软件开发效率和有效性的关键组成部分。它将正面的代码片段整合在一起，同时将负面的样本推出给定的搜索查询。在对比学习中，InfoNCE 因其良好的性能而成为应用最广泛的损失函数。然而，InfoNCE 的负样本存在以下问题，可能会影响其表征学习: 1)大型编码语料库中存在重复的假负样本。2).未能明确区分负面样本的潜在相关性。举个例子，一个气泡排序算法的例子比一个快速排序算法查询的文件保存功能要少一些“负面”。在本文中，我们通过提出一个简单而有效的软信息丢失来解决上述问题，即在信息丢失中插入权重项。在我们提出的损失函数中，我们使用了三种方法来估计负对的权重，并且证明了普通的 InfoNCE 损失是软信息 NCE 的一个特例。从理论上分析了软信息 NCE 对控制学习代码表示分布的影响，以及对推导出更精确的互信息估计的影响。我们进一步讨论了提出的损失函数与其他设计方案的优越性。大量的实验表明，在最先进的代码搜索模型下，软信息 NCE 和权重估计方法在一个由六种编程语言组成的大规模公共数据集上是有效的。源代码可在 url { https://github.com/alex-haochenli/soft-infonce }获得。"
    },
    {
        "title": "Rethinking Large-scale Pre-ranking System: Entire-chain Cross-domain\n  Models",
        "url": "http://arxiv.org/abs/2310.08039v1",
        "pub_date": "2023-10-12",
        "summary": "Industrial systems such as recommender systems and online advertising, have\nbeen widely equipped with multi-stage architectures, which are divided into\nseveral cascaded modules, including matching, pre-ranking, ranking and\nre-ranking. As a critical bridge between matching and ranking, existing\npre-ranking approaches mainly endure sample selection bias (SSB) problem owing\nto ignoring the entire-chain data dependence, resulting in sub-optimal\nperformances. In this paper, we rethink pre-ranking system from the perspective\nof the entire sample space, and propose Entire-chain Cross-domain Models (ECM),\nwhich leverage samples from the whole cascaded stages to effectively alleviate\nSSB problem. Besides, we design a fine-grained neural structure named ECMM to\nfurther improve the pre-ranking accuracy. Specifically, we propose a\ncross-domain multi-tower neural network to comprehensively predict for each\nstage result, and introduce the sub-networking routing strategy with $L0$\nregularization to reduce computational costs. Evaluations on real-world\nlarge-scale traffic logs demonstrate that our pre-ranking models outperform\nSOTA methods while time consumption is maintained within an acceptable level,\nwhich achieves better trade-off between efficiency and effectiveness.",
        "translated": "推荐系统和在线广告等工业系统已经广泛地配备了多阶段的体系结构，这些体系结构被划分为多个级联模块，包括匹配、预排序、排序和重排序。作为匹配与排序之间的关键桥梁，现有的预排序方法由于忽略了全链数据的相关性，主要承受样本选择偏差(SSB)问题，导致性能不理想。本文从整个样本空间的角度重新思考预排序系统，提出了利用整个级联阶段的样本有效缓解 SSB 问题的整链跨域模型(ECM)。此外，我们设计了一个细粒度的神经结构 ECMM，以进一步提高预排序的准确性。具体来说，我们提出了一种跨域多塔神经网络来综合预测每个阶段的结果，并引入了子网路由策略与 $L0 $正则化，以降低计算成本。对现实世界大规模交通日志的评估表明，我们的预排序模型优于 SOTA 方法，同时时间消耗保持在一个可接受的水平，这实现了更好的效率和有效性之间的权衡。"
    },
    {
        "title": "Continual Learning via Manifold Expansion Replay",
        "url": "http://arxiv.org/abs/2310.08038v1",
        "pub_date": "2023-10-12",
        "summary": "In continual learning, the learner learns multiple tasks in sequence, with\ndata being acquired only once for each task. Catastrophic forgetting is a major\nchallenge to continual learning. To reduce forgetting, some existing\nrehearsal-based methods use episodic memory to replay samples of previous\ntasks. However, in the process of knowledge integration when learning a new\ntask, this strategy also suffers from catastrophic forgetting due to an\nimbalance between old and new knowledge. To address this problem, we propose a\nnovel replay strategy called Manifold Expansion Replay (MaER). We argue that\nexpanding the implicit manifold of the knowledge representation in the episodic\nmemory helps to improve the robustness and expressiveness of the model. To this\nend, we propose a greedy strategy to keep increasing the diameter of the\nimplicit manifold represented by the knowledge in the buffer during memory\nmanagement. In addition, we introduce Wasserstein distance instead of cross\nentropy as distillation loss to preserve previous knowledge. With extensive\nexperimental validation on MNIST, CIFAR10, CIFAR100, and TinyImageNet, we show\nthat the proposed method significantly improves the accuracy in continual\nlearning setup, outperforming the state of the arts.",
        "translated": "在连续学习中，学习者依次学习多个任务，每个任务只获取一次数据。灾难性遗忘是持续学习的主要挑战。为了减少遗忘，一些现有的基于排练的方法使用情景记忆来重播以前任务的样本。然而，在学习新任务的知识整合过程中，由于新旧知识的不平衡，这种策略也会遭受灾难性遗忘。为了解决这个问题，我们提出了一种新的重放策略，称为流形扩展重放(MaER)。我们认为扩展情景记忆中知识表示的内隐流形有助于提高模型的鲁棒性和表达能力。为此，我们提出了一种贪婪策略，在内存管理过程中不断增加由缓冲区中的知识表示的隐式流形的直径。另外，为了保留已有的知识，我们引入了 Wasserstein 距离代替交叉熵作为蒸馏损失。通过对 MNIST，CIFAR10，CIFAR100和 TinyImageNet 的广泛实验验证，我们表明所提出的方法显着提高了连续学习设置的准确性，超过了最先进的水平。"
    },
    {
        "title": "Tree-Planner: Efficient Close-loop Task Planning with Large Language\n  Models",
        "url": "http://arxiv.org/abs/2310.08582v1",
        "pub_date": "2023-10-12",
        "summary": "This paper studies close-loop task planning, which refers to the process of\ngenerating a sequence of skills (a plan) to accomplish a specific goal while\nadapting the plan based on real-time observations. Recently, prompting Large\nLanguage Models (LLMs) to generate actions iteratively has become a prevalent\nparadigm due to its superior performance and user-friendliness. However, this\nparadigm is plagued by two inefficiencies: high token consumption and redundant\nerror correction, both of which hinder its scalability for large-scale testing\nand applications. To address these issues, we propose Tree-Planner, which\nreframes task planning with LLMs into three distinct phases: plan sampling,\naction tree construction, and grounded deciding. Tree-Planner starts by using\nan LLM to sample a set of potential plans before execution, followed by the\naggregation of them to form an action tree. Finally, the LLM performs a\ntop-down decision-making process on the tree, taking into account real-time\nenvironmental information. Experiments show that Tree-Planner achieves\nstate-of-the-art performance while maintaining high efficiency. By decomposing\nLLM queries into a single plan-sampling call and multiple grounded-deciding\ncalls, a considerable part of the prompt are less likely to be repeatedly\nconsumed. As a result, token consumption is reduced by 92.2% compared to the\npreviously best-performing model. Additionally, by enabling backtracking on the\naction tree as needed, the correction process becomes more flexible, leading to\na 40.5% decrease in error corrections. Project page:\nhttps://tree-planner.github.io/",
        "translated": "本文研究了闭环任务规划，即在实时观察的基础上调整任务规划，生成一系列完成特定目标的技能(计划)的过程。最近，提示大型语言模型(LLM)迭代生成操作已经成为一个流行的范例，由于其卓越的性能和用户友好性。然而，这种范式受到两个效率低下的困扰: 高令牌消耗和冗余错误纠正，这两者都阻碍了它在大规模测试和应用程序中的可伸缩性。为了解决这些问题，我们提出了树型规划器，它将具有 LLM 的任务规划重构为三个不同的阶段: 计划抽样、行动树构建和接地决策。Tree-Planner 首先使用 LLM 在执行前对一组可能的计划进行抽样，然后对它们进行聚合以形成一个操作树。最后，LLM 在树上执行自顶向下的决策过程，同时考虑到实时环境信息。实验表明，该算法在保持高效率的同时，实现了最佳的性能。通过将 LLM 查询分解为单个计划抽样调用和多个接地决策调用，提示符的相当大一部分不太可能被重复使用。因此，令牌消耗比以前性能最好的模型减少了92.2% 。此外，通过根据需要启用动作树上的回溯，纠正过程变得更加灵活，从而使错误纠正减少了40.5% 。项目主页:  https://tree-planner.github.io/"
    },
    {
        "title": "Visual Data-Type Understanding does not emerge from Scaling\n  Vision-Language Models",
        "url": "http://arxiv.org/abs/2310.08577v1",
        "pub_date": "2023-10-12",
        "summary": "Recent advances in the development of vision-language models (VLMs) are\nyielding remarkable success in recognizing visual semantic content, including\nimpressive instances of compositional image understanding. Here, we introduce\nthe novel task of \\textit{Visual Data-Type Identification}, a basic perceptual\nskill with implications for data curation (e.g., noisy data-removal from large\ndatasets, domain-specific retrieval) and autonomous vision (e.g.,\ndistinguishing changing weather conditions from camera lens staining). We\ndevelop two datasets consisting of animal images altered across a diverse set\nof 27 visual \\textit{data-types}, spanning four broad categories. An extensive\nzero-shot evaluation of 39 VLMs, ranging from 100M to 80B parameters, shows a\nnuanced performance landscape. While VLMs are reasonably good at identifying\ncertain stylistic \\textit{data-types}, such as cartoons and sketches, they\nstruggle with simpler \\textit{data-types} arising from basic manipulations like\nimage rotations or additive noise. Our findings reveal that (i) model scaling\nalone yields marginal gains for contrastively-trained models like CLIP, and\n(ii) there is a pronounced drop in performance for the largest\nauto-regressively trained VLMs like OpenFlamingo. This finding points to a\nblind spot in current frontier VLMs: they excel in recognizing semantic content\nbut fail to acquire an understanding of visual \\textit{data-types} through\nscaling. By analyzing the pre-training distributions of these models and\nincorporating \\textit{data-type} information into the captions during\nfine-tuning, we achieve a significant enhancement in performance. By exploring\nthis previously uncharted task, we aim to set the stage for further advancing\nVLMs to equip them with visual data-type understanding. Code and datasets are\nreleased \\href{https://github.com/bethgelab/DataTypeIdentification}{here}.",
        "translated": "视觉语言模型(VLM)的最新进展在识别视觉语义内容方面取得了显著的成功，包括令人印象深刻的组合图像理解实例。在这里，我们介绍了一个新颖的任务，文本{视觉数据类型识别} ，一个基本的知觉技能与暗示的数据管理(例如，噪音数据从大数据集，领域特定检索)和自主视觉(例如，区分变化的天气条件从相机镜头染色)。我们开发了两个数据集，包括在27个不同的视觉文本(数据类型)中改变的动物图像，跨越四大类。对39个 VLM (从100M 到80B 参数)进行了广泛的零拍评估，显示了微妙的性能前景。虽然 VLM 相当擅长识别某些风格的文本(数据类型) ，比如卡通和草图，但它们很难识别更简单的文本(数据类型) ，这些文本源于图像旋转或附加噪音等基本操作。我们的研究结果显示，(i)单独的模型扩展为对比训练的模型(如 CLIP)产生边际收益，以及(ii)对于最大的自动回归训练的 VLM (如 OpenFlamingo) ，性能显着下降。这一发现指出了当前前沿 VLM 的一个盲点: 他们擅长识别语义内容，但无法通过缩放获得对视觉文本(数据类型)的理解。通过分析这些模型的预训练分布，并在微调期间将文本{数据类型}信息合并到标题中，我们实现了显著的性能提高。通过探索这一前所未有的任务，我们的目标是为进一步推进 VLM 奠定基础，使它们具备可视化的数据类型理解能力。代码和数据集发布 href { https://github.com/bethgelab/datatypeidentification }{ here }。"
    },
    {
        "title": "Transformers as Decision Makers: Provable In-Context Reinforcement\n  Learning via Supervised Pretraining",
        "url": "http://arxiv.org/abs/2310.08566v1",
        "pub_date": "2023-10-12",
        "summary": "Large transformer models pretrained on offline reinforcement learning\ndatasets have demonstrated remarkable in-context reinforcement learning (ICRL)\ncapabilities, where they can make good decisions when prompted with interaction\ntrajectories from unseen environments. However, when and how transformers can\nbe trained to perform ICRL have not been theoretically well-understood. In\nparticular, it is unclear which reinforcement-learning algorithms transformers\ncan perform in context, and how distribution mismatch in offline training data\naffects the learned algorithms. This paper provides a theoretical framework\nthat analyzes supervised pretraining for ICRL. This includes two recently\nproposed training methods -- algorithm distillation and decision-pretrained\ntransformers. First, assuming model realizability, we prove the\nsupervised-pretrained transformer will imitate the conditional expectation of\nthe expert algorithm given the observed trajectory. The generalization error\nwill scale with model capacity and a distribution divergence factor between the\nexpert and offline algorithms. Second, we show transformers with ReLU attention\ncan efficiently approximate near-optimal online reinforcement learning\nalgorithms like LinUCB and Thompson sampling for stochastic linear bandits, and\nUCB-VI for tabular Markov decision processes. This provides the first\nquantitative analysis of the ICRL capabilities of transformers pretrained from\noffline trajectories.",
        "translated": "在离线强化学习数据集上预先训练的大型变压器模型已经展示了非凡的上下文强化学习(ICRL)能力，当从看不见的环境中提示交互轨迹时，它们可以做出正确的决策。然而，变压器何时以及如何能够被训练来执行 ICRL 在理论上还没有得到很好的理解。具体而言，目前还不清楚哪些强化学习算法变换器可以在上下文中执行，以及离线训练数据中的分布不匹配如何影响学习算法。本文提供了一个分析 ICRL 监督预训练的理论框架。这包括最近提出的两种训练方法——算法精馏和决策预训练变换器。首先，假设模型可实现，我们证明了监督预训练变压器将模仿专家算法的条件期望，给定观察轨迹。该泛化误差将根据模型容量和专家算法与离线算法之间的分布差异因素进行扩展。其次，我们发现具有 relU 注意力的变压器可以有效地逼近近似最优的在线强化学习算法，如随机线性土匪的 LinUCB 和 Thompson 采样，以及表马尔可夫决策过程的 UCB-VI。这提供了从离线轨迹预先训练的变压器的 ICRL 能力的第一个定量分析。"
    },
    {
        "title": "Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of\n  Language Models with Hypothesis Refinement",
        "url": "http://arxiv.org/abs/2310.08559v1",
        "pub_date": "2023-10-12",
        "summary": "The ability to derive underlying principles from a handful of observations\nand then generalize to novel situations -- known as inductive reasoning -- is\ncentral to human intelligence. Prior work suggests that language models (LMs)\noften fall short on inductive reasoning, despite achieving impressive success\non research benchmarks. In this work, we conduct a systematic study of the\ninductive reasoning capabilities of LMs through iterative hypothesis\nrefinement, a technique that more closely mirrors the human inductive process\nthan standard input-output prompting. Iterative hypothesis refinement employs a\nthree-step process: proposing, selecting, and refining hypotheses in the form\nof textual rules. By examining the intermediate rules, we observe that LMs are\nphenomenal hypothesis proposers (i.e., generating candidate rules), and when\ncoupled with a (task-specific) symbolic interpreter that is able to\nsystematically filter the proposed set of rules, this hybrid approach achieves\nstrong results across inductive reasoning benchmarks that require inducing\ncausal relations, language-like instructions, and symbolic concepts. However,\nthey also behave as puzzling inductive reasoners, showing notable performance\ngaps in rule induction (i.e., identifying plausible rules) and rule application\n(i.e., applying proposed rules to instances), suggesting that LMs are proposing\nhypotheses without being able to actually apply the rules. Through empirical\nand human analyses, we further reveal several discrepancies between the\ninductive reasoning processes of LMs and humans, shedding light on both the\npotentials and limitations of using LMs in inductive reasoning tasks.",
        "translated": "从一些观察中得出基本原理，然后将其推广到新情况的能力——被称为归纳推理——是人类智力的核心。先前的研究表明，尽管语言模型在研究基准上取得了令人印象深刻的成功，但它们往往缺乏归纳推理。在这项工作中，我们进行了一个系统的研究，通过迭代假设完善的归纳推理模型的能力，这种技术更接近地反映了人类的归纳过程比标准的投入产出激励。迭代假设细化过程包括三个步骤: 以文本规则的形式提出、选择和细化假设。通过研究中间规则，我们观察到 LM 是非凡的假设提出者(即，生成候选规则) ，当与一个(任务特定的)符号解释器，能够系统地过滤提出的规则集，这种混合方法在跨归纳推理基准，需要诱导因果关系，类语言指令和符号概念，取得了强大的结果。然而，它们也表现为令人困惑的归纳推理，在规则归纳(即，确定合理的规则)和规则应用(即，对实例应用拟议的规则)方面表现出明显的性能差距，表明 LM 提出假设而不能实际应用规则。通过实证分析和人类分析，我们进一步揭示了归纳推理模型和人类模型在归纳推理过程中的一些差异，揭示了在人类任务中使用语言模型的潜力和局限性。"
    },
    {
        "title": "Do pretrained Transformers Really Learn In-context by Gradient Descent?",
        "url": "http://arxiv.org/abs/2310.08540v1",
        "pub_date": "2023-10-12",
        "summary": "Is In-Context Learning (ICL) implicitly equivalent to Gradient Descent (GD)?\nSeveral recent works draw analogies between the dynamics of GD and the emergent\nbehavior of ICL in large language models. However, these works make assumptions\nfar from the realistic natural language setting in which language models are\ntrained. Such discrepancies between theory and practice, therefore, necessitate\nfurther investigation to validate their applicability.\n  We start by highlighting the weaknesses in prior works that construct\nTransformer weights to simulate gradient descent. Their experiments with\ntraining Transformers on ICL objective, inconsistencies in the order\nsensitivity of ICL and GD, sparsity of the constructed weights, and sensitivity\nto parameter changes are some examples of a mismatch from the real-world\nsetting.\n  Furthermore, we probe and compare the ICL vs. GD hypothesis in a natural\nsetting. We conduct comprehensive empirical analyses on language models\npretrained on natural data (LLaMa-7B). Our comparisons on various performance\nmetrics highlight the inconsistent behavior of ICL and GD as a function of\nvarious factors such as datasets, models, and number of demonstrations. We\nobserve that ICL and GD adapt the output distribution of language models\ndifferently. These results indicate that the equivalence between ICL and GD is\nan open hypothesis, requires nuanced considerations and calls for further\nstudies.",
        "translated": "在上下文中学习(ICL)是否隐含地等同于梯度下降法学习(GD) ？最近的一些著作将 GD 的动力学和 ICL 在大型语言模型中的涌现行为进行了类比。然而，这些作品所做的假设远离训练语言模型的现实的自然语言环境。因此，理论与实践之间的这种差异需要进一步的研究来验证它们的适用性。我们首先强调在以前的工作中构建 formerweight 来模拟梯度下降法的弱点。他们在 ICL 目标上训练变压器的实验，ICL 和 GD 顺序灵敏度的不一致，构造的权重的稀疏性，以及对参数变化的敏感性是一些与现实世界设置不匹配的例子。此外，我们探讨和比较 ICL 与 GD 假说在自然环境中。我们对基于自然数据的语言模型(LLaMa-7B)进行了全面的实证分析。我们对各种性能指标的比较突出了 ICL 和 GD 作为各种因素(如数据集、模型和演示数量)的函数的不一致行为。我们观察到 ICL 和 GD 对语言模型输出分布的适应性不同。这些结果表明，ICL 和 GD 之间的等价性是一个开放的假设，需要细致的考虑，需要进一步的研究。"
    },
    {
        "title": "Formally Specifying the High-Level Behavior of LLM-Based Agents",
        "url": "http://arxiv.org/abs/2310.08535v1",
        "pub_date": "2023-10-12",
        "summary": "LLM-based agents have recently emerged as promising tools for solving\nchallenging problems without the need for task-specific finetuned models that\ncan be expensive to procure. Currently, the design and implementation of such\nagents is ad hoc, as the wide variety of tasks that LLM-based agents may be\napplied to naturally means there can be no one-size-fits-all approach to agent\ndesign. In this work we aim to alleviate the difficulty of designing and\nimplementing new agents by proposing a minimalistic, high-level generation\nframework that simplifies the process of building agents. The framework we\nintroduce allows the user to specify desired agent behaviors in Linear Temporal\nLogic (LTL). The declarative LTL specification is then used to construct a\nconstrained decoder that guarantees the LLM will produce an output exhibiting\nthe desired behavior. By designing our framework in this way, we obtain several\nbenefits, including the ability to enforce complex agent behavior, the ability\nto formally validate prompt examples, and the ability to seamlessly incorporate\ncontent-focused logical constraints into generation. In particular, our\ndeclarative approach, in which the desired behavior is simply described without\nconcern for how it should be implemented or enforced, enables rapid design,\nimplementation and experimentation with different LLM-based agents. We\ndemonstrate how the proposed framework can be used to implement recent\nLLM-based agents, and show how the guardrails our approach provides can lead to\nimprovements in agent performance. In addition, we release our code for general\nuse.",
        "translated": "基于 LLM 的代理最近已经成为解决具有挑战性的问题的有希望的工具，而不需要任务特定的微调模型，这可能是昂贵的采购。目前，这类代理的设计和实现是临时性的，因为基于 LLM 的代理可以应用于各种各样的任务，这自然意味着代理设计不能采用一刀切的方法。在这项工作中，我们的目标是减轻设计和实现新的代理的困难，提出了一个最低限度的，高层次的生成框架，简化了建筑代理的过程。我们介绍的框架允许用户在线性时序逻辑(LTL)中指定所需的代理行为。然后使用声明性 LTL 规范构造受约束的解码器，该解码器保证 LLM 将产生显示所需行为的输出。通过以这种方式设计我们的框架，我们获得了一些好处，包括实施复杂代理行为的能力，正式验证提示示例的能力，以及将以内容为中心的逻辑约束无缝地合并到生成中的能力。特别是，我们的声明性方法，其中所需的行为只是简单地描述，而不关心它应该如何实现或强制执行，这使得基于不同 LLM 代理的快速设计、实现和实验成为可能。我们演示了如何使用提出的框架来实现最近的基于 LLM 的代理，并展示了我们的方法提供的防护如何能够导致代理性能的改进。此外，我们还发布了通用代码。"
    },
    {
        "title": "LLM-augmented Preference Learning from Natural Language",
        "url": "http://arxiv.org/abs/2310.08523v1",
        "pub_date": "2023-10-12",
        "summary": "Finding preferences expressed in natural language is an important but\nchallenging task. State-of-the-art(SotA) methods leverage transformer-based\nmodels such as BERT, RoBERTa, etc. and graph neural architectures such as graph\nattention networks. Since Large Language Models (LLMs) are equipped to deal\nwith larger context lengths and have much larger model sizes than the\ntransformer-based model, we investigate their ability to classify comparative\ntext directly. This work aims to serve as a first step towards using LLMs for\nthe CPC task. We design and conduct a set of experiments that format the\nclassification task into an input prompt for the LLM and a methodology to get a\nfixed-format response that can be automatically evaluated. Comparing\nperformances with existing methods, we see that pre-trained LLMs are able to\noutperform the previous SotA models with no fine-tuning involved. Our results\nshow that the LLMs can consistently outperform the SotA when the target text is\nlarge -- i.e. composed of multiple sentences --, and are still comparable to\nthe SotA performance in shorter text. We also find that few-shot learning\nyields better performance than zero-shot learning.",
        "translated": "寻找用自然语言表达的偏好是一项重要但具有挑战性的任务。最先进的(SotA)方法利用了基于变压器的模型，如 BERT、 RoBERTa 等，以及图形神经结构，如图形注意网络。由于大语言模型(LLM)具有较大的上下文长度和较大的模型大小比基于转换器的模型，我们研究了它们的能力分类比较文本直接。这项工作旨在作为使用 LLM 完成 CPC 任务的第一步。我们设计并进行了一系列实验，将分类任务格式化为 LLM 的输入提示，并提出了一种获得固定格式响应的方法，该响应可以被自动评估。比较现有方法的性能，我们看到预先训练的 LLM 能够在不进行微调的情况下胜过以前的 SotA 模型。我们的研究结果表明，当目标文本较大时，即由多个句子组成时，LLM 的性能始终优于 SotA，并且仍然与较短文本中的 SotA 性能相当。我们还发现，少镜头学习比零镜头学习产生更好的性能。"
    },
    {
        "title": "HoneyBee: Progressive Instruction Finetuning of Large Language Models\n  for Materials Science",
        "url": "http://arxiv.org/abs/2310.08511v1",
        "pub_date": "2023-10-12",
        "summary": "We propose an instruction-based process for trustworthy data curation in\nmaterials science (MatSci-Instruct), which we then apply to finetune a\nLLaMa-based language model targeted for materials science (HoneyBee).\nMatSci-Instruct helps alleviate the scarcity of relevant, high-quality\nmaterials science textual data available in the open literature, and HoneyBee\nis the first billion-parameter language model specialized to materials science.\nIn MatSci-Instruct we improve the trustworthiness of generated data by\nprompting multiple commercially available large language models for generation\nwith an Instructor module (e.g. Chat-GPT) and verification from an independent\nVerifier module (e.g. Claude). Using MatSci-Instruct, we construct a dataset of\nmultiple tasks and measure the quality of our dataset along multiple\ndimensions, including accuracy against known facts, relevance to materials\nscience, as well as completeness and reasonableness of the data. Moreover, we\niteratively generate more targeted instructions and instruction-data in a\nfinetuning-evaluation-feedback loop leading to progressively better performance\nfor our finetuned HoneyBee models. Our evaluation on the MatSci-NLP benchmark\nshows HoneyBee's outperformance of existing language models on materials\nscience tasks and iterative improvement in successive stages of\ninstruction-data refinement. We study the quality of HoneyBee's language\nmodeling through automatic evaluation and analyze case studies to further\nunderstand the model's capabilities and limitations. Our code and relevant\ndatasets are publicly available at\n\\url{https://github.com/BangLab-UdeM-Mila/NLP4MatSci-HoneyBee}.",
        "translated": "我们提出了一个基于指令的过程，用于材料科学中可信赖的数据管理(MatSci-Direct) ，然后我们应用这个过程来微调一个面向材料科学(HoneyBee)的基于 LLaMa 的语言模型。MatSci-翘课有助于缓解开放文献中相关的高质量材料科学文本数据的稀缺性，而 HoneyBee 是第一个专门用于材料科学的10亿参数语言模型。在 MatSci-Instruct，我们通过提示多种商业上可用的大型语言模型，使用一个指导模块(例如 Chat-GPT)进行生成，并通过一个独立的验证模块(例如 Claude)进行验证，从而提高生成数据的可靠性。使用 MatSci-Direct，我们构建了一个包含多个任务的数据集，并沿着多个维度测量数据集的质量，包括对已知事实的准确性、与材料科学的相关性以及数据的完整性和合理性。此外，我们在微调-评估-反馈循环中迭代地生成更多有针对性的指令和指令数据，从而使我们的微调 HoneyBee 模型的性能逐步提高。我们对 MatSci-NLP 基准的评估表明，在材料科学任务和指令-数据细化的连续阶段的迭代改进方面，HoneyBee 的表现优于现有的语言模型。我们通过自动评估和分析案例研究来研究 HoneyBee 语言建模的质量，以进一步了解该模型的性能和局限性。我们的代码和相关数据集可以在 url { https://github.com/banglab-udem-mila/nlp4matsci-honeybee }上公开获得。"
    },
    {
        "title": "The Uncertainty-based Retrieval Framework for Ancient Chinese CWS and\n  POS",
        "url": "http://arxiv.org/abs/2310.08496v1",
        "pub_date": "2023-10-12",
        "summary": "Automatic analysis for modern Chinese has greatly improved the accuracy of\ntext mining in related fields, but the study of ancient Chinese is still\nrelatively rare. Ancient text division and lexical annotation are important\nparts of classical literature comprehension, and previous studies have tried to\nconstruct auxiliary dictionary and other fused knowledge to improve the\nperformance. In this paper, we propose a framework for ancient Chinese Word\nSegmentation and Part-of-Speech Tagging that makes a twofold effort: on the one\nhand, we try to capture the wordhood semantics; on the other hand, we\nre-predict the uncertain samples of baseline model by introducing external\nknowledge. The performance of our architecture outperforms pre-trained BERT\nwith CRF and existing tools such as Jiayan.",
        "translated": "现代汉语自动分析大大提高了相关领域文本挖掘的准确性，但对古汉语的研究还相对较少。古代文本分类和词汇注释是古典文学理解的重要组成部分，以往的研究试图构建辅助词典和其他融合知识来提高理解效率。在本文中，我们提出了一个古汉语分词和词性标注的框架，一方面，我们试图捕捉词性语义，另一方面，我们通过引入外部知识重新预测基线模型的不确定样本。我们的架构的性能优于预先训练的 BERT 与 CRF 和现有的工具，如佳研。"
    },
    {
        "title": "Prometheus: Inducing Fine-grained Evaluation Capability in Language\n  Models",
        "url": "http://arxiv.org/abs/2310.08491v1",
        "pub_date": "2023-10-12",
        "summary": "Recently, using a powerful proprietary Large Language Model (LLM) (e.g.,\nGPT-4) as an evaluator for long-form responses has become the de facto\nstandard. However, for practitioners with large-scale evaluation tasks and\ncustom criteria in consideration (e.g., child-readability), using proprietary\nLLMs as an evaluator is unreliable due to the closed-source nature,\nuncontrolled versioning, and prohibitive costs. In this work, we propose\nPrometheus, a fully open-source LLM that is on par with GPT-4's evaluation\ncapabilities when the appropriate reference materials (reference answer, score\nrubric) are accompanied. We first construct the Feedback Collection, a new\ndataset that consists of 1K fine-grained score rubrics, 20K instructions, and\n100K responses and language feedback generated by GPT-4. Using the Feedback\nCollection, we train Prometheus, a 13B evaluator LLM that can assess any given\nlong-form text based on customized score rubric provided by the user.\nExperimental results show that Prometheus scores a Pearson correlation of 0.897\nwith human evaluators when evaluating with 45 customized score rubrics, which\nis on par with GPT-4 (0.882), and greatly outperforms ChatGPT (0.392).\nFurthermore, measuring correlation with GPT-4 with 1222 customized score\nrubrics across four benchmarks (MT Bench, Vicuna Bench, Feedback Bench, Flask\nEval) shows similar trends, bolstering Prometheus's capability as an evaluator\nLLM. Lastly, Prometheus achieves the highest accuracy on two human preference\nbenchmarks (HHH Alignment &amp; MT Bench Human Judgment) compared to open-sourced\nreward models explicitly trained on human preference datasets, highlighting its\npotential as an universal reward model. We open-source our code, dataset, and\nmodel at https://github.com/kaistAI/Prometheus.",
        "translated": "最近，使用强大的专有大语言模型(LLM)(例如，GPT-4)作为长形式响应的评估器已经成为行业标准。然而，对于考虑大规模评估任务和自定义标准(例如，儿童可读性)的从业人员来说，使用专有 LLM 作为评估器是不可靠的，这是由于封闭源代码的性质，不受控制的版本控制和过高的成本。在这项工作中，我们提出了普罗米修斯，一个完全开源的 LLM，与 GPT-4的评估能力相当时，适当的参考材料(参考答案，评分标准)。我们首先构建了反馈集合，这是一个由1K 细粒度评分标准、20K 指令以及由 GPT-4生成的100K 反馈和语言反馈组成的新数据集。使用反馈集合，我们训练 Prometheus，一个13B 评估器 LLM，它可以基于用户提供的自定义评分标准来评估任何给定的长格式文本。实验结果显示，当使用45个定制评分标准进行评估时，Prometheus 与人类评估者的 Pearson 相关性为0.897，与 GPT-4(0.882)相当，并且大大优于 ChatGPT (0.392)。此外，测量与 gPT-4的相关性，在四个基准(MT Bench，Vicuna Bench，Feeback Bench，Flask Eval)上使用1222个定制评分标准，显示了类似的趋势，增强了普罗米修斯作为评估者 LLM 的能力。最后，与在人类偏好数据集上明确训练的开源奖励模型相比，普罗米修斯在两个人类偏好基准(HHH 校准和 MT 台人类判断)上获得了最高的准确性，突出了其作为通用奖励模型的潜力。我们开源的代码，数据集和模型在 https://github.com/kaistai/prometheus。"
    }
]
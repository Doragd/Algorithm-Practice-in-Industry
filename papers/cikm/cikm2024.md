# CIKM2024 Paper List

|论文|作者|组织|摘要|翻译|代码|引用数|
|---|---|---|---|---|---|---|
|[Enhancing Click-through Rate Prediction in Recommendation Domain with Search Query Representation](https://doi.org/10.1145/3627673.3679849)|Yuening Wang, Man Chen, Yaochen Hu, Wei Guo, Yingxue Zhang, Huifeng Guo, Yong Liu, Mark Coates|Huawei Noah's Ark Lab, Singapore, Singapore; Huawei Noah's Ark Lab, Markham, Canada; Huawei Noah's Ark Lab, Shenzhen, China; McGill University, Montreal, Canada; Huawei Noah's Ark Lab, Montreal, Canada|Many platforms, such as e-commerce websites, offer both search and recommendation services simultaneously to better meet users' diverse needs. Recommendation services suggest items based on user preferences, while search services allow users to search for items before providing recommendations. Since users and items are often shared between the search and recommendation domains, there is a valuable opportunity to enhance the recommendation domain by leveraging user preferences extracted from the search domain. Existing approaches either overlook the shift in user intention between these domains or fail to capture the significant impact of learning from users' search queries on understanding their interests. In this paper, we propose a framework that learns from user search query embeddings within the context of user preferences in the recommendation domain. Specifically, user search query sequences from the search domain are used to predict the items users will click at the next time point in the recommendation domain. Additionally, the relationship between queries and items is explored through contrastive learning. To address issues of data sparsity, the diffusion model is incorporated to infer positive items the user will select after searching with certain queries in a denoising manner, which is particularly effective in preventing false positives. Effectively extracting this information, the queries are integrated into click-through rate prediction in the recommendation domain. Experimental analysis demonstrates that our model outperforms state-of-the-art models in the recommendation domain.|许多平台，如电子商务网站，同时提供搜索和推荐服务，以更好地满足用户多样化的需求。推荐服务根据用户的偏好推荐商品，而搜索服务则允许用户在提供推荐之前搜索商品。由于用户和商品通常在搜索和推荐领域之间共享，因此有机会通过利用从搜索领域提取的用户偏好来增强推荐领域。现有方法要么忽略了这两个领域之间用户意图的转变，要么未能捕捉到从用户搜索查询中学习对理解用户兴趣的重大影响。本文提出了一种框架，该框架在推荐领域的用户偏好背景下学习用户搜索查询嵌入。具体来说，使用搜索领域的用户搜索查询序列来预测用户在推荐领域中下一次点击的商品。此外，通过对比学习探索查询与商品之间的关系。为了解决数据稀疏性问题，采用了扩散模型以去噪方式推断用户在使用某些查询进行搜索后将选择的正向商品，这在防止误报方面特别有效。有效地提取这些信息后，将查询整合到推荐领域的点击率预测中。实验分析表明，我们的模型在推荐领域的表现优于最先进的模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Click-through+Rate+Prediction+in+Recommendation+Domain+with+Search+Query+Representation)|0|
|[Calibration-Disentangled Learning and Relevance-Prioritized Reranking for Calibrated Sequential Recommendation](https://doi.org/10.1145/3627673.3679728)|Hyunsik Jeon, Seeun Yoon, Julian J. McAuley||Calibrated recommendation, which aims to maintain personalized proportions of categories within recommendations, is crucial in practical scenarios since it enhances user satisfaction by reflecting diverse interests. However, achieving calibration in a sequential setting (i.e., calibrated sequential recommendation) is challenging due to the need to adapt to users' evolving preferences. Previous methods typically leverage reranking algorithms to calibrate recommendations after training a model without considering the effect of calibration and do not effectively tackle the conflict between relevance and calibration during the reranking process. In this work, we propose LeapRec (Calibration-Disentangled Learning and Relevance-Prioritized Reranking), a novel approach for the calibrated sequential recommendation that addresses these challenges. LeapRec consists of two phases, model training phase and reranking phase. In the training phase, a backbone model is trained using our proposed calibration-disentangled learning-to-rank loss, which optimizes personalized rankings while integrating calibration considerations. In the reranking phase, relevant items are prioritized at the top of the list, with items needed for calibration following later to address potential conflicts between relevance and calibration. Through extensive experiments on four real-world datasets, we show that LeapRec consistently outperforms previous methods in the calibrated sequential recommendation. Our code is available at https://github.com/jeon185/LeapRec.|校准推荐旨在保持推荐中类别的个性化比例，这在实际场景中至关重要，因为它通过反映多样化的兴趣来增强用户满意度。然而，在序列环境中实现校准（即校准序列推荐）具有挑战性，因为需要适应用户不断变化的偏好。先前的方法通常利用重新排序算法在训练模型后进行推荐校准，而没有考虑校准效果，并且在重新排序过程中未能有效解决相关性与校准之间的冲突。在这项工作中，我们提出了LeapRec（校准解耦学习和相关性优先重新排序），这是一种新颖的校准序列推荐方法，旨在解决这些挑战。LeapRec包括两个阶段，模型训练阶段和重新排序阶段。在训练阶段，使用我们提出的校准解耦学习排序损失训练骨干模型，该损失在优化个性化排序的同时整合了校准考虑。在重新排序阶段，相关项目优先置于列表顶部，而需要校准的项目随后放置，以解决相关性与校准之间可能的冲突。通过在四个真实世界数据集上的广泛实验，我们展示了LeapRec在校准序列推荐方面始终优于先前的方法。我们的代码可在https://github.com/jeon185/LeapRec获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Calibration-Disentangled+Learning+and+Relevance-Prioritized+Reranking+for+Calibrated+Sequential+Recommendation)|0|
|[Aligning Query Representation with Rewritten Query and Relevance Judgments in Conversational Search](https://doi.org/10.1145/3627673.3679534)|Fengran Mo, Chen Qu, Kelong Mao, Yihong Wu, Zhan Su, Kaiyu Huang, JianYun Nie||Conversational search supports multi-turn user-system interactions to solve complex information needs. Different from the traditional single-turn ad-hoc search, conversational search encounters a more challenging problem of context-dependent query understanding with the lengthy and long-tail conversational history context. While conversational query rewriting methods leverage explicit rewritten queries to train a rewriting model to transform the context-dependent query into a stand-stone search query, this is usually done without considering the quality of search results. Conversational dense retrieval methods use fine-tuning to improve a pre-trained ad-hoc query encoder, but they are limited by the conversational search data available for training. In this paper, we leverage both rewritten queries and relevance judgments in the conversational search data to train a better query representation model. The key idea is to align the query representation with those of rewritten queries and relevant documents. The proposed model – Query Representation Alignment Conversational Dense Retriever, QRACDR, is tested on eight datasets, including various settings in conversational search and ad-hoc search. The results demonstrate the strong performance of QRACDR compared with state-of-the-art methods, and confirm the effectiveness of representation alignment.|对话搜索支持多轮用户-系统交互，以解决复杂的信息需求。与传统的单轮即席搜索不同，对话搜索面临着一个更具挑战性的问题，即在长篇且长尾的对话历史背景下进行依赖上下文的查询理解。虽然对话查询重写方法利用显式的重写查询来训练重写模型，将依赖上下文的查询转换为独立的搜索查询，但这通常不考虑搜索结果的质量。对话密集检索方法通过微调预训练的即席查询编码器来改进，但受限于可用于训练的对话搜索数据。本文中，我们利用对话搜索数据中的重写查询和相关性判断来训练一个更好的查询表示模型。关键思想是将查询表示与重写查询和相关文档的表示对齐。提出的模型——查询表示对齐对话密集检索器（QRACDR），在八个数据集上进行了测试，包括对话搜索和即席搜索的各种设置。结果显示，QRACDR相比最先进的方法表现出强劲的性能，并证实了表示对齐的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Aligning+Query+Representation+with+Rewritten+Query+and+Relevance+Judgments+in+Conversational+Search)|0|
|[Improved Estimation of Ranks for Learning Item Recommenders with Negative Sampling](https://doi.org/10.1145/3627673.3679943)|Anushya Subbiah, Steffen Rendle, Vikram Aggarwal||In recommendation systems, there has been a growth in the number of recommendable items (# of movies, music, products). When the set of recommendable items is large, training and evaluation of item recommendation models becomes computationally expensive. To lower this cost, it has become common to sample negative items. However, the recommendation quality can suffer from biases introduced by traditional negative sampling mechanisms. In this work, we demonstrate the benefits from correcting the bias introduced by sampling of negatives. We first provide sampled batch version of the well-studied WARP and LambdaRank methods. Then, we present how these methods can benefit from improved ranking estimates. Finally, we evaluate the recommendation quality as a result of correcting rank estimates and demonstrate that WARP and LambdaRank can be learned efficiently with negative sampling and our proposed correction technique.|在推荐系统中，可推荐项目的数量（如电影、音乐、产品）有所增加。当可推荐项目的集合规模较大时，训练和评估项目推荐模型的计算成本会变得非常高。为了降低这一成本，通常会采用负样本采样的方法。然而，传统的负样本采样机制可能会引入偏差，从而影响推荐质量。在这项工作中，我们展示了通过纠正负样本采样引入的偏差所带来的好处。我们首先提供了经过深入研究的WARP和LambdaRank方法的采样批次版本。然后，我们展示了这些方法如何从改进的排序估计中受益。最后，我们评估了纠正排序估计后的推荐质量，并证明WARP和LambdaRank可以通过负样本采样和我们的修正技术高效地进行学习。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improved+Estimation+of+Ranks+for+Learning+Item+Recommenders+with+Negative+Sampling)|0|
|[Scalable Dynamic Embedding Size Search for Streaming Recommendation](https://doi.org/10.1145/3627673.3679638)|Yunke Qu, Liang Qu, Tong Chen, Xiangyu Zhao, Quoc Viet Hung Nguyen, Hongzhi Yin||Recommender systems typically represent users and items by learning their embeddings, which are usually set to uniform dimensions and dominate the model parameters. However, real-world recommender systems often operate in streaming recommendation scenarios, where the number of users and items continues to grow, leading to substantial storage resource consumption for these embeddings. Although a few methods attempt to mitigate this by employing embedding size search strategies to assign different embedding dimensions in streaming recommendations, they assume that the embedding size grows with the frequency of users/items, which eventually still exceeds the predefined memory budget over time. To address this issue, this paper proposes to learn Scalable Lightweight Embeddings for streaming recommendation, called SCALL, which can adaptively adjust the embedding sizes of users/items within a given memory budget over time. Specifically, we propose to sample embedding sizes from a probabilistic distribution, with the guarantee to meet any predefined memory budget. By fixing the memory budget, the proposed embedding size sampling strategy can increase and decrease the embedding sizes in accordance to the frequency of the corresponding users or items. Furthermore, we develop a reinforcement learning-based search paradigm that models each state with mean pooling to keep the length of the state vectors fixed, invariant to the changing number of users and items. As a result, the proposed method can provide embedding sizes to unseen users and items. Comprehensive empirical evaluations on two public datasets affirm the advantageous effectiveness of our proposed method.|推荐系统通常通过学习嵌入来表示用户和物品，这些嵌入通常设置为统一的维度，并且主导模型参数。然而，现实世界的推荐系统经常在流式推荐场景中运行，其中用户和物品的数量持续增长，导致这些嵌入的存储资源消耗巨大。尽管一些方法试图通过采用嵌入大小搜索策略在流式推荐中分配不同的嵌入维度来缓解这一问题，但它们假设嵌入大小随着用户/物品的频率增长，最终仍然会超过预定义的内存预算。为了解决这个问题，本文提出了一种名为SCALL的流式推荐可扩展轻量级嵌入学习方法，它能够在给定的内存预算内随时间自适应地调整用户/物品的嵌入大小。具体来说，我们提出从概率分布中采样嵌入大小，以确保满足任何预定义的内存预算。通过固定内存预算，所提出的嵌入大小采样策略可以根据相应用户或物品的频率增加或减少嵌入大小。此外，我们开发了一种基于强化学习的搜索范式，该范式通过均值池化来建模每个状态，以保持状态向量的长度固定，不受用户和物品数量变化的影响。因此，所提出的方法可以为未见过的用户和物品提供嵌入大小。在两个公共数据集上的综合实证评估证实了我们提出的方法的优势有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+Dynamic+Embedding+Size+Search+for+Streaming+Recommendation)|0|
|[Ask or Recommend: An Empirical Study on Conversational Product Search](https://doi.org/10.1145/3627673.3679875)|Heli Ma, Jie Zou, Mohammad Aliannejadi, Evangelos Kanoulas, Yi Bin, Yang Yang|University of Electronic Science and Technology of China, Chengdu, China; Tongji University, Shanghai, China; University of Science and Technology of China, Chengdu, China; University of Amsterdam, Amstedam, Netherlands; University of Amsterdam, Amsterdam, Netherlands|Conversational Product Search (CPS) provides an engaging way for users to find products through effective natural language conversations. However, understanding the effect of conversational characteristics on user search performance and when to ask clarifying questions or recommend products remains unexplored. To fill the gap, we conduct an empirical study in this paper. Specifically, we developed a conversational system that allows participants to join as customers or shopping assistants, to simulate the conversational product search activity. Data collected from conversations and participant feedback indicate that: (a) CPS systems tend to ask clarifying questions early in the conversation when users express the intent of issuing a new query and chitchat, while they tend to recommend products at a later stage of conversations; asking clarifying questions early and recommending products lately can significantly improve search performance and user's satisfaction; (b) asking clarifying questions and more fine-grained search keywords positively influence search performance in terms of finding relevant products; (c) although the conversation time has a positive impact on the number of recommended products, the performance gain diminishes with longer conversation time; (d) more clarifying questions, more conversation turns, and longer system response time lead to decreased user satisfaction.|对话式产品搜索（Conversational Product Search, CPS）为用户提供了一种通过高效自然语言对话寻找产品的互动方式。然而，对话特性对用户搜索表现的影响以及何时提问澄清问题或推荐产品的问题尚未得到深入研究。为了填补这一空白，本文进行了一项实证研究。具体而言，我们开发了一个对话系统，允许参与者扮演顾客或购物助手的角色，模拟对话式产品搜索活动。从对话中收集的数据及参与者反馈表明：(a) CPS系统在用户表达新查询意图和闲聊时，倾向于在对话初期提问澄清问题，而在对话后期则更倾向于推荐产品；尽早提问澄清问题和延迟推荐产品可以显著提升搜索表现和用户满意度；(b)提问澄清问题和更细粒度的搜索关键词对查找相关产品有正面影响，从而提高搜索表现；(c)尽管对话时间对推荐产品数量有正面影响，但随对话时间延长，性能提升逐渐减少；(d)更多的澄清问题、更多的对话轮次和更长的系统响应时间会导致用户满意度下降。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ask+or+Recommend:+An+Empirical+Study+on+Conversational+Product+Search)|0|
|[Towards Better Seach Query Classification with Distribution-Diverse Multi-Expert Knowledge Distillation in JD Ads Search](https://doi.org/10.1145/3627673.3680049)|KunPeng Ning, Ming Pang, Zheng Fang, Xue Jiang, XiWei Zhao, Changping Peng, Zhangang Lin, Jinghe Hu, Jingping Shao, Li Yuan|Peking University, ShenZhen, China; Business Growth BU, JD.COM, Beijing, China; Peking University, Shenzhen, China|In the dynamic landscape of online advertising, decoding user intent remains a pivotal challenge, particularly in the context of query classification. Swift classification models, exemplified by FastText, cater to the demand for real-time responses but encounter limitations in handling intricate queries. Conversely, accuracy-centric models like BERT introduce challenges associated with increased latency. This paper undertakes a nuanced exploration, navigating the delicate balance between efficiency and accuracy. It unveils FastText's latent potential as an 'online dictionary' for historical queries while harnessing the semantic robustness of BERT for novel and complex scenarios. The proposed Distribution-Diverse Multi-Expert (DDME) framework employs multiple teacher models trained from diverse data distributions. Through meticulous data categorization and enrichment, it elevates the classification performance across the query spectrum. Empirical results within the JD ads search system validate the superiority of our proposed approaches.|在在线广告的动态环境中，解读用户意图仍然是一个关键挑战，尤其是在查询分类的背景下。以FastText为代表的快速分类模型满足了实时响应的需求，但在处理复杂查询时存在局限性。相反，以准确性为中心的模型如BERT，虽然引入了延迟增加的挑战，但在处理复杂查询时表现出色。本文深入探讨了在效率和准确性之间寻求微妙平衡的问题。研究发现，FastText作为历史查询的“在线词典”具有潜在价值，同时利用BERT的语义丰富性来应对新颖和复杂的场景。提出的分布多样多专家（DDME）框架采用了从不同数据分布中训练的多个教师模型。通过细致的数据分类和丰富化处理，该框架提升了查询分类的整体性能。在京东广告搜索系统中的实证结果验证了我们提出的方法的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Better+Seach+Query+Classification+with+Distribution-Diverse+Multi-Expert+Knowledge+Distillation+in+JD+Ads+Search)|0|
|[Spectral and Geometric Spaces Representation Regularization for Multi-Modal Sequential Recommendation](https://doi.org/10.1145/3627673.3679647)|Zihao Li, Xuekong Xu, Zuoli Tang, Lixin Zou, Qian Wang, Chenliang Li||Recent works demonstrate the effectiveness of multi-modal information for sequential recommendation. However, the computational cost and representation degeneration fail to be focused specifically and addressed adequately in multi-modality recommendation. To this end, we first identify and formalize three properties i.e., diversity, compactness, and consistency from the geometric space and spectrum perspective. Building upon this foundation, we devise tailored loss functions to regularize the above three properties for representation optimization. Theoretical underpinnings and experimental results demonstrate the efficacy of an enhanced item representation in ameliorating degeneration. Furthermore, we propose an efficient and expandable image-centered method, named E2 ImgRec, to mitigate the immense cost of computation. Concretely, we substitute the linear projection operations in the self-attention module and feed-forward network layer with two learnable rescaling vectors or efficient recommendation, then leverage cross-attention for multi-modality information fusion. Extensive experiments on three public datasets illustrate our method outperforms representative ID-based solutions and multi-modal based state-of-the-arts with only up to 39.9% in memory usage and 4.3× acceleration in training time. The code for replication is available at https://github.com/WHUIR/E2ImgRec.|近期的研究展示了多模态信息在序列推荐中的有效性。然而，多模态推荐中的计算成本和表示退化问题尚未得到充分关注和解决。为此，我们首先从几何空间和频谱的角度识别并形式化了三个特性，即多样性、紧凑性和一致性。在此基础上，我们设计了定制的损失函数来规范上述三个特性，以优化表示。理论基础和实验结果表明，增强的物品表示能够有效改善退化问题。此外，我们提出了一种高效且可扩展的以图像为中心的方法，名为E2 ImgRec，以缓解巨大的计算成本。具体而言，我们用两个可学习的重缩放向量替代了自注意力模块和前馈网络层中的线性投影操作，并利用交叉注意力进行多模态信息融合。在三个公开数据集上的广泛实验表明，我们的方法在内存使用率最高仅为39.9%和训练时间加速4.3倍的情况下，优于基于ID的代表性解决方案和多模态的最新技术。可复现代码已发布在https://github.com/WHUIR/E2ImgRec。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spectral+and+Geometric+Spaces+Representation+Regularization+for+Multi-Modal+Sequential+Recommendation)|0|
|[Retrieval-Oriented Knowledge for Click-Through Rate Prediction](https://doi.org/10.1145/3627673.3679842)|Huanshuo Liu, Bo Chen, Menghui Zhu, Jianghao Lin, Jiarui Qin, Hao Zhang, Yang Yang, Ruiming Tang||Click-through rate (CTR) prediction plays an important role in personalizedrecommendations. Recently, sample-level retrieval-based models (e.g., RIM) haveachieved remarkable performance by retrieving and aggregating relevant samples.However, their inefficiency at the inference stage makes them impractical forindustrial applications. To overcome this issue, this paper proposes auniversal plug-and-play Retrieval-Oriented Knowledge (ROK) framework.Specifically, a knowledge base, consisting of a retrieval-oriented embeddinglayer and a knowledge encoder, is designed to preserve and imitate theretrieved aggregated representations in a decomposition-reconstructionparadigm. Knowledge distillation and contrastive learning methods are utilizedto optimize the knowledge base, and the learned retrieval-enhancedrepresentations can be integrated with arbitrary CTR models in bothinstance-wise and feature-wise manners. Extensive experiments on threelarge-scale datasets show that ROK achieves competitive performance with theretrieval-based CTR models while reserving superior inference efficiency andmodel compatibility.|点击率（CTR）预测在个性化推荐中扮演着重要角色。近期，基于样本级检索的模型（如RIM）通过检索并聚合相关样本来取得了显著的性能。然而，这些模型在推理阶段的效率低下使其难以应用于工业场景。为解决这一问题，本文提出了一种通用的即插即用型检索导向知识（ROK）框架。具体而言，设计了一个由检索导向嵌入层和知识编码器组成的知识库，该知识库在分解-重构范式中保留并模仿检索到的聚合表示。利用知识蒸馏和对比学习方法来优化知识库，所学到的检索增强表示可以与任意CTR模型在实例级和特征级方式上进行集成。在三个大规模数据集上的广泛实验表明，ROK在保留优越的推理效率和模型兼容性的同时，实现了与基于检索的CTR模型相当的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Retrieval-Oriented+Knowledge+for+Click-Through+Rate+Prediction)|0|
|[Mitigating Exposure Bias in Online Learning to Rank Recommendation: A Novel Reward Model for Cascading Bandits](https://doi.org/10.1145/3627673.3679763)|Masoud Mansoury, Bamshad Mobasher, Herke van Hoof||Exposure bias is a well-known issue in recommender systems where items and suppliers are not equally represented in the recommendation results. This bias becomes particularly problematic over time as a few items are repeatedly over-represented in recommendation lists, leading to a feedback loop that further amplifies this bias. Although extensive research has addressed this issue in model-based or neighborhood-based recommendation algorithms, less attention has been paid to online recommendation models, such as those based on top-K contextual bandits, where recommendation models are dynamically updated with ongoing user feedback. In this paper, we study exposure bias in a class of well-known contextual bandit algorithms known as Linear Cascading Bandits. We analyze these algorithms in their ability to handle exposure bias and provide a fair representation of items in the recommendation results. Our analysis reveals that these algorithms fail to mitigate exposure bias in the long run during the course of ongoing user interactions. We propose an Exposure-Aware reward model that updates the model parameters based on two factors: 1) implicit user feedback and 2) the position of the item in the recommendation list. The proposed model mitigates exposure bias by controlling the utility assigned to the items based on their exposure in the recommendation list. Our experiments with two real-world datasets show that our proposed reward model improves the exposure fairness of the linear cascading bandits over time while maintaining the recommendation accuracy. It also outperforms the current baselines. Finally, we prove a high probability upper regret bound for our proposed model, providing theoretical guarantees for its performance.|曝光偏差是推荐系统中一个众所周知的问题，其中物品和供应商在推荐结果中的表现并不均衡。随着时间的推移，这种偏差变得尤为严重，因为少数物品在推荐列表中被过度重复展示，形成了一个反馈循环，进一步加剧了这种偏差。尽管大量研究已经解决了基于模型或基于邻域的推荐算法中的这一问题，但对于在线推荐模型（如基于top-K上下文强盗的模型）的关注较少，这些模型会根据用户的持续反馈动态更新推荐模型。在本文中，我们研究了一类著名的上下文强盗算法——线性级联强盗算法中的曝光偏差问题。我们分析了这些算法在处理曝光偏差和在推荐结果中公平展示物品方面的能力。我们的分析表明，这些算法在长期用户交互过程中无法有效缓解曝光偏差。我们提出了一种曝光感知奖励模型，该模型根据两个因素更新模型参数：1）隐式用户反馈和2）物品在推荐列表中的位置。所提出的模型通过根据物品在推荐列表中的曝光程度调整分配给它们的效用，来缓解曝光偏差。我们在两个真实世界数据集上的实验表明，所提出的奖励模型随着时间的推移提高了线性级联强盗算法的曝光公平性，同时保持了推荐准确性。此外，它还优于当前的基线模型。最后，我们证明了所提出模型的高概率上界遗憾界限，为其性能提供了理论保证。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mitigating+Exposure+Bias+in+Online+Learning+to+Rank+Recommendation:+A+Novel+Reward+Model+for+Cascading+Bandits)|0|
|[MemoCRS: Memory-enhanced Sequential Conversational Recommender Systems with Large Language Models](https://doi.org/10.1145/3627673.3679599)|Yunjia Xi, Weiwen Liu, Jianghao Lin, Bo Chen, Ruiming Tang, Weinan Zhang, Yong Yu||Conversational recommender systems (CRSs) aim to capture user preferences and provide personalized recommendations through multi-round natural language dialogues. However, most existing CRS models mainly focus on dialogue comprehension and preferences mining from the current dialogue session, overlooking user preferences in historical dialogue sessions. The preferences embedded in the user's historical dialogue sessions and the current session exhibit continuity and sequentiality, and we refer to CRSs with this characteristic as sequential CRSs. In this work, we leverage memory-enhanced LLMs to model the preference continuity, primarily focusing on addressing two key issues: (1) redundancy and noise in historical dialogue sessions, and (2) the cold-start users problem. To this end, we propose a Memory-enhanced Conversational Recommender System Framework with Large Language Models (dubbed MemoCRS) consisting of user-specific memory and general memory. User-specific memory is tailored to each user for their personalized interests and implemented by an entity-based memory bank to refine preferences and retrieve relevant memory, thereby reducing the redundancy and noise of historical sessions. The general memory, encapsulating collaborative knowledge and reasoning guidelines, can provide shared knowledge for users, especially cold-start users. With the two kinds of memory, LLMs are empowered to deliver more precise and tailored recommendations for each user. Extensive experiments on both Chinese and English datasets demonstrate the effectiveness of MemoCRS.|对话推荐系统（CRSs）旨在通过多轮自然语言对话捕捉用户偏好并提供个性化推荐。然而，大多数现有的CRS模型主要关注当前对话会话中的对话理解和偏好挖掘，忽视了历史对话会话中的用户偏好。用户历史对话会话和当前会话中嵌入的偏好具有连续性和顺序性，我们将具备这种特性的CRS称为顺序CRS。在本研究中，我们利用记忆增强型LLMs来建模偏好连续性，主要解决两个关键问题：（1）历史对话会话中的冗余和噪声，（2）冷启动用户问题。为此，我们提出了一种基于大语言模型的记忆增强对话推荐系统框架（称为MemoCRS），该框架包括用户特定记忆和通用记忆。用户特定记忆针对每个用户的个性化兴趣定制，并通过基于实体的记忆库实现，以精炼偏好并检索相关记忆，从而减少历史会话的冗余和噪声。通用记忆封装了协作知识和推理指南，可以为所有用户提供共享知识，特别是冷启动用户。通过这两种记忆，LLMs能够为每个用户提供更精确和定制化的推荐。在中英文数据集上的广泛实验证明了MemoCRS的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MemoCRS:+Memory-enhanced+Sequential+Conversational+Recommender+Systems+with+Large+Language+Models)|0|
|[Early Exit Strategies for Approximate k-NN Search in Dense Retrieval](https://doi.org/10.1145/3627673.3679903)|Francesco Busolin, Claudio Lucchese, Franco Maria Nardini, Salvatore Orlando, Raffaele Perego, Salvatore Trani||Learned dense representations are a popular family of techniques for encoding queries and documents using high-dimensional embeddings, which enable retrieval by performing approximate k nearest-neighbors search (A-kNN). A popular technique for making A-kNN search efficient is based on a two-level index, where the embeddings of documents are clustered offline and, at query processing, a fixed number N of clusters closest to the query is visited exhaustively to compute the result set. In this paper, we build upon state-of-the-art for early exit A-kNN and propose an unsupervised method based on the notion of patience, which can reach competitive effectiveness with large efficiency gains. Moreover, we discuss a cascade approach where we first identify queries that find their nearest neighbor within the closest t << N clusters, and then we decide how many more to visit based on our patience approach or other state-of-the-art strategies. Reproducible experiments employing state-of-the-art dense retrieval models and publicly available resources show that our techniques improve the A-kNN efficiency with up to 5x speedups while achieving negligible effectiveness losses. All the code used is available at https://github.com/francescobusolin/faiss_pEE|学习到的密集表示是一种流行的技术家族，用于使用高维嵌入对查询和文档进行编码，通过执行近似k近邻搜索（A-kNN）来实现检索。使A-kNN搜索高效的一种流行技术是基于两级索引，其中文档的嵌入在离线状态下被聚类，在查询处理时，固定数量的N个最接近查询的聚类被穷尽地访问以计算结果集。在本文中，我们基于最先进的早期退出A-kNN技术，提出了一种基于耐心理念的无监督方法，该方法能够在大幅提高效率的同时达到竞争性的有效性。此外，我们讨论了一种级联方法，首先识别在其最接近的t << N个聚类内找到最近邻的查询，然后根据我们的耐心理念或其他最先进策略决定访问更多聚类的数量。使用最先进的密集检索模型和公开可用资源的可重复实验表明，我们的技术在实现几乎无有效性损失的情况下，将A-kNN效率提高了最多5倍的速度。所有使用的代码均可在https://github.com/francescobusolin/faiss_pEE获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Early+Exit+Strategies+for+Approximate+k-NN+Search+in+Dense+Retrieval)|0|
|[MODRL-TA: A Multi-Objective Deep Reinforcement Learning Framework for Traffic Allocation in E-Commerce Search](https://doi.org/10.1145/3627673.3679964)|Peng Cheng, Huimu Wang, Jinyuan Zhao, Yihao Wang, Enqiang Xu, Yu Zhao, Zhuojian Xiao, Songlin Wang, Guoyu Tang, Lin Liu, Sulong Xu||Traffic allocation is a process of redistributing natural traffic to products by adjusting their positions in the post-search phase, aimed at effectively fostering merchant growth, precisely meeting customer demands, and ensuring the maximization of interests across various parties within e-commerce platforms. Existing methods based on learning to rank neglect the long-term value of traffic allocation, whereas approaches of reinforcement learning suffer from balancing multiple objectives and the difficulties of cold starts within realworld data environments. To address the aforementioned issues, this paper propose a multi-objective deep reinforcement learning framework consisting of multi-objective Q-learning (MOQ), a decision fusion algorithm (DFM) based on the cross-entropy method(CEM), and a progressive data augmentation system(PDA). Specifically. MOQ constructs ensemble RL models, each dedicated to an objective, such as click-through rate, conversion rate, etc. These models individually determine the position of items as actions, aiming to estimate the long-term value of multiple objectives from an individual perspective. Then we employ DFM to dynamically adjust weights among objectives to maximize long-term value, addressing temporal dynamics in objective preferences in e-commerce scenarios. Initially, PDA trained MOQ with simulated data from offline logs. As experiments progressed, it strategically integrated real user interaction data, ultimately replacing the simulated dataset to alleviate distributional shifts and the cold start problem. Experimental results on real-world online e-commerce systems demonstrate the significant improvements of MODRL-TA, and we have successfully deployed MODRL-TA on an e-commerce search platform.|流量分配是通过调整产品在搜索后阶段的位置来重新分配自然流量，旨在有效促进商家增长、精准满足客户需求，并确保电子商务平台各方的利益最大化。现有的基于学习排序的方法忽视了流量分配的长期价值，而强化学习的方法则在平衡多个目标和处理现实数据环境中的冷启动问题上存在困难。为解决上述问题，本文提出了一种多目标深度强化学习框架，包括多目标Q学习（MOQ）、基于交叉熵方法（CEM）的决策融合算法（DFM）和渐进式数据增强系统（PDA）。具体而言，MOQ构建了专注于不同目标（如点击率、转化率等）的集成强化学习模型，每个模型独立决定商品的位置作为动作，旨在从个体角度估计多个目标的长期价值。随后，我们采用DFM动态调整目标之间的权重以最大化长期价值，解决电子商务场景中目标偏好的时间动态性。最初，PDA使用离线日志中的模拟数据训练MOQ。随着实验的进行，它策略性地整合了真实用户交互数据，最终替代模拟数据集以缓解分布偏移和冷启动问题。在真实在线电子商务系统上的实验结果显示了MODRL-TA的显著改进，并且我们已成功将MODRL-TA部署在电子商务搜索平台上。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MODRL-TA:+A+Multi-Objective+Deep+Reinforcement+Learning+Framework+for+Traffic+Allocation+in+E-Commerce+Search)|0|
|[Enhancing CTR Prediction through Sequential Recommendation Pre-training: Introducing the SRP4CTR framework](https://doi.org/10.1145/3627673.3679914)|Ruidong Han, Qianzhong Li, He Jiang, Rui Li, Yurou Zhao, Xiang Li, Wei Lin||Understanding user interests is crucial for Click-Through Rate (CTR) prediction tasks. In sequential recommendation, pre-training from user historical behaviors through self-supervised learning can better comprehend user dynamic preferences, presenting the potential for direct integration with CTR tasks. Previous methods have integrated pre-trained models into downstream tasks with the sole purpose of extracting semantic information or well-represented user features, which are then incorporated as new features. However, these approaches tend to ignore the additional inference costs to the downstream tasks, and they do not consider how to transfer the effective information from the pre-trained models for specific estimated items in CTR prediction. In this paper, we propose a Sequential Recommendation Pre-training framework for CTR prediction (SRP4CTR) to tackle the above problems. Initially, we discuss the impact of introducing pre-trained models on inference costs. Subsequently, we introduced a pre-trained method to encode sequence side information concurrently.During the fine-tuning process, we incorporate a cross-attention block to establish a bridge between estimated items and the pre-trained model at a low cost. Moreover, we develop a querying transformer technique to facilitate the knowledge transfer from the pre-trained model to industrial CTR models. Offline and online experiments show that our method outperforms previous baseline models.|理解用户兴趣对于点击率（CTR）预测任务至关重要。在序列推荐中，通过自监督学习从用户历史行为中进行预训练，能更好地理解用户的动态偏好，为直接整合到CTR任务中提供了潜力。以往的方法将预训练模型整合到下游任务中，主要是为了提取语义信息或良好表示的用户特征，并将其作为新特征引入。然而，这些方法往往忽略了增加的推理成本，以及如何将预训练模型中的有效信息传递给CTR预测中特定的估计项。本文提出了一种用于CTR预测的序列推荐预训练框架（SRP4CTR），以解决上述问题。首先，我们讨论了引入预训练模型对推理成本的影响。接着，我们引入了一种预训练方法，以同时编码序列侧信息。在微调过程中，我们通过一个交叉注意力模块，以较低的成本在估计项和预训练模型之间建立桥梁。此外，我们开发了一种查询变换器技术，以促进预训练模型中的知识向工业CTR模型的转移。离线和在线实验表明，我们的方法优于以往的基线模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+CTR+Prediction+through+Sequential+Recommendation+Pre-training:+Introducing+the+SRP4CTR+framework)|0|
|[MARS: Matching Attribute-aware Representations for Text-based Sequential Recommendation](https://doi.org/10.1145/3627673.3679960)|Hyunsoo Kim, Junyoung Kim, Minjin Choi, Sunkyung Lee, Jongwuk Lee||Sequential recommendation aims to predict the next item a user is likely to prefer based on their sequential interaction history. Recently, text-based sequential recommendation has emerged as a promising paradigm that uses pre-trained language models to exploit textual item features to enhance performance and facilitate knowledge transfer to unseen datasets. However, existing text-based recommender models still struggle with two key challenges: (i) representing users and items with multiple attributes, and (ii) matching items with complex user interests. To address these challenges, we propose a novel model, Matching Attribute-aware Representations for Text-based Sequential Recommendation (MARS)}. MARS extracts detailed user and item representations through attribute-aware text encoding, capturing diverse user intents with multiple attribute-aware representations. It then computes user-item scores via attribute-wise interaction matching, effectively capturing attribute-level user preferences. Our extensive experiments demonstrate that MARS significantly outperforms existing sequential models, achieving improvements of up to 24.43% and 29.26% in Recall@10 and NDCG@10 across five benchmark datasets. Code is available at https://github.com/junieberry/MARS|顺序推荐旨在根据用户的顺序交互历史预测他们可能偏好的下一个项目。近年来，基于文本的顺序推荐作为一种有前景的范式出现，它利用预训练的语言模型来利用文本项目特征，以提升性能并促进知识向未见数据集的转移。然而，现有的基于文本的推荐模型仍面临两个关键挑战：（i）用多个属性表示用户和项目，以及（ii）匹配具有复杂用户兴趣的项目。为解决这些挑战，我们提出了一种新颖的模型，即基于文本的顺序推荐匹配属性感知表示（MARS）。MARS通过属性感知的文本编码提取详细的用户和项目表示，利用多个属性感知表示捕捉多样化的用户意图。然后，它通过属性层面的交互匹配计算用户-项目分数，有效捕捉属性级别的用户偏好。我们的广泛实验表明，MARS显著优于现有的顺序推荐模型，在五个基准数据集上的Recall@10和NDCG@10分别提高了24.43%和29.26%。代码可在https://github.com/junieberry/MARS获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MARS:+Matching+Attribute-aware+Representations+for+Text-based+Sequential+Recommendation)|0|
|[How to Leverage Personal Textual Knowledge for Personalized Conversational Information Retrieval](https://doi.org/10.1145/3627673.3679939)|Fengran Mo, Longxiang Zhao, Kaiyu Huang, Yue Dong, Degen Huang, JianYun Nie||Personalized conversational information retrieval (CIR) combines conversational and personalizable elements to satisfy various users' complex information needs through multi-turn interaction based on their backgrounds. The key promise is that the personal textual knowledge base (PTKB) can improve the CIR effectiveness because the retrieval results can be more related to the user's background. However, PTKB is noisy: not every piece of knowledge in PTKB is relevant to the specific query at hand. In this paper, we explore and test several ways to select knowledge from PTKB and use it for query reformulation by using a large language model (LLM). The experimental results show the PTKB might not always improve the search results when used alone, but LLM can help generate a more appropriate personalized query when high-quality guidance is provided.|个性化对话信息检索（CIR）结合了对话性和可个性化元素，通过基于用户背景的多轮交互来满足不同用户的复杂信息需求。其核心优势在于，个性化文本知识库（PTKB）能够提升CIR的效果，因为检索结果可以更贴近用户的背景。然而，PTKB存在噪声问题：并非PTKB中的每条知识都与当前的具体查询相关。本文探讨并测试了几种从PTKB中选择知识并用于查询重构的方法，这些方法借助大型语言模型（LLM）实现。实验结果表明，单独使用PTKB并不总能提升搜索结果，但在高质量指引下，LLM能够生成更为合适的个性化查询。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+to+Leverage+Personal+Textual+Knowledge+for+Personalized+Conversational+Information+Retrieval)|0|
|[Enhancing Relevance of Embedding-based Retrieval at Walmart](https://doi.org/10.1145/3627673.3680047)|Juexin Lin, Sachin Yadav, Feng Liu, Nicholas Rossi, Praveen Reddy Suram, Satya Chembolu, Prijith Chandran, Hrushikesh Mohapatra, Tony Lee, Alessandro Magnani, Ciya Liao||Embedding-based neural retrieval (EBR) is an effective search retrieval method in product search for tackling the vocabulary gap between customer search queries and products. The initial launch of our EBR system at Walmart yielded significant gains in relevance and add-to-cart rates [1]. However, despite EBR generally retrieving more relevant products for reranking, we have observed numerous instances of relevance degradation. Enhancing retrieval performance is crucial, as it directly influences product reranking and affects the customer shopping experience. Factors contributing to these degradations include false positives/negatives in the training data and the inability to handle query misspellings. To address these issues, we present several approaches to further strengthen the capabilities of our EBR model in terms of retrieval relevance. We introduce a Relevance Reward Model (RRM) based on human relevance feedback. We utilize RRM to remove noise from the training data and distill it into our EBR model through a multi-objective loss. In addition, we present the techniques to increase the performance of our EBR model, such as typo-aware training, and semi-positive generation. The effectiveness of our EBR is demonstrated through offline relevance evaluation, online AB tests, and successful deployments to live production. [1] Alessandro Magnani, Feng Liu, Suthee Chaidaroon, Sachin Yadav, Praveen Reddy Suram, Ajit Puthenputhussery, Sijie Chen, Min Xie, Anirudh Kashi, Tony Lee, et al. 2022. Semantic retrieval at walmart. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 3495-3503.|基于嵌入的神经检索（EBR）是一种在产品搜索中有效应对客户搜索查询与产品之间词汇差异的搜索检索方法。我们最初在沃尔玛推出的EBR系统显著提升了相关性和加入购物车的比率[1]。然而，尽管EBR通常能检索到更相关的产品以进行重新排序，我们仍观察到许多相关性下降的情况。提升检索性能至关重要，因为它直接影响产品重新排序并影响客户购物体验。导致这些下降的因素包括训练数据中的假阳性/阴性以及无法处理查询拼写错误。为解决这些问题，我们提出了几种方法来进一步增强EBR模型在检索相关性方面的能力。我们引入了一个基于人类相关性反馈的相关性奖励模型（RRM）。我们利用RRM来消除训练数据中的噪声，并通过多目标损失将其提炼到EBR模型中。此外，我们还提出了提升EBR模型性能的技术，如拼写感知训练和半正例生成。通过离线相关性评估、在线AB测试以及成功部署到实际生产中，展示了我们EBR的有效性。[1] Alessandro Magnani, Feng Liu, Suthee Chaidaroon, Sachin Yadav, Praveen Reddy Suram, Ajit Puthenputhussery, Sijie Chen, Min Xie, Anirudh Kashi, Tony Lee, 等. 2022. 沃尔玛的语义检索. 在第28届ACM SIGKDD知识发现与数据挖掘会议论文集. 3495-3503.|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Relevance+of+Embedding-based+Retrieval+at+Walmart)|0|
|[Relevance Filtering for Embedding-based Retrieval](https://doi.org/10.1145/3627673.3680095)|Nicholas Rossi, Juexin Lin, Feng Liu, Zhen Yang, Tony Lee, Alessandro Magnani, Ciya Liao||In embedding-based retrieval, Approximate Nearest Neighbor (ANN) search enables efficient retrieval of similar items from large-scale datasets. While maximizing recall of relevant items is usually the goal of retrieval systems, a low precision may lead to a poor search experience. Unlike lexical retrieval, which inherently limits the size of the retrieved set through keyword matching, dense retrieval via ANN search has no natural cutoff. Moreover, the cosine similarity scores of embedding vectors are often optimized via contrastive or ranking losses, which make them difficult to interpret. Consequently, relying on top-K or cosine-similarity cutoff is often insufficient to filter out irrelevant results effectively. This issue is prominent in product search, where the number of relevant products is often small. This paper introduces a novel relevance filtering component (called "Cosine Adapter") for embedding-based retrieval to address this challenge. Our approach maps raw cosine similarity scores to interpretable scores using a query-dependent mapping function. We then apply a global threshold on the mapped scores to filter out irrelevant results. We are able to significantly increase the precision of the retrieved set, at the expense of a small loss of recall. The effectiveness of our approach is demonstrated through experiments on both public MS MARCO dataset and internal Walmart product search data. Furthermore, online A/B testing on the Walmart site validates the practical value of our approach in real-world e-commerce settings.|在基于嵌入的检索中，近似最近邻（ANN）搜索能够从大规模数据集中高效地检索相似项目。尽管最大化相关项目的召回率通常是检索系统的目标，但低精度可能会导致糟糕的搜索体验。与通过关键词匹配自然限制检索集大小的词法检索不同，通过ANN搜索的密集检索没有自然的截止点。此外，嵌入向量的余弦相似度分数通常通过对比或排序损失进行优化，这使得它们难以解释。因此，仅依赖于前K个结果或余弦相似度截止点往往不足以有效过滤掉不相关的结果。在产品搜索中，这一问题尤为突出，因为相关产品的数量通常较少。本文为基于嵌入的检索引入了一种新颖的相关性过滤组件（称为“余弦适配器”），以应对这一挑战。我们的方法使用查询依赖的映射函数将原始余弦相似度分数映射为可解释的分数，然后对映射后的分数应用全局阈值以过滤掉不相关的结果。我们能够在召回率小幅损失的情况下显著提高检索集的精度。通过在公共MS MARCO数据集和内部沃尔玛产品搜索数据上的实验，证明了我们方法的有效性。此外，在沃尔玛网站上的在线A/B测试验证了我们的方法在实际电子商务环境中的实用价值。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Relevance+Filtering+for+Embedding-based+Retrieval)|0|
|[Advancing Re-Ranking with Multimodal Fusion and Target-Oriented Auxiliary Tasks in E-Commerce Search](https://doi.org/10.1145/3627673.3680063)|Enqiang Xu, Xinhui Li, Zhigong Zhou, Jiahao Ji, Jinyuan Zhao, Dadong Miao, Songlin Wang, Lin Liu, Sulong Xu||In the rapidly evolving field of e-commerce, the effectiveness of search re-ranking models is crucial for enhancing user experience and driving conversion rates. Despite significant advancements in feature representation and model architecture, the integration of multimodal information remains underexplored. This study addresses this gap by investigating the computation and fusion of textual and visual information in the context of re-ranking. We propose Advancing Re-Ranking with Multimodal Fusion and Target-Oriented Auxiliary Tasks (ARMMT), which integrates an attention-based multimodal fusion technique and an auxiliary ranking-aligned task to enhance item representation and improve targeting capabilities. This method not only enriches the understanding of product attributes but also enables more precise and personalized recommendations. Experimental evaluations on JD.com's search platform demonstrate that ARMMT achieves state-of-the-art performance in multimodal information integration, evidenced by a 0.22% increase in the Conversion Rate (CVR), significantly contributing to Gross Merchandise Volume (GMV). This pioneering approach has the potential to revolutionize e-commerce re-ranking, leading to elevated user satisfaction and business growth.|在电子商务快速发展的领域中，搜索重排序模型的有效性对于提升用户体验和推动转化率至关重要。尽管在特征表示和模型架构方面取得了显著进展，但多模态信息的整合仍未得到充分探索。本研究通过探讨重排序情境下文本和视觉信息的计算与融合，填补了这一空白。我们提出了基于多模态融合与面向目标的辅助任务的进阶重排序模型（ARMMT），该模型整合了基于注意力的多模态融合技术与辅助排序对齐任务，以增强商品表示并提升目标定位能力。这种方法不仅丰富了对产品属性的理解，还实现了更精确和个性化的推荐。在京东搜索平台上的实验评估表明，ARMMT在多模态信息整合方面达到了最先进的性能，体现在转化率（CVR）提高了0.22%，显著促进了商品交易总额（GMV）的增长。这一开创性方法有望革新电子商务重排序，带来用户满意度和业务增长的双重提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Advancing+Re-Ranking+with+Multimodal+Fusion+and+Target-Oriented+Auxiliary+Tasks+in+E-Commerce+Search)|0|
|[Missing Interest Modeling with Lifelong User Behavior Data for Retrieval Recommendation](https://doi.org/10.1145/3627673.3680019)|Gaode Chen, Yuezihan Jiang, Rui Huang, Kuo Cai, Yunze Luo, Ruina Sun, Qi Zhang, Han Li, Kun Gai|Kuaishou Technology, Beijing, China|Rich user behavior data has been proven to be of great value for recommendation systems. Modeling lifelong user behavior data in the retrieval stage to explore user long-term preference and obtain comprehensive retrieval results is crucial. Existing lifelong modeling methods cannot applied to the retrieval stage because they extract target-relevant items through the coupling between the user and the target item. Moreover, the current retrieval methods fail to precisely capture user interests when the length of the user behavior sequence increases further. That leads to a gap in the ability of retrieval models to model lifelong user behavior data. In this paper, we propose the concept of missing interest, leveraging the idea of complementarity, which serves as a supplement to short-term interest based on lifelong behavior data in the retrieval stage. Specifically, we design a missing interest operator and deploy it in Kafka data stream, without incurring latency or storage costs. This operator derives categories and authors of items that the user was previously interested in but has recently missed, and uses these as triggers to output missing features to the downstream retrieval model. Our retrieval model is a complete dual-tower structure that combines short-term and missing interests on the user side to provide a comprehensive depiction of lifelong behaviors. Since 2023, the presented solution has been deployed in Kuaishou, one of the most popular short-video streaming platforms in China with hundreds of millions of active users.|丰富的用户行为数据已被证明对推荐系统具有巨大价值。在检索阶段对终身用户行为数据进行建模，以探索用户的长期偏好并获得全面的检索结果至关重要。现有的终身建模方法无法应用于检索阶段，因为它们通过用户与目标项目之间的耦合来提取目标相关项目。此外，当前的检索方法在用户行为序列长度进一步增加时无法精确捕捉用户兴趣。这导致了检索模型在终身用户行为数据建模能力上的差距。本文提出了缺失兴趣的概念，利用互补的思想，作为基于终身行为数据在检索阶段对短期兴趣的补充。具体来说，我们设计了一个缺失兴趣操作符，并将其部署在Kafka数据流中，不会产生延迟或存储成本。该操作符推导出用户之前感兴趣但最近错过的项目的类别和作者，并使用这些作为触发器向下游检索模型输出缺失特征。我们的检索模型是一个完整的双塔结构，结合了用户端的短期兴趣和缺失兴趣，全面描绘了终身行为。自2023年以来，所提出的解决方案已部署在中国最受欢迎的短视频流媒体平台之一——快手，该平台拥有数亿活跃用户。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Missing+Interest+Modeling+with+Lifelong+User+Behavior+Data+for+Retrieval+Recommendation)|0|
|[Relative Contrastive Learning for Sequential Recommendation with Similarity-based Positive Sample Selection](https://doi.org/10.1145/3627673.3679681)|Zhikai Wang, Yanyan Shen, Zexi Zhang, Li He, Yichun Li, Hao Gu, Yinghua Zhang|Shanghai Jiao Tong University, Shanghai, China; Meituan, Shanghai, China|Contrastive Learning (CL) enhances the training of sequential recommendation (SR) models through informative self-supervision signals. Existing methods often rely on data augmentation strategies to create positive samples and promote representation invariance. Some strategies such as item reordering and item substitution may inadvertently alter user intent. Supervised Contrastive Learning (SCL) based methods find an alternative to augmentation-based CL methods by selecting same-target sequences (interaction sequences with the same target item) to form positive samples. However, SCL-based methods suffer from the scarcity of same-target sequences and consequently lack enough signals for contrastive learning. In this work, we propose to use similar sequences (with different target items) as additional positive samples and introduce a Relative Contrastive Learning (RCL) framework for sequential recommendation. RCL comprises a dual-tiered positive sample selection module and a relative contrastive learning module. The former module selects same-target sequences as strong positive samples and selects similar sequences as weak positive samples. The latter module employs a weighted relative contrastive loss, ensuring that each sequence is represented closer to its strong positive samples than its weak positive samples. We apply RCL on two mainstream deep learning-based SR models, and our empirical results reveal that RCL can achieve 4.88% improvement averagely than the state-of-the-art SR methods on five public datasets and one private dataset. The code can be found at https://github.com/Cloudcatcher888/RCL.|对比学习（CL）通过提供信息丰富的自监督信号，增强了序列推荐（SR）模型的训练。现有方法通常依赖于数据增强策略来创建正样本并促进表示的不变性。一些策略如物品重新排序和物品替换可能会无意中改变用户意图。基于监督对比学习（SCL）的方法通过选择相同目标序列（与相同目标物品的交互序列）来形成正样本，从而为基于增强的CL方法提供了替代方案。然而，SCL方法面临相同目标序列稀缺的问题，因此缺乏足够的对比学习信号。在这项工作中，我们提出使用相似序列（具有不同目标物品）作为额外的正样本，并引入了一个相对对比学习（RCL）框架用于序列推荐。RCL包括一个双层正样本选择模块和一个相对对比学习模块。前者模块选择相同目标序列作为强正样本，并选择相似序列作为弱正样本。后者模块采用加权相对对比损失，确保每个序列的表示更接近其强正样本而非弱正样本。我们将RCL应用于两个主流的基于深度学习的SR模型，我们的实验结果显示，RCL在五个公共数据集和一个私有数据集上平均比最先进的SR方法提高了4.88%。代码可在https://github.com/Cloudcatcher888/RCL找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Relative+Contrastive+Learning+for+Sequential+Recommendation+with+Similarity-based+Positive+Sample+Selection)|0|
|[Momentum Contrastive Bidirectional Encoding with Self-Distillation for Sequential Recommendation](https://doi.org/10.1145/3627673.3679965)|Dingyi Zhang, Haoyu Wenren, Yue Wang, Yingming Li|Zhejiang University, Hangzhou, China; Alipay (Hangzhou) Information Technology Co., Ltd, Hangzhou, China|In this paper, we propose a new Momentum Contrastive Bidirectional Encoding network with S elf-D istillation (MoCoBE-SD) to alleviate the data sparsity and noise issues in sequential recommendation by providing rich informative supervisions from both sequence-level and item-level perspectives. In particular, a Momentum Contrastive Bidirectional Encoding (MoCoBE) network is first proposed by constructing momentum updated encoder based on an online bidirectional self-attention encoder, where a momentum contrastive learning task and a masked item prediction task are simultaneously optimized. Building upon MoCoBE, a well-elaborated Self-Distillation (SD) scheme is incorporated to further suppress the noise influence. Specifically, a well-trained sequence encoder by MoCoBE is adopted as the teacher encoder to provide refined supervision for the masked item prediction, which constitutes our MoCoBE-SD framework. Extensive experiments on three public datasets show that MoCoBE-SD outperforms the existing state-of-the-art methods consistently.|本文提出了一种新的动量对比双向编码网络，结合自蒸馏技术（MoCoBE-SD），以缓解序列推荐中数据稀疏和噪声问题。通过从序列级和项目级两个角度提供丰富的信息监督来实现这一目标。具体而言，首先提出了一种动量对比双向编码（MoCoBE）网络，该网络基于在线双向自注意力编码器构建了动量更新的编码器，同时优化了动量对比学习任务和掩码项目预测任务。在MoCoBE的基础上，引入了一种精心设计的自蒸馏（SD）方案，以进一步抑制噪声的影响。具体来说，通过MoCoBE训练好的序列编码器被用作教师编码器，为掩码项目预测提供精细化的监督，从而构成了我们的MoCoBE-SD框架。在三个公共数据集上的广泛实验表明，MoCoBE-SD在性能上持续优于现有的最先进方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Momentum+Contrastive+Bidirectional+Encoding+with+Self-Distillation+for+Sequential+Recommendation)|0|
|[A Real-Time Adaptive Multi-Stream GPU System For Online Approximate Nearest Neighborhood Search](https://doi.org/10.1145/3627673.3680054)|Yiping Sun, Yang Shi, Jiaolong Du||In recent years, Approximate Nearest Neighbor Search (ANNS) has played a pivotal role in modern search and recommendation systems, especially in emerging LLM applications like Retrieval-Augmented Generation. There is a growing exploration into harnessing the parallel computing capabilities of GPUs to meet the substantial demands of ANNS. However, existing systems primarily focus on offline scenarios, overlooking the distinct requirements of online applications that necessitate real-time insertion of new vectors. This limitation renders such systems inefficient for real-world scenarios. Moreover, previous architectures struggled to effectively support real-time insertion due to their reliance on serial execution streams. In this paper, we introduce a novel Real-Time Adaptive Multi-Stream GPU ANNS System (RTAMS-GANNS). Our architecture achieves its objectives through three key advancements: 1) We initially examined the real-time insertion mechanisms in existing GPU ANNS systems and discovered their reliance on repetitive copying and memory allocation, which significantly hinders real-time effectiveness on GPUs. As a solution, we introduce a dynamic vector insertion algorithm based on memory blocks, which includes in-place rearrangement. 2) To enable real-time vector insertion in parallel, we introduce a multi-stream parallel execution mode, which differs from existing systems that operate serially within a single stream. Our system utilizes a dynamic resource pool, allowing multiple streams to execute concurrently without additional execution blocking. 3) Through extensive experiments and comparisons, our approach effectively handles varying QPS levels across different datasets, reducing latency by up to 40 proposed system has also been deployed in real-world industrial search and recommendation systems, serving hundreds of millions of users daily, and has achieved good results.|近年来，近似最近邻搜索（ANNS）在现代搜索和推荐系统中发挥了关键作用，特别是在诸如增强检索生成（Retrieval-Augmented Generation）等新兴的大型语言模型（LLM）应用中。越来越多的研究致力于利用GPU的并行计算能力来满足ANNS的巨大需求。然而，现有的系统主要关注离线场景，忽视了在线应用的独特需求，这些需求需要实时插入新向量。这种局限性使得这些系统在现实场景中效率低下。此外，先前的架构由于依赖串行执行流，难以有效支持实时插入。在本文中，我们介绍了一种新型实时自适应多流GPU ANNS系统（RTAMS-GANNS）。我们的架构通过三个关键进展实现了其目标：1）我们首先研究了现有GPU ANNS系统中的实时插入机制，发现它们依赖于重复的复制和内存分配，这严重阻碍了GPU上的实时效率。作为解决方案，我们引入了一种基于内存块的动态向量插入算法，包括就地重排。2）为了实现并行实时向量插入，我们引入了一种多流并行执行模式，这与现有系统在单一流中串行操作不同。我们的系统利用动态资源池，允许多个流并发执行而无需额外的执行阻塞。3）通过广泛的实验和比较，我们的方法有效地处理了不同数据集上的不同QPS水平，延迟降低了高达40%。所提出的系统也已部署在实际的工业搜索和推荐系统中，每天服务于数亿用户，并取得了良好的效果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Real-Time+Adaptive+Multi-Stream+GPU+System+For+Online+Approximate+Nearest+Neighborhood+Search)|0|
|[MERLIN: Multimodal & Multilingual Embedding for Recommendations at Large-scale via Item Associations](https://doi.org/10.1145/3627673.3680106)|Sambeet Tiady, Arihant Jain, Dween Rabius Sanny, Khushi Gupta, Srinivas Virinchi, Swapnil Gupta, Anoop Saladi, Deepak Gupta|Amazon.com, Bangalore, India|Product recommendations incentivize customers to make multi-unit purchases by surfacing relevant products, leading to lower cost per unit for e-commerce stores and lower prices for their customers. However, the humongous scale of products, implicit co-purchase asymmetry and variation in co-purchase behavior across different categories, are orthogonal problems to solve. To address these problems, we propose MERLIN (Multimodal & Multilingual Embedding for Recommendations at Large-scale via Item associations), a Graph Neural Network that generates product recommendations from a heterogeneous and directed product graph. We mine category associations to remove noisy product co-purchase associations, leading to higher quality recommendations. Leveraging product co-view relationships, we finetune SentenceBERT model for textual representation, and train a self-supervised knowledge distillation model to learn visual representation, which allows us to learn product representations which are multi-lingual and multi-modal in nature. We selectively align node embeddings leveraging co-viewed products. MERLIN model can handle node asymmetry by learning dual embeddings for each product, and can generate recommendations for cold-start products by employing catalog metadata such as title, category and image. Extensive offline experiments on internal and external datasets show that MERLIN model outperforms state-of-the-art baselines for node recommendation and link prediction task. We conduct ablations to quantify the impact of our model components and choices. Further, MERLIN model delivers significant improvement in sales measured through an A/B experiment.|产品推荐通过展示相关产品激励顾客进行多单位购买，从而降低电商商店的单位成本和顾客的购买价格。然而，产品规模的巨大、隐含的共同购买不对称性以及不同类别间共同购买行为的变化，是相互独立的问题。为了解决这些问题，我们提出了MERLIN（通过项目关联进行大规模推荐的多模态与多语言嵌入），这是一个从异构且有向的产品图中生成产品推荐的图神经网络。我们挖掘类别关联来消除噪声产品共同购买关联，从而提高推荐质量。利用产品共同浏览关系，我们微调了SentenceBERT模型以获取文本表示，并训练了一个自监督的知识蒸馏模型来学习视觉表示，这使我们能够学习到本质上是多语言和多模态的产品表示。我们通过共同浏览的产品有选择地对齐节点嵌入。MERLIN模型通过为每个产品学习双重嵌入来处理节点不对称性，并通过使用标题、类别和图像等目录元数据为冷启动产品生成推荐。在内、外部数据集上的广泛离线实验表明，MERLIN模型在节点推荐和链接预测任务上优于最先进的基线模型。我们进行了消融实验，以量化我们模型组件和选择的影响。此外，通过A/B实验测量的销售数据显示，MERLIN模型带来了显著的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MERLIN:+Multimodal+&+Multilingual+Embedding+for+Recommendations+at+Large-scale+via+Item+Associations)|0|
|[Towards Advancing Text-Based User and Item Representation in Personalized Recommendation](https://doi.org/10.1145/3627673.3680270)|Hanjia Lyu|University of Rochester, Rochester, NY, USA|In the realm of personalized recommendation systems, accurately capturing user preferences and item characteristics is important for delivering relevant and satisfying recommendations. This study introduces innovative approaches using Large Language Models (LLMs) to generate detailed textual descriptions that enhance both user and item representations. We propose a dual strategy: for user representation, we employ supervised fine-tuning coupled with Retrieval-Augmented Generation (RAG) to keep the model current with dynamic user preferences; for item representation, we leverage the extensive knowledge base of LLMs to enrich item descriptions and infer traits from user interactions. These methods promise a deeper, more nuanced understanding of both users and items, potentially leading to superior recommendation accuracy. We adopt a rigorous evaluation methodology, ensuring the reliability of our results and the effectiveness of our proposed system. This paper discusses these methodologies, presents our preliminary findings, and highlights the potential of text-augmented profiles in advancing recommendation systems.|在个性化推荐系统领域，准确捕捉用户偏好和物品特征对于提供相关且令人满意的推荐至关重要。本研究引入了利用大型语言模型（LLMs）生成详细文本描述的创新方法，以增强用户和物品的表示。我们提出了一种双重策略：对于用户表示，我们采用监督微调结合检索增强生成（RAG），以使模型与动态用户偏好保持同步；对于物品表示，我们利用LLMs的广泛知识库来丰富物品描述，并从用户交互中推断特征。这些方法有望对用户和物品实现更深入、更细致的理解，从而可能提高推荐准确性。我们采用严格的评估方法，确保结果的可靠性和所提出系统的有效性。本文讨论了这些方法，展示了初步研究成果，并强调了文本增强型用户和物品描述在推进推荐系统方面的潜力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Advancing+Text-Based+User+and+Item+Representation+in+Personalized+Recommendation)|0|
|[Contrastive Learning on Medical Intents for Sequential Prescription Recommendation](https://doi.org/10.1145/3627673.3679836)|Arya Hadizadeh Moghaddam, Mohsen Nayebi Kerdabadi, Mei Liu, Zijun Yao||Recent advancements in sequential modeling applied to Electronic Health Records (EHR) have greatly influenced prescription recommender systems. While the recent literature on drug recommendation has shown promising performance, the study of discovering a diversity of coexisting temporal relationships at the level of medical codes over consecutive visits remains less explored. The goal of this study can be motivated from two perspectives. First, there is a need to develop a sophisticated sequential model capable of disentangling the complex relationships across sequential visits. Second, it is crucial to establish multiple and diverse health profiles for the same patient to ensure a comprehensive consideration of different medical intents in drug recommendation. To achieve this goal, we introduce Attentive Recommendation with Contrasted Intents (ARCI), a multi-level transformer-based method designed to capture the different but coexisting temporal paths across a shared sequence of visits. Specifically, we propose a novel intent-aware method with contrastive learning, that links specialized medical intents of the patients to the transformer heads for extracting distinct temporal paths associated with different health profiles. We conducted experiments on two real-world datasets for the prescription recommendation task using both ranking and classification metrics. Our results demonstrate that ARCI has outperformed the state-of-the-art prescription recommendation methods and is capable of providing interpretable insights for healthcare practitioners.|近年来，应用于电子健康记录（EHR）的序列建模的进展极大地影响了处方推荐系统。尽管最近关于药物推荐的文献展示了令人鼓舞的性能，但在连续就诊中，在医疗代码层面发现多种共存的时间关系的研究仍较少探索。本研究的目标可以从两个角度来推动。首先，需要开发一种复杂的序列模型，能够解开跨连续就诊的复杂关系。其次，为同一患者建立多个多样化的健康档案至关重要，以确保在药物推荐中全面考虑不同的医疗意图。为了实现这一目标，我们引入了带有对比意图的注意力推荐（ARCI），这是一种基于多层变换器的方法，旨在捕捉共享序列就诊中不同的但共存的时间路径。具体来说，我们提出了一种新颖的意图感知方法，结合对比学习，将患者的专门医疗意图链接到变换器头部，以提取与不同健康档案相关的独特时间路径。我们在两个真实世界的数据集上进行了处方推荐任务的实验，使用了排名和分类指标。结果表明，ARCI在性能上优于最先进的处方推荐方法，并能够为医疗从业者提供可解释的见解。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Learning+on+Medical+Intents+for+Sequential+Prescription+Recommendation)|0|
|[Behavior-Dependent Linear Recurrent Units for Efficient Sequential Recommendation](https://doi.org/10.1145/3627673.3679717)|Chengkai Liu, Jianghao Lin, Hanzhou Liu, Jianling Wang, James Caverlee||Sequential recommender systems aims to predict the users' next interaction through user behavior modeling with various operators like RNNs and attentions. However, existing models generally fail to achieve the three golden principles for sequential recommendation simultaneously, i.e., training efficiency, low-cost inference, and strong performance. To this end, we propose RecBLR, an Efficient Sequential Recommendation Model based on Behavior-Dependent Linear Recurrent Units to accomplish the impossible triangle of the three principles. By incorporating gating mechanisms and behavior-dependent designs into linear recurrent units, our model significantly enhances user behavior modeling and recommendation performance. Furthermore, we unlock the parallelizable training as well as inference efficiency for our model by designing a hardware-aware scanning acceleration algorithm with a customized CUDA kernel. Extensive experiments on real-world datasets with varying lengths of user behavior sequences demonstrate RecBLR's remarkable effectiveness in simultaneously achieving all three golden principles - strong recommendation performance, training efficiency, and low-cost inference, while exhibiting excellent scalability to datasets with long user interaction histories.|顺序推荐系统旨在通过使用RNN和注意力等操作符对用户行为进行建模来预测用户的下一次交互。然而，现有的模型通常无法同时实现顺序推荐的三个黄金原则，即训练效率、低成本推理和强大的性能。为此，我们提出了RecBLR，一种基于行为依赖线性循环单元的高效顺序推荐模型，以实现这三个原则的不可能三角。通过将门控机制和行为依赖设计融入线性循环单元，我们的模型显著增强了用户行为建模和推荐性能。此外，我们通过设计一个硬件感知的扫描加速算法和定制的CUDA内核，为我们的模型解锁了可并行化的训练以及推理效率。在具有不同长度用户行为序列的实际数据集上的广泛实验表明，RecBLR在同时实现所有三个黄金原则方面表现出色——强大的推荐性能、训练效率和低成本推理，同时在处理具有长用户交互历史的数据集时展现出卓越的可扩展性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Behavior-Dependent+Linear+Recurrent+Units+for+Efficient+Sequential+Recommendation)|0|
|[MultiLoRA: Multi-Directional Low Rank Adaptation for Multi-Domain Recommendation](https://doi.org/10.1145/3627673.3679549)|Zijian Song, Wenhan Zhang, Lifang Deng, Jiandong Zhang, Kaigui Bian, Bin Cui|School of CS, Peking University & AI Innovation Center, Peking University, Beijing, China; Lazada Group, Beijing, China|To address the business needs of industrial recommendation systems, an increasing number of Multi-Domain Recommendation (MDR) methods are designed to improve recommendation performance on multiple domains simultaneously. Most MDR methods follow a multi-task learning paradigm, suffering from poor deployability and negative transfer. Due to the great success of large pre-trained models, the pre-train & fine-tune paradigm is attracting increasing attention. The latest methods introduce parameter-efficient fine-tuning techniques like prompt-tuning, showcasing high efficiency and effectiveness. However, these methods neglect the fundamental differences between recommendation and NLP tasks. The inadequate capacity of recommendation models restricts the effectiveness of prompts and adapters. Worse still, traditional natural domain division may group non-identically distributed samples into the same domain, violating the assumption of independent and identically distributed (i.i.d.) data. In this paper, we propose MultiLoRA, a Multi-directional Low Rank Adaptation paradigm for multi-domain recommendation. First we pre-train a universal model using all data samples. Then we conduct multiple domain divisions on the sample space. Under each division, we fine-tune the pre-trained model to obtain a set of domain-specific LoRAs. Finally, we learn a LoRA fusion module to integrate domain-specific preference patterns across multiple divisions. Experimental results on real-world datasets demonstrate notable advantages of MultiLoRA: (1) achieving SOTA performance, (2) showcasing remarkable compatibility, and (3) proving highly efficient, featuring only 2% trainable parameters compared to the backbone.|为了满足工业推荐系统的业务需求，越来越多的多领域推荐（MDR）方法被设计出来，以同时提升多个领域的推荐性能。大多数MDR方法遵循多任务学习的范式，存在部署性差和负迁移的问题。由于大型预训练模型取得了巨大成功，预训练与微调的范式正受到越来越多的关注。最新的方法引入了如提示调优等参数高效的微调技术，展示了高效性和有效性。然而，这些方法忽略了推荐任务与自然语言处理任务之间的根本差异。推荐模型的不足能力限制了提示词和适配器的有效性。更糟糕的是，传统的自然领域划分可能将非同分布的样本归入同一领域，违反了独立同分布（i.i.d.）数据的假设。在本文中，我们提出了MultiLoRA，一种面向多领域推荐的多向低秩适应范式。首先，我们使用所有数据样本预训练一个通用模型。然后，我们在样本空间上进行多次领域划分。在每次划分下，我们对预训练模型进行微调，以获得一组领域特定的LoRAs。最后，我们学习一个LoRA融合模块，以整合多个划分中的领域特定偏好模式。在真实世界数据集上的实验结果显示了MultiLoRA的显著优势：（1）实现了SOTA性能，（2）展示了出色的兼容性，（3）证明了高效率，仅具有与骨干模型相比2%的可训练参数。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MultiLoRA:+Multi-Directional+Low+Rank+Adaptation+for+Multi-Domain+Recommendation)|0|
|[Bridging User Dynamics: Transforming Sequential Recommendations with Schrödinger Bridge and Diffusion Models](https://doi.org/10.1145/3627673.3679756)|Wenjia Xie, Rui Zhou, Hao Wang, Tingjia Shen, Enhong Chen||Sequential recommendation has attracted increasing attention due to its ability to accurately capture the dynamic changes in user interests. We have noticed that generative models, especially diffusion models, which have achieved significant results in fields like image and audio, hold considerable promise in the field of sequential recommendation. However, existing sequential recommendation methods based on diffusion models are constrained by a prior distribution limited to Gaussian distribution, hindering the possibility of introducing user-specific information for each recommendation and leading to information loss. To address these issues, we introduce the Schrödinger Bridge into diffusion-based sequential recommendation models, creating the SdifRec model. This allows us to replace the Gaussian prior of the diffusion model with the user's current state, directly modeling the process from a user's current state to the target recommendation. Additionally, to better utilize collaborative information in recommendations, we propose an extended version of SdifRec called con-SdifRec, which utilizes user clustering information as a guiding condition to further enhance the posterior distribution. Finally, extensive experiments on multiple public benchmark datasets have demonstrated the effectiveness of SdifRec and con-SdifRec through comparison with several state-of-the-art methods. Further in-depth analysis has validated their efficiency and robustness.|顺序推荐因其能够准确捕捉用户兴趣的动态变化而受到越来越多的关注。我们注意到，生成模型，特别是扩散模型，在图像和音频等领域取得了显著成果，在顺序推荐领域也展现出巨大的潜力。然而，现有的基于扩散模型的顺序推荐方法受限于仅限于高斯分布的先验分布，这阻碍了在每次推荐中引入特定用户信息的可能性，导致信息损失。为了解决这些问题，我们将薛定谔桥引入基于扩散的顺序推荐模型，创建了SdifRec模型。这使得我们能够将扩散模型的高斯先验替换为用户当前状态，直接模拟从用户当前状态到目标推荐的过程。此外，为了更好地利用推荐中的协同信息，我们提出了SdifRec的扩展版本，称为con-SdifRec，它利用用户聚类信息作为指导条件，进一步增强后验分布。最后，在多个公共基准数据集上的广泛实验通过与几种最先进方法的比较，证明了SdifRec和con-SdifRec的有效性。进一步的深入分析验证了它们的效率和鲁棒性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bridging+User+Dynamics:+Transforming+Sequential+Recommendations+with+Schrödinger+Bridge+and+Diffusion+Models)|0|
|[Generating Intent-aware Clarifying Questions in Conversational Information Retrieval Systems](https://doi.org/10.1145/3627673.3679851)|Ziliang Zhao, Zhicheng Dou, Yujia Zhou|Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China|Generating clarifying questions can effectively clarify users' complicated search intent in conversational search systems. However, existing methods based on pre-defined templates are inadequate in understanding explicit user intents, making generated questions monotonous or inaccurate in some cases. In this paper, we define the ''intent'' of a query as a verb representing the potential behavior, action, or task the user may take. We study generating clarifying questions from a new perspective by incorporating the intents explicitly to form ''intent-aware'' questions with high informativeness and accuracy. Since obtaining gold intent-aware questions is expensive, we propose a rule-based method and a continual learning model to generate intent-aware questions as weak supervision signals. The former leverages search results to mine contextual intent-aware words or phrases, and the latter relies on parallel corpora to paraphrase template-based questions by incorporating the intents. The generated weak supervision data are then applied to fine-tune a BART-based model for end-to-end intent-aware question generation. We also explore to prompt a large language model to generate intent-aware questions. Experimental results on a public clarification dataset demonstrate that our proposed methods improve users' search experience compared to existing methods.|生成澄清问题可以有效澄清对话搜索系统中用户复杂的搜索意图。然而，现有基于预定义模板的方法在理解明确用户意图方面存在不足，导致生成的问题在某些情况下单调或不准确。本文中，我们将查询的“意图”定义为用户可能采取的潜在行为、动作或任务的动词表示。我们通过明确结合意图，从新的角度研究生成信息丰富且准确的“意图感知”澄清问题。由于获取黄金标准的意图感知问题成本高昂，我们提出了一种基于规则的方法和一种持续学习模型，以生成意图感知的弱监督信号。前者利用搜索结果挖掘上下文中的意图感知词或短语，后者则依赖平行语料库通过结合意图对基于模板的问题进行释义。生成的弱监督数据随后用于微调基于BART的模型，以实现端到端的意图感知问题生成。我们还探索了引导大型语言模型生成意图感知问题的方法。在公开的澄清数据集上的实验结果表明，与现有方法相比，我们提出的方法提升了用户的搜索体验。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generating+Intent-aware+Clarifying+Questions+in+Conversational+Information+Retrieval+Systems)|0|
|[Enhancing E-Commerce Query Rewriting: A Large Language Model Approach with Domain-Specific Pre-Training and Reinforcement Learning](https://doi.org/10.1145/3627673.3680109)|Aijun Dai, Zhenyu Zhu, Haiqing Hu, Guoyu Tang, Lin Liu, Sulong Xu|JD.com, Beijing, China; JD.com, Bejing, China|In the domain of e-commerce, query rewriting is a potent strategy for bridging the lexical gap between search queries and product descriptions, thereby enhancing the recall rate of search engines. This research introduces a query rewriting framework predicated on large language models (LLM), encompassing three phases of training: domain-specific pre-training, supervised fine-tuning (SFT) and reinforcement learning (RL) for objective alignment. To detail, the process initiates with domain-specific pre-training using consumer behavior data and product descriptions from JD.com. Subsequently, we filter and utilize high-quality query-rewrite pairs for SFT. The final stage employs RL to refine the model's objective alignment, utilizing an offline search system as the simulation environment. The RL's training reward is derived from the recall rate, aiming to optimize the number of relevant products the rewrites retrieve. Through offline evaluations, our method has demonstrated its capacity to substantially enhance the efficacy of LLMs for e-commerce query rewriting. Moreover, online A/B testing has corroborated that our approach significantly boosts the number of purchases made per user (UCVR). Since December 2023, our approach has been successfully implemented on JD.com, one of China's most frequented online shopping platforms.|在电子商务领域，查询重写是弥合搜索查询与产品描述之间词汇鸿沟的有效策略，从而提高搜索引擎的召回率。本研究引入了一种基于大型语言模型（LLM）的查询重写框架，该框架包括三个训练阶段：领域特定的预训练、有监督的微调（SFT）和用于目标对齐的强化学习（RL）。具体而言，该过程首先使用京东的消费行为数据和产品描述进行领域特定的预训练。随后，我们筛选并利用高质量的查询-重写对进行SFT。最后阶段采用RL来优化模型的目标对齐，利用离线搜索系统作为模拟环境。RL的训练奖励基于召回率，旨在优化重写查询所检索到的相关产品数量。通过离线评估，我们的方法展示了其显著提升LLM在电子商务查询重写中效能的能力。此外，在线A/B测试证实了我们的方法显著提高了每位用户的购买转化率（UCVR）。自2023年12月以来，我们的方法已成功应用于京东，这是中国访问量最大的在线购物平台之一。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+E-Commerce+Query+Rewriting:+A+Large+Language+Model+Approach+with+Domain-Specific+Pre-Training+and+Reinforcement+Learning)|0|
|[Deep Uncertainty-Based Explore for Index Construction and Retrieval in Recommendation System](https://doi.org/10.1145/3627673.3680077)|Xin Jiang, Kaiqiang Wang, Yinlong Wang, Fengchang Lv, Taiyang Peng, Shuai Yang, Xianteng Wu, Pengye Zhang, Shuo Yuan, Yifan Zeng||In recommendation systems, the relevance and novelty of the final results are selected through a cascade system of Matching -> Ranking -> Strategy. The matching model serves as the starting point of the pipeline and determines the upper bound of the subsequent stages. Balancing the relevance and novelty of matching results is a crucial step in the design and optimization of recommendation systems, contributing significantly to improving recommendation quality. However, the typical matching algorithms have not simultaneously addressed the relevance and novelty perfectly. One main reason is that deep matching algorithms exhibit significant uncertainty when estimating items in the long tail (e.g., due to insufficient training samples) items.The uncertainty not only affects the training of the models but also influences the confidence in the index construction and beam search retrieval process of these models. This paper proposes the UICR (Uncertainty-based explore for Index Construction and Retrieval) algorithm, which introduces the concept of uncertainty modeling in the matching stage and achieves multi-task modeling of model uncertainty and index uncertainty. The final matching results are obtained by combining the relevance score and uncertainty score infered by the model. Experimental results demonstrate that the UICR improves novelty without sacrificing relevance on realworld industrial productive environments and multiple open-source datasets. Remarkably, online A/B test results of display advertising in Shopee demonstrates the effectiveness of the proposed algorithm.|在推荐系统中，最终结果的相关性和新颖性是通过匹配（Matching）->排序（Ranking）->策略（Strategy）的级联系统来选择的。匹配模型作为管道的起点，决定了后续阶段的上限。平衡匹配结果的相关性和新颖性是推荐系统设计和优化的关键步骤，对提高推荐质量有显著贡献。然而，典型的匹配算法并没有同时完美地解决相关性和新颖性问题。主要原因之一是深度匹配算法在估计长尾（例如，由于训练样本不足）项目时表现出显著的不确定性。这种不确定性不仅影响模型的训练，还影响这些模型在索引构建和束搜索检索过程中的置信度。本文提出了基于不确定性的索引构建和检索（UICR）算法，该算法在匹配阶段引入了不确定性建模的概念，实现了模型不确定性和索引不确定性的多任务建模。最终的匹配结果是通过结合模型推断的相关性分数和不确定性分数获得的。实验结果表明，UICR在不牺牲相关性的情况下提高了新颖性，在现实世界的工业生产环境和多个开源数据集上都得到了验证。值得注意的是，Shopee展示广告的在线A/B测试结果证明了所提出算法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Uncertainty-Based+Explore+for+Index+Construction+and+Retrieval+in+Recommendation+System)|0|
|[Towards Seamless User Query to REST API Conversion](https://doi.org/10.1145/3627673.3680275)|Han Xu|University of Illinois Urbana-Champaign, Urbana, IL, USA|Integrating Large Language Models (LLMs) with external tools and APIs is essential for fields such as information retrieval and knowledge management. While LLMs have made significant strides, their effective integration with external APIs-essential for real-world applications-remains challenging. This paper introduces RESTful-Llama, a novel method designed to empower open-source LLMs to accurately convert natural language instructions into well-formed RESTful API calls. Moreover, RESTful-Llama utilizes DOC-Prompt, a newly proposed technique for generating fine-tuning datasets from publicly available API documentation. Initial experiments demonstrate that RESTful-Llama significantly enhances the accuracy of generated REST API requests.|将大型语言模型（LLMs）与外部工具和API集成对于信息检索和知识管理等领域至关重要。尽管LLMs取得了显著进展，但它们与外部API的有效集成——这对于实际应用至关重要——仍然具有挑战性。本文介绍了RESTful-Llama，这是一种新颖的方法，旨在使开源LLMs能够准确地将自然语言指令转换为格式良好的RESTful API调用。此外，RESTful-Llama利用了DOC-Prompt，这是一种新提出的技术，用于从公开可用的API文档生成微调数据集。初步实验表明，RESTful-Llama显著提高了生成的REST API请求的准确性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Seamless+User+Query+to+REST+API+Conversion)|0|
|[Product Retrieval and Ranking for Alphanumeric Queries](https://doi.org/10.1145/3627673.3679080)|Hadeel Saadany, Swapnil Bhosale, Samarth Agrawal, Zhe Wu, Constantin Orasan, Diptesh Kanojia|People-Centred AI, University of Surrey, Guildford, United Kingdom; eBay Inc., Seattle, USA; Centre for Translation Studies, University of Surrey, Guildford, United Kingdom; eBay Inc., San Jose, USA|This talk addresses the challenge of improving user experience on e-commerce platforms by enhancing product ranking relevant to user's search queries. Queries such as S2716DG consist of alphanumeric characters where a letter or number can signify important detail for the product/model. Speaker describes recent research where we curate samples from existing datasets at eBay, manually annotated with buyer-centric relevance scores, and centrality scores which reflect how well the product title matches the user's intent. We introduce a User-intent Centrality Optimization (UCO) approach for existing models, which optimizes for the user intent in semantic product search. To that end, we propose a dual-loss based optimization to handle hard negatives, i.e., product titles that are semantically relevant but do not reflect the user's intent. Our contributions include curating a challenging evaluation set and implementing UCO, resulting in significant improvements in product ranking efficiency, observed for different evaluation metrics. Our work aims to ensure that the most buyer-centric titles for a query are ranked higher, thereby, enhancing the user experience on e-commerce platforms.|本次演讲探讨了通过提升与用户搜索查询相关的产品排序来改善电子商务平台用户体验的挑战。诸如S2716DG之类的查询包含字母数字字符，其中字母或数字可能代表产品/型号的重要细节。演讲者描述了最近的研究，我们在eBay的现有数据集中精选样本，这些样本经过手动标注，具有以买家为中心的相关性评分和中心性评分，后者反映了产品标题与用户意图的匹配程度。我们引入了一种用户意图中心性优化（User-intent Centrality Optimization, UCO）方法，用于现有模型，该方法优化了语义产品搜索中的用户意图。为此，我们提出了一种基于双重损失的优化方法来处理硬负样本，即那些在语义上相关但未反映用户意图的产品标题。我们的贡献包括策划一个具有挑战性的评估集和实现UCO，从而在不同的评估指标下显著提高了产品排序效率。我们的工作旨在确保对于一个查询，最符合买家意图的标题排名更高，从而增强电子商务平台的用户体验。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Product+Retrieval+and+Ranking+for+Alphanumeric+Queries)|0|
|[PTSR: Prefix-Target Graph-based Sequential Recommendation](https://doi.org/10.1145/3627673.3679718)|Jiayu Chen, Xiaoyu Du, Yonghua Pan, Jinhui Tang|Nanjing University of Science and Technology, Nanjing, China|Sequential recommendation approaches predict the next items (targets) by analyzing prefix subsequences. These methods primarily model the correlations between prefixes and targets but often neglect the inherent correlations among prefixes and items. In this paper, we propose a Prefix-Target Graph-based Sequential Recommendation Approach (PTSR), which constructs a prefix-target graph (PTG) to collect observed correlations among prefixes and targets. It utilizes a graph neural network to model these inherent correlations, thus improving the item representations used in the predictive model. Specifically, prefixes linked to the same target reflect similar intents, while targets linked to the same prefix indicate available choices. This allows the graph neural network to effectively capture high-level correlations among prefixes and items, enhancing recommendation accuracy. We conduct extensive experiments on four real-world datasets to demonstrate the superiority of PTSR compared to state-of-the-art (SOTA) sequential recommendation methods. The source code of the PTSR is available at https://github.com/TosakRin/PTSR.|顺序推荐方法通过分析前缀子序列来预测下一个项目（目标）。这些方法主要建模前缀与目标之间的关联，但往往忽略了前缀和项目之间固有的关联。本文提出了一种基于前缀-目标图的顺序推荐方法（PTSR），该方法构建了一个前缀-目标图（PTG）以收集前缀与目标之间观察到的关联。它利用图神经网络来建模这些固有关联，从而改进预测模型中使用的项目表示。具体而言，与同一目标相连的前缀反映了相似的意图，而与同一前缀相连的目标则表示可用的选择。这使得图神经网络能够有效地捕捉前缀和项目之间的高层次关联，从而提高推荐准确性。我们在四个真实世界数据集上进行了广泛的实验，以证明PTSR相较于最先进的（SOTA）顺序推荐方法的优越性。PTSR的源代码可在https://github.com/TosakRin/PTSR获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PTSR:+Prefix-Target+Graph-based+Sequential+Recommendation)|0|
|[PACIFIC: Enhancing Sequential Recommendation via Preference-aware Causal Intervention and Counterfactual Data Augmentation](https://doi.org/10.1145/3627673.3679803)|Jinpeng Chen, Huachen Guan, Huan Li, Fan Zhang, Liwei Huang, Guangyao Pang, Xiongnan Jin|; Beijing Institute of Remote Sensing, Beijing, China; The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China|Sequential recommendation has been receiving increasing attention from researchers. Existing sequential recommendation models leverage deep learning models to capture sequential features. However, these methods ignore confounders in the recommendation process, which can lead the model to learn incorrect correlations and fail to accurately capture users' true preferences. Moreover, these methods rely on extensive interaction sequences, but sequential data often suffers from sparsity issues. To address these limitations, this paper proposes a P reference- a ware C ausal I ntervention and Counter f a c tual Data Augmentation ( Pacific ) framework to enhance sequential recommendation. Initially, we model the causal graph of sequential recommendation and categorize user preferences into global long-term preferences, local long-term preferences, and short-term preferences. Then, we introduce the front-door criterion to eliminate the interference of confounders and design different self-attention mechanisms to estimate the causal effects, aiming to capture users' true preferences. In addition, based on counterfactual thinking, we design a counterfactual data augmentation module to generate enriched sequences. Experimental results on four real-world datasets demonstrate the superiority of our proposed approach over state-of-the-art sequential recommendation methods.|序列推荐近年来引起了研究人员的广泛关注。现有的序列推荐模型利用深度学习模型来捕捉序列特征。然而，这些方法忽略了推荐过程中的混杂因素，这可能导致模型学习到错误的关联，无法准确捕捉用户的真实偏好。此外，这些方法依赖于大量的交互序列，但序列数据往往存在稀疏性问题。为了解决这些局限性，本文提出了一个P reference-a ware C ausal I ntervention and Counter f a c tual Data Augmentation（Pacific）框架，以增强序列推荐。首先，我们建模了序列推荐的因果图，并将用户偏好分为全局长期偏好、局部长期偏好和短期偏好。然后，我们引入了前门准则来消除混杂因素的干扰，并设计了不同的自注意力机制来估计因果效应，旨在捕捉用户的真实偏好。此外，基于反事实思维，我们设计了一个反事实数据增强模块，以生成丰富的序列。在四个真实世界数据集上的实验结果表明，我们提出的方法优于最先进的序列推荐方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PACIFIC:+Enhancing+Sequential+Recommendation+via+Preference-aware+Causal+Intervention+and+Counterfactual+Data+Augmentation)|0|
|[Context Matters: Enhancing Sequential Recommendation with Context-aware Diffusion-based Contrastive Learning](https://doi.org/10.1145/3627673.3679655)|Ziqiang Cui, Haolun Wu, Bowei He, Ji Cheng, Chen Ma|City University of Hong Kong, Hong Kong SAR, Hong Kong; McGill University, Montréal, Canada|Contrastive learning has been effectively utilized to enhance the training of sequential recommendation models by leveraging informative self-supervised signals. Most existing approaches generate augmented views of the same user sequence through random augmentation and subsequently maximize their agreement in the representation space. However, these methods often neglect the rationality of the augmented samples. Due to significant uncertainty, random augmentation can disrupt the semantic information and interest evolution patterns inherent in the original user sequences. Moreover, pulling semantically inconsistent sequences closer in the representation space can render the user sequence embeddings insensitive to variations in user preferences, which contradicts the primary objective of sequential recommendation. To address these limitations, we propose the Context-aware Diffusion-based Contrastive Learning for Sequential Recommendation, named CaDiRec. The core idea is to leverage context information to generate more reasonable augmented views. Specifically, CaDiRec employs a context-aware diffusion model to generate alternative items for the given positions within a sequence. These generated items are aligned with their respective context information and can effectively replace the corresponding original items, thereby generating a positive view of the original sequence. By considering two different augmentations of the same user sequence, we can construct a pair of positive samples for contrastive learning. To ensure representation cohesion, we train the entire framework in an end-to-end manner, with shared item embeddings between the diffusion model and the recommendation model. Extensive experiments on five benchmark datasets demonstrate the advantages of our proposed method over existing baselines.|对比学习已被有效利用，通过利用信息丰富的自监督信号来增强序列推荐模型的训练。大多数现有方法通过随机增强生成同一用户序列的增强视图，并在表示空间中最大化它们的共识。然而，这些方法往往忽略了增强样本的合理性。由于存在显著的不确定性，随机增强可能会破坏原始用户序列中固有的语义信息和兴趣演变模式。此外，在表示空间中将语义不一致的序列拉近会导致用户序列嵌入对用户偏好变化的敏感性降低，这与序列推荐的主要目标相悖。为了解决这些局限性，我们提出了基于上下文感知的扩散对比学习用于序列推荐，命名为CaDiRec。其核心思想是利用上下文信息生成更合理的增强视图。具体来说，CaDiRec采用上下文感知的扩散模型为序列中给定位置生成替代项。这些生成的项与其上下文信息对齐，并能有效替换相应的原始项，从而生成原始序列的正视图。通过考虑同一用户序列的两种不同增强，我们可以构建一对用于对比学习的正样本。为确保表示的一致性，我们以端到端的方式训练整个框架，并在扩散模型和推荐模型之间共享项嵌入。在五个基准数据集上的广泛实验证明了我们提出的方法相对于现有基线的优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Context+Matters:+Enhancing+Sequential+Recommendation+with+Context-aware+Diffusion-based+Contrastive+Learning)|0|
|[A General Strategy Graph Collaborative Filtering for Recommendation Unlearning](https://doi.org/10.1145/3627673.3679637)|Yongjing Hao, Fuzhen Zhuang, Deqing Wang, Guanfeng Liu, Victor S. Sheng, Pengpeng Zhao|Macquarie University, Sydney, Australia; Beihang University, Beijing, China; Texas Tech University, Lubbock, USA; Soochow University, Suzhou, Jiangsu, China|Recommender systems play a crucial role in delivering personalized services to users, but the increasing volume of user data raises significant concerns about privacy, security, and utility. However, existing machine unlearning methods cannot be directly applied to recommendation systems as they overlook the collaborative information shared across users and items. More recently, a method known as RecEraser was introduced, offering partitioning and aggregation-based approaches. Nevertheless, these approaches have limitations due to their inadequate handling of additional overhead costs. In this paper, we propose A General Strategy Graph Collaborative Filtering for Recommendation Unlearning (GSGCF-RU), which is a novel model-agnostic learnable delete operator that optimizes unlearning edge consistency and feature representation consistency. Specifically, the GSGCF-RU model utilizes unlearning edge consistency to eliminate the influence of deleted elements, followed by feature representation consistency to retain knowledge after deletion. Lastly, experimental results on three real-world public benchmarks demonstrate that GSGCF-RU not only achieves efficient recommendation unlearning but also surpasses state-of-the-art methods in terms of model utility. The source code can be found at https://github.com/YongjingHao/GSGCF-RU.|推荐系统在为用户提供个性化服务方面起着至关重要的作用，但随着用户数据量的增加，隐私、安全和效用问题日益突出。然而，现有的机器遗忘方法无法直接应用于推荐系统，因为它们忽略了用户和物品之间共享的协作信息。最近，一种名为RecEraser的方法被提出，采用了基于分区和聚合的策略。然而，这些方法由于未能充分处理额外的开销成本而存在局限性。本文提出了一种通用策略图协同过滤推荐遗忘（GSGCF-RU）方法，这是一种新颖的模型无关可学习删除操作符，优化了遗忘边缘一致性和特征表示一致性。具体而言，GSGCF-RU模型利用遗忘边缘一致性来消除已删除元素的影响，随后通过特征表示一致性来保留删除后的知识。最后，在三个真实世界的公共基准上的实验结果表明，GSGCF-RU不仅实现了高效的推荐遗忘，而且在模型效用方面超越了最先进的方法。源代码可在https://github.com/YongjingHao/GSGCF-RU找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+General+Strategy+Graph+Collaborative+Filtering+for+Recommendation+Unlearning)|0|
|[Interpretable Triplet Importance for Personalized Ranking](https://doi.org/10.1145/3627673.3679536)|Bowei He, Chen Ma||Personalized item ranking has been a crucial component contributing to the performance of recommender systems. As a representative approach, pairwise ranking directly optimizes the ranking with user implicit feedback by constructing (user, positive item, negative item) triplets. Several recent works have noticed that treating all triplets equally may hardly achieve the best effects. They assign different importance scores to negative items, user-item pairs, or triplets, respectively. However, almost all the generated importance scores are groundless and hard to interpret, thus far from trustworthy and transparent. To tackle these, we propose the Triplet Shapley – a Shapely value-based method to measure the triplet importance in an interpretable manner. Due to the huge number of triplets, we transform the original Shapley value calculation to the Monte Carlo (MC) approximation, where the guarantee for the approximation unbiasedness is also provided. To stabilize the MC approximation, we adopt a control covariates-based method. Finally, we utilize the triplet Shapley value to guide the resampling of important triplets for benefiting the model learning. Extensive experiments are conducted on six public datasets involving classical matrix factorization- and graph neural network-based recommendation models. Empirical results and subsequent analysis show that our model consistently outperforms the state-of-the-art methods.|个性化项目排序已成为提升推荐系统性能的关键组成部分。作为代表性方法，成对排序通过构建（用户，正项，负项）三元组，直接优化用户隐式反馈的排序。近期研究注意到，同等对待所有三元组可能难以达到最佳效果。因此，它们分别对负项、用户-项目对或三元组分配不同的重要性分数。然而，几乎所有生成的重要性分数都缺乏依据且难以解释，因此远非可靠和透明。为解决这些问题，我们提出了三元组Shapley——一种基于Shapley值的方法，以可解释的方式衡量三元组的重要性。由于三元组数量庞大，我们将原始Shapley值计算转换为蒙特卡洛（MC）近似，并提供了近似无偏性的保证。为稳定MC近似，我们采用了基于控制协变量的方法。最后，我们利用三元组Shapley值来指导重要三元组的重新采样，以促进模型学习。在涉及经典矩阵分解和图神经网络推荐模型的六个公开数据集上进行了广泛的实验。实证结果和后续分析表明，我们的模型始终优于最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interpretable+Triplet+Importance+for+Personalized+Ranking)|0|
|[CausalMed: Causality-Based Personalized Medication Recommendation Centered on Patient Health State](https://doi.org/10.1145/3627673.3679542)|Xiang Li, Shunpan Liang, Yu Lei, Chen Li, Yulei Hou, Dashun Zheng, Tengfei Ma|; Yanshan University School of Information Science and Engineering; Xinjiang University of Science & Technology School of Information Science and Engineering; Hunan University School of Computer Science and Engineering; Yanshan University School of Mechanical Engineering|Medication recommendation systems are developed to recommend suitable medications tailored to specific patient. Previous researches primarily focus on learning medication representations, which have yielded notable advances. However, these methods are limited to capturing personalized patient representations due to the following primary limitations: (i) unable to capture the differences in the impact of diseases/procedures on patients across various patient health states; (ii) fail to model the direct causal relationships between medications and specific health state of patients, resulting in an inability to determine which specific disease each medication is treating. To address these limitations, we propose CausalMed, a patient health state-centric model capable of enhancing the personalization of patient representations. Specifically, CausalMed first captures the causal relationship between diseases/procedures and medications through causal discovery and evaluates their causal effects. Building upon this, CausalMed focuses on analyzing the health state of patients, capturing the dynamic differences of diseases/procedures in different health states of patients, and transforming diseases/procedures into medications on direct causal relationships. Ultimately, CausalMed integrates information from longitudinal visits to recommend medication combinations. Extensive experiments on real-world datasets show that our method learns more personalized patient representation and outperforms state-of-the-art models in accuracy and safety.|药物推荐系统旨在为特定患者推荐合适的药物。以往的研究主要集中在学习药物表征上，取得了显著进展。然而，这些方法由于以下主要限制，无法捕捉个性化的患者表征：（i）无法捕捉疾病/程序对不同患者健康状态影响的差异；（ii）未能建模药物与患者特定健康状态之间的直接因果关系，导致无法确定每种药物具体治疗哪种疾病。为解决这些限制，我们提出了CausalMed，一种以患者健康状态为中心的模型，能够增强患者表征的个性化。具体来说，CausalMed首先通过因果发现捕捉疾病/程序与药物之间的因果关系，并评估其因果效应。在此基础上，CausalMed专注于分析患者的健康状态，捕捉疾病/程序在不同健康状态下的动态差异，并基于直接因果关系将疾病/程序转化为药物。最终，CausalMed整合了纵向就诊信息，推荐药物组合。在真实世界数据集上的广泛实验表明，我们的方法学习到了更个性化的患者表征，并在准确性和安全性方面优于最先进的模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CausalMed:+Causality-Based+Personalized+Medication+Recommendation+Centered+on+Patient+Health+State)|0|
|[PSNE: Efficient Spectral Sparsification Algorithms for Scaling Network Embedding](https://doi.org/10.1145/3627673.3679540)|Longlong Lin, Yunfeng Yu, Zihao Wang, Zeli Wang, Yuying Zhao, Jin Zhao, Tao Jia||Network embedding has numerous practical applications and has received extensive attention in graph learning, which aims at mapping vertices into a low-dimensional and continuous dense vector space by preserving the underlying structural properties of the graph. Many network embedding methods have been proposed, among which factorization of the Personalized PageRank (PPR for short) matrix has been empirically and theoretically well supported recently. However, several fundamental issues cannot be addressed. (1) Existing methods invoke a seminal Local Push subroutine to approximate \textit{a single} row or column of the PPR matrix. Thus, they have to execute $n$ ($n$ is the number of nodes) Local Push subroutines to obtain a provable PPR matrix, resulting in prohibitively high computational costs for large $n$. (2) The PPR matrix has limited power in capturing the structural similarity between vertices, leading to performance degradation. To overcome these dilemmas, we propose PSNE, an efficient spectral s\textbf{P}arsification method for \textbf{S}caling \textbf{N}etwork \textbf{E}mbedding, which can fast obtain the embedding vectors that retain strong structural similarities. Specifically, PSNE first designs a matrix polynomial sparser to accelerate the calculation of the PPR matrix, which has a theoretical guarantee in terms of the Frobenius norm. Subsequently, PSNE proposes a simple but effective multiple-perspective strategy to enhance further the representation power of the obtained approximate PPR matrix. Finally, PSNE applies a randomized singular value decomposition algorithm on the sparse and multiple-perspective PPR matrix to get the target embedding vectors. Experimental evaluation of real-world and synthetic datasets shows that our solutions are indeed more efficient, effective, and scalable compared with ten competitors.|网络嵌入在图学习领域具有众多实际应用，并受到了广泛关注。其目标是将顶点映射到一个低维且连续的密集向量空间，同时保留图的底层结构特性。已有多种网络嵌入方法被提出，其中个性化PageRank（简称PPR）矩阵的分解方法近期在实践和理论上都得到了良好的支持。然而，仍存在几个基本问题无法解决。（1）现有方法调用一个开创性的Local Push子程序来近似PPR矩阵的单行或单列。因此，它们需要执行n（n为节点数量）次Local Push子程序以获得可证明的PPR矩阵，这对于大规模n来说计算成本极高。（2）PPR矩阵在捕捉顶点间结构相似性方面能力有限，导致性能下降。为解决这些问题，我们提出了PSNE，这是一种高效的谱稀疏化方法，用于扩展网络嵌入，能够快速获取保留强结构相似性的嵌入向量。具体而言，PSNE首先设计了一种矩阵多项式稀疏化方法，以加速PPR矩阵的计算，该方法在Frobenius范数方面具有理论保证。随后，PSNE提出了一种简单但有效的多视角策略，进一步增强所获得的近似PPR矩阵的表示能力。最后，PSNE对稀疏且多视角的PPR矩阵应用随机奇异值分解算法，以获取目标嵌入向量。对真实世界和合成数据集的实验评估表明，与十个竞争对手相比，我们的解决方案确实更加高效、有效且可扩展。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PSNE:+Efficient+Spectral+Sparsification+Algorithms+for+Scaling+Network+Embedding)|0|
|[UniRec: A Dual Enhancement of Uniformity and Frequency in Sequential Recommendations](https://doi.org/10.1145/3627673.3679689)|Yang Liu, Yitong Wang, Chenyue Feng||Representation learning in sequential recommendation is critical for accurately modeling user interaction patterns and improving recommendation precision. However, existing approaches predominantly emphasize item-to-item transitions, often neglecting the time intervals between interactions, which are closely related to behavior pattern changes. Additionally, broader interaction attributes, such as item frequency, are frequently overlooked. We found that both sequences with more uniform time intervals and items with higher frequency yield better prediction performance. Conversely, non-uniform sequences exacerbate user interest drift and less-frequent items are difficult to model due to sparse sampling, presenting unique challenges inadequately addressed by current methods. In this paper, we propose UniRec, a novel bidirectional enhancement sequential recommendation method. UniRec leverages sequence uniformity and item frequency to enhance performance, particularly improving the representation of non-uniform sequences and less-frequent items. These two branches mutually reinforce each other, driving comprehensive performance optimization in complex sequential recommendation scenarios. Additionally, we present a multidimensional time module to further enhance adaptability. To the best of our knowledge, UniRec is the first method to utilize the characteristics of uniformity and frequency for feature augmentation. Comparing with eleven advanced models across four datasets, we demonstrate that UniRec outperforms SOTA models significantly. The code is available at https://github.com/Linxi000/UniRec.|在序列推荐中的表示学习对于准确建模用户交互模式和提升推荐精度至关重要。然而，现有方法主要侧重于项目间的转换，往往忽视了交互之间的时间间隔，这些时间间隔与行为模式的变化密切相关。此外，更广泛的交互属性，如项目频率，也经常被忽略。我们发现，时间间隔更均匀的序列和频率更高的项目能带来更好的预测性能。相反，时间间隔不均匀的序列会加剧用户兴趣的漂移，而采样稀疏的低频项目则难以建模，这为当前方法带来了独特的挑战。在本文中，我们提出了UniRec，一种新颖的双向增强序列推荐方法。UniRec利用序列均匀性和项目频率来提升性能，特别是在改进非均匀序列和低频项目的表示方面。这两个分支相互强化，推动在复杂序列推荐场景中的全面性能优化。此外，我们还引入了一个多维度时间模块，以进一步增强适应性。据我们所知，UniRec是首个利用均匀性和频率特性进行特征增强的方法。通过与四个数据集上的十一种先进模型进行比较，我们展示了UniRec显著优于现有的最先进模型。代码已公开在https://github.com/Linxi000/UniRec。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UniRec:+A+Dual+Enhancement+of+Uniformity+and+Frequency+in+Sequential+Recommendations)|0|
|[Collaborative Cross-modal Fusion with Large Language Model for Recommendation](https://doi.org/10.1145/3627673.3679596)|Zhongzhou Liu, Hao Zhang, Kuicai Dong, Yuan Fang||Despite the success of conventional collaborative filtering (CF) approaches for recommendation systems, they exhibit limitations in leveraging semantic knowledge within the textual attributes of users and items. Recent focus on the application of large language models for recommendation (LLM4Rec) has highlighted their capability for effective semantic knowledge capture. However, these methods often overlook the collaborative signals in user behaviors. Some simply instruct-tune a language model, while others directly inject the embeddings of a CF-based model, lacking a synergistic fusion of different modalities. To address these issues, we propose a framework of Collaborative Cross-modal Fusion with Large Language Models, termed CCF-LLM, for recommendation. In this framework, we translate the user-item interactions into a hybrid prompt to encode both semantic knowledge and collaborative signals, and then employ an attentive cross-modal fusion strategy to effectively fuse latent embeddings of both modalities. Extensive experiments demonstrate that CCF-LLM outperforms existing methods by effectively utilizing semantic and collaborative signals in the LLM4Rec context.|尽管传统的协同过滤（CF）方法在推荐系统中取得了成功，但它们在利用用户和项目文本属性中的语义知识方面存在局限性。最近，大语言模型在推荐系统中的应用（LLM4Rec）强调了其在有效捕捉语义知识方面的能力。然而，这些方法往往忽略了用户行为中的协同信号。有些方法仅仅是通过指令调整语言模型，而另一些方法则直接注入基于协同过滤模型的嵌入，缺乏不同模态之间的协同融合。为了解决这些问题，我们提出了一种名为CCF-LLM的大语言模型协同跨模态融合框架，用于推荐系统。在该框架中，我们将用户-项目交互转换为混合提示，以编码语义知识和协同信号，然后采用一种注意力跨模态融合策略，有效地融合两种模态的潜在嵌入。广泛的实验表明，CCF-LLM在LLM4Rec背景下，通过有效利用语义和协同信号，优于现有的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Collaborative+Cross-modal+Fusion+with+Large+Language+Model+for+Recommendation)|0|
|[Re-evaluating the Command-and-Control Paradigm in Conversational Search Interactions](https://doi.org/10.1145/3627673.3679588)|Johanne R. Trippas, Luke Gallagher, Joel Mackenzie|RMIT University, Melbourne, Australia; The University of Queensland, Brisbane, Australia; The University of Melbourne, Melbourne, Australia|Conversational assistants are becoming prevalent among the wider population due to their simplicity and increasing utility. However, the shortcomings of these tools are as renowned as their benefits. In this work, we present a "first look" at an extensive collection of conversational queries, aiming to identify limitations and improvement opportunities specifically related to information access (i.e., search interactions). We explore over 600,000 Google Assistant interactions from 173 unique users, examining usage trends and the resulting deficiencies and strengths of these assistants. We aim to provide a balanced assessment, highlighting the assistant's shortcomings in supporting users and delivering relevant information to user needs and areas where it demonstrates a reasonable response to user inputs. Our analysis shows that, although most users conduct information-seeking tasks, there is little evidence of complex information-seeking behaviour, with most interactions consisting of simple, imperative instructions. Finally, we find that conversational devices allow users to benefit from increased naturalistic interactions and the ability to apply acquired information in situ, a novel observation for conversational information seeking.|对话助手因其简便性和日益增加的实用性，在更广泛的人群中变得普及。然而，这些工具的缺点与其优点同样为人所知。在这项工作中，我们首次对大量对话查询进行了深入分析，旨在识别与信息访问（即搜索交互）相关的局限性和改进机会。我们研究了来自173名独特用户的超过600,000次Google Assistant交互，考察了使用趋势以及这些助手的缺陷和优势。我们的目标是提供一个平衡的评估，突出助手在支持用户和传递相关信息以满足用户需求方面的不足，以及在合理响应用户输入的领域。我们的分析显示，尽管大多数用户进行信息检索任务，但几乎没有证据表明存在复杂的信息检索行为，大多数交互由简单的、命令式的指令组成。最后，我们发现对话设备使用户能够受益于更加自然的交互，并能够在现场应用所获取的信息，这是对话信息检索的一个新颖观察。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Re-evaluating+the+Command-and-Control+Paradigm+in+Conversational+Search+Interactions)|0|
|[Collaborative Alignment for Recommendation](https://doi.org/10.1145/3627673.3679535)|Chen Wang, Liangwei Yang, Zhiwei Liu, Xiaolong Liu, Mingdai Yang, Yueqing Liang, Philip S. Yu|Salesforce AI Research, Palo Alto, CA, USA; University of Illinois Chicago, Chicago, IL, USA; University of Illinois Chicago, Chicgao, IL, USA; Illinois Institute of Technology, Chicago, IL, USA|Traditional recommender systems have primarily relied on identity representations (IDs) to model users and items. Recently, the integration of pre-trained language models (PLMs) has enhanced the capability to capture semantic descriptions of items. However, while PLMs excel in few-shot, zero-shot, and unified modeling scenarios, they often overlook the crucial signals from collaborative filtering (CF), resulting in suboptimal performance when sufficient training data is available. To effectively combine semantic representations with the CF signal and enhance recommender system performance in both warm and cold settings, two major challenges must be addressed: (1) bridging the gap between semantic and collaborative representation spaces, and (2) refining while preserving the integrity of semantic representations. In this paper, we introduce CARec, a novel model that adeptly integrates collaborative filtering signals with semantic representations, ensuring alignment within the semantic space while maintaining essential semantics. We present experimental results from four real-world datasets, which demonstrate significant improvements. By leveraging collaborative alignment, CARec also shows remarkable effectiveness in cold-start scenarios, achieving notable enhancements in recommendation performance. The code is available at https://github.com/ChenMetanoia/CARec **REMOVE 2nd URL**://github.com/ChenMetanoia/CARec.|传统的推荐系统主要依赖于身份表示（IDs）来建模用户和物品。近年来，预训练语言模型（PLMs）的引入增强了捕捉物品语义描述的能力。然而，尽管PLMs在少样本、零样本和统一建模场景中表现出色，但它们往往忽略了协同过滤（CF）中的关键信号，导致在有足够训练数据时性能不佳。为了有效结合语义表示与CF信号，并在冷启动和热启动场景中提升推荐系统性能，必须解决两个主要挑战：（1）弥合语义与协同表示空间之间的差距，（2）在保持语义表示完整性的同时进行优化。本文介绍了CARec，这是一种新型模型，能够巧妙地将协同过滤信号与语义表示相结合，确保在语义空间内的对齐同时保持基本语义。我们在四个真实世界数据集上进行了实验，结果显示了显著的改进。通过利用协同对齐，CARec在冷启动场景中也表现出显著的有效性，实现了推荐性能的显著提升。代码可在https://github.com/ChenMetanoia/CARec获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Collaborative+Alignment+for+Recommendation)|0|
|[Sparks of Surprise: Multi-objective Recommendations with Hierarchical Decision Transformers for Diversity, Novelty, and Serendipity](https://doi.org/10.1145/3627673.3679533)|Jie Wang, Alexandros Karatzoglou, Ioannis Arapakis, Xin Xin, Xuri Ge, Joemon M. Jose|ShanDong University, Qingdao, China; University of Glasgow, Glasgow, United Kingdom; Telefonica Research, BARCELONA, Spain; Amazon, BARCELONA, Spain|Personalized Session-based Recommendation (PSR) extends the traditional sequential recommendation models-which typically recommends the next item based on a recent active session-to leverage historical sessions of a user for short-term recommendations in current session. However, existing PSR methods face two limitations: (1) treating offline sessions uniformly as static data and relying on user embeddings to represent personalized information overlook the dynamic evolution of interests over time, which can change significantly as sessions progress in practical application. (2) focusing on accuracy, i.e., recommending items relevant to recent interactions, ignores the balance of multi-faceted requirements for user satisfaction, i.e., diversity, novelty, and serendipity. Therefore, we introduce Multi-objective PSR (MOPSR) task and propose Hierarchical Decision Transformers (HDT) framework, which models strictly sequential preference transitions of users across and within sessions to balance recommendation accuracy with the mentioned objectives. To address the first problem, Inter-session DT dynamically tracks the user's long-term preference across sessions by maintaining a goal state. This goal state serves as personalized information to collaboratively make recommendations with short-term state via the Intra-session DT. To tackle the second limitation, we propose inter-session and intra-session unexpected returns to trade off relevant recommendations and user preferences on diversity, novelty, and serendipity. The hierarchical returns help the recommender accurately identify signals of the user's expectations and changes in multi-objective preferences. To verify the effectiveness of our method on the MOPSR, we apply HDT to four state-of-the-art sequential recommendation models and conduct experiments on two publicly available datasets. Experimental results demonstrate that (1) HDT can widely generalize sequential models to solve the MOPSR task in scenarios with incrementally generated sessions, and (2) our method can balance multi-objectives by maintaining and even enhancing accuracy while effectively improving the diversity, novelty, and serendipity objectives.|个性化会话推荐（PSR）扩展了传统的序列推荐模型——这些模型通常根据最近的活动会话推荐下一个项目——以利用用户的历史会话为当前会话提供短期推荐。然而，现有的PSR方法存在两个局限性：（1）将离线会话统一视为静态数据，并依赖用户嵌入来表示个性化信息，忽略了兴趣随时间的动态演变，这在实际应用中随着会话的进展可能会发生显著变化。（2）专注于准确性，即推荐与最近交互相关的项目，忽略了用户满意度的多方面需求平衡，即多样性、新颖性和意外性。因此，我们引入了多目标PSR（MOPSR）任务，并提出了层次决策变换器（HDT）框架，该框架对用户在会话内外严格顺序的偏好转移进行建模，以平衡推荐准确性与上述目标。为解决第一个问题，会话间DT通过维护一个目标状态来动态追踪用户在会话间的长期偏好。该目标状态作为个性化信息，通过会话内DT与短期状态协作进行推荐。为应对第二个局限性，我们提出了会话间和会话内的意外回报，以权衡相关推荐与用户对多样性、新颖性和意外性的偏好。层次回报有助于推荐系统准确识别用户期望的信号和多目标偏好的变化。为验证我们的方法在MOPSR上的有效性，我们将HDT应用于四种最先进的序列推荐模型，并在两个公开数据集上进行实验。实验结果表明：（1）HDT能够广泛推广序列模型，以解决在会话增量生成场景下的MOPSR任务；（2）我们的方法能够在保持甚至提高准确性的同时，有效提升多样性、新颖性和意外性目标，从而平衡多目标。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sparks+of+Surprise:+Multi-objective+Recommendations+with+Hierarchical+Decision+Transformers+for+Diversity,+Novelty,+and+Serendipity)|0|
|[Content-Based Collaborative Generation for Recommender Systems](https://doi.org/10.1145/3627673.3679692)|Yidan Wang, Zhaochun Ren, Weiwei Sun, Jiyuan Yang, Zhixiang Liang, Xin Chen, Ruobing Xie, Su Yan, Xu Zhang, Pengjie Ren, Zhumin Chen, Xin Xin|Leiden University, Leiden, Netherlands; Tencent, Beijing, China; Shandong University, Qingdao, China; Zhejiang University, Hangzhou, China; WeChat, Tencent, Beijing, China|Generative models have emerged as a promising utility to enhance recommender systems. It is essential to model both item content and user-item collaborative interactions in a unified generative framework for better recommendation. Although some existing large language model (LLM)-based methods contribute to fusing content information and collaborative signals, they fundamentally rely on textual language generation, which is not fully aligned with the recommendation task. How to integrate content knowledge and collaborative interaction signals in a generative framework tailored for item recommendation is still an open research challenge. In this paper, we propose co ntent-based col la borative generation for rec ommender systems, namely ColaRec. ColaRec is a sequence-to-sequence framework which is tailored for directly generating the recommended item identifier. Precisely, the input sequence comprises data pertaining to the user's interacted items, and the output sequence represents the generative identifier (GID) for the suggested item. To model collaborative signals, the GIDs are constructed from a pretrained collaborative filtering model, and the user is represented as the content aggregation of interacted items. To this end, ColaRec captures both collaborative signals and content information in a unified framework. Then an item indexing task is proposed to conduct the alignment between the content-based semantic space and the interaction-based collaborative space. Besides, a contrastive loss is further introduced to ensure that items with similar collaborative GIDs have similar content representations. To verify the effectiveness of ColaRec, we conduct experiments on four benchmark datasets. Empirical results demonstrate the superior performance of ColaRec.|生成模型已成为增强推荐系统的有力工具。为了实现更好的推荐效果，在一个统一的生成框架中同时建模项目内容和用户-项目协同交互是至关重要的。尽管一些现有的基于大型语言模型（LLM）的方法有助于融合内容信息和协同信号，但它们本质上依赖于文本语言生成，这并未完全适应推荐任务的需求。如何在专为项目推荐设计的生成框架中整合内容知识和协同交互信号，仍然是一个开放的研究挑战。本文提出了一种基于内容的协同生成推荐系统方法，命名为ColaRec。ColaRec是一个序列到序列框架，专门用于直接生成推荐项目的标识符。具体而言，输入序列包含用户交互过的项目数据，输出序列表示推荐项目的生成标识符（GID）。为了建模协同信号，GID由预训练的协同过滤模型构建，用户则表示为交互项目的聚合内容。通过这种方式，ColaRec在一个统一的框架中捕捉了协同信号和内容信息。随后，提出了一项项目索引任务，以实现基于内容语义空间与基于交互的协同空间之间的对齐。此外，引入对比损失以确保具有相似协同GID的项目具有相似的内容表示。为了验证ColaRec的有效性，我们在四个基准数据集上进行了实验。实证结果表明，ColaRec具有优越的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Content-Based+Collaborative+Generation+for+Recommender+Systems)|0|
|[Multi-Task Recommendation with Task Information Decoupling](https://doi.org/10.1145/3627673.3679621)|Ruiran Yan, Rui Fan, Defu Lian||Multi-task learning (MTL) has become increasingly prevalent in e-commerce recommender systems. However, existing MTL methods, particularly those utilizing the Multi-gate Mixture-of-Experts (MMoE) architecture, face challenges due to their implicit routing mechanisms. These mechanisms can inadvertently lead to negative knowledge transfer, failing to resolve conflicts among tasks and resulting in gradient contradictions on shared parameters. Such issues undermine the generalization capability of MTL models across various tasks. To address these limitations, we introduce the Task Information Decoupling Model (TIDM), designed to alleviate negative transfer by decoupling task knowledge. TIDM incorporates two innovative modules following the expert layer: the Maximize Information Aggregation Module (MIA) and the Automatic Information Selection Module (AIS). The MIA module employs an auxiliary loss to filter out irrelevant task information and aggregates task-specific knowledge using a dissimilar self-attention network. Subsequently, the AIS module automatically selects the most pertinent task-specific information to facilitate task tower learning. Our experiments demonstrate that TIDM outperforms five contemporary MTL models across two datasets, showcasing its effectiveness in extracting task-specific information. This advancement is crucial for enhancing the performance of recommender systems in e-commerce and other complex domains.|多任务学习（MTL）在电子商务推荐系统中变得越来越普遍。然而，现有的MTL方法，特别是那些采用多门混合专家（MMoE）架构的方法，面临着由于其隐式路由机制带来的挑战。这些机制可能会无意中导致负知识转移，无法解决任务间的冲突，并在共享参数上产生梯度矛盾。这些问题削弱了MTL模型在各种任务中的泛化能力。为了解决这些局限性，我们引入了任务信息解耦模型（TIDM），旨在通过解耦任务知识来减轻负转移。TIDM在专家层之后包含了两个创新模块：最大化信息聚合模块（MIA）和自动信息选择模块（AIS）。MIA模块采用辅助损失来过滤无关任务信息，并使用不相似的自注意力网络聚合任务特定知识。随后，AIS模块自动选择最相关的任务特定信息，以促进任务塔的学习。我们的实验表明，TIDM在两个数据集上优于五种当代MTL模型，展示了其在提取任务特定信息方面的有效性。这一进展对于提升电子商务及其他复杂领域中推荐系统的性能至关重要。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Task+Recommendation+with+Task+Information+Decoupling)|0|
|[MMLRec: A Unified Multi-Task and Multi-Scenario Learning Benchmark for Recommendation](https://doi.org/10.1145/3627673.3679691)|Guanghu Yuan, Jieyu Yang, Shujie Li, Mingjie Zhong, Ang Li, Ke Ding, Yong He, Min Yang, Liang Zhang, Xiaolu Zhang, Linjian Mo|Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Ant Group, Hangzhou, China|In recent years, there has been a trend in the field of recommender systems towards multi-task modeling and multi-scenario modeling. The aim is to enhance the performance of various tasks and scenarios by jointly training on multiple tasks or scenarios to learn common patterns and features. Joint modeling of tasks and scenarios has also received widespread attention recently. However, despite the rich proposals of methods for Multi-Task Learning (MTL), Multi-Scenario Learning (MSL), and Multi-Task-Multi-Scenario Learning (MTMSL) in recent years, there still lacks a comprehensive benchmark to evaluate these methods. Previous studies often employed different datasets, data processing techniques, data partitioning strategies, and hyperparameter settings, making replication of existing research and fair comparison of experimental results challenging. To address this challenge, we introduce MMLRec, the first unified comprehensive benchmark for evaluating MTL, MSL and MTMSL, featuring consistent dataset processing and identical parameter settings. This benchmark implements a range of MTL, MSL, and MTMSL algorithms, and evaluates them on multiple commonly used recommender systems datasets. Through fair comparative experiments, we find that some structurally simplistic recommendation algorithms are underestimated, as they can achieve comparable results to more complex algorithms while maintaining lower complexity. Furthermore, our experimental analysis indicates that more complex methods exhibit better robustness when there are significant differences between tasks or scenarios. By providing a unified framework (MMLRec), our goal is to promote rapid evaluation and inspire innovative research in this continuously evolving field. We hope that our open-source benchmark can facilitate swift, equitable evaluations, while also fostering further breakthrough research in the domains of MTL, MSL, and MTMSL.|近年来，推荐系统领域出现了一种趋势，即向多任务建模和多场景建模发展。其目的是通过联合训练多个任务或场景，以学习共同的模型和特征，从而提升各个任务和场景的性能。任务和场景的联合建模也近来受到了广泛关注。然而，尽管近年来针对多任务学习（MTL）、多场景学习（MSL）以及多任务多场景学习（MTMSL）的方法提出了丰富的建议，但仍缺乏一个全面的基准来评估这些方法。以往的研究往往采用不同的数据集、数据处理技术、数据划分策略和超参数设置，这使得现有研究的复现和实验结果的公平比较变得困难。为了应对这一挑战，我们引入了MMLRec，这是首个用于评估MTL、MSL和MTMSL的统一综合性基准，具有一致的数据集处理和相同的参数设置。该基准实现了一系列MTL、MSL和MTMSL算法，并在多个常用的推荐系统数据集上对其进行了评估。通过公平的比较实验，我们发现一些结构上较为简单的推荐算法被低估了，因为它们能够在保持较低复杂度的同时，取得与更复杂算法相当的结果。此外，我们的实验分析表明，当任务或场景之间存在显著差异时，更复杂的方法表现出更好的鲁棒性。通过提供一个统一的框架（MMLRec），我们的目标是促进该领域的快速评估，并激发创新研究。我们希望我们的开源基准能够促进快速、公平的评估，同时也推动MTL、MSL和MTMSL领域的进一步突破性研究。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MMLRec:+A+Unified+Multi-Task+and+Multi-Scenario+Learning+Benchmark+for+Recommendation)|0|
|[Reformulating Conversational Recommender Systems as Tri-Phase Offline Policy Learning](https://doi.org/10.1145/3627673.3679792)|Gangyi Zhang, Chongming Gao, Hang Pan, Runzhe Teng, Ruizhe Li||Existing Conversational Recommender Systems (CRS) predominantly utilize user simulators for training and evaluating recommendation policies. These simulators often oversimplify the complexity of user interactions by focusing solely on static item attributes, neglecting the rich, evolving preferences that characterize real-world user behavior. This limitation frequently leads to models that perform well in simulated environments but falter in actual deployment. Addressing these challenges, this paper introduces the Tri-Phase Offline Policy Learning-based Conversational Recommender System (TPCRS), which significantly reduces dependency on real-time interactions and mitigates overfitting issues prevalent in traditional approaches. TPCRS integrates a model-based offline learning strategy with a controllable user simulation that dynamically aligns with both personalized and evolving user preferences. Through comprehensive experiments, TPCRS demonstrates enhanced robustness, adaptability, and accuracy in recommendations, outperforming traditional CRS models in diverse user scenarios. This approach not only provides a more realistic evaluation environment but also facilitates a deeper understanding of user behavior dynamics, thereby refining the recommendation process.|现有的对话推荐系统（CRS）主要依赖用户模拟器进行推荐策略的训练和评估。这些模拟器通常过于简化用户交互的复杂性，仅关注静态的物品属性，而忽略了现实世界中用户行为所具有的丰富且不断演变的偏好。这一局限性往往导致模型在模拟环境中表现良好，但在实际应用中却表现不佳。为了应对这些挑战，本文提出了基于三阶段离线策略学习的对话推荐系统（TPCRS），该系统显著减少了对实时交互的依赖，并缓解了传统方法中常见的过拟合问题。TPCRS结合了基于模型的离线学习策略与可控的用户模拟器，后者能够动态地与个性化且不断演变的用户偏好相匹配。通过全面的实验，TPCRS在推荐系统的鲁棒性、适应性和准确性方面表现出色，在多种用户场景下均优于传统的CRS模型。这种方法不仅提供了一个更为真实的评估环境，还促进了对于用户行为动态的深入理解，从而优化了推荐过程。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reformulating+Conversational+Recommender+Systems+as+Tri-Phase+Offline+Policy+Learning)|0|
|[HGCH: A Hyperbolic Graph Convolution Network Model for Heterogeneous Collaborative Graph Recommendation](https://doi.org/10.1145/3627673.3679701)|Lu Zhang, Ning Wu|Huazhong University of Science and Technology, Wuhan, China; Beihang University, Beijing, China|User-item interaction data in collaborative filtering and graph modeling tasks often exhibit power-law characteristics, which suggest the suitability of hyperbolic space modeling. Hyperbolic Graph Convolution Neural Networks (HGCNs) are a novel technique that leverages the advantages of GCN and hyperbolic space, and then achieves remarkable results. However, existing HGCN methods have several drawbacks: they fail to fully leverage hyperbolic space properties due to arbitrary embedding initialization and imprecise tangent space aggregation; they overlook auxiliary information that could enrich the collaborative graph; and their training convergence is slow due to margin ranking loss and random negative sampling. To overcome these challenges, we propose Hyperbolic Graph Collaborative for Heterogeneous Recommendation (HGCH), an enhanced HGCN-based model for collaborative filtering that integrates diverse side information into a heterogeneous collaborative graph and improves training convergence speed. HGCH first preserves the long-tailed nature of the graph by initializing node embeddings with power law prior; then it aggregates neighbors in hyperbolic space using the gyromidpoint method for accurate computation; finally, it fuses multiple embeddings from different hyperbolic spaces by the gate fusion with prior. Moreover, HGCH employs a hyperbolic user-specific negative sampling to speed up convergence. We evaluate HGCH on four real datasets, and the results show that HGCH achieves competitive results and outperforms leading baselines, including HGCNs. Extensive ablation studies further confirm its effectiveness.|在协同过滤和图建模任务中的用户-物品交互数据往往呈现出幂律分布特征，这表明双曲空间建模的适用性。双曲图卷积神经网络（HGCNs）是一种利用GCN和双曲空间优势的新技术，并取得了显著成果。然而，现有的HGCN方法存在几个缺点：由于任意嵌入初始化和不精确的切空间聚合，未能充分利用双曲空间特性；忽略了可以丰富协同图的辅助信息；由于边缘排序损失和随机负采样，训练收敛速度慢。为了克服这些挑战，我们提出了异构推荐的双曲图协同（HGCH），这是一个基于HGCN的协同过滤增强模型，它将多样化的辅助信息整合到异构协同图中，并提高了训练收敛速度。HGCH首先通过使用幂律先验初始化节点嵌入来保留图的长尾特性；然后使用双曲空间中的中点方法聚合邻居以进行精确计算；最后，通过带先验的门融合方法融合来自不同双曲空间的多个嵌入。此外，HGCH采用双曲用户特定的负采样来加速收敛。我们在四个真实数据集上评估了HGCH，结果显示HGCH取得了竞争性的结果，并优于包括HGCNs在内的领先基线。广泛的消融研究进一步证实了其有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HGCH:+A+Hyperbolic+Graph+Convolution+Network+Model+for+Heterogeneous+Collaborative+Graph+Recommendation)|0|
|[EMERGE: Enhancing Multimodal Electronic Health Records Predictive Modeling with Retrieval-Augmented Generation](https://doi.org/10.1145/3627673.3679582)|Yinghao Zhu, Changyu Ren, Zixiang Wang, Xiaochen Zheng, Shiyun Xie, Junlan Feng, Xi Zhu, Zhoujun Li, Liantao Ma, Chengwei Pan|China Mobile Research Institute, Beijing, China; Beihang University & Peking University, Beijing, China; Beihang University, Beijing, China; Peking University, Beijing, China; ETH Zürich, Zürich, Switzerland; Beihang University & Zhongguancun Laboratory, Beijing, China|The integration of multimodal Electronic Health Records (EHR) data has significantly advanced clinical predictive capabilities. Existing models, which utilize clinical notes and multivariate time-series EHR data, often fall short of incorporating the necessary medical context for accurate clinical tasks, while previous approaches with knowledge graphs (KGs) primarily focus on structured knowledge extraction. In response, we propose EMERGE, a Retrieval-Augmented Generation (RAG) driven framework to enhance multimodal EHR predictive modeling. We extract entities from both time-series data and clinical notes by prompting Large Language Models (LLMs) and align them with professional PrimeKG, ensuring consistency. In addition to triplet relationships, we incorporate entities' definitions and descriptions for richer semantics. The extracted knowledge is then used to generate task-relevant summaries of patients' health statuses. Finally, we fuse the summary with other modalities using an adaptive multimodal fusion network with cross-attention. Extensive experiments on the MIMIC-III and MIMIC-IV datasets' in-hospital mortality and 30-day readmission tasks demonstrate the superior performance of the EMERGE framework over baseline models. Comprehensive ablation studies and analysis highlight the efficacy of each designed module and robustness to data sparsity. EMERGE contributes to refining the utilization of multimodal EHR data in healthcare, bridging the gap with nuanced medical contexts essential for informed clinical predictions. We have publicly released the code at https://github.com/yhzhu99/EMERGE.|多模态电子健康记录（EHR）数据的整合显著提升了临床预测能力。现有的模型，尽管利用了临床笔记和多元时间序列EHR数据，但往往未能充分纳入必要的医学背景信息，以实现精准的临床任务；而先前基于知识图谱（KGs）的方法则主要集中在结构化知识的提取上。为此，我们提出了EMERGE，一个由检索增强生成（RAG）驱动框架，旨在提升多模态EHR预测建模。我们通过提示大型语言模型（LLMs）从时间序列数据和临床笔记中提取实体，并将其与专业的PrimeKG对齐，以确保一致性。除了三元组关系外，我们还纳入了实体的定义和描述，以丰富语义。提取的知识随后用于生成与任务相关的患者健康状况摘要。最后，我们利用具有交叉注意力的自适应多模态融合网络将该摘要与其他模态数据融合。在MIMIC-III和MIMIC-IV数据集上的住院死亡率和30天再入院任务的广泛实验表明，EMERGE框架优于基线模型。全面的消融研究和分析突显了每个设计模块的有效性及其对数据稀疏性的稳健性。EMERGE有助于优化多模态EHR数据在医疗领域的应用，弥合了与精细医学背景之间的差距，这对于精准的临床预测至关重要。我们已经公开发布了代码，地址为https://github.com/yhzhu99/EMERGE。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EMERGE:+Enhancing+Multimodal+Electronic+Health+Records+Predictive+Modeling+with+Retrieval-Augmented+Generation)|0|
|[Pairing Clustered Inverted Indexes with κ-NN Graphs for Fast Approximate Retrieval over Learned Sparse Representations](https://doi.org/10.1145/3627673.3679977)|Sebastian Bruch, Franco Maria Nardini, Cosimo Rulli, Rossano Venturini||Learned sparse representations form an effective and interpretable class of embeddings for text retrieval. While exact top-k retrieval over such embeddings faces efficiency challenges, a recent algorithm called Seismic has enabled remarkably fast, highly-accurate approximate retrieval. Seismic statically prunes inverted lists, organizes each list into geometrically-cohesive blocks, and augments each block with a summary vector. At query time, each inverted list associated with a query term is traversed one block at a time in an arbitrary order, with the inner product between the query and summaries determining if a block must be evaluated. When a block is deemed promising, its documents are fully evaluated with a forward index. Seismic is one to two orders of magnitude faster than state-of-the-art inverted index-based solutions and significantly outperforms the winning graph-based submissions to the BigANN 2023 Challenge. In this work, we speed up Seismic further by introducing two innovations to its query processing subroutine. First, we traverse blocks in order of importance, rather than arbitrarily. Second, we take the list of documents retrieved by Seismic and expand it to include the neighbors of each document using an offline k-regular nearest neighbor graph; the expanded list is then ranked to produce the final top-k set. Experiments on two public datasets show that our extension, named SeismicWave, can reach almost-exact accuracy levels and is up to 2.2x faster than Seismic.|学习到的稀疏表示为文本检索提供了一类有效且可解释的嵌入。尽管在这种嵌入上进行精确的top-k检索面临效率挑战，但最近的一种名为Seismic的算法实现了非常快速且高度精确的近似检索。Seismic静态地修剪倒排列表，将每个列表组织成几何上内聚的块，并为每个块增加一个摘要向量。在查询时，与查询词相关的每个倒排列表按任意顺序逐块遍历，通过查询与摘要之间的内积来确定是否需要评估该块。当一个块被认为有前景时，其文档会通过正向索引进行全面评估。Seismic比最先进的基于倒排索引的解决方案快一到两个数量级，并且在2023年BigANN挑战赛中显著优于基于图的获胜提交方案。在本研究中，我们通过在查询处理子程序中引入两项创新来进一步加速Seismic。首先，我们按重要性顺序遍历块，而不是任意顺序。其次，我们使用离线的k-正则最近邻图，将Seismic检索到的文档列表扩展为包含每个文档的邻居；然后对扩展后的列表进行排序以生成最终的top-k集合。在两个公开数据集上的实验表明，我们的扩展版本SeismicWave几乎可以达到完全精确的准确度，并且比Seismic快2.2倍。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pairing+Clustered+Inverted+Indexes+with+κ-NN+Graphs+for+Fast+Approximate+Retrieval+over+Learned+Sparse+Representations)|0|
|[PP4RNR: Popularity- and Position-Aware Contrastive Learning for Retrieval-Driven News Recommendation](https://doi.org/10.1145/3627673.3679979)|Wenwei Chen, Yewang Chen|College of Computer Science and Technology, Huaqiao University, Xiamen, China|Existing news recommendation systems often overlook the diversity of recommended content and exhibit popularity bias, resulting in suboptimal performance. To address this issue, this paper introduces a novel news recommendation approach, Popularity- and Position-Aware Contrastive Learning for Retrieval-Driven News Recommendation (PP4RNR). It consists of two modules: Entity-Level Retrieval Augmentation (ERA) and Popularity- and Position-Aware Contrastive Learning (PPCL). The ERA module utilizes both entities and titles to retrieve relevant news. Subsequently, retrieval-augmented news is fused with candidate news using our innovative cascaded attention network, leading to richer and more diverse news semantics. The PPCL module introduces perturbations in the news representation using a Gaussian perturbation vector based on the popularity and position information and then employs contrastive learning to regularize the representation space. Hence, this approach not only deepens the understanding of content diversity but also implicitly mitigates the popularity bias prevalent in current models. Rigorous testing on benchmark datasets demonstrates that our method significantly outperforms a range of state-of-the-art techniques.|现有的新闻推荐系统往往忽视推荐内容的多样性，并表现出流行度偏差，导致推荐效果不佳。为解决这一问题，本文提出了一种新颖的新闻推荐方法——基于检索的新闻推荐的流行度和位置感知对比学习（PP4RNR）。该方法包含两个模块：实体级检索增强（ERA）和流行度与位置感知的对比学习（PPCL）。ERA模块利用实体和标题来检索相关新闻。随后，通过我们创新的级联注意力网络将检索增强的新闻与候选新闻融合，从而丰富和多样化新闻语义。PPCL模块基于新闻的流行度和位置信息引入高斯扰动向量，对新闻表示进行扰动，然后利用对比学习来规范化表示空间。因此，这种方法不仅加深了对内容多样性的理解，还隐式地缓解了当前模型中普遍存在的流行度偏差。在基准数据集上的严格测试表明，我们的方法显著优于一系列最先进的技术。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PP4RNR:+Popularity-+and+Position-Aware+Contrastive+Learning+for+Retrieval-Driven+News+Recommendation)|0|
|[Exploiting Preferences in Loss Functions for Sequential Recommendation via Weak Transitivity](https://doi.org/10.1145/3627673.3679920)|Hyunsoo Chung, Jungtaek Kim, Hyungeun Jo, Hyungwon Choi||A choice of optimization objective is immensely pivotal in the design of a recommender system as it affects the general modeling process of a user's intent from previous interactions. Existing approaches mainly adhere to three categories of loss functions: pairwise, pointwise, and setwise loss functions. Despite their effectiveness, a critical and common drawback of such objectives is viewing the next observed item as a unique positive while considering all remaining items equally negative. Such a binary label assignment is generally limited to assuring a higher recommendation score of the positive item, neglecting potential structures induced by varying preferences between other unobserved items. To alleviate this issue, we propose a novel method that extends original objectives to explicitly leverage the different levels of preferences as relative orders between their scores. Finally, we demonstrate the superior performance of our method compared to baseline objectives.|优化目标的选择在推荐系统设计中极为关键，因为它影响从用户先前交互中对用户意图的一般建模过程。现有方法主要遵循三类损失函数：成对损失、逐点损失和集合损失函数。尽管这些方法有效，但它们的一个关键且普遍的缺点是将下一个观察到的项目视为唯一的正样本，而将所有剩余项目视为等同的负样本。这种二元标签分配通常仅限于确保正样本的推荐得分更高，而忽略了其他未观察项目之间因偏好差异所诱导的潜在结构。为解决这一问题，我们提出了一种新方法，将原始目标扩展为显式利用其得分之间的相对顺序来表示不同级别的偏好。最后，我们展示了我们的方法相对于基线目标的优越性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploiting+Preferences+in+Loss+Functions+for+Sequential+Recommendation+via+Weak+Transitivity)|0|
|[RECE: Reduced Cross-Entropy Loss for Large-Catalogue Sequential Recommenders](https://doi.org/10.1145/3627673.3679986)|Danil Gusak, Gleb Mezentsev, Ivan V. Oseledets, Evgeny Frolov||Scalability is a major challenge in modern recommender systems. In sequential recommendations, full Cross-Entropy (CE) loss achieves state-of-the-art recommendation quality but consumes excessive GPU memory with large item catalogs, limiting its practicality. Using a GPU-efficient locality-sensitive hashing-like algorithm for approximating large tensor of logits, this paper introduces a novel RECE (REduced Cross-Entropy) loss. RECE significantly reduces memory consumption while allowing one to enjoy the state-of-the-art performance of full CE loss. Experimental results on various datasets show that RECE cuts training peak memory usage by up to 12 times compared to existing methods while retaining or exceeding performance metrics of CE loss. The approach also opens up new possibilities for large-scale applications in other domains.|可扩展性是现代推荐系统面临的主要挑战之一。在序列推荐中，全交叉熵（CE）损失实现了最先进的推荐质量，但在处理大型物品目录时会消耗过多的GPU内存，限制了其实用性。本文介绍了一种新的RECE（缩减交叉熵）损失，通过使用GPU高效的类似局部敏感哈希算法来近似大的logits张量。RECE显著减少了内存消耗，同时允许用户享受到全CE损失的最先进性能。在各种数据集上的实验结果表明，与现有方法相比，RECE将训练峰值内存使用量减少了高达12倍，同时保持或超过了CE损失的性能指标。该方法还为其他领域的大规模应用开辟了新的可能性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RECE:+Reduced+Cross-Entropy+Loss+for+Large-Catalogue+Sequential+Recommenders)|0|
|[Enhanced Retrieval Effectiveness through Selective Query Generation](https://doi.org/10.1145/3627673.3679912)|Seyed Mohammad Hosseini, Negar Arabzadeh, Morteza Zihayat, Ebrahim Bagheri|University of Waterloo, Waterloo, Ontario, Canada; Toronto Metropolitan University, Toronto, Ontario, Canada|Prior research has demonstrated that reformulation of queries can significantly enhance retrieval effectiveness. Despite notable successes in neural-based query reformulation methods, identifying optimal reformulations that cover the same information need while enhancing retrieval effectiveness is still challenging. This paper introduces a two-step query reformulation framework for generating and selecting optimal target query variants which not only achieve higher retrieval performance but also preserve the original query's information need. Our comprehensive evaluations on the MS MARCO dataset and TREC Deep Learning tracks demonstrate substantial improvements over original query's performance.|先前研究表明，查询的重构可以显著提升检索效果。尽管基于神经网络的查询重构方法取得了显著成功，但识别出既能覆盖相同信息需求又能增强检索效果的最佳重构查询仍然具有挑战性。本文提出了一种两步走的查询重构框架，用于生成和选择最优的目标查询变体，这些变体不仅实现了更高的检索性能，还保留了原始查询的信息需求。我们在MS MARCO数据集和TREC深度学习赛道上的全面评估显示，相较于原始查询，性能有显著提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhanced+Retrieval+Effectiveness+through+Selective+Query+Generation)|0|
|[Post-Training Embedding Enhancement for Long-Tail Recommendation](https://doi.org/10.1145/3627673.3679978)|Geon Lee, Kyungho Kim, Kijung Shin|KAIST, Seoul, Republic of Korea|Item popularity in real-world data follows a long-tail distribution, where a few items attract most of the attention, while the majority receive much less. This disparity results in high-quality embeddings for popular (head) items, but lower-quality embeddings for unpopular (tail) items, leading to less accurate recommendations for the latter. Our observations confirm that embeddings of tail items often exhibit (1) magnitudes (i.e., norms) that are less reflective of actual popularity and (2) directions that are less effective in capturing user preferences, compared to those of head items. To address this issue, we propose EDGE, a post-training embedding enhancement method for long-tail recommendations. EDGE employs two key strategies: (1) refining embedding magnitudes to better reflect item popularity and (2) adjusting embedding directions by leveraging knowledge from head items. Importantly, EDGE is model-agnostic and can be applied to embeddings learned from any trained recommender system. Experimental results show that EDGE significantly improves tail item recommendation performance and overall system performance, achieving up to an improvement of 211.23% in NDCG@20 over the state-of-the-art method. Our code and datasets are available at https://github.com/geon0325/EDGE.|现实世界数据中的物品流行度遵循长尾分布，其中少数物品吸引了大部分关注，而大多数物品则受到较少的关注。这种差异导致流行（头部）物品的嵌入质量较高，但不流行（尾部）物品的嵌入质量较低，从而使得后者的推荐准确性降低。我们的观察证实了尾部物品的嵌入通常表现出（1）范数（即模）不太能反映实际流行度，以及（2）方向不太能有效捕捉用户偏好，相比头部物品的嵌入。为了解决这一问题，我们提出了EDGE，一种用于长尾推荐的后训练嵌入增强方法。EDGE采用两种关键策略：（1）优化嵌入范数以更好地反映物品流行度，以及（2）通过利用头部物品的知识来调整嵌入方向。重要的是，EDGE与模型无关，可以应用于从任何训练好的推荐系统中学习到的嵌入。实验结果表明，EDGE显著提升了尾部物品的推荐性能和整体系统性能，在NDCG@20指标上相比最先进的方法提升了高达211.23%。我们的代码和数据集可在https://github.com/geon0325/EDGE获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Post-Training+Embedding+Enhancement+for+Long-Tail+Recommendation)|0|
|[Scalable and Adaptive Spectral Embedding for Attributed Graph Clustering](https://doi.org/10.1145/3627673.3679992)|Yunhui Liu, Tieke He, Qing Wu, Tao Zheng, Jianhua Zhao||Attributed graph clustering, which aims to group the nodes of an attributed graph into disjoint clusters, has made promising advancements in recent years. However, most existing methods face challenges when applied to large graphs due to the expensive computational cost and high memory usage. In this paper, we introduce Scalable and Adaptive Spectral Embedding (SASE), a simple attributed graph clustering method devoid of parameter learning. SASE comprises three main components: node features smoothing via $k$-order simple graph convolution, scalable spectral clustering using random Fourier features, and adaptive order selection. With these designs, SASE not only effectively captures global cluster structures but also exhibits linear time and space complexity relative to the graph size. Empirical results demonstrate the superiority of SASE. For example, on the ArXiv dataset with 169K nodes and 1.17M edges, SASE achieves a 6.9\% improvement in ACC and a $5.87\times$ speedup compared to the runner-up, S3GC.|属性图聚类旨在将属性图的节点分组为不相交的集群，近年来取得了显著进展。然而，大多数现有方法在应用于大规模图时面临挑战，主要是因为计算成本高且内存使用量大。本文提出了一种名为可扩展自适应谱嵌入（SASE）的简单属性图聚类方法，该方法无需参数学习。SASE包含三个主要组件：通过$k$阶简单图卷积进行节点特征平滑、使用随机傅里叶特征的可扩展谱聚类以及自适应阶数选择。这些设计使得SASE不仅能够有效捕捉全局聚类结构，而且相对于图的大小表现出线性的时间和空间复杂度。实证结果表明，SASE具有优越性。例如，在拥有169K节点和1.17M边的ArXiv数据集上，SASE在ACC上比次优的S3GC提高了6.9%，并且速度提升了$5.87$倍。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+and+Adaptive+Spectral+Embedding+for+Attributed+Graph+Clustering)|0|
|[P-Rank+: A Scalable Efficient P-Rank Search Algorithm](https://doi.org/10.1145/3627673.3679976)|Maoyin Zhang, Weiren Yu|Warwick University, Coventry, United Kingdom; Nanjing University of Sci. & Tech., Jiangsu, China|P-Rank (Penetrating-Rank) is a charming measure of structural similarity between objects based on graph topology. It recursively follows the principle that "two objects are considered similar if (a) they are referenced by similar objects and (b) they reference similar objects''. The best-known algorithm for computing P-Rank employs two repeated Singular Value Decompositions (SVDs) coupled with the Woodbury matrix identity. However, this method does not scale well on billion-sized graphs. Worse yet, this algorithm only provides a linear approximation of the P-Rank model and cannot deliver accurate P-Rank values. In this paper, we propose P-Rank+, a fast and efficient algorithm for computing P-Rank similarities, which scales well on large graphs with billions of edges. P-Rank+ leverages dimensionality reduction techniques by performing only one SVD of the graph integrated with Hadamard products in the reduced subspace. Moreover, we provide provable error guarantees for P-Rank+ computation. Experiments on various datasets validate that P-Rank+ is 1--3 orders of magnitude faster than the best-known competitor while achieving excellent scalability on massive graphs.|P-Rank（渗透排序）是一种基于图拓扑结构的对象间结构相似性的迷人度量方法。它递归地遵循以下原则：“如果两个对象（a）被相似的对象引用，并且（b）引用相似的对象，则认为它们是相似的”。计算P-Rank最著名的算法采用了两个重复的奇异值分解（SVD），并与Woodbury矩阵恒等式相结合。然而，这种方法在处理十亿级大小的图时扩展性不佳。更糟糕的是，该算法仅提供了P-Rank模型的线性近似，无法提供精确的P-Rank值。在本文中，我们提出了P-Rank+，一种快速且高效的计算P-Rank相似性的算法，该算法在拥有数十亿条边的大型图上具有良好的扩展性。P-Rank+通过在降维子空间中执行一次图的SVD结合Hadamard积来利用降维技术。此外，我们为P-Rank+的计算提供了可证明的误差保证。在各种数据集上的实验验证了P-Rank+比已知的最优竞争对手快1到3个数量级，同时在大型图上表现出卓越的可扩展性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=P-Rank+:+A+Scalable+Efficient+P-Rank+Search+Algorithm)|0|
|[Learning the Dynamics in Sequential Recommendation by Exploiting Real-time Information](https://doi.org/10.1145/3627673.3679955)|Rujiao Zhang, Hao Zhang, Yucong Luo, Zhiding Liu, Mingyue Cheng, Qi Liu, Enhong Chen||Sequential recommender systems offer personalized suggestions by modeling users' interactions chronologically to capture dynamic user interest. Existing approaches typically fail to adequately describe the dynamics of the entire recommender system, including shifts in both user interest and item availability. To address this, we propose a simple yet effective framework with three key perspectives, tailored to the dynamics of recommender system by fully exploiting the time information. Firstly, we propose a dynamic candidate set construction approach to prevent the model from learning future interactions. Secondly, assuming that user behaviors remain consistent over short terms but may evolve over long terms, we employ a interval-weighted optimization target to model the correlation of users' historical interactions. Finally, we introduce a specialized time-aware attention module to enhance recommendations within specific temporal contexts. Extensive experiments demonstrate the effectiveness and generalizability of our framework. We make our codes publicly available.|顺序推荐系统通过按时间顺序建模用户的交互来捕捉动态用户兴趣，从而提供个性化建议。现有的方法通常未能充分描述整个推荐系统的动态变化，包括用户兴趣和物品可用性的变化。为了解决这一问题，我们提出了一个简单而有效的框架，该框架从三个关键角度出发，充分利用时间信息来适应推荐系统的动态变化。首先，我们提出了一种动态候选集构建方法，以防止模型学习未来的交互。其次，假设用户行为在短期内保持一致，但在长期内可能发生变化，我们采用了一种区间加权优化目标来建模用户历史交互的相关性。最后，我们引入了一个专门的时间感知注意力模块，以增强在特定时间上下文中的推荐效果。大量实验证明了我们框架的有效性和普适性。我们将代码公开发布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+the+Dynamics+in+Sequential+Recommendation+by+Exploiting+Real-time+Information)|0|
|[VIER: Visual Imagination Enhanced Retrieval in Sponsored Search](https://doi.org/10.1145/3627673.3680005)|Yadong Zhang, Yuqing Song, Siyu Lu, Qiang Liu, Xingxing Wang|Meituan, Beijing, China|Embedding-based Retrieval (EBR) has been a fundamental component in sponsored-search systems, which retrieves high-quality products for the user's search query by encoding the information of the query, user and product into dense embeddings. However, due to the characteristic of location-based service, the user input queries suffer from two extremes: overly brief queries with vague intentions and lengthy queries with substantial noise, both of which make it challenging to discern the exact user search intent. In fact, the e-consumers typically have a mental imagery of the product they intend to search for, reflecting their specific purchasing intentions. In this paper, we propose a Visual Imagination Enhanced Retrieval model (VIER) to explore the implicit imagery of users. Specifically, we design a visual imagination network to reconstruct the imagery embeddings that capture both coarse-grained query commonalities and fine-grained user personalities. These pseudo-image representations are integrated with the query and user behavior to enhance the understanding of user search intentions for improved retrieval. According to online A/B tests on Meituan sponsored-search system, our method significantly outperforms baselines in terms of revenue, clicks and click-through rate.|基于嵌入的检索（EBR）已成为赞助搜索系统中的基础组件，通过将查询、用户和产品的信息编码为密集嵌入，检索出高质量的产品以满足用户的搜索需求。然而，由于基于位置服务的特性，用户输入的查询呈现出两种极端：过于简短且意图模糊的查询，以及冗长但包含大量噪音的查询，这两者都使得准确识别用户的搜索意图变得困难。实际上，电子消费者通常对其意图搜索的产品有一个心理意象，这反映了他们特定的购买意向。在本文中，我们提出了一种视觉想象力增强的检索模型（VIER），以探索用户的隐含意象。具体而言，我们设计了一个视觉想象力网络，用于重建捕捉粗粒度查询共性和细粒度用户个性的意象嵌入。这些伪图像表示与查询和用户行为相结合，以增强对用户搜索意图的理解，从而改进检索效果。根据在美团赞助搜索系统上的在线A/B测试结果，我们的方法在收入、点击量和点击率方面显著优于基线方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=VIER:+Visual+Imagination+Enhanced+Retrieval+in+Sponsored+Search)|0|
|[Transforming Location Retrieval at Airbnb: A Journey from Heuristics to Reinforcement Learning](https://doi.org/10.1145/3627673.3680089)|Dillon Davis, Huiji Gao, Thomas Legrand, Malay Haldar, Alex Deng, Han Zhao, Liwei He, Sanjeev Katariya||The Airbnb search system grapples with many unique challenges as it continues to evolve. We oversee a marketplace that is nuanced by geography, diversity of homes, and guests with a variety of preferences. Crafting an efficient search system that can accommodate diverse guest needs, while showcasing relevant homes lies at the heart of Airbnb's success. Airbnb search has many challenges that parallel other recommendation and search systems but it has a unique information retrieval problem, upstream of ranking, called location retrieval. It requires defining a topological map area that is relevant to the searched query for homes listing retrieval. The purpose of this paper is to demonstrate the methodology, challenges, and impact of building a machine learning based location retrieval product from the ground up. Despite the lack of suitable, prevalent machine learning based approaches, we tackle cold start, generalization, differentiation and algorithmic bias. We detail the efficacy of heuristics, statistics, machine learning, and reinforcement learning approaches to solve these challenges, particularly for systems that are often unexplored by current literature.|随着不断发展，Airbnb搜索系统面临着许多独特的挑战。我们管理着一个由地理位置、房屋多样性和具有各种偏好的客人所构成的复杂市场。打造一个能够满足不同客人需求的高效搜索系统，同时展示相关房屋，是Airbnb成功的核心。Airbnb搜索系统面临许多与其他推荐和搜索系统相似的挑战，但它有一个独特的信息检索问题，即在排序之前的位置检索。这需要定义一个与搜索查询相关的拓扑地图区域，以便进行房屋列表检索。本文旨在展示从头构建一个基于机器学习的位置检索产品的过程、挑战及其影响。尽管缺乏合适且普遍的基于机器学习的方法，我们解决了冷启动、泛化、差异化和算法偏差等问题。我们详细介绍了启发式、统计学、机器学习和强化学习方法在这些挑战中的有效性，特别是针对当前文献中较少探索的系统。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Transforming+Location+Retrieval+at+Airbnb:+A+Journey+from+Heuristics+to+Reinforcement+Learning)|0|
|[Pareto-based Multi-Objective Recommender System with Forgetting Curve](https://doi.org/10.1145/3627673.3680080)|Jipeng Jin, Zhaoxiang Zhang, Zhiheng Li, Xiaofeng Gao, Xiongwen Yang, Lei Xiao, Jie Jiang|; Shanghai Jiao Tong University|Recommender systems with cascading architecture play an increasinglysignificant role in online recommendation platforms, where the approach todealing with negative feedback is a vital issue. For instance, in short videoplatforms, users tend to quickly slip away from candidates that they feelaversive, and recommender systems are expected to receive these explicitnegative feedbacks and make adjustments to avoid these recommendations.Considering recency effect in memories, we propose a forgetting model based onEbbinghaus Forgetting Curve to cope with negative feedback. In addition, weintroduce a Pareto optimization solver to guarantee a better trade-off betweenrecency and model performance. In conclusion, we propose Pareto-basedMulti-Objective Recommender System with forgetting curve (PMORS), which can beapplied to any multi-objective recommendation and show sufficiently superioritywhen facing explicit negative feedback. We have conducted evaluations of PMORSand achieved favorable outcomes in short-video scenarios on both public datasetand industrial dataset. After being deployed on an online short video platformnamed WeChat Channels in May, 2023, PMORS has not only demonstrated promisingresults for both consistency and recency but also achieved an improvement of upto +1.45|具有级联架构的推荐系统在在线推荐平台中扮演着越来越重要的角色，其中如何处理负面反馈是一个关键问题。例如，在短视频平台中，用户往往会对感到不喜欢的候选内容迅速失去兴趣，推荐系统需要接收这些明确的负面反馈并进行调整，以避免此类推荐。考虑到记忆中的时效性效应，我们提出了一种基于艾宾浩斯遗忘曲线的遗忘模型来处理负面反馈。此外，我们引入了一种帕累托优化求解器，以确保在时效性和模型性能之间取得更好的平衡。综上所述，我们提出了基于帕累托的多目标推荐系统（PMORS），该系统可以应用于任何多目标推荐，并且在面对明确的负面反馈时表现出足够的优越性。我们对PMORS进行了评估，并在公共数据集和工业数据集的短视频场景中取得了良好的结果。自2023年5月在名为微信视频号的在线短视频平台上部署以来，PMORS不仅在一致性和时效性方面展示了有前景的结果，还实现了高达+1.45的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pareto-based+Multi-Objective+Recommender+System+with+Forgetting+Curve)|0|
|[Ads Supply Personalization via Doubly Robust Learning](https://doi.org/10.1145/3627673.3680035)|Wei Shi, Chen Fu, Qi Xu, Sanjian Chen, Jizhe Zhang, Qinqin Zhu, Zhigang Hua, Shuang Yang|Meta Platforms, Inc., Menlo Park, CA, USA; Meta Platforms, Inc., Sunnyvale, CA, USA|Ads supply personalization aims to balance the revenue and user engagement, two long-term objectives in social media ads, by tailoring the ad quantity and density. In the industry-scale system, the challenge for ads supply lies in modeling the counterfactual effects of a conservative supply treatment (e.g., a small density change) over an extended duration. In this paper, we present a streamlined framework for personalized ad supply. This framework optimally utilizes information from data collection policies through the doubly robust learning. Consequently, it significantly improves the accuracy of long-term treatment effect estimates. Additionally, its low-complexity design not only results in computational cost savings compared to existing methods, but also makes it scalable for billion-scale applications. Through both offline experiments and online production tests, the framework consistently demonstrated significant improvements in top-line business metrics over months. The framework has been fully deployed to live traffic in one of the world's largest social media platforms.|广告供应个性化旨在通过调整广告数量和密度，平衡社交媒体广告中的两个长期目标：收入和用户参与度。在行业规模的系统中，广告供应的挑战在于对保守供应处理（例如，小幅密度变化）在长时间内的反事实效应进行建模。本文提出了一种简化的个性化广告供应框架。该框架通过双重稳健学习最优地利用数据收集策略中的信息，从而显著提高了长期处理效应估计的准确性。此外，其低复杂度的设计不仅在计算成本上优于现有方法，还使其适用于亿级规模的应用。通过离线实验和在线生产测试，该框架在数月内持续显示出对业务关键指标的显著改进。该框架已全面部署到全球最大社交媒体平台之一的实时流量中。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ads+Supply+Personalization+via+Doubly+Robust+Learning)|0|
|[DivNet: Diversity-Aware Self-Correcting Sequential Recommendation Networks](https://doi.org/10.1145/3627673.3680059)|Shuai Xiao, Zaifan Jiang|Alibaba Group, Beijing, China; Alibaba Group, Shanghai, China|As the last stage of a typical recommendation system, collective recommendation aims to give the final touches to the recommended items and their layout so as to optimize overall objectives such as diversity and whole-page relevance. In practice, however, the interaction dynamics among the recommended items, their visual appearances and meta-data such as specifications are often too complex to be captured by experts' heuristics or simple models. To address this issue, we propose a div ersity-aware self-correcting sequential recommendation net works (DivNet) that is able to estimate utility by capturing the complex interactions among sequential items and diversify recommendations simultaneously. Experiments on both offline and online settings demonstrate that DivNet can achieve better results compared to baselines with or without collective recommendations.|在典型的推荐系统的最后一个阶段，集体推荐旨在对推荐项目及其布局进行最后的调整，以优化多样性和整个页面的相关性等总体目标。然而，在实践中，推荐项目之间的交互动态、它们的视觉外观和规格等元数据往往过于复杂，难以被专家的启发式方法或简单的模型捕捉。为了解决这个问题，我们提出了一种多样性感知的自校正序列推荐网络（DivNet），它能够通过捕捉序列项目之间的复杂交互来估计效用，并同时实现推荐项目的多样化。在离线和在线设置中的实验表明，与有无集体推荐的基线相比，DivNet能够取得更好的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DivNet:+Diversity-Aware+Self-Correcting+Sequential+Recommendation+Networks)|0|
|[Enhancing Playback Performance in Video Recommender Systems with an On-Device Gating and Ranking Framework](https://doi.org/10.1145/3627673.3680076)|Yunfei Yang, Zhenghao Qi, Honghuan Wu, Qi Song, Tieyao Zhang, Hao Li, Yimin Tu, Kaiqiao Zhan, Ben Wang||Video recommender systems (RSs) have gained increasing attention in recent years. Existing mainstream RSs focus on optimizing the matching function between users and items. However, we noticed that users frequently encounter playback issues such as slow loading or stuttering while browsing the videos, especially in weak network conditions, which will lead to a subpar browsing experience, and may cause users to leave, even when the video content and recommendations are superior. It is quite a serious issue, yet easily overlooked. To tackle this issue, we propose an on-device Gating and Ranking Framework (GRF) that cooperates with server-side RS. Specifically, we utilize a gate model to identify videos that may have playback issues in real-time, and then we employ a ranking model to select the optimal result from a locally-cached pool to replace the stuttering videos. Our solution has been fully deployed on Kwai, a large-scale short video platform with hundreds of millions of users globally. Moreover, it significantly enhances video playback performance and improves overall user experience and retention rates.|视频推荐系统（RSs）近年来受到了越来越多的关注。现有的主流RSs专注于优化用户与项目之间的匹配函数。然而，我们注意到用户在浏览视频时经常遇到播放问题，如加载缓慢或卡顿，尤其是在网络条件较差的情况下，这将导致浏览体验不佳，甚至可能使用户流失，即使视频内容和推荐本身是优质的。这是一个相当严重但容易被忽视的问题。为了解决这个问题，我们提出了一个设备端门控与排序框架（GRF），该框架与服务器端RS协同工作。具体来说，我们利用门控模型实时识别可能存在播放问题的视频，然后使用排序模型从本地缓存池中选择最佳结果来替换卡顿的视频。我们的解决方案已在快手这一全球拥有数亿用户的大型短视频平台上全面部署。此外，它显著提升了视频播放性能，并改善了整体用户体验和留存率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Playback+Performance+in+Video+Recommender+Systems+with+an+On-Device+Gating+and+Ranking+Framework)|0|
|[An Enhanced Batch Query Architecture in Real-time Recommendation](https://doi.org/10.1145/3627673.3680034)|Qiang Zhang, Zhipeng Teng, Disheng Wu, Jiayin Wang||In industrial recommendation systems on websites and apps, it is essential to recall and predict top-n results relevant to user interests from a content pool of billions within milliseconds. To cope with continuous data growth and improve real-time recommendation performance, we have designed and implemented a high-performance batch query architecture for real-time recommendation systems. Our contributions include optimizing hash structures with a cacheline-aware probing method to enhance coalesced hashing, as well as the implementation of a hybrid storage key-value service built upon it. Our experiments indicate this approach significantly surpasses conventional hash tables in batch query throughput, achieving up to 90 of random memory access when incorporating parallel optimization. The support for NVMe, integrating two-tier storage for hot and cold data, notably reduces resource consumption. Additionally, the system facilitates dynamic updates, automated sharding of attributes and feature embedding tables, and introduces innovative protocols for consistency in batch queries, thereby enhancing the effectiveness of real-time incremental learning updates. This architecture has been deployed and in use in the bilibili recommendation system for over a year, a video content community with hundreds of millions of users, supporting 10x increase in model computation with minimal resource growth, improving outcomes while preserving the system's real-time performance.|在网站和应用的工业推荐系统中，从数十亿内容库中毫秒级召回并预测与用户兴趣相关的前N个结果至关重要。为应对持续的数据增长并提升实时推荐性能，我们设计并实现了一种高性能的实时推荐系统批量查询架构。我们的贡献包括通过缓存行感知的探测方法优化哈希结构以增强聚合哈希，以及基于此构建的混合存储键值服务。实验表明，该方法在批量查询吞吐量方面显著超越传统哈希表，结合并行优化时随机内存访问可达90%。对NVMe的支持，结合冷热数据的两级存储，显著降低了资源消耗。此外，系统支持动态更新、属性和特征嵌入表的自动分片，并引入了创新的批量查询一致性协议，从而提升了实时增量学习更新的效果。该架构已在拥有数亿用户的视频内容社区bilibili推荐系统中部署并使用超过一年，支持模型计算量10倍增长的同时资源增长最小化，既提升了推荐效果又保持了系统的实时性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Enhanced+Batch+Query+Architecture+in+Real-time+Recommendation)|0|
|[Voting with Generative AI for German Compound Splitting in E-commerce Search](https://doi.org/10.1145/3627673.3679074)|Ümit Yilmaz, Kilian Merkelbach, Daniel Stein, Hasan Oezkan|eBay Inc., Aachen, Germany; eBay Inc., Dreilinden, Germany|Compound words are a grammatical structure that allows forming new words by composing existing words. For e-commerce search in German, it is essential to split these compounds into meaningful parts because item titles often use the joint form while search queries are often split. We propose a method for German compound splitting leveraging a large language model (LLM) with a voting mechanism and a hyperparameter search for automatically optimizing prompt and parameter combinations. Our evaluation of the proposed method on human-created gold standard data for e-commerce shows that it outperforms existing methods for compound splitting in this domain.|复合词是一种语法结构，通过组合现有词汇来形成新词。在德语的电子商务搜索中，将这些复合词拆分为有意义的组成部分至关重要，因为商品标题通常使用联合形式，而搜索查询则通常是拆分后的形式。我们提出了一种利用大型语言模型（LLM）进行德语复合词拆分的方法，该方法结合了投票机制和超参数搜索，以自动优化提示和参数组合。我们对所提出的方法在人工创建的电子商务金标准数据上的评估显示，它在复合词拆分方面优于现有的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Voting+with+Generative+AI+for+German+Compound+Splitting+in+E-commerce+Search)|0|
|[AI Agent for Information Retrieval: Generating and Ranking](https://doi.org/10.1145/3627673.3680120)|Yongfeng Zhang, Zhiwei Liu, Qingsong Wen, Linsey Pang, Wei Liu, Philip S. Yu|Salesforce, San Francisco, CA, USA; Salesforce AI Research, Palo Alto, CA, USA; University of Illinois at Chicago, Chicago, IL, USA; University of Technology Sydney, Sydney, NSW, Australia; Squirrel Ai Learning, Seattle, WA, USA; Rutgers University, New Brunswick, NJ, USA|The field of information retrieval has significantly transformed with the integration of AI technologies. AI agents, especially those leveraging LLMs and vast computational power, have revolutionized information retrieval, processing, and presentation. LLM agents, with advanced memory, reasoning, and planning capabilities, can perform complex tasks, engage in coherent conversations, and provide personalized responses. Despite these advancements, challenges such as ensuring relevance and accuracy, mitigating biases, providing real-time responses, and maintaining data security remain. This workshop aims to explore these challenges, share innovative solutions, and discuss future directions. It will provide a platform to bring together researchers, practitioners to discuss the latest theoretical advancements and practical implementations of AI agents in information retrieval. Topics include AI in search, recommendation, and personalization systems. By gathering a diverse group of experts, the workshop seeks to deepen the understanding of AI agents in information retrieval, advance the field, and enhance its societal impact. Participants will gain insights into cutting-edge research, emerging trends, and foster knowledge exchange and collaboration within the community.|信息检索领域随着AI技术的融合发生了显著变革。AI代理，尤其是那些利用大型语言模型（LLMs）和强大计算能力的代理，已经彻底改变了信息检索、处理和呈现的方式。具备先进记忆、推理和规划能力的LLM代理能够执行复杂任务、进行连贯对话并提供个性化响应。尽管取得了这些进展，但仍面临确保相关性和准确性、减轻偏见、提供实时响应以及维护数据安全等挑战。本次研讨会旨在探讨这些挑战，分享创新解决方案，并讨论未来的发展方向。研讨会将提供一个平台，让研究人员和从业者能够讨论AI代理在信息检索中最新的理论进展和实际应用。主题包括AI在搜索、推荐和个人化系统中的应用。通过汇集多元化的专家群体，研讨会旨在深化对信息检索中AI代理的理解，推动该领域的发展，并增强其社会影响力。参与者将获得关于尖端研究、新兴趋势的见解，并促进社区内的知识交流与合作。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AI+Agent+for+Information+Retrieval:+Generating+and+Ranking)|0|
|[UniEmbedding: Learning Universal Multi-Modal Multi-Domain Item Embeddings via User-View Contrastive Learning](https://doi.org/10.1145/3627673.3680098)|Boqi Dai, Zhaocheng Du, Jieming Zhu, Jintao Xu, Deqing Zou, Quanyu Dai, Zhenhua Dong, Rui Zhang, HaiTao Zheng|Huazhong University of Science and Technology, Shenzhen, China; Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Huawei Noah's Ark Lab, Shenzhen, China; Shenzhen International Graduate School, Tsinghua University & Pengcheng Laboratory, Shenzhen, China|Learning high-quality item embeddings is crucial for recommendation tasks such as matching and ranking. However, existing methods often rely on ID-based item embeddings learned end-to-end with downstream recommendation models, which may suffer from overfitting and limited generalizability. In this paper, we aim to learn universal item embeddings (dubbed UniEmbedding) that capture multi-modal semantics, generalize across multiple domains, and serve different downstream tasks. To achieve this goal, we introduce the UniEmbedding pretraining framework, which includes three modules: a domain-aware multi-modal adapter, a user-view projection module, and contrastive learning objectives across domains. Compared to naive ID embeddings, UniEmbedding provides rich semantic information that generalizes more effectively across domains. Unlike multi-modal embeddings directly extracted from off-the-shelf pretrained models, UniEmbedding achieves better alignment between content semantics and behaviors. We evaluated UniEmbedding on both public and industrial datasets, demonstrating its effectiveness in matching and ranking tasks. Furthermore, UniEmbedding has been deployed in multiple recommendation applications at Huawei, resulting in significant gains in user engagement metrics.|学习高质量的物品嵌入对于匹配和排序等推荐任务至关重要。然而，现有方法通常依赖于基于ID的物品嵌入，这些嵌入与下游推荐模型端到端学习，可能会遭受过拟合和泛化能力有限的问题。本文旨在学习一种通用的物品嵌入（称为UniEmbedding），这种嵌入能够捕捉多模态语义，跨多个领域泛化，并服务于不同的下游任务。为实现这一目标，我们引入了UniEmbedding预训练框架，该框架包括三个模块：领域感知的多模态适配器、用户视角投影模块以及跨领域的对比学习目标。与简单的ID嵌入相比，UniEmbedding提供了更丰富的语义信息，能更有效地跨领域泛化。与直接从现成的预训练模型中提取的多模态嵌入不同，UniEmbedding在内容语义和行为之间实现了更好的对齐。我们在公共和工业数据集上评估了UniEmbedding，证明了其在匹配和排序任务中的有效性。此外，UniEmbedding已在华为的多个推荐应用中部署，显著提升了用户参与度指标。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UniEmbedding:+Learning+Universal+Multi-Modal+Multi-Domain+Item+Embeddings+via+User-View+Contrastive+Learning)|0|
|[Modeling User Intent Beyond Trigger: Incorporating Uncertainty for Trigger-Induced Recommendation](https://doi.org/10.1145/3627673.3680065)|Jianxing Ma, Zhibo Xiao, Luwei Yang, Hansheng Xue, Xuanzhou Liu, Wen Jiang, Wei Ning, Guannan Zhang||To cater to users' desire for an immersive browsing experience, numerous e-commerce platforms provide various recommendation scenarios, with a focus on Trigger-Induced Recommendation (TIR) tasks. However, the majority of current TIR methods heavily rely on the trigger item to understand user intent, lacking a higher-level exploration and exploitation of user intent (e.g., popular items and complementary items), which may result in an overly convergent understanding of users' short-term intent and can be detrimental to users' long-term purchasing experiences. Moreover, users' short-term intent shows uncertainty and is affected by various factors such as browsing context and historical behaviors, which poses challenges to user intent modeling. To address these challenges, we propose a novel model called Deep Uncertainty Intent Network (DUIN), comprising three essential modules: i) Explicit Intent Exploit Module extracting explicit user intent using the contrastive learning paradigm; ii) Latent Intent Explore Module exploring latent user intent by leveraging the multi-view relationships between items; iii) Intent Uncertainty Measurement Module offering a distributional estimation and capturing the uncertainty associated with user intent. Experiments on three real-world datasets demonstrate the superior performance of DUIN compared to existing baselines. Notably, DUIN has been deployed across all TIR scenarios in our e-commerce platform, with online A/B testing results conclusively validating its superiority.|为了满足用户对沉浸式浏览体验的需求，众多电商平台提供了多种推荐场景，着重于触发式推荐（Trigger-Induced Recommendation, TIR）任务。然而，当前大多数TIR方法过于依赖触发项来理解用户意图，缺乏对用户意图的高层次探索和利用（例如，流行商品和互补商品），这可能导致对用户短期意图的理解过于集中，从而对用户的长期购买体验产生不利影响。此外，用户的短期意图表现出不确定性，并受到浏览上下文和历史行为等多种因素的影响，这对用户意图建模提出了挑战。为了应对这些挑战，我们提出了一种名为深度不确定性意图网络（Deep Uncertainty Intent Network, DUIN）的新模型，该模型包含三个核心模块：i) 显式意图利用模块，通过对比学习范式提取显式用户意图；ii) 潜在意图探索模块，利用商品之间的多视角关系来探索潜在用户意图；iii) 意图不确定性度量模块，提供分布估计并捕捉用户意图的不确定性。在三个真实世界数据集上的实验表明，DUIN相比现有基线方法表现出优越的性能。值得注意的是，DUIN已在我们电商平台的所有TIR场景中部署，在线A/B测试结果有力地验证了其优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modeling+User+Intent+Beyond+Trigger:+Incorporating+Uncertainty+for+Trigger-Induced+Recommendation)|0|
|[Confidence-aware Self-Semantic Distillation on Knowledge Graph Embedding](https://doi.org/10.1145/3627673.3679683)|Yichen Liu, Jiawei Chen, Defang Chen, Zhehui Zhou, Yan Feng, Can Wang||Knowledge Graph Embedding (KGE), which projects entities and relations intocontinuous vector spaces, have garnered significant attention. Althoughhigh-dimensional KGE methods offer better performance, they come at the expenseof significant computation and memory overheads. Decreasing embeddingdimensions significantly deteriorates model performance. While several recentefforts utilize knowledge distillation or non-Euclidean representation learningto augment the effectiveness of low-dimensional KGE, they either necessitate apre-trained high-dimensional teacher model or involve complex non-Euclideanoperations, thereby incurring considerable additional computational costs. Toaddress this, this work proposes Confidence-aware Self-Knowledge Distillation(CSD) that learns from model itself to enhance KGE in a low-dimensional space.Specifically, CSD extracts knowledge from embeddings in previous iterations,which would be utilized to supervise the learning of the model in the nextiterations. Moreover, a specific semantic module is developed to filterreliable knowledge by estimating the confidence of previously learnedembeddings. This straightforward strategy bypasses the need for time-consumingpre-training of teacher models and can be integrated into various KGE methodsto improve their performance. Our comprehensive experiments on six KGEbackbones and four datasets underscore the effectiveness of the proposed CSD.|知识图谱嵌入（KGE）将实体和关系投影到连续的向量空间中，引起了广泛关注。尽管高维KGE方法提供了更好的性能，但它们也带来了显著的计算和内存开销。降低嵌入维度会显著降低模型性能。虽然最近的一些研究利用知识蒸馏或非欧几里得表示学习来增强低维KGE的有效性，但它们要么需要预训练的高维教师模型，要么涉及复杂的非欧几里得操作，从而产生了大量的额外计算成本。为了解决这一问题，本文提出了置信度感知的自知识蒸馏（CSD），该方法通过从模型自身学习来增强低维空间的KGE。具体而言，CSD从先前迭代中的嵌入中提取知识，这些知识将被用于监督模型在后续迭代中的学习。此外，本文还开发了一个特定的语义模块，通过估计先前学习嵌入的置信度来过滤可靠的知识。这种直接的策略避免了耗时的教师模型预训练，并且可以集成到各种KGE方法中以提高其性能。我们在六个KGE基线和四个数据集上的综合实验验证了所提出CSD的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Confidence-aware+Self-Semantic+Distillation+on+Knowledge+Graph+Embedding)|0|
|[SAQRec: Aligning Recommender Systems to User Satisfaction via Questionnaire Feedback](https://doi.org/10.1145/3627673.3679643)|Kepu Zhang, Teng Shi, Sunhao Dai, Xiao Zhang, Yinfeng Li, Jing Lu, Xiaoxue Zang, Yang Song, Jun Xu|Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China; Kuaishou Technology Co., Ltd., Beijing, China|In real-world recommender systems, user engagement and subjective feedback play pivotal roles in shaping the content distribution mechanism of the platform. When platforms reach a certain scale, they often gather valuable questionnaire feedback data from users to evaluate their satisfaction with recommended items. Compared to traditional user feedback such as likes, questionnaires explicitly capture both satisfaction and dissatisfaction and are unaffected by other users' questionnaires, thus better expressing users' true preferences. In this paper, we aim to leverage the questionnaire feedback to align the recommendation model with users' true preferences. However, due to the platform distribution mechanism and divergent user attitudes toward questionnaires, the questionnaire feedback data frequently becomes sparse and exhibits selection biases, resulting in challenges in feature integration and training process. To address these issues, we introduce a novel user Satisfaction Alignment framework that effectively leverages Questionnaire feedback to enhance Recommendation, named SAQRec. SAQRec begins by training an unbiased satisfaction model to impute satisfaction, addressing selection bias and data sparsity. Then, SAQRec aligns features with users' true preferences by disentangling satisfaction and dissatisfaction from click history and categorizing clicked items into multiple satisfaction levels through the imputed satisfactions. Additionally, the imputed satisfactions from the pre-trained unbiased satisfaction model serve as pseudo-labels to align the model's outputs with users' true preferences. Extensive experiments on both public and commercial datasets demonstrate SAQRec's superior integration of questionnaire feedback in recommendation models. Online A/B testing on a short video platform confirms its effectiveness in boosting user watch time and positive-to-negative feedback ratio, enhancing overall performance and user satisfaction.|在实际的推荐系统中，用户参与度和主观反馈在塑造平台内容分发机制方面起着关键作用。当平台达到一定规模时，通常会收集用户对推荐项目的满意度问卷反馈数据，以评估用户的满意度。与传统的用户反馈（如点赞）相比，问卷能够明确捕捉用户的满意和不满意情况，并且不受其他用户问卷的影响，因此更能表达用户的真实偏好。本文旨在利用问卷反馈来使推荐模型与用户的真实偏好相一致。然而，由于平台分发机制和用户对问卷的不同态度，问卷反馈数据往往变得稀疏并存在选择偏差，导致特征整合和训练过程面临挑战。为解决这些问题，我们提出了一种新的用户满意度对齐框架，该框架有效利用问卷反馈来增强推荐，命名为SAQRec。SAQRec首先训练一个无偏的满意度模型来填补满意度，解决选择偏差和数据稀疏问题。然后，SAQRec通过对点击历史进行解耦，将满意和不满意分离，并通过填补的满意度将点击项目分类为多个满意度级别，从而使特征与用户的真实偏好对齐。此外，预训练的无偏满意度模型产生的填补满意度作为伪标签，用于使模型的输出与用户的真实偏好对齐。在公共和商业数据集上的广泛实验表明，SAQRec在推荐模型中对问卷反馈的整合具有优越性。在一个短视频平台上的在线A/B测试证实了其在提升用户观看时间和正面反馈与负面反馈比例方面的有效性，从而提高了整体性能和用户满意度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SAQRec:+Aligning+Recommender+Systems+to+User+Satisfaction+via+Questionnaire+Feedback)|0|
|[CXSimulator: A User Behavior Simulation using LLM Embeddings for Web-Marketing Campaign Assessment](https://doi.org/10.1145/3627673.3679894)|Akira Kasuga, Ryo Yonetani||This paper presents the Customer Experience (CX) Simulator, a novel framework designed to assess the effects of untested web-marketing campaigns through user behavior simulations. The proposed framework leverages large language models (LLMs) to represent various events in a user's behavioral history, such as viewing an item, applying a coupon, or purchasing an item, as semantic embedding vectors. We train a model to predict transitions between events from their LLM embeddings, which can even generalize to unseen events by learning from diverse training data. In web-marketing applications, we leverage this transition prediction model to simulate how users might react differently when new campaigns or products are presented to them. This allows us to eliminate the need for costly online testing and enhance the marketers' abilities to reveal insights. Our numerical evaluation and user study, utilizing BigQuery Public Datasets from the Google Merchandise Store, demonstrate the effectiveness of our framework.|本文介绍了客户体验（CX）模拟器，这是一个新颖的框架，旨在通过用户行为模拟来评估未经测试的网络营销活动的效果。该框架利用大型语言模型（LLMs）将用户行为历史中的各种事件，如查看商品、使用优惠券或购买商品，表示为语义嵌入向量。我们训练了一个模型，从这些LLM嵌入中预测事件之间的转换，该模型甚至可以通过从多样化的训练数据中学习来泛化到未见过的事件。在网络营销应用中，我们利用这种转换预测模型来模拟用户在新活动或新产品呈现给他们时可能产生的不同反应。这使我们能够消除昂贵的在线测试需求，并增强营销人员揭示洞察的能力。我们的数值评估和用户研究，利用了Google商品商店的BigQuery公共数据集，证明了我们框架的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CXSimulator:+A+User+Behavior+Simulation+using+LLM+Embeddings+for+Web-Marketing+Campaign+Assessment)|0|
|[Exploring High-Order User Preference with Knowledge Graph for Recommendation](https://doi.org/10.1145/3627673.3679921)|Caijun Xu, Fuwei Zhang, Zhao Zhang, Fuzhen Zhuang, Rui Liu|School of Computer Science, Beihang University, Beijing, China; Institute of Artificial Intelligence, Beihang University, Beijing, China; Institute of Artificial Intelligence, Beihang University & Zhongguancun Laboratory, Beijing, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China|Knowledge Graph (KG) has proven its effectiveness in recommendation systems. Recent knowledge-aware recommendation methods, which utilize graph neural networks and contrastive learning, underestimate two issues: 1) The neglect of modeling the latent relationships between users and entities; 2) The insufficiency of traditional cross-view contrastive learning whose domain is incapable of covering all nodes in a graph. To address these issues, we propose a novel model named Knowledge-aware User Preference Network (KUPN). Specifically, KUPN first constructs the relational preference view containing a new graph named User Preference Graph (UPG) to model the potential relationships between users and entities. Then, we adopt a novel attentive information aggregation to learn the UPG. In addition, we obtain semantic information of users and entities from collaborative knowledge view which consists of KG and Interaction Graph (IG) as supplementary. Finally, we apply a cross-view contrastive learning for complete domains between dynamic relational preference view and collaborative knowledge view. Extensive experiments on three real-world datasets demonstrate the superiority of KUPN against the state-of-the-art methods.|知识图谱（KG）在推荐系统中已证明其有效性。近年来，利用图神经网络和对比学习的知识感知推荐方法低估了两个问题：1）忽视了用户与实体之间潜在关系的建模；2）传统跨视图对比学习的领域不足以覆盖图中的所有节点。为解决这些问题，我们提出了一种名为知识感知用户偏好网络（KUPN）的新模型。具体而言，KUPN首先构建了包含用户偏好图（UPG）的关系偏好视图，以建模用户与实体之间的潜在关系。接着，我们采用了一种新颖的注意力信息聚合方法来学习UPG。此外，我们从协同知识视图中获取用户和实体的语义信息，该视图由KG和交互图（IG）组成，作为补充。最后，我们在动态关系偏好视图和协同知识视图之间应用了跨视图对比学习，以实现完整领域的覆盖。在三个真实世界数据集上的广泛实验表明，KUPN相较于最先进的方法具有优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+High-Order+User+Preference+with+Knowledge+Graph+for+Recommendation)|0|
|[EXIT: An EXplicit Interest Transfer Framework for Cross-Domain Recommendation](https://doi.org/10.1145/3627673.3680055)|Lei Huang, Weitao Li, Chenrui Zhang, Jinpeng Wang, Xianchun Yi, Sheng Chen||Cross-domain recommendation has attracted substantial interest in industrial apps such as Meituan, which serves multiple business domains via knowledge transfer and meets the diverse interests of users. However, existing methods typically follow an implicit modeling paradigm that blends the knowledge from both the source and target domains, and design intricate network structures to share learned embeddings or patterns between domains to improve recommendation accuracy. Since the transfer of interest signals is unsupervised, these implicit paradigms often struggle with the negative transfer resulting from differences in service functions and presentation forms across different domains. In this paper, we propose a simple and effective EXplicit Interest Transfer framework named EXIT to address the stated challenge. Specifically, we propose a novel label combination approach that enables the model to directly learn beneficial source domain interests through supervised learning, while excluding inappropriate interest signals. Moreover, we introduce a scene selector network to model the interest transfer intensity under fine-grained scenes. Offline experiments conducted on the industrial production dataset and online A/B tests validate the superiority and effectiveness of our proposed framework. Without complex network structures or training processes, EXIT can be easily deployed in the industrial recommendation system. EXIT has been successfully deployed in the online homepage recommendation system of Meituan App, serving the main traffic.|跨领域推荐在美团等工业应用中引起了广泛关注，通过知识转移服务于多个业务领域，满足用户的多样化兴趣。然而，现有方法通常采用隐式建模范式，将源域和目标域的知识混合，设计复杂的网络结构以在域间共享学习到的嵌入或模式，从而提高推荐准确性。由于兴趣信号的转移是无监督的，这些隐式范式往往因不同域间服务功能和呈现形式的差异而遭遇负迁移问题。本文提出了一种简单而有效的显式兴趣转移框架，名为EXIT，以应对上述挑战。具体而言，我们提出了一种新颖的标签组合方法，使模型能够通过监督学习直接学习有益的源域兴趣，同时排除不适当的兴趣信号。此外，我们引入了一个场景选择器网络，以在细粒度场景下建模兴趣转移强度。在工业生产数据集上的离线实验和在线A/B测试验证了我们提出的框架的优越性和有效性。EXIT无需复杂的网络结构或训练过程，可以轻松部署在工业推荐系统中。EXIT已成功部署在美团App的在线首页推荐系统中，服务于主要流量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EXIT:+An+EXplicit+Interest+Transfer+Framework+for+Cross-Domain+Recommendation)|0|
|[To Explore or Exploit? A Gradient-informed Framework to Address the Feedback Loop for Graph based Recommendation](https://doi.org/10.1145/3627673.3680061)|Zhigang Huangfu, Binbin Hu, Zhengwei Wu, Fengyu Han, GongDuo Zhang, Lihong Gu, Zhiqiang Zhang|Ant Group, Hang Zhou, China; Ant Group, Hangzhou, China|Graph-based Recommendation Systems (GRSs) have gained prominence for their ability to enhance the accuracy and effectiveness of recommender systems by exploiting structural relationships in user-item interaction data. Despite their advanced capabilities, we find GRSs are susceptible to feedback-loop phenomena that disproportionately diminish the visibility of new and long-tail items, leading to a homogenization of recommendations and the potential emergence of echo chambers. To mitigate this feedback-loop issue, exploration and exploitation (E&E) strategies have been extensively researched. However, conventional E&E methods rest on the assumption that recommendations are independent and identically distributed-an assumption that is not valid for GRSs. To forge an effective E&E approach tailored to GRSs, we introduce a novel framework, the GRADient-informed Exploration and Exploitation (GRADE), designed to adaptively seek out underrepresented or new items with promising rewards. Our method evaluates the potential benefit of exploring an item by assessing the change in the system's empirical risk error pre- and post-exposure. For practical implementation, we approximate this measure using the gradients of potential edges and model parameters, alongside their associated uncertainties. We then orchestrate the balance between exploration and exploitation utilizing Thompson sampling and the Upper Confidence Bound (UCB) strategy. Empirical tests on datasets from two industrial environments demonstrate that GRADE consistently outperforms existing state-of-the-art methods. Additionally, our approach has been successfully integrated into actual industrial systems.|基于图的推荐系统（GRSs）因其能够通过利用用户-项目交互数据中的结构关系来提高推荐系统的准确性和有效性而备受关注。尽管其功能强大，我们发现GRSs易受反馈循环现象的影响，这种现象不均衡地降低了新项目和长尾项目的可见性，导致推荐内容的同质化，并可能催生回音壁效应。为缓解这一反馈循环问题，探索与利用（E&E）策略得到了广泛研究。然而，传统的E&E方法基于推荐是独立同分布的假设，这一假设对于GRSs并不成立。为了针对GRSs开发一种有效的E&E方法，我们引入了一个新的框架——基于梯度的探索与利用（GRADE），该框架旨在自适应地发掘具有潜在回报的未充分代表或新项目。我们的方法通过评估系统在项目曝光前后的经验风险误差变化，来评估探索某一项目的潜在收益。在实际应用中，我们利用潜在边的梯度和模型参数及其相关的不确定性来近似这一度量。随后，我们利用汤普森采样和上置信界（UCB）策略来协调探索与利用之间的平衡。在两个工业环境数据集上的实证测试表明，GRADE始终优于现有的最先进方法。此外，我们的方法已成功集成到实际的工业系统中。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=To+Explore+or+Exploit?+A+Gradient-informed+Framework+to+Address+the+Feedback+Loop+for+Graph+based+Recommendation)|0|
|[Sequential Optimum Test with Multi-armed Bandits for Online Experimentation](https://doi.org/10.1145/3627673.3680040)|Fang Kong, Penglei Zhao, Shichao Han, Yong Wang, Shuai Li|Tencent Inc., Shenzhen, China; Shanghai Jiao Tong University, Shanghai, China|In large-scale online experimentation platforms, experimenters aim to discover the best treatment (arm) among multiple candidates. Traditional A/B testing and multi-armed bandits (MAB) algorithms are two popular designs. The former usually achieves a higher power but may hurt the customers' satisfaction when always recommending a poor arm, while the latter aims at improving the customers' experience (collecting more rewards) but faces the loss of testing power. Recently, [26] combine the advantage of A/B testing and MAB algorithms to maximize the testing power while maintaining more rewards for experiments with two-arm and Bernoulli rewards. However, in practice, the number of arms is usually larger than two and the reward type also varies. In multi-arm experiments, the required sample size to find the optimal arm blows up to guarantee a false discovery rate with the increase of arm numbers, bringing high opportunity costs to experimenters. To save the cost during the long experimental process, we propose a more efficient sequential test framework named Soptima that can work with general reward types. Inspired by the design of traditional MAB algorithms in chasing rewards and A/B testing in maximizing power, we propose an Elimination-type strategy adapted to this framework to dynamically adjust the traffic split on arms. This strategy cooperating with Soptima simultaneously maintains the advantage of the A/B testing in maximizing the testing power, the sequential test methods in saving the sample size, and the MAB algorithms in collecting rewards. The theoretical analysis gives guarantees on the Type-I, Type-II, and optimality error rates of the proposed approach. A series of experiments from both simulation and industrial historical data sets are conducted to verify the superiority of our approach compared with available baselines.|在大规模在线实验平台中，实验者的目标是从多个候选方案（臂）中找出最佳方案。传统的A/B测试和多臂老虎机（MAB）算法是两种流行的设计方案。前者通常具有更高的测试效能，但当总是推荐效果不佳的方案时，可能会损害客户的满意度；而后者旨在提升客户体验（收集更多奖励），但面临测试效能的损失。最近，[26]结合了A/B测试和MAB算法的优势，以最大化测试效能，同时在两臂和伯努利奖励的实验中保持更多的奖励。然而，在实践中，臂的数量通常大于两个，且奖励类型也多种多样。在多臂实验中，随着臂数量的增加，为了保证错误发现率，找到最佳臂所需的样本量会急剧增加，这给实验者带来了高昂的机会成本。为了在漫长的实验过程中节省成本，我们提出了一种名为Soptima的高效序列测试框架，该框架适用于一般的奖励类型。受传统MAB算法在追逐奖励和A/B测试在最大化效能的设计启发，我们提出了一种适应此框架的淘汰型策略，以动态调整对各臂的流量分配。这种策略与Soptima合作，同时保持了A/B测试在最大化测试效能、序列测试方法在节省样本量以及MAB算法在收集奖励方面的优势。理论分析为所提出方法的I类错误率、II类错误率和最优性错误率提供了保障。通过一系列来自模拟和工业历史数据集的实验，验证了我们的方法相对于现有基线的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sequential+Optimum+Test+with+Multi-armed+Bandits+for+Online+Experimentation)|0|
|[TWIN V2: Scaling Ultra-Long User Behavior Sequence Modeling for Enhanced CTR Prediction at Kuaishou](https://doi.org/10.1145/3627673.3680030)|Zihua Si, Lin Guan, Zhongxiang Sun, Xiaoxue Zang, Jing Lu, Yiqun Hui, Xingchao Cao, Zeyu Yang, Yichen Zheng, Dewei Leng, Kai Zheng, Chenbin Zhang, Yanan Niu, Yang Song, Kun Gai||The significance of modeling long-term user interests for CTR prediction tasks in large-scale recommendation systems is progressively gaining attention among researchers and practitioners. Existing work, such as SIM and TWIN, typically employs a two-stage approach to model long-term user behavior sequences for efficiency concerns. The first stage rapidly retrieves a subset of sequences related to the target item from a long sequence using a search-based mechanism namely the General Search Unit (GSU), while the second stage calculates the interest scores using the Exact Search Unit (ESU) on the retrieved results. Given the extensive length of user behavior sequences spanning the entire life cycle, potentially reaching up to 10^6 in scale, there is currently no effective solution for fully modeling such expansive user interests. To overcome this issue, we introduced TWIN-V2, an enhancement of TWIN, where a divide-and-conquer approach is applied to compress life-cycle behaviors and uncover more accurate and diverse user interests. Specifically, a hierarchical clustering method groups items with similar characteristics in life-cycle behaviors into a single cluster during the offline phase. By limiting the size of clusters, we can compress behavior sequences well beyond the magnitude of 10^5 to a length manageable for online inference in GSU retrieval. Cluster-aware target attention extracts comprehensive and multi-faceted long-term interests of users, thereby making the final recommendation results more accurate and diverse. Extensive offline experiments on a multi-billion-scale industrial dataset and online A/B tests have demonstrated the effectiveness of TWIN-V2. Under an efficient deployment framework, TWIN-V2 has been successfully deployed to the primary traffic that serves hundreds of millions of daily active users at Kuaishou.|在大规模推荐系统中，建模长期用户兴趣对点击率（CTR）预测任务的重要性正逐渐受到研究者和从业者的关注。现有的研究工作，如SIM和TWIN，通常采用两阶段方法来高效地建模长期用户行为序列。第一阶段通过基于搜索的机制，即通用搜索单元（GSU），从长序列中快速检索与目标项目相关的子集序列；第二阶段则使用精确搜索单元（ESU）对检索结果计算兴趣分数。鉴于用户行为序列的广泛长度可能跨越整个生命周期，规模可达10^6，目前尚无有效解决方案来全面建模如此广泛的用户兴趣。为解决这一问题，我们引入了TWIN-V2，即TWIN的增强版本，采用分而治之的方法来压缩生命周期行为并揭示更准确和多样的用户兴趣。具体而言，层次聚类方法在离线阶段将具有相似特征的生命周期行为项目分组为一个集群。通过限制集群大小，我们可以将行为序列压缩到远超10^5的规模，使其适合在线推理中的GSU检索。集群感知的目标注意力机制提取了用户全面且多方面的长期兴趣，从而使最终的推荐结果更加准确和多样化。在多十亿规模工业数据集上的广泛离线实验和在线A/B测试证明了TWIN-V2的有效性。在高效部署框架下，TWIN-V2已成功部署到快手的主要流量中，服务数亿日活用户。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TWIN+V2:+Scaling+Ultra-Long+User+Behavior+Sequence+Modeling+for+Enhanced+CTR+Prediction+at+Kuaishou)|0|
|[Understanding the User: An Intent-Based Ranking Dataset](https://doi.org/10.1145/3627673.3679166)|Abhijit Anand, Jurek Leonhardt, Venktesh V, Avishek Anand||As information retrieval systems continue to evolve, accurate evaluation and benchmarking of these systems become pivotal. Web search datasets, such as MS MARCO, primarily provide short keyword queries without accompanying intent or descriptions, posing a challenge in comprehending the underlying information need. This paper proposes an approach to augmenting such datasets to annotate informative query descriptions, with a focus on two prominent benchmark datasets: TREC-DL-21 and TREC-DL-22. Our methodology involves utilizing state-of-the-art LLMs to analyze and comprehend the implicit intent within individual queries from benchmark datasets. By extracting key semantic elements, we construct detailed and contextually rich descriptions for these queries. To validate the generated query descriptions, we employ crowdsourcing as a reliable means of obtaining diverse human perspectives on the accuracy and informativeness of the descriptions. This information can be used as an evaluation set for tasks such as ranking, query rewriting, or others.|随着信息检索系统不断演进，对其进行准确的评估和基准测试变得至关重要。诸如MS MARCO等网络搜索数据集主要提供简短的关键词查询，缺乏伴随的意图或描述，这给理解背后的信息需求带来了挑战。本文提出了一种增强此类数据集的方法，旨在为查询添加信息丰富的描述，重点关注两个著名的基准数据集：TREC-DL-21和TREC-DL-22。我们的方法涉及利用最先进的LLMs（大型语言模型）来分析和理解基准数据集中各个查询的隐含意图。通过提取关键的语义元素，我们为这些查询构建了详细且上下文丰富的描述。为了验证生成的查询描述，我们采用众包作为获取多样化人类视角的可靠手段，以评估描述的准确性和信息量。这些信息可以作为排序、查询重写等任务的评估集使用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+the+User:+An+Intent-Based+Ranking+Dataset)|0|
|[Domain Alignment with Large Vision-language Models for Cross-domain Remote Sensing Image Retrieval](https://doi.org/10.1145/3627673.3679612)|Yan Chen, Guocan Cai, Fufang Li, Yangtao Wang, Xin Tan, Xiaocui Li|East China Normal University, Shanghai, China; School of Computer Science and Cyber Engineering, Guangzhou University, Guangzhou, China; Hunan University of Technology and Business, Changsha, China|Cross-domain remote sensing image retrieval has been a hotspot in the past few years. Most of the existing methods focus on combining semantic learning with domain adaptation on well-labeled source domain and unlabeled target domain. However, they face two serious challenges. (1) They cannot deal with practical scenarios where the source domain lacks sufficient label supervision. (2) They suffer from severe performance degradation when the data distribution between the source domain and target domain becomes highly inconsistent. To address these challenges, we propose D omain A lignment with L arge V ision-language models for cross-domain remote sensing image retrieval (termed as DALV). First, we design a dual-modality prototype guided pseudo-labeling mechanism, which leverages the pre-trained large vision-language model (i.e., CLIP) to assign pseudo-labels for all unlabeled source domain images and target domain images. Second, we compute the confidence scores for these pseudo-labels to distinguish their reliability. Next, we devise a loss reweighting strategy, which incorporates the confidence scores as weight values into the contrastive loss to mitigate the impact of noisy pseudo-labels. Finally, the low-rank adaptation fine-tuning means is adapted to update our model and achieve domain alignment to obtain class discriminative features. Extensive experiments on 12 cross-domain remote sensing image retrieval tasks show that our proposed DALV outperforms the state-of-the-art approaches. The source code is available at https://github.com/ptyy01/DALV.|跨领域遥感图像检索近年来成为研究热点。现有方法大多集中在结合语义学习和领域适应于标签丰富的源域和无标签的目标域。然而，这些方法面临两个严重挑战：（1）无法处理源域缺乏足够标签监督的实际场景；（2）当源域和目标域的数据分布高度不一致时，性能严重下降。为应对这些挑战，我们提出了基于大规模视觉语言模型的跨领域遥感图像检索的领域对齐方法（简称DALV）。首先，我们设计了一种双模态原型引导的伪标签机制，利用预训练的大规模视觉语言模型（如CLIP）为所有无标签的源域图像和目标域图像分配伪标签。其次，我们计算这些伪标签的置信度分数以区分其可靠性。接着，我们设计了一种损失重加权策略，将置信度分数作为权重值融入对比损失，以减轻噪声伪标签的影响。最后，采用低秩适应微调方法更新模型，实现领域对齐，获取具有类别区分性的特征。在12个跨领域遥感图像检索任务上的广泛实验表明，我们提出的DALV方法优于现有最先进的方法。源代码可在https://github.com/ptyy01/DALV获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Domain+Alignment+with+Large+Vision-language+Models+for+Cross-domain+Remote+Sensing+Image+Retrieval)|0|
|[DIIT: A Domain-Invariant Information Transfer Method for Industrial Cross-Domain Recommendation](https://doi.org/10.1145/3627673.3679782)|Heyuan Huang, Xingyu Lou, Chaochao Chen, Pengxiang Cheng, Yue Xin, Chengwei He, Xiang Liu, Jun Wang||Cross-Domain Recommendation (CDR) have received widespread attention due to their ability to utilize rich information across domains. However, most existing CDR methods assume an ideal static condition that is not practical in industrial recommendation systems (RS). Therefore, simply applying existing CDR methods in the industrial RS environment may lead to low effectiveness and efficiency. To fill this gap, we propose DIIT, an end-to-end Domain-Invariant Information Transfer method for industrial cross-domain recommendation. Specifically, We first simulate the industrial RS environment that maintains respective models in multiple domains, each of them is trained in the incremental mode. Then, for improving the effectiveness, we design two extractors to fully extract domain-invariant information from the latest source domain models at the domain level and the representation level respectively. Finally, for improving the efficiency, we design a migrator to transfer the extracted information to the latest target domain model, which only need the target domain model for inference. Experiments conducted on one production dataset and two public datasets verify the effectiveness and efficiency of DIIT.|跨域推荐（CDR）因其能够利用跨领域的丰富信息而受到广泛关注。然而，大多数现有的CDR方法假设了一个理想的静态条件，这在工业推荐系统（RS）中并不实际。因此，简单地将现有的CDR方法应用于工业RS环境中可能导致效果和效率低下。为了填补这一空白，我们提出了DIIT，一种用于工业跨域推荐的端到端领域不变信息传递方法。具体而言，我们首先模拟了工业RS环境，该环境在多个领域中维护各自的模型，每个模型都以增量模式进行训练。然后，为了提高效果，我们设计了两个提取器，分别从领域级别和表示级别充分提取最新源域模型中的领域不变信息。最后，为了提高效率，我们设计了一个迁移器，将提取的信息传递到最新的目标域模型，该模型仅需要进行目标域模型的推理。在一个生产数据集和两个公共数据集上进行的实验验证了DIIT的有效性和效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DIIT:+A+Domain-Invariant+Information+Transfer+Method+for+Industrial+Cross-Domain+Recommendation)|0|
|[The Devil is in the Sources! Knowledge Enhanced Cross-Domain Recommendation in an Information Bottleneck Perspective](https://doi.org/10.1145/3627673.3679595)|Binbin Hu, Weifan Wang, Shuhan Wang, Ziqi Liu, Bin Shen, Yong He, Jiawei Chen||Cross-domain Recommendation (CDR) aims to alleviate the data sparsity and the cold-start problems in traditional recommender systems by leveraging knowledge from an informative source domain. However, previously proposed CDR models pursue an imprudent assumption that the entire information from the source domain is equally contributed to the target domain, neglecting the evil part that is completely irrelevant to users' intrinsic interest. To address this concern, in this paper, we propose a novel knowledge enhanced cross-domain recommendation framework named CoTrans, which remolds the core procedures of CDR models with: Compression on the knowledge from the source domain and Transfer of the purity to the target domain. Specifically, following the theory of Graph Information Bottleneck, CoTrans first compresses the source behaviors with the perception of information from the target domain. Then to preserve all the important information for the CDR task, the feedback signals from both domains are utilized to promote the effectiveness of the transfer procedure. Additionally, a knowledge-enhanced encoder is employed to narrow gaps caused by the non-overlapped items across separate domains. Comprehensive experiments on three widely used cross-domain datasets demonstrate that CoTrans significantly outperforms both single-domain and state-of-the-art cross-domain recommendation approaches.|跨域推荐（CDR）旨在通过利用信息丰富的源域知识，缓解传统推荐系统中的数据稀疏性和冷启动问题。然而，先前提出的CDR模型追求一个不谨慎的假设，即源域的全部信息对目标域的贡献是均等的，忽视了与用户内在兴趣完全无关的有害部分。为了解决这一问题，本文提出了一种名为CoTrans的新型知识增强跨域推荐框架，该框架通过以下核心步骤重构了CDR模型的流程：源域知识的压缩和目标域纯净信息的转移。具体而言，遵循图信息瓶颈理论，CoTrans首先根据目标域的信息感知压缩源域行为。然后，为了保留CDR任务的所有重要信息，利用来自两个域的反馈信号来提升转移过程的有效性。此外，采用知识增强编码器来缩小各域之间非重叠项目造成的差距。在三个广泛使用的跨域数据集上的综合实验表明，CoTrans显著优于单一域和最先进的跨域推荐方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Devil+is+in+the+Sources!+Knowledge+Enhanced+Cross-Domain+Recommendation+in+an+Information+Bottleneck+Perspective)|0|
|[MuLe: Multi-Grained Graph Learning for Multi-Behavior Recommendation](https://doi.org/10.1145/3627673.3679709)|Seunghan Lee, Geonwoo Ko, HyunJe Song, Jinhong Jung|School of Software, Soongsil University, Seoul, Republic of Korea; Dept. of CSAI, Jeonbuk Nat'l Univ., Jeonju, Republic of Korea|Multi-behavior recommender systems, rapidly advancing across various domains, utilize plentiful auxiliary interactions on a variety of user behaviors to enhance recommendations for the target behavior, such as purchases. While previous methods have made strides in leveraging such interactions with advanced machine learning methods, they still face challenges in adequately using multi-faceted relationships among behaviors and handling uncertain auxiliary interactions that could potentially lead to purchases or not. In this paper, we propose MuLe (Multi-Grained Graph Learning), a novel graph-based model designed to address these limitations. We design a multi-grained graph learning strategy to capture diverse aspects of behaviors, ranging from unified to specific, and then to target-related behavior interactions. To handle uncertain interactions, we use graph attention, weighting the importance of those interactions related to the target behavior. Afterward, we use an attention mechanism to effectively aggregate diverse behavior embeddings obtained from the multi-grained graph encoders. Extensive experiments show that MuLe significantly outperforms the state-of-the-art methods, achieving improvements of up to 44.6% in HR@10 and 52.9% in NDCG@10, respectively. Our code and datasets are available at https://github.com/geonwooko/MULE.|多行为推荐系统在各个领域迅速发展，利用丰富的用户行为辅助交互来增强对目标行为（如购买）的推荐。尽管先前的方法通过先进的机器学习方法在这一领域取得了进展，但它们在充分使用行为之间的多方面关系以及处理可能导致或不导致购买的模糊辅助交互方面仍面临挑战。本文提出了MuLe（多粒度图学习），这是一种新颖的基于图的模型，旨在解决这些局限性。我们设计了一种多粒度图学习策略，以捕捉从统一到具体再到与目标相关的行为交互的多样性。为了处理不确定的交互，我们使用图注意力机制，对与目标行为相关的交互进行重要性加权。随后，我们采用注意力机制，有效地聚合从多粒度图编码器获得的各种行为嵌入。广泛的实验表明，MuLe显著优于最先进的方法，HR@10和NDCG@10分别提高了44.6%和52.9%。我们的代码和数据集可在https://github.com/geonwooko/MULE获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MuLe:+Multi-Grained+Graph+Learning+for+Multi-Behavior+Recommendation)|0|
|[Inferring Visualization Intent from Conversation](https://doi.org/10.1145/3627673.3679589)|Haotian Li, Nithin Chalapathi, Huamin Qu, Alvin Cheung, Aditya G. Parameswaran|UC Berkeley, Berkeley, CA, USA; HKUST, Hong Kong, China|During visual data analysis, users often explore visualizations one at a time, with each visualization leading to new directions of exploration. We consider a conversational approach to visualization, where users specify their needs at each step in natural language, with a visualization being returned in turn. Prior work has shown that visualization generation can be boiled down to the identification of visualization intent and visual encodings. Recognizing that the latter is a well-studied problem with standard solutions, we focus on the former, i.e., identifying visualization intent during conversation. We develop Luna, a framework that comprises a novel combination of language models adapted from BERT and rule-based inference, that together predict various aspects of visualization intent. We compare Luna with other conversational NL-to-visualization and NL-to-SQL approaches (adapted to visualization intent), including GPT-3.5 and GPT-4, and demonstrate that Luna has 14.3% higher accuracy than the state-of-the-art. We also apply Luna to a usage scenario on a dataset of police misconduct, showcasing its benefits relative to other approaches.|在视觉数据分析过程中，用户通常一次只探索一个可视化图表，每个图表都引导出新的探索方向。我们考虑了一种对话式的可视化方法，用户在每一步以自然语言指定其需求，并依次返回一个可视化图表。先前的研究表明，可视化生成可以简化为可视化意图和视觉编码的识别。鉴于后者是一个已有标准解决方案的成熟问题，我们将重点放在前者，即在对话过程中识别可视化意图。我们开发了Luna框架，该框架结合了从BERT改编的语言模型和基于规则的推理，共同预测可视化意图的各个方面。我们将Luna与其他对话式自然语言到可视化和自然语言到SQL的方法（适配于可视化意图）进行了比较，包括GPT-3.5和GPT-4，并展示了Luna比现有技术高出14.3%的准确性。我们还应用Luna到一个关于警察不当行为的实际数据集场景中，展示了其相对于其他方法的优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Inferring+Visualization+Intent+from+Conversation)|0|
|[GUME: Graphs and User Modalities Enhancement for Long-Tail Multimodal Recommendation](https://doi.org/10.1145/3627673.3679620)|Guojiao Lin, Zhen Meng, Dongjie Wang, Qingqing Long, Yuanchun Zhou, Meng Xiao||Multimodal recommendation systems (MMRS) have received considerable attention from the research community due to their ability to jointly utilize information from user behavior and product images and text. Previous research has two main issues. First, many long-tail items in recommendation systems have limited interaction data, making it difficult to learn comprehensive and informative representations. However, past MMRS studies have overlooked this issue. Secondly, users' modality preferences are crucial to their behavior. However, previous research has primarily focused on learning item modality representations, while user modality representations have remained relatively simplistic.To address these challenges, we propose a novel Graphs and User Modalities Enhancement (GUME) for long-tail multimodal recommendation. Specifically, we first enhance the user-item graph using multimodal similarity between items. This improves the connectivity of long-tail items and helps them learn high-quality representations through graph propagation. Then, we construct two types of user modalities: explicit interaction features and extended interest features. By using the user modality enhancement strategy to maximize mutual information between these two features, we improve the generalization ability of user modality representations. Additionally, we design an alignment strategy for modality data to remove noise from both internal and external perspectives. Extensive experiments on four publicly available datasets demonstrate the effectiveness of our approach.|多模态推荐系统（MMRS）因其能够联合利用用户行为、产品图像和文本信息而受到研究界的广泛关注。以往的研究存在两个主要问题。首先，推荐系统中许多长尾项目（long-tail items）的交互数据有限，这使得学习全面且信息丰富的表示变得困难。然而，过去的MMRS研究忽视了这一问题。其次，用户的模态偏好对其行为至关重要。然而，以往的研究主要集中在学习项目模态表示上，而用户模态表示则相对简单。为了解决这些挑战，我们提出了一种新的针对长尾多模态推荐的图与用户模态增强（GUME）方法。具体来说，我们首先通过项目间的多模态相似性来增强用户-项目图，这提高了长尾项目的连通性，并帮助它们通过图传播学习高质量的表示。然后，我们构建了两种用户模态：显式交互特征和扩展兴趣特征。通过使用用户模态增强策略来最大化这两种特征之间的互信息，我们提高了用户模态表示的泛化能力。此外，我们还设计了一种模态数据对齐策略，以从内部和外部角度去除噪声。在四个公开可用的数据集上进行的广泛实验证明了我们方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GUME:+Graphs+and+User+Modalities+Enhancement+for+Long-Tail+Multimodal+Recommendation)|0|
|[Multi-Behavior Generative Recommendation](https://doi.org/10.1145/3627673.3679730)|Zihan Liu, Yupeng Hou, Julian J. McAuley|University of California, San Diego, San Diego, CA, USA|Multi-behavior sequential recommendation (MBSR) aims to incorporate behaviortypes of interactions for better recommendations. Existing approaches focus onthe next-item prediction objective, neglecting the value of integrating thetarget behavior type into the learning objective. In this paper, we proposeMBGen, a novel Multi-Behavior sequential Generative recommendation framework.We formulate the MBSR task into a consecutive two-step process: (1) given itemsequences, MBGen first predicts the next behavior type to frame the userintention, (2) given item sequences and a target behavior type, MBGen thenpredicts the next items. To model such a two-step process, we tokenize bothbehaviors and items into tokens and construct one single token sequence withboth behaviors and items placed interleaved. Furthermore, MBGen learns toautoregressively generate the next behavior and item tokens in a unifiedgenerative recommendation paradigm, naturally enabling a multi-task capability.Additionally, we exploit the heterogeneous nature of token sequences in thegenerative recommendation and propose a position-routed sparse architecture toefficiently and effectively scale up models. Extensive experiments on publicdatasets demonstrate that MBGen significantly outperforms existing MBSR modelsacross multiple tasks.|多行为序列推荐（MBSR）旨在整合交互行为类型以实现更佳的推荐效果。现有方法主要聚焦于下一项预测目标，忽略了将目标行为类型整合到学习目标中的价值。本文提出了一种名为MBGen的新型多行为序列生成推荐框架。我们将MBSR任务构建成一个连续的两步过程：（1）在给定项目序列的情况下，MBGen首先预测下一行为类型以构建用户意图；（2）在给定项目序列和目标行为类型的基础上，MBGen随后预测下一项目。为模拟这一两步过程，我们将行为和项目都标记化为令牌，并构建一个包含交错放置的行为和项目的单一令牌序列。此外，MBGen在统一的生成推荐范式中自回归地生成下一行为和项目令牌，自然地实现了多任务能力。我们还利用生成推荐中令牌序列的异构性，提出了一种位置路由稀疏架构，以高效且有效地扩展模型规模。在公共数据集上的广泛实验表明，MBGen在多个任务中显著优于现有的MBSR模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Behavior+Generative+Recommendation)|0|
|[Veracity Estimation for Entity-Oriented Search with Knowledge Graphs](https://doi.org/10.1145/3627673.3679561)|Stefano Marchesin, Gianmaria Silvello, Omar Alonso|Amazon, Palo Alto, California, USA; University of Padua, Padua, Italy|In this paper, we discuss the potential costs that emerge from using a Knowledge Graph (KG) in entity-oriented search without considering its data veracity. We argue for the need for KG veracity analysis to gain insights and propose a scalable assessment framework. Previous assessments focused on relevance, assuming correct KGs, and overlooking the potential risks of misinformation. Our approach strategically allocates annotation resources, optimizing utility and revealing the significant impact of veracity on entity search and card generation. Contributions include a fresh perspective on entity-oriented search extending beyond the conventional focus on relevance, a scalable assessment framework, exploratory experiments highlighting the impact of veracity on ranking and user experience, as well as outlining associated challenges and opportunities.|本文探讨了在面向实体的搜索中使用知识图谱（KG）而不考虑其数据真实性所可能产生的潜在成本。我们主张进行知识图谱真实性分析以获取洞察，并提出一个可扩展的评估框架。以往的评估主要集中在相关性上，假设知识图谱是正确的，而忽视了错误信息可能带来的潜在风险。我们的方法策略性地分配标注资源，优化效用并揭示真实性对实体搜索和卡片生成的重要影响。主要贡献包括：对面向实体的搜索提出了超越传统相关性关注的新视角，一个可扩展的评估框架，探索性实验突显了真实性对排名和用户体验的影响，以及概述了相关的挑战和机遇。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Veracity+Estimation+for+Entity-Oriented+Search+with+Knowledge+Graphs)|0|
|[Inductive Knowledge Graph Embedding via Exploring Interaction Patterns of Relations](https://doi.org/10.1145/3627673.3679667)|Chong Mu, Lizong Zhang, Jinchuan Zhang, Qian Huang, Zhiguo Wang||Recent research in inductive reasoning has focused on predicting missing links between entities that are not observed during training. However, most approaches usually require that the relations are known at the inference time. In the real world, new entities and new relations usually emerge concurrently, which greatly challenges the model's generalization ability. In this paper, we propose a novel inductive knowledge graph embedding model that effectively handles unknown entities and relations by capturing their local structural features. Specifically, a relation graph is constructed to learn relation representations. In the relation graph, we employ a four-dimensional vector to represent the interaction patterns between nodes (relations), where each dimension corresponds to a specific type of interaction. For entity representations, our model dynamically initializes entity features using relation features and attentively aggregates neighboring features of entities to update entity features. By modeling interaction patterns between relations and incorporating structural information of entities, our model learns how to aggregate neighboring embeddings using attention mechanisms, thus generating high-quality embeddings for new entities and relations. Extensive experiments on benchmark datasets demonstrate that our model outperforms state-of-the-art methods, particularly in scenarios involving completely new relations.|最近的研究集中在归纳推理，即预测训练过程中未观察到的实体之间的缺失链接。然而，大多数方法通常要求在推理时已知关系。在现实世界中，新实体和新关系通常同时出现，这对模型的泛化能力提出了巨大挑战。在本文中，我们提出了一种新颖的归纳知识图谱嵌入模型，该模型通过捕捉实体和关系的局部结构特征，有效处理未知实体和关系。具体来说，我们构建了一个关系图来学习关系表示。在关系图中，我们使用一个四维向量来表示节点（关系）之间的交互模式，其中每个维度对应一种特定的交互类型。对于实体表示，我们的模型使用关系特征动态初始化实体特征，并注意聚合实体的邻居特征以更新实体特征。通过建模关系之间的交互模式并结合实体的结构信息，我们的模型学习如何使用注意力机制聚合邻居嵌入，从而生成新实体和关系的高质量嵌入。在基准数据集上的广泛实验表明，我们的模型优于最先进的方法，特别是在涉及完全新关系的场景中。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Inductive+Knowledge+Graph+Embedding+via+Exploring+Interaction+Patterns+of+Relations)|0|
|[When LLM Meets Hypergraph: A Sociological Analysis on Personality via Online Social Networks](https://doi.org/10.1145/3627673.3679646)|Zhiyao Shu, Xiangguo Sun, Hong Cheng||Individual personalities significantly influence our perceptions, decisions, and social interactions, which is particularly crucial for gaining insights into human behavior patterns in online social network analysis. Many psychological studies have observed that personalities are strongly reflected in their social behaviors and social environments. In light of these problems, this paper proposes a sociological analysis framework for one's personality in an environment-based view instead of individual-level data mining. Specifically, to comprehensively understand an individual's behavior from low-quality records, we leverage the powerful associative ability of LLMs by designing an effective prompt. In this way, LLMs can integrate various scattered information with their external knowledge to generate higher-quality profiles, which can significantly improve the personality analysis performance. To explore the interactive mechanism behind the users and their online environments, we design an effective hypergraph neural network where the hypergraph nodes are users and the hyperedges in the hypergraph are social environments. We offer a useful dataset with user profile data, personality traits, and several detected environments from the real-world social platform. To the best of our knowledge, this is the first network-based dataset containing both hypergraph structure and social information, which could push forward future research in this area further. By employing the framework on this dataset, we can effectively capture the nuances of individual personalities and their online behaviors, leading to a deeper understanding of human interactions in the digital world.|个体性格显著影响我们的感知、决策和社会互动，这对于深入理解在线社交网络分析中的人类行为模式尤为关键。许多心理学研究观察到，性格在其社会行为和社会环境中得到了强烈体现。鉴于这些问题，本文提出了一种基于环境视角而非个体层面数据挖掘的社会学分析框架，用于分析个体性格。具体而言，为了从低质量记录中全面理解个体行为，我们利用大型语言模型（LLMs）强大的关联能力，通过设计有效的提示词，使LLMs能够整合各种分散的信息与其外部知识，生成更高质量的个体画像，从而显著提升性格分析的性能。为了探索用户与其在线环境之间的交互机制，我们设计了一种有效的超图神经网络，其中超图节点为用户，超图的超边为社会环境。我们提供了一个包含用户画像数据、性格特征及从真实社交平台检测到的多种环境的实用数据集。据我们所知，这是首个同时包含超图结构和社会信息的网络数据集，有望推动该领域的未来研究。通过在该数据集上应用该框架，我们能够有效捕捉个体性格及其在线行为的细微差别，从而更深入地理解数字世界中的人类互动。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=When+LLM+Meets+Hypergraph:+A+Sociological+Analysis+on+Personality+via+Online+Social+Networks)|0|
|[FABLE: Approximate Butterfly Counting in Bipartite Graph Stream with Duplicate Edges](https://doi.org/10.1145/3627673.3679812)|Guozhang Sun, Yuhai Zhao, Yuan Li|Northeastern University, Shenyang, China; North China University of Technology, Beijing, China|Bipartite graph models the relationship between two different sets of entities. Such graph data become more dynamic and are organized as stream with duplicate edges in real-word applications such as customer-product in e-commerce. A butterfly, (2,2)-biclique, is the simplest cohesive substructure and of great importance in a bipartite graph. However, it is challenging to estimate the number of butterflies in large scale and high dynamic bipartite graph stream when given a limited memory. Besides, existing works for butterfly counting assume no duplicate edges in the bipartite graph stream, which cause less accuracy in bipartite graph stream with duplicate edges. In this paper, we propose FABLE, a Fixed-size memory Approximate Butterfly counting algorithm for dupLicate Edges in bipartite graph stream. In FABLE, we compute the number of distinct edges by maintaining an ordered list of edge priorities for replacement and sampling. We provide theoretical proof of unbiasedness and derive the variance of butterfly count. Our extensive experiments on 5 real-world datasets confirm that our approach has higher accuracy compared with the baseline method under the same memory usage.|二分图模型描述了两组不同实体之间的关系。在电子商务等实际应用中，如客户-产品关系，这种图数据变得更加动态，并以包含重复边的流形式组织。蝴蝶结构，即(2,2)-二分团，是二分图中最重要的简单凝聚子结构。然而，在有限的内存条件下，估计大规模和高动态二分图流中的蝴蝶数量是一个挑战。此外，现有的蝴蝶计数方法假设二分图流中没有重复边，这导致在包含重复边的二分图流中计数精度较低。本文提出了FABLE，一种用于二分图流中重复边的固定内存近似蝴蝶计数算法。在FABLE中，我们通过维护一个用于替换和采样的边优先级有序列表来计算不同边的数量。我们提供了无偏性的理论证明，并推导了蝴蝶计数的方差。在5个真实世界数据集上的广泛实验证实，在相同内存使用条件下，我们的方法相比基线方法具有更高的精度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FABLE:+Approximate+Butterfly+Counting+in+Bipartite+Graph+Stream+with+Duplicate+Edges)|0|
|[Learnable Item Tokenization for Generative Recommendation](https://doi.org/10.1145/3627673.3679569)|Wenjie Wang, Honghui Bao, Xinyu Lin, Jizhi Zhang, Yongqi Li, Fuli Feng, SeeKiong Ng, TatSeng Chua||Utilizing powerful Large Language Models (LLMs) for generative recommendation has attracted much attention. Nevertheless, a crucial challenge is transforming recommendation data into the language space of LLMs through effective item tokenization. Current approaches, such as ID, textual, and codebook-based identifiers, exhibit shortcomings in encoding semantic information, incorporating collaborative signals, or handling code assignment bias. To address these limitations, we propose LETTER (a LEarnable Tokenizer for generaTivE Recommendation), which integrates hierarchical semantics, collaborative signals, and code assignment diversity to satisfy the essential requirements of identifiers. LETTER incorporates Residual Quantized VAE for semantic regularization, a contrastive alignment loss for collaborative regularization, and a diversity loss to mitigate code assignment bias. We instantiate LETTER on two models and propose a ranking-guided generation loss to augment their ranking ability theoretically. Experiments on three datasets validate the superiority of LETTER, advancing the state-of-the-art in the field of LLM-based generative recommendation.|利用强大的大型语言模型（LLMs）进行生成式推荐引起了广泛关注。然而，一个关键挑战是如何通过有效的物品标记化将推荐数据转换为LLMs的语言空间。当前的方法，如基于ID、文本和码本的标识符，在编码语义信息、整合协作信号或处理码分配偏差方面存在不足。为了解决这些限制，我们提出了LETTER（一种用于生成式推荐的LEarnable Tokenizer），它整合了层次语义、协作信号和码分配多样性，以满足标识符的基本要求。LETTER结合了残差量化VAE进行语义正则化，对比对齐损失进行协作正则化，以及多样性损失以减轻码分配偏差。我们在两个模型上实例化了LETTER，并提出了一种排名引导的生成损失，以理论增强其排名能力。在三个数据集上的实验验证了LETTER的优越性，推动了基于LLM的生成式推荐领域的前沿进展。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learnable+Item+Tokenization+for+Generative+Recommendation)|0|
|[Improving Adversarial Transferability via Frequency-Guided Sample Relevance Attack](https://doi.org/10.1145/3627673.3679858)|Xinyi Wang, Zhibo Jin, Zhiyu Zhu, Jiayu Zhang, Huaming Chen|University of Malaya, Kuala Lumpur, Malaysia; Suzhou Yierqi, Suzhou, China; The University of Sydney, Sydney, Australia|Deep neural networks (DNNs) are known to be vulnerable to adversarial examples. To facilitate model safety, transfer-based attacks employ surrogate models to craft adversarial examples. In this work, we firstly study the intricate mechanisms of such attacks. We observe a correlation between the sharpness of decision boundaries in model sensitive regions and overfitting during adversarial training, which hampers the adversarial examples' transferability. To address this issue, we propose a novel approach termed Frequency-Guided Sample Relevance Attack (FGSRA). Specifically, we leverage frequency information to explore similar sensitive regions across different models, thereby generating neighborhood samples. Additional similarity weights are subsequently introduced to assess the adversarial contribution of the neighborhood samples. A hybrid gradient is then obtained to thoroughly exploit neighborhood information within input samples. Extensive experiments demonstrate the prominent performance of our approach. Compared to other state-of-the-art benchmarks on surrogate model Inc-v3, our method has an average improvement of 27.21% for normally trained CNNs and 42.1% for adversarially trained CNNs. Moreover, we achieve an average improvement of 24.6% for ViTs. Our code is available at:https://github.com/LMBTough/FGSRA|深度神经网络（DNNs）在面对对抗样本时表现出脆弱性。为了提升模型的安全性，基于迁移的攻击方法利用代理模型来生成对抗样本。在本研究中，我们首先探讨了这类攻击的复杂机制。我们观察到，在模型的敏感区域中，决策边界的锐度与对抗训练中的过拟合现象之间存在关联，这影响了对抗样本的迁移性。为解决这一问题，我们提出了一种名为频率引导样本相关性攻击（Frequency-Guided Sample Relevance Attack, FGSRA）的新方法。具体而言，我们利用频率信息来探索不同模型间相似的敏感区域，从而生成邻域样本。随后，引入额外的相似性权重来评估这些邻域样本的对抗贡献。通过这种方式，我们获得了一种混合梯度，以充分挖掘输入样本中的邻域信息。广泛的实验结果表明，我们的方法表现出色。与基于代理模型Inc-v3的其他最先进基准相比，我们的方法在常规训练的CNNs上平均提升了27.21%，在对抗训练的CNNs上平均提升了42.1%。此外，我们在ViTs上也实现了平均24.6%的提升。我们的代码已公开，可访问：https://github.com/LMBTough/FGSRA。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Adversarial+Transferability+via+Frequency-Guided+Sample+Relevance+Attack)|0|
|[Image-text Retrieval with Main Semantics Consistency](https://doi.org/10.1145/3627673.3679619)|Yi Xie, Yangtao Wang, Yanzhao Xie, Xin Tan, Jingjing Li, Xiaocui Li, Weilong Peng, Maobin Tang, Meie Fang|University of Electronic Science and Technology of China, Chengdu, China; East China Normal University, Shanghai, China; School of Computer Science and Cyber Engineering, Guangzhou University, Guangzhou, China; Hunan University of Technology and Business, Changsha, China|Image-text retrieval (ITR) has been one of the primary tasks in cross-modal retrieval, serving as a crucial bridge between computer vision and natural language processing. Significant progress has been made to achieve global alignment and local alignment between images and texts by mapping images and texts into a common space to establish correspondences between these two modalities. However, the rich semantic content contained in each image may bring false matches, resulting in the matched text ignoring the main semantics but focusing on the secondary or other semantics of this image. To address this issue, this paper proposes a semantically optimized approach with a novel Main Semantics Consistency (MSC) loss function, which aims to rank the semantically most similar images (or texts) corresponding to the given query at the top position during the retrieval process. First, in each batch of image-text pairs, we separately compute (i) the image-image similarity, i.e., the similarity between every two images, (ii) the text-text similarity, i.e., the similarity between a group of texts (that belong to a certain image) and another group of texts (that belong to another image), and (iii) the image-text similarity, i.e., the similarity between each image and each text. Afterward, our proposed MSC effectively aligns the above image-image, image-text, and text-text similarity, since the main semantics of every two images will be highly close if their text descriptions remain highly semantically consistent. By this means, we can capture the main semantics of each image to be matched with its corresponding texts, prioritizing the semantically most related retrieval results. Extensive experiments on MSCOCO and FLICKR30K verify the superior performance of MSC compared with the SOTA image-text retrieval methods. The source code of this project is released at GitHub: https://github.com/xyi007/MSC.|图像-文本检索（ITR）一直是跨模态检索中的主要任务之一，作为连接计算机视觉和自然语言处理的关键桥梁。通过将图像和文本映射到共同空间以建立这两种模态之间的对应关系，已经取得了显著的进展，实现了图像与文本之间的全局对齐和局部对齐。然而，每张图像中丰富的语义内容可能会带来错误的匹配，导致匹配的文本忽略了主要语义，而聚焦于次要或其他语义。为了解决这一问题，本文提出了一种语义优化的方法，并引入了一种新颖的主语义一致性（MSC）损失函数，旨在检索过程中将语义上最相似的图像（或文本）排在给定查询结果的最前面。首先，在每一批图像-文本对中，我们分别计算（i）图像-图像相似度，即每两张图像之间的相似度；（ii）文本-文本相似度，即属于某张图像的一组文本与属于另一张图像的另一组文本之间的相似度；以及（iii）图像-文本相似度，即每张图像与每个文本之间的相似度。随后，我们提出的MSC有效地对齐了上述的图像-图像、图像-文本和文本-文本相似度，因为如果两张图像的文本描述在语义上保持高度一致，那么这两张图像的主要语义将会高度接近。通过这种方式，我们可以捕捉每张图像的主要语义，并将其与相应的文本匹配，优先考虑语义上最相关的检索结果。在MSCOCO和FLICKR30K上的大量实验验证了MSC相比最先进的图像-文本检索方法的优越性能。本项目的源代码已在GitHub上发布：https://github.com/xyi007/MSC。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Image-text+Retrieval+with+Main+Semantics+Consistency)|0|
|[Post-Quantum Searchable Encryption Supporting User-Authorization for Outsourced Data Management](https://doi.org/10.1145/3627673.3679522)|Shiyuan Xu, Yibo Cao, Xue Chen, Yu Guo, Yuer Yang, Fangda Guo, SiuMing Yiu|; School of Artificial Intelligence, Beijing Normal University, Beijing, China; School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China; Department of Computer Science, The University of Hong Kong, Hong Kong, China|With the widespread development of database systems, data security has become crucial when it comes to sharing among users and servers. A straightforward approach involves using searchable encryption to ensure the confidentiality of shared data. However, in certain scenarios, varying user tiers are granted disparate data searching privileges, and administrators need to restrict the searchability of ciphertexts to select users exclusively. To address this issue, public key encryption with authorized keyword search (PEAKS) was proposed, wherein solely authorized users possess the ability to conduct targeted keyword searches. Nonetheless, it is vulnerable to resist quantum computing attacks. As a result, research focusing on authorizing users to search for keywords while achieving quantum security is far-reaching. In this paper, we propose a lattice-based variant of PEAKS (L-PEAKS) that enables keyword dataset authorization for outsourced data management. Unlike existing schemes, our design incorporates identity-based encryption (IBE) to overcome the bottleneck of public key management. Besides, we utilize several lattice sampling algorithms to defend against attacks from quantum adversaries. Specifically, each authorized user must obtain a search privilege from an authority. The authority distributes an authorized token to the user within a specific time period, and the user generates a trapdoor for any authorized keywords. Our scheme is proven to be secure against IND-sID-CKA and T-EUF security in a quantum setting. We also conduct comprehensive evaluations on a commodity machine to assess completeness and provide theoretical complexity comparisons with existing state-of-the-art schemes.|随着数据库系统的广泛发展，数据安全在用户和服务器之间的共享过程中变得至关重要。一个直接的方法是使用可搜索加密来确保共享数据的机密性。然而，在某些情况下，不同的用户层级被授予不同的数据搜索权限，管理员需要将密文的可搜索性限制为仅对选定的用户开放。为了解决这个问题，提出了基于授权关键词搜索的公钥加密（PEAKS），其中只有授权用户能够进行目标关键词搜索。然而，这种方案易受量子计算攻击的影响。因此，研究授权用户进行关键词搜索同时实现量子安全的方案具有深远意义。本文提出了一种基于格的PEAKS变体（L-PEAKS），该变体支持外包数据管理的关键词数据集授权。与现有方案不同，我们的设计结合了基于身份的加密（IBE）来解决公钥管理的瓶颈问题。此外，我们利用多种格采样算法来防御量子敌手的攻击。具体而言，每个授权用户必须从权威机构获取搜索权限。权威机构在特定时间段内向用户分发授权令牌，用户为任何授权关键词生成陷门。我们的方案在量子环境下被证明对IND-sID-CKA和T-EUF安全是安全的。我们还对商用机器进行了全面的评估，以评估其完整性，并提供了与现有最先进方案的理论复杂度比较。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Post-Quantum+Searchable+Encryption+Supporting+User-Authorization+for+Outsourced+Data+Management)|0|
|[Decoupled Behavior-based Contrastive Recommendation](https://doi.org/10.1145/3627673.3679636)|Mengduo Yang, Jie Zhou, Meng Xi, Xiaohua Pan, Yi Yuan, Ying Li, Yangyang Wu, Jinshan Zhang, Jianwei Yin|; School of Software Technology, Zhejiang University, Ningbo, Zhejiang, China|Recommender systems are crucial tools in online applications, assisting users in discovering relevant content efficiently. Recent studies demonstrate that contrastive learning (CL) based methods yield significant results in collaborative filtering (CF) recommendations, due to their ability to address the issue of data sparsity. However, two inherent limitations remain unexplored in these methods. a) Since the datasets commonly used are binary (0: no interaction; 1: interaction), current methods only provide rudimentary modeling of user behaviors in binary form, which fails to model complex user-item interactions and relationships in real-world recommendation scenarios. b) Existing CL-based methods mostly construct contrastive views through heuristic-based embedding or structure perturbation, which are prone to introduce noise or discard important information, leading to a decreased representation quality. To address these issues, we propose a Decoupled Behavior-based Contrastive Recommendation model (DBCR) that effectively decouples user behaviors from binary datasets for better user-item interaction modeling. The core idea is to decouple latent user behaviors from unlabelled user-item interactions (binary datasets) and utilize self-supervised contrastive learning to optimize CF-based recommendation jointly. Specifically, we introduce latent behavior variables and embed them into user-item interaction modeling within the generalized expectation-maximization (EM) framework. Moreover, we design a contrastive learning task by constructing a preference view instead of unreasonable perturbation to further improve the learned representation. Experimental results and analyses on three real-world datasets demonstrate the effectiveness of DBCR and its high efficiency, with an average improvement of 16.9% over state-of-the-art methods. Our code is available on https://github.com/Du-danger/DBCR.|推荐系统是在线应用中的关键工具，能够帮助用户高效地发现相关内容。最近的研究表明，基于对比学习（Contrastive Learning, CL）的方法在协同过滤（Collaborative Filtering, CF）推荐中取得了显著成果，这主要归功于它们解决数据稀疏性问题的能力。然而，这些方法存在两个内在限制尚未得到充分探讨。a) 由于常用的数据集通常是二值的（0：无交互；1：有交互），当前的方法仅以二值形式对用户行为进行初步建模，未能捕捉真实推荐场景中复杂的用户-物品交互和关系。b) 现有的基于CL的方法大多通过启发式嵌入或结构扰动来构建对比视图，这容易引入噪声或丢弃重要信息，导致表示质量下降。为了解决这些问题，我们提出了一种解耦行为对比推荐模型（Decoupled Behavior-based Contrastive Recommendation model, DBCR），该模型有效地将用户行为从二值数据集中解耦，以更好地建模用户-物品交互。其核心思想是将潜在用户行为从无标签的用户-物品交互（二值数据集）中解耦，并利用自监督对比学习来联合优化基于CF的推荐。具体来说，我们引入了潜在行为变量，并在广义期望最大化（EM）框架内将其嵌入到用户-物品交互建模中。此外，我们设计了一个对比学习任务，通过构建偏好视图而非不合理的扰动来进一步提高学习到的表示质量。在三个真实世界数据集上的实验结果和分析表明，DBCR的有效性和高效性，平均比最先进的方法提高了16.9%。我们的代码可在https://github.com/Du-danger/DBCR获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Decoupled+Behavior-based+Contrastive+Recommendation)|0|
|[Hyperbolic Contrastive Learning for Cross-Domain Recommendation](https://doi.org/10.1145/3627673.3679572)|Xin Yang, Heng Chang, Zhijian Lai, Jinze Yang, Xingrun Li, Yu Lu, Shuaiqiang Wang, Dawei Yin, Erxue Min|University of Tsukuba, Tsukuba, Japan; Baidu Inc., Beijing, China; University of Tokyo, Tokyo, Japan; Kyoto University, Kyoto, Japan; Peking University, Beijing, China; Tsinghua University, Beijing, China|Cross-Domain Recommendation (CDR) seeks to utilize knowledge from different domains to alleviate the problem of data sparsity in the target recommendation domain, and has been gaining more attention in recent years. Although there have been notable advances in this area, most current methods represent users and items in Euclidean space, which is not ideal for handling long-tail distributed data in recommendation systems. Additionally, adding data from other domains can worsen the long-tail characteristics of the entire dataset, making it harder to train CDR models effectively. Recent studies have shown that hyperbolic methods are particularly suitable for modeling long-tail distributions, which has led us to explore hyperbolic representations for users and items in CDR scenarios. However, due to the distinct characteristics of the different domains, applying hyperbolic representation learning to CDR tasks is quite challenging. In this paper, we introduce a new framework called Hyperbolic Contrastive Learning (HCTS), designed to capture the unique features of each domain while enabling efficient knowledge transfer between domains. We achieve this by embedding users and items from each domain separately and mapping them onto distinct hyperbolic manifolds with adjustable curvatures for prediction. To improve the representations of users and items in the target domain, we develop a hyperbolic contrastive learning module for knowledge transfer. Extensive experiments on real-world datasets demonstrate that hyperbolic manifolds are a promising alternative to Euclidean space for CDR tasks. The codes are available at https://github.com/EnkiXin/hcts.|跨域推荐（CDR）旨在利用不同领域的知识来缓解目标推荐领域中的数据稀疏问题，近年来受到越来越多的关注。尽管在这一领域取得了显著进展，但大多数现有方法将用户和物品表示在欧几里得空间中，这对于处理推荐系统中的长尾分布数据并不理想。此外，添加其他领域的数据可能会加剧整个数据集的长尾特性，使得有效训练CDR模型变得更加困难。最近的研究表明，双曲方法特别适合于建模长尾分布，这促使我们探索在CDR场景中使用双曲表示用户和物品。然而，由于不同领域的特性各异，将双曲表示学习应用于CDR任务相当具有挑战性。在本文中，我们引入了一种称为双曲对比学习（HCTS）的新框架，旨在捕捉每个领域的独特特征，同时实现领域间高效的知识转移。我们通过将每个领域的用户和物品分别嵌入，并将它们映射到具有可调曲率的独立双曲流形上进行预测来实现这一点。为了改进目标领域中用户和物品的表示，我们开发了一个双曲对比学习模块用于知识转移。在真实世界数据集上的广泛实验表明，双曲流形是CDR任务中欧几里得空间的一个有前景的替代方案。代码可在https://github.com/EnkiXin/hcts获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hyperbolic+Contrastive+Learning+for+Cross-Domain+Recommendation)|0|
|[Guaranteeing Accuracy and Fairness under Fluctuating User Traffic: A Bankruptcy-Inspired Re-ranking Approach](https://doi.org/10.1145/3627673.3679590)|Xiaopeng Ye, Chen Xu, Jun Xu, Xuyang Xie, Gang Wang, Zhenhua Dong||Out of sustainable and economical considerations, two-sided recommendation platforms must satisfy the needs of both users and providers. Previous studies often show that the two sides' needs show different urgency: providers need a relatively long-term exposure demand while users want more short-term and accurate service. However, our empirical study reveals that previous methods for trading off fairness-accuracy often fail to guarantee long-term fairness and short-term accuracy simultaneously in real applications of fluctuating user traffic. Especially, when user traffic is low, the user experience often drops a lot. Our theoretical analysis also confirms that user traffic is a key factor in such a trade-off problem. How to guarantee accuracy and fairness under fluctuating user traffic remains a problem. Inspired by the bankruptcy problem in economics, we propose a novel fairness-aware re-ranking approach named BankFair. Intuitively, BankFair employs the Talmud rule to leverage periods of abundant user traffic to offset periods of user traffic scarcity, ensuring consistent user service at every period while upholding long-term fairness. Specifically, BankFair consists of two modules: (1) employing the Talmud rule to determine the required fairness degree under varying periods of user traffic; and (2) conducting an online re-ranking algorithm based on the fairness degree determined by the Talmud rule. Experiments on two real-world recommendation datasets show that BankFair outperforms all baselines regarding accuracy and provider fairness.|出于可持续性和经济性的考虑，双边推荐平台必须同时满足用户和提供者的需求。以往的研究通常表明，双方的需求显示出不同的紧迫性：提供者需要相对长期的曝光需求，而用户则希望获得更多短期且准确的服务。然而，我们的实证研究揭示，先前用于权衡公平性与准确性的方法在面对用户流量波动的实际应用中，往往无法同时保证长期的公平性和短期的准确性。特别是在用户流量较低时，用户体验往往会大幅下降。我们的理论分析也证实，用户流量是此类权衡问题中的关键因素。如何在用户流量波动的情况下保证准确性和公平性仍然是一个问题。受经济学中破产问题的启发，我们提出了一种名为BankFair的新型公平感知重排序方法。直观上，BankFair利用用户流量充足期来弥补用户流量稀缺期，通过使用塔木德规则确保每个时期用户服务的连续性，同时维护长期的公平性。具体而言，BankFair包含两个模块：（1）利用塔木德规则确定在不同用户流量时期所需的公平性程度；（2）基于塔木德规则确定的公平性程度进行在线重排序算法。在两个真实世界推荐数据集上的实验表明，BankFair在准确性和提供者公平性方面均优于所有基线方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Guaranteeing+Accuracy+and+Fairness+under+Fluctuating+User+Traffic:+A+Bankruptcy-Inspired+Re-ranking+Approach)|0|
|[EFVAE: Efficient Federated Variational Autoencoder for Collaborative Filtering](https://doi.org/10.1145/3627673.3679818)|Lu Zhang, Qian Rong, Xuanang Ding, Guohui Li, Ling Yuan|Huazhong University of Science and Technology, Wuhan, China|Federated recommender systems are used to address privacy issues in recommendations. Among them, FedVAE extends the representative non-linear recommendation method MultVAE. However, the bottleneck of FedVAE lies in its communication load during training, as the parameter volume of its first and last layers is correlated with the number of items. This leads to significant communication cost during the model's transmission phases (distribution and upload), making FedVAE's implementation extremely challenging. To address these challenges, we propose an Efficient Federated Variational AutoEncoder for collaborative filtering, EFVAE, which core is the Federated Collaborative Importance Sampling (FCIS) method. FCIS reduces communication costs through a client-to-server collaborative sampling mechanism and provides satisfactory recommendation performance through dynamic multi-stage approximation of the decoding distribution. Extensive experiments and analyses on real-world datasets confirm that EFVAE significantly reduces communication costs by up to 94.51% while maintaining the recommendation performance. Moreover, its recommendation performance is better on sparse datasets, with improvements reaching up to 13.79%.|联邦推荐系统用于解决推荐中的隐私问题。其中，FedVAE扩展了代表性的非线性推荐方法MultVAE。然而，FedVAE的瓶颈在于其训练过程中的通信负载，因为其第一层和最后一层的参数体积与项目数量相关。这导致模型传输阶段（分发和上传）的通信成本显著增加，使得FedVAE的实现极为困难。为了应对这些挑战，我们提出了一种高效的联邦变分自编码器用于协同过滤，EFVAE，其核心是联邦协同重要性采样（FCIS）方法。FCIS通过客户端到服务器的协同采样机制减少通信成本，并通过解码分布的动态多阶段近似提供令人满意的推荐性能。在真实世界数据集上的广泛实验和分析证实，EFVAE显著减少了高达94.51%的通信成本，同时保持了推荐性能。此外，它在稀疏数据集上的推荐性能更好，提升幅度最高可达13.79%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EFVAE:+Efficient+Federated+Variational+Autoencoder+for+Collaborative+Filtering)|0|
|[MSKR: Advancing Multi-modal Structured Knowledge Representation with Synergistic Hard Negative Samples](https://doi.org/10.1145/3627673.3679680)|Shuili Zhang, Hongzhang Mu, Tingwen Liu, Qianqian Tong, Jiawei Sheng|; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China|Despite the notable progress achieved by large-scale vision-language pre-training models in a wide range of multi-modal tasks, their performance often falls short in image-text matching challenges that require an in-depth understanding of structured representations. For instance, when distinguishing between texts or images that are generally similar but have distinct structured knowledge (such as entities and relationships in text, or objects and object attributes in images), the model's capabilities are limited. In this paper, we propose a advancing Multi-modal Structured Knowledge Representation with synergistic hard negative samples (MSKR), thereby significantly improving the model's matching capability for such data. Specifically, our model comprises a structured knowledge-enhanced encoder designed to bolster the structured knowledge inherent in textual data, such as entities, their attributes, and the relationships among these entities as well as structured knowledge within images, focusing on elements like objects and their attributes. To further refine the model's learning process, we produce both image and text challenging negative samples. Extensive experimental evaluations on the Winoground, InpaintCOCO, and MSCOCO benchmark reveal that MSKR significantly outperforms the baseline model, showcasing marked improvements 2.66% on average in structured representation learning compared to the baseline. Moreover, general representation results illustrate that our model not only excels in structured representation learning but also maintains its proficiency in general representation learning.|尽管大规模视觉-语言预训练模型在多模态任务中取得了显著进展，但在需要深入理解结构化表示的图像-文本匹配挑战中，其表现往往不尽如人意。例如，在区分文本或图像时，当这些文本或图像总体相似但具有不同的结构化知识（如文本中的实体及其关系，或图像中的对象及其属性）时，模型的能力受到限制。本文提出了一种通过协同硬负样本推进多模态结构化知识表示（MSKR）的方法，从而显著提升了模型对这类数据的匹配能力。具体而言，我们的模型包括一个结构化知识增强的编码器，旨在强化文本数据中固有的结构化知识，如实体、实体属性及其关系，以及图像中关注对象及其属性的结构化知识。为了进一步优化模型的学习过程，我们生成了图像和文本的挑战性负样本。在Winoground、InpaintCOCO和MSCOCO基准上的广泛实验评估表明，MSKR显著优于基线模型，与基线相比，在结构化表示学习中平均提高了2.66%。此外，通用表示结果显示，我们的模型不仅在结构化表示学习中表现出色，而且在通用表示学习中也保持了其熟练度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MSKR:+Advancing+Multi-modal+Structured+Knowledge+Representation+with+Synergistic+Hard+Negative+Samples)|0|
|[Watermarking Recommender Systems](https://doi.org/10.1145/3627673.3679617)|Sixiao Zhang, Cheng Long, Wei Yuan, Hongxu Chen, Hongzhi Yin||Recommender systems embody significant commercial value and represent crucial intellectual property. However, the integrity of these systems is constantly challenged by malicious actors seeking to steal their underlying models. Safeguarding against such threats is paramount to upholding the rights and interests of the model owner. While model watermarking has emerged as a potent defense mechanism in various domains, its direct application to recommender systems remains unexplored and non-trivial. In this paper, we address this gap by introducing Autoregressive Out-of-distribution Watermarking (AOW), a novel technique tailored specifically for recommender systems. Our approach entails selecting an initial item and querying it through the oracle model, followed by the selection of subsequent items with small prediction scores. This iterative process generates a watermark sequence autoregressively, which is then ingrained into the model's memory through training. To assess the efficacy of the watermark, the model is tasked with predicting the subsequent item given a truncated watermark sequence. Through extensive experimentation and analysis, we demonstrate the superior performance and robust properties of AOW. Notably, our watermarking technique exhibits high-confidence extraction capabilities and maintains effectiveness even in the face of distillation and fine-tuning processes.|推荐系统具有显著的商业价值，并代表着重要的知识产权。然而，这些系统的完整性不断受到恶意行为者的挑战，他们试图窃取其底层模型。保护这些系统免受此类威胁对于维护模型所有者的权益至关重要。尽管模型水印技术在多个领域已成为一种强大的防御机制，但将其直接应用于推荐系统仍未得到探索且具有挑战性。在本文中，我们通过引入自回归分布外水印技术（Autoregressive Out-of-distribution Watermarking, AOW）来填补这一空白，这是一种专为推荐系统量身定制的新技术。我们的方法包括选择初始项目并通过oracle模型查询，随后选择具有较小预测分数的后续项目。这一迭代过程自回归地生成水印序列，然后通过训练将其嵌入模型的记忆中。为了评估水印的有效性，模型被要求在给定截断水印序列的情况下预测后续项目。通过广泛的实验和分析，我们展示了AOW的优越性能和鲁棒特性。值得注意的是，我们的水印技术表现出高置信度的提取能力，并且在面对蒸馏和微调过程时仍能保持有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Watermarking+Recommender+Systems)|0|
|[Multi-modal Food Recommendation with Health-aware Knowledge Distillation](https://doi.org/10.1145/3627673.3679580)|Yixin Zhang, Xin Zhou, Fanglin Zhu, Ning Liu, Wei Guo, Yonghui Xu, Zhiqi Shen, Lizhen Cui|Shandong University, Jinan, China; Nanyang Technological University, Singapore, Singapore|Food recommendation systems play a pivotal role in shaping dietary salubrity and fostering sustainable lifestyles by recommending recipes and foodstuffs that align with user preferences. Metadata information of a recipe, encompassing multi-modal descriptions, constituent ingredients, and health-related attributes, can furnish a more holistic perspective on the recipe's profile, thereby augmenting recommendation performance. However, existing state-of-the-art methods often overlook the inherent interdependencies between modalities, ingredients, and health factors, leaving the health information pertaining to recipe characteristics underexploited. Notably, our preliminary investigation on two datasets unveiled that the semantic divergence between health-related knowledge and collaborative filtering signals is more pronounced in comparison to other metadata information, thereby potentially impeding the efficacy of food recommendation systems. To address these limitations, we propose HealthRec, a novel multi-modal food recommendation framework with health-aware knowledge distillation. HealthRec employs a global graph representation learning module to capture high-order dependencies across diverse food-related relations, enriching the representations. Subsequently, a co-attention network is leveraged to capture local, recipe-level knowledge transfer between modality-related and ingredient-related embeddings. Additionally, we exploit external supervision signals derived from WHO recommendations, utilizing knowledge distillation during the training phase to transfer local health-aware knowledge into global collaborative embeddings. Extensive experimentation on real-world datasets demonstrates HealthRec's superiority compared to current state-of-the-art recommendation baselines, highlighting its effectiveness in modeling health-aware food recommendations.|食物推荐系统在通过推荐符合用户偏好的食谱和食品来塑造饮食健康和促进可持续生活方式方面发挥着关键作用。食谱的元数据信息，包括多模态描述、成分成分和健康相关属性，可以提供关于食谱特征的更全面视角，从而增强推荐性能。然而，现有的最先进方法往往忽视了模态、成分和健康因素之间的固有相互依赖性，导致与食谱特征相关的健康信息未得到充分利用。值得注意的是，我们初步研究的两个数据集揭示了健康相关知识与协同过滤信号之间的语义差异相较于其他元数据信息更为显著，这可能阻碍食物推荐系统的有效性。为了解决这些限制，我们提出了HealthRec，一种新颖的多模态食物推荐框架，结合了健康意识的知识蒸馏。HealthRec采用全局图表示学习模块来捕捉跨多种食物相关关系的高阶依赖性，丰富表示内容。随后，利用协同注意力网络来捕捉模态相关和成分相关嵌入之间的局部、食谱级别知识传递。此外，我们利用来自世界卫生组织建议的外部监督信号，在训练阶段通过知识蒸馏将局部健康意识知识传递到全局协同嵌入中。在真实世界数据集上的广泛实验表明，HealthRec相较于当前最先进的推荐基线具有优越性，突显了其在建模健康意识食物推荐方面的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-modal+Food+Recommendation+with+Health-aware+Knowledge+Distillation)|0|
|[Preference Prototype-Aware Learning for Universal Cross-Domain Recommendation](https://doi.org/10.1145/3627673.3679774)|Yuxi Zhang, Ji Zhang, Feiyang Xu, Lvying Chen, Bohan Li, Lei Guo, Hongzhi Yin|; College of Computer Science and Technology, Shandong Normal University, Jinan, China; Polytechnic Institute, Zhejiang University, Hangzhou, China|Cross-domain recommendation (CDR) aims to suggest items from new domains that align with potential user preferences, based on their historical interactions. Existing methods primarily focus on acquiring item representations by discovering user preferences under specific, yet possibly redundant, item features. However, user preferences may be more strongly associated with interacted items at higher semantic levels, rather than specific item features. Consequently, this item feature-focused recommendation approach can easily become suboptimal or even obsolete when conducting CDR with disturbances of these redundant features. In this paper, we propose a novel Preference Prototype-Aware (PPA) learning method to quantitatively learn user preferences while minimizing disturbances from the source domain. The PPA framework consists of two complementary components: a mix-encoder and a preference prototype-aware decoder, forming an end-to-end unified framework suitable for various real-world scenarios. The mix-encoder employs a mix-network to learn better general representations of interacted items and capture the intrinsic relationships between items across different domains. The preference prototype-aware decoder implements a learnable prototype matching mechanism to quantitatively perceive user preferences, which can accurately capture user preferences at a higher semantic level. This decoder can also avoid disturbances caused by item features from the source domain. The experimental results on public benchmark datasets in different scenarios demonstrate the superiority of the proposed PPA learning method compared to state-of-the-art counterparts. PPA excels not only in providing accurate recommendations but also in offering reliable preference prototypes. Our code is available at https://github.com/zyx-nuaa/PPA-for-CDR.|跨域推荐（CDR）旨在根据用户的历史交互行为，向他们推荐来自新领域的符合其潜在偏好的项目。现有方法主要集中在通过在特定但可能冗余的项目特征下发现用户偏好来获取项目表示。然而，用户偏好可能更多地与高语义层次上的交互项目相关联，而不是特定的项目特征。因此，这种以项目特征为中心的推荐方法在进行跨域推荐时，当遇到这些冗余特征的干扰时，很容易变得次优甚至失效。本文提出了一种新的偏好原型感知（PPA）学习方法，该方法在最小化源域干扰的同时，定量学习用户偏好。PPA框架由两个互补组件组成：一个混合编码器和一个偏好原型感知解码器，形成一个适用于各种现实场景的端到端统一框架。混合编码器采用混合网络来学习交互项目的更好泛化表示，并捕捉不同领域项目之间的内在关系。偏好原型感知解码器实现了一个可学习的原型匹配机制，以定量感知用户偏好，能够准确捕捉用户在高语义层次上的偏好。该解码器还能避免来自源域项目特征的干扰。在不同场景的公共基准数据集上的实验结果表明，所提出的PPA学习方法相比现有最先进的方法具有优越性。PPA不仅在提供准确推荐方面表现出色，还能提供可靠的偏好原型。我们的代码可在https://github.com/zyx-nuaa/PPA-for-CDR获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Preference+Prototype-Aware+Learning+for+Universal+Cross-Domain+Recommendation)|0|
|[Multi-Task Modeling of Student Knowledge and Behavior](https://doi.org/10.1145/3627673.3679823)|Siqian Zhao, Sherry Sahebi|Department of Computer Science, University at Albany - SUNY, Albany, NY, USA|Knowledge Tracing (KT) and Behavior Modeling (BM) are essential mining and discovery problems in education. KT models student knowledge based on prior performance with learning materials, while BM focuses on patterns such as student preferences, engagement, and procrastination. Traditional research in these areas focuses on each task individually, thereby overlooking their interconnections. However, recent research on multi-activity knowledge tracing suggests that student preferences for learning materials are key to understanding student learning. In this paper, we propose a novel multi-task model, the Multi-Task Student Knowledge and Behavior Model (KTBM), which combines KT and BM to improve both performance and interoperability. KTBM includes a multi-activity KT component and a preference behavior component while enabling robust information transfer between them. We conceptualize this approach as a multi-task learning problem with two objectives: predicting students' performance and their choices concerning learning material types. To address this dual-objective challenge, we employ a Pareto multi-task learning optimization algorithm. Our experiments on three real-world datasets show that KTBM significantly enhances both KT and BM performance, demonstrating improvement across various settings and providing interpretable results.|知识追踪（KT）和行为建模（BM）是教育领域中重要的挖掘与发现问题。KT根据学生先前在学习材料上的表现来模型化学生的知识水平，而BM则关注学生的偏好、参与度及拖延等模式。传统研究往往单独处理这些任务，忽略了它们之间的关联。然而，近期关于多活动知识追踪的研究表明，学生对学习材料的偏好是理解其学习行为的关键。本文中，我们提出了一种新颖的多任务模型——多任务学生知识与行为模型（KTBM），该模型结合了KT和BM，旨在提升性能与互操作性。KTBM包含一个多活动KT组件和一个偏好行为组件，并支持两者之间的信息稳健传递。我们将这一方法构想为一个具有两个目标的多任务学习问题：预测学生的表现及其对学习材料类型的选择。为应对这一双重目标挑战，我们采用了帕累托多任务学习优化算法。我们在三个真实世界数据集上的实验表明，KTBM显著提升了KT和BM的性能，展示了在各种情境下的改进，并提供了可解释的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Task+Modeling+of+Student+Knowledge+and+Behavior)|0|
|[Accurate Embedding-based Log Determinant Optimization](https://doi.org/10.1145/3627673.3679871)|Daye Eun, Byungkon Kang|SUNY Korea, Incheon, Republic of Korea; MagicFinger, Incheon, Republic of Korea|Many tangible and intangible objects are represented as itemsets; i.e., composition of individual items. In this paper, we address the problem of finding the embedding of such items so as to use those embeddings in tasks like missing item prediction. We approach this problem by means of determinantal point process (DPP) in order to reflect the diversity within each set. Doing so requires an optimization of a log determinant of a symmetric positive definite (SPD) matrix. The standard practice to achieve this is to perform a low-rank decomposition of the matrix and derive update rules for the low rank matrix. In this work, we propose to approach this problem by means of item embedding. That is, we will learn the SPD matrix by trying to find the right vector representations for the given data for a fixed kernel function. To this end, we propose a novel algorithm to accurately compute the gradients of the log determinant with respect to the embedding vectors. We also show that our approach outperforms Autodiff-based learning in terms of gradient direction and running time, and that other general log determinant optimization problems can be addressed.|许多有形和无形的物体被表示为项集；即，由单个项组成的组合。本文中，我们解决了为这些项寻找嵌入的问题，以便在诸如缺失项预测等任务中使用这些嵌入。我们通过行列式点过程（DPP）来解决这个问题，以反映每个集合内的多样性。这样做需要对对称正定（SPD）矩阵的对数行列式进行优化。实现这一目标的标准做法是对矩阵进行低秩分解，并推导出低秩矩阵的更新规则。在这项工作中，我们提出通过项嵌入的方式来解决这个问题。也就是说，我们将通过尝试为给定数据找到适当的向量表示来学习SPD矩阵，对于一个固定的核函数。为此，我们提出了一种新的算法，能够准确计算对数行列式相对于嵌入向量的梯度。我们还表明，我们的方法在梯度方向和运行时间方面优于基于自动微分的学习，并且可以解决其他一般性的对数行列式优化问题。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Accurate+Embedding-based+Log+Determinant+Optimization)|0|
|[Knowledge-enhanced Dynamic Modeling framework for Multi-Behavior Recommendation](https://doi.org/10.1145/3627673.3679949)|Xiujuan Li, Nan Wang, Jin Zeng, Yingli Zhong, Zhonghui Shen|Heilongjiang University, Harbin, China|Multi-behavior recommendation (MBR) aims at predicting the items that the user will interact with at the next moment through the target behavior. Most existing MBR models are devoted to designing novel graph convolutional networks to combine multi-behavioral information. However, they ignore the negative impact of auxiliary behaviours, and also fail to take into account the effects of item characteristics. These limitations can lead to model performance degradation and affect user satisfaction. To address these issues, we propose a Knowledge-enhanced Dynamic Modeling framework for Multi-Behavior Recommendation (KDMBR). The algorithm utilises a multi-behavioral interaction module and a knowledge graph module to capture the user's overall interest and feature information respectively. The former designs a behavior-aware attention to distinguish contributions between behaviors. The latter introduces KG to enrich item characteristics and proposes a graph reconstruction strategy to enrich user information. Experiments on two large datasets further demonstrate the effectiveness of KDMBR.|多行为推荐（MBR）旨在通过目标行为预测用户在下一时刻将与之交互的项目。大多数现有的MBR模型致力于设计新颖的图卷积网络以结合多行为信息。然而，这些模型忽视了辅助行为的负面影响，也未能考虑到项目特征的影响。这些局限性可能导致模型性能下降并影响用户满意度。为了解决这些问题，我们提出了一个知识增强的动态建模框架，用于多行为推荐（KDMBR）。该算法利用多行为交互模块和知识图谱模块分别捕捉用户的整体兴趣和特征信息。前者设计了一种行为感知的注意力机制来区分不同行为之间的贡献。后者引入了知识图谱（KG）来丰富项目特征，并提出了一种图重建策略来丰富用户信息。在两个大型数据集上的实验进一步证明了KDMBR的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge-enhanced+Dynamic+Modeling+framework+for+Multi-Behavior+Recommendation)|0|
|[Multi-DSI: Non-deterministic Identifier and Concept Alignment for Differentiable Search Index](https://doi.org/10.1145/3627673.3679971)|YuZe Liu, JyunYu Jiang, PuJen Cheng|National Taiwan University, Taipei, Taiwan; Amazon Search, Palo Alto, CA, USA|With the advent of generative deep learning models, generative IR has gained increasing attention. However, existing methods face two issues: (1) when a document is represented by a single semantic ID, the retrieval model may fail to capture the multifaceted and complex content of the document; and (2) when the generated training data exhibits semantic ambiguity, the retrieval model may struggle to distinguish the differences in the content of similar documents. To address these issues, we propose Multi-DSI to (1) offer multiple non-deterministic semantic identifiers and (2) align the concepts of queries and documents to avoid ambiguity. Extensive experiments on two benchmark datasets demonstrate that Multi-DSI significantly outperforms baseline methods by 7.4%.|随着生成式深度学习模型的兴起，生成式信息检索（IR）受到了越来越多的关注。然而，现有方法面临两个问题：（1）当文档由单一的语义ID表示时，检索模型可能无法捕捉到文档多面且复杂的内容；（2）当生成的训练数据存在语义模糊时，检索模型可能难以区分相似文档内容的差异。为解决这些问题，我们提出了多维度语义标识符（Multi-DSI），以（1）提供多个非确定性的语义标识符，并（2）对齐查询与文档的概念，以避免语义模糊。在两个基准数据集上的广泛实验表明，Multi-DSI显著优于基线方法，性能提升了7.4%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-DSI:+Non-deterministic+Identifier+and+Concept+Alignment+for+Differentiable+Search+Index)|0|
|[Do We Really Need to Drop Items with Missing Modalities in Multimodal Recommendation?](https://doi.org/10.1145/3627673.3679898)|Daniele Malitesta, Emanuele Rossi, Claudio Pomo, Tommaso Di Noia, Fragkiskos D. Malliaros||Generally, items with missing modalities are dropped in multimodal recommendation. However, with this work, we question this procedure, highlighting that it would further damage the pipeline of any multimodal recommender system. First, we show that the lack of (some) modalities is, in fact, a widely-diffused phenomenon in multimodal recommendation. Second, we propose a pipeline that imputes missing multimodal features in recommendation by leveraging traditional imputation strategies in machine learning. Then, given the graph structure of the recommendation data, we also propose three more effective imputation solutions that leverage the item-item co-purchase graph and the multimodal similarities of co-interacted items. Our method can be plugged into any multimodal RSs in the literature working as an untrained pre-processing phase, showing (through extensive experiments) that any data pre-filtering is not only unnecessary but also harmful to the performance.|通常，在多模态推荐中，会丢弃缺少模态的项。然而，通过这项工作，我们质疑这一做法，强调这将进一步损害任何多模态推荐系统的流程。首先，我们展示了在多模态推荐中，某些模态的缺失实际上是一个普遍存在的现象。其次，我们提出了一种流程，通过利用机器学习中的传统插补策略来填补推荐中缺失的多模态特征。然后，鉴于推荐数据的图结构，我们还提出了三种更有效的插补解决方案，这些方案利用了物品间共同购买图和共同交互物品的多模态相似性。我们的方法可以插入到任何现有的多模态推荐系统中，作为一个未经训练的预处理阶段，通过广泛的实验表明，任何数据预过滤不仅是不必要的，而且对性能有害。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Do+We+Really+Need+to+Drop+Items+with+Missing+Modalities+in+Multimodal+Recommendation?)|0|
|[SOUP: A Unified Shopping Query Suggestion Framework to Optimize Language Model with User Preference](https://doi.org/10.1145/3627673.3679995)|Xu Meng, Zhaohui Luo, Xinxin Wang, Wen Jiang, Wei Ning, Shuhan Qi|Harbin Institute of Technology, Shenzhen, Shenzhen, China; Alibaba Group, Hangzhou, China|The shopping query suggestion offers personalized queries to users and plays a crucial role in search engines. However, existing shopping query suggestion methods suffer from poor task generalization and limited semantic comprehension problems. This paper presents a comprehensive framework for the shopping query suggestion that effectively addresses the shortcomings of existing approaches. Our proposed framework leverages a generative language model and fine-grained preference alignment to enhance semantic comprehension and improve the quality of generated queries. Our key contributions include the introduction of a personalized prompt set for diverse query suggestion tasks, the integration of interaction behavior time to capture user query interests, and the utilization of reinforcement learning techniques to align user preferences. Experimental results demonstrate enhancements in different scenarios. Our codes are available at https://github.com/1170300319/CIKM2024_SOUP.|购物查询建议为用户提供个性化的查询，并在搜索引擎中发挥关键作用。然而，现有的购物查询建议方法存在任务泛化性差和语义理解有限的问题。本文提出了一种全面的购物查询建议框架，有效解决了现有方法的不足。我们提出的框架利用生成式语言模型和细粒度偏好对齐来增强语义理解，并提高生成查询的质量。我们的主要贡献包括引入个性化提示集以应对多样化的查询建议任务，整合交互行为时间以捕捉用户的查询兴趣，以及利用强化学习技术来对齐用户偏好。实验结果显示在不同场景下均有改进。我们的代码可在 https://github.com/1170300319/CIKM2024_SOUP 获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SOUP:+A+Unified+Shopping+Query+Suggestion+Framework+to+Optimize+Language+Model+with+User+Preference)|0|
|[LayerPlexRank: Exploring Node Centrality and Layer Influence through Algebraic Connectivity in Multiplex Networks](https://doi.org/10.1145/3627673.3679950)|Hao Ren, Jiaojiao Jiang||As the calculation of centrality in complex networks becomes increasinglyvital across technological, biological, and social systems, precise andscalable ranking methods are essential for understanding these networks. Thispaper introduces LayerPlexRank, an algorithm that simultaneously assesses nodecentrality and layer influence in multiplex networks using algebraicconnectivity metrics. This method enhances the robustness of the rankingalgorithm by effectively assessing structural changes across layers usingrandom walk, considering the overall connectivity of the graph. We substantiatethe utility of LayerPlexRank with theoretical analyses and empiricalvalidations on varied real-world datasets, contrasting it with establishedcentrality measures.|随着复杂网络中中心性计算在技术、生物和社会系统中的日益重要，精确且可扩展的排序方法对于理解这些网络至关重要。本文介绍了LayerPlexRank算法，该算法利用代数连通性指标在多层网络中同时评估节点中心性和层级影响。通过使用随机游走有效评估跨层的结构变化，并考虑图的整体连通性，这种方法增强了排序算法的鲁棒性。我们通过理论分析和在不同真实世界数据集上的实证验证，证明了LayerPlexRank的实用性，并与现有的中心性度量方法进行了对比。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LayerPlexRank:+Exploring+Node+Centrality+and+Layer+Influence+through+Algebraic+Connectivity+in+Multiplex+Networks)|0|
|[Osprey 🪶: A Reference Framework for Online Grooming Detection via Neural Models and Conversation Features](https://doi.org/10.1145/3627673.3679974)|Hamed Waezi, Reza Barzegar, Hossein Fani|School of Computer Science, University of Windsor, Windsor, ON, Canada|Online grooming is the process of an adult initiating a sexual relationship with a minor through online conversation platforms. While neural models are developed to detect such incidents, their practical implications in real-world settings remain moot for their closed, irreproducible, and poor evaluation methodologies under the sparse distribution of grooming conversations in the training datasets, like undermining recall over precision. Furthermore, proposed models overlook characteristic features of grooming in online conversations, including the number of participants, message exchange patterns, and temporal signals, such as the elapsed times between messages. In this paper, we foremost contribute Osprey, an open-source library to support a standard pipeline and experimental details, incorporating canonical neural models and a variety of vector representation learning for conversations while accommodating new models and training datasets. Further, we incorporate conversation features into the models to improve recall while maintaining precision. Our experiments across neural baselines and vector representations of conversations demonstrated that recurrent neural models, particularly gru, on the sequence of pretrained transformer-based embeddings of messages in a conversation along with conversation features obtain state-of-the-art performance, winning the best recall with competitive precision. Osprey is available at https://github.com/fani-lab/Osprey/tree/cikm24.|在线“狩猎”是指成年人通过在线聊天平台与未成年人建立性关系的过程。尽管已开发出神经模型来检测此类事件，但由于训练数据集中“狩猎”对话的分布稀疏，这些模型在实际应用中的效果仍不明确，其封闭、不可复现且评估方法不当的问题削弱了召回率而偏重精度。此外，现有模型忽视了在线对话中“狩猎”行为的特征，如参与者数量、消息交换模式及时间信号（如消息之间的时间间隔）。本文首先贡献了Osprey，一个开源库，支持标准流程和实验细节，整合了经典的神经模型和多种对话向量表示学习方法，并兼容新模型和训练数据集。进一步，我们将对话特征融入模型，以提高召回率的同时保持精度。我们的实验表明，在神经基线和对话向量表示中，基于预训练变换器嵌入的消息序列及对话特征的循环神经模型，特别是GRU，取得了最先进的性能，获得了最佳召回率并保持了竞争力的精度。Osprey可通过以下链接获取：https://github.com/fani-lab/Osprey/tree/cikm24。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Osprey+🪶:+A+Reference+Framework+for+Online+Grooming+Detection+via+Neural+Models+and+Conversation+Features)|0|
|[The Effect of Icon Semantic Distance on Preschool Children's Information Search: Evidence from an Eye-Tracking Study](https://doi.org/10.1145/3627673.3680001)|Jiaqi Yang, Pianran Wang|Department of Information Management, Peking University, Beijing, China|Icons are frequently employed in children-oriented information systems due to children's limited literacy. However, the inherent semantic distances of icons, which may influence their affordance to children, are often overlooked in the development of such systems and related research. In this study, we apply semantic distance to measure the explicitness of icons in children-oriented book search, utilizing self-developed icons tailored for indexing picture books. We first gathered data from children through questionnaires to assess the perceived semantic distance of each icon. Subsequently, we conducted eye-tracking experiments with 50 preschool children, measuring their search accuracy, response time, and eye movement patterns while using icons to locate specific picture books. Our findings indicate that preschool children are easier to use icons with close semantic distance and single icons for searching. Additionally, the ability to use icons with distant semantic distances and combination icons significantly improves with age. These findings may contribute to the development of more effective and children-friendly information search systems.|由于儿童的识字能力有限，图标经常被用于面向儿童的信息系统中。然而，图标固有的语义距离，这可能会影响它们对儿童的可操作性，在开发此类系统和相关研究中往往被忽视。在本研究中，我们应用语义距离来衡量面向儿童的图书搜索中图标的显性程度，使用为索引图画书而定制的自开发图标。我们首先通过问卷从儿童那里收集数据，以评估每个图标的感知语义距离。随后，我们对50名学前儿童进行了眼动追踪实验，测量他们在使用图标定位特定图画书时的搜索准确性、反应时间和眼动模式。我们的研究结果表明，学前儿童更容易使用语义距离接近的单个图标进行搜索。此外，随着年龄的增长，使用语义距离较远的组合图标的能力显著提高。这些发现可能有助于开发更有效且更适合儿童的信息搜索系统。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Effect+of+Icon+Semantic+Distance+on+Preschool+Children's+Information+Search:+Evidence+from+an+Eye-Tracking+Study)|0|
|[Contrastive Disentangled Representation Learning for Debiasing Recommendation with Uniform Data](https://doi.org/10.1145/3627673.3679889)|Xinxin Yang, Zhen Liu, Xiaoman Lu, Yafan Yuan, Sibo Lu, Yibo Gao|Beijing Jiaotong University, Beijing, China|In recommender systems, learning high-quality user and item representations is crucial for predicting user preferences. However, there are various confounding factors in observational data, resulting in data bias, which hinders the learning of user and item representations. Recent work proposed to use uniform data to alleviate bias problem. However, these methods fail to learn pure representations for unbiased prediction, which are not affected by confounding factors. This paper introduces a novel disentangled framework, named CDLRec, for learning unbiased representations, leveraging uniform data as supervisory signal for disentangling. Furthermore, to address the scarcity problem of uniform data, the contrastive learning is utilized to implement disentanglement by providing augmented samples. Specifically, two contrastive strategies are designed based on different sampling ways for positives and negatives. Extensive experiments are conducted over two real-world datasets and the results demonstrate the superior performance of our proposed method.|在推荐系统中，学习高质量的用户和物品表示对于预测用户偏好至关重要。然而，观察数据中存在多种混淆因素，导致数据偏差，这阻碍了用户和物品表示的学习。最近的工作提出使用均匀数据来缓解偏差问题。然而，这些方法未能学习到不受混淆因素影响的纯表示，从而无法进行无偏预测。本文引入了一种名为CDLRec的新型解耦框架，利用均匀数据作为解耦的监督信号来学习无偏表示。此外，为了解决均匀数据稀缺的问题，本文利用对比学习通过提供增强样本来实现解耦。具体来说，基于正负样本的不同采样方式设计了两种对比策略。在两个真实世界数据集上进行了大量实验，结果表明我们提出的方法具有优越的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Disentangled+Representation+Learning+for+Debiasing+Recommendation+with+Uniform+Data)|0|
|[Dual-level Intents Modeling for Knowledge-aware Recommendation](https://doi.org/10.1145/3627673.3679902)|Jin Zeng, Nan Wang, Jinbao Li|Qilu University of Technology, Jinan, China; Heilongjiang University, Harbin, China|Previous user-item interaction graphs have typically focused on simple interaction between users and items, failing to identify the important effects of user's intents in the interaction. While recent studies have ventured into exploring intent relationships between users and items for modeling, they predominantly emphasize user preferences manifesting in the interaction, overlooking knowledge-driven insight, thereby limiting the interpretability of intent. In this paper, we utilize the rich interpretable knowledge information in the knowledge graph to design a novel dual-level intents modeling framework called DIM. DIM aims to mine user's true intents, which usually include user popularity preference and personalized preference. Therefore, we extract both the popular and personalized user preferences from attribute tuples within the knowledge graph at the global and local levels, respectively. Experimental results on three datasets demonstrate the superiority of DIM over various state-of-the-art approaches.|以往的用户-项目交互图主要关注用户与项目之间的简单交互，未能识别出用户意图在交互中的重要影响。虽然近期研究开始探索用户与项目之间的意图关系以进行建模，但它们主要强调交互中表现出的用户偏好，忽视了基于知识的洞察，从而限制了意图的可解释性。本文利用知识图谱中丰富的可解释知识信息，设计了一种新颖的双层次意图建模框架，称为DIM。DIM旨在挖掘用户的真实意图，这些意图通常包括用户的热门偏好和个性化偏好。因此，我们从知识图谱的属性元组中分别提取了全局和局部层面的热门和个性化用户偏好。在三个数据集上的实验结果表明，DIM优于各种最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual-level+Intents+Modeling+for+Knowledge-aware+Recommendation)|0|
|[Distilling Knowledge Based on Curriculum Learning for Temporal Knowledge Graph Embeddings](https://doi.org/10.1145/3627673.3679896)|Bin Zhang, Jiayin Li, Yuanfei Dai|Fujian Normal University, Fuzhou, China; Nanjing Tech University, Nanjing, China|Lower-dimensional temporal knowledge graph embedding (TKGE) models are crucial for practical applications and resource-limited scenarios, although existing models employ higher-dimensional embeddings in training. In this paper, we propose a new framework for distilling TKGE models via an easy to hard pedagogical principle. The framework utilizes a learnable curriculum temperature (CT) module to optimize and guide the knowledge distillation process dynamically, ensuring that the entire procedure adheres to the principle. It also employs a self-adaptive attention mechanism to endeavor to achieve efficient transfer of knowledge from higher-dimensional models to lower-dimensional ones. Evaluation on various TKGE models and datasets demonstrates the proposed approach significantly reduces the model's parameters without noticeably affecting its performance.|低维时间知识图谱嵌入（TKGE）模型对于实际应用和资源有限场景至关重要，尽管现有模型在训练中采用高维嵌入。本文提出了一种基于由易到难教学原则的TKGE模型蒸馏新框架。该框架利用可学习的课程温度（CT）模块动态优化并指导知识蒸馏过程，确保整个过程遵循该原则。同时，采用自适应注意力机制，努力实现从高维模型到低维模型的知识高效传递。在多种TKGE模型和数据集上的评估表明，所提出的方法显著减少了模型参数，且对性能影响甚微。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Distilling+Knowledge+Based+on+Curriculum+Learning+for+Temporal+Knowledge+Graph+Embeddings)|0|
|[Feedback Reciprocal Graph Collaborative Filtering](https://doi.org/10.1145/3627673.3680015)|Weijun Chen, Yuanchen Bei, Qijie Shen, Hao Chen, Xiao Huang, Feiran Huang||Collaborative filtering on user-item interaction graphs has achieved success in the industrial recommendation. However, recommending users' truly fascinated items poses a seesaw dilemma for collaborative filtering models learned from the interaction graph. On the one hand, not all items that users interact with are equally appealing. Some items are genuinely fascinating to users, while others are unfascinated. Training graph collaborative filtering models in the absence of distinction between them can lead to the recommendation of unfascinating items to users. On the other hand, disregarding the interacted but unfascinating items during graph collaborative filtering will result in an incomplete representation of users' interaction intent, leading to a decline in the model's recommendation capabilities. To address this seesaw problem, we propose Feedback Reciprocal Graph Collaborative Filtering (FRGCF), which emphasizes the recommendation of fascinating items while attenuating the recommendation of unfascinating items. Specifically, FRGCF first partitions the entire interaction graph into the Interacted Fascinated (I F) graph and the Interacted Unfascinated (I U) graph based on the user feedback. Then, FRGCF introduces separate collaborative filtering on the I F graph and the I U graph with feedback-reciprocal contrastive learning and macro-level feedback modeling. This enables the I F graph recommender to learn multi-grained interaction characteristics from the I U graph without being misdirected by it. Extensive experiments on four benchmark datasets and a billion-scale industrial dataset demonstrate that FRGCF improves the performance by recommending more fascinating items and fewer unfascinating items. Besides, online A/B tests on Taobao's recommender system verify the superiority of FRGCF.|在用户-物品交互图上的协同过滤在工业推荐中取得了成功。然而，从交互图中学习的协同过滤模型在推荐用户真正感兴趣的物品时面临着跷跷板难题。一方面，用户交互的所有物品并非同样吸引人。有些物品确实能引起用户的兴趣，而有些则不能。在没有区分这些物品的情况下训练图协同过滤模型可能会导致向用户推荐不吸引人的物品。另一方面，在图协同过滤过程中忽略那些虽被交互但不吸引人的物品会导致用户交互意图的表示不完整，从而降低模型的推荐能力。为了解决这一跷跷板问题，我们提出了反馈互惠图协同过滤（FRGCF），该方法强调推荐吸引人的物品，同时减弱对不吸引人物品的推荐。具体来说，FRGCF首先根据用户反馈将整个交互图划分为交互且吸引人（I F）图和交互但不吸引人（I U）图。然后，FRGCF在I F图和I U图上分别引入协同过滤，并结合反馈互惠对比学习和宏观层次的反馈建模。这使得I F图推荐器能够从I U图中学习多粒度的交互特征，而不会被其误导。在四个基准数据集和一个亿级工业数据集上的广泛实验表明，FRGCF通过推荐更多吸引人的物品和更少不吸引人的物品，提升了性能。此外，在淘宝推荐系统上的在线A/B测试验证了FRGCF的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Feedback+Reciprocal+Graph+Collaborative+Filtering)|0|
|[DIFN: A Dual Intention-aware Network for Repurchase Recommendation with Hierarchical Spatio-temporal Fusion](https://doi.org/10.1145/3627673.3680071)|Li Lin, Xin Xu, Hai Wang, Tian He, Desheng Zhang, Shuai Wang|JD Logistics, Beijing, Beijing, China; Rutgers University, Piscataway, New Jersey, USA; Southeast University, Nanjing, Jiangsu, China|Recommendation systems play a crucial role in both industrial applications and research fields, which target to understand user preferences and intentions to provide personalized services. Compared to conventional recommendations, repurchase recommendations aim to suggest suitable products to users that they used to buy based on their intention evolution. Existing research on product recommendation can mainly be divided into behavior sequence-based methods and graph-based methods. Although these methods represent user interests and preference features effectively, they still fail to model repurchase behaviors because (i) the environment causing repurchase intention change is neglected and (ii) the lack of feedback after purchasing makes it difficult to learn the impacts of diverse behaviors. To comprehensively consider these limitations, we design a D ual I ntention-aware F usion N etwork framework (DIFN) to understand the effects of environment and after-purchasing feedback on users' intentions. Firstly, a hierarchical graph-based multi-level relational attention module is designed to effectively extract basic user features and spatial features from complex environmental information. Then, we introduce a behavior intention module and a usage intention module for different types of feedback data. Finally, we propose a dual intention fusion network that effectively fuses user basic features with spatial attributes and user intention features with temporal attributes for recommendation. Comprehensive evaluations on real-world datasets show that our method exceeds state-of-the-art baselines, which show an average of 8.2% improvements in different metrics.|推荐系统在工业应用和研究领域中扮演着至关重要的角色，其目标是通过理解用户偏好和意图来提供个性化服务。与传统推荐相比，复购推荐旨在根据用户意图的演变，向其推荐他们曾经购买过的合适产品。现有的产品推荐研究主要可分为基于行为序列的方法和基于图的方法。尽管这些方法能够有效表示用户的兴趣和偏好特征，但它们未能对复购行为进行建模，原因有二：(i) 忽视了导致复购意图变化的环境因素；(ii) 购买后缺乏反馈，使得难以学习多样行为的影响。为了全面考虑这些限制，我们设计了一个双意图感知融合网络框架（DIFN），以理解环境和购买后反馈对用户意图的影响。首先，我们设计了一个基于层次图的多级关系注意力模块，以有效从复杂的环境信息中提取基本用户特征和空间特征。接着，我们引入了行为意图模块和使用意图模块，分别处理不同类型的反馈数据。最后，我们提出了一种双意图融合网络，该网络能够有效融合用户基本特征与空间属性以及用户意图特征与时间属性，用于推荐。在真实世界数据集上的综合评估表明，我们的方法超越了最先进的基线方法，在不同指标上平均提升了8.2%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DIFN:+A+Dual+Intention-aware+Network+for+Repurchase+Recommendation+with+Hierarchical+Spatio-temporal+Fusion)|0|
|[Building Natural Language Interface for Product Search](https://doi.org/10.1145/3627673.3680070)|Vijit Malik, Vinayak Puranik, Anirban Majumder, Vivek Sembium|Amazon, Bangalore, India|Automatic extraction of attribute preferences from search queries is a critical problem in providing accurate product recommendations to customer. The task becomes even more challenging in cold-start settings where we do not have any supervised/labelled data available to train ML models. In this work, we implement a novel dataset generation pipeline (LLM-API) that leverages Large Language Models (LLMs), search logs and proprietary product information data from an ecommerce website to create a high quality dataset. Our proposed pipeline of LLM-API is robust as it can generalize to any product category with minimal changes in the LLM prompts. For the problem of converting product search queries to API calls we propose a multi-task schema generator model which we train on our generated dataset. Experiments on an internal test set reveals that our proposed model achieves an improvement of ≈9.6% and ≈5% in Exact Match and Micro-F1 respectively, over competitive baselines. Benchmarking our approach on public test set of search queries further reveals a gain of ≈8.6% and ≈10.5% in Exact Match and Micro-F1. We further demonstrate that our approach outperforms a state-of-the-art LLM (Claude) applied on our task using few-shot prompting and CoT reasoning, while at the same time, achieves improvement in inference latency.|从搜索查询中自动提取属性偏好是向客户提供准确产品推荐的关键问题。在冷启动场景下，这一任务变得更加具有挑战性，因为我们没有任何监督/标注数据来训练机器学习模型。在这项工作中，我们实现了一种新颖的数据集生成管道（LLM-API），该管道利用大型语言模型（LLMs）、搜索日志以及来自电子商务网站的专有产品信息数据，来创建高质量的数据集。我们提出的LLM-API管道具有鲁棒性，因为它可以推广到任何产品类别，只需对LLM提示进行最小的更改。对于将产品搜索查询转换为API调用的问题，我们提出了一种多任务模式生成器模型，并在我们生成的数据集上进行训练。在内部测试集上的实验表明，我们提出的模型在精确匹配和微观F1得分上分别比竞争基线提高了约9.6%和5%。在公共测试集上的基准测试进一步显示，精确匹配和微观F1得分分别提高了约8.6%和10.5%。我们进一步证明，我们的方法在少样本提示和CoT推理下，优于应用于我们任务的最先进的LLM（Claude），同时在推理延迟方面也实现了改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Building+Natural+Language+Interface+for+Product+Search)|0|
|[EASE: Learning Lightweight Semantic Feature Adapters from Large Language Models for CTR Prediction](https://doi.org/10.1145/3627673.3680048)|Zexuan Qiu, Jieming Zhu, Yankai Chen, Guohao Cai, Weiwen Liu, Zhenhua Dong, Irwin King|Conrnell University, Ithaca, USA; Huawei Noah's Ark Lab, Shenzhen, China; The Chinese University of Hong Kong, Hong Kong, China|Recent studies highlight the potential of large language models (LLMs) to enhance content integration in recommender systems by leveraging their semantic understanding capabilities. However, directly incorporating LLMs into an online inference pipeline significantly increases computation costs for large-scale deployment, posing a practical challenge in balancing their benefits and costs. In this work, we propose the EASE framework, which enriches and aligns semantic feature embeddings using LLMs during the training phase while establishing a lightweight inference pipeline that does not directly involve LLMs. Specifically, we train a semantic adapter to align item features with LLMs and simultaneously enrich semantic embeddings through reconstruction tasks from LLMs. During inference, we retain only the item feature encoder and lightweight semantic adapter, thereby eliminating the computation overhead of resource-intensive LLMs. Our EASE framework is flexible, supporting not only text and visual features but also other pre-processed embedding features. Extensive experiments on both public and industrial datasets demonstrate that enriching semantic feature embeddings with our EASE framework yields consistent improvements in downstream click-through rate prediction tasks.|近期研究强调了大型语言模型（LLMs）通过利用其语义理解能力来增强推荐系统中内容整合的潜力。然而，直接将LLMs整合到在线推理管道中显著增加了大规模部署的计算成本，这使得在平衡其收益和成本方面面临实际挑战。在此工作中，我们提出了EASE框架，该框架在训练阶段利用LLMs丰富和校准语义特征嵌入，同时建立一个不直接涉及LLMs的轻量级推理管道。具体而言，我们训练一个语义适配器来校准项目特征与LLMs，并通过从LLMs进行重建任务来同时丰富语义嵌入。在推理阶段，我们仅保留项目特征编码器和轻量级语义适配器，从而消除了资源密集型LLMs的计算开销。我们的EASE框架具有灵活性，不仅支持文本和视觉特征，还支持其他预处理的嵌入特征。在公共和工业数据集上的广泛实验表明，通过我们的EASE框架丰富语义特征嵌入在下游点击率预测任务中持续提升了性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EASE:+Learning+Lightweight+Semantic+Feature+Adapters+from+Large+Language+Models+for+CTR+Prediction)|0|
|[Mitigating Extreme Cold Start in Graph-based RecSys through Re-ranking](https://doi.org/10.1145/3627673.3680069)|Alessandro Sbandi, Federico Siciliano, Fabrizio Silvestri|TIM S.p.A. & Sapienza University of Rome, Rome, Italy; Sapienza University of Rome, Rome, Italy|Recommender systems based on Graph Neural Networks (GNN) have become the state-of-the-art approach in recommendation, but they struggle with in extreme cold-start settings, where most users or items lack interaction data. This paper proposes a novel framework to address this challenge in four steps: (i) a propensity model to predict item purchase behaviour, with associated explainability to identify the most relevant features, (ii) a link augmentation module to connect users based on previously obtained similarities, (iii) a GNN-based link prediction step on the obtained dense graph and (iv) a final re-ranking stage to increase diversity in predictions leveraging users embeddings. By exploiting the enriched graph structure, the framework generates embeddings for cold-start users and items, enabling diverse recommendations, containing long tail and unsold items, for both established and new users. We validate the framework's effectiveness on real-world industrial data from TIM S.p.A.|基于图神经网络（GNN）的推荐系统已成为推荐领域的最先进方法，但在极端冷启动情况下表现不佳，此时大多数用户或物品缺乏交互数据。本文提出了一种新颖的框架，通过四个步骤来解决这一挑战：（i）一个倾向模型用于预测物品购买行为，并提供相关解释性以识别最相关的特征；（ii）一个链接增强模块，基于先前获得的相似性连接用户；（iii）在获得的密集图上进行基于GNN的链接预测步骤；（iv）一个最终的重新排序阶段，利用用户嵌入来增加预测的多样性。通过利用丰富的图结构，该框架为冷启动用户和物品生成嵌入，从而能够为既有用户和新用户提供包含长尾和未售物品的多样化推荐。我们在TIM S.p.A.的真实工业数据上验证了该框架的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mitigating+Extreme+Cold+Start+in+Graph-based+RecSys+through+Re-ranking)|0|
|[Sequence-level Semantic Representation Fusion for Recommender Systems](https://doi.org/10.1145/3627673.3680037)|Lanling Xu, Zhen Tian, Bingqian Li, Junjie Zhang, Daoyuan Wang, Hongyu Wang, Jinpeng Wang, Sheng Chen, Wayne Xin Zhao||With the rapid development of recommender systems, there is increasing side information that can be employed to improve the recommendation performance. Specially, we focus on the utilization of the associated textual data of items (eg product title) and study how text features can be effectively fused with ID features in sequential recommendation. However, there exists distinct data characteristics for the two kinds of item features, making a direct fusion method (eg adding text and ID embeddings as item representation) become less effective. To address this issue, we propose a novel Text-ID semantic fusion approach for sequential Recommendation, namely . The core idea of our approach is to conduct a sequence-level semantic fusion approach by better integrating global contexts. The key strategy lies in that we transform the text embeddings and ID embeddings by Fourier Transform from time domain to frequency domain. In the frequency domain, the global sequential characteristics of the original sequences are inherently aggregated into the transformed representations, so that we can employ simple multiplicative operations to effectively fuse the two kinds of item features. Our fusion approach can be proved to have the same effects of contextual convolution, so as to achieving sequence-level semantic fusion. In order to further improve the fusion performance, we propose to enhance the discriminability of the text embeddings from the text encoder, by adaptively injecting positional information via a mixture-of-experts (MoE) modulation method. Our implementation is available at this repository: .|随着推荐系统的快速发展，越来越多的辅助信息可用于提升推荐性能。特别是，我们专注于利用项目的关联文本数据（如产品标题），并研究如何在序列推荐中有效地将文本特征与ID特征融合。然而，这两类项目特征存在显著的数据特性，使得直接的融合方法（如将文本和ID嵌入作为项目表示相加）效果不佳。为了解决这一问题，我们提出了一种新的文本-ID语义融合方法，用于序列推荐，即。我们的方法的核心思想是通过更好地整合全局上下文，进行序列级别的语义融合。关键策略在于，我们通过傅里叶变换将文本嵌入和ID嵌入从时域转换到频域。在频域中，原始序列的全局序列特性自然地聚合到转换后的表示中，从而我们可以使用简单的乘法操作来有效融合这两类项目特征。我们的融合方法可以证明具有与上下文卷积相同的效果，从而实现序列级别的语义融合。为了进一步提高融合性能，我们提出通过混合专家（MoE）调制方法自适应地注入位置信息，以增强文本编码器中文本嵌入的区分性。我们的实现代码可在以下仓库中获取：。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sequence-level+Semantic+Representation+Fusion+for+Recommender+Systems)|0|
|[Effective Utilization of Large-scale Unobserved Data in Recommendation Systems](https://doi.org/10.1145/3627673.3680067)|Feng Zhang, Yulin Xu, Hongjie Chen, Xu Yuan, Qingwen Liu, Yuning Jiang|Taotian Group, Hangzhou, China; Taotian Group, Beijing, China|Ranking models play an important role in industrial recommendation systems. However, most ranking models are trained only with the observed items but used to retrieve all items in the entire space, which may suffer from the sample selection bias and the exposure bias. Inspired by the entire space learning framework, we carry out detailed data analyses on large-scale unobserved items and find that they contain quite a few "potentially-positive" samples. In this paper, we propose an "Extract and Transfer" (EAT) framework, utilizing quantities of unobserved items and other domains' data to construct more training data for ranking models. Specifically, we first extract "potentially-positive" samples and negative ones according to their ranking scores from the unobserved data, and then design an Entire Space Transfer Learning (ESTL) model to transfer knowledge between observed and unobserved samples, instead of directly mixing them together to avoid negative transfer. Experiments on production data collected from Taobao validate the proposed method's superiority. Besides, we have deployed EAT on the Taobao recommendation system, obtaining 6.22% IPV (Item Page View) and 3.77% CTR improvement. The code is available at https://github.com/Recommender1/EAT.git1.|排名模型在工业推荐系统中扮演着重要角色。然而，大多数排名模型仅使用观察到的项目进行训练，但在整个项目空间中检索所有项目时使用，这可能导致样本选择偏差和曝光偏差。受整体空间学习框架的启发，我们对大规模未观察到的项目进行了详细的数据分析，发现其中包含相当数量的“潜在正面”样本。本文提出了一种“提取与迁移”（EAT）框架，利用大量未观察到的项目和其他领域的数据来构建更多用于排名模型的训练数据。具体而言，我们首先根据排名分数从未观察到的数据中提取“潜在正面”样本和负样本，然后设计了一个整体空间迁移学习（ESTL）模型，用于在观察到的样本和未观察到的样本之间进行知识迁移，而不是直接将它们混合在一起，以避免负迁移。在从淘宝收集的生产数据上的实验验证了所提出方法的优越性。此外，我们已经在淘宝推荐系统中部署了EAT，获得了6.22%的IPV（商品页面浏览量）和3.77%的CTR提升。代码可在https://github.com/Recommender1/EAT.git1获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Effective+Utilization+of+Large-scale+Unobserved+Data+in+Recommendation+Systems)|0|
|[ECRT: Flexible Sequence Enhancement Framework for Cross-Domain Information Reuse in Recommendation](https://doi.org/10.1145/3627673.3680038)|Weiqiang Zhao, ZiYuan Wu, Yatao Yang, Lifeng Hua, Hao Xiong|Nanjing University, Nanjing, China; Alibaba Group, Hangzhou, China|Chronological sequence of user-item interactions is a key feature in recommender systems, as it reveals the transition of users' interests as well as contextual relevance between nearby items. In modern e-commerce applications, various scenarios are usually integrated in one entry page, and the behavior sequence tend to be a combination of user-item interactions across multiple domains, such as on-sale goods, search queries, short videos, livestreams, etc. However, traditional domain-specified recommendations only deal with the interactions within the target domain, which neglects the overall profiles depicted by the behavior across the entire application, leading to overestimation of retargeted items as well as underestimation of unseen ones. So it is crucial to leverage cross-domain data from prominent domains to better supplement user behavior sequences for our targets. To tackle this problem, we propose the Enhanced Cross-domain Ralation Transfer (ECRT) framework to make flexible sequence augmentation with the assist of cross-domain information from other domains. We first employ similarity-based retrieval to obtain relevant sequence information from neighbor domains and build a heterogeneous graph to represent the complex behavior of users. Then we use innovative mining approaches to sample relevant information from the graph to supplement users' behavior sequences, and a hierarchical gated attention structure is used to aggregate these augmented information. We apply our proposed method in the livestream recommendation of Taobao channel pages, and the final experimental results indicate that our method demonstrates excellent performance in both online and offline environments, with an excess of up to 3.6% in main online indicators beyond past SOTA methods.|用户与物品交互的时间序列是推荐系统中的一个关键特征，因为它揭示了用户兴趣的转变以及相邻物品之间的上下文相关性。在现代电子商务应用中，各种场景通常集成在一个入口页面上，行为序列往往是跨多个领域（如在售商品、搜索查询、短视频、直播等）的用户-物品交互的组合。然而，传统的特定领域推荐系统仅处理目标领域内的交互，忽略了整个应用中行为所描绘的整体轮廓，导致对再定位物品的高估和对未见物品的低估。因此，利用来自显著领域的跨领域数据来更好地补充用户行为序列以实现我们的目标至关重要。为了解决这个问题，我们提出了增强的跨领域关系迁移（ECRT）框架，通过借助其他领域的跨领域信息来实现灵活的序列增强。我们首先采用基于相似性的检索方法从邻近领域获取相关的序列信息，并构建一个异构图来表示用户的复杂行为。然后，我们使用创新的挖掘方法从图中采样相关信息来补充用户的行为序列，并使用分层门控注意力结构来聚合这些增强的信息。我们将所提出的方法应用于淘宝频道页面的直播推荐，最终的实验结果表明，我们的方法在在线和离线环境中均表现出色，主要在线指标比过去的SOTA方法高出多达3.6%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ECRT:+Flexible+Sequence+Enhancement+Framework+for+Cross-Domain+Information+Reuse+in+Recommendation)|0|
|[Collaborative Scope: Encountering the Substitution Effect within the Delivery Scope in Online Food Delivery Platform](https://doi.org/10.1145/3627673.3680029)|Yida Zhu, Liying Chen, Chen Zheng, Jia Shi, Daping Xiong, Zewen Huang, Shihao Ren, Shuiping Chen, Jinghua Hao, Renqing He|Meituan, Beijing, China|Online food delivery (OFD) services, known for offering varied meals at home, have gained global popularity. Meituan has recently ventured into the affordable market segment with its "Pinhaofan'' service, highlighting the imperative to delivery efficiency. To achieve this, delivery scope is regarded as one of the most effective operational tools. The delivery scope of a merchant refers to the geo-graphical area where they can serve customers. Current methods for generating delivery scopes primarily focus on optimizing a single merchant's efficiency or rely on manual delineated from the merchant's perspective, neglecting the merchant substitution effect and potentially resulting in order loss. In this paper, we propose a novel method, named Collaborative Scope, which views the delivery scope as an assortment optimization problem, considering the substitution effect between merchants from the user's perspective. We introduce the discrete choice model of econometrics and use the Enhanced Multinomial Logit Model to predict user conversion rates in the merchant list. Next, we formulate the delivery scope optimization problem of multiple merchants as a mixed integer programming problem. The city-wide solution of this problem, owing to the large-scale combinatorial optimization triggered by high-dimensional decision variables, incurs high computational complexity. To address this, we propose an approximate solution to the original problem through a first-order Taylor series approximation, which significantly reduces the computation complexity at the expense of a slight decrease in solution accuracy. Offline and online A/B test results indicate that, compared to existing methods, Collaborative Scope significantly improves delivery efficiency by reducing delivery difficulty without hurt of order volume. Notably, Collaborative Scope is currently deployed on "Pinhaofan'', serving tens of millions of online users.|在线食品配送（OFD）服务因其能够将多样化的餐食送至家中而风靡全球。美团最近通过其“拼好饭”服务进军了平价市场领域，突显了配送效率的重要性。为此，配送范围被视为最有效的运营工具之一。商家的配送范围指的是他们能够服务顾客的地理区域。目前生成配送范围的方法主要集中在优化单个商家的效率，或依赖商家视角的手动划定，忽视了商家之间的替代效应，可能导致订单损失。本文提出了一种名为“协同范围”的新方法，将配送范围视为一个组合优化问题，从用户的角度考虑商家之间的替代效应。我们引入了计量经济学的离散选择模型，并使用增强的多项式逻辑回归模型来预测用户在商家列表中的转化率。接着，我们将多个商家的配送范围优化问题形式化为一个混合整数规划问题。由于高维决策变量引发的大规模组合优化，该问题的城市级解决方案计算复杂度高。为此，我们通过一阶泰勒级数近似提出了原问题的近似解，显著降低了计算复杂度，但略微降低了解决方案的精度。离线和在线A/B测试结果表明，与现有方法相比，协同范围显著提高了配送效率，减少了配送难度，且不影响订单量。值得注意的是，协同范围目前已在“拼好饭”上部署，服务于数千万在线用户。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Collaborative+Scope:+Encountering+the+Substitution+Effect+within+the+Delivery+Scope+in+Online+Food+Delivery+Platform)|0|
|[EDGE: A Conversational Interface driven by Large Language Models for Educational Knowledge Graphs Exploration](https://doi.org/10.1145/3627673.3679231)|Neda Afreen, Giacomo Balloccu, Ludovico Boratto, Gianni Fenu, Francesca Maridina Malloci, Mirko Marras, Andrea Giovanni Martis|University of Cagliari, Cagliari, Italy|As education adopts digital platforms, the vast amount of information from various sources, such as learning management systems and learning object repositories, presents challenges in navigation and elaboration. Traditional interfaces involve a steep learning curve, limited user accessibility, and lack flexibility. Language models alone cannot address these issues as they do not have access to structured information specific to the educational organization. In this paper, we propose EDGE (EDucational knowledge Graph Explorer), a natural language interface that uses knowledge graphs to organize educational information. EDGE translates natural language requests into queries and converts the results back into natural language responses. We show EDGE's versatility using knowledge graphs built from public datasets, providing example interactions of different stakeholders. Demo video: https://u.garr.it/eYq63.|随着教育转向数字化平台，来自学习管理系统、学习对象资源库等各种来源的海量信息在导航和详细阐述方面带来了挑战。传统界面存在学习曲线陡峭、用户可访问性有限以及缺乏灵活性的问题。仅依赖语言模型无法解决这些问题，因为它们无法访问教育机构特有的结构化信息。本文提出了EDGE（教育知识图谱探索器），这是一个利用知识图谱组织教育信息的自然语言界面。EDGE将自然语言请求转换为查询，并将结果转换回自然语言响应。我们展示了EDGE的多样性，使用了从公共数据集构建的知识图谱，并提供了不同利益相关者的示例交互。演示视频链接：https://u.garr.it/eYq63。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EDGE:+A+Conversational+Interface+driven+by+Large+Language+Models+for+Educational+Knowledge+Graphs+Exploration)|0|
|[A Supervised BERT Model for Identifying Core-Intent Bearing Phrases in e-Commerce Queries](https://doi.org/10.1145/3627673.3679072)|Abhishek Sudhakar Deshmukh, Arnab Dutta|eBay GmbH, Aachen, Germany; eBay GmbH, Dreilinden, Germany|In the realm of e-Commerce, a fundamental problem is accurate interpretation of users' core intent. The intent is often subtly expressed implicitly or stated explicitly with the usage of verbose tokens or key phrases in a user query. In this work, we focus on the later class of problems where we identify a subset of query tokens which are the primary intent bearing phrases that convey explicit intents. We did not solve this as an intent detection problem but rather an immutable component detection problem because we believe that discovering the immutable phrases in a query entails that those are the intent bearing phrases. Furthermore, identifying a certain set of query tokens as immutable ensures better downstream processing in terms of unprecedented token handling, query category detection or query rewrites. We have developed a BERT based supervised learned model which can identify core-intent tokens, thereby improving F1 score over the baseline by over 35%. Furthermore, we integrated our proposed approach for a query recovery strategy which produces approximately 11.9% improvement in offline relevance scores compared to the production model.|在电子商务领域，一个基本问题是如何准确解读用户的中心意图。用户的意图通常通过隐晦的隐式表达或使用冗长的标记或关键词在用户查询中明确表达。在这项工作中，我们关注的是后一类问题，即识别查询标记中的一部分，这些标记是主要承载意图的短语，传达明确的意图。我们没有将这个问题视为意图检测问题，而是视为不可变组件检测问题，因为我们认为，发现查询中的不可变短语意味着这些短语是承载意图的短语。此外，将某些查询标记识别为不可变，确保了在处理前所未见的标记、查询类别检测或查询重写方面的下游处理效果更好。我们开发了一个基于BERT的有监督学习模型，该模型能够识别核心意图标记，从而将F1得分比基线提高了35%以上。此外，我们将提出的方法集成到一个查询恢复策略中，与生产模型相比，离线相关性评分提高了约11.9%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Supervised+BERT+Model+for+Identifying+Core-Intent+Bearing+Phrases+in+e-Commerce+Queries)|0|
|[Traversing the Journey of Data and AI: From Convergence to Translation](https://doi.org/10.1145/3627673.3679026)|Nitesh V. Chawla|University of Notre Dame, Notre Dame, IN, USA|In this talk, I will present our work on fundamental advances in AI, inspired by interdisciplinary problem statements and societal challenges. I will also highlight our innovation journey that encapsulates both the opportunities and challenges inherent in harnessing the full potential of AI for societal benefit, in particular highlighting the realization of societal impact through translational work and partnerships. Additionally, I will highlight our educational endeavors, emphasizing experiential learning and interdisciplinary approaches as fundamental elements of the student experience.|在本次演讲中，我将介绍我们在人工智能基础性进展方面的工作，这些工作受到跨学科问题陈述和社会挑战的启发。我还将重点介绍我们的创新历程，这一历程既体现了利用人工智能全部潜力造福社会的机遇，也揭示了其中的挑战，特别强调了通过转化工作和合作伙伴关系实现社会影响的重要性。此外，我将强调我们的教育努力，突出体验式学习和跨学科方法作为学生体验的基本要素。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Traversing+the+Journey+of+Data+and+AI:+From+Convergence+to+Translation)|0|
|[Is the Search Engine of the Future a Chatbot?](https://doi.org/10.1145/3627673.3679059)|Suzan Verberne|Leiden Institute of Advanced Computer Science, Leiden University, Leiden, Netherlands|The rise of Large Language Models (LLMs) has had a huge impact on the interaction of users with information. Many people argue that the age of search engines as we know them has ended, while other people argue that retrieval technology is more relevant than ever before, because we need information to be grounded in sources. In my talk I will argue that both statements are true. I will discuss the multiple relations between LLMs and Information Retrieval: how can they strengthen each other, what are the challenges we face, and what directions should we go in our research?|大型语言模型（LLMs）的崛起对用户与信息的交互方式产生了巨大影响。许多人认为，我们所熟知的搜索引擎时代已经结束，而另一些人则认为，检索技术比以往任何时候都更加重要，因为我们需要的不仅仅是信息，而是基于来源的信息。在我的演讲中，我将主张这两种观点都是正确的。我将探讨LLMs与信息检索之间的多重关系：它们如何相互增强，我们面临的挑战是什么，以及我们的研究应该朝着哪些方向发展？|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Is+the+Search+Engine+of+the+Future+a+Chatbot?)|0|
|[Navigating the Landscape of Reproducible Research: A Predictive Modeling Approach](https://doi.org/10.1145/3627673.3679831)|Akhil Pandey Akella, Sagnik Ray Choudhury, David Koop, Hamed Alhoori|Northern Illinois University & Northwestern University, Dekalb, IL, USA; Northern Illinois University, Dekalb, IL, USA; University of North Texas, Denton, TX, USA|The reproducibility of scientific articles is central to the advancement of science. Despite this importance, evaluating reproducibility remains challenging due to the scarcity of ground truth data. Predictive models can address this limitation by streamlining the tedious evaluation process. Typically, a paper's reproducibility is inferred based on the availability of artifacts such as code, data, or supplemental information, often without extensive empirical investigation. To address these issues, we utilized artifacts of papers as fundamental units to develop a novel, dual-spectrum framework that focuses on author-centric and external-agent perspectives. We used the author-centric spectrum, followed by the external-agent spectrum, to guide a structured, model-based approach to quantify and assess reproducibility. We explored the interdependencies between different factors influencing reproducibility and found that linguistic features such as readability and lexical diversity are strongly correlated with papers achieving the highest statuses on both spectrums. Our work provides a model-driven pathway for evaluating the reproducibility of scientific research. The code, methods, and artifacts for our study are publicly available at: https://github.com/reproducibilityproject/NLRR/|科学文章的可重复性对于科学的进步至关重要。尽管其重要性不言而喻，但由于缺乏真实数据，评估可重复性仍然具有挑战性。预测模型可以通过简化繁琐的评估过程来解决这一限制。通常，一篇论文的可重复性是基于代码、数据或补充信息等资源的存在来推断的，而往往没有进行广泛的实证调查。为了解决这些问题，我们利用论文的资源作为基本单位，开发了一种新颖的双光谱框架，该框架侧重于以作者为中心和外部代理的视角。我们使用以作者为中心的光谱，随后是外部代理的光谱，来指导一种结构化的、基于模型的方法来量化和评估可重复性。我们探讨了影响可重复性的不同因素之间的相互依赖关系，并发现语言特征如可读性和词汇多样性与论文在两个光谱上达到最高状态之间存在强烈的相关性。我们的工作为评估科学研究的可重复性提供了一种模型驱动的途径。我们研究的代码、方法和资源可在以下公开获取：https://github.com/reproducibilityproject/NLRR/。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Navigating+the+Landscape+of+Reproducible+Research:+A+Predictive+Modeling+Approach)|0|
|[Aligning Large Language Model with Direct Multi-Preference Optimization for Recommendation](https://doi.org/10.1145/3627673.3679611)|Zhuoxi Bai, Ning Wu, Fengyu Cai, Xinyi Zhu, Yun Xiong|Shanghai University, Shanghai, China; Fudan University, Shanghai, China; Beihang University, Beijing, China; CashCat, Hangzhou, China; Technical University of Darmstadt, Darmstadt, Germany|Large Language Models (LLMs) have shown impressive performance in various domains, prompting researchers to explore their potential application in recommendation systems. However, directly applying LLMs to recommendation tasks has proven to be less effective due to the significant gap between the data used for pre-training LLMs and the specific requirements of recommendation tasks. In this study, we propose Direct Multi-Preference Optimization (DMPO), a streamlined framework to bridge this gap and enhance the alignment of LLMs for recommendation tasks. DMPO can be viewed as a pair-wise ranking loss to distinguish between positive and negative samples in recommendation tasks. Furthermore, DMPO improves the performance of LLM-based recommenders by maximizing the probability of positive samples and minimizing the probability of multiple negative samples at the same time. Experimental evaluations are conducted to compare DMPO with traditional recommendation methods and other LLM-based recommendation methods. The results reveal that DMPO significantly enhances the recommendation capabilities of LLMs across three real-world public datasets in few-shot scenarios. Furthermore, the experiments also demonstrate that DMPO exhibits superior generalization ability in cross-domain recommendation. A case study elucidates the reasons behind these consistent improvements and also underscores DMPO's potential as an explainable recommendation system. Our code and data are available at https://github.com/BZX667/DMPO.|大型语言模型（LLMs）在多个领域展示了卓越的性能，促使研究人员探索其在推荐系统中的潜在应用。然而，直接将LLMs应用于推荐任务已被证明效果不佳，因为用于预训练LLMs的数据与推荐任务的具体需求之间存在显著差距。在本研究中，我们提出了直接多偏好优化（Direct Multi-Preference Optimization, DMPO），这是一个简化的框架，旨在弥合这一差距并增强LLMs在推荐任务中的适应性。DMPO可以视为一种成对排序损失，用于区分推荐任务中的正样本和负样本。此外，DMPO通过最大化正样本的概率并同时最小化多个负样本的概率，提升了基于LLM的推荐系统的性能。我们进行了实验评估，将DMPO与传统的推荐方法以及其他基于LLM的推荐方法进行了比较。结果显示，在少样本场景下，DMPO在三个真实世界的公开数据集上显著增强了LLMs的推荐能力。此外，实验还表明，DMPO在跨领域推荐中展现出优越的泛化能力。一项案例研究阐明了这些持续改进的原因，并强调了DMPO作为可解释推荐系统的潜力。我们的代码和数据可在https://github.com/BZX667/DMPO 获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Aligning+Large+Language+Model+with+Direct+Multi-Preference+Optimization+for+Recommendation)|0|
|[Wise Fusion: Group Fairness Enhanced Rank Fusion](https://doi.org/10.1145/3627673.3679649)|Kathleen Cachel, Elke A. Rundensteiner|Worcester Polytechnic Institute, Worcester, MA, USA|Rank fusion is a technique for combining multiple rankings into a single aggregated ranking, commonly used in high-stakes applications. For hiring decisions, a fused ranking might combine evaluations of different candidates from various job boards into one list. Ideally, such fused rankings are fair. Meaning they do not withhold opportunities or resources from marginalized groups of candidates, even if such biases may be present in the to-be-fused rankings. Prior work fairly aggregating rankings is limited to ensuring proportional (not addressing equality) fairness when combining ranked lists containing the same candidate items. Yet, real-world fusion tasks often combine rankings of varying candidate sets, may also contain relevance scores, or are better suited to equal representation. To address fairness in these settings, we present a new plug-and-play fairness-aware fusion strategy: WISE fusion. WISE works in fusion settings where we have closed-box access to a score-powered rank fusion (SRF) method, making it possible to fairness-enhance existing fusion pipelines with little added cost. WISE uses existing evaluations of candidates from an as-is SRF method to achieve proportional or equal rank fairness in the final fused ranking. Our experimental study demonstrates that WISE beats the fairness and utility performance of state-of-the-art methods applied to these new fair rank fusion settings.|排名融合是一种将多个排名合并为单一综合排名的技术，常见于高风险应用中。例如，在招聘决策中，一个融合后的排名可能会将来自不同求职网站的候选人评估整合成一个名单。理想情况下，这种融合后的排名应该是公平的，即它们不会剥夺边缘化候选人群体的机会或资源，即使待融合的排名本身可能存在偏见。先前的工作在公平地聚合排名方面，仅限于在合并包含相同候选人项目的排名列表时确保比例（而非平等）公平性。然而，现实世界的融合任务通常涉及合并不同候选人集合的排名，可能还包含相关性评分，或者更适合于平等代表性。为了在这些情境中解决公平性问题，我们提出了一种新的即插即用公平感知融合策略：WISE融合。WISE适用于我们对基于分数的排名融合（SRF）方法有封闭式访问权限的融合场景，使得我们能够以较低的额外成本增强现有融合流程的公平性。WISE利用现有SRF方法对候选人的评估，以在最终融合排名中实现比例或平等的排名公平性。我们的实验研究表明，WISE在这些新的公平排名融合设置中，其公平性和效用性能优于最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Wise+Fusion:+Group+Fairness+Enhanced+Rank+Fusion)|0|
|[FCS-HGNN: Flexible Multi-type Community Search in Heterogeneous Information Networks](https://doi.org/10.1145/3627673.3679696)|Guoxin Chen, Fangda Guo, Yongqing Wang, Yanghao Liu, Peiying Yu, Huawei Shen, Xueqi Cheng|; Soochow University Institute of Computing Technology; University of Chinese Academy of Sciences Institute of Computing Technology; Chinese Academy of Sciences Institute of Computing Technology|Community search is a personalized community discovery problem designed to identify densely connected subgraphs containing the query node. Recently, community search in heterogeneous information networks (HINs) has received considerable attention. Existing methods typically focus on modeling relationships in HINs through predefined meta-paths or user-specified relational constraints. However, metapath-based methods are primarily designed to identify single-type communities with nodes of the same type rather than multi-type communities involving nodes of different types. Constraint-based methods require users to have a good understanding of community patterns to define a suitable set of relational constraints, which increases the burden on users. In this paper, we propose FCS-HGNN, a novel method for flexibly identifying both single-type and multi-type communities in HINs. Specifically, FCS-HGNN extracts complementary information from different views and dynamically considers the contribution of each relation instead of treating them equally, thereby capturing more fine-grained heterogeneous information. Furthermore, to improve efficiency on large-scale graphs, we further propose LS-FCS-HGNN, which incorporates i) the neighbor sampling strategy to improve training efficiency, and ii) the depth-based heuristic search strategy to improve query efficiency. We conducted extensive experiments to demonstrate the superiority of our proposed methods over state-of-the-art methods, achieving average improvements of 14.3% and 11.1% on single-type and multi-type communities, respectively.|社区搜索是一个个性化的社区发现问题，旨在识别包含查询节点的密集连接子图。近来，异构信息网络（HINs）中的社区搜索引起了广泛关注。现有方法通常通过预定义的元路径或用户指定的关系约束来建模HINs中的关系。然而，基于元路径的方法主要设计用于识别单一类型的社区，其中节点属于同一类型，而不是涉及不同类型节点的多类型社区。基于约束的方法要求用户对社区模式有良好的理解，以定义合适的关系约束集合，这增加了用户的负担。在本文中，我们提出了FCS-HGNN，一种新颖的方法，用于在HINs中灵活识别单一类型和多类型社区。具体来说，FCS-HGNN从不同视角提取互补信息，并动态考虑每种关系的贡献，而不是平等对待它们，从而捕捉到更细粒度的异构信息。此外，为了提高大规模图上的效率，我们进一步提出了LS-FCS-HGNN，它结合了：i）邻居采样策略以提高训练效率，以及ii）基于深度的启发式搜索策略以提高查询效率。我们进行了广泛的实验，以展示我们提出的方法相对于最先进方法的优越性，在单一类型和多类型社区上分别实现了14.3%和11.1%的平均改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FCS-HGNN:+Flexible+Multi-type+Community+Search+in+Heterogeneous+Information+Networks)|0|
|[ELCoRec: Enhance Language Understanding with Co-Propagation of Numerical and Categorical Features for Recommendation](https://doi.org/10.1145/3627673.3679789)|Jizheng Chen, Kounianhua Du, Jianghao Lin, Bo Chen, Ruiming Tang, Weinan Zhang, Yong Yu||Large language models have been flourishing in the natural language processing (NLP) domain, and their potential for recommendation has been paid much attention to. Despite the intelligence shown by the recommendation-oriented finetuned models, LLMs struggle to fully understand the user behavior patterns due to their innate weakness in interpreting numerical features and the overhead for long context, where the temporal relations among user behaviors, subtle quantitative signals among different ratings, and various side features of items are not well explored. Existing works only fine-tune a sole LLM on given text data without introducing that important information to it, leaving these problems unsolved. In this paper, we propose ELCoRec to Enhance Language understanding with CoPropagation of numerical and categorical features for Recommendation. Concretely, we propose to inject the preference understanding capability into LLM via a GAT expert model where the user preference is better encoded by parallelly propagating the temporal relations, and rating signals as well as various side information of historical items. The parallel propagation mechanism could stabilize heterogeneous features and offer an informative user preference encoding, which is then injected into the language models via soft prompting at the cost of a single token embedding. To further obtain the user's recent interests, we proposed a novel Recent interaction Augmented Prompt (RAP) template. Experiment results over three datasets against strong baselines validate the effectiveness of ELCoRec. The code is available at https://anonymous.4open.science/r/CIKM_Code_Repo-E6F5/README.md.|大型语言模型在自然语言处理（NLP）领域蓬勃发展，其在推荐系统中的潜力也备受关注。尽管面向推荐的微调模型展现了智能性，但大型语言模型（LLMs）由于其固有的对数值特征解释的弱点以及长上下文处理的负担，难以完全理解用户行为模式。这些模式包括用户行为之间的时间关系、不同评分之间的细微数量信号以及项目各种侧边特征等，都未得到充分探索。现有工作仅在给定文本数据上对单一LLM进行微调，而未引入这些重要信息，导致这些问题未得到解决。本文提出ELCoRec，旨在通过数值和类别特征的协同传播来增强语言理解，以提升推荐效果。具体而言，我们提出通过一个图注意力网络（GAT）专家模型将偏好理解能力注入LLM，其中用户偏好通过并行传播时间关系、评分信号以及历史项目的各种侧信息得到更好编码。这种并行传播机制能够稳定异构特征，并提供信息丰富的用户偏好编码，随后通过单个令牌嵌入的软提示方式注入语言模型。为进一步捕捉用户的近期兴趣，我们提出了新颖的近期交互增强提示（RAP）模板。在三个数据集上与强基线方法的实验结果验证了ELCoRec的有效性。代码可访问https://anonymous.4open.science/r/CIKM_Code_Repo-E6F5/README.md获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ELCoRec:+Enhance+Language+Understanding+with+Co-Propagation+of+Numerical+and+Categorical+Features+for+Recommendation)|0|
|[Social Influence Learning for Recommendation Systems](https://doi.org/10.1145/3627673.3679598)|Ximing Chen, Pui Ieng Lei, Yijun Sheng, Yanyan Liu, Zhiguo Gong|University of Macau, Macau, China|Social recommendation systems leverage the social relations among users to deal with the inherent cold-start problem in user-item interactions. However, previous models only treat the social graph as the static auxiliary to the user-item interaction graph, rather than dig out the hidden essentials and optimize them for better recommendations. Thus, the potential of social influence is still under-explored. In this paper, we will fill this gap by proposing a novel model for social influence learning to derive the essential influence patterns within the user relationships. Our model views the social influence from the perspectives of (1) the diversity of neighborhood's influence on the users, (2) the disentanglement of neighborhood's influence on the users, and (3) the exploration of underlying implicit social influence. To this end, we first employ a novel layerwise graph-enhanced variational autoencoder for the reconstruction of neighborhoods' representations, which aims to learn the pattern of social influence as well as simulate the social profile of each user for overcoming the sparsity issue in social relation data. Meanwhile, we introduce a layerwise graph attentive network for capturing the most influential scope of neighborhood. Finally, we adopt a dual sampling process to generate new social relations for enhancing the social recommendation. Extensive experiments have been conducted on three widely-used benchmark datasets, verifying the superiority of our proposed model compared with the representative approaches.|社交推荐系统利用用户之间的社交关系来应对用户-物品交互中固有的冷启动问题。然而，以往的模型仅将社交图视为用户-物品交互图的静态辅助，而未深入挖掘隐藏的基本要素并对其进行优化以实现更好的推荐。因此，社交影响力的潜力仍未得到充分探索。本文通过提出一种新的社交影响力学习模型来填补这一空白，旨在从用户关系中提取基本的影响模式。我们的模型从以下三个角度看待社交影响力：（1）邻域对用户影响的多样性，（2）邻域对用户影响的解耦，以及（3）潜在隐性社交影响力的探索。为此，我们首先采用了一种新颖的分层图增强变分自编码器来重构邻域的表示，旨在学习社交影响力的模式并模拟每个用户的社交概况，以克服社交关系数据中的稀疏性问题。同时，我们引入了一种分层图注意力网络来捕捉邻域中最具影响力的范围。最后，我们采用双重采样过程来生成新的社交关系，以增强社交推荐。我们在三个广泛使用的基准数据集上进行了大量实验，验证了我们提出的模型相对于代表性方法的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Social+Influence+Learning+for+Recommendation+Systems)|0|
|[Enhancing Deep Entity Resolution with Integrated Blocker-Matcher Training: Balancing Consensus and Discrepancy](https://doi.org/10.1145/3627673.3679843)|Wenzhou Dou, Derong Shen, Xiangmin Zhou, Hui Bai, Yue Kou, Tiezheng Nie, Hang Cui, Ge Yu|RMIT University, Melbourne, Australia; University of Illinois at Urbana-Champaign, Urbana, USA; Northeastern University, Shenyang, China|Deep entity resolution (ER) identifies matching entities across data sources using techniques based on deep learning. It involves two steps: a blocker for identifying the potential matches to generate the candidate pairs, and a matcher for accurately distinguishing the matches and non-matches among these candidate pairs. Recent deep ER approaches utilize pretrained language models (PLMs) to extract similarity features for blocking and matching, achieving state-of-the-art performance. However, they often fail to balance the consensus and discrepancy between the blocker and matcher, emphasizing the consensus while neglecting the discrepancy. This paper proposes MutualER, a deep entity resolution framework that integrates and jointly trains the blocker and matcher, balancing both the consensus and discrepancy between them. Specifically, we firstly introduce a lightweight PLM in siamese structure for the blocker and a heavier PLM in cross structure or an autoregressive large language model (LLM) for the matcher. Two optimization techniques named Mutual Sample Selection (MSS) and Similarity Knowledge Transferring (SKT) are designed to jointly train the blocker and matcher. MSS enables the blocker and matcher to mutually select the customized training samples for each other to maintain the discrepancy, while SKT allows them to share the similarity knowledge for improving their blocking and matching capabilities respectively to maintain the consensus. Extensive experiments on five datasets demonstrate that MutualER significantly outperforms existing PLM-based and LLM-based approaches, achieving leading performance in both effectiveness and efficiency.|深度实体解析（ER）利用基于深度学习的技术，识别跨数据源的匹配实体。它包括两个步骤：用于识别潜在匹配以生成候选对的阻塞器，以及用于在这些候选对中准确区分匹配与非匹配的匹配器。最近的深度ER方法利用预训练语言模型（PLMs）来提取用于阻塞和匹配的相似性特征，从而达到最先进的性能。然而，这些方法往往未能平衡阻塞器和匹配器之间的共识与差异，过于强调共识而忽视了差异。本文提出了MutualER，这是一个深度实体解析框架，它整合并联合训练阻塞器和匹配器，平衡两者之间的共识与差异。具体来说，我们首先在阻塞器中引入一个轻量级的PLM，采用孪生结构，而在匹配器中使用更重的PLM，采用交叉结构或自回归大型语言模型（LLM）。我们设计了两种优化技术，名为互样本选择（MSS）和相似性知识转移（SKT），以联合训练阻塞器和匹配器。MSS使阻塞器和匹配器能够相互选择定制的训练样本，以保持差异，而SKT则允许它们共享相似性知识，以分别提高各自的阻塞和匹配能力，从而保持共识。在五个数据集上的广泛实验表明，MutualER显著优于现有的基于PLM和LLM的方法，在效果和效率方面均达到了领先水平。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Deep+Entity+Resolution+with+Integrated+Blocker-Matcher+Training:+Balancing+Consensus+and+Discrepancy)|0|
|[CHDAER: Consistent Hashing-based Data Allocation for Efficient Recommendation in Edge Environment](https://doi.org/10.1145/3627673.3679809)|Zhikang Feng, Chao Yan, Rong Jiang, Xiaolong Xu, Xuyun Zhang, Xiaokang Zhou, Wanchun Dou, Lianyong Qi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CHDAER:+Consistent+Hashing-based+Data+Allocation+for+Efficient+Recommendation+in+Edge+Environment)|0|
|[HierRec: Scenario-Aware Hierarchical Modeling for Multi-scenario Recommendations](https://doi.org/10.1145/3627673.3679615)|Jingtong Gao, Bo Chen, Menghui Zhu, Xiangyu Zhao, Xiaopeng Li, Yuhao Wang, Yichao Wang, Huifeng Guo, Ruiming Tang|City University of Hong Kong, Hong Kong, Hong Kong; Huawei Noah's Ark Lab, Shenzhen, China|Click-Through Rate (CTR) prediction is a fundamental technique in recommendation and advertising systems. Recent studies have shown that implementing multi-scenario recommendations contributes to strengthening information sharing and improving overall performance. However, existing multi-scenario models only consider coarse-grained explicit scenario modeling that depends on pre-defined scenario identification from manual prior rules, which is biased and sub-optimal. To address these limitations, we propose a Scenario-Aware Hierarchical Dynamic Network for Multi-Scenario Recommendations (HierRec), which perceives implicit patterns adaptively, and conducts explicit and implicit scenario modeling jointly. In particular, HierRec designs a basic scenario-oriented module based on the dynamic weight to capture scenario-specific representations. Then the hierarchical explicit and implicit scenario-aware modules are proposed to model hybrid-grained scenario information, where the multi-head implicit modeling design contributes to perceiving distinctive patterns from different perspectives. Our experiments on two public datasets and real-world industrial applications on a mainstream online advertising platform demonstrate that HierRec outperforms existing models significantly. The implementation code is available for reproducibility.|点击率（CTR）预测是推荐和广告系统中的基础技术。近期的研究表明，实施多场景推荐有助于增强信息共享并提升整体性能。然而，现有的多场景模型仅考虑基于预定义场景识别的粗粒度显式场景建模，这种识别依赖于人工先验规则，存在偏差且效果不佳。为解决这些局限，我们提出了面向多场景推荐的场景感知分层动态网络（HierRec），该网络能够自适应地感知隐式模式，并联合进行显式和隐式场景建模。具体而言，HierRec设计了一个基于动态权重的基本场景导向模块，以捕捉特定场景的表示。随后，提出了分层的显式和隐式场景感知模块，用于建模混合粒度的场景信息，其中多头的隐式建模设计有助于从不同角度感知独特的模式。我们在两个公开数据集以及主流在线广告平台的实际工业应用中的实验表明，HierRec显著优于现有的模型。实现代码已公开，便于复现。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HierRec:+Scenario-Aware+Hierarchical+Modeling+for+Multi-scenario+Recommendations)|0|
|[Information Retrieval Optimization for Non-Exemplar Class Incremental Learning](https://doi.org/10.1145/3627673.3679631)|Shuai Guo, Yang Gu, Yuan Ma, Yingwei Zhang, Weining Weng, Jun Liu, Weiwei Dai, Yiqiang Chen||Existing non-example class-incremental learning (NECIL) methods usually utilize a combination strategy of replay mechanism and knowledge distillation. However, this combination strategy only focuses on the preservation of old information quantitatively, ignoring the preservation quality. When the old knowledge has wrong redundant information, catastrophic forgetting is more likely to occur. Therefore, obtaining adequate information without impurities as much as possible and removing invalid or even harmful information has become an effective solution to improve the performance of NECIL. This process is consistent with the information bottleneck (IB) theory. Thus, we propose a new NECIL method based on the IB framework. By using the different information obtained from the new and old class samples and the implicit knowledge in the teacher model training process, the error of harmful redundant information learned is eliminated. Specifically, we propose two optimization strategies that align with the two optimization processes of the information bottleneck. Firstly, we employ a pseudo-prototype selection mechanism that selectively incorporates pseudo-samples into the learning process of new and old categories, thus enhancing the distinction between new and old categories and diminishing the mutual information between the input and intermediate features. Secondly, we introduce an attention-based feature distillation method that regulates the distillation strength between feature pairs based on their similarity, thereby augmenting the mutual information between intermediate features and output prediction. Extensive experiments on three benchmarks demonstrate that the proposed method exhibits significant incremental performance improvements over existing methods.|现有的非示例类增量学习（NECIL）方法通常采用回放机制和知识蒸馏的组合策略。然而，这种组合策略仅关注旧信息的定量保存，忽略了保存的质量。当旧知识包含错误的冗余信息时，灾难性遗忘更容易发生。因此，尽可能获取无杂质的充足信息并去除无效甚至有害信息，已成为提升NECIL性能的有效解决方案。这一过程与信息瓶颈（IB）理论相一致。因此，我们提出了一种基于IB框架的新NECIL方法。通过利用新旧类别样本获取的不同信息以及教师模型训练过程中蕴含的隐性知识，消除了有害冗余信息学习的错误。具体而言，我们提出了两种优化策略，分别对应信息瓶颈的两个优化过程。首先，我们采用伪原型选择机制，有选择地将伪样本纳入新旧类别的学习过程，从而增强新旧类别之间的区分度，并减少输入与中间特征之间的互信息。其次，我们引入了一种基于注意力的特征蒸馏方法，根据特征对之间的相似性调节蒸馏强度，从而增强中间特征与输出预测之间的互信息。在三个基准上的大量实验表明，所提出的方法相较于现有方法显著提升了增量学习性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Information+Retrieval+Optimization+for+Non-Exemplar+Class+Incremental+Learning)|0|
|[Fragment Allocations for Partially Replicated Databases Considering Data Modifications and Changing Workloads](https://doi.org/10.1145/3627673.3679767)|Stefan Halfpap, Rainer Schlosser|Hasso Plattner Institute, Potsdam, Germany; BIFOLD, TU Berlin, Berlin, Germany|Columnar database systems can process complex mixed workloads on a single node. In case of increasing and peak analytical processing demand, we can offload read-only queries to replicas. Partial replication, i.e., duplicating only data subsets to additional nodes, is more cost-efficient than full replication for two primary reasons: (i) Partial replicas require less storage and can be set up faster. (ii) Partial replicas must synchronize only stored data subsets, allowing better scalability. However, determining which queries to offload is challenging for larger workloads because queries access overlapping data subsets and cause synchronization costs. This paper shows how to calculate optimized replica configurations that consider reallocation and data modification costs using integer linear programming (ILP) techniques. While ILP is effective for solving assignment problems, it does not scale well. For larger problems, users often fall back to simple heuristics, which can lose optimization potential. This paper demonstrates that scalable heuristics can be built on ILP, preserving its strengths. The three proposed approaches for reducing the calculation time allow trading solution quality flexibly. Our evaluations using TPC-H, TPC-DS, and a large real-world accounting workload show that our approach outperforms state-of-the-art solutions, often reducing reallocated data by more than 80% and halving modification costs. At the same time, the new allocations reduce the storage consumption by over 30%, with solutions computed in just a few seconds.|列式数据库系统能够在单个节点上处理复杂的混合工作负载。在分析处理需求增加和达到峰值的情况下，我们可以将只读查询卸载到副本上。部分复制，即仅将数据子集复制到附加节点，相较于全复制更为成本高效，主要原因有两点：(i) 部分副本所需的存储较少，且设置速度更快；(ii) 部分副本仅需同步存储的数据子集，从而实现更好的可扩展性。然而，对于较大的工作负载，确定哪些查询应被卸载是一个挑战，因为查询访问重叠的数据子集，并导致同步成本增加。本文展示了如何使用整数线性规划（ILP）技术计算优化的副本配置，考虑了重新分配和数据修改成本。尽管ILP在解决分配问题方面有效，但其扩展性不佳。对于较大的问题，用户通常会回退到简单的启发式方法，这可能会失去优化的潜力。本文证明，可扩展的启发式方法可以建立在ILP基础上，保留其优势。所提出的三种减少计算时间的方法允许灵活地权衡解决方案的质量。我们使用TPC-H、TPC-DS和大规模真实会计工作负载的评估显示，我们的方法优于最先进的解决方案，通常将重新分配的数据减少超过80%，并将修改成本减半。同时，新的分配方案将存储消耗减少了30%以上，且解决方案在几秒钟内即可计算完成。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fragment+Allocations+for+Partially+Replicated+Databases+Considering+Data+Modifications+and+Changing+Workloads)|0|
|[Practical and Robust Safety Guarantees for Advanced Counterfactual Learning to Rank](https://doi.org/10.1145/3627673.3679531)|Shashank Gupta, Harrie Oosterhuis, Maarten de Rijke||Counterfactual learning to rank (CLTR ) can be risky; various circumstances can cause it to produce sub-optimal models that hurt performance when deployed. Safe CLTR was introduced to mitigate these risks when using inverse propensity scoring to correct for position bias. However, the existing safety measure for CLTR is not applicable to state-of-the-art CLTR, it cannot handle trust bias, and its guarantees rely on specific assumptions about user behavior. Our contributions are two-fold. First, we generalize the existing safe CLTR approach to make it applicable to state-of-the-art doubly robust (DR) CLTR and trust bias. Second, we propose a novel approach, proximal ranking policy optimization (PRPO ), that provides safety in deployment without assumptions about user behavior. PRPO removes incentives for learning ranking behavior that is too dissimilar to a safe ranking model. Thereby, PRPO imposes a limit on how much learned models can degrade performance metrics, without relying on any specific user assumptions. Our experiments show that both our novel safe doubly robust method and PRPO provide higher performance than the existing safe inverse propensity scoring approach. However, when circumstances are unexpected, the safe doubly robust approach can become unsafe and bring detrimental performance. In contrast, PRPO always maintains safety, even in maximally adversarial situations. By avoiding assumptions, PRPO is the first method with unconditional safety in deployment that translates to robust safety for real-world applications.|反事实学习排序（CLTR）存在风险；多种情况可能导致其生成次优模型，从而在部署时损害性能。安全CLTR被引入以在使用逆倾向评分来纠正位置偏差时减轻这些风险。然而，现有的CLTR安全措施不适用于最先进的CLTR，无法处理信任偏差，并且其安全保证依赖于对用户行为的特定假设。我们的贡献有两方面。首先，我们将现有的安全CLTR方法推广到适用于最先进的双重稳健（DR）CLTR和信任偏差。其次，我们提出了一种新颖的方法，即近端排序策略优化（PRPO），该方法在部署时提供安全性，而无需对用户行为做出任何假设。PRPO消除了学习与安全排序模型过于不同的排序行为的激励。因此，PRPO在不依赖任何特定用户假设的情况下，对学习模型可能降低性能指标的程度施加了限制。我们的实验表明，我们的新颖安全双重稳健方法和PRPO都比现有的安全逆倾向评分方法提供了更高的性能。然而，在遇到意外情况时，安全双重稳健方法可能会变得不安全并带来有害的性能。相比之下，PRPO始终保持安全，即使在最恶劣的对抗情况下也是如此。通过避免假设，PRPO是第一种在部署时具有无条件安全性的方法，这为实际应用带来了强大的安全性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Practical+and+Robust+Safety+Guarantees+for+Advanced+Counterfactual+Learning+to+Rank)|0|
|[Quantum Cognition-Inspired EEG-based Recommendation via Graph Neural Networks](https://doi.org/10.1145/3627673.3679564)|Jinkun Han, Wei Li, Yingshu Li, Zhipeng Cai|Department of Computer Science, Georgia State University, Atlanta, Georgia, USA|Current recommendation systems recommend goods by considering users' historical behaviors, social relations, ratings, and other multi-modals. Although outdated user information presents the trends of a user's interests, no recommendation system can know the users' real-time thoughts indeed. With the development of brain-computer interfaces, it is time to explore next-generation recommenders that show users' real-time thoughts without delay. Electroencephalography (EEG) is a promising method of collecting brain signals because of its convenience and mobility. Currently, there is only few research on EEG-based recommendations due to the complexity of learning human brain activity. To explore the utility of EEG-based recommendation, we propose a novel neural network model, QUARK, combining Quantum Cognition Theory and Graph Convolutional Networks for accurate item recommendations. Compared with the state-of-the-art recommendation models, the superiority of QUARK is confirmed via extensive experiments.|当前的推荐系统通过考虑用户的历史行为、社交关系、评分以及其他多模态信息来推荐商品。尽管过时的用户信息展示了用户兴趣的趋势，但没有任何推荐系统能够真正了解用户的实时想法。随着脑机接口的发展，是时候探索下一代推荐系统，这些系统能够即时展示用户的实时想法。脑电图（EEG）是一种有前景的收集脑信号的方法，因其便捷性和移动性。目前，由于学习人类脑活动复杂性，基于脑电图的推荐研究还很少。为了探索基于脑电图的推荐的实用性，我们提出了一种新颖的神经网络模型——QUARK，它结合了量子认知理论和图卷积网络，以实现准确的项目推荐。通过广泛的实验，QUARK相较于最先进的推荐模型展现出了优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quantum+Cognition-Inspired+EEG-based+Recommendation+via+Graph+Neural+Networks)|0|
|[From Retrieval to Generation: Efficient and Effective Entity Set Expansion](https://doi.org/10.1145/3627673.3679837)|Shulin Huang, Shirong Ma, Yangning Li, Yinghui Li, HaiTao Zheng||Entity Set Expansion (ESE) is a critical task aiming at expanding entities of the target semantic class described by seed entities. Most existing ESE methods are retrieval-based frameworks that need to extract contextual features of entities and calculate the similarity between seed entities and candidate entities. To achieve the two purposes, they iteratively traverse the corpus and the entity vocabulary, resulting in poor efficiency and scalability. Experimental results indicate that the time consumed by the retrieval-based ESE methods increases linearly with entity vocabulary and corpus size. In this paper, we firstly propose Generative Entity Set Expansion (GenExpan) framework, which utilizes a generative pre-trained auto-regressive language model to accomplish ESE task. Specifically, a prefix tree is employed to guarantee the validity of entity generation, and automatically generated class names are adopted to guide the model to generate target entities. Moreover, we propose Knowledge Calibration and Generative Ranking to further bridge the gap between generic knowledge of the language model and the goal of ESE task. For efficiency, expansion time consumed by GenExpan is independent of entity vocabulary and corpus size, and GenExpan achieves an average 600% speedup compared to strong baselines. For expansion effectiveness, our framework outperforms previous state-of-the-art ESE methods.|实体集扩展（Entity Set Expansion, ESE）是一项关键任务，旨在通过种子实体扩展目标语义类别的实体。大多数现有的ESE方法基于检索框架，需要提取实体的上下文特征并计算种子实体与候选实体之间的相似度。为了实现这两个目的，它们需要迭代遍历语料库和实体词汇表，导致效率和扩展性较差。实验结果表明，基于检索的ESE方法所消耗的时间随实体词汇表和语料库大小的增加而线性增长。在本文中，我们首先提出了生成式实体集扩展（Generative Entity Set Expansion, GenExpan）框架，该框架利用生成式预训练的自回归语言模型来完成ESE任务。具体而言，我们使用前缀树来保证实体生成的有效性，并采用自动生成的类别名称来指导模型生成目标实体。此外，我们提出了知识校准和生成式排序，以进一步缩小语言模型的通用知识与ESE任务目标之间的差距。在效率方面，GenExpan所消耗的扩展时间与实体词汇表和语料库大小无关，并且与强基线相比，GenExpan实现了平均600%的加速。在扩展效果方面，我们的框架优于之前最先进的ESE方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=From+Retrieval+to+Generation:+Efficient+and+Effective+Entity+Set+Expansion)|0|
|[RD-P: A Trustworthy Retrieval-Augmented Prompter with Knowledge Graphs for LLMs](https://doi.org/10.1145/3627673.3679659)|Yubo Huang, Guosun Zeng|Tongji University, Shanghai, China|Large Language Models (LLMs) face challenges due to hallucination issues. Current solutions use retrieval-augmented generation (RAG), integrating LLMs with external knowledge to enhance answer accuracy. However, the misuse of irrelevant external knowledge can be misleading. In this paper, we propose a novel method called Retrieve-and-Discriminate Prompter (RD-P), which leverages knowledge graphs (KGs) for trustworthy RAG by synchronizing knowledge retrieval and discrimination in a unified model. Specifically, we train a prompter based on a pre-trained language model with shared parameters. It has two key modules: the retriever and the discriminator. The retriever identifies relevant reasoning paths in the KG, while the discriminator evaluates their credibility through "logical coverage calculation" and in turn instructs the retrieval process. Prompts are then constructed to guide LLMs in reasoning and answering questions using both retrieved and implicit knowledge. Experiments on knowledge-intensive question answering (QA) tasks demonstrate that our method significantly improves answer coverage rate while reducing the retrieval scale, achieving superior performance in complex KGQA tasks compared with state-of-the-art RAG methods at a low cost.|大型语言模型（LLMs）面临幻觉问题的挑战。当前的解决方案采用检索增强生成（RAG），将LLMs与外部知识整合以提高答案的准确性。然而，不相关外部知识的误用可能会产生误导。在本文中，我们提出了一种名为“检索与鉴别提示器”（Retrieve-and-Discriminate Prompter, RD-P）的新方法，该方法通过在统一模型中同步知识检索与鉴别，利用知识图谱（KGs）实现可信的RAG。具体而言，我们基于一个具有共享参数的预训练语言模型训练了一个提示器，该提示器包含两个关键模块：检索器和鉴别器。检索器在KG中识别相关的推理路径，而鉴别器通过“逻辑覆盖计算”评估这些路径的可信度，并反过来指导检索过程。随后，构建提示以指导LLMs使用检索到的知识和隐含知识进行推理并回答问题。在知识密集型问答（QA）任务上的实验表明，我们的方法显著提高了答案覆盖率，同时减少了检索规模，在复杂KGQA任务中以较低成本实现了优于现有RAG方法的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RD-P:+A+Trustworthy+Retrieval-Augmented+Prompter+with+Knowledge+Graphs+for+LLMs)|0|
|[Understanding GNNs for Boolean Satisfiability through Approximation Algorithms](https://doi.org/10.1145/3627673.3679813)|Jan Hula, David Mojzísek, Mikolás Janota||The paper deals with the interpretability of Graph Neural Networks in the context of Boolean Satisfiability. The goal is to demystify the internal workings of these models and provide insightful perspectives into their decision-making processes. This is done by uncovering connections to two approximation algorithms studied in the domain of Boolean Satisfiability: Belief Propagation and Semidefinite Programming Relaxations. Revealing these connections has empowered us to introduce a suite of impactful enhancements. The first significant enhancement is a curriculum training procedure, which incrementally increases the problem complexity in the training set, together with increasing the number of message passing iterations of the Graph Neural Network. We show that the curriculum, together with several other optimizations, reduces the training time by more than an order of magnitude compared to the baseline without the curriculum. Furthermore, we apply decimation and sampling of initial embeddings, which significantly increase the percentage of solved problems.|本文探讨了在布尔可满足性（Boolean Satisfiability）背景下图神经网络（Graph Neural Networks, GNN）的可解释性问题。其目标在于揭秘这些模型的内部运作机制，并深入洞察其决策过程。通过揭示与布尔可满足性领域内两种近似算法——信念传播（Belief Propagation）和半定规划松弛（Semidefinite Programming Relaxations）之间的联系，我们得以引入一系列具有影响力的改进措施。首先，一个显著的改进是课程训练程序，该程序在训练集中逐步增加问题复杂度，同时提升图神经网络的消息传递迭代次数。研究表明，结合课程训练与其他多项优化措施，相较于无课程训练的基线模型，训练时间减少了超过一个数量级。此外，我们还采用了初始嵌入的降维和采样技术，这显著提高了问题解决的百分比。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+GNNs+for+Boolean+Satisfiability+through+Approximation+Algorithms)|0|
|[HiQuE: Hierarchical Question Embedding Network for Multimodal Depression Detection](https://doi.org/10.1145/3627673.3679797)|Juho Jung, Chaewon Kang, Jeewoo Yoon, Seungbae Kim, Jinyoung Han||The utilization of automated depression detection significantly enhances early intervention for individuals experiencing depression. Despite numerous proposals on automated depression detection using recorded clinical interview videos, limited attention has been paid to considering the hierarchical structure of the interview questions. In clinical interviews for diagnosing depression, clinicians use a structured questionnaire that includes routine baseline questions and follow-up questions to assess the interviewee's condition. This paper introduces HiQuE (Hierarchical Question Embedding network), a novel depression detection framework that leverages the hierarchical relationship between primary and follow-up questions in clinical interviews. HiQuE can effectively capture the importance of each question in diagnosing depression by learning mutual information across multiple modalities. We conduct extensive experiments on the widely-used clinical interview data, DAIC-WOZ, where our model outperforms other state-of-the-art multimodal depression detection models and emotion recognition models, showcasing its clinical utility in depression detection.|自动化抑郁症检测的利用显著增强了针对抑郁症患者的早期干预。尽管已有众多关于使用录制的临床访谈视频进行自动化抑郁症检测的提议，但很少有研究考虑到访谈问题之间的层次结构。在诊断抑郁症的临床访谈中，临床医生使用包含常规基线问题和后续问题的结构化问卷来评估受访者的状况。本文介绍了HiQuE（分层问题嵌入网络），这是一种利用临床访谈中主要问题与后续问题之间层次关系的新型抑郁症检测框架。HiQuE通过跨多种模态学习互信息，能够有效捕捉每个问题在抑郁症诊断中的重要性。我们在广泛使用的临床访谈数据DAIC-WOZ上进行了大量实验，结果表明，我们的模型在多模态抑郁症检测和情感识别模型中表现优于其他最先进的模型，展示了其在抑郁症检测中的临床实用性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HiQuE:+Hierarchical+Question+Embedding+Network+for+Multimodal+Depression+Detection)|0|
|[Embedding Knowledge Graphs in Function Spaces](https://doi.org/10.1145/3627673.3679819)|Louis Mozart Kamdem Teyou, Caglar Demir, AxelCyrille Ngonga Ngomo||We introduce a novel embedding method diverging from conventional approaches by operating within function spaces of finite dimension rather than finite vector space, thus departing significantly from standard knowledge graph embedding techniques. Initially employing polynomial functions to compute embeddings, we progress to more intricate representations using neural networks with varying layer complexities. We argue that employing functions for embedding computation enhances expressiveness and allows for more degrees of freedom, enabling operations such as composition, derivatives and primitive of entities representation. Additionally, we meticulously outline the step-by-step construction of our approach and provide code for reproducibility, thereby facilitating further exploration and application in the field.|我们提出了一种新颖的嵌入方法，该方法与传统方法不同，它在有限维函数空间中进行操作，而非有限维向量空间，从而显著区别于标准的知识图谱嵌入技术。初始阶段使用多项式函数来计算嵌入，随后我们采用具有不同层复杂度的神经网络来实现更为复杂的表示。我们认为，使用函数进行嵌入计算能够增强表达能力，并提供更多的自由度，使得实体表示的组合、导数和原函数等操作成为可能。此外，我们详细描述了该方法的逐步构建过程，并提供了可重复使用的代码，从而促进该领域内的进一步探索和应用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Embedding+Knowledge+Graphs+in+Function+Spaces)|0|
|[Federated Deep Equilibrium Learning: Harnessing Compact Global Representations to Enhance Personalization](https://doi.org/10.1145/3627673.3679752)|Long Tan Le, Tuan Dung Nguyen, TungAnh Nguyen, Choong Seon Hong, Suranga Seneviratne, Wei Bao, Nguyen H. Tran|Kyung Hee University, Yongin-si, Republic of Korea; The University of Sydney, Sydney, NSW, Australia; The University of Pennsylvania, Philadelphia, PA, USA|Federated Learning (FL) has emerged as a groundbreaking distributed learning paradigm enabling clients to train a global model collaboratively without exchanging data. Despite enhancing privacy and efficiency in information retrieval and knowledge management contexts, training and deploying FL models confront significant challenges such as communication bottlenecks, data heterogeneity, and memory limitations. To comprehensively address these challenges, we introduce FeDEQ, a novel FL framework that incorporates deep equilibrium learning and consensus optimization to harness compact global data representations for efficient personalization. Specifically, we design a unique model structure featuring an equilibrium layer for global representation extraction, followed by explicit layers tailored for local personalization. We then propose a novel FL algorithm rooted in the alternating directions method of multipliers (ADMM), which enables the joint optimization of a shared equilibrium layer and individual personalized layers across distributed datasets. Our theoretical analysis confirms that FeDEQ converges to a stationary point, achieving both compact global representations and optimal personalized parameters for each client. Extensive experiments on various benchmarks demonstrate that FeDEQ matches the performance of state-of-the-art personalized FL methods, while significantly reducing communication size by up to 4 times and memory footprint by 1.5 times during training.|联邦学习（Federated Learning, FL）作为一种突破性的分布式学习范式，使得客户端能够在不交换数据的情况下协作训练全局模型。尽管在信息检索和知识管理领域中增强了隐私和效率，但训练和部署FL模型仍面临重大挑战，如通信瓶颈、数据异质性和内存限制。为了全面应对这些挑战，我们提出了FeDEQ，这是一种新颖的FL框架，它结合了深度平衡学习和共识优化，以利用紧凑的全局数据表示实现高效个性化。具体而言，我们设计了一种独特的模型结构，包括一个用于提取全局表示的平衡层，随后是专门为本地个性化定制的显式层。接着，我们提出了一种基于交替方向乘子法（ADMM）的新型FL算法，该算法能够联合优化分布式数据集中的共享平衡层和各个个性化层。我们的理论分析证实，FeDEQ能够收敛到一个平稳点，为每个客户端实现紧凑的全局表示和最优的个性化参数。在多个基准上的广泛实验表明，FeDEQ与最先进的个性化FL方法性能相当，同时在训练过程中将通信量减少了高达4倍，内存占用减少了1.5倍。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Federated+Deep+Equilibrium+Learning:+Harnessing+Compact+Global+Representations+to+Enhance+Personalization)|0|
|[Privacy-preserving Spatial Dataset Search in Cloud](https://doi.org/10.1145/3627673.3679733)|Pengyue Li, Hua Dai, Sheng Wang, Wenzhe Yang, Geng Yang|School of Computer Science, Wuhan University, Wuhan, China; School of Computer Science, Nanjing University of Posts and Telecommunications, Nanjing, China|The development of cloud computing has met the growing demand for dataset search in the era of massive data. In the field of spatial dataset search, the high prevalence of sensitive information in spatial datasets underscores the necessity of privacy-preserving search processing in the cloud. However, existing spatial dataset search schemes are designed on plaintext datasets and do not consider privacy protection in search processing. In this paper, we first propose a privacy-preserving spatial dataset search scheme. The density distribution-based similarity model is proposed to measure the similarity between spatial datasets, and then the order-preserving encrypted similarity is designed to achieve secure similarity calculation. With the above idea, the baseline search scheme (PriDAS) is proposed. To improve the search efficiency, a two-layer index is designed to filter candidate datasets and accelerate the similarity calculation between datasets. By using the index, the optimized search scheme (PriDAS+) is proposed. To analyze the security of the proposed schemes, the game simulation-based proof is presented. Experimental results on three real-world spatial data repositories with 100,000 spatial datasets show that PriDAS+ only needs less than 0.4 seconds to accomplish the search processing.|云计算的发展满足了大数据时代对数据集搜索日益增长的需求。在空间数据集搜索领域，空间数据集中敏感信息的高普及率突显了在云环境中进行隐私保护搜索处理的必要性。然而，现有的空间数据集搜索方案设计基于明文数据集，并未考虑搜索处理中的隐私保护。本文首先提出了一种隐私保护的空间数据集搜索方案。基于密度分布的相似性模型被提出用于衡量空间数据集之间的相似性，然后设计了顺序保持加密的相似性以实现安全的相似性计算。基于上述思路，提出了基线搜索方案（PriDAS）。为了提高搜索效率，设计了一个两层索引以过滤候选数据集并加速数据集之间的相似性计算。通过使用该索引，提出了优化的搜索方案（PriDAS+）。为了分析所提出方案的安全性，提出了基于博弈模拟的证明。在包含10万个空间数据集的三个真实世界空间数据存储库上的实验结果表明，PriDAS+仅需不到0.4秒即可完成搜索处理。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Privacy-preserving+Spatial+Dataset+Search+in+Cloud)|0|
|[Privacy-Preserving Graph Embedding based on Local Differential Privacy](https://doi.org/10.1145/3627673.3679759)|Zening Li, RongHua Li, Meihao Liao, Fusheng Jin, Guoren Wang|Beijing Institute of Technology, Beijing, China|Graph embedding has become a powerful tool for learning latent representations of nodes in a graph. Despite its superior performance in various graph-based machine learning tasks, serious privacy concerns arise when the graph data contains personal or sensitive information. To address this issue, we investigate and develop graph embedding algorithms that satisfy local differential privacy (LDP). We introduce a novel privacy-preserving graph embedding framework, named PrivGE, to protect node data privacy. Specifically, we propose an LDP mechanism to obfuscate node data and utilize personalized PageRank as the proximity measure to learn node representations. Furthermore, we provide a theoretical analysis of the privacy guarantees and utility offered by the PrivGE framework. Extensive experiments on several real-world graph datasets demonstrate that PrivGE achieves an optimal balance between privacy and utility, and significantly outperforms existing methods in node classification and link prediction tasks.|图嵌入已成为学习图中节点潜在表示的有力工具。尽管在各种基于图的机器学习任务中表现优异，但当图数据包含个人信息或敏感信息时，严重的隐私问题也随之产生。为解决这一问题，我们研究并开发了满足局部差分隐私（LDP）的图嵌入算法。我们引入了一种新的隐私保护图嵌入框架，命名为PrivGE，以保护节点数据隐私。具体而言，我们提出了一种LDP机制来混淆节点数据，并利用个性化PageRank作为接近度度量来学习节点表示。此外，我们对PrivGE框架提供的隐私保障和效用进行了理论分析。在多个真实世界图数据集上的广泛实验表明，PrivGE在隐私与效用之间实现了最佳平衡，并在节点分类和链接预测任务中显著优于现有方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Privacy-Preserving+Graph+Embedding+based+on+Local+Differential+Privacy)|0|
|[On Evaluation Metrics for Diversity-enhanced Recommendations](https://doi.org/10.1145/3627673.3679629)|Xueqi Li, Gao Cong, Guoqing Xiao, Yang Xu, Wenjun Jiang, Kenli Li|College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; Nanyang Technological University, Singapore, Singapore|Diversity is increasingly recognized as a crucial factor in recommendation systems for enhancing user satisfaction. However, existing studies on diversity-enhanced recommendation systems primarily focus on designing recommendation strategies, often overlooking the development of evaluation metrics. Widely used diversity metrics such as CC, ILAD, and ILMD are typically assessed independently of accuracy. This separation leads to a critical limitation: existing diversity measures are unable to distinguish between diversity improvements from effective recommendations and those from in effective recommendations. Our evaluations reveal that the diversity improvements are primarily contributed by ineffective recommendations, which often do not positively contribute to user satisfaction. Furthermore, existing diversity metrics disregard the feature distribution of ground-truth items, potentially skewing the assessment of diversity performance. To address these limitations, we design three new accuracy-aware metrics: DCC, FDCC, and DILAD, and conduct a re-evaluation using these metrics. Surprisingly, our results illustrate that the diversity improvements of existing diversity-enhanced approaches are limited and even negative compared to those of accurate recommendations. This finding underscores the need to explore more sophisticated diversity-enhanced techniques for improving the diversity within effective recommendations.|多样性在提升用户满意度的推荐系统中日益被视为一个关键因素。然而，现有关于增强多样性的推荐系统的研究主要集中在设计推荐策略上，往往忽视了评估指标的开发。广泛使用的多样性指标如CC、ILAD和ILMD通常独立于准确性进行评估。这种分离导致了一个关键的局限性：现有的多样性测量无法区分多样性改进是来自有效的推荐还是无效的推荐。我们的评估显示，多样性改进主要由无效推荐贡献，这些推荐往往对用户满意度没有积极贡献。此外，现有的多样性指标忽略了真实物品的特征分布，这可能扭曲了对多样性表现的评估。为了解决这些限制，我们设计了三种新的关注准确性的指标：DCC、FDCC和DILAD，并使用这些指标进行了重新评估。令人惊讶的是，我们的结果表明，现有增强多样性的方法在多样性改进方面是有限的，甚至相比于准确推荐是负面的。这一发现强调了需要探索更复杂的多样性增强技术，以提高有效推荐中的多样性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Evaluation+Metrics+for+Diversity-enhanced+Recommendations)|0|
|[RecDiff: Diffusion Model for Social Recommendation](https://doi.org/10.1145/3627673.3679630)|Zongwei Li, Lianghao Xia, Chao Huang||Social recommendation has emerged as a powerful approach to enhancepersonalized recommendations by leveraging the social connections among users,such as following and friend relations observed in online social platforms. Thefundamental assumption of social recommendation is that socially-connectedusers exhibit homophily in their preference patterns. This means that usersconnected by social ties tend to have similar tastes in user-item activities,such as rating and purchasing. However, this assumption is not always valid dueto the presence of irrelevant and false social ties, which can contaminate userembeddings and adversely affect recommendation accuracy. To address thischallenge, we propose a novel diffusion-based social denoising framework forrecommendation (RecDiff). Our approach utilizes a simple yet effectivehidden-space diffusion paradigm to alleivate the noisy effect in the compressedand dense representation space. By performing multi-step noise diffusion andremoval, RecDiff possesses a robust ability to identify and eliminate noisefrom the encoded user representations, even when the noise levels vary. Thediffusion module is optimized in a downstream task-aware manner, therebymaximizing its ability to enhance the recommendation process. We conductedextensive experiments to evaluate the efficacy of our framework, and theresults demonstrate its superiority in terms of recommendation accuracy,training efficiency, and denoising effectiveness. The source code for the modelimplementation is publicly available at: https://github.com/HKUDS/RecDiff.|社交推荐作为一种利用用户间社交关系（如在线社交平台中的关注和好友关系）来增强个性化推荐的方法，已经崭露头角。社交推荐的基本假设是，通过社交关系连接的用户在偏好模式上表现出同质性。这意味着通过社交纽带连接的用户在用户-项目活动（如评分和购买）中往往具有相似的品味。然而，由于存在无关和虚假的社交关系，这一假设并不总是成立，这些关系可能会污染用户嵌入，从而对推荐准确性产生负面影响。为了应对这一挑战，我们提出了一种基于扩散的社交去噪推荐框架（RecDiff）。我们的方法采用了一种简单而有效的隐空间扩散范式，以减轻压缩和密集表示空间中的噪声影响。通过执行多步噪声扩散和去除，RecDiff具有强大的能力来识别和消除编码用户表示中的噪声，即使在噪声水平变化的情况下也是如此。扩散模块以任务感知的方式进行优化，从而最大化其增强推荐过程的能力。我们进行了广泛的实验来评估我们框架的有效性，结果表明它在推荐准确性、训练效率和去噪效果方面具有优越性。该模型的实现代码已在以下公开可用：https://github.com/HKUDS/RecDiff。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RecDiff:+Diffusion+Model+for+Social+Recommendation)|0|
|[Efficient and Robust Regularized Federated Recommendation](https://doi.org/10.1145/3627673.3679682)|Langming Liu, Wanyu Wang, Xiangyu Zhao, Zijian Zhang, Chunxu Zhang, Shanru Lin, Yiqi Wang, Lixin Zou, Zitao Liu, Xuetao Wei, Hongzhi Yin, Qing Li|Jilin University, Changchun, China; Jinan University, Guangzhou, China; The University of Queensland, Brisbane, Australia; The Hong Kong Polytechnic University, Hong Kong, China; Michigan State University, East Lansing, USA; Wuhan University, Wuhan, China; City University of Hong Kong, Hong Kong, China; Southern University of Science and Technology, Shenzhen, China|Recommender systems play a pivotal role across practical scenarios, showcasing remarkable capabilities in user preference modeling. However, the centralized learning paradigm predominantly used raises serious privacy concerns. The federated recommender system (FedRS) addresses this by updating models on clients, while a central server orchestrates training without accessing private data. Existing FedRS approaches, however, face unresolved challenges, including non-convex optimization, vulnerability, potential privacy leakage risk, and communication inefficiency. This paper addresses these challenges by reformulating the federated recommendation problem as a convex optimization issue, ensuring convergence to the global optimum. Based on this, we devise a novel method, RFRec, to tackle this optimization problem efficiently. In addition, we propose RFRecF, a highly efficient version that incorporates non-uniform stochastic gradient descent to improve communication efficiency. In user preference modeling, both methods learn local and global models, collaboratively learning users' common and personalized interests under the federated learning setting. Moreover, both methods significantly enhance communication efficiency, robustness, and privacy protection, with theoretical support. Comprehensive evaluations on four benchmark datasets demonstrate RFRec and RFRecF's superior performance compared to diverse baselines.|推荐系统在实际应用场景中扮演着关键角色，展现了在用户偏好建模方面的显著能力。然而，目前主要采用的集中式学习模式引发了严重的隐私问题。联邦推荐系统（FedRS）通过在客户端更新模型来解决这一问题，同时中央服务器在不访问私人数据的情况下协调训练。尽管如此，现有的FedRS方法仍面临一些未解决的挑战，包括非凸优化、易受攻击性、潜在的隐私泄露风险以及通信效率低下。本文通过将联邦推荐问题重新表述为凸优化问题，确保了全局最优解的收敛性，从而应对这些挑战。基于此，我们设计了一种新型方法RFRec，以高效解决这一优化问题。此外，我们还提出了RFRecF，这是一种高效版本，结合了非均匀随机梯度下降以提高通信效率。在用户偏好建模方面，这两种方法都学习局部和全局模型，在联邦学习设置下协同学习用户的共同和个性化兴趣。此外，这两种方法在理论支持下显著提升了通信效率、鲁棒性和隐私保护。对四个基准数据集的综合评估表明，RFRec和RFRecF相较于多种基线方法表现更为优越。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+and+Robust+Regularized+Federated+Recommendation)|0|
|[Two Heads are Better than One: Zero-shot Cognitive Reasoning via Multi-LLM Knowledge Fusion](https://doi.org/10.1145/3627673.3679744)|Liang Liu, Dong Zhang, Shoushan Li, Guodong Zhou, Erik Cambria|School of Computer Science and Technology, Soochow University, Suzhou, China; College of Computing and Data Science, Nanyang Technological University, Singapore, Singapore|Cognitive reasoning holds a significant place within Natural Language Processing (NLP). Yet, the exploration of zero-shot scenarios, which align more closely with real-life situations than supervised scenarios, has been relatively limited. While a few studies have employed Large Language Models (LLMs) to tackle zero-shot cognitive reasoning tasks, they still grapple with two key challenges: 1) Traditional approaches rely on the chain-of-thought (CoT) mechanism, wherein LLMs are provided with a "Let's think step by step'' prompt. However, this schema may not accurately understand the meaning of a given question and ignores the possible learned knowledge (e.g., background or commonsense) of the LLMs about the questions, leading to incorrect answers. 2) Previous CoT methods normally exploit a single Large Language Model (LLM) and design many strategies to augment this LLM. We argue that the power of a single LLM is typically finite since it may not have learned some relevant knowledge about the question. To address these issues, we propose a Multi-LLM Knowledge Fusion (MLKF) approach, which resorts to heterogeneous knowledge emerging from multiple LLMs, for zero-shot cognitive reasoning tasks. Through extensive experiments and detailed analysis, we demonstrate that our MLKF can outperform the existing zero-shot or unsupervised state-of-the-art methods on four kinds of zero-shot tasks: aspect sentiment analysis, named entity recognition, question answering, and mathematical reasoning. Our code is available at https://github.com/trueBatty/MLKF|认知推理在自然语言处理（NLP）中占有重要地位。然而，零样本场景的研究相对较少，这些场景比监督场景更接近现实情况。尽管一些研究已经使用大型语言模型（LLMs）来解决零样本认知推理任务，但它们仍然面临两个关键挑战：1）传统方法依赖于思维链（CoT）机制，其中LLMs通过“让我们一步一步地思考”提示进行推理。然而，这种模式可能无法准确理解给定问题的含义，并且忽略了LLMs关于问题的潜在学习知识（例如背景或常识），导致答案错误。2）之前的CoT方法通常利用单一的大型语言模型（LLM），并设计多种策略来增强该LLM。我们认为，单一LLM的能力通常是有限的，因为它可能没有学习到与问题相关的某些知识。为了解决这些问题，我们提出了一种多LLM知识融合（MLKF）方法，该方法利用多个LLMs中涌现的异构知识来进行零样本认知推理任务。通过广泛的实验和详细分析，我们证明了我们的MLKF在四种零样本任务（方面情感分析、命名实体识别、问答和数学推理）上可以超越现有的零样本或无监督的最先进方法。我们的代码可在https://github.com/trueBatty/MLKF获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Two+Heads+are+Better+than+One:+Zero-shot+Cognitive+Reasoning+via+Multi-LLM+Knowledge+Fusion)|0|
|[Collaborative Fraud Detection on Large Scale Graph Using Secure Multi-Party Computation](https://doi.org/10.1145/3627673.3679863)|Xin Liu, Xiaoyu Fan, Rong Ma, Kun Chen, Yi Li, Guosai Wang, Wei Xu|Independent Researcher, Beijing, China; Tsingjiao Information Technology Co. Ltd., Beijing, China; Ant Group, Beijing, China; Tsinghua University, Beijing, China|Enabling various parties to share data enhances online fraud detection capabilities considering fraudsters tend to reuse resources attacking multiple platforms. Multi-party computation (MPC) techniques, such as secret sharing, offer potential privacy-preserving solutions but face efficiency challenges when handling large-scale data. This paper presents a novel approach, SecureFD (Secure Fraud Detector), aimed at detecting fraud in multi-party graph data, ensuring privacy, accuracy, and scalability. We propose a graph neural network EPR-GNN, which is MPC-friendly, as the base detector. Then we design a framework that allows multiple parties to train EPR-GNN collaboratively on secure sparse graphs in a privacy- preserving manner. The oblivious node embedding sharing protocol in the collaborative training procedure achieves up to a 45× speed-up, supporting over four million users compared to the naive solution. Additionally, we further reduce secure computation by locally pruning a significant number of non-suspicious users and selecting only the most valuable resources for sharing. Experiments on real datasets demonstrate that by securely integrating data from different parties, SecureFD achieves superior detection performance compared to state-of-the-art local detectors. And the local pruning greatly improves the scalability without compromising detection accuracies.|使各方能够共享数据增强了在线欺诈检测能力，因为欺诈者倾向于重复使用资源攻击多个平台。多方计算（MPC）技术，如秘密共享，提供了潜在的隐私保护解决方案，但在处理大规模数据时面临效率挑战。本文提出了一种新方法，SecureFD（安全欺诈检测器），旨在检测多方图数据中的欺诈行为，确保隐私、准确性和可扩展性。我们提出了一种图神经网络EPR-GNN，它对MPC友好，作为基础检测器。然后，我们设计了一个框架，允许多方在隐私保护的方式下，在安全稀疏图上协作训练EPR-GNN。协作训练过程中的不经意节点嵌入共享协议实现了高达45倍的速度提升，相比朴素解决方案，支持超过四百万用户。此外，我们通过本地修剪大量非可疑用户并仅选择最有价值的资源进行共享，进一步减少了安全计算。在真实数据集上的实验表明，通过安全地整合来自不同方的数据，SecureFD相比最先进的本地检测器实现了更优越的检测性能。而本地修剪极大地提高了可扩展性，且不影响检测准确性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Collaborative+Fraud+Detection+on+Large+Scale+Graph+Using+Secure+Multi-Party+Computation)|0|
|[AlignRec: Aligning and Training in Multimodal Recommendations](https://doi.org/10.1145/3627673.3679626)|Yifan Liu, Kangning Zhang, Xiangyuan Ren, Yanhua Huang, Jiarui Jin, Yingjie Qin, Ruilong Su, Ruiwen Xu, Yong Yu, Weinan Zhang||With the development of multimedia systems, multimodal recommendations are playing an essential role, as they can leverage rich contexts beyond interactions. Existing methods mainly regard multimodal information as an auxiliary, using them to help learn ID features; However, there exist semantic gaps among multimodal content features and ID-based features, for which directly using multimodal information as an auxiliary would lead to misalignment in representations of users and items. In this paper, we first systematically investigate the misalignment issue in multimodal recommendations, and propose a solution named AlignRec. In AlignRec, the recommendation objective is decomposed into three alignments, namely alignment within contents, alignment between content and categorical ID, and alignment between users and items. Each alignment is characterized by a specific objective function and is integrated into our multimodal recommendation framework. To effectively train AlignRec, we propose starting from pre-training the first alignment to obtain unified multimodal features and subsequently training the following two alignments together with these features as input. As it is essential to analyze whether each multimodal feature helps in training and accelerate the iteration cycle of recommendation models, we design three new classes of metrics to evaluate intermediate performance. Our extensive experiments on three real-world datasets consistently verify the superiority of AlignRec compared to nine baselines. We also find that the multimodal features generated by AlignRec are better than currently used ones, which are to be open-sourced in our repository https://github.com/sjtulyf123/AlignRec_CIKM24.|随着多媒体系统的发展，多模态推荐系统正发挥着至关重要的作用，因为它们能够利用超越交互的丰富上下文信息。现有的方法主要将多模态信息视为辅助手段，利用它们来帮助学习ID特征；然而，多模态内容特征与基于ID的特征之间存在语义鸿沟，直接将多模态信息作为辅助使用会导致用户和物品表示之间的对齐错误。在本文中，我们首先系统地研究了多模态推荐中的对齐问题，并提出了一种名为AlignRec的解决方案。在AlignRec中，推荐目标被分解为三种对齐方式，即内容内部对齐、内容与类别ID之间的对齐，以及用户与物品之间的对齐。每种对齐方式都由一个特定的目标函数表征，并被整合到我们的多模态推荐框架中。为了有效训练AlignRec，我们提出从预训练第一个对齐开始，以获得统一的多模态特征，随后将这些特征作为输入，同时训练后续的两个对齐。由于分析每个多模态特征是否有助于训练并加速推荐模型的迭代周期至关重要，我们设计了三类新的指标来评估中间性能。我们在三个真实世界数据集上的广泛实验一致验证了AlignRec相对于九个基线的优越性。我们还发现，由AlignRec生成的多模态特征优于当前使用的特征，这些特征将在我们的代码库https://github.com/sjtulyf123/AlignRec_CIKM24中开源。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AlignRec:+Aligning+and+Training+in+Multimodal+Recommendations)|0|
|[A Universal Sets-level Optimization Framework for Next Set Recommendation](https://doi.org/10.1145/3627673.3679610)|Yuli Liu, Min Liu, Christian Walder, Lexing Xie|; Australian National University, Canberra, Australia; Qinghai University & Australian National University, Xining, China; Google DeepMind, Montreal, Canada|Next Set Recommendation (NSRec), encompassing related tasks such as next basket recommendation and temporal sets prediction, stands as a trending research topic. Although numerous attempts have been made on this topic, there are certain drawbacks: (i) Existing studies are still confined to utilizing objective functions commonly found in Next Item Recommendation (NIRec), such as binary cross entropy and BPR, which are calculated based on individual item comparisons; (ii) They place emphasis on building sophisticated learning models to capture intricate dependency relationships across sequential sets, but frequently overlook pivotal dependency in their objective functions; (iii) Diversity factor within sequential sets is frequently overlooked. In this research, we endeavor to unveil a universal and Sets-level optimization framework for Next Set Recommendation (SNSRec), offering a holistic fusion of diversity distribution and intricate dependency relationships within temporal sets. To realize this, the following contributions are made: (i) We directly model the temporal set in a sequence as a cohesive entity, leveraging the Structured Determinantal Point Process (SDPP), wherein the probabilistic DPP distribution prioritizes collections of structures (sequential sets) instead of individual items; (ii) We introduce a co-occurrence representation to discern and acknowledge the importance of different sets; (iii) We propose a sets-level optimization criterion, which integrates the diversity distribution and dependency relations across the entire sequence of sets, guiding the model to recommend relevant and diversified set. Extensive experiments on real-world datasets show that our approach consistently outperforms previous methods on both relevance and diversity.|下一集合推荐（NSRec），包括下一篮子推荐和时间集合预测等相关的任务，已经成为一个热门的研究课题。尽管在这个领域已经有很多尝试，但仍存在一些不足：（i）现有的研究仍然局限于使用在下一项目推荐（NIRec）中常见的目标函数，如二元交叉熵和BPR，这些函数是基于单个项目的比较计算的；（ii）它们注重构建复杂的学习模型来捕捉序列集合之间的复杂依赖关系，但往往忽略了目标函数中的关键依赖关系；（iii）序列集合内的多样性因素经常被忽视。在本研究中，我们努力揭示一个通用的、集合级别的优化框架，用于下一集合推荐（SNSRec），提供了一个将多样性分布和时间集合内的复杂依赖关系全面融合的方案。为了实现这一点，我们做出了以下贡献：（i）我们将时间序列集合直接建模为一个有凝聚力的实体，利用结构化行列式点过程（SDPP），其中概率DPP分布优先考虑结构集合（序列集合）而不是单个项目；（ii）我们引入了一个共现表示来识别和承认不同集合的重要性；（iii）我们提出了一种集合级别的优化标准，该标准整合了整个序列集合的多样性分布和依赖关系，指导模型推荐相关且多样化的集合。在真实世界数据集上的广泛实验表明，我们的方法在相关性和多样性方面始终优于以前的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Universal+Sets-level+Optimization+Framework+for+Next+Set+Recommendation)|0|
|[Adversarial Text Rewriting for Text-aware Recommender Systems](https://doi.org/10.1145/3627673.3679592)|Sejoon Oh, Gaurav Verma, Srijan Kumar||Text-aware recommender systems incorporate rich textual features, such as titles and descriptions, to generate item recommendations for users. The use of textual features helps mitigate cold-start problems, and thus, such recommender systems have attracted increased attention. However, we argue that the dependency on item descriptions makes the recommender system vulnerable to manipulation by adversarial sellers on e-commerce platforms. In this paper, we explore the possibility of such manipulation by proposing a new text rewriting framework to attack text-aware recommender systems. We show that the rewriting attack can be exploited by sellers to unfairly uprank their products, even though the adversarially rewritten descriptions are perceived as realistic by human evaluators. Methodologically, we investigate two different variations to carry out text rewriting attacks: (1) two-phase fine-tuning for greater attack performance, and (2) in-context learning for higher text rewriting quality. Experiments spanning 3 different datasets and 4 existing approaches demonstrate that recommender systems exhibit vulnerability against the proposed text rewriting attack. Our work adds to the existing literature around the robustness of recommender systems, while highlighting a new dimension of vulnerability in the age of large-scale automated text generation.|文本感知推荐系统利用丰富的文本特征，如标题和描述，为用户生成物品推荐。使用文本特征有助于缓解冷启动问题，因此这类推荐系统引起了越来越多的关注。然而，我们认为，对物品描述的依赖使得推荐系统容易受到电子商务平台上对抗性卖家的操纵。在本文中，我们通过提出一个新的文本重写框架来探索这种操纵的可能性，以攻击文本感知推荐系统。我们展示了重写攻击可以被卖家利用来不公平地提升其产品的排名，即使对抗性重写的描述被人类评估者认为是真实的。在方法上，我们研究了两种不同的变体来进行文本重写攻击：（1）两阶段微调以提高攻击性能，（2）上下文内学习以提高文本重写质量。跨越3个不同数据集和4种现有方法的实验表明，推荐系统对所提出的文本重写攻击表现出脆弱性。我们的工作增加了关于推荐系统鲁棒性的现有文献，同时在大规模自动化文本生成时代突显了新的脆弱性维度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adversarial+Text+Rewriting+for+Text-aware+Recommender+Systems)|0|
|[Towards Completeness-Oriented Tool Retrieval for Large Language Models](https://doi.org/10.1145/3627673.3679847)|Changle Qu, Sunhao Dai, Xiaochi Wei, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Jun Xu, JiRong Wen||Recently, integrating external tools with Large Language Models (LLMs) has gained significant attention as an effective strategy to mitigate the limitations inherent in their pre-training data. However, real-world systems often incorporate a wide array of tools, making it impractical to input all tools into LLMs due to length limitations and latency constraints. Therefore, to fully exploit the potential of tool-augmented LLMs, it is crucial to develop an effective tool retrieval system. Existing tool retrieval methods primarily focus on semantic matching between user queries and tool descriptions, frequently leading to the retrieval of redundant, similar tools. Consequently, these methods fail to provide a complete set of diverse tools necessary for addressing the multifaceted problems encountered by LLMs. In this paper, we propose a novel modelagnostic COllaborative Learning-based Tool Retrieval approach, COLT, which captures not only the semantic similarities between user queries and tool descriptions but also takes into account the collaborative information of tools. Specifically, we first fine-tune the PLM-based retrieval models to capture the semantic relationships between queries and tools in the semantic learning stage. Subsequently, we construct three bipartite graphs among queries, scenes, and tools and introduce a dual-view graph collaborative learning framework to capture the intricate collaborative relationships among tools during the collaborative learning stage. Extensive experiments on both the open benchmark and the newly introduced ToolLens dataset show that COLT achieves superior performance. Notably, the performance of BERT-mini (11M) with our proposed model framework outperforms BERT-large (340M), which has 30 times more parameters. Furthermore, we will release ToolLens publicly to facilitate future research on tool retrieval.|近期，将外部工具与大型语言模型（LLMs）集成作为一种有效策略，以缓解其预训练数据固有的局限性，已引起广泛关注。然而，现实世界系统通常包含多种工具，由于长度限制和延迟约束，将所有工具输入LLMs并不现实。因此，为了充分挖掘工具增强型LLMs的潜力，开发一个高效的工具检索系统至关重要。现有的工具检索方法主要集中在用户查询与工具描述之间的语义匹配上，这往往导致检索出冗余、相似的工具。因此，这些方法无法提供一套多样化的工具来解决LLMs面临的多方面问题。本文提出了一种新颖的模型无关的基于协同学习的工具检索方法，称为COLT，该方法不仅捕捉用户查询与工具描述之间的语义相似性，还考虑了工具之间的协同信息。具体而言，我们首先微调基于PLM的检索模型，以在语义学习阶段捕捉查询与工具之间的语义关系。随后，我们在查询、场景和工具之间构建三个二部图，并引入一个双重视图的图协同学习框架，以在协同学习阶段捕捉工具之间复杂的协同关系。在公开基准和新引入的ToolLens数据集上的广泛实验表明，COLT表现优异。值得注意的是，在我们提出的模型框架下，BERT-mini（11M参数）的性能超过了BERT-large（340M参数），后者参数数量是前者的30倍。此外，我们将公开发布ToolLens数据集，以促进未来在工具检索领域的研究。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Completeness-Oriented+Tool+Retrieval+for+Large+Language+Models)|0|
|[No Query Left Behind: Query Refinement via Backtranslation](https://doi.org/10.1145/3627673.3679729)|Delaram Rajaei, Zahra Taheri, Hossein Fani|School of Computer Science, University of Windsor, Windsor, ON., Canada|Query refinement is to enhance the relevance of search results by modifying users' original queries to refined versions. State-of-the-art query refinement models have been trained on web query logs, which are predisposed to topic drifts. To fill the gap, little work has been proposed to generate benchmark datasets of (query ’ refined query) pairs through an overwhelming application of unsupervised or supervised modifications to the original query while controlling topic drifts. In this paper, however, we propose leveraging natural language backtranslation, a round-trip translation of a query from a source language via target languages, as a simple yet effective unsupervised approach to scale up generating gold-standard benchmark datasets. Backtranslation can (1) uncover terms that are omitted in a query for being commonly understood in a source language, but may not be known in a target language (e.g., 'figs'’(tamil) 'in a target language (e.g., ‘figs’→(tamil) ‘அத்திமரங்கள்’→‘the fig trees’), (2) augment a query with context-aware synonyms in a target language (e.g., ‘italian nobel prize winners’→(farsi) ’برنده های ایتالیایی جایزه نوبل‘ →‘italian nobel laureates’, and (3) help with the semantic disambiguation of polysemous terms and collocations (e.g., 'custer's last stand'’(malay)`pertahan terakhir custer'’`custer's last defence'. Our experiments across 5 query sets with different query lengths and topics and 10 languages from 7 language families using 2 neural machine translators validated the effectiveness of query backtranslation in generating a more extensive gold-standard dataset for query refinement. We open-sourced our research at https://github.com/fani-lab/RePair/tree/nqlb.|查询精炼是通过修改用户原始查询为精炼版本，以增强搜索结果的相关性。目前最先进的查询精炼模型已经在网络查询日志上进行了训练，这些日志容易出现主题偏移。为了填补这一空白，很少有研究提出通过广泛应用无监督或监督的修改方法来生成（查询-精炼查询）对的基准数据集，同时控制主题偏移。然而，本文提出利用自然语言回译（一种通过目标语言进行源语言查询的往返翻译）作为一种简单而有效的无监督方法，来扩展生成黄金标准的基准数据集。回译可以（1）揭示在源语言中因常见而被省略但在目标语言中可能不为人知的术语（例如，‘figs’→(tamil) ‘அத்திமரங்கள்’→‘the fig trees’），（2）通过目标语言中的上下文相关同义词来增强查询（例如，‘italian nobel prize winners’→(farsi) ’برنده های ایتالیایی جایزه نوبل‘ →‘italian nobel laureates’），以及（3）帮助消除多义词和搭配的语义歧义（例如，‘custer's last stand’→(malay) ‘pertahan terakhir custer’→‘custer's last defence’）。我们在5个不同查询长度和主题的查询集以及来自7个语系的10种语言上进行的实验，使用了2种神经机器翻译器，验证了查询回译在生成更广泛的查询精炼黄金标准数据集方面的有效性。我们在https://github.com/fani-lab/RePair/tree/nqlb 开源了我们的研究。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=No+Query+Left+Behind:+Query+Refinement+via+Backtranslation)|0|
|[Retrieval-enhanced Knowledge Editing in Language Models for Multi-Hop Question Answering](https://doi.org/10.1145/3627673.3679722)|Yucheng Shi, Qiaoyu Tan, Xuansheng Wu, Shaochen Zhong, Kaixiong Zhou, Ninghao Liu||Large Language Models (LLMs) have shown proficiency in question-answering tasks but often struggle to integrate real-time knowledge, leading to potentially outdated or inaccurate responses. This problem becomes even more challenging when dealing with multi-hop questions, since they require LLMs to update and integrate multiple knowledge pieces relevant to the questions. To tackle the problem, we propose the Retrieval-Augmented model Editing (RAE) framework for multi-hop question answering. RAE first retrieves edited facts and then refines the language model through in-context learning. Specifically, our retrieval approach, based on mutual information maximization, leverages the reasoning abilities of LLMs to identify chain facts that traditional similarity-based searches might miss. In addition, our framework includes a pruning strategy to eliminate redundant information from the retrieved facts, which enhances the editing accuracy and mitigates the hallucination problem. Our framework is supported by theoretical justification for its fact retrieval efficacy. Finally, comprehensive evaluation across various LLMs validates RAE's ability in providing accurate answers with updated knowledge. Our code is available at: https://github.com/sycny/RAE.|大型语言模型（LLMs）在问答任务中表现出色，但往往难以整合实时知识，导致可能提供过时或不准确的信息。在处理多跳问题时，这一问题变得更加复杂，因为这要求LLMs更新并整合与问题相关的多个知识片段。为了解决这一问题，我们提出了多跳问答的检索增强模型编辑（RAE）框架。RAE首先检索编辑后的事实，然后通过上下文学习对语言模型进行精炼。具体而言，我们的检索方法基于互信息最大化，利用LLMs的推理能力来识别传统基于相似性搜索可能遗漏的链式事实。此外，我们的框架还包括一种剪枝策略，以消除检索事实中的冗余信息，从而提高编辑的准确性并缓解幻觉问题。我们的框架得到了理论上的支持，证明了其在事实检索中的有效性。最后，通过对多种LLMs的综合评估，验证了RAE在提供更新知识的基础上准确回答问题的能力。我们的代码可在以下链接获取：https://github.com/sycny/RAE。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Retrieval-enhanced+Knowledge+Editing+in+Language+Models+for+Multi-Hop+Question+Answering)|0|
|[Large Language Models Enhanced Collaborative Filtering](https://doi.org/10.1145/3627673.3679558)|Zhongxiang Sun, Zihua Si, Xiaoxue Zang, Kai Zheng, Yang Song, Xiao Zhang, Jun Xu|Kuaishou Technology Co., Ltd; Renmin University of China Gaoling School of Artificial Intelligence|Recent advancements in Large Language Models (LLMs) have attractedconsiderable interest among researchers to leverage these models to enhanceRecommender Systems (RSs). Existing work predominantly utilizes LLMs togenerate knowledge-rich texts or utilizes LLM-derived embeddings as features toimprove RSs. Al- though the extensive world knowledge embedded in LLMsgenerally benefits RSs, the application can only take limited number of usersand items as inputs, without adequately exploiting collaborative filteringinformation. Considering its crucial role in RSs, one key challenge inenhancing RSs with LLMs lies in providing better collaborative filteringinformation through LLMs. In this paper, drawing inspiration from thein-context learning and chain of thought reasoning in LLMs, we propose theLarge Language Models enhanced Collaborative Filtering (LLM-CF) framework,which distils the world knowledge and reasoning capabilities of LLMs intocollaborative filtering. We also explored a concise and efficientinstruction-tuning method, which improves the recommendation capabilities ofLLMs while preserving their general functionalities (e.g., not decreasing onthe LLM benchmark). Comprehensive experiments on three real-world datasetsdemonstrate that LLM-CF significantly enhances several backbone recommendationmodels and consistently outperforms competitive baselines, showcasing itseffectiveness in distilling the world knowledge and reasoning capabilities ofLLM into collaborative filtering.|近期大型语言模型（LLMs）的进展引起了研究者的广泛关注，他们试图利用这些模型来提升推荐系统（RSs）的性能。现有研究主要利用LLMs生成知识丰富的文本，或使用从LLM派生的嵌入作为特征来改进推荐系统。尽管LLMs嵌入的广泛世界知识通常对推荐系统有益，但这些应用只能处理有限数量的用户和物品作为输入，未能充分挖掘协同过滤信息。考虑到协同过滤在推荐系统中的关键作用，利用LLMs提升推荐系统的一个主要挑战在于通过LLMs提供更好的协同过滤信息。本文受LLMs中的上下文学习和思维链推理的启发，提出了大型语言模型增强的协同过滤（LLM-CF）框架，该框架将LLMs的世界知识和推理能力提炼到协同过滤中。我们还探索了一种简洁高效的指令调优方法，该方法在保留LLMs通用功能（如在LLM基准测试中不降低性能）的同时，提升了其推荐能力。在三个真实世界数据集上的综合实验表明，LLM-CF显著增强了多个骨干推荐模型，并持续优于竞争基线，展示了其将LLM的世界知识和推理能力提炼到协同过滤中的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large+Language+Models+Enhanced+Collaborative+Filtering)|0|
|[Natural Language-Assisted Multi-modal Medication Recommendation](https://doi.org/10.1145/3627673.3679529)|Jie Tan, Yu Rong, Kangfei Zhao, Tian Bian, Tingyang Xu, Junzhou Huang, Hong Cheng, Helen Meng|University of Texas at Arlington, Arlington, TX, USA; DAMO Academy, Alibaba Group, Hupan Lab, Hangzhou, China; Beijing Institute of Technology, Beijing, China; The Chinese University of Hong Kong, HongKong, China; The Chinese University of Hong Kong, Hong Kong, China|Combinatorial medication recommendation (CMR) is a fundamental task of healthcare, which offers opportunities for clinical physicians to provide more precise prescriptions for patients with intricate health conditions, particularly in the scenarios of long-term medical care. Previous research efforts have sought to extract meaningful information from electronic health records (EHRs) to facilitate combinatorial medication recommendations. Existing learning-based approaches further consider the chemical structures of medications, but ignore the textual medication descriptions in which the functionalities are clearly described. Furthermore, the textual knowledge derived from the EHRs of patients remains largely underutilized. To address these issues, we introduce the Natural Language-Assisted Multi-modal Medication Recommendation (NLA-MMR), a multimodal alignment framework designed to learn knowledge from the patient view and medication view jointly. Specifically, NLA-MMR formulates CMR as an alignment problem from patient and medication modalities. In this vein, we employ pretrained language models (PLMs) to extract in-domain knowledge regarding patients and medications, serving as the foundational representation for both modalities. In the medication modality, we exploit both chemical structures and textual descriptions to create medication representations. In the patient modality, we generate the patient representations based on textual descriptions of diagnosis, procedure, and symptom. Extensive experiments conducted on three publicly accessible datasets demonstrate that NLA-MMR achieves new state-of-the-art performance, with a notable average improvement of 4.72% in Jaccard score.|组合药物推荐（CMR）是医疗保健中的一个基本任务，它为临床医生提供了为病情复杂的患者提供更精确处方的机会，特别是在长期医疗护理的情景中。以往的研究致力于从电子健康记录（EHRs）中提取有意义的信息，以促进组合药物推荐。现有的基于学习的方法进一步考虑了药物的化学结构，但忽略了药物描述文本，这些文本中清楚地描述了药物的功能。此外，从患者EHRs中提取的文本知识在很大程度上未被充分利用。为了解决这些问题，我们引入了自然语言辅助的多模态药物推荐（NLA-MMR），这是一个多模态对齐框架，旨在从患者视角和药物视角共同学习知识。具体来说，NLA-MMR将CMR表述为从患者和药物模态出发的对齐问题。为此，我们采用预训练语言模型（PLMs）来提取关于患者和药物的领域内知识，作为两种模态的基础表示。在药物模态中，我们利用化学结构和文本描述来创建药物表示。在患者模态中，我们基于诊断、治疗程序和症状的文本描述生成患者表示。在三个公开可用的数据集上进行的广泛实验表明，NLA-MMR达到了新的最先进性能，Jaccard分数平均提高了4.72%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Natural+Language-Assisted+Multi-modal+Medication+Recommendation)|0|
|[LAMRec: Label-aware Multi-view Drug Recommendation](https://doi.org/10.1145/3627673.3679656)|Yunsen Tang, Ning Liu, Haitao Yuan, Yonghe Yan, Lei Liu, Weixing Tan, Lizhen Cui|Shandong Research Institute of Industrial Technology, Jinan, China; Shandong University, Jinan, China; Nanyang Technological University, Singapore, Singapore|The drug recommendation task aims to predict safe and effective drug prescriptions based on the patients' historical electronic health records (EHRs). However, existing drug recommendation models generally have two limitations. First, they neglect the inherent characteristics of multiple views existing in patients' clinical data (e.g., diagnoses and procedures), leading to fragmented and inconsistent patient representations. Second, they do not fully exploit drug label information. Most models do not explicitly establish a mapping relationship between drug labels and patients' historical visits. To address these two problems, we proposed a label-aware multi-view drug recommendation model named LAMRec. In particular, LAMRec uses a cross-attention module to fuse information from the diagnosis and procedure views, and increases the mutual information of patient multi-view representations through multi-view contrastive loss; the label-wise attention mechanism fully explores drug label information by constructing an adaptive mapping of drug-visit to generate personalized representations that are aware of the drug-related visit information. Experiments on three real world medical datasets demonstrated the superiority of LAMRec, with a relative reduction of 5.25% in DDI compared to the optimal baseline, a relative improvement of 4.20% in Jaccard similarity scores, and a relative improvement of 3.10% in F1 scores. We released the code online at: https://github.com/Tyunsen/LAMRec.|药物推荐任务旨在根据患者的电子健康记录（EHR）历史数据预测安全有效的药物处方。然而，现有的药物推荐模型普遍存在两个局限性。首先，它们忽略了患者临床数据中多视图（如诊断和手术）的固有特性，导致患者表示碎片化和不一致。其次，它们未能充分利用药物标签信息。大多数模型没有明确建立药物标签与患者历史就诊之间的映射关系。为了解决这两个问题，我们提出了一种名为LAMRec的标签感知多视图药物推荐模型。具体而言，LAMRec通过交叉注意力模块融合诊断和手术视图的信息，并通过多视图对比损失增加患者多视图表示的互信息；标签感知注意力机制通过构建药物-就诊的自适应映射，充分挖掘药物标签信息，生成包含药物相关就诊信息的个性化表示。在三个真实世界的医疗数据集上的实验表明，LAMRec具有优越性，与最优基线相比，DDI相对减少5.25%，Jaccard相似度分数相对提高4.20%，F1分数相对提高3.10%。我们在网上发布了代码：https://github.com/Tyunsen/LAMRec。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LAMRec:+Label-aware+Multi-view+Drug+Recommendation)|0|
|[Retrieval Augmented Deep Anomaly Detection for Tabular Data](https://doi.org/10.1145/3627673.3679559)|Hugo Thimonier, Fabrice Popineau, Arpad Rimmel, BichLiên Doan||Deep learning for tabular data has garnered increasing attention in recent years, yet employing deep models for structured data remains challenging. While these models excel with unstructured data, their efficacy with structured data has been limited. Recent research has introduced retrieval-augmented models to address this gap, demonstrating promising results in supervised tasks such as classification and regression. In this work, we investigate using retrieval-augmented models for anomaly detection on tabular data. We propose a reconstruction-based approach in which a transformer model learns to reconstruct masked features of normal samples. We test the effectiveness of KNN-based and attention-based modules to select relevant samples to help in the reconstruction process of the target sample. Our experiments on a benchmark of 31 tabular datasets reveal that augmenting this reconstruction-based anomaly detection (AD) method with sample-sample dependencies via retrieval modules significantly boosts performance. The present work supports the idea that retrieval module are useful to augment any deep AD method to enhance anomaly detection on tabular data.|近年来，深度学习在表格数据处理领域引起了越来越多的关注，然而，将深度模型应用于结构化数据仍然充满挑战。尽管这些模型在非结构化数据上表现出色，但它们在结构化数据上的有效性却受到限制。最近的研究引入了检索增强模型来填补这一空白，在分类和回归等监督任务中展示了有前景的结果。在这项工作中，我们探讨了使用检索增强模型进行表格数据异常检测的方法。我们提出了一种基于重构的方法，其中变压器模型学习重构正常样本的掩码特征。我们测试了基于KNN和基于注意力模块的有效性，以选择相关样本来辅助目标样本的重构过程。我们在31个表格数据集的基准测试中进行的实验表明，通过检索模块增强这种基于重构的异常检测（AD）方法，利用样本间的依赖关系，显著提升了性能。本研究支持了这样一个观点：检索模块对于增强任何深度AD方法，以提高表格数据上的异常检测效能是有益的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Retrieval+Augmented+Deep+Anomaly+Detection+for+Tabular+Data)|0|
|[On Causally Disentangled State Representation Learning for Reinforcement Learning based Recommender Systems](https://doi.org/10.1145/3627673.3679674)|Siyu Wang, Xiaocong Chen, Lina Yao||In Reinforcement Learning-based Recommender Systems (RLRS), the complexity and dynamism of user interactions often result in high-dimensional and noisy state spaces, making it challenging to discern which aspects of the state are truly influential in driving the decision-making process. This issue is exacerbated by the evolving nature of user preferences and behaviors, requiring the recommender system to adaptively focus on the most relevant information for decision-making while preserving generaliability. To tackle this problem, we introduce an innovative causal approach for decomposing the state and extracting \textbf{C}ausal-\textbf{I}n\textbf{D}ispensable \textbf{S}tate Representations (CIDS) in RLRS. Our method concentrates on identifying the \textbf{D}irectly \textbf{A}ction-\textbf{I}nfluenced \textbf{S}tate Variables (DAIS) and \textbf{A}ction-\textbf{I}nfluence \textbf{A}ncestors (AIA), which are essential for making effective recommendations. By leveraging conditional mutual information, we develop a framework that not only discerns the causal relationships within the generative process but also isolates critical state variables from the typically dense and high-dimensional state representations. We provide theoretical evidence for the identifiability of these variables. Then, by making use of the identified causal relationship, we construct causal-indispensable state representations, enabling the training of policies over a more advantageous subset of the agent's state space. We demonstrate the efficacy of our approach through extensive experiments, showcasing our method outperforms state-of-the-art methods.|在基于强化学习的推荐系统（RLRS）中，用户交互的复杂性和动态性常常导致高维度和噪声状态空间，使得难以辨别哪些状态方面真正影响决策过程。这一问题因用户偏好和行为的不断演变而加剧，要求推荐系统在保持泛化能力的同时，自适应地专注于决策中最相关的信息。为解决此问题，我们引入了一种创新的因果分解方法，用于在RLRS中提取\textbf{C}ausal-\textbf{I}n\textbf{D}ispensable \textbf{S}tate Representations（CIDS）。我们的方法专注于识别\textbf{D}irectly \textbf{A}ction-\textbf{I}nfluenced \textbf{S}tate Variables（DAIS）和\textbf{A}ction-\textbf{I}nfluence \textbf{A}ncestors（AIA），这些变量对于做出有效推荐至关重要。通过利用条件互信息，我们开发了一个框架，不仅能够辨别生成过程中的因果关系，还能从通常密集且高维的状态表示中隔离出关键状态变量。我们提供了这些变量可识别性的理论证据。随后，通过利用识别出的因果关系，我们构建了因果不可或缺的状态表示，使得在代理状态空间中更具优势的子集上训练策略成为可能。我们通过广泛的实验展示了我们方法的有效性，证明其优于现有最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Causally+Disentangled+State+Representation+Learning+for+Reinforcement+Learning+based+Recommender+Systems)|0|
|[Topology-aware Retrieval Augmentation for Text Generation](https://doi.org/10.1145/3627673.3679746)|Yu Wang, Nedim Lipka, Ruiyi Zhang, Alexa F. Siu, Yuying Zhao, Bo Ni, Xin Wang, Ryan A. Rossi, Tyler Derr||Despite the impressive advancements of Large Language Models (LLMs) ingenerating text, they are often limited by the knowledge contained in the inputand prone to producing inaccurate or hallucinated content. To tackle theseissues, Retrieval-augmented Generation (RAG) is employed as an effectivestrategy to enhance the available knowledge base and anchor the responses inreality by pulling additional texts from external databases. In real-worldapplications, texts are often linked through entities within a graph, such ascitations in academic papers or comments in social networks. This paperexploits these topological relationships to guide the retrieval process in RAG.Specifically, we explore two kinds of topological connections: proximity-based,focusing on closely connected nodes, and role-based, which looks at nodessharing similar subgraph structures. Our empirical research confirms theirrelevance to text relationships, leading us to develop a Topology-awareRetrieval-augmented Generation framework. This framework includes a retrievalmodule that selects texts based on their topological relationships and anaggregation module that integrates these texts into prompts to stimulate LLMsfor text generation. We have curated established text-attributed networks andconducted comprehensive experiments to validate the effectiveness of thisframework, demonstrating its potential to enhance RAG with topologicalawareness.|尽管大型语言模型（LLM）在生成文本方面取得了显著进展，但它们通常受限于输入中的知识，容易产生不准确或虚构的内容。为了解决这些问题，检索增强生成（RAG）被用作一种有效的策略，通过从外部数据库中提取额外的文本来增强可用知识库，并将响应锚定在现实世界中。在实际应用中，文本通常通过图中的实体相互关联，例如学术论文中的引用或社交网络中的评论。本文利用这些拓扑关系来指导RAG中的检索过程。具体而言，我们探索了两类拓扑连接：基于接近度的连接，关注紧密连接的节点；以及基于角色的连接，关注共享相似子图结构的节点。我们的实证研究表明它们与文本关系的相关性，从而开发了一种拓扑感知检索增强生成框架。该框架包括一个基于拓扑关系选择文本的检索模块和一个将这些文本整合到提示中以刺激LLM进行文本生成的聚合模块。我们精心构建了现有的文本属性网络，并进行了全面的实验以验证该框架的有效性，展示了其通过拓扑感知增强RAG的潜力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Topology-aware+Retrieval+Augmentation+for+Text+Generation)|0|
|[LLM4MSR: An LLM-Enhanced Paradigm for Multi-Scenario Recommendation](https://doi.org/10.1145/3627673.3679743)|Yuhao Wang, Yichao Wang, Zichuan Fu, Xiangyang Li, Wanyu Wang, Yuyang Ye, Xiangyu Zhao, Huifeng Guo, Ruiming Tang||As the demand for more personalized recommendation grows and a dramatic boomin commercial scenarios arises, the study on multi-scenario recommendation(MSR) has attracted much attention, which uses the data from all scenarios tosimultaneously improve their recommendation performance. However, existingmethods tend to integrate insufficient scenario knowledge and neglect learningpersonalized cross-scenario preferences, thus leading to suboptimal performanceand inadequate interpretability. Meanwhile, though large language model (LLM)has shown great capability of reasoning and capturing semantic information, thehigh inference latency and high computation cost of tuning hinder itsimplementation in industrial recommender systems. To fill these gaps, wepropose an effective efficient interpretable LLM-enhanced paradigm LLM4MSR inthis work. Specifically, we first leverage LLM to uncover multi-level knowledgeincluding scenario correlations and users' cross-scenario interests from thedesigned scenario- and user-level prompt without fine-tuning the LLM, thenadopt hierarchical meta networks to generate multi-level meta layers toexplicitly improves the scenario-aware and personalized recommendationcapability. Our experiments on KuaiSAR-small, KuaiSAR, and Amazon datasetsvalidate two significant advantages of LLM4MSR: (i) the effectiveness andcompatibility with different multi-scenario backbone models (achieving 1.51deployability on industrial recommender systems, and (iii) improvedinterpretability. The implemented code and data is available to easereproduction.|随着对更个性化推荐的需求日益增长以及商业场景中的显著繁荣，多场景推荐（MSR）研究引起了广泛关注。该研究利用所有场景的数据，旨在同时提升各场景的推荐性能。然而，现有方法往往整合不足的场景知识，忽视了跨场景个性化偏好的学习，导致性能次优且解释性不足。同时，尽管大型语言模型（LLM）在推理和捕捉语义信息方面展现出强大能力，但其高推理延迟和高计算成本的调优阻碍了其在工业推荐系统中的应用。

为填补这些空白，本文提出了一种高效的、可解释的LLM增强范式LLM4MSR。具体而言，我们首先利用LLM在不进行微调的情况下，通过设计场景级和用户级提示，揭示包括场景关联和用户跨场景兴趣在内的多层次知识。随后，采用分层元网络生成多层次元层，以显式提升场景感知和个性化推荐能力。我们在KuaiSAR-small、KuaiSAR和Amazon数据集上的实验验证了LLM4MSR的两个显著优势：（i）有效性和与不同多场景骨干模型的兼容性（在工业推荐系统中实现1.51的部署性），以及（iii）提升的解释性。我们提供的实现代码和数据将有助于复现研究成果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LLM4MSR:+An+LLM-Enhanced+Paradigm+for+Multi-Scenario+Recommendation)|0|
|[Time-Sensitve Retrieval-Augmented Generation for Question Answering](https://doi.org/10.1145/3627673.3679800)|Feifan Wu, Lingyuan Liu, Wentao He, Ziqi Liu, Zhiqiang Zhang, Haofen Wang, Meng Wang|Ant Group, Hangzhou, China; Southeast University & XAI Lab, Tongji University, Nanjing, China; Southeast University, Nanjing, China; College of Design and Innovation, Tongji University, Shanghai, China|Retrieval-augmented generation (RAG) enhances large language models (LLMs) by accessing external data sources, offering a promising way to improve accuracy and reliability. Despite its potential, conventional retrievers encounter bias and flaws with time-sensitive queries. In this paper, a benchmark query dataset is constructed to retrieve documents containing time-evolving facts, and the results show that current embedding-based similarity-matching methods struggle to handle queries with explicit temporal constraints. Therefore, we propose a novel approach that integrates supervised contrastive learning with tailored negative sample pairs for temporal constraints to train the retriever of an RAG system, along with query-side fine-tuning and routing techniques. Experimental results show that our approach significantly enhances the retriever performance of time-sensitive queries while ensuring the effectiveness of general queries. We will make the code and dataset publicly available at https://github.com/suzhou-22/TS-Retriever.|检索增强生成（RAG）通过访问外部数据源，增强了大型语言模型（LLMs）的能力，为提高准确性和可靠性提供了一种有前景的方式。尽管其潜力巨大，传统的检索器在处理与时间敏感的查询时仍面临偏差和缺陷。本文构建了一个基准查询数据集，用于检索包含时间演化事实的文档，结果显示当前基于嵌入的相似性匹配方法在处理带有明确时间约束的查询时表现不佳。因此，我们提出了一种新方法，将监督对比学习与针对时间约束定制的负样本对相结合，用于训练RAG系统的检索器，同时结合查询端的微调和路由技术。实验结果表明，我们的方法显著提升了对时间敏感查询的检索器性能，同时确保了通用查询的有效性。我们将在https://github.com/suzhou-22/TS-Retriever公开代码和数据集。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Time-Sensitve+Retrieval-Augmented+Generation+for+Question+Answering)|0|
|[Bridge the Gap between Past and Future: Siamese Model Optimization for Context-Aware Document Ranking](https://doi.org/10.1145/3627673.3679661)|Songhao Wu, Quan Tu, Mingjie Zhong, Hong Liu, Jia Xu, Jinjie Gu, Rui Yan|Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China; Ant Group, Hangzhou, China|In the realm of information retrieval, users often engage in multi-turn interactions with search engines to acquire information, leading to the formation of sequences of user feedback behaviors. Leveraging the session context has proven to be beneficial for inferring user search intent and document ranking. A multitude of approaches have been proposed to exploit in-session context for improved document ranking. Despite these advances, the limitation of historical session data for capturing evolving user intent remains a challenge. In this work, we explore the integration of future contextual information into the session context to enhance document ranking. We present the siamese model optimization framework, comprising a history-conditioned model and a future-aware model. The former processes only the historical behavior sequence, while the latter integrates both historical and anticipated future behaviors. Both models are trained collaboratively using the supervised labels and pseudo labels predicted by the other. The history-conditioned model, referred to as ForeRanker, progressively learns future-relevant information to enhance ranking, while it singly uses historical session at inference time. To mitigate inconsistencies during training, we introduce the peer knowledge distillation method with a dynamic gating mechanism, allowing models to selectively incorporate contextual information. Experimental results on benchmark datasets demonstrate the effectiveness of our ForeRanker, showcasing its superior performance compared to existing methods.|在信息检索领域，用户通常通过与搜索引擎的多轮交互来获取信息，从而形成一系列用户反馈行为。利用会话上下文已被证明有助于推断用户搜索意图和文档排序。已经提出了多种方法来利用会话内上下文以改进文档排序。尽管取得了这些进展，但捕捉用户意图演变的历史会话数据的局限性仍然是一个挑战。在这项工作中，我们探讨了将会话上下文与未来上下文信息相结合以增强文档排序的方法。我们提出了孪生模型优化框架，包括一个历史条件模型和一个未来感知模型。前者仅处理历史行为序列，而后者则结合了历史和预期的未来行为。两个模型通过监督标签和另一个模型预测的伪标签进行协同训练。历史条件模型，称为ForeRanker，逐步学习与未来相关的信息以提升排序，而在推理时单独使用历史会话。为了减少训练过程中的不一致性，我们引入了具有动态门控机制的同行知识蒸馏方法，使模型能够选择性地整合上下文信息。在基准数据集上的实验结果证明了我们ForeRanker的有效性，展示了其相对于现有方法的优越性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bridge+the+Gap+between+Past+and+Future:+Siamese+Model+Optimization+for+Context-Aware+Document+Ranking)|0|
|[Federated Node Classification over Distributed Ego-Networks with Secure Contrastive Embedding Sharing](https://doi.org/10.1145/3627673.3679834)|Han Xie, Li Xiong, Carl Yang|Emory University, Atlanta, GA, USA|Federated learning on graphs (a.k.a., federated graph learning - FGL) has recently received increasing attention due to its capacity to enable collaborative learning over distributed graph datasets without compromising local clients' data privacy. In previous works, clients of FGL typically represent institutes or organizations that possess sets of entire graphs (e.g., molecule graphs in biochemical research) or parts of a larger graph (e.g., sub-user networks of e-commerce platforms). However, another natural paradigm exists where clients act as remote devices retaining the graph structures of local neighborhoods centered around the device owners (i.e., ego-networks), which can be modeled for specific graph applications such as user profiling on social ego-networks and infection prediction on contact ego-networks. FGL in such novel yet realistic ego-network settings faces the unique challenge of incomplete neighborhood information for non-ego local nodes since they likely appear and have different sets of neighbors in multiple ego-networks. To address this challenge, we propose an FGL method for distributed ego-networks in which clients obtain complete neighborhood information of local nodes through sharing node embeddings with other clients. A contrastive learning mechanism is proposed to bridge the gap between local and global node embeddings and stabilize the local training of graph neural network models, while a secure embedding sharing protocol is employed to protect individual node identity and embedding privacy against the server and other clients. Comprehensive experiments on various distributed ego-network datasets successfully demonstrate the effectiveness of our proposed embedding sharing method on top of different federated model sharing frameworks, and we also provide discussions on the potential efficiency and privacy drawbacks of the method as well as their future mitigation.|图上的联邦学习（又称联邦图学习 - FGL）近年来因其能够在不损害本地客户端数据隐私的情况下实现分布式图数据集上的协作学习而受到越来越多的关注。在以往的研究中，FGL的客户端通常代表拥有完整图集（例如，生物化学研究中的分子图）或大型图的一部分（例如，电子商务平台的子用户网络）的机构或组织。然而，还存在另一种自然范式，其中客户端作为远程设备，保留以设备所有者为中心的本地邻域的图结构（即自我网络），这些图结构可以用于特定的图应用，例如社交自我网络上的用户画像和接触自我网络上的感染预测。在这种新颖且现实的自我网络设置中，FGL面临一个独特的挑战，即非自我本地节点的邻域信息不完整，因为它们可能出现在多个自我网络中并具有不同的邻居集合。为了应对这一挑战，我们提出了一种针对分布式自我网络的FGL方法，其中客户端通过与其他客户端共享节点嵌入来获取本地节点的完整邻域信息。我们提出了一种对比学习机制，以弥合本地和全局节点嵌入之间的差距，并稳定图神经网络模型的本地训练，同时采用了一种安全的嵌入共享协议，以保护服务器和其他客户端对个体节点身份和嵌入隐私的访问。在各种分布式自我网络数据集上的综合实验成功证明了我们提出的嵌入共享方法在不同联邦模型共享框架上的有效性，并且我们还讨论了该方法潜在的效率和隐私缺陷及其未来的缓解措施。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Federated+Node+Classification+over+Distributed+Ego-Networks+with+Secure+Contrastive+Embedding+Sharing)|0|
|[UniMPC: Towards a Unified Framework for Multi-Party Conversations](https://doi.org/10.1145/3627673.3679864)|Yunhe Xie, Chengjie Sun, Yifan Liu, Zhenzhou Ji, Bingquan Liu|Faculty of Computing, Harbin Institute of Technology, Harbin, China|The Multi-Party Conversation (MPC) system has gained attention for its relevance in modern communication. Recent work has focused on developing specialized models for different MPC subtasks, improving state-of-the-art (SOTA) performance. However, since MPC demands often arise collaboratively, managing multiple specialized models is impractical. Additionally, dialogue evolves through diverse meta-information, where knowledge from specific subtasks can influence others. To address this, we propose UniMPC, a unified framework that consolidates common MPC subtasks. UniMPC uses a graph network with utterance nodes, a global node for combined local and global information, and two adaptable free nodes. It also incorporates discourse parsing to enhance model updates. We introduce MPCEval, a new benchmark for evaluating MPC systems. Experiments show UniMPC achieves over 95% of SOTA performance across all subtasks, with some surpassing existing SOTA, highlighting the effectiveness of the global node, free nodes, and dynamic discourse-aware graphs.|多方对话（Multi-Party Conversation, MPC）系统因其与现代通信的相关性而受到关注。近期研究致力于为不同的MPC子任务开发专用模型，以提升最先进（SOTA）的性能。然而，由于MPC需求通常是协同产生的，管理多个专用模型并不现实。此外，对话通过多样化的元信息演变，特定子任务的知识可以影响其他子任务。为了解决这一问题，我们提出了UniMPC，这是一个整合常见MPC子任务的统一框架。UniMPC采用了一个图网络，其中包括话语节点、一个用于结合局部和全局信息的全局节点以及两个可适应的自由节点。它还集成了话语解析以增强模型更新。我们引入了MPCEval，一个新的用于评估MPC系统的基准。实验表明，UniMPC在所有子任务上达到了超过95%的SOTA性能，其中一些子任务超过了现有的SOTA，突显了全局节点、自由节点和动态话语感知图的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UniMPC:+Towards+a+Unified+Framework+for+Multi-Party+Conversations)|0|
|[AlignGroup: Learning and Aligning Group Consensus with Member Preferences for Group Recommendation](https://doi.org/10.1145/3627673.3679697)|Jinfeng Xu, Zheyu Chen, Jinze Li, Shuo Yang, Hewei Wang, Edith C. H. Ngai||Group activities are important behaviors in human society, providing personalized recommendations for groups is referred to as the group recommendation task. Existing methods can usually be categorized into two strategies to infer group preferences: 1) determining group preferences by aggregating members' personalized preferences, and 2) inferring group consensus by capturing group members' coherent decisions after common compromises. However, the former would suffer from the lack of group-level considerations, and the latter overlooks the fine-grained preferences of individual users. To this end, we propose a novel group recommendation method AlignGroup, which focuses on both group consensus and individual preferences of group members to infer the group decision-making. Specifically, AlignGroup explores group consensus through a well-designed hypergraph neural network that efficiently learns intra- and inter-group relationships. Moreover, AlignGroup innovatively utilizes a self-supervised alignment task to capture fine-grained group decision-making by aligning the group consensus with members' common preferences. Extensive experiments on two real-world datasets validate that our AlignGroup outperforms the state-of-the-art on both the group recommendation task and the user recommendation task, as well as outperforms the efficiency of most baselines.|群体活动在人类社会中是重要的行为，为群体提供个性化推荐被称为群体推荐任务。现有的方法通常可以分为两种策略来推断群体偏好：1) 通过聚合成员的个性化偏好来确定群体偏好，2) 通过捕捉群体成员在共同妥协后的连贯决策来推断群体共识。然而，前者缺乏对群体层面的考虑，而后者则忽略了用户的细粒度偏好。为此，我们提出了一种新的群体推荐方法AlignGroup，该方法同时关注群体共识和群体成员的个体偏好，以推断群体决策。具体而言，AlignGroup通过一个精心设计的高阶图神经网络来探索群体共识，该网络有效地学习群体内和群体间的关系。此外，AlignGroup创新性地利用自监督对齐任务，通过将群体共识与成员的共同偏好对齐来捕捉细粒度的群体决策。在两个真实世界数据集上的广泛实验验证了我们的AlignGroup在群体推荐任务和用户推荐任务上均优于现有技术水平，并且在效率上也优于大多数基线方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AlignGroup:+Learning+and+Aligning+Group+Consensus+with+Member+Preferences+for+Group+Recommendation)|0|
|[Shape-aware Graph Spectral Learning](https://doi.org/10.1145/3627673.3679604)|Junjie Xu, Enyan Dai, Dongsheng Luo, Xiang Zhang, Suhang Wang||Spectral Graph Neural Networks (GNNs) are gaining attention for their abilityto surpass the limitations of message-passing GNNs. They rely on supervisionfrom downstream tasks to learn spectral filters that capture the graph signal'suseful frequency information. However, some works empirically show that thepreferred graph frequency is related to the graph homophily level. Thisrelationship between graph frequency and graphs with homophily/heterophily hasnot been systematically analyzed and considered in existing spectral GNNs. Tomitigate this gap, we conduct theoretical and empirical analyses revealing apositive correlation between low-frequency importance and the homophily ratio,and a negative correlation between high-frequency importance and the homophilyratio. Motivated by this, we propose shape-aware regularization on a NewtonInterpolation-based spectral filter that can (i) learn an arbitrary polynomialspectral filter and (ii) incorporate prior knowledge about the desired shape ofthe corresponding homophily level. Comprehensive experiments demonstrate thatNewtonNet can achieve graph spectral filters with desired shapes and superiorperformance on both homophilous and heterophilous datasets.|谱图神经网络（GNNs）因其能够超越消息传递GNN的局限性而受到关注。它们依赖于下游任务的监督来学习捕捉图信号有用频谱信息的谱滤波器。然而，一些研究表明，优选的图频谱与图同质性水平相关。这种图频谱与具有同质性/异质性的图之间的关系尚未在现有的谱GNN中得到系统的分析和考虑。为了弥补这一差距，我们进行了理论和实证分析，揭示了低频重要性与同质性比率之间的正相关关系，以及高频重要性与同质性比率之间的负相关关系。受此启发，我们提出了一种基于牛顿插值的谱滤波器的形状感知正则化方法，该方法能够（i）学习任意多项式谱滤波器，（ii）结合关于所需同质性水平的先验知识。综合实验表明，NewtonNet能够实现具有所需形状的图谱滤波器，并在同质性和异质性数据集上均表现出优越的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Shape-aware+Graph+Spectral+Learning)|0|
|[Topological Anonymous Walk Embedding: A New Structural Node Embedding Approach](https://doi.org/10.1145/3627673.3679565)|Yuchen Yan, Yongyi Hu, Qinghai Zhou, Shurang Wu, Dingsu Wang, Hanghang Tong|University of Science and Technology of China, Hefei, Anhui, China; University of Illinois at Urbana-Champaign, Urbana, IL, USA; Shanghai Jiao Tong University, Minhang, Shanghai, China|Network embedding is a commonly used technique in graph mining and plays an important role in a variety of applications. Most network embedding works can be categorized into positional node embedding methods and target at capturing the proximity/relative position of node pairs. Recently, structural node embedding has attracted tremendous research interest, which is intended to perceive the local structural information of node, i.e., nodes can share similar local structures in different positions of graphs. Although numerous structural node embedding methods are designed to encode such structural information, most, if not all, of these methods cannot simultaneously achieve the following three desired properties: (1) bijective mapping between embedding and local structure of node; (2) inductive capability; and (3) good interpretability of node embedding. To address this challenge, in this paper, we propose a novel structural node embedding algorithm named topological anonymous walk embedding (TAWE). Specifically, TAWE creatively integrates anonymous walk and breadth-first search (BFS) to construct the bijective mapping between node embedding and local structure of node. In addition, TAWE possesses inductive capability and good interpretability of node embedding. Experimental results on both synthetic and real-world datasets demonstrate the effectiveness of the proposed TAWE algorithm in both structural node classification task and structural node clustering task.|网络嵌入是图挖掘中常用的一种技术，在多种应用中发挥着重要作用。大多数网络嵌入工作可以归类为位置节点嵌入方法，旨在捕捉节点对的接近度/相对位置。最近，结构节点嵌入引起了极大的研究兴趣，其目的是感知节点的局部结构信息，即节点可以在图的不同位置共享相似的局部结构。尽管设计了大量结构节点嵌入方法来编码这种结构信息，但大多数（如果不是全部）这些方法无法同时实现以下三个期望属性：（1）嵌入与节点局部结构之间的双射映射；（2）归纳能力；（3）节点嵌入的良好可解释性。为了解决这一挑战，本文提出了一种名为拓扑匿名游走嵌入（Topological Anonymous Walk Embedding, TAWE）的新型结构节点嵌入算法。具体来说，TAWE创新地将匿名游走与广度优先搜索（BFS）相结合，构建了节点嵌入与其局部结构之间的双射映射。此外，TAWE具有归纳能力和良好的节点嵌入可解释性。在合成数据集和真实世界数据集上的实验结果表明，所提出的TAWE算法在结构节点分类任务和结构节点聚类任务中均表现出了有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Topological+Anonymous+Walk+Embedding:+A+New+Structural+Node+Embedding+Approach)|0|
|[Spectral-Aware Augmentation for Enhanced Graph Representation Learning](https://doi.org/10.1145/3627673.3679762)|Kaiqi Yang, Haoyu Han, Wei Jin, Hui Liu|Emory University; Michigan State University|Graph Contrastive Learning (GCL) has demonstrated remarkable effectiveness in learning representations on graphs in recent years. To generate ideal augmentation views, the augmentation generation methods should preserve essential information while discarding less relevant details for downstream tasks. However, current augmentation methods usually involve random topology corruption in the spatial domain, which fails to adequately address information spread across different frequencies in the spectral domain. Our preliminary study highlights this issue, demonstrating that spatial random perturbations impact all frequency bands almost uniformly. Given that task-relevant information typically resides in specific spectral regions that vary across graphs, this one-size-fits-all approach can pose challenges. We argue that indiscriminate spatial random perturbation might unintentionally weaken task-relevant information, reducing its effectiveness. To tackle this challenge, we propose applying perturbations selectively, focusing on information specific to different frequencies across diverse graphs. In this paper, we present GASSER, a model that applies tailored perturbations to specific frequencies of graph structures in the spectral domain, guided by spectral hints. Through extensive experimentation and theoretical analysis, we demonstrate that the augmentation views generated by GASSER are adaptive, controllable, and intuitively aligned with the homophily ratios and spectrum of graph structures.|图对比学习（GCL）近年来在图的表示学习中展示了显著的有效性。为了生成理想的增强视图，增强生成方法应在保留关键信息的同时，去除与下游任务不相关的细节。然而，当前的增强方法通常涉及空间域中的随机拓扑破坏，这未能充分解决频谱域中不同频率上的信息分布问题。我们的初步研究表明了这一问题，表明空间随机扰动几乎均匀地影响所有频段。鉴于任务相关的信息通常位于特定图谱区域，这些区域在不同图中有所不同，这种一刀切的方法可能会带来挑战。我们认为，不分青红皂白的空间随机扰动可能会无意中削弱与任务相关的信息，从而降低其有效性。为了应对这一挑战，我们提出有选择地应用扰动，专注于不同频率上特定于不同图的信息。本文中，我们介绍了GASSER模型，该模型在频谱域中根据频谱提示对图结构的特定频率应用定制的扰动。通过广泛的实验和理论分析，我们证明GASSER生成的增强视图具有自适应性、可控性，并且直观地与图结构的同质性比率和频谱相一致。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spectral-Aware+Augmentation+for+Enhanced+Graph+Representation+Learning)|0|
|[Efficient Pruned Top-K Subgraph Matching with Topology-Aware Bounds](https://doi.org/10.1145/3627673.3679790)|Linglin Yang, Yuqi Zhou, Yue Pang, Lei Zou|Peking University, Beijing, China|Given a query graph, top-k subgraph matching finds up to k matches in a data graph with the highest scores according to a user-defined scoring function. It has wide applications across many fields, including knowledge graphs and social networks. Due to the enormous search space, existing methods are not efficient enough on large graphs. In this paper, we propose PTAB, an efficient algorithm for top-k subgraph matching. It traverses an efficiently pruned search space by topology-aware sub-space score upper bounds computed from a novel hop index, which stores the range of node properties in a constrained multi-hop neighborhood of each node. Additionally, PTAB integrates a cost-aware root selection strategy, which chooses query nodes leading to a search process that utilizes the pruning power of the hop index as much as possible. Furthermore, we use a novel edge-cut strategy to handle general query graphs with cycles. Experimental results on real and synthetic datasets demonstrate that our method outperforms existing methods.|给定一个查询图，top-k子图匹配任务是在数据图中找到至多k个匹配度最高的子图，匹配度由用户定义的评分函数决定。该任务在多个领域中有广泛应用，包括知识图谱和社会网络。由于搜索空间巨大，现有方法在大规模图上效率不足。本文提出了PTAB，一种高效的top-k子图匹配算法。它通过一种新颖的跳跃索引计算出的拓扑感知子空间评分上界，遍历经过高效剪枝的搜索空间，该跳跃索引存储了每个节点在受限多跳邻域内节点属性的范围。此外，PTAB集成了一个成本感知的根节点选择策略，选择能够引导搜索过程尽可能利用跳跃索引剪枝能力的查询节点。我们还采用了一种新颖的边切策略来处理包含循环的一般查询图。在真实和合成数据集上的实验结果表明，我们的方法优于现有方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Pruned+Top-K+Subgraph+Matching+with+Topology-Aware+Bounds)|0|
|[A New Framework for Evaluating Faithfulness of Video Moment Retrieval against Multiple Distractors](https://doi.org/10.1145/3627673.3679838)|Nakyeong Yang, Minsung Kim, Seunghyun Yoon, Joongbo Shin, Kyomin Jung|Seoul National University; Adobe Research; LG AI Research|With the explosion of multimedia content, video moment retrieval (VMR), which aims to detect a video moment that matches a given text query from a video, has been studied intensively as a critical problem. However, the existing VMR framework evaluates video moment retrieval performance, assuming that a video is given, which may not reveal whether the models exhibit overconfidence in the falsely given video. In this paper, we propose the MVMR (Massive Videos Moment Retrieval for Faithfulness Evaluation) task that aims to retrieve video moments within a massive video set, including multiple distractors, to evaluate the faithfulness of VMR models. For this task, we suggest an automated massive video pool construction framework to categorize negative (distractors) and positive (false-negative) video sets using textual and visual semantic distance verification methods. We extend existing VMR datasets using these methods and newly construct three practical MVMR datasets. To solve the task, we further propose a strong informative sample-weighted learning method, CroCs, which employs two contrastive learning mechanisms: (1) weakly-supervised potential negative learning and (2) cross-directional hard-negative learning. Experimental results on the MVMR datasets reveal that existing VMR models are easily distracted by the misinformation (distractors), whereas our model shows significantly robust performance, demonstrating that CroCs is essential to distinguishing positive moments against distractors. Our code and datasets are publicly available: https://github.com/yny0506/Massive-Videos-Moment-Retrieval.|随着多媒体内容的激增，视频时刻检索（VMR）——旨在从视频中检测与给定文本查询匹配的视频片段——已被广泛研究为一个关键问题。然而，现有的VMR框架在评估视频时刻检索性能时，假设视频是已知的，这可能无法揭示模型是否在错误提供的视频上表现出过度自信。在本文中，我们提出了MVMR（大规模视频时刻检索以评估模型忠实度）任务，该任务旨在从包含多个干扰项的大规模视频集中检索视频片段，以评估VMR模型的忠实度。为此任务，我们建议了一种自动大规模视频池构建框架，通过文本和视觉语义距离验证方法来分类负样本（干扰项）和正样本（假负例）视频集。我们使用这些方法扩展了现有的VMR数据集，并新构建了三个实用的MVMR数据集。为了解决该任务，我们进一步提出了一种强信息样本加权学习方法CroCs，该方法采用两种对比学习机制：（1）弱监督潜在负样本学习；（2）跨方向硬负样本学习。在MVMR数据集上的实验结果表明，现有VMR模型容易被错误信息（干扰项）所迷惑，而我们的模型表现出显著的鲁棒性能，证明了CroCs在区分正样本时刻与干扰项方面的重要性。我们的代码和数据集已公开发布：https://github.com/yny0506/Massive-Videos-Moment-Retrieval。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+New+Framework+for+Evaluating+Faithfulness+of+Video+Moment+Retrieval+against+Multiple+Distractors)|0|
|[Attacking Visually-aware Recommender Systems with Transferable and Imperceptible Adversarial Styles](https://doi.org/10.1145/3627673.3679828)|Shiyi Yang, Chen Wang, Xiwei Xu, Liming Zhu, Lina Yao|Data61, CSIRO & The University of New South Wales, Eveleigh, Australia; The University of New South Wales & Data61, CSIRO, Sydney, Australia|The inclusion of the images opens up a security vulnerability of visually-aware recommender systems (VARSs). It can be exploited by unscrupulous parties to upload well-crafted adversarial images for certain malicious purposes (e.g., promoting their own products for profits). Some studies have focused on attacking VARSs to gain insights into their robustness, while they are still far from practical, i.e., the attacks often 1) lack diversity in perturbations, 2) are easily perceived and 3) have limited transferability, which may lead to overestimation of defenses in practice. To tackle the problems, we propose to perturb the style of the product, which is an unnoticeable but important property of visual recommendations. Specifically, we propose a novel Style perturbation-based Practical Attack Framework (SPAF). Unlike existing attacks that change pixels within l∞ -norm constraints, SPAF interferes with styles in latent feature space so that the attack becomes unbounded in the pixel space to reflect possible actual perturbations. SPAF formulates attack objectives as an optimization problem and adopts an adaptive adversarial style transfer network to solve it so that transferable and imperceptible attacks can be generated. Comprehensive experiments on real-world datasets demonstrate that SPAF significantly outperforms state-of-the-art attacks.|图像的引入为视觉感知推荐系统（VARSs）带来了一个安全漏洞。不法分子可以利用这一漏洞上传精心制作的对抗性图像以达到某些恶意目的（例如，推广自己的产品以获取利润）。一些研究专注于攻击VARSs以了解其鲁棒性，但这些攻击方法在实际应用中仍存在不足，主要表现为：1) 扰动缺乏多样性，2) 容易被察觉，3) 转移性有限，这可能导致对防御措施的实际效果产生高估。为解决这些问题，我们提出对产品风格进行扰动，这是一种不易察觉但影响视觉推荐的重要属性。具体而言，我们提出了一种基于风格扰动的实用攻击框架（SPAF）。与现有在l∞范数约束下改变像素的攻击方法不同，SPAF在潜在特征空间中干扰风格，使得攻击在像素空间中变得无边界，以反映可能的实际扰动。SPAF将攻击目标形式化为一个优化问题，并采用自适应对抗风格转移网络来解决该问题，从而生成可转移且不可察觉的攻击。在真实世界数据集上的全面实验表明，SPAF显著优于现有的最先进攻击方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Attacking+Visually-aware+Recommender+Systems+with+Transferable+and+Imperceptible+Adversarial+Styles)|0|
|[A Cause-Focused Query Optimizer Alert System](https://doi.org/10.1145/3627673.3679771)|Runfan Ye, Zibo Liang, Xu Chen, Shuncheng Liu, Kai Zheng||A series of studies apply machine learning to assist cost-based query optimizers in DBMS, emphasizing incorporating uncertainty predictions to guide decision-making. While these approaches have demonstrated advancement in some benchmarks, their drawbacks, such as unstable performance, stem from the inherent challenges of using machine learning models to predict the cost of execution plans and the lack of exploration of the intrinsic characteristics of suboptimal plans. In this paper, we introduce an alert system for query optimization, which is built upon cost models to reduce the selection of regressed plans. The key insight is that there are differences in the predictive uncertainty that lead to query optimization and the regression of execution plans. We investigate the causes of these differences in uncertainty and design a discriminator to filter out execution plans with higher risks of regression. The alert system can be integrated with various cost models, enhancing the robustness of query optimizers. In our experiments, the system further reduces execution time by 20% compared to learned optimizers. Meanwhile, the proportion of optimized queries reduced by the alert system is just 15% of the proportion of regressed queries diminished.|一系列研究将机器学习应用于数据库管理系统（DBMS）中的基于成本的查询优化器，强调了将不确定性预测纳入决策过程的重要性。尽管这些方法在一些基准测试中展示了进步，但其缺点，如性能不稳定，源于使用机器学习模型预测执行计划成本的固有挑战以及对次优计划内在特性的探索不足。本文介绍了一种查询优化预警系统，该系统基于成本模型来减少选择退化的执行计划。关键见解在于，导致查询优化和执行计划退化的预测不确定性之间存在差异。我们研究了这些不确定性差异的原因，并设计了一个判别器来筛选出更有可能退化的执行计划。该预警系统可以与各种成本模型集成，增强了查询优化器的鲁棒性。在我们的实验中，该系统相比学习型优化器进一步减少了20%的执行时间。同时，预警系统减少的优化查询比例仅为减少的退化查询比例的15%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Cause-Focused+Query+Optimizer+Alert+System)|0|
|[DAMe: Personalized Federated Social Event Detection with Dual Aggregation Mechanism](https://doi.org/10.1145/3627673.3679551)|Xiaoyan Yu, Yifan Wei, Pu Li, Shuaishuai Zhou, Hao Peng, Li Sun, Liehuang Zhu, Philip S. Yu||Training social event detection models through federated learning (FedSED) aims to improve participants' performance on the task. However, existing federated learning paradigms are inadequate for achieving FedSED's objective and exhibit limitations in handling the inherent heterogeneity in social data. This paper proposes a personalized federated learning framework with a dual aggregation mechanism for social event detection, namely DAMe. We present a novel local aggregation strategy utilizing Bayesian optimization to incorporate global knowledge while retaining local characteristics. Moreover, we introduce a global aggregation strategy to provide clients with maximum external knowledge of their preferences. In addition, we incorporate a global-local event-centric constraint to prevent local overfitting and “client-drift”. Experiments within a realistic simulation of a natural federated setting, utilizing six social event datasets spanning six languages and two social media platforms, along with an ablation study, have demonstrated the effectiveness of the proposed framework. Further robustness analyses have shown that DAMe is resistant to injection attacks.|通过联邦学习（FedSED）训练社交事件检测模型的目的是提高参与者在任务中的表现。然而，现有的联邦学习范式不足以实现FedSED的目标，并且在处理社交数据固有的异质性方面存在局限性。本文提出了一种具有双重聚合机制的个性化联邦学习框架，用于社交事件检测，即DAMe。我们提出了一种新颖的局部聚合策略，利用贝叶斯优化来融合全局知识同时保留局部特征。此外，我们引入了一种全局聚合策略，以向客户端提供与其偏好相关的最大外部知识。此外，我们结合了一个全局-局部以事件为中心的约束，以防止局部过拟合和“客户端漂移”。在一个现实的联邦设置模拟实验中，使用了跨越六种语言和两个社交媒体平台的六个社交事件数据集，以及一项消融研究，已证明了所提出框架的有效性。进一步的鲁棒性分析表明，DAMe对注入攻击具有抵抗力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DAMe:+Personalized+Federated+Social+Event+Detection+with+Dual+Aggregation+Mechanism)|0|
|[Transformer Based Bayesian Network Embedding for Efficient Multiple Probabilistic Inferences](https://doi.org/10.1145/3627673.3679860)|Kun Yue, Zhiwei Qi, Liang Duan|Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Kunming, Yunnan, Peoples R China; Yunnan Univ, Sch Informat Sci & Engn, Kunming, Yunnan, Peoples R China; Chengdu Univ Informat Technol, Sch Software Engn, Chengdu, Peoples R China|Bayesian network (BN) is a well adopted framework for representing and inferring uncertain knowledge. By the existing methods, multiple probabilistic inferences on the same BN are often fulfilled one by one via repeated searches and calculations of probabilities. However, lots of intermediate results of probability calculations cannot be shared and reused among different probabilistic inferences. It is necessary to improve the overall efficiency of multiple probabilistic inferences on the same BN by incorporating an easy-to-calculate representation of BN and an easy-to-reuse technique for common calculations in multiple inferences. In this paper, we first propose the method of Bayesian network embedding to generate the easy-to-reuse node embeddings. Specifically, we transform BN into the point mutual information (PMI) matrix to simultaneously preserve the directed acyclic graph (DAG) and conditional probability tables (CPTs). Then, we give the singular value decomposition (SVD) based method to factorize the PMI matrix for generating node embeddings. Secondly, we propose a novel method of random sampling to make multiple probabilistic inferences via similarity calculation between node embeddings. Experimental results show that the runtime of our proposed BNERS performing 10 times of inferences is 30% faster than Gibbs sampling (GS) and 50% faster than forward sampling (FS) on LINK BN (very large network), while maintaining almost the same results as GS and FS.|贝叶斯网络（BN）是一个广泛采用的框架，用于表示和推断不确定的知识。现有的方法通常通过重复搜索和概率计算来逐一完成同一贝叶斯网络上的多个概率推断。然而，不同概率推断之间无法共享和重用大量的概率计算中间结果。为了提高同一贝叶斯网络上多个概率推断的整体效率，有必要结合易于计算的贝叶斯网络表示和易于在多次推断中重用的通用计算技术。本文首先提出了贝叶斯网络嵌入方法，以生成易于重用的节点嵌入。具体而言，我们将贝叶斯网络转换为点互信息（PMI）矩阵，以同时保留有向无环图（DAG）和条件概率表（CPTs）。接着，我们给出了基于奇异值分解（SVD）的方法，用于对PMI矩阵进行分解以生成节点嵌入。其次，我们提出了一种新的随机采样方法，通过节点嵌入之间的相似度计算来进行多个概率推断。实验结果表明，在我们提出的BNERS方法中，进行10次推断的运行时间比吉布斯采样（GS）快30%，比前向采样（FS）快50%，并且在LINK BN（非常大的网络）上保持了与GS和FS几乎相同的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Transformer+Based+Bayesian+Network+Embedding+for+Efficient+Multiple+Probabilistic+Inferences)|0|
|[Do We Really Need Graph Convolution During Training? Light Post-Training Graph-ODE for Efficient Recommendation](https://doi.org/10.1145/3627673.3679773)|Weizhi Zhang, Liangwei Yang, Zihe Song, Henry Peng Zou, Ke Xu, Liancheng Fang, Philip S. Yu||The efficiency and scalability of graph convolution networks (GCNs) in training recommender systems (RecSys) have been persistent concerns, hindering their deployment in real-world applications. This paper presents a critical examination of the necessity of graph convolutions during the training phase and introduces an innovative alternative: the Light Post-Training Graph Ordinary-Differential-Equation (LightGODE). Our investigation reveals that the benefits of GCNs are more pronounced during testing rather than training. Motivated by this, LightGODE utilizes a novel post-training graph convolution method that bypasses the computation-intensive message passing of GCNs and employs a non-parametric continuous graph ordinary-differential-equation (ODE) to dynamically model node representations. This approach drastically reduces training time while achieving fine-grained post-training graph convolution to avoid the distortion of the original training embedding space, termed the embedding discrepancy issue. We validate our model across several real-world datasets of different scales, demonstrating that LightGODE not only outperforms GCN-based models in terms of efficiency and effectiveness but also significantly mitigates the embedding discrepancy commonly associated with deeper graph convolution layers. Our LightGODE challenges the prevailing paradigms in RecSys training and suggests re-evaluating the role of graph convolutions, potentially guiding future developments of efficient large-scale graph-based RecSys.|图卷积网络（GCNs）在训练推荐系统（RecSys）中的效率和可扩展性一直是持续关注的问题，阻碍了其在实际应用中的部署。本文对训练阶段图卷积的必要性进行了批判性审视，并提出了一种创新替代方案：轻量级后训练图常微分方程（LightGODE）。我们的研究揭示，GCNs的优势在测试阶段比在训练阶段更为显著。基于此，LightGODE采用了一种新颖的后训练图卷积方法，该方法绕过了GCNs计算密集的消息传递过程，并采用非参数连续图常微分方程（ODE）来动态建模节点表示。这种方法大幅减少了训练时间，同时实现了细粒度的后训练图卷积，以避免原始训练嵌入空间的扭曲，即所谓的嵌入差异问题。我们在多个不同规模的实际数据集上验证了模型的有效性，结果表明LightGODE不仅在效率和效果上优于基于GCN的模型，而且显著缓解了深层图卷积层常见的嵌入差异问题。我们的LightGODE挑战了当前推荐系统训练的主流范式，并建议重新评估图卷积的作用，可能为未来高效大规模基于图的推荐系统的发展提供指导。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Do+We+Really+Need+Graph+Convolution+During+Training?+Light+Post-Training+Graph-ODE+for+Efficient+Recommendation)|0|
|[ROLeR: Effective Reward Shaping in Offline Reinforcement Learning for Recommender Systems](https://doi.org/10.1145/3627673.3679633)|Yi Zhang, Ruihong Qiu, Jiajun Liu, Sen Wang||Offline reinforcement learning (RL) is an effective tool for real-world recommender systems with its capacity to model the dynamic interest of users and its interactive nature. Most existing offline RL recommender systems focus on model-based RL through learning a world model from offline data and building the recommendation policy by interacting with this model. Although these methods have made progress in the recommendation performance, the effectiveness of model-based offline RL methods is often constrained by the accuracy of the estimation of the reward model and the model uncertainties, primarily due to the extreme discrepancy between offline logged data and real-world data in user interactions with online platforms. To fill this gap, a more accurate reward model and uncertainty estimation are needed for the model-based RL methods. In this paper, a novel model-based Reward Shaping in Offline Reinforcement Learning for Recommender Systems, ROLeR, is proposed for reward and uncertainty estimation in recommendation systems. Specifically, a non-parametric reward shaping method is designed to refine the reward model. In addition, a flexible and more representative uncertainty penalty is designed to fit the needs of recommendation systems. Extensive experiments conducted on four benchmark datasets showcase that ROLeR achieves state-of-the-art performance compared with existing baselines. The source code can be downloaded at https://github.com/ArronDZhang/ROLeR.|离线强化学习（RL）凭借其对用户动态兴趣的建模能力和交互特性，成为现实世界推荐系统的有效工具。现有的多数离线RL推荐系统侧重于基于模型的RL方法，即通过从离线数据中学习世界模型，并通过与该模型交互来构建推荐策略。尽管这些方法在推荐性能上取得了进展，但基于模型的离线RL方法的有效性往往受限于奖励模型估计的准确性和模型不确定性，主要原因在于离线日志数据与用户在在线平台上的真实交互数据之间存在极大的差异。为填补这一差距，基于模型的RL方法需要更准确的奖励模型和不确定性估计。本文提出了一种新颖的基于模型的离线强化学习推荐系统奖励塑造方法——ROLeR，用于推荐系统中的奖励和不确定性估计。具体而言，设计了一种非参数的奖励塑造方法来优化奖励模型。此外，还设计了一种灵活且更具代表性的不确定性惩罚机制，以满足推荐系统的需求。在四个基准数据集上进行的大量实验表明，ROLeR相较于现有的基线方法，实现了最先进的性能。源代码可在https://github.com/ArronDZhang/ROLeR下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ROLeR:+Effective+Reward+Shaping+in+Offline+Reinforcement+Learning+for+Recommender+Systems)|0|
|[Aligning Explanations for Recommendation with Rating and Feature via Maximizing Mutual Information](https://doi.org/10.1145/3627673.3679663)|Yurou Zhao, Yiding Sun, Ruidong Han, Fei Jiang, Lu Guan, Xiang Li, Wei Lin, Weizhi Ma, Jiaxin Mao||Providing natural language-based explanations to justify recommendations helps to improve users' satisfaction and gain users' trust. However, as current explanation generation methods are commonly trained with an objective to mimic existing user reviews, the generated explanations are often not aligned with the predicted ratings or some important features of the recommended items, and thus, are suboptimal in helping users make informed decision on the recommendation platform. To tackle this problem, we propose a flexible model-agnostic method named MMI (Maximizing Mutual Information) framework to enhance the alignment between the generated natural language explanations and the predicted rating/important item features. Specifically, we propose to use mutual information (MI) as a measure for the alignment and train a neural MI estimator. Then, we treat a well-trained explanation generation model as the backbone model and further fine-tune it through reinforcement learning with guidance from the MI estimator, which rewards a generated explanation that is more aligned with the predicted rating or a pre-defined feature of the recommended item. Experiments on three datasets demonstrate that our MMI framework can boost different backbone models, enabling them to outperform existing baselines in terms of alignment with predicted ratings and item features. Additionally, user studies verify that MI-enhanced explanations indeed facilitate users' decisions and are favorable compared with other baselines due to their better alignment properties.|提供基于自然语言的解释以证明推荐理由，有助于提升用户的满意度并赢得用户的信任。然而，当前的解释生成方法通常以模仿现有用户评论为目标进行训练，导致生成的解释往往与预测的评分或推荐项目的重要特征不一致，从而在帮助用户在推荐平台上做出明智决策方面表现不佳。为解决这一问题，我们提出了一种灵活的、与模型无关的方法，名为MMI（最大化互信息）框架，以增强生成的自然语言解释与预测评分或重要项目特征之间的一致性。具体而言，我们建议使用互信息（MI）作为一致性的度量，并训练一个神经互信息估计器。随后，我们将一个训练良好的解释生成模型作为基础模型，并通过强化学习对其进行进一步微调，强化学习的指导来自互信息估计器，该估计器奖励那些与预测评分或预定义的项目特征更一致的生成解释。在三个数据集上的实验表明，我们的MMI框架能够提升不同的基础模型，使其在预测评分和项目特征的一致性方面优于现有的基线模型。此外，用户研究表明，经过互信息增强的解释确实有助于用户做出决策，并且由于其更好的对齐特性，相比其他基线方法更受用户青睐。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Aligning+Explanations+for+Recommendation+with+Rating+and+Feature+via+Maximizing+Mutual+Information)|0|
|[Interaction-level Membership Inference Attack against Recommender Systems with Long-tailed Distribution](https://doi.org/10.1145/3627673.3679804)|Da Zhong, Xiuling Wang, Zhichao Xu, Jun Xu, Wendy Hui Wang|Stevens Institute of Technology, Hoboken, NJ, USA; University of Utah, Salt Lake City, UT, USA|Recommender systems (RSs) are susceptible to Interaction-level Membership Inference Attacks (IMIAs), which aim to determine whether specific user-item interactions are present in the training data of the target RS. However, existing IMIAs struggle with inferring the membership of tail interactions, i.e., the interactions involving tail items, due to the limited information available about these items. This paper introduces MINER, a new IMIA designed to enhance attack performance against RSs with long-tailed item distribution. MINER addresses the information scarcity of tail items at both the feature and sample levels. At the feature level, MINER leverages the Knowledge Graphs (KGs) to obtain the auxiliary knowledge of tail items. At the sample level, MINER designs a Bilateral-Branch Network (BBN) as the attack model. The BBN trains two branches independently, with one branch trained on interaction samples with the original long-tailed item distribution and the other on interaction samples with a more balanced item distribution. The outputs of the two branches are aggregated using a cumulative learning component. Our experimental results demonstrate that MINER significantly enhances the attack accuracy of IMIA, especially for tail interactions. Beyond attack design, we design a defense mechanism named RGL to defend against MINER. Empirical evaluations demonstrate that RGL effectively mitigates the privacy risks posed by MINER while preserving recommendation accuracy. Our code is available at https://github.com/dzhong2/MINER.|推荐系统（RSs）容易受到交互级别成员推断攻击（IMIA）的影响，这种攻击旨在确定特定用户-项目交互是否存在于目标推荐系统的训练数据中。然而，现有的IMIA在推断尾部交互（即涉及尾部项目的交互）的成员身份时遇到困难，因为这些项目的信息有限。本文介绍了MINER，这是一种新的IMIA，旨在提高对具有长尾项目分布的推荐系统的攻击性能。MINER在特征和样本两个层面上解决了尾部项目的信息稀缺问题。在特征层面上，MINER利用知识图谱（KGs）获取尾部项目的辅助知识。在样本层面上，MINER设计了一个双分支网络（BBN）作为攻击模型。BBN独立训练两个分支，其中一个分支在具有原始长尾项目分布的交互样本上训练，另一个分支在具有更平衡项目分布的交互样本上训练。两个分支的输出通过累积学习组件进行聚合。我们的实验结果表明，MINER显著提高了IMIA的攻击准确性，尤其是对尾部交互的攻击。除了攻击设计，我们还设计了一种名为RGL的防御机制来抵御MINER。实证评估表明，RGL在保持推荐准确性的同时，有效减轻了MINER带来的隐私风险。我们的代码可在https://github.com/dzhong2/MINER获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interaction-level+Membership+Inference+Attack+against+Recommender+Systems+with+Long-tailed+Distribution)|0|
|[A Power Method to Alleviate Over-smoothing for Recommendation](https://doi.org/10.1145/3627673.3679553)|Peng Zhou, Yachao Cui, Han Cao|Shaanxi Normal University, Xi'an, Shaanxi, China|In recent years, graph convolution networks (GCNs) have been widely used in recommender systems due to high-order node information propagation and aggregation mechanisms. However, existing GCN-based recommender systems drop sharply in performance as the depth of the network increases. This phenomenon is called over-smoothing, which refers to the fact that the embeddings of all nodes become more similar and indistinguishable. Previous works have rarely explored over-smoothing from characteristics of the recommendation field. Specifically, we found experimentally that too many layers can lead to such large loss values that they are difficult to decrease. After theoretical analysis, we can effectively solve the problem of difficulty in decreasing the loss value by adding only a hyperparameter, called "power". This hyperparameter can effectively control the smoothness and alleviate the over-smoothing problem. Experiments on four public datasets demonstrate that this hyperparameter can effectively improve performance.|近年来，图卷积网络（GCN）由于其高阶节点信息传播和聚合机制，在推荐系统中得到了广泛应用。然而，现有的基于GCN的推荐系统在网络深度增加时性能急剧下降。这种现象被称为过平滑，即所有节点的嵌入变得更为相似且难以区分。以往的研究很少从推荐领域的特性出发探讨过平滑问题。具体来说，我们通过实验发现，过多的层数会导致损失值变得如此之大，以至于难以进一步降低。经过理论分析，我们可以通过仅添加一个称为“幂”的超参数来有效解决损失值难以降低的问题。这一超参数能有效控制平滑度并缓解过平滑问题。在四个公开数据集上的实验结果表明，该超参数能有效提升性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Power+Method+to+Alleviate+Over-smoothing+for+Recommendation)|0|
|[Not All Negatives are Equally Negative: Soft Contrastive Learning for Unsupervised Sentence Representations](https://doi.org/10.1145/3627673.3679745)|Haojie Zhuang, Wei Emma Zhang, Jian Yang, Weitong Chen, Quan Z. Sheng|Macquarie University, Sydney, Australia; The University of Adelaide, Adelaide, Australia|Contrastive learning has been extensively studied in sentence representation learning as it demonstrates effectiveness in various downstream applications, where the same sentence with different dropout masks (or other augmentation methods) is considered as positive pair while taking other sentences in the same mini-batch as negative pairs. However, these methods mostly treat all negative examples equally and overlook the different similarities between the negative examples and the anchors, which thus fail to capture the fine-grained semantic information of the sentences. To address this issue, we explicitly differentiate the negative examples by their similarities with the anchor, and thus propose a simple yet effective method SoftCSE that individualizes either the weight or temperature of each negative pair in the standard InfoNCE loss according to the similarities of the negative examples and the anchors. We further provide the theoretical analysis of our methods to show why and how SoftCSE works, including the optimal solution, gradient analysis and the connection with other loss. Empirically, we conduct extensive experiments on semantic textual similarity (STS) and transfer (TR) tasks, as well as text retrieval and reranking, where we observe significant performance improvements compared to strong baseline models.|对比学习在句子表征学习中得到了广泛研究，因为它在各种下游应用中展示了有效性，其中同一个句子在不同的dropout掩码（或其他增强方法）下被视为正样本对，而同一小批次中的其他句子则被视为负样本对。然而，这些方法大多将所有负样本平等对待，忽略了负样本与锚点之间的不同相似性，从而未能捕捉到句子的细粒度语义信息。为了解决这一问题，我们根据负样本与锚点的相似性显式区分负样本，并提出了一种简单而有效的方法SoftCSE，该方法根据负样本与锚点的相似性，在标准的InfoNCE损失中个性化地调整每个负样本对的权重或温度。我们进一步提供了方法的理论分析，以展示SoftCSE为何及如何工作，包括最优解、梯度分析以及与其他损失函数的联系。在实验上，我们在语义文本相似性（STS）和迁移（TR）任务以及文本检索和重排序任务中进行了广泛的实验，观察到与强基线模型相比显著的性能提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Not+All+Negatives+are+Equally+Negative:+Soft+Contrastive+Learning+for+Unsupervised+Sentence+Representations)|0|
|[Professionalism-Aware Pre-Finetuning for Profitability Ranking](https://doi.org/10.1145/3627673.3679981)|ChungChi Chen, Hiroya Takamura, Ichiro Kobayashi, Yusuke Miyao|Ochanomizu University, Tokyo, Japan; The University of Tokyo, Tokyo, Japan; National Institute of Advanced Industrial Science and Technology, Tokyo, Japan|Opinion mining, specifically in the investment sector, has experienced a significant increase in interest over recent years. This paper presents a novel approach to overcome current limitations in assessing and ranking investor opinions based on profitability. The study introduces a pre-finetuning scheme to improve language models' capacity to distinguish professionalism, thus enabling ranking of all available opinions. Furthermore, the paper evaluates ranking results using traditional metrics and suggests the use of a pairwise setting for better performances over a regression setting. Lastly, our method is shown to be effective across various investor opinion tasks, encompassing both professional and amateur investors. The results indicate that this approach significantly enhances the efficiency and accuracy of opinion mining in the investment sector.|观点挖掘，特别是在投资领域，近年来引起了极大的关注。本文提出了一种新颖的方法，以克服当前在根据盈利能力评估和排序投资者观点方面的局限性。研究引入了一种预微调方案，以提高语言模型区分专业性的能力，从而实现对所有可用观点的排序。此外，本文使用传统指标评估排序结果，并建议采用成对设置以在回归设置中获得更好的性能。最后，我们的方法在各种投资者观点任务中显示出有效性，涵盖了专业和业余投资者。结果表明，这种方法显著提高了投资领域观点挖掘的效率和准确性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Professionalism-Aware+Pre-Finetuning+for+Profitability+Ranking)|0|
|[Boosting Large Language Models with Socratic Method for Conversational Mathematics Teaching](https://doi.org/10.1145/3627673.3679881)|Yuyang Ding, Hanglei Hu, Jie Zhou, Qin Chen, Bo Jiang, Liang He||With the introduction of large language models (LLMs), automatic math reasoning has seen tremendous success. However, current methods primarily focus on providing solutions or using techniques like Chain-of-Thought to enhance problem-solving accuracy. In this paper, we focus on improving the capability of mathematics teaching via a Socratic teaching-based LLM (), which guides learners toward profound thinking with clarity and self-discovery via conversation. We collect and release a high-quality mathematical teaching dataset, named , which provides Socratic-style conversations of problems with extra knowledge. Also, we propose a knowledge-enhanced LLM as a strong baseline to generate reliable responses with review, guidance/heuristic, rectification, and summarization. Experimental results show the great advantages of by comparing it with several strong generative models. The codes and datasets are available on .|随着大型语言模型（LLMs）的引入，自动数学推理取得了显著的成功。然而，当前的方法主要集中在提供解决方案或使用链式思维（Chain-of-Thought）等技术来提高问题解决的准确性。在本文中，我们专注于通过基于苏格拉底教学法的LLM（）来提升数学教学能力，该模型通过对话引导学习者进行清晰且自我发现的深刻思考。我们收集并发布了一个高质量的数学教学数据集，命名为，该数据集提供了包含额外知识的苏格拉底式问题对话。此外，我们提出了一个知识增强的LLM作为强基线模型，以生成包含审查、指导/启发、纠正和总结的可靠响应。实验结果表明，通过与几个强大的生成模型进行比较，显示出显著的优势。代码和数据集可在上获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Boosting+Large+Language+Models+with+Socratic+Method+for+Conversational+Mathematics+Teaching)|0|
|[Towards Better Utilization of Multiple Views for Bundle Recommendation](https://doi.org/10.1145/3627673.3680003)|Kyungho Kim, Sunwoo Kim, Geon Lee, Kijung Shin|KAIST, Seoul, Republic of Korea|Bundle recommender systems aim to recommend suitable collections (i.e., bundles) of items to each user, meeting their diverse needs with all-in-one convenience. Typically, they utilize three distinct types of information: user-bundle purchase interactions (U-B view), user-item purchase interactions (U-I view), and bundle-item affiliations (B-I view). Our focus is on better integrating these three perspectives (i.e., views) to deliver more accurate bundle recommendations. Our examination of different role (main or sub-views) combinations of the views reveals two key observations: (1) the best combination varies across target users (i.e., who receive recommendations), and (2) the U-I view is relatively weak as the main role. Driven by these observations, we propose PET, which synergizes the three views through (1) personalized view weighting, (2) U-I view enhancement, and (3) two-pronged contrastive learning. Our extensive experiments demonstrate that PET significantly outperforms existing methods in all popular benchmark datasets. Our code and datasets are available at https://github.com/K-Kyungho/PET.|捆绑推荐系统旨在向每位用户推荐合适的物品集合（即捆绑包），以一站式服务的便利性满足他们的多样化需求。通常，这些系统利用三种不同类型的信息：用户-捆绑包购买交互（U-B视图）、用户-物品购买交互（U-I视图）以及捆绑包-物品关联（B-I视图）。我们的重点是更好地整合这三种视角（即视图），以提供更准确的捆绑推荐。我们对不同角色（主视图或子视图）组合的视图进行了考察，发现了两个关键观察结果：（1）最佳组合因目标用户（即接收推荐的用户）而异，（2）U-I视图作为主角色时相对较弱。基于这些观察，我们提出了PET，它通过以下方式协同整合三种视图：（1）个性化视图加权，（2）U-I视图增强，以及（3）双管齐下的对比学习。我们的广泛实验表明，PET在所有流行的基准数据集上显著优于现有方法。我们的代码和数据集可在https://github.com/K-Kyungho/PET获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Better+Utilization+of+Multiple+Views+for+Bundle+Recommendation)|0|
|[Improving Prompt-based News Recommendation with Individual Template and Customized Answer](https://doi.org/10.1145/3627673.3679945)|Yijiang Li, Jun Wu||Prompt learning plays a key role in aligning the task of news recommendation (NR) with the Pre-trained Language Models (PLMs). However, current prompt-based NR methods utilize fixed templates and answer words, ignoring the personalization of user's demand and the diversity between news topics. To this end, we propose an Automatic Prompt based NR (AutoPNR) scheme, which automatically generates individual templates for users according to their potential interests, and customized answer words w.r.t. the topics of candidate news. Concretely, such an individual template utilizes several specific tokens to encode a user's interest extracted from her/his reading history, while a pair of customized answer words are retrieved from a large vocabulary (often existing alongside PLMs) based on the topic of candidate news. Through extensive experiments on the real-world datasets, we show that our AutoPNR works well with different PLMs, and considerably outperforms state-of-the-art NR techniques.|提示学习在将新闻推荐（NR）任务与预训练语言模型（PLMs）对齐方面起着关键作用。然而，当前基于提示的NR方法使用固定的模板和答案词，忽视了用户需求的个性化以及新闻主题之间的多样性。为此，我们提出了一种基于自动提示的NR（AutoPNR）方案，该方案根据用户的潜在兴趣自动生成个性化的模板，并根据候选新闻的主题定制答案词。具体而言，这种个性化模板使用多个特定标记来编码从用户的阅读历史中提取的兴趣，而一对定制的答案词则根据候选新闻的主题从大型词汇表（通常与PLMs一起存在）中检索。通过对真实世界数据集的广泛实验，我们展示了AutoPNR在不同PLMs上的良好表现，并显著优于现有的最先进NR技术。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Prompt-based+News+Recommendation+with+Individual+Template+and+Customized+Answer)|0|
|[RecPrompt: A Self-tuning Prompting Framework for News Recommendation Using Large Language Models](https://doi.org/10.1145/3627673.3679987)|Dairui Liu, Boming Yang, Honghui Du, Derek Greene, Neil Hurley, Aonghus Lawlor, Ruihai Dong, Irene Li|University College Dublin Insight Centre for Data Analytics; The University of Tokyo Information Technology Center|News recommendations heavily rely on Natural Language Processing (NLP) methods to analyze, understand, and categorize content, enabling personalized suggestions based on user interests and reading behaviors. Large Language Models (LLMs) like GPT-4 have shown promising performance in understanding natural language. However, the extent of their applicability to news recommendation systems remains to be validated. This paper introduces RecPrompt, the first self-tuning prompting framework for news recommendation, leveraging the capabilities of LLMs to perform complex news recommendation tasks. This framework incorporates a news recommender and a prompt optimizer that applies an iterative bootstrapping process to enhance recommendations through automatic prompt engineering. Extensive experimental results with 400 users show that RecPrompt can achieve an improvement of 3.36 MRR, 9.64 Additionally, we introduce TopicScore, a novel metric to assess explainability by evaluating LLM's ability to summarize topics of interest for users. The results show LLM's effectiveness in accurately identifying topics of interest and delivering comprehensive topic-based explanations.|新闻推荐系统严重依赖自然语言处理（NLP）方法来分析、理解和分类内容，从而根据用户的兴趣和阅读行为提供个性化的建议。像GPT-4这样的大型语言模型（LLMs）在理解自然语言方面展示了良好的性能。然而，它们在新闻推荐系统中的适用性仍需验证。本文介绍了RecPrompt，这是首个用于新闻推荐的自调优提示框架，利用LLMs的能力执行复杂的新闻推荐任务。该框架整合了一个新闻推荐器和一个提示优化器，通过自动提示工程的迭代引导过程来增强推荐效果。对400名用户进行的广泛实验结果显示，RecPrompt能够实现3.36的MRR改进和9.64的额外提升。此外，我们引入了TopicScore，一种评估LLM对用户感兴趣主题的总结能力的新指标，以评估解释性。结果表明，LLM在准确识别用户感兴趣的主题并提供全面基于主题的解释方面表现出色。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RecPrompt:+A+Self-tuning+Prompting+Framework+for+News+Recommendation+Using+Large+Language+Models)|0|
|[Enhanced Privacy Bound for Shuffle Model with Personalized Privacy](https://doi.org/10.1145/3627673.3679911)|Yixuan Liu, Yuhan Liu, Li Xiong, Yujie Gu, Hong Chen||The shuffle model of Differential Privacy (DP) is an enhanced privacy protocol which introduces an intermediate trusted server between local users and a central data curator. It significantly amplifies the central DP guarantee by anonymizing and shuffling the local randomized data. Yet, deriving a tight privacy bound is challenging due to its complicated randomization protocol. While most existing work are focused on unified local privacy settings, this work focuses on deriving the central privacy bound for a more practical setting where personalized local privacy is required by each user. To bound the privacy after shuffling, we first need to capture the probability of each user generating clones of the neighboring data points. Second, we need to quantify the indistinguishability between two distributions of the number of clones on neighboring datasets. Existing works either inaccurately capture the probability, or underestimate the indistinguishability between neighboring datasets. Motivated by this, we develop a more precise analysis, which yields a general and tighter bound for arbitrary DP mechanisms. Firstly, we derive the clone-generating probability by hypothesis testing perspective, which leads to a more accurate characterization of the probability. Secondly, we analyze the indistinguishability in the context of f-DP, where the convexity of the distributions is leveraged to achieve a tighter privacy bound. Theoretical and numerical results demonstrate that our bound remarkably outperforms the existing results in the literature.|差分隐私（DP）的洗牌模型是一种增强隐私协议，它在本地用户和中央数据管理员之间引入了一个中间的可信服务器。通过匿名化和洗牌本地随机化的数据，它显著增强了中央DP的保障。然而，由于其复杂的随机化协议，推导出一个紧密的隐私界限是具有挑战性的。尽管大多数现有工作集中在统一的本地隐私设置上，但本文关注的是为每个用户需要个性化本地隐私的更实际设置推导中央隐私界限。为了在洗牌后界定隐私，我们首先需要捕捉每个用户生成相邻数据点副本的概率。其次，我们需要量化相邻数据集上副本数量的两个分布之间的不可区分性。现有工作要么不准确地捕捉概率，要么低估了相邻数据集之间的不可区分性。受此启发，我们开发了一种更精确的分析方法，为任意DP机制提供了一个更通用且更紧密的界限。首先，我们通过假设检验的角度推导出副本生成的概率，从而更准确地描述了概率。其次，我们在f-DP的背景下分析不可区分性，利用分布的凸性来实现更紧密的隐私界限。理论和数值结果表明，我们的界限在文献中显著优于现有结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhanced+Privacy+Bound+for+Shuffle+Model+with+Personalized+Privacy)|0|
|[Channel-Aware Low-Rank Adaptation in Time Series Forecasting](https://doi.org/10.1145/3627673.3679884)|Tong Nie, Yuewen Mei, Guoyang Qin, Jian Sun, Wei Ma||The balance between model capacity and generalization has been a key focus of recent discussions in long-term time series forecasting. Two representative channel strategies are closely associated with model expressivity and robustness, including channel independence (CI) and channel dependence (CD). The former adopts individual channel treatment and has been shown to be more robust to distribution shifts, but lacks sufficient capacity to model meaningful channel interactions. The latter is more expressive for representing complex cross-channel dependencies, but is prone to overfitting. To balance the two strategies, we present a channel-aware low-rank adaptation method to condition CD models on identity-aware individual components. As a plug-in solution, it is adaptable for a wide range of backbone architectures. Extensive experiments show that it can consistently and significantly improve the performance of both CI and CD models with demonstrated efficiency and flexibility. The code is available at https://github.com/tongnie/C-LoRA.|在长期时间序列预测中，模型容量与泛化能力的平衡一直是近期讨论的焦点。两种具有代表性的通道策略与模型的表达能力和鲁棒性密切相关，分别是通道独立性（CI）和通道依赖性（CD）。前者采用独立通道处理，已被证明对分布偏移更具鲁棒性，但缺乏足够的容量来建模有意义的通道交互。后者在表示复杂的跨通道依赖方面更具表达力，但容易过拟合。为了平衡这两种策略，我们提出了一种通道感知的低秩适应方法，将CD模型条件化为具有身份感知的独立组件。作为一种即插即用的解决方案，它适用于广泛的主干架构。大量实验表明，该方法能够持续且显著地提升CI和CD模型的性能，并展现出高效性和灵活性。代码可在https://github.com/tongnie/C-LoRA获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Channel-Aware+Low-Rank+Adaptation+in+Time+Series+Forecasting)|0|
|[Learning Links for Adaptable and Explainable Retrieval](https://doi.org/10.1145/3627673.3679953)|Jianqiang Shen, Yuchin Juan, Ping Liu, Wen Pu, Shaobo Zhang, Qianqi Shen, Liangjie Hong, Wenjing Zhang|LinkedIn, Mountain View, CA, USA|Web-scale search systems typically tackle the scalability challenge with a two-step paradigm: retrieval and ranking. The retrieval step, also known as candidate selection, often involves extracting entities, creating an inverted index, and performing term matching for retrieval. Such traditional methods require manual and time-consuming development of retrieval models. In this paper, we propose a framework for constructing a graph that integrates human knowledge with user activity data analysis. The learned links are utilized for retrieval purposes. The model is easy to explain, debug, and tune. The system implementation is straightforward and can directly leverage existing inverted index systems. We applied this retrieval framework to enhance the job search and recommendation systems on a large professional networking portal, resulting in significant performance improvements.|网络规模的搜索引擎通常采用两步范式来应对可扩展性挑战：检索和排序。检索步骤，也称为候选选择，通常涉及提取实体、创建倒排索引以及执行术语匹配以进行检索。这些传统方法需要手动且耗时的检索模型开发。在本文中，我们提出了一种构建图的框架，该框架将人类知识与用户活动数据分析相结合。学习到的链接用于检索目的。该模型易于解释、调试和调整。系统实现简单直接，可以直接利用现有的倒排索引系统。我们将此检索框架应用于大型专业社交门户网站上的职位搜索和推荐系统，显著提升了性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Links+for+Adaptable+and+Explainable+Retrieval)|0|
|[Preliminary Study on Incremental Learning for Large Language Model-based Recommender Systems](https://doi.org/10.1145/3627673.3679922)|Tianhao Shi, Yang Zhang, Zhijian Xu, Chong Chen, Fuli Feng, Xiangnan He, Qi Tian|Huawei Cloud BU; University of Science and Technology of China Hefei|Adapting Large Language Models for Recommendation (LLM4Rec) has shown promising results. However, the challenges of deploying LLM4Rec in real-world scenarios remain largely unexplored. In particular, recommender models need incremental adaptation to evolving user preferences, while the suitability of traditional incremental learning methods within LLM4Rec remains ambiguous due to the unique characteristics of Large Language Models (LLMs). In this study, we empirically evaluate two commonly employed incremental learning strategies (full retraining and fine-tuning) for LLM4Rec. Surprisingly, neither approach shows significant improvements in the performance of LLM4Rec. Instead of dismissing the role of incremental learning, we attribute the lack of anticipated performance enhancement to a mismatch between the LLM4Rec architecture and incremental learning: LLM4Rec employs a single adaptation module for learning recommendations, limiting its ability to simultaneously capture long-term and short-term user preferences in the incremental learning context. To test this speculation, we introduce a Long- and Short-term Adaptation-aware Tuning (LSAT) framework for incremental learning in LLM4Rec. Unlike the single adaptation module approach, LSAT utilizes two distinct adaptation modules to independently learn long-term and short-term user preferences. Empirical results verify that LSAT enhances performance, thereby validating our speculation. We release our code at: https://github.com/TianhaoShi2001/LSAT.|将大型语言模型（LLM）应用于推荐系统（LLM4Rec）已显示出良好的前景。然而，在实际场景中部署LLM4Rec的挑战仍未得到充分探索。特别是，推荐模型需要对不断变化的用户偏好进行增量适应，而由于大型语言模型的独特特性，传统增量学习方法在LLM4Rec中的适用性尚不明确。在本研究中，我们实证评估了两种常用的增量学习策略（全量重新训练和微调）在LLM4Rec中的应用。令人意外的是，这两种方法均未显著提升LLM4Rec的性能。我们并未因此否定增量学习的作用，而是认为预期的性能提升未能实现的原因在于LLM4Rec架构与增量学习之间的不匹配：LLM4Rec采用单一适应模块进行推荐学习，这限制了其在增量学习情境下同时捕捉长期和短期用户偏好的能力。为验证这一推测，我们引入了长短期适应感知调优（Long- and Short-term Adaptation-aware Tuning, LSAT）框架，用于LLM4Rec中的增量学习。与单一适应模块方法不同，LSAT使用两个独立的适应模块分别学习长期和短期用户偏好。实证结果验证了LSAT能够提升性能，从而证实了我们的推测。我们已在以下链接公开了代码：https://github.com/TianhaoShi2001/LSAT。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Preliminary+Study+on+Incremental+Learning+for+Large+Language+Model-based+Recommender+Systems)|0|
|[ Tabularis Revilio:  Converting Text to Tables](https://doi.org/10.1145/3627673.3680000)|Mukul Singh, Gust Verbruggen, Vu Le, Sumit Gulwani|Microsoft, Keerbergen, Belgium; Microsoft, Redmond, WA, USA|Copying tables from documents and applications without proper tabular support, like PDF documents, web pages or images, surprisingly remains a challenge. In this paper, we present Revilio, a novel neurosymbolic system for reconstructing tables when their column boundaries have been lost. Revilio addresses this task by detecting headers, generating an initial table sketch using a large language model, and using that sketch as a guiding representation during an enumerate-and-test strategy that evaluates syntactic and semantic table structures. We evaluate Revilio on a diverse set of datasets, demonstrating significant improvements over existing table parsing methods. Revilio outperforms traditional techniques in both accuracy and scalability, handling large tables with over 100,000 rows. Our experiments find an increase in reconstruction accuracy by 5.8-11.3% over both neural and symbolic baseline systems|从缺乏适当表格支持的文档和应用程序（如PDF文档、网页或图像）中复制表格，依然是一个出乎意料的挑战。本文介绍了Revilio，这是一种新颖的神经符号系统，用于在表格的列边界丢失时重建表格。Revilio通过检测表头、利用大型语言模型生成初始表格草图，并在此草图的指导下，采用枚举与测试策略来评估句法和语义表格结构，从而解决这一任务。我们在多个数据集上对Revilio进行了评估，结果显示其显著优于现有的表格解析方法。Revilio在准确性和可扩展性方面均超越了传统技术，能够处理包含超过100,000行的大型表格。我们的实验发现，与神经和符号基线系统相比，Revilio的重建准确性提高了5.8%至11.3%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=+Tabularis+Revilio:++Converting+Text+to+Tables)|0|
|[STAR: Sparse Text Approach for Recommendation](https://doi.org/10.1145/3627673.3679999)|Anna Tigunova, Ghazaleh Haratinezhad Torbati, Andrew Yates, Gerhard Weikum|University of Amsterdam, Amsterdam, Netherlands; Amazon, Berlin, Germany; Max Planck Institute for Informatics, Saarbrücken, Germany|In this work we propose to adapt Learned Sparse Retrieval, an emerging approach in IR, to text-centric content-based recommendations, leveraging the strengths of transformer models for an efficient and interpretable user-item matching. We conduct extensive experiments, showing that our LSR-based recommender, dubbed STAR, outperforms existing dense bi-encoder baselines on three recommendation domains. The obtained word-level representations of users and items are easy to examine and result in over 10x more compact indexes.|在这项工作中，我们提出将新兴的信息检索（IR）方法——学习稀疏检索（Learned Sparse Retrieval, LSR），应用于以文本为中心的内容推荐系统中，利用转换器模型的优势实现高效且可解释的用户-物品匹配。我们进行了广泛的实验，结果表明，基于LSR的推荐系统（称为STAR）在三个推荐领域中均优于现有的密集双编码器基线。所获得的用户和物品的词级表示易于检查，并且生成的索引比传统方法紧凑10倍以上。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=STAR:+Sparse+Text+Approach+for+Recommendation)|0|
|[Harnessing Empathy and Ethics for Relevance Detection and Information Categorization in Climate and COVID-19 Tweets](https://doi.org/10.1145/3627673.3679937)|Apoorva Upadhyaya, Wolfgang Nejdl, Marco Fisichella|L3S Research Center, Hannover, Germany|In this work, we aim to understand the general public perception of societal issues related to the current climate crisis and the COVID-19 pandemic on Twitter (X). Social media discussions on such matters often lead to misleading information, resulting in delays in initiatives proposed by governments or policymakers. Hence, we focus on extracting relevant information from the conversations on climate change and COVID that could be useful for authorities to curb the spread of potentially biased information by proposing the classification tasks of relevance detection (RD) and information categorization (IC). We first curate the datasets for the RD and IC tasks for the climate domain and extend the COVID-19 benchmark attention-worthy Twitter dataset for the IC task through manual annotation. We initially conduct experiments with LLMs and observe that LLMs can extract the relevant information in zero and few-shot settings based on multi-perspective reasoning in the form of cognitive empathy and ethical standards, but still perform worse than fine-tuned small language models. Based on the initial findings, we conclude that LLMs may not be the best extractor of relevant information, but induce cognitive empathy and ethical reasonings that can intuitively guide supervised models. To achieve this idea, we develop a cognitive empathy and ethical reasoning-based multi-tasking pipelined network for RD and IC tasks. Our proposed approach provides valuable insights that could be useful in real-world scenarios for governments, policymakers, and other researchers to decode the overall public outlook on societal issues.|在这项工作中，我们的目标是理解公众在Twitter（X）上对当前气候危机和COVID-19大流行相关社会问题的看法。社交媒体上关于这些话题的讨论往往会导致误导性信息的传播，从而延误政府或政策制定者提出的倡议。因此，我们专注于从气候变化和COVID的对话中提取相关信息，这些信息对当局来说可能有助于遏制潜在偏见信息的传播，具体通过提出相关性检测（RD）和信息分类（IC）的分类任务来实现。我们首先为气候领域的RD和IC任务策划数据集，并通过手动注释扩展了COVID-19基准的值得关注的Twitter数据集以用于IC任务。我们最初使用大型语言模型（LLMs）进行实验，观察到LLMs在零样本和少样本设置下能够基于认知共情和伦理标准的多角度推理提取相关信息，但仍然表现不如经过微调的小型语言模型。基于初步发现，我们得出结论，LLMs可能不是相关信息的最佳提取器，但能引发认知共情和伦理推理，这些可以直观地指导监督模型。为了实现这一想法，我们开发了一个基于认知共情和伦理推理的多任务流水线网络，用于RD和IC任务。我们提出的方法提供了有价值的见解，这些见解在现实世界中对政府、政策制定者和其他研究人员解读公众对社会问题的整体看法时可能非常有用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Harnessing+Empathy+and+Ethics+for+Relevance+Detection+and+Information+Categorization+in+Climate+and+COVID-19+Tweets)|0|
|[FashionLOGO: Prompting Multimodal Large Language Models for Fashion Logo Embeddings](https://doi.org/10.1145/3627673.3679926)|Zhen Wang, Da Li, Yulin Su, Min Yang, Minghui Qiu, Walton Wang||Logo embedding models convert the product logos in images into vectors, enabling their utilization for logo recognition and detection within e-commerce platforms. This facilitates the enforcement of intellectual property rights and enhances product search capabilities. However, current methods treat logo embedding as a purely visual problem. A noteworthy issue is that visual models capture features more than logos. Instead, we view this as a multimodal task, using text as auxiliary information to facilitate the visual model's understanding of the logo. The emerging Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in both visual and textual understanding. Inspired by this, we propose an approach, FashionLOGO, to explore how to prompt MLLMs to generate appropriate text for product images, which can help visual models achieve better logo embeddings. We adopt a cross-attention transformer block that enables visual embedding to automatically learn supplementary knowledge from textual embedding. Our extensive experiments on real-world datasets prove that FashionLOGO is capable of generating generic and robust logo embeddings, achieving state-of-the-art performance in all benchmarks.|Logo嵌入模型将图像中的产品Logo转换为向量，从而使其能够在电子商务平台中用于Logo识别和检测。这有助于知识产权的保护并提升产品搜索能力。然而，现有方法将Logo嵌入视为纯粹的视觉问题。一个值得注意的问题是，视觉模型捕捉到的特征往往超出Logo本身。相反，我们将其视为一个多模态任务，利用文本作为辅助信息来帮助视觉模型更好地理解Logo。新兴的多模态大型语言模型（MLLMs）在视觉和文本理解方面展示出卓越的能力。受此启发，我们提出了一种名为FashionLOGO的方法，探索如何引导MLLMs为产品图像生成适当的文本，这有助于视觉模型实现更好的Logo嵌入。我们采用了一个交叉注意力转换器块，使视觉嵌入能够自动从文本嵌入中学习补充知识。我们在真实世界数据集上的广泛实验证明，FashionLOGO能够生成通用且鲁棒的Logo嵌入，在所有基准测试中均达到了最先进的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FashionLOGO:+Prompting+Multimodal+Large+Language+Models+for+Fashion+Logo+Embeddings)|0|
|[CrossPred: A Cross-City Mobility Prediction Framework for Long-Distance Travelers via POI Feature Matching](https://doi.org/10.1145/3627673.3679893)|Shuai Xu, Donghai Guan|Nanjing University of Aeronautics and Astronautics, Nanjing, China|Current studies mainly rely on overlapping users (who leave trajectories in both cities) as a medium to learn travelers' preference in the target city, however it is unrealistic to find overlapping users when two cities are far apart, thus a severe data scarcity issue exists for this problem. Besides, due to the mixture of mobility pattern from both cities, directly applying the model trained in the source city may lead to negative transfer in the target city. To tackle these issues, in this paper, we conceive and implement a novel framework called CrossPred to predict the cross-city mobility of long-distance travelers in the target city. Specifically, POI features including popularity, textual description, spatial distribution as well as sequential pattern are considered for cross-city POI matching, which further acts as a vital link for jointly modeling native user mobility preference in both source and target cities. Maximum Mean Discrepancy (MMD) is adopted to strengthen the shared POI features among cities and weaken the unique POI features, thereby promoting cross-city POI feature matching. Extensive experiments on real-world datasets demonstrate the effectiveness and superiority of the proposed framework.|当前的研究主要依赖于重叠用户（在两个城市都留下轨迹的用户）作为媒介来学习目标城市中旅行者的偏好，然而当两个城市相距甚远时，找到重叠用户是不现实的，因此这个问题存在严重的数据稀缺问题。此外，由于两个城市的移动模式混合，直接应用在源城市训练的模型可能会导致在目标城市中出现负迁移。为了解决这些问题，本文构思并实现了一个名为CrossPred的新框架，用于预测目标城市中长途旅行者的跨城市移动。具体而言，POI特征包括流行度、文本描述、空间分布以及序列模式被考虑用于跨城市POI匹配，这进一步作为联合建模源城市和目标城市中本地用户移动偏好的关键环节。最大均值差异（MMD）被采用来加强城市间的共享POI特征并削弱独特的POI特征，从而促进跨城市POI特征匹配。在真实世界数据集上的广泛实验证明了所提出框架的有效性和优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CrossPred:+A+Cross-City+Mobility+Prediction+Framework+for+Long-Distance+Travelers+via+POI+Feature+Matching)|0|
|[Enhancing Content-based Recommendation via Large Language Model](https://doi.org/10.1145/3627673.3679913)|Wentao Xu, Qianqian Xie, Shuo Yang, Jiangxia Cao, Shuchao Pang||In real-world applications, users express different behaviors when theyinteract with different items, including implicit click/like interactions, andexplicit comments/reviews interactions. Nevertheless, almost all recommenderworks are focused on how to describe user preferences by the implicitclick/like interactions, to find the synergy of people. For the content-basedexplicit comments/reviews interactions, some works attempt to utilize them tomine the semantic knowledge to enhance recommender models. However, they stillneglect the following two points: (1) The content semantic is a universal worldknowledge; how do we extract the multi-aspect semantic information to empowerdifferent domains? (2) The user/item ID feature is a fundamental element forrecommender models; how do we align the ID and content semantic feature space?In this paper, we propose a `plugin' semantic knowledge transferring methodLoID, which includes two major components: (1) LoRA-based largelanguage model pretraining to extract multi-aspect semantic information; (2)ID-based contrastive objective to align their feature spaces. We conductextensive experiments with SOTA baselines on real-world datasets, the detailedresults demonstrating significant improvements of our method LoID.|在实际应用中，用户在与不同项目互动时表现出不同的行为，包括隐式的点击/点赞互动和显式的评论/评价互动。然而，几乎所有的推荐系统都专注于如何通过隐式的点击/点赞互动来描述用户偏好，以发现人群的协同效应。对于基于内容的显式评论/评价互动，一些研究尝试利用它们来挖掘语义知识以增强推荐模型。但是，这些研究仍然忽略了以下两点：（1）内容语义是一种普遍的世界知识；我们如何提取多方面的语义信息以赋能不同领域？（2）用户/项目ID特征是推荐模型的基本元素；我们如何对齐ID和内容语义特征空间？在本文中，我们提出了一种名为LoID的“插件”语义知识转移方法，该方法包括两个主要组件：（1）基于LoRA的大语言模型预训练，以提取多方面的语义信息；（2）基于ID的对比目标，以对齐它们的特征空间。我们在真实世界的数据集上进行了广泛的实验，与最先进的基线方法相比，详细结果显示我们的方法LoID显著提升了性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Content-based+Recommendation+via+Large+Language+Model)|0|
|[Learn From Mistakes: Guidance on Zero-shot Conversational Text-to-SQL](https://doi.org/10.1145/3627673.3679951)|Wenshuo Zhai, Xiang Zhao, Jinzhi Liao, Ziyang Chen||Large language models (LLMs) possess powerful contextual comprehension capabilities and have demonstrated remarkable success in conversational tasks. However, existing works that apply LLMs to conversational text-to-SQL task have the problem of repetitive mistakes, which results in the failure to bring out the performance of LLMs. In this paper, we propose a novel approach that provides guidance through learning from mistakes. Specifically, the guidance offered by our approach includes tailored suggestions, corrective feedback, and personalized strategies aimed at improving learning outcomes. Furthermore, we employ chain-of-thought (CoT) to utilize guidance that is not suitable directly as prompts. Our method rigorously analyzes actual errors and strategizes on how to utilize the derived guidance effectively. Experimental results demonstrate that our approach improves the state-of-the-art (SOTA) performance metrics, increasing QEX performance from 66.3% to 70.9% (an absolute improvement of 4.6%) and IEX performance from 37.4% to 45.1% (an absolute improvement of 7.7%) on the CoSQL dataset.|大型语言模型（LLMs）具备强大的上下文理解能力，并在对话任务中展示了显著的成功。然而，现有将LLMs应用于对话式文本到SQL任务的研究存在重复错误的问题，导致无法充分发挥LLMs的性能。本文提出了一种通过从错误中学习来提供指导的新方法。具体而言，我们的方法提供的指导包括定制建议、纠正反馈和个性化策略，旨在提升学习效果。此外，我们采用思维链（Chain-of-Thought, CoT）来利用不适合直接作为提示的指导。我们的方法严格分析实际错误，并策略性地规划如何有效利用所得到的指导。实验结果表明，我们的方法提升了最先进（SOTA）的性能指标，在CoSQL数据集上，QEX性能从66.3%提高到70.9%（绝对提升4.6%），IEX性能从37.4%提高到45.1%（绝对提升7.7%）。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learn+From+Mistakes:+Guidance+on+Zero-shot+Conversational+Text-to-SQL)|0|
|[Mamba Retriever: Utilizing Mamba for Effective and Efficient Dense Retrieval](https://doi.org/10.1145/3627673.3679959)|Hanqi Zhang, Chong Chen, Lang Mei, Qi Liu, Jiaxin Mao||In the information retrieval (IR) area, dense retrieval (DR) models use deep learning techniques to encode queries and passages into embedding space to compute their semantic relations. It is important for DR models to balance both efficiency and effectiveness. Pre-trained language models (PLMs), especially Transformer-based PLMs, have been proven to be effective encoders of DR models. However, the self-attention component in Transformer-based PLM results in a computational complexity that grows quadratically with sequence length, and thus exhibits a slow inference speed for long-text retrieval. Some recently proposed non-Transformer PLMs, especially the Mamba architecture PLMs, have demonstrated not only comparable effectiveness to Transformer-based PLMs on generative language tasks but also better efficiency due to linear time scaling in sequence length. This paper implements the Mamba Retriever to explore whether Mamba can serve as an effective and efficient encoder of DR model for IR tasks. We fine-tune the Mamba Retriever on the classic short-text MS MARCO passage ranking dataset and the long-text LoCoV0 dataset. Experimental results show that (1) on the MS MARCO passage ranking dataset and BEIR, the Mamba Retriever achieves comparable or better effectiveness compared to Transformer-based retrieval models, and the effectiveness grows with the size of the Mamba model; (2) on the long-text LoCoV0 dataset, the Mamba Retriever can extend to longer text length than its pre-trained length after fine-tuning on retrieval task, and it has comparable or better effectiveness compared to other long-text retrieval models; (3) the Mamba Retriever has superior inference speed for long-text retrieval. In conclusion, Mamba Retriever is both effective and efficient, making it a practical model, especially for long-text retrieval.|在信息检索（IR）领域，密集检索（DR）模型利用深度学习技术将查询和文档编码到嵌入空间中，以计算它们的语义关系。对于DR模型来说，平衡效率和效果至关重要。预训练语言模型（PLMs），特别是基于Transformer的PLMs，已被证明是有效的DR模型编码器。然而，基于Transformer的PLM中的自注意力组件导致了计算复杂度随序列长度呈二次增长的特性，因此在长文本检索中表现出较慢的推理速度。最近提出的一些非Transformer的PLMs，特别是Mamba架构的PLMs，不仅在生成性语言任务上展示了与基于Transformer的PLMs相当的有效性，而且由于序列长度线性时间缩放的特性，还表现出更高的效率。本文实现了Mamba检索器，以探讨Mamba是否可以作为IR任务中DR模型的有效且高效的编码器。我们在经典的短文本MS MARCO文档排序数据集和长文本LoCoV0数据集上对Mamba检索器进行了微调。实验结果表明：（1）在MS MARCO文档排序数据集和BEIR上，Mamba检索器与基于Transformer的检索模型相比，达到了相当或更好的效果，并且效果随着Mamba模型规模的增大而提升；（2）在长文本LoCoV0数据集上，Mamba检索器在检索任务上微调后，可以扩展到比预训练时更长的文本长度，并且与其他长文本检索模型相比，具有相当或更好的效果；（3）Mamba检索器在长文本检索中具有优越的推理速度。综上所述，Mamba检索器既有效又高效，尤其适用于长文本检索，是一个实用的模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mamba+Retriever:+Utilizing+Mamba+for+Effective+and+Efficient+Dense+Retrieval)|0|
|[Generating Cross-model Analytics Workloads Using LLMs](https://doi.org/10.1145/3627673.3679932)|Xiuwen Zheng, Arun Kumar, Amarnath Gupta|University of California, San Diego, La Jolla, USA|Data analytics applications today often require processing heterogeneous data from different data models, including relational, graph, and text data, for more holistic analytics. While query optimization for single data models, especially relational data, has been studied for decades, there is surprisingly little work on query optimization for cross-model data analytics. Cross-model query optimization can benefit from the long line of prior work in query optimization in the relational realm, wherein cost-based and/or machine learning-based (ML-based) optimizers are common. Both approaches require a large and diverse set of query workloads to measure, tune, and evaluate a query optimizer. To the best of our knowledge, there are still no large public cross-model benchmark workloads, a significant obstacle for systems researchers in this space. In this paper, we take a step toward filling this research gap by generating new query workloads spanning relational and graph data, which are ubiquitous in analytics applications. Our approach leverages large language models (LLMs) via different prompting strategies to generate queries and proposes new rule-based post-processing methods to ensure query correctness. We evaluate the pros and cons of each strategy and perform an in-depth analysis by categorizing the syntactic and semantic errors of the generated queries. So far, we have produced over 4000 correct cross-model queries, the largest set ever. Our code, prompts, data, and query workloads will all be released publicly.|当今的数据分析应用通常需要处理来自不同数据模型的异构数据，包括关系型数据、图数据和文本数据，以实现更全面的分析。尽管针对单一数据模型的查询优化，尤其是关系型数据，已经研究了几十年，但关于跨模型数据分析的查询优化研究却出乎意料地少。跨模型查询优化可以借鉴关系领域中丰富的查询优化先前工作，其中基于成本和/或基于机器学习（ML-based）的优化器是常见的。这两种方法都需要大量且多样化的查询工作负载来测量、调整和评估查询优化器。据我们所知，目前仍没有大型公共的跨模型基准工作负载，这对该领域的系统研究人员来说是一个重大障碍。在本文中，我们朝着填补这一研究空白迈出了一步，生成了涵盖关系型和图数据的新查询工作负载，这些数据在分析应用中非常普遍。我们的方法利用大型语言模型（LLMs）通过不同的提示策略生成查询，并提出了新的基于规则的后处理方法以确保查询的正确性。我们评估了每种策略的优缺点，并通过分类生成的查询的句法和语义错误进行了深入分析。到目前为止，我们已经生成了超过4000个正确的跨模型查询，这是迄今为止最大的集合。我们的代码、提示、数据和查询工作负载将全部公开发布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generating+Cross-model+Analytics+Workloads+Using+LLMs)|0|
|[Deep Journey Hierarchical Attention Networks for Conversion Predictions in Digital Marketing](https://doi.org/10.1145/3627673.3680066)|Girim Ban, Hyeonseok Yun, Banseok Lee, David Sung, Simon S. Woo|Korea Telecom (KT) NexR, Seoul, Republic of Korea; Sungkyunkwan University, Suwon, Republic of Korea|In digital marketing, precise audience targeting is crucial for campaign efficiency. However, digital marketing agencies often struggle with incomplete user profiles and interaction details from Advertising Identifier (ADID) data in user behavior modeling. To address this, we introduce the Deep Journey Hierarchical Attention Networks (DJHAN). This novel method enhances conversion predictions by leveraging heterogeneous action sequences associated with ADIDs and encapsulating these interactions into structured journeys. These journeys are hierarchically aggregated to effectively represent ADID's behavioral attributes. Moreover, DJHAN incorporates three specialized attention mechanisms: temporal attention for time-sensitive contexts, action attention for emphasizing key behaviors, and journety attention for highlighting influential journeys in the purchase conversion process. Emprically, DJHAN surpasses state-of-the-art (SOTA) models across three diverse datasets, including real-world data from NasMedia, a leading media representative in Asia. In backtesting simulations with three advertisers, DJHAN outperforms existing baselines, achieving the highest improvements in Conversion Rate (CVR) and Return on Ad Spend (ROAS) across three advertisers, demonstrating its practical potential in digital marketing.|在数字营销中，精准的受众定位对于提升广告活动效率至关重要。然而，数字营销机构在用户行为建模中常常面临用户资料不完整以及从广告标识符（ADID）数据中获取的互动细节不足的问题。为解决这一问题，我们提出了深度旅程分层注意力网络（DJHAN）。这一创新方法通过利用与ADID相关的异构行为序列，并将这些互动封装成结构化的旅程，从而提高转化预测的准确性。这些旅程被分层聚合，以有效表示ADID的行为属性。此外，DJHAN结合了三种专门的注意力机制：时间注意力用于处理时间敏感的上下文，行为注意力用于强调关键行为，以及旅程注意力用于突出购买转化过程中具有影响力的旅程。实验证明，DJHAN在三个不同数据集上均超越了当前最先进（SOTA）的模型，其中包括来自亚洲领先媒体代表NasMedia的真实世界数据。在针对三家广告商的回测模拟中，DJHAN优于现有的基准模型，在转化率（CVR）和广告支出回报率（ROAS）方面均实现了最高的提升，展示了其在数字营销中的实际应用潜力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Journey+Hierarchical+Attention+Networks+for+Conversion+Predictions+in+Digital+Marketing)|0|
|[LiNR: Model Based Neural Retrieval on GPUs at LinkedIn](https://doi.org/10.1145/3627673.3680091)|Fedor Borisyuk, Qingquan Song, Mingzhou Zhou, Ganesh Parameswaran, Madhu Arun, Siva Popuri, Tugrul Bingol, Zhuotao Pei, KuangHsuan Lee, Lu Zheng, Qizhan Shao, Ali Naqvi, Sen Zhou, Aman Gupta||This paper introduces LiNR, LinkedIn's large-scale, GPU-based retrieval system. LiNR supports a billion-sized index on GPU models. We discuss our experiences and challenges in creating scalable, differentiable search indexes using TensorFlow and PyTorch at production scale. In LiNR, both items and model weights are integrated into the model binary. Viewing index construction as a form of model training, we describe scaling our system for large indexes, incorporating full scans and efficient filtering. A key focus is on enabling attribute-based pre-filtering for exhaustive GPU searches, addressing the common challenge of post-filtering in KNN searches that often reduces system quality. We further provide multi-embedding retrieval algorithms and strategies for tackling cold start issues in retrieval. Our advancements in supporting larger indexes through quantization are also discussed. We believe LiNR represents one of the industry's first Live-updated model-based retrieval indexes. Applied to out-of-network post recommendations on LinkedIn Feed, LiNR has contributed to a 3% relative increase in professional daily active users. We envisage LiNR as a step towards integrating retrieval and ranking into a single GPU model, simplifying complex infrastructures and enabling end-to-end optimization of the entire differentiable infrastructure through gradient descent.|本文介绍了LiNR，即LinkedIn基于GPU的大规模检索系统。LiNR支持在GPU模型上处理十亿级索引。我们探讨了在生产规模下使用TensorFlow和PyTorch创建可扩展、可微分搜索索引的经验和挑战。在LiNR中，项目和模型权重都被整合到模型二进制文件中。将索引构建视为一种模型训练的形式，我们描述了如何扩展系统以处理大规模索引，包括全扫描和高效过滤。一个关键重点是启用基于属性的预过滤，以支持全面的GPU搜索，解决KNN搜索中常见的后过滤问题，这些问题通常会降低系统质量。此外，我们还提供了多嵌入检索算法和策略，用于解决检索中的冷启动问题。我们还在通过量化支持更大索引方面取得了进展。我们相信，LiNR代表了业界首批实时更新的基于模型的检索索引之一。应用于LinkedIn Feed的非网络帖子推荐，LiNR已为专业每日活跃用户带来了3%的相对增长。我们设想LiNR是朝着将检索和排序整合到单一GPU模型中的方向迈出的一步，简化了复杂的基础设施，并通过梯度下降实现了整个可微分基础设施的端到端优化。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LiNR:+Model+Based+Neural+Retrieval+on+GPUs+at+LinkedIn)|0|
|[Personalized Video Summarization by Multimodal Video Understanding](https://doi.org/10.1145/3627673.3680011)|Brian Y. Chen, Xiangyuan Zhao, Yingnan Zhu|VDIL, Samsung Research America, irvine, CA, USA; VDIL, Samsung Research America, Irvine, CA, USA|Video summarization techniques have been proven to improve the overall user experience when it comes to accessing and comprehending video content. If the user's preference is known, video summarization can identify significant information or relevant content from an input video, aiding them in obtaining the necessary information or determining their interest in watching the original video. Adapting video summarization to various types of video and user preferences requires significant training data and expensive human labeling. To facilitate such research, we proposed a new benchmark for video summarization that captures various user preferences. Also, we present a pipeline called Video Summarization with Language (VSL) for user-preferred video summarization that is based on pre-trained visual language models (VLMs) to avoid the need to train a video summarization system on a large training dataset. The pipeline takes both video and closed captioning as input and performs semantic analysis at the scene level by converting video frames into text. Subsequently, the user's genre preference was used as the basis for selecting the pertinent textual scenes. The experimental results demonstrate that our proposed pipeline outperforms current state-of-the-art unsupervised video summarization models. We show that our method is more adaptable across different datasets compared to supervised query-based video summarization models. In the end, the runtime analysis demonstrates that our pipeline is more suitable for practical use when scaling up the number of user preferences and videos.|视频摘要技术已被证明在用户访问和理解视频内容时能够提升整体用户体验。如果用户的偏好已知，视频摘要可以从输入视频中识别出重要信息或相关内容，帮助用户获取必要信息或判断是否对观看原视频感兴趣。将视频摘要适应于各种类型的视频和用户偏好需要大量的训练数据和昂贵的人工标注。为了促进此类研究，我们提出了一种新的视频摘要基准，该基准捕捉了多种用户偏好。此外，我们提出了一种名为Video Summarization with Language（VSL）的管道，用于基于预训练的视觉语言模型（VLMs）的用户偏好视频摘要，以避免在大规模训练数据集上训练视频摘要系统的需求。该管道接受视频和封闭字幕作为输入，并通过将视频帧转换为文本来在场景级别进行语义分析。随后，用户的类型偏好被用作选择相关文本场景的基础。实验结果表明，我们提出的管道优于当前最先进的无监督视频摘要模型。我们展示了与基于监督查询的视频摘要模型相比，我们的方法在不同数据集上更具适应性。最后，运行时分析表明，当扩展用户偏好和视频数量时，我们的管道更适合实际应用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Video+Summarization+by+Multimodal+Video+Understanding)|0|
|[Blind-Match:  Efficient Homomorphic Encryption-Based 1: N Matching for Privacy-Preserving Biometric Identification](https://doi.org/10.1145/3627673.3680017)|Hyunmin Choi, Jiwon Kim, Chiyoung Song, Simon S. Woo, Hyoungshick Kim||We present Blind-Match, a novel biometric identification system that leverages homomorphic encryption (HE) for efficient and privacy-preserving 1:N matching. Blind-Match introduces a HE-optimized cosine similarity computation method, where the key idea is to divide the feature vector into smaller parts for processing rather than computing the entire vector at once. By optimizing the number of these parts, Blind-Match minimizes execution time while ensuring data privacy through HE. Blind-Match achieves superior performance compared to state-of-the-art methods across various biometric datasets. On the LFW face dataset, Blind-Match attains a 99.63 feature vector, demonstrating its robustness in face recognition tasks. For fingerprint identification, Blind-Match achieves a remarkable 99.55 accuracy on the PolyU dataset, even with a compact 16-dimensional feature vector, significantly outperforming the state-of-the-art method, Blind-Touch, which achieves only 59.17 efficiency in large-scale biometric identification scenarios, such as Naver Cloud's FaceSign, by processing 6,144 biometric samples in 0.74 seconds using a 128-dimensional feature vector.|我们提出了Blind-Match，这是一种新颖的生物识别身份验证系统，利用同态加密（HE）实现高效且隐私保护的1:N匹配。Blind-Match引入了一种HE优化的余弦相似度计算方法，其关键思想是将特征向量分成较小的部分进行处理，而不是一次性计算整个向量。通过优化这些部分的数量，Blind-Match在确保通过HE保护数据隐私的同时，最小化了执行时间。与现有最先进的方法相比，Blind-Match在各种生物识别数据集上表现出色。在LFW人脸数据集上，Blind-Match实现了99.63的特征向量识别率，展示了其在人脸识别任务中的鲁棒性。对于指纹识别，Blind-Match在PolyU数据集上达到了惊人的99.55的准确率，即使使用的是紧凑的16维特征向量，也显著优于最先进的方法Blind-Touch，后者在大规模生物识别身份验证场景中，如Naver Cloud的FaceSign，仅实现了59.17的效率，通过处理6,144个生物识别样本在0.74秒内使用128维特征向量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Blind-Match:++Efficient+Homomorphic+Encryption-Based+1:+N+Matching+for+Privacy-Preserving+Biometric+Identification)|0|
|[Automated Contrastive Learning Strategy Search for Time Series](https://doi.org/10.1145/3627673.3680086)|Baoyu Jing, Yansen Wang, Guoxin Sui, Jing Hong, Jingrui He, Yuqing Yang, Dongsheng Li, Kan Ren|Ruijin Hospital; Microsoft Research Asia; University of Illinois at Urbana-Champaign; ShanghaiTech University|In recent years, Contrastive Learning (CL) has become a predominantrepresentation learning paradigm for time series. Most existing methods in theliterature focus on manually building specific Contrastive Learning Strategies(CLS) by human heuristics for certain datasets and tasks. However, manuallydeveloping CLS usually require excessive prior knowledge about the datasets andtasks, e.g., professional cognition of the medical time series in healthcare,as well as huge human labor and massive experiments to determine the detailedlearning configurations. In this paper, we present an Automated MachineLearning (AutoML) practice at Microsoft, which automatically learns tocontrastively learn representations for various time series datasets and tasks,namely Automated Contrastive Learning (AutoCL). We first construct a principleduniversal search space of size over 3x1012, covering data augmentation,embedding transformation, contrastive pair construction and contrastive losses.Further, we introduce an efficient reinforcement learning algorithm, whichoptimizes CLS from the performance on the validation tasks, to obtain moreeffective CLS within the space. Experimental results on various real-worldtasks and datasets demonstrate that AutoCL could automatically find thesuitable CLS for a given dataset and task. From the candidate CLS found byAutoCL on several public datasets/tasks, we compose a transferable GenerallyGood Strategy (GGS), which has a strong performance for other datasets. We alsoprovide empirical analysis as a guidance for future design of CLS.|近年来，对比学习（Contrastive Learning, CL）已成为时间序列的主要表示学习范式。现有文献中的大多数方法侧重于通过人类启发式方法为特定数据集和任务手动构建特定的对比学习策略（Contrastive Learning Strategy, CLS）。然而，手动开发CLS通常需要对数据集和任务有大量的先验知识，例如医疗保健领域中对医疗时间序列的专业认知，以及大量的人力劳动和实验来确定详细的学习配置。在本文中，我们介绍了微软在自动化机器学习（Automated Machine Learning, AutoML）方面的一项实践，该实践能够自动学习为各种时间序列数据集和任务进行对比学习表示，即自动化对比学习（Automated Contrastive Learning, AutoCL）。我们首先构建了一个原则性的通用搜索空间，其大小超过3x10^12，涵盖了数据增强、嵌入变换、对比对构建和对比损失。此外，我们引入了一种高效的强化学习算法，该算法从验证任务的性能出发优化CLS，以在空间内获得更有效的CLS。在各种真实世界任务和数据集上的实验结果表明，AutoCL能够自动找到适合给定数据集和任务的CLS。从AutoCL在几个公共数据集/任务上找到的候选CLS中，我们组合了一个可迁移的通用良好策略（Generally Good Strategy, GGS），该策略在其他数据集上表现出色。我们还提供了经验分析，作为未来设计CLS的指导。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automated+Contrastive+Learning+Strategy+Search+for+Time+Series)|0|
|[REAPER: Reasoning based Retrieval Planning for Complex RAG Systems](https://doi.org/10.1145/3627673.3680087)|Ashutosh Joshi, Sheikh Muhammad Sarwar, Samarth Varshney, Sreyashi Nag, Shrivats Agrawal, Juhi Naik||Complex dialog systems often use retrieved evidence to facilitate factual responses. Such RAG (Retrieval Augmented Generation) systems retrieve from massive heterogeneous data stores that are usually architected as multiple indexes or APIs instead of a single monolithic source. For a given query, relevant evidence needs to be retrieved from one or a small subset of possible retrieval sources. Complex queries can even require multi-step retrieval. For example, a conversational agent on a retail site answering customer questions about past orders will need to retrieve the appropriate customer order first and then the evidence relevant to the customer's question in the context of the ordered product. Most RAG Agents handle such Chain-of-Thought (CoT) tasks by interleaving reasoning and retrieval steps. However, each reasoning step directly adds to the latency of the system. For large models (>100B parameters) this latency cost is significant – in the order of multiple seconds. Multi-agent systems may classify the query to a single Agent associated with a retrieval source, though this means that a (small) classification model dictates the performance of a large language model. In this work we present REAPER (REAsoning-based PlannER) - an LLM based planner to generate retrieval plans in conversational systems. We show significant gains in latency over Agent-based systems and are able to scale easily to new and unseen use cases as compared to classification-based planning. Though our method can be applied to any RAG system, we show our results in the context of Rufus – Amazon's conversational shopping assistant.|复杂的对话系统通常使用检索到的证据来支持事实性回答。这类RAG（检索增强生成）系统从通常架构为多个索引或API而非单一整体源的庞大异构数据存储中进行检索。对于给定的查询，相关证据需要从一个或少数几个可能的检索源中检索出来。复杂的查询甚至可能需要多步检索。例如，一个零售网站上的对话代理在回答关于过去订单的客户问题时，首先需要检索到适当的客户订单，然后在此订单产品的上下文中检索与客户问题相关的证据。大多数RAG代理通过交错推理和检索步骤来处理此类思维链（Chain-of-Thought, CoT）任务。然而，每个推理步骤都会直接增加系统的延迟。对于大型模型（超过1000亿参数），这种延迟成本是显著的——通常在几秒的量级。多代理系统可能会将查询分类到一个与检索源相关的单一代理，尽管这意味着一个（小型）分类模型决定了大型语言模型的性能。在这项工作中，我们提出了REAPER（基于推理的计划器）——一个基于LLM的计划器，用于在对话系统中生成检索计划。我们展示了在基于代理的系统中显著的延迟改进，并且能够轻松扩展到新的和未见过的用例，相比于基于分类的计划。虽然我们的方法可以应用于任何RAG系统，但我们展示了在Rufus——亚马逊的对话购物助手——中的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=REAPER:+Reasoning+based+Retrieval+Planning+for+Complex+RAG+Systems)|0|
|[RL-ISLAP: A Reinforcement Learning Framework for Industrial-Scale Linear Assignment Problems at Alipay](https://doi.org/10.1145/3627673.3680108)|Hanjie Li, Yue Ning, Yang Bao, Changsheng Li, Boxiao Chen, Xingyu Lu, Ye Yuan, Guoren Wang|Independent Researcher, Hangzhou, China; Independent Researcher, Shanghai, China; Beijing Institute of Technology, Beijing, China|Industrial-scale linear assignment problems (LAPs) are frequently encountered in various industrial scenarios, e.g., asset allocation within the domain of credit management. However, optimization algorithms for such problems (e.g., PJ-ADMM) are highly sensitive to hyper-parameters. Existing solving systems rely on empirical parameter selection, which is challenging to achieve convergence and extremely time-consuming. Additionally, the resulting parameter rules are often inefficient. To alleviate this issue, we propose RL-ISLAP, an efficient and lightweight Reinforcement Learning framework for Industrial-Scale Linear Assignment Problems. We formulate the hyper-parameter selection for PJ-ADMM as a sequential decision problem and leverage reinforcement learning to enhance its convergence. Addressing the sparse reward challenge inherent in learning policies for such problems, we devise auxiliary rewards to provide dense signals for policy optimization, and present a rollback mechanism to prevent divergence in the solving process. Experiments on OR-Library benchmark demonstrate that our method is competitive to SOTA stand-alone solvers. Furthermore, the scale-independent design of observations enables us to transfer the acquired hyper-parameter policy to a scenario of LAPs in varying scales. On two real-world industrial-scale LAPs with up to 10 millions of decision variables, our proposed RL-ISLAP achieves solutions of comparable quality in 2/3 of the time when compared to the SOTA distributed solving system employing fine-tuned empirical parameter rules.|在各种工业场景中，例如信用管理领域的资产分配，经常会遇到大规模的线性分配问题（LAPs）。然而，针对此类问题的优化算法（例如PJ-ADMM）对超参数非常敏感。现有的求解系统依赖于经验参数选择，这不仅难以实现收敛，而且极其耗时。此外，由此产生的参数规则往往效率低下。为了缓解这一问题，我们提出了RL-ISLAP，一个针对工业规模线性分配问题的高效且轻量级的强化学习框架。我们将PJ-ADMM的超参数选择问题形式化为一个序列决策问题，并利用强化学习来增强其收敛性。针对此类问题中固有的稀疏奖励挑战，我们设计了辅助奖励以提供密集的信号用于策略优化，并提出了一种回滚机制以防止求解过程中的发散。在OR-Library基准测试中的实验表明，我们的方法与最先进的独立求解器具有竞争力。此外，观察结果的规模无关设计使我们能够将获得的超参数策略迁移到不同规模的LAP场景中。在两个具有多达1000万个决策变量的真实工业规模LAP问题上，与使用精细调参的经验参数规则的最先进分布式求解系统相比，我们提出的RL-ISLAP在2/3的时间内实现了同等质量的解决方案。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RL-ISLAP:+A+Reinforcement+Learning+Framework+for+Industrial-Scale+Linear+Assignment+Problems+at+Alipay)|0|
|[Explainable and Coherent Complement Recommendation Based on Large Language Models](https://doi.org/10.1145/3627673.3680028)|Zelong Li, Yan Liang, Ming Wang, Sungro Yoon, Jiaying Shi, Xin Shen, Xiang He, Chenwei Zhang, Wenyi Wu, Hanbo Wang, Jin Li, Jim Chan, Yongfeng Zhang|Amazon.com, Seattle, WA, USA; Rutgers University, New Brunswick, NJ, USA|A complementary item is an item that pairs well with another item when consumed together. In the context of e-commerce, providing recommendations for complementary items is essential for both customers and stores. Current models for suggesting complementary items often rely heavily on user behavior data, such as co-purchase relationships. However, just because two items are frequently bought together does not necessarily mean they are truly complementary. Relying solely on co-purchase data may not align perfectly with the goal of making meaningful complementary recommendations. In this paper, we introduce the concept of "coherent complement recommendation", where "coherent" implies that recommended item pairs are compatible and relevant. Our approach builds upon complementary item pairs, with a focus on ensuring that recommended items are well used together and contextually relevant. To enhance the explainability and coherence of our complement recommendations, we fine-tune the Large Language Model (LLM) with coherent complement recommendation and explanation generation tasks since LLM has strong natural language explanation generation ability and multi-task fine-tuning enhances task understanding. Experimental results indicate that our model can provide more coherent complementary recommendations than existing state-of-the-art methods, and human evaluation validates that our approach achieves up to a 48% increase in the coherent rate of complement recommendations.|互补商品是指在共同消费时能够良好搭配的商品。在电子商务领域，为顾客和商家提供互补商品的推荐至关重要。当前推荐互补商品的模型通常严重依赖用户行为数据，如共同购买关系。然而，仅仅因为两种商品经常被一起购买并不一定意味着它们真正具有互补性。仅依赖共同购买数据可能无法完全实现提供有意义的互补推荐的目标。本文中，我们引入了“连贯互补推荐”的概念，其中“连贯”意味着推荐的商品对是兼容且相关的。我们的方法基于互补商品对，重点确保推荐的商品在使用时能够良好搭配并具有上下文相关性。为了增强互补推荐的解释性和连贯性，我们通过连贯互补推荐和解释生成任务对大型语言模型（LLM）进行微调，因为LLM具有强大的自然语言解释生成能力和多任务微调可以增强任务理解。实验结果表明，我们的模型能够提供比现有最先进方法更为连贯的互补推荐，而人工评估验证了我们的方法在互补推荐连贯率上实现了高达48%的提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explainable+and+Coherent+Complement+Recommendation+Based+on+Large+Language+Models)|0|
|[Boosting LLM-based Relevance Modeling with Distribution-Aware Robust Learning](https://doi.org/10.1145/3627673.3680052)|Hong Liu, Saisai Gong, Yixin Ji, Kaixin Wu, Jia Xu, Jinjie Gu|Ant Group, Hangzhou, China|Relevance modeling plays a crucial role in e-commerce search engines, striving to identify the utmost pertinent items corresponding to a given search query. With the rapid advancement of pre-trained large language models (LLMs), recent endeavors have leveraged the capabilities of LLMs in relevance modeling, resulting in enhanced performance. This is usually done through the process of fine-tuning LLMs on specifically annotated datasets to determine the relevance between queries and items. However, there are two limitations when LLMs are naively employed for relevance modeling through fine-tuning and inference. First, it is not inherently efficient for performing nuanced tasks beyond simple yes or no answers, such as assessing search relevance. It may therefore tend to be overconfident and struggle to distinguish fine-grained degrees of relevance (e.g., strong relevance, weak relevance, irrelevance) used in search engines. Second, it exhibits significant performance degradation when confronted with data distribution shift in real-world scenarios. In this paper, we propose a novel Distribution-Aware Robust Learning framework (DaRL) for relevance modeling in Alipay Search. Specifically, we design an effective loss function to enhance the discriminability of LLM-based relevance modeling across various fine-grained degrees of query-item relevance. To improve the generalizability of LLM-based relevance modeling, we first propose the Distribution-Aware Sample Augmentation (DASA) module. This module utilizes out-of-distribution (OOD) detection techniques to actively select appropriate samples that are not well covered by the original training set for model fine-tuning. Furthermore, we adopt a multi-stage fine-tuning strategy to simultaneously improve in-distribution (ID) and OOD performance, bridging the performance gap between them. DaRL has been deployed online to serve the Alipay's insurance product search. Both offline experiments on real-world industry data and online A/B testing show that DaRL effectively improves the performance of relevance modeling.|相关性建模在电子商务搜索引擎中扮演着至关重要的角色，旨在识别与给定搜索查询最相关的商品。随着预训练大型语言模型（LLMs）的快速发展，近期研究已利用LLMs在相关性建模中的能力，从而提升了性能。这通常通过在专门标注的数据集上微调LLMs来实现，以确定查询与商品之间的相关性。然而，当LLMs通过微调和推理简单地用于相关性建模时，存在两个局限性。首先，LLMs并不擅长执行超出简单是或否回答的细微任务，例如评估搜索相关性。因此，它们可能倾向于过度自信，难以区分搜索引擎中使用的细粒度相关性程度（如强相关、弱相关、不相关）。其次，在面对现实场景中的数据分布偏移时，LLMs表现出显著的性能下降。

本文提出了一个名为分布感知鲁棒学习框架（DaRL）的新方法，用于支付宝搜索中的相关性建模。具体而言，我们设计了一种有效的损失函数，以增强基于LLM的相关性建模在不同细粒度查询-商品相关性上的区分能力。为了提高基于LLM的相关性建模的泛化能力，我们首先提出了分布感知样本增强（DASA）模块。该模块利用分布外（OOD）检测技术，主动选择原始训练集未充分覆盖的适当样本进行模型微调。此外，我们采用多阶段微调策略，以同时提升分布内（ID）和分布外（OOD）性能，缩小两者之间的性能差距。DaRL已部署上线，服务于支付宝的保险产品搜索。基于真实行业数据的线下实验和在线A/B测试均表明，DaRL有效提升了相关性建模的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Boosting+LLM-based+Relevance+Modeling+with+Distribution-Aware+Robust+Learning)|0|
|[A Self-Adaptive Fairness Constraint Framework for Industrial Recommender System](https://doi.org/10.1145/3627673.3680099)|Zhiqiang Liu, Xiaoxiao Xu, Jiaqi Yu, Han Xu, Lantao Hu, Han Li, Kun Gai|Unaffiliated, Beijing, China; Kuaishou Technology, BeiJing, China; Kuaishou Technology, Beijing, China|Achieving fairness among different individuals or groups is an essential task for industrial recommender systems. Due to the group's personalized selection tendencies and the non-uniform population distributions, existing industrial recommenders tend to make unfair predictions towards the preferences of minority groups. To alleviate this unfairness, we propose a model-agnostic self-adaptive fairness constraint framework (SaFair) based on the posterior preferences of different groups. We construct group-level and individual-level fairness constraints. The former measures consistency between group-level posterior preferences and predicted interests, and the latter relies on the degree of consistency in interests between a user and their associated group to perform self-adaptive constraints. In particular, to balance effectiveness and fairness, we utilize uncertainty estimation to adjust the intensity of constraints according to the model's learning status called self-adaptive constraints. Extensive offline experiments and online A/B Testing are conducted and the results validate the superiority of our proposed method over the baselines. SaFair has been successfully deployed in Kuaishou, one of China's most popular short-video streaming platforms with hundreds of millions of active users.|在工业推荐系统中，实现不同个体或群体之间的公平性是一项至关重要的任务。由于群体的个性化选择倾向和非均匀的人口分布，现有的工业推荐系统往往对少数群体的偏好做出不公平的预测。为了缓解这种不公平性，我们提出了一个基于不同群体后验偏好的模型无关的自适应公平约束框架（SaFair）。我们构建了群体级别和个人级别的公平约束。前者衡量群体级别后验偏好与预测兴趣之间的一致性，而后者则依赖于用户与其所属群体之间兴趣一致性的程度来执行自适应约束。特别地，为了平衡有效性和公平性，我们利用不确定性估计根据模型的学习状态调整约束的强度，称为自适应约束。我们进行了广泛的离线实验和在线A/B测试，结果验证了我们提出的方法相对于基线的优越性。SaFair已成功部署在中国最受欢迎的短视频流媒体平台之一——快手，该平台拥有数亿活跃用户。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Self-Adaptive+Fairness+Constraint+Framework+for+Industrial+Recommender+System)|0|
|[GLaD: Synergizing Molecular Graphs and Language Descriptors for Enhanced Power Conversion Efficiency Prediction in Organic Photovoltaic Devices](https://doi.org/10.1145/3627673.3680103)|Thao Nguyen, Tiara TorresFlores, Changhyun Hwang, Carl Edwards, Ying Diao, Heng Ji|University of Illinois Urbana-Champaign Siebel School of Computing and Data Science; University of Illinois Urbana-Champaign Department of Chemical & Biomolecular Engineering|This paper presents a novel approach for predicting Power ConversionEfficiency (PCE) of Organic Photovoltaic (OPV) devices, called GLaD:synergizing molecular Graphs and Language Descriptors for enhanced PCEprediction. Due to the lack of high-quality experimental data, we collect adataset consisting of 500 pairs of OPV donor and acceptor molecules along withtheir corresponding PCE values, which we utilize as the training data for ourpredictive model. In this low-data regime, GLaD leverages properties learnedfrom large language models (LLMs) pretrained on extensive scientific literatureto enrich molecular structural representations, allowing for a multimodalrepresentation of molecules. GLaD achieves precise predictions of PCE, therebyfacilitating the synthesis of new OPV molecules with improved efficiency.Furthermore, GLaD showcases versatility, as it applies to a range of molecularproperty prediction tasks (BBBP, BACE, ClinTox, and SIDER), not limited tothose concerning OPV materials. Especially, GLaD proves valuable for tasks inlow-data regimes within the chemical space, as it enriches molecularrepresentations by incorporating molecular property descriptions learned fromlarge-scale pretraining. This capability is significant in real-worldscientific endeavors like drug and material discovery, where access tocomprehensive data is crucial for informed decision-making and efficientexploration of the chemical space.|本文提出了一种名为GLaD（结合分子图和语言描述符以增强功率转换效率预测）的新方法，用于预测有机光伏（OPV）器件的功率转换效率（PCE）。由于缺乏高质量的实验数据，我们收集了一个包含500对OPV供体和受体分子及其相应PCE值的数据集，并将其用作预测模型的训练数据。在这种数据量较少的情况下，GLaD利用从广泛科学文献预训练的大型语言模型（LLMs）中学习到的属性来丰富分子结构表示，从而实现分子的多模态表示。GLaD能够精确预测PCE，从而促进合成效率更高的新OPV分子。此外，GLaD展示了其多功能性，适用于一系列分子属性预测任务（BBBP、BACE、ClinTox和SIDER），不仅限于与OPV材料相关的任务。特别是在化学空间中的低数据任务中，GLaD通过整合从大规模预训练中学习到的分子属性描述来丰富分子表示，这被证明具有重要价值。这一能力在药物和材料发现等实际科学工作中至关重要，因为全面的数据对于明智的决策和化学空间的有效探索至关重要。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GLaD:+Synergizing+Molecular+Graphs+and+Language+Descriptors+for+Enhanced+Power+Conversion+Efficiency+Prediction+in+Organic+Photovoltaic+Devices)|0|
|[Cross-contextual Sequential Optimization via Deep Reinforcement Learning for Algorithmic Trading](https://doi.org/10.1145/3627673.3680101)|Kaiming Pan, Yifan Hu, Li Han, Haoyu Sun, Dawei Cheng, Yuqi Liang|Seek Data Group, Emoney Inc., Shanghai, China; Software Engineering Institute, East China Normal University, Shanghai, China; Department of Computer Science, Tongji University, Shanghai, China|High-frequency algorithmic trading has consistently attracted attention in both academic and industrial fields, which is formally modeled as a near real-time sequential decision problem. DRL methods are treated as a promising direction compared with the traditional approaches, as they have shown great potential in chasing maximum accumulative return. However, the financial data gathered from volatile market change rapidly, which makes it dramatically difficult to grasp crucial factors for effective decision-making. Existing works mainly focus on capturing temporal relations while ignoring deriving essential factors across features. Therefore, we propose a DRL-based cross-contextual sequential optimization (CCSO) method for algorithmic trading. In particular, we employ a convolution module in the first stage to derive latent factors via inter-sequence aggregation and apply a well-designed self-attention module in the second stage to capture market dynamics by aggregating temporal intra-sequence details. With the two-stage extractor as encoder and a RNN-based decision-maker as decoder, an Encoder-Decoder module is established as the policy network to conduct potent feature analysis and suggest action plans. Then, we design a dynamic programming based learning method to address the challenge of complex network updates in reinforcement learning, leading to considerable enhancement in learning stability and efficiency. To the best of our knowledge, this is the first work that solves the sequential optimization problem by joint representation of trading data across time and features in the DRL framework. Extensive experiments demonstrate the superior performance of our method compared to other state-of-the-art algorithmic trading approaches in various widely-used metrics.|高频算法交易在学术界和工业界持续受到关注，其正式模型被视为一种近实时序列决策问题。与传统方法相比，深度强化学习（DRL）方法被视为一个有前景的方向，因为它们在追求最大累积回报方面展现了巨大潜力。然而，从市场波动中收集的金融数据变化迅速，这使得捕捉有效决策的关键因素变得极其困难。现有研究主要集中在捕捉时间关系，而忽视了跨特征推导重要因素。因此，我们提出了一种基于DRL的跨上下文序列优化（CCSO）方法用于算法交易。具体而言，我们在第一阶段采用卷积模块通过序列间聚合推导潜在因素，并在第二阶段应用设计良好的自注意力模块通过聚合时间序列内细节来捕捉市场动态。通过将两阶段提取器作为编码器和基于RNN的决策者作为解码器，构建了一个编码器-解码器模块作为策略网络，以进行强大的特征分析并提出行动计划。随后，我们设计了一种基于动态规划的学习方法来应对强化学习中复杂网络更新的挑战，从而显著提升了学习稳定性和效率。据我们所知，这是首次在DRL框架中通过时间与特征的联合表示来解决序列优化问题的工作。广泛的实验证明，我们的方法在各种广泛使用的指标上优于其他最先进的算法交易方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cross-contextual+Sequential+Optimization+via+Deep+Reinforcement+Learning+for+Algorithmic+Trading)|0|
|[STIR: Siamese Transformer for Image Retrieval Postprocessing](https://doi.org/10.1145/3627673.3680075)|Aleksei Shabanov, Aleksei Tarasov, Sergey I. Nikolenko||Current metric learning approaches for image retrieval are usually based on learning a space of informative latent representations where simple approaches such as the cosine distance will work well. Recent state of the art methods such as HypViT move to more complex embedding spaces that may yield better results but are harder to scale to production environments. In this work, we first construct a simpler model based on triplet loss with hard negatives mining that performs at the state of the art level but does not have these drawbacks. Second, we introduce a novel approach for image retrieval postprocessing called Siamese Transformer for Image Retrieval (STIR) that reranks several top outputs in a single forward pass. Unlike previously proposed Reranking Transformers, STIR does not rely on global/local feature extraction and directly compares a query image and a retrieved candidate on pixel level with the usage of attention mechanism. The resulting approach defines a new state of the art on standard image retrieval datasets: Stanford Online Products and DeepFashion In-shop. We also release the source code at https://github.com/OML-Team/open-metric-learning/tree/main/pipelines/postprocessing/ and an interactive demo of our approach at https://dapladoc-oml-postprocessing-demo-srcappmain-pfh2g0.streamlit.app/|当前用于图像检索的度量学习方法通常基于学习一个信息丰富的潜在表示空间，其中简单的度量方法（如余弦距离）表现良好。最近的最先进方法，如HypViT，转向了更复杂的嵌入空间，可能带来更好的结果，但更难以扩展到生产环境中。在这项工作中，我们首先构建了一个基于三元组损失与难负样本挖掘的简单模型，该模型达到了最先进的性能水平，但没有这些缺点。其次，我们引入了一种名为Siamese Transformer for Image Retrieval（STIR）的图像检索后处理新方法，通过一次前向传播对多个顶部输出进行重新排序。与之前提出的重新排序变压器不同，STIR不依赖于全局/局部特征提取，而是直接在像素级别上使用注意力机制比较查询图像和检索到的候选图像。该方法在标准图像检索数据集上定义了新的最先进水平：Stanford Online Products和DeepFashion In-shop。我们还发布了源代码，链接为https://github.com/OML-Team/open-metric-learning/tree/main/pipelines/postprocessing/，并提供了一个交互式演示，链接为https://dapladoc-oml-postprocessing-demo-srcappmain-pfh2g0.streamlit.app/。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=STIR:+Siamese+Transformer+for+Image+Retrieval+Postprocessing)|0|
|[Enhancing Taobao Display Advertising with Multimodal Representations: Challenges, Approaches and Insights](https://doi.org/10.1145/3627673.3680068)|XiangRong Sheng, Feifan Yang, Litong Gong, Biao Wang, Zhangming Chan, Yujing Zhang, Yueyao Cheng, YongNan Zhu, Tiezheng Ge, Han Zhu, Yuning Jiang, Jian Xu, Bo Zheng||Despite the recognized potential of multimodal data to improve model accuracy, many large-scale industrial recommendation systems, including Taobao display advertising system, predominantly depend on sparse ID features in their models. In this work, we explore approaches to leverage multimodal data to enhance the recommendation accuracy. We start from identifying the key challenges in adopting multimodal data in a manner that is both effective and cost-efficient for industrial systems. To address these challenges, we introduce a two-phase framework, including: 1) the pre-training of multimodal representations to capture semantic similarity, and 2) the integration of these representations with existing ID-based models. Furthermore, we detail the architecture of our production system, which is designed to facilitate the deployment of multimodal representations. Since the integration of multimodal representations in mid-2023, we have observed significant performance improvements in Taobao display advertising system. We believe that the insights we have gathered will serve as a valuable resource for practitioners seeking to leverage multimodal data in their systems.|尽管多模态数据被认为具有提高模型准确性的潜力，但许多大规模工业推荐系统，包括淘宝展示广告系统，主要依赖于模型中的稀疏ID特征。在这项工作中，我们探索了利用多模态数据来增强推荐准确性的方法。我们从识别在工业系统中有效且成本高效地采用多模态数据的关键挑战开始。为了解决这些挑战，我们引入了一个两阶段框架，包括：1）多模态表示的预训练以捕捉语义相似性，以及2）将这些表示与现有的基于ID的模型进行整合。此外，我们详细介绍了我们的生产系统架构，该架构设计用于促进多模态表示的部署。自2023年年中多模态表示整合以来，我们在淘宝展示广告系统中观察到了显著的性能提升。我们相信，我们获得的这些见解将为寻求在其系统中利用多模态数据的从业者提供宝贵的资源。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Taobao+Display+Advertising+with+Multimodal+Representations:+Challenges,+Approaches+and+Insights)|0|
|[LLM-based Automated Web Retrieval and Text Classification of Food Sharing Initiatives](https://doi.org/10.1145/3627673.3680090)|Hao Wu, Hyunji Cho, Anna R. Davies, Gareth J. F. Jones|Geography, School of Natural Sciences, Trinity College Dublin, Dublin, Ireland; ADAPT Centre, School of Computing, Dublin City University, Dublin, Ireland|Urban and peri-urban (UPU) food systems encounter challenges in sustainability and are fragile and vulnerable to shocks. Addressing these issues is one of the key drivers of food sharing initiatives (FSIs) which focus on collective acts around food across the food system. FSIs range from seed sharing and surplus food redistribution to community composting. We describe our development and deployment of web retrieval and content classification tools designed to provide automated mapping of FSIs at scale to populate databases of FSIs within cities. We present our novel automated system tailored for retrieving, identifying, categorizing and real-time monitoring of FSIs in over 200 European cities. Developed within the European CULTIVATE project, this system not only aids in comprehending the complex dynamics of the food sharing economy, but also enhances its visibility and operational efficiency. The automation of these processes plays a vital role in supporting the goals of the CULTIVATE project, notably in promoting sustainable food practices and resilient local food networks. Our system integrates web search using queries constructed automatically using domain-specific vocabulary resources with Large Language Model (LLM) query writing and classification methods. Experimental results using a collection of data derived from real online FSI content underscore the potential of digital automation to make significant contributions to innovative digital solutions to contemporary sustainability challenges. As such, the findings of this work pave the way for future research and implementation in similar contexts.|城市和城郊（UPU）食品系统在可持续性方面面临挑战，且容易受到冲击的影响，表现出脆弱性。解决这些问题是食品共享倡议（FSIs）的关键驱动力之一，这些倡议侧重于整个食品系统中的集体食品行为。FSIs的范围从种子共享和剩余食品再分配到社区堆肥。我们描述了开发和部署的网络检索和内容分类工具，这些工具旨在大规模自动绘制FSIs地图，以填充城市内的FSIs数据库。我们展示了一种专为在200多个欧洲城市中检索、识别、分类和实时监控FSIs而设计的自动化系统。该系统是在欧洲CULTIVATE项目中开发的，不仅有助于理解食品共享经济的复杂动态，还增强了其可见性和运营效率。这些过程的自动化对支持CULTIVATE项目的目标起着至关重要的作用，特别是在促进可持续食品实践和弹性本地食品网络方面。我们的系统集成了利用领域特定词汇资源自动构建查询的网络搜索与大型语言模型（LLM）查询编写和分类方法。使用从真实在线FSI内容中提取的数据集进行的实验结果，突显了数字自动化对当代可持续性挑战创新数字解决方案的潜在贡献。因此，这项工作的发现为未来在类似情境中的研究和实施铺平了道路。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LLM-based+Automated+Web+Retrieval+and+Text+Classification+of+Food+Sharing+Initiatives)|0|
|[Breaking the Barrier: Utilizing Large Language Models for Industrial Recommendation Systems through an Inferential Knowledge Graph](https://doi.org/10.1145/3627673.3680022)|Qian Zhao, Hao Qian, Ziqi Liu, GongDuo Zhang, Lihong Gu|; Utilizing Large Language Models for Industrial Recom-mendation Systems through an Inferential Knowledge Graph; Ant Group Hangzhou|Recommendation systems are widely used in e-commerce websites and onlineplatforms to address information overload. However, existing systems primarilyrely on historical data and user feedback, making it difficult to capture userintent transitions. Recently, Knowledge Base (KB)-based models are proposed toincorporate expert knowledge, but it struggle to adapt to new items and theevolving e-commerce environment. To address these challenges, we propose anovel Large Language Model based Complementary Knowledge EnhancedRecommendation System (LLM-KERec). It introduces an entity extractor thatextracts unified concept terms from item and user information. To providecost-effective and reliable prior knowledge, entity pairs are generated basedon entity popularity and specific strategies. The large language modeldetermines complementary relationships in each entity pair, constructing acomplementary knowledge graph. Furthermore, a new complementary recall moduleand an Entity-Entity-Item (E-E-I) weight decision model refine the scoring ofthe ranking model using real complementary exposure-click samples. Extensiveexperiments conducted on three industry datasets demonstrate the significantperformance improvement of our model compared to existing approaches.Additionally, detailed analysis shows that LLM-KERec enhances users' enthusiasmfor consumption by recommending complementary items. In summary, LLM-KERecaddresses the limitations of traditional recommendation systems byincorporating complementary knowledge and utilizing a large language model tocapture user intent transitions, adapt to new items, and enhance recommendationefficiency in the evolving e-commerce landscape.|推荐系统在电子商务网站和在线平台上被广泛使用，以应对信息过载问题。然而，现有系统主要依赖历史数据和用户反馈，难以捕捉用户意图的转变。最近，基于知识库（KB）的模型被提出以整合专家知识，但它们难以适应新商品和不断变化的电子商务环境。为解决这些挑战，我们提出了一种新颖的大语言模型（LLM）增强的补充知识推荐系统（LLM-KERec）。该系统引入了一个实体提取器，从商品和用户信息中提取统一的概念术语。为了提供成本效益高且可靠的先验知识，实体对基于实体流行度和特定策略生成。大语言模型确定每个实体对中的补充关系，构建一个补充知识图。此外，一个新的补充召回模块和一个实体-实体-商品（E-E-I）权重决策模型使用真实的补充曝光-点击样本来优化排序模型的评分。在三个行业数据集上进行的大量实验表明，我们的模型相较于现有方法显著提升了性能。详细分析显示，LLM-KERec通过推荐补充商品增强了用户的消费热情。总之，LLM-KERec通过整合补充知识并利用大语言模型捕捉用户意图转变，适应新商品，并在不断变化的电子商务环境中提升推荐效率，从而解决了传统推荐系统的局限性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Breaking+the+Barrier:+Utilizing+Large+Language+Models+for+Industrial+Recommendation+Systems+through+an+Inferential+Knowledge+Graph)|0|
|[STaR: Space and Time-aware Statistic Query Answering](https://doi.org/10.1145/3627673.3679209)|Oana Balalau, Simon Ebel, Helena Galhardas, Théo Galizzi, Ioana Manolescu|Inria & Institut Polytechnique de Paris, Palaiseau, France; INESC-ID & IST, Universidade Lisboa, Lisbon, Portugal|High-quality data is essential for informed public debate. High-quality statistical data sources provide valuable reference information for verifying claims. To assist journalists and fact-checkers, user queries about specific claims should be automatically answered using statistical tables. However, the large number and variety of these sources make this task challenging. We propose to demonstrate STaR, a novel method for Space and Time-aware STatistic Retrieval, based on a user natural language query. STaR is deployed within our system StatCheck, which we developed and shared with fact-checking journalists. STaR improves the quality of statistic fact retrieval by treating space and time separately from the other parts of the statistics dataset. Specifically, we use them as dimensions of the data (and the query), and focus the linguistic part of our dataset search on the rich, varied language present in the data. Our demonstration uses statistic datasets from France, Europe, and a few beyond, allowing users to query and explore along space and time dimensions.|高质量的数据对于公众辩论至关重要。高质量的统计数据源为验证声明提供了宝贵的参考信息。为了协助记者和事实核查人员，应能够自动使用统计表格回答用户关于特定声明的查询。然而，这些来源的数量和多样性使得这项任务颇具挑战性。我们提出了STaR，一种基于用户自然语言查询的空间和时间感知统计检索新方法。STaR被部署在我们的系统StatCheck中，该系统是我们开发并与事实核查记者共享的。STaR通过将空间和时间与统计数据集的其他部分分开处理，提高了统计事实检索的质量。具体而言，我们将它们用作数据的维度（以及查询的维度），并将数据集中搜索的语言部分聚焦于数据中丰富多样的语言。我们的演示使用了来自法国、欧洲及其它几个地区的统计数据集，允许用户沿空间和时间维度进行查询和探索。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=STaR:+Space+and+Time-aware+Statistic+Query+Answering)|0|
|[FairRankTune: A Python Toolkit for Fair Ranking Tasks](https://doi.org/10.1145/3627673.3679238)|Kathleen Cachel, Elke A. Rundensteiner|Worcester Polytechnic Institute, Worcester, MA, USA|We present FairRankTune, a multi-purpose open-source Python toolkit offering three primary services: quantifying fairness-related harms, leveraging bias mitigation algorithms, and constructing custom fairness-relevant datasets. FairRankTune provides researchers and practitioners with a self-contained resource for fairness auditing, experimentation, and advancing research. The central piece of FairRankTune is a novel fairness-tunable ranked data generator, RankTune, that streamlines the creation of custom fairness-relevant ranked datasets. FairRankTune also offers numerous fair ranking metrics and fairness-aware ranking algorithms within the same plug-and-play package. We demonstrate the key innovations of FairRankTune, focusing on features that are valuable to stakeholders via use cases highlighting workflows in the end-to-end process of mitigating bias in ranking systems. FairRankTune addresses the gap of limited publicly available datasets, auditing tools, and implementations for fair ranking.|我们介绍了FairRankTune，这是一个多用途的开源Python工具包，提供三项主要服务：量化与公平性相关的损害、运用偏差缓解算法以及构建自定义的与公平性相关的数据集。FairRankTune为研究人员和实践者提供了一个自包含的资源，用于公平性审计、实验和推动研究进展。该工具包的核心是一个新颖的可调公平性的排名数据生成器RankTune，它简化了自定义公平相关排名数据集的创建过程。FairRankTune还在同一即插即用包中提供了众多公平排名指标和公平意识排名算法。我们展示了FairRankTune的关键创新，重点介绍了通过端到端流程中的用例突出显示的工作流，这些工作流对利益相关者具有重要价值，特别是在缓解排名系统中的偏差方面。FairRankTune解决了公开可用数据集、审计工具和公平排名实现有限的缺口问题。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FairRankTune:+A+Python+Toolkit+for+Fair+Ranking+Tasks)|0|
|[LLM-PQA: LLM-enhanced Prediction Query Answering](https://doi.org/10.1145/3627673.3679210)|Ziyu Li, Wenjie Zhao, Asterios Katsifodimos, Rihan Hai||The advent of Large Language Models (LLMs) provides an opportunity to change the way queries are processed, moving beyond the constraints of conventional SQL-based database systems. However, using an LLM to answer a prediction query is still challenging, since an external ML model has to be employed and inference has to be performed in order to provide an answer. This paper introduces LLM-PQA, a novel tool that addresses prediction queries formulated in natural language. LLM-PQA is the first to combine the capabilities of LLMs and retrieval-augmented mechanism for the needs of prediction queries by integrating data lakes and model zoos. This integration provides users with access to a vast spectrum of heterogeneous data and diverse ML models, facilitating dynamic prediction query answering. In addition, LLM-PQA can dynamically train models on demand, based on specific query requirements, ensuring reliable and relevant results even when no pre-trained model in a model zoo, available for the task.|大规模语言模型（LLMs）的出现为我们提供了一个改变查询处理方式的契机，使其超越了传统基于SQL的数据库系统的限制。然而，使用LLM来回答预测性查询仍然具有挑战性，因为需要借助外部机器学习模型并进行推理才能提供答案。本文介绍了LLM-PQA，这是一种新颖的工具，专门用于处理以自然语言表达的预测性查询。LLM-PQA首次将LLM的能力与检索增强机制相结合，以满足预测查询的需求，通过整合数据湖和模型库来实现这一目标。这种整合使用户能够访问广泛且异构的数据集以及多样化的机器学习模型，从而促进动态预测查询的解答。此外，LLM-PQA能够根据特定查询需求动态训练模型，即使在模型库中没有适用于该任务的预训练模型时，也能确保结果的可靠性和相关性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LLM-PQA:+LLM-enhanced+Prediction+Query+Answering)|0|
|[Unified Argument Retrieval System from German News Articles Using Large Language Models](https://doi.org/10.1145/3627673.3679232)|Piriyakorn Piriyatamwong, Saikishore Kalloori, Fabio Zünd|ETH Zürich, Zürich, Switzerland|The rapid growth in the number of news articles published daily can create challenges for users to explore specific topics and gather different perspectives around the topics to make neutral and unbiased conclusions. The system's ability to intelligently cluster news articles from multiple sources and retrieve concise (pro/con) relevant arguments is necessary for users' well-informed decision-making. In this paper, we introduce our unified argument retrieval system that uses our clustering model to cluster news articles and subsequently extracts the core arguments from news articles using the argument prediction model. We conducted a user study to understand the system's usability and users' satisfaction with the quality of clusters and arguments extracted.|随着每日发布的新闻文章数量迅速增长，用户在探索特定话题并收集不同观点以做出中立和无偏见的结论方面面临挑战。系统能够智能地从多个来源聚类新闻文章并检索简明的（支持/反对）相关论点，这对于用户做出明智决策是必要的。在本文中，我们介绍了一个统一的论点检索系统，该系统使用我们的聚类模型对新闻文章进行聚类，并随后使用论点预测模型从新闻文章中提取核心论点。我们进行了一项用户研究，以了解系统的可用性以及用户对聚类和提取论点质量的满意度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unified+Argument+Retrieval+System+from+German+News+Articles+Using+Large+Language+Models)|0|
|[Empowering Shoppers with Event-focused Search](https://doi.org/10.1145/3627673.3679235)|Austin R. Ward, Omar Alonso|Amazon, Palo Alto, CA, USA; Amazon, Seattle, WA, USA|We present Event-focused Search, an automated and scalable pipeline designed to facilitate event discovery and enhance event-based search. This is done by leveraging large language models (LLMs) to populate event datasets, perform temporal search based on selected dates, and aggregate search results based on appropriate events based on those searches. We illustrate this pipeline through proof-of-concept interfaces in an e-commerce context, though such a framework is applicable to different types of search scenarios (e.g., sports, entertainment).|我们提出了事件聚焦搜索（Event-focused Search），这是一个自动化且可扩展的流程，旨在促进事件发现并增强基于事件的搜索。通过利用大型语言模型（LLMs）来填充事件数据集，基于选定日期执行时间搜索，并根据这些搜索结果聚合相关事件的搜索结果，我们实现了这一目标。我们通过在电子商务环境中展示概念验证界面来说明这一流程，尽管该框架同样适用于不同类型搜索场景（例如，体育、娱乐）。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Empowering+Shoppers+with+Event-focused+Search)|0|
|[Multi-turn Classroom Dialogue Dataset: Assessing Student Performance from One-on-one Conversations](https://doi.org/10.1145/3627673.3679108)|Jiahao Chen, Zitao Liu, Mingliang Hou, Xiangyu Zhao, Weiqi Luo|Guangdong Institute of Smart Education, Jinan University, Guangzhou, China; School of Data Science, City University of Hong Kong, Hong Kong, China; TAL Education Group, Beijing, China|Accurately judging student on-going performance is crucial for adaptive teaching. In this work, we focus on the task of automatically predicting students' levels of mastery of math questions from teacher-student classroom dialogue data in online one-on-one classes. As a step toward this direction, we introduce the Multi-turn Classroom Dialogue (MCD) dataset as a benchmark testing the capabilities of machine learning models in classroom conversation understanding of student performance judgment. Our dataset contains aligned multi-turn spoken language of 5000+ unique samples of solving grade-8 math questions collected from 500+ hours' worth of online one-on-one tutoring classes. In our experiments, we assess various state-of-the-art models on the MCD dataset, highlighting the importance of understanding multi-turn dialogues and handling noisy ASR transcriptions. Our findings demonstrate the dataset's utility in advancing research on automated student performance assessment. To encourage reproducible research, we make our data publicly available at https://github.com/ai4ed/MCD.|准确判断学生的实时表现对于适应性教学至关重要。本研究聚焦于从在线一对一课堂中的师生对话数据中自动预测学生对数学问题的掌握程度。为此，我们引入了多轮课堂对话（Multi-turn Classroom Dialogue, MCD）数据集，作为评估机器学习模型在课堂对话理解与学生表现判断能力方面的基准。该数据集包含了5000多个独特样本的多轮口语对话，这些样本来自500多小时的在线一对一辅导课程，内容涉及八年级数学问题的解答。在实验中，我们评估了多种最先进的模型在MCD数据集上的表现，强调了理解多轮对话和处理噪声ASR（自动语音识别）转录文本的重要性。研究结果表明，该数据集在推动自动化学生表现评估研究方面具有重要价值。为促进可重复研究，我们公开了数据集，访问地址为：https://github.com/ai4ed/MCD。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-turn+Classroom+Dialogue+Dataset:+Assessing+Student+Performance+from+One-on-one+Conversations)|0|
|[An Evaluation Framework for Attributed Information Retrieval using Large Language Models](https://doi.org/10.1145/3627673.3679172)|Hanane Djeddal, Pierre Erbacher, Raouf Toukal, Laure Soulier, Karen PinelSauvagnat, Sophia Katrenko, Lynda Tamine||With the growing success of Large Language models (LLMs) in information-seeking scenarios, search engines are now adopting generative approaches to provide answers along with in-line citations as attribution. While existing work focuses mainly on attributed question answering, in this paper, we target information-seeking scenarios which are often more challenging due to the open-ended nature of the queries and the size of the label space in terms of the diversity of candidate-attributed answers per query. We propose a reproducible framework to evaluate and benchmark attributed information seeking, using any backbone LLM, and different architectural designs: (1) Generate (2) Retrieve then Generate, and (3) Generate then Retrieve. Experiments using HAGRID, an attributed information-seeking dataset, show the impact of different scenarios on both the correctness and attributability of answers.|随着大型语言模型（LLMs）在信息检索场景中的应用日益成功，搜索引擎正采用生成式方法来提供带有内联引用作为归属的答案。尽管现有研究主要集中在归属问答上，本文则针对更具挑战性的信息检索场景，这类场景由于查询的开放性及每个查询对应的候选归属答案多样性导致的标签空间庞大而显得尤为复杂。我们提出了一种可复现的框架，用于评估和基准测试归属信息检索，使用任何骨干LLM，并结合不同的架构设计：（1）生成式（2）检索后生成，以及（3）生成后检索。通过使用HAGRID这一归属信息检索数据集进行的实验，展示了不同场景对答案正确性和归属性的影响。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Evaluation+Framework+for+Attributed+Information+Retrieval+using+Large+Language+Models)|0|
|[AnnoRank: A Comprehensive Web-Based Framework for Collecting Annotations and Assessing Rankings](https://doi.org/10.1145/3627673.3679174)|Clara Rus, Gabrielle Poerwawinata, Andrew Yates, Maarten de Rijke|University of Amsterdam, Amsterdam, Netherlands|We present AnnoRank, a web-based user interface (UI) framework designed to facilitate collecting crowdsource annotations in the context of information retrieval. AnnoRank enables the collection of explicit and implicit annotations for a specified query and a single or multiple documents, allowing for the observation of user-selected items and the assignment of relevance judgments. Furthermore, AnnoRank allows for ranking comparisons, allowing for the visualization and evaluation of a ranked list generated by different fairness interventions, along with its utility and fairness metrics. Fairness interventions in the annotation pipeline are necessary to prevent the propagation of bias when a user selects the top-k items in a ranked list. With the widespread use of ranking systems, the application supports multimodality through text and image document formats. We also support the assessment of agreement between annotators to ensure the quality of the annotations. AnnoRank is integrated with the Ranklib library, offering a vast range of ranking models that can be applied to the data and displayed in the UI. AnnoRank is designed to be flexible, configurable, and easy to deploy to meet diverse annotation needs in information retrieval. AnnoRank is publicly available as open-source software, together with detailed documentation at https://github.com/ClaraRus/AnnoRank.|我们提出了AnnoRank，这是一个基于网络的用户界面（UI）框架，旨在促进在信息检索背景下收集众包标注。AnnoRank能够收集针对指定查询和一个或多个文档的显式和隐式标注，使用户能够观察到用户选择的项目并进行相关性判断。此外，AnnoRank支持排序比较，允许可视化和评估由不同公平性干预措施生成的排序列表，以及其效用和公平性指标。在标注流程中实施公平性干预是必要的，以防止用户在选择排序列表中的前k个项目时偏差的传播。随着排序系统的广泛应用，该系统通过文本和图像文档格式支持多模态。我们还支持评估标注者之间的一致性，以确保标注的质量。AnnoRank与Ranklib库集成，提供了一系列广泛的排序模型，这些模型可以应用于数据并在UI中展示。AnnoRank设计灵活、可配置，并且易于部署，以满足信息检索中多样化的标注需求。AnnoRank作为开源软件公开发布，详细文档可在https://github.com/ClaraRus/AnnoRank获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AnnoRank:+A+Comprehensive+Web-Based+Framework+for+Collecting+Annotations+and+Assessing+Rankings)|0|
|[Advancing Misinformation Awareness in Recommender Systems for Social Media Information Integrity](https://doi.org/10.1145/3627673.3680259)|Royal Pathak|Boise State University, Boise, ID, USA|Recommender systems play an essential role in determining the content users encounter on social media platforms and in uncovering relevant news. However, they also present significant risks, such as reinforcing biases, over-personalizing content, fostering filter bubbles, and inadvertently promoting misinformation. The spread of false information is rampant across various online platforms, such as Twitter (now X), Meta, and TikTok, especially noticeable during events like the COVID-19 pandemic and the US Presidential elections. These instances underscore the critical necessity for transparency and regulatory oversight in the development of recommender systems. Given the challenge of balancing free speech with the risks of outright removal of fake news, this paper aims to address the spread of misinformation from algorithmic biases in recommender systems using a social science perspective.|推荐系统在决定用户在社交媒体平台上接触的内容以及揭示相关新闻方面发挥着至关重要的作用。然而，它们也带来了重大风险，例如强化偏见、过度个性化内容、助长信息茧房以及无意中推广虚假信息。虚假信息的传播在各种在线平台上十分猖獗，如Twitter（现为X）、Meta和TikTok，尤其在COVID-19疫情和美国大选等事件期间更为明显。这些情况凸显了在推荐系统开发中透明度和监管监督的迫切需要。鉴于在平衡言论自由与彻底删除虚假新闻的风险方面的挑战，本文旨在从社会科学的角度探讨推荐系统中的算法偏差如何导致虚假信息的传播。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Advancing+Misinformation+Awareness+in+Recommender+Systems+for+Social+Media+Information+Integrity)|0|
|[Multi-Granularity Modeling in Recommendation: from the Multi-Scenario Perspective](https://doi.org/10.1145/3627673.3680264)|Yuhao Wang|City University of Hong Kong, Hong Kong, Hong Kong|In today's digital landscape, Deep Recommender Systems (DRS) play a crucial role in navigating and customizing online content for individual preferences. However, conventional methods, which mainly depend on single recommendation task, scenario, data modality and user behavior, are increasingly seen as insufficient due to their inability to accurately reflect users' complex and changing preferences. This gap underscores the need for multi-granularity modeling, which are central to overcoming these limitations by integrating diverse tasks, scenarios, modalities, and behaviors in the recommendation process, thus promising significant enhancements in recommendation precision, efficiency, and customization. In this paper, from the multi-scenario perspective, we illustrate our existing explorations and present results. Ultimately, we wish to highlight our multi-granularity approach sheds light on building the next generation of recommender system1 .|在当今的数字环境中，深度推荐系统（DRS）在根据个人偏好导航和定制在线内容方面发挥着关键作用。然而，传统方法主要依赖于单一推荐任务、场景、数据模态和用户行为，由于无法准确反映用户复杂且多变的偏好，这些方法的局限性日益凸显。这一差距突显了多粒度建模的必要性，该方法通过在推荐过程中整合多种任务、场景、模态和行为，有望显著提升推荐的准确性、效率和个性化水平。本文从多场景的角度，展示了我们现有的探索成果，并介绍了相关结果。最终，我们希望强调我们的多粒度方法为构建下一代推荐系统提供了重要启示。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Granularity+Modeling+in+Recommendation:+from+the+Multi-Scenario+Perspective)|0|
|[Unifying Spectral and Spatial Graph Neural Networks](https://doi.org/10.1145/3627673.3679088)|Zhiqian Chen, Lei Zhang, Liang Zhao|Mississippi State University, Starkville, MS, USA; Northern Illinois University, Dekalb, IL, USA; Emory University, Atlanta, GA, USA|In recent years, Graph Neural Networks (GNNs) have attracted considerable attention. However, the rapid emergence of diverse GNN models, each grounded in different theoretical foundations, complicates the model selection process, as these models are not easily understood within a unified framework. Initial GNNs were constructed using spectral theory, while others were developed based on spatial theory. This theoretical divergence makes direct comparisons difficult. Furthermore, the variety of models within each theoretical domain further complicates their evaluation. In this tutorial, we explore state-of-the-art GNNs and present a comprehensive framework that bridges the spatial and spectral domains, clarifying their interrelationship. This framework deepens our understanding of GNN operations. The tutorial delves into key paradigms, such as spatial and spectral methods, through a synthesis of spectral graph theory and approximation theory. We conduct an in-depth analysis of recent research advancements, addressing emerging issues like over-smoothing, using well-established GNN models to illustrate the universality of our framework.|近年来，图神经网络（GNNs）引起了广泛关注。然而，由于不同理论基础支撑的多样化GNN模型的快速涌现，模型选择过程变得复杂，因为这些模型难以在一个统一的框架内被理解。最初的GNN模型是基于谱理论构建的，而其他模型则基于空间理论发展。这种理论上的分歧使得直接比较变得困难。此外，每个理论领域内模型的多样性进一步增加了评估的复杂性。在本教程中，我们探讨了最先进的GNN，并提出了一个综合框架，该框架连接了空间和谱域，阐明了它们之间的相互关系。这一框架加深了我们对GNN操作的理解。教程深入探讨了关键范式，如空间和谱方法，通过结合谱图理论和近似理论的合成来进行分析。我们对最近的研究进展进行了深入分析，并使用成熟的GNN模型来解决新兴问题，如过平滑问题，以说明我们框架的普遍性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unifying+Spectral+and+Spatial+Graph+Neural+Networks)|0|
|[Tutorial on Landing Generative AI in Industrial Social and E-commerce Recsys](https://doi.org/10.1145/3627673.3679099)|Da Xu, Danqing Zhang, Lingling Zheng, Bo Yang, Guangyu Yang, Shuyuan Xu, Cindy Liang|Microsoft, Redmond, Washington, USA; TikTok, San Jose, California, USA; LinkedIn, Sunnyvale, California, USA; TikTok, Santa Clara, California, USA; Amazon, Palo Alto, California, USA|Over the past two years, GAI has evolved rapidly, influencing various fields including social and e-commerce Recsys. Despite exciting advances, landing these innovations in real-world Recsys remains challenging due to the sophistication of modern industrial product and systems. Our tutorial begins with a brief overview of building industrial Recsys and GAI fundamentals, followed by the ongoing efforts and opportunities to enhance personalized recommendations with foundation models. We then explore the integration of curation capabilities into Recsys, such as repurposing raw content, incorporating external knowledge, and generating personalized insights/explanations to foster transparency and trust. Next, the tutorial illustrates how AI agents can transform Recsys through interactive reasoning and action loops, shifting away from traditional passive feedback models. Finally, we shed insights on real-world solutions for human-AI alignment and responsible GAI practices. A critical component of the tutorial is detailing the AI, Infrastructure, LLMOps, and Product roadmap (including the evaluation and responsible AI practices) derived from the production solutions in LinkedIn, Amazon, TikTok, and Microsoft. While GAI in Recsys is still in its early stages, this tutorial provides valuable insights and practical solutions for the Recsys and GAI communities.|在过去两年中，生成式人工智能（GAI）迅速发展，影响了包括社交和电子商务推荐系统（Recsys）在内的多个领域。尽管取得了令人振奋的进展，但将这些创新应用于实际的推荐系统仍然面临挑战，这主要是由于现代工业产品和系统的复杂性。我们的教程首先简要概述了构建工业级推荐系统的基础知识以及生成式人工智能的基本原理，随后探讨了利用基础模型提升个性化推荐的努力和机遇。接着，我们探讨了如何将内容策划能力整合到推荐系统中，例如重新利用原始内容、整合外部知识，以及生成个性化的见解和解释，以促进透明度和用户信任。然后，教程展示了人工智能代理如何通过交互式推理和行动循环来转变推荐系统，从而摆脱传统的被动反馈模式。最后，我们分享了关于人机协作和负责任的生成式人工智能实践的实际解决方案。教程的一个重要部分是详细介绍了从LinkedIn、Amazon、TikTok和Microsoft的生产解决方案中提炼出的AI、基础设施、LLMOps和产品路线图（包括评估和负责任的AI实践）。尽管生成式人工智能在推荐系统中的应用仍处于早期阶段，但本教程为推荐系统和生成式人工智能社区提供了宝贵的见解和实用的解决方案。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tutorial+on+Landing+Generative+AI+in+Industrial+Social+and+E-commerce+Recsys)|0|
|[Reviewerly: Modeling the Reviewer Assignment Task as an Information Retrieval Problem](https://doi.org/10.1145/3627673.3679081)|Negar Arabzadeh, Sajad Ebrahimi, Sara Salamat, Mahdi Bashari, Ebrahim Bagheri|Reviewerly, Toronto, ON, Canada; Reviewerly, Guelph, ON, Canada|The peer review process is a fundamental aspect of academic publishing, ensuring the quality and credibility of scholarly work. In this talk, we will explore the critical challenges associated specifically with the assignment of reviewers to submitted papers. We will introduce Reviewerly, our innovative solution designed to enhance the efficiency and effectiveness of reviewer assignments by leveraging data from diverse sources, including OpenAlex, PubMed, and DBLP. By modeling the reviewer assignment problem as an information retrieval task, we focus on retrieving a pool of relevant and diverse reviewers for each paper.|同行评审过程是学术出版的一个基本环节，确保学术工作的质量和可信度。在本次演讲中，我们将探讨与提交论文的审稿人分配相关的关键挑战。我们将介绍Reviewerly，这是我们的一项创新解决方案，旨在通过利用来自OpenAlex、PubMed和DBLP等多种来源的数据，提高审稿人分配的效率和效果。通过将审稿人分配问题建模为信息检索任务，我们专注于为每篇论文检索一组相关且多样化的审稿人。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reviewerly:+Modeling+the+Reviewer+Assignment+Task+as+an+Information+Retrieval+Problem)|0|
|[AI-safe Autocompletion with RAG and Relevance Curation](https://doi.org/10.1145/3627673.3679078)|Kilian Merkelbach, Ksenia Riabinova, Arnab Dutta|eBay Inc., Aachen, Germany; eBay Inc., Dreilinden, Germany|In search, autocomplete (AC) is an essential tool that provides suggestions for each keystroke, functioning well with token-based queries. However, it is challenging to handle at scale when input queries are conversational and semantically rich. Identifying relevant queries for sub-tokens requires efficient lookup strategies, real-time ranking, and relevance in the results. This work integrates Retrieval-Augmented Generation (RAG), AI safety, and relevance ranking to produce autocomplete suggestions for conversational queries in a production system. RAG-based responses ensure a high hit ratio for popular AC inputs and maintain a very low risk category by not triggering any critical AI safety concerns.|在搜索领域，自动补全（Autocomplete，简称AC）是一项关键工具，它能够针对每个按键提供建议，与基于词汇的查询配合良好。然而，当输入的查询是会话式的且语义丰富时，大规模处理这些查询变得极具挑战性。为子词汇识别相关查询需要高效的查找策略、实时排序以及结果的相关性。本研究将检索增强生成（Retrieval-Augmented Generation，简称RAG）、人工智能安全性和相关性排序相结合，以在生产系统中为会话式查询生成自动补全建议。基于RAG的响应确保了对常见AC输入的高命中比率，并通过不触发任何关键的人工智能安全问题，保持了极低的风险类别。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AI-safe+Autocompletion+with+RAG+and+Relevance+Curation)|0|
|[Towards Real-Time and Personalized Code Generation](https://doi.org/10.1145/3627673.3679071)|Han Xu, Xingyuan Wang, Haipeng Chen|University of Illinois Urbana-Champaign, Urbana, IL, USA; William & Mary, Williamsburg, VA, USA; Meta Platforms Inc., Seattle, WA, USA|Large language models (LLMs) have transformed automated code generation. However, their high computational demands often lead to server overload and increased latency in SaaS deployments. To address this, we present SpeCoder, a framework that accelerates server-side code generation using speculative sampling (SpS) and supervised fine-tuning (SFT). SpS allows lower latency in the code generation, whereas SFT enables more personalized code generation tailored to the user's needs.|大型语言模型（LLMs）已经彻底改变了自动化代码生成的领域。然而，其高计算需求常常导致服务器过载，并在软件即服务（SaaS）部署中增加了延迟。为此，我们提出了SpeCoder框架，该框架通过使用推测采样（SpS）和监督微调（SFT）来加速服务器端代码生成。SpS降低了代码生成的延迟，而SFT则使代码生成更加个性化，以满足用户的特定需求。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Real-Time+and+Personalized+Code+Generation)|0|
|[Advertiser Content Understanding via LLMs for Google Ads Safety](https://doi.org/10.1145/3627673.3679077)|Joseph Wallace, Tushar Dogra, Wei Qiao, Yuan Wang||Ads Content Safety at Google requires classifying billions of ads for Google Ads content policies. Consistent and accurate policy enforcement is important for advertiser experience and user safety and it is a challenging problem, so there is a lot of value for improving it for advertisers and users. Inconsistent policy enforcement causes increased policy friction and poor experience with good advertisers, and bad advertisers exploit the inconsistency by creating multiple similar ads in the hope that some will get through our defenses. This study proposes a method to understand advertiser's intent for content policy violations, using Large Language Models (LLMs). We focus on identifying good advertisers to reduce content over-flagging and improve advertiser experience, though the approach can easily be extended to classify bad advertisers too. We generate advertiser's content profile based on multiple signals from their ads, domains, targeting info, etc. We then use LLMs to classify the advertiser content profile, along with relying on any knowledge the LLM has of the advertiser, their products or brand, to understand whether they are likely to violate a certain policy or not. After minimal prompt tuning our method was able to reach 95% accuracy on a small test set.|谷歌的广告内容安全工作要求对数十亿条广告进行分类，以符合谷歌广告的内容政策。一致且准确的政策执行对于广告主体验和用户安全至关重要，这也是一个具有挑战性的问题，因此改进这一工作对广告主和用户都有很大价值。政策执行的不一致会导致政策摩擦增加，并对遵守规则的广告主带来不良体验，而违规广告主则利用这种不一致性，通过创建多个相似广告，寄希望于其中部分广告能够绕过我们的防御机制。本研究提出了一种利用大型语言模型（LLMs）来理解广告主内容政策违规意图的方法。我们专注于识别遵守规则的广告主，以减少内容过度标记并提升广告主体验，尽管该方法同样可以轻松扩展用于分类违规广告主。我们基于广告主的广告、域名、定向信息等多个信号生成其内容画像，然后利用LLMs对广告主内容画像进行分类，并结合LLMs对广告主、其产品或品牌的已有知识，判断其是否可能违反特定政策。在经过最小化的提示调优后，我们的方法在小型测试集上达到了95%的准确率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Advertiser+Content+Understanding+via+LLMs+for+Google+Ads+Safety)|0|
|[Generative AI and Retrieval-Augmented Generation (RAG) Systems for Enterprise](https://doi.org/10.1145/3627673.3680117)|Anbang Xu, Tan Yu, Min Du, Pritam Gundecha, Yufan Guo, Xinliang Zhu, May Wang, Ping Li, Xinyun Chen|Amazon, Seattle, Washington, USA; NVIDIA, Santa Clara, California, USA; Google Brain, Mountain View, California, USA; Palo Alto Networks, Santa Clara, California, USA; Amazon, Palo Alto, Washington, USA; VECML, Seattle, Washington, USA|This workshop introduces generative AI applications for enterprise, with a focus on retrieval-augmented generation (RAG) systems. Generative AI is a field of artificial intelligence that can create new content and solve complex problems. RAG systems are a novel generative AI technique that combines information retrieval with text generation to generate rich and diverse responses. RAG systems can leverage enterprise data, which is often specific, structured, and dynamic, to provide customized solutions for various domains. However, enterprise data also poses challenges such as scalability, security, and data quality. This workshop convenes researchers and practitioners to explore RAG and other generative AI systems in real-world enterprise scenarios, fostering knowledge exchange, collaboration, and identification of future directions. Relevant to the CIKM community, the workshop intersects with core areas of data science and machine learning, offering potential benefits across various domains.|本次研讨会介绍了生成式AI在企业中的应用，重点聚焦于检索增强生成（Retrieval-Augmented Generation，RAG）系统。生成式AI是人工智能领域的一个分支，能够创建新内容并解决复杂问题。RAG系统是一种新颖的生成式AI技术，它将信息检索与文本生成相结合，以生成丰富多样的响应。RAG系统能够利用企业数据，这些数据通常具有特定性、结构性和动态性，从而为各个领域提供定制化的解决方案。然而，企业数据也带来了诸如可扩展性、安全性和数据质量等方面的挑战。本次研讨会汇聚了研究人员和实践者，共同探讨RAG及其他生成式AI系统在实际企业场景中的应用，促进知识交流、合作以及未来发展方向的识别。研讨会与CIKM社区相关，涉及数据科学和机器学习的核心领域，为多个领域带来了潜在的益处。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generative+AI+and+Retrieval-Augmented+Generation+(RAG)+Systems+for+Enterprise)|0|
|[A Bayesian Multi-Armed Bandit Algorithm for Bid Shading in Online Display Advertising](https://doi.org/10.1145/3627673.3680107)|Mengzhuo Guo, Wuqi Zhang, Congde Yuan, Binfeng Jia, Guoqing Song, Hua Hua, Shuangyang Wang, Qingpeng Zhang|Sichuan University, Chengdu, Sichuan, China; The University of Hong Kong, Hong Kong, Hong Kong; Tencent, Shenzhen, Guangdong, China|In real-time bidding systems, ad exchanges and supply-side platforms (SSP) are switching from the second-price auction (SPA) to the first-price auction (FPA), where the advertisers should pay what they bid if they win the auction. To avoid overpaying, advertisers are motivated to conceal their truthful evaluations of impression opportunities through bid shading methods. However, advertisers are consistently facing a trade-off between the probability and cost-saving of winning, due to the information asymmetry, where advertisers lack knowledge about their competitors' bids in the market. To address this challenge, we propose a Bayes ian Multi-Armed Bandit (BayesMAB) algorithm for bid shading when the winning price is unknown to advertisers who lose the impression opportunity. BayesMAB incorporates the mechanism of FPA to infer each price interval's winning rate by progressively updating the market price hidden by SSP. In this way, BayesMAB better approximates the winning rates of price intervals and thus is able to derive the optimal shaded bid that balances the trade-off between the probability and cost-saving of winning the impression opportunity. We conducted large-scale A/B tests on Tencent's online display advertising platform. The cost-per-mile (CPM) and cost-per-action (CPA) decreased by 13.06% and 11.90%, respectively, whereas the return on investment (ROI) increased by 12.31% with only 2.7% sacrifice of the winning rate. We also validated BayesMAB's superior performance in an offline semi-simulated experiment with SPA data sets. BayesMAB has been deployed online and is impacting billions of traffic every day. Codes are available at https://github.com/BayesMAB/BayesMAB.|在实时竞价系统中，广告交易平台和供应方平台（SSP）正从第二价格拍卖（SPA）转向第一价格拍卖（FPA），在这种拍卖中，广告主如果赢得竞价，则需支付其出价金额。为了避免支付过高，广告主倾向于通过出价遮蔽（bid shading）方法隐藏其对展示机会的真实评估。然而，由于信息不对称——广告主缺乏对市场上竞争对手出价的了解——他们始终面临着一个在赢得竞价概率与成本节约之间的权衡。为应对这一挑战，我们提出了一种贝叶斯多臂赌博机（BayesMAB）算法，用于在广告主未能赢得展示机会且无法知晓获胜价格时进行出价遮蔽。BayesMAB结合了FPA机制，通过逐步更新SSP隐藏的市场价格来推断每个价格区间的获胜率。通过这种方式，BayesMAB能够更好地逼近价格区间的获胜率，从而得出能够平衡赢得展示机会概率与成本节约之间权衡的最优遮蔽出价。我们在腾讯的在线展示广告平台上进行了大规模A/B测试。结果显示，每千次展示成本（CPM）和每次行动成本（CPA）分别下降了13.06%和11.90%，而投资回报率（ROI）提升了12.31%，同时仅牺牲了2.7%的获胜率。我们还在基于SPA数据集的线下半模拟实验中验证了BayesMAB的优越性能。BayesMAB已在线部署，每天影响数十亿流量。代码可在https://github.com/BayesMAB/BayesMAB获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Bayesian+Multi-Armed+Bandit+Algorithm+for+Bid+Shading+in+Online+Display+Advertising)|0|
|[SGFL-Attack: A Similarity-Guidance Strategy for Hard-Label Textual Adversarial Attack Based on Feedback Learning](https://doi.org/10.1145/3627673.3679639)|Panjia Qiu, Guanghao Zhou, Mingyuan Fan, Cen Chen, Yaliang Li, Wenming Zhou|East China Normal University, ShangHai, China; Alibaba Group, Hangzhou, China; East China Normal University, Shanghai, China|Hard-label black-box textual adversarial attack presents a challenging task where only the predictions of the victim model are available. Moreover, several constraints further complicate the task of launching such attacks, including the inherent discrete and non-differentiable nature of text data and the need to introduce subtle perturbations that remain imperceptible to humans while preserving semantic similarity. Despite the considerable research efforts dedicated to this problem, existing methods still suffer from several limitations. For example, algorithms based on complex heuristic searches necessitate extensive querying, rendering them computationally expensive. The introduction of continuous gradient strategies into discrete text spaces often leads to estimation errors. Meanwhile, geometry-based strategies are prone to falling into local optima. To address these limitations, in this paper, we introduce SGFL-Attack, a novel approach that leverages a Similarity-Guidance strategy based on Feedback Learning for hard-label textual adversarial attack, with limited query budget. Specifically, the proposed SGFL-Attack utilizes word embedding vectors to assess the importance of words and positions in text sequences, and employs a feedback learning mechanism to determine reward or punishment based on changes in predicted labels caused by replacing words. In each iteration, SGFL-Attack guides the search based on knowledge acquired from the feedback learning mechanism, generating more similar samples while maintaining low perturbations. Moreover, to reduce the query budget, we incorporate local hash mapping to avoid redundant queries during the search process. Extensive experiments on seven widely used datasets show that the proposed SGFL-Attack method significantly outperforms state-of-the-art baselines and defenses over multiple language models.|硬标签黑箱文本对抗攻击是一项具有挑战性的任务，其中仅能获取受害模型的预测结果。此外，多种约束条件进一步增加了实施此类攻击的难度，包括文本数据固有的离散性和不可微性，以及需要在保持语义相似性的同时引入细微扰动且不被人察觉。尽管针对这一问题已有大量研究工作，现有方法仍存在诸多局限性。例如，基于复杂启发式搜索的算法需要大量查询，导致计算成本高昂；将连续梯度策略引入离散文本空间往往导致估计误差；而基于几何的策略则容易陷入局部最优。为解决这些局限性，本文提出了SGFL-Attack，这是一种基于反馈学习的相似性引导策略的新型硬标签文本对抗攻击方法，旨在有限的查询预算下实现攻击。具体而言，所提出的SGFL-Attack方法利用词嵌入向量评估文本序列中词语及其位置的重要性，并通过反馈学习机制根据替换词语导致的预测标签变化来决定奖励或惩罚。在每次迭代中，SGFL-Attack根据反馈学习机制获取的知识引导搜索，生成相似度更高的样本同时保持较低的扰动。此外，为减少查询预算，我们引入了局部哈希映射以避免搜索过程中的冗余查询。在七个广泛使用的数据集上的大量实验表明，所提出的SGFL-Attack方法在多种语言模型上显著优于当前最先进的基线和防御方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SGFL-Attack:+A+Similarity-Guidance+Strategy+for+Hard-Label+Textual+Adversarial+Attack+Based+on+Feedback+Learning)|0|
|[Factor Model-Based Large Covariance Estimation from Streaming Data Using a Knowledge-Based Sketch Matrix](https://doi.org/10.1145/3627673.3679820)|Xiao Tan, Zhaoyang Wang, Hao Qian, Jun Zhou, Peibo Duan, Dian Shen, Meng Wang, Beilun Wang|Tongji University, Shanghai, China; Ant Group, Hangzhou, China; Monash University, Melbourne, Australia; Southeast University, Nanjing, China|Covariance matrix estimation is an important problem in statistics, with wide applications in finance, neuroscience, meteorology, oceanography, and other fields. However, when the data are high-dimensional and constantly generated and updated in a streaming fashion, the covariance matrix estimation faces huge challenges, including the curse of dimensionality and limited memory space. The existing methods either assume sparsity, ignoring any possible common factor among the variables, or obtain poor performance in recovering the covariance matrix directly from sketched data. To address these issues, we propose a novel method - KEEF: Knowledge-based Time and Memory Efficient Covariance Estimator in Factor Model and its extended variation. Our method leverages historical data to train a knowledge-based sketch matrix, which is used to accelerate the factor analysis of streaming data and directly estimates the covariance matrix from the sketched data. We provide theoretical guarantees, showing the advantages of our method in terms of time and space complexity, as well as accuracy. We conduct extensive experiments on synthetic and real-world data, comparing KEEF with several state-of-the-art methods, demonstrating the superior performance of our method.|协方差矩阵估计是统计学中的一个重要问题，广泛应用于金融、神经科学、气象学、海洋学等多个领域。然而，当数据具有高维度且以流式方式持续生成和更新时，协方差矩阵估计面临巨大挑战，包括维度灾难和有限的内存空间。现有的方法要么假设数据稀疏，忽视了变量之间可能存在的共同因子，要么在从草图数据中直接恢复协方差矩阵时表现不佳。为解决这些问题，我们提出了一种新颖的方法——KEEF：基于知识的时-空高效协方差估计器，适用于因子模型及其扩展变体。我们的方法利用历史数据训练一个基于知识的草图矩阵，该矩阵用于加速流数据的因子分析，并直接从草图数据中估计协方差矩阵。我们提供了理论保证，证明了该方法在时间和空间复杂度以及准确性方面的优势。我们在合成数据和真实数据上进行了广泛的实验，将KEEF与几种最先进的方法进行了比较，展示了我们方法的优越性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Factor+Model-Based+Large+Covariance+Estimation+from+Streaming+Data+Using+a+Knowledge-Based+Sketch+Matrix)|0|
|[Teach Harder, Learn Poorer: Rethinking Hard Sample Distillation for GNN-to-MLP Knowledge Distillation](https://doi.org/10.1145/3627673.3679586)|Lirong Wu, Yunfan Liu, Haitao Lin, Yufei Huang, Stan Z. Li||To bridge the gaps between powerful Graph Neural Networks (GNNs) and lightweight Multi-Layer Perceptron (MLPs), GNN-to-MLP Knowledge Distillation (KD) proposes to distill knowledge from a well-trained teacher GNN into a student MLP. In this paper, we revisit the knowledge samples (nodes) in teacher GNNs from the perspective of hardness, and identify that hard sample distillation may be a major performance bottleneck of existing graph KD algorithms. The GNN-to-MLP KD involves two different types of hardness, one student-free knowledge hardness describing the inherent complexity of GNN knowledge, and the other student-dependent distillation hardness describing the difficulty of teacher-to-student distillation. However, most of the existing work focuses on only one of these aspects or regards them as one thing. This paper proposes a simple yet effective Hardness-aware GNN-to-MLP Distillation (HGMD) framework, which decouples the two hardnesses and estimates them using a non-parametric approach. Finally, two hardness-aware distillation schemes (i.e., HGMD-weight and HGMD-mixup) are further proposed to distill hardness-aware knowledge from teacher GNNs into the corresponding nodes of student MLPs. As non-parametric distillation, HGMD does not involve any additional learnable parameters beyond the student MLPs, but it still outperforms most of the state-of-the-art competitors. HGMD-mixup improves over the vanilla MLPs by 12.95 over seven real-world datasets.|为了弥合强大的图神经网络（GNN）与轻量级多层感知器（MLP）之间的差距，GNN-to-MLP知识蒸馏（KD）提出将经过良好训练的教师GNN的知识蒸馏到学生MLP中。本文从难度的角度重新审视教师GNN中的知识样本（节点），并识别出硬样本蒸馏可能是现有图KD算法的主要性能瓶颈。GNN-to-MLP KD涉及两种不同类型的难度：一种是描述GNN知识固有复杂性的学生无关知识难度，另一种是描述教师到学生蒸馏难度的学生依赖蒸馏难度。然而，现有的大部分工作只关注其中一个方面，或将两者视为一体。本文提出了一种简单而有效的硬度感知GNN-to-MLP蒸馏（HGMD）框架，该框架将两种难度解耦，并使用非参数方法进行估计。最后，进一步提出了两种硬度感知蒸馏方案（即HGMD-weight和HGMD-mixup），以将硬度感知的知识从教师GNN蒸馏到学生MLP的相应节点中。作为一种非参数蒸馏方法，HGMD除了学生MLP外不涉及任何额外的可学习参数，但仍优于大多数最先进的竞争对手。在七个真实世界数据集上，HGMD-mixup相较于普通MLP提升了12.95%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Teach+Harder,+Learn+Poorer:+Rethinking+Hard+Sample+Distillation+for+GNN-to-MLP+Knowledge+Distillation)|0|
|[Correcting Biases of Shapley Value Attributions for Informative Machine Learning Model Explanations](https://doi.org/10.1145/3627673.3679846)|Ningsheng Zhao, Jia Yuan Yu, Trang Bui, Krzysztof Dzieciolowski|Concordia University and Daesys Inc., Montreal, Quebec, Canada; Concordia University, Montreal, Quebec, Canada; University of Waterloo, Waterloo, Ontario, Canada|Shapley value attribution (SVA) is an increasingly popular Explainable AI (XAI) approach that has been widely used in many recent applied studies to gain new insights into the underlying information systems. However, most existing SVA methods are error-prone, providing biased or unreliable explanations that fail to correctly capture the informational dependencies between features and model outputs. These explanation errors can be decomposed into two components: 1) observation bias which stems from data sparsity and leads to over-informativeness; and 2) structural bias which stems from distributional assumptions and leads to under-informativeness. To alleviate these biases, in this paper, we propose a series of refinement methods that combine out-of-distribution (OOD) detection and importance sampling. In essence, our methods aim to rectify the distribution drift caused by distributional assumptions. We apply our refinement methods to two popular SVAs: the marginal SVA and the surrogate model-based SVA. Our extensive experiments show that the proposed methods significantly enhance the informativeness of both local and global Shapley value-based explanations.|Shapley值归因（SVA）是一种日益流行的可解释人工智能（XAI）方法，近年来在许多应用研究中被广泛使用，以深入了解底层信息系统。然而，现有的SVA方法大多存在误差，提供有偏或不可靠的解释，未能正确捕捉特征与模型输出之间的信息依赖关系。这些解释误差可以分解为两个部分：1）观测偏差，源于数据稀疏性，导致过度信息量；2）结构偏差，源于分布假设，导致信息量不足。为了缓解这些偏差，本文提出了一系列结合分布外（OOD）检测和重要性采样的改进方法。本质上，我们的方法旨在纠正由分布假设引起的分布偏移。我们将这些改进方法应用于两种流行的SVA方法：边际SVA和基于代理模型的SVA。大量实验表明，所提出的方法显著提高了基于Shapley值的局部和全局解释的信息量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Correcting+Biases+of+Shapley+Value+Attributions+for+Informative+Machine+Learning+Model+Explanations)|0|
|[HiMTM: Hierarchical Multi-Scale Masked Time Series Modeling with Self-Distillation for Long-Term Forecasting](https://doi.org/10.1145/3627673.3679741)|Shubao Zhao, Ming Jin, Zhaoxiang Hou, Chengyi Yang, Zengxiang Li, Qingsong Wen, Yi Wang|; Digital Research Institute of ENN Group; Monash University; The University of Hong Kong|Time series forecasting is a critical and challenging task in practical application. Recent advancements in pre-trained foundation models for time series forecasting have gained significant interest. However, current methods often overlook the multi-scale nature of time series, which is essential for accurate forecasting. To address this, we propose HiMTM, a hierarchical multi-scale masked time series modeling with self-distillation for long-term forecasting. HiMTM integrates four key components: (1) hierarchical multi-scale transformer (HMT) to capture temporal information at different scales; (2) decoupled encoder-decoder (DED) that directs the encoder towards feature extraction while the decoder focuses on pretext tasks; (3) hierarchical self-distillation (HSD) for multi-stage feature-level supervision signals during pre-training; and (4) cross-scale attention fine-tuning (CSA-FT) to capture dependencies between different scales for downstream tasks. These components collectively enhance multi-scale feature extraction in masked time series modeling, improving forecasting accuracy. Extensive experiments on seven mainstream datasets show that HiMTM surpasses state-of-the-art self-supervised and end-to-end learning methods by a considerable margin of 3.16-68.54%. Additionally, HiMTM outperforms the latest robust self-supervised learning method, PatchTST, in cross-domain forecasting by a significant margin of 2.3%. The effectiveness of HiMTM is further demonstrated through its application in natural gas demand forecasting.|时间序列预测在实际应用中是一项重要且具有挑战性的任务。近年来，针对时间序列预测的预训练基础模型取得了显著进展，并引起了广泛关注。然而，现有方法往往忽视了时间序列的多尺度特性，而这一特性对于精确预测至关重要。为此，我们提出了HiMTM，一种用于长期预测的分层多尺度掩码时间序列建模方法，结合了自蒸馏机制。HiMTM整合了四个关键组件：（1）分层多尺度Transformer（HMT），用于捕捉不同尺度的时间信息；（2）解耦编码器-解码器（DED），使编码器专注于特征提取，而解码器则聚焦于前置任务；（3）分层自蒸馏（HSD），在预训练过程中提供多阶段的特征级监督信号；（4）跨尺度注意力微调（CSA-FT），用于捕捉下游任务中不同尺度之间的依赖关系。这些组件共同增强了掩码时间序列建模中的多尺度特征提取能力，从而提高了预测精度。在七个主流数据集上的广泛实验表明，HiMTM在自监督和端到端学习方法上显著超越了现有最先进的方法，提升幅度达3.16%至68.54%。此外，HiMTM在跨领域预测中显著优于最新的鲁棒自监督学习方法PatchTST，提升幅度为2.3%。通过在天然气需求预测中的应用，进一步证明了HiMTM的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HiMTM:+Hierarchical+Multi-Scale+Masked+Time+Series+Modeling+with+Self-Distillation+for+Long-Term+Forecasting)|0|
|[GLFNet: Global and Local Frequency-domain Network for Long-term Time Series Forecasting](https://doi.org/10.1145/3627673.3679579)|Xucheng Zhou, Yuwen Liu, Lianyong Qi, Xiaolong Xu, Wanchun Dou, Xuyun Zhang, Yang Zhang, Xiaokang Zhou|Nanjing University, Nanjing, China; China University of Petroleum (East China) & Qufu Normal University, Qingdao, China; Kansai University, Osaka, Japan; Macquarie University, Sydney, Australia; Nanjing University of Information Science and Technology, Nanjing, China; China University of Petroleum (East China), Qingdao, China|Recently, patch-based transformer methods have demonstrated strong effectiveness in time series forecasting. However, the complexity of self-attention imposes demands on memory and compute resources. In addition, though patches can capture comprehensive temporal information while preserving locality, temporal information within patches remains important for time series prediction. The existing methods mainly focus on modeling long-term dependencies across patches, while paying little attention to the short-term dependencies within patches. In this paper, we propose the Global and Local Frequency-domain Network (GLFNet), a novel architecture that efficiently learns global time dependencies and local time relationships in the frequency domain. Specifically, we design a frequency filtering layer to learn the temporal interactions instead of self-attention. Then we devise a dual filtering block consisting of global filter block and local filter block which learns the global dependencies across patches and local dependencies within patches. Experiments on seven benchmark datasets demonstrate that our approach achieve superior performance with improved efficiency.|近年来，基于分块的Transformer方法在时间序列预测中展现了强大的有效性。然而，自注意力机制的复杂性对内存和计算资源提出了较高要求。此外，尽管分块方法能够在保留局部性的同时捕捉全面的时间信息，但分块内部的时间信息对于时间序列预测仍然至关重要。现有方法主要关注跨分块的长程依赖建模，而对分块内部短程依赖的关注较少。本文提出了一种新颖的架构——全局与局部频域网络（GLFNet），该架构能够在频域中高效学习全局时间依赖关系和局部时间关系。具体而言，我们设计了一个频域滤波层来学习时间交互，而非使用自注意力机制。随后，我们提出了一种双滤波块结构，由全局滤波块和局部滤波块组成，分别学习跨分块的全局依赖关系和分块内部的局部依赖关系。在七个基准数据集上的实验表明，我们的方法在提升效率的同时实现了卓越的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GLFNet:+Global+and+Local+Frequency-domain+Network+for+Long-term+Time+Series+Forecasting)|0|
|[Facets of Disparate Impact: Evaluating Legally Consistent Bias in Machine Learning](https://doi.org/10.1145/3627673.3679925)|Jarren Briscoe, Assefaw H. Gebremedhin|Washington State University, Pullman, WA, USA|Leveraging current legal standards, we define bias through the lens of marginal benefits and objective testing with the novel metric "Objective Fairness Index". This index combines the contextual nuances of objective testing with metric stability, providing a legally consistent and reliable measure. Utilizing the Objective Fairness Index, we provide fresh insights into sensitive machine learning applications, such as COMPAS (recidivism prediction), highlighting the metric's practical and theoretical significance. The Objective Fairness Index allows one to differentiate between discriminatory tests and systemic disparities.|借助当前的法律标准，我们通过边际效益和客观测试的视角定义了偏见，并提出了一个新的指标——“客观公平指数”。该指数结合了客观测试的上下文细微差别与指标稳定性，提供了一种法律上一致且可靠的衡量标准。利用客观公平指数，我们对敏感的机器学习应用（如COMPAS再犯预测）进行了深入分析，突显了该指标在实际应用和理论上的重要性。客观公平指数能够区分歧视性测试与系统性差异。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Facets+of+Disparate+Impact:+Evaluating+Legally+Consistent+Bias+in+Machine+Learning)|0|
|[Bubble Sketch: A High-performance and Memory-efficient Sketch for Finding Top-k Items in Data Streams](https://doi.org/10.1145/3627673.3679882)|Lu Cao, Qilong Shi, Yuxi Liu, Hanyue Zheng, Yao Xin, Wenjun Li, Tong Yang, Yangyang Wang, Yang Xu, Weizhe Zhang, Mingwei Xu|Fudan University, Shanghai, China; Harbin Institute of Technology, Shenzhen, China; Peking University, Beijing, China; Harbin Institute of Technology, Harbin, China; Guangzhou University, Guangzhou, China; Pengcheng Laboratory, Shenzhen, China; Tsinghua University, Beijing, China|Sketch algorithms are crucial for identifying top-k items in large-scale data streams. Existing methods often compromise between performance and accuracy, unable to efficiently handle increasing data volumes with limited memory. We present Bubble Sketch, a compact algorithm that excels in both performance and accuracy. Bubble Sketch achieves this by (1) Recording only full keys of hot items, significantly reducing memory usage, and (2) Using threshold relocation to resolve conflicts, enhancing detection accuracy. Unlike traditional methods, Bubble Sketch eliminates the need for a Min-Heap, ensuring fast processing speeds. Experiments show Bubble Sketch outperforms the other seven algorithms compared, with the highest throughput and precision, and surpasses HeavyKeeper in accuracy by up to two orders of magnitude.|草图算法在识别大规模数据流中的前k个项目方面至关重要。现有方法通常在性能和准确性之间做出妥协，无法在有限内存下高效处理日益增长的数据量。我们提出了Bubble Sketch，这是一种在性能和准确性方面表现出色的紧凑型算法。Bubble Sketch通过以下方式实现这一目标：(1) 仅记录热门项目的完整键，显著减少内存使用；(2) 使用阈值重定位来解决冲突，提高检测准确性。与传统方法不同，Bubble Sketch无需使用Min-Heap，从而确保了快速的处理速度。实验表明，Bubble Sketch在与其他七种算法相比时，具有最高的吞吐量和精确度，并且在准确性上超越了HeavyKeeper多达两个数量级。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bubble+Sketch:+A+High-performance+and+Memory-efficient+Sketch+for+Finding+Top-k+Items+in+Data+Streams)|0|
|[Optimizing Numerical Estimation and Operational Efficiency in the Legal Domain through Large Language Models](https://doi.org/10.1145/3627673.3680025)|JiaHong Huang, ChaoChun Yang, Yixian Shen, Alessio M. Pacces, Evangelos Kanoulas||The legal landscape encompasses a wide array of lawsuit types, presenting lawyers with challenges in delivering timely and accurate information to clients, particularly concerning critical aspects like potential imprisonment duration or financial repercussions. Compounded by the scarcity of legal experts, there's an urgent need to enhance the efficiency of traditional legal workflows. Recent advances in deep learning, especially Large Language Models (LLMs), offer promising solutions to this challenge. Leveraging LLMs' mathematical reasoning capabilities, we propose a novel approach integrating LLM-based methodologies with specially designed prompts to address precision requirements in legal Artificial Intelligence (LegalAI) applications. The proposed work seeks to bridge the gap between traditional legal practices and modern technological advancements, paving the way for a more accessible, efficient, and equitable legal system. To validate this method, we introduce a curated dataset tailored to precision-oriented LegalAI tasks, serving as a benchmark for evaluating LLM-based approaches. Extensive experimentation confirms the efficacy of our methodology in generating accurate numerical estimates within the legal domain, emphasizing the role of LLMs in streamlining legal processes and meeting the evolving demands of LegalAI.|法律领域的诉讼类型繁多，给律师在向客户提供及时、准确的信息方面带来了挑战，尤其是在涉及潜在监禁时间或财务影响等关键问题上。加之法律专家的稀缺，提升传统法律工作流程的效率显得尤为迫切。近年来，深度学习的进展，特别是大型语言模型（LLMs）的发展，为这一挑战提供了有前景的解决方案。利用LLMs的数学推理能力，我们提出了一种将基于LLM的方法与专门设计的提示相结合的新方法，以满足法律人工智能（LegalAI）应用中的精确性要求。该研究旨在弥合传统法律实践与现代技术进步之间的差距，为构建更加便捷、高效和公平的法律体系铺平道路。为验证这一方法，我们引入了一个针对精确导向的LegalAI任务定制的数据集，作为评估基于LLM方法的基准。广泛的实验证实了我们的方法在法律领域内生成准确数值估计的有效性，突显了LLMs在简化法律流程和满足LegalAI不断变化需求中的重要作用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimizing+Numerical+Estimation+and+Operational+Efficiency+in+the+Legal+Domain+through+Large+Language+Models)|0|
|[A Multi-Node Multi-GPU Distributed GNN Training Framework for Large-Scale Online Advertising](https://doi.org/10.1145/3627673.3680018)|Xuewu Jiao, Xinsheng Luo, Miao Li, Jiang Bian, Junchao Yang, Wei Hu, Mingqing Hu, Weipeng Lu, Shikun Feng, Danlei Feng, Dongxu Yang, Haoyi Xiong, Shuanglong Li, Lin Liu|NVIDIA, CA, USA; Big Data Lab, Baidu Inc., Beijing, China; Baidu Inc., Beijing, China|Graph Neural Networks (GNNs) have become critical in various domains such as online advertising but face scalability challenges due to the growing size of graph data, leading to the needs for advanced distributed GPU computation strategies across multiple nodes. This paper presents PGLBox-Cluster, a robust distributed graph learning framework constructed atop the PaddlePaddle platform, implemented to efficiently process graphs comprising billions of nodes and edges. Through strategic partitioning of the model, node attributes, and graph data and leveraging industrial-grade RPC and NCCL for communication, PGLBox-Cluster facilitates effective distributed computation. The extensive experimental results confirm that PGLBox-Cluster achieves a 1.94x to 2.93x speedup over the single-node configuration, significantly elevating graph neural network scalability and efficiency by handling datasets exceeding 3 billion nodes and 120 billion edges with its novel asynchronous communication and graph partitioning techniques. The repository is released at This Link.|图神经网络（GNN）在在线广告等多个领域中已成为关键技术，但由于图数据规模的不断增长，面临着可扩展性挑战，这促使需要跨多个节点的先进分布式GPU计算策略。本文介绍了PGLBox-Cluster，这是一个构建在PaddlePaddle平台之上的强大分布式图学习框架，旨在高效处理包含数十亿节点和边的图数据。通过策略性地对模型、节点属性和图数据进行分区，并利用工业级的RPC和NCCL进行通信，PGLBox-Cluster促进了有效的分布式计算。广泛的实验结果证实，PGLBox-Cluster相较于单节点配置实现了1.94倍至2.93倍的加速，通过其新颖的异步通信和图分区技术，显著提升了图神经网络的可扩展性和效率，能够处理超过30亿节点和1200亿条边的数据集。该框架的代码库已在此链接发布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Multi-Node+Multi-GPU+Distributed+GNN+Training+Framework+for+Large-Scale+Online+Advertising)|0|
|[3M-Health: Multimodal Multi-Teacher Knowledge Distillation for Mental Health Detection](https://doi.org/10.1145/3627673.3679635)|Rina Carines Cabral, Siwen Luo, Josiah Poon, Soyeon Caren Han||The significance of mental health classification is paramount in contemporary society, where digital platforms serve as crucial sources for monitoring individuals' well-being. However, existing social media mental health datasets primarily consist of text-only samples, potentially limiting the efficacy of models trained on such data. Recognising that humans utilise cross-modal information to comprehend complex situations or issues, we present a novel approach to address the limitations of current methodologies. In this work, we introduce a Multimodal and Multi-Teacher Knowledge Distillation model for Mental Health Classification, leveraging insights from cross-modal human understanding. Unlike conventional approaches that often rely on simple concatenation to integrate diverse features, our model addresses the challenge of appropriately representing inputs of varying natures (e.g., texts and sounds). To mitigate the computational complexity associated with integrating all features into a single model, we employ a multimodal and multi-teacher architecture. By distributing the learning process across multiple teachers, each specialising in a particular feature extraction aspect, we enhance the overall mental health classification performance. Through experimental validation, we demonstrate the efficacy of our model in achieving improved performance.|心理健康分类在当代社会中具有至关重要的意义，数字平台作为监测个体健康状况的关键来源。然而，现有的社交媒体心理健康数据集主要由纯文本样本组成，这可能限制了基于此类数据训练的模型的有效性。认识到人类利用跨模态信息来理解复杂情境或问题，我们提出了一种新颖的方法来解决当前方法的局限性。在这项工作中，我们引入了一种多模态和多教师知识蒸馏模型用于心理健康分类，借鉴了跨模态人类理解的见解。与传统方法通常依赖简单拼接来整合不同特征不同，我们的模型解决了适当表示不同性质输入（如文本和声音）的挑战。为了减轻将所有特征整合到单一模型中带来的计算复杂性，我们采用了多模态和多教师架构。通过将学习过程分布到多个教师中，每个教师专门负责特定的特征提取方面，我们提升了整体心理健康分类的性能。通过实验验证，我们展示了该模型在提高性能方面的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=3M-Health:+Multimodal+Multi-Teacher+Knowledge+Distillation+for+Mental+Health+Detection)|0|
|[Hypergraph Hash Learning for Efficient Trajectory Similarity Computation](https://doi.org/10.1145/3627673.3679555)|Yuan Cao, Lei Li, Xiangru Chen, Xue Xu, Zuojin Huang, Yanwei Yu|Computer Science and Technology, Ocean University of China, Qingdao, Shandong, China|Trajectory similarity computation is a fundamental problem in various applications (e.g., transportation optimization, behavioral study). Recent researches learn trajectory representations instead of point matching to realize more accurate and efficient trajectory similarity computation. However, these methods can still not be scaled to large datasets due to high computational cost. In this paper, we propose a novel hash learning method to encode the trajectories into binary hash codes and compute trajectory similarities by Hamming distances which is much more efficient. To the best of our knowledge, this is the first work to conduct hash learning for trajectory similarity computation. Furthermore, unlike the Word2Vec model based on random walk strategy, we utilize hypergraph neural networks for the first time to learn the representations for the grids by constructing the hyperedges according to the real-life trajectories, resulting in more representative grid embeddings. In addition, we design a residual network into the multi-layer GRU to learn more discriminative trajectory representations. The proposed Hypergraph Hash Learning for Trajectory similarity commutation is an end-to-end framework and named HHL-Traj. Experimental results on two real-world trajectory datasets (i.e., Porto and Beijing) demonstrate that the proposed framework achieves up to 6.23% and 15.42% accuracy gains compared with state-of-the-art baselines in unhashed and hashed cases, respectively. The efficiency of trajectory similarity computation based on hash codes is also verified. Our code is available at https://github.com/caoyuan57/HHL-Traj.|轨迹相似度计算是众多应用中的一个基础问题（例如，交通优化、行为研究）。近期的研究通过学习轨迹表示而非点匹配来实现更精确和高效的轨迹相似度计算。然而，这些方法由于高计算成本仍无法扩展到大规模数据集。本文提出了一种新颖的哈希学习方法，将轨迹编码为二进制哈希码，并通过汉明距离计算轨迹相似度，从而显著提高效率。据我们所知，这是首次将哈希学习应用于轨迹相似度计算的工作。此外，与基于随机游走策略的Word2Vec模型不同，我们首次利用超图神经网络，根据现实生活中的轨迹构建超边，从而学习更具代表性的网格表示。此外，我们将残差网络设计融入多层GRU中，以学习更具辨别力的轨迹表示。所提出的超图哈希学习框架用于轨迹相似度计算，是一个端到端的框架，命名为HHL-Traj。在两个真实世界的轨迹数据集（即波尔图和北京）上的实验结果表明，与未哈希和哈希情况下的最先进基线相比，所提出的框架分别实现了高达6.23%和15.42%的准确性提升。基于哈希码的轨迹相似度计算效率也得到了验证。我们的代码可在https://github.com/caoyuan57/HHL-Traj获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hypergraph+Hash+Learning+for+Efficient+Trajectory+Similarity+Computation)|0|
|[Towards Online and Safe Configuration Tuning with Semi-supervised Anomaly Detection](https://doi.org/10.1145/3627673.3679700)|Haitian Chen, Xu Chen, Zibo Liang, Xiushi Feng, Jiandong Xie, Han Su, Kai Zheng|; Huawei Technologies Co., Ltd., Chengdu, China|The performance of modern database management systems highly relies on hundreds of adjustable knobs. Traditionally, these knobs are manually adjusted by database administrators, a process that is both inefficient and ineffective for tuning large-scale databases in cloud environments. Recent research has explored the use of machine learning techniques to enable the automatic tuning of database configurations. Although most existing learning-based methods achieve satisfactory results on static workloads, they often experience performance degradation and low sampling efficiency in real-world environments. According to our study, this is primarily due to a lack of safety guarantees during the configuration sampling process. To address the aforementioned issues, we propose SafeTune, an online tuning system that adapts to dynamic workloads. Our core idea is to filter out a large number of configurations with potential risks during the configuration sampling process. We employ a two-stage filtering approach: The first stage utilizes a semi-supervised outlier ensemble with feature learning to achieve high-quality feature representation. The second stage employs a ranking-based classifier to refine the filtering process. In addition, to alleviate the cold-start problem, we leverage the historical tuning experience to provide high-quality initial samples during the initialization phase. We conducted comprehensive evaluations on static and dynamic workloads. In comparison to offline baseline methods, SafeTune reduces 95.6%-98.6% unsafe configuration suggestions. In contrast with state-of-the-art methods, SafeTune has improved cumulative performance by 10.5%-46.6% and tuning speed by 15.1%-35.4%.|现代数据库管理系统的表现高度依赖于数百个可调节的参数。传统上，这些参数由数据库管理员手动调整，这种方法在云环境中对大规模数据库进行调优时既不高效也不有效。最近的研究探索了使用机器学习技术来自动调整数据库配置。尽管大多数现有的基于学习的方法在静态工作负载上取得了令人满意的结果，但它们在现实环境中往往会出现性能下降和采样效率低下的问题。根据我们的研究，这主要是由于在配置采样过程中缺乏安全保障。为了解决上述问题，我们提出了SafeTune，一个适应动态工作负载的在线调优系统。我们的核心思想是在配置采样过程中过滤掉大量可能存在风险的配置。我们采用两阶段过滤方法：第一阶段利用带有特征学习的半监督异常值集成来实现高质量的特征表示；第二阶段采用基于排名的分类器来优化过滤过程。此外，为了缓解冷启动问题，我们利用历史调优经验在初始化阶段提供高质量的初始样本。我们对静态和动态工作负载进行了全面的评估。与离线基线方法相比，SafeTune减少了95.6%-98.6%的不安全配置建议。与最先进的方法相比，SafeTune的累计性能提高了10.5%-46.6%，调优速度提高了15.1%-35.4%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Online+and+Safe+Configuration+Tuning+with+Semi-supervised+Anomaly+Detection)|0|
|[Urban Traffic Accident Risk Prediction Revisited: Regionality, Proximity, Similarity and Sparsity](https://doi.org/10.1145/3627673.3679567)|Minxiao Chen, Haitao Yuan, Nan Jiang, Zhifeng Bao, Shangguang Wang||Traffic accidents pose a significant risk to human health and property safety. Therefore, to prevent traffic accidents, predicting their risks has garnered growing interest. We argue that a desired prediction solution should demonstrate resilience to the complexity of traffic accidents. In particular, it should adequately consider the regional background, accurately capture both spatial proximity and semantic similarity, and effectively address the sparsity of traffic accidents. However, these factors are often overlooked or difficult to incorporate. In this paper, we propose a novel multi-granularity hierarchical spatio-temporal network. Initially, we innovate by incorporating remote sensing data, facilitating the creation of hierarchical multi-granularity structure and the comprehension of regional background. We construct multiple high-level risk prediction tasks to enhance model's ability to cope with sparsity. Subsequently, to capture both spatial proximity and semantic similarity, region feature and multi-view graph undergo encoding processes to distill effective representations. Additionally, we propose message passing and adaptive temporal attention module that bridges different granularities and dynamically captures time correlations inherent in traffic accident patterns. At last, a multivariate hierarchical loss function is devised considering the complexity of the prediction purpose. Extensive experiments on two real datasets verify the superiority of our model against the state-of-the-art methods.|交通事故对人类健康和财产安全构成重大威胁。因此，为预防交通事故，预测其风险的重要性日益凸显。我们认为，理想的预测方案应能应对交通事故的复杂性。具体而言，它应充分考虑区域背景，准确捕捉空间邻近性和语义相似性，并有效处理交通事故数据的稀疏性。然而，这些因素往往被忽视或难以整合。本文提出了一种新颖的多粒度层次时空网络。首先，我们创新性地引入遥感数据，有助于构建层次化的多粒度结构并理解区域背景。我们构建了多个高层风险预测任务，以增强模型应对稀疏性的能力。接着，为捕捉空间邻近性和语义相似性，我们对区域特征和多视角图进行编码，提炼出有效的表示。此外，我们提出了消息传递和自适应时间注意力模块，这些模块连接不同粒度，并动态捕捉交通事故模式中的时间相关性。最后，针对预测目的的复杂性，我们设计了一种多元层次损失函数。在两个真实数据集上的广泛实验验证了我们的模型相较于现有最先进方法的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Urban+Traffic+Accident+Risk+Prediction+Revisited:+Regionality,+Proximity,+Similarity+and+Sparsity)|0|
|[Hyperedge Importance Estimation via Identity-aware Hypergraph Attention Network](https://doi.org/10.1145/3627673.3679685)|Yin Chen, Xiaoyang Wang, Chen Chen|University of Wollongong, Wollongong, Australia; University of New South Wales, Sydney, Australia; Zhejiang Gongshang University, Hangzhou, China|Hypergraphs provide a more flexible representation for group interactions in complex systems compared to ordinary graphs, where each hyperedge can connect any number of nodes. In practice, data modeled as hypergraphs often contain hyperedge importance values, which indicate the influence or popularity of the group collaborations. For example, in a co-authorship hypergraph, a paper (hyperedge) is co-authored by multiple authors (nodes). The number of citations a paper receives can be regarded as the importance value of its corresponding hyperedge, reflecting its academic influence and significance. In this work, we introduce hyperedge importance estimation as a new problem in hypergraph learning. The flexibility of hyperedges enables hypergraph modeling to capture high-order relationships between entities, which has attracted widespread attention. The importance value of hyperedge has also been proven to be highly valuable in many applications. To address this problem, we propose the Identity-aware Hypergraph Attention Network (ID-HAN) for efficient hyperedge importance estimation. ID-HAN~employs a special attention mechanism to model the importance contribution of each node within the hyperedge, which injects identity information according to the hyperedge-dependent node labels. Additionally, a centrality-aware positional encoding module generates learnable positional embeddings of nodes and hyperedges based on the relative order of degree centrality and identity information, thereby enhancing the consistency between message passing and importance propagation. Extensive experiments on four real-world datasets demonstrate that ID-HAN~significantly outperforms the state-of-the-art hypergraph neural networks on the hyperedge importance estimation task.|相较于普通图，超图在复杂系统中为群体交互提供了更为灵活的表示方式，其中每条超边可以连接任意数量的节点。在实际应用中，以超图形式建模的数据通常包含超边的重要性值，这些值反映了群体协作的影响力或受欢迎程度。例如，在合著超图中，一篇论文（超边）由多位作者（节点）共同撰写。一篇论文的引用次数可以视为其对应超边的重要性值，体现了其学术影响力和重要性。在本研究中，我们引入了超边重要性估计作为超图学习中的一个新问题。超边的灵活性使得超图建模能够捕捉实体间的高阶关系，这一特性受到了广泛关注。超边的重要性值在许多应用中也已被证明具有极高的价值。为解决这一问题，我们提出了身份感知超图注意力网络（Identity-aware Hypergraph Attention Network, ID-HAN），用于高效的超边重要性估计。ID-HAN采用了一种特殊的注意力机制来建模超边内每个节点的重要性贡献，该机制根据超边依赖的节点标签注入了身份信息。此外，一个中心性感知的位置编码模块基于节点的度中心性和身份信息的相对顺序，生成了可学习的节点和超边位置嵌入，从而增强了消息传递与重要性传播之间的一致性。在四个真实世界数据集上的广泛实验表明，ID-HAN在超边重要性估计任务上显著优于当前最先进的超图神经网络。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hyperedge+Importance+Estimation+via+Identity-aware+Hypergraph+Attention+Network)|0|
|[PIXEL: Prompt-based Zero-shot Hashing via Visual and Textual Semantic Alignment](https://doi.org/10.1145/3627673.3679747)|Zeyu Dong, Qingqing Long, Yihang Zhou, Pengfei Wang, Zhihong Zhu, Xiao Luo, Yidong Wang, Pengyang Wang, Yuanchun Zhou|; University of California, Los Angeles, Los Angeles, USA; University of Macau, Macau, China; Peking University, Beijing, China|Zero-Shot Hashing (ZSH) has aroused significant attention due to its efficiency and generalizability in multi-modal retrieval scenarios, which aims to encode semantic information into hash codes without needing unseen labeled training samples. In addition to commonly used visual images as visual semantics and class labels as global semantics, the corresponding attribute descriptions contain critical local semantics with detailed information. However, most existing methods focus on leveraging the extracted attribute numerical values, without exploring the textual semantics in attribute descriptions. To bridge this gap, in this paper, we propose Prompt-based zero-shot hashing via vIsual and teXtual sEmantic aLignment, namely PIXEL. Concretely, we design the attribute prompt template depending on attribute descriptions to make the model capture the corresponding local semantics. Then, achieving the textual embedding and visual embedding, we proposed an alignment module to model the intra- and inter-class contrastive distances. In addition, the attribute-wise constraint and class-wise constraint are utilized to collaboratively learn the hash code, image representation, and visual attributes more effectively. Finally, extensive experimental results demonstrate the superiority of PIXEL.|零样本哈希（Zero-Shot Hashing, ZSH）因其在大规模多模态检索场景中的高效性和通用性而备受关注，其目标是将语义信息编码为哈希码，而无需使用未见过的标注训练样本。除了常用的视觉图像作为视觉语义和类别标签作为全局语义外，相应的属性描述还包含了具有详细信息的局部语义。然而，现有的大多数方法主要利用提取的属性数值，而未探索属性描述中的文本语义。为了填补这一空白，本文提出了一种基于提示的零样本哈希方法，通过视觉与文本语义对齐来实现，命名为PIXEL。具体而言，我们根据属性描述设计了属性提示模板，以使模型能够捕捉相应的局部语义。随后，在获得文本嵌入和视觉嵌入后，我们提出了一种对齐模块，用于建模类内和类间对比距离。此外，利用属性级约束和类别级约束来协同学习哈希码、图像表示和视觉属性，从而更有效地实现目标。最后，广泛的实验结果证明了PIXEL的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PIXEL:+Prompt-based+Zero-shot+Hashing+via+Visual+and+Textual+Semantic+Alignment)|0|
|[Progressive Multimodal Pivot Learning: Towards Semantic Discordance Understanding as Humans](https://doi.org/10.1145/3627673.3679524)|Junlin Fang, Wenya Wang, Tianze Luo, Yanyong Huang, Fengmao Lv|; School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore; School of Computing and Artificial Intelligence, Southwest Jiaotong University, Chengdu, China|Multimodal recognition can achieve enhanced performance by leveraging the complementary information from different modalities. However, in real-world scenarios, multimodal samples often express discordant semantic meanings across modalities, lacking evident complementary information. Unlike humans who can easily understand the intrinsic semantic information of these semantically discordant samples, existing multimodal recognition models show poor performance on them. With the motivation of improving the robustness of multimodal recognition models in practical scenarios, this work poses a new challenge in multimodal recognition, which is coined as Semantic Discordance Understanding. Unlike existing works only focusing on detecting semantically discordant samples as noisy data, this new challenge requires deep models to follow humans' ability in understanding the inherent semantic meanings of semantically discordant samples. To address this challenge, we further propose the Progressive Multimodal Pivot Learning (PMPL) approach by introducing a learnable pivot memory to explore the inherent semantics meaning hidden under discordant modalities. To this end, our approach inserts Pivot Memory Learning (PML) modules into multiple layers of unimodal foundation models to progressively trade-off the conflict information across modalities. By introducing the multimodal pivot learning paradigm for multimodal recognition, the proposed PMPL approach can alleviate the negative effect of semantic discordance caused by the cross-modal information exchange mechanism of existing multimodal recognition models. Experiments on different benchmarks validate the superiority of our approach. Code is available at https://github.com/tiggers23/PMPL.|多模态识别通过利用不同模态间的互补信息，能够实现性能的提升。然而，在现实场景中，多模态样本往往在不同模态间表现出不一致的语义含义，缺乏明显的互补信息。与人类能够轻松理解这些语义不一致样本的内在语义信息不同，现有的多模态识别模型在这些样本上的表现较差。为了提高多模态识别模型在实际场景中的鲁棒性，本研究提出了一项新的多模态识别挑战，称为“语义不一致理解”。与现有工作仅关注将语义不一致样本检测为噪声数据不同，这一新挑战要求深度模型具备像人类一样理解语义不一致样本内在语义信息的能力。为应对这一挑战，我们进一步提出了渐进式多模态枢纽学习（Progressive Multimodal Pivot Learning, PMPL）方法，通过引入可学习的枢纽记忆体来探索隐藏在不一致模态下的内在语义信息。为此，我们的方法在单模态基础模型的多个层中插入了枢纽记忆学习（Pivot Memory Learning, PML）模块，以逐步权衡模态间的冲突信息。通过引入多模态枢纽学习范式，所提出的PMPL方法能够缓解现有多模态识别模型中跨模态信息交换机制导致的语义不一致的负面影响。在不同基准上的实验验证了我们方法的优越性。代码可在https://github.com/tiggers23/PMPL获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Progressive+Multimodal+Pivot+Learning:+Towards+Semantic+Discordance+Understanding+as+Humans)|0|
|[Precision Meets Resilience: Cross-Database Generalization with Uncertainty Quantification for Robust Cost Estimation](https://doi.org/10.1145/3627673.3679632)|Shuhuan Fan, Mengshu Hou, Rui Xi, Wenwen Ma|University of Electronic Science and Technology of China, Chengdu, China; |Learning-based models have shown promise in addressing query optimization challenges in the database field, where the learned cost model plays a central role. While these models outperform traditional optimizers on static datasets, their resilience and reliability in real-world applications remain a concern, limiting their widespread adoption. In this paper, we take a step towards a practical cost estimation model, named Tosure, which can quantify the uncerT ainty for cost estimation and generalizes to unseen databases accurately and efficiently. It consists primarily of two modules: a Cross-Database Representation (CDR) module and a Cost Estimation with Uncertainty (CEU) module. The CDR module captures the transferable features by focusing the minimal set based on deep-learning network, thereby enhancing the model's generalization capabilities. The CEU module introduces a novel Neural Network Gaussian Process (NNGP) to quantify the uncertainty in cost estimation, ensuring more robust estimations with an upper bound. To improve the model's performance, we perform pre-training on diverse large-scale datasets. Furthermore, we implement the model and integrate it with traditional query optimizer to validate its usability and effectiveness in real-world scenarios. Extensive experimentation demonstrates that Tosure outperforms state-of-the-art methods, achieving a 20% improvement in cost estimation accuracy and twice of the robustness.|基于学习的模型在解决数据库领域中的查询优化挑战方面展现了潜力，其中学习到的成本模型起着核心作用。尽管这些模型在静态数据集上优于传统优化器，但它们在实际应用中的韧性和可靠性仍然是一个问题，限制了它们的广泛采用。本文中，我们朝着实现一个实用的成本估算模型迈出了一步，该模型名为Tosure，能够量化成本估算的不确定性，并能够准确高效地推广到未见过的数据库。它主要由两个模块组成：跨数据库表示（CDR）模块和带不确定性的成本估算（CEU）模块。CDR模块通过聚焦基于深度学习网络的最小特征集来捕捉可迁移的特征，从而增强模型的泛化能力。CEU模块引入了一种新颖的神经网络高斯过程（NNGP）来量化成本估算中的不确定性，确保更鲁棒的估算并带有上限。为了提升模型的性能，我们在多样的大规模数据集上进行预训练。此外，我们还实现了该模型并将其与传统查询优化器集成，以验证其在实际场景中的可用性和有效性。广泛的实验表明，Tosure优于最先进的方法，成本估算准确性提高了20%，并且鲁棒性提升了两倍。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Precision+Meets+Resilience:+Cross-Database+Generalization+with+Uncertainty+Quantification+for+Robust+Cost+Estimation)|0|
|[ACDM: An Effective and Scalable Active Clustering with Pairwise Constraint](https://doi.org/10.1145/3627673.3679601)|Xun Fu, WenBo Xie, Bin Chen, Tao Deng, Tian Zou, Xin Wang|School of Computer Science and Software Engineering, Southwest Petroleum University, Chengdu, China|Clustering is fundamentally a subjective task: a single dataset can be validly clustered in various ways, and without further information, clustering systems cannot determine the appropriate clustering to perform. This underscores the importance of integrating constraints into clustering, enabling users to convey their preferences to the system. Active constraint-based clustering approaches prioritize the identification of the most valuable constraints to inquire about, striving to achieve effective clustering with the minimal number of constraints needed. We propose an A ctive C lustering with D iffusion M odel (ACDM). ACDM applies the nearest-neighbor technique to construct a diffusion graph, and utilizes an online framework to refine the clustering result iteratively. In each iteration, (a) nodes with high uncertainty and representativeness are selected in batch mode, (b) then a novel neighborhood-set-based query is used for categorizing the selected nodes, using pairwise constraints, and (c) the categorized nodes are used as source nodes in the diffusion model for cluster refinement. We experimentally demonstrate that ACDM outperforms state-of-the-art methods in terms of clustering quality and scalability.|聚类本质上是一项主观任务：单一数据集可以通过多种方式进行合理聚类，而在缺乏进一步信息的情况下，聚类系统无法确定应执行的适当聚类方式。这突显了将约束条件整合到聚类过程中的重要性，使用户能够向系统传达其偏好。基于主动约束的聚类方法优先识别最有价值的约束条件以进行询问，力求以最少数量的约束实现有效的聚类。我们提出了一种基于扩散模型的主动聚类方法（Active Clustering with Diffusion Model，简称ACDM）。ACDM采用最近邻技术构建扩散图，并利用在线框架迭代优化聚类结果。在每次迭代中，（a）以批处理模式选择具有高不确定性和代表性的节点，（b）然后使用基于邻域集的新型查询方法，通过成对约束对所选节点进行分类，（c）将分类后的节点作为扩散模型中的源节点，用于进一步的聚类优化。实验结果表明，ACDM在聚类质量和可扩展性方面均优于当前最先进的聚类方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ACDM:+An+Effective+and+Scalable+Active+Clustering+with+Pairwise+Constraint)|0|
|[Compositional and Hierarchical Semantic Learning Model for Hospital Readmission Prediction](https://doi.org/10.1145/3627673.3679814)|Weiting Gao, Xiangyu Gao, Yi Chen|New Jersey Institute of Technology, Newark, NJ, USA|Clinical notes provide a wealth of patient information that is valuable for predicting clinical outcomes. In particular, predicting hospital 30-day readmission is important to improve healthcare outcomes and reduce cost. Previous works on outcome prediction using clinical notes overlook complex semantic compositions and syntactic structure when learning the note level embedding, which may fail to capture the note semantics and make accurate predictions. To address these limitations, we propose a Compositional and Hierarchical Semantic Learning Model (CHSLM). It formulates the semantic learning of clinical notes into three hierarchies: word, composition, and note, and aggregates the semantics in a bottom-up manner. To aggregate the semantics from words to compositions, we construct heterogeneous medical-composition graphs to represent word interactions within and between medical compositions and use Graph Neural Networks to learn the composition embedding. To aggregate the semantics from composition- to note-level, we incorporate a mutual BiAffine transformation process. The experimental results on 30-day readmission prediction using two types of clinical notes demonstrate the effectiveness of our method over the state-of-the-art clinical prediction models.|临床记录提供了丰富的患者信息，这些信息对于预测临床结果具有重要价值。特别是，预测患者在出院后30天内再次入院的情况对于改善医疗结果和降低成本至关重要。以往利用临床记录进行结果预测的研究在学习笔记级别的嵌入时，忽视了复杂的语义组合和句法结构，这可能导致无法准确捕捉笔记的语义并做出精确的预测。为解决这些局限性，我们提出了一种组合与层次语义学习模型（CHSLM）。该模型将临床记录的语义学习划分为三个层次：词、组合和笔记，并以自底向上的方式聚合语义。为了从词到组合聚合语义，我们构建了异构的医疗组合图，以表示医疗组合内外的词交互，并使用图神经网络来学习组合嵌入。为了从组合层级到笔记层级聚合语义，我们引入了一个双向BiAffine转换过程。在利用两种类型的临床记录进行30天再入院预测的实验中，我们的方法展示了其优于现有最先进临床预测模型的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Compositional+and+Hierarchical+Semantic+Learning+Model+for+Hospital+Readmission+Prediction)|0|
|[Mitigating Cold-Start Problems in Knowledge Tracing with Large Language Models: An Attribute-aware Approach](https://doi.org/10.1145/3627673.3679664)|Yuxiang Guo, Shuanghong Shen, Qi Liu, Zhenya Huang, Linbo Zhu, Yu Su, Enhong Chen|; Institute of Artificial Intelligence, Hefei Comprehensive National Science Center, Hefei, China|Knowledge Tracing (KT) is a crucial research task for dynamically monitoring students' knowledge states, particularly in online education systems. Recently, knowledge tracing has gained significant attention and in-depth research. Most existing methods rely on students' response data for question understanding and modeling, which helps better updating students' knowledge states. Meanwhile, question ID is utilized to indicate and represent questions. However, this presents a challenge when transitioning to new, cold-start questions that few students has answered before. Also, prior work has overlooked the semantic modeling of questions, which could better assist in modeling the transfer of students' knowledge states. In this paper, we explore leveraging the power of Large Language Models (LLMs) to help understand questions for knowledge tracing, which benefits mitigating cold-start and sparse problems and modeling the transfer of students' knowledge states in a sophisticated manner. Specifically, we first design an attribute estimation module to estimate the attribute of the questions (e.g., difficulty, ability requirements, expected response time) by prompting Large Language Models. Subsequently, we have developed a question embedding module that incorporates graph attention network to effectively utilizing these attributes. Extensive experiments on various datasets demonstrate that our model outperforms existing state-of-the-art models and effectively addresses the problems of cold-start and sparsity. In addition, due to the estimation of multiple attributes of the questions, our model exhibits superior interpretability.|知识追踪（Knowledge Tracing, KT）是动态监测学生知识状态的关键研究任务，尤其在在线教育系统中具有重要意义。近年来，知识追踪受到了广泛关注并进行了深入研究。现有的大多数方法依赖于学生的回答数据来理解问题并进行建模，从而更好地更新学生的知识状态。同时，问题ID被用来指示和表示问题。然而，这种方法在面对新出现的“冷启动”问题时存在挑战，尤其是那些之前很少有学生回答过的问题。此外，先前的研究忽视了问题的语义建模，这本可以更好地辅助建模学生知识状态的转移。本文探讨了利用大语言模型（Large Language Models, LLMs）来帮助理解问题，以进行知识追踪，这有助于缓解冷启动和数据稀疏问题，并以更精细的方式建模学生知识状态的转移。具体而言，我们首先设计了一个属性估计模块，通过提示大语言模型来估计问题的属性（如难度、能力要求、预期回答时间）。随后，我们开发了一个问题嵌入模块，结合图注意力网络，以有效利用这些属性。在多个数据集上的广泛实验表明，我们的模型优于现有的最先进模型，并有效地解决了冷启动和稀疏性问题。此外，由于对问题多个属性的估计，我们的模型展现出更强的可解释性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mitigating+Cold-Start+Problems+in+Knowledge+Tracing+with+Large+Language+Models:+An+Attribute-aware+Approach)|0|
|[HeckmanCD: Exploiting Selection Bias in Cognitive Diagnosis](https://doi.org/10.1145/3627673.3679648)|Dongxuan Han, Qi Liu, Siqi Lei, Shiwei Tong, Wei Huang|; Tencent Company, Shenzhen, China; Item Bank Department, National Education Examinations Authority, Beijing, China|Cognitive diagnosis, a fundamental task in education assessments, aims to quantify the students' proficiency level based on the historical test logs. However, the interactions between students and exercises are incomplete and even sparse, which means that only a few exercise scores of a specific student are observed. A key finding is that the pattern of this missingness is non-random, which could induce bias in the estimated proficiency value. To this end, we formulate cognitive diagnosis with a sample selection problem where observations are sampled through non-random probabilities that correlate with both the student's response correctness and the features of the student and exercise. We proposed a simple but effective method called HeckmanCD, adapting the Heckman two-stage approach to mitigate this endogeneity issue. We first employ an interaction model to predict the occurrence probability of a specific student-exercise pair. After that, a selection variable, derived from this interaction model, is incorporated as a controlled independent variable in the cognitive diagnosis framework. Our analysis reveals that the vanilla estimations of the item response theory model are inherently biased in the existence of confounders, and our method can correct this bias by capturing the covariance. The proposed HeckmanCD can be applied to most existing cognitive diagnosis models, including deep models, and the empirical evaluation demonstrates the effectiveness of our method while no other auxiliary information is required such as textual descriptions of exercises.|认知诊断，作为教育评估中的基础任务，旨在基于学生的历史测试记录量化其熟练度水平。然而，学生与练习之间的互动往往是不完整的，甚至是稀疏的，这意味着只能观察到特定学生的少数练习成绩。一个关键发现是，这种缺失的模式并非随机，可能会导致估计的熟练度值出现偏差。为此，我们将认知诊断问题形式化为一个样本选择问题，其中观察值是通过与学生回答正确性和学生及练习特征相关的非随机概率进行采样的。我们提出了一种简单但有效的方法，称为HeckmanCD，该方法采用Heckman两阶段方法来缓解这种内生性问题。首先，我们使用一个交互模型来预测特定学生-练习对的发生概率。随后，从该交互模型中得出的选择变量被纳入认知诊断框架中，作为受控的自变量。我们的分析表明，在存在混杂因素的情况下，项目反应理论模型的朴素估计本质上是有偏的，而我们的方法通过捕捉协方差可以纠正这种偏差。所提出的HeckmanCD方法可以应用于大多数现有的认知诊断模型，包括深度模型，并且实证评估显示了该方法的有效性，而无需其他辅助信息，如练习的文本描述。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HeckmanCD:+Exploiting+Selection+Bias+in+Cognitive+Diagnosis)|0|
|[Spatio-Temporal Transformer Network with Physical Knowledge Distillation for Weather Forecasting](https://doi.org/10.1145/3627673.3679841)|Jing He, Junzhong Ji, Minglong Lei|College of Computer Science, Beijing University of Technology, Beijing, China|Weather forecasting has become a popular research topic recently, which mainly benefits from the development of spatio-temporal neural networks to effectively extract useful patterns from weather data. Generally, the weather changes in the meteorological system are governed by physical principles. However, it is challenging for spatio-temporal methods to capture the physical knowledge of meteorological dynamics. To address this problem, we propose in this paper a spatio-temporal Transformer network with physical knowledge distillation (PKD-STTN) for weather forecasting. First, the teacher network is implemented by a differential equation network that models weather changes by the potential energy in the atmosphere to reveal the physical mechanism of atmospheric movements. Second, the student network uses a spatio-temporal Transformer that concurrently utilizes three attention modules to comprehensively capture the semantic spatial correlation, geographical spatial correlation, and temporal correlation from weather data. Finally, the physical knowledge of the teacher network is transferred to the student network by inserting a distillation position encoding into the Transformer. Notice that the output of the teacher network is distilled to the position encoding rather than the output of the student network, which can largely utilize physical knowledge without influencing the feature extraction process of Transformers. Experiments on benchmark datasets show that the proposed method can effectively utilize physical principles of weather changes and has obvious performance advantages compared with several strong baselines.|天气预报近年来成为热门研究课题，主要得益于时空神经网络的发展，能够有效从天气数据中提取有用模式。通常，气象系统中的天气变化受物理原理支配。然而，时空方法难以捕捉气象动力学的物理知识。为解决此问题，本文提出一种融入物理知识蒸馏的时空Transformer网络（PKD-STTN）用于天气预报。首先，教师网络采用微分方程网络，通过大气中的势能建模天气变化，揭示大气运动的物理机制。其次，学生网络使用时空Transformer，同时利用三个注意力模块全面捕捉天气数据中的语义空间相关性、地理空间相关性和时间相关性。最后，通过插入蒸馏位置编码，将教师网络的物理知识传递给学生网络。注意，教师网络的输出被蒸馏至位置编码而非学生网络的输出，这样可以在不影响Transformer特征提取过程的情况下充分利用物理知识。在基准数据集上的实验表明，所提方法能有效利用天气变化的物理原理，相比多个强基线方法具有明显的性能优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spatio-Temporal+Transformer+Network+with+Physical+Knowledge+Distillation+for+Weather+Forecasting)|0|
|[New Localization Frameworks: User-centric Approaches to Source Localization in Real-world Propagation Scenarios](https://doi.org/10.1145/3627673.3679796)|Dongpeng Hou, Yuchen Wang, Chao Gao, Xianghua Li, Zhen Wang|Northwestern Polytechnical University, Xi'an, Shaanxi, China|Source localization in social platforms is critical for managing and controlling the misinformation spreading. Despite all the recent advancements, existing methods do not consider the dynamic and heterogeneous propagation behaviors of users and are developed based on simulated data with strong model assumptions, limiting the application in real-world scenarios. This research addresses this limitation by presenting a novel framework for source localization, grounded in real-world propagation cascades from platforms like Weibo and Twitter. What's more, recognizing the user-driven nature of users in information spread, we systematically crawl and integrate user-specific profiles, offering a realistic understanding of user-driven propagation dynamics. In summary, by developing datasets derived from real-world propagation cascades, we set a precedent in enhancing the authenticity and practice of source identification for social media. Our comprehensive experiments not only validate the feasibility and rationale of our novel user-centric localization approaches but also emphasize the significance of considering user profiles in real-world propagation scenarios. The code is available at https://github.com/cgao-comp/NFSL.|社交平台中的信息源定位对于管理和控制虚假信息的传播至关重要。尽管近年来取得了诸多进展，但现有方法并未考虑用户传播行为的动态性和异质性，并且这些方法基于具有强假设的模拟数据开发，限制了其在现实场景中的应用。本研究通过提出一种基于微博和推特等平台真实传播链的全新源定位框架，解决了这一局限性。此外，鉴于信息传播中用户驱动的特性，我们系统地爬取并整合了用户特定的个人资料，从而提供了对用户驱动传播动态的真实理解。总之，通过开发源自真实传播链的数据集，我们为增强社交媒体源识别的真实性和实用性树立了先例。我们的全面实验不仅验证了我们以用户为中心的新型定位方法的可行性和合理性，还强调了在现实传播场景中考虑用户个人资料的重要性。代码已公开，详见 https://github.com/cgao-comp/NFSL。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=New+Localization+Frameworks:+User-centric+Approaches+to+Source+Localization+in+Real-world+Propagation+Scenarios)|0|
|[Physics-guided Active Sample Reweighting for Urban Flow Prediction](https://doi.org/10.1145/3627673.3679738)|Wei Jiang, Tong Chen, Guanhua Ye, Wentao Zhang, Lizhen Cui, Zi Huang, Hongzhi Yin||Urban flow prediction is a spatio-temporal modeling task that estimates the throughput of transportation services like buses, taxis, and ride-sharing, where data-driven models have become the most popular solution in the past decade. Meanwhile, the implicitly learned mapping between historical observations to the prediction targets tend to over-simplify the dynamics of real-world urban flows, leading to suboptimal predictions. Some recent spatio-temporal prediction solutions bring remedies with the notion of physics-guided machine learning (PGML), which describes spatio-temporal data with nuanced and principled physics laws, thus enhancing both the prediction accuracy and interpretability. However, these spatio-temporal PGML methods are built upon a strong assumption that the observed data fully conforms to the differential equations that define the physical system, which can quickly become ill-posed in urban flow prediction tasks. The observed urban flow data, especially when sliced into time-dependent snapshots to facilitate predictions, is typically incomplete and sparse, and prone to inherent noise incurred in the collection process. As a result, such physical inconsistency between the data and PGML model significantly limits the predictive power and robustness of the solution. Moreover, due to the interval-based predictions and intermittent nature of data filing in many transportation services, the instantaneous dynamics of urban flows can hardly be captured, rendering differential equation-based continuous modeling a loose fit for this setting. To overcome the challenges, we develop a discretized physics-guided network (PN), and propose a data-aware framework Physics-guided Active Sample Reweighting (P-GASR) to enhance PN. Experimental results in four real-world datasets demonstrate that our method achieves state-of-the-art performance with a demonstrable improvement in robustness.|城市流量预测是一项时空建模任务，旨在估算公交车、出租车和共享出行等交通服务的吞吐量，其中数据驱动模型在过去十年中已成为最受欢迎的解决方案。然而，隐式学习的历史观测与预测目标之间的映射关系往往过于简化现实世界中城市流量的动态特性，导致预测效果不佳。近期，一些时空预测解决方案引入了物理引导机器学习（PGML）的概念，通过利用细致且基于物理定律的描述来增强预测的准确性和可解释性。然而，这些时空PGML方法基于一个强假设，即观测数据完全符合定义物理系统的微分方程，这在城市流量预测任务中往往难以成立。观测到的城市流量数据，尤其是为了便于预测而分割成时间依赖的快照时，通常是不完整且稀疏的，并且容易受到采集过程中固有噪声的影响。因此，数据与PGML模型之间的物理不一致性显著限制了该解决方案的预测能力和鲁棒性。此外，由于许多交通服务中的数据记录是基于时间间隔的，并且具有间歇性，难以捕捉城市流量的瞬时动态，使得基于微分方程的连续建模方法在此场景下并不适用。为应对这些挑战，我们开发了一种离散化的物理引导网络（PN），并提出了一种数据感知框架——物理引导主动样本重加权（P-GASR），以增强PN的性能。在四个真实世界数据集上的实验结果表明，我们的方法在实现最先进性能的同时，显著提升了模型的鲁棒性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Physics-guided+Active+Sample+Reweighting+for+Urban+Flow+Prediction)|0|
|[Federated Heterogeneous Contrastive Distillation for Molecular Representation Learning](https://doi.org/10.1145/3627673.3679725)|Jinjia Feng, Zhen Wang, Zhewei Wei, Yaliang Li, Bolin Ding, Hongteng Xu|Alibaba Group, Bellevue, CA, USA; Peng Cheng Laboratory & Renmin University of China, Shenzhen, China; Renmin University of China, Beijing, China; Alibaba Group, Bellevue, WA, USA; Sun Yat-sen University, Guangzhou, China|With the increasing application of deep learning to solve scientific problems in biochemistry, molecular federated learning has become popular due to its ability to offer distributed privacy-preserving solutions. However, most existing molecular federated learning methods rely on joint training with public datasets, which are difficult to obtain in practice. These methods also fail to leverage multi-modal molecular representations effectively. To address the above issues, we propose a novel framework, Federated Heterogeneous Contrastive Distillation (FedHCD), which enables to jointly train global models from clients with heterogeneous data modalities, learning tasks, and molecular models. To aggregate data representations of different modalities in a data-free manner, we design a global multi-modal contrastive strategy to align the representation of clients without public dataset. Utilizing intrinsic characteristics of molecular data in different modalities, we tackle the exacerbation of local model drift and data Non-IIDness caused by multi-modal clients. We introduce a multi-view contrastive knowledge transfer to extract features from atoms, substructures, and molecules, solving the issue of information distillation failure due to dimensional biases in different data modalities. Our evaluations on eight real-world molecular datasets and ablation experiments show that FedHCD outperforms other state-of-the-art FL methods, irrespective of whether or not they use public datasets.|随着深度学习在解决生物化学领域科学问题中的应用日益增多，分子联邦学习因其能够提供分布式隐私保护解决方案而受到广泛关注。然而，现有的大多数分子联邦学习方法依赖于与公共数据集的联合训练，这在实际中难以获取。此外，这些方法未能有效利用多模态分子表示。为解决上述问题，我们提出了一种新颖的框架——联邦异构对比蒸馏（Federated Heterogeneous Contrastive Distillation, FedHCD），该框架能够从具有异构数据模态、学习任务和分子模型的客户端中联合训练全局模型。为了在无需数据的情况下聚合不同模态的数据表示，我们设计了一种全局多模态对比策略，以对齐客户端的表示，而不依赖于公共数据集。利用不同模态分子数据的内禀特性，我们解决了多模态客户端导致的局部模型漂移和数据非独立同分布（Non-IID）问题。我们引入了一种多视角对比知识迁移方法，从原子、子结构和分子中提取特征，解决了由于不同数据模态间的维度偏差导致的信息蒸馏失败问题。我们在八个真实世界的分子数据集上进行了评估和消融实验，结果表明，无论是否使用公共数据集，FedHCD均优于其他最先进的联邦学习方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Federated+Heterogeneous+Contrastive+Distillation+for+Molecular+Representation+Learning)|0|
|[Discrepancy-guided Channel Dropout for Domain Generalization](https://doi.org/10.1145/3627673.3679539)|Seonggyeom Kim, Byeongtae Park, Harim Lee, DongKyu Chae|Hanyang University, Seoul, Republic of Korea|Deep Neural Networks (DNNs) tend to perform poorly on unseen domains due to domain shifts. Domain Generalization (DG) aims to improve the performance on such scenarios by minimizing the distribution discrepancy between source domains. Among many studies, dropout-based DG approaches which remove domain-specific features have gained attention. However, they are limited in minimizing the upper bound of generalization risk because they do not explicitly consider the distribution discrepancy when discarding features. In this paper, we propose a novel Discrepancy-guided Channel Dropout (DgCD) for DG that explicitly derives the discrepancy between domains and drops the channels with significant distribution discrepancy. Given a training batch, we perform two ways of standardization: (1) based on the variance/mean of the batch (i.e., sampled from all source domains) and (2) based on the variance/mean of domain-wise samples in the batch. With the two normal distributions, we explicitly derive the discrepancy using KL-divergence and backpropagate it towards each channel. A channel with a higher contribution to the discrepancy is more likely to be dropped. Experimental results show the superiority of DgCD over the state-of-the-art DG baselines, demonstrating the effectiveness of our dropout strategy which is directly coupled to reducing the domain discrepancy. Our code is available at: https://github.com/gyeomo/DgCD|深度神经网络（DNNs）在面对未见过的领域时往往表现不佳，这是由于领域转移造成的。领域泛化（Domain Generalization, DG）旨在通过最小化源领域之间的分布差异来提升在这些场景下的性能。在众多研究中，基于dropout的DG方法因其能够去除领域特定特征而受到关注。然而，这些方法在最小化泛化风险的上界方面存在局限，因为它们在丢弃特征时并未明确考虑分布差异。本文提出了一种新颖的差异引导通道dropout（Discrepancy-guided Channel Dropout, DgCD）方法，用于领域泛化，该方法明确地推导出领域间的差异，并丢弃具有显著分布差异的通道。在给定的训练批次中，我们执行两种标准化方式：（1）基于批次的方差/均值（即从所有源领域中采样）；（2）基于批次中各领域样本的方差/均值。通过这两个正态分布，我们使用KL散度明确地推导出差异，并将其反向传播到每个通道。对差异贡献较大的通道更有可能被丢弃。实验结果表明，DgCD在性能上优于当前最先进的领域泛化基线方法，证明了我们的dropout策略能直接减少领域差异的有效性。我们的代码已公开，地址为：https://github.com/gyeomo/DgCD。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Discrepancy-guided+Channel+Dropout+for+Domain+Generalization)|0|
|[Efficient and Secure Contribution Estimation in Vertical Federated Learning](https://doi.org/10.1145/3627673.3679613)|Juan Li, Rui Deng, Tianzi Zang, Mingqi Kong, Kun Zhu|Nanjing University of Aeronautics and Astronautics, Nanjing, China|As necessary information about whether cooperation can be reached, rewards should be determined in advance in Vertical Federated Learning (VFL). To determine reasonable rewards, participant contributions should be estimated precisely. We propose a Vertically Federated Contribution Estimation (VF-CE) method. VF-CE calculates Mutual Information (MI) between distributed features and the label using a neural network trained via VFL itself. Note that compensation for CE is low as it only covers computation costs, and reward for real VFL training is high as it needs to cover training costs as well as participants' contributions to model performance and the resulting business benefits. Because MI presents a strong positive correlation with the final model performance, contributions to model performance can be estimated based on contributions to MI. We integrate a scalar-level attention mechanism in MI neural network. The attention weights of participants are treated as their contributions. We find that attention weights can effectively measure contribution redundancy, as its Spearman correlation coefficient with Shapley value is as high as 0.963. We demonstrate that VF-CE also satisfies properties of balance, zero element, and symmetry concerning fairness, which are hallmark properties of Shapley value. Compared with existing work, we consider contribution redundancy precisely, efficiently output approximated Shapley values through one MI calculation instead of 2 n where n is the number of participants, and introduce no extra privacy risk except the inherent risk in VFL, i.e., gradient transmission.|在纵向联邦学习（Vertical Federated Learning, VFL）中，为了确定合作是否能够达成，奖励应提前设定。为了设定合理的奖励，参与者的贡献应被精确估计。我们提出了一种纵向联邦贡献估计（Vertically Federated Contribution Estimation, VF-CE）方法。VF-CE通过使用VFL自身训练的神经网络计算分布式特征与标签之间的互信息（Mutual Information, MI）。需要注意的是，CE的补偿较低，因为它仅涵盖计算成本，而实际VFL训练的奖励较高，因为它需要涵盖训练成本以及参与者对模型性能和由此产生的业务效益的贡献。由于MI与最终模型性能呈现强正相关，因此可以通过MI的贡献来估计对模型性能的贡献。我们在MI神经网络中集成了一个标量级别的注意力机制，将参与者的注意力权重视为他们的贡献。我们发现，注意力权重能够有效衡量贡献冗余，其与Shapley值的Spearman相关系数高达0.963。我们证明，VF-CE在公平性方面也满足平衡性、零元素和对称性等特性，这些是Shapley值的标志性特性。与现有工作相比，我们精确考虑了贡献冗余，通过一次MI计算高效输出近似的Shapley值，而不是2^n次计算（其中n是参与者的数量），并且除了VFL固有的梯度传输隐私风险外，不引入额外的隐私风险。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+and+Secure+Contribution+Estimation+in+Vertical+Federated+Learning)|0|
|[MoTTo: Scalable Motif Counting with Time-aware Topology Constraint for Large-scale Temporal Graphs](https://doi.org/10.1145/3627673.3679694)|Jiantao Li, Jianpeng Qi, Yueling Huang, Lei Cao, Yanwei Yu, Junyu Dong|Ocean University of China, Qingdao, China; Ocean University of China, Qingdao, Shandong, China; University of Arizona, Tucson, USA|Temporal motifs are recurring subgraph patterns in temporal graphs, and are present in various domains such as social networks, fraud detection, and biological networks. Despite their significance, counting temporal motifs efficiently remains a challenge, particularly on moderately sized datasets with millions of motif instances. To address this challenge, we propose a novel algorithm called Scalable Motif Counting with Time-aware Topology Constraint (MoTTo). MoTTo focuses on accurately counting temporal motifs with up to three nodes and three edges. It first utilizes a topology constraint-based pruning strategy to eliminate nodes that cannot participate in forming temporal motifs before the counting process. Then, it adopts a time-aware topology constraint-based pruning strategy to split large-scale datasets into independent partitions and filter out the unrelated ones, ensuring that the counting results remain unaffected. By investigating the second pruning strategy, we also find that MoTTo can be implemented in a multi-thread manner, further accelerating the counting process significantly. Experimental results on several real-world datasets of varying sizes demonstrate that MoTTo outperforms state-of-the-art methods in terms of efficiency, achieving up to a nine-fold improvement in total temporal motif counting. Specifically, the efficiency of counting triangular temporal motifs is enhanced by up to 31 times compared to state-of-the-art baselines.|时态模体是在时态图中重复出现的子图模式，广泛存在于社交网络、欺诈检测和生物网络等多个领域。尽管它们具有重要意义，但高效地统计时态模体仍然是一个挑战，尤其是在包含数百万模体实例的中等规模数据集上。为了应对这一挑战，我们提出了一种名为“带有时态拓扑约束的可扩展模体计数”（MoTTo）的新算法。MoTTo专注于精确统计包含最多三个节点和三条边的时态模体。首先，它利用基于拓扑约束的剪枝策略，在计数过程之前排除无法参与形成时态模体的节点。接着，它采用基于时态拓扑约束的剪枝策略，将大规模数据集分割成独立的分区并过滤掉无关部分，从而确保计数结果不受影响。通过研究第二种剪枝策略，我们还发现MoTTo可以实现多线程处理，进一步显著加速计数过程。在多个不同规模的实际数据集上的实验结果表明，MoTTo在效率方面优于当前最先进的方法，总时态模体计数效率提升高达九倍。具体而言，与最先进的基线方法相比，三角形时态模体的计数效率提高了多达31倍。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MoTTo:+Scalable+Motif+Counting+with+Time-aware+Topology+Constraint+for+Large-scale+Temporal+Graphs)|0|
|[LagCNN: A Fast yet Effective Model for Multivariate Long-term Time Series Forecasting](https://doi.org/10.1145/3627673.3679672)|Linsen Li, Chunfei Jian, Feng Wan, Dongdong Geng, Ziquan Fang, Lu Chen, Yunjun Gao, Weihao Jiang, Jiang Zhu|Zhejiang University, Hangzhou, China; Hikvision Research Institute, Hangzhou, China; Zhejiang University & Hikvision Research Institute, Hangzhou, China|Long-term time series forecasting has gained significant attention in recent years due to its widely-application in various fields. Transformer-based models have gained popularity for the ability to capture long-sequence interactions. However, these models are limited in real-world use because of the memory consumption and computation explosion. The CNN-based models are also one of the main models used for time series prediction, but their performance has always been inferior to the transformer-based models in previous works. We have reconsidered the role of CNN components and redefined the way CNN basic components are used for time series prediction. In addition, the time lags information between periods in the time series is important. Unfortunately, existing works lack consideration of this classic but important information. Motivated by these factors, we propose a fast yet effective CNN model with time lags for multivariate long-term time series forecasting, named LagCNN. Specifically, the time series is transformed into lag-patches to capture the correlation between periods. Then, a fast CNN model is performed in the feature dimension rather than the time dimension like most previous works do. Meanwhile, information aggregation is performed in the time dimension to extract complex temporal patterns. LagCNN significantly outperforms state-of-the-art on multiple publicly available datasets. One step further, LagCNN exhibits significant efficiency advantages over the most efficient Transformer model (PatchTST), resulting in a significant reduction in memory usage (4.4×) and runtime (10.7×).|长期时间序列预测近年来因其广泛的应用而备受关注。基于Transformer的模型因其捕捉长序列交互的能力而受到欢迎。然而，这些模型在实际应用中受到限制，因为它们存在内存消耗和计算爆炸的问题。基于CNN的模型也是用于时间序列预测的主要模型之一，但它们在以往的研究中的表现一直不如基于Transformer的模型。我们重新考虑了CNN组件的作用，并重新定义了用于时间序列预测的CNN基本组件的使用方式。此外，时间序列中各周期之间的时间滞后信息非常重要。遗憾的是，现有研究缺乏对这一经典但重要信息的考虑。受这些因素的启发，我们提出了一种快速且有效的CNN模型，用于多元长期时间序列预测，命名为LagCNN。具体来说，时间序列被转换为滞后补丁，以捕捉周期之间的相关性。然后，在特征维度而不是像大多数先前的工作那样在时间维度上执行快速CNN模型。同时，在时间维度上进行信息聚合，以提取复杂的时间模式。LagCNN在多个公开可用的数据集上显著优于最先进的方法。进一步地，LagCNN在与最有效的Transformer模型（PatchTST）相比时表现出显著的效率优势，导致内存使用量（4.4倍）和运行时间（10.7倍）大幅减少。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LagCNN:+A+Fast+yet+Effective+Model+for+Multivariate+Long-term+Time+Series+Forecasting)|0|
|[Noise-Resilient Unsupervised Graph Representation Learning via Multi-Hop Feature Quality Estimation](https://doi.org/10.1145/3627673.3679758)|Shiyuan Li, Yixin Liu, Qingfeng Chen, Geoffrey I. Webb, Shirui Pan||Unsupervised graph representation learning (UGRL) based on graph neural networks (GNNs), has received increasing attention owing to its efficacy in handling graph-structured data. However, existing UGRL methods ideally assume that the node features are noise-free, which makes them fail to distinguish between useful information and noise when applied to real data with noisy features, thus affecting the quality of learned representations. This urges us to take node noisy features into account in real-world UGRL. With empirical analysis, we reveal that feature propagation, the essential operation in GNNs, acts as a "double-edged sword" in handling noisy features - it can both denoise and diffuse noise, leading to varying feature quality across nodes, even within the same node at different hops. Building on this insight, we propose a novel UGRL method based on Multi-hop feature Quality Estimation (MQE for short). Unlike most UGRL models that directly utilize propagation-based GNNs to generate representations, our approach aims to learn representations through estimating the quality of propagated features at different hops. Specifically, we introduce a Gaussian model that utilizes a learnable "meta-representation" as a condition to estimate the expectation and variance of multi-hop propagated features via neural networks. In this way, the "meta representation" captures the semantic and structural information underlying multiple propagated features but is naturally less susceptible to interference by noise, thereby serving as high-quality node representations beneficial for downstream tasks. Extensive experiments on multiple real-world datasets demonstrate that MQE in learning reliable node representations in scenarios with diverse types of feature noise.|基于图神经网络（GNN）的无监督图表示学习（UGRL）因其有效处理图结构数据的能力而受到越来越多的关注。然而，现有的UGRL方法理想化地假设节点特征是无噪声的，这使得它们在应用于具有噪声特征的真实数据时，无法区分有用信息和噪声，从而影响学习到的表示质量。这促使我们在现实世界的UGRL中考虑节点噪声特征。通过实证分析，我们揭示了特征传播——GNN中的基本操作——在处理噪声特征时起到了“双刃剑”的作用——它既能去噪又能扩散噪声，导致不同节点之间的特征质量不同，甚至在同一节点的不同跳数之间也存在差异。基于这一见解，我们提出了一种基于多跳特征质量估计（MQE）的新型UGRL方法。与大多数直接利用基于传播的GNN生成表示的UGRL模型不同，我们的方法旨在通过估计不同跳数传播特征的质量来学习表示。具体来说，我们引入了一个高斯模型，该模型利用可学习的“元表示”作为条件，通过神经网络估计多跳传播特征的期望和方差。通过这种方式，“元表示”捕捉了多个传播特征背后的语义和结构信息，但自然较少受到噪声的干扰，从而作为高质量的节点表示，有利于下游任务。在多个真实世界数据集上的广泛实验表明，MQE在处理具有多种特征噪声的场景中能够学习到可靠的节点表示。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Noise-Resilient+Unsupervised+Graph+Representation+Learning+via+Multi-Hop+Feature+Quality+Estimation)|0|
|[Aligning Large Language Models to a Domain-specific Graph Database for NL2GQL](https://doi.org/10.1145/3627673.3679713)|Yuanyuan Liang, Keren Tan, Tingyu Xie, Wenbiao Tao, Siyuan Wang, Yunshi Lan, Weining Qian||Graph Databases (Graph DB) find extensive application across diverse domains such as finance, social networks, and medicine. Yet, the translation of Natural Language (NL) into the Graph Query Language (GQL), referred to as NL2GQL, poses significant challenges owing to its intricate and specialized nature. Some approaches have sought to utilize Large Language Models (LLMs) to address analogous tasks like text2SQL. Nonetheless, in the realm of NL2GQL tasks tailored to a particular domain, the absence of domain-specific NL-GQL data pairs adds complexity to aligning LLMs with the graph DB. To tackle this challenge, we present a well-defined pipeline. Initially, we utilize ChatGPT to generate NL-GQL data pairs, leveraging the provided graph DB with self-instruction. Subsequently, we employ the generated data to fine-tune LLMs, ensuring alignment between LLMs and the graph DB. Moreover, we find the importance of relevant schema in efficiently generating accurate GQLs. Thus, we introduce a method to extract relevant schema as the input context. We evaluate our method using two carefully constructed datasets derived from graph DBs in the finance and medicine domains, named FinGQL and MediGQL. Experimental results reveal that our approach significantly outperforms a set of baseline methods, with improvements of 5.90 and 6.36 absolute points on EM, and 6.00 and 7.09 absolute points on EX for FinGQL and MediGQL, respectively.|图数据库（Graph Databases，简称Graph DB）在金融、社交网络、医药等多个领域得到了广泛应用。然而，将自然语言（Natural Language，简称NL）转化为图查询语言（Graph Query Language，简称GQL），即NL2GQL，由于其复杂且专业化的特性，面临着重大挑战。一些方法尝试利用大型语言模型（Large Language Models，简称LLMs）来解决类似任务，如text2SQL。然而，在针对特定领域的NL2GQL任务中，缺乏领域特定的NL-GQL数据对，增加了将LLMs与图数据库对齐的复杂性。为了应对这一挑战，我们提出了一条明确的工作流程。首先，我们利用ChatGPT生成NL-GQL数据对，通过自指令机制利用提供的图数据库。接着，我们使用生成的数据对LLMs进行微调，确保LLMs与图数据库的对齐。此外，我们发现相关模式在高效生成准确GQL中的重要性。因此，我们引入了一种方法，提取相关模式作为输入上下文。我们通过从金融和医药领域图数据库构建的两个精心设计的测试集——FinGQL和MediGQL，来评估我们的方法。实验结果显示，我们的方法显著优于一组基线方法，FinGQL和MediGQL在EM上的提升分别为5.90和6.36个绝对点，在EX上的提升分别为6.00和7.09个绝对点。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Aligning+Large+Language+Models+to+a+Domain-specific+Graph+Database+for+NL2GQL)|0|
|[ITIU: Intention Understanding via Interactive Table in Large Language Models](https://doi.org/10.1145/3627673.3679688)|Zenghua Liao, Jinzhi Liao, Xiang Zhao||Large language models (LLMs) have shown impressive success in various applications. However, they encounter issues in accurately understanding user intentions, thereby impeding the successful accomplishment of tasks. The pioneering study tackles intention understanding through iteratively interacting with users to enhance response quality; however, it fails to identify the notorious challenges associated with the task, where efficiency and accuracy are paramount for ensuring optimal user experience. To address these challenges, we introduce a new interactive table based intention understanding (ITIU) framework, which refers to and implements non-linear thinking in psychology such that details of intention are parallelly generated. Specifically, in the table interacting design phase, ITIU first brainstorms a more concrete intention table relevant to user instructions and subsequently incorporates a rule-based supervision mechanism to enhance the accuracy of its content. In the specialized model training phase, we obtain the procedural records generated by ITIU to develop a specialized upstream interactive intention understanding model. The specialized model replaces internal steps within the original interaction design for further efficiency improvement. Comprehensive experimental results demonstrate that ITIU significantly outperforms existing intention understanding methods, particularly in terms of interaction efficiency and intention understanding accuracy. Furthermore, whether integrated into the open-source LLaMA or powerful LLMs like GPT-4 and Claude-3, ITIU shows significant performance improvements. All the data and codes are released.|大型语言模型（LLMs）在多种应用中展现了卓越的性能。然而，它们在准确理解用户意图方面存在问题，这阻碍了任务的成功完成。先驱性研究通过与用户迭代交互来提升响应质量，但未能识别出该任务中臭名昭著的挑战，即效率和准确性对于确保最佳用户体验至关重要。为应对这些挑战，我们提出了一种新的基于交互式表格的意图理解（ITIU）框架，该框架借鉴并实现了心理学中的非线性思维，从而并行生成意图细节。具体来说，在表格交互设计阶段，ITIU首先针对用户指令进行头脑风暴，生成一个更为具体的意图表，随后引入基于规则的监督机制以提高其内容的准确性。在专业模型训练阶段，我们获取ITIU生成的程序记录，以开发一个专门的上游交互意图理解模型。该专业模型取代了原始交互设计中的内部步骤，从而进一步提升了效率。全面的实验结果表明，ITIU在交互效率和意图理解准确性方面显著优于现有的意图理解方法。此外，无论是在开源的LLaMA还是强大的LLMs如GPT-4和Claude-3中集成，ITIU都展现了显著的性能提升。所有数据和代码均已发布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ITIU:+Intention+Understanding+via+Interactive+Table+in+Large+Language+Models)|0|
|[Unveiling Intellectual Property Vulnerabilities of GAN-Based Distributed Machine Learning through Model Extraction Attacks](https://doi.org/10.1145/3627673.3679850)|Mengyao Ma, Shuofeng Liu, M. A. P. Chamikara, Mohan Baruwal Chhetri, Guangdong Bai|; The University of Queensland, Brisbane, Australia; The University of Queensland & CSIRO's Data61, Brisbane, Australia; CSIRO's Data61, Melbourne, Australia|Generative Adversarial Networks (GANs), as a cornerstone of artificial intelligence (AI), are widely recognized as the intellectual property (IP) of their owners, given the sensitivity of the training data and the commercial value tied to the models. Model extraction attacks, which aim to steal well-trained proprietary models, pose a significant threat to model IP. Nevertheless, current research predominately focuses on the context of machine learning as a service (MLaaS), where the emphasis lies in understanding the attack knowledge acquired through black-box API queries. This restricted perspective exposes a critical gap in investigating model extraction attacks within realistic distributed settings for generative tasks. In this work, we present the first investigation into model extraction attacks against GANs in distributed settings. We provide a comprehensive attack taxonomy, considering three different levels of knowledge the adversary can obtain in practice. Based on it, we introduce a novel model extraction attack named MoEx, which focuses on the GAN-based distributed learning scenario, i.e., Multi-Discriminator GANs, a typical asymmetric distributed setting. MoEx uses the objective function simulation, leveraging data exchanged during the learning process, to approximate the GAN generator owned by the server. We define two attack goals for MoEx, fidelity extraction and accuracy extraction. Then we comprehensively evaluate the effectiveness of MoEx's two goals with real-world datasets. Our results demonstrate its robust capabilities in extracting generators with high fidelity and accuracy compared with existing methods.|生成对抗网络（GANs）作为人工智能（AI）的基石，因其训练数据的敏感性和与模型相关的商业价值，被广泛认为是其所有者的知识产权（IP）。模型提取攻击旨在窃取经过良好训练的专有模型，对模型IP构成了重大威胁。然而，当前的研究主要集中在机器学习即服务（MLaaS）的背景下，重点是通过黑箱API查询获取的攻击知识。这种有限的视角暴露了在生成任务的现实分布式环境中研究模型提取攻击的关键空白。在本研究中，我们首次探讨了分布式环境中针对GAN的模型提取攻击。我们提供了一个全面的攻击分类法，考虑了对手在实践中可以获得的三种不同层次的知识。基于此，我们引入了一种名为MoEx的新型模型提取攻击，专注于基于GAN的分布式学习场景，即多判别器GAN（Multi-Discriminator GANs），这是一种典型的非对称分布式设置。MoEx利用学习过程中交换的数据进行目标函数模拟，以近似服务器拥有的GAN生成器。我们为MoEx定义了两个攻击目标：保真度提取和准确度提取。然后，我们使用真实世界的数据集全面评估了MoEx两个目标的有效性。我们的结果表明，与现有方法相比，MoEx在提取具有高保真度和准确度的生成器方面具有强大的能力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unveiling+Intellectual+Property+Vulnerabilities+of+GAN-Based+Distributed+Machine+Learning+through+Model+Extraction+Attacks)|0|
|[Semantic Prototypes: Enhancing Transparency without Black Boxes](https://doi.org/10.1145/3627673.3679795)|Orfeas MenisMastromichalakis, Giorgos Filandrianos, Jason Liartis, Edmund Dervakos, Giorgos Stamou||As machine learning (ML) models and datasets increase in complexity, the demand for methods that enhance explainability and interpretability becomes paramount. Prototypes, by encapsulating essential characteristics within data, offer insights that enable tactical decision-making and enhance transparency. Traditional prototype methods often rely on sub-symbolic raw data and opaque latent spaces, reducing explainability and increasing the risk of misinterpretations. This paper presents a novel framework that utilizes semantic descriptions to define prototypes and provide clear explanations, effectively addressing the shortcomings of conventional methods. Our approach leverages concept-based descriptions to cluster data on the semantic level, ensuring that prototypes not only represent underlying properties intuitively but are also straightforward to interpret. Our method simplifies the interpretative process and effectively bridges the gap between complex data structures and human cognitive processes, thereby enhancing transparency and fostering trust. Our approach outperforms existing widely-used prototype methods in facilitating human understanding and informativeness, as validated through a user survey.|随着机器学习（ML）模型和数据集的复杂性不断增加，提高可解释性和可理解性的方法需求变得至关重要。原型通过封装数据中的关键特征，提供了有助于战术决策和增强透明度的洞察力。传统的原型方法通常依赖于亚符号的原始数据和模糊的潜在空间，这降低了可解释性并增加了误解的风险。本文提出了一种新颖的框架，利用语义描述来定义原型并提供清晰的解释，有效解决了传统方法的不足。我们的方法利用基于概念的描述在语义层面上对数据进行聚类，确保原型不仅直观地代表底层属性，而且易于解释。我们的方法简化了解释过程，有效地弥合了复杂数据结构与人类认知过程之间的差距，从而增强了透明度并促进了信任。通过用户调查验证，我们的方法在促进人类理解和信息量方面优于现有广泛使用的原型方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Semantic+Prototypes:+Enhancing+Transparency+without+Black+Boxes)|0|
|[Revisiting Optimal Window Aggregation in Data Streams: The Prefix-Sum Approach](https://doi.org/10.1145/3627673.3679573)|José Martinez, Guillaume Raschia|LS2N UMR CNRS 6004 Nantes Université, Nantes, France|The article presents a simple yet optimal approach to compute aggregates of window queries over data streams. The proposal is built as a fully-fledged pipeline of operators that are literal transcripts of mathematical definitions. Main features are an application of the prefix sums and a well-founded un-/slicing technique. The overall process is linear in the number of events and windows, and it takes quasi-constant space for a mix of periodic windows, still applicable to multiple deterministic window queries. The limitations are twofold: the events come in-order and the aggregation function is a left-cancellative monoid.|本文提出了一种简单但最优的方法来计算数据流上的窗口查询聚合。该方案构建为一个完整的操作符流水线，这些操作符直接对应于数学定义。其主要特点是应用了前缀和以及一种基于充分理论基础的分片/解片技术。整个过程在事件数量和窗口数量上是线性的，并且对于周期性窗口的混合，其空间复杂度接近常数，同时仍然适用于多个确定性窗口查询。该方法的局限性有两点：事件必须按顺序到达，且聚合函数是一个左可消幺半群。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revisiting+Optimal+Window+Aggregation+in+Data+Streams:+The+Prefix-Sum+Approach)|0|
|[Adaptive Cascading Network for Continual Test-Time Adaptation](https://doi.org/10.1145/3627673.3679801)|Kien X. Nguyen, Fengchun Qiao, Xi Peng||We study the problem of continual test-time adaption where the goal is to adapt a source pre-trained model to a sequence of unlabelled target domains at test time. Existing methods on test-time training suffer from several limitations: (1) Mismatch between the feature extractor and classifier; (2) Interference between the main and self-supervised tasks; (3) Lack of the ability to quickly adapt to the current distribution. In light of these challenges, we propose a cascading paradigm that simultaneously updates the feature extractor and classifier at test time, mitigating the mismatch between them and enabling long-term model adaptation. The pre-training of our model is structured within a meta-learning framework, thereby minimizing the interference between the main and self-supervised tasks and encouraging fast adaptation in the presence of limited unlabelled data. Additionally, we introduce innovative evaluation metrics, average accuracy and forward transfer, to effectively measure the model's adaptation capabilities in dynamic, real-world scenarios. Extensive experiments and ablation studies demonstrate the superiority of our approach in a range of tasks including image classification, text classification, and speech recognition.|我们研究了持续测试时适应的问题，其目标是在测试阶段将源预训练模型适应到一系列未标记的目标领域。现有的测试时训练方法存在几个局限性：(1) 特征提取器与分类器之间的不匹配；(2) 主任务与自监督任务之间的干扰；(3) 缺乏快速适应当前分布的能力。针对这些挑战，我们提出了一种级联范式，该范式在测试时同时更新特征提取器和分类器，从而缓解它们之间的不匹配问题，并实现长期模型适应。我们的模型预训练在元学习框架内进行结构化设计，从而最小化了主任务与自监督任务之间的干扰，并在有限未标记数据的情况下促进了快速适应。此外，我们引入了创新的评估指标——平均准确率和前向迁移，以有效衡量模型在动态、现实场景中的适应能力。广泛的实验和消融研究表明，我们的方法在图像分类、文本分类和语音识别等一系列任务中表现优越。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adaptive+Cascading+Network+for+Continual+Test-Time+Adaptation)|0|
|[Exploring Robustness of GNN against Universal Injection Attack from a Worst-case Perspective](https://doi.org/10.1145/3627673.3679862)|Dandan Ni, Sheng Zhang, Cong Deng, Han Liu, Gang Chen, Minhao Cheng, Hongyang Chen|Database Laboratory, Zhejiang University, Hangzhou, China; The Pennsylvania State University, University Park, USA; Zhejiang Lab, Hangzhou, China; Institute of Software, University of Chinese Academy of Sciences, Hangzhou, China; Dalian University of Technology, Dalian, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China|Recently, graph neural networks (GNNs) have demonstrated outstanding performance in fundamental tasks such as node classification and link prediction, as well as in specialized domains like recommendation systems, fraud detection, and drug discovery. However, their vulnerability to adversarial attacks raises concerns about their reliability in security-critical areas. To address this issue, researchers are exploring various defense methods, including specific attack countermeasures and certifiable robustness approaches. Nevertheless, these strategies are often effective only against limited attack scenarios, and prevailing certification methods prove inadequate when confronted with injection attacks. In this paper, we propose a method named CERT_UIA to enhance the robustness of GNN models against worst-case attacks, specifically targeting the scenario of Universal node Injection Attacks (UIA), thereby filling a gap in the existing literature on certified robustness in this context. Our approach involves a two-stage attack process that replaces the transformations of the topology and feature spaces with equivalent unified feature transformations, unifying the optimization of worst-case perturbations into a single feature space. Furthermore, we empirically evaluate our method on several benchmark datasets and compare it with existing certified methods.|近年来，图神经网络（GNNs）在节点分类、链接预测等基础任务以及推荐系统、欺诈检测和药物发现等专业领域中表现出色。然而，其对对抗攻击的脆弱性引发了对其在安全关键领域可靠性的担忧。为解决这一问题，研究人员正在探索多种防御方法，包括针对特定攻击的对策和可验证的鲁棒性方法。然而，这些策略通常仅在有限的攻击场景下有效，而现有的认证方法在面对注入攻击时显得不足。本文提出了一种名为CERT_UIA的方法，旨在增强GNN模型对最坏情况攻击的鲁棒性，特别是针对通用节点注入攻击（UIA）的场景，从而填补了现有文献中在此背景下认证鲁棒性的空白。我们的方法涉及一个两阶段的攻击过程，通过等效的统一特征变换替代拓扑和特征空间的变换，将最坏情况扰动的优化统一到一个特征空间中。此外，我们在多个基准数据集上实证评估了我们的方法，并与现有的认证方法进行了比较。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+Robustness+of+GNN+against+Universal+Injection+Attack+from+a+Worst-case+Perspective)|0|
|[CADIF-OSN: Detecting Cloned Accounts with Missing Profile Attributes on Online Social Networks](https://doi.org/10.1145/3627673.3679761)|Dewei Ning, YongFeng Ge, Hua Wang, Changjun Zhou|Zhejiang Normal University, Jinhua, China; Victoria University, Melbourne, Australia|The growth of online social networks (OSNs) has become increasingly significant. Potential cloned accounts on these platforms raise serious concerns due to the risks they pose to user privacy and security. Previous works in the detection of cloned accounts on OSNs do not yield satisfactory results and lack consideration of the impact of missing attributes on the detection process. We propose cloned account detection with imputation framework for online social networks (CADIF-OSN) to accurately find potential cloned accounts on OSNs. This framework enables the accurate identification of potential cloned accounts on OSNs by leveraging their public profile information, even in cases where some of the information may not be accessible. The framework comprises four key components: 1) Fuzzy string matching with Levenshtein Distance that quickly generates suspicious account pairs by matching all the accounts' usernames and screennames; 2) An embedded method Doc2Vec that transforms all existing profile information of accounts into estimable vectors; 3) A HyperImpute model that imputes the missing information; and 4) A deep-forest model that is trained to detect cloned accounts. We evaluated our framework using a Twitter dataset consisting of 3,826 pairs of cloned accounts and 70,000 normal accounts. The evaluation results demonstrate that our framework significantly surpasses existing approaches in terms of Precision and F1-score.|在线社交网络（OSNs）的快速发展变得日益重要。这些平台上潜在的克隆账号对用户隐私和安全构成了严重威胁。先前在检测OSNs上克隆账号的研究未能取得令人满意的结果，且未充分考虑属性缺失对检测过程的影响。为此，我们提出了基于填补框架的在线社交网络克隆账号检测（CADIF-OSN），以准确识别OSNs上的潜在克隆账号。该框架通过利用账号的公开资料信息，即使在部分信息不可访问的情况下，也能实现对潜在克隆账号的精准识别。框架包含四个关键组件：1）利用Levenshtein距离的模糊字符串匹配，通过匹配所有账号的用户名和屏幕名称快速生成可疑账号对；2）嵌入方法Doc2Vec，将账号的所有现有资料信息转换为可估计的向量；3）HyperImpute模型，用于填补缺失信息；4）深度森林模型，用于训练检测克隆账号。我们使用包含3,826对克隆账号和70,000个正常账号的Twitter数据集对框架进行了评估。评估结果表明，我们的框架在Precision和F1-score方面显著优于现有方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CADIF-OSN:+Detecting+Cloned+Accounts+with+Missing+Profile+Attributes+on+Online+Social+Networks)|0|
|[Distilling Large Language Models for Text-Attributed Graph Learning](https://doi.org/10.1145/3627673.3679830)|Bo Pan, Zheng Zhang, Yifei Zhang, Yuntong Hu, Liang Zhao|Emory University Atlanta Department of Computer Science|Text-Attributed Graphs (TAGs) are graphs of connected textual documents.Graph models can efficiently learn TAGs, but their training heavily relies onhuman-annotated labels, which are scarce or even unavailable in manyapplications. Large language models (LLMs) have recently demonstratedremarkable capabilities in few-shot and zero-shot TAG learning, but they sufferfrom scalability, cost, and privacy issues. Therefore, in this work, we focuson synergizing LLMs and graph models with their complementary strengths bydistilling the power of LLMs to a local graph model on TAG learning. To addressthe inherent gaps between LLMs (generative models for texts) and graph models(discriminative models for graphs), we propose first to let LLMs teach aninterpreter with rich textual rationale and then let a student model mimic theinterpreter's reasoning without LLMs' textual rationale. Extensive experimentsvalidate the efficacy of our proposed framework.|文本属性图（Text-Attributed Graphs，简称TAGs）是由连接的文本文档构成的图结构。图模型能够高效地学习TAGs，但其训练过程高度依赖于人工标注的标签，而这些标签在许多应用中往往稀缺甚至不可得。近期，大型语言模型（LLMs）在少样本和零样本TAG学习方面展现出显著能力，但它们面临着可扩展性、成本和隐私问题。因此，本研究聚焦于通过将LLMs的能力蒸馏到一个局部图模型上，来协同LLMs和图模型的互补优势，以实现TAG学习。为了弥合LLMs（文本生成模型）与图模型（图判别模型）之间的固有差距，我们首先提出让LLMs教导一个具有丰富文本依据的解释器，然后让一个学生模型在不依赖LLMs文本依据的情况下模仿解释器的推理过程。大量实验验证了我们提出的框架的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Distilling+Large+Language+Models+for+Text-Attributed+Graph+Learning)|0|
|[Table-Filling via Mean Teacher for Cross-domain Aspect Sentiment Triplet Extraction](https://doi.org/10.1145/3627673.3679543)|Kun Peng, Lei Jiang, Qian Li, Haoran Li, Xiaoyan Yu, Li Sun, Shuo Sun, Yanxian Bi, Hao Peng||Cross-domain Aspect Sentiment Triplet Extraction (ASTE) aims to extract fine-grained sentiment elements from target domain sentences by leveraging the knowledge acquired from the source domain. Due to the absence of labeled data in the target domain, recent studies tend to rely on pre-trained language models to generate large amounts of synthetic data for training purposes. However, these approaches entail additional computational costs associated with the generation process. Different from them, we discover a striking resemblance between table-filling methods in ASTE and two-stage Object Detection (OD) in computer vision, which inspires us to revisit the cross-domain ASTE task and approach it from an OD standpoint. This allows the model to benefit from the OD extraction paradigm and region-level alignment. Building upon this premise, we propose a novel method named Table-Filling via Mean Teacher (TFMT). Specifically, the table-filling methods encode the sentence into a 2D table to detect word relations, while TFMT treats the table as a feature map and utilizes a region consistency to enhance the quality of those generated pseudo labels. Additionally, considering the existence of the domain gap, a cross-domain consistency based on Maximum Mean Discrepancy is designed to alleviate domain shift problems. Our method achieves state-of-the-art performance with minimal parameters and computational costs, making it a strong baseline for cross-domain ASTE.|跨域方面情感三元组抽取（ASTE）旨在利用从源域获取的知识，从目标域句子中提取细粒度的情感元素。由于目标域缺乏标注数据，近期的研究倾向于依赖预训练语言模型生成大量合成数据用于训练。然而，这些方法在生成过程中产生了额外的计算成本。与这些方法不同，我们发现ASTE中的表格填充方法与计算机视觉中的两阶段目标检测（OD）有着惊人的相似性，这启发我们重新审视跨域ASTE任务，并从OD的角度来处理。这种方法使模型能够受益于OD的提取范式和区域级对齐。基于这一前提，我们提出了一种名为通过均值教师进行表格填充（TFMT）的新方法。具体而言，表格填充方法将句子编码为二维表格以检测词语关系，而TFMT将表格视为特征图，并利用区域一致性来提高生成的伪标签的质量。此外，考虑到域差异的存在，我们设计了一种基于最大均值差异的跨域一致性方法，以缓解域迁移问题。我们的方法以最少的参数和计算成本实现了最先进的性能，成为跨域ASTE的一个强有力的基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Table-Filling+via+Mean+Teacher+for+Cross-domain+Aspect+Sentiment+Triplet+Extraction)|0|
|[Periormer: Periodic Transformer for Seasonal and Irregularly Sampled Time Series](https://doi.org/10.1145/3627673.3679720)|Xiaobin Ren, Kaiqi Zhao, Katerina Taskova, Patricia Riddle, Lianyan Li|University of Auckland, Auckland, New Zealand|Time series prediction presents a significant challenge across various domains, such as transportation systems, environmental science, and multiple industrial sectors. Real-world time series data commonly exhibit periodic patterns and irregular sampling rates. Recent advancements in long sequence time series forecasting have made significant progress in adopting deep neural networks, particularly the Transformers, renowned for their robust representational capabilities. However, current Transformer-based models consider time steps as discrete tokens, thereby failing to account for periodicity and temporal intervals when selecting relevant time steps in the past. To address this limitation, we propose an end-to-end framework called Periormer for forecasting irregularly sampled time series. Periormer comprises three key components: (1) a novel input embedding layer that encodes the periodicity and time interval information, analogous to positional encoding in Transformers; (2) a feature-wise periodic attention mechanism that selects essential data points considering the periods and amplitudes of the periodic signals; and (3) a cross-feature periodic attention mechanism that identifies essential features relevant to the prediction. Experiments on four real-world datasets and one synthetic dataset demonstrate that Periormer reduces the mean squared error by 14.9% compared to state-of-the-art models.|时间序列预测在交通系统、环境科学以及多个工业领域中都是一个重大挑战。现实世界中的时间序列数据通常表现出周期性模式和非均匀采样率。近年来，长序列时间序列预测在采用深度神经网络方面取得了显著进展，特别是以强大的表示能力著称的Transformer模型。然而，当前基于Transformer的模型将时间步视为离散的标记，因此在选择过去相关时间步时未能考虑周期性和时间间隔。为解决这一局限性，我们提出了一种名为Periormer的端到端框架，用于预测非均匀采样的时间序列。Periormer包含三个关键组件：（1）一种新颖的输入嵌入层，编码周期性和时间间隔信息，类似于Transformer中的位置编码；（2）一种特征层面的周期性注意力机制，考虑周期信号的周期和幅度来选择关键数据点；（3）一种跨特征的周期性注意力机制，识别与预测相关的重要特征。在四个真实世界数据集和一个合成数据集上的实验表明，Periormer相比最先进的模型将均方误差降低了14.9%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Periormer:+Periodic+Transformer+for+Seasonal+and+Irregularly+Sampled+Time+Series)|0|
|[Self-supervised One-Stage Learning for RF-based Multi-Person Pose Estimation](https://doi.org/10.1145/3627673.3679609)|Seunghwan Shin, Yusung Kim|Sungkyunkwan University, Suwon, Gyeonggi-do, Republic of Korea; Vueron Technology, Gangnam, Seoul, Republic of Korea|In the field of Multi-Person Pose Estimation (MPPE), Radio Frequency (RF)-based methods can operate effectively regardless of lighting conditions and obscured line-of-sight situations. Existing RF-based MPPE methods typically involve either 1) converting RF signals into heatmap images through complex preprocessing, or 2) applying a deep embedding network directly to raw RF signals. The first approach, while delivering decent performance, is computationally intensive and time-consuming. The second method, though simpler in preprocessing, results in lower MPPE accuracy and generalization performance. This paper proposes an efficient and lightweight one-stage MPPE model based on raw RF signals. By sub-grouping RF signals and embedding them using a shared single-layer CNN followed by multi-head attention, this model outperforms previous methods that embed all signals at once through a large and deep CNN. Additionally, we propose a new self-supervised learning (SSL) method that takes inputs from both one unmasked subgroup and the remaining masked subgroups to predict the latent representations of the masked data. Empirical results demonstrate that our model improves MPPE accuracy by up to 15 in [email protected] compared to previous methods using raw RF signals. Especially, the proposed SSL method has shown to significantly enhance performance improvements when placed in new locations or in front of obstacles at RF antennas, contributing to greater performance gains as the number of people increases. Our code and dataset is open at Github.|在多人体姿态估计（MPPE）领域，基于射频（RF）的方法能够在各种光照条件和视线受阻的情况下有效运行。现有的RF-based MPPE方法通常包括两种方式：1) 通过复杂的预处理将RF信号转换为热图图像，或2) 直接将深度嵌入网络应用于原始RF信号。第一种方法虽然性能不错，但计算量大且耗时。第二种方法虽然预处理简单，但其MPPE精度和泛化性能较低。本文提出了一种基于原始RF信号的高效轻量级单阶段MPPE模型。通过将RF信号分组并使用共享的单层CNN进行嵌入，随后采用多头注意力机制，该模型在性能上优于以往通过大型深层CNN一次性嵌入所有信号的方法。此外，我们还提出了一种新的自监督学习（SSL）方法，该方法从一组未屏蔽的子组和其余屏蔽的子组中获取输入，以预测屏蔽数据的潜在表示。实验结果表明，与使用原始RF信号的先前方法相比，我们的模型在[email protected]指标上提高了最多15个点。特别是，所提出的SSL方法在RF天线位于新位置或前方有障碍物时，显著提升了性能提升，随着人数增加，性能提升更为显著。我们的代码和数据集已在Github上公开。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-supervised+One-Stage+Learning+for+RF-based+Multi-Person+Pose+Estimation)|0|
|[DFLStar: A Decentralized Federated Learning Framework with Self-Knowledge Distillation and Participant Selection](https://doi.org/10.1145/3627673.3679853)|Behnaz Soltani, Venus Haghighi, Yipeng Zhou, Quan Z. Sheng, Lina Yao|Macquarie University, Sydney, NSW, Australia; CSIRO Data61, Sydney, NSW, Australia|Federated learning (FL) is a distributed machine learning paradigm in which clients collaboratively train models in a privacy-preserving manner. While centralized FL (CFL) suffers from single points of failure and performance bottlenecks, decentralized FL (DFL), which depends on inter-client communication, has emerged to eliminate the need of a central entity. However, due to lack of the coordination of a central server, heterogeneous data distribution across clients makes local models in DFL inclined to diverge towards their local objectives, resulting in poor model accuracy. Moreover, each client in DFL needs to communicate with multiple neighbors, yielding a heavy communication load. To tackle these challenges, we propose a novel DFL framework called DFLStar, which can improve DFL from two perspectives. First, to avoid significantly diverging towards local data, DFLStar incorporates self-knowledge distillation to enhance the local model training by assimilating knowledge from the aggregated model. Second, clients in DFLStar identify and only select the most informative neighbors (based on the last layer model similarity) for parameter exchange, thereby minimizing the communication overhead. Our experimental results on two real datasets demonstrate that DFLStar significantly improves both communication overhead and training time compared to traditional DFL algorithms while achieving a specific target accuracy. Furthermore, within a fixed training duration, DFLStar constantly obtains the highest model accuracy compared to the baselines.|联邦学习（Federated Learning, FL）是一种分布式机器学习范式，其中客户端以保护隐私的方式协作训练模型。尽管集中式联邦学习（Centralized FL, CFL）存在单点故障和性能瓶颈，但去中心化联邦学习（Decentralized FL, DFL）通过客户端间的通信消除了对中央实体的依赖。然而，由于缺乏中央服务器的协调，客户端间的异质数据分布导致DFL中的本地模型倾向于向各自的局部目标发散，从而导致模型精度下降。此外，DFL中的每个客户端需要与多个邻居进行通信，导致通信负载沉重。为了应对这些挑战，我们提出了一种新的DFL框架，称为DFLStar，该框架从两个方面改进DFL。首先，为了避免显著发散到局部数据，DFLStar引入了自知识蒸馏，通过吸收聚合模型的知识来增强本地模型的训练。其次，DFLStar中的客户端识别并仅选择最具信息量的邻居（基于最后一层模型相似性）进行参数交换，从而最小化通信开销。我们在两个真实数据集上的实验结果表明，与传统的DFL算法相比，DFLStar在实现特定目标精度的同时，显著减少了通信开销和训练时间。此外，在固定的训练时间内，DFLStar始终获得了比基线更高的模型精度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DFLStar:+A+Decentralized+Federated+Learning+Framework+with+Self-Knowledge+Distillation+and+Participant+Selection)|0|
|[TEXT CAN BE FAIR: Mitigating Popularity Bias with PLMs by Learning Relative Preference](https://doi.org/10.1145/3627673.3679581)|Zuoli Tang, Zhaoxin Huan, Zihao Li, Shirui Hu, Xiaolu Zhang, Jun Zhou, Lixin Zou, Chenliang Li|; Ant Group, Hangzhou, China; Ant Group, Beijing, China|Recently, the item textual information has been exploited with pre-trained language models (PLMs) to enrich the representations of tail items. The underlying idea is to align the hot items and tail items in terms of the external semantic knowledge covered by the PLM. However, it is non-trivial to eliminate the popularity bias by exploiting the textual semantics. One major obstacle is that the model supervision still counts on the sparse yet binary user behaviors. In the preliminary investigation, we discover that text-based recommendations also suffer from the popularity bias. To this end, we propose a novel self-distillation framework based on a pre-trained language model, named Staple. The proposed Staple consists of two main components: ranker model and recommender model, which are both instantiated as a PLM towards exploiting the item textual semantics. Motivated by the recent success of reinforcement learning with human feedback (RLHF), the proposed Staple aims to recover the relative preference by learning a fair ranker model that can successfully distinguish the preference levels for uninteracted items. Specifically, analogous to the training of large language models (LLMs), we introduce a pre-training and a fair supervised fine-tuning with a decoupled layer to build the ranker model. Then, similar to RLHF for LLM training, we utilize the relative preference information estimated by the ranker over candidate items to complement the learning of the recommender model. We show that this RLHF process can be reformed as an efficient distillation learning process. We conduct extensive experiments on three real-world datasets. In addition to the performance metrics, we employ two additional metrics to measure fairness and debiased performance. The experiments show that our method can significantly improve the item exposure fairness of recommendation and mitigate popularity bias, while also improving the recommendation performance. The source code is available at https://github.com/WHUIR/STAPLE.|最近，通过利用预训练语言模型（PLMs）处理项目文本信息，旨在丰富尾部项目的表示。其核心思想是通过PLM所涵盖的外部语义知识，使热门项目和尾部项目在语义上对齐。然而，利用文本语义消除流行度偏差并非易事。一个主要障碍在于，模型监督仍然依赖于稀疏且二值化的用户行为数据。在初步研究中，我们发现基于文本的推荐系统同样存在流行度偏差问题。为此，我们提出了一种基于预训练语言模型的新型自蒸馏框架，名为Staple。该框架包含两个主要组件：排序模型和推荐模型，两者均采用PLM以充分利用项目文本语义。受人类反馈强化学习（RLHF）近期成功的启发，Staple旨在通过学习一个公平的排序模型来恢复相对偏好，该模型能够有效区分用户对未交互项目的偏好程度。具体而言，类似于大规模语言模型（LLMs）的训练方式，我们引入了预训练和公平监督微调两个阶段，并采用解耦层构建排序模型。随后，类似于LLM训练中的RLHF方法，我们利用排序模型对候选项目估计的相对偏好信息来辅助推荐模型的学习。我们证明，这一RLHF过程可以重构为一个高效的蒸馏学习过程。我们在三个真实世界数据集上进行了广泛的实验。除了性能指标外，我们还采用了两个额外的公平性和去偏性能指标。实验结果表明，我们的方法能够显著提升推荐系统的项目曝光公平性，有效缓解流行度偏差，同时提升推荐性能。源代码可在https://github.com/WHUIR/STAPLE获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TEXT+CAN+BE+FAIR:+Mitigating+Popularity+Bias+with+PLMs+by+Learning+Relative+Preference)|0|
|[LTBoost: Boosted Hybrids of Ensemble Linear and Gradient Algorithms for the Long-term Time Series Forecasting](https://doi.org/10.1145/3627673.3679527)|Hubert Truchan, Christian Kalfar, Zahra Ahmadi|L3S Research Center, Hannover, Germany|The progress of deep-learning-based forecasting architectures is evident through their expanding parameter configurations. However, the need for rapid online decision making in practical scenarios calls for an alternative strategy, highlighting the necessity for networks that are not only adaptive but also efficient in real-time operations. This shift is critical as we confront three principal challenges in deep-learning-based forecasting frameworks: (i) the inherent limitations of transformers, which, despite their attempts to preserve ordering information, the temporal information loss due to the permutation-invariant nature of self-attention mechanisms is inevitable, (ii) the inefficacy of linear models in capturing the dynamic interactions within swiftly evolving signals; and (iii) the incapacity of tree-based approaches to extrapolating beyond values present in the training set. In response to these challenges, we introduce LTBoost, an innovative boosted hybrid of linear and tree-based ensemble gradient algorithms tailored for long-term time series forecasting (LTSF) tasks, scalable to high data dimensions. LTBoost employs a dual strategy, beginning with a linear regression model to capture trends and extrapolate beyond known data, complemented by a robust nonlinear tree-based model that focuses on the residuals. This boosted hybrid approach not only addresses the challenges posed by existing models but also significantly improves forecast accuracy. The effectiveness of LTBoost is validated through empirical experiments conducted on nine well-established benchmark datasets, demonstrating superior performance and achieving state-of-the-art results in 32 out of 36 cases, measured by mean absolute error (MAE). Our findings also explore the impact of lag features and signal normalization techniques, demonstrating further improvements in predictive accuracy. This hybrid and highly effective approach highlights LTBoost's innovation and its resolution of specific forecasting challenges, setting the stage for its contribution to the field of time series forecasting, paving the way for its application in diverse real-world scenarios.|基于深度学习的预测架构的进展显而易见，体现在其参数配置的不断扩展上。然而，在实际场景中快速在线决策的需求呼唤一种替代策略，强调网络不仅需要具备适应性，还必须在实时操作中表现高效。这一转变至关重要，因为我们在基于深度学习的预测框架中面临三大主要挑战：（i）Transformer的固有局限性，尽管它们试图保留顺序信息，但由于自注意力机制的排列不变性，时间信息的损失是不可避免的；（ii）线性模型在捕捉快速变化信号中的动态交互方面效率低下；（iii）基于树的方法无法外推超出训练集中存在的值。为应对这些挑战，我们提出了LTBoost，这是一种创新的线性和树基集成梯度算法的增强混合模型，专门为长期时间序列预测（LTSF）任务设计，可扩展至高维数据。LTBoost采用双重策略，首先使用线性回归模型捕捉趋势并外推已知数据之外的信息，随后通过一个强大的非线性树基模型专注于残差处理。这种增强混合方法不仅解决了现有模型的挑战，还显著提高了预测精度。通过在九个公认的基准数据集上进行的实证实验，LTBoost的有效性得到了验证，展示了其卓越的性能，并在36个案例中的32个中，以平均绝对误差（MAE）衡量，达到了最先进的结果。我们的研究还探讨了滞后特征和信号归一化技术的影响，进一步提升了预测准确性。这种混合且高效的方法凸显了LTBoost的创新性及其在解决特定预测挑战方面的能力，为其在时间序列预测领域的贡献奠定了基础，并为在多样化的现实场景中的应用铺平了道路。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LTBoost:+Boosted+Hybrids+of+Ensemble+Linear+and+Gradient+Algorithms+for+the+Long-term+Time+Series+Forecasting)|0|
|[Why Misinformation is Created? Detecting them by Integrating Intent Features](https://doi.org/10.1145/3627673.3679799)|Bing Wang, Ximing Li, Changchun Li, Bo Fu, Songwen Pei, Shengsheng Wang||Various social media platforms, e.g., Twitter and Reddit, allow people to disseminate a plethora of information more efficiently and conveniently. However, they are inevitably full of misinformation, causing damage to diverse aspects of our daily lives. To reduce the negative impact, timely identification of misinformation, namely Misinformation Detection (MD), has become an active research topic receiving widespread attention. As a complex phenomenon, the veracity of an article is influenced by various aspects. In this paper, we are inspired by the opposition of intents between misinformation and real information. Accordingly, we propose to reason the intent of articles and form the corresponding intent features to promote the veracity discrimination of article features. To achieve this, we build a hierarchy of a set of intents for both misinformation and real information by referring to the existing psychological theories, and we apply it to reason the intent of articles by progressively generating binary answers with an encoder-decoder structure. We form the corresponding intent features and integrate it with the token features to achieve more discriminative article features for MD. Upon these ideas, we suggest a novel MD method, namely Detecting Misinformation by Integrating Intent featuRes (DM-INTER). To evaluate the performance of DM-INTER, we conduct extensive experiments on benchmark MD datasets. The experimental results validate that DM-INTER can outperform the existing baseline MD methods.|各种社交媒体平台，如Twitter和Reddit，使得人们能够更高效、便捷地传播大量信息。然而，这些平台不可避免地充斥着错误信息，对我们的日常生活造成了多方面的损害。为了减少这种负面影响，及时识别错误信息，即错误信息检测（Misinformation Detection, MD），已成为一个备受关注且活跃的研究课题。作为一种复杂现象，文章的真实性受到多方面因素的影响。本文受错误信息与真实信息意图对立的启发，提出通过推理文章的意图并形成相应的意图特征，以促进文章特征的真实性判别。为此，我们借鉴现有心理学理论，构建了一个包含错误信息和真实信息意图的层次结构，并通过编码器-解码器结构逐步生成二元答案来推理文章的意图。我们形成相应的意图特征，并与词元特征结合，以获得更具判别力的文章特征用于MD。基于这些思想，我们提出了一种新的MD方法，即通过整合意图特征检测错误信息（Detecting Misinformation by Integrating Intent featuRes, DM-INTER）。为了评估DM-INTER的性能，我们在基准MD数据集上进行了广泛的实验。实验结果验证了DM-INTER能够优于现有的基线MD方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Why+Misinformation+is+Created?+Detecting+them+by+Integrating+Intent+Features)|0|
|[Bots Shield Fake News: Adversarial Attack on User Engagement based Fake News Detection](https://doi.org/10.1145/3627673.3679583)|Lanjun Wang, Zehao Wang, Le Wu, AnAn Liu|Hefei University of Technology, Hefie, An'hui, China; Tianjin University, Tianjin, China|The surge in detecting fake news on social networks leads to increased research attention, particularly in the realm of deep learning models based on graph neural networks (GNNs). However, as research progresses, concerns emerge about the vulnerability of these detection models. In this study, we introduce an attack problem that perturbs user-news engagements by injecting bots to shield the targeted fake news from being detected by GNN-based fake news detection models. We propose a black-box attack method named Query-enhanced Surrogate-based Attack under Assortativity Constraint (QSA-AC) to work for this attack problem. QSA-AC combines surrogate-based and query-based approaches to improve attack effectiveness. At the same time, QSA-AC maintains a balance between attack effectiveness and imperceptibility by adjusting the local fluctuations of the assortativity with respect to the news on the social network. In addition, we introduce an evaluation metric, local strength assortativity perturbation rate (LSAPR), to assess the imperceptibility of the attack from the local perspective. Extensive experiments on two fake news datasets demonstrate that the proposed QSA-AC can achieve the optimal attack effectiveness, and control the trade-off between the attack effectiveness and imperceptibility.|随着社交媒体上检测虚假新闻的需求激增，基于图神经网络（GNN）的深度学习模型受到了越来越多的研究关注。然而，随着研究的深入，这些检测模型的脆弱性问题逐渐显现。在本研究中，我们提出了一种攻击问题，即通过注入机器人来干扰用户与新闻的互动，从而保护目标虚假新闻不被基于GNN的虚假新闻检测模型发现。为此，我们提出了一种名为“在同配性约束下的查询增强代理攻击”（Query-enhanced Surrogate-based Attack under Assortativity Constraint, QSA-AC）的黑盒攻击方法。QSA-AC结合了基于代理和基于查询的两种方法，以提高攻击的有效性。同时，QSA-AC通过调整社交网络上新闻的局部同配性波动，在攻击效果与不可察觉性之间保持平衡。此外，我们引入了一种新的评估指标——局部强度同配性扰动率（Local Strength Assortativity Perturbation Rate, LSAPR），用于从局部角度评估攻击的不可察觉性。在两个虚假新闻数据集上的大量实验表明，所提出的QSA-AC方法能够实现最佳的攻击效果，并能有效控制攻击效果与不可察觉性之间的权衡。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bots+Shield+Fake+News:+Adversarial+Attack+on+User+Engagement+based+Fake+News+Detection)|0|
|[Learning to Differentiate Pairwise-Argument Representations for Implicit Discourse Relation Recognition](https://doi.org/10.1145/3627673.3679584)|Zhipang Wang, Yu Hong, Yuxiang Lu, Xiabing Zhou, Jianmin Yao, Guodong Zhou|School of Computer Science and Technology, Soochow University, Suzhou, China; School of Computer Science and Technology, Soochow University, SuZhou, China|Recognizing implicit discourse relations between texts is challenging due to the absence of explicit connectives. Encoding texts into distinguishable semantic representations is beneficial to connective-free relation determination. To enable encoders to produce clearly distinguishable representations, we propose a joint learning framework. It combines prototypical and adversarial learning as well as hub-migration based redistribution. We experiment on PDTB 2.0, PDTB 3.0 and the CoNLL-2016 shared benchmark dataset. Experimental results show that our methods yield substantial improvements, compared to BERT, RoBERTa and DeBERTa baselines. In the separate comparison experiment where implicit connectives are disable during training, our models outperform the previous work for the four main discourse relation types (Temporality, Comparison, Contingency and Expansion), achieving F1-scores of about 60.75%, 63.48%, 75.70% and 77.09%. On the other hand, our models obtain comparable performance compared to part of the state-of-the-art models which adopt implicit connectives as observable hints for training. When the pretrained language models are used as the backbones, our methods yield the extra time consumption, which is about 1 hour at worst when training is conducted on Tesla 40GB A100 GPU.|识别文本之间的隐含话语关系由于缺乏显式连接词而具有挑战性。将文本编码为可区分的语义表示有助于无连接词的关系判定。为了使编码器生成清晰可辨的表示，我们提出了一种联合学习框架，结合了原型学习和对抗学习以及基于枢纽迁移的重分配方法。我们在PDTB 2.0、PDTB 3.0和CoNLL-2016共享基准数据集上进行了实验。实验结果表明，与BERT、RoBERTa和DeBERTa基线相比，我们的方法带来了显著的改进。在单独的对比实验中，当训练过程中禁用隐含连接词时，我们的模型在四种主要话语关系类型（时序性、比较性、偶然性和扩展性）上优于先前的工作，分别达到了约60.75%、63.48%、75.70%和77.09%的F1分数。另一方面，与部分采用隐含连接词作为可观察线索进行训练的最先进模型相比，我们的模型表现相当。当使用预训练语言模型作为骨干时，我们的方法额外增加了时间消耗，在最坏情况下，在Tesla 40GB A100 GPU上训练时大约增加了1小时。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Differentiate+Pairwise-Argument+Representations+for+Implicit+Discourse+Relation+Recognition)|0|
|[Identifying Disinformation from Online Social Media via Dynamic Modeling across Propagation Stages](https://doi.org/10.1145/3627673.3679788)|Shuai Xu, Jianqiu Xu, Shuo Yu, Bohan Li|; Nanjing University of Aeronautics and Astronautics, Nanjing, China|Identifying disinformation from online social media is crucial for maintaining a credible cyberspace. Although features from the content and propagation topology are widely exploited by existing studies to distinguish disinformation from normal ones, they are becoming less effective as content can be intentionally written to mislead readers and topological features are difficult to be extracted due to the high variance and diversity of reposting trees. Moreover, related works mainly focus on modeling the complete information propagation event, ignoring the staged evolution patterns along with propagation, which may also degrade the detection performance. In this paper, we conceive and implement a novel framework called DMPS for identifying disinformation, which Dynamically Models diverse topological structures of reposting trees as well as the textual content streams across different Propagation Stages. In particular, DMPS learns expressive representations of the structural features via meta-trees and extracts sequential features of the content for intra-stage modeling, then it captures temporal dependencies for inter-stage modeling. The whole framework is optimized in a binary classification manner. Experiments based on multilingual social media datasets validate the effectiveness and superiority of DMPS over state-of-the-art models. We believe that this study can provide insights for crisis management in response to disinformation in social network campaigns.|识别来自在线社交媒体的虚假信息对于维护可信的网络空间至关重要。尽管现有研究广泛利用内容特征和传播拓扑结构来区分虚假信息与正常信息，但随着内容可以被故意编写以误导读者，以及由于转发树的高变异性和多样性导致拓扑特征难以提取，这些方法的有效性正在降低。此外，相关工作主要集中在对完整信息传播事件的建模上，忽视了传播过程中分阶段的演化模式，这可能也会降低检测性能。在本文中，我们构思并实现了一个名为DMPS的新框架，用于识别虚假信息。该框架动态地建模了转发树的多样化拓扑结构以及不同传播阶段中的文本内容流。具体而言，DMPS通过元树学习结构的表达性表示，并提取内容的序列特征以进行阶段内建模，然后捕获阶段间的时间依赖性。整个框架以二元分类的方式进行优化。基于多语言社交媒体数据集的实验验证了DMPS相较于最先进模型的有效性和优越性。我们相信，这项研究可以为应对社交媒体活动中虚假信息的危机管理提供见解。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Identifying+Disinformation+from+Online+Social+Media+via+Dynamic+Modeling+across+Propagation+Stages)|0|
|[SGES: A General and Space-efficient Framework for Graphlet Counting in Graph Streams](https://doi.org/10.1145/3627673.3679739)|Chen Yang, Lailong Luo, Yuliang Lu, Chu Huang, Qianzhen Zhang, Guozheng Yang, Deke Guo|; College of Electronic Engineering, National University of Defense Technology, Hefei, China|Graphlets are small, connected, and non-isomorphic induced subgraphs that describe the topological structure of a graph. Counting graphlets is a fundamental task in graph mining and social network analysis. It has numerous applications in many fields, including dense subgraph discovery, anomaly detection, etc. Most existing work assumes a static graph. However, graphs are dynamic in the real world, which can be described as graph streams. Counting graphlets in graph streams is a challenge due to the streaming nature of the input. While there have been several studies on counting graphlets in graph streams, these works are limited to simple graphlets like triangles and butterflies. In this paper, we propose SGES algorithm to estimate more complex graphlets in graph streams. In SGES, we first propose an unbiased sampling strategy to maintain fixed-size sampled edges, which in turn allows us to unbiasedly estimate the number of subgraphs and then count graphlets based on the combinational relationship between the number of subgraphs and the number of graphlets. Extensive experiments over large real-world graph streams prove that our algorithm can obtain accurate estimation values of graphlet counts with high throughput.|图元（Graphlets）是描述图拓扑结构的小型、连通且非同构的诱导子图。在图挖掘和社会网络分析中，统计图元是一项基础任务，并在许多领域中有着广泛的应用，如密集子图发现、异常检测等。现有的多数研究假设图是静态的，然而在现实世界中，图通常是动态的，可以被描述为图流（graph streams）。由于输入的流式特性，在图流中统计图元是一项挑战。尽管已有一些研究探讨了在图流中统计图元的问题，但这些工作仅限于简单的图元，如三角形和蝴蝶形。本文提出了一种名为SGES的算法，用于在图流中估计更复杂的图元。在SGES中，我们首先提出了一种无偏采样策略，以维护固定大小的采样边集合，从而能够无偏地估计子图的数量，并基于子图数量与图元数量之间的组合关系来统计图元。通过对大规模真实世界图流的广泛实验，证明了我们的算法能够在高吞吐量的情况下获得准确的图元数量估计值。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SGES:+A+General+and+Space-efficient+Framework+for+Graphlet+Counting+in+Graph+Streams)|0|
|[Behavior-Aware Hypergraph Convolutional Network for Illegal Parking Prediction with Multi-Source Contextual Information](https://doi.org/10.1145/3627673.3679563)|Guang Yang, Meiqi Tu, Zelong Li, Jinquan Hang, Taichi Liu, Ruofeng Liu, Yi Ding, Yu Yang, Desheng Zhang|Rutgers University, Piscataway, NJ, USA; JD Logistics, Beijing, China; Lehigh University, Bethlehem, PA, USA; The University of Texas at Dallas, Richardson, TX, USA; Michigan State University, East Lansing, MI, USA|Illegal parking prediction is a crucial problem to help stakeholders with better urban planning and management. Existing works advance the field by capturing complex traffic correlations from spatial and temporal perspectives using deep learning models, and achieve state-of-the-art performance. However, current works do not consider the unique perspective from the illegal parking data collection process carried out by patrol officers, which can reflect a wealth of knowledge gained from each officer's on-the-ground experiences for more effective patrol. In this paper, we propose a novel behavior-aware hypergraph convolutional network named BHIPP for city-wide illegal parking prediction. To better represent the correlations of illegal parking events from patrol officers' perspective, we construct a new patrol hypergraph integrating patrol officers' experience alongsie multi-source contextual information. Additionally, we design a behavior-aware hypergraph convolutional network, which captures the complex and high-order illegal parking event correlations with officers' patrol behaviors explicitly considered. Further, we introduce a spatial-temporal illegal parking approximation module to estimate parking violations in under-patrolled regions using both historical and multi-source contextual data. Extensive experiments on real-world datasets demonstrate the superiority of our proposed BHIPP compared with a broad range of state-of-the-art baseline models across varying spatial-temporal granularities, from both regression and ranking aspects.|非法停车预测是一个关键问题，有助于利益相关者进行更有效的城市规划和管理。现有研究通过深度学习模型从时空角度捕捉复杂的交通关联，取得了最先进的性能。然而，当前的研究并未考虑巡逻警员在非法停车数据收集过程中所特有的视角，这一视角能够反映每位警员实地经验所积累的丰富知识，从而实现更有效的巡逻。本文提出了一种名为BHIPP的新型行为感知超图卷积网络，用于城市范围的非法停车预测。为了更好地从巡逻警员的视角表示非法停车事件的关联，我们构建了一个新的巡逻超图，整合了警员的经验与多源上下文信息。此外，我们设计了一种行为感知的超图卷积网络，该网络明确考虑了警员的巡逻行为，捕捉复杂的、高阶的非法停车事件关联。进一步地，我们引入了一个时空非法停车近似模块，利用历史和多源上下文数据估算巡逻不足区域的停车违规情况。在真实世界数据集上的大量实验表明，与各种最先进的基线模型相比，我们提出的BHIPP在不同时空粒度上，无论是在回归还是排序方面，都表现出了优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Behavior-Aware+Hypergraph+Convolutional+Network+for+Illegal+Parking+Prediction+with+Multi-Source+Contextual+Information)|0|
|[Distilling Multi-Scale Knowledge for Event Temporal Relation Extraction](https://doi.org/10.1145/3627673.3679520)|HaoRen Yao, Luke Breitfeller, Aakanksha Naik, Chunxiao Zhou, Carolyn P. Rosé|; Allen Institute for AI; Carnegie Mellon University|Event Temporal Relation Extraction (ETRE) is paramount but challenging. Within a discourse, event pairs are situated at different distances or the so-called proximity bands. The temporal ordering communicated about event pairs where at more remote (i.e., "long'') or less remote (i.e., "short'') proximity bands are encoded differently. SOTA models have tended to perform well on events situated at either short or long proximity bands, but not both. Nonetheless, real-world, natural texts contain all types of temporal event-pairs. In this paper, we present MulCo : Distilling Mul ti-Scale Knowledge via Co ntrastive Learning, a knowledge co-distillation approach that shares knowledge across multiple event pair proximity bands to improve performance on all types of temporal datasets. Our experimental results show that MulCo successfully integrates linguistic cues pertaining to temporal reasoning across both short and long proximity bands and achieves new state-of-the-art results on several ETRE benchmark datasets.|事件时间关系提取（ETRE）至关重要但充满挑战。在语篇中，事件对位于不同的距离，即所谓的接近带。关于远距离（即“长”）或近距离（即“短”）接近带的事件对的时间顺序信息以不同的方式编码。现有的最先进（SOTA）模型往往在短或长接近带的事件对上表现良好，但无法兼顾两者。然而，现实世界中的自然文本包含各种类型的时间事件对。本文提出了MulCo：通过对比学习提炼多尺度知识的知识共同提炼方法，该方法在多个事件对接近带之间共享知识，以提高所有类型时间数据集的性能。我们的实验结果表明，MulCo成功整合了涉及短和长接近带的时间推理的语言线索，并在多个ETRE基准数据集上取得了新的最先进结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Distilling+Multi-Scale+Knowledge+for+Event+Temporal+Relation+Extraction)|0|
|[Debiased Graph Poisoning Attack via Contrastive Surrogate Objective](https://doi.org/10.1145/3627673.3679686)|Kanghoon Yoon, Yeonjun In, Namkyeong Lee, Kibum Kim, Chanyoung Park||Graph neural networks (GNN) are vulnerable to adversarial attacks, which aim to degrade the performance of GNNs through imperceptible changes on the graph. However, we find that in fact the prevalent meta-gradient-based attacks, which utilizes the gradient of the loss w.r.t the adjacency matrix, are biased towards training nodes. That is, their meta-gradient is determined by a training procedure of the surrogate model, which is solely trained on the training nodes. This bias manifests as an uneven perturbation, connecting two nodes when at least one of them is a labeled node, i.e., training node, while it is unlikely to connect two unlabeled nodes. However, these biased attack approaches are sub-optimal as they do not consider flipping edges between two unlabeled nodes at all. This means that they miss the potential attacked edges between unlabeled nodes that significantly alter the representation of a node. In this paper, we investigate the meta-gradients to uncover the root cause of the uneven perturbations of existing attacks. Based on our analysis, we propose a Meta-gradient-based attack method using contrastive surrogate objective (Metacon), which alleviates the bias in meta-gradient using a new surrogate loss. We conduct extensive experiments to show that Metacon outperforms existing meta gradient-based attack methods through benchmark datasets, while showing that alleviating the bias towards training nodes is effective in attacking the graph structure.|图神经网络（GNN）容易受到对抗攻击，这些攻击旨在通过对图进行难以察觉的更改来降低GNN的性能。然而，我们发现实际上流行的基于元梯度的攻击方法，即利用损失对邻接矩阵的梯度，偏向于训练节点。也就是说，它们的元梯度由代理模型的训练过程决定，该代理模型仅在训练节点上进行训练。这种偏差表现为不均匀的扰动，即当至少其中一个节点是有标签的节点（即训练节点）时，连接两个节点，而连接两个未标记节点的可能性较低。然而，这些有偏的攻击方法并不理想，因为它们完全不考虑翻转两个未标记节点之间的边。这意味着它们忽略了未标记节点之间可能存在的潜在攻击边，这些边会显著改变节点的表示。在本文中，我们研究了元梯度，以揭示现有攻击不均匀扰动的根本原因。基于我们的分析，我们提出了一种基于元梯度的攻击方法，使用对比代理目标（Metacon），通过新的代理损失来缓解元梯度中的偏差。我们进行了大量实验，通过基准数据集证明了Metacon优于现有的基于元梯度的攻击方法，同时表明减轻对训练节点的偏差在攻击图结构时是有效的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Debiased+Graph+Poisoning+Attack+via+Contrastive+Surrogate+Objective)|0|
|[Language Models-enhanced Semantic Topology Representation Learning For Temporal Knowledge Graph Extrapolation](https://doi.org/10.1145/3627673.3679602)|Tianli Zhang, Tongya Zheng, Zhenbang Xiao, Zulong Chen, Liangyue Li, Zunlei Feng, Dongxiang Zhang, Mingli Song|Zhejiang University, Hangzhou, China; ; Alibaba Group, Hangzhou, China; Hangzhou City University, Hangzhou, China|Temporal Knowledge Graph (TKG) extrapolation aims to predict future missing facts based on historical information, which has exhibited both semantics and topology of events. The mainstream methods have advanced the prediction performance by exploring the potential of topology representations of TKGs based on dedicated temporal Graph Neural Networks (GNNs). Until recently, few Language Models (LM) based methods have attempted to model the semantic representations of TKGs, however, lacking specific designs for the topology information. Therefore, we propose a Semantic TOpology REpresentation learning (STORE) framework enhanced by LMs to bridge the gap between the semantics and topology of TKGs. Firstly, we tackle the challenge of long historical facts modeling by a time-aware sampling based on semantic priors to extract concise yet precise facts. Secondly, we handle the challenge of the interaction between topology and semantics by transforming graph representations into virtual tokens that are then integrated with generated prompts and fed into LMs. Finally, multi-head attention is adopted to obtain better semantic topology representations, thereby achieving joint optimization of both temporal GNNs and LMs. Extensive experiments on five datasets show that our STORE outperforms state-of-the-art GNNs- and LM-based methods.|时序知识图谱（Temporal Knowledge Graph, TKG）外推旨在基于历史信息预测未来的缺失事实，这些事实既包含事件的语义信息，又包含其拓扑结构。主流方法通过探索基于专用时序图神经网络（Graph Neural Networks, GNNs）的TKG拓扑表示潜力，提升了预测性能。然而，直到最近，基于语言模型（Language Models, LM）的方法才开始尝试对TKG的语义表示进行建模，但缺乏针对拓扑信息的专门设计。为此，我们提出了一种由LM增强的语义拓扑表示学习（Semantic TOpology REpresentation learning, STORE）框架，以弥合TKG语义与拓扑之间的差距。首先，我们通过基于语义先验的时间感知采样方法，解决了长历史事实建模的挑战，提取出简洁且精确的事实。其次，我们通过将图表示转换为虚拟标记，并将其与生成的提示信息结合后输入到语言模型中，处理了拓扑与语义之间的交互问题。最后，采用多头注意力机制以获得更好的语义拓扑表示，从而实现时序GNN与LM的联合优化。在五个数据集上的大量实验表明，我们的STORE框架优于现有的基于GNN和LM的最先进方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Language+Models-enhanced+Semantic+Topology+Representation+Learning+For+Temporal+Knowledge+Graph+Extrapolation)|0|
|[SaLa: Scenario-aware Label Graph Interaction for Multi-intent Spoken Language Understanding](https://doi.org/10.1145/3627673.3679676)|Zhihong Zhu, Xuxin Cheng, Zhanpeng Chen, Zhichang Wang, Zhiqi Huang, Yuexian Zou|School of ECE, Peking University, Shenzhen, China|Recent joint models for multi-intent detection and slot filling (a.k.a multi-intent SLU) have obtained promising results by leveraging the semantic similarities or co-occurrence relationships between intent and slot labels. However, a critical aspect frequently neglected by current models is the significant correlations between label co-occurrences and specific scenarios, such as watching a movie or booking a ticket, which is essential for understanding user utterances in multi-intent SLU. In this paper, we propose a new framework dubbed SALA (short for Scenario-aware Label graph interaction), which effectively captures the dynamic co-occurrence relationships among labels across various scenarios, employing a strategy akin to a divide-and-conquer approach. Concretely, SALA first autonomously classifies the scenario of utterances, and tracks the co-occurring labels by maintaining a unique co-occurrence matrix for each scenario during the training phase. These scenario-independent co-occurrence matrices are further employed to guide the interactions among label representations through graph propagation to conduct accurate prediction. Extensive experiments on two multi-intent SLU benchmark datasets demonstrate the superiority of our SALA. More strikingly, SALA also attains competitive results on four extra single-intent and multi-domain SLU benchmark datasets, demonstrating its strong generalizability.|近年来，针对多意图检测与槽位填充（即多意图SLU）的联合模型，通过利用意图与槽位标签之间的语义相似性或共现关系，取得了显著的成果。然而，当前模型经常忽视的一个重要方面是标签共现与特定场景（如观看电影或预订票务）之间的显著关联，这对于理解多意图SLU中的用户话语至关重要。本文提出了一种名为SALA（Scenario-aware Label graph interaction，场景感知标签图交互）的新框架，该框架采用类似于分而治之的策略，有效捕捉了跨不同场景的标签动态共现关系。具体而言，SALA首先自主分类话语的场景，并在训练阶段通过为每个场景维护一个独特的共现矩阵来跟踪共现标签。这些与场景无关的共现矩阵进一步用于通过图传播指导标签表示之间的交互，从而进行精确预测。在两个多意图SLU基准数据集上的广泛实验证明了SALA的优越性。更为突出的是，SALA在四个额外的单意图和多领域SLU基准数据集上也取得了竞争性的结果，展示了其强大的泛化能力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SaLa:+Scenario-aware+Label+Graph+Interaction+for+Multi-intent+Spoken+Language+Understanding)|0|
|[Distributed Boosting: An Enhancing Method on Dataset Distillation](https://doi.org/10.1145/3627673.3679897)|Xuechao Chen, Wenchao Meng, Peiran Wang, Qihang Zhou|Zhejiang University, Hangzhou, Zhejiang, China; Tsinghua University, Beijing, China|Dataset Distillation (DD) is a technique for synthesizing smaller, compressed datasets from large original datasets while retaining essential information to maintain efficacy. Efficient DD is a current research focus among scholars. Squeeze, Recover and Relabel (SRe2L) and Adversarial Prediction Matching (APM) are two advanced and efficient DD methods, yet their performance is moderate with lower volumes of distilled data. This paper proposes an ingenious improvement method, Distributed Boosting (DB), capable of significantly enhancing the performance of these two algorithms at low distillation volumes, leading to DB-SRe2L and DB-APM. Specifically, DB is divided into three stages: Distribute & Encapsulate, Distill, and Integrate & Mix-relabel. DB-SRe2L, compared to SRe2L, demonstrates performance improvements of 25.2%, 26.9%, and 26.2% on full 224×224 ImageNet-1k at Images Per Class (IPC) 10, CIFAR-10 at IPC 10, and CIFAR-10 at IPC 50, respectively. Meanwhile, DB-APM, in comparison to APM, exhibits performance enhancements of 21.2% and 20.9% on CIFAR-10 at IPC 10, CIFAR-100 at IPC 1, respectively. Additionally, we provide a theoretical proof of convergence for DB. To the best of our knowledge, DB is the first method suitable for distributed parallel computing scenarios.|数据集蒸馏（Dataset Distillation, DD）是一种从大型原始数据集中合成较小压缩数据集的技术，同时保留关键信息以维持其有效性。高效的DD技术是当前学者的研究重点。Squeeze, Recover and Relabel（SRe2L）和Adversarial Prediction Matching（APM）是两种先进且高效的数据集蒸馏方法，然而在蒸馏数据量较低时，其性能表现中等。本文提出了一种巧妙的改进方法——分布式增强（Distributed Boosting, DB），能够在低蒸馏数据量的情况下显著提升这两种算法的性能，从而形成DB-SRe2L和DB-APM。具体而言，DB分为三个阶段：分布与封装（Distribute & Encapsulate）、蒸馏（Distill）以及整合与混合重标记（Integrate & Mix-relabel）。与SRe2L相比，DB-SRe2L在224×224全尺寸ImageNet-1k（每类图像数，IPC为10）、CIFAR-10（IPC为10）和CIFAR-10（IPC为50）上的性能分别提升了25.2%、26.9%和26.2%。同时，与APM相比，DB-APM在CIFAR-10（IPC为10）和CIFAR-100（IPC为1）上的性能分别提升了21.2%和20.9%。此外，本文还为DB提供了理论上的收敛性证明。据我们所知，DB是首个适用于分布式并行计算场景的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Distributed+Boosting:+An+Enhancing+Method+on+Dataset+Distillation)|0|
|[The Factuality of Large Language Models in the Legal Domain](https://doi.org/10.1145/3627673.3679961)|Rajaa El Hamdani, Thomas Bonald, Fragkiskos D. Malliaros, Nils Holzenberger, Fabian M. Suchanek||This paper investigates the factuality of large language models (LLMs) as knowledge bases in the legal domain, in a realistic usage scenario: we allow for acceptable variations in the answer, and let the model abstain from answering when uncertain. First, we design a dataset of diverse factual questions about case law and legislation. We then use the dataset to evaluate several LLMs under different evaluation methods, including exact, alias, and fuzzy matching. Our results show that the performance improves significantly under the alias and fuzzy matching methods. Further, we explore the impact of abstaining and in-context examples, finding that both strategies enhance precision. Finally, we demonstrate that additional pre-training on legal documents, as seen with SaulLM, further improves factual precision from 63 81|本文研究了大型语言模型（LLMs）在法律领域作为知识库的事实准确性，基于一个现实使用场景：我们允许答案存在可接受的变体，并在模型不确定时允许其选择不回答。首先，我们设计了一个包含关于判例法和立法多样事实问题的数据集。随后，我们使用该数据集通过不同的评估方法（包括精确匹配、别名匹配和模糊匹配）对多个LLMs进行了评估。结果显示，在别名匹配和模糊匹配方法下，模型的表现显著提升。此外，我们探讨了选择不回答和上下文示例的影响，发现这两种策略均能提高准确性。最后，我们展示了在法律文档上进行额外预训练（如SaulLM所示），可以将事实准确性从63%提升至81%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Factuality+of+Large+Language+Models+in+the+Legal+Domain)|0|
|[Beyond Language Bias: Overcoming Multimodal Shortcut and Distribution Biases for Robust Visual Question Answering](https://doi.org/10.1145/3627673.3679880)|Jingliang Gu, Zhixin Li||Recent studies have found that many VQA models are influenced by biases, preventing them from effectively using multimodal information for reasoning. Consequently, these methods, which perform well on standard VQA datasets, exhibit underwhelming performance on the bias-sensitive VQA-CP dataset. Although numerous studies in the past have focused on mitigating biases in VQA models, most have only considered language bias. In this paper, we address the issue of bias in VQA task by targeting the various sources of bias. Specifically, to counteract shortcut biases, we integrate a bias detector capable of capturing both vision and language biases, and we reinforce its ability to capture biases using a generative adversarial network and knowledge distillation. To combat distribution bias, we use a cosine classifier to obtain a cosine feature branch from the base model, training it with an adaptive angular margin loss based on answer frequency and difficulty, along with a supervised contrastive loss to enhance the model's classification ability in the feature space. In the prediction stage, we fuse the cosine features with the prediction of the base model to obtain the final prediction of our model. Finally, extensive experiments demonstrate that our approach SD-VQA achieves state-of-the-art performance on the VQA-CPv2 dataset without using any data balancing, and achieves competitive results on the VQAv2 dataset.|近期研究表明，许多视觉问答（VQA）模型受到偏差的影响，导致它们无法有效利用多模态信息进行推理。因此，尽管这些方法在标准VQA数据集上表现良好，但在偏差敏感的VQA-CP数据集上表现却不尽如人意。尽管过去已有许多研究致力于减轻VQA模型中的偏差，但大多数研究仅关注语言偏差。本文针对VQA任务中的偏差问题，从多种偏差来源入手进行解决。具体而言，为了对抗捷径偏差，我们引入了一个能够捕捉视觉和语言偏差的偏差检测器，并通过生成对抗网络和知识蒸馏来增强其捕捉偏差的能力。为应对分布偏差，我们使用余弦分类器从基础模型中获取余弦特征分支，并采用基于答案频率和难度的自适应角度间隔损失进行训练，同时结合监督对比损失以增强模型在特征空间中的分类能力。在预测阶段，我们将余弦特征与基础模型的预测结果进行融合，以获得最终的预测结果。最后，大量实验表明，我们的方法SD-VQA在不使用任何数据平衡的情况下，在VQA-CPv2数据集上达到了最先进的性能，并在VQAv2数据集上取得了具有竞争力的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Language+Bias:+Overcoming+Multimodal+Shortcut+and+Distribution+Biases+for+Robust+Visual+Question+Answering)|0|
|[A Contextual Combinatorial Semi-Bandit Approach to Network Bottleneck Identification](https://doi.org/10.1145/3627673.3679867)|Fazeleh Sadat Hoseini, Niklas Åkerblom, Morteza Haghir Chehreghani||Bottleneck identification is a challenging task in network analysis, especially when the network is not fully specified. To address this task, we develop a unified online learning framework based on combinatorial semi-bandits that performs bottleneck identification in parallel with learning the specifications of the underlying network. Within this framework, we adapt and study various combinatorial semi-bandit methods such as epsilon-greedy, LinUCB, BayesUCB, NeuralUCB, and Thompson Sampling. In addition, our framework is capable of using contextual information in the form of contextual bandits. Finally, we evaluate our framework on the real-world application of road networks and demonstrate its effectiveness in different settings.|瓶颈识别是网络分析中的一个难题，尤其是在网络结构不完全明确的情况下。为应对这一挑战，我们开发了一种基于组合半 bandit 的统一在线学习框架，该框架能够在学习底层网络结构的同时并行执行瓶颈识别。在此框架内，我们适应并研究了多种组合半 bandit 方法，如 epsilon-greedy、LinUCB、BayesUCB、NeuralUCB 和 Thompson Sampling。此外，我们的框架还能够利用上下文信息，以上下文 bandit 的形式进行处理。最后，我们在实际应用场景——道路网络中评估了该框架，并展示了其在不同设置下的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Contextual+Combinatorial+Semi-Bandit+Approach+to+Network+Bottleneck+Identification)|0|
|[Nonparametric Estimation of Non-Smooth Divergences](https://doi.org/10.1145/3627673.3679972)|M. Mahbub Hossain, Alan Wisler, Kevin R. Moon|Utah State University, Logan, UT, USA|Nonparametric estimation of information divergence functionals between two probability densities is an important problem in machine learning. Several estimators exist that guarantee the parametric rate of mean squared error (MSE) of O(1/N) under various assumptions on the smoothness and boundary of the underlying densities, with N being the number of samples. In particular, previous work on ensemble estimation theory derived ensemble estimators of divergence functionals that achieve the parametric rate without requiring knowledge of the densities' support set and are simple to implement. However, these and most other methods all assume some level of differentiability of the divergence functional. This excludes important divergence functionals such as the total variation distance and the Bayes error rate. Here, we show empirically that the ensemble estimation approach for smooth functionals can be applied to less smooth functionals and obtain good convergence rates, suggesting a gap in current theory.|在机器学习领域，非参数方法估计两个概率密度之间的信息散度是一个重要问题。已有多种估计器能够在不同假设下（如底层密度的平滑性和边界条件）保证均方误差（MSE）的参数化速率为O(1/N)，其中N为样本数量。特别是，之前的集成估计理论工作推导出了能够达到参数化速率的散度函数集成估计器，这些估计器无需了解密度的支撑集，且易于实现。然而，这些方法及大多数其他方法都假设散度函数具有某种程度的可微性，这排除了总变差距离和贝叶斯误差率等重要散度函数。在此，我们通过实验证明，针对平滑函数的集成估计方法同样适用于不太平滑的函数，并能获得良好的收敛速率，这表明当前理论存在一定的空白。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Nonparametric+Estimation+of+Non-Smooth+Divergences)|0|
|[LEX-GNN: Label-Exploring Graph Neural Network for Accurate Fraud Detection](https://doi.org/10.1145/3627673.3679956)|Woochang Hyun, Insoo Lee, Bongwon Suh|Supreme Prosecutors' Office, Seoul, Republic of Korea; Seoul National University, Seoul, Republic of Korea|Graph-based fraud detection faces significant challenges, such as severe class imbalance, inconsistent connections due to the scarcity of fraudulent nodes, and the camouflage of these nodes appearing like benign nodes. Existing studies often adopt the approach of filtering similar nodes to strengthen the homophily assumption of graph neural networks. However, to effectively address these issues, it is important to distinguish and adaptively utilize the labels of neighboring nodes. In this study, we propose the Label-Exploring Graph Neural Network (LEX-GNN), designed to enhance fraud detection by actively leveraging labeled node information. The core idea is that the manner of message passing and reception should vary depending on the node types. Specifically, we first predict the labels of nodes based on their original or previous representations. Subsequently, each node transmits differently processed messages according to its probability of being fraudulent. Finally, target nodes also receive the messages differently depending on their pre-predicted probability. Extensive experimental results on real-world benchmarks demonstrate that LEX-GNN outperforms existing state-of-the-art baselines. Our code is available at https://github.com/wdhyun/LEX-GNN.|基于图的欺诈检测面临重大挑战，如严重类别不平衡、由于欺诈节点稀缺导致连接不一致，以及这些节点伪装成良性节点的现象。现有研究通常采用过滤相似节点的方法来加强图神经网络的同质性假设。然而，为了有效解决这些问题，区分并自适应利用邻近节点的标签至关重要。在本研究中，我们提出了标签探索图神经网络（Label-Exploring Graph Neural Network, LEX-GNN），旨在通过主动利用带标签节点信息来增强欺诈检测。其核心思想是消息传递和接收的方式应根据节点类型而异。具体而言，我们首先基于节点的原始或先前表示预测其标签。随后，每个节点根据其欺诈概率的不同处理消息并进行传输。最后，目标节点也根据其预预测的欺诈概率以不同方式接收消息。在真实世界基准上的广泛实验结果表明，LEX-GNN优于现有的最先进基线方法。我们的代码可在 https://github.com/wdhyun/LEX-GNN 获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LEX-GNN:+Label-Exploring+Graph+Neural+Network+for+Accurate+Fraud+Detection)|0|
|[GraphVAE: Unveiling Dynamic Stock Relationships with Variational Autoencoder-based Factor Modeling](https://doi.org/10.1145/3627673.3679935)|Yulong Jia, Guanxing Li, Ganlong Zhao, Xiangru Lin, Guanbin Li|The University of Hong Kong, Hong Kong, China; Shanghai Long Life Quant Investment Co.,Ltd., Shenzhen, China; Sun Yat-sen University, Guangzhou, China|Factor models, originating in finance for asset pricing, are fundamental tools in quantitative investment. Recently, there has been a trend towards adopting more flexible machine learning approaches instead of previous linear models. However, traditional factor models and recent deep learning approaches either overlook the relationships among stocks or rely on static, predefined ones, which hampers their representational power and hinders their ability to dynamically adapt to market changes. To overcome this limitation, we introduce a novel dynamic factor model named GraphVAE. This model leverages temporal adaptive dynamic stock relationship graphs, facilitating improved information transfer among stocks within the dynamic probabilistic factor model. Experimental results on three real stock market datasets demonstrate that our method outperforms various state-of-the-art approaches.|因子模型起源于金融领域的资产定价，是量化投资中的基础工具。近年来，业界倾向于采用更为灵活的机器学习方法，而非传统的线性模型。然而，传统的因子模型和近期的深度学习方法要么忽略了股票之间的关系，要么依赖于静态、预定义的关系，这限制了它们的表达能力，并阻碍了它们对市场变化的动态适应性。为克服这一局限，我们提出了一种新颖的动态因子模型，名为GraphVAE。该模型利用时序自适应的动态股票关系图，促进了动态概率因子模型中股票间信息的更好传递。在三个真实股票市场数据集上的实验结果表明，我们的方法优于多种最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphVAE:+Unveiling+Dynamic+Stock+Relationships+with+Variational+Autoencoder-based+Factor+Modeling)|0|
|[Covariate Ordered Systematic Sampling as an Improvement to Randomized Controlled Trials](https://doi.org/10.1145/3627673.3679892)|Deddy Jobson, Yilin Li, Naoki Nishimura, Koya Ohashi, Jie Yang, Takeshi Matsumoto||The Randomized Controlled Trial (RCT) or A/B testing is considered the goldstandard method for estimating causal effects. Fisher famously advocatedrandomly allocating experiment units into treatment and control groups topreclude systematic biases. We propose a variant of systematic sampling calledCovariate Ordered Systematic Sampling (COSS). In COSS, we order experimentalunits using a pre-experiment covariate and allocate them alternately intotreatment and control groups. Using theoretical proofs, experiments onsimulated data, and hundreds of A/B tests conducted within 3 real-worldmarketing campaigns, we show how our method achieves better sensitivity gainsthan commonly used variance reduction techniques like CUPED while retaining thesimplicity of RCTs.|随机对照试验（RCT）或A/B测试被视为估计因果效应的金标准方法。费舍尔曾大力提倡通过随机分配实验单元到处理组和对照组来避免系统性偏差。我们提出了一种称为协变量有序系统抽样（Covariate Ordered Systematic Sampling，简称COSS）的系统抽样变体。在COSS中，我们利用实验前的协变量对实验单元进行排序，并交替将它们分配到处理组和对照组。通过理论证明、模拟数据实验以及在三个真实世界营销活动中进行的数百次A/B测试，我们展示了该方法如何在保持RCT简单性的同时，比常用的方差缩减技术（如CUPED）实现更好的敏感性提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Covariate+Ordered+Systematic+Sampling+as+an+Improvement+to+Randomized+Controlled+Trials)|0|
|[Flexi-clique: Exploring Flexible and Sub-linear Clique Structures](https://doi.org/10.1145/3627673.3679927)|Song Kim, Junghoon Kim, Susik Yoon, Jungeun Kim|Korea University, Seoul, Republic of Korea; Inha University, Incheon, Republic of Korea; Ulsan National Institute of Science & Technology, Ulsan, Republic of Korea|Identifying cohesive subgraphs within networks is a fundamental problem in graph theory, relevant to various domains. The traditional clique problem, which finds fully connected subgraphs, often faces limitations due to its strict connectivity requirements. This paper introduces a novel degree-based relaxation model called Flexi-clique, where the degree constraint is adjusted sub-linearly based on the subgraph size. We establish that the maximum Flexi-clique problem is NP-hard and propose an efficient and effective peeling algorithm to address it. Our extensive experimental evaluation of real-world datasets demonstrates the effectiveness and efficiency of our approach in discovering large, cohesive subgraphs in networks.|在网络中识别连贯子图是图论中的一个基本问题，与多个领域相关。传统的团问题（clique problem）寻找完全连接的子图，但由于其严格的连通性要求，常常面临局限性。本文提出了一种新颖的基于度的松弛模型，称为Flexi-clique，其中度约束根据子图大小进行亚线性调整。我们证明了最大Flexi-clique问题是NP难的，并提出了一种高效且有效的剥离算法来解决该问题。通过对真实世界数据集的广泛实验评估，我们展示了该方法在发现网络中大型连贯子图方面的有效性和高效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Flexi-clique:+Exploring+Flexible+and+Sub-linear+Clique+Structures)|0|
|[Intricate Object Detection in Self Driving Environments with Edge-Adaptive Depth Estimation(EADE)](https://doi.org/10.1145/3627673.3679948)|SuBi Kim, Jieun Kang, Yongik Yoon|; Department of IT Engineering, Sookmyung Women's University, Seoul, Republic of Korea|Autonomous vehicles make decisions and controls based on various object recognition results. The driving environment is characterized by the coexistence of a multitude of objects of varying shapes and sizes. Therefore, the ability to accurately recognise fine-grained objects is essential for accurate object recognition in a variety of changing situations. For object detection, the autonomous vehicle performs bounding box and segmentation to provide the detected object information. However, bounding box and segmentation based object detection has difficulties in identifying objects with complex shapes, small or distant objects, and it is hard to distinguish and detect objects with similar colors to the background or similar colors and textures to surrounding objects. This has limitations for reliable object identification in autonomous driving environments containing a variety of objects, which is a challenge for clear criteria-based object avoidance and collision protection. To overcome these limitations, this paper proposes Edge-Adaptive Depth Estimation(EADE). EADE, the combination of edge extraction and depth estimation, enables detailed edge extraction and partial distance estimation of objects even in environments where object shape and size, surrounding objects, and backgrounds make it difficult to recognise distinct objects, which allows for reliable autonomous decision-making and control based on detailed object collision and avoidance criteria. To validate EADE, experiments were conducted with real-world driving environment image data. The results of EADE demonstrate that detailed object recognition is possible with clear edge recognition and estimation of object distance, even for complex shaped objects such as trees with branches in multiple directions, distant objects, and objects that are difficult to distinguish from the background such as curbs.|自动驾驶车辆根据多种物体识别结果进行决策和控制。驾驶环境的特点是存在大量形状和大小各异的物体共存。因此，在各种变化情况下准确识别细粒度物体的能力对于精确的物体识别至关重要。在物体检测方面，自动驾驶车辆通过边界框和分割来提供检测到的物体信息。然而，基于边界框和分割的物体检测在识别形状复杂、小尺寸或远距离的物体时存在困难，并且难以区分和检测与背景颜色相似或与周围物体颜色和纹理相似的物体。这对于在包含多种物体的自动驾驶环境中进行可靠的物体识别存在局限性，这对基于明确标准的物体避让和碰撞保护构成了挑战。为了克服这些局限性，本文提出了边缘自适应深度估计（Edge-Adaptive Depth Estimation, EADE）。EADE结合了边缘提取和深度估计，即使在物体形状和大小、周围物体和背景使得难以识别明显物体的环境中，也能够进行详细的边缘提取和部分距离估计，从而基于详细的对象碰撞和避让标准实现可靠的自主决策和控制。为了验证EADE的有效性，本文使用真实驾驶环境图像数据进行了实验。实验结果表明，EADE能够通过清晰的边缘识别和物体距离估计实现详细的物体识别，即使是形状复杂的物体（如多方向分支的树木）、远距离物体以及难以与背景区分的物体（如路缘）也能被准确识别。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Intricate+Object+Detection+in+Self+Driving+Environments+with+Edge-Adaptive+Depth+Estimation(EADE))|0|
|[Ocean Significant Wave Height Estimation with Spatio-temporally Aware Large Language Models](https://doi.org/10.1145/3627673.3679973)|Zhe Li, Ronghui Xu, Jilin Hu, Zhong Peng, Xi Lu, Chenjuan Guo, Bin Yang||Significant wave height (SWH) is a vital metric in marine science, and accurate SWH estimation is crucial for various applications, e.g., marine energy development, fishery, early warning systems for potential risks, etc. Traditional SWH estimation methods that are based on numerical models and physical theories are hindered by computational inefficiencies. Recently, machine learning has emerged as an appealing alternative to improve accuracy and reduce computational time. However, due to limited observational technology and high costs, the scarcity of real-world data restricts the potential of machine learning models. To overcome these limitations, we propose an ocean SWH estimation framework, namely Orca. Specifically, Orca enhances the limited spatio-temporal reasoning abilities of classic LLMs with a novel spatiotemporal aware encoding module. By segmenting the limited buoy observational data temporally, encoding the buoys' locations spatially, and designing prompt templates, Orca capitalizes on the robust generalization ability of LLMs to estimate significant wave height effectively with limited data. Experimental results on the Gulf of Mexico demonstrate that Orca achieves state-of-the-art performance in SWH estimation.|有效波高（SWH）是海洋科学中的一个关键指标，准确的SWH估算对于海洋能源开发、渔业、潜在风险预警系统等多种应用至关重要。基于数值模型和物理理论的传统SWH估算方法受限于计算效率。近年来，机器学习作为一种有吸引力的替代方案，旨在提高估算精度并减少计算时间。然而，由于观测技术有限和高成本，现实世界数据的稀缺性限制了机器学习模型的潜力。为了克服这些限制，我们提出了一种海洋SWH估算框架，名为Orca。具体而言，Orca通过引入一个新颖的时空感知编码模块，增强了经典大语言模型（LLMs）在有限时空推理能力上的不足。通过时间上分割有限的浮标观测数据，空间上编码浮标位置，并设计提示模板，Orca利用LLMs强大的泛化能力，在有限数据下有效估算有效波高。在墨西哥湾的实验结果表明，Orca在SWH估算方面达到了最先进的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ocean+Significant+Wave+Height+Estimation+with+Spatio-temporally+Aware+Large+Language+Models)|0|
|[The Elusiveness of Detecting Political Bias in Language Models](https://doi.org/10.1145/3627673.3680002)|Riccardo Lunardi, David La Barbera, Kevin Roitero|University of Udine, Udine, Italy|This study challenges the prevailing approach of measuring political leanings in Large Language Models (LLMs) through direct questioning. By extensively testing LLMs with original, positively and negatively paraphrased Political Compass questions we demonstrate that LLMs do not consistently reveal their political biases in response to standard questions. Our findings indicate that LLMs' political orientations are elusive, easily influenced by subtle changes in phrasing and context. This study underscores the limitations of direct questioning in accurately measuring the political biases of LLMs and emphasizes the necessity for more refined and effective approaches to understand their true political stances.|本研究挑战了当前通过直接提问来衡量大型语言模型（LLMs）政治倾向的主流方法。通过广泛测试LLMs对原始、正面和负面改写的政治罗盘问题，我们证明LLMs在回答标准问题时并不一致地展现出其政治偏见。我们的研究结果表明，LLMs的政治倾向难以捉摸，容易受到措辞和语境微小变化的影响。本研究强调了直接提问在准确测量LLMs政治偏见方面的局限性，并强调了需要更精细和有效的方法来理解其真实的政治立场。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Elusiveness+of+Detecting+Political+Bias+in+Language+Models)|0|
|[ILTS: Inducing Intention Propagation in Decentralized Multi-Agent Tasks with Large Language Models](https://doi.org/10.1145/3627673.3679942)|Xihe Qiu, Haoyu Wang, Xiaoyu Tan, Chao Qu|Shanghai University of Engineering Science, Shanghai, China; INF Technology(Shanghai) Co., Ltd., Shanghai, China|Achieving coordination while avoiding suboptimal equilibria poses a significant challenge in decentralized multi-agent reinforcement learning (MARL) systems operating under limited global information. Conventional decentralized approaches have struggled to effectively induce cooperative behaviors between agents. We propose a novel hierarchical framework that synergistically combines large language models (LLMs) and deep reinforcement learning to address this challenge. Our proposed learning-to-share (ILTS) method decomposes the global objective into a two-level hierarchy: high-level LLM policy determines how to share rewards between neighboring agents to shape emergent collaboration, while low-level policies optimize the induced localized objectives using Q value networks. A meta-learning sophisticated dynamic reward-sharing scheme via LLMs is developed to facilitate decentralized cooperation without explicit communication. Experimental results demonstrate that ILTS outperforms prior MARL algorithms across cooperative multi-agent tasks by inducing collaborative strategies and performing intention propagation from lightweight learned signals. This hierarchical framework avoids the need for hand-engineered rewards or explicit communication while promoting scalable learning of intricate symbiotic behaviors between agents perceiving only local observations.|在有限全局信息下的分散式多智能体强化学习（MARL）系统中，实现协调并避免次优均衡是一个重大挑战。传统的分散式方法难以有效促进智能体间的合作行为。我们提出了一种新颖的分层框架，该框架将大型语言模型（LLMs）与深度强化学习协同结合，以应对这一挑战。我们提出的学习共享（ILTS）方法将全局目标分解为两个层次：高层次的LLM策略决定如何在与邻近智能体之间共享奖励，以塑造涌现的合作行为；而低层次的策略则利用Q值网络优化由此产生的局部目标。通过LLM开发的元学习复杂动态奖励共享方案，促进了分散式合作，而无需显式通信。实验结果表明，ILTS在合作多智能体任务中超越了之前的MARL算法，通过引发协作策略并从轻量级学习信号中进行意图传播。该分层框架避免了手工设计奖励或显式通信的需求，同时推动了仅感知局部观察的智能体之间复杂共生行为的可扩展学习。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ILTS:+Inducing+Intention+Propagation+in+Decentralized+Multi-Agent+Tasks+with+Large+Language+Models)|0|
|[Automation of Text-Based Economic Indicator Construction: A Pilot Exploration on Economic Policy Uncertainty Index](https://doi.org/10.1145/3627673.3679877)|HsiuHsuan Yeh, YuLieh Huang, Ziho Park, ChungChi Chen|; National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; Department of Economics, National Taiwan University, Taipei, Taiwan|The growing popularity of text-as-data in various domain-specific applications and research has often relied on manually selected keywords or annotations. Although labor-intensive, expensive and time-consuming, the effectiveness of these efforts is not always guaranteed, especially in the early stages of research. This predicament raises the question of the extent to which large language models (LLMs) can aid in verifying the potential of a nascent research idea. This paper seeks to explore the reliability of LLM-suggested keywords in the automatic construction of the Economic Policy Uncertainty (EPU) index. Our findings confirm that LLMs can effectively automate the construction of EPU index. Furthermore, we delve into the potential of LLMs in enhancing the indicator construction process.|随着数据即文本在各个领域特定应用和研究中的日益普及，其往往依赖于人工选择的关键词或标注。尽管这一过程劳动密集、成本高昂且耗时，但其效果并不总是有保障，尤其是在研究的早期阶段。这种困境引发了一个问题：大型语言模型（LLMs）在多大程度上能够辅助验证新兴研究理念的潜力。本文旨在探讨LLM推荐的关键词在自动构建经济政策不确定性（EPU）指数中的可靠性。我们的研究结果证实，LLMs能够有效自动化EPU指数的构建。此外，我们还深入探讨了LLMs在提升指标构建过程中的潜力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automation+of+Text-Based+Economic+Indicator+Construction:+A+Pilot+Exploration+on+Economic+Policy+Uncertainty+Index)|0|
|[Prioritized Binary Transformation Method for Efficient Multi-label Classification of Data Streams with Many Labels](https://doi.org/10.1145/3627673.3679980)|Onur Yildirim, Sepehr Bakhshi, Fazli Can|Bilkent University, Ankara, Turkey|Real-time data processing systems generate huge amounts of data that need to be classified. The volume, variety, velocity, and veracity (uncertainty) of this data necessitate new approaches and the adaptation of existing classification methods. Moreover, the arriving data can belong to more than one class at the same time. As the number of labels grows larger, a significant portion of the multi-label data stream classification methods become computationally inefficient. We propose a novel online approach: the Prioritized Binary Transformation (PBT) method, which can classify data with large numbers of labels by ordering the labels using Principal Component Analysis (PCA) within a fixed-size window. This order is then used to transform the label vectors for classification. We perform an empirical analysis on 12 datasets and compare PBT to four prominent baselines using four evaluation metrics. PBT achieves the best average ranking in three of the four evaluation metrics. Moreover, we investigate efficiency under average execution time per data item and memory consumption where PBT achieves second and first average rankings, respectively.|实时数据处理系统产生了大量需要进行分类的数据。这些数据的体量、多样性、速度和准确性（不确定性）要求采用新的方法并调整现有的分类技术。此外，到达的数据可能同时属于多个类别。随着标签数量的增加，许多多标签数据流分类方法在计算上变得效率低下。我们提出了一种新颖的在线方法：优先级二值化变换（PBT）方法，该方法通过在固定大小的窗口内使用主成分分析（PCA）对标签进行排序，从而对具有大量标签的数据进行分类。然后，利用这个顺序对标签向量进行变换以进行分类。我们在12个数据集上进行了实证分析，并使用四种评估指标将PBT与四种著名的基线方法进行了比较。PBT在其中三种评估指标上取得了最佳的平均排名。此外，我们在每个数据项的平均执行时间和内存消耗方面研究了效率，PBT在这两项指标上分别取得了第二和第一的平均排名。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Prioritized+Binary+Transformation+Method+for+Efficient+Multi-label+Classification+of+Data+Streams+with+Many+Labels)|0|
|[Forecasting Live Chat Intent from Browsing History](https://doi.org/10.1145/3627673.3679928)|Seeun Yoon, Ahmad Bin Rabiah, Zaid Alibadi, Surya Kallumadi, Julian J. McAuley||Customers reach out to online live chat agents with various intents, such as asking about product details or requesting a return. In this paper, we propose the problem of predicting user intent from browsing history and address it through a two-stage approach. The first stage classifies a user's browsing history into high-level intent categories. Here, we represent each browsing history as a text sequence of page attributes and use the ground-truth class labels to fine-tune pretrained Transformers. The second stage provides a large language model (LLM) with the browsing history and predicted intent class to generate fine-grained intents. For automatic evaluation, we use a separate LLM to judge the similarity between generated and ground-truth intents, which closely aligns with human judgments. Our two-stage approach yields significant performance gains compared to generating intents without the classification stage.|用户在与在线客服进行实时聊天时，可能会表达各种意图，例如询问产品详情或申请退货。本文提出了从浏览历史中预测用户意图的问题，并采用两阶段方法来解决。第一阶段将用户的浏览历史分类为高层次的意图类别。在此阶段，我们将每段浏览历史表示为页面属性的文本序列，并利用真实类别标签对预训练的Transformer模型进行微调。第二阶段则将浏览历史和预测的意图类别输入大型语言模型（LLM），以生成细粒度的意图。为了进行自动评估，我们使用另一个LLM来判断生成意图与真实意图之间的相似度，这一判断与人类判断高度一致。与不经过分类阶段直接生成意图的方法相比，我们的两阶段方法显著提升了性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Forecasting+Live+Chat+Intent+from+Browsing+History)|0|
|[XRDMamba: Large-scale Crystal Material Space Group Identification with Selective State Space Model](https://doi.org/10.1145/3627673.3680006)|Liheng Yu, Pengkun Wang, Zhe Zhao, Zhongchao Yi, Sun Nan, Di Wu, Yang Wang|University of Science and Technology of China, Suzhou, Jiangsu, China; Huazhong University of Science and Technology, Wuhan, Jiangsu, China|In material science, the properties of crystalline materials largely depend on their structures, and space group is a key descriptor of crystal structure. With the rapid advancement of deep learning, the traditional artificial structure analysis method based on X-ray diffraction (XRD) has become cumbersome and is being gradually supplanted by neural networks. However, existing models are too simplistic and lack a comprehensive understanding of material structure. Our approach XRDMamba integrates chemical knowledge and presents a fresh crystal planes perspective on XRD data. We also introduce a knowledge-driven model for space group identification tasks. We have thoroughly analyzed our approach through numerous experiments, observing its SOTA performance and excellent generalization capabilities. The code is available in ~https://github.com/baigeiguai/XRDMamba.|在材料科学中，晶体材料的性质很大程度上取决于其结构，而空间群是晶体结构的关键描述符。随着深度学习的快速发展，基于X射线衍射（XRD）的传统人工结构分析方法已显得繁琐，并逐渐被神经网络所取代。然而，现有模型过于简单，对材料结构的全面理解不足。我们的方法XRDMamba结合了化学知识，从晶面角度对XRD数据进行了全新解读，并引入了一种知识驱动型模型用于空间群识别任务。我们通过大量实验对所提出的方法进行了全面分析，观察到其达到了当前最佳性能，并展现了出色的泛化能力。相关代码可在~https://github.com/baigeiguai/XRDMamba获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=XRDMamba:+Large-scale+Crystal+Material+Space+Group+Identification+with+Selective+State+Space+Model)|0|
|[Long-Term Hydrologic Time Series Prediction with LSPM](https://doi.org/10.1145/3627673.3679957)|Sicheng Zhou, David C. Anastasiu|Santa Clara University, Santa Clara, CA, USA; PRISMS High School, Princeton, NJ, USA|Predicting multivariate time series has been a topic of interest among researchers for a long time, especially in hydrological prediction. Due to the presence of extreme events, hydrological prediction requires capturing long-range dependencies and modeling rare but significant extreme values. Accurate prediction of these dependencies is often accomplished using complex models, such as stacked RNNs or transformer-based models, which can be computationally expensive and challenging to train. In addition, existing studies have identified a strong correlation between streamflow and rainfall data. However, the use of additional input data in these studies has often been insufficient, resulting in predictions with low accuracy. In this paper, we address these issues and propose LSPM, a Long Short-term Polar-Learning time series forecasting Model. LSPM learns polar representations through a feature reuse method called EDDU (Encoder Double-Decoder Unit). EDDU creatively incorporates exogenous input to generate long-term predictions based on these learned representations. To maximize the use of indicator sequences from exogenous data, LSPM enhances short-term predictions by a carefully designed loss function and integrates them into the overall forecast, improving robustness to short-term severe events. Experiments on four real-life hydrologic streamflow datasets demonstrate that LSPM significantly outperforms both state-of-the-art hydrologic time series prediction methods and general methods designed for long-term time series prediction.|预测多元时间序列一直是研究者们长期关注的课题，特别是在水文预测领域。由于极端事件的存在，水文预测需要捕捉长程依赖性并建模罕见但显著的极端值。准确预测这些依赖性通常依赖于复杂的模型，如堆叠的循环神经网络（RNNs）或基于Transformer的模型，这些模型在计算上开销大且训练难度高。此外，现有研究已发现径流量与降雨数据之间存在强相关性。然而，这些研究中对额外输入数据的使用往往不足，导致预测精度较低。本文针对这些问题，提出了LSPM（Long Short-term Polar-Learning time series forecasting Model），一种长短期极性学习时间序列预测模型。LSPM通过一种称为EDDU（Encoder Double-Decoder Unit）的特征复用方法学习极性表示。EDDU创新性地结合外源输入，基于这些学习到的表示生成长期预测。为了最大化利用外源数据的指示序列，LSPM通过精心设计的损失函数增强了短期预测，并将它们整合到整体预测中，从而提高了对短期严重事件的鲁棒性。在四个真实水文径流数据集上的实验表明，LSPM显著优于现有的最先进水文时间序列预测方法以及为长期时间序列预测设计的一般方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Long-Term+Hydrologic+Time+Series+Prediction+with+LSPM)|0|
|[Boosting Entity Recognition by leveraging Cross-task Domain Models for Weak Supervision](https://doi.org/10.1145/3627673.3680009)|Sanjay Agrawal, Srujana Merugu, Vivek Sembium|Amazon.com Inc., Bengaluru, India|Entity Recognition (ER) is a common natural language processing task encountered in a number of real-world applications. For common domains and named entities such as places and organisations, there exists sufficient high quality annotated data and foundational models such as T5 and GPT-3.5 also provide highly accurate predictions. However, for niche domains such as e-commerce and medicine with specialized entity types, there is a paucity of labeled data since manual labeling of tokens is often time-consuming and expensive, which makes entity recognition challenging for such domains. Recent works such as NEEDLE [48] propose hybrid solutions to efficiently combine a small amount of strongly labeled (human-annotated) with a large amount of weakly labeled (distant supervision) data to yield superior performance relative to supervised training. The extensive noise in the weakly labeled data, however, remains a challenge. In this paper, we propose WeSDoM (Weak Supervision with Domain Models), which leverages pretrained encoder models from the same domain but different tasks to create domain ontologies that can enable the creation of less noisy weakly labeled data. Experiments on internal e-commerce and public biomedical NER datasets demonstrate that WeSDoM outperforms existing SOTA baselines by a significant margin. We achieve new SOTA F1 scores on two popular Biomedical NER datasets, BC5CDR-chem 94.27, BC5CDR-disease 91.23.|实体识别（ER）是自然语言处理中常见的一项任务，广泛应用于多个现实场景中。对于常见的领域和命名实体（如地点和组织），现有高质量的标注数据充足，且基础模型如T5和GPT-3.5也能提供高度准确的预测。然而，对于电子商务和医疗等专业领域，由于特定实体类型的标注数据稀缺，手动标注词元既耗时又成本高昂，这使得在这些领域进行实体识别变得极具挑战性。近期研究如NEEDLE[48]提出了混合解决方案，通过高效结合少量强标注（人工标注）数据和大量弱标注（远程监督）数据，相较于仅依赖监督训练的方法，取得了更优的性能。然而，弱标注数据中广泛存在的噪声问题仍未得到解决。本文提出了WeSDoM（基于领域模型的弱监督），该方法利用同一领域内但不同任务的预训练编码器模型，构建领域本体，从而生成噪声更少的弱标注数据。我们在内部电子商务数据集和公开的生物医学NER数据集上进行的实验表明，WeSDoM显著超越了现有的最先进基线模型。我们在两个流行的生物医学NER数据集上取得了新的最先进F1分数：BC5CDR-chem达到94.27，BC5CDR-disease达到91.23。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Boosting+Entity+Recognition+by+leveraging+Cross-task+Domain+Models+for+Weak+Supervision)|0|
|[PlayBest: Professional Basketball Player Behavior Synthesis via Planning with Diffusion](https://doi.org/10.1145/3627673.3680092)|Xiusi Chen, WeiYao Wang, Ziniu Hu, David Reynoso, Kun Jin, Mingyan Liu, P. Jeffrey Brantingham, Wei Wang||Dynamically planning in complex systems has been explored to improve decision-making in various domains. Professional basketball serves as a compelling example of a dynamic spatio-temporal game, encompassing context-dependent decision-making. However, processing the diverse on-court signals and navigating the vast space of potential actions and outcomes make it difficult for existing approaches to swiftly identify optimal strategies in response to evolving circumstances. In this study, we formulate the sequential decision-making process as a conditional trajectory generation process. Based on the formulation, we introduce PlayBest (PLAYer BEhavior SynThesis), a method to improve player decision-making. We extend the diffusion probabilistic model to learn challenging environmental dynamics from historical National Basketball Association (NBA) player motion tracking data. To incorporate data-driven strategies, an auxiliary value function is trained with corresponding rewards. To accomplish reward-guided trajectory generation, we condition the diffusion model on the value function via classifier-guided sampling. We validate the effectiveness of PlayBest through simulation studies, contrasting the generated trajectories with those employed by professional basketball teams. Our results reveal that the model excels at generating reasonable basketball trajectories that produce efficient plays. Moreover, the synthesized play strategies exhibit an alignment with professional tactics, highlighting the model's capacity to capture the intricate dynamics of basketball games.|在复杂系统中动态规划已被探索用于提升各领域的决策能力。职业篮球作为动态时空游戏的典型例子，包含了依赖上下文的决策过程。然而，处理多样化的场上信号并导航于庞大的潜在行动和结果空间，使得现有方法难以迅速识别出应对不断变化情况的最佳策略。在本研究中，我们将序列决策过程形式化为条件轨迹生成过程。基于此形式化，我们提出了PlayBest（PLAYer BEhavior SynThesis），一种用于提升球员决策的方法。我们扩展了扩散概率模型，以从历史NBA球员运动追踪数据中学习复杂的环境动态。为了整合数据驱动策略，我们训练了一个辅助价值函数，并赋予其相应的奖励。为了实现奖励引导的轨迹生成，我们通过分类器引导采样将扩散模型与价值函数相结合。我们通过模拟研究验证了PlayBest的有效性，对比了生成的轨迹与职业篮球队所使用的轨迹。结果显示，该模型在生成合理的篮球轨迹方面表现出色，这些轨迹能够产生高效的战术。此外，合成的战术策略与职业战术相吻合，突显了模型捕捉篮球比赛复杂动态的能力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PlayBest:+Professional+Basketball+Player+Behavior+Synthesis+via+Planning+with+Diffusion)|0|
|[GraphScale: A Framework to Enable Machine Learning over Billion-node Graphs](https://doi.org/10.1145/3627673.3680021)|Vipul Gupta, Xin Chen, Ruoyun Huang, Fanlong Meng, Jianjun Chen, Yujun Yan||Graph Neural Networks (GNNs) have emerged as powerful tools for supervised machine learning over graph-structured data, while sampling-based node representation learning is widely utilized in unsupervised learning. However, scalability remains a major challenge in both supervised and unsupervised learning for large graphs (e.g., those with over 1 billion nodes). The scalability bottleneck largely stems from the mini-batch sampling phase in GNNs and the random walk sampling phase in unsupervised methods. These processes often require storing features or embeddings in memory. In the context of distributed training, they require frequent, inefficient random access to data stored across different workers. Such repeated inter-worker communication for each mini-batch leads to high communication overhead and computational inefficiency. We propose GraphScale, a unified framework for both supervised and unsupervised learning to store and process large graph data distributedly. The key insight in our design is the separation of workers who store data and those who perform the training. This separation allows us to decouple computing and storage in graph training, thus effectively building a pipeline where data fetching and data computation can overlap asynchronously. Our experiments show that GraphScale outperforms state-of-the-art methods for distributed training of both GNNs and node embeddings. We evaluate GraphScale both on public and proprietary graph datasets and observe a reduction of at least 40 end-to-end training times compared to popular distributed frameworks, without any loss in performance. While most existing methods don't support billion-node graphs for training node embeddings, GraphScale is currently deployed in production at TikTok enabling efficient learning over such large graphs.|图神经网络（GNN）已成为处理图结构数据监督式机器学习的强大工具，而基于采样的节点表示学习则在无监督学习中得到广泛应用。然而，在处理大规模图数据（例如包含超过十亿节点的图）时，无论是在监督学习还是无监督学习中，可扩展性仍然是一个重大挑战。这一瓶颈主要源于GNN中的小批量采样阶段以及无监督方法中的随机游走采样阶段。这些过程通常需要将特征或嵌入存储在内存中。在分布式训练的背景下，它们需要频繁且低效地随机访问存储在不同工作节点上的数据。这种针对每个小批量的重复跨节点通信导致了高昂的通信开销和计算效率低下。

我们提出了GraphScale，这是一个统一的框架，旨在分布式地存储和处理大规模图数据，适用于监督和无监督学习。我们设计的关键洞察在于将存储数据的工作节点与执行训练的工作节点分离。这种分离使得我们能够在图训练中解耦计算与存储，从而有效地构建一个流水线，使得数据获取与数据计算可以异步重叠进行。我们的实验表明，GraphScale在分布式训练GNN和节点嵌入方面优于最先进的方法。我们在公开和专有的图数据集上评估了GraphScale，并观察到与流行的分布式框架相比，至少减少了40%的端到端训练时间，且性能没有任何损失。尽管大多数现有方法不支持对十亿节点规模的图进行节点嵌入训练，但GraphScale已在TikTok的生产环境中部署，能够高效地处理此类大规模图数据的学习任务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphScale:+A+Framework+to+Enable+Machine+Learning+over+Billion-node+Graphs)|0|
|[Cryptocurrency Price Forecasting using Variational Autoencoder with Versatile Quantile Modeling](https://doi.org/10.1145/3627673.3680027)|Sungchul Hong, SeungHwan An, JongJune Jeon|Department of Statistical Data Science, University of Seoul, Seoul, Republic of Korea; Department of Statistics, University of Seoul, Seoul, Republic of Korea|In recent years, there has been a growing interest in probabilistic forecasting methods that offer more comprehensive insights by considering prediction uncertainties rather than point estimates. This paper introduces a novel variational autoencoder learning framework for multivariate distributional forecasting. Our approach employs distributional learning to directly estimate the cumulative distribution function of future time series conditional distributions using the continuous ranked probability score. By incorporating a temporal structure within the latent space and utilizing versatile quantile models, such as the generalized lambda distribution, we enable distributional forecasting by generating synthetic time series data for future time points. To assess the effectiveness of our method, we conduct experiments using a multivariate dataset of real cryptocurrency prices, demonstrating its superiority in forecasting high-volatility scenarios.|近年来，针对预测不确定性而非点估计的概率预测方法引起了越来越多的关注，这些方法通过提供更全面的见解来增强预测的可靠性。本文提出了一种新颖的变分自编码器学习框架，用于多变量分布式预测。我们的方法采用分布式学习，直接利用连续排名概率分数来估计未来时间序列条件分布的累积分布函数。通过在潜在空间中结合时间结构并利用多种分位数模型（如广义lambda分布），我们能够通过生成未来时间点的合成时间序列数据来实现分布式预测。为了评估我们方法的有效性，我们使用了一个包含真实加密货币价格的多变量数据集进行实验，结果表明，在预测高波动性场景时，该方法具有显著优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cryptocurrency+Price+Forecasting+using+Variational+Autoencoder+with+Versatile+Quantile+Modeling)|0|
|[DAMOCRO: A Data Migration Framework Using Online Classification and Reordering](https://doi.org/10.1145/3627673.3680097)|Zhongxin Hu, Kaiyu Li, Xingjian Mao, Jingfeng Pan, Yunfei Peng, Aijun An, Xiaohui Yu, Dariusz Jania|IBM Cloud and Cognitive Software, Warszawa, Poland; York University, Toronto, Canada|This paper introduces DAMOCRO, a data migration framework using online classification and tuple reordering to improve throughput and decrease the costs of data migration. The DAMOCRO workflow consists of four main steps. First, it classifies records into subgroups to maximize the similarity within each group. Next, it reorders tuples within these groups, ensuring that similar tuples are adjacent. Subsequently, column-wise compression is applied to each group. Finally, the compressed data is transferred from the source to the target machine. The initial two steps enhance the compression ratio, thereby boosting throughput and reducing costs. Our evaluations on five real-world datasets and two benchmark datasets, show that the online classification process in DAMOCRO improves throughput by more than 24% and reduces costs by over 19% compared to baselines. Besides, implementing reordering based on functional dependencies brings an additional cost reduction ranging from 10% to 60%, while also enhancing throughput.|本文介绍了DAMOCRO，这是一个利用在线分类和元组重排序来提高数据迁移吞吐量并降低成本的数据迁移框架。DAMOCRO的工作流程包括四个主要步骤。首先，它将记录分类到子组中，以最大化每个组内的相似性。接着，它对这些组内的元组进行重排序，确保相似的元组彼此相邻。随后，对每个组应用列式压缩。最后，将压缩后的数据从源机器传输到目标机器。前两个步骤提高了压缩率，从而提升了吞吐量并降低了成本。我们在五个真实世界数据集和两个基准数据集上的评估表明，DAMOCRO中的在线分类过程使吞吐量提高了24%以上，成本降低了19%以上，相较于基线方法。此外，基于函数依赖实现的重排序带来了额外的成本降低，范围在10%到60%之间，同时也提高了吞吐量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DAMOCRO:+A+Data+Migration+Framework+Using+Online+Classification+and+Reordering)|0|
|[XCapsUTL: Cross-domain Unsupervised Transfer Learning Framework using a Capsule Neural Network](https://doi.org/10.1145/3627673.3680053)|Naman Khetan, Sanyog Dewani, Gokul Swamy, Vikalp Gajbhiye|Amazon, Seattle, USA; Amazon, Bengaluru, India; Amazon, Delhi, India|As e-commerce stores broaden their reach into new regions and introduce new products within established markets, the development of effective machine learning models becomes increasingly challenging due to the scarcity of labeled data. Traditional transfer learning methods typically require some labeled data from the target domain and often face computational bottlenecks. Despite the availability of a few transfer learning techniques, most are primarily developed for vision and text applications, making them unsuitable for other types of data. In many industries, however, tabular data is a predominant and crucial data type. Our work introduces XCapsUTL, a novel unsupervised transfer learning framework specifically designed for tabular data, aiming to fill this significant gap. Our approach leverages Capsule Neural Networks (CapsNet) to extract domain-agnostic knowledge. This knowledge is then refined using a constrained fine-tuning process, ensuring adaptability to the target task while preserving learned representations. XCapsUTL's unique feature encapsulation capabilities within CapsNet promote effective knowledge transfer without the need for designing effective feature-wise interaction approaches to capture higher-level semantics. Extensive experiments demonstrate the robustness and generalization capabilities of XCapsUTL across multiple domains and datasets, highlighting its practical significance and utility in addressing the unique challenges of tabular data in industry settings.|随着电子商务商店将其业务扩展到新区域并在已建立的市场中引入新产品，由于标签数据的稀缺，开发有效的机器学习模型变得越来越具有挑战性。传统的迁移学习方法通常需要目标领域的一些标签数据，并且经常面临计算瓶颈。尽管存在一些迁移学习技术，但大多数主要为视觉和文本应用而开发，因此不适用于其他类型的数据。然而，在许多行业中，表格数据是一种占主导地位且至关重要的数据类型。我们的工作引入了XCapsUTL，这是一种专为表格数据设计的新型无监督迁移学习框架，旨在填补这一重要空白。我们的方法利用胶囊神经网络（CapsNet）来提取领域无关的知识。然后，通过受限的微调过程对这些知识进行精炼，确保适应目标任务的同时保留学习到的表示。XCapsUTL在CapsNet中的独特特征封装能力促进了有效的知识迁移，而无需设计有效的特征间交互方法来捕捉更高层次的语义。广泛的实验证明了XCapsUTL在多个领域和数据集上的鲁棒性和泛化能力，突显了其在解决行业环境中表格数据独特挑战方面的实际意义和实用性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=XCapsUTL:+Cross-domain+Unsupervised+Transfer+Learning+Framework+using+a+Capsule+Neural+Network)|0|
|[EFfECT-RL: Enabling Framework for Establishing Causality and Triggering engagement through RL](https://doi.org/10.1145/3627673.3680058)|Debanjan Sadhukhan, Deepanshi Seth, Sanjay Agrawal, Tridib Mukherjee|Games 24x7, Bangalore, Karnataka, India|Skill-based games offer an exceptional avenue for entertainment, fostering self-esteem, relaxation, and social satisfaction. Engagement in online skill gaming platforms is however heavily dependent on the outcomes and experience (e.g., wins/losses). Understanding the factors driving increased engagement is crucial within skill gaming platforms. In this study, we aim to address two key questions: (1) "What factors are driving users to increase their engagement?" and (2) "How can we personalize users journey accordingly to further optimize their engagement?". In skill gaming platforms, the impact of causal relationships often manifests with a delay, which varies significantly as users? personas evolve. Without a detailed information on treatments (such as timing and frequency), estimating the impact of a causal-treatment-effect in a highly volatile game-play data becomes exceedingly challenging. This work proposes a framework called EFfECT-RL that establishes causal discovery by integrating change-point detection and explainable K-means clustering, while leveraging users' game-play and transactional-data. Unlike existing methods which were unable to detect causal-effects in extremely volatile-data, EFfECT-RL generates threshold-trees (~ 79% accuracy) elucidating causal-relationships. Once the causal relationship is established, we personalize treatments by developing a novel offline deep reinforcement learning-based approach. Our online recommendations show a 3% improvement in user engagement (platform-centric) with 70% relevancy (user-centric).|基于技能的游戏为娱乐提供了一个独特的途径，能够促进自信心、放松感和社交满足感。然而，在线技能游戏平台的参与度很大程度上依赖于游戏结果和体验（例如胜负情况）。理解推动用户增加参与度的因素对于技能游戏平台至关重要。本研究旨在回答两个关键问题：（1）“哪些因素推动用户增加参与度？”和（2）“我们如何根据这些因素个性化用户的旅程，以进一步优化他们的参与度？”在技能游戏平台中，因果关系的影响通常会延迟显现，且随着用户个人特征的变化，延迟时间差异显著。在没有详细的治疗信息（如时间和频率）的情况下，估计高度波动的游戏数据中的因果治疗效果变得极为困难。本研究提出了一种名为EFfECT-RL的框架，通过整合变化点检测和可解释的K-means聚类来建立因果发现，同时利用用户的游戏数据和交易数据。与无法在极端波动的数据中检测因果效应的现有方法不同，EFfECT-RL生成了阈值树（准确率约为79%），阐明了因果关系。一旦建立了因果关系，我们通过开发一种新颖的基于离线深度强化学习的方法来个性化治疗。我们的在线推荐显示，用户参与度（以平台为中心）提高了3%，且相关性（以用户为中心）达到70%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EFfECT-RL:+Enabling+Framework+for+Establishing+Causality+and+Triggering+engagement+through+RL)|0|
|[CPFD: Confidence-aware Privileged Feature Distillation for Short Video Classification](https://doi.org/10.1145/3627673.3680045)|Jinghao Shi, Xiang Shen, Kaili Zhao, Xuedong Wang, Vera Wen, Zixuan Wang, Yifan Wu, Zhixin Zhang||Dense features, customized for different business scenarios, are essential in short video classification. However, their complexity, specific adaptation requirements, and high computational costs make them resource-intensive and less accessible during online inference. Consequently, these dense features are categorized as `Privileged Dense Features'.Meanwhile, end-to-end multi-modal models have shown promising results in numerous computer vision tasks. In industrial applications, prioritizing end-to-end multi-modal features, can enhance efficiency but often leads to the loss of valuable information from historical privileged dense features.To integrate both features while maintaining efficiency and manageable resource costs, we present Confidence-aware Privileged Feature Distillation (CPFD), which empowers features of an end-to-end multi-modal model by adaptively distilling privileged features during training.Unlike existing privileged feature distillation (PFD) methods, which apply uniform weights to all instances during distillation, potentially causing unstable performance across different business scenarios and a notable performance gap between teacher model (Dense Feature enhanced multimodal-model DF-X-VLM) and student model (multimodal-model only X-VLM), our CPFD leverages confidence scores derived from the teacher model to adaptively mitigate the performance variance with the student model.We conducted extensive offline experiments on five diverse tasks demonstrating that CPFD improves the video classification F1 score by 6.76 multimodal-model (X-VLM) and by 2.31 reduces the performance gap by 84.6 model DF-X-VLM. The effectiveness of CPFD is further substantiated by online experiments, and our framework has been deployed in production systems for over a dozen models.|在短视频分类中，针对不同业务场景定制的密集特征是不可或缺的。然而，这些密集特征的复杂性、特定适配需求以及高计算成本使得它们在资源消耗上较为沉重，且在在线推理过程中不易获取。因此，这些密集特征被归类为“特权密集特征”。同时，端到端的多模态模型在众多计算机视觉任务中展现出令人瞩目的成果。在工业应用中，优先采用端到端的多模态特征可以提升效率，但往往导致历史特权密集特征中的宝贵信息丢失。

为了在保持效率和可控资源成本的前提下整合这两类特征，我们提出了**置信度感知的特权特征蒸馏（Confidence-aware Privileged Feature Distillation, CPFD）**，该方法在训练过程中通过自适应地蒸馏特权特征，增强了端到端多模态模型的特征表现。与现有的特权特征蒸馏（PFD）方法不同，这些方法在蒸馏过程中对所有实例应用统一权重，可能导致在不同业务场景下性能不稳定，并且教师模型（密集特征增强的多模态模型 DF-X-VLM）与学生模型（仅多模态模型 X-VLM）之间的性能差距显著。我们的 CPFD 方法利用教师模型生成的置信度分数，自适应地减少学生模型与教师模型之间的性能差异。

我们在五个不同的任务上进行了广泛的离线实验，结果表明 CPFD 将多模态模型（X-VLM）的视频分类 F1 分数提升了 6.76，并将教师模型 DF-X-VLM 与学生模型 X-VLM 之间的性能差距缩小了 2.31，缩小幅度达 84.6%。在线实验进一步验证了 CPFD 的有效性，我们的框架已在生产系统中部署，服务于十几个模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CPFD:+Confidence-aware+Privileged+Feature+Distillation+for+Short+Video+Classification)|0|
|[Dynamic Graph-based Deep Reinforcement Learning with Long and Short-term Relation Modeling for Portfolio Optimization](https://doi.org/10.1145/3627673.3680039)|Haoyu Sun, Yuxuan Bian, Li Han, Peng Zhu, Dawei Cheng, Yuqi Liang|; Seek Data Group, Emoney Inc., Shanghai, China; Department of Computer Science, The Chinese University of Hong Kong, HongKong, China; Department of Computer Science, Tongji University, Shanghai, China|Portfolio optimization is a significant concern in finance. Existing research on portfolio optimization fails to adequately learn from the long and short-term relationships among equities, which inevitably leads to suboptimal performance. In this paper, we propose a Dynamic Graph-based Deep Reinforcement Learning (DGDRL) for optimal portfolio decisions. We achieve this goal by devising two mechanisms for naturally modeling the financial market. Firstly, we utilize the static and dynamic graphs to represent the long and short-term relations, which are then naturally represented by the proposed multi-channel graph attention neural network. Secondly, compared with the traditional two-phase approach, forecasting equity's trend and then weighting them by combinatorial optimization, we naturally optimize the portfolio decisions, which could directly guide the model to converge to optimal rewards. Through extensive experiments on three real-world datasets, we have demonstrated that our method significantly outperforms state-of-the-art benchmark methods in portfolio management. Furthermore, the evaluation of the industrial trading system has shown the applicability of our model to real-world financial markets.|投资组合优化是金融领域的一个重要课题。现有的投资组合优化研究未能充分学习股票之间的长期和短期关系，这不可避免地导致了次优的性能。本文提出了一种基于动态图的深度强化学习（DGDRL）方法，用于优化投资决策。我们通过设计两种机制来自然地建模金融市场，从而实现这一目标。首先，我们利用静态和动态图来表示长期和短期关系，这些关系通过提出的多通道图注意力神经网络自然地表示出来。其次，与传统的两阶段方法（先预测股票趋势，然后通过组合优化对其进行加权）相比，我们自然地优化了投资组合决策，这可以直接指导模型收敛到最优回报。通过在三个真实世界数据集上的广泛实验，我们证明了该方法在投资组合管理方面显著优于最先进的基准方法。此外，工业交易系统的评估也显示了该模型在实际金融市场中的适用性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamic+Graph-based+Deep+Reinforcement+Learning+with+Long+and+Short-term+Relation+Modeling+for+Portfolio+Optimization)|0|
|[Behavior-aware Sparse Trajectory Recovery in Last-mile Delivery with Multi-scale Attention Fusion](https://doi.org/10.1145/3627673.3680079)|Hai Wang, Shuai Wang, Li Lin, Yu Yang, Shuai Wang, Hongkai Wen|University of Warwick, Coventry, United Kingdom; Southeast University, Nanjing, China; Lehigh University, Bethlehem, PA, USA; Southeast University & JD Logistic, Nanjing, China|Trajectory data is a valuable asset for service management and spatio-temporal mining in transportation and logistics systems. However, due to equipment failure, network delay, and energy constraints, some trajectory point may be missed, which makes it difficult for trajectory-based management. Some researchers have focused on recovering sparse trajectories from road networks and historical trajectory data, but these methods are ineffective when the road network is incomplete. Recent research works have explored learning-based methods to recover trajectories in free space but lack user movement behavior modeling and efficient feature extraction on sparse long-range trajectories. Our work exploits the periodic behavior of couriers and fine-grained Area of Interest (AOI) data for sparse trajectory recovery in last-mile delivery. However, we face challenges with AOI access sequence deviations due to GPS inaccuracies and abnormal courier behaviors, as well as the complex, dynamic relationships within and between courier routes due to uncertain pick-up demands. To address these challenges, we design a graph-based multi-task learning framework, focusing on multi-scale attention fusion for end-to-end free space trajectory recovery. Our approach starts with a behavior-aware graph network that generates detailed spatial features. Following this, we propose a multi-scale attention fusion mechanism to extract intra- and inter-trajectory features. Finally, we design a multi-task learning module that predicts both coarse-grained spatial access sequences and fine-grained trajectory points. We evaluate the model with six-month data involved with more than 360,000 trajectory segments and more than 7.2 million waybills collected from one of the largest logistic companies in China. Extensive experiments on real-world datasets demonstrate that our method outperforms state-of-the-arts in multiple metrics.|轨迹数据是交通和物流系统中服务管理与时空挖掘的宝贵资源。然而，由于设备故障、网络延迟和能源限制，某些轨迹点可能会缺失，从而增加了基于轨迹的管理难度。一些研究者专注于从道路网络和历史轨迹数据中恢复稀疏轨迹，但这些方法在道路网络不完整时效果不佳。近期的研究工作探索了基于学习的方法来恢复自由空间中的轨迹，但缺乏对用户移动行为的建模以及在稀疏长距离轨迹上的高效特征提取。我们的工作利用了快递员的周期性行为和细粒度的兴趣区域（AOI）数据，以实现最后一公里配送中的稀疏轨迹恢复。然而，我们面临GPS精度不足和快递员异常行为导致的AOI访问序列偏差问题，以及由于不确定的取件需求而产生的快递路线间复杂动态关系。为应对这些挑战，我们设计了一个基于图的多任务学习框架，专注于多尺度注意力融合，以实现端到端的自由空间轨迹恢复。我们的方法首先通过一个行为感知的图网络生成详细的空间特征。接着，我们提出了一种多尺度注意力融合机制，以提取轨迹内部和轨迹间的特征。最后，我们设计了一个多任务学习模块，用于同时预测粗粒度的空间访问序列和细粒度的轨迹点。我们使用中国最大的物流公司之一提供的六个月数据进行模型评估，涉及超过36万条轨迹段和超过720万张运单。在真实世界数据集上的广泛实验表明，我们的方法在多个指标上优于现有技术。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Behavior-aware+Sparse+Trajectory+Recovery+in+Last-mile+Delivery+with+Multi-scale+Attention+Fusion)|0|
|[CourIRL: Predicting Couriers' Behavior in Last-Mile Delivery Using Crossed-Attention Inverse Reinforcement Learning](https://doi.org/10.1145/3627673.3680046)|Shuai Wang, Tongtong Kong, Baoshen Guo, Li Lin, Haotian Wang|Southeast University & JD Logistics, Nanjing, China; Southeast University, Nanjing, China; JD Logistics, Beijing, China|Human behavior prediction is an essential AI-based task, which has inspired many real-world applications. In last-mile logistics, predicting couriers' behavior can benefit the couriers' preference learning and workflow optimization. In this paper, we devote to the behavioral prediction of courier workload and quantify their workload by the working time spent at each area of interest (AOI). Considering the behavior interpretability of inverse reinforcement learning (IRL), existing studies have applied IRL to some real-world transportation prediction scenarios. However, in last-mile logistics, the platform assigns multiple orders to each courier, and couriers also receive new tasks in real-time, which additionally influence the couriers' subsequent decisions. The uncertainty in decision spaces and dynamic the workflow distribution make it more challenging to predict the couriers' working time. In this paper, we propose CourIRL, a practical IRL-based framework leveraging cross-attention to integrate Couriers' historical and spatio-temporal features to predict their future working time. CourIRL formulates the couriers' pick-up and delivery tour as a sequential decision-making process and designs a model-free IRL to learn decision-making preference vectors. A multi-head cross-attention mechanism-based deep regression model is proposed for fine-grained working-time prediction. The results of extensive experiments on two real-world datasets demonstrate that the proposed CourIRL surpasses the state-of-the-art baselines by an average of 6.11% across settings, showing the efficacy and potential contributions of CourIRL in last-mile logistics.|人类行为预测是一项基于人工智能的重要任务，已在许多实际应用中得到广泛关注。在“最后一公里”物流中，预测快递员的行为有助于了解其偏好并优化工作流程。本文致力于预测快递员的工作负荷，并通过其在每个兴趣区域（AOI）所花费的工作时间来量化其工作量。考虑到逆强化学习（IRL）在行为解释性方面的优势，现有研究已将IRL应用于一些实际的交通预测场景。然而，在“最后一公里”物流中，平台会为每位快递员分配多个订单，快递员还需实时接收新任务，这些因素进一步影响其后续决策。决策空间的不确定性和工作流程的动态分布使得预测快递员的工作时间更具挑战性。本文提出了CourIRL，这是一个基于IRL的实用框架，利用交叉注意力机制整合快递员的历史和时空特征，以预测其未来的工作时间。CourIRL将快递员的取件和送货行程建模为序列决策过程，并设计了一种无模型的IRL方法来学习决策偏好向量。此外，本文提出了一种基于多头交叉注意力机制的深度回归模型，用于细粒度的工作时间预测。在两个真实世界数据集上的大量实验结果表明，CourIRL在各种设置下平均优于现有最先进基线6.11%，展示了其在“最后一公里”物流中的有效性和潜在贡献。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CourIRL:+Predicting+Couriers'+Behavior+in+Last-Mile+Delivery+Using+Crossed-Attention+Inverse+Reinforcement+Learning)|0|
|[Multiscale Representation Enhanced Temporal Flow Fusion Model for Long-Term Workload Forecasting](https://doi.org/10.1145/3627673.3680072)|Shiyu Wang, Zhixuan Chu, Yinbo Sun, Yu Liu, Yuliang Guo, Yang Chen, Huiyang Jian, Lintao Ma, Xingyu Lu, Jun Zhou||Accurate workload forecasting is critical for efficient resource management in cloud computing systems, enabling effective scheduling and autoscaling. Despite recent advances with transformer-based forecasting models, challenges remain due to the non-stationary, nonlinear characteristics of workload time series and the long-term dependencies. In particular, inconsistent performance between long-term history and near-term forecasts hinders long-range predictions. This paper proposes a novel framework leveraging self-supervised multiscale representation learning to capture both long-term and near-term workload patterns. The long-term history is encoded through multiscale representations while the near-term observations are modeled via temporal flow fusion. These representations of different scales are fused using an attention mechanism and characterized with normalizing flows to handle non-Gaussian/non-linear distributions of time series. Extensive experiments on 9 benchmarks demonstrate superiority over existing methods.|准确的工作负载预测对于云计算系统中的高效资源管理至关重要，能够实现有效的任务调度和自动扩展。尽管基于Transformer的预测模型在近年来取得了进展，但由于工作负载时间序列的非平稳性和非线性特征以及长期依赖性，仍然存在挑战。特别是，长期历史与近期预测之间的性能不一致性阻碍了长期预测的准确性。本文提出了一种新的框架，利用自监督的多尺度表示学习来捕捉长期和近期的工作负载模式。通过多尺度表示对长期历史进行编码，同时通过时间流融合对近期观测进行建模。不同尺度的表示通过注意力机制进行融合，并利用归一化流来处理时间序列的非高斯/非线性分布特性。在9个基准数据集上的广泛实验表明，该方法优于现有的预测方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multiscale+Representation+Enhanced+Temporal+Flow+Fusion+Model+for+Long-Term+Workload+Forecasting)|0|
|[Revolutionizing Biomarker Discovery: Leveraging Generative AI for Bio-Knowledge-Embedded Continuous Space Exploration](https://doi.org/10.1145/3627673.3680041)|Wangyang Ying, Dongjie Wang, Xuanming Hu, Ji Qiu, Jin Park, Yanjie Fu||Biomarker discovery is vital in advancing personalized medicine, offering insights into disease diagnosis, prognosis, and therapeutic efficacy. Traditionally, the identification and validation of biomarkers heavily depend on extensive experiments and statistical analyses. These approaches are time-consuming, demand extensive domain expertise, and are constrained by the complexity of biological systems. These limitations motivate us to ask: Can we automatically identify the effective biomarker subset without substantial human efforts? Inspired by the success of generative AI, we think that the intricate knowledge of biomarker identification can be compressed into a continuous embedding space, thus enhancing the search for better biomarkers. Thus, we propose a new biomarker identification framework with two important modules:1) training data preparation and 2) embedding-optimization-generation. The first module uses a multi-agent system to automatically collect pairs of biomarker subsets and their corresponding prediction accuracy as training data. These data establish a strong knowledge base for biomarker identification. The second module employs an encoder-evaluator-decoder learning paradigm to compress the knowledge of the collected data into a continuous space. Then, it utilizes gradient-based search techniques and autoregressive-based reconstruction to efficiently identify the optimal subset of biomarkers. Finally, we conduct extensive experiments on three real-world datasets to show the efficiency, robustness, and effectiveness of our method.|生物标志物的发现对于推动个性化医疗至关重要，能够为疾病诊断、预后评估以及治疗效果提供关键见解。传统上，生物标志物的识别与验证高度依赖于大量的实验和统计分析。这些方法耗时较长，需要广泛的领域专业知识，并且受到生物系统复杂性的限制。这些局限性促使我们提出一个问题：我们是否可以在不投入大量人力的情况下自动识别有效的生物标志物子集？受到生成式人工智能成功的启发，我们认为生物标志物识别的复杂知识可以被压缩到一个连续的嵌入空间中，从而提升寻找更优生物标志物的效率。因此，我们提出了一种新的生物标志物识别框架，该框架包含两个重要模块：1）训练数据准备和2）嵌入优化生成。第一个模块利用多智能体系统自动收集生物标志物子集及其对应的预测准确性作为训练数据。这些数据为生物标志物识别建立了强大的知识库。第二个模块采用编码器-评估器-解码器学习范式，将收集到的数据知识压缩到一个连续空间中。随后，利用基于梯度的搜索技术和自回归重建方法，高效识别出最优的生物标志物子集。最后，我们在三个真实世界的数据集上进行了广泛的实验，展示了我们方法的效率、鲁棒性和有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revolutionizing+Biomarker+Discovery:+Leveraging+Generative+AI+for+Bio-Knowledge-Embedded+Continuous+Space+Exploration)|0|
|[A Behavior-aware Cause Identification Framework for Order Cancellation in Logistics Service](https://doi.org/10.1145/3627673.3680051)|Shuxin Zhong, Yahan Gu, Wenjun Lyu, Hongyu Lin, Guang Yang, Yao Lu, Guang Wang, Yu Yang, Desheng Zhang|Rutgers University, Piscataway, NJ, USA; JD Logistics, Beijing, China; Florida State University, Tallahassee, FL, USA; Lehigh University, Bethlehem, PA, USA; Rutgers University, Piscataway, NJ, China|Logistics platforms provide real-time door-to-door order pickup services to enhance customer convenience. However, a high volume of unexpected order cancellations negatively impacts both customer satisfaction and logistics profitability. Identifying whether these cancellations are due to customers' decisions or couriers' behaviors is crucial for implementing targeted operational improvements. While traditional methods directly interpret customer-courier dialogues, incorporating situational context (e.g., couriers' historical performance and current workloads) helps us to accurately understand the hidden content. The main challenges lie in dynamically correlating couriers' varying behaviors with dialogue content. To tackle this challenge, we develop COCO, a cause identification framework for order cancellation in logistics, which includes: i) Multi-modal features exploration, which analyzes dialogues and couriers' behaviors (both historical and current); ii) Multi-modal features aggregation, which uses a hierarchical attention mechanism to adaptively capture the dynamic correlations within dialogues and behaviors; iii) LLM-enhanced refinement, which leverages Large Language Models to accurately process a large number of unlabeled dialogues, significantly enhancing COCO's generalization and performance. Our extensive evaluation with JD Logistics demonstrates COCO's exceptional performance, achieving an 12.2% increase in precision and a 9.1% improvement in recall over existing methods. Furthermore, after deploying COCO at JD Logistics, it has achieved an accuracy of 89.5%, further demonstrating its practical utility.|物流平台提供实时上门取件服务，以提升客户便利性。然而，大量意外的订单取消行为严重影响了客户满意度和物流利润。识别这些取消行为是由客户决策还是快递员行为导致的，对于实施有针对性的运营改进至关重要。传统方法直接解读客户与快递员的对话，而结合情境信息（如快递员的历史表现和当前工作负荷）则有助于我们更准确地理解隐藏的内容。主要挑战在于动态关联快递员多变的行为与对话内容。为应对这一挑战，我们开发了COCO，这是一个针对物流订单取消原因的识别框架，包含以下几个方面：

1. **多模态特征探索**：分析对话内容以及快递员的行为（包括历史和当前行为）。
2. **多模态特征聚合**：采用层级注意力机制，自适应地捕捉对话和行为之间的动态关联。
3. **大语言模型增强的精炼**：利用大语言模型（LLM）准确处理大量未标注的对话数据，显著提升COCO的泛化能力和性能。

我们在京东物流进行的广泛评估显示，COCO表现出色，相较于现有方法，其准确率提高了12.2%，召回率提升了9.1%。此外，在京东物流部署COCO后，其准确率达到了89.5%，进一步证明了其实际应用价值。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Behavior-aware+Cause+Identification+Framework+for+Order+Cancellation+in+Logistics+Service)|0|
|[LSR-IGRU: Stock Trend Prediction Based on Long Short-Term Relationships and Improved GRU](https://doi.org/10.1145/3627673.3680012)|Peng Zhu, Yuante Li, Yifan Hu, Qinyuan Liu, Dawei Cheng, Yuqi Liang||Stock price prediction is a challenging problem in the field of finance and receives widespread attention. In recent years, with the rapid development of technologies such as deep learning and graph neural networks, more research methods have begun to focus on exploring the interrelationships between stocks. However, existing methods mostly focus on the short-term dynamic relationships of stocks and directly integrating relationship information with temporal information. They often overlook the complex nonlinear dynamic characteristics and potential higher-order interaction relationships among stocks in the stock market. Therefore, we propose a stock price trend prediction model named LSR-IGRU in this paper, which is based on long short-term stock relationships and an improved GRU input. Firstly, we construct a long short-term relationship matrix between stocks, where secondary industry information is employed for the first time to capture long-term relationships of stocks, and overnight price information is utilized to establish short-term relationships. Next, we improve the inputs of the GRU model at each step, enabling the model to more effectively integrate temporal information and long short-term relationship information, thereby significantly improving the accuracy of predicting stock trend changes. Finally, through extensive experiments on multiple datasets from stock markets in China and the United States, we validate the superiority of the proposed LSR-IGRU model over the current state-of-the-art baseline models. We also apply the proposed model to the algorithmic trading system of a financial company, achieving significantly higher cumulative portfolio returns compared to other baseline methods. Our sources are released at https://github.com/ZP1481616577/Baselines_LSR-IGRU.|股票价格预测是金融领域的一个难题，备受广泛关注。近年来，随着深度学习和图神经网络等技术的快速发展，越来越多的研究方法开始聚焦于探索股票之间的相互关系。然而，现有方法大多侧重于股票的短期动态关系，并直接将关系信息与时间信息进行整合，往往忽视了股票市场中复杂的非线性动态特征以及潜在的高阶交互关系。因此，本文提出了一种名为LSR-IGRU的股票价格趋势预测模型，该模型基于长短期股票关系并改进了GRU的输入。首先，我们构建了股票之间的长短期关系矩阵，首次采用二级行业信息来捕捉股票的长期关系，并利用隔夜价格信息来建立短期关系。接着，我们对GRU模型在每一步的输入进行了改进，使得模型能够更有效地整合时间信息和长短期关系信息，从而显著提升股票趋势变化的预测准确性。最后，通过对中美股市多个数据集的大量实验，验证了所提出的LSR-IGRU模型相较于当前最先进的基线模型的优越性。我们还将其应用于某金融公司的算法交易系统，与其它基线方法相比，实现了显著更高的累计投资组合收益。相关资源已发布在https://github.com/ZP1481616577/Baselines_LSR-IGRU。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LSR-IGRU:+Stock+Trend+Prediction+Based+on+Long+Short-Term+Relationships+and+Improved+GRU)|0|
|[RevEx: An Online Consumer Reviews Extraction Tool](https://doi.org/10.1145/3627673.3679214)|Julián Alarte, Carlos Galindo, Carlos Martín, Josep Silva|Universitat Politècnica de València, València, Spain|This paper presents RevEx, an online consumer reviews extraction tool. RevEx extracts the comments section for products in webshops. In contrast to other web scraping tools, it can work with heterogeneous web pages automatically, that is, it does not need any additional information apart from the web page itself. In addition, RevEx is a page-level tool since it only needs to load the web page whose comments have to be extracted. The technique includes a mechanism to group similar DOM nodes and then, once several sets of similar DOM nodes are obtained, an algorithm selects the group of DOM nodes that corresponds to the comments of the web page. The results of the empirical evaluation show an average F1 higher than 88%, and perfect results for around 75% of web pages.|本文介绍了一种名为RevEx的在线消费者评论提取工具。RevEx能够从网店中提取产品的评论部分。与其他网页抓取工具不同，RevEx能够自动处理异构网页，即除了网页本身之外，不需要任何额外信息。此外，RevEx是一个页面级别的工具，因为它只需要加载需要提取评论的网页即可。该技术包括一个机制，用于对相似的DOM节点进行分组，然后，一旦获取了几组相似的DOM节点，算法会选择与网页评论相对应的DOM节点组。实证评估的结果显示，平均F1值超过88%，并且对大约75%的网页实现了完美的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RevEx:+An+Online+Consumer+Reviews+Extraction+Tool)|0|
|[Introducing CausalBench: A Flexible Benchmark Framework for Causal Analysis and Machine Learning](https://doi.org/10.1145/3627673.3679218)|Ahmet Kapkiç, Pratanu Mandal, Shu Wan, Paras Sheth, Abhinav Gorantla, Yoonhyuk Choi, Huan Liu, K. Selçuk Candan||While witnessing the exceptional success of machine learning (ML) technologies in many applications, users are starting to notice a critical shortcoming of ML: correlation is a poor substitute for causation. The conventional way to discover causal relationships is to use randomized controlled experiments (RCT); in many situations, however, these are impractical or sometimes unethical. Causal learning from observational data offers a promising alternative. While being relatively recent, causal learning aims to go far beyond conventional machine learning, yet several major challenges remain. Unfortunately, advances are hampered due to the lack of unified benchmark datasets, algorithms, metrics, and evaluation service interfaces for causal learning. In this paper, we introduce CausalBench, a transparent, fair, and easy-to-use evaluation platform, aiming to (a) enable the advancement of research in causal learning by facilitating scientific collaboration in novel algorithms, datasets, and metrics and (b) promote scientific objectivity, reproducibility, fairness, and awareness of bias in causal learning research. CausalBench provides services for benchmarking data, algorithms, models, and metrics, impacting the needs of a broad of scientific and engineering disciplines.|尽管目睹了机器学习（ML）技术在众多应用中的卓越成功，用户开始注意到ML的一个关键缺陷：相关性并不能替代因果关系。传统上，发现因果关系的方法是使用随机对照实验（RCT）；然而，在许多情况下，这些实验是不切实际的，有时甚至是不道德的。从观测数据中进行因果学习提供了一种有前景的替代方案。尽管因果学习相对较新，但其目标远超传统机器学习，然而仍存在几个主要挑战。不幸的是，由于缺乏统一的基准数据集、算法、评估指标和服务接口，因果学习的进展受到了阻碍。在本文中，我们介绍了CausalBench，一个透明、公平且易于使用的评估平台，旨在（a）通过促进新型算法、数据集和评估指标的科学合作，推动因果学习研究的进展，以及（b）促进因果学习研究中的科学客观性、可重复性、公平性以及对偏见的认识。CausalBench提供了用于基准测试数据、算法、模型和评估指标的服务，影响着广泛的科学和工程学科的需求。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Introducing+CausalBench:+A+Flexible+Benchmark+Framework+for+Causal+Analysis+and+Machine+Learning)|0|
|[Multi-Graph Explorer: A Framework for Advanced Multi-Graph Analysis and Method Development](https://doi.org/10.1145/3627673.3679213)|Yorgos Tsitsikas, Evangelos E. Papalexakis||In recent years, multi-graphs have been gaining increasing popularity due to their ability to better capture the multi-faceted information of real-world graphs. This, in turn, has consistently provided superior insights and performance in related machine learning tasks. However, the analysis of real-world multi-graphs and the development of multi-graph methods is currently stifled by a few limitations. On one side, researchers often struggle to properly evaluate the performance of multi-graph methods they design due to a lack of high-quality benchmarks, but also a lack of tools that allow for efficient and seamless experimentation. On the other side, practitioners aiming to analyze real-world multi-graphs often struggle obtaining robust insights due to a lack of high-quality multi-graph methods. To this end, we present Multi-Graph Explorer: a MATLAB software designed to offer a user-friendly yet comprehensive, flexible, and extensible workflow for multi-graph analysis, aiming to break these barriers and accelerate progress in machine learning tasks involving multi-graphs.|近年来，多图（multi-graphs）因其能够更好地捕捉现实世界图的多方面信息而日益受到欢迎。这进而为相关机器学习任务提供了更优越的洞察力和性能。然而，现实世界多图的分析以及多图方法的开发目前受到一些限制。一方面，由于缺乏高质量的基准测试和高效的实验工具，研究人员在评估其设计的多图方法性能时常常遇到困难。另一方面，旨在分析现实世界多图的从业者由于缺乏高质量的多图方法，往往难以获得稳健的见解。为此，我们推出了Multi-Graph Explorer：一款MATLAB软件，旨在为用户提供一个友好、全面、灵活且可扩展的工作流程，用于多图分析，以打破这些障碍，并加速涉及多图的机器学习任务的进展。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Graph+Explorer:+A+Framework+for+Advanced+Multi-Graph+Analysis+and+Method+Development)|0|
|[GongBu: Easily Fine-tuning LLMs for Domain-specific Adaptation](https://doi.org/10.1145/3627673.3679233)|Bolin Zhang, Yimin Tian, Shengwei Wang, Zhiying Tu, Dianhui Chu, Zhiqi Shen|Harbin Institute of Technology & Nanyang Technological University, Harbin, China; Harbin Institute of Technology, Weihai, China; Nanyang Technological University, Singapore, Singapore|Parameter-Efficient Fine-Tuning (PEFT) adapts large language models (LLMs) to specific domains by updating only a small portion of the parameters. To easily and efficiently adapt LLMs to custom domains, we present a no-code fine-tuning platform, GongBu, supporting 9 PEFT methods and open-source LLMs. GongBu allows LLM fine-tuning through a user-friendly GUI, eliminating the need to write any code. Its features include data selection, accelerated training speed, decoupled deployment, performance monitoring, and error log analysis. The demonstration video is available at https://www.youtube.com/watch?v=QuDR_WNoB9o.|参数高效微调（Parameter-Efficient Fine-Tuning, PEFT）通过仅更新模型参数的一小部分，使大型语言模型（LLMs）适应特定领域。为了便于高效地将LLMs适配到自定义领域，我们推出了一款无需编码的微调平台——GongBu，该平台支持9种PEFT方法和开源LLMs。GongBu通过用户友好的图形用户界面（GUI）实现LLM微调，无需编写任何代码。其功能包括数据选择、加速训练速度、解耦部署、性能监控以及错误日志分析。演示视频可在以下链接观看：https://www.youtube.com/watch?v=QuDR_WNoB9o。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GongBu:+Easily+Fine-tuning+LLMs+for+Domain-specific+Adaptation)|0|
|[Covid19-twitter: A Twitter-based Dataset for Discourse Analysis in Sentence-level Sentiment Classification](https://doi.org/10.1145/3627673.3679120)|Shashank Gupta, Mohamed Reda Bouadjenek, Antonio RoblesKelly, TszKwan Lee, Thanh Thi Nguyen, Asef Nazari, Dhananjay R. Thiruvady|Deakin University & Defence Science and Technology Group, Geelong, Australia; Deakin University, Geelong, Australia; Deakin University & Monash University, Geelong, Australia|For the sentence-level sentiment classification task, learning Contrastive Discourse Relations (CDRs) like a-but-b is difficult for Deep Neural Networks (DNNs) via purely data-driven training. Several methods exist in the literature for dissemination of CDR information with DNNs, but there is no dedicated dataset available to effectively test their dissemination performance. In this paper, we propose a new large-scale dataset for this purpose called Covid19-twitter, which contains around 100k tweets symmetrically divided into various categories. Instead of manual annotation, we used a combination of an Emoji analysis and a lexicon-based tool called Valence Aware Dictionary and sEntiment Reasoner (VADER) to perform automatic labelling of the tweets, while also ensuring high accuracy of the annotation process through some quality checks. We also provide benchmark performances of several baselines on our dataset for both the sentiment classification and CDR dissemination tasks. We believe that this dataset will be valuable for discourse analysis research in sentiment classification.|在句子级情感分类任务中，深度神经网络（DNN）通过纯数据驱动的训练方式难以学习对比性话语关系（CDR），如“a-但是-b”。尽管文献中存在多种利用DNN传播CDR信息的方法，但尚无专门的数据集来有效测试这些方法的传播性能。本文提出了一种新的用于此目的的大规模数据集，名为Covid19-twitter，该数据集包含约10万条对称划分为不同类别的推文。我们采用表情符号分析与基于词典的工具Valence Aware Dictionary and sEntiment Reasoner（VADER）相结合的方法进行自动标注，并通过一些质量检查确保标注过程的高准确性，而非依赖人工标注。此外，我们还提供了多个基线模型在我们数据集上的基准性能，涵盖情感分类和CDR传播任务。我们相信，该数据集将对情感分类中的话语分析研究具有重要价值。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Covid19-twitter:+A+Twitter-based+Dataset+for+Discourse+Analysis+in+Sentence-level+Sentiment+Classification)|0|
|[CH-Mits: A Cross-Modal Dataset for User Sentiment Analysis on Chinese Social Media](https://doi.org/10.1145/3627673.3679125)|Juhao Ma, Shuai Xu, Yilin Liu, Xiaoming Fu|Nanjing University of Aeronautics and Astronautics, Nanjing, China; University of Göttingen, Göttingen, Germany|Multimodal social network user sentiment analysis aims to determine users' emotional polarity (positive or negative) by mining the associations between multiple data types such as images and texts. Existing public datasets are mainly constructed from English social media platforms, while Chinese social media datasets for multimodal user sentiment analysis are extremely scarce. In terms of the posts published by Chinese social media users, it is not rare that the emotional polarity delivered by the image and the textual content is inconsistent. Given such emotional inconsistency between images and texts, how to effectively identify users' true emotion polarity is still challenging. Toward the above issues, in this paper, we firstly construct a Chinese social media dataset CH-Mits for multimodal user sentiment analysis. In order to evaluate the usability of the dataset, we conceive and implement a novel model called PEMNet, and compare it with state-of-the-art models based on the CH-Mits dataset. In the end, we analyze the performance of PEMNet on selected samples with emotional inconsistency between images and texts. The constructed dataset and codes for PEMNet are available at https://github.com/Marblrdumdore/CH-Mits.|多模态社交网络用户情感分析旨在通过挖掘图像和文本等多种数据类型之间的关联，来确定用户的情感极性（正面或负面）。现有的公开数据集主要构建自英文社交媒体平台，而用于多模态用户情感分析的中文社交媒体数据集极为稀缺。在中文社交媒体用户发布的帖子中，图像与文本内容传递的情感极性不一致的情况并不少见。面对图像与文本之间的这种情感不一致性，如何有效识别用户的真实情感极性仍是一个挑战。针对上述问题，本文首先构建了一个用于多模态用户情感分析的中文社交媒体数据集CH-Mits。为了评估该数据集的可用性，我们设计并实现了一种新型模型PEMNet，并在CH-Mits数据集上与现有的先进模型进行了比较。最后，我们对PEMNet在图像与文本情感不一致的选定样本上的表现进行了分析。所构建的数据集及PEMNet的代码已公开，详见https://github.com/Marblrdumdore/CH-Mits。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CH-Mits:+A+Cross-Modal+Dataset+for+User+Sentiment+Analysis+on+Chinese+Social+Media)|0|
|[The Veracity Problem: Detecting False Information and its Propagation on Online Social Media Networks](https://doi.org/10.1145/3627673.3680265)|Sarah Condran||Detecting false information on social media is critical in mitigating its negative societal impacts. To reduce the propagation of false information, automated detection provide scalable, unbiased, and cost-effective methods. However, there are three potential research areas identified which once solved improve detection. First, current AI-based solutions often provide a uni-dimensional analysis on a complex, multi-dimensional issue, with solutions differing based on the features used. Furthermore, these methods do not account for the temporal and dynamic changes observed within the document's life cycle. Second, there has been little research on the detection of coordinated information campaigns and in understanding the intent of the actors and the campaign. Thirdly, there is a lack of consideration of cross-platform analysis, with existing datasets focusing on a single platform, such as X, and detection models designed for specific platform. This work aims to develop methods for effective detection of false information and its propagation. To this end, firstly we aim to propose the creation of an ensemble multi-faceted framework that leverages multiple aspects of false information. Secondly, we propose a method to identify actors and their intent when working in coordination to manipulate a narrative. Thirdly, we aim to analyse the impact of cross-platform interactions on the propagation of false information via the creation of a new dataset.|检测社交媒体上的虚假信息对于减轻其对社会的负面影响至关重要。为了减少虚假信息的传播，自动化检测提供了可扩展、无偏见且成本效益高的方法。然而，目前存在三个潜在的研究领域，一旦解决，将能提升检测效果。首先，当前基于人工智能的解决方案通常对复杂的多维问题进行单一维度的分析，且解决方案因所使用的特征不同而有所差异。此外，这些方法未能考虑文档生命周期内的时间性和动态变化。其次，针对协调性信息活动的检测以及对参与者和活动的意图理解的研究较少。第三，缺乏跨平台分析的考虑，现有数据集主要集中于单一平台（如X），且检测模型为特定平台设计。本研究旨在开发有效检测虚假信息及其传播的方法。为此，首先我们拟提出一个综合多方面的集成框架，利用虚假信息的多个方面进行检测。其次，我们提出一种方法，用于识别在协调操纵叙事时参与者的身份及其意图。第三，我们旨在通过创建新数据集，分析跨平台互动对虚假信息传播的影响。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Veracity+Problem:+Detecting+False+Information+and+its+Propagation+on+Online+Social+Media+Networks)|0|
|[Evaluating Social Media Reach via Mainstream Media Discourse](https://doi.org/10.1145/3627673.3680260)|Himarsha R. Jayanetti|Old Dominion University, Norfolk, Virginia, USA|This study examines the intersection between social media and mainstream television (TV) news with an aim to understand how social media content amplifies its impact through TV broadcasts. While many studies emphasize social media as a primary platform for information dissemination, they often underestimate its total influence by focusing solely on interactions within the platform. This research examines instances where social media posts gain prominence on TV broadcasts, reaching new audiences and prompting public discourse. By using TV news closed captions, on-screen text recognition, and social media logo detection, we analyze how social media is referenced in TV news. Our methodology aims to analyze this data to develop metrics that quantify the extent of this amplification and understand the contexts in which social media is integrated into broadcast content.|本研究探讨了社交媒体与主流电视新闻之间的交集，旨在理解社交媒体内容如何通过电视广播放大其影响力。尽管许多研究强调社交媒体作为信息传播的主要平台，但它们往往仅关注平台内的互动，从而低估了社交媒体的总体影响力。本研究考察了社交媒体帖子在电视广播中获得显著地位的情况，这些帖子触及了新的受众并引发了公众讨论。通过使用电视新闻的闭路字幕、屏幕文本识别以及社交媒体标志检测，我们分析了社交媒体在电视新闻中的引用方式。我们的方法旨在通过分析这些数据，开发出量化这种放大效应程度的指标，并理解社交媒体内容被整合到广播内容中的情境。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Evaluating+Social+Media+Reach+via+Mainstream+Media+Discourse)|0|
|[PTM-Mamba: A PTM-Aware Protein Language Model with Bidirectional Gated Mamba Blocks](https://doi.org/10.1145/3627673.3680276)|Zhangzhi Peng|Department of Biomedical Engineering, Duke University.; Department of Computer Science, Duke University.|Proteins serve as the workhorses of living organisms, orchestrating a wide array of vital functions. Post-translational modifications (PTMs) of their amino acids greatly influence the structural and functional diversity of different protein types and uphold proteostasis, allowing cells to swiftly respond to environmental changes and intricately regulate complex biological processes. To this point, efforts to model the complex features of proteins have involved the training of large and expressive protein language models (pLMs) such as ESM-2 and ProtT5, which accurately encode structural, functional, and physicochemical properties of input protein sequences. However, the over 200 million sequences that these pLMs were trained on merely scratch the surface of proteomic diversity, as they neither input nor account for the effects of PTMs. In this work, we fill this major gap in protein sequence modeling by introducing PTM tokens into the pLM training regime. We then leverage recent advancements in structured state space models (SSMs), specifically Mamba, which utilizes efficient hardware-aware primitives to overcome the quadratic time complexities of Transformers. After adding a comprehensive set of PTM tokens to the model vocabulary, we train bidirectional Mamba blocks whose outputs are fused with state-of-the-art ESM-2 embeddings via a novel gating mechanism. We demonstrate that our resultant PTM-aware pLM, PTM-Mamba, improves upon ESM-2's performance on various PTM-specific tasks. PTM-Mamba is the first and only pLM that can uniquely input and represent both wild-type and PTM sequences, motivating downstream modeling and design applications specific to post-translationally modified proteins. To facilitate PTM-aware protein language modeling applications, we have made our model available at: https://huggingface.co/ChatterjeeLab/PTM-Mamba.|蛋白质作为生物体中的工作主力，协调着多种关键功能。氨基酸的翻译后修饰（PTMs）极大地影响了不同蛋白质类型的结构和功能多样性，并维持蛋白质组的稳定，使细胞能够迅速响应环境变化并精细调控复杂的生物过程。迄今为止，对蛋白质复杂特征的建模工作涉及训练大型且表达能力强的蛋白质语言模型（pLMs），如ESM-2和ProtT5，这些模型能够准确编码输入蛋白质序列的结构、功能和物理化学性质。然而，这些pLMs所训练的超过2亿条序列仅仅是蛋白质组多样性的冰山一角，因为它们既不输入也不考虑PTMs的影响。在本研究中，我们通过在pLM训练机制中引入PTM标记，填补了蛋白质序列建模中的这一重大空白。我们随后利用结构化状态空间模型（SSMs）的最新进展，特别是Mamba，它通过使用高效的硬件感知原语来克服Transformer的二次时间复杂度问题。在向模型词汇表中添加了一组全面的PTM标记后，我们训练了双向Mamba模块，并通过一种新颖的门控机制将其输出与最先进的ESM-2嵌入进行融合。我们证明，由此产生的PTM感知pLM——PTM-Mamba，在各种PTM特定任务上优于ESM-2的性能。PTM-Mamba是首个也是唯一一个能够独特地输入和表示野生型和PTM序列的pLM，这为下游建模和翻译后修饰蛋白质的专门设计应用提供了动力。为了促进PTM感知的蛋白质语言建模应用，我们已将模型发布在以下网址：https://huggingface.co/ChatterjeeLab/PTM-Mamba。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PTM-Mamba:+A+PTM-Aware+Protein+Language+Model+with+Bidirectional+Gated+Mamba+Blocks)|0|
|[Towards Making Effective Machine Learning Decisions Against Out-of-Distribution Data](https://doi.org/10.1145/3627673.3680272)|Lakpa Dorje Tamang|School of Information Technology, Deakin University, Geelong, VIC, Australia|Conventional machine learning systems operate on the assumption of independent and identical distribution (i.i.d), where both the training and test data share a similar sample space, and no distribution shift exists between them. However, this assumption does not hold in practical deployment scenarios, making it crucial to develop methodologies that address the non-trivial task of data distribution shift. In our research, we aim to address this problem by developing ML algorithms that explicitly achieve promising performance when subjected to various types of out-of-distribution (OOD) data. Specifically, we approach the problem by categorizing the data distribution shifts into two types: covariate shifts and semantic shifts, and proposing effective methodologies to tackle each type independently and conjointly while validating them with different types of datasets. We aim to propose ideas that are compatible with existing deep neural networks to perform detection and/or generalization of the test instances that are shifted in semantic and covariate space, respectively.|传统的机器学习系统基于独立同分布（i.i.d）假设运行，即训练数据和测试数据共享相似的样本空间，且两者之间不存在分布偏移。然而，在实际部署场景中，这一假设往往不成立，这使得开发能够应对数据分布偏移的非平凡任务的方法变得至关重要。在我们的研究中，我们旨在通过开发能够在面对各种类型的分布外（OOD）数据时表现出良好性能的机器学习算法来解决这一问题。具体而言，我们将数据分布偏移问题分为两类：协变量偏移和语义偏移，并提出了有效的方法分别和联合应对这两类偏移，同时通过不同类型的数据集对这些方法进行验证。我们的目标是提出与现有深度神经网络兼容的思想，以分别实现对语义空间和协变量空间中偏移的测试实例的检测和/或泛化。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Making+Effective+Machine+Learning+Decisions+Against+Out-of-Distribution+Data)|0|
|[The 'Path' to Clarity: Identifying False Claims Through a Knowledge Graph Exploration](https://doi.org/10.1145/3627673.3680262)|Wenbo Wang|Department of Informatics, New Jersey Institute of Technology, Newark, NJ, USA|Automated fact-checking has emerged as a safeguard against the spread of false information. Existing fact-checking approaches aim to determine whether a news claim is true or false, and they have achieved decent accuracy of veracity prediction. However, the current state-of-the-art models still face challenges, such as ambiguity in the claims and lack of contextual information. This study introduces a fact-checking model, Path-FC, which focuses on 1) augmenting the representations of claims and evidence by incorporating additional context using the Knowledge Paths extracted from the external Knowledge Graph; 2) Identifying false claims by learning the differences between claims and evidence. The experimental results demonstrate that Knowledge Path retrieval, combined with the multi-head attention technique, contributes to improved performance of fact-checking. The code is available at https://anonymous.4open.science/r/Path-FC.|自动化事实核查已成为防止虚假信息传播的保障手段。现有的事实核查方法旨在判断新闻声明的真伪，并在真实性预测方面取得了不错的准确率。然而，当前最先进的模型仍面临一些挑战，如声明的模糊性和缺乏上下文信息。本研究提出了一种事实核查模型——Path-FC，该模型专注于：1）通过结合从外部知识图谱中提取的知识路径来增强声明和证据的表示，从而引入额外的上下文信息；2）通过学习声明与证据之间的差异来识别虚假声明。实验结果表明，知识路径检索与多头注意力技术的结合有助于提升事实核查的性能。代码可在https://anonymous.4open.science/r/Path-FC获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+'Path'+to+Clarity:+Identifying+False+Claims+Through+a+Knowledge+Graph+Exploration)|0|
|[Hands-On Introduction to Quantum Machine Learning](https://doi.org/10.1145/3627673.3679103)|Samuel YenChi Chen, Joongheon Kim||This tutorial covers a hands-on introduction to quantum machine learning. Foundational concepts of quantum information science (QIS) are presented (qubits, single and multiple qubit gates, measurements, and entanglement). Building on that, foundational concepts of quantum machine learning (QML) are introduced (parametrized circuits, data encoding, and feature mapping). Then, QML models are discussed (quantum support vector machine, quantum feedforward neural network, and quantum convolutional neural network). All the aforementioned topics and concepts are examined using codes run on a quantum computer simulator. All the covered materials assume a novice audience interested in learning about QML. Further reading and software packages and frameworks are shared with the audience.|本教程提供了一个动手实践的量子机器学习入门介绍。首先，介绍了量子信息科学（QIS）的基础概念（包括量子比特、单量子比特与多量子比特门、测量以及量子纠缠）。在此基础上，进一步讲解了量子机器学习（QML）的基础概念（如参数化电路、数据编码与特征映射）。随后，讨论了量子机器学习模型（包括量子支持向量机、量子前馈神经网络以及量子卷积神经网络）。所有上述主题和概念均通过在量子计算机模拟器上运行的代码进行演示和探讨。本教程面向对量子机器学习感兴趣的初学者，并提供了进一步阅读的参考资料以及相关的软件包和框架。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hands-On+Introduction+to+Quantum+Machine+Learning)|0|
|[Data Quality-aware Graph Machine Learning](https://doi.org/10.1145/3627673.3679095)|Yu Wang, Kaize Ding, Xiaorui Liu, Jian Kang, Ryan A. Rossi, Tyler Derr|Northwestern University, Evanston, IL, USA; Adobe Research, San Jose, CA, USA; University of Oregon, Eugene, OR, USA; Vanderbilt University, Nashville, TN, USA; North Carolina State University, Raleigh, NC, USA; University of Rochester, Rochester, NY, USA|Recent years have seen a significant shift in Artificial Intelligence from model-centric to data-centric approaches, highlighted by the success of large foundational models. Following this trend, despite numerous innovations in graph machine learning model design, graph-structured data often suffers from data quality issues, jeopardizing the progress of Data-centric AI in graph-structured applications. Our proposed tutorial addresses this gap by raising awareness about data quality issues within the graph machine-learning community. We provide an overview of existing topology, imbalance, bias, limited data, and abnormality issues in graph data. Additionally, we highlight recent developments in foundational graph models that focus on identifying, investigating, mitigating, and resolving these issues.|近年来，人工智能领域经历了从以模型为中心到以数据为中心的显著转变，这一趋势在大规模基础模型的成功中得到了突出体现。尽管图机器学习模型设计方面取得了众多创新，但图结构数据常常面临数据质量问题，这严重阻碍了以数据为中心的人工智能在图结构应用中的进展。我们提出的教程旨在填补这一空白，提高图机器学习社区对数据质量问题的认识。我们概述了图数据中现有的拓扑问题、不平衡问题、偏差问题、数据有限问题以及异常问题。此外，我们还强调了基础图模型领域的最新进展，这些模型专注于识别、研究、缓解和解决这些问题。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Data+Quality-aware+Graph+Machine+Learning)|0|
|[Systems for Scalable Graph Analytics and Machine Learning: Trends and Methods](https://doi.org/10.1145/3627673.3679101)|Da Yan, Lyuheng Yuan, Akhlaque Ahmad, Saugat Adhikari|; Kasma Pte. Ltd., Singapore, Singapore; Department of Computer Science, Indiana University Bloomington, Bloomington, Indiana, USA|Graph-theoretic algorithms and graph machine learning models are essential tools for addressing many real-life problems, such as social network analysis and bioinformatics. To support large-scale graph analytics, graph-parallel systems have been actively developed for over one decade, such as Google's Pregel and Spark's GraphX, which (i) promote a think-like-a-vertex computing model and target (ii) iterative algorithms and (iii) those problems that output a value for each vertex. However, this model is too restricted for supporting the rich set of heterogeneous operations for graph analytics and machine learning that many real applications demand. In recent years, two new trends emerge in graph-parallel systems research: (1) a novel think-like-a-task computing model that can efficiently support the various computationally expensive problems of subgraph search; and (2) scalable systems for learning graph neural networks. These systems effectively complement the diversity needs of graph-parallel tools that can flexibly work together in a comprehensive graph processing pipeline for real applications, with the capability of capturing structural features. This tutorial will provide an effective categorization of the recent systems in these two directions based on their computing models and adopted techniques, and will review the key design ideas of these systems.|图论算法和图机器学习模型是解决许多现实问题的关键工具，如社交网络分析和生物信息学。为了支持大规模图分析，图并行系统在过去十多年中得到了积极的发展，例如Google的Pregel和Spark的GraphX。这些系统（i）推广了“像顶点一样思考”的计算模型，并针对（ii）迭代算法和（iii）为每个顶点输出值的问题。然而，这种模型对于支持许多实际应用所需的丰富异构图分析和机器学习操作来说过于受限。近年来，图并行系统研究中出现了两个新趋势：（1）一种新颖的“像任务一样思考”的计算模型，能够高效支持子图搜索等计算密集型问题；（2）用于学习图神经网络的可扩展系统。这些系统有效地补充了图并行工具的多样化需求，能够在实际应用中灵活地协同工作，形成一个全面的图处理流水线，并具备捕捉结构特征的能力。本教程将根据这些系统的计算模型和采用的技术，提供对近期系统的一个有效分类，并回顾这些系统的设计关键思想。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Systems+for+Scalable+Graph+Analytics+and+Machine+Learning:+Trends+and+Methods)|0|
|[Neural Additive Tensor Decomposition for Sparse Tensors](https://doi.org/10.1145/3627673.3679833)|Dawon Ahn, Uday Singh Saini, Evangelos E. Papalexakis, Ali Payani|University of California, Riverside, Riverside, USA; Cisco Systems Inc., San Jose, USA|Given a sparse tensor, how can we accurately capture complex latent structures inherent in the tensor while maintaining the interpretability of those structures? Tensor decomposition is a fundamental technique for analyzing tensors. Classical tensor models provide multi-linear structures that are easy to interpret, but have limitations in capturing complex structures present in real-world sparse tensors. Recent neural tensor models have extended the capabilities of classical tensor models in capturing complex structures within the data. However, this has come at the cost of interpretability: neural tensor models entangle interactions across and within latent structures in a black-box manner, making it difficult to readily understand the discovered structures. Understanding these structures, however, is crucial in applications such as healthcare, which requires transparency in critical decision-making processes. To overcome this major limitation and bridge the gap between the classical multi-linear models and neural tensor models, we propose Neural Additive Tensor Decomposition (NeAT), an accurate and interpretable neural tensor model for sparse tensors. The main idea of NeAT is to apply neural networks to each latent component in an additive fashion. This not only captures diverse patterns and complex structures in sparse tensors, but also provides a direct and intuitive interpretation of the structures by being close to the multi-linear tensor model. We conduct extensive experiments on six large real-world sparse tensors. NeAT outperforms the state-of-the-art neural tensor models in link prediction, surpassing a linear tensor model by 10% and the second-best neural tensor model by 4%, in accuracy. Through ablation studies, we explore various model designs for NeAT to identify key factors that impact generalization. Finally, we evaluate qualitatively and quantitatively latent patterns discovered by NeAT, demonstrating how to analyze the discovered latent patterns in real data obtained from NeAT.|给定一个稀疏张量，我们如何才能准确捕捉到张量中固有的复杂潜在结构，同时保持这些结构的解释性？张量分解是分析张量的基础技术。经典的张量模型提供了易于解释的多线性结构，但在捕捉现实世界稀疏张量中的复杂结构方面存在局限性。最近，神经张量模型扩展了经典张量模型在捕捉数据中复杂结构的能力。然而，这以牺牲解释性为代价：神经张量模型以黑箱方式纠缠了潜在结构内部和之间的交互，使得难以直接理解所发现的结构。然而，理解这些结构在诸如医疗保健等应用中至关重要，这些应用需要在关键决策过程中保持透明度。为了克服这一主要限制，并弥合经典多线性模型与神经张量模型之间的差距，我们提出了神经加性张量分解（NeAT），这是一种针对稀疏张量的准确且可解释的神经张量模型。NeAT的主要思想是以加性方式将神经网络应用于每个潜在组件。这不仅能够捕捉稀疏张量中的多样模式和复杂结构，而且通过接近多线性张量模型，提供了对结构的直接和直观的解释。我们在六个大型真实世界稀疏张量上进行了广泛的实验。NeAT在链接预测方面优于最先进的神经张量模型，准确率分别比线性张量模型高出10%，比第二好的神经张量模型高出4%。通过消融研究，我们探讨了NeAT的各种模型设计，以识别影响泛化的关键因素。最后，我们从定性和定量两个方面评估了NeAT发现的潜在模式，展示了如何分析从NeAT获得的真实数据中发现的潜在模式。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neural+Additive+Tensor+Decomposition+for+Sparse+Tensors)|0|
|[A Geometric Perspective for High-Dimensional Multiplex Graphs](https://doi.org/10.1145/3627673.3679541)|Kamel Abdous, Nairouz Mrabah, Mohamed Bouguessa|Department of Computer Science, University of Quebec at Montreal, Montreal, Quebec, Canada|High-dimensional multiplex graphs are characterized by their high number of complementary and divergent dimensions. The existence of multiple hierarchical latent relations between the graph dimensions poses significant challenges to embedding methods. In particular, the geometric distortions that might occur in the representational space have been overlooked in the literature. This work studies the problem of high-dimensional multiplex graph embedding from a geometric perspective. We find that the node representations reside on highly curved manifolds, thus rendering their exploitation more challenging for downstream tasks. Moreover, our study reveals that increasing the number of graph dimensions can cause further distortions to the highly curved manifolds. To address this problem, we propose a novel multiplex graph embedding method that harnesses hierarchical dimension embedding and Hyperbolic Graph Neural Networks. The proposed approach hierarchically extracts hyperbolic node representations that reside on Riemannian manifolds while gradually learning fewer and more expressive latent dimensions of the multiplex graph. Experimental results on real-world high-dimensional multiplex graphs show that the synergy between hierarchical and hyperbolic embeddings incurs much fewer geometric distortions and brings notable improvements over state-of-the-art approaches on downstream tasks.|高维多重图的特点是其具有大量互补和发散的维度。图中各维度之间存在的多层次潜在关系对嵌入方法提出了重大挑战。特别是，在表示空间中可能出现的几何失真在文献中被忽视了。本研究从几何角度探讨了高维多重图嵌入的问题。我们发现，节点表示位于高度弯曲的流形上，这使得它们在下游任务中的利用变得更加困难。此外，我们的研究表明，增加图的维度数量会导致高度弯曲的流形进一步失真。为解决这一问题，我们提出了一种新颖的多重图嵌入方法，该方法结合了层次维度嵌入和双曲图神经网络（Hyperbolic Graph Neural Networks）。所提出的方法层次化地提取位于黎曼流形上的双曲节点表示，同时逐步学习多重图中更少且更具表达力的潜在维度。在真实世界的高维多重图上的实验结果表明，层次化与双曲嵌入的协同作用显著减少了几何失真，并在下游任务中显著优于当前最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Geometric+Perspective+for+High-Dimensional+Multiplex+Graphs)|0|
|[Ensembles for Outlier Detection and Evaluation](https://doi.org/10.1145/3627673.3679060)|Charu C. Aggarwal|IBM T. J. Watson Research Center, Yorktown Heights, NY, USA|Ensemble methods are widely used in many machine learning applications such as classification and recommender systems. However, ensemble methods have been slow to develop in unsupervised domains such as outlier detection[1]. The earliest methods for outlier ensemble analysis include techniques such as feature bagging and isolation forests[5,6]. Subsequently, theoretical foundations were developed for outlier ensembles[2], which turned out to be analogous to those used in classification. Therefore, many outlier ensemble methods from classification can be generalized to outlier detection. However, the unsupervised nature of the outlier detection problem necessitates some changes to these algorithms. For example, subsampling methods need to be replaced by variable subsampling in order to obtain the best results[2]. This is because variable subsampling methods implicitly explore the parameter space over different base detectors so that problems associated with lack of supervision are addressed. Outlier ensemble methods can be either data-centric (in which components use different subsets or subspaces of the data) or they could be model-centric (in which components use different variations of model-centric design). Examples of data-centric methods include methods like feature bagging and subsampling, whereas examples of model-centric methods include Isolation Forests[6], RandNet [4], and Subspace Histograms[7]. However, techniques like variable subsampling seem to have characteristics of both types of ensembles. Unsupervised algorithms like outlier are often hard to evaluate because different algorithms may perform better for different choices of parameters. In general, it is not fair to compare base detectors with ensembles, since techniques like variable subsampling almost always improve performance. In such cases, outlier ensembles could be used for evaluation of outlier detection algorithms[3] by wrapping the base detectors in variable subsampling. A large number of base detectors and their ensemble-centric versions were compared, and the correlations between different detectors was analyzed. This analysis was used to propose TRINITY[3], which is an ensemble-of-ensembles detector --- this detector combines the variable subsampling versions of three base detectors and seems to be very robust over a wide variety of data sets. Recently, outlier ensembles have also been used for meta-learning[8]. It is shown how a transfer resource of labeled data sets can be used to combine scores optimally from different detectors for a new unlabeled data set.|集成方法在许多机器学习应用中被广泛使用，如分类和推荐系统。然而，集成方法在无监督领域（如异常检测）中的发展相对缓慢[1]。最早的异常集成分析方法包括特征打包和孤立森林等技术[5,6]。随后，为异常集成建立了理论基础[2]，这些基础与分类中使用的理论基础类似。因此，许多来自分类的异常集成方法可以推广到异常检测中。然而，由于异常检测问题的无监督性质，这些算法需要进行一些调整。例如，子采样方法需要被变量子采样替代，以获得最佳结果[2]。这是因为变量子采样方法隐含地探索了不同基检测器的参数空间，从而解决了缺乏监督的问题。异常集成方法可以是数据中心化的（组件使用数据的不同子集或子空间），也可以是模型中心化的（组件使用模型中心化设计的不同变体）。数据中心化方法的例子包括特征打包和子采样，而模型中心化方法的例子包括孤立森林[6]、RandNet [4]和子空间直方图[7]。然而，像变量子采样这样的技术似乎具有两种集成类型的特征。无监督算法（如异常检测）通常难以评估，因为不同的算法可能在不同的参数选择下表现更好。一般来说，将基检测器与集成方法直接比较是不公平的，因为像变量子采样这样的技术几乎总是能提高性能。在这种情况下，异常集成可以用于评估异常检测算法[3]，通过将基检测器包装在变量子采样中。大量基检测器及其以集成为中心的版本被进行了比较，并分析了不同检测器之间的相关性。这一分析被用来提出TRINITY[3]，这是一个集成的集成检测器——该检测器结合了三个基检测器的变量子采样版本，并且在各种数据集上显示出非常强的鲁棒性。最近，异常集成也被用于元学习[8]。展示了如何使用标记数据集的转移资源来为新的未标记数据集从不同检测器中最佳地组合分数。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ensembles+for+Outlier+Detection+and+Evaluation)|0|
|[Out-of-Distribution Aware Classification for Tabular Data](https://doi.org/10.1145/3627673.3679755)|Amirhossein Ansari, Ke Wang, Pulei Xiong|National Research Council Canada, Ottawa, Canada; School of Computing Science, Simon Fraser University, Burnaby, Canada|Out-of-distribution (OOD) aware classification aims to classify in-distribution samples into their respective classes while simultaneously detecting OOD samples. Previous works have largely focused on the image domain, where images from an unrelated dataset can serve as auxiliary OOD training data. In this work, we address OOD-aware classification for tabular data, where an unrelated dataset cannot be used as OOD training data. A potential solution to OOD-aware classification involves filtering out OOD samples using an outlier detection method and classifying the remaining samples with a traditional classification model. However, seamlessly integrating this approach into downstream optimization tasks is challenging due to the employment of multiple methods. Our approach is turning OOD-aware classification into traditional classification by augmenting the in-distribution training data with synthesized OOD data. This approach continues leveraging traditional classification methods while detecting OOD samples, and the learned model retains the same mathematical properties as traditional classification models, thus, it can be easily integrated into downstream tasks. We evaluate these benefits empirically using real-life datasets. Code is available at https://github.com/ah-ansari/OCT.|分布外（OOD）感知分类旨在将分布内样本分类到其各自的类别中，同时检测出分布外样本。先前的研究主要集中在图像领域，其中来自不相关数据集的图像可以作为辅助的OOD训练数据。在本研究中，我们针对表格数据的OOD感知分类问题展开研究，其中不相关数据集不能用作OOD训练数据。解决OOD感知分类的一个潜在方案是使用异常检测方法过滤掉OOD样本，然后使用传统分类模型对剩余样本进行分类。然而，由于采用了多种方法，将这种方法无缝集成到下游优化任务中具有挑战性。我们的方法通过在分布内训练数据中加入合成的OOD数据，将OOD感知分类转化为传统分类。这种方法在继续利用传统分类方法的同时，能够检测OOD样本，并且所学模型保留了与传统分类模型相同的数学特性，因此可以轻松集成到下游任务中。我们通过使用真实数据集对这些优势进行了实证评估。代码可在https://github.com/ah-ansari/OCT获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Out-of-Distribution+Aware+Classification+for+Tabular+Data)|0|
|[Spatio-temporal Graph Normalizing Flow for Probabilistic Traffic Prediction](https://doi.org/10.1145/3627673.3679705)|Yang An, Zhibin Li, Wei Liu, Haoliang Sun, Meng Chen, Wenpeng Lu, Yongshun Gong|The Commonwealth Scientific and Industrial Research Organisation, Brisbane, Australia; University of Technology Sydney, Sydney, Australia; Qilu University of Technology, Jinan, China; Shandong University, Jinan, China; School of Software, Shandong University, Jinan, China|With the development of the Intelligent Transportation Systems, a great deal of work has been proposed to tackle traffic prediction tasks. Despite their good performance, most traffic prediction models are point estimation models, lacking the capability to estimate the uncertainties of future traffic data, which is crucial in practical traffic decision-making. Aiming at this problem, we combine the probabilistic estimation capabilities of conditional normalizing flows with the spatio-temporal relationship learning of spatio-temporal graphs, leading to a Spatio-Temporal Graph Normalizing Flow (STGNF) model to estimate the distribution of future traffic data. We are the first to employ the conditional normalizing flows as the backbone for probabilistic traffic prediction. Then we design a spatio-temporal graph conditional fusion network to learn the spatio-temporal relationships between future and historical traffic data, which are provided to the conditional normalizing flows as conditional information. Extensive experiments on two real-world traffic datasets demonstrate that our proposed model significantly outperforms the state-of-the-art baselines.|随着智能交通系统的发展，大量研究工作被提出以解决交通预测任务。尽管这些模型表现良好，但大多数交通预测模型都是点估计模型，缺乏对未来交通数据不确定性的估计能力，而这种能力在实际交通决策中至关重要。针对这一问题，我们将条件归一化流（conditional normalizing flows）的概率估计能力与时空图的时空关系学习相结合，提出了一种时空图归一化流（Spatio-Temporal Graph Normalizing Flow, STGNF）模型，用于估计未来交通数据的分布。我们是首个将条件归一化流作为概率交通预测的主干网络的研究者。随后，我们设计了一种时空图条件融合网络，用于学习未来与历史交通数据之间的时空关系，并将这些关系作为条件信息提供给条件归一化流。在两个真实世界交通数据集上的广泛实验表明，我们提出的模型显著优于现有的最先进基线模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spatio-temporal+Graph+Normalizing+Flow+for+Probabilistic+Traffic+Prediction)|0|
|[Can LLMs Reason Like Humans? Assessing Theory of Mind Reasoning in LLMs for Open-Ended Questions](https://doi.org/10.1145/3627673.3679832)|Maryam Amirizaniani, Elias Martin, Maryna Sivachenko, Afra Mashhadi, Chirag Shah|University of Washington, Seattle, WA, USA; University of Washington - Bothell, Bothell, WA, USA|Theory of mind (ToM) reasoning involves understanding that others have intentions, emotions, and thoughts, which is crucial for regulating one's reasoning. Although large language models (LLMs) excel in tasks such as summarization, question answering, and translation, they still face challenges with ToM reasoning, especially in open-ended questions. Despite advancements, the extent to which LLMs truly understand ToM reasoning and how closely it aligns with human ToM reasoning remains inadequately explored in open-ended scenarios. Motivated by this gap, we assess the abilities of LLMs to perceive and integrate human intentions and emotions into their ToM reasoning processes within open-ended questions. Our study utilizes posts from Reddit's ChangeMyView platform, which demands nuanced social reasoning to craft persuasive responses. Our analysis, comparing semantic similarity and lexical overlap metrics between responses generated by humans and LLMs, reveals clear disparities in ToM reasoning capabilities in open-ended questions, with even the most advanced models showing notable limitations. To enhance LLM capabilities, we implement a prompt tuning method that incorporates human intentions and emotions, resulting in improvements in ToM reasoning performance. However, despite these improvements, the enhancement still falls short of fully achieving human-like reasoning. This research highlights the deficiencies in LLMs' social reasoning and demonstrates how integrating human intentions and emotions can boost their effectiveness.|心智理论（Theory of Mind, ToM）推理涉及理解他人具有意图、情感和思想的能力，这对于调节个人的推理过程至关重要。尽管大型语言模型（LLMs）在摘要生成、问答和翻译等任务中表现出色，但它们在处理开放性问题中的ToM推理时仍面临挑战。尽管已有进展，LLMs在开放性场景下对ToM推理的真实理解程度及其与人类ToM推理的契合度仍未得到充分探索。基于这一研究空白，我们评估了LLMs在开放性问题中感知和整合人类意图与情感以进行ToM推理的能力。本研究使用了Reddit的ChangeMyView平台上的帖子，该平台要求在构建有说服力的回复时进行细致的社会推理。通过对比人类与LLMs生成回复之间的语义相似度和词汇重叠度指标，我们的分析揭示了在开放性问题中ToM推理能力的明显差异，即使是当前最先进的模型也显示出显著的局限性。为了提升LLMs的能力，我们实施了一种提示调优方法，该方法融入了人类意图和情感，从而改善了ToM推理的表现。然而，尽管有所改进，这种提升仍未达到完全实现类人推理的水平。本研究突显了LLMs在社会推理中的不足，并展示了如何通过整合人类意图和情感来增强其推理效果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Can+LLMs+Reason+Like+Humans?+Assessing+Theory+of+Mind+Reasoning+in+LLMs+for+Open-Ended+Questions)|0|
|[Advances in Citation Text Generation: Leveraging Multi-Source Seq2Seq Models and Large Language Models](https://doi.org/10.1145/3627673.3679783)|Avinash Anand, Ashwin R. Nair, Kritarth Prasad, Vrinda Narayan, Naman Lal, Debanjan Mahata, Yaman Singla, Rajiv Ratn Shah|Adobe Media and Data Science Research (MDSR), Noida, Uttar Pradesh, India; MIDAS Lab, IIIT-Delhi, New Delhi, Delhi, India; IIIT Delhi, New Delhi, Delhi, India|Citation Text Generation (CTG) in scientific documents often relies on standard summarization techniques, which may not fully capture the nuanced relationship between the citing and cited papers. To address this, we present a Multi-Source Citation Text Generation (M-CTG) architecture, leveraging a Seq2Seq transformer framework enhanced with keyphrase embeddings, graph embeddings, and text representations. This approach aims to produce more contextually relevant and accurate citation texts by integrating multiple sources of information. Our methodology is tested using the newly created CTG-S2ORC dataset, consisting of English-language computer science research papers. In a comparative analysis, we explore the performance of traditional Language Models (LMs) and demonstrate how Large Language Models (LLMs), particularly when integrated with various prompting techniques and Knowledge Graphs, offer superior capabilities in analyzing and generating citation texts. In addition to traditional evaluation metrics, we introduce a custom metric that emphasizes the overlap of key terms and semantic similarity, providing a more comprehensive assessment of our model's performance. Our code and data are available at https://github.com/midas-research/M-CTG/tree/main.|在科学文献中的引用文本生成（Citation Text Generation, CTG）通常依赖于标准摘要技术，这些技术可能无法充分捕捉引用文献与被引用文献之间微妙的关系。为解决这一问题，我们提出了一种多源引用文本生成（Multi-Source Citation Text Generation, M-CTG）架构，该架构利用了Seq2Seq变换器框架，并结合了关键词嵌入、图嵌入和文本表示。这种方法旨在通过整合多种信息源，生成更具上下文相关性和准确性的引用文本。我们的方法使用新创建的CTG-S2ORC数据集进行测试，该数据集由英语的计算机科学研究论文组成。在对比分析中，我们探讨了传统语言模型（Language Models, LMs）的性能，并展示了大型语言模型（Large Language Models, LLMs），尤其是在结合各种提示技术和知识图谱时，在分析和生成引用文本方面具有更强的能力。除了传统的评估指标外，我们还引入了一个自定义指标，该指标强调关键词的重叠和语义相似性，从而提供了对我们模型性能的更全面评估。我们的代码和数据可在https://github.com/midas-research/M-CTG/tree/main获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Advances+in+Citation+Text+Generation:+Leveraging+Multi-Source+Seq2Seq+Models+and+Large+Language+Models)|0|
|[City Foundation Models for Learning General Purpose Representations from OpenStreetMap](https://doi.org/10.1145/3627673.3679662)|Pasquale Balsebre, Weiming Huang, Gao Cong, Yi Li||Pre-trained Foundation Models (PFMs) have ushered in a paradigm-shift in Artificial Intelligence, due to their ability to learn general-purpose representations that can be readily employed in a wide range of downstream tasks. While PFMs have been successfully adopted in various fields such as Natural Language Processing and Computer Vision, their capacity in handling geospatial data and answering urban questions remains limited. This can be attributed to the intrinsic heterogeneity of geospatial data, which encompasses different data types, including points, segments and regions, as well as multiple information modalities, such as a spatial position, visual characteristics and textual annotations. The proliferation of Volunteered Geographic Information initiatives, and the ever-increasing availability of open geospatial data sources, like OpenStreetMap, which is freely accessible globally, unveil a promising opportunity to bridge this gap. In this paper, we present CityFM, a self-supervised framework to train a foundation model within a selected geographical area of interest, such as a city. CityFM relies solely on open data from OSM, and produces multimodal representations of entities of different types, incorporating spatial, visual, and textual information. We analyse the entity representations generated using our foundation models from a qualitative perspective, and conduct quantitative experiments on road, building, and region-level downstream tasks. We compare its results to algorithms tailored specifically for the respective applications. In all the experiments, CityFM achieves performance superior to, or on par with, the baselines.|预训练基础模型（PFMs）因其能够学习可广泛应用于各种下游任务的通用表示，已引领人工智能领域发生范式转变。尽管PFMs在自然语言处理和计算机视觉等多个领域取得了成功应用，但其在处理地理空间数据和回答城市相关问题方面的能力仍显不足。这主要归因于地理空间数据的内在异质性，包括点、线段和区域等多种数据类型，以及空间位置、视觉特征和文本注释等多模态信息。随着志愿者地理信息计划的普及和开放地理数据源（如全球免费访问的OpenStreetMap）的日益增多，为填补这一差距提供了契机。本文提出了CityFM，这是一个在选定的地理区域（如城市）内训练基础模型的自监督框架。CityFM完全依赖于OSM的开放数据，生成包含空间、视觉和文本信息的多模态实体表示。我们从定性角度分析了使用基础模型生成的实体表示，并在道路、建筑和区域级别的下游任务上进行了定量实验。我们将CityFM的结果与针对各自应用专门设计的算法进行了比较。在所有实验中，CityFM的表现均优于或与基线相当。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=City+Foundation+Models+for+Learning+General+Purpose+Representations+from+OpenStreetMap)|0|
|[A Learning-based Approach for Explaining Language Models](https://doi.org/10.1145/3627673.3679548)|Oren Barkan, Yonatan Toib, Yehonatan Elisha, Noam Koenigstein|The Open University, Tel Aviv, Israel; Tel Aviv University, Tel Aviv, Israel|We present Learning Attributions (LA), a novel method for explaining language models. The core idea behind LA is to train a dedicated attribution model that functions as a surrogate explainer for the language model. This attribution model is designed to identify which tokens are most influential in driving the model's predictions. By optimizing the attribution model to mask the minimal amount of information necessary to induce substantial changes in the language model's output, LA provides a mechanism to understand which tokens in the input are critical for the model's decisions. We demonstrate the effectiveness of LA across several language models, highlighting its superiority over multiple state-of-the-art explanation methods across various datasets and evaluation metrics.|我们提出了“学习归因”（Learning Attributions，简称LA），这是一种用于解释语言模型的新方法。LA的核心思想是训练一个专门的归因模型，该模型作为语言模型的替代解释器。这个归因模型的设计目的是识别哪些词元对驱动模型预测最为关键。通过优化归因模型，使其仅掩盖引发语言模型输出显著变化所需的最小信息量，LA提供了一种机制，用于理解输入中的哪些词元对模型的决策至关重要。我们在多个语言模型上展示了LA的有效性，强调了其在各种数据集和评估指标上优于多种最先进的解释方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Learning-based+Approach+for+Explaining+Language+Models)|0|
|[Discovering Denial Constraints Based on Deep Reinforcement Learning](https://doi.org/10.1145/3627673.3679714)|Lingfeng Bian, Weidong Yang, Jingyi Xu, Zijing Tan|; Fudan University & Zhuhai Fudan Innovation Research Institute, Shanghai, China; Fudan University, Shanghai, China|Numerous algorithms have been proposed for discovering denial constraints (DCs), which are essential and effective for maintaining data consistency. However, existing methods only focus on discovering the complete set of DCs, often resulting in hundreds or even tens of thousands of discovered rules. Such a large number of DCs are impractical for users to verify and utilize. Besides, these methods overlook the intent of users, which requires the discovered DCs to be succinct, relevant, and diverse concurrently. To address these limitations, we introduce DCMiner, a deep reinforcement learning (DRL)-based framework that produces rules satisfying user preferences. Specifically, we first model the discovering process via a kCover Markov decision process to improve efficiency. Then, a graphQ model is introduced to capture the data distribution and facilitate the discovery of DCs. Lastly, we design a reward function that flexibly integrates both objective and subjective criteria to align the discovered rules with user intent, and we propose an efficient training process. Extensive experiments on both real-world and synthetic datasets show that DCMiner can discover succinct, relevant, and diverse rules.|已经提出了许多算法来发现否定约束（DCs），这对于维护数据一致性至关重要且有效。然而，现有方法仅关注于发现DCs的完整集合，通常会产生数百甚至数万条规则。如此大量的DCs对用户来说难以验证和利用。此外，这些方法忽略了用户的需求，即所发现的DCs需要同时简洁、相关且多样化。为了解决这些局限性，我们提出了DCMiner，一个基于深度强化学习（DRL）的框架，用于生成符合用户偏好的规则。具体来说，我们首先通过kCover马尔可夫决策过程对发现过程进行建模，以提高效率。然后，引入graphQ模型来捕捉数据分布，从而促进DCs的发现。最后，我们设计了一个奖励函数，该函数灵活地结合了客观和主观标准，以使发现的规则与用户意图相一致，并提出了一个高效的训练过程。在真实世界和合成数据集上的广泛实验表明，DCMiner能够发现简洁、相关且多样化的规则。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Discovering+Denial+Constraints+Based+on+Deep+Reinforcement+Learning)|0|
|[Covering a Graph with Dense Subgraph Families, via Triangle-Rich Sets](https://doi.org/10.1145/3627673.3679578)|Sabyasachi Basu, Daniel PaulPena, Kun Qian, C. Seshadhri, Edward W. Huang, Karthik Subbian||Graphs are a fundamental data structure used to represent relationships in domains as diverse as the social sciences, bioinformatics, cybersecurity, the Internet, and more. One of the central observations in network science is that real-world graphs are globally sparse, yet contains numerous "pockets" of high edge density. A fundamental task in graph mining is to discover these dense subgraphs. Most common formulations of the problem involve finding a single (or a few) "optimally" dense subsets. But in most real applications, one does not care for the optimality. Instead, we want to find a large collection of dense subsets that covers a significant fraction of the input graph. We give a mathematical formulation of this problem, using a new definition of regularly triangle-rich (RTR) families. These families capture the notion of dense subgraphs that contain many triangles and have degrees comparable to the subgraph size. We design a provable algorithm, RTRExtractor, that can discover RTR families that approximately cover any RTR set. The algorithm is efficient and is inspired by recent results that use triangle counts for community testing and clustering. We show that RTRExtractor has excellent behavior on a large variety of real-world datasets. It is able to process graphs with hundreds of millions of edges within minutes. Across many datasets, RTRExtractor achieves high coverage using high edge density datasets. For example, the output covers a quarter of the vertices with subgraphs of edge density more than (say) 0.5, for datasets with 10M+ edges. We show an example of how the output of RTRExtractor correlates with meaningful sets of similar vertices in a citation network, demonstrating the utility of RTRExtractor for unsupervised graph discovery tasks.|图结构是一种基本的数据结构，广泛应用于社会科学、生物信息学、网络安全、互联网等多个领域，用于表示各种关系。网络科学的一个核心观察是，现实世界的图在全局上是稀疏的，但包含许多高边密度的“口袋”区域。图挖掘中的一个基本任务是发现这些稠密子图。大多数常见的问题表述涉及寻找单个（或少数几个）“最优”稠密子集。然而，在大多数实际应用中，人们并不追求最优性，而是希望找到大量稠密子集，这些子集能够覆盖输入图的显著部分。我们通过引入一个新的定义——规则三角富集（RTR）家族，给出了这个问题的数学表述。这些家族捕捉了稠密子图的概念，这些子图包含许多三角形，并且其度数与子图大小相当。我们设计了一种可证明的算法RTRExtractor，能够发现近似覆盖任何RTR集的RTR家族。该算法高效，并受到近期利用三角形计数进行社区检测和聚类的研究启发。我们在大量真实世界数据集上展示了RTRExtractor的优异表现。它能够在几分钟内处理包含数亿条边的图。在许多数据集中，RTRExtractor使用高边密度的子图实现了高覆盖率。例如，对于包含1000万条边以上的数据集，其输出覆盖了四分之一的顶点，且这些子图的边密度超过（例如）0.5。我们展示了一个示例，说明RTRExtractor的输出如何与引用网络中有意义的相似顶点集合相关联，从而展示了RTRExtractor在无监督图发现任务中的实用性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Covering+a+Graph+with+Dense+Subgraph+Families,+via+Triangle-Rich+Sets)|0|
|[Hierarchical Graph Latent Diffusion Model for Conditional Molecule Generation](https://doi.org/10.1145/3627673.3679547)|Tian Bian, Yifan Niu, Heng Chang, Divin Yan, Junzhou Huang, Yu Rong, Tingyang Xu, Jia Li, Hong Cheng|The Chinese University of Hong Kong, Hong Kong, Hong Kong; University of Texas, Arlington, Arlington, TX, USA; DAMO Academy, Alibaba Group & Hupan Lab, Hangzhou, China; Fudan University, Shanghai, China; Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; Tsinghua University, Beijing, China|Recently, generative models based on the diffusion process have emerged as a promising direction for automating the design of molecules. However, directly adding continuous Gaussian noise to discrete graphs leads to the problem that the generated data do not conform to the discrete graph data distribution in the training set. Current graph diffusion models either corrupt discrete data through a transition matrix or relax the discrete data to continuous space for the diffusion process. These approaches make it hard to perform extensible conditional generation, such as adapting to text-based conditions, due to the lack of embedding representations and require significant computation resources due to the diffusion process of the bond type matrix. This paper introduces the Hierarchical Graph Latent Diffusion Model (HGLDM), a novel variant of latent diffusion models that overcomes the problem of applying continuous diffusion models directly to discrete graph data. Meanwhile, based on the latent diffusion framework, HGLDM avoids the issues of computational consumption and lack of embeddings for extensible conditional generation. In addition, by comparing the HGLDM with its variant, the Graph Latent Diffusion Model (GLDM), which only has graph-level embeddings, we validate the advantage of the hierarchical graph structure for capturing the relationship between structure information and molecular properties. We evaluate the performance of our model through various conditional generation tasks, demonstrating its superior performance.|最近，基于扩散过程的生成模型已成为自动化分子设计的一个有前景的方向。然而，直接向离散图添加连续高斯噪声会导致生成数据不符合训练集中离散图数据分布的问题。当前的图扩散模型要么通过转移矩阵破坏离散数据，要么将离散数据松弛到连续空间进行扩散过程。这些方法由于缺乏嵌入表示，难以进行可扩展的条件生成，例如适应基于文本的条件，并且由于键类型矩阵的扩散过程，需要大量的计算资源。本文介绍了分层图潜在扩散模型（HGLDM），这是一种潜在扩散模型的新变体，克服了直接将连续扩散模型应用于离散图数据的问题。同时，基于潜在扩散框架，HGLDM避免了计算消耗和缺乏嵌入表示以进行可扩展条件生成的问题。此外，通过将HGLDM与其变体图潜在扩散模型（GLDM）进行比较，后者仅具有图级嵌入，我们验证了分层图结构在捕捉结构信息与分子性质之间关系方面的优势。我们通过各种条件生成任务评估了模型的性能，展示了其优越的表现。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Graph+Latent+Diffusion+Model+for+Conditional+Molecule+Generation)|0|
|[Finding MIDDLE Ground: Scalable and Secure Distributed Learning](https://doi.org/10.1145/3627673.3679587)|Marco Bornstein, Nawaf Nazir, Ján Drgona, Soumya Kundu, Veronica Adetola|Pacific Northwest National Laboratory, Richland, WA, USA; University of Maryland, College Park, MD, USA|Edge-computing methods allow devices to efficiently train a high-performing, robust, and personalized model for predictive tasks. However, these methods succumb to privacy and scalability concerns such as adversarial data recovery and expensive model communication. Furthermore, edge computing methods unrealistically assume that all devices train an identical model. In practice, edge devices have varying computational and memory constraints, which may not allow certain devices to have the space or speed to train a specific model. To overcome these issues, we propose MIDDLE, a model-independent distributed learning algorithm that allows heterogeneous edge devices to assist each other in training while communicating only non-sensitive information. MIDDLE unlocks the ability for edge devices, regardless of computational or memory constraints, to assist each other even with completely different model architectures. Furthermore, MIDDLE does not require model or gradient communication, significantly reducing communication size and time. We prove that MIDDLE attains the optimal convergence rate of stochastic gradient descent for convex and non-convex smooth optimization. Finally, our experimental results demonstrate that MIDDLE attains robust and high-performing models without model or gradient communication.|边缘计算方法使得设备能够高效地训练出高性能、稳健且个性化的预测模型。然而，这些方法存在隐私和可扩展性问题，例如对抗性数据恢复和昂贵的模型通信。此外，边缘计算方法不切实际地假设所有设备都训练相同的模型。实际上，边缘设备的计算和内存资源各不相同，某些设备可能没有足够的空间或速度来训练特定的模型。为了解决这些问题，我们提出了MIDDLE，一种与模型无关的分布式学习算法，允许异构边缘设备在仅通信非敏感信息的情况下相互协助进行训练。MIDDLE使得边缘设备，无论其计算或内存约束如何，即使使用完全不同的模型架构，也能相互协助。此外，MIDDLE不需要模型或梯度通信，显著减少了通信的大小和时间。我们证明了MIDDLE在凸和非凸光滑优化中达到了随机梯度下降的最优收敛率。最后，我们的实验结果表明，MIDDLE在不进行模型或梯度通信的情况下，仍能获得稳健且高性能的模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Finding+MIDDLE+Ground:+Scalable+and+Secure+Distributed+Learning)|0|
|[MATCC: A Novel Approach for Robust Stock Price Prediction Incorporating Market Trends and Cross-time Correlations](https://doi.org/10.1145/3627673.3679715)|Zhiyuan Cao, Jiayu Xu, Chengqi Dong, Peiwen Yu, Tian Bai|Jilin University, Changchun, China; SHANGHAI RUITIAN INVESTMENT LLC, Shanghai, China|Stock price prediction has been a challenging problem due to non-stationary dynamics and complex market dependencies. Existing work has two limitations: 1. Previous studies have underestimated the importance of market trends, relying solely on stock data to learn patterns and capture market regularities implicitly. However, due to random stock fluctuations and trading noise caused by market sentiment, it is difficult to learn underlying market trends, resulting in poor model performance. 2. Prior research has predominantly concentrated on time-aligned feature correlations, with limited exploration of cross-time stock correlations. To address these issues, we propose a novel framework, MATCC (Market Trend and Cross-time Correlation model). It explicitly extracts market trends as guiding information, decomposes stock data into trend and fluctuation components, and employs a carefully designed structure for mining cross-time correlation. Extensive experiments demonstrate that MATCC significantly outperforms previous works in both ranking and portfolio-based metrics. Additionally, we illustrate the influence of trends and correlations on stock prediction through visualization. We publish our code at https://github.com/caozhiy/MATCC.|股票价格预测一直是一个具有挑战性的问题，主要由于其非平稳的动力学特性和复杂的市场依赖关系。现有的研究存在两个主要局限性：1. 以往的研究低估了市场趋势的重要性，仅依赖股票数据来学习模式并隐式捕捉市场规律。然而，由于市场情绪导致的随机股票波动和交易噪音，很难学习到潜在的市场趋势，从而导致模型性能不佳。2. 先前的研究主要集中在时间对齐的特征相关性上，对跨时间股票相关性的探索有限。为了解决这些问题，我们提出了一种新的框架——MATCC（市场趋势与跨时间相关性模型）。该框架明确提取市场趋势作为指导信息，将股票数据分解为趋势和波动成分，并采用精心设计的结构来挖掘跨时间相关性。大量实验表明，MATCC在排名和基于投资组合的指标上显著优于以往的工作。此外，我们通过可视化展示了趋势和相关性对股票预测的影响。我们的代码已发布在 https://github.com/caozhiy/MATCC。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MATCC:+A+Novel+Approach+for+Robust+Stock+Price+Prediction+Incorporating+Market+Trends+and+Cross-time+Correlations)|0|
|[DiHAN: A Novel Dynamic Hierarchical Graph Attention Network for Fake News Detection](https://doi.org/10.1145/3627673.3679675)|YaTing Chang, Zhibo Hu, Xiaoyu Li, Shuiqiao Yang, Jiaojiao Jiang, Nan Sun|University of New South Wales, Canberra, ACT, Australia; Stevens Institute of Technology, Hoboken, NJ, USA; Data61, Sydney, NSW, Australia; University of New South Wales, Sydney, NSW, Australia|The rapid spread of fake news on social media has caused great harm to society in recent years, which raises the detection of fake news as an urgent task. Recent methods utilize the interactions among different entities such as authors, subjects, and news articles to model news propagation as a static heterogeneous information network (HIN). However, this is suboptimal since fake news emerges dynamically, and the latent chronological interactions between news in HIN are essential signals for fake news detection. To this end, we model the dynamics of news and associated entities as a News-Driven Dynamic Heterogeneous Information Network (News-DyHIN), where the temporal relationships among news articles are well captured with meta-path based temporal neighbors. With the support of News-DyHIN, we propose a novel fake news detection framework, named D ynam i c H ierarchical A ttention N etwork (DiHAN), which learns news representations via a hierarchical attention mechanism to fuse temporal interactions among news articles. In particular, DiHAN first employs a temporal node level attention to learn the temporal information from meta-path based news neighbors through the modeled News-DyHIN. Then, a semantic attention layer is adopted to fuse different types of meta-path based temporal information for news representation learning. Extensive evaluations conducted on two public real-world datasets demonstrate that our proposed DiHAN achieves significant improvements over established baseline models.|近年来，社交媒体上虚假新闻的迅速传播对社会造成了巨大危害，使得虚假新闻检测成为一项紧迫任务。最近的方法利用作者、主题和新闻文章等不同实体之间的交互，将新闻传播建模为静态的异构信息网络（HIN）。然而，这种方法并不理想，因为虚假新闻是动态出现的，而HIN中新闻之间潜在的时间交互是虚假新闻检测的重要信号。为此，我们将新闻及其相关实体的动态性建模为新闻驱动的动态异构信息网络（News-DyHIN），其中新闻文章之间的时间关系通过基于元路径的时间邻居得到良好捕捉。在News-DyHIN的支持下，我们提出了一种新的虚假新闻检测框架，称为动态分层注意力网络（DiHAN），该框架通过分层注意力机制来融合新闻文章之间的时间交互，从而学习新闻表示。具体而言，DiHAN首先采用时间节点级注意力机制，通过建模的News-DyHIN从基于元路径的新闻邻居中学习时间信息。然后，采用语义注意力层来融合不同类型的基于元路径的时间信息，以进行新闻表示学习。在两个公开的真实世界数据集上进行的大量评估表明，我们提出的DiHAN相比现有的基线模型取得了显著的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DiHAN:+A+Novel+Dynamic+Hierarchical+Graph+Attention+Network+for+Fake+News+Detection)|0|
|[Improving Message-Passing GNNs by Asynchronous Aggregation](https://doi.org/10.1145/3627673.3679778)|Jialong Chen, Tianchi Liao, Chuan Chen, Zibin Zheng|Sun Yat-sen University, Guangzhou, Guangdong, China|Message passing (MP) is a popular paradigm for designing graph neural networks (GNNs), which iteratively aggregates neighbor information and updates node embeddings. However, this paradigm suffers from several issues: First, long-range information struggles to be fully utilized, known as over-squashing. Second, excessive MP layers lead to indistinguishable representations, referred to as over-smoothing. Finally, vanilla MPNNs fail to meet the ability of training in heterophilic graphs. In this paper, we provide a unified insight into these defects: node embeddings are sent to neighbors at a constant "pace" and are aggregated immediately. Such synchronicity causes embeddings closer to the output to be more important, i.e. local priority, manifesting the aforementioned issues. Based on this, Asyn-MPNN, an asynchronous framework that customizes the speed of information aggregation, is proposed, which can unify many popular GNNs. We further propose the automated asynchronous (a Asyn) layer, which achieves effects similar to Asyn-MPNN but without introducing extra hyperparameters and can be integrated into any GNN. aAsyn-MPNN validates its performance through extensive experiments on both graph-level and node-level tasks and achieves leading results on tasks from long-range graph benchmark.|消息传递（MP）是设计图神经网络（GNNs）的一种流行范式，它通过迭代聚合邻居信息并更新节点嵌入。然而，这一范式存在几个问题：首先，长程信息难以被充分利用，即所谓的“过度压缩”。其次，过多的MP层会导致表示难以区分，称为“过度平滑”。最后，传统的MPNNs在异质图上的训练能力不足。本文对这些问题提供了一个统一的见解：节点嵌入以固定的“速度”传递给邻居并立即聚合。这种同步性导致更接近输出的嵌入更为重要，即“局部优先”，从而表现出上述问题。基于此，我们提出了Asyn-MPNN，一个自定义信息聚合速度的异步框架，能够统一多种流行的GNNs。我们进一步提出了自动化异步（a Asyn）层，它实现了与Asyn-MPNN类似的效果，但没有引入额外的超参数，并且可以集成到任何GNN中。通过在图级和节点级任务上的广泛实验，aAsyn-MPNN验证了其性能，并在长程图基准任务上取得了领先的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Message-Passing+GNNs+by+Asynchronous+Aggregation)|0|
|[ERASE: Error-Resilient Representation Learning on Graphs for Label Noise Tolerance](https://doi.org/10.1145/3627673.3679552)|LingHao Chen, Yuanshuo Zhang, Taohua Huang, Liangcai Su, Zeyi Lin, Xi Xiao, Xiaobo Xia, Tongliang Liu|Xidian University; The University of Sydney; Tsinghua University|Deep learning has achieved remarkable success in graph-related tasks, yetthis accomplishment heavily relies on large-scale high-quality annotateddatasets. However, acquiring such datasets can be cost-prohibitive, leading tothe practical use of labels obtained from economically efficient sources suchas web searches and user tags. Unfortunately, these labels often come withnoise, compromising the generalization performance of deep networks. To tacklethis challenge and enhance the robustness of deep learning models against labelnoise in graph-based tasks, we propose a method called ERASE (Error-Resilientrepresentation learning on graphs for lAbel noiSe tolerancE). The core idea ofERASE is to learn representations with error tolerance by maximizing codingrate reduction. Particularly, we introduce a decoupled label propagation methodfor learning representations. Before training, noisy labels are pre-correctedthrough structural denoising. During training, ERASE combines prototypepseudo-labels with propagated denoised labels and updates representations witherror resilience, which significantly improves the generalization performancein node classification. The proposed method allows us to more effectivelywithstand errors caused by mislabeled nodes, thereby strengthening therobustness of deep networks in handling noisy graph data. Extensiveexperimental results show that our method can outperform multiple baselineswith clear margins in broad noise levels and enjoy great scalability. Codes arereleased at https://github.com/eraseai/erase.|深度学习在图相关任务中取得了显著的成功，然而这一成就很大程度上依赖于大规模高质量的标注数据集。然而，获取这样的数据集可能成本高昂，导致实际应用中使用从网络搜索和用户标签等经济高效的来源获取的标签。不幸的是，这些标签往往带有噪声，影响了深度网络的泛化性能。为了应对这一挑战并提高深度学习模型在基于图的任务中对标签噪声的鲁棒性，我们提出了一种名为ERASE（Error-Resilient representation learning on graphs for lAbel noiSe tolerancE）的方法。ERASE的核心思想是通过最大化编码率降低来学习具有容错能力的表示。特别地，我们引入了一种解耦的标签传播方法来学习表示。在训练之前，通过结构去噪预先校正噪声标签。在训练过程中，ERASE结合原型伪标签和传播的去噪标签，并以容错能力更新表示，这显著提高了节点分类中的泛化性能。所提出的方法使我们能够更有效地抵抗错误标记节点导致的错误，从而增强了深度网络在处理噪声图数据时的鲁棒性。广泛的实验结果表明，我们的方法在广泛的噪声水平下能够显著优于多个基线，并具有良好的可扩展性。代码已在https://github.com/eraseai/erase 发布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ERASE:+Error-Resilient+Representation+Learning+on+Graphs+for+Label+Noise+Tolerance)|0|
|[Assessing Image Inpainting via Re-Inpainting Self-Consistency Evaluation](https://doi.org/10.1145/3627673.3679693)|Tianyi Chen, Jianfu Zhang, Yan Hong, Yiyi Zhang, Liqing Zhang||Image inpainting, the task of reconstructing missing segments in corruptedimages using available data, faces challenges in ensuring consistency andfidelity, especially under information-scarce conditions. Traditionalevaluation methods, heavily dependent on the existence of unmasked referenceimages, inherently favor certain inpainting outcomes, introducing biases.Addressing this issue, we introduce an innovative evaluation paradigm thatutilizes a self-supervised metric based on multiple re-inpainting passes. Thisapproach, diverging from conventional reliance on direct comparisons in pixelor feature space with original images, emphasizes the principle ofself-consistency to enable the exploration of various viable inpaintingsolutions, effectively reducing biases. Our extensive experiments acrossnumerous benchmarks validate the alignment of our evaluation method with humanjudgment.|图像修复，即利用可用数据重建受损图像中缺失部分的任务，面临着在信息匮乏条件下确保一致性和忠实度的挑战。传统的评估方法严重依赖于未被遮蔽的参考图像的存在，这本身就偏向于某些修复结果，从而引入了偏见。为解决这一问题，我们引入了一种创新的评估范式，该范式基于多次重新修复的自监督指标。这种方法不同于传统上依赖于与原始图像在像素或特征空间中直接比较的方式，而是强调自一致性原则，以探索多种可行的修复解决方案，从而有效减少偏见。我们在众多基准上的广泛实验验证了我们的评估方法与人类判断的一致性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Assessing+Image+Inpainting+via+Re-Inpainting+Self-Consistency+Evaluation)|0|
|[DTFormer: A Transformer-Based Method for Discrete-Time Dynamic Graph Representation Learning](https://doi.org/10.1145/3627673.3679568)|Xi Chen, Yun Xiong, Siwei Zhang, Jiawei Zhang, Yao Zhang, Shiyang Zhou, Xixi Wu, Mingyang Zhang, Tengfei Liu, Weiqiang Wang||Discrete-Time Dynamic Graphs (DTDGs), which are prevalent in real-world implementations and notable for their ease of data acquisition, have garnered considerable attention from both academic researchers and industry practitioners. The representation learning of DTDGs has been extensively applied to model the dynamics of temporally changing entities and their evolving connections. Currently, DTDG representation learning predominantly relies on GNN+RNN architectures, which manifest the inherent limitations of both Graph Neural Networks (GNNs) and Recurrent Neural Networks (RNNs). GNNs suffer from the over-smoothing issue as the models architecture goes deeper, while RNNs struggle to capture long-term dependencies effectively. GNN+RNN architectures also grapple with scaling to large graph sizes and long sequences. Additionally, these methods often compute node representations separately and focus solely on individual node characteristics, thereby overlooking the behavior intersections between the two nodes whose link is being predicted, such as instances where the two nodes appear together in the same context or share common neighbors. This paper introduces a novel representation learning method DTFormer for DTDGs, pivoting from the traditional GNN+RNN framework to a Transformer-based architecture. Our approach exploits the attention mechanism to concurrently process topological information within the graph at each timestamp and temporal dynamics of graphs along the timestamps, circumventing the aforementioned fundamental weakness of both GNNs and RNNs. Moreover, we enhance the model's expressive capability by incorporating the intersection relationships among nodes and integrating a multi-patching module. Extensive experiments conducted on six public dynamic graph benchmark datasets confirm our model's efficacy, achieving the SOTA performance.|离散时间动态图（Discrete-Time Dynamic Graphs, DTDGs）在现实世界中的应用广泛，因其数据获取简便而备受关注，不仅吸引了学术界的研究者，也得到了行业实践者的重视。DTDGs的表示学习被广泛应用于建模时间上变化实体及其演化连接的动态特性。当前，DTDG表示学习主要依赖于GNN+RNN架构，这种架构同时展现了图神经网络（GNNs）和循环神经网络（RNNs）的固有局限性。GNNs随着模型深度的增加会遭遇过平滑问题，而RNNs则难以有效捕捉长期依赖关系。GNN+RNN架构在处理大规模图和长序列时也面临扩展性挑战。此外，这些方法通常单独计算节点表示，仅关注单个节点的特性，忽略了在预测链接时两个节点行为交集的重要性，例如两个节点在同一上下文中出现或共享共同邻居的情况。

本文提出了一种新颖的DTDG表示学习方法DTFormer，从传统的GNN+RNN框架转向基于Transformer的架构。我们的方法利用注意力机制同时处理每个时间戳内的图拓扑信息和沿时间戳的图动态变化，从而规避了GNNs和RNNs的上述根本性弱点。此外，我们通过引入节点间的交集关系并整合多补丁模块，增强了模型的表达能力。在六个公开的动态图基准数据集上进行的广泛实验验证了我们模型的有效性，实现了当前最优（SOTA）的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DTFormer:+A+Transformer-Based+Method+for+Discrete-Time+Dynamic+Graph+Representation+Learning)|0|
|[Honest-Majority Maliciously Secure Skyline Queries on Outsourced Data](https://doi.org/10.1145/3627673.3679666)|Yu Chen, Lin Liu, Rongmao Chen, Shaojing Fu, Yuexiang Yang|National University of Defense Technology, Changsha, Hunan, China|The application of skyline queries on outsourced databases significantly aids online analysis, yet efficiently handling encrypted queries remains a formidable obstacle. Moreover, query outcomes are vulnerable to potential malicious cloud services. To circumvent these limitations, this work presents the Honest-Majority and Maliciously Skyline Query scheme (HMMSQ), which facilitates efficient skyline queries while safeguarding the privacy of datasets, queries, and skylines, as well as detecting malevolent activities. The core of HMMSQ is an optimized skyline diagram constructed by a novel skyline region-splitting algorithm for accurate skyline queries. Furthermore, it mitigates the frequency of dataset accesses by leveraging a multi-path R-tree for secure skyline retrieval. Notably, the majority of malicious behavior detection is focused on the servers, thereby minimizing user authentication overhead. The complexity and security are thoroughly analyzed, and experimental evaluations on various datasets demonstrate its efficiency and practicality in terms of computational cost and communication overhead. Remarkably, HMMSQ outperforms existing methods in query latency, achieving up to an order of magnitude improvement.|在外包数据库上应用天际线查询显著促进了在线分析，然而高效处理加密查询仍然是一个巨大的挑战。此外，查询结果容易受到潜在恶意云服务的威胁。为了克服这些限制，本研究提出了诚实多数与恶意天际线查询方案（HMMSQ），该方案在保护数据集、查询和天际线隐私的同时，实现了高效的天际线查询，并能检测恶意活动。HMMSQ的核心是一个优化的天际线图，由一种新颖的天际线区域分割算法构建，以实现精确的天际线查询。此外，它通过利用多路径R树来减少安全天际线检索中的数据集访问频率。值得注意的是，恶意行为检测的大部分工作集中在服务器端，从而最小化了用户认证的开销。研究对复杂性和安全性进行了全面分析，并在多种数据集上的实验评估表明，HMMSQ在计算成本和通信开销方面表现出了高效性和实用性。特别地，HMMSQ在查询延迟方面优于现有方法，实现了高达一个数量级的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Honest-Majority+Maliciously+Secure+Skyline+Queries+on+Outsourced+Data)|0|
|[SVIPTR: Fast and Efficient Scene Text Recognition with Vision Permutable Extractor](https://doi.org/10.1145/3627673.3679618)|Xianfu Cheng, Weixiao Zhou, Xiang Li, Jian Yang, Hang Zhang, Tao Sun, Wei Zhang, Yuying Mai, Tongliang Li, Xiaoming Chen, Zhoujun Li|Beihang University; ; Beihang University Shenzhen Intelligent Strong Technology Co; Shenzhen Intelligent Strong Technology Co|Scene Text Recognition (STR) is an important and challenging upstream task for building structured information databases, that involves recognizing text within images of natural scenes. Although current state-of-the-art (SOTA) models for STR exhibit high performance, they typically suffer from low inference efficiency due to their reliance on hybrid architectures comprised of visual encoders and sequence decoders. In this work, we propose a VIsion Permutable extractor for fast and efficient Scene Text Recognition (SVIPTR), which achieves an impressive balance between high performance and rapid inference speeds in the domain of STR. Specifically, SVIPTR leverages a visual-semantic extractor with a pyramid structure, characterized by the Permutation and combination of local and global self-attention layers. This design results in a lightweight and efficient model and its inference is insensitive to input length. Extensive experimental results on various standard datasets for both Chinese and English scene text recognition validate the superiority of SVIPTR. Notably, the SVIPTR-T (Tiny) variant delivers highly competitive accuracy on par with other lightweight models and achieves SOTA inference speeds. Meanwhile, the SVIPTR-L (Large) attains SOTA accuracy in single-encoder-type models, while maintaining a low parameter count and favorable inference speed. Our proposed method provides a compelling solution for the STR challenge, which greatly benefits real-world applications requiring fast and efficient STR. The code is publicly available at https://github.com/cxfyxl/VIPTR.|场景文本识别（Scene Text Recognition, STR）是构建结构化信息数据库的重要且具有挑战性的上游任务，涉及识别自然场景图像中的文本。尽管当前最先进的（State-of-the-Art, SOTA）STR模型表现出高水平的性能，但由于它们依赖于由视觉编码器和序列解码器组成的混合架构，通常存在推理效率低下的问题。在本研究中，我们提出了一种用于快速高效场景文本识别的视觉可置换提取器（VIsion Permutable extractor for fast and efficient Scene Text Recognition, SVIPTR），该方法在STR领域实现了高性能与快速推理速度的卓越平衡。具体而言，SVIPTR采用了一种具有金字塔结构的视觉-语义提取器，其特点是通过局部和全局自注意力层的排列与组合。这一设计使得模型既轻量又高效，并且其推理过程对输入长度不敏感。在多种中英文场景文本识别的标准数据集上的广泛实验结果验证了SVIPTR的优越性。值得注意的是，SVIPTR-T（Tiny）变体在与其他轻量级模型相当的精度下，达到了SOTA的推理速度。同时，SVIPTR-L（Large）在单编码器类型模型中达到了SOTA的精度，同时保持了较低的参数量和良好的推理速度。我们提出的方法为STR挑战提供了一个强有力的解决方案，极大地促进了需要快速高效STR的实际应用。代码已公开发布于https://github.com/cxfyxl/VIPTR。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SVIPTR:+Fast+and+Efficient+Scene+Text+Recognition+with+Vision+Permutable+Extractor)|0|
|[TESSM: Tree-based Selective State Space Models for Efficient Join Order Selection Learning](https://doi.org/10.1145/3627673.3679742)|Yaohui Chu, Yizhe Liu, Yue Zhang, Xuan Hou, Longfei Yu, Zhaohui Peng|Shandong University, Qingdao, China|Join order optimization is pivotal in database query optimization, seeking the most efficient join sequence to reduce execution costs. As more tables join, the complexity surges, turning it into an NP-hard problem due to the exponential growth of possible orders. Deep reinforcement learning (DRL) has recently made significant strides, outperforming traditional algorithms by treating join selection as a Markov Decision Process to devise more effective strategies.Current methods struggle with integrating query semantics and plan structures, as well as encountering issues with complex joins where bottom-up learning can lead to information loss.To tackle these issues, we present the Tree-based Selective State Space Models for Efficient Join Order Selection Learning(TESSM). This framework uses the Tree Mamba architecture to integrate join pattern graphs with execution plan nodes, enhancing long-term dependency information flow. A tiered training strategy enhances the model's training precision and speed.Our approach has proven effective, as evidenced by JOB and TPC-H benchmark tests, showing TESSM's substantial improvements in query optimization efficiency and effectiveness.|连接顺序优化在数据库查询优化中至关重要，旨在找到最有效的连接序列以降低执行成本。随着连接表数量的增加，复杂性急剧上升，由于可能的顺序呈指数增长，这使其成为一个NP难问题。深度强化学习（DRL）近年来取得了显著进展，通过将连接选择视为马尔可夫决策过程，设计出更有效的策略，从而超越了传统算法。当前的方法在整合查询语义和计划结构方面存在困难，并且在处理复杂连接时，自底向上的学习可能导致信息丢失。为了解决这些问题，我们提出了基于树的选择性状态空间模型，用于高效的连接顺序选择学习（TESSM）。该框架采用Tree Mamba架构，将连接模式图与执行计划节点相结合，增强了长期依赖信息的流动。分层训练策略提高了模型的训练精度和速度。我们的方法在JOB和TPC-H基准测试中得到了验证，显示出TESSM在查询优化效率和效果方面的显著提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TESSM:+Tree-based+Selective+State+Space+Models+for+Efficient+Join+Order+Selection+Learning)|0|
|[Automatic Large Language Model Evaluation via Peer Review](https://doi.org/10.1145/3627673.3679677)|Zhumin Chu, Qingyao Ai, Yiteng Tu, Haitao Li, Yiqun Liu|DCST, Tsinghua University & Quan Cheng Laboratory, Beijing, China; Quan Cheng Laboratory & DCST, Tsinghua University, Beijing, China; DCST, Tsinghua University & Zhongguancun Laboratory, Beijing, China|The impressive performance of large language models (LLMs) has attracted considerable attention from the academic and industrial communities. Besides how to construct and train LLMs, how to effectively evaluate and compare the capacity of LLMs has also been well recognized as an important yet difficult problem. Existing paradigms rely on either human annotators or model-based evaluators to evaluate the performance of LLMs on different tasks. However, these paradigms often suffer from high cost, low generalizability, and inherited biases in practice, which make them incapable of supporting the sustainable development of LLMs in the long term. In order to address these issues, inspired by the peer review systems widely used in the academic publication process, we propose a novel framework that can automatically evaluate LLMs through a peer-review process. Specifically, for the evaluation of a specific task, we first construct a small qualification exam to select "reviewers'' from a couple of powerful LLMs. Then, to actually evaluate the "submissions" written by different candidate LLMs, i.e., the evaluatees, we use the reviewer LLMs to rate or compare the submissions. The final ranking of evaluatee LLMs is generated based on the results provided by all reviewers. We conducted extensive experiments on both text summarization and non-factoid question-answering tasks with eleven LLMs including GPT-4. The results demonstrate the existence of biasness when evaluating using a single LLM. Also, our PRE model outperforms all the baselines, illustrating the effectiveness of the peer review mechanism.|大型语言模型（LLMs）的卓越表现引起了学术界和工业界的广泛关注。除了如何构建和训练LLMs之外，如何有效评估和比较LLMs的能力也被广泛认为是一个重要但困难的问题。现有的评估范式依赖于人工标注者或基于模型的评估器来评估LLMs在不同任务上的表现。然而，这些范式在实践中往往成本高昂、泛化能力低，并且存在固有的偏见，这使得它们无法长期支持LLMs的可持续发展。为了解决这些问题，受学术出版过程中广泛使用的同行评审系统的启发，我们提出了一种新颖的框架，通过同行评审过程来自动评估LLMs。具体而言，对于特定任务的评估，我们首先构建一个小型的资格考试，从多个强大的LLMs中选出“评审员”。然后，为了实际评估不同候选LLMs（即被评估者）生成的“提交内容”，我们使用评审LLMs对这些提交内容进行评分或比较。最终，被评估LLMs的排名是基于所有评审员提供的结果生成的。我们在文本摘要和非事实性问答任务上进行了广泛的实验，涉及包括GPT-4在内的十一个LLMs。实验结果表明，使用单一LLM进行评估时存在偏见。此外，我们的PRE模型优于所有基线模型，证明了同行评审机制的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automatic+Large+Language+Model+Evaluation+via+Peer+Review)|0|
|[Empowering Private Tutoring by Chaining Large Language Models](https://doi.org/10.1145/3627673.3679665)|Yulin Chen, Ning Ding, HaiTao Zheng, Zhiyuan Liu, Maosong Sun, Bowen Zhou||Artificial intelligence has been applied in various aspects of onlineeducation to facilitate teaching and learning. However, few approaches has beenmade toward a complete AI-powered tutoring system. In this work, we explore thedevelopment of a full-fledged intelligent tutoring system powered bystate-of-the-art large language models (LLMs), covering automatic courseplanning and adjusting, tailored instruction, and flexible quiz evaluation. Tomake the system robust to prolonged interaction and cater to individualizededucation, the system is decomposed into three inter-connected coreprocesses-interaction, reflection, and reaction. Each process is implemented bychaining LLM-powered tools along with dynamically updated memory modules. Toolsare LLMs prompted to execute one specific task at a time, while memories aredata storage that gets updated during education process. Statistical resultsfrom learning logs demonstrate the effectiveness and mechanism of each toolusage. Subjective feedback from human users reveal the usability of eachfunction, and comparison with ablation systems further testify the benefits ofthe designed processes in long-term interaction.|人工智能已应用于在线教育的多个方面，以促进教学和学习。然而，目前尚缺乏一个完全由人工智能驱动的辅导系统。在本研究中，我们探索了利用最先进的大型语言模型（LLMs）开发一个全面的智能辅导系统，该系统涵盖了自动课程规划与调整、个性化指导以及灵活的测验评估。为使系统能够应对长时间的交互并适应个性化教育需求，我们将系统分解为三个相互连接的核心过程：交互、反思和反应。每个过程通过链接由LLM驱动的工具和动态更新的记忆模块来实现。工具是LLM根据提示一次执行一个特定任务，而记忆则是教育过程中更新的数据存储。学习日志的统计结果展示了每个工具使用的有效性和机制。来自用户的主观反馈揭示了每个功能的可用性，而与简化系统的比较进一步验证了设计过程中在长期交互中的优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Empowering+Private+Tutoring+by+Chaining+Large+Language+Models)|0|
|[Time is Not Enough: Time-Frequency based Explanation for Time-Series Black-Box Models](https://doi.org/10.1145/3627673.3679844)|Hyunseung Chung, Sumin Jo, Yeonsu Kwon, Edward Choi||Despite the massive attention given to time-series explanations due to their extensive applications, a notable limitation in existing approaches is their primary reliance on the time-domain. This overlooks the inherent characteristic of time-series data containing both time and frequency features. In this work, we present Spectral eXplanation (SpectralX), an XAI framework that provides time-frequency explanations for time-series black-box classifiers. This easily adaptable framework enables users to "plug-in" various perturbation-based XAI methods for any pre-trained time-series classification models to assess their impact on the explanation quality without having to modify the framework architecture. Additionally, we introduce Feature Importance Approximations (FIA), a new perturbation-based XAI method. These methods consist of feature insertion, deletion, and combination techniques to enhance computational efficiency and class-specific explanations in time-series classification tasks. We conduct extensive experiments in the generated synthetic dataset and various UCR Time-Series datasets to first compare the explanation performance of FIA and other existing perturbation-based XAI methods in both time-domain and time-frequency domain, and then show the superiority of our FIA in the time-frequency domain with the SpectralX framework. Finally, we conduct a user study to confirm the practicality of our FIA in SpectralX framework for class-specific time-frequency based time-series explanations. The source code is available in https://github.com/gustmd0121/Time_is_not_Enough|尽管由于广泛的应用，时间序列解释受到了极大的关注，但现有方法的一个显著局限性在于它们主要依赖于时域。这忽视了时间序列数据同时包含时间和频率特征的固有特性。在这项工作中，我们提出了Spectral eXplanation（SpectralX），这是一个为时间序列黑箱分类器提供时频解释的可解释人工智能（XAI）框架。这个易于适应的框架允许用户为任何预训练的时间序列分类模型“插入”各种基于扰动的XAI方法，以评估它们对解释质量的影响，而无需修改框架架构。此外，我们引入了特征重要性近似（Feature Importance Approximations, FIA），这是一种新的基于扰动的XAI方法。这些方法包括特征插入、删除和组合技术，以提高时间序列分类任务中的计算效率和类特定解释。我们在生成的合成数据集和多个UCR时间序列数据集上进行了广泛的实验，首先比较了FIA和其他现有基于扰动的XAI方法在时域和时频域中的解释性能，然后展示了我们的FIA在时频域中与SpectralX框架结合时的优越性。最后，我们进行了一项用户研究，以确认我们的FIA在SpectralX框架中对基于时频的时间序列解释的实用性。源代码可在https://github.com/gustmd0121/Time_is_not_Enough获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Time+is+Not+Enough:+Time-Frequency+based+Explanation+for+Time-Series+Black-Box+Models)|0|
|[PROSPECT: Learn MLPs on Graphs Robust against Adversarial Structure Attacks](https://doi.org/10.1145/3627673.3679857)|Bowen Deng, Jialong Chen, Yanming Hu, Zhiyong Xu, Chuan Chen, Tao Zhang|Sun Yat-sen University, GuangZhou, China|Current adversarial defense methods for GNNs exhibit critical limitations obstructing real-world application: 1) inadequate adaptability to graph heterophily, 2) absent generalizability to early GNNs like GraphSAGE used downstream, and 3) low inference scalability unacceptable for resource-constrained scenarios. To simultaneously address these challenges, we propose the first online GNN-MLP distillation framework PROSPECT, which merges the complementary knowledge of MLP and GNN and can thus learn GNN and MLP robust against adversarial structure attacks on both homophilic and heterophilic graphs. PROSPECT integrates seamlessly into GraphSAGE and achieves inference scalability exponentially higher than conventional GNNs. To mitigate potential convergence failure caused by inductive bias conflicts between the heterogeneous MLP and GNN, we propose the Quasi-Alternating Cosine Annealing (QACA) learning rate scheduler, inspired by our convergence analysis of the involved MLP. Experiments on homophilic and heterophilic graphs demonstrate the advantages of PROSPECT over current defenses and offline GNN-MLP distillation methods in terms of adversarial robustness and clean accuracy, the inference scalability of PROSPECT orders of magnitude higher than existing defenses, and the effectiveness of QACA.|当前的图神经网络（GNN）对抗防御方法存在严重的局限性，阻碍了其在实际应用中的推广：1）对图异质性的适应性不足；2）对早期GNN（如图SAGE）的通用性缺失，这些早期GNN通常用于下游任务；3）在资源受限场景下，推理的可扩展性较低，难以接受。为了同时解决这些问题，我们提出了首个在线GNN-MLP蒸馏框架PROSPECT，该框架融合了MLP和GNN的互补知识，从而能够学习到对同质图和异质图上的对抗结构攻击具有鲁棒性的GNN和MLP。PROSPECT可以无缝集成到GraphSAGE中，并且其推理可扩展性比传统GNN呈指数级提升。为了缓解异质MLP和GNN之间归纳偏差冲突可能导致的收敛失败问题，我们提出了准交替余弦退火（Quasi-Alternating Cosine Annealing，QACA）学习率调度器，这一调度器的设计灵感来自于我们对相关MLP收敛性的分析。在同质图和异质图上的实验表明，PROSPECT在对抗鲁棒性和干净数据准确性方面优于当前的防御方法和离线GNN-MLP蒸馏方法，其推理可扩展性比现有防御方法高出几个数量级，并且QACA的有效性得到了验证。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PROSPECT:+Learn+MLPs+on+Graphs+Robust+against+Adversarial+Structure+Attacks)|0|
|[ByGCN: Spatial Temporal Byroad-Aware Graph Convolution Network for Traffic Flow Prediction in Road Networks](https://doi.org/10.1145/3627673.3679690)|Tangpeng Dan, Xiao Pan, Bolong Zheng, Xiaofeng Meng|Renmin University of China, Beijing, China; Huazhong University of Science and Technology, Wuhan, China; Shijiazhuang Tiedao University, Shijiazhuang, China|As a fundamental technology in intelligent transportation systems (ITS), accurate traffic flow prediction has emerged as a critical challenge in real-time applications. How to fully utilize the traffic data, and capture the spatial temporal correlation are keys to improve the model's prediction ability. Numerous neural networks have been proposed to address this issue. However, most of these existing methods have the following two problems: 1) Lack of byroads information. Meaning that the existing methods do not consider the byroads in real-life traffic environments; 2) Lack of potential learning ability. Meaning that the existing methods suffer the non-similar forgetting and hard to gain the multi-hop correlation. To overcome these problems, we propose a novel Spatial Temporal Byroad-Aware Graph Convolution Network (ByGCN) in this paper. ByGCN consists of byroad identification and spatial temporal learning modules. In the first module, we design spatial temporal decoupling and graph diffusion blocks to identify the byroads and reconstruct them into the flow data. In the second module, with the help of spatial temporal attention and GCN, our module can capture the complex spatial temporal correlation. Experiments on four real-world traffic datasets demonstrate that ByGCN outperforms the state-of-the-art methods.|作为智能交通系统（ITS）中的基础技术，精确的交通流量预测已成为实时应用中的一个关键挑战。如何充分利用交通数据并捕捉其时空相关性，是提升模型预测能力的关键。已有多种神经网络被提出以解决这一问题。然而，大多数现有方法存在以下两个问题：1）缺乏支路信息，即现有方法未考虑现实交通环境中的支路；2）缺乏潜在学习能力，即现有方法存在非相似性遗忘问题，难以获取多跳相关性。为克服这些问题，本文提出了一种新颖的时空支路感知图卷积网络（ByGCN）。ByGCN由支路识别和时空学习两个模块组成。在第一个模块中，我们设计了时空解耦和图扩散块，用于识别支路并将其重构为流量数据。在第二个模块中，借助时空注意力机制和图卷积网络（GCN），我们的模块能够捕捉复杂的时空相关性。在四个真实世界的交通数据集上的实验表明，ByGCN优于当前最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ByGCN:+Spatial+Temporal+Byroad-Aware+Graph+Convolution+Network+for+Traffic+Flow+Prediction+in+Road+Networks)|0|
|[ALDF: An Adaptive Logical Decision Framework for Multimodal Named Entity Recognition](https://doi.org/10.1145/3627673.3679706)|Guohui Ding, Tianhao Jiang, Rui Zhou, Qian Gao|; Swinburne University of Technology, Melbourne, Australia; Shenyang Aerospace University, Shenyang, China|Multimodal Named Entity Recognition (MNER) aims to achieve more accurate entity recognition by incorporating image information to assist text, which is particularly significant on social media platforms. Current research disproportionately emphasizes enhancing text with images, overlooking that the core of the NER task remains textual. The modal differences between images and text inevitably introduces noise when incorporating image information. Therefore, when textual information is sufficient to independently complete the NER task, the introduction of image information is unnecessary. This paper proposes an Adaptive Logical Decision Framework (ALDF) capable of determining the sufficiency of textual information in NER tasks, deciding whether to introduce image information, avoiding unnecessary noise, and focusing more on information-scarce entities when introducing image information. Specifically, we designed a Logic Reasoning Neural Network (LRNN) that uses an evidence-theory-based method to simulate human decision-making logic and generate decision support degrees for deciding whether image information should participate in the recognition task. When incorporating image information, we utilize the generated decision support degrees to guide the multi-head self-attention mechanism, enhancing the model's focus on information-scarce entities. Additionally, we employ a modality-aware progressive training method that can use decision information in real-time during multimodal training and reduce information redundancy between modalities. Extensive experiments demonstrate that our model achieves state-of-the-art performance on popular public datasets.|多模态命名实体识别（MNER）旨在通过引入图像信息来辅助文本，从而实现更准确的实体识别，这在社交媒体平台上尤为重要。当前的研究过度强调利用图像增强文本，却忽视了命名实体识别任务的核心仍然是文本。图像与文本之间的模态差异在引入图像信息时不可避免地会带来噪声。因此，当文本信息足以独立完成命名实体识别任务时，引入图像信息就显得多余。本文提出了一种自适应逻辑决策框架（ALDF），该框架能够判断命名实体识别任务中文本信息的充分性，决定是否引入图像信息，从而避免不必要的噪声，并在引入图像信息时更多关注信息匮乏的实体。具体而言，我们设计了一种基于证据理论的逻辑推理神经网络（LRNN），用于模拟人类决策逻辑，生成决定图像信息是否参与识别任务的决策支持度。在引入图像信息时，我们利用生成的决策支持度来指导多头自注意力机制，增强模型对信息匮乏实体的关注。此外，我们还采用了一种模态感知的渐进式训练方法，该方法能够在多模态训练过程中实时利用决策信息，减少模态间的信息冗余。大量实验表明，我们的模型在流行的公共数据集上达到了最先进的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ALDF:+An+Adaptive+Logical+Decision+Framework+for+Multimodal+Named+Entity+Recognition)|0|
|[DRFormer: Multi-Scale Transformer Utilizing Diverse Receptive Fields for Long Time-Series Forecasting](https://doi.org/10.1145/3627673.3679724)|Ruixin Ding, Yuqi Chen, YuTing Lan, Wei Zhang||Long-term time series forecasting (LTSF) has been widely applied in finance, traffic prediction, and other domains. Recently, patch-based transformers have emerged as a promising approach, segmenting data into sub-level patches that serve as input tokens. However, existing methods mostly rely on predetermined patch lengths, necessitating expert knowledge and posing challenges in capturing diverse characteristics across various scales. Moreover, time series data exhibit diverse variations and fluctuations across different temporal scales, which traditional approaches struggle to model effectively. In this paper, we propose a dynamic tokenizer with a dynamic sparse learning algorithm to capture diverse receptive fields and sparse patterns of time series data. In order to build hierarchical receptive fields, we develop a multi-scale Transformer model, coupled with multi-scale sequence extraction, capable of capturing multi-resolution features. Additionally, we introduce a group-aware rotary position encoding technique to enhance intra- and inter-group position awareness among representations across different temporal scales. Our proposed model, named DRFormer, is evaluated on various real-world datasets, and experimental results demonstrate its superiority compared to existing methods. Our code is available at: https://github.com/ruixindingECNU/DRFormer.|长期时间序列预测（LTSF）在金融、交通预测等领域得到了广泛应用。近年来，基于分块的Transformer方法崭露头角，它将数据分割成子级别的分块，作为输入的标记。然而，现有方法大多依赖于预定的分块长度，这需要专家知识，并且在捕捉不同尺度上的多样特征时面临挑战。此外，时间序列数据在不同时间尺度上表现出多样的变化和波动，传统方法难以有效建模。本文提出了一种动态分词器，结合动态稀疏学习算法，以捕捉时间序列数据的多样感受野和稀疏模式。为了构建层次化的感受野，我们开发了一种多尺度Transformer模型，并结合多尺度序列提取，能够捕捉多分辨率特征。此外，我们引入了一种组感知的旋转位置编码技术，以增强不同时间尺度上表示之间的组内和组间位置感知。我们提出的模型名为DRFormer，在多个真实世界数据集上进行了评估，实验结果表明其优于现有方法。代码已公开，详见：https://github.com/ruixindingECNU/DRFormer。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DRFormer:+Multi-Scale+Transformer+Utilizing+Diverse+Receptive+Fields+for+Long+Time-Series+Forecasting)|0|
|[Effective Illicit Account Detection on Large Cryptocurrency MultiGraphs](https://doi.org/10.1145/3627673.3679707)|Zhihao Ding, Jieming Shi, Qing Li, Jiannong Cao||Cryptocurrencies are rapidly expanding and becoming vital in digital financial markets. However, the rise in cryptocurrency-related illicit activities has led to significant losses for users. To protect the security of these platforms, it is critical to identify illicit accounts effectively. Current detection methods mainly depend on feature engineering or are inadequate to leverage the complex information within cryptocurrency transaction networks, resulting in suboptimal performance. In this paper, we present DIAM, an effective method for detecting illicit accounts in cryptocurrency transaction networks modeled by directed multi-graphs with attributed edges. DIAM first features an Edge2Seq module that captures intrinsic transaction patterns from parallel edges by considering edge attributes and their directed sequences, to generate effective node representations. Then in DIAM, we design a multigraph Discrepancy (MGD) module with a tailored message passing mechanism to capture the discrepant features between normal and illicit nodes over the multigraph topology, assisted by an attention mechanism. DIAM integrates these techniques for end-to-end training to detect illicit accounts from legitimate ones. Extensive experiments, comparing against 15 existing solutions on 4 large cryptocurrency datasets of Bitcoin and Ethereum, demonstrate that DIAM consistently outperforms others in accurately identifying illicit accounts. For example, on a Bitcoin dataset with 20 million nodes and 203 million edges, DIAM attains an F1 score of 96.55 markedly surpassing the runner-up's score of 83.92 https://github.com/TommyDzh/DIAM.|加密货币正在迅速扩展并成为数字金融市场中的重要组成部分。然而，与加密货币相关的非法活动增加已导致用户遭受重大损失。为了保护这些平台的安全，有效识别非法账户至关重要。当前的检测方法主要依赖于特征工程，或未能充分利用加密货币交易网络中的复杂信息，导致性能不佳。本文提出了DIAM，一种在由带属性的有向多重图建模的加密货币交易网络中有效检测非法账户的方法。DIAM首先采用Edge2Seq模块，通过考虑边属性和它们的有向序列，从并行边中捕捉内在的交易模式，从而生成有效的节点表示。接着，在DIAM中，我们设计了一个多重图差异（MGD）模块，该模块采用定制的消息传递机制，借助注意力机制捕捉多重图拓扑结构上正常节点与非法节点之间的差异特征。DIAM整合了这些技术，实现了端到端的训练，以从合法账户中检测出非法账户。在4个大型比特币和以太坊数据集上与15种现有解决方案进行广泛比较的实验表明，DIAM在准确识别非法账户方面始终优于其他方法。例如，在一个包含2000万个节点和2.03亿条边的比特币数据集上，DIAM的F1得分达到96.55，显著超过了第二名83.92的得分。项目代码可在https://github.com/TommyDzh/DIAM获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Effective+Illicit+Account+Detection+on+Large+Cryptocurrency+MultiGraphs)|0|
|[SGOOD: Substructure-enhanced Graph-Level Out-of-Distribution Detection](https://doi.org/10.1145/3627673.3679710)|Zhihao Ding, Jieming Shi, Shiqi Shen, Xuequn Shang, Jiannong Cao, Zhipeng Wang, Zhi Gong||Graph-level representation learning is important in a wide range of applications. Existing graph-level models are generally built on i.i.d. assumption for both training and testing graphs. However, in an open world, models can encounter out-of-distribution (OOD) testing graphs that are from different distributions unknown during training. A trustworthy model should be able to detect OOD graphs to avoid unreliable predictions, while producing accurate in-distribution (ID) predictions. To achieve this, we present SGOOD, a novel graph-level OOD detection framework. We find that substructure differences commonly exist between ID and OOD graphs, and design SGOOD with a series of techniques to encode task-agnostic substructures for effective OOD detection. Specifically, we build a super graph of substructures for every graph, and develop a two-level graph encoding pipeline that works on both original graphs and super graphs to obtain substructure-enhanced graph representations. We then devise substructure-preserving graph augmentation techniques to further capture more substructure semantics of ID graphs. Extensive experiments against 11 competitors on numerous graph datasets demonstrate the superiority of SGOOD, often surpassing existing methods by a significant margin. The code is available at https://github.com/TommyDzh/SGOOD.|图级表示学习在众多应用中具有重要意义。现有的图级模型通常基于训练和测试图的独立同分布假设。然而，在开放世界中，模型可能会遇到来自训练期间未知分布的分布外（OOD）测试图。一个可信的模型应当能够检测出OOD图，以避免不可靠的预测，同时确保对分布内（ID）图的预测准确。为此，我们提出了SGOOD，一种新颖的图级OOD检测框架。我们发现，ID图与OOD图之间普遍存在子结构差异，因此设计了SGOOD，通过一系列技术对任务无关的子结构进行编码，以实现有效的OOD检测。具体而言，我们为每个图构建了一个子结构的超级图，并开发了一个双层图编码流程，同时作用于原始图和超级图，以获得增强子结构的图表示。随后，我们设计了子结构保留的图增强技术，以进一步捕捉ID图中更多的子结构语义。在众多图数据集上与11个竞争方法进行的大量实验表明，SGOOD具有显著优势，通常大幅超越现有方法。代码已公开，详见https://github.com/TommyDzh/SGOOD。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SGOOD:+Substructure-enhanced+Graph-Level+Out-of-Distribution+Detection)|0|
|[Boosting Certificate Robustness for Time Series Classification with Efficient Self-Ensemble](https://doi.org/10.1145/3627673.3679748)|Chang George Dong, Zhengyang David Li, Liangwei Nathan Zheng, Weitong Chen, Wei Emma Zhang||Recently, the issue of adversarial robustness in the time series domain has garnered significant attention. However, the available defense mechanisms remain limited, with adversarial training being the predominant approach, though it does not provide theoretical guarantees. Randomized Smoothing has emerged as a standout method due to its ability to certify a provable lower bound on robustness radius under ℓ_p-ball attacks. Recognizing its success, research in the time series domain has started focusing on these aspects. However, existing research predominantly focuses on time series forecasting, or under the non-ℓ_p robustness in statistic feature augmentation for time series classification (TSC). Our review found that Randomized Smoothing performs modestly in TSC, struggling to provide effective assurances on datasets with poor robustness. Therefore, we propose a self-ensemble method to enhance the lower bound of the probability confidence of predicted labels by reducing the variance of classification margins, thereby certifying a larger radius. This approach also addresses the computational overhead issue of Deep Ensemble (DE) while remaining competitive and, in some cases, outperforming it in terms of robustness. Both theoretical analysis and experimental results validate the effectiveness of our method, demonstrating superior performance in robustness testing compared to baseline approaches.|近期，时间序列领域的对抗鲁棒性问题引起了广泛关注。然而，现有的防御机制仍然有限，对抗训练虽然是最主要的方法，但并未提供理论上的保证。随机平滑（Randomized Smoothing）因其能够在ℓ_p球攻击下认证鲁棒半径的定理下界而脱颖而出。鉴于其在该领域的成功，时间序列领域的研究开始聚焦于这些方面。然而，现有研究主要集中在时间序列预测，或在时间序列分类（TSC）中针对非ℓ_p鲁棒性的统计特征增强。我们的回顾发现，随机平滑在TSC中的表现较为一般，难以在鲁棒性较差的数据集上提供有效的保证。因此，我们提出了一种自集成方法，通过减少分类边界的方差来增强预测标签概率置信度的下界，从而认证更大的半径。该方法还解决了深度集成（Deep Ensemble, DE）的计算开销问题，同时在鲁棒性方面保持竞争力，并在某些情况下超越了DE。理论分析和实验结果均验证了我们方法的有效性，表明在鲁棒性测试中相比基线方法具有更优的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Boosting+Certificate+Robustness+for+Time+Series+Classification+with+Efficient+Self-Ensemble)|0|
|[FZR: Enhancing Knowledge Transfer via Shared Factors Composition in Zero-Shot Relational Learning](https://doi.org/10.1145/3627673.3679770)|Zhijun Dong, Likang Wu, Kai Zhang, Ye Liu, Yanghai Zhang, Zhi Li, Hongke Zhao, Enhong Chen|; Tianjin University, Tianjin, China; College of Management and Economics, Tianjin University, Tianjin, China; Shenzhen International Graduate School, Tsinghua University, Shenzhen, Guangdong, China|Zero-Shot Relational Learning (ZSRL), strives to predict relations that have not been observed during training, presenting a considerable challenge in terms of model generalization. Existing ZSRL methods usually utilize the prior knowledge of labels (e.g., text description, ontological schema) to enable knowledge transfer by learned features. Nonetheless, these methods remain limited to calculating the surface features exhibited by relations, failing to fully explore their underlying driving factors. This leads to insufficient discrimination between the shared and distinctive inherent components among relations, which consequently impedes the cognitive understanding required for advanced reasoning. In our study, we aim to identify and utilize shared factors that widely exist in the prior knowledge of classes to learn enhanced semantic representations via shared factors composition, and develop our Factor-based ZSRL framework (FZR) with Generative Adversarial Networks (GANs) to bridge inequality between seen and unseen classes. FZR is designed to restructure the semantic space in such a way that it captures the essence of relation formation, thereby facilitating superior knowledge transfer in zero-shot scenarios. We conduct extensive experiments and evaluate our model on real-world datasets, and the results clearly demonstrate the effectiveness of the proposed model in zero-shot relational learning tasks.|零样本关系学习（Zero-Shot Relational Learning, ZSRL）旨在预测训练过程中未曾观察到的关系，这对模型的泛化能力提出了巨大挑战。现有的ZSRL方法通常利用标签的先验知识（例如文本描述、本体结构）通过学习到的特征来实现知识转移。然而，这些方法仅限于计算关系表现出的表面特征，未能充分探索其背后的驱动因素。这导致关系之间共享和独特固有成分的区分不足，进而阻碍了高级推理所需的认知理解。在我们的研究中，我们旨在识别并利用广泛存在于类别先验知识中的共享因子，通过共享因子组合来学习增强的语义表示，并开发基于因子的ZSRL框架（Factor-based ZSRL, FZR），该框架结合生成对抗网络（GANs）以弥合已见类别与未见类别之间的差距。FZR旨在重构语义空间，以捕捉关系形成的本质，从而在零样本场景中促进更优的知识转移。我们进行了广泛的实验，并在真实世界数据集上评估了我们的模型，结果清楚地证明了所提出的模型在零样本关系学习任务中的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FZR:+Enhancing+Knowledge+Transfer+via+Shared+Factors+Composition+in+Zero-Shot+Relational+Learning)|0|
|[Explainable Stock Price Movement Prediction using Contrastive Learning](https://doi.org/10.1145/3627673.3679544)|Kelvin Du, Rui Mao, Frank Xing, Erik Cambria|National University of Singapore, Singapore, Singapore; Nanyang Technological University, Singapore, Singapore|Predicting stock price movements is a high-stakes task that demands explainability for human decision-makers. A key shortcoming in current methods is treating sub-predictions independently, without learning from accumulated experiences. We propose a novel triplet network for contrastive learning to enhance the explainability of stock movement prediction by considering instances of "integrated textual information and quantitative indicators". We refer to the target past-l-day tweet-price time series as the "anchor instance". Each anchor instance is paired with a "positive instance" characterized by highly correlated return trends yet significant differences across the entire feature space, and a "negative instance" that exhibits similar return trends along with high proximity in the feature space. The model is designed with the objective of (1) minimizing the cross entropy loss between input logits and target, (2) minimizing the distance between the anchor instances and positive instances, and (3) maximizing the distance between the anchor instances and negative instances. Our framework's effectiveness is demonstrated through extensive testing, showing superior performance on stock prediction benchmarks.|预测股票价格走势是一项高风险的任务，需要为人类决策者提供可解释性。当前方法的一个主要缺陷是独立处理子预测，而没有从累积的经验中学习。我们提出了一种新颖的三重网络用于对比学习，通过考虑“综合文本信息和定量指标”的实例来增强股票走势预测的可解释性。我们将目标的过去l天的推文-价格时间序列称为“锚实例”。每个锚实例都与一个“正实例”配对，该正实例具有高度相关的回报趋势，但在整个特征空间上存在显著差异；同时与一个“负实例”配对，该负实例在回报趋势上相似，并且在特征空间中具有高度的接近性。该模型的设计目标包括：(1) 最小化输入逻辑与目标之间的交叉熵损失，(2) 最小化锚实例与正实例之间的距离，以及(3) 最大化锚实例与负实例之间的距离。我们的框架通过广泛的测试展示了其有效性，在股票预测基准上表现出优越的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explainable+Stock+Price+Movement+Prediction+using+Contrastive+Learning)|0|
|[Towards Uncertainty Quantification for Time Series Segmentation](https://doi.org/10.1145/3627673.3679652)|Erick Draayer, Huiping Cao|Computer Science, New Mexico State University, Las Cruces, NM, USA|Time Series Segmentation (TSS) is a data mining task widely used in many applications to generate a set of change points for a time series. Current TSS performance analyses focus on accuracy and, therefore, fail to fully evaluate the reliability and originality of a segmentation. We investigate using uncertainty quantification (UQ) to fully evaluate TSS performance. We propose UQ-TSS, a framework to quantify uncertainties surrounding TSS. UQ-TSS captures uncertainties from different sources in an integrative manner. It incorporates a novel TS augmentation algorithm to address inherent uncertainty in the data. It uses ensemble learning in a novel way to create samples and estimate the probability distributions of changepoint presence and locations. We demonstrate the ability of UQ-TSS to guide hyperparameter selection, refine segmentations, and determine an algorithm's suitability for segmenting without the need for ground truth. We validate these claims through extensive experimentation using several well-established TSS algorithms and datasets.|时间序列分割（TSS）是一项广泛应用于多个领域的数据挖掘任务，旨在为时间序列生成一组变化点。当前的TSS性能分析主要集中在准确性上，因此未能全面评估分割的可靠性和原创性。我们探讨了使用不确定性量化（UQ）来全面评估TSS性能的方法。为此，我们提出了UQ-TSS框架，用于量化围绕TSS的不确定性。UQ-TSS以综合方式捕捉来自不同来源的不确定性，并引入了一种新颖的时间序列增强算法来处理数据固有的不确定性。此外，它以创新的方式运用集成学习来生成样本，并估计变化点的存在概率及其位置分布。我们展示了UQ-TSS在指导超参数选择、优化分割结果以及在不依赖真实标签的情况下确定算法适用性方面的能力。通过使用多个广泛认可的TSS算法和数据集进行大量实验，我们验证了这些观点。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Uncertainty+Quantification+for+Time+Series+Segmentation)|0|
|[iMIRACLE: An Iterative Multi-View Graph Neural Network to Model Intercellular Gene Regulation From Spatial Transcriptomic Data](https://doi.org/10.1145/3627673.3679574)|Ziheng Duan, Siwei Xu, Cheyu Lee, Dylan Riffle, Jing Zhang|University of California, Irvine, Irvine, CA, USA.|Spatial transcriptomics has transformed genomic research by measuring spatially resolved gene expressions, allowing us to investigate how cells adapt to their microenvironment via modulating their expressed genes. This essential process usually starts from cell-cell communication (CCC) via ligand-receptor (LR) interaction, leading to regulatory changes within the receiver cell. However, few methods were developed to connect them to provide biological insights into intercellular regulation. To fill this gap, we propose iMiracle, an iterative multi-view graph neural network that models each cell's intercellular regulation with three key features. Firstly, iMiracle integrates inter- and intra-cellular networks to jointly estimate cell-type- and micro-environment-driven gene expressions. Optionally, it allows prior knowledge of intra-cellular networks as pre-structured masks to maintain biological relevance. Secondly, iMiracle employs iterative learning to overcome the sparsity of spatial transcriptomic data and gradually fill in the missing edges in the CCC network. Thirdly, iMiracle infers a cell-specific ligand-gene regulatory score based on the contributions of different LR pairs to interpret inter-cellular regulation. We applied iMiracle to nine simulated and eight real datasets from three sequencing platforms and demonstrated that iMiracle consistently outperformed ten methods in gene expression imputation and four methods in regulatory score inference. Lastly, we developed iMiracle as an open-source software and anticipate that it can be a powerful tool in decoding the complexities of inter-cellular transcriptional regulation.|空间转录组学通过测量空间分辨的基因表达，彻底改变了基因组研究，使我们能够研究细胞如何通过调节其表达的基因来适应其微环境。这一关键过程通常始于通过配体-受体（LR）相互作用的细胞间通信（CCC），从而在接收细胞内引发调控变化。然而，很少有方法被开发出来，将这些过程联系起来，以提供关于细胞间调控的生物学见解。为了填补这一空白，我们提出了iMiracle，一种迭代的多视图图神经网络，它通过三个关键特征来模拟每个细胞的细胞间调控。首先，iMiracle整合了细胞间和细胞内网络，以联合估计由细胞类型和微环境驱动的基因表达。可选地，它允许将细胞内网络的先验知识作为预结构化掩码，以保持生物学相关性。其次，iMiracle采用迭代学习来克服空间转录组数据的稀疏性，并逐渐填补CCC网络中的缺失边。第三，iMiracle基于不同LR对对细胞间调控的贡献，推断出细胞特异的配体-基因调控得分，以解释细胞间调控。我们将iMiracle应用于来自三个测序平台的九个模拟数据集和八个真实数据集，并证明iMiracle在基因表达插补和调控得分推断方面持续优于十种方法和四种方法。最后，我们将iMiracle开发为开源软件，并期待它成为解码细胞间转录调控复杂性的强大工具。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=iMIRACLE:+An+Iterative+Multi-View+Graph+Neural+Network+to+Model+Intercellular+Gene+Regulation+From+Spatial+Transcriptomic+Data)|0|
|[Low Carbon Footprint Training for 1D-CNNs with Temporal Max-Pooling](https://doi.org/10.1145/3627673.3679678)|Anandharaju Durai Raju, Ke Wang|School of Computing Science, Simon Fraser University, Vancouver, British Columbia, Canada|Training convolutional neural networks (CNNs) demands huge GPU memory consumption and training time, leading to increased carbon emissions, and impacting sustainability. In this paper, we propose HotConv, a low GPU memory and low carbon footprint learning strategy for training the class of 1D CNNs that have a temporal max-pooling layer. Such CNNs are widely used in various domains for learning large-sized inputs, including genomics and malware detection. HotConv reduces the GPU memory usage of such CNNs by harnessing the sparsity of relevant activations and gradients at the temporal max-pooling layer, which produces the same model as the full computation of activations and gradients, without trading-off model performance. Evaluations using the public benchmark BODMAS and VirusTotal datasets for malware detection with HotConv applied to the public MalConv network architecture show that the carbon footprint reduction using HotConv is superior to existing approaches. For instance, HotConv uses only 1/22 of the GPU memory used by MalConv2 - the memory-efficient variant of MalConv, while also consuming less training time than MalConv2. This is equivalent to reducing the carbon footprint up to 1/4 of that of MalConv2 without compromising performance.|训练卷积神经网络（CNNs）需要大量的GPU内存和训练时间，导致碳排放增加，影响可持续性。本文提出了HotConv，一种用于训练具有时间最大池化层的1D CNNs的低GPU内存和低碳足迹学习策略。这类CNNs广泛应用于多个领域，用于学习大型输入数据，包括基因组学和恶意软件检测。HotConv通过利用时间最大池化层中相关激活和梯度的稀疏性，减少了此类CNNs的GPU内存使用量，且生成的模型与完全计算激活和梯度所得到的模型相同，无需牺牲模型性能。在应用HotConv到公开的MalConv网络架构上，并使用公开基准BODMAS和VirusTotal数据集进行恶意软件检测的评估结果表明，HotConv在减少碳足迹方面优于现有方法。例如，HotConv仅使用MalConv2（MalConv的内存高效变体）所用GPU内存的1/22，同时训练时间也比MalConv2更少。这相当于在不降低性能的情况下，将碳足迹减少到MalConv2的1/4。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Low+Carbon+Footprint+Training+for+1D-CNNs+with+Temporal+Max-Pooling)|0|
|[Integrating Fair Representation Learning with Fairness Regularization for Intersectional Group Fairness](https://doi.org/10.1145/3627673.3679802)|David Quashigah Dzakpasu, Jixue Liu, Jiuyong Li, Lin Liu|UniSA STEM, University of South Australia, Adelaide, South Australia, Australia|In the pursuit of intersectional group fairness in machine learning models, significant attention has been directed towards fair representation learning methods. These methods aim to mitigate bias in training data by encoding data effectively while removing sensitive attribute information. However, existing fair representation learning methods often assume that decoupling sensitive attribute information from the latent representation will automatically lead to fairness on any downstream tasks learnt on the non-sensitive subspace of the latent representation. Nonetheless, biases can persist even when using representations devoid of sensitive attribute information. This is due to the learning algorithm's influence during downstream task training. In this paper, we propose a method dubbed FairReg which integrates fairness regularization with fair representation learning. This unified approach creates a more comprehensive and robust framework for ensuring intersectional group fairness in machine learning models. Empirical evaluations conducted on two real-world depression prediction datasets demonstrate the effectiveness of our method in improving intersectional group fairness compared to existing approaches.|在追求机器学习模型中的交叉群体公平性过程中，公平表示学习方法受到了广泛关注。这些方法旨在通过有效编码数据并移除敏感属性信息来减少训练数据中的偏差。然而，现有的公平表示学习方法通常假设，将敏感属性信息从潜在表示中解耦会自动导致在潜在表示的非敏感子空间上学习的任何下游任务的公平性。尽管如此，即使在使用不包含敏感属性信息的表示时，偏差也可能持续存在。这是由于学习算法在下游任务训练过程中的影响。在本文中，我们提出了一种名为FairReg的方法，该方法将公平正则化与公平表示学习相结合。这种统一的方法为确保机器学习模型中的交叉群体公平性创建了一个更全面和稳健的框架。在两个真实世界抑郁症预测数据集上进行的实证评估表明，与现有方法相比，我们的方法在提高交叉群体公平性方面具有显著效果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Integrating+Fair+Representation+Learning+with+Fairness+Regularization+for+Intersectional+Group+Fairness)|0|
|[Probabilistic Path Integration with Mixture of Baseline Distributions](https://doi.org/10.1145/3627673.3679641)|Yehonatan Elisha, Oren Barkan, Noam Koenigstein|The Open University, Tel Aviv, Israel; Tel-Aviv University, Tel Aviv, Israel|Path integration methods generate attributions by integrating along a trajectory from a baseline to the input. These techniques have demonstrated considerable effectiveness in the field of explainability research. While multiple types of baselines for the path integration process have been explored in the literature, there is no consensus on the ultimate one. This work examines the performance of different baseline distributions on explainability metrics and proposes a probabilistic path integration approach where the baseline distribution is modeled as a mixture of distributions, learned for each combination of model architecture and explanation metric. Extensive evaluations on various model architectures show that our method outperforms state-of-the-art explanation methods across multiple metrics.|路径积分方法通过在从基线到输入的轨迹上进行积分来生成归因。这些技术在可解释性研究领域已展现出显著的成效。尽管文献中已探讨了多种用于路径积分过程的基线类型，但对于最佳基线尚未达成共识。本研究考察了不同基线分布在可解释性指标上的表现，并提出了一种概率路径积分方法，其中基线分布被建模为分布的混合体，并针对每种模型架构与解释指标的组合进行学习。对各种模型架构的广泛评估表明，我们的方法在多项指标上均优于现有的最先进解释方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Probabilistic+Path+Integration+with+Mixture+of+Baseline+Distributions)|0|
|[A Spatio-Temporal Diffusion Model for Missing and Real-Time Financial Data Inference](https://doi.org/10.1145/3627673.3679806)|Yupeng Fang, Ruirui Liu, Huichou Huang, Peilin Zhao, Qingyao Wu|South China University of Technology, Guangzhou, China; Tencent AI Lab, Shenzhen, China; Brunel University London & King's College London, London, United Kingdom; City University of Hong Kong & Bayescien Technologies, Hong Kong, China; South China University of Technology & Peng Cheng Laboratory, Guangzhou, China|Missing values and unreleased figures are common but highly important for backtesting and real-time analysis in the financial industry, yet underexploited in the existing literature. In this paper, we focus on the issue of empirical asset pricing, where the cross-section of future asset returns is a function of lagged firm characteristics that vary in time frequencies and missing ratios. Most of the existing imputation methods cannot fully capture the complex and evolving spatio-temporal relations among firm-level characteristics. In particular, these methods fail to explicitly consider the spatial relations and feature structure in the stock network where we have to process granular data of thousands of stocks and hundreds of characteristics for each stock. To address these challenges, we propose a spatio-temporal diffusion model (STDM) that gradually recovers the masked financial data conditioning on high-dimensional stock-and-characteristics historical data. We propose characteristic-specific projection to construct characteristic-level features at both ends of the STDM, meanwhile maintaining firm-level features in the middle of the STDM to largely reduce the computational memory. Moreover, along with the temporal attention, we design a spatial graph convolutional network, making it computationally efficient and effective to learn time-varying spatio-temporal interdependence across firms. We further employ an implicit sampler that greatly accelerates the inference procedure so that the STDM is able to produce high-quality point and density estimates of missing and real-time firm characteristics within a few steps. We evaluate our model on the most comprehensive open-source dataset 'OSAP' and generate state-of-the-art performance in extensive experiments.|在金融行业中，缺失值和未公布的数据是常见但极其重要的，尤其是在回溯测试和实时分析中，然而现有文献对此研究不足。本文聚焦于实证资产定价问题，其中未来资产收益的横截面是滞后公司特征的函数，这些特征在时间频率和缺失比例上存在差异。现有的多数插补方法无法充分捕捉公司层面特征之间复杂且不断演化的时空关系。特别是，这些方法未能明确考虑股票网络中的空间关系和特征结构，而我们必须处理数千只股票和每只股票数百个特征的细粒度数据。为解决这些挑战，我们提出了一种时空扩散模型（STDM），该模型基于高维股票和特征历史数据逐步恢复被掩盖的财务数据。我们提出了特征特定的投影方法，在STDM的两端构建特征层面的特征，同时在STDM中间保持公司层面的特征，从而大幅减少计算内存。此外，结合时间注意力机制，我们设计了一个空间图卷积网络，使其在计算上高效且有效地学习跨公司的时间变化时空相互依赖性。我们还采用了一种隐式采样器，显著加速了推理过程，使STDM能够在几步之内生成缺失和实时公司特征的高质量点估计和密度估计。我们在最全面的开源数据集“OSAP”上评估了我们的模型，并在广泛的实验中取得了最先进的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Spatio-Temporal+Diffusion+Model+for+Missing+and+Real-Time+Financial+Data+Inference)|0|
|[PARs: Predicate-based Association Rules for Efficient and Accurate Anomaly Explanation](https://doi.org/10.1145/3627673.3679625)|Cheng Feng||While new and effective methods for anomaly detection are frequently introduced, many studies prioritize the detection task without considering the need for explainability. Yet, in real-world applications, anomaly explanation, which aims to provide explanation of why specific data instances are identified as anomalies, is an equally important task. In this work, we present a novel approach for efficient and accurate model-agnostic anomaly explanation for tabular data using Predicate-based Association Rules (PARs). PARs can provide intuitive explanations not only about which features of the anomaly instance are abnormal, but also the reasons behind their abnormality. Our user study indicates that the anomaly explanation form of PARs is better comprehended and preferred by regular users of anomaly detection systems as compared to existing model-agnostic explanation options. Furthermore, we conduct extensive experiments on various benchmark datasets, demonstrating that PARs compare favorably to state-of-the-art model-agnostic methods in terms of computing efficiency and explanation accuracy on anomaly explanation tasks. The code for PARs tool is available at https://github.com/NSIBF/PARs-EXAD.|尽管新的有效异常检测方法不断被引入，但许多研究优先考虑检测任务，而忽视了可解释性的需求。然而，在实际应用中，异常解释（旨在解释为什么特定数据实例被识别为异常）同样是一项重要的任务。在本研究中，我们提出了一种新颖的方法，利用基于谓词的关联规则（Predicate-based Association Rules, PARs）对表格数据进行高效且准确的模型无关异常解释。PARs不仅能够直观地解释异常实例的哪些特征异常，还能解释这些特征异常的原因。我们的用户研究表明，与现有的模型无关解释选项相比，PARs的异常解释形式更容易被异常检测系统的普通用户理解并受到青睐。此外，我们在多个基准数据集上进行了广泛的实验，结果表明PARs在计算效率和异常解释任务的解释准确性方面优于最先进的模型无关方法。PARs工具的代码可在https://github.com/NSIBF/PARs-EXAD获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PARs:+Predicate-based+Association+Rules+for+Efficient+and+Accurate+Anomaly+Explanation)|0|
|[SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model](https://doi.org/10.1145/3627673.3679760)|Lingyue Fu, Hao Guan, Kounianhua Du, Jianghao Lin, Wei Xia, Weinan Zhang, Ruiming Tang, Yasheng Wang, Yong Yu||Knowledge Tracing (KT) aims to determine whether students will respond correctly to the next question, which is a crucial task in intelligent tutoring systems (ITS). In educational KT scenarios, transductive ID-based methods often face severe data sparsity and cold start problems, where interactions between individual students and questions are sparse, and new questions and concepts consistently arrive in the database. In addition, existing KT models only implicitly consider the correlation between concepts and questions, lacking direct modeling of the more complex relationships in the heterogeneous graph of concepts and questions. In this paper, we propose a Structure-aware Inductive Knowledge Tracing model with large language model (dubbed SINKT), which, for the first time, introduces large language models (LLMs) and realizes inductive knowledge tracing. Firstly, SINKT utilizes LLMs to introduce structural relationships between concepts and constructs a heterogeneous graph for concepts and questions. Secondly, by encoding concepts and questions with LLMs, SINKT incorporates semantic information to aid prediction. Finally, SINKT predicts the student's response to the target question by interacting with the student's knowledge state and the question representation. Experiments on four real-world datasets demonstrate that SINKT achieves state-of-the-art performance among 12 existing transductive KT models. Additionally, we explore the performance of SINKT on the inductive KT task and provide insights into various modules.|知识追踪（Knowledge Tracing, KT）旨在判断学生是否能够正确回答下一个问题，这是智能辅导系统（Intelligent Tutoring Systems, ITS）中的一项关键任务。在教育知识追踪场景中，基于ID的转导式方法常常面临严重的数据稀疏性和冷启动问题，即个别学生与问题之间的交互稀疏，并且新问题和概念不断涌入数据库。此外，现有的知识追踪模型仅隐式地考虑了概念与问题之间的关联，缺乏对概念与问题异质图中更复杂关系的直接建模。本文提出了一种基于大语言模型的结构感知归纳知识追踪模型（Structure-aware Inductive Knowledge Tracing model with large language model, SINKT），首次引入了大语言模型（LLMs）并实现了归纳知识追踪。首先，SINKT利用大语言模型引入概念之间的结构关系，并构建了概念与问题的异质图。其次，通过使用大语言模型对概念和问题进行编码，SINKT融入了语义信息以辅助预测。最后，SINKT通过与学生知识状态和问题表示进行交互，预测学生对目标问题的回答。在四个真实世界数据集上的实验表明，SINKT在12个现有的转导式知识追踪模型中达到了最先进的性能。此外，我们还探讨了SINKT在归纳知识追踪任务中的表现，并对各个模块进行了深入分析。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SINKT:+A+Structure-Aware+Inductive+Knowledge+Tracing+Model+with+Large+Language+Model)|0|
|[Graph Local Homophily Network for Anomaly Detection](https://doi.org/10.1145/3627673.3679785)|Ronghui Guo, Minghui Zou, Sai Zhang, Xiaowang Zhang, Zhizhi Yu, Zhiyong Feng|College of Intelligence and Computing, Tianjin University, Tianjin, China|In graph anomaly detection (GAD), the fact that anomalous nodes usually exhibit high heterophily, while most Graph Neural Networks (GNNs) have homophily assumptions, leads to poor performance. Many studies have attempted to solve this problem by employing a set of graph filters covering various frequencies. Their ultimate goal is to design the most appropriate spectral filter to capture the complex signals generated by normals and anomalies. The critical aspect lies in the fusion of information from filters with different frequency response functions. However, existing methods lack a clear indicator to guide the fusion of information at different frequencies. In this paper, we find that local homophily is a valuable metric for assessing the weights of high- and low-frequency information at the node level, and explicitly point out that the accuracy of local homophily is positively correlated with the accuracy of anomaly detection. Moreover, we unveil the phenomenon of camouflage in anomalous, wherein these nodes disguise themselves by making their features resemble those of surrounding normals. Based on this investigation, we propose the Graph Local Homophily Network for Anomaly Detection (GLHAD). Specifically, we first identify the local homophily of the nodes in the graph under the supervision of the labeled nodes, where two contrasting paradigms are employed to resist the camouflage of anomalies. Then, the local homophily-based combination module combines low- and high-frequency signals based on the predicted local homophily. Eventually, the node representations of different layers are aggregated to make finally predictions.Comprehensive experiments on four anomaly detection datasets show that GLHAD outperforms other state-of-the-art baselines.|在图异常检测（Graph Anomaly Detection, GAD）中，异常节点通常表现出高度的异质性，而大多数图神经网络（Graph Neural Networks, GNNs）基于同质性假设，这导致了性能不佳。许多研究尝试通过使用一组覆盖多种频率的图滤波器来解决这一问题。它们的最终目标是设计最合适的谱滤波器，以捕捉正常节点和异常节点生成的复杂信号。关键之处在于如何融合来自具有不同频率响应函数的滤波器的信息。然而，现有方法缺乏明确的指标来指导不同频率信息的融合。

在本文中，我们发现局部同质性是一个有价值的指标，可用于在节点级别评估高频和低频信息的权重，并明确指出局部同质性的准确性与异常检测的准确性呈正相关。此外，我们揭示了异常节点中的伪装现象，即这些节点通过使其特征与周围正常节点相似来伪装自己。基于这一研究，我们提出了基于图局部同质性的异常检测网络（Graph Local Homophily Network for Anomaly Detection, GLHAD）。具体来说，我们首先在标记节点的监督下识别图中节点的局部同质性，其中采用两种对比范式来抵抗异常节点的伪装。然后，基于局部同质性的组合模块根据预测的局部同质性结合低频和高频信号。最终，聚合不同层的节点表示以做出最终预测。在四个异常检测数据集上的综合实验表明，GLHAD优于其他最先进的基线方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Local+Homophily+Network+for+Anomaly+Detection)|0|
|[Look Globally and Reason: Two-stage Path Reasoning over Sparse Knowledge Graphs](https://doi.org/10.1145/3627673.3679845)|Saiping Guan, Jiyao Wei, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng||Sparse Knowledge Graphs (KGs), frequently encountered in real-world applications, contain fewer facts in the form of (head entity, relation, tail entity) compared to more populated KGs. The sparse KG completion task, which reasons answers for given queries in the form of (head entity, relation, ?) for sparse KGs, is particularly challenging due to the necessity of reasoning missing facts based on limited facts. Path-based models, known for excellent explainability, are often employed for this task. However, existing path-based models typically rely on external models to fill in missing facts and subsequently perform path reasoning. This approach introduces unexplainable factors or necessitates meticulous rule design. In light of this, this paper proposes an alternative approach by looking inward instead of seeking external assistance. We introduce a two-stage path reasoning model called LoGRe (Look Globally and Reason) over sparse KGs. LoGRe constructs a relation-path reasoning schema by globally analyzing the training data to alleviate the sparseness problem. Based on this schema, LoGRe then aggregates paths to reason out answers. Experimental results on five benchmark sparse KG datasets demonstrate the effectiveness of the proposed LoGRe model.|稀疏知识图谱（KGs）在现实应用中经常出现，与更为密集的KGs相比，它们包含的（头实体，关系，尾实体）形式的事实较少。稀疏KG补全任务，即在稀疏KGs中推理出给定查询（头实体，关系，？）的答案，由于需要基于有限的事实推理出缺失的事实，因此特别具有挑战性。基于路径的模型因其出色的可解释性而常被用于此任务。然而，现有的基于路径的模型通常依赖外部模型来填补缺失的事实，然后进行路径推理。这种方法引入了不可解释的因素或需要精细的规则设计。鉴于此，本文提出了一种替代方法，即向内寻求解决方案而非依赖外部帮助。我们引入了一种名为LoGRe（全局观察与推理）的两阶段路径推理模型，用于稀疏KGs。LoGRe通过全局分析训练数据构建关系-路径推理模式，以缓解稀疏性问题。基于此模式，LoGRe随后聚合路径以推理出答案。在五个基准稀疏KG数据集上的实验结果证明了所提出的LoGRe模型的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Look+Globally+and+Reason:+Two-stage+Path+Reasoning+over+Sparse+Knowledge+Graphs)|0|
|[Tiled Bit Networks: Sub-Bit Neural Network Compression Through Reuse of Learnable Binary Vectors](https://doi.org/10.1145/3627673.3679603)|Matt Gorbett, Hossein Shirazi, Indrakshi Ray||Binary Neural Networks (BNNs) enable efficient deep learning by saving on storage and computational costs. However, as the size of neural networks continues to grow, meeting computational requirements remains a challenge. In this work, we propose a new form of quantization to tile neural network layers with sequences of bits to achieve sub-bit compression of binary-weighted neural networks. The method learns binary vectors (i.e. tiles) to populate each layer of a model via aggregation and reshaping operations. During inference, the method reuses a single tile per layer to represent the full tensor. We employ the approach to both fully-connected and convolutional layers, which make up the breadth of space in most neural architectures. Empirically, the approach achieves near fullprecision performance on a diverse range of architectures (CNNs, Transformers, MLPs) and tasks (classification, segmentation, and time series forecasting) with up to an 8x reduction in size compared to binary-weighted models. We provide two implementations for Tiled Bit Networks: 1) we deploy the model to a microcontroller to assess its feasibility in resource-constrained environments, and 2) a GPU-compatible inference kernel to facilitate the reuse of a single tile per layer in memory.|二进制神经网络（BNNs）通过节省存储和计算成本，实现了高效的深度学习。然而，随着神经网络规模的持续增长，满足计算需求仍然是一个挑战。在本研究中，我们提出了一种新的量化形式，通过将神经网络层划分为比特序列，以实现二值加权神经网络的亚比特压缩。该方法通过学习二进制向量（即“瓦片”），并通过聚合和重塑操作来填充模型的每一层。在推理过程中，该方法每层复用单个瓦片来表示完整的张量。我们将该方法应用于全连接层和卷积层，这两者在大多数神经网络架构中占据了广泛的空间。实验表明，该方法在多种架构（如卷积神经网络、Transformer、多层感知机）和任务（如分类、分割和时间序列预测）上实现了接近全精度的性能，同时与二值加权模型相比，模型大小最多减少了8倍。我们为“瓦片比特网络”提供了两种实现方式：1）我们将模型部署到微控制器上，以评估其在资源受限环境中的可行性；2）我们提供了一个与GPU兼容的推理内核，以促进在内存中每层复用单个瓦片。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tiled+Bit+Networks:+Sub-Bit+Neural+Network+Compression+Through+Reuse+of+Learnable+Binary+Vectors)|0|
|[MSTEM: Masked Spatiotemporal Event Series Modeling for Urban Undisciplined Events Forecasting](https://doi.org/10.1145/3627673.3679810)|Zehao Gu, Shiyang Zhou, Yun Xiong, Yang Luo, Hongrun Ren, Qiang Wang, Xiaofeng Gao, Philip S. Yu|; University of Illinois at Chicago, Chicgao, IL, USA; Shanghai Center for Meteorological Disaster Prevention Technology, Shanghai, China|Urban undisciplined events (UUE) are of increasing concern to urban officials because they reduce the quality of life and cause societal disorder. How to accurately predict future occurrences is a key point in preventing these events. However, existing supervised methods struggle to perform well on sparse UUEs while self-supervised MAE-based methods adopt a traditional random masking strategy which leads to limited performance on UUE forecasting. Fortunately, we have designed an innovative spatiotemporal masking strategy and its corresponding pre-training task called Masked Spatio-Temporal Event Series Modeling (MSTEM). Through Cluster-assisted region masking, MSTEM efficiently distributes masked regions evenly among different clusters, enhancing the model's ability to capture spatial correlation and heterogeneity while addressing sparse region distribution of UUEs. Frequency-enhanced patch masking helps the model to sufficiently extract the temporal features of UUEs by reconstructing multiple views. Additionally, we propose future merge and cluster label modeling to enhance the extraction of spatiotemporal dependencies, thereby improving the performance of MSTEM on downstream prediction tasks. Experimental evaluations on four real-world datasets including crimes and disorderly conduct show that our masked autoencoder with MSTEM outperforms most of the state-of-the-art baselines.|城市无序事件（Urban Undisciplined Events, UUE）日益引起城市管理者的关注，因为这些事件降低了生活质量并引发社会混乱。如何准确预测未来事件的发生是预防这些事件的关键。然而，现有的监督学习方法在处理稀疏的UUE时表现不佳，而基于自监督的MAE（Masked Autoencoder）方法采用传统的随机掩码策略，导致在UUE预测中的性能有限。幸运的是，我们设计了一种创新的时空掩码策略及其相应的预训练任务，称为掩码时空事件序列建模（Masked Spatio-Temporal Event Series Modeling, MSTEM）。通过聚类辅助的区域掩码，MSTEM能够将掩码区域均匀分布在不同的聚类中，增强模型捕捉空间相关性和异质性的能力，同时解决UUE区域分布稀疏的问题。频率增强的补丁掩码通过重建多视图，帮助模型充分提取UUE的时间特征。此外，我们提出了未来合并和聚类标签建模，以增强时空依赖关系的提取，从而提升MSTEM在下游预测任务中的性能。在包括犯罪和扰乱秩序在内的四个真实世界数据集上的实验评估表明，我们结合MSTEM的掩码自编码器在大多数情况下优于现有的最先进基线方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MSTEM:+Masked+Spatiotemporal+Event+Series+Modeling+for+Urban+Undisciplined+Events+Forecasting)|0|
|[Multi-Modal Sarcasm Detection via Graph Convolutional Network and Dynamic Network](https://doi.org/10.1145/3627673.3679703)|Jiaqi Hao, Junfeng Zhao, Zhigang Wang|College of Computer Science, Inner Mongolia University, Hohhot, China|Sarcasm is a form of language used to convey implicit information contradicting the literal meaning of words, often observed on online social media platforms. Accurately detecting satirical or ironic expressions could significantly enhance sentiment analysis and opinion mining. For multi-modal data, capturing both inter- and intra-modal incongruities is crucial for this task. Recently, graph-based approaches to modeling incongruous features bet-ween image and text have made significant progress in this task. However, these methods rely on static networks to capture incongruous features, which makes them inflexible in adapting to diverse groups of text and image, or neglect important information due to inadequate use of text and image. To address these limitations, we propose a multi-modal sarcasm detection model based on the combination of Graph Convolutional Network and Dynamic Network. The graph convolutional network learns the incongruity of the three modal graphs and makes full use of the object-level information. The dynamic network dynamically captures the incongruity between the global-level image and the text and can flexibly adapt to different image and related text. At the same time, we generate augmented text to better utilize the text information. Extensive experiments demonstrate that our proposed method performs favorably against state-of-the-art approaches.|讽刺是一种用于传达与字面意义相矛盾的隐含信息的语言形式，在在线社交媒体平台上尤为常见。准确检测讽刺或反讽表达可以显著增强情感分析和意见挖掘的效果。对于多模态数据而言，捕捉模态间和模态内的不一致性对于完成这一任务至关重要。近年来，基于图的方法在建模图像与文本之间的不一致特征方面取得了显著进展。然而，这些方法依赖于静态网络来捕捉不一致特征，这使得它们在适应不同文本和图像组时缺乏灵活性，或者由于未能充分利用文本和图像信息而忽略了重要内容。为了解决这些局限性，我们提出了一种基于图卷积网络（Graph Convolutional Network, GCN）和动态网络（Dynamic Network）相结合的多模态讽刺检测模型。图卷积网络通过学习三个模态图的不一致性，充分利用对象级别的信息；而动态网络则动态捕捉全局级别的图像与文本之间的不一致性，并能够灵活适应不同的图像及相关文本。同时，我们通过生成增强文本来更好地利用文本信息。大量实验表明，我们提出的方法在性能上优于当前最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Modal+Sarcasm+Detection+via+Graph+Convolutional+Network+and+Dynamic+Network)|0|
|[On the Sensitivity of Individual Fairness: Measures and Robust Algorithms](https://doi.org/10.1145/3627673.3679721)|Xinyu He, Jian Kang, Ruizhong Qiu, Fei Wang, Jose Sepulveda, Hanghang Tong|Amazon, Sunnyvale, CA, USA; University of Illinois at Urbana-Champaign, Champaign, IL, USA; University of Rochester, Rochester, NY, USA; Amazon, Seattle, WA, USA|Algorithmic fairness has been receiving increasing attention in recent years. Among others, individual fairness, with its root in the dictionary definition of fairness, offers a fine-grained fairness notion. At the algorithmic level, individual fairness can often be operationalized as a convex regularization term with respect to a similarity matrix. Appealing as it might be, a notorious challenge of individual fairness lies in how to find appropriate distance or similarity measure, which largely remains open to date. Consequently, the similarity or distance measure used in almost any individually fair algorithm is likely to be imperfect due to various reasons such as imprecise prior/domain knowledge, noise, or even adversaries. In this paper, we take an important step towards resolving this fundamental challenge and ask: how sensitive is the individually fair learning algorithm with respect to the given similarities? How can we make the learning results robust with respect to the imperfection of the given similarity measure? First (Soul-M), we develop a sensitivity measure to characterize how the learning outcomes of an individually fair learning algorithm change in response to the change of the given similarity measure. Second (Soul-A ), based on the proposed sensitive measure, we further develop a robust individually fair algorithm by adversarial learning that optimizes the similarity matrix to defend against L_∞ attack. A unique advantage of our sensitivity measure and robust algorithm lies in that they are applicable to a broad range of learning models as long as the objective function is twice differentiable. We conduct extensive experiments to demonstrate the efficacy of our methods.|近年来，算法公平性受到了越来越多的关注。其中，个体公平性源于词典中对公平性的定义，提供了一种细粒度的公平性概念。在算法层面，个体公平性通常可以操作化为关于相似度矩阵的凸正则化项。尽管个体公平性具有吸引力，但其面临的一个著名挑战在于如何找到合适的距离或相似性度量，这一问题至今仍未得到充分解决。因此，由于各种原因（如不精确的先验/领域知识、噪声甚至敌对行为），几乎任何个体公平算法中使用的相似性或距离度量都可能存在缺陷。本文在解决这一基础性挑战方面迈出了重要一步，并提出以下问题：个体公平学习算法对给定相似性的敏感程度如何？我们如何使学习结果在面对给定相似性度量的不完美时保持稳健？首先（Soul-M），我们开发了一种敏感性度量，用于描述个体公平学习算法的学习结果如何随着给定相似性度量的变化而变化。其次（Soul-A），基于所提出的敏感性度量，我们进一步开发了一种通过对抗学习优化的稳健个体公平算法，该算法通过优化相似性矩阵来防御L_∞攻击。我们的敏感性度量和稳健算法的独特优势在于，只要目标函数是二次可微的，它们就适用于广泛的学习模型。我们进行了大量实验，以验证我们方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+the+Sensitivity+of+Individual+Fairness:+Measures+and+Robust+Algorithms)|0|
|[NC2D: Novel Class Discovery for Node Classification](https://doi.org/10.1145/3627673.3679779)|Yue Hou, Xueyuan Chen, He Zhu, Ruomei Liu, Bowen Shi, Jiaheng Liu, Junran Wu, Ke Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NC2D:+Novel+Class+Discovery+for+Node+Classification)|0|
|[Accurate Neural Network Option Pricing Methods with Control Variate Techniques and Data Synthesis/Cleaning with Financial Rationality](https://doi.org/10.1145/3627673.3679530)|ChiaWei Hsu, TianShyr Dai, ChuanJu Wang, YingPing Chen|; Department of Computer Science, National Yang Ming Chiao Tung University, HsinChu, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan|This paper enhances option pricing accuracy by incorporating financial expertise into a neural network (NN) design and optimizing data sample quality through cleaning and synthesis. Instead of directly estimating option values (OVs) with NNs, we leverage the concept of control variate by decomposing OVs as time values (TVs) estimated by NNs, plus the analytically solvable intrinsic values (IVs). TV surface can be decomposed into two scenarios with very different properties, and we design two NNs according to our derived no-arbitrage constraints for these two scenarios. To alleviate learning inaccuracy due to the kink of the TV surface along the scenario boundary, we synthesize training samples based on our derived constraints to smoothly extend the surface for each scenario. On the other hand, irrational option quotes commonly found in illiquid markets incur uneven surfaces, significantly deteriorating NN predictability. We develop a learnable data-cleaning method to remove potentially irrational quotes spotted by no-arbitrage constraints properly. Besides, unnecessary data syntheses proposed in previous literature can also be removed by incorporating corresponding constraints into our NN to enhance training efficiency. Comprehensive experiments on liquid S&P 500 and illiquid TAIEX option markets examine the superiority of our approach.|本文通过将金融专业知识融入神经网络（NN）设计，并通过数据清洗和合成优化数据样本质量，从而提高了期权定价的准确性。我们并未直接使用神经网络估计期权价值（OVs），而是利用控制变量的概念，将期权价值分解为由神经网络估计的时间价值（TVs）加上可解析求解的内在价值（IVs）。时间价值曲面可以分解为具有截然不同属性的两种情景，我们根据推导出的无套利约束为这两种情景设计了两个神经网络。为了缓解由于时间价值曲面在情景边界处的“折痕”导致的学习不准确性，我们基于推导的约束条件合成了训练样本，以平滑地扩展每种情景的曲面。另一方面，在流动性较差的市场中常见的非理性期权报价会导致曲面不平整，从而显著降低神经网络的预测能力。我们开发了一种可学习的数据清洗方法，以适当地移除由无套利约束识别的潜在非理性报价。此外，通过将相应的约束条件融入我们的神经网络，还可以移除先前文献中提出的不必要的数据合成，从而提高训练效率。通过对流动性较高的标普500期权市场和流动性较低的台指期权市场的全面实验，验证了我们方法的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Accurate+Neural+Network+Option+Pricing+Methods+with+Control+Variate+Techniques+and+Data+Synthesis/Cleaning+with+Financial+Rationality)|0|
|[PIECE: Protagonist Identification and Event Chronology Extraction for Enhanced Timeline Summarization](https://doi.org/10.1145/3627673.3679723)|TzHuan Hsu, LiHsuan Chin, YenHao Huang, YiShin Chen|CreatorDB, Taipei, Taiwan; National Tsing Hua University, Hsinchu, Taiwan; Taiwan Semiconductor Manufacturing Company, Hsinchu, Taiwan|Timeline summarization involves condensing events from news articles to illustrate the temporal development of a specific topic. Traditional methods often extract events based on the number of related reports but tend to overlook the movement of protagonists, the leading actors participating in events that shape the progression of the topic. This oversight can result in the extraction of sensationalized events unrelated to the topic's progression, distracting readers from tracking the topic's development. To address this limitation, we propose a novel strategy that identifies protagonists through dependency relations and tracks changes in the context surrounding them over time using a multi-faceted temporal graph. This temporal graph is a sequence of graphs that effectively captures information progression and shifts over time. Our approach aims to build a biographical timeline with accurate chronology by identifying and following the movement of protagonists. Our experiments demonstrate that our method, PIECE, outperforms previous approaches in date assignment for timeline summarization across different language datasets.|时间线摘要任务旨在从新闻报道中提炼事件，以展示特定主题的时间发展脉络。传统方法通常根据相关报道的数量来提取事件，但往往忽视了主角（即参与并推动主题发展的主要参与者）的动态变化。这种忽视可能导致提取与主题发展无关的煽动性事件，从而分散读者对主题发展轨迹的注意力。为解决这一局限，我们提出了一种新颖的策略，该策略通过依存关系识别主角，并利用多层次时间图追踪主角周围语境随时间的变化。这种时间图是由一系列图组成的序列，能够有效捕捉信息的演变和随时间的变化。我们的方法旨在通过识别并跟踪主角的动态变化，构建一个具有准确时间顺序的传记式时间线。实验结果表明，我们的方法PIECE在不同语言数据集上的时间线摘要日期分配任务中，优于以往的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PIECE:+Protagonist+Identification+and+Event+Chronology+Extraction+for+Enhanced+Timeline+Summarization)|0|
|[Prompt-Based Spatio-Temporal Graph Transfer Learning](https://doi.org/10.1145/3627673.3679554)|Junfeng Hu, Xu Liu, Zhencheng Fan, Yifang Yin, Shili Xiang, Savitha Ramasamy, Roger Zimmermann|A*STAR Institute for Infocomm Research; National University of Singapore; University of Technology Sydney|Spatio-temporal graph neural networks have proven efficacy in capturing complex dependencies for urban computing tasks such as forecasting and kriging. Yet, their performance is constrained by the reliance on extensive data for training on a specific task, thereby limiting their adaptability to new urban domains with varied task demands. Although transfer learning has been proposed to remedy this problem by leveraging knowledge across domains, the cross-task generalization still remains under-explored in spatio-temporal graph transfer learning due to the lack of a unified framework. To bridge the gap, we propose Spatio-Temporal Graph Prompting (STGP), a prompt-based framework capable of adapting to multi-diverse tasks in a data-scarce domain. Specifically, we first unify different tasks into a single template and introduce a task-agnostic network architecture that aligns with this template. This approach enables capturing dependencies shared across tasks. Furthermore, we employ learnable prompts to achieve domain and task transfer in a two-stage prompting pipeline, facilitating the prompts to effectively capture domain knowledge and task-specific properties. Our extensive experiments demonstrate that STGP outperforms state-of-the-art baselines in three tasks-forecasting, kriging, and extrapolation-achieving an improvement of up to 10.7|时空图神经网络在捕捉城市计算任务（如预测和克里金插值）中的复杂依赖关系方面已证明其有效性。然而，其性能受到对特定任务训练所需大量数据的依赖的限制，从而限制了其在具有不同任务需求的新城市领域中的适应性。尽管迁移学习已被提出通过跨领域知识共享来解决这一问题，但由于缺乏统一的框架，跨任务泛化在时空图迁移学习中的研究仍然不足。为了弥补这一差距，我们提出了时空图提示（STGP），一个基于提示的框架，能够在数据稀缺的领域中适应多种任务。具体而言，我们首先将不同任务统一到一个模板中，并引入一个与该模板对齐的任务无关的网络架构。这种方法能够捕捉跨任务共享的依赖关系。此外，我们采用可学习的提示，在双阶段提示管道中实现领域和任务的迁移，使提示能够有效捕捉领域知识和任务特定属性。我们的大量实验表明，STGP在预测、克里金插值和外推三个任务中均优于最先进的基线方法，性能提升高达10.7%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Prompt-Based+Spatio-Temporal+Graph+Transfer+Learning)|0|
|[APTNESS: Incorporating Appraisal Theory and Emotion Support Strategies for Empathetic Response Generation](https://doi.org/10.1145/3627673.3679687)|Yuxuan Hu, Minghuan Tan, Chenwei Zhang, Zixuan Li, Xiaodan Liang, Min Yang, Chengming Li, Xiping Hu||Empathetic response generation is designed to comprehend the emotions of others and select the most appropriate strategies to assist them in resolving emotional challenges. Empathy can be categorized into cognitive empathy and affective empathy. The former pertains to the ability to understand and discern the emotional issues and situations of others, while the latter involves the capacity to provide comfort. To enhance one's empathetic abilities, it is essential to develop both these aspects. Therefore, we develop an innovative framework that combines retrieval augmentation and emotional support strategy integration. Our framework starts with the introduction of a comprehensive emotional palette for empathy. We then apply appraisal theory to decompose this palette and create a database of empathetic responses. This database serves as an external resource and enhances the LLM's empathy by integrating semantic retrieval mechanisms. Moreover, our framework places a strong emphasis on the proper articulation of response strategies. By incorporating emotional support strategies, we aim to enrich the model's capabilities in both cognitive and affective empathy, leading to a more nuanced and comprehensive empathetic response. Finally, we extract datasets ED and ET from the empathetic dialogue dataset EmpatheticDialogues and ExTES based on dialogue length. Experiments demonstrate that our framework can enhance the empathy ability of LLMs from both cognitive and affective empathy perspectives. Our code is released at https://github.com/CAS-SIAT-XinHai/APTNESS.|共情回应生成旨在理解他人的情绪，并选择最合适的策略来帮助他们解决情感挑战。共情可以分为认知共情和情感共情。前者涉及理解和辨别他人情感问题和情境的能力，而后者则涉及提供安慰的能力。为了提升共情能力，必须同时发展这两个方面。因此，我们开发了一个结合检索增强和情感支持策略整合的创新框架。我们的框架首先引入了一个全面的共情情感调色板。然后，我们运用评价理论对该调色板进行分解，并创建了一个共情回应数据库。该数据库作为外部资源，通过整合语义检索机制来增强大语言模型（LLM）的共情能力。此外，我们的框架特别强调回应策略的恰当表达。通过融入情感支持策略，我们旨在丰富模型在认知和情感共情方面的能力，从而生成更为细致和全面的共情回应。最后，我们基于对话长度从共情对话数据集EmpatheticDialogues和ExTES中提取了ED和ET数据集。实验证明，我们的框架能够从认知和情感共情的角度提升LLM的共情能力。我们的代码已发布在 https://github.com/CAS-SIAT-XinHai/APTNESS。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=APTNESS:+Incorporating+Appraisal+Theory+and+Emotion+Support+Strategies+for+Empathetic+Response+Generation)|0|
|[A Payment Transaction Pre-training Model for Fraud Transaction Detection](https://doi.org/10.1145/3627673.3679670)|Wenxi Huang, Zhangyi Zhao, Xiaojun Chen, Qin Zhang, Mark Junjie Li, Hanjing Su, Qingyao Wu|Shenzhen University, Shenzhen, China; Tencent, Shenzhen, China; South China University Of Technology, Guangzhou, China|The surge in merchant fraud poses a significant threat to market order and consumer security. Effective security monitoring for merchants is crucial in safeguarding the digital life ecosystem and users' financial well-being. Detecting daily fraudulent payment transactions, a challenging task for current methods, requires efficient transformation of transactions into embeddings, especially in representing merchants based on their behavioral transactions. To address this, we propose the Grouping Sampling-based Sequence Generation (GSSG) method to generate meaningful sequences, enabling interactions among correlated transactions. We introduce Hierarchical Embedding Learning (HEL) and Hierarchical Masking pre-training (HMP) for the effective representation of hierarchical structures within flat transaction sequences. Pretrained on WeChat Pay data, our model, PTP, demonstrates superior performance in downstream fraud transaction detection, especially in few-shot learning scenarios, showcasing great potential in payment transaction scenarios.|商户欺诈行为的激增对市场秩序和消费者安全构成了重大威胁。对商户进行有效的安全监控对于保护数字生活生态系统和用户的财务安全至关重要。检测日常的欺诈支付交易是当前方法面临的一项挑战，这需要将交易高效地转化为嵌入表示，尤其是基于商户的行为交易来表征商户。为解决这一问题，我们提出了基于分组采样的序列生成（GSSG）方法，以生成有意义的序列，从而实现相关交易之间的交互。我们引入了分层嵌入学习（HEL）和分层掩码预训练（HMP）方法，以有效地表示扁平交易序列中的分层结构。我们的模型PTP在微信支付数据上进行预训练后，在下游欺诈交易检测任务中表现出色，尤其是在少样本学习场景中，展示了在支付交易场景中的巨大潜力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Payment+Transaction+Pre-training+Model+for+Fraud+Transaction+Detection)|0|
|[Fast and Accurate PARAFAC2 Decomposition for Time Range Queries on Irregular Tensors](https://doi.org/10.1145/3627673.3679735)|JunGi Jang, Yongchan Park, U Kang|Seoul National University, Seoul, Republic of Korea; University of Illinois, Urbana-Champaign, IL, USA|How can we efficiently analyze a specific time range on an irregular tensor? PARAFAC2 decomposition is widely used when analyzing an irregular tensor which consists of several matrices with different row sizes. A crucial task related to PARAFAC2 decomposition is to analyze sub-tensors corresponding to various time ranges of a given tensor, instead of analyzing the entire tensor. Although many recent works have developed efficient PARAFAC2 decomposition methods, existing PARAFAC2 decomposition methods are inappropriate for addressing various time range queries, as they need to decompose sub-tensors from scratch. In this paper, we propose Repeat, a fast and accurate PARAFAC2 decomposition method for handling arbitrary time range queries on irregular tensors. To avoid decomposing sub-tensors of queries from scratch, Repeat obtains preprocessed results that support efficient query answering before time ranges are given. For time range queries, Repeat efficiently computes the PARAFAC2 decomposition for the sub-tensors corresponding to the queries by using preprocessed results rather than the original irregular tensor. We experimentally demonstrate that Repeat outperforms existing PARAFAC2 methods, providing up to 12x faster speed while having comparable errors. We also present a case study for the use of Repeat in detecting locally appearing patterns through a variety of time range queries.|如何高效地分析不规则张量中的特定时间范围？PARAFAC2分解在分析由多个具有不同行大小的矩阵组成的不规则张量时被广泛使用。与PARAFAC2分解相关的一个关键任务是分析对应于给定张量中不同时间范围的子张量，而不是分析整个张量。尽管最近许多研究开发了高效的PARAFAC2分解方法，但现有的PARAFAC2分解方法并不适合处理各种时间范围查询，因为它们需要从头开始分解子张量。在本文中，我们提出了Repeat，一种快速且准确的PARAFAC2分解方法，用于处理不规则张量上的任意时间范围查询。为了避免从头开始分解查询的子张量，Repeat在给出时间范围之前获取预处理结果，以支持高效的查询应答。对于时间范围查询，Repeat通过使用预处理结果而不是原始的不规则张量，高效地计算对应于查询的子张量的PARAFAC2分解。我们通过实验证明，Repeat优于现有的PARAFAC2方法，在具有可比误差的情况下，速度提高了多达12倍。我们还展示了通过多种时间范围查询使用Repeat检测局部出现模式的案例研究。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fast+and+Accurate+PARAFAC2+Decomposition+for+Time+Range+Queries+on+Irregular+Tensors)|0|
|[HiLite: Hierarchical Level-implemented Architecture Attaining Part-Whole Interpretability](https://doi.org/10.1145/3627673.3679538)|Yoo Hyun Jeong, Sunghyun Hwang, DongKyu Chae|Hanyang University, Seoul, Republic of Korea|Beyond the traditional CNN structure, we have recently witnessed lots of breakthroughs in computer vision architectures such as Vision Transformer, MLP-Mixer, SNN-MLP, and so on. However, many efforts in developing novel architectures for vision tasks are heavily focused on achieving powerful performances, and how to attain interpretability in a trained neural network remains an open question. Inspired by the imaginary system GLOM, we present HiLite : Hierarchical Level-implemented Architecture attaining Part-Whole Interpretability, where islands of identical vectors can provide unprecedented interpretability. In our column-like structure, each level is a layer of a part-whole hierarchy composed of multiple neurons, and the function to define the neural field along an image input patch is initialized as the level vector inside the model. We propose two-column networks (Top-Down (TD) and Bottom-Up (BU)) that allow inter-level communication between adjacent levels on a specific patch and propose Gated Consensus Attention to perform intra-level communication on different patches within the level. At each time step, the level vector and outputs from different networks are combined into a weighted sum and passed to the next step, and outputs from the final time step are utilized as representation vectors. Here, supervised contrastive learning is used to find the relationship of meaningful patches in each class, where negative examples contribute to preventing representation collapse between neighboring patches. HiLite shows a possibility of performance through a quantitative evaluation on four image classification datasets as well as two metrics for assessing representation quality and showcases the intrinsic interpretability by simply generating a visual cue. We believe that our work is a solid step towards novel research on neural architectures attaining interpretability.|在传统的卷积神经网络（CNN）结构之外，我们最近见证了计算机视觉架构领域的许多突破，例如Vision Transformer、MLP-Mixer、SNN-Mixer等。然而，许多开发新型视觉任务架构的努力主要集中在实现强大的性能上，而如何在训练好的神经网络中实现可解释性仍然是一个悬而未决的问题。受虚拟系统GLOM的启发，我们提出了HiLite：一种实现部分-整体可解释性的分层架构，其中相同向量的“岛屿”可以提供前所未有的可解释性。在我们的柱状结构中，每一层都是由多个神经元组成的部分-整体层次结构，并且定义沿图像输入补丁的神经场的函数被初始化为模型内部的层级向量。我们提出了双列网络（自上而下（TD）和自下而上（BU）），允许在特定补丁上的相邻层级之间进行跨层级通信，并提出了门控共识注意力机制（Gated Consensus Attention）以在同一层级内的不同补丁之间进行层级内通信。在每个时间步，层级向量和来自不同网络的输出被组合成加权和并传递给下一步，最终时间步的输出被用作表示向量。在这里，我们使用监督对比学习来寻找每个类中有意义补丁之间的关系，其中负样本有助于防止相邻补丁之间的表示崩溃。HiLite通过对四个图像分类数据集的定量评估以及用于评估表示质量的两个指标展示了其性能潜力，并通过简单地生成视觉线索展示了其内在的可解释性。我们相信，我们的工作为在实现可解释性的神经架构研究领域迈出了坚实的一步。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HiLite:+Hierarchical+Level-implemented+Architecture+Attaining+Part-Whole+Interpretability)|0|
|[GameTrail: Probabilistic Lifecycle Process Model for Deep Game Understanding](https://doi.org/10.1145/3627673.3679736)|Shanyang Jiang, Lan Zhang, Hui Xu, Jiahui Huang, Qi He, Xing Zhou, Lei Huang, Jie Jiang|; Tencent Inc., Shanghai, China|As the mobile gaming market experiences significant growth, there is a continuous emergence of new gaming products such as premium games and video mini-games. Meeting their marketing needs and supporting their business growth is essential for long-term prosperity. However, compared with extensive studies on user modeling such as LTV prediction, much less attention has been drawn to special gaming products, especially in terms of understanding their lifecycle stages and corresponding demands. Unlike modeling individual users, understanding games is closely tied to user behavior: the lifecycle of a game encompasses the entire process from initial user interaction to churn, and by accurately identifying and tracking the evolution of the game lifecycle can lead to better personal service. This raises the necessity of comprehensively understanding the lifecycle process model of the game. In this paper, we introduce the GameTrail - Probabilistic Lifecycle Process Model, designed to construct the complete lifecycle and stage representation for games and users through long-term repeated interactions. Specifically, we first initiate the complete game lifecycle using a joint probabilistic stochastic process model by defining the lifecycle stages of both games and users as latent variables and learning it via Bayesian Variation Inference. Furthermore, we employ cross attention and online embedding learning to capture the more recent advertising context changes in the in-game stage transitions. Finally, we collect various games' data from public resources to construct an experimental dataset for our experiments. Meanwhile, more comprehensive experiments conducted on real-world gaming industry datasets have showcased the effectiveness of our approach, showing a relative improvement of 48% and 17% on NMSE and NMAE than the live baseline.|随着移动游戏市场的显著增长，诸如付费游戏和视频小游戏等新型游戏产品不断涌现。满足其营销需求并支持其业务增长对于长期繁荣至关重要。然而，与用户建模（如LTV预测）方面的广泛研究相比，特殊游戏产品受到的关注要少得多，特别是在理解其生命周期阶段和相应需求方面。与建模个体用户不同，理解游戏与用户行为密切相关：游戏的生命周期涵盖了从用户初次互动到流失的整个过程，通过准确识别和跟踪游戏生命周期的演变，可以实现更好的个性化服务。这引发了对全面理解游戏生命周期过程模型的必要性。在本文中，我们介绍了GameTrail——概率生命周期过程模型，旨在通过长期的重复互动为游戏和用户构建完整的生命周期和阶段表示。具体而言，我们首先通过联合概率随机过程模型启动完整的游戏生命周期，将游戏和用户的生命周期阶段定义为潜在变量，并通过贝叶斯变分推断进行学习。此外，我们采用交叉注意力和在线嵌入学习来捕捉游戏中阶段转换时更近期的广告上下文变化。最后，我们从公共资源中收集了各种游戏的数据，构建了实验数据集用于我们的实验。同时，在真实世界的游戏行业数据集上进行的更全面实验展示了我们方法的有效性，与实时基线相比，NMSE和NMAE相对提高了48%和17%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GameTrail:+Probabilistic+Lifecycle+Process+Model+for+Deep+Game+Understanding)|0|
|[Causality-Aware Spatiotemporal Graph Neural Networks for Spatiotemporal Time Series Imputation](https://doi.org/10.1145/3627673.3679642)|Baoyu Jing, Dawei Zhou, Kan Ren, Carl Yang||Spatiotemporal time series are usually collected via monitoring sensors placed at different locations, which usually contain missing values due to various mechanical failures. Imputing the missing values is crucial for analyzing time series. When recovering a specific data point, most existing methods consider all the information relevant to that point regardless of the cause-and-effect relationship. During data collection, it is inevitable that some unknown confounders are included, e.g., background noise in time series and non-causal shortcut edges in the constructed sensor network. These confounders could open backdoor paths and establish non-causal correlations between the input and output. Over-exploiting these non-causal correlations could cause overfitting. In this paper, we first revisit spatiotemporal time series imputation from a causal perspective and show how to block the confounders via the frontdoor adjustment. Based on the results of frontdoor adjustment, we introduce a novel Causality-Aware Spatiotemporal Graph Neural Network (Casper), which contains a novel Prompt Based Decoder (PBD) and a Spatiotemporal Causal Attention (SCA). PBD could reduce the impact of confounders and SCA could discover the sparse causal relationships among embeddings. Theoretical analysis reveals that SCA discovers causal relationships based on the values of gradients. We evaluate Casper on three real-world datasets, and the experimental results show that Casper could outperform the baselines and could effectively discover causal relationships.|时空时间序列通常通过部署在不同位置的监测传感器收集，由于各种机械故障，这些数据通常包含缺失值。填补这些缺失值对于分析时间序列至关重要。在恢复特定数据点时，大多数现有方法会考虑与该点相关的所有信息，而不考虑因果关系。在数据收集过程中，不可避免地会包含一些未知的混杂因素，例如时间序列中的背景噪声和构建的传感器网络中的非因果捷径边。这些混杂因素可能会打开后门路径，并在输入和输出之间建立非因果关联。过度利用这些非因果关联可能会导致过拟合。在本文中，我们首先从因果关系的角度重新审视时空时间序列填补，并展示如何通过前门调整来阻断这些混杂因素。基于前门调整的结果，我们提出了一种新颖的因果感知时空图神经网络（Casper），该网络包含一种新颖的基于提示的解码器（PBD）和一种时空因果注意力机制（SCA）。PBD可以减少混杂因素的影响，而SCA可以发现嵌入之间的稀疏因果关系。理论分析表明，SCA基于梯度的值来发现因果关系。我们在三个真实世界的数据集上评估了Casper，实验结果表明，Casper能够超越基线方法，并有效地发现因果关系。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causality-Aware+Spatiotemporal+Graph+Neural+Networks+for+Spatiotemporal+Time+Series+Imputation)|0|
|[Tackling Noisy Clients in Federated Learning with End-to-end Label Correction](https://doi.org/10.1145/3627673.3679550)|Xuefeng Jiang, Sheng Sun, Jia Li, Jingjing Xue, Runhan Li, Zhiyuan Wu, Gang Xu, Yuwei Wang, Min Liu||Recently, federated learning (FL) has achieved wide successes for diverse privacy-sensitive applications without sacrificing the sensitive private information of clients. However, the data quality of client datasets can not be guaranteed since corresponding annotations of different clients often contain complex label noise of varying degrees, which inevitably causes the performance degradation. Intuitively, the performance degradation is dominated by clients with higher noise rates since their trained models contain more misinformation from data, thus it is necessary to devise an effective optimization scheme to mitigate the negative impacts of these noisy clients. In this work, we propose a two-stage framework FedELC to tackle this complicated label noise issue. The first stage aims to guide the detection of noisy clients with higher label noise, while the second stage aims to correct the labels of noisy clients' data via an end-to-end label correction framework which is achieved by learning possible ground-truth labels of noisy clients' datasets via back propagation. We implement sixteen related methods and evaluate five datasets with three types of complicated label noise scenarios for a comprehensive comparison. Extensive experimental results demonstrate our proposed framework achieves superior performance than its counterparts for different scenarios. Additionally, we effectively improve the data quality of detected noisy clients' local datasets with our label correction framework. The code is available at https://github.com/Sprinter1999/FedELC.|近年来，联邦学习（FL）在多种隐私敏感应用中取得了广泛的成功，而无需牺牲客户的敏感隐私信息。然而，由于不同客户的相应注释通常包含不同程度的复杂标签噪声，客户数据集的数据质量无法得到保证，这不可避免地导致性能下降。直观上，性能下降主要由噪声率较高的客户主导，因为他们的训练模型包含更多来自数据的错误信息，因此有必要设计一种有效的优化方案来减轻这些噪声客户的负面影响。在本工作中，我们提出了一个两阶段框架FedELC来解决这一复杂的标签噪声问题。第一阶段旨在指导检测具有较高标签噪声的噪声客户，而第二阶段旨在通过端到端的标签校正框架来校正噪声客户数据的标签，该框架通过反向传播学习噪声客户数据集的可能真实标签来实现。我们实现了十六种相关方法，并在三种复杂标签噪声场景下评估了五个数据集，以进行全面比较。大量实验结果表明，我们提出的框架在不同场景下均优于其他方法。此外，我们通过标签校正框架有效提高了检测到的噪声客户本地数据集的数据质量。代码可在https://github.com/Sprinter1999/FedELC获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tackling+Noisy+Clients+in+Federated+Learning+with+End-to-end+Label+Correction)|0|
|[Effectively Capturing Label Correlation for Tabular Multi-Label Classification](https://doi.org/10.1145/3627673.3679772)|Sajjad Kamali Siahroudi, Zahra Ahmadi, Daniel Kudenko|L3S Research Center, Leibniz University Hannover, Hannover, Niedersachsen, Germany|Multi-label data is prevalent across various applications, where instances can be annotated with a set of classes. Although multi-label data can take various forms, such as images and text, tabular multi-label data stands out as the predominant data type in many real-world scenarios. Over the past decades, numerous methods have been proposed for tabular multi-label classification. Effectively addressing challenges like class imbalance, correlation among labels and features, and scalability is crucial for a high-performance multi-label classifier. However, many existing methods fall short of fully considering the correlation between labels and features. In cases where attempts are made, they often encounter high computational costs, rendering them impractical for large datasets. This paper in- troduces an innovative classification method for tabular multi-label data, utilizing a fusion of transformers and graph convolutional networks (GCN). The central concept of the proposed approach involves transforming tabular data into images, leveraging state-of-the-art methods in image processing, including image-based transformers and pre-trained models to capture correlation among labels effectively. Our approach jointly learns the representation of feature space and the correlation among labels within a unified network. To substantiate the performance of our proposed method, we conducted a rigorous series of experiments across diverse multi-label datasets1. The results underscore the superior performance and scalability of our approach compared to other existing state-of-the-art methods. This work not only contributes a novel perspective to the field of tabular multi-label classification but also showcases advancements in both accuracy and scalability.|多标签数据在各种应用场景中普遍存在，其中实例可以被标注为一组类别。尽管多标签数据可以呈现多种形式，如图像和文本，但在许多实际场景中，表格形式的多标签数据占据主导地位。在过去的几十年中，针对表格多标签分类提出了许多方法。有效应对类别不平衡、标签与特征之间的相关性以及可扩展性等挑战，对于构建高性能的多标签分类器至关重要。然而，许多现有方法未能充分考虑标签与特征之间的相关性。即使在某些尝试中，也常常面临高计算成本的问题，使得这些方法在处理大规模数据集时显得不切实际。本文提出了一种创新的表格多标签数据分类方法，该方法结合了Transformer和图卷积网络（GCN）的优势。该方法的核心理念是将表格数据转换为图像，利用图像处理领域的最新技术，包括基于图像的Transformer和预训练模型，以有效捕捉标签之间的相关性。我们的方法在一个统一的网络中联合学习特征空间的表示和标签之间的相关性。为了验证所提出方法的性能，我们在多个多标签数据集上进行了严格的实验。结果表明，与其他现有的最先进方法相比，我们的方法在性能和可扩展性方面均表现出色。这项工作不仅为表格多标签分类领域提供了一个新颖的视角，还展示了在准确性和可扩展性方面的显著进展。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Effectively+Capturing+Label+Correlation+for+Tabular+Multi-Label+Classification)|0|
|[Transformer for Point Anomaly Detection](https://doi.org/10.1145/3627673.3679859)|Harim Kim, Chang Ha Lee, Charmgil Hong|; GMDSOFT, Seongnam, Republic of Korea|In data analysis, unsupervised anomaly detection holds an important position for identifying statistical outliers that signify atypical behavior, erroneous readings, or interesting patterns within data. The Transformer model, known for its ability to capture dependencies within sequences, has revolutionized areas such as text and image data analysis. However, its potential for tabular data, where sequence dependencies are not inherently present, remains underexplored. This paper introduces Transformer for Point Anomaly Detection (TransPAD), a novel Transformer-based AutoEncoder framework specifically designed for point anomaly detection. Our method captures interdependencies across entire datasets, addressing the challenges posed with non-sequential, tabular data. It incorporates unique random and criteria sampling strategies for effective training and anomaly identification, and avoids the common pitfall of trivial generalization that affects many conventional methods. By leveraging an attention weight-based anomaly scoring system, TransPAD offers a more precise approach to detect anomalies. Extensive testing on a range of benchmark tabular datasets shows that TransPAD consistently outperforms existing methods. Our source code is available at https://github.com/nth221/TransPAD.|在数据分析领域，无监督异常检测在识别统计异常值方面占据重要地位，这些异常值通常表示数据中的非典型行为、错误读数或有趣模式。Transformer模型以其捕捉序列间依赖关系的能力而闻名，已经在文本和图像数据分析等领域引发了革命性变化。然而，对于表格数据，由于序列依赖关系并不天然存在，Transformer模型的潜力尚未得到充分探索。本文提出了用于点异常检测的Transformer模型（TransPAD），这是一种专门为点异常检测设计的基于Transformer的自编码器框架。我们的方法能够捕捉整个数据集中的相互依赖关系，解决了非序列化表格数据带来的挑战。TransPAD结合了独特的随机和标准采样策略，以实现有效的训练和异常识别，并避免了传统方法中常见的平庸泛化问题。通过利用基于注意力权重的异常评分系统，TransPAD提供了一种更为精确的异常检测方法。在一系列基准表格数据集上的广泛测试表明，TransPAD始终优于现有方法。我们的源代码可在https://github.com/nth221/TransPAD获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Transformer+for+Point+Anomaly+Detection)|0|
|[PolarDSN: An Inductive Approach to Learning the Evolution of Network Polarization in Dynamic Signed Networks](https://doi.org/10.1145/3627673.3679654)|MinJeong Kim, YeonChang Lee, SangWook Kim|Ulsan National Institute of Science and Technology (UNIST), Ulsan, Republic of Korea; Hanyang University, Seoul, Republic of Korea|The goal of dynamic signed network embedding (DSNE) is to represent the nodes in a dynamic signed network (DSN) as embeddings that preserve the evolving nature of conflicting relationships between nodes. While existing DSNE methods are useful for understanding polarization between users in diverse domains, they fail to consider the concept of a community boundary that contributes to network-wide polarization and lack inductive ability due to their reliance on homophily bias. To address these limitations, we propose a novel DSNE method, named PolarDSN, which learns the evolution of network POLARization and enhances inductive ability for Dynamic Signed Networks. It leverages node-level community boundaries as well as structural characteristics of nodes such as structural isomorphism and temporal transitivity. Experiments on four real-world DSN datasets demonstrate that PolarDSN consistently and significantly outperforms 12 state-of-the-art methods, achieving up to 31.6% and 21.1% improvement in macro-F1 for transductive and inductive settings, respectively. The code is available at https://github.com/kmj0792/PolarDSN.|动态符号网络嵌入（Dynamic Signed Network Embedding, DSNE）的目标是将动态符号网络（Dynamic Signed Network, DSN）中的节点表示为能够保留节点间冲突关系演化特性的嵌入向量。尽管现有的DSNE方法在理解多领域中用户之间的极化现象方面具有一定作用，但它们未能考虑社区边界的概念，而这一概念对网络范围内的极化现象有重要贡献。此外，由于这些方法依赖于同质性偏差，它们缺乏归纳能力。为了解决这些局限性，我们提出了一种名为**PolarDSN**的新型DSNE方法，该方法能够学习网络极化（POLARization）的演化过程，并增强动态符号网络的归纳能力。PolarDSN利用了节点级别的社区边界以及节点的结构特征，如结构同构性和时间传递性。在四个真实世界的DSN数据集上的实验表明，PolarDSN在一致性和显著程度上优于12种最先进的方法，在传导性和归纳性设置下分别实现了高达31.6%和21.1%的宏F1值提升。代码已开源，地址为：https://github.com/kmj0792/PolarDSN。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PolarDSN:+An+Inductive+Approach+to+Learning+the+Evolution+of+Network+Polarization+in+Dynamic+Signed+Networks)|0|
|[Enhancing Anomaly Detection via Generating Diversified and Hard-to-distinguish Synthetic Anomalies](https://doi.org/10.1145/3627673.3679623)|Hyuntae Kim, Changhee Lee||Unsupervised anomaly detection is a daunting task, as it relies solely on normality patterns from the training data to identify unseen anomalies during testing. Recent approaches have focused on leveraging domain-specific transformations or perturbations to generate synthetic anomalies from normal samples. The objective here is to acquire insights into normality patterns by learning to differentiate between normal samples and these crafted anomalies. However, these approaches often encounter limitations when domain-specific transformations are not well-specified such as in tabular data, or when it becomes trivial to distinguish between them. To address these issues, we introduce a novel domain-agnostic method that employs a set of conditional perturbators and a discriminator. The perturbators are trained to generate input-dependent perturbations, which are subsequently utilized to construct synthetic anomalies, and the discriminator is trained to distinguish normal samples from them. We ensure that the generated anomalies are both diverse and hard to distinguish through two key strategies: i) directing perturbations to be orthogonal to each other and ii) constraining perturbations to remain in proximity to normal samples. Throughout experiments on real-world datasets, we demonstrate the superiority of our method over state-of-the-art benchmarks, which is evident not only in image data but also in tabular data, where domain-specific transformation is not readily accessible. Additionally, we empirically confirm the adaptability of our method to semi-supervised settings, demonstrating its capacity to incorporate supervised signals to enhance anomaly detection performance even further.|无监督异常检测是一项极具挑战性的任务，因为它仅依赖于训练数据中的正常模式来识别测试期间未见过的异常。最近的研究方法主要集中在利用领域特定的变换或扰动，从正常样本中生成合成异常。其目标是通过学习区分正常样本与这些人为构造的异常，从而深入理解正常模式。然而，当领域特定的变换未能明确定义时（例如在表格数据中），或者当区分正常样本与合成异常变得过于简单时，这些方法往往会遇到局限。为了解决这些问题，我们提出了一种新颖的领域无关方法，该方法采用了一组条件扰动器和一个判别器。扰动器经过训练以生成依赖于输入的扰动，随后这些扰动被用于构建合成异常，而判别器则被训练用于区分正常样本与这些异常。我们通过两个关键策略确保生成的异常既多样化又难以区分：i）使扰动彼此正交，ii）限制扰动保持在正常样本附近。通过在真实数据集上的实验，我们证明了该方法在图像数据和表格数据中均优于现有的最先进基准方法，尤其是在表格数据中，领域特定变换并不容易获得。此外，我们通过实验验证了该方法在半监督设置下的适应性，展示了其能够结合监督信号以进一步提升异常检测性能的能力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Anomaly+Detection+via+Generating+Diversified+and+Hard-to-distinguish+Synthetic+Anomalies)|0|
|[FaDE: A Face Segment Driven Identity Anonymization Framework For Fair Face Recognition](https://doi.org/10.1145/3627673.3679737)|Ziyi Kou, Yijun Tian, Meng Jiang, Xiangliang Zhang|University of Notre Dame, Notre Dame, IN, USA|Current face recognition (FR) algorithms frequently encounter discrimination issues in terms of various attributes (e.g., gender, age) due to the biased demographic distribution of the training datasets towards specific groups. In this paper, we study an identity protected fair FR problem where the goal is to augment the datasets with external face images while ensuring the anonymity of the corresponding face identities. Our problem is motivated by the limitation of current fairness driven data augmentation approaches that directly utilize the external face images accessed by FR algorithm developers while ignoring the protection on the face identities of the image owners. To address the problem, we develop FaDE, a face segment driven identity anonymization framework that augments biased face image datasets by identifying specific face segments with diversified demographic characteristics from external face images but with least identity disclosure, and then reconstructing the segments to full face images with new identities. As a result, the augmented dataset is under a more balanced demographic distribution and improves the fairness performance of the optimized FR algorithms. We evaluate FaDE on two public face datasets, CelebA and LFW that suffer from various demographic imbalance. The results show that FaDE significantly enhances both fairness and accuracy performance of the optimized FR algorithms, while keeping effective anonymity for the identities of external face images.|当前的人脸识别（FR）算法由于训练数据集在特定群体上存在偏见的分布，常常在性别、年龄等各种属性上遇到歧视问题。本文研究了一个身份保护的公平FR问题，其目标是通过外部人脸图像扩充数据集，同时确保相应人脸身份信息的匿名性。我们的研究动机源于当前公平性驱动的数据增强方法的局限性，这些方法直接利用FR算法开发者获取的外部人脸图像，而忽略了图像拥有者人脸身份信息的保护。为了解决这一问题，我们开发了FaDE，一个基于人脸片段的身份匿名化框架，该框架通过从外部人脸图像中识别具有多样化人口统计特征的特定人脸片段，同时最小化身份信息的泄露，然后将这些片段重建为具有新身份的全脸图像，从而扩充带有偏见的人脸图像数据集。因此，扩充后的数据集在人口统计分布上更加平衡，并提升了优化后FR算法的公平性表现。我们在两个存在各种人口统计失衡问题的公开人脸数据集CelebA和LFW上评估了FaDE。结果表明，FaDE显著提高了优化后FR算法的公平性和准确性表现，同时有效保持了外部人脸图像身份信息的匿名性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FaDE:+A+Face+Segment+Driven+Identity+Anonymization+Framework+For+Fair+Face+Recognition)|0|
|[Vision Language Model is NOT All You Need: Augmentation Strategies for Molecule Language Models](https://doi.org/10.1145/3627673.3679607)|Namkyeong Lee, Siddhartha Laghuvarapu, Chanyoung Park, Jimeng Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Vision+Language+Model+is+NOT+All+You+Need:+Augmentation+Strategies+for+Molecule+Language+Models)|0|
|[FastSimiFeat: A Fast and Generalized Approach Utilizing k-NN for Noisy Data Handling](https://doi.org/10.1145/3627673.3679591)|Jungi Lee, Hwiwoo Park, Myounghwan Kim, Jiseong Yoon, Kwangsun Yoo, SeokJoo Byun|ELROILAB Inc., Seoul, Republic of Korea|As deep learning technologies continue to evolve, the challenge of training neural networks with noisy data becomes increasingly critical. Incorrect labels, which often result in the model's tendency to memorize incorrect data--a phenomenon known as the memorization effect--significantly undermine both performance and the ability to generalize. Traditional methods to address noisy labels typically involve extensive modifications during training, leading to prolonged refinement processes. Although some recent approaches eliminate the need for retraining by using pre-trained models, they still face challenges with lengthy refinement times and inaccurate noise ratio estimations. In response, we introduce FastSimiFeat, a novel algorithm that utilizes the k-nearest neighbors (k-NN) technique on feature vectors derived from pre-trained models efficiently. This training-free method incorporates a new confusion matrix-based noise ratio estimator that significantly reduces the need for iterative refinement by adapting the number of k-NN cycles based on the detected noise level. Additionally, we propose an innovative label correction method that leverages potentially noisy data to enhance model robustness and generality. Our extensive evaluations on both synthetic and real-world datasets demonstrate that FastSimiFeat not only minimizes refinement time but also consistently outperforms existing methods in terms of accuracy. These results confirm the suitability of FastSimiFeat for industrial applications where reliable data processing is paramount. By leveraging inherent features of neural networks pre-trained on large datasets, FastSimiFeat sets a new standard for minimal-dependency approaches in noisy data environments, facilitating the deployment of more reliable and efficient deep learning models across various sectors.|随着深度学习技术的不断发展，使用噪声数据训练神经网络变得越来越具有挑战性。不正确的标签通常会导致模型倾向于记忆错误数据，这种现象被称为记忆效应，严重削弱了模型的性能和泛化能力。传统的处理噪声标签的方法通常需要在训练过程中进行大量修改，导致精炼过程耗时较长。尽管最近的一些方法通过使用预训练模型消除了重新训练的需求，但它们仍然面临着精炼时间过长和噪声比例估计不准确的挑战。为此，我们提出了FastSimiFeat，这是一种新颖的算法，它有效地利用k近邻（k-NN）技术对预训练模型生成的特征向量进行处理。这种无需训练的方法引入了一种新的基于混淆矩阵的噪声比例估计器，通过根据检测到的噪声水平调整k-NN循环次数，显著减少了对迭代精炼的需求。此外，我们提出了一种创新的标签校正方法，该方法利用潜在的噪声数据来增强模型的鲁棒性和泛化能力。我们在合成数据集和真实数据集上的广泛评估表明，FastSimiFeat不仅最大限度地减少了精炼时间，而且在准确性方面始终优于现有方法。这些结果证实了FastSimiFeat在需要可靠数据处理的工业应用中的适用性。通过利用在大规模数据集上预训练的神经网络的固有特征，FastSimiFeat为噪声数据环境中的最小依赖方法设定了新标准，促进了跨行业部署更可靠、更高效的深度学习模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FastSimiFeat:+A+Fast+and+Generalized+Approach+Utilizing+k-NN+for+Noisy+Data+Handling)|0|
|[Learning Fair Invariant Representations under Covariate and Correlation Shifts Simultaneously](https://doi.org/10.1145/3627673.3679727)|Dong Li, Chen Zhao, Minglai Shao, Wenjun Wang||Achieving the generalization of an invariant classifier from training domains to shifted test domains while simultaneously considering model fairness is a substantial and complex challenge in machine learning. Existing methods address the problem of fairness-aware domain generalization, focusing on either covariate shift or correlation shift, but rarely consider both at the same time. In this paper, we introduce a novel approach that focuses on learning a fairness-aware domain-invariant predictor within a framework addressing both covariate and correlation shifts simultaneously, ensuring its generalization to unknown test domains inaccessible during training. In our approach, data are first disentangled into content and style factors in latent spaces. Furthermore, fairness-aware domain-invariant content representations can be learned by mitigating sensitive information and retaining as much other information as possible. Extensive empirical studies on benchmark datasets demonstrate that our approach surpasses state-of-the-art methods with respect to model accuracy as well as both group and individual fairness.|在机器学习领域，实现一个不变分类器从训练域到偏移测试域的泛化，同时兼顾模型公平性，是一项重大且复杂的挑战。现有方法在处理公平感知的域泛化问题时，主要关注协变量偏移或相关性偏移，但很少同时考虑两者。本文提出了一种新颖的方法，旨在同时处理协变量和相关性偏移的框架内，学习公平感知的域不变预测器，确保其在训练期间无法访问的未知测试域上的泛化能力。在我们的方法中，数据首先在潜在空间中被解耦为内容因子和风格因子。此外，通过减少敏感信息并尽可能保留其他信息，可以学习到公平感知的域不变内容表示。在基准数据集上的大量实证研究表明，我们的方法在模型准确性以及群体和个体公平性方面均优于现有最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Fair+Invariant+Representations+under+Covariate+and+Correlation+Shifts+Simultaneously)|0|
|[Dynamic Neural Control Flow Execution: an Agent-Based Deep Equilibrium Approach for Binary Vulnerability Detection](https://doi.org/10.1145/3627673.3679726)|Li Tao Li, Steven H. H. Ding, Andrew Walenstein, Philippe Charland, Benjamin C. M. Fung|Mission Critical Cyber Security Section; BlackBerry Ltd; Queen's University School of Computing; McGill University Data Mining and Security (DMaS) Lab|Software vulnerabilities are a challenge in cybersecurity. Manual securitypatches are often difficult and slow to be deployed, while new vulnerabilitiesare created. Binary code vulnerability detection is less studied and morecomplex compared to source code, and this has important practical implications.Deep learning has become an efficient and powerful tool in the security domain,where it provides end-to-end and accurate prediction. Modern deep learningapproaches learn the program semantics through sequence and graph neuralnetworks, using various intermediate representation of programs, such asabstract syntax trees (AST) or control flow graphs (CFG). Due to the complexnature of program execution, the output of an execution depends on the manyprogram states and inputs. Also, a CFG generated from static analysis can be anoverestimation of the true program flow. Moreover, the size of programs oftendoes not allow a graph neural network with fixed layers to aggregate globalinformation. To address these issues, we propose DeepEXE, an agent-basedimplicit neural network that mimics the execution path of a program. We usereinforcement learning to enhance the branching decision at every program statetransition and create a dynamic environment to learn the dependency between avulnerability and certain program states. An implicitly defined neural networkenables nearly infinite state transitions until convergence, which captures thestructural information at a higher level. The experiments are conducted on twosemi-synthetic and two real-world datasets. We show that DeepEXE is an accurateand efficient method and outperforms the state-of-the-art vulnerabilitydetection methods.|软件漏洞是网络安全领域的一大挑战。手动部署安全补丁往往既困难又缓慢，而新的漏洞却不断涌现。与源代码相比，二进制代码的漏洞检测研究较少且更为复杂，但具有重要的实际意义。深度学习已成为安全领域中一种高效且强大的工具，能够提供端到端的精准预测。现代深度学习方法通过序列神经网络和图神经网络，利用程序的多种中间表示（如抽象语法树（AST）或控制流图（CFG））来学习程序语义。由于程序执行的复杂性，执行结果依赖于多种程序状态和输入。此外，通过静态分析生成的CFG可能会高估实际的程序流程。而且，程序的规模通常不允许具有固定层数的图神经网络聚合全局信息。为解决这些问题，我们提出了DeepEXE，这是一种基于代理的隐式神经网络，能够模拟程序的执行路径。我们使用强化学习来增强每个程序状态转换时的分支决策，并创建一个动态环境来学习漏洞与特定程序状态之间的依赖关系。隐式定义的神经网络允许近乎无限的状态转换直至收敛，从而在更高层次上捕捉结构信息。实验在两个半合成数据集和两个真实世界数据集上进行。结果表明，DeepEXE是一种准确且高效的方法，优于现有的最先进漏洞检测方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamic+Neural+Control+Flow+Execution:+an+Agent-Based+Deep+Equilibrium+Approach+for+Binary+Vulnerability+Detection)|0|
|[Integrating Structure and Text for Enhancing Hyper-relational Knowledge Graph Representation via Structure Soft Prompt Tuning](https://doi.org/10.1145/3627673.3679698)|Lijie Li, Hui Wang, Jiahang Li, Xiaodi Xu, Ye Wang, Tao Ren|Harbin Engineering University, Harbin, Heilongjiang, China; State Library of Intelligent Game, Institute of Software Chinese Academy of Sciences, Beijing, China|Different from traditional knowledge graphs, where facts are usually represented as (subject, relation, object), hyper-relational knowledge graphs (HKGs) allow facts to be associated with additional relation-entity pairs to constrain the validity of facts. HKGs contain a substantial amount of textual information, which plays a crucial role in enriching representations. However, existing HKG embedding methods mainly rely on structural information but overlook textual information in HKGs, which are less effective in representing entities with limited structural information. To address this issue, the paper proposes HIST (Hyper-relational Knowledge Graph Encoder Integrating Structure and Text), which incorporates textual information and structural information in HKGs to enhance representations of entities and relations. HIST adopts the graph convolutional network to extract structural information and utilizes it to generate the Structure Soft Prompt. During the Structure Soft Prompt Tuning process, the textual information and structural information are fully integrated to generate more comprehensive representations. Additionally, an effective contrastive learning method for HKG embedding is formulated to improve the efficiency of negative sampling. Experimental results show that HIST achieves state-of-the-art performance on several public datasets. Our code is available at https://github.com/QieFangBaiLuQingYaJian/HIST.|与传统知识图谱不同，传统知识图谱中的事实通常表示为（主语，关系，宾语），而超关系知识图谱（HKGs）允许事实与额外的关系-实体对相关联，以约束事实的有效性。HKGs包含大量的文本信息，这些信息在丰富表示方面起着至关重要的作用。然而，现有的HKG嵌入方法主要依赖于结构信息，却忽略了HKGs中的文本信息，这在表示结构信息有限的实体时效果较差。为了解决这一问题，本文提出了HIST（整合结构与文本的超关系知识图谱编码器），它结合了HKGs中的文本信息和结构信息，以增强实体和关系的表示。HIST采用图卷积网络来提取结构信息，并利用其生成结构软提示。在结构软提示调优过程中，文本信息和结构信息被充分整合，以生成更全面的表示。此外，还提出了一种有效的HKG嵌入对比学习方法，以提高负采样的效率。实验结果表明，HIST在多个公开数据集上实现了最先进的性能。我们的代码可在https://github.com/QieFangBaiLuQingYaJian/HIST获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Integrating+Structure+and+Text+for+Enhancing+Hyper-relational+Knowledge+Graph+Representation+via+Structure+Soft+Prompt+Tuning)|0|
|[Seeing the Forest for the Trees: Road-Level Insights Assisted Lane-Level Traffic Prediction](https://doi.org/10.1145/3627673.3679600)|Shuhao Li, Yue Cui, Jingyi Xu, Jing Zhao, Fan Zhang, Weidong Yang, Xiaofang Zhou|Guangzhou University & GZHU-SCHB Intelligent Transportation Joint Lab, Guangzhou, China; Fudan University & Zhuhai Fudan Innovation Research Institute, Shanghai, China; Fudan University & Shanghai Key Laboratory of Data Science, Shanghai, China; The Hong Kong University of Science and Technology, Hong Kong SAR, China|Lane-level traffic prediction is crucial for refined smart city applications, yet the scarcity and quality issues of datasets hinder its development. To overcome these challenges, this study introduces a novel M ulti- c hannel g raph-structured V ariational A uto E ncoder model, McgVAE. This model integrates road-level information to provide a global perspective for lane prediction and performs integrated tasks through three interconnected channels: the road-level channel ensures accurate prediction of road traffic states and communicates closely with the data quality channel to share historical and predicted road information; the data quality channel leverages road-level information to identify and correct missing and noisy data; and finally, the lane channel uses the aforementioned information for lane-level traffic prediction. After extensive experimental comparisons with multiple baseline models across three datasets, the McgVAE model demonstrated outstanding predictive performance and the ability to handle data missingness and noise|车道级交通预测对于精细化智慧城市应用至关重要，然而数据集的稀缺性和质量问题阻碍了其发展。为了克服这些挑战，本研究引入了一种新颖的**多通道图结构变分自编码器模型**，即McgVAE。该模型整合了道路级信息，为车道预测提供全局视角，并通过三个相互关联的通道执行综合任务：**道路级通道**确保道路交通状态的准确预测，并与**数据质量通道**紧密通信，共享历史和预测的道路信息；**数据质量通道**利用道路级信息识别并校正缺失和噪声数据；最后，**车道通道**利用上述信息进行车道级交通预测。经过在三个数据集上与多个基线模型的广泛实验对比，McgVAE模型展现了卓越的预测性能以及处理数据缺失和噪声的能力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Seeing+the+Forest+for+the+Trees:+Road-Level+Insights+Assisted+Lane-Level+Traffic+Prediction)|0|
|[LLM-Empowered Few-Shot Node Classification on Incomplete Graphs with Real Node Degrees](https://doi.org/10.1145/3627673.3679861)|Yun Li, Yi Yang, Jiaqi Zhu, Hui Chen, Hongan Wang|; Institute of Software, Chinese Academy of Sciences, Beijing, China|Graphs constructed from real-world scenarios are often incomplete due to privacy restrictions or resource limitations, posing significant challenges for node classification, especially when labeled data are scarce. In many scenarios of incomplete graphs, the real node degrees, such as the number of followers in social networks or publications' references in citation networks, are easily accessible and informative, which could indicate the degree of incompleteness. However, most of existing researches of incomplete graphs focus on edge completion, but ignore the node completion with known node degrees. In this paper, we propose a new few-shot node classification problem on incomplete graphs with real node degrees. To deal with node completion, edge completion and label completion of this problem, we develop an effective Large Language Models (LLMs) empowered Graph Convolutional Network (GCN) model utilizing the real node Degrees, namely LLMDGCN. First, we leverage LLMs to initially fill in the missing nodes and labels. Next, we design an edge prediction module that employs the real node degrees and inter-category probability matrix to recover the missing edges for each node. We then iteratively train the GCN and the edge prediction module. The GCN generates pseudo labels, which the edge prediction module uses to restore edges, and these edges are fed back into the GCN to improve accuracy. Extensive experiments on four benchmark datasets demonstrate the effectiveness and robustness of our proposed method for the few-shot node classification on incomplete graphs with real node degrees.|由于隐私限制或资源限制，从现实场景中构建的图通常是不完整的，这给节点分类带来了重大挑战，尤其是在标注数据稀缺的情况下。在许多不完整图的场景中，真实的节点度（如社交网络中的粉丝数量或引文网络中的参考文献数量）很容易获取且具有信息量，这些信息可以指示图的完整性程度。然而，现有关于不完整图的研究大多集中在边的补全上，而忽略了利用已知节点度进行节点补全。本文提出了一种新的基于真实节点度的不完整图上的少样本节点分类问题。为了处理该问题的节点补全、边补全和标签补全，我们开发了一种有效的基于大语言模型（LLMs）的图卷积网络（GCN）模型，该模型利用真实节点度，称为LLMDGCN。首先，我们利用LLMs初步填充缺失的节点和标签。接着，我们设计了一个边预测模块，该模块利用真实节点度和类别间概率矩阵为每个节点恢复缺失的边。然后，我们迭代训练GCN和边预测模块。GCN生成伪标签，边预测模块利用这些伪标签恢复边，并将这些边反馈给GCN以提高准确性。在四个基准数据集上的大量实验表明，我们提出的方法在基于真实节点度的不完整图上的少样本节点分类中具有有效性和鲁棒性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LLM-Empowered+Few-Shot+Node+Classification+on+Incomplete+Graphs+with+Real+Node+Degrees)|0|
|[Design Element Aware Poster Layout Generation](https://doi.org/10.1145/3627673.3679557)|Yinan Li, Jia Chen, Yin Bai, Jia Cheng, Jun Lei|Meituan Inc, Chaoyang Qu, Beijing Shi, China|Despite the recent significant advancements in poster layout generation, existing works are mainly unaware of the given design elements (i.e., text, logo, and underlay), which leads to undesirable layouts or visual artifacts. The visual artifacts we refer to include (1) improper sizes, e.g., placing a short piece of text into a large textbox or long texts into small text boxes, and (2) image distortion, e.g., the stretched logo in Fig. 1. To advance research in this field, we propose a new design-element aware poster layout generation task, which require the generated layouts to not only have harmonic relationships but also fit well with the design elements. To address this task, we propose Design Element aware Transformer (DET), an encoder-decoder based transformer network, to generate reasonable layouts that fit not only the background images but also the design elements. The encoder extracts a fine-grained multi-scale representation from the background image and its saliency map. The decoder receives the background features and produces layouts conditioned on the content and desired sizes of the design elements. Adopting the multi-scale representation and the deformable attention in both the encoder and decoder enables our method to accurately understand/generate the spatial relationships between the background objects and design elements. We adapted three public poster layout generation datasets to fit our task and conducted experiments on them. In the meantime, we propose a new evaluation metric called AspDiff to measure whether the generated layout matches the given design elements. Quantitative and qualitative evaluation on three datasets demonstrates that DET yields superior results compared to other layout generation methods. Our code and datasets will be released.|尽管近年来在海报布局生成方面取得了显著进展，但现有工作大多未充分考虑给定的设计元素（即文本、标志和底图），这导致了不理想的布局或视觉瑕疵。我们提到的视觉瑕疵包括：（1）尺寸不当，例如将短文本放入大文本框或将长文本放入小文本框；（2）图像失真，例如图1中被拉伸的标志。为了推动该领域的研究，我们提出了一种新的设计元素感知的海报布局生成任务，要求生成的布局不仅具有和谐的关系，还要与设计元素良好契合。为了解决这一任务，我们提出了设计元素感知的Transformer（DET），这是一个基于编码器-解码器的Transformer网络，用于生成不仅适合背景图像，还适合设计元素的合理布局。编码器从背景图像及其显著图中提取细粒度的多尺度表示。解码器接收背景特征，并根据设计元素的内容和期望尺寸生成布局。在编码器和解码器中采用多尺度表示和可变形注意力机制，使我们的方法能够准确理解/生成背景对象与设计元素之间的空间关系。我们调整了三个公开的海报布局生成数据集以适应我们的任务，并在其上进行了实验。同时，我们提出了一种新的评估指标AspDiff，用于衡量生成的布局是否与给定的设计元素匹配。在三个数据集上的定量和定性评估表明，与其他布局生成方法相比，DET取得了更优的结果。我们的代码和数据集将公开发布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Design+Element+Aware+Poster+Layout+Generation)|0|
|[Learning from Novel Knowledge: Continual Few-shot Knowledge Graph Completion](https://doi.org/10.1145/3627673.3679734)|Zhuofeng Li, Haoxiang Zhang, Qiannan Zhang, Ziyi Kou, Shichao Pei|Shanghai University, Shanghai, China; University of Notre Dame, South Bend, USA; University of Massachusetts Boston, Boston, MA, USA; Cornell University, New York, USA|Knowledge graph (KG) completion has been increasingly recognized as a vital approach for uncovering missing knowledge and addressing the incompleteness issue in KGs. To enhance inference on rare relations and mitigate the impact of the long-tail distribution, the dominant strategy designs few-shot models following the meta-learning paradigm. However, these approaches typically operate under the assumption that KGs are available instantly, disregarding the newly emerging relations during KG enrichment. Thus, the emergence of these novel relations presents a need for few-shot models to continually learn from emerging knowledge. Although promising, two significant obstacles, i.e., catastrophic forgetting and the scarcity of novel relations, prevent effective learning from newly emerging relations. In this paper, we propose a novel framework designed to equip the few-shot model with the ability to learn sequentially from novel relations. Specifically, we introduce innovative strategies at both data and model levels: data-level rehearsal and model-level modulation to address catastrophic forgetting, alongside multi-view relation augmentation aimed at resolving the issue of insufficient novel relations. Extensive experiments conducted on real-world KGs validate the effectiveness of our proposed method.|知识图谱（KG）补全逐渐被视为揭示缺失知识、解决知识图谱不完整性问题的关键方法。为了增强对稀有关系的推理能力并缓解长尾分布的影响，主流策略遵循元学习范式设计少样本模型。然而，这些方法通常假设知识图谱是即时可用的，忽视了在知识图谱丰富过程中新出现的关系。因此，这些新关系的出现要求少样本模型能够持续从新兴知识中学习。尽管前景广阔，但两个主要障碍——灾难性遗忘和新关系的稀缺性——阻碍了从新关系中有效学习。本文提出了一种新颖的框架，旨在使少样本模型具备从新关系中顺序学习的能力。具体而言，我们在数据和模型两个层面引入了创新策略：数据层面的复习和模型层面的调节以应对灾难性遗忘，以及多视角关系增强旨在解决新关系不足的问题。在真实世界的知识图谱上进行的广泛实验验证了我们所提出方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+from+Novel+Knowledge:+Continual+Few-shot+Knowledge+Graph+Completion)|0|
|[Higher-order Spatio-temporal Physics-incorporated Graph Neural Network for Multivariate Time Series Imputation](https://doi.org/10.1145/3627673.3679775)|Guojun Liang, Prayag Tiwari, Slawomir Nowaczyk, Stefan Byttner|Halmstad University School of Information Technology|Exploring the missing values is an essential but challenging issue due to the complex latent spatio-temporal correlation and dynamic nature of time series. Owing to the outstanding performance in dealing with structure learning potentials, Graph Neural Networks (GNNs) and Recurrent Neural Networks (RNNs) are often used to capture such complex spatio-temporal features in multivariate time series. However, these data-driven models often fail to capture the essential spatio-temporal relationships when significant signal corruption occurs. Additionally, calculating the high-order neighbor nodes in these models is of high computational complexity. To address these problems, we propose a novel higher-order spatio-temporal physics-incorporated GNN (HSPGNN). Firstly, the dynamic Laplacian matrix can be obtained by the spatial attention mechanism. Then, the generic inhomogeneous partial differential equation (PDE) of physical dynamic systems is used to construct the dynamic higher-order spatio-temporal GNN to obtain the missing time series values. Moreover, we estimate the missing impact by Normalizing Flows (NF) to evaluate the importance of each node in the graph for better explainability. Experimental results on four benchmark datasets demonstrate the effectiveness of HSPGNN and the superior performance when combining various order neighbor nodes. Also, graph-like optical flow, dynamic graphs, and missing impact can be obtained naturally by HSPGNN, which provides better dynamic analysis and explanation than traditional data-driven models. Our code is available at https://github.com/gorgen2020/HSPGNN.|探索缺失值是一个至关重要但具有挑战性的问题，这源于时间序列中复杂的潜在时空相关性和动态特性。由于在处理结构学习潜力方面表现出色，图神经网络（GNNs）和循环神经网络（RNNs）通常用于捕捉多元时间序列中的复杂时空特征。然而，当发生显著信号损坏时，这些数据驱动模型往往无法捕捉到关键的时空关系。此外，在这些模型中计算高阶邻居节点具有较高的计算复杂度。为了解决这些问题，我们提出了一种新颖的高阶时空物理融合图神经网络（HSPGNN）。首先，通过空间注意力机制可以获得动态拉普拉斯矩阵。然后，利用物理动态系统的通用非齐次偏微分方程（PDE）构建动态高阶时空GNN，以获取缺失的时间序列值。此外，我们通过归一化流（NF）估计缺失影响，以评估图中每个节点的重要性，从而提高模型的可解释性。在四个基准数据集上的实验结果表明，HSPGNN的有效性以及在结合不同阶邻居节点时的优越性能。此外，HSPGNN可以自然地获得类似光流的图、动态图和缺失影响，这比传统的数据驱动模型提供了更好的动态分析和解释。我们的代码可在https://github.com/gorgen2020/HSPGNN获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Higher-order+Spatio-temporal+Physics-incorporated+Graph+Neural+Network+for+Multivariate+Time+Series+Imputation)|0|
|[Towards Robust Vision Transformer via Masked Adaptive Ensemble](https://doi.org/10.1145/3627673.3679750)|Fudong Lin, Jiadong Lou, Xu Yuan, NianFeng Tzeng||Adversarial training (AT) can help improve the robustness of Vision Transformers (ViT) against adversarial attacks by intentionally injecting adversarial examples into the training data. However, this way of adversarial injection inevitably incurs standard accuracy degradation to some extent, thereby calling for a trade-off between standard accuracy and robustness. Besides, the prominent AT solutions are still vulnerable to adaptive attacks. To tackle such shortcomings, this paper proposes a novel ViT architecture, including a detector and a classifier bridged by our newly developed adaptive ensemble. Specifically, we empirically discover that detecting adversarial examples can benefit from the Guided Backpropagation technique. Driven by this discovery, a novel Multi-head Self-Attention (MSA) mechanism is introduced to enhance our detector to sniff adversarial examples. Then, a classifier with two encoders is employed for extracting visual representations respectively from clean images and adversarial examples, with our adaptive ensemble to adaptively adjust the proportion of visual representations from the two encoders for accurate classification. This design enables our ViT architecture to achieve a better trade-off between standard accuracy and robustness. Besides, our adaptive ensemble technique allows us to mask off a random subset of image patches within input data, boosting our ViT's robustness against adaptive attacks, while maintaining high standard accuracy. Experimental results exhibit that our ViT architecture, on CIFAR-10, achieves the best standard accuracy and adversarial robustness of 90.3|对抗训练（Adversarial Training, AT）通过在训练数据中故意注入对抗样本来帮助提升视觉Transformer（Vision Transformers, ViT）对对抗攻击的鲁棒性。然而，这种对抗注入方式不可避免地会在一定程度上导致标准精度下降，因此需要在标准精度和鲁棒性之间进行权衡。此外，现有的AT解决方案仍然容易受到自适应攻击的影响。为了解决这些不足，本文提出了一种新颖的ViT架构，包括一个检测器和一个分类器，并通过我们新开发的自适应集成方法进行连接。具体来说，我们通过实验发现，检测对抗样本可以从Guided Backpropagation技术中受益。基于这一发现，我们引入了一种新颖的多头自注意力机制（Multi-head Self-Attention, MSA）来增强检测器，使其能够更有效地嗅探对抗样本。然后，我们采用了一个带有两个编码器的分类器，分别从干净图像和对抗样本中提取视觉表示，并通过我们的自适应集成方法自适应地调整来自两个编码器的视觉表示比例，以实现准确的分类。这种设计使我们的ViT架构能够在标准精度和鲁棒性之间实现更好的权衡。此外，我们的自适应集成技术允许我们在输入数据中随机屏蔽一部分图像块，从而提升ViT对自适应攻击的鲁棒性，同时保持较高的标准精度。实验结果表明，我们的ViT架构在CIFAR-10数据集上实现了90.3%的最佳标准精度和对抗鲁棒性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Robust+Vision+Transformer+via+Masked+Adaptive+Ensemble)|0|
|[Hierarchical Spatio-Temporal Graph Learning Based on Metapath Aggregation for Emergency Supply Forecasting](https://doi.org/10.1145/3627673.3679854)|Li Lin, Kaiwen Xia, Anqi Zheng, Shijie Hu, Shuai Wang|Southeast University & JD Logistics, Nanjing, China; Southeast University, Nanjing, China|Integrated Warehousing and Distribution Supply Networks (IWDSN) have shown their high efficiency in E-commerce. Efficient supply capacity prediction is crucial for logistics systems to maintain the delivery capacity to meet users' requirements. However, unforeseen events such as extreme weather and public health emergencies pose challenges in supply forecasting. Previous work mainly infers supply optimization based on the invariant topology of logistic networks, neglecting dynamic routing and distinct node effects reacting to emergencies. To address these challenges, the hierarchical relations among warehouses, sorting centers, and delivery stations in logistic networks are necessary to learn the diverse reactions. In this paper, we propose a hierarchical spatio-temporal graph learning model to predict the emergency supply capacity of IWDSN based on micro and macro graphs. The micro graph shows transportation connectivity while the macro graph shows the geographical correlation. Specifically, it consists of three components. (1) For micro graphs, a metapath aggregation strategy is designed to capture dynamic routing information on both route-view and event-view graphs. (2) For macro graphs, a bipartite graph learning approach to extract spatial representations. (3) For spatio-temporal feature fusion, the spatio-temporal joint forecasting module combines the temporal feature from the time-series encoder with hierarchical spatial features to predict the future supply capacity. The extensive experiments on two real-world datasets demonstrate the effectiveness of our proposed model, which achieves state-of-the-art performance compared with advanced baselines.|集成仓储与配送供应链网络（Integrated Warehousing and Distribution Supply Networks, IWDSN）在电子商务中展现了其高效性。高效的供应能力预测对于物流系统维持配送能力以满足用户需求至关重要。然而，极端天气和公共卫生事件等不可预见的事件给供应预测带来了挑战。以往的研究主要基于物流网络的不变拓扑结构来推断供应优化，忽略了动态路由和节点在面对突发事件时的不同反应。为了解决这些挑战，需要学习仓库、分拣中心和配送站在物流网络中的层次关系，以捕捉多样化的反应。本文提出了一种基于微观和宏观图的分层时空图学习模型，用于预测IWDSN的应急供应能力。微观图展示了运输连通性，而宏观图则展示了地理相关性。具体而言，该模型由三个部分组成：（1）对于微观图，设计了一种元路径聚合策略，以捕捉路由视图和事件视图图中的动态路由信息；（2）对于宏观图，采用了一种二分图学习方法提取空间表示；（3）对于时空特征融合，时空联合预测模块将时间序列编码器生成的时间特征与分层空间特征相结合，以预测未来的供应能力。在两个真实世界数据集上的大量实验证明了我们提出的模型的有效性，与先进的基线模型相比，该模型实现了最先进的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Spatio-Temporal+Graph+Learning+Based+on+Metapath+Aggregation+for+Emergency+Supply+Forecasting)|0|
|[Self-Supervision Improves Diffusion Models for Tabular Data Imputation](https://doi.org/10.1145/3627673.3679829)|Yixin Liu, Thalaiyasingam Ajanthan, Hisham Husain, Vu Nguyen||The ubiquity of missing data has sparked considerable attention and focus on tabular data imputation methods. Diffusion models, recognized as the cutting-edge technique for data generation, demonstrate significant potential in tabular data imputation tasks. However, in pursuit of diversity, vanilla diffusion models often exhibit sensitivity to initialized noises, which hinders the models from generating stable and accurate imputation results. Additionally, the sparsity inherent in tabular data poses challenges for diffusion models in accurately modeling the data manifold, impacting the robustness of these models for data imputation. To tackle these challenges, this paper introduces an advanced diffusion model named Self-supervised imputation Diffusion Model (SimpDM for brevity), specifically tailored for tabular data imputation tasks. To mitigate sensitivity to noise, we introduce a self-supervised alignment mechanism that aims to regularize the model, ensuring consistent and stable imputation predictions. Furthermore, we introduce a carefully devised state-dependent data augmentation strategy within SimpDM, enhancing the robustness of the diffusion model when dealing with limited data. Extensive experiments demonstrate that SimpDM matches or outperforms state-of-the-art imputation methods across various scenarios.|缺失数据的普遍性引发了对表格数据填补方法的高度关注和重视。扩散模型作为数据生成的前沿技术，在表格数据填补任务中展现出显著潜力。然而，为了追求多样性，传统的扩散模型往往对初始化噪声表现出敏感性，这阻碍了模型生成稳定且准确的填补结果。此外，表格数据固有的稀疏性给扩散模型在准确建模数据流形方面带来了挑战，影响了这些模型在数据填补中的鲁棒性。为了解决这些问题，本文提出了一种名为自监督填补扩散模型（简称SimpDM）的先进扩散模型，专门为表格数据填补任务量身定制。为了降低对噪声的敏感性，我们引入了一种自监督对齐机制，旨在对模型进行正则化，确保一致且稳定的填补预测。此外，我们在SimpDM中引入了一种精心设计的状态依赖数据增强策略，增强了扩散模型在处理有限数据时的鲁棒性。大量实验表明，SimpDM在各种场景下均能匹配或超越最先进的填补方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-Supervision+Improves+Diffusion+Models+for+Tabular+Data+Imputation)|0|
|[KMCT: k-Means Clustering of Trajectories Efficiently in Location-Based Services](https://doi.org/10.1145/3627673.3679848)|Yuanjun Liu, Guanfeng Liu, Qingzhi Ma, Zhixu Li, Shiting Wen, Lei Zhao, An Liu|School of Computer Science and Technology, Soochow University, Suzhou, China; School of Computer Science and Technology, Fudan University, Shanghai, China; School of Computer and Data Engneering, NingboTech University, Ningbo, China; School of Computing, Macquarie University, Sydney, Australia|With the widespread use of GPS devices and the advancement of location-based services, a vast amount of trajectory data has been collected and mined for various applications. Trajectory clustering, which categorizes trajectories into distinct groups, is the fundamental functionality of trajectory data mining. The challenge is how to cluster on a mass of trajectory data efficiently and universally with satisfying results. The raw trajectory clustering algorithms are universal, but trapped in the dilemma between efficiency and desirable results. Other approaches, such as density-based, road network-based, and deep learning-based algorithms, encounter issues like high time complexity, loss of trajectory integrity, reliance on road networks, and data quality during training. To tackle these challenges, we first propose the efficient KMCT (k-Means Clustering of Trajectories) algorithm based on a semantic interpolation transformation to cluster raw trajectories and achieve satisfying results. Additionally, we introduce the DA-KMCT (Density Accelerated k-Means Clustering of Trajectories) algorithm to further boost the clustering process based on trajectory densities and an optimized centroid selecting strategy. Moreover, we present a novel clustering evaluation method called IOD, which efficiently estimates clustering results on large-scale datasets with linear time complexity. Experimental results on real-world datasets demonstrate that KMCT and DA-KMCT outperform five related methods in terms of clustering quality and time efficiency, and the proposed IOD evaluation shows a strong correlation with the Silhouette Coefficient, offering a reliable and efficient alternative for evaluating clustering results.|随着GPS设备的广泛应用和基于位置服务的不断发展，大量的轨迹数据被收集并挖掘用于各种应用。轨迹聚类是将轨迹分类为不同组的基本功能，是轨迹数据挖掘的核心。面临的挑战是如何在大量轨迹数据上高效且普遍地进行聚类，并获得令人满意的结果。原始的轨迹聚类算法具有普适性，但在效率和理想结果之间陷入了两难境地。其他方法，如基于密度的、基于路网的和基于深度学习的算法，则面临高时间复杂度、轨迹完整性丢失、对路网的依赖以及训练过程中数据质量等问题。为了应对这些挑战，我们首先提出了一种基于语义插值变换的高效KMCT（k-Means Clustering of Trajectories）算法，用于对原始轨迹进行聚类并获得令人满意的结果。此外，我们引入了DA-KMCT（Density Accelerated k-Means Clustering of Trajectories）算法，通过基于轨迹密度和优化质心选择策略进一步加速聚类过程。此外，我们提出了一种新的聚类评估方法IOD，该方法能够在线性时间复杂度下高效估计大规模数据集上的聚类结果。在真实数据集上的实验结果表明，KMCT和DA-KMCT在聚类质量和时间效率方面优于五种相关方法，且所提出的IOD评估方法与Silhouette Coefficient表现出强相关性，为评估聚类结果提供了一种可靠且高效的替代方案。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KMCT:+k-Means+Clustering+of+Trajectories+Efficiently+in+Location-Based+Services)|0|
|[A Universal and Interpretable Method for Enhancing Stock Price Prediction](https://doi.org/10.1145/3627673.3679731)|Yuchen Liu, Shimin Di, Lei Chen, Xiaofang Zhou, Fei Lin|; AITOPIA Artificial Intelligence Technology Co., Ltd, Beijing, China; Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; Hong Kong University of Science and Technology, Hong Kong SAR, China|The prediction of stock prices is a highly sought-after topic in the data mining field. In recent decades, many promising methods have been proposed and widely adopted for stock price prediction. However, these methods have inherent limitations, such as low accuracy, lack of transparency, and failure to consider the interactions among stock factors. To address these issues, we propose a UNIversal and interpretable framework for enhancing Stock Price Prediction (abbreviated to UniSPP), which is capable of modeling the interactions among stock factors. UniSPP first builds a fully connected graph, where the nodes and edges are the stock factors and interactions between them, respectively. However, it is a non-trivial task to discover a proper feature interaction subgraph from a large space, especially in discrete graph modeling. Therefore, UniSPP proposes a novel idea to mine the real factor interactions by iteratively sampling subgraphs and optimizing the sampling controller. Empirical studies show that our framework can be incorporated with many popular forecasting models and can effectively discover the suitable factor interaction, which can significantly improve the prediction results of existing models.|股票价格预测是数据挖掘领域中备受关注的热点话题。近几十年来，许多有前景的方法被提出并广泛应用于股票价格预测中。然而，这些方法存在固有的局限性，例如准确性低、缺乏透明度以及未能考虑股票因子之间的相互作用。为了解决这些问题，我们提出了一种通用且可解释的框架，用于增强股票价格预测（简称UniSPP），该框架能够建模股票因子之间的相互作用。UniSPP首先构建了一个全连接图，其中节点和边分别代表股票因子及其之间的相互作用。然而，从大规模空间中发掘合适的特征相互作用子图并非易事，尤其是在离散图建模中。因此，UniSPP提出了一种新颖的思路，通过迭代采样子图并优化采样控制器来挖掘真实的因子相互作用。实证研究表明，我们的框架能够与多种流行的预测模型结合，并能够有效发现合适的因子相互作用，从而显著提升现有模型的预测效果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Universal+and+Interpretable+Method+for+Enhancing+Stock+Price+Prediction)|0|
|[Multivariate Time-Series Anomaly Detection based on Enhancing Graph Attention Networks with Topological Analysis](https://doi.org/10.1145/3627673.3679614)|Zhe Liu, Xiang Huang, Jingyun Zhang, Zhifeng Hao, Li Sun, Hao Peng||Unsupervised anomaly detection in time series is essential in industrial applications, as it significantly reduces the need for manual intervention. Multivariate time series pose a complex challenge due to their feature and temporal dimensions. Traditional methods use Graph Neural Networks (GNNs) or Transformers to analyze spatial while RNNs to model temporal dependencies. These methods focus narrowly on one dimension or engage in coarse-grained feature extraction, which can be inadequate for large datasets characterized by intricate relationships and dynamic changes. This paper introduces a novel temporal model built on an enhanced Graph Attention Network (GAT) for multivariate time series anomaly detection called TopoGDN. Our model analyzes both time and feature dimensions from a fine-grained perspective. First, we introduce a multi-scale temporal convolution module to extract detailed temporal features. Additionally, we present an augmented GAT to manage complex inter-feature dependencies, which incorporates graph topology into node features across multiple scales, a versatile, plug-and-play enhancement that significantly boosts the performance of GAT. Our experimental results confirm that our approach surpasses the baseline models on four datasets, demonstrating its potential for widespread application in fields requiring robust anomaly detection. The code is available at https://github.com/ljj-cyber/TopoGDN.|时间序列中的无监督异常检测在工业应用中至关重要，因为它显著减少了对人工干预的需求。多变量时间序列由于其特征和时间维度的复杂性，带来了巨大的挑战。传统方法使用图神经网络（GNN）或Transformer来分析空间维度，同时使用循环神经网络（RNN）来建模时间依赖性。这些方法通常只专注于单一维度或进行粗粒度的特征提取，这对于具有复杂关系和动态变化的大规模数据集来说可能是不够的。本文提出了一种基于增强型图注意力网络（GAT）的新型时间模型，称为TopoGDN，用于多变量时间序列异常检测。我们的模型从细粒度的角度同时分析时间和特征维度。首先，我们引入了一个多尺度时间卷积模块，以提取详细的时间特征。此外，我们提出了一种增强的GAT来管理复杂的特征间依赖关系，该方法将图拓扑结构融入到多尺度的节点特征中，这是一种多功能、即插即用的增强方法，显著提升了GAT的性能。我们的实验结果证实，该方法在四个数据集上均超越了基线模型，展示了其在需要强大异常检测的领域中广泛应用的潜力。代码可在https://github.com/ljj-cyber/TopoGDN获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multivariate+Time-Series+Anomaly+Detection+based+on+Enhancing+Graph+Attention+Networks+with+Topological+Analysis)|0|
|[MOAT: Graph Prompting for 3D Molecular Graphs](https://doi.org/10.1145/3627673.3679628)|Qingqing Long, Yuchen Yan, Wentao Cui, Wei Ju, Zhihong Zhu, Yuanchun Zhou, Xuezhi Wang, Meng Xiao|CNIC, CAS & UCAS, Beijing, China; Sichuan University, Beijing, China; Peking University, Beijing, China|Molecular property prediction stands as a cornerstone task in AI-driven drug design and discovery, wherein the atoms within a molecule serve as nodes, collectively forming a graph with bonds acting as edges. Given the crucial role of geometric structures in molecular property prediction, the integration of 3D information with various graph learning methods has been explored to enhance prediction performance. Despite the increasing adoption of the "Graph pre-training and fine-tuning" paradigm to refine molecular representations, a significant challenge persists due to the misalignment between pre-training objectives and downstream tasks. Drawing inspiration from prompt tuning techniques in Natural Language Processing (NLP), several graph prompt-based methods have emerged. However, existing approaches tend to overlook the unique properties inherent in molecular graphs. To address this gap, our paper introduces a novel approach named 3D MO lecul A rpromp T (MOAT) designed specifically for geometric molecules. Specifically, we propose atom-level prompts to capture atom distribution, geometry-level prompts tailored for molecular conformers, where different conformations have distinct chemical properties, and task-level prompts to leverage functional group properties. Results on both 3D and 2D downstream tasks demonstrate its ability to successfully bridge the data gap across diverse settings. To the best of our knowledge, this paper is the first attempt to introduce geometric graph-prompting learning for molecules.|分子性质预测是人工智能驱动的药物设计与发现中的一项基石任务，其中分子内的原子作为节点，共同构成一个以化学键为边的图。鉴于几何结构在分子性质预测中的关键作用，研究者们探索了将三维信息与各种图学习方法相结合以提升预测性能。尽管“图预训练与微调”范式在优化分子表示方面得到越来越多的应用，但由于预训练目标与下游任务之间的不一致性，仍存在显著挑战。受自然语言处理（NLP）中提示调优技术的启发，一些基于图提示的方法应运而生。然而，现有方法往往忽视了分子图所特有的属性。为了填补这一空白，本文提出了一种名为**3D MOleculAr prompT (MOAT)**的新方法，专门为几何分子设计。具体而言，我们提出了**原子级提示**以捕捉原子分布，**几何级提示**针对分子构象体（不同构象具有不同的化学性质），以及**任务级提示**以利用官能团特性。在三维和二维下游任务上的结果表明，该方法能够成功弥合不同场景下的数据差距。据我们所知，本文是首次尝试为分子引入几何图提示学习的研究。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MOAT:+Graph+Prompting+for+3D+Molecular+Graphs)|0|
|[A Knowledge-Enhanced Transformer-FL Method for Fault Root Cause Localization](https://doi.org/10.1145/3627673.3679816)|Zhe Lv, Yaqiong Liu, Xidian Wang, Peng Gao, Zhouyuan Li, Yuanzhen Jiang|China Mobile Group Design Institute Co., Ltd., Beijing, China; BKL-NAC & BL-AIN, Beijing University of Posts and Telecommunications, Beijing, China|Root cause analysis for faults is one of the core tasks in the operation and maintenance of communication networks. Although artificial intelligence techniques can be used to assist manual inspections, fault diagnosis is still a tough problem. In the scenario of fault root cause localization, insufficient associated information makes it difficult to accurately determine the root cause. Meanwhile, it is a big challenge to extract as many feature details as possible from limited information and then fully utilize them. Therefore, this paper proposes a Knowledge-Enhanced Transformer-FL method, namely, KETrans-FL, to address the problem of root cause localization, by treating it as a multi-class classification problem. Our method first constructs a knowledge graph for knowledge enhancement, which consists of four types of nodes (base station, alarm, fault and alarm level) and their relationships based on the network operations. This knowledge enhancement technique incorporates real operation data and other external knowledge (e.g., alarm level) to serve as the source of feature information and thus can extract statistical and embedded features. Then, our method designs a Trans-FL (Transformer-Focal Loss) model, which uses the adapted Transformer encoder to learn the correlation information between input features to generate classification probabilities and employs Focal Loss as the loss function to mitigate severe class imbalance in the multi-class classification problem. Experimental results show that our proposed KETrans-FL method achieves a classification accuracy of nearly 91% and an average AUC score of 93%, indicating a significant improvement on fault root cause localization compared to baseline models. In addition, experimental results also validate the remarkable effect of our knowledge enhancement technique on improving the final classification accuracy.|故障根因分析是通信网络运维中的核心任务之一。尽管可以利用人工智能技术辅助人工检查，但故障诊断仍然是一个难题。在故障根因定位的场景中，关联信息不足使得难以准确确定根因。同时，从有限的信息中尽可能提取特征细节并充分利用这些信息也是一大挑战。因此，本文提出了一种知识增强的Transformer-FL方法，即KETrans-FL，通过将根因定位问题视为多分类问题来解决。我们的方法首先构建了一个知识图谱用于知识增强，该图谱由四种类型的节点（基站、告警、故障和告警等级）及其基于网络运维的关系组成。这种知识增强技术结合了实际运维数据和其他外部知识（如告警等级），作为特征信息的来源，从而能够提取统计特征和嵌入特征。然后，我们的方法设计了一个Trans-FL（Transformer-Focal Loss）模型，该模型使用改进的Transformer编码器学习输入特征之间的关联信息以生成分类概率，并采用Focal Loss作为损失函数，以缓解多分类问题中的严重类别不平衡。实验结果表明，我们提出的KETrans-FL方法实现了近91%的分类准确率和93%的平均AUC得分，表明与基线模型相比，在故障根因定位方面有显著提升。此外，实验结果也验证了我们的知识增强技术在提高最终分类准确率方面的显著效果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Knowledge-Enhanced+Transformer-FL+Method+for+Fault+Root+Cause+Localization)|0|
|[Hierarchical Structure Construction on Hypergraphs](https://doi.org/10.1145/3627673.3679765)|Qi Luo, Wenjie Zhang, Zhengyi Yang, Dong Wen, Xiaoyang Wang, Dongxiao Yu, Xuemin Lin|Shanghai Jiao Tong University, Shanghai, China; University of New South Wales, Sydney, Australia; Shandong University, Qingdao, China|Exploring the hierarchical structure of graphs presents notable advantages for graph analysis, revealing insights ranging from individual vertex behavior to community distribution and overall graph stability. This paper studies hierarchical structures within hypergraphs, where a hyperedge can connect multiple vertices. We observed that directly extending hierarchical frameworks from pairwise graphs to hypergraphs overlooks high-order interactions and can result in either high computational complexity or sparse hierarchy structure. To address this challenge, we introduce a dual-layer hypergraph hierarchy consisting of a primary hierarchy and a secondary hierarchy, enabling the construction of a refined hypergraph hierarchy in linear time. The dual-layer hierarchy establishes a global hierarchy based on vertex cohesion, utilizing vertex-induced subhypergraphs, and a local hierarchy based on hyperedge containment, employing edge-induced subhypergraphs. The combination of global and local hierarchy mitigates the homogeneity and sparsity issues inherent in single-layer hierarchies, allowing more effective modeling of high-order interactions. Furthermore, we propose an efficient hierarchical construction algorithm by leveraging a novel hyperedge-based disjoint set to identify connected subhypergraphs. Additionally, to optimize the local hierarchy further and prevent the emergence of excessively redundant levels, we introduce a compact local hierarchy by defining a restricted subgraph metric to eliminate redundancy caused by large-sized hyperedges. Empirical studies on real-world hypergraphs demonstrate the effectiveness of our approach.|探索图的分层结构为图分析带来了显著优势，能够揭示从单个顶点行为到社区分布以及整体图稳定性的多方面洞察。本文研究了超图中的分层结构，其中超边可以连接多个顶点。我们观察到，直接将分层框架从成对图扩展到超图会忽略高阶交互，并可能导致高计算复杂度或稀疏的分层结构。为了解决这一挑战，我们引入了一种双层超图分层结构，包括主层次和次层次，从而能够在线性时间内构建精细的超图分层结构。双层分层结构通过顶点诱导子超图建立基于顶点凝聚的全局层次，并通过边诱导子超图建立基于超边包含的局部层次。全局层次与局部层次的结合缓解了单层分层结构固有的同质性和稀疏性问题，使得高阶交互的建模更加有效。此外，我们提出了一种基于超边的并查集的高效分层构建算法，用于识别连通的子超图。为了进一步优化局部层次并防止出现过多的冗余层级，我们引入了一种紧凑的局部层次结构，通过定义受限子图度量来消除由大规模超边引起的冗余。在真实世界超图上的实证研究证明了我们方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Structure+Construction+on+Hypergraphs)|0|
|[Data Void Exploits: Tracking & Mitigation Strategies](https://doi.org/10.1145/3627673.3679781)|Miro Mannino, Junior Garcia, Reem Hazim, Azza Abouzied, Paolo Papotti||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Data+Void+Exploits:+Tracking+&+Mitigation+Strategies)|0|
|[PIP: Prototypes-Injected Prompt for Federated Class Incremental Learning](https://doi.org/10.1145/3627673.3679794)|Muhammad Anwar Ma'sum, Mahardhika Pratama, Savitha Ramasamy, Lin Liu, Habibullah Habibullah, Ryszard Kowalczyk||Federated Class Incremental Learning (FCIL) is a new direction in continual learning (CL) for addressing catastrophic forgetting and non-IID data distribution simultaneously. Existing FCIL methods call for high communication costs and exemplars from previous classes. We propose a novel rehearsal-free method for FCIL named prototypes-injected prompt (PIP) that involves 3 main ideas: a) prototype injection on prompt learning, b) prototype augmentation, and c) weighted Gaussian aggregation on the server side. Our experiment result shows that the proposed method outperforms the current state of the arts (SOTAs) with a significant improvement (up to 33 and TinyImageNet datasets. Our extensive analysis demonstrates the robustness of PIP in different task sizes, and the advantage of requiring smaller participating local clients, and smaller global rounds. For further study, source codes of PIP, baseline, and experimental logs are shared publicly in https://github.com/anwarmaxsum/PIP.|联邦类增量学习（Federated Class Incremental Learning, FCIL）是持续学习（Continual Learning, CL）领域中的一个新兴方向，旨在同时解决灾难性遗忘和非独立同分布（non-IID）数据分布问题。现有的FCIL方法通常需要较高的通信成本，并且依赖于先前类别的样本。我们提出了一种无需样本回放的新颖FCIL方法，称为原型注入提示（Prototypes-Injected Prompt, PIP），该方法包含三个主要创新点：a) 在提示学习中进行原型注入，b) 原型增强，以及c) 服务器端的加权高斯聚合。实验结果表明，所提出的方法在CIFAR100和TinyImageNet数据集上显著优于当前的最先进方法（SOTAs），性能提升高达33%。我们进行了广泛的分析，证明了PIP在不同任务规模下的鲁棒性，以及在需要较少参与本地客户端和较少全局轮次方面的优势。为了进一步研究，PIP的源代码、基线方法和实验日志已在https://github.com/anwarmaxsum/PIP上公开分享。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PIP:+Prototypes-Injected+Prompt+for+Federated+Class+Incremental+Learning)|0|
|[Link Polarity Prediction from Sparse and Noisy Labels via Multiscale Social Balance](https://doi.org/10.1145/3627673.3679786)|Marco Minici, Federico Cinus, Francesco Bonchi, Giuseppe Manco||Signed Graph Neural Networks (SGNNs) have recently gained attention as an effective tool for several learning tasks on signed networks, i.e., graphs where edges have an associated polarity. One of these tasks is to predict the polarity of the links for which this information is missing, starting from the network structure and the other available polarities. However, when the available polarities are few and potentially noisy, such a task becomes challenging. In this work, we devise a semi-supervised learning framework that builds around the novel concept of multiscale social balance to improve the prediction of link polarities in settings characterized by limited data quantity and quality. Our model-agnostic approach can seamlessly integrate with any SGNN architecture, dynamically reweighting the importance of each data sample while making strategic use of the structural information from unlabeled edges combined with social balance theory. Empirical validation demonstrates that our approach outperforms established baseline models, effectively addressing the limitations imposed by noisy and sparse data. This result underlines the benefits of incorporating multiscale social balance into SGNNs, opening new avenues for robust and accurate predictions in signed network analysis.|有符号图神经网络（SGNNs）近年来作为一种有效的工具，在处理有符号网络（即边带有极性属性的图）上的多种学习任务中获得了关注。其中一项任务是基于网络结构和其他已知的极性信息，预测那些缺失极性信息的链接的极性。然而，当可用的极性信息较少且可能存在噪声时，这一任务变得极具挑战性。  

在本研究中，我们设计了一种半监督学习框架，围绕多尺度社会平衡这一新概念展开，以在数据数量和质量有限的场景下提升链接极性的预测效果。我们的模型无关方法可以无缝集成到任何SGNN架构中，动态调整每个数据样本的重要性权重，同时策略性地利用未标记边的结构信息并结合社会平衡理论。  

实验验证表明，我们的方法优于现有的基准模型，有效解决了噪声和稀疏数据带来的限制。这一结果凸显了将多尺度社会平衡融入SGNN的优势，为有符号网络分析中实现鲁棒且准确的预测开辟了新的途径。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Link+Polarity+Prediction+from+Sparse+and+Noisy+Labels+via+Multiscale+Social+Balance)|0|
|[LLaVA-Chef: A Multi-modal Generative Model for Food Recipes](https://doi.org/10.1145/3627673.3679562)|Fnu Mohbat, Mohammed J. Zaki||In the rapidly evolving landscape of online recipe sharing within a globalized context, there has been a notable surge in research towards comprehending and generating food recipes. Recent advancements in large language models (LLMs) like GPT-2 and LLaVA have paved the way for Natural Language Processing (NLP) approaches to delve deeper into various facets of food-related tasks, encompassing ingredient recognition and comprehensive recipe generation. Despite impressive performance and multi-modal adaptability of LLMs, domain-specific training remains paramount for their effective application. This work evaluates existing LLMs for recipe generation and proposes LLaVA-Chef, a novel model trained on a curated dataset of diverse recipe prompts in a multi-stage approach. First, we refine the mapping of visual food image embeddings to the language space. Second, we adapt LLaVA to the food domain by fine-tuning it on relevant recipe data. Third, we utilize diverse prompts to enhance the model's recipe comprehension. Finally, we improve the linguistic quality of generated recipes by penalizing the model with a custom loss function. LLaVA-Chef demonstrates impressive improvements over pretrained LLMs and prior works. A detailed qualitative analysis reveals that LLaVA-Chef generates more detailed recipes with precise ingredient mentions, compared to existing approaches.|在全球化的背景下，随着在线食谱分享的快速发展，理解和生成食物食谱的研究显著增加。最近，像GPT-2和LLaVA这样的大型语言模型（LLMs）的进展为自然语言处理（NLP）方法深入探索与食物相关的各种任务铺平了道路，这些任务包括食材识别和全面的食谱生成。尽管LLMs表现出色且具备多模态适应性，但领域特定的训练对于其有效应用仍然至关重要。本研究评估了现有的LLMs在食谱生成方面的表现，并提出了LLaVA-Chef，这是一个在多阶段方法中基于精选的多样化食谱提示数据集训练的新模型。首先，我们改进了视觉食物图像嵌入到语言空间的映射。其次，我们通过在相关食谱数据上进行微调，将LLaVA适应到食物领域。第三，我们利用多样化的提示来增强模型的食谱理解能力。最后，我们通过使用自定义的损失函数惩罚模型，提高了生成食谱的语言质量。LLaVA-Chef在预训练的LLMs和先前工作的基础上展示了显著的改进。详细的定性分析表明，与现有方法相比，LLaVA-Chef生成的食谱更加详细，并且包含了精确的食材提及。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LLaVA-Chef:+A+Multi-modal+Generative+Model+for+Food+Recipes)|0|
|[Let Silence Speak: Enhancing Fake News Detection with Generated Comments from Large Language Models](https://doi.org/10.1145/3627673.3679519)|Qiong Nan, Qiang Sheng, Juan Cao, Beizhe Hu, Danding Wang, Jintao Li||Fake news detection plays a crucial role in protecting social media users and maintaining a healthy news ecosystem. Among existing works, comment-based fake news detection methods are empirically shown as promising because comments could reflect users' opinions, stances, and emotions and deepen models' understanding of fake news. Unfortunately, due to exposure bias and users' different willingness to comment, it is not easy to obtain diverse comments in reality, especially for early detection scenarios. Without obtaining the comments from the “silent” users, the perceived opinions may be incomplete, subsequently affecting news veracity judgment. In this paper, we explore the possibility of finding an alternative source of comments to guarantee the availability of diverse comments, especially those from silent users. Specifically, we propose to adopt large language models (LLMs) as a user simulator and comment generator, and design GenFEND, a generated feedback-enhanced detection framework, which generates comments by prompting LLMs with diverse user profiles and aggregating generated comments from multiple subpopulation groups. Experiments demonstrate the effectiveness of GenFEND and further analysis shows that the generated comments cover more diverse users and could even be more effective than actual comments.|虚假新闻检测在保护社交媒体用户和维护健康的新闻生态系统中起着至关重要的作用。在现有研究中，基于评论的虚假新闻检测方法被实证证明具有潜力，因为评论可以反映用户的观点、立场和情感，并加深模型对虚假新闻的理解。然而，由于曝光偏差和用户评论意愿的不同，在现实中获取多样化的评论并不容易，尤其是在早期检测场景中。如果无法获取“沉默”用户的评论，所感知到的观点可能是不完整的，从而影响新闻真实性的判断。在本文中，我们探索了寻找替代评论来源的可能性，以确保获取多样化的评论，特别是来自沉默用户的评论。具体而言，我们提出采用大语言模型（LLMs）作为用户模拟器和评论生成器，并设计了GenFEND，一个生成反馈增强的检测框架，该框架通过提示LLMs生成多样化的用户画像，并聚合来自多个子群体生成的评论。实验证明了GenFEND的有效性，进一步分析表明，生成的评论覆盖了更多样化的用户，甚至可能比实际评论更为有效。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Let+Silence+Speak:+Enhancing+Fake+News+Detection+with+Generated+Comments+from+Large+Language+Models)|0|
|[Saliency Detection in Educational Videos: Analyzing the Performance of Current Models, Identifying Limitations and Advancement Directions](https://doi.org/10.1145/3627673.3679825)|Evelyn Navarrete, Ralph Ewerth, Anett Hoppe||Identifying the regions of a learning resource that a learner pays attention to is crucial for assessing the material's impact and improving its design and related support systems. Saliency detection in videos addresses the automatic recognition of attention-drawing regions in single frames. In educational settings, the recognition of pertinent regions in a video's visual stream can enhance content accessibility and information retrieval tasks such as video segmentation, navigation, and summarization. Such advancements can pave the way for the development of advanced AI-assisted technologies that support learning with greater efficacy. However, this task becomes particularly challenging for educational videos due to the combination of unique characteristics such as text, voice, illustrations, animations, and more. To the best of our knowledge, there is currently no study that evaluates saliency detection approaches in educational videos. In this paper, we address this gap by evaluating four state-of-the-art saliency detection approaches for educational videos. We reproduce the original studies and explore the replication capabilities for general-purpose (non-educational) datasets. Then, we investigate the generalization capabilities of the models and evaluate their performance on educational videos. We conduct a comprehensive analysis to identify common failure scenarios and possible areas of improvement. Our experimental results show that educational videos remain a challenging context for generic video saliency detection models.|识别学习者在学习资源中关注的关键区域对于评估材料的影响以及改进其设计及相关支持系统至关重要。视频中的显著性检测旨在自动识别单帧图像中吸引注意力的区域。在教育环境中，识别视频视觉流中的相关区域可以增强内容的可访问性，并提升诸如视频分割、导航和摘要等信息检索任务的效果。这些进展可以为开发更高效的先进人工智能辅助学习技术铺平道路。然而，由于教育视频中包含了文本、语音、插图、动画等多种独特特征的组合，这一任务变得尤为复杂。据我们所知，目前尚无研究评估教育视频中的显著性检测方法。本文填补了这一空白，通过评估四种最先进的显著性检测方法在教育视频中的应用来解决这一问题。我们复现了原始研究，并探索了这些方法在通用（非教育类）数据集上的可复制性。随后，我们研究了这些模型的泛化能力，并评估了它们在教育视频中的表现。我们进行了全面分析，以识别常见的失败场景及可能的改进方向。实验结果表明，教育视频仍然是通用视频显著性检测模型面临的挑战性场景。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Saliency+Detection+in+Educational+Videos:+Analyzing+the+Performance+of+Current+Models,+Identifying+Limitations+and+Advancement+Directions)|0|
|[Towards Fair Graph Anomaly Detection: Problem, Benchmark Datasets, and Evaluation](https://doi.org/10.1145/3627673.3679754)|Neng Kai Nigel Neo, YeonChang Lee, Yiqiao Jin, SangWook Kim, Srijan Kumar|; Hanyang University Seoul; UNIST Ulsan; Georgia Institute of Technology Atlanta|The Fair Graph Anomaly Detection (FairGAD) problem aims to accurately detect anomalous nodes in an input graph while avoiding biased predictions against individuals from sensitive subgroups. However, the current literature does not comprehensively discuss this problem, nor does it provide realistic datasets that encompass actual graph structures, anomaly labels, and sensitive attributes. To bridge this gap, we introduce a formal definition of the FairGAD problem and present two novel datasets constructed from the social media platforms Reddit and Twitter. These datasets comprise 1.2 million and 400,000 edges associated with 9,000 and 47,000 nodes, respectively, and leverage political leanings as sensitive attributes and misinformation spreaders as anomaly labels. We demonstrate that our FairGAD datasets significantly differ from the synthetic datasets used by the research community. Using our datasets, we investigate the performance-fairness trade-off in nine existing GAD and non-graph AD methods on five state-of-the-art fairness methods. Our code and datasets are available at https://github.com/nigelnnk/FairGAD|公平图异常检测（FairGAD）问题的目标是在准确检测输入图中异常节点的同时，避免对来自敏感子群体的个体产生偏见的预测。然而，现有文献并未全面讨论这一问题，也未提供包含实际图结构、异常标签和敏感属性的真实数据集。为了填补这一空白，我们引入了FairGAD问题的正式定义，并提出了两个基于社交媒体平台Reddit和Twitter构建的新数据集。这些数据集分别包含与9,000个节点和47,000个节点相关联的120万条和40万条边，并利用政治倾向作为敏感属性，将传播虚假信息的用户作为异常标签。我们证明了我们的FairGAD数据集与研究界使用的合成数据集存在显著差异。通过使用我们的数据集，我们研究了九种现有的图异常检测（GAD）和非图异常检测（AD）方法在五种最先进的公平性方法上的性能-公平性权衡。我们的代码和数据集可在https://github.com/nigelnnk/FairGAD获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Fair+Graph+Anomaly+Detection:+Problem,+Benchmark+Datasets,+and+Evaluation)|0|
|[Cultural Commonsense Knowledge for Intercultural Dialogues](https://doi.org/10.1145/3627673.3679768)|TuanPhong Nguyen, Simon Razniewski, Gerhard Weikum||Despite recent progress, large language models (LLMs) still face the challenge of appropriately reacting to the intricacies of social and cultural conventions. This paper presents MANGO, a methodology for distilling high-accuracy, high-recall assertions of cultural knowledge. We judiciously and iteratively prompt LLMs for this purpose from two entry points, concepts and cultures. Outputs are consolidated via clustering and generative summarization. Running the MANGO method with GPT-3.5 as underlying LLM yields 167K high-accuracy assertions for 30K concepts and 11K cultures, surpassing prior resources by a large margin in quality and size. In an extrinsic evaluation for intercultural dialogues, we explore augmenting dialogue systems with cultural knowledge assertions. Notably, despite LLMs inherently possessing cultural knowledge, we find that adding knowledge from MANGO improves the overall quality, specificity, and cultural sensitivity of dialogue responses, as judged by human annotators. Data and code are available for download.|尽管近期取得了进展，大型语言模型（LLMs）仍然面临如何恰当应对社会和文化习俗复杂性的挑战。本文提出了MANGO方法，用于提炼高准确率、高召回率的文化知识断言。我们为此目的，从概念和文化两个切入点，审慎且迭代地提示LLMs。通过聚类和生成式摘要，输出结果得以整合。以GPT-3.5作为底层LLM运行MANGO方法，生成了16.7万个高准确率断言，涵盖3万个概念和1.1万种文化，在质量和规模上均大幅超越以往资源。在跨文化对话的外在评估中，我们探索了用文化知识断言增强对话系统的方法。值得注意的是，尽管LLMs本身具备文化知识，但我们发现，加入来自MANGO的知识显著提高了对话回应的整体质量、具体性和文化敏感性，这一结论得到了人工标注者的认可。数据和代码可供下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cultural+Commonsense+Knowledge+for+Intercultural+Dialogues)|0|
|[Reviving the Context: Camera Trap Species Classification as Link Prediction on Multimodal Knowledge Graphs](https://doi.org/10.1145/3627673.3679545)|Vardaan Pahuja, Weidi Luo, Yu Gu, ChengHao Tu, HongYou Chen, Tanya Y. BergerWolf, Charles V. Stewart, Song Gao, WeiLun Chao, Yu Su|; The Ohio State University; University of Wisconsin-Madison; The Ohio State University Rensselaer Polytechnic Institute|Camera traps are important tools in animal ecology for biodiversity monitoring and conservation. However, their practical application is limited by issues such as poor generalization to new and unseen locations. Images are typically associated with diverse forms of context, which may exist in different modalities. In this work, we exploit the structured context linked to camera trap images to boost out-of-distribution generalization for species classification tasks in camera traps. For instance, a picture of a wild animal could be linked to details about the time and place it was captured, as well as structured biological knowledge about the animal species. While often overlooked by existing studies, incorporating such context offers several potential benefits for better image understanding, such as addressing data scarcity and enhancing generalization. However, effectively incorporating such heterogeneous context into the visual domain is a challenging problem. To address this, we propose a novel framework that transforms species classification as link prediction in a multimodal knowledge graph (KG). This framework enables the seamless integration of diverse multimodal contexts for visual recognition. We apply this framework for out-of-distribution species classification on the iWildCam2020-WILDS and Snapshot Mountain Zebra datasets and achieve competitive performance with state-of-the-art approaches. Furthermore, our framework enhances sample efficiency for recognizing under-represented species.|相机陷阱是动物生态学中用于生物多样性监测和保护的重要工具。然而，其实际应用受到诸如对新地点和未见地点的泛化能力差等问题的限制。图像通常与多种形式的上下文相关联，这些上下文可能存在于不同的模态中。在本研究中，我们利用与相机陷阱图像相关的结构化上下文，以提升相机陷阱中物种分类任务的分布外泛化能力。例如，一张野生动物的照片可能与捕捉它的时间和地点的详细信息，以及关于该动物物种的结构化生物学知识相关联。尽管现有研究常常忽视这些上下文，但将其纳入图像理解中具有多种潜在优势，例如解决数据稀缺问题并增强泛化能力。然而，如何有效地将这种异构上下文融入视觉领域是一个具有挑战性的问题。为此，我们提出了一种新颖的框架，将物种分类任务转化为多模态知识图谱（KG）中的链接预测。该框架能够无缝整合多种多模态上下文以进行视觉识别。我们在iWildCam2020-WILDS和Snapshot Mountain Zebra数据集上应用该框架进行分布外物种分类，并取得了与最先进方法相媲美的性能。此外，我们的框架还提高了识别代表性不足物种的样本效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reviving+the+Context:+Camera+Trap+Species+Classification+as+Link+Prediction+on+Multimodal+Knowledge+Graphs)|0|
|[The Impact of External Sources on the Friedkin-Johnsen Model](https://doi.org/10.1145/3627673.3679780)|Charlotte Out, Sijing Tu, Stefan Neumann, Ahad N. Zehmakan|TU Wien, Vienna, Austria; KTH Royal Institute of Technology, Stockholm, Sweden; The Australian National University, Canberra, Australia; University of Cambridge, Cambridge, United Kingdom|To obtain a foundational understanding of timeline algorithms and viral content in shaping public opinions, computer scientists started to study augmented versions of opinion formation models from sociology. In this paper, we generalize the popular Friedkin--Johnsen model to include the effects of external media sources on opinion formation. Our goal is to mathematically analyze the influence of biased media, arising from factors such as manipulated news reporting or the phenomenon of false balance. Within our framework, we examine the scenario of two opposing media sources, which do not adapt their opinions like ordinary nodes, and analyze the conditions and the number of periods required for radicalizing the opinions in the network. When both media sources possess equal influence, we theoretically characterize the final opinion configuration. In the special case where there is only a single media source present, we prove that media sources which do not adapt their opinions are significantly more powerful than those which do. Lastly, we conduct the experiments on real-world and synthetic datasets, showing that our theoretical guarantees closely align with experimental simulations.|为了深入理解时间线算法和病毒式内容在塑造公众舆论中的作用，计算机科学家开始从社会学角度研究增强版的舆论形成模型。在本文中，我们对广为人知的弗里德金-约翰森模型进行了推广，以包含外部媒体来源对舆论形成的影响。我们的目标是从数学角度分析偏见媒体的影响，这些偏见可能源于操纵性新闻报道或虚假平衡现象。在我们的框架内，我们考察了两种对立媒体来源的情景，这些媒体来源不像普通节点那样调整其观点，并分析了在网络中使观点极端化所需的条件和周期数。当两种媒体来源具有同等影响力时，我们从理论上描述了最终的舆论配置。在仅存在单一媒体来源的特殊情况下，我们证明了不调整自身观点的媒体来源比那些调整观点的媒体来源具有显著更强的力量。最后，我们在真实世界和合成数据集上进行了实验，结果表明我们的理论保证与实验模拟结果高度一致。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Impact+of+External+Sources+on+the+Friedkin-Johnsen+Model)|0|
|[Novelty-aware Graph Traversal and Expansion for Hierarchical Reinforcement Learning](https://doi.org/10.1145/3627673.3679523)|Jongchan Park, Seungjun Oh, Yusung Kim||Hierarchical Reinforcement Learning (HRL) is specially designed for environments characterized by long-term goals and sparse rewards. High-level policies in HRL learn to generate appropriate subgoals aimed at accomplishing the final goal, while low-level policies focus on achieving these designated subgoals. Recently, graph-based HRL algorithms have demonstrated enhanced learning capabilities through the structural representation of state spaces as graphs. However, existing graph-based HRL methods still often generate inefficient subgoals. This paper introduces a new method, Novelty-aware Graph Traversal and Expansion (NGTE), which selects an optimal node at the graph boundary, termed an Outpost Subgoal, as a direct path toward the final goal. Once the Outpost Subgoal is reached, NGTE transitions into an exploration phase, offering exploration subgoals within a reachable distance to efficiently expand the graph. Demonstrated in complex environments such as quadruped robot navigation and robotic arm manipulation, NGTE consistently outperforms existing graph and non-graph HRL methods, showing outstanding performance, especially in the most challenging scenarios with fixed start and fixed goal conditions.|分层强化学习（Hierarchical Reinforcement Learning, HRL）专为具有长期目标和稀疏奖励的环境而设计。HRL中的高层策略学习生成适当的子目标，旨在实现最终目标，而低层策略则专注于完成这些指定的子目标。近年来，基于图的HRL算法通过将状态空间表示为图结构，展示了更强的学习能力。然而，现有的基于图的HRL方法仍然经常生成低效的子目标。本文提出了一种新方法，称为**新颖性感知图遍历与扩展（Novelty-aware Graph Traversal and Expansion, NGTE）**，该方法在图边界选择一个最优节点，称为**前哨子目标（Outpost Subgoal）**，作为通向最终目标的直接路径。一旦达到前哨子目标，NGTE会转入探索阶段，提供在可达距离内的探索子目标，以高效扩展图。在四足机器人导航和机械臂操作等复杂环境中，NGTE始终优于现有的基于图和非图的HRL方法，尤其在具有固定起点和固定目标条件的最具挑战性的场景中表现出色。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Novelty-aware+Graph+Traversal+and+Expansion+for+Hierarchical+Reinforcement+Learning)|0|
|[Exploiting Pre-trained Models for Drug Target Affinity Prediction with Nearest Neighbors](https://doi.org/10.1145/3627673.3679704)|Qizhi Pei, Lijun Wu, Zhenyu He, Jinhua Zhu, Yingce Xia, Shufang Xie, Rui Yan||Drug-Target binding Affinity (DTA) prediction is essential for drug discovery. Despite the application of deep learning methods to DTA prediction, the achieved accuracy remain suboptimal. In this work, inspired by the recent success of retrieval methods, we propose kNN-DTA, a non-parametric embedding-based retrieval method adopted on a pre-trained DTA prediction model, which can extend the power of the DTA model with no or negligible cost. Different from existing methods, we introduce two neighbor aggregation ways from both embedding space and label space that are integrated into a unified framework. Specifically, we propose a label aggregation with pair-wise retrieval and a representation aggregation with point-wise retrieval of the nearest neighbors. This method executes in the inference phase and can efficiently boost the DTA prediction performance with no training cost. In addition, we propose an extension, Ada-kNN-DTA, an instance-wise and adaptive aggregation with lightweight learning. Results on four benchmark datasets show that kNN-DTA brings significant improvements, outperforming previous state-of-the-art (SOTA) results, e.g, on BindingDB IC_50 and K_i testbeds, kNN-DTA obtains new records of RMSE 0.684 and 0.750. The extended Ada-kNN-DTA further improves the performance to be 0.675 and 0.735 RMSE. These results strongly prove the effectiveness of our method. Results in other settings and comprehensive studies/analyses also show the great potential of our kNN-DTA approach.|药物-靶标结合亲和力（DTA）预测对于药物发现至关重要。尽管深度学习方法已应用于DTA预测，但所达到的准确性仍然不尽如人意。在本研究中，受检索方法近期成功的启发，我们提出了kNN-DTA，这是一种基于预训练DTA预测模型的无参数嵌入检索方法，能够在不增加或仅增加极小成本的情况下扩展DTA模型的能力。与现有方法不同，我们引入了从嵌入空间和标签空间两种邻居聚合方式，并将其集成到一个统一的框架中。具体而言，我们提出了基于成对检索的标签聚合和基于最近邻点检索的表示聚合。该方法在推理阶段执行，能够在不增加训练成本的情况下有效提升DTA预测性能。此外，我们还提出了一种扩展方法——Ada-kNN-DTA，它通过轻量级学习实现实例自适应的聚合。在四个基准数据集上的实验结果表明，kNN-DTA带来了显著的改进，超越了之前的最先进（SOTA）结果。例如，在BindingDB IC_50和K_i测试集上，kNN-DTA分别取得了RMSE 0.684和0.750的新记录。扩展的Ada-kNN-DTA进一步将性能提升至RMSE 0.675和0.735。这些结果有力地证明了我们方法的有效性。在其他设置和全面研究/分析中的结果也展示了kNN-DTA方法的巨大潜力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploiting+Pre-trained+Models+for+Drug+Target+Affinity+Prediction+with+Nearest+Neighbors)|0|
|[Towards Deconfounded Visual Question Answering via Dual-causal Intervention](https://doi.org/10.1145/3627673.3679594)|Daowan Peng, Wei Wei||The Visual Question Answering (VQA) task has recently become notorious because models are prone to predicting well-educated "guesses" as answers rather than deriving them through visual understanding. The main culprit for this is that VQA models memorize the shortcut biases in the dataset during the training process. While a variety of solutions have been proposed, they solely focus on the shortcuts in the language modality, leaving other kinds of shortcut biases untouched. In this paper, we shift our lens to all kinds of shortcuts and resort to causal inference to circumvent these issues. Causal inference methods can discover the causal effect (P(Y|do(X))) [27] rather than statistic-based spurious correlations (P(Y|X)) in the dataset, making them naturally suitable for debiasing learning. To deconfound these shortcut biases, we propose a causality-aware method, coined as Dual Causal Intervention (DCI), to endow VQA models with better generalization by combining two components: linguistic backdoor intervention and visual front-door intervention. To be specific, we harness backdoor intervention to cut off the effects of confounders in the language modality and employ front-door intervention to eliminate the impact of confounders in the visual modality. We conducted extensive experiments on two challenging Out-of-Distribution (OOD) benchmarks, including VQA-VS and VQA-CE, which are designed to assess the robustness of VQA models under different shortcut biases. The experimental results show the effectiveness of our method. Specifically, our approach outperforms the current state-of-the-art debiasing methods on the IID metric and all nine OOD metrics of the VQA-VS dataset, and also surpasses the performance of the best-performing methods on all metrics of the VQA-CE dataset.|视觉问答（VQA）任务最近备受争议，因为模型倾向于预测经过良好训练的“猜测”作为答案，而不是通过视觉理解来推导答案。造成这一问题的主要原因是VQA模型在训练过程中记住了数据集中的捷径偏差。尽管已经提出了多种解决方案，但它们仅关注语言模态中的捷径偏差，而忽略了其他类型的捷径偏差。在本文中，我们将视角转向所有类型的捷径偏差，并借助因果推理来规避这些问题。因果推理方法能够发现数据集中的因果效应（P(Y|do(X))）[27]，而不是基于统计的虚假相关性（P(Y|X)），这使得它们天然适合用于去偏学习。为了消除这些捷径偏差的混淆影响，我们提出了一种因果感知方法，称为**双重因果干预（DCI）**，通过结合两个组件来增强VQA模型的泛化能力：语言后门干预和视觉前门干预。具体而言，我们利用后门干预切断语言模态中混杂因素的影响，并采用前门干预消除视觉模态中混杂因素的影响。我们在两个具有挑战性的**分布外（OOD）**基准测试（包括VQA-VS和VQA-CE）上进行了广泛的实验，这些基准测试旨在评估VQA模型在不同捷径偏差下的鲁棒性。实验结果表明了我们方法的有效性。具体而言，在VQA-VS数据集的**IID指标**和所有九个**OOD指标**上，我们的方法优于当前最先进的去偏方法，并且在VQA-CE数据集的所有指标上也超越了表现最佳的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Deconfounded+Visual+Question+Answering+via+Dual-causal+Intervention)|0|
|[Beyond Over-smoothing: Uncovering the Trainability Challenges in Deep Graph Neural Networks](https://doi.org/10.1145/3627673.3679776)|Jie Peng, Runlin Lei, Zhewei Wei||The drastic performance degradation of Graph Neural Networks (GNNs) as the depth of the graph propagation layers exceeds 8-10 is widely attributed to a phenomenon of Over-smoothing. Although recent research suggests that Over-smoothing may not be the dominant reason for such a performance degradation, they have not provided rigorous analysis from a theoretical view, which warrants further investigation. In this paper, we systematically analyze the real dominant problem in deep GNNs and identify the issues that these GNNs towards addressing Over-smoothing essentially work on via empirical experiments and theoretical gradient analysis. We theoretically prove that the difficult training problem of deep MLPs is actually the main challenge, and various existing methods that supposedly tackle Over-smoothing actually improve the trainability of MLPs, which is the main reason for their performance gains. Our further investigation into trainability issues reveals that properly constrained smaller upper bounds of gradient flow notably enhance the trainability of GNNs. Experimental results on diverse datasets demonstrate consistency between our theoretical findings and empirical evidence. Our analysis provides new insights in constructing deep graph models.|随着图传播层深度超过8-10层，图神经网络（GNNs）性能的急剧下降被广泛归因于一种称为“过平滑”（Over-smoothing）的现象。尽管最近的研究表明过平滑可能并非导致这种性能下降的主要原因，但它们并未从理论角度提供严谨的分析，这值得进一步探讨。在本文中，我们系统地分析了深层GNNs中的真正主导问题，并通过实验和理论梯度分析，确定了这些GNNs在解决过平滑问题时实际处理的问题。我们从理论上证明了深度多层感知机（MLPs）的训练困难才是主要的挑战，而各种被认为解决过平滑的现有方法实际上改善了MLPs的可训练性，这才是它们性能提升的主要原因。我们对可训练性问题的进一步研究表明，适当约束梯度流的上界显著增强了GNNs的可训练性。在不同数据集上的实验结果证明了我们的理论发现与实证证据之间的一致性。我们的分析为构建深度图模型提供了新的见解。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Over-smoothing:+Uncovering+the+Trainability+Challenges+in+Deep+Graph+Neural+Networks)|0|
|[Bi-directional Learning of Logical Rules with Type Constraints for Knowledge Graph Completion](https://doi.org/10.1145/3627673.3679695)|Kunxun Qi, Jianfeng Du, Hai Wan|School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; Guangdong University of Foreign Studies & Bigmath Technology, Guangzhou, China|Knowledge graph completion (KGC) aims to infer missing facts from existing facts. Learning logical rules plays a pivotal role in KGC, as logical rules excel in explaining why a missing fact is inferred. Most existing rule learning methods focus merely on learning chain-like rules, neglecting type constraints on entities. In practice, type constraints are crucial in expressing precise rules. Therefore, we propose a novel formalism for logical rules named TC-rules, which complements chain-like rules with both explicit and implicit type constraints on entity variables. Accordingly, we propose an end-to-end approach to effectively learn TC-rules, by parameterizing a neural model to simulate the inference of TC-rules. Considering that existing end-to-end methods learn two different sets of logical rules to respectively answer a head query (?,rnew, t) and a tail query (h,rrnew, ?), leading to confusing explanations for supporting a new fact (h,rnew, t), we propose a bi-directional learning mechanism to ensure that the TC-rules learnt for answering (?,rnew, t) are the same as the TC-rules learnt for answering (h,rnew, ?). Experimental results on eight benchmark datasets demonstrate that the proposed method outperforms state-of-the-art rule learners in both the link prediction task and the triple classification task. Furthermore, our case study confirms that expressive TC-rules can be extracted from the parameter assignment of the learnt neural model.|知识图谱补全（Knowledge Graph Completion, KGC）旨在从现有事实中推断缺失的事实。学习逻辑规则在KGC中起着关键作用，因为逻辑规则擅长解释为什么推断出某个缺失的事实。大多数现有的规则学习方法仅关注学习链式规则，而忽略了对实体的类型约束。实际上，类型约束在表达精确规则时至关重要。因此，我们提出了一种名为TC规则的新型逻辑规则形式化方法，它通过为实体变量添加显式和隐式的类型约束来补充链式规则。相应地，我们提出了一种端到端的方法来有效地学习TC规则，通过参数化神经网络模型来模拟TC规则的推理过程。考虑到现有的端到端方法学习两组不同的逻辑规则来分别回答头查询（?,rnew, t）和尾查询（h,rnew, ?），这导致在支持新事实（h,rnew, t）时产生混淆的解释，我们提出了一种双向学习机制，以确保为回答（?,rnew, t）而学习的TC规则与为回答（h,rnew, ?）而学习的TC规则相同。在八个基准数据集上的实验结果表明，所提出的方法在链接预测任务和三元组分类任务中均优于最先进的规则学习器。此外，我们的案例研究证实，可以从学习到的神经网络模型的参数分配中提取出具有表达力的TC规则。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bi-directional+Learning+of+Logical+Rules+with+Type+Constraints+for+Knowledge+Graph+Completion)|0|
|[UniMEL: A Unified Framework for Multimodal Entity Linking with Large Language Models](https://doi.org/10.1145/3627673.3679793)|Qi Liu, Yongyi He, Tong Xu, Defu Lian, Che Liu, Zhi Zheng, Enhong Chen||Multimodal Entity Linking (MEL) is a crucial task that aims at linking ambiguous mentions within multimodal contexts to the referent entities in a multimodal knowledge base, such as Wikipedia. Existing methods focus heavily on using complex mechanisms and extensive model tuning methods to model the multimodal interaction on specific datasets. However, these methods overcomplicate the MEL task and overlook the visual semantic information, which makes them costly and hard to scale. Moreover, these methods can not solve the issues like textual ambiguity, redundancy, and noisy images, which severely degrade their performance. Fortunately, the advent of Large Language Models (LLMs) with robust capabilities in text understanding and reasoning, particularly Multimodal Large Language Models (MLLMs) that can process multimodal inputs, provides new insights into addressing this challenge. However, how to design a universally applicable LLMs-based MEL approach remains a pressing challenge. To this end, we propose UniMEL, a unified framework which establishes a new paradigm to process multimodal entity linking tasks using LLMs. In this framework, we employ LLMs to augment the representation of mentions and entities individually by integrating textual and visual information and refining textual information. Subsequently, we employ the embedding-based method for retrieving and re-ranking candidate entities. Then, with only 0.26 selection from the candidate entities. Extensive experiments on three public benchmark datasets demonstrate that our solution achieves state-of-the-art performance, and ablation studies verify the effectiveness of all modules. Our code is available at https://github.com/Javkonline/UniMEL.|多模态实体链接（Multimodal Entity Linking, MEL）是一项关键任务，旨在将多模态上下文中的模糊提及链接到多模态知识库（如维基百科）中的目标实体。现有方法主要侧重于使用复杂的机制和广泛的模型调优方法来建模特定数据集上的多模态交互。然而，这些方法使MEL任务过于复杂化，并忽略了视觉语义信息，导致其成本高昂且难以扩展。此外，这些方法无法解决文本歧义、冗余和噪声图像等问题，这些问题严重影响了其性能。幸运的是，具有强大文本理解和推理能力的大型语言模型（Large Language Models, LLMs）的出现，特别是能够处理多模态输入的多模态大型语言模型（Multimodal Large Language Models, MLLMs），为解决这一挑战提供了新的思路。然而，如何设计一种普遍适用的基于LLMs的MEL方法仍然是一个紧迫的挑战。为此，我们提出了UniMEL，这是一个统一的框架，建立了使用LLMs处理多模态实体链接任务的新范式。在该框架中，我们利用LLMs通过整合文本和视觉信息并优化文本信息，分别增强提及和实体的表示。随后，我们采用基于嵌入的方法进行候选实体的检索和重排序。然后，仅需从候选实体中进行0.26的选择。在三个公开基准数据集上的大量实验表明，我们的解决方案实现了最先进的性能，消融研究验证了所有模块的有效性。我们的代码可在https://github.com/Javkonline/UniMEL获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UniMEL:+A+Unified+Framework+for+Multimodal+Entity+Linking+with+Large+Language+Models)|0|
|[PISeL: Pipelining DNN Inference for Serverless Computing](https://doi.org/10.1145/3627673.3679824)|Masoud Rahimi Jafari, Jianchang Su, Yifan Zhang, Oliver Wang, Wei Zhang|University of Connecticut, Storrs, CT, USA; University of Chicago, Chicago, IL, USA|Serverless computing offers resource efficiency, cost efficiency, and a "pay-as-you-go" pricing model, which makes it highly attractive to both users and cloud providers. However, serverless computing faces serious cold start problem, especially for deep neural network (DNN) inference, which requires low latency. Existing cold start optimization focuses only on quick container start and fast runtime and library loading. However, DNN application bootstrap (DNN framework load and start, model initialization, model download, deserialization and copy) is the leading factor during the overall cold start time. As the model size grows, the application-level bootstrap becomes more severe. We present PISeL, a generic and fast application-level cold-start optimization mechanism for DNN inference. We propose a layer-grouping mechanism and policy to pipeline model download, model deserialization and copy and request execution. The grouping policy strikes a balance that minimizes both pipeline bubble risk and synchronization overhead. The pipelining process is transparent to a variety of DNN jobs and is implemented with the hook point in a lightweight manner. PISeL not only greatly reduces the cold start time, but also the peek memory usage which can easily incur OOM (out of memory) problem. Our experiments show that PISeL accelerates cold start time with all experimented system configurations and DNN models. PISeL can speed up cold start times by 37% and 63% using PyTorch framework executed on CPU and GPU and also 29% and 33% using TensorFlow framework executed on CPU and GPU. Furthermore, PISeL reduces maximum memory usage by up to 59% and 30% using PyTorch and TensorFlow frameworks.|无服务器计算提供了资源效率、成本效益以及“按需付费”的定价模式，这使得它对用户和云服务提供商都极具吸引力。然而，无服务器计算面临着严重的冷启动问题，尤其是对于需要低延迟的深度神经网络（DNN）推理任务。现有的冷启动优化主要集中在快速容器启动和运行时及库的快速加载上。然而，DNN应用的启动过程（包括DNN框架的加载和启动、模型初始化、模型下载、反序列化和复制）在整个冷启动时间中占据了主导地位。随着模型规模的增大，应用层面的启动问题变得更加严重。我们提出了PISeL，一种通用且快速的DNN推理应用层面冷启动优化机制。我们提出了一种分层分组机制和策略，将模型下载、模型反序列化和复制与请求执行进行流水线处理。分组策略在最小化流水线气泡风险和同步开销之间取得了平衡。流水线过程对多种DNN任务是透明的，并通过轻量级的钩子点实现。PISeL不仅大幅减少了冷启动时间，还降低了峰值内存使用量，从而避免了内存溢出（OOM）问题。我们的实验表明，PISeL在所有实验系统配置和DNN模型上均加速了冷启动时间。使用PyTorch框架在CPU和GPU上执行时，PISeL分别将冷启动时间缩短了37%和63%；使用TensorFlow框架在CPU和GPU上执行时，分别缩短了29%和33%。此外，PISeL在使用PyTorch和TensorFlow框架时，最大内存使用量分别减少了59%和30%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PISeL:+Pipelining+DNN+Inference+for+Serverless+Computing)|0|
|[SmartHash: Perceptual Hashing for Image Tampering Detection and Authentication](https://doi.org/10.1145/3627673.3679827)|Priyanka Samanta, Shweta Jain|The Graduate Center, CUNY & Brooklyn College, New York, NY, USA; CUNY John Jay College of Criminal Justice & The Graduate Center of CUNY, New York, NY, USA|Perceptual hashing algorithms have been used extensively to detect duplicate images, similar images for reverse image search, inappropriate and explicit images, and child sexual abuse (CSAM) images. These algorithms use various techniques to extract perceptual features from an image to create a succinct representation called the hash which is akin to the bio-metric marker of an image. This paper explores the ability of perceptual hashes to determine whether an image is a tampered version of a previously known image, i.e., it was created by object addition or removal from the original known image. In particular, a fast and efficient DCT-based perceptual hashing algorithm called SmartHash is proposed. SmartHash is an extension of a well-known and widely used pHash algorithm. It is evaluated on several publicly available datasets of tampered images and is shown to have high accuracy and precision in detecting such images. Additionally, an in-depth examination of the results is provided to quantify the limitations and hence, operating parameters of any software that integrates SmartHash in its workflow. Comparison with the state of the art Apple's NeuralHash and Microsoft's PhotoDNA is provided in the context of detecting tampered images. This work contributes to the content authentication initiative which is led by Adobe to establish content provenance and authentication across the Internet.|感知哈希算法已被广泛应用于检测重复图像、反向图像搜索中的相似图像、不适当和露骨图像，以及儿童性虐待（CSAM）图像。这些算法采用多种技术从图像中提取感知特征，生成一种称为哈希的简洁表示，类似于图像的生物特征标记。本文探讨了感知哈希在判断图像是否为已知图像的篡改版本（即通过从原始已知图像中添加或删除对象而创建）方面的能力。特别是，本文提出了一种基于离散余弦变换（DCT）的快速高效感知哈希算法，称为SmartHash。SmartHash是对广为人知且广泛使用的pHash算法的扩展。它在多个公开可用的篡改图像数据集上进行了评估，结果显示其在检测此类图像方面具有较高的准确性和精确度。此外，本文还提供了对结果的深入分析，以量化其局限性，从而确定任何在其工作流程中集成SmartHash的软件的操作参数。本文还在检测篡改图像的背景下，与当前最先进的苹果NeuralHash和微软PhotoDNA进行了比较。这项工作为Adobe主导的内容认证计划做出了贡献，该计划旨在建立互联网上的内容来源和认证。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SmartHash:+Perceptual+Hashing+for+Image+Tampering+Detection+and+Authentication)|0|
|[Mining Path Association Rules in Large Property Graphs](https://doi.org/10.1145/3627673.3679525)|Yuya Sasaki, Panagiotis Karras||How can we mine frequent path regularities from a graph with edge labels and vertex attributes? The task of association rule mining successfully discovers regular patterns in item sets and substructures. Still, to our best knowledge, this concept has not yet been extended to path patterns in large property graphs. In this paper, we introduce the problem of path association rule mining (PARM). Applied to any reachability path between two vertices within a large graph, PARM discovers regular ways in which path patterns, identified by vertex attributes and edge labels, co-occur with each other. We develop an efficient and scalable algorithm PIONEER that exploits an anti-monotonicity property to effectively prune the search space. Further, we devise approximation techniques and employ parallelization to achieve scalable path association rule mining. Our experimental study using real-world graph data verifies the significance of path association rules and the efficiency of our solutions.|如何从具有边标签和顶点属性的图中挖掘频繁路径规律？关联规则挖掘任务成功地发现了项集和子结构中的规律模式。然而，据我们所知，这一概念尚未扩展到大型属性图中的路径模式。在本文中，我们引入了路径关联规则挖掘（PARM）问题。PARM应用于大型图中两个顶点之间的任何可达路径，发现由顶点属性和边标签标识的路径模式相互共现的规律方式。我们开发了一种高效且可扩展的算法PIONEER，该算法利用反单调性属性有效地剪枝搜索空间。此外，我们设计了近似技术并采用并行化方法，以实现可扩展的路径关联规则挖掘。我们使用真实世界的图数据进行的实验研究验证了路径关联规则的重要性以及我们解决方案的效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mining+Path+Association+Rules+in+Large+Property+Graphs)|0|
|[Leveraging Trustworthy Node Attributes for Effective Network Alignment](https://doi.org/10.1145/3627673.3679658)|DongHyuk Seo, JaeHwan Lim, WonYong Shin, SangWook Kim|Computational Science and Engineering, Yonsei University, Seoul, Republic of Korea; Computer Science, Hanyang University, Seoul, Republic of Korea|With the prevalence of social media platforms, accurately identifying the same users across different networks through network alignment has become crucial. Existing methods often struggle due to sparse or absent user-identifiable information (node attributes), highlighting the need for augmenting node attributes. However, research on attribute augmentation remains largely under-explored. In this study, we aim to design augmented attributes that enhance network alignment by reflecting three key structural C haracteristics: (C1) global structural characteristic, reflects the global network structure; (C2) seed-based structural characteristic, leverages cross-network structural information associated with seed nodes; (C3) multi-aspect structural characteristic, employs diverse structural relationship measures. To this end, we propose a novel approach for designing trustworthy Augmented Seed-baSed and multI-aspect STructurAl iNformaTion (ASSISTANT) attributes. To enhance alignment performance, we also present a learning module that utilizes a gate mechanism to select the most effective measure dynamically. Extensive experiments across various datasets demonstrate the following: 1) Our network alignment framework, which includes a gate mechanism module, significantly outperforms state-of-the-art methods in alignment accuracy; 2) other state-of-the-art methods using ASSISTANT attributes as input substantially boosts their own alignment accuracy; and 3) using only ASSISTANT attributes without any training process also leads to effective alignment, showcasing their high trustworthiness.|随着社交媒体平台的普及，通过网络对齐准确识别跨平台的相同用户变得至关重要。现有的方法往往因用户可识别信息（节点属性）稀疏或缺失而难以有效工作，这凸显了增强节点属性的必要性。然而，关于属性增强的研究在很大程度上仍未被充分探索。在本研究中，我们的目标是设计能够增强网络对齐的增强属性，这些属性通过反映三个关键的结构特征来实现：(C1) 全局结构特征，反映全局网络结构；(C2) 基于种子的结构特征，利用与种子节点相关的跨网络结构信息；(C3) 多维度结构特征，采用多样化的结构关系度量。为此，我们提出了一种新颖的方法，用于设计可信的基于种子和多维度结构信息的增强属性（ASSISTANT）。为了提升对齐性能，我们还引入了一个学习模块，该模块利用门控机制动态选择最有效的度量。在多个数据集上的广泛实验表明：1）我们的网络对齐框架，包括门控机制模块，在对齐准确性上显著优于现有最先进的方法；2）其他最先进的方法使用ASSISTANT属性作为输入时，其对齐准确性也大幅提升；3）仅使用ASSISTANT属性而无需任何训练过程也能实现有效的对齐，展示了其高度的可信性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Trustworthy+Node+Attributes+for+Effective+Network+Alignment)|0|
|[Structural Representation Learning and Disentanglement for Evidential Chinese Patent Approval Prediction](https://doi.org/10.1145/3627673.3679766)|Jinzhi Shan, Qi Zhang, Chongyang Shi, Mengting Gui, Shoujin Wang, Usman Naseem||Automatic Chinese patent approval prediction is an emerging and valuable task in patent analysis. However, it involves a rigorous and transparent decision-making process that includes patent comparison and examination to assess its innovation and correctness. This resultant necessity of decision evidentiality, coupled with intricate patent comprehension presents significant challenges and obstacles for the patent analysis community. Consequently, few existing studies are addressing this task. This paper presents the pioneering effort on this task using a retrieval-based classification approach. We propose a novel framework called DiSPat, which focuses on structural representation learning and disentanglement to predict the approval of Chinese patents and offer decision-making evidence. DiSPat comprises three main components: base reference retrieval to retrieve the Top-k most similar patents as a reference base; structural patent representation to exploit the inherent claim hierarchy in patents for learning a structural patent representation; disentangled representation learning to learn disentangled patent representations that enable the establishment of an evidential decision-making process. To ensure a thorough evaluation, we have meticulously constructed three datasets of Chinese patents. Extensive experiments on these datasets unequivocally demonstrate our DiSPat surpasses state-of-the-art baselines on patent approval prediction, while also exhibiting enhanced evidentiality.|中文专利自动审批预测是专利分析领域中一项新兴且具有重要价值的任务。然而，这一任务涉及一个严谨且透明的决策过程，包括专利对比和审查，以评估其创新性和正确性。这种对决策证据性的必然要求，加之对专利文本的复杂理解，给专利分析领域带来了巨大的挑战和障碍。因此，目前针对该任务的研究相对较少。本文首次采用基于检索的分类方法对这一任务进行了探索。我们提出了一个名为DiSPat的新框架，该框架专注于结构化表示学习和解耦，以预测中文专利的审批结果并提供决策证据。DiSPat由三个主要组件构成：基础参考检索，用于检索与目标专利最相似的Top-k个专利作为参考基础；结构化专利表示，利用专利中固有的权利要求层次结构来学习结构化专利表示；解耦表示学习，通过学习解耦的专利表示，从而建立一个基于证据的决策过程。为了确保全面评估，我们精心构建了三个中文专利数据集。在这些数据集上进行的大量实验表明，DiSPat在专利审批预测方面超越了现有的最先进基线方法，同时表现出更强的证据性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Structural+Representation+Learning+and+Disentanglement+for+Evidential+Chinese+Patent+Approval+Prediction)|0|
|[Fast Human Action Recognition via Millimeter Wave Radar Point Cloud Sequences Learning](https://doi.org/10.1145/3627673.3679787)|Tongfei Shao, Zheyu Du, Chuanyou Li, Tianxing Wu, Meng Wang|Tongji University, Shanghai, China; Southeast University, Nanjing, China|Human action recognition using commercial millimeter wave radar is gaining significant attention in smart elderly care and smart homes. Due to privacy concerns, the sensing data often needs to be processed locally on embedded systems with restricted computational resources, necessitating a balance between recognition accuracy and efficiency. In this paper, we propose a fast human action recognition framework based on 3D point cloud sequences generated by commercial 4D millimeter wave imaging radar systems. The framework comprises two primary phases: data preprocessing and spatial-temporal feature extraction. During the data preprocessing phase, we employ a sliding window approach for frame fusion to enhance the spatial information of the sparse point cloud while retaining its temporal features. Additionally, Morton coding is used to address the disorderliness in the point cloud sequence. For spatial-temporal feature extraction, we introduce an innovative two-stage algorithm. In the spatial feature extraction stage, we initially extract local spatial features for each point, utilizing self-attention to construct a local graph and circumvent the limitations of using Euclidean distance in sparse point clouds. Subsequently, 3D frame fusion convolution is applied to extract spatial features at the frame level, reducing the length of the spatial feature map sequence and lowering computational requirements for subsequent temporal feature extraction. In the temporal feature extraction stage, we employ a modified Transformer encoder with fine-grained feature fusion to extract temporal features. We conducted comprehensive experiments using both our collected dataset and the open dataset RadHar. The experimental outcomes demonstrate that our framework not only improves inference accuracy but also maintains satisfactory real-time performance on embedded platforms with constrained computational resources. When compared with state-of-the-art (SOTA) methods, our framework significantly enhances inference speed while retaining competitive inference accuracy. Codes and dataset are available at https://github.com/Feiyuyu0503/FastHAR.|基于商用毫米波雷达的人体动作识别在智能养老和智能家居领域正受到广泛关注。由于隐私问题，感知数据通常需要在计算资源受限的嵌入式系统上进行本地处理，因此需要在识别精度和效率之间取得平衡。本文提出了一种基于商用4D毫米波成像雷达系统生成的3D点云序列的快速人体动作识别框架。该框架包含两个主要阶段：数据预处理和时空特征提取。在数据预处理阶段，我们采用滑动窗口方法进行帧融合，以增强稀疏点云的空间信息，同时保留其时间特征。此外，使用Morton编码来解决点云序列的无序性问题。在时空特征提取阶段，我们引入了一种创新的两阶段算法。在空间特征提取阶段，我们首先为每个点提取局部空间特征，利用自注意力机制构建局部图，以规避在稀疏点云中使用欧几里得距离的局限性。随后，应用3D帧融合卷积提取帧级别的空间特征，减少空间特征图序列的长度，从而降低后续时间特征提取的计算需求。在时间特征提取阶段，我们采用改进的Transformer编码器进行细粒度特征融合，以提取时间特征。我们使用自收集的数据集和公开数据集RadHar进行了全面的实验。实验结果表明，我们的框架不仅提高了推理精度，而且在计算资源受限的嵌入式平台上保持了令人满意的实时性能。与最先进的（SOTA）方法相比，我们的框架在保持竞争力的推理精度的同时，显著提高了推理速度。代码和数据集可在https://github.com/Feiyuyu0503/FastHAR获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fast+Human+Action+Recognition+via+Millimeter+Wave+Radar+Point+Cloud+Sequences+Learning)|0|
|[Robust Federated Unlearning](https://doi.org/10.1145/3627673.3679817)|Xinyi Sheng, Wei Bao, Liming Ge|School of Computer Science, The University of Sydney, Sydney, NSW, Australia|Federated unlearning (FU) algorithms offer participants in federated learning (FL) the "right to be forgotten'' for their individual data and its impact on a collaboratively trained model. Existing FU algorithms primarily focus on accelerating the retraining process and enhancing the utility of the retrained models following data removal requests. However, these approaches generally lack consideration for the robustness of FU algorithms in potential adversarial environments, where adversaries can craft malicious data removal requests to compromise the retrained model. In this work, we introduce a robust federated unlearning framework (robustFU) which notably enhances the resilience of FU algorithms against a wide range of adversarial attacks. In robustFU, we design a novel dynamic conflict sample compensation algorithm that dynamically reintroduces randomly generated samples with significant information gain to the participating clients during retraining. Additionally, robustFU employs an innovative global reweighting mechanism which adjusts the weight of each model update during the global aggregation, based on its degree of misalignment with the trained model prior to unlearning. Extensive experiments demonstrates the effectiveness and robustness of the proposed robustFU framework under adversarial environments. Furthermore, robustFU significantly accelerates the retraining process, achieving a 2.53× speed-up compared to the retrain from the scratch baseline.|联邦遗忘学习（Federated Unlearning, FU）算法为联邦学习（Federated Learning, FL）中的参与者提供了对其个人数据及其对协作训练模型影响的“遗忘权”。现有的FU算法主要关注在数据删除请求后加速重训练过程并提升重训练模型的效用。然而，这些方法通常缺乏对FU算法在潜在对抗环境中鲁棒性的考虑，攻击者可能通过构造恶意的数据删除请求来破坏重训练模型。在本研究中，我们提出了一种鲁棒的联邦遗忘学习框架（robustFU），该框架显著增强了FU算法在面对多种对抗攻击时的韧性。在robustFU中，我们设计了一种新颖的动态冲突样本补偿算法，该算法在重训练过程中动态地将随机生成的具有显著信息增益的样本重新引入参与客户端。此外，robustFU采用了一种创新的全局重加权机制，该机制根据每次模型更新与遗忘前训练模型的对齐程度，在全局聚合时调整其权重。大量实验证明了所提出的robustFU框架在对抗环境下的有效性和鲁棒性。此外，robustFU显著加速了重训练过程，与从头开始重训练的基线相比，实现了2.53倍的加速。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Federated+Unlearning)|0|
|[AgentRE: An Agent-Based Framework for Navigating Complex Information Landscapes in Relation Extraction](https://doi.org/10.1145/3627673.3679791)|Yuchen Shi, Guochao Jiang, Tian Qiu, Deqing Yang||The relation extraction (RE) in complex scenarios faces challenges such as diverse relation types and ambiguous relations between entities within a single sentence, leading to the poor performance of pure "text-in, text-out" language models (LMs). To address these challenges, in this paper, we propose an agent-based RE framework, namely AgentRE, which fully leverages the potential of large language models (LLMs) including memory, retrieval and reflection, to achieve RE in complex scenarios. Specifically, three major modules are built in AgentRE serving as the tools to help the agent acquire and process various useful information, thereby obtaining improved RE performance. Our extensive experimental results upon two datasets in English and Chinese demonstrate our AgentRE's superior performance, especially in low-resource scenarios. Additionally, the trajectories generated by AgentRE can be refined to construct a high-quality training dataset incorporating different reasoning methods, which can be used to fine-tune smaller models. Code is available at https://github.com/Lightblues/AgentRE.|在复杂场景中的关系抽取（RE）面临诸多挑战，例如关系类型多样以及单一句子中实体间关系的模糊性，这导致纯“文本输入，文本输出”语言模型（LMs）的表现不佳。为了解决这些挑战，本文提出了一种基于代理的关系抽取框架，即AgentRE，该框架充分利用了大语言模型（LLMs）的潜力，包括记忆、检索和反思能力，以实现复杂场景中的关系抽取。具体而言，AgentRE中构建了三个主要模块，作为帮助代理获取和处理各种有用信息的工具，从而提升关系抽取的性能。我们在英文和中文的两个数据集上进行了广泛的实验，结果表明AgentRE具有卓越的性能，尤其是在低资源场景下。此外，AgentRE生成的轨迹可以进一步优化，构建出包含不同推理方法的高质量训练数据集，这些数据集可用于微调较小的模型。代码可在https://github.com/Lightblues/AgentRE获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AgentRE:+An+Agent-Based+Framework+for+Navigating+Complex+Information+Landscapes+in+Relation+Extraction)|0|
|[Discovering Graph Generating Dependencies for Property Graph Profiling](https://doi.org/10.1145/3627673.3679764)|Larissa Capobianco Shimomura, Nikolay Yakovets, George Fletcher|IPVS, University of Stuttgart, Stuttgart, Germany; Eindhoven University of Technology, Eindhoven, Netherlands|Knowledge graphs have soared in popularity by supporting different types of applications and domains. In this context, the property graph data model has become an emerging standard in industry and academia. With its widespread use, there is also an increasing interest in investigating constraints for property graph data and their applications in data profiling. Graph Generating Dependencies (GGDs) are a class of property graph data dependencies that can express constraints on topology and properties of nodes and edges of the graph, making them a suitable candidate to expose an overview of the property graph to the user (profile graph data). However, GGDs can be difficult to set manually. To solve this issue, we propose a framework for discovering GGDs automatically from the property graph to profile graph data. Our framework has three main steps: (1) pre-processing, (2) candidate generation, and, (3) GGD extraction. Our results show that the discovered set of GGDs can give an overview of the input graph, including schema-level information between the graph patterns and attributes.|知识图谱因其支持不同类型应用和领域的能力而广受欢迎。在此背景下，属性图数据模型已成为工业界和学术界的新兴标准。随着其广泛使用，人们对于研究属性图数据的约束及其在数据剖析中的应用也越来越感兴趣。图生成依赖（Graph Generating Dependencies, GGDs）是一类属性图数据依赖，能够表达图中节点和边的拓扑结构及属性的约束，使其成为向用户展示属性图概览（即剖析图数据）的合适选择。然而，手动设置GGDs可能较为困难。为解决这一问题，我们提出了一个框架，用于从属性图中自动发现GGDs以剖析图数据。我们的框架包含三个主要步骤：(1) 预处理，(2) 候选生成，以及 (3) GGD提取。我们的结果表明，所发现的GGDs集能够提供输入图的概览，包括图模式与属性之间的模式级信息。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Discovering+Graph+Generating+Dependencies+for+Property+Graph+Profiling)|0|
|[XCrowd: Combining Explainability and Crowdsourcing to Diagnose Models in Relation Extraction](https://doi.org/10.1145/3627673.3679777)|Alisa Smirnova, Jie Yang, Philippe CudréMauroux|University of Fribourg, Fribourg, Switzerland; Delft University of Technology, Delft, Netherlands|Relation extraction methods are currently dominated by deep neural models, which capture complex statistical patterns while being brittle and vulnerable to perturbations in data and distribution. Explainability techniques offer a means for understanding such vulnerabilities, and thus represent an opportunity to mitigate future errors; yet, existing methods are limited to describing what the model 'knows', while totally failing at explaining what the model does not know. This paper presents a new method for diagnosing model predictions and detecting potential inaccuracies. Our approach involves breaking down the problem into two components: (i) determining the necessary knowledge the model should possess for accurate prediction, through human annotations, and (ii) assessing the actual knowledge possessed by the model, using explainable AI methods (XAI). We apply our method to several relation extraction tasks and conduct an empirical study leveraging human specifications of what a model should know and does not know. Results show that human workers are capable of accurately specifying the model should-knows, despite variations in the specification, that the alignment between what a model really knows and what it should know is indeed indicative of model accuracy, and that the unknowns identified through our methods allow to foresee future errors that may or may not have been observed otherwise.|当前，关系抽取方法主要依赖于深度神经网络模型，这些模型能够捕捉复杂的统计模式，但却具有脆弱性，容易受到数据和分布扰动的干扰。可解释性技术提供了一种理解这些脆弱性的手段，从而为减轻未来错误提供了机会；然而，现有方法仅限于描述模型“知道”的内容，而完全无法解释模型“不知道”的内容。本文提出了一种新的诊断模型预测并检测潜在不准确性的方法。我们的方法包括将问题分解为两个部分：(i) 通过人工标注确定模型进行准确预测所需的必要知识，以及(ii) 使用可解释的人工智能方法（XAI）评估模型实际掌握的知识。我们将该方法应用于多个关系抽取任务，并利用人类对模型应知和未知的规范进行实证研究。结果表明，尽管规范存在差异，人类工作者能够准确指定模型的应知内容，模型实际掌握的知识与其应知知识之间的对齐确实能够指示模型的准确性，并且通过我们的方法识别出的未知内容能够预见未来可能或不可能被观察到的错误。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=XCrowd:+Combining+Explainability+and+Crowdsourcing+to+Diagnose+Models+in+Relation+Extraction)|0|
|[HTFabric: A Fast Re-ordering and Parallel Re-execution Method for a High-Throughput Blockchain](https://doi.org/10.1145/3627673.3679606)|Jaeyub Song, Juyeong Jeong, Jemin Lee, Inju Na, MinSoo Kim|Riiid, Seoul, Republic of Korea; GraphAI, Daejeon, Republic of Korea; InfoLab, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; ICS Lab, Yonsei University, Seoul, Republic of Korea|The Execute-Order-Validate (EOV) model of blockchain has significantly improved throughput compared to the Order-Execute (OE) model. However, existing systems following the EOV model still struggle to meet the required throughput levels in many applications. We address two critical performance bottlenecks that hinder their throughput: the high cost of transaction re-ordering and the high cost of re-execution of invalid transactions. To address these challenges, we propose HTFabric, a method that combines fast re-ordering and parallel re-execution to achieve exceptionally high successful throughput. We have implemented HTFabric based on Hyperledger Fabric. Through extensive experiments, we demonstrate that HTFabric outperforms SOTA systems by 2.34 to 10.51 times, achieving a successful throughput of up to 8,930 TPS.|区块链的执行-排序-验证（EOV）模型相较于排序-执行（OE）模型显著提升了吞吐量。然而，遵循EOV模型的现有系统在许多应用中仍难以满足所需的吞吐量水平。我们针对阻碍其吞吐量的两个关键性能瓶颈进行了研究：交易重新排序的高成本和无效交易重新执行的高成本。为了解决这些挑战，我们提出了HTFabric方法，该方法结合了快速重新排序和并行重新执行，以实现极高的成功吞吐量。我们基于Hyperledger Fabric实现了HTFabric。通过大量实验，我们证明HTFabric的性能优于现有最先进（SOTA）系统2.34至10.51倍，成功吞吐量高达8,930 TPS。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HTFabric:+A+Fast+Re-ordering+and+Parallel+Re-execution+Method+for+a+High-Throughput+Blockchain)|0|
|[How Much Do Prompting Methods Help LLMs on Quantitative Reasoning with Irrelevant Information?](https://doi.org/10.1145/3627673.3679840)|Seok Hwan Song, Wallapak Tavanapong|Department of Computer Science, Iowa State University, Ames, Iowa, USA|Real-world quantitative reasoning problems are complex, often including extra information irrelevant to the question (or "IR noise" for short). State-of-the-art (SOTA) prompting methods have increased the Large Language Model's ability for quantitative reasoning on grade-school Math Word Problems (MWPs). To assess how well these SOTA methods handle IR noise, we constructed four new datasets with IR noise, each consisting of 300 problems from each of the four public datasets: MAWPS, ASDiv, SVAMP, and GSM8K, with added IR noise. We called the collection of these new datasets "MPN"--Math Word Problems with IR Noise. We evaluated SOTA prompting methods using MPN. We propose Noise Reduction Prompting (NRP) and its variant (NRP+) to reduce the impact of IR noise. Findings: Our IR noise significantly degrades the performance of Chain-of-Thought (CoT) Prompting on three different backend models: ChatGPT (gpt-3.5-turbo-0613), PaLM2, and Llama3-8B-instruct. Among them, ChatGPT offers the best accuracy on MPN with and without IR noise. With IR noise, performances of CoT, Least-To-Most Prompting, Progressive-Hint Prompting, and Program-aided Language Models with ChatGPT were significantly impacted, each with an average accuracy drop of above 12%. NRP is least impacted by the noise, with a drop in average accuracy to only around 1.9%. Our NRP+ and NRP perform comparably in the presence of IR noise.|现实世界中的定量推理问题往往较为复杂，通常包含与问题无关的额外信息（简称“IR噪声”）。最先进的（SOTA）提示方法已经提升了大型语言模型在解决小学数学应用题（MWPs）中的定量推理能力。为了评估这些SOTA方法在处理IR噪声方面的表现，我们构建了四个包含IR噪声的新数据集，每个数据集分别从四个公开数据集（MAWPS、ASDiv、SVAMP和GSM8K）中各选取300道问题，并添加了IR噪声。我们将这些新数据集的集合命名为“MPN”——即带有IR噪声的数学应用题数据集。我们使用MPN对SOTA提示方法进行了评估，并提出了噪声减少提示（Noise Reduction Prompting, NRP）及其变体（NRP+）以降低IR噪声的影响。研究发现：我们的IR噪声显著降低了链式思维提示（Chain-of-Thought, CoT）在三种不同后端模型（ChatGPT (gpt-3.5-turbo-0613)、PaLM2和Llama3-8B-instruct）上的表现。其中，ChatGPT在MPN数据集上无论是否包含IR噪声均表现最佳。在存在IR噪声的情况下，CoT、Least-To-Most提示、渐进提示（Progressive-Hint Prompting）以及程序辅助语言模型（Program-aided Language Models）在ChatGPT上的表现均受到显著影响，平均准确率下降超过12%。NRP受噪声影响最小，平均准确率下降仅为约1.9%。在有IR噪声的情况下，NRP+与NRP的表现相当。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+Much+Do+Prompting+Methods+Help+LLMs+on+Quantitative+Reasoning+with+Irrelevant+Information?)|0|
|[Breaking the Bottleneck on Graphs with Structured State Spaces](https://doi.org/10.1145/3627673.3679866)|Yunchong Song, Siyuan Huang, Jiacheng Cai, Xinbing Wang, Chenghu Zhou, Zhouhan Lin|Shanghai Jiao Tong University, Shanghai, China; Chinese Academy of Sciences, Shanghai, China|The majority of GNNs are based on message-passing mechanisms. However, Message Passing Neural Networks (MPNNs) have inherent limitations in capturing long-range interactions. The exponentially growing node information is compressed into fixed-size representations through multiple rounds of message passing, leading to the over-squashing problem. This issue severely hinders the flow of information across the graph and creates a bottleneck in graph learning. The natural idea of introducing global attention to point-to-point communication, as adopted in Graph Transformers (GTs), lacks inductive biases on graph structures and relies on complex positional encodings to enhance their performance in practical tasks. In this paper, we observe that the sensitivity between nodes in MPNNs decreases exponentially with the shortest path distance. In contrast, GTs have constant sensitivity, which leads to a loss of inductive bias. To address these issues, we introduce structured state spaces to capture the hierarchy of rooted trees, achieving linear sensitivity with theoretical guarantees. We further propose a novel state-space model-based graph convolution, resulting in a new paradigm that retains both the strong inductive biases from MPNNs and the long-range modeling capabilities from GTs. Extensive experimental results on long-range and general graph benchmarks demonstrate the superiority of our approach.|大多数图神经网络（GNNs）基于消息传递机制。然而，消息传递神经网络（MPNNs）在捕捉长程交互方面存在固有的局限性。通过多轮消息传递，指数级增长的节点信息被压缩为固定大小的表示，从而导致过度压缩问题。这一问题严重阻碍了图中信息的流动，并在图学习中形成了瓶颈。在图变换器（GTs）中引入全局注意力以进行点对点通信的自然想法，缺乏对图结构的归纳偏差，并依赖于复杂的位置编码来提升其在实际任务中的表现。本文中，我们观察到MPNNs中节点之间的敏感度随着最短路径距离呈指数级下降。相比之下，GTs具有恒定的敏感度，这导致了归纳偏差的丢失。为了解决这些问题，我们引入了结构化状态空间来捕捉根树层次结构，实现了具有理论保证的线性敏感度。我们进一步提出了一种基于状态空间模型的新型图卷积，形成了一种新范式，既保留了MPNNs的强归纳偏差，又具备GTs的长程建模能力。在长程和通用图基准测试上的大量实验结果证明了我们方法的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Breaking+the+Bottleneck+on+Graphs+with+Structured+State+Spaces)|0|
|[A Learning-path based Supervised Method for Concept Prerequisite Relations Extraction in Educational Data](https://doi.org/10.1145/3627673.3679597)|Jingwen Sun, Yu He, Yiyu Xu, Jingwei Sun, Guangzhong Sun|University of Science and Technology of China, Hefei, China; Hefei University of Technology, Hefei, China|In educational data mining, concept prerequisite relations extraction determines which concepts need to be learned before learning another concept. It plays a crucial role in pedagogical practices, such as learning path planning and curriculum design. Deep neural networks, especially graph neural networks, have recently made significant strides in concept prerequisite relations extraction. However, existing methods face two primary limitations. (1) Methods with better performance construct heterogeneous complete graphs, leading to higher model complexity and training cost. Meanwhile, the performance of low-complexity methods is inferior to the former. (2) A disregard for temporal context, essential for learning, limits both the performance and the application of these methods. To address these issues, we propose a novel graph-based approach, called Learning-path based Concept Prerequisite Relations Extraction (LCPRE). LCPRE constructs a lightweight sparse graph in a simple manner, which reduces complexity from quadratic to linear and captures the temporal feature through learning-path, a comprehensible learning approach from one concept to another. Experimental results on three benchmark datasets demonstrate that LCPRE outperforms existing methods, establishing a new state-of-the-art in concept prerequisite relations extraction.|在教育数据挖掘中，概念先决关系提取用于确定在学习某一概念之前需要先掌握哪些概念。这一任务在教学实践中扮演着至关重要的角色，例如学习路径规划和课程设计。近年来，深度神经网络，尤其是图神经网络，在概念先决关系提取方面取得了显著进展。然而，现有方法面临两个主要局限性。(1) 性能较好的方法构建了异构的完全图，导致模型复杂度和训练成本较高。与此同时，低复杂度方法的性能则逊色于前者。(2) 忽视了学习过程中至关重要的时间上下文，限制了这些方法的性能和应用。为了解决这些问题，我们提出了一种基于图的新方法，称为基于学习路径的概念先决关系提取（LCPRE）。LCPRE以一种简单的方式构建了一个轻量级的稀疏图，将复杂度从二次降低到线性，并通过学习路径捕捉时间特征，学习路径是一种从一个概念到另一个概念的可理解的学习方式。在三个基准数据集上的实验结果表明，LCPRE优于现有方法，在概念先决关系提取方面确立了新的最先进水平。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Learning-path+based+Supervised+Method+for+Concept+Prerequisite+Relations+Extraction+in+Educational+Data)|0|
|[Multimodal Misinformation Detection using Large Vision-Language Models](https://doi.org/10.1145/3627673.3679826)|Sahar Tahmasebi, Eric MüllerBudack, Ralph Ewerth||The increasing proliferation of misinformation and its alarming impact have motivated both industry and academia to develop approaches for misinformation detection and fact checking. Recent advances on large language models (LLMs) have shown remarkable performance in various tasks, but whether and how LLMs could help with misinformation detection remains relatively underexplored. Most of existing state-of-the-art approaches either do not consider evidence and solely focus on claim related features or assume the evidence to be provided. Few approaches consider evidence retrieval as part of the misinformation detection but rely on fine-tuning models. In this paper, we investigate the potential of LLMs for misinformation detection in a zero-shot setting. We incorporate an evidence retrieval component into the process as it is crucial to gather pertinent information from various sources to detect the veracity of claims. To this end, we propose a novel re-ranking approach for multimodal evidence retrieval using both LLMs and large vision-language models (LVLM). The retrieved evidence samples (images and texts) serve as the input for an LVLM-based approach for multimodal fact verification (LVLM4FV). To enable a fair evaluation, we address the issue of incomplete ground truth for evidence samples in an existing evidence retrieval dataset by annotating a more complete set of evidence samples for both image and text retrieval. Our experimental results on two datasets demonstrate the superiority of the proposed approach in both evidence retrieval and fact verification tasks and also better generalization capability across dataset compared to the supervised baseline.|随着虚假信息的日益泛滥及其带来的惊人影响，业界和学术界都致力于开发虚假信息检测和事实核查的方法。最近，大语言模型（LLMs）在各种任务中表现出色，但LLMs是否以及如何帮助虚假信息检测仍相对缺乏探索。现有的大多数最先进方法要么不考虑证据，仅专注于与声明相关的特征，要么假设证据已被提供。少数方法将证据检索作为虚假信息检测的一部分，但依赖于微调模型。在本文中，我们探讨了LLMs在零样本设置下进行虚假信息检测的潜力。我们在过程中加入了证据检索组件，因为从各种来源收集相关信息对于检测声明的真实性至关重要。为此，我们提出了一种新颖的多模态证据检索重排序方法，结合了LLMs和大视觉语言模型（LVLM）。检索到的证据样本（图像和文本）作为基于LVLM的多模态事实核查方法（LVLM4FV）的输入。为了进行公平的评估，我们通过为现有的证据检索数据集中的图像和文本检索标注更完整的证据样本，解决了证据样本地面真值不完整的问题。在两个数据集上的实验结果表明，所提出的方法在证据检索和事实核查任务中均表现出优越性，并且与监督基线相比，在跨数据集上具有更好的泛化能力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multimodal+Misinformation+Detection+using+Large+Vision-Language+Models)|0|
|[EasyST: A Simple Framework for Spatio-Temporal Prediction](https://doi.org/10.1145/3627673.3679749)|Jiabin Tang, Wei Wei, Lianghao Xia, Chao Huang||Spatio-temporal prediction is a crucial research area in data-driven urban computing, with implications for transportation, public safety, and environmental monitoring. However, scalability and generalization challenges remain significant obstacles. Advanced models often rely on Graph Neural Networks to encode spatial and temporal correlations, but struggle with the increased complexity of large-scale datasets. The recursive GNN-based message passing schemes used in these models hinder their training and deployment in real-life urban sensing scenarios. Moreover, long-spanning large-scale spatio-temporal data introduce distribution shifts, necessitating improved generalization performance. To address these challenges, we propose a simple framework for spatio-temporal prediction - EasyST paradigm. It learns lightweight and robust Multi-Layer Perceptrons (MLPs) by effectively distilling knowledge from complex spatio-temporal GNNs. We ensure robust knowledge distillation by integrating the spatio-temporal information bottleneck with teacher-bounded regression loss, filtering out task-irrelevant noise and avoiding erroneous guidance. We further enhance the generalization ability of the student model by incorporating spatial and temporal prompts to provide downstream task contexts. Evaluation on three spatio-temporal datasets for urban computing tasks demonstrates that EasyST surpasses state-of-the-art approaches in terms of efficiency and accuracy. The implementation code is available at: https://github.com/HKUDS/EasyST.|时空预测是数据驱动城市计算中的一个关键研究领域，对交通、公共安全和环境监测具有重要意义。然而，可扩展性和泛化能力仍然是主要的挑战。先进模型通常依赖图神经网络（GNN）来编码空间和时间相关性，但在处理大规模数据集的复杂性时面临困难。这些模型中使用的基于递归GNN的消息传递机制阻碍了其在现实城市感知场景中的训练和部署。此外，长时间跨度的大规模时空数据引入了分布偏移，需要提升泛化性能。为了解决这些挑战，我们提出了一种简单的时空预测框架——EasyST范式。它通过有效蒸馏复杂时空GNN的知识，学习轻量且鲁棒的多层感知机（MLPs）。我们通过将时空信息瓶颈与教师边界回归损失相结合，确保鲁棒的知识蒸馏，过滤掉任务无关的噪声并避免错误引导。我们进一步通过引入空间和时间提示来增强学生模型的泛化能力，为下游任务提供上下文。在三个城市计算任务的时空数据集上的评估表明，EasyST在效率和准确性方面均超越了现有最先进的方法。实现代码可在以下网址获取：https://github.com/HKUDS/EasyST。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EasyST:+A+Simple+Framework+for+Spatio-Temporal+Prediction)|0|
|[GAS-Norm: Score-Driven Adaptive Normalization for Non-Stationary Time Series Forecasting in Deep Learning](https://doi.org/10.1145/3627673.3679822)|Edoardo Urettini, Daniele Atzeni, Reshawn Ramjattan, Antonio Carta||Despite their popularity, deep neural networks (DNNs) applied to time series forecasting often fail to beat simpler statistical models. One of the main causes of this suboptimal performance is the data non-stationarity present in many processes. In particular, changes in the mean and variance of the input data can disrupt the predictive capability of a DNN. In this paper, we first show how DNN forecasting models fail in simple non-stationary settings. We then introduce GAS-Norm, a novel methodology for adaptive time series normalization and forecasting based on the combination of a Generalized Autoregressive Score (GAS) model and a Deep Neural Network. The GAS approach encompasses a score-driven family of models that estimate the mean and variance at each new observation, providing updated statistics to normalize the input data of the deep model. The output of the DNN is eventually denormalized using the statistics forecasted by the GAS model, resulting in a hybrid approach that leverages the strengths of both statistical modeling and deep learning. The adaptive normalization improves the performance of the model in non-stationary settings. The proposed approach is model-agnostic and can be applied to any DNN forecasting model. To empirically validate our proposal, we first compare GAS-Norm with other state-of-the-art normalization methods. We then combine it with state-of-the-art DNN forecasting models and test them on real-world datasets from the Monash open-access forecasting repository. Results show that deep forecasting models improve their performance in 21 out of 25 settings when combined with GAS-Norm compared to other normalization methods.|尽管深度神经网络（DNNs）在时间序列预测中广受欢迎，但它们往往无法超越更简单的统计模型。这种次优性能的主要原因之一是许多过程中存在的数据非平稳性。特别是，输入数据的均值和方差变化可能会破坏DNN的预测能力。在本文中，我们首先展示了DNN预测模型在简单非平稳环境中的失败情况。然后，我们引入了GAS-Norm，这是一种基于广义自回归评分（GAS）模型和深度神经网络相结合的自适应时间序列归一化和预测的新方法。GAS方法包含了一类评分驱动的模型，这些模型在每个新观测值处估计均值和方差，为深度模型的输入数据提供更新的统计量进行归一化。DNN的输出最终使用GAS模型预测的统计量进行反归一化，从而形成一种结合了统计建模和深度学习优势的混合方法。这种自适应归一化提高了模型在非平稳环境中的性能。所提出的方法是模型无关的，可以应用于任何DNN预测模型。为了实证验证我们的提议，我们首先将GAS-Norm与其他最先进的归一化方法进行比较。然后，我们将其与最先进的DNN预测模型结合，并在Monash开放访问预测库中的真实世界数据集上进行测试。结果显示，与其他归一化方法相比，结合GAS-Norm的深度预测模型在25种环境中的21种中提高了性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GAS-Norm:+Score-Driven+Adaptive+Normalization+for+Non-Stationary+Time+Series+Forecasting+in+Deep+Learning)|0|
|[Causal Probing for Dual Encoders](https://doi.org/10.1145/3627673.3679556)|Jonas Wallat, Hauke Hinrichs, Avishek Anand|Department of Software Technology, Delft University of Technology, Delft, Netherlands; L3S Research Center, Hannover, Germany|Dual encoders are highly effective and widely deployed in the retrieval phase for passage and document ranking, question answering, or retrieval-augmented generation (RAG) setups. Most dual-encoder models use transformer models like BERT to map input queries and output targets to a common vector space encoding the semantic similarity. Despite their prevalence and impressive performance, little is known about the inner workings of dense encoders for retrieval. We investigate neural retrievers using the probing paradigm to identify well-understood IR properties that causally result in ranking performance. Unlike existing works that have probed cross-encoders to show query-document interactions, we provide a principled approach to probe dual-encoders. Importantly, we employ causal probing to avoid correlation effects that might be artefacts of vanilla probing. We conduct extensive experiments on one such dual encoder (TCT-ColBERT) to check for the existence and relevance of six properties: term importance, lexical matching (BM25), semantic matching, question classification, and the two linguistic properties of named entity recognition and coreference resolution. Our layer-wise analysis shows important differences between re-rankers and dual encoders, establishing which tasks are not only understood by the model but also used for inference.|双编码器在段落和文档排序、问答系统或检索增强生成（RAG）等场景的检索阶段非常有效且被广泛部署。大多数双编码器模型使用如BERT这样的Transformer模型，将输入查询和输出目标映射到一个共同的向量空间，以编码语义相似性。尽管它们普遍存在且表现出色，但人们对于用于检索的密集编码器的内部工作机制知之甚少。我们使用探测范式来研究神经检索器，以识别那些能够因果影响排序性能的、易于理解的信息检索（IR）属性。与现有工作主要探测交叉编码器以展示查询-文档交互不同，我们提供了一种原则性的方法来探测双编码器。重要的是，我们采用因果探测以避免普通探测可能带来的相关性效应。我们在一个双编码器（TCT-ColBERT）上进行了大量实验，以检查六种属性的存在和相关性：术语重要性、词汇匹配（BM25）、语义匹配、问题分类以及命名实体识别和共指消解这两个语言属性。我们的分层分析显示了重排序器和双编码器之间的重要差异，确定了哪些任务不仅被模型理解，还被用于推理。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causal+Probing+for+Dual+Encoders)|0|
|[HC-GST: Heterophily-aware Distribution Consistency based Graph Self-training](https://doi.org/10.1145/3627673.3679622)|Fali Wang, Tianxiang Zhao, Junjie Xu, Suhang Wang||Graph self-training (GST), which selects and assigns pseudo-labels to unlabeled nodes, is popular for tackling label sparsity in graphs. However, recent study on homophily graphs show that GST methods could introduce and amplify distribution shift between training and test nodes as they tend to assign pseudo-labels to nodes they are good at. As GNNs typically perform better on homophilic nodes, there could be potential shifts towards homophilic pseudo-nodes, which is underexplored. Our preliminary experiments on heterophilic graphs verify that these methods can cause shifts in homophily ratio distributions, leading to training bias that improves performance on homophilic nodes while degrading it on heterophilic ones. Therefore, we study a novel problem of reducing homophily ratio distribution shifts during self-training on heterophilic graphs. A key challenge is the accurate calculation of homophily ratios and their distributions without extensive labeled data. To tackle them, we propose a novel Heterophily-aware Distribution Consistency-based Graph Self-Training (HC-GST) framework, which estimates homophily ratios using soft labels and optimizes a selection vector to align pseudo-nodes with the global homophily ratio distribution. Extensive experiments on both homophilic and heterophilic graphs show that HC-GST effectively reduces training bias and enhances self-training performance.|图自训练（Graph Self-Training, GST）通过为未标记节点选择并分配伪标签，成为解决图中标签稀疏性问题的流行方法。然而，最近关于同质性图的研究表明，GST方法可能会引入并放大训练节点和测试节点之间的分布偏移，因为这些方法倾向于为它们擅长的节点分配伪标签。由于图神经网络（GNNs）通常在同质性节点上表现更好，这可能导致伪节点向同质性方向偏移，而这一现象尚未得到充分研究。我们在异质性图上的初步实验验证了这些方法可能导致同质性比率分布的变化，从而引发训练偏差，即在同质性节点上提升性能的同时，在异质性节点上表现下降。因此，我们研究了一个新问题：如何在异质性图的自训练过程中减少同质性比率分布的偏移。一个关键挑战是在没有大量标记数据的情况下准确计算同质性比率及其分布。为了解决这一问题，我们提出了一种新颖的基于异质性感知分布一致性的图自训练框架（Heterophily-aware Distribution Consistency-based Graph Self-Training, HC-GST），该框架利用软标签估计同质性比率，并通过优化选择向量使伪节点与全局同质性比率分布对齐。在同质性和异质性图上的大量实验表明，HC-GST有效减少了训练偏差，并提升了自训练的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HC-GST:+Heterophily-aware+Distribution+Consistency+based+Graph+Self-training)|0|
|[MMPolymer: A Multimodal Multitask Pretraining Framework for Polymer Property Prediction](https://doi.org/10.1145/3627673.3679684)|Fanmeng Wang, Wentao Guo, Minjie Cheng, Shen Yuan, Hongteng Xu, Zhifeng Gao||Polymers are high-molecular-weight compounds constructed by the covalent bonding of numerous identical or similar monomers so that their 3D structures are complex yet exhibit unignorable regularity. Typically, the properties of a polymer, such as plasticity, conductivity, bio-compatibility, and so on, are highly correlated with its 3D structure. However, existing polymer property prediction methods heavily rely on the information learned from polymer SMILES sequences (P-SMILES strings) while ignoring crucial 3D structural information, resulting in sub-optimal performance. In this work, we propose MMPolymer, a novel multimodal multitask pretraining framework incorporating polymer 1D sequential and 3D structural information to encourage downstream polymer property prediction tasks. Besides, considering the scarcity of polymer 3D data, we further introduce the "Star Substitution" strategy to extract 3D structural information effectively. During pretraining, in addition to predicting masked tokens and recovering clear 3D coordinates, MMPolymer achieves the cross-modal alignment of latent representations. Then we further fine-tune the pretrained MMPolymer for downstream polymer property prediction tasks in the supervised learning paradigm. Experiments show that MMPolymer achieves state-of-the-art performance in downstream property prediction tasks. Moreover, given the pretrained MMPolymer, utilizing merely a single modality in the fine-tuning phase can also outperform existing methods, showcasing the exceptional capability of MMPolymer in polymer feature extraction and utilization.|聚合物是由众多相同或相似的单体通过共价键结合而成的高分子量化合物，其三维结构复杂但表现出不可忽视的规律性。通常，聚合物的特性，如塑性、导电性、生物相容性等，与其三维结构高度相关。然而，现有的聚合物特性预测方法主要依赖于从聚合物SMILES序列（P-SMILES字符串）中学习到的信息，而忽略了关键的三维结构信息，导致性能欠佳。在本研究中，我们提出了MMPolymer，一种新颖的多模态多任务预训练框架，结合了聚合物的一维序列和三维结构信息，以促进下游的聚合物特性预测任务。此外，考虑到聚合物三维数据的稀缺性，我们进一步引入了“星形替换”策略，以有效提取三维结构信息。在预训练过程中，除了预测被遮蔽的标记和恢复清晰的三维坐标外，MMPolymer还实现了潜在表示的跨模态对齐。然后，我们在监督学习范式下进一步微调预训练的MMPolymer，用于下游的聚合物特性预测任务。实验表明，MMPolymer在下游特性预测任务中实现了最先进的性能。此外，给定预训练的MMPolymer，在微调阶段仅使用单一模态也能超越现有方法，展示了MMPolymer在聚合物特征提取和利用方面的卓越能力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MMPolymer:+A+Multimodal+Multitask+Pretraining+Framework+for+Polymer+Property+Prediction)|0|
|[Trojan Activation Attack: Red-Teaming Large Language Models using Steering Vectors for Safety-Alignment](https://doi.org/10.1145/3627673.3679821)|Haoran Wang, Kai Shu|Illinois Institute of Technology Chicago|To ensure AI safety, instruction-tuned Large Language Models (LLMs) are specifically trained to ensure alignment, which refers to making models behave in accordance with human intentions. While these models have demonstrated commendable results on various safety benchmarks, the vulnerability of their safety alignment has not been extensively studied. This is particularly troubling given the potential harm that LLMs can inflict. Existing attack methods on LLMs often rely on poisoned training data or the injection of malicious prompts. These approaches compromise the stealthiness and generalizability of the attacks, making them susceptible to detection. Additionally, these models often demand substantial computational resources for implementation, making them less practical for real-world applications. In this work, we study a different attack scenario, called Trojan Activation Attack (TA^2), which injects trojan steering vectors into the activation layers of LLMs. These malicious steering vectors can be triggered at inference time to steer the models toward attacker-desired behaviors by manipulating their activations. Our experiment results on four primary alignment tasks show that TA^2 is highly effective and adds little or no overhead to attack efficiency. Additionally, we discuss potential countermeasures against such activation attacks.|为确保人工智能的安全性，指令微调的大型语言模型（LLMs）经过专门训练以实现对齐，即让模型的行为符合人类意图。尽管这些模型在各种安全基准测试中表现出了令人称赞的结果，但其安全对齐的脆弱性尚未得到广泛研究。考虑到LLMs可能造成的潜在危害，这一点尤其令人担忧。现有的对LLMs的攻击方法通常依赖于投毒的训练数据或注入恶意提示。这些方法损害了攻击的隐蔽性和泛化性，使其容易被检测到。此外，这些模型通常需要大量的计算资源来实施，使其在实际应用中不太实用。在本研究中，我们探讨了一种不同的攻击场景，称为木马激活攻击（TA^2），该攻击将木马导向向量注入LLMs的激活层。这些恶意导向向量可以在推理时被触发，通过操纵模型的激活来引导模型朝向攻击者期望的行为。我们在四项主要对齐任务上的实验结果表明，TA^2非常有效，并且对攻击效率几乎没有增加额外开销。此外，我们还讨论了对这种激活攻击的潜在防御措施。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Trojan+Activation+Attack:+Red-Teaming+Large+Language+Models+using+Steering+Vectors+for+Safety-Alignment)|0|
|[MANA-Net: Mitigating Aggregated Sentiment Homogenization with News Weighting for Enhanced Market Prediction](https://doi.org/10.1145/3627673.3679653)|Mengyu Wang, Tiejun Ma||It is widely acknowledged that extracting market sentiments from news data benefits market predictions. However, existing methods of using financial sentiments remain simplistic, relying on equal-weight and static aggregation to manage sentiments from multiple news items. This leads to a critical issue termed “Aggregated Sentiment Homogenization”, which has been explored through our analysis of a large financial news dataset from industry practice. This phenomenon occurs when aggregating numerous sentiments, causing representations to converge towards the mean values of sentiment distributions and thereby smoothing out unique and important information. Consequently, the aggregated sentiment representations lose much predictive value of news data. To address this problem, we introduce the Market Attention-weighted News Aggregation Network (MANA-Net), a novel method that leverages a dynamic market-news attention mechanism to aggregate news sentiments for market prediction. MANA-Net learns the relevance of news sentiments to price changes and assigns varying weights to individual news items. By integrating the news aggregation step into the networks for market prediction, MANA-Net allows for trainable sentiment representations that are optimized directly for prediction. We evaluate MANA-Net using the S P 500 and NASDAQ 100 indices, along with financial news spanning from 2003 to 2018. Experimental results demonstrate that MANA-Net outperforms various recent market prediction methods, enhancing Profit Loss by 1.1|广泛认为，从新闻数据中提取市场情绪有助于市场预测。然而，现有的金融情绪使用方法仍然较为简单，主要依赖于等权重和静态聚合来管理来自多条新闻的情绪。这导致了一个称为“聚合情绪同质化”的关键问题，我们通过对行业实践中大量金融新闻数据集的分析对此进行了探讨。这种现象在聚合大量情绪时发生，导致表示趋向于情绪分布的平均值，从而平滑掉独特且重要的信息。因此，聚合后的情绪表示失去了新闻数据的许多预测价值。为了解决这个问题，我们引入了市场注意力加权新闻聚合网络（MANA-Net），这是一种新颖的方法，利用动态市场-新闻注意力机制来聚合新闻情绪以进行市场预测。MANA-Net学习新闻情绪与价格变化的相关性，并为单个新闻项分配不同的权重。通过将新闻聚合步骤整合到市场预测网络中，MANA-Net允许可训练的情绪表示直接为预测进行优化。我们使用标普500指数和纳斯达克100指数以及2003年至2018年的金融新闻对MANA-Net进行了评估。实验结果表明，MANA-Net优于最近的各种市场预测方法，将盈亏提高了1.1。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MANA-Net:+Mitigating+Aggregated+Sentiment+Homogenization+with+News+Weighting+for+Enhanced+Market+Prediction)|0|
|[DDIPrompt: Drug-Drug Interaction Event Prediction based on Graph Prompt Learning](https://doi.org/10.1145/3627673.3679645)|Yingying Wang, Yun Xiong, Xixi Wu, Xiangguo Sun, Jiawei Zhang, Guangyong Zheng||Drug combinations can cause adverse drug-drug interactions(DDIs). Identifying specific effects is crucial for developing safer therapies. Previous works on DDI event prediction have typically been limited to using labels of specific events as supervision, which renders them insufficient to address two significant challenges: (1) the bias caused by highly imbalanced event distribution where certain interaction types are vastly under-represented. (2) the scarcity of labeled data for rare events, a pervasive issue where rare yet potentially critical interactions are often overlooked or under-explored due to limited available data. In response, we offer “DDIPrompt”, an innovative solution inspired by the recent advancements in graph prompt learning. Our framework aims to address these issues by leveraging the intrinsic knowledge from pre-trained models, which can be efficiently deployed with minimal downstream data. Specifically, to solve the first challenge, DDIPrompt features a hierarchical pre-training strategy to foster a generalized and comprehensive understanding of drug properties. It captures intra-molecular structures through augmented links based on structural proximity between drugs, further learns inter-molecular interactions emphasizing edge connections rather than concrete catagories. For the second challenge, we implement a prototype-enhanced prompting mechanism during inference. This mechanism, refined by few-shot examples from each category, effectively harnesses the rich pre-training knowledge to enhance prediction accuracy, particularly for these rare but crucial interactions. Extensive experiments on two benchmark datasets demonstrate DDIPrompt's SOTA performance, especially for those rare DDI events.|药物组合可能导致不良的药物-药物相互作用（DDIs）。识别特定效应对于开发更安全的治疗方案至关重要。以往关于DDI事件预测的研究通常仅限于使用特定事件的标签作为监督，这使得它们在解决两个重大挑战时显得不足：（1）由高度不平衡的事件分布引起的偏差，其中某些相互作用类型在数据中严重不足。（2）稀有事件的标注数据稀缺，这是一个普遍存在的问题，稀有但可能关键的相互作用由于可用数据有限而常常被忽视或未充分探索。为此，我们提出了“DDIPrompt”，这是一个受图提示学习最新进展启发的创新解决方案。我们的框架旨在通过利用预训练模型的内在知识来解决这些问题，这些模型可以在下游数据极少的情况下高效部署。具体来说，为了解决第一个挑战，DDIPrompt采用了一种分层次的预训练策略，以促进对药物属性的广义和全面理解。它通过基于药物结构邻近性的增强链接捕捉分子内结构，进一步学习分子间相互作用，强调边缘连接而非具体类别。对于第二个挑战，我们在推理过程中实施了一种原型增强的提示机制。这种机制通过每个类别的少量示例进行优化，有效地利用了丰富的预训练知识，以提高预测准确性，特别是对于那些稀有但至关重要的相互作用。在两个基准数据集上的大量实验表明，DDIPrompt在SOTA性能方面表现出色，尤其是对于那些稀有DDI事件。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DDIPrompt:+Drug-Drug+Interaction+Event+Prediction+based+on+Graph+Prompt+Learning)|0|
|[Inferring Information Diffusion Networks without Timestamps](https://doi.org/10.1145/3627673.3679798)|Yuchen Wang, Dongpeng Hou, Chao Gao, Xianghua Li, Zhen Wang|Northwestern Polytechnical University, Xi'an, Shaanxi, China|The topology of diffusion networks plays an essential role in understanding information propagation dynamics and conducting social network analysis. However, diffusion networks are often unobservable in practical applications, leading to wide research on network inference from information cascades over the past decade. At present, novel cascades-based methods have been further developed to recover temporal dynamics and network topology by exploring the utilization of node temporal information, resulting in notable advancements. However, it requires high costs to acquire extensive temporal information, and the performance of network inference may decrease due to potential observational errors. Therefore, this paper specifically focuses on the time-independent scenario to address these limitations. Firstly, this paper models the node statuses of each diffusion process by leveraging the assumption of propagation trees based on the well-known independent cascade model. Subsequently, a gradient-based approach is developed to estimate the influences between nodes, facilitating the inference of network structure. Furthermore, this paper proposes a Monte Carlo EM-based approach to enhance the efficiency of network inference while maintaining comparable accuracy. Extensive experiments are conducted to verify the efficiency and effectiveness of our approaches on both synthetic and real-world networks.|扩散网络的拓扑结构在理解信息传播动力学和进行社交网络分析中起着至关重要的作用。然而，在实际应用中，扩散网络往往是不可观测的，这导致了过去十年来基于信息级联的网络推断研究的广泛开展。目前，基于级联的新方法通过探索节点时间信息的利用，进一步发展为恢复时间动态和网络拓扑结构，取得了显著进展。然而，获取大量时间信息的成本较高，且网络推断的性能可能由于潜在的观测误差而下降。因此，本文特别关注时间无关的场景，以解决这些限制。首先，本文利用基于著名的独立级联模型的传播树假设，对每个扩散过程的节点状态进行建模。随后，开发了一种基于梯度的方法来估计节点之间的影响，从而促进网络结构的推断。此外，本文提出了一种基于蒙特卡罗EM的方法，以提高网络推断的效率，同时保持相当的准确性。在合成网络和真实网络上进行的大量实验验证了我们方法的效率和有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Inferring+Information+Diffusion+Networks+without+Timestamps)|0|
|[A Mixed-Curvature Graph Diffusion Model](https://doi.org/10.1145/3627673.3679708)|Yujie Wang, Shuo Zhang, Junda Ye, Hao Peng, Li Sun|Beijing University of Posts and Telecommunications, Beijing, China; North China Electric Power University, Beijing, China; Beihang University, Beijing, China|Graph generation plays a vital role in a wide range of applications such as traffic analysis, drug discovery and more, for its rapid and efficient generation speed coupled with its precise and stable generation capabilities. And the diffusion model, which is the dominant solution in image generation domain, has shown its potential in graph generation recently. In the literature, existing graph diffusion models trivialize the graph structure, and prioritize the Euclidean space for graph generation, ignoring the intrinsic difference between non-Euclidean graph structures and Euclidean grid-like image/text data. The few graph diffusion models in hyperbolic space separate the embedding and diffusion process, and loose the geometric constraints in the diffusion process. The problem of generating graph structure in a generic Riemannian space largely remains open. It faces several fundamental challenges. On the one hand, navigating and structuring graphs within Riemannian spaces poses greater difficulty. In other words, how to preserve adherence to the constraints of Riemannian geometry has not been touched in the literature. On the other hand, Riemannian operators for graph diffusion models are not available so far, which is inherently different from that in Euclidean space. In light of the aforementioned issues, we restore the notion of product space, and propose a generic graph generation method, called mixed-curvature Product Space Graph Diffusion Model (ProGDM). Specifically, ProGDM includes a Riemannian embedding module based on contrastive learning and a geometric diffusion models across multiple Riemannian sub-spaces. We evaluate the proposed ProGDM with extensive experiments on benchmark datasets, and the empirical results show that ProGDM has achieved superior performance to the state-of-the-art methods.|图生成在交通分析、药物发现等众多应用中发挥着至关重要的作用，因为它具有快速高效的生成速度以及精确稳定的生成能力。扩散模型作为图像生成领域的主导解决方案，最近在图生成领域也展现了其潜力。然而，现有的图扩散模型在文献中往往简化了图结构，并优先在欧几里得空间中进行图生成，忽略了非欧几里得图结构与欧几里得网格状图像/文本数据之间的本质差异。少数在双曲空间中的图扩散模型将嵌入过程和扩散过程分离，并在扩散过程中失去了几何约束。在一般的黎曼空间中生成图结构的问题在很大程度上仍未得到解决，并面临几个基本挑战。一方面，在黎曼空间中导航和构建图结构更为困难。换句话说，如何在生成过程中保持对黎曼几何约束的遵循尚未在文献中得到探讨。另一方面，迄今为止，图扩散模型的黎曼算子尚未出现，这与欧几里得空间中的算子有本质上的不同。

针对上述问题，我们恢复了乘积空间的概念，并提出了一种通用的图生成方法，称为混合曲率乘积空间图扩散模型（ProGDM）。具体而言，ProGDM包括一个基于对比学习的黎曼嵌入模块和一个跨多个黎曼子空间的几何扩散模型。我们在基准数据集上通过大量实验对所提出的ProGDM进行了评估，实验结果表明，ProGDM在性能上优于当前最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Mixed-Curvature+Graph+Diffusion+Model)|0|
|[GAD: A Generalized Framework for Anomaly Detection at Different Risk Levels](https://doi.org/10.1145/3627673.3679634)|Rulan Wei, Zewei He, Martin Pavlovski, Fang Zhou|Temple University, Philadelphia, PA, USA; East China Normal University, Shanghai, China|Anomaly detection is a crucial data mining problem due to its extensive range of applications. In real-world scenarios, anomalies often exhibit different levels of priority. Unfortunately, existing methods tend to overlook this phenomenon and identify all types of anomalies into a single class. In this paper, we propose a generalized formulation of the anomaly detection problem, which covers not only the conventional anomaly detection task, but also the partial anomaly detection task that is focused on identifying target anomalies of primary interest while intentionally disregarding non-target (low-risk) anomalies. One of the challenges in addressing this problem is the overlap among normal instances and anomalies of different levels of priority, which may cause high false positive rates. Additionally, acquiring a sufficient quantity of all types of labeled non-target anomalies is not always feasible. For this purpose, we present a generalized anomaly detection framework flexible in addressing a broader range of anomaly detection scenarios. Employing a dual-center mechanism to handle relationships among normal instances, non-target anomalies, and target anomalies, the proposed framework significantly reduces the number of false positives caused by class overlap and tackles the challenge of limited amount of labeled data. Extensive experiments conducted on two publicly available datasets from different domains demonstrate the effectiveness, robustness and superior labeled data utilization of the proposed framework. When applied to a real-world application, it exhibits a lift of at least 7.08% in AUPRC compared to the alternatives, showcasing its remarkable practicality.|异常检测是一个关键的数据挖掘问题，因其广泛的应用范围而备受关注。在现实场景中，异常通常表现出不同的优先级。遗憾的是，现有方法往往忽视这一现象，并将所有类型的异常归为一类。本文提出了一种广义的异常检测问题公式化方法，不仅涵盖了传统的异常检测任务，还包括部分异常检测任务，即专注于识别主要关注的目标异常，同时有意忽略非目标（低风险）异常。解决这一问题的一个挑战在于正常实例与不同优先级异常之间的重叠，这可能导致较高的误报率。此外，获取足够数量的所有类型的标记非目标异常数据并不总是可行的。为此，我们提出了一种广义的异常检测框架，能够灵活应对更广泛的异常检测场景。该框架采用双中心机制来处理正常实例、非目标异常和目标异常之间的关系，显著减少了由类别重叠引起的误报数量，并解决了标记数据量有限的挑战。在不同领域的两个公开数据集上进行的大量实验表明，所提出的框架具有有效性、鲁棒性和优越的标记数据利用率。在实际应用中，与其他方法相比，该框架在AUPRC指标上至少提升了7.08%，展示了其显著的实用性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GAD:+A+Generalized+Framework+for+Anomaly+Detection+at+Different+Risk+Levels)|0|
|[OptDist: Learning Optimal Distribution for Customer Lifetime Value Prediction](https://doi.org/10.1145/3627673.3679712)|Yunpeng Weng, Xing Tang, Zhenhao Xu, Fuyuan Lyu, Dugang Liu, Zexu Sun, Xiuqiang He||Customer Lifetime Value (CLTV) prediction is a critical task in business applications. Accurately predicting CLTV is challenging in real-world business scenarios, as the distribution of CLTV is complex and mutable. Firstly, there is a large number of users without any consumption consisting of a long-tailed part that is too complex to fit. Secondly, the small set of high-value users spent orders of magnitude more than a typical user leading to a wide range of the CLTV distribution which is hard to capture in a single distribution. Existing approaches for CLTV estimation either assume a prior probability distribution and fit a single group of distribution-related parameters for all samples, or directly learn from the posterior distribution with manually predefined buckets in a heuristic manner. However, all these methods fail to handle complex and mutable distributions. In this paper, we propose a novel optimal distribution selection model OptDist for CLTV prediction, which utilizes an adaptive optimal sub-distribution selection mechanism to improve the accuracy of complex distribution modeling. Specifically, OptDist trains several candidate sub-distribution networks in the distribution learning module (DLM) for modeling the probability distribution of CLTV. Then, a distribution selection module (DSM) is proposed to select the sub-distribution for each sample, thus making the selection automatically and adaptively. Besides, we design an alignment mechanism that connects both modules, which effectively guides the optimization. We conduct extensive experiments on both two public and one private dataset to verify that OptDist outperforms state-of-the-art baselines. Furthermore, OptDist has been deployed on a large-scale financial platform for customer acquisition marketing campaigns and the online experiments also demonstrate the effectiveness of OptDist.|客户终身价值（CLTV）预测是商业应用中的一项关键任务。在实际的商业场景中，准确预测CLTV具有挑战性，因为CLTV的分布复杂且多变。首先，存在大量没有任何消费的用户，这些用户构成了一个长尾部分，其复杂性使得难以拟合。其次，一小部分高价值用户的消费金额比普通用户高出几个数量级，导致CLTV分布范围广泛，难以用单一分布捕捉。现有的CLTV估计方法要么假设一个先验概率分布并为所有样本拟合一组与分布相关的参数，要么以启发式的方式直接从手动预定义的桶中进行后验分布学习。然而，这些方法都无法处理复杂且多变的分布。

本文提出了一种新颖的最优分布选择模型OptDist用于CLTV预测，该模型利用自适应最优子分布选择机制来提高复杂分布建模的准确性。具体来说，OptDist在分布学习模块（DLM）中训练多个候选子分布网络，用于建模CLTV的概率分布。然后，提出了一个分布选择模块（DSM），为每个样本选择子分布，从而实现自动化和自适应的选择。此外，我们设计了一个连接这两个模块的对齐机制，有效指导优化过程。

我们在两个公开数据集和一个私有数据集上进行了广泛的实验，验证了OptDist优于现有的最先进基线方法。此外，OptDist已在一个大型金融平台上部署，用于客户获取营销活动，在线实验也证明了OptDist的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=OptDist:+Learning+Optimal+Distribution+for+Customer+Lifetime+Value+Prediction)|0|
|[Identifying Contemporaneous and Lagged Dependence Structures by Promoting Sparsity in Continuous-time Neural Networks](https://doi.org/10.1145/3627673.3679751)|Fan Wu, Woojin Cho, David Korotky, Sanghyun Hong, Donsub Rim, Noseong Park, Kookjin Lee|Yonsei University, Seoul, Republic of Korea; Oregon State University, Corvallis, OR, USA; Arizona State University, Tempe, AZ, USA; Washington University in St. Louis, St. Louis, MO, USA; KAIST, Daejeon, Republic of Korea|Continuous-time dynamics models, e.g., neural ordinary differential equations, enable accurate modeling of underlying dynamics in time-series data. However, employing neural networks for parameterizing dynamics makes it challenging for humans to identify dependence structures, especially in the presence of delayed effects. In consequence, these models are not an attractive option when capturing dependence carries more importance than accurate modeling, e.g., in tsunami forecasting. In this paper, we present a novel method for identifying dependence structures in continuous-time dynamics models. We take a two-step approach: (1) During training, we promote weight sparsity in the model's first layer during training. (2) We prune the sparse weights after training to identify dependence structures. In evaluation, we test our method in scenarios where the exact dependence-structures of time-series are known. Compared to baselines, our method is more effective in uncovering dependence structures in data even when there are delayed effects. Moreover, we evaluate our method to a real-world tsunami forecasting, where the exact dependence structures are unknown beforehand. Even in this challenging scenario, our method still effective learns physically-consistent dependence structures and achieves high accuracy in forecasting.|连续时间动态模型，例如神经常微分方程，能够准确建模时间序列数据中的潜在动态。然而，使用神经网络来参数化动态模型使得人类难以识别依赖结构，特别是在存在延迟效应的情况下。因此，当捕捉依赖关系比精确建模更为重要时（例如在海啸预测中），这些模型并不是一个理想的选择。本文提出了一种新的方法，用于识别连续时间动态模型中的依赖结构。我们采用了两步法：（1）在训练过程中，我们在模型的第一层中促进权重稀疏性。（2）在训练后，我们对稀疏权重进行剪枝以识别依赖结构。在评估中，我们在已知时间序列确切依赖结构的情况下测试了我们的方法。与基线方法相比，我们的方法在揭示数据中的依赖结构方面更为有效，即使存在延迟效应。此外，我们将我们的方法应用于真实世界的海啸预测中，其中依赖结构事先未知。即使在这种具有挑战性的场景中，我们的方法仍然能够有效地学习物理上一致的依赖结构，并在预测中实现高精度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Identifying+Contemporaneous+and+Lagged+Dependence+Structures+by+Promoting+Sparsity+in+Continuous-time+Neural+Networks)|0|
|[StatioCL: Contrastive Learning for Time Series via Non-Stationary and Temporal Contrast](https://doi.org/10.1145/3627673.3679732)|Yu Yvonne Wu, Ting Dang, Dimitris Spathis, Hong Jia, Cecilia Mascolo||Contrastive learning (CL) has emerged as a promising approach for representation learning in time series data by embedding similar pairs closely while distancing dissimilar ones. However, existing CL methods often introduce false negative pairs (FNPs) by neglecting inherent characteristics and then randomly selecting distinct segments as dissimilar pairs, leading to erroneous representation learning, reduced model performance, and overall inefficiency. To address these issues, we systematically define and categorize FNPs in time series into semantic false negative pairs and temporal false negative pairs for the first time: the former arising from overlooking similarities in label categories, which correlates with similarities in non-stationarity and the latter from neglecting temporal proximity. Moreover, we introduce StatioCL, a novel CL framework that captures non-stationarity and temporal dependency to mitigate both FNPs and rectify the inaccuracies in learned representations. By interpreting and differentiating non-stationary states, which reflect the correlation between trends or temporal dynamics with underlying data patterns, StatioCL effectively captures the semantic characteristics and eliminates semantic FNPs. Simultaneously, StatioCL establishes fine-grained similarity levels based on temporal dependencies to capture varying temporal proximity between segments and to mitigate temporal FNPs. Evaluated on real-world benchmark time series classification datasets, StatioCL demonstrates a substantial improvement over state-of-the-art CL methods, achieving a 2.9 increase in Recall and a 19.2 also shows enhanced data efficiency and robustness against label scarcity.|对比学习（Contrastive Learning, CL）作为一种有前景的方法，在时间序列数据的表示学习中取得了显著进展，其通过将相似样本对紧密嵌入同时拉开不相似样本对的距离来学习表示。然而，现有的对比学习方法常常因忽略时间序列的固有特性而引入虚假负样本对（False Negative Pairs, FNPs），即随机选择不同片段作为不相似样本对，这会导致错误的表示学习、降低模型性能并影响整体效率。为了解决这些问题，我们首次系统性地定义了时间序列中的虚假负样本对，并将其分为**语义虚假负样本对**和**时间虚假负样本对**：前者由于忽略了标签类别之间的相似性而产生，这种相似性与非平稳性相关；后者则因忽视时间邻近性而产生。此外，我们提出了一种新颖的对比学习框架——**StatioCL**，该框架通过捕捉非平稳性和时间依赖性来缓解这两类虚假负样本对，从而纠正学习表示中的不准确性。通过解释和区分非平稳状态（这些状态反映了趋势或时间动态与底层数据模式之间的相关性），StatioCL能够有效捕捉语义特征并消除语义虚假负样本对。同时，StatioCL基于时间依赖性建立了细粒度的相似性级别，以捕捉不同片段之间的时间邻近性差异，从而缓解时间虚假负样本对。在真实世界的时间序列分类基准数据集上的评估表明，StatioCL相较于最先进的对比学习方法有显著提升，召回率（Recall）提高了2.9，F1分数提高了19.2。此外，StatioCL还展现出更高的数据效率和对标签稀缺性的鲁棒性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=StatioCL:+Contrastive+Learning+for+Time+Series+via+Non-Stationary+and+Temporal+Contrast)|0|
|[Advancing Certified Robustness of Explanation via Gradient Quantization](https://doi.org/10.1145/3627673.3679650)|Yang Xiao, Zijie Zhang, Yuchen Fang, Da Yan, Yang Zhou, WeiShinn Ku, Bo Hui|University of Electronic Science and Technology of China, Chengdu, China; Auburn University, Auburn, AL, USA; Social Psychology, Nankai Unviersity, Tianjin, China; Indiana University Bloomington, Bloomington, AL, USA; University of Texas at San Antonio, San Antonio, TX, USA; Auburn University, Auburn, USA; University of Tulsa, Tulsa, AL, USA|Explaining black-box models is fundamental to gaining trust and deploying these models in real applications. As existing explanation methods have been shown to lack robustness against adversarial perturbations, there has been a growing interest in generating robust explanations. However, existing works resort to empirical defense strategies and these heuristic methods fail against powerful adversaries. In this paper, we certify the robustness of explanations motivated by the success of randomized smoothing. Specifically, we compute a tight radius in which the robustness of the explanation is certified. While a challenge is how to formulate the robustness of the explanation mathematically, we quantize the explanation into discrete spaces to mimic classification in randomized smoothing. To address the high computational cost of randomized smoothing, we introduce randomized gradient smoothing. Also, we explore the robustness of the semantic explanation by certifying the robustness of capsules. In the experiment, we demonstrate the effectiveness of our method on benchmark datasets from the perspectives of post-hoc explanation and semantic explanation respectively. Our work is a promising step towards filling the gap between the theoretical robustness bound and empirical explanations. Our code has been released at https://github.com/NKUShaw/CertifiedExplanation.|解释黑箱模型对于获得信任并在实际应用中部署这些模型至关重要。由于现有的解释方法已被证明在面对对抗性扰动时缺乏鲁棒性，因此生成鲁棒解释的兴趣日益增长。然而，现有的工作依赖于经验性的防御策略，这些启发式方法在面对强大的对手时往往失效。在本文中，我们借鉴随机平滑的成功经验，证明了解释的鲁棒性。具体而言，我们计算了一个紧致的半径，在该半径内解释的鲁棒性得到了保证。尽管一个挑战是如何在数学上表达解释的鲁棒性，但我们将解释量化为离散空间，以模拟随机平滑中的分类。为了解决随机平滑的高计算成本问题，我们引入了随机梯度平滑。此外，我们还通过验证胶囊的鲁棒性来探索语义解释的鲁棒性。在实验中，我们分别从后验解释和语义解释的角度在基准数据集上展示了我们方法的有效性。我们的工作朝着填补理论鲁棒性界限与经验解释之间的空白迈出了有希望的一步。我们的代码已发布在 https://github.com/NKUShaw/CertifiedExplanation。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Advancing+Certified+Robustness+of+Explanation+via+Gradient+Quantization)|0|
|[GetCom: An Efficient and Generalizable Framework for Community Detection](https://doi.org/10.1145/3627673.3679865)|Kaiyu Xiong, Yucheng Jin, Yun Xiong, Jiawei Zhang|; IFM Lab, Department of Computer Science, University of California, Davis, CA, USA|Community detection plays a pivotal role in network analysis, with applications in recommendation systems, anomaly detection, and biochemistry. However, traditional methods, while computationally efficient, often fall short in managing the complexities of real-world network structures. In contrast, deep learning approaches enhance accuracy but require substantial computational resources and task-specific architectures. This paper introduce GetCom, a novel three-phase "pre-train, generate, prompt" framework that integrates traditional methods and deep learning techniques. In the pre-training phase, GetCom acquires comprehensive understanding of community structures, which provides a solid foundation for the subsequent phases. During the generation phase, traditional community detection methods are employed to efficiently identify potential communities, which are subsequently refined in the prompt learning phase. This integration offers an efficient, accurate, and generalizable solution for community detection. Experiments on five real-world network datasets demonstrate that GetCom achieves state-of-the-art performance, with strong efficiency and generalization capabilities across diverse datasets and tasks.|社区检测在网络分析中扮演着关键角色，广泛应用于推荐系统、异常检测和生物化学等领域。然而，传统方法虽然在计算上较为高效，但在处理现实世界网络结构的复杂性时往往表现不足。相比之下，深度学习方法提高了准确性，但需要大量的计算资源和针对特定任务的架构。本文提出了GetCom，一种新颖的三阶段“预训练、生成、提示”框架，该框架结合了传统方法和深度学习技术。在预训练阶段，GetCom获取对社区结构的全面理解，为后续阶段奠定坚实基础。在生成阶段，采用传统社区检测方法高效识别潜在社区，随后在提示学习阶段对这些社区进行优化。这种整合为社区检测提供了一种高效、准确且可推广的解决方案。在五个现实世界网络数据集上的实验表明，GetCom在多种数据集和任务中均实现了最先进的性能，具有强大的效率和泛化能力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GetCom:+An+Efficient+and+Generalizable+Framework+for+Community+Detection)|0|
|[Editing Factual Knowledge and Explanatory Ability of Medical Large Language Models](https://doi.org/10.1145/3627673.3679673)|Derong Xu, Ziheng Zhang, Zhihong Zhu, Zhenxi Lin, Qidong Liu, Xian Wu, Tong Xu, Wanyu Wang, Yuyang Ye, Xiangyu Zhao, Enhong Chen, Yefeng Zheng||Model editing aims to precisely alter the behaviors of large language models (LLMs) in relation to specific knowledge, while leaving unrelated knowledge intact. This approach has proven effective in addressing issues of hallucination and outdated information in LLMs. However, the potential of using model editing to modify knowledge in the medical field remains largely unexplored, even though resolving hallucination is a pressing need in this area. Our observations indicate that current methods face significant challenges in dealing with specialized and complex knowledge in medical domain. Therefore, we propose MedLaSA, a novel Layer-wise Scalable Adapter strategy for medical model editing. MedLaSA harnesses the strengths of both adding extra parameters and locate-then-edit methods for medical model editing. We utilize causal tracing to identify the association of knowledge in neurons across different layers, and generate a corresponding scale set from the association value for each piece of knowledge. Subsequently, we incorporate scalable adapters into the dense layers of LLMs. These adapters are assigned scaling values based on the corresponding specific knowledge, which allows for the adjustment of the adapter's weight and rank. The more similar the content, the more consistent the scale between them. This ensures precise editing of semantically identical knowledge while avoiding impact on unrelated knowledge. To evaluate the editing impact on the behaviours of LLMs, we propose two model editing studies for medical domain: (1) editing factual knowledge for medical specialization and (2) editing the explanatory ability for complex knowledge. We build two novel medical benchmarking datasets and introduce a series of challenging and comprehensive metrics. Extensive experiments on medical LLMs demonstrate the editing efficiency of MedLaSA, without affecting unrelated knowledge.|模型编辑旨在精确改变大型语言模型（LLMs）在特定知识上的行为，同时保持不相关知识的完整性。这种方法已被证明在解决LLMs中的幻觉和过时信息问题上非常有效。然而，尽管在医疗领域解决幻觉问题是一个迫切需求，但利用模型编辑来修改医疗领域知识的潜力尚未得到充分探索。我们的观察表明，当前方法在处理医疗领域专业且复杂的知识时面临重大挑战。因此，我们提出了MedLaSA，一种新颖的层次可扩展适配器策略，用于医疗模型编辑。MedLaSA结合了添加额外参数和定位后编辑方法的优势，用于医疗模型编辑。我们利用因果追踪来识别不同层神经元中知识的关联，并根据每个知识的关联值生成相应的比例集。随后，我们在LLMs的密集层中引入可扩展适配器。这些适配器根据相应的特定知识分配比例值，从而调整适配器的权重和等级。内容越相似，它们之间的比例越一致。这确保了在编辑语义相同的知识时保持精确，同时避免影响不相关的知识。为了评估编辑对LLMs行为的影响，我们提出了两项针对医疗领域的模型编辑研究：(1) 编辑医疗专业化的事实知识；(2) 编辑复杂知识的解释能力。我们构建了两个新颖的医疗基准数据集，并引入了一系列具有挑战性和全面性的指标。在医疗LLMs上的大量实验证明了MedLaSA的编辑效率，且不影响不相关的知识。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Editing+Factual+Knowledge+and+Explanatory+Ability+of+Medical+Large+Language+Models)|0|
|[Contrasformer: A Brain Network Contrastive Transformer for Neurodegenerative Condition Identification](https://doi.org/10.1145/3627673.3679560)|Jiaxing Xu, Kai He, Mengcheng Lan, Qingtian Bian, Wei Li, Tieying Li, Yiping Ke, Miao Qiao||Understanding neurological disorder is a fundamental problem in neuroscience, which often requires the analysis of brain networks derived from functional magnetic resonance imaging (fMRI) data. Despite the prevalence of Graph Neural Networks (GNNs) and Graph Transformers in various domains, applying them to brain networks faces challenges. Specifically, the datasets are severely impacted by the noises caused by distribution shifts across sub-populations and the neglect of node identities, both obstruct the identification of disease-specific patterns. To tackle these challenges, we propose Contrasformer, a novel contrastive brain network Transformer. It generates a prior-knowledge-enhanced contrast graph to address the distribution shifts across sub-populations by a two-stream attention mechanism. A cross attention with identity embedding highlights the identity of nodes, and three auxiliary losses ensure group consistency. Evaluated on 4 functional brain network datasets over 4 different diseases, Contrasformer outperforms the state-of-the-art methods for brain networks by achieving up to 10.8% improvement in accuracy, which demonstrates its efficacy in neurological disorder identification. Case studies illustrate its interpretability, especially in the context of neuroscience. This paper provides a solution for analyzing brain networks, offering valuable insights into neurological disorders. Our code is available at .|理解神经系统疾病是神经科学中的一个基本问题，通常需要分析从功能性磁共振成像（fMRI）数据中提取的脑网络。尽管图神经网络（GNNs）和图变换器（Graph Transformers）在各个领域广泛应用，但将它们应用于脑网络仍面临挑战。具体而言，数据集受到子群体间分布变化引起的噪声以及节点身份忽视的严重影响，这两者都阻碍了疾病特定模式的识别。为了应对这些挑战，我们提出了Contrasformer，一种新颖的对比脑网络变换器。它通过双流注意力机制生成一个先验知识增强的对比图，以解决子群体间的分布变化问题。带有身份嵌入的交叉注意力机制突出了节点的身份，并通过三个辅助损失确保群体一致性。在4个不同疾病的脑网络数据集上进行的评估表明，Contrasformer在脑网络分析中优于现有方法，准确率提高了最多10.8%，这证明了其在神经系统疾病识别中的有效性。案例研究展示了其可解释性，特别是在神经科学背景下。本文提供了一种分析脑网络的解决方案，为神经系统疾病提供了有价值的见解。我们的代码可在以下网址获取：。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrasformer:+A+Brain+Network+Contrastive+Transformer+for+Neurodegenerative+Condition+Identification)|0|
|[scACT: Accurate Cross-modality Translation via Cycle-consistent Training from Unpaired Single-cell Data](https://doi.org/10.1145/3627673.3679576)|Siwei Xu, Junhao Liu, Jing Zhang|University of California, Irvine, Irvine, California, USA.|Single-cell sequencing technologies have revolutionized genomics by enabling the simultaneous profiling of various molecular modalities within individual cells. Their integration, especially cross-modality translation, offers deep insights into cellular regulatory mechanisms. Many methods have been developed for cross-modality translation, but their reliance on scarce high-quality co-assay data limits their applicability. Addressing this, we introduce scACT, a deep generative model designed to extract cross-modality biological insights from unpaired single-cell data. scACT tackles three major challenges: aligning unpaired multi-modal data via adversarial training, facilitating cross-modality translation without prior knowledge via cycle-consistent training, and enabling interpretable regulatory interconnections explorations via in-silico perturbations. To test its performance, we applied scACT on diverse single-cell datasets and found it outperformed existing methods in all three tasks. Finally, we have developed scACT as an individual open-source software package to advance single-cell omics data processing and analysis within the research community.|单细胞测序技术通过同时分析单个细胞内多种分子模态的信息，彻底改变了基因组学领域。这些技术的整合，尤其是跨模态翻译，为细胞调控机制提供了深刻的见解。尽管已经开发了许多跨模态翻译的方法，但它们对稀缺高质量共测数据的依赖限制了其应用范围。针对这一问题，我们提出了scACT，这是一种深度生成模型，旨在从未配对的单细胞数据中提取跨模态的生物学见解。scACT解决了三大挑战：通过对抗训练对齐未配对的多模态数据，通过循环一致性训练在没有先验知识的情况下促进跨模态翻译，以及通过计算机模拟扰动实现可解释的调控互连探索。为了测试其性能，我们在多种单细胞数据集上应用了scACT，并发现它在所有三项任务中均优于现有方法。最后，我们将scACT开发为一个独立的开源软件包，以推动研究界在单细胞组学数据处理和分析方面的进步。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=scACT:+Accurate+Cross-modality+Translation+via+Cycle-consistent+Training+from+Unpaired+Single-cell+Data)|0|
|[Source Prompt: Coordinated Pre-training of Language Models on Diverse Corpora from Multiple Sources](https://doi.org/10.1145/3627673.3679835)|Yipei Xu, Dakuan Lu, Jiaqing Liang, Jin Zhao, Xintao Wang, Hengkui Wu, Ken Chen, Liujiang Liu, Yingsi Xin, Xuepeng Liu, Yanghua Xiao, Zhixu Li|Fudan University|Pre-trained language models (PLMs) have established the new paradigm in the field of NLP. For more powerful PLMs, one of the most popular and successful way is to continuously scale up sizes of the models and the pre-training corpora. These large corpora are generally obtained by converging smaller ones from multiple sources, they are thus growing increasingly diverse. However, the side-effects of these colossal converged corpora remain understudied. In this paper, we identify the disadvantage of heterogeneous corpora from multiple sources for pre-training PLMs. Towards coordinated pre-training on diverse corpora, we further propose source prompts (SP), which explicitly prompt the model of the data source at the pre-training and fine-tuning stages. Results of extensive experiments demonstrate that PLMs pre-trained with SP on diverse corpora gain significant improvement in various downstream tasks.|预训练语言模型（PLMs）已在自然语言处理（NLP）领域确立了新的范式。为了构建更强大的PLMs，最流行且成功的方法之一是不断扩大模型规模和预训练语料库。这些大型语料库通常是通过整合来自多个来源的较小语料库而获得的，因此它们变得越来越多样化。然而，这些庞大的整合语料库的副作用仍未得到充分研究。在本文中，我们指出了来自多个来源的异构语料库在预训练PLMs中的劣势。为了在多样化语料库上进行协调的预训练，我们进一步提出了源提示（Source Prompts, SP），在预训练和微调阶段明确提示模型数据来源。大量实验结果表明，使用SP在多样化语料库上预训练的PLMs在各种下游任务中获得了显著的提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Source+Prompt:+Coordinated+Pre-training+of+Language+Models+on+Diverse+Corpora+from+Multiple+Sources)|0|
|[CLR2G: Cross modal Contrastive Learning on Radiology Report Generation](https://doi.org/10.1145/3627673.3679668)|Hongchen Xue, Qingzhi Ma, Guanfeng Liu, Jianfeng Qu, Yuanjun Liu, An Liu|School of Computer Science and Technology, Soochow University, Suzhou, China; School of Computing, Macquarie University, Sydney, Australia|The automatic generation of radiological imaging reports aims to produce accurate and coherent clinical descriptions based on X-ray images. This facilitates clinicians in completing the arduous task of report writing and advances clinical automation. The primary challenge in radiological imaging report generation lies in accurately capturing and describing abnormal regions in the images under data bias conditions, resulting in the generation of lengthy texts containing image details. Existing methods mostly rely on prior knowledge such as medical knowledge graphs, corpora, and image databases to assist models in generating more precise textual descriptions. However, these methods still struggle to identify rare anomalies in the images. To address this issue, we propose a two-stage training model, named CLR2G, based on cross-modal contrastive learning. This model delegates the task of capturing anomalies, particularly those challenging for the generative model trained with cross-entropy loss under data bias conditions, to a specialized abnormality capture component. Specifically, we employ a semantic matching loss function to train additional abnormal image and text encoders through cross-modal contrastive learning, facilitating the capture of 13 common anomalies. We utilize the anomalous image features, text features and their confidence probabilities as a posteriori knowledge to help the model generate accurate image reports. Experimental results demonstrate the state-of-the-art performance of our method on two widely used public datasets, IU-Xray and MIMIC-CXR.|放射影像报告的自动生成旨在基于X光图像生成准确且连贯的临床描述。这有助于临床医生完成繁琐的报告撰写任务，并推动临床自动化的发展。放射影像报告生成的主要挑战在于在数据偏差条件下准确捕捉和描述图像中的异常区域，从而生成包含图像细节的长篇文本。现有方法大多依赖于医学知识图谱、语料库和图像数据库等先验知识，以辅助模型生成更精确的文本描述。然而，这些方法在识别图像中的罕见异常方面仍存在困难。为解决这一问题，我们提出了一种基于跨模态对比学习的两阶段训练模型，命名为CLR2G。该模型将捕捉异常的任务，特别是那些在数据偏差条件下使用交叉熵损失训练的生成模型难以处理的异常，委托给一个专门的异常捕捉组件。具体而言，我们采用语义匹配损失函数，通过跨模态对比学习训练额外的异常图像和文本编码器，以促进13种常见异常的捕捉。我们利用异常图像特征、文本特征及其置信概率作为后验知识，帮助模型生成准确的影像报告。实验结果表明，我们的方法在两个广泛使用的公共数据集IU-Xray和MIMIC-CXR上达到了最先进的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CLR2G:+Cross+modal+Contrastive+Learning+on+Radiology+Report+Generation)|0|
|[Enhancing the Completeness of Rationales for Multi-Step Question Answering](https://doi.org/10.1145/3627673.3679660)|Shangzi Xue, Zhenya Huang, Xin Lin, Jiayu Liu, Longhu Qin, Tianhuang Su, Haifeng Liu, Qi Liu|; University of Science and Technology of China, Hefei, China; Guangdong OPPO Mobile Telecommunications Corp., Ltd, Shenzhen, China|Learning to answer multi-step complex questions requires machines to perform like a human to think and reason step by step, which is one of the core abilities of a question answering system. Recent advancements have revealed that large language models exhibit remarkable reasoning capabilities by generating intermediate chain-of-thought rationales. However, the completeness of their rationales lacks assurance as they are susceptible to omitting steps and making factual errors. In this paper, drawing inspiration from human-like reasoning processes in answering multi-step questions, we explicitly plan the rationales to ensure their completeness. We propose a two-stage Decomposition-Evaluation (Dec-Eval) framework including a step decomposition stage and a rationale generation stage. Specifically, in the first stage, we decompose the complex question into simpler sub-ones and simulate a human's ability to grasp logical clues to ensure the integrity of step planning. Then, in the second stage, based on the sub-questions, we generate and evaluate rationales step by step. Both stages work together organically, improving the completeness of rationales and the accuracy of the answer. To further control the question answering process, we propose a novel knowledge injection mechanism that incorporates external knowledge to guide both stages. Extensive experiments on three challenging multi-step QA datasets demonstrate that Dec-Eval can explicitly generate more logical rationales, and significantly improve the reasoning performances of different backbone models.|学习回答多步复杂问题需要机器像人类一样逐步思考和推理，这是问答系统的核心能力之一。最近的进展表明，大型语言模型通过生成中间链式思维推理过程，展现出显著的推理能力。然而，这些推理过程的完整性缺乏保证，因为它们容易遗漏步骤并产生事实性错误。在本文中，我们从人类回答多步问题的推理过程中汲取灵感，明确提出规划推理过程以确保其完整性。我们提出了一个两阶段的分解-评估（Dec-Eval）框架，包括步骤分解阶段和推理生成阶段。具体来说，在第一阶段，我们将复杂问题分解为更简单的子问题，并模拟人类抓住逻辑线索的能力，以确保步骤规划的完整性。然后，在第二阶段，基于子问题，我们逐步生成并评估推理过程。这两个阶段有机协作，提高了推理过程的完整性和答案的准确性。为了进一步控制问答过程，我们提出了一种新颖的知识注入机制，将外部知识融入两个阶段以指导推理。在三个具有挑战性的多步问答数据集上进行的大量实验表明，Dec-Eval能够明确生成更具逻辑性的推理过程，并显著提升不同骨干模型的推理性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+the+Completeness+of+Rationales+for+Multi-Step+Question+Answering)|0|
|[Predicting Scientific Impact Through Diffusion, Conformity, and Contribution Disentanglement](https://doi.org/10.1145/3627673.3679546)|Zhikai Xue, Guoxiu He, Zhuoren Jiang, Sichen Gu, Yangyang Kang, Star Zhao, Wei Lu|; Alibaba Group; National Institute of Intelligent Evaluation and Governance Institute of Big Data (IBD); East China Normal University Faculty of Economics and Management; Zhejiang University School of Public Affairs; Wuhan University School of Information Management; East China Normal University Institute of AI for Education|The scientific impact of academic papers is influenced by intricate factors such as dynamic popularity and inherent contribution. Existing models typically rely on static graphs for citation count estimation, failing to differentiate among its sources. In contrast, we propose distinguishing effects derived from various factors and predicting citation increments as estimated potential impacts within the dynamic context. In this research, we introduce a novel model, DPPDCC, which Disentangles the Potential impacts of Papers into Diffusion, Conformity, and Contribution values. It encodes temporal and structural features within dynamic heterogeneous graphs derived from the citation networks and applies various auxiliary tasks for disentanglement. By emphasizing comparative and co-cited/citing information and aggregating snapshots evolutionarily, DPPDCC captures knowledge flow within the citation network. Afterwards, popularity is outlined by contrasting augmented graphs to extract the essence of citation diffusion and predicting citation accumulation bins for quantitative conformity modeling. Orthogonal constraints ensure distinct modeling of each perspective, preserving the contribution value. To gauge generalization across publication times and replicate the realistic dynamic context, we partition data based on specific time points and retain all samples without strict filtering. Extensive experiments on three datasets validate DPPDCC's superiority over baselines for papers published previously, freshly, and immediately, with further analyses confirming its robustness. Our codes and supplementary materials can be found at https://github.com/ECNU-Text-Computing/DPPDCC.|学术论文的科学影响力受到动态流行度和内在贡献等复杂因素的影响。现有模型通常依赖静态图进行引用计数估计，未能区分其来源。相比之下，我们提出区分来自各种因素的影响，并在动态背景下预测引用增量作为估计的潜在影响。在本研究中，我们引入了一种新颖的模型DPPDCC，该模型将论文的潜在影响分解为扩散、从众和贡献值。它编码了来自引用网络的动态异构图中的时间和结构特征，并应用各种辅助任务进行分解。通过强调比较和共被引/引用信息，并以进化方式聚合快照，DPPDCC捕捉了引用网络内的知识流动。随后，通过对比增强图来概述流行度，以提取引用扩散的本质，并预测引用累积区间以进行定量从众建模。正交约束确保每个视角的独特建模，保留贡献值。为了评估跨出版时间的泛化能力并复制现实的动态背景，我们根据特定时间点划分数据并保留所有样本，而不进行严格过滤。在三个数据集上的广泛实验验证了DPPDCC对于先前、新近和即时发表的论文相对于基线的优越性，进一步分析证实了其鲁棒性。我们的代码和补充材料可在https://github.com/ECNU-Text-Computing/DPPDCC找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Predicting+Scientific+Impact+Through+Diffusion,+Conformity,+and+Contribution+Disentanglement)|0|
|[Buffalo: Biomedical Vision-Language Understanding with Cross-Modal Prototype and Federated Foundation Model Collaboration](https://doi.org/10.1145/3627673.3679627)|Bingjie Yan, Qian Chen, Yiqiang Chen, Xinlong Jiang, Wuliang Huang, Bingyu Wang, Zhirui Wang, Chenlong Gao, Teng Zhang||Federated learning (FL) enables collaborative learning across multiple biomedical data silos with multimodal foundation models while preserving privacy. Due to the heterogeneity in data processing and collection methodologies across diverse medical institutions and the varying medical inspections patients undergo, modal heterogeneity exists in practical scenarios, where severe modal heterogeneity may even prevent model training. With privacy considerations, data transfer cannot be permitted, restricting knowledge exchange among different clients. To trickle these issues, we propose a cross-modal prototype imputation method for visual-language understanding (Buffalo) with only a slight increase in communication cost, which can improve the performance of fine-tuning general foundation models for downstream biomedical tasks. We conducted extensive experiments on medical report generation and biomedical visual question-answering tasks. The results demonstrate that Buffalo can fully utilize data from all clients to improve model generalization compared to other modal imputation methods in three modal heterogeneity scenarios, approaching or even surpassing the performance in the ideal scenario without missing modality.|联邦学习（FL）使得能够在多个生物医学数据孤岛之间利用多模态基础模型进行协作学习，同时保护隐私。由于不同医疗机构在数据处理和收集方法上的异质性，以及患者接受的各种医学检查的差异，实际场景中存在模态异质性，严重的模态异质性甚至可能阻碍模型训练。出于隐私考虑，不允许数据传输，这限制了不同客户端之间的知识交换。为了解决这些问题，我们提出了一种用于视觉-语言理解的跨模态原型填补方法（Buffalo），该方法仅略微增加通信成本，能够提高对通用基础模型进行微调以用于下游生物医学任务的性能。我们在医学报告生成和生物医学视觉问答任务上进行了广泛的实验。结果表明，在三种模态异质性场景下，与其他模态填补方法相比，Buffalo能够充分利用所有客户端的数据来提高模型泛化能力，接近甚至超越在无缺失模态的理想场景下的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Buffalo:+Biomedical+Vision-Language+Understanding+with+Cross-Modal+Prototype+and+Federated+Foundation+Model+Collaboration)|0|
|[ST-ECP: A Novel Spatial-Temporal Framework for Energy Consumption Prediction of Vehicle Trajectory](https://doi.org/10.1145/3627673.3679807)|Biao Yang, Yun Xiong, Xi Chen, Xuejing Feng, Meng Wang, Jun Ma|; Tongji University, Shanghai, China|Accurately predicting Vehicle Energy Consumption (VEC) is crucial for estimating a vehicle's total energy requirements along a predetermined trajectory. Current research mainly focuses on personalized models that enhance VEC prediction accuracy by leveraging driving behavior features extracted from historical trajectory data. However, there are still two significant limitations. First, existing algorithms predominantly model trajectories with coarse granularity, focusing solely on overall characteristics and neglecting the crucial interplay between vehicles, drivers, and the environments, which fundamentally shape trajectory dynamics. Second, current models predict driver behavior preferences solely from vehicle operational states in historical trajectories, often overlooking the influence of external environmental factors. To overcome these limitations, we introduce a Spatial-Temporal Framework for Energy Consumption Prediction of Vehicle Trajectories (ST-ECP). Specifically, we construct a heterogeneous interaction graph that captures the complex relationships between vehicles, environments, and drivers, effectively characterizing the dynamic attributes of trajectories across various conditions. Additionally, we design a personalized pattern aggregation module to extract personalized driving behavior features. Extensive experimental on real-world datasets demonstrate the effectiveness and efficiency of ST-ECP.|准确预测车辆能量消耗（Vehicle Energy Consumption, VEC）对于估算车辆在预定轨迹上的总能量需求至关重要。当前的研究主要集中在个性化模型上，这些模型通过利用从历史轨迹数据中提取的驾驶行为特征来提高VEC预测的准确性。然而，仍然存在两个显著的局限性。首先，现有算法主要以粗粒度对轨迹进行建模，仅关注整体特征，而忽略了车辆、驾驶员和环境之间至关重要的相互作用，这些相互作用从根本上塑造了轨迹的动态特性。其次，当前模型仅从历史轨迹中的车辆运行状态来预测驾驶员行为偏好，往往忽视了外部环境因素的影响。为了克服这些局限性，我们提出了一种用于车辆轨迹能量消耗预测的时空框架（Spatial-Temporal Framework for Energy Consumption Prediction of Vehicle Trajectories, ST-ECP）。具体而言，我们构建了一个异质交互图，捕捉了车辆、环境和驾驶员之间的复杂关系，有效地表征了各种条件下轨迹的动态属性。此外，我们设计了一个个性化模式聚合模块，用于提取个性化驾驶行为特征。在真实世界数据集上的大量实验证明了ST-ECP的有效性和高效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ST-ECP:+A+Novel+Spatial-Temporal+Framework+for+Energy+Consumption+Prediction+of+Vehicle+Trajectory)|0|
|[MalLight: Influence-Aware Coordinated Traffic Signal Control for Traffic Signal Malfunctions](https://doi.org/10.1145/3627673.3679605)|Qinchen Yang, Zejun Xie, Hua Wei, Desheng Zhang, Yu Yang||Urban traffic is subject to disruptions that cause extended waiting time and safety issues at signalized intersections. While numerous studies have addressed the issue of intelligent traffic systems in the context of various disturbances, traffic signal malfunction, a common real-world occurrence with significant repercussions, has received comparatively limited attention. The primary objective of this research is to mitigate the adverse effects of traffic signal malfunction, such as traffic congestion and collision, by optimizing the control of neighboring functioning signals. To achieve this goal, this paper presents a novel traffic signal control framework (MalLight), which leverages an Influence-aware State Aggregation Module (ISAM) and an Influence-aware Reward Aggregation Module (IRAM) to achieve coordinated control of surrounding traffic signals. To the best of our knowledge, this study pioneers the application of a Reinforcement Learning(RL)-based approach to address the challenges posed by traffic signal malfunction. Empirical investigations conducted on real-world datasets substantiate the superior performance of our proposed methodology over conventional and deep learning-based alternatives in the presence of signal malfunction, with reduction of throughput alleviated by as much as 48.6%.|城市交通常常受到各种干扰，导致信号灯交叉口的等待时间延长和安全问题。尽管许多研究已经在各种干扰背景下探讨了智能交通系统的问题，但交通信号灯故障这一在现实生活中常见且影响重大的现象，却相对较少受到关注。本研究的主要目标是通过优化邻近正常运行的信号灯控制，来减轻交通信号灯故障带来的不利影响，如交通拥堵和碰撞。为实现这一目标，本文提出了一种新颖的交通信号控制框架（MalLight），该框架利用影响感知状态聚合模块（ISAM）和影响感知奖励聚合模块（IRAM）来实现对周边交通信号的协调控制。据我们所知，本研究首次应用基于强化学习（RL）的方法来解决交通信号灯故障带来的挑战。在真实世界数据集上进行的实证研究证实，在信号灯故障的情况下，我们提出的方法相较于传统方法和基于深度学习的替代方案表现出更优越的性能，吞吐量减少的缓解程度高达48.6%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MalLight:+Influence-Aware+Coordinated+Traffic+Signal+Control+for+Traffic+Signal+Malfunctions)|0|
|[Leveraging Local Structure for Improving Model Explanations: An Information Propagation Approach](https://doi.org/10.1145/3627673.3679575)|Ruo Yang, Binghui Wang, Mustafa Bilgic||Numerous explanation methods have been recently developed to interpret the decisions made by deep neural network (DNN) models. For image classifiers, these methods typically provide an attribution score to each pixel in the image to quantify its contribution to the prediction. However, most of these explanation methods appropriate attribution scores to pixels independently, even though both humans and DNNs make decisions by analyzing a set of closely related pixels simultaneously. Hence, the attribution score of a pixel should be evaluated jointly by considering itself and its structurally-similar pixels. We propose a method called IProp, which models each pixel's individual attribution score as a source of explanatory information and explains the image prediction through the dynamic propagation of information across all pixels. To formulate the information propagation, IProp adopts the Markov Reward Process, which guarantees convergence, and the final status indicates the desired pixels' attribution scores. Furthermore, IProp is compatible with any existing attribution-based explanation method. Extensive experiments on various explanation methods and DNN models verify that IProp significantly improves them on a variety of interpretability metrics.|近年来，已经开发了许多解释方法来解读深度神经网络（DNN）模型的决策过程。对于图像分类器，这些方法通常为图像中的每个像素分配一个归因分数，以量化其对预测的贡献。然而，尽管人类和DNN都是通过同时分析一组紧密相关的像素来做出决策，但大多数解释方法却独立地为像素分配归因分数。因此，像素的归因分数应通过考虑其自身及其结构相似像素来共同评估。我们提出了一种名为IProp的方法，该方法将每个像素的个体归因分数建模为解释信息的来源，并通过信息在所有像素间的动态传播来解释图像预测。为了构建信息传播模型，IProp采用了马尔可夫奖励过程，该过程保证了收敛性，并且最终状态表示了所需像素的归因分数。此外，IProp与任何现有的基于归因的解释方法兼容。通过对各种解释方法和DNN模型的大量实验验证，IProp在多种可解释性指标上显著提升了这些方法的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Local+Structure+for+Improving+Model+Explanations:+An+Information+Propagation+Approach)|0|
|[TrafCL: Robust Encrypted Malicious Traffic Detection via Contrastive Learning](https://doi.org/10.1145/3627673.3679839)|Xiaodu Yang, Sijie Ruan, Jinyu Li, Yinliang Yue, Bo Sun|; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; National Computer Network Emergency Response Technical Team, Beijing, China; Zhongguancun Laboratory, Beijing, China|Remote control malwares enable cyber attackers to achieve command and control over victim hosts, which are widely employed in ransomware attacks and espionage operations, jeopardizing personal privacy and state security. To effectively detect such malicious traffics holds high practical value. However, prior works have not adequately addressed the task due to challenges of encrypted traffics with misleading contents, incomplete sessions, and limited labels. To overcome these limitations, in this paper, we propose TrafCL, a contrastive learning framework for robust encrypted malicious traffic detection. In TrafCL, we first generate incomplete variants for the input session by Session Augmentation, then extract explicit session features with excluding misleading traffic contents by Triple-aspect Session Feature Extraction, and obtain session representations by Co-attention Session Encoder which fuses triple-aspect session features with capturing their interdependence. After that, we use a projection head to obtain final representations. TrafCL is pre-trained using unlabeled data to learn close representations for complete sessions and their incomplete variants, then fine-tuned on labeled data to detect encrypted malicious traffics. Experiment results show that TrafCL outperforms the best baseline by 11.35% and 6.71% in F1-scores on two datasets respectively.|远程控制恶意软件使网络攻击者能够实现对受害主机的命令和控制，这些软件被广泛应用于勒索软件攻击和间谍活动中，严重威胁个人隐私和国家安全。有效检测此类恶意流量具有很高的实用价值。然而，由于加密流量内容具有误导性、会话不完整以及标签有限等挑战，先前的研究未能充分解决这一任务。为了克服这些限制，本文提出了一种用于鲁棒加密恶意流量检测的对比学习框架——TrafCL。在TrafCL中，我们首先通过会话增强为输入会话生成不完整变体，然后通过三方面会话特征提取排除误导性流量内容，提取显式会话特征，并通过融合三方面会话特征并捕捉其相互依赖性的共注意力会话编码器获得会话表示。之后，我们使用投影头获得最终表示。TrafCL使用未标记数据进行预训练，以学习完整会话及其不完整变体的紧密表示，然后在标记数据上进行微调以检测加密恶意流量。实验结果表明，TrafCL在两个数据集上的F1分数分别比最佳基线高出11.35%和6.71%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TrafCL:+Robust+Encrypted+Malicious+Traffic+Detection+via+Contrastive+Learning)|0|
|[Breaking State-of-the-Art Poisoning Defenses to Federated Learning: An Optimization-Based Attack Framework](https://doi.org/10.1145/3627673.3679566)|Yuxin Yang, Qiang Li, Chenfei Nie, Yuan Hong, Binghui Wang|; School of Computing, University of Connecticut, Storrs, Connecticut, USA; Department of Computer Science, Illinois Institute of Technology, Chicago, Illinois, USA; College of Computer Science and Technology, Jilin University, Changchun, Jilin, China|Federated Learning (FL) is a novel client-server distributed learning framework that can protect data privacy. However, recent works show that FL is vulnerable to poisoning attacks. Many defenses with robust aggregators (AGRs) are proposed to mitigate the issue, but they are all broken by advanced attacks. Very recently, some renewed robust AGRs are designed, typically with novel clipping or/and filtering strategies, and they show promising defense performance against the advanced poisoning attacks. In this paper, we show that these novel robust AGRs are also vulnerable to carefully designed poisoning attacks. Specifically, we observe that breaking these robust AGRs reduces to bypassing the clipping or/and filtering of malicious clients, and propose an optimization-based attack framework to leverage this observation. Under the framework, we then design the customized attack against each robust AGR. Extensive experiments on multiple datasets and threat models verify our proposed optimizationbased attack can break the SOTA AGRs. We hence call for novel defenses against poisoning attacks to FL. Code is available at: https: //github.com/Yuxin104/BreakSTOAPoisoningDefenses.|联邦学习（Federated Learning, FL）是一种新颖的客户端-服务器分布式学习框架，能够保护数据隐私。然而，近期研究表明，联邦学习容易受到投毒攻击的影响。为了缓解这一问题，许多具有鲁棒聚合器（Aggregators, AGRs）的防御机制被提出，但这些防御机制均被高级攻击所攻破。最近，一些重新设计的鲁棒聚合器被提出，通常采用新颖的剪裁和/或过滤策略，并在对抗高级投毒攻击中表现出良好的防御效果。本文表明，这些新颖的鲁棒聚合器在面对精心设计的投毒攻击时仍然脆弱。具体而言，我们观察到，攻破这些鲁棒聚合器可以归结为绕过对恶意客户端的剪裁和/或过滤，并提出了一个基于优化的攻击框架来利用这一发现。在该框架下，我们针对每个鲁棒聚合器设计了定制化的攻击。通过在多个数据集和威胁模型上的广泛实验，验证了我们提出的基于优化的攻击能够攻破当前最先进的聚合器。因此，我们呼吁针对联邦学习的投毒攻击提出新的防御机制。代码可在以下网址获取：https://github.com/Yuxin104/BreakSTOAPoisoningDefenses。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Breaking+State-of-the-Art+Poisoning+Defenses+to+Federated+Learning:+An+Optimization-Based+Attack+Framework)|0|
|[What a Surprise! Computing Rewritten Modules Can Be as Efficient as Computing Subset Modules](https://doi.org/10.1145/3627673.3679528)|Zhihao Yang, Yizheng Zhao|National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China|Uniform Interpolation (UI) is an advanced non-standard reasoning service that seeks to refine ontologies by creating rewritten modules. These modules, known as uniform interpolants, retain only "relevant names" while preserving their meanings in the absence of other names. UI holds significant potential across various domains where tailored ontology modules are required. However, realizing its full potential demands highly optimized techniques for generating such modules. Previous studies have identified notable challenges in generating uniform interpolants for EL-ontologies, where their computation is substantially more complex and computationally demanding than standard subset modules. Despite these obstacles, this paper introduces an advanced "forgetting" method tailored for computing uniform interpolants of ELIO-ontologies with ABoxes. We show that with effective normalization and inference strategies, these uniform interpolants can be computed efficiently, matching the speed of standard module computation. A comprehensive evaluation using a prototype implementation of this method achieved a 100% success rate on two major benchmark datasets, Oxford-ISG and BioPortal, with results delivered within seconds. The efficiency of our approach is attributed to our novel linear strategy for introducing definers, in sharp contrast to existing strategies that lead to an exponential increase in definers and computational inefficiency. Our method is unique in its ability to create signature-restricted modules for large-scale ontologies, making it a vital addition to the community's toolkit.|统一插值（Uniform Interpolation，UI）是一种高级的非标准推理服务，旨在通过创建重写模块来精炼本体。这些模块，称为统一插值体，仅保留“相关名称”，同时在没有其他名称的情况下保持其含义。UI 在需要定制本体模块的各个领域中具有显著潜力。然而，充分发挥其潜力需要高度优化的技术来生成此类模块。先前的研究已经指出，在为 EL 本体生成统一插值体时存在显著挑战，其计算比标准子集模块复杂得多且计算需求更高。尽管存在这些障碍，本文提出了一种专为计算带有 ABox 的 ELIO 本体的统一插值体而设计的高级“遗忘”方法。我们证明，通过有效的归一化和推理策略，这些统一插值体可以高效计算，其速度与标准模块计算相当。使用该方法的原型实现进行的全面评估在两大基准数据集 Oxford-ISG 和 BioPortal 上取得了 100% 的成功率，结果在几秒钟内即可交付。我们方法的效率归功于引入定义器的新颖线性策略，这与现有策略形成鲜明对比，后者导致定义器数量呈指数增长且计算效率低下。我们的方法独特之处在于能够为大规模本体创建签名受限的模块，使其成为社区工具包中的重要补充。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=What+a+Surprise!+Computing+Rewritten+Modules+Can+Be+as+Efficient+as+Computing+Subset+Modules)|0|
|[Adaptive Differentially Private Structural Entropy Minimization for Unsupervised Social Event Detection](https://doi.org/10.1145/3627673.3679537)|Zhiwei Yang, Yuecen Wei, Haoran Li, Qian Li, Lei Jiang, Li Sun, Xiaoyan Yu, Chunming Hu, Hao Peng||Social event detection refers to extracting relevant message clusters from social media data streams to represent specific events in the real world. Social event detection is important in numerous areas, such as opinion analysis, social safety, and decision-making. Most current methods are supervised and require access to large amounts of data. These methods need prior knowledge of the events and carry a high risk of leaking sensitive information in the messages, making them less applicable in open-world settings. Therefore, conducting unsupervised detection while fully utilizing the rich information in the messages and protecting data privacy remains a significant challenge. To this end, we propose a novel social event detection framework, ADP-SEMEvent, an unsupervised social event detection method that prioritizes privacy. Specifically, ADP-SEMEvent is divided into two stages, i.e., the construction stage of the private message graph and the clustering stage of the private message graph. In the first stage, an adaptive differential privacy approach is used to construct a private message graph. In this process, our method can adaptively apply differential privacy based on the events occurring each day in an open environment to maximize the use of the privacy budget. In the second stage, to address the reduction in data utility caused by noise, a novel 2-dimensional structural entropy minimization algorithm based on optimal subgraphs is used to detect events in the message graph. The highlight of this process is unsupervised and does not compromise differential privacy. Extensive experiments on two public datasets demonstrate that ADP-SEMEvent can achieve detection performance comparable to state-of-the-art methods while maintaining reasonable privacy budget parameters.|社交事件检测是指从社交媒体数据流中提取相关的消息簇，以代表现实世界中的特定事件。社交事件检测在众多领域中具有重要意义，例如意见分析、社会安全和决策制定。目前大多数方法都是有监督的，并且需要访问大量数据。这些方法需要事先了解事件的知识，并且存在泄露消息中敏感信息的高风险，使得它们在开放世界环境中的适用性较低。因此，在充分利用消息中的丰富信息并保护数据隐私的同时，进行无监督检测仍然是一个重大挑战。为此，我们提出了一种新颖的社交事件检测框架，ADP-SEMEvent，这是一种优先考虑隐私的无监督社交事件检测方法。具体而言，ADP-SEMEvent分为两个阶段，即私有消息图的构建阶段和私有消息图的聚类阶段。在第一阶段，使用自适应差分隐私方法来构建私有消息图。在此过程中，我们的方法可以根据开放环境中每天发生的事件自适应地应用差分隐私，以最大化隐私预算的利用。在第二阶段，为了解决由噪声引起的数据效用下降问题，使用了一种基于最优子图的二维结构熵最小化算法来检测消息图中的事件。此过程的亮点是无监督的，并且不会损害差分隐私。在两个公共数据集上的广泛实验表明，ADP-SEMEvent在保持合理隐私预算参数的同时，可以实现与最先进方法相当的检测性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adaptive+Differentially+Private+Structural+Entropy+Minimization+for+Unsupervised+Social+Event+Detection)|0|
|[Combining Incomplete Observational and Randomized Data for Heterogeneous Treatment Effects](https://doi.org/10.1145/3627673.3679593)|Dong Yao, Caizhi Tang, Qing Cui, Longfei Li|Ant Group, Hangzhou, China|Data from observational studies (OSs) is widely available and readily obtainable yet frequently contains confounding biases. On the other hand, data derived from randomized controlled trials (RCTs) helps to reduce these biases; however, it is expensive to gather, resulting in a tiny size of randomized data. For this reason, effectively fusing observational data and randomized data to better estimate heterogeneous treatment effects (HTEs) has gained increasing attention. However, existing methods for integrating observational data with randomized data must require complete observational data, meaning that both treated subjects and untreated subjects must be included in OSs. This prerequisite confines the applicability of such methods to very specific situations, given that including all subjects, whether treated or untreated, in observational studies is not consistently achievable. In our paper, we propose a resilient approach to Combine Incomplete Observational data and randomized data for HTE estimation, which we abbreviate as CIO. The CIO is capable of estimating HTEs efficiently regardless of the completeness of the observational data, be it full or partial. Concretely, a confounding bias function is first derived using the pseudo-experimental group from OSs, in conjunction with the pseudo-control group from RCTs, via an effect estimation procedure. This function is subsequently utilized as a corrective residual to rectify the observed outcomes of observational data during the HTE estimation by combining the available observational data and the all randomized data. To validate our approach, we have conducted experiments on a synthetic dataset and two semi-synthetic datasets.|观察性研究（OSs）的数据广泛可用且易于获取，但常常包含混杂偏差。另一方面，随机对照试验（RCTs）的数据有助于减少这些偏差；然而，收集这些数据的成本高昂，导致随机数据的规模较小。因此，有效融合观察性数据和随机数据以更好地估计异质处理效应（HTEs）已引起越来越多的关注。然而，现有的将观察性数据与随机数据整合的方法必须要求完整的观察性数据，这意味着观察性研究中必须包括接受处理和未接受处理的受试者。这一前提条件限制了这些方法在非常特定情况下的适用性，因为在观察性研究中包含所有受试者（无论是否接受处理）并不总是可行的。在我们的论文中，我们提出了一种将不完整的观察性数据与随机数据结合以估计HTEs的弹性方法，我们将其缩写为CIO。CIO能够有效估计HTEs，无论观察性数据是否完整。具体而言，首先通过效应估计过程，利用OSs中的伪实验组和RCTs中的伪对照组推导出混杂偏差函数。然后，在HTE估计过程中，通过结合可用的观察性数据和所有随机数据，将该函数用作校正残差来修正观察性数据的观察结果。为了验证我们的方法，我们在一个合成数据集和两个半合成数据集上进行了实验。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Combining+Incomplete+Observational+and+Randomized+Data+for+Heterogeneous+Treatment+Effects)|0|
|[CKNN: Cleansed k-Nearest Neighbor for Unsupervised Video Anomaly Detection](https://doi.org/10.1145/3627673.3679526)|Jihun Yi, Sungroh Yoon||In this paper, we address the problem of unsupervised video anomaly detection (UVAD). The task aims to detect abnormal events in test video using unlabeled videos as training data. The presence of anomalies in the training data poses a significant challenge in this task, particularly because they form clusters in the feature space. We refer to this property as the "Anomaly Cluster" issue. The condensed nature of these anomalies makes it difficult to distinguish between normal and abnormal data in the training set. Consequently, training conventional anomaly detection techniques using an unlabeled dataset often leads to sub-optimal results. To tackle this difficulty, we propose a new method called Cleansed k-Nearest Neighbor (CKNN), which explicitly filters out the Anomaly Clusters by cleansing the training dataset. Following the k-nearest neighbor algorithm in the feature space provides powerful anomaly detection capability. Although the identified Anomaly Cluster issue presents a significant challenge to applying k-nearest neighbor in UVAD, our proposed cleansing scheme effectively addresses this problem. We evaluate the proposed method on various benchmark datasets and demonstrate that CKNN outperforms the previous state-of-the-art UVAD method by up to 8.5% (from 82.0 to 89.0) in terms of AUROC. Moreover, we emphasize that the performance of the proposed method is comparable to that of the state-of-the-art method trained using anomaly-free data.|本文针对无监督视频异常检测（Unsupervised Video Anomaly Detection, UVAD）问题展开研究。该任务旨在利用未标注的视频作为训练数据，检测测试视频中的异常事件。训练数据中存在的异常事件对此任务构成了重大挑战，尤其是这些异常事件在特征空间中形成了聚类。我们将这一特性称为“异常聚类”问题。由于这些异常的密集性，导致在训练集中难以区分正常数据和异常数据。因此，使用未标注数据集训练传统的异常检测技术往往会导致次优结果。为了解决这一难题，我们提出了一种名为“净化k近邻”（Cleansed k-Nearest Neighbor, CKNN）的新方法，该方法通过对训练数据集进行净化，显式地过滤掉异常聚类。在特征空间中应用k近邻算法提供了强大的异常检测能力。尽管所识别的异常聚类问题对在UVAD中应用k近邻算法提出了重大挑战，但我们提出的净化方案有效地解决了这一问题。我们在多个基准数据集上评估了所提出的方法，并证明CKNN在AUROC指标上比之前的最先进UVAD方法提高了最多8.5%（从82.0提高到89.0）。此外，我们强调，所提出方法的性能与使用无异常数据训练的最先进方法相当。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CKNN:+Cleansed+k-Nearest+Neighbor+for+Unsupervised+Video+Anomaly+Detection)|0|
|[GraphCBAL: Class-Balanced Active Learning for Graph Neural Networks via Reinforcement Learning](https://doi.org/10.1145/3627673.3679624)|Chengcheng Yu, Jiapeng Zhu, Xiang Li|East China Normal University, Shanghai, China; Shanghai Polytechnic University, Shanghai, China|Graph neural networks (GNNs) have recently demonstrated significant success. Active learning for GNNs aims to query the valuable samples from the unlabeled data for annotation to maximize the GNNs' performance at a low cost. However, most existing methods for reinforced active learning in GNNs may lead to a highly imbalanced class distribution, especially in highly skewed class scenarios. This further adversely affects the classification performance. To tackle this issue, in this paper, we propose a novel reinforced class-balanced active learning framework for GNNs, namely, GraphCBAL. It learns an optimal policy to acquire class-balanced and informative nodes for annotation, maximizing the performance of GNNs trained with selected labeled nodes. GraphCBAL designs class-balance-aware states, as well as a reward function that achieves trade-off between model performance and class balance. We further upgrade GraphCBAL to GraphCBAL++ by introducing a punishment mechanism to obtain a more class-balanced labeled set. Extensive experiments on multiple datasets demonstrate the effectiveness of the proposed approaches, achieving superior performance over state-of-the-art baselines. In particular, our methods can strike the balance between classification results and class balance. We provide our code and data at https://github.com/cici-chengcheng/GraphCBAL.|图神经网络（GNNs）近年来取得了显著的成功。针对GNNs的主动学习旨在从未标注数据中查询有价值的样本进行标注，以低成本最大化GNNs的性能。然而，现有的GNNs强化主动学习方法大多可能导致高度不平衡的类别分布，尤其是在类别分布高度倾斜的场景中。这进一步对分类性能产生了不利影响。为了解决这一问题，本文提出了一种新颖的GNNs强化类别平衡主动学习框架，即GraphCBAL。该框架通过学习一个最优策略，获取类别平衡且信息丰富的节点进行标注，从而最大化使用所选标注节点训练的GNNs的性能。GraphCBAL设计了类别平衡感知的状态，以及一个在模型性能和类别平衡之间实现权衡的奖励函数。我们进一步通过引入惩罚机制，将GraphCBAL升级为GraphCBAL++，以获得更加类别平衡的标注集。在多个数据集上的大量实验证明了所提出方法的有效性，其性能优于现有的先进基线方法。特别是，我们的方法能够在分类结果和类别平衡之间取得良好的平衡。我们提供了代码和数据，详见https://github.com/cici-chengcheng/GraphCBAL。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphCBAL:+Class-Balanced+Active+Learning+for+Graph+Neural+Networks+via+Reinforcement+Learning)|0|
|[Rethinking Attention Mechanism for Spatio-Temporal Modeling: A Decoupling Perspective in Traffic Flow Prediction](https://doi.org/10.1145/3627673.3679571)|Qi Yu, Weilong Ding, Hao Zhang, Yang Yang, Tianpu Zhang|SINOPEC Beijing Research Institute of Chemical Industry, Beijing, China; North China University of Technology, Beijing, China|The attention mechanism has the advantage of handling long-term correlations, and has been widely adopted in multivariate time series (MTS) prediction. As an important application of MTS, traffic flow prediction has the most popular solution using transformer-based prediction models nowadays. Just with attention mechanism, those models can learn the spatio-temporal correlations from traffic data. However, the up-to-date linear prediction models have questioned the effectiveness of current transformer-based models in certain conditions, which provides new possibilities for more efficient work. We rethink the role of the attention mechanism during spatio-temporal modeling from a decoupling perspective, and propose DEC-Former for traffic flow prediction. Specifically, the trend and seasonal parts of the time series data, the geographical adjacency of the nodes in the road network, and the traditional encoder-decoder architecture, are respectively decoupled. Such decoupling leverages the attention mechanism's advantage to capture long-term and long-range correlations.From extensive experiments on four real-world datasets, our work proves better predictive performance and efficiency than state-of-the-art attention-based models. Two case studies further show the distinct real effects.|注意力机制具有处理长期相关性的优势，已广泛应用于多元时间序列（MTS）预测中。作为MTS的重要应用，交通流量预测目前最流行的解决方案是使用基于Transformer的预测模型。这些模型仅通过注意力机制即可从交通数据中学习时空相关性。然而，最新的线性预测模型对当前基于Transformer的模型在某些条件下的有效性提出了质疑，这为更高效的工作提供了新的可能性。我们从解耦的角度重新思考了注意力机制在时空建模中的作用，并提出了用于交通流量预测的DEC-Former模型。具体而言，时间序列数据的趋势和季节性部分、道路网络中节点的地理邻近性以及传统的编码器-解码器架构分别被解耦。这种解耦利用了注意力机制的优势，以捕捉长期和远距离的相关性。通过在四个真实数据集上的广泛实验，我们的工作证明了比现有基于注意力机制的模型更好的预测性能和效率。两个案例研究进一步展示了其显著的实际效果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rethinking+Attention+Mechanism+for+Spatio-Temporal+Modeling:+A+Decoupling+Perspective+in+Traffic+Flow+Prediction)|0|
|[Time-Series Representation Learning via Dual Reference Contrasting](https://doi.org/10.1145/3627673.3679699)|Rui Yu, Yongshun Gong, Shoujin Wang, Jiasheng Si, Xueping Peng, Bing Xu, Wenpeng Lu|; Qilu University of Technology (Shandong Academy of Sciences), Jinan, Shandong, China; School of Software, Shandong University, Jinan, Shandong, China; Australian Artificial Intelligence Institute, University of Technology Sydney, Sydney, Australia; Data Science Institute, University of Technology Sydney, Sydney, Australia; Faculty of Computing, Harbin Institute of Technology, Harbin, Heilongjiang, China|The inherent complexity of real-world time series data, combined with the cost and infeasibility of manual labeling, presents considerable challenges to time series representation learning. Most existing studies tend to utilize data augmentation techniques to construct positive and negative samples and leverage a comparative learning framework to generate time series representations. However, they typically employ simple data augmentation techniques, such as jitter and cropping, to construct positive samples while randomly selecting irrelevant samples as negative ones, which are easily distinguished and unable to guide comparative learning to capture subtle discriminative features. Furthermore, they usually employ only a single positive sample for comparative learning, which is insufficient to model the diversity and hurts the robustness. To address these issues, this paper proposes a Time Series representation learning framework via Dual Reference Contrasting (TS-DRC). Specifically, we first utilize Markov transition field or Gramian angular field to transform the anchor sample of time series into image representations, which are adopted as positive samples. Then, we incorporate two positive samples (dual references) and one negative sample into the comparative learning framework, and devise a novel optimization objective to guide the model to capture more discriminate features, mitigate overfitting, and enhance the robustness. Extensive experiments conducted on four public real-world datasets demonstrate that our TS-DRC outperforms other state-of-the-art baselines.Our code is available at: https://github.com/yurui12138/TS-DRC.|现实世界时间序列数据固有的复杂性，加上手动标注的成本高昂和不可行性，给时间序列表示学习带来了巨大的挑战。现有的大多数研究倾向于利用数据增强技术来构建正负样本，并借助对比学习框架生成时间序列表示。然而，这些研究通常采用简单的数据增强技术（如抖动和裁剪）来构建正样本，同时随机选择不相关的样本作为负样本，这些负样本容易区分，无法指导对比学习捕捉细微的判别特征。此外，它们通常仅使用单个正样本进行对比学习，这不足以建模多样性并损害了鲁棒性。为了解决这些问题，本文提出了一种基于双参考对比（TS-DRC）的时间序列表示学习框架。具体而言，我们首先利用马尔可夫转移场或格拉米安角场将时间序列的锚样本转换为图像表示，并将其作为正样本。接着，我们在对比学习框架中引入两个正样本（双参考）和一个负样本，并设计了一种新的优化目标，以指导模型捕捉更具判别性的特征，减轻过拟合并增强鲁棒性。在四个公开的真实世界数据集上进行的广泛实验表明，我们的TS-DRC优于其他最先进的基线方法。我们的代码可在以下网址获取：https://github.com/yurui12138/TS-DRC。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Time-Series+Representation+Learning+via+Dual+Reference+Contrasting)|0|
|[Using Distributed Ledgers To Build Knowledge Graphs For Decentralized Computing Ecosystems](https://doi.org/10.1145/3627673.3679644)|Tarek Zaarour, Ahmed Khalid, Preeja Pradeep, Ahmed H. Zahran|Dell Research, Dell Technologies, Cork, Ireland; School of CSIT, University College Cork, Cork, Ireland|Knowledge graphs have proven vital for efficient data management, enhanced search capabilities, and improved decision-making in various information technology domains. However, constructing reliable knowledge graphs in decentralized ecosystems, with distributed autonomous actors, poses significant challenges related to asynchronous transmission, out-of-order knowledge-sharing, device heterogeneity, and trust issues. These challenges are also present in resource orchestration within multi-cloud edge ecosystems where multiple stakeholders must collaborate and share information to enable next-gen smart applications. In this paper, we propose a novel system design that utilizes Distributed Ledger Technology to build knowledge graphs. This approach ensures consistent and trustworthy knowledge sharing among orchestrators in a cloud-edge continuum. Our solution accommodates diverse requirements of both cloud and edge servers, allowing clients to construct complete historic graphs or build filtered sub-graphs. We deploy our solution in a multi-cloud edge environment and construct knowledge graphs representing the system state, including clusters, servers, microservices, and various resources. We validate the feasibility and performance of our solution through a real-world deployment and experiments in a smart shopping use case. Results demonstrate that the proposed solution achieves the claimed benefits with minimal or acceptable delays in comparison to traditional event streaming services.|知识图谱已被证明在各种信息技术领域中对于高效数据管理、增强搜索能力和改进决策至关重要。然而，在去中心化生态系统中，由于存在分布式自主参与者，构建可靠的知识图谱面临着异步传输、知识共享顺序错乱、设备异构性和信任问题等重大挑战。这些挑战在多云边缘生态系统的资源编排中同样存在，其中多个利益相关者必须协作并共享信息，以支持下一代智能应用。在本文中，我们提出了一种新颖的系统设计，利用分布式账本技术构建知识图谱。该方法确保了云边缘连续体中编排者之间一致且可信的知识共享。我们的解决方案适应了云服务器和边缘服务器的多样化需求，允许客户端构建完整的历史图谱或过滤后的子图谱。我们在多云边缘环境中部署了我们的解决方案，并构建了表示系统状态的知识图谱，包括集群、服务器、微服务和各种资源。我们通过在实际智能购物用例中的部署和实验验证了解决方案的可行性和性能。结果表明，与传统的事件流服务相比，所提出的解决方案以最小或可接受的延迟实现了所声称的优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Using+Distributed+Ledgers+To+Build+Knowledge+Graphs+For+Decentralized+Computing+Ecosystems)|0|
|[Chain-of-Layer: Iteratively Prompting Large Language Models for Taxonomy Induction from Limited Examples](https://doi.org/10.1145/3627673.3679608)|Qingkai Zeng, Yuyang Bai, Zhaoxuan Tan, Shangbin Feng, Zhenwen Liang, Zhihan Zhang, Meng Jiang||Automatic taxonomy induction is crucial for web search, recommendationsystems, and question answering. Manual curation of taxonomies is expensive interms of human effort, making automatic taxonomy construction highly desirable.In this work, we introduce Chain-of-Layer which is an in-context learningframework designed to induct taxonomies from a given set of entities.Chain-of-Layer breaks down the task into selecting relevant candidate entitiesin each layer and gradually building the taxonomy from top to bottom. Tominimize errors, we introduce the Ensemble-based Ranking Filter to reduce thehallucinated content generated at each iteration. Through extensiveexperiments, we demonstrate that Chain-of-Layer achieves state-of-the-artperformance on four real-world benchmarks.|自动分类体系构建对于网络搜索、推荐系统和问答系统至关重要。手动构建分类体系需要耗费大量的人力成本，因此自动构建分类体系具有很高的需求。在本研究中，我们提出了**Chain-of-Layer**，这是一种基于上下文学习的框架，旨在从给定的一组实体中自动推导出分类体系。Chain-of-Layer 将任务分解为在每一层中选择相关的候选实体，并逐步从顶层到底层构建分类体系。为了减少错误，我们引入了**基于集成的排序过滤器**，以降低每次迭代中生成的虚假内容。通过大量实验，我们证明了 Chain-of-Layer 在四个真实世界基准数据集上达到了最先进的性能水平。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Chain-of-Layer:+Iteratively+Prompting+Large+Language+Models+for+Taxonomy+Induction+from+Limited+Examples)|0|
|[Benchmarking Challenges for Temporal Knowledge Graph Alignment](https://doi.org/10.1145/3627673.3679784)|Weixin Zeng, Jie Zhou, Xiang Zhao||Temporal knowledge graph alignment (TKGA) discovers the equivalent elements among heterogeneous temporal knowledge graphs (TKGs), and thus can increase the coverage of a given TKG. However, existing TKGA datasets fail to mirror the real-life challenges, and the oversimplified scenarios may even impede the fair comparison and development of the alignment solutions. To address the aforementioned issues, in this work, we propose to benchmark challenges for temporal knowledge graph alignment by establishing a new dataset, i.e., BETA, which features multi-granular temporal information, more realistic quadruple distribution, and new challenging alignment scenarios. Furthermore, we also offer a simple yet effective solution, MGTEA, to address the aforementioned challenges, which effectively models the complex structural and multi-granular temporal features to facilitate the alignment. Extensive experiments reveal that BETA indeed better mirrors the real-life challenges, and there is still room for developing more advanced solutions to address these difficulties, despite of the superior performance achieved by MGTEA.|时间知识图谱对齐（Temporal Knowledge Graph Alignment, TKGA）旨在发现异构时间知识图谱（Temporal Knowledge Graphs, TKGs）中的等价元素，从而提升给定时间知识图谱的覆盖范围。然而，现有的TKGA数据集未能充分反映现实中的挑战，且过于简化的场景可能会阻碍对齐解决方案的公平比较和发展。为了解决上述问题，在本工作中，我们提出了通过建立一个新数据集（即BETA）来对时间知识图谱对齐进行基准测试，该数据集具有多粒度时间信息、更真实的四元组分布以及新的具有挑战性的对齐场景。此外，我们还提供了一种简单但有效的解决方案MGTEA，以应对上述挑战，该方案有效地建模了复杂的结构和多粒度时间特征，从而促进对齐。大量实验表明，BETA确实更好地反映了现实中的挑战，尽管MGTEA取得了优异的性能，但在开发更先进的解决方案以应对这些困难方面仍有改进空间。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Benchmarking+Challenges+for+Temporal+Knowledge+Graph+Alignment)|0|
|[M2ConceptBase: A Fine-Grained Aligned Concept-Centric Multimodal Knowledge Base](https://doi.org/10.1145/3627673.3679852)|Zhiwei Zha, Jiaan Wang, Zhixu Li, Xiangru Zhu, Wei Song, Yanghua Xiao|; Soochow University School of Computer Science and Technology; Fudan University School of Computer Science|Multimodal knowledge bases (MMKBs) provide cross-modal aligned knowledge crucial for multimodal tasks. However, the images in existing MMKBs are generally collected for entities in encyclopedia knowledge graphs. Therefore, detailed groundings of visual semantics with linguistic concepts are lacking, which are essential for the visual concept cognition ability of multimodal models. Addressing this gap, we introduce M^2ConceptBase, the first concept-centric MMKB. M^2ConceptBase models concepts as nodes with associated images and detailed textual descriptions. We propose a context-aware multimodal symbol grounding approach to align concept-image and concept-description pairs using context information from image-text datasets. Comprising 951K images and 152K concepts, M^2ConceptBase links each concept to an average of 6.27 images and a single description, ensuring comprehensive visual and textual semantics. Human studies confirm more than 95 quality. Additionally, our experiments demonstrate that M^2ConceptBase significantly enhances VQA model performance on the OK-VQA task. M^2ConceptBase also substantially improves the fine-grained concept understanding capabilities of multimodal large language models through retrieval augmentation in two concept-related tasks, highlighting its value.|多模态知识库（MMKBs）提供了对多模态任务至关重要的跨模态对齐知识。然而，现有MMKBs中的图像通常是为百科全书知识图谱中的实体收集的。因此，缺乏视觉语义与语言概念的详细关联，而这些关联对于多模态模型的视觉概念认知能力至关重要。为了解决这一不足，我们引入了M^2ConceptBase，这是第一个以概念为中心的多模态知识库。M^2ConceptBase将概念建模为节点，并关联图像和详细的文本描述。我们提出了一种上下文感知的多模态符号对齐方法，利用图像-文本数据集中的上下文信息对齐概念-图像和概念-描述对。M^2ConceptBase包含951K张图像和152K个概念，每个概念平均关联6.27张图像和一个描述，确保了全面的视觉和文本语义。人类研究证实其质量超过95%。此外，我们的实验表明，M^2ConceptBase显著提升了VQA模型在OK-VQA任务上的性能。M^2ConceptBase还通过检索增强在两个与概念相关的任务中显著提高了多模态大语言模型的细粒度概念理解能力，突显了其价值。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=M2ConceptBase:+A+Fine-Grained+Aligned+Concept-Centric+Multimodal+Knowledge+Base)|0|
|[Cost-Effective Framework with Optimized Task Decomposition and Batch Prompting for Medical Dialogue Summary](https://doi.org/10.1145/3627673.3679671)|Chi Zhang, Tao Chen, Jiehao Chen, Hao Wang, Jiyun Shi, Zhaojing Luo, Meihui Zhang|China Academy of Industrial Internet, Beijing, China; Beijing Institute of Technology, Beijing, China|The generation of medical dialogue notes is essential in healthcare, providing a structured recapitalization of patient-provider interactions. Medical notes are rigorously organized into various sections, including Chief Complaint, History of Present Illness and more. Each section serves a specific purpose to record detailed medical content. Traditionally, this task is labor-intensive, requiring physicians to manually create notes, a process prone to errors. With advancements in AI, it is now feasible to automate the generation of medical notes. There are mainly two categories of methods for automatic medical note generation. Pre-trained language models (PLMs) struggle with unstructured outputs, limited datasets, and inadequate medical terminology. In-context learning (ICL) methods improve accuracy and reduce data requirements but still produce unstructured notes and require high time and cost. To tackle the above challenges, we propose a three-module framework, called CE-DEPT, for accurate, efficient and cost-effective medical note generation. Specifically, the Task Decomposition Module breaks down complete medical dialogues into section-specific dialogues to ensure relevance and accuracy. The Batch Combination Module groups these sections into batches based on disease similarity to reduce costs and improve efficiency. The Note Generation Module employs batch prompting with ICL to generate each section note, followed by combining them into a structured, comprehensive medical note. Experiments on benchmark datasets demonstrated the effectiveness of Task Decomposition and Batch Prompting. Our method, CE-DEPT outperforms the best method by 5% on the ROUGE-1 score, 3% on the Bertscore-F1, a cost-effectiveness improvement of 15%, and a reduction in time consumption of 25% at peak accuracy.|医疗对话记录的生成在医疗保健领域至关重要，它为医患互动提供了结构化的总结。医疗记录通常被严格组织成多个部分，包括主诉、现病史等。每个部分都有其特定的目的，用于记录详细的医疗内容。传统上，这项任务需要大量的人力，医生需要手动创建记录，这一过程容易出错。随着人工智能的进步，现在可以实现医疗记录的自动生成。自动生成医疗记录的方法主要分为两类。预训练语言模型（PLMs）在处理非结构化输出、有限数据集和不足的医学术语方面存在困难。上下文学习（ICL）方法提高了准确性并减少了数据需求，但仍生成非结构化的记录，并且需要较高的时间和成本。为了解决上述挑战，我们提出了一个三模块框架，称为CE-DEPT，以实现准确、高效且经济的医疗记录生成。具体来说，任务分解模块将完整的医疗对话分解为特定部分的对话，以确保相关性和准确性。批量组合模块根据疾病相似性将这些部分分组，以降低成本并提高效率。记录生成模块采用批量提示与ICL相结合的方法生成每个部分的记录，然后将它们组合成一个结构化的、全面的医疗记录。在基准数据集上的实验证明了任务分解和批量提示的有效性。我们的方法CE-DEPT在ROUGE-1得分上比最佳方法高出5%，在Bertscore-F1上高出3%，成本效益提高了15%，并且在达到最高准确性时，时间消耗减少了25%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cost-Effective+Framework+with+Optimized+Task+Decomposition+and+Batch+Prompting+for+Medical+Dialogue+Summary)|0|
|[InfoMLP: Unlocking the Potential of MLPs for Semi-Supervised Learning with Structured Data](https://doi.org/10.1145/3627673.3679679)|Hengrui Zhang, Qitian Wu, Chenxiao Yang, Philip S. Yu|University of Illinois at Chicago, Chicago, USA; Shanghai Jiao Tong University, Shanghai, China|We introduce InfoMLP, an innovative model structured like a Multilayer Perceptron (MLP) for semi-supervised classification of structured data, e.g., graphs. InfoMLP was inspired by our observation that overlapping information between node features and the structure between data points significantly influences the performance gap between feature-only MLPs and advanced graph-based semi-supervised methods, e.g., GNNs. To quantify the overlapping information, we first introduce a tractable metric to quantify the mutual information between node features and graph structure. Based on this, we propose InfoMLP, which seeks to maximize the mutual information between node embeddings derived from the MLP and the structure information. Our info-max objective is split into two sub-objectives: the first is a non-parametric preprocessing step aiming to find the optimal graph-augmented node feature matrix that captures the maximal information about the graph structure, while the second sub-objective is to maximize the mutual information between node embeddings generated from the original node features and those from the graph-augmented node features. Since the message-passing operation is integrated into the preprocessing step, requiring only a single execution per dataset, InfoMLP maintains the same efficiency as a vanilla MLP during both training and testing. We validate the efficacy of our design through experiments on real-world datasets of varying scales supplemented by comprehensive ablation studies. Our results corroborate our analysis and demonstrate the effectiveness of our novel approach.|我们提出了InfoMLP，一种创新的多层感知机（MLP）结构模型，用于结构化数据（如图）的半监督分类。InfoMLP的灵感来源于我们观察到节点特征和数据点之间结构信息之间的重叠信息显著影响了仅使用特征的MLP与先进的基于图的半监督方法（如图神经网络GNNs）之间的性能差距。为了量化这种重叠信息，我们首先引入了一种可处理的度量标准来量化节点特征和图结构之间的互信息。基于此，我们提出了InfoMLP，该模型旨在最大化从MLP中得到的节点嵌入与结构信息之间的互信息。我们的信息最大化目标被分为两个子目标：第一个是非参数的预处理步骤，旨在找到能够捕捉图结构最大信息的最优图增强节点特征矩阵；第二个子目标是最大化从原始节点特征生成的节点嵌入与从图增强节点特征生成的节点嵌入之间的互信息。由于消息传递操作被集成到预处理步骤中，每个数据集只需执行一次，因此InfoMLP在训练和测试期间保持了与普通MLP相同的效率。我们通过在多种规模的现实世界数据集上的实验以及全面的消融研究验证了我们设计的有效性。我们的结果证实了我们的分析，并展示了我们新方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=InfoMLP:+Unlocking+the+Potential+of+MLPs+for+Semi-Supervised+Learning+with+Structured+Data)|0|
|[Revisit Orthogonality in Graph-Regularized MLPs](https://doi.org/10.1145/3627673.3679811)|Hengrui Zhang, Shen Wang, Vassilis N. Ioannidis, Soji Adeshina, Jiani Zhang, Xiao Qin, Christos Faloutsos, Da Zheng, George Karypis, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revisit+Orthogonality+in+Graph-Regularized+MLPs)|0|
|[CYCLE: Cross-Year Contrastive Learning in Entity-Linking](https://doi.org/10.1145/3627673.3679702)|Pengyu Zhang, Congfeng Cao, Klim Zaporojets, Paul Groth||Knowledge graphs constantly evolve with new entities emerging, existing definitions being revised, and entity relationships changing. These changes lead to temporal degradation in entity linking models, characterized as a decline in model performance over time. To address this issue, we propose leveraging graph relationships to aggregate information from neighboring entities across different time periods. This approach enhances the ability to distinguish similar entities over time, thereby minimizing the impact of temporal degradation. We introduce CYCLE: Cross-Year Contrastive Learning for Entity-Linking. This model employs a novel graph contrastive learning method to tackle temporal performance degradation in entity linking tasks. Our contrastive learning method treats newly added graph relationships as positive samples and newly removed ones as negative samples. This approach helps our model effectively prevent temporal degradation, achieving a 13.90% performance improvement over the state-of-the-art from 2023 when the time gap is one year, and a 17.79% improvement as the gap expands to three years. Further analysis shows that CYCLE is particularly robust for low-degree entities, which are less resistant to temporal degradation due to their sparse connectivity, making them particularly suitable for our method. The code and data are made available at .|知识图谱随着新实体的出现、现有定义的修订以及实体关系的变化而不断演变。这些变化导致实体链接模型出现时间退化现象，表现为模型性能随时间的推移而下降。为了解决这一问题，我们提出利用图关系来聚合不同时间段的相邻实体信息。这种方法增强了随时间区分相似实体的能力，从而最大限度地减少时间退化的影响。我们引入了CYCLE：跨年度对比学习实体链接模型。该模型采用了一种新颖的图对比学习方法来应对实体链接任务中的时间性能退化问题。我们的对比学习方法将新添加的图关系视为正样本，将新删除的关系视为负样本。这种方法帮助我们的模型有效防止时间退化，与2023年的最先进技术相比，在时间差距为一年时性能提升了13.90%，当差距扩大到三年时提升了17.79%。进一步的分析表明，CYCLE对于低度实体特别稳健，这些实体由于其稀疏的连接性而较难抵抗时间退化，因此特别适合我们的方法。代码和数据可在以下网址获取：。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CYCLE:+Cross-Year+Contrastive+Learning+in+Entity-Linking)|0|
|[Data Imputation from the Perspective of Graph Dirichlet Energy](https://doi.org/10.1145/3627673.3679669)|Weiqi Zhang, Guanlue Li, Jianheng Tang, Jia Li, Fugee Tsung||Data imputation is a crucial task due to the widespread occurrence of missing data. Many methods adopt a two-step approach: initially crafting a preliminary imputation (the "draft") and then refining it to produce the final missing data imputation result, commonly referred to as "draft-then-refine". In our study, we examine this prevalent strategy through the lens of graph Dirichlet energy. We observe that a basic "draft" imputation tends to decrease the Dirichlet energy. Therefore, a subsequent "refine" step is necessary to restore the overall energy balance. Existing refinement techniques, such as the Graph Convolutional Network (GCN), often result in further energy reduction. To address this, we introduce a new framework, the Graph Laplacian Pyramid Network (GLPN). GLPN incorporates a U-shaped autoencoder and residual networks to capture both global and local details effectively. Through extensive experiments on multiple real-world datasets, GLPN consistently outperforms state-of-the-art methods across three different missing data mechanisms. The code is available at https://github.com/liguanlue/GLPN.|数据填补是一项关键任务，因为缺失数据普遍存在。许多方法采用两步策略：首先构建一个初步的填补（称为“草稿”），然后对其进行优化以生成最终的缺失数据填补结果，这一过程通常被称为“先草稿后优化”。在我们的研究中，我们通过图狄利克雷能量的视角来审视这一普遍策略。我们观察到，一个简单的“草稿”填补往往会导致狄利克雷能量的下降。因此，后续的“优化”步骤是必要的，以恢复整体的能量平衡。现有的优化技术，如图卷积网络（GCN），通常会导致能量的进一步减少。为了解决这一问题，我们引入了一个新的框架——图拉普拉斯金字塔网络（GLPN）。GLPN结合了U形自动编码器和残差网络，以有效地捕捉全局和局部细节。通过在多个真实世界数据集上的广泛实验，GLPN在三种不同的缺失数据机制下始终优于最先进的方法。代码可在https://github.com/liguanlue/GLPN获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Data+Imputation+from+the+Perspective+of+Graph+Dirichlet+Energy)|0|
|[DPCAG: A Community Affiliation Graph Generation Model for Preserving Group Relationships](https://doi.org/10.1145/3627673.3679657)|Xinjian Zhang, Bo Ning, Chengfei Liu|; School of Information Science and Technology, Dalian Maritime University, Dalian, Liaoning, China|Graph data has been widely applied due to its powerful expressive capabilities. The release of raw graph data without preprocessing may lead to privacy information leakage. Thus, generating privacy-protected graphs is necessary for data analysis. Current privacy protection methods in graphs focus on securing attributes like degree distribution, triangle counts, and node information, but they often overlook the need to protect user group relationships. Additionally, some privacy-preserving graph publishing methods introduce significant noise due to the chosen graph generation techniques and the points at which noise is added. This paper aims to propose an effective graph synthesis algorithm by using differential privacy named DPCAG (Differentially Private Community Affiliation Graph Generation Model) for protecting user group relationships. Firstly, it is observed that there are numerous small probabilities in the adjacency matrix D generated by the affiliation matrix F, directly utilizing it to construct graph G would result in the generation of a substantial number of redundant edges. Therefore, we introduce a generating threshold theta to filter out unnecessary edges. Secondly, to achieve a better balance between data availability and the level of privacy protection, two budget allocation schemes are designed based on the introduction of k-truss to describe the tightness of group relationships. Lastly, we demonstrate the proposed model satisfies differential privacy mathematically and the effectiveness of DPCAG is validated using four real graph datasets.|图数据因其强大的表达能力而得到广泛应用。未经预处理的原始图数据发布可能导致隐私信息泄露。因此，生成具有隐私保护的图对于数据分析是必要的。当前的图隐私保护方法主要关注保护诸如度分布、三角形计数和节点信息等属性，但往往忽视了保护用户群体关系的需求。此外，一些隐私保护图发布方法由于所选的图生成技术和添加噪声的时机，引入了显著的噪声。本文旨在提出一种有效的图合成算法，使用差分隐私技术，名为DPCAG（差分隐私社区隶属图生成模型），以保护用户群体关系。首先，观察到由隶属矩阵F生成的邻接矩阵D中存在许多小概率值，直接利用其构建图G会导致生成大量冗余边。因此，我们引入一个生成阈值theta来过滤掉不必要的边。其次，为了在数据可用性和隐私保护水平之间实现更好的平衡，基于引入k-核来描述群体关系的紧密性，设计了两种预算分配方案。最后，我们通过数学证明所提出的模型满足差分隐私，并使用四个真实的图数据集验证了DPCAG的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DPCAG:+A+Community+Affiliation+Graph+Generation+Model+for+Preserving+Group+Relationships)|0|
|[A GAIL Fine-Tuned LLM Enhanced Framework for Low-Resource Knowledge Graph Question Answering](https://doi.org/10.1145/3627673.3679753)|Zhiqiang Zhang, Liqiang Wen, Wen Zhao|Peking University, Beijing, China|Recent studies on knowledge graph question answering (KGQA) have focused on tackling complex inquiries to enhance the applicability of models in real-life settings. Unfortunately, KGQA models encounter significant challenges due to the lack of high-quality annotated data, making it difficult to accurately answer the diverse range of complex natural language questions posed by users. Inspired by the recent success of Large Language Models (LLMs), the burden associated with manual annotation can be mitigated by utilizing LLMs. However, the data generated directly by LLMs may exhibit a potential distribution discrepancy with real user queries. In this paper, we present an enhancement framework that utilizes Generative Adversarial Imitation Learning (GAIL) to fine-tune LLMs, which can address the challenges inherent in the low-resource KGQA task. Specifically, based on GAIL, the LLMs act as the generator aiming to output samples resembling expert demonstrations. Meanwhile, we utilize a paired discriminator to assess the authenticity of generated sequences and their relevance to the input SPARQL queries. Additionally, proximal policy optimization is leveraged to stabilize the training of the generator. Furthermore, we employ an automated algorithm to controllably sample various SPARQL queries from the knowledge graph, subsequently transforming them into corresponding natural language questions using fine-tuned LLMs. The synthetic dataset can serve as supplementary data for training lightweight KGQA models in real-world scenarios. Experimental results on the WebQuestionsSP, ComplexWebQuestions, and GrailQA show that our framework achieves state-of-the-art performance in a low-resource setting, even approaching the performance of supervised models.|最近关于知识图谱问答（KGQA）的研究主要集中在应对复杂查询，以提高模型在现实生活中的适用性。然而，由于缺乏高质量标注数据，KGQA模型面临着重大挑战，难以准确回答用户提出的各种复杂自然语言问题。受到大语言模型（LLMs）近期成功的启发，利用LLMs可以减轻与手动标注相关的负担。然而，直接由LLMs生成的数据可能与真实用户查询存在潜在的分布差异。本文提出了一种增强框架，利用生成对抗模仿学习（GAIL）对LLMs进行微调，以解决低资源KGQA任务中固有的挑战。具体而言，基于GAIL，LLMs作为生成器，旨在输出类似于专家演示的样本。同时，我们使用配对的判别器来评估生成序列的真实性及其与输入SPARQL查询的相关性。此外，我们利用近端策略优化来稳定生成器的训练。此外，我们采用自动化算法从知识图谱中可控地采样各种SPARQL查询，随后使用微调的LLMs将其转换为相应的自然语言问题。生成的合成数据集可以作为补充数据，用于在现实场景中训练轻量级KGQA模型。在WebQuestionsSP、ComplexWebQuestions和GrailQA上的实验结果表明，我们的框架在低资源设置下实现了最先进的性能，甚至接近有监督模型的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+GAIL+Fine-Tuned+LLM+Enhanced+Framework+for+Low-Resource+Knowledge+Graph+Question+Answering)|0|
|[NeutronCache: An Efficient Cache-Enhanced Distributed Graph Neural Network Training System](https://doi.org/10.1145/3627673.3679815)|Chu Zhao, Shengjie Dong, Yuhai Zhao, Yuan Li|Northeastern University, Shenyang, Liaoning, China; North China University of Technology, Beijing, Beijing, China|As real-world graph data continues to grow larger and larger, training large graphs in a distributed environment is becoming increasingly prevalent. However, network transmission in a distributed environment can hinder subsequent training steps, resulting in suboptimal training performance. After conducting a comprehensive analysis and experimental demonstration, we have discovered that during the training process, there exist certain data that can be computed once and reused multiple times. In addition, we also found that after a certain iterations of training, the parameter updates during each iteration had minimal effect on the parameters. Based on these findings, we have improved the original implementation and proposed a cache-enhanced distributed graph training system, NeutronCache. It utilizes cached reusable intermediate data and a dynamically adjusted stale embedding reuse strategy, reducing network overhead in distributed systems and accelerating the training process. Through experimental validation, our implementation achieved acceleration ranging from 1.4X to 16.61X on real graph datasets with almost no loss in accuracy.|随着现实世界中的图数据规模不断增大，在分布式环境中训练大规模图数据变得越来越普遍。然而，分布式环境中的网络传输可能会阻碍后续的训练步骤，导致训练性能不佳。经过全面的分析和实验验证，我们发现，在训练过程中存在一些可以计算一次并重复使用多次的数据。此外，我们还发现，经过一定次数的训练迭代后，每次迭代中的参数更新对参数的影响微乎其微。基于这些发现，我们对原有实现进行了改进，并提出了一种缓存增强的分布式图训练系统——NeutronCache。该系统利用缓存的可重用中间数据以及动态调整的陈旧嵌入重用策略，减少了分布式系统中的网络开销，并加速了训练过程。通过实验验证，我们的实现在真实图数据集上实现了1.4倍到16.61倍的加速，且几乎未损失准确性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NeutronCache:+An+Efficient+Cache-Enhanced+Distributed+Graph+Neural+Network+Training+System)|0|
|[Towards Coarse-grained Visual Language Navigation Task Planning Enhanced by Event Knowledge Graph](https://doi.org/10.1145/3627673.3679711)|Kaichen Zhao, Yaoxian Song, Haiquan Zhao, Haoyu Liu, Tiefeng Li, Zhixu Li||Visual language navigation (VLN) is one of the important research in embodied AI. It aims to enable an agent to understand the surrounding environment and complete navigation tasks. VLN instructions could be categorized into coarse-grained and fine-grained commands. Fine-grained command describes a whole task with subtasks step-by-step. In contrast, coarse-grained command gives an abstract task description, which more suites human habits. Most existing work focuses on the former kind of instruction in VLN tasks, ignoring the latter abstract instructions belonging to daily life scenarios. To overcome the above challenge in abstract instruction, we attempt to consider coarse-grained instruction in VLN by event knowledge enhancement. Specifically, we first propose a prompt-based framework to extract an event knowledge graph (named VLN-EventKG) for VLN integrally over multiple mainstream benchmark datasets. Through small and large language model collaboration, we realize knowledge-enhanced navigation planning (named EventNav) for VLN tasks with coarse-grained instruction input. Additionally, we design a novel dynamic history backtracking module to correct potential error action planning in real time. Experimental results in various public benchmarks show our knowledge-enhanced method has superiority in coarse-grained-instruction VLN using our proposed VLN-EventKG with over 5% improvement in success rate. Our project is available at https://sites.google.com/view/vln-eventkg|视觉语言导航（VLN）是具身人工智能（Embodied AI）领域的重要研究方向之一。其目标是使智能体能够理解周围环境并完成导航任务。VLN指令可分为粗粒度指令和细粒度指令。细粒度指令通过逐步描述子任务来定义整个任务，而粗粒度指令则提供抽象的任务描述，更符合人类的日常习惯。现有研究大多关注VLN任务中的细粒度指令，而忽略了日常生活中常见的抽象指令。

为了应对抽象指令带来的挑战，我们尝试通过事件知识增强来处理VLN中的粗粒度指令。具体而言，我们首先提出了一种基于提示（prompt-based）的框架，从多个主流基准数据集中提取出用于VLN的事件知识图谱（命名为VLN-EventKG）。通过小型和大型语言模型的协作，我们实现了针对粗粒度指令输入的VLN任务的知识增强导航规划（命名为EventNav）。此外，我们还设计了一种新颖的动态历史回溯模块，以实时纠正潜在的错误动作规划。

在多个公开基准数据集上的实验结果表明，我们提出的知识增强方法在使用VLN-EventKG的粗粒度指令VLN任务中表现优异，成功率提升了5%以上。我们的项目可通过以下链接访问：https://sites.google.com/view/vln-eventkg。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Coarse-grained+Visual+Language+Navigation+Task+Planning+Enhanced+by+Event+Knowledge+Graph)|0|
|[Zero-shot Knowledge Graph Question Generation via Multi-agent LLMs and Small Models Synthesis](https://doi.org/10.1145/3627673.3679805)|Runhao Zhao, Jiuyang Tang, Weixin Zeng, Ziyang Chen, Xiang Zhao||Knowledge Graph Question Generation (KGQG) is the task of generating natural language questions based on the given knowledge graph (KG). Although extensively explored in recent years, prevailing models predominantly depend on labelled data for training deep learning models or employ large parametric frameworks, e.g., Large Language Models (LLMs), which can incur significant deployment costs and pose practical implementation challenges. To address these issues, in this work, we put forward a zero-shot, multi-agent KGQG framework. This framework integrates the capabilities of LLMs with small models to facilitate cost-effective, high-quality question generation. In specific, we develop a professional editorial team architecture accompanied by two workflow optimization tools to reduce unproductive collaboration among LLMs-based agents and enhance the robustness of the system. Extensive experiments demonstrate that our proposed framework derives the new state-of-the-art performance on the zero-shot KGQG tasks, with relative gains of 20.24% and 13.57% on two KGQG datasets, respectively, which rival fully supervised state-of-the-art models.|知识图谱问答生成（KGQG）是一项基于给定知识图谱（KG）生成自然语言问题的任务。尽管近年来该领域得到了广泛探索，但主流模型主要依赖于标注数据来训练深度学习模型，或采用大型参数化框架（例如大语言模型，LLMs），这可能导致高昂的部署成本并带来实际实施中的挑战。为了解决这些问题，本文提出了一种零样本、多代理的KGQG框架。该框架将大语言模型的能力与小型模型相结合，以实现高性价比且高质量的问题生成。具体而言，我们设计了一种专业编辑团队架构，并配备了两个工作流程优化工具，以减少基于LLMs的代理之间无效的协作，同时增强系统的鲁棒性。大量实验表明，我们提出的框架在零样本KGQG任务中取得了新的最先进性能，在两个KGQG数据集上分别实现了20.24%和13.57%的相对提升，其表现可与完全监督的最先进模型相媲美。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Zero-shot+Knowledge+Graph+Question+Generation+via+Multi-agent+LLMs+and+Small+Models+Synthesis)|0|
|[Devil in the Tail: A Multi-Modal Framework for Drug-Drug Interaction Prediction in Long Tail Distinction](https://doi.org/10.1145/3627673.3679719)|Liangwei Nathan Zheng, Chang George Dong, Wei Emma Zhang, Xin Chen, Lin Yue, Weitong Chen||Drug-drug interaction (DDI) identification is a crucial aspect of pharmacology research. There are many DDI types (hundreds), and they are not evenly distributed with equal chance to occur. Some of the rarely occurred DDI types are often high risk and could be life-critical if overlooked, exemplifying the long-tailed distribution problem. Existing models falter against this distribution challenge and overlook the multi-faceted nature of drugs in DDI prediction. In this paper, a novel multi-modal deep learning-based framework, namely TFDM, is introduced to leverage multiple properties of a drug to achieve DDI classification. The proposed framework fuses multimodal features of drugs, including graph-based, molecular structure, Target and Enzyme, for DDI identification. To tackle the challenge posed by the distribution skewness across categories, a novel loss function called Tailed Focal Loss is introduced, aimed at further enhancing the model performance and address gradient vanishing problem of focal loss in extremely long-tailed dataset. Intensive experiments over 4 challenging long-tailed dataset demonstrate that the TFMD outperforms the most recent SOTA methods in long-tailed DDI classification tasks. The source code is released to reproduce our experiment results: https://github.com/IcurasLW/TFMD_Longtailed_DDI.git|药物相互作用（DDI）识别是药理学研究中的一个关键方面。DDI类型众多（数百种），并且它们的分布并不均匀，发生的概率也不相等。某些罕见的DDI类型通常具有高风险，如果被忽视可能会危及生命，这体现了长尾分布问题。现有模型在面对这种分布挑战时表现不佳，并且在DDI预测中忽视了药物的多面性。本文提出了一种新颖的多模态深度学习框架，即TFDM，以利用药物的多种特性来实现DDI分类。所提出的框架融合了药物的多模态特征，包括基于图的结构、分子结构、靶标和酶，用于DDI识别。为了应对类别间分布偏斜带来的挑战，引入了一种新的损失函数，称为Tailed Focal Loss，旨在进一步增强模型性能，并解决焦点损失在极长尾数据集中的梯度消失问题。在4个具有挑战性的长尾数据集上进行的大量实验表明，TFMD在长尾DDI分类任务中优于最新的SOTA方法。源代码已发布，以重现我们的实验结果：https://github.com/IcurasLW/TFMD_Longtailed_DDI.git|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Devil+in+the+Tail:+A+Multi-Modal+Framework+for+Drug-Drug+Interaction+Prediction+in+Long+Tail+Distinction)|0|
|[Irregularity-Informed Time Series Analysis: Adaptive Modelling of Spatial and Temporal Dynamics](https://doi.org/10.1145/3627673.3679716)|Liangwei Nathan Zheng, Zhengyang Li, Chang George Dong, Wei Emma Zhang, Lin Yue, Miao Xu, Olaf Maennel, Weitong Chen||Irregular Time Series Data (IRTS) has shown increasing prevalence in real-world applications. We observed that IRTS can be divided into two specialized types: Natural Irregular Time Series (NIRTS) and Accidental Irregular Time Series (AIRTS). Various existing methods either ignore the impacts of irregular patterns or statically learn the irregular dynamics of NIRTS and AIRTS data and suffer from limited data availability due to the sparsity of IRTS. We proposed a novel transformer-based framework for general irregular time series data that treats IRTS from four views: Locality, Time, Spatio and Irregularity to motivate the data usage to the highest potential. Moreover, we design a sophisticated irregularity-gate mechanism to adaptively select task-relevant information from irregularity, which improves the generalization ability to various IRTS data. We implement extensive experiments to demonstrate the resistance of our work to three highly missing ratio datasets (88.4%, 94.9%, 60% missing value) and investigate the significance of the irregularity information for both NIRTS and AIRTS by additional ablation study. We release our implementation in https://github.com/IcurasLW/MTSFormer-Irregular_Time_Series.git|不规则时间序列数据（Irregular Time Series Data, IRTS）在实际应用中的出现频率日益增加。我们观察到，IRTS可以分为两种特殊类型：自然不规则时间序列（Natural Irregular Time Series, NIRTS）和偶然不规则时间序列（Accidental Irregular Time Series, AIRTS）。现有的各种方法要么忽视了不规则模式的影响，要么静态地学习NIRTS和AIRTS数据的不规则动态，并且由于IRTS的稀疏性，数据可用性受到限制。我们提出了一种基于Transformer的新框架，用于处理一般的不规则时间序列数据，该框架从四个视角对待IRTS：局部性（Locality）、时间（Time）、空间（Spatio）和不规则性（Irregularity），以最大限度地激发数据的潜力。此外，我们设计了一种复杂的不规则门机制，能够自适应地从不规则性中选择与任务相关的信息，从而提高了对各种IRTS数据的泛化能力。我们进行了广泛的实验，以证明我们的工作对三个高缺失率数据集（88.4%、94.9%、60%缺失值）的抵抗能力，并通过额外的消融研究探讨了不规则信息对NIRTS和AIRTS的重要性。我们在https://github.com/IcurasLW/MTSFormer-Irregular_Time_Series.git上发布了我们的实现。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Irregularity-Informed+Time+Series+Analysis:+Adaptive+Modelling+of+Spatial+and+Temporal+Dynamics)|0|
|[FGITrans: Cross-City Transformer for Fine-grained Urban Flow Inference](https://doi.org/10.1145/3627673.3679855)|Yuhao Zheng, Yishuo Cai, Zihao Cai, Changjun Fan, Senzhang Wang, Jianxin Wang|National University of Defense Technology Changsha, China; Central South University Changsha, China|Inferring the fine-grained urban flows based on the coarse-grained flow observations is practically important to many smart city-related applications. Adequate data is usually a prerequisite for existing machine learning methods, especially most deep learning models. However, many cities still suffer from the data scarcity issue due to the unbalanced city development levels. To mitigate this issue, we propose a novel cross-city fine-grained urban flow inference model named FGITrans, which aims to effectively transfer the knowledge from the data-rich cities to the data-scarce cities. Specifically, we design a weight-sharing triple-branch transformer framework which adopts self-attention and cross-attention for source/target city feature learning and domain alignment, respectively. Then, we propose a novel spatio-temporal adaptive embedding (STAE) layer for our transformer framework, and introduce a cross-city knowledge distillation (CKD) loss to narrow the cross-city disparities. The CKD loss explicitly enforces the framework to learn the discriminative domain-specific and domain-invariant representations simultaneously. Extensive experiments conducted on four large real-world datasets validate the effectiveness of FGITrans compared with the state-of-the-art baselines.|基于粗粒度流量观测推断细粒度城市流量，对于许多智慧城市相关应用具有重要的实际意义。充足的数据通常是现有机器学习方法，尤其是大多数深度学习模型的先决条件。然而，由于城市发展水平不均衡，许多城市仍然面临数据稀缺问题。为了缓解这一问题，我们提出了一种名为 FGITrans 的新型跨城市细粒度城市流量推断模型，旨在有效地将知识从数据丰富的城市迁移到数据稀缺的城市。具体而言，我们设计了一个权重共享的三分支 Transformer 框架，该框架分别采用自注意力和交叉注意力进行源/目标城市特征学习和领域对齐。然后，我们为 Transformer 框架提出了一种新颖的时空自适应嵌入（STAE）层，并引入了跨城市知识蒸馏（CKD）损失以缩小跨城市差异。CKD 损失明确地强制框架同时学习判别性的领域特定和领域不变表示。在四个大型真实世界数据集上进行的大量实验验证了 FGITrans 相较于最先进基线的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FGITrans:+Cross-City+Transformer+for+Fine-grained+Urban+Flow+Inference)|0|
|[AdaTM: Fine-grained Urban Flow Inference with Adaptive Knowledge Transfer across Multiple Cities](https://doi.org/10.1145/3627673.3679856)|Yuhao Zheng, Jinyang Wu, Zihao Cai, Senzhang Wang, Jianxin Wang|Central South University, Changsha, China|Inferring the fine-grained urban traffic flows based on the coarse-grained traffic flow observations is practically important to many real applications for smart city. Existing approaches mostly rely on a large number of high quality urban flow data, but neglect the data sparsity issue which is common in real-world scenarios. Therefore, the performance of existing methods may not be promising towards cities that lack sufficient traffic flow data. How to design a more generalizable urban flow inference model that is able to effectively transfer knowledge across multiple cities is challenging and remains as an open research problem. In this paper, we propose a novel fine-grained urban flow inference model named AdaTM, which leverages the city-specific and city-invariant knowledge extracted from multiple cities. Specifically, we first propose a transformer-based urban feature extraction network named UBFormer to comprehensively extract the spatial-temporal features of multiple source cities. Then, we incorporate a learnable integrator to fuse the city-invariant and city-specific feature representations for the target city with sparse traffic flow data. Finally, we construct the feature representation of the target city through adaptive feature fusion and infer its fine-grained urban flows through the designed urban flow upsampler. Extensive experiments conducted on four large real-world datasets demonstrate the effectiveness of our approach.|基于粗粒度交通流观测数据推断细粒度城市交通流对于智慧城市的许多实际应用具有重要意义。现有的方法大多依赖于大量高质量的城市流量数据，但忽视了现实场景中常见的数据稀疏性问题。因此，现有方法在缺乏足够交通流量数据的城市中表现可能不佳。如何设计一个更具通用性的城市流量推断模型，能够有效地在多个城市之间进行知识迁移，是一个具有挑战性且尚未解决的研究问题。本文提出了一种名为AdaTM的新型细粒度城市流量推断模型，该模型利用从多个城市中提取的城市特定知识和城市不变知识。具体而言，我们首先提出了一种基于Transformer的城市特征提取网络UBFormer，以全面提取多个源城市的时空特征。然后，我们引入了一个可学习的集成器，将城市不变特征和城市特定特征表示融合到交通流量数据稀疏的目标城市中。最后，我们通过自适应特征融合构建目标城市的特征表示，并通过设计的城市流量上采样器推断其细粒度城市流量。在四个大型真实数据集上进行的大量实验证明了我们方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AdaTM:+Fine-grained+Urban+Flow+Inference+with+Adaptive+Knowledge+Transfer+across+Multiple+Cities)|0|
|[AdaTrans: Adaptive Transfer Time Prediction for Multi-modal Transportation Modes](https://doi.org/10.1145/3627673.3679585)|Shuxin Zhong, Hua Wei, Wenjun Lyu, Guang Yang, Zhiqing Hong, Guang Wang, Yu Yang, Desheng Zhang|Florida State University, Tallahassee, FL, USA; Arizona State University, Tempe, AZ, USA; Rutgers University, Piscataway, NJ, USA; Lehigh University, Bethlehem, PA, USA|Multi-modal transportation leverages the advantages of various transportation modes, leading to more efficient urban traveling services. Accurately predicting transfer times between different modes provides guidance for tasks such as trip planning and transportation management. Most existing transfer time prediction works rely on strong assumptions, e.g., predetermined routes, assumed speeds, and predefined downstream transportation timetables. However, these assumptions are hard to hold in practice due to internal factors like individual preferences and external factors like dynamic traffic conditions. These factors are dynamic and vary with location and time, presenting a significant challenge. To address this, we introduce an adaptive transfer time prediction framework, AdaTrans, to forecast personalized transfer times between upstream and downstream transportation modes. Firstly, an attribute learning module is designed to model the trends of internal factors. Then a spatial-temporal adaptive learning component is designed to learn dynamic external factors. Finally, an aggregation component with a capsule network is employed to fuse the influences of these factors. The extensive evaluation results in two real-world datasets demonstrate that AdaTrans effectively harnesses insights from internal and external factors, outperforming state-of-the-art methods by ~20%.|多模态交通利用各种交通方式的优势，从而实现更高效的城市出行服务。准确预测不同交通方式之间的换乘时间为行程规划和交通管理等任务提供了指导。现有的换乘时间预测工作大多依赖于强假设，例如预设路线、假设速度以及预定义的下游交通时刻表。然而，由于个体偏好等内部因素和动态交通状况等外部因素，这些假设在实际中难以成立。这些因素具有动态性，并随地点和时间而变化，带来了显著挑战。为解决这一问题，我们提出了一种自适应换乘时间预测框架——AdaTrans，用于预测上游和下游交通方式之间的个性化换乘时间。首先，设计了一个属性学习模块来建模内部因素的趋势。然后，设计了一个时空自适应学习组件来学习动态的外部因素。最后，采用带有胶囊网络的聚合组件来融合这些因素的影响。在两个真实数据集上的广泛评估结果表明，AdaTrans有效利用了内部和外部因素的洞察力，性能优于现有最先进方法约20%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AdaTrans:+Adaptive+Transfer+Time+Prediction+for+Multi-modal+Transportation+Modes)|0|
|[Learning Cross-modal Knowledge Reasoning and Heuristic-prompt for Visual-language Navigation](https://doi.org/10.1145/3627673.3679740)|Dongming Zhou, Zhengbin Pang, Wei Li|School of Computer Science, National University of Defence Technology, Changsha, China; School of Computer and Electronic Information, Guangxi University, Nanning, China; School of Computer Science, National University of Defense Technology, Changsha, China|Visual language navigation is an exciting and challenging multi-modal task. Most existing research focuses on the fusion of visual features and semantic space, which ignoring the importance of local highlight features and semantic knowledge alignment in images for agent navigation. Therefore, this paper proposes a novel visual language model combining Knowledge-augmented Reasoning and Soft-Prompt (KRSP) learning. First, we perform fine-grained processing of local regions in the image and to map context image features and text knowledge to the same common sub-space. We focus on regional knowledge to increase the model reasoning ability. Next, soft-prompt learning aligns keywords and sub-visual information in instruction features to solve the path mismatch problem in coarse-grained instructions. We use a large-scale pre-training model CoCoOp to collect highly matched soft action prompts into a unified instruction set. Finally, we propose a general cross-modal feature alignment loss function. The potential semantic correlation between sub-visual information and instruction space is closer through the penalty mechanism of the alignment function. This paper verifies the method effectiveness on the R2R and REVERIE datasets, and the experimental results show that KRSP achieves state-of-the-art performance. Among them, the KRSP of SPL evaluation metric increased by 4.5% in unseen scenarios.|视觉语言导航是一项令人兴奋且具有挑战性的多模态任务。大多数现有研究集中于视觉特征与语义空间的融合，而忽略了图像中的局部突出特征与语义知识对齐在智能体导航中的重要性。因此，本文提出了一种结合知识增强推理与软提示学习（Knowledge-augmented Reasoning and Soft-Prompt, KRSP）的新型视觉语言模型。首先，我们对图像中的局部区域进行细粒度处理，并将上下文图像特征与文本知识映射到同一公共子空间。我们关注区域知识以增强模型的推理能力。接着，软提示学习将指令特征中的关键词与子视觉信息对齐，以解决粗粒度指令中的路径不匹配问题。我们使用大规模预训练模型CoCoOp收集高度匹配的软动作提示，并将其整合到统一的指令集中。最后，我们提出了一种通用的跨模态特征对齐损失函数。通过对齐函数的惩罚机制，子视觉信息与指令空间之间的潜在语义关联更加紧密。本文在R2R和REVERIE数据集上验证了该方法的有效性，实验结果表明KRSP达到了最先进的性能。其中，在未见场景中，KRSP的SPL评估指标提升了4.5%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Cross-modal+Knowledge+Reasoning+and+Heuristic-prompt+for+Visual-language+Navigation)|0|
|[LST2A: Lexical-Syntactic Targeted Adversarial Attack for Texts](https://doi.org/10.1145/3627673.3679640)|Guanghao Zhou, Panjia Qiu, Mingyuan Fan, Cen Chen, Yaliang Li, Wenmeng Zhou|Alibaba Group, Hangzhou, China; East China Normal University, Shanghai, China|Textual adversarial attack in black-box scenarios is a challenging task, as only the predicted label is available, and the text space is discrete and non-differentiable. Current research in this area is still in its infancy and mostly focuses on untargeted attack, lacking the capability to control the labels of the generated adversarial examples. Meanwhile, existing textual adversarial attack methods primarily rely on word substitution operations to maintain semantic similarity between the adversarial and original examples, which greatly limits the search space for adversarial examples. To address these issues, we propose a novel Lexical-Syntactic Targeted Adversarial Attack method tailored for the black-box settings, referred to as LST2A. Our approach involves adversarial perturbations at different levels of granularities, i.e., word-level with word substitution operations and syntactic-level through rewriting the syntax of the examples. Specifically, we first embed the entire text into the embedding layer of a masked language model, and then optimize perturbations at the word level within the hidden state to generate adversarial examples with the target label. For examples that are difficult to attack successfully with only word-level perturbations at higher semantic similarity thresholds, we leverage Large Language Model (LLM) to introduce syntactic-level perturbations to these examples, making them more vulnerable to the decision boundary of the victim model. Subsequently, we re-optimize the word-level perturbations for these vulnerable examples. Extensive experiments and human evaluations demonstrate that our proposed method consistently outperforms the state-of-the-art baselines, crafting smoother, more grammatically correct adversarial examples.|黑盒场景下的文本对抗攻击是一项具有挑战性的任务，因为只有预测标签可用，且文本空间是离散且不可微分的。目前该领域的研究仍处于起步阶段，主要集中在无目标攻击上，缺乏控制生成对抗样本标签的能力。同时，现有的文本对抗攻击方法主要依赖词汇替换操作来保持对抗样本与原始样本之间的语义相似性，这大大限制了对抗样本的搜索空间。为了解决这些问题，我们提出了一种新颖的针对黑盒设置的词汇-句法目标对抗攻击方法，称为LST2A。我们的方法涉及不同粒度级别的对抗扰动，即通过词汇替换操作在词汇级别进行扰动，以及通过重写样本的句法在句法级别进行扰动。具体来说，我们首先将整个文本嵌入到掩码语言模型的嵌入层中，然后在隐藏状态中优化词汇级别的扰动，以生成具有目标标签的对抗样本。对于在较高语义相似度阈值下仅通过词汇级别扰动难以成功攻击的样本，我们利用大型语言模型（LLM）引入句法级别的扰动，使它们更容易受到受害者模型决策边界的影响。随后，我们重新优化这些易受攻击样本的词汇级别扰动。大量的实验和人工评估表明，我们提出的方法始终优于最先进的基线方法，生成的对抗样本更流畅、语法更正确。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LST2A:+Lexical-Syntactic+Targeted+Adversarial+Attack+for+Texts)|0|
|[MTSCI: A Conditional Diffusion Model for Multivariate Time Series Consistent Imputation](https://doi.org/10.1145/3627673.3679532)|Jianping Zhou, Junhao Li, Guanjie Zheng, Xinbing Wang, Chenghu Zhou||Missing values are prevalent in multivariate time series, compromising the integrity of analyses and degrading the performance of downstream tasks. Consequently, research has focused on multivariate time series imputation, aiming to accurately impute the missing values based on available observations. A key research question is how to ensure imputation consistency, i.e., intra-consistency between observed and imputed values, and inter-consistency between adjacent windows after imputation. However, previous methods rely solely on the inductive bias of the imputation targets to guide the learning process, ignoring imputation consistency and ultimately resulting in poor performance. Diffusion models, known for their powerful generative abilities, prefer to generate consistent results based on available observations. Therefore, we propose a conditional diffusion model for Multivariate Time Series Consistent Imputation (MTSCI). Specifically, MTSCI employs a contrastive complementary mask to generate dual views during the forward noising process. Then, the intra contrastive loss is calculated to ensure intra-consistency between the imputed and observed values. Meanwhile, MTSCI utilizes a mixup mechanism to incorporate conditional information from adjacent windows during the denoising process, facilitating the inter-consistency between imputed samples. Extensive experiments on multiple real-world datasets demonstrate that our method achieves the state-of-the-art performance on multivariate time series imputation task under different missing scenarios. Code is available at https://github.com/JeremyChou28/MTSCI.|缺失值在多元时间序列中普遍存在，这会损害分析的完整性并降低下游任务的性能。因此，研究集中在多元时间序列插补上，旨在基于可用观测值准确插补缺失值。一个关键的研究问题是如何确保插补的一致性，即在插补后观测值和插补值之间的内部一致性，以及相邻窗口之间的相互一致性。然而，以往的方法仅依赖于插补目标的归纳偏差来指导学习过程，忽略了插补一致性，最终导致性能不佳。扩散模型以其强大的生成能力而闻名，更倾向于基于可用观测值生成一致的结果。因此，我们提出了一种用于多元时间序列一致性插补的条件扩散模型（MTSCI）。具体来说，MTSCI在前向加噪过程中使用对比互补掩码生成双视图。然后，计算内部对比损失以确保插补值和观测值之间的内部一致性。同时，MTSCI在去噪过程中利用混合机制结合相邻窗口的条件信息，促进插补样本之间的相互一致性。在多个真实世界数据集上的大量实验表明，我们的方法在不同缺失场景下的多元时间序列插补任务中实现了最先进的性能。代码可在https://github.com/JeremyChou28/MTSCI获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MTSCI:+A+Conditional+Diffusion+Model+for+Multivariate+Time+Series+Consistent+Imputation)|0|
|[Graph Anomaly Detection with Adaptive Node Mixup](https://doi.org/10.1145/3627673.3679577)|Qinghai Zhou, Yuzhong Chen, Zhe Xu, Yuhang Wu, Menghai Pan, Mahashweta Das, Hao Yang, Hanghang Tong|Visa Research, Foster City, CA, USA; University of Illinois at Urbana-Champaign, Champaign, IL, USA|Graph anomaly detection (GAD) aims to find network elements (e.g., nodes, edges) with significantly atypical patterns and has a profound impact in a variety of application domains, including social network analysis, security, Web, finance, and many more. Most of the existing methods have been developed in an unsupervised manner or with extremely limited supervision, due to the high cost of acquiring ground-truth information. Consequently, the identified anomalies may turn out to be noises or uneventful instances because of the lack of prior knowledge on graph anomalies. To address the data scarcity issue in GAD, in this paper, we propose, gADAM, a novel graph neural network-based GAD framework, which consolidates (1) an innovative mixup approach to augment the original training data by adaptively interpolating data instances in the embedding space, and (2) an efficacious sampling method to obtain high-quality negative samples for model training. Additionally, to advance the representation learning for GAD, we further equip the proposed framework with a generic prototype-based learning module. Through extensive empirical evaluations, we corroborate the superiority of the proposed gADAM framework on graph anomaly detection w.r.t. various metrics.|图异常检测（Graph Anomaly Detection, GAD）旨在发现网络中具有显著异常模式的元素（如节点、边），并在社交网络分析、安全、Web、金融等多个应用领域具有深远影响。由于获取真实标签信息的成本较高，现有方法大多以无监督或极有限监督的方式开发。因此，由于缺乏对图异常的先验知识，所识别的异常可能只是噪声或无意义的实例。为了解决GAD中的数据稀缺问题，本文提出了一种基于图神经网络的新型GAD框架——gADAM。该框架结合了以下两个关键创新点：（1）一种创新的混合方法，通过在嵌入空间中对数据实例进行自适应插值来增强原始训练数据；（2）一种有效的采样方法，用于获取高质量的负样本以支持模型训练。此外，为了进一步提升GAD中的表示学习能力，我们还为所提出的框架配备了一个通用的基于原型的学习模块。通过广泛的实验评估，我们验证了所提出的gADAM框架在图异常检测任务中的优越性，并在多种评价指标上表现出色。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Anomaly+Detection+with+Adaptive+Node+Mixup)|0|
|[REDI: Recurrent Diffusion Model for Probabilistic Time Series Forecasting](https://doi.org/10.1145/3627673.3679808)|Shiyang Zhou, Zehao Gu, Yun Xiong, Yang Luo, Qiang Wang, Xiaofeng Gao|; Shanghai Center for Meteorological Disaster Prevention Technology, Shanghai, China|Time series forecasting (TSF) consists of point prediction and probabilistic forecasting. Unlike point forecasting which predicts an expected value of a future target, probabilistic time series forecasting models the uncertainty in data by predicting the distribution of future values, which enhances decision-making flexibility and improves risk management. Traditional probabilistic forecasting methods usually assume a fixed distribution of data, which is not always true for time series. Recently, there have been efforts to adapt diffusion models for time series owing to their exceptional ability to model the distribution of data without prior assumptions. However, how to apply advantages of diffusion models to time series forecasting remains a substantial challenge due to specific issues in time series such as distribution drift and complex dynamic temporal patterns. In this paper, we focus on the adaptation of diffusion models for time series forecasting. We propose REDI, a recurrent diffusion model that achieves effective probabilistic time series prediction with recurrent forward diffusion process and step-aware guidance in backward denoising process. The recurrent forward diffusion process enables the model to pay more attention to the impact of recent history on future values during the diffusion process, while the step-aware guidance facilitates precise guidance based on historical information during the denoising process. We conduct experiments on 5 real-world datasets and achieve average rankings of 1.8 for deterministic metrics and 1.5 for probabilistic metrics across 12 baselines, which strongly demonstrates the effectiveness of REDI.|时间序列预测（TSF）包括点预测和概率预测。与点预测不同，点预测预测未来目标的期望值，而概率时间序列预测通过预测未来值的分布来建模数据中的不确定性，从而增强决策的灵活性并改善风险管理。传统的概率预测方法通常假设数据具有固定的分布，但这对于时间序列来说并不总是正确的。最近，由于扩散模型在建模数据分布方面的卓越能力而无需先验假设，人们开始尝试将其应用于时间序列。然而，由于时间序列中的特定问题，如分布漂移和复杂的动态时间模式，如何将扩散模型的优势应用于时间序列预测仍然是一个重大挑战。在本文中，我们专注于将扩散模型应用于时间序列预测。我们提出了REDI，一种递归扩散模型，通过递归前向扩散过程和后向去噪过程中的步骤感知指导，实现了有效的概率时间序列预测。递归前向扩散过程使模型在扩散过程中更加关注近期历史对未来值的影响，而步骤感知指导则有助于在去噪过程中基于历史信息进行精确指导。我们在5个真实世界的数据集上进行了实验，并在12个基线模型中取得了确定性指标平均排名1.8和概率指标平均排名1.5的成绩，这有力地证明了REDI的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=REDI:+Recurrent+Diffusion+Model+for+Probabilistic+Time+Series+Forecasting)|0|
|[Scalable Transformer for High Dimensional Multivariate Time Series Forecasting](https://doi.org/10.1145/3627673.3679757)|Xin Zhou, Weiqing Wang, Wray L. Buntine, Shilin Qu, Abishek Sriramulu, Weicong Tan, Christoph Bergmeir||Deep models for Multivariate Time Series (MTS) forecasting have recently demonstrated significant success. Channel-dependent models capture complex dependencies that channel-independent models cannot capture. However, the number of channels in real-world applications outpaces the capabilities of existing channel-dependent models, and contrary to common expectations, some models underperform the channel-independent models in handling high-dimensional data, which raises questions about the performance of channel-dependent models. To address this, our study first investigates the reasons behind the suboptimal performance of these channel-dependent models on high-dimensional MTS data. Our analysis reveals that two primary issues lie in the introduced noise from unrelated series that increases the difficulty of capturing the crucial inter-channel dependencies, and challenges in training strategies due to high-dimensional data. To address these issues, we propose STHD, the Scalable Transformer for High-Dimensional Multivariate Time Series Forecasting. STHD has three components: a) Relation Matrix Sparsity that limits the noise introduced and alleviates the memory issue; b) ReIndex applied as a training strategy to enable a more flexible batch size setting and increase the diversity of training data; and c) Transformer that handles 2-D inputs and captures channel dependencies. These components jointly enable STHD to manage the high-dimensional MTS while maintaining computational feasibility. Furthermore, experimental results show STHD's considerable improvement on three high-dimensional datasets: Crime-Chicago, Wiki-People, and Traffic. The source code and dataset are publicly available https://github.com/xinzzzhou/ScalableTransformer4HighDimensionMTSF.git.|近年来，深度模型在多变量时间序列（MTS）预测领域取得了显著成功。通道依赖模型能够捕捉通道独立模型无法捕捉的复杂依赖关系。然而，在实际应用中，通道数量的增长速度超过了现有通道依赖模型的能力，并且与普遍预期相反，某些模型在处理高维数据时表现不如通道独立模型，这引发了人们对通道依赖模型性能的质疑。为了解决这一问题，我们的研究首先探讨了这些通道依赖模型在高维MTS数据上表现不佳的原因。分析表明，两个主要问题在于：1）来自不相关序列的噪声增加了捕捉关键通道间依赖关系的难度；2）由于高维数据导致的训练策略挑战。为了解决这些问题，我们提出了STHD，即可扩展的高维多变量时间序列预测变换器。STHD包含三个组件：a）关系矩阵稀疏性，用于限制引入的噪声并缓解内存问题；b）ReIndex作为训练策略，能够实现更灵活的批量大小设置并增加训练数据的多样性；c）变换器，用于处理二维输入并捕捉通道依赖关系。这些组件共同使STHD能够在保持计算可行性的同时管理高维MTS。此外，实验结果表明，STHD在三个高维数据集（Crime-Chicago、Wiki-People和Traffic）上均有显著改进。源代码和数据集已公开，可在https://github.com/xinzzzhou/ScalableTransformer4HighDimensionMTSF.git获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+Transformer+for+High+Dimensional+Multivariate+Time+Series+Forecasting)|0|
|[Regularized Unconstrained Weakly Submodular Maximization](https://doi.org/10.1145/3627673.3679651)|Yanhui Zhu, Samik Basu, A. Pavan||Submodular optimization finds applications in machine learning and data mining. In this paper, we study the problem of maximizing functions of the form h = f-c, where f is a monotone, non-negative, weakly submodular set function and c is a modular function. We design a deterministic approximation algorithm that runs with O(n/ϵlogn/γϵ) oracle calls to function h, and outputs a set S such that h(S) ≥γ(1-ϵ)f(OPT)-c(OPT)-c(OPT)/γ(1-ϵ)logf(OPT)/c(OPT), where γ is the submodularity ratio of f. Existing algorithms for this problem either admit a worse approximation ratio or have quadratic runtime. We also present an approximation ratio of our algorithm for this problem with an approximate oracle of f. We validate our theoretical results through extensive empirical evaluations on real-world applications, including vertex cover and influence diffusion problems for submodular utility function f, and Bayesian A-Optimal design for weakly submodular f. Our experimental results demonstrate that our algorithms efficiently achieve high-quality solutions.|子模优化在机器学习和数据挖掘中有着广泛的应用。本文研究了形式为h = f - c的函数最大化问题，其中f是一个单调、非负、弱子模的集合函数，c是一个模函数。我们设计了一种确定性近似算法，该算法运行过程中对函数h进行了O(n/ϵ log n/γϵ)次查询调用，并输出一个集合S，使得h(S) ≥ γ(1-ϵ)f(OPT) - c(OPT) - c(OPT)/γ(1-ϵ) log f(OPT)/c(OPT)，其中γ是f的子模比率。现有的解决该问题的算法要么具有较差的近似比，要么具有二次运行时间。我们还展示了我们的算法在f的近似查询下的近似比。我们通过在真实世界的应用中进行广泛的实证评估来验证我们的理论结果，包括子模效用函数f的顶点覆盖和影响扩散问题，以及弱子模f的贝叶斯A-最优设计。我们的实验结果表明，我们的算法能够高效地获得高质量的解决方案。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Regularized+Unconstrained+Weakly+Submodular+Maximization)|0|
|[PRISM: Mitigating EHR Data Sparsity via Learning from Missing Feature Calibrated Prototype Patient Representations](https://doi.org/10.1145/3627673.3679521)|Yinghao Zhu, Zixiang Wang, Long He, Shiyun Xie, Xiaochen Zheng, Liantao Ma, Chengwei Pan|Beihang University & Peking University, Beijing, China; Beihang University, Beijing, China; Peking Univeristy, Beijing, China; Peking University, Beijing, China; ETH Zürich, Zürich, Switzerland; Beihang University & Zhongguancun Laboratory, Beijing, China; Tsinghua University, Beijing, China|Electronic Health Records (EHRs) provide valuable patient data but often suffer from sparsity issue, posing significant challenges in predictive modeling. Conventional imputation methods inadequately distinguish between real and imputed data, leading to potential inaccuracies of patient representations. To address these issues, we introduce PRISM, a framework that indirectly imputes data through prototype representations of similar patients, thus ensuring denser and more accurate embeddings. PRISM also includes a feature confidence learner module, which evaluates the reliability of each feature considering missing statuses. Additionally, it incorporates a new patient similarity metric that accounts for feature confidence, avoiding overreliance on imprecise imputed values. Our extensive experiments on the MIMIC-III, MIMIC-IV, PhysioNet Challenge 2012, eICU datasets demonstrate PRISM's superior performance in predicting in-hospital mortality and 30-day readmission tasks, showcasing its effectiveness in handling EHR data sparsity. For the sake of reproducibility and further research, we have publicly released the code at https://github.com/yhzhu99/PRISM.|电子健康记录（EHRs）提供了宝贵的患者数据，但常常面临稀疏性问题，这对预测建模提出了重大挑战。传统的插补方法无法有效区分真实数据和插补数据，可能导致患者表示的不准确性。为了解决这些问题，我们提出了PRISM框架，该框架通过相似患者的原型表示间接插补数据，从而确保生成更密集且更准确的嵌入。PRISM还包含一个特征置信度学习器模块，该模块评估每个特征在考虑缺失状态下的可靠性。此外，PRISM引入了一种新的患者相似性度量方法，该方法考虑了特征置信度，避免了对不精确插补值的过度依赖。我们在MIMIC-III、MIMIC-IV、PhysioNet Challenge 2012和eICU数据集上进行了广泛的实验，结果表明PRISM在预测住院死亡率和30天再入院任务中表现出色，展示了其在处理EHR数据稀疏性方面的有效性。为了促进可重复性和进一步研究，我们已在https://github.com/yhzhu99/PRISM上公开了代码。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PRISM:+Mitigating+EHR+Data+Sparsity+via+Learning+from+Missing+Feature+Calibrated+Prototype+Patient+Representations)|0|
|[L-APPLE: Language-agnostic Prototype Prefix Learning for Cross-lingual Event Detection](https://doi.org/10.1145/3627673.3679769)|Ziqin Zhu, Xutan Peng, Qian Li, Cheng Ji, Qingyun Sun, Jianxin Li|Department of Computer Science, University of Sheffield, Sheffield, United Kingdom; Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science and Engineering, BDBC, Beihang University, Beijing, China|Cross-lingual event detection (CLED) is a challenging information extraction task in which a model is trained in one language and evaluated in another. Most recent methods attack CLED by aligning source and target language representations based on fine-tuning multilingual pre-trained language models. However, they need to modify all the model parameters and store a complete copy for each source-target language pair, which is resource-intensive and requires significant memory. In contrast, prefix-tuning is a more lightweight alternative, but it relies solely on the labeled source language data during training, limiting its performance. To address the above problems, we propose a novel framework for CLED with Language-agnostic Prototypical Prefix-Learning (L-APPLE), which can integrate language-agnostic event information with prefix-tuning. In detail, inspired by vanilla prompt methods, L-APPLE divides the prefix into two parts: one optimized as continuous word embeddings while the other generated with cross-lingual aligned event prototypes. Meanwhile, we employ language alignment with contrastive learning to acquire cross-lingual aligned event prototypes, and finally, parameters are optimized using both task and alignment loss. The evaluation of public CLED benchmarks demonstrates that L-APPLE achieves significant improvements in CLED with only less than 0.1% of the parameters optimized compared to previous fine-tuning methods.|跨语言事件检测（Cross-lingual Event Detection, CLED）是一项具有挑战性的信息抽取任务，其目标是在一种语言上训练模型，并在另一种语言上进行评估。最近的方法主要通过基于微调的多语言预训练语言模型来对齐源语言和目标语言的表示，从而解决CLED问题。然而，这些方法需要修改所有模型参数，并为每个源-目标语言对存储完整的模型副本，这不仅资源消耗大，而且需要大量的内存。相比之下，前缀调优（prefix-tuning）是一种更为轻量化的替代方案，但其在训练过程中仅依赖于标注的源语言数据，限制了其性能。

为了解决上述问题，我们提出了一种新颖的跨语言事件检测框架——**语言无关的原型前缀学习（Language-agnostic Prototypical Prefix-Learning, L-APPLE）**，该框架能够将语言无关的事件信息与前缀调优相结合。具体而言，受到经典提示学习（prompt learning）方法的启发，L-APPLE将前缀分为两部分：一部分作为连续的词嵌入进行优化，另一部分则通过跨语言对齐的事件原型生成。同时，我们利用对比学习进行语言对齐，以获得跨语言对齐的事件原型，并通过任务损失和对齐损失共同优化参数。在公开的CLED基准测试中，L-APPLE仅优化了不到0.1%的参数，却显著提升了跨语言事件检测的性能，优于以往的微调方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=L-APPLE:+Language-agnostic+Prototype+Prefix+Learning+for+Cross-lingual+Event+Detection)|0|
|[MV-BART: Multi-view BART for Multi-modal Sarcasm Detection](https://doi.org/10.1145/3627673.3679570)|Xingjie Zhuang, Fengling Zhou, Zhixin Li||Understanding emotions in dialogue is an essential part of human communication, its an extremely complex cognitive process involving cross-modal interactions and cross-emotional associations, and multimodal sarcasm detection is an emerging but challenging research task in this process aiming at video discourse incorporating appropriate contextual information and external knowledge and identifying sarcasm by understanding both verbal and non-verbal components. However, existing research primarily focuses on constructing multimodal fusion representations and capturing incongruity between modalities as indicative cues for recognizing sarcasm, which relies on a fixed network design architecture that is difficult to cope with complex and diverse satirical scenarios in real life. As humans, we rely on the combination of visual and auditory cues, such as facial expressions and intonations, to understand information. Our brains are implicitly trained to integrate information from multiple senses to form a comprehensive understanding of conveyed messages, a process known as multi-sensory integration. The combination of different modalities not only provides additional information but also amplifies the information conveyed by each modality relative to others. Therefore, dynamic variations in the weights of different modalities play a crucial role in multi-modal understanding. From this perspective, we propose a new framework called Multi-view BART(MV-BART), which is capable of exploiting multi-granularity cues from multiple viewpoints and dynamically adjusting the view weights, applied to different sarcastic scenarios. It is worth mentioning that we analyze the proposed framework by testing it on several benchmark datasets, and the results outperform the existing state-of-the-art.|理解对话中的情感是人类交流的重要组成部分，这是一个极其复杂的认知过程，涉及跨模态交互和跨情感关联。多模态讽刺检测是这一过程中新兴但具有挑战性的研究任务，旨在通过整合适当的上下文信息和外部知识，理解视频话语中的语言和非语言成分来识别讽刺。然而，现有研究主要集中在构建多模态融合表示和捕捉模态间的不一致性作为识别讽刺的指示线索，这依赖于固定的网络设计架构，难以应对现实生活中复杂多样的讽刺场景。作为人类，我们依赖于视觉和听觉线索（如面部表情和语调）的组合来理解信息。我们的大脑被隐式训练以整合来自多种感官的信息，从而形成对传达信息的全面理解，这一过程被称为多感官整合。不同模态的组合不仅提供了额外的信息，还放大了每个模态相对于其他模态所传达的信息。因此，不同模态权重的动态变化在多模态理解中起着至关重要的作用。基于这一视角，我们提出了一个名为多视图BART（MV-BART）的新框架，该框架能够从多个视点利用多粒度线索并动态调整视图权重，适用于不同的讽刺场景。值得一提的是，我们通过在多个基准数据集上测试所提出的框架进行分析，结果优于现有的最先进方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MV-BART:+Multi-view+BART+for+Multi-modal+Sarcasm+Detection)|0|
|[Enhancing Event Detection with Inter-Event Dependencies in Large Ontologies](https://doi.org/10.1145/3627673.3679915)|Samireh Abdi|Azad University, Sanandaj, Iran|Event Detection (ED), a crucial component of comprehensive text analysis tools, is a well-established task within the fields of Natural Language Processing (NLP) and Information Extraction (IE). Current state-of-the-art models for ED primarily focus on identifying a limited set of predefined event types. Recently, the challenge of detecting a broad array of predefined event types has garnered increasing interest within the IE community. However, a significant gap in existing research on ED with extensive ontologies is the inadequate exploration of how interactions between event types affect ED model performance. One of the hindrances for this purpose is the lack of resources to encode event-event dependencies for large ontologies. This study introduces a novel approach that leverages existing inter-event dependency resources to provide this information for extensive ontologies. Specifically, a solution based on Optimal Transport is proposed to map event-event dependency from existing resources to a large ontology. We conduct extensive experiments on multiple benchmark datasets to assess the effectiveness of our approach. Our findings, supported by a thorough analysis, demonstrate that this innovative technique significantly enhances the performance of ED models, especially for ontologies with a large number of event types.|事件检测（Event Detection, ED）作为全面文本分析工具的重要组成部分，是自然语言处理（Natural Language Processing, NLP）和信息抽取（Information Extraction, IE）领域中一个成熟的任务。当前最先进的ED模型主要集中于识别一组有限的预定义事件类型。最近，检测广泛预定义事件类型的挑战在IE社区中引起了越来越多的关注。然而，现有关于使用广泛本体论的ED研究中的一个显著空白是，对事件类型之间相互作用如何影响ED模型性能的探索不足。实现这一目标的一个障碍是缺乏编码大规模本体论中事件-事件依赖关系的资源。本研究引入了一种新颖的方法，利用现有的事件间依赖资源为广泛的本体论提供这些信息。具体而言，提出了一种基于最优传输（Optimal Transport）的解决方案，将现有资源中的事件-事件依赖关系映射到一个大规模本体论中。我们在多个基准数据集上进行了广泛的实验，以评估我们方法的有效性。通过深入分析支持的研究结果表明，这一创新技术显著提升了ED模型的性能，尤其是对于具有大量事件类型的本体论。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Event+Detection+with+Inter-Event+Dependencies+in+Large+Ontologies)|0|
|[COSCO: A Sharpness-Aware Training Framework for Few-shot Multivariate Time Series Classification](https://doi.org/10.1145/3627673.3679891)|Jesus Barreda, Ashley Gomez, Ruben Puga, Kaixiong Zhou, Li Zhang||Multivariate time series classification is an important task with widespread domains of applications. Recently, deep neural networks (DNN) have achieved state-of-the-art performance in time series classification. However, they often require large expert-labeled training datasets which can be infeasible in practice. In few-shot settings, i.e. only a limited number of samples per class are available in training data, DNNs show a significant drop in testing accuracy and poor generalization ability. In this paper, we propose to address these problems from an optimization and a loss function perspective. Specifically, we propose a new learning framework named COSCO consisting of a sharpness-aware minimization (SAM) optimization and a Prototypical loss function to improve the generalization ability of DNN for multivariate time series classification problems under few-shot setting. Our experiments demonstrate our proposed method outperforms the existing baseline methods. Our source code is available at: https://github.com/JRB9/COSCO.|多元时间序列分类是一项重要的任务，具有广泛的应用领域。近年来，深度神经网络（DNN）在时间序列分类中取得了最先进的性能。然而，这些方法通常需要大量专家标注的训练数据集，这在实际中可能是不可行的。在少样本设置中，即训练数据中每类只有有限的样本可用时，DNN在测试准确率和泛化能力方面表现出显著的下降。本文从优化和损失函数的角度提出解决这些问题的方法。具体而言，我们提出了一个名为COSCO的新学习框架，该框架结合了锐度感知最小化（SAM）优化和原型损失函数，以提高DNN在少样本设置下对多元时间序列分类问题的泛化能力。我们的实验表明，所提出的方法优于现有的基线方法。我们的源代码可在以下网址获取：https://github.com/JRB9/COSCO。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=COSCO:+A+Sharpness-Aware+Training+Framework+for+Few-shot+Multivariate+Time+Series+Classification)|0|
|[Accurate Path Prediction of Provenance Traces](https://doi.org/10.1145/3627673.3679872)|Raza Ahmad, HeeYoung Jung, Yuta Nakamura, Tanu Malik|DePaul University, Chicago, Illinois, USA; The University of Chicago, Chicago, Illinois, USA|Several security and workflow applications require provenance information at the operating system level for diagnostics. The resulting provenance traces are often more informative if they are efficiently mapped to execution paths within the control flow graph. However, current provenance systems do not map traces to control flow graphs for diagnostics purposes due to the computational complexity of mapping traces to graphs. We formulate the path prediction problem for provenance traces and take a machine learning approach to solve the problem. We develop a transformer-based graph convolutional network to predict paths. Our experiments demonstrate that our machine learning model achieves more than twice the accuracy on average compared to simple probabilistic models, with an increased computation time trade-off.|多个安全和流程应用需要操作系统层面的溯源信息来进行诊断。如果能够有效地将这些溯源轨迹映射到控制流图中的执行路径，所得出的溯源轨迹通常会更具信息量。然而，由于将轨迹映射到图的计算复杂性，当前的溯源系统并未将轨迹映射到控制流图以用于诊断目的。我们针对溯源轨迹提出了路径预测问题，并采用机器学习方法来解决该问题。我们开发了一种基于Transformer的图卷积网络来预测路径。我们的实验表明，与简单的概率模型相比，我们的机器学习模型平均准确率提高了一倍以上，但计算时间有所增加。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Accurate+Path+Prediction+of+Provenance+Traces)|0|
|[Fractional Budget Allocation for Influence Maximization under General Marketing Strategies](https://doi.org/10.1145/3627673.3679929)|Akhil Bhimaraju, Eliot W. Robson, Lav R. Varshney, Abhishek K. Umrawal||We consider the fractional influence maximization problem, i.e., identifying users on a social network to be incentivized with potentially partial discounts to maximize the influence on the network. The larger the discount given to a user, the higher the likelihood of its activation (adopting a new product or innovation), who then attempts to activate its neighboring users, causing a cascade effect of influence through the network. Our goal is to devise efficient algorithms that assign initial discounts to the network's users to maximize the total number of activated users at the end of the cascade, subject to a constraint on the total sum of discounts given. In general, the activation likelihood could be any non-decreasing function of the discount, whereas, our focus lies on the case when the activation likelihood is an affine function of the discount, potentially varying across different users. As this problem is shown to be NP-hard, we propose and analyze an efficient (1-1/e)-approximation algorithm. Furthermore, we run experiments on real-world social networks to show the performance and scalability of our method.|我们考虑分数影响力最大化问题，即在社交网络上识别用户并给予潜在的部分折扣激励，以最大化网络上的影响力。给予用户的折扣越大，其激活（采用新产品或创新）的可能性越高，激活后的用户会尝试激活其邻近用户，从而通过网络产生级联效应。我们的目标是设计高效的算法，为网络用户分配初始折扣，以在给定总折扣约束的条件下，最大化级联结束时激活的用户总数。通常情况下，激活概率可以是折扣的任何非递减函数，而我们的研究重点在于激活概率是折扣的仿射函数且可能因用户而异的情况。由于该问题被证明是NP难问题，我们提出并分析了一种高效的(1-1/e)近似算法。此外，我们在真实世界的社交网络上进行了实验，以展示我们方法的性能和可扩展性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fractional+Budget+Allocation+for+Influence+Maximization+under+General+Marketing+Strategies)|0|
|[IEcons: A New Consensus Approach Using Multi-Text Representations for Clustering Task](https://doi.org/10.1145/3627673.3679941)|Karima Boutalbi, Rafika Boutalbi, Hervé Verjus, Kavé Salamatian, David Telisson, Olivier Le Van|LIS Lab, Aix-Marseille University, Marseille, France; Université Savoie Mont Blanc & Cegedim Business Services, Annecy, France; Cegedim Business Services, Lyon, France; Université Savoie Mont Blanc, Annecy, France|Today we are able to generate a large set of text representations from the simple Bag-of-word (BOW) to the recent transformers capturing the semantic and the contextual text meaning. It was proven that there is no best text representation for text clustering task. Consequently, some works combined text representations using a consensus clustering approach. Two consensus approach types exist, namely explicit and implicit consensus. In the explicit consensus, also known asensemble clustering, the consensus function is applied a posterior after obtaining cluster labels from each text representation clustering allowing to capture global mutual information between the partitions of all text representations. On the other hand, implicit consensus uses tensor clustering to optimize the clustering consensus partition that deals with similarity matrices of text representations. In this paper, we propose a new consensus text clustering algorithm named IEcons (Implicit-Explicit consensus) that optimizes explicit and implicit consensus clustering simultaneously through text embeddings and tensor representation of texts through similarity matrices. We compare our algorithm with others from the literature on five different textual datasets using several algorithm performance criteria. The comparison results reveal that our algorithm best suits most situations.|如今，我们能够生成从简单的词袋模型（Bag-of-Word, BOW）到最新的捕捉语义和上下文文本含义的Transformer模型的大量文本表示方法。已有研究证明，在文本聚类任务中并不存在一种最佳的文本表示方法。因此，一些研究通过共识聚类方法将多种文本表示结合起来。共识聚类方法主要分为两种类型：显式共识和隐式共识。显式共识，也称为集成聚类，其共识函数是在从每种文本表示聚类中获得聚类标签后，通过后验方式应用的，从而捕捉所有文本表示分区之间的全局互信息。另一方面，隐式共识则使用张量聚类来优化处理文本表示相似性矩阵的聚类共识分区。

在本文中，我们提出了一种名为IEcons（隐式-显式共识）的新共识文本聚类算法，该算法通过文本嵌入和基于相似性矩阵的文本张量表示，同时优化显式和隐式共识聚类。我们使用多个算法性能标准，在五个不同文本数据集上将我们的算法与文献中的其他算法进行了比较。比较结果表明，我们的算法在大多数情况下表现最佳。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=IEcons:+A+New+Consensus+Approach+Using+Multi-Text+Representations+for+Clustering+Task)|0|
|[Scalable Unsupervised Feature Selection with Reconstruction Error Guarantees via QMR Decomposition](https://doi.org/10.1145/3627673.3679994)|Ciwan Ceylan, Kambiz Ghoorchian, Danica Kragic|KTH Royal Institute of Technology, Stockholm, Sweden; SEB Group, Stockholm, Sweden|Unsupervised feature selection (UFS) methods have garnered significant attention for their capability to eliminate redundant features without relying on class label information. However, their scalability to large datasets remains a challenge, rendering common UFS methods impractical for such applications. To address this issue, we introduce QMR-FS, a greedy forward filtering approach that selects linearly independent features up to a specified relative tolerance, ensuring that any excluded features can be reconstructed from the retained set within this tolerance. This is achieved through the QMR matrix decomposition, which builds upon the well-known QR decomposition. QMR-FS benefits from linear complexity relative to the number of instances and boasts exceptional performance due to its ability to leverage parallelized computation on both CPU and GPU. Despite its greedy nature, QMR-FS achieves comparable classification and clustering accuracies across multiple datasets when compared to other UFS methods, while achieving runtimes approximately 10 times faster than recently proposed scalable UFS methods for datasets ranging from 100 million to 1 billion elements.|无监督特征选择（UFS）方法因其能够在无需依赖类别标签信息的情况下消除冗余特征而受到了广泛关注。然而，这些方法在大规模数据集上的可扩展性仍然是一个挑战，使得常见的UFS方法在此类应用中显得不切实际。为了解决这一问题，我们提出了QMR-FS，这是一种贪婪的前向过滤方法，它选择达到指定相对容差的线性独立特征，确保任何被排除的特征都可以在保留的特征集内以该容差进行重建。这一目标通过QMR矩阵分解实现，该分解基于著名的QR分解。QMR-FS具有相对于实例数量的线性复杂度，并且由于能够在CPU和GPU上利用并行计算，其性能表现极为出色。尽管QMR-FS是一种贪婪算法，但在多个数据集上，与其他UFS方法相比，它在分类和聚类精度上表现相当，同时在处理包含1亿到10亿个元素的数据集时，其运行时间比最近提出的可扩展UFS方法快了约10倍。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+Unsupervised+Feature+Selection+with+Reconstruction+Error+Guarantees+via+QMR+Decomposition)|0|
|[End-to-End Aspect Based Sentiment Analysis Using Graph Attention Network](https://doi.org/10.1145/3627673.3679910)|Abir Chakraborty|Microsoft, Redmond, WA, USA|In this work we investigate the capability of Graph Attention Network for extracting aspect and opinion terms. Aspect and opinion term extraction is posed as a token-level classification task akin to named entity recognition. We use the dependency tree of the input query as additional feature in a Graph Attention Network along with the token and part-of-speech features. We show that the dependency structure is a powerful feature that in the presence of a CRF layer substantially improves the performance and generates the best result on the commonly used datasets from SemEval 2014, 2015 and 2016. We experiment with additional layers like BiLSTM and Transformer in addition to the CRF layer. We also show that our approach works well in the presence of multiple aspects or sentiments in the same query and it is not necessary to modify the dependency tree based on a single aspect as was the original application for sentiment classification.|在本研究中，我们探讨了图注意力网络（Graph Attention Network, GAT）在提取方面词和观点词方面的能力。方面词和观点词的提取被形式化为一个类似于命名实体识别的词元级分类任务。我们利用输入查询的依存树作为图注意力网络中的附加特征，同时结合词元和词性特征。研究表明，依存结构是一个强有力的特征，在条件随机场（CRF）层的辅助下，显著提升了模型性能，并在SemEval 2014、2015和2016的常用数据集上取得了最佳结果。除了CRF层外，我们还实验了双向长短期记忆网络（BiLSTM）和Transformer等附加层。此外，我们还展示了该方法在同一个查询中存在多个方面或情感时依然表现良好，并且无需像最初的情感分类应用那样基于单一方面调整依存树。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=End-to-End+Aspect+Based+Sentiment+Analysis+Using+Graph+Attention+Network)|0|
|[Deep Noise-Aware Quality Loss for Speaker Verification](https://doi.org/10.1145/3627673.3679895)|Pantid Chantangphol, Theerat Sakdejayont, Monchai Lertsutthiwong, Tawunrat Chalothorn|Kasikorn Labs, Kasikorn Business-Technology Group, Nonthaburi, Thailand|This paper addresses the common challenge of system performance degradation due to speech inconsistency and mismatched acoustic conditions across various domains in speaker verification tasks. We propose a Noise-Aware Quality Network designed to estimate a score based on speech quality and the presence of speech obscured by noise in real-world environments. The score, derived from the normalization of estimated speech quality evaluations, is incorporated into a proposed Noise-Aware Quality loss function, aiming to prioritize speech quality by weighting the embedding distances based on the quality score. Our methodology significantly improves speaker verification performance, particularly in noisy environments. Furthermore, our work highlights the importance of speech quality and the potential benefits of incorporating speech quality weight into the loss function for speaker verification tasks.|本文针对说话人验证任务中，由于语音不一致性和跨领域声学条件不匹配导致的系统性能下降这一普遍挑战，提出了一种噪声感知质量网络。该网络旨在基于语音质量和现实环境中被噪声掩盖的语音存在情况，估计一个得分。该得分源自于估计语音质量评估的归一化，并被纳入到我们提出的噪声感知质量损失函数中，旨在通过根据质量得分对嵌入距离进行加权，从而优先考虑语音质量。我们的方法显著提高了说话人验证的性能，特别是在噪声环境中。此外，我们的工作强调了语音质量的重要性，以及在说话人验证任务中将语音质量权重纳入损失函数的潜在优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Noise-Aware+Quality+Loss+for+Speaker+Verification)|0|
|[Empowering LLMs for Multi-Page Layout Generation via Consistency-Oriented In-Context Learning](https://doi.org/10.1145/3627673.3679908)|Mengyao Chen, Xinghua Zhang, Junhao Zhang, Quangang Li, Tingwen Liu|; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China|Document layout generation, a burgeoning field of document intelligence, entails positioning and sizing various elements within given constraints. While significant strides have been made in single-page layout generation, real-world documents predominantly span multiple pages, and exploring multi-page layout generation methods has also become the key to meeting the contemporary dramatically increased document processing demands. Despite the promise of leveraging large language models (LLMs) like GPT-4 for their powerful in-context learning abilities, the task transition to multi-page layouts, which contains considerably complex data, presents formidable challenges including excessively long prompts and strict consistency between pages. To this end, we propose a novel framework called Multi-Page Layout Generation via Consistency-Oriented modeling (MuLCO) that capitalizes on in-context learning of LLMs without the need for training or fine-tuning. MuLCO employs three key components: serialization based on code blocks maps intricate document layouts to code-style exemplars, self-correcting reasoning hint decomposes the complex generation task into numerous steps to improve reasoning interpretability, and consistency-oriented multi-round generation predicts coherent multi-page layouts in form of a continuous dialogue. To summarize, we contribute by proposing MuLCO and developing a task-specific dataset and evaluation mechanism. Extensive experiments validate the effectiveness of the MuLCO framework for multi-page layout generation.|文档布局生成是文档智能领域中一个新兴的研究方向，其核心在于在给定约束条件下对文档中的各种元素进行定位和尺寸调整。尽管单页布局生成已经取得了显著进展，但现实世界中的文档大多跨越多个页面，因此探索多页布局生成方法也成为满足当今急剧增长的文档处理需求的关键。尽管利用像GPT-4这样的大型语言模型（LLMs）的强大上下文学习能力具有广阔前景，但将任务扩展到包含极其复杂数据的多页布局生成仍面临巨大挑战，包括过长的提示词和页面之间的严格一致性要求。为此，我们提出了一种名为**基于一致性建模的多页布局生成框架（MuLCO）**的新方法，该框架充分利用了LLMs的上下文学习能力，而无需进行训练或微调。MuLCO包含三个关键组件：基于代码块的序列化将复杂的文档布局映射为代码风格的示例，自校正推理提示将复杂的生成任务分解为多个步骤以提高推理的可解释性，而面向一致性的多轮生成则以连续对话的形式预测连贯的多页布局。总结而言，我们的贡献在于提出了MuLCO框架，并开发了针对该任务的专用数据集和评估机制。大量实验验证了MuLCO框架在多页布局生成中的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Empowering+LLMs+for+Multi-Page+Layout+Generation+via+Consistency-Oriented+In-Context+Learning)|0|
|[CMG: A Causality-enhanced Multi-view Graph Model for Stock Trend Prediction](https://doi.org/10.1145/3627673.3679886)|Xi Cheng, Liang Wang, Yunan Zeng, Qiang Liu|NLPR, CASIA, Beijing, China|The stock trend prediction problem refers to forecasting future stock price trends. In recent years, some methods discovered causal relations between stocks to address this problem. However, traditional causal discovery methods face unique challenges in the stock market, as they fail to uncover accurate causal relationships when a distribution shift happens in stock. Additionally, current methods also overlook the commonalities and differences between stock relations. To address these shortcomings, we propose a causal-enhanced multi-view temporal graph model, named CMG. This method explores comprehensive causal relations by incorporating distribution shift confounder and constructs a multi-view contrastive learning module to unearth the commonalities and differences between stock relations, thereby enabling more accurate stock trend predictions. Further experimental results and investment simulations demonstrate the effectiveness and profitability of CMG.|股票趋势预测问题指的是对未来股票价格走势进行预测。近年来，一些方法通过发现股票之间的因果关系来解决这一问题。然而，传统的因果发现方法在股票市场中面临独特的挑战，因为当股票发生分布偏移时，它们无法揭示准确的因果关系。此外，现有方法也忽视了股票关系之间的共性和差异。针对这些不足，我们提出了一种因果增强的多视图时序图模型，命名为CMG。该方法通过引入分布偏移混杂因子来探索全面的因果关系，并构建了一个多视图对比学习模块来挖掘股票关系之间的共性和差异，从而实现更准确的股票趋势预测。进一步的实验结果和投资模拟验证了CMG的有效性和盈利能力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CMG:+A+Causality-enhanced+Multi-view+Graph+Model+for+Stock+Trend+Prediction)|0|
|[MSG-Chart: Multimodal Scene Graph for ChartQA](https://doi.org/10.1145/3627673.3679967)|Yue Dai, Soyeon Caren Han, Wei Liu||Automatic Chart Question Answering (ChartQA) is challenging due to the complex distribution of chart elements with patterns of the underlying data not explicitly displayed in charts. To address this challenge, we design a joint multimodal scene graph for charts to explicitly represent the relationships between chart elements and their patterns. Our proposed multimodal scene graph includes a visual graph and a textual graph to jointly capture the structural and semantical knowledge from the chart. This graph module can be easily integrated with different vision transformers as inductive bias. Our experiments demonstrate that incorporating the proposed graph module enhances the understanding of charts' elements' structure and semantics, thereby improving performance on publicly available benchmarks, ChartQA and OpenCQA.|自动图表问答（ChartQA）由于图表元素分布的复杂性以及图表中未明确显示的底层数据模式而具有挑战性。为了解决这一挑战，我们设计了一个联合多模态场景图来显式表示图表元素及其模式之间的关系。我们提出的多模态场景图包括视觉图和文本图，以共同捕捉图表中的结构和语义知识。该图模块可以轻松地与不同的视觉变换器集成，作为归纳偏差。我们的实验表明，结合所提出的图模块增强了对图表元素结构和语义的理解，从而在公开可用的基准测试ChartQA和OpenCQA上提高了性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MSG-Chart:+Multimodal+Scene+Graph+for+ChartQA)|0|
|[Quantifying Uncertainty in Neural Networks through Residuals](https://doi.org/10.1145/3627673.3679983)|Dalavai Udbhav Mallanna, Rini Smita Thakur, Rajeev Ranjan Dwivedi, Vinod K. Kurmi|IISER Bhopal, Bhopal, India|Regression models are of fundamental importance in explicitly explaining the response variable in terms of covariates. However, point predictions of these models limit them from many real world applications. Heteroscedasticity is common in most real-world scenarios and is hard to model due to its randomness. The Gaussian process generally captures epistemic (model) uncertainty but fails to capture heteroscedastic aleatoric uncertainty. The framework of HetGP inherently captures both epistemic and aleatoric by placing independent GP's priors on both mean function and error term. We propose the posthoc HetGP on the residuals of the trained deterministic neural network to obtain both epistemic and aleatoric uncertainty. The advantage of posthoc HetGP on residuals is that it can be extended to any type of model, since the model is assumed to be black-box that gives point predictions. We demonstrate our approach through simulation studies and UCI regression datasets. The code is available at https://visdomlab.github.io/HetGP/|回归模型在通过协变量明确解释响应变量方面具有基础重要性。然而，这些模型的点预测限制了它们在许多现实世界应用中的使用。异方差性在大多数现实场景中普遍存在，由于其随机性而难以建模。高斯过程通常捕捉认知（模型）不确定性，但无法捕捉异方差的随机不确定性。HetGP框架通过在均值函数和误差项上放置独立的高斯过程先验，固有地捕捉了认知和随机不确定性。我们提出了在训练好的确定性神经网络的残差上应用后验HetGP，以获得认知和随机不确定性。在残差上应用后验HetGP的优势在于，它可以扩展到任何类型的模型，因为模型被假定为提供点预测的黑箱。我们通过模拟研究和UCI回归数据集展示了我们的方法。代码可在https://visdomlab.github.io/HetGP/获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quantifying+Uncertainty+in+Neural+Networks+through+Residuals)|0|
|[A Systematic Evaluation of Generated Time Series and Their Effects in Self-Supervised Pretraining](https://doi.org/10.1145/3627673.3679870)|Audrey Der, ChinChia Michael Yeh, Xin Dai, Huiyuan Chen, Yan Zheng, Yujie Fan, Zhongfang Zhuang, Vivian Lai, Junpeng Wang, Liang Wang, Wei Zhang, Eamonn J. Keogh||Self-supervised Pretrained Models (PTMs) have demonstrated remarkable performance in computer vision and natural language processing tasks. These successes have prompted researchers to design PTMs for time series data. In our experiments, most self-supervised time series PTMs were surpassed by simple supervised models. We hypothesize this undesired phenomenon may be caused by data scarcity. In response, we test six time series generation methods, use the generated data in pretraining in lieu of the real data, and examine the effects on classification performance. Our results indicate that replacing a real-data pretraining set with a greater volume of only generated samples produces noticeable improvement.|自监督预训练模型（PTMs）在计算机视觉和自然语言处理任务中展现了卓越的性能。这些成功促使研究人员为时间序列数据设计PTMs。在我们的实验中，大多数自监督时间序列PTMs被简单的监督模型超越。我们推测这一不良现象可能是由数据稀缺引起的。为此，我们测试了六种时间序列生成方法，使用生成的数据代替真实数据进行预训练，并考察其对分类性能的影响。我们的结果表明，用更大规模的仅生成样本替换真实数据预训练集，能带来显著的性能提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Systematic+Evaluation+of+Generated+Time+Series+and+Their+Effects+in+Self-Supervised+Pretraining)|0|
|[Quantum Inverse Contextual Vision Transformers (Q-ICVT): A New Frontier in 3D Object Detection for AVs](https://doi.org/10.1145/3627673.3679984)|Sanjay Bhargav Dharavath, Tanmoy Dam, Supriyo Chakraborty, Prithwiraj Roy, Aniruddha Maiti||The field of autonomous vehicles (AVs) predominantly leverages multi-modal integration of LiDAR and camera data to achieve better performance compared to using a single modality. However, the fusion process encounters challenges in detecting distant objects due to the disparity between the high resolution of cameras and the sparse data from LiDAR. Insufficient integration of global perspectives with local-level details results in sub-optimal fusion performance.To address this issue, we have developed an innovative two-stage fusion process called Quantum Inverse Contextual Vision Transformers (Q-ICVT). This approach leverages adiabatic computing in quantum concepts to create a novel reversible vision transformer known as the Global Adiabatic Transformer (GAT). GAT aggregates sparse LiDAR features with semantic features in dense images for cross-modal integration in a global form. Additionally, the Sparse Expert of Local Fusion (SELF) module maps the sparse LiDAR 3D proposals and encodes position information of the raw point cloud onto the dense camera feature space using a gating point fusion approach. Our experiments show that Q-ICVT achieves an mAPH of 82.54 for L2 difficulties on the Waymo dataset, improving by 1.88 analyze GAT and SELF in ablation studies to highlight the impact of Q-ICVT. Our code is available at https://github.com/sanjay-810/Qicvt Q-ICVT|自动驾驶领域（AVs）主要利用激光雷达（LiDAR）和摄像头数据的多模态集成，以取得比单一模态更好的性能。然而，由于摄像头的高分辨率与激光雷达稀疏数据之间的差异，融合过程在检测远距离物体时面临挑战。全局视角与局部细节的整合不足导致融合性能不佳。为解决这一问题，我们开发了一种创新的两阶段融合过程，称为量子逆上下文视觉变换器（Q-ICVT）。该方法利用量子概念中的绝热计算，创建了一种新颖的可逆视觉变换器，称为全局绝热变换器（GAT）。GAT将稀疏的激光雷达特征与密集图像中的语义特征聚合，以全局形式进行跨模态集成。此外，局部融合稀疏专家（SELF）模块通过门控点融合方法，将稀疏的激光雷达3D提议映射并编码原始点云的位置信息到密集摄像头特征空间中。我们的实验表明，Q-ICVT在Waymo数据集上对L2难度的mAPH达到了82.54，提高了1.88。我们在消融研究中分析了GAT和SELF，以突出Q-ICVT的影响。我们的代码可在https://github.com/sanjay-810/Qicvt Q-ICVT获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quantum+Inverse+Contextual+Vision+Transformers+(Q-ICVT):+A+New+Frontier+in+3D+Object+Detection+for+AVs)|0|
|[Efficient Global Message Passing for Heterophilous Graphs](https://doi.org/10.1145/3627673.3679907)|Yanfei Dong, Mohammed Haroon Dupty, Lambert Deng, Yong Liang Goh, Wee Sun Lee|National University of Singapore, Singapore, Singapore; Independent, Singapore, Singapore|We investigate Graph Neural Networks (GNNs) on heterophilous graphs for node classification. To address the scarcity of useful local information in heterophilous neighborhood, it is often essential to explore global interactions. However, many existing methods in this endeavor are computationally expensive and may suffer from issues like oversquashing. In addition, earlier studies show that GNNs can be outperformed by Multi-Layer Perceptrons on heterophilous graphs, indicating insufficient exploitation of node feature information. To address these limitations, we propose Prototype Mediated GNN (PM-GNN), a novel framework which efficiently captures global feature information using class prototypes. PM-GNN learns multiple class prototypes for each class from raw node features with a soft k-means clustering mechanism. These prototypes are then transferred onto node embeddings via explicit message passing, bypassing local neighborhoods and mitigating oversquashing. PM-GNN can scale to large graphs, outperforming strong baselines on multiple heterophilous datasets.|我们研究了图神经网络（GNNs）在异质图上的节点分类任务。为了解决异质邻域中有效局部信息稀缺的问题，通常需要探索全局交互。然而，许多现有方法在实现这一目标时计算成本高昂，并且可能存在诸如过度压缩（oversquashing）等问题。此外，早期研究表明，在异质图上，多层感知器（MLP）的表现可能优于GNNs，这表明节点特征信息利用不足。为了应对这些局限性，我们提出了原型介导的图神经网络（PM-GNN），这是一种新颖的框架，能够利用类别原型高效捕获全局特征信息。PM-GNN通过软k-means聚类机制从原始节点特征中为每个类别学习多个类别原型。然后，这些原型通过显式的消息传递机制转移到节点嵌入上，绕过局部邻域并缓解过度压缩问题。PM-GNN能够扩展到大规模图，并在多个异质数据集上优于强基线模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Global+Message+Passing+for+Heterophilous+Graphs)|0|
|[General Time Transformer: an Encoder-only Foundation Model for Zero-Shot Multivariate Time Series Forecasting](https://doi.org/10.1145/3627673.3679931)|Cheng Feng, Long Huang, Denis Krompass|Siemens Technology, Munich, Germany; Siemens Technology, Beijing, China; Tsinghua University, Beijing, China|We present General Time Transformer (GTT), an encoder-only style foundation model for zero-shot multivariate time series forecasting. GTT is pretrained on a large dataset of 200M high-quality time series samples spanning diverse domains. In our framework, we consider multivariate time series as a distinct category of images characterized by varying number of channels, and represent each time series sample as a sequence of non-overlapping curve shapes (patches) within an unified numerical magnitude. Furthermore, we formulate the task of multivariate time series forecasting as a problem of predicting the next curve shape based on a window of past curve shapes on a channel-wise basis. Experimental results demonstrate that GTT exhibits superior zero-shot multivariate forecasting capabilities on unseen time series datasets, even surpassing state-of-the-art supervised baselines. Additionally, we investigate the impact of varying GTT model parameters and training dataset scales, observing that the scaling law also applies in the context of zero-shot multivariate time series forecasting. The codebase of GTT is available at https://github.com/cfeng783/GTT.|我们提出了通用时间变换器（General Time Transformer, GTT），这是一种仅包含编码器风格的基础模型，用于零样本多元时间序列预测。GTT在一个包含2亿个高质量时间序列样本的大型数据集上进行了预训练，这些样本涵盖了多个领域。在我们的框架中，我们将多元时间序列视为一种具有不同通道数的独特图像类别，并将每个时间序列样本表示为统一数值范围内的不重叠曲线形状（片段）序列。此外，我们将多元时间序列预测任务形式化为基于过去窗口的曲线形状逐通道预测下一个曲线形状的问题。实验结果表明，GTT在未见时间序列数据集上展现出卓越的零样本多元预测能力，甚至超越了当前最先进的监督基线模型。此外，我们研究了不同GTT模型参数和训练数据集规模的影响，观察到缩放定律在零样本多元时间序列预测的背景下同样适用。GTT的代码库可在https://github.com/cfeng783/GTT获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=General+Time+Transformer:+an+Encoder-only+Foundation+Model+for+Zero-Shot+Multivariate+Time+Series+Forecasting)|0|
|[Effective Clean-Label Backdoor Attacks on Graph Neural Networks](https://doi.org/10.1145/3627673.3679905)|Xuanhao Fan, Enyan Dai|The Pennsylvania State University & HKUST(GZ), State College, PA, USA; Independent, Beijing, China|Graph Neural Networks (GNNs) have achieved remarkable success across various domains, yet recent studies have exposed their vulnerability to backdoor attacks. Backdoor attacks inject triggers into the training set to poison the model, with adversaries typically relabeling training samples with backdoor triggers to a target label. This leads a GNN trained on the poisoned dataset to misclassify any test sample containing the backdoor trigger as the target label. However, relabeling not only increases the cost of the attack but also raises the risk of detection. Therefore, our study focuses on clean-label backdoor attacks, which do not require modify the labels of trigger-attached samples in the training phase. Specifically, we employ a novel method to select effective poisoned samples belonging to the target class. An adaptive trigger generator is furthest deployed to high attack success rates under a small backdoor budget. Our experiments on four public datasets validate the effectiveness of our proposed attack.|图神经网络（GNNs）在各个领域取得了显著的成功，然而最近的研究揭示了它们对后门攻击的脆弱性。后门攻击通过在训练集中注入触发器来污染模型，攻击者通常会将带有后门触发器的训练样本重新标记为目标标签。这使得在受污染的数据集上训练的GNN会将任何包含后门触发器的测试样本错误分类为目标标签。然而，重新标记不仅增加了攻击的成本，还增加了被检测的风险。因此，我们的研究集中于干净标签的后门攻击，这种攻击在训练阶段不需要修改带有触发器的样本的标签。具体来说，我们采用了一种新颖的方法来选择属于目标类别的有效污染样本。自适应触发器生成器被最大限度地部署，以在小的后门预算下实现高攻击成功率。我们在四个公共数据集上的实验验证了我们所提出攻击的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Effective+Clean-Label+Backdoor+Attacks+on+Graph+Neural+Networks)|0|
|[Retrogressive Document Manipulation of US Federal Environmental Websites](https://doi.org/10.1145/3627673.3679988)|Lesley Frew, Michael L. Nelson, Michele C. Weigle|Department of Computer Science, Old Dominion University, Norfolk, VA, USA|Changes made to webpages can affect their retrievability. Often this is done with the intention of increasing the page's search engine ranking to improve overall access to information on the page. The Environmental Data and Governance Initiative (EDGI) created a dataset that describes changes on US federal environmental webpages between 2016 and 2020. EDGI noted that many environmental terms were deleted from the pages, but without user data, claims that page retrievability and public information access were lowered are only anecdotal. The Open Resource for Click Analysis in Search (ORCAS) dataset was created during the same time frame, from 2017 to 2020, and enables high quality user intent analysis without compromising on user privacy protection. We present an analysis of the intersection of the EDGI dataset and the ORCAS dataset, matching changes on federal environmental webpages with their associated queries. We use web archives and a change-text indexing system to link changes in term frequency on the pages with the queries. We find that the pages contain fewer query terms in 2020 than in 2016, lowering the pages' retrievability. The analysis provides substantive support of EDGI's claim that federal environmental pages were made less accessible between 2016 and 2020.|对网页所做的更改可能会影响其可检索性。通常，这些更改的目的是提高网页在搜索引擎中的排名，从而改善对网页上信息的整体访问。环境数据与治理倡议（Environmental Data and Governance Initiative, EDGI）创建了一个数据集，描述了2016年至2020年间美国联邦环境网页的变更情况。EDGI指出，许多环境相关术语从这些页面中被删除，但由于缺乏用户数据，关于页面可检索性和公众信息访问性降低的说法仅是传闻。在同一时间段内，即2017年至2020年，开放搜索点击分析资源（Open Resource for Click Analysis in Search, ORCAS）数据集被创建，该数据集能够在保护用户隐私的前提下进行高质量的用户意图分析。我们提出了对EDGI数据集和ORCAS数据集交集的分析，将联邦环境网页的变更与其相关的查询进行匹配。我们使用网页存档和变更文本索引系统，将页面上术语频率的变化与查询联系起来。我们发现，与2016年相比，2020年这些页面包含的查询术语更少，从而降低了页面的可检索性。该分析为EDGI的声明提供了实质性支持，即2016年至2020年间，联邦环境页面的可访问性确实有所降低。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Retrogressive+Document+Manipulation+of+US+Federal+Environmental+Websites)|0|
|[Application of Large Language Models in Chemistry Reaction Data Extraction and Cleaning](https://doi.org/10.1145/3627673.3679874)|Xiaobao Huang, Mihir Surve, Yuhan Liu, Tengfei Luo, Olaf Wiest, Xiangliang Zhang, Nitesh V. Chawla|University of Notre Dame, Notre Dame, USA; University of Notre Dame, Notre Dame, IN, USA|Chemical reaction data has existed and still largely exists in unstructured forms. But curating such information into datasets suitable for tasks such as yield and reaction outcome prediction is impractical via manual curation and not possible to automate through programmatic means alone. Large language models (LLMs) have emerged as potent tools, showcasing remarkable capabilities in processing textual information and therefore could be extremely useful in automating this process. To address the challenge of unstructured data, we manually curated a dataset of structured chemical reaction data to fine-tune and evaluate LLMs. We propose a paradigm that leverages prompt-tuning, fine-tuning techniques, and a verifier to check the extracted information. We evaluate the capabilities of various LLMs, including LLAMA-2 and GPT models with different parameter counts, on the data extraction task. Our results show that prompt tuning of GPT-4 yields the best accuracy and evaluation results. Fine-tuning LLAMA-2 models with hundreds of samples does enable them and organize scientific material according to user-defined schemas better though. This workflow shows an adaptable approach for chemical reaction data extraction but also highlights the challenges associated with nuance in chemical information. We open-sourced our code at https://github.com/joker-bruce/LLM_Extraction_Chem.|化学反应数据长期以来主要以非结构化的形式存在，且目前仍然大量以这种形式存在。然而，手动将这些信息整理成适合用于产率和反应结果预测等任务的数据集是不现实的，也无法仅通过编程手段实现自动化。大型语言模型（LLMs）作为一种强大的工具崭露头角，展现了在处理文本信息方面的卓越能力，因此在自动化这一过程中可能极为有用。为了应对非结构化数据的挑战，我们手动整理了一个结构化的化学反应数据集，用于微调和评估LLMs。我们提出了一种范式，利用提示调优、微调技术和验证器来检查提取的信息。我们评估了包括LLAMA-2和不同参数数量的GPT模型在内的各种LLMs在数据提取任务中的能力。我们的结果表明，通过提示调优的GPT-4在准确性和评估结果上表现最佳。尽管仅使用数百个样本微调LLAMA-2模型确实使其能够更好地根据用户定义的架构组织科学材料。这一工作流程展示了一种适用于化学反应数据提取的灵活方法，但也凸显了与化学信息细节相关的挑战。我们在https://github.com/joker-bruce/LLM_Extraction_Chem上开源了我们的代码。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Application+of+Large+Language+Models+in+Chemistry+Reaction+Data+Extraction+and+Cleaning)|0|
|[Error Detection and Constraint Recovery in Hierarchical Multi-Label Classification without Prior Knowledge](https://doi.org/10.1145/3627673.3679918)|Joshua Shay Kricheli, Khoa Vo, Aniruddha Datta, Spencer Ozgur, Paulo Shakarian||Recent advances in Hierarchical Multi-label Classification (HMC), particularly neurosymbolic-based approaches, have demonstrated improved consistency and accuracy by enforcing constraints on a neural model during training. However, such work assumes the existence of such constraints a-priori. In this paper, we relax this strong assumption and present an approach based on Error Detection Rules (EDR) that allow for learning explainable rules about the failure modes of machine learning models. We show that these rules are not only effective in detecting when a machine learning classifier has made an error but also can be leveraged as constraints for HMC, thereby allowing the recovery of explainable constraints even if they are not provided. We show that our approach is effective in detecting machine learning errors and recovering constraints, is noise tolerant, and can function as a source of knowledge for neurosymbolic models on multiple datasets, including a newly introduced military vehicle recognition dataset.|近期在层次多标签分类（HMC）领域，尤其是基于神经符号方法的研究进展，通过在训练过程中对神经模型施加约束，显著提升了模型的一致性和准确性。然而，这类研究通常假设这些约束是预先存在的。本文中，我们放宽了这一强假设，提出了一种基于错误检测规则（EDR）的方法，该方法能够学习关于机器学习模型失效模式的可解释规则。我们证明了这些规则不仅能有效检测机器学习分类器何时出错，还能作为HMC的约束条件，从而即使在没有提供约束的情况下也能恢复出可解释的约束。我们的方法在检测机器学习错误和恢复约束方面表现出色，具有噪声容忍性，并且可以作为神经符号模型在多个数据集（包括一个新引入的军用车辆识别数据集）上的知识来源。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Error+Detection+and+Constraint+Recovery+in+Hierarchical+Multi-Label+Classification+without+Prior+Knowledge)|0|
|[Learning Prompt-Level Quality Variance for Cost-Effective Text-to-Image Generation](https://doi.org/10.1145/3627673.3679954)|Dongkeun Lee, Wonjun Lee|Korea University, Seoul, Republic of Korea|Text-to-image generation is a multivariable process in which the resulting quality is determined by both the generative model and the input prompt. While previous efforts rely on a single model either by enhancing its capability or by reformulating prompts, we point out that no single model excels at handling all types of tasks, as there exist inter-model and intra-model quality variance induced by the difference in types of prompts. This paper explores the relationship between the generation quality of text-to-image models and the linguistic features of input prompts by measuring the performance of state-of-the-art models using five different prompt datasets each with its distinctive features. Motivated by our empirical observations, we propose a novel approach that assigns each prompt to its best-performing model based on quality prediction. This enables utilizing a diverse set of models each with its expertise and cost, thereby enhancing cost-effectiveness. Evaluation results show that our approach can reduce the total generation cost by 29.25% with comparable or even higher generation quality than using only the single best model.|文本到图像生成是一个多变量过程，其生成质量由生成模型和输入提示共同决定。尽管以往的研究主要依赖于单一模型，通过增强其能力或重新设计提示来实现改进，但我们指出，没有一个单一模型能够出色地处理所有类型的任务，因为不同类型的提示会导致模型间和模型内的质量差异。本文通过使用五个具有各自独特特征的提示数据集，测量了最先进的文本到图像模型的性能，探讨了文本到图像模型的生成质量与输入提示的语言特征之间的关系。基于我们的实证观察，我们提出了一种新方法，该方法通过质量预测将每个提示分配给其表现最佳的模型。这使得我们可以利用一组具有各自专长和成本的多样化模型，从而提高成本效益。评估结果表明，与仅使用单一最佳模型相比，我们的方法可以在生成质量相当甚至更高的情况下，将总生成成本降低29.25%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Prompt-Level+Quality+Variance+for+Cost-Effective+Text-to-Image+Generation)|0|
|[HypMix: Hyperbolic Representation Learning for Graphs with Mixed Hierarchical and Non-hierarchical Structures](https://doi.org/10.1145/3627673.3679940)|Eric Wonhee Lee, Bo Xiong, Carl Yang, Joyce C. Ho|University of Stuttgart, Stuttgart, Germany; Emory University, Atlanta, GA, USA|Heterogeneous networks contain multiple types of nodes and links, with some link types encapsulating hierarchical structure over entities. Hierarchical relationships can codify information such as subcategories or one entity being subsumed by another and are often used for organizing conceptual knowledge into a tree-structured graph. Hyperbolic embedding models learn node representations in a hyperbolic space suitable for preserving the hierarchical structure. Unfortunately, current hyperbolic embedding models only implicitly capture the hierarchical structure, failing to distinguish between node types, and they only assume a single tree. In practice, many networks contain a mixture of hierarchical and non-hierarchical structures, and the hierarchical relations may be represented as multiple trees with complex structures, such as sharing certain entities. In this work, we propose a new hyperbolic representation learning model that can handle complex hierarchical structures and also learn the representation of both hierarchical and non-hierarchic structures. We evaluate our model on several datasets, including identifying relevant articles for a systematic review, which is an essential tool for evidence-driven medicine and node classification.|异构网络包含多种类型的节点和链接，其中一些链接类型封装了实体之间的层次结构。层次关系可以编码诸如子类别或一个实体被另一个实体包含的信息，并常用于将概念知识组织成树状图。双曲嵌入模型在适合保留层次结构的双曲空间中学习节点表示。然而，当前的双曲嵌入模型仅隐式地捕捉层次结构，无法区分节点类型，并且仅假设单一树结构。实际上，许多网络包含层次和非层次结构的混合，且层次关系可能表现为具有复杂结构的多个树，例如共享某些实体。在本研究中，我们提出了一种新的双曲表示学习模型，能够处理复杂的层次结构，并同时学习层次和非层次结构的表示。我们在多个数据集上评估了我们的模型，包括为系统综述识别相关文章（这是循证医学的重要工具）以及节点分类任务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HypMix:+Hyperbolic+Representation+Learning+for+Graphs+with+Mixed+Hierarchical+and+Non-hierarchical+Structures)|0|
|[Document-Level Relation Extraction Based on Heterogeneous Graph Reasoning](https://doi.org/10.1145/3627673.3679899)|Dong Li, Miao Li, ZhiLei Lei, Baoyan Song, Xiaohuan Shan|; Liaoning University, Shenyang, China|The goal of document-level relation extraction is to extract semantic information from multiple sentences within a document and identify the relations between entities across sentences. However, effectively representing the document's content and reasoning about cross-sentence entities presents a formidable challenge. In this paper, we propose an efficient Document-Level Relation Extraction Model based on Heterogeneous Graph Reasoning (HGR-DREM), which enables relation extraction more accurate. Specifically, we first construct a document-level heterogeneous graph to comprehensively capture the semantic relations between entities. Then, we design a meta-path attention-based reasoning mechanism to enhance the mutual influence among graph nodes. Furthermore, we utilize an extended adjacency matrix to represent the heterogeneous graph and leverage graph convolutional neural networks (GCNs) to extract high-dimensional features. The experiments on a real-world dataset demonstrate the effectiveness of our proposed model. All codes have been released at https://github.com/NuyoaH-code/HGR-DREM.|文档级关系抽取的目标是从文档中的多个句子中提取语义信息，并识别跨句子的实体之间的关系。然而，有效地表示文档内容并进行跨句子实体的推理是一个巨大的挑战。在本文中，我们提出了一种基于异构图推理的高效文档级关系抽取模型（HGR-DREM），该模型能够使关系抽取更加准确。具体来说，我们首先构建了一个文档级异构图，以全面捕捉实体之间的语义关系。然后，我们设计了一种基于元路径注意力的推理机制，以增强图节点之间的相互影响。此外，我们利用扩展的邻接矩阵来表示异构图，并利用图卷积神经网络（GCNs）提取高维特征。在真实数据集上的实验证明了我们提出的模型的有效性。所有代码已在https://github.com/NuyoaH-code/HGR-DREM上发布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Document-Level+Relation+Extraction+Based+on+Heterogeneous+Graph+Reasoning)|0|
|[Beyond Aggregation: Efficient Federated Model Consolidation with Heterogeneity-Adaptive Weights Diffusion](https://doi.org/10.1145/3627673.3679879)|Jiaqi Li, Xiaoyang Qu, Wenbo Ding, Zihao Zhao, Jianzong Wang|; Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Ping An Technology (Shenzhen) Co., Ltd., Shenzhen, China|As the Internet of Things (IoT) evolves, the need for enhanced data-sharing to improve edge device performance has led to the adoption of Federated Learning (FL) for data privacy and optimized data utilization. However, communication costs in FL remain a significant challenge. Traditional methods focus on client enhancements but overlook server-side aggregation, potentially increasing client computation loads. In response, we introduce a novel method, FedDiff, which utilizes diffusion models for generating model weights on FL servers, replacing traditional aggregation methods. Our approach, tailored for heterogeneous environments, significantly improves communication efficiency, achieving faster convergence and robust performance against weight noise in rigorous tests.|随着物联网（IoT）的发展，为了提高边缘设备的性能，增强数据共享的需求促使了联邦学习（FL）的采用，以保护数据隐私并优化数据利用。然而，FL中的通信成本仍然是一个重大挑战。传统方法侧重于客户端的增强，但忽视了服务器端的聚合，这可能会增加客户端的计算负担。为此，我们引入了一种新方法——FedDiff，该方法利用扩散模型在FL服务器上生成模型权重，替代了传统的聚合方法。我们的方法专为异构环境设计，显著提高了通信效率，在严格的测试中实现了更快的收敛速度和对权重噪声的鲁棒性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Aggregation:+Efficient+Federated+Model+Consolidation+with+Heterogeneity-Adaptive+Weights+Diffusion)|0|
|[ChefFusion: Multimodal Foundation Model Integrating Recipe and Food Image Generation](https://doi.org/10.1145/3627673.3679885)|Peiyu Li, Xiaobao Huang, Yijun Tian, Nitesh V. Chawla||Significant work has been conducted in the domain of food computing, yet these studies typically focus on single tasks such as t2t (instruction generation from food titles and ingredients), i2t (recipe generation from food images), or t2i (food image generation from recipes). None of these approaches integrate all modalities simultaneously. To address this gap, we introduce a novel food computing foundation model that achieves true multimodality, encompassing tasks such as t2t, t2i, i2t, it2t, and t2ti. By leveraging large language models (LLMs) and pre-trained image encoder and decoder models, our model can perform a diverse array of food computing-related tasks, including food understanding, food recognition, recipe generation, and food image generation. Compared to previous models, our foundation model demonstrates a significantly broader range of capabilities and exhibits superior performance, particularly in food image generation and recipe generation tasks. We open-sourced ChefFusion at GitHub.|在食品计算领域已经开展了大量研究，但这些研究通常只关注单一任务，例如t2t（根据食品标题和配料生成指令）、i2t（根据食品图像生成食谱）或t2i（根据食谱生成食品图像）。这些方法均未同时整合所有模态。为了填补这一空白，我们引入了一种新型的食品计算基础模型，该模型实现了真正的多模态，涵盖了t2t、t2i、i2t、it2t和t2ti等任务。通过利用大型语言模型（LLMs）以及预训练的图像编码器和解码器模型，我们的模型能够执行各种与食品计算相关的任务，包括食品理解、食品识别、食谱生成和食品图像生成。与之前的模型相比，我们的基础模型展现出更广泛的能力，并在食品图像生成和食谱生成任务中表现出卓越的性能。我们已在GitHub上开源了ChefFusion。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ChefFusion:+Multimodal+Foundation+Model+Integrating+Recipe+and+Food+Image+Generation)|0|
|[Coresets for Deletion-Robust k-Center Clustering](https://doi.org/10.1145/3627673.3679890)|Ruien Li, Yanhao Wang, Michael Mathioudakis|East China Normal University, Shanghai, China; University of Helsinki, Helsinki, Finland|The k-center clustering problem is of fundamental importance for a broad range of machine learning and data science applications. In this paper, we study the deletion-robust version of the problem. Specifically, we aim to extract a small subset of a given data set, referred to as a coreset, that contains a provably good set of k centers even after an adversary deletes up to z arbitrarily chosen points from the data set. We propose a 4-approximation algorithm that provides a coreset of size O(kz). To our knowledge, this is the first algorithm for deletion-robust k-center clustering with a theoretical guarantee. Moreover, we accompany our theoretical results with extensive experiments, demonstrating that our algorithm achieves significantly better robustness than non-trivial baselines against three heuristic gray-box and white-box adversarial deletion attacks.|k中心聚类问题在广泛的机器学习和数据科学应用中具有基础性重要性。本文研究了该问题的删除鲁棒性版本。具体而言，我们的目标是从给定的数据集中提取一个小的子集，称为核心集（coreset），即使在对数据集中的任意z个点进行删除后，该核心集仍能包含一组具有理论保证的k个中心。我们提出了一种4-近似算法，该算法生成的核心集大小为O(kz)。据我们所知，这是首个具有理论保证的删除鲁棒k中心聚类算法。此外，我们通过大量实验验证了理论结果，证明我们的算法在面对三种启发式的灰盒和白盒对抗删除攻击时，比非平凡的基线算法表现出显著更好的鲁棒性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Coresets+for+Deletion-Robust+k-Center+Clustering)|0|
|[Effective Job-market Mobility Prediction with Attentive Heterogeneous Knowledge Learning and Synergy](https://doi.org/10.1145/3627673.3679906)|Sida Lin, Zhouyi Zhang, Yankai Chen, Chenhao Ma, Yixiang Fang, Shan Dai, Guangli Lu|; Cornell University, Ithaca, NY, USA; The Chinese University of Hong Kong, Shenzhen, Shenzhen, China; The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China|Job-market mobility prediction plays a crucial role in optimizing human capital usage for both employees and employers. Most conventional methods primarily focus on learning sequential career sequences while ignoring the sufficient information extraction of mutual entity correlations in the job market. In this work, we push forward to exploit the heterogeneous relational knowledge among the job market structures by proposing a model namely Attentive Heterogeneous Knowledge Learning and Synergy (AHKLS). Equipped with the subsequent module of time-aware perception, AHKLS achieves effective career trajectory encoding for job-market mobility prediction. To evaluate the AHKLS performance, we conduct extensive experiments on three real-world datasets with different sizes. The empirical analyses demonstrate not only the performance superiority of AHKLS over several competing methods, but also the module effectiveness and model compatibility with other methods in enhancing the mobility prediction tasks accordingly.|工作市场流动性预测在优化员工和雇主的人力资本使用方面起着至关重要的作用。大多数传统方法主要集中于学习顺序的职业序列，而忽视了工作市场中相互实体关联的充分信息提取。在本研究中，我们通过提出一种名为“注意力异构知识学习与协同”（Attentive Heterogeneous Knowledge Learning and Synergy, AHKLS）的模型，进一步挖掘工作市场结构中的异构关系知识。结合时间感知模块，AHKLS实现了有效的职业轨迹编码，用于工作市场流动性预测。为了评估AHKLS的性能，我们在三个不同规模的真实数据集上进行了广泛的实验。实证分析不仅展示了AHKLS在性能上优于几种竞争方法，还证明了模块的有效性以及模型与其他方法在增强流动性预测任务中的兼容性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Effective+Job-market+Mobility+Prediction+with+Attentive+Heterogeneous+Knowledge+Learning+and+Synergy)|0|
|[An Explainable Multi-atlas Fusion Model based on Spatial Overlap for ASD Diagnosis](https://doi.org/10.1145/3627673.3679873)|Yuefeng Ma, Xiaochen Mu, Tengfei Zhang|The School of Computer Science, Qufu Normal University, Rizhao, China|Autism spectrum disorder (ASD) is a prevalent neurodevelopmental condition. Prompt recognition and treatment are vital for enhancing the life quality of individuals affected by ASD. However, current research either focus on a single atlas or a simple matrix concatenation combination, neglecting the complex and spatial relationship among the brain regions in different atlases. To tackle this weakness, in this paper, we propose a novel multi-atlas time-series feature fusion model with three steps based on spatial overlap proportion of brain regions to obtain an explainable representation of brain networks, which aims to achieve excellent diagnosis of ASD/TC. Specifically, we formally introduce the concept of spatial overlap and give its measurement, spatial overlap proportion. Then, we fuse the brain regions of multi-atlas to obtain an explainable brain networks of each subject. Finally, the GCN classifier is used to perform the final classification. The experimental results on Autism Brain Imaging Data Exchange (ABIDE) demonstrate that our proposed method achieved an accuracy of 0.771. Overall, our method outperforms SOTA methods in ASD/TC classification.|自闭症谱系障碍（ASD）是一种常见的神经发育性疾病。及时的识别和治疗对于提高ASD患者的生活质量至关重要。然而，当前的研究要么集中于单一脑图谱，要么采用简单的矩阵拼接组合，忽略了不同脑图谱之间脑区的复杂空间关系。为了解决这一不足，本文提出了一种新颖的多脑图谱时间序列特征融合模型，该模型基于脑区的空间重叠比例，通过三个步骤获得可解释的脑网络表示，旨在实现ASD/TC的精准诊断。具体而言，我们正式引入了空间重叠的概念，并给出了其度量方法——空间重叠比例。接着，我们融合多脑图谱的脑区，获得每个受试者的可解释脑网络。最后，使用图卷积网络（GCN）分类器进行最终分类。在自闭症脑成像数据交换（ABIDE）上的实验结果表明，我们提出的方法达到了0.771的准确率。总体而言，我们的方法在ASD/TC分类任务中优于现有的最先进（SOTA）方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Explainable+Multi-atlas+Fusion+Model+based+on+Spatial+Overlap+for+ASD+Diagnosis)|0|
|[ToxVI: a Multimodal LLM-based Framework for Generating Intervention in Toxic Code-Mixed Videos](https://doi.org/10.1145/3627673.3680004)|Krishanu Maity, A. S. Poornash, Sriparna Saha, Kitsuchart Pasupa|King Mongkut's Institute of Technology Ladkrabang, Bangkok, Thailand; Indian Institute of Technology Patna, Patna, India|While considerable research has delved into detecting toxic content in text-based data, the realm of video content, particularly in languages other than English, has received less attention. Prior studies have primarily focused on creating automated tools to identify online toxic speech but have often overlooked the crucial next steps of mitigating its impact and discouraging future use. We can discourage social media users from sharing such material by automatically generating interventions that explain why certain content is inappropriate. To bridge this research gap, we propose an innovative task: generating interventions for toxic videos in code-mixed languages which go beyond existing methods focusing on text and images to combat online toxicity. We are introducing a Toxic Code-Mixed Intervention Video benchmark dataset (ToxCMI), comprising 1697 code-mixed toxic video utterances sourced from YouTube. Each utterance in this dataset has been meticulously annotated for toxicity and severity, accompanied by interventions provided in Hindi-English code-mixed languages. We have developed an advanced multimodal framework ToxVI, specifically designed for the task of generating Toxic Video appropriate Interventions, leveraging Large Language Models (LLMs), which comprises three modules - Modality module, Cross-Modal Synchronization module and Generation module. Our experiments demonstrate that integrating multiple modalities from the videos significantly enhances the performance of the proposed task and outperforms all the baselines by a significant margin.|尽管已有大量研究致力于检测基于文本数据中的有害内容，但视频内容领域，尤其是非英语语言的视频内容，却较少受到关注。先前的研究主要集中在创建自动化工具来识别网络上的有害言论，但往往忽略了减轻其影响并阻止未来使用的关键后续步骤。通过自动生成干预措施，解释某些内容为何不恰当，我们可以阻止社交媒体用户分享此类材料。为了填补这一研究空白，我们提出了一项创新任务：生成针对代码混合语言中有害视频的干预措施，这些干预措施超越了现有专注于文本和图像的方法，以应对网络有害内容。我们引入了一个名为Toxic Code-Mixed Intervention Video（ToxCMI）的基准数据集，该数据集包含从YouTube获取的1697个代码混合的有害视频话语。该数据集中的每个话语都经过细致的毒性和严重性标注，并附有印地语-英语代码混合语言提供的干预措施。我们开发了一个先进的多模态框架ToxVI，专门设计用于生成针对有害视频的适当干预措施，该框架利用大型语言模型（LLMs），包含三个模块——模态模块、跨模态同步模块和生成模块。我们的实验表明，整合视频中的多种模态显著提升了所提出任务的性能，并且在所有基线方法中表现优异。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ToxVI:+a+Multimodal+LLM-based+Framework+for+Generating+Intervention+in+Toxic+Code-Mixed+Videos)|0|
|[Extended Japanese Commonsense Morality Dataset with Masked Token and Label Enhancement](https://doi.org/10.1145/3627673.3679924)|Takumi Ohashi, Tsubasa Nakagawa, Hitoshi Iyatomi||Rapid advancements in artificial intelligence (AI) have made it crucial to integrate moral reasoning into AI systems. However, existing models and datasets often overlook regional and cultural differences. To address this shortcoming, we have expanded the JCommonsenseMorality (JCM) dataset, the only publicly available dataset focused on Japanese morality. The Extended JCM (eJCM) has grown from the original 13,975 sentences to 31,184 sentences using our proposed sentence expansion method called Masked Token and Label Enhancement (MTLE). MTLE selectively masks important parts of sentences related to moral judgment and replaces them with alternative expressions generated by a large language model (LLM), while re-assigning appropriate labels. The model trained using our eJCM achieved an F1 score of 0.857, higher than the scores for the original JCM (0.837), ChatGPT one-shot classification (0.841), and data augmented using AugGPT, a state-of-the-art augmentation method (0.850). Specifically, in complex moral reasoning tasks unique to Japanese culture, the model trained with eJCM showed a significant improvement in performance (increasing from 0.681 to 0.756) and achieved a performance close to that of GPT-4 Turbo (0.787). These results demonstrate the validity of the eJCM dataset and the importance of developing models and datasets that consider the cultural context.|人工智能（AI）的快速发展使得将道德推理整合到AI系统中变得至关重要。然而，现有的模型和数据集往往忽视了地区和文化差异。为了解决这一不足，我们对JCommonsenseMorality（JCM）数据集进行了扩展，这是唯一一个专注于日本道德的公开数据集。通过我们提出的句子扩展方法——掩码标记与标签增强（Masked Token and Label Enhancement, MTLE），扩展后的JCM（eJCM）从最初的13,975个句子增加到31,184个句子。MTLE选择性地掩码与道德判断相关的句子重要部分，并用大型语言模型（LLM）生成的替代表达替换这些部分，同时重新分配适当的标签。使用我们的eJCM训练的模型取得了0.857的F1分数，高于原始JCM（0.837）、ChatGPT单次分类（0.841）以及使用AugGPT（一种最先进的增强方法）进行数据增强后的分数（0.850）。特别是在日本文化特有的复杂道德推理任务中，使用eJCM训练的模型表现出显著的性能提升（从0.681提高到0.756），并且接近GPT-4 Turbo的性能（0.787）。这些结果证明了eJCM数据集的有效性，以及开发考虑文化背景的模型和数据集的重要性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Extended+Japanese+Commonsense+Morality+Dataset+with+Masked+Token+and+Label+Enhancement)|0|
|[Progressive Label Disambiguation for Partial Label Learning in Homogeneous Graphs](https://doi.org/10.1145/3627673.3679982)|Rajat Patel, Aakarsh Malhotra, Sudipta Modak, Siddharth Yerramsetty|University of Windsor, Windsor, Canada; Mastercard, Gurugram, India|Many existing Graph Neural Networks (GNN) methods assume that labels are reliable and sufficient, which may not be the case in real-world scenarios. This paper addresses one such problem of Partial Label Learning (PLL) on graph-structured data. In the PLL for graphs, each node is represented by a candidate set of labels, where only one is true while the others are inaccurate. Despite advancements with PLL in tabular and vision domains, the graph-structured data still needs to be explored. In this work, we first define PLL for graphs. Subsequently, we propose a new PLD-Graph algorithm for PLL in homogeneous graphs with scarce labels. We utilize graph augmentation to reduce the effects of inexact labels and provide additional supervision from unlabeled nodes. Progressive label disambiguation is performed based on the model's ability to predict correct classes. Furthermore, an additional loss estimates the label corruption matrix to capture associations between correct and incorrect labels. We show the effectiveness of the proposed algorithm on multiple graph datasets, with two types of noise and varying levels of ambiguous labels. Overall, the proposed PLD-Graph algorithm outperforms state-of-the-art PLL methods.|许多现有的图神经网络（GNN）方法假设标签是可靠且充足的，然而在实际场景中，这种情况可能并不成立。本文探讨了图结构数据上的部分标签学习（PLL）问题。在图数据的PLL中，每个节点由一个候选标签集表示，其中仅有一个标签是真实的，而其他标签则是不准确的。尽管在表格数据和视觉领域的PLL研究已取得进展，但图结构数据的PLL问题仍需进一步探索。在本研究中，我们首先定义了图数据的PLL问题。随后，我们提出了一种新的PLD-Graph算法，用于处理标签稀缺的同构图数据中的PLL问题。我们利用图增强技术来减少不准确标签的影响，并从无标签节点中提供额外的监督信息。基于模型预测正确类别的能力，我们逐步进行标签消歧。此外，通过额外的损失函数估计标签污染矩阵，以捕捉正确标签与错误标签之间的关联。我们在多个图数据集上验证了所提出算法的有效性，数据集包含两种类型的噪声以及不同程度的标签模糊性。总体而言，所提出的PLD-Graph算法在性能上优于现有的PLL方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Progressive+Label+Disambiguation+for+Partial+Label+Learning+in+Homogeneous+Graphs)|0|
|[MEDFuse: Multimodal EHR Data Fusion with Masked Lab-Test Modeling and Large Language Models](https://doi.org/10.1145/3627673.3679962)|Phan Nguyen Minh Thao, CongTinh Dao, Chenwei Wu, JianZhe Wang, Shun Liu, JunEn Ding, David S. Restrepo, Feng Liu, FangMing Hung, WenChih Peng||Electronic health records (EHRs) are multimodal by nature, consisting of structured tabular features like lab tests and unstructured clinical notes. In real-life clinical practice, doctors use complementary multimodal EHR data sources to get a clearer picture of patients' health and support clinical decision-making. However, most EHR predictive models do not reflect these procedures, as they either focus on a single modality or overlook the inter-modality interactions/redundancy. In this work, we propose MEDFuse, a Multimodal EHR Data Fusion framework that incorporates masked lab-test modeling and large language models (LLMs) to effectively integrate structured and unstructured medical data. MEDFuse leverages multimodal embeddings extracted from two sources: LLMs fine-tuned on free clinical text and masked tabular transformers trained on structured lab test results. We design a disentangled transformer module, optimized by a mutual information loss to 1) decouple modality-specific and modality-shared information and 2) extract useful joint representation from the noise and redundancy present in clinical notes. Through comprehensive validation on the public MIMIC-III dataset and the in-house FEMH dataset, MEDFuse demonstrates great potential in advancing clinical predictions, achieving over 90 classification task.|电子健康记录（EHR）本质上是多模态的，包含结构化的表格特征（如实验室测试）和非结构化的临床笔记。在实际的临床实践中，医生使用互补的多模态EHR数据源来更清晰地了解患者的健康状况并支持临床决策。然而，大多数EHR预测模型并未反映这些过程，因为它们要么专注于单一模态，要么忽略了模态间的交互/冗余。在本研究中，我们提出了MEDFuse，一个多模态EHR数据融合框架，该框架结合了掩码实验室测试建模和大语言模型（LLMs），以有效整合结构化和非结构化医疗数据。MEDFuse利用从两个来源提取的多模态嵌入：在自由临床文本上微调的LLMs和在结构化实验室测试结果上训练的掩码表格变换器。我们设计了一个解耦变换器模块，通过互信息损失进行优化，以1）解耦模态特定和模态共享信息，以及2）从临床笔记中的噪声和冗余中提取有用的联合表示。通过在公开的MIMIC-III数据集和内部FEMH数据集上的全面验证，MEDFuse展示了在推进临床预测方面的巨大潜力，在超过90%的分类任务中取得了优异的成绩。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MEDFuse:+Multimodal+EHR+Data+Fusion+with+Masked+Lab-Test+Modeling+and+Large+Language+Models)|0|
|[Improving German News Clustering with Contrastive Learning](https://doi.org/10.1145/3627673.3679944)|Piriyakorn Piriyatamwong, Saikishore Kalloori, Fabio Zünd|ETH Zürich, Zürich, Switzerland|Automatic news articles clustering is one of the most important tasks for news publishers. Traditional unsupervised models exploit generic text representation (e.g., BERT) and typically do not consider the relationships between each paragraph in news articles. Such depth learning from news articles is important for clustering full-length articles. Recently contrastive learning (CL) has shown to be a popular method for representation learning that uses positive and negative data pairs generated using data augmentation techniques to improve the representation in the latent space. In this work, we propose text augmentation methods and use contrastive learning to cluster daily growing full-length German news articles. Our experiments on four German news article datasets (one labeled and three unlabeled datasets) demonstrate that contrastive learning and our text augmentation methods significantly improve the representation of news articles compared to generic pre-trained text representation and have high performance for clustering tasks.|自动新闻文章聚类是新闻出版商最重要的任务之一。传统的无监督模型利用通用文本表示（例如BERT），通常不会考虑新闻文章中每个段落之间的关系。这种从新闻文章中进行的深度学习对于全文文章的聚类非常重要。最近，对比学习（CL）已成为一种流行的表示学习方法，它使用通过数据增强技术生成的正负数据对来改进潜在空间中的表示。在本研究中，我们提出了文本增强方法，并使用对比学习对每日增长的德语全文新闻文章进行聚类。我们在四个德语新闻文章数据集（一个有标签和三个无标签数据集）上的实验表明，与通用的预训练文本表示相比，对比学习和我们的文本增强方法显著提高了新闻文章的表示能力，并且在聚类任务中表现出色。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+German+News+Clustering+with+Contrastive+Learning)|0|
|[Hol-Light: A Holistic framework for Efficient and Dynamic Traffic Signal Management](https://doi.org/10.1145/3627673.3679938)|Siyao Qiao, Jia Wu|University of Electronic Science and Technology of China, Chengdu, China|Numerous reinforcement learning-based traffic control methods have been proposed to enhance transportation efficiency and alleviate traffic congestion. However, the existing solutions predominantly address only specific facets of the challenge. For instance, some focus on enhancing control performance, while others aim to address control issues within heterogeneous road networks, explore model generalizability, or consider model compression for practical deployment scenarios. The question arises: Can a single approach effectively tackle all these issues concurrently? We propose a holistic framework, Hol-Light, that can effectively solve all these issues. It delves deeply into the feature representations of traffic phase considering the interplay between phase relationships and traffic flow dynamics, and meticulously captures the interphase relationships through an elegantly designed model that is both parameter-efficient and minimal. To substantiate the efficacy of our approach, we conducted comprehensive experiments utilizing two well-established traffic simulators: CityFlow and SUMO. The experiment results indicate that our method excels in terms of high performance, rapid training speed, robust generalization capabilities, and adaptability to diverse road network configurations.|众多基于强化学习的交通控制方法已被提出，旨在提升交通效率并缓解交通拥堵。然而，现有的解决方案大多仅针对挑战的特定方面。例如，一些方法专注于提升控制性能，而另一些则旨在解决异构路网中的控制问题，探索模型的泛化能力，或考虑实际部署场景中的模型压缩。这就引出了一个问题：是否有一种方法能够同时有效解决所有这些问题？我们提出了一个综合框架——Hol-Light，它能够有效解决所有这些问题。该框架深入探讨了交通相位的特征表示，考虑了相位关系与交通流动态之间的相互作用，并通过一个设计优雅、参数高效且极简的模型细致地捕捉了相位间的关系。为了验证我们方法的有效性，我们利用两个成熟的交通模拟器——CityFlow和SUMO——进行了全面的实验。实验结果表明，我们的方法在高性能、快速训练速度、强大的泛化能力以及对多样化路网配置的适应性方面表现出色。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hol-Light:+A+Holistic+framework+for+Efficient+and+Dynamic+Traffic+Signal+Management)|0|
|[ExPrompt: Augmenting Prompts Using Examples as Modern Baseline for Stance Classification](https://doi.org/10.1145/3627673.3679923)|Umair Qudus, Michael Röder, Daniel Vollmers, AxelCyrille Ngonga Ngomo|Data Science Group, Department of Computer Science, Paderborn University, Paderborn, Germany|Detecting the veracity of a statement automatically is a challenge the world is grappling with due to the vast amount of data spread across the web. Verifying a given claim typically entails validating it within the framework of supporting evidence like a retrieved piece of text. Classifying the stance of the text with respect to the claim is called stance classification. Despite advancements in automated fact-checking, most systems still rely on a substantial quantity of labeled training data, which can be costly. In this work, we avoid the costly training or fine-tuning of models by reusing pre-trained large language models together with few-shot in-context learning. Since we do not train any model, our approach ExPrompt is lightweight, demands fewer resources than other stance classification methods and can serve as a modern baseline for future developments. At the same time, our evaluation shows that our approach is able to outperform former state-of-the-art stance classification approaches regarding accuracy by at least 2 percent. Our scripts and data used in this paper are available at https://github.com/factcheckerr/ExPrompt.|自动检测陈述的真实性是一个全球都在努力应对的挑战，原因在于网络上散布着海量的数据。验证一个给定的声明通常需要在其支持证据框架内进行确认，例如检索到的一段文本。对文本相对于声明的立场进行分类被称为立场分类。尽管自动事实核查技术有所进步，但大多数系统仍然依赖于大量带标签的训练数据，这可能成本高昂。在本研究中，我们通过重用预训练的大型语言模型以及少量示例的上下文学习，避免了昂贵的模型训练或微调。由于我们没有训练任何模型，我们的方法ExPrompt是轻量级的，比其他立场分类方法需要更少的资源，并且可以作为未来发展的现代基准。同时，我们的评估显示，我们的方法在准确性上能够超越以前的先进立场分类方法至少2个百分点。我们在本文中使用的脚本和数据可在https://github.com/factcheckerr/ExPrompt获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ExPrompt:+Augmenting+Prompts+Using+Examples+as+Modern+Baseline+for+Stance+Classification)|0|
|[A Mixture of Experts in Forecasting Student Performance in Classroom Programming Activities](https://doi.org/10.1145/3627673.3679868)|Moqsadur Rahman, Monika Akbar, Justice T. Walker, Mahmud Shahriar Hossain|University of Texas at El Paso, El Paso, TX, USA|Predicting students' performance early in programming courses is crucial because it allows instructors to intervene early, improving learning outcomes. Currently, no existing platforms can effectively forecast student performance in programming activities based on students' developed code. Forecasting student scores based on their programming activities is challenging because the accuracy of different predictive models often varies throughout these activities. To address this challenge, we introduce a novel framework utilizing Mixture of Experts (MoE). The MoE method combines insights from various neural networks and dynamically picks the most accurate predictions. This system significantly enhances the reliability of forecasting each student's performance within the first 15 minutes of a 30-minute programming session. By enabling early predictions, the MoE provides instructors with a powerful mechanism to understand and support the student learning process in real-time.|在编程课程中尽早预测学生的表现至关重要，因为这使得教师能够及时干预，从而提高学习效果。目前，现有的平台无法有效地基于学生编写的代码来预测学生在编程活动中的表现。基于学生的编程活动来预测其成绩具有挑战性，因为不同预测模型的准确性在这些活动中往往会发生变化。为了解决这一挑战，我们引入了一种利用专家混合模型（Mixture of Experts, MoE）的新框架。MoE方法结合了来自各种神经网络的见解，并动态选择最准确的预测结果。该系统显著提高了在30分钟编程课程的前15分钟内预测每个学生表现的可靠性。通过实现早期预测，MoE为教师提供了一种强大的机制，能够实时了解并支持学生的学习过程。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Mixture+of+Experts+in+Forecasting+Student+Performance+in+Classroom+Programming+Activities)|0|
|[Compressed Models are NOT Miniature Versions of Large Models](https://doi.org/10.1145/3627673.3679888)|Rohit Raj Rai, Rishant Pal, Amit Awekar|Microsoft, Bing Ads AI & Res Grp, Redmond, WA 98052 USA|Pre-trained language models have achieved great success in a wide variety of natural language processing (NLP) tasks, while the superior performance comes with high demand in computational resources, which hinders the application in low-latency information retrieval (IR) systems. To address the problem, we present TwinBERT model, which has two improvements: 1) represent query and document separately using twin-structured encoders and 2) each encoder is a highly compressed BERT-like model with less than one third of the parameters. The former allows document embeddings to be pre-computed offline and cached in memory, which is different from BERT, where the two input sentences are concatenated and encoded together. The change saves large amount of computation time, however, it is still not sufficient for real-time retrieval considering the complexity of BERT model itself. To further reduce computational cost, a compressed multi-layer transformer encoder is proposed with special training strategies as a substitution of the original complex BERT encoder. Lastly, two versions of TwinBERT are developed to combine the query and keyword embeddings for retrieval and relevance tasks correspondingly. Both of them have met the real-time latency requirement and achieve close or on-par performance to BERT-Base model. The models were trained following the teacher-student framework and evaluated with data from one of the major search engines. Experimental results showed that the inference time was significantly reduced and was for the first time controlled within 20ms on CPUs while at the same time the performance gain from fine-tuned BERT-Base model was mostly retained. Integration of the models in production systems also demonstrated remarkable improvements on relevance metrics with negligible influence on latency. The models were released in 2019 with significant production impacts.|预训练语言模型在多种自然语言处理（NLP）任务中取得了巨大成功，然而其卓越性能伴随着对计算资源的高需求，这阻碍了其在低延迟信息检索（IR）系统中的应用。为解决这一问题，我们提出了TwinBERT模型，该模型具有两项改进：1）使用双结构编码器分别表示查询和文档；2）每个编码器都是一个高度压缩的类BERT模型，其参数量不到原始BERT模型的三分之一。前者允许文档嵌入在离线状态下预先计算并缓存在内存中，这与BERT不同，BERT将两个输入句子拼接在一起进行编码。这一改变节省了大量计算时间，然而考虑到BERT模型本身的复杂性，这仍不足以满足实时检索的需求。为了进一步降低计算成本，我们提出了一种压缩的多层Transformer编码器，并采用特殊训练策略作为原始复杂BERT编码器的替代方案。最后，我们开发了两个版本的TwinBERT模型，分别用于结合查询和关键词嵌入以进行检索和相关性任务。这两个版本均满足了实时延迟要求，并在性能上接近或达到了BERT-Base模型的水平。模型采用师生框架进行训练，并使用来自一个主要搜索引擎的数据进行评估。实验结果表明，推理时间显著减少，并首次在CPU上将推理时间控制在20毫秒以内，同时大部分保留了微调BERT-Base模型的性能增益。将模型集成到生产系统中也显著提升了相关性指标，且对延迟的影响微乎其微。该模型于2019年发布，对生产环境产生了显著影响。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Compressed+Models+are+NOT+Miniature+Versions+of+Large+Models)|0|
|[Generative AI for Energy: Multi-Horizon Power Consumption Forecasting using Large Language Models](https://doi.org/10.1145/3627673.3679933)|Kevin Roitero, Gianluca D'Abrosca, Andrea Zancola, Vincenzo Della Mea, Stefano Mizzaro|AcegasApsAmga SpA, Hera Group, Udine, Italy; University of Udine, Udine, Italy|We leverage generative NLP-based models, specifically Transformer-Based models, for multi-horizon univariate and multivariate power consumption forecasting. We apply our approach to various datasets, focusing on short-term (1 day) and long-term (1 week) forecasts. We test several lag configurations with and without additional contextual information and achieve promising results. We evaluate the forecasts' effectiveness using a range of metrics, and aggregate the results on a monthly basis for a comprehensive understanding of the performance throughout the year.|我们利用基于生成式自然语言处理（NLP）的模型，特别是基于Transformer的模型，进行多时间尺度的单变量和多变量电力消耗预测。我们将该方法应用于多个数据集，重点关注短期（1天）和长期（1周）的预测。我们测试了多种滞后配置，包括是否包含额外的上下文信息，并取得了令人满意的结果。我们使用一系列指标评估预测的有效性，并将结果按月汇总，以便全面了解全年性能表现。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generative+AI+for+Energy:+Multi-Horizon+Power+Consumption+Forecasting+using+Large+Language+Models)|0|
|[Scalable Expressiveness through Preprocessed Graph Perturbations](https://doi.org/10.1145/3627673.3679993)|Danial Saber, Amirali SalehiAbari||Graph Neural Networks (GNNs) have emerged as the predominant method foranalyzing graph-structured data. However, canonical GNNs have limitedexpressive power and generalization capability, thus triggering the developmentof more expressive yet computationally intensive methods. One such approach isto create a series of perturbed versions of input graphs and then repeatedlyconduct multiple message-passing operations on all variations during training.Despite their expressive power, this approach does not scale well on largergraphs. To address this scalability issue, we introduce Scalable Expressivenessthrough Preprocessed Graph Perturbation (SE2P). This model offers a flexible,configurable balance between scalability and generalizability with fourdistinct configuration classes. At one extreme, the configuration prioritizesscalability through minimal learnable feature extraction and extensivepreprocessing; at the other extreme, it enhances generalizability with morelearnable feature extractions, though this increases scalability costs. Weconduct extensive experiments on real-world datasets to evaluate thegeneralizability and scalability of SE2P variants compared to variousstate-of-the-art benchmarks. Our results indicate that, depending on the chosenSE2P configuration, the model can enhance generalizability compared tobenchmarks while achieving significant speed improvements of up to 8-fold.|图神经网络（GNNs）已成为分析图结构数据的主要方法。然而，经典GNN的表达能力和泛化能力有限，这促使了更具表达能力但计算密集的方法的发展。其中一种方法是创建输入图的一系列扰动版本，然后在训练期间对所有变体重复进行多次消息传递操作。尽管这种方法具有强大的表达能力，但在较大的图上扩展性较差。为了解决这一可扩展性问题，我们引入了通过预处理图扰动实现的可扩展表达能力（SE2P）。该模型通过四种不同的配置类别，在可扩展性和泛化性之间提供了灵活且可配置的平衡。在一种极端情况下，配置通过最小化可学习特征提取和广泛的预处理来优先考虑可扩展性；在另一种极端情况下，它通过增加可学习特征提取来增强泛化能力，尽管这会增加可扩展性成本。我们在真实世界的数据集上进行了广泛的实验，以评估SE2P变体与各种最先进基准相比的泛化能力和可扩展性。我们的结果表明，根据所选的SE2P配置，与基准相比，该模型可以增强泛化能力，同时实现高达8倍的显著速度提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+Expressiveness+through+Preprocessed+Graph+Perturbations)|0|
|[EDGE: Evaluation Framework for Logical vs. Subgraph Explanations for Node Classifiers on Knowledge Graphs](https://doi.org/10.1145/3627673.3679904)|Rupesh Sapkota, Dominik Köhler, Stefan Heindorf|Paderborn University, Paderborn, Germany|As machine learning and deep learning become increasingly integrated into our daily lives, understanding how these technologies make decisions is crucial. To ensure transparency, accountability, and ethical adherence, these so-called "black-box" models should be accompanied by human-comprehensible explanations of their predictions. This clarity is essential for establishing trust in their real-world applications. Similarly, it is crucial to compare different types of explanations to evaluate and understand their effectiveness, interpretability, and generalization capabilities for informed selection in various applications. To this end, we propose a framework called EDGE to evaluate diverse knowledge graph explanations, assessing logical rule-based and subgraph-based explanations by various explainers in terms of prediction accuracy and fidelity to the Graph Neural Network (GNN) model. Our evaluations reveal that logical methods excel in explaining complex and structured data, while subgraph-based models exhibit higher fidelity to the GNN model, earning them the label "GNN Explainers". Although further diversified evaluations are necessary to determine the superiority of one explanation type over another, our study shows that each type has pros and cons.|随着机器学习和深度学习技术日益融入我们的日常生活，理解这些技术如何做出决策变得至关重要。为了确保透明度、责任性和道德合规性，这些所谓的“黑箱”模型应当附带人类可理解的预测解释。这种清晰性对于建立对其在实际应用中信任至关重要。同样，比较不同类型的解释以评估和理解它们的有效性、可解释性和泛化能力，从而在各种应用中进行明智选择，也是至关重要的。为此，我们提出了一个名为EDGE的框架，用于评估多种知识图谱解释，通过不同的解释器评估基于逻辑规则和基于子图的解释在预测准确性和对图神经网络（GNN）模型的保真度方面的表现。我们的评估表明，逻辑方法在解释复杂和结构化数据方面表现出色，而基于子图的模型则表现出对GNN模型更高的保真度，因此被称为“GNN解释器”。尽管需要进一步多样化的评估来确定一种解释类型是否优于另一种，但我们的研究表明，每种类型都有其优缺点。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EDGE:+Evaluation+Framework+for+Logical+vs.+Subgraph+Explanations+for+Node+Classifiers+on+Knowledge+Graphs)|0|
|[Empowering Traffic Speed Prediction with Auxiliary Feature-Aided Dependency Learning](https://doi.org/10.1145/3627673.3679909)|DongHyuk Seo, Jiwon Son, Namhyuk Kim, WonYong Shin, SangWook Kim|Yonsei University, Seoul, Republic of Korea; Hanyang University, Seoul, Republic of Korea; Hyundai Motor Company, Seoul, Republic of Korea|Traffic speed prediction is a crucial task for optimizing navigation systems and reducing traffic congestion. Although there have been efforts to improve the accuracy of speed prediction by incorporating auxiliary features, such as traffic flow, weather, and time, types of auxiliary features are limited and their detailed relationships with speed have not been explored yet. In our study, we present the individual spatio-temporal (IST) dependencies on flow and speed, and characterize three types of IST-dependencies with the flow-to-flow, speed-to-speed, and flow-to-speed graphs. Then, we propose Auxiliary feature-aided Attention Network (ARIAN), a novel approach to judiciously learning the degrees of IST-dependencies with the three graphs and predicting the future speed by leveraging various auxiliary features. Through comprehensive experiments using 3 real-world datasets, we validate the superiority of ARIAN over 10 state-of-the-art methods and the effectiveness of each auxiliary feature and each dependency learner in ARIAN.|交通速度预测是优化导航系统和减少交通拥堵的关键任务。尽管已有研究通过整合辅助特征（如交通流量、天气和时间等）来提高速度预测的准确性，但辅助特征的类型仍然有限，且它们与速度之间的详细关系尚未得到充分探索。在本研究中，我们提出了流量和速度的个体时空（IST）依赖性，并通过流量-流量、速度-速度以及流量-速度三种图来表征这些依赖性。随后，我们提出了一种新颖的方法——辅助特征辅助注意力网络（ARIAN），该方法能够通过这三种图智能地学习IST依赖性的程度，并利用多种辅助特征来预测未来的交通速度。通过使用三个真实世界的数据集进行综合实验，我们验证了ARIAN相较于10种最先进方法的优越性，并证明了ARIAN中每个辅助特征和每个依赖性学习器的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Empowering+Traffic+Speed+Prediction+with+Auxiliary+Feature-Aided+Dependency+Learning)|0|
|[QuestGen: Effectiveness of Question Generation Methods for Fact-Checking Applications](https://doi.org/10.1145/3627673.3679985)|Ritvik Setty, Vinay Setty||Verifying fact-checking claims poses a significant challenge, even for humans. Recent approaches have demonstrated that decomposing claims into relevant questions to gather evidence enhances the efficiency of the fact-checking process. In this paper, we provide empirical evidence showing that this question decomposition can be effectively automated. We demonstrate that smaller generative models, fine-tuned for the question generation task using data augmentation from various datasets, outperform large language models by up to 8 machine-generated questions proves to be significantly more effective for fact-checking than that obtained from human-written questions. We also perform manual evaluation of the decomposed questions to assess the quality of the questions generated.|验证事实核查声明即使对人类来说也是一项重大挑战。最近的研究表明，将声明分解为相关的问题以收集证据可以提高事实核查过程的效率。在本文中，我们提供了实证证据，表明这种问题分解可以有效地自动化。我们展示了针对问答生成任务进行微调的较小生成模型，通过从各种数据集中进行数据增强，其性能优于大型语言模型，最多可提升8个机器生成的问题。事实证明，这些机器生成的问题在事实核查中的效果显著优于从人类撰写的问题中获得的结果。我们还对分解后的问题进行了人工评估，以评估生成问题的质量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=QuestGen:+Effectiveness+of+Question+Generation+Methods+for+Fact-Checking+Applications)|0|
|[M2IoU: A Min-Max Distance-based Loss Function for Bounding Box Regression in Medical Imaging](https://doi.org/10.1145/3627673.3679958)|Anurag Shandilya, Kalash Shah, Bhavik Kanekar, Akshat Gautam, Pavni Tandon, Ganesh Ramakrishnan, Kshitij S. Jadhav|IIT Bombay, Mumbai, India|Computer vision applications such as object detection have increased manifolds in the medical domain for diagnosis and treatment purposes. Generally, object detection models such as YOLO(You Only Look Once) involve identifying the correct bounding box and classifying the objects inside the bounding box. However, medical imaging object detection is a challenging endeavor, requiring models that are both efficient and extremely accurate in the face of limited data and expensive annotations. In this paper, we propose a Min-Max IoU (M2IoU) loss function by introducing a new min-max-based penalty term in the loss equation, between the predicted box and the ground truth coordinates. We further compare the results of several loss functions on the YOLOv8 model trained on multiple medical datasets and demonstrate that the M2IoU loss function leads to faster learning and outperforms other existing loss functions like CIoU and GIoU.|诸如目标检测等计算机视觉应用在医学领域的诊断和治疗目的中得到了显著增长。通常，目标检测模型如YOLO（You Only Look Once）涉及识别正确的边界框并对边界框内的对象进行分类。然而，医学成像中的目标检测是一项具有挑战性的任务，需要模型在面对有限数据和昂贵标注时既高效又极其准确。在本文中，我们提出了一种Min-Max IoU（M2IoU）损失函数，通过在损失方程中引入一个新的基于最小最大值的惩罚项，该惩罚项位于预测框和真实坐标之间。我们进一步比较了在多个医学数据集上训练的YOLOv8模型上几种损失函数的结果，并证明M2IoU损失函数能够加快学习速度，并且在性能上优于现有的其他损失函数，如CIoU和GIoU。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=M2IoU:+A+Min-Max+Distance-based+Loss+Function+for+Bounding+Box+Regression+in+Medical+Imaging)|0|
|[Enhancing SPARQL Generation by Triplet-order-sensitive Pre-training](https://doi.org/10.1145/3627673.3679916)|Chang Su, Jiexing Qi, He Yan, Kai Zou, Zhouhan Lin||Semantic parsing that translates natural language queries to SPARQL is of great importance for Knowledge Graph Question Answering (KGQA) systems. Although pre-trained language models like T5 have achieved significant success in the Text-to-SPARQL task, their generated outputs still exhibit notable errors specific to the SPARQL language, such as triplet flips. To address this challenge and further improve the performance, we propose an additional pre-training stage with a new objective, Triplet Order Correction (TOC), along with the commonly used Masked Language Modeling (MLM), to collectively enhance the model's sensitivity to triplet order and SPARQL syntax. Our method achieves state-of-the-art performances on three widely-used benchmarks.|将自然语言查询翻译成SPARQL的语义解析对于知识图谱问答（KGQA）系统至关重要。尽管像T5这样的预训练语言模型在文本到SPARQL任务中取得了显著成功，但其生成的输出仍然存在一些特定于SPARQL语言的显著错误，例如三元组翻转。为了应对这一挑战并进一步提高性能，我们提出了一个额外的预训练阶段，引入了一个新的目标——三元组顺序校正（Triplet Order Correction, TOC），与常用的掩码语言建模（Masked Language Modeling, MLM）结合，共同增强模型对三元组顺序和SPARQL语法的敏感性。我们的方法在三个广泛使用的基准测试中达到了最先进的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+SPARQL+Generation+by+Triplet-order-sensitive+Pre-training)|0|
|[Revealing the Power of Masked Autoencoders in Traffic Forecasting](https://doi.org/10.1145/3627673.3679989)|Jiarui Sun, Yujie Fan, ChinChia Michael Yeh, Wei Zhang, Girish Chowdhary|University of Illinois Urbana-Champaign; Visa Research|Traffic forecasting, crucial for urban planning, requires accurate predictions of spatial-temporal traffic patterns across urban areas. Existing research mainly focuses on designing complex models that capture spatial-temporal dependencies among variables explicitly. However, this field faces challenges related to data scarcity and model stability, which results in limited performance improvement. To address these issues, we propose Spatial-Temporal Masked AutoEncoders (STMAE), a plug-and-play framework designed to enhance existing spatial-temporal models on traffic prediction. STMAE consists of two learning stages. In the pretraining stage, an encoder processes partially visible traffic data produced by a dual-masking strategy, including biased random walk-based spatial masking and patch-based temporal masking. Subsequently, two decoders aim to reconstruct the masked counterparts from both spatial and temporal perspectives. The fine-tuning stage retains the pretrained encoder and integrates it with decoders from existing backbones to improve forecasting accuracy. Our results on traffic benchmarks show that STMAE can largely enhance the forecasting capabilities of various spatial-temporal models.|交通预测对于城市规划至关重要，其需要对城市区域内的时空交通模式进行准确预测。现有的研究主要集中在设计复杂的模型，以显式地捕捉变量之间的时空依赖关系。然而，该领域面临着数据稀缺和模型稳定性相关的挑战，这导致了性能提升有限。为了解决这些问题，我们提出了时空掩码自编码器（Spatial-Temporal Masked AutoEncoders, STMAE），这是一个即插即用的框架，旨在增强现有时空模型在交通预测中的表现。STMAE包含两个学习阶段。在预训练阶段，编码器处理由双重掩码策略生成的部分可见交通数据，该策略包括基于偏置随机游走的空间掩码和基于补丁的时间掩码。随后，两个解码器分别从空间和时间角度重建被掩码的部分。在微调阶段，保留预训练的编码器，并将其与现有骨干模型的解码器集成，以提高预测精度。我们在交通基准测试上的结果表明，STMAE能够大幅提升各种时空模型的预测能力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revealing+the+Power+of+Masked+Autoencoders+in+Traffic+Forecasting)|0|
|[Spatio-Temporal Sequence Modeling for Traffic Signal Control](https://doi.org/10.1145/3627673.3679998)|Qian Sun, Le Zhang, Jingbo Zhou, Rui Zha, Yu Mei, Chujie Tian, Hui Xiong|; Department of Intelligent Transportation System, Baidu Inc., Beijing, China; School of Computer Science, University of Science and Technology of China, Hefei, China; Baidu Research, Baidu Inc., Beijing, China|Traffic Signal Control(TSC), a pivotal and challenging research area in the transportation domain, aims to alleviate congestion at urban intersections by optimizing vehicular flows from different inflow directions. While large efforts have been focused on using Reinforcement Learning(RL) based methods to tackle the TSC problem, it possesses constraints such as unpredictable training duration and risks of online exploration, limiting its real-world deployment. Recently, offline RL has emerged as a new solution by transitioning from learning through online interactions to deriving policies from pre-collected datasets, which guarantees a safer and more efficient learning process. However, existing offline methods overlook the crucial temporal and spatial intricacy among data from different traffic signals at different timesteps, which leads to suboptimal performance. To this end, in this paper, we present an innovative formulation of the offline TSC problem by introducing a spatio-temporal graph to model the historical Markov Decision Process sequences across all traffic signals within the road network. Along this line, we propose STLight, a novel spatio-temporal sequence modeling approach to predict optimal actions for the signals from historical data, accounting for the inherent inter-dependencies among them. Specifically, we incorporate a spatio-temporal encoder to represent states, actions, and returns by capturing dynamic and spatially dependent information. The ordered space-time-aware representations are further fed to the Action Decoder to predict signal phase actions in an auto-regressive manner, accounting for the hidden dependencies between the actions and the reward and state tokens. Furthermore, to adaptively handle tasks with different levels of congestion scenarios, we incorporate space-aware return-based contrastive learning to automatically differentiate data samples with disparate traffic flow patterns. Finally, extensive experiments conducted on two public real-world traffic datasets clearly demonstrate the superior performance of the proposed model over both the state-of-the-art online and offline traffic signal control baselines.|交通信号控制（Traffic Signal Control, TSC）是交通领域中一个关键且具有挑战性的研究方向，旨在通过优化来自不同流入方向的车辆流量来缓解城市交叉口的拥堵问题。尽管已有大量研究集中在使用基于强化学习（Reinforcement Learning, RL）的方法来解决TSC问题，但这类方法存在训练时长不可预测和在线探索风险等限制，阻碍了其在实际场景中的广泛应用。近年来，离线强化学习（Offline RL）作为一种新的解决方案崭露头角，它将学习方式从在线交互转变为从预收集的数据集中推导策略，从而确保了更安全、更高效的学习过程。然而，现有的离线方法忽略了不同时间步下不同交通信号数据之间的关键时空复杂性，导致性能表现不佳。

为此，本文提出了一种创新的离线TSC问题建模方法，通过引入时空图来建模路网内所有交通信号的历史马尔可夫决策过程（Markov Decision Process, MDP）序列。在此基础上，我们提出了STLight，一种新颖的时空序列建模方法，用于从历史数据中预测信号的最优动作，同时考虑它们之间的固有相互依赖性。具体而言，我们设计了一个时空编码器，通过捕捉动态和空间依赖的信息来表示状态、动作和回报。这些有序的时空感知表示进一步被输入到动作解码器中，以自回归的方式预测信号相位动作，同时考虑动作与奖励及状态标记之间的隐含依赖关系。此外，为了自适应地处理不同拥堵场景的任务，我们引入了基于空间感知回报的对比学习机制，以自动区分具有不同交通流模式的数据样本。

最后，我们在两个公开的真实世界交通数据集上进行了广泛的实验，结果清晰地表明，所提出的模型在性能上显著优于当前最先进的在线和离线交通信号控制基线方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spatio-Temporal+Sequence+Modeling+for+Traffic+Signal+Control)|0|
|[SurvReLU: Inherently Interpretable Survival Analysis via Deep ReLU Networks](https://doi.org/10.1145/3627673.3679947)|Xiaotong Sun, Peijie Qiu, Shengfan Zhang||Survival analysis models time-to-event distributions with censorship. Recently, deep survival models using neural networks have dominated due to their representational power and state-of-the-art performance. However, their "black-box" nature hinders interpretability, which is crucial in real-world applications. In contrast, "white-box" tree-based survival models offer better interpretability but struggle to converge to global optima due to greedy expansion. In this paper, we bridge the gap between previous deep survival models and traditional tree-based survival models through deep rectified linear unit (ReLU) networks. We show that a deliberately constructed deep ReLU network (SurvReLU) can harness the interpretability of tree-based structures with the representational power of deep survival models. Empirical studies on both simulated and real survival benchmark datasets show the effectiveness of the proposed SurvReLU in terms of performance and interoperability. The code is available at \href{https://github.com/xs018/SurvReLU}{\color{magenta}{ https://github.com/xs018/SurvReLU}}.|生存分析用于建模带有删失的事件时间分布。近年来，基于神经网络的深度生存模型因其强大的表示能力和最先进的性能而占据主导地位。然而，它们的“黑箱”特性阻碍了可解释性，而可解释性在实际应用中至关重要。相比之下，基于树的“白箱”生存模型提供了更好的可解释性，但由于贪婪扩展策略，难以收敛到全局最优解。本文通过深度整流线性单元（ReLU）网络，弥合了先前的深度生存模型与传统基于树的生存模型之间的差距。我们证明，精心构建的深度ReLU网络（SurvReLU）能够结合基于树结构的可解释性和深度生存模型的表示能力。在模拟和真实生存基准数据集上的实验研究表明，所提出的SurvReLU在性能和可解释性方面均表现出色。代码可在 \href{https://github.com/xs018/SurvReLU}{\color{magenta}{ https://github.com/xs018/SurvReLU}} 获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SurvReLU:+Inherently+Interpretable+Survival+Analysis+via+Deep+ReLU+Networks)|0|
|[Over-penalization for Extra Information in Neural IR Models](https://doi.org/10.1145/3627673.3679975)|Kota Usuha, Makoto P. Kato, Sumio Fujita|LY Corporation, Tokyo, Japan; University of Tsukuba, Tsukuba, Japan|This paper presents our analysis of neural IR models, particularly focusing on over-penalization for extra information (OPEX) - a phenomenon where addition of a sentence to a document causes an unreasonable decline in the document rank. We found that neural IR models suffered from OPEX, especially when the added sentence is similar to the other sentences in the document. To mitigate OPEX, we propose to apply a window-based scoring approach that segments a document and aggregates scores of the segments to compute the overall document score. We theoretically proved that the window-based scoring approach fully suppressed OPEX in an extreme case where each segment contains only a single sentence, and empirically showed that this approach mitigated OPEX. The code is available at https://github.com/argonism/OPEX .|本文对神经信息检索（IR）模型进行了分析，特别关注了“对额外信息的过度惩罚”（Over-Penalization for Extra Information, OPEX）这一现象——即当向文档中添加一个句子时，文档的排名会不合理地下降。我们发现，神经IR模型普遍存在OPEX问题，尤其是在添加的句子与文档中其他句子相似的情况下。为了缓解OPEX，我们提出了一种基于窗口的评分方法，该方法将文档分段并聚合各段的评分以计算文档的整体评分。我们从理论上证明了，在极端情况下（即每个段仅包含一个句子），基于窗口的评分方法能够完全抑制OPEX，并通过实验验证了该方法确实能够缓解OPEX现象。相关代码已开源，详见：https://github.com/argonism/OPEX。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Over-penalization+for+Extra+Information+in+Neural+IR+Models)|0|
|[Enhancing Temporal and Geographical Named Entity Recognition in Chinese Ancient Texts with External Time-series Knowledge Bases](https://doi.org/10.1145/3627673.3679917)|Xiaotong Wang, Xuanning Liu, Shuai Zhong, Xinming Chen, Bin Wu|Beijing University of Posts and Telecommunications, Beijing, China|In the field of ancient Chinese text, extracting and analysing temporal and geographic information are crucial for understanding the personal experiences of historical figures, the development of historical events, and the overall historical background. Currently, named entity recognition(NER) strategies such as BERT+CRF are used to extract temporal and geographic information from ancient Chinese text. However, ancient Chinese text covers a vast time span, and the temporal and geographic entities constantly evolve and change, making it difficult to extract these entities from text. This paper proposes a temporal and geographic extraction model for ancient Chinese text, enhanced by time-series external knowledge base. The extraction of proprietary nouns and general structures are divided into two independent networks. An external database is applied to enhance extraction of proprietary nouns and reduce noise for general structure inference. We constructed address trees and chronological tables containing commonly used places and time-related keywords from different periods and collected 12,000 texts spanning 3,000 years for extensive training. Overall, our research highlights the importance of external knowledge base for ancient Chinese NER, and provides new ideas for research in related fields.|在古代汉语文本领域，提取和分析时间与地理信息对于理解历史人物的个人经历、历史事件的发展以及整体历史背景至关重要。目前，诸如BERT+CRF等命名实体识别（NER）策略被用于从古代汉语文本中提取时间和地理信息。然而，古代汉语文本跨越了广阔的时间跨度，时间和地理实体不断演变和变化，使得从文本中提取这些实体变得困难。本文提出了一种增强版的时间序列外部知识库的古代汉语文本时间与地理信息提取模型。该模型将专有名词和通用结构的提取分为两个独立的网络。通过应用外部数据库来增强专有名词的提取，并减少通用结构推理中的噪声。我们构建了包含不同时期常用地点和时间相关关键词的地址树和年代表，并收集了跨越3000年的12000篇文本进行广泛训练。总体而言，我们的研究强调了外部知识库在古代汉语NER中的重要性，并为相关领域的研究提供了新的思路。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Temporal+and+Geographical+Named+Entity+Recognition+in+Chinese+Ancient+Texts+with+External+Time-series+Knowledge+Bases)|0|
|[Does Knowledge Localization Hold True? Surprising Differences Between Entity and Relation Perspectives in Language Models](https://doi.org/10.1145/3627673.3679900)|Yifan Wei, Xiaoyan Yu, Yixuan Weng, Huanhuan Ma, Yuanzhe Zhang, Jun Zhao, Kang Liu||Large language models encapsulate knowledge and have demonstrated superior performance on various natural language processing tasks. Recent studies have localized this knowledge to specific model parameters, such as the MLP weights in intermediate layers. This study investigates the differences between entity and relational knowledge through knowledge editing. Our findings reveal that entity and relational knowledge cannot be directly transferred or mapped to each other. This result is unexpected, as logically, modifying the entity or the relation within the same knowledge triplet should yield equivalent outcomes. To further elucidate the differences between entity and relational knowledge, we employ causal analysis to investigate how relational knowledge is stored in pre-trained models. Contrary to prior research suggesting that knowledge is stored in MLP weights, our experiments demonstrate that relational knowledge is also significantly encoded in attention modules. This insight highlights the multifaceted nature of knowledge storage in language models, underscoring the complexity of manipulating specific types of knowledge within these models.|大型语言模型蕴含了丰富的知识，并在各种自然语言处理任务中展现了卓越的性能。最近的研究将这些知识定位到特定的模型参数中，例如中间层的多层感知机（MLP）权重。本研究通过知识编辑探讨了实体知识与关系知识之间的差异。我们的研究发现，实体知识与关系知识无法直接相互转移或映射。这一结果出乎意料，因为在逻辑上，修改同一知识三元组中的实体或关系应当产生等价的结果。为了进一步阐明实体知识与关系知识之间的差异，我们采用因果分析方法来研究关系知识在预训练模型中的存储方式。与之前的研究认为知识仅存储在MLP权重中的观点不同，我们的实验表明，关系知识在注意力模块中也得到了显著编码。这一发现揭示了语言模型中知识存储的多面性，凸显了在这些模型中操纵特定类型知识的复杂性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Does+Knowledge+Localization+Hold+True?+Surprising+Differences+Between+Entity+and+Relation+Perspectives+in+Language+Models)|0|
|[DP-FedFace: Privacy-Preserving Facial Recognition in Real Federated Scenarios](https://doi.org/10.1145/3627673.3679901)|Wenjing Wang, Si Li|Beijing University of Posts and Telecommunications, Beijing Shi, Haidian Qu, China|Advanced deep learning-based face recognition models require extensive datasets for optimal performance. However, increasing privacy concerns drive the limitation of face image access on devices to prevent personal information leaks. To address this, federated learning, which allows decentralized data collaboration, has gained popularity. However, traditional federated learning methods risk privacy by transmitting identity proxies to servers. We propose DP-FedFace, a privacy framework specifically designed for a realistic scenario where each client contains only the owner's face images (one identity per client). It uses the difference between human and model perception to eliminate visualization-critical low-frequency components, thus protecting user privacy. We also introduce a novel, learnable privacy cost allocation mechanism that optimizes allocation strategies and adds noise to frequency domain features. Extensive experiments demonstrate that DP-FedFace maintains high recognition accuracy while offers robust privacy protection.|基于深度学习的先进人脸识别模型需要大量数据集才能达到最佳性能。然而，日益增长的隐私问题推动了对设备上人脸图像访问的限制，以防止个人信息泄露。为了解决这一问题，联邦学习（允许分散式数据协作）变得越来越受欢迎。然而，传统的联邦学习方法通过向服务器传输身份代理存在隐私风险。我们提出了DP-FedFace，这是一个专为现实场景设计的隐私保护框架，其中每个客户端仅包含拥有者的人脸图像（每个客户端一个身份）。它利用人类感知与模型感知之间的差异，消除对可视化至关重要的低频成分，从而保护用户隐私。我们还引入了一种新颖的可学习隐私成本分配机制，该机制优化了分配策略，并向频域特征添加噪声。大量实验表明，DP-FedFace在保持高识别准确性的同时，提供了强大的隐私保护。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DP-FedFace:+Privacy-Preserving+Facial+Recognition+in+Real+Federated+Scenarios)|0|
|[Attentional Neural Integral Equation for Temporal Knowledge Graph Forecasting](https://doi.org/10.1145/3627673.3679876)|Likang Xiao, Zijie Chen, Richong Zhang, Junfan Chen|Beihang University, Haidian Qu, Beijing, China; University of Toronto, Toronto, Ontario, Canada|Temporal Knowledge Graph Forecasting (TKGF) aims to forecast the missing entities or relations at a specific timestamp when only the historical information is observed. It is crucial to accurately identify the historical information of complex temporal relational graphs related to the query. Existing works, e.g., TANGO, have exploited the Neural Ordinary Differential Equation (NODE) to TKGF. However, TANGO encounters two limitations. First, TANGO observes historical facts with only one timestamp at each step, leading to a long-term forgetting problem. Second, TANGO gives the same weight to the entire history graph, including facts that are not relevant to the query. To tackle the above limitations, this paper utilizes Attentional Neural Integral Equation for TKGF (tIE), enabling the global interaction between query-related historical graph sequences. To achieve this, we employ the Relational Graph Convolutional Network and Fourier-type Transformer to model the graph structure and temporal evolution of TKG. The Iterative Integral Equation Solver is exploited to enhance the accuracy and robustness of numerical solutions. The proposed method outperforms baseline models regarding several metrics and inference speed on four benchmark datasets, especially on the long horizontal link forecasting task with irregular time intervals.|时序知识图谱预测（Temporal Knowledge Graph Forecasting, TKGF）旨在仅基于历史信息预测特定时间戳下缺失的实体或关系。准确识别与查询相关的复杂时序关系图的历史信息至关重要。现有工作，例如TANGO，已尝试将神经常微分方程（Neural Ordinary Differential Equation, NODE）应用于TKGF。然而，TANGO存在两个局限性。首先，TANGO在每一步仅观察具有单一时间戳的历史事实，导致长期遗忘问题。其次，TANGO对整个历史图赋予相同的权重，包括与查询无关的事实。为了解决上述局限性，本文提出了一种基于注意力神经积分方程的TKGF方法（tIE），实现了与查询相关的历史图序列之间的全局交互。为实现这一目标，我们采用关系图卷积网络（Relational Graph Convolutional Network）和傅里叶型Transformer（Fourier-type Transformer）来建模时序知识图谱的图结构和时间演化。通过迭代积分方程求解器（Iterative Integral Equation Solver）增强数值解的准确性和鲁棒性。所提出的方法在四个基准数据集上的多项指标和推理速度上均优于基线模型，尤其是在具有不规则时间间隔的长水平链接预测任务中表现突出。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Attentional+Neural+Integral+Equation+for+Temporal+Knowledge+Graph+Forecasting)|0|
|[MPHDetect: Multi-View Prompting and Hypergraph Fusion for Malevolence Detection in Dialogues](https://doi.org/10.1145/3627673.3679966)|Bo Xu, Xuening Qiao, Hongfei Lin, Linlin Zong|School of Computer Science and Technology, Dalian University Of Technology, Dalian, China; School of Software, Dalian University of Technology, Dalian, China; School of Computer Science and Technology, Dalian University of Technology, Dalian, China|Malevolence detection in dialogues aims to identify harmful or inappropriate utterances, significantly impacting dialogue quality and user satisfaction. Although existing studies have shown promising performance by modeling interaction patterns from dialogue history, various malevolence-invoking factors, such as fine-grained emotions, evolving topics and user profiles, are often overlooked. To comprehensively consider these factors, we propose a hypergraph fusion model by employing multi-view LLM-driven prompts for malevolence detection in dialogues. Our model integrates emotion context, topic context, user profile context and interaction context, utilizing hypergraphs to establish high-order contextual relationships from multi views for deducing malevolence-invoking semantics. Experimental results on two benchmark datasets demonstrate that our model achieves the state-of-the-art performance.|对话中的恶意检测旨在识别有害或不恰当的言论，这对对话质量和用户满意度有显著影响。尽管现有研究通过建模对话历史中的交互模式取得了良好的性能，但诸如细粒度情绪、演变话题和用户画像等多种引发恶意的因素往往被忽视。为了全面考虑这些因素，我们提出了一种超图融合模型，通过采用多视角大语言模型（LLM）驱动的提示来进行对话中的恶意检测。我们的模型整合了情绪上下文、话题上下文、用户画像上下文和交互上下文，利用超图从多视角建立高阶上下文关系，以推断引发恶意的语义。在两个基准数据集上的实验结果表明，我们的模型达到了最先进的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MPHDetect:+Multi-View+Prompting+and+Hypergraph+Fusion+for+Malevolence+Detection+in+Dialogues)|0|
|[SparseBF: Enhancing Scalability and Efficiency for Sparsely Filled Privacy-Preserving Record Linkage](https://doi.org/10.1145/3627673.3679997)|Han Xu, Yuhong Shao, Kareem Benaissa, Yutong Li|University of Illinois at Urbana-Champaign, Champaign, IL, USA; University of Illinois at Urbana-Champaign, Urbana, IL, USA|Bloom filter (BF) encodings are a proven method for comparing the similarity of records from multiple databases while maintaining privacy. This process, known as privacy-preserving record linkage (PPRL), is computationally expensive, especially with large datasets. To address this challenge, we have observed that BF encodings often exhibit sparsely filled patterns. Leveraging this insight, we introduce SparseBF, a scalable data structure that is space-optimized and maintains fast computation speed for PPRL. Compared to typical BF encodings, SparseBF brings in three improvements. First, SparseBF employs a hybrid storage scheme that selects the optimal storage component for BF encodings. Second, SparseBF utilizes its adaptive compressed sparse row storage to achieve lossless space compression, both when BFs are sparsely occupied and when they are densely populated. Third, SparseBF supports SIMD vector instructions to optimize the record linkage speed. Experiments show that, in sparsely filled scenarios, SparseBF outperforms the existing solution by up to 2.1x record linkage computation speed, while delivering up to 70.5% savings in storage space.|布隆过滤器（Bloom Filter, BF）编码是一种经过验证的方法，用于在保护隐私的前提下比较来自多个数据库的记录相似性。这一过程被称为隐私保护记录链接（Privacy-Preserving Record Linkage, PPRL），其计算成本较高，尤其是在处理大规模数据集时。为了解决这一挑战，我们观察到BF编码通常表现出稀疏填充的模式。基于这一发现，我们提出了SparseBF，这是一种空间优化且保持快速计算速度的可扩展数据结构，专门用于PPRL。与典型的BF编码相比，SparseBF带来了三项改进。首先，SparseBF采用混合存储方案，为BF编码选择最优的存储组件。其次，SparseBF利用其自适应压缩稀疏行存储技术，实现了无损空间压缩，无论BF是稀疏填充还是密集填充都能适用。第三，SparseBF支持SIMD向量指令集，以优化记录链接的速度。实验表明，在稀疏填充的场景下，SparseBF的记录链接计算速度比现有解决方案快至2.1倍，同时节省了高达70.5%的存储空间。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SparseBF:+Enhancing+Scalability+and+Efficiency+for+Sparsely+Filled+Privacy-Preserving+Record+Linkage)|0|
|[Learning Counterfactual Explanations with Intervals for Time-series Classification](https://doi.org/10.1145/3627673.3679952)|Akihiro Yamaguchi, Ken Ueno, Ryusei Shingaki, Hisashi Kashima|Department of Intelligence Science and Technology, Kyoto University, Kyoto, Japan; Corporate R&D Center, Toshiba Corporation, Kawasaki, Japan|The need for explainability in time-series classification models has been increasing. Counterfactual explanations recommend how to modify the features of an original instance so that the prediction by a given classifier flips to the desired class. Since features in the time series are temporally dependent, interpretability is improved by considering intervals where the counterfactual can deviate from the original instance. In this study, we propose a model-agnostic counterfactual generation method (CEI) that jointly learns these intervals and the counterfactual. Furthermore, CEI can generate a counterfactual tailored to the directly specified limited number of intervals. We mathematically formulate CEI as a continuous optimization and demonstrate its effectiveness on the UCR datasets.|时间序列分类模型的可解释性需求日益增加。反事实解释（Counterfactual Explanations）建议如何修改原始实例的特征，以使给定分类器的预测结果翻转到期望的类别。由于时间序列中的特征具有时间依赖性，通过考虑反事实可以与原始实例偏离的时间间隔，可以提升模型的可解释性。在本研究中，我们提出了一种模型无关的反事实生成方法（CEI），该方法能够同时学习这些时间间隔和反事实。此外，CEI可以生成针对直接指定的有限数量时间间隔量身定制的反事实。我们将CEI数学公式化为一个连续优化问题，并在UCR数据集上验证了其有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Counterfactual+Explanations+with+Intervals+for+Time-series+Classification)|0|
|[GeoReasoner: Reasoning On Geospatially Grounded Context For Natural Language Understanding](https://doi.org/10.1145/3627673.3679934)|Yibo Yan, Joey Lee||In human reading and communication, individuals tend to engage in geospatial reasoning, which involves recognizing geographic entities and making informed inferences about their interrelationships. To mimic such cognitive process, current methods either utilize conventional natural language understanding toolkits, or directly apply models pretrained on geo-related natural language corpora. However, these methods face two significant challenges: i) they do not generalize well to unseen geospatial scenarios, and ii) they overlook the importance of integrating geospatial context from geographical databases with linguistic information from the Internet. To handle these challenges, we propose GeoReasoner, a language model capable of reasoning on geospatially grounded natural language. Specifically, it first leverages Large Language Models (LLMs) to generate a comprehensive location description based on linguistic and geospatial information. It also encodes direction and distance information into spatial embedding via treating them as pseudo-sentences. Consequently, the model is trained on both anchor-level and neighbor-level inputs to learn geo-entity representation. Extensive experimental results demonstrate GeoReasoner's superiority in three tasks: toponym recognition, toponym linking, and geo-entity typing, compared to the state-of-the-art baselines.|在人类阅读和交流过程中，个体倾向于进行地理空间推理，这包括识别地理实体并对其相互关系做出有依据的推断。为了模拟这种认知过程，现有方法要么利用传统的自然语言理解工具包，要么直接应用在涉及地理的自然语言语料库上预训练的模型。然而，这些方法面临两个主要挑战：i) 它们对未见过的地理空间场景的泛化能力不强；ii) 它们忽视了将来自地理数据库的地理空间上下文与来自互联网的语言信息相结合的重要性。为了应对这些挑战，我们提出了GeoReasoner，一个能够对基于地理空间的自然语言进行推理的语言模型。具体而言，它首先利用大型语言模型（LLMs）基于语言和地理空间信息生成全面的位置描述。它还将方向和距离信息通过视为伪句子的方式编码到空间嵌入中。因此，模型在锚点级别和邻居级别的输入上进行训练，以学习地理实体表示。大量实验结果表明，与最先进的基线方法相比，GeoReasoner在地名识别、地名链接和地理实体类型化三个任务中均表现出优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GeoReasoner:+Reasoning+On+Geospatially+Grounded+Context+For+Natural+Language+Understanding)|0|
|[Multi-Scale Contrastive Attention Representation Learning for Encrypted Traffic Classification](https://doi.org/10.1145/3627673.3679968)|Shuo Yang, Xinran Zheng, Jinze Li, Jinfeng Xu, Edith C. H. Ngai|The Univerisity of Hong Kong, Hong Kong SAR, China; The University of Hong Kong, Hong Kong SAR, China; Tsinghua University, Beijing, China|Encrypted traffic classification is essential for network security and management. However, the encrypted nature makes it challenging to extract representative features from raw traffic data. Existing end-to-end methods ignore byte correlations within packets and potential correlations among packets, hindering the learning of real traffic semantics and leading to suboptimal performance. This paper proposes MsETC, a multi-scale contrastive attention representation learning method for encrypted traffic classification. MsETC divides the raw packet byte sequence into multi-scale patches and then extracts dual views for contrastive learning from both the inter-patch and intra-patch perspectives. This allows the model to capture correlations among bytes within a packet as well as the potential interactions between packets. Extensive experiments on real-world datasets demonstrate that the proposed method achieves superior classification performance with lower complexity.|加密流量分类对于网络安全和管理至关重要。然而，加密的特性使得从原始流量数据中提取代表性特征变得具有挑战性。现有的端到端方法忽略了数据包内部的字节相关性以及数据包之间的潜在相关性，阻碍了对真实流量语义的学习，导致性能不佳。本文提出了MsETC，一种用于加密流量分类的多尺度对比注意力表示学习方法。MsETC将原始数据包字节序列划分为多尺度片段，然后从片段间和片段内两个视角提取双视图进行对比学习。这使得模型能够捕捉数据包内字节之间的相关性以及数据包之间的潜在交互。在真实数据集上的大量实验表明，所提出的方法以较低的复杂度实现了优越的分类性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Scale+Contrastive+Attention+Representation+Learning+for+Encrypted+Traffic+Classification)|0|
|[You Can't Ignore Either: Unifying Structure and Feature Denoising for Robust Graph Learning](https://doi.org/10.1145/3627673.3680007)|Tianmeng Yang, Jiahao Meng, Min Zhou, Yaming Yang, Yujing Wang, Xiangtai Li, Yunhai Tong||Recent research on the robustness of Graph Neural Networks (GNNs) under noises or attacks has attracted great attention due to its importance in real-world applications. Most previous methods explore a single noise source, recovering corrupt node embedding by reliable structures bias or developing structure learning with reliable node features. However, the noises and attacks may come from both structures and features in graphs, making the graph denoising a dilemma and challenging problem. In this paper, we develop a unified graph denoising (UGD) framework to unravel the deadlock between structure and feature denoising. Specifically, a high-order neighborhood proximity evaluation method is proposed to recognize noisy edges, considering features may be perturbed simultaneously. Moreover, we propose to refine noisy features with reconstruction based on a graph auto-encoder. An iterative updating algorithm is further designed to optimize the framework and acquire a clean graph, thus enabling robust graph learning for downstream tasks. Our UGD framework is self-supervised and can be easily implemented as a plug-and-play module. We carry out extensive experiments, which proves the effectiveness and advantages of our method. Code is avalaible at https://github.com/YoungTimmy/UGD.|近年来，关于图神经网络（GNNs）在噪声或攻击下的鲁棒性研究因其在实际应用中的重要性而引起了广泛关注。以往的大多数方法仅探索单一噪声源，通过可靠的结构偏差恢复损坏的节点嵌入，或利用可靠的节点特征进行结构学习。然而，噪声和攻击可能同时来自图的结构和特征，这使得图去噪成为一个两难且具有挑战性的问题。在本文中，我们开发了一个统一的图去噪（UGD）框架，以解决结构和特征去噪之间的僵局。具体而言，考虑到特征可能同时受到干扰，我们提出了一种高阶邻域邻近性评估方法来识别噪声边。此外，我们提出基于图自编码器的重构来精炼噪声特征。进一步设计了一种迭代更新算法来优化框架并获得干净的图，从而为下游任务提供鲁棒的图学习能力。我们的UGD框架是自监督的，并且可以轻松实现为即插即用模块。我们进行了广泛的实验，证明了该方法的有效性和优势。代码可在 https://github.com/YoungTimmy/UGD 获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=You+Can't+Ignore+Either:+Unifying+Structure+and+Feature+Denoising+for+Robust+Graph+Learning)|0|
|[CAG: A Consistency-Adaptive Text-Image Alignment Generation for Joint Multimodal Entity-Relation Extraction](https://doi.org/10.1145/3627673.3679883)|Xinjie Yang, Xiaocheng Gong, Binghao Tang, Yang Lei, Yayue Deng, Huan Ouyang, Gang Zhao, Lei Luo, Yunling Feng, Bin Duan, Si Li, Yajing Xu|; Beijing University of Posts and Telecommunications, Beijing, China|Joint Multimodal Entity-Relation Extraction (JMERE) aims to extract entity-relationship triples in texts from given image-text pairs. As a joint multimodal information extraction task, it has attracted increasing research interest. Previous works of JMERE typically utilize graph networks to align textual entities and visual objects and achieve promising performance. However, these methods do not pay attention to the inconsistency between text and image and the straight alignment could limit the performance of JMERE models. In this paper, we propose a Consistency-adaptive text-image Alignment Generation (CAG) framework for various text-image consistency scenarios. Specifically, we propose a Consistency Factor (CF) to measure the consistency between images and texts. We also design consistency-adaptive contrastive learning based on CF, which can reduce the impact of inconsistent visual and textual information. Additionally, we adopt JMERE-specifical instruction tuning for better entity-relationship triplet generation. Experimental results on the JMERE dataset demonstrate that our proposed CAG is effective and achieves state-of-the-art performance.|联合多模态实体-关系抽取（JMERE）旨在从给定的图像-文本对中提取文本中的实体-关系三元组。作为一个联合多模态信息抽取任务，它吸引了越来越多的研究兴趣。以往的JMERE工作通常利用图网络来对齐文本实体和视觉对象，并取得了良好的性能。然而，这些方法并未关注文本与图像之间的不一致性，直接的对齐可能会限制JMERE模型的性能。在本文中，我们提出了一种适用于不同文本-图像一致性场景的一致性自适应文本-图像对齐生成（CAG）框架。具体来说，我们提出了一致性因子（CF）来度量图像与文本之间的一致性。我们还设计了基于CF的一致性自适应对比学习，以减少不一致的视觉和文本信息的影响。此外，我们采用JMERE特定的指令微调以更好地生成实体-关系三元组。在JMERE数据集上的实验结果表明，我们提出的CAG是有效的，并达到了最先进的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CAG:+A+Consistency-Adaptive+Text-Image+Alignment+Generation+for+Joint+Multimodal+Entity-Relation+Extraction)|0|
|[Robust Heterophily Graph Learning via Uniformity Augmentation](https://doi.org/10.1145/3627673.3679991)|Xusheng Yang, Zhengyu Chen, Yuexian Zou|Meituan, Beijing, China; Peking University, Shenzhen, China|Graphs serve as fundamental representations for a diverse array of complex systems, capturing intricate relationships and interactions between entities. In many real-world scenarios, graphs exhibit non-homophilous, or heterophilous, characteristics, challenging traditional graph analysis methods rooted in homophily assumptions. Recent heterophilous methods frequently struggle with noise in node attributes, which can degrade the quality of graph representations and affect downstream task performance. Common graph augmentations, while useful, often introduce bias and irrelevant noise. This paper proposes a novel method, Robust Heterophily Graph Learning via Uniformity Augmentation (RHGL-UA), which incorporates uniformity in the augmentation process through controlled random perturbations. This approach ensures a more uniform distribution of representations across different layers of the model. By adapting to data variations and learning more diverse information, RHGL-UA significantly improves performance on downstream tasks and stands out as the first practical robust heterophily graph method using representation augmentation with a theoretical guarantee. Extensive experiments demonstrate the merit of our proposed method.|图作为多种复杂系统的基础表示形式，能够捕捉实体之间复杂的关系和交互。在许多现实场景中，图表现出非同质性（或称异质性）特征，这对基于同质性假设的传统图分析方法提出了挑战。现有的异质性方法在处理节点属性中的噪声时常常表现不佳，这些噪声可能会降低图表示的质量并影响下游任务的性能。常用的图增强方法虽然有用，但往往会引入偏差和不相关的噪声。本文提出了一种新颖的方法，即通过均匀增强实现鲁棒异质性图学习（RHGL-UA），该方法通过在增强过程中引入受控的随机扰动来确保表示的均匀分布。这种方法能够适应数据的变化并学习更多样化的信息，从而显著提升下游任务的性能，并成为首个具有理论保证的、使用表示增强的实用鲁棒异质性图方法。大量实验证明了我们提出的方法的优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Heterophily+Graph+Learning+via+Uniformity+Augmentation)|0|
|[Multi-Stage Refined Visual Captioning for Baidu Ad Creatives Generation](https://doi.org/10.1145/3627673.3679969)|Yi Yang, Xinyu Zhao, Kang Zhao, Zhipeng Jin, Wen Tao, Lin Liu, Shuanglong Li|Baidu Search Ads, Baidu Inc., Beijing, China|High-quality multimodal training data is of critical importance for improving of multimodal model performance. However, the utilization of web-crawled vision-caption pairs is hindered by the presence of noise and irrelevance, as well as a lack of Chinese data. Large Language Models (LLM) and Large Multimodal Models (LMM) has demonstrated promising performance in cross-modal understanding and generation. In light of this, we propose a Chinese visual captioning pipeline for the synthesis of high-quality data. Our pipeline is comprised of two phases: the initial training of an encoder for visual understanding; and the subsequent fine-tuning of a captioning model in a two-stage iterative human-in-the-loop process, where the captioning model incorporates the pre-trained vision encoder and LLM by a visual cross-attention querying transformer. Extensive experiments have been conducted to validate our framework, including both quantitative and qualitative evaluation of captions generated from images and videos. The synthesis pipeline has been integrated into the ad image creative generation process in Baidu Search Ads, resulting in enhanced capabilities in prompt following.|高质量的多模态训练数据对于提升多模态模型的性能至关重要。然而，网络爬取的视觉-文本对数据由于存在噪声和无关内容，以及缺乏中文数据，其利用受到了限制。大型语言模型（LLM）和大型多模态模型（LMM）在跨模态理解和生成方面展现了良好的性能。鉴于此，我们提出了一种中文视觉描述生成管道，用于合成高质量数据。该管道包含两个阶段：首先是视觉理解编码器的初步训练；其次是在一个两阶段迭代的人机协作过程中对描述生成模型进行微调，其中描述生成模型通过视觉交叉注意力查询变换器整合了预训练的视觉编码器和LLM。我们进行了广泛的实验来验证我们的框架，包括对从图像和视频生成的描述进行定量和定性评估。该合成管道已集成到百度搜索广告的广告创意生成过程中，从而提升了提示跟随的能力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Stage+Refined+Visual+Captioning+for+Baidu+Ad+Creatives+Generation)|0|
|[BART-based Hierarchical Attentional Network for Sentence Ordering](https://doi.org/10.1145/3627673.3679878)|Yiping Yang, Baiyun Cui, Yingming Li|Zhejiang University, Hangzhou, China|In this paper, we introduce a novel BART-based Hierarchical Attentional Ordering Network (BHAONet), aiming to address the coherence modeling challenge within paragraphs, which stands as a cornerstone in comprehension, generation, and reasoning tasks. By leveraging the pre-trained BART model to encode the entire sequence, we can effectively exploit global semantic and contextual information. Moreover, the token-level and sentence-level hierarchical attentional layers are incorporated to encourage the model to focus on features at various levels of granularity. In addition, a transformer-guided pointer network is developed for decoding. Extensive experiments conducted on benchmark datasets demonstrate the effectiveness and superiority of our proposed model.|本文介绍了一种基于BART的新型层次化注意力排序网络（BHAONet），旨在解决段落内部的连贯性建模挑战，该挑战是理解、生成和推理任务的基石。通过利用预训练的BART模型对整个序列进行编码，我们能够有效地利用全局语义和上下文信息。此外，模型还集成了词级和句子级的层次化注意力层，以促使模型关注不同粒度级别的特征。此外，我们还开发了一种由Transformer引导的指针网络用于解码。在基准数据集上进行的大量实验证明了我们所提出模型的有效性和优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BART-based+Hierarchical+Attentional+Network+for+Sentence+Ordering)|0|
|[Span Confusion is All You Need for Chinese Spelling Correction](https://doi.org/10.1145/3627673.3679996)|Dezhi Ye, Haomei Jia, Bowen Tian, Jie Liu, Haijin Liang, Jin Ma, Wenmin Wang|Tencent, Beijing, China; Macau University of Science and Technology, Macau, China|Chinese Spelling Correction is to detect errors in a statement and correct them. Researchers have recently begun to investigate the use of pre-train language models to perform this task. They replace tokens with similar characters based on a confusion set rather than mask tokens when pre-training. A significant limitation of this method is that pre-training with single tokens cannot effectively simulate natural errors, such as full spelling. Furthermore, the confusion set consists of single characters, which lacks the contextual relationship between characters. This leads to a lower quality of generated pseudo-labeled samples. To this end, we contribute a novel approach of constructing confusion corpus, which can automatically generate high-quality spelling errors. The construction of our confusion set is based on user behavior patterns, aiming to identify characters that are easily confused in similar contexts. Then we introduce a Span Confusion Pre-Train(SCPre) strategy for Chinese Spelling Correction. The span confusion strategy replaces characters, words, and phrases in the text according to a large confusion set. Upon the constructed corpus, different models are trained and evaluated for CSC with respect to real-world datasets. Quantitative experiments on datasets show that our approach empirically achieves unprecedented performance.|中文拼写纠错旨在检测语句中的错误并进行修正。最近，研究人员开始探索使用预训练语言模型来完成这一任务。他们在预训练时基于混淆集用相似字符替换标记，而不是掩盖标记。这种方法的一个显著局限性是，单标记预训练无法有效模拟自然错误，如全拼错误。此外，混淆集仅包含单字符，缺乏字符间的上下文关系，这导致生成的伪标签样本质量较低。为此，我们提出了一种构建混淆语料库的新方法，能够自动生成高质量的拼写错误。我们的混淆集构建基于用户行为模式，旨在识别在相似上下文中容易混淆的字符。接着，我们引入了一种用于中文拼写纠错的跨度混淆预训练（SCPre）策略。该策略根据一个大型混淆集替换文本中的字符、词语和短语。在构建的语料库上，针对真实世界数据集训练并评估了不同模型的中文拼写纠错效果。数据集上的定量实验表明，我们的方法在经验上取得了前所未有的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Span+Confusion+is+All+You+Need+for+Chinese+Spelling+Correction)|0|
|[GaQR: An Efficient Generation-augmented Question Rewriter](https://doi.org/10.1145/3627673.3679930)|Oliver Young, Yixing Fan, Ruqing Zhang, Jiafeng Guo, Maarten de Rijke, Xueqi Cheng|University of Amsterdam, Amsterdam, Netherlands; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China|Query understanding is an essential part in search systems to improve the recall. Unlike prior works focusing on word expansions, in this paper, we leverage the comprehension ability of LLM to generate detailed queries from a global semantic perspective. To this end, we introduce an efficient GaQR to reformulate a question into several queries using Chain of Thought (CoT) and make it more efficient through knowledge distillation. Specifically, we first prompt a teacher model to generate indicative queries by considering answer generation one step ahead. Then, we filter out low-quality queries by validating the effectiveness of all generated queries in retrieving useful passages. Finally, we distill a student rewriter based on the verified results to improve efficiency. Our experimental results demonstrate that the rewriter improves the retrieval performance by 3% to 15% on the Miracl and NFCorpus datasets and shows good generalisation ability across different retrieval methods. Moreover, the efficiency of the rewriter after knowledge distillation is improved by as much as 5 times. Code is available at https://github.com/youngbeauty250/GaQR.|查询理解是提升搜索系统召回率的关键环节。与以往专注于词汇扩展的研究不同，本文利用大语言模型（LLM）的理解能力，从全局语义角度生成详细的查询。为此，我们提出了一种高效的GaQR方法，通过思维链（Chain of Thought, CoT）将一个问题重写为多个查询，并通过知识蒸馏进一步提升其效率。具体而言，我们首先提示教师模型在生成答案之前一步生成具有指示性的查询。接着，我们通过验证所有生成查询在检索有用段落时的有效性，过滤掉低质量查询。最后，我们基于验证结果蒸馏出一个学生重写器，以提高效率。实验结果表明，在Miracl和NFCorpus数据集上，该重写器将检索性能提升了3%至15%，并在不同检索方法中展现出良好的泛化能力。此外，经过知识蒸馏后，重写器的效率提升了多达5倍。代码可在https://github.com/youngbeauty250/GaQR获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GaQR:+An+Efficient+Generation-augmented+Question+Rewriter)|0|
|[Meta-Prompt Tuning Vision-Language Model for Multi-Label Few-Shot Image Recognition](https://doi.org/10.1145/3627673.3679963)|Feng Zhang, Wei Chen, Fei Ding, Tengjiao Wang, Dawei Lu, Jiabin Zheng|; State Grid Information and Telecommunication Group, Beijing, China|Multi-label few-shot image recognition aims to identify multiple unseen objects using only a handful of examples. Recent methods typically tune pre-trained vision-language models with shared or class-specific prompts. However, they still have drawbacks. Tuning a shared prompt is insufficient for all samples especially when the tasks are complex and tuning specific prompts for each class is inevitable to lose generalization ability, thus failing to capture diverse visual knowledge. To address these issues, we propose to meta-tune a generalized prompt pool, enabling each prompt to act as an expert for multi-label few-shot image recognition. Specifically, we first construct a diverse prompt pool to handle complex samples and tasks effectively. Then, the meta-tuning strategy is designed to learn meta-knowledge and transfer it from source tasks to target tasks, enhancing the generalization of prompts. Extensive experimental results on two widely used multi-label image recognition datasets demonstrate the effectiveness of our method.|多标签少样本图像识别的目标是通过仅有的少量示例来识别多个未见过的对象。最近的方法通常使用共享或特定类别的提示来微调预训练的视觉-语言模型。然而，这些方法仍存在一些缺陷。对于所有样本，微调一个共享提示是不够的，尤其是在任务复杂的情况下；而为每个类别微调特定提示不可避免地会丧失泛化能力，从而无法捕捉多样化的视觉知识。为了解决这些问题，我们提出了一种元微调广义提示池的方法，使每个提示都能作为多标签少样本图像识别的专家。具体而言，我们首先构建了一个多样化的提示池，以有效处理复杂的样本和任务。然后，设计了元微调策略，以学习元知识并将其从源任务迁移到目标任务，从而增强提示的泛化能力。在两个广泛使用的多标签图像识别数据集上进行的大量实验结果验证了我们方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Meta-Prompt+Tuning+Vision-Language+Model+for+Multi-Label+Few-Shot+Image+Recognition)|0|
|[Multi-view Temporal Knowledge Graph Reasoning](https://doi.org/10.1145/3627673.3679970)|Fuwei Zhang, Zhao Zhang, Fuzhen Zhuang, Zhiqiang Zhang, Jun Zhou, Deqing Wang|Institute of Artificial Intelligence, Beihang University & Zhongguancun Laboratory, Beijing, China; Independent Researcher, Beijing, China; Institute of Artificial Intelligence, Beihang University, Beijing, China; School of Computer Science, Beihang University, Beijing, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China|Temporal Knowledge Graph (TKG) reasoning is a crucial task that aims to predict future facts based on historical information. In the process of reasoning over TKGs, we identify two types of facts that need to be predicted: 1) recurring facts and 2) unknown facts. While existing models emphasize reasoning about recurring facts, they inadvertently overlook the importance of unknown facts. To make better predictions on both facts, we introduce a novel TKG reasoning model, named Multi-view Recurrent Network (MV-NET), which generates different views to capture reasoning patterns for both recurring and unknown facts. Specifically, MV-NET comprises three views: a recurring history view that captures repetitive features, an exploring history view that focuses on exploring new information for unknown facts, and a full history view that assimilates historical information comprehensively. Then, the historical information of each view is encoded by a multi-view recurrent network. To better integrate the embeddings of three views, we employ an adaptive scoring module, which consists of a query-aware attentive fusion mechanism to incorporate the predicted scores from three views, thus obtaining fused scores for prediction. Extensive experiments on three commonly used datasets demonstrate the superiority of MV-NET compared to many state-of-the-art baselines.|时序知识图谱（TKG）推理是一项关键任务，旨在基于历史信息预测未来事实。在对TKG进行推理的过程中，我们识别出两类需要预测的事实：1）重复事实和2）未知事实。尽管现有模型强调对重复事实的推理，但它们无意中忽视了未知事实的重要性。为了更好地预测这两类事实，我们提出了一种新颖的TKG推理模型，称为多视图循环网络（MV-NET），该模型通过生成不同的视图来捕捉重复事实和未知事实的推理模式。具体来说，MV-NET包含三个视图：一个捕捉重复特征的重复历史视图，一个专注于探索未知事实新信息的探索历史视图，以及一个全面吸收历史信息的完整历史视图。然后，每个视图的历史信息通过多视图循环网络进行编码。为了更好地整合三个视图的嵌入，我们采用了一个自适应评分模块，该模块包含一个查询感知的注意力融合机制，用于整合来自三个视图的预测分数，从而获得用于预测的融合分数。在三个常用数据集上进行的大量实验表明，MV-NET相较于许多现有最先进的基线模型具有显著优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-view+Temporal+Knowledge+Graph+Reasoning)|0|
|[Evolving to the Future: Unseen Event Adaptive Fake News Detection on Social Media](https://doi.org/10.1145/3627673.3679919)|Jiajun Zhang, Zhixun Li, Qiang Liu, Shu Wu, Zilei Wang, Liang Wang||With the rapid development of social media, the wide dissemination of fake news on social media is increasingly threatening both individuals and society. One of the unique challenges for fake news detection on social media is how to detect fake news on future events. Recently, numerous fake news detection models that utilize textual information and the propagation structure of posts have been proposed. Unfortunately, most of the existing approaches can hardly handle this challenge since they rely heavily on event-specific features for prediction and cannot generalize to unseen events. To address this, we introduce Future ADaptive Event-based Fake news Detection (FADE) framework. Specifically, we train a target predictor through an adaptive augmentation strategy and graph contrastive learning to obtain higher-quality features and make more accurate overall predictions. Simultaneously, we independently train an event-only predictor to obtain biased predictions. We further mitigate event bias by subtracting the event-only predictor's output from the target predictor's output to obtain the final prediction. Encouraging results from experiments designed to emulate real-world social media conditions validate the effectiveness of our method in comparison to existing state-of-the-art approaches.|随着社交媒体的快速发展，虚假新闻在社交媒体上的广泛传播日益威胁到个人和社会。社交媒体上虚假新闻检测面临的一个独特挑战是如何检测未来事件的虚假新闻。最近，许多利用文本信息和帖子传播结构的虚假新闻检测模型被提出。然而，现有的方法大多难以应对这一挑战，因为它们严重依赖特定事件的特征进行预测，无法推广到未见事件。为了解决这一问题，我们引入了未来自适应事件驱动的虚假新闻检测框架（FADE）。具体而言，我们通过自适应增强策略和图对比学习训练一个目标预测器，以获取更高质量的特征并做出更准确的总体预测。同时，我们独立训练一个仅基于事件的预测器以获得有偏见的预测。我们进一步通过从目标预测器的输出中减去仅事件预测器的输出，来缓解事件偏差，从而获得最终预测。在模拟真实社交媒体环境的实验中，令人鼓舞的结果验证了我们的方法相较于现有最先进方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Evolving+to+the+Future:+Unseen+Event+Adaptive+Fake+News+Detection+on+Social+Media)|0|
|[H2D: Hierarchical Heterogeneous Graph Learning Framework for Drug-Drug Interaction Prediction](https://doi.org/10.1145/3627673.3679936)|Ran Zhang, Xuezhi Wang, Sheng Wang, Kunpeng Liu, Yuanchun Zhou, Pengfei Wang|; Computer Network Information Center, Chinese Academy of Sciences, Beijing, China; Portland State University, Portland, OR, USA; University of Washington, Seattle, WA, USA|Accurately predicting Drug-Drug Interactions (DDIs) is critical to designing effective drug combination therapies. Recently, Artificial Intelligence (AI)-powered DDI prediction approaches have emerged as a new paradigm. However, most existing methods oversimplify the complex hierarchical structure within molecules and overlook the multi-source heterogeneous information external to molecules, limiting their modeling and predictive capabilities. To address this, we propose a H ierarchical H eterogeneous graph learning framework for D DI prediction, namely H2D. H2D employs an internal-to-external, local-to-global hierarchical perspective, exploiting intra-molecular multi-granularity structures and inter-molecular biomedical interactions to mutually enhance across hierarchical levels. Extensive experimental results demonstrate H2D's effectiveness on three real-world DDI prediction tasks (binary-class, multi-class, and multi-label). In sum, H2D achieves state-of-the-art performance in DDI prediction by leveraging the multi-scale graph structures, opening up new avenues in AI-powered DDI prediction.|准确预测药物间相互作用（Drug-Drug Interactions, DDIs）对于设计有效的药物组合疗法至关重要。近年来，基于人工智能（Artificial Intelligence, AI）的DDI预测方法已成为一种新的研究范式。然而，现有的大多数方法过度简化了分子内部的复杂层次结构，并且忽略了分子外部的多源异构信息，从而限制了其建模和预测能力。为了解决这一问题，我们提出了一种用于DDI预测的**层次化异质图学习框架**，即**H2D**。H2D采用从内部到外部、从局部到全局的层次化视角，利用分子内部的多粒度结构以及分子间的生物医学相互作用，在多个层次上实现相互增强。大量实验结果表明，H2D在三种实际DDI预测任务（二分类、多分类和多标签）中均表现出卓越的有效性。总之，H2D通过利用多尺度图结构，在DDI预测中实现了最先进的性能，为基于AI的DDI预测开辟了新的方向。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=H2D:+Hierarchical+Heterogeneous+Graph+Learning+Framework+for+Drug-Drug+Interaction+Prediction)|0|
|[In Situ Answer Sentence Selection at Web-scale](https://doi.org/10.1145/3627673.3679946)|Zeyu Zhang, Thuy Vu, Alessandro Moschitti||Current answer sentence selection (AS2) applied in open-domain question answering (ODQA) selects answers by ranking a large set of possible candidates, i.e., sentences, extracted from the retrieved text. In this paper, we present Passage-based Extracting Answer Sentence In-place (PEASI), a novel design for AS2 optimized for Web-scale setting, that, instead, computes such answer without processing each candidate individually. Specifically, we design a Transformer-based framework that jointly (i) reranks passages retrieved for a question and (ii) identifies a probable answer from the top passages in place. We train PEASI in a multi-task learning framework that encourages feature sharing between the components: passage reranker and passage-based answer sentence extractor. To facilitate our development, we construct a new Web-sourced large-scale QA dataset consisting of 800,000+ labeled passages/sentences for 60,000+ questions. The experiments show that our proposed design effectively outperforms the current state-of-the-art setting for AS2, i.e., a point-wise model for ranking sentences independently, by 6.51 in accuracy, from 48.86 efficient in computing answer sentences, requiring only 20 compared to the standard setting, i.e., reranking all possible candidates. We believe the release of PEASI, both the dataset and our proposed design, can contribute to advancing the research and development in deploying question answering services at Web scale.|当前应用于开放域问答（ODQA）中的答案句子选择（AS2）通过从检索到的文本中提取的大量候选句子进行排序来选择答案。在本文中，我们提出了一种新颖的AS2设计——基于段落的就地提取答案句子（PEASI），该设计针对Web规模的设置进行了优化，无需单独处理每个候选句子即可计算答案。具体而言，我们设计了一个基于Transformer的框架，该框架联合执行以下两个任务：（i）对检索到的与问题相关的段落进行重排序，（ii）从顶级段落中就地识别可能的答案。我们在一个多任务学习框架中训练PEASI，该框架鼓励段落重排序器和基于段落的答案句子提取器之间的特征共享。为了促进我们的开发，我们构建了一个新的Web来源的大规模问答数据集，包含60,000多个问题的800,000多个标注段落/句子。实验表明，我们提出的设计在AS2的当前最先进设置（即独立排序句子的点对点模型）的基础上，准确率提高了6.51，从48.86%提升到55.37%。此外，我们的设计在计算答案句子时更加高效，仅需要20%的计算资源，而标准设置则需要重新排序所有可能的候选句子。我们相信，PEASI的发布，包括数据集和我们提出的设计，将有助于推动在Web规模上部署问答服务的研究和开发。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=In+Situ+Answer+Sentence+Selection+at+Web-scale)|0|
|[CNN to GNN: Unsupervised Multi-level Knowledge Learning](https://doi.org/10.1145/3627673.3679887)|Ziheng Jiao, Hongyuan Zhang, Xuelong Li|Institute of Artificial Intelligence (TeleAI), China Telecom, Shanghai, China|Although graph neural networks (GNNs) can extract the latent relationship-level knowledge among the graph nodes and have achieved excellent performance in unsupervised scenarios, it is weak in learning the instance-level knowledge in contrast to the convolution neural networks (CNNs). Besides, lacking of the graph structure limits the extension of GNNs on non-graph datasets. To solve these problems, we propose a novel unsupervised multi-level knowledge fusion network. It successfully unifies the instance-level and relationship-level knowledge on the non-graph data by distillation from a pre-trained CNN teacher to a GNN student. Meanwhile, a sparse weighted strategy is designed to adaptively extract the sparse graph topology and extend the GNN on non-graph datasets. By optimization of distillation loss, the "boosted'' GNN student can learn the multi-level knowledge and extract more discriminative deep embeddings for clustering. Finally, extensive experiments show it has achieved excellent performance compared with the current methods.|尽管图神经网络（GNNs）能够提取图节点之间的潜在关系级知识，并在无监督场景中取得了优异的性能，但与卷积神经网络（CNNs）相比，它在学习实例级知识方面较弱。此外，缺乏图结构限制了GNN在非图数据集上的扩展。为了解决这些问题，我们提出了一种新颖的无监督多级知识融合网络。它通过从预训练的CNN教师网络向GNN学生网络进行知识蒸馏，成功地在非图数据上统一了实例级和关系级知识。同时，设计了一种稀疏加权策略，自适应地提取稀疏图拓扑，并将GNN扩展到非图数据集上。通过优化蒸馏损失，“增强”的GNN学生网络能够学习多级知识，并提取更具判别性的深度嵌入用于聚类。最后，大量实验表明，与现有方法相比，该方法取得了优异的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CNN+to+GNN:+Unsupervised+Multi-level+Knowledge+Learning)|0|
|[A Structural Information Guided Hierarchical Reconstruction for Graph Anomaly Detection](https://doi.org/10.1145/3627673.3679869)|Dongcheng Zou, Hao Peng, Chunyang Liu|Didi Chuxing Technology Co., Ltd., Beijing, China; Beihang University, Beijing, China|Anomalies in graphs involve attributes and structures and may occur at different levels (e.g., node or community). Existing GNN-based detection methods often merely focus on anomalies of single nodes or neighborhoods, making it hard to cope with complex and organized networks. Towards this, we propose SI-HGAD, a novel Graph Anomaly Detection (GAD) approach that utilizes hierarchical information to detect anomalies. Powered by structural information, SI-HGAD can mine an optimal graph abstraction while enabling hierarchical substructural modeling. Also, we design a Graph Transformer to mine multi-range structural and attribute patterns for nodes. The decoders reconstruct both the node attributes and the multi-level subgraphs in a bottom-up manner. Extensive experiments demonstrate the superiority of SI-HGAD.|图中的异常涉及属性和结构，并可能发生在不同层次（例如节点或社区）。现有的基于图神经网络（GNN）的检测方法通常仅关注单个节点或邻域的异常，难以应对复杂且有组织的网络。为此，我们提出了SI-HGAD，这是一种新颖的图异常检测（GAD）方法，利用层次信息来检测异常。借助结构信息，SI-HGAD能够挖掘出最优的图抽象，同时支持层次化的子结构建模。此外，我们设计了一种图Transformer来挖掘节点的多范围结构和属性模式。解码器以自底向上的方式重建节点属性和多层次子图。大量实验证明了SI-HGAD的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Structural+Information+Guided+Hierarchical+Reconstruction+for+Graph+Anomaly+Detection)|0|
|[UGAD: Universal Generative AI Detector utilizing Frequency Fingerprints](https://doi.org/10.1145/3627673.3680085)|Inzamamul Alam, Muhammad Shahid Muneer, Simon S. Woo||In the wake of a fabricated explosion image at the Pentagon, an ability to discern real images from fake counterparts has never been more critical. Our study introduces a novel multi-modal approach to detect AI-generated images amidst the proliferation of new generation methods such as Diffusion models. Our method, UGAD, encompasses three key detection steps: First, we transform the RGB images into YCbCr channels and apply an Integral Radial Operation to emphasize salient radial features. Secondly, the Spatial Fourier Extraction operation is used for a spatial shift, utilizing a pre-trained deep learning network for optimal feature extraction. Finally, the deep neural network classification stage processes the data through dense layers using softmax for classification. Our approach significantly enhances the accuracy of differentiating between real and AI-generated images, as evidenced by a 12.64 increase in accuracy and 28.43 state-of-the-art methods.|在五角大楼虚假爆炸图像事件之后，辨别真实图像与伪造图像的能力变得前所未有的重要。我们的研究引入了一种新颖的多模态方法，用于在扩散模型等新一代生成方法泛滥的背景下检测AI生成的图像。我们的方法，UGAD，包含三个关键的检测步骤：首先，我们将RGB图像转换为YCbCr通道，并应用积分径向操作以突出显著的径向特征。其次，使用空间傅里叶提取操作进行空间变换，利用预训练的深度学习网络进行最优特征提取。最后，深度神经网络分类阶段通过密集层处理数据，并使用softmax进行分类。我们的方法显著提高了区分真实图像与AI生成图像的准确性，准确率提高了12.64，超越了现有技术方法28.43。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UGAD:+Universal+Generative+AI+Detector+utilizing+Frequency+Fingerprints)|0|
|[iRAG: Advancing RAG for Videos with an Incremental Approach](https://doi.org/10.1145/3627673.3680088)|Md. Adnan Arefeen, Biplob Debnath, Md. Yusuf Sarwar Uddin, Srimat Chakradhar|University of Missouri-Kansas City NEC Laboratories America; NEC Laboratories America; University of Missouri-Kansas City|Retrieval-augmented generation (RAG) systems combine the strengths of language generation and information retrieval to power many real-world applications like chatbots. Use of RAG for understanding of videos is appealing but there are two critical limitations. One-time, upfront conversion of all content in large corpus of videos into text descriptions entails high processing times. Also, not all information in the rich video data is typically captured in the text descriptions. Since user queries are not known apriori, developing a system for video to text conversion and interactive querying of video data is challenging. To address these limitations, we propose an incremental RAG system called iRAG, which augments RAG with a novel incremental workflow to enable interactive querying of a large corpus of videos. Unlike traditional RAG, iRAG quickly indexes large repositories of videos, and in the incremental workflow, it uses the index to opportunistically extract more details from select portions of the videos to retrieve context relevant to an interactive user query. Such an incremental workflow avoids long video to text conversion times, and overcomes information loss issues due to conversion of video to text, by doing on-demand query-specific extraction of details in video data. This ensures high quality of responses to interactive user queries that are often not known apriori. To the best of our knowledge, iRAG is the first system to augment RAG with an incremental workflow to support efficient interactive querying of a large corpus of videos. Experimental results on real-world datasets demonstrate 23x to 25x faster video to text ingestion, while ensuring that latency and quality of responses to interactive user queries is comparable to responses from a traditional RAG where all video data is converted to text upfront before any user querying.|检索增强生成（Retrieval-augmented generation, RAG）系统结合了语言生成和信息检索的优势，为许多现实世界的应用（如聊天机器人）提供动力。然而，将RAG用于视频理解虽然具有吸引力，但存在两个关键限制。首先，将大规模视频库中的所有内容一次性预先转换为文本描述需要较长的处理时间。其次，丰富的视频数据中的信息通常无法完全通过文本描述捕捉。由于用户查询无法事先预知，开发一个能够进行视频到文本转换并支持视频数据交互式查询的系统具有挑战性。

为了解决这些限制，我们提出了一种名为**iRAG**的增量RAG系统，它通过引入一种新颖的增量工作流来增强RAG，从而支持对大规模视频库的交互式查询。与传统RAG不同，iRAG能够快速索引大量视频库，并在增量工作流中利用索引从视频的选定部分中动态提取更多细节，以检索与用户交互查询相关的上下文。这种增量工作流避免了长时间的视频到文本转换，并通过按需进行与查询相关的视频数据细节提取，克服了视频到文本转换导致的信息丢失问题。这确保了在用户交互查询（通常无法事先预知）中提供高质量的响应。

据我们所知，iRAG是首个通过增量工作流增强RAG的系统，支持对大规模视频库的高效交互式查询。在真实数据集上的实验结果表明，iRAG的视频到文本转换速度比传统方法快23到25倍，同时确保了对用户交互查询的响应延迟和质量与传统RAG相当（后者需要在任何用户查询之前将所有视频数据预先转换为文本）。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=iRAG:+Advancing+RAG+for+Videos+with+an+Incremental+Approach)|0|
|[Leveraging Large Language Models for Improving Keyphrase Generation for Contextual Targeting](https://doi.org/10.1145/3627673.3680093)|Xiao Bai, Xue Wu, Ivan Stojkovic, Kostas Tsioutsiouliklis|Zmaitech, Hayward, California, USA; Yahoo Research, Mountain View, California, USA|Generating a set of keyphrases that convey the main concepts discussed in a document has been applied to improve various applications including document retrieval and online advertising. The state-of-the-art approaches mostly rely on the neural sequence-to-sequence framework to generate keyphrases. However, training such deep neural networks either requires a significant amount of human efforts in obtaining ground truth keyphrases or suffers from lower quality training data derived from weakly supervised signals. More recently, pre-trained language models are fine-tuned to build more data-efficient keyphrase generation models. Yet, the documents often need to be truncated to adapt to the pre-trained context window. On the other hand, large language models (LLMs) have demonstrated impressive abilities in understanding very long text and generating answers for a wide range of natural language processing tasks, making them great candidates for improving keyphrase generation. There however is a lack of a systematic study on how to use LLMs, especially in an industrial setting that requires low generation latency. In this work, we present an empirical study to facilitate a more informed use of LLMs for keyphrase generation. We compare zero-shot and few-shot in-context learning with parameter efficient fine-tuning using a number of open-source LLMs. We show that using only a handful of well selected human annotated samples, the LLMs already outperform the fine-tuned language model baselines. When thousands of human labeled samples are available, fine-tuned large language models significantly improve the amount and the quality of the generated keyphrases. To enable efficient keyphrase generation at scale, we distill the knowledge from LLMs to a base-size language model. Our evaluation shows significant increase in user reach when the generated keyphrases are used for contextual targeting at Yahoo.|生成一组能够传达文档中讨论的主要概念的关键词已被应用于改进包括文档检索和在线广告在内的各种应用。最先进的方法主要依赖于神经序列到序列框架来生成关键词。然而，训练这样的深度神经网络要么需要大量人力来获取真实关键词，要么依赖于从弱监督信号中获得的低质量训练数据。最近，预训练的语言模型被微调以构建更高效的关键词生成模型。然而，文档通常需要被截断以适应预训练的上下文窗口。另一方面，大型语言模型（LLMs）在理解非常长的文本和为广泛自然语言处理任务生成答案方面展示了令人印象深刻的能力，使其成为改进关键词生成的理想候选者。然而，目前缺乏关于如何使用LLMs的系统研究，特别是在需要低生成延迟的工业环境中。在本研究中，我们进行了一项实证研究，以促进更明智地使用LLMs进行关键词生成。我们比较了零样本和少量样本的上下文学习与使用多个开源LLMs进行参数高效微调的效果。我们发现，仅使用少量精心挑选的人工标注样本，LLMs就已经优于微调的语言模型基线。当有数千个人工标注样本可用时，微调的大型语言模型显著提高了生成关键词的数量和质量。为了实现大规模高效的关键词生成，我们将LLMs的知识蒸馏到一个基础大小的语言模型中。我们的评估显示，当生成的关键词用于雅虎的上下文定向时，用户覆盖范围显著增加。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Large+Language+Models+for+Improving+Keyphrase+Generation+for+Contextual+Targeting)|0|
|[LLP-Bench: A Large Scale Tabular Benchmark for Learning from Label Proportions](https://doi.org/10.1145/3627673.3680032)|Anand Brahmbhatt, Mohith Pokala, Rishi Saket, Aravindan Raghuveer||In the task of Learning from Label Proportions (LLP), a model is trained ongroups (a.k.a bags) of instances and their corresponding label proportions topredict labels for individual instances. LLP has been applied pre-dominantly ontwo types of datasets - image and tabular. In image LLP, bags of fixed size arecreated by randomly sampling instances from an underlying dataset. Bags createdvia this methodology are called random bags. Experimentation on Image LLP hasbeen mostly on random bags on CIFAR-* and MNIST datasets. Despite being a verycrucial task in privacy sensitive applications, tabular LLP does not yet have aopen, large scale LLP benchmark. One of the unique properties of tabular LLP isthe ability to create feature bags where all the instances in a bag have thesame value for a given feature. It has been shown in prior research thatfeature bags are very common in practical, real world applications [Chen et. al'23, Saket et. al. '22]. In this paper, we address the lack of a open, large scale tabular benchmark.First we propose LLP-Bench, a suite of 70 LLP datasets (62 feature bag and 8random bag datasets) created from the Criteo CTR prediction and the CriteoSponsored Search Conversion Logs datasets, the former a classification and thelatter a regression dataset. These LLP datasets represent diverse ways in whichbags can be constructed from underlying tabular data. To the best of ourknowledge, LLP-Bench is the first large scale tabular LLP benchmark with anextensive diversity in constituent datasets. Second, we propose four metricsthat characterize and quantify the hardness of a LLP dataset. Using these fourmetrics we present deep analysis of the 62 feature bag datasets in LLP-Bench.Finally we present the performance of 9 SOTA and popular tabular LLP techniqueson all the 62 datasets.|在从标签比例学习（Learning from Label Proportions, LLP）任务中，模型通过训练在实例组（也称为袋）及其相应的标签比例上，来预测单个实例的标签。LLP主要应用于两种类型的数据集——图像和表格数据。在图像LLP中，通过从基础数据集中随机采样实例来创建固定大小的袋。通过这种方法创建的袋被称为随机袋。图像LLP的实验主要在CIFAR-*和MNIST数据集的随机袋上进行。尽管在隐私敏感应用中是一个非常重要的任务，表格LLP目前还没有一个公开的大规模LLP基准。表格LLP的一个独特属性是能够创建特征袋，其中袋中的所有实例在给定特征上具有相同的值。先前的研究表明，特征袋在实际应用中非常常见[Chen et al. '23, Saket et al. '22]。在本文中，我们解决了缺乏公开的大规模表格基准的问题。首先，我们提出了LLP-Bench，这是一个由70个LLP数据集（62个特征袋和8个随机袋数据集）组成的套件，这些数据集是从Criteo点击率预测和Criteo赞助搜索转化日志数据集中创建的，前者是一个分类数据集，后者是一个回归数据集。这些LLP数据集代表了从基础表格数据中构建袋的多种方式。据我们所知，LLP-Bench是第一个具有广泛多样性的表格LLP基准。其次，我们提出了四个指标来表征和量化LLP数据集的难度。使用这四个指标，我们对LLP-Bench中的62个特征袋数据集进行了深入分析。最后，我们展示了9种最先进（SOTA）和流行的表格LLP技术在所有这些62个数据集上的表现。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LLP-Bench:+A+Large+Scale+Tabular+Benchmark+for+Learning+from+Label+Proportions)|0|
|[DeepClair: Utilizing Market Forecasts for Effective Portfolio Selection](https://doi.org/10.1145/3627673.3680008)|Donghee Choi, Jinkyu Kim, Mogan Gim, Jinho Lee, Jaewoo Kang||Utilizing market forecasts is pivotal in optimizing portfolio selection strategies. We introduce DeepClair, a novel framework for portfolio selection. DeepClair leverages a transformer-based time-series forecasting model to predict market trends, facilitating more informed and adaptable portfolio decisions. To integrate the forecasting model into a deep reinforcement learning-driven portfolio selection framework, we introduced a two-step strategy: first, pre-training the time-series model on market data, followed by fine-tuning the portfolio selection architecture using this model. Additionally, we investigated the optimization technique, Low-Rank Adaptation (LoRA), to enhance the pre-trained forecasting model for fine-tuning in investment scenarios. This work bridges market forecasting and portfolio selection, facilitating the advancement of investment strategies.|利用市场预测对于优化投资组合选择策略至关重要。我们提出了DeepClair，一个用于投资组合选择的新型框架。DeepClair利用基于Transformer的时间序列预测模型来预测市场趋势，从而促进更明智和适应性更强的投资组合决策。为了将预测模型整合到深度强化学习驱动的投资组合选择框架中，我们引入了一个两步策略：首先，在市场数据上预训练时间序列模型，然后使用该模型对投资组合选择架构进行微调。此外，我们研究了优化技术——低秩适应（LoRA），以增强预训练的预测模型，使其在投资场景中进行微调。这项工作将市场预测与投资组合选择相结合，推动了投资策略的进步。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DeepClair:+Utilizing+Market+Forecasts+for+Effective+Portfolio+Selection)|0|
|[Causal Interventional Prediction System for Robust and Explainable Effect Forecasting](https://doi.org/10.1145/3627673.3680073)|Zhixuan Chu, Hui Ding, Guang Zeng, Shiyu Wang, Yiming Li||Although the widespread use of AI systems in today's world is growing, many current AI systems are found vulnerable due to hidden bias and missing information, especially in the most commonly used forecasting system. In this work, we explore the robustness and explainability of AI-based forecasting systems. We provide an in-depth analysis of the underlying causality involved in the effect prediction task and further establish a causal graph based on treatment, adjustment variable, confounder, and outcome. Correspondingly, we design a causal interventional prediction system (CIPS) based on a variational autoencoder and fully conditional specification of multiple imputations. Extensive results demonstrate the superiority of our system over state-of-the-art methods and show remarkable versatility and extensibility in practice.|尽管人工智能系统在当今世界的广泛应用日益增长，但许多现有的人工智能系统被发现存在脆弱性，这主要是由于隐藏的偏见和缺失的信息，尤其是在最常用的预测系统中。在本研究中，我们探讨了基于人工智能的预测系统的鲁棒性和可解释性。我们对效应预测任务中涉及的潜在因果关系进行了深入分析，并进一步基于处理变量、调整变量、混杂因素和结果变量建立了因果图。相应地，我们设计了一个基于变分自编码器和多重插补完全条件规范的因果干预预测系统（CIPS）。大量的实验结果证明了我们的系统相较于最先进方法的优越性，并在实践中展示了显著的通用性和可扩展性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causal+Interventional+Prediction+System+for+Robust+and+Explainable+Effect+Forecasting)|0|
|[Automated Nanoparticle Image Processing Pipeline for AI-Driven Materials Characterization](https://doi.org/10.1145/3627673.3680100)|Alexandra L. Day, Carolin B. Wahl, Roberto dos Reis, Weikeng Liao, Vinayak P. Dravid, Alok N. Choudhary, Ankit Agrawal|Northwestern University, Evanston, Illinois, USA|Recent innovations have made it possible to produce millions of distinct nanoparticles on a chip. These vast volumes of data are impossible to analyze manually, necessitating the development of automated tools. In previous work, we created a binary classification machine learning model to select quality nanoparticle images for downstream analysis. In this work, we show that adding a custom image preprocessing step before model training can produce significantly higher-performing models in a fraction of the time and make the model more robust to different image noise levels and microscope acquisition settings. The proposed image processing pipeline effectively cleans raw nanoparticle images, enhances key features, and allows us to use much lower resolution images and simpler neural network model architectures, resulting in higher performance and significant cost savings. Experiments demonstrate superior performance relative to our baseline, including a 15% improvement in recall and more than a 10% increase in accuracy. Given the high cost of downstream analysis, it is critical to minimize false positives in our application, and our best-performing model obtains a precision of 97.3% and weighted F-score of 95.9% on an unseen test set. Additionally, model training time is reduced from 15.5 hours to 32 seconds. We expect that adopting this pipeline for AI-driven automated nanoparticle characterization will offer a considerable speedup in the laboratory, allowing researchers to rapidly and accurately analyze much greater volumes of data and accelerate materials discovery.|最近的技术创新使得在芯片上生产数百万个不同的纳米颗粒成为可能。如此庞大的数据量无法通过手动方式进行分析，因此开发自动化工具变得十分必要。在之前的工作中，我们构建了一个二分类机器学习模型，用于筛选高质量的纳米颗粒图像以进行下游分析。在本研究中，我们展示了在模型训练之前添加自定义图像预处理步骤，可以在更短的时间内显著提升模型性能，并使模型对不同的图像噪声水平和显微镜采集设置具有更强的鲁棒性。所提出的图像处理流程能够有效清理原始纳米颗粒图像，增强关键特征，并允许我们使用分辨率更低的图像和更简单的神经网络模型架构，从而实现更高的性能和显著的成本节约。实验结果表明，相较于基线模型，我们的方法表现出显著优势，召回率提高了15%，准确率提升了超过10%。鉴于下游分析的高成本，在我们的应用中尽量减少误报至关重要，而我们表现最佳的模型在未见过的测试集上获得了97.3%的精确率和95.9%的加权F分数。此外，模型训练时间从15.5小时缩短至32秒。我们预计，采用这一流程用于人工智能驱动的自动化纳米颗粒表征，将在实验室中带来显著的加速，使研究人员能够快速、准确地分析更大规模的数据，并加速材料发现进程。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automated+Nanoparticle+Image+Processing+Pipeline+for+AI-Driven+Materials+Characterization)|0|
|[Parallel-friendly Spatio-Temporal Graph Learning for Photovoltaic Degradation Analysis at Scale](https://doi.org/10.1145/3627673.3680026)|Yangxin Fan, Raymond Wieser, Laura S. Bruckman, Roger H. French, Yinghui Wu|Case Western Reserve University Cleveland|We propose a novel Spatio-Temporal Graph Neural Network empowered trendanalysis approach (ST-GTrend) to perform fleet-level performance degradationanalysis for Photovoltaic (PV) power networks. PV power stations have become anintegral component to the global sustainable energy production landscape.Accurately estimating the performance of PV systems is critical to theirfeasibility as a power generation technology and as a financial asset. One ofthe most challenging problems in assessing the Levelized Cost of Energy (LCOE)of a PV system is to understand and estimate the long-term Performance LossRate (PLR) for large fleets of PV inverters. ST-GTrend integratesspatio-temporal coherence and graph attention to separate PLR as a long-term"aging" trend from multiple fluctuation terms in the PV input data. To copewith diverse degradation patterns in timeseries, ST-GTrend adopts a paralleledgraph autoencoder array to extract aging and fluctuation terms simultaneously.ST-GTrend imposes flatness and smoothness regularization to ensure thedisentanglement between aging and fluctuation. To scale the analysis to largePV systems, we also introduce Para-GTrend, a parallel algorithm to acceleratethe training and inference of ST-GTrend. We have evaluated ST-GTrend on threelarge-scale PV datasets, spanning a time period of 10 years. Our results showthat ST-GTrend reduces Mean Absolute Percent Error (MAPE) and EuclideanDistances by 34.74demonstrate that Para-GTrend can speed up ST-GTrend by up to 7.92 times. Wefurther verify the generality and effectiveness of ST-GTrend for trend analysisusing financial and economic datasets.|我们提出了一种新颖的时空图神经网络驱动的趋势分析方法（ST-GTrend），用于对光伏（PV）电力网络进行舰队级性能退化分析。光伏电站已成为全球可持续能源生产景观中不可或缺的组成部分。准确估计光伏系统的性能对于其作为发电技术和金融资产的可行性至关重要。评估光伏系统平准化能源成本（LCOE）时最具挑战性的问题之一是理解和估计大型光伏逆变器舰队的长期性能损失率（PLR）。ST-GTrend集成了时空一致性和图注意力机制，将PLR作为长期“老化”趋势从光伏输入数据中的多个波动项中分离出来。为了应对时间序列中的多样化退化模式，ST-GTrend采用并行图自编码器阵列同时提取老化和波动项。ST-GTrend施加平坦度和平滑度正则化以确保老化和波动之间的解耦。为了将分析扩展到大型光伏系统，我们还引入了Para-GTrend，一种并行算法，以加速ST-GTrend的训练和推理。我们已经在三个大规模光伏数据集上评估了ST-GTrend，时间跨度长达10年。我们的结果表明，ST-GTrend将平均绝对百分比误差（MAPE）和欧几里得距离减少了34.74%，并证明Para-GTrend可以将ST-GTrend加速高达7.92倍。我们进一步验证了ST-GTrend在使用金融和经济数据集进行趋势分析时的通用性和有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Parallel-friendly+Spatio-Temporal+Graph+Learning+for+Photovoltaic+Degradation+Analysis+at+Scale)|0|
|[GraphWeaver: Billion-Scale Cybersecurity Incident Correlation](https://doi.org/10.1145/3627673.3680057)|Scott Freitas, Amir Gharib||In the dynamic landscape of large enterprise cybersecurity, accurately andefficiently correlating billions of security alerts into comprehensiveincidents is a substantial challenge. Traditional correlation techniques oftenstruggle with maintenance, scaling, and adapting to emerging threats and novelsources of telemetry. We introduce GraphWeaver, an industry-scale frameworkthat shifts the traditional incident correlation process to a data-optimized,geo-distributed graph based approach. GraphWeaver introduces a suite ofinnovations tailored to handle the complexities of correlating billions ofshared evidence alerts across hundreds of thousands of enterprises. Key amongthese innovations are a geo-distributed database and PySpark analytics enginefor large-scale data processing, a minimum spanning tree algorithm to optimizecorrelation storage, integration of security domain knowledge and threatintelligence, and a human-in-the-loop feedback system to continuously refinekey correlation processes and parameters. GraphWeaver is integrated into theMicrosoft Defender XDR product and deployed worldwide, handling billions ofcorrelations with a 99extensive investigations by security experts. This integration has not onlymaintained high correlation accuracy but reduces traditional correlationstorage requirements by 7.4x. We provide an in-depth overview of the key designand operational features of GraphWeaver, setting a precedent as the firstcybersecurity company to openly discuss these critical capabilities at thislevel of depth.|在大企业网络安全的动态环境中，准确且高效地将数十亿条安全警报关联成全面的事件是一项重大挑战。传统的关联技术通常在维护、扩展以及适应新兴威胁和新型遥测源方面存在困难。我们引入了GraphWeaver，这是一个工业规模的框架，它将传统的事件关联过程转变为一种数据优化的、基于地理分布式图的方法。GraphWeaver引入了一系列创新，专门用于处理跨数十万家企业的数十亿条共享证据警报的复杂性。这些创新中的关键点包括：用于大规模数据处理的地理分布式数据库和PySpark分析引擎、用于优化关联存储的最小生成树算法、安全领域知识和威胁情报的集成，以及一个人类在环反馈系统，以持续优化关键的关联过程和参数。GraphWeaver已集成到Microsoft Defender XDR产品中，并在全球范围内部署，处理数十亿次关联，准确率高达99%，同时显著减少了安全专家的广泛调查需求。这一集成不仅保持了高关联准确性，还将传统关联存储需求减少了7.4倍。我们深入概述了GraphWeaver的关键设计和操作特性，作为首家网络安全公司，以这种深度公开讨论这些关键能力，开创了先例。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphWeaver:+Billion-Scale+Cybersecurity+Incident+Correlation)|0|
|[PODTILE: Facilitating Podcast Episode Browsing with Auto-generated Chapters](https://doi.org/10.1145/3627673.3680081)|Azin Ghazimatin, Ekaterina Garmash, Gustavo Penha, Kristen Sheets, Martin Achenbach, Oguz Semerci, Remi Galvez, Marcus Tannenberg, Sahitya Mantravadi, Divya Narayanan, Ofeliya Kalaydzhyan, Douglas Cole, Ben Carterette, Ann Clifton, Paul N. Bennett, Claudia Hauff, Mounia Lalmas|Spotify, London, United Kingdom; Spotify, Boston, USA; Spotify, San Francisco, USA; Spotify, Gothenburg, Sweden; Spotify, Berlin, Germany; Spotify, New York, USA; Spotify, Delft, Netherlands; Spotify, Amsterdam, Netherlands|Listeners of long-form talk-audio content, such as podcast episodes, often find it challenging to understand the overall structure and locate relevant sections. A practical solution is to divide episodes into chapters–semantically coherent segments labeled with titles and timestamps. Since most episodes on our platform at Spotify currently lack creator-provided chapters, automating the creation of chapters is essential. Scaling the chapterization of podcast episodes presents unique challenges. First, episodes tend to be less structured than written texts, featuring spontaneous discussions with nuanced transitions. Second, the transcripts are usually lengthy, averaging about 16,000 tokens, which necessitates efficient processing that can preserve context. To address these challenges, we introduce PODTILE, a fine-tuned encoder-decoder transformer to segment conversational data. The model simultaneously generates chapter transitions and titles for the input transcript. To preserve context, each input text is augmented with global context, including the episode's title, description, and previous chapter titles. In our intrinsic evaluation, PODTILE achieved an 11 ROUGE score over the strongest baseline. Additionally, we provide insights into the practical benefits of auto-generated chapters for listeners navigating episode content. Our findings indicate that auto-generated chapters serve as a useful tool for engaging with less popular podcasts. Finally, we present empirical evidence that using chapter titles can enhance effectiveness of sparse retrieval in search tasks.|长篇音频内容（如播客节目）的听众通常难以理解整体结构并定位相关部分。一个实用的解决方案是将节目划分为章节——语义连贯的段落，并标注标题和时间戳。由于我们Spotify平台上的大多数节目目前缺乏创作者提供的章节，因此自动化生成章节是至关重要的。然而，规模化地实现播客节目的章节划分面临独特挑战。首先，节目通常比书面文本的结构性更低，包含自发的讨论和微妙的过渡。其次，转录文本通常较长，平均约为16,000个词汇，这要求高效的处理方法以保留上下文信息。

为了解决这些挑战，我们提出了PODTILE，这是一个经过微调的编码器-解码器Transformer模型，用于分割对话数据。该模型同时为输入转录文本生成章节过渡和标题。为了保留上下文，每个输入文本都通过全局上下文进行增强，包括节目标题、描述以及之前的章节标题。在我们的内部评估中，PODTILE在最强基线模型的基础上，ROUGE得分提高了11分。此外，我们还探讨了自动生成章节对听众浏览节目内容的实际益处。我们的研究结果表明，自动生成的章节是帮助听众更好地参与不太受欢迎的播客的有用工具。最后，我们提供了实证证据，表明在搜索任务中使用章节标题可以增强稀疏检索的有效性。

总结来说，PODTILE通过结合全局上下文信息，实现了对播客节目的高效章节划分，不仅提升了听众的体验，还为搜索任务中的信息检索提供了新的优化路径。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PODTILE:+Facilitating+Podcast+Episode+Browsing+with+Auto-generated+Chapters)|0|
|[CancerKG.ORG - A Web-scale, Interactive, Verifiable Knowledge Graph-LLM Hybrid for Assisting with Optimal Cancer Treatment and Care](https://doi.org/10.1145/3627673.3680094)|Michael N. Gubanov, Anna Pyayt, Aleksandra Karolak|Moffitt Cancer Center and Research Institute, Tampa, FL, USA; Florida State University, Tallahassee, FL, USA; University of South Florida, Tampa, FL, USA|Here, we describe one of the first Web-scale hybrid Knowledge Graph (KG)-Large Language Model (LLM), populated with the latest peer-reviewed medical knowledge on colorectal Cancer. It is currently being evaluated to assist with both medical research and clinical information retrieval tasks at Moffitt Cancer Center, which is one of the top Cancer centers in the U.S. and in the world. Our hybrid is remarkable as it serves the user needs better than just an LLM, KG or a search-engine in isolation. LLMs as is are known to exhibit hallucinations and catastrophic forgetting as well as are trained on outdated corpora. The state of the art KGs, such as PrimeKG, cBioPortal, ChEMBL, NCBI, and other require manual curation, hence are quickly getting stale. CancerKG is unsupervised and is capable of automatically ingesting and organizing the latest medical findings. To alleviate the LLMs shortcomings, the verified KG serves as a Retrieval Augmented Generation (RAG) guardrail. CancerKG exhibits 5 different advanced user interfaces, each tailored to serve different data modalities better and more convenient for the user.|在此，我们介绍了一种首批网络规模的混合知识图谱（KG）-大型语言模型（LLM），其中包含了关于结直肠癌的最新同行评审医学知识。该模型目前正在Moffitt癌症中心进行评估，以协助医学研究和临床信息检索任务，Moffitt癌症中心是美国乃至全球顶尖的癌症中心之一。我们的混合模型之所以引人注目，是因为它比单独的LLM、KG或搜索引擎更能满足用户需求。众所周知，LLM存在幻觉和灾难性遗忘问题，并且是在过时的语料库上训练的。诸如PrimeKG、cBioPortal、ChEMBL、NCBI等最先进的KG需要人工管理，因此很快会过时。CancerKG是无监督的，能够自动吸收和组织最新的医学发现。为了缓解LLM的缺点，经过验证的KG作为检索增强生成（RAG）的防护栏。CancerKG展示了五种不同的高级用户界面，每种界面都经过定制，以更好地服务于不同的数据模态，并更方便用户使用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CancerKG.ORG+-+A+Web-scale,+Interactive,+Verifiable+Knowledge+Graph-LLM+Hybrid+for+Assisting+with+Optimal+Cancer+Treatment+and+Care)|0|
|[Quality Prediction in Arc Welding: Leveraging Transformer Models and Discrete Representations from Vector Quantised-VAE](https://doi.org/10.1145/3627673.3680031)|Yannik Hahn, Robert F. Maack, Hasan Tercan, Tobias Meisen, Marion Purrio, Guido Buchholz, Matthias Angerhausen|; Forschungs- und Entwicklungsgesellschaft Fügetechnik GmbH (FEF), Aachen, Germany|Modern manufacturing relies heavily on fusion welding processes, including gas metal arc welding (GMAW), which efficiently converts electrical energy into thermal energy to join metals. Despite decades of research and extensive application in the automotive and aerospace sectors, weld quality assessment in the GMAW process remains a major challenge. This paper presents a novel learning-based approach relying on a vector quantised variational autoencoder (VQ-VAE) for data representation. In addition, we are the first to provide a time series dataset to the research community that combines labeled and unlabeled time series data from the GMAW domain, thereby enabling further research. The core idea of our approach consists of two stages: In the first stage, we use a learned automatic extraction of local features of the input signal using a VQ-VAE architecture. Based on this, in the second stage, we use a transformer model that processes the discretized features and performs weld quality prediction and classification. Our approach addresses real-world scenarios and improves the prediction of quality and fill existing data gaps by providing a reliable approach for quality assessment during manufacturing based on sensor data.|现代制造业高度依赖熔焊工艺，包括气体保护金属弧焊（GMAW），该工艺能够高效地将电能转化为热能以连接金属。尽管经过数十年的研究并在汽车和航空航天领域广泛应用，GMAW工艺中的焊接质量评估仍然是一个重大挑战。本文提出了一种基于学习的新方法，依赖于向量量化变分自编码器（VQ-VAE）进行数据表示。此外，我们首次向研究界提供了一个结合了GMAW领域带标签和无标签时间序列数据的时间序列数据集，从而为进一步研究提供了可能。我们方法的核心思想包括两个阶段：在第一阶段，我们使用VQ-VAE架构自动提取输入信号的局部特征。基于此，在第二阶段，我们使用一个Transformer模型来处理离散化特征，并进行焊接质量预测和分类。我们的方法解决了实际场景中的问题，并通过提供基于传感器数据的制造过程中质量评估的可靠方法，改进了质量预测并填补了现有的数据空白。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quality+Prediction+in+Arc+Welding:+Leveraging+Transformer+Models+and+Discrete+Representations+from+Vector+Quantised-VAE)|0|
|[Reinforcement Feature Transformation for Polymer Property Performance Prediction](https://doi.org/10.1145/3627673.3680105)|Xuanming Hu, Dongjie Wang, Wangyang Ying, Yanjie Fu||Polymer property performance prediction aims to forecast specific features or attributes of polymers, which has become an efficient approach to measuring their performance. However, existing machine learning models face challenges in effectively learning polymer representations due to low-quality polymer datasets, which consequently impact their overall performance. This study focuses on improving polymer property performance prediction tasks by reconstructing an optimal and explainable descriptor representation space. Nevertheless, prior research such as feature engineering and representation learning can only partially solve this task since they are either labor-incentive or unexplainable. This raises two issues: 1) automatic transformation and 2) explainable enhancement. To tackle these issues, we propose our unique Traceable Group-wise Reinforcement Generation Perspective. Specifically, we redefine the reconstruction of the representation space into an interactive process, combining nested generation and selection. Generation creates meaningful descriptors, and selection eliminates redundancies to control descriptor sizes. Our approach employs cascading reinforcement learning with three Markov Decision Processes, automating descriptor and operation selection, and descriptor crossing. We utilize a group-wise generation strategy to explore and enhance reward signals for cascading agents. Ultimately, we conduct experiments to indicate the effectiveness of our proposed framework.|聚合物性能预测旨在预测聚合物的特定特征或属性，这已成为衡量其性能的一种有效方法。然而，由于聚合物数据集质量较低，现有的机器学习模型在有效学习聚合物表征方面面临挑战，从而影响了其整体性能。本研究致力于通过重建一个最优且可解释的描述符表示空间来改进聚合物性能预测任务。然而，先前的研究如特征工程和表示学习只能部分解决这一任务，因为它们要么需要大量人工投入，要么缺乏可解释性。这引发了两个问题：1）自动化转换和2）可解释性增强。为了解决这些问题，我们提出了独特的可追踪分组强化生成视角。具体而言，我们将表示空间的重建重新定义为结合嵌套生成和选择的交互过程。生成过程创建有意义的描述符，而选择过程则消除冗余以控制描述符的规模。我们的方法采用级联强化学习，包含三个马尔可夫决策过程，自动化地进行描述符和操作选择以及描述符交叉。我们利用分组生成策略来探索和增强级联代理的奖励信号。最终，我们通过实验验证了所提出框架的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reinforcement+Feature+Transformation+for+Polymer+Property+Performance+Prediction)|0|
|[Robust Sequence-Based Self-Supervised Representation Learning for Anti-Money Laundering](https://doi.org/10.1145/3627673.3680078)|Shuaibin Huang, Yun Xiong, Yi Xie, Tianyu Qiu, Guangzhong Wang|; Bank of Communications, Shanghai, China|As online transactions rapidly increase, money laundering has become more difficult to detect, rendering traditional rule-based algorithms inadequate for the current severe laundering landscape. Although efforts have been made to model user behavior sequences for detecting money laundering, these approaches still fall short in scenarios with extremely low anomaly rates. In our anti-money laundering practices, we have identified the following three challenges: weak perception of intensity, scarce labels, poor representation robustness. In this paper, we present CLeAR, a novel robust sequence-based self-supervised Representation Learning framework for Anti-Money Laundering. To address the weak perception of intensity, we devise an Intensity-Aware Transformer to better capture the nuances of user behavior sequences. By introducing sequence-based Contrastive Learning into this task, we effectively tackle the issue of scarce labels and enhance sequence modeling. Additionally, we developed two self-supervised learning tasks-next behavior matching and sub-sequence matching-that significantly enhance the overall robustness of representation. After rigorous experiments across datasets of various scales, CLeAR consistently delivers exceptional performance, even under the extremely low anomaly rates that closely mimic real-world conditions.|随着在线交易的迅速增加，洗钱行为变得更加难以检测，使得传统的基于规则的算法在当前严峻的洗钱形势下显得不足。尽管已有研究尝试通过建模用户行为序列来检测洗钱行为，但这些方法在异常率极低的情况下仍显不足。在我们的反洗钱实践中，我们发现了以下三个挑战：强度感知弱、标签稀缺、表示鲁棒性差。本文提出了一种新颖的基于序列的自监督表示学习框架CLeAR，用于反洗钱。为了解决强度感知弱的问题，我们设计了一种强度感知Transformer，以更好地捕捉用户行为序列的细微差别。通过将基于序列的对比学习引入该任务，我们有效解决了标签稀缺的问题，并增强了序列建模。此外，我们开发了两个自监督学习任务——下一行为匹配和子序列匹配——显著增强了表示的整体鲁棒性。在多个规模的数据集上进行严格实验后，CLeAR即使在极低的异常率下（接近于现实世界的情况）也始终表现出卓越的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Sequence-Based+Self-Supervised+Representation+Learning+for+Anti-Money+Laundering)|0|
|[LAPIS: Language Model-Augmented Police Investigation System](https://doi.org/10.1145/3627673.3680044)|Heedou Kim, Dain Kim, Jiwoo Lee, Chanwoong Yoon, Donghee Choi, Mogan Gim, Jaewoo Kang||Crime situations are race against time. An AI-assisted criminal investigation system, providing prompt but precise legal counsel is in need for police officers. We introduce LAPIS (Language Model Augmented Police Investigation System), an automated system that assists police officers to perform rational and legal investigative actions. We constructed a finetuning dataset and retrieval knowledgebase specialized in crime investigation legal reasoning task. We extended the dataset's quality by incorporating manual curation efforts done by a group of domain experts. We then finetuned the pretrained weights of a smaller Korean language model to the newly constructed dataset and integrated it with the crime investigation knowledgebase retrieval approach. Experimental results show LAPIS' potential in providing reliable legal guidance for police officers, even better than the proprietary GPT-4 model. Qualitative analysis on the rationales generated by LAPIS demonstrate the model's reasoning ability to leverage the premises and derive legally correct conclusions.|犯罪情境往往是与时间赛跑。警察需要一种AI辅助的刑事调查系统，能够提供及时而准确的法律建议。我们介绍了LAPIS（语言模型增强型警察调查系统），这是一个自动化系统，旨在协助警察执行合理且合法的调查行动。我们构建了一个专门用于犯罪调查法律推理任务的微调数据集和检索知识库。通过引入一组领域专家的人工审核工作，我们进一步提升了数据集的质量。随后，我们将一个较小的韩语预训练语言模型的权重微调到新构建的数据集上，并将其与犯罪调查知识库检索方法相结合。实验结果表明，LAPIS在提供可靠法律指导方面展现出潜力，甚至优于专有的GPT-4模型。对LAPIS生成推理过程的定性分析表明，该模型具备利用前提推导出法律正确结论的推理能力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LAPIS:+Language+Model-Augmented+Police+Investigation+System)|0|
|[XploitSQL: Advancing Adversarial SQL Injection Attack Generation with Language Models and Reinforcement Learning](https://doi.org/10.1145/3627673.3680102)|Daniel Leung, Omar Tsai, Kourosh Hashemi, Bardia Tayebi, Mohammad A. Tayebi|School of Computing Science, University of Isfahan, Isfahan, Iran; School of Computing Science, Simon Fraser University, Burnaby, Canada|SQL injection (SQLi) compromises database-driven applications by enabling attackers to insert malicious SQL commands via input fields, potentially leading to unauthorized access, data manipulation, or system compromise. In recent years, alongside the development of various rule-based Web Application Firewalls (WAFs) aimed at mitigating SQL injection attacks, there has also been a notable rise in the utilization of machine learning and deep learning techniques to address this issue. Although significant progress has been made in these studies, detecting and mitigating SQLi-related attacks continues to present a significant challenge. A crucial factor contributing to the lack of extensive SQLi detection solutions is the absence of a comprehensive testing methodology. In this work, we introduce XploitSQL-an innovative approach to advance adversarial SQL injection generation by leveraging language models and reinforcement learning. Our model is trained to produce evasive SQLi samples, enhancing the robustness of SQLi detection models and offering opportunities for more comprehensive detection strategies. To assess the efficacy of the proposed method, we employed state-of-the-art SQL injection detection models in conjunction with commercially available web-based firewalls. Across all tested detection models, detection rates declined when faced with evasive samples generated by XploitSQL. Furthermore, our model outperforms existing methods for generating attack samples.|SQL注入（SQLi）通过允许攻击者通过输入字段插入恶意SQL命令，从而破坏数据库驱动的应用程序，可能导致未经授权的访问、数据操纵或系统受损。近年来，除了旨在减轻SQL注入攻击的各种基于规则的Web应用防火墙（WAF）的发展外，利用机器学习和深度学习技术来解决这一问题的应用也显著增加。尽管这些研究取得了显著进展，但检测和缓解SQLi相关攻击仍然是一个重大挑战。导致缺乏广泛SQLi检测解决方案的一个关键因素是缺乏全面的测试方法。在本研究中，我们引入了XploitSQL——一种创新的方法，通过利用语言模型和强化学习来推进对抗性SQL注入生成。我们的模型经过训练，能够生成规避性的SQLi样本，从而增强SQLi检测模型的鲁棒性，并为更全面的检测策略提供机会。为了评估所提出方法的有效性，我们采用了最先进的SQL注入检测模型与市售的基于Web的防火墙相结合。在所有测试的检测模型中，当面对由XploitSQL生成的规避性样本时，检测率均有所下降。此外，我们的模型在生成攻击样本方面优于现有方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=XploitSQL:+Advancing+Adversarial+SQL+Injection+Attack+Generation+with+Language+Models+and+Reinforcement+Learning)|0|
|[RealTCD: Temporal Causal Discovery from Interventional Data with Large Language Model](https://doi.org/10.1145/3627673.3680042)|Peiwen Li, Xin Wang, Zeyang Zhang, Yuan Meng, Fang Shen, Yue Li, Jialong Wang, Yang Li, Wenwu Zhu||In the field of Artificial Intelligence for Information TechnologyOperations, causal discovery is pivotal for operation and maintenance of graphconstruction, facilitating downstream industrial tasks such as root causeanalysis. Temporal causal discovery, as an emerging method, aims to identifytemporal causal relationships between variables directly from observations byutilizing interventional data. However, existing methods mainly focus onsynthetic datasets with heavy reliance on intervention targets and ignore thetextual information hidden in real-world systems, failing to conduct causaldiscovery for real industrial scenarios. To tackle this problem, in this paperwe propose to investigate temporal causal discovery in industrial scenarios,which faces two critical challenges: 1) how to discover causal relationshipswithout the interventional targets that are costly to obtain in practice, and2) how to discover causal relations via leveraging the textual information insystems which can be complex yet abundant in industrial contexts. To addressthese challenges, we propose the RealTCD framework, which is able to leveragedomain knowledge to discover temporal causal relationships withoutinterventional targets. Specifically, we first develop a score-based temporalcausal discovery method capable of discovering causal relations for root causeanalysis without relying on interventional targets through strategic maskingand regularization. Furthermore, by employing Large Language Models (LLMs) tohandle texts and integrate domain knowledge, we introduce LLM-guidedmeta-initialization to extract the meta-knowledge from textual informationhidden in systems to boost the quality of discovery. We conduct extensiveexperiments on simulation and real-world datasets to show the superiority ofour proposed RealTCD framework over existing baselines in discovering temporalcausal structures.|在信息技术运维的人工智能领域，因果发现对于运维图的构建至关重要，有助于根因分析等下游工业任务。时序因果发现作为一种新兴方法，旨在通过利用干预数据直接从观测数据中识别变量之间的时序因果关系。然而，现有方法主要依赖于干预目标的合成数据集，并忽略了现实世界系统中隐藏的文本信息，无法在实际工业场景中进行因果发现。为了解决这一问题，本文提出研究工业场景中的时序因果发现，这面临两个关键挑战：1）如何在没有干预目标的情况下发现因果关系，这些干预目标在实际中获取成本高昂；2）如何通过利用系统中的文本信息来发现因果关系，这些信息在工业环境中可能复杂且丰富。为了应对这些挑战，我们提出了RealTCD框架，该框架能够利用领域知识在没有干预目标的情况下发现时序因果关系。具体而言，我们首先开发了一种基于分数的时序因果发现方法，该方法通过策略性掩码和正则化，能够在不需要干预目标的情况下发现因果关系以进行根因分析。此外，通过使用大型语言模型（LLMs）处理文本并整合领域知识，我们引入了LLM引导的元初始化，从系统中隐藏的文本信息中提取元知识，以提高发现的质量。我们在模拟和真实世界的数据集上进行了广泛的实验，结果表明我们提出的RealTCD框架在发现时序因果结构方面优于现有的基线方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RealTCD:+Temporal+Causal+Discovery+from+Interventional+Data+with+Large+Language+Model)|0|
|[Bridging Dynamic Factor Models and Neural Controlled Differential Equations for Nowcasting GDP](https://doi.org/10.1145/3627673.3680074)|Seonkyu Lim, Jeongwhan Choi, Noseong Park, SangHa Yoon, ShinHyuck Kang, YoungMin Kim, Hyunjoong Kang||Gross domestic product (GDP) nowcasting is crucial for policy-making as GDP growth is a key indicator of economic conditions. Dynamic factor models (DFMs) have been widely adopted by government agencies for GDP nowcasting due to their ability to handle irregular or missing macroeconomic indicators and their interpretability. However, DFMs face two main challenges: i) the lack of capturing economic uncertainties such as sudden recessions or booms, and ii) the limitation of capturing irregular dynamics from mixed-frequency data. To address these challenges, we introduce NCDENow, a novel GDP nowcasting framework that integrates neural controlled differential equations (NCDEs) with DFMs. This integration effectively handles the dynamics of irregular time series. NCDENow consists of 3 main modules: i) factor extraction leveraging DFM, ii) dynamic modeling using NCDE, and iii) GDP growth prediction through regression. We evaluate NCDENow against 6 baselines on 2 real-world GDP datasets from South Korea and the United Kingdom, demonstrating its enhanced predictive capability. Our empirical results favor our method, highlighting the significant potential of integrating NCDE into nowcasting models. Our code and dataset are available at https://github.com/sklim84/NCDENow_CIKM2024.|国内生产总值（GDP）即时预测对于政策制定至关重要，因为GDP增长是经济状况的关键指标。动态因子模型（DFMs）因其能够处理不规则或缺失的宏观经济指标及其可解释性，已被政府机构广泛用于GDP即时预测。然而，DFMs面临两个主要挑战：i) 无法捕捉经济不确定性，如突然的衰退或繁荣；ii) 难以从混合频率数据中捕捉不规则的动态。为了解决这些挑战，我们引入了NCDENow，这是一个新颖的GDP即时预测框架，将神经控制微分方程（NCDEs）与DFMs相结合。这种结合有效地处理了不规则时间序列的动态。NCDENow由三个主要模块组成：i) 利用DFM进行因子提取，ii) 使用NCDE进行动态建模，iii) 通过回归进行GDP增长预测。我们在来自韩国和英国的两个真实GDP数据集上对NCDENow与6个基线模型进行了评估，展示了其增强的预测能力。我们的实证结果支持我们的方法，凸显了将NCDE集成到即时预测模型中的巨大潜力。我们的代码和数据集可在https://github.com/sklim84/NCDENow_CIKM2024获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bridging+Dynamic+Factor+Models+and+Neural+Controlled+Differential+Equations+for+Nowcasting+GDP)|0|
|[Hierarchical Information Propagation and Aggregation in Disentangled Graph Networks for Audience Expansion](https://doi.org/10.1145/3627673.3680062)|Li Lin, Xinyao Chen, Kaiwen Xia, Shuai Wang, Desheng Zhang, Tian He|Southeast University & JD Logistics, Nanjing, China; Southeast University, Nanjing, China; Rutgers University, New Brunswick, NJ, USA; JD Logistics, Beijing, China|With the development of the logistics industry, the user base of logistics services has expanded swiftly. This rapid increase in user scale presents significant challenges for logistics business management. A fundamental issue in such scenarios is audience expansion, which aims to find users willing to sign long-term services with logistics companies to foster business growth. Existing methods in addressing audience expansion mainly assume user modeling is entangled and neglects the inherent community structure among users. Due to these limitations, the effectiveness of traditional methods in achieving accurate user expansion is often restricted. Our work introduces a novel heterogeneous graph-based model, named Hi-DGN, which concentrates on the Hierarchical information propagation and aggregation in Disentangled Graph Networks for audience expansion. It consists of three main components: (i) the disentangled embedding layer to decouple user representations into different aspects, enabling the extraction of differentiated features; (ii) the hierarchical information propagation module partitions individual nodes into distinct groups and propagates information from group nodes to individual nodes hierarchically to capture diverse granularity representations; and (iii) the aggregation module to fuse all relation-specific embeddings to generate global node embeddings. Extensive experiments on two real-world datasets demonstrate the effectiveness of our method in various evaluation settings.|随着物流行业的发展，物流服务的用户基础迅速扩大。用户规模的快速增长给物流业务管理带来了重大挑战。在这种情况下，一个基本问题是受众扩展，其目标是找到愿意与物流公司签订长期服务的用户，以促进业务增长。现有的受众扩展方法主要假设用户建模是纠缠的，而忽略了用户之间固有的社区结构。由于这些限制，传统方法在实现准确用户扩展方面的有效性往往受到限制。我们的工作引入了一种新颖的基于异质图的模型，名为Hi-DGN，它专注于在解耦图网络中进行层次信息传播和聚合以实现受众扩展。该模型由三个主要组件组成：(i) 解耦嵌入层，将用户表示解耦为不同方面，从而提取差异化特征；(ii) 层次信息传播模块，将单个节点划分为不同的组，并从组节点向单个节点层次传播信息，以捕捉多样化的粒度表示；(iii) 聚合模块，融合所有特定关系的嵌入以生成全局节点嵌入。在两个真实世界的数据集上进行的大量实验证明了我们的方法在各种评估设置中的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Information+Propagation+and+Aggregation+in+Disentangled+Graph+Networks+for+Audience+Expansion)|0|
|[DECO: Cooperative Order Dispatching for On-Demand Delivery with Real-Time Encounter Detection](https://doi.org/10.1145/3627673.3680084)|Yao Lu, Shuai Wang, Yu Yang, Hai Wang, Baoshen Guo, Desheng Zhang, Shuai Wang, Tian He|Rutgers University, Piscataway, NJ, USA; Southeast University, Nanjing, China; Lehigh University, Bethlehem, PA, USA; JD Logistics, Beijing, China|In on-demand delivery,online orders are delivered by couriers from merchants to customers within a short time (e.g., 45 minutes). An important task is to provide an efficient order dispatching solution. Existing studies focus on scenarios with stable routing behavior using pre-determined courier-order matching before delivery while ignoring real-time dynamics during delivery. In this work, we leverage courier-courier encounter events as an opportunity to enable cooperative order dispatching (i.e., conducting order transfers among couriers during delivery) for better delivery efficiency. However, it is non-trivial to conduct encounter-aware cooperative order dispatching in real-time dynamics due to two major challenges: (i) the dynamic nature of encounters in diverse real-world scenarios, and (ii) global delivery efficiency optimization by local order transfers. To address the above challenges, we design a detection-driven cooperative dispatching framework, called DECO. Specifically, we design (i) a Received Signal Strength Indicator (RSSI) variance-based state encoder to model encounter dynamics, (ii) an encounter event selector to choose encounter scenarios, (iii) a time-constrained order mask module to filter unsuitable orders, and (iv) an encounter-aware order transfer scheduler to make detailed order transfer decisions. Extensive experiments on real-world data from two large companies (i.e., JD Logistics, Eleme) show that DECO outperforms other baselines.Real-world deployment results at JD Logistics show that DECO improves the order overdue rate by 4.8%.|在即时配送服务中，在线订单由配送员在短时间内（例如45分钟）从商家送达至顾客。一个重要任务是提供高效的订单调度解决方案。现有研究主要关注在配送前通过预定的配送员-订单匹配来实现稳定路由行为的场景，而忽略了配送过程中的实时动态。在本研究中，我们利用配送员之间的相遇事件作为机会，实现合作订单调度（即在配送过程中进行订单转移），以提高配送效率。然而，在实时动态中进行相遇感知的合作订单调度并非易事，主要面临两大挑战：(i) 多样现实场景中相遇的动态性，(ii) 通过局部订单转移实现全局配送效率的优化。为了解决上述挑战，我们设计了一个检测驱动的合作调度框架，称为DECO。具体而言，我们设计了(i) 基于接收信号强度指示器（RSSI）方差的状态编码器来建模相遇动态，(ii) 相遇事件选择器来选择相遇场景，(iii) 时间约束的订单掩码模块来过滤不合适的订单，以及(iv) 相遇感知的订单转移调度器来制定详细的订单转移决策。基于来自两家大型公司（即京东物流和饿了么）的实际数据进行的广泛实验表明，DECO优于其他基线方法。在京东物流的实际部署结果显示，DECO将订单超时率降低了4.8%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DECO:+Cooperative+Order+Dispatching+for+On-Demand+Delivery+with+Real-Time+Encounter+Detection)|0|
|[Combat Greenwashing with GoalSpotter: Automatic Sustainability Objective Detection in Heterogeneous Reports](https://doi.org/10.1145/3627673.3680110)|Mohammad Mahdavi, Ramin Baghaei Mehr, Tom Debus|Gisma University of Applied Sciences, Potsdam, Germany; Ferris Solutions AG, Cham, Switzerland|Sustainable development is nowadays a prominent factor for the public. As a result, companies publish their sustainability visions and strategies in various reports to show their commitment to saving the environment and promoting social progress. However, not all statements in these sustainability reports are fact-based. When a company tries to mislead the public with its non-fact-based sustainability claims, greenwashing happens. To combat greenwashing, society needs effective automated approaches to identify the sustainability claims of companies in their heterogeneous reports. In this paper, we present a new sustainability objective detection system, named GoalSpotter, that automatically identifies the environmental and social claims of companies in their heterogeneous reports. Our system extracts text blocks of diverse reports, preprocesses and labels them using domain expert annotations, and then fine-tunes transformer models on the labeled text blocks. This way, our system can detect sustainability objectives in any new heterogeneous report. As our experiments show, our system outperforms existing state-of-the-art sustainability objective detection approaches. Furthermore, our post-deployment results show the significant impacts of our system in real-world business.|可持续发展已成为当今社会公众关注的重要因素。因此，企业通过发布各种报告来展示其可持续发展愿景和战略，以表明其在环境保护和社会进步方面的承诺。然而，并非所有这些可持续发展报告中的声明都基于事实。当企业试图通过非事实基础的可持续发展声明误导公众时，便产生了“漂绿”现象。为了应对“漂绿”问题，社会需要有效的自动化方法来识别企业在各类异构报告中的可持续发展声明。本文提出了一种新的可持续发展目标检测系统，名为GoalSpotter，该系统能够自动识别企业在异构报告中的环境和社会声明。我们的系统从多样化的报告中提取文本块，使用领域专家的注释进行预处理和标注，然后在标注的文本块上微调Transformer模型。通过这种方式，我们的系统能够检测任何新的异构报告中的可持续发展目标。实验结果表明，我们的系统优于现有的最先进的可持续发展目标检测方法。此外，部署后的结果显示，我们的系统在现实商业环境中具有显著的影响。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Combat+Greenwashing+with+GoalSpotter:+Automatic+Sustainability+Objective+Detection+in+Heterogeneous+Reports)|0|
|[Multi-view Causal Graph Fusion Based Anomaly Detection in Cyber-Physical Infrastructures](https://doi.org/10.1145/3627673.3680096)|Arun Vignesh Malarkkan, Dongjie Wang, Yanjie Fu|University of Kansas, Lawrence, KS, USA; Arizona State University, Tempe, AZ, USA|The rise in cyber attacks on cyber-physical critical infrastructures, like water treatment networks, is evidenced by the growing frequency of breaches and the evolving sophistication of attack methods. Attack detection in such vulnerable critical infrastructures can be generalized into a task of anomaly detection with multivariate stream data. There are two essential challenges of this task: 1) Evolving and Shifting data streams; and 2) Robust Attack Pattern representation. Existing anomaly detection approaches, including statistical, distance, density, neural network, and graph-based methods, are not specialized in solving the spurious statistical relationships of evolving distribution shifts in sensing data streams. To address the two challenges, we propose a multi-view causal graph perspective, where 1) We build causal graphs to capture invariant anomaly patterns in varying streams; and 2) Introduce multi-view fusion for robust attack pattern representation. To implement this technical perspective, we develop a fused multi-view causal graph-aware anomaly detection framework. This framework includes two phases: 1) Multi-view Causal Graphs and Spectral Fusion, where we learn the dense view and sparse view causal graphs from sensory data streams and fuse the two causal graphs into a single weighted Laplacian matrix representation. 2) Graph Anomaly Detection, where we train a Deep Convolutional Graph Neural Network (DGCNN) on the Laplacian representation of the "Attack" and "Normal" status graphs to detect attack statuses on sensory data streams per time interval. Our framework achieves a ROC-Score of 82.4% and 93.2% on the SWaT and WADI Water Treatment Network Datasets with an improvement of 9.03% and 16.5% on the f1-score respectively when compared with the best-performing baseline methods on both the datasets.|针对网络物理关键基础设施（如水处理网络）的网络攻击日益频繁，攻击手段也日趋复杂，这凸显了此类基础设施面临的威胁。在这些脆弱的关键基础设施中，攻击检测可以概括为一种多变量流数据的异常检测任务。该任务面临两个主要挑战：1) 数据流的演化和偏移；2) 鲁棒的攻击模式表示。现有的异常检测方法，包括统计方法、距离方法、密度方法、神经网络方法和基于图的方法，并未专门解决传感数据流中演化分布偏移导致的虚假统计关系问题。

为了应对这两个挑战，我们提出了一种多视图因果图视角：1) 我们构建因果图以捕捉变化流中的不变异常模式；2) 引入多视图融合以实现鲁棒的攻击模式表示。为实现这一技术视角，我们开发了一种融合多视图因果图感知的异常检测框架。该框架包括两个阶段：1) 多视图因果图与谱融合，我们从传感数据流中学习密集视图和稀疏视图的因果图，并将这两个因果图融合为一个加权拉普拉斯矩阵表示；2) 图异常检测，我们在“攻击”和“正常”状态图的拉普拉斯表示上训练深度卷积图神经网络（DGCNN），以检测每个时间间隔内传感数据流上的攻击状态。

我们的框架在SWaT和WADI水处理网络数据集上的ROC得分分别达到82.4%和93.2%，与两个数据集上表现最佳的基线方法相比，f1分数分别提高了9.03%和16.5%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-view+Causal+Graph+Fusion+Based+Anomaly+Detection+in+Cyber-Physical+Infrastructures)|0|
|[Ericsogate: Advancing Analytics and Management of Data from Diverse Sources within Ericsson Using Knowledge Graphs](https://doi.org/10.1145/3627673.3680033)|Abdelghny Orogat, Sri Lakshmi Vadlamani, Dimple Thomas, Ahmed ElRoby|Carleton University, Ottawa, Canada; Ericsson, Ottawa, Canada|As data in the telecommunications industry becomes more voluminous and complex, extracting insightful information requires efficient and scalable systems that can effectively link and manage this data. This paper introduces a novel, multi-layered approach to managing interlinked data for Cloud Radio Access Network (CloudRAN) at Ericsson, utilizing Knowledge Graphs (KGs). Our system is structured into six distinct layers, each focusing on a specific aspect of managing interlinked data. This division enhances clarity and manageability, and promotes effective teamwork and collaborative development. A cornerstone of our architecture is its modularity, which enables the flexible exchange of components, such as the triple store, with minimal impact on the system's operations, ensuring longevity and adaptability to evolving technological trends. Moreover, we introduce novel applications in knowledge graph summarization and semantic search, specifically engineered for industrial decision-making. These innovations provide concise insights and actionable intelligence, fostering rapid and informed decision-making processes crucial for industry professionals. Finally, we discuss the lessons learned from deploying and utilizing this six-layer framework.|随着电信行业数据量的增加和复杂性的提升，提取有价值的信息需要高效且可扩展的系统，这些系统能够有效地链接和管理这些数据。本文介绍了一种新颖的多层方法，用于管理爱立信云无线接入网络（CloudRAN）中的互连数据，该方法利用知识图谱（KGs）。我们的系统分为六个不同的层次，每个层次专注于管理互连数据的特定方面。这种分层增强了清晰度和可管理性，并促进了有效的团队合作和协作开发。我们架构的一个核心特点是其模块化，这使得组件（如三元组存储）能够灵活替换，对系统操作的影响最小，从而确保系统的持久性和对技术发展趋势的适应性。此外，我们引入了知识图谱摘要和语义搜索中的新应用，这些应用专门为工业决策设计。这些创新提供了简洁的见解和可操作的情报，促进了行业专业人士所需的快速且明智的决策过程。最后，我们讨论了从部署和使用这个六层框架中获得的经验教训。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ericsogate:+Advancing+Analytics+and+Management+of+Data+from+Diverse+Sources+within+Ericsson+Using+Knowledge+Graphs)|0|
|[COKE: Causal Discovery with Chronological Order and Expert Knowledge in High Proportion of Missing Manufacturing Data](https://doi.org/10.1145/3627673.3680083)|TingYun Ou, Ching Chang, WenChih Peng||Understanding causal relationships between machines is crucial for fault diagnosis and optimization in manufacturing processes. Real-world datasets frequently exhibit up to 90 of sensors. These datasets also include domain-specific expert knowledge and chronological order information, reflecting the recording order across different machines, which is pivotal for discerning causal relationships within the manufacturing data. However, previous methods for handling missing data in scenarios akin to real-world conditions have not been able to effectively utilize expert knowledge. Conversely, prior methods that can incorporate expert knowledge struggle with datasets that exhibit missing values. Therefore, we propose COKE to construct causal graphs in manufacturing datasets by leveraging expert knowledge and chronological order among sensors without imputing missing data. Utilizing the characteristics of the recipe, we maximize the use of samples with missing values, derive embeddings from intersections with an initial graph that incorporates expert knowledge and chronological order, and create a sensor ordering graph. The graph-generating process has been optimized by an actor-critic architecture to obtain a final graph that has a maximum reward. Experimental evaluations in diverse settings of sensor quantities and missing proportions demonstrate that our approach compared with the benchmark methods shows an average improvement of 39.9 F1-score improvement can reach 62.6 to real-world datasets, and 85.0 source code is available at https://github.com/OuTingYun/COKE.|理解机器之间的因果关系对于制造过程中的故障诊断和优化至关重要。现实世界的数据集通常包含高达90%的传感器缺失数据。这些数据集还包括领域专家的知识和时间顺序信息，反映了不同机器之间的记录顺序，这对于识别制造数据中的因果关系至关重要。然而，以往的方法在处理类似于现实世界条件下的缺失数据时，未能有效利用专家知识。相反，之前能够融入专家知识的方法在处理具有缺失值的数据集时表现不佳。因此，我们提出了COKE方法，通过利用专家知识和传感器之间的时间顺序，在不填补缺失数据的情况下构建制造数据集中的因果图。利用配方特性，我们最大限度地利用具有缺失值的样本，从与包含专家知识和时间顺序的初始图的交集中导出嵌入，并创建一个传感器顺序图。图生成过程通过actor-critic架构进行了优化，以获得具有最大奖励的最终图。在不同传感器数量和缺失比例设置下的实验评估表明，与基准方法相比，我们的方法平均提高了39.9%的F1分数，最高可达62.6%。对于现实世界的数据集，F1分数的平均改进为85.0%。源代码可在https://github.com/OuTingYun/COKE获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=COKE:+Causal+Discovery+with+Chronological+Order+and+Expert+Knowledge+in+High+Proportion+of+Missing+Manufacturing+Data)|0|
|[LawLLM: Law Large Language Model for the US Legal System](https://doi.org/10.1145/3627673.3680020)|Dong Shu, Haoran Zhao, Xukun Liu, David Demeter, Mengnan Du, Yongfeng Zhang||In the rapidly evolving field of legal analytics, finding relevant cases and accurately predicting judicial outcomes are challenging because of the complexity of legal language, which often includes specialized terminology, complex syntax, and historical context. Moreover, the subtle distinctions between similar and precedent cases require a deep understanding of legal knowledge. Researchers often conflate these concepts, making it difficult to develop specialized techniques to effectively address these nuanced tasks. In this paper, we introduce the Law Large Language Model (LawLLM), a multi-task model specifically designed for the US legal domain to address these challenges. LawLLM excels at Similar Case Retrieval (SCR), Precedent Case Recommendation (PCR), and Legal Judgment Prediction (LJP). By clearly distinguishing between precedent and similar cases, we provide essential clarity, guiding future research in developing specialized strategies for these tasks. We propose customized data preprocessing techniques for each task that transform raw legal data into a trainable format. Furthermore, we also use techniques such as in-context learning (ICL) and advanced information retrieval methods in LawLLM. The evaluation results demonstrate that LawLLM consistently outperforms existing baselines in both zero-shot and few-shot scenarios, offering unparalleled multi-task capabilities and filling critical gaps in the legal domain.|在快速发展的法律分析领域，由于法律语言的复杂性，寻找相关案例并准确预测司法结果具有挑战性。法律语言通常包含专业术语、复杂的句法结构以及历史背景。此外，类似案例与判例之间的细微差别需要对法律知识有深刻的理解。研究人员常常将这些概念混为一谈，导致难以开发出专门的技术来有效应对这些复杂任务。在本文中，我们提出了法律大语言模型（LawLLM），这是一个专门为美国法律领域设计的多任务模型，旨在解决这些挑战。LawLLM在类似案例检索（SCR）、判例推荐（PCR）和法律判决预测（LJP）方面表现卓越。通过明确区分判例和类似案例，我们提供了关键的清晰性，为未来研究开发针对这些任务的专门策略提供了指导。我们为每项任务提出了定制的数据预处理技术，将原始法律数据转化为可训练的格式。此外，我们还在LawLLM中使用了上下文学习（ICL）和先进的信息检索方法等技术。评估结果表明，LawLLM在零样本和少样本场景中始终优于现有基线模型，提供了无与伦比的多任务能力，填补了法律领域的关键空白。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LawLLM:+Law+Large+Language+Model+for+the+US+Legal+System)|0|
|["Reasoning before Responding": Towards Legal Long-form Question Answering with Interpretability](https://doi.org/10.1145/3627673.3680082)|Utkarsh Ujwal, Sai Sri Harsha Surampudi, Sayantan Mitra, Tulika Saha|JPMorgan Chase & Co., Bangalore, India; University of Liverpool, Liverpool, United Kingdom|Long-Form Question Answering (LFQA) represents a growing interest in Legal Natural Language Processing (Legal-NLP) as many individuals encounter legal disputes at some point in their lives, but lack of knowledge about how to negotiate these complex situations might put them at risk. The endeavor to generate detailed answers to contextually rich legal questions has faced challenges, primarily due to the limited availability of specialized datasets involving intensive manual effort or incapability of existing LFQA models to produce informative responses. Addressing this, our research introduces a semi-synthetic dataset, Legal-LFQA (L2FQA) created by exploiting a large language model (LLM) and utilizing contexts derived from existing legal datasets. Additionally, we hypothesize that integrating legal reasoning into the answer generation process of the LLMs will help bolster both the quality and interpretability of the produced responses. We systematically analyze the quality of L2FQA using human evaluation and natural language inference based metrics. Next, we benchmark L2FQA on a wide range of general-purpose and domain-specific LLMs using fine-tuning and in-context learning (with zero, one and few shot) strategies. The efficacy of these techniques is gauged through several automated and human evaluations. Results indicate that incorporating legal reasoning into the answer generation process provides an avenue for improving the quality of responses in the context of Legal-LFQA task. By addressing the challenges faced in LFQA and emphasizing the potential of interpretability, this research contributes to the foundational work in enhancing question-answering systems within the legal domain.|长文本问答（Long-Form Question Answering, LFQA）在**法律自然语言处理（Legal-NLP）**领域引起了越来越多的关注，因为许多人在生活中都会遇到法律纠纷，但缺乏如何应对这些复杂情况的知识可能会使他们处于风险之中。生成针对情境丰富的法律问题的详细答案的努力面临挑战，主要原因是涉及大量人工工作的专门数据集有限，或者现有的LFQA模型无法生成信息丰富的回答。为了解决这一问题，我们的研究引入了一个半合成的数据集，称为**Legal-LFQA（L2FQA）**，该数据集通过利用大型语言模型（LLM）并结合现有法律数据集中的上下文生成。此外，我们假设将法律推理集成到LLM的答案生成过程中，将有助于提高生成答案的质量和可解释性。我们通过人工评估和基于自然语言推理的指标，系统分析了L2FQA的质量。接着，我们在广泛的通用和领域特定LLM上对L2FQA进行了基准测试，使用了微调（fine-tuning）和上下文学习（in-context learning，包括零样本、单样本和少样本）策略。这些技术的效果通过多项自动化和人工评估来衡量。结果表明，在法律LFQA任务中，将法律推理融入答案生成过程为提高回答质量提供了途径。通过解决LFQA面临的挑战并强调可解释性的潜力，这项研究为增强法律领域问答系统的基础工作做出了贡献。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q="Reasoning+before+Responding":+Towards+Legal+Long-form+Question+Answering+with+Interpretability)|0|
|[COIN: Chance-Constrained Imitation Learning for Safe and Adaptive Resource Oversubscription under Uncertainty](https://doi.org/10.1145/3627673.3680060)|Lu Wang, Mayukh Das, Fangkai Yang, Chao Du, Bo Qiao, Hang Dong, Chetan Bansal, Si Qin, Saravan Rajmohan, Qingwei Lin, Dongmei Zhang, Qi Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=COIN:+Chance-Constrained+Imitation+Learning+for+Safe+and+Adaptive+Resource+Oversubscription+under+Uncertainty)|0|
|[RCAgent: Cloud Root Cause Analysis by Autonomous Agents with Tool-Augmented Large Language Models](https://doi.org/10.1145/3627673.3680016)|Zefan Wang, Zichuan Liu, Yingying Zhang, Aoxiao Zhong, Jihong Wang, Fengbin Yin, Lunting Fan, Lingfei Wu, Qingsong Wen|; Alibaba Group; Nanjing University; Harvard University; Anytime.AI Inc; Tsinghua University|Large language model (LLM) applications in cloud root cause analysis (RCA) have been actively explored recently. However, current methods are still reliant on manual workflow settings and do not unleash LLMs' decision-making and environment interaction capabilities. We present RCAgent, a tool-augmented LLM autonomous agent framework for practical and privacy-aware industrial RCA usage. Running on an internally deployed model rather than GPT families, RCAgent is capable of free-form data collection and comprehensive analysis with tools. Our framework combines a variety of enhancements, including a unique Self-Consistency for action trajectories, and a suite of methods for context management, stabilization, and importing domain knowledge. Our experiments show RCAgent's evident and consistent superiority over ReAct across all aspects of RCA -- predicting root causes, solutions, evidence, and responsibilities -- and tasks covered or uncovered by current rules, as validated by both automated metrics and human evaluations. Furthermore, RCAgent has already been integrated into the diagnosis and issue discovery workflow of the Real-time Compute Platform for Apache Flink of Alibaba Cloud.|近年来，大型语言模型（LLM）在云根因分析（RCA）中的应用得到了积极探索。然而，当前的方法仍然依赖于手动工作流设置，未能充分发挥LLM在决策制定和环境交互方面的潜力。我们提出了RCAgent，这是一个工具增强的LLM自主代理框架，旨在实现实用且注重隐私的工业RCA应用。RCAgent运行于内部部署的模型而非GPT系列模型之上，能够通过工具进行自由形式的数据收集和全面分析。我们的框架结合了多种增强功能，包括独特的自一致性用于动作轨迹，以及一套用于上下文管理、稳定性和导入领域知识的方法。实验结果表明，RCAgent在RCA的各个方面——预测根本原因、解决方案、证据和责任——以及当前规则涵盖或未涵盖的任务上，均显著且一致地优于ReAct，这一点通过自动化指标和人工评估得到了验证。此外，RCAgent已被集成到阿里巴巴云Apache Flink实时计算平台的诊断和问题发现工作流中。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RCAgent:+Cloud+Root+Cause+Analysis+by+Autonomous+Agents+with+Tool-Augmented+Large+Language+Models)|0|
|[Process-Informed Deep Learning for Enhanced Order Fulfillment Cycle Time Prediction in On-Demand Grocery Retailing](https://doi.org/10.1145/3627673.3680056)|Jiawen Wei, Ziwen Ye, Chuan Yang, Chen Chen, Guangrui Ma|Meituan, Beijing, China; Nankai University, Tianjin, China|Accurate prediction of Order Fulfillment Cycle Time (OFCT) is essential for improving customer satisfaction and operational efficiency within the domain of on-demand grocery retailing (OGR). OGR platforms typically rely on Front Distribution Centers (FDCs) to manage inventory and deploy dedicated fleets for last-mile delivery to fulfill customer demands. Orders are processed at FDCs initially and then dispatched to delivery fleets. OFCT is influenced by a multitude of factors such as order volume, processing capabilities, delivery capacities, and dispatching strategies. These factors pose significant challenges to refining OFCT prediction accuracy. This paper presents an innovative deep learning model informed by a detailed comprehension of the order fulfillment process, with the objective of significantly enhancing OFCT prediction precision. We employ Recurrent Neural Network (RNN) blocks to dynamically evaluate the workload across processing and delivery stages. To address the interactions among orders and the impact of latent courier dynamics on order prioritization, we incorporate a suite of specialized attention modules into our framework. Our approach further employs Deep Bayesian Multi-Target Learning (DBMTL) to discern the sequential interactions between various stages of order fulfillment, thereby elucidating the influence of earlier stages on subsequent ones. Through online experiments on Meituan-Maicai, one of the biggest OGR platforms in China, our model demonstrates its superiority by outperforming well-acknowledged and advanced baselines. Furthermore, we assess the contributions of specific designs in our model through ablation studies. Our research presents a notable advancement in OFCT prediction, providing valuable insights for OGR platforms seeking to optimize their fulfillment operations and enhance customer experiences.|在按需杂货零售（OGR）领域，准确预测订单履行周期时间（OFCT）对于提高客户满意度和运营效率至关重要。OGR平台通常依赖前端配送中心（FDC）来管理库存，并部署专用车队进行最后一英里配送以满足客户需求。订单首先在FDC处理，然后分派给配送车队。OFCT受多种因素影响，如订单量、处理能力、配送能力和分派策略等。这些因素对提高OFCT预测精度提出了重大挑战。本文提出了一种创新的深度学习模型，该模型基于对订单履行过程的详细理解，旨在显著提升OFCT预测精度。我们采用循环神经网络（RNN）模块动态评估处理和配送阶段的工作负载。为了解决订单之间的相互作用以及潜在配送员动态对订单优先级的影响，我们在框架中引入了一套专门的注意力模块。我们的方法进一步采用深度贝叶斯多目标学习（DBMTL）来识别订单履行各阶段之间的顺序交互，从而阐明早期阶段对后续阶段的影响。通过在中国最大的OGR平台之一美团-买菜上进行在线实验，我们的模型展示了其优越性，超越了公认的先进基线方法。此外，我们通过消融研究评估了模型中特定设计的贡献。我们的研究在OFCT预测方面取得了显著进展，为寻求优化其履行操作并提升客户体验的OGR平台提供了宝贵的见解。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Process-Informed+Deep+Learning+for+Enhanced+Order+Fulfillment+Cycle+Time+Prediction+in+On-Demand+Grocery+Retailing)|0|
|[G2PTL: A Geography-Graph Pre-trained Model](https://doi.org/10.1145/3627673.3680023)|Lixia Wu, Jianlin Liu, Junhong Lou, Minhui Deng, Jianbin Zheng, Haomin Wen, Chao Song, Shu He|Cainiao Network, Hangzhou Shi, China|As an important data resource containing spatial information, addresses record the geospatial information corresponding to social production activities and human behavioral activities. How to effectively encode addresses has always been a core challenge in the field of Geographic Information Systems (GIS). Pre-trained Models (PTMs) designed for Natural Language Process (NLP) have emerged as the dominant tools for encoding semantic information in text. Though promising, those NLP-based PTMs fall short of encoding geographic knowledge in addresses, which limits their application potential in geospatial tasks. To tackle the above problem, this study proposes a Geography-Graph Pre-trained model (G2PTL) that combines graph learning and text pre-training, aiming to make up for the shortcomings of traditional PTM in the geography field. Specifically, we first utilize real-world delivery data to build a large-scale heterogeneous graph of addresses, which contains abundant geographic knowledge and spatial topology information. Then, G2PTL is pre-trained with subgraphs sampled from the heterogeneous graph. Through experimental evaluation on multiple downstream tasks of GIS, including geocoding, geographic entity prediction, and geographic entity recognition, G2PTL demonstrated significant performance improvements. G2PTL has been successfully deployed in production-level GIS, such as Cainiao's logistics system, effectively improving the execution efficiency and accuracy of address-related tasks. This research not only provides a new technical path for the encoding and processing of geographical information, but also opens up a new perspective for the study of pre-training models in the geographical field. The code resources of the G2PTL model have been opened for research and application developers to access and use at https://huggingface.co/Cainiao-AI/G2PTL.|作为一种包含空间信息的重要数据资源，地址记录了社会生产活动和人类行为活动对应的地理空间信息。如何有效地对地址进行编码一直是地理信息系统（GIS）领域的核心挑战。为自然语言处理（NLP）设计的预训练模型（PTMs）已成为编码文本语义信息的主要工具。尽管前景广阔，但这些基于NLP的预训练模型在编码地址中的地理知识方面存在不足，这限制了它们在地理空间任务中的应用潜力。为解决上述问题，本研究提出了一种结合图学习和文本预训练的地理图预训练模型（G2PTL），旨在弥补传统预训练模型在地理领域的不足。具体而言，我们首先利用现实世界的配送数据构建了一个大规模的地址异构图，其中包含了丰富的地理知识和空间拓扑信息。然后，G2PTL通过从异构图中采样的子图进行预训练。通过对GIS的多个下游任务（包括地理编码、地理实体预测和地理实体识别）进行实验评估，G2PTL展示了显著的性能提升。G2PTL已成功部署在生产级GIS中，如菜鸟的物流系统，有效提高了地址相关任务的执行效率和准确性。这项研究不仅为地理信息的编码和处理提供了新的技术路径，还为地理领域预训练模型的研究开辟了新的视角。G2PTL模型的代码资源已在https://huggingface.co/Cainiao-AI/G2PTL上开放，供研究和应用开发者访问和使用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=G2PTL:+A+Geography-Graph+Pre-trained+Model)|0|
|[Deep Learning-Based Compressed Sensing for Mobile Device-Derived Sensor Data](https://doi.org/10.1145/3627673.3680050)|Liqiang Xu, Yuuki Nishiyama, Kota Tsubouchi, Kaoru Sezaki|LY Corporation, Tokyo, Japan; The University of Tokyo, Tokyo, Japan|As the capabilities of smart sensing and mobile technologies continue to evolve and expand, storing diverse sensor data on smartphones and cloud servers becomes increasingly challenging. Effective data compression is crucial to alleviate these storage pressures. Compressed sensing (CS) offers a promising approach, but traditional CS methods often struggle with the unique characteristics of sensor data-like variability, dynamic changes, and different sampling rates-leading to slow processing and poor reconstruction quality. To address these issues, we developed Mob-ISTA-1DNet, an innovative CS framework that integrates deep learning with the iterative shrinkage-thresholding algorithm (ISTA) to adaptively compress and reconstruct smartphone sensor data. This framework is designed to manage the complexities of smartphone sensor data, ensuring high-quality reconstruction across diverse conditions. We developed a mobile application to collect data from 30 volunteers over one month, including accelerometer, gyroscope, barometer, and other sensor measurements. Comparative analysis reveals that Mob-ISTA-1DNet not only enhances reconstruction accuracy but also significantly reduces processing time, consistently outperforming other methods in various scenarios.|随着智能感知和移动技术的不断发展与扩展，在智能手机和云服务器上存储多样化的传感器数据变得越来越具有挑战性。有效的数据压缩对于缓解这些存储压力至关重要。压缩感知（CS）提供了一种有前景的解决方案，但传统的CS方法在处理传感器数据的独特特性（如变异性、动态变化和不同的采样率）时常常面临困难，导致处理速度缓慢且重建质量较差。为解决这些问题，我们开发了Mob-ISTA-1DNet，这是一种创新的CS框架，它将深度学习与迭代收缩阈值算法（ISTA）相结合，以自适应地压缩和重建智能手机传感器数据。该框架旨在管理智能手机传感器数据的复杂性，确保在各种条件下都能实现高质量的重建。我们开发了一款移动应用程序，用于在一个月内从30名志愿者中收集数据，包括加速度计、陀螺仪、气压计和其他传感器测量值。对比分析表明，Mob-ISTA-1DNet不仅提高了重建精度，还显著减少了处理时间，在各种场景中始终优于其他方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Learning-Based+Compressed+Sensing+for+Mobile+Device-Derived+Sensor+Data)|0|
|[Towards a Zero-Day Anomaly Detector in Cyber Physical Systems Using a Hybrid VAE-LSTM-OCSVM Model](https://doi.org/10.1145/3627673.3680064)|Romarick Yatagha, Betelhem Nebebe, Karl Waedt, Christoph Ruland|Friedrich-Alexander-Universität, Erlangen, Germany; Framatome, Erlangen, Germany; Universität Siegen, Siegen, Germany|Despite the growing volume of time series data across various domains, detecting anomalies remains challenging due to the complexity and dynamic nature of the data. Traditional monitoring systems are inefficient in capturing contextual and temporal anomalies that are only viable through time and handling high-dimensional data. From implementation to deployment, this paper presents an anomaly detection system on a cyber-physical system by integrating Variational Autoencoders (VAE) with Long Short-Term Memory (LSTM) networks and One-Class Support Vector Machine (OCSVM), forming a hybrid VAE-LSTM-OCSVM model. The proposed architecture positions itself as a zero-day anomaly detector, by learning the nominal functioning of systems, enabling it to identify deviations from normal operations without prior knowledge of specific anomalies. This capability significantly enhances the model's utility in online monitoring, making it adept at detecting unforeseen operational disruptions. We propose an Adaptive Loss Weight Adjustment Algorithm (ALWAA) to account for Domain incremental learning in our system, as required by the ISO/IEC 42001:2023 and ISO/IEC 23053:2022 standards. The model is evaluated on a dataset including 2 types of anomalies, comparing and demonstrating its superiority over existing methods. The findings suggest that the hybrid VAE-LSTM-OCSVM model offers a promising direction for more effective and efficient anomaly detection in time series data, with its ability to safeguard against known and unknown anomalies.|尽管各个领域的时间序列数据量不断增长，但由于数据的复杂性和动态特性，异常检测仍然具有挑战性。传统的监控系统在捕捉仅通过时间才能识别的上下文和时间异常以及处理高维数据方面效率低下。本文从实现到部署，提出了一种在信息物理系统中集成了变分自编码器（VAE）、长短期记忆网络（LSTM）和一类支持向量机（OCSVM）的异常检测系统，形成了混合的VAE-LSTM-OCSVM模型。所提出的架构通过学习系统的正常运行状态，能够识别与正常操作的偏差，而无需事先了解特定异常，从而定位为零日异常检测器。这种能力显著增强了模型在线监控的实用性，使其能够有效检测未预见的操作中断。我们提出了一种自适应损失权重调整算法（ALWAA），以应对ISO/IEC 42001:2023和ISO/IEC 23053:2022标准要求的领域增量学习需求。该模型在包含两种异常类型的数据集上进行了评估，比较并展示了其相对于现有方法的优越性。研究结果表明，混合VAE-LSTM-OCSVM模型为时间序列数据中更有效和高效的异常检测提供了一个有前景的方向，其能够防范已知和未知的异常。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+a+Zero-Day+Anomaly+Detector+in+Cyber+Physical+Systems+Using+a+Hybrid+VAE-LSTM-OCSVM+Model)|0|
|[An End-to-End Reinforcement Learning Based Approach for Micro-View Order-Dispatching in Ride-Hailing](https://doi.org/10.1145/3627673.3680013)|Xinlang Yue, Yiran Liu, Fangzhou Shi, Sihong Luo, Chen Zhong, Min Lu, Zhe Xu||Assigning orders to drivers under localized spatiotemporal context (micro-view order-dispatching) is a major task in Didi, as it influences ride-hailing service experience. Existing industrial solutions mainly follow a two-stage pattern that incorporate heuristic or learning-based algorithms with naive combinatorial methods, tackling the uncertainty of both sides' behaviors, including emerging timings, spatial relationships, and travel duration, etc. In this paper, we propose a one-stage end-to-end reinforcement learning based order-dispatching approach that solves behavior prediction and combinatorial optimization uniformly in a sequential decision-making manner. Specifically, we employ a two-layer Markov Decision Process framework to model this problem, and present Deep Double Scalable Network (D2SN), an encoder-decoder structure network to generate order-driver assignments directly and stop assignments accordingly. Besides, by leveraging contextual dynamics, our approach can adapt to the behavioral patterns for better performance. Extensive experiments on Didi's real-world benchmarks justify that the proposed approach significantly outperforms competitive baselines in optimizing matching efficiency and user experience tasks. In addition, we evaluate the deployment outline and discuss the gains and experiences obtained during the deployment tests from the view of large-scale engineering implementation.|在滴滴出行中，将订单分配给司机（微观层面的订单调度）是一项重要任务，因为它直接影响网约车服务的用户体验。现有的工业解决方案主要采用两阶段模式，即将启发式或基于学习的算法与简单的组合方法相结合，以应对双方行为的不确定性，包括订单出现的时间、空间关系以及行程时长等因素。本文提出了一种基于强化学习的单阶段端到端订单调度方法，通过序列决策的方式统一解决行为预测和组合优化问题。具体而言，我们采用了两层马尔可夫决策过程框架来建模这一问题，并提出了深度双可扩展网络（D2SN），这是一种编码器-解码器结构的网络，能够直接生成订单-司机分配方案并适时停止分配。此外，通过利用上下文动态信息，我们的方法能够适应行为模式，从而提升性能。在滴滴的真实场景基准测试中，大量实验表明，所提出的方法在优化匹配效率和用户体验任务方面显著优于竞争基线。此外，我们从大规模工程实施的角度评估了部署方案，并讨论了在部署测试中获得的收益和经验。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+End-to-End+Reinforcement+Learning+Based+Approach+for+Micro-View+Order-Dispatching+in+Ride-Hailing)|0|
|[On the Fly Detection of Root Causes from Observed Data with Application to IT Systems](https://doi.org/10.1145/3627673.3680010)|Lei Zan, Charles K. Assaad, Emilie Devijver, Éric Gaussier, Ali AïtBachir||This paper introduces a new structural causal model tailored for representing threshold-based IT systems and presents a new algorithm designed to rapidly detect root causes of anomalies in such systems. When root causes are not causally related, the method is proven to be correct; while an extension is proposed based on the intervention of an agent to relax this assumption. Our algorithm and its agent-based extension leverage causal discovery from offline data and engage in subgraph traversal when encountering new anomalies in online data. Our extensive experiments demonstrate the superior performance of our methods, even when applied to data generated from alternative structural causal models or real IT monitoring data.|本文介绍了一种新的结构因果模型，专门用于表示基于阈值的IT系统，并提出了一种新算法，旨在快速检测此类系统中异常的根源。当根源之间不存在因果关系时，该方法被证明是正确的；同时，基于代理干预的扩展被提出，以放宽这一假设。我们的算法及其基于代理的扩展利用从离线数据中发现的因果关系，并在在线数据中遇到新异常时进行子图遍历。我们的大量实验表明，即使应用于从其他结构因果模型生成的数据或真实的IT监控数据，我们的方法也表现出卓越的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+the+Fly+Detection+of+Root+Causes+from+Observed+Data+with+Application+to+IT+Systems)|0|
|[Scaling Vison-Language Foundation Model to 12 Billion Parameters in Baidu Dynamic Image Advertising](https://doi.org/10.1145/3627673.3680014)|Xinyu Zhao, Kang Zhao, Zhipeng Jin, Yi Yang, Wen Tao, Xiaodong Chen, Cong Han, Shuanglong Li, Lin Liu|Baidu Search Ads, Baidu Inc., Beijing, China|Dynamic image advertising is an add-on service in search advertising that matches visuals to search ads in real-time. However, the image matching system encompasses various sub-tasks with different objectives, increasing the complexity of achieving global optimization. Besides, prevalent long-tailed data poses a challenge to the multimodal representation learning in dynamic image advertising. Recently, vision-language pre-trained models have achieved remarkable performance across a variety of multimodal tasks, and implemented as the foundational representation model in electronic business scenarios. In this paper, to improve multimodal content understanding in Dynamic Image adVERtising, we present a viSion-language rEpresentation model (referred to as DIVERSE) that learns on cross-view and cross-token contrastive loss. Moreover, with large-scale curated advertising image-text data and extensive efficient training techniques, we scale DIVERSE to 12 billion parameters, which is the biggest Chinese multimodal representation model in industrial practices. Experiment results demonstrate the distinct advantages of DIVERSE12B in business datasets, with competitive performance on public benchmarks. Further evaluation in downstream applications including ad text-image retrieval, text-image relevance modeling, and image content moderation, shows that it outperforms previous separately-trained models across offline and online metrics. Moreover, DIVERSE12B has been implemented on the system primary traffic of Baidu Search Ads, bringing considerable increase to both user experience, and revenue for advertisers and search engine.|动态图片广告是搜索广告中的一项附加服务，它能实时将视觉内容与搜索广告进行匹配。然而，图像匹配系统包含多个目标不同的子任务，这增加了实现全局优化的复杂性。此外，普遍存在的长尾数据对动态图片广告中的多模态表示学习构成了挑战。近年来，视觉-语言预训练模型在各种多模态任务中取得了显著成绩，并在电子商务场景中作为基础表示模型得到应用。本文旨在提升动态图片广告中的多模态内容理解能力，提出了一种基于跨视图和跨标记对比损失的视觉-语言表示模型（简称DIVERSE）。此外，通过大规模精选的广告图文数据及广泛的高效训练技术，我们将DIVERSE扩展至120亿参数，成为工业实践中最大的中文多模态表示模型。实验结果显示，DIVERSE12B在商业数据集上展现出显著优势，并在公共基准测试中表现出竞争力。在广告文本-图像检索、文本-图像相关性建模及图像内容审核等下游应用的进一步评估中，DIVERSE12B在离线和在线指标上均超越了先前单独训练的模型。此外，DIVERSE12B已在百度搜索广告系统的主要流量中部署，显著提升了用户体验，并为广告主和搜索引擎带来了可观的收入增长。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scaling+Vison-Language+Foundation+Model+to+12+Billion+Parameters+in+Baidu+Dynamic+Image+Advertising)|0|
|[Confidence-Aware Multi-Field Model Calibration](https://doi.org/10.1145/3627673.3680043)|Yuang Zhao, Chuhan Wu, Qinglin Jia, Hong Zhu, Jia Yan, Libin Zong, Linxuan Zhang, Zhenhua Dong, Muyu Zhang|Noah's Ark Lab; Huawei Petal Cloud Technology Co., Ltd; Tsinghua University; Consumer Cloud Service Interactive Media BU|Accurately predicting the probabilities of user feedback, such as clicks andconversions, is critical for ad ranking and bidding. However, there often existunwanted mismatches between predicted probabilities and true likelihoods due tothe shift of data distributions and intrinsic model biases. Calibration aims toaddress this issue by post-processing model predictions, and field-awarecalibration can adjust model output on different feature field values tosatisfy fine-grained advertising demands. Unfortunately, the observed samplescorresponding to certain field values can be too limited to make confidentcalibrations, which may yield bias amplification and online disturbance. Inthis paper, we propose a confidence-aware multi-field calibration method, whichadaptively adjusts the calibration intensity based on the confidence levelsderived from sample statistics. It also utilizes multiple feature fields forjoint model calibration with awareness of their importance to mitigate the datasparsity effect of a single field. Extensive offline and online experimentsshow the superiority of our method in boosting advertising performance andreducing prediction deviations.|准确预测用户反馈（如点击和转化）的概率对于广告排序和竞价至关重要。然而，由于数据分布的偏移和模型固有的偏差，预测概率与真实概率之间往往存在不期望的差异。校准旨在通过后处理模型预测来解决这一问题，而基于特征域的校准可以根据不同特征域的值调整模型输出，以满足细粒度的广告需求。然而，某些特征域值对应的观察样本可能过于有限，无法进行可靠的校准，这可能导致偏差放大和线上扰动。本文提出了一种基于置信度的多域校准方法，该方法根据样本统计得出的置信度自适应地调整校准强度。同时，该方法还利用多个特征域进行联合模型校准，并考虑它们的重要性，以缓解单一域数据稀疏的影响。大量的离线和在线实验表明，我们的方法在提升广告效果和减少预测偏差方面具有显著优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Confidence-Aware+Multi-Field+Model+Calibration)|0|
|[Adaptive Cross-platform Transportation Time Prediction for Logistics](https://doi.org/10.1145/3627673.3680024)|Shuxin Zhong, Wenjun Lyu, Zhiqing Hong, Guang Yang, Weijian Zuo, Haotian Wang, Guang Wang, Yu Yang, Desheng Zhang|Rutgers University, Piscataway, NJ, USA; JD Logistics, Beijing, China; Florida State University, Tallahassee, FL, USA; Lehigh University, Bethlehem, PA, USA; Rutgers University, Piscataway, NJ, China|Accurate prediction of order transportation time is essential for customer satisfaction in logistics. Existing methods based on origin-destination (OD) pairs do not consider the diversity of road segments, while route-based methods may fail to account for real-time traffic conditions due to the infrequent dispatch schedules of logistics vehicles. In reality, e-commerce platforms have collaborated with multiple logistics companies for parcel delivery, providing a richer dataset that offers a more comprehensive view of real-time transportation conditions. The key insight is that data from one company can serve as internal capability detectors and data from others can act as external environment detectors. However, a significant challenge arises in inferring travel-time-correlated station pairs across different companies, especially without full disclosure of station information. To address this, we design an Adaptive cross-platform Transportation time prediction framework built upon a hypergraph structure, named AdaTrans, comprising: i) A spatial-temporal routing graph learner employs node-centric and edge-centric hyperedges to address the complex, non-pairwise correlations among stations and station pairs within and across companies; ii) A spatial-temporal graph-based transportation time predictor that utilizes multi-task learning to enhance overall transportation time prediction by leveraging the correlations between interconnected sub-tasks (i.e., dwell and travel times prediction) Extensive evaluation with real-world data collected from JD.com, a leading e-commerce platform in China, demonstrates that consolidating records from other companies reduces RMSE, MAE, and MAPE by 12.63%, 5.18%, and 16.67%, compared to state-of-the-art methods.|在物流行业中，准确预测订单运输时间对于提升客户满意度至关重要。现有的基于起点-终点（OD）对的方法未能考虑路段的多样性，而基于路径的方法可能因物流车辆调度计划的不频繁而无法反映实时交通状况。实际上，电子商务平台已与多家物流公司合作进行包裹配送，提供了更丰富的数据集，从而能够更全面地反映实时运输状况。关键见解在于，一家公司的数据可以作为内部能力检测器，而其他公司的数据则可以充当外部环境检测器。然而，在不同公司之间推断与旅行时间相关的站点对存在显著挑战，尤其是在站点信息未完全公开的情况下。为解决这一问题，我们设计了一个基于超图结构的自适应跨平台运输时间预测框架，名为AdaTrans，该框架包括：i) 一个时空路由图学习器，采用以节点为中心和以边为中心的超边来处理公司内部和跨公司站点及站点对之间复杂的非成对相关性；ii) 一个基于时空图的运输时间预测器，利用多任务学习通过利用相互关联的子任务（即停留时间和旅行时间预测）之间的相关性来增强整体运输时间预测。通过从中国领先的电子商务平台京东收集的实际数据进行广泛评估，结果表明，与最先进的方法相比，整合其他公司的记录使RMSE、MAE和MAPE分别降低了12.63%、5.18%和16.67%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adaptive+Cross-platform+Transportation+Time+Prediction+for+Logistics)|0|
|[Understanding and Modeling Job Marketplace with Pretrained Language Models](https://doi.org/10.1145/3627673.3680036)|Yaochen Zhu, Liang Wu, Binchi Zhang, Song Wang, Qi Guo, Liangjie Hong, Luke Simon, Jundong Li||Job marketplace is a heterogeneous graph composed of interactions among members (job-seekers), companies, and jobs. Understanding and modeling job marketplace can benefit both job seekers and employers, ultimately contributing to the greater good of the society. However, existing graph neural network (GNN)-based methods have shallow understandings of the associated textual features and heterogeneous relations. To address the above challenges, we propose PLM4Job, a job marketplace foundation model that tightly couples pretrained language models (PLM) with job market graph, aiming to fully utilize the pretrained knowledge and reasoning ability to model member/job textual features as well as various member-job relations simultaneously. In the pretraining phase, we propose a heterogeneous ego-graph-based prompting strategy to model and aggregate member/job textual features based on the topological structure around the target member/job node, where entity type embeddings and graph positional embeddings are introduced accordingly to model different entities and their heterogeneous relations. Meanwhile, a proximity-aware attention alignment strategy is designed to dynamically adjust the attention of the PLM on ego-graph node tokens in the prompt, such that the attention can be better aligned with job marketplace semantics. Extensive experiments at LinkedIn demonstrate the effectiveness of PLM4Job.|职位市场是一个由成员（求职者）、公司和职位之间的互动构成的异质图。理解和建模职位市场可以同时惠及求职者和雇主，最终促进社会的更大利益。然而，现有的基于图神经网络（GNN）的方法对相关文本特征和异质关系的理解较为浅显。为了解决上述挑战，我们提出了PLM4Job，一个将预训练语言模型（PLM）与职位市场图紧密结合的职位市场基础模型，旨在充分利用预训练知识和推理能力，同时建模成员/职位文本特征以及各种成员-职位关系。在预训练阶段，我们提出了一种基于异质自我图的提示策略，以基于目标成员/职位节点周围的拓扑结构来建模和聚合成员/职位文本特征，其中引入了实体类型嵌入和图位置嵌入，以建模不同实体及其异质关系。同时，设计了一种邻近感知的注意力对齐策略，动态调整PLM在提示中对自我图节点标记的注意力，使得注意力能够更好地与职位市场语义对齐。在LinkedIn上的大量实验证明了PLM4Job的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+and+Modeling+Job+Marketplace+with+Pretrained+Language+Models)|0|
|[XplainScreen: Unveiling the Black Box of Graph Neural Network Drug Screening Models with a Unified XAI Framework](https://doi.org/10.1145/3627673.3679236)|Geonhee Ahn, Md. Mahim Anjum Haque, Subhashis Hazarika, Soo Kyung Kim|Luminary-AI, Blacksburg, VA, USA; Fujitsu Research of America, Santa Clara, CA, USA; Ewha Womans University, Seoul, Republic of Korea|Despite the powerful capabilities of GNN-based drug screening model in predicting target drug properties, the black-box nature of these models poses a challenge for practical application, particularly in a field as critical as drug development where understanding and trust in AI-driven decisions are important. To address the interpretability issues associated with GNN-based virtual drug screening, we introduce XplainScreen: a unified explanation framework designed to evaluate various explanation methods for GNN-based models. XplainScreen offers a user-friendly, web-based interactive platform that allows for the selection of specific GNN-based drug screening models and multiple cutting-edge explainable AI methods. It supports both qualitative assessments (through visualization and generative text descriptions) and quantitative evaluations of these methods, utilizing drug molecules in SMILES format. This demonstration showcases the utility of XplainScreen through a user study with pharmacological researchers focused on virtual screening tasks based on toxicity, highlighting the framework's potential to enhance the integrity and trustworthiness of AI-driven virtual drug screening. A video demo of XplainScreen is available at https://youtu.be/Q4yobrTLKec, and the source code can be accessed at https://github.com/GeonHeeAhn/XplainScreen.|尽管基于图神经网络（GNN）的药物筛选模型在预测目标药物性质方面具有强大的能力，但这些模型的黑箱特性为实际应用带来了挑战，尤其是在药物开发这一关键领域，理解和信任人工智能驱动的决策至关重要。为了解决与基于GNN的虚拟药物筛选相关的可解释性问题，我们引入了XplainScreen：一个统一的解释框架，旨在评估基于GNN模型的各种解释方法。XplainScreen提供了一个用户友好的、基于网络的交互平台，允许用户选择特定的基于GNN的药物筛选模型和多种前沿的可解释人工智能方法。它支持对这些方法进行定性评估（通过可视化和生成性文本描述）和定量评估，并利用SMILES格式的药物分子。本演示通过与专注于基于毒性的虚拟筛选任务的药理学研究人员进行的用户研究，展示了XplainScreen的实用性，突出了该框架在增强人工智能驱动的虚拟药物筛选的完整性和可信度方面的潜力。XplainScreen的视频演示可在https://youtu.be/Q4yobrTLKec观看，源代码可在https://github.com/GeonHeeAhn/XplainScreen获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=XplainScreen:+Unveiling+the+Black+Box+of+Graph+Neural+Network+Drug+Screening+Models+with+a+Unified+XAI+Framework)|0|
|[AuditLLM: A Tool for Auditing Large Language Models Using Multiprobe Approach](https://doi.org/10.1145/3627673.3679222)|Maryam Amirizaniani, Elias Martin, Tanya Roosta, Aman Chadha, Chirag Shah||As Large Language Models (LLMs) are integrated into various sectors, ensuringtheir reliability and safety is crucial. This necessitates rigorous probing andauditing to maintain their effectiveness and trustworthiness in practicalapplications. Subjecting LLMs to varied iterations of a single query can unveilpotential inconsistencies in their knowledge base or functional capacity.However, a tool for performing such audits with a easy to execute workflow, andlow technical threshold is lacking. In this demo, we introduce “AuditLLM,” anovel tool designed to audit the performance of various LLMs in a methodicalway. AuditLLM's primary function is to audit a given LLM by deploying multipleprobes derived from a single question, thus detecting any inconsistencies inthe model's comprehension or performance. A robust, reliable, and consistentLLM is expected to generate semantically similar responses to variably phrasedversions of the same question. Building on this premise, AuditLLM generateseasily interpretable results that reflect the LLM's consistency based on asingle input question provided by the user. A certain level of inconsistencyhas been shown to be an indicator of potential bias, hallucinations, and otherissues. One could then use the output of AuditLLM to further investigate issueswith the aforementioned LLM. To facilitate demonstration and practical uses,AuditLLM offers two key modes: (1) Live mode which allows instant auditing ofLLMs by analyzing responses to real-time queries; and (2) Batch mode whichfacilitates comprehensive LLM auditing by processing multiple queries at oncefor in-depth analysis. This tool is beneficial for both researchers and generalusers, as it enhances our understanding of LLMs' capabilities in generatingresponses, using a standardized auditing platform.|随着大型语言模型（LLMs）被整合到各个领域，确保其可靠性和安全性变得至关重要。这需要进行严格的探测和审计，以保持其在实际应用中的有效性和可信度。通过将同一查询的不同变体输入LLMs，可以揭示其知识库或功能能力中的潜在不一致性。然而，目前缺乏一种能够以易于执行的工作流程和低技术门槛进行此类审计的工具。在本演示中，我们介绍了一种名为“AuditLLM”的新工具，旨在系统化地审计各种LLMs的性能。AuditLLM的主要功能是通过部署从单一问题派生的多个探测来审计给定的LLM，从而检测模型在理解或性能上的任何不一致性。一个强大、可靠且一致的LLM应该能够对同一问题的不同表述生成语义相似的响应。基于这一前提，AuditLLM生成易于解释的结果，这些结果反映了基于用户提供的单一输入问题的LLM一致性。一定程度的不一致性已被证明是潜在偏见、幻觉和其他问题的指标。然后，用户可以利用AuditLLM的输出进一步调查上述LLM的问题。为了方便演示和实际使用，AuditLLM提供了两种关键模式：（1）实时模式，允许通过分析对实时查询的响应来即时审计LLMs；（2）批量模式，通过同时处理多个查询以进行深入分析，从而促进全面的LLM审计。该工具对研究人员和普通用户都有益，因为它通过标准化的审计平台增强了我们对LLMs生成响应能力的理解。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AuditLLM:+A+Tool+for+Auditing+Large+Language+Models+Using+Multiprobe+Approach)|0|
|[Preserving Old Memories in Vivid Detail: Human-Interactive Photo Restoration Framework](https://doi.org/10.1145/3627673.3679215)|SeungYeon Back, Geonho Son, Dahye Jeong, Eunil Park, Simon S. Woo||Photo restoration technology enables preserving visual memories in photographs. However, physical prints are vulnerable to various forms of deterioration, ranging from physical damage to loss of image quality, etc. While restoration by human experts can improve the quality of outcomes, it often comes at a high price in terms of cost and time for restoration. In this work, we present the AI-based photo restoration framework composed of multiple stages, where each stage is tailored to enhance and restore specific types of photo damage, accelerating and automating the photo restoration process. By integrating these techniques into a unified architecture, our framework aims to offer a one-stop solution for restoring old and deteriorated photographs. Furthermore, we present a novel old photo restoration dataset because we lack a publicly available dataset for our evaluation.|照片修复技术能够保存照片中的视觉记忆。然而，实体照片容易受到各种形式的损坏，从物理损伤到图像质量下降等。虽然由人类专家进行修复可以提高修复结果的质量，但这往往需要高昂的成本和时间。在本研究中，我们提出了一种基于人工智能的照片修复框架，该框架由多个阶段组成，每个阶段都针对特定类型的照片损坏进行增强和修复，从而加速并自动化照片修复过程。通过将这些技术整合到一个统一的架构中，我们的框架旨在为修复老旧和损坏的照片提供一站式解决方案。此外，由于缺乏公开可用的评估数据集，我们提出了一个新的老照片修复数据集。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Preserving+Old+Memories+in+Vivid+Detail:+Human-Interactive+Photo+Restoration+Framework)|0|
|[FactCheckBureau: Build Your Own Fact-Check Analysis Pipeline](https://doi.org/10.1145/3627673.3679220)|Oana Balalau, Pablo BertaudVelten, Younes El Fraihi, Garima Gaur, Oana Goga, Samuel Guimaraes, Ioana Manolescu, Brahim Saadi|Federal University of Minas Gerais, CNRS, Institut Polytechnique de Paris, Belo Horizonte, Brazil; CNRS, Institut Polytechnique de Paris, Palaiseau, France; INRIA, CNRS, Institut Polytechnique de Paris, Palaiseau, France; INRIA, Institut Polytechnique de Paris, Palaiseau, France|Fact-checkers are overwhelmed by the volume of claims they need to pay attention to fight misinformation. Even once debunked, a claim may still be spread by people unaware that it is false, or it may be recycled as a source of inspiration by malicious users. Hence, the importance of fact-check (FC) retrieval as a research problem: given a claim and a database of previous checks, find the checks relevant to the claim. Existing solutions addressing this problem rely on the strategy of retrieve and re-rank relevant documents. We have built FactCheckBureau, an end-to-end solution that enables researchers to easily and interactively design and evaluate FC retrieval pipelines. We also present a corpus we have built, which can be used in further research to test fact-check retrieval tools. The source code of our tool is available at this link.|事实核查人员在应对需要关注的大量声明以打击错误信息时常常感到不堪重负。即使某个声明已被揭穿，仍可能被不知情者传播，或被恶意用户重新利用作为灵感来源。因此，事实核查（FC）检索作为一个研究问题的重要性不言而喻：给定一个声明和一个以往核查的数据库，找到与该声明相关的核查。现有的解决方案依赖于检索和重新排序相关文档的策略。我们构建了FactCheckBureau，这是一个端到端的解决方案，使研究人员能够轻松且交互式地设计和评估FC检索流程。我们还展示了一个我们构建的语料库，该语料库可用于进一步研究以测试事实核查检索工具。我们工具的源代码可通过此链接获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FactCheckBureau:+Build+Your+Own+Fact-Check+Analysis+Pipeline)|0|
|[Music2P: A Multi-Modal AI-Driven Tool for Simplifying Album Cover Design](https://doi.org/10.1145/3627673.3679223)|Joong Ho Choi, Geonyeong Choi, Ji Eun Han, Wonjin Yang, ZhiQi Cheng||In today's music industry, album cover design is as crucial as the music itself, reflecting the artist's vision and brand. However, many AI-driven album cover services require subscriptions or technical expertise, limiting accessibility. To address these challenges, we developed Music2P, an open-source, multi-modal AI-driven tool that streamlines album cover creation, making it efficient, accessible, and cost-effective through Ngrok. Music2P automates the design process using techniques such as Bootstrapping Language Image Pre-training (BLIP), music-to-text conversion (LP-music-caps), image segmentation (LoRA), and album cover and QR code generation (ControlNet). This paper demonstrates the Music2P interface, details our application of these technologies, and outlines future improvements. Our ultimate goal is to provide a tool that empowers musicians and producers, especially those with limited resources or expertise, to create compelling album covers.|在当今的音乐产业中，专辑封面设计与音乐本身同样重要，它体现了艺术家的愿景和品牌形象。然而，许多基于人工智能的专辑封面服务需要订阅或技术专长，限制了其可及性。为了解决这些问题，我们开发了Music2P，这是一款开源的多模态人工智能驱动工具，通过Ngrok简化了专辑封面的创作过程，使其高效、易用且经济实惠。Music2P利用自举语言图像预训练（BLIP）、音乐到文本转换（LP-music-caps）、图像分割（LoRA）以及专辑封面和二维码生成（ControlNet）等技术，自动化了设计流程。本文展示了Music2P的界面，详细介绍了我们如何应用这些技术，并概述了未来的改进方向。我们的最终目标是提供一个工具，帮助音乐家和制作人，尤其是那些资源或专业知识有限的人，创作出引人注目的专辑封面。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Music2P:+A+Multi-Modal+AI-Driven+Tool+for+Simplifying+Album+Cover+Design)|0|
|[Shaded Route Planning Using Active Segmentation and Identification of Satellite Images](https://doi.org/10.1145/3627673.3679234)|Longchao Da, Rohan Chhibba, Rushabh Jaiswal, Ariane Middel, Hua Wei||Heatwaves pose significant health risks, particularly due to prolonged exposure to high summer temperatures. Vulnerable groups, especially pedestrians and cyclists on sun-exposed sidewalks, motivate the development of a route planning method that incorporates somatosensory temperature effects through shade ratio consideration. This paper is the first to introduce a pipeline that utilizes segmentation foundation models to extract shaded areas from high-resolution satellite images. These areas are then integrated into a multi-layered road map, enabling users to customize routes based on a balance between distance and shade exposure, thereby enhancing comfort and health during outdoor activities. Specifically, we construct a graph-based representation of the road map, where links indicate connectivity and are updated with shade ratio data for dynamic route planning. This system is already implemented online, with a video demonstration, and will be specifically adapted to assist travelers during the 2024 Olympic Games in Paris.|热浪对健康构成重大威胁，尤其是由于长时间暴露在夏季高温环境下。易受影响的群体，特别是那些在阳光直射的人行道上行走或骑行的行人和骑行者，促使我们开发了一种通过考虑遮阳比例来整合体感温度效应的路径规划方法。本文首次提出了一种利用分割基础模型从高分辨率卫星图像中提取阴影区域的流程。这些阴影区域随后被整合到一个多层道路地图中，使用户能够根据距离和遮阳暴露之间的平衡来定制路线，从而提升户外活动的舒适度和健康水平。具体而言，我们构建了一个基于图的道路地图表示，其中链接表示连通性，并通过遮阳比例数据进行更新，以实现动态路径规划。该系统已在线实现，并配有视频演示，将特别适用于2024年巴黎奥运会期间为旅行者提供帮助。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Shaded+Route+Planning+Using+Active+Segmentation+and+Identification+of+Satellite+Images)|0|
|[A Skill Proficiency Framework for Workforce Learning and Development](https://doi.org/10.1145/3627673.3679228)|Rebecca Dew, Mingzhao Li, Sandya Baratha Raj|Pearson, Melbourne, Australia; Pearson, Adelaide, Australia; Pearson, Sydney, Australia|Understanding the skills and proficiency levels required for various roles is crucial for effective workforce planning, learning and development. In this paper, we propose a robust skill proficiency modeling framework that offers a structured method to help describe, assess and develop proficiency in key skills, facilitating individuals' career pathways and aiding organizations in talent management and adaptability. We first design a skill proficiency description pipeline, which generates statements describing the requirements at each proficiency level of a skill. Following this, we build a skill proficiency by occupation model using large-scale job ad data to help organizations and individuals understand the skill proficiency requirements for different roles. Finally,we design a visual analytics system, based on a real-world career pathway scenario, to demonstrate the practical usefulness and effectiveness of our framework. A demo video is available at www.dropbox.com/scl/fi/nd0f3vi03n12g4y0sluaw/cikm24_demo.mp4?rlkey=55vya144q5ftai1uqqaubr5u5.|理解不同职位所需的技能和熟练程度对于有效的人力资源规划、学习和发展至关重要。在本文中，我们提出了一个稳健的技能熟练度建模框架，该框架提供了一种结构化的方法，帮助描述、评估和发展关键技能的熟练度，从而促进个人的职业发展路径，并协助组织进行人才管理和适应性调整。我们首先设计了一个技能熟练度描述管道，该管道生成描述每个技能熟练度级别要求的陈述。随后，我们利用大规模招聘广告数据构建了一个按职业划分的技能熟练度模型，以帮助组织和个人理解不同职位所需的技能熟练度要求。最后，我们基于一个真实的职业发展路径场景设计了一个可视化分析系统，以展示我们框架的实际实用性和有效性。演示视频可在以下链接获取：www.dropbox.com/scl/fi/nd0f3vi03n12g4y0sluaw/cikm24_demo.mp4?rlkey=55vya144q5ftai1uqqaubr5u5。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Skill+Proficiency+Framework+for+Workforce+Learning+and+Development)|0|
|[Human-in-the-Loop Feature Discovery for Tabular Data](https://doi.org/10.1145/3627673.3679211)|Andra Ionescu, Zeger Mouw, Efthimia Aivaloglou, Rihan Hai, Asterios Katsifodimos|Delft University of Technology, Delft, Netherlands|In recent years, researchers have developed several methods to automate discovering datasets and augmenting features for training Machine Learning (ML) models. Together with feature selection, these efforts have paved the way towards what is termed the feature discovery process. Data scientists and engineers use automated feature discovery over tabular datasets to add new features from different sources and enrich training data. By surveying data practitioners, we have observed that automated feature discovery approaches do not allow data scientists to use their domain knowledge during the feature discovery process. In addition, automated feature discovery methods can leak private features or introduce biased ones. In this paper, we introduce the first user-driven human-in-the-loop feature discovery method called HILAutoFeat. We demonstrate the capabilities of HILAutoFeat, which effectively combines automated feature discovery with user-driven insights. Our demonstration is centred around two scenarios: (i) an automated feature discovery scenario -- HILAutoFeat acts as a steward in a large data lake where the user is unaware of the quality and relevance of the data, and (ii) a scenario where HILAutoFeat and the user work together -- the user drives the feature discovery process by adding his domain and business knowledge, while HILAutoFeat performs the intensive computations.|近年来，研究人员开发了多种方法来自动化发现数据集并增强用于训练机器学习（ML）模型的特征。这些努力与特征选择相结合，为所谓的特征发现过程铺平了道路。数据科学家和工程师在表格数据集上使用自动化特征发现，从不同来源添加新特征并丰富训练数据。通过对数据从业者的调查，我们观察到自动化特征发现方法不允许数据科学家在特征发现过程中使用他们的领域知识。此外，自动化特征发现方法可能会泄露私有特征或引入有偏见的特征。在本文中，我们介绍了一种名为HILAutoFeat的首个用户驱动的人机交互特征发现方法。我们展示了HILAutoFeat的能力，它有效地将自动化特征发现与用户驱动的洞察相结合。我们的演示围绕两个场景展开：（i）自动化特征发现场景——HILAutoFeat在大型数据湖中充当管理员，用户对数据的质量和相关性一无所知；（ii）HILAutoFeat与用户合作的场景——用户通过添加其领域和业务知识来驱动特征发现过程，而HILAutoFeat执行密集的计算。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Human-in-the-Loop+Feature+Discovery+for+Tabular+Data)|0|
|[DirDense: A Tool for Mining Dense Subgraphs from a Big Directed Graph](https://doi.org/10.1145/3627673.3679207)|Jalal Khalil, Akhlaque Ahmad, Da Yan, Lyuheng Yuan, Saugat Adhikari, Yang Zhou, Zhe Jiang|St. Cloud State University, St. Cloud, Minnesota, USA; Indiana University Bloomington, Bloomington, Indiana, USA; Auburn University, Auburn, Alabama, USA; University of Florida, Gainesville, Florida, USA|Mining dense subgraphs from a big graph is important in applications such as community (or module) detection in social (or biological) networks. While most dense structures are defined on undirected graphs, recent efforts have generalized these notions to directed graphs. In this demonstration paper, we present DirDense, an interactive tool that makes it easy for end-users to mine dense structures from a big directed graph. DirDense currently supports the mining of maximal (γ1, γ2)-quasi-cliques, maximal (k 1,k 1)-plexes, and the directed densest subgraph. DirDense facilitates parameter tuning for each type of the structure-mining tasks, and provides intuitive interfaces to visualize and examine the dense directed structures. Using real-world data, we showcase how users can mine dense directed structures by parameter tuning in DirDense, and how they can conveniently examine these structures and cascade the mining tasks to find progressively larger dense subgraphs more quickly.|从大规模图中挖掘密集子图在社交网络（或生物网络）中的社区（或模块）检测等应用中具有重要意义。虽然大多数密集结构是在无向图上定义的，但最近的研究已经将这些概念推广到了有向图。在这篇演示论文中，我们介绍了DirDense，这是一个交互式工具，使终端用户能够轻松地从大规模有向图中挖掘密集结构。DirDense目前支持挖掘最大（γ1, γ2）-准团、最大（k 1,k 1）-plex以及有向最密集子图。DirDense为每种结构挖掘任务提供了参数调优功能，并提供了直观的界面来可视化和检查密集有向结构。通过使用真实世界的数据，我们展示了用户如何在DirDense中通过参数调优来挖掘密集有向结构，以及如何方便地检查这些结构并级联挖掘任务，以更快地找到逐步增大的密集子图。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DirDense:+A+Tool+for+Mining+Dense+Subgraphs+from+a+Big+Directed+Graph)|0|
|[A One-Health Platform for Antimicrobial Resistance Data Analytics](https://doi.org/10.1145/3627673.3679237)|Benoit Lange, Reza Akbarinia, Florent Masseglia|Inria, University of Montpellier, CNRS, LIRMM, MONTPELLIER, Occitanie, France|Antimicrobial resistance (AMR) poses potentially critical health issues for human and animal populations in the near future. To meet this challenge, we need to adopt a "One Health" strategy, which involves studying and linking information from human and animal populations, as well as from the environment. In this demonstration, we present an early prototype of PROMISE platform, which we are developing for One Health data management and analytics, to enable experts from different fields to gain insights into AMR. It is designed to handle data from 25 academic networks and 42 partners. Our demonstration illustrate the capabilities of our methodology for analyzing these data. The user is freed from considerations related to data heterogeneity, as interoperability issues are managed by the platform. Additionally, each data provider will be able to stay within his/her own vocabulary, whatever the taxonomy used by other data providers.|抗菌素耐药性（AMR）在不久的将来可能对人类和动物群体构成严重的健康威胁。为了应对这一挑战，我们需要采用“一体健康”（One Health）策略，该策略涉及研究和整合来自人类和动物群体以及环境的信息。在本演示中，我们展示了PROMISE平台的早期原型，该平台是我们为“一体健康”数据管理和分析开发的，旨在使不同领域的专家能够深入了解AMR。该平台设计用于处理来自25个学术网络和42个合作伙伴的数据。我们的演示展示了我们分析这些数据的方法的能力。用户无需考虑与数据异质性相关的问题，因为平台会处理互操作性问题。此外，无论其他数据提供者使用何种分类法，每个数据提供者都将能够使用自己的词汇表。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+One-Health+Platform+for+Antimicrobial+Resistance+Data+Analytics)|0|
|[DiaKoP: Dialogue-based Knowledge-oriented Programming for Neural-symbolic Knowledge Base Question Answering](https://doi.org/10.1145/3627673.3679229)|Zhicheng Lee, Zhidian Huang, Zijun Yao, Jinxin Liu, Amy Xin, Lei Hou, Juanzi Li||We present Dialogue-based Knowledge-oriented Programming system (DiaKoP), a system with a chat interface designed for multi-turn knowledge base question answering (KBQA). DiaKoP enables users to decompose complex questions into multiple simpler follow-up questions and interact with the system to obtain answers. Multi-turn KBQA presents unique challenges because users may switch topics or ask incomplete questions that rely on previous interactions. To address this, we develop a Dialogue History Tracker and Dialogue Policy to manage user conversations effectively. Additionally, we enhance the knowledge from the knowledge graph by integrating parametric knowledge from a large language model (LLM) to provide more comprehensive answers. To mitigate the issue of wrongly parsed questions by semantic parser, we implement a human-in-the-loop mechanism, allowing users to correct errors. We evaluate DiaKoP both qualitatively and quantitatively, with user study indicating that our system better meets users' needs. DiaKoP is open-sourced on https://github.com/THU-KEG/DiaKoP with a guiding demo on https://youtu.be/Tq17k0OxPVg.|我们提出了基于对话的知识导向编程系统（DiaKoP），这是一个具有聊天界面的系统，专为多轮知识库问答（KBQA）而设计。DiaKoP使用户能够将复杂问题分解为多个更简单的后续问题，并通过与系统交互来获取答案。多轮KBQA带来了独特的挑战，因为用户可能会切换话题或提出依赖于先前交互的不完整问题。为了解决这些问题，我们开发了对话历史追踪器和对话策略，以有效管理用户对话。此外，我们通过整合来自大型语言模型（LLM）的参数化知识来增强知识图谱中的知识，以提供更全面的答案。为了减轻语义解析器错误解析问题的影响，我们实施了人机交互机制，允许用户纠正错误。我们对DiaKoP进行了定性和定量评估，用户研究表明我们的系统更好地满足了用户需求。DiaKoP已在https://github.com/THU-KEG/DiaKoP上开源，并在https://youtu.be/Tq17k0OxPVg上提供了指导演示。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DiaKoP:+Dialogue-based+Knowledge-oriented+Programming+for+Neural-symbolic+Knowledge+Base+Question+Answering)|0|
|[EHR-Based Mobile and Web Platform for Chronic Disease Risk Prediction Using Large Language Multimodal Models](https://doi.org/10.1145/3627673.3679227)|ChunChieh Liao, WeiTing Kuo, IHsuan Hu, YenChen Shih, JunEn Ding, Feng Liu, FangMing Hung||Traditional diagnosis of chronic diseases involves in-person consultations with physicians to identify the disease. However, there is a lack of research focused on predicting and developing application systems using clinical notes and blood test values. We collected five years of Electronic Health Records (EHRs) from Taiwan's hospital database between 2017 and 2021 as an AI database. Furthermore, we developed an EHR-based chronic disease prediction platform utilizing Large Language Multimodal Models (LLMMs), successfully integrating with frontend web and mobile applications for prediction. This prediction platform can also connect to the hospital's backend database, providing physicians with real-time risk assessment diagnostics. The demonstration link can be found at https://www.youtube.com/watch?v=oqmL9DEDFgA.|传统的慢性疾病诊断需要患者与医生面对面咨询以确定疾病。然而，目前缺乏利用临床记录和血液检测值进行预测和开发应用系统的研究。我们从台湾医院数据库中收集了2017年至2021年间的五年电子健康记录（EHRs），构建了一个AI数据库。此外，我们开发了一个基于EHR的慢性疾病预测平台，利用大型语言多模态模型（LLMMs），并成功集成了前端网页和移动应用程序进行预测。该预测平台还可以连接到医院的后端数据库，为医生提供实时的风险评估诊断。演示链接可在https://www.youtube.com/watch?v=oqmL9DEDFgA找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EHR-Based+Mobile+and+Web+Platform+for+Chronic+Disease+Risk+Prediction+Using+Large+Language+Multimodal+Models)|0|
|[Demonstrating PARS: A Decision Support System for Developing Vertical Partitioning Plans](https://doi.org/10.1145/3627673.3679224)|Pengju Liu, Kai Zhong, Cuiping Li, Hong Chen|Renmin University of China, Beijing, China|Vertical partitioning is a crucial physical design strategy in databases that enhances data management and retrieval through optimal data placement. However, current research often overlooks the use of query predicates for effective data block allocation, resulting in potential performance bottlenecks. Moreover, selecting an appropriate partitioning technique based solely on historical experimental results from research articles is challenging due to variability in storage devices, evaluation metrics, and database schemas. We propose PARS to address these issues by offering end-to-end input/output, customizable database configurations, and prioritized optimization objectives to aid database administrators (DBAs) in making informed partitioning decisions. Additionally, PARS introduces a novel algorithm that leverages both numeric and non-numeric query predicates to partition the tablespace into finer data blocks, reducing query latency by 36.1% when benchmarked against the state-of-the-art (SOTA) method.|垂直分区是数据库中一种关键的物理设计策略，通过优化数据布局来增强数据管理和检索效率。然而，当前的研究往往忽视了利用查询谓词进行有效的数据块分配，从而导致潜在的性能瓶颈。此外，由于存储设备、评估指标和数据库模式的差异性，仅依赖研究文章中的历史实验结果来选择合适的分区技术具有挑战性。我们提出了PARS来解决这些问题，它提供了端到端的输入/输出、可定制的数据库配置以及优先优化的目标，以帮助数据库管理员（DBA）做出明智的分区决策。此外，PARS引入了一种新颖的算法，该算法利用数值和非数值查询谓词将表空间划分为更细粒度的数据块，与最先进的（SOTA）方法相比，查询延迟减少了36.1%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Demonstrating+PARS:+A+Decision+Support+System+for+Developing+Vertical+Partitioning+Plans)|0|
|[OpenTOS: Open-source System for Transfer Learning Bayesian Optimization](https://doi.org/10.1145/3627673.3679225)|Peili Mao, Ke Li|University of Exeter, Exeter, United Kingdom; University of Electronic Science and Technology of China, Chengdu, Sichuan, China|In recent years, many studies successfully integrated transfer learning techniques to improve the performance of Bayesian optimization. However, these advanced methods have not been widely adopted in real-world applications due to their inherent complexity and challenges in re-implementation and reproducibility. In this work, we introduce OpenTOS, an open-source system designed for transfer learning in Bayesian optimization. OpenTOS introduces a new implementation paradigm for these methods, allowing users to build different algorithms by choosing algorithmic components, similar to assembling LEGO blocks. Additionally, OpenTOS provides robust data management for supporting transfer learning with data from various sources. We also developed a web interface that allows for interactive building, analysis, and visualization of the optimization process. Powered by LLM, this interface offers a conversational experience, allowing users to interact with the system through natural language dialogue. OpenTOS is available as open-source on https://github.com/COLA-Laboratory/TransOPTGitHub .|近年来，许多研究成功地集成了迁移学习技术来提升贝叶斯优化的性能。然而，由于这些先进方法固有的复杂性以及在重新实现和可重复性方面的挑战，它们尚未在现实世界应用中得到广泛采用。在本研究中，我们介绍了OpenTOS，这是一个专为贝叶斯优化中的迁移学习设计的开源系统。OpenTOS为这些方法引入了一种新的实现范式，允许用户通过选择算法组件来构建不同的算法，类似于组装乐高积木。此外，OpenTOS提供了强大的数据管理功能，以支持从各种来源的数据进行迁移学习。我们还开发了一个网络界面，允许用户交互式地构建、分析和可视化优化过程。该界面由大语言模型（LLM）驱动，提供了对话式体验，使用户能够通过自然语言对话与系统进行交互。OpenTOS已在https://github.com/COLA-Laboratory/TransOPTGitHub 上开源提供。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=OpenTOS:+Open-source+System+for+Transfer+Learning+Bayesian+Optimization)|0|
|[GARF: A Self-supervised Data Cleaning System with SeqGAN](https://doi.org/10.1145/3627673.3679226)|Jinfeng Peng, Hanghai Cui, Derong Shen, Yue Kou, Tiezheng Nie, Tianlong Guo|Northeastern University, Shenyang, China|High-quality data is essential for data science and machine learning applications, but unfortunately, real-world data often contains significant amounts of errors, such as typos, missing values, and data inconsistencies. Despite all the efforts in cleaning data using either logical or learning-based methods, in practice, data cleaning still requires high human cost, for either manually providing data repairing rules or preparing labeled datasets for training machine learning models. In this paper, we introduce GARF, a novel data cleaning system based on sequence generative adversarial networks (SeqGAN). One key information GARF tries to learn is data repair rules. To automatically extracts data repair rules from dirty data, GARF employs a SeqGAN to capture the dependency relationships, and converts the information learned by machine to interpretable data repair rules for humans. Additionally, considering that both generated rules and data may not be fully trusted, GARF provides a co-cleaning process to iteratively update inaccurate rules and repair dirty data until there is no tuple violating rules. We have implemented and deployed GARF as an open-sourced system, and demonstrated its usability on data cleaning in real-world scenarios.|高质量的数据对于数据科学和机器学习应用至关重要，但遗憾的是，现实世界中的数据往往包含大量错误，例如拼写错误、缺失值以及数据不一致。尽管已经通过逻辑方法或基于学习的方法进行了数据清洗，但在实际应用中，数据清洗仍然需要高昂的人力成本，无论是手动提供数据修复规则，还是为训练机器学习模型准备标注数据集。本文介绍了一种基于序列生成对抗网络（SeqGAN）的新型数据清洗系统GARF。GARF试图学习的关键信息之一是数据修复规则。为了从脏数据中自动提取数据修复规则，GARF利用SeqGAN来捕获依赖关系，并将机器学习到的信息转换为人类可解释的数据修复规则。此外，考虑到生成的规则和数据可能不完全可信，GARF提供了一个协同清洗过程，以迭代更新不准确的规则并修复脏数据，直到没有违反规则的元组为止。我们已经将GARF实现并部署为一个开源系统，并在现实场景中展示了其在数据清洗中的可用性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GARF:+A+Self-supervised+Data+Cleaning+System+with+SeqGAN)|0|
|[CourtsightTV: An Interactive Visualization Software for Labeling Key Basketball Moments](https://doi.org/10.1145/3627673.3679230)|Alexander Russakoff, Kenny Miller, Vahid Mahzoon, Parsa Esmaeilkhani, Christine Cho, Jaffar Alzeidi, Sandro Hauri, Slobodan Vucetic|Temple University, Philadelphia, USA|Advancements in sensor technology are leading to massive collection of tracking data in sports. There is an increasing interest in analyzing the tracking data to gain competitive advantage. Analyzing and labeling key game moments can provide deep insights into player performance, team dynamics, as well as game strategy. However, the process of manually labeling and analyzing these moments is costly and time-consuming. In this paper, we describe a visual interface for user-friendly and efficient labeling of key moments in basketball games aided by neural networks. We report results of a user study evaluating the labeling interface.|传感器技术的进步正在推动体育领域追踪数据的大规模收集。分析这些追踪数据以获得竞争优势的兴趣日益增加。分析和标注关键比赛时刻能够为球员表现、团队动态以及比赛策略提供深入的洞察。然而，手动标注和分析这些时刻的过程既昂贵又耗时。本文描述了一种基于神经网络辅助的、用户友好且高效的篮球比赛关键时刻标注视觉界面。我们还报告了一项用户研究的结果，该研究评估了标注界面的效果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CourtsightTV:+An+Interactive+Visualization+Software+for+Labeling+Key+Basketball+Moments)|0|
|[A Scalable Tool for Democratizing Variant Calling on Human Genomes Using Commodity Clusters](https://doi.org/10.1145/3627673.3679221)|Khawar Shehzad, Ajay Kumar, Matthew Schutz, Chase Webb, Polycarp Nalela, Manas Jyoti Das, Praveen Rao|University of Missouri, Columbia, USA|Variant calling is a fundamental task that involves identifying variants in an individual's genome compared to the reference genome. Knowing these variants is critical for assessing an individual's risk for diseases such as cancer and developing new treatments. Due to the large size of human genome sequences, processing and analyzing them requires significant compute and storage resources. Cluster computing is an attractive solution for processing a large workload of human genomes. In this paper, we present a scalable tool for democratizing variant calling on human genome sequences using testbeds that are available for academic research at no charge. Our tool can (a) execute two types of variant calling pipelines in a commodity cluster with CPUs and graphics processing units (GPUs); (b) enable improved cluster utilization and faster execution via asynchronous computations, minimal synchronization, and mutual exclusion when employing GPUs; and (c) execute variant calling pipelines of multiple users concurrently. Using publicly available human genome sequences, users can interactively experience the unique features of our tool, which has a low barrier to entry for large-scale variant calling.|变异检测是一项基础任务，涉及识别个体基因组与参考基因组之间的变异。了解这些变异对于评估个体患癌症等疾病的风险以及开发新的治疗方法至关重要。由于人类基因组序列的规模庞大，处理和分析这些序列需要大量的计算和存储资源。集群计算是处理大量人类基因组工作负载的一个有吸引力的解决方案。在本文中，我们提出了一种可扩展的工具，利用免费提供给学术研究的测试平台，使人类基因组序列的变异检测更加普及。我们的工具可以（a）在配备CPU和图形处理单元（GPU）的商用集群上执行两种类型的变异检测流程；（b）通过异步计算、最小化同步和在使用GPU时采用互斥机制，提高集群利用率和加快执行速度；（c）同时执行多个用户的变异检测流程。利用公开可用的人类基因组序列，用户可以交互式地体验我们工具的独特功能，该工具在大规模变异检测方面具有较低的入门门槛。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Scalable+Tool+for+Democratizing+Variant+Calling+on+Human+Genomes+Using+Commodity+Clusters)|0|
|[Demonstration of a Multi-agent Framework for Text to SQL Applications with Large Language Models](https://doi.org/10.1145/3627673.3679216)|Chen Shen, Jin Wang, Sajjadur Rahman, Eser Kandogan|Megagon Labs, Mountain View, CA, USA|The Text-to-SQL problem aims at developing natural language query interfaces for relational database systems by converting the text input into executable SQL queries. Recently, using Large Language Models (LLM) has emerged as a new paradigm for the Text-to-SQL problem. To this end, the LLM needs to understand not only user input but also information from the database. In this demo, we present multi-agent SQL (MageSQL), an LLM based Text-to-SQL approach that tackles the task by orchestrating multiple agents in a pipeline. We will showcase a user-friendly interface to demonstrate the inner workings of our approach that allows users to add and modify the agents with different functionalities, customize prompts, and see their impact on specific examples. Through several use cases, we will demonstrate how to (i) construct a Text-to-SQL pipeline with multiple agents; (ii) generate prompts for LLM with various templates and strategies; and (iii) monitor the results of natural language queries and perform debugging.|文本到SQL（Text-to-SQL）问题旨在通过将文本输入转换为可执行的SQL查询，为关系数据库系统开发自然语言查询接口。最近，使用大型语言模型（LLM）已成为解决Text-to-SQL问题的新范式。为此，LLM不仅需要理解用户输入，还需要理解来自数据库的信息。在本演示中，我们展示了多代理SQL（MageSQL），这是一种基于LLM的Text-to-SQL方法，通过在一个流水线中协调多个代理来完成任务。我们将展示一个用户友好的界面，以演示我们方法的内在机制，该界面允许用户添加和修改具有不同功能的代理，自定义提示，并查看它们对具体示例的影响。通过多个用例，我们将展示如何：（i）构建一个包含多个代理的Text-to-SQL流水线；（ii）使用各种模板和策略为LLM生成提示；（iii）监控自然语言查询的结果并进行调试。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Demonstration+of+a+Multi-agent+Framework+for+Text+to+SQL+Applications+with+Large+Language+Models)|0|
|[LINKin-PARK: Land Valuation Information and Knowledge in Predictive Analysis and Reporting Kit via Dual Attention-DCCNN](https://doi.org/10.1145/3627673.3679239)|TengYuan Tsou, ShihYu Lai, HsuanChing Chen, JungTsang Yeh, PeiXuan Li, TzuChang Lee, HsunPing Hsieh|Department of Industrial and Information Management, National Cheng Kung University, Tainan, Taiwan; Department of Urban Planning, National Cheng Kung University, Tainan, Taiwan; Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan|We present LINKin-PARK, an innovative system that seamlessly merges geographic visualization with an advanced Dual Attention Double Channel Convolutional Neural Network with Multilayer Perceptron (Dual Attention-DCCNN+MLP) to facilitate the efficient analysis of land valuation. LINKin-PARK provides robust visualization capabilities for intuitive comprehension. Our model outperforms traditional methods, e.g., linear regression, multilayer perceptron (MLP), Extreme Gradient Boosting (XGBoost), and the combination of CNN (Convolutional Neural Network) with MLP. An ablation study further evaluates the influence of specific components within the model, revealing that spatial and channel-wise attention mechanisms and the integration of DCCNN and skip connections are crucial for capturing spatial details and improving prediction accuracy. Users have the flexibility to explore and predict developable land valuation based on their specific requirements and provide their feedback to minimize errors in model prediction. For instance, this system can forecast future development potential and market demand for everywhere in an urban space, enabling users to make informed decisions before purchasing a property. Similarly, retailers can anticipate future revenues to aid in strategic decisions, such as selecting optimal locations for establishing new retail outlets. In summary, LINKin-PARK effectively combines geographic visualization and Dual Attention-DCCNN+MLP to assist users in analyzing and predicting land valuation and other scenarios.|我们提出了LINKin-PARK，这是一个创新系统，它将地理可视化与先进的双注意力双通道卷积神经网络结合多层感知器（Dual Attention-DCCNN+MLP）无缝融合，以促进土地估值的有效分析。LINKin-PARK提供了强大的可视化能力，便于直观理解。我们的模型优于传统方法，例如线性回归、多层感知器（MLP）、极端梯度提升（XGBoost）以及卷积神经网络（CNN）与多层感知器（MLP）的组合。消融研究进一步评估了模型中特定组件的影响，揭示了空间和通道注意力机制以及DCCNN和跳跃连接的集成对于捕捉空间细节和提高预测准确性至关重要。用户可以根据其特定需求灵活地探索和预测可开发土地的估值，并提供反馈以最小化模型预测中的误差。例如，该系统可以预测城市空间中任何地方未来的发展潜力和市场需求，使用户在购买房产前能够做出明智的决策。同样，零售商可以预测未来收入以辅助战略决策，例如选择建立新零售店的最佳位置。总之，LINKin-PARK有效地结合了地理可视化和双注意力DCCNN+MLP，帮助用户分析和预测土地估值及其他场景。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LINKin-PARK:+Land+Valuation+Information+and+Knowledge+in+Predictive+Analysis+and+Reporting+Kit+via+Dual+Attention-DCCNN)|0|
|[DeliLaw: A Chinese Legal Counselling System Based on a Large Language Model](https://doi.org/10.1145/3627673.3679219)|Nan Xie, Yuelin Bai, Hengyuan Gao, Ziqiang Xue, Feiteng Fang, Qixuan Zhao, Zhijian Li, Liang Zhu, Shiwen Ni, Min Yang||Traditional legal retrieval systems designed to retrieve legal documents, statutes, precedents, and other legal information are unable to give satisfactory answers due to lack of semantic understanding of specific questions. Large Language Models (LLMs) have achieved excellent results in a variety of natural language processing tasks, which inspired us that we train a LLM in the legal domain to help legal retrieval. However, in the Chinese legal domain, due to the complexity of legal questions and the rigour of legal articles, there is no legal large model with satisfactory practical application yet. In this paper, we present DeliLaw, a Chinese legal counselling system based on a large language model. DeliLaw integrates a legal retrieval module and a case retrieval module to overcome the model hallucination. Users can consult professional legal questions, search for legal articles and relevant judgement cases, etc. on the DeliLaw system in a dialogue mode. In addition, DeliLaw supports the use of English for counseling. we provide the address of the system: https://data.delilegal.com/lawQuestion.|传统的法律检索系统旨在检索法律文件、法规、判例和其他法律信息，但由于对特定问题缺乏语义理解，无法给出令人满意的答案。大型语言模型（LLMs）在各种自然语言处理任务中取得了优异的成果，这启发我们在法律领域训练一个大型语言模型以辅助法律检索。然而，在中文法律领域，由于法律问题的复杂性和法律条文的严谨性，目前尚未有具有满意实际应用的法律大模型。在本文中，我们提出了DeliLaw，一个基于大型语言模型的中文法律咨询系统。DeliLaw集成了法律检索模块和案例检索模块，以克服模型幻觉问题。用户可以在DeliLaw系统中以对话模式咨询专业的法律问题、搜索法律条文和相关判决案例等。此外，DeliLaw支持使用英语进行咨询。我们提供了系统的访问地址：https://data.delilegal.com/lawQuestion。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DeliLaw:+A+Chinese+Legal+Counselling+System+Based+on+a+Large+Language+Model)|0|
|[myCADI: my Contextual Anomaly Detection using Isolation](https://doi.org/10.1145/3627673.3679208)|Véronne Yepmo, Grégory Smits|Université de Rennes - IRISA, Lannion, France; IMT Atlantique - Lab STICC, Brest, France|myCADI is a machine learning framework associated with a graphical interface for discovering and understanding the internal structure of an unsupervised dataset. It is an intuitive end-user interface to the CADI approach, which uses a revised version of the Isolation Forest method to both 1) identify local anomalies, 2) reconstruct the cluster-based internal structure of the data, and 3) provide end-users with explanations of how anomalies deviate from the found clusters. myCADI takes numerical data as input and is structured around several interfaces, each of which displays a ranked list of the found anomalies, a description of the subspaces in which the different clusters lie, and feature attribution explanations to ease the interpretation of anomalies. These explanations make explicit why a selected point is considered to be a local anomaly of one (or more) cluster(s). The framework also provides dataset and trees visualizations.|myCADI 是一种与图形界面相结合的机器学习框架，旨在发现和理解无监督数据集的内部结构。它是 CADI 方法的直观终端用户界面，该方法使用改进版的孤立森林（Isolation Forest）算法来实现以下三个目标：1) 识别局部异常点，2) 重建基于聚类的数据内部结构，以及 3) 向终端用户解释异常点如何偏离已发现的聚类。myCADI 以数值数据作为输入，其结构围绕多个界面设计，每个界面显示已发现异常点的排序列表、不同聚类所在子空间的描述，以及特征归因解释，以便于异常点的解读。这些解释明确说明了为什么某个选定点被视为一个（或多个）聚类的局部异常点。该框架还提供数据集和树的可视化功能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=myCADI:+my+Contextual+Anomaly+Detection+using+Isolation)|0|
|[Mastodoner: A Command-line Tool and Python Library for Public Data Collection from Mastodon](https://doi.org/10.1145/3627673.3679217)|Haris Bin Zia, Ignacio Castro, Gareth Tyson|HKUST (GZ) & QMUL, Guangzhou, China; QMUL, London, United Kingdom|This paper introduces Mastodoner, a command-line tool and Python library aimed at simplifying access to public data on Mastodon, a prominent player in the Fediverse --- a decentralized network of interconnected social media platforms. Mastodoner addresses the challenges posed by Mastodon's decentralized nature by providing a unified interface for data collection, instance discovery, and secure data sharing. Through examples and demonstrations, this paper illustrates Mastodoner's capabilities in facilitating researchers' access to and analysis of public Mastodon data, thus advancing research in decentralized social media analytics. The tool and documentation are available at: https://github.com/harisbinzia/mastodoner.|本文介绍了Mastodoner，这是一个命令行工具和Python库，旨在简化对Mastodon上公共数据的访问。Mastodon是Fediverse（一个由相互连接的社交媒体平台组成的去中心化网络）中的一个重要参与者。Mastodoner通过提供一个统一的接口来处理数据收集、实例发现和安全数据共享，解决了Mastodon去中心化特性带来的挑战。通过示例和演示，本文展示了Mastodoner在帮助研究人员访问和分析Mastodon公开数据方面的能力，从而推动了去中心化社交媒体分析领域的研究。该工具及其文档可在以下网址获取：https://github.com/harisbinzia/mastodoner。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mastodoner:+A+Command-line+Tool+and+Python+Library+for+Public+Data+Collection+from+Mastodon)|0|
|[DetCat: Detecting Categorical Outliers in Relational Datasets](https://doi.org/10.1145/3627673.3679212)|Arthur Zylinski, Abdulhakim Ali Qahtan|Utrecht University, Utrecht, Netherlands|Poor data quality significantly affects different data analytics tasks, leading to inaccurate decisions and poor predictions of the machine learning models. Outliers represent one of the most common data glitches that impact data quality. While detecting outliers in numerical data has been extensively studied, few attempts were made to solve the problem of detecting categorical outliers. In this paper, we introduce DetCat for detecting categorical outliers in relational datasets, by utilizing the syntactic structure of the values. For a given attribute, DetCat identifies a set of patterns that represents the majority of the values as dominating patterns. Data values that cannot be generated by the dominating patterns are declared as outliers. The demo will show the effectiveness of our tool in detecting categorical outliers and discovering the syntactical data patterns.|数据质量差会显著影响各种数据分析任务，导致决策不准确以及机器学习模型的预测效果不佳。异常值是影响数据质量的最常见数据问题之一。尽管在数值数据中检测异常值已被广泛研究，但在解决检测分类异常值的问题上，尝试还相对较少。本文提出了DetCat，用于在关系数据集中检测分类异常值，通过利用值的语法结构来实现。对于给定的属性，DetCat识别出一组代表大多数值的模式作为主导模式。无法由主导模式生成的数据值被声明为异常值。演示将展示我们工具在检测分类异常值和发现语法数据模式方面的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DetCat:+Detecting+Categorical+Outliers+in+Relational+Datasets)|0|
|[3DLNews: A Three-decade Dataset of US Local News Articles](https://doi.org/10.1145/3627673.3679165)|Gangani Ariyarathne, Alexander C. Nwala||We present 3DLNews, a novel dataset with local news articles from the United States spanning the period from 1996 to 2024. It contains almost 1 million URLs (with HTML text) from over 14,000 local newspapers, TV, and radio stations across all 50 states, and provides a broad snapshot of the US local news landscape. The dataset was collected by scraping Google and Twitter search results. We employed a multi-step filtering process to remove non-news article links and enriched the dataset with metadata such as the names and geo-coordinates of the source news media organizations, article publication dates, etc. Furthermore, we demonstrated the utility of 3DLNews by outlining four applications.|我们提出了3DLNews，这是一个新颖的数据集，包含从1996年到2024年美国本地新闻文章。该数据集包含来自全美50个州的超过14,000家地方报纸、电视台和广播电台的近100万个URL（带有HTML文本），并提供了美国本地新闻格局的广泛概览。该数据集通过抓取Google和Twitter的搜索结果进行收集。我们采用了一个多步骤的过滤过程来移除非新闻文章的链接，并通过添加元数据（如新闻媒体组织的名称和地理坐标、文章发布日期等）来丰富数据集。此外，我们通过概述四个应用展示了3DLNews的实用性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=3DLNews:+A+Three-decade+Dataset+of+US+Local+News+Articles)|0|
|[BioMAISx: A Corpus for Aspect-Based Sentiment Analysis of Media Representations of Agricultural Biotechnologies in Africa](https://doi.org/10.1145/3627673.3679152)|Patricia Chiril, Trevor Spreadbury, Joeva Rock, Brian DowdUribe, David Uminsky|Stony Brook University, Stony Brook, NY, USA; University of San Francisco, San Francisco, CA, USA; University of Chicago, Chicago, IL, USA|News articles constitute a valuable resource for opinion mining, as they contain important perspectives related to the subject matter they cover. In this paper, we explore how aspect-based sentiment analysis might help in understanding the public discourse surrounding agricultural biotechnologies in Africa. We introduce BioMAISx, the first English language dataset composed of direct quotes pertaining to agricultural biotechnologies extracted from a curated list of Africa-based news sources. We have identified and labelled entities related to key aspects of agricultural biotechnologies, providing valuable insights into public discourse. This dataset can aid in identifying challenges, improving public discourse, and monitoring the perception of agricultural biotechnologies, thus contributing to informed decision-making.|新闻文章是意见挖掘的宝贵资源，因为它们包含了与所报道主题相关的重要观点。在本文中，我们探讨了基于方面的情感分析如何帮助理解围绕非洲农业生物技术的公共讨论。我们介绍了BioMAISx，这是第一个由从精选的非洲新闻来源中提取的与农业生物技术相关的直接引用组成的英语数据集。我们已经识别并标记了与农业生物技术关键方面相关的实体，为公共讨论提供了宝贵的见解。该数据集有助于识别挑战、改善公共讨论并监测农业生物技术的感知，从而为明智的决策做出贡献。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BioMAISx:+A+Corpus+for+Aspect-Based+Sentiment+Analysis+of+Media+Representations+of+Agricultural+Biotechnologies+in+Africa)|0|
|[Moving Region Representations on the Spread of a Forest Fire](https://doi.org/10.1145/3627673.3679111)|Henrique Macías da Silva, Tiago F. R. Ribeiro, Rogério Luís C. Costa, José Manuel Moreira|IEETA  LASI, University of Aveiro, Aveiro, Portugal; DETI  IEETA  LASI, University of Aveiro, Aveiro, Portugal; CIIC, ESTG, Polytechnic Institute of Leiria, Leiria, Portugal|This paper focuses on the generation of spatiotemporal data from real-world observations to represent the evolution of phenomena of interest as moving regions. The case study is the creation of a dataset to represent the spread of a controlled forest fire from aerial images captured using a drone. We present an overview of the data acquisition and preparation steps and describe the optimization strategy implemented to establish a vertex correspondence between the regions that delimit the burned region at discrete time instants. The resulting dataset is used to create a continuous representation of the evolution of the burned region over time.|本文主要研究如何从现实世界的观测中生成时空数据，以表示感兴趣现象作为移动区域的演变过程。案例研究是通过无人机拍摄的航空图像创建一个数据集，以表示受控森林火灾的蔓延情况。我们概述了数据采集和准备步骤，并描述了在离散时间点上划定燃烧区域之间建立顶点对应关系的优化策略。最终生成的数据集用于创建燃烧区域随时间演变的连续表示。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Moving+Region+Representations+on+the+Spread+of+a+Forest+Fire)|0|
|[pyPANTERA: A Python PAckage for Natural language obfuscaTion Enforcing pRivacy & Anonymization](https://doi.org/10.1145/3627673.3679173)|Francesco Luigi De Faveri, Guglielmo Faggioli, Nicola Ferro|University of Padova, Padova, Italy|Privacy is critical when dealing with user-generated text, as common in Natural Language Processing (NLP) and Information Retrieval (IR) tasks. Documents, queries, posts, and reviews might pose a risk of inadvertently disclosing sensitive information. Such exposure of private data is a significant threat to user privacy, as it may reveal information that users prefer to keep confidential. The leading framework to protect user privacy when handling textual information is represented by the ε-Differential Privacy (DP). However, the research community lacks a unified framework for comparing different DP mechanisms. This study introduces pyPANTERA, an open-source Python package developed for text obfuscation. The package is designed to incorporate State-of-the-Art DP mechanisms within a unified framework for obfuscating data. pyPANTERA is not only designed as a modular and extensible library for enriching DP techniques, thereby enabling the integration of new DP mechanisms in future research, but also to allow reproducible comparison of the current State-of-the-Art mechanisms. Through extensive evaluation, we demonstrate the effectiveness of pyPANTERA, making it an essential resource for privacy researchers and practitioners. The source code of the library and for the experiments is available at: https://github.com/Kekkodf/pypantera **REMOVE 2nd URL**://github.com/Kekkodf/pypantera.|在处理用户生成的文本时，隐私是至关重要的，这在自然语言处理（NLP）和信息检索（IR）任务中尤为常见。文档、查询、帖子和评论可能会无意中泄露敏感信息。这种私人数据的暴露对用户隐私构成了重大威胁，因为它可能揭示用户希望保密的信息。在处理文本信息时，保护用户隐私的主要框架是ε-差分隐私（DP）。然而，研究界缺乏一个统一的框架来比较不同的DP机制。本研究介绍了pyPANTERA，这是一个为文本混淆开发的开源Python包。该包旨在将最先进的DP机制整合到一个统一的框架中，以实现数据混淆。pyPANTERA不仅设计为一个模块化和可扩展的库，用于丰富DP技术，从而在未来的研究中实现新DP机制的集成，还允许对当前最先进的机制进行可重复的比较。通过广泛的评估，我们展示了pyPANTERA的有效性，使其成为隐私研究人员和实践者的重要资源。该库和实验的源代码可在以下网址获取：https://github.com/Kekkodf/pypantera **移除第二个URL**://github.com/Kekkodf/pypantera。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=pyPANTERA:+A+Python+PAckage+for+Natural+language+obfuscaTion+Enforcing+pRivacy+&+Anonymization)|0|
|[VHAKG: A Multi-modal Knowledge Graph Based on Synchronized Multi-view Videos of Daily Activities](https://doi.org/10.1145/3627673.3679175)|Shusaku Egami, Takanori Ugai, Swe Nwe Nwe Htun, Ken Fukuda||Multi-modal knowledge graphs (MMKGs), which ground various non-symbolic data (e.g., images and videos) into symbols, have attracted attention as resources enabling knowledge processing and machine learning across modalities. However, the construction of MMKGs for videos consisting of multiple events, such as daily activities, is still in the early stages. In this paper, we construct an MMKG based on synchronized multi-view simulated videos of daily activities. Besides representing the content of daily life videos as event-centric knowledge, our MMKG also includes frame-by-frame fine-grained changes, such as bounding boxes within video frames. In addition, we provide support tools for querying our MMKG. As an application example, we demonstrate that our MMKG facilitates benchmarking vision-language models by providing the necessary vision-language datasets for a tailored task.|多模态知识图谱（Multi-modal Knowledge Graphs, MMKGs）将各种非符号数据（如图像和视频）映射为符号数据，作为一种支持跨模态知识处理和机器学习的资源，已经引起了广泛关注。然而，针对由多个事件组成的视频（如日常活动）构建多模态知识图谱仍处于早期阶段。在本文中，我们基于同步多视角的日常活动模拟视频构建了一个多模态知识图谱。除了将日常生活视频内容表示为以事件为中心的知识外，我们的多模态知识图谱还包括逐帧的细粒度变化，例如视频帧中的边界框。此外，我们还提供了用于查询该多模态知识图谱的支持工具。作为一个应用示例，我们展示了该多模态知识图谱通过为特定任务提供必要的视觉-语言数据集，能够促进视觉-语言模型的基准测试。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=VHAKG:+A+Multi-modal+Knowledge+Graph+Based+on+Synchronized+Multi-view+Videos+of+Daily+Activities)|0|
|[A Generative Benchmark Creation Framework for Detecting Common Data Table Versions](https://doi.org/10.1145/3627673.3679157)|Daniel C. Fox, Aamod Khatiwada, Roee Shraga|Worcester Polytechnic Institute, Worcester, USA; Northeastern University, Boston, USA|Multiple versions of the same dataset can exist in a data repository (e.g., data warehouses, data lakes, etc.), mainly because of the interactive and collaborative nature of data science. Data creators generally update existing datasets and upload them as new datasets to data repositories without proper documentation. Identifying such versions helps in data management, data governance, and making better decisions using data. However, there is a dearth of benchmarks to develop and evaluate data versioning techniques, which requires a lot of human effort. Thus, this work introduces a novel framework to generate benchmarks for data versioning using Generative AI (specifically Large Language Models). The proposed framework offers properties that existing benchmarks do not have, including proper documentation, version lineage, and complex transformations generated by an LLM. We also share VerLLM-v1, the first version of the benchmark that features these properties, and compare it to existing benchmarks.|在数据仓库（如数据仓库、数据湖等）中，同一数据集的多个版本可能会同时存在，这主要是由于数据科学的交互性和协作性。数据创建者通常会更新现有数据集并将其作为新数据集上传到数据存储库中，但往往缺乏适当的文档记录。识别这些版本有助于数据管理、数据治理以及利用数据做出更好的决策。然而，目前缺乏用于开发和评估数据版本控制技术的基准数据集，这需要大量的人力投入。因此，本研究提出了一种利用生成式人工智能（特别是大型语言模型）生成数据版本控制基准的新框架。该框架提供了现有基准所不具备的特性，包括适当的文档记录、版本沿袭以及由大型语言模型生成的复杂转换。我们还分享了VerLLM-v1，这是具有这些特性的基准的第一个版本，并将其与现有基准进行了比较。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Generative+Benchmark+Creation+Framework+for+Detecting+Common+Data+Table+Versions)|0|
|[Dataset Generation for Korean Urban Parks Analysis with Large Language Models](https://doi.org/10.1145/3627673.3679109)|Honggu Kim, Minwoo Kang, Hyeyoung Choi, YunGyung Cheong|Sungkyunkwan University, Suwon, Republic of Korea; Sungkyungwan University, Suwon, Republic of Korea|Understanding how urban parks are utilized and perceived by the public is crucial for effective urban planning and management. This study introduces a novel dataset derived from Instagram, using 42,187 images tagged with #Seoul and #Park hashtags from 2017 to 2023. These images were filtered using InternLM-XComposer2, a Multimodal Large Language Model (MLLM), to confirm they depicted park scenes. GPT-4 then annotated the filtered images, resulting in 29,866 valid image annotations of physical elements, human activities, animals, and emotions. The dataset is publicly available at https://huggingface.co/datasets/RedBall/seoul-urban-park-analysis-by-llm.|了解城市公园如何被公众利用和感知对于有效的城市规划和管理至关重要。本研究引入了一个从Instagram提取的新颖数据集，使用了2017年至2023年间带有#Seoul和#Park标签的42,187张图片。这些图片通过InternLM-XComposer2（一种多模态大语言模型，MLLM）进行过滤，以确认它们描绘的是公园场景。随后，GPT-4对过滤后的图片进行了标注，生成了29,866条有效图像注释，包括物理元素、人类活动、动物和情感。该数据集已在https://huggingface.co/datasets/RedBall/seoul-urban-park-analysis-by-llm上公开提供。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dataset+Generation+for+Korean+Urban+Parks+Analysis+with+Large+Language+Models)|0|
|[EUvsDisinfo: A Dataset for Multilingual Detection of Pro-Kremlin Disinformation in News Articles](https://doi.org/10.1145/3627673.3679167)|João Augusto Leite, Olesya Razuvayevskaya, Kalina Bontcheva, Carolina Scarton||This work introduces EUvsDisinfo, a multilingual dataset of disinformation articles originating from pro-Kremlin outlets, along with trustworthy articles from credible / less biased sources. It is sourced directly from the debunk articles written by experts leading the EUvsDisinfo project. Our dataset is the largest to-date resource in terms of the overall number of articles and distinct languages. It also provides the largest topical and temporal coverage. Using this dataset, we investigate the dissemination of pro-Kremlin disinformation across different languages, uncovering language-specific patterns targeting certain disinformation topics. We further analyse the evolution of topic distribution over an eight-year period, noting a significant surge in disinformation content before the full-scale invasion of Ukraine in 2022. Lastly, we demonstrate the dataset's applicability in training models to effectively distinguish between disinformation and trustworthy content in multilingual settings.|本研究介绍了EUvsDisinfo，这是一个多语言的虚假信息文章数据集，其中包含来自亲克里姆林宫媒体的虚假信息文章，以及来自可信/较少偏见来源的可信文章。该数据集直接来源于由EUvsDisinfo项目专家撰写的辟谣文章。我们的数据集在文章总数和涵盖的语种数量上都是迄今为止最大的资源，并且在主题和时间覆盖范围上也是最大的。利用这一数据集，我们研究了亲克里姆林宫虚假信息在不同语言中的传播情况，揭示了针对某些虚假信息主题的特定语言模式。我们进一步分析了八年期间主题分布的演变，注意到在2022年全面入侵乌克兰之前，虚假信息内容显著激增。最后，我们展示了该数据集在训练模型以在多语言环境中有效区分虚假信息和可信内容方面的适用性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EUvsDisinfo:+A+Dataset+for+Multilingual+Detection+of+Pro-Kremlin+Disinformation+in+News+Articles)|0|
|[LeDQA: A Chinese Legal Case Document-based Question Answering Dataset](https://doi.org/10.1145/3627673.3679154)|Bulou Liu, Zhenhao Zhu, Qingyao Ai, Yiqun Liu, Yueyue Wu|Quan Cheng Laboratory, DCST & Institute for Internet Judiciary, Tsinghua University, Beijing, China; DCST & Institute for Internet Judiciary, Tsinghua University, Beijing, China; DCST & Institute for Internet Judiciary, Quan Cheng Laboratory, Tsinghua University, Beijing, China; Weiyang College, Tsinghua University, Beijing, China|Legal question answering based on case documents is a pivotal legal AI application and helps extract key elements from the legal case documents to promote downstream tasks. Intuitively, the form of this task is similar to legal machine reading comprehension. However, in existing legal machine reading comprehension datasets, the background information is much shorter than the legal case documents, and the questions are not designed from the perspective of legal knowledge. In this paper, we present LeDQA, the first Chinese legal case document-based question answering dataset to our best knowledge. Specifically, we build a comprehensive question schema (including 48 element-based questions) for the Chinese civil law by legal professionals. And considering the cost of human annotations are too expensive, we use one of the SOTA LLMs (i.e., GPT-4) to annotate the relevant sentences to these questions in each case document. The constructed dataset originates from Chinese civil cases and contains 100 case documents, 4,800 case-question pairs and 132,048 sentence-level relevance annotations. We implement several text matching algorithms for relevant sentence selection and various Large Language Models(LLMs) for legal question answering on LeDQA. The experimental results indicate that incorporating relevant sentences can benefit the performance of question answering models, but further efforts are still required to address the remaining challenges such as retrieving irrelevant sentences and incorrect reasoning between retrieved sentences.|基于案例文档的法律问答是一项关键的法律人工智能应用，它有助于从法律案例文档中提取关键要素，从而促进下游任务的开展。直观上看，该任务的形式类似于法律机器阅读理解。然而，在现有的法律机器阅读理解数据集中，背景信息远远短于法律案例文档，且问题并未从法律知识的角度进行设计。在本文中，我们提出了LeDQA，这是我们所知的第一个基于中文法律案例文档的问答数据集。具体而言，我们由法律专业人士为中国民法构建了一个全面的问题模式（包括48个基于要素的问题）。考虑到人工标注的成本过高，我们使用了一种最先进的大型语言模型（即GPT-4）来标注每个案例文档中与这些问题相关的句子。构建的数据集来源于中国民事案例，包含100个案例文档、4,800个案例-问题对以及132,048个句子级别的相关性标注。我们在LeDQA上实现了多种文本匹配算法用于相关句子选择，并使用了多种大型语言模型（LLMs）进行法律问答。实验结果表明，结合相关句子可以提高问答模型的性能，但仍需进一步努力解决诸如检索无关句子和检索句子之间错误推理等挑战。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LeDQA:+A+Chinese+Legal+Case+Document-based+Question+Answering+Dataset)|0|
|[Refining Wikidata Taxonomy using Large Language Models](https://doi.org/10.1145/3627673.3679156)|Yiwen Peng, Thomas Bonald, Mehwish Alam||Due to its collaborative nature, Wikidata is known to have a complex taxonomy, with recurrent issues like the ambiguity between instances and classes, the inaccuracy of some taxonomic paths, the presence of cycles, and the high level of redundancy across classes. Manual efforts to clean up this taxonomy are time-consuming and prone to errors or subjective decisions. We present WiKC, a new version of Wikidata taxonomy cleaned automatically using a combination of Large Language Models (LLMs) and graph mining techniques. Operations on the taxonomy, such as cutting links or merging classes, are performed with the help of zero-shot prompting on an open-source LLM. The quality of the refined taxonomy is evaluated from both intrinsic and extrinsic perspectives, on a task of entity typing for the latter, showing the practical interest of WiKC.|由于其协作性质，维基数据（Wikidata）的类属体系（taxonomy）通常较为复杂，存在诸如实例与类之间的歧义、某些类属路径的不准确性、循环结构的存在以及类之间高度冗余等常见问题。手动清理这些类属体系既耗时又容易出错或产生主观决策。我们提出了WiKC，这是一个通过结合大型语言模型（LLMs）和图挖掘技术自动清理的维基数据类属体系的新版本。对类属体系的操作，例如切断链接或合并类，是在一个开源LLM的零样本提示（zero-shot prompting）的帮助下完成的。我们从内在和外在两个角度评估了改进后类属体系的质量，后者通过实体类型标注任务来展示WiKC的实际应用价值。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Refining+Wikidata+Taxonomy+using+Large+Language+Models)|0|
|[InfinityMath: A Scalable Instruction Tuning Dataset in Programmatic Mathematical Reasoning](https://doi.org/10.1145/3627673.3679122)|BoWen Zhang, Yan Yan, Lin Li, Guang Liu|Beijing Academy of Artificial Intelligence, Beijing, China; China University of Mining &amp Technology Beijing, Beijing, China|Recent advancements in Chain-of-Thoughts (CoT) and Program-of-Thoughts (PoT) methods have greatly enhanced language models' mathematical reasoning capabilities, facilitating their integration into instruction tuning datasets with LLMs. However, existing methods for large-scale dataset creation require substantial seed data and high computational costs for data synthesis, posing significant challenges for scalability. We introduce InfinityMATH, a scalable instruction tuning dataset for programmatic mathematical reasoning. The construction pipeline emphasizes decoupling numbers from mathematical problems to synthesize number-independent programs, enabling efficient and flexible scaling while minimizing dependency on specific numerical values. Fine-tuning experiments with open-source language and code models, such as Llama2 and CodeLlama, demonstrate the practical benefits of InfinityMATH. These fine-tuned models, showed significant relative improvements on both in-domain and out-of-domain benchmarks, ranging from 184.7 Additionally, these models exhibited high robustness on the GSM8K+ and MATH+ benchmarks, which are enhanced version of test sets with simply the number variations. InfinityMATH ensures that models are more versatile and effective across a broader range of mathematical problems. The data is available at https://huggingface.co/datasets/flagopen/InfinityMATH.|近期在思维链（Chain-of-Thoughts, CoT）和程序思维链（Program-of-Thoughts, PoT）方法上的进展显著提升了语言模型在数学推理方面的能力，促进了它们与大型语言模型（LLMs）在指令微调数据集中的集成。然而，现有的大规模数据集创建方法需要大量的种子数据和高昂的数据合成计算成本，这对可扩展性提出了重大挑战。我们引入了InfinityMATH，一个用于程序化数学推理的可扩展指令微调数据集。该数据集的构建流程强调将数字从数学问题中解耦，以合成与数字无关的程序，从而实现高效且灵活的扩展，同时最小化对特定数值的依赖。通过对开源语言和代码模型（如Llama2和CodeLlama）进行微调实验，我们验证了InfinityMATH的实际优势。这些微调后的模型在领域内和领域外的基准测试中均展现出显著的相对提升，提升幅度从184.7%到更高不等。此外，这些模型在GSM8K+和MATH+基准测试中表现出高度的鲁棒性，这些基准测试是通过简单改变数字而增强的测试集版本。InfinityMATH确保了模型在更广泛的数学问题中具有更高的通用性和有效性。该数据集可在https://huggingface.co/datasets/flagopen/InfinityMATH获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=InfinityMath:+A+Scalable+Instruction+Tuning+Dataset+in+Programmatic+Mathematical+Reasoning)|0|
|[Advancing Multivariate Time Series Anomaly Detection: A Comprehensive Benchmark with Real-World Data from Alibaba Cloud](https://doi.org/10.1145/3627673.3679128)|Chaoli Zhang, Yingying Zhang, Lanshu Peng, Qingsong Wen, Yiyuan Yang, ChongJiong Fan, Minqi Jiang, Lunting Fan, Liang Sun|Shanghai University of Finance and Economics, Shanghai, China; University of Oxford, Oxford, United Kingdom; Alibaba Group, Hangzhou, China; DAMO Academy, Alibaba Group, Seattle, USA; Squirrel AI Learning, Seattle, USA; Zhejiang Normal University, Jinhua, China|Time series anomaly detection is of significant importance in many real-world applications, including finance, healthcare, network security, industrial equipment, complex computing systems, and space probes. Most of these applications involve multi-sensor systems, thus how to perform multivariate time series anomaly detection (MTSAD) has garnered widespread attention. This broad attention has fueled extensive research endeavors aimed to innovate and develop methods and techniques to improve the efficiency and precision of anomaly detection on multivariate time series data, including both classic machine learning methods and deep learning methods. However, evaluating the performance of these methods remains challenging due to the limited availability of public benchmark datasets for MTSAD, which are often criticized for various reasons. Additionally, there is no consensus on the best metrics for time series anomaly detection, further complicating MTSAD research. In this paper, we advance the benchmarking of time series anomaly detection by addressing datasets, evaluation metrics, and algorithm comparison. To the best of our knowledge, we have generated the largest real-world datasets for MTSAD using the Hologres AIOps system in the Alibaba Cloud platform. We review and compare popular evaluation metrics including recently proposed ones. To evaluate classic machine learning and recent deep learning methods fairly, we have conducted extensive comparisons of these methods on various datasets. We believe that our benchmarks and datasets will promote reproducible results and accelerate the progress of MTSAD research.|时间序列异常检测在许多实际应用中具有重要意义，包括金融、医疗保健、网络安全、工业设备、复杂计算系统和空间探测器等领域。这些应用大多涉及多传感器系统，因此如何进行多元时间序列异常检测（MTSAD）引起了广泛关注。这种广泛的关注推动了大量研究工作的开展，旨在创新和开发方法和技术，以提高多元时间序列数据异常检测的效率和精度，包括经典的机器学习方法和深度学习方法。然而，由于可用于MTSAD的公共基准数据集有限，这些方法的性能评估仍然具有挑战性，这些数据集常常因各种原因受到批评。此外，对于时间序列异常检测的最佳评价指标尚未达成共识，这进一步增加了MTSAD研究的复杂性。在本文中，我们通过解决数据集、评价指标和算法比较问题，推进了时间序列异常检测的基准测试。据我们所知，我们利用阿里云平台的Hologres AIOps系统生成了用于MTSAD的最大真实世界数据集。我们回顾并比较了包括最近提出的流行评价指标。为了公平地评估经典机器学习和最近的深度学习方法，我们在多个数据集上对这些方法进行了广泛的比较。我们相信，我们的基准和数据集将促进可重复的结果，并加速MTSAD研究的进展。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Advancing+Multivariate+Time+Series+Anomaly+Detection:+A+Comprehensive+Benchmark+with+Real-World+Data+from+Alibaba+Cloud)|0|
|[ELF-Gym: Evaluating Large Language Models Generated Features for Tabular Prediction](https://doi.org/10.1145/3627673.3679153)|Yanlin Zhang, Ning Li, Quan Gan, Weinan Zhang, David Wipf, Minjie Wang||Crafting effective features is a crucial yet labor-intensive and domain-specific task within machine learning pipelines. Fortunately, recent advancements in Large Language Models (LLMs) have shown promise in automating various data science tasks, including feature engineering. But despite this potential, evaluations thus far are primarily based on the end performance of a complete ML pipeline, providing limited insight into precisely how LLMs behave relative to human experts in feature engineering. To address this gap, we propose ELF-Gym, a framework for Evaluating LLM-generated Features. We curated a new dataset from historical Kaggle competitions, including 251 "golden" features used by top-performing teams. ELF-Gym then quantitatively evaluates LLM-generated features by measuring their impact on downstream model performance as well as their alignment with expert-crafted features through semantic and functional similarity assessments. This approach provides a more comprehensive evaluation of disparities between LLMs and human experts, while offering valuable insights into specific areas where LLMs may have room for improvement. For example, using ELF-Gym we empirically demonstrate that, in the best-case scenario, LLMs can semantically capture approximately 56 golden features, but at the more demanding implementation level this overlap drops to 13 on datasets that require complex features, indicating broad potential pathways for improvement.|在机器学习流程中，构建有效的特征是一项关键但劳动密集且领域特定的任务。幸运的是，最近在大型语言模型（LLMs）方面的进展显示出在自动化各种数据科学任务（包括特征工程）方面的潜力。然而，尽管存在这种潜力，迄今为止的评估主要基于完整机器学习流程的最终性能，这为LLMs在特征工程中相对于人类专家的行为提供了有限的洞察。为了解决这一差距，我们提出了ELF-Gym，一个用于评估LLM生成特征的框架。我们从历史Kaggle竞赛中整理了一个新的数据集，包括251个由表现最佳的团队使用的“黄金”特征。ELF-Gym通过衡量LLM生成特征对下游模型性能的影响以及通过语义和功能相似性评估与专家构建特征的一致性，来定量评估这些特征。这种方法提供了对LLMs和人类专家之间差异的更全面评估，同时为LLMs可能改进的具体领域提供了有价值的见解。例如，使用ELF-Gym我们经验性地证明，在最佳情况下，LLMs可以在语义上捕捉大约56个黄金特征，但在需要复杂特征的数据集上，这种一致性在更严格的实现水平上下降到13个，表明有广泛的改进潜力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ELF-Gym:+Evaluating+Large+Language+Models+Generated+Features+for+Tabular+Prediction)|0|
|[M3: A Multi-Image Multi-Modal Entity Alignment Dataset](https://doi.org/10.1145/3627673.3679126)|Shiqi Zhang, Weixin Zeng, Zhen Tan, Xiang Zhao, Weidong Xiao||Multi-modal Entity Alignment (MMEA) aims to identify equivalent entities across different multi-modal knowledge graphs (MMKGs), facilitating their integration and enhancing coverage. However, current MMEA datasets have limitations, including low entity coverage, a single image per entity, high inter-image correlation, and images sourced from the same search engine, which do not reflect real-world challenges. The fair comparison and development of alignment solutions may be hindered by these oversimplified scenarios. To address this problem, in this work, we first construct M3, an MMEA benchmark equipped with multiple images from different search engines in real-world scenarios. Additionally, we design a simple and universal multi-image processing module (AMIA), which assigns varying attention weights to images associated with entities to effectively model visual information. Experimental results validate the difficulty of M3, as well as the effectiveness of AMIA. Despite the superior performance of AMIA, there is still room for developing more advanced solutions to address these difficulties. Our dataset is publicly released.|多模态实体对齐（Multi-modal Entity Alignment, MMEA）旨在识别不同多模态知识图谱（Multi-modal Knowledge Graphs, MMKGs）中等价的实体，促进它们的整合并提升覆盖范围。然而，当前的MMEA数据集存在一些局限性，包括实体覆盖率低、每个实体仅有一张图像、图像间相关性高，以及图像均来自同一搜索引擎，这些问题未能反映现实世界中的复杂挑战。这些过于简化的场景可能会阻碍对齐解决方案的公平比较与发展。为了解决这一问题，在本研究中，我们首先构建了M3，这是一个在现实场景中配备来自不同搜索引擎的多张图像的MMEA基准数据集。此外，我们设计了一个简单且通用的多图像处理模块（AMIA），该模块为与实体相关的图像分配不同的注意力权重，以有效地建模视觉信息。实验结果验证了M3的难度以及AMIA的有效性。尽管AMIA表现出色，但在应对这些挑战时，仍有空间开发更先进的解决方案。我们的数据集已公开发布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=M3:+A+Multi-Image+Multi-Modal+Entity+Alignment+Dataset)|0|
|[CheckGuard: Advancing Stolen Check Detection with a Cross-Modal Image-Text Benchmark Dataset](https://doi.org/10.1145/3627673.3679155)|Fei Zhao, Jiawen Chen, Bin Huang, Chengcui Zhang, Gary Warner|Ji Zhi Xing Huo Technology Beijing, Beijing, China; The University of Alabama at Birmingham, Birmingham, USA; Beijing-Dublin International College, Beijing University of Technology, Beijing, China|The prevalence of check fraud, particularly with stolen checks sold on platforms such as Telegram, creates significant challenges for both individuals and financial institutions. This underscores the urgent need for innovative solutions to detecting and preventing such fraud on social media platforms. While deep learning techniques show great promise in detecting objects and extracting information from images, their effectiveness in addressing check fraud is hindered by the lack of comprehensive, open-source, large training datasets specifically for check information extraction. To bridge this gap, this paper introduces "CheckGuard," a large labeled image-to-text cross-modal dataset designed for check information extraction. CheckGuard comprises over 7,000 real-world stolen check image segments from more than 15 financial institutions, featuring a variety of check styles and layouts. These segments have been manually labeled, resulting in over 50,000 samples across seven key elements: Drawer, Payee, Amount, Date, Drawee, Routing Number, and Check Number. This dataset supports various tasks such as visual question answering (VQA) on checks and check image captioning. Our paper details the rigorous data collecting, cleaning, and annotation processes that make CheckGuard a valuable resource for researchers in check fraud detection, machine learning, and multimodal large language models (MLLMs). We not only benchmark state-of-the-art (SOTA) methods on this dataset to assess their performance but also explore potential enhancements. Our application of parameter-efficient fine-tuning (PEFT) techniques on the SOTA MLLMs demonstrates significant performance improvements, providing valuable insights and practical approaches for enhancing model efficacy on this task. As an evolving project, CheckGuard will continue to be updated with new data, enhancing its utility and driving further advancements in the field. Our PEFT-based MLLM code is available at: https://github.com/feizhao19/CheckGuard. For data access, researchers are required to contact the authors directly.|支票欺诈，尤其是通过Telegram等平台出售的盗窃支票，给个人和金融机构带来了巨大的挑战。这凸显了在社交媒体平台上检测和预防此类欺诈的紧迫需求。尽管深度学习技术在从图像中检测对象和提取信息方面显示出巨大的潜力，但由于缺乏专门用于支票信息提取的全面、开源、大规模训练数据集，其在应对支票欺诈方面的效果受到限制。为了填补这一空白，本文引入了“CheckGuard”，这是一个为支票信息提取设计的大规模标注图像到文本跨模态数据集。CheckGuard包含来自超过15家金融机构的7000多个现实世界中的盗窃支票图像片段，涵盖了各种支票样式和布局。这些片段经过人工标注，生成了超过50,000个样本，涵盖了七个关键元素：出票人、收款人、金额、日期、付款人、路由号码和支票号码。该数据集支持各种任务，如支票上的视觉问答（VQA）和支票图像描述生成。本文详细介绍了使CheckGuard成为支票欺诈检测、机器学习和多模态大语言模型（MLLMs）研究人员宝贵资源的严格数据收集、清理和标注过程。我们不仅在该数据集上对最先进的（SOTA）方法进行了基准测试以评估其性能，还探索了潜在的改进方法。我们在SOTA MLLMs上应用了参数高效微调（PEFT）技术，展示了显著的性能提升，为该任务中提高模型效能提供了宝贵的见解和实用方法。作为一个不断发展的项目，CheckGuard将继续更新新数据，增强其实用性并推动该领域的进一步发展。我们的基于PEFT的MLLM代码可在以下网址获取：https://github.com/feizhao19/CheckGuard。研究人员如需访问数据，需直接联系作者。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CheckGuard:+Advancing+Stolen+Check+Detection+with+a+Cross-Modal+Image-Text+Benchmark+Dataset)|0|
|[GeoAI for Natural Disaster Assessment](https://doi.org/10.1145/3627673.3680257)|Saugat Adhikari|Indiana University Bloomington, Bloomington, IN, USA|Climate change has led to a sharp increase in the number and severity of extreme events, such as floods, tornados and wildfires. These events have resulted in adverse effects on human lives and the infrastructure. Swift disaster assessment is crucial for the effective planning of disaster response and relief efforts. AI and big data have provided unprecedented opportunities to enable swift disaster assessment, but two significant hurdles exist: (1) the scarcity of annotated geospatial data to train AI models, and (2) the lack of AI solutions that encode physics knowledge in a geospatial context. My research aims to address both challenges by developing an active-learning-based annotation platform that improves the annotation productivity of geospatial data for geospatial machine learning, and by developing physics-guided machine learning models for accurate natural disaster assessment.|气候变化导致极端事件（如洪水、龙卷风和野火）的数量和严重性急剧增加。这些事件对人类生命和基础设施造成了不利影响。快速的灾害评估对于有效规划灾害响应和救援工作至关重要。人工智能（AI）和大数据为快速灾害评估提供了前所未有的机遇，但存在两个重大障碍：（1）用于训练AI模型的标注地理空间数据的稀缺性；（2）缺乏在地理空间背景下编码物理知识的AI解决方案。我的研究旨在通过开发一种基于主动学习的标注平台来应对这两个挑战，该平台可以提高地理空间数据的标注效率，从而促进地理空间机器学习的发展，并通过开发物理引导的机器学习模型来实现准确的自然灾害评估。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GeoAI+for+Natural+Disaster+Assessment)|0|
|[Assessing Human Viewpoints in Theory of Mind for Large Language Models in Open-Ended Questioning](https://doi.org/10.1145/3627673.3680273)|Maryam Amirizaniani|University of Washington, Seattle, WA, USA|Theory of Mind (ToM) reasoning involves understanding that others have unique mental states-like beliefs, thoughts, intentions, viewpoints, and emotions-different from one's own, and incorporating this into one's reasoning. While some research suggests that LLMs possess reasoning abilities, other studies challenge this assertion, often focusing on structured responses and overlooking the complexities of open-ended interactions. As LLMs are increasingly employed in different sectors, their ability to accurately interpret human mental states in reasoning becomes critical. For example, in psychological services, if LLMs generate reasoning responses without understanding human mental states, their answers may lack logical soundness and potentially exacerbate client distress. Therefore, understanding LLMs' ToM capabilities is crucial to ensure they deliver effective and appropriate responses in real-world scenarios. In this research, I investigate the effectiveness of incorporating questioners' viewpoints in the questions-whether posed in a rational or intuitive manner-on the generation of reasoning answers by LLMs and how these generated answers align with human-written responses. The results demonstrate that incorporating these viewpoints into the prompt instructions enhances the reasoning performance of LLMs, although the responses still fall short of being truly human-like. This research contributes to the information retrieval and generative AI community by raising awareness about the limitations of LLMs in reasoning and their alignment with human responses in this domain.|心智理论（Theory of Mind, ToM）推理涉及理解他人具有独特的心理状态——如信念、思想、意图、观点和情感——这些状态与自己的不同，并将这种理解纳入推理过程中。尽管一些研究表明大型语言模型（LLMs）具备推理能力，但其他研究对此提出了质疑，通常关注结构化响应，而忽视了开放式交互的复杂性。随着LLMs在不同领域的应用日益广泛，它们在推理中准确解读人类心理状态的能力变得至关重要。例如，在心理服务中，如果LLMs在不理解人类心理状态的情况下生成推理响应，其答案可能缺乏逻辑严谨性，甚至可能加剧客户的困扰。因此，理解LLMs的心智理论能力对于确保它们在现实场景中提供有效且适当的响应至关重要。

在本研究中，我探讨了在问题中融入提问者观点——无论是通过理性还是直觉的方式——对LLMs生成推理答案的有效性，以及这些生成的答案与人类撰写的回答之间的契合度。研究结果表明，将提问者的观点融入提示指令中可以提升LLMs的推理表现，尽管这些响应仍未能达到真正的人类水平。本研究通过揭示LLMs在推理中的局限性及其与人类响应的契合度问题，为信息检索和生成式人工智能领域提供了重要的见解。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Assessing+Human+Viewpoints+in+Theory+of+Mind+for+Large+Language+Models+in+Open-Ended+Questioning)|0|
|[Leveraging Knowledge Graphs and LLMs to Support and Monitor Legislative Systems](https://doi.org/10.1145/3627673.3680268)|Andrea Colombo||Knowledge Graphs (KGs) have been used to organize large datasets into structured, interconnected information, enhancing data analytics across various fields. In the legislative context, one potential natural application of KGs is modeling the intricate set of interconnections that link laws and their articles with each other and the broader legislative context. At the same time, the rise of large language models (LLMs) such as GPT has opened new opportunities in legal applications, such as text generation and document drafting. Despite their potential, the use of LLMs in legislative contexts is critical since it requires the absence of hallucinations and reliance on up-to-date information, as new laws are published on a daily basis. This work investigates how Legislative Knowledge Graphs and LLMs can synergize and support legislative processes. We address three key questions: the benefits of using KGs for legislative systems, how LLM can support legislative activities by ensuring an accurate output, and how we can allow non-technical users to use such technologies in their activities. To this aim, we develop Legis AI Platform, an interactive platform focused on Italian legislation that enhances the possibility of conducting legislative analysis and that aims to support lawmaking activities.|知识图谱（KGs）已被用于将大规模数据集组织成结构化、相互关联的信息，从而增强各个领域的数据分析能力。在立法领域，知识图谱的一个潜在自然应用是建模法律及其条款之间以及与更广泛立法背景之间的复杂关联网络。与此同时，大型语言模型（LLMs，如GPT）的兴起为法律应用开辟了新的机会，例如文本生成和文件起草。尽管LLMs具有潜力，但在立法背景中使用它们至关重要，因为它要求避免幻觉并依赖最新信息，因为新法律每天都在发布。本研究探讨了立法知识图谱与LLMs如何协同工作并支持立法过程。我们解决了三个关键问题：使用知识图谱对立法系统的益处、LLM如何通过确保准确输出来支持立法活动，以及如何让非技术用户在其活动中使用这些技术。为此，我们开发了Legis AI平台，这是一个专注于意大利立法的交互式平台，旨在增强进行立法分析的可能性，并支持立法活动。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Knowledge+Graphs+and+LLMs+to+Support+and+Monitor+Legislative+Systems)|0|
|[Realistic Synthetic Signed Network Generation and Analysis](https://doi.org/10.1145/3627673.3680274)|Aikta Arya|Indian Institute of Technology Roorkee, Roorkee, India|Designing and analyzing network science algorithms, such as node classification, link prediction, and pattern identification (communities, triangles, dense sub-graphs, cliques), require diverse real-world datasets for performance evaluation. However, these datasets are often limited and small due to privacy concerns and platform access policies. This scarcity is even more pronounced for signed networks, as negative relationship data is rarely shared publicly. This PhD thesis aims to address this problem by generating realistic synthetic signed networks using the SNSRM and SISSRM models. Preserving the mesoscopic spectral and structural characteristics of the input signed network is crucial in this process. Additionally, this thesis tackles the challenge of efficiently analyzing elementary network property of triad enumeration by developing an triangle counting algorithm capable of enumerating balanced and unbalanced triads.|设计和分析网络科学算法，如节点分类、链接预测和模式识别（社区、三角形、密集子图、团），需要多样化的真实世界数据集来进行性能评估。然而，由于隐私问题和平台访问政策的限制，这些数据集通常有限且规模较小。对于带符号网络（signed networks）来说，这种稀缺性更为明显，因为负面关系数据很少公开共享。本博士论文旨在通过使用SNSRM和SISSRM模型生成逼真的合成带符号网络来解决这一问题。在此过程中，保留输入带符号网络的介观光谱和结构特征至关重要。此外，本论文还通过开发一种能够枚举平衡和不平衡三元组的三角形计数算法，解决了高效分析三元组枚举这一基本网络属性的挑战。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Realistic+Synthetic+Signed+Network+Generation+and+Analysis)|0|
|[Demystifying Financial Texts Using Natural Language Processing](https://doi.org/10.1145/3627673.3680258)|Sohom Ghosh|Department of Computer Science and Engineering, Jadavpur University, Kolkata, West Bengal, India|Human beings aspire for a better life. Financial well-being enables this. However, lack of financial literacy, ever-growing wealth inequality, and persuading illicit information floating in social media inhibit one's progress towards a good fortune. In this paper, we discuss four pillars where Natural Language Processing can help improve financial literacy, reduce wealth disparity, ensure a sustainable future, and economic prosperity. These pillars are: Inclusive investing, Improved investing, Impactful (green) investing, and Informed investing. Additionally, we focus to specifically cater to the Indian market (Indic investing) and present several resources to enhance comprehensibility of financial texts. Inclusive investing deals with enhancing the readability and reachability of financial texts. Improved investing addresses the need to simplify investors' journey by providing them with hypernyms and relations between entities. Impactful investing is associated with focusing on sustainable pathways. Improved investing is about eradicating finance related misinformation from social media, like evaluating trustworthiness of posts by executives, detecting in-claim and exaggerated numerals, etc. In most cases, we are able to demonstrate the efficacies of our approaches by benchmarking them with existing state-of-the-art methods.|人类渴望过上更好的生活，而财务福祉是实现这一目标的关键。然而，缺乏金融知识、日益加剧的财富不平等以及社交媒体中充斥的误导性信息，阻碍了人们追求财富的道路。本文讨论了自然语言处理（NLP）在四个支柱领域如何帮助提升金融素养、减少财富差距、确保可持续发展以及促进经济繁荣。这些支柱包括：包容性投资（Inclusive Investing）、改进型投资（Improved Investing）、影响力（绿色）投资（Impactful (Green) Investing）和知情投资（Informed Investing）。此外，我们特别关注印度市场（Indic Investing），并提供了多种资源以增强金融文本的可理解性。

包容性投资致力于提高金融文本的可读性和可达性，使其更易于被大众理解。改进型投资旨在通过提供实体的上位词及其关系来简化投资者的决策过程。影响力投资则聚焦于可持续发展的路径，推动绿色和负责任的投资实践。知情投资的目标是消除社交媒体中与金融相关的虚假信息，例如评估高管发布内容的可信度、检测虚假声明和夸大的数据等。在大多数情况下，我们通过与现有最先进方法的基准测试，展示了所提出方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Demystifying+Financial+Texts+Using+Natural+Language+Processing)|0|
|[Reliable Knowledge Graph Reasoning with Uncertainty Quantification](https://doi.org/10.1145/3627673.3680266)|Bo Ni|Vanderbilt University, Nashville, TN, USA|Recently, Knowledge Graphs (KGs) have been successfully coupled with Large Language Models (LLMs) to mitigate their hallucinations and enhance their reasoning capability, e.g., KG-based retrieval-augmented framework for question-answering. However, current KG-LLM frameworks lack rigorous uncertainty estimation, limiting their reliable deployment in high-stake applications where the cost of errors is significant. To address this crucial gap, we propose a new trustworthy KG-LLM framework, UaG(Uncertainty Aware Graph Reasoning), which incorporates uncertainty quantification into the KG-LLM framework. We design an uncertainty-aware multi-step reasoning framework that leverages conformal prediction to provide a theoretical guarantee on the prediction set. To manage the error rate of the multi-step process, we additionally introduce an error rate control module to adjust the error rate within the individual components. Our preliminary results demonstrate that UaG can achieve the desired theoretical coverage while maintaining a reasonable prediction set size.|最近，知识图谱（KGs）已成功与大型语言模型（LLMs）结合，以减少其幻觉并增强其推理能力，例如基于知识图谱的检索增强问答框架。然而，当前的KG-LLM框架缺乏严格的不确定性估计，限制了其在高风险应用中的可靠部署，这些应用中的错误成本非常高。为了解决这一关键问题，我们提出了一种新的可信KG-LLM框架，UaG（不确定性感知图推理），该框架将不确定性量化纳入KG-LLM框架中。我们设计了一个不确定性感知的多步推理框架，利用共形预测为预测集提供理论保证。为了管理多步过程的错误率，我们还引入了一个错误率控制模块，以调整各个组件内的错误率。我们的初步结果表明，UaG能够在保持合理预测集大小的同时，实现所需的理论覆盖。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reliable+Knowledge+Graph+Reasoning+with+Uncertainty+Quantification)|0|
|[Graph-theoretical Approach to Enhance Accuracy of Financial Fraud Detection Using Synthetic Tabular Data Generation](https://doi.org/10.1145/3627673.3680267)|DaeYoung Park||Tabular data synthesis has become crucial for financial applications including fraud detection, especially where there are data privacy regulations such as General Data Protection Regulation (GDPR) restrict access to original data. Despite its importance, current generative models inadequately address key challenges in financial fraud detection (FFD) data, namely extreme class imbalance, high data sparsity, and non-normal attribute distributions. My research introduces novel graph-theoretical generative models, SeparateGGM and SignedGGM, designed to tackle these challenges. By integrating graph neural network-based feature engineering, graph topology and connectivity analysis, and novel graph centrality indicators, my models achieve optimal graph settings for enhanced fraud detection accuracy. This approach is pioneering in its application of diverse graph-theoretical methods to improve FFD performance. Preliminary results demonstrate my models' superiority over competing methods on multiple FFD benchmark datasets. The goal of this research is to significantly advance real-world financial fraud detection techniques and to show that several graph-theoretical methodologies can significantly contribute to the generation of high-quality tabular synthetic data for enhancing fraud detection accuracy to the data science community.|表格数据合成在金融应用中变得至关重要，尤其是在存在数据隐私法规（如《通用数据保护条例》（GDPR））限制对原始数据访问的情况下，包括欺诈检测。尽管其重要性不言而喻，当前的生成模型在应对金融欺诈检测（FFD）数据中的关键挑战时表现不足，这些挑战包括极端的类别不平衡、高数据稀疏性以及非正态属性分布。我的研究引入了新颖的图论生成模型，SeparateGGM和SignedGGM，旨在解决这些挑战。通过集成基于图神经网络的特征工程、图拓扑和连通性分析以及新颖的图中心性指标，我的模型实现了优化的图设置，从而提高了欺诈检测的准确性。这一方法在应用多样化的图论方法以提升FFD性能方面具有开创性。初步结果表明，我的模型在多个FFD基准数据集上优于竞争方法。本研究的目的是显著推进现实世界中的金融欺诈检测技术，并向数据科学界展示，多种图论方法可以显著贡献于生成高质量的表格合成数据，从而提高欺诈检测的准确性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph-theoretical+Approach+to+Enhance+Accuracy+of+Financial+Fraud+Detection+Using+Synthetic+Tabular+Data+Generation)|0|
|[Towards Effective Fusion and Forecasting of Multimodal Spatio-temporal Data for Smart Mobility](https://doi.org/10.1145/3627673.3680261)|Chenxing Wang||With the rapid development of location based services, multimodal spatio-temporal (ST) data including trajectories, transportation modes, traffic flow and social check-ins are being collected for deep learning based methods. These deep learning based methods learn ST correlations to support the downstream tasks in the fields such as smart mobility, smart city and other intelligent transportation systems. Despite their effectiveness, ST data fusion and forecasting methods face practical challenges in real-world scenarios. First, forecasting performance for ST data-insufficient area is inferior, making it necessary to transfer meta knowledge from heterogeneous area to enhance the sparse representations. Second, it is nontrivial to accurately forecast in multi-transportation-mode scenarios due to the fine-grained ST features of similar transportation modes, making it necessary to distinguish and measure the ST correlations to alleviate the influence caused by entangled ST features. At last, partial data modalities (e.g., transportation mode) are lost due to privacy or technical issues in certain scenarios, making it necessary to effectively fuse the multimodal sparse ST features and enrich the ST representations. To tackle these challenges, our research work aim to develop effective fusion and forecasting methods for multimodal ST data in smart mobility scenario. In this paper, we will introduce our recent works that investigates the challenges in terms of various real-world applications and establish the open challenges in this field for future work.|随着基于位置服务的快速发展，包括轨迹、交通方式、交通流量和社交签到在内的多模态时空（ST）数据正在被收集用于基于深度学习的方法。这些基于深度学习的方法学习时空相关性，以支持智能出行、智慧城市和其他智能交通系统中的下游任务。尽管这些方法有效，但在实际场景中，时空数据融合和预测方法仍面临实际挑战。首先，对于时空数据不足的区域，预测性能较差，因此需要从异构区域转移元知识以增强稀疏表示。其次，在多交通方式场景中，由于相似交通方式的细粒度时空特征，准确预测变得复杂，因此需要区分和测量时空相关性，以缓解由纠缠的时空特征带来的影响。最后，在某些场景中，部分数据模态（如交通方式）由于隐私或技术问题而丢失，因此需要有效融合多模态稀疏时空特征并丰富时空表示。为了解决这些挑战，我们的研究工作旨在开发适用于智能出行场景中多模态时空数据的有效融合和预测方法。在本文中，我们将介绍最近的研究工作，探讨这些挑战在不同实际应用中的表现，并为未来工作确立该领域的开放挑战。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Effective+Fusion+and+Forecasting+of+Multimodal+Spatio-temporal+Data+for+Smart+Mobility)|0|
|[Causal Discovery from Heterogenous Multivariate Time Series](https://doi.org/10.1145/3627673.3680269)|Lei Zan|Univ. Grenoble Alpes, CNRS, Grenoble INP, LIG, EasyVista, Grenoble, France|This paper explores three key aspects of causal discovery from heterogeneous time series. First, it introduces a method that uses (conditional) mutual information to determine (conditional) independence among diverse qualitative and quantitative variables, alongside a novel local permutation test. Next, the paper presents a new algorithm for identifying event-based causal relations in threshold-based IT systems for root cause analysis. This method is effective when root causes are not causally related, and an extension involving agent intervention is proposed to address this limitation. Both the algorithm and its extension utilize causal discovery from offline data and subgraph traversal for new anomalies in online data. Finally, the paper addresses time series with multiple piecewise consistent regimes, each having distinct causal mechanisms. The proposed method segments the time series into appropriate regimes and identifies the correct window causal graph, capturing both instantaneous and lagged connections within each regime. Experiments with synthetic data confirm the effectiveness of the proposed methods.|本文探讨了从异质时间序列中进行因果发现的三个关键方面。首先，本文介绍了一种利用（条件）互信息来确定不同定性和定量变量之间（条件）独立性的方法，并结合了一种新颖的局部置换检验。其次，本文提出了一种新的算法，用于在基于阈值的IT系统中识别基于事件的因果关系，以进行根因分析。该方法在根因之间不存在因果关系时尤为有效，并且提出了一种涉及代理干预的扩展方法以解决这一局限性。该算法及其扩展均利用离线数据中的因果发现和子图遍历来处理在线数据中的新异常。最后，本文讨论了具有多个分段一致机制的时间序列，每个机制具有不同的因果机制。所提出的方法将时间序列分割为适当的机制，并识别出正确的窗口因果图，捕捉每个机制内的瞬时和滞后连接。通过合成数据的实验验证了所提出方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causal+Discovery+from+Heterogenous+Multivariate+Time+Series)|0|
|[Submodular Optimization: Variants, Theory and Applications](https://doi.org/10.1145/3627673.3680271)|Yanhui Zhu|Iowa State University, Ames, IA, USA|Submodular function optimization is a fundamental tool in modeling complex interactions in machine learning and graph mining problems. We propose to study constrained submodular optimization to improve the current state of the art. Our goals are to design evolutionary algorithms with stronger approximation guarantees, the study of submodular maximization under submodular constraints, fairness in submodular optimization, and k-submodular optimization. We begin by exploring a basic submodular maximization problem in the context of viral marketing/information diffusion in social networks. From there, we broaden our scope to include a broader range of scenarios and formulate them into more optimization problems. Looking ahead, we plan to tackle scalable submodular optimization problems in fairness, dynamic constraints, dynamic streams, and distributed fashion. Lastly, we discuss a series of real-world applications that can be formulated as submodular optimization problems. In the future, we aim to apply algorithmic ideas to solve more real-world problems.|子模函数优化是建模机器学习和图挖掘问题中复杂交互的基本工具。我们提出研究约束子模优化以改进当前的技术水平。我们的目标是设计具有更强近似保证的进化算法，研究在子模约束下的子模最大化问题，子模优化中的公平性，以及k-子模优化。我们首先在社交网络中的病毒营销/信息传播背景下探索一个基本的子模最大化问题。随后，我们扩大研究范围，涵盖更广泛的场景，并将它们表述为更多的优化问题。展望未来，我们计划解决公平性、动态约束、动态流和分布式方式中的可扩展子模优化问题。最后，我们讨论了一系列可以表述为子模优化问题的实际应用。未来，我们旨在应用算法思想解决更多的实际问题。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Submodular+Optimization:+Variants,+Theory+and+Applications)|0|
|[Fairness in Large Language Models in Three Hours](https://doi.org/10.1145/3627673.3679090)|Thang Viet Doan, Zichong Wang, Nhat Nguyen Minh Hoang, Wenbin Zhang||Large Language Models (LLMs) have demonstrated remarkable success across various domains but often lack fairness considerations, potentially leading to discriminatory outcomes against marginalized populations. Unlike fairness in traditional machine learning, fairness in LLMs involves unique backgrounds, taxonomies, and fulfillment techniques. This tutorial provides a systematic overview of recent advances in the literature concerning fair LLMs, beginning with real-world case studies to introduce LLMs, followed by an analysis of bias causes therein. The concept of fairness in LLMs is then explored, summarizing the strategies for evaluating bias and the algorithms designed to promote fairness. Additionally, resources for assessing bias in LLMs, including toolkits and datasets, are compiled, and current research challenges and open questions in the field are discussed. The repository is available at .|大型语言模型（LLMs）在各个领域展示了显著的成就，但往往缺乏公平性考虑，这可能导致对边缘化群体的歧视性结果。与传统机器学习中的公平性不同，LLMs中的公平性涉及独特的背景、分类学及实现技术。本教程系统性地概述了有关公平LLMs的文献最新进展，首先通过现实世界的案例研究介绍LLMs，随后分析其中的偏见成因。接着探讨LLMs中的公平性概念，总结评估偏见的策略及旨在促进公平性的算法。此外，还汇编了评估LLMs偏见的资源，包括工具包和数据集，并讨论了该领域当前的研究挑战和开放性问题。相关资源库可在访问。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fairness+in+Large+Language+Models+in+Three+Hours)|0|
|[On the Use of Large Language Models for Table Tasks](https://doi.org/10.1145/3627673.3679100)|Yuyang Dong, Masafumi Oyamada, Chuan Xiao, Haochen Zhang|Osaka University, Suita, Osaka, Japan; Osaka University, Nagoya University, Suita, Osaka, Japan; NEC, Kawasaki, Kanagawa, Japan|The proliferation of large language models (LLMs) has catalyzed a diverse array of applications. This tutorial delves into the application of LLMs for tabular data and targets a variety of table-related tasks, such as table understanding, text-to-SQL conversion, and tabular data preprocessing. It surveys LLM solutions to these tasks in five classes, categorized by their underpinning techniques: prompting, fine-tuning, RAG, agents, and multimodal methods. It discusses how LLMs offer innovative ways to interpret, augment, query, and cleanse tabular data, featuring academic contributions and their practical use in the industrial sector. It emphasizes the versatility and effectiveness of LLMs in handling complex table tasks, showcasing their ability to improve data quality, enhance analytical capabilities, and facilitate more intuitive data interactions. By surveying different approaches, this tutorial highlights the strengths of LLMs in enriching table tasks with more accuracy and usability, setting a foundation for future research and application in data science and AI-driven analytics. Presentation slides for this tutorial will be available at: https://dongyuyang.github.io/tableLLM-tutorial/ .|大型语言模型（LLMs）的广泛应用催生了多样化的应用场景。本教程深入探讨了LLMs在表格数据中的应用，并针对多种与表格相关的任务，如表格理解、文本到SQL转换以及表格数据预处理等进行了详细分析。教程将这些任务的LLM解决方案分为五类，基于它们所依赖的技术：提示（prompting）、微调（fine-tuning）、检索增强生成（RAG）、代理（agents）和多模态方法（multimodal methods）。教程讨论了LLMs如何通过创新的方式解释、增强、查询和清洗表格数据，涵盖了学术贡献及其在工业领域的实际应用。教程强调了LLMs在处理复杂表格任务时的多功能性和高效性，展示了它们在提升数据质量、增强分析能力以及促进更直观的数据交互方面的潜力。通过对不同方法的综述，本教程突出了LLMs在提高表格任务准确性和可用性方面的优势，为未来数据科学和人工智能驱动分析的研究与应用奠定了基础。本教程的演示文稿可在以下网址获取：https://dongyuyang.github.io/tableLLM-tutorial/。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+the+Use+of+Large+Language+Models+for+Table+Tasks)|0|
|[Tabular Data-centric AI: Challenges, Techniques and Future Perspectives](https://doi.org/10.1145/3627673.3679102)|Yanjie Fu, Dongjie Wang, Hui Xiong, Kunpeng Liu|Hong Kong University of Science and Technology (Guangzhou), Guangzhou, Guangdong, China; Arizona State University, Tempe, Arizona, USA; University of Kansas, Lawrence, Kansas, USA; Portland State University, Portland, Oregon, USA|Tabular data are the most widely used data formats in almost every application domain, such as, biology, ecology, and material science. The purpose of tabular data-centric AI is to use AI to augment the predictive power of tabular data to get better AI. Tabular data-centric AI is essential because it can reconstruct distance measures, reshape discriminative patterns, and improve data AI readiness (structural, predictive, interaction, and expression levels), which is significant in industries and real-world deployments. Therefore, our tutorial is designed to capture the interest of professionals with expertise in artificial intelligence, machine learning, and data mining, as well as researchers engaged in specific application areas and interdisciplinary studies. Examples of such applications include quality control, predictive maintenance, supply chain optimization, process efficiency improvements, biomarker identification, material performance screening. In this tutorial, we will explore the emerging field of Tabular Data-Centric AI. Our discussion will provide a comprehensive overview of this domain: (1) We will demonstrate the different settings within this research domain based on distinct application scenarios. (2) We will identify and explain the significant challenges encountered in tabular data-centric AI. (3) We will highlight existing methods and benchmarks. (4) We will discuss future potential directions for this domain and examine its interconnections with other research areas. To enhance the learning experience, this tutorial will include a hands-on section designed to teach participants the fundamental aspects of developing, evaluating and visualizing techniques in tabular data-centric AI. After this tutorial, attendees will have a deep understanding of tabular data-centric AI research, including its key challenges, seminal techniques, and insights into integrating tabular data-centric AI into their own research.|表格数据是几乎所有应用领域中最广泛使用的数据格式，例如生物学、生态学和材料科学。以表格数据为中心的人工智能（Tabular Data-Centric AI）旨在利用人工智能增强表格数据的预测能力，从而获得更好的人工智能效果。以表格数据为中心的人工智能至关重要，因为它可以重构距离度量、重塑判别模式，并提升数据的人工智能准备度（包括结构、预测、交互和表达层面），这在工业界和实际部署中具有重要意义。因此，本教程旨在吸引具有人工智能、机器学习和数据挖掘专业知识的专业人士，以及从事特定应用领域和跨学科研究的研究人员。此类应用示例包括质量控制、预测性维护、供应链优化、流程效率提升、生物标志物识别和材料性能筛选。在本教程中，我们将探索以表格数据为中心的人工智能这一新兴领域。我们的讨论将全面概述这一领域：（1）我们将基于不同的应用场景展示该研究领域中的不同设置。（2）我们将识别并解释以表格数据为中心的人工智能中遇到的重要挑战。（3）我们将重点介绍现有的方法和基准。（4）我们将讨论该领域的未来潜在方向，并探讨其与其他研究领域的相互联系。为了增强学习体验，本教程将包含一个实践环节，旨在向参与者教授在以表格数据为中心的人工智能中开发、评估和可视化技术的基本知识。通过本教程，参与者将深入了解以表格数据为中心的人工智能研究，包括其关键挑战、开创性技术，以及如何将以表格数据为中心的人工智能整合到自己的研究中的见解。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tabular+Data-centric+AI:+Challenges,+Techniques+and+Future+Perspectives)|0|
|[Frontiers of Large Language Model-Based Agentic Systems - Construction, Efficacy and Safety](https://doi.org/10.1145/3627673.3679105)|Jia He, Reshmi Ghosh, Kabir Walia, Jieqiu Chen, Tushar Dhadiwal, April Hazel, Chandra Inguva|Microsoft Corp., Redmond, WA, USA; Microsoft Corp., Salt Lake City, Utah, USA; Microsoft Corp., Cambridge, MA, USA; Microsoft Corp., St Louis, MO, USA|"The previous era was about information at your fingertips; I think of the AI era as expertise at your fingertips." - Satya Nadella, CNBC This tutorial explores Large Language Model (LLM)-based autonomous agents, addressing the lack of comprehensive guides on the topic. It systematically examines key components such as profiling, perception, memory, planning, and action, using an established taxonomy. The tutorial also extends the discussion to multi-agent frameworks, offering insights into collaborative intelligence. Additionally, it compares popular open-source frameworks for LLM-based agent development and discusses evaluation methodologies, focusing on efficiency and safety. The tutorial aims to catalyze dialogue and partnership among practitioners, propelling forward the integration of robust and effective LLM agent systems into the production environment.|“过去的时代是关于触手可及的信息；我认为人工智能时代是关于触手可及的专业知识。”——萨提亚·纳德拉，CNBC  
本教程探讨了基于大型语言模型（LLM）的自主代理，针对该领域缺乏全面指南的问题。通过使用既定的分类法，系统地研究了关键组件，如画像、感知、记忆、规划和行动。教程还将讨论扩展到多代理框架，提供了对协作智能的见解。此外，教程比较了流行的开源框架用于基于LLM的代理开发，并讨论了评估方法，重点关注效率和安全性。本教程旨在促进从业者之间的对话和合作，推动将稳健且有效的LLM代理系统集成到生产环境中。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Frontiers+of+Large+Language+Model-Based+Agentic+Systems+-+Construction,+Efficacy+and+Safety)|0|
|[Towards Efficient Temporal Graph Learning: Algorithms, Frameworks, and Tools](https://doi.org/10.1145/3627673.3679104)|Ruijie Wang, Wanyu Zhao, Dachun Sun, Charith Mendis, Tarek F. Abdelzaher|University of Illinois Urbana-Champaign, Champaign, IL, USA; University of Illinois Urbana-Champaign, Champaign, USA|Temporal graphs capture dynamic node relations via temporal edges, finding extensive utility in wide domains where time-varying patterns are crucial. Temporal Graph Neural Networks (TGNNs) have gained significant attention for their effectiveness in representing temporal graphs. However, TGNNs still face significant efficiency challenges in real-world low-resource settings. First, from a data-efficiency standpoint, training TGNNs requires sufficient temporal edges and data labels, which is problematic in practical scenarios with limited data collection and annotation. Second, from a resource-efficiency perspective, TGNN training and inference are computationally demanding due to complex encoding operations, especially on large-scale temporal graphs. Minimizing resource consumption while preserving effectiveness is essential. Inspired by these efficiency challenges, this tutorial systematically introduces state-of-the-art data-efficient and resource-efficient TGNNs, focusing on algorithms, frameworks, and tools, and discusses promising yet under-explored research directions in efficient temporal graph learning. This tutorial aims to benefit researchers and practitioners in data mining, machine learning, and artificial intelligence.|时序图通过时序边捕捉动态节点关系，在时间变化模式至关重要的广泛领域中具有广泛应用。时序图神经网络（TGNNs）因其在表示时序图方面的有效性而受到广泛关注。然而，TGNNs在实际低资源环境中仍面临显著的效率挑战。首先，从数据效率的角度来看，训练TGNNs需要足够的时序边和数据标签，这在数据收集和注释有限的实际场景中存在问题。其次，从资源效率的角度来看，TGNN的训练和推理由于复杂的编码操作而计算量大，尤其是在大规模时序图上。在保持有效性的同时最小化资源消耗至关重要。受这些效率挑战的启发，本教程系统地介绍了最先进的数据高效和资源高效的TGNNs，重点关注算法、框架和工具，并讨论了在高效时序图学习中有前景但尚未充分探索的研究方向。本教程旨在为数据挖掘、机器学习和人工智能领域的研究人员和从业者提供帮助。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Efficient+Temporal+Graph+Learning:+Algorithms,+Frameworks,+and+Tools)|0|
|[Transforming Digital Forensics with Large Language Models: Unlocking Automation, Insights, and Justice](https://doi.org/10.1145/3627673.3679091)|Eric Xu, Wenbin Zhang, Weifeng Xu|Florida International University, Miami, FL, USA; University of Maryland, College Park, MD, USA; University of Baltimore, Baltimore, MD, USA|In the pursuit of justice and accountability in the digital age, the integration of Large Language Models (LLMs) with digital forensics holds immense promise. This half-day tutorial provides a comprehensive exploration of the transformative potential of LLMs in automating digital investigations and uncovering hidden insights. Through a combination of real-world case studies, interactive exercises, and hands-on labs, participants will gain a deep understanding of how to harness LLMs for evidence analysis, entity identification, and knowledge graph reconstruction. By fostering a collaborative learning environment, this tutorial aims to empower professionals, researchers, and students with the skills and knowledge needed to drive innovation in digital forensics. As LLMs continue to revolutionize the field, this tutorial will have far-reaching implications for enhancing justice outcomes, promoting accountability, and shaping the future of digital investigations.|在数字时代追求正义和问责的过程中，将大语言模型（LLMs）与数字取证相结合具有巨大的潜力。本次半天的教程全面探讨了LLMs在自动化数字调查和揭示隐藏洞察力方面的变革性潜力。通过结合真实案例分析、互动练习和动手实验，参与者将深入了解如何利用LLMs进行证据分析、实体识别和知识图谱重建。通过营造协作学习环境，本教程旨在为专业人士、研究人员和学生提供推动数字取证创新所需的技能和知识。随着LLMs继续革新这一领域，本教程将对提升司法结果、促进问责以及塑造数字调查的未来产生深远影响。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Transforming+Digital+Forensics+with+Large+Language+Models:+Unlocking+Automation,+Insights,+and+Justice)|0|
|[Collecting and Analyzing Public Data from Mastodon](https://doi.org/10.1145/3627673.3679093)|Haris Bin Zia, Ignacio Castro, Gareth Tyson|HKUST & QMUL, Guangzhou, China; QMUL, London, United Kingdom|Understanding online behaviors, communities, and trends through social media analytics is becoming increasingly important. Recent changes in the accessibility of platforms like Twitter have made Mastodon a valuable alternative for researchers. In this tutorial, we will explore methods for collecting and analyzing public data from Mastodon, a decentralized micro-blogging social network. Participants will learn about the architecture of Mastodon, techniques and best practices for data collection, and various analytical methods to derive insights from the collected data. This session aims to equip researchers with the skills necessary to harness the potential of Mastodon data in computational social science and social data science research.|通过社交媒体分析来理解在线行为、社区和趋势正变得越来越重要。最近，像Twitter这样的平台在可访问性方面的变化使得Mastodon成为研究者的一个宝贵替代选择。在本教程中，我们将探讨从Mastodon（一个去中心化的微博客社交网络）收集和分析公共数据的方法。参与者将了解Mastodon的架构、数据收集的技术和最佳实践，以及从收集的数据中提取洞察的各种分析方法。本课程旨在为研究者提供必要的技能，以利用Mastodon数据在计算社会科学和社会数据科学研究中的潜力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Collecting+and+Analyzing+Public+Data+from+Mastodon)|0|
|[Bridging Knowledge Gaps in LLMs via Function Calls](https://doi.org/10.1145/3627673.3679070)|Kinjal Basu|IBM Research, Dallas, TX, USA|Large Language Models (LLMs) demonstrate impressive abilities across a wide range of NLP tasks. However, their underlying architecture and design come with inherent limitations, which result in issues like hallucinations and constrained reasoning capabilities. Additionally, creating an autonomous AI agent capable of handling complex real-world tasks demands access to real-time information, sensitive data, or external tools-capabilities that most LLMs currently lack. Addressing these issues may require augmenting LLMs with external knowledge through function calling. These function calls serve as an interface between LLMs and the world, enabling access to real-time data, diverse tools, reasoning systems, knowledge graphs, APIs, plugins, code interpreters, and more. The primary objective of this talk is to highlight the significance of function-calling capabilities in bridging the knowledge gap in LLMs, showcase recent research advancements in this area, and discuss existing challenges along with future directions. Also, I will present a training and benchmarking data suite for function calling - API-BLEND and a function calling model - Granite-20B-FunctionCalling.|大型语言模型（LLMs）在广泛的自然语言处理（NLP）任务中展现了令人印象深刻的能力。然而，它们的基础架构和设计存在固有的局限性，这导致了诸如幻觉和推理能力受限等问题。此外，创建一个能够处理复杂现实世界任务的自主人工智能代理需要访问实时信息、敏感数据或外部工具——这些能力是目前大多数LLMs所缺乏的。解决这些问题可能需要通过函数调用为LLMs增强外部知识。这些函数调用充当LLMs与外部世界之间的接口，使其能够访问实时数据、多样化工具、推理系统、知识图谱、API、插件、代码解释器等。本次演讲的主要目标是强调函数调用能力在弥补LLMs知识差距中的重要性，展示该领域的最新研究进展，并讨论现有的挑战及未来方向。此外，我将介绍一个用于函数调用的训练和基准测试数据集——API-BLEND，以及一个函数调用模型——Granite-20B-FunctionCalling。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bridging+Knowledge+Gaps+in+LLMs+via+Function+Calls)|0|
|[Planes, Trains and Automobiles: Leverage Multimodal In-Mission Signals for Shopping Journeys](https://doi.org/10.1145/3627673.3679067)|Viet HaThuc, Shasha Li, Arnau Ramisa, Xinliang Zhu|Amazon Inc., Palo Alto, CA, USA|Modern search systems offer multiple ways for expressing information needs, including image, voice, and text. Consequently, an increasing number of users seamlessly transition between these modalities to convey their intents. This emerging trend presents new opportunities for utilizing queries in different modalities to help users complete their search journeys efficiently. In this proposal, we introduce an approach to segmenting a multimodal query stream into missions, demonstrate how these in-mission queries can enhance search ranking, and outline key areas for future research.|现代搜索系统提供了多种表达信息需求的方式，包括图像、语音和文本。因此，越来越多的用户在这些模态之间无缝切换以传达他们的意图。这一新兴趋势为利用不同模态的查询来帮助用户高效完成搜索旅程提供了新的机会。在本提案中，我们介绍了一种将多模态查询流分割为任务的方法，展示了这些任务内查询如何增强搜索排序，并概述了未来研究的关键领域。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Planes,+Trains+and+Automobiles:+Leverage+Multimodal+In-Mission+Signals+for+Shopping+Journeys)|0|
|[Towards Energy-Efficient Llama2 Architecture on Embedded FPGAs](https://doi.org/10.1145/3627673.3679068)|Han Xu, Xingyuan Wang, Shihao Ji|University of Illinois at Urbana-Champaign, Urbana, IL, USA; Georgia State University, Atlanta, GA, USA; Meta Platforms Inc., Seattle, WA, USA|Large language models (LLMs) have shown immense potential for applications in information retrieval and knowledge management, but their computational and memory demands pose challenges for resource-constrained devices. In response, this work introduces an FPGA-based accelerator designed to improve LLM inference performance on embedded devices. We leverage quantization techniques, asynchronous computation, and a fully-pipelined accelerator to enhance efficiency. Our empirical evaluations, conducted using the TinyLlama 1.1B model on a Xilinx ZCU102 platform, demonstrate a 14.3-15.8x speedup and a 6.1x energy efficiency improvement over running exclusively on the ZCU102 processing system (PS).|大型语言模型（LLMs）在信息检索和知识管理领域展现了巨大的应用潜力，但其计算和内存需求对资源受限的设备构成了挑战。为此，本研究提出了一种基于FPGA的加速器，旨在提升嵌入式设备上的LLM推理性能。我们采用了量化技术、异步计算和全流水线加速器来提高效率。通过在Xilinx ZCU102平台上使用TinyLlama 1.1B模型进行的实证评估表明，与仅在ZCU102处理系统（PS）上运行相比，该加速器实现了14.3至15.8倍的加速，并且能效提升了6.1倍。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Energy-Efficient+Llama2+Architecture+on+Embedded+FPGAs)|0|
|[Trustworthy and Responsible AI for Information and Knowledge Management System](https://doi.org/10.1145/3627673.3680111)|Huaming Chen, Jun Zhuang, Yu Yao, Wei Jin, Haohan Wang, Yong Xie, ChiHung Chi, KimKwang Raymond Choo|Amazon, Seattle, USA; The University of Sydney, Sydney, Australia; The University of Texas at San Antonio, San Antonio, USA; Boise State University, Boise, USA; Emory University, Atlanta, USA; Nanyang Technological University, Singapore, Singapore; University of Illinois Urbana-Champaign, Champaign, USA|The way research and business manage and utilize knowledge is undergoing a significant transformation, driven by Artificial Intelligence (AI). Deep learning and machine learning are emerging as powerful tools for optimizing knowledge management systems, leading to more informed and productive development. AI offers unique solutions for organizations struggling with information overload and inefficient knowledge transfer. These AI models can significantly improve data management and utilization. Imagine an AI-powered system that streamlines onboarding processes, provides precise answers to various queries, and even captures the valuable tacit knowledge (implicit skills and expertise) often residing within individuals. AI bridges the gap between explicit knowledge (easily documented information) and tacit knowledge, fostering a more comprehensive and accessible knowledge base. However, such AI systems solicit trustworthy and responsible approaches to mitigate potential misuse and malfunction. In this workshop, we aim to gather researchers and engineers from academia and industry to discuss the latest advances in trustworthy and responsible AI solutions for information and knowledge management systems.|研究和商业领域管理和利用知识的方式正在经历一场由人工智能（AI）驱动的重大变革。深度学习和机器学习正成为优化知识管理系统的强大工具，从而推动更明智和高效的发展。对于面临信息过载和知识传递效率低下问题的组织，人工智能提供了独特的解决方案。这些AI模型能够显著改善数据的管理和利用。试想一个由AI驱动的系统，它可以简化入职流程，为各种查询提供精准答案，甚至能够捕捉通常存在于个人中的宝贵隐性知识（即隐含的技能和专业知识）。AI在显性知识（易于记录的信息）和隐性知识之间架起了桥梁，从而构建了一个更加全面和易于访问的知识库。然而，这类AI系统需要采用可信且负责任的方法，以减轻潜在的滥用和故障风险。在本研讨会中，我们旨在汇集来自学术界和工业界的研究人员和工程师，共同探讨信息和知识管理系统中可信且负责任的人工智能解决方案的最新进展。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Trustworthy+and+Responsible+AI+for+Information+and+Knowledge+Management+System)|0|
|[Knowledge Graphs for Responsible AI](https://doi.org/10.1145/3627673.3679085)|Edlira Vakaj, Nandana Mihindukulasooriya, Manas Gaur, Arijit Khan|University of Maryland Baltimore County, Baltimore, MD, USA; IBM Research, New York, USA; Birmingham City University, Birmingham, United Kingdom; Aalborg University, Aalborg, Denmark|Responsible AI is built upon a set of principles that prioritize fairness, transparency, accountability, and inclusivity in AI development and deployment. As AI systems become increasingly sophisticated, including the explosion of generative AI, there is a growing need to address ethical considerations and potential societal impacts of their uses. Knowledge graphs (KGs), as structured representations of information, can enhance generative AI performance by providing context, explaining outputs, and reducing biases, thereby offering a powerful framework to address the challenges of responsible AI. By leveraging semantic relationships and contextual understanding, KGs facilitate transparent decision-making, enabling stakeholders to trace and interpret the reasoning behind AI driven outcomes. Moreover, they provide a means to capture and manage diverse knowledge sources, supporting the development of fair and unbiased AI models. The workshop aims to investigate the role of knowledge graphs in promoting responsible AI principles and creating a cooperative space for researchers, practitioners, and policymakers to exchange insights and enhance their comprehension of KGs' impact on achieving responsible AI solutions. It seeks to facilitate collaboration and idea-sharing to advance the understanding of how KGs can contribute to responsible AI.|负责任的人工智能（Responsible AI）建立在一系列原则之上，这些原则优先考虑公平性、透明性、问责性和包容性，贯穿人工智能的开发与部署过程。随着人工智能系统（包括生成式人工智能的爆炸式增长）变得越来越复杂，解决其使用中的伦理考量和潜在社会影响的需求也日益迫切。知识图谱（Knowledge Graphs, KGs）作为信息的结构化表示形式，能够通过提供上下文、解释输出以及减少偏见来增强生成式人工智能的性能，从而为解决负责任人工智能的挑战提供了一个强大的框架。通过利用语义关系和上下文理解，知识图谱促进了透明决策的制定，使利益相关者能够追踪和解释人工智能驱动结果的推理过程。此外，知识图谱还提供了一种捕捉和管理多样化知识来源的手段，支持开发公平且无偏见的人工智能模型。本次研讨会旨在探讨知识图谱在推动负责任人工智能原则中的作用，并创建一个供研究人员、从业者和政策制定者交流见解、加深对知识图谱在实现负责任人工智能解决方案中影响理解的合作空间。研讨会希望通过促进协作与思想共享，进一步推动对知识图谱如何助力负责任人工智能的理解。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge+Graphs+for+Responsible+AI)|0|

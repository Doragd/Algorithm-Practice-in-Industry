# CIKM2023 Paper List

|论文|作者|组织|摘要|翻译|代码|引用数|
|---|---|---|---|---|---|---|
|[BI-GCN: Bilateral Interactive Graph Convolutional Network for Recommendation](https://doi.org/10.1145/3583780.3615232)|Yinan Zhang, Pei Wang, Congcong Liu, Xiwei Zhao, Hao Qi, Jie He, Junsheng Jin, Changping Peng, Zhangang Lin, Jingping Shao|JD.com, Beijing, China|Recently, Graph Convolutional Network (GCN) based methods have become novel state-of-the-arts for Collaborative Filtering (CF) based Recommender Systems. To obtain users' preferences over different items, it is a common practice to learn representations of users and items by performing embedding propagation on a user-item bipartite graph, and then calculate the preference scores based on the representations. However, in most existing algorithms, user/item representations are generated independently of target items/users. To address this problem, we propose a novel graph attention model named Bilateral Interactive GCN (BI-GCN), which introduces bilateral interactive guidance into each user-item pair and thus leads to target-aware representations for preference prediction. Specifically, to learn the user/item representation from its neighborhood, we assign higher attention weights to those neighbors similar to the target item/user. By this manner, we can obtain target-aware representations, i.e., the information of the target item/user is explicitly encoded in the corresponding user/item representation, for more precise matching. Extensive experiments on three benchmark datasets demonstrate the effectiveness and robustness of BI-GCN.|最近，基于图卷积网络(GCN)的方法已经成为基于协同过滤(CF)的推荐系统的最新技术。为了获得用户对不同项目的偏好，通常的做法是通过在用户-项目二部图上嵌入传播来学习用户和项目的表示，然后根据表示计算偏好得分。但是，在大多数现有算法中，用户/项表示是独立于目标项/用户生成的。为了解决这一问题，我们提出了一种新的图形注意模型——双边交互式 GCN (BI-GCN) ，该模型将双边交互式引导引入到每个用户项目对中，从而产生用于偏好预测的目标感知表示。具体来说，为了从邻域中学习用户/项目表示，我们给与目标项目/用户相似的邻域分配更高的注意力权重。通过这种方式，我们可以获得目标感知的表示，也就是说，目标项/用户的信息显式地编码在相应的用户/项表示中，以便进行更精确的匹配。在三个基准数据集上的大量实验证明了 BI-GCN 的有效性和鲁棒性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BI-GCN:+Bilateral+Interactive+Graph+Convolutional+Network+for+Recommendation)|1|
|[Monotonic Neural Ordinary Differential Equation: Time-series Forecasting for Cumulative Data](https://doi.org/10.1145/3583780.3615487)|Zhichao Chen, Leilei Ding, Zhixuan Chu, Yucheng Qi, Jianmin Huang, Hao Wang|Ant Group, Hangzhou, China|Time-Series Forecasting based on Cumulative Data (TSFCD) is a crucial problem in decision-making across various industrial scenarios. However, existing time-series forecasting methods often overlook two important characteristics of cumulative data, namely monotonicity and irregularity, which limit their practical applicability. To address this limitation, we propose a principled approach called Monotonic neural Ordinary Differential Equation (MODE) within the framework of neural ordinary differential equations. By leveraging MODE, we are able to effectively capture and represent the monotonicity and irregularity in practical cumulative data. Through extensive experiments conducted in a bonus allocation scenario, we demonstrate that MODE outperforms state-of-the-art methods, showcasing its ability to handle both monotonicity and irregularity in cumulative data and delivering superior forecasting performance.|基于累积数据的时间序列预测是各种工业情景下决策的关键问题。然而，现有的时间序列预测方法往往忽视了累积数据的两个重要特征，即单调性和不规则性，这限制了它们的实际应用。为了解决这一局限性，我们提出了一种在神经常微分方程框架内的原理性方法，称为单调神经常微分方程(MODE)。通过利用 MODE，我们能够有效地捕获和表示实际累积数据中的单调性和不规则性。通过在奖金分配场景中进行的大量实验，我们证明了 MODE 优于最先进的方法，展示了其处理累积数据中的单调性和不规则性的能力，并提供了卓越的预测性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Monotonic+Neural+Ordinary+Differential+Equation:+Time-series+Forecasting+for+Cumulative+Data)|1|
|[Continual Learning in Predictive Autoscaling](https://doi.org/10.1145/3583780.3615463)|Hongyan Hao, Zhixuan Chu, Shiyi Zhu, Gangwei Jiang, Yan Wang, Caigao Jiang, James Y. Zhang, Wei Jiang, Siqiao Xue, Jun Zhou|Ant Group, Hangzhou, China; Ant Group, New York, NY, USA|Predictive Autoscaling is used to forecast the workloads of servers and prepare the resources in advance to ensure service level objectives (SLOs) in dynamic cloud environments.However, in practice, its prediction task often suffers from performance degradation under abnormal traffics caused by external events (such as sales promotional activities and applications' re-configurations), for which a common solution is to re-train the model with data of a long historical period, but at the expense of high computational and storage costs.To better address this problem, we propose a replay-based continual learning method, i.e., Density-based Memory Selection and Hint-based Network Learning Model (DMSHM), using only a small part of the historical log to achieve accurate predictions.First, we discover the phenomenon of sample overlap when applying replay-based continual learning in prediction tasks. In order to surmount this challenge and effectively integrate new sample distribution, we propose a density-based sample selection strategy that utilizes kernel density estimation to calculate sample density as a reference to compute sample weight, and employs weight sampling to construct a new memory set.Then we implement hint-based network learning based on hint representation to optimize the parameters.Finally, we conduct experiments on public and industrial datasets to demonstrate that our proposed method outperforms state-of-the-art continual learning methods in terms of memory capacity and prediction accuracy. Furthermore, we demonstrate remarkable practicability of DMSHM in real industrial applications.|预测性自动伸缩用于预测服务器的工作负载并提前准备资源，以确保动态云环境中的服务水平目标(SLOs)。然而，在实践中，其预测任务往往受到异常流量下的性能下降的外部事件(如销售促销活动和应用程序的重新配置) ，其中一个常见的解决方案是重新训练模型与长期的历史时期的数据，但以高计算和存储成本为代价。为了更好地解决这个问题，我们提出了一个基于重放的连续学习方法，即基于密度的记忆选择和基于提示的网络学习模型(DMSHM) ，只使用历史日志的一小部分来实现准确的预测。首先，我们发现了在预测任务中应用基于重播的连续学习时样本重叠的现象。为了克服这个挑战，并有效地整合新的样本分布，我们提出一个基于密度的样本选择策略，利用核密度估计计算样本密度作为计算样本权重的参考，并利用权重采样来构建一个新的记忆集。然后基于提示表示实现了基于提示的网络学习，对参数进行了优化。最后，我们在公共数据集和工业数据集上进行了实验，结果表明我们提出的方法在记忆容量和预测准确性方面优于最先进的连续学习方法。此外，我们证明了 DMSHM 在实际工业应用中的显著实用性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Continual+Learning+in+Predictive+Autoscaling)|1|
|[TEI2GO: A Multilingual Approach for Fast Temporal Expression Identification](https://doi.org/10.1145/3583780.3615130)|Hugo Sousa, Ricardo Campos, Alípio Jorge|University of Porto & INESC TEC, Porto, Portugal; University of Beira Interior & INESC TEC, Covilhã, Portugal|Temporal expression identification is crucial for understanding texts written in natural language. Although highly effective systems such as HeidelTime exist, their limited runtime performance hampers adoption in large-scale applications and production environments. In this paper, we introduce the TEI2GO models, matching HeidelTime's effectiveness but with significantly improved runtime, supporting six languages, and achieving state-of-the-art results in four of them. To train the TEI2GO models, we used a combination of manually annotated reference corpus and developed "Professor HeidelTime'', a comprehensive weakly labeled corpus of news texts annotated with HeidelTime. This corpus comprises a total of 138,069 documents (over six languages) with 1,050,921 temporal expressions, the largest open-source annotated dataset for temporal expression identification to date. By describing how the models were produced, we aim to encourage the research community to further explore, refine, and extend the set of models to additional languages and domains. Code, annotations, and models are openly available for community exploration and use. The models are conveniently on HuggingFace for seamless integration and application.|时间表达式识别是理解自然语言文本的关键。尽管存在像 HeidelTime 这样的高效系统，但它们有限的运行时性能阻碍了在大规模应用程序和生产环境中的采用。在本文中，我们介绍了 TEI2GO 模型，匹配 HeidelTime 的有效性，但有显著改进的运行时，支持六种语言，并在其中四种语言中取得了最先进的结果。为了训练 TEI2GO 模型，我们使用了人工注释的参考语料库的组合，并开发了“海德尔时间教授”，一个全面的弱标记的新闻文本的海德尔时间注释语料库。这个语料库包含138,069个文档(超过6种语言)和1,050,921个时态表达式，是迄今为止用于时态表达式识别的最大的开源注释数据集。通过描述模型是如何产生的，我们的目标是鼓励研究团体进一步探索、完善和扩展模型集到其他语言和领域。代码、注释和模型可供社区探索和使用。该模型可以方便地在 HuggingFace 上进行无缝集成和应用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TEI2GO:+A+Multilingual+Approach+for+Fast+Temporal+Expression+Identification)|1|
|[APGL4SR: A Generic Framework with Adaptive and Personalized Global Collaborative Information in Sequential Recommendation](https://doi.org/10.1145/3583780.3614781)|Mingjia Yin, Hao Wang, Xiang Xu, Likang Wu, Sirui Zhao, Wei Guo, Yong Liu, Ruiming Tang, Defu Lian, Enhong Chen|University of Science and Technology of China & State Key Laboratory of Cognitive Intelligence, Hefei, China; Huawei Singapore Research Center, Singapore, Singapore; Huawei Noah's Ark Lab, Shenzhen, China|The sequential recommendation system has been widely studied for its promising effectiveness in capturing dynamic preferences buried in users' sequential behaviors. Despite the considerable achievements, existing methods usually focus on intra-sequence modeling while overlooking exploiting global collaborative information by inter-sequence modeling, resulting in inferior recommendation performance. Therefore, previous works attempt to tackle this problem with a global collaborative item graph constructed by pre-defined rules. However, these methods neglect two crucial properties when capturing global collaborative information, i.e., adaptiveness and personalization, yielding sub-optimal user representations. To this end, we propose a graph-driven framework, named Adaptive and Personalized Graph Learning for Sequential Recommendation (APGL4SR), that incorporates adaptive and personalized global collaborative information into sequential recommendation systems. Specifically, we first learn an adaptive global graph among all items and capture global collaborative information with it in a self-supervised fashion, whose computational burden can be further alleviated by the proposed SVD-based accelerator. Furthermore, based on the graph, we propose to extract and utilize personalized item correlations in the form of relative positional encoding, which is a highly compatible manner of personalizing the utilization of global collaborative information. Finally, the entire framework is optimized in a multi-task learning paradigm, thus each part of APGL4SR can be mutually reinforced. As a generic framework, APGL4SR can not only outperform other baselines with significant margins, but also exhibit promising versatility, the ability to learn a meaningful global collaborative graph, and the ability to alleviate the dimensional collapse issue of item embeddings.|顺序推荐系统在捕获隐藏在用户顺序行为中的动态偏好方面有着广泛的应用前景。尽管已经取得了相当大的成就，但现有的方法往往只注重序列内建模，而忽视了通过序列间建模来开发全局协同信息，导致推荐性能较差。因此，以往的研究尝试利用预先定义的规则构造一个全局协同项目图来解决这个问题。然而，这些方法在获取全局协作信息时忽略了两个关键性质，即适应性和个性化，产生了次优的用户表示。为此，我们提出了一个图驱动的序列推荐自适应和个性化图学习框架(APGL4SR) ，该框架将自适应和个性化的全局协作信息融入到序列推荐系统中。具体来说，我们首先学习一个所有项目之间的自适应全局图，并以自监督的方式捕获全局协作信息，通过提出的基于奇异值分解的加速器可以进一步减轻全局协作信息的计算负担。在此基础上，提出了以相对位置编码的形式提取和利用个性化项目相关性，这是一种高度兼容的利用全球协同信息的个性化方式。最后，在多任务学习范式下对整个框架进行优化，使 APGL4SR 的各个部分得到相互增强。作为一个通用框架，APGL4SR 不仅具有显著的优势，而且具有良好的通用性、学习有意义的全局协作图的能力以及缓解项目嵌入的尺寸崩溃问题的能力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=APGL4SR:+A+Generic+Framework+with+Adaptive+and+Personalized+Global+Collaborative+Information+in+Sequential+Recommendation)|0|
|[Query-dominant User Interest Network for Large-Scale Search Ranking](https://doi.org/10.1145/3583780.3615022)|Tong Guo, Xuanping Li, Haitao Yang, Xiao Liang, Yong Yuan, Jingyou Hou, Bingqing Ke, Chao Zhang, Junlin He, Shunyu Zhang, Enyun Yu, Wenwu Ou|unaffiliated, Beijing, China; Kuaishou Technology Co., Ltd, Beijing, China|Historical behaviors have shown great effect and potential in various prediction tasks, including recommendation and information retrieval. The overall historical behaviors are various but noisy while search behaviors are always sparse. Most existing approaches in personalized search ranking adopt the sparse search behaviors to learn representation with bottleneck, which do not sufficiently exploit the crucial long-term interest. In fact, there is no doubt that user long-term interest is various but noisy for instant search, and how to exploit it well still remains an open problem. To tackle this problem, in this work, we propose a novel model named Query-dominant user Interest Network (QIN), including two cascade units to filter the raw user behaviors and reweigh the behavior subsequences. Specifically, we propose a relevance search unit (RSU), which aims to search a subsequence relevant to the query first and then search the sub-subsequences relevant to the target item. These items are then fed into an attention unit called Fused Attention Unit (FAU). It should be able to calculate attention scores from the ID field and attribute field separately, and then adaptively fuse the item embedding and content embedding based on the user engagement of past period. Extensive experiments and ablation studies on real-world datasets demonstrate the superiority of our model over state-of-the-art methods. The QIN now has been successfully deployed on Kuaishou search, an online video search platform, and obtained 7.6% improvement on CTR.|历史行为在各种预测任务中显示出巨大的效果和潜力，包括推荐和信息检索。整体的历史行为是多样的，但是有噪声，而搜索行为总是稀疏的。大多数现有的个性化检索排名方法采用稀疏搜索行为来学习带有瓶颈的表示，这种方法没有充分利用关键的长期兴趣。事实上，毫无疑问，用户对即时搜索的长期兴趣是多种多样的，但是噪音很大，如何很好地利用它仍然是一个悬而未决的问题。为了解决这一问题，本文提出了一种新的查询主导用户兴趣网络(QIN)模型，该模型包括两个级联单元，用于过滤原始用户行为和重新权衡行为子序列。具体来说，我们提出了一种相关搜索单元(RSU) ，它的目的是先搜索与查询相关的子序列，然后再搜索与目标项相关的子子序列。然后，这些物品被输入一个称为“融合注意力单元”(FAU)的注意力单元。它应该能够分别从 ID 字段和属性字段计算注意力得分，然后根据用户过去一段时间的参与度自适应地融合项目嵌入和内容嵌入。对真实世界数据集的大量实验和消融研究表明，我们的模型优于最先进的方法。QIN 现已成功部署在快手搜索(一个在线视频搜索平台)上，点击率提高了7.6% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Query-dominant+User+Interest+Network+for+Large-Scale+Search+Ranking)|0|
|[Modeling Sequential Collaborative User Behaviors For Seller-Aware Next Basket Recommendation](https://doi.org/10.1145/3583780.3614973)|Ziyi Kou, Saurav Manchanda, ShihTing Lin, Min Xie, Haixun Wang, Xiangliang Zhang|University of Notre Dame, Notre Dame, IN, USA; Instacart, San Francisco, CA, USA|Next Basket Recommendation (NBR) aims to recommend a set of products as a basket to users based on their historical shopping behavior. In this paper, we investigate the problem of NBR in online marketplaces (e.g., Instacart, Uber Eats) that connect users with multiple sellers. In such scenarios, effective NBR can significantly enhance the shopping experience of users by recommending diversified and completed products based on specific sellers, especially when a user purchases from a seller they have not visited before. However, conventional NBR approaches assume that all considered products are from the same sellers, which overlooks the complex relationships between users, sellers, and products. To address such limitations, we develop SecGT, a sequential collaborative graph transformer framework that recommends users with baskets from specific sellers based on seller-aware user preference representations that are generated by collaboratively modeling the joint user-seller-product interactions and sequentially exploring the user-agnostic basket transitions in an interactive way. We evaluate the performance of SecGT on users from a leading online marketplace at multiple cities with various involved sellers. The results show that SecGT outperforms existing NBR and also traditional product recommendation approaches on recommending baskets from cold sellers for different types of users across all cities.|下一个购物篮推荐系统(NBR)的目标是根据用户的历史购物行为向他们推荐一组产品作为购物篮。在本文中，我们研究了在线市场(如 Instacart，Uber Eats)中连接用户和多个卖家的 NBR 问题。在这种情况下，有效的 NBR 可以通过推荐基于特定卖家的多样化和完整的产品来显著提高用户的购物体验，特别是当用户从他们以前没有访问过的卖家那里购买产品时。然而，传统的 NBR 方法假设所有被考虑的产品都来自同一个销售商，这忽略了用户、销售商和产品之间的复杂关系。为了解决这些局限性，我们开发了 SecGT，这是一个连续的协作图形转换框架，根据卖方感知的用户偏好表示，通过协作建模联合用户-卖方-产品交互并以交互方式顺序探索用户不可知的篮子转换来推荐用户。我们评估的性能，从一个领先的在线市场在多个城市的用户与各种参与的卖家。结果表明，在向各城市不同类型的用户推荐冷卖篮子方面，SecGT 的表现优于现有的 NBR 和传统的产品推荐方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modeling+Sequential+Collaborative+User+Behaviors+For+Seller-Aware+Next+Basket+Recommendation)|0|
|[Rec4Ad: A Free Lunch to Mitigate Sample Selection Bias for Ads CTR Prediction in Taobao](https://doi.org/10.1145/3583780.3615496)|Jingyue Gao, Shuguang Han, Han Zhu, Siran Yang, Yuning Jiang, Jian Xu, Bo Zheng|Alibaba Group, Beijing, China|Click-Through Rate (CTR) prediction serves as a fundamental component in online advertising. A common practice is to train a CTR model on advertisement (ad) impressions with user feedback. Since ad impressions are purposely selected by the model itself, their distribution differs from the inference distribution and thus exhibits sample selection bias (SSB) that affects model performance. Existing studies on SSB mainly employ sample re-weighting techniques which suffer from high variance and poor model calibration. Another line of work relies on costly uniform data that is inadequate to train industrial models. Thus mitigating SSB in industrial models with a uniform-data-free framework is worth exploring. Fortunately, many platforms display mixed results of organic items (i.e., recommendations) and sponsored items (i.e., ads) to users, where impressions of ads and recommendations are selected by different systems but share the same user decision rationales. Based on the above characteristics, we propose to leverage recommendations samples as a free lunch to mitigate SSB for ads CTR model (Rec4Ad). After elaborating data augmentation, Rec4Ad learns disentangled representations with alignment and decorrelation modules for enhancement. When deployed in Taobao display advertising system, Rec4Ad achieves substantial gains in key business metrics, with a lift of up to +6.6\% CTR and +2.9\% RPM.|点进率预测是在线广告的一个基本组成部分。一个常见的做法是训练广告(广告)印象与用户反馈的点击率模型。由于广告印象是由模型本身有目的地选择的，它们的分布不同于推断分布，因此表现出影响模型性能的样本选择偏差(SSB)。现有的 SSB 研究主要采用样本重权重技术，存在方差大、模型校正差等问题。另一项工作依赖于昂贵的统一数据，这些数据不足以培训工业模型。因此，在无统一数据框架的工业模型中减少 SSB 是值得探索的。幸运的是，许多平台向用户显示有机项目(即推荐)和赞助项目(即广告)的混合结果，其中广告和推荐的印象由不同的系统选择，但共享相同的用户决策理由。基于上述特点，我们建议利用推荐样本作为免费午餐，以减轻 SSB 广告点击率模型(Rec4Ad)。在详细阐述了数据增强之后，Rec4Ad 学习了利用对齐和去相关模块进行增强的解纠缠表示。在淘宝展示广告系统中部署 Rec4Ad 后，Rec4Ad 在关键业务指标上取得了实质性进展，点击率和转速分别提高了6.6% 和2.9% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rec4Ad:+A+Free+Lunch+to+Mitigate+Sample+Selection+Bias+for+Ads+CTR+Prediction+in+Taobao)|0|
|[Fragment and Integrate Network (FIN): A Novel Spatial-Temporal Modeling Based on Long Sequential Behavior for Online Food Ordering Click-Through Rate Prediction](https://doi.org/10.1145/3583780.3615478)|Jun Li, Ge Zhang||Spatial-temporal information has been proven to be of great significance for click-through rate prediction tasks in online Location-Based Services (LBS), especially in mainstream food ordering platforms such as DoorDash, Uber Eats, Meituan, and Ele.me. Modeling user spatial-temporal preferences with sequential behavior data has become a hot topic in recommendation systems and online advertising. However, most of existing methods either lack the representation of rich spatial-temporal information or only handle user behaviors with limited length, e.g. 100. In this paper, we tackle these problems by designing a new spatial-temporal modeling paradigm named Fragment and Integrate Network (FIN). FIN consists of two networks: (i) Fragment Network (FN) extracts Multiple Sub-Sequences (MSS) from lifelong sequential behavior data, and captures the specific spatial-temporal representation by modeling each MSS respectively. Here both a simplified attention and a complicated attention are adopted to balance the performance gain and resource consumption. (ii) Integrate Network (IN) builds a new integrated sequence by utilizing spatial-temporal interaction on MSS and captures the comprehensive spatial-temporal representation by modeling the integrated sequence with a complicated attention. Both public datasets and production datasets have demonstrated the accuracy and scalability of FIN. Since 2022, FIN has been fully deployed in the recommendation advertising system of Ele.me, one of the most popular online food ordering platforms in China, obtaining 5.7% improvement on Click-Through Rate (CTR) and 7.3% increase on Revenue Per Mille (RPM).|时空信息已被证明对于在线基于位置服务(LBS)的点进率预测任务具有重要意义，特别是在主流食品订购平台如 DoorDash、 Uber Eats、美团和 Ele.me 中。利用序列行为数据建立用户时空偏好模型已成为推荐系统和在线广告研究的热点。然而，大多数现有的方法要么缺乏丰富的时空信息的表示，要么只能处理有限长度的用户行为，例如100。针对这些问题，本文设计了一种新的时空建模范式——分段集成网络(FIN)。FIN 由两个网络组成: (1)片段网络(FN)从终身序列行为数据中提取多个子序列(MSS) ，并分别对每个子序列进行建模，获取特定的时空表示。这里采用了简化注意和复杂注意来平衡性能增益和资源消耗。(2)综合网络(IN)利用 MSS 上的时空相互作用建立一个新的综合序列，通过对综合序列进行复杂注意力建模，获取综合的时空表示。公共数据集和生产数据集都证明了 FIN 的准确性和可扩展性。自2022年以来，中国最受欢迎的在线食品订购平台之一饿了么的推荐广告系统中已经全面部署了财务识别系统，点进率点击率提高了5.7% ，每公里收入提高了7.3% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fragment+and+Integrate+Network+(FIN):+A+Novel+Spatial-Temporal+Modeling+Based+on+Long+Sequential+Behavior+for+Online+Food+Ordering+Click-Through+Rate+Prediction)|0|
|[Batch-Mix Negative Sampling for Learning Recommendation Retrievers](https://doi.org/10.1145/3583780.3614789)|Yongfu Fan, Jin Chen, Yongquan Jiang, Defu Lian, Fangda Guo, Kai Zheng|University of Science and Technology of China, Hefei, China; Southwest Jiaotong University, Chengdu, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; University of Electronic Science and Technology of China, Chengdu, China|Recommendation retrievers commonly retrieve user potentially preferred items from numerous items, where the query and item representation are learned according to the dual encoders with the log-softmax loss. Under real scenarios, the number of items becomes considerably large, making it exceedingly difficult to calculate the partition function with the whole item corpus. Negative sampling, which samples a subset from the item corpus, is widely used to accelerate the model training. Among different samplers, the in-batch sampling is commonly adopted for online recommendation retrievers, which regards the other items within the mini-batch as the negative samples for the given query, owing to its time and memory efficiency. However, the sample selection bias occurs due to the skewed feedback, harming the retrieval quality. In this paper, we propose a negative sampling approach named Batch-Mix Negative Sampling (BMNS), which adopts batch mixing operation to generate additional negatives for model training. Concretely, BMNS first generates new negative items with the sampled mix coefficient from the Beta distribution, after which a tailored correct strategy guided by frequency is designed to match the sampled softmax loss. In this way, the effort of re-encoding items out of the mini-batch is reduced while also improving the representation space of the negative set. The empirical experiments on four real-world datasets demonstrate BMNS is superior to the competitive negative inbatch sampling method.|推荐检索器通常从许多项目中检索用户潜在首选项，其中根据带有 log-softmax 损失的双编码器学习查询和项表示。在实际情况下，条目的数量会变得相当大，这使得用整个条目语料库计算配分函数变得非常困难。负抽样是从项目语料库中抽取子集，广泛用于加速模型训练。在不同的抽样方法中，在线推荐检索通常采用批内抽样，由于时间和内存效率的原因，将小批内的其他项目作为给定查询的否定样本。然而，样本选择偏差的产生是由于反馈的偏差，影响了检索质量。本文提出了一种负抽样方法——批量混合负抽样(BMNS) ，该方法采用批量混合操作产生附加负数，用于模型训练。具体来说，BMNS 首先根据采样的混合系数生成新的负项，然后根据频率设计一个量身定制的正确策略，以匹配采样的软最大损失(softmax loss) Β分布。这样，既减少了从小批处理中重新编码项的工作量，又提高了负集的表示空间。在四个实际数据集上的实验表明，BMNS 方法优于竞争性负内批抽样方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Batch-Mix+Negative+Sampling+for+Learning+Recommendation+Retrievers)|0|
|[Dynamic Embedding Size Search with Minimum Regret for Streaming Recommender System](https://doi.org/10.1145/3583780.3615135)|Bowei He, Xu He, Renrui Zhang, Yingxue Zhang, Ruiming Tang, Chen Ma|The Chinese University of Hong Kong, Hong Kong, Hong Kong; City University of Hong Kong, Hong Kong, Hong Kong; Huawei Noah's Ark Lab Montreal, Montreal, PQ, Canada; Huawei Noah's Ark Lab, Shenzhen, China|With the continuous increase of users and items, conventional recommender systems trained on static datasets can hardly adapt to changing environments. The high-throughput data requires the model to be updated in a timely manner for capturing the user interest dynamics, which leads to the emergence of streaming recommender systems. Due to the prevalence of deep learning-based recommender systems, the embedding layer is widely adopted to represent the characteristics of users, items, and other features in low-dimensional vectors. However, it has been proved that setting an identical and static embedding size is sub-optimal in terms of recommendation performance and memory cost, especially for streaming recommendations. To tackle this problem, we first rethink the streaming model update process and model the dynamic embedding size search as a bandit problem. Then, we analyze and quantify the factors that influence the optimal embedding sizes from the statistics perspective. Based on this, we propose the \textbf{D}ynamic \textbf{E}mbedding \textbf{S}ize \textbf{S}earch (\textbf{DESS}) method to minimize the embedding size selection regret on both user and item sides in a non-stationary manner. Theoretically, we obtain a sublinear regret upper bound superior to previous methods. Empirical results across two recommendation tasks on four public datasets also demonstrate that our approach can achieve better streaming recommendation performance with lower memory cost and higher time efficiency.|随着用户和项目的不断增加，传统的基于静态数据集的推荐系统难以适应不断变化的环境。高吞吐量数据要求模型及时更新，以捕捉用户兴趣动态，从而导致流式推荐系统的出现。由于基于深度学习的推荐系统的普及，嵌入层被广泛采用来在低维向量中表示用户、项目等特征。然而，已经证明，设置一个相同的静态嵌入大小在推荐性能和内存成本方面是次优的，特别是对于流式推荐。为了解决这个问题，我们首先重新考虑了流模型更新过程，并将动态嵌入大小搜索模型建模为盗贼问题。然后，从统计学的角度对影响最优嵌入规模的因素进行了分析和量化。在此基础上，提出了一种动态 textbf { D }嵌入 textbf { E }嵌入 textbf { S } ize textbf { S } earch (textbf { DESS })方法，以非平稳方式最小化用户端和项目端的嵌入大小选择遗憾。从理论上，我们得到了一个次线性后悔上界优于以往的方法。对四个公共数据集的两个推荐任务的实验结果也表明，该方法能够以较低的内存开销和较高的时间效率获得较好的流推荐性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamic+Embedding+Size+Search+with+Minimum+Regret+for+Streaming+Recommender+System)|0|
|[Text Matching Improves Sequential Recommendation by Reducing Popularity Biases](https://doi.org/10.1145/3583780.3615077)|Zhenghao Liu, Sen Mei, Chenyan Xiong, Xiaohua Li, Shi Yu, Zhiyuan Liu, Yu Gu, Ge Yu|Northeastern University, Shenyang, China; Carnegie Mellon University, Pittsburgh, PA, USA; Tsinghua University, Beijing, China|This paper proposes Text mAtching based SequenTial rEcommendation model (TASTE), which maps items and users in an embedding space and recommends items by matching their text representations. TASTE verbalizes items and user-item interactions using identifiers and attributes of items. To better characterize user behaviors, TASTE additionally proposes an attention sparsity method, which enables TASTE to model longer user-item interactions by reducing the self-attention computations during encoding. Our experiments show that TASTE outperforms the state-of-the-art methods on widely used sequential recommendation datasets. TASTE alleviates the cold start problem by representing long-tail items using full-text modeling and bringing the benefits of pretrained language models to recommendation systems. Our further analyses illustrate that TASTE significantly improves the recommendation accuracy by reducing the popularity bias of previous item id based recommendation models and returning more appropriate and text-relevant items to satisfy users. All codes are available at https://github.com/OpenMatch/TASTE.|提出了一种基于文本匹配的序列推荐模型(TASTE) ，该模型将项目和用户映射到嵌入空间中，通过匹配项目的文本表示来推荐项目。TASTE 使用项目的标识符和属性语言化项目和用户-项目交互。为了更好地描述用户行为，TASTE 还提出了一种注意稀疏方法，该方法通过减少编码过程中的自我注意计算，使 TASTE 能够模拟更长时间的用户-项目交互。我们的实验表明，在广泛使用的顺序推荐数据集上，TASTE 优于最先进的方法。TASTE 通过使用全文建模来表示长尾项目，并将预训练语言模型的优点带到推荐系统中，从而缓解了冷启动问题。我们进一步的分析表明，TASTE 通过减少以前基于项目 ID 的推荐模型的流行偏差和返回更合适的和文本相关的项目来满足用户，从而显著提高了推荐的准确性。所有密码都在 https://github.com/openmatch/taste。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Text+Matching+Improves+Sequential+Recommendation+by+Reducing+Popularity+Biases)|0|
|[Cracking the Code of Negative Transfer: A Cooperative Game Theoretic Approach for Cross-Domain Sequential Recommendation](https://doi.org/10.1145/3583780.3614828)|Chung Park, Taesan Kim, Taekyoon Choi, Junui Hong, Yelim Yu, Mincheol Cho, Kyunam Lee, Sungil Ryu, Hyungjun Yoon, Minsung Choi, Jaegul Choo|SK Telecom & Korea Advanced Institute of Science and Technology, Seoul & Daejeon, Republic of Korea; SK Telelcom & Korea Advanced Institute of Science and Technology, Seoul & Daejeon, Republic of Korea; SK Telelcom, Seoul, Republic of Korea; Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; NAVER, Seongnam, Republic of Korea|This paper investigates Cross-Domain Sequential Recommendation (CDSR), a promising method that uses information from multiple domains (more than three) to generate accurate and diverse recommendations, and takes into account the sequential nature of user interactions. The effectiveness of these systems often depends on the complex interplay among the multiple domains. In this dynamic landscape, the problem of negative transfer arises, where heterogeneous knowledge between dissimilar domains leads to performance degradation due to differences in user preferences across these domains. As a remedy, we propose a new CDSR framework that addresses the problem of negative transfer by assessing the extent of negative transfer from one domain to another and adaptively assigning low weight values to the corresponding prediction losses. To this end, the amount of negative transfer is estimated by measuring the marginal contribution of each domain to model performance based on a cooperative game theory. In addition, a hierarchical contrastive learning approach that incorporates information from the sequence of coarse-level categories into that of fine-level categories (e.g., item level) when implementing contrastive learning was developed to mitigate negative transfer. Despite the potentially low relevance between domains at the fine-level, there may be higher relevance at the category level due to its generalised and broader preferences. We show that our model is superior to prior works in terms of model performance on two real-world datasets across ten different domains.|本文研究了跨域序列推荐(CDSR) ，这是一种利用多个域(超过三个)的信息来生成准确和多样化推荐的有前途的方法，并考虑了用户交互的序列特性。这些系统的有效性往往取决于多个领域之间复杂的相互作用。在这种动态环境中，出现了负迁移问题，即不同领域之间的异质知识由于这些领域的用户偏好不同而导致性能下降。作为补救措施，我们提出了一个新的 CDSR 框架，通过评估从一个领域到另一个领域的负转移程度，并自适应地为相应的预测损失赋予低权值来解决负转移问题。为此，负向转移的数量是通过衡量每个领域对基于合作博弈理论的绩效模型的边际贡献来估计的。此外，在实施对比学习的过程中，还开发了一种分层对比学习方法，将粗级别类别的信息整合到细级别类别的信息中(例如，项目级别) ，以减轻负迁移。尽管在精细层面上各领域之间的相关性可能较低，但在类别层面上可能具有更高的相关性，因为它具有普遍性和更广泛的偏好。我们表明，我们的模型是优于以往的工作方面的两个真实世界的数据集在十个不同的领域的模型性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cracking+the+Code+of+Negative+Transfer:+A+Cooperative+Game+Theoretic+Approach+for+Cross-Domain+Sequential+Recommendation)|0|
|[Personalized Interest Sustainability Modeling for Sequential POI Recommendation](https://doi.org/10.1145/3583780.3615278)|Zewen Long, Liang Wang, Qiang Liu, Shu Wu|CRIPAC, MAIS, Institute of Automation, Chinese Academy of Sciences & University of Chinese Academy of Science, Beijing, China|Sequential point-of-interest (POI) recommendation endeavors to capture users' dynamic interests based on their historical check-ins, subsequently predicting the next POIs that they are most likely to visit.Existing methods conventionally capture users' personalized dynamic interests from their chronological sequences of visited POIs. However, these methods fail to explicitly consider personalized interest sustainability, which means whether each user's interest in specific POIs will sustain beyond the training time. In this work, we propose a personalized INterest Sustainability modeling framework for sequential POI REcommendation, INSPIRE for brevity. Different from existing methods that directly recommend next POIs through users' historical trajectories, our proposed INSPIRE focuses on users' personalized interest sustainability. Specifically, we first develop a new task to predict whether each user will visit the POIs in the recent period of the training time. Afterwards, to remedy the sparsity issue of users' check-in history, we propose to augment users' check-in history in three ways: geographical, intrinsic, and extrinsic schemes. Extensive experiments are conducted on two real-world datasets and results show that INSPIRE outperforms existing next POI solutions.|连续感兴趣点(POI)推荐努力根据用户的历史签入来捕获用户的动态兴趣，随后预测他们最有可能访问的下一个 POI。现有的方法通常从用户访问的 POI 的时间序列中获取用户的个性化动态兴趣。然而，这些方法没有明确考虑个性化兴趣的可持续性，这意味着每个用户对特定 POI 的兴趣是否会持续到培训时间之后。在这项工作中，我们提出了一个个性化的兴趣可持续性建模框架的顺序 POI 推荐，简短的 INSPIRE。与现有的通过用户历史轨迹直接推荐下一个 POI 的方法不同，我们提出的 INSPIRE 侧重于用户个性化兴趣的可持续性。具体来说，我们首先开发一个新的任务来预测每个用户是否会在最近的培训时间内访问 POI。然后，针对用户签入历史的稀疏性问题，提出了从地理方案、内部方案和外部方案三个方面增加用户签入历史的方法。在两个实际数据集上进行了广泛的实验，结果表明 INSPIRE 的性能优于现有的下一个 POI 解决方案。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Interest+Sustainability+Modeling+for+Sequential+POI+Recommendation)|0|
|[Differentiable Retrieval Augmentation via Generative Language Modeling for E-commerce Query Intent Classification](https://doi.org/10.1145/3583780.3615210)|Chenyu Zhao, Yunjiang Jiang, Yiming Qiu, Han Zhang, WenYun Yang|JD.com, Beijing, China|Retrieval augmentation, which enhances downstream models by a knowledge retriever and an external corpus instead of by merely increasing the number of model parameters, has been successfully applied to many natural language processing (NLP) tasks such as text classification, question answering and so on. However, existing methods that separately or asynchronously train the retriever and downstream model mainly due to the non-differentiability between the two parts, usually lead to degraded performance compared to end-to-end joint training.|检索增强技术通过知识检索器和外部语料库对下游模型进行增强，而不仅仅是增加模型参数，已经成功地应用于文本分类、问答等自然语言处理任务中。然而，现有的分别或异步训练检索器和下游模型的方法，主要是由于两部分之间的不可微性，通常导致性能下降相比，端到端联合训练。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Differentiable+Retrieval+Augmentation+via+Generative+Language+Modeling+for+E-commerce+Query+Intent+Classification)|0|
|[Enhancing E-commerce Product Search through Reinforcement Learning-Powered Query Reformulation](https://doi.org/10.1145/3583780.3615474)|Sanjay Agrawal, Srujana Merugu, Vivek Sembium|Amazon.com Inc., Bengaluru, India|Query reformulation (QR) is a widely used technique in web and product search. In QR, we map a poorly formed or low coverage user query to a few semantically similar queries that are rich in product coverage, thereby enabling effective targeted searches with less cognitive load on the user. Recent QR approaches based on generative language models are superior to informational retrieval-based methods but exhibit key limitations: (i) generated reformulations often have low lexical diversity and fail to retrieve a large set of relevant products of a wider variety, (ii) the training objective of generative models does not incorporate a our goal of improving product coverage. In this paper, we propose RLQR (Reinforcement Learning for Query Reformulations), for generating high quality diverse reformulations which aim to maximize the product coverage (number of distinct relevant products returned). We evaluate our approach against supervised generative models and strong RL-based methods. Our experiments demonstrate a 28.6% increase in product coverage compared to a standard generative model, outperforming SOTA benchmarks by a significant margin. We also conduct our experiments on an external Amazon shopping dataset and demonstrate increased product coverage over SOTA algorithms.|查询重构(QR)是一种广泛应用于网络和产品搜索的技术。在 QR 中，我们将一个形式不正确或覆盖率低的用户查询映射到几个语义相似的查询，这些查询具有丰富的产品覆盖率，从而使得有效的目标搜索能够减轻用户的认知负荷。最近基于生成语言模型的 QR 方法优于基于信息检索的方法，但表现出关键的局限性: (i)生成的重新编排通常具有较低的词汇多样性，并且不能检索更多种类的大量相关产品，(ii)生成模型的培训目标不包含我们提高产品覆盖率的目标。在本文中，我们提出了 RLQR (查询重构的强化学习) ，用于产生高质量的多样化重构，目的是最大化产品覆盖率(返回的不同相关产品的数量)。我们评估我们的方法对监督生成模型和强 RL 为基础的方法。我们的实验表明，与标准生成模型相比，产品覆盖率提高了28.6% ，远远超过 SOTA 基准。我们还在一个外部 Amazon 购物数据集上进行了实验，并证明了 SOTA 算法对产品覆盖率的提高。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+E-commerce+Product+Search+through+Reinforcement+Learning-Powered+Query+Reformulation)|0|
|[Multitask Ranking System for Immersive Feed and No More Clicks: A Case Study of Short-Form Video Recommendation](https://doi.org/10.1145/3583780.3615489)|Qingyun Liu, Zhe Zhao, Liang Liu, Zhen Zhang, Junjie Shan, Yuening Li, Shuchao Bi, Lichan Hong, Ed H. Chi|Google Inc, Mountain View, CA, USA; Google DeepMind, Mountain View, CA, USA|In recent years, social media users spend significant amount of time on Short-Form Video (SFV) platforms. Its success in creating an immersive viewership experience is not only from the content, but also due to its unique UI innovation: instead of providing choices for users to click, SFV platforms actively recommend content to users to watch one at a time. In this paper, we highlight unique challenges rooted from such UI changes for SFV recommendation system design. Firstly, there is yet much unexplored for sources of system biases under the new UI, as there are no clicks nor the common click-based position biases. Additionally, when training multiple types of user activities, positive labels for activities like sharing and commenting can be much sparser and more skewed than traditional click-based recommendation systems, as the latter can filter non-click impressions when generating "post-click" activities. To tackle these challenges, we introduce a unified multi-task ranking framework which puts two novel components all together into an overall system for SFV recommendation. First, we identify that there are position biases of SFVs in the recommendation sequence, namely "watch trail biases", and introduce biases correction using trail-related information. Second, to get the most benefits from multi-task learning, especially co-training tasks with extremely skewed and sparse labels, we adapt a disentangle regularization to mitigate task conflicts, introduce loss upweighting for sparse task co-training and adopt a meta-learning algorithm for efficient weight selection. We demonstrate the effectiveness and efficiency of the framework on one of today's largest SFV platforms. Our framework has been deployed to the production system for more than 6 months.|近年来，社交媒体用户在短视频(SFV)平台上花费了大量的时间。SFV 成功地创造了一种身临其境的观看体验，不仅仅是因为内容，还因为它独特的用户界面创新: SFV 平台没有为用户提供点击选择，而是积极地向用户推荐内容，让他们一次看一个。在本文中，我们强调了这种 UI 变化对 SFV 推荐系统设计的独特挑战。首先，由于没有点击，也没有常见的基于点击的位置偏差，因此在新 UI 下还有很多系统偏差的来源没有被探索。此外，在培训多种类型的用户活动时，分享和评论等活动的正面标签可能比传统的基于点击的推荐系统更稀疏和更倾斜，因为后者可以在生成“后点击”活动时过滤非点击印象。为了应对这些挑战，我们引入了一个统一的多任务排序框架，它将两个新的组件放在一起，形成一个全面的 SFV 推荐系统。首先，我们发现在推荐序列中存在着 SFV 的位置偏差，即“观察轨迹偏差”，并利用轨迹相关信息进行偏差校正。其次，为了从多任务协同学习中获得最大的效益，特别是极度倾斜和稀疏标签的协同训练任务，我们采用了一种解缠正则化来缓解任务冲突，引入了稀疏任务协同训练的损失加权，并采用了一种元学习算法来进行有效的权重选择。我们在当今最大的 SFV 平台之一上展示了该框架的有效性和效率。我们的框架已经部署到生产系统超过6个月了。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multitask+Ranking+System+for+Immersive+Feed+and+No+More+Clicks:+A+Case+Study+of+Short-Form+Video+Recommendation)|0|
|[RUEL: Retrieval-Augmented User Representation with Edge Browser Logs for Sequential Recommendation](https://doi.org/10.1145/3583780.3615498)|Ning Wu, Ming Gong, Linjun Shou, Jian Pei, Daxin Jiang|Microsoft STCA, Beijing, China; Duke University, Durham, NC, USA|Online recommender systems (RS) aim to match user needs with the vast amount of resources available on various platforms. A key challenge is to model user preferences accurately under the condition of data sparsity. To address this challenge, some methods have leveraged external user behavior data from multiple platforms to enrich user representation. However, all of these methods require a consistent user ID across platforms and ignore the information from similar users. In this study, we propose RUEL, a novel retrieval-based sequential recommender that can effectively incorporate external anonymous user behavior data from Edge browser logs to enhance recommendation. We first collect and preprocess a large volume of Edge browser logs over a one-year period and link them to target entities that correspond to candidate items in recommendation datasets. We then design a contrastive learning framework with a momentum encoder and a memory bank to retrieve the most relevant and diverse browsing sequences from the full browsing log based on the semantic similarity between user representations. After retrieval, we apply an item-level attentive selector to filter out noisy items and generate refined sequence embeddings for the final predictor. RUEL is the first method that connects user browsing data with typical recommendation datasets and can be generalized to various recommendation scenarios and datasets. We conduct extensive experiments on four real datasets for sequential recommendation tasks and demonstrate that RUEL significantly outperforms state-of-the-art baselines. We also conduct ablation studies and qualitative analysis to validate the effectiveness of each component of RUEL and provide additional insights into our method.|在线推荐系统(RS)旨在将用户的需求与各种平台上可用的大量资源相匹配。在数据稀疏的情况下，准确地建立用户偏好模型是一个关键的挑战。为了解决这个问题，一些方法利用来自多个平台的外部用户行为数据来丰富用户表示。但是，所有这些方法都需要跨平台的一致用户 ID，并忽略来自相似用户的信息。在这项研究中，我们提出了一种新的基于检索的顺序推荐系统 RUEL，它可以有效地合并来自边缘浏览器日志的外部匿名用户行为数据来增强推荐系统。我们首先在一年的时间内收集和预处理大量的 Edge 浏览器日志，并将它们链接到与推荐数据集中的候选项对应的目标实体。然后基于用户表示的语义相似性，设计了一个带有动量编码器和记忆库的对比学习框架，从完整的浏览日志中检索出最相关、最多样的浏览序列。检索后，应用项级注意选择器滤除噪声项，并为最终的预测器生成精化序列嵌入。RUEL 是第一种将用户浏览数据与典型的推荐数据集连接起来的方法，可以推广到各种推荐场景和数据集。我们在四个实际数据集上对顺序推荐任务进行了广泛的实验，并证明 RUEL 显著优于最先进的基线。我们还进行了消融研究和定性分析，以验证 RUEL 的每个组成部分的有效性，并提供额外的见解，我们的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RUEL:+Retrieval-Augmented+User+Representation+with+Edge+Browser+Logs+for+Sequential+Recommendation)|0|
|[Towards Effective Modeling and Exploitation of Search and User Context in Conversational Information Retrieval](https://doi.org/10.1145/3583780.3616005)|Praveen Acharya|Dublin City University, Dublin, Ireland|Conversational information retrieval has garnered considerable attention in recent years. A major challenge in conversational search is formulating the most effective query during the dialogue between the searcher and the conversational agent. Unlike traditional information retrieval systems that assume users can independently create queries, conversational settings allow agents to assist users in query formulation. This alleviates the burden on users by leveraging the multi-turn nature of the conversation to aid them in reaching their information goals. Conversational context plays a vital role in the query process. In this work, we focus on understanding and leveraging conversational context from two dimensions: conversational history and knowledge history. The goal is to identify and model the relevant portions from the search dialogue and the knowledge history and to use this within the search process to improve the overall performance of conversational information retrieval systems.|近年来，会话信息检索引起了相当大的关注。会话搜索的一个主要挑战是在搜索者和会话代理人之间的对话中提出最有效的查询。与传统的信息检索系统假设用户可以独立创建查询不同，会话设置允许代理协助用户制定查询。这样可以减轻用户的负担，因为可以利用对话的多回合特性来帮助他们实现信息目标。会话上下文在查询过程中起着至关重要的作用。在这项工作中，我们侧重于从两个维度理解和利用会话语境: 会话历史和知识历史。我们的目标是从搜索对话和知识历史中识别和建模相关部分，并在搜索过程中使用这些来提高会话信息检索系统的整体性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Effective+Modeling+and+Exploitation+of+Search+and+User+Context+in+Conversational+Information+Retrieval)|0|
|[CPMR: Context-Aware Incremental Sequential Recommendation with Pseudo-Multi-Task Learning](https://doi.org/10.1145/3583780.3615512)|Qingtian Bian, Jiaxing Xu, Hui Fang, Yiping Ke|Shanghai University of Finance and Economics, Shanghai, China; Nanyang Technological University, Singapore, Singapore|The motivations of users to make interactions can be divided into static preference and dynamic interest. To accurately model user representations over time, recent studies in sequential recommendation utilize information propagation and evolution to mine from batches of arriving interactions. However, they ignore the fact that people are easily influenced by the recent actions of other users in the contextual scenario, and applying evolution across all historical interactions dilutes the importance of recent ones, thus failing to model the evolution of dynamic interest accurately. To address this issue, we propose a Context-Aware Pseudo-Multi-Task Recommender System (CPMR) to model the evolution in both historical and contextual scenarios by creating three representations for each user and item under different dynamics: static embedding, historical temporal states, and contextual temporal states. To dually improve the performance of temporal states evolution and incremental recommendation, we design a Pseudo-Multi-Task Learning (PMTL) paradigm by stacking the incremental single-target recommendations into one multi-target task for joint optimization. Within the PMTL paradigm, CPMR employs a shared-bottom network to conduct the evolution of temporal states across historical and contextual scenarios, as well as the fusion of them at the user-item level. In addition, CPMR incorporates one real tower for incremental predictions, and two pseudo towers dedicated to updating the respective temporal states based on new batches of interactions. Experimental results on four benchmark recommendation datasets show that CPMR consistently outperforms state-of-the-art baselines and achieves significant gains on three of them. The code is available at: https://github.com/DiMarzioBian/CPMR.|用户进行交互的动机可以分为静态偏好和动态兴趣。为了随时间精确地建立用户表示模型，最近在顺序推荐方面的研究利用信息传播和进化从到达的交互批次中挖掘信息。然而，他们忽略了这样一个事实，即人们很容易受到其他用户最近在上下文场景中的行为的影响，并且在所有的历史交互中应用进化会削弱最近交互的重要性，从而无法精确地模拟动态兴趣的进化。为了解决这个问题，我们提出了一个上下文感知的伪多任务推荐系统(Context-Aware Pseudo-multi-Task) ，通过在不同的动态下为每个用户和项目创建三种表示(静态嵌入、历史时间状态和上下文时间状态)来模拟历史和上下文场景中的演化。为了同时提高时间状态演化和增量推荐的性能，我们设计了一个伪多任务学习(PMTL)范式，将增量的单目标推荐叠加到一个多目标任务中进行联合优化。在 PMTL 范式中，CPMR 使用一个共享底层网络来跨越历史和上下文场景进行时间状态的演化，以及在用户项目级别进行时间状态的融合。此外，CPMR 还包括一个用于增量预测的实际塔，以及两个用于根据新批量的相互作用更新各自的时间状态的伪塔。对四个基准推荐数据集的实验结果表明，CPMR 的性能始终优于最先进的基准，并在其中三个基准上取得了显著的增益。密码可于以下 https://github.com/dimarziobian/cpmr 索取:。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CPMR:+Context-Aware+Incremental+Sequential+Recommendation+with+Pseudo-Multi-Task+Learning)|0|
|[Leveraging Post-Click User Behaviors for Calibrated Conversion Rate Prediction Under Delayed Feedback in Online Advertising](https://doi.org/10.1145/3583780.3615161)|Yuyao Guo, Xiang Ao, Qiming Liu, Qing He|Institute of Computing Technology, Chinese Academy of Sciences & University of Chinese Academy of Sciences, Beijing, China|Obtaining accurately calibrated conversion rate predictions is essential for the bidding and ranking process in online advertising systems. Nevertheless, the inherent latency between clicks and conversions leads to delayed feedback, which may introduce bias into the prediction models. Compared to indefinitely long conversion delays, post-click user behaviors manifest within a relatively brief time and have been empirically validated to exert a favorable influence on the precision of conversion rate estimates. In light of this, we propose a novel approach that leverages post-click user behaviors to calibrate conversion rate predictions. Specifically, we treat user behaviors as predictable targets to improve accuracy and enhance timeliness. An adaptive loss function based on task uncertainty is employed for multi-task learning. To further reduce calibration error, we integrate the modified prediction model with a parameterized scaling technique. Experiments conducted on two real-world datasets demonstrate that our proposed method outperforms existing models in providing more calibrated predictions.|获得准确校准的转换率预测是必不可少的投标和排名过程中的在线广告系统。然而，点击和转换之间的内在延迟会导致延迟反馈，这可能会给预测模型带来偏差。与无限长的转换延迟相比，点击后的用户行为在相对较短的时间内表现出来，并且已经被经验验证对转换率估计的精度产生了有利的影响。鉴于此，我们提出了一种新的方法，利用点击后的用户行为来校准转换率预测。具体来说，我们将用户行为视为可预测的目标，以提高准确性和及时性。采用基于任务不确定性的自适应损失函数进行多任务学习。为了进一步减小校准误差，我们将改进的预测模型与参数化标度技术相结合。在两个真实世界数据集上进行的实验表明，我们提出的方法在提供更精确的预测方面优于现有的模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Post-Click+User+Behaviors+for+Calibrated+Conversion+Rate+Prediction+Under+Delayed+Feedback+in+Online+Advertising)|0|
|[DAE: Distribution-Aware Embedding for Numerical Features in Click-Through Rate Prediction](https://doi.org/10.1145/3583780.3615212)|Bin Shen, Jingran Xu, Xu Min, Zeyu Ke, Yong He, Liang Zhang, Xin Dong, Linjian Mo|Ant Group, Hangzhou, China; Antgroup, Hangzhou, China|Numerical features are an important type of input for CTR prediction models. Recently, several discretization and numerical transformation methods have been proposed to deal with numerical features. However, existing approaches do not fully consider compatibility with different distributions. Here, we propose a novel numerical feature embedding framework, called Distribution-Aware Embedding (DAE), which is applicable to various numerical feature distributions. First, DAE efficiently approximates the cumulative distribution function by estimating the expectation of the order statistics. Then, the distribution information is applied to the embedding layer by nonlinear interpolation. Finally, to capture both local and global information, we aggregate the embeddings at multiple scales to obtain the final representation. Empirical results validate the effectiveness of DAE compared to the baselines, while demonstrating the adaptability to different CTR models and distributions.|数值特征是 CTR 预测模型的重要输入类型。近年来，人们提出了几种离散化和数值变换方法来处理数值特征。但是，现有的方法并不完全考虑与不同发行版的兼容性。在这里，我们提出了一种新的数值特征嵌入框架，称为分布感知嵌入(DAE) ，它适用于各种数值特征分布。首先，DAE 通过估计订单统计数据的期望值来有效地逼近累积分布函数。然后，通过非线性插值将分布信息应用到嵌入层。最后，为了同时捕获局部和全局信息，我们在多个尺度上聚合嵌入信息以获得最终的表示。实证结果验证了 DAE 与基线相比的有效性，同时证明了 DAE 对不同 CTR 模型和分布的适应性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DAE:+Distribution-Aware+Embedding+for+Numerical+Features+in+Click-Through+Rate+Prediction)|0|
|[Unified Generative & Dense Retrieval for Query Rewriting in Sponsored Search](https://doi.org/10.1145/3583780.3615459)|Akash Kumar Mohankumar, Bhargav Dodla, Gururaj K, Amit Singh|New York University; Fudan University|Named Entity Recognition (NER) is the task of identifying spans that represent entities in sentences. Whether the entity spans are nested or discontinuous, the NER task can be categorized into the flat NER, nested NER, and discontinuous NER subtasks. These subtasks have been mainly solved by the token-level sequence labelling or span-level classification. However, these solutions can hardly tackle the three kinds of NER subtasks concurrently. To that end, we propose to formulate the NER subtasks as an entity span sequence generation task, which can be solved by a unified sequence-to-sequence (Seq2Seq) framework. Based on our unified framework, we can leverage the pre-trained Seq2Seq model to solve all three kinds of NER subtasks without the special design of the tagging schema or ways to enumerate spans. We exploit three types of entity representations to linearize entities into a sequence. Our proposed framework is easy-to-implement and achieves state-of-the-art (SoTA) or near SoTA performance on eight English NER datasets, including two flat NER datasets, three nested NER datasets, and three discontinuous NER datasets.|命名实体识别(NER)是识别句子中表示实体的跨度的任务。无论实体跨度是嵌套的还是不连续的，NER 任务都可以分为平面的 NER、嵌套的 NER 和不连续的 NER 子任务。这些子任务主要通过令牌级序列标记或跨级分类来解决。然而，这些解决方案很难同时处理三种 NER 子任务。为此，我们提出将 NER 子任务表示为一个实体跨度序列生成任务，该任务可以通过一个统一的序列到序列(Seq2Seq)框架来解决。基于我们的统一框架，我们可以利用预先训练的 Seq2Seq 模型来解决所有三种 NER 子任务，而不需要特别设计标记模式或枚举范围的方法。我们利用三种类型的实体表示将实体线性化为一个序列。我们提出的框架易于实现，并在八个英文 NER 数据集上实现了最先进的(SoTA)或接近 SoTA 的性能，包括两个平面 NER 数据集，三个嵌套的 NER 数据集和三个不连续的 NER 数据集。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unified+Generative+&+Dense+Retrieval+for+Query+Rewriting+in+Sponsored+Search)|0|
|[SPM: Structured Pretraining and Matching Architectures for Relevance Modeling in Meituan Search](https://doi.org/10.1145/3583780.3615500)|Wen Zan, Yaopeng Han, Xiaotian Jiang, Yao Xiao, Yang Yang, Dayao Chen, Sheng Chen|Meituan Inc., Beijing, China|In e-commerce search, relevance between query and documents is an essential requirement for satisfying user experience. Different from traditional e-commerce platforms that offer products, users search on life service platforms such as Meituan mainly for product providers, which usually have abundant structured information, e.g. name, address, category, thousands of products. Modeling search relevance with these rich structured contents is challenging due to the following issues: (1) there is language distribution discrepancy among different fields of structured document, making it difficult to directly adopt off-the-shelf pretrained language model based methods like BERT. (2) different fields usually have different importance and their length vary greatly, making it difficult to extract document information helpful for relevance matching. To tackle these issues, in this paper we propose a novel two-stage pretraining and matching architecture for relevance matching with rich structured documents. At pretraining stage, we propose an effective pretraining method that employs both query and multiple fields of document as inputs, including an effective information compression method for lengthy fields. At relevance matching stage, a novel matching method is proposed by leveraging domain knowledge in search query to generate more effective document representations for relevance scoring. Extensive offline experiments and online A/B tests on millions of users verify that the proposed architectures effectively improve the performance of relevance modeling. The model has already been deployed online, serving the search traffic of Meituan for over a year.|在电子商务搜索中，查询与文档之间的相关性是满足用户体验的基本要求。与提供产品的传统电子商务平台不同，用户在生活服务平台(例如主要为产品供应商提供的美团)上进行搜索，这些平台通常有大量的结构化信息，例如名称、地址、类别、数以千计的产品。用这些丰富的结构化内容来建立搜索相关性具有挑战性，这是由于以下问题: (1)不同领域的结构性文件之间存在语言分布差异，使得很难直接采用现成的基于语言模型的方法，比如 BERT。(2)不同领域的重要性不同，领域长度差异较大，难以提取有助于相关匹配的文档信息。为了解决这些问题，本文提出了一种新的两阶段预训练和匹配体系结构，用于富结构化文档的相关性匹配。在预训练阶段，我们提出了一种有效的预训练方法，该方法同时使用文档的查询和多个字段作为输入，包括一种有效的长字段信息压缩方法。在相关匹配阶段，利用搜索查询中的领域知识，提出了一种新的匹配方法，为相关评分生成更有效的文档表示。大量的离线实验和对数百万用户的在线 A/B 测试验证了所提出的体系结构有效地提高了相关建模的性能。该模型已经在网上部署，为美团的搜索流量服务了一年多。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SPM:+Structured+Pretraining+and+Matching+Architectures+for+Relevance+Modeling+in+Meituan+Search)|0|
|[Towards Filling the Gap in Conversational Search: From Passage Retrieval to Conversational Response Generation](https://doi.org/10.1145/3583780.3615132)|Weronika Lajewska, Krisztian Balog|University of Stavanger, Stavanger, Norway|Research on conversational search has so far mostly focused on query rewriting and multi-stage passage retrieval. However, synthesizing the top retrieved passages into a complete, relevant, and concise response is still an open challenge. Having snippet-level annotations of relevant passages would enable both (1) the training of response generation models that are able to ground answers in actual statements and (2) the automatic evaluation of the generated responses in terms of completeness. In this paper, we address the problem of collecting high-quality snippet-level answer annotations for two of the TREC Conversational Assistance track datasets. To ensure quality, we first perform a preliminary annotation study, employing different task designs, crowdsourcing platforms, and workers with different qualifications. Based on the outcomes of this study, we refine our annotation protocol before proceeding with the full-scale data collection. Overall, we gather annotations for 1.8k question-paragraph pairs, each annotated by three independent crowd workers. The process of collecting data at this magnitude also led to multiple insights about the problem that can inform the design of future response-generation methods. This is an extended version of the article published with the same title in the Proceedings of CIKM'23.|会话搜索的研究目前主要集中在查询重写和多阶段文章检索两个方面。然而，将检索到的顶级段落综合成一个完整的、相关的、简洁的回应仍然是一个公开的挑战。对相关段落进行片段级注释，可以(1)训练能够在实际语句中找到答案的响应生成模型，(2)根据完整性自动评估生成的响应。在本文中，我们解决了为两个 TREC 会话辅助跟踪数据集收集高质量片段级答案注释的问题。为了保证质量，我们首先进行了初步的注释研究，采用了不同的任务设计，众包平台，以及不同资历的工人。基于本研究的结果，我们在进行全面的数据收集之前优化了我们的注释协议。总的来说，我们收集了1.8 k 问题-段落对的注释，每个注释由三个独立的人群工作者。在这种规模上收集数据的过程也导致了对这个问题的多种认识，这些认识可以为设计未来的响应生成方法提供信息。这是一个扩展版本的文章与同一标题发表在 CIKM’23会议记录。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Filling+the+Gap+in+Conversational+Search:+From+Passage+Retrieval+to+Conversational+Response+Generation)|0|
|[IUI: Intent-Enhanced User Interest Modeling for Click-Through Rate Prediction](https://doi.org/10.1145/3583780.3614939)|Mao Pan, Tao Yu, Kun Zhou, Zheng Li, Dongyue Wang, Zhuoye Ding, Xiwei Zhao, Sulong Xu|JD.com, Inc., Beijing, China|Click-Through Rate (CTR) prediction is becoming increasingly vital in many industrial applications, such as recommendations and online advertising. How to precisely capture users' dynamic and evolving interests from previous interactions (e.g., clicks, purchases, etc.) is a challenging task in CTR prediction. Mainstream approaches focus on disentangling user interests in a heuristic way or modeling user interests into a static representation. However, these approaches overlook the importance of users' current intent and the complex interactions between their current intent and global interests. To address these concerns, in this paper, we propose a novel intent-enhanced user interest modeling for click-through rate prediction in large-scale e-commerce recommendations, abbreviated as IUI. Methodologically, different from existing works, we consider users' recent interactions to be inspired by their implicit intent and then leverage an intent-aware network to model their current local interests in a more precise and fine-grained manner. In addition, to obtain a more stable co-dependent global and local interest representation, we employ a co-attention network capable of activating the corresponding interest in global-level interactions and capturing the dynamic interactions between global- and local-level interaction behaviors. Finally, we incorporate self-supervised learning into the model training by maximizing the mutual information between the global and local representations obtained via the above two networks to enhance the CTR prediction performance. Compared with existing methods, IUI benefits from the different granularity of user interest to generate a more accurate and comprehensive preference representation. Experimental results demonstrate that the proposed model outperforms previous state-of-the-art methods in various metrics on three real-world datasets. In addition, an online A/B test deployed on the JD recommendation platforms shows a promising improvement across multiple evaluation metrics.|在诸如推荐和在线广告等许多工业应用中，点进率预测(ctrl)正变得越来越重要。如何从以前的交互(例如点击、购买等)中准确捕捉用户的动态和不断变化的兴趣是 CTR 预测中的一个具有挑战性的任务。主流方法侧重于以启发式方式分离用户兴趣，或者将用户兴趣建模为静态表示。然而，这些方法忽略了用户当前意图的重要性，以及用户当前意图与全局兴趣之间的复杂交互。为了解决这些问题，在本文中，我们提出了一种新的意图增强的用户兴趣模型，用于大规模电子商务推荐中的点进率预测，简称为 IUI。在方法论上，与现有的作品不同，我们认为用户最近的互动是受到他们的隐含意图的启发，然后利用意图感知网络，以更精确和细粒度的方式建模他们当前的本地兴趣。此外，为了获得更稳定的相互依赖的全局和局部兴趣表示，我们采用了能够激活全局层面相互作用中的相应兴趣并捕获全局和局部层面相互作用行为之间的动态相互作用的共注意网络。最后，将自监督学习算法引入模型训练中，通过最大化两个网络所获得的全局和局部表示之间的互信息来提高 CTR 预测性能。与现有的方法相比，IUI 受益于不同粒度的用户兴趣，以生成更准确和全面的偏好表示。实验结果表明，该模型在三个实际数据集的各种度量指标上优于先前的最新方法。此外，部署在 JD 推荐平台上的在线 A/B 测试显示了跨多个评估指标的有希望的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=IUI:+Intent-Enhanced+User+Interest+Modeling+for+Click-Through+Rate+Prediction)|0|
|[TPUF: Enhancing Cross-domain Sequential Recommendation via Transferring Pre-trained User Features](https://doi.org/10.1145/3583780.3615094)|Yujia Ding, Huan Li, Ke Chen, Lidan Shou|Zhejiang University, Hangzhou, China|Sequential recommendation has long been challenged by data sparsity issues. Most recently, cross-domain sequential recommendation (CDSR) techniques have been proposed to leverage sequential interaction data from other domains. However, accessing raw data from source domains is often restricted due to privacy concerns. To tackle this issue, we introduce TPUF, a novel CDSR model that transfers pre-trained latent user features from the source domain (UFS) instead of the original interaction data. By doing so, TPUF improves recommendation effectiveness while maintaining practicality. TPUF has three functional characteristics: (1) It is a feature mapping-and-aggregation framework that does not impose specific constraints on the nature of pre-trained UFS. (2) It incorporates a temporal feature mapping unit to effectively extract domain-shared information from UFS with temporal information recovered. (3) It additionally employs an adversarial feature alignment unit to align features across domains to combat feature transfer bias. Experimental results on real-world datasets demonstrate that TPUF outperforms other state-of-the-art cross-domain recommendation models and is compatible with multiple UFS types.|长期以来，连续推荐一直受到数据稀疏问题的挑战。最近，跨域顺序推荐(CDSR)技术被提出来利用来自其他域的顺序交互数据。然而，从源域访问原始数据通常由于隐私问题而受到限制。为了解决这个问题，我们引入了 TPUF，一种新的 CDSR 模型，它从源域(UFS)传输预先训练好的潜在用户特征，而不是传输原始的交互数据。通过这样做，TPUF 在保持实用性的同时提高了推荐的有效性。TPUF 具有三个功能特征: (1)它是一个特征映射和聚合框架，不对预先训练的 UFS 的性质施加特定的限制。(2)结合时态特征映射单元，有效地提取 UFS 中的域共享信息，并恢复时态信息。(3)采用对抗性特征对齐单元对特征进行跨域对齐，以对抗特征迁移偏差。在实际数据集上的实验结果表明，TPUF 的性能优于其他最先进的跨域推荐模型，并且可以兼容多种 UFS 类型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TPUF:+Enhancing+Cross-domain+Sequential+Recommendation+via+Transferring+Pre-trained+User+Features)|0|
|[Zero-shot Item-based Recommendation via Multi-task Product Knowledge Graph Pre-Training](https://doi.org/10.1145/3583780.3615110)|Ziwei Fan, Zhiwei Liu, Shelby Heinecke, Jianguo Zhang, Huan Wang, Caiming Xiong, Philip S. Yu|University of Illinois Chicago, Chicago, IL, USA; Salesforce AI Research, Palo Alto, CA, USA|Existing recommender systems face difficulties with zero-shot items, i.e. items that have no historical interactions with users during the training stage. Though recent works extract universal item representation via pre-trained language models (PLMs), they ignore the crucial item relationships. This paper presents a novel paradigm for the Zero-Shot Item-based Recommendation (ZSIR) task, which pre-trains a model on product knowledge graph (PKG) to refine the item features from PLMs. We identify three challenges for pre-training PKG, which are multi-type relations in PKG, semantic divergence between item generic information and relations and domain discrepancy from PKG to downstream ZSIR task. We address the challenges by proposing four pre-training tasks and novel task-oriented adaptation (ToA) layers. Moreover, this paper discusses how to fine-tune the model on new recommendation task such that the ToA layers are adapted to ZSIR task. Comprehensive experiments on 18 markets dataset are conducted to verify the effectiveness of the proposed model in both knowledge prediction and ZSIR task.|现有的推荐系统面临着“零拍摄”项目的困难，也就是说，这些项目在培训阶段与用户没有历史性的交互。近年来的研究虽然通过预训练语言模型(PLM)提取通用项表示，但忽视了关键项之间的关系。提出了一种新的基于零拍项目推荐(ZSIR)任务的实现方法，该方法通过对产品知识图(PKG)模型进行预训练来提取 PLM 中的项目特征。我们确定了 PKG 训练前的三个挑战，即 PKG 中的多类型关系、项目类属信息和关系之间的语义分歧以及从 PKG 到下游 ZSIR 任务之间的领域差异。我们通过提出四个训练前任务和新的面向任务的适应(ToA)层来应对这些挑战。此外，本文还讨论了如何对新推荐任务模型进行微调，使 ToA 层适应 ZSIR 任务。通过对18个市场数据集的综合实验，验证了该模型在知识预测和 ZSIR 任务中的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Zero-shot+Item-based+Recommendation+via+Multi-task+Product+Knowledge+Graph+Pre-Training)|0|
|[A Generalized Propensity Learning Framework for Unbiased Post-Click Conversion Rate Estimation](https://doi.org/10.1145/3583780.3614760)|Yuqing Zhou, Tianshu Feng, Mingrui Liu, Ziwei Zhu|George Mason University, Fairfax, VA, USA|This paper addresses the critical gap in the unbiased estimation of post-click conversion rate (CVR) in recommender systems. Existing CVR prediction methods, such as Inverse Propensity Score (IPS) and various Doubly Robust (DR) based estimators, overlook the impact of propensity estimation on the model bias and variance, thus leading to a debiasing performance gap. We propose a Generalized Propensity Learning (GPL) framework to directly minimize the bias and variance in CVR prediction models. The proposed method works as a complement to existing methods like IPS, DR, MRDR, and DRMSE to improve prediction performance by reducing their bias and variance. Extensive experiments on real-world datasets and semi-synthetic datasets demonstrate the significant performance promotion brought by our proposed method. Data and code can be found at: https://github.com/yuqing-zhou/GPL.|本文研究了推荐系统中点击后转换率(CVR)无偏估计的关键缺陷。现有的 CVR 预测方法，如逆倾向评分(IPS)和各种基于双稳健(DR)的估计方法，忽视了倾向估计对模型偏差和方差的影响，从而导致性能差距的消除。我们提出了一个广义倾向学习(GPL)框架，直接最小化 CVR 预测模型的偏差和方差。该方法对现有的 IPS、 DR、 MRDR 和 DRMSE 等预测方法进行了补充，减少了它们的偏差和方差，提高了预测性能。在实际数据集和半合成数据集上进行的大量实验表明，该方法能够显著提高系统的性能。数据和代码可在以下 https://github.com/yuqing-zhou/gpl 找到:。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Generalized+Propensity+Learning+Framework+for+Unbiased+Post-Click+Conversion+Rate+Estimation)|0|
|[Satisfaction-Aware User Interest Network for Click-Through Rate Prediction](https://doi.org/10.1145/3583780.3615288)|Mao Pan, Wen Shi, Kun Zhou, Zheng Li, Dongyue Wang, Zhuoye Ding, Xiwei Zhao, Sulong Xu|JD.com, Inc., Beijing, China|Click-Through Rate (CTR) prediction plays a pivotal role in numerous industrial applications, including online advertising and recommender systems. Existing approaches primarily focus on modeling the correlation between user interests and candidate items. However, we argue that personalized user preferences for candidate items depend not only on correlation but also on the satisfaction of associated interests. To address this limitation, we propose SUIN, a novel CTR model that integrates satisfaction factors into user interest modeling for enhanced click-through rate prediction. Specifically, we employ a user interest satisfaction-aware network to capture the degree of satisfaction for each interest, thereby enabling adaptation of the user's personalized preference based on satisfaction levels. Additionally, we leverage the exposure-unclicked signal (recommended to the user but not clicked) as supervision during training, facilitating the interest satisfaction module to better model the satisfaction degree of user interests. Besides, this module serves as a foundational building block suitable for integration into mainstream sequential-based CTR models. Extensive experiments conducted on two real-world datasets demonstrate the superiority of our proposed model, outperforming state-of-the-art methods across various evaluation metrics. Furthermore, an online A/B test deployed on large-scale recommender systems shows significant improvements achieved by our model in diverse evaluation metrics.|在许多工业应用中，包括在线广告和推荐系统中，点进率(ctrl)预测起着关键的作用。现有的方法主要集中在建模用户兴趣和候选项之间的关系。然而，我们认为个性化用户对候选项的偏好不仅取决于相关性，而且还取决于相关兴趣的满意度。为了解决这一局限性，我们提出了 SUIN 模型，这是一种新型的点击率模型，它将满意度因素集成到用户兴趣模型中，以增强点进率预测。具体来说，我们使用一个感知用户兴趣满意度的网络来获取每个兴趣的满意度，从而能够根据满意度来适应用户的个性化偏好。此外，我们利用曝光-未点击信号(推荐给用户但未点击)作为培训期间的监督，促进兴趣满意度模块，以更好地模拟用户兴趣的满意度。此外，该模块作为一个基本的积木块，适合集成到主流的顺序为基础的 CTR 模型。在两个真实世界的数据集上进行的大量实验证明了我们提出的模型的优越性，在各种评估指标上优于最先进的方法。此外，部署在大型推荐系统上的在线 A/B 测试显示，我们的模型在不同的评估指标上取得了显著的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Satisfaction-Aware+User+Interest+Network+for+Click-Through+Rate+Prediction)|0|
|[Unsupervised Multi-Modal Representation Learning for High Quality Retrieval of Similar Products at E-commerce Scale](https://doi.org/10.1145/3583780.3615504)|Kushal Kumar, Tarik Arici, Tal Neiman, Jinyu Yang, Shioulin Sam, Yi Xu, Hakan Ferhatosmanoglu, Ismail B. Tutar|Amazon, Seattle, WA, USA; Amazon, New York, NY, USA|Identifying similar products in e-commerce is useful in discovering relationships between products, making recommendations, and increasing diversity in search results. Product representation learning is the first step to define a generalized product similarity metric for search. The second step is to extend similarity search to a large scale (e.g., e-commerce catalog scale) without sacrificing quality. In this work, we present a solution that interweaves both steps, i.e., learn representations suited to high quality retrieval using contrastive learning (CL) and retrieve similar items from a large search space using approximate nearest neighbor search (ANNS) to trade-off quality for speed. We propose a CL training strategy for learning uni-modal encoders suited to multi-modal similarity search for e-commerce. We study ANNS retrieval by generating Pareto Frontiers (PFs) without requiring labels. Our CL training strategy doubles retrieval@1 metric across categories (e.g., from 36% to 88% in category C). We also demonstrate that ANNS engine optimization using PFs help select configurations appropriately (e.g., we achieve 6.8× search speed with just 2% drop from the maximum retrieval accuracy in medium size datasets).|在电子商务中识别类似的产品有助于发现产品之间的关系，提出建议，并增加搜索结果的多样性。产品表示学习是定义用于搜索的广义产品相似度量的第一步。第二步是在不牺牲质量的情况下将最近邻搜索扩展到大规模(例如，电子商务目录规模)。在这项工作中，我们提出了一个解决方案，交织两个步骤，即，学习表示适合高质量的检索使用对比学习(CL)和检索相似的项目从一个大的搜索空间使用近似最近邻搜索(ANNS) ，以权衡质量的速度。我们建议采用 CL 培训策略，学习适用于电子商务多模态最近邻搜索的单模态编码器。我们通过生成不需要标签的帕累托前沿(PF)来研究 ANNS 检索。我们的 CL 训练策略将跨类别的检索@1指标加倍(例如，在 C 类中从36% 增加到88%)。我们还证明了使用 PF 的 ANNS 引擎优化有助于选择适当的配置(例如，我们实现了6.8倍的搜索速度，仅比中等大小数据集的最大检索精度下降2%)。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unsupervised+Multi-Modal+Representation+Learning+for+High+Quality+Retrieval+of+Similar+Products+at+E-commerce+Scale)|0|
|[Graph Exploration Matters: Improving both Individual-Level and System-Level Diversity in WeChat Feed Recommendation](https://doi.org/10.1145/3583780.3614688)|Shuai Yang, Lixin Zhang, Feng Xia, Leyu Lin|Tencent Inc., Beijing, China; Tencent Inc., Shenzhen, China|There are roughly three stages in real industrial recommendation systems, candidates generation (retrieval), ranking and reranking. Individual-level diversity and system-level diversity are both important for industrial recommender systems. The former focus on each single user's experience, while the latter focus on the difference among users. Graph-based retrieval strategies are inevitably hijacked by heavy users and popular items, leading to the convergence of candidates for users and the lack of system-level diversity. Meanwhile, in the reranking phase, Determinantal Point Process (DPP) is deployed to increase individual-level diverisity. Heavily relying on the semantic information of items, DPP suffers from clickbait and inaccurate attributes. Besides, most studies only focus on one of the two levels of diversity, and ignore the mutual influence among different stages in real recommender systems. We argue that individual-level diversity and system-level diversity should be viewed as an integrated problem, and we provide an efficient and deployable solution for web-scale recommenders. Generally, we propose to employ the retrieval graph information in diversity-based reranking, by which to weaken the hidden similarity of items exposed to users, and consequently gain more graph explorations to improve the system-level diveristy. Besides, we argue that users' propensity for diversity changes over time in content feed recommendation. Therefore, with the explored graph, we also propose to capture the user's real-time personalized propensity to the diversity. We implement and deploy the combined system in WeChat App's Top Stories used by hundreds of millions of users. Offline simulations and online A/B tests show our solution can effectively improve both user engagement and system revenue.|在实际的行业推荐系统中，大致有三个阶段: 候选人的生成(检索)、排名和重新排名。个体层次的多样性和系统层次的多样性对于工业推荐系统都很重要。前者关注每个用户的体验，而后者关注用户之间的差异。基于图的检索策略不可避免地会受到大量用户和热门项目的劫持，导致用户候选项的收敛和系统级多样性的缺乏。与此同时，在重新排名阶段，行列式点过程(DPP)被用来增加个人层面的多样性。民进党严重依赖项目语义信息，饱受点击率和不准确属性的困扰。此外，大多数研究只关注两个层次中的一个层次的多样性，而忽略了实际推荐系统中不同层次之间的相互影响。我们认为，个人层面的多样性和系统层面的多样性应该被视为一个综合的问题，我们提供了一个有效的和可部署的解决方案，网络规模的推荐。一般来说，我们建议在基于多样性的重新排序中使用检索图信息来削弱暴露给用户的项目的隐藏相似性，从而获得更多的图探索以提高系统级的多样性。此外，我们认为用户的多样性倾向随着时间的推移而变化。因此，通过对图形的研究，我们还提出了捕捉用户对多样性的实时个性化倾向。我们在微信应用程序的热门故事中实现并部署了这个组合系统，被数亿用户使用。离线模拟和在线 A/B 测试表明，我们的解决方案可以有效地提高用户参与度和系统收入。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Exploration+Matters:+Improving+both+Individual-Level+and+System-Level+Diversity+in+WeChat+Feed+Recommendation)|0|
|[Build Faster with Less: A Journey to Accelerate Sparse Model Building for Semantic Matching in Product Search](https://doi.org/10.1145/3583780.3614661)|Jiong Zhang, YauShian Wang, WeiCheng Chang, Wei Li, JyunYu Jiang, ChoJui Hsieh, HsiangFu Yu|UCLA, Los Angeles, CA, USA; Amazon, Palo Alto, CA, USA|The semantic matching problem in product search seeks to retrieve all semantically relevant products given a user query. Recent studies have shown that extreme multi-label classification~(XMC) model enjoys both low inference latency and high recall in real-world scenarios. These XMC semantic matching models adopt TF-IDF vectorizers to extract query text features and use mainly sparse matrices for the model weights. However, limited availability of libraries for efficient parallel sparse modules may lead to tediously long model building time when the problem scales to hundreds of millions of labels. This incurs significant hardware cost and renders the semantic model stale even before it is deployed. In this paper, we investigate and accelerate the model building procedures in a tree-based XMC model. On a real-world semantic matching task with 100M labels, our enhancements achieve over 10 times acceleration (from 3.1 days to 6.7 hours) while reducing hardware cost by 25%.|产品搜索中的语义匹配问题寻求检索给定用户查询的所有语义相关的产品。最近的研究表明，极端多标签分类 ~ (XMC)模型在现实场景中具有较低的推理延迟和较高的召回率。这些 XMC 语义匹配模型采用 TF-IDF 向量提取查询文本特征，模型权重以稀疏矩阵为主。然而，对于高效的并行稀疏模块来说，库的有限可用性可能导致当问题扩展到数亿个标签时，冗长的模型构建时间。这会带来巨大的硬件成本，甚至在部署语义模型之前，它就已经过时了。在本文中，我们研究并加速了一个基于树的 XMC 模型中的模型建立过程。在一个现实世界的语义匹配任务与100M 标签，我们的增强实现了10倍以上的加速(从3.1天到6.7小时) ，同时减少了25% 的硬件成本。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Build+Faster+with+Less:+A+Journey+to+Accelerate+Sparse+Model+Building+for+Semantic+Matching+in+Product+Search)|0|
|[Dual Interests-Aligned Graph Auto-Encoders for Cross-domain Recommendation in WeChat](https://doi.org/10.1145/3583780.3614676)|Jiawei Zheng, Hao Gu, Chonggang Song, Dandan Lin, Lingling Yi, Chuan Chen|WeChat, Tencent, Shenzhen, China|Recently, cross-domain recommendation (CDR) has been widely studied in both research and industry since it can alleviate a long-standing challenge of traditional recommendation methods, i.e., data sparsity issue, by transferring the information from a relatively richer domain (termed source domain) to a sparser domain (termed target domain). To our best knowledge, most (if not all) existing CDR methods focus on transferring either the similar content information or the user preferences embedding from the source domain to the target domain. However, they fail to improve the recommendation performance in real-world recommendation scenarios where the items in the source domain are totally different from those in the target domain in terms of attributes. To solve the above issues, we analyzed the historical interactions of users from different domains in the WeChat platform, and found that if two users have similar interests (interactions) in one domain, they are very likely to have similar interests in another domain even though the items of these two domains are totally different in terms of attributes. Based on this observation, in this paper, we propose a novel model named Dual Interests-Aligned Graph Auto-Encoders (DIAGAE) by utilizing the inter-domain interest alignment of users. Besides, our proposed model DIAGAE also leverages graph decoding objectives to align intra-domain user interests, which makes the representation of two users who have similar interests in a single domain closer. Comprehensive experimental results demonstrate that our model DIAGAE outperforms state-of-the-art methods on both public benchmark datasets and online A/B tests in WeChat live-stream recommendation scenario. Our model DIAGAE now serves the major online traffic in WeChat live-streaming recommendation scenario.|近年来，跨域推荐技术(CDR)在研究和工业界得到了广泛的研究，因为它可以通过将信息从相对丰富的域(称为源域)转移到较稀疏的域(称为目标域)来缓解传统推荐方法长期以来面临的挑战，即数据稀疏问题。据我们所知，大多数(如果不是全部的话)现有的 CDR 方法集中于将相似的内容信息或用户首选项从源域嵌入到目标域。但是，在源域中的条目在属性方面与目标域中的条目完全不同的现实推荐场景中，它们无法提高推荐性能。为了解决上述问题，我们分析了微信平台中不同领域用户的历史互动，发现如果两个用户在一个领域有相似的兴趣(互动) ，他们很可能在另一个领域有相似的兴趣，即使这两个领域的项目在属性方面完全不同。在此基础上，本文提出了一种利用用户域间兴趣对齐的双兴趣对齐图自动编码器(DIAGAE)模型。此外，我们提出的模型 DIAGAE 还利用图解码目标来调整域内用户的兴趣，使两个用户在一个单一的领域有相似的兴趣更接近的表示。综合实验结果表明，在微信实时流推荐场景中，我们的模型 DIAGAE 在公共基准数据集和在线 A/B 测试方面都优于最先进的方法。我们的模型 DIAGAE 现在服务于微信直播推荐场景中的主要在线流量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual+Interests-Aligned+Graph+Auto-Encoders+for+Cross-domain+Recommendation+in+WeChat)|0|
|[Self-supervised Contrastive Enhancement with Symmetric Few-shot Learning Towers for Cold-start News Recommendation](https://doi.org/10.1145/3583780.3615053)|Hao Jiang, Chuanzhen Li, Juanjuan Cai, Runyu Tian, Jingling Wang|Communication University of China, Beijing, China|Nowadays, news spreads faster than it is consumed. This, alongside the rapid news cycle and delayed updates, has led to a challenging news cold-start issue. Likewise, the user cold-start problem, due to limited user engagement, has long hindered recommendations. To tackle both of them, we introduce the Symmetric Few-shot Learning framework for Cold-start News Recommendation (SFCNR), built upon self-supervised contrastive enhancement. Our approach employs symmetric few-shot learning towers (SFTs) to transform warm user/news attributes into their behavior/content features during training. We design two innovative feature alignment strategies to enhance towers training. Subsequently, this tower generates virtual features for cold users/news during inference, leveraging tower-stored prior knowledge through a personalized gating network. We assess the SFCNR on four quality news recommendation models, conducting comprehensive experiments on two kinds of News dataset. Results showcase significant performance boosts for both warm and cold-start scenarios compared to baseline models.|如今，新闻的传播速度快于消费速度。这与快速的新闻周期和延迟更新一起，导致了一个具有挑战性的新闻冷启动问题。同样，由于用户参与有限，用户冷启动问题长期以来阻碍了推荐。为了解决这两个问题，我们引入了基于自监督对比增强的冷启动新闻推荐对称少镜头学习框架(SFCNR)。我们的方法使用对称的少镜头学习塔(SFT)来转换温暖的用户/新闻属性到他们的行为/内容特征在训练期间。我们设计了两个创新的特征对齐策略来加强塔训练。随后，该塔在推理过程中为冷用户/新闻生成虚拟特征，通过个性化门控网络利用塔存储的先验知识。我们在四种优质新闻推荐模型上对 SFCNR 进行了评估，并对两种新闻数据集进行了综合实验。结果显示，与基线模型相比，暖启动和冷启动方案的性能都有显著提高。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-supervised+Contrastive+Enhancement+with+Symmetric+Few-shot+Learning+Towers+for+Cold-start+News+Recommendation)|0|
|[Capturing Popularity Trends: A Simplistic Non-Personalized Approach for Enhanced Item Recommendation](https://doi.org/10.1145/3583780.3614801)|Jiazheng Jing, Yinan Zhang, Xin Zhou, Zhiqi Shen|Nanyang Technological University, Singapore, Singapore|Recommender systems have been gaining increasing research attention over the years. Most existing recommendation methods focus on capturing users' personalized preferences through historical user-item interactions, which may potentially violate user privacy. Additionally, these approaches often overlook the significance of the temporal fluctuation in item popularity that can sway users' decision-making. To bridge this gap, we propose Popularity-Aware Recommender (PARE), which makes non-personalized recommendations by predicting the items that will attain the highest popularity. PARE consists of four modules, each focusing on a different aspect: popularity history, temporal impact, periodic impact, and side information. Finally, an attention layer is leveraged to fuse the outputs of four modules. To our knowledge, this is the first work to explicitly model item popularity in recommendation systems. Extensive experiments show that PARE performs on par or even better than sophisticated state-of-the-art recommendation methods. Since PARE prioritizes item popularity over personalized user preferences, it can enhance existing recommendation methods as a complementary component. Our experiments demonstrate that integrating PARE with existing recommendation methods significantly surpasses the performance of standalone models, highlighting PARE's potential as a complement to existing recommendation methods. Furthermore, the simplicity of PARE makes it immensely practical for industrial applications and a valuable baseline for future research.|推荐系统近年来得到了越来越多的研究关注。现有的大多数推荐方法都是通过历史的用户-项目交互来获取用户的个性化偏好，这可能会侵犯用户的隐私。此外，这些方法往往忽略了项目流行度的时间波动的重要性，可以影响用户的决策。为了弥补这一差距，我们提出了流行感知推荐(PARE) ，它通过预测将获得最高流行度的项目来提供非个性化的推荐。PARE 由四个模块组成，每个模块关注一个不同的方面: 流行历史、时间影响、周期性影响和侧面信息。最后，利用注意层融合四个模块的输出。据我们所知，这是第一个在推荐系统中对项目流行性进行明确建模的工作。大量的实验表明，价格调整汇率的表现与最先进的复杂推荐方法相当，甚至更好。由于 PARE 优先考虑项目流行度而不是个性化的用户偏好，它可以增强现有的推荐方法作为一个补充组件。我们的实验表明，将价格调整汇率与现有的推荐方法相结合，显著地超过了独立模型的性能，突出了价格调整汇率作为现有推荐方法的补充的潜力。此外，价格调整汇率的简单性使其对工业应用非常实用，并为未来的研究提供了宝贵的基准。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Capturing+Popularity+Trends:+A+Simplistic+Non-Personalized+Approach+for+Enhanced+Item+Recommendation)|0|
|[Multi-domain Recommendation with Embedding Disentangling and Domain Alignment](https://doi.org/10.1145/3583780.3614977)|Wentao Ning, Xiao Yan, Weiwen Liu, Reynold Cheng, Rui Zhang, Bo Tang|Southern University of Science and Technology, Shenzhen, China; The University of Hong Kong, Hong Kong, Hong Kong; ruizhang.info, Beijing, China; Huawei Noah's Ark Lab, Shenzhen, China|Multi-domain recommendation (MDR) aims to provide recommendations for different domains (e.g., types of products) with overlapping users/items and is common for platforms such as Amazon, Facebook, and LinkedIn that host multiple services. Existing MDR models face two challenges: First, it is difficult to disentangle knowledge that generalizes across domains (e.g., a user likes cheap items) and knowledge specific to a single domain (e.g., a user likes blue clothing but not blue cars). Second, they have limited ability to transfer knowledge across domains with small overlaps. We propose a new MDR method named EDDA with two key components, i.e., embedding disentangling recommender and domain alignment, to tackle the two challenges respectively. In particular, the embedding disentangling recommender separates both the model and embedding for the inter-domain part and the intra-domain part, while most existing MDR methods only focus on model-level disentangling. The domain alignment leverages random walks from graph processing to identify similar user/item pairs from different domains and encourages similar user/item pairs to have similar embeddings, enhancing knowledge transfer. We compare EDDA with 12 state-of-the-art baselines on 3 real datasets. The results show that EDDA consistently outperforms the baselines on all datasets and domains. All datasets and codes are available at https://github.com/Stevenn9981/EDDA.|多域名推荐(MDR)的目的是为不同领域(例如，产品类型)的重叠用户/项目提供推荐，这种推荐在亚马逊、 Facebook 和 LinkedIn 等提供多种服务的平台上很常见。现有的 MDR 模型面临两个挑战: 首先，很难区分跨领域概括的知识(例如，用户喜欢廉价商品)和特定于单个领域的知识(例如，用户喜欢蓝色衣服但不喜欢蓝色汽车)。其次，他们跨领域传递知识的能力有限，重叠的领域很小。我们提出了一种新的 MDR 方法 EDDA，该方法由两个关键部分组成，即嵌入分离推荐和域对齐，分别解决了这两个难题。特别是嵌入式解缠推荐器将域间部分和域内部分的模型和嵌入分离开来，而现有的 MDR 方法大多只关注模型级的解缠。领域对齐利用图形处理中的随机游走来识别来自不同领域的相似用户/项目对，并鼓励相似的用户/项目对具有相似的嵌入，增强知识转移。我们比较了3个实际数据集上的 EDDA 和12个最先进的基线。结果表明，EDDA 在所有数据集和域上的性能均优于基线。所有数据集和代码都可以在 https://github.com/stevenn9981/edda 获得。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-domain+Recommendation+with+Embedding+Disentangling+and+Domain+Alignment)|0|
|[Dimension Independent Mixup for Hard Negative Sample in Collaborative Filtering](https://doi.org/10.1145/3583780.3614845)|Xi Wu, Liangwei Yang, Jibing Gong, Chao Zhou, Tianyu Lin, Xiaolong Liu, Philip S. Yu|University of Illinois Chicago, Chicago, IL, USA; YanShan University, Qinhuangdao, China|Collaborative filtering (CF) is a widely employed technique that predicts user preferences based on past interactions. Negative sampling plays a vital role in training CF-based models with implicit feedback. In this paper, we propose a novel perspective based on the sampling area to revisit existing sampling methods. We point out that current sampling methods mainly focus on Point-wise or Line-wise sampling, lacking flexibility and leaving a significant portion of the hard sampling area un-explored. To address this limitation, we propose Dimension Independent Mixup for Hard Negative Sampling (DINS), which is the first Area-wise sampling method for training CF-based models. DINS comprises three modules: Hard Boundary Definition, Dimension Independent Mixup, and Multi-hop Pooling. Experiments with real-world datasets on both matrix factorization and graph-based models demonstrate that DINS outperforms other negative sampling methods, establishing its effectiveness and superiority. Our work contributes a new perspective, introduces Area-wise sampling, and presents DINS as a novel approach that achieves state-of-the-art performance for negative sampling. Our implementations are available in PyTorch.|协同过滤(CF)是一种广泛应用的技术，它基于过去的交互预测用户偏好。负抽样在基于 CF 的隐式反馈模型的训练中起着至关重要的作用。在本文中，我们提出了一个新的视角基于抽样面积重新审视现有的抽样方法。我们指出，目前的抽样方法主要集中在点或线抽样，缺乏灵活性，并留下了很大一部分硬抽样区域未被探索。针对这一局限性，我们提出了硬负采样的尺寸无关混合(DINS)方法，这是第一种用于训练基于 CF 模型的区域采样方法。DINS 由三个模块组成: 硬边界定义模块、尺寸无关混合模块和多跳池模块。在矩阵分解模型和基于图形的模型上对真实世界数据集进行的实验表明，DINS 优于其他负采样方法，确立了它的有效性和优越性。我们的工作提供了一个新的视角，介绍了区域采样，并提出了 DINS 作为一种新颖的方法，实现了最先进的性能负采样。我们的实现在 PyTorch 中可用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dimension+Independent+Mixup+for+Hard+Negative+Sample+in+Collaborative+Filtering)|0|
|[Sequential Recommendation via an Adaptive Cross-domain Knowledge Decomposition](https://doi.org/10.1145/3583780.3615058)|Chuang Zhao, Xinyu Li, Ming He, Hongke Zhao, Jianping Fan|College of Management and Economics, Tianjin University, Tianjin, China; AI Lab at Lenovo Research, Beijing, China|Cross-domain recommendation, as an intelligent machine to alleviate data sparsity and cold start problems, has attracted extensive attention from scholars. Existing cross-domain recommendation frameworks usually leverage overlapping entities for knowledge transfer, the most popular of which are information aggregation and consistency maintenance. Despite decent improvements, the neglect of dynamic perspectives, the presence of confounding factors, and the disparities in domain properties inevitably constrain model performance. In view of this, this paper proposes a sequential recommendation framework via adaptive cross-domain knowledge decomposition, namely ARISEN, which focuses on employing adaptive causal learning to improve recommendation performance. Specifically, in order to facilitate sequence transfer, we align the user's behaviour sequences in the source domain and target domain according to the timestamps, expecting to use the abundant semantics of the former to augment the information of the latter. Regarding confounding factor removal, we introduce the causal learning technique and promote it as an adaptive representation decomposition framework on the basis of instrumental variables. For the sake of alleviating the impact of domain disparities, this paper endeavors to employ two mutually orthogonal transformation matrices for information fusion. Extensive experiments and detailed analyzes on large industrial and public data sets demonstrate that our framework can achieve substantial improvements over state-of-the-art algorithms.|跨域推荐作为一种缓解数据稀疏和冷启动问题的智能机器，已经引起了学者们的广泛关注。现有的跨领域推荐框架通常利用重叠实体进行知识转移，其中最流行的是信息聚合和一致性维护。尽管有了不错的改进，但是忽视动态视角、混杂因素的存在以及领域属性的差异不可避免地限制了模型的性能。鉴于此，本文提出了一种基于自适应跨领域知识分解的顺序推荐框架 ARISEN，重点研究了利用自适应因果学习来提高推荐性能的方法。具体来说，为了方便序列传输，我们根据时间戳对源域和目标域中的用户行为序列进行对齐，期望利用前者丰富的语义来增强后者的信息。关于去除混杂因素，我们引入了因果学习技术，并将其推广为一个基于工具变量的自适应表征分解框架。为了减轻领域差异的影响，本文尝试采用两个互正交的变换矩阵进行信息融合。大量的实验和对大型工业和公共数据集的详细分析表明，我们的框架可以比最先进的算法实现实质性的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sequential+Recommendation+via+an+Adaptive+Cross-domain+Knowledge+Decomposition)|0|
|[Noisy Perturbations for Estimating Query Difficulty in Dense Retrievers](https://doi.org/10.1145/3583780.3615270)|Negar Arabzadeh, Radin Hamidi Rad, Maryam Khodabakhsh, Ebrahim Bagheri|Toronto Metropolitan University, Toronto, ON, Canada; Shahrood University of Technology, Shahrood, Iran; University of Waterloo, Waterloo, ON, Canada|Estimating query difficulty, also known as Query Performance Prediction (QPP), is concerned with assessing the retrieval quality of a ranking method for an input query. Most traditional unsupervised frequency-based models and many recent supervised neural methods have been designed specifically for predicting the performance of sparse retrievers such as BM25. In this paper we propose an unsupervised QPP method for dense neural retrievers which operates by redefining the well-known concept of query robustness i.e., a more robust query to perturbations is an easier query to handle. We propose to generate query perturbations for measuring query robustness by systematically injecting noise into the contextualized neural representation of each query. We then compare the retrieved list for the original query with that of the perturbed query as a way to measure query robustness. Our experiments on four different query sets including MS MARCO, TREC Deep Learning track 2019 and 2020 and TREC DL-Hard show consistently improved performance on linear and ranking correlation metrics over the state of the art.|评估查询难度，也称为查询性能预测(QueryPerformance預，QPP) ，与评估输入查询的排序方法的检索质量有关。大多数传统的基于频率的无监督模型和许多最近的监督神经网络方法已被专门设计用于预测稀疏检索器的性能，如 BM25。本文提出了一种密集型神经元检索器的无监督 QPP 方法，该方法通过重新定义查询鲁棒性的概念来实现。我们提出通过系统地在每个查询的上下文化神经表示中注入噪声来产生查询扰动来衡量查询的鲁棒性。然后，我们将检索到的原始查询列表与受干扰的查询列表进行比较，作为衡量查询健壮性的一种方法。我们在包括 MS MARCO，TREC Deep Learning track 2019和2020以及 TREC DL-Hard 在内的四个不同的查询集上进行的实验显示，在线性和排名相关性指标方面，相对于最先进的水平，性能持续改善。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Noisy+Perturbations+for+Estimating+Query+Difficulty+in+Dense+Retrievers)|0|
|[Deep Context Interest Network for Click-Through Rate Prediction](https://doi.org/10.1145/3583780.3615233)|Xuyang Hou, Zhe Wang, Qi Liu, Tan Qu, Jia Cheng, Jun Lei|University of Science and Technology of China, Hefei, China; Meituan, Beijing, China|Click-Through Rate (CTR) prediction, estimating the probability of a user clicking on an item, is essential in industrial applications, such as online advertising. Many works focus on user behavior modeling to improve CTR prediction performance. However, most of those methods only model users' positive interests from users' click items while ignoring the context information, which is the display items around the clicks, resulting in inferior performance. In this paper, we highlight the importance of context information on user behavior modeling and propose a novel model named Deep Context Interest Network (DCIN), which integrally models the click and its display context to learn users' context-aware interests. DCIN consists of three key modules: 1) Position-aware Context Aggregation Module (PCAM), which performs aggregation of display items with an attention mechanism; 2) Feedback-Context Fusion Module (FCFM), which fuses the representation of clicks and display contexts through non-linear feature interaction; 3) Interest Matching Module (IMM), which activates interests related with the target item. Moreover, we provide our hands-on solution to implement our DCIN model on large-scale industrial systems. The significant improvements in both offline and online evaluations demonstrate the superiority of our proposed DCIN method. Notably, DCIN has been deployed on our online advertising system serving the main traffic, which brings 1.5% CTR and 1.5% RPM lift.|点进率(ctrl)预测，估计用户点击一个项目的概率，在工业应用中是必不可少的，比如在线广告。许多工作集中在用户行为建模，以提高点击率预测性能。然而，这些方法大多只是从用户的点击项目中建立用户的积极兴趣模型，而忽略了上下文信息，即点击周围的显示项目，导致性能较差。本文强调了上下文信息在用户行为建模中的重要性，提出了一种新的模型——深度上下文兴趣网络(Deep Context Interest Network，DCIN)。DCIN 由三个关键模块组成: 1)位置感知上下文聚合模块(PCAM) ，利用注意机制对显示项目进行聚合; 2)反馈上下文融合模块(FCFM) ，通过非线性特征交互融合点击表示和显示上下文; 3)兴趣匹配模块(IMM) ，激活与目标项目相关的兴趣。此外，我们提供了我们的动手解决方案，以实现我们的 DCIN 模型的大规模工业系统。离线和在线评估的显著改进证明了我们提出的 DCIN 方法的优越性。值得注意的是，DCIN 已经部署在我们的在线广告系统服务的主要流量，这带来了1.5% 的点击率和1.5% 的转速提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Context+Interest+Network+for+Click-Through+Rate+Prediction)|0|
|[MSRA: A Multi-Aspect Semantic Relevance Approach for E-Commerce via Multimodal Pre-Training](https://doi.org/10.1145/3583780.3615224)|Hanqi Jin, Jiwei Tan, Lixin Liu, Lisong Qiu, Shaowei Yao, Xi Chen, Xiaoyi Zeng|Alibaba Group, Hangzhou, China|To enhance the effectiveness of matching user requests with millions of online products, practitioners invest significant efforts in developing semantic relevance models on large-scale e-commerce platforms. Generally, such semantic relevance models are formulated as text-matching approaches, which measure the relevance between users' search queries and the titles of candidate items (i.e., products). However, we argue that conventional relevance methods may lead to sub-optimal performance due to the limited information provided by the titles of candidate items. To alleviate this issue, we suggest incorporating additional information about candidate items from multiple aspects, including their attributes and images. This could supplement the information that may not be fully provided by titles alone. To this end, we propose a multi-aspect semantic relevance model that takes into account the match between search queries and the title, attribute and image information of items simultaneously. The model is further enhanced through pre-training using several well-designed self-supervised and weakly-supervised tasks. Furthermore, the proposed model is fine-tuned using annotated data and distilled into a representation-based architecture for efficient online deployment. Experimental results show the proposed approach significantly improves relevance and leads to considerable enhancements in business metrics.|为了提高将用户请求与数百万在线产品匹配的有效性，从业人员投入大量精力在大规模电子商务平台上开发语义相关性模型。通常，这种语义相关模型都是以文本匹配的方式构建的，用于测量用户的搜索查询与候选项(即产品)标题之间的相关性。然而，由于候选项目标题提供的信息有限，传统的关联方法可能导致性能不理想。为了缓解这个问题，我们建议从多个方面整合关于候选项目的额外信息，包括它们的属性和图像。这可以补充标题本身可能无法完全提供的信息。为此，我们提出了一个多方面的语义相关模型，该模型同时考虑了搜索查询与项目的标题、属性和图像信息之间的匹配。该模型通过使用几个设计良好的自监督和弱监督任务进行预训练得到进一步增强。此外，该模型使用带注释的数据进行了微调，并提炼为一个基于表示的体系结构，以实现有效的在线部署。实验结果表明，提出的方法显著提高了相关性，并导致业务度量的显著增强。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MSRA:+A+Multi-Aspect+Semantic+Relevance+Approach+for+E-Commerce+via+Multimodal+Pre-Training)|0|
|[LEAD-ID: Language-Enhanced Denoising and Intent Distinguishing Graph Neural Network for Sponsored Search Broad Retrievals](https://doi.org/10.1145/3583780.3615175)|Xiao Zhou, Ran Wang, Haorui Li, Qiang Liu, Xingxing Wang, Dong Wang|Meituan.com, Beijing, China|As a local-based service (LBS), search ad retrieval in online meal delivery platforms should be broader to bridge the gap between vague consumption intentions of users and shortage of ad candidates limited by users' queries and positions. Recently, graph neural networks (GNNs) have been successfully applied to search ad retrieval task. However, directly applying GNNs suffer from noisy interactions and intents indistinguishability, which seriously degrades systems' effectiveness in the broad retrieval. In this paper, we propose a Language-EnhAnced Denoising and Intent Distinguishing graph neural network, LEAD-ID, which is developed and deployed at Meituan for sponsored search broad retrieval. To denoise interaction data, LEAD-ID designs hard- and soft- denoising strategies for GNNs based on a pretrained language model. A variational EM method is also employed to reduce high computational complexity of combining LMs and GNNs jointly. To distinguish various intents, LEAD-ID generates intent-aware node representations based on meticulously crafted LMs (language model) and GNNs; and then, it is guided by a contrastive learning object in an explicit and effective manner. According to offline experiments and online A/B tests, our framework significantly outperforms baselines in terms of recall and revenue.|作为一种基于本地的服务(LBS) ，在线送餐平台的搜索广告检索应该更加广泛，以弥补用户模糊的消费意图和受用户查询和位置限制的广告候选人短缺之间的差距。近年来，图神经网络(GNN)已成功地应用于广告检索任务中。然而，直接应用 GNN 存在着噪声交互和意图不可区分的问题，严重影响了系统在广义检索中的有效性。在本文中，我们提出了一个语言增强去噪和意图识别图神经网络，LEAD-ID，这是开发和部署在美团的赞助搜索广泛检索。为了对交互数据进行去噪，LEAD-ID 基于预先训练好的语言模型设计了 GNN 的软硬去噪策略。采用变分 EM 方法，降低了 LM 和 GNN 联合运算的高计算复杂度。为了区分不同的意图，LEAD-ID 基于精心制作的 LM (语言模型)和 GNN 生成意图感知的节点表示; 然后，在一个对比学习对象的指导下，以一种明确而有效的方式。根据离线实验和在线 A/B 测试，我们的框架在召回和收入方面明显优于基准。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LEAD-ID:+Language-Enhanced+Denoising+and+Intent+Distinguishing+Graph+Neural+Network+for+Sponsored+Search+Broad+Retrievals)|0|
|[Regression Compatible Listwise Objectives for Calibrated Ranking with Binary Relevance](https://doi.org/10.1145/3583780.3614712)|Aijun Bai, Rolf Jagerman, Zhen Qin, Le Yan, Pratyush Kar, BingRong Lin, Xuanhui Wang, Michael Bendersky, Marc Najork|Google LLC, New York, NY, USA; Google LLC, Mountain View, CA, USA; Google LLC, Paris, France; Google LLC, Amsterdam, Netherlands|As Learning-to-Rank (LTR) approaches primarily seek to improve ranking quality, their output scores are not scale-calibrated by design. This fundamentally limits LTR usage in score-sensitive applications. Though a simple multi-objective approach that combines a regression and a ranking objective can effectively learn scale-calibrated scores, we argue that the two objectives are not necessarily compatible, which makes the trade-off less ideal for either of them. In this paper, we propose a practical regression compatible ranking (RCR) approach that achieves a better trade-off, where the two ranking and regression components are proved to be mutually aligned. Although the same idea applies to ranking with both binary and graded relevance, we mainly focus on binary labels in this paper. We evaluate the proposed approach on several public LTR benchmarks and show that it consistently achieves either best or competitive result in terms of both regression and ranking metrics, and significantly improves the Pareto frontiers in the context of multi-objective optimization. Furthermore, we evaluated the proposed approach on YouTube Search and found that it not only improved the ranking quality of the production pCTR model, but also brought gains to the click prediction accuracy. The proposed approach has been successfully deployed in the YouTube production system.|由于学习到排名(LTR)方法主要寻求提高排名质量，因此它们的输出分数不是按照设计进行标度校准的。这从根本上限制了对分数敏感的应用程序中 LTR 的使用。虽然一个简单的多目标方法，结合回归和排名目标可以有效地学习量表校准的分数，我们认为，这两个目标不一定相容，这使得权衡不太理想的任何一个。在本文中，我们提出了一个实用的回归相容排序(RCR)方法，以实现更好的权衡，其中两个排序和回归组件被证明是相互一致的。虽然同样的思想也适用于二进制和分级相关性的排序，但本文主要关注二进制标签。我们在几个公共 LTR 基准上对所提出的方法进行了评估，结果表明，该方法在回归和排序指标方面始终达到最佳或有竞争力的结果，并且在多目标优化的情况下显著改善了帕累托前沿。此外，我们在 YouTube 搜索中对该方法进行了评估，发现该方法不仅提高了产品 pCTR 模型的排序质量，而且提高了点击预测的准确性。提议的方法已经成功地部署在 YouTube 制作系统中。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Regression+Compatible+Listwise+Objectives+for+Calibrated+Ranking+with+Binary+Relevance)|0|
|[An Unified Search and Recommendation Foundation Model for Cold-Start Scenario](https://doi.org/10.1145/3583780.3614657)|Yuqi Gong, Xichen Ding, Yehui Su, Kaiming Shen, Zhongyi Liu, Guannan Zhang|Ant Group, Beijing, China; Ant Group, Hangzhou, China|In modern commercial search engines and recommendation systems, data from multiple domains is available to jointly train the multi-domain model. Traditional methods train multi-domain models in the multi-task setting, with shared parameters to learn the similarity of multiple tasks, and task-specific parameters to learn the divergence of features, labels, and sample distributions of individual tasks. With the development of large language models, LLM can extract global domain-invariant text features that serve both search and recommendation tasks. We propose a novel framework called S\&R Multi-Domain Foundation, which uses LLM to extract domain invariant features, and Aspect Gating Fusion to merge the ID feature, domain invariant text features and task-specific heterogeneous sparse features to obtain the representations of query and item. Additionally, samples from multiple search and recommendation scenarios are trained jointly with Domain Adaptive Multi-Task module to obtain the multi-domain foundation model. We apply the S\&R Multi-Domain foundation model to cold start scenarios in the pretrain-finetune manner, which achieves better performance than other SOTA transfer learning methods. The S\&R Multi-Domain Foundation model has been successfully deployed in Alipay Mobile Application's online services, such as content query recommendation and service card recommendation, etc.|在现代商业搜索引擎和推荐系统中，来自多个域的数据可用于联合训练多域模型。传统方法在多任务环境下训练多领域模型，通过共享参数来学习多任务的相似性，通过任务特定参数来学习单个任务的特征、标签和样本分布的差异性。随着大型语言模型的发展，LLM 可以提取全局域不变的文本特征，这些特征可以同时服务于搜索和推荐任务。提出了一种新的基于领域不变特征提取的框架 S & R Multi-Domain Foundation，该框架利用 LLM 提取领域不变特征，利用方面门控融合技术融合 ID 特征、领域不变文本特征和任务特定的异构稀疏特征，得到查询和项目的表示。此外，将多个搜索和推荐场景的样本与领域自适应多任务模块联合训练，得到多领域基础模型。我们将 S & R 多领域基础模型应用于预训练-微调方式的冷启动场景，比其他 SOTA 迁移学习方法获得了更好的性能。S & R 多域基金会模式已成功应用于支付宝移动应用的在线服务，如内容查询推荐和服务卡推荐等。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Unified+Search+and+Recommendation+Foundation+Model+for+Cold-Start+Scenario)|0|
|[BOLT: An Automated Deep Learning Framework for Training and Deploying Large-Scale Search and Recommendation Models on Commodity CPU Hardware](https://doi.org/10.1145/3583780.3615458)|Nicholas Meisburger, Vihan Lakshman, Benito Geordie, Joshua Engels, David Torres Ramos, Pratik Pranav, Benjamin Coleman, Benjamin Meisburger, Shubh Gupta, Yashwanth Adunukota, Siddharth Jain, Tharun Medini, Anshumali Shrivastava|ThirdAI, Houston, TX, USA|Efficient large-scale neural network training and inference on commodity CPU hardware is of immense practical significance in democratizing deep learning (DL) capabilities. Presently, the process of training massive models consisting of hundreds of millions to billions of parameters requires the extensive use of specialized hardware accelerators, such as GPUs, which are only accessible to a limited number of institutions with considerable financial resources. Moreover, there is often an alarming carbon footprint associated with training and deploying these models. In this paper, we take a step towards addressing these challenges by introducing BOLT, a sparse deep learning library for training large-scale search and recommendation models on standard CPU hardware. BOLT provides a flexible, high-level API for constructing models that will be familiar to users of existing popular DL frameworks. By automatically tuning specialized hyperparameters, BOLT also abstracts away the algorithmic details of sparse network training. We evaluate BOLT on a number of information retrieval tasks including product recommendations, text classification, graph neural networks, and personalization. We find that our proposed system achieves competitive performance with state-of-the-art techniques at a fraction of the cost and energy consumption and an order-of-magnitude faster inference time. BOLT has also been successfully deployed by multiple businesses to address critical problems, and we highlight one customer case study in the field of e-commerce.|高效的大规模神经网络训练和推理对于普及深度学习(DL)能力具有重要的现实意义。目前，培训由数亿至数十亿个参数组成的大型模型的过程需要广泛使用专门的硬件加速器，如图形处理器，只有少数拥有大量财政资源的机构才能使用这些加速器。此外，在培训和部署这些模型时，往往存在令人担忧的碳足印。在本文中，我们通过引入 BOLT 向解决这些挑战迈出了一步，BOLT 是一个稀疏的深度学习库，用于在标准 CPU 硬件上培训大规模搜索和推荐模型。BOLT 提供了一个灵活的高级 API，用于构造现有流行的 DL 框架的用户所熟悉的模型。通过自动调整专门的超参数，BOLT 还抽象出稀疏网络训练的算法细节。我们评估 BOLT 的一些信息检索任务，包括产品推荐、文本分类、图形神经网络和个性化。我们发现，我们提出的系统实现了具有竞争力的性能与国家的最先进的技术在成本和能源消耗的一小部分和一个数量级更快的推理时间。BOLT 还被多个企业成功部署以解决关键问题，我们强调了电子商务领域的一个客户案例研究。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BOLT:+An+Automated+Deep+Learning+Framework+for+Training+and+Deploying+Large-Scale+Search+and+Recommendation+Models+on+Commodity+CPU+Hardware)|0|
|[Graph Learning for Exploratory Query Suggestions in an Instant Search System](https://doi.org/10.1145/3583780.3615481)|Enrico Palumbo, Andreas Damianou, Alice Wang, Alva Liu, Ghazal Fazelnia, Francesco Fabbri, Rui Ferreira, Fabrizio Silvestri, Hugues Bouchard, Claudia Hauff, Mounia Lalmas, Ben Carterette, Praveen Chandar, David Nyhan|Spotify, Alexandria, USA; Spotify, Delft, Netherlands; Spotify, Barcelona, Spain; Spotify, New York, USA; Spotify, Cambridge, United Kingdom; Spotify, Wilmington, USA; Spotify, Rome, Italy; Spotify, Turin, Italy; Spotify, London, United Kingdom; Spotify, Farsta, Sweden|Search systems in online content platforms are typically biased toward a minority of highly consumed items, reflecting the most common user behavior of navigating toward content that is already familiar and popular. Query suggestions are a powerful tool to support query formulation and to encourage exploratory search and content discovery. However, classic approaches for query suggestions typically rely either on semantic similarity, which lacks diversity and does not reflect user searching behavior, or on a collaborative similarity measure mined from search logs, which suffers from data sparsity and is biased by highly popular queries. In this work, we argue that the task of query suggestion can be modelled as a link prediction task on a heterogeneous graph including queries and documents, enabling Graph Learning methods to effectively generate query suggestions encompassing both semantic and collaborative information. We perform an offline evaluation on an internal Spotify dataset of search logs and on two public datasets, showing that node2vec leads to an accurate and diversified set of results, especially on the large scale real-world data. We then describe the implementation in an instant search scenario and discuss a set of additional challenges tied to the specific production environment. Finally, we report the results of a large scale A/B test involving millions of users and prove that node2vec query suggestions lead to an increase in online metrics such as coverage (+1.42% shown search results pages with suggestions) and engagement (+1.21% clicks), with a specifically notable boost in the number of clicks on exploratory search queries (+9.37%).|在线内容平台中的搜索系统通常偏向于少数高消费项目，这反映了最常见的用户行为，即导航到已经熟悉和流行的内容。查询建议是一个强大的工具，可以支持查询表达，并鼓励探索性搜索和内容发现。然而，经典的查询建议方法通常依赖于语义相似性，这种相似性缺乏多样性，不能反映用户的搜索行为; 或者依赖于从搜索日志中挖掘出来的协作相似性度量，这种度量受到数据稀疏性的影响，并且受到非常流行的查询的影响。本文认为，查询建议任务可以建模为包含查询和文档的异构图上的链接预测任务，使图学习方法能够有效地生成包含语义和协作信息的查询建议。我们对搜索日志的内部 Spotify 数据集和两个公共数据集进行离线评估，表明 node2vec 导致准确和多样化的结果集，特别是在大规模的现实世界数据上。然后，我们在一个即时搜索场景中描述实现，并讨论一组与特定生产环境相关的附加挑战。最后，我们报告了一个涉及数百万用户的大规模 A/B 测试的结果，并证明 node2vec 查询建议导致在线指标的增加，如覆盖率(+ 1.42% 显示带有建议的搜索结果页面)和参与度(+ 1.21% 点击率) ，特别是探索性搜索查询的点击数显著增加(+ 9.37%)。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Learning+for+Exploratory+Query+Suggestions+in+an+Instant+Search+System)|0|
|[Learning and Optimization of Implicit Negative Feedback for Industrial Short-video Recommender System](https://doi.org/10.1145/3583780.3615482)|Yunzhu Pan, Nian Li, Chen Gao, Jianxin Chang, Yanan Niu, Yang Song, Depeng Jin, Yong Li|Beijing Kuaishou Technology Co., Ltd., Beijing, China; Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; University of Electronic Science and Technology of China, Chengdu, China|Short-video recommendation is one of the most important recommendation applications in today's industrial information systems. Compared with other recommendation tasks, the enormous amount of feedback is the most typical characteristic. Specifically, in short-video recommendation, the easiest-to-collect user feedback is from the skipping behaviors, which leads to two critical challenges for the recommendation model. First, the skipping behavior reflects implicit user preferences, and thus it is challenging for interest extraction. Second, the kind of special feedback involves multiple objectives, such as total watching time, which is also very challenging. In this paper, we present our industrial solution in Kuaishou, which serves billion-level users every day. Specifically, we deploy a feedback-aware encoding module which well extracts user preference taking the impact of context into consideration. We further design a multi-objective prediction module which well distinguishes the relation and differences among different model objectives in the short-video recommendation. We conduct extensive online A/B testing, along with detailed and careful analysis, which verifies the effectiveness of our solution.|短视频推荐是当今工业信息系统中最重要的推荐应用之一。与其他推荐任务相比，大量的反馈是最典型的特征。具体来说，在短视频推荐中，最容易收集的用户反馈来自跳跃行为，这给推荐模型带来了两个关键的挑战。首先，跳跃行为反映了隐式用户偏好，因此对兴趣提取具有挑战性。其次，这种特殊的反馈涉及多个目标，如总观看时间，这也是非常具有挑战性的。在本文中，我们介绍了我们在 Kuaishou 的工业解决方案，这个方案每天为数十亿用户提供服务。具体来说，我们部署了一个反馈感知的编码模块，该模块在考虑上下文影响的情况下很好地提取了用户偏好。进一步设计了一个多目标预测模块，可以很好地区分短视频推荐中不同模型目标之间的关系和差异。我们进行了广泛的在线 A/B 测试，并进行了详细和仔细的分析，从而验证了我们的解决方案的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+and+Optimization+of+Implicit+Negative+Feedback+for+Industrial+Short-video+Recommender+System)|0|
|[3MN: Three Meta Networks for Multi-Scenario and Multi-Task Learning in Online Advertising Recommender Systems](https://doi.org/10.1145/3583780.3614651)|Yifei Zhang, Hua Hua, Hui Guo, Shuangyang Wang, Chongyu Zhong, Shijie Zhang|Interactive Entertainment Group, Tencent, Shenzhen, China|Recommender systems are widely applied on web. For example, online advertising systems rely on recommender systems to accurately estimate the value of display opportunities, which is critical to maximize the profits of advertisers. To reduce computational resource consumption, the core tactic of Multi-Scenario Multi-Task Learning (MSMTL) is to devise a single recommder system that is adapted to all contexts instead of implementing multiple scenario-oriented or task-oriented recommender systems. However, MSMTL is challenging because there are complicated task-task, scenario-scenario, and task-scenario interrelations; the characteristic of different tasks in different scenarios also largely varies; and samples of each context are often unevenly distributed. Previous MSMTL solutions focus on applying scenario knowledge to improve the performance of multi-task learning, while neglecting the complicated interrelations among tasks and scenarios. Moreover, samples derived from different scenarios are transferred into the latent embedding with the same dimension. This static embedding strategy impedes the practicality of model expressiveness, since the scenarios with sufficient samples are underrepresented and those with insufficient samples are over-represented. In this paper, we propose a novel three meta networks-based solution (3MN) to MSMTL that addresses all the limitations discussed above. Specifically, we innovatively bind the meta network with scenario-related input in bottom embedding layer, so that the embedding layer is capable of learning the scenario-related knowledge explicitly. To counteract the imbalanced scenario-related data distributions, our flexible embedding layer adaptively learns the representation of samples. This innovative embedding layer is also able to boost other solutions as a plug-in. Moreover, to fully capture the interrelations among scenarios and tasks, we enforce the task and scenario information into the other two meta networks, and transfer the resulted meta-knowledge into the top components (i.e., backbone network and classifier) of the recommender system, respectively. These three meta networks contribute to the superiority of our 3MN solution over state-of-the-art MSMTL solutions, which is demonstrated by extensive offline experiments. 3MN has been successfully deployed in our industrial online advertising system.|推荐系统在网络上得到了广泛的应用。例如，在线广告系统依赖于推荐系统来准确估计展示机会的价值，这对于广告商的利润最大化至关重要。为了减少计算资源消耗，多场景多任务学习(MSMTL)的核心策略是设计一个单一的推荐系统，以适应所有环境，而不是实施多场景或任务导向的推荐系统。然而，MSMTL 具有挑战性，因为存在复杂的任务-任务、场景-场景和任务-场景之间的相互关系; 不同场景中不同任务的特征也大不相同; 每个上下文的样本通常分布不均匀。以往的 MSMTL 解决方案侧重于应用场景知识来提高多任务学习的性能，而忽视了任务和场景之间复杂的相互关系。同时，将不同场景的样本转化为同维数的潜在嵌入。这种静态嵌入策略阻碍了模型表达的实用性，因为有足够样本的场景表示不足，而有不足样本的场景表示过多。在本文中，我们提出了一个新的三元网络为基础的解决方案(3MN)的 MSMTL，解决所有的限制上述讨论。具体来说，我们在底层嵌入层创新性地将元网络与场景相关的输入绑定在一起，使得嵌入层能够显式地学习场景相关的知识。为了抵消不平衡的场景相关数据分布，我们的灵活嵌入层自适应地学习样本的表示。这个创新的嵌入层还可以作为插件提升其他解决方案。此外，为了充分捕捉场景和任务之间的相互关系，我们将任务和场景信息强制加入另外两个元网络，并将得到的元知识分别转移到推荐系统的顶层组件(即骨干网络和分类器)中。这三个元网络有助于我们的3MN 解决方案优于最先进的 MSMTL 解决方案，这在大量的离线实验中得到了证明。3MN 已成功部署在我们的工业在线广告系统。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=3MN:+Three+Meta+Networks+for+Multi-Scenario+and+Multi-Task+Learning+in+Online+Advertising+Recommender+Systems)|0|
|[GripRank: Bridging the Gap between Retrieval and Generation via the Generative Knowledge Improved Passage Ranking](https://doi.org/10.1145/3583780.3614901)|Jiaqi Bai, Hongcheng Guo, Jiaheng Liu, Jian Yang, Xinnian Liang, Zhao Yan, Zhoujun Li|Tencent Cloud AI, Beijing, China; Beihang University, Beijing, China; DAMO Academy, Alibaba Group, Beijing, China; State Key Lab of Software Development Environment, Beihang University, Beijing, China|Retrieval-enhanced text generation, which aims to leverage passages retrieved from a large passage corpus for delivering a proper answer given the input query, has shown remarkable progress on knowledge-intensive language tasks such as open-domain question answering and knowledge-enhanced dialogue generation. However, the retrieved passages are not ideal for guiding answer generation because of the discrepancy between retrieval and generation, i.e., the candidate passages are all treated equally during the retrieval procedure without considering their potential to generate the proper answers. This discrepancy makes a passage retriever deliver a sub-optimal collection of candidate passages to generate answers. In this paper, we propose the GeneRative Knowledge Improved Passage Ranking (GripRank) approach, addressing the above challenge by distilling knowledge from a generative passage estimator (GPE) to a passage ranker, where the GPE is a generative language model used to measure how likely the candidate passages can generate the proper answer. We realize the distillation procedure by teaching the passage ranker learning to rank the passages ordered by the GPE. Furthermore, we improve the distillation quality by devising a curriculum knowledge distillation mechanism, which allows the knowledge provided by the GPE can be progressively distilled to the ranker through an easy-to-hard curriculum, enabling the passage ranker to correctly recognize the provenance of the answer from many plausible candidates. We conduct extensive experiments on four datasets across three knowledge-intensive language tasks. Experimental results show advantages over the state-of-the-art methods for both passage ranking and answer generation on the KILT benchmark.|检索增强型文本生成的目的是利用从大型文章语料库中检索到的段落来提供输入查询的正确答案，在开放领域问题回答和知识增强型对话生成等知识密集型语言任务方面取得了显著进展。然而，由于检索和生成之间的差异，被检索的段落并不是指导生成答案的理想选择，也就是说，候选段落在检索过程中都被平等对待，而没有考虑它们生成正确答案的潜力。这种差异使得文章检索器提供一个次优的候选文章集合来生成答案。在本文中，我们提出了生成知识改进通道排名(GripRank)方法，通过从生成通道估计(GPE)中提取知识到一个通道排名，其中 GPE 是一个生成语言模型，用于衡量候选通道产生正确答案的可能性，从而解决上述挑战。通过教导通道排序器学习对 GPE 排序的通道进行排序，实现了蒸馏过程。此外，我们通过设计一个课程知识蒸馏机制来提高蒸馏质量，该机制允许 GPE 提供的知识可以通过一个容易到难的课程逐步蒸馏到排名，使得通过排名能够正确地识别来自许多合理候选人的答案的来源。我们在三个知识密集型语言任务的四个数据集上进行了广泛的实验。实验结果表明，在 KILT 基准的文章排序和答案生成方面，该方法比目前最先进的方法具有更大的优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GripRank:+Bridging+the+Gap+between+Retrieval+and+Generation+via+the+Generative+Knowledge+Improved+Passage+Ranking)|0|
|[CLosER: Conversational Legal Longformer with Expertise-Aware Passage Response Ranker for Long Contexts](https://doi.org/10.1145/3583780.3614812)|Arian Askari, Mohammad Aliannejadi, Amin Abolghasemi, Evangelos Kanoulas, Suzan Verberne|LIACS, Leiden University, Leiden, Netherlands; University of Amsterdam, Amsterdam, Netherlands; Leiden University, Amsterdam, Netherlands; Leiden Institute of Advanced Computer Science, Leiden University, Leiden, Netherlands|In this paper, we investigate the task of response ranking in conversational legal search. We propose a novel method for conversational passage response retrieval (ConvPR) for long conversations in domains with mixed levels of expertise. Conversational legal search is challenging because the domain includes long, multi-participant dialogues with domain-specific language. Furthermore, as opposed to other domains, there typically is a large knowledge gap between the questioner (a layperson) and the responders (lawyers), participating in the same conversation. We collect and release a large-scale real-world dataset called LegalConv with nearly one million legal conversations from a legal community question answering (CQA) platform. We address the particular challenges of processing legal conversations, with our novel Conversational Legal Longformer with Expertise-Aware Response Ranker, called CLosER. The proposed method has two main innovations compared to state-of-the-art methods for ConvPR: (i) Expertise-Aware Post-Training; a learning objective that takes into account the knowledge gap difference between participants to the conversation; and (ii) a simple but effective strategy for re-ordering the context utterances in long conversations to overcome the limitations of the sparse attention mechanism of the Longformer architecture. Evaluation on LegalConv shows that our proposed method substantially and significantly outperforms existing state-of-the-art models on the response selection task. Our analysis indicates that our Expertise-Aware PostTraining, i.e., continued pre-training or domain/task adaptation, plays an important role in the achieved effectiveness. Our proposed method is generalizable to other tasks with domain-specific challenges and can facilitate future research on conversational search in other domains.|本文研究了会话法律搜索中的回答排序问题。本文提出了一种基于混合专业知识水平的会话通道反应检索方法。对话式法律搜索具有挑战性，因为该领域包括与领域特定语言的长时间、多参与者对话。此外，与其他领域不同，提问者(外行)和回答者(律师)参与同一对话时，通常存在很大的知识差距。我们收集并发布了一个名为 LegalConv 的大规模现实世界数据集，其中包括来自法律社区问答(cQA)平台的近一百万个法律对话。我们解决处理法律对话的特殊挑战，我们的新颖的对话法律长期与专家意识的响应排名，所谓的关闭。与目前最先进的 ConvPR 方法相比，提出的方法有两个主要创新: (i)专业知识意识的后期培训; 一个考虑到会话参与者之间的知识差异的学习目标; 和(ii)一个简单但有效的策略来重新排序长时间会话中的上下文语句，以克服 Longform 架构的稀疏注意机制的局限性。对 LegalConv 的评估表明，我们提出的方法在响应选择任务上大大优于现有的最先进的模型。我们的分析表明，我们的专业意识后期培训，即持续的培训前或领域/任务适应，在实现有效性方面发挥了重要作用。我们提出的方法可推广到其他具有领域特定挑战的任务，并可促进未来其他领域的会话搜索研究。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CLosER:+Conversational+Legal+Longformer+with+Expertise-Aware+Passage+Response+Ranker+for+Long+Contexts)|0|
|[Multi-modal Mixture of Experts Represetation Learning for Sequential Recommendation](https://doi.org/10.1145/3583780.3614978)|Shuqing Bian, Xingyu Pan, Wayne Xin Zhao, Jinpeng Wang, Chuyuan Wang, JiRong Wen|Renmin University of China, Beijing, China; Meituan, Beijing, China|Within online platforms, it is critical to capture the dynamic user preference from the sequential interaction behaviors for making accurate recommendation over time. Recently, significant progress has been made in sequential recommendation with deep learning. However, existing neural sequential recommender often suffer from the data sparsity issue in real-world applications. To tackle this problem, we propose a Multi-Modal Mixture of experts model for Sequential Recommendation, named M3SRec, which leverage rich multi-modal interaction data for improving sequential recommendation. Different from existing multi-modal recommendation models, our approach jointly considers reducing the semantic gap across modalities and adapts multi-modal semantics to fit recommender systems. For this purpose, we make two important technical contributions in architecture and training. Firstly, we design a novel multi-modal mixture-of-experts (MoE) fusion network, which can deeply fuse the across-modal semantics and largely enhance the modeling capacity of complex user intents. For training, we design specific pre-training tasks that can mimic the goal of the recommendation, which help model learn the semantic relatedness between the multi-modal sequential context and the target item. Extensive experiments conducted on both public and industry datasets demonstrate the superiority of our proposed method over existing state-of-the-art methods, especially when only limited training data is available.|在在线平台中，从连续的交互行为中捕获动态用户偏好对于随时间做出准确的推荐是至关重要的。近年来，随着深度学习在序贯推荐方面取得了显著的进展。然而，现有的神经顺序推荐系统在实际应用中经常遇到数据稀疏的问题。为了解决这个问题，我们提出了一个序贯推荐的多模态混合专家模型 M3SRec，该模型利用丰富的多模态交互数据来改进序贯推荐。与现有的多模态推荐模型不同，我们的方法共同考虑缩小模态间的语义差距，并采用多模态语义来适应推荐系统。为此，我们在建筑和培训方面做出了两项重要的技术贡献。首先，我们设计了一种新的多模态专家混合(MoE)融合网络，该网络能够深入融合跨模态语义，大大提高复杂用户意图的建模能力。对于训练，我们设计了能够模拟推荐目标的特定的预训练任务，帮助模型学习多模态顺序上下文和目标项之间的语义关系。在公共数据集和行业数据集上进行的大量实验表明，我们提出的方法优于现有的最先进的方法，特别是当只有有限的训练数据可用时。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-modal+Mixture+of+Experts+Represetation+Learning+for+Sequential+Recommendation)|0|
|[BOMGraph: Boosting Multi-scenario E-commerce Search with a Unified Graph Neural Network](https://doi.org/10.1145/3583780.3614794)|Shuai Fan, Jinping Gou, Yang Li, Jiaxing Bai, Chen Lin, Wanxian Guan, Xubin Li, Hongbo Deng, Jian Xu, Bo Zheng|Xiamen University, Xiamen, China; Alibaba Group, Hangzhou, China|Mobile Taobao Application delivers search services on multiple scenarios that take textual, visual, or product queries. This paper aims to propose a unified graph neural network for these search scenarios to leverage data from multiple scenarios and jointly optimize search performances with less training and maintenance costs. Towards this end, this paper proposes BOMGraph, BOosting Multi-scenario E-commerce Search with a unified Graph neural network. BOMGraph is embodied with several components to address challenges in multi-scenario search. It captures heterogeneous information flow across scenarios by inter-scenario and intra-scenario metapaths. It learns robust item representations by disentangling specific characteristics for different scenarios and encoding common knowledge across scenarios. It alleviates label scarcity and long-tail problems in scenarios with low traffic by contrastive learning with cross-scenario augmentation. BOMGraph has been deployed in production by Alibaba's E-commerce search advertising platform. Both offline evaluations and online A/B tests demonstrate the effectiveness of BOMGraph.|移动淘宝应用程序提供多种场景的搜索服务，包括文本查询、视觉查询或产品查询。针对这些搜索场景，本文提出了一种统一的图形神经网络，以较少的训练和维护成本，充分利用多个场景的数据，共同优化搜索性能。为此，本文提出了基于统一图神经网络的 BOMGraph，以推动多场景电子商务搜索。BOMGraph 由几个组件组成，用于解决多场景搜索中的挑战。它通过场景间和场景内的元路径捕获跨场景的异构信息流。它通过分离不同场景的特定特征并跨场景编码公共知识来学习健壮的项表示。通过对比学习和跨场景扩展，缓解了低流量场景下的标签稀缺性和长尾问题。BOMGraph 已被阿里巴巴电子商务搜索广告平台投入生产。离线评估和在线 A/B 测试都证明了 BOMGraph 的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BOMGraph:+Boosting+Multi-scenario+E-commerce+Search+with+a+Unified+Graph+Neural+Network)|0|
|[Large Language Models as Zero-Shot Conversational Recommenders](https://doi.org/10.1145/3583780.3614949)|Zhankui He, Zhouhang Xie, Rahul Jha, Harald Steck, Dawen Liang, Yesu Feng, Bodhisattwa Prasad Majumder, Nathan Kallus, Julian J. McAuley|University of California, San Diego, La Jolla, CA, USA; Netflix Inc. & Cornell University, Los Gatos, CA, USA; Netflix Inc., Los Gatos, CA, USA|In this paper, we present empirical studies on conversational recommendation tasks using representative large language models in a zero-shot setting with three primary contributions. (1) Data: To gain insights into model behavior in "in-the-wild" conversational recommendation scenarios, we construct a new dataset of recommendation-related conversations by scraping a popular discussion website. This is the largest public real-world conversational recommendation dataset to date. (2) Evaluation: On the new dataset and two existing conversational recommendation datasets, we observe that even without fine-tuning, large language models can outperform existing fine-tuned conversational recommendation models. (3) Analysis: We propose various probing tasks to investigate the mechanisms behind the remarkable performance of large language models in conversational recommendation. We analyze both the large language models' behaviors and the characteristics of the datasets, providing a holistic understanding of the models' effectiveness, limitations and suggesting directions for the design of future conversational recommenders|本文采用三个主要贡献的零击点模型对会话推荐任务进行了实证研究。(1)数据: 为了深入了解“野外”会话推荐场景中的模型行为，我们通过刮取一个流行的讨论网站，构建了一个新的推荐相关会话数据集。这是迄今为止最大的公共现实世界对话推荐数据集。(2)评估: 在新的数据集和两个现有的会话推荐数据集上，我们观察到即使没有微调，大型语言模型也能胜过现有的微调会话推荐模型。(3)分析: 我们提出了各种探究任务来研究大语言模型在会话推荐中显著表现的机制。我们分析了大型语言模型的行为和数据集的特点，为模型的有效性、局限性提供了全面的理解，并为未来会话推荐系统的设计提供了建议|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large+Language+Models+as+Zero-Shot+Conversational+Recommenders)|0|
|[Adaptive Multi-Modalities Fusion in Sequential Recommendation Systems](https://doi.org/10.1145/3583780.3614775)|Hengchang Hu, Wei Guo, Yong Liu, MinYen Kan|Huawei Noah's Ark Lab, Singapore, Singapore; National University of Singapore, Singapore, Singapore|In sequential recommendation, multi-modal information (e.g., text or image) can provide a more comprehensive view of an item's profile. The optimal stage (early or late) to fuse modality features into item representations is still debated. We propose a graph-based approach (named MMSR) to fuse modality features in an adaptive order, enabling each modality to prioritize either its inherent sequential nature or its interplay with other modalities. MMSR represents each user's history as a graph, where the modality features of each item in a user's history sequence are denoted by cross-linked nodes. The edges between homogeneous nodes represent intra-modality sequential relationships, and the ones between heterogeneous nodes represent inter-modality interdependence relationships. During graph propagation, MMSR incorporates dual attention, differentiating homogeneous and heterogeneous neighbors. To adaptively assign nodes with distinct fusion orders, MMSR allows each node's representation to be asynchronously updated through an update gate. In scenarios where modalities exhibit stronger sequential relationships, the update gate prioritizes updates among homogeneous nodes. Conversely, when the interdependent relationships between modalities are more pronounced, the update gate prioritizes updates among heterogeneous nodes. Consequently, MMSR establishes a fusion order that spans a spectrum from early to late modality fusion. In experiments across six datasets, MMSR consistently outperforms state-of-the-art models, and our graph propagation methods surpass other graph neural networks. Additionally, MMSR naturally manages missing modalities.|在顺序推荐中，多模态信息(例如文本或图像)可以提供一个更全面的项目配置文件视图。最佳阶段(早期或晚期)融合情态特征的项目表示仍然存在争议。我们提出了一种基于图的方法(命名为 MMSR) ，以自适应的顺序融合模态特征，使每个模态优先考虑其固有的顺序性质或其与其他模态的相互作用。MMSR 将每个用户的历史表示为一个图，其中用户历史序列中每个项目的模态特征由交叉链接的节点表示。同质节点之间的边表示模态内部的顺序关系，异质节点之间的边表示模态间的相互依赖关系。在图的传播过程中，MMSR 融合了双重注意，区分了同质和异质邻居。为了自适应地分配具有不同融合顺序的节点，MMSR 允许通过更新门异步更新每个节点的表示。在模式表现出更强的顺序关系的场景中，更新门优先更新同质节点。相反，当模式之间的相互依赖关系更加明显时，更新门优先考虑异构节点之间的更新。因此，MMSR 建立了一个从早期到晚期的融合序列。在跨六个数据集的实验中，MMSR 始终优于最先进的模型，我们的图传播方法优于其他图神经网络。此外，MMSR 自然会管理缺失的模式。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adaptive+Multi-Modalities+Fusion+in+Sequential+Recommendation+Systems)|0|
|[AdaMCT: Adaptive Mixture of CNN-Transformer for Sequential Recommendation](https://doi.org/10.1145/3583780.3614773)|Juyong Jiang, Peiyan Zhang, Yingtao Luo, Chaozhuo Li, Jae Boum Kim, Kai Zhang, Senzhang Wang, Xing Xie, Sunghun Kim||Sequential recommendation (SR) aims to model users' dynamic preferences from their historical interactions. Recently, Transformer and convolution neural network (CNNs) have shown great success in learning representations for SR. Nevertheless, Transformer mainly focus on capturing content-based global interactions, while CNNs effectively exploit local features in practical recommendation scenarios. Thus, how to effectively aggregate CNNs and Transformer to model both local and global dependencies of historical item sequence still remains an open challenge and is rarely studied in SR. To this regard, we inject locality inductive bias into Transformer by combining its global attention mechanism with a local convolutional filter, and adaptively determine the mixing importance on a personalized basis through a module- and layer-aware adaptive mixture units, named AdaMCT. Moreover, considering that softmax-based attention may encourage unimodal activation, we introduce the Squeeze-Excitation Attention (with sigmoid activation) into sequential recommendation to capture multiple relevant items (keys) simultaneously. Extensive experiments on three widely used benchmark datasets demonstrate that AdaMCT significantly outperforms the previous Transformer and CNNs based models by an average of 18.46% and 60.85% respectively in terms of NDCG@5 and achieves state-of-the-art performance.|序贯推荐(SR)的目的是根据用户的历史交互对其动态偏好进行建模。近年来，变压器和卷积神经网络(CNN)在 SR 的学习表征方面取得了很大的成功。尽管如此，Transformer 主要关注于捕获基于内容的全局交互，而 CNN 在实际推荐场景中有效地利用了局部特征。因此，如何有效地聚合 CNN 和 Transformer 来模拟历史项目序列的局部和全局依赖关系仍然是一个开放的挑战，在 SR 中很少进行研究。为此，我们将变压器的全局注意机制与局部卷积滤波器相结合，将局部感应偏差注入变压器，并通过模块和层感知自适应混合单元 AdaMCT 自适应地确定混合重要性。此外，考虑到基于 softmax 的注意力可能会鼓励单峰激活，我们将挤压-兴奋注意力(具有乙状结肠激活)引入顺序推荐，以同时捕获多个相关项目(键)。在三个广泛使用的基准数据集上进行的大量实验表明，AdaMCT 在 NDCG@5方面的性能显著优于以前基于 former 和 CNN 的模型，平均分别为18.46% 和60.85% ，并且达到了最先进的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AdaMCT:+Adaptive+Mixture+of+CNN-Transformer+for+Sequential+Recommendation)|0|
|[AutoMRM: A Model Retrieval Method Based on Multimodal Query and Meta-learning](https://doi.org/10.1145/3583780.3614787)|Zhaotian Li, Binhang Qi, Hailong Sun, Xiang Gao|Beihang University, Beijing, China|With more and more Deep Neural Network (DNN) models are publicly available on model sharing platforms (e.g., HuggingFace), model reuse has become a promising way in practice to improve the efficiency of DNN model construction by avoiding the costs of model training. To that end, a pivotal step for model reuse is model retrieval, which facilitates discovering suitable models from a model hub that match the requirements of users. However, the existing model retrieval methods have inadequate performance and efficiency, since they focus on matching user requirements with the model names, and thus cannot work well for high-dimensional data such as images. In this paper, we propose a user-task-centric multimodal model retrieval method named AutoMRM. AutoMRM can retrieve DNN models suitable for the user's task according to both the dataset and description of the task. Moreover, AutoMRM utilizes meta-learning to retrieve models for previously unseen task queries. Specifically, given a task, AutoMRM extracts the latent meta-features from the dataset and description for training meta-learners offline and obtaining the representation of user task queries online. Experimental results demonstrate that AutoMRM outperforms existing model retrieval methods including the state-of-the-art method in both effectiveness and efficiency.|随着深度神经网络(DNN)模型在模型共享平台(如 HuggingFace)上的广泛应用，模型重用已成为提高 DNN 模型构建效率、避免模型训练成本的有效途径。为此，模型重用的关键步骤是模型检索，它有助于从模型中心发现符合用户需求的合适模型。然而，现有的模型检索方法由于侧重于匹配用户需求和模型名称，因此性能和效率不高，不能很好地适用于图像等高维数据。本文提出了一种以用户任务为中心的多模态模型检索方法 AutoMRM。AutoMRM 可以根据数据集和任务描述检索适合用户任务的 DNN 模型。此外，AutoMRM 利用元学习来检索以前未见到的任务查询的模型。具体来说，AutoMRM 从数据集中提取潜在的元特征，用于离线培训元学习者，并在线获取用户任务查询的表示。实验结果表明，AutoMRM 在有效性和效率方面都优于现有的模型检索方法，包括最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AutoMRM:+A+Model+Retrieval+Method+Based+on+Multimodal+Query+and+Meta-learning)|0|
|[Retrieving GNN Architecture for Collaborative Filtering](https://doi.org/10.1145/3583780.3615035)|Fengqi Liang, Huan Zhao, Zhenyi Wang, Wei Fang, Chuan Shi|Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Potsts and Telecommunications, Beijing, China; 4Paradigm, Beijing, China|Graph Neural Networks (GNNs) have been widely used in Collaborative Filtering (CF). However, when given a new recommendation scenario, the current options are either selecting from existing GNN architectures or employing Neural Architecture Search (NAS) to obtain a well-performing GNN model, both of which are expensive in terms of human expertise or computational resources.To address the problem, in this work,we propose a novel neural retrieval approach, dubbed RGCF, to search a well-performing architecture for GNN-based CF rapidly when handling new scenarios. Specifically, we design the neural retrieval approach based on meta-learning by developing two-level meta-features, ranking loss, and task-level data augmentation, and in a retrieval paradigm, RGCF can directly return a well-performing architecture given a new dataset (query), thus being efficient inherently. Experimental results on two mainstream tasks, i.e., rating prediction and item ranking, show that RGCF outperforms all models either by human-designed or NAS on two new datasets in terms of effectiveness and efficiency. Particularly, the efficiency improvement is significant, taking as an example that RGCF is 61.7-206.3x faster than a typical reinforcement learning based NAS approach on the two new datasets. Code and data are available at https://github.com/BUPT-GAMMA/RGCF.|图形神经网络(GNN)已广泛应用于协同过滤(CF)。然而，当给出一个新的推荐场景时，目前的选择要么是从现有的 GNN 架构中选择，要么是使用神经结构搜索(NAS)来获得一个性能良好的 GNN 模型，这两者在人类专业知识或计算资源方面都是昂贵的。为了解决这个问题，在这项工作中，我们提出了一种新的神经检索方法，称为 RGCF，在处理新的场景时快速搜索一个性能良好的基于 GNN 的 CF 架构。具体而言，我们通过开发两级元特征，排序丢失和任务级数据增强来设计基于元学习的神经检索方法，并且在检索范例中，RGCF 可以直接返回给定新数据集(查询)的性能良好的架构，从而本质上是有效的。在评分预测和项目排序这两个主流任务上的实验结果表明，RGCF 在两个新数据集上的有效性和效率均优于人工设计的或 NAS 的所有模型。特别是，效率的提高是显著的，例如在两个新的数据集上，RgCF 比典型的基于强化学习的 NAS 方法快61.7-206.3倍。代码和数据可在 https://github.com/bupt-gamma/rgcf 查阅。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Retrieving+GNN+Architecture+for+Collaborative+Filtering)|0|
|[AutoSeqRec: Autoencoder for Efficient Sequential Recommendation](https://doi.org/10.1145/3583780.3614788)|Sijia Liu, Jiahao Liu, Hansu Gu, Dongsheng Li, Tun Lu, Peng Zhang, Ning Gu|Independent, Seattle, WA, USA; Fudan University, Shanghai, China; Microsoft Research Asia, Shanghai, China|Sequential recommendation demonstrates the capability to recommend items by modeling the sequential behavior of users. Traditional methods typically treat users as sequences of items, overlooking the collaborative relationships among them. Graph-based methods incorporate collaborative information by utilizing the user-item interaction graph. However, these methods sometimes face challenges in terms of time complexity and computational efficiency. To address these limitations, this paper presents AutoSeqRec, an incremental recommendation model specifically designed for sequential recommendation tasks. AutoSeqRec is based on autoencoders and consists of an encoder and three decoders within the autoencoder architecture. These components consider both the user-item interaction matrix and the rows and columns of the item transition matrix. The reconstruction of the user-item interaction matrix captures user long-term preferences through collaborative filtering. In addition, the rows and columns of the item transition matrix represent the item out-degree and in-degree hopping behavior, which allows for modeling the user's short-term interests. When making incremental recommendations, only the input matrices need to be updated, without the need to update parameters, which makes AutoSeqRec very efficient. Comprehensive evaluations demonstrate that AutoSeqRec outperforms existing methods in terms of accuracy, while showcasing its robustness and efficiency.|顺序推荐通过建模用户的顺序行为来展示推荐项目的能力。传统方法通常将用户视为项目序列，忽略了它们之间的协作关系。基于图的方法利用用户-项目交互图来整合协作信息。然而，这些方法有时面临着时间复杂性和计算效率方面的挑战。为了解决这些局限性，本文提出了 AutoSeqRec，一个专门为顺序推荐任务设计的增量推荐模型。AutoSeqRec 基于自动编码器，在自动编码器体系结构中由一个编码器和三个解码器组成。这些组件同时考虑用户-项目交互矩阵和项目转移矩阵的行和列。用户-项目交互矩阵的重建通过协同过滤捕捉用户的长期偏好。此外，项目转移矩阵中的行和列表示项目的出度和内度跳跃行为，这允许对用户的短期兴趣进行建模。当进行增量建议时，只需要更新输入矩阵，而不需要更新参数，这使得 AutoSeqRec 非常高效。综合评估表明，AutoSeqRec 在准确性方面优于现有方法，同时展示了其健壮性和效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AutoSeqRec:+Autoencoder+for+Efficient+Sequential+Recommendation)|0|
|[MATA*: Combining Learnable Node Matching with A* Algorithm for Approximate Graph Edit Distance Computation](https://doi.org/10.1145/3583780.3614959)|Junfeng Liu, Min Zhou, Shuai Ma, Lujia Pan|Beihang University, Beijing, China; Huawei Noah's Ark Lab, Shenzhen, China|Graph Edit Distance (GED) is a general and domain-agnostic metric to measure graph similarity, widely used in graph search or retrieving tasks. However, the exact GED computation is known to be NP-complete. For instance, the widely used A* algorithms explore the entire search space to find the optimal solution which inevitably suffers scalability issues. Learning-based methods apply graph representation techniques to learn the GED by formulating a regression task, which can not recover the edit path and lead to inaccurate GED approximation (i.e., the predicted GED is smaller than the exact). To this end, in this work, we present a data-driven hybrid approach MATA* for approximate GED computation based on Graph Neural Networks (GNNs) and A* algorithms, which models from the perspective of learning to match nodes instead of directly regressing GED. Specifically, aware of the structure-dominant operations (i.e., node and edge insertion/deletion) property in GED computation, a structure-enhanced GNN is firstly designed to jointly learn local and high-order structural information for node embeddings for node matchings. Second, top-k candidate nodes are produced via a differentiable top-k operation to enable the training for node matchings, which is adhering to another property of GED, i.e., multiple optimal node matchings. Third, benefiting from the candidate nodes, MATA* only performs on the promising search directions, reaching the solution efficiently. Finally, extensive experiments show the superiority of MATA* as it significantly outperforms the combinatorial search-based, learning-based and hybrid methods and scales well to large-size graphs.|图形编辑距离(GED)是度量图形相似度的一种通用的领域不可知度量方法，广泛应用于图形搜索或检索任务中。然而，精确的 GED 计算是已知的 NP 完全的。例如，广泛使用的 A * 算法探索整个搜索空间，寻找不可避免地存在可伸缩性问题的最优解。基于学习的方法应用图表示技术，通过制定回归任务来学习 GED，回归任务不能恢复编辑路径并导致不精确的 GED 近似(即，预测的 GED 小于精确的 GED)。为此，本文提出了一种基于图神经网络(GNNs)和 A * 算法的数据驱动混合 MATA * 算法用于 GED 近似计算，该算法从学习匹配节点而不是直接回归 GED 的角度进行建模。针对 GED 计算中的结构主导操作(即节点和边插入/删除操作)特性，设计了一种结构增强的 GNN，用于联合学习节点嵌入的局部和高阶结构信息，实现节点匹配。其次，通过可微 top-k 操作生成 top-k 候选节点，从而实现节点匹配的训练，这符合 GED 的另一个特性，即多个最优节点匹配。第三，利用候选节点，MATA * 只执行有希望的搜索方向，有效地达到解决方案。最后，广泛的实验表明，MATA * 的优越性，因为它明显优于基于组合搜索，基于学习和混合方法和规模以及大型图。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MATA*:+Combining+Learnable+Node+Matching+with+A*+Algorithm+for+Approximate+Graph+Edit+Distance+Computation)|0|
|[Leveraging Event Schema to Ask Clarifying Questions for Conversational Legal Case Retrieval](https://doi.org/10.1145/3583780.3614953)|Bulou Liu, Yiran Hu, Qingyao Ai, Yiqun Liu, Yueyue Wu, Chenliang Li, Weixing Shen|Tsinghua University, Quan Cheng Laboratory, & Tsinghua University, Beijing, China; Tsinghua University, Beijing, China; Wuhan University, Wuhan, China|Legal case retrieval is a special IR task aiming to retrieve supporting cases for a given query case. Existing works have shown that conversational search paradigm can improve users' search experience in legal case retrieval. One of the keys to a practical conversational search system is how to ask high-quality clarifying questions to initiate conversations with users and understand their search intents. Recently, Large Language Models, such as ChatGPT and GPT-4, have shown superior ability in both open-domain QA and conversations with human. Thus it is natural to believe that they could be applied to legal conversational search as well. However, our preliminary study has shown that generating clarifying questions in legal conversational search with SOTA LLMs (e.g., GPT-4) often suffers from several problems such as duplication and low-utility contents. To address these problems, we propose LeClari, which leverages legal event schema as external knowledge to instruct LLMs to generate effective clarifying questions for legal conversational search. LeClari is constructed with a prompt module and a novel legal event selection module. The former defines a prompt with legal events for clarifying question generation and the latter selects potential event types by modeling the relationships of legal event types, conversational context, and candidate cases. We also propose ranking-oriented rewards and employ the reward augmented maximum likelihood (RAML) method to optimize LeClari directly based on the final retrieval performance of the conversational legal search system. Empirical results over two widely adopted legal case retrieval datasets demonstrate the effectiveness of our approach as compared with the state-of-the-art baselines.|法律案例检索是一项特殊的信息检索任务，旨在为给定的查询案例检索支持案例。已有的研究表明，会话搜索范式可以提高用户在法律案件检索中的搜索体验。实际会话搜索系统的关键问题之一是如何提出高质量的澄清性问题来启动与用户的对话并理解他们的搜索意图。最近，大型语言模型，如 ChatGPT 和 GPT-4，在开放领域的 QA 和与人类的对话方面表现出了卓越的能力。因此，很自然地认为，它们也可以应用于合法的会话搜索。然而，我们的初步研究表明，在使用 SOTA LLM (例如，GPT-4)进行法律会话搜索时，产生澄清问题常常会遇到重复和低效用内容等问题。为了解决这些问题，我们提出了 LeClari，它利用法律事件模式作为外部知识，指导 LLM 为法律会话搜索生成有效的澄清问题。LeClari 由一个提示模块和一个新的法律事件选择模块构成。前者定义了一个带有法律事件的提示符，用于说明问题的产生，后者通过建模法律事件类型、会话语境和候选案例之间的关系来选择潜在的事件类型。我们还提出了面向排序的奖励方法，并利用奖励增加的最大似然(RAML)方法直接根据会话法律搜索系统的最终检索性能对 LeClari 进行优化。通过两个广泛采用的法律案例检索数据集的实证结果表明，与最先进的基线相比，我们的方法是有效的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Event+Schema+to+Ask+Clarifying+Questions+for+Conversational+Legal+Case+Retrieval)|0|
|[Diffusion Augmentation for Sequential Recommendation](https://doi.org/10.1145/3583780.3615134)|Qidong Liu, Fan Yan, Xiangyu Zhao, Zhaocheng Du, Huifeng Guo, Ruiming Tang, Feng Tian|Xi'an Jiaotong University, Xi'an, China; City University of Hong Kong, Hong Kong, Hong Kong; Xi'an Jiaotong University & City University of Hong Kong, Xi'an, China; Huawei Noah's Ark Lab, Shenzhen, China|Sequential recommendation (SRS) has become the technical foundation in many applications recently, which aims to recommend the next item based on the user's historical interactions. However, sequential recommendation often faces the problem of data sparsity, which widely exists in recommender systems. Besides, most users only interact with a few items, but existing SRS models often underperform these users. Such a problem, named the long-tail user problem, is still to be resolved. Data augmentation is a distinct way to alleviate these two problems, but they often need fabricated training strategies or are hindered by poor-quality generated interactions. To address these problems, we propose a Diffusion Augmentation for Sequential Recommendation (DiffuASR) for a higher quality generation. The augmented dataset by DiffuASR can be used to train the sequential recommendation models directly, free from complex training procedures. To make the best of the generation ability of the diffusion model, we first propose a diffusion-based pseudo sequence generation framework to fill the gap between image and sequence generation. Then, a sequential U-Net is designed to adapt the diffusion noise prediction model U-Net to the discrete sequence generation task. At last, we develop two guide strategies to assimilate the preference between generated and origin sequences. To validate the proposed DiffuASR, we conduct extensive experiments on three real-world datasets with three sequential recommendation models. The experimental results illustrate the effectiveness of DiffuASR. As far as we know, DiffuASR is one pioneer that introduce the diffusion model to the recommendation.|序贯推荐(SRS)已经成为许多应用程序的技术基础，其目的是根据用户的历史交互情况推荐下一个项目。然而，在推荐系统中，顺序推荐常常面临数据稀疏的问题。此外，大多数用户只与少数几个项目交互，但现有的 SRS 模型往往表现不佳。这样一个被称为长尾用户问题的问题仍有待解决。数据增强是缓解这两个问题的一种独特方式，但它们往往需要编造的培训策略，或者受到低质量生成的交互作用的阻碍。为了解决这些问题，我们提出了一种扩散增强的序列推荐(区分 ASR)为更高的质量生成。区分扩展数据集可以直接用于训练序列推荐模型，避免了复杂的训练过程。为了充分利用扩散模型的生成能力，我们首先提出了一种基于扩散的伪序列生成框架，以填补图像和序列生成之间的空白。然后，设计了一个序列 U-Net，使扩散噪声预测模型 U-Net 适应离散序列生成任务。最后，我们提出了两种引导策略来同化生成序列和起源序列之间的偏好。为了验证所提出的 DISUASR，我们使用三个连续的推荐模型在三个真实世界的数据集上进行了广泛的实验。实验结果表明了该方法的有效性。据我们所知，DISUASR 是将扩散模型引入推荐系统的先驱者之一。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Diffusion+Augmentation+for+Sequential+Recommendation)|0|
|[Deep Task-specific Bottom Representation Network for Multi-Task Recommendation](https://doi.org/10.1145/3583780.3614837)|Qi Liu, Zhilong Zhou, Gangwei Jiang, Tiezheng Ge, Defu Lian|University of Science and Technology of China, Hefei, China; Alibaba Group, Beijing, China|Neural-based multi-task learning (MTL) has gained significant improvement, and it has been successfully applied to recommendation system (RS). Recent deep MTL methods for RS (e.g. MMoE, PLE) focus on designing soft gating-based parameter-sharing networks that implicitly learn a generalized representation for each task. However, MTL methods may suffer from performance degeneration when dealing with conflicting tasks, as negative transfer effects can occur on the task-shared bottom representation. This can result in a reduced capacity for MTL methods to capture task-specific characteristics, ultimately impeding their effectiveness and hindering the ability to generalize well on all tasks. In this paper, we focus on the bottom representation learning of MTL in RS and propose the Deep Task-specific Bottom Representation Network (DTRN) to alleviate the negative transfer problem. DTRN obtains task-specific bottom representation explicitly by making each task has its own representation learning network in the bottom representation modeling stage. Specifically, it extracts the user's interests from multiple types of behavior sequences for each task through the parameter-efficient hypernetwork. To further obtain the dedicated representation for each task, DTRN refines the representation of each feature by employing a SENet-like network for each task. The two proposed modules can achieve the purpose of getting task-specific bottom representation to relieve tasks' mutual interference. Moreover, the proposed DTRN is flexible to combine with existing MTL methods. Experiments on one public dataset and one industrial dataset demonstrate the effectiveness of the proposed DTRN. Furthermore, we deploy DTRN in an industrial recommender system and gain remarkable improvements in multiple tasks.|基于神经网络的多任务学习(MTL)已经取得了显著的进步，并已成功地应用于推荐系统(RS)。最近的 RS 深层 MTL 方法(例如 MMoE，PLE)主要集中在设计基于软门控的参数共享网络，这种网络隐式地学习每个任务的通用表示。然而，MTL 方法在处理相互冲突的任务时可能会出现性能退化，因为任务共享的底层表示可能会受到负迁移效应的影响。这可能导致 MTL 方法捕获特定任务特征的能力下降，最终妨碍其有效性，并阻碍在所有任务中良好推广的能力。本文针对 RS 中 MTL 的底层表示学习问题，提出了基于深层任务的底层表示网络(DTRN)来解决负迁移问题。DTRN 通过在底层表示建模阶段使每个任务都有自己的表示学习网络，明确地获得任务特定的底层表示。具体来说，它通过参数有效的超网络从每个任务的多种类型的行为序列中提取用户的兴趣。为了进一步获得每个任务的专用表示，DTRN 通过为每个任务使用类似 SENet 的网络来改进每个特性的表示。这两个模块可以实现任务特定的底部表示，减少任务间的相互干扰。此外，提出的 DTRN 是灵活的结合现有的 MTL 方法。在一个公共数据集和一个工业数据集上的实验表明了所提出的 DTRN 方法的有效性。此外，我们在工业推荐系统部署 DTRN，并在多项任务中取得显著改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Task-specific+Bottom+Representation+Network+for+Multi-Task+Recommendation)|0|
|[Post-hoc Selection of Pareto-Optimal Solutions in Search and Recommendation](https://doi.org/10.1145/3583780.3615010)|Vincenzo Paparella, Vito Walter Anelli, Franco Maria Nardini, Raffaele Perego, Tommaso Di Noia|ISTI-CNR, Pisa, Italy; Politecnico di Bari, Bari, Italy|Information Retrieval (IR) and Recommender Systems (RS) tasks are moving from computing a ranking of final results based on a single metric to multi-objective problems. Solving these problems leads to a set of Pareto-optimal solutions, known as Pareto frontier, in which no objective can be further improved without hurting the others. In principle, all the points on the Pareto frontier are potential candidates to represent the best model selected with respect to the combination of two, or more, metrics. To our knowledge, there are no well-recognized strategies to decide which point should be selected on the frontier. In this paper, we propose a novel, post-hoc, theoretically-justified technique, named "Population Distance from Utopia" (PDU), to identify and select the one-best Pareto-optimal solution from the frontier. In detail, PDU analyzes the distribution of the points by investigating how far each point is from its utopia point (the ideal performance for the objectives). The possibility of considering fine-grained utopia points allows PDU to select solutions tailored to individual user preferences, a novel feature we call "calibration". We compare PDU against existing state-of-the-art strategies through extensive experiments on tasks from both IR and RS. Experimental results show that PDU and combined with calibration notably impact the solution selection. Furthermore, the results show that the proposed framework selects a solution in a principled way, irrespective of its position on the frontier, thus overcoming the limits of other strategies.|信息检索(IR)和推荐系统(RS)任务正在从计算基于单一指标的最终结果排序过渡到多目标问题。解决这些问题导致一组帕累托最优解，称为帕累托边界，其中没有一个目标可以进一步改进而不损害其他目标。原则上，Pareto 前沿上的所有点都是潜在的候选者，可以代表就两个或更多指标的组合而选择的最佳模型。据我们所知，没有公认的战略来决定哪一点应该选择在前沿。本文提出了一种新的、事后的、理论证明的技术，称为“距离乌托邦的人口距离”(PDU) ，从前沿中识别和选择一个最佳的帕累托最优解。具体来说，PDU 通过调查每个点离它的乌托邦点(目标的理想性能)有多远来分析这些点的分布。考虑细粒度乌托邦点的可能性允许 PDU 选择适合个人用户偏好的解决方案，这个新特性我们称之为“校准”。通过对 IR 和 RS 任务的大量实验，我们比较了 PDU 和现有的最新策略。实验结果表明，PDU 和标定相结合对解决方案的选择有显著影响。此外，结果表明，所提出的框架以原则性的方式选择解决方案，而不考虑其在前沿的位置，从而克服了其他战略的局限性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Post-hoc+Selection+of+Pareto-Optimal+Solutions+in+Search+and+Recommendation)|0|
|[MERIT: A Merchant Incentive Ranking Model for Hotel Search & Ranking](https://doi.org/10.1145/3583780.3614964)|Shigang Quan, Hailong Tan, Shui Liu, Zhenzhe Zheng, Ruihao Zhu, Liangyue Li, Quan Lu, Fan Wu|Shanghai Jiao Tong University, Shanghai, China; Alibaba Group, Hangzhou, China; Cornell University, Ithaca, NY, USA|Online Travel Platforms (OTPs) have been working on improving their hotel Search & Ranking (S&R) systems that facilitate efficient matching between consumers and hotels. Existing OTPs focus on improving platform revenue. In this work, we take a first step in incorporating hotel merchants' objectives into the design of hotel S&R systems to achieve an incentive loop: the OTP tilts impressions and better-ranked positions to merchants with high service quality, and in return, the merchants provide better service to consumers. Three critical design challenges need to be resolved to achieve this incentive loop: Matthew Effect in the consumer feedback-loop, unclear relation between hotel service quality and performance, and conflicts between platform revenue and consumer experience. To address these challenges, we propose MERIT, a MERchant InceTive ranking model, which can simultaneously take the interests of merchants and consumers into account. We introduce information about the hotel service quality at the input-output level. At the input level, we incorporate factors of hotel service quality as features (as the underlying reasons for service quality), while at the output level, we introduce the metric Hotel Rating Score (HRS) as a label (as the evaluated outcome of service quality). Also, we design a monotonic structure for Merchant Tower to provide a clear relation between hotel quality and performance. Finally, we propose a Multi-objective Stratified Pairwise Loss, which can mitigate the conflicts between OTP's revenue and consumer experience. To demonstrate the effectiveness of MERIT, we compare our method with several state-of-the-art benchmarks. The offline experiment results indicate that MERIT outperforms these methods in optimizing the demands of consumers and merchants. Furthermore, we conduct an online A/B test and obtain an improvement of 3.02% for the HRS score. Based on these results, we have deployed MERIT online on Fliggy, one of the most popular OTPs in China, to serve tens of millions of consumers and hundreds of thousands of hotel merchants. To address these challenges, we propose MERIT, a MER chant I nceT ive ranking model, which can simultaneously take the interests of merchants and consumers into account. We introduce information about the hotel service quality at the input-output level. At the input level, we incorporate factors of hotel service quality as features (as the underlying reasons for service quality), while at the output level, we introduce the metric Hotel Rating Score (HRS) as a label (as the evaluated outcome of service quality). Also, we design a monotonic structure for Merchant Tower to provide a clear relation between hotel quality and performance. Finally, we propose a Multi-objective Stratified Pairwise Loss, which can mitigate the conflicts between OTP's revenue and consumer experience. To demonstrate the effectiveness of MERIT, we compare our method with several state-of-the-art benchmarks. The offline experiment results indicate that MERIT outperforms these methods in optimizing the demands of consumers and merchants. Furthermore, we conduct an online A/B test and obtain an improvement of 3.02% for the HRS score. Based on these results, we have deployed MERIT online on Fliggy, one of the most popular OTPs in China, to serve tens of millions of consumers and hundreds of thousands of hotel merchants.|在线旅游平台(OTP)一直致力于改进其酒店搜索和排名(S & R)系统，以促进消费者和酒店之间的有效匹配。现有的 OTP 侧重于提高平台收入。在这项工作中，我们首先将酒店商家的目标融入到酒店 S & R 系统的设计中，以实现激励循环: OTP 向服务质量较高的商家倾斜印象和排名较高的位置，作为回报，商家为消费者提供更好的服务。要实现这种激励回路，需要解决三个关键的设计难题: 消费者反馈回路中的马太效应、酒店服务质量与绩效之间的模糊关系以及平台收入与消费者体验之间的冲突。为了应对这些挑战，我们提出 MERIT，一个 MERchant InceTive 排名模型，它可以同时考虑商家和消费者的利益。我们从投入产出的角度介绍酒店服务质量的信息。在输入层面，我们将酒店服务质量的因素作为特征(作为服务质量的根本原因) ，而在输出层面，我们引入度量酒店评分(HRS)作为标签(作为评估服务质量的结果)。此外，我们设计了一个单调的结构商务大厦，以提供一个明确的关系，酒店质量和性能。最后，我们提出了一个多目标成对分层损失模型，它可以缓解 OTP 的收入和消费者体验之间的冲突。为了证明 MERIT 的有效性，我们将我们的方法与几个最先进的基准进行比较。离线实验结果表明，MERIT 在优化消费者和商家需求方面优于这些方法。此外，我们进行了在线 A/B 测试，HRS 得分提高了3.02% 。基于这些结果，我们在中国最受欢迎的 OTP 之一 Fliggy 上部署了 MERIT 在线服务，为数千万消费者和数十万酒店商家提供服务。为了应对这些挑战，我们提出了 MERIT 模型，这是一个可以同时考虑商家和消费者利益的 MER 商号排名模型。我们从投入产出的角度介绍酒店服务质量的信息。在输入层面，我们将酒店服务质量的因素作为特征(作为服务质量的根本原因) ，而在输出层面，我们引入度量酒店评分(HRS)作为标签(作为评估服务质量的结果)。此外，我们设计了一个单调的结构商务大厦，以提供一个明确的关系，酒店质量和性能。最后，我们提出了一个多目标成对分层损失模型，它可以缓解 OTP 的收入和消费者体验之间的冲突。为了证明 MERIT 的有效性，我们将我们的方法与几个最先进的基准进行比较。离线实验结果表明，MERIT 在优化消费者和商家需求方面优于这些方法。此外，我们进行了在线 A/B 测试，HRS 得分提高了3.02% 。基于这些结果，我们在中国最受欢迎的 OTP 之一 Fliggy 上部署了 MERIT 在线服务，为数千万消费者和数十万酒店商家提供服务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MERIT:+A+Merchant+Incentive+Ranking+Model+for+Hotel+Search+&+Ranking)|0|
|[Enhancing Repeat-Aware Recommendation from a Temporal-Sequential Perspective](https://doi.org/10.1145/3583780.3614866)|Shigang Quan, Shui Liu, Zhenzhe Zheng, Fan Wu|Shanghai Jiao Tong University, Shanghai, China; Alibaba Group, Hangzhou, China|Repeat consumption, such as re-purchasing items and re-listening songs, is a common scenario in daily life. To model repeat consumption, the repeat-aware recommendation has been proposed to predict which item will be re-interacted based on the user-item interactions. In this paper, we investigate various inherent characteristics to enhance the performance of repeat-aware recommendation. Specifically, we explore these characteristics from two aspects: one is from the temporal aspect where we consider the time interval relationship in user behavior sequence; the other is from the sequential aspect where we consider the sequential-level relationship. Our intuition is that both thetemporal pattern andsequential pattern reflect users' intentions of repeat consumption. By utilizing these two patterns, a novel model called Temporal and Sequential repeat-aware Recommendation(TSRec for short) is proposed to enhance repeat-aware recommendation. TSRec has three main components: 1) User-specific Temporal Representation Module (UTRM), which encodes and extracts user historical repeat temporal information. 2) Item-specific Temporal Representation Module (ITRM), which incorporates item time interval information as side information to alleviate the data sparsity problem of user repeat behavior sequence. 3) Sequential Repeat-Aware Module (SRAM), which represents the similarity between user's current and the last repeat sequences. Extensive experimental results on three public benchmarks demonstrate the superiority of TSRec over state-of-the-art methods. The code is released online.|重复消费，例如重新购买物品和重新听歌，是日常生活中常见的情况。为了对重复消费进行建模，提出了基于重复感知的推荐方法来预测基于用户-项目交互的重复消费项目。为了提高重复感知推荐的性能，本文研究了重复感知推荐的各种内在特征。具体来说，我们从两个方面来探讨这些特征: 一个是从时间方面考虑用户行为序列中的时间间隔关系; 另一个是从序列方面考虑序列级关系。我们的直觉是，时间模式和序列模式都反映了用户的重复消费意图。利用这两种模式，提出了一种新的时序重复感知推荐(TSRec)模型来增强重复感知推荐。TSRec 主要由三部分组成: 1)用户特定时态表示模块(UTRM) ，对用户历史重复时态信息进行编码和提取。2)项目特定时间表示模块(ITRM) ，该模块将项目时间间隔信息作为侧信息，解决了用户重复行为序列的数据稀疏性问题。3)顺序重复感知模块(SRAM) ，表示用户当前重复序列与最后重复序列的相似性。在三个公共基准上的大量实验结果证明了 TSRec 相对于最先进的方法的优越性。代码已经在网上公布了。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Repeat-Aware+Recommendation+from+a+Temporal-Sequential+Perspective)|0|
|[ELTRA: An Embedding Method based on Learning-to-Rank to Preserve Asymmetric Information in Directed Graphs](https://doi.org/10.1145/3583780.3614862)|Masoud Reyhani Hamedani, JinSu Ryu, SangWook Kim|Hanyang University, Seoul, Republic of Korea|Double-vector embedding methods capture the asymmetric information in directed graphs first, and then preserve them in the embedding space by providingtwo latent vectors, i.e., source and target, per node. Although these methods are known to besuperior to the single-vector ones (i.e., providing asingle latent vector per node), wepoint out their three drawbacks as inability to preserve asymmetry on NU-paths, inability to preserve global nodes similarity, and impairing in/out-degree distributions. To address these, we first proposeCRW, anovel similarity measure for graphs that considers contributions ofboth in-links and out-links in similarity computation,without ignoring their directions. Then, we proposeELTRA, aneffective double-vector embedding method to preserve asymmetric information in directed graphs. ELTRA computesasymmetry preserving proximity scores (AP-scores) by employing CRW in which the contribution of out-links and in-links in similarity computation isupgraded anddowngraded, respectively. Then, for every node u, ELTRA selects its top-tclosest nodes based on AP-scores andconforms theranks of their corresponding target vectors w.r.t u's source vector in the embedding space to theiroriginal ranks. Our extensive experimental results withseven real-world datasets andsixteen embedding methods show that (1) CRWsignificantly outperforms Katz and RWR in computing nodes similarity in graphs, (2) ELTRAoutperforms the existing state-of-the-art methods in graph reconstruction, link prediction, and node classification tasks.|双向量嵌入方法首先捕获有向图中的不对称信息，然后通过每个节点提供源和目标两个潜在向量，将不对称信息保存在嵌入空间中。尽管这些方法已知优于单向量方法(即每个节点提供单个潜在向量) ，但我们指出了它们的三个缺点，即无法在 NU 路径上保持不对称性，无法保持全局节点相似性，以及损害/外度分布。为了解决这些问题，我们首先提出了 CRW，一种新的图的相似性度量，它考虑了相似性计算中的内链接和外链接的贡献，而没有忽略它们的方向。然后，我们提出了 ELTRA，一种有效的双向量嵌入方法来保持有向图中的不对称信息。ELTRA 通过使用 CRW 计算保持不对称性的邻近分数(AP 分数) ，其中外链和内链在相似性计算中的贡献分别被升级和降级。然后，对于每个节点 u，ELTRA 根据 AP 得分选择其最接近的节点，并将嵌入空间中相应的目标向量的排序与原始排序相一致。我们对7个实际数据集和16种嵌入方法的广泛实验结果表明: (1) CRW 在计算图中节点相似度方面明显优于 Katz 和 RWR; (2) ELTRAB 在图重构、链接预测和节点分类任务方面优于现有的最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ELTRA:+An+Embedding+Method+based+on+Learning-to-Rank+to+Preserve+Asymmetric+Information+in+Directed+Graphs)|0|
|[Periodicity May Be Emanative: Hierarchical Contrastive Learning for Sequential Recommendation](https://doi.org/10.1145/3583780.3615007)|Changxin Tian, Binbin Hu, Wayne Xin Zhao, Zhiqiang Zhang, Jun Zhou|Renmin University of China, Beijing, China; Ant Group, Hangzhou, China|Nowadays, contrastive self-supervised learning has been widely incorporated into sequential recommender systems. However, most existing contrastive sequential recommender systems simply emphasize the overall information of interaction sequences, thereby neglecting the special periodic patterns of user behavior. In this study, we propose that users exhibit emanative periodicity towards a group of correlated items, i.e., user behavior follow a certain periodic pattern while their interests may shift from one item to other related items over time. In light of this observation, we present a hierarchical contrastive learning framework to model EmAnative periodicity for SEquential Recommendation (referred to as EASE). Specifically, we design dual-channel contrastive strategy from the perspective of correlation and periodicity to capture emanative periodic patterns. Furthermore, we extend the traditional binary contrastive loss with hierarchical constraint to handle hierarchical contrastive samples, thus preserving the inherent hierarchical information of correlation and periodicity. Comprehensive experiments conducted on five datasets substantiate the effectiveness of our proposed EASE in improving sequential recommendation.|目前，对比自监督学习已广泛应用于顺序推荐系统中。然而，现有的对比序列推荐系统大多只强调交互序列的整体信息，而忽视了用户行为的特殊周期模式。在本研究中，我们提出使用者对一组相关项目表现出发射周期性，即使用者的兴趣可能随时间由一个项目转移至其他相关项目，使用者的行为仍遵循一定的周期性模式。根据这一观察，我们提出了一个层次对比学习框架来模拟顺序推荐的 EmAnative 周期性(简称 EASE)。具体来说，我们从相关性和周期性的角度设计了双通道对比策略来捕捉发射周期图案。在此基础上，将传统的具有层次约束的二进制对比度损失算法扩展到层次对比度样本的处理，从而保留了相关性和周期性的固有层次信息。在五个数据集上进行的综合实验证实了我们提出的 EASE 在改进顺序推荐方面的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Periodicity+May+Be+Emanative:+Hierarchical+Contrastive+Learning+for+Sequential+Recommendation)|0|
|[Diversity-aware Deep Ranking Network for Recommendation](https://doi.org/10.1145/3583780.3614848)|Zihong Wang, Yingxia Shao, Jiyuan He, Jinbao Liu, Shitao Xiao, Tao Feng, Ming Liu|Beijing University of Posts and Telecommunications, Beijing, China; Meituan Inc., Beijing, China|Diversity is a vital factor in recommendation systems.Improving the diversity in recommendations helps broaden users' horizons, bring good user experience and promote the enterprises' sales. In the past years, many efforts have been devoted to optimizing the diversity in the matching stage and the re-ranking stage of the recommendation system, but few in the ranking stage. The ranking stage is the intermediate stage of the recommendation system. Improving the diversity of the ranking stage can preserve the diversity of the matching stage, and provide a more diversified list for the re-ranking stage. Besides, the ranking models are able to achieve a better balance between accuracy and diversity. In this paper, we aim to improve the diversity in the ranking stage. To address the diversity challenges posed by the pointwise ranking model and biased user interaction history, we propose a Diversity-aware Deep Ranking Network by carefully designing two diversity-aware components that are diversity-aware listwise information fusion and balanced weighting loss. We conduct both offline and online experiments, and the results demonstrate that our proposed model effectively improves the recommendation diversity in the ranking stage while maintaining the accuracy. Moreover, the new model achieves 1.27%, 2.30% and 1.98% improvements in VBR, GMV and Coverage in Meituan, one of the world's largest E-commerce platforms.|多样性是推荐系统中的一个重要因素。提高推荐的多样性有助于拓宽用户的视野，带来良好的用户体验，促进企业的销售。近年来，在推荐系统的匹配阶段和重新排序阶段，人们致力于优化推荐系统的多样性，但在排序阶段却很少。排名阶段是推荐系统的中间阶段。提高排序阶段的多样性可以保持匹配阶段的多样性，为重排阶段提供更加多样化的列表。此外，排名模型能够在准确性和多样性之间取得更好的平衡。在本文中，我们的目标是提高排名阶段的多样性。针对逐点排序模型和有偏差的用户交互历史带来的多样性挑战，提出了一种多样性感知的深度排序网络，该网络通过精心设计两个多样性感知组件: 多样性感知列表信息融合和均衡加权损失。我们进行了离线和在线实验，结果表明，我们提出的模型有效地提高了排名阶段的推荐多样性，同时保持了准确性。此外，作为全球最大的电子商贸平台之一，新模式在视频比率、通用市场价格和美团覆盖率方面分别取得1.27% 、2.30% 和1.98% 的改善。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Diversity-aware+Deep+Ranking+Network+for+Recommendation)|0|
|[Sentiment-aware Review Summarization with Personalized Multi-task Fine-tuning](https://doi.org/10.1145/3583780.3615056)|Hongyan Xu, Hongtao Liu, Zhepeng Lv, Qing Yang, Wenjun Wang|Du Xiaoman Financial, Beijing, China; Tianjin University, Tianjin, China|Personalized review summarization is a challenging task in recommender systems, which aims to generate condensed and readable summaries for product reviews. Recently, some methods propose to adopt the sentiment signals of reviews to enhance the review summarization. However, most previous works only share the semantic features of reviews via preliminary multi-task learning, while ignoring the rich personalized information of users and products, which is crucial to both sentiment identification and comprehensive review summarization. In this paper, we propose a sentiment-aware review summarization method with an elaborately designed multi-task fine-tuning framework to make full use of personalized information of users and products effectively based on Pretrained Language Models (PLMs). We first denote two types of personalized information including IDs and historical summaries to indicate their identification and semantics information respectively. Subsequently, we propose to incorporate the IDs of the user/product into the PLMs-based encoder to learn the personalized representations of input reviews and their historical summaries in a fine-tuning way. Based on this, an auxiliary context-aware review sentiment classification task and a further sentiment-guided personalized review summarization task are jointly learned. Specifically, the sentiment representation of input review is used to identify relevant historical summaries, which are then treated as additional semantic context features to enhance the summary generation process. Extensive experimental results show our approach could generate sentiment-consistent summaries and outperforms many competitive baselines on both review summarization and sentiment classification tasks.|在推荐系统中，个性化的评论摘要是一项具有挑战性的任务，它的目标是为产品评论生成简明易读的摘要。近年来，一些方法提出采用评论的情感信号来加强评论总结。然而，以往的研究大多只是通过初步的多任务学习来共享评论的语义特征，而忽略了用户和产品丰富的个性化信息，这对于情感识别和综合评论总结都是至关重要的。本文提出了一种基于预训练语言模型的情感感知评论摘要方法，该方法通过精心设计的多任务微调框架，有效地利用了用户和产品的个性化信息。我们首先表示两种类型的个性化信息，包括 ID 和历史汇总，分别表示它们的识别和语义信息。随后，我们建议将用户/产品的 ID 合并到基于 PLM 的编码器中，以微调的方式学习输入评论及其历史摘要的个性化表示。在此基础上，共同学习了一个辅助上下文感知的评论情感分类任务和一个进一步的情感引导的个性化评论摘要任务。具体来说，输入评论的情感表示被用来识别相关的历史摘要，然后将其作为额外的语义上下文特征来加强摘要的生成过程。广泛的实验结果表明，我们的方法可以产生情绪一致的摘要，并优于许多竞争基线审查摘要和情绪分类任务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sentiment-aware+Review+Summarization+with+Personalized+Multi-task+Fine-tuning)|0|
|[A Two-tier Shared Embedding Method for Review-based Recommender Systems](https://doi.org/10.1145/3583780.3614770)|Zhen Yang, Junrui Liu, Tong Li, Di Wu, Shiqiu Yang, Huan Liu|Beijing University of Technology, Beijing, China; Arizona State University, Tempe, AZ, USA|Reviews are valuable resources that have been widely researched and used to improve the quality of recommendation services. Recent methods use multiple full embedding layers to model various levels of individual preferences, increasing the risk of the data sparsity issue. Although it is a potential way to deal with this issue that models homophily among users who have similar behaviors, the existing approaches are implemented in a coarse-grained way. They calculate user similarities by considering the homophily in their global behaviors but ignore their local behaviors under a specific context. In this paper, we propose a two-tier shared embedding model (TSE), which fuses coarse- and fine-grained ways of modeling homophily. It considers global behaviors to model homophily in a coarse-grained way, and the high-level feature in the process of each user-item interaction to model homophily in a fine-grained way. TSE designs a whole-to-part principle-based process to fuse these ways in the review-based recommendation. Experiments on five real-world datasets demonstrate that TSE significantly outperforms state-of-the-art models. It outperforms the best baseline by 20.50% on the root-mean-square error (RMSE) and 23.96% on the mean absolute error (MAE), respectively. The source code is available at https://github.com/dianziliu/TSE.git.|评论是有价值的资源，已被广泛研究和用于提高推荐服务的质量。最近的方法使用多个完整的嵌入层来模拟不同层次的个人偏好，增加了数据稀疏问题的风险。尽管在具有相似行为的用户之间建模同质性是解决这个问题的一种潜在方法，但是现有的方法都是以粗粒度的方式实现的。它们通过考虑全局行为中的同质性来计算用户相似性，但是忽略了特定环境下的局部行为。本文提出了一种两层共享嵌入模型(TSE) ，它融合了粗粒度和细粒度同构建模方法。它考虑了全局行为的粗粒度同质性建模，考虑了每个用户项交互过程中的高层次特征的细粒度同质性建模。TSE 设计了一个基于整体到部分原则的过程，将这些方法融合到基于评论的推荐中。在五个真实世界数据集上的实验表明，TSE 显著优于最先进的模型。它在均方根差(RMSE)和平均绝对误差(MAE)方面分别比最佳基线高出20.50% 和23.96% 。源代码可在 https://github.com/dianziliu/tse.git 下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Two-tier+Shared+Embedding+Method+for+Review-based+Recommender+Systems)|0|
|[Improving Query Correction Using Pre-train Language Model In Search Engines](https://doi.org/10.1145/3583780.3614930)|Dezhi Ye, Bowen Tian, Jiabin Fan, Jie Liu, Tianhua Zhou, Xiang Chen, Mingming Li, Jin Ma|Tencent, Beijing, China|Query correction is a task that automatically detects and corrects errors in what users type into a search engine. Misspelled queries can lead to user dissatisfaction and churn. However, correcting a user query accurately is not an easy task. One major challenge is that a correction model must be capable of high-level language comprehension. Recently, pre-trained language models (PLMs) have been successfully applied to text correction tasks, but few works have been done on query correction. However, it is nontrivial to directly apply these PLMs to query correction in large-scale search systems due to the following challenging issues: 1) Expensive deployment. Deploying such a model requires expensive computations. 2) Lacking domain knowledge. A neural correction model needs massive training data to activate its power. To this end, we introduce KSTEM, a Knowledge-based Sequence To Edit Model for Chinese query correction. KSTEM transforms the sequence generation task into sequence tagging by mapping errors into five categories: KEEP, REPLACE, SWAP, DELETE, and INSERT, reducing computational complexity. Additionally, KSTEM adopts 2D position encoding, which is composed of the internal and external order of the words. Meanwhile, to compensate for the lack of domain knowledge, we propose a task-specific training paradigm for query correction, including edit strategy-based pre-training, user click-based post pre-train, and human label-based fine-tuning. Finally, we apply KSTEM to the industrial search system. Extensive offline and online experiments show that KSTEM significantly improves query correction performance. We hope that our experience will benefit frontier researchers.|查询纠正是一项自动检测和纠正用户在搜索引擎中输入的错误的任务。拼写错误的查询可能导致用户不满意和混乱。然而，准确地纠正用户查询并非易事。一个主要的挑战是，纠错模式必须能够高水平的语言理解。近年来，预训练语言模型(PLM)已经成功地应用于文本校正任务中，但在查询校正方面的研究还很少。然而，由于以下挑战性问题，直接应用这些 PLM 在大规模搜索系统中进行查询更正并非易事: 1)昂贵的部署。部署这样的模型需要昂贵的计算。2)缺乏领域知识。神经校正模型需要大量的训练数据来激活它的能量。为此，本文介绍了基于知识的汉语查询纠错序列编辑模型 KSTEM。KSTEM 通过将错误映射到 KEEP、 REPLACE、 SWAP、 DELETE 和 INSERT 五个类别，将序列生成任务转换为序列标记，降低了计算复杂度。此外，KSTEM 还采用了二维位置编码，由词的内部和外部顺序组成。同时，为了弥补领域知识的不足，本文提出了一种针对具体任务的查询修正训练范式，包括基于编辑策略的预训练、基于用户点击的后期预训练和基于人工标签的微调。最后，我们将 KSTEM 应用于产业搜索系统。大量的离线和在线实验表明，KSTEM 显著提高了查询纠错性能。我们希望我们的经验将有益于前沿研究人员。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Query+Correction+Using+Pre-train+Language+Model+In+Search+Engines)|0|
|[iHAS: Instance-wise Hierarchical Architecture Search for Deep Learning Recommendation Models](https://doi.org/10.1145/3583780.3614925)|Yakun Yu, Shiang Qi, Jiuding Yang, Liyao Jiang, Di Niu|University of Alberta, Edmonton, AB, Canada|Current recommender systems employ large-sized embedding tables with uniform dimensions for all features, leading to overfitting, high computational cost, and suboptimal generalizing performance. Many techniques aim to solve this issue by feature selection or embedding dimension search. However, these techniques typically select a fixed subset of features or embedding dimensions for all instances and feed all instances into one recommender model without considering heterogeneity between items or users. This paper proposes a novel instance-wise Hierarchical Architecture Search framework, iHAS, which automates neural architecture search at the instance level. Specifically, iHAS incorporates three stages: searching, clustering, and retraining. The searching stage identifies optimal instance-wise embedding dimensions across different field features via carefully designed Bernoulli gates with stochastic selection and regularizers. After obtaining these dimensions, the clustering stage divides samples into distinct groups via a deterministic selection approach of Bernoulli gates. The retraining stage then constructs different recommender models, each one designed with optimal dimensions for the corresponding group. We conduct extensive experiments to evaluate the proposed iHAS on two public benchmark datasets from a real-world recommender system. The experimental results demonstrate the effectiveness of iHAS and its outstanding transferability to widely-used deep recommendation models.|目前的推荐系统采用大型嵌入表，所有特征尺寸统一，导致拟合过度，计算成本高，泛化性能不理想。许多技术都是通过特征选择或嵌入维搜索来解决这一问题。然而，这些技术通常为所有实例选择固定的特性子集或嵌入维度，并将所有实例提供给一个推荐模型，而不考虑项目或用户之间的异构性。提出了一种新的实例级层次体系结构搜索框架 iHAS，该框架在实例级自动进行神经体系结构搜索。具体来说，iHAS 包括三个阶段: 搜索、集群和再培训。搜索阶段通过精心设计的带有随机选择和正则化子的伯努利门来确定不同场特征之间的最佳实例嵌入维数。在获得这些维度之后，聚类阶段通过贝努利门的确定性选择方法将样本划分为不同的组。然后再培训阶段构建不同的推荐模型，每个模型都为相应的群体设计了最优维度。我们进行了广泛的实验，以评估来自真实世界的两个公共基准数据集的 iHAS 推荐系统。实验结果表明了 iHAS 的有效性及其对广泛使用的深度推荐模型的突出可转移性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=iHAS:+Instance-wise+Hierarchical+Architecture+Search+for+Deep+Learning+Recommendation+Models)|0|
|[Search Result Diversification Using Query Aspects as Bottlenecks](https://doi.org/10.1145/3583780.3615050)|Puxuan Yu, Razieh Rahimi, Zhiqi Huang, James Allan|University of Massachusetts Amherst, Amherst, USA|We address some of the limitations of coverage-based search result diversification models, which often consist of separate components and rely on external systems for query aspects. To overcome these challenges, we introduce an end-to-end learning framework called DUB. Our approach preserves the intrinsic interpretability of coverage-based methods while enhancing diversification performance. Drawing inspiration from the information bottleneck method, we propose an aspect extractor that generates query aspect embeddings optimized as information bottlenecks for the task of diversified document re-ranking. Experimental results demonstrate that DUB outperforms state-of-the-art diversification models.|我们解决了基于覆盖率的搜索结果多样化模型的一些局限性，这些模型通常由单独的组件组成，并依赖于外部系统进行查询。为了克服这些挑战，我们引入了一个名为 DUB 的端到端学习框架。我们的方法保留了基于覆盖的方法的内在可解释性，同时增强了多样化性能。从信息瓶颈方法的启发出发，提出了一种方面提取器，该方面提取器生成的查询方面嵌入作为信息瓶颈进行优化，用于多样化的文档重排任务。实验结果表明，DUB 的性能优于国家的最先进的多元化模式。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Search+Result+Diversification+Using+Query+Aspects+as+Bottlenecks)|0|
|[Attention Calibration for Transformer-based Sequential Recommendation](https://doi.org/10.1145/3583780.3614785)|Peilin Zhou, Qichen Ye, Yueqi Xie, Jingqi Gao, Shoujin Wang, Jae Boum Kim, Chenyu You, Sunghun Kim|Yale University, New Haven, CT, USA; University of Technology Sydney, Sydney, Australia; The Hong Kong University of Science and Technology, Hong Kong, Hong Kong; Upstage, Hong Kong, Hong Kong; Peking University, Beijing, China; The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China|Transformer-based sequential recommendation (SR) has been booming in recent years, with the self-attention mechanism as its key component. Self-attention has been widely believed to be able to effectively select those informative and relevant items from a sequence of interacted items for next-item prediction via learning larger attention weights for these items. However, this may not always be true in reality. Our empirical analysis of some representative Transformer-based SR models reveals that it is not uncommon for large attention weights to be assigned to less relevant items, which can result in inaccurate recommendations. Through further in-depth analysis, we find two factors that may contribute to such inaccurate assignment of attention weights: sub-optimal position encoding and noisy input. To this end, in this paper, we aim to address this significant yet challenging gap in existing works. To be specific, we propose a simple yet effective framework called Attention Calibration for Transformer-based Sequential Recommendation (AC-TSR). In AC-TSR, a novel spatial calibrator and adversarial calibrator are designed respectively to directly calibrates those incorrectly assigned attention weights. The former is devised to explicitly capture the spatial relationships (i.e., order and distance) among items for more precise calculation of attention weights. The latter aims to redistribute the attention weights based on each item's contribution to the next-item prediction. AC-TSR is readily adaptable and can be seamlessly integrated into various existing transformer-based SR models. Extensive experimental results on four benchmark real-world datasets demonstrate the superiority of our proposed ACTSR via significant recommendation performance enhancements. The source code is available at https://github.com/AIM-SE/AC-TSR.|基于变压器的顺序推荐(SR)近年来兴起，自注意机制是其关键组成部分。人们普遍认为，自我注意能够有效地从一系列相互作用的项目中选择信息丰富的相关项目，通过学习这些项目的较大注意权重来进行下一个项目的预测。然而，这在现实中可能并不总是正确的。我们对一些有代表性的基于变压器的 SR 模型的实证分析表明，将大的注意力权重分配给相关性较低的项目并不罕见，这可能导致不准确的推荐。通过进一步的深入分析，我们发现了两个可能导致注意力权重分配不准确的因素: 次优位置编码和噪声输入。为此，在本文中，我们的目标是解决这一重大但具有挑战性的差距，在现有的工作。具体来说，我们提出了一个简单而有效的框架，称为基于变压器的顺序推荐注意力校正(AC-TSR)。在 AC-TSR 中，分别设计了一种新的空间校正器和对抗校正器，用于直接校正那些不正确分配的注意权重。前者旨在明确地捕捉项目之间的空间关系(即顺序和距离) ，以便更精确地计算注意力权重。后者的目的是重新分配注意权重的基础上，每个项目的贡献，下一个项目的预测。AC-TSR 很容易适应，可以无缝地集成到各种现有的基于变压器的 SR 模型中。在四个基准的真实世界数据集上的大量实验结果显示了我们提出的 ACTSR 通过显著的推荐性能增强的优越性。源代码可在 https://github.com/aim-se/ac-tsr 下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Attention+Calibration+for+Transformer-based+Sequential+Recommendation)|0|
|[HCL4QC: Incorporating Hierarchical Category Structures Into Contrastive Learning for E-commerce Query Classification](https://doi.org/10.1145/3583780.3614907)|Lvxing Zhu, Kexin Zhang, Hao Chen, Chao Wei, Weiru Zhang, Haihong Tang, Xiu Li|Tsinghua University, Shenzhen, China; Alibaba Group, Hangzhou, China|Query classification plays a crucial role in e-commerce, where the goal is to assign user queries to appropriate categories within a hierarchical product category taxonomy. However, existing methods rely on a limited number of words from the category description and often neglect the hierarchical structure of the category tree, resulting in suboptimal category representations. To overcome these limitations, we propose a novel approach named hierarchical contrastive learning framework for query classification (HCL4QC), which leverages the hierarchical category tree structure to improve the performance of query classification. Specifically, HCL4QC is designed as a plugin module that consists of two innovative losses, namely local hierarchical contrastive loss (LHCL) and global hierarchical contrastive loss (GHCL). LHCL adjusts representations of categories according to their positional relationship in the hierarchical tree, while GHCL ensures the semantic consistency between the parent category and its child categories. Our proposed method can be adapted to any query classification tasks that involve a hierarchical category structure. We conduct experiments on two real-world datasets to demonstrate the superiority of our hierarchical contrastive learning. The results demonstrate significant improvements in the query classification task, particularly for long-tail categories with sparse supervised information.|查询分类在电子商务中起着至关重要的作用，其目标是在分层的产品类别分类中将用户查询分配给适当的类别。然而，现有的方法仅仅依赖于类别描述中有限的词汇，往往忽略了类别树的层次结构，导致了类别表示的次优化。为了克服这些局限性，提出了一种新的查询分类层次对比学习框架(HCL4QC) ，该框架利用层次分类树结构来提高查询分类的性能。具体来说，HCL4QC 被设计成一个插件模块，由两个创新性的损失组成，即局部层次对比损失(LHCL)和全局层次对比损失(GHCL)。LHCL 根据类别在层次树中的位置关系来调整类别的表示，而 GHCL 保证了父类别与其子类别之间的语义一致性。该方法适用于任何涉及层次分类结构的查询分类任务。我们在两个真实世界的数据集上进行了实验，以验证我们的分层对比学习的优越性。实验结果表明，该算法在查询分类任务方面有明显的改进，特别是对于监督信息稀疏的长尾类别。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HCL4QC:+Incorporating+Hierarchical+Category+Structures+Into+Contrastive+Learning+for+E-commerce+Query+Classification)|0|
|[Non-Recursive Cluster-Scale Graph Interacted Model for Click-Through Rate Prediction](https://doi.org/10.1145/3583780.3615180)|Yuanchen Bei, Hao Chen, Shengyuan Chen, Xiao Huang, Sheng Zhou, Feiran Huang|Jinan University, Guangzhou, China; Zhejiang University, Hangzhou, China; The Hong Kong Polytechnic University, Hung Hom, Hong Kong|Extracting users' interests from their behavior, particularly their 1-hop neighbors, has been shown to enhance Click-Through Rate (CTR) prediction performance. However, online recommender systems impose strict constraints on the inference time of CTR models, which necessitates pruning or filtering users' 1-hop neighbors to reduce computational complexity. Furthermore, while the graph information of users and items has been proven effective in collaborative filtering models, recursive graph convolution can be computationally costly and expensive to implement. To address these challenges, we propose the Non-Recursive Cluster-scale Graph Interacted (NRCGI) model, which reorganizes graph convolutional networks in a non-recursive and cluster-scale view to enable CTR models to consider deep graph information with low computational cost. NRCGI employs non-recursive cluster-scale graph aggregation, which allows the online recommendation computational complexity to shrink from tens of thousands of items to tens to hundreds of clusters. Additionally, since NRCGI aggregates neighbors in a non-recursive view, each hop of neighbors has a clear physical meaning. NRCGI explicitly constructs meaningful interactions between the hops of neighbors of users and items to fully model users' intent towards the given item. Experimental results demonstrate that NRCGI outperforms state-of-the-art baselines in three public datasets and one industrial dataset while maintaining efficient inference.|从用户的行为中提取他们的兴趣，特别是他们的一跳邻居，已经被证明可以提高点进率(CTR)预测性能。然而，在线推荐系统对 CTR 模型的推理时间有严格的限制，为了降低计算复杂度，需要对用户的1跳邻居进行剪枝或过滤。此外，虽然用户和项目的图形信息已被证明在协同过滤模型中是有效的，递归图形卷积可能在计算上是昂贵的，实现起来也是昂贵的。为了解决这些挑战，我们提出了非递归聚类尺度图交互(NRCGI)模型，该模型以非递归和聚类尺度视图重新组织图卷积网络，以使 CTR 模型能够以低计算成本考虑深层图信息。NRCGI 采用非递归聚类规模的图聚合技术，使在线推荐计算复杂度从几万个项目减少到几十到几百个聚类。此外，由于 NRCGI 以非递归视图的形式聚合邻居，因此邻居的每个跃点都有明确的物理意义。NRCGI 显式地在用户和项目的邻居之间构造有意义的交互，以充分模拟用户对给定项目的意图。实验结果表明，在保持有效推理的同时，NRCGI 在三个公共数据集和一个工业数据集中的表现优于最先进的基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Non-Recursive+Cluster-Scale+Graph+Interacted+Model+for+Click-Through+Rate+Prediction)|0|
|[SAFE: Sequential Attentive Face Embedding with Contrastive Learning for Deepfake Video Detection](https://doi.org/10.1145/3583780.3615279)|Juho Jung, Chaewon Kang, Jeewoo Yoon, Simon S. Woo, Jinyoung Han|Sungkyunkwan University, Suwon, Republic of Korea; Sungkyunkwan University, Seoul, Republic of Korea; Raondata, Seoul, Republic of Korea|The emergence of hyper-realistic deepfake videos has raised significant concerns regarding their potential misuse. However, prior research on deepfake detection has primarily focused on image-based approaches, with little emphasis on video. With the advancement of generation techniques enabling intricate and dynamic manipulation of entire faces as well as specific facial components in a video sequence, capturing dynamic changes in both global and local facial features becomes crucial in detecting deepfake videos. This paper proposes a novel sequential attentive face embedding, SAFE, that can capture facial dynamics in a deepfake video. The proposed SAFE can effectively integrate global and local dynamics of facial features revealed in a video sequence using contrastive learning. Through a comprehensive comparison with the state-of-the-art methods on the DFDC (Deepfake Detection Challenge) dataset and the FaceForensic++ benchmark, we show that our model achieves the highest accuracy in detecting deepfake videos on both datasets.|超真实的深度假视频的出现引起了人们对其潜在滥用的严重关切。然而，先前对深度伪造检测的研究主要集中在基于图像的方法上，对视频的研究很少。随着生成技术的进步，可以对视频序列中的整个面部以及特定的面部组件进行复杂和动态的操作，捕捉全局和局部面部特征的动态变化成为检测深度伪造视频的关键。提出了一种新的序列注意人脸嵌入方法 SAFE，该方法可以在深度伪造视频中捕获人脸动态特征。该方法利用对比学习，有效地整合了视频序列中人脸特征的全局和局部动态特征。通过全面比较 DFDC 数据集和 FaceForensic + + 基准上的最新方法，我们表明我们的模型在两个数据集上检测深度伪造视频时达到了最高的准确性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SAFE:+Sequential+Attentive+Face+Embedding+with+Contrastive+Learning+for+Deepfake+Video+Detection)|0|
|[Can Embeddings Analysis Explain Large Language Model Ranking?](https://doi.org/10.1145/3583780.3615225)|Claudio Lucchese, Giorgia Minello, Franco Maria Nardini, Salvatore Orlando, Raffaele Perego, Alberto Veneri|Università Ca' Foscari Venezia, Venice, Italy; Ca' Foscari University of Venice, Venice, Italy; Institute of Information Science and Technologies "Alessandro Faedo" - National Research Council of Italy, Pisa, Italy; Ca' Foscari University of Venice & Institute of Information Science and Technologies, Venice, Italy|Understanding the behavior of deep neural networks for Information Retrieval (IR) is crucial to improve trust in these effective models. Current popular approaches to diagnose the predictions made by deep neural networks are mainly based on: i) the adherence of the retrieval model to some axiomatic property of the IR system, ii) the generation of free-text explanations, or iii) feature importance attributions. In this work, we propose a novel approach that analyzes the changes of document and query embeddings in the latent space and that might explain the inner workings of IR large pre-trained language models. In particular, we focus on predicting query/document relevance, and we characterize the predictions by analyzing the topological arrangement of the embeddings in their latent space and their evolution while passing through the layers of the network. We show that there exists a link between the embedding adjustment and the predicted score, based on how tokens cluster in the embedding space. This novel approach, grounded in the query and document tokens interplay over the latent space, provides a new perspective on neural ranker explanation and a promising strategy for improving the efficiency of the models and Query Performance Prediction (QPP).|理解信息检索深层神经网络的行为对于提高人们对这些有效模型的信任至关重要。目前流行的诊断深度神经网络预测的方法主要基于: i)检索模型对 IR 系统的某些公理化特性的依从性，ii)自由文本解释的生成，或 iii)特征重要性归属。在这项工作中，我们提出了一种新的方法，分析文档和查询嵌入的变化，在潜在的空间，这可能解释了内部工作的信息检索大型预训练语言模型。特别地，我们侧重于预测查询/文档的相关性，并且通过分析嵌入在其潜在空间中的拓扑排列以及它们在通过网络层时的演化来刻画预测的特征。基于标记在嵌入空间中的聚类，我们证明了嵌入调整和预测得分之间存在联系。该方法基于查询和文档标记在潜在空间上的相互作用，为神经排序解释提供了一个新的视角，为提高模型效率和查询性能预测(QPP)提供了一种有前途的策略。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Can+Embeddings+Analysis+Explain+Large+Language+Model+Ranking?)|0|
|[A Self-Learning Resource-Efficient Re-Ranking Method for Clinical Trials Search](https://doi.org/10.1145/3583780.3615174)|Maciej Rybinski, Vincent Nguyen, Sarvnaz Karimi|CSIRO, Sydney, Australia|Complex search scenarios, such as those in biomedical settings, can be challenging. One such scenario is matching a patient's profile to relevant clinical trials. There are multiple criteria that should match for a document (clinical trial) to be considered relevant to a query (patient's profile represented with an admission note). While different neural ranking methods have been proposed for searching clinical trials, resource-efficient approaches to ranker training are less studied. A resource-efficient method uses training data in moderation. We propose a self-learning reranking method that achieves results comparable to those of more complicated, fully supervised, systems. Our experiments demonstrate our method's robustness and competitiveness compared to the state-of-the-art approaches in clinical trial search.|复杂的搜索场景，例如在生物医学环境中，可能是具有挑战性的。其中一种情况是将患者的特征与相关的临床试验相匹配。有多个标准，应该匹配的文件(临床试验)被认为是相关的查询(病人的配置文件代表入院说明)。虽然不同的神经排序方法已被提出搜索临床试验，资源效率的方法排序训练的研究较少。一种节约资源的方法适度使用训练数据。我们提出了一种自学习重新排序的方法，实现的结果相当于那些更复杂的，完全监督的系统。我们的实验证明了我们的方法的稳健性和竞争力相比，在临床试验搜索的最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Self-Learning+Resource-Efficient+Re-Ranking+Method+for+Clinical+Trials+Search)|0|
|[Efficient Multi-Task Learning via Generalist Recommender](https://doi.org/10.1145/3583780.3615229)|Luyang Wang, Cangcheng Tang, Chongyang Zhang, Jun Ruan, Kai Huang, Jason Jinquan Dai|Intel Corporation, Santa Clara, CA, USA; Verizon, Boston, MA, USA; Verizon, Alpharetta, GA, USA; Verizon, Basking Ridge, NJ, USA|Multi-task learning (MTL) is a common machine learning technique that allows the model to share information across different tasks and improve the accuracy of recommendations for all of them. Many existing MTL implementations suffer from scalability issues as the training and inference performance can degrade with the increasing number of tasks, which can limit production use case scenarios for MTL-based recommender systems. Inspired by the recent advances of large language models, we developed an end-to-end efficient and scalable Generalist Recommender (GRec). GRec takes comprehensive data signals by utilizing NLP heads, parallel Transformers, as well as a wide and deep structure to process multi-modal inputs. These inputs are then combined and fed through a newly proposed task-sentence level routing mechanism to scale the model capabilities on multiple tasks without compromising performance. Offline evaluations and online experiments show that GRec significantly outperforms our previous recommender solutions. GRec has been successfully deployed on one of the largest telecom websites and apps, effectively managing high volumes of online traffic every day.|多任务学习(Multi-Task Learning，MTL)是一种常见的机器学习技术，它允许模型在不同的任务之间共享信息，并提高对所有任务的推荐的准确性。许多现有的 MTL 实现都存在可伸缩性问题，因为培训和推理性能可能随着任务数量的增加而下降，这可能会限制基于 MTL 的推荐系统的生产用例场景。受到大型语言模型最新进展的启发，我们开发了一个端到端高效且可扩展的通用推荐程序(Generalist Revimender，GRec)。GRec 利用自然语言处理(NLP)磁头、并联变压器以及广泛而深入的结构来处理多模态输入，从而获得全面的数据信号。然后，这些输入通过新提出的任务句子级路由机制进行组合和馈送，以在不影响性能的情况下扩展多任务的模型能力。脱机评估和在线实验表明，GRec 明显优于我们以前的推荐解决方案。GREc 已成功部署在世界上最大的电信网站和应用程序之一上，有效地管理了每天大量的在线流量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Multi-Task+Learning+via+Generalist+Recommender)|0|
|[MTKDN: Multi-Task Knowledge Disentanglement Network for Recommendation](https://doi.org/10.1145/3583780.3615271)|Haotian Wu, Bowen Xing, Ivor W. Tsang|Beijing Jiaotong University, CFAR, Agency for Science, Technology and Research, & IHPC, Agency for Science, Technology and Research, Beijing, China; University of Technology Sydney, CFAR, Agency for Science, Technology and Research, & IHPC, Agency for Science, Technology and Research, Sydney, NSW, Australia; CFAR, Agency for Science, Technology and Research & IHPC, Agency for Science, Technology and Research, Singapore, Singapore|Multi-task learning (MTL) is a widely adopted machine learning paradigm in recommender systems. However, existing MTL models often suffer from performance degeneration with negative transfer and seesaw phenomena. Some works attempt to alleviate the negative transfer and seesaw issues by separating task-specific and shared experts to mitigate the harmful interference between task-specific and shared knowledge. Despite the success of these efforts, task-specific and shared knowledge have still not been thoroughly decoupled. There may still exist unnecessary mixture between the shared and task-specific knowledge, which may harm MLT models' performances. To tackle this problem, in this paper, we propose multi-task knowledge disentanglement network (MTKDN) to further reduce harmful interference between the shared and task-specific knowledge. Specifically, we propose a novel contrastive disentanglement mechanism to explicitly decouple the shared and task-specific knowledge in corresponding hidden spaces. In this way, the unnecessary mixture between shared and task-specific knowledge can be reduced. As for optimization objectives, we propose individual optimization objectives for shared and task-specific experts, by which we can encourage these two kinds of experts to focus more on extracting the shared and task-specific knowledge, respectively. Additionally, we propose a margin regularization to ensure that the fusion of shared and task-specific knowledge can outperform exploiting either of them alone. We conduct extensive experiments on open-source large-scale recommendation datasets. The experimental results demonstrate that MTKDN significantly outperforms state-of-the-art MTL models. In addition, the ablation experiments further verify the necessity of our proposed contrastive disentanglement mechanism and the novel loss settings.|多任务学习(MTL)是推荐系统中广泛采用的机器学习范式。然而，现有的 MTL 模型往往遭受性能退化的负转移和跷跷板现象。有些作品试图通过将具体任务专家和共享专家分开来缓解负面转移和跷跷板问题，以减轻具体任务专家和共享知识之间的有害干扰。尽管这些努力取得了成功，但特定任务和共享知识仍然没有完全解耦。共享知识和特定任务知识之间可能仍然存在不必要的混合，这可能会损害 MLT 模型的性能。为了解决这一问题，本文提出了多任务知识解缠网络(MTKDN) ，以进一步减少共享知识和特定任务知识之间的有害干扰。具体来说，我们提出了一种新的对比解缠机制，以显式解耦共享和任务特定的知识在相应的隐藏空间。通过这种方式，可以减少共享知识和特定任务知识之间不必要的混合。对于优化目标，我们提出了共享专家和任务特定专家的个体优化目标，通过这些目标可以鼓励这两类专家更多地关注共享知识和任务特定知识的提取。此外，我们提出了一个边际正则化，以确保融合共享和任务特定的知识可以胜过利用任何一个单独。我们在开源的大规模推荐数据集上进行了广泛的实验。实验结果表明，MTKDN 的性能明显优于最先进的 MTL 模型。此外，烧蚀实验进一步验证了我们提出的对比解缠机制和新型损耗设置的必要性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MTKDN:+Multi-Task+Knowledge+Disentanglement+Network+for+Recommendation)|0|
|[FiBiNet++: Reducing Model Size by Low Rank Feature Interaction Layer for CTR Prediction](https://doi.org/10.1145/3583780.3615242)|Pengtao Zhang, Zheng Zheng, Junlin Zhang|Sina Weibo, Beijing, China; Brandeis University, Waltham, MA, USA|Click-Through Rate (CTR) estimation has become one of the most fundamental tasks in many real-world applications and various deep models have been proposed. Some research has proved that FiBiNet is one of the best performance models and outperforms all other models on Avazu dataset. However, the large model size of FiBiNet hinders its wider application. In this paper, we propose a novel FiBiNet++ model to redesign FiBiNet's model structure, which greatly reduces model size while further improves its performance. One of the primary techniques involves our proposed "Low Rank Layer" focused on feature interaction, which serves as a crucial driver of achieving a superior compression ratio for models. Extensive experiments on three public datasets show that FiBiNet++ effectively reduces non-embedding model parameters of FiBiNet by 12x to 16x on three datasets. On the other hand, FiBiNet++ leads to significant performance improvements compared to state-of-the-art CTR methods, including FiBiNet. The source code is in https://github.com/recommendation-algorithm/FiBiNet.|点进率估计已经成为现实应用中最基本的任务之一，各种深度模型已经被提出。一些研究已经证明，FiBiNet 是最好的性能模型之一，在 Avazu 数据集上优于所有其他模型。然而，FiBiNet 的大型模型阻碍了它的广泛应用。本文提出了一种新的 FiBiNet + + 模型，重新设计了 FiBiNet 的模型结构，大大减小了模型尺寸，进一步提高了性能。其中一个主要的技术涉及我们提出的“低等级层”，重点是功能交互，这是一个关键的驱动器，以实现一个优越的压缩比模型。在三个公共数据集上进行的大量实验表明，FiBiNet + + 在三个数据集上有效地将 FiBiNet 的非嵌入模型参数减少了12 ~ 16倍。另一方面，与包括 FiBiNet 在内的最先进的 CTR 方法相比，FiBiNet + + 带来了显著的性能改进。源代码在 https://github.com/recommendation-algorithm/fibinet 里。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FiBiNet++:+Reducing+Model+Size+by+Low+Rank+Feature+Interaction+Layer+for+CTR+Prediction)|0|
|[Learning To Rank Diversely At Airbnb](https://doi.org/10.1145/3583780.3614692)|Malay Haldar, Mustafa Abdool, Liwei He, Dillon Davis, Huiji Gao, Sanjeev Katariya|Airbnb, Inc., San Francisco, CA, USA; Airbnb, Inc., San Jose, CA, USA; Airbnb, Inc., Sunnyvale, CA, USA; Airbnb, Inc., Cupertino, CA, USA; Airbnb, Inc., Seattle, WA, USA|Airbnb is a two-sided marketplace, bringing together hosts who own listings for rent, with prospective guests from around the globe. Applying neural network-based learning to rank techniques has led to significant improvements in matching guests with hosts. These improvements in ranking were driven by a core strategy: order the listings by their estimated booking probabilities, then iterate on techniques to make these booking probability estimates more and more accurate. Embedded implicitly in this strategy was an assumption that the booking probability of a listing could be determined independently of other listings in search results. In this paper we discuss how this assumption, pervasive throughout the commonly-used learning to rank frameworks, is false. We provide a theoretical foundation correcting this assumption, followed by efficient neural network architectures based on the theory. Explicitly accounting for possible similarities between listings, and reducing them to diversify the search results generated strong positive impact. We discuss these metric wins as part of the online A/B tests of the theory. Our method provides a practical way to diversify search results for large-scale production ranking systems.|Airbnb 是一个双面市场，汇集了拥有出租房源的房东，以及来自世界各地的潜在客户。将基于神经网络的学习应用于排序技术已经导致了客户与主机匹配方面的重大改进。排名方面的这些改进是由一个核心策略驱动的: 根据预订概率的估计对列表进行排序，然后迭代技术，使这些预订概率估计越来越准确。该策略隐含的假设是，一个列表的预订概率可以独立于搜索结果中的其他列表来确定。在本文中，我们将讨论这个贯穿于常用的对框架进行排序的学习过程中的假设是如何错误的。我们提供了一个理论基础，纠正这一假设，其次是有效的神经网络架构的基础上的理论。明确说明列表之间可能存在的相似之处，并减少列表数量以使搜索结果多样化，产生了强有力的积极影响。我们讨论这些度量胜利作为在线 A/B 理论测试的一部分。该方法为大规模生产排序系统提供了一种实用的搜索结果多样化方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+To+Rank+Diversely+At+Airbnb)|0|
|[Dynamic Group Parameter Modeling for Click-Through-Rate Prediction](https://doi.org/10.1145/3583780.3615471)|Xuan Ma, Jian Wang, Zhiyuan Chen, Zehua Zhang, Jie He, Changping Peng, Zhangang Lin, Jingping Shao|JD.com, Beijing, China|It is noted that Click-Through-Rate(CTR) prediction plays an important part in recommendation systems and online advertising. Over the past few years, numerous studies have been conducted to improve the accuracy of CTR prediction by exploring data inherent patterns. These studies indicate that training CTR models with group-specific parameters on divided data groups can lead to significant improvements. However, most works generally divide groups manually with some prior knowledge, and such a fixed group division method may hinder the expression of user common interests. To address this limitation, we propose a novel group parameter modeling method, where the user group division and group parameter learning processes are completed in an automatic and dynamic way. Our method employs a three-stage approach, consisting of group information selection, group representation learning, and group parameter generation, which allows the efficient expression of user common interests. We conduct experiments on both public datasets and industrial datasets, and the experimental results demonstrate the effectiveness of our method. We have also deployed the model in an online advertising system and observed significant improvements in both CTR and Revenue Per Mille (RPM).|点击率(CTR)预测在推荐系统和在线广告中起着重要作用。在过去的几年中，通过探索数据固有的模式，已经进行了大量的研究来提高 CTR 预测的准确性。这些研究表明，在分组的数据组上训练具有组特定参数的 CTR 模型可以导致显著的改进。然而，大多数工作一般都是利用一定的先验知识进行人工分组，这种固定的分组方法可能会阻碍用户共同兴趣的表达。针对这一局限性，提出了一种新的组参数建模方法，用户组划分和组参数学习过程可以自动动态地完成。我们的方法采用了三个阶段的方法，包括群体信息选择、群表示论学习和群体参数生成，这样可以有效地表达用户的共同兴趣。我们在公共数据集和工业数据集上进行了实验，实验结果表明了该方法的有效性。我们还在一个在线广告系统中部署了该模型，并观察到在点击率和每公里收入(RPM)方面的显著改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamic+Group+Parameter+Modeling+for+Click-Through-Rate+Prediction)|0|
|[Practice on Effectively Extracting NLP Features for Click-Through Rate Prediction](https://doi.org/10.1145/3583780.3614707)|Hao Yang, Ziliang Wang, Weijie Bian, Yifan Zeng|Shopee Discovery Ads, Beijing, China|Click-through rate (CTR) prediction is critical for industrial applications such as recommendation system and online advertising. Practically, there are a series of research proved that Natural Language Processing (NLP) features are helpful to improve CTR task performance. As these works show, there are different ways to extract NLP features. For example, keywords of item title are extracted as open-box feature by term frequency?inverse document frequency (tf-idf) method while item semantic embedding is extracted as black-box feature by shallow models (\emphe.g., word2vec) or deep learning models (e.g., BERT). However, these NLP models are pre-trained on NLP task, which is very different from the CTR task. Then it leads to the limited improvement of Area Under the ROC Curve (AUC) in CTR task. On the other hand, traditional NLP models for CTR task only consider open-box feature or black-box feature separately, which also leads to the discounted effect. Lastly, many NLP models are mainly used to extract semantic features only on item side. These methods take little account of user side information, or only IDs related features (\emphe.g., item's IDs) in user behavior sequence are introduced. In our work, we proposed a new network named BERT Attention method based on both Item and User information (BAIU). The target of BAIU is consistent with the CTR task, which is helpful to extract more effective NLP features. Also, both open-box and black-box features are simultaneously extracted by this network, which makes the model to learn more useful NLP features for CTR task and also makes the model more interpretable. Extensive experiments on both public data and our commercial data validate the effectiveness of our approach. Finally, the online experiment brings 2.2% gain of CTR on recommendation.|对于推荐系统和在线广告等工业应用而言，点进率(ctrl)预测至关重要。实践证明，自然语言处理(NLP)特性有助于提高 CTR 任务性能。正如这些工作所显示的，有不同的方法提取自然语言处理特征。例如，项目标题的关键词通过词频-逆文档频率(tf-idf)方法提取为开箱特征，而项目语义嵌入通过浅层模型(word2vec)或深层学习模型(BERT)提取为黑箱特征。然而，这些自然语言处理模型是在自然语言处理任务上进行预训练的，这与 CTR 任务有很大的不同。然后，它导致 ROC 曲线下面积(aUC)在 CTR 任务中的有限改进。另一方面，传统的点击率任务自然语言处理模型只考虑开箱特征和黑箱特征，这也导致了模型的折现效应。最后，许多自然语言处理模型主要用于仅在项目一侧提取语义特征。这些方法很少考虑用户端信息，或者只引入用户行为序列中与 ID 相关的特征(例如，项的 ID)。在我们的工作中，我们提出了一种新的基于项目和用户信息(BAIU)的网络方法—— BERT 注意方法。BAIU 的目标与 CTR 任务一致，有助于提取更有效的自然语言处理特征。该网络同时提取了开箱特征和黑箱特征，使模型学习到更多有用的自然语言处理特征，使模型更具可解释性。对公共数据和我们的商业数据的大量实验验证了我们的方法的有效性。最后，在线实验给推荐带来了2.2% 的点击率增益。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Practice+on+Effectively+Extracting+NLP+Features+for+Click-Through+Rate+Prediction)|0|
|[DiscoverPath: A Knowledge Refinement and Retrieval System for Interdisciplinarity on Biomedical Research](https://doi.org/10.1145/3583780.3614739)|YuNeng Chuang, Guanchu Wang, ChiaYuan Chang, KweiHerng Lai, Daochen Zha, Ruixiang Tang, Fan Yang, Alfredo CostillaReyes, Kaixiong Zhou, Xiaoqian Jiang, Xia Hu|Texas A&M University, College Station, TX, USA; Rice University, Houston, TX, USA; UTHealth at Houston, Houston, TX, USA|The exponential growth in scholarly publications necessitates advanced tools for efficient article retrieval, especially in interdisciplinary fields where diverse terminologies are used to describe similar research. Traditional keyword-based search engines often fall short in assisting users who may not be familiar with specific terminologies. To address this, we present a knowledge graph-based paper search engine for biomedical research to enhance the user experience in discovering relevant queries and articles. The system, dubbed DiscoverPath, employs Named Entity Recognition (NER) and part-of-speech (POS) tagging to extract terminologies and relationships from article abstracts to create a KG. To reduce information overload, DiscoverPath presents users with a focused subgraph containing the queried entity and its neighboring nodes and incorporates a query recommendation system, enabling users to iteratively refine their queries. The system is equipped with an accessible Graphical User Interface that provides an intuitive visualization of the KG, query recommendations, and detailed article information, enabling efficient article retrieval, thus fostering interdisciplinary knowledge exploration. DiscoverPath is open-sourced at https://github.com/ynchuang/DiscoverPath.|学术出版物的指数增长需要先进的工具来进行有效的文章检索，特别是在跨学科领域，在这些领域中，不同的术语被用来描述类似的研究。传统的基于关键字的搜索引擎往往不能帮助那些可能不熟悉特定术语的用户。为了解决这个问题，我们提供了一个基于知识图表的生物医学研究纸质搜索引擎，以增强用户发现相关查询和文章的体验。这个名为 Discover Path 的系统使用命名实体识别(NER)和词性标签(POS)从文章摘要中提取术语和关系来创建 KG。为了减少信息超载，Discover Path 为用户提供了一个包含被查询实体及其邻近节点的聚焦子图，并结合了一个查询推荐系统，使用户能够迭代地完善他们的查询。该系统配备了一个易于使用的图形用户界面，可以直观地显示幼稚园、查询建议和详细的文章信息，从而提供有效的文章检索，从而促进跨学科的知识探索。发现路径在 https://github.com/ynchuang/DiscoverPath 是开源的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DiscoverPath:+A+Knowledge+Refinement+and+Retrieval+System+for+Interdisciplinarity+on+Biomedical+Research)|0|
|[KuaiSAR: A Unified Search And Recommendation Dataset](https://doi.org/10.1145/3583780.3615123)|Zhongxiang Sun, Zihua Si, Xiaoxue Zang, Dewei Leng, Yanan Niu, Yang Song, Xiao Zhang, Jun Xu|Renmin Unversity of China, Beijing, China; Kuaishou Technology Co., Ltd, Beijing, China|The confluence of Search and Recommendation services is a vital aspect of online content platforms like Kuaishou and TikTok. The integration of S&R modeling is a highly intuitive approach adopted by industry practitioners. However, there is a noticeable lack of research conducted in this area within the academia, primarily due to the absence of publicly available datasets. Consequently, a substantial gap has emerged between academia and industry regarding research endeavors in this field. To bridge this gap, we introduce the first large-scale, real-world dataset KuaiSAR of integrated Search And Recommendation behaviors collected from Kuaishou, a leading short-video app in China with over 300 million daily active users. Previous research in this field has predominantly employed publicly available datasets that are semi-synthetic and simulated, with artificially fabricated search behaviors. Distinct from previous datasets, KuaiSAR records genuine user behaviors, the occurrence of each interaction within either search or recommendation service, and the users' transitions between the two services. This work aids in joint modeling of S&R, and the utilization of search data for recommenders (and recommendation data for search engines). Additionally, due to the diverse feedback labels of user-video interactions, KuaiSAR also supports a wide range of other tasks, including intent recommendation, multi-task learning, and long sequential multi-behavior modeling etc. We believe this dataset will facilitate innovative research and enrich our understanding of S&R services integration in real-world applications.|搜索和推荐服务的融合是 Kuaishou 和 TikTok 等在线内容平台的一个重要方面。S & R 建模的集成是业界从业人员采用的一种高度直观的方法。然而，学术界在这一领域明显缺乏研究，主要是由于缺乏公开可用的数据集。因此，在这个领域的研究工作方面，学术界和工业界之间出现了巨大的差距。为了弥补这一差距，我们介绍了第一个大规模的，真实世界的数据集 KuaiSAR 的集成搜索和推荐行为收集自 Kuaishou，一个领先的短视频应用程序在中国有超过3亿日活跃用户。以前在这个领域的研究主要使用公开可用的数据集，这些数据集是半合成的和模拟的，具有人为制造的搜索行为。与以前的数据集不同，KuaiSAR 记录了真实的用户行为、搜索或推荐服务中每个交互的发生情况以及用户在两个服务之间的转换。这项工作有助于 S & R 的联合建模，以及对推荐者的搜索数据(和搜索引擎的推荐数据)的利用。此外，由于用户与视频交互的反馈标签多种多样，KuaiSAR 还支持广泛的其他任务，包括意图推荐、多任务学习和长顺序多行为建模等。我们相信这个数据集将促进创新研究，丰富我们对现实世界应用中的 S & R 服务集成的理解。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KuaiSAR:+A+Unified+Search+And+Recommendation+Dataset)|0|
|[HyperBandit: Contextual Bandit with Hypernewtork for Time-Varying User Preferences in Streaming Recommendation](https://doi.org/10.1145/3583780.3614921)|Chenglei Shen, Xiao Zhang, Wei Wei, Jun Xu|Renmin University of China, Beijing, China; Huazhong University of Science and Technology, Wuhan, China|In real-world streaming recommender systems, user preferences often dynamically change over time (e.g., a user may have different preferences during weekdays and weekends). Existing bandit-based streaming recommendation models only consider time as a timestamp, without explicitly modeling the relationship between time variables and time-varying user preferences. This leads to recommendation models that cannot quickly adapt to dynamic scenarios. To address this issue, we propose a contextual bandit approach using hypernetwork, called HyperBandit, which takes time features as input and dynamically adjusts the recommendation model for time-varying user preferences. Specifically, HyperBandit maintains a neural network capable of generating the parameters for estimating time-varying rewards, taking into account the correlation between time features and user preferences. Using the estimated time-varying rewards, a bandit policy is employed to make online recommendations by learning the latent item contexts. To meet the real-time requirements in streaming recommendation scenarios, we have verified the existence of a low-rank structure in the parameter matrix and utilize low-rank factorization for efficient training. Theoretically, we demonstrate a sublinear regret upper bound against the best policy. Extensive experiments on real-world datasets show that the proposed HyperBandit consistently outperforms the state-of-the-art baselines in terms of accumulated rewards.|在现实世界的流媒体推荐系统中，用户的偏好通常会随着时间而动态变化(例如，用户在工作日和周末可能会有不同的偏好)。现有的基于盗贼的流媒体推荐模型只考虑时间作为时间戳，而没有明确建模时间变量和时变用户偏好之间的关系。这导致推荐模型不能快速适应动态场景。为了解决这个问题，我们提出了一种使用超网络的上下文绑架方法，称为 HyperBandit，它以时间特征作为输入，并动态调整推荐模型以适应时变的用户偏好。具体来说，HyperBandit 维护了一个神经网络，该网络能够生成用于估计时变奖励的参数，同时考虑到时间特征和用户偏好之间的相关性。利用估计的时变奖励，采用强盗策略，通过学习潜在项目上下文提出在线推荐。为了满足流媒体推荐场景的实时性要求，我们验证了参数矩阵中低秩结构的存在性，并利用低秩分解进行有效的训练。从理论上证明了最优策略的次线性后悔上界。在真实世界数据集上的大量实验表明，提出的 HyperBandit 在累积奖励方面始终优于最先进的基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HyperBandit:+Contextual+Bandit+with+Hypernewtork+for+Time-Varying+User+Preferences+in+Streaming+Recommendation)|0|
|[Dually Enhanced Delayed Feedback Modeling for Streaming Conversion Rate Prediction](https://doi.org/10.1145/3583780.3614856)|Sunhao Dai, Yuqi Zhou, Jun Xu, JiRong Wen|Renmin University of China, Beijing, China|In online industrial advertising systems, conversion actions (e.g., purchases or downloads) often occur significantly delayed, even up to several days or weeks after the user clicks. This phenomenon leads to the crucial challenge calleddelayed feedback problem in streaming CVR prediction, that is, the online systems cannot receive the true label of conversions immediately for continuous training. To mitigate the delayed feedback problem, recent state-of-the-art methods often apply sample duplicate mechanisms to introduce early certain conversion information. Nevertheless, these works have overlooked a crucial issue of rapid shifts in data distribution and considered both the newly observed data and duplicated early data together, resulting in biases in both distributions. In this work, we propose a Dually enhanced Delayed Feedback Model (DDFM), which tackles the above issues by treating the newly observed data and duplicated early data separately. DDFM consists of dual unbiased CVR estimators that share the same form but utilize different latent variables as weights: one for the newly observed data and the other for the duplicated early data. To avoid high variance, we adopt an addition-only formula for these latent variables, eliminating multiplication or division operations. Furthermore, we design a shared-bottom network that efficiently and jointly estimates the latent variables in DDFM. Theoretical analysis demonstrates the unbiasedness and convergence properties of DDFM. Extensive experiments on both public and industrial large-scale real-world datasets exhibit that our proposed DDFM consistently outperforms existing state-of-the-art methods.|在在线工业广告系统中，转换操作(例如购买或下载)经常出现明显延迟，甚至在用户点击后几天或几周。这种现象导致了流式 CVR 预测中的关键问题——延迟反馈问题，即在线系统不能立即得到连续训练所需的转换的真实标签。为了缓解延迟反馈问题，最新的技术方法通常应用样本重复机制来引入早期确定的转换信息。然而，这些工作忽略了数据分布快速变化的关键问题，同时考虑了新观测数据和重复的早期数据，导致两种分布的偏差。在这项工作中，我们提出了一个双增强延迟反馈模型(DDFM) ，它通过分别处理新观测数据和重复早期数据来解决上述问题。DDFM 由双无偏 CVR 估计器组成，它们具有相同的形式，但利用不同的潜变量作为权值: 一个用于新观测数据，另一个用于重复的早期数据。为了避免高方差，我们对这些潜在变量采用一个只加的公式，消除了乘法或除法运算。此外，我们还设计了一个共享底层网络，可以有效地联合估计 DDFM 中的潜变量。理论分析证明了 DDFM 的无偏性和收敛性。在公共和工业大规模真实世界数据集上的大量实验表明，我们提出的 DDFM 始终优于现有的最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dually+Enhanced+Delayed+Feedback+Modeling+for+Streaming+Conversion+Rate+Prediction)|0|
|[Knowledge-Aware Cross-Semantic Alignment for Domain-Level Zero-Shot Recommendation](https://doi.org/10.1145/3583780.3614945)|Junji Jiang, Hongke Zhao, Ming He, Likang Wu, Kai Zhang, Jianping Fan|University of Science and Technology of China & State Key Laboratory of Cognitive Intelligence, Hefei, China; Tianjin University, Tianjin, China; AI Lab at Lenovo Research, Beijing, China|Recommendation systems have attracted attention from academia and industry due to their wide range of application scenarios. However, cold start remains a challenging problem limited by sparse user interactions. Some scholars propose to transfer the dense information from the source domain to the target domain through cross-domain recommendation, but most of the work assumes that there is a small amount of historical interaction in the target domain. However, this approach essentially presupposes the existence of at least some historical interaction within the target domain. In this paper, we focus on the domain-level zero-shot recommendation (DZSR) problem. To address the above challenges, we propose a knowledge-aware cross-semantic alignment (K-CSA) framework to learn transferable source domain semantic information. The motivation is to establish stable alignments of interests in different domains through class semantic descriptions (CSDs). Specifically, due to the lack of effective information in the target domain, we learn semantic representations of source and target domain items based on knowledge graphs. Moreover, we conduct multi-view K-means to extract item CSDs from the learned semantic representations. Further, K-CSA learns universal user CSDs through the designed multi-head self-attention. To facilitate the transference of user interest from the source domain to the target domain, we devise a cross-semantic contrastive learning strategy, grounded in the prototype distribution matrix. We conduct extensive experiments on several real-world cross-domain datasets, and the experimental results clearly demonstrate the superiority of our proposed K-CSA compared with other baselines.|推荐系统由于其广泛的应用场景吸引了学术界和工业界的注意。然而，受稀疏用户交互的限制，冷启动仍然是一个具有挑战性的问题。一些学者提出通过跨域推荐将密集信息从源域转移到目标域，但大多数工作假设目标域中存在少量的历史交互。然而，这种方法基本上是以目标域内至少存在一些历史交互为前提的。本文主要研究领域级零拍推荐(DZSR)问题。为了应对上述挑战，我们提出了一个知识感知跨语义比对(k-CSA)框架来学习可转移源域语义信息。其动机是通过类语义描述(CSD)在不同领域建立稳定的兴趣对齐。具体来说，由于目标领域缺乏有效的信息，我们基于知识图学习源和目标领域项目的语义表示。此外，我们还进行了多视图 K- 均值从学习的语义表征中提取项目 CSD。此外，K-CSA 通过设计的多头自我注意来学习通用用户 CSD。为了促进用户兴趣从源域向目标域的转移，我们设计了一种基于原型分布矩阵的跨语义对比学习策略。我们在几个实际的跨域数据集上进行了广泛的实验，实验结果清楚地表明了我们提出的 K-CSA 相对于其他基线的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge-Aware+Cross-Semantic+Alignment+for+Domain-Level+Zero-Shot+Recommendation)|0|
|[Continuous Personalized Knowledge Tracing: Modeling Long-Term Learning in Online Environments](https://doi.org/10.1145/3583780.3614822)|Chunpai Wang, Shaghayegh Sahebi|University at Albany - SUNY, Albany, NY, USA; JPMorgan Chase & Co., New York, NY, USA|With the advance of online education systems, accessibility to learning materials has increased. In these systems, students can practice independently and learn from different learning materials over long periods of time. As a result, it is essential to trace students' knowledge states over long learning sequences while maintaining a personalized model of each individual student's progress. However, the existing deep learning-based knowledge tracing models are either not personalized or not tailored for handling long sequences. Handling long sequences are especially essential in the online education environments, in where models are preferred to be updated with the newly collected user data in a timely manner as students could acquire knowledge on each learning activity. In this paper, we propose a knowledge tracing model, Continuous Personalized Knowledge Tracing (CPKT), that can mimic the real-world long-term continuous learning scenario by incorporating a novel online model training paradigm that is suitable for the knowledge tracing problem. To achieve personalized knowledge tracing, we propose two model components: 1) personalized memory slots to maintain learner's knowledge in a lifelong manner, and 2) personalized user embeddings that help to accurately predict the individual responses, correctly detect the personalized knowledge acquisition and forgetting patterns, and better interpret and analyze the learner's progress. Additionally, we propose transition-aware stochastic shared embedding according to the learning transition matrix to regularize the online model training. Extensive experiments on four real-world datasets showcase the effectiveness and superiority of CPKT, especially for students with longer sequences.|随着在线教育系统的发展，获取学习材料的机会越来越多。在这些系统中，学生可以长时间独立练习和从不同的学习材料中学习。因此，在长时间的学习序列中追踪学生的知识状态，同时保持每个学生进步的个性化模型是至关重要的。然而，现有的基于深度学习的知识跟踪模型要么不个性化，要么不适合处理长序列。处理长序列在在线教育环境中尤为重要，在这种环境中，由于学生可以获得关于每项学习活动的知识，因此倾向于使用新收集的用户数据及时更新模型。在本文中，我们提出了一个知识跟踪模型，连续个性化知识跟踪(CPKT) ，它可以模拟真实世界的长期连续学习情景，通过引入一个新的在线模型训练范式，适合于知识跟踪问题。为了实现个性化的知识追踪，我们提出了两个模型组件: 1)个性化的记忆槽，以终身的方式维护学习者的知识; 2)个性化的用户嵌入，有助于准确预测个体的反应，正确检测个性化的知识获取和遗忘模式，并更好地解释和分析学习者的进步。此外，我们根据学习转移矩阵提出了具有过渡意识的随机共享嵌入，以规范在线模型训练。在四个实际数据集上的大量实验表明了 CPKT 的有效性和优越性，特别是对于序列较长的学生。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Continuous+Personalized+Knowledge+Tracing:+Modeling+Long-Term+Learning+in+Online+Environments)|0|
|[Modeling Preference as Weighted Distribution over Functions for User Cold-start Recommendation](https://doi.org/10.1145/3583780.3614972)|Jingxuan Wen, Huafeng Liu, Liping Jing|Beijing Jiaotong University, Beijing, China|=User cold-start recommendation is a well-known challenge in current recommender systems. The cause is that the number of user interactions is too few to accurately estimate user preferences. Furthermore, the uncertainty of user interactions intensifies along with the number of user interactions decreasing. Although existing meta-learning based models with globally sharing knowledge show good performance in most cold-start scenarios, the ability of handling challenges on intention importance and prediction uncertainty is missing: (1) Intra-user uncertainty. When estimating user preferences (reflected in the user's latent representation), each of user interactions is independently considered in the form of user-item pair, which cannot capture the correlation between user interactions, as well as considering the global intent under user interactions. (2) Inter-user importance. During the model training, all users are treated as equally important, which cannot distinguish the contribution of users in the model training process. Assigning the same weight to all users may lead to users with high uncertainty incorrectly guiding the model learning in the early stage of training. To tackle the above challenges, in this paper, we focus on modeling user preference as a weighted distribution over functions (WDoF) for user cold-start recommendation, which not only models the intra-user uncertainty through neural processes with Multinomial likelihood but also considers the importance of different users with curriculum learning during the model training process. Furthermore, we provide a theoretical explanation that why the proposed model performs better than regular neural processes based recommendation methods. Experiments on four real-world datasets demonstrate the effectiveness of the proposed model over several state-of-the-art cold-start recommendation methods.|= 用户冷启动推荐在当前的推荐系统中是一个众所周知的挑战。原因是用户交互的数量太少，无法准确估计用户偏好。此外，用户交互的不确定性随着用户交互次数的减少而增加。虽然现有的基于元学习的全局知识共享模型在大多数冷启动情景下表现出良好的性能，但缺乏处理意图重要性和预测不确定性挑战的能力: (1)用户内部的不确定性。在估计用户偏好时(反映在用户的潜在表示中) ，每个用户交互都以用户项对的形式独立考虑，不能捕获用户交互之间的相关性，也不能考虑用户交互下的全局意图。(2)用户之间的重要性。在模型训练过程中，所有用户都被视为同等重要的用户，不能区分用户在模型训练过程中的贡献。给所有用户赋予相同的权重可能会导致高不确定性用户在训练的早期阶段错误地指导模型学习。针对上述挑战，本文将用户偏好建模为用户冷启动推荐的加权函数分布(WDoF) ，不仅通过多项式似然的神经过程模拟用户内部的不确定性，而且在模型训练过程中考虑了不同用户课程学习的重要性。此外，我们提供了一个理论上的解释，为什么所提出的模型性能优于常规的神经过程为基础的推荐方法。在四个实际数据集上的实验结果表明了该模型对于几种最新的冷启动推荐方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modeling+Preference+as+Weighted+Distribution+over+Functions+for+User+Cold-start+Recommendation)|0|
|[Multimodal Optimal Transport Knowledge Distillation for Cross-domain Recommendation](https://doi.org/10.1145/3583780.3614983)|Wei Yang, Jie Yang, Yuan Liu|Institute of Automation, Chinese Academy of Sciences, Beijing, China; Tencent Technology, Beijing, China|Recommendation systems have been widely used in e-commerce, news media, and short video platforms. With the abundance of images, text, and audio information, users often engage in personalized interactions based on their multimodal preferences. With the continuous expansion of application scenarios, cross domain recommendation issues have become important, such as recommendations in both the public and private domains of e-commerce. The current cross domain recommendation methods have achieved certain results through methods such as shared encoders and contrastive learning. However, few studies have focused on the effective extraction and utilization of multimodal information in cross domain recommendations. Furthermore, due to the existence of distribution drift issues, directly constructing feature alignment between source domain and target domain representations is not an effective way. Therefore, we propose a Multimodal Optimal Transport Knowledge Distillation (MOTKD) method for cross domain recommendation. Specifically, we propose a multimodal graph attention network to model the multimodal preference representation of users. Then, we introduce a proxy distribution space as a bridge between the source and target domains. Based on the common proxy distribution, we utilize the optimal transport method to achieve cross domain knowledge transfer. Further, in order to improve the auxiliary training effect of source domain supervised signals on target domain, we design a multi-level cross domain knowledge distillation module. We conducted extensive experiments on two pairs of cross domain datasets composed of four datasets. The experimental results indicate that our proposed MOTKD method outperforms other state-of-the-art models.|推荐系统已广泛应用于电子商务、新闻媒体和短视频平台。随着丰富的图像，文字和音频信息，用户往往从事个性化的交互基于他们的多模态偏好。随着应用场景的不断扩展，跨域推荐问题变得越来越重要，例如电子商务的公共和私人领域的推荐。现有的跨域推荐方法通过共享编码器和对比学习等方法取得了一定的效果。然而，很少有研究关注跨领域推荐中多模态信息的有效提取和利用。此外，由于分布漂移问题的存在，直接构造源域和目标域表示之间的特征对齐并不是一种有效的方法。因此，我们提出了一种跨域推荐的多模式最优运输知识提取(MOTKD)方法。具体来说，我们提出了一个多模态图注意网络来模拟用户的多模态偏好表示。然后，引入一个代理分布空间作为源域和目标域之间的桥梁。在公共代理分布的基础上，利用最优传输方法实现跨领域的知识转移。进一步，为了提高源域监督信号对目标域的辅助训练效果，我们设计了一个多级跨域知识提取模块。我们对由四个数据集组成的两对跨域数据集进行了广泛的实验。实验结果表明，我们提出的 MOTKD 方法优于其他最先进的模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multimodal+Optimal+Transport+Knowledge+Distillation+for+Cross-domain+Recommendation)|0|
|[Task-Difficulty-Aware Meta-Learning with Adaptive Update Strategies for User Cold-Start Recommendation](https://doi.org/10.1145/3583780.3615074)|Xuhao Zhao, Yanmin Zhu, Chunyang Wang, Mengyuan Jing, Jiadi Yu, Feilong Tang|Shanghai Jiao Tong University, Shanghai, China|User cold-start recommendation is one of the most challenging problems that limit the effectiveness of recommender systems. Meta-learning-based methods are introduced to address this problem by learning initialization parameters for cold-start tasks. Recent studies attempt to enhance the initialization methods. They first represent each task by the cold-start user and interacted items. Then they distinguish tasks based on the task relevance to learn adaptive initialization. However, this manner is based on the assumption that user preferences can be reflected by the interacted items saliently, which is not always true in reality. In addition, we argue that previous approaches suffer from their adaptive framework (e.g., adaptive initialization), which reduces the adaptability in the process of transferring meta-knowledge to personalized RSs. In response to the issues, we propose a task-difficulty-aware meta-learning with adaptive update strategies (TDAS) for user cold-start recommendation. First, we design a task difficulty encoder, which can represent user preference salience, task relevance, and other task characteristics by modeling task difficulty information. Second, we adopt a novel framework with task-adaptive local update strategies by optimizing the initialization parameters with task-adaptive per-step and per-layer hyperparameters. Extensive experiments based on three real-world datasets demonstrate that our TDAS outperforms the state-of-the-art methods. The source code is available at https://github.com/XuHao-bit/TDAS.|用户冷启动推荐是限制推荐系统有效性的最具挑战性的问题之一。为了解决这个问题，引入了基于元学习的方法，学习冷启动任务的初始化参数。最近的研究试图改进初始化方法。它们首先由冷启动用户和交互项表示每个任务。然后根据任务相关性区分任务，学习自适应初始化。然而，这种方式是基于这样的假设，即用户的偏好可以通过交互的项显著地反映出来，这在现实中并不总是正确的。此外，我们认为以前的方法受到其自适应框架(例如，自适应初始化)的影响，这降低了元知识向个性化 RSS 传输过程中的适应性。针对这些问题，我们提出了一种基于任务难度感知的元学习算法，该算法采用自适应更新策略(TDAS)对用户进行冷启动推荐。首先，我们设计了一个任务难度编码器，通过对任务难度信息进行建模来表示用户偏好显著性、任务相关性等任务特征。其次，采用任务自适应局部更新策略，通过每步任务自适应和每层超参数对初始化参数进行优化，提出了一种新的任务自适应局部更新策略框架。基于三个真实世界数据集的大量实验表明，我们的 TDAS 优于最先进的方法。源代码可在 https://github.com/xuhao-bit/tdas 下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Task-Difficulty-Aware+Meta-Learning+with+Adaptive+Update+Strategies+for+User+Cold-Start+Recommendation)|0|
|[Retrievability Bias Estimation Using Synthetically Generated Queries](https://doi.org/10.1145/3583780.3615221)|Amin Abolghasemi, Suzan Verberne, Arian Askari, Leif Azzopardi|Leiden University, Leiden, Netherlands; University of Strathclyde, Glasgow, United Kingdom|Ranking with pre-trained language models (PLMs) has shown to be highly effective for various Information Retrieval tasks. Previous studies investigated the performance of these models in terms of effectiveness and efficiency. However, there is no prior work on evaluating PLM-based rankers in terms of their retrievability bias. In this paper, we evaluate the retrievability bias of PLM-based rankers with the use of synthetically generated queries. We compare the retrievability bias in two of the most common PLM-based rankers, a Bi-Encoder BERT ranker and a Cross-Encoder BERT re-ranker against BM25, which was found to be one of the least biased models in prior work. We conduct a series of experiments with which we explore the plausibility of using synthetic queries generated with a generative model, docT5query, in the evaluation of retrievability bias. Our experiments show promising results on the use of synthetically generated queries for the purpose of retrievability bias estimation. Moreover, we find that the estimated bias values resulting from synthetically generated queries are lower than the ones estimated with user-generated queries on the MS MARCO evaluation benchmark. This indicates that synthetically generated queries might cause less bias than user-generated queries and therefore, by using such queries in training PLM-based rankers, we might be able to reduce the retrievability bias in these models.|使用预先训练好的语言模型(PLM)进行排名已被证明对于各种信息检索任务非常有效。以往的研究从效能和效率的角度研究了这些模型的性能。然而，目前还没有关于评估基于 PLM 的排名在他们的检索偏差方面的工作。本文利用综合生成的查询来评估基于 PLM 的排序器的可检索性偏差。我们比较了两种最常见的基于 PLM 的排序器，双编码器 BERT 排序器和交叉编码器 BERT 重排序器对 BM25的可检索性偏差，这被发现是先前工作中偏差最小的模型之一。我们进行了一系列的实验，通过这些实验，我们探索了使用一个名为 doct5 query 的生成模型生成的合成查询来评估可检索性偏差的可行性。实验结果表明，综合生成的查询用于可检索性偏差估计具有良好的效果。此外，我们发现在 MS MARCO 评估基准上，由合成生成查询所得到的估计偏差值低于由用户生成查询所得到的估计偏差值。这表明综合生成的查询可能比用户生成的查询引起的偏差更小，因此，通过在训练基于 PLM 的排名中使用这样的查询，我们可能能够减少这些模型中的可检索性偏差。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Retrievability+Bias+Estimation+Using+Synthetically+Generated+Queries)|0|
|[On the Reliability of User Feedback for Evaluating the Quality of Conversational Agents](https://doi.org/10.1145/3583780.3615286)|Jordan Massiah, Emine Yilmaz, Yunlong Jiao, Gabriella Kazai|Amazon, London, United Kingdom; Amazon & University College London, London, United Kingdom|We analyse the reliability of users' explicit feedback for evaluating the quality of conversational agents. Using data from a commercial conversational system, we analyse how user feedback compares with human annotations; how well it aligns with implicit user satisfaction signals, such as retention; and how much user feedback is needed to reliably evaluate the quality of a conversational system.|我们分析了用户显性反馈对于评价会话代理质量的可靠性。使用来自商业会话系统的数据，我们分析了用户反馈与人工注释的比较; 它与隐含的用户满意信号(如保留)的匹配程度; 以及需要多少用户反馈才能可靠地评估会话系统的质量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+the+Reliability+of+User+Feedback+for+Evaluating+the+Quality+of+Conversational+Agents)|0|
|[SeqGen: A Sequence Generator via User Side Information for Behavior Sparsity in Recommendation](https://doi.org/10.1145/3583780.3615244)|Xu Min, Xiaolu Zhang, Bin Shen, Shuhan Wang, Yong He, Changsheng Li, Jun Zhou|Ant Group, Beijing, China; Beijing Institute of Technology, Beijing, China; Ant Group, Hangzhou, China|In real-world industrial advertising systems, user behavior sparsity is a key issue that affects online recommendation performance. We observe that users with rich behaviors can obtain better recommendation results than those with sparse behaviors in a conversion-rate (CVR) prediction model. Inspired by this phenomenon, we propose a new method SeqGen, in an effort to exploit user side information to bridge the gap between rich and sparse behaviors. SeqGen is a learnable and pluggable module, which can be easily integrated into any CVR model and no longer requires two-stage training as in previous works. In particular, SeqGen learns a mapping relationship between the user side information and behavior sequences, only on the basis of the users with long behavior sequences. After that, SeqGen can generate rich sequence features for users with sparse behaviors based on their side information, so as to alleviate the issue of user behavior sparsity. The generated sequence features will then be fed into the classifier tower of an arbitrary CVR model together with the original sequence features. To the best of our knowledge, our approach constitutes the first attempt to exploit user side information for addressing the user behavior sparsity issue. We validate the effectiveness of SeqGen on the publicly available dataset MovieLens-1M, and our method receives an improvement of up to 0.5% in terms of the AUC score. More importantly, we successfully deploy SeqGen in the commercial advertising system Xlight of Alipay, which improves the grouped AUC of the CVR model by 0.6% and brings a boost of 0.49% in terms of the conversion rate on A/B testing.|在现实工业广告系统中，用户行为稀疏性是影响在线推荐性能的关键问题。在 CVR 预测模型中，我们观察到行为丰富的用户比行为稀疏的用户获得更好的推荐结果。受到这一现象的启发，我们提出了一种新的方法 SeqGen，尝试利用用户端信息来弥补丰富和稀疏行为之间的差距。SeqGen 是一个可学习和可插拔的模块，它可以很容易地集成到任何 CVR 模型中，不再像以前的作品那样需要两阶段的培训。特别是，SeqGen 只在具有长行为序列的用户的基础上学习用户端信息和行为序列之间的映射关系。然后，SeqGen 可以根据用户的侧信息为稀疏行为的用户生成丰富的序列特征，从而缓解用户行为稀疏的问题。然后将生成的序列特征与原始序列特征一起反馈到任意 CVR 模型的分类器塔中。据我们所知，我们的方法是第一次尝试利用用户端信息来解决用户行为稀疏性问题。我们验证了 SeqGen 在公开数据集 MovieLens-1M 上的有效性，并且我们的方法在 AUC 评分方面获得了高达0.5% 的改善。更重要的是，我们成功地在支付宝的商业广告系统 Xlight 中部署了 SeqGen，它将 CVR 模型的分组 AUC 提高了0.6% ，在 A/B 测试中的转换率提高了0.49% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SeqGen:+A+Sequence+Generator+via+User+Side+Information+for+Behavior+Sparsity+in+Recommendation)|0|
|[Beyond Semantics: Learning a Behavior Augmented Relevance Model with Self-supervised Learning](https://doi.org/10.1145/3583780.3615457)|Zeyuan Chen, Wei Chen, Jia Xu, Zhongyi Liu, Wei Zhang|East China Normal University, Shanghai, China; Ant Group, Hangzhou, China|Relevance modeling aims to locate desirable items for corresponding queries, which is crucial for search engines to ensure user experience. Although most conventional approaches address this problem by assessing the semantic similarity between the query and item, pure semantic matching is not everything. In reality, auxiliary query-item interactions extracted from user historical behavior data of the search log could provide hints to reveal users' search intents further. Drawing inspiration from this, we devise a novel Behavior Augmented Relevance Learning model for Alipay Search (BARL-ASe) that leverages neighbor queries of target item and neighbor items of target query to complement target query-item semantic matching. Specifically, our model builds multi-level co-attention for distilling coarse-grained and fine-grained semantic representations from both neighbor and target views. The model subsequently employs neighbor-target self-supervised learning to improve the accuracy and robustness of BARL-ASe by strengthening representation and logit learning. Furthermore, we discuss how to deal with the long-tail query-item matching of the mini apps search scenario of Alipay practically. Experiments on real-world industry data and online A/B testing demonstrate our proposal achieves promising performance with low latency.|相关性建模的目的是为相应的查询定位合适的条目，这对于搜索引擎保证用户体验是至关重要的。尽管大多数传统的方法都是通过评估查询和条目之间的语义相似性来解决这个问题，但是纯语义匹配并不是一切。实际上，从搜索日志的用户历史行为数据中提取的辅助查询项交互可以为进一步揭示用户的搜索意图提供提示。基于此，我们设计了一种新的支付宝搜索行为增强关联学习模型(BARL-ASE) ，该模型利用目标项的邻居查询和目标查询的邻居查询来补充目标查询项语义匹配。具体来说，我们的模型建立了多级共注意，从邻居视图和目标视图中提取粗粒度和细粒度的语义表示。该模型随后采用邻居-目标自监督学习，通过加强表示和逻辑学习来提高 BARL-ASE 的准确性和鲁棒性。此外，本文还讨论了如何实际处理支付宝迷你应用搜索场景中的长尾查询项匹配问题。在现实工业数据和在线 A/B 测试中的实验表明，该方案具有良好的性能和较低的延迟。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Semantics:+Learning+a+Behavior+Augmented+Relevance+Model+with+Self-supervised+Learning)|0|
|[Entire Space Cascade Delayed Feedback Modeling for Effective Conversion Rate Prediction](https://doi.org/10.1145/3583780.3615475)|Yunfeng Zhao, Xu Yan, Xiaoqiang Gui, Shuguang Han, XiangRong Sheng, Guoxian Yu, Jufeng Chen, Zhao Xu, Bo Zheng|School of Software, Shandong University, Jinan, China; Alibaba Group, Hangzhou, China|Conversion rate (CVR) prediction is an essential task for large-scale e-commerce platforms. However, refund behaviors frequently occur after conversion in online shopping systems, which drives us to pay attention to effective conversion for building healthier shopping services. This paper defines the probability of item purchasing without any subsequent refund as an effective conversion rate (ECVR). A simple paradigm for ECVR prediction is to decompose it into two sub-tasks: CVR prediction and post-conversion refund rate (RFR) prediction. However, RFR prediction suffers from data sparsity (DS) and sample selection bias (SSB) issues, as the refund behaviors are only available after user purchase. Furthermore, there is delayed feedback in both conversion and refund events and they are sequentially dependent, named cascade delayed feedback (CDF), which significantly harms data freshness for model training. Previous studies mainly focus on tackling DS and SSB or delayed feedback for a single event. To jointly tackle these issues in ECVR prediction, we propose an Entire space CAscade Delayed feedback modeling (ECAD) method. Specifically, ECAD deals with DS and SSB by constructing two tasks including CVR prediction and conversion \& refund rate (CVRFR) prediction using the entire space modeling framework. In addition, it carefully schedules auxiliary tasks to leverage both conversion and refund time within data to alleviate CDF. Experimental results on the offline industrial dataset and online A/B testing demonstrate the effectiveness of ECAD. In addition, ECAD has been deployed in one of the recommender systems in Alibaba, contributing to a significant improvement of ECVR.|转化率(CVR)预测是大型电子商务平台的一项基本任务。然而，在网上购物系统中，退款行为经常发生在转换之后，这促使我们关注有效的转换以建立更健康的购物服务。本文将不随后退款的物品购买概率定义为有效转换率(ECVR)。ECVR 预测的一个简单范例是将其分解为两个子任务: CVR 预测和转换后退款率(RFR)预测。然而，RFR 预测存在数据稀疏(DS)和样本选择偏差(SSB)问题，因为退款行为只能在用户购买之后才能得到。此外，在转换事件和退款事件中都存在延迟反馈，并且它们是相互依赖的，称为级联延迟反馈(CDF) ，这严重损害了模型训练的数据新鲜度。以往的研究主要集中在处理 DS 和 SSB 或单个事件的延迟反馈。为了共同解决 ECVR 预测中的这些问题，我们提出了一种全空间级联延迟反馈建模(ECAD)方法。具体来说，ECAD 利用整个空间建模框架构造了 CVR 预测和转换退款率(CVRFR)预测两个任务来处理 DS 和 SSB。此外，它仔细地安排辅助任务，以利用数据中的转换和退款时间来缓解 CDF。离线工业数据集和在线 A/B 测试的实验结果证明了 ECAD 的有效性。此外，阿里巴巴其中一个推荐系统已采用 ECAD，有助显著改善 ECVR。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Entire+Space+Cascade+Delayed+Feedback+Modeling+for+Effective+Conversion+Rate+Prediction)|0|
|[MUSER: A Multi-View Similar Case Retrieval Dataset](https://doi.org/10.1145/3583780.3615125)|Qingquan Li, Yiran Hu, Feng Yao, Chaojun Xiao, Zhiyuan Liu, Maosong Sun, Weixing Shen|Tsinghua University, Beijing, China|Similar case retrieval (SCR) is a representative legal AI application that plays a pivotal role in promoting judicial fairness. However, existing SCR datasets only focus on the fact description section when judging the similarity between cases, ignoring other valuable sections (e.g., the court's opinion) that can provide insightful reasoning process behind. Furthermore, the case similarities are typically measured solely by the textual semantics of the fact descriptions, which may fail to capture the full complexity of legal cases from the perspective of legal knowledge. In this work, we present MUSER, a similar case retrieval dataset based on multi-view similarity measurement and comprehensive legal element with sentence-level legal element annotations. Specifically, we select three perspectives (legal fact, dispute focus, and law statutory) and build a comprehensive and structured label schema of legal elements for each of them, to enable accurate and knowledgeable evaluation of case similarities. The constructed dataset originates from Chinese civil cases and contains 100 query cases and 4,024 candidate cases. We implement several text classification algorithms for legal element prediction and various retrieval methods for retrieving similar cases on MUSER. The experimental results indicate that incorporating legal elements can benefit the performance of SCR models, but further efforts are still required to address the remaining challenges posed by MUSER. The source code and dataset are released at https://github.com/THUlawtech/MUSER.|类似案件检索(SCR)是一种具有代表性的法律人工智能应用，对促进司法公正起着举足轻重的作用。然而，现有的 SCR 数据集只集中在事实描述部分，当判断案件之间的相似性时，忽略了其他有价值的部分(例如，法院的意见) ，可以提供深刻的推理过程背后。此外，案件的相似性通常仅通过事实描述的文本语义来衡量，这可能无法从法律知识的角度捕捉到法律案件的全部复杂性。本文提出了一个基于多视图相似度量和综合法律要素的相似案例检索数据集 MUSER。具体来说，我们选取法律事实、争议焦点和法律成文法三个视角，为每一个视角建立一个全面而结构化的法律要素标签模式，以便能够准确而知识化地评价案件的相似性。所构建的数据集来源于中国民事案件，包含100个查询案件和4024个候选案件。在 MUSER 上实现了法律元素预测的文本分类算法和相似案例检索的各种检索方法。实验结果表明，纳入法律因素有利于可持续性研究模型的性能，但仍需作出进一步努力，以解决 MUSER 提出的其余挑战。源代码和数据集在 https://github.com/thulawtech/muser 发布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MUSER:+A+Multi-View+Similar+Case+Retrieval+Dataset)|0|
|[A Multi-Task Semantic Decomposition Framework with Task-specific Pre-training for Few-Shot NER](https://doi.org/10.1145/3583780.3614766)|Guanting Dong, Zechen Wang, Jinxu Zhao, Gang Zhao, Daichi Guo, Dayuan Fu, Tingfeng Hui, Chen Zeng, Keqing He, Xuefeng Li, Liwen Wang, Xinyue Cui, Weiran Xu|Beijing University of Posts and Telecommunications, Beijing, China; Meituan Group, Beijing, China|The objective of few-shot named entity recognition is to identify named entities with limited labeled instances. Previous works have primarily focused on optimizing the traditional token-wise classification framework, while neglecting the exploration of information based on NER data characteristics. To address this issue, we propose a Multi-Task Semantic Decomposition Framework via Joint Task-specific Pre-training (MSDP) for few-shot NER. Drawing inspiration from demonstration-based and contrastive learning, we introduce two novel pre-training tasks: Demonstration-based Masked Language Modeling (MLM) and Class Contrastive Discrimination. These tasks effectively incorporate entity boundary information and enhance entity representation in Pre-trained Language Models (PLMs). In the downstream main task, we introduce a multi-task joint optimization framework with the semantic decomposing method, which facilitates the model to integrate two different semantic information for entity classification. Experimental results of two few-shot NER benchmarks demonstrate that MSDP consistently outperforms strong baselines by a large margin. Extensive analyses validate the effectiveness and generalization of MSDP.|少镜头命名实体识别的目标是识别具有有限标记实例的命名实体。以往的工作主要集中在优化传统的标记分类框架，而忽视了基于 NER 数据特征的信息探索。针对这一问题，提出了一种基于联合任务特定预训练(MSDP)的多任务语义分解框架。借鉴基于演示和对比学习的方法，我们介绍了两种新颖的预训练任务: 基于演示的掩蔽语言建模(MLM)和类别对比鉴别。这些任务有效地整合了实体边界信息，增强了预训练语言模型(PLM)中的实体表示。在下游的主要任务中，我们引入了一个基于语义分解的多任务联合优化框架，该框架有利于模型集成两个不同的语义信息进行实体分类。两个短镜头 NER 基准测试的实验结果表明，MSDP 的性能始终大大优于强基准测试。广泛的分析验证了 MSDP 的有效性和推广性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Multi-Task+Semantic+Decomposition+Framework+with+Task-specific+Pre-training+for+Few-Shot+NER)|0|
|[CLSPRec: Contrastive Learning of Long and Short-term Preferences for Next POI Recommendation](https://doi.org/10.1145/3583780.3614813)|Chenghua Duan, Wei Fan, Wei Zhou, Hu Liu, Junhao Wen|Chongqing University, Chongqing, China|Next point-of-interest (POI) recommendation optimizes user travel experiences and enhances platform revenues by providing users with potentially appealing next location choices. In recent research, scholars have successfully mined users' general tastes and varying interests by modeling long-term and short-term check-in sequences. However, conventional methods for long and short-term modeling predominantly employ distinct encoders to process long and short-term interaction data independently, with disparities in encoders and data limiting the ultimate performance of these models. Instead, we propose a shared trajectory encoder and a novel Contrastive learning of Long and Short-term Preferences for next POI Recommendation (CLSPRec) model to better utilize the preference similarity among the same users and distinguish different users' travel preferences for more accurate next POI prediction. CLSPRec adopts a masking strategy in long-term sequences to enhance model robustness and further strengthens user representation through short-term sequences. Extensive experiments on three real-world datasets validate the superiority of our model. Our code is publicly available at https://github.com/Wonderdch/CLSPRec.|下一个兴趣点(Next Point-of-interest，POI)推荐通过为用户提供具有潜在吸引力的下一个地点选择，优化了用户的旅游体验，增强了平台收入。在最近的研究中，学者们通过建立长期和短期的签入序列模型，成功地挖掘了用户的一般品味和不同的兴趣。然而，用于长期和短期建模的传统方法主要使用不同的编码器来独立处理长期和短期的交互数据，编码器和数据的差异限制了这些模型的最终性能。相反，我们提出了一个共享的轨迹编码器和一个新的下一个 POI 推荐的长期和短期偏好对比学习(CLSPRec)模型，以更好地利用相同用户之间的偏好相似性，并区分不同用户的出行偏好，以便更准确地预测下一个 POI。CLSPRec 在长序列中采用掩蔽策略来增强模型的鲁棒性，并通过短序列进一步增强用户表示。在三个实际数据集上的大量实验验证了该模型的优越性。我们的代码可以在 https://github.com/wonderdch/clsprec 上公开获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CLSPRec:+Contrastive+Learning+of+Long+and+Short-term+Preferences+for+Next+POI+Recommendation)|0|
|[Predictive Uncertainty-based Bias Mitigation in Ranking](https://doi.org/10.1145/3583780.3615011)|Maria Heuss, Daniel Cohen, Masoud Mansoury, Maarten de Rijke, Carsten Eickhoff|University of Amsterdam, Amsterdam, Netherlands; University of Tübingen, Tübingen, Germany; Dataminr, NYC, NY, USA|Societal biases that are contained in retrieved documents have received increased interest. Such biases, which are often prevalent in the training data and learned by the model, can cause societal harms, by misrepresenting certain groups, and by enforcing stereotypes. Mitigating such biases demands algorithms that balance the trade-off between maximized utility for the user with fairness objectives, which incentivize unbiased rankings. Prior work on bias mitigation often assumes that ranking scores, which correspond to the utility that a document holds for a user, can be accurately determined. In reality, there is always a degree of uncertainty in the estimate of expected document utility. This uncertainty can be approximated by viewing ranking models through a Bayesian perspective, where the standard deterministic score becomes a distribution. In this work, we investigate whether uncertainty estimates can be used to decrease the amount of bias in the ranked results, while minimizing loss in measured utility. We introduce a simple method that uses the uncertainty of the ranking scores for an uncertainty-aware, post hoc approach to bias mitigation. We compare our proposed method with existing baselines for bias mitigation with respect to the utility-fairness trade-off, the controllability of methods, and computational costs. We show that an uncertainty-based approach can provide an intuitive and flexible trade-off that outperforms all baselines without additional training requirements, allowing for the post hoc use of this approach on top of arbitrary retrieval models.|检索到的文件中包含的社会偏见越来越受到关注。这样的偏见，通常在培训数据中普遍存在，并被模型学习到，通过歪曲特定群体和强制执行刻板印象，可能造成社会危害。减轻这种偏见需要算法，平衡之间的权衡最大效用的用户和公平的目标，激励无偏排名。先前关于减少偏差的工作通常假设排名分数，这对应于一个文档为用户持有的效用，可以被准确地确定。实际上，在预期文档效用的估计中总是存在一定程度的不确定性。这种不确定性可以通过贝叶斯透视图查看排名模型来近似化，其中标准的确定性得分成为一个分布。在这项工作中，我们调查是否不确定性估计可以用来减少排名结果中的偏差量，同时最小化测量效用的损失。我们介绍了一个简单的方法，使用不确定性的排名得分的不确定性的不确定性，事后的方法来减少偏见。在效用-公平权衡、方法的可控性和计算成本方面，我们将提出的方法与现有的减少偏差的基线进行了比较。我们展示了一个基于不确定性的方法可以提供一个直观和灵活的权衡，在没有额外的训练要求的情况下优于所有的基线，允许在任意检索模型之上事后使用这种方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Predictive+Uncertainty-based+Bias+Mitigation+in+Ranking)|0|
|[Single-User Injection for Invisible Shilling Attack against Recommender Systems](https://doi.org/10.1145/3583780.3615062)|Chengzhi Huang, Hui Li|Xiamen University, Xiamen, China|Recommendation systems (RS) are crucial for alleviating the information overload problem. Due to its pivotal role in guiding users to make decisions, unscrupulous parties are lured to launch attacks against RS to affect the decisions of normal users and gain illegal profits. Among various types of attacks, shilling attack is one of the most subsistent and profitable attacks. In shilling attack, an adversarial party injects a number of well-designed fake user profiles into the system to mislead RS so that the attack goal can be achieved. Although existing shilling attack methods have achieved promising results, they all adopt the attack paradigm of multi-user injection, where some fake user profiles are required. This paper provides the first study of shilling attack in an extremely limited scenario: only one fake user profile is injected into the victim RS to launch shilling attacks (i.e., single-user injection). We propose a novel single-user injection method SUI-Attack for invisible shilling attack. SUI-Attack is a graph based attack method that models shilling attack as a node generation task over the user-item bipartite graph of the victim RS, and it constructs the fake user profile by generating user features and edges that link the fake user to items. Extensive experiments demonstrate that SUI-Attack can achieve promising attack results in single-user injection. In addition to its attack power, SUI-Attack increases the stealthiness of shilling attack and reduces the risk of being detected. We provide our implementation at: https://github.com/KDEGroup/SUI-Attack.|推荐系统(RS)对于缓解信息超载问题至关重要。由于 RS 在引导用户做出决策方面发挥着关键作用，因此引诱不法分子对 RS 发起攻击，以影响正常用户的决策并获取非法利润。在各种类型的攻击中，先令攻击是最具生命力和最有利可图的攻击之一。在先令攻击中，敌对方向系统中注入大量精心设计的虚假用户资料，以误导 RS，从而达到攻击目的。现有的先令攻击方法虽然取得了良好的效果，但都采用了多用户注入的攻击范式，需要一些伪造的用户配置文件。本文提供了在极其有限的情况下的先令攻击的第一个研究: 只有一个假的用户配置文件被注入到受害者的 RS 发动先令攻击(即，单用户注入)。针对隐形先令攻击，提出了一种新的单用户注入方法 SUI- 攻击。SUI 攻击是一种基于图的攻击方法，在受害者 RS 的用户-项目二分图上将先令攻击建模为一个节点生成任务，通过生成用户特征和边将假用户与项目连接起来，构造假用户轮廓。大量的实验表明，SUI 攻击可以在单用户注入中获得良好的攻击效果。除了它的攻击威力，SUI 攻击增加了先令攻击的隐蔽性，并降低了被发现的风险。我们在以下 https://github.com/kdegroup/sui-attack 提供实施方案:。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Single-User+Injection+for+Invisible+Shilling+Attack+against+Recommender+Systems)|0|
|[Meta-Learning with Adaptive Weighted Loss for Imbalanced Cold-Start Recommendation](https://doi.org/10.1145/3583780.3614965)|Minchang Kim, Yongjin Yang, Jung Hyun Ryu, Taesup Kim|Seoul National University, Seoul, Republic of Korea|Sequential recommenders have made great strides in capturing a user's preferences. Nevertheless, the cold-start recommendation remains a fundamental challenge in which only a few user-item interactions are available for personalization. Gradient-based meta-learning approaches have recently emerged in the sequential recommendation field due to their fast adaptation and easy-to-integrate abilities. The meta-learning algorithms formulate the cold-start recommendation as a few-shot learning problem, where each user is represented as a task to be adapted. However, while meta-learning algorithms generally assume that task-wise samples are evenly distributed over classes or values, user-item interactions are not that way in real-world applications (e.g., watching favorite videos multiple times, leaving only good ratings and no bad ones). As a result, in the real-world, imbalanced user feedback that accounts for most task training data may dominate the user adaptation and prevent meta-learning algorithms from learning meaningful meta-knowledge for personalized recommendations. To alleviate this limitation, we propose a novel sequential recommendation framework based on gradient-based meta-learning that captures the imbalance of each user's rating distribution and accordingly computes adaptive loss for user-specific learning. It is the first work to tackle the impact of imbalanced ratings in cold-start sequential recommendation scenarios. We design adaptive weighted loss and improve the existing meta-learning algorithms for state-of-the-art sequential recommendation methods. Extensive experiments conducted on real-world datasets demonstrate the effectiveness of our framework.|顺序推荐系统在捕获用户的首选项方面取得了长足的进步。然而，冷启动建议仍然是一个根本性的挑战，因为只有少数用户项交互可用于个性化。基于梯度的元学习方法由于其快速的适应性和易于集成的能力，近年来出现在顺序推荐领域。元学习算法将冷启动推荐表示为一个短镜头学习问题，将每个用户表示为一个需要调整的任务。然而，虽然元学习算法通常假设任务智能样本均匀分布在类或值上，但在现实世界的应用程序中，用户项交互并非如此(例如，多次观看最喜欢的视频，只留下好的评分，没有坏的)。因此，在现实世界中，占用大多数任务训练数据的不平衡的用户反馈可能会主导用户适应性，并阻碍元学习算法学习有意义的元知识以获得个性化推荐。为了解决这一问题，本文提出了一种基于梯度元学习的顺序推荐框架，该框架能够捕捉每个用户评分分布的不平衡性，从而计算用户特定学习的自适应损失。这是第一个处理冷启动顺序推荐情景中评分不平衡的影响的工作。设计了自适应加权损失算法，并对现有的元学习算法进行了改进。在真实世界数据集上进行的大量实验证明了我们框架的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Meta-Learning+with+Adaptive+Weighted+Loss+for+Imbalanced+Cold-Start+Recommendation)|0|
|[Learning the Co-evolution Process on Live Stream Platforms with Dual Self-attention for Next-topic Recommendations](https://doi.org/10.1145/3583780.3614952)|HsuChao Lai, Philip S. Yu, JiunLong Huang|National Yang Ming Chiao Tung University, Hsinchu, Taiwan Roc; University of Illinois at Chicago, Chicago, IL, USA|Live stream platforms have gained popularity in light of emerging social media platforms. Unlike traditional on-demand video platforms, viewers and streamers on the live stream platforms are able to interact in real-time, and this makes viewer interests and live stream topics mutually affect each other on the fly, which is the unique co-evolution phenomenon on live stream platforms. In this paper, we make the first attempt to introduce a novel next-topic recommendation problem for the streamers, LSNR, which incorporates the co-evolution phenomenon. A novel framework CENTR introducing the Co-evolutionary Sequence Embedding Structure that captures the temporal relations of viewer interests and live stream topic sequences with two stacks of self-attention layers is proposed. Instead of learning the sequences individually, a novel dual self-attention mechanism is designed to model interactions between the sequences. The dual self-attention includes two modules, LCA and LVA, to leverage viewer loyalty to improve efficiency and flexibility. Finally, to facilitate cold-start recommendations for new streamers, a collaborative diffusion mechanism is implemented to improve a meta learner. Through the experiments in real datasets, CENTR outperforms state-of-the-art recommender systems in both regular and cold-start scenarios.|随着社交媒体平台的兴起，直播平台越来越受欢迎。与传统的视频点播平台不同，直播平台上的观众和流媒体可以实时互动，这使得观众的兴趣和直播话题在运动中相互影响，这是直播平台上独特的协同进化现象。在本文中，我们首次尝试引入一个新的流媒体下一主题推荐问题，LSNR，它结合了协同进化现象。提出了一种引入协同进化序列嵌入结构的新框架 CENTR，该结构能够捕获观看者兴趣与实时流主题序列之间的时间关系。提出了一种新的双重自我注意机制来模拟序列之间的相互作用，而不是单独学习序列。双重自我关注包括两个模块，LCA 和 LVA，以利用观众忠诚度，提高效率和灵活性。最后，为了促进新流媒体的冷启动建议，实现了一个协作扩散机制，以改善元学习者。通过在实际数据集中的实验，CENTR 在常规和冷启动情况下都优于最先进的推荐系统。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+the+Co-evolution+Process+on+Live+Stream+Platforms+with+Dual+Self-attention+for+Next-topic+Recommendations)|0|
|[HAMUR: Hyper Adapter for Multi-Domain Recommendation](https://doi.org/10.1145/3583780.3615137)|Xiaopeng Li, Fan Yan, Xiangyu Zhao, Yichao Wang, Bo Chen, Huifeng Guo, Ruiming Tang|City University of Hong Kong, Hong Kong, Hong Kong; Huawei Noah's Ark Lab, Shenzhen, China|Multi-Domain Recommendation (MDR) has gained significant attention in recent years, which leverages data from multiple domains to enhance their performance concurrently.However, current MDR models are confronted with two limitations. Firstly, the majority of these models adopt an approach that explicitly shares parameters between domains, leading to mutual interference among them. Secondly, due to the distribution differences among domains, the utilization of static parameters in existing methods limits their flexibility to adapt to diverse domains. To address these challenges, we propose a novel model Hyper Adapter for Multi-Domain Recommendation (HAMUR). Specifically, HAMUR consists of two components: (1). Domain-specific adapter, designed as a pluggable module that can be seamlessly integrated into various existing multi-domain backbone models, and (2). Domain-shared hyper-network, which implicitly captures shared information among domains and dynamically generates the parameters for the adapter. We conduct extensive experiments on two public datasets using various backbone networks. The experimental results validate the effectiveness and scalability of the proposed model.|多域推荐(MDR)近年来受到了广泛的关注，它利用来自多个域的数据来同时提高它们的性能。然而，当前的 MDR 模型面临两个限制。首先，这些模型中的大多数都采用了域之间显式共享参数的方法，导致了域之间的相互干扰。其次，由于领域之间的分布差异，现有方法中静态参数的使用限制了它们适应不同领域的灵活性。为了应对这些挑战，我们提出了一种新型的多域推荐超级适配器(HAMUR)模型。具体来说，HAMUR 由两部分组成: (1)。特定于领域的适配器，设计为可插入模块，可以无缝集成到各种现有的多领域主干模型，以及(2)。域共享超网络，它隐式地捕获域之间的共享信息并动态地生成适配器的参数。我们使用不同的骨干网络对两个公共数据集进行了广泛的实验。实验结果验证了该模型的有效性和可扩展性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HAMUR:+Hyper+Adapter+for+Multi-Domain+Recommendation)|0|
|[Prompt Distillation for Efficient LLM-based Recommendation](https://doi.org/10.1145/3583780.3615017)|Lei Li, Yongfeng Zhang, Li Chen|Hong Kong Baptist University, Hong Kong, Hong Kong; Rutgers University, New Brunswick, NJ, USA|Large language models (LLM) have manifested unparalleled modeling capability on various tasks, e.g., multi-step reasoning, but the input to these models is mostly limited to plain text, which could be very long and contain noisy information. Long text could take long time to process, and thus may not be efficient enough for recommender systems that require immediate response. In LLM-based recommendation models, user and item IDs are usually filled in a template (i.e., discrete prompt) to allow the models to understand a given task, but the models usually need extensive fine-tuning to bridge the user/item IDs and the template words and to unleash the power of LLM for recommendation. To address the problems, we propose to distill the discrete prompt for a specific task to a set of continuous prompt vectors so as to bridge IDs and words and to reduce the inference time. We also design a training strategy with an attempt to improve the efficiency of training these models. Experimental results on three real-world datasets demonstrate the effectiveness of our PrOmpt Distillation (POD) approach on both sequential recommendation and top-N recommendation tasks. Although the training efficiency can be significantly improved, the improvement of inference efficiency is limited. This finding may inspire researchers in the community to further improve the inference efficiency of LLM-based recommendation models.|大型语言模型(LLM)在多种任务(如多步推理)上表现出了无与伦比的建模能力，但是这些模型的输入大多局限于纯文本，这些文本可能非常长并且包含有噪声的信息。处理冗长的文本可能需要很长的时间，因此对于需要立即响应的推荐系统来说，效率可能不够高。在基于 LLM 的推荐模型中，用户和项目 ID 通常填写在一个模板中(即，离散提示符) ，以使模型能够理解给定的任务，但是模型通常需要大量的微调来连接用户/项目 ID 和模板词，并释放 LLM 的推荐功能。为了解决这个问题，我们提出将特定任务的离散提示提取到一组连续的提示向量中，从而桥接 ID 和单词，减少推理时间。我们还设计了一个训练策略，试图提高这些模型的训练效率。在三个实际数据集上的实验结果表明了本文提示精馏(POD)方法在顺序推荐和前 N 推荐任务上的有效性。虽然训练效率可以显著提高，但推理效率的提高是有限的。这一发现可能会激励社区研究人员进一步提高基于 LLM 的推荐模型的推理效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Prompt+Distillation+for+Efficient+LLM-based+Recommendation)|0|
|[Bias Invariant Approaches for Improving Word Embedding Fairness](https://doi.org/10.1145/3583780.3614792)|Siyu Liao, Ringting Zhang, Barbara Poblete, Vanessa Murdock|University of Chile & Amazon.com, Santiago, Chile; Amazon.com, Seattle, WA, USA|Many public pre-trained word embeddings have been shown to encode different types of biases. Embeddings are often obtained from training on large pre-existing corpora, and therefore resulting biases can be a reflection of unfair representations in the original data. Bias, in this scenario, is a challenging problem since current mitigation techniques require knowing and understanding existing biases in the embedding, which is not always possible. In this work, we propose to improve word embedding fairness by borrowing methods from the field of data privacy. The idea behind this approach is to treat bias as if it were a special type of training data leakage. This has the unique advantage of not requiring prior knowledge of potential biases in word embeddings. We investigated two types of privacy algorithms, and measured their effect on bias using four different metrics. To investigate techniques from differential privacy, we applied Gaussian perturbation to public pre-trained word embeddings. To investigate noiseless privacy, we applied vector quantization during training. Experiments show that both approaches improve fairness for commonly used embeddings, and additionally, noiseless privacy techniques reduce the size of the resulting embedding representation.|许多公开的预先训练的词语嵌入已经被证明可以编码不同类型的偏见。嵌入常常是通过对大型预先存在的语料库进行训练而获得的，因此产生的偏差可能是原始数据中不公平表示的反映。在这种情况下，偏差是一个具有挑战性的问题，因为当前的缓解技术需要了解和理解嵌入中存在的偏差，而这并不总是可能的。本文从数据隐私的角度出发，提出了一种改进嵌入公平性的方法。这种方法背后的思想是把偏差当作一种特殊类型的训练数据泄漏来处理。这样做的独特优点是不需要事先知道嵌入词中的潜在偏差。我们研究了两种类型的隐私算法，并使用四种不同的指标来测量它们对偏差的影响。为了研究基于差分隐私的嵌入技术，我们将高斯扰动应用于公共预先训练的单词嵌入。为了研究无声的私隐，我们在训练期间使用了向量量化。实验结果表明，这两种方法都提高了常用嵌入算法的公平性，并且无噪隐私技术减小了嵌入表示的大小。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bias+Invariant+Approaches+for+Improving+Word+Embedding+Fairness)|0|
|[PopDCL: Popularity-aware Debiased Contrastive Loss for Collaborative Filtering](https://doi.org/10.1145/3583780.3615009)|Zhuang Liu, Haoxuan Li, Guanming Chen, Yuanxin Ouyang, Wenge Rong, Zhang Xiong|Beihang University, Beijing, China|Collaborative filtering (CF) is the basic method for recommendation with implicit feedback. Recently, various state-of-the-art CF integrates graph neural networks. However, they often suffer from popularity bias, causing recommendations to deviate from users' genuine preferences. Additionally, several contrastive learning methods based on the in-batch sample strategy have been proposed to train the CF model effectively, but they are prone to suffering from sample bias. To address this problem, debiased contrastive loss has been employed in the recommendation, but instead of personalized debiasing, it treats each user equally. In this paper, we propose a popularity-aware debiased contrastive loss for CF, which can adaptively correct the positive and negative scores based on the popularity of users and items. Our approach aims to reduce the negative impact of popularity and sample bias simultaneously. We theoretically analyze the effectiveness of the proposed method and reveal the relationship between popularity and gradient, which justifies the correction strategy. We extensively evaluate our method on three public benchmarks over balanced and imbalanced settings. The results demonstrate its superiority over the existing debiased strategies, not only on the entire datasets but also when segmenting the datasets based on item popularity.|协同过滤(CF)是内隐反馈推荐的基本方法。最近，各种最先进的 CF 集成了图神经网络。然而，他们经常受到流行偏见的影响，导致推荐偏离用户的真实偏好。此外，为了有效地训练 CF 模型，人们提出了几种基于批内样本策略的对比学习方法，但这些方法容易产生样本偏差。为了解决这个问题，去偏对比度损失被用于推荐，但它不是个性化的去偏，它对每个用户一视同仁。本文提出了一种基于流行度的消偏对比度损失算法，该算法可以根据用户和项目的流行度自适应地修正正负分值。我们的方法旨在同时减少受欢迎程度和样本偏差的负面影响。从理论上分析了该方法的有效性，揭示了流行度与梯度的关系，从而验证了该方法的正确性。我们广泛评估我们的方法在三个公共基准平衡和不平衡的设置。实验结果表明，无论是在整个数据集上，还是在基于项目知名度的数据集分割上，该方法都优于现有的去偏策略。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PopDCL:+Popularity-aware+Debiased+Contrastive+Loss+for+Collaborative+Filtering)|0|
|[ForeSeer: Product Aspect Forecasting Using Temporal Graph Embedding](https://doi.org/10.1145/3583780.3614887)|Zixuan Liu, Gaurush Hiranandani, Kun Qian, Edward W. Huang, Yi Xu, Belinda Zeng, Karthik Subbian, Sheng Wang|University of Washington, Seattle, WA, USA; ; Amazon, Palo Alto, CA, USA; Amazon, Seattle, WA, USA|Developing text mining approaches to mine aspects from customer reviews has been well-studied due to its importance in understanding customer needs and product attributes. In contrast, it remains unclear how to predict the future emerging aspects of a new product that currently has little review information. This task, which we named product aspect forecasting, is critical for recommending new products, but also challenging because of the missing reviews. Here, we propose ForeSeer, a novel textual mining and product embedding approach progressively trained on temporal product graphs for this novel product aspect forecasting task. ForeSeer transfers reviews from similar products on a large product graph and exploits these reviews to predict aspects that might emerge in future reviews. A key novelty of our method is to jointly provide review, product, and aspect embeddings that are both time-sensitive and less affected by extremely imbalanced aspect frequencies. We evaluated ForeSeer on a real-world product review system containing 11,536,382 reviews and 11,000 products over 3 years. We observe that ForeSeer substantially outperformed existing approaches with at least 49.1\% AUPRC improvement under the real setting where aspect associations are not given. ForeSeer further improves future link prediction on the product graph and the review aspect association prediction. Collectively, Foreseer offers a novel framework for review forecasting by effectively integrating review text, product network, and temporal information, opening up new avenues for online shopping recommendation and e-commerce applications.|由于文本挖掘在理解客户需求和产品属性方面的重要性，开发从客户评论中挖掘方面的文本挖掘方法已经得到了很好的研究。相比之下，目前尚不清楚如何预测新产品的未来新出现的方面，目前几乎没有审查信息。这项任务，我们命名为产品方面的预测，是至关重要的推荐新产品，但也具有挑战性，因为缺少审查。在这里，我们提出了 ForeSeer，一种新的文本挖掘和产品嵌入方法，逐步训练的时间产品图为这种新的产品方面的预测任务。ForeSeer 将类似产品的评论转移到一个较大的产品图上，并利用这些评论来预测未来评论中可能出现的方面。我们的方法的一个关键的新颖之处是联合提供审查、产品和方面嵌入，它们都是时间敏感的，并且受极不平衡的方面频率的影响较小。我们在一个包含11,536,382个评论和11,000个产品的真实世界产品评论系统上对 ForeSeer 进行了评估。我们观察到 ForeSeer 在没有给出方面关联的实际情况下，至少有49.1% 的 AUPRC 改进，大大优于现有的方法。ForeSeer 进一步改进了产品图上的未来链接预测和评论方面的关联预测。通过有效地整合评论文本、产品网络和时间信息，为在线购物推荐和电子商务应用开辟了新的途径，Foreseer 提供了一个新颖的评论预测框架。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ForeSeer:+Product+Aspect+Forecasting+Using+Temporal+Graph+Embedding)|0|
|[Neural Personalized Topic Modeling for Mining User Preferences on Social Media](https://doi.org/10.1145/3583780.3614987)|Luyang Liu, Qunyang Lin, Haonan Tong, Hongyin Zhu, Ke Liu, Min Wang, Chuang Zhang|Inspur Electronic Information Industry Co., Ltd., Beijing, China|With the rapid development of web services, social media has been a prevalent and readily way for people to express themselves and share their daily lives. Consequently, numerous user-generated content is accumulated on social media platforms. These data usually contain rich information and knowledge for users, which is a viable source for user data mining. As one of the prevalent techniques in user data mining, mining personalized topics and discovering user preferences from social media data attract much interest in academic and industrial communities. The emerging Neural Topic Models(NTMs) have recently shown leading performance and scalability by employing neural networks. However, most existing NTMs usually model topics simply from observed document token information and do not explicitly take user preferences into the generative process, which inevitably fails to model personalized topics. To address this issue, we introduce Neural Personalized Topic Model(NPTM), a novel NTM that can discover personalized topics and user preferences. NPTM introduces a novel hybrid generative process for combining user preferences and contextualized document codes in modeling personalized topics. A transformer-based document encoder to obtain contextualized document codes. For user preference modeling, NPTM regards user-related information as trainable user embeddings, further determining user preferences over the topics. Following the proposed hybrid generative process, we present a module-wise asynchronous optimization strategy to get coherent topics and user preferences. Then, we apply our model to two challenging real-world social media post collections and compare them against several baseline methods to verify our contributions. The experimental results demonstrate the effectiveness of the proposed method.|随着网络服务的快速发展，社交媒体已经成为人们表达自己和分享日常生活的一种流行和便捷的方式。因此，社交媒体平台上积累了大量的用户生成内容。这些数据通常包含丰富的用户信息和知识，这是用户数据挖掘的可行来源。作为用户数据挖掘的一种流行技术，从社会媒体数据中挖掘个性化主题和发现用户偏好引起了学术界和工业界的广泛关注。新兴的神经主题模型(NTMs)通过使用神经网络表现出领先的性能和可扩展性。然而，大多数现有的 NTM 通常只是根据观察到的文档令牌信息对主题进行建模，并没有明确地将用户偏好引入到生成过程中，这就不可避免地无法对个性化主题进行建模。为了解决这个问题，我们引入了神经个性化主题模型(NPTM) ，这是一种新的可以发现个性化主题和用户偏好的神经个性化主题模型。NPTM 引入了一种新的混合生成过程，将用户偏好和上下文文档代码相结合，对个性化主题进行建模。一种基于转换器的获取上下文文档编码的文档编码器。对于用户偏好建模，NPTM 将用户相关信息视为可训练的用户嵌入，进一步确定用户对主题的偏好。根据所提出的混合生成过程，我们提出了一个模块化的异步优化策略，以获得一致的主题和用户偏好。然后，我们将我们的模型应用于两个具有挑战性的现实社会媒体帖子集合，并将它们与几个基线方法进行比较，以验证我们的贡献。实验结果表明了该方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neural+Personalized+Topic+Modeling+for+Mining+User+Preferences+on+Social+Media)|0|
|[Improving Long-Tail Item Recommendation with Graph Augmentation](https://doi.org/10.1145/3583780.3614929)|Sichun Luo, Chen Ma, Yuanzhang Xiao, Linqi Song|University of Hawaii at Manoa, Honolulu, HI, USA; City University of Hong Kong & City University of Hong Kong Shenzhen Research Institute, Hong Kong, Hong Kong; City University of Hong Kong, Hong Kong, Hong Kong|The ubiquitous long-tail distribution of inherent user behaviors results in worse recommendation performance for the items with fewer user records (i.e., tail items) than those with richer ones (i.e., head items). Graph-based recommendation methods (e.g., using graph neural networks) have recently emerged as a powerful tool for recommender systems, often outperforming traditional methods. However, existing techniques for alleviating the long-tail problem mainly focus on traditional methods. There is a lack of graph-based methods that can efficiently deal with the long-tail problem. In this paper, we propose a novel approach, Graph Augmentation for Long-tail Recommendation (GALORE), which can be plugged into any graph-based recommendation models to improve the performance for tail items. GALORE incorporates an edge addition module that enriches the graph's connectivity for tail items by injecting additional item-to-item edges. To further balance the graph structure, GALORE utilizes a degree-aware edge dropping strategy, preserving the more valuable edges from the tail items while selectively discarding less informative edges from the head items. Beyond structural augmentation, we synthesize new data samples, thereby addressing the data scarcity issue for tail items. We further introduce a two-stage training strategy to facilitate the learning for both head and tail items. Comprehensive empirical studies conducted on four datasets show that GALORE outperforms existing methods in terms of the performance for tail items as well as the overall performance.|无处不在的固有用户行为的长尾分布导致用户记录较少的条目(即尾条目)的推荐性能低于用户记录较丰富的条目(即头条目)的推荐性能。基于图形的推荐方法(例如，使用图形神经网络)最近已经成为推荐系统的一个强大工具，其性能通常优于传统方法。然而，现有的解决长尾问题的技术主要集中在传统方法上。缺乏基于图论的方法来有效地处理长尾问题。在本文中，我们提出了一种新的方法，图增强的长尾推荐(GALORE) ，可以插入到任何基于图的推荐模型，以提高性能的尾项。GALORE 合并了一个边缘添加模块，通过注入额外的项目到项目的边缘，丰富了图形对尾部项目的连通性。为了进一步平衡图形结构，GALORE 使用了一种度感知的边缘丢弃策略，保留了尾部项目中更有价值的边缘，同时选择性地丢弃了头部项目中信息量较小的边缘。除了结构增强，我们还合成了新的数据样本，从而解决了尾部项目的数据稀缺问题。我们进一步引入了一个两阶段的训练策略，以促进头部和尾部项目的学习。对四个数据集进行的综合实证研究表明，GALORE 在尾部项目的性能以及整体性能方面优于现有的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Long-Tail+Item+Recommendation+with+Graph+Augmentation)|0|
|[Parallel Knowledge Enhancement based Framework for Multi-behavior Recommendation](https://doi.org/10.1145/3583780.3615004)|Chang Meng, Chenhao Zhai, Yu Yang, Hengyu Zhang, Xiu Li|Tsinghua University, Shenzhen, China|Multi-behavior recommendation algorithms aim to leverage the multiplex interactions between users and items to learn users' latent preferences. Recent multi-behavior recommendation frameworks contain two steps: fusion and prediction. In the fusion step, advanced neural networks are used to model the hierarchical correlations between user behaviors. In the prediction step, multiple signals are utilized to jointly optimize the model with a multi-task learning (MTL) paradigm. However, recent approaches have not addressed the issue caused by imbalanced data distribution in the fusion step, resulting in the learned relationships being dominated by high-frequency behaviors. In the prediction step, the existing methods use a gate mechanism to directly aggregate expert information generated by coupling input, leading to negative information transfer. To tackle these issues, we propose a Parallel Knowledge Enhancement Framework (PKEF) for multi-behavior recommendation. Specifically, we enhance the hierarchical information propagation in the fusion step using parallel knowledge (PKF). Meanwhile, in the prediction step, we decouple the representations to generate expert information and introduce a projection mechanism during aggregation to eliminate gradient conflicts and alleviate negative transfer (PME). We conduct comprehensive experiments on three real-world datasets to validate the effectiveness of our model. The results further demonstrate the rationality and effectiveness of the designed PKF and PME modules. The source code and datasets are available at https://github.com/MC-CV/PKEF.|多行为推荐算法旨在利用用户和项目之间的多重交互来了解用户的潜在偏好。最近的多行为推荐框架包含两个步骤: 融合和预测。在融合步骤中，采用先进的神经网络对用户行为之间的层次关系进行建模。在预测步骤中，利用多个信号与多任务学习(MTL)范式联合优化模型。然而，最近的方法还没有解决由于融合步骤中数据分布不平衡所引起的问题，导致学习关系被高频行为所主导。在预测步骤中，现有的方法采用门机制直接聚合由耦合输入产生的专家信息，导致负信息传递。为了解决这些问题，我们提出了一个用于多行为推荐的并行知识增强框架(PKEF)。具体地说，我们在融合步骤中使用并行知识(PKF)来增强层次信息的传播。同时，在预测步骤中，对表示进行解耦，生成专家信息，并在聚合过程中引入投影机制，消除梯度冲突，减轻负迁移(PME)。为了验证模型的有效性，我们在三个实际数据集上进行了综合实验。仿真结果进一步验证了所设计的 PKF 模块和 PME 模块的合理性和有效性。源代码和数据集可在 https://github.com/mc-cv/pkef 下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Parallel+Knowledge+Enhancement+based+Framework+for+Multi-behavior+Recommendation)|0|
|[DebCSE: Rethinking Unsupervised Contrastive Sentence Embedding Learning in the Debiasing Perspective](https://doi.org/10.1145/3583780.3614833)|Pu Miao, Zeyao Du, Junlin Zhang|Sina Weibo, Beijing, China; China Literature Limited, Shang Hai, China; Sina Weibo, BeiJing, China|Several prior studies have suggested that word frequency biases can cause the Bert model to learn indistinguishable sentence embeddings. Contrastive learning schemes such as SimCSE and ConSERT have already been adopted successfully in unsupervised sentence embedding to improve the quality of embeddings by reducing this bias. However, these methods still introduce new biases such as sentence length bias and false negative sample bias, that hinders model's ability to learn more fine-grained semantics. In this paper, we reexamine the challenges of contrastive sentence embedding learning from a debiasing perspective and argue that effectively eliminating the influence of various biases is crucial for learning high-quality sentence embeddings. We think all those biases are introduced by simple rules for constructing training data in contrastive learning and the key for contrastive learning sentence embedding is to mimic the distribution of training data in supervised machine learning in unsupervised way. We propose a novel contrastive framework for sentence embedding, termed DebCSE, which can eliminate the impact of these biases by an inverse propensity weighted sampling method to select high-quality positive and negative pairs according to both the surface and semantic similarity between sentences. Extensive experiments on semantic textual similarity (STS) benchmarks reveal that DebCSE significantly outperforms the latest state-of-the-art models with an average Spearman's correlation coefficient of 80.33% on BERTbase.|已有的研究表明，词频偏差可以导致 Bert 模型学习不可区分的句子嵌入。对比学习方法如 SimCSE 和 ConSERT 已经成功地应用于无监督句子嵌入中，通过减少这种偏差来提高嵌入质量。然而，这些方法仍然引入了新的偏差，如句子长度偏差和错误的否定样本偏差，阻碍了模型学习更细粒度语义的能力。本文从消除偏差的角度重新审视对比句嵌入学习的挑战，认为有效地消除各种偏差的影响对于学习高质量的句子嵌入是至关重要的。我们认为所有这些偏差都是由构建对比学习中的训练数据的简单规则引入的，而对比学习句子嵌入的关键是以无监督的方式模拟训练数据在监督式学习中的分布。我们提出了一个新的句子嵌入对比框架，称为 DebCSE，它可以消除这些偏见的影响，通过反倾向加权抽样方法，根据句子之间的表面和语义相似性选择高质量的正负对。对语义文本相似度(STS)测试的大量实验表明，DebCSE 的性能明显优于最新的最先进的模型，在 BERTbase 上 Spearman 的平均相关系数为80.33% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DebCSE:+Rethinking+Unsupervised+Contrastive+Sentence+Embedding+Learning+in+the+Debiasing+Perspective)|0|
|[Bi-channel Multiple Sparse Graph Attention Networks for Session-based Recommendation](https://doi.org/10.1145/3583780.3614791)|Shutong Qiao, Wei Zhou, Junhao Wen, Hongyu Zhang, Min Gao|Chongqing University, Chongqing, China|Session-based Recommendation (SBR) has recently received significant attention due to its ability to provide personalized recommendations based on the interaction sequences of anonymous session users. The challenges facing SBR consist mainly of how to utilize information other than the current session and how to reduce the negative impact of irrelevant information in the session data on the prediction. To address these challenges, we propose a novel graph attention network-based model called Multiple Sparse Graph Attention Networks (MSGAT). MSGAT leverages two parallel channels to model intra-session and inter-session information. In the intra-session channel, we utilize a gated graph neural network to perform initial encoding, followed by a self-attention mechanism to generate the target representation. The global representation is then noise-reduced based on the target representation. Additionally, the target representation is used as a medium to connect the two channels. In the inter-session channel, the noise-reduced relation representation is generated using the global attention mechanism of target perception. Moreover, MSGAT fully considers session similarity from the intent perspective by integrating valid information from both channels. Finally, the intent neighbor collaboration module effectively combines relevant information to enhance the current session representation. Extensive experiments on five datasets demonstrate that simultaneous modeling of intra-session and inter-session data can effectively enhance the performance of the SBR model.|基于会话的推荐技术(SBS)由于能够根据匿名会话用户的交互序列提供个性化的推荐，近年来受到了广泛的关注。SBR 面临的挑战主要包括如何利用本届会议以外的信息，以及如何减少会议数据中不相关信息对预测的负面影响。为了应对这些挑战，我们提出了一种新的基于图注意网络的模型，称为多稀疏图注意网络(MSGAT)。MSGAT 利用两个并行通道对会话内和会话间信息建模。在会话内信道中，利用门控图神经网络进行初始编码，然后利用自注意机制生成目标表示。然后在目标表示的基础上对全局表示进行噪声抑制。此外，目标表示形式被用作连接两个通道的媒介。在会话间信道中，利用目标感知的全局注意机制生成降噪关系表示。此外，MSGAT 通过整合来自两个通道的有效信息，从意图的角度充分考虑了会话相似性。最后，意向邻居协作模块有效地结合了相关信息，增强了当前的会话表示。对五个数据集的大量实验表明，同时建模会话内和会话间数据可以有效地提高 SBR 模型的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bi-channel+Multiple+Sparse+Graph+Attention+Networks+for+Session-based+Recommendation)|0|
|[CDR: Conservative Doubly Robust Learning for Debiased Recommendation](https://doi.org/10.1145/3583780.3614805)|Zijie Song, Jiawei Chen, Sheng Zhou, Qihao Shi, Yan Feng, Chun Chen, Can Wang|Hangzhou City University, Hangzhou, China; Zhejiang University, Hangzhou, China|In recommendation systems (RS), user behavior data is observational rather than experimental, resulting in widespread bias in the data. Consequently, tackling bias has emerged as a major challenge in the field of recommendation systems. Recently, Doubly Robust Learning (DR) has gained significant attention due to its remarkable performance and robust properties. However, our experimental findings indicate that existing DR methods are severely impacted by the presence of so-called Poisonous Imputation, where the imputation significantly deviates from the truth and becomes counterproductive. To address this issue, this work proposes Conservative Doubly Robust strategy (CDR) which filters imputations by scrutinizing their mean and variance. Theoretical analyses show that CDR offers reduced variance and improved tail bounds.In addition, our experimental investigations illustrate that CDR significantly enhances performance and can indeed reduce the frequency of poisonous imputation.|在推荐系统(RS)中，用户行为数据是观察性的而不是实验性的，这导致了数据中广泛的偏差。因此，处理偏差已经成为推荐系统领域的一个主要挑战。近年来，双鲁棒学习(DR)以其显著的性能和鲁棒性得到了广泛的关注。然而，我们的实验结果表明，现有的 DR 方法受到所谓的有毒归责的严重影响，其中归责明显偏离真相，并成为适得其反。为了解决这个问题，本文提出了保守的双稳健策略(CDR) ，它通过检查估计的均值和方差来过滤估计。理论分析表明，CDR 方差减小，尾界改善，实验结果表明，CDR 方差显著提高了性能，并且确实能够减少有毒插补的频率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CDR:+Conservative+Doubly+Robust+Learning+for+Debiased+Recommendation)|0|
|[Disentangled Interest importance aware Knowledge Graph Neural Network for Fund Recommendation](https://doi.org/10.1145/3583780.3614846)|Ke Tu, Wei Qu, Zhengwei Wu, Zhiqiang Zhang, Zhongyi Liu, Yiming Zhao, Le Wu, Jun Zhou, Guannan Zhang|Ant Financial Services Group, Hangzhou, China; Hefei University of Technology, Hefei, China; Ant Group, Beijing, China; Ant Group, Hangzhou, China; Alipay, Beijing, China; Ant Financial, Hangzhou, China|At present, people are gradually becoming aware of financial management and thus fund recommendation attracts more and more attention to help them find suitable funds quickly. As a user usually takes many factors (e.g., fund theme, fund manager) into account when investing a fund and the fund usually consists of a substantial collection of investments, effectively modeling multi-interest representations is more crucial for personalized fund recommendation than the traditional goods recommendation. However, existing multi-interest methods are largely sub-optimal for fund recommendation, since they ignore financial domain knowledge and diverse fund investment intentions. In this work, we propose a Disentangled Interest importance aware Knowledge Graph Neural Network (DIKGNN) for personalized fund recommendation on FinTech platforms. In particular, we restrict the multiple intent spaces by introducing the attribute nodes from the fund knowledge graph as the minimum intent modeling unit to utilize financial domain knowledge and provide interpretability. In the intent space, we define disentangled intent representations, equipped with intent importance distributions to describe the diverse fund investment intentions. Then we design a new neighbor aggregation mechanism with the learned intent importance distribution upon the interaction graph and knowledge graph to collect multi-intent information. Furthermore, we leverage micro independence and macro balance constraints on the representations and distributions respectively to encourage intent independence and diversity. The extensive experiments on public recommendation benchmarks demonstrate that DIKGNN can achieve substantial improvement over state-of-the-art methods. Our proposed model is also evaluated over one real-world industrial fund dataset from a FinTech platform and has been deployed online.|目前，人们逐渐意识到财务管理的重要性，因此基金推荐越来越受到人们的重视，以帮助他们尽快找到合适的基金。由于投资者在投资基金时通常会考虑多种因素(如基金主题、基金经理等) ，而基金通常由大量的投资组合构成，因此有效地建立多利益表示模型对于个性化基金推荐比传统的商品推荐更为重要。然而，现有的多利率基金推荐方法由于忽视了金融领域的知识和基金投资意向的多样性，在很大程度上不能满足基金推荐的要求。在这项工作中，我们提出了一个分离利益重要性感知知识图神经网络(DIKGNN)个性化基金推荐在金融科技平台。特别地，我们通过引入基金知识图中的属性节点作为最小意图建模单元来限制多意图空间，以利用金融领域的知识并提供可解释性。在意向空间中，我们定义了非纠缠意向表示，并配备了意向重要性分布来描述不同的基金投资意向。然后设计了一种新的邻居聚集机制，在交互图和知识图上分布学习意图的重要性，以收集多意图信息。此外，我们利用微观独立性和宏观平衡约束分别表示和分布，以鼓励意向独立性和多样性。对公众推荐基准的广泛实验表明，DIKGNN 可以取得实质性的改善国家的最新方法。我们提出的模型也评估了一个来自金融科技平台的真实世界的工业基金数据集，并已在线部署。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Disentangled+Interest+importance+aware+Knowledge+Graph+Neural+Network+for+Fund+Recommendation)|0|
|[Node-dependent Semantic Search over Heterogeneous Graph Neural Networks](https://doi.org/10.1145/3583780.3614989)|Zhenyi Wang, Huan Zhao, Fengqi Liang, Chuan Shi|Beijing University of Posts and Telecommunications, Beijing, China; 4Paradigm Inc., Beijing, China|In recent years, Heterogeneous Graph Neural Networks (HGNNs) have been the state-of-the-art approaches for various tasks on Heterogeneous Graphs (HGs), e.g., recommendation and social network analysis. Despite the success of existing HGNNs, the utilization of the intricate semantic information in HGs is still insufficient. In this work, we study the problem of how to design powerful HGNNs under the guidance of node-dependent semantics. Specifically, to perform semantic search over HGNNs, we propose to develop semantic structures in terms of relation selection and connection selection, which could guide a task-relevant message flow. Furthermore, to better capture the diversified property of different node samples in HGs, we design predictors to adaptively decide the semantic structures per node. Extensive experiments on seven benchmarking datasets across different downstream tasks, i.e., node classification and recommendation, show that our method can consistently outperform various state-of-the-art baselines with shorter inference latency, which justifies its effectiveness and efficiency. The code and data are available at https://github.com/BUPT-GAMMA/NDS.|近年来，异构图神经网络(HGNN)已经成为异构图(HGs)上各种任务(如推荐和社会网络分析)的最新研究方法。尽管现有的 HGNN 取得了成功，但在 HGs 中使用的复杂语义信息仍然不足。本文主要研究如何在节点依赖语义的指导下设计强大的 HGNN。具体来说，为了在 HGNN 上进行语义搜索，我们提出了在关系选择和连接选择方面开发语义结构，以指导任务相关的消息流。此外，为了更好地捕捉 HG 中不同节点样本的多样性，我们设计了预测器来自适应地确定每个节点的语义结构。对不同下游任务(即节点分类和推荐)的7个基准测试数据集进行的大量实验表明，我们的方法能够以更短的推理延迟持续优于各种最先进的基线，这证明了其有效性和效率。代码和数据可在 https://github.com/bupt-gamma/nds 查阅。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Node-dependent+Semantic+Search+over+Heterogeneous+Graph+Neural+Networks)|0|
|[Towards Communication-Efficient Model Updating for On-Device Session-Based Recommendation](https://doi.org/10.1145/3583780.3615088)|Xin Xia, Junliang Yu, Guandong Xu, Hongzhi Yin|The University of Queensland, Brisbane, QLD, Australia; University of Technology Sydney, Sydney, NSW, Australia|On-device recommender systems recently have garnered increasing attention due to their advantages of providing prompt response and securing privacy. To stay current with evolving user interests, cloud-based recommender systems are periodically updated with new interaction data. However, on-device models struggle to retrain themselves because of limited onboard computing resources. As a solution, we consider the scenario where the model retraining occurs on the server side and then the updated parameters are transferred to edge devices via network communication. While this eliminates the need for local retraining, it incurs a regular transfer of parameters that significantly taxes network bandwidth. To mitigate this issue, we develop an efficient approach based on compositional codes to compress the model update. This approach ensures the on-device model is updated flexibly with minimal additional parameters whilst utilizing previous knowledge. The extensive experiments conducted on multiple session-based recommendation models with distinctive architectures demonstrate that the on-device model can achieve comparable accuracy to the retrained server-side counterpart through transferring an update 60x smaller in size. The codes are available at \url{https://github.com/xiaxin1998/ODUpdate}.|设备上推荐系统最近受到越来越多的关注，因为它们具有提供快速响应和保护隐私的优点。为了与不断变化的用户兴趣保持同步，基于云的推荐系统定期更新新的交互数据。然而，由于机载计算资源有限，在设备上的模型很难进行再培训。作为解决方案，我们考虑在服务器端进行模型再训练，然后通过网络通信将更新后的参数传输到边缘设备。虽然这消除了对本地再培训的需要，但它引起定期参数传输，大大增加了网络带宽的负担。为了解决这一问题，我们提出了一种基于复合代码的模型更新压缩方法。这种方法确保在设备上的模型更新灵活，最小的额外参数，同时利用以前的知识。在具有独特体系结构的多会话推荐模型上进行的大量实验表明，设备上模型可以通过传输小60倍的更新来达到与再训练的服务器端模型相当的精度。这些代码可以在 url { https://github.com/xiaxin1998/odupdate }获得。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Communication-Efficient+Model+Updating+for+On-Device+Session-Based+Recommendation)|0|
|[CoSaR: Combating Label Noise Using Collaborative Sample Selection and Adversarial Regularization](https://doi.org/10.1145/3583780.3614826)|Xiaobo Zhang, Yutao Liu, Hao Wang, Wei Wang, Panpan Ni, Ji Zhang|Southwest Jiaotong University, Chengdu, China; The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; Southwest Jiaotong University, Chendu, China; University of Southern Queensland, Toowoomba, Australia|Learning with noisy labels is nontrivial for deep learning models. Sample selection is a widely investigated research topic for handling noisy labels. However, most existing methods face challenges such as imprecise selection, a lack of global selection capabilities, and the need for tedious hyperparameter tuning. In this paper, we propose CoSaR (Collaborative Selection and adversarial Regularization ), a twin-networks based model that performs globally adaptive sample selection to tackle label noise. Specifically, the collaborative selection estimates the average distribution distances between predictions and generation labels through the collaboration of two networks to address the bias of the average distribution distances and the manual tuning of hyperparameters. Adversarial regularization is integrated into CoSaR to restrict the network's tendency to fit and memorize noisy labels, thereby enhancing its collaborative selection capability. In addition, we employ a label smoothing regularization and two types of data augmentation to enhance the robustness of the model further. Extensive experiments on both synthetic and real-world noisy datasets demonstrate that the proposed model outperforms baseline methods remarkably, with an accuracy improvement ranging between +0.56% and +15.14%.|对于深度学习模型来说，使用噪声标签进行学习是非常重要的。样本选择是一个广泛研究的课题，处理噪声标签。然而，大多数现有的方法都面临挑战，如选择不精确、缺乏全局选择能力以及需要冗长的超参数调优。本文提出了一种基于双网络的协同选择与对抗正则化(CoSaR)模型，该模型对标签噪声进行全局自适应样本选择。具体而言，协作选择通过两个网络的协作来估计预测和产生标签之间的平均分布距离，以解决平均分布距离的偏差和手动调整超参数。将对抗性规则化集成到 CoSaR 中，以限制网络适配和记忆噪声标签的倾向，从而增强其协同选择能力。此外，我们采用了标签平滑正则化和两种数据增强方法来进一步增强模型的鲁棒性。在合成和真实噪声数据集上的大量实验表明，该模型的性能明显优于基线方法，精度提高幅度在 + 0.56% 和 + 15.14% 之间。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CoSaR:+Combating+Label+Noise+Using+Collaborative+Sample+Selection+and+Adversarial+Regularization)|0|
|[HST-GT: Heterogeneous Spatial-Temporal Graph Transformer for Delivery Time Estimation in Warehouse-Distribution Integration E-Commerce](https://doi.org/10.1145/3583780.3614918)|Xiaohui Zhao, Shuai Wang, Hai Wang, Tian He, Desheng Zhang, Guang Wang|JD Logistics, Beijing, China; Southeast University, Nanjing, China; Rutgers University, New Brunswick, NJ, USA; Florida State University, Tallahassee, FL, USA|Warehouse-distribution integration has been adopted by many e-commerce retailers (e.g., Amazon, TAOBAO, and JD) as an efficient business mode. In warehouse-distribution integration e-commerce, one of the most important problems is to estimate the full-link delivery time for better decision-making. Existing solutions for traditional warehouse-distribution separation mode are challenging to address this problem due to two unique features in the integration mode including (i) contextual influence caused by neighbor units in heterogeneous delivery networks, (ii) uncertain delivery time caused by the dynamic temporal data (e.g., online sales volume) and heterogeneity of delivery units. To incorporate these new factors, we propose Heterogeneous Spatial-Temporal Graph Transformer (HST-GT), a novel full-link delivery time estimation method under the warehouse-distribution integration mode, where we (i) develop heterogeneous graph transformers to capture hierarchical heterogeneous information; and (ii) design a set of spatial-temporal transformers based on heterogeneous features to fully exploit the correlation of spatial and temporal information. We extensively evaluate our method based on one-month real-world data consisting of hundreds of warehouses and sorting centers, and millions of historical orders collected from one of the largest e-commerce retailers in the world. Experimental results demonstrate that our method outperforms state-of-the-art baselines in various metrics.|仓储-分销集成已被许多电子商务零售商(如亚马逊、淘宝和 JD)采用为一种高效的商业模式。在仓储-配送一体化电子商务中，为了更好地进行决策，需要解决的一个重要问题就是如何估计全程配送时间。由于集成模式中的两个独特特征，传统的仓储-分销分离模式的现有解决方案难以解决这一问题，这两个特征包括: (i)异构配送网络中邻居单元引起的上下文影响，(ii)动态时态数据(如在线销售量)引起的不确定配送时间和配送单元的异质性。为了吸收这些新的因素，我们提出了异构时空图形转换器(HST-GT) ，这是一种在仓库-分布式集成模式下的新的全链路传输时间估计方法。我们(i)开发异构图形转换器来捕获层次化的异构信息; (ii)设计一组基于异构特征的时空转换器来充分利用空间和时间信息的相关性。我们广泛评估我们的方法基于一个月的真实世界数据，包括数百个仓库和分拣中心，以及从世界上最大的电子商务零售商之一收集的数百万历史订单。实验结果表明，我们的方法优于国家的最先进的基线在各种指标。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HST-GT:+Heterogeneous+Spatial-Temporal+Graph+Transformer+for+Delivery+Time+Estimation+in+Warehouse-Distribution+Integration+E-Commerce)|0|
|[Scalable Neural Contextual Bandit for Recommender Systems](https://doi.org/10.1145/3583780.3615048)|Zheqing Zhu, Benjamin Van Roy|Stanford University, Stanford, USA; Meta AI, Stanford University, Menlo Park, USA|High-quality recommender systems ought to deliver both innovative and relevant content through effective and exploratory interactions with users. Yet, supervised learning-based neural networks, which form the backbone of many existing recommender systems, only leverage recognized user interests, falling short when it comes to efficiently uncovering unknown user preferences. While there has been some progress with neural contextual bandit algorithms towards enabling online exploration through neural networks, their onerous computational demands hinder widespread adoption in real-world recommender systems. In this work, we propose a scalable sample-efficient neural contextual bandit algorithm for recommender systems. To do this, we design an epistemic neural network architecture, Epistemic Neural Recommendation (ENR), that enables Thompson sampling at a large scale. In two distinct large-scale experiments with real-world tasks, ENR significantly boosts click-through rates and user ratings by at least 9% and 6% respectively compared to state-of-the-art neural contextual bandit algorithms. Furthermore, it achieves equivalent performance with at least 29% fewer user interactions compared to the best-performing baseline algorithm. Remarkably, while accomplishing these improvements, ENR demands orders of magnitude fewer computational resources than neural contextual bandit baseline algorithms.|高质量的推荐系统应该通过与用户有效和探索性的互动交付创新和相关的内容。然而，作为许多现有推荐系统骨干的基于监督学习的神经网络，只能利用已识别的用户兴趣，在有效发现未知用户偏好方面存在不足。虽然神经上下文盗贼算法在通过神经网络实现在线探索方面取得了一些进展，但是它们繁重的计算需求阻碍了在现实世界中推荐系统的广泛采用。在这项工作中，我们提出了一个可扩展的样本效率神经上下文盗贼算法的推荐系统。为了做到这一点，我们设计了一个认知神经网络结构，认知神经推荐(ENR) ，使汤普森采样在大规模。在两个不同的大规模实验与现实世界的任务，ENR 显着提高点击率和用户评分至少9% 和6% 分别相比，国家的最先进的神经上下文土匪算法。此外，与性能最好的基线算法相比，它至少减少了29% 的用户交互，从而实现了相同的性能。值得注意的是，在完成这些改进的同时，ENR 所需的计算资源数量级比神经上下文强盗基线算法要少。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+Neural+Contextual+Bandit+for+Recommender+Systems)|0|
|[PCENet: Psychological Clues Exploration Network for Multimodal Personality Assessment](https://doi.org/10.1145/3583780.3615005)|Yangfu Zhu, Yuting Wei, Meiling Li, Tingting Zhang, Siqi Wei, Bin Wu|Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications,, Beijing, China|Multimodal personality assessment aims to identify and express human personality traits in videos. Existing methods primarily focus on multimodal fusion while ignoring the inherent psychological clues essential for this interdisciplinary task. Modality clues: personality traits are stable over time due to their genetic and environmental origins, resulting in stable personality traits in the multimodal data. Trait clues: multiple traits often co-occur with non-negligible correlations, which can collectively aid trait identification. To simultaneously capture the above psychological clues, we propose a novel Psychological Clues Exploration Network (PCENet) for multimodal personality assessment, which is a human-like judgment paradigm with more generalization capability. Specifically, we first devise a multimodal hierarchical disentanglement, which clearly aligns stable representations among different modalities and separates the mutability of each modality. Subsequently, a Transformer-backbone decoder equipped with modality-to-trait attention is exploited to adaptively generate a tailored representation for each trait with the guidance of trait semantics. The trait semantics are obtained by exploiting trait correlations through self-attention. Extensive experiments on the First Impression V2 dataset demonstrate that our PCENet outperforms the state-of-the-art methods for multimodal personality assessment.|多模态人格评估旨在识别和表达视频中的人格特征。现有的方法主要侧重于多模态融合，而忽视了这一跨学科任务所必需的内在心理线索。情态线索: 由于遗传和环境起源，人格特征随着时间的推移是稳定的，在多模态数据中导致稳定的人格特征。性状线索: 多个性状常常与不可忽视的相关性共同出现，这可以共同帮助性状识别。为了同时捕捉上述心理线索，我们提出了一个新的心理线索探索网络(PCENet)的多模态人格评估，这是一个类人的判断范式，具有更多的泛化能力。具体来说，我们首先设计了一个多模态层次分离，它清楚地调整了不同模态之间的稳定表示，并分离了每种模态的可变性。然后，在特征语义的指导下，利用具有模态-特征注意的主干变压器解码器自适应地为每个特征生成一个量身定制的表示。特质语义是通过自我注意利用特质相关获得的。对第一印象 V2数据集的大量实验表明，我们的 PCENet 优于最先进的多模态人格评估方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PCENet:+Psychological+Clues+Exploration+Network+for+Multimodal+Personality+Assessment)|0|
|[G-STO: Sequential Main Shopping Intention Detection via Graph-Regularized Stochastic Transformer](https://doi.org/10.1145/3583780.3614890)|Yuchen Zhuang, Xin Shen, Yan Zhao, Chaosheng Dong, Ming Wang, Jin Li, Chao Zhang|Georgia Institute of Technology, Atlanta, GA, USA; Amazon, Seattle, WA, USA; Amazon, New York, NY, USA|Sequential recommendation requires understanding the dynamic patterns of users' behaviors, contexts, and preferences from their historical interactions. Most existing works focus on modeling user-item interactions only from the item level, ignoring that they are driven by latent shopping intentions (e.g., ballpoint pens, miniatures, etc). The detection of the underlying shopping intentions of users based on their historical interactions is a crucial aspect for e-commerce platforms, such as Amazon, to enhance the convenience and efficiency of their customers' shopping experiences. Despite its significance, the area of main shopping intention detection remains under-investigated in the academic literature. To fill this gap, we propose a graph-regularized stochastic Transformer method, G-STO. By considering intentions as sets of products and user preferences as compositions of intentions, we model both of them as stochastic Gaussian embeddings in the latent representation space. Instead of training the stochastic representations from scratch, we develop a global intention relational graph as prior knowledge for regularization, allowing relevant shopping intentions to be distributionally close. Finally, we feed the newly regularized stochastic embeddings into Transformer-based models to encode sequential information from the intention transitions. We evaluate our main shopping intention identification model on three different real-world datasets, where G-STO achieves significantly superior performances to the baselines by 18.08% in Hit@1, 7.01% in Hit@10, and 6.11% in NDCG@10 on average.|顺序推荐需要从用户的历史交互中理解用户行为、上下文和偏好的动态模式。大多数现有的作品只关注于从商品层次建模用户-商品交互，忽略了它们是由潜在的购物意图驱动的(例如，圆珠笔，微缩模型等)。基于用户历史交互的潜在购物意图的检测是亚马逊等电子商务平台提高用户购物体验的便利性和效率的一个关键方面。尽管其意义重大，主要的购物意图检测领域仍然没有得到充分的研究在学术文献。为了填补这个空白，我们提出了一个图正则化的随机变压器方法，G-STO。通过将意图看作是产品集合，将用户偏好看作是意图的组合，我们将两者建模为潜在表征空间中的随机高斯嵌入。我们不需要从头开始训练随机表示，而是开发一个全局意图关系图作为正则化的先验知识，允许相关的购物意图分布接近。最后，我们将新的正则化随机嵌入输入到基于变压器的模型中，从意图转换中编码序列信息。我们在三个不同的真实世界数据集上评估了我们的主要购物意向识别模型，其中 G-STO 在 Hit@1中的性能明显优于基线18.08% ，在 Hit@10中的性能为7.01% ，在 NDCG@10中的性能平均为6.11% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=G-STO:+Sequential+Main+Shopping+Intention+Detection+via+Graph-Regularized+Stochastic+Transformer)|0|
|[TCCM: Time and Content-Aware Causal Model for Unbiased News Recommendation](https://doi.org/10.1145/3583780.3615272)|Yewang Chen, Weiyao Ye, Guipeng Xv, Chen Lin, Xiaomin Zhu|Xiamen University, Xiamen, China; Huaqiao University, Xiamen, China; Academy of Military Sciences, Beijing, China|Popularity bias significantly impacts news recommendation systems, as popular news articles receive more exposure and are often delivered to irrelevant users, resulting in unsatisfactory performance. Existing methods have not adequately addressed the issue of popularity bias in news recommendations, largely due to the neglect of the time factor and the impact of news content on popularity. In this paper, we propose a novel approach called Time and Content-aware Causal Model, namely TCCM. It models the effects of three factors on user interaction behavior, i.e., the time factor, the news popularity, and the matching between news content and user interest. TCCM also estimates news popularity more accurately by incorporating the news content, i.e., the popularity of entity and words. Causal intervention techniques are applied to obtain debiased recommendations. Extensive experiments on well-known benchmark datasets demonstrate that the proposed approach outperforms a range of state-of-the-art techniques.|受欢迎度偏差对新闻推荐系统有显著影响，因为受欢迎的新闻文章曝光率更高，而且常常被传递给不相关的用户，从而导致不令人满意的性能。现有的研究方法没有充分解决新闻推荐中的受欢迎程度偏差问题，这主要是由于忽视了时间因素和新闻内容对受欢迎程度的影响。在本文中，我们提出了一种新的方法称为时间和内容感知的因果模型，即 TCCM。它模拟了三个因素对用户交互行为的影响，即时间因素、新闻受欢迎程度以及新闻内容与用户兴趣的匹配程度。TCCM 还通过结合新闻内容，即实体和词汇的受欢迎程度，更准确地估计新闻的受欢迎程度。应用因果干预技术来获得消除偏见的建议。在著名基准数据集上的大量实验表明，所提出的方法优于一系列最先进的技术。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TCCM:+Time+and+Content-Aware+Causal+Model+for+Unbiased+News+Recommendation)|0|
|[Attribute-enhanced Dual Channel Representation Learning for Session-based Recommendation](https://doi.org/10.1145/3583780.3615245)|Qian Chen, Jianjun Li, Zhiqiang Guo, Guohui Li, Zhiying Deng|Huazhong University of Science and Technology, Wuhan, China|Session-based recommendation (SBR) aims to predict the anonymous user's next-click items by modeling the short-term sequence pattern. As most existing SBR models generally generate item representations based only on information propagation over the short sequence while ignoring additional valuable knowledge, their expressive abilities are somewhat limited by data sparsity caused by short sequence. Though there have been some attempts on utilizing items' attributes, they basically embed attributes into items directly, ignoring the fact that 1) there is no contextual relationship among attributes; and 2) users have varying levels of attention to different attributes, which still leads to unsatisfactory performance. To tackle the issues, we propose a novel Attribute-enhanced Dual Channel Representation Learning (ADRL) model for SBR, in which we independently model session representations in attribute-related pattern and sequence-related pattern. Specifically, we learn session representations with sequence patterns from the session graph, and we further design an frequency-driven attribute aggregator to generate the attribute-related session representations within a session. The proposed attribute aggregator is plug-and-play, as it can be coupled with most existing SBR models. Extensive experiments on three real-world public datasets demonstrate the superiority of the proposed ADRL over several state-of-the-art baselines, as well as the effectiveness and efficiency of our attribute aggregator module.|基于会话的推荐(SBS)通过建立短期序列模式来预测匿名用户的下一次点击项目。由于现有的 SBR 模型大多只是基于短序列的信息传播来产生条目表示，而忽略了附加的有价值的知识，因此它们的表示能力受到短序列造成的数据稀疏的限制。尽管已经有一些尝试利用项目的属性，他们基本上直接将属性嵌入到项目中，忽略了这样一个事实: 1)属性之间没有上下文关系; 2)用户对不同属性的关注程度不同，这仍然会导致不令人满意的性能。为了解决这一问题，我们提出了一种新的基于属性增强的双通道表示学习(ADRL)模型，该模型独立地对会话表示进行属性相关模式和序列相关模式的建模。具体来说，我们从会话图中学习具有序列模式的会话表示，并且进一步设计一个频率驱动的属性聚合器来在会话中生成与属性相关的会话表示。提出的属性聚合器是即插即用的，因为它可以与大多数现有的 SBR 模型耦合。在三个真实世界的公共数据集上的大量实验表明了所提出的 ADRL 相对于几个最先进的基线的优越性，以及我们的属性聚合器模块的有效性和效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Attribute-enhanced+Dual+Channel+Representation+Learning+for+Session-based+Recommendation)|0|
|[Simulating Users in Interactive Web Table Retrieval](https://doi.org/10.1145/3583780.3615187)|Björn Engelmann, Timo Breuer, Philipp Schaer|TH Köln (University of Applied Sciences), Köln, Germany|Considering the multimodal signals of search items is beneficial for retrieval effectiveness. Especially in web table retrieval (WTR) experiments, accounting for multimodal properties of tables boosts effectiveness. However, it still remains an open question how the single modalities affect user experience in particular. Previous work analyzed WTR performance in ad-hoc retrieval benchmarks, which neglects interactive search behavior and limits the conclusion about the implications for real-world user environments. To this end, this work presents an in-depth evaluation of simulated interactive WTR search sessions as a more cost-efficient and reproducible alternative to real user studies. As a first of its kind, we introduce interactive query reformulation strategies based on Doc2Query, incorporating cognitive states of simulated user knowledge. Our evaluations include two perspectives on user effectiveness by considering different cost paradigms, namely query-wise and time-oriented measures of effort. Our multi-perspective evaluation scheme reveals new insights about query strategies, the impact of modalities, and different user types in simulated WTR search sessions.|考虑检索项的多模态信号有利于提高检索效率。特别是在 Web 表检索(WTR)实验中，考虑表的多模态特性可以提高检索效率。然而，单一模式如何特别影响用户体验仍然是一个悬而未决的问题。以往的工作分析了自组织检索基准的 WTR 性能，忽略了交互式搜索行为，限制了对实际用户环境影响的结论。为此，这项工作提出了一个深入的评价模拟交互式 WTR 搜索会话作为一个更具成本效益和可重复的替代真正的用户研究。首次提出了基于 Doc2Query 的交互式查询重构策略，该策略融合了模拟用户知识的认知状态。通过考虑不同的成本范式，我们的评估包括对用户有效性的两个视角，即查询式和面向时间的工作量度。我们的多视角评估方案揭示了在模拟 WTR 搜索会话中关于查询策略、模式影响和不同用户类型的新见解。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Simulating+Users+in+Interactive+Web+Table+Retrieval)|0|
|[Test-Time Embedding Normalization for Popularity Bias Mitigation](https://doi.org/10.1145/3583780.3615281)|Dain Kim, Jinhyeok Park, Dongwoo Kim|POSTECH, Pohang, Republic of Korea|Popularity bias is a widespread problem in the field of recommender systems, where popular items tend to dominate recommendation results. In this work, we propose 'Test Time Embedding Normalization' as a simple yet effective strategy for mitigating popularity bias, which surpasses the performance of the previous mitigation approaches by a significant margin. Our approach utilizes the normalized item embedding during the inference stage to control the influence of embedding magnitude, which is highly correlated with item popularity. Through extensive experiments, we show that our method combined with the sampled softmax loss effectively reduces popularity bias compare to previous approaches for bias mitigation. We further investigate the relationship between user and item embeddings and find that the angular similarity between embeddings distinguishes preferable and non-preferable items regardless of their popularity. The analysis explains the mechanism behind the success of our approach in eliminating the impact of popularity bias. Our code is available at https://github.com/ml-postech/TTEN.|在推荐系统领域，流行度偏差是一个普遍存在的问题，在这个领域中，流行项目往往占据推荐结果的主导地位。在这项工作中，我们提出了“测试时间嵌入规范化”作为一个简单而有效的策略，以减轻流行偏差，这超过了以前的缓解方法的性能显着差距。该方法在推理阶段利用归一化项目嵌入来控制项目嵌入量的影响，项目嵌入量与项目知名度高度相关。通过大量的实验，我们发现与以往的偏差抑制方法相比，我们的方法结合采样软最大损失有效地降低了流行偏差。我们进一步研究了用户与项目嵌入之间的关系，发现无论项目受欢迎程度如何，用户与项目嵌入之间的角度相似度都能区分出优选项目和不优选项目。该分析解释了我们的方法在消除流行偏见影响方面取得成功背后的机制。我们的代码可以在 https://github.com/ml-postech/tten 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Test-Time+Embedding+Normalization+for+Popularity+Bias+Mitigation)|0|
|[Boosting Meta-Learning Cold-Start Recommendation with Graph Neural Network](https://doi.org/10.1145/3583780.3615283)|Han Liu, Hongxiang Lin, Xiaotong Zhang, Fenglong Ma, Hongyang Chen, Lei Wang, Hong Yu, Xianchao Zhang|Zhejiang Lab, Hangzhou, China; Meituan, Beijing, China; Dalian University of Technology, Dalian, China; The Pennsylvania State University, University Park, USA; Peking University, Beijing, China|Meta-learning methods have shown to be effective in dealing with cold-start recommendation. However, most previous methods rely on an ideal assumption that there exists a similar data distribution between source and target tasks, which are unsuitable for the scenario that only extremely limited number of new user or item interactions are available. In this paper, we propose to boost meta-learning cold-start recommendation with graph neural network (MeGNN). First, it utilizes the global neighborhood translation learning to obtain consistent potential interactions for all new user and item nodes, which can refine their representations. Second, it employs the local neighborhood translation learning to predict specific potential interactions for each node, thus guaranteeing the personalized requirement. In experiments, we combine MeGNN with two representative meta-learning models MeLU and TaNP. Extensive results on two widely-used datasets show the superiority of MeGNN in four different scenarios.|元学习方法已被证明在处理冷启动推荐时是有效的。但是，大多数以前的方法都依赖于一个理想的假设，即在源任务和目标任务之间存在类似的数据分布，这种假设不适合于只有极其有限的新用户或项交互可用的场景。本文提出了一种基于图神经网络(MeGNN)的元学习冷启动推荐算法。首先，利用全局邻域翻译学习来获得所有新的用户和项目节点的一致的潜在交互，从而改进它们的表示。其次，利用局部邻域翻译学习来预测每个节点的特定潜在交互，从而保证个性化需求。在实验中，我们将 MeGNN 与两个有代表性的元学习模型 MeLU 和 TaNP 相结合。在两个广泛使用的数据集上的广泛结果显示了 MeGNN 在四种不同场景下的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Boosting+Meta-Learning+Cold-Start+Recommendation+with+Graph+Neural+Network)|0|
|[STGIN: Spatial-Temporal Graph Interaction Network for Large-scale POI Recommendation](https://doi.org/10.1145/3583780.3615200)|Shaohua Liu, Yu Qi, Gen Li, Mingjian Chen, Teng Zhang, Jia Cheng, Jun Lei|Meituan, Shanghai, China|In Location-Based Services, Point-Of-Interest(POI) recommendation plays a crucial role in both user experience and business opportunities. Graph neural networks have been proven effective in providing personalized POI recommendation services. However, there are still two critical challenges. First, existing graph models attempt to capture users' diversified interests through a unified graph, which limits their ability to express interests in various spatial-temporal contexts. Second, the efficiency limitations of graph construction and graph sampling in large-scale systems make it difficult to adapt quickly to new real-time interests. To tackle the above challenges, we propose a novel Spatial-Temporal Graph Interaction Network. Specifically, we construct subgraphs of spatial, temporal, spatial-temporal, and global views respectively to precisely characterize the user's interests in various contexts. In addition, we design an industry-friendly framework to track the user's latest interests. Extensive experiments on the real-world dataset show that our method outperforms state-of-the-art models. This work has been successfully deployed in a large e-commerce platform, delivering a 1.1% CTR and 6.3% RPM improvement.|在基于位置的服务中，兴趣点(POI)推荐在用户体验和商业机会中都扮演着至关重要的角色。图形神经网络在提供个性化 POI 推荐服务方面已被证明是有效的。然而，仍然存在两个关键的挑战。首先，现有的图模型试图通过一个统一的图来捕捉用户的多样化兴趣，这限制了用户在不同的时空背景下表达兴趣的能力。其次，在大规模系统中，由于图的构造和采样效率的限制，很难快速适应新的实时需求。为了解决上述问题，我们提出了一种新的时空图交互网络。具体来说，我们分别构造了空间、时间、空间-时间和全局视图的子图，以精确表征用户在不同情境下的兴趣。此外，我们还设计了一个行业友好的框架来跟踪用户的最新兴趣。在真实世界数据集上的大量实验表明，我们的方法优于最先进的模型。这项工作已经成功地部署在一个大型电子商务平台，提供了1.1% 的点击率和6.3% 的 RPM 改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=STGIN:+Spatial-Temporal+Graph+Interaction+Network+for+Large-scale+POI+Recommendation)|0|
|[FairGraph: Automated Graph Debiasing with Gradient Matching](https://doi.org/10.1145/3583780.3615176)|Yezi Liu|University of California, Irvine, Irvine, CA, USA|As a prevalence data structure in the real world, graphs have found extensive applications ranging from modeling social networks to molecules. However, the existence of diverse biases within graphs gives rise to unfair representations learned by graph neural networks (GNNs). Addressing this issue has typically been approached from a modeling perspective, which not only compromises the integrity of the model structure but also entails additional effort and cost for retraining model parameters when the architecture changes. In this study, we adopt a data-centric standpoint to tackle the problem of fairness, focusing on graph debiasing for Graph Neural Networks. Our specific objective is to eliminate various biases from the input graph by generating a fair synthetic graph. By training GNNs on this fair graph, we aim to achieve an optimal accuracy-fairness trade-off. To this end, we propose FairGraph, which approaches the graph debiasing problem by mimicking the GNN training trajectory of the input graph through an optimization process involving a gradient-matching loss and fairness constraints. Through extensive experiments conducted on three benchmark datasets, we demonstrate the effectiveness of FairGraph and its ability to automatedly generate fair graphs that are transferable across different GNN architectures.|作为现实世界中流行的数据结构，图表已经发现了广泛的应用，从建模社会网络到分子。然而，图中存在不同的偏差会导致图神经网络学习到的不公平表示。解决这个问题通常是从建模的角度出发的，这不仅损害了模型结构的完整性，而且在体系结构发生变化时需要额外的努力和成本来重新训练模型参数。在本研究中，我们采用以数据为中心的观点来解决公平性问题，重点是图神经网络的图形消偏。我们的具体目标是通过生成一个公平的综合图来消除输入图中的各种偏差。通过在这个公平图上训练 GNN，我们的目标是实现最佳的精度-公平权衡。为此，我们提出了 FairGraph，它通过一个包含梯度匹配损失和公平约束的优化过程来模拟输入图的 GNN 训练轨迹，从而解决图的去偏问题。通过在三个基准数据集上进行的大量实验，我们证明了 FairGraph 的有效性及其自动生成可跨不同 GNN 架构转移的 Fair 图的能力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FairGraph:+Automated+Graph+Debiasing+with+Gradient+Matching)|0|
|[Product Entity Matching via Tabular Data](https://doi.org/10.1145/3583780.3615172)|Ali Naeim abadi, Mir Tafseer Nayeem, Davood Rafiei|University of Alberta, Edmonton, AB, Canada|Product Entity Matching (PEM)--a subfield of record linkage that focuses on linking records that refer to the same product--is a challenging task for many entity matching models. For example, recent transformer models report a near-perfect performance score on many datasets while their performance is the lowest on PEM datasets. In this paper, we study PEM under the common setting where the information is spread over text and tables. We show that adding tables can enrich the existing PEM datasets and those tables can act as a bridge between the entities being matched. We also propose TATEM, an effective solution that leverages Pre-trained Language Models (PLMs) with a novel serialization technique to encode tabular product data and an attribute ranking module to make our model more data-efficient. Our experiments on both current benchmark datasets and our proposed datasets show significant improvements compared to state-of-the-art methods, including Large Language Models (LLMs) in zero-shot and few-shot settings.|产品实体匹配(Product Entity Matching，PEM)——记录链接的一个子领域，其重点是链接引用同一产品的记录——对于许多实体匹配模型来说是一项具有挑战性的任务。例如，最近的变压器模型在许多数据集上报告了接近完美的性能得分，而在 PEM 数据集上它们的性能最低。在本文中，我们研究质子交换膜下的公共设置，其中的信息是分布在文本和表格。我们表明，添加表可以丰富现有的 PEM 数据集，并且这些表可以作为匹配实体之间的桥梁。我们还提出了 TATEM，一个有效的解决方案，利用预训练语言模型(PLM)与一种新的序列化技术来编码表格产品数据和属性排序模块，使我们的模型更有效的数据。我们对当前基准数据集和我们提出的数据集的实验表明，与最先进的方法相比，包括大语言模型(LLM)在零拍摄和少拍摄设置方面有显著的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Product+Entity+Matching+via+Tabular+Data)|0|
|[Neural Disentanglement of Query Difficulty and Semantics](https://doi.org/10.1145/3583780.3615189)|Sara Salamat, Negar Arabzadeh, Shirin Seyedsalehi, Amin Bigdeli, Morteza Zihayat, Ebrahim Bagheri|Toronto Metropolitan University, Toronto, ON, Canada; University of Waterloo, Waterloo, ON, Canada|Researchers have shown that the retrieval effectiveness of queries may depend on other factors in addition to the semantics of the query. In other words, several queries expressed with the same intent, and even using overlapping keywords, may exhibit completely different degrees of retrieval effectiveness. As such, the objective of our work in this paper is to propose a neural disentanglement method that is able to disentangle query semantics from query difficulty. The disentangled query semantics representation provides the means to determine semantic association between queries whereas the disentangled query difficulty representation would allow for the estimation of query effectiveness. We show through our experiments on the query performance prediction; and, query similarity calculation tasks that our proposed disentanglement method is able to show better performance compared to the state of the art.|研究表明，查询的检索效果除了取决于查询的语义外，还取决于其他因素。换句话说，几个具有相同意图的查询，甚至使用重叠关键字，可能表现出完全不同程度的检索效率。因此，本文的工作目标是提出一种能够将查询语义从查询难度中分离出来的神经网络分离方法。分离查询语义表示提供了确定查询之间语义关联的方法，而分离查询难度表示则可以评估查询的有效性。通过对查询性能预测和查询相似度计算任务的实验表明，本文提出的分离方法能够比现有方法表现出更好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neural+Disentanglement+of+Query+Difficulty+and+Semantics)|0|
|[EdgeNet : Encoder-decoder generative Network for Auction Design in E-commerce Online Advertising](https://doi.org/10.1145/3583780.3615192)|Guangyuan Shen, Shengjie Sun, Dehong Gao, Duanxiao Song, Libin Yang, Zhen Wang, Yongping Shi, Wei Ning||We present a new encoder-decoder generative network dubbed EdgeNet, which introduces a novel encoder-decoder framework for data-driven auction design in online e-commerce advertising. We break the neural auction paradigm of Generalized-Second-Price(GSP), and improve the utilization efficiency of data while ensuring the economic characteristics of the auction mechanism. Specifically, EdgeNet introduces a transformer-based encoder to better capture the mutual influence among different candidate advertisements. In contrast to GSP based neural auction model, we design an autoregressive decoder to better utilize the rich context information in online advertising auctions. EdgeNet is conceptually simple and easy to extend to the existing end-to-end neural auction framework. We validate the efficiency of EdgeNet on a wide range of e-commercial advertising auction, demonstrating its potential in improving user experience and platform revenue.|提出了一种新的编解码生成网络 EdgeNet，该网络为在线电子商务广告中的数据驱动拍卖设计提供了一种新的编解码框架。我们打破了广义二级价格(GSP)的神经拍卖范式，在保证拍卖机制的经济性的同时，提高了数据的利用效率。具体来说，EdgeNet 引入了一种基于变压器的编码器，以更好地捕捉不同候选广告之间的相互影响。与基于 GSP 的神经拍卖模型相比，我们设计了一个自回归解码器，以更好地利用在线广告拍卖中丰富的上下文信息。EdgeNet 概念简单，易于扩展到现有的端到端神经拍卖框架。我们验证了 EdgeNet 在广泛的电子商务广告拍卖中的效率，证明了它在改善用户体验和平台收入方面的潜力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EdgeNet+:+Encoder-decoder+generative+Network+for+Auction+Design+in+E-commerce+Online+Advertising)|0|
|[G-Meta: Distributed Meta Learning in GPU Clusters for Large-Scale Recommender Systems](https://doi.org/10.1145/3583780.3615208)|Youshao Xiao, Shangchun Zhao, Zhenglei Zhou, Zhaoxin Huan, Lin Ju, Xiaolu Zhang, Lin Wang, Jun Zhou|Ant Group, Hangzhou, China|Recently, a new paradigm, meta learning, has been widely applied to Deep Learning Recommendation Models (DLRM) and significantly improves statistical performance, especially in cold-start scenarios. However, the existing systems are not tailored for meta learning based DLRM models and have critical problems regarding efficiency in distributed training in the GPU cluster. It is because the conventional deep learning pipeline is not optimized for two task-specific datasets and two update loops in meta learning. This paper provides a high-performance framework for large-scale training for Optimization-based Meta DLRM models over the G PU cluster, namely G -Meta. Firstly, G-Meta utilizes both data parallelism and model parallelism with careful orchestration regarding computation and communication efficiency, to enable high-speed distributed training. Secondly, it proposes a Meta-IO pipeline for efficient data ingestion to alleviate the I/O bottleneck. Various experimental results show that G-Meta achieves notable training speed without loss of statistical performance. Since early 2022, G-Meta has been deployed in Alipay's core advertising and recommender system, shrinking the continuous delivery of models by four times. It also obtains 6.48% improvement in Conversion Rate (CVR) and 1.06% increase in CPM (Cost Per Mille) in Alipay's homepage display advertising, with the benefit of larger training samples and tasks.|最近，一种新的学习模式元学习被广泛应用于深度学习推荐模型(DLRM) ，并显著提高了统计性能，特别是在冷启动情景下。然而，现有的系统并不适合基于元学习的 DLRM 模型，并且在 GPU 集群的分布式培训效率方面存在关键问题。这是因为传统的深度学习流水线没有针对元学习中的两个任务特定的数据集和两个更新循环进行优化。本文提供了一个在 G PU 集群上进行基于优化的元 DLRM 模型大规模培训的高性能框架，即 G-Meta。首先，G-Meta 利用了资料平行和模型的并行性，在计算和通信效率方面进行了精心的编排，从而实现了高速的分布式训练。其次，提出了一种有效的数据摄取元 IO 管道，以缓解 I/O 瓶颈。各种实验结果表明，G-Meta 在不损失统计性能的前提下，达到了显著的训练速度。自2022年初以来，g-Meta 一直部署在支付宝的核心广告和推荐系统中，将模型的持续交付缩减了4倍。在支付宝主页显示广告中，转化率(CVR)提高了6.48% ，每公里成本(CPM)提高了1.06% ，这些都得益于更大的培训样本和任务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=G-Meta:+Distributed+Meta+Learning+in+GPU+Clusters+for+Large-Scale+Recommender+Systems)|0|
|[MEBS: Multi-task End-to-end Bid Shading for Multi-slot Display Advertising](https://doi.org/10.1145/3583780.3615486)|Zhen Gong, Lvyin Niu, Yang Zhao, Miao Xu, Haoqi Zhang, Zhenzhe Zheng, Zhilin Zhang, Rongquan Bai, Chuan Yu, Jian Xu, Bo Zheng, Fan Wu|Shanghai Jiao Tong University, Shanghai, China; Alibaba Group, Beijing, China|Online bidding and auction are crucial aspects of the online advertising industry. Conventionally, there is only one slot for ad display and most current studies focus on it. Nowadays, multi-slot display advertising is gradually becoming popular where many ads could be displayed in a list and shown as a whole to users. However, multi-slot display advertising leads to different cost-effectiveness. Advertisers have the incentive to adjust bid prices so as to win the most economical ad positions. In this study, we introduce bid shading into multi-slot display advertising for bid price adjustment with a Multi-task End-to-end Bid Shading~(MEBS) method. We prove the optimality of our method theoretically and examine its performance experimentally. Through extensive offline and online experiments, we demonstrate the effectiveness and efficiency of our method, and we obtain a 7.01% lift in Gross Merchandise Volume, a 7.42% lift in Return on Investment, and a 3.26% lift in ad buy count.|在线招标和拍卖是在线广告业的重要方面。传统上，只有一个广告展示时段，目前大多数研究集中在它。如今，多插槽显示广告正逐渐流行，许多广告可以显示在一个列表中，并作为一个整体显示给用户。然而，多插槽显示广告导致不同的成本效益。广告商有动机调整投标价格，以赢得最经济的广告位置。在本研究中，我们利用多任务端到端的投标底纹 ~ (MEBS)方法，将投标底纹引入多时隙显示广告中，以调整投标价格。从理论上证明了该方法的最优性，并对其性能进行了实验验证。通过大量的线下和线上实验，我们证明了我们的方法的有效性和效率，我们获得了7.01% 的商品总量增长，7.42% 的投资回报增长，3.26% 的广告购买数量增长。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MEBS:+Multi-task+End-to-end+Bid+Shading+for+Multi-slot+Display+Advertising)|0|
|[DFFM: Domain Facilitated Feature Modeling for CTR Prediction](https://doi.org/10.1145/3583780.3615469)|Wei Guo, Chenxu Zhu, Fan Yan, Bo Chen, Weiwen Liu, Huifeng Guo, Hongkun Zheng, Yong Liu, Ruiming Tang|Huawei Noah's Ark Lab, Huawei, Shanghai, China; Huawei Technologies Co Ltd, Shenzhen, China; Huawei Noah's Ark Lab, Shanghai, China|CTR prediction is critical to industrial recommender systems. Recently, with the growth of business domains in enterprises, much attention has been focused on the multi-domain CTR recommendation. Numerous models have been proposed that attempt to use a unified model to serve multiple domains. Although much progress has been made, we argue that they ignore the importance of feature interactions and user behaviors when modeling cross-domain relations, which is a coarse-grained utilizing of domain information. To solve this problem, we propose Domain Facilitated Feature Modeling (DFFM) for CTR prediction. It incorporates domain-related information into the parameters of the feature interaction and user behavior modules, allowing for domain-specific learning of these two aspects. Extensive experiments are conducted on two public datasets and one industrial dataset to demonstrate the effectiveness of DFFM. We deploy the DFFM model in Huawei advertising platform and gain a 4.13% improvement of revenue on a two week online A/B test. Currently DFFM model has been used as the main traffic model, serving for hundreds of millions of people.|CTR 预测是工业推荐系统的关键。近年来，随着企业业务领域的不断扩大，多领域 CTR 推荐引起了人们的广泛关注。许多模型试图使用一个统一的模型来服务于多个领域。虽然已经取得了很大的进展，但是我们认为他们忽视了特征交互和用户行为在跨领域关系建模中的重要性，这是对领域信息的粗粒度利用。为了解决这个问题，我们提出了领域简化特征建模(DFFM)的 CTR 预测。它将领域相关信息整合到特征交互和用户行为模块的参数中，允许特定领域学习这两个方面。为了验证 DFFM 算法的有效性，在两个公共数据集和一个工业数据集上进行了大量的实验。我们在华为广告平台采用了 dFFM 模式，通过两周的在线 A/B 测试，收入提高了4.13% 。目前 DFFM 模型已经成为主要的流量模型，服务于数亿人。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DFFM:+Domain+Facilitated+Feature+Modeling+for+CTR+Prediction)|0|
|[Masked Multi-Domain Network: Multi-Type and Multi-Scenario Conversion Rate Prediction with a Single Model](https://doi.org/10.1145/3583780.3614697)|Wentao Ouyang, Xiuwu Zhang, Chaofeng Guo, Shukui Ren, Yupei Sui, Kun Zhang, Jinmei Luo, Yunfeng Chen, Dongbo Xu, Xiangzheng Liu, Yanlong Du|Alibaba Group, Beijing, China|In real-world advertising systems, conversions have different types in nature and ads can be shown in different display scenarios, both of which highly impact the actual conversion rate (CVR). This results in the multi-type and multi-scenario CVR prediction problem. A desired model for this problem should satisfy the following requirements: 1) Accuracy: the model should achieve fine-grained accuracy with respect to any conversion type in any display scenario. 2) Scalability: the model parameter size should be affordable. 3) Convenience: the model should not require a large amount of effort in data partitioning, subset processing and separate storage. Existing approaches cannot simultaneously satisfy these requirements. For example, building a separate model for each (conversion type, display scenario) pair is neither scalable nor convenient. Building a unified model trained on all the data with conversion type and display scenario included as two features is not accurate enough. In this paper, we propose the Masked Multi-domain Network (MMN) to solve this problem. To achieve the accuracy requirement, we model domain-specific parameters and propose a dynamically weighted loss to account for the loss scale imbalance issue within each mini-batch. To achieve the scalability requirement, we propose a parameter sharing and composition strategy to reduce model parameters from a product space to a sum space. To achieve the convenience requirement, we propose an auto-masking strategy which can take mixed data from all the domains as input. It avoids the overhead caused by data partitioning, individual processing and separate storage. Both offline and online experimental results validate the superiority of MMN for multi-type and multi-scenario CVR prediction. MMN is now the serving model for real-time CVR prediction in UC Toutiao.|在现实世界的广告系统中，转化率具有不同的性质，广告可以在不同的显示场景中显示，这两者都对实际转化率(CVR)有很大的影响。这导致了多类型和多情景 CVR 预测问题。这个问题的期望模型应该满足以下要求: 1)精度: 模型应该达到细粒度的精度相对于任何转换类型在任何显示场景。2)可伸缩性: 模型参数的大小应该是可以承受的。3)方便性: 模型不需要在数据分区、子集处理和独立存储方面做大量的工作。现有的方法不能同时满足这些需求。例如，为每个(转换类型，显示场景)对构建单独的模型既不可伸缩也不方便。将转换类型和显示场景作为两个特征包含在内，对所有数据建立统一的训练模型是不够准确的。本文提出了掩蔽多域网络(MMN)来解决这一问题。为了达到精度要求，我们对特定领域的参数进行建模，并提出一个动态加权损失，以解决每个小批量内损失规模不平衡的问题。为了满足可扩展性的要求，我们提出了一种参数共享和合成策略，将模型参数从乘积空间减少到和空间。为了达到方便的要求，我们提出了一种自动掩蔽的策略，可以从所有领域的混合数据作为输入。它避免了由于数据分区、单独处理和单独存储而造成的开销。离线和在线实验结果验证了 MMN 在多类型、多情景 CVR 预测中的优越性。MMN 现在是 UC 今日头条实时 CVR 预测的服务模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Masked+Multi-Domain+Network:+Multi-Type+and+Multi-Scenario+Conversion+Rate+Prediction+with+a+Single+Model)|0|
|[TrendSpotter: Forecasting E-commerce Product Trends](https://doi.org/10.1145/3583780.3615503)|Gayatri Ryali, Shreyas S, Sivaramakrishnan Kaveri, Prakash Mandayam Comar|Amazon.com Inc., Bengaluru, India|Internet users actively search for trending products on various social media services like Instagram and YouTube which serve as popular hubs for discovering and exploring fashionable and popular items. It is imperative for e-commerce giants to have the capability to accurately identify, predict and subsequently showcase these trending products to the customers. E-commerce stores can effectively cater to the evolving demands of the customer base and enhance the overall shopping experience by offering recent and most sought-after products in a timely manner. In this work we propose a framework for predicting and surfacing trending products in e-commerce stores, the first of its kind to the best of our knowledge. We begin by defining what constitutes a trending product using sound statistical tests. We then introduce a machine learning-based early trend prediction system called TrendSpotter to help users identify upcoming product trends. TrendSpotter is a unique adaptation of the state-of-the-art InceptionTime model\citeInceptionTime that predicts the future popularity of a product based on its current customer engagement, such as clicks, purchases, and other relevant product attributes. The effectiveness of our approach is demonstrated through A/B tests, where we first showcase the effectiveness of our statistical test based labeling strategy, resulting in an incremental sales lift of 59 bps\footnotebps or basis points are a measure of percentages. 1 bps = 0.01% across two experiments on home page and search page. Subsequently, we conduct a comparison between our machine learning model and the statistical labeling baseline and observe an additional sales gain of 14 bps, reflecting the importance of early identification of trending products.|互联网用户在 Instagram 和 YouTube 等社交媒体上积极搜索流行产品，这些社交媒体是发现和探索时尚和流行物品的热门中心。电子商务巨头必须具备准确识别、预测和随后向客户展示这些趋势产品的能力。电子商务商店能够有效地满足顾客群不断变化的需求，并通过及时提供最新和最受欢迎的产品，提高整体购物体验。在这项工作中，我们提出了一个框架，预测和表面趋势的产品在电子商务商店，这是第一个类似的最好的我们的知识。我们首先使用可靠的统计检验来定义什么是趋势产品。然后，我们引入一个基于机器学习的早期趋势预测系统，称为趋势观察器，以帮助用户识别即将出现的产品趋势。TrendSpotter 是对最先进的 InceptionTime 模型 citeInceptionTime 的独特改编，该模型根据当前的客户参与度，如点击、购买和其他相关产品属性，预测产品未来的受欢迎程度。我们的方法的有效性通过 A/B 测试得到了证明，我们首先展示了我们基于统计测试的标签策略的有效性，从而使销售额增加了59个基点。1bps = 0.01% ，通过主页和搜索页面的两个实验。随后，我们对我们的机器学习模型和统计标签基线进行了比较，观察到额外的14个基点的销售收益，反映了早期识别趋势产品的重要性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TrendSpotter:+Forecasting+E-commerce+Product+Trends)|0|
|[An Incremental Update Framework for Online Recommenders with Data-Driven Prior](https://doi.org/10.1145/3583780.3615456)|Chen Yang, Jin Chen, Qian Yu, Xiangdong Wu, Kui Ma, Zihao Zhao, Zhiwei Fang, Wenlong Chen, Chaosheng Fan, Jie He, Changping Peng, Zhangang Lin, Jingping Shao|JD.com, Beijing, China; UESTC, Chengdu, China|Online recommenders have attained growing interest and created great revenue for businesses. Given numerous users and items, incremental update becomes a mainstream paradigm for learning large-scale models in industrial scenarios, where only newly arrived data within a sliding window is fed into the model, meeting the strict requirements of quick response. However, this strategy would be prone to overfitting to newly arrived data. When there exists a significant drift of data distribution, the long-term information would be discarded, which harms the recommendation performance. Conventional methods address this issue through native model-based continual learning methods, without analyzing the data characteristics for online recommenders. To address the aforementioned issue, we propose an incremental update framework for online recommenders with Data-Driven Prior (DDP), which is composed of Feature Prior (FP) and Model Prior (MP). The FP performs the click estimation for each specific value to enhance the stability of the training process. The MP incorporates previous model output into the current update while strictly following the Bayes rules, resulting in a theoretically provable prior for the robust update. In this way, both the FP and MP are well integrated into the unified framework, which is model-agnostic and can accommodate various advanced interaction models. Extensive experiments on two publicly available datasets as well as an industrial dataset demonstrate the superior performance of the proposed framework.|在线推荐已经获得了越来越多的兴趣，并为企业创造了巨大的收入。鉴于用户和项目众多，增量更新成为工业场景中学习大规模模型的主流范式，在工业场景中，只有滑动窗口中新到达的数据才被输入模型，以满足快速响应的严格要求。但是，这种策略容易过度适应新到达的数据。当数据分布存在显著漂移时，长期信息会被丢弃，从而影响推荐性能。传统的方法通过基于本地模型的连续学习方法来解决这个问题，而没有分析在线推荐的数据特征。为了解决上述问题，我们提出了一种基于数据驱动优先级(DDP)的在线推荐增量更新框架，该框架由特征优先级(FP)和模型优先级(MP)组成。FP 对每个特定值执行点击估计，以增强培训过程的稳定性。MP 在严格遵循贝叶斯规则的同时，将以前的模型输出合并到当前更新中，从而为鲁棒更新提供了一个理论上可证明的先验。通过这种方式，FP 和 MP 很好地集成到统一框架中，这是模型不可知的，可以适应各种先进的交互模型。在两个公开可用的数据集和一个工业数据集上的大量实验证明了该框架的优越性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Incremental+Update+Framework+for+Online+Recommenders+with+Data-Driven+Prior)|0|
|[SHARK: A Lightweight Model Compression Approach for Large-scale Recommender Systems](https://doi.org/10.1145/3583780.3615499)|Beichuan Zhang, Chenggen Sun, Jianchao Tan, Xinjun Cai, Jun Zhao, Mengqi Miao, Kang Yin, Chengru Song, Na Mou, Yang Song|Kuaishou, Beijing, China|Increasing the size of embedding layers has shown to be effective in improving the performance of recommendation models, yet gradually causing their sizes to exceed terabytes in industrial recommender systems, and hence the increase of computing and storage costs. To save resources while maintaining model performances, we propose SHARK, the model compression practice we have summarized in the recommender system of industrial scenarios. SHARK consists of two main components. First, we use the novel first-order component of Taylor expansion as importance scores to prune the number of embedding tables (feature fields). Second, we introduce a new row-wise quantization method to apply different quantization strategies to each embedding. We conduct extensive experiments on both public and industrial datasets, demonstrating that each component of our proposed SHARK framework outperforms previous approaches. We conduct A/B tests in multiple models on Kuaishou, such as short video, e-commerce, and advertising recommendation models. The results of the online A/B test showed SHARK can effectively reduce the memory footprint of the embedded layer. For the short-video scenarios, the compressed model without any performance drop significantly saves 70% storage and thousands of machines, improves 30\% queries per second (QPS), and has been deployed to serve hundreds of millions of users and process tens of billions of requests every day.|在工业推荐系统中，增加嵌入层的大小可以有效地提高推荐模型的性能，但是会逐渐导致其大小超过 TB，从而增加计算和存储成本。为了在保持模型性能的同时节省资源，我们提出了 SHARK，这是我们在工业场景推荐系统中总结的模型压缩实践。鲨鱼由两个主要部分组成。首先，我们利用泰勒展开的一阶分量作为重要性分数来裁剪嵌入表(特征域)的数目。其次，我们介绍了一种新的行量化方法，对每个嵌入应用不同的量化策略。我们在公共和工业数据集上进行了广泛的实验，证明了我们提出的 SHARK 框架的每个组件都优于以前的方法。我们在 Kuaishou 进行多种模式的 A/B 测试，例如短片、电子商务和广告推荐模式。在线 A/B 测试结果表明，SHARK 可以有效地减少嵌入层的内存占用。对于短视频场景，没有任何性能下降的压缩模型显著地节省了70% 的存储和数千台机器，提高了每秒30% 的查询(QPS) ，并且已经被部署用于服务数亿用户和每天处理数百亿个请求。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SHARK:+A+Lightweight+Model+Compression+Approach+for+Large-scale+Recommender+Systems)|0|
|[Leveraging Watch-time Feedback for Short-Video Recommendations: A Causal Labeling Framework](https://doi.org/10.1145/3583780.3615483)|Yang Zhang, Yimeng Bai, Jianxin Chang, Xiaoxue Zang, Song Lu, Jing Lu, Fuli Feng, Yanan Niu, Yang Song|University of Science and Technology of China, Hefei, China; Kuaishou Technology, Beijing, China; University of Science and Technology of China & USTC Beijing Research Institute, Hefei, China|With the proliferation of short video applications, the significance of short video recommendations has vastly increased. Unlike other recommendation scenarios, short video recommendation systems heavily rely on feedback from watch time. Existing approaches simply treat watch time as a direct label, failing to effectively harness its extensive semantics and introduce bias, thereby limiting the potential for modeling user interests based on watch time. To overcome this challenge, we propose a framework named Debiasied Multiple-semantics-extracting Labeling (DML). DML constructs labels that encompass various semantics by utilizing quantiles derived from the distribution of watch time, prioritizing relative order rather than absolute label values. This approach facilitates easier model learning while aligning with the ranking objective of recommendations. Furthermore, we introduce a method inspired by causal adjustment to refine label definitions, thereby reducing the impact of bias on the label and directly mitigating bias at the label level. We substantiate the effectiveness of our DML framework through both online and offline experiments. Extensive results demonstrate that our DML could effectively leverage watch time to discover users' real interests, enhancing their engagement in our application.|随着短视频应用程序的激增，短视频推荐的重要性大大增加。与其他推荐场景不同，短视频推荐系统严重依赖于观看时间的反馈。现有的方法只是简单地将手表时间作为一个直接标签，未能有效地利用其广泛的语义并引入偏见，从而限制了基于手表时间建模用户兴趣的潜力。为了克服这一挑战，我们提出了一个名为 Debiasied 多语义抽取标记(DML)的框架。DML 通过利用从手表时间分布派生的分位数构造包含各种语义的标签，优先考虑相对顺序而不是绝对标签值。这种方法促进了更容易的模型学习，同时与建议的排名目标保持一致。此外，我们引入了一种方法，受因果调整的启发，以完善标签的定义，从而减少偏见的影响，标签和直接减轻偏见的水平。我们通过两个在线和离线的实验证实了我们的 DML 框架的有效性。大量的结果表明，我们的 DML 可以有效地利用观看时间来发现用户的真正兴趣，提高他们在我们的应用程序中的参与度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Watch-time+Feedback+for+Short-Video+Recommendations:+A+Causal+Labeling+Framework)|0|
|[COPR: Consistency-Oriented Pre-Ranking for Online Advertising](https://doi.org/10.1145/3583780.3615465)|Zhishan Zhao, Jingyue Gao, Yu Zhang, Shuguang Han, Siyuan Lou, XiangRong Sheng, Zhe Wang, Han Zhu, Yuning Jiang, Jian Xu, Bo Zheng|Alibaba Group, Beijing, China|Cascading architecture has been widely adopted in large-scale advertising systems to balance efficiency and effectiveness. In this architecture, the pre-ranking model is expected to be a lightweight approximation of the ranking model, which handles more candidates with strict latency requirements. Due to the gap in model capacity, the pre-ranking and ranking models usually generate inconsistent ranked results, thus hurting the overall system effectiveness. The paradigm of score alignment is proposed to regularize their raw scores to be consistent. However, it suffers from inevitable alignment errors and error amplification by bids when applied in online advertising. To this end, we introduce a consistency-oriented pre-ranking framework for online advertising, which employs a chunk-based sampling module and a plug-and-play rank alignment module to explicitly optimize consistency of ECPM-ranked results. A $\Delta NDCG$-based weighting mechanism is adopted to better distinguish the importance of inter-chunk samples in optimization. Both online and offline experiments have validated the superiority of our framework. When deployed in Taobao display advertising system, it achieves an improvement of up to +12.3\% CTR and +5.6\% RPM.|为了平衡效率和效果，级联体系结构在大规模广告系统中得到了广泛的应用。在这种体系结构中，预排序模型被期望是排序模型的轻量级近似，它处理具有严格延迟要求的更多候选者。由于模型容量的差距，预排序模型和排序模型通常会产生不一致的排序结果，从而影响系统的整体有效性。提出了分数对齐的范式，以规范他们的原始分数是一致的。然而，在网络广告中应用时，不可避免地会出现一致性错误和出价放大错误。为此，我们引入了一个面向一致性的在线广告预排序框架，该框架采用基于块的抽样模块和即插即用的排序对齐模块来显式优化 ECPM 排序结果的一致性。为了更好地区分块间样本在优化中的重要性，采用了基于 $Delta NDCG 的加权机制。这两个在线和离线实验都验证了我们框架的优越性。在淘宝展示广告系统中，点击率和转速分别提高了12.3% 和5.6% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=COPR:+Consistency-Oriented+Pre-Ranking+for+Online+Advertising)|0|
|[Learning What to Ask: Mining Product Attributes for E-commerce Sales from Massive Dialogue Corpora](https://doi.org/10.1145/3583780.3614745)|Yan Fan, Chengyu Wang, Fan Feng, Hengbin Cui, Yuchuan Wu, Yongbin Li|Alibaba Group, Hangzhou, China|Conversational Recommender Systems (CRSs) are extensively applied in e-commercial platforms that recommend items to users. To ensure accurate recommendation, agents usually ask for users' preferences towards specific product attributes which are pre-defined by humans. In e-commercial platforms, however, the number of products easily reaches to billions, making it prohibitive to pre-define decisive attributes for efficient recommendation due to the lack of substantial human resources and the scarce domain expertise. In this work, we present AliMeMOSAIC, a novel knowledge mining and conversational assistance framework that extracts core product attributes from massive dialogue corpora for better conversational recommendation experience. It first extracts user-agent interaction utterances from massive corpora that contain product attributes. A Joint Attribute and Value Extraction (JAVE) network is designed to extract product attributes from user-agent interaction utterances. Finally, AliMeMOSAIC generates attribute sets that frequently appear in dialogues as the target attributes for agents to request, and serve as an assistant to guide the dialogue flow. To prove the effectiveness of AliMeMOSAIC, we show that it consistently improves the overall recommendation performance of our CRS system. An industrial demonstration scenario is further presented to show how it benefits online shopping experiences.|会话推荐系统(CRS)广泛应用于向用户推荐项目的电子商务平台。为了确保准确的推荐，代理通常会询问用户对特定产品属性的偏好，这些属性是由人工预先定义的。然而，在电子商务平台上，产品的数量很容易达到数十亿，由于缺乏大量人力资源和稀缺的领域专门知识，因此无法预先确定有效推荐的决定性属性。在这项工作中，我们提出了 AliMeMOSAIC，一个新的知识挖掘和会话辅助框架，提取核心产品属性从大量的对话语料库，以更好的会话推荐体验。它首先从包含产品属性的海量语料库中提取用户-代理交互语句。设计了一个联合属性和价值提取(JAVE)网络，从用户-代理交互语句中提取产品属性。最后，AliMeMOSAIC 生成对话中经常出现的属性集，作为代理请求的目标属性，并作为指导对话流的助手。为了证明 AliMeMOSAIC 的有效性，我们展示了它持续改善了我们的 CRS 系统的整体推荐性能。进一步介绍了一个工业示范场景，以说明它如何有利于在线购物体验。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+What+to+Ask:+Mining+Product+Attributes+for+E-commerce+Sales+from+Massive+Dialogue+Corpora)|0|
|[Uplift Modeling: From Causal Inference to Personalization](https://doi.org/10.1145/3583780.3615298)|Felipe Moraes, Hugo Manuel Proença, Anastasiia Kornilova, Javier Albert, Dmitri Goldenberg|Booking.com, Tel-Aviv, Israel; Booking.com, Amsterdam, Netherlands|Uplift modeling is a collection of machine learning techniques for estimating causal effects of a treatment at the individual or subgroup levels. Over the last years, causality and uplift modeling have become key trends in personalization at online e-commerce platforms, enabling the selection of the best treatment for each user in order to maximize the target business metric. Uplift modeling can be particularly useful for personalized promotional campaigns, where the potential benefit caused by a promotion needs to be weighed against the potential costs. In this tutorial we will cover basic concepts of causality and introduce the audience to state-of-the-art techniques in uplift modeling. We will discuss the advantages and the limitations of different approaches and dive into the unique setup of constrained uplift modeling. Finally, we will present real-life applications and discuss challenges in implementing these models in production.|提升建模是机器学习技术的集合，用于估计个体或亚组水平治疗的因果效应。在过去几年中，因果关系和提升建模已成为在线电子商务平台个性化的主要趋势，使得能够为每个用户选择最佳待遇，以最大限度地实现目标业务指标。提升模型对于个性化的促销活动特别有用，因为需要权衡促销活动带来的潜在收益和潜在成本。在本教程中，我们将涵盖因果关系的基本概念，并向观众介绍最先进的提升建模技术。我们将讨论不同方法的优点和局限性，并深入探讨约束抬升模型的独特设置。最后，我们将展示实际应用程序，并讨论在生产中实现这些模型的挑战。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Uplift+Modeling:+From+Causal+Inference+to+Personalization)|0|
|[Vigil: Effective End-to-end Monitoring for Large-scale Recommender Systems at Glance](https://doi.org/10.1145/3583780.3615997)|Priyansh Saxena, Manisha R|Glance, Bangalore, India|The success of large-scale recommender systems hinges upon their ability to deliver accurate and timely recommendations to a diverse user base. At Glance, we deliver snackable personalized content to the lock screens of 200M smartphones. In this context, continuous monitoring is paramount as it safeguards data integrity, detects drifts, addresses evolving user preferences, optimizes system downtime, and ultimately augments the system's effectiveness and user satisfaction. In this talk, we delve into Vigil, a set of monitoring practices developed to provide comprehensive end-to-end monitoring of recommender systems at Glance. These practices revolve around three key pillars: mitigating developer fatigue, ensuring precise predictions, and establishing a centralized monitoring framework. By adopting these practices, we have observed a 30% reduction in compute cost, a 26% drop in downtime, and a surge in developer productivity demonstrated by a 45% decrease in turnaround time.|大型推荐系统的成功取决于它们向不同用户群提供准确和及时的推荐的能力。在 Glance，我们为2亿部智能手机的锁定屏幕提供可点心的个性化内容。在这种情况下，持续监控是至关重要的，因为它可以保证数据的完整性，检测漂移，解决不断变化的用户偏好，优化系统停机时间，并最终提高系统的有效性和用户满意度。在这个演讲中，我们深入研究了 Vigil，这是一组监控实践，开发它们是为了在 Glance 中提供对推荐系统的全面的端到端监控。这些实践围绕着三个关键支柱: 减轻开发人员疲劳、确保精确的预测以及建立一个集中的监控框架。通过采用这些实践，我们观察到计算成本降低了30% ，停机时间减少了26% ，开发人员生产力大幅提高，周转时间减少了45% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Vigil:+Effective+End-to-end+Monitoring+for+Large-scale+Recommender+Systems+at+Glance)|0|
|[Prod2Vec-Var: A Session Based Recommendation System with Enhanced Diversity](https://doi.org/10.1145/3583780.3615995)|Hacer Turgut, Tan Doruk Yetki, Ömür Bali, Tayfun Arda Yücel|iLab Ventures, Istanbul, Turkey|Understanding user behavior and leveraging this information in recommendation systems pose challenges for websites lacking a login system or with limited logged-in users. This study introduces the Prod2Vec-Var recommendation system, a modified version of a session-based recommendation algorithm aimed at enhancing the performance of product recommendation systems with a cold-start extension. The proposed model builds upon the original prod2vec algorithm, incorporating an additional step to improve the diversity of product recommendations. The project entails a well-designed data pipeline, effectively processing user actions to align them with the model, and implementing unique functions that expand the range of products capturing users' attention. Moreover, a straightforward yet effective cold-start model is developed to address newly added products that have not been viewed by users. The outcome of our project, namely product suggestions, is presented to users of cimri.com, one of iLab's affiliated companies, which attracts millions of daily visits, thereby enabling seamless access to desired products. Experimental results demonstrated the superior performance of our model compared to the other two different strategies in running recommendation on popular products, as evidenced by favorable R@1, R@5, R@10, and R@15 metrics. Concerning less popular products, we observed an improvement in our model's performance as the value of K increased, ultimately achieving optimal results in terms of R@15. Additionally, our cold-start model for new products substantiated the efficacy of our methodology, yielding the highest scores across R@5, R@10, and R@15 metrics.|理解用户行为并在推荐系统中利用这些信息对缺乏登录系统或登录用户有限的网站构成挑战。本研究介绍了 Prod2Vec-Var 推荐系统，它是基于会话的推荐算法的一个修改版本，旨在通过冷启动扩展来提高产品推荐系统的性能。提出的模型建立在原始的 prod2vec 算法的基础上，包含了一个额外的步骤来改善产品推荐的多样性。该项目需要一个设计良好的数据管道，有效地处理用户行为，使其与模型保持一致，并实现独特的功能，以扩大产品的范围，吸引用户的注意力。此外，还开发了一个简单而有效的冷启动模型，以处理用户尚未查看的新增产品。我们的项目成果，即产品建议，将呈现给 cimri.com 的用户，cimri.com 是 iLab 的附属公司之一，每天吸引数百万的访问量，从而使人们能够无缝地访问想要的产品。实验结果表明，与其他两种不同的策略相比，我们的模型在推荐流行产品方面表现出更好的性能，这可以通过有利的 R@1、 R@5、 R@10和 R@15指标来证明。关于不太受欢迎的产品，我们观察到随着 K 值的增加，我们模型的性能有所改善，最终达到 R@15的最佳结果。此外，我们新产品的冷启动模型证实了我们方法的有效性，在 R@5、 R@10和 R@15指标上得分最高。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Prod2Vec-Var:+A+Session+Based+Recommendation+System+with+Enhanced+Diversity)|0|
|[RePair: An Extensible Toolkit to Generate Large-Scale Datasets for Query Refinement via Transformers](https://doi.org/10.1145/3583780.3615129)|Yogeswar Lakshmi Narayanan, Hossein Fani|University of Windsor, Windsor, ON, Canada|Query refinement is the process of transforming users' queries into newrefined versions without semantic drift to enhance the relevance of search results. Prior query refiners were benchmarked on web query logs followingweak assumptions that users' input queries within a search session are about a single topic and improve gradually, which is not necessarily accurate in practice. In this paper, we contribute RePair, an open-source configurable toolkit to generatelarge-scale gold-standard benchmark datasets whose pairs of (original query, refined versions) arealmost surely guaranteed to be in the same semantic context. RePair takes a dataset of queries and their relevance judgements (e.g., msmarco or aol), a sparse or dense retrieval method (e.g., bm25 or colbert ), and an evaluation metric (e.g., map or mrr), and outputs refined versions of queries, each of which with the relevance improvement guarantees under the retrieval method in terms of the evaluation metric. RePair benefits from text-to-text-transfer-transformer (t5) to generate gold-standard datasets for any input query sets and is designed with extensibility in mind. Out of the box, RePair includes gold-standard datasets for aol and msmarco.passage as well as benchmark results of state-of-the-art supervised query suggestion methods on the generated datasets at https://github.com/fani-lab/RePair.|查询精化是将用户的查询转换为不带语义漂移的新精化版本以增强搜索结果相关性的过程。之前的查询精炼器在网络查询日志上进行了基准测试，这是基于一个薄弱的假设，即用户在搜索会话中的输入查询是关于单个主题的，并且是逐渐改进的，这在实践中并不一定准确。在本文中，我们提供了 RePair，一个开源的可配置工具包，用于生成大规模的黄金标准基准数据集，这些数据集的对(原始查询，精化版本)几乎肯定是在相同的语义上下文中。RePair 采用查询及其相关性判断(例如，mmarco 或 aol)、稀疏或密集检索方法(例如，bm25或 colbert)和评估度量(例如，map 或 mrr)的数据集，并输出精化版本的查询，其中每个查询在检索方法下的相关性改进都在评估度量方面得到保证。RePair 受益于文本到文本传输转换器(t5) ，可以为任何输入查询集生成黄金标准的数据集，并且在设计时考虑到了可扩展性。开箱即用，RePair 包括美国在线和 mmarco.pass 的黄金标准数据集，以及最先进的监督查询建议方法在 https://github.com/fani-lab/RePair 生成的数据集上的基准结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RePair:+An+Extensible+Toolkit+to+Generate+Large-Scale+Datasets+for+Query+Refinement+via+Transformers)|0|
|[Combining Inductive and Deductive Reasoning for Query Answering over Incomplete Knowledge Graphs](https://doi.org/10.1145/3583780.3614816)|Medina Andresel, TrungKien Tran, Csaba Domokos, Pasquale Minervini, Daria Stepanova|Bosch Center for Artificial Intelligence, Renningen, Germany; AIT Austrian Institute of Technology, Vienna, Austria; University of Edinburgh, Edinburgh, United Kingdom|Current methods for embedding-based query answering over incomplete Knowledge Graphs (KGs) only focus on inductive reasoning, i.e., predicting answers by learning patterns from the data, and lack the complementary ability to do deductive reasoning, which requires the application of domain knowledge to infer further information. To address this shortcoming, we investigate the problem of incorporating ontologies into embedding-based query answering models by defining the task of embedding-based ontology-mediated query answering. We propose various integration strategies into prominent representatives of embedding models that involve (1) different ontology-driven data augmentation techniques and (2) adaptation of the loss function to enforce the ontology axioms. We design novel benchmarks for the considered task based on the LUBM and the NELL KGs and evaluate our methods on them. The achieved improvements in the setting that requires both inductive and deductive reasoning are from 20% to 55% in HITS@3.|目前基于嵌入式查询回答的不完整知识图(kGs)方法只关注归纳推理，即通过学习数据模式来预测答案，缺乏做演绎推理的互补能力，这需要应用领域知识来推断进一步的信息。针对这一缺陷，本文通过定义基于嵌入本体的查询回答任务，研究了将本体融入基于嵌入的查询回答模型中的问题。我们提出了各种集成策略的嵌入模型的突出代表，涉及(1)不同的本体驱动的数据增强技术和(2)适应的损失函数，以执行本体公理。我们基于 LUBM 和 NELL 幼儿园设计了新的任务基准，并对我们的方法进行了评估。在 HITS@3中，要求同时具有归纳性和演绎推理的环境改善率由20% 提高到55% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Combining+Inductive+and+Deductive+Reasoning+for+Query+Answering+over+Incomplete+Knowledge+Graphs)|0|
|[GraphERT- Transformers-based Temporal Dynamic Graph Embedding](https://doi.org/10.1145/3583780.3614899)|Moran Beladev, Gilad Katz, Lior Rokach, Uriel Singer, Kira Radinsky|Technion, Haifa, Israel; Ben Gurion University of the Negev, Beer Sheva, Israel|Dynamic temporal graphs evolve over time, adding and removing nodes and edges between time snapshots. The tasks performed on such graphs are diverse and include detecting temporal trends, finding graph-to-graph similarities, and graph visualization and clustering. For all these tasks, it is necessary to embed the entire graph in a low-dimensional space by using graph-level representations instead of the more common node-level representations. This embedding requires handling the appearance of new nodes over time as well as capturing temporal patterns of the entire graph. Most existing methods perform temporal node embeddings and focus on different methods of aggregating them for a graph-based representation. In this work, we propose an end-to-end architecture that captures both the node embeddings and their influence in a structural context during a specific time period of the graph. We present GraphERT (Graph Embedding Representation using Transformers), a novel approach to temporal graph-level embeddings. Our method pioneers the use of Transformers to seamlessly integrate graph structure learning with temporal analysis. By employing a masked language model on sequences of graph random walks, together with a novel temporal classification task, our model not only comprehends the intricate graph dynamics but also unravels the temporal significance of each node and path. This novel training paradigm empowers GraphERT to capture the essence of both the structural and temporal aspects of graphs, surpassing state-of-the-art approaches across multiple tasks on real-world datasets.|动态时间图随着时间的推移而发展，在时间快照之间添加和删除节点和边。在这些图上执行的任务是多种多样的，包括检测时间趋势，发现图到图的相似性，以及图的可视化和聚类。对于所有这些任务，有必要通过使用图级表示代替更常见的节点级表示将整个图嵌入到低维空间中。这种嵌入需要随着时间的推移处理新节点的出现，并捕获整个图的时间模式。大多数现有的方法执行时间节点嵌入，并集中在不同的方法聚合它们为一个基于图的表示。在这项工作中，我们提出了一个端到端的架构，捕获两个节点嵌入和它们的影响在一个结构上下文在一个特定的时间段的图。本文提出了一种新的时态图级嵌入方法——图形嵌入表示(GraphERT)。我们的方法率先使用变压器，以无缝集成图结构学习与时间分析。该模型通过对图的随机游动序列采用掩蔽语言模型，结合一种新的时间分类任务，不仅理解了复杂的图动态，而且揭示了每个节点和路径的时间意义。这种新颖的训练范式使 GraphERT 能够捕捉图形的结构和时间方面的本质，超越现实世界数据集上多个任务的最新方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphERT-+Transformers-based+Temporal+Dynamic+Graph+Embedding)|0|
|[Faster Approximation Algorithms for Parameterized Graph Clustering and Edge Labeling](https://doi.org/10.1145/3583780.3614878)|Vedangi Bengali, Nate Veldt|Texas A&M University, College Station, TX, USA|Graph clustering is a fundamental task in network analysis where the goal is to detect sets of nodes that are well-connected to each other but sparsely connected to the rest of the graph. We present faster approximation algorithms for an NP-hard parameterized clustering framework called LambdaCC, which is governed by a tunable resolution parameter and generalizes many other clustering objectives such as modularity, sparsest cut, and cluster deletion. Previous LambdaCC algorithms are either heuristics with no approximation guarantees, or computationally expensive approximation algorithms. We provide fast new approximation algorithms that can be made purely combinatorial. These rely on a new parameterized edge labeling problem we introduce that generalizes previous edge labeling problems that are based on the principle of strong triadic closure and are of independent interest in social network analysis. Our methods are orders of magnitude more scalable than previous approximation algorithms and our lower bounds allow us to obtain a posteriori approximation guarantees for previous heuristics that have no approximation guarantees of their own.|图聚类是网络分析中的一个基本任务，其目标是检测彼此连接良好但与图的其余部分连接稀疏的节点集。我们提出了一个名为 LambdaCC 的 NP- 硬参数化聚类框架的更快的近似算法，该框架由一个可调的分辨率参数控制，并推广了许多其他聚类目标，如模块化，最稀疏切割和集群删除。以前的 LambdaCC 算法要么是没有近似保证的启发式算法，要么是计算昂贵的近似算法。我们提供了新的快速近似算法，可以使纯组合。这些都依赖于一个新的参数化边标注问题，我们引入了推广以前的边标注问题是基于强三元闭包原理，并在社会网络分析中的独立兴趣。我们的方法比以前的近似算法具有更大的数量级，我们的下限允许我们为以前的启发式算法获得一个没有近似保证的后验近似保证。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Faster+Approximation+Algorithms+for+Parameterized+Graph+Clustering+and+Edge+Labeling)|0|
|[Relevance-based Infilling for Natural Language Counterfactuals](https://doi.org/10.1145/3583780.3615029)|Lorenzo Betti, Carlo Abrate, Francesco Bonchi, Andreas Kaltenbrunner|ISI Foundation & Central European University, Turin, Italy; CENTAI & Sapienza University, Turin, Italy; CENTAI & Eurecat, Turin, Italy; ISI Foundation & Universitat Oberta de Catalunya, Turin, Italy|Counterfactual explanations are a natural way for humans to gain understanding and trust in the outcomes of complex machine learning algorithms. In the context of natural language processing, generating counterfactuals is particularly challenging as it requires the generated text to be fluent, grammatically correct, and meaningful. In this study, we improve the current state of the art for the generation of such counterfactual explanations for text classifiers. Our approach, named RELITC (Relevance-based Infilling for Textual Counterfactuals), builds on the idea of masking a fraction of text tokens based on their importance in a given prediction task and employs a novel strategy, based on the entropy of their associated probability distributions, to determine the infilling order of these tokens. Our method uses less time than competing methods to generate counterfactuals that require less changes, are closer to the original text and preserve its content better, while being competitive in terms of fluency. We demonstrate the effectiveness of the method on four different datasets and show the quality of its outcomes in a comparison with human generated counterfactuals.|反事实解释是人类理解和信任复杂机器学习算法结果的一种自然方式。在自然语言处理的环境中，生成反事实特别具有挑战性，因为它要求生成的文本流畅、语法正确和有意义。在这项研究中，我们改善了目前的技术状况，以生成这样的反事实解释的文本量词。我们的方法被命名为 RELITC (基于相关性的文本反事实填充) ，它基于根据文本标记在给定预测任务中的重要性来掩盖一小部分文本标记的想法，并采用一种新的策略，基于相关概率分布的熵来确定这些标记的填充顺序。我们的方法比竞争的方法用更少的时间来产生反事实，需要更少的变化，更接近原始文本，更好地保存其内容，同时在流畅性方面具有竞争力。我们证明了该方法在四个不同的数据集上的有效性，并通过与人类产生的反事实的比较显示了其结果的质量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Relevance-based+Infilling+for+Natural+Language+Counterfactuals)|0|
|[How Expressive are Graph Neural Networks in Recommendation?](https://doi.org/10.1145/3583780.3614917)|Xuheng Cai, Lianghao Xia, Xubin Ren, Chao Huang|The University of Hong Kong, Hong Kong, China|Graph Neural Networks (GNNs) have demonstrated superior performance on various graph learning tasks, including recommendation, where they leverage user-item collaborative filtering signals in graphs. However, theoretical formulations of their capability are scarce, despite their empirical effectiveness in state-of-the-art recommender models. Recently, research has explored the expressiveness of GNNs in general, demonstrating that message passing GNNs are at most as powerful as the Weisfeiler-Lehman test, and that GNNs combined with random node initialization are universal. Nevertheless, the concept of "expressiveness" for GNNs remains vaguely defined. Most existing works adopt the graph isomorphism test as the metric of expressiveness, but this graph-level task may not effectively assess a model's ability in recommendation, where the objective is to distinguish nodes of different closeness. In this paper, we provide a comprehensive theoretical analysis of the expressiveness of GNNs in recommendation, considering three levels of expressiveness metrics: graph isomorphism (graph-level), node automorphism (node-level), and topological closeness (link-level). We propose the topological closeness metric to evaluate GNNs' ability to capture the structural distance between nodes, which aligns closely with the objective of recommendation. To validate the effectiveness of this new metric in evaluating recommendation performance, we introduce a learning-less GNN algorithm that is optimal on the new metric and can be optimal on the node-level metric with suitable modification. We conduct extensive experiments comparing the proposed algorithm against various types of state-of-the-art GNN models to explore the explainability of the new metric in the recommendation task. For reproducibility, implementation codes are available at https://github.com/HKUDS/GTE.|图形神经网络(GNN)在各种图形学习任务中表现出了卓越的性能，包括推荐，它们利用图形中的用户项目协同过滤信号。然而，他们的能力的理论公式是稀缺的，尽管他们的经验有效性在国家的最先进的推荐模型。最近，研究人员对 GNN 的表达能力进行了一般性的探索，证明了信息传递 GNN 的最大强度与 Weisfeiler-Lehman 检验相当，并且 GNN 与随机节点初始化相结合是通用的。尽管如此，GNN 的“表现性”概念仍然含糊不清。现有的大多数工作都采用图同构测试作为表达能力的度量标准，但是这种图级任务可能不能有效地评估模型的推荐能力，其目标是区分不同亲密度的节点。本文从图同构(图级)、节点自同构(节点级)和拓扑亲密度(链路级)三个层次对推荐中 GNN 的表达能力进行了全面的理论分析。我们提出拓扑贴近度量来评估 GNN 捕获节点间结构距离的能力，这与推荐的目标非常接近。为了验证这一新指标在评估推荐性能方面的有效性，我们引入了一种无学习 GNN 算法，该算法在新指标上是最优的，并且在适当修改后可以在节点级指标上达到最优。我们进行了广泛的实验比较提出的算法与各种类型的国家最先进的 GNN 模型，以探索新的指标在推荐任务的可解释性。为确保可重复性，实施守则可于 https://github.com/hkuds/gte 索取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+Expressive+are+Graph+Neural+Networks+in+Recommendation?)|0|
|[L2R: Lifelong Learning for First-stage Retrieval with Backward-Compatible Representations](https://doi.org/10.1145/3583780.3614947)|Yinqiong Cai, Keping Bi, Yixing Fan, Jiafeng Guo, Wei Chen, Xueqi Cheng|CAS Key Lab of Network Data Science and Technology, ICT, CAS & University of Chinese Academy of Sciences, Beijing, China|First-stage retrieval is a critical task that aims to retrieve relevant document candidates from a large-scale collection. While existing retrieval models have achieved impressive performance, they are mostly studied on static data sets, ignoring that in the real-world, the data on the Web is continuously growing with potential distribution drift. Consequently, retrievers trained on static old data may not suit new-coming data well and inevitably produce sub-optimal results. In this work, we study lifelong learning for first-stage retrieval, especially focusing on the setting where the emerging documents are unlabeled since relevance annotation is expensive and may not keep up with data emergence. Under this setting, we aim to develop model updating with two goals: (1) to effectively adapt to the evolving distribution with the unlabeled new-coming data, and (2) to avoid re-inferring all embeddings of old documents to efficiently update the index each time the model is updated. We first formalize the task and then propose a novel Lifelong Learning method for the first-stage Retrieval, namely L2R. L2R adopts the typical memory mechanism for lifelong learning, and incorporates two crucial components: (1) selecting diverse support negatives for model training and memory updating for effective model adaptation, and (2) a ranking alignment objective to ensure the backward-compatibility of representations to save the cost of index rebuilding without hurting the model performance. For evaluation, we construct two new benchmarks from LoTTE and Multi-CPR datasets to simulate the document distribution drift in realistic retrieval scenarios. Extensive experiments show that L^2R significantly outperforms competitive lifelong learning baselines.|第一阶段检索是一项关键任务，其目的是从大规模的文档集合中检索相关的候选文档。虽然现有的检索模型已经取得了令人印象深刻的性能，但它们大多是在静态数据集上进行研究，忽略了在现实世界中，Web 上的数据随着潜在的分布漂移而不断增长。因此，对静态旧数据进行训练的检索器可能不能很好地适应新数据，并不可避免地产生次优结果。在这项工作中，我们研究了第一阶段检索的终身学习，特别关注于新出现的文档没有标记的情况，因为相关注释的成本很高，而且可能跟不上数据出现的速度。在这种情况下，我们的目标是开发模型更新有两个目标: (1)有效地适应演化的分布与未标记的新来的数据，(2)避免重新推断所有嵌入的旧文档，以有效地更新索引每次模型更新。我们首先将任务形式化，然后为第一阶段的检索提出一种新的终身学习方法，即 L2R。L2R 采用了典型的终身学习记忆机制，包括两个关键部分: (1)选择不同的支持否定来进行模型训练和记忆更新，以便有效地进行模型适应; (2)排序对齐目标，以确保表征的向后兼容性，从而在不损害模型性能的情况下节省索引重建的成本。为了进行评估，我们从 LoTTE 和 Multi-CPR 数据集中构建了两个新的基准来模拟真实检索场景中的文档分布漂移。大量实验表明，L ^ 2R 的表现明显优于竞争性的终身学习基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=L2R:+Lifelong+Learning+for+First-stage+Retrieval+with+Backward-Compatible+Representations)|0|
|[Incorporating Constituent Syntax into Grammatical Error Correction with Multi-Task Learning](https://doi.org/10.1145/3583780.3614931)|Chen Chen, Bo He, Jing Yuan, Chunyan Hou, Xiaojie Yuan|Tianjin University of Technology, Tianjin, China; Nankai University, Tianjin, China|Grammatical Error Correction (GEC) is usually considered as a translation task where an erroneous sentence is treated as the source language and the corrected sentence as the target language. The state-of-the-art GEC models often adopt transformer-based sequence-to-sequence architecture of machine translation. However, most of these approaches ignore the syntactic information because the syntax of an erroneous sentence is also full of errors and not beneficial to GEC. In this paper, we propose a novel Error-Correction Constituent Parsing (ECCP) task which uses the constituent parsing of corrected sentences to avoid the harmful effect of the erroneous sentence. We also propose an architecture that includes one encoder and two decoders. There are millions of parameters in transformer-based GEC models, and the labeled training data is substantially less than synthetic pre-training data. Therefore, adapter layers are added to the proposed architecture, and adapter tuning is used for fine-tuning our model to alleviate the low-resource issue. We conduct experiments on CoNLL-2014, BEA-2019, and JFLEG test datasets in unsupervised and supervised settings. Experimental results show that our method outperforms the-state-of-art baselines and achieves superior performance on all datasets.|语法错误纠正(GEC)通常被认为是一个翻译任务，其中错误的句子被视为源语言，被纠正的句子被视为目标语言。目前最先进的 GEC 模型通常采用基于变压器的序列到序列的机器翻译体系结构。然而，这些方法大多忽略了句法信息，因为错误句子的句法也充满了错误，不利于 GEC。本文提出了一种新的纠错成分分析(ECCP)任务，利用纠错句的成分分析来避免错误句的有害影响。我们还提出了一个包括一个编码器和两个解码器的体系结构。在基于变压器的 GEC 模型中有数百万个参数，标记的训练数据大大少于合成的训练前数据。因此，将适配器层添加到提出的体系结构中，并使用适配器调优来微调我们的模型，以缓解资源不足的问题。我们在 CoNLL-2014、 BEA-2019和 JFLEG 测试数据集上进行了无监督和监督环境下的实验。实验结果表明，该方法的性能优于现有的基线方法，在所有数据集上都取得了较好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Incorporating+Constituent+Syntax+into+Grammatical+Error+Correction+with+Multi-Task+Learning)|0|
|[HEProto: A Hierarchical Enhancing ProtoNet based on Multi-Task Learning for Few-shot Named Entity Recognition](https://doi.org/10.1145/3583780.3614908)|Wei Chen, Lili Zhao, Pengfei Luo, Tong Xu, Yi Zheng, Enhong Chen|University of Science and Technology of China & State Key Laboratory of Cognitive Intelligence, Hefei, China; Huawei Cloud Computing Technologies Co., Ltd, Hangzhou, China|Few-shot Named Entity Recognition (NER) task, which aims to identify and classify entities from different domains with limited training samples, has long been treated as a basic step for knowledge graph (KG) construction. Great efforts have been made on this task with competitive performance, however, they usually treat the two subtasks, namely span detection and type classification, as mutually independent, and the integrity and correlation between subtasks have been largely ignored. Moreover, prior arts may fail to absorb the coarse-grained features of entities, resulting in a semantic-insufficient representation of entity types. To that end, in this paper, we propose a Hierarchical Enhancing ProtoNet (HEProto) based on multi-task learning, which is utilized to jointly learn these two subtasks and model their correlation. Specifically, we adopt contrastive learning to enhance the span boundary information and the type semantic representations in these two subtasks. Then, the hierarchical prototypical network is designed to leverage the coarse-grained information of entities in the type classification stage, which could help the model to better learn the fine-grained semantic representations. Along this line, we construct a similarity margin loss to reduce the similarity between fine-grained entities and other irrelevant coarse-grained prototypes. Finally, extensive experiments on the Few-NERD dataset prove that our solution outperforms competitive baseline methods. The source code of HEProto is available at \hrefhttps://github.com/fanshu6hao/HEProto https://github.com/fanshu6hao/HEProto.|少镜头命名实体识别(NER)任务是利用有限的训练样本对来自不同领域的实体进行识别和分类，长期以来一直被视为构建知识图(KG)的基本步骤。但是，人们往往将跨度检测和类型分类这两个子任务看作是相互独立的，而忽视了子任务之间的完整性和相关性。此外，现有技术可能无法吸收实体的粗粒度特征，导致实体类型的语义表示不足。为此，本文提出了一种基于多任务学习的分层增强协议网(HEProto) ，利用它来联合学习这两个子任务并建立它们之间的关联模型。具体来说，我们采用对比学习来增强这两个子任务中的跨度边界信息和类型语义表示。然后，设计层次化原型网络，在类型分类阶段利用实体的粗粒度信息，帮助模型更好地学习细粒度的语义表示。沿着这条线，我们构造一个相似性边界损失来减少细粒度实体和其他不相关的粗粒度原型之间的相似性。最后，在极少数 NERD 数据集上的大量实验证明了我们的解决方案优于竞争基线方法。HEproto 的源代码可以在 hrefhttps:// github.com/fanshu6hao/HEProto  https://github.com/fanshu6hao/HEProto 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HEProto:+A+Hierarchical+Enhancing+ProtoNet+based+on+Multi-Task+Learning+for+Few-shot+Named+Entity+Recognition)|0|
|[Continual Learning for Generative Retrieval over Dynamic Corpora](https://doi.org/10.1145/3583780.3614821)|Jiangui Chen, Ruqing Zhang, Jiafeng Guo, Maarten de Rijke, Wei Chen, Yixing Fan, Xueqi Cheng|ICT, CAS & University of Chinese Academy of Sciences, Beijing, China; University of Amsterdam, Amsterdam, Netherlands|Generative retrieval (GR) directly predicts the identifiers of relevant documents (i.e., docids) based on a parametric model. It has achieved solid performance on many ad-hoc retrieval tasks. So far, these tasks have assumed a static document collection. In many practical scenarios, however, document collections are dynamic, where new documents are continuously added to the corpus. The ability to incrementally index new documents while preserving the ability to answer queries with both previously and newly indexed relevant documents is vital to applying GR models. In this paper, we address this practical continual learning problem for GR. We put forward a novel Continual-LEarner for generatiVE Retrieval (CLEVER) model and make two major contributions to continual learning for GR: (i) To encode new documents into docids with low computational cost, we present Incremental Product Quantization, which updates a partial quantization codebook according to two adaptive thresholds; and (ii) To memorize new documents for querying without forgetting previous knowledge, we propose a memory-augmented learning mechanism, to form meaningful connections between old and new documents. Empirical results demonstrate the effectiveness and efficiency of the proposed model.|生成检索(GR)基于参数模型直接预测相关文档(即文档)的标识符。它在许多自组织检索任务中取得了可靠的性能。到目前为止，这些任务都假定为静态文档集合。然而，在许多实际场景中，文档集合是动态的，其中新文档不断地添加到语料库中。增量索引新文档的能力，同时保留用先前和新索引的相关文档回答查询的能力，对于应用 GR 模型至关重要。在本文中，我们解决了这个实际的 GR 连续学习问题。我们提出了一种新的生成式虚拟检索(CLEVER)的 Continual-LEarner 模型，并为 GR 的持续学习做出了两个主要贡献: (i)为了以较低的计算成本将新文档编码成文档，我们提出了增量产品量化，它根据两个自适应阈值更新部分量化码书; (ii)为了在不忘记先前知识的情况下记忆查询新文档，我们提出了一种记忆增强学习机制，在新旧文档之间形成有意义的联系。实证结果证明了该模型的有效性和有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Continual+Learning+for+Generative+Retrieval+over+Dynamic+Corpora)|0|
|[I3 Retriever: Incorporating Implicit Interaction in Pre-trained Language Models for Passage Retrieval](https://doi.org/10.1145/3583780.3614923)|Qian Dong, Yiding Liu, Qingyao Ai, Haitao Li, Shuaiqiang Wang, Yiqun Liu, Dawei Yin, Shaoping Ma|Baidu Inc., Beijing, China; Tsinghua University, Beijing, China|Passage retrieval is a fundamental task in many information systems, such as web search and question answering, where both efficiency and effectiveness are critical concerns. In recent years, neural retrievers based on pre-trained language models (PLM), such as dual-encoders, have achieved huge success. Yet, studies have found that the performance of dual-encoders are often limited due to the neglecting of the interaction information between queries and candidate passages. Therefore, various interaction paradigms have been proposed to improve the performance of vanilla dual-encoders. Particularly, recent state-of-the-art methods often introduce late-interaction during the model inference process. However, such late-interaction based methods usually bring extensive computation and storage cost on large corpus. Despite their effectiveness, the concern of efficiency and space footprint is still an important factor that limits the application of interaction-based neural retrieval models. To tackle this issue, we Incorporate Implicit Interaction into dual-encoders, and propose I3 retriever. In particular, our implicit interaction paradigm leverages generated pseudo-queries to simulate query-passage interaction, which jointly optimizes with query and passage encoders in an end-to-end manner. It can be fully pre-computed and cached, and its inference process only involves simple dot product operation of the query vector and passage vector, which makes it as efficient as the vanilla dual encoders. We conduct comprehensive experiments on MSMARCO and TREC2019 Deep Learning Datasets, demonstrating the I3 retriever's superiority in terms of both effectiveness and efficiency. Moreover, the proposed implicit interaction is compatible with special pre-training and knowledge distillation for passage retrieval, which brings a new state-of-the-art performance. The codes are available at https://github.com/Deriq-Qian-Dong/III-Retriever.|短文检索是许多信息系统(如网络搜索和问答系统)的基本任务，其效率和有效性是关键问题。近年来，基于预训练语言模型(PLM)的神经检索器(如双编码器)取得了巨大的成功。然而，研究发现，由于忽略了查询和候选段之间的交互信息，双编码器的性能往往受到限制。因此，人们提出了各种交互模式来提高普通双编码器的性能。特别是，最近最先进的方法经常在模型推理过程中引入后期交互。然而，这种基于后期交互的方法通常会在大型语料库上带来大量的计算和存储开销。尽管有效，但对效率和空间足迹的关注仍然是限制基于交互的神经检索模型应用的一个重要因素。为了解决这个问题，我们将隐式交互集成到双编码器中，并提出了 I3检索器。特别是，我们的隐式交互范例利用生成的伪查询来模拟查询-通道交互，它与查询和通道编码器以端到端的方式进行联合优化。它可以完全预先计算和缓存，其推理过程只涉及查询向量和通道向量的简单点乘操作，这使得它像普通的双重编码器一样高效。我们在 MSMARCO 和 TREC2019深度学习数据集上进行了全面的实验，证明了 I3检索器在有效性和效率方面的优势。此外，提出的隐式交互与文章检索的专门预训练和知识提取兼容，带来了新的技术水平的性能。密码可以在 https://github.com/deriq-qian-dong/iii-retriever 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=I3+Retriever:+Incorporating+Implicit+Interaction+in+Pre-trained+Language+Models+for+Passage+Retrieval)|0|
|[Optimal Linear Subspace Search: Learning to Construct Fast and High-Quality Schedulers for Diffusion Models](https://doi.org/10.1145/3583780.3614999)|Zhongjie Duan, Chengyu Wang, Cen Chen, Jun Huang, Weining Qian|East China Normal University, Shanghai, China; Alibaba Group, Hangzhou, China|In recent years, diffusion models have become the most popular and powerful methods in the field of image synthesis, even rivaling human artists in artistic creativity. However, the key issue currently limiting the application of diffusion models is its extremely slow generation process. Although several methods were proposed to speed up the generation process, there still exists a trade-off between efficiency and quality. In this paper, we first provide a detailed theoretical and empirical analysis of the generation process of the diffusion models based on schedulers. We transform the designing problem of schedulers into the determination of several parameters, and further transform the accelerated generation process into an expansion process of the linear subspace. Based on these analyses, we consequently propose a novel method called Optimal Linear Subspace Search (OLSS), which accelerates the generation process by searching for the optimal approximation process of the complete generation process in the linear subspaces spanned by latent variables. OLSS is able to generate high-quality images with a very small number of steps. To demonstrate the effectiveness of our method, we conduct extensive comparative experiments on open-source diffusion models. Experimental results show that with a given number of steps, OLSS can significantly improve the quality of generated images. Using an NVIDIA A100 GPU, we make it possible to generate a high-quality image by Stable Diffusion within only one second without other optimization techniques.|近年来，扩散模型已经成为图像合成领域中最流行、最有力的方法，甚至在艺术创造力方面可以与人类艺术家相媲美。然而，目前限制扩散模型应用的关键问题是其生成过程极其缓慢。虽然提出了几种方法来加快生成过程，但仍然存在效率和质量之间的平衡。本文首先对基于调度器的扩散模型的生成过程进行了详细的理论和实证分析。将调度器的设计问题转化为多个参数的确定问题，并将加速生成过程进一步转化为线性子空间的展开过程。在此基础上，提出了一种新的最优线性子空间搜索(OLSS)方法，该方法通过在潜变量跨度的线性子空间中搜索完全生成过程的最优逼近过程来加速生成过程。OLSS 只需很少的步骤就能生成高质量的图像。为了证明我们方法的有效性，我们对开源扩散模型进行了广泛的比较实验。实验结果表明，在给定步长的情况下，OLSS 可以显著提高图像的质量。使用 NVIDIA A100图形处理器，我们可以在不使用其他优化技术的情况下，通过稳定扩散在仅仅一秒钟内生成高质量的图像。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimal+Linear+Subspace+Search:+Learning+to+Construct+Fast+and+High-Quality+Schedulers+for+Diffusion+Models)|0|
|[KG4Ex: An Explainable Knowledge Graph-Based Approach for Exercise Recommendation](https://doi.org/10.1145/3583780.3614943)|Quanlong Guan, Fang Xiao, Xinghe Cheng, Liangda Fang, Ziliang Chen, Guanliang Chen, Weiqi Luo|Jinan University, Guangzhou, China; Monash University, Melbourne, Australia|Effective exercise recommendation is crucial for guiding students' learning trajectories and fostering their interest in the subject matter. However, the vast exercise resource and the varying learning abilities of individual students pose a significant challenge in selecting appropriate exercise questions. Collaborative filtering-based methods often struggle with recommending suitable exercises, while deep learning-based methods lack explanation, limiting their practical adoption. To address these limitations, this paper proposes KG4Ex, a knowledge graph-based exercise recommendation method. KG4Ex facilitates the matching of diverse students with suitable exercises while providing recommendation reasons. Specifically, we introduce a feature extraction module to represent students' learning states and construct a knowledge graph for exercise recommendation. This knowledge graph comprises three key entities (knowledge concepts, students, and exercises) and their interrelationships, and can be used to recommend suitable exercises. Extensive experiments on three real-world datasets and expert interviews demonstrate the superiority of KG4Ex over existing baseline methods and highlight its strong explainability.|有效的练习推荐对于引导学生的学习轨迹和培养他们对科目的兴趣是至关重要的。然而，大量的练习资源和个别学生不同的学习能力对选择合适的练习题提出了重大挑战。基于协作过滤的方法往往难以推荐合适的练习，而基于深度学习的方法缺乏解释，限制了它们的实际应用。针对这些局限性，本文提出了一种基于知识图的练习推荐方法 KG4Ex。KG4Ex 在提供推荐理由的同时，为不同类型的学生提供合适的练习。具体地说，我们引入了一个特征提取模块来表示学生的学习状态，并构造了一个用于练习推荐的知识图。这个知识图包括三个关键实体(知识概念、学生和练习)及其相互关系，可以用来推荐合适的练习。通过对三个现实世界数据集的大量实验和专家访谈，证明了 KG4Ex 相对于现有基线方法的优越性，并突出了其强大的可解释性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KG4Ex:+An+Explainable+Knowledge+Graph-Based+Approach+for+Exercise+Recommendation)|0|
|[Targeted Shilling Attacks on GNN-based Recommender Systems](https://doi.org/10.1145/3583780.3615073)|Sihan Guo, Ting Bai, Weihong Deng|Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing , China|GNN-based recommender systems have shown their vulnerability to shilling attacks in recent studies. By conducting shilling attacks on recommender systems, the attackers aim to have homogeneous impacts on all users. However, such indiscriminate attacks suffer from a waste of resources because even if the target item is promoted to users who are not interested, they are unlikely to click on them. In this paper, we conduct targeted shilling attacks in GNN-based recommender systems. By automatically constructing the features and edges of the fake users, our proposed framework AutoAttack achieves accurate attacks on a specific group of users while minimizing the impact on non-target users. Specifically, the features of fake users are generated based on a similarity function, which is optimized according to the features of target users. The structure of fake users is learned by conducting spectral clustering on the target users based on their graph Laplacian matrix, which contains the degree and adjacency information that provides guidance to the edge generation of fake users. We conduct extensive experiments on four real-world datasets in different GNN-based RS and evaluate the performance of our method on the shilling attack and recommendation tasks comprehensively, showing the effectiveness and flexibility of our framework.|在最近的研究中，基于 GNN 的推荐系统已经显示了它们对先令攻击的脆弱性。通过对推荐系统进行先令式攻击，攻击者的目标是对所有用户产生同样的影响。然而，这种不分青红皂白的攻击造成资源浪费，因为即使目标项目被推广给不感兴趣的用户，他们也不太可能点击这些项目。本文在基于 GNN 的推荐系统中进行有针对性的先令攻击。通过自动构造虚假用户的特征和边缘，我们提出的框架自动攻击实现了对特定用户群的准确攻击，同时最小化了对非目标用户的影响。具体来说，基于相似度函数生成虚假用户的特征，并根据目标用户的特征进行优化。虚假用户的结构是通过基于目标用户的图形 SVD 来了解的，图形 Laplacian Matrix 包含程度和邻接信息，为虚假用户的边缘生成提供指导。我们在四个不同的基于 GNN 的 RS 的真实世界数据集上进行了广泛的实验，全面评估了我们的方法在先令攻击和推荐任务上的性能，显示了我们的框架的有效性和灵活性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Targeted+Shilling+Attacks+on+GNN-based+Recommender+Systems)|0|
|[Robust Basket Recommendation via Noise-tolerated Graph Contrastive Learning](https://doi.org/10.1145/3583780.3615039)|Xinrui He, Tianxin Wei, Jingrui He|University of Illinois at Urbana-Champaign, Champaign, USA|The growth of e-commerce has seen a surge in popularity of platforms like Amazon, eBay, and Taobao. This has given rise to a unique shopping behavior involving baskets - sets of items purchased together. As a less studied interaction mode in the community, the question of how should shopping basket complement personalized recommendation systems remains under-explored. While previous attempts focused on jointly modeling user purchases and baskets, the distinct semantic nature of these elements can introduce noise when directly integrated. This noise negatively impacts the model's performance, further exacerbated by significant noise (e.g., a user is misled to click an item or recognizes it as uninteresting after consuming it) within both user and basket behaviors. In order to cope with the above difficulties, we propose a novel Basket recommendation framework via Noise-tolerated Contrastive Learning, named BNCL, to handle the noise existing in the cross-behavior integration and within-behavior modeling. First, we represent the basket-item interactions as the hypergraph to model the complex basket behavior, where all items appearing in the same basket are treated as a single hyperedge. Second, cross-behavior contrastive learning is designed to suppress the noise during the fusion of diverse behaviors. Next, to further inhibit the within-behavior noise of the user and basket interactions, we propose to exploit invariant properties of the recommenders w.r.t augmentations through within-behavior contrastive learning. A novel consistency-aware augmentation approach is further designed to better identify the noisy interactions with the consideration of the above two types of interactions. Our framework BNCL offers a generic training paradigm that is applicable to different backbones. Extensive experiments on three shopping transaction datasets verify the effectiveness of our proposed method.|随着电子商务的发展，像亚马逊、 eBay 和淘宝这样的平台越来越受欢迎。这就产生了一种独特的购物行为，包括一篮子一套的商品一起购买。作为一种研究较少的社区互动模式，购物篮应该如何补充个性化推荐系统的问题仍然没有得到充分的探讨。虽然以前的尝试侧重于联合建模用户购买和购物篮，但是当直接集成时，这些元素独特的语义特性可能会引入噪音。这种噪音会对模型的性能产生负面影响，而在用户和购物篮的行为中，显著的噪音会进一步加剧这种影响(例如，用户被误导去点击一个项目，或者在消费之后认为它没有意思)。为了克服上述困难，我们提出了一种新的基于噪声容忍对比学习的 Basket 推荐框架 BNCL，用于处理跨行为集成和行为内建模中存在的噪声。首先，我们将篮子项目的交互作用表示为超图来模拟复杂的篮子行为，其中出现在同一个篮子中的所有项目都被视为一个单一的超边。其次，设计交叉行为对比学习来抑制不同行为融合过程中的噪声。接下来，为了进一步抑制用户和篮子交互的行为内噪声，我们建议通过行为内对比学习来利用推荐者 w.r.t 增强的不变性。进一步设计了一种新的一致性增强方法，以便在考虑上述两类相互作用的情况下更好地识别噪声相互作用。我们的框架 BNCL 提供了一个通用的培训范例，适用于不同的骨干。在三个购物交易数据集上的大量实验验证了该方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Basket+Recommendation+via+Noise-tolerated+Graph+Contrastive+Learning)|0|
|[Search-Efficient Computerized Adaptive Testing](https://doi.org/10.1145/3583780.3615049)|Yuting Hong, Shiwei Tong, Wei Huang, Yan Zhuang, Qi Liu, Enhong Chen, Xin Li, Yuanjing He|University of Science and Technology of China & iFLYTEK Co., Ltd, Hefei, China; Open University of China, Beijing, China; University of Science and Technology of China & State Key Laboratory of Cognitive Intelligence, Hefei, China|Computerized Adaptive Testing (CAT) arises as a promising personalized test mode in online education, targeting at revealing students' latent knowledge state by selecting test items adaptively. The item selection strategy is the core component of CAT, which searches for the best suitable test item based on students' current estimated ability at each test step. However, existing selection strategies behave in a brute-force manner, which results in the time complexity being linear to the number of items (N) in the item pool, i.e., O(N). Thus, in reality, the search latency becomes the bottleneck for CAT with a large-scale item pool. To this end, we propose a Search-Efficient Computerized Adaptive Testing framework (SECAT), which aims at enhancing CAT with an efficient selection strategy. Specifically, SECAT contains two main phases: item pool indexing and item search. In the item pool indexing phase, we apply a student-aware spatial partition method on the item pool to divide the test items into many sub-spaces, considering the adaptability of test items. In the item search phase, we optimize the traditional single-round search strategy with the asymptotic theory and propose a multi-round search strategy that can further improve the time efficiency. Compared with existing strategies, the time complexity of SECAT decreases from O(N) to O(logN). Across two real-world datasets, SECAT achieves over 200x speed up with negligible accuracy degradation.|计算机自适应测试(CAT)作为一种新兴的网络教育个性化测试模式，旨在通过自适应选择测试项目来揭示学生的潜在知识状态。试题选择策略是计算机辅助测试(CAT)的核心组成部分，它根据学生在每个测试步骤中的当前估计能力来寻找最适合的试题。然而，现有的选择策略表现出一种蛮力的方式，导致时间复杂度与项目池中的项目数(N)成线性关系，即 O (N)。因此，在现实中，搜索延迟成为大规模项目池 CAT 的瓶颈。为此，我们提出了一个搜索效率高的计算机自适应测试框架(SECAT) ，旨在通过一种有效的选择策略来增强 CAT。具体来说，SECAT 包含两个主要阶段: 项目池索引和项目搜索。在试题库索引阶段，考虑试题的适应性，在试题库上采用学生感知的空间划分方法，将试题划分为多个子空间。在项目搜索阶段，我们利用渐近理论优化了传统的单轮搜索策略，并提出了多轮搜索策略，进一步提高了时间效率。与已有策略相比，SECAT 的时间复杂度从 O (N)降低到 O (logN)。通过两个真实世界的数据集，SECAT 在可以忽略不计的精度降低的情况下实现了超过200倍的速度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Search-Efficient+Computerized+Adaptive+Testing)|0|
|[Celebrity-aware Graph Contrastive Learning Framework for Social Recommendation](https://doi.org/10.1145/3583780.3614806)|Zheng Hu, Satoshi Nakagawa, Liang Luo, Yu Gu, Fuji Ren|The University of Tokyo, Tokyo, Japan; University of Electronic Science and Technology of China, Chengdu, China|Social networks exhibit a distinct "celebrity effect" whereby influential individuals have a more significant impact on others compared to ordinary individuals, unlike other network structures such as citation networks and knowledge graphs. Despite its common occurrence in social networks, the celebrity effect is frequently overlooked by existing social recommendation methods when modeling social relationships, thereby hindering the full exploitation of social networks to mine similarities between users. In this paper, we fill this gap and propose a Celebrity-aware Graph Contrastive Learning Framework for Social Recommendation (CGCL), which explicitly models the celebrity effect in the social domain. Technically, we measure the different influences of celebrity and ordinary nodes by mining social network structure features, such as closeness centrality. To model the celebrity effect in social networks, we design a novel user-user impact-aware aggregation method, which incorporates the celebrity-aware influence information into the message propagation process. Additionally, we design a graph neural network-based framework which incorporates social semantics into the user-item interaction modeling with contrastive learning-enhanced data augmentation. The experimental results on three real-world datasets show the effectiveness of the proposed framework. We conduct ablation experiments to prove that the key components of our model benefit the recommendation performance improvement.|与引用网络和知识图表等其他网络结构不同，社交网络表现出明显的“名人效应”，与普通个体相比，有影响力的个体对他人的影响更为显著。尽管名人效应在社交网络中普遍存在，但现有的社交推荐方法在对社交关系建模时往往忽视了名人效应，从而阻碍了对社交网络的充分利用以挖掘用户之间的相似性。在本文中，我们填补了这一空白，并提出了一个名人感知的图形对比学习框架(CGCL)的社会推荐，显式模型的名人效应的社会领域。在技术上，我们通过挖掘社会网络结构特征，如亲密度中心性，来衡量名人和普通节点的不同影响。为了模拟社交网络中的名人效应，我们设计了一种新的用户-用户影响感知聚合方法，该方法将名人感知的影响信息融入到信息传播过程中。此外，我们还设计了一个基于图神经网络的框架，该框架将社会语义引入到用户项目交互建模中，通过对比学习增强数据增强。在三个实际数据集上的实验结果表明了该框架的有效性。通过烧蚀实验证明了该模型的关键部分有利于推荐性能的提高。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Celebrity-aware+Graph+Contrastive+Learning+Framework+for+Social+Recommendation)|0|
|[Independent Distribution Regularization for Private Graph Embedding](https://doi.org/10.1145/3583780.3614933)|Qi Hu, Yangqiu Song|HKUST, Hong Kong, Hong Kong|Learning graph embeddings is a crucial task in graph mining tasks. An effective graph embedding model can learn low-dimensional representations from graph-structured data for data publishing benefiting various downstream applications such as node classification, link prediction, etc. However, recent studies have revealed that graph embeddings are susceptible to attribute inference attacks, which allow attackers to infer private node attributes from the learned graph embeddings. To address these concerns, privacy-preserving graph embedding methods have emerged, aiming to simultaneously consider primary learning and privacy protection through adversarial learning. However, most existing methods assume that representation models have access to all sensitive attributes in advance during the training stage, which is not always the case due to diverse privacy preferences. Furthermore, the commonly used adversarial learning technique in privacy-preserving representation learning suffers from unstable training issues. In this paper, we propose a novel approach called Private Variational Graph AutoEncoders (PVGAE) with the aid of independent distribution penalty as a regularization term. Specifically, we split the original variational graph autoencoder (VGAE) to learn sensitive and non-sensitive latent representations using two sets of encoders. Additionally, we introduce a novel regularization to enforce the independence of the encoders. We prove the theoretical effectiveness of regularization from the perspective of mutual information. Experimental results on three real-world datasets demonstrate that PVGAE outperforms other baselines in private embedding learning regarding utility performance and privacy protection.|图嵌入学习是图挖掘任务中的一个关键问题。一个有效的图嵌入模型可以从图结构化数据中学习低维表示，用于数据发布，有利于各种下游应用，如节点分类、链路预测等。然而，最近的研究表明，图嵌入容易受到属性推理攻击，使攻击者能够从学习的图嵌入中推断出私有节点的属性。为了解决这些问题，出现了保护隐私的图嵌入方法，旨在同时考虑初级学习和通过对抗学习保护隐私。然而，现有的大多数方法都假设表示模型在训练阶段可以提前访问所有敏感属性，但由于隐私偏好的不同，这种假设并不总是成立。此外，隐私保护表征学习中常用的对抗学习技术存在不稳定的训练问题。在本文中，我们提出了一种新的方法称为私有变分图自动编码器(PVGAE)的援助下，独立分布罚金作为一个正则化项。具体来说，我们将原始的变分图自动编码器(VGAE)分离，使用两组编码器来学习敏感和非敏感的潜在表示。此外，我们还引入了一种新的正则化方法来增强编码器的独立性。从互信息的角度证明了正则化的理论有效性。在三个实际数据集上的实验结果表明，PVGAE 在效用性能和隐私保护方面优于其他基线的私有嵌入学习。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Independent+Distribution+Regularization+for+Private+Graph+Embedding)|0|
|[Enhancing the Robustness via Adversarial Learning and Joint Spatial-Temporal Embeddings in Traffic Forecasting](https://doi.org/10.1145/3583780.3614868)|Juyong Jiang, Binqing Wu, Ling Chen, Kai Zhang, Sunghun Kim|East China Normal University, Shanghai, China; The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; Zhejiang University, Hangzhou, China|Traffic forecasting is an essential problem in urban planning and computing. The complex dynamic spatial-temporal dependencies among traffic objects (e.g., sensors and road segments) have been calling for highly flexible models; unfortunately, sophisticated models may suffer from poor robustness especially in capturing the trend of the time series (1st-order derivatives with time), leading to unrealistic forecasts. To address the challenge of balancing dynamics and robustness, we propose TrendGCN, a new scheme that extends the flexibility of GCNs and the distribution-preserving capacity of generative and adversarial loss for handling sequential data with inherent statistical correlations. On the one hand, our model simultaneously incorporates spatial (node-wise) embeddings and temporal (time-wise) embeddings to account for heterogeneous space-and-time convolutions; on the other hand, it uses GAN structure to systematically evaluate statistical consistencies between the real and the predicted time series in terms of both the temporal trending and the complex spatial-temporal dependencies. Compared with traditional approaches that handle step-wise predictive errors independently, our approach can produce more realistic and robust forecasts. Experiments on six benchmark traffic forecasting datasets and theoretical analysis both demonstrate the superiority and the state-of-the-art performance of TrendGCN. Source code is available at https://github.com/juyongjiang/TrendGCN.|交通量预测是城市规划和计算中的一个基本问题。交通对象(如传感器和路段)之间复杂的动态时空依赖性一直要求高度灵活的模型; 不幸的是，复杂的模型可能会受到鲁棒性差的影响，特别是在捕捉时间序列的趋势(随时间的一阶导数)时，导致不切实际的预测。为了解决平衡动态和稳健性的挑战，我们提出了 TrendGCN，这是一种新的方案，扩展了 GCNs 的灵活性以及生成和对抗性损失的分布保持能力，用于处理具有固有统计相关性的顺序数据。一方面，我们的模型同时结合了空间(节点)嵌入和时间(时间)嵌入来解释异质的时空卷积; 另一方面，它使用 GAN 结构来系统地评估实际时间序列和预测时间序列之间的统计一致性，包括时间趋势和复杂的时空相关性。与独立处理逐步预测误差的传统方法相比，我们的方法可以产生更加真实和稳健的预测。通过对6个基准流量预测数据集的实验和理论分析，验证了趋势 GCN 的优越性和最新性能。源代码可在 https://github.com/juyongjiang/trendgcn 下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+the+Robustness+via+Adversarial+Learning+and+Joint+Spatial-Temporal+Embeddings+in+Traffic+Forecasting)|0|
|[Replace Scoring with Arrangement: A Contextual Set-to-Arrangement Framework for Learning-to-Rank](https://doi.org/10.1145/3583780.3615031)|Jiarui Jin, Xianyu Chen, Weinan Zhang, Mengyue Yang, Yang Wang, Yali Du, Yong Yu, Jun Wang|University College London, London, United Kingdom; Shanghai Jiao Tong University, Shanghai, China; East China Normal University, Shanghai, China; King's College London, London, United Kingdom|Learning-to-rank is a core technique in the top-N recommendation task, where an ideal ranker would be a mapping from an item set to an arrangement (a.k.a. permutation). Most existing solutions fall in the paradigm of probabilistic ranking principle (PRP), i.e., first score each item in the candidate set and then perform a sort operation to generate the top ranking list. However, these approaches neglect the contextual dependence among candidate items during individual scoring, and the sort operation is non-differentiable. To bypass the above issues, we propose Set-To-Arrangement Ranking (STARank), a new framework directly generates the permutations of the candidate items without the need for individually scoring and sort operations; and is end-to-end differentiable. As a result, STARank can operate when only the ground-truth permutations are accessible without requiring access to the ground-truth relevance scores for items. For this purpose, STARank first reads the candidate items in the context of the user browsing history, whose representations are fed into a Plackett-Luce module to arrange the given items into a list. To effectively utilize the given ground-truth permutations for supervising STARank, we leverage the internal consistency property of Plackett-Luce models to derive a computationally efficient list-wise loss. Experimental comparisons against 9 the state-of-the-art methods on 2 learning-to-rank benchmark datasets and 3 top-N real-world recommendation datasets demonstrate the superiority of STARank in terms of conventional ranking metrics. Notice that these ranking metrics do not consider the effects of the contextual dependence among the items in the list, we design a new family of simulation-based ranking metrics, where existing metrics can be regarded as special cases. STARank can consistently achieve better performance in terms of PBM and UBM simulation-based metrics.|学习排名是排名前 N 的推荐任务中的一项核心技术，理想的排名应该是从一个项目集到一个排列(又称排列)的映射。大多数现有的解决方案属于概率排序原则(PRP)的范式，即首先给候选集中的每个项目打分，然后执行排序操作来生成最高排名列表。然而，这些方法忽略了个体评分过程中候选项之间的上下文依赖性，且排序操作是不可微的。为了绕过上述问题，我们提出了一个新的框架集到排列排序(STARank) ，它直接生成候选项的排列，而不需要单独的评分和排序操作，并且是端到端可微的。因此，STARank 可以在只有地面真相排列可以访问时运行，而不需要访问项目的地面真相相关分数。为此，STARank 首先在用户浏览历史记录的上下文中读取候选项，其表示被提供给 Plackett-Luce 模块，以便将给定的项排列成列表。为了有效地利用给定的地面真理排列来监督 STARank，我们利用 Plackett-Luce 模型的内部一致性特性来导出一个计算有效的列表损失。通过对2个学习排名基准数据集和3个排名前 N 的实际推荐数据集的9种最新方法的实验比较，证明了 STARank 在常规排名指标方面的优越性。请注意，这些排名指标没有考虑列表中项目之间的上下文相关性的影响，我们设计了一个新的基于模拟的排名指标家族，其中现有的指标可以被视为特殊情况。STARank 在基于 PBM 和基于 UBM 仿真的度量方面能够持续地获得更好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Replace+Scoring+with+Arrangement:+A+Contextual+Set-to-Arrangement+Framework+for+Learning-to-Rank)|0|
|[Real-time Emotion Pre-Recognition in Conversations with Contrastive Multi-modal Dialogue Pre-training](https://doi.org/10.1145/3583780.3615024)|Xincheng Ju, Dong Zhang, Suyang Zhu, Junhui Li, Shoushan Li, Guodong Zhou|Soochow University, Suzhou, China|This paper presents our pioneering effort in addressing a new and realistic scenario in multi-modal dialogue systems called Multi-modal Real-time Emotion Pre-recognition in Conversations (MREPC). The objective is to predict the emotion of a forthcoming target utterance that is highly likely to occur. We believe that this task can enhance the dialogue system's understanding of the interlocutor's state of mind, enabling it to prepare an appropriate response in advance. However, addressing MREPC poses the following challenges:1) Previous studies on emotion elicitation typically focus on textual modality and perform sentiment forecasting within a fixed contextual scenario. 2) Previous studies on multi-modal emotion recognition aim to predict the emotion of existing utterances, making it difficult to extend these approaches to MREPC due to the absence of the target utterance. To tackle these challenges, we construct two benchmark multi-modal datasets for MREPC and propose a task-specific multi-modal contrastive pre-training approach. This approach leverages large-scale unlabeled multi-modal dialogues to facilitate emotion pre-recognition for potential utterances of specific target speakers. Through detailed experiments and extensive analysis, we demonstrate that our proposed multi-modal contrastive pre-training architecture effectively enhances the performance of multi-modal real-time emotion pre-recognition in conversations.|本文介绍了我们在处理多模态对话系统中的一个新的和现实的场景，称为多模态实时情绪会话预识别(MREPC)的开拓性工作。目的是预测一个即将到来的目标话语的情绪，这是非常可能发生的。我们相信，这一任务可以提高对话系统对对话者心理状态的理解，使其能够提前准备好适当的应对措施。然而，解决 MREPC 问题带来了以下挑战: 1)以往的情绪诱发研究主要集中在语篇情态上，在固定的语境情景下进行情绪预测。2)以往对多模态情绪识别的研究主要是针对已有话语的情绪预测，但由于目标话语的缺失，这些方法难以推广到 MREPC。为了应对这些挑战，我们构建了两个基准的 MREPC 多模态数据集，并提出了一种针对特定任务的多模态对比预训练方法。该方法利用大规模未标记的多模态对话，促进对特定目标说话人潜在话语的情感预识别。通过详细的实验和广泛的分析表明，本文提出的多模态对比预训练结构有效地提高了会话中多模态实时情绪预识别的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Real-time+Emotion+Pre-Recognition+in+Conversations+with+Contrastive+Multi-modal+Dialogue+Pre-training)|0|
|[Nudging Neural Click Prediction Models to Pay Attention to Position](https://doi.org/10.1145/3583780.3614994)|Efi Karra Taniskidou, Wenjie Zhao, Iain Murray, Roberto Pellegrini|Amazon, Edinburgh, United Kingdom; Amazon & The University of Edinburgh, Edinburgh, United Kingdom|Predicting the click-through rate (CTR) of an item is a fundamental task in online advertising and recommender systems. CTR prediction models are typically trained on user click data from traffic logs. However, users are more likely to interact with items that were shown prominently on a website. CTR models often over-estimate the value of such items and show them more often, at the expense of items of higher quality that were previously shown at less prominent positions. This self-reinforcing position bias effect reduces both the immediate and long-term quality of recommendations for users. In this paper, we revisit position bias in a family of state-of-the-art neural models for CTR prediction, and use synthetic data to demonstrate the difficulty of controlling for position. We propose an approach that encourages neural networks to use position (or other confounding variables) as much as possible to explain the training data, and a metric that can directly measure bias. Experiments on two real-world datasets demonstrate the effectiveness of our approach in correcting for position-like features in 2 state-of-the-art CTR prediction models.|在在线广告和推荐系统中，预测商品的点进率是一项基本任务。CTR 预测模型通常根据流量日志中的用户点击数据进行训练。然而，用户更可能与网站上显著显示的项目进行交互。CTR 模型往往高估这些项目的价值，并更经常地显示它们，以牺牲以前显示在不太突出位置的高质量项目为代价。这种自我强化的位置偏差效应降低了对用户推荐的即时和长期质量。在本文中，我们回顾了位置偏差在一个国家的最先进的 CTR 预测神经模型的家庭，并使用合成数据来说明位置控制的困难。我们提出了一种方法，鼓励神经网络使用位置(或其他混杂变量)尽可能多地解释训练数据，并指标，可以直接测量偏倚。在两个真实世界的数据集上的实验证明了我们的方法在两个最先进的 CTR 预测模型中校正位置类特征的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Nudging+Neural+Click+Prediction+Models+to+Pay+Attention+to+Position)|0|
|[A Model-Agnostic Method to Interpret Link Prediction Evaluation of Knowledge Graph Embeddings](https://doi.org/10.1145/3583780.3614763)|Narayanan Asuri Krishnan, Carlos R. Rivero|Rochester Institute of Technology, Rochester, NY, USA|In link prediction evaluation, an embedding model assigns plausibility scores to unseen triples in a knowledge graph using an input partial triple. Performance metrics like mean rank are useful to compare models side by side, but do not shed light on their behavior. Interpreting link prediction evaluation and comparing models based on such interpretation are appealing. Current interpretation methods have mainly focused on single predictions or other tasks different from link prediction. Since knowledge graph embedding methods are diverse, interpretation methods that are applicable only to certain machine learning approaches cannot be used. In this paper, we propose a model-agnostic method for interpreting link prediction evaluation as a whole. The interpretation consists of Horn rules mined from the knowledge graph containing the triples a model deems plausible. We combine precision and recall measurements of mined rules using Fβ score to quantify interpretation accuracy. To maximize interpretation accuracy when comparing models, we study two approximations to the hard problem of merging rules. Our quantitative study shows that interpretation accuracy serves to compare diverse models side by side, and that these comparisons are different from those using ranks. Our qualitative study shows that several models globally capture expected semantics, and that models make a common set of predictions despite of redundancy reduction.|在链接预测评价中，嵌入模型使用输入部分三元组将合理性分值赋给知识图中的未知三元组。像平均排名这样的性能指标对于并排比较模型很有用，但是不能说明它们的行为。解释链接预测评价和基于这种解释的比较模型是很有吸引力的。目前的解释方法主要集中在单个预测或其他不同于链接预测的任务。由于知识图嵌入方法多种多样，不能采用仅适用于某些机器学习方法的解释方法。本文提出了一种从整体上解释链路预测评价的模型不可知方法。解释包括从知识图中挖掘的 Horn 规则，其中包含模型认为合理的三元组。我们结合了准确率召回率挖掘规则的测量结果，使用 Fβ 评分来量化解释的准确性。为了在比较模型时最大限度地提高解释的准确性，我们研究了合并规则这一难题的两个近似值。我们的定量研究表明，解释的准确性服务于比较不同的模型并排，这些比较是不同的使用等级。我们的定性研究表明，几个模型全局捕获预期的语义，模型作出了一个共同的预测集，尽管冗余减少。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Model-Agnostic+Method+to+Interpret+Link+Prediction+Evaluation+of+Knowledge+Graph+Embeddings)|0|
|[Towards Automatic ICD Coding via Knowledge Enhanced Multi-Task Learning](https://doi.org/10.1145/3583780.3615087)|Xinhang Li, Xiangyu Zhao, Yong Zhang, Chunxiao Xing|Tsinghua University, Beijing, China; City University of Hong Kong, Hong Kong, Hong Kong|The aim of ICD coding is to assign International Classification of Diseases (ICD) codes to unstructured clinical notes or discharge summaries. Numerous methods have been proposed for automatic ICD coding in an effort to reduce human labor and errors. However, existing works disregard the data imbalance problem of clinical notes. In addition, the noisy clinical note issue has not been thoroughly investigated. To address such issues, we propose a knowledge enhanced Graph Attention Network (GAT) under multi-task learning setting. Specifically, multi-level information transitions and interactions have been implemented. On the one hand, a large heterogeneous text graph is constructed to capture both intra- and inter-note correlations between various semantic concepts, thereby alleviating the data imbalance issue. On the other hand, two auxiliary healthcare tasks have been proposed to facilitate the sharing of information across tasks. Moreover, to tackle the issue of noisy clinical notes, we propose to utilize the rich structured knowledge facts and information provided by medical domain knowledge, thereby encouraging the model to focus on the clinical notes' noteworthy portion and valuable information. The experimental results on the widely-used medical dataset, MIMIC-III, demonstrate the advantages of our proposed framework.|ICD 编码的目的是为非结构化的临床记录或出院摘要分配国际疾病与相关健康问题统计分类(ICD)编码。为了减少人工劳动和错误，人们提出了许多 ICD 自动编码的方法。然而，现有的研究忽视了临床注释的数据不平衡问题。此外，噪音临床注意事项并没有被彻底调查。为了解决这些问题，我们提出了一种多任务学习环境下的知识增强型图注意网络(GAT)。具体来说，已经实现了多级信息转换和交互。一方面，构造了一个大型的异构文本图来捕捉各种语义概念之间的注释内和注释间的相关性，从而缓解数据不平衡问题。另一方面，我们提出了两项辅助保健工作，以促进各项工作之间的信息共享。此外，为了解决临床记录噪声的问题，我们建议利用医学领域知识所提供的丰富的结构化知识事实和信息，从而鼓励模型关注临床记录的值得注意的部分和有价值的信息。在广泛使用的医学数据集 MIMIC-III 上的实验结果证明了该框架的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Automatic+ICD+Coding+via+Knowledge+Enhanced+Multi-Task+Learning)|0|
|[Graph Enhanced Hierarchical Reinforcement Learning for Goal-oriented Learning Path Recommendation](https://doi.org/10.1145/3583780.3614897)|Qingyao Li, Wei Xia, Li'ang Yin, Jian Shen, Renting Rui, Weinan Zhang, Xianyu Chen, Ruiming Tang, Yong Yu|Shanghai Jiaotong University, Shanghai, China; Shanghai Jiao Tong University, Shanghai, China; Huawei Noah's Art Lab, Shenzhen, China; Huawei Noah's Ark Lab, Shenzhen, China|Goal-oriented Learning path recommendation aims to recommend learning items (concepts or exercises) step-by-step to a learner to promote the mastery level of her specific learning goals. By formulating this task as a Markov decision process, reinforcement learning (RL) methods have demonstrated great power. Although extensive research efforts have been made, previous methods still fail to recommend effective goal-oriented paths due to the under-utilizing of goals. Specifically, it is mainly reflected in two aspects: (1)The lack of goal planning. When learners have multiple goals with different difficulties, the previous methods can't fully utilize the difficulties and dependencies between goal learning items to plan the sequence of achieving these goals, making the path chaotic and inefficient; (2)The lack of efficiency in goal achieving. When pursuing a single goal, the path may contain learning items unrelated to the goal, which makes realizing a certain goal inefficient. To address these challenges, we present a novel Graph Enhanced Hierarchical Reinforcement Learning (GEHRL) framework for goal-oriented learning path recommendation. The framework divides learning path recommendation into two parts: sub-goal selection(planning) and sub-goal achieving(learning item recommendation). Specifically, we employ a high-level agent as a sub-goal selector to select sub-goals for the low-level agent to achieve. The low-level agent in the framework is to recommend learning items to the learner. To make the path only contain goal-related learning items to improve the efficiency of achieving the goal, we develop a graph-based candidate selector to constrain the action space of the low-level agent based on the sub-goal and knowledge graph. We also develop test-based internal reward for low-level training so that the sparsity problem of external reward can be alleviated. Extensive experiments on three different simulators demonstrate our framework achieves state-of-the-art performance.|目标导向学习路径推荐旨在向学习者逐步推荐学习项目(概念或练习) ，以提高其对特定学习目标的掌握程度。通过把这个任务作为一个马可夫决策过程，强化学习(RL)方法已经证明了它的巨大威力。尽管已经做了大量的研究工作，以往的方法仍然不能推荐有效的目标导向的路径，由于目标利用不足。具体来说，主要体现在两个方面: (1)目标规划的缺失。当学习者有不同困难的多个目标时，以往的方法不能充分利用目标学习项目之间的困难和依赖关系来规划实现这些目标的顺序，使得路径混乱和效率低下; (2)目标实现效率低下。在追求单一目标时，路径中可能包含与目标无关的学习项，使得实现某一目标效率低下。为了应对这些挑战，我们提出了一个新的图形增强层次强化学习(GEHRL)框架，用于面向目标的学习路径推荐。该框架将学习路径推荐分为子目标选择(规划)和子目标实现(学习项目推荐)两部分。具体来说，我们使用高级代理作为子目标选择器，为低级代理选择要实现的子目标。框架中的底层代理是向学习者推荐学习项目。为了使路径只包含与目标相关的学习项，提高实现目标的效率，提出了一种基于子目标和知识图的候选选择器来约束底层智能体的行为空间。我们还针对低水平培训开发了基于测试的内部奖励，以缓解外部奖励稀缺的问题。在三个不同的模拟器上进行的大量实验表明，我们的框架实现了最先进的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Enhanced+Hierarchical+Reinforcement+Learning+for+Goal-oriented+Learning+Path+Recommendation)|0|
|[THGNN: An Embedding-based Model for Anomaly Detection in Dynamic Heterogeneous Social Networks](https://doi.org/10.1145/3583780.3615079)|Yilin Li, Jiaqi Zhu, Congcong Zhang, Yi Yang, Jiawen Zhang, Ying Qiao, Hongan Wang|The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; Institute of Software, Chinese Academy of Sciences & University of Chinese Academy of Sciences, Beijing, China; Institute of Software, Chinese Academy of Sciences, Beijing, China|Anomaly detection, particularly the detection of anomalous behaviors in dynamic and heterogeneous social networks, is becoming more and more crucial in real life. Traditional rule-based and feature-based methods cannot well capture the structural and temporal patterns of ever-changing user behaviors. Moreover, most of the existing works based on network embedding either rely on discretized snapshots, which have ignored accurate temporal relations among user behaviors and weakened the impact of new edges, or fail to utilize dynamic and heterogeneous information simultaneously to distinguish varying effects of new edges on existing nodes. In this paper, we propose an end-to-end continuous-time model, named Temporal Heterogeneous Graph Neural Network (THGNN), to detect anomalous behaviors (edges) in dynamic heterogeneous social networks. Specifically, the model constantly updates node embeddings by propagating the information of a new edge to its source and target nodes as well as their neighbors. In this process, heterogeneous encoders are employed to handle different types of nodes and edges. What is more, a novel dual-level distributive attention mechanism is designed to allocate the influence degree of a currently interacting node to its multiple neighbors, considering the combined effect of edge type and time interval information. That can be regarded as an extension of the classical aggregative attention mechanism in the opposite direction. Extensive experiments on four real-world datasets demonstrate that THGNN outperforms all the baselines on the task of anomalous edge detection, achieving an average AUC gain of 6% across all datasets.|异常检测，特别是在动态和异构的社交网络中发现异常行为，在现实生活中变得越来越重要。传统的基于规则和基于特征的方法不能很好地捕获不断变化的用户行为的结构和时间模式。此外，现有的基于网络嵌入的工作大多依赖于离散快照，忽略了用户行为之间精确的时间关系，削弱了新边的影响，或者未能同时利用动态和异构信息来区分新边对现有节点的不同影响。本文提出了一种端到端连续时间模型——时态异构图神经网络(THGNN) ，用于检测动态异构社会网络中的异常行为(边)。具体来说，该模型通过将新边的信息传播到源节点和目标节点以及它们的邻居，不断地更新节点嵌入。在这个过程中，异构编码器被用来处理不同类型的节点和边缘。同时，考虑到边缘类型和时间间隔信息的组合效应，设计了一种新的双层分布式注意机制来分配当前交互节点对其多个邻居的影响程度。这可以看作是对经典的聚集性注意机制在相反方向上的延伸。在四个实际数据集上的大量实验表明，THGNN 在异常边缘检测任务上优于所有基线，在所有数据集上平均获得6% 的 AUC 增益。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=THGNN:+An+Embedding-based+Model+for+Anomaly+Detection+in+Dynamic+Heterogeneous+Social+Networks)|0|
|[MadSGM: Multivariate Anomaly Detection with Score-based Generative Models](https://doi.org/10.1145/3583780.3614956)|Haksoo Lim, Sewon Park, Minjung Kim, Jaehoon Lee, Seonkyu Lim, Noseong Park|Yonsei University, Seoul, Republic of Korea; LG AI Research, Seoul, Republic of Korea; Samsung SDS, Seoul, Republic of Korea|The time-series anomaly detection is one of the most fundamental tasks for time-series. Unlike the time-series forecasting and classification, the time-series anomaly detection typically requires unsupervised (or self-supervised) training since collecting and labeling anomalous observations are difficult. In addition, most existing methods resort to limited forms of anomaly measurements and therefore, it is not clear whether they are optimal in all circumstances. To this end, we present a multivariate time-series anomaly detector based on score-based generative models, called MadSGM, which considers the broadest ever set of anomaly measurement factors: i) reconstruction-based, ii) density-based, and iii) gradient-based anomaly measurements. We also design a conditional score network and its denoising score matching loss for the time-series anomaly detection. Experiments on five real-world benchmark datasets illustrate that MadSGM achieves the most robust and accurate predictions.|时间序列异常检测是时间序列最基本的任务之一。与时间序列预测和分类不同，时间序列异常检测通常需要无监督(或自我监督)的训练，因为收集和标记异常观测是困难的。此外，大多数现有方法采用有限形式的异常测量，因此，不清楚它们是否在所有情况下都是最佳的。为此，我们提出了一个基于基于评分的生成模型的多变量时间序列异常检测器，称为 MadSGM，其考虑了有史以来最广泛的一组异常测量因素: i)基于重建的，ii)基于密度的，和 iii)基于梯度的异常测量。我们还设计了一个条件得分网络及其去噪得分匹配丢失的时间序列异常检测。对五个真实世界基准数据集的实验表明，MadSGM 能够实现最稳健和准确的预测。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MadSGM:+Multivariate+Anomaly+Detection+with+Score-based+Generative+Models)|0|
|[Hierarchical Prompt Tuning for Few-Shot Multi-Task Learning](https://doi.org/10.1145/3583780.3614913)|Jingping Liu, Tao Chen, Zujie Liang, Haiyun Jiang, Yanghua Xiao, Feng Wei, Yuxi Qian, Zhenghong Hao, Bing Han|Ant Group, Shanghai, China; East China University of Science and Technology, Shanghai, China; Fudan University, Shanghai, China|Prompt tuning has enhanced the performance of Pre-trained Language Models for multi-task learning in few-shot scenarios. However, existing studies fail to consider that the prompts among different layers in Transformer are different due to the diverse information learned at each layer. In general, the bottom layers in the model tend to capture low-level semantic or structural information, while the upper layers primarily acquire task-specific knowledge. Hence, we propose a novel hierarchical prompt tuning model for few-shot multi-task learning to capture this regularity. The designed model mainly consists of three types of prompts: shared prompts, auto-adaptive prompts, and task-specific prompts. Shared prompts facilitate the sharing of general information across all tasks. Auto-adaptive prompts dynamically select and integrate relevant prompt information from all tasks into the current task. Task-specific prompts concentrate on learning task-specific knowledge. To enhance the model's adaptability to diverse inputs, we introduce deep instance-aware language prompts as the foundation for constructing the above prompts. To evaluate the effectiveness of our proposed method, we conduct extensive experiments on multiple widely-used datasets. The experimental results demonstrate that the proposed method achieves state-of-the-art performance for multi-task learning in few-shot settings and outperforms ChatGPT in the full-data setting.|及时调优提高了预训练语言模型在少镜头情景下多任务学习的性能。然而，现有的研究没有考虑到变压器不同层之间的提示是不同的，因为在每一层学习的不同信息。一般来说，模型的底层倾向于捕获低层次的语义或结构信息，而上层主要获取特定于任务的知识。因此，我们提出了一个新的分层提示调整模型来捕捉这种规律性的少拍多任务学习。所设计的模型主要包括三种类型的提示: 共享提示、自适应提示和任务特定提示。共享提示有助于在所有任务之间共享一般信息。自适应提示动态选择并将所有任务中的相关提示信息集成到当前任务中。特定于任务的提示集中于学习特定于任务的知识。为了增强模型对不同输入的适应性，我们引入了深度实例感知语言提示作为构造上述提示的基础。为了评估我们提出的方法的有效性，我们在多个广泛使用的数据集上进行了广泛的实验。实验结果表明，该方法在少镜头情况下获得了最佳的多任务学习性能，在全数据情况下优于 ChatGPT。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Prompt+Tuning+for+Few-Shot+Multi-Task+Learning)|0|
|[SMEF: Social-aware Multi-dimensional Edge Features-based Graph Representation Learning for Recommendation](https://doi.org/10.1145/3583780.3615063)|Xiao Liu, Shunmei Meng, Qianmu Li, Lianyong Qi, Xiaolong Xu, Wanchun Dou, Xuyun Zhang|Digital Economy Research Institute, Nanjing University of Science & Technology, Nanjing, China; College of Computer Science and Technology, China University of Petroleum (East China), Qingdao, China; Nanjing University of Information Science & Technology, Nanjing, China; Macquarie University, Sydney, Australia; Nanjing University, Nanjing, China; Department of Cyber Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; Department of Computer Science and Engineering, Nanjing University of Science and Technology & State Key Lab. for Novel Software Technology, Nanjing University, Nanjing, China|Exploring user-item interaction cues is crucial for the performance of recommender systems. Explicit investigation of interaction cues is made possible by using graph-based models, where each user-item relationship is described by an edge, and the introduction of user-user social network. While existing graph-based recommendation methods use only a single-value edge to define the relationship between a pair of user and item, which limits the ability to represent complex user-item interactions. Furthermore, some social recommendation methods overlook the heterogeneous user behavior patterns in social and interaction relationships, resulting in the suboptimal performance of existing systems. In this paper, we propose a novel Social-aware Multi-dimensional Edge Feature-based Graph Representation Learning method, called SMEF. It represents all users and items as a graph and deep learns a multi-dimensional edge feature to explicitly describe the task-specific relationships of each user-item pair. Specifically, the proposed SMEF focuses on two distinct user behavior patterns toward social friends and interactive items, which explore the underlying heterogeneous relationship cues within them. This way, the learned multi-dimensional edge features encode user information from both social and interaction aspects. The proposed SMEF is a plug-and-play module that can be combined with different recommendation frameworks and Graph Neural Networks (GNNs) backbones to generate high quality user representations. The experimental results achieved on three publicly accessible datasets show that our SMEF-based method outperforms strong baselines.|探索用户项交互线索对于推荐系统的性能至关重要。通过使用基于图的模型(其中每个用户-项目关系由一个边描述)和引入用户-用户社交网络，可以对交互线索进行明确的调查。而现有的基于图的推荐方法只使用单值边界来定义一对用户和项目之间的关系，这限制了表示复杂用户-项目交互的能力。此外，一些社交推荐方法忽视了社交和交互关系中的异构用户行为模式，导致现有系统的性能不理想。本文提出了一种新的基于社会感知的多维边缘特征的图形表示学习方法，称为 SMF。它将所有用户和项目表示为一个图形，并深入学习一个多维边缘特性，以显式地描述每个用户-项目对的特定于任务的关系。具体而言，本研究针对两种不同的使用者行为模式，分别针对社交朋友与互动项目，探讨其中潜在的异质性关系线索。这样，学习的多维边缘特征从社会和交互两个方面对用户信息进行编码。该模块可以与不同的推荐框架和图形神经网络(GNN)骨干结合，生成高质量的用户表示。在三个公开可访问数据集上的实验结果表明，我们提出的基于 MESF 的方法性能优于强基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SMEF:+Social-aware+Multi-dimensional+Edge+Features-based+Graph+Representation+Learning+for+Recommendation)|0|
|[Self-Supervised Dynamic Hypergraph Recommendation based on Hyper-Relational Knowledge Graph](https://doi.org/10.1145/3583780.3615054)|Yi Liu, Hongrui Xuan, Bohan Li, Meng Wang, Tong Chen, Hongzhi Yin|Nanjing University of Aeronautics and Astronautics, Nanjing, China; Tongji University, Shanghai, China; The University of Queensland, Brisbane, Australia|Knowledge graphs (KGs) are commonly used as side information to enhance collaborative signals and improve recommendation quality. In the context of knowledge-aware recommendation (KGR), graph neural networks (GNNs) have emerged as promising solutions for modeling factual and semantic information in KGs. However, the long-tail distribution of entities leads to sparsity in supervision signals, which weakens the quality of item representation when utilizing KG enhancement. Additionally, the binary relation representation of KGs simplifies hyper-relational facts, making it challenging to model complex real-world information. Furthermore, the over-smoothing phenomenon results in indistinguishable representations and information loss. To address these challenges, we propose the SDK (Self-Supervised Dynamic Hypergraph Recommendation based on Hyper-Relational Knowledge Graph) framework. This framework establishes a cross-view hypergraph self-supervised learning mechanism for KG enhancement. Specifically, we model hyper-relational facts in KGs to capture interdependencies between entities under complete semantic conditions. With the refined representation, a hypergraph is dynamically constructed to preserve features in the deep vector space, thereby alleviating the over-smoothing problem. Furthermore, we mine external supervision signals from both the global perspective of the hypergraph and the local perspective of collaborative filtering (CF) to guide the model prediction process. Extensive experiments conducted on different datasets demonstrate the superiority of the SDK framework over state-of-the-art models. The results showcase its ability to alleviate the effects of over-smoothing and supervision signal sparsity.|知识图作为辅助信息被广泛应用于增强协作信号和提高推荐质量。在知识感知推荐(KGR)的背景下，图形神经网络(GNN)已经成为幼儿园建立事实和语义信息模型的有希望的解决方案。然而，实体的长尾分布导致监督信号的稀疏性，使得 KG 增强的项目表示质量下降。此外，KGs 的二进制关系表示简化了超关系事实，使得对复杂的现实世界信息进行建模具有挑战性。此外，过度平滑现象导致不可区分的表示和信息损失。针对这些挑战，本文提出了基于超关系知识图的自监督动态超图推荐(SDK)框架。该框架建立了一种用于 KG 增强的跨视图超图自监督学习机制。具体来说，我们在 KG 中对超关系事实建模，以在完全语义条件下捕获实体之间的相互依赖性。该方法通过动态构造超图来保留深向量空间中的特征，从而解决了超图的过平滑问题。此外，我们从超图的全局视角和协同过滤的局部视角来挖掘外部监督信号，以指导模型的预测过程。在不同数据集上进行的大量实验表明，SDK 框架优于最先进的模型。实验结果表明，该算法能够有效地缓解过平滑和监控信号稀疏的影响。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-Supervised+Dynamic+Hypergraph+Recommendation+based+on+Hyper-Relational+Knowledge+Graph)|0|
|[Black-box Adversarial Attacks against Dense Retrieval Models: A Multi-view Contrastive Learning Method](https://doi.org/10.1145/3583780.3614793)|YuAn Liu, Ruqing Zhang, Jiafeng Guo, Maarten de Rijke, Wei Chen, Yixing Fan, Xueqi Cheng|ICT, CAS & University of Chinese Academy of Sciences, Beijing, China; University of Amsterdam, Amsterdam, Netherlands|Neural ranking models (NRMs) and dense retrieval (DR) models have given rise to substantial improvements in overall retrieval performance. In addition to their effectiveness, and motivated by the proven lack of robustness of deep learning-based approaches in other areas, there is growing interest in the robustness of deep learning-based approaches to the core retrieval problem. Adversarial attack methods that have so far been developed mainly focus on attacking NRMs, with very little attention being paid to the robustness of DR models. In this paper, we introduce the adversarial retrieval attack (AREA) task. The AREA task is meant to trick DR models into retrieving a target document that is outside the initial set of candidate documents retrieved by the DR model in response to a query. We consider the decision-based black-box adversarial setting, which is realistic in real-world search engines. To address the AREA task, we first employ existing adversarial attack methods designed for NRMs. We find that the promising results that have previously been reported on attacking NRMs, do not generalize to DR models: these methods underperform a simple term spamming method. We attribute the observed lack of generalizability to the interaction-focused architecture of NRMs, which emphasizes fine-grained relevance matching. DR models follow a different representation-focused architecture that prioritizes coarse-grained representations. We propose to formalize attacks on DR models as a contrastive learning problem in a multi-view representation space. The core idea is to encourage the consistency between each view representation of the target document and its corresponding viewer via view-wise supervision signals. Experimental results demonstrate that the proposed method can significantly outperform existing attack strategies in misleading the DR model with small indiscernible text perturbations.|神经排序模型(NRM)和密集检索(DR)模型在总体检索性能方面有了很大的提高。除了这些方法的有效性外，由于在其他领域基于深度学习的方法缺乏稳健性，人们对基于深度学习的方法解决核心检索问题的稳健性越来越感兴趣。目前发展起来的对抗性攻击方法主要集中在攻击 NRM，很少关注 DR 模型的鲁棒性。本文介绍了对抗性检索攻击(AREA)任务。AREA 任务是为了欺骗 DR 模型来检索目标文档，该目标文档位于 DR 模型在响应查询时检索的候选文档的初始集之外。我们考虑基于决策的黑盒对抗设置，这在现实世界的搜索引擎中是现实的。为了解决 AREA 任务，我们首先使用为 NRM 设计的现有对手攻击方法。我们发现，以前报道的攻击 NRM 的有希望的结果并没有推广到 DR 模型: 这些方法不如一个简单的术语发送方法。我们将观察到的缺乏普遍性归因于以交互为中心的 NRM 体系结构，它强调细粒度的相关性匹配。DR 模型遵循不同的以表示为中心的体系结构，该体系结构对粗粒度表示进行优先级排序。我们提出将对 DR 模型的攻击形式化为一个多视图表示空间中的对比学习问题。其核心思想是通过视图监控信号鼓励目标文档的每个视图表示与其相应的查看器之间的一致性。实验结果表明，该方法能够明显优于现有的攻击策略，具有较小的不可分辨文本扰动误导 DR 模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Black-box+Adversarial+Attacks+against+Dense+Retrieval+Models:+A+Multi-view+Contrastive+Learning+Method)|0|
|[Selecting Walk Schemes for Database Embedding](https://doi.org/10.1145/3583780.3615052)|Yuval Lev Lubarsky, Jan Tönshoff, Martin Grohe, Benny Kimelfeld|Technion, Haifa, Israel; RWTH Aachen University, Aachen, Germany|Machinery for data analysis often requires a numeric representation of the input. Towards that, a common practice is to embed components of structured data into a high-dimensional vector space. We study the embedding of the tuples of a relational database, where existing techniques are often based on optimization tasks over a collection of random walks from the database. The focus of this paper is on the recent FoRWaRD algorithm that is designed for dynamic databases, where walks are sampled by following foreign keys between tuples. Importantly, different walks have different schemas, or ?walk schemes," that are derived by listing the relations and attributes along the walk. Also importantly, different walk schemes describe relationships of different natures in the database. We show that by focusing on a few informative walk schemes, we can obtain tuple embedding significantly faster, while retaining the quality. We define the problem of scheme selection for tuple embedding, devise several approaches and strategies for scheme selection, and conduct a thorough empirical study of the performance over a collection of downstream tasks. Our results confirm that with effective strategies for scheme selection, we can obtain high-quality embeddings considerably (e.g., three times) faster, preserve the extensibility to newly inserted tuples, and even achieve an increase in the precision of some tasks.|用于数据分析的机器通常需要输入的数字表示。为此，一个常见的做法是将结构化数据的组件嵌入到高维向量空间中。我们研究了关系数据库元组的嵌入，其中现有的技术通常是基于优化任务，从数据库中随机游走的集合。本文的重点是针对动态数据库设计的最新的 ForRWaRD 算法，该算法通过在元组之间跟随外键来采样行走。重要的是，不同的散步有不同的模式，还是？这是通过列出步行过程中的关系和属性得出的。同样重要的是，不同的遍历方案描述数据库中不同性质的关系。实验结果表明，在保证质量的前提下，通过对几种信息量较大的步进方案进行分析，可以显著提高元组嵌入的速度。我们定义了元组嵌入的方案选择问题，设计了几种方案选择的方法和策略，并对下游任务集的性能进行了深入的实证研究。实验结果表明，采用有效的方案选择策略，可以更快地获得高质量的嵌入，保持新插入元组的可扩展性，甚至可以提高某些任务的精度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Selecting+Walk+Schemes+for+Database+Embedding)|0|
|[Timestamps as Prompts for Geography-Aware Location Recommendation](https://doi.org/10.1145/3583780.3615083)|Yan Luo, Haoyi Duan, Ye Liu, FuLai Chung|Zhejiang University, Hangzhou, China; The Hong Kong Polytechnic University, Hong Kong, Hong Kong|Location recommendation plays a vital role in improving users' travel experience. The timestamp of the POI to be predicted is of great significance, since a user will go to different places at different times. However, most existing methods either do not use this kind of temporal information, or just implicitly fuse it with other contextual information. In this paper, we revisit the problem of location recommendation and point out that explicitly modeling temporal information is a great help when the model needs to predict not only the next location but also further locations. In addition, state-of-the-art methods do not make effective use of geographic information and suffer from the hard boundary problem when encoding geographic information by gridding. To this end, a Temporal Prompt-based and Geography-aware (TPG) framework is proposed. The temporal prompt is firstly designed to incorporate temporal information of any further check-in. A shifted window mechanism is then devised to augment geographic data for addressing the hard boundary problem. Via extensive comparisons with existing methods and ablation studies on five real-world datasets, we demonstrate the effectiveness and superiority of the proposed method under various settings. Most importantly, our proposed model has the superior ability of interval prediction. In particular, the model can predict the location that a user wants to go to at a certain time while the most recent check-in behavioral data is masked, or it can predict specific future check-in (not just the next one) at a given timestamp.|位置推荐在改善用户的旅游体验方面起着至关重要的作用。预测的 POI 的时间戳非常重要，因为用户将在不同的时间到达不同的地点。然而，大多数现有的方法要么不使用这种时间信息，要么只是隐式地将其与其他上下文信息融合在一起。在本文中，我们再次回顾了位置推荐的问题，并指出当模型不仅需要预测下一个位置，而且需要预测更远的位置时，显式地建立时间信息是一个很大的帮助。另外，现有的方法在对地理信息进行网格化编码时，不能有效地利用地理信息，存在硬边界问题。为此，提出了一个基于时态提示和地理感知(TPG)的框架。时间提示符首先设计为合并任何进一步签入的时间信息。然后设计了一种移动窗口机制来增加地理数据，以解决硬边界问题。通过与现有方法的广泛比较以及对五个实际数据集的烧蚀研究，我们证明了该方法在不同环境下的有效性和优越性。最重要的是，我们提出的模型具有优越的区间预测能力。特别是，当最近的签入行为数据被掩盖时，该模型可以预测用户在特定时间想要去的位置，或者它可以预测给定时间戳的特定未来签入(不仅仅是下一次)。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Timestamps+as+Prompts+for+Geography-Aware+Location+Recommendation)|0|
|[LambdaRank Gradients are Incoherent](https://doi.org/10.1145/3583780.3614948)|Federico Marcuzzi, Claudio Lucchese, Salvatore Orlando|Università Ca' Foscari Venezia, Venice, Italy|In Information Retrieval (IR), the Learning-to-Rank (LTR) task requires building a ranking model that optimises a specific IR metric. One of the most effective approaches to do so is the well-known LambdaRank algorithm. LambdaRank uses gradient descent optimisation, and at its core, it defines approximate gradients, the so-called lambdas, for a non-differentiable IR metric. Intuitively, each lambda describes how much a document's score should be "pushed" up/down to reduce the ranking error. In this work, we show that lambdas may be incoherent w.r.t. the metric being optimised: e.g., a document with high relevance in the ground truth may receive a smaller gradient push than a document with lower relevance. This behaviour goes far beyond the expected degree of approximation. We analyse such behaviour of LambdaRank gradients and we introduce some strategies to reduce their incoherencies. We demonstrate through extensive experiments, conducted using publicly available datasets, that the proposed approach reduces the frequency of the incoherencies in LambdaRank and derivatives, and leads to models that achieve statistically significant improvements in the NDCG metric, without compromising the training efficiency.|在信息检索中，学习排名(Learning-to-Rank，LTR)任务需要建立一个排名模型来优化一个特定的 IR 指标。最有效的方法之一是著名的 LambdaRank 算法。LambdaRank 使用梯度下降法优化，在其核心，它定义了近似梯度，即所谓的 lambdas，用于不可微 IR 度量。直观地说，每个 lambda 描述了一个文档的分数应该“上推”多少，以减少排名错误。在这项工作中，我们表明，lambdas 可能是不连贯的 W.R.T。的度量被优化: 例如，一个文件与地面真相高相关性可能会收到一个较小的梯度推动比一个文件与低相关性。这种行为远远超出了预期的近似程度。我们分析了这种行为的 LambdaRank 梯度和我们介绍了一些策略，以减少他们的不一致性。我们通过使用公开可用的数据集进行的广泛实验证明，所提出的方法降低了 LambdaRank 和衍生物中不相干的频率，并导致模型在 NDCG 指标中实现统计学显着的改善，而不损害训练效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LambdaRank+Gradients+are+Incoherent)|0|
|[System Initiative Prediction for Multi-turn Conversational Information Seeking](https://doi.org/10.1145/3583780.3615070)|Chuan Meng, Mohammad Aliannejadi, Maarten de Rijke|University of Amsterdam, Amsterdam, Netherlands|Identifying the right moment for a system to take the initiative is essential to conversational information seeking (CIS). Existing studies have extensively studied the clarification need prediction task, i.e., predicting when to ask a clarifying question, however, it only covers one specific system-initiative action. We define the system initiative prediction (SIP) task as predicting whether a CIS system should take the initiative at the next turn. Our analysis reveals that for effective modeling of SIP, it is crucial to capture dependencies between adjacent user?system initiative-taking decisions. We propose to model SIP by CRFs. Due to their graphical nature, CRFs are effective in capturing such dependencies and have greater transparency than more complex methods, e.g., LLMs. Applying CRFs to SIP comes with two challenges: (i) CRFs need to be given the unobservable system utterance at the next turn, and (ii) they do not explicitly model multi-turn features. We model SIP as an input-incomplete sequence labeling problem and propose a multi-turn system initiative predictor (MuSIc) that has (i) prior-posterior inter-utterance encoders to eliminate the need to be given the unobservable system utterance, and (ii) a multi-turn feature-aware CRF layer to incorporate multi-turn features into the dependencies between adjacent initiative-taking decisions. Experiments show that MuSIc outperforms LLM-based baselines including LLaMA, achieving state-of-the-art results on SIP. We also show the benefits of SIP on clarification need prediction and action prediction.|确定系统采取主动的合适时机对于会话信息搜索(CIS)至关重要。现有的研究已经广泛地研究了澄清需求预测任务，即预测何时提出澄清问题，但它只涉及一个具体的系统-主动行为。我们将系统主动预测(SIP)任务定义为预测一个 CIS 系统是否应该在下一轮采取主动。我们的分析表明，对于 SIP 的有效建模，捕获相邻用户系统主动决策之间的依赖性是至关重要的。我们提出用 CRF 来建立 SIP 模型。由于它们的图形化特性，通用报告格式能够有效地捕获这种依赖关系，并且比更复杂的方法(例如 LLM)具有更大的透明度。将 CRF 应用于 SIP 有两个挑战: (i) CRF 需要在下一个回合中被赋予不可观察的系统语句，以及(ii)它们没有明确地建模多回合特征。我们将 SIP 建模为一个输入不完全序列标记问题，并提出了一个多回合系统主动预测器(MuSic) ，它具有(i)先验-后验语音编码器以消除给定不可观测系统语音的需要，以及(ii)一个多回合特征感知 CRF 层以将多回合特征纳入相邻主动决策之间的依赖关系。实验结果表明，MuSIC 的性能优于基于 LLM 的基线(包括 LLaMA) ，在 SIP 上取得了一流的效果。我们还展示了 SIP 在澄清需求预测和作用预测方面的优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=System+Initiative+Prediction+for+Multi-turn+Conversational+Information+Seeking)|0|
|[Hybrid Contrastive Constraints for Multi-Scenario Ad Ranking](https://doi.org/10.1145/3583780.3614920)|Shanlei Mu, Penghui Wei, Wayne Xin Zhao, Shaoguo Liu, Liang Wang, Bo Zheng|Gaoling School of Artificial Intelligence, Renmin University of China & Beijing Key Laboratory of Big Data Management and Analysis Methods, Beijing, China; Alibaba Group, Beijing, China|Multi-scenario ad ranking aims at leveraging the data from multiple domains or channels for training a unified ranking model to improve the performance at each individual scenario. Although the research on this task has made important progress, it still lacks the consideration of cross-scenario relations, thus leading to limitation in learning capability and difficulty in interrelation modeling. In this paper, we propose a Hybrid Contrastive Constrained approach (HC^2) for multi-scenario ad ranking. To enhance the modeling of data interrelation, we elaborately design a hybrid contrastive learning approach to capture commonalities and differences among multiple scenarios. The core of our approach consists of two elaborated contrastive losses, namely generalized and individual contrastive loss, which aim at capturing common knowledge and scenario-specific knowledge, respectively. To adapt contrastive learning to the complex multi-scenario setting, we propose a series of important improvements. For generalized contrastive loss, we enhance contrastive learning by extending the contrastive samples (label-aware and diffusion noise enhanced contrastive samples) and reweighting the contrastive samples (reciprocal similarity weighting). For individual contrastive loss, we use the strategies of dropout-based augmentation and {cross-scenario encoding} for generating meaningful positive and negative contrastive samples, respectively. Extensive experiments on both offline evaluation and online test have demonstrated the effectiveness of the proposed HC$^2$ by comparing it with a number of competitive baselines.|多场景广告排名的目的是利用来自多个领域或渠道的数据来训练一个统一的排名模型，以提高每个场景的性能。本课题的研究虽然取得了重要进展，但仍然缺乏对跨场景关系的考虑，从而导致学习能力的局限性和相互关系建模的困难。本文提出了一种基于混合对比约束的多场景广告排名方法(HC ^ 2)。为了加强数据相关性的建模，我们精心设计了一种混合对比学习方法来捕捉多个场景之间的共性和差异。我们的方法的核心包括两个详细的对比损失，即广义对比损失和个体对比损失，分别旨在获取共同知识和情景特定的知识。为了使对比学习适应复杂的多场景环境，我们提出了一系列重要的改进措施。对于广义对比损失，我们通过扩展对比样本(标签感知和扩散噪声增强的对比样本)和重新加权对比样本(互惠相似性加权)来增强对比学习。对于个体对比损失，我们分别使用基于辍学的增强策略和{交叉情景编码}来产生有意义的正向和负向对比样本。离线评估和在线测试的广泛实验已经证明了所提出的 HC $^ 2 $的有效性，通过比较它与一些竞争性的基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hybrid+Contrastive+Constraints+for+Multi-Scenario+Ad+Ranking)|0|
|[Contrastive Learning of Temporal Distinctiveness for Survival Analysis in Electronic Health Records](https://doi.org/10.1145/3583780.3614824)|Mohsen Nayebi Kerdabadi, Arya Hadizadeh Moghaddam, Bin Liu, Mei Liu, Zijun Yao|University of Kansas, Lawrence, KS, USA; University of Florida, Gainesville, FL, USA; West Virginia University, Morgantown, WV, USA|Survival analysis plays a crucial role in many healthcare decisions, where the risk prediction for the events of interest can support an informative outlook for a patient's medical journey. Given the existence of data censoring, an effective way of survival analysis is to enforce the pairwise temporal concordance between censored and observed data, aiming to utilize the time interval before censoring as partially observed time-to-event labels for supervised learning. Although existing studies mostly employed ranking methods to pursue an ordering objective, contrastive methods which learn a discriminative embedding by having data contrast against each other, have not been explored thoroughly for survival analysis. Therefore, in this paper, we propose a novel Ontology-aware Temporality-based Contrastive Survival (OTCSurv) analysis framework that utilizes survival durations from both censored and observed data to define temporal distinctiveness and construct negative sample pairs with adjustable hardness for contrastive learning. Specifically, we first use an ontological encoder and a sequential self-attention encoder to represent the longitudinal EHR data with rich contexts. Second, we design a temporal contrastive loss to capture varying survival durations in a supervised setting through a hardness-aware negative sampling mechanism. Last, we incorporate the contrastive task into the time-to-event predictive task with multiple loss components. We conduct extensive experiments using a large EHR dataset to forecast the risk of hospitalized patients who are in danger of developing acute kidney injury (AKI), a critical and urgent medical condition. The effectiveness and explainability of the proposed model are validated through comprehensive quantitative and qualitative studies.|生存分析在许多医疗决策中起着至关重要的作用，其中对感兴趣的事件的风险预测可以支持对患者医疗旅程的信息性展望。鉴于数据审查的存在，一个有效的生存分析方法是加强审查数据和观察数据之间的成对时间一致性，目的是利用审查前的时间间隔作为部分观察到的监督式学习时间-事件标签。虽然现有的研究大多采用排序方法来追求排序目标，但对比分析方法通过数据对比来学习判别嵌入，尚未深入探讨用于生存分析的方法。因此，本文提出了一种新的基于本体感知时间性的对比生存(OTCSurv)分析框架，该框架利用截尾数据和观测数据的生存时间来定义时间差异性，并构造具有可调硬度的负样本对用于对比学习。具体来说，我们首先使用一个本体编码器和一个顺序自我注意编码器来表示具有丰富上下文的纵向 EHR 数据。其次，我们设计了一个时间对比损失，通过硬度感知的负采样机制，在监督环境下捕获不同的生存期。最后，我们将对比任务融入到具有多个损失分量的时间-事件预测任务中。我们使用一个大型的 EHR 数据集进行了广泛的实验，以预测有发展为急性肾损伤(AKI)危险的住院患者的风险，急性肾损伤是一种危险和紧急的医疗状况。通过全面的定量和定性研究，验证了该模型的有效性和可解释性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Learning+of+Temporal+Distinctiveness+for+Survival+Analysis+in+Electronic+Health+Records)|0|
|[MUSE: Music Recommender System with Shuffle Play Recommendation Enhancement](https://doi.org/10.1145/3583780.3614976)|Yunhak Oh, Sukwon Yun, Dongmin Hyun, Sein Kim, Chanyoung Park|POSTECH, Pohang, Republic of Korea; KAIST, Daejeon, Republic of Korea|Recommender systems have become indispensable in music streaming services, enhancing user experiences by personalizing playlists and facilitating the serendipitous discovery of new music. However, the existing recommender systems overlook the unique challenges inherent in the music domain, specifically shuffle play, which provides subsequent tracks in a random sequence. Based on our observation that the shuffle play sessions hinder the overall training process of music recommender systems mainly due to the high unique transition rates of shuffle play sessions, we propose a Music Recommender System with Shuffle Play Recommendation Enhancement (MUSE). MUSE employs the self-supervised learning framework that maximizes the agreement between the original session and the augmented session, which is augmented by our novel session augmentation method, called transition-based augmentation. To further facilitate the alignment of the representations between the two views, we devise two fine-grained matching strategies, i.e., item- and similarity-based matching strategies. Through rigorous experiments conducted across diverse environments, we demonstrate MUSE's efficacy over 12 baseline models on a large-scale Music Streaming Sessions Dataset (MSSD) from Spotify. The source code of MUSE is available at \url{https://github.com/yunhak0/MUSE}.|在音乐流媒体服务中，推荐系统已经变得不可或缺，它通过个性化播放列表和促进偶然发现新音乐来增强用户体验。然而，现有的推荐系统忽略了音乐领域固有的独特挑战，特别是随机播放，它提供随机序列的后续曲目。根据我们的观察，主要由于洗牌游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游戏游。MUSE 采用自监督学习框架，最大限度地提高了原始会话和扩展会话之间的一致性，并通过我们新颖的会话扩展方法(称为基于转换的扩展)进行了扩展。为了进一步促进两个视图之间的匹配，我们设计了两种细粒度匹配策略，即基于项目和相似性的匹配策略。通过在不同环境中进行的严格实验，我们在来自 Spotify 的大规模音乐流媒体会话数据集(MSSD)上证明了 MUSE 超过12个基线模型的功效。MUSE 的源代码可以在 url { https://github.com/yunhak0/MUSE }找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MUSE:+Music+Recommender+System+with+Shuffle+Play+Recommendation+Enhancement)|0|
|[Dual-Oriented Contrast for Recommendation with A Stop-Gradient Operation](https://doi.org/10.1145/3583780.3614852)|Byungkook Oh, Yul Kim, Bumky Min|Samsung Research, Seoul, Republic of Korea|Recently, contrastive loss is adopted as a main objective of recommender systems. InfoNCE-like losses penalize hard negative items more and control the strength of penalties with a temperature, called hardness-aware sensitivity. However, since they leverageuser->item patterns in a non-symmetric way, negative items are pushed away from anchor users and attract semantically-similar items to each other, focusing on the distribution of item embeddings. We point out that user embeddings also have inherent semantic structures that can be captured fromitem->user patterns. This paper presents Dual-oriented Contrast(DuCo), a novel symmetric learning objective for recommendation to learn more comprehensive representations fromusereftrightarrowitem patterns. DuCo controls user-/item-centric hardness-aware sensitivities and simultaneously optimizes the score distributions over sampled items (user-oriented contrast) and users (item-oriented contrast). This aims to explore ideal user and item distributions that are locally clustered and globally uniform. However, since user-/item-side temperatures are interdependent, naive control over temperatures may break the underlying semantic structures of the other side. To this end, we employ a stop-gradient operation to preserve the individual characteristics of user/item embedding distributions. Furthermore, we balance user-/item-oriented contrasts during learning to maintain consistent high-rank performance (e.g., recall@1). Empirical results show that DuCo contributes to the top-k user and item prediction simultaneously, and outperforms state-of-the-art learning objectives across different backbones from ID-based to neighbor-based encoders.|近年来，对比损失被作为推荐系统的主要目标。类似于 InfoNCE 的损失更多地惩罚硬负面项目，并用温度控制惩罚的强度，称为硬度感知灵敏度。然而，由于它们以一种非对称的方式利用 user-> item 模式，负面条目被推离锚用户，并且相互吸引语义相似的条目，关注条目嵌入的分布。我们指出，用户嵌入还具有可以从 mitem-> 用户模式捕获的固有语义结构。本文提出了一种新的对称推荐学习目标——双向对比度(DuCo)。DuCo 控制以用户/项目为中心的硬度感知敏感性，并同时优化分数分布的抽样项目(面向用户的对比)和用户(面向项目的对比)。这旨在探索理想的本地集群和全局统一的用户和项目分布。但是，由于用户/项目端的温度是相互依赖的，因此对温度的天真控制可能会破坏另一端的底层语义结构。为此，我们使用了一个停止梯度操作来保留用户/项嵌入分布的各自特征。此外，我们在学习过程中平衡用户/项目导向的对比，以保持一致的高等级性能(例如，召回@1)。实证结果表明，DuCo 能够同时提供最佳用户和项目预测，并且在从基于 ID 的编码器到基于邻居的编码器的不同骨干网络中，其学习效果优于最先进的学习目标。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual-Oriented+Contrast+for+Recommendation+with+A+Stop-Gradient+Operation)|0|
|[Quad-Tier Entity Fusion Contrastive Representation Learning for Knowledge Aware Recommendation System](https://doi.org/10.1145/3583780.3615020)|Rongqing Kenneth Ong, Wei Qiu, Andy W. H. Khong|Nanyang Technological University, Singapore, Singapore|Knowledge graph (KG) has recently emerged as a powerful source of auxiliary information in the realm of knowledge-aware recommendation (KGR) systems. However, due to the lack of supervision signals caused by the sparse nature of user-item interactions, existing supervised graph neural network (GNN) models suffer from performance degradation. Moreover, the over-smoothing issue further limits the number of GNN layers or hops required to propagate messages - these models ignore the non-local information concealed deep within the knowledge graph. We propose the Quad-Tier Entity Fusion Contrastive Representation Learning (QTEF-CRL) knowledge-aware framework to achieve learning of deep user preferences from four perspectives: the collaborative, semantic, preference, and structural view. Unlike existing methods, the proposed tri-local and single-global quad-tier architecture exploits the knowledge graph holistically to achieve effective self-supervised representation learning. The newly-introduced preference view constructed from the collaborative knowledge graph (CKG) comprises a preference graph and preference-guided GNN that are specifically designed to capture non-local information explicitly. Experiments conducted on three datasets highlight the efficacy of our proposed model.|在知识感知推荐(KGR)系统领域，知识图(KG)已经成为一个强大的辅助信息源。然而，由于用户-项目交互的稀疏性造成监督信号的缺乏，现有的监督图神经网络(GNN)模型存在性能下降的问题。此外，过于平滑的问题进一步限制了传播消息所需的 GNN 层数或跳数——这些模型忽略了隐藏在知识图深处的非本地信息。我们提出了四层实体融合对比表示学习(QTEF-CRL)知识感知框架，从协作、语义、偏好和结构四个角度实现深度用户偏好的学习。与现有的方法不同，本文提出的三局部和单全局四层结构全面地利用知识图来实现有效的自监督表示学习。由协同知识图(CKG)构造的新的偏好视图包括偏好图和偏好引导的 GNN，它们是专门为显式捕获非局部信息而设计的。在三个数据集上进行的实验突出了我们提出的模型的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quad-Tier+Entity+Fusion+Contrastive+Representation+Learning+for+Knowledge+Aware+Recommendation+System)|0|
|[A Retrieve-and-Read Framework for Knowledge Graph Link Prediction](https://doi.org/10.1145/3583780.3614769)|Vardaan Pahuja, Boshi Wang, Hugo Latapie, Jayanth Srinivasa, Yu Su|The Ohio State University, Columbus, OH, USA; Cisco Research, San Jose, CA, USA|Knowledge graph (KG) link prediction aims to infer new facts based on existing facts in the KG. Recent studies have shown that using the graph neighborhood of a node via graph neural networks (GNNs) provides more useful information compared to just using the query information. Conventional GNNs for KG link prediction follow the standard message-passing paradigm on the entire KG, which leads to over-smoothing of representations and also limits their scalability. On a large scale, it becomes computationally expensive to aggregate useful information from the entire KG for inference. To address the limitations of existing KG link prediction frameworks, we propose a novel retrieve-and-read framework, which first retrieves a relevant subgraph context for the query and then jointly reasons over the context and the query with a high-capacity reader. As part of our exemplar instantiation for the new framework, we propose a novel Transformer-based GNN as the reader, which incorporates graph-based attention structure and cross-attention between query and context for deep fusion. This design enables the model to focus on salient context information relevant to the query. Empirical results on two standard KG link prediction datasets demonstrate the competitive performance of the proposed method.|知识图(KG)链接预测的目的是根据 KG 中已有的事实推断出新的事实。最近的研究表明，通过图神经网络(GNN)使用节点的图邻域比仅仅使用查询信息提供更多有用的信息。用于 KG 链路预测的传统 GNN 遵循整个 KG 上的标准消息传递范式，这导致表示过于平滑，也限制了它们的可伸缩性。在大规模情况下，从整个 KG 中聚合有用的信息进行推理的计算开销变得很大。针对现有 KG 链路预测框架的局限性，提出了一种新的检索-读取框架，该框架首先检索查询的相关子图上下文，然后与大容量阅读器对上下文和查询进行联合推理。作为新框架示例实例的一部分，我们提出了一种新的基于 Transform- 的 GNN 作为读者，它结合了基于图的注意结构和查询与上下文之间的交叉注意来进行深度融合。这种设计使模型能够关注与查询相关的显著上下文信息。在两个标准 KG 链路预测数据集上的实验结果证明了该方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Retrieve-and-Read+Framework+for+Knowledge+Graph+Link+Prediction)|0|
|[Toward a Better Understanding of Loss Functions for Collaborative Filtering](https://doi.org/10.1145/3583780.3615086)|Seongmin Park, Mincheol Yoon, Jaewoong Lee, Hogun Park, Jongwuk Lee|Sungkyunkwan University, Suwon, Republic of Korea|Collaborative filtering (CF) is a pivotal technique in modern recommender systems. The learning process of CF models typically consists of three components: interaction encoder, loss function, and negative sampling. Although many existing studies have proposed various CF models to design sophisticated interaction encoders, recent work shows that simply reformulating the loss functions can achieve significant performance gains. This paper delves into analyzing the relationship among existing loss functions. Our mathematical analysis reveals that the previous loss functions can be interpreted as alignment and uniformity functions: (i) the alignment matches user and item representations, and (ii) the uniformity disperses user and item distributions. Inspired by this analysis, we propose a novel loss function that improves the design of alignment and uniformity considering the unique patterns of datasets called Margin-aware Alignment and Weighted Uniformity (MAWU). The key novelty of MAWU is two-fold: (i) margin-aware alignment (MA) mitigates user/item-specific popularity biases, and (ii) weighted uniformity (WU) adjusts the significance between user and item uniformities to reflect the inherent characteristics of datasets. Extensive experimental results show that MF and LightGCN equipped with MAWU are comparable or superior to state-of-the-art CF models with various loss functions on three public datasets.|协同过滤(CF)是现代推荐系统中的一项关键技术。CF 模型的学习过程通常由三部分组成: 交互编码器、损耗函数和负采样。虽然许多现有的研究已经提出了各种 CF 模型来设计复杂的交互编码器，最近的工作表明，简单地重新制定损失函数可以取得显著的性能增益。本文深入分析了现有损失函数之间的关系。我们的数学分析表明，先前的损失函数可以解释为对齐和一致性函数: (i)对齐匹配用户和项目表示，和(ii)一致性分散用户和项目分布。受此分析的启发，我们提出了一种新的损失函数，改进了排列和均匀性的设计，考虑到独特的模式数据集称为边缘感知排列和加权均匀性(MAWU)。MAWU 的关键新颖性有两个方面: (i)边际感知对齐(MA)减轻用户/项目特定的流行偏见，和(ii)加权一致性(WU)调整用户和项目一致性之间的显着性以反映数据集的固有特征。大量的实验结果表明，配备 MAWU 的 MF 和 LightGCN 在三个公共数据集上具有各种损失函数，与最先进的 CF 模型相比具有可比性或优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Toward+a+Better+Understanding+of+Loss+Functions+for+Collaborative+Filtering)|0|
|[Evaluating and Optimizing the Effectiveness of Neural Machine Translation in Supporting Code Retrieval Models: A Study on the CAT Benchmark](https://doi.org/10.1145/3583780.3614869)|Hung Phan, Ali Jannesari|Iowa State University, Ames, IA, USA|Neural Machine Translation (NMT) is widely applied in software engineering tasks. The effectiveness of NMT for code retrieval relies on the ability to learn from the sequence of tokens in the source language to the sequence of tokens in the target language. While NMT performs well in pseudocode-to-code translation, it might have challenges in learning to translate from natural language query to source code in newly curated real-world code documentation/ implementation datasets. In this work, we analyze the performance of NMT in natural language-to-code translation in the newly curated CAT benchmark that includes the optimized versions of three Java datasets TLCodeSum, CodeSearchNet, Funcom, and a Python dataset PCSD. Our evaluation shows that NMT has low accuracy, measured by CrystalBLEU and Meteor metrics in this task. To alleviate the duty of NMT in learning complex representation of source code, we propose ASTTrans Representation, a tailored representation of an Abstract Syntax Tree (AST) using a subset of non-terminal nodes. We show that the classical approach NMT performs significantly better in learning ASTTrans Representation over code tokens with up to 36% improvement on Meteor score. Moreover, we leverage ASTTrans Representation to conduct combined code search processes from the state-of-the-art code search processes using GraphCodeBERT and UniXcoder. Our NMT models of learning ASTTrans Representation can boost the Mean Reciprocal Rank of these state-of-the-art code search processes by up to 3.08% and improve 23.08% of queries' results over the CAT benchmark.|神经机器翻译(NMT)在软件工程任务中有着广泛的应用。NMT 对于代码检索的有效性依赖于从源语言中的令牌序列学习到目标语言中的令牌序列的能力。虽然 NMT 在伪代码到代码的转换中表现良好，但是在学习如何在新策划的真实世界代码文档/实现数据集中从自然语言查询转换为源代码时，可能会遇到挑战。在这项工作中，我们分析了 NMT 在自然语言到代码的翻译中的性能，新策划的 CAT 基准包括三个 Java 数据集 tlcodeSum，codeSearchNet，Funcom 和一个 Python 数据集 PCSD 的优化版本。我们的评估表明，NMT 的准确度较低，测量晶体 BLEU 和流星指标在这个任务。为了减轻 NMT 在学习源代码复杂表示方面的责任，我们提出了一种基于非终端节点子集的抽象语法树表示(AST)。我们表明，经典的方法 NMT 在学习 ASTTrans 表示明显优于代码令牌，提高了36% 的流星分数。此外，我们利用 ASTTrans 表示来使用 GraphCodeBERT 和 UniXcoder 从最先进的代码搜索过程中进行组合代码搜索过程。我们的学习 ASTTrans 表示的 NMT 模型可以将这些最先进的代码搜索过程的平均倒数排名提高3.08% ，比 CAT 基准提高23.08% 的查询结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Evaluating+and+Optimizing+the+Effectiveness+of+Neural+Machine+Translation+in+Supporting+Code+Retrieval+Models:+A+Study+on+the+CAT+Benchmark)|0|
|[Dual-Process Graph Neural Network for Diversified Recommendation](https://doi.org/10.1145/3583780.3614853)|Yuanyi Ren, Hang Ni, Yingxue Zhang, Xi Wang, Guojie Song, Dong Li, Jianye Hao|Huawei Noah's Ark Lab, Beijing, China; Peking University, Beijing, China; Northwestern Polytechnical University, Xi'an, China; Huawei Noah's Ark Lab, Markham, Canada|The recommender system is one of the most fundamental information services. A significant effort has been devoted to improving prediction accuracy, inevitably leading to the potential degradation of recommendation diversity. Moreover, individuals have different needs for diversity. To address these problems, diversity-enhanced approaches are proposed to modify the recommender models. However, these methods fail to break free from the relevance-oriented paradigm and are mostly haunted by sharply-declined accuracy and high computational costs. To tackle these challenges, we propose the Dual-Process Graph Neural Network (DPGNN), an efficient diversity-enhanced recommender system, resonating with the dual-process model of human cognition and the arousal theory of human interest. The first stage reduces the risk of suboptimal output during the training procedure, which helps to find a solution outside the relevance-oriented paradigm. Moreover, the second stage utilizes user-specific rating adjustments, boosting the recommendation diversity and accommodating users' distinctive needs with minimum computational costs. Extensive experiments on real-world datasets verify the effectiveness of our method in improving diversity, while maintaining accuracy with low computational costs.|推荐系统是最基本的信息服务之一。为了提高预测的准确性，人们付出了巨大的努力，这不可避免地导致了推荐多样性的潜在退化。此外，个体对多样性有不同的需求。为了解决这些问题，提出了基于多样性增强的方法来修改推荐模型。然而，这些方法未能摆脱以关联为导向的范式，并且大多受到精度急剧下降和计算成本高的困扰。为了应对这些挑战，我们提出了双进程图形神经网络(DPGNN) ，一种有效的多样性增强推荐系统，与人类认知的双进程模型和人类兴趣唤醒理论产生共鸣。第一阶段降低了培训过程中产出不理想的风险，这有助于找到一个以关联为导向的范式之外的解决方案。此外，第二阶段利用用户特定的评分调整，提高推荐的多样性，以最小的计算成本满足用户的特殊需求。在真实世界数据集上的大量实验证明了该方法在提高多样性的同时以较低的计算成本保持准确性方面的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual-Process+Graph+Neural+Network+for+Diversified+Recommendation)|0|
|[Dual-view Contrastive Learning for Auction Recommendation](https://doi.org/10.1145/3583780.3614854)|Dan Ni Ren, Leong Hou U, Wei Liu|University of Macau, Macau SAR, Macao; Sun Yat-sen University, Guangdong, China|Recommendation systems in auction platforms like eBay function differently in comparison to those found in traditional trading platforms. The bidding process involves multiple users competing for a product, with the highest bidder winning the item. As a result, each transaction is independent and characterized by varying transaction prices. The individual nature of auction items means that users cannot purchase identical items, adding to the uniqueness of the purchasing history. Bidders in auction systems rely on their judgment to determine the value of a product, as bidding prices reflect preferences rather than cost-free actions like clicking or collecting. Conventional methodologies that heavily rely on user-item purchase history are ill-suited to handle these unique and extreme product features. Unfortunately, prior recommendation approaches have failed to give due attention to the contextual intricacies of auction items, thereby missing out on the full potential of the invaluable bidding record at hand. This paper introduces a novel contrastive learning approach for auction recommendation, addressing the challenges of data sparsity and uniqueness in auction recommendation. Our method focuses on capturing multiple behavior relations and item context through contrastive pairs construction, contrastive embedding, and contrastive optimization techniques from both user and item perspectives. By overcoming the limitations of previous approaches, our method delivers promising results on two auction datasets, highlighting the practicality and effectiveness of our model.|EBay 等拍卖平台中的推荐系统与传统交易平台中的推荐系统功能不同。投标过程涉及多个用户竞争一个产品，出价最高者中标。因此，每笔交易都是独立的，拥有属性不同的交易价格。拍卖物品的个别性质意味着用户不能购买相同的物品，增加了购买历史的唯一性。拍卖系统中的投标人依靠自己的判断来确定产品的价值，因为投标价格反映的是偏好，而不是点击或收集等无成本的行为。严重依赖于用户商品购买历史的传统方法不适合处理这些独特和极端的产品特性。遗憾的是，先前的推荐办法未能适当注意到拍卖物品的复杂背景，从而错过了手头宝贵的投标记录的全部潜力。针对拍卖推荐中存在的数据稀疏性和唯一性等问题，提出了一种新的拍卖推荐对比学习方法。该方法从用户和项目的角度出发，通过对比对构造、对比嵌入和对比优化技术来捕获多个行为关系和项目上下文。通过克服以往方法的局限性，我们的方法在两个拍卖数据集上提供了有希望的结果，突出了我们的模型的实用性和有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual-view+Contrastive+Learning+for+Auction+Recommendation)|0|
|[GiGaMAE: Generalizable Graph Masked Autoencoder via Collaborative Latent Space Reconstruction](https://doi.org/10.1145/3583780.3614894)|Yucheng Shi, Yushun Dong, Qiaoyu Tan, Jundong Li, Ninghao Liu|University of Virginia, Charlottesville, VA, USA; Texas A&M University, College Station, TX, USA; University of Georgia, Athens, GA, USA|Self-supervised learning with masked autoencoders has recently gained popularity for its ability to produce effective image or textual representations, which can be applied to various downstream tasks without retraining. However, we observe that the current masked autoencoder models lack good generalization ability on graph data. To tackle this issue, we propose a novel graph masked autoencoder framework called GiGaMAE. Different from existing masked autoencoders that learn node presentations by explicitly reconstructing the original graph components (e.g., features or edges), in this paper, we propose to collaboratively reconstruct informative and integrated latent embeddings. By considering embeddings encompassing graph topology and attribute information as reconstruction targets, our model could capture more generalized and comprehensive knowledge. Furthermore, we introduce a mutual information based reconstruction loss that enables the effective reconstruction of multiple targets. This learning objective allows us to differentiate between the exclusive knowledge learned from a single target and common knowledge shared by multiple targets. We evaluate our method on three downstream tasks with seven datasets as benchmarks. Extensive experiments demonstrate the superiority of GiGaMAE against state-of-the-art baselines. We hope our results will shed light on the design of foundation models on graph-structured data. Our code is available at: https://github.com/sycny/GiGaMAE.|掩蔽自动编码器的自监督学习因其能够产生有效的图像或文本表示而得到广泛应用，可以在不需要再培训的情况下应用于各种下游任务。然而，我们观察到目前的掩码自动编码器模型缺乏良好的图形数据泛化能力。为了解决这个问题，我们提出了一种新的图形掩码自动编码框架，称为 GiGaMAE。与现有的隐式自动编码器不同，隐式自动编码器通过显式重构原始的图形组件(如特征或边)来学习节点表示，本文提出了协同重构信息化和集成化的潜在嵌入。该模型以包含图形拓扑和属性信息的嵌入为重构目标，可以获得更广泛、更全面的知识。此外，我们还引入了一种基于互信息的重建损失算法，可以有效地重建多个目标。这种学习目标使我们能够区分从单个目标学习的专有知识和由多个目标共享的共同知识。我们用七个数据集作为基准，在三个下游任务上评估我们的方法。大量的实验证明了 GiGaMAE 相对于最先进的基线的优越性。我们希望我们的研究结果能够对基于图结构数据的基础模型的设计有所帮助。我们的代码可以在以下 https://github.com/sycny/gigamae 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GiGaMAE:+Generalizable+Graph+Masked+Autoencoder+via+Collaborative+Latent+Space+Reconstruction)|0|
|[Joint Rebalancing and Charging for Shared Electric Micromobility Vehicles with Energy-informed Demand](https://doi.org/10.1145/3583780.3614942)|Heng Tan, Yukun Yuan, Shuxin Zhong, Yu Yang|Lehigh University, Bethlehem, PA, USA; Rutgers University, New Brunswick, NJ, USA; University of Tennessee at Chattanooga, Chattanooga, TN, USA|Shared electric micromobility (e.g., shared electric bikes and electric scooters), as an emerging way of urban transportation, has been increasingly popular in recent years. However, managing thousands of micromobility vehicles in a city, such as rebalancing and charging vehicles to meet spatial-temporally varied demand, is challenging. Existing management frameworks generally consider demand as the number of requests without the energy consumption of these requests, which can lead to less effective management. To address this limitation, we design RECOMMEND, a rebalancing and charging framework for shared electric micromobility vehicles with energy-informed demand to improve the system revenue. Specifically, we first re-define the demand from the perspective of energy consumption and predict the future energy-informed demand based on the state-of-the-art spatial-temporal prediction method. Then we fuse the predicted energy-informed demand into different components of a rebalancing and charging framework based on reinforcement learning. We evaluate the RECOMMEND system with 2-month real-world electric micromobility system operation data. Experimental results show that our method can be easily integrated into a general RL framework and outperform state-of-the-art baselines by at least 26.89% in terms of net revenue.|共享电动微型交通(如共享电动自行车和电动滑板车) ，作为一种新兴的城市交通方式，近年来越来越受欢迎。然而，在一个城市管理数以千计的微型移动车辆，如重新平衡和充电车辆，以满足时空不同的需求，是具有挑战性的。现有管理框架一般将需求视为没有这些需求的能源消耗的需求数量，这可能导致管理效率较低。为了解决这一局限性，我们设计了一个再平衡和充电框架 RECOMMEND，用于具有能源信息需求的共享电动微型移动车辆，以提高系统收入。具体来说，我们首先从能源消费的角度重新定义需求，并基于最新的时空预测方法对未来的能源知情需求进行预测。然后，我们将预测的能源需求融入基于强化学习的再平衡和收费框架的不同组成部分。我们使用2个月的实际电子微移动系统运行数据对 RECOMMEND 系统进行了评估。实验结果表明，该方法可以很容易地集成到一个通用的 RL 框架中，并且在净收入方面比最先进的基线至少高出26.89% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Joint+Rebalancing+and+Charging+for+Shared+Electric+Micromobility+Vehicles+with+Energy-informed+Demand)|0|
|[Experience and Evidence are the eyes of an excellent summarizer! Towards Knowledge Infused Multi-modal Clinical Conversation Summarization](https://doi.org/10.1145/3583780.3614870)|Abhisek Tiwari, Anisha Saha, Sriparna Saha, Pushpak Bhattacharyya, Minakshi Dhar|Indian Institute of Technology, Bombay, Bombay, India; All India Institute of Medical Sciences, Rishikesh, Rishikesh, India; Indian Institute of Technology, Patna, Patna, India|With the advancement of telemedicine, both researchers and medical practitioners are working hand-in-hand to develop various techniques to automate various medical operations, such as diagnosis report generation. In this paper, we first present a multi-modal clinical conversation summary generation task that takes a clinician-patient interaction (both textual and visual information) and generates a succinct synopsis of the conversation. We propose a knowledge-infused, multi-modal, multi-tasking medical domain identification and clinical conversation summary generation (MM-CliConSummation) framework. It leverages an adapter to infuse knowledge and visual features and unify the fused feature vector using a gated mechanism. Furthermore, we developed a multi-modal, multi-intent clinical conversation summarization corpus annotated with intent, symptom, and summary. The extensive set of experiments, both quantitatively and qualitatively, led to the following findings: (a) critical significance of visuals, (b) more precise and medical entity preserving summary with additional knowledge infusion, and (c) a correlation between medical department identification and clinical synopsis generation. Furthermore, the dataset and source code are available at https://github.com/NLP-RL/MM-CliConSummation.|随着远程医疗的发展，研究人员和医务人员正携手合作，开发各种技术，以自动化各种医疗操作，如诊断报告生成。在本文中，我们首先提出了一个多模态的临床会话摘要生成任务，采用临床医生-患者的互动(文本和视觉信息) ，并生成一个简洁的会话概要。我们提出了一个知识注入、多模态、多任务的医学领域识别和临床会话摘要生成(MM-CliConsum)框架。它利用适配器来注入知识和可视化特征，并使用门控机制统一融合特征向量。此外，我们开发了一个多模式，多意图临床会话摘要语料库注释意图，症状和总结。广泛的一系列定量和定性实验导致了以下发现: (a)视觉的关键意义，(b)更精确的医疗实体保存总结与额外的知识输入，以及(c)医疗部门识别和临床概要生成之间的相关性。此外，数据集和源代码也可以在 https://github.com/nlp-rl/mm-cliconsummation 中找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Experience+and+Evidence+are+the+eyes+of+an+excellent+summarizer!+Towards+Knowledge+Infused+Multi-modal+Clinical+Conversation+Summarization)|0|
|[Towards Deeper, Lighter and Interpretable Cross Network for CTR Prediction](https://doi.org/10.1145/3583780.3615089)|Fangye Wang, Hansu Gu, Dongsheng Li, Tun Lu, Peng Zhang, Ning Gu||Click Through Rate (CTR) prediction plays an essential role in recommender systems and online advertising. It is crucial to effectively model feature interactions to improve the prediction performance of CTR models. However, existing methods face three significant challenges. First, while most methods can automatically capture high-order feature interactions, their performance tends to diminish as the order of feature interactions increases. Second, existing methods lack the ability to provide convincing interpretations of the prediction results, especially for high-order feature interactions, which limits the trustworthiness of their predictions. Third, many methods suffer from the presence of redundant parameters, particularly in the embedding layer. This paper proposes a novel method called Gated Deep Cross Network (GDCN) and a Field-level Dimension Optimization (FDO) approach to address these challenges. As the core structure of GDCN, Gated Cross Network (GCN) captures explicit high-order feature interactions and dynamically filters important interactions with an information gate in each order. Additionally, we use the FDO approach to learn condensed dimensions for each field based on their importance. Comprehensive experiments on five datasets demonstrate the effectiveness, superiority and interpretability of GDCN. Moreover, we verify the effectiveness of FDO in learning various dimensions and reducing model parameters. The code is available on https://github.com/anonctr/GDCN.|点击通过率(CTR)预测在推荐系统和在线广告中起着至关重要的作用。有效的特征交互建模对于提高 CTR 模型的预测性能至关重要。然而，现有的方法面临三个重大挑战。首先，虽然大多数方法可以自动捕获高阶特征交互，但是它们的性能往往会随着特征交互次序的增加而下降。其次，现有的方法缺乏对预测结果提供令人信服的解释的能力，特别是对于高阶特征相互作用，这限制了它们的预测的可信度。第三，许多方法都存在冗余参数，特别是在嵌入层。本文提出了一种新的方法，称为门控深交叉网络(GDCN)和场级尺寸优化(FDO)的方法来解决这些挑战。门限交叉网络(GCN)作为 GDCN 的核心结构，捕获显式的高阶特征交互，并动态过滤每个阶段与信息门的重要交互。此外，我们使用 FDO 方法根据每个领域的重要性来学习压缩维度。通过对五个数据集的综合实验，验证了 GDCN 算法的有效性、优越性和可解释性。此外，我们还验证了 FDO 在学习各种维数和降低模型参数方面的有效性。密码可以在 https://github.com/anonctr/gdcn 上找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Deeper,+Lighter+and+Interpretable+Cross+Network+for+CTR+Prediction)|0|
|[AFRF: Angle Feature Retrieval Based Popularity Forecasting](https://doi.org/10.1145/3583780.3614776)|Haoyu Wang, Zongxia Xie, Meiyao Liu, Canhua Guan|Tianjin University, Tianjin, China|Social media popularity forecasting has become a hot research topic in recent years. It is of great significance in assisting public opinion monitoring and advertising placement. Time series prediction is one of the simple and commonly used methods for popularity forecasting, which takes the popularity of the first few time steps in the observed data as inputs. However, the complete popularity trend of each social media is known in the training dataset, while the historical time series information except for the first few time steps is neglected in the existing models. In order to utilize the complete historical information from the observed data, a retrieval method is introduced in this paper. Therefore, how to retrieve similar social media based on the first few steps time series and how to integrate the similar historical information have become two challenges. A two-stage prediction method named Angle Feature Retrieval based Forecasting (AFRF) is proposed in this paper to solve the upper two problems. In the first stage, based on the angle features of series, we retrieve K similar series from the historical posts and concatenate them with the target series as the model's input. In the second stage, an attention mechanism is used to learn the temporal relationships among the series and generate future popularity forecasts. We evaluated the multi-step and single-point forecasting performance of AFRF on three real-world datasets and compared it with state-of-the-art popularity forecasting methods, such as temporal feature-based and cascade-based methods, verifying the effectiveness of AFRF.|社交媒体受欢迎程度预测已成为近年来的研究热点。它对辅助舆论监督和广告投放具有重要意义。时间序列预测是一种简单、常用的流行度预测方法，它以观测数据中前几个时间步长的流行度作为输入。然而，在训练数据集中已经知道每个社会媒体的完全流行趋势，而在现有的模型中，除了前几个时间步骤之外的历史时间序列信息被忽略了。为了充分利用观测数据中的完整历史信息，本文提出了一种检索方法。因此，如何基于前几步时间序列检索相似的社会媒体，如何整合相似的历史信息，已成为两大挑战。针对上述两个问题，提出了一种基于角度特征反演的两阶段预测方法(AFRF)。在第一阶段，根据序列的角度特征，从历史文章中提取出 K 个相似序列，并将它们与目标序列连接起来作为模型的输入。在第二阶段，使用注意机制来学习序列之间的时间关系，并生成未来的流行预测。对 AFRF 在三个实际数据集上的多步预测性能和单点预测性能进行了评估，并与基于时间特征和基于级联的流行性预测方法进行了比较，验证了 AFRF 的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AFRF:+Angle+Feature+Retrieval+Based+Popularity+Forecasting)|0|
|[SplitGNN: Spectral Graph Neural Network for Fraud Detection against Heterophily](https://doi.org/10.1145/3583780.3615067)|Bin Wu, Xinyu Yao, Boyan Zhang, KuoMing Chao, Yinsheng Li|Fudan University, Shanghai, China; University of Roehampton, London, United Kingdom|Fraudsters in the real world frequently add more legitimate links while concealing their direct ones with other fraudsters, leading to heterophily in fraud graphs, which is a problem that most GNN-based techniques are not built to solve. Several works have been proposed to tackle the issue from the spatial domain. However, researches on addressing the heterophily problem in the spectral domain are still limited due to a lack of understanding of spectral energy distribution in graphs with heterophily. In this paper, we analyze the spectral distribution with different heterophily degrees and observe that the heterophily of fraud nodes leads to the spectral energy moving from low-frequency to high-frequency. Further, we verify that splitting graphs using heterophilic and homophilic edges can obtain more significant expressions of signals in different frequency bands. The observation drives us to propose the spectral graph neural network, SplitGNN, to capture signals for fraud detection against heterophily. SplitGNN uses an edge classifier to split the original graph and adopts flexible band-pass graph filters to learn representations. Extensive experiments on real-world datasets demonstrate the effectiveness of our proposed method. The code and data are available at https://github.com/Split-GNN/SplitGNN.|现实世界中的欺诈者经常添加更多的合法链接，同时隐藏他们与其他欺诈者的直接链接，从而导致欺诈图中的异质性，这是大多数基于 GNN 的技术无法解决的问题。已经提出了几个工作，以解决从空间领域的问题。然而，由于缺乏对具有异质性的图的光谱能量分布的理解，有关谱域异质性问题的研究仍然十分有限。本文分析了欺诈节点不同异质性程度的频谱分布，发现欺诈节点的异质性导致频谱能量由低频向高频移动。进一步，我们验证了使用异质和同质边的分裂图可以在不同的频带获得更有意义的信号表达式。这一观测结果促使我们提出了谱图神经网络 SplitGNN 来捕获信号用于对异质性的欺诈检测。SplitGNN 使用边分类器对原始图进行分割，并采用灵活的带通图滤波器来学习表示。在实际数据集上的大量实验证明了该方法的有效性。代码和数据可在 https://github.com/split-gnn/splitgnn 查阅。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SplitGNN:+Spectral+Graph+Neural+Network+for+Fraud+Detection+against+Heterophily)|0|
|[DPGN: Denoising Periodic Graph Network for Life Service Recommendation](https://doi.org/10.1145/3583780.3614850)|Hao Xu, Huixuan Chi, Danyang Liu, Sheng Zhou, Mengdi Zhang|Zhejiang University, Hangzhou, China; Meituan, Beijing, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China|Different from traditional e-commerce platforms, life service recommender systems provide hundreds of millions of users with daily necessities services such as nearby food ordering. In this scenario, users have instant intentions and living habits, which exhibit a periodic tendency to click or buy products with similar intentions. This can be summarized as the intentional periodicity problem, which was not well-studied in previous works. Existing periodic-related recommenders exploit time-sensitive functions to capture the evolution of user preferences. However, these methods are easily affected by the real noisy signal in life service platforms, wherein the recent noisy signals can mislead the instant intention and living habits modeling. We summarize it as the noise issue. Although there are some denoising recommenders, these methods cannot effectively solve the noise issue for intentional periodicity modeling. To alleviate the issues, we propose a novel Denoising Periodic Graph Network (DPGN) for life service recommendation. First, to alleviate the noisy signals and model the instant intention accurately, we propose (i) temporal pooling (TP) to encode the most representative information shared by recent behaviors; (ii) temporal encoding (TE) to encode the relative time intervals. Second, to capture the user's living habits accurately, we propose the memory mechanism to maintain a series of instant intentions in different time periods. Third, to further capture the intentional periodicity, we propose the temporal graph transformer (TGT) layer to aggregate temporal information. Last, the denoising task is further proposed to alleviate the noisy signals. Extensive experiments on both real-world public and industrial datasets validate the state-of-the-art performance of DPGN. Code is available in https://github.com/ytchx1999/DPGN|与传统的电子商务平台不同，生活服务推荐系统为数亿用户提供日常必需品服务，如附近的食品订购。在这种情况下，用户有即时的意图和生活习惯，这表现出一个周期性的趋势，点击或购买具有相似意图的产品。这可以概括为有意识的周期性问题，在以前的工作中没有得到很好的研究。现有的与周期相关的推荐程序利用时间敏感的功能来捕获用户偏好的演变。然而，这些方法很容易受到生活服务平台中真实噪声信号的影响，其中最近的噪声信号会误导人们的即时意图和生活习惯建模。我们把它归结为噪音问题。虽然有一些去噪建议，但这些方法不能有效地解决有意识的周期性建模的噪声问题。为了解决这些问题，我们提出了一种新的消噪周期图网络(DPGN)用于终身服务推荐。首先，为了减轻噪声信号的影响，准确地模拟瞬时意图，我们提出: (1)时间池(TP)对最近行为共享的最有代表性的信息进行编码; (2)时间编码(TE)对相对时间间隔进行编码。其次，为了准确地捕捉用户的生活习惯，我们提出了在不同时间段保持一系列即时意图的记忆机制。第三，为了进一步捕获有意识的周期性，我们提出了时间图转换(TGT)层来聚集时间信息。最后，进一步提出降噪任务，以减轻噪声信号。在真实世界的公共数据集和工业数据集上的大量实验验证了 DPGN 的最新性能。代码可在 https://github.com/ytchx1999/dpgn 下载|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DPGN:+Denoising+Periodic+Graph+Network+for+Life+Service+Recommendation)|0|
|[Identifying Regional Driving Risks via Transductive Cross-City Transfer Learning Under Negative Transfer](https://doi.org/10.1145/3583780.3614924)|Hua Yan, Hao Wang, Desheng Zhang, Yu Yang|Lehigh University, Bethlehem, PA, USA; Rutgers University, Piscataway, NJ, USA|Identifying regional driving risks is important for real-world applications such as driving safety warning applications, public safety management, and insurance company premium pricing. Previous approaches are either based on traffic accident reports or vehicular sensor data. They either fail to identify potential risks, such as near-miss collisions, which would need other important measurements (e.g., hard break, acceleration, etc.), or fail to generalize to cities without vehicular sensor data, severely limiting their practicality. In this work, we address these two challenges and successfully identify regional driving risks in a target city without vehicular sensor data via cross-city transfer learning. Specifically, we design a novel framework RiskTrans by optimizing both the predictor and the relationship between cities to achieve transfer learning. We advance the existing works from two aspects: (i) we achieve it in a transductive manner without accessing labeled data in the target cities; (ii) we identify and address the problem of negative transfer in cross-city transfer learning, a prominent issue that is often (surprisingly) neglected in previous works. Finally, we conduct extensive experiments based on data collected from 175 thousand vehicles in six cities. The results show RiskTrans outperforms baselines by at least 50.2% and reduces negative transfer by 49.4%.|识别区域驾驶风险对于驾驶安全警告应用程序、公共安全管理和保险公司保险费定价等实际应用程序非常重要。以前的方法要么基于交通事故报告，要么基于车辆传感器数据。他们要么不能识别潜在的风险，例如差点撞上，这将需要其他重要的测量(例如，硬碰撞，加速度等) ，或者不能推广到没有车辆传感器数据的城市，严重限制了他们的实用性。在这项工作中，我们解决这两个挑战，并成功地识别区域驾驶风险在目标城市没有车辆传感器数据通过跨城市转移学习。具体来说，我们设计了一个新的框架 RiskTrans，通过优化预测器和城市之间的关系来实现迁移学习。我们从两个方面推进现有的工作: (1)我们实现了转换的方式，而没有访问目标城市的标记数据; (2)我们识别和解决跨城市迁移学习中的负迁移问题，这是一个突出的问题，往往(令人惊讶)被忽视在以前的工作。最后，我们在六个城市17.5万辆汽车的数据基础上进行了广泛的实验。结果显示 RiskTrans 的业绩至少比基线水平高出50.2% ，负转移减少了49.4% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Identifying+Regional+Driving+Risks+via+Transductive+Cross-City+Transfer+Learning+Under+Negative+Transfer)|0|
|[FARA: Future-aware Ranking Algorithm for Fairness Optimization](https://doi.org/10.1145/3583780.3614877)|Tao Yang, Zhichao Xu, Zhenduo Wang, Qingyao Ai|University of Utah, Salt Lake City, UT, USA; DCST, Tsinghua University, Quan Cheng Laboratory, Zhongguancun Laboratory, Beijing, China|Ranking systems are the key components of modern Information Retrieval (IR) applications, such as search engines and recommender systems. Besides the ranking relevance to users, the exposure fairness to item providers has also been considered an important factor in ranking optimization. Many fair ranking algorithms have been proposed to jointly optimize both ranking relevance and fairness. However, we find that most existing fair ranking methods adopt greedy algorithms that only optimize rankings for the next immediate session or request. As shown in this paper, such a myopic paradigm could limit the upper bound of ranking optimization and lead to suboptimal performance in the long term. To this end, we propose FARA, a novel Future-Aware Ranking Algorithm for ranking relevance and fairness optimization. Instead of greedily optimizing rankings for the next immediate session, FARA plans ahead by jointly optimizing multiple ranklists together and saving them for future sessions. Particularly, FARA first uses the Taylor expansion to investigate how future ranklists will influence the overall fairness of the system. Then, based on the analysis of the Taylor expansion, FARA adopts a two-phase optimization algorithm where we first solve an optimal future exposure planning problem and then construct the optimal ranklists according to the optimal future exposure planning. Theoretically, we show that FARA is optimal for ranking relevance and fairness joint optimization. Empirically, our extensive experiments on three semi-synthesized datasets show that FARA is efficient, effective, and can deliver significantly better ranking performance compared to state-of-the-art fair ranking methods.|排名系统是现代信息检索应用(如搜索引擎和推荐系统)的关键组成部分。除了与用户的排名相关性之外，项目提供者的曝光公平性也被认为是排名优化的一个重要因素。许多公平排序算法被提出来共同优化排序的相关性和公平性。然而，我们发现大多数现有的公平排名方法采用贪婪算法，只优化下一个即时会话或请求的排名。如本文所述，这种短视的范式可能会限制排序优化的上界，并导致长期的次优性能。为此，我们提出了一种新的未来感知排序算法 FARA，用于排序相关性和公平性优化。FARA 没有贪婪地优化下一阶段的排名，而是提前计划，联合优化多个排名，并将它们保存到未来的阶段。特别是，FARA 首先利用泰勒扩展来调查未来的排行榜将如何影响系统的整体公平性。然后，在分析泰勒展开的基础上，采用两阶段优化算法，首先解决未来曝光规划问题，然后根据未来曝光规划的优化结果构造最优排名表。从理论上证明了 FARA 对于排序相关性和公平性联合优化是最优的。经验上，我们在三个半合成数据集上的大量实验表明，FARA 是有效的，有效的，并且能够提供比最先进的公平排序方法更好的排序性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FARA:+Future-aware+Ranking+Algorithm+for+Fairness+Optimization)|0|
|[Co-guided Random Walk for Polarized Communities Search](https://doi.org/10.1145/3583780.3614814)|Fanyi Yang, Huifang Ma, Cairui Yan, Zhixin Li, Liang Chang|Northwest Normal University, Lanzhou, China; Guangxi Normal University, Guilin, China; Guilin University of Electronic Technology, Guilin, China; NorthWest Normal University, Lanzhou, China|Polarized Communities Search (PCS) aims to identify query-dependent communities where positive links predominantly connect nodes within each community, while negative links primarily connect nodes across different communities. Existing solutions primarily focus on modeling network topology, disregarding the crucial factor of node attributes. However, it is non-trivial to incorporate node attributes into PCS. In this paper, we propose a novel method called CO-guided RAndom walk in attributed signed networks (CORA) for PCS. Our approach involves constructing an attribute-based signed network to represent the auxiliary relations between nodes. We introduce a weight assignment mechanism to assess the reliability of edges in the signed network. Then, we design a co-guided random walk scheme that operates on two signed networks to model the connections between network topology and node attributes, thereby enhancing the search outcomes. Finally, we identify polarized communities using the Rayleigh quotient in the signed network. Extensive experiments conducted on three public datasets demonstrate the superior performance of CORA compared to state-of-the-art baselines for polarized communities search.|极化社区搜索(PCS)旨在识别查询依赖的社区，其中正向链接主要连接每个社区内的节点，而负向链接主要连接不同社区的节点。现有的解决方案主要侧重于建模网络拓扑，忽略了节点属性的关键因素。然而，将节点属性合并到 PCS 中是非常重要的。在本文中，我们提出了一种新的方法称为 CO 引导的随机游走在属性签名网络(CORA)的 PCS。我们的方法包括构造一个基于属性的有符号网络来表示节点之间的辅助关系。我们引入了一种权重分配机制来评估有符号网络中边的可靠性。然后，我们设计一个共同引导的随机游走方案，在两个签名网络上操作，建立网络拓扑和节点属性之间的联系模型，从而提高搜索结果。最后，我们利用有符号网络中的瑞利商来识别极化群落。在三个公共数据集上进行的大量实验表明，与最先进的极化社区搜索基线相比，CORA 具有更好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Co-guided+Random+Walk+for+Polarized+Communities+Search)|0|
|[Federated News Recommendation with Fine-grained Interpolation and Dynamic Clustering](https://doi.org/10.1145/3583780.3614881)|Sanshi Lei Yu, Qi Liu, Fei Wang, Yang Yu, Enhong Chen|Anhui Province Key Laboratory of Big Data Analysis and Application, University of Science and Technology of China & State Key Laboratory of Cognitive Intelligence, Hefei, China|Researchers have successfully adapted the privacy-preserving Federated Learning (FL) to news recommendation tasks to better protect users' privacy, although typically at the cost of performance degradation due to the data heterogeneity issue. To address this issue, Personalized Federated Learning (PFL) has emerged, among which model interpolation is a promising approach that interpolates the local personalized models with the global model. However, the existing model interpolation method may not work well for news recommendation tasks for some reasons. First, it neglects the fine-grained personalization needs at both the temporal and spatial levels in news recommendation tasks. Second, due to the cold-user problem in real-world news recommendation tasks, the local personalized models may perform poorly, thus limiting the performance gain from model interpolation. To this end, we propose FINDING (Federated News Recommendation with Fine-grained Interpolation and Dynamic Clustering ), a novel personalized federated learning framework based on model interpolation. Specifically, we first propose the fine-grained model interpolation strategy which interpolates the local personalized models with the global model in a time-aware and layer-aware way. Then, to address the cold-user problem in news recommendation tasks, we adopt the group-level personalization approach where users are dynamically clustered into groups and the group-level personalized models are used for interpolation. Extensive experiments on two real-world datasets show that our method can effectively handle the above limitations of the current model interpolation method and alleviate the heterogeneity issue faced by traditional FL.|研究人员已经成功地将保护隐私的联邦学习(FL)应用到新闻推荐任务中，以更好地保护用户的隐私，尽管由于数据异构性问题，这通常会以性能下降为代价。为了解决这一问题，个性化联邦学习(PFL)应运而生，其中模型插值是一种很有前途的方法，它利用全局模型对局部个性化模型进行插值。然而，由于某些原因，现有的模型插值方法在新闻推荐任务中可能不能很好地工作。首先，它忽略了新闻推荐任务在时间和空间层面上的细粒度个性化需求。其次，由于现实新闻推荐任务中的冷用户问题，本地个性化模型可能表现不佳，从而限制了模型插值的性能增益。为此，本文提出了一种新的基于模型插值的个性化联邦学习框架 FINING (具有细粒度插值和动态聚类的联邦新闻推荐)。具体地说，我们首先提出了细粒度模型插值策略，该策略以时间感知和层感知的方式将局部个性化模型插值到全局模型中。然后，针对新闻推荐任务中的冷用户问题，采用组级个性化方法，将用户动态聚类成组，并使用组级个性化模型进行插值。在两个实际数据集上的大量实验表明，该方法能有效地处理现有模型插值方法的上述局限性，缓解传统 FL 所面临的异构性问题。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Federated+News+Recommendation+with+Fine-grained+Interpolation+and+Dynamic+Clustering)|0|
|[VILE: Block-Aware Visual Enhanced Document Retrieval](https://doi.org/10.1145/3583780.3615107)|Huaying Yuan, Zhicheng Dou, Yujia Zhou, Yu Guo, JiRong Wen|Engineering Research Center of Next-Generation Intelligent Search and Recommendation, Ministry of Education & Renmin University of China, Beijing, China; Renmin University of China, Beijing, China|Document retrieval has always been a crucial problem in Web search. Recent works leverage pre-trained language models to represent documents in dense vectors. However, these works focus on the textual content but ignore the appearance of web pages (e.g., the visual style, the layout, and the images), which are actually essential for information delivery. To alleviate this problem, we propose a new dense retrieval model, namely VILE, to incorporate visual features into document representations. However, because a web page is usually very large and contains diverse information, simply concatenating its textual and visual features may result in a cluttered multi-modal representation that lacks focus on the important parts of the page. We observe that web pages often have a structured content organization, comprising multiple blocks that convey different information. Motivated by the observation, we propose building a multi-modal document representation by aggregating the fine-grained multi-modal block representations, to enable a more comprehensive understanding of the page. Specifically, we first segment a web page into multiple blocks, then create multi-modal features for each block. %allowing for more effective capture of its content and visual information. The representations of all blocks are then integrated into the final multi-modal page representation. VILE can better model the importance of different content regions, leading to a high-quality multi-modal representation. We collect screenshots and the corresponding layout information of some web pages in the MS MARCO Document Ranking dataset, resulting in a new multi-modal document retrieval dataset. Experimental results conducted on this dataset demonstrate that our model exhibits significant improvements over existing document retrieval models. Our code is available at https://github.com/yhy-2000/VILE.|文献检索一直是网络搜索中的一个关键问题。最近的工作利用预训练语言模型来表示密集向量文档。然而，这些作品关注的是文本内容，而忽略了网页的外观(例如，视觉风格、布局和图像) ，这些实际上是信息传递所必需的。为了解决这一问题，我们提出了一种新的密集检索模型，即 VILE，将视觉特征融入到文档表示中。然而，由于一个网页通常非常大，并包含不同的信息，简单地连接其文本和视觉特征可能会导致一个混乱的多模态表示，缺乏重点页面的重要部分。我们观察到，网页通常有一个结构化内容的组织，由多个块组成，传达不同的信息。基于这种观察，我们提出通过聚合细粒度的多模态块表示来构建多模态文档表示，以便更全面地理解页面。具体来说，我们首先将网页分割成多个块，然后为每个块创建多模态特性。% ，以便更有效地捕捉其内容和视觉信息。然后将所有块的表示集成到最终的多模态页表示中。VILE 可以更好地为不同内容区域的重要性建模，从而实现高质量的多模态表示。我们收集了微软 MARCO 文件排名数据集中一些网页的截图和相应的布局信息，产生了一个新的多模式文献检索数据集。在这个数据集上进行的实验结果表明，我们的模型比现有的文献检索模型有显著的改进。我们的代码可以在 https://github.com/yhy-2000/vile 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=VILE:+Block-Aware+Visual+Enhanced+Document+Retrieval)|0|
|[MemoNet: Memorizing All Cross Features' Representations Efficiently via Multi-Hash Codebook Network for CTR Prediction](https://doi.org/10.1145/3583780.3614963)|Pengtao Zhang, Junlin Zhang|Sina Weibo, Beijing, China|New findings in natural language processing (NLP) demonstrate that the strong memorization capability contributes a lot to the success of Large Language Models (LLM). This inspires us to explicitly bring an independent memory mechanism into CTR ranking model to learn and memorize cross features' representations. In this paper, we propose multi-Hash Codebook NETwork (HCNet) as the memory mechanism for efficiently learning and memorizing representations of cross features in CTR tasks. HCNet uses a multi-hash codebook as the main memory place and the whole memory procedure consists of three phases: multi-hash addressing, memory restoring, and feature shrinking. We also propose a new CTR model named MemoNet which combines HCNet with a DNN backbone. Extensive experimental results on three public datasets and online test show that MemoNet reaches superior performance over state-of-the-art approaches. Besides, MemoNet shows scaling law of large language model in NLP, which means we can enlarge the size of the codebook in HCNet to sustainably obtain performance gains. Our work demonstrates the importance and feasibility of learning and memorizing representations of cross features, which sheds light on a new promising research direction. The source code is in https://github.com/ptzhangAlg/RecAlg.|自然语言处理(NLP)的新发现表明，强记忆能力对大语言模型(LLM)的成功有很大的贡献。这促使我们将独立的记忆机制明确地引入到 CTR 排名模型中，以便学习和记忆交叉特征的表示。本文提出了多哈希码书网络(HCNet)作为 CTR 任务中有效学习和记忆交叉特征表示的记忆机制。HCNet 使用多哈希码本作为主存储位置，整个存储过程由三个阶段组成: 多哈希寻址、存储恢复和特征收缩。我们还提出了一种新的 CTR 模型—— MemoNet，它将 HCNet 和 DNN 骨干网结合在一起。在三个公共数据集上的大量实验结果和在线测试表明，MemoNet 的性能优于最先进的方法。此外，MemoNet 在自然语言处理中显示了大语言模型的尺度规律，这意味着我们可以在 HCNet 中扩大码书的尺寸，以获得可持续的性能增益。我们的工作证明了学习和记忆交叉特征表征的重要性和可行性，这为一个新的有前途的研究方向指明了方向。源代码在 https://github.com/ptzhangalg/recalg 里。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MemoNet:+Memorizing+All+Cross+Features'+Representations+Efficiently+via+Multi-Hash+Codebook+Network+for+CTR+Prediction)|0|
|[FATA-Trans: Field And Time-Aware Transformer for Sequential Tabular Data](https://doi.org/10.1145/3583780.3614879)|Dongyu Zhang, Liang Wang, Xin Dai, Shubham Jain, Junpeng Wang, Yujie Fan, ChinChia Michael Yeh, Yan Zheng, Zhongfang Zhuang, Wei Zhang|Visa Research, Palo Alto, CA, USA; Worcester Polytechnic Institute, Worcester, MA, USA|Sequential tabular data is one of the most commonly used data types in real-world applications. Different from conventional tabular data, where rows in a table are independent, sequential tabular data contains rich contextual and sequential information, where some fields aredynamically changing over time and others arestatic. Existing transformer-based approaches analyzing sequential tabular data overlook the differences between dynamic and static fields by replicating and filling static fields into each record, and ignore temporal information between rows, which leads to three major disadvantages: (1) computational overhead, (2) artificially simplified data for masked language modeling pre-training task that may yield less meaningful representations, and (3) disregarding the temporal behavioral patterns implied by time intervals. In this work, we propose FATA-Trans, a model with two field transformers for modeling sequential tabular data, where each processes static and dynamic field information separately. FATA-Trans isfield - andtime -aware for sequential tabular data. Thefield -type embedding in the method enables FATA-Trans to capture differences between static and dynamic fields. Thetime -aware position embedding exploits both order and time interval information between rows, which helps the model detect underlying temporal behavior in a sequence. Our experiments on three benchmark datasets demonstrate that the learned representations from FATA-Trans consistently outperform state-of-the-art solutions in the downstream tasks. We also present visualization studies to highlight the insights captured by the learned representations, enhancing our understanding of the underlying data. Our codes are available at https://github.com/zdy93/FATA-Trans.|序列表数据是实际应用中最常用的数据类型之一。与传统的表格数据(表中的行是独立的)不同，顺序表格数据包含丰富的上下文和顺序信息，其中一些字段随时间动态变化，其他字段是静态的。现有的基于转换器的序列表格数据分析方法通过在每个记录中复制和填充静态字段忽略了动态字段和静态字段之间的差异，忽略了行之间的时间信息，这导致了三个主要的缺点: (1)计算开销，(2)人为地简化了掩蔽语言建模预训练任务的数据，这可能产生意义不大的表示，(3)忽略了时间间隔隐含的时间行为模式。在这项工作中，我们提出了 FATA-Trans 模型，一个有两个场变换器的模型用于建模顺序表格数据，其中每个场分别处理静态和动态的场信息。FATA-用于顺序表格数据的 Trans isfield-and time-aware。该方法中的字段类型嵌入使 FATA-Trans 能够捕获静态字段和动态字段之间的差异。时间感知位置嵌入利用行之间的顺序和时间间隔信息，帮助模型检测序列中潜在的时间行为。我们在三个基准数据集上的实验表明，FATA-Trans 的学习表示在下游任务中始终优于最先进的解决方案。我们还提出可视化研究，以突出所获得的见解表示，提高了我们对基础数据的理解。我们的代码可以在 https://github.com/zdy93/fata-trans 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FATA-Trans:+Field+And+Time-Aware+Transformer+for+Sequential+Tabular+Data)|0|
|[Efficient Exact Minimum k-Core Search in Real-World Graphs](https://doi.org/10.1145/3583780.3614861)|Qifan Zhang, Shengxin Liu|Harbin Institute of Technology, Shenzhen, Shenzhen, China|The k-core, which refers to the induced subgraph with a minimum degree of at least k, is widely used in cohesive subgraph discovery and has various applications. However, the k-core in real-world graphs tends to be extremely large, which hinders its effectiveness in practical applications. This challenge has motivated researchers to explore a variant of the k-core problem known as the minimum k-core search problem. This problem has been proven to be NP-Hard, and most of the existing studies naturally either deal with approximate solutions or suffer from inefficiency in practice. In this paper, we focus on designing efficient exact algorithms for the minimum k-core search problem. In particular, we develop an iterative-based framework that decomposes an instance of the minimum k-core search problem into a list of problem instances on another well-structured graph pattern. Based on this framework, we propose an iterative-based branch-and-bound algorithm, namely IBB, with additional pruning and reduction techniques. We show that, with a n-vertex graph, IBB runs in cn nO(1) time for some c < 2, achieving better theoretical performance than the trivial bound of 2n nO(1). Finally, our experiments on real-world graphs demonstrate that IBB is up to three orders of magnitude faster than the state-of-the-art algorithms on real-world datasets.|K 核是指至少 k 个最小度的诱导子图，广泛应用于内聚子图的发现，具有多种应用。然而，现实世界图中的 k 核往往非常大，这阻碍了它在实际应用中的有效性。这一挑战促使研究人员探索一种称为最小 k 核搜索问题的 k 核问题的变体。这个问题已经被证明是 NP 难的，现有的大多数研究要么自然地处理近似解，要么在实际应用中效率低下。本文主要研究最小 k 核搜索问题的高效精确算法设计。特别地，我们开发了一个基于迭代的框架，该框架将最小 k 核搜索问题的一个实例分解为另一个结构良好的图模式上的问题实例列表。在此框架的基础上，提出了一种基于迭代的分枝定界算法 IBB，该算法采用了附加的剪枝和约简技术。我们证明了，使用 n 个顶点图，IBB 在 cnnO (1)时间内运行一些 c < 2，比2nnO (1)的平凡界取得了更好的理论性能。最后，我们在真实世界图表上的实验表明，IBB 比现实世界数据集上的最先进算法快了三个数量级。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Exact+Minimum+k-Core+Search+in+Real-World+Graphs)|0|
|[Decentralized Graph Neural Network for Privacy-Preserving Recommendation](https://doi.org/10.1145/3583780.3614834)|Xiaolin Zheng, Zhongyu Wang, Chaochao Chen, Jiashu Qian, Yao Yang|Zhejiang Lab, Hangzhou, China; Zhejiang University, Hangzhou, China|Building a graph neural network (GNN)-based recommender system without violating user privacy proves challenging. Existing methods can be divided into federated GNNs and decentralized GNNs. But both methods have undesirable effects, i.e., low communication efficiency and privacy leakage. This paper proposes DGREC, a novel decentralized GNN for privacy-preserving recommendations, where users can choose to publicize their interactions. It includes three stages, i.e., graph construction, local gradient calculation, and global gradient passing. The first stage builds a local inner-item hypergraph for each user and a global inter-user graph. The second stage models user preference and calculates gradients on each local device. The third stage designs a local differential privacy mechanism named secure gradient-sharing, which proves strong privacy-preserving of users' private data. We conduct extensive experiments on three public datasets to validate the consistent superiority of our framework.|在不侵犯用户隐私的情况下构建一个基于图形神经网络(GNN)的推荐系统是具有挑战性的。现有的方法可以分为联邦 GNN 和分散 GNN。但这两种方法都存在通信效率低、隐私泄露等不良后果。本文提出了 DGREC，一种新型的用于隐私保护建议的分散式 GNN，用户可以选择在其中公开他们的交互。它包括图的构造、局部梯度计算和全局梯度传递三个阶段。第一阶段为每个用户构建一个本地内部项超图和一个全局用户间图。第二阶段建立用户偏好模型，并计算每个本地设备上的渐变。第三阶段设计了一种本地差分隐私机制——安全梯度共享机制，该机制对用户的私人数据具有很强的隐私保护能力。我们在三个公共数据集上进行了广泛的实验，以验证我们的框架的一致优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Decentralized+Graph+Neural+Network+for+Privacy-Preserving+Recommendation)|0|
|[FedPSE: Personalized Sparsification with Element-wise Aggregation for Federated Learning](https://doi.org/10.1145/3583780.3614882)|Longfei Zheng, Yingting Liu, Xiaolong Xu, Chaochao Chen, Yuzhou Tang, Lei Wang, Xiaolong Hu|; University of Science and Technology of China; Zhejiang University; University of Chinese Academy of Sciences; University of Hong Kong; Shanghai Jiaotong University|Federated learning (FL) is a popular distributed machine learning framework in which clients aggregate models' parameters instead of sharing their individual data. In FL, clients communicate with the server under limited network bandwidth frequently, which arises the communication challenge. To resolve this challenge, multiple compression methods have been proposed to reduce the transmitted parameters. However, these techniques show that the federated performance degrades significantly with Non-IID (non-identically independently distributed) datasets. To address this issue, we propose an effective method, called FedPSE, which solves the efficiency challenge of FL with heterogeneous data. FedPSE compresses the local updates on clients using Top-K sparsification and aggregates these updates on the server by element-wise average. Then clients download the personalized sparse updates from the server to update their individual local models. We then theoretically analyze the convergence of FedPSE under the non-convex setting. Moreover, extensive experiments on four benchmark tasks demonstrate that our FedPSE outperforms the state-of-the-art methods on Non-IID datasets in terms of both efficiency and accuracy.|联邦学习(FL)是一种流行的分布式机器学习框架，客户端聚合模型参数而不是共享个体数据。在 FL 中，客户端频繁地在有限的网络带宽下与服务器进行通信，这给通信带来了挑战。为了解决这一问题，人们提出了多种压缩方法来减少传输参数。但是，这些技术表明，使用 Non-IID (非相同独立分布的)数据集时，联邦性能会显著下降。为了解决这个问题，我们提出了一种有效的方法，称为 FedPSE，它解决了异构数据的 FL 的效率挑战。FedPSE 使用 Top-K 稀疏化压缩客户机上的本地更新，并按照元素的平均值聚合服务器上的这些更新。然后客户端从服务器下载个性化稀疏更新，以更新各自的本地模型。然后从理论上分析了 FedPSE 在非凸集下的收敛性。此外，在四个基准任务上的大量实验表明，我们的 FedPSE 在效率和准确性方面都优于非 IID 数据集上的最新方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FedPSE:+Personalized+Sparsification+with+Element-wise+Aggregation+for+Federated+Learning)|0|
|[Contrastive Counterfactual Learning for Causality-aware Interpretable Recommender Systems](https://doi.org/10.1145/3583780.3614823)|Guanglin Zhou, Chengkai Huang, Xiaocong Chen, Xiwei Xu, Chen Wang, Liming Zhu, Lina Yao|The University of New South Wales, Sydney, NSW, Australia; Data61, CSIRO, Eveleigh, Australia; Data61, CSIRO & The University of New South Wales, Eveleigh & Sydney, Australia|The field of generating recommendations within the framework of causal inference has seen a recent surge.This approach enhances insights into the influence of recommendations on user behavior and helps in identifying the underlying factors. Existing research has often leveraged propensity scores to mitigate bias, albeit at the risk of introducing additional variance. Others have explored the use of unbiased data from randomized controlled trials, although this comes with assumptions that may prove challenging in practice. In this paper, we first present the causality-aware interpretation of recommendations and reveal how the underlying exposure mechanism can bias the maximum likelihood estimation (MLE) of observational feedback. Recognizing that confounders may be elusive, we propose a contrastive self-supervised learning to minimize exposure bias, employing inverse propensity scores and expanding the positive sample set. Building on this foundation, we present a novel contrastive counterfactual learning method (CCL) that incorporates three unique positive sampling strategies grounded in estimated exposure probability or random counterfactual samples. Through extensive experiments on two real-world datasets, we demonstrate that our CCL outperforms the state-of-the-art methods.|在因果推理框架内提出建议的领域最近出现了激增。这种方法增强了对推荐对用户行为的影响的洞察力，并有助于识别潜在的因素。现有的研究经常利用倾向分数来减轻偏差，尽管有引入额外差异的风险。其他人已经探索了随机对照试验中无偏倚数据的使用，尽管这些假设在实践中可能被证明是具有挑战性的。在本文中，我们首先提出了因果关系意识的解释建议，并揭示了如何潜在的暴露机制可以偏差的最大似然估计(MLE)的观察反馈。认识到混杂因素可能是难以捉摸的，我们提出一个对比的自我监督学习，以尽量减少暴露偏差，使用逆倾向得分和扩大正样本集。在此基础上，我们提出了一种新的对比反事实学习方法(CCL) ，该方法结合了基于估计暴露概率或随机反事实样本的三种独特的正抽样策略。通过在两个实际数据集上的大量实验，我们证明了我们的 CCL 优于最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Counterfactual+Learning+for+Causality-aware+Interpretable+Recommender+Systems)|0|
|[Personalized Location-Preference Learning for Federated Task Assignment in Spatial Crowdsourcing](https://doi.org/10.1145/3583780.3615008)|Xiaolong Zhong, Hao Miao, Dazhuo Qiu, Yan Zhao, Kai Zheng|Aalborg University, Aalborg, Denmark; University of Electronic Science and Technology of China, Chengdu, China|With the proliferation of wireless and mobile devices, Spatial Crowdsourcing (SC) attracts increasing attention, where task assignment plays a critically important role. However, recent task assignment solutions in SC often assume that data is stored in a central station while ignoring the issue of privacy leakage. To enable decentralized training and privacy protection, we propose a federated task assignment framework with personalized location-preference learning, which performs efficient task assignment while keeping the data decentralized and private in each platform center (e.g., a delivery center of an SC company). The framework consists of two phases: personalized federated location-preference learning and task assignment. Specifically, in the first phase, we design a personalized location-preference learning model for each platform center by simultaneously considering the location information and data heterogeneity across platform centers. Based on workers' location preference, the task assignment phase aims to achieve effective and efficient task assignment by means of the Kuhn-Munkres (KM) algorithm and the newly proposed conditional degree-reduction algorithm. Extensive experiments on real-world data show the effectiveness of the proposed framework.|随着无线和移动设备的普及，空间众包越来越受到人们的关注，其中任务分配起着至关重要的作用。然而，最近 SC 中的任务分配解决方案往往假设数据存储在中央站，而忽略了隐私泄露问题。为了实现分散式训练和隐私保护，提出了一种基于个性化位置偏好学习的联邦任务分配框架，该框架在保持平台中心(如 SC 公司的交付中心)数据分散和私有的同时，实现了高效的任务分配。该框架包括两个阶段: 个性化联邦位置偏好学习和任务分配。具体来说，在第一阶段，我们同时考虑了平台中心之间的位置信息和数据异构性，为每个平台中心设计了一个个性化的位置偏好学习模型。任务分配阶段基于工人的位置偏好，采用 Kuhn-Munkres (KM)算法和新提出的条件降度算法实现高效的任务分配。对实际数据的大量实验表明了该框架的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Location-Preference+Learning+for+Federated+Task+Assignment+in+Spatial+Crowdsourcing)|0|
|[Improving Adversarial Transferability via Frequency-based Stationary Point Search](https://doi.org/10.1145/3583780.3614927)|Zhiyu Zhu, Huaming Chen, Jiayu Zhang, Xinyi Wang, Zhibo Jin, Qinghua Lu, Jun Shen, KimKwang Raymond Choo|The University of Sydney, Sydney, NSW, Australia; Suzhou Yierqi, Suzhou, China; University of Texas at San Antonio, San Antonio, TX, USA; Data61, CSIRO, Sydney, NSW, Australia; Jiangsu University, Zhenjiang, China; SCIT, University of Wollongong, Australia, Wollongong, Australia|Deep neural networks (DNNs) have been shown vulnerable to interference from adversarial samples, leading to erroneous predictions. Investigating adversarial attacks can effectively improve the reliability as well as the performance of deep neural models in real-world applications. Since it is generally challenging to infer the parameters in black-box models, high transferability becomes an important factor for the success rate of an attack method. Recently, the Spectrum Simulation Attack method exhibits promising results based on the frequency domain. In light of SSA, we propose a novel attack approach in this paper, which achieves the best results among diverse state-of-the-art transferable adversarial attack methods. Our method aims to find a stationary point, which extends the ability to find multiple local optima with the optimal local attack effect. After finding the stationary point, a frequency-based search is employed to explore the best adversarial samples in the neighbouring space, utilmately determining the final adversarial direction. We compare our method against a variety of cutting-edge transferable adversarial methods. Extensive experiments validate that our method improves the attack success rate by 4.7% for conventionally trained models and 53.1% for adversarially trained models. Our code is available at https://github.com/LMBTough/FSPS|深层神经网络(DNN)已被证明易受敌对样本的干扰，从而导致错误的预测。研究对手攻击可以有效地提高深度神经网络模型在现实应用中的可靠性和性能。由于黑盒模型中的参数推断通常具有挑战性，因此高可转移性成为影响攻击方法成功率的一个重要因素。近年来，基于频域的频谱仿真攻击方法取得了很好的效果。针对 SSA 的特点，本文提出了一种新的攻击方法，在各种最新的可转移对手攻击方法中取得了最好的效果。我们的方法的目标是找到一个驻点，扩展了寻找具有最佳局部攻击效果的多个局部最优解的能力。在找到驻点后，使用基于频率的搜索来探索邻近空间中最好的对手样本，最终确定最终的对手方向。我们将我们的方法与各种尖端的可转移的对抗性方法进行比较。大量的实验验证了该方法对传统训练模型的攻击成功率提高了4.7% ，对对抗训练模型的攻击成功率提高了53.1% 。我们的代码可以在 https://github.com/lmbtough/fsps 找到|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Adversarial+Transferability+via+Frequency-based+Stationary+Point+Search)|0|
|[Counterfactual Graph Augmentation for Consumer Unfairness Mitigation in Recommender Systems](https://doi.org/10.1145/3583780.3615165)|Ludovico Boratto, Francesco Fabbri, Gianni Fenu, Mirko Marras, Giacomo Medda|University of Cagliari, Cagliari, Italy; Spotify, Barcelona, Spain|In recommendation literature, explainability and fairness are becoming two prominent perspectives to consider. However, prior works have mostly addressed them separately, for instance by explaining to consumers why a certain item was recommended or mitigating disparate impacts in recommendation utility. None of them has leveraged explainability techniques to inform unfairness mitigation. In this paper, we propose an approach that relies on counterfactual explanations to augment the set of user-item interactions, such that using them while inferring recommendations leads to fairer outcomes. Modeling user-item interactions as a bipartite graph, our approach augments the latter by identifying new user-item edges that not only can explain the original unfairness by design, but can also mitigate it. Experiments on two public data sets show that our approach effectively leads to a better trade-off between fairness and recommendation utility compared with state-of-the-art mitigation procedures. We further analyze the characteristics of added edges to highlight key unfairness patterns. Source code available at https://github.com/jackmedda/RS-BGExplainer/tree/cikm2023.|在推荐文献中，可解释性和公平性正成为两个需要考虑的重要方面。然而，以前的工作大多是单独处理这些问题，例如向消费者解释为什么要推荐某个项目，或者减轻推荐实用程序中的不同影响。它们都没有利用可解释性技术来缓解不公平性。在本文中，我们提出了一种方法，依赖于反事实的解释，以增加用户项目的交互集，使用他们，而推断建议导致更公平的结果。将用户-项目交互建模为二分图，我们的方法通过识别新的用户-项目边缘来扩展后者，这些边缘不仅可以通过设计来解释原始的不公平，而且还可以减轻它。在两个公共数据集上的实验表明，与最先进的缓解过程相比，我们的方法有效地在公平性和推荐效用之间取得了更好的平衡。我们进一步分析了附加边缘的特征，以突出关键的不公平模式。源代码可在 https://github.com/jackmedda/rs-bgexplainer/tree/cikm2023下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Counterfactual+Graph+Augmentation+for+Consumer+Unfairness+Mitigation+in+Recommender+Systems)|0|
|[Region-Wise Attentive Multi-View Representation Learning For Urban Region Embedding](https://doi.org/10.1145/3583780.3615194)|Weiliang Chan, Qianqian Ren||Urban region embedding is an important and yet highly challenging issue due to the complexity and constantly changing nature of urban data. To address the challenges, we propose a Region-Wise Multi-View Representation Learning (ROMER) to capture multi-view dependencies and learn expressive representations of urban regions without the constraints of rigid neighbourhood region conditions. Our model focus on learn urban region representation from multi-source urban data. First, we capture the multi-view correlations from mobility flow patterns, POI semantics and check-in dynamics. Then, we adopt global graph attention networks to learn similarity of any two vertices in graphs. To comprehensively consider and share features of multiple views, a two-stage fusion module is further proposed to learn weights with external attention to fuse multi-view embeddings. Extensive experiments for two downstream tasks on real-world datasets demonstrate that our model outperforms state-of-the-art methods by up to 17\% improvement.|由于城市数据的复杂性和不断变化的性质，城市区域嵌入是一个重要而又极具挑战性的问题。为了应对这些挑战，我们提出了一种区域智能多视图表示学习(ROMER)方法来捕获多视图依赖关系，并在不受严格的邻近区域条件约束的情况下学习城市地区的表示。我们的模型侧重于从多源城市数据中学习城市区域表示。首先，我们从移动流模式、 POI 语义和签入动态中获取多视图相关性。然后，我们采用全局图注意网络来学习图中任意两个顶点的相似性。为了综合考虑和共享多视图的特征，进一步提出了一个两阶段融合模块，该模块通过学习权值和外部注意力来融合多视图嵌入。对真实世界数据集上的两个下游任务进行的大量实验表明，我们的模型比最先进的方法提高了17% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Region-Wise+Attentive+Multi-View+Representation+Learning+For+Urban+Region+Embedding)|0|
|['Choose your Data Wisely': Active Learning based Selection with Multi-Objective Optimisation for Mitigating Stereotypes](https://doi.org/10.1145/3583780.3615261)|Manish Chandra, Debasis Ganguly, Tulika Saha, Iadh Ounis|University of Glasgow, Glasgow, United Kingdom; University of Liverpool, Liverpool, United Kingdom|Data-driven (deep) learning methods has led to parameterised abstractions of the data, often leading to stereotype societal biases in their predictions, e.g., predicting more frequently that women are weaker than men, or that African Americans are more likely to commit crimes than Caucasians. Standard approaches of mitigating such stereotypical biases from deep neural models include modifying the training dataset (pre-processing), or adjusting the model parameters with a bias-specific objective (in-processing). In our work, we approach this bias mitigation from a different perspective - that of an active learning-based selection of a subset of data instances towards training a model optimised for both effectiveness and fairness. Specifically speaking, the imbalances in the attribute value priors can be alleviated by constructing a balanced subset of the data instances with two selection objectives - first, of improving the model confidence of the primary task itself (a standard practice in active learning), and the second, of taking into account the parity of the model predictions with respect to the sensitive attributes, such as gender and race etc. We demonstrate that our proposed selection function achieves better results in terms of both the primary task effectiveness and fairness. The results are further shown to improve when this active learning-based data selection is combined with an in-process method of multi-objective training.|数据驱动(深度)学习方法已经导致数据的参数化抽象，往往导致他们的预测中的刻板的社会偏见，例如，更频繁地预测女性比男性弱，或非裔美国人比白种人更有可能犯罪。从深度神经模型中减轻这种定型偏差的标准方法包括修改训练数据集(预处理) ，或者用偏差特定的目标(在处理中)调整模型参数。在我们的工作中，我们从一个不同的角度来处理这种偏差缓解-这是一个积极的基于学习的选择一个子集的数据实例，以训练一个模型优化的有效性和公平性。具体来说，可以通过构建一个具有两个选择目标的数据实例的平衡子集来缓解属性值先验的不平衡——第一，提高主要任务本身的模型置信度(主动学习的标准实践) ，第二，考虑模型预测相对于敏感属性的平等性，如性别和种族等。实验结果表明，本文提出的选择函数在主要任务有效性和公平性方面都取得了较好的效果。结果进一步表明，当这种基于主动学习的数据选择与过程中的多目标训练方法相结合时，结果得到了改善。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q='Choose+your+Data+Wisely':+Active+Learning+based+Selection+with+Multi-Objective+Optimisation+for+Mitigating+Stereotypes)|0|
|[MI-DPG: Decomposable Parameter Generation Network Based on Mutual Information for Multi-Scenario Recommendation](https://doi.org/10.1145/3583780.3615223)|Wenzhuo Cheng, Ke Ding, Xin Dong, Yong He, Liang Zhang, Linjian Mo|Ant Group, Shanghai, China; Ant Group, Hangzhou, China|Conversion rate (CVR) prediction models play a vital role in recommendation systems. Recent research shows that learning a unified model to serve multiple scenarios is effective for improving overall performance. However, it remains challenging to improve model prediction performance across scenarios at low model parameter cost, and current solutions are hard to robustly model multi-scenario diversity. In this paper, we propose MI-DPG for the multi-scenario CVR prediction, which learns scenario-conditioned dynamic model parameters for each scenario in a more efficient and effective manner. Specifically, we introduce an auxiliary network to generate scenario-conditioned dynamic weighting matrices, which are obtained by combining decomposed scenario-specific and scenario-shared low-rank matrices with parameter efficiency. For each scenario, weighting the backbone model parameters by the weighting matrix helps to specialize the model parameters for different scenarios. It can not only modulate the complete parameter space of the backbone model but also improve the model effectiveness. Furthermore, we design a mutual information regularization to enhance the diversity of model parameters across scenarios by maximizing the mutual information between the scenario-aware input and the scenario-conditioned dynamic weighting matrix. Experiments from three real-world datasets show that MI-DPG outperforms previous multi-scenario recommendation models.|转化率(CVR)预测模型在推荐系统中起着至关重要的作用。最近的研究表明，学习一个统一的模型来服务于多种场景对于提高整体性能是有效的。然而，在模型参数成本较低的情景下提高模型预测性能仍然是一个挑战，目前的解决方案难以对多情景多样性进行稳健的模型建模。本文提出了多情景 CVR 预测的 MI-DPG 方法，该方法能够更有效地学习每个情景的情景条件动态模型参数。具体地说，我们引入了一个辅助网络来生成情景条件下的动态权重矩阵，这些权重矩阵是通过将分解的情景特定的和情景共享的低秩矩阵与参数有效性相结合而得到的。对于每个场景，通过加权矩阵对骨干模型参数进行加权，有助于为不同场景专门化模型参数。它不仅可以调节骨干模型的完整参数空间，而且可以提高模型的有效性。此外，我们设计了一个互信息正则化方案，通过最大化情景感知输入和情景条件下的动态加权矩阵之间的互信息来增强不同情景下模型参数的多样性。通过对三个实际数据集的实验表明，MI-DPG 的性能优于以往的多场景推荐模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MI-DPG:+Decomposable+Parameter+Generation+Network+Based+on+Mutual+Information+for+Multi-Scenario+Recommendation)|0|
|[Incorporating Co-purchase Correlation for Next-basket Recommendation](https://doi.org/10.1145/3583780.3615257)|Yu Hao Chou, PuJen Cheng|National Taiwan University, Taipei, Taiwan Roc|Next-basket recommendation (NBR) aims to recommend a set of items that users would most likely purchase together. Existing approaches use deep learning to capture basket-level preference and traditional statistical methods to model user behavior sequences. However, these methods neglect the correlation of co-purchase items among users. We, therefore, propose a novel model that incorporates Co-purchase Correlation with Bidirectional Transformer (CCBT) to enhance item representation by exploiting the correlation among users' baskets. The results of experiments conducted on four real-world datasets demonstrate the proposed model outperforms state-of-the-art NBR methods. The relative improvement for Recall@20 ranges from 11% to 27%.|下一篮子推荐(NBR)旨在推荐一组用户最有可能一起购买的商品。现有的方法使用深度学习来捕获篮子级别的偏好，使用传统的统计方法来建模用户行为序列。然而，这些方法忽略了用户之间共同购买项目的相关性。因此，我们提出了一个新的模型，结合双向变压器(CCBT)的共同购买相关性，以提高项目表示的利用用户篮之间的相关性。在四个实际数据集上进行的实验结果表明，该模型的性能优于目前最先进的 NBR 方法。召回@20的相对改善幅度从11% 到27% 不等。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Incorporating+Co-purchase+Correlation+for+Next-basket+Recommendation)|0|
|[DPAN: Dynamic Preference-based and Attribute-aware Network for Relevant Recommendations](https://doi.org/10.1145/3583780.3615218)|Wei Dai, Yingmin Su, Xiaofeng Pan, Yufeng Wang, Zhenyu Zhu, Nan Xu, Chengjun Mao, Bo Cao||In e-commerce platforms, the relevant recommendation is a unique scenario providing related items for a trigger item that users are interested in. However, users' preferences for the similarity and diversity of recommendation results are dynamic and vary under different conditions. Moreover, individual item-level diversity is too coarse-grained since all recommended items are related to the trigger item. Thus, the two main challenges are to learn fine-grained representations of similarity and diversity and capture users' dynamic preferences for them under different conditions. To address these challenges, we propose a novel method called the Dynamic Preference-based and Attribute-aware Network (DPAN) for predicting Click-Through Rate (CTR) in relevant recommendations. Specifically, based on Attribute-aware Activation Values Generation (AAVG), Bi-dimensional Compression-based Re-expression (BCR) is designed to obtain similarity and diversity representations of user interests and item information. Then Shallow and Deep Union-based Fusion (SDUF) is proposed to capture users' dynamic preferences for the diverse degree of recommendation results according to various conditions. DPAN has demonstrated its effectiveness through extensive offline experiments and online A/B testing, resulting in a significant 7.62% improvement in CTR. Currently, DPAN has been successfully deployed on our e-commerce platform serving the primary traffic for relevant recommendations. The code of DPAN has been made publicly available.|在电子商务平台中，相关建议是为用户感兴趣的触发项目提供相关项目的独特场景。然而，用户对推荐结果的相似性和多样性的偏好是动态的，并且在不同的条件下会有所不同。此外，由于所有推荐的项目都与触发项目相关，因此单个项目级别的多样性过于粗粒度。因此，两个主要的挑战是学习相似性和多样性的细粒度表示，并捕获用户在不同条件下的动态偏好。为了应对这些挑战，我们提出了一种新的方法，称为基于动态偏好和属性感知网络(dpAN) ，用于预测相关建议中的点进率。在基于属性感知的激活值生成(AAVG)方法的基础上，设计了基于二维压缩的重新表达(BCR)方法来获得用户兴趣和项目信息的相似性和多样性表示。然后提出了基于浅联盟和深联盟的融合方法(SDUF) ，根据不同的条件获取用户对不同程度推荐结果的动态偏好。DPAN 通过大量的离线实验和在线 A/B 测试证明了其有效性，使 CTR 显著提高了7.62% 。目前，DPAN 已成功应用于我们的电子商务平台，为主要流量提供相关建议。DPAN 的代码已经向公众开放。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DPAN:+Dynamic+Preference-based+and+Attribute-aware+Network+for+Relevant+Recommendations)|0|
|[Learning Sparse Lexical Representations Over Specified Vocabularies for Retrieval](https://doi.org/10.1145/3583780.3615207)|Jeffrey M. Dudek, Weize Kong, Cheng Li, Mingyang Zhang, Michael Bendersky|Google Research, Mountain View, CA, USA|A recent line of work in first-stage Neural Information Retrieval has focused on learning sparse lexical representations instead of dense embeddings. One such work is SPLADE, which has been shown to lead to state-of-the-art results in both the in-domain and zero-shot settings, can leverage inverted indices for efficient retrieval, and offers enhanced interpretability. However, existing SPLADE models are fundamentally limited to learning a sparse representation based on the native BERT WordPiece vocabulary. In this work, we extend SPLADE to support learning sparse representations over arbitrary sets of tokens to improve flexibility and aid integration with existing retrieval systems. As an illustrative example, we focus on learning a sparse representation over a large (300k) set of unigrams. We add an unsupervised pretraining task on C4 to learn internal representations for new tokens. Our experiments show that our Expanded-SPLADE model maintains the performance of WordPiece-SPLADE on both in-domain and zero-shot retrieval while allowing for custom output vocabularies.|最近，第一阶段神经信息检索的工作重点是学习稀疏的词汇表征，而不是密集的嵌入。SPLADE 就是这样一个工作，它已经被证明可以在领域内和零拍摄设置中获得最先进的结果，可以利用反向索引进行有效的检索，并且提供了增强的可解释性。然而，现有的 SPLADE 模型基本上仅限于学习基于本地 BERT WordPiece 词汇表的稀疏表示。在这项工作中，我们扩展了 SPLADE 来支持对任意标记集的稀疏表示学习，以提高灵活性并帮助与现有检索系统的集成。作为一个说明性的例子，我们关注于在一个大的(300k) Unigram 集合上学习稀疏表示。我们在 C4上添加一个无监督的预训练任务来学习新标记的内部表示。我们的实验表明，我们的扩展 SPLADE 模型保持了 WordPiece-SPLADE 在域内和零镜头检索方面的性能，同时允许自定义输出词汇表。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Sparse+Lexical+Representations+Over+Specified+Vocabularies+for+Retrieval)|0|
|[KGPR: Knowledge Graph Enhanced Passage Ranking](https://doi.org/10.1145/3583780.3615252)|Jinyuan Fang, Zaiqiao Meng, Craig Macdonald|University of Glasgow, Glasgow, United Kingdom|Passage ranking aims to rank a set of passages based on their relevance to a query. Current state-of-the-art models for this task typically employ a cross-encoder structure. However, these models lack access to background knowledge, i.e., information related to the query that can be helpful in retrieving relevant passages. Knowledge Graphs (KGs) provide a structured way of storing information about entities and their relationships, offering valuable background knowledge about entities. While KGs have been used to augment pretrained language models (LMs) to perform several reasoning tasks such as question answering, it remains an open question of how to utilise the information from KGs to enhance the performance of cross-encoders on the passage ranking task. Therefore, we propose KGPR, a KG-enhanced cross-encoder for the Passage Retrieval task. KGPR is built upon LUKE, an entity-aware pretrained LM, with an additional module that fuses information from KGs into LUKE. By leveraging the background knowledge from KGs, KGPR enhances the model's comprehension of queries and passages, resulting in improved ranking performance. Experimental results demonstrate that using KGs can enhance the performance of LUKE in the passage retrieval task, and KGPR can outperform state-of-the-art monoT5 cross-encoder by 3.32% and 10.77% on the MS MARCO development set and TREC DL-HARD query set respectively, using a model with a similar number of parameters.|短文排名的目的是根据一组短文与查询的相关性对它们进行排名。当前用于此任务的最先进模型通常采用交叉编码器结构。然而，这些模型缺乏对背景知识的访问，即与查询相关的信息，这些信息有助于检索相关段落。知识图(KGs)提供了一种结构化的方式来存储有关实体及其关系的信息，并提供有关实体的有价值的背景知识。虽然幼稚园已被用来增加预先训练的语言模型，以执行多项推理任务，例如问题回答，但如何利用幼稚园提供的资料，以提高交叉编码器在短文排名任务中的表现，仍然是一个悬而未决的问题。因此，我们提出 KGPR，一个 KG 增强的交叉编码器的通道检索任务。KGPR 建立在 LUKE 之上，这是一个实体感知的预训练 LM，还有一个附加的模块，将来自 KGs 的信息融合到 LUKE 中。通过利用来自 KG 的背景知识，KGPR 增强了模型对查询和段落的理解，从而提高了排名性能。实验结果表明，在文章检索任务中使用 KGs 可以提高 LUKE 的性能，在参数相似的模型下，KGPR 在 MS MARCO 开发集和 TREC DL-HARD 查询集上的性能分别比单 T5交叉编码器的性能提高3.32% 和10.77% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KGPR:+Knowledge+Graph+Enhanced+Passage+Ranking)|0|
|[Multi-step Prompting for Few-shot Emotion-Grounded Conversations](https://doi.org/10.1145/3583780.3615265)|Mauzama Firdaus, Gopendra Vikram Singh, Asif Ekbal, Pushpak Bhattacharyya|IIT Patna, Patna, India; University of Alberta, Edmonton, AB, Canada; IIT Bombay, Maharashtra, India|Conversational systems have shown immense growth in their ability to communicate like humans. With the emergence of large pre-trained language models (PLMs) the ability to provide informative responses have improved significantly. Despite the success of PLMs, the ability to identify and generate engaging and empathetic responses is largely dependent on labelled-data. In this work, we design a prompting approach that identifies the emotion of a given utterance and uses the emotion information for generating the appropriate responses for conversational systems. We propose a two-step prompting method that first recognises the emotion in the dialogue utterance and in the second-step uses the predicted emotion to prompt the PLM to generate the corresponding em- pathetic response in a few-shot setting. Experimental results on three publicly available datasets show that our proposed approach outperforms the state-of-the-art approaches for both automatic and manual evaluation.|会话系统已经显示出它们像人类一样交流能力的巨大增长。随着大型预训练语言模型(PLM)的出现，提供信息反馈的能力得到了显著提高。尽管 PLM 取得了成功，但是识别和产生引人入胜和富有同情心的反应的能力在很大程度上依赖于标记数据。在这项工作中，我们设计了一个提示方法，识别一个给定的话语的情绪，并利用情绪信息产生适当的反应的会话系统。我们提出了一种两步提示方法，首先在对话中识别情绪，然后在第二步利用预测的情绪提示 PLM 产生相应的情感反应。在三个公开数据集上的实验结果表明，我们提出的方法在自动和手动评估方面都优于最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-step+Prompting+for+Few-shot+Emotion-Grounded+Conversations)|0|
|[Extracting Methodology Components from AI Research Papers: A Data-driven Factored Sequence Labeling Approach](https://doi.org/10.1145/3583780.3615258)|Madhusudan Ghosh, Debasis Ganguly, Partha Basuchowdhuri, Sudip Kumar Naskar|University of Glasgow, Glasgow, United Kingdom; Indian Association for the Cultivation of Science, Kolkata, India; Dept. of Computer Science & Engineering, Jadavpur University, India, Kolkata, India|Extraction of methodology component names from scientific articles is a challenging task due to the diversified contexts around the occurrences of these entities, and the different levels of granularity and containment relationships exhibited by these entities. We hypothesize that standard sequence labeling approaches may not adequately model the dependence of methodology name mentions with their contexts, due to the problems of their large, fast evolving, and domain-specific vocabulary. As a solution, we propose a factored approach, where the mention-context dependencies are represented in a more fine-grained manner, thus allowing the model parameters to better adjust to the different characteristic patterns inherent within the data. In particular, we experiment with two variants of this factored approach - one that uses the per-entity category information derived from an ontology, and the other that makes use of the topology of the sentence embedding space to infer a category for each entity constituting that sentence. We demonstrate that both these factored variants of SciBERT outperform their non-factored counterpart, a state-of-the-art model for scientific concept extraction.|从科技论文中提取方法论组件名称是一项具有挑战性的任务，因为这些实体出现的背景多种多样，而且这些实体表现出不同层次的粒度和包含关系。我们假设，标准的序列标签方法可能不能充分模拟方法名称提及与其上下文的依赖性，由于它们的大型，快速发展和领域特定的词汇表的问题。作为一种解决方案，我们提出了一种分因式方法，其中提及上下文依赖关系以更细粒度的方式表示，从而允许模型参数更好地调整以适应数据中固有的不同特征模式。具体来说，我们用这种因素分析方法的两种变体进行了实验——一种使用从本体派生出来的每个实体的类别信息，另一种使用句子嵌入空间的拓扑结构来推断构成该句子的每个实体的类别。我们证明 SciBERT 的这两个因子变体都优于它们的非因子变体，后者是科学概念提取的最先进模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Extracting+Methodology+Components+from+AI+Research+Papers:+A+Data-driven+Factored+Sequence+Labeling+Approach)|0|
|[Lightweight Adaptation of Neural Language Models via Subspace Embedding](https://doi.org/10.1145/3583780.3615269)|Amit Kumar Jaiswal, Haiming Liu|University of Surrey, Guildford, United Kingdom; University of Southampton, Southampton, United Kingdom|Traditional neural word embeddings are usually dependent on a richer diversity of vocabulary. However, the language models recline to cover major vocabularies via the word embedding parameters, in particular, for multilingual language models that generally cover a significant part of their overall learning parameters. In this work, we present a new compact embedding structure to reduce the memory footprint of the pre-trained language models with a sacrifice of up to 4% absolute accuracy. The embeddings vectors reconstruction follows a set of subspace embeddings and an assignment procedure via the contextual relationship among tokens from pre-trained language models. The subspace embedding structure calibrates to masked language models, to evaluate our compact embedding structure on similarity and textual entailment tasks, sentence and paraphrase tasks. Our experimental evaluation shows that the subspace embeddings achieve compression rates beyond 99.8% in comparison with the original embeddings for the language models on XNLI and GLUE benchmark suites.|传统的神经词汇嵌入通常依赖于更丰富的词汇多样性。然而，语言模型通过单词嵌入参数覆盖了主要词汇，特别是多语言语言模型通常覆盖了其总体学习参数的很大一部分。在这项工作中，我们提出了一个新的紧凑的嵌入结构，以减少预训练的语言模型的内存占用，高达4% 的绝对准确率的牺牲。嵌入向量重构遵循一组子空间嵌入和一个赋值过程，通过预训练语言模型中标记之间的上下文关系实现。子空间嵌入结构校准到掩盖语言模型，评估我们紧凑的嵌入结构的相似性和文字蕴涵任务，句子和释义任务。实验结果表明，与基于 XNLI 和 GLUE 基准测试套件的语言模型原始嵌入相比，子空间嵌入的压缩率达到了99.8% 以上。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Lightweight+Adaptation+of+Neural+Language+Models+via+Subspace+Embedding)|0|
|[Multi-Granularity Attention Model for Group Recommendation](https://doi.org/10.1145/3583780.3615140)|Jianye Ji, Jiayan Pei, Shaochuan Lin, Taotao Zhou, Hengxu He, Jia Jia, Ning Hu|Alibaba Group, Shanghai, China; Alibaba Group, Hangzhou, China|Group recommendation provides personalized recommendations to a group of users based on their shared interests, preferences, and characteristics. Current studies have explored different methods for integrating individual preferences and making collective decisions that benefit the group as a whole. However, most of them heavily rely on users with rich behavior and ignore latent preferences of users with relatively sparse behavior, leading to insufficient learning of individual interests. To address this challenge, we present the Multi-Granularity Attention Model (MGAM), a novel approach that utilizes multiple levels of granularity (i.e., subsets, groups, and supersets) to uncover group members' latent preferences and mitigate recommendation noise. Specially, we propose a Subset Preference Extraction module that enhances the representation of users' latent subset-level preferences by incorporating their previous interactions with items and utilizing a hierarchical mechanism. Additionally, our method introduces a Group Preference Extraction module and a Superset Preference Extraction module, which explore users' latent preferences on two levels: the group-level, which maintains users' original preferences, and the superset-level, which includes group-group exterior information. By incorporating the subset-level embedding, group-level embedding, and superset-level embedding, our proposed method effectively reduces group recommendation noise across multiple granularities and comprehensively learns individual interests. Extensive offline and online experiments have demonstrated the superiority of our method in terms of performance.|群组推荐根据用户的共同兴趣、偏好和特征，向用户群体提供个性化的推荐。目前的研究探索了整合个人偏好和做出有利于整个群体的集体决策的不同方法。然而，它们大多严重依赖于行为丰富的用户，忽视了行为相对稀疏的用户的潜在偏好，导致个体兴趣学习不足。为了解决这一挑战，我们提出了多粒度注意力模型(MGAM) ，这是一种利用多个粒度级别(即子集，组和超集)来揭示组成员的潜在偏好并减轻推荐噪音的新方法。特别地，我们提出了一个子集偏好提取模块，该模块通过合并用户以前与项目的交互并利用层次化机制来增强用户潜在子集级偏好的表示。此外，该方法还引入了群组偏好提取模块和超集偏好提取模块，分别从两个层次探索用户的潜在偏好: 保持用户原始偏好的群组层次和包含群组外部信息的超集层次。该方法融合了子集级嵌入、组级嵌入和超集级嵌入，有效地降低了跨多个粒度的群推荐噪声，全面地学习了个人兴趣。大量的离线和在线实验已经证明了我们的方法在性能方面的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Granularity+Attention+Model+for+Group+Recommendation)|0|
|[CSPM: A Contrastive Spatiotemporal Preference Model for CTR Prediction in On-Demand Food Delivery Services](https://doi.org/10.1145/3583780.3615239)|Guyu Jiang, Xiaoyun Li, Rongrong Jing, Ruoqi Zhao, Xingliang Ni, Guodong Cao, Ning Hu||Click-through rate (CTR) prediction is a crucial task in the context of an online on-demand food delivery (OFD) platform for precisely estimating the probability of a user clicking on food items. Unlike universal e-commerce platforms such as Taobao and Amazon, user behaviors and interests on the OFD platform are more location and time-sensitive due to limited delivery ranges and regional commodity supplies. However, existing CTR prediction algorithms in OFD scenarios concentrate on capturing interest from historical behavior sequences, which fails to effectively model the complex spatiotemporal information within features, leading to poor performance. To address this challenge, this paper introduces the Contrastive Sres under different search states using three modules: contrastive spatiotemporal representation learning (CSRL), spatiotemporal preference extractor (StPE), and spatiotemporal information filter (StIF). CSRL utilizes a contrastive learning framework to generate a spatiotemporal activation representation (SAR) for the search action. StPE employs SAR to activate users' diverse preferences related to location and time from the historical behavior sequence field, using a multi-head attention mechanism. StIF incorporates SAR into a gating network to automatically capture important features with latent spatiotemporal effects. Extensive experiments conducted on two large-scale industrial datasets demonstrate the state-of-the-art performance of CSPM. Notably, CSPM has been successfully deployed in Alibaba's online OFD platform Ele.me, resulting in a significant 0.88% lift in CTR, which has substantial business implications.|点进率预测是网上按需供应食物平台的一项重要工作，目的是准确估计使用者点击食物项目的机会。与淘宝和亚马逊等通用电子商务平台不同，OFD 平台上的用户行为和兴趣更具地点和时间敏感性，因为交付范围和区域性商品供应有限。然而，现有的 OFD 场景下的 CTR 预测算法主要集中于从历史行为序列中获取兴趣，未能有效地模拟特征中复杂的时空信息，导致性能较差。为了解决这一问题，本文使用了三个模块: 对比时空表示学习(CSRL)、时空偏好提取器(StPE)和时空信息过滤器(StIF) ，介绍了不同搜索状态下的对比 Sres。CSRL 利用对比学习框架生成搜索动作的时空激活表示(SAR)。STPE 利用多头注意机制，从历史行为序列场中激活用户与位置和时间相关的多样化偏好。STIF 将合成孔径雷达(SAR)与门控网络相结合，自动捕获具有潜在时空效应的重要特征。在两个大规模工业数据集上进行的大量实验证明了 CSPM 的最新性能。值得注意的是，cSPM 已成功部署在阿里巴巴的在线 OFD 平台 Ele.me 上，使点击率大幅提高了0.88% ，这对商业具有重大意义。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CSPM:+A+Contrastive+Spatiotemporal+Preference+Model+for+CTR+Prediction+in+On-Demand+Food+Delivery+Services)|0|
|[MvFS: Multi-view Feature Selection for Recommender System](https://doi.org/10.1145/3583780.3615243)|Youngjune Lee, Yeongjong Jeong, Keunchan Park, SeongKu Kang|NAVER Corporation, Seongnam, Republic of Korea; University of Illinois at Urbana-Champaign, Urbana, IL, USA|Feature selection, which is a technique to select key features in recommender systems, has received increasing research attention. Recently, Adaptive Feature Selection (AdaFS) has shown remarkable performance by adaptively selecting features for each data instance, considering that the importance of a given feature field can vary significantly across data. However, this method still has limitations in that its selection process could be easily biased to major features that frequently occur. To address these problems, we propose Multi-view Feature Selection (MvFS), which selects informative features for each instance more effectively. Most importantly, MvFS employs a multi-view network consisting of multiple sub-networks, each of which learns to measure the feature importance of a part of data with different feature patterns. By doing so, MvFS promotes a more balanced feature selection process mitigating the bias problem towards dominant patterns. Moreover, MvFS adopts an effective importance score modeling strategy which is applied independently to each field without incurring dependency among features. Experimental results on real-world datasets demonstrate the effectiveness of MvFS compared to state-of-the-art baselines.|特征选择作为推荐系统中的一种关键特征选择技术，越来越受到研究者的重视。最近，自适应特征选择(AdaFS)通过为每个数据实例自适应地选择特征来表现出显著的性能，考虑到给定特征字段的重要性在不同数据之间可能有显著的差异。然而，这种方法仍然有局限性，因为它的选择过程很容易偏向于频繁出现的主要特征。为了解决这些问题，我们提出了多视图特征选择(MvFS) ，它能够更有效地为每个实例选择信息特征。最重要的是，MvFS 使用一个由多个子网络组成的多视图网络，每个子网络学习测量具有不同特征模式的部分数据的特征重要性。通过这样做，MvFS 促进了一个更加平衡的特征选择过程，减轻了对主导模式的偏见问题。此外，MvFS 采用了一种有效的重要性评分建模策略，该策略可以独立地应用于各个领域，不会引起特征之间的依赖性。在真实世界数据集上的实验结果表明，与最先进的基线相比，MvFS 是有效的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MvFS:+Multi-view+Feature+Selection+for+Recommender+System)|0|
|[HEPT Attack: Heuristic Perpendicular Trial for Hard-label Attacks under Limited Query Budgets](https://doi.org/10.1145/3583780.3615198)|Qi Li, Xingyu Li, Xiaodong Cui, Keke Tang, Peican Zhu|Northwestern Polytechnical University, Xi'an, China; University of Alberta, Edmonton, AB, Canada; Guangzhou University, Guangzhou, China; National University of Singapore, Singapore, Singapore|Exploring adversarial attacks on deep neural networks (DNNs) is crucial for assessing and enhancing their adversarial robustness. Among various attack types, hard-label attacks that rely only on predicted labels offer a practical approach. This paper focuses on the challenging task of hard-label attacks within an extremely limited query budget, which is a significant achievement rarely accomplished by existing methods. To tackle this, we propose an attack framework that leverages geometric information from previous perturbation directions to form triangles and employs a heuristic perpendicular trial to effectively utilize the intermediate directions. Extensive experiments validate the effectiveness of our approach under strict query constraints and demonstrate its superiority to the state-of-the-art methods.|研究深层神经网络(DNN)的对抗性攻击对于评估和增强其对抗性鲁棒性至关重要。在各种攻击类型中，只依赖于预测标签的硬标签攻击提供了一种实用的方法。本文重点研究了在极其有限的查询预算内进行硬标签攻击的具有挑战性的任务，这是现有方法很少能够完成的一项重大成就。为了解决这个问题，我们提出了一个攻击框架，它利用先前摄动方向的几何信息来形成三角形，并采用启发式垂直试验来有效地利用中间方向。大量的实验验证了该方法在严格查询约束下的有效性，并证明了该方法相对于现有方法的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HEPT+Attack:+Heuristic+Perpendicular+Trial+for+Hard-label+Attacks+under+Limited+Query+Budgets)|0|
|[Retrieval-Based Unsupervised Noisy Label Detection on Text Data](https://doi.org/10.1145/3583780.3615146)|Peiyang Liu, Jinyu Yang, Lin Wang, Sen Wang, Yunlai Hao, Huihui Bai|Shanxi Institute of Energy, JIn Zhong, China; PX Securities, Shen Zhen, China|The success of deep neural networks hinges on both high-quality annotations and copious amounts of data; however, in practice, a compromise between dataset size and quality frequently arises. Data collection and cleansing are often resource-intensive and time-consuming, leading to real-world datasets containing label noise that can introduce incorrect correlation patterns, adversely affecting model generalization capabilities. The efficient identification of corrupted patterns is indispensable, with prevalent methods predominantly concentrating on devising robust training techniques to preclude models from internalizing these patterns. Nevertheless, these supervised approaches often necessitate tailored training procedures, potentially resulting in overfitting corrupted patterns and a decline in detection performance. This paper presents a retrieval-based unsupervised solution for the detection of noisy labels, surpassing the performance of three current competitive methods in this domain.|深度神经网络的成功取决于高质量的注释和大量的数据; 然而，在实践中，数据集大小和质量之间的妥协经常出现。数据收集和清理通常是资源密集型和耗时的，导致包含标签噪声的真实世界数据集可能引入不正确的相关模式，从而对模型泛化能力产生不利影响。腐败模式的有效识别是必不可少的，普遍的方法主要集中在设计稳健的训练技术，以排除模型内化这些模式。然而，这些监督的方法往往需要量身定制的训练程序，潜在地导致过度拟合损坏的模式和检测性能的下降。本文提出了一种基于检索的无监督的噪声标签检测方法，其性能超过了目前该领域三种竞争方法的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Retrieval-Based+Unsupervised+Noisy+Label+Detection+on+Text+Data)|0|
|[Counterfactual Adversarial Learning for Recommendation](https://doi.org/10.1145/3583780.3615152)|Jialin Liu, Zijian Zhang, Xiangyu Zhao, Jun Li|Computer Network Information Center, Chinese Academy of Sciences, Beijing, China; Computer Network Information Center, Chinese Academy of Sciences, University of Chinese Academy Sciences, Beijing, China; City University of Hong Kong, Hong Kong, China; Jilin University, City University of Hong Kong, Changchun, China|Long-term user responses, i.e., clicks or purchases on e-commerce platforms, are crucial for sequential recommender systems. Recent off-policy evaluation methods involve these responses by simultaneously maximizing expected cumulative rewards. However, two aspects of these methods require further consideration. Firstly, from the system's point of view, candidates with various values are interchangeable, which may result in contradictory future recommendations despite having the same interaction history. Secondly, rewards are manually designed, which necessitates a trial-and-error approach to strike a balance between training stabilization and reward distinction. To address these issues, we propose a new sequential recommender system called NCM4Rec. Specifically, for the distinction problem, NCM4Rec achieves counterfactual consistency via a neural causal model, which is learnable yet equally expressive as classic structural causal models. Such consistency is maintained by a Gumbel-Max design. For the representing problem, NCM4Rec encodes different types of responses as one-hot vectors and captures the long-term preference via adversarial learning. As a consequence, NCM4Rec is both adaptive and identifiable. Both theoretical analyses of the consistency and empirical studies over two real-world datasets demonstrate the effectiveness of our method.|长期的用户响应，即电子商务平台上的点击或购买，对于顺序推荐系统至关重要。最近的非政策性评估方法通过同时最大化预期累积回报来涉及这些反应。然而，这些方法的两个方面需要进一步考虑。首先，从系统的角度来看，具有不同价值观的候选人是可以互换的，这可能会导致相互矛盾的未来推荐，尽管有相同的互动历史。其次，奖励是手工设计的，这就需要一个试错法来平衡训练的稳定性和奖励的区别。为了解决这些问题，我们提出了一个新的连续推荐系统，称为 NCM4rec。具体来说，对于区分问题，NCM4Rec 通过一个神经因果模型来实现反事实的一致性，这个模型是可以学习的，但是与经典的结构因果模型同样具有表现力。这种一致性是由 Gumbel-Max 设计保持的。对于表示问题，NCM4Rec 将不同类型的响应编码为一个热向量，并通过对抗学习获取长期偏好。因此，NCM4Rec 既是自适应的，也是可识别的。对两个实际数据集的一致性理论分析和实证研究都证明了该方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Counterfactual+Adversarial+Learning+for+Recommendation)|0|
|[Understanding the Multi-vector Dense Retrieval Models](https://doi.org/10.1145/3583780.3615282)|Qi Liu, Jiaxin Mao|Renmin University of China, Beijing, China|While dense retrieval has become a promising alternative to the traditional text retrieval models, such as BM25, some recent studies show that multi-vector dense retrieval models are more effective than the single-vector method in retrieval tasks. However, due to a lack of interpretability, why the multi-vector method outperforms its single-vector counterpart has not been fully studied. To fill this research gap, in this work, we investigate and compare the behaviors of single-vector and multi-vector models in retrieval. Specifically, we analyze the vocabulary distribution of dense representations by mapping them back to the sparse, vocabulary space. Our empirical findings show that the multi-vector representation has more lexical overlaps between queries and passages. Additionally, we show that this feature of multi-vector representation can enhance its ranking performance when a given passage can fulfill different information needs and thus can be retrieved by different queries. These results shed light on the internal mechanisms of multi-vector representation and may provide new perspectives for future research.|虽然密集检索已经成为传统文本检索模型(如 BM25)的一个有前途的替代方案，但最近的一些研究表明，多向量密集检索模型在检索任务中比单向量方法更有效。然而，由于缺乏可解释性，为什么多向量方法的性能优于单向量方法还没有得到充分的研究。为了填补这一研究空白，本文对单向量模型和多向量模型在检索中的行为进行了研究和比较。具体来说，我们通过将密集表示映射回稀疏的词汇空间来分析它们的词汇分布。我们的实证结果表明，多向量表示在查询和段落之间有更多的词汇重叠。此外，我们还发现，当一个给定的段落可以满足不同的信息需求时，这种多向量表示特征可以提高其排序性能，从而可以通过不同的查询进行检索。这些结果揭示了多向量表示的内在机制，为今后的研究提供了新的视角。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+the+Multi-vector+Dense+Retrieval+Models)|0|
|[Spatio-Temporal Adaptive Embedding Makes Vanilla Transformer SOTA for Traffic Forecasting](https://doi.org/10.1145/3583780.3615160)|Hangchen Liu, Zheng Dong, Renhe Jiang, Jiewen Deng, Jinliang Deng, Quanjun Chen, Xuan Song|Southern University of Science and Technology, Shenzhen, China; University of Technology Sydney, Sydney, Australia; The University of Tokyo, Kashiwa, Japan|With the rapid development of the Intelligent Transportation System (ITS), accurate traffic forecasting has emerged as a critical challenge. The key bottleneck lies in capturing the intricate spatio-temporal traffic patterns. In recent years, numerous neural networks with complicated architectures have been proposed to address this issue. However, the advancements in network architectures have encountered diminishing performance gains. In this study, we present a novel component called spatio-temporal adaptive embedding that can yield outstanding results with vanilla transformers. Our proposed Spatio-Temporal Adaptive Embedding transformer (STAEformer) achieves state-of-the-art performance on five real-world traffic forecasting datasets. Further experiments demonstrate that spatio-temporal adaptive embedding plays a crucial role in traffic forecasting by effectively capturing intrinsic spatio-temporal relations and chronological information in traffic time series.|随着智能交通系统(ITS)的快速发展，准确的交通量预测已经成为智能交通系统面临的一个重要挑战。关键的瓶颈在于捕获复杂的时空交通模式。近年来，许多具有复杂结构的神经网络被提出来解决这个问题。然而，网络体系结构的改进遇到了性能收益递减的问题。在这项研究中，我们提出了一个新的组成部分称为时空自适应嵌入，可以产生突出的结果与香草变压器。我们提出的时空自适应嵌入变压器(STAEformer)在五个真实世界的交通预测数据集上实现了最先进的性能。进一步的实验表明，时空自适应嵌入通过有效地捕获交通时间序列中固有的时空关系和时间信息，在交通预测中发挥了重要作用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spatio-Temporal+Adaptive+Embedding+Makes+Vanilla+Transformer+SOTA+for+Traffic+Forecasting)|0|
|[Personalized Differentially Private Federated Learning without Exposing Privacy Budgets](https://doi.org/10.1145/3583780.3615247)|Junxu Liu, Jian Lou, Li Xiong, Xiaofeng Meng|Emory University, Atlanta, GA, USA; Renmin University of China, Beijing, China; Zhejiang University, Hangzhou, China|The meteoric rise of cross-silo Federated Learning (FL) is due to its ability to mitigate data breaches during collaborative training. To further provide rigorous privacy protection with consideration of the varying privacy requirements across different clients, a privacy-enhanced line of work on personalized differentially private federated learning (PDP-FL) has been proposed. However, the existing solution for PDP-FL [20] assumes the raw privacy budgets of all clients should be collected by the server. These values are then directly utilized to improve the model utility via facilitating the privacy preferences partitioning (i.e., partitioning all clients into multiple privacy groups). It is however non-realistic because the raw privacy budgets can be quite informative and sensitive. In this work, our goal is to achieve PDP-FL without exposing clients' raw privacy budgets by indirectly partitioning the privacy preferences solely based on clients' noisy model updates. The crux lies in the fact that the noisy updates could be influenced by two entangled factors of DP noises and non-IID clients' data, leaving it unknown whether it is possible to uncover privacy preferences by disentangling the two affecting factors. To overcome the hurdle, we systematically investigate the unexplored question of under what conditions can the model updates of clients be primarily influenced by noise levels rather than data distribution. Then, we propose a simple yet effective strategy based on clustering the L2 norm of the noisy updates, which can be integrated into the vanilla PDP-FL to maintain the same performance. Experimental results demonstrate the effectiveness and feasibility of our privacy-budget-agnostic PDP-FL method.|跨竖井联邦学习(FL)的迅速崛起是由于它在协作培训期间减轻数据泄露的能力。为了进一步提供严格的隐私保护，考虑到不同客户端的不同隐私要求，提出了一种个性化差异私有联邦学习(PDP-FL)的隐私增强工作路线。然而，现有的 PDP-FL [20]解决方案假设所有客户端的原始隐私预算都应该由服务器收集。然后，这些值被直接用于通过促进隐私首选项分区(即，将所有客户端分成多个隐私组)来改进模型实用程序。然而，这是不现实的，因为原始的隐私预算可以相当信息量和敏感性。在这项工作中，我们的目标是实现 PDP-FL，而不暴露客户的原始隐私预算，通过间接分割的隐私偏好完全基于客户的噪声模型更新。问题的关键在于噪声更新可能受到 DP 噪声和非 IID 用户数据两个纠缠因素的影响，这使得是否可以通过分离这两个影响因素来揭示隐私偏好成为一个未知数。为了克服这一障碍，我们系统地研究了在什么条件下客户端的模型更新主要受噪声水平而不是数据分布的影响这一尚未探索的问题。然后，我们提出了一个简单而有效的策略，基于聚类的 L2范数的噪声更新，可以集成到普通的 PDP-FL，以保持相同的性能。实验结果证明了我们提出的隐私预算不可知的 PDP-FL 方法的有效性和可行性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Differentially+Private+Federated+Learning+without+Exposing+Privacy+Budgets)|0|
|[A Flash Attention Transformer for Multi-Behaviour Recommendation](https://doi.org/10.1145/3583780.3615206)|Tendai Mukande, Esraa Ali, Annalina Caputo, Ruihai Dong, Noel E. O'Connor|University College Dublin, Dublin, Ireland; Dublin City University, Dublin, Ireland|\beginabstract Recently, modelling heterogeneous interactions in recommender systems has attracted research interest. Real-world scenarios involve sequential multi-type user-item interactions such as ''shape view'', ''shape add-to-favourites'', ''shape add-to-cart'' and ''shape purchase''. Graph Neural Network (GNN) methods have been widely adopted in Representation Learning of similar sequential user-item interactions. Promising results have been achieved by the integration of GNNs and transformers for self-attention. However, GNN based methods suffer from limited capability in handling global user-item interaction dependencies, particularly for long sequences. Moreover, these models require high computational cost of transformers, due to the quadratic memory and time complexity with respect to sequence length. This results in memory bottlenecks and slow training especially in computational resource-constrained environments. To address these challenges, we propose the FATH model which employs Flash Attention mechanism to reduce the high-bandwidth memory usage over higher-order user-item interaction sequences. Experimental results show that our model improves the training speed and reduces the memory usage with better recommendation performance in comparison with the state-of the art baselines.|近年来，在推荐系统中建立异构交互模型引起了人们的研究兴趣。真实世界的场景涉及连续的多类型用户项交互，如“形状视图”、“形状添加到收藏夹”、“形状添加到购物车”和“形状购买”。图神经网络(GNN)方法已被广泛应用于相似序列用户-项目交互的表示学习。全球导航卫星系统和变压器的结合为自我关注取得了令人鼓舞的成果。然而，基于 GNN 的方法在处理全局用户项交互依赖性方面能力有限，特别是对于长序列。此外，这些模型需要高计算成本的变压器，由于二次记忆和时间复杂度相对序列长度。这导致了内存瓶颈和训练速度缓慢，特别是在计算资源受限的环境中。为了解决这些问题，我们提出了基于 Flash 注意机制的 FATH 模型，以降低高阶用户项交互序列的高带宽内存使用。实验结果表明，该模型提高了训练速度，减少了内存使用，与目前最先进的基线相比，具有更好的推荐性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Flash+Attention+Transformer+for+Multi-Behaviour+Recommendation)|0|
|[Differential Privacy in HyperNetworks for Personalized Federated Learning](https://doi.org/10.1145/3583780.3615203)|Vaisnavi Nemala, Phung Lai, NhatHai Phan|New Jersey Institute of Technology, Newark, NJ, USA; University at Albany - State University of New York, Albany, NY, USA|Federated learning (FL) is a framework for collaborative learning among users through a coordinating server. A recent HyperNetwork-based personalized FL framework, called HyperNetFL, is used to generate local models using personalized descriptors optimized for each user independently. However, HyperNetFL introduces unknown privacy risks. This paper introduces a novel approach to preserve user-level differential privacy, dubbed User-level DP, by providing formal privacy protection for data owners in training a HyperNetFL model. To achieve that, our proposed algorithm, called UDP-Alg, optimizes the trade-off between privacy loss and model utility by tightening sensitivity bounds. An intensive evaluation using benchmark datasets shows that our proposed UDP-Alg significantly improves privacy protection at a modest cost in utility.|联合学习(FL)是一个通过协调服务器在用户之间建立合作学习的框架。最近一个基于 HyperNetwork 的个性化 FL 框架，称为 HyperNetFL，用于使用为每个用户独立优化的个性化描述符生成本地模型。然而，HyperNetFL 引入了未知的隐私风险。本文介绍了一种新的方法来保护用户级别的差分隐私，称为用户级 DP，通过提供正式的隐私保护数据所有者在培训 HypernetFL 模型。为了实现这一目标，我们提出的算法，称为 UDP-Alg，通过收紧灵敏度界限，优化了隐私损失和模型实用性之间的权衡。使用基准数据集进行的深入评估表明，我们提出的 UDP-Alg 显著改善了隐私保护，而且成本不高。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Differential+Privacy+in+HyperNetworks+for+Personalized+Federated+Learning)|0|
|[Pre-training with Aspect-Content Text Mutual Prediction for Multi-Aspect Dense Retrieval](https://doi.org/10.1145/3583780.3615157)|Xiaojie Sun, Keping Bi, Jiafeng Guo, Xinyu Ma, Yixing Fan, Hongyu Shan, Qishen Zhang, Zhongyi Liu|ICT, CAS & University of Chinese Academy of Sciences, Beijing, China; ; Ant Group, Beijing, China|Grounded on pre-trained language models (PLMs), dense retrieval has been studied extensively on plain text. In contrast, there has been little research on retrieving data with multiple aspects using dense models. In the scenarios such as product search, the aspect information plays an essential role in relevance matching, e.g., category: Electronics, Computers, and Pet Supplies. A common way of leveraging aspect information for multi-aspect retrieval is to introduce an auxiliary classification objective, i.e., using item contents to predict the annotated value IDs of item aspects. However, by learning the value embeddings from scratch, this approach may not capture the various semantic similarities between the values sufficiently. To address this limitation, we leverage the aspect information as text strings rather than class IDs during pre-training so that their semantic similarities can be naturally captured in the PLMs. To facilitate effective retrieval with the aspect strings, we propose mutual prediction objectives between the text of the item aspect and content. In this way, our model makes more sufficient use of aspect information than conducting undifferentiated masked language modeling (MLM) on the concatenated text of aspects and content. Extensive experiments on two real-world datasets (product and mini-program search) show that our approach can outperform competitive baselines both treating aspect values as classes and conducting the same MLM for aspect and content strings. Code and related dataset will be available at the URL \footnote{https://github.com/sunxiaojie99/ATTEMPT}.|基于预训练语言模型(PLM)的密集检索已经在纯文本上得到了广泛的研究。相比之下，使用密集模型检索多方面数据的研究很少。在诸如产品搜索这样的场景中，方面信息在相关性匹配中扮演着重要的角色，例如，类别: 电子产品、计算机和宠物用品。利用方面信息进行多方面检索的一种常见方法是引入辅助分类目标，即使用项目内容来预测项目方面的注释值 ID。然而，通过从头学习值嵌入，这种方法可能无法充分捕获值之间的各种语义相似性。为了解决这个限制，我们在预训练期间利用方面信息作为文本字符串而不是类 ID，这样它们的语义相似性可以自然地在 PLM 中捕获。为了方便有效的检索与方面字符串，我们提出了项目方面的文本和内容之间的相互预测目标。通过这种方式，我们的模型比对方面和内容的连接文本进行无区别掩蔽语言建模(MLM)更充分地利用了方面信息。对两个真实世界数据集(产品和小型程序搜索)的大量实验表明，我们的方法可以胜过将方面值作为类处理以及对方面和内容字符串执行相同的传销的竞争性基线。代码和相关数据集可在网址脚注{ https://github.com/sunxiaojie99/attempt }查阅。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pre-training+with+Aspect-Content+Text+Mutual+Prediction+for+Multi-Aspect+Dense+Retrieval)|0|
|[Sequential Text-based Knowledge Update with Self-Supervised Learning for Generative Language Models](https://doi.org/10.1145/3583780.3615188)|HaoRu Sung, YingJhe Tang, YuChung Cheng, PaiLin Chen, TsaiYen Li, HenHsen Huang|Academia Sinica, Taipei City, Taiwan Roc; National Chengchi University, Taipei City, Taiwan Roc|This work proposes a new natural language processing (NLP) task to tackle the issue of multi-round, sequential text-based knowledge update. The study introduces a hybrid learning architecture and a novel self-supervised training strategy to enable generative language models to consolidate knowledge in the same way as humans. A dataset was also created for evaluation and results showed the effectiveness of our methodology. Experimental results confirm the superiority of the proposed approach over existing models and large language models (LLMs). The proposed task and model framework have the potential to significantly improve the automation of knowledge organization, making text-based knowledge an increasingly crucial resource for powerful LLMs to perform various tasks for humans.|提出了一种新的自然语言处理(NLP)任务来解决基于文本序列的多轮知识更新问题。该研究引入了一种混合学习架构和一种新的自我监督训练策略，使生成语言模型能够像人类一样巩固知识。还创建了一个用于评估的数据集，结果显示了我们的方法的有效性。实验结果证实了该方法相对于现有模型和大语言模型(LLM)的优越性。提出的任务和模型框架有可能显著提高知识组织的自动化程度，使基于文本的知识成为强大的 LLM 执行人类各种任务的日益重要的资源。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sequential+Text-based+Knowledge+Update+with+Self-Supervised+Learning+for+Generative+Language+Models)|0|
|[RecRec: Algorithmic Recourse for Recommender Systems](https://doi.org/10.1145/3583780.3615181)|Sahil Verma, Ashudeep Singh, Varich Boonsanong, John P. Dickerson, Chirag Shah|University of Washington, Seattle, WA, USA; Pinterest, Inc., San Francisco, CA, USA; University of Maryland, College Park, MD, USA|Recommender systems play an essential role in the choices people make in domains such as entertainment, shopping, food, news, employment, and education. The machine learning models underlying these recommender systems are often enormously large and black-box in nature for users, content providers, and system developers alike. It is often crucial for all stakeholders to understand the model's rationale behind making certain predictions and recommendations. This is especially true for the content providers whose livelihoods depend on the recommender system. Drawing motivation from the practitioners' need, in this work, we propose a recourse framework for recommender systems, targeted towards the content providers. Algorithmic recourse in the recommendation setting is a set of actions that, if executed, would modify the recommendations (or ranking) of an item in the desired manner. A recourse suggests actions of the form: "if a feature changes X to Y, then the ranking of that item for a set of users will change to Z." Furthermore, we demonstrate that RecRec is highly effective in generating valid, sparse, and actionable recourses through an empirical evaluation of recommender systems trained on three real-world datasets. To the best of our knowledge, this work is the first to conceptualize and empirically test a generalized framework for generating recourses for recommender systems.|推荐系统在人们在娱乐、购物、食品、新闻、就业和教育等领域做出的选择中起着至关重要的作用。对于用户、内容提供商和系统开发人员来说，这些推荐系统背后的机器学习模型通常是非常巨大的黑盒子。对于所有的利益相关者来说，理解模型做出某些预测和建议背后的基本原理通常是至关重要的。对于内容提供商来说尤其如此，因为他们的生计取决于推荐系统。在这项工作中，我们从实践者的需要中汲取动机，提出了一个面向内容提供者的推荐系统的追索框架。推荐设置中的算法追索权是一组操作，如果执行，将以期望的方式修改项目的推荐(或排名)。资源建议的行动的形式: “如果一个功能改变 X 到 Y，那么该项目的排名为一组用户将改变为 Z。”此外，我们证明，RecRec 是非常有效的生成有效的，稀疏，可操作的资源，通过实证评估的推荐系统训练的三个现实世界的数据集。据我们所知，这项工作是第一个概念化和经验测试一个通用的框架生成推荐系统的资源。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RecRec:+Algorithmic+Recourse+for+Recommender+Systems)|0|
|[Network Embedding with Adaptive Multi-hop Contrast](https://doi.org/10.1145/3583780.3615179)|Chenhao Wang, Yong Liu, Yan Yang|Heilongjiang University, Harbin, China|\beginabstract Graph neural networks (GNNs) have shown strong performance in graph-based analysis tasks. Despite their remarkable success, the inherent homophilic message-passing mechanism (MP) makes GNNs challenging to generalize to heterophilic graphs. In addition, the MP explicitly exploits the connection relationships between local neighbor nodes making GNNs unable to maintain stable performance in the face of adversarial perturbation attacks. In this paper, we propose a new method to explore graph structure by removing explicit message-passing mechanisms and present a network embedding framework AMCNE with Adaptive Multi-hop Contrast loss (AMCLoss) to address these challenges. AMCNE only relies on a simple autoencoder to obtain node representations for classification and uses elaborate contrastive loss to drive nodes capturing complex structural information on heterophilic graphs. The comprehensive experiments show that AMCNE outperforms state-of-the-art baseline models on homophilic and heterophilic graphs and is more robust in the node classification task. \endabstract|初级抽象图神经网络(GNN)在基于图的分析任务中表现出很强的性能。尽管它们取得了显著的成功，但是固有的同质信息传递机制(MP)使得 GNN 难以推广到异质图。此外，MP 算法明确地利用了本地邻居节点之间的连接关系，使得 GNN 在面对对抗性扰动攻击时无法保持稳定的性能。本文提出了一种通过去除显式消息传递机制来探索图结构的新方法，并提出了一种带有自适应多跳对比度损失(AMCLoss)的网络嵌入框架 AMCNE 来解决这些问题。AMCNE 只依靠一个简单的自动编码器来获得分类的节点表示，并使用精细的对比损失来驱动节点捕获异质图上的复杂结构信息。综合实验表明，AMCNE 在同亲和异亲图上优于最先进的基线模型，在节点分类任务中具有更强的鲁棒性。结束摘要|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Network+Embedding+with+Adaptive+Multi-hop+Contrast)|0|
|[A Joint Training-Calibration Framework for Test-Time Personalization with Label Shift in Federated Learning](https://doi.org/10.1145/3583780.3615173)|Jian Xu, ShaoLun Huang|Tsinghua University, Shenzhen, China|The data heterogeneity has been a challenging issue in federated learning in both training and inference stages, which motivates a variety of approaches to learn either personalized models for participating clients or test-time adaptations for unseen clients. One such approach is employing a shared feature representation and a customized classifier head for each client. However, previous works either neglect the global head with rich knowledge or assume the new clients have enough labeled data, which significantly limit their broader practicality. In this work, we propose a lightweight framework to tackle with the label shift issue during the model deployment by test priors estimation and model prediction calibration. We also demonstrate the importance of training a balanced global model in FL so as to guarantee the general effectiveness of prior estimation approaches. Evaluation results on benchmark datasets demonstrate the superiority of our framework for model adaptation in unseen clients with unknown label shifts.|数据异构性在联邦学习的训练和推理阶段都是一个具有挑战性的问题，它激发了各种方法来学习参与客户的个性化模型或者为看不见的客户进行测试时间适应。其中一种方法是为每个客户机使用一个共享特征表示和一个定制的分类器头。然而，以往的研究忽略了具有丰富知识的全局负责人，或者假设新客户拥有足够的标记数据，从而大大限制了其更广泛的实用性。在这项工作中，我们提出了一个轻量级的框架，通过测试先验估计和模型预测校准来解决模型部署过程中的标签移位问题。我们还证明了在 FL 中训练一个平衡的全局模型以保证先验估计方法的一般有效性的重要性。对基准数据集的评估结果表明了我们的模型适应框架在未知客户端的未知标签位移方面的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Joint+Training-Calibration+Framework+for+Test-Time+Personalization+with+Label+Shift+in+Federated+Learning)|0|
|[Geometry Interaction Augmented Graph Collaborative Filtering](https://doi.org/10.1145/3583780.3615204)|Jie Xu, Chaozhuo Li|Beijing Foreign Studies University, Beijing, China; Microsoft Research Asia, Beijing, China|Graph collaborative filtering, which could capture the abundant collaborative signal from the high-order connectivity of the tree-likeness user-item interaction graph, has received considerable research attention recently. Most graph collaborative filtering methods embed graphs in the Euclidean spaces, but that could have high distortion when embedding graphs with tree-likeness structure. Recently, some researchers address this problem by learning the feature representations in the hyperbolic spaces. However, because the user-item interaction graphs also have cyclic structure, the high-order collaborative signal cannot be well captured by hyperbolic spaces. From this point of view, neither Euclidean spaces nor hyperbolic spaces can capture the full information from the complexity of user-item interactions. Therefore, how to construct a suitable embedding space for graph collaboration filtering is an important problem. In this paper, we analyze the properties of hyperbolic geometry in graph collaborative filtering tasks and proposed a novel geometry interaction augmented graph collaborative filtering (GeoGCF) method, which leverages both Euclidean and hyperbolic geometry to model the user-item interactions. Experimental results show the effectiveness of the proposed method.|图形协同过滤能够从树形用户-项目交互图的高阶连通性中捕捉到丰富的协作信号，近年来得到了广泛的研究关注。大多数图形协同过滤方法都是在欧几里德空间中嵌入图形，但是当嵌入具有树形结构的图形时，这种方法会产生很大的失真。最近，一些研究者通过学习双曲空间中的特征表示来解决这个问题。然而，由于用户项交互图也具有循环结构，双曲空间不能很好地捕获高阶协作信号。从这个角度来看，无论是欧几里德空间还是双曲空间都不能从用户-项目交互的复杂性中获取完整的信息。因此，如何构造合适的嵌入空间进行图协同过滤是一个重要问题。在这篇文章中，我们分析了图形双曲几何任务的协同过滤特性，提出了一种新的几何交互增强图形协同过滤(GeogCF)方法，该方法利用欧几里得和双曲几何对用户-项目的交互进行建模。实验结果表明了该方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Geometry+Interaction+Augmented+Graph+Collaborative+Filtering)|0|
|[Graph-based Alignment and Uniformity for Recommendation](https://doi.org/10.1145/3583780.3615185)|Liangwei Yang, Zhiwei Liu, Chen Wang, Mingdai Yang, Xiaolong Liu, Jing Ma, Philip S. Yu|University of Illinois Chicago, Chicago, IL, USA; Salesforce AI Research, Palo Alto, CA, USA; University of Electronic Science and Technology of China, Chengdu, China|Collaborative filtering-based recommender systems (RecSys) rely on learning representations for users and items to predict preferences accurately. Representation learning on the hypersphere is a promising approach due to its desirable properties, such as alignment and uniformity. However, the sparsity issue arises when it encounters RecSys. To address this issue, we propose a novel approach, graph-based alignment and uniformity (GraphAU), that explicitly considers high-order connectivities in the user-item bipartite graph. GraphAU aligns the user/item embedding to the dense vector representations of high-order neighbors using a neighborhood aggregator, eliminating the need to compute the burdensome alignment to high-order neighborhoods individually. To address the discrepancy in alignment losses, GraphAU includes a layer-wise alignment pooling module to integrate alignment losses layer-wise. Experiments on four datasets show that GraphAU significantly alleviates the sparsity issue and achieves state-of-the-art performance. We open-source GraphAU at https://github.com/YangLiangwei/GraphAU.|基于协同过滤的推荐系统(RecSys)依赖于用户和项目的学习表示来准确预测偏好。超球面上的表示学习是一种很有前途的学习方法，因为它具有良好的对齐性和一致性等特性。然而，当它遇到 RecSys 时，稀疏性问题就出现了。为了解决这个问题，我们提出了一种新的方法——基于图的对齐和一致性(GraphAU) ，它明确地考虑了用户项二部图中的高阶连通性。GraphAU 使用邻域聚合器将嵌入的用户/项目对齐到高阶邻居的密集向量表示，从而消除了单独计算高阶邻居的繁琐对齐的需要。为了解决对齐损失中的差异，GraphAU 包括一个分层对齐池模块，以分层集成对齐损失。在四个数据集上的实验表明，GraphAU 显著地缓解了稀疏性问题，并达到了最先进的性能。我们 https://github.com/yangliangwei/GraphAU 开源 GraphAU。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph-based+Alignment+and+Uniformity+for+Recommendation)|0|
|[Predicting Interaction Quality of Conversational Assistants With Spoken Language Understanding Model Confidences](https://doi.org/10.1145/3583780.3615493)|Yue Gao, Enrico Piovano, Tamer Soliman, Monir Moniruzzaman, Anoop Kumar, Melanie Bradford, Subhrangshu Nandi|University of Wisconsin-Madison, Madison, USA; Amazon Alexa AI, Sunnyvale, USA; Amazon Alexa AI, Seattle, USA; Amazon Alexa AI, Berlin, Germany|In conversational AI assistants, SLU models are part of a complex pipeline composed of several modules working in harmony. Hence, an update to the SLU model needs to ensure improvements not only in the model specific metrics but also in the overall conversational assistant performance. Specifically, the impact on user interaction quality metrics must be factored in, while integrating interactions with distal modules upstream and downstream of the SLU component. We develop a ML model that makes it possible to gauge the interaction quality metrics due to SLU model changes before a production launch. The proposed model is a multi-modal transformer with a gated mechanism that conditions on text embeddings, output of a BERT model pre-trained on conversational data, and the hypotheses of the SLU classifiers with the corresponding confidence scores. We show that the proposed model predicts defect with more than 76% correlation with live interaction quality defects, compared to 46% baseline.|在会话型人工智能助手领域，SLU 模型是由几个协调工作的模块组成的复杂管道的一部分。因此，对 SLU 模型的更新不仅需要确保模型特定指标的改进，还需要确保整体会话助理性能的改进。具体来说，在与 SLU 组件的远程模块集成交互时，必须考虑到对用户交互质量指标的影响上游或下游。我们开发了一个机器学习模型，可以在产品投入生产之前测量由于 SLU 模型变化而产生的交互质量指标。该模型是一个具有门控机制的多模态转换器，其条件为文本嵌入、基于会话数据的 BERT 模型的输出以及 SLU 分类器的假设和相应的置信度。我们表明，与46% 的基线相比，提出的模型预测缺陷与实时交互质量缺陷的相关性超过76% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Predicting+Interaction+Quality+of+Conversational+Assistants+With+Spoken+Language+Understanding+Model+Confidences)|0|
|[pADR: Towards Personalized Adverse Drug Reaction Prediction by Modeling Multi-sourced Data](https://doi.org/10.1145/3583780.3615490)|Junyu Luo, Cheng Qian, Xiaochen Wang, Lucas Glass, Fenglong Ma|The Pennsylvania State University, University Park, PA, USA; IQVIA, Chicago, IL, USA|Predicting adverse drug reactions (ADRs) of drugs is one of the most critical steps in drug development. By pre-estimating the adverse reactions, researchers and drug development companies can greatly prevent the potential ADR risks and tragedies. However, the current ADR prediction methods suffer from several limitations. First, the prediction results are based on pure drug-related information, which makes them impossible to be directly applied for the personalized ADR prediction task. The lack of personalization of models also makes rare adverse events hard to be predicted. Therefore, it is of great interest to develop a new personalized ADR prediction method by introducing additional sources, e.g., patient health records. However, few methods have tried to use additional sources. In the meantime, the variety of different source formats and structures makes this task more challenging. To address the above challenges, we propose a novel personalized multi-sourced-based drug adverse reaction prediction model named pADR. pADR first works on every single source to transform them into proper representations. Next, a hierarchical multi-sourced Transformer is designed to automatically model the interactions between different sources and fuse them together for the final adverse event prediction. Experimental results on a new multi-sourced ADR prediction dataset show that pADR1 outperforms state-of-the-art drug-based baselines. Moreover, the case and ablation studies also illustrate the effectiveness of our proposed fusion strategies and the reasonableness of each module design.|预测药物不良反应(ADR)是药物开发过程中最关键的步骤之一。通过预测不良反应，研究人员和药物开发公司可以大大防止潜在的不良反应风险和悲剧。然而，目前的药品不良反应预测方法存在一些局限性。首先，预测结果基于纯药物相关信息，不可能直接应用于个性化的药品不良反应预测任务。缺乏个性化的模型也使罕见的不良事件难以预测。因此，开发一种新的个性化的 ADR 预测方法，通过引入额外的资源，如病人健康记录，是非常有意义的。然而，很少有方法尝试使用其他来源。与此同时，各种不同的源格式和结构使这项任务更具挑战性。为了应对上述挑战，我们提出了一种新的个性化的基于多来源的药物不良反应预测模型 pADR。PADR 首先对每一个源进行处理，将它们转换成适当的表示。接下来，设计了一个分层的多源变压器，自动建模不同源之间的交互，并将它们融合在一起进行最终的不良事件预测。在一个新的多源 ADR 预测数据集上的实验结果表明，pADR1的表现优于最先进的基于药物的基线。此外，实例和烧蚀研究也说明了我们提出的融合策略的有效性和每个模块设计的合理性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=pADR:+Towards+Personalized+Adverse+Drug+Reaction+Prediction+by+Modeling+Multi-sourced+Data)|0|
|[Exploiting Sequential Music Preferences via Optimisation-Based Sequencing](https://doi.org/10.1145/3583780.3615476)|Dmitrii Moor, Yi Yuan, Rishabh Mehrotra, Zhenwen Dai, Mounia Lalmas|Spotify, London, United Kingdom; Spotify, New York, NY, USA; ShareChat, London, United Kingdom|Users in music streaming platforms typically consume tracks sequentially in sessions by interacting with personalised playlists. To satisfy users, music platforms usually rely on recommender systems that learn users' preferences over individual tracks and rank the tracks within each playlist according to the learned preferences. However, such rankings often do not fully exploit the sequential nature of the users' consumption, which may result in a lower within-a-session consumption. In this paper, we model the sequential within-a-session preferences of users and propose an optimisation-based sequencing approach that allows for optimally incorporating such preferences into the rankings. To this end, we rely on interaction data of a major music streaming service to identify two most common aspects of the users' sequential preferences: (1) Position-Aware preferences, and (2) Local-Sequential preferences. We propose a sequencing model that can leverage each of these aspects optimally to maximise the expected total consumption from the session. We further perform an extensive offline and off-policy evaluation of our model, and carry out a large scale online randomised control trial with 7M users across 80 countries. Our findings confirm that we can effectively incorporate sequential preferences of users into our sequencer to make users complete more and skip less tracks within their listening sessions.|音乐流媒体平台的用户通常通过与个性化播放列表交互，在会话中连续消费歌曲。为了满足用户的需求，音乐平台通常依赖于推荐系统来了解用户对单曲的偏好，并根据学到的偏好对每个播放列表中的曲目进行排名。然而，这样的排名往往没有充分利用用户消费的顺序性质，这可能导致较低的会话内消费。在这篇论文中，我们模拟了用户在一个会话内的顺序偏好，并提出了一个基于优化的排序方法，允许将这些偏好最佳地纳入到排名中。为此，我们依靠一个主流音乐流媒体服务的交互数据来识别用户顺序偏好的两个最常见的方面: (1)位置感知偏好和(2)本地顺序偏好。我们提出了一个排序模型，可以最佳地利用这些方面中的每一个来最大化会话的预期总消耗。我们进一步对我们的模型进行了广泛的离线和非政策评估，并在80个国家的700万用户中进行了大规模的在线随机对照试验。我们的研究结果证实，我们可以有效地将用户的顺序偏好纳入我们的音序器，使用户完成更多，跳过更少的轨道在他们的听力会议。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploiting+Sequential+Music+Preferences+via+Optimisation-Based+Sequencing)|0|
|[Deep Query Rewriting For Geocoding](https://doi.org/10.1145/3583780.3615466)|Pravakar Roy, Chirag Sharma, Chao Gao, Kumarswamy Valegerepura|Microsoft, Bellevue, WA, USA; Microsoft, Mountain View, CA, USA|Query rewriting aims to bridge the gap between user queries and indexed data. In the context of geocoding, it augments the user query to match all relevant entities in indexed data. This work presents an end-to-end trainable attention-based query rewriting model for geocoding. Most recent works attempt to solve query rewriting with sequence-to-sequence models, which often fail to satisfy the tight latency constraints of production environments. Toward developing a low latency model, we formulate it as a combination of multiple token classification tasks. We introduce numerous novel techniques, such as constructing a separate output space for alterations containing whole words to tackle many-to-one/one-to-many associations, using regular expression rules as prediction classes to handle the limitations of having a non-word piece prediction space, and curbing the output space for each wordpiece in our vocabulary to reduce inference time by 20x in average. We also present a data generation pipeline that generates train/test data without human judgment from the query logs. Through offline and online experiments, we demonstrate that the proposed model is orders of magnitude faster than their seq2seq and SMT-based counterparts in inference time, achieves better/on-par performance, and improves the relevance of overall geocoding.|查询重写旨在弥合用户查询和索引数据之间的差距。在地理编码的上下文中，它扩展用户查询以匹配索引数据中的所有相关实体。提出了一种基于端到端可训练注意的地理编码查询重写模型。最近的工作尝试用序列到序列模型来解决查询重写问题，这种模型往往不能满足生产环境的严格延迟约束。为了开发一个低延迟模型，我们将其描述为多个令牌分类任务的组合。我们引入了许多新颖的技术，例如构建一个单独的输出空间，用于包含整个单词的修改以处理多对一/一对多的关联，使用正则表达式规则作为预测类来处理具有非单词片段预测空间的局限性，以及限制词汇表中每个单词片段的输出空间以平均减少20倍的推理时间。我们还提供了一个数据生成流水线，该流水线生成列车/测试数据，而不需要从查询日志中进行人工判断。通过离线和在线实验，我们证明了所提出的模型在推理时间上比基于 seq2seq 和基于 SMT 的对应数量级更快，获得了更好/同等的性能，并提高了整体地理编码的相关性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Query+Rewriting+For+Geocoding)|0|
|[An Efficient Content-based Time Series Retrieval System](https://doi.org/10.1145/3583780.3614655)|ChinChia Michael Yeh, Huiyuan Chen, Xin Dai, Yan Zheng, Junpeng Wang, Vivian Lai, Yujie Fan, Audrey Der, Zhongfang Zhuang, Liang Wang, Wei Zhang, Jeff M. Phillips|Visa Resarch, Palo Alto, CA, USA; University of California, Riverside, Riverside, CA, USA; Visa Research, Palo Alto, CA, USA; University of Utah, Salt Lake City, UT, USA|A Content-based Time Series Retrieval (CTSR) system is an information retrieval system for users to interact with time series emerged from multiple domains, such as finance, healthcare, and manufacturing. For example, users seeking to learn more about the source of a time series can submit the time series as a query to the CTSR system and retrieve a list of relevant time series with associated metadata. By analyzing the retrieved metadata, users can gather more information about the source of the time series. Because the CTSR system is required to work with time series data from diverse domains, it needs a high-capacity model to effectively measure the similarity between different time series. On top of that, the model within the CTSR system has to compute the similarity scores in an efficient manner as the users interact with the system in real-time. In this paper, we propose an effective and efficient CTSR model that outperforms alternative models, while still providing reasonable inference runtimes. To demonstrate the capability of the proposed method in solving business problems, we compare it against alternative models using our in-house transaction data. Our findings reveal that the proposed model is the most suitable solution compared to others for our transaction data problem.|基于内容的时间序列检索系统是一个信息检索系统，用户可以通过该系统与来自多个领域的时间序列进行交互，如金融、医疗和制造业。例如，希望进一步了解时间序列来源的用户可以将时间序列作为一个查询提交给 CTSR 系统，并检索带有相关元数据的相关时间序列清单。通过分析检索到的元数据，用户可以收集关于时间序列源的更多信息。由于 CTSR 系统需要处理来自不同领域的时间序列数据，因此需要一个高容量的模型来有效地度量不同时间序列之间的相似性。此外，CTSR 系统中的模型必须在用户与系统进行实时交互时有效地计算相似度得分。在本文中，我们提出了一个有效和高效的 CTSR 模型，其性能优于其他模型，同时仍然提供合理的推理运行时。为了证明该方法解决业务问题的能力，我们将其与使用内部事务数据的替代模型进行比较。我们的研究结果表明，所提出的模型是最适合的解决方案比其他人为我们的交易数据问题。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Efficient+Content-based+Time+Series+Retrieval+System)|0|
|[Multi-gate Mixture-of-Contrastive-Experts with Graph-based Gating Mechanism for TV Recommendation](https://doi.org/10.1145/3583780.3615488)|Cong Zhang, Dongyang Liu, Lin Zuo, Junlan Feng, Chao Deng, Jian Sun, Haitao Zeng, Yaohong Zhao|China Mobile Research Institute, Beijing, China; China Mobile Research Institute, Xi'an, China|With the rapid development of smart TV, TV recommendation is attracting more and more users. TV users usually distribute in multiple regions with different cultures and hence have diverse TV program preferences. From the perspective of engineering practice and performance improvement, it's very essential to model users from multiple regions with one single model. In previous work, Multi-gate Mixture-of-Expert (MMoE) has been widely adopted in multi-task and multi-domain recommendation scenarios. In practice, however, we first observe the embeddings generated by experts tend to be homogeneous which may result in high semantic similarities among embeddings that reduce the capability of Multi-gate Mixture-of-Expert (MMoE) model. Secondly, we also find there are lots of commonalities and differences between multiple regions regarding user preferences. Therefore, it's meaningful to model the complicated relationships between regions. In this paper, we first introduce contrastive learning to overcome the expert representation degeneration problem. The embeddings of two augmented samples generated by the same experts are pushed closer to enhance the alignment, and the embeddings of the same samples generated by different experts are pushed away in vector space to improve uniformity. Then we propose a Graph-based Gating Mechanism to empower typical Multi-gate Mixture-of-Experts. Graph-based MMoE is able to recognize the commonalities and differences among multiple regions by introducing a Graph Neural Network (GNN) with region similarity prior. We name our model Multi-gate Mixture-of-Contrastive-Experts model with Graph-based Gating Mechanism (MMoCEG). Extensive offline experiments and online A/B tests on a commercial TV service provider over 100 million users and 2.3 million items demonstrate the efficacy of MMoCEG compared to the existing models.|随着智能电视的迅速发展，电视推荐正在吸引越来越多的用户。电视用户通常分布在具有不同文化的多个地区，因此有不同的电视节目偏好。从工程实践和性能改进的角度来看，用一个单一的模型对来自多个地区的用户进行建模是非常必要的。在以往的工作中，多门专家混合(MMoE)已经被广泛应用于多任务和多领域的推荐场景中。然而，在实际应用中，我们首先观察到由专家生成的嵌入趋于同质，这可能导致嵌入之间的语义相似度很高，从而降低了多门专家混合(MMoE)模型的性能。其次，我们还发现，在用户偏好方面，不同地区之间存在很多共性和差异。因此，建立区域间的复杂关系模型具有重要意义。在本文中，我们首先引入对比学习来克服专家表示退化问题。同一专家产生的两个增广样本的嵌入被推近以提高对齐度，同时不同专家产生的相同样本的嵌入被推远以提高向量空间的均匀性。然后提出了一种基于图的门控机制来增强典型的多门混合专家系统的能力。基于图的 MMoE 能够通过引入具有区域相似性的图神经网络(GNN)来识别多个区域之间的共性和差异。我们将该模型命名为基于图形的门控机制(MMoCEG)的多门控混合对比专家模型。与现有模型相比，MMoCEG 在一个拥有1亿用户和230万条目的商业电视服务提供商上进行了大量的离线实验和在线 A/B 测试，证明了 MMoCEG 的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-gate+Mixture-of-Contrastive-Experts+with+Graph-based+Gating+Mechanism+for+TV+Recommendation)|0|
|[Popularity-aware Distributionally Robust Optimization for Recommendation System](https://doi.org/10.1145/3583780.3615492)|Jujia Zhao, Wenjie Wang, Xinyu Lin, Leigang Qu, Jizhi Zhang, TatSeng Chua|University of Science and Technology of China, Hefei, China, China; National University of Singapore, Singapore, Singapore|Collaborative Filtering (CF) has been widely applied for personalized recommendations in various industrial applications. However, due to the training strategy of Empirical Risk Minimization, CF models tend to favor popular items, resulting in inferior performance on sparse users and items. To enhance the CF representation learning of sparse users and items without sacrificing the performance of popular items, we propose a novel Popularity- aware Distributionally Robust Optimization (PDRO) framework. In particular, PDRO emphasizes the optimization of sparse users/items, while incorporating item popularity to preserve the performance of popular items through two modules. First, an implicit module develops a new popularity-aware DRO objective, paying more attention to items that will potentially become popular over time. Second, an explicit module that directly predicts the popularity of items to help the estimation of user-item matching scores. We apply PDRO to a micro-video recommendation scenario and implement it on two representative backend models. Extensive experiments on a real-world industrial dataset, as well as two public benchmark datasets, validate the efficacy of our proposed PDRO. Additionally, we perform an offline A/B test on the industrial dataset, further demonstrating the superiority of PDRO in real-world application scenarios.|协同过滤(CF)已广泛应用于各种工业应用中的个性化推荐。然而，由于经验风险最小化的训练策略，CF 模型倾向于流行项目，导致稀疏用户和项目的绩效较差。为了增强稀疏用户和项目的 CF 表示学习，同时不牺牲流行项目的性能，提出了一种新的流行感知分布鲁棒优化(PDRO)框架。特别是，PDRO 强调稀疏用户/项目的优化，同时通过两个模块结合项目流行性来保持流行项目的性能。首先，一个隐式模块开发一个新的流行感知 DRO 目标，更多地关注随着时间的推移可能变得流行的项目。第二，一个直接预测项目流行程度的显式模块，以帮助估计用户项目匹配得分。我们将 PDRO 应用于一个微视频推荐场景，并在两个有代表性的后端模型上实现它。对一个真实世界的工业数据集以及两个公共基准数据集的大量实验验证了我们提出的 PDRO 的有效性。此外，我们还对工业数据集进行了离线 A/B 测试，进一步证明了 PDRO 在实际应用场景中的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Popularity-aware+Distributionally+Robust+Optimization+for+Recommendation+System)|0|
|[DeepTagger: Knowledge Enhanced Named Entity Recognition for Web-Based Ads Queries](https://doi.org/10.1145/3583780.3615467)|Simiao Zuo, Pengfei Tang, Xinyu Hu, Qiang Lou, Jian Jiao, Denis Charles|Microsoft, Redmond, USA|Named entity recognition (NER) is a crucial task for online advertisement. State-of-the-art solutions leverage pre-trained language models for this task. However, three major challenges remain unresolved: web queries differ from natural language, on which pre-trained models are trained; web queries are short and lack contextual information; and labeled data for NER is scarce. We propose DeepTagger, a knowledge-enhanced NER model for web-based ads queries. The proposed knowledge enhancement framework leverages both model-free and model-based approaches. For model-free enhancement, we collect unlabeled web queries to augment domain knowledge; and we collect web search results to enrich the information of ads queries. We further leverage effective prompting methods to automatically generate labels using large language models such as ChatGPT. Additionally, we adopt a model-based knowledge enhancement method based on adversarial data augmentation. We employ a three-stage training framework to train DeepTagger models. Empirical results in various NER tasks demonstrate the effectiveness of the proposed framework.|命名实体识别(NER)是网络广告中的一项重要任务。最先进的解决方案利用预先训练好的语言模型完成这项任务。然而，三个主要的挑战仍然没有得到解决: 网络查询与自然语言不同，预先训练的模型是在自然语言的基础上进行训练的; 网络查询很短，缺乏上下文信息; NER 的标记数据很少。我们提出 DeepTagger，一个基于知识增强的网络广告查询 NER 模型。建议的知识增强框架利用了无模型和基于模型的方法。对于无模型增强，我们收集未标记的网页查询来增强领域知识; 收集网页搜索结果来增强广告查询的信息。我们进一步利用有效的提示方法，使用 ChatGPT 等大型语言模型自动生成标签。此外，我们还采用了一种基于模型的知识增强方法。我们采用了一个三阶段的训练框架来训练 DeepTagger 模型。在各种 NER 任务中的实证结果证明了该框架的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DeepTagger:+Knowledge+Enhanced+Named+Entity+Recognition+for+Web-Based+Ads+Queries)|0|
|[A Data-Driven Index Recommendation System for Slow Queries](https://doi.org/10.1145/3583780.3614731)|Gan Peng, Peng Cai, Kaikai Ye, Kai Li, Jinlong Cai, Yufeng Shen, Han Su|East China Normal University, Shanghai, China; Meituan, Shanghai, China|The Database Autonomy Service (DAS) is a platform designed to assist database administrators in managing a large number of database instances within major internet companies. One of the key tasks in DAS is to find missing indexes to improve the slow query execution. In Meituan, a vast array of business lines deploy tens of thousands of MySQL database instances. Consequently, a great number of human-generated index cases are accumulated in the DAS platform. This motivates us to build a data-driven index recommendation system, referred to as idxLearner, which can learn index creation knowledge from human-generated index cases. In this demonstration, users can interact with idxLearner by choosing source databases to construct the training data, training the recommendation model, inputting slow queries for various target databases, and observing the recommended indexes and their evaluation results.|数据库自主服务(DAS)是一个平台，旨在帮助数据库管理员管理大型互联网公司的大量数据库实例。DAS 的关键任务之一是查找丢失的索引，以提高查询执行速度。在美团中，大量的业务部门部署了成千上万的 MySQL 数据库实例。因此，在 DAS 平台上积累了大量的人工索引案例。这促使我们建立一个数据驱动的索引推荐系统，称为 idxLearner，它可以从人工生成的索引案例中学习索引创建知识。在这个演示中，用户可以通过选择源数据库来构建训练数据，训练推荐模型，输入各种目标数据库的慢速查询，观察推荐索引及其评估结果，从而与 idxLearner 进行交互。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Data-Driven+Index+Recommendation+System+for+Slow+Queries)|0|
|[IMinimize: A System for Negative Influence Minimization via Vertex Blocking](https://doi.org/10.1145/3583780.3614743)|Siyi Teng, Jiadong Xie, Mingkai Zhang, Kai Wang, Fan Zhang|University of New South Wales, Sydney, NSW, Australia; East China Normal University, Shanghai, China; Guangzhou University, Guangzhou, China; Shanghai Jiao Tong University, Shanghai, China|The rapid rise and prevalence of social platforms have created great demands on effective schemes to limit the influence of negative information, e.g., blocking key vertices for influence minimization. However, there is currently no system providing practical schemes to solve the negative influence minimization problem with a blocking budget effectively and efficiently in the literature. In this demo, we present IMinimize, the first interactive system that provides audiences with vertex-blocking schemes over different budgets and demonstrates via visualization for comparison vividly and directly, aiming to help minimize the negative influence spreading in networks. Our IMinimize system applies an advanced greedy algorithm to select blocked vertices with both high efficiency and effectiveness. Furthermore, we extend IMinimize to the application of epidemic controlling and prevention and show the usability of IMinimize through two case studies of real-life applications.|社交平台的迅速兴起和普及对限制负面信息影响的有效方案提出了巨大要求，例如，为尽量减少影响而屏蔽关键顶点。然而，目前还没有系统提供切实可行的方案，以解决负面影响最小化问题的阻塞预算有效和高效的文献。在这个演示中，我们介绍了 IMiniize，这是第一个交互式系统，它在不同的预算下为受众提供顶点阻塞方案，并通过可视化演示进行生动直观的比较，旨在帮助最小化网络中的负面影响传播。我们的最小化系统采用了一种先进的贪婪算法来选择阻塞顶点，具有很高的效率和有效性。进一步，我们将 IMinimize 推广到流行病控制和预防的应用中，并通过两个实际应用的案例分析，说明了 IMinimize 的可用性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=IMinimize:+A+System+for+Negative+Influence+Minimization+via+Vertex+Blocking)|0|
|[Towards Improving Accuracy and Computation Cost Optimization of Recommendation Systems](https://doi.org/10.1145/3583780.3616006)|Abdelghani Azri|Hassan First University of Settat, Settat, Morocco|It is hard to avoid recommender systems (RS) these days which play a vital role in various domains, such as e-commerce, online streaming platforms, and personalized content delivery. These systems assist users in discovering relevant items based on their preferences and past interactions. A variety of methods are developed by RS communities, to address the accuracy issue. But, most of these methods are sequential and omit the item features and user side information which contains relevant and rich information that can increase the accuracy of these systems. However, enhancing the accuracy of recommendations often comes at the expense of increased computational costs. This PhD thesis aims to address the challenge of improving the accuracy of RS following a hybrid approach that allows leveraging user-item features based on some relevant state-of-the-art models and using deep learning techniques such as the contractive autoencoder (CAE) while optimizing the cost of computation using parallel/distributed paradigms.|推荐系统(RS)在电子商务、在线流媒体平台和个性化内容发布等领域发挥着重要作用。这些系统帮助用户根据他们的偏好和过去的交互发现相关项目。RS 社区开发了各种各样的方法来解决准确性问题。但是，这些方法大多是顺序的，省略了项目特征和用户侧信息，这些信息包含了相关的、丰富的信息，可以提高这些系统的准确性。然而，提高建议的准确性往往是以增加计算成本为代价的。这篇博士论文旨在解决提高 RS 准确性的挑战，采用一种混合方法，允许利用基于一些相关的最先进模型的用户项特征，并使用深度学习技术，如压缩式自动编码器(CAE) ，同时使用并行/分布式范例优化计算成本。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Improving+Accuracy+and+Computation+Cost+Optimization+of+Recommendation+Systems)|0|
|[Explaining Learning to Rank Methods to Improve Them](https://doi.org/10.1145/3583780.3616002)|Alberto Veneri|Ca' Foscari University of Venice & ISTI-CNR, Venice, Italy|State-of-the-art methods for Learning to Rank (LtR), either designed for tabular or textual data, are incredibly complex. Increasing the complexity of the models has many drawbacks, including difficulties in understanding the logic behind each prediction and a lack of trust in the system during its deployment. In this paper, which describes the author's goals during his Ph.D., there is an analysis and discussion of how we can use the ideas and tools coming from the eXplainable Artificial Intelligence (XAI) field to make the most effective methods for LtR understandable to the practitioners with the final goal of making them more efficient and/or understand better when they can be improved. The strategies adopted to achieve the aforementioned goals are different and based on the type of models analyzed, which go from more traditional LtR models based on ensembles of decision trees and using handcrafted features to fairly new neural LtR models using text data.|最先进的学习排名的方法，无论是为表格还是文本数据设计的，都是难以置信的复杂。增加模型的复杂性有许多缺点，包括难以理解每个预测背后的逻辑，以及在部署期间对系统缺乏信任。本文描述了作者在博士期间的目标，分析和讨论了如何利用可解释人工智能(XAI)领域的思想和工具，使从业者能够理解最有效的 LT R 方法，最终目标是使它们更有效和/或更好地理解当它们可以被改进时。为实现上述目标所采取的策略是不同的，它们基于所分析的模型类型，从更传统的基于决策树集合和使用手工特征的 LTR 模型转变为使用文本数据的相当新的神经 LTR 模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explaining+Learning+to+Rank+Methods+to+Improve+Them)|0|
|[Data Augmentation for Conversational AI](https://doi.org/10.1145/3583780.3615291)|Heydar Soudani, Evangelos Kanoulas, Faegheh Hasibi|University of Amsterdam, Amsterdam, Netherlands; Radboud University, Nijmegen, Netherlands|Advancements in conversational systems have revolutionized information access, surpassing the limitations of single queries. However, developing dialogue systems requires a large amount of training data, which is a challenge in low-resource domains and languages. Traditional data collection methods like crowd-sourcing are labor-intensive and time-consuming, making them ineffective in this context. Data augmentation (DA) is an affective approach to alleviate the data scarcity problem in conversational systems. This tutorial provides a comprehensive and up-to-date overview of DA approaches in the context of conversational systems. It highlights recent advances in conversation augmentation, open domain and task-oriented conversation generation, and different paradigms of evaluating these models. We also discuss current challenges and future directions in order to help researchers and practitioners to further advance the field in this area.|会话系统的进步彻底改变了信息访问，超越了单个查询的局限性。然而，开发对话系统需要大量的训练数据，这在资源不足的领域和语言中是一个挑战。传统的数据收集方法，如众包，是劳动密集型和耗时的，使他们在这种情况下无效。数据增强是解决会话系统中数据稀缺问题的有效途径。本教程提供了在会话系统上下文中 DA 方法的全面和最新概述。它强调了会话增强，开放领域和面向任务的会话生成的最新进展，以及评估这些模型的不同范式。我们还讨论了当前的挑战和未来的方向，以帮助研究人员和从业人员进一步推进该领域。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Data+Augmentation+for+Conversational+AI)|0|
|[Tutorial: Data Denoising Metrics in Recommender Systems](https://doi.org/10.1145/3583780.3615297)|Pengfei Wang, Chenliang Li, Lixin Zou, Zhichao Feng, Kaiyuan Li, Xiaochen Li, Xialong Liu, Shangguang Wang|Beijing University of Posts and Telecommunications, Beijing, China; School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Chinese Academy of Sciences, Beijing, China|Recommender systems play a pivotal role in navigating users through vast reservoirs of information. However, data sparseness can compromise recommendation accuracy, making it challenging to improve recommendation performance. To address this issue, researchers have explored incorporating multiple data types. Yet, this approach can introduce noise that impairs the recommendations' accuracy. Therefore, it is crucial to denoise the data to enhance recommendation quality. This tutorial highlights the importance of data denoising metrics for improving the accuracy and quality of recommendations. Four groups of data denoising metrics are introduced: feature, item, pattern, and modality level. For each group, various denoising methods are presented. The tutorial emphasizes the significance of selecting the right data denoising methods to enhance recommendation quality. It provides valuable guidance for practitioners and researchers implementing reliable data denoising metrics in recommender systems. Finally, the tutorial proposes open research questions for future studies, making it a valuable resource for the research community.|推荐系统在通过大量信息库为用户导航方面发挥着关键作用。然而，数据稀疏会影响推荐的准确性，从而给提高推荐性能带来挑战。为了解决这个问题，研究人员已经探索了合并多种数据类型。然而，这种方法会引入噪音，影响建议的准确性。因此，对数据进行去噪处理以提高推荐质量至关重要。本教程强调了数据去噪指标对于提高建议的准确性和质量的重要性。介绍了四组数据去噪指标: 特征、项目、模式和模态水平。对于每一组，提出了各种去噪方法。本教程强调了选择正确的数据去噪方法以提高推荐质量的重要性。它为在推荐系统中实现可靠的数据去噪指标的从业人员和研究人员提供了有价值的指导。最后，本教程提出了未来研究的开放性研究问题，使其成为研究社区的宝贵资源。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tutorial:+Data+Denoising+Metrics+in+Recommender+Systems)|0|
|[Reasoning beyond Triples: Recent Advances in Knowledge Graph Embeddings](https://doi.org/10.1145/3583780.3615294)|Bo Xiong, Mojtaba Nayyeri, Daniel Daza, Michael Cochez|Vrije Universiteit Amsterdam, Amsterdam, Netherlands; Vrije Universiteit Amsterdam & University of Amsterdam, Amsterdam, Netherlands; University of Stuttgart, Stuttgart, Germany|Knowledge Graphs (KGs) are a collection of facts describing entities connected by relationships. KG embeddings map entities and relations into a vector space while preserving their relational semantics. This enables effective inference of missing knowledge from the embedding space. Most KG embedding approaches focused on triple-shaped KGs. A great amount of real-world knowledge, however, cannot simply be represented by triples. In this tutorial, we give a systematic introduction to KG embeddings that go beyond the triple representation. In particular, the tutorial will focus on temporal facts where the triples are enriched with temporal information, hyper-relational facts where the triples are enriched with qualifiers, n-ary facts describing relationships between multiple entities, and also facts that are augmented with literal and text descriptions. During the tutorial, we will introduce both fundamental knowledge and advanced topics for understanding recent embedding approaches for beyond-triple representations.|知识图(KGs)是描述通过关系连接的实体的事实的集合。KG 嵌入将实体和关系映射到向量空间，同时保留它们的关系语义。这使得能够从嵌入空间有效地推断缺失的知识。大多数幼稚园的嵌入方法集中在三重形状的幼稚园。然而，现实世界中的大量知识不能简单地用三元组来表示。在本教程中，我们将系统地介绍超越三重表示的 KG 嵌入。特别是，本教程将重点关注三元组充满时间信息的时间事实，三元组充满修饰符的超关系事实，描述多个实体之间关系的 n 元事实，以及用文字和文本描述增强的事实。在本教程中，我们将介绍基础知识和高级主题，以便理解超越三重表示的最新嵌入方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reasoning+beyond+Triples:+Recent+Advances+in+Knowledge+Graph+Embeddings)|0|
|[Comparative Analysis of Open Source and Commercial Embedding Models for Question Answering](https://doi.org/10.1145/3583780.3615994)|Georgios Balikas|Salesforce Inc., Grenoble, France|In this industry track presentation, we will provide a comprehensive tour of the best performing embedding models for question answering, as determined by the Massive Text Embedding Benchmark1. We showcase these models while also considering solutions offered by OpenAI and Cohere, renowned for their state-of-the-art performance. Through rigorous evaluations on internal Salesforce datasets tailored for Question Answering on Knowledge articles, we compare the performance of these models using standardized metrics. Our analysis sheds light on the current state-of-the-art in question answering using embedding models across three diverse domains. We hope that this talk's outcomes will empower practitioners and researchers to make informed decisions when selecting the most suitable solution for their specific requirements.|在这个行业的轨道演示中，我们将提供一个全面的旅游，最佳表现嵌入模型的问题回答，由海量文本嵌入基准1。我们展示了这些模型，同时也考虑了 OpenAI 和 Cohere 提供的解决方案，它们以最先进的性能而闻名。通过对内部 Salesforce 数据集的严格评估，我们使用标准化指标比较了这些模型的性能。我们的分析揭示了目前使用三个不同领域的嵌入模型进行问题回答的最新技术。我们希望这次演讲的结果能够使从业者和研究人员在为他们的具体需求选择最合适的解决方案时做出明智的决定。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Comparative+Analysis+of+Open+Source+and+Commercial+Embedding+Models+for+Question+Answering)|0|
|[Practical Lessons Learned From Detecting, Preventing and Mitigating Harmful Experiences on Facebook](https://doi.org/10.1145/3583780.3615511)|Prathyusha Senthil Kumar|Meta Platforms Inc., Menlo Park, CA, USA|Social media's explosive growth brings with it a variety of societal risks ranging from severely harmful issues such as dangerous organizations and child sexual exploitation to moderately harmful content like displays of aggression, borderline nudity to benign or distasteful contents like gross videos and baity content. In recent times, the multitude and magnitude of these harms is being further exacerbated with the advent of generative AI [5]. Meta is committed to ensuring that Facebook is a place where people feel empowered to communicate and we take our role seriously in keeping abuse off the platform [7]. In this talk, I will describe practical challenges and lessons learned from tackling bad experiences for users on Facebook, particularly in the subjective, borderline and low quality spectrum of harms using state of the art, scalable machine learning approaches to content understanding, user behavior understanding and personalized ranking.|社交媒体的爆炸式增长带来了各种各样的社会风险，从严重有害的问题，如危险的组织和儿童性剥削，到中等有害的内容，如暴力行为的展示，边缘性的裸体，以良性或令人厌恶的内容，如恶心的视频和色情内容。近年来，随着生成性人工智能的出现，这些危害的多样性和严重性正在进一步加剧[5]。Meta 致力于确保 Facebook 是一个让人们感到有能力进行交流的地方，我们认真对待自己在防止滥用平台方面的作用[7]。在这个演讲中，我将描述实际的挑战和经验教训，从解决 Facebook 用户的不良体验，特别是在主观，边缘和低质量的危害范围使用最先进的，可扩展的机器学习方法的内容理解，用户行为理解和个性化排名。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Practical+Lessons+Learned+From+Detecting,+Preventing+and+Mitigating+Harmful+Experiences+on+Facebook)|0|
|[A Test Collection of Synthetic Documents for Training Rankers: ChatGPT vs. Human Experts](https://doi.org/10.1145/3583780.3615111)|Arian Askari, Mohammad Aliannejadi, Evangelos Kanoulas, Suzan Verberne|University of Amsterdam, Amsterdam, Netherlands; LIACS, Leiden University, Leiden, Netherlands; Leiden Institute of Advanced Computer Science, Leiden University, Leiden, Netherlands|In this resource paper, we investigate the usefulness of generative Large Language Models (LLMs) in generating training data for cross-encoder re-rankers in a novel direction: generating synthetic documents instead of synthetic queries. We introduce a new dataset, ChatGPT-RetrievalQA, and compare the effectiveness of strong models fine-tuned on both LLM-generated and human-generated data. We build ChatGPT-RetrievalQA based on an existing dataset, human ChatGPT Comparison Corpus (HC3), consisting of public question collections with human responses and answers from ChatGPT. We fine-tune a range of cross-encoder re-rankers on either human-generated or ChatGPT-generated data. Our evaluation on MS MARCO DEV, TREC DL'19, and TREC DL'20 demonstrates that cross-encoder re-ranking models trained on LLM-generated responses are significantly more effective for out-of-domain re-ranking than those trained on human responses. For in-domain re-ranking, the human-trained re-rankers outperform the LLM-trained re-rankers. Our novel findings suggest that generative LLMs have high potential in generating training data for neural retrieval models and can be used to augment training data, especially in domains with smaller amounts of labeled data. We believe that our dataset, ChatGPT-RetrievalQA, presents various opportunities for analyzing and improving rankers with human and synthetic data. We release our data, code, and model checkpoints for future work.|在这篇资源论文中，我们研究了生成大语言模型(LLM)在生成交叉编码器重新排序的训练数据方面的有用性: 生成合成文档而不是合成查询。我们引入了一个新的数据集 ChatGPT-RetrievalQA，并比较了对 LLM 生成的数据和人类生成的数据进行微调的强模型的有效性。我们基于现有的数据集，人类 ChatGPT 比较语料库(HC3)构建 ChatGPT 检索 QA，该语料库由公共问题集合和来自 ChatGPT 的答案组成。我们微调一系列的交叉编码器重新排序的人类生成或 ChatGPT 生成的数据。我们对 MS MARCO DEV，TREC DL’19和 TREC DL’20的评估表明，在 LLM 生成的响应上训练的交叉编码器重新排序模型对于域外重新排序显着比那些训练人类响应更有效。对于域内重新排序，人类训练的重新排序优于 LLM 训练的重新排序。我们的新发现表明，生成性 LLM 在为神经检索模型生成训练数据方面具有很大的潜力，可用于增强训练数据，特别是在标记数据量较小的领域。我们相信我们的数据集，ChatGPT-RetrievalQA，提供了各种机会来分析和提高排名与人类和合成数据。我们为将来的工作发布数据、代码和模型检查点。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Test+Collection+of+Synthetic+Documents+for+Training+Rankers:+ChatGPT+vs.+Human+Experts)|0|
|[Anserini Gets Dense Retrieval: Integration of Lucene's HNSW Indexes](https://doi.org/10.1145/3583780.3615112)|Xueguang Ma, Tommaso Teofili, Jimmy Lin|Roma Tre University, Rome, Italy; University of Waterloo, Waterloo, ON, Canada|Anserini is a Lucene-based toolkit for reproducible information retrieval research in Java that has been gaining traction in the community. It provides retrieval capabilities for both "traditional" bag-of-words retrieval models such as BM25 as well as retrieval using learned sparse representations such as SPLADE. With Pyserini, which provides a Python interface to Anserini, users gain access to both sparse and dense retrieval models, as Pyserini implements bindings to the Faiss vector search library alongside Lucene inverted indexes in a uniform, consistent interface. Nevertheless, hybrid fusion techniques that integrate sparse and dense retrieval models need to stitch together results from two completely different "software stacks", which creates unnecessary complexities and inefficiencies. However, the introduction of HNSW indexes for dense vector search in Lucene promises the integration of both dense and sparse retrieval within a single software framework. We explore exactly this integration in the context of Anserini. Experiments on the MS MARCO passage and BEIR datasets show that our Anserini HNSW integration supports (reasonably) effective and (reasonably) efficient approximate nearest neighbor search for dense retrieval models, using only Lucene.|Anserini 是一个基于 Lucene 的工具包，用于在 Java 中进行可重复的信息检索研究，在社区中获得了越来越多的关注。它为“传统的”单词检索模型(如 BM25)以及使用学习稀疏表示(如 SPLADE)的检索提供了检索能力。Pyserini 为 Anserini 提供了一个 Python 界面，用户可以访问稀疏和密集的检索模型，因为 Pyserini 实现了对 Faiss 矢量搜索库的绑定，以及在统一、一致的界面中的 Lucene 反向索引。然而，集成稀疏和密集检索模型的混合融合技术需要将来自两个完全不同的“软件栈”的结果拼接在一起，这造成了不必要的复杂性和效率低下。然而，在 Lucene 引入用于密集向量搜索的 HNSW 索引有望在单一软件框架内实现密集和稀疏检索的集成。我们正是在 Anserini 的背景下探讨这种一体化。对 MS MARCO 通道和 BEIR 数据集的实验表明，我们的 Anserini HNSW 集成只使用 Lucene 支持(合理地)有效和(合理地)近似最近邻搜索密集检索模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Anserini+Gets+Dense+Retrieval:+Integration+of+Lucene's+HNSW+Indexes)|0|
|[ITA-ELECTION-2022: A Multi-Platform Dataset of Social Media Conversations Around the 2022 Italian General Election](https://doi.org/10.1145/3583780.3615121)|Francesco Pierri, Geng Liu, Stefano Ceri|Politecnico di Milano, Milano, Italy|Online social media play a major role in shaping public discourse and opinion, especially during political events. We present the first public multi-platform dataset of Italian-language political conversations, focused on the 2022 Italian general election taking place on September 25th. Leveraging public APIs and a keyword-based search, we collected millions of posts published by users, pages and groups on Facebook, Instagram and Twitter, along with metadata of TikTok and YouTube videos shared on these platforms, over a period of four months. We augmented the dataset with a collection of political ads sponsored on Meta platforms, and a list of social media handles associated with political representatives. Our data resource will allow researchers and academics to further our understanding of the role of social media in the democratic process.|在线社交媒体在塑造公共话语和舆论方面发挥着重要作用，特别是在政治事件期间。我们提出了第一个公开的多平台意大利语政治对话数据集，重点是2022年意大利大选在9月25日举行。我们利用公共 API 和基于关键词的搜索，在四个月的时间里收集了 Facebook、 Instagram 和 Twitter 上用户、页面和群组发布的数百万条帖子，以及 TikTok 和 YouTube 视频在这些平台上分享的元数据。我们通过 Meta 平台上赞助的一系列政治广告以及与政治代表相关的社交媒体处理列表来扩充数据集。我们的数据资源将使研究人员和学者进一步了解社会媒体在民主进程中的作用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ITA-ELECTION-2022:+A+Multi-Platform+Dataset+of+Social+Media+Conversations+Around+the+2022+Italian+General+Election)|0|
|[Explore Epistemic Uncertainty in Domain Adaptive Semantic Segmentation](https://doi.org/10.1145/3583780.3614872)|Kai Yao, Zixian Su, Xi Yang, Jie Sun, Kaizhu Huang|Duke Kunshan University, Kunshan, China; Xi'an Jiaotong-Liverpool University, Suzhou, China; University of Liverpool & Xi'an Jiaotong-Liverpool University, Liverpool, United Kingdom|In domain adaptive segmentation, domain shift may cause erroneous high-confidence predictions on the target domain, resulting in poor self-training. To alleviate the potential error, most previous works mainly consider aleatoric uncertainty arising from the inherit data noise. This may however lead to overconfidence in incorrect predictions and thus limit the performance. In this paper, we take advantage of Deterministic Uncertainty Methods (DUM) to explore the epistemic uncertainty, which reflects accurately the domain gap depending on the model choice and parameter fitting trained on source domain. The epistemic uncertainty on target domain is evaluated on-the-fly to facilitate online reweighting and correction in the self-training process. Meanwhile, to tackle the class-wise quantity and learning difficulty imbalance problem, we introduce a novel data resampling strategy to promote simultaneous convergence across different categories. This strategy prevents the class-level over-fitting in source domain and further boosts the adaptation performance by better quantifying the uncertainty in target domain. We illustrate the superiority of our method compared with the state-of-the-art methods.|在领域自适应分割中，领域移位可能导致目标领域的高置信度预测错误，从而导致自学习效果差。为了减小潜在的误差，以往的工作主要考虑由继承数据噪声引起的任意不确定性。然而，这可能导致对错误预测的过度自信，从而限制了性能。本文利用确定性不确定性方法(DUM)对认知不确定性进行了研究，根据源域上训练的模型选择和参数拟合，准确地反映了领域间的差异。在自我训练过程中，对目标域上的认知不确定性进行动态评估，以便于在线加权和校正。同时，为了解决类别数量和学习困难不平衡的问题，我们引入了一种新的数据重采样策略，以促进不同类别之间的同时收敛。该策略防止了源域中的类级过拟合，并通过更好地量化目标域中的不确定性进一步提高了自适应性能。我们说明了我们的方法相对于最先进的方法的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explore+Epistemic+Uncertainty+in+Domain+Adaptive+Semantic+Segmentation)|0|
|[Temporal Convolutional Explorer Helps Understand 1D-CNN's Learning Behavior in Time Series Classification from Frequency Domain](https://doi.org/10.1145/3583780.3615076)|Junru Zhang, Lang Feng, Yang He, Yuhan Wu, Yabo Dong|Zhejiang University, Hangzhou, China|While one-dimensional convolutional neural networks (1D-CNNs) have been empirically proven effective in time series classification tasks, we find that there remain undesirable outcomes that could arise in their application, motivating us to further investigate and understand their underlying mechanisms. In this work, we propose a Temporal Convolutional Explorer (TCE) to empirically explore the learning behavior of 1D-CNNs from the perspective of the frequency domain. Our TCE analysis highlights that deeper 1D-CNNs tend to distract the focus from the low-frequency components leading to the accuracy degradation phenomenon, and the disturbing convolution is the driving factor. Then, we leverage our findings to the practical application and propose a regulatory framework, which can easily be integrated into existing 1D-CNNs. It aims to rectify the suboptimal learning behavior by enabling the network to selectively bypass the specified disturbing convolutions. Finally, through comprehensive experiments on widely-used UCR, UEA, and UCI benchmarks, we demonstrate that 1) TCE's insight into 1D-CNN's learning behavior; 2) our regulatory framework enables state-of-the-art 1D-CNNs to get improved performances with less consumption of memory and computational overhead.|虽然一维卷积神经网络(1D-CNN)已经被经验证明在时间序列分类任务中是有效的，但是我们发现在其应用中仍然存在可能出现的不良结果，促使我们进一步调查和理解其潜在的机制。在本研究中，我们提出了一个时间卷积探索器(TCE) ，从频率域的角度对1D-CNN 的学习行为进行实证研究。我们的 TCE 分析强调，更深的1D-CNN 往往会分散对低频分量的关注，导致精度退化现象，干扰卷积是驱动因素。然后，我们利用我们的研究结果的实际应用，并提出了一个监管框架，这可以很容易地集成到现有的1D-CNN。它的目的是纠正次优学习行为，使网络能够有选择地绕过指定的干扰卷积。最后，通过对广泛使用的 UCR，UEA 和 UCI 基准的全面实验，我们证明了1) TCE 对1D-CNN 学习行为的洞察力; 2)我们的监管框架使最先进的1D-CNN 能够以更少的内存消耗和计算开销获得改善的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Temporal+Convolutional+Explorer+Helps+Understand+1D-CNN's+Learning+Behavior+in+Time+Series+Classification+from+Frequency+Domain)|0|
|[PS-SA: An Efficient Self-Attention via Progressive Sampling for User Behavior Sequence Modeling](https://doi.org/10.1145/3583780.3615495)|Jiacen Hu, Zhangming Chan, Yu Zhang, Shuguang Han, Siyuan Lou, Baolin Liu, Han Zhu, Yuning Jiang, Jian Xu, Bo Zheng|USTB, Beijing, China; Alibaba Group, Beijing, China|As the self-attention mechanism offers powerful capabilities for capturing sequential relationships, it has become increasingly popular to use it for modeling user behavior sequences in recommender systems. However, the self-attention mechanism has a quadratic computational complexity of O(n^2), as it conducts interactions among all item pairs in the sequence. This can lead to expensive model training and slow inference speeds, which may hinder practical deployment. To this end, we pursue to develop alternative approaches to improve the efficiency of the self-attention mechanism. We observe that the attention scores calculated from each item interacting with other items (including itself) are sparse, indicating that there are limited valuable item pairs (with non-zero attention weight) that contribute to the final output. This motivates us to develop effective strategies for discerning valuable items and computing attention scores solely for these items, thereby minimizing the consumption of unnecessary computations. Herein, we present a novel Progressive Sampling-based Self-Attention (PS-SA) mechanism, which utilizes a learnable progressive sampling strategy to identify the most valuable items. Subsequently, we solely utilize these selected items to produce the final output. Experiments on academic and production datasets demonstrate PS-SA could still achieve promising results while reducing computational costs. It is notable that we have successfully deployed it on Alibaba display advertising system, resulting in a 2.6% CTR and 1.3% RPM increase.|由于自我注意机制提供了捕获序列关系的强大功能，因此在推荐系统中使用自我注意机制对用户行为序列进行建模越来越受到欢迎。然而，自我注意机制具有 O (n ^ 2)的二次计算复杂度，因为它在序列中的所有项目对之间进行交互作用。这可能导致昂贵的模型训练和缓慢的推理速度，这可能会阻碍实际部署。为此，我们寻求发展替代方法，以提高自我注意机制的效率。我们观察到，从每个项目与其他项目(包括它自己)的相互作用中计算出的注意力得分是稀疏的，表明有限的有价值的项目对(非零注意力重量)有助于最终的输出。这促使我们制定有效的策略来识别有价值的项目，并仅仅为这些项目计算注意力分数，从而最大限度地减少不必要的计算消耗。本文提出了一种新的基于递进抽样的自我注意机制(PS-SA) ，该机制利用一种可学习的递进抽样策略来识别最有价值的项目。随后，我们只利用这些选定的项目来产生最终的输出。在学术和生产数据集上的实验表明，PS-SA 在降低计算成本的同时，仍然可以取得有希望的结果。值得注意的是，我们已经成功地在阿里巴巴展示广告系统中使用了它，点击率和每分钟转速分别提高了2.6% 和1.3% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PS-SA:+An+Efficient+Self-Attention+via+Progressive+Sampling+for+User+Behavior+Sequence+Modeling)|0|
|[Delivery Optimized Discovery in Behavioral User Segmentation under Budget Constraint](https://doi.org/10.1145/3583780.3614839)|Harshita Chopra, Atanu R. Sinha, Sunav Choudhary, Ryan A. Rossi, Paavan Kumar Indela, Veda Pranav Parwatala, Srinjayee Paul, Aurghya Maiti|Adobe Research, Bangalore, India; Adobe Research, San Jose, CA, USA|Users' behavioral footprints online enable firms to discover behavior-based user segments (or, segments) and deliver segment specific messages to users. Following the discovery of segments, delivery of messages to users through preferred media channels like Facebook and Google can be challenging, as only a portion of users in a behavior segment find match in a medium, and only a fraction of those matched actually see the message (exposure). Even high quality discovery becomes futile when delivery fails. Many sophisticated algorithms exist for discovering behavioral segments; however, these ignore the delivery component. The problem is compounded because (i) the discovery is performed on the behavior data space in firms' data (e.g., user clicks), while the delivery is predicated on the static data space (e.g., geo, age) as defined by media; and (ii) firms work under budget constraint. We introduce a stochastic optimization based algorithm for delivery optimized discovery of behavioral user segments and offer new metrics to address the joint optimization. We leverage optimization under a budget constraint for delivery combined with a learning-based component for discovery. Extensive experiments on a public dataset from Google and a proprietary dataset show the effectiveness of our approach by simultaneously improving delivery metrics, reducing budget spend and achieving strong predictive performance in discovery.|用户的在线行为足迹使企业能够发现基于行为的用户段(或段) ，并向用户传递段特定的信息。随着信息片段的发现，通过 Facebook 和 Google 这样的首选媒体渠道向用户传递信息可能是一个挑战，因为在行为片段中只有一部分用户在媒介中找到匹配，而且只有一小部分匹配的用户实际上看到了信息(曝光)。当交付失败时，即使是高质量的发现也是徒劳的。存在许多发现行为片段的复杂算法; 然而，这些算法忽略了传递组件。这个问题是复杂的，因为(i)发现是在企业数据的行为数据空间(例如，用户点击)上执行的，而交付是在媒体定义的静态数据空间(例如，地理位置，年龄)上进行的; (ii)企业在预算线下工作。提出了一种基于随机优化的行为用户段发现算法，并提出了一种新的度量方法来解决联合优化问题。我们利用优化的预算线，结合基于学习的组件进行发现。对来自 Google 的公共数据集和专有数据集进行的大量实验表明，我们的方法通过同时改进交付指标、减少预算开支和在发现方面实现强大的预测性能来显示有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Delivery+Optimized+Discovery+in+Behavioral+User+Segmentation+under+Budget+Constraint)|0|
|[Understanding User Immersion in Online Short Video Interaction](https://doi.org/10.1145/3583780.3615099)|Zhiyu He, Shaorun Zhang, Peijie Sun, Jiayu Li, Xiaohui Xie, Min Zhang, Yiqun Liu|Tsinghua University, Beijing, China|Short video~(SV) online streaming has been one of the most popular Internet applications in recent years. When browsing SVs, users gradually immerse themselves and derive relaxation or knowledge. Whereas prolonged browsing will lead to a decline in positive feelings, users continue due to inertia, resulting in decreased satisfaction. Immersion is shown to be an essential factor for users' positive experience and highly related to users' interactions in film, games, and virtual reality. However, immersion in SV interaction is still unexplored, which differs from the previously studied scenarios essentially because SV delivery is fragmented, discrete, and with limited time for each video. In this paper, we aim to make an extensive understanding of user immersion in online short video interaction, include related factors, detecting possibility, and satisfaction representation. We conduct a three-step user study on real SV browsing, including an online survey, a field study, and a lab study with EEG signals. The user study reveals that immersion is a common feeling in SV interaction, and it is related to video features, personalization of recommendations, user mood, and interaction behaviors. Specifically, prolonged browsing leads to a significant decrease in immersion. Furthermore, analyses of EEG signals demonstrate that the prefrontal lobe and parietal lobe of the gamma band are associated with immersion. Besides, immersion prediction experiments achieve encouraging results, showing that user immersion status is predictable and EEG signals do help improve prediction performance. Moreover, correlation analysis indicates that the predicted immersion is more representative of user satisfaction than user behaviors, revealing the potential of immersion as an indicator of satisfaction in the recommender system. To the best of our knowledge, it is the first study on user immersion in real online SV interaction scenarios, and our findings are enlightening for SV users and recommender system designers.|短视频 ~ (SV)在线流媒体是近年来最流行的互联网应用之一。浏览 SVs 时，用户逐渐沉浸其中，从中获得放松或知识。而长时间的浏览会导致积极情绪的下降，用户继续由于惯性，导致满意度下降。沉浸被证明是一个重要因素，用户的积极体验和高度相关的用户在电影，游戏和虚拟现实的互动。然而，沉浸在 SV 交互中仍然是未知的，这与以前研究的场景不同，本质上是因为 SV 交付是零碎的，离散的，并且每个视频的时间有限。本文旨在深入了解在线短视频交互中的用户沉浸现象，包括相关因素、检测可能性、满意度表征等。我们对真实的 SV 浏览进行了三个步骤的用户研究，包括在线调查、实地研究和脑电信号的实验室研究。用户研究表明，沉浸感是 SV 交互中的一种常见感觉，它与视频特性、推荐的个性化、用户情绪和交互行为有关。具体来说，长时间的浏览会导致沉浸感的显著降低。此外，脑电信号分析表明，伽玛波段的前额叶和顶叶与浸泡有关。此外，沉浸预测实验取得了令人鼓舞的结果，表明用户沉浸状态是可预测的，脑电信号有助于提高预测性能。此外，相关分析表明，预测沉浸比用户行为更能代表用户满意度，揭示了沉浸作为推荐系统满意度指标的潜力。据我们所知，这是第一个关于用户沉浸在真实在线 SV 交互场景中的研究，我们的研究结果对于 SV 用户和推荐系统设计者都是有启发的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+User+Immersion+in+Online+Short+Video+Interaction)|0|
|[Tight-Sketch: A High-Performance Sketch for Heavy Item-Oriented Data Stream Mining with Limited Memory Size](https://doi.org/10.1145/3583780.3615080)|Weihe Li, Paul Patras|The University of Edinburgh, Edinburgh, United Kingdom|Accurate and fast data stream mining is critical and fundamental to many tasks, including time series database handling, big data management and machine learning. Different heavy-based detection tasks, such as heavy hitter, heavy changer, persistent item and significant item detection, have drawn much attention from both the industry and academia. Unfortunately, due to the growing data stream speeds and limited memory (L1 cache) available for real-time processing, existing schemes face challenges in simultaneously achieving high detection accuracy, high memory efficiency, and fast update throughput, as we reveal. To tackle this conundrum, we propose a versatile and elegant sketch framework named Tight-Sketch, which supports a spectrum of heavy-based detection tasks. Considering that most items are cold (non-heavy/persistent/significant) in practice, we employ different eviction treatments for different types of items to discard these potentially cold ones as soon as possible, and offer more protection to those that are hot (heavy/persistent/significant). In addition, we propose an eviction method that follows a stochastic decay strategy, enabling Tight-Sketch to only bear small one-sided errors (no overestimation). We present a theoretical analysis of the error bounds and conduct extensive experiments on diverse detection tasks to demonstrate that Tight-Sketch significantly outperforms existing methods in terms of accuracy and update speed. Lastly, we accelerate Tight-Sketch's update throughput by up to 36% with Single Instruction Multiple Data (SIMD) instructions.|准确、快速的数据流挖掘是时间序列数据库处理、大数据管理和机器学习等许多工作的关键和基础。不同的重基检测任务，如重点检测、重变换、持久性项目和重要项目检测等，已经引起了业界和学术界的广泛关注。不幸的是，由于不断增长的数据流速度和有限的内存(L1缓存)可用于实时处理，现有的方案在同时实现高检测精度、高内存效率和快速更新吞吐量方面面临挑战，正如我们所揭示的。为了解决这个难题，我们提出了一个通用而优雅的草图框架 Tight-Sketch，它支持一系列基于重量的检测任务。考虑到大多数物品在实践中是冷的(非重的/持久的/重要的) ，我们对不同类型的物品采用不同的驱逐处理方法，以尽快丢弃这些可能冷的物品，并为那些热的(重的/持久的/重要的)提供更多的保护。此外，我们提出了一个驱逐方法，遵循随机衰减策略，使紧凑草图只承受小的单方面误差(没有过高估计)。我们提出了一个误差界限的理论分析，并进行了广泛的实验在不同的检测任务，以证明紧致草图显着优于现有的方法在准确性和更新速度方面。最后，我们使用单指令流多数据流指令(SIMD)将 Tight-Sketch 的更新吞吐量提高了36% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tight-Sketch:+A+High-Performance+Sketch+for+Heavy+Item-Oriented+Data+Stream+Mining+with+Limited+Memory+Size)|0|
|[printf: Preference Modeling Based on User Reviews with Item Images and Textual Information via Graph Learning](https://doi.org/10.1145/3583780.3615012)|HaoLun Lin, JyunYu Jiang, MingHao Juan, PuJen Cheng|Amazon Search, Palo Alto, CA, USA; National Taiwan University, Taipei, Taiwan Roc|Nowadays, modern recommender systems usually leverage textual and visual contents as auxiliary information to predict user preference. For textual information, review texts are one of the most popular contents to model user behaviors. Nevertheless, reviews usually lose their shine when it comes to top-N recommender systems because those that solely utilize textual reviews as features struggle to adequately capture the interaction relationships between users and items. For visual one, it is usually modeled with naive convolutional networks and also hard to capture high-order relationships between users and items. Moreover, previous works did not collaboratively use both texts and images in a proper way. In this paper, we propose printf, preference modeling based on user reviews with item images and textual information via graph learning, to address the above challenges. Specifically, the dimension-based attention mechanism directs relations between user reviews and interacted items, allowing each dimension to contribute different importance weights to derive user representations. Extensive experiments are conducted on three publicly available datasets. The experimental results demonstrate that our proposed printf consistently outperforms baseline methods with the relative improvements for NDCG@5 of 26.80%, 48.65%, and 25.74% on Amazon-Grocery, Amazon-Tools, and Amazon-Electronics datasets, respectively. The in-depth analysis also indicates the dimensions of review representations definitely have different topics and aspects, assisting the validity of our model design.|现代推荐系统通常利用文本和可视化内容作为辅助信息来预测用户偏好。对于文本信息来说，评论文本是建立用户行为模型最常用的内容之一。尽管如此，当涉及到排名前 N 的推荐系统时，评论通常会失去它们的光芒，因为那些仅仅利用文本评论作为特性的系统很难充分捕捉到用户和项目之间的交互关系。对于可视化模型，它通常使用天真的卷积网络进行建模，并且很难捕捉用户和项目之间的高阶关系。此外，以前的作品没有合作使用文本和图像在适当的方式。针对上述挑战，本文提出了基于用户评论的 printf 偏好建模方法，该方法通过图形学习，利用项目图像和文本信息建立用户评论的 printf 偏好模型。具体来说，基于维度的注意机制指导用户评论和交互项目之间的关系，允许每个维度贡献不同的重要性权重来推导用户表示。在三个公开的数据集上进行了广泛的实验。实验结果表明，我们提出的 printf 始终优于基线方法，分别在 Amazon-Grocery，Amazon-Tools 和 Amazon-Electronics 数据集上对 NDCG@5的相对改进分别为26.80% ，48.65% 和25.74% 。深入的分析还表明，评论表征的维度肯定有不同的主题和方面，有助于我们的模型设计的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=printf:+Preference+Modeling+Based+on+User+Reviews+with+Item+Images+and+Textual+Information+via+Graph+Learning)|0|
|[The Role of Unattributed Behavior Logs in Predictive User Segmentation](https://doi.org/10.1145/3583780.3615078)|Atanu R. Sinha, Harshita Chopra, Aurghya Maiti, Atishay Ganesh, Sarthak Kapoor, Saili Myana, Saurabh Mahapatra|Adobe Inc., San Jose, USA; Adobe Research, Bangalore, India|Online browsing on firms' sites generates user behavior logs (or, logs). These logs are mainstays that drive several user modeling tasks. The logs that inform user modeling are the ones that are attributed to each user, termed Attributed Behaviors (AB). But, a lot more logs are anonymous, upwards of 85%. For example, many users do not sign in while browsing. These logs are not attributed to users, termed Unattributed Behaviors (UB), and are not recognized in user modeling. We examine whether and how UB can benefit user modeling. We focus on a common task, that of user segmentation, for which the prior art uses only AB. We demonstrate that information from UBs, although unattributed to any individual, when used along with ABs, enriches performance of machine learning model for user segmentation. We perform predictive segmentation, whereby predicted outcomes for each segment are evaluated against actual outcomes. Multiple evaluations on two datasets, one of which is public, relative to state of the art baseline, show strong performance of our model in predicting outcomes and in reducing user segmentation error.|在线浏览公司网站会产生用户行为日志(或者，日志)。这些日志是驱动多个用户建模任务的支柱。通知用户建模的日志是属于每个用户的日志，称为归属行为(AttributedBehavior，AB)。但是，更多的日志是匿名的，高达85% 。例如，许多用户在浏览时不登录。这些日志不属于用户，称为非属性化行为(UB) ，并且在用户建模中不被识别。我们研究 UB 是否以及如何有利于用户建模。我们的重点是一个共同的任务，即用户分割，其中现有的技术只使用 AB。我们证明了来自 UB 的信息虽然不属于任何个体，但是当与 ABs 一起使用时，丰富了用户分割的机器学习模型的性能。我们进行预测性分割，即根据实际结果评估每个部分的预测结果。对两个数据集(其中一个是公开的)的多重评估相对于最先进的基线，显示了我们的模型在预测结果和减少用户分割误差方面的强大性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Role+of+Unattributed+Behavior+Logs+in+Predictive+User+Segmentation)|0|
|[Treatment Effect Estimation across Domains](https://doi.org/10.1145/3583780.3615096)|YiXuan Sun, YaLin Zhang, Wei Wang, Longfei Li, Jun Zhou|Nanjing University, Nanjing, China; Ant Group, Hangzhou, China|Treatment effect estimation is essential in the causal inference literature, which has attracted increasing attention in recent years. Most previous methods assume that the training and test data are drawn from the same distribution, which may not hold in practice since the effect estimators may need to be deployed across domains. Meanwhile, in real-world applications, little or no targeted treatments may be conducted in the new domain. Therefore, we focus on a more realistic scenario in this paper, where treatments and outcomes can be observed in the source domain, but the target domain only contains some unlabeled data, i.e., only features are available. In this scenario, thedistribution shift exists not only in the source data due to the selection bias between the control and treated groups, but also between the source and target data. We propose a novel direct learning framework along with the distribution adaptation and reliable scoring modules. In the distribution adaptation module, we design three specialized density ratio estimators to aid the issue of complex distribution shifts. Even so, we may face the challenge of unreliable pseudo-effects in this framework. To address that, we also design the uncertainty-based reliable scoring module as a vital support, which makes the method more reliable. The experiments are conducted on synthetic data and benchmark datasets, which demonstrate the superiority of our method.|治疗效果评估是因果推理文献中必不可少的内容，近年来受到越来越多的关注。大多数以前的方法假定训练和测试数据来自同一个分布，这在实践中可能不成立，因为效应估计器可能需要跨领域部署。与此同时，在现实世界的应用，很少或没有针对性的治疗可能进行了新的领域。因此，我们在本文中关注一个更加现实的场景，在这个场景中，治疗和结果可以在源域中观察到，但是目标域只包含一些未标记的数据，也就是说，只有特征可用。在这种情况下，由于控制组和治疗组之间的选择偏差，不仅源数据中存在分布偏移，而且源数据和目标数据之间也存在分布偏移。我们提出了一个新的直接学习框架，以及分布适应和可靠的评分模块。在分布自适应模块中，我们设计了三个专门的密度比估计器，以解决复杂分布移位的问题。即便如此，我们也可能面临这一框架中不可靠的伪效应的挑战。为了解决这一问题，我们还设计了基于不确定性的可靠性评分模块作为重要的支持，使得该方法更加可靠。在综合数据和基准数据集上进行了实验，验证了该方法的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Treatment+Effect+Estimation+across+Domains)|0|
|[CLOCK: Online Temporal Hierarchical Framework for Multi-scale Multi-granularity Forecasting of User Impression](https://doi.org/10.1145/3583780.3614810)|Xiaoyu Wang, Yonghui Guo, Xiaoyang Ma, Dongbo Huang, Lan Xu, Haisheng Tan, Hao Zhou, XiangYang Li|University of Science and Technology of China, Hefei, China; Tencent Advertising, Shanghai, China|User impression forecasting underpins various commercial activities, from long-term strategic decisions to short-term automated operations. As a representative that involves both kinds, the highly profitable Guaranteed Delivery (GD) advertising focuses mainly on promoting brand effect by allowing advertisers to order target impressions weeksin advance and get allocatedonline at the scheduled time. Such a business mode naturally incurs three issues making existing solutions inferior: 1) Timescale-granularity dilemma of coherently supporting the sales of day-level impressions of the distant future and the corresponding fine-grained allocation in real-time. 2) High dimensionality due to the Cartesian product of user attribute combinations. 3) Stability-plasticity dilemma of instant adaptation to emerging patterns of temporal dependency withoutcatastrophic forgetting of repeated ones facing the non-stationary traffic. To overcome the obstacles, we propose an online temporal hierarchical framework that functions analogously to a CLOCK and hence its name. Long-timescale, coarse-grained temporal data (e.g., the daily impression of one quarter) and short-timescale but fine-grained ones are handled separately by dedicated models, just like the hour/minute/second hands. Each tier in the hierarchy is triggered for forecasting and updating by need at different frequencies, thus saving the maintenance overhead. Furthermore, we devise a reconciliation mechanism to coordinate tiers by aggregating the separately learned local variance and global trends tier by tier. CLOCK solves the dimensionality dilemma by subsuming the autoencoder design to achieve an end-to-end, nonlinear factorization of streaming data into a low-dimension latent space, where a neural predictor produces predictions for the decoder to project them back to the high dimension. Lastly, we regulate the CLOCK's continual refinement by combining the complementary Experience Replay (ER) and Knowledge Distillation (KD) techniques to consolidate and recall previously learned temporal patterns. We conduct extensive evaluations on three public datasets and the real-life user impression log from the Tencent advertising system, and the results demonstrate CLOCK's efficacy.|用户印象预测是各种商业活动的基础，从长期战略决策到短期自动化操作。作为这两类广告的代表，利润丰厚的保证送达广告主要侧重于提升品牌效应，允许广告主提前订购目标印象周，并在预定时间在线分配。这种商业模式自然会产生三个问题，使得现有的解决方案相形见绌: 1)连贯支持销售遥远未来的日级印象和相应的实时细粒度分配的时间尺度-粒度困境。2)由于用户属性组合的笛卡儿积，导致维度较高。3)即时适应新兴时间依赖模式的稳定性-可塑性困境，不会灾难性遗忘面对非平稳流量的重复模式。为了克服这些障碍，我们提出了一个类似于时钟的在线时间层次结构框架。长时间尺度的粗粒度时间数据(例如，一个季度的每日印象)和短时间尺度但细粒度的数据由专用模型分别处理，就像小时/分钟/秒针一样。层次结构中的每一层都被触发，以便在不同的频率根据需要进行预测和更新，从而节省维护开销。此外，我们设计了一个协调机制，通过聚合分别学习的局部方差和全球趋势层层协调层。CLOCK 通过包含自动编码器设计来解决维度困境，实现流数据的端到端非线性因子分解到一个低维潜在空间，其中神经预测器为解码器产生预测，将它们投射回高维空间。最后，我们通过结合互补的体验重放(ER)和知识提取(KD)技术来调节时钟的持续细化，以巩固和回忆先前学习的时间模式。我们对来自腾讯广告系统的三个公共数据集和现实生活中的用户印象日志进行了广泛的评估，结果证明了时钟的功效。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CLOCK:+Online+Temporal+Hierarchical+Framework+for+Multi-scale+Multi-granularity+Forecasting+of+User+Impression)|0|
|[Optimizing Upstream Representations for Out-of-Domain Detection with Supervised Contrastive Learning](https://doi.org/10.1145/3583780.3615001)|Bo Wang, Tsunenori Mine|Kyushu University, Fukuoka, Japan|Out-of-Domain (OOD) text detection has attracted significant research interest. However, conventional approaches primarily employ Cross-Entropy loss during upstream encoder training and seldom focus on optimizing discriminative In-Domain (IND) and OOD representations. To fill this gap, we introduce a novel method that applies supervised contrastive learning (SCL) to IND data for upstream representation optimization. This effectively brings the embeddings of semantically similar texts together while pushing dissimilar ones further apart, leading to more compact and distinct IND representations. This optimization subsequently improves the differentiation between IND and OOD representations, thereby enhancing the detection effect in downstream tasks. To further strengthen the ability of SCL to consolidate IND embedding clusters, and to improve the generalizability of the encoder, we propose a method that generates two different variations of the same text as "views". This is achieved by applying a twice "dropped-out" on the embeddings before performing SCL. Extensive experiments indicate that our method not only outperforms state-of-the-art approaches, but also reduces the requirement for training a large 354M-parameter model down to a more efficient 110M-parameter model, highlighting its superiority in both effectiveness and computational economy.|域外(OOD)文本检测已经引起了人们的极大兴趣。然而，传统的方法主要使用交叉熵损失在上游编码器训练，很少重点优化区分在域(IND)和面向对象的表示。为了填补这一空白，我们提出了一种新的方法，将监督对比学习(SCL)应用于 IND 数据的上游表示优化。这有效地将语义相似的文本嵌入在一起，同时将不同的文本进一步分离，从而产生更紧凑、更独特的 IND 表示。这种优化随后改进了 IND 和 OOD 表示之间的区别，从而增强了下游任务的检测效果。为了进一步增强 SCL 对 IND 嵌入簇的整合能力，提高编码器的通用性，提出了一种生成同一文本中“视图”的两种不同变体的方法。这是通过在执行 SCL 之前对嵌入应用两次“退出”来实现的。大量实验表明，该方法不仅优于最新的方法，而且降低了对大型354M 参数模型的训练要求，使其降低到更高效的110M 参数模型，突出了其在有效性和计算经济性方面的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimizing+Upstream+Representations+for+Out-of-Domain+Detection+with+Supervised+Contrastive+Learning)|0|
|[Dual Intents Graph Modeling for User-centric Group Discovery](https://doi.org/10.1145/3583780.3614855)|Xixi Wu, Yun Xiong, Yao Zhang, Yizhu Jiao, Jiawei Zhang|University of California, Davis, Davis, CA, USA; University of Illinois at Urbana-Champaign, Champaign, IL, USA; Fudan University, Shanghai, China|Online groups have become increasingly prevalent, providing users with space to share experiences and explore interests. Therefore, user-centric group discovery task, i.e., recommending groups to users can help both users' online experiences and platforms' long-term developments. Existing recommender methods can not deal with this task as modeling user-group participation into a bipartite graph overlooks their item-side interests. Although there exist a few works attempting to address this task, they still fall short in fully preserving the social context and ensuring effective interest representation learning. In this paper, we focus on exploring the intents that motivate users to participate in groups, which can be categorized into different types, like the social-intent and the personal interest-intent. The former refers to users joining a group affected by their social links, while the latter relates to users joining groups with like-minded people for self-enjoyment. To comprehend different intents, we propose a novel model, DiRec, that first models each intent separately and then fuses them together for predictions. Specifically, for social-intent, we introduce the hypergraph structure to model the relationship between groups and members, leading to a richer understanding of the social context. As for interest-intent, we employ novel structural refinement on the interactive graph to uncover more intricate user behaviors and group interests, realizing better representation learning of interests. Furthermore, we also observe the intent overlapping in real-world scenarios and devise a novel self-supervised learning loss that encourages such alignment for final recommendations. Extensive experiments on three public datasets show the significant improvement of DiRec over the state-of-the-art methods.|在线小组已经变得越来越普遍，为用户提供了分享经验和探索兴趣的空间。因此，以用户为中心的群组发现任务，即向用户推荐群组，可以帮助用户的在线体验和平台的长期发展。现有的推荐方法无法处理这个任务，因为将用户组参与建模成二分图忽略了它们的项目侧兴趣。虽然有一些工作试图解决这一任务，但他们仍然不能充分保存的社会背景和确保有效的兴趣表征学习。本文着重探讨了激发用户参与群体的意图，这些意图可以分为社会意图和个人兴趣意图。前者是指使用者加入一个受其社交联系影响的群组，而后者是指使用者加入与志同道合者的群组以自娱自乐。为了理解不同的意图，我们提出了一个新的模型，DiRec，它首先分别模拟每个意图，然后将它们融合在一起进行预测。具体地说，对于社会意图，我们引入超图结构来建模群体和成员之间的关系，从而更加丰富地理解社会背景。对于兴趣意图，我们在交互图上采用了新颖的结构细化方法，以揭示更复杂的用户行为和群体兴趣，实现更好的兴趣表示学习。此外，我们还观察到在现实世界的情况下意图重叠，并设计了一种新的自我监督学习丢失，鼓励这种调整为最终的建议。在三个公共数据集上的大量实验表明，DiRec 相对于最先进的方法有显著的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual+Intents+Graph+Modeling+for+User-centric+Group+Discovery)|0|
|[DSformer: A Double Sampling Transformer for Multivariate Time Series Long-term Prediction](https://doi.org/10.1145/3583780.3614851)|Chengqing Yu, Fei Wang, Zezhi Shao, Tao Sun, Lin Wu, Yongjun Xu|Institute of Computing Technology, Chinese Academy of Sciences & University of Chinese Academy of Sciences, Beijing, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China|Multivariate time series long-term prediction, which aims to predict the change of data in a long time, can provide references for decision-making. Although transformer-based models have made progress in this field, they usually do not make full use of three features of multivariate time series: global information, local information, and variables correlation. To effectively mine the above three features and establish a high-precision prediction model, we propose a double sampling transformer (DSformer), which consists of the double sampling (DS) block and the temporal variable attention (TVA) block. Firstly, the DS block employs down sampling and piecewise sampling to transform the original series into feature vectors that focus on global information and local information respectively. Then, TVA block uses temporal attention and variable attention to mine these feature vectors from different dimensions and extract key information. Finally, based on a parallel structure, DSformer uses multiple TVA blocks to mine and integrate different features obtained from DS blocks respectively. The integrated feature information is passed to the generative decoder based on a multi-layer perceptron to realize multivariate time series long-term prediction. Experimental results on nine real-world datasets show that DSformer can outperform eight existing baselines.|多变量时间序列长期预测旨在预测数据在较长时间内的变化，可以为决策提供参考。虽然基于变压器的模型在这方面取得了一定的进展，但是它们往往没有充分利用多变量时间序列的三个特征: 全局信息、局部信息和变量相关性。为了有效地挖掘上述三个特征，建立高精度的预测模型，提出了一种双采样变压器(DSformer) ，它由双采样(DS)块和时变注意(TVA)块组成。首先，DS 块采用下采样和分段采样的方法，将原始序列分别转换成全局信息和局部信息的特征向量。然后，TVA 块利用时间注意和变量注意从不同维度挖掘特征向量，提取关键信息。最后，在并行结构的基础上，采用多个 TVA 块分别挖掘和集成 DS 块获得的不同特征。将集成的特征信息传递给基于多层感知器的生成解码器，实现多变量时间序列的长期预测。在九个实际数据集上的实验结果表明，DSformer 的性能优于现有的八个基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DSformer:+A+Double+Sampling+Transformer+for+Multivariate+Time+Series+Long-term+Prediction)|0|
|[Manipulating Out-Domain Uncertainty Estimation in Deep Neural Networks via Targeted Clean-Label Poisoning](https://doi.org/10.1145/3583780.3614957)|Huimin Zeng, Zhenrui Yue, Yang Zhang, Lanyu Shang, Dong Wang|University of Illinois Urbana-Champaign, Urbana-Champaign, IL, USA|Robust out-domain uncertainty estimation has gained growing attention for its capacity of providing adversary-resistant uncertainty estimates on out-domain samples. However, existing work on robust uncertainty estimation mainly focuses on evasion attacks that happen during test time. The threat of poisoning attacks against uncertainty models is largely unexplored. Compared to evasion attacks, poisoning attacks do not necessarily modify test data, and therefore, would be more practical in real-world applications. In this work, we systematically investigate the robustness of state-of-the-art uncertainty estimation algorithms against data poisoning attacks, with the ultimate objective of developing robust uncertainty training methods. In particular, we focus on attacking the out-domain uncertainty estimation. Under the proposed attack, the training process of models is affected. A fake high-confidence region is established around the targeted out-domain sample, which originally would have been rejected by the model due to low confidence. More fatally, our attack is clean-label and targeted: it leaves the poisoned data with clean labels and attacks a specific targeted test sample without degrading the overall model performance. We evaluate the proposed attack on several image benchmark datasets and a real-world application of COVID-19 misinformation detection. The extensive experimental results on different tasks suggest that the state-of-the-art uncertainty estimation methods could be extremely vulnerable and easily corrupted by our proposed attack.|鲁棒域外不确定性估计由于具有提供域外样本抗对手攻击不确定性估计的能力而受到越来越多的关注。然而，现有的鲁棒不确定性估计工作主要集中在测试期间发生的规避攻击。针对不确定性模型的中毒攻击的威胁在很大程度上尚未得到探索。与规避攻击相比，中毒攻击不一定会修改测试数据，因此在实际应用中会更加实用。在这项工作中，我们系统地研究了最先进的不确定性估计算法对数据中毒攻击的鲁棒性，最终目标是开发鲁棒的不确定性训练方法。特别地，我们重点攻击域外不确定性估计。在所提出的攻击下，模型的训练过程会受到影响。在目标域外样本周围建立一个假的高置信区域，这个区域原本会因为低置信度而被模型拒绝。更致命的是，我们的攻击是干净标签和有针对性的: 它使被污染的数据保持干净标签，并攻击特定的目标测试样本，而不会降低整体模型性能。我们评估了针对几个图像基准数据集的攻击，以及2019冠状病毒疾病错误信息检测的实际应用。在不同任务上的广泛实验结果表明，最先进的不确定性估计方法可能是极其脆弱的，很容易受到我们提出的攻击。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Manipulating+Out-Domain+Uncertainty+Estimation+in+Deep+Neural+Networks+via+Targeted+Clean-Label+Poisoning)|0|
|[All about Sample-Size Calculations for A/B Testing: Novel Extensions & Practical Guide](https://doi.org/10.1145/3583780.3614779)|Jing Zhou, Jiannan Lu, Anas Shallah|Apple, Cupertino, CA, USA; Apple, Seattle, WA, USA|While there exists a large amount of literature on the general challenges and best practices for trustworthy online A/B testing, there are limited studies on sample size estimation, which plays a crucial role in trustworthy and efficient A/B testing that ensures the resulting inference has a sufficient power and type I error control. For example, when sample size is under-estimated, the statistical inference, even with the correct analysis methods, will not be able to detect the true significant improvement leading to misinformed and costly decisions. This paper addresses this fundamental gap by developing new sample size calculation methods for correlated data, as well as absolute vs. relative treatment effects, both ubiquitous in online experiments. Additionally, we address a practical question of the minimal observed difference that will be statistically significant and how it relates to average treatment effect and sample size calculation. All proposed methods are accompanied by mathematical proofs, illustrative examples, and simulations. We end by sharing some best practices on various practical topics on sample size calculation and experimental design.|尽管存在大量关于可信的在线 A/B 测试的一般挑战和最佳实践的文献，但是关于样本量估计的研究有限，这在可信和高效的 A/B 测试中起着关键作用，确保所得到的推断具有足够的功效和 I 型错误控制。例如，当样本数量被低估时，即使使用正确的分析方法，推论统计学也无法发现导致错误信息和昂贵决策的真正显著改善。本文通过开发新的相关数据样本量计算方法，以及在线实验中普遍存在的绝对与相对处理效应，解决了这一根本性差距。此外，我们解决了一个实际问题，即观察到的最小差异将具有统计学意义，以及它如何与平均治疗效果和样本量计算有关。所有提出的方法都伴随着数学证明，说明性的例子，和模拟。最后，我们分享了一些关于样本量计算和实验设计的实际问题的最佳实践。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=All+about+Sample-Size+Calculations+for+A/B+Testing:+Novel+Extensions+&+Practical+Guide)|0|
|[Enhancing Information Diffusion Prediction with Self-Supervised Disentangled User and Cascade Representations](https://doi.org/10.1145/3583780.3615230)|Zhangtao Cheng, Wenxue Ye, Leyuan Liu, Wenxin Tai, Fan Zhou|University of Electronic Science and Technology of ChinaUniversity of Electronic Science and Technology of China & Kash Instiute of Electronics and Information Industry, Chengdu & Kashgar, China; University of Electronic Science and Technology of China & Kash Instiute of Electronics and Information Industry, Chengdu & Kashgar, China; University of Electronic Science and Technology of China, Chengdu, China|Accurately predicting information diffusion is critical for a vast range of applications. Existing methods generally consider user re-sharing behaviors to be driven by a single intent, and/or assume cascade temporal influence to be unchanged, which might not be consistent with real-world scenarios. To address these issues, we propose a self-supervised disentanglement framework (DisenIDP) for information diffusion prediction. First, we construct intent-aware hypergraphs to capture users' potential intents from different perspectives, and then perform the light hypergraph convolution to adaptively activate disentangled intents. Second, we extract long-term and short-term cascade influence via independent attention-based encoders. Finally, we set a self-supervised disentanglement task to alleviate the information loss and learn better-disentanglement representations. Extensive experiments conducted on two real-world social datasets demonstrate that DisenIDP outperforms state-of-the-art models across several settings.|准确预测信息扩散对于广泛的应用至关重要。现有的方法通常认为用户重新共享行为是由单一意图驱动的，并且/或者假定级联时间影响不变，这可能与现实世界的情况不一致。为了解决这些问题，我们提出了一个用于信息扩散预测的自监督解缠框架(DisenIDP)。首先构造意图感知超图，从不同角度捕捉用户的潜在意图，然后进行光超图卷积，自适应地激活解纠缠意图。其次，通过独立的基于注意的编码器提取长期和短期的级联影响。最后，我们设置了一个自我监督的解缠任务，以减轻信息丢失和学习更好的解缠表示。在两个真实世界的社会数据集上进行的大量实验表明，DisenIDP 在几个设置中的表现优于最先进的模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Information+Diffusion+Prediction+with+Self-Supervised+Disentangled+User+and+Cascade+Representations)|0|
|[Unlocking the Potential of User Feedback: Leveraging Large Language Model as User Simulators to Enhance Dialogue System](https://doi.org/10.1145/3583780.3615220)|Zhiyuan Hu, Yue Feng, Anh Tuan Luu, Bryan Hooi, Aldo Lipani|University College London, London, United Kingdom; Nanyang Technological University,, Singapore, Singapore; National University of Singapore, Singapore, Singapore|Dialogue systems and large language models (LLMs) have gained considerable attention. However, the direct utilization of LLMs as task-oriented dialogue (TOD) models has been found to underperform compared to smaller task-specific models. Nonetheless, it is crucial to acknowledge the significant potential of LLMs and explore improved approaches for leveraging their impressive abilities. Motivated by the goal of leveraging LLMs, we propose an alternative approach called User-Guided Response Optimization (UGRO) to combine it with a smaller TOD model. This approach uses LLM as annotation-free user simulator to assess dialogue responses, combining them with smaller fine-tuned end-to-end TOD models. By utilizing the satisfaction feedback generated by LLMs, UGRO further optimizes the supervised fine-tuned TOD model. Specifically, the TOD model takes the dialogue history as input and, with the assistance of the user simulator's feedback, generates high-satisfaction responses that meet the user's requirements. Through empirical experiments on two TOD benchmarks, we validate the effectiveness of our method. The results demonstrate that our approach outperforms previous state-of-the-art (SOTA) results.|对话系统和大语言模型(LLM)已经引起了人们的广泛关注。然而，直接利用 LLM 作为任务导向对话(TOD)模型被发现表现不如较小的任务特定模型。尽管如此，承认 LLM 的巨大潜力并探索利用其令人印象深刻的能力的改进方法是至关重要的。受到利用 LLM 目标的激励，我们提出了一种称为用户引导响应优化(UGRO)的替代方法，将其与较小的 TOD 模型相结合。这种方法使用 LLM 作为无注释的用户模拟器来评估对话响应，并将它们与较小的经过微调的端到端 TOD 模型相结合。通过利用 LLM 产生的满意度反馈，UGRO 进一步优化了监督微调 TOD 模型。具体来说，TOD 模型以对话历史为输入，在用户模拟器反馈的帮助下，产生满足用户需求的高满意度响应。通过对两个 TOD 基准的实验，验证了该方法的有效性。结果表明，我们的方法优于以前的最先进的(SOTA)结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unlocking+the+Potential+of+User+Feedback:+Leveraging+Large+Language+Model+as+User+Simulators+to+Enhance+Dialogue+System)|0|
|[Training Heterogeneous Graph Neural Networks using Bandit Sampling](https://doi.org/10.1145/3583780.3615276)|TaYang Wang, Rajgopal Kannan, Viktor K. Prasanna|University of Southern California, Los Angeles, CA, USA; DEVCOM Army Research Lab, Los Angeles, CA, USA|Graph neural networks (GNNs) have gained significant attention across diverse areas due to their superior performance in learning graph representations. While GNNs exhibit superior performance compared to other methods, they are primarily designed for homogeneous graphs, where all nodes and edges are of the same type. Training a GNN model for large-scale graphs incurs high computation and storage costs, especially when considering the heterogeneous structural information of each node. To address the demand for efficient GNN training, various sampling methods have been proposed. In this paper, we propose a sampling method based on bandit sampling, an online learning algorithm with provable convergence under weak assumptions on the learning objective. To the best of our knowledge, this is the first bandit-based sampling method applied to heterogeneous GNNs with a theoretical guarantee. The main idea is to prioritize node types with more informative connections with respect to the learning objective. Compared with existing techniques for GNN training on heterogeneous graphs, extensive experiments using the Open Academic Graph (OAG) dataset demonstrate that our proposed method outperforms the state-of-the-art in terms of the runtime across various tasks with a speed-up of 1.5-2x, while achieving similar accuracy.|图神经网络(GNN)由于其在学习图表示方面的优越性能，在各个领域得到了广泛的关注。虽然 GNN 表现出比其他方法更好的性能，但它们主要是为同质图设计的，其中所有节点和边都是相同类型的。针对大规模图的 GNN 模型的训练需要很高的计算和存储成本，尤其是在考虑每个节点的异构结构信息时。为了满足有效的 GNN 训练需求，提出了多种抽样方法。本文提出了一种基于强盗抽样的抽样方法，这是一种在学习目标弱假设下具有可证明收敛性的在线学习算法。据我们所知，这是第一个基于强盗的抽样方法应用于异构 GNN 的理论保证。其主要思想是优先考虑与学习目标有更多信息联系的节点类型。与现有的在异构图上进行 GNN 训练的技术相比，使用开放学术图(OAG)数据集的大量实验表明，我们提出的方法在不同任务的运行时间方面优于最先进的技术，速度提高了1.5 -2倍，同时达到了类似的精度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Training+Heterogeneous+Graph+Neural+Networks+using+Bandit+Sampling)|0|
|[Robust User Behavioral Sequence Representation via Multi-scale Stochastic Distribution Prediction](https://doi.org/10.1145/3583780.3614714)|Chilin Fu, Weichang Wu, Xiaolu Zhang, Jun Hu, Jing Wang, Jun Zhou|Ant Group, Hangzhou, China; AntGroup, Hangzhou, China|User behavior representation learned by self-supervised pre-training tasks is widely used in various domains and applications. Conventional methods usually follow the methodology in Natural Language Processing (NLP) to set the pre-training tasks. They either randomly mask some of the behaviors in the sequence and predict the masked ones or predict the next k behaviors. These methods fit for text sequence, in which the tokens are sequentially arranged subject to linguistic criterion. However, the user behavior sequences can be stochastic with noise and randomness. The same paradigm is intractable for learning a robust user behavioral representation. Though the next user behavior can be stochastic, the behavior distribution over a period of time is much more stable and less noisy. Based on this, we propose a Multi-scale Stochastic Distribution Prediction (MSDP) algorithm for learning robust user behavioral sequence representation. Instead of using predictions on concrete behavior as pre-training tasks, we take the prediction on user's behaviors distribution over a period of time as the self-supervision signal. Moreover, inspired by the recent success of the multi-task prompt training method on Large Language Models (LLM), we propose using the window size of the predicted time period as a prompt, enabling the model to learn user behavior representations that can be applied to prediction tasks across various future time periods. We generate different window size prompts through stochastic sampling. It effectively improves the generalization capability of the learned sequence representation. Extensive experiments demonstrate that our approach can learn robust user behavior representation successfully, which significantly outperforms state-of-the-art (SOTA) baselines.|自监督预训练任务学习的用户行为表示在各个领域和应用中得到了广泛的应用。传统的方法通常遵循自然语言处理(NLP)的方法来设置预训练任务。他们要么随机掩盖序列中的一些行为并预测掩盖的行为，要么预测下一个 k 行为。这些方法适用于符号按照语言规范顺序排列的文本序列。然而，用户行为序列具有随机性和噪声性。同样的范例对于学习一个健壮的用户行为表示是难以实现的。虽然下一个用户行为可能是随机的，但是在一段时间内的行为分布更加稳定，噪声更小。在此基础上，提出了一种学习鲁棒用户行为序列表示的多尺度随机分布预测(MSDP)算法。我们不再把对具体行为的预测作为训练前的任务，而是把对用户一段时间内行为分布的预测作为自我监督的信号。此外，受到最近大型语言模型(LLM)多任务提示训练方法的成功启发，我们建议使用预测时间段的窗口大小作为提示，使模型能够学习用户行为表示，可以应用于未来不同时间段的预测任务。我们通过随机抽样产生不同的窗口大小提示。有效地提高了学习序列表示的泛化能力。大量的实验表明，我们的方法可以学习鲁棒的用户行为表示成功，这显着优于国家的最先进的(SOTA)基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+User+Behavioral+Sequence+Representation+via+Multi-scale+Stochastic+Distribution+Prediction)|0|
|[Addressing Selection Bias in Computerized Adaptive Testing: A User-Wise Aggregate Influence Function Approach](https://doi.org/10.1145/3583780.3615455)|Soonwoo Kwon, Sojung Kim, Seunghyun Lee, JinYoung Kim, Suyeong An, Kyuseok Kim|Riiid AI Research, Seoul, Republic of Korea; Riiid AI Research, Seoul, South Korea|Computerized Adaptive Testing (CAT) is a widely used, efficient test mode that adapts to the examinee's proficiency level in the test domain. CAT requires pre-trained item profiles, for CAT iteratively assesses the student real-time based on the registered items' profiles, and selects the next item to administer using candidate items' profiles. However, obtaining such item profiles is a costly process that involves gathering a large, dense item-response data, then training a diagnostic model on the collected data. In this paper, we explore the possibility of leveraging response data collected in the CAT service. We first show that this poses a unique challenge due to the inherent selection bias introduced by CAT, i.e., more proficient students will receive harder questions. Indeed, when naively training the diagnostic model using CAT response data, we observe that item profiles deviate significantly from the ground-truth. To tackle the selection bias issue, we propose the user-wise aggregate influence function method. Our intuition is to filter out users whose response data is heavily biased in an aggregate manner, as judged by how much perturbation the added data will introduce during parameter estimation. This way, we may enhance the performance of CAT while introducing minimal bias to the item profiles. We provide extensive experiments to demonstrate the superiority of our proposed method based on the three public datasets and one dataset that contains real-world CAT response data.||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Addressing+Selection+Bias+in+Computerized+Adaptive+Testing:+A+User-Wise+Aggregate+Influence+Function+Approach)|0|
|[The Price is Right: Removing A/B Test Bias in a Marketplace of Expirable Goods](https://doi.org/10.1145/3583780.3615502)|Thu Le, Alex Deng|Airbnb, San Francisco, CA, USA; Airbnb, Seattle, WA, USA|Pricing Guidance tools at Airbnb aim to help hosts maximize the earning for each night of stay. For a given listing, the earning-maximization price point of a night can vary greatly with lead-day - the number of days from now until the night of stay. This introduces systematic bias in running marketplace A/B tests to compare the performances of two pricing strategies. Lead-day bias can cause the short-term experiment result to move in the opposite direction to the long-term impact, possibly leading to the suboptimal business decision and customer dissatisfaction. We propose an efficient experimentation approach that corrects for the bias, minimizes the possible negative impact of experimenting, and greatly accelerates the R&D cycle. This paper is the first of its kind to lays out the theoretical framework along with the real-world example that demonstrates the magnitude of the bias. It serves as a conversation starter for such insidious type of experimentation bias that is likely present in other marketplaces of expirable goods such as vacation nights, car rentals, and airline tickets, concert passes, or ride-hailings.||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Price+is+Right:+Removing+A/B+Test+Bias+in+a+Marketplace+of+Expirable+Goods)|0|
|[Optimal Real-Time Bidding Strategy for Position Auctions in Online Advertising](https://doi.org/10.1145/3583780.3614727)|Weitong Ou, Bo Chen, Weiwen Liu, Xinyi Dai, Weinan Zhang, Wei Xia, Xuan Li, Ruiming Tang, Yong Yu|Huawei Noah's Ark Lab, Nanjing, China; Shanghai Jiao Tong University, Shanghai, China; Huawei Noah's Ark Lab, Shenzhen, China|Position auctions are widely studied in the context of sponsored search advertising, where multiple ad slots are sold in a single auction. In traditional sponsored search, bids are submitted at the keyword level, while recent works have explored transitioning to impression-level bidding using Real-Time Bidding (RTB) techniques to achieve finer bidding. However, position auctions introduce varying user appeal across different positions and more dynamic auction landscape, which RTB, originally devised for single-slot display advertising, fails to address adequately. In this work, we are the first to study the optimal bidding strategy for position auctions in RTB. The position auctions we study belong to a broader class, including both sponsored search and display advertising with multiple ad slots. In particular, we aim at maximizing the advertising value within the budget constraint for an advertiser. We mathematically formulate the problem with explicit modeling of position effects. By leveraging the Lagrange multiplier, we derive the optimal bid price and prove its uniqueness under mild assumptions. Efficient numeric methods are applied to obtain the solution practically. Extensive experiments are conducted on a public semi-synthetic dataset and a private industry dataset to validate the effectiveness and feasibility in practice.||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimal+Real-Time+Bidding+Strategy+for+Position+Auctions+in+Online+Advertising)|0|
|[STREAMER 3.0: Towards Online Monitoring and Distributed Learning](https://doi.org/10.1145/3583780.3614755)|Baudouin Naline, Sandra GarciaRodriguez, Karine Zeitouni|DAVID Lab, University of Versailles, University of Paris-Saclay, Versailles, France; Université Paris-Saclay, CEA, List, Saclay, France|Applications that generate continuous data have proliferated in recent years, and thus the challenge of processing those data streams has emerged. This requires Data Stream Processing frameworks with monitoring capabilities able to detect and react to any non-desired situation. Many streaming use cases deal with distributed sources of data which, for privacy and communication saving purposes, need to be tackled in a distributed manner. Based on the mentioned challenges, this paper presents STREAMER 3.0, an improvement on the former data stream framework with two new modules: (i) a monitoring manager with detection algorithms, alert raising and automatic model updater; and (ii) a distributed learning module relying on federated learning. We showcase these new functionalities with an example of remaining useful life estimation of turbofan engines using an LSTM.||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=STREAMER+3.0:+Towards+Online+Monitoring+and+Distributed+Learning)|0|
|[Proactive Streaming Analytics at Scale: A Journey from the State-of-the-art to a Production Platform](https://doi.org/10.1145/3583780.3615293)|Nikos Giatrakos, Elias Alevizos, Antonios Deligiannakis, Ralf Klinkenberg, Alexander Artikis|Technical University of Crete, Chania, Greece; National Centre for Scientific Research Demokritos, Agia Paraskevi, Greece; Altair Engineering GmbH, Dortmund, Germany|Proactive streaming analytics continuously extract real-time business value from massive data that stream in data centers or clouds. This requires (a) to process the data while they are still in motion; (b) to scale the processing to multiple machines, often over various, dispersed computer clusters, with diverse Big Data technologies; and (c) to forecast complex business events for proactive decision-making. Combining the necessary facilities for proactive streaming analytics at scale entails: (I) deep knowledge of the relevant state-of-the-art, (II) cherry-picking cutting edge research outcomes based on desired features and with the prospect of building interoperable components, and (III) building components and deploying them into a holistic architecture within a real-world platform. In this tutorial, we drive the audience through the whole journey from (I) to (III), delivering cutting edge research into a commercial analytics platform, for which we provide a hands-on experience.||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Proactive+Streaming+Analytics+at+Scale:+A+Journey+from+the+State-of-the-art+to+a+Production+Platform)|0|
|[Generalization Bound for Estimating Causal Effects from Observational Network Data](https://doi.org/10.1145/3583780.3614892)|Ruichu Cai, Zeqin Yang, Weilin Chen, Yuguang Yan, Zhifeng Hao|Guangdong University of Technology, Guangzhou, China; Shantou University, Shantou, China|Estimating causal effects from observational network data is a significant but challenging problem. Existing works in causal inference for observational network data lack an analysis of the generalization bound, which can theoretically provide support for alleviating the complex confounding bias and practically guide the design of learning objectives in a principled manner. To fill this gap, we derive a generalization bound for causal effect estimation in network scenarios by exploiting 1) the reweighting schema based on joint propensity score and 2) the representation learning schema based on Integral Probability Metric (IPM). We provide two perspectives on the generalization bound in terms of reweighting and representation learning, respectively. Motivated by the analysis of the bound, we propose a weighting regression method based on the joint propensity score augmented with representation learning. Extensive experimental studies on two real-world networks with semi-synthetic data demonstrate the effectiveness of our algorithm.||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generalization+Bound+for+Estimating+Causal+Effects+from+Observational+Network+Data)|0|
|[Beyond Trading Data: The Hidden Influence of Public Awareness and Interest on Cryptocurrency Volatility](https://doi.org/10.1145/3583780.3614790)|Zeyd Boukhers, Azeddine Bouabdallah, Cong Yang, Jan Jürjens|University of Koblenz, Koblenz, Germany; Fraunhofer Institute for Applied Information Technology, Sankt Augustin, Germany; Soochow University, Suzhou, China|Since Bitcoin first appeared on the scene in 2009, cryptocurrencies have become a worldwide phenomenon as important decentralized financial assets. Their decentralized nature, however, leads to notable volatility against traditional fiat currencies, making the task of accurately forecasting the crypto-fiat exchange rate complex. In this study, we examine the various independent factors that affect the Bitcoin-Dollar exchange rate's volatility. To this end, we propose CoMForE, a multimodal AdaBoost-LSTM ensemble model, which not only utilizes historical trading data but also incorporates public sentiments from related tweets, public interest demonstrated by search volumes, and blockchain hash-rate data. Our developed model goes a step further by predicting fluctuations in the overall cryptocurrency value distribution, thus increasing its value for investment decision-making. We have subjected this method to extensive testing via comprehensive experiments, thereby validating the importance of multimodal combination over exclusive reliance on trading data. Further experiments show that our method significantly surpasses existing forecasting tools and methodologies, demonstrating a 19.29% improvement. This result underscores the influence of external independent factors on cryptocurrency volatility.||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Trading+Data:+The+Hidden+Influence+of+Public+Awareness+and+Interest+on+Cryptocurrency+Volatility)|0|
|[Causality and Independence Enhancement for Biased Node Classification](https://doi.org/10.1145/3583780.3614804)|Guoxin Chen, Yongqing Wang, Fangda Guo, Qinglang Guo, Jiangli Shao, Huawei Shen, Xueqi Cheng|Chinese Academy of Sciences, Beijing, China; University of Science and Technology of China & China Academic of Electronics and Information Technology, HeFei, China; Chinese Academy of Sciences & University of Chinese Academy of Sciences, Beijing, China|Most existing methods that address out-of-distribution (OOD) generalization for node classification on graphs primarily focus on a specific type of data biases, such as label selection bias or structural bias. However, anticipating the type of bias in advance is extremely challenging, and designing models solely for one specific type may not necessarily improve overall generalization performance. Moreover, limited research has focused on the impact of mixed biases, which are more prevalent and demanding in real-world scenarios. To address these limitations, we propose a novel Causality and Independence Enhancement (CIE) framework, applicable to various graph neural networks (GNNs). Our approach estimates causal and spurious features at the node representation level and mitigates the influence of spurious correlations through the backdoor adjustment. Meanwhile, independence constraint is introduced to improve the discriminability and stability of causal and spurious features in complex biased environments. Essentially, CIE eliminates different types of data biases from a unified perspective, without the need to design separate methods for each bias as before. To evaluate the performance under specific types of data biases, mixed biases, and low-resource scenarios, we conducted comprehensive experiments on five publicly available datasets. Experimental results demonstrate that our approach CIE not only significantly enhances the performance of GNNs but outperforms state-of-the-art debiased node classification methods.||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causality+and+Independence+Enhancement+for+Biased+Node+Classification)|0|
|[Knowledge-inspired Subdomain Adaptation for Cross-Domain Knowledge Transfer](https://doi.org/10.1145/3583780.3614946)|Liyue Chen, Linian Wang, Jinyu Xu, Shuai Chen, Weiqiang Wang, Wenbiao Zhao, Qiyu Li, Leye Wang|Alipay (Hangzhou) Information & Technology Co., Ltd, Hangzhou, China; Peking University, Beijing, China; Key Lab of High Confidence Software Technologies (Peking University), Ministry of Education, Beijing, China|Most state-of-the-art deep domain adaptation techniques align source and target samples in a global fashion. That is, after alignment, each source sample is expected to become similar to any target sample. However, global alignment may not always be optimal or necessary in practice. For example, consider cross-domain fraud detection, where there are two types of transactions: credit and non-credit. Aligning credit and non-credit transactions separately may yield better performance than global alignment, as credit transactions are unlikely to exhibit patterns similar to non-credit transactions. To enable such fine-grained domain adaption, we propose a novel Knowledge-Inspired Subdomain Adaptation (KISA) framework. In particular, (1) We provide the theoretical insight that KISA minimizes the shared expected loss which is the premise for the success of domain adaptation methods. (2) We propose the knowledge-inspired subdomain division problem that plays a crucial role in fine-grained domain adaption. (3) We design a knowledge fusion network to exploit diverse domain knowledge. Extensive experiments demonstrate that KISA achieves remarkable results on fraud detection and traffic demand prediction tasks.||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge-inspired+Subdomain+Adaptation+for+Cross-Domain+Knowledge+Transfer)|0|
|[Rebalancing Social Feed to Minimize Polarization and Disagreement](https://doi.org/10.1145/3583780.3615025)|Federico Cinus, Aristides Gionis, Francesco Bonchi|KTH Royal Institute of Technology, Stockholm, Sweden; CENTAI & Eurecat, Turin, Italy; Sapienza University & CENTAI, Rome, Italy|Social media have great potential for enabling public discourse on important societal issues. However, adverse effects, such as polarization and echo chambers, greatly impact the benefits of social media and call for algorithms that mitigate these effects. In this paper, we propose a novel problem formulation aimed at slightly nudging users' social feeds in order to strike a balance between relevance and diversity, thus mitigating the emergence of polarization, without lowering the quality of the feed. Our approach is based on re-weighting the relative importance of the accounts that a user follows, so as to calibrate the frequency with which the content produced by various accounts is shown to the user. We analyze the convexity properties of the problem, demonstrating the non-matrix convexity of the objective function and the convexity of the feasible set. To efficiently address the problem, we develop a scalable algorithm based on projected gradient descent. We also prove that our problem statement is a proper generalization of the undirected-case problem so that our method can also be adopted for undirected social networks. As a baseline for comparison in the undirected case, we develop a semidefinite programming approach, which provides the optimal solution. Through extensive experiments on synthetic and real-world datasets, we validate the effectiveness of our approach, which outperforms non-trivial baselines, underscoring its ability to foster healthier and more cohesive online communities.||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rebalancing+Social+Feed+to+Minimize+Polarization+and+Disagreement)|0|
|[AI in the Gray: Exploring Moderation Policies in Dialogic Large Language Models vs. Human Answers in Controversial Topics](https://doi.org/10.1145/3583780.3614777)|Vahid Ghafouri, Vibhor Agarwal, Yong Zhang, Nishanth Sastry, Jose M. Such, Guillermo SuarezTangil|King's College London & Universitat Politecnica de Valencia, London, United Kingdom; University of Surrey, Guildford, United Kingdom; IMDEA Networks Institute & Universidad Carlos III de Madrid, Leganes, Spain; IMDEA Networks Institute, Leganes, Spain|The introduction of ChatGPT and the subsequent improvement of Large Language Models (LLMs) have prompted more and more individuals to turn to the use of ChatBots, both for information and assistance with decision-making. However, the information the user is after is often not formulated by these ChatBots objectively enough to be provided with a definite, globally accepted answer. Controversial topics, such as "religion", "gender identity", "freedom of speech", and "equality", among others, can be a source of conflict as partisan or biased answers can reinforce preconceived notions or promote disinformation. By exposing ChatGPT to such debatable questions, we aim to understand its level of awareness and if existing models are subject to socio-political and/or economic biases. We also aim to explore how AI-generated answers compare to human ones. For exploring this, we use a dataset of a social media platform created for the purpose of debating human-generated claims on polemic subjects among users, dubbed Kialo. Our results show that while previous versions of ChatGPT have had important issues with controversial topics, more recent versions of ChatGPT (gpt-3.5-turbo) are no longer manifesting significant explicit biases in several knowledge areas. In particular, it is well-moderated regarding economic aspects. However, it still maintains degrees of implicit libertarian leaning toward right-winged ideals which suggest the need for increased moderation from the socio-political point of view. In terms of domain knowledge on controversial topics, with the exception of the "Philosophical" category, ChatGPT is performing well in keeping up with the collective human level of knowledge. Finally, we see that sources of Bing AI have slightly more tendency to the center when compared to human answers. All the analyses we make are generalizable to other types of biases and domains.|ChatGPT 的引入和随后对大型语言模型(LLM)的改进促使越来越多的人转向使用 ChatBots，以获取信息和帮助决策。然而，用户所需要的信息通常不是由这些聊天机器人客观地制定的，不足以提供一个明确的、全球公认的答案。有争议的话题，如“宗教”、“性别认同”、“言论自由”和“平等”等等，可能成为冲突的根源，因为党派或有偏见的答案可能会强化先入为主的观念或助长虚假信息。通过让 ChatGPT 接触这些有争议的问题，我们旨在了解其认识水平，以及现有模式是否受到社会政治和/或经济偏见的影响。我们还打算探索人工智能生成的答案与人类的答案之间的比较。为了探索这个问题，我们使用了一个社交媒体平台的数据集，该平台被命名为 Kialo，目的是对用户之间的争论话题进行辩论。我们的研究结果表明，虽然以前版本的 ChatGPT 在有争议的话题上存在重要问题，但是最近版本的 ChatGPT (gpt-3.5-turbo)在几个知识领域不再显示出明显的偏见。特别是，在经济方面，它是很有节制的。然而，它仍然保持着一定程度的隐性自由意志主义倾向于右翼理想，这表明从社会政治的角度来看，需要增加温和。就有争议话题的领域知识而言，除了“哲学”范畴外，ChatGPT 在与人类集体知识水平保持一致方面表现良好。最后，我们看到，与人类的答案相比，Bing AI 的来源稍微更倾向于中心。我们所做的所有分析都可以推广到其他类型的偏差和领域。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AI+in+the+Gray:+Exploring+Moderation+Policies+in+Dialogic+Large+Language+Models+vs.+Human+Answers+in+Controversial+Topics)|0|
|[Safe-NORA: Safe Reinforcement Learning-based Mobile Network Resource Allocation for Diverse User Demands](https://doi.org/10.1145/3583780.3615043)|Wenzhen Huang, Tong Li, Yuting Cao, Zhe Lyu, Yanping Liang, Li Yu, Depeng Jin, Junge Zhang, Yong Li|China Mobile Research Institute, Beijing, China; Tsinghua University, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China|As mobile communication technologies advance, mobile networks become increasingly complex, and user requirements become increasingly diverse. To satisfy the diverse demands of users while improving the overall performance of the network system, the limited wireless network resources should be efficiently and dynamically allocated to them based on the magnitude of their demands and their relative location to the base stations. We separated the problem into four constrained subproblems, which we then solved using a safe reinforcement learning method. In addition, we design a reward mechanism to encourage agent cooperation in distributed training environments. We test our methodology in a simulated scenario with thousands of users and hundreds of base stations. According to experimental findings, our method guarantees that over 95% of user demands are satisfied while also maximizing the overall system throughput.|随着移动通信技术的发展，移动网络变得越来越复杂，用户需求也变得越来越多样化。为了满足用户的多样化需求，同时提高网络系统的整体性能，需要根据用户的需求量及其与基站的相对位置，对有限的无线网络资源进行有效的动态分配。我们把问题分成四个约束子问题，然后用安全强化学习法解决。此外，我们还设计了一个奖励机制来鼓励分布式培训环境中的代理合作。我们在一个有数千用户和数百个基站的模拟场景中测试我们的方法。根据实验结果，我们的方法保证超过95% 的用户需求得到满足，同时也使系统总吞吐量最大化。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Safe-NORA:+Safe+Reinforcement+Learning-based+Mobile+Network+Resource+Allocation+for+Diverse+User+Demands)|0|
|[Deep Variational Bayesian Modeling of Haze Degradation Process](https://doi.org/10.1145/3583780.3614838)|Eun Woo Im, Junsung Shin, Sungyong Baik, Tae Hyun Kim|Hanyang University, Seoul, Republic of Korea|Relying on the representation power of neural networks, most recent works have often neglected several factors involved in haze degradation, such as transmission (the amount of light reaching an observer from a scene over distance) and atmospheric light. These factors are generally unknown, making dehazing problems ill-posed and creating inherent uncertainties. To account for such uncertainties and factors involved in haze degradation, we introduce a variational Bayesian framework for single image dehazing. We propose to take not only a clean image and but also transmission map as latent variables, the posterior distributions of which are parameterized by corresponding neural networks: dehazing and transmission networks, respectively. Based on a physical model for haze degradation, our variational Bayesian framework leads to a new objective function that encourages the cooperation between them, facilitating the joint training of and thereby boosting the performance of each other. In our framework, a dehazing network can estimate a clean image independently of a transmission map estimation during inference, introducing no overhead. Furthermore, our model-agnostic framework can be seamlessly incorporated with other existing dehazing networks, greatly enhancing the performance consistently across datasets and models.|依赖于神经网络的表现能力，大多数最近的工作往往忽略了几个因素涉及到阴霾退化，如透射(从远处的场景到达观察者的光量)和大气光。这些因素通常是未知的，使得令人厌烦的问题不适定，并造成固有的不确定性。为了解决这些不确定性和影响霾退化的因素，我们引入了一个变分贝叶斯框架来处理单幅图像的除霾问题。我们提出不仅以清晰图像作为潜变量，而且以传输图作为潜变量，其后验分布分别由相应的神经网络参数化: 去雾网络和传输网络。基于雾霾退化的物理模型，我们的变化贝叶斯框架导致一个新的目标函数，鼓励他们之间的合作，促进联合训练，从而提高彼此的表现。在我们的框架中，去雾网络可以在推理过程中独立于传输图估计来估计干净的图像，不会引入开销。此外，我们的模型无关框架可以与其他现有的去雾网络无缝结合，极大地提高了跨数据集和模型的一致性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Variational+Bayesian+Modeling+of+Haze+Degradation+Process)|0|
|[Diffusion Variational Autoencoder for Tackling Stochasticity in Multi-Step Regression Stock Price Prediction](https://doi.org/10.1145/3583780.3614844)|Kelvin J. L. Koa, Yunshan Ma, Ritchie Ng, TatSeng Chua|Eastspring Investments, Singapore, Singapore; National University of Singapore, Singapore, Singapore|Multi-step stock price prediction over a long-term horizon is crucial for forecasting its volatility, allowing financial institutions to price and hedge derivatives, and banks to quantify the risk in their trading books. Additionally, most financial regulators also require a liquidity horizon of several days for institutional investors to exit their risky assets, in order to not materially affect market prices. However, the task of multi-step stock price prediction is challenging, given the highly stochastic nature of stock data. Current solutions to tackle this problem are mostly designed for single-step, classification-based predictions, and are limited to low representation expressiveness. The problem also gets progressively harder with the introduction of the target price sequence, which also contains stochastic noise and reduces generalizability at test-time. To tackle these issues, we combine a deep hierarchical variational-autoencoder (VAE) and diffusion probabilistic techniques to do seq2seq stock prediction through a stochastic generative process. The hierarchical VAE allows us to learn the complex and low-level latent variables for stock prediction, while the diffusion probabilistic model trains the predictor to handle stock price stochasticity by progressively adding random noise to the stock data. Our Diffusion-VAE (D-Va) model is shown to outperform state-of-the-art solutions in terms of its prediction accuracy and variance. More importantly, the multi-step outputs can also allow us to form a stock portfolio over the prediction length. We demonstrate the effectiveness of our model outputs in the portfolio investment task through the Sharpe ratio metric and highlight the importance of dealing with different types of prediction uncertainties.|长期多步股价预测对于预测其波动性至关重要，它使金融机构能够对衍生品进行定价和对冲，使银行能够量化其交易账户中的风险。此外，大多数金融监管机构还要求机构投资者在几天内退出风险资产，以免对市场价格产生重大影响。然而，由于股票数据的高度随机性，多步股价预测的任务是具有挑战性的。目前解决这个问题的解决方案大多是为单步、基于分类的预测而设计的，并且仅限于低表示表达性。随着目标价格序列的引入，这个问题也变得越来越难，因为目标价格序列还包含随机噪声，降低了测试时的通用性。为了解决这些问题，我们将深层变分自动编码器(VAE)和扩散概率技术结合起来，通过一个随机生成过程进行 seq2seq 股票预测。分层 VAE 使我们能够学习复杂和低层潜变量的股票预测，而扩散概率模型训练预测器处理股票价格的随机性，逐步增加随机噪声的股票数据。我们的扩散 VAE (D-Va)模型在预测精度和方差方面表现优于最先进的解。更重要的是，多步输出还可以让我们形成一个股票投资组合的预测长度。我们证明了我们的模型输出在证券投资任务中的有效性，通过 Sharpe 比率度量，并强调了处理不同类型的预测不确定性的重要性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Diffusion+Variational+Autoencoder+for+Tackling+Stochasticity+in+Multi-Step+Regression+Stock+Price+Prediction)|0|
|[Non-Compliant Bandits](https://doi.org/10.1145/3583780.3614990)|Branislav Kveton, Yi Liu, Johan Matteo Kruijssen, Yisu Nie|Amazon, Santa Clara, USA; Amazon, New York, USA; Amazon, Seattle, USA|Bandit algorithms arose as a standard approach to learning better models online. As they become more popular, they are increasingly deployed in complex machine learning pipelines, where their actions can be overwritten. For example, in ranking problems, a list of recommended items can be modified by a downstream algorithm to increase diversity. This may break the classic bandit algorithms and lead to linear regret. Specifically, if the proposed action is not taken, uncertainty in its estimated mean reward may not get reduced. In this work, we study this setting and call it non-compliant bandits; as the agent tries to learn rewarding actions that comply with a downstream task. We propose two algorithms, compliant contextual UCB (CompUCB) and Thompson sampling (CompTS), which learn separate reward and compliance models. The compliance model allows the agent to avoid non-compliant actions. We derive a sublinear regret bound for CompUCB. We also conduct experiments that compare our algorithms to classic bandit baselines. The experiments show failures of the baselines and that we mitigate them by learning compliance models.|盗贼算法作为在线学习更好模型的标准方法而兴起。随着它们变得越来越流行，它们越来越多地部署在复杂的机器学习管道中，在那里它们的行为可以被覆盖。例如，在排序问题中，可以通过下游算法修改推荐项目的列表，以增加多样性。这可能会打破经典的强盗算法，并导致线性遗憾。具体来说，如果没有采取建议的行动，其估计的平均报酬的不确定性可能不会得到减少。在这项工作中，我们研究这种情况，并称之为不顺从的土匪; 因为代理人试图学习符合下游任务的奖励行动。我们提出了两个算法，遵从上下文 UCB (CompUCB)和汤普森抽样(CompTS) ，它们学习单独的奖励和遵从模型。遵从性模型允许代理避免不遵从的操作。我们得到了 CompUCB 的一个次线性后悔界。我们还进行实验，将我们的算法与传统的强盗基线进行比较。实验显示了基线的失败，并且我们通过学习遵从性模型来减轻它们。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Non-Compliant+Bandits)|0|
|[ST-MoE: Spatio-Temporal Mixture-of-Experts for Debiasing in Traffic Prediction](https://doi.org/10.1145/3583780.3615068)|Shuhao Li, Yue Cui, Yan Zhao, Weidong Yang, Ruiyuan Zhang, Xiaofang Zhou|The Hong Kong University of Science and Technology, Hong Kong SAR, China; Aalborg University, Aalborg, Denmark; Fudan University, Shanghai, China|The pervasiveness of GPS-enabled devices and wireless communication technologies results in a proliferation of traffic data in intelligent transportation systems, where traffic prediction is often essential to enable reliability and safety. Many recent studies target traffic prediction using deep learning techniques. They model spatio-temporal dependencies among traffic states by deep learning and achieve good overall performance. However, existing studies ignore the bias on traffic prediction models, which refers to non-uniformed performance distribution across road segments, especially the significantly poor prediction results on certain road segments. To solve this issue, we propose a framework named spatio-temporal mixture-of-experts (ST-MoE) that aims to eliminate the bias on traffic prediction. In general, we refer to any traffic prediction model as the based model, and adopt the proposed ST-MoE framework as a plug-in to debias. ST-MoE uses stacked convolution-based networks to learn spatio-temporal representations of individual patterns of road segments and then adaptively assigns appropriate expert layers (sub-networks) to different patterns through a spatio-temporal gating network. To this end, the patterns can be distinguished, and biased performance among road segments can be eliminated by experts tailored for specific patterns, which also further improves the overall prediction accuracy of the base model. Extensive experimental results on various base models and real-world datasets prove the effectiveness of ST-MoE.|具有全球定位系统功能的设备和无线通信技术的普及导致智能交通系统中交通数据的激增，在这些系统中，交通预测往往对可靠性和安全性至关重要。最近的许多研究目标交通预测使用深度学习技术。它们通过深度学习模拟交通状态之间的时空依赖关系，取得了良好的综合性能。然而，现有的研究忽略了交通预测模型的偏差，即路段间的性能分布不均匀，特别是某些路段的预测效果明显较差。为了解决这一问题，我们提出了一种时空混合专家模型(ST-MoE) ，旨在消除交通预测中的偏差。一般来说，我们把任何一种交通预测模型作为基础模型，并采用所提出的 ST-MoE 框架作为插件进行偏置。ST-MoE 使用基于叠加卷积的网络来学习路段单个模式的时空表示，然后通过时空门控网络自适应地为不同的模式分配适当的专家层(子网)。为此，专家针对特定的模式，可以区分模式，消除路段之间的偏差性能，从而进一步提高基本模型的整体预测精度。在各种基本模型和实际数据集上的大量实验结果证明了 ST-MoE 方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ST-MoE:+Spatio-Temporal+Mixture-of-Experts+for+Debiasing+in+Traffic+Prediction)|0|
|[UniTE: A Unified Treatment Effect Estimation Method for One-sided and Two-sided Marketing](https://doi.org/10.1145/3583780.3615100)|Runshi Liu, Zhipeng Hou|Ant Group, Shanghai, China; Ant Group, Hangzhou, China|Many internet platforms are two-sided markets that involve two types of participants. Examples include e-commerce platforms like Taobao (retailers and consumers) and ride-hailing platforms like Uber (drivers and passengers). Participants of different types in the two-sided market have relationships (i.e., supply and demand) that provide externalities and network benefits. On two-sided platforms, marketing campaigns are designed by subsidizing supply or demand. Uplift models built in this scenario usually consider the treatment assignment for only one of the two sides. However, ignoring the interaction of treatments between two sides or treating them as noises may result in incomplete models and inaccurate predictions. As far as we know, there is not much work related to modeling the combinational treatment effects in the two-sided market. In this paper, we first introduce the two-sided treatment effects estimation problem and then propose a Unified Treatment effect Estimation (UniTE) method for one-sided and two-sided marketing. We extend the Robinson Decomposition to two-sided, in which the relationship of the three involved tasks, namely the outcome, the propensity, and the treatment effect, is theoretically derived. Based on the decomposition result, a multi-task-based neural network model is proposed to integrate the three tasks and learn the inter-task-related common information, which prompts the model to estimate the treatment effects better. We also propose a unified synthetic data generation method that adapts to one/two-sided situations to verify the treatment effects estimation performance. Extensive and comprehensive experimental results show that our method outperforms the other methods.|许多互联网平台是双边市场，涉及两种类型的参与者。例如电子商务平台如淘宝(零售商和消费者)和叫车平台如优步(司机和乘客)。双边市场中不同类型的参与者之间的关系(即供求关系)提供了外部性和网络效益。在双边平台上，营销活动是通过补贴供给或需求来设计的。在这种情况下建立的提升模型通常只考虑两侧中的一侧的处理分配。然而，忽略两侧处理之间的相互作用或将它们视为噪声可能导致模型不完整和预测不准确。据我们所知，目前还没有多少工作涉及到在双边市场中建立联合治疗效果的模型。在本文中，我们首先介绍了双边治疗效果估计问题，然后提出了单边和双边营销的统一治疗效果估计(UniTE)方法。我们将鲁滨逊分解推广到双侧，从理论上导出了三个相关任务，即结果、倾向和治疗效果之间的关系。在分解结果的基础上，提出了一种基于多任务的神经网络模型来整合三个任务，学习任务间相关的共同信息，从而更好地估计治疗效果。我们还提出了一个统一的综合数据生成方法，适用于单/双边情况，以验证治疗效果估计性能。广泛而全面的实验结果表明，我们的方法优于其他方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UniTE:+A+Unified+Treatment+Effect+Estimation+Method+for+One-sided+and+Two-sided+Marketing)|0|
|[Online Efficient Secure Logistic Regression based on Function Secret Sharing](https://doi.org/10.1145/3583780.3614998)|Jing Liu, Jamie Cui, Cen Chen|East China Normal University, Shanghai, China; Ant Group & East China Normal University, Hangzhou, China; East China Normal University & Ant Group, Shanghai, China|Logistic regression is an algorithm widely used for binary classification in various real-world applications such as fraud detection, medical diagnosis, and recommendation systems. However, training a logistic regression model with data from different parties raises privacy concerns. Secure Multi-Party Computation (MPC) is a cryptographic tool that allows multiple parties to train a logistic regression model jointly without compromising privacy. The efficiency of the online training phase becomes crucial when dealing with large-scale data in practice. In this paper, we propose an online efficient protocol for privacy-preserving logistic regression based on Function Secret Sharing (FSS). Our protocols are designed in the two non-colluding servers setting and assume the existence of a third-party dealer who only poses correlated randomness to the computing parties. During the online phase, two servers jointly train a logistic regression model on their private data by utilizing pre-generated correlated randomness. Furthermore, we propose accurate and MPC-friendly alternatives to the sigmoid function and encapsulate the logistic regression training process into a function secret sharing gate. The online communication overhead significantly decreases compared with the traditional secure logistic regression training based on secret sharing. We provide both theoretical and experimental analyses to demonstrate the efficiency and effectiveness of our method.|Logit模型是一种广泛用于二进制分类的算法，在现实世界的各种应用中，如欺诈检测、医疗诊断和推荐系统。然而，利用来自不同方面的数据训练一个 Logit模型模型会引起隐私方面的担忧。安全多方计算是一种加密工具，允许多方在不损害隐私的情况下联合训练一个 Logit模型模型。在实际处理大规模数据时，在线训练阶段的效率变得至关重要。在这篇文章中，我们提出了一个基于功能秘密共享(fSS)的在线高效的保护隐私的 Logit模型协议。我们的协议设计在两个非合谋的服务器设置，并假设存在一个第三方经销商谁只提出了相关的随机性的计算各方。在联机阶段，两台服务器利用预先生成的相关随机性，共同训练一个私有数据的 Logit模型模型。此外，我们还提出了精确的 MPC 友好的替代 S形函数，并将 Logit模型培训过程封装成一个功能秘密共享门。与传统的基于秘密共享的安全 Logit模型训练相比，在线通信开销显著降低。我们提供了理论和实验分析，以证明我们的方法的效率和有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Online+Efficient+Secure+Logistic+Regression+based+on+Function+Secret+Sharing)|0|
|[Khronos: A Real-Time Indexing Framework for Time Series Databases on Large-Scale Performance Monitoring Systems](https://doi.org/10.1145/3583780.3614944)|Xinyu Liu, Zijing Wei, Wenqing Yu, Shaozhi Liu, Gang Wang, Xiaoguang Liu, Yusen Li|Nankai University, Tianjin, China; Alibaba Group Holding Limited, Beijing, China|Time series databases play a critical role in large-scale performance monitoring systems. Metrics are required to be observable immediately after being generated to support real-time analysis. However, the commonly used Log-Structured Merge-Tree structure suffers from periodically visible delay spikes when a new segment is created due to the instantaneous index construction pressure. In this paper, we present Khronos, an asynchronous indexing framework tailored for high-cardinal monitoring data, aiming at reducing the visible delay. Firstly, we analyze the temporal locality nature of time series and propose a complementary index construction algorithm by only indexing series not reported before to relieve indexing workload. Secondly, we design index structures based on Minimum Excluded value function to effectively reuse indexes of previous segments. Thirdly, we take advantage of the non-repetitive feature of complementary indexes and further develop an intermediate query results reusing approach for deduplicating index traversal among segments. Moreover, we propose an index dependency management strategy that cuts off the previous reusing dependency before persistence to avoid extended dependency overhead. Experimental results show that our framework significantly reduces the visible delay from minutes to milliseconds. Khronos outperforms the state-of-the-art databases InfluxDB and TimeScaleDB with at least 4 times higher write throughput, hundreds of times lower visible delay, and 6 times lower query latency. Khronos has been deployed in production since 2020 and has become the largest performance monitoring database in Alibaba.|时间序列数据库在大规模性能监测系统中起着关键的作用。为了支持实时分析，需要在生成度量值后立即可观察到。但是，常用的日志结构化合并树结构在创建新段时，由于瞬时索引构造压力，会出现周期性可见的延迟峰值。本文提出了一种异步索引框架 Khronos，该框架针对高基数监测数据，旨在减少可见的延迟。首先分析了时间序列的时间局部性，提出了一种只索引以前未报道的时间序列的互补索引构造算法，以减轻索引工作量。其次，设计了基于最小排除值函数的索引结构，有效地重用了前面分段的索引。第三，利用互补索引的非重复性特点，进一步提出了一种中间查询结果重用方法，用于去除段间索引遍历的重复性。此外，我们提出了一种索引依赖关系管理策略，在持久化之前切断先前的重用依赖关系，以避免扩展依赖开销。实验结果表明，我们的框架显著减少了可见的延迟从分钟到毫秒。Khronos 的写入吞吐量至少比最先进的数据库 FluxDB 和 TimeScaleDB 高4倍，可见延迟低数百倍，查询延迟低6倍。Khronos 自2020年开始投入生产，已成为阿里巴巴最大的性能监控数据库。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Khronos:+A+Real-Time+Indexing+Framework+for+Time+Series+Databases+on+Large-Scale+Performance+Monitoring+Systems)|0|
|[Exploring Low-Dimensional Manifolds of Deep Neural Network Parameters for Improved Model Optimization](https://doi.org/10.1145/3583780.3614873)|Ke Lu, Xiaotong He, Ze Qin, Xinyao Li, Zhekai Du|University of Electronic Science and Technology of China, Chengdu, China|Manifold learning techniques have significantly enhanced the comprehension of massive data by exploring the geometric properties of the data manifold in low-dimensional subspaces. However, existing research on manifold learning primarily focuses on understanding the intricate data, overlooking the explosive growth of the scale and complexity of deep neural networks (DNNs), which presents a significant challenge for model optimization. In this work, we propose to explore the intrinsic low-dimensional manifold of network parameters for efficient model optimization. Specifically, we analyze parameter distributions in a deep model and perform sampling to map them onto a low-dimensional parameter manifold using the local tangent space alignment (LTSA). Since our focus is on studying parameter manifolds to guide model optimization, we therefore select dynamic optimal training trajectories for sampling and approximate tangent spaces to obtain low-dimensional representations of DNNs. By applying manifold learning techniques and employing a two-step alternate optimization method, we achieve a fixed subspace that reduces training time and resource costs for commonly used deep networks. The trained low-dimensional network can be mapped back to the original parameter space for further use. We demonstrate the benefits of learning low-dimensional parameterization of DNNs on both noisy label learning and federated learning tasks. Extensive experimental results on various benchmarks show the effectiveness of our method concerning both superior accuracy and reduced resource consumption.|流形学习技术通过研究低维子空间中数据流形的几何性质，极大地提高了对海量数据的理解能力。然而，现有的流形学习研究主要集中在对复杂数据的理解上，忽视了深层神经网络(DNN)规模和复杂性的爆炸性增长，这对模型优化提出了严峻的挑战。在这项工作中，我们提出探索内在的低维流形的网络参数为有效的模型优化。具体来说，我们分析深度模型中的参数分布，并使用局部切线空间对齐(LTSA)进行抽样，将它们映射到低维参数流形上。由于我们的重点是研究参数流形，以指导模型优化，因此我们选择动态最优的采样训练轨迹和近似切线空间，以获得 DNN 的低维表示。通过应用流形学习技术和采用两步交替优化方法，我们得到了一个固定的子空间，降低了常用深层网络的训练时间和资源成本。训练后的低维网络可以映射回原始参数空间以供进一步使用。我们展示了学习低维参量化的 DNN 在噪声标签学习和联合学习任务中的好处。在各种基准上的大量实验结果表明，我们的方法在提高精度和降低资源消耗方面是有效的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+Low-Dimensional+Manifolds+of+Deep+Neural+Network+Parameters+for+Improved+Model+Optimization)|0|
|[Integrating Priors into Domain Adaptation Based on Evidence Theory](https://doi.org/10.1145/3583780.3614935)|Ying Lv, Jianpeng Ma, Yiqiu Zhang, Gang Xu|Shanghai Artificial Intelligence Laboratory & Fudan University, Shanghai, China; Shanghai Artificial Intelligence Laboratory, Shanghai, China|Domain adaptation aims to build up a learning model for target domain by leveraging transferable knowledge from different but related source domains. Existing domain adaptation methods generally transfer the knowledge from source domain to target domain through measuring the consistency between the different domains. Under this strategy, if the data of source domain is not sufficient to guarantee the consistency, the transferable knowledge will be very limited. On the other hand, we often have priors about target domain which facilitate knowledge transfer but are neglected in the extant domain adaptation methods. To tackle the problems, we integrate the priors of target domain into transfer process and propose a domain adaptation method based on evidence evidence theory. We represent the priors with evidential belief function and reformulate the domain adaptation objective based on likelihood principle, in which the priors are used to adjust transferred knowledge to suit for target domain. Based on this, we propose an improved coordinate ascent algorithm to optimize likelihood objective of domain adaption. Experimental results on both text and image datasets validate that the proposed method is effective to improve the knowledge transferability in domain adaptation, especially when the source domain is limited.|领域适应旨在通过利用来自不同但相关源领域的可转移知识，建立目标领域的学习模型。现有的领域自适应方法一般通过测量不同领域之间的一致性将知识从源领域转移到目标领域。在这种策略下，如果源域的数据不足以保证一致性，可转移的知识就会非常有限。另一方面，我们对目标领域的研究往往存在一些先例，这些先例有利于知识转移，但在现有的领域适应方法中却被忽视了。为了解决这些问题，我们将目标域的先验信息融入到转移过程中，提出了一种基于证据理论的域自适应方法。利用证据信度函数对先验知识进行表示，并基于似然原理重新制定领域适应性目标，利用先验知识对传递知识进行调整以适应目标领域。在此基础上，提出了一种改进的坐标提升算法来优化域自适应的似然目标。在文本和图像数据集上的实验结果验证了该方法在提高领域自适应知识转移能力方面的有效性，特别是在源领域有限的情况下。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Integrating+Priors+into+Domain+Adaptation+Based+on+Evidence+Theory)|0|
|[A Principled Decomposition of Pointwise Mutual Information for Intention Template Discovery](https://doi.org/10.1145/3583780.3614767)|Denghao Ma, Kevin ChenChuan Chang, Yueguo Chen, Xueqiang Lv, Liang Shen|Meituan, Beijing, China; Renmin University of China, Beijing, China; Beijing Information Science and Technology University, Beijing, China; University of Illinois at Urbana-Champaign, URBANA, IL, USA|With the rise of Artificial Intelligence (AI), question answering systems have become common for users to interact with computers, e.g., ChatGPT and Siri. These systems require a substantial amount of labeled data to train their models. However, the labeled data is scarce and challenging to be constructed. The construction process typically involves two stages: discovering potential sample candidates and manually labeling these candidates. To discover high-quality candidate samples, we study the intention paraphrase template discovery task: Given some seed questions or templates of an intention, discover new paraphrase templates that describe the intention and are diverse to the seeds enough in text. As the first exploration of the task, we identify the new quality requirements, i.e., relevance, divergence and popularity, and identify the new challenges, i.e., the paradox of divergent yet relevant paraphrases, and the conflict of popular yet relevant paraphrases. To untangle the paradox of divergent yet relevant paraphrases, in which the traditional bag of words falls short, we develop usage-centric modeling, which represents a question/template/answer as a bag of usages that users engaged (e.g., up-votes), and uses a usage-flow graph to interrelate templates, questions and answers. To balance the conflict of popular yet relevant paraphrases, we propose a new and principled decomposition for the well-known Pointwise Mutual Information from the usage perspective (usage-PMI), and then develop a Bayesian inference framework over the usage-flow graph to estimate the usage-PMI. Extensive experiments over three large CQA corpora show strong performance advantage over the baselines adopted from paraphrase identification task. We release 885,000 paraphrase templates of high quality discovered by our proposed PMI decomposition model, and the data is available in site https://github.com/Para-Questions/Intention\_template\_discovery.|随着人工智能(AI)的兴起，问答系统已经成为用户与计算机交互的常见方式，例如 ChatGPT 和 Siri。这些系统需要大量的标记数据来训练它们的模型。然而，标记数据是稀缺和具有挑战性的构建。构建过程通常包括两个阶段: 发现潜在的候选样本和手动标记这些候选样本。为了发现高质量的候选样本，我们研究了意向释义模板发现任务: 给定一些意向的种子问题或模板，发现新的释义模板描述意向，并在文本中对种子足够多样化。作为任务的第一次探索，我们确定了新的质量要求，即相关性，分歧和流行，并确定了新的挑战，即矛盾的分歧但相关的释义，以及流行但相关的释义的冲突。为了解决这个矛盾，我们开发了以用法为中心的模型，它将问题/模板/答案表示为用户参与的一组用法(例如赞成票) ，并使用用法流图来相互关联模板、问题和答案。为了平衡流行但相关的转述之间的冲突，我们从使用角度(使用-采购经理指数)提出了一个新的和原则性的分解点间互信息，然后在使用-流程图上开发了一个贝叶斯推断框架来估计使用-采购经理指数。通过对三个大型 CQA 语料库的大量实验表明，该方法比释义识别任务所采用的基线方法具有更强的性能优势。我们发布了885,000个由我们提出的 PMI 分解模型发现的高质量的转述模板，数据可以在现场 https://github.com/para-questions/intention_template_discovery 中获得。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Principled+Decomposition+of+Pointwise+Mutual+Information+for+Intention+Template+Discovery)|0|
|[Good Intentions: Adaptive Parameter Management via Intent Signaling](https://doi.org/10.1145/3583780.3614895)|Alexander RenzWieland, Andreas Kieslinger, Robert Gericke, Rainer Gemulla, Zoi Kaoudi, Volker Markl|Technische Universität Berlin, Berlin, Germany; Universität Mannheim, Mannheim, Germany; IT University of Copenhagen, Copenhagen, Denmark|Parameter management is essential for distributed training of large machine learning (ML) tasks. Some ML tasks are hard to distribute because common approaches to parameter management can be highly inefficient. Advanced parameter management approaches -- such as selective replication or dynamic parameter allocation -- can improve efficiency, but to do so, they typically need to be integrated manually into each task's implementation and they require expensive upfront experimentation to tune correctly. In this work, we explore whether these two problems can be avoided. We first propose a novel intent signaling mechanism that integrates naturally into existing ML stacks and provides the parameter manager with crucial information about parameter accesses. We then describe AdaPM, a fully adaptive, zero-tuning parameter manager based on this mechanism. In contrast to prior systems, this approach separates providing information (simple, done by the task) from exploiting it effectively (hard, done automatically by AdaPM). In our experimental evaluation, AdaPM matched or outperformed state-of-the-art parameter managers out of the box, suggesting that automatic parameter management is possible.|参数管理是大型机器学习任务分布式训练的基础。一些机器学习任务很难分发，因为常见的参数管理方法效率很低。高级的参数管理方法——比如选择性复制或动态参数分配——可以提高效率，但是要做到这一点，它们通常需要手动集成到每个任务的实现中，并且需要昂贵的前期试验来正确调优。在这项工作中，我们探讨这两个问题是否可以避免。我们首先提出了一种新的意图信号机制，该机制自然地集成到现有的 ML 栈中，并为参数管理器提供关于参数访问的关键信息。然后，我们描述 AdaPM，一个基于此机制的完全自适应、零调整的参数管理器。与以前的系统不同，这种方法将提供信息(简单的，由任务完成)和有效的利用信息(难的，由 AdaPM 自动完成)分离开来。在我们的实验评估中，AdaPM 匹配或超过了现有的最先进的参数管理器，这表明自动参数管理是可能的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Good+Intentions:+Adaptive+Parameter+Management+via+Intent+Signaling)|0|
|[Automatic and Precise Data Validation for Machine Learning](https://doi.org/10.1145/3583780.3614786)|Shreya Shankar, Labib Fawaz, Karl Gyllstrom, Aditya G. Parameswaran|Meta, Menlo Park, CA, USA; University of California, Berkeley, Berkeley, CA, USA|Machine learning (ML) models in production pipelines are frequently retrained on the latest partitions of large, continually- growing datasets. Due to engineering bugs, partitions in such datasets almost always have some corrupted features; thus, it's critical to find data issues and block retraining before downstream ML accuracy decreases. However, current ML data validation methods are difficult to operationalize: they yield too many false positive alerts, require manual tuning, or are infeasible at scale. In this pa- per, we present an automatic, precise, and scalable data validation system for ML pipelines, employing a simple idea that we call a Partition Summarization (PS) approach to data validation: each timestamp-based partition of data is summarized with data quality metrics, and summaries are compared to detect corrupted partitions. We demonstrate how to adapt PS for any data validation method in a robust manner and evaluate several adaptations-which by themselves provide limited precision. Finally, we present gate, our data validation method that leverages these adaptations, giving a 2.1× average improvement in precision over the baseline from prior work on a case study within our large tech company.|生产管道中的机器学习(ML)模型经常在大型、不断增长的数据集的最新分区上重新训练。由于工程缺陷，这类数据集中的分区几乎总是有一些损坏的特征; 因此，在下游机器学习精度下降之前，发现数据问题和阻塞再训练是至关重要的。然而，目前的机器学习数据验证方法很难操作: 它们产生了太多的误报警，需要人工调整，或者在规模上不可行。在本文中，我们提出了一个自动的，精确的，可扩展的机器学习管道数据验证系统，采用一个简单的想法，我们称之为分区总结(PS)方法的数据验证: 每个时间戳为基础的数据分区总结与数据质量指标，并总结进行比较，以检测损坏的分区。我们演示了如何以一种健壮的方式将 PS 适应于任何数据验证方法，并评估了几种适应性——这些适应性本身提供了有限的精度。最后，我们介绍了我们的数据验证方法 gate，它利用了这些适应性，从我们大型科技公司以前的案例研究中得到了2.1倍的平均精度提高。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automatic+and+Precise+Data+Validation+for+Machine+Learning)|0|
|[TOAK: A Topology-oriented Attack Strategy for Degrading User Identity Linkage in Cross-network Learning](https://doi.org/10.1145/3583780.3615084)|Jiangli Shao, Yongqing Wang, Fangda Guo, Boshen Shi, Huawei Shen, Xueqi Cheng|Institute of Computing Technology, CAS, Beijing, China; Institute of Computing Technology, CAS & University of Chinese Academy of Sciences, Beijing, China|Privacy concerns on social networks have received extensive attention in recent years. The task of user identity linkage (UIL), which aims to identify corresponding users across different social networks, poses a threat to privacy if applied unethically. Sensitive user information would be inferred with cross-network identity linkages. A feasible solution to this issue is to design an adversarial strategy that degrades the matching performance of UIL models. Nevertheless, most of the current adversarial attacks on graphs are tailored towards models working within a single network, failing to account for the challenges presented by cross-network learning tasks such as UIL. Also, in real-world scenarios, the adversarial strategy against UIL has more constraints as service providers can only add perturbations to their own networks. To tackle these challenges, this paper proposes a novel poisoning strategy to prevent nodes in a target network from being linked to other networks by UIL algorithms. Specifically, the UIL problem is formalized in the kernelized topology consistency perspective, and the objective is formulated as maximizing the structural variations in the target network before and after modifications. To achieve this, a novel graph kernel is defined based on earth mover's distance (EMD) in the edge-embedding space. In terms of efficiency, a fast attack strategy is proposed using greedy searching and a lower bound approximation of EMD. Results on three real-world datasets demonstrate that the proposed method outperforms six baselines and reaches a balance between effectiveness and imperceptibility while being efficient.|近年来，社交网络上的隐私问题受到广泛关注。用户身份链接(UIL)任务旨在识别不同社交网络上的相应用户，如果应用不道德，将对隐私构成威胁。敏感用户信息将通过跨网络身份链接推断出来。一个可行的解决方案是设计一个对抗策略，降低 UIL 模型的匹配性能。然而，目前大多数对图形的敌对攻击都是针对单一网络内工作的模型，没有考虑到跨网络学习任务(如 UIL)所带来的挑战。此外，在现实世界的情况下，对 UIL 的对抗策略有更多的限制，因为服务提供商只能添加扰动到他们自己的网络。为了解决这些问题，本文提出了一种新的中毒策略，以防止目标网络中的节点被 UIL 算法链接到其他网络。具体地说，UIL 问题被形式化为核拓扑一致性视角，目标被表述为在目标网络修改前后使结构变化最大化。为了实现这一点，在边嵌入空间中定义了一种新的基于地球动子距离(EMD)的图核。在效率方面，提出了一种基于贪婪搜索和 EMD 下界近似的快速攻击策略。在三个实际数据集上的实验结果表明，该方法的性能优于六个基线，在有效性和不可感知性之间达到了平衡。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TOAK:+A+Topology-oriented+Attack+Strategy+for+Degrading+User+Identity+Linkage+in+Cross-network+Learning)|0|
|[Improving Graph Domain Adaptation with Network Hierarchy](https://doi.org/10.1145/3583780.3614928)|Boshen Shi, Yongqing Wang, Fangda Guo, Jiangli Shao, Huawei Shen, Xueqi Cheng|Institute of Computing Technology, CAS, Beijing, China; Institute of Computing Technology, CAS & University of Chinese Academy of Sciences, Beijing, China|Graph domain adaptation models have become instrumental in addressing cross-network learning problems due to their ability to transfer abundant label and structural knowledge from source graphs to target graphs. A crucial step in transfer involves measuring domain discrepancy, which refers to distribution shifts between graphs from source and target domains. While conventional models simply provide a node-level measurement, exploiting information from different levels of network hierarchy is intuitive. As each hierarchical level characterizes distinct and meaningful properties or functionalities of the original graph, integrating domain discrepancy based on such hierarchies should contribute to a more precise domain discrepancy measurement. Moreover, class conditional distribution shift is often overlooked in node classification tasks, which could potentially lead to sub-optimal performance. To address the above limitations, we propose a new graph domain adaptation model and apply it to cross-network node classification tasks. Specifically, a hierarchical pooling model to extract meaningful and adaptive hierarchical structures is designed, where both marginal and class conditional distribution shifts on each hierarchical level are jointly minimized. The effectiveness is demonstrated through theoretical analysis and experimental studies across various datasets.|图域自适应模型由于能够将丰富的标签和结构知识从源图转移到目标图，因而在解决跨网络学习问题方面发挥了重要作用。转移中的一个关键步骤涉及到测量域差异，这是指来自源域和目标域的图之间的分布移位。虽然传统的模型只提供节点级的度量，但是利用来自不同层次的网络层次结构的信息是直观的。由于每个层次结构都表征了原始图的独特和有意义的属性或功能，基于这种层次结构的领域差异整合应该有助于更精确的领域差异度量。此外，在节点分类任务中，类条件分布移位往往被忽视，这可能导致性能不理想。针对上述局限性，提出了一种新的图域自适应模型，并将其应用于跨网络节点分类任务。具体地说，设计了一个分层池模型来提取有意义的和自适应的分层结构，其中边际和类别条件分布移动在每个分层级别共同最小化。通过对不同数据集的理论分析和实验研究，验证了该方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Graph+Domain+Adaptation+with+Network+Hierarchy)|0|
|[EmFore: Online Learning of Email Folder Classification Rules](https://doi.org/10.1145/3583780.3614863)|Mukul Singh, José Cambronero, Sumit Gulwani, Vu Le, Gust Verbruggen|Microsoft, Redmond, WA, USA; Microsoft, Delhi, India; Microsoft, Keerbergen, Belgium|Modern email clients support predicate-based folder assignment rules that can automatically organize emails. Unfortunately, users still need to write these rules manually. Prior machine learning approaches have framed automatically assigning email to folders as a classification task and do not produce symbolic rules. Prior inductive logic programming (ILP) approaches, which generate symbolic rules, fail to learn efficiently in the online environment needed for email management. To close this gap, we present EmFORE, an online system that learns symbolic rules for email classification from observations. Our key insights to do this successfully are: (1) learning rules over a folder abstraction that supports quickly determining candidate predicates to add or replace terms in a rule, (2) ensuring that rules remain consistent with historical assignments, (3) ranking rule updates based on existing predicate and folder name similarity, and (4) building a rule suppression model to avoid surfacing low-confidence folder predictions while keeping the rule for future use. We evaluate on two popular public email corpora and compare to 13 baselines, including state-of-the-art folder assignment systems, incremental machine learning, ILP and transformer-based approaches. We find that EmFORE performs significantly better, updates four orders of magnitude faster, and is more robust than existing methods and baselines.|现代电子邮件客户端支持基于谓词的文件夹分配规则，可以自动组织电子邮件。不幸的是，用户仍然需要手动编写这些规则。先前的机器学习方法将自动分配电子邮件到文件夹作为一个分类任务，而不产生符号规则。先前的归纳逻辑编程(ILP)方法产生符号规则，无法在电子邮件管理所需的在线环境中有效地学习。为了缩小这个差距，我们提出了 EmFORE，一个在线系统，它从观察中学习电子邮件分类的符号规则。我们成功做到这一点的关键见解是: (1)通过文件夹抽象学习规则，支持快速确定候选谓词在规则中添加或替换术语; (2)确保规则与历史分配保持一致; (3)根据现有谓词和文件夹名相似性对规则更新进行排序; (4)建立规则抑制模型，以避免出现低信任度的文件夹预测，同时保留规则供将来使用。我们评估了两个流行的公共电子邮件语料库，并比较了13个基线，包括最先进的文件夹分配系统，增量机器学习，ILP 和转换器为基础的方法。我们发现 EmFORE 的性能明显更好，更新数量级更快，比现有的方法和基线更加健壮。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EmFore:+Online+Learning+of+Email+Folder+Classification+Rules)|0|
|[SAND: Semantic Annotation of Numeric Data in Web Tables](https://doi.org/10.1145/3583780.3615046)|Yuchen Su, Davood Rafiei, Behrad Khorram Nazari|University of Alberta, Edmonton, Canada|A large portion of quantitative information about entities is expressed as Web tables, and these tables often lack proper schema and annotation, which introduces challenges for the purpose of querying and analysis. In this paper, we introduce SAND, a novel approach for annotating numeric columns of Web tables by linking them to properties in a knowledge graph. Our approach relies only on the semantic information readily available in knowledge graphs and not on contextual information that can be missing or labelled data which may be difficult to obtain. We show that our approach can reliably detect both semantic types (e.g., height) and unit labels (e.g., Centimeter) when the semantic type is present in the knowledge graph. Our evaluation on real-world web tables shows that our method outperforms by a large margin, in terms of accuracy, some of the state-of-the-art approaches on semantic labeling and unit detection.|有关实体的大部分定量信息表示为 Web 表，而这些表往往缺乏适当的模式和注释，这为查询和分析带来了挑战。在本文中，我们介绍了 SAND，一种新颖的方法来标注网络表格中的数字列，通过链接它们到一个知识图中的属性。我们的方法只依赖于知识图表中容易获得的语义信息，而不依赖于可能丢失或难以获得的标记数据的上下文信息。我们证明了我们的方法可以可靠地检测语义类型(例如，高度)和单位标签(例如，厘米)当语义类型存在于知识图中。我们对现实世界中的网络表格的评估表明，我们的方法在准确性方面大大优于一些最先进的语义标记和单元检测方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SAND:+Semantic+Annotation+of+Numeric+Data+in+Web+Tables)|0|
|[Graph Inference via the Energy-efficient Dynamic Precision Matrix Estimation with One-bit Data](https://doi.org/10.1145/3583780.3614898)|Xiao Tan, Yangyang Shen, Meng Wang, Beilun Wang|Southeast University, Nanjing, China|Graph knowledge discovery from graph-structured data is a fascinating data mining topic in various domains, especially in the Internet of Things, where inferring the graph structure from such informative data can benefit many downstream tasks. Deep neural networks are typically used to perform such predictions, but they produce unreliable results without sufficient high-quality data. Therefore, researchers introduce lightweight statistical precision matrix learning to infer the graph structure in many IoT scenarios with limited communication and resolution of sensors. However, these methods still suffer from low-resolution data or the omission of hidden information in time-series data. To address the challenges, we propose a novel approach for Energy-efficient Dynamic Sparse Graph Structure Estimation with one-bit data, EDGE. Our method proposes a novel estimator to estimate the covariance matrix from one-bit data, and then utilize the covariance matrices to capture the dynamic structure. We theoretically demonstrate the effectiveness of the estimators by deriving two non-asymptotic estimation error bounds for the estimated covariance matrix and precision matrix, respectively. The theoretical results show that our method can achieve a consistent result of the precision matrix at the rate O(log p/n). On multiple synthetic and real-world datasets, the experimental results demonstrate that our proposed estimator is able to obtain a relatively high detection rate using one-bit data, which exceeds the baseline by 35%, and identify potentially perturbed nodes in real-time dynamic network inference.|基于图结构数据的图形知识发现是各个领域，尤其是物联网领域中一个引人注目的数据挖掘话题，从这些信息性数据中推断出图形结构可以使许多下游任务受益。深度神经网络通常用于执行这样的预测，但是它们在没有足够高质量数据的情况下产生不可靠的结果。因此，研究人员引入了轻量级统计精度矩阵学习来推断在传感器通信和分辨率有限的物联网场景中的图结构。然而，这些方法仍然存在低分辨率数据或时间序列数据中隐藏信息的遗漏问题。为了解决这一问题，我们提出了一种新的基于一位数据的能量有效的动态稀疏图结构估计方法 EDGE。我们的方法提出了一个新的估计器来估计单位数据的协方差矩阵，然后利用协方差矩阵来捕获动态结构。我们从理论上证明了估计的有效性，通过导出估计的协方差矩阵和精度矩阵的两个非渐近估计误差界。理论分析结果表明，该方法在速率为 O (log p/n)时，可以得到精度矩阵一致的结果。在多个合成和真实数据集上，实验结果表明，我们提出的估计器能够使用单位数据获得相对较高的检测率，超过基线35% ，并在实时动态网络推理中识别潜在的干扰节点。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Inference+via+the+Energy-efficient+Dynamic+Precision+Matrix+Estimation+with+One-bit+Data)|0|
|[Multi-Representation Variational Autoencoder via Iterative Latent Attention and Implicit Differentiation](https://doi.org/10.1145/3583780.3614980)|NhuThuat Tran, Hady W. Lauw|Singapore Management University, Singapore, Singapore|Variational Autoencoder (VAE) offers a non-linear probabilistic modeling of user's preferences. While it has achieved remarkable performance at collaborative filtering, it typically samples a single vector for representing user's preferences, which may be insufficient to capture the user's diverse interests. Existing solutions extend VAE to model multiple interests of users by resorting a variant of self-attentive method, i.e., employing prototypes to group items into clusters, each capturing one topic of user's interests. Despite showing improvements, the current design could be more effective since prototypes are randomly initialized and shared across users, resulting in uninformative and non-personalized clusters. To fill the gap, firstly, we introduce iterative latent attention for personalized item grouping into VAE framework to infer multiple interests of users. Secondly, we propose to incorporate implicit differentiation to improve training of our iterative refinement model. Thirdly, we study the self-attention to refine cluster prototypes for item grouping, which is largely ignored by existing works. Extensive experiments on three real-world datasets demonstrate stronger performance of our method over those of baselines.|变量自动编码器(VAE)提供用户偏好的非线性概率建模。虽然它在协同过滤上取得了显著的性能，但它通常采用一个单一的向量来表示用户的偏好，这可能不足以捕捉用户的不同兴趣。现有的解决方案将 VAE 扩展到多用户兴趣模型，采用了一种变体的自我关注方法，即利用原型将项目分组到集群中，每个项目捕获用户兴趣的一个主题。尽管有所改进，但当前的设计可能更有效，因为原型是随机初始化的，并在用户之间共享，导致无信息和非个性化的集群。为了填补这一空白，我们首先在 VAE 框架中引入个性化项目分组的迭代潜在注意，以推断用户的多重兴趣。其次，我们提出加入隐式微分来改善我们的迭代求精模型的训练。再次，研究了自注意对项目分组的聚类原型进行细化的问题，但现有的研究大多忽略了这一问题。在三个真实世界数据集上的大量实验表明，我们的方法比基线方法的性能更强。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Representation+Variational+Autoencoder+via+Iterative+Latent+Attention+and+Implicit+Differentiation)|0|
|[Citation Intent Classification and Its Supporting Evidence Extraction for Citation Graph Construction](https://doi.org/10.1145/3583780.3614808)|HongJin Tsai, AnZi Yen, HenHsen Huang, HsinHsi Chen|National Yang Ming Chiao Tung University, Hsinchu, Taiwan Roc; Institute of Information Science, Academia Sinica, Taipei, Taiwan Roc; National Taiwan University, Taipei, Taiwan Roc|As the significant growth of scientific publications in recent years, an efficient way to extract scholarly knowledge and organize the relationship among literature is necessitated. Previous works constructed scientific knowledge graph with authors, papers, citations, and scientific entities. To assist researchers to grasp the research context comprehensively, this paper constructs a fine-grained citation graph in which citation intents and their supporting evidence are labeled between citing and cited papers instead. We propose a model with a Transformer encoder to encode the long-lengthy paper. To capture the coreference relations of words and sentences in a paper, a coreference graph is created by utilizing Gated Graph Convolution Network (GGCN). We further propose a graph modification mechanism to dynamically update the coreference links. Experimental results show that our model achieves promising results on identifying multiple citation intents in sentences.|近年来，随着科技出版物的大量增加，有必要采用一种有效的方法来提取学术知识，组织文献之间的关系。以往的著作构建了包括作者、论文、引文和科学实体的科学知识图表。为了帮助研究者全面把握研究背景，本文构建了一个细粒度的引文图，在引文和被引文之间标注引文意图及其支持证据。我们提出了一个模型与变压器编码器编码的长篇论文。利用门限图卷积网络(GGCN)构造共指图，以获取文章中单词和句子之间的共指关系。我们进一步提出了一个图修改机制来动态更新共引用链接。实验结果表明，该模型在识别句子中的多引文意图方面取得了较好的效果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Citation+Intent+Classification+and+Its+Supporting+Evidence+Extraction+for+Citation+Graph+Construction)|0|
|[FAMC-Net: Frequency Domain Parity Correction Attention and Multi-Scale Dilated Convolution for Time Series Forecasting](https://doi.org/10.1145/3583780.3614876)|Min Wang, Hua Wang, Fan Zhang|Shandong Technology and Business University, Yantai, China; Ludong University, Yantai, China|In recent years, time series forecasting models based on the Transformer framework have shown great potential, but they suffer from the inherent drawback of high computational complexity and only focus on global modeling. Inspired by trend-seasonality decomposition, we propose a method that combines global modeling with local feature extraction within the seasonal cycle. It aims at capturing the global view while fully exploring the potential features within each seasonal cycle and better expressing the long-term and periodic characteristics of time series. We introduce a frequency domain parity correction block to compute global attention and utilize multi-scale dilated convolution to extract local correlations within each cycle. Additionally, we adopt a dual-branch structure to separately model the seasonality and trend based on their intrinsic features, improving prediction performance and enhancing model interpretability. This model is implemented on a completely single-layer decoder architecture, breaking through the traditional encoder-decoder architecture paradigm and reducing computational complexity to a certain extent. We conducted sufficient experimental validation on eight benchmark datasets, and the results demonstrate its superior performance compared to existing methods in both univariate and multivariate forecasting.|近年来，基于变压器框架的时间序列预测模型已经显示出巨大的潜力，但它们存在着计算复杂度高的固有缺陷，只关注于全局建模。受趋势-季节性分解的启发，本文提出了一种在季节周期内将全局建模和局部特征提取相结合的方法。它的目的是捕捉全球视野，同时充分挖掘每个季节周期的潜在特征，更好地表达时间序列的长期和周期特征。我们引入一个频域奇偶校正块来计算全局注意力，并利用多尺度扩张卷积来提取每个周期内的局部相关性。此外，我们采用双分支结构，根据季节性和趋势的内在特征分别建立模型，提高了预测性能和模型的可解释性。该模型采用完全单层的解码器体系结构，突破了传统的编解码器体系结构范式，在一定程度上降低了计算复杂度。我们对八个基准数据集进行了充分的实验验证，结果表明其性能优于现有的单变量和多变量预测方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FAMC-Net:+Frequency+Domain+Parity+Correction+Attention+and+Multi-Scale+Dilated+Convolution+for+Time+Series+Forecasting)|0|
|[MultiPLe: Multilingual Prompt Learning for Relieving Semantic Confusions in Few-shot Event Detection](https://doi.org/10.1145/3583780.3614984)|Siyuan Wang, Jianming Zheng, Wanyu Chen, Fei Cai, Xueshan Luo|National University of Defense Technology, Hefei, China; National University of Defense Technology, Changsha, China|Event detection (ED) is a challenging task in the field of information extraction. Due to the monolingual text and rampant confusing triggers, traditional ED models suffer from semantic confusions in terms of polysemy and synonym, leading to severe detection mistakes. Such semantic confusions can be further exacerbated in a practical situation where scarce labeled data cannot provide sufficient semantic clues. To mitigate such bottleneck, we propose a multilingual prompt learning (MultiPLe) framework for few-shot event detection (FSED), including three components, i.e., a multilingual prompt, a hierarchical prototype and a quadruplet contrastive learning module. In detail, to ease the polysemy confusion, the multilingual prompt module develops the in-context semantics of triggers via the multilingual disambiguation and prior knowledge in pretrained language models. Then, the hierarchical prototype module is adopted to diminish the synonym confusion by connecting the captured inmost semantics of fuzzy triggers with labels at a fine granularity. Finally, we employ the quadruplet contrastive learning module to tackle the insufficient label representation and potential noise. Experiments on two public datasets show that MultiPLe outperforms the state-of-the-art baselines in weighted F1-score, presenting a maximum improvement of 13.63% for FSED.|事件检测(ED)是信息抽取领域的一项具有挑战性的任务。由于单语文本和猖獗的混淆触发，传统的 ED 模型在多义词和同义词方面存在语义混淆，导致严重的检测错误。在实际情况下，这种语义混淆可能会进一步加剧，因为稀缺的标记数据不能提供足够的语义线索。为了缓解这种瓶颈，我们提出了一个多语言提示学习(MultiPLe)框架用于少镜头事件检测(FSED) ，该框架包括三个组件，即多语言提示、层次原型和四元组对比学习模块。具体来说，为了缓解多义现象，多语言提示模块通过多语言消歧和预训练语言模型中的先验知识，开发了触发器的上下文语义。然后，采用层次化原型模块，将模糊触发器捕获的最内层语义与标签细粒度地连接起来，以消除同义词混淆。最后，我们利用四元组对比学习模组来处理不充分的标签表示和潜在的噪声。在两个公共数据集上的实验表明，MultiPLe 在加权 F1得分方面优于最先进的基线，FSED 的最大改善率为13.63% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MultiPLe:+Multilingual+Prompt+Learning+for+Relieving+Semantic+Confusions+in+Few-shot+Event+Detection)|0|
|[Understanding and Modeling Collision Avoidance Behavior for Realistic Crowd Simulation](https://doi.org/10.1145/3583780.3615098)|Zihan Yu, Guozhen Zhang, Yong Li, Depeng Jin|Tsinghua University, Beijing, China|For walking pedestrians, when they are blocked by obstacles or other pedestrians, they adjust their speeds and directions to avoid colliding with them, which is called collision avoidance behavior. This behavior is the most complex part of pedestrians' walking processes and its modeling and simulation are the keys to realistic crowd simulation, which serves as the foundation for various applications. However, most existing methods either lack the representation power to accurately model the complex collision behavior or do not model it explicitly, which leads to a poor level of realism of the simulation. To realize realistic crowd simulation, we propose to analyze, understand, and model the collision avoidance behavior in a data-driven way. First, to automatically detect collision avoidance behavior for further analysis, we propose a domain transformation algorithm that detects it by transforming the trajectories in the spatial domain into a new domain where the behavior is much more apparent and is thus easier to detect. The new domain also provides a new perspective for understanding collision avoidance behavior. Second, since there are no mature metrics to evaluate the level of realism, we propose a new evaluation metric based on the least-effort theory, which evaluates the realism of collision avoidance behavior by its physical and mental consumption. This evaluation metric also provides the foundation of modeling. Third, for realistic crowd simulation, we design a reinforcement learning model. It trains agents with our proposed reward function that models pedestrians' intrinsic needs of "reducing effort consumption'' and thus can guide agents to behave realistically when avoiding collisions. Extensive experiments show our model is 55.9% and 52.5% more realistic in collision avoidance behavior than the best baselines on two real-world datasets. We release our codes at https://github.com/tsinghua-fib-lab/TECRL.|对于行走的行人，当他们被障碍物或其他行人阻挡时，他们会调整自己的速度和方向以避免与他们发生碰撞，这种行为被称为避碰行为。这种行为是行人行走过程中最复杂的部分，其建模与模拟是真实人群模拟的关键，也是各种应用的基础。然而，现有的大多数方法要么缺乏对复杂碰撞行为进行精确建模的表示能力，要么没有对其进行明确的建模，从而导致仿真的真实性较差。为了实现真实的人群仿真，我们提出用数据驱动的方法来分析、理解和建模避碰行为。首先，为了自动检测避碰行为以便进一步分析，我们提出了一种域变换算法，该算法通过将空间域中的轨迹转换为一个新的域来检测避碰行为，该域的行为更加明显，因此更容易检测。这一新领域也为理解避碰行为提供了一个新的视角。其次，由于目前还没有成熟的指标来评价避碰行为的实际水平，本文提出了一种新的基于最小努力理论的避碰行为实际水平评价指标，即通过避碰行为的身心消耗来评价避碰行为的实际水平。这个评估指标也提供了建模的基础。第三，为了实现真实的人群模拟，我们设计了一个强化学习模型。它用我们提出的奖励函数训练代理，该函数模拟行人“减少努力消耗”的内在需求，从而可以指导代理在避免碰撞时实际行动。大量实验表明，该模型在避免碰撞行为方面比两个真实数据集上的最佳基线分别提高了55.9% 和52.5% 。我们在 https://github.com/tsinghua-fib-lab/tecrl 公布密码。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+and+Modeling+Collision+Avoidance+Behavior+for+Realistic+Crowd+Simulation)|0|
|[iLoRE: Dynamic Graph Representation with Instant Long-term Modeling and Re-occurrence Preservation](https://doi.org/10.1145/3583780.3614926)|Siwei Zhang, Yun Xiong, Yao Zhang, Xixi Wu, Yiheng Sun, Jiawei Zhang|Tencent Weixin Group, Shenzhen, China; University of California, Davis, Davis, CA, USA; Fudan University, Shanghai, China|Continuous-time dynamic graph modeling is a crucial task for many real-world applications, such as financial risk management and fraud detection. Though existing dynamic graph modeling methods have achieved satisfactory results, they still suffer from three key limitations, hindering their scalability and further applicability. i) Indiscriminate updating. For incoming edges, existing methods would indiscriminately deal with them, which may lead to more time consumption and unexpected noisy information. ii) Ineffective node-wise long-term modeling. They heavily rely on recurrent neural networks (RNNs) as a backbone, which has been demonstrated to be incapable of fully capturing node-wise long-term dependencies in event sequences. iii) Neglect of re-occurrence patterns. Dynamic graphs involve the repeated occurrence of neighbors that indicates their importance, which is disappointedly neglected by existing methods. In this paper, we present iLoRE, a novel dynamic graph modeling method with instant node-wise Long-term modeling and Re-occurrence preservation. To overcome the indiscriminate updating issue, we introduce the Adaptive Short-term Updater module that will automatically discard the useless or noisy edges, ensuring iLoRE's effectiveness and instant ability. We further propose the Long-term Updater to realize more effective node-wise long-term modeling, where we innovatively propose the Identity Attention mechanism to empower a Transformer-based updater, bypassing the limited effectiveness of typical RNN-dominated designs. Finally, the crucial re-occurrence patterns are also encoded into a graph module for informative representation learning, which will further improve the expressiveness of our method. Our experimental results on real-world datasets demonstrate the effectiveness of our iLoRE for dynamic graph modeling.|连续时间动态图建模是金融风险管理和欺诈检测等实际应用中的关键问题。现有的动态图建模方法虽然取得了令人满意的效果，但仍然存在三个关键的局限性，阻碍了其可扩展性和进一步的适用性。I)不加选择地更新。对于传入的边缘，现有的方法会不加区分地处理它们，这可能会导致更多的时间消耗和意外的噪声信息。Ii)无效的节点长期建模。它们严重依赖于回归神经网络(RNN)作为骨干，已被证明不能完全捕获事件序列中的节点长期依赖性。Iii)忽略重复出现的模式。动态图涉及到邻居的重复出现，表明了它们的重要性，这是令人失望的忽略了现有的方法。本文提出了一种新的动态图形建模方法 iLoRE，该方法具有即时节点长期建模和再现保持的特点。为了克服不加区分的更新问题，引入了自适应短期更新模块，该模块能够自动丢弃无用或有噪声的边缘，保证了 iLoRE 的有效性和即时性。我们进一步提出长期更新器来实现更有效的节点式长期建模，其中我们创新性地提出了身份注意机制来赋予基于变压器的更新器权力，绕过典型的 RNN 主导设计的有限效率。最后，将关键的重现模式编码成图模块，用于信息表示学习，进一步提高了该方法的表示能力。我们在真实世界数据集上的实验结果证明了我们的 iLoRE 对动态图形建模的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=iLoRE:+Dynamic+Graph+Representation+with+Instant+Long-term+Modeling+and+Re-occurrence+Preservation)|0|
|[Task Relation Distillation and Prototypical Pseudo Label for Incremental Named Entity Recognition](https://doi.org/10.1145/3583780.3615075)|Duzhen Zhang, Hongliu Li, Wei Cong, Rongtao Xu, Jiahua Dong, Xiuyi Chen|The Hong Kong Polytechnic University, Hong Kong, China; Shenyang Institute of Automation, Chinese Academy of Science, Shenyang, China; Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang, China; Baidu Inc., Beijing, China; Beijing Academy of Artificial Intelligence, Beijing, China|Incremental Named Entity Recognition (INER) involves the sequential learning of new entity types without accessing the training data of previously learned types. However, INER faces the challenge of catastrophic forgetting specific for incremental learning, further aggravated by background shift (i.e., old and future entity types are labeled as the non-entity type in the current task). To address these challenges, we propose a method called task Relation Distillation and Prototypical pseudo label (RDP) for INER. Specifically, to tackle catastrophic forgetting, we introduce a task relation distillation scheme that serves two purposes: 1) ensuring inter-task semantic consistency across different incremental learning tasks by minimizing inter-task relation distillation loss, and 2) enhancing the model's prediction confidence by minimizing intra-task self-entropy loss. Simultaneously, to mitigate background shift, we develop a prototypical pseudo label strategy that distinguishes old entity types from the current non-entity type using the old model. This strategy generates high-quality pseudo labels by measuring the distances between token embeddings and type-wise prototypes. We conducted extensive experiments on ten INER settings of three benchmark datasets (i.e., CoNLL2003, I2B2, and OntoNotes5). The results demonstrate that our method achieves significant improvements over the previous state-of-the-art methods, with an average increase of 6.08% in Micro F1 score and 7.71% in Macro F1 score.|增量命名实体识别(INER)涉及到新实体类型的连续学习，而不需要访问先前学习的类型的训练数据。然而，INER 面临着特定于在线机机器学习的灾难性遗忘的挑战，背景变化进一步加剧了这一挑战(即，旧的和未来的实体类型在当前任务中被标记为非实体类型)。为了解决这些问题，我们提出了一种基于 INER 的任务关系提取和原型伪标签(RDP)方法。具体来说，为了解决灾难性遗忘问题，我们引入了一个任务关系精馏方案，该方案有两个目的: 1)通过最小化任务间关系精馏损失来确保不同在线机机器学习任务间的语义一致性; 2)通过最小化任务内自熵损失来提高模型的预测置信度。同时，为了减少背景移位，我们开发了一个原型的伪标签策略，使用旧的模型区分旧的实体类型和当前的非实体类型。该策略通过测量令牌嵌入和类型原型之间的距离来生成高质量的伪标签。我们对三个基准数据集(即 CoNLL2003、 I2B2和 OntoNotes5)的10个 INER 设置进行了广泛的实验。实验结果表明，该方法在微 F1评分和宏 F1评分上的平均增长率分别为6.08% 和7.71% ，明显优于以往的最新评分方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Task+Relation+Distillation+and+Prototypical+Pseudo+Label+for+Incremental+Named+Entity+Recognition)|0|
|[Communication-Efficient Decentralized Online Continuous DR-Submodular Maximization](https://doi.org/10.1145/3583780.3614817)|Qixin Zhang, Zengde Deng, Xiangru Jian, Zaiyi Chen, Haoyuan Hu, Yu Yang|University of Waterloo, ON, Canada; City University of Hong Kong, Hong Kong, China; Cainiao Network, Hangzhou, China|Maximizing a monotone submodular function is a fundamental task in machine learning, economics, and statistics. In this paper, we present two communication-efficient decentralized online algorithms for the monotone continuous DR-submodular maximization problem, both of which reduce the number of per-function gradient evaluations and per-round communication complexity from $T^{3/2}$ to $1$. The first one, One-shot Decentralized Meta-Frank-Wolfe (Mono-DMFW), achieves a $(1-1/e)$-regret bound of $O(T^{4/5})$. As far as we know, this is the first one-shot and projection-free decentralized online algorithm for monotone continuous DR-submodular maximization. Next, inspired by the non-oblivious boosting function \citep{zhang2022boosting}, we propose the Decentralized Online Boosting Gradient Ascent (DOBGA) algorithm, which attains a $(1-1/e)$-regret of $O(\sqrt{T})$. To the best of our knowledge, this is the first result to obtain the optimal $O(\sqrt{T})$ against a $(1-1/e)$-approximation with only one gradient inquiry for each local objective function per step. Finally, various experimental results confirm the effectiveness of the proposed methods.|最大化单调子模函数是机器学习、经济学和统计学中的一个基本任务。本文针对单调连续 DR 子模极大化问题，提出了两种通信效率高的分散在线算法，它们都将每个函数的梯度估计次数和每轮通信复杂度从 $T ^ {3/2} $减少到 $1 $。第一种是一次性分散元 Frank-Wolfe (Mono-DMFW) ，它实现了 $(1-1/e) $- 后悔界 $O (T ^ {4/5}) $。据我们所知，这是第一个单调连续 DR 子模极大化的一次无投影分散在线算法。接下来，受到非遗忘增强函数 citep { zhang2022booting }的启发，我们提出了分散在线增强梯度上升(DOBGA)算法，该算法获得了 $(1-1/e) $- 后悔的 $O (sqrt { T }) $。据我们所知，这是第一个获得最优 $O (sqrt { T }) $与 $(1-1/e) $- 近似的结果，每个步骤对每个局部目标函数只有一个梯度查询。最后，各种实验结果证实了该方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Communication-Efficient+Decentralized+Online+Continuous+DR-Submodular+Maximization)|0|
|[HTMapper: Bidirectional Head-Tail Mapping for Nested Named Entity Recognition](https://doi.org/10.1145/3583780.3614919)|Jin Zhao, Zhixu Li, Yanghua Xiao, Jiaqing Liang, Jingping Liu|Fudan University & Fudan-Aishu Cognitive Intelligence Joint Research Center, Shanghai, China; East China University of Science and Technology, Shanghai, China; Fudan University, Shanghai, China|Nested named entity recognition (Nested NER) aims to identify entities with nested structures from the given text, which is a fundamental task in Natural Language Processing. The region-based approach is the current mainstream approach, which first generates candidate spans and then classifies them into predefined categories. However, this method suffers from several drawbacks, including over-reliance on span representation, vulnerability to unbalanced category distribution, and inaccurate span boundary detection. To address these problems, we propose to model the nested NER problem into a head-tail mapping problem, namely, HTMapper, which detects head boundaries first and then models a conditional mapping from head to tail under a given category. Based on this mapping, we can find corresponding tails under different categories for each detected head by enumerating all entity categories. Our approach directly models the head boundary and tail boundary of entities, avoiding over-reliance on the span representation. Additionally, Our approach utilizes category information as an indicator signal to address the imbalance of category distribution during category prediction. Furthermore, our approach enhances the detection of span boundaries by capturing the correlation between head and tail boundaries. Extensive experiments on three nested NER datasets and two flat NER datasets demonstrate that our HTMapper achieves excellent performance with F1 scores of 89.09%, 88.30%, 81.57% on ACE2004,ACE2005, GENIA, and 94.26%, 91.40% on CoNLL03, OntoNotes, respectively.|嵌套命名实体识别(NER)是自然语言处理中的一项基础性工作，其目的是从给定的文本中识别具有嵌套结构的实体。基于区域的方法是当前的主流方法，它首先生成候选范围，然后将它们分类为预定义的类别。然而，该方法存在着对跨度表示的过度依赖，容易受到类别分布不平衡的影响，以及跨度边界检测不准确等缺点。为了解决这些问题，我们提出将嵌套的 NER 问题建模为一个头尾映射问题，即 HTMapper，它首先检测头部边界，然后在给定类别下建模从头部到尾部的条件映射。基于这种映射，我们可以通过枚举所有的实体类别，为每个检测到的头找到不同类别下的相应尾。我们的方法直接建模实体的头部边界和尾部边界，避免了对跨度表示的过度依赖。此外，我们的方法利用类别信息作为指标信号，以解决类别预测过程中类别分布不均衡的问题。此外，我们的方法通过捕捉头尾边界之间的相关性来提高跨度边界的检测。在三个嵌套的 NER 数据集和两个平面的 NER 数据集上的大量实验表明，我们的 HTMapper 在 ACE2004，ACe2005，GENIA 和94.26% ，91.40% 的 CoNLL03，OntoNotes 上分别取得了89.09% ，88.30% ，81.57% 的 F1得分，取得了很好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HTMapper:+Bidirectional+Head-Tail+Mapping+for+Nested+Named+Entity+Recognition)|0|
|[GCformer: An Efficient Solution for Accurate and Scalable Long-Term Multivariate Time Series Forecasting](https://doi.org/10.1145/3583780.3615136)|Yanjun Zhao, Ziqing Ma, Tian Zhou, Mengni Ye, Liang Sun, Yi Qian|Xi'an Jiaotong University, Xi'an, China; Alibaba Group, Hangzhou, China; Alibaba Group, Bellevue, WA, USA; Xi'an Jiaotong University & Alibaba Group, hangzhou, China|Transformer-based models have emerged as promising tools for time series forecasting. However, these models cannot make accurate prediction for long input time series. On the one hand, they failed to capture long-range dependency within time series data. On the other hand, the long input sequence usually leads to large model size and high time complexity. To address these limitations, we present GCformer, which combines a structured global convolutional branch for processing long input sequences with a local Transformer-based branch for capturing short, recent signals. A cohesive framework for a global convolution kernel has been introduced, utilizing three distinct parameterization methods. The selected structured convolutional kernel in the global branch has been specifically crafted with sublinear complexity, thereby allowing for the efficient and effective processing of lengthy and noisy input signals. Empirical studies on six benchmark datasets demonstrate that GCformer outperforms state-of-the-art methods, reducing MSE error in multivariate time series benchmarks by 4.38% and model parameters by 61.92%. In particular, the global convolutional branch can serve as a plug-in block to enhance the performance of other models, with an average improvement of 31.93%, including various recently published Transformer-based models. Our code is publicly available at https://github.com/Yanjun-Zhao/GCformer.|基于变压器的模型已经成为时间序列预测的有前途的工具。然而，这些模型不能对长输入时间序列做出准确的预测。一方面，它们未能捕捉到时间序列数据的长期依赖性。另一方面，长的输入序列通常会导致大的模型规模和高的时间复杂度。为了解决这些局限性，我们提出了 GCformer，它结合了用于处理长输入序列的结构化全局卷积分支和用于捕获短的、最近的信号的基于局部变压器的分支。引入了一个全局卷积内核的内聚框架，使用了三种不同的参量化方法。全局分支中所选择的结构化卷积核具有特定的次线性复杂度，从而可以有效地处理冗长而嘈杂的输入信号。对6个基准数据集的实证研究表明，GCform 方法的性能优于最先进的方法，使多变量时间序列基准的 MSE 误差降低了4.38% ，模型参数的 MSE 误差降低了61.92% 。特别是，全局卷积分支可以作为一个插件块来增强其他模型的性能，平均改进率为31.93% ，其中包括最近发布的各种基于 Transformer 的模型。我们的代码可以在 https://github.com/yanjun-zhao/gcformer 上公开获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GCformer:+An+Efficient+Solution+for+Accurate+and+Scalable+Long-Term+Multivariate+Time+Series+Forecasting)|0|
|[DynED: Dynamic Ensemble Diversification in Data Stream Classification](https://doi.org/10.1145/3583780.3615266)|Soheil Abadifard, Sepehr Bakhshi, Sanaz Gheibuni, Fazli Can|Bilkent University, Ankara, Turkey|Ensemble methods are commonly used in classification due to their remarkable performance. Achieving high accuracy in a data stream environment is a challenging task considering disruptive changes in the data distribution, also known as concept drift. A greater diversity of ensemble components is known to enhance prediction accuracy in such settings. Despite the diversity of components within an ensemble, not all contribute as expected to its overall performance. This necessitates a method for selecting components that exhibit high performance and diversity. We present a novel ensemble construction and maintenance approach based on MMR (Maximal Marginal Relevance) that dynamically combines the diversity and prediction accuracy of components during the process of structuring an ensemble. The experimental results on both four real and 11 synthetic datasets demonstrate that the proposed approach (DynED) provides a higher average mean accuracy compared to the five state-of-the-art baselines.|集成方法由于其显著的性能，在分类中得到了广泛的应用。在数据流环境中实现高精度是一项具有挑战性的任务，考虑到数据分布的破坏性变化，也称为概念漂移。众所周知，集合分量的更大多样性可以提高这种情况下的预测精度。尽管一个集合中的组件多种多样，但并非所有组件都如预期的那样对其整体性能有贡献。这就需要一种方法来选择具有高性能和多样性的组件。提出了一种基于最大边际相关(MMR)的集成构建和维护方法，该方法在集成构建过程中动态地综合了组件的多样性和预测精度。在4个实际数据集和11个合成数据集上的实验结果表明，与5个最先进的基线相比，该方法提供了更高的平均精度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DynED:+Dynamic+Ensemble+Diversification+in+Data+Stream+Classification)|0|
|[HOVER: Homophilic Oversampling via Edge Removal for Class-Imbalanced Bot Detection on Graphs](https://doi.org/10.1145/3583780.3615264)|Bradley Ashmore, Lingwei Chen|Wright State University, Dayton, OH, USA|As malicious bots reside in a network to disrupt network stability, graph neural networks (GNNs) have emerged as one of the most popular bot detection methods. However, in most cases these graphs are significantly class-imbalanced. To address this issue, graph oversampling has recently been proposed to synthesize nodes and edges, which still suffers from graph heterophily, leading to suboptimal performance. In this paper, we propose HOVER, which implements Homophilic Oversampling Via Edge Removal for bot detection on graphs. Instead of oversampling nodes and edges within initial graph structure, HOVER designs a simple edge removal method with heuristic criteria to mitigate heterophily and learn distinguishable node embeddings, which are then used to oversample minority bots to generate a balanced class distribution without edge synthesis. Experiments on TON IoT networks demonstrate the state-of-the-art performance of HOVER on bot detection with high graph heterophily and extreme class imbalance.|由于恶意机器人驻留在网络中以破坏网络的稳定性，图神经网络(GNN)已经成为最流行的机器人检测方法之一。然而，在大多数情况下，这些图是显着的类不平衡。为了解决这个问题，最近提出了图过采样来综合节点和边，这仍然受到图异构性的影响，导致次优性能。本文提出了 HOVER 方法，通过边缘去除实现图上机器人的同态过采样检测。HOVER 设计了一种简单的基于启发式标准的边去除方法，用以消除异构性，学习可区分的节点嵌入，而不需要对初始图结构中的节点和边进行过采样，然后利用过采样的少数机器人生成一个不需要边合成的均衡类分布。在 TON 物联网上的实验表明，HOVER 在具有高度图异构性和极端类不平衡的机器人检测方面具有很好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HOVER:+Homophilic+Oversampling+via+Edge+Removal+for+Class-Imbalanced+Bot+Detection+on+Graphs)|0|
|[Accelerating Concept Learning via Sampling](https://doi.org/10.1145/3583780.3615158)|Alkid Baci, Stefan Heindorf|Paderborn University, Paderborn, Germany|Node classification is an important task in many fields, e.g., predicting entity types in knowledge graphs, classifying papers in citation graphs, or classifying nodes in social networks. In many cases, it is crucial to explain why certain predictions are made. Towards this end, concept learning has been proposed as a means of interpretable node classification: given positive and negative examples in a knowledge base, concepts in description logics are learned that serve as classification models. However, state-of-the-art concept learners, including EvoLearner and CELOE exhibit long runtimes. In this paper, we propose to accelerate concept learning with graph sampling techniques. We experiment with seven techniques and tailor them to the setting of concept learning. In our experiments, we achieve a reduction in training size by over 90% while maintaining a high predictive performance.|节点分类是知识图中实体类型预测、引文图中论文分类、社会网络中节点分类等领域的重要研究课题。在许多情况下，解释为什么做出某些预测是至关重要的。为此，概念学习被提出作为可解释节点分类的一种手段: 在知识库中给出正反两方面的例子，学习描述逻辑中作为分类模型的概念。然而，最先进的概念学习者，包括 EvoLearner 和 CELOE 展示了长时间的运行。本文提出利用图抽样技术来加速概念学习。我们试验了七种技巧，并根据概念学习的环境对它们进行调整。在我们的实验中，我们在保持高预测性能的同时，将训练规模减少了90% 以上。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Accelerating+Concept+Learning+via+Sampling)|0|
|[Unsupervised Anomaly Detection & Diagnosis: A Stein Variational Gradient Descent Approach](https://doi.org/10.1145/3583780.3615167)|Zhichao Chen, Leilei Ding, Jianmin Huang, Zhixuan Chu, Qingyang Dai, Hao Wang|Orange Labs, Sophia Antipolis, France; EURECOM & Orange, Sophia Antipolis, France; Orange, Sophia Antipolis, France; EURECOM, Biot, France|The automatic supervision of IT systems is a current challenge at Orange. Given the size and complexity reached by its IT operations, the number of sensors needed to obtain measurements over time, used to infer normal and abnormal behaviors, has increased dramatically making traditional expert-based supervision methods slow or prone to errors. In this paper, we propose a fast and stable method called UnSupervised Anomaly Detection for multivariate time series (USAD) based on adversely trained autoencoders. Its autoencoder architecture makes it capable of learning in an unsupervised way. The use of adversarial training and its architecture allows it to isolate anomalies while providing fast training. We study the properties of our methods through experiments on five public datasets, thus demonstrating its robustness, training speed and high anomaly detection performance. Through a feasibility study using Orange's proprietary data we have been able to validate Orange's requirements on scalability, stability, robustness, training speed and high performance.|IT 系统的自动监控是奥兰治目前面临的一个挑战。鉴于其 IT 操作的规模和复杂性，随着时间的推移，用于推断正常和异常行为的获取测量数据所需的传感器数量急剧增加，使得传统的基于专家的监督方法变得缓慢或容易出错。在这篇文章中，我们提出了一个快速而稳定的方法，称为多变量时间序列的无监督异常检测(USAD) ，它基于受过不良训练的自动编码器。它的自动编码器结构使它能够以无监督的方式学习。对抗性训练的使用及其架构允许它在提供快速训练的同时隔离异常。我们通过在五个公共数据集上的实验来研究我们的方法的特性，从而证明了它的鲁棒性、训练速度和高异常检测性能。通过使用 Orange 专有数据的可行性研究，我们已经能够验证 Orange 在可扩展性、稳定性、健壮性、培训速度和高性能方面的要求。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unsupervised+Anomaly+Detection+&+Diagnosis:+A+Stein+Variational+Gradient+Descent+Approach)|0|
|[Segment Augmentation and Prediction Consistency Neural Network for Multi-label Unknown Intent Detection](https://doi.org/10.1145/3583780.3615163)|Miaoxin Chen, Cao Liu, Boqi Dai, HaiTao Zheng, Ting Song, Jiansong Chen, Guanglu Wan, Rui Xie|Tsinghua Shenzhen International Graduate School, Shenzhen, China; Meituan, Shanghai, China; Meituan, Beijing, China; Tsinghua Shenzhen International Graduate School & Pengcheng Laboratory, Shenzhen, China|Multi-label unknown intent detection is a challenging task where each utterance may contain not only multiple known but also unknown intents. To tackle this challenge, pioneers proposed to predict the intent number of the utterance first, then compare it with the results of known intent matching to decide whether the utterance contains unknown intent(s). Though they have made remarkable progress on this task, their method still suffers from two important issues: 1) It is inadequate to extract multiple intents using only utterance encoding; 2) Optimizing two sub-tasks (intent number prediction and known intent matching) independently leads to inconsistent predictions. In this paper, we propose to incorporate segment augmentation rather than only use utterance encoding to better detect multiple intents. We also design a prediction consistency module to bridge the gap between the two sub-tasks. Empirical results on MultiWOZ2.3 show that our method achieves state-of-the-art performance and improves the best baseline significantly.|多标签未知意图检测是一项具有挑战性的任务，每个话语不仅包含多个已知意图，而且还包含未知意图。为了应对这一挑战，先驱者提出先预测话语的意图数量，然后将其与已知意图匹配的结果进行比较，以确定话语是否包含未知意图。尽管他们在这个任务上取得了显著的进步，但是他们的方法仍然面临两个重要的问题: 1)仅仅使用话语编码提取多个意图是不够的; 2)优化两个子任务(意图数预测和已知意图匹配)独立导致不一致的预测。在本文中，我们提出采用分段增强，而不仅仅使用话语编码，以更好地检测多个意图。同时设计了一个预测一致性模块来弥补这两个子任务之间的差距。在 MultiWOZ2.3上的实验结果表明，该方法达到了最先进的性能，并显著提高了最佳基线的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Segment+Augmentation+and+Prediction+Consistency+Neural+Network+for+Multi-label+Unknown+Intent+Detection)|0|
|[Assessing Student Performance with Multi-granularity Attention from Online Classroom Dialogue](https://doi.org/10.1145/3583780.3615143)|Jiahao Chen, Zitao Liu, Shuyan Huang, Yaying Huang, Xiangyu Zhao, Boyu Gao, Weiqi Luo|Guangdong Institute of Smart Education, Jinan University, Guangzhou, China; The Primary School attached to Jinan University, Guangzhou, China; TAL Education Group, Beijing, China; City University of Hong Kong, Hong Kong, Hong Kong|Accurately judging students' ongoing performance is very crucial for real-world educational scenarios. In this work, we focus on the task of automatically predicting students' levels of mastery of math questions from teacher-student classroom dialogue data in the online learning environment. We propose a novel neural network armed with a multi-granularity attention mechanism to capture the personalized pedagogical instructions from the very noisy teacher-student dialogue transcriptions. We conduct experiments on a real-world educational dataset and the results demonstrate the superiority and availability of our model in terms of various evaluation metrics.|准确地判断学生正在进行的表现对于真实世界的教育情景是非常关键的。在本研究中，我们主要探讨在网路学习环境下，利用师生课堂对话资料，自动预测学生数学问题的掌握程度。我们提出了一种新的神经网络，该网络具有多粒度的注意机制，可以从非常嘈杂的师生对话转录中获取个性化的教学指令。我们在一个真实的教育数据集上进行了实验，结果表明了我们的模型在各种评价指标方面的优越性和可用性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Assessing+Student+Performance+with+Multi-granularity+Attention+from+Online+Classroom+Dialogue)|0|
|[Learning Invariant Representations for New Product Sales Forecasting via Multi-Granularity Adversarial Learning](https://doi.org/10.1145/3583780.3615219)|Zhenzhen Chu, Chengyu Wang, Cen Chen, Dawei Cheng, Yuqi Liang, Weining Qian|Seek Data Group, Emoney Inc., Shanghai, China; East China Normal University, Shanghai, China; Tongji University, Shanghai, China; Alibaba Group, Hangzhou, China|Sales forecasting during the launch of new products has always been a challenging task, due to the lack of historical sales data. The dynamic market environment and consumer preferences also increase the uncertainty of predictions. Large chains face even greater difficulties due to their extensive presence across various regions. Traditional time-series forecasting methods usually rely on statistical models and empirical judgments, which are difficult to handle large, variable data and often fail to achieve satisfactory performance for new products. In this paper, we propose a Multi-granularity AdversaRial Learning framework (MARL) to leverage knowledge from old products and improve the quality of invariant representations for more accurate sales predictions. To evaluate our proposed method, we conducted extensive experiments on both a real-world dataset from a prominent international Café chain and a public dataset. The results demonstrated that our method is more effective than the existing state-of-the-art baselines for new product sales forecasting.|由于缺乏历史销售数据，新产品推出期间的销售预测一直是一项具有挑战性的任务。动态的市场环境和消费者偏好也增加了预测的不确定性。由于大型连锁企业遍布各个区域，它们面临的困难更大。传统的时间序列预测方法往往依赖于统计模型和经验判断，这些方法难以处理大量的可变数据，往往无法使新产品取得令人满意的性能。在本文中，我们提出了一个多粒度逆向学习框架(MARL) ，以利用知识从旧产品和提高质量的不变表示更准确的销售预测。为了评估我们提出的方法，我们进行了广泛的实验，从一个著名的国际咖啡连锁店和公共数据集的真实世界的数据集。结果表明，该方法比现有的新产品销售预测基准更有效。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Invariant+Representations+for+New+Product+Sales+Forecasting+via+Multi-Granularity+Adversarial+Learning)|0|
|[OnlineAutoClust: A Framework for Online Automated Clustering](https://doi.org/10.1145/3583780.3615148)|Radwa El Shawi, Dmitri Rozgonjuk|Tartu University, Tartu, Estonia|Automated Machine Learning (AutoML) has been successful when the learning task is assumed to be static. However, it remains unclear whether AutoML methods can efficiently create online pipelines in dynamic environments. The current online AutoML frameworks primarily focus on supervised learning. However, unsupervised learning, particularly clustering, also requires AutoML solutions, especially with the ambiguity associated with evaluating clustering results. In this paper, we introduce OnlineAutoClust, a framework for online automated clustering for algorithm selection and hyperparameter tuning. OnlineAutoClust combines the inherent adaptation capabilities of online learners with automated pipeline optimization using Bayesian optimization. OnlineAutoClust develops a collaborative mechanism based on clustering ensemble to combine optimized pipelines based on different internal cluster validity indices. The proposed framework is based on River library and utilizes five clustering algorithms. Empirical evaluation on several real and synthetic data streams with varying types of concept drift demonstrates the effectiveness of the proposed approach compared to existing methods|当学习任务是静态的时候，自动机器学习(AutoML)就取得了成功。然而，目前尚不清楚 AutoML 方法是否能够在动态环境中有效地创建联机管道。当前的在线 AutoML 框架主要关注监督式学习。然而，非监督式学习，尤其是集群，也需要 AutoML 解决方案，尤其是在评估集群结果时，存在模糊性。本文介绍了 OnlineAutoClust，一个用于算法选择和超参数调整的在线自动聚类框架。OnlineAutoClust 将在线学习者固有的自适应能力与使用贝叶斯优化的自动流水线优化相结合。OnlineAutoClust 开发了一种基于集群集成的协作机制，将基于不同内部集群有效性指标的优化流水线结合起来。该框架基于 River 库，采用了五种聚类算法。对具有不同类型概念漂移的实际和合成数据流进行了实证评估，结果表明该方法与现有方法相比具有较好的有效性|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=OnlineAutoClust:+A+Framework+for+Online+Automated+Clustering)|0|
|[Synergistic Disease Similarity Measurement via Unifying Hierarchical Relation Perception and Association Capturing](https://doi.org/10.1145/3583780.3615274)|Zihao Gao, Huifang Ma, Yike Wang, Zhixin Li, Liang Chang|NorthWest Normal University, Lanzhou, China; Guangxi Normal University, Guilin, China; NorthWest Normal University & Guilin University of Electronic Technology, Lanzhou, China; Guilin University of Electronic Technology, Guilin, China|Quantifying similarities among human diseases is crucial to enhance our understanding of disease biology. Deep learning efforts have been devoted to quantifying disease similarity by integrating multi-view data sources from disparate biological data. However, disease data are often sparse, leading to suboptimal representation of disease given biological entity relationships and labeled disease data are not adequately modeled. In this paper, we propose an effective Synergistic disease Similarity measurement model called SynerSim. SynerSim possesses two key components: a hierarchical biological entity relation perception module to capture disease features from various biological entities, and a disease association capturing module based on signed random walk to model precious disease data. Additionally, SynerSim leverages dual granularity contrastive learning to enhance the representation of diverse biological entities, owing to the ability to enable the synergistic supervision of diseases represented by both homogeneous and heterogeneous information. Experimental results demonstrate that SynerSim achieves outstanding performance in the disease similarity measurement.|量化人类疾病之间的相似性对于提高我们对疾病生物学的理解是至关重要的。深度学习致力于通过整合来自不同生物学数据的多视图数据源来量化疾病相似性。然而，疾病数据往往是稀疏的，导致疾病的次优表示给予生物实体关系和标记的疾病数据没有充分建模。在本文中，我们提出了一个有效的协同疾病相似性度量模型 SynerSim。SynerSim 具有两个关键部分: 一个层次化的生物实体关系感知模块，用于从各种生物实体中获取疾病特征; 一个基于签名随机游走的疾病关联获取模块，用于建模珍贵的疾病数据。此外，SynerSim 利用双粒度对比学习来增强不同生物实体的表示，这是由于能够对同质和异质信息所代表的疾病进行协同监督。实验结果表明，SynerSim 在疾病相似性度量中取得了优异的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Synergistic+Disease+Similarity+Measurement+via+Unifying+Hierarchical+Relation+Perception+and+Association+Capturing)|0|
|[Knowledge-Enhanced Multi-Label Few-Shot Product Attribute-Value Extraction](https://doi.org/10.1145/3583780.3615142)|Jiaying Gong, WeiTe Chen, Hoda Eldardiry|Rakuten Institute of Technology, Boston, MA, USA; Virginia Polytechnic Institute and State University, Blacksburg, VA, USA|Existing attribute-value extraction (AVE) models require large quantities of labeled data for training. However, new products with new attribute-value pairs enter the market every day in real-world e-Commerce. Thus, we formulate AVE in multi-label few-shot learning (FSL), aiming to extract unseen attribute value pairs based on a small number of training examples. We propose a Knowledge-Enhanced Attentive Framework (KEAF) based on prototypical networks, leveraging the generated label description and category information to learn more discriminative prototypes. Besides, KEAF integrates with hybrid attention to reduce noise and capture more informative semantics for each class by calculating the label-relevant and query-related weights. To achieve multi-label inference, KEAF further learns a dynamic threshold by integrating the semantic information from both the support set and the query set. Extensive experiments with ablation studies conducted on two datasets demonstrate that KEAF outperforms other SOTA models for information extraction in FSL. The code can be found at: https://github.com/gjiaying/KEAF|现有的属性值提取(AVE)模型需要大量的标记数据进行训练。然而，在现实的电子商务中，每天都有新的属性-价值对产品进入市场。因此，我们在多标签少镜头学习(FSL)中构造 AVE，目的是在少量训练样本的基础上提取不可见的属性值对。我们提出了一个基于原型网络的知识增强注意框架(KEAF) ，利用生成的标签描述和类别信息来学习更多的区分原型。此外，KEAF 与混合注意相结合，通过计算与标签相关和查询相关的权重来降低噪声并为每个类捕获更多的信息语义。为了实现多标签推理，KEAF 进一步通过集成来自支持集和查询集的语义信息来学习动态阈值。在两个数据集上进行的消融研究的广泛实验表明，在 FSL 中，KEAF 的性能优于其他 SOTA 模型的信息抽取。密码可在以下 https://github.com/gjiaying/keaf 找到:|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge-Enhanced+Multi-Label+Few-Shot+Product+Attribute-Value+Extraction)|0|
|[Perturbation-Based Two-Stage Multi-Domain Active Learning](https://doi.org/10.1145/3583780.3615222)|Rui He, Zeyu Dai, Shan He, Ke Tang|The Hong Kong Polytechnic University & Southern University of Science and Technology, Hong Kong, Hong Kong; University of Birmingham, Birmingham, United Kingdom; Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology & University of Birmingham, Shenzhen / Birmingham, China|In multi-domain learning (MDL) scenarios, high labeling effort is required due to the complexity of collecting data from various domains. Active Learning (AL) presents an encouraging solution to this issue by annotating a smaller number of highly informative instances, thereby reducing the labeling effort. Previous research has relied on conventional AL strategies for MDL scenarios, which underutilize the domain-shared information of each instance during the selection procedure. To mitigate this issue, we propose a novel perturbation-based two-stage multi-domain active learning (P2S-MDAL) method incorporated into the well-regarded ASP-MTL model. Specifically, P2S-MDAL involves allocating budgets for domains and establishing regions for diversity selection, which are further used to select the most cross-domain influential samples in each region. A perturbation metric has been introduced to evaluate the robustness of the shared feature extractor of the model, facilitating the identification of potentially cross-domain influential samples. Experiments are conducted on three real-world datasets, encompassing both texts and images. The superior performance over conventional AL strategies shows the effectiveness of the proposed strategy. Additionally, an ablation study has been carried out to demonstrate the validity of each component. Finally, we outline several intriguing potential directions for future MDAL research, thus catalyzing the field's advancement.|在多领域学习(MDL)场景中，由于从不同领域收集数据的复杂性，需要进行大量的标记工作。主动学习(AL)提出了一个令人鼓舞的解决方案，通过注释数量较少的高信息量的实例，从而减少了标记工作。以往的研究都依赖于传统的 AL 策略来处理 MDL 场景，这种策略在选择过程中没有充分利用每个实例的域共享信息。为了解决这一问题，我们提出了一种新的基于扰动的两阶段多域主动学习(P2S-MDAL)方法，并将其引入到广受好评的 ASP-MTL 模型中。具体来说，P2S-MDAL 涉及到为域分配预算和建立区域进行多样性选择，进一步用于选择每个区域中最具跨域影响力的样本。引入摄动度量来评估模型的共享特征提取器的鲁棒性，便于识别潜在的跨域影响样本。实验在三个真实世界的数据集上进行，包括文本和图像。相对于传统 AL 策略的优越性能表明了该策略的有效性。此外，还进行了消融研究，以证明各组分的有效性。最后，我们概述了未来 MDAL 研究的几个有趣的潜在方向，从而促进该领域的进步。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Perturbation-Based+Two-Stage+Multi-Domain+Active+Learning)|0|
|[KGrEaT: A Framework to Evaluate Knowledge Graphs via Downstream Tasks](https://doi.org/10.1145/3583780.3615241)|Nicolas Heist, Sven Hertling, Heiko Paulheim|University of Mannheim, Mannheim, Germany|In recent years, countless research papers have addressed the topics of knowledge graph creation, extension, or completion in order to create knowledge graphs that are larger, more correct, or more diverse. This research is typically motivated by the argumentation that using such enhanced knowledge graphs to solve downstream tasks will improve performance. Nonetheless, this is hardly ever evaluated. Instead, the predominant evaluation metrics - aiming at correctness and completeness - are undoubtedly valuable but fail to capture the complete picture, i.e., how useful the created or enhanced knowledge graph actually is. Further, the accessibility of such a knowledge graph is rarely considered (e.g., whether it contains expressive labels, descriptions, and sufficient context information to link textual mentions to the entities of the knowledge graph). To better judge how well knowledge graphs perform on actual tasks, we present KGrEaT - a framework to estimate the quality of knowledge graphs via actual downstream tasks like classification, clustering, or recommendation. Instead of comparing different methods of processing knowledge graphs with respect to a single task, the purpose of KGrEaT is to compare various knowledge graphs as such by evaluating them on a fixed task setup. The framework takes a knowledge graph as input, automatically maps it to the datasets to be evaluated on, and computes performance metrics for the defined tasks. It is built in a modular way to be easily extendable with additional tasks and datasets.|近年来，为了创建更大、更正确或更多样化的知识图，无数的研究论文都涉及到知识图的创建、扩展或完成等主题。这项研究是典型的动机论证，使用这种增强的知识图解决下游任务将提高性能。尽管如此，这几乎从未被评估过。相反，主要的评估指标——旨在正确性和完整性——无疑是有价值的，但是没有捕捉到完整的图景，也就是说，创建或增强的知识图实际上是多么有用。此外，这样一个知识图表的可访问性很少被考虑(例如，它是否包含表达性标签、描述和足够的上下文信息来链接文本提及到知识图表的实体)。为了更好地判断知识图表在实际任务中的表现，我们提出了 KGraT-一个通过分类、聚类或推荐等实际下游任务来评估知识图表质量的框架。KGreaT 的目的不是针对单个任务比较不同的知识图处理方法，而是通过在一个固定的任务设置上评估不同的知识图来比较不同的知识图。该框架将知识图作为输入，自动将其映射到要评估的数据集，并计算已定义任务的性能指标。它是以一种模块化的方式构建的，可以很容易地通过附加的任务和数据集进行扩展。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KGrEaT:+A+Framework+to+Evaluate+Knowledge+Graphs+via+Downstream+Tasks)|0|
|[Forgetting-aware Linear Bias for Attentive Knowledge Tracing](https://doi.org/10.1145/3583780.3615191)|Yoonjin Im, Eunseong Choi, Heejin Kook, Jongwuk Lee|Sungkyunkwan University, Suwon, Republic of Korea|Knowledge Tracing (KT) aims to track proficiency based on a question-solving history, allowing us to offer a streamlined curriculum. Recent studies actively utilize attention-based mechanisms to capture the correlation between questions and combine it with the learner's characteristics for responses. However, our empirical study shows that existing attention-based KT models neglect the learner's forgetting behavior, especially as the interaction history becomes longer. This problem arises from the bias that overprioritizes the correlation of questions while inadvertently ignoring the impact of forgetting behavior. This paper proposes a simple-yet-effective solution, namely Forgetting-aware Linear Bias (FoLiBi), to reflect forgetting behavior as a linear bias. Despite its simplicity, FoLiBi is readily equipped with existing attentive KT models by effectively decomposing question correlations with forgetting behavior. FoLiBi plugged with several KT models yields a consistent improvement of up to 2.58% in AUC over state-of-the-art KT models on four benchmark datasets.|知识追踪(KT)旨在追踪基于问题解决历史的熟练程度，使我们能够提供一个简化的课程。最近的研究积极利用基于注意的机制来捕捉问题之间的相关性，并将其与学习者的反应特征结合起来。然而，我们的实证研究表明，现有的基于注意的 KT 模型忽视了学习者的遗忘行为，特别是随着交互历史的增长。这个问题产生于一种偏见，即过度优先考虑问题的相关性，而无意中忽略了遗忘行为的影响。本文提出了一种简单而有效的解决方案，即遗忘感知线性偏差(FoLiBi) ，以反映遗忘行为作为一种线性偏差。尽管 FoLiBi 很简单，但它可以通过有效地分解与遗忘行为的问题相关性，很容易地配备现有的注意 KT 模型。在四个基准数据集上，与最先进的 KT 模型相比，用几个 KT 模型封装的 FoLiBi 在 AUC 上获得了高达2.58% 的一致性改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Forgetting-aware+Linear+Bias+for+Attentive+Knowledge+Tracing)|0|
|[Exploring Cohesive Subgraphs in Hypergraphs: The (k, g)-core Approach](https://doi.org/10.1145/3583780.3615275)|Dahee Kim, Junghoon Kim, Sungsu Lim, Hyun Ji Jeong|Ulsan National Institute of Science & Technology, Ulsan, Republic of Korea; Kongju National University, Cheonan, Republic of Korea; Chungnam National University, Daejeon, Republic of Korea|Identifying cohesive subgraphs in hypergraphs is a fundamental problem that has received recent attention in data mining and engineering fields. Existing approaches mainly focus on a strongly induced subhypergraph or edge cardinality, overlooking the importance of the frequency of co-occurrence. In this paper, we propose a new cohesive subgraph named (k,g)-core, which considers both neighbour and co-occurrence simultaneously. The $(k,g)$-core has various applications including recommendation system, network analysis, and fraud detection. To the best of our knowledge, this is the first work to combine these factors. We extend an existing efficient algorithm to find solutions for $(k,g)$-core. Finally, we conduct extensive experimental studies that demonstrate the efficiency and effectiveness of our proposed algorithm.|在超图中识别内聚子图是近年来数据挖掘和工程领域关注的一个基本问题。现有的方法主要集中在强诱导子超图或边基数上，忽略了共现频率的重要性。本文提出了一个新的内聚子图(k，g)-core，它同时考虑了邻域和共现。$(k，g) $- 核心具有各种应用程序，包括推荐系统、网络分析和欺诈检测。据我们所知，这是第一项将这些因素结合起来的工作。我们扩展了一个已有的有效算法来寻找 $(k，g) $- 核的解。最后，我们进行了广泛的实验研究，证明了我们提出的算法的效率和有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+Cohesive+Subgraphs+in+Hypergraphs:+The+(k,+g)-core+Approach)|0|
|[AmpliBias: Mitigating Dataset Bias through Bias Amplification in Few-shot Learning for Generative Models](https://doi.org/10.1145/3583780.3615184)|Donggeun Ko, Dongjun Lee, Namjun Park, Kyoungrae Noh, Hyeonjin Park, Jaekwang Kim|Sungkyunkwan University, Suwon, Republic of Korea; Sungkyunkwan University, Seoul, Republic of Korea|Deep learning models exhibit a dependency on peripheral attributes of input data, such as shapes and colors, leading the models to become biased towards these certain attributes that result in subsequent degradation of performance. In this paper, we alleviate this problem by presenting~\sysname, a novel framework that tackles dataset bias by leveraging generative models to amplify bias and facilitate the learning of debiased representations of the classifier. Our method involves three major steps. We initially train a biased classifier, denoted as f_b, on a biased dataset and extract the top-K biased-conflict samples. Next, we train a generator solely on a bias-conflict dataset comprised of these top-K samples, aiming to learn the distribution of bias-conflict samples. Finally, we re-train the classifier on the newly constructed debiased dataset, which combines the original and amplified data. This allows the biased classifier to competently learn debiased representation. Extensive experiments validate that our proposed method effectively debiases the biased classifier.|深度学习模型表现出对输入数据的外围属性(如形状和颜色)的依赖性，导致模型偏向于这些特定属性，从而导致随后的性能下降。在本文中，我们通过提出 ~ sysname 来缓解这个问题，这是一个新的框架，它通过利用生成模型来放大偏差和促进分类器去偏表示的学习来处理数据集偏差。我们的方法包括三个主要步骤。我们首先在一个有偏的数据集上训练一个有偏的分类器，表示为 f _ b，然后提取上 K 个有偏冲突的样本。接下来，我们训练一个生成器单独的偏差冲突数据集包含这些顶 K 样本，旨在学习偏差冲突样本的分布。最后，在新构造的去偏数据集上重新训练分类器，将原始数据和放大数据结合起来。这允许有偏分类器胜任地学习去偏表示。大量的实验验证了我们提出的方法有效地降低了有偏分类器。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AmpliBias:+Mitigating+Dataset+Bias+through+Bias+Amplification+in+Few-shot+Learning+for+Generative+Models)|0|
|[Causal Discovery in Temporal Domain from Interventional Data](https://doi.org/10.1145/3583780.3615177)|Peiwen Li, Yuan Meng, Xin Wang, Fang Shen, Yue Li, Jialong Wang, Wenwu Zhu|Tsinghua University & Alibaba Group, Shenzhen, China; Alibaba Group, Hangzhou, China; Tsinghua University, Beijing, China|Causal learning from observational data has garnered attention as controlled experiments can be costly. To enhance identifiability, incorporating intervention data has become a mainstream approach. However, these methods have yet to be explored in the context of time series data, despite their success in static data. To address this research gap, this paper presents a novel contribution. Firstly, a temporal interventional dataset with causal labels is introduced, derived from a data center IT room of a cloud service company. Secondly, this paper introduces TECDI, a novel approach for temporal causal discovery. TECDI leverages the smooth, algebraic characterization of acyclicity in causal graphs to efficiently uncover causal relationships. Experimental results on simulated and proposed real-world datasets validate the effectiveness of TECDI in accurately uncovering temporal causal relationships. The introduction of the temporal interventional dataset and the superior performance of TECDI contribute to advancing research in temporal causal discovery. Our datasets and codes have released at~\hrefhttps://github.com/lpwpower/TECDI https://github.com/lpwpower/TECDI.|从观测数据中进行因果学习已经引起了人们的注意，因为对照实验的成本可能很高。为了提高可识别性，合并干预数据已成为一种主流方法。然而，尽管这些方法在静态数据方面取得了成功，但在时间序列数据方面还有待进一步研究。为了解决这一研究差距，本文提出了一个新的贡献。首先，介绍了一个基于因果标签的时间干预数据集，该数据集来源于一家云服务公司的数据中心 IT 机房。其次，介绍了时间因果发现的新方法 TECDI。TECDI 利用因果图中平滑的代数角色塑造来有效地揭示因果关系。实验结果验证了 TECDI 在准确揭示时间因果关系方面的有效性。时间干预数据集的引入和 TECDI 的优越性能有助于推进时间因果发现的研究。我们的数据集和代码已经在 ~ hrefhttps:// github.com/lpwpower/tecdi  https://github.com/lpwpower/tecdi 发布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causal+Discovery+in+Temporal+Domain+from+Interventional+Data)|0|
|[T-SaS: Toward Shift-aware Dynamic Adaptation for Streaming Data](https://doi.org/10.1145/3583780.3615267)|Weijieying Ren, Tianxiang Zhao, Wei Qin, Kunpeng Liu|The Pennsylvania State University, State College, PA, USA; Portland State University, Portland , OR, USA; Hefei University of Technology, Hefei, China|In many real-world scenarios, distribution shifts exist in the streaming data across time steps. Many complex sequential data can be effectively divided into distinct regimes that exhibit persistent dynamics. Discovering the shifted behaviors and the evolving patterns underlying the streaming data are important to understand the dynamic system. Existing methods typically train one robust model to work for the evolving data of distinct distributions or sequentially adapt the model utilizing explicitly given regime boundaries. However, there are two challenges: (1) shifts in data streams could happen drastically and abruptly without precursors. Boundaries of distribution shifts are usually unavailable, and (2) training a shared model for all domains could fail to capture varying patterns. This paper aims to solve the problem of sequential data modeling in the presence of sudden distribution shifts that occur without any precursors. Specifically, we design a Bayesian framework, dubbed as T-SaS, with a discrete distribution-modeling variable to capture abrupt shifts of data. Then, we design a model that enable adaptation with dynamic network selection conditioned on that discrete variable. The proposed method learns specific model parameters for each distribution by learning which neurons should be activated in the full network. A dynamic masking strategy is adopted here to support inter-distribution transfer through the overlapping of a set of sparse networks. Extensive experiments show that our proposed method is superior in both accurately detecting shift boundaries to get segments of varying distributions and effectively adapting to downstream forecast or classification tasks.|在许多实际场景中，流数据中存在跨时间步长的分布变化。许多复杂的顺序数据可以有效地划分为具有持续动态的不同区域。发现流数据背后的移动行为和演化模式对于理解动态系统非常重要。现有的方法通常训练一个稳健的模型来处理不同分布的演化数据，或者利用明确给定的制度边界顺序调整模型。然而，有两个挑战: (1)数据流的转移可能发生剧烈和突然没有前兆。分布转移的边界通常是不可用的，(2)为所有领域训练一个共享模型可能无法捕获不同的模式。本文旨在解决在没有任何前兆的情况下发生突变分布的时序数据建模问题。具体来说，我们设计了一个被称为 T-SaS 的贝叶斯框架，其中包含一个离散的分布建模变量来捕获数据的突变。然后，我们设计了一个以该离散变量为条件的动态网络选择自适应模型。该方法通过学习在整个网络中哪些神经元应该被激活来学习每个分布的特定模型参数。该算法采用动态掩蔽策略，通过一组稀疏网络的重叠来支持分布间转移。大量实验表明，该方法在准确检测移位边界以获得变化分布的片段和有效适应下游预测或分类任务方面具有优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=T-SaS:+Toward+Shift-aware+Dynamic+Adaptation+for+Streaming+Data)|0|
|[Adversarial Density Ratio Estimation for Change Point Detection](https://doi.org/10.1145/3583780.3615248)|Shreyas S, Prakash Mandayam Comar, Sivaramakrishnan Kaveri|Amazon, Bengaluru, India|Change Point Detection (CPD) models are used to identify abrupt changes in the distribution of a data stream and have a widespread practical use. CPD methods generally compare the distribution of data sequences before and after a given time step to infer if there is a shift in distribution at the said time step. Numerous divergence measures, which measure distance between data distributions of sequence pairs, have been proposed for CPD \citeMStatisticNIPS, BergCPD and often the choice of divergence measure depends on the data used. Density Ratio Estimation (DRE) \citeRelDivCPD,BergCPD can be used to estimate a broad family of f-divergences, which includes widely used CPD divergences like Kullback-Leibler (KL) and Pearson, and thus DRE is a popular approach for CPD. In this work, we improve upon the existing DRE techniques for CPD, by proposing a novel objective that combines DRE seamlessly with adversarial sample generation. The adversarial samples allows for a robust CPD with DRE to track subtle changes in distribution, leading to a reduction in false negatives. We experiment on a wide variety of real-world, public benchmark datasets to show that our approach improves upon existing state-of-the-art (SoTA) methods, including DRE based CPD methods, by demonstrating an \sim 5% increase in F-score.|变点检测(CPD)模型用于识别数据流分布的突变，有着广泛的实际应用。CPD 方法通常比较给定时间步长前后数据序列的分布情况，以推断在给定时间步长内数据序列的分布是否有偏移。对于 CPD 引用 MStatistics-NIPS，BergCPD，已经提出了许多测量序列对数据分布之间距离的发散度量，而且发散度量的选择往往取决于所使用的数据。密度比估计(DRE) citeRelDivCPD，BergCPD 可以用来估计广泛的 f 散度族，其中包括广泛使用的 CPD 散度，如 Kullback-Leibler (KL)和 Pearson，因此 DRE 是一种流行的 CPD 方法。在这项工作中，我们改进了现有的 DRE 技术的 CPD，提出了一个新的目标，结合 DRE 无缝的对手样本生成。对手样本允许一个强大的 CPD 与 DRE 跟踪分布的微妙变化，导致减少假阴性。我们在大量真实世界的公共基准数据集上进行了实验，结果表明我们的方法比现有的最先进的(SoTA)方法(包括基于 DRE 的 CPD 方法)提高了5% 的 F 值。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adversarial+Density+Ratio+Estimation+for+Change+Point+Detection)|0|
|[Improving Diversity in Unsupervised Keyphrase Extraction with Determinantal Point Process](https://doi.org/10.1145/3583780.3615141)|Mingyang Song, Huafeng Liu, Liping Jing|Beijing Jiaotong University, Beijing, China|Keyphrase extraction aims to provide readers with high-level information about the central ideas or important topics described in a given source text. Recent advances in embedding-based models have made remarkable progress on unsupervised keyphrase extraction, demonstrated through improved quality metrics such as F1-score. However, the diversity in the keyphrase extraction task needs to be addressed. In this paper, we focus on diverse keyphrase extraction, which entails extracting keyphrases that cover different central information or essential topics in the document. To achieve this goal, we propose a re-ranking-based approach that employs determinantal point processes utilizing BERT as kernels, which we call DiversityRank. Specifically, DiversityRank jointly considers phrase-document relevance and cross-phrase similarities to select candidate keyphrases that are document-relevant and diverse. Results demonstrate that our re-ranking strategy outperforms the state-of-the-art unsupervised keyphrase extraction baselines on three benchmark datasets.|关键词提取旨在为读者提供关于给定源文本中描述的中心思想或重要主题的高级信息。基于嵌入的模型在无监督关键词提取方面取得了显著的进展，通过改进质量指标(如 F1得分)可以证明这一点。然而，关键词提取任务的多样性需要得到解决。在本文中，我们重点研究了不同的关键词提取，这涉及到提取涵盖文档中不同中心信息或基本主题的关键词。为了实现这一目标，我们提出了一种基于重新排序的方法，该方法采用行列式点过程，利用 BERT 作为内核，我们称之为 DiversityRank。具体来说，DiversityRank 联合考虑短语文档相关性和跨短语相似性，以选择与文档相关且多样化的候选关键短语。结果表明，我们的重新排序策略优于国家的最先进的无监督关键字提取基线的三个基准数据集。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Diversity+in+Unsupervised+Keyphrase+Extraction+with+Determinantal+Point+Process)|0|
|[Exposing Model Theft: A Robust and Transferable Watermark for Thwarting Model Extraction Attacks](https://doi.org/10.1145/3583780.3615211)|Ruixiang Tang, Hongye Jin, Mengnan Du, Curtis Wigington, Rajiv Jain, Xia Hu|New Jersey Institute of Technology, Newark, USA; Texas A&M Univeristy, College Station, TX, USA; Rice Univeristy, Houston, USA; Rice University, Houston, USA; Adobe, San Francisco, USA|The increasing prevalence of Deep Neural Networks (DNNs) in cloud-based services has led to their widespread use through various APIs. However, recent studies reveal the susceptibility of these public APIs to model extraction attacks, where adversaries attempt to create a local duplicate of the private model using data and API-generated predictions. Existing defense methods often involve perturbing prediction distributions to hinder an attacker's training goals, inadvertently affecting API utility. In this study, we extend the concept of digital watermarking to protect DNNs' APIs. We suggest embedding a watermark into the safeguarded APIs; thus, any model attempting to copy will inherently carry the watermark, allowing the defender to verify any suspicious models. We propose a simple yet effective framework to increase watermark transferability. By requiring the model to memorize the preset watermarks in the final decision layers, we significantly enhance the transferability of watermarks. Comprehensive experiments show that our proposed framework not only successfully watermarks APIs but also maintains their utility.|深度神经网络(DNN)在基于云的服务中日益流行，导致它们通过各种 API 被广泛使用。然而，最近的研究揭示了这些公共 API 对模型提取攻击的敏感性，在这种攻击中，对手试图使用数据和 API 生成的预测来创建私有模型的局部副本。现有的防御方法通常会扰乱预测分布，从而阻碍攻击者的训练目标，无意中影响 API 的实用性。在这项研究中，我们扩展了数字水印的概念，以保护 DNN 的 API。我们建议在受保护的 API 中嵌入一个水印; 因此，任何试图复制的模型都会带有水印，允许防御者验证任何可疑的模型。我们提出了一个简单而有效的框架来提高水印的可转移性。通过要求模型在最终决策层中存储预设置的水印，我们显著提高了水印的可转移性。综合实验表明，我们提出的框架不仅成功地实现了水印 API，而且保持了它们的实用性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exposing+Model+Theft:+A+Robust+and+Transferable+Watermark+for+Thwarting+Model+Extraction+Attacks)|0|
|[Mitigating Semantic Confusion from Hostile Neighborhood for Graph Active Learning](https://doi.org/10.1145/3583780.3615199)|Tianmeng Yang, Min Zhou, Yujing Wang, Zhengjie Lin, Lujia Pan, Bin Cui, Yunhai Tong|Peking University, Beijing, China; Huawei Cloud, Shenzhen, China; School of Intelligence Science and Technology, Peking University, Beijing, China; Huawei Noah's Ark Lab, Shenzhen, China|Graph Active Learning (GAL), which aims to find the most informative nodes in graphs for annotation to maximize the Graph Neural Networks (GNNs) performance, has attracted many research efforts but remains non-trivial challenges. One major challenge is that existing GAL strategies may introduce semantic confusion to the selected training set, particularly when graphs are noisy. Specifically, most existing methods assume all aggregating features to be helpful, ignoring the semantically negative effect between inter-class edges under the message-passing mechanism. In this work, we present Semantic-aware Active learning framework for Graphs (SAG) to mitigate the semantic confusion problem. Pairwise similarities and dissimilarities of nodes with semantic features are introduced to jointly evaluate the node influence. A new prototype-based criterion and query policy are also designed to maintain diversity and class balance of the selected nodes, respectively. Extensive experiments on the public benchmark graphs and a real-world financial dataset demonstrate that SAG significantly improves node classification performances and consistently outperforms previous methods. Moreover, comprehensive analysis and ablation study also verify the effectiveness of the proposed framework.|图形主动学习(Graph Active Learning，GAL)旨在寻找图形中信息量最大的节点进行注释，以最大限度地提高图形神经网络(Graph NeuroNetworks，GNN)的性能。一个主要的挑战是现有的 GAL 策略可能会给选定的训练集引入语义混淆，特别是当图是有噪声的时候。具体来说，大多数现有方法都假定所有聚合特性都是有用的，忽略了消息传递机制下类间边缘之间的语义负面影响。本文提出了一种基于语义感知的图主动学习框架(SAG)来缓解语义混淆问题。引入具有语义特征的节点的成对相似性和不相似性来联合评价节点的影响。设计了一种新的基于原型的准则和查询策略，分别保持所选节点的多样性和类平衡。在公共基准图和真实世界金融数据集上的大量实验表明，SAG 显著提高了节点分类性能，并始终优于以前的方法。此外，综合分析和烧蚀研究也验证了该框架的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mitigating+Semantic+Confusion+from+Hostile+Neighborhood+for+Graph+Active+Learning)|0|
|[Target-oriented Few-shot Transferring via Measuring Task Similarity](https://doi.org/10.1145/3583780.3615149)|Zhipeng Zhou, Wei Gong, Haoquan Zhou|University of Science and Technology of China, Hefei, China; The First Affiliated Hospital of USTC, Hefei, China|Despite significant progress in recent years, few-shot learning (FSL) still faces two critical challenges. Firstly, most FSL solutions in the training phase rely on exploiting auxiliary tasks, while target tasks are underutilized. Secondly, current benchmarks sample numerous target tasks, each with only an N-way C-shot shot query set in the evaluation phase, which is not representative of real-world scenarios. To address these issues, we propose Guidepost, a target-oriented FSL method that can implicitly learn task similarities using a task-level learn-to-learn mechanism and then re-weight auxiliary tasks. Additionally, we introduce a new FSL benchmark that satisfies realistic needs and aligns with our target-oriented approach. Mainstream FSL methods struggle under this new experimental setting. Extensive experiments demonstrate that Guidepost outperforms two classical few-shot learners, i.e., MAML and ProtoNet, and one state-of-the-art few-shot learner, i.e., RENet, on several FSL image datasets. Furthermore, we implement Guidepost as a domain adaptor to achieve high accuracy wireless sensing on our collected WiFi-based human activity recognition dataset.|尽管近年来取得了显著的进展，但是少镜头学习(FSL)仍然面临着两个严峻的挑战。首先，大多数 FSL 解决方案在训练阶段依赖于开发辅助任务，而目标任务未得到充分利用。其次，目前的基准测试对大量的目标任务进行抽样，每个任务在评估阶段只有一个 N 路 C 镜头查询集，不能代表真实场景。为了解决这些问题，我们提出了 Guidepost，一种面向目标的 FSL 方法，它可以使用任务级的学习学习机制隐式地学习任务的相似性，然后重新加权辅助任务。此外，我们还引入了一个新的 FSL 基准测试，它满足了现实的需求，并与我们的面向目标的方法保持一致。主流的 FSL 方法在这个新的实验环境下挣扎。大量的实验表明，Guidepost 在几个 FSL 图像数据集上优于两个经典的少镜头学习者，即 MAML 和 ProtoNet，以及一个最先进的少镜头学习者，即 RENet。此外，我们将 Guidepost 作为一个域适配器来实现在我们收集的基于 WiFi 的人类活动识别数据集上的高精度无线传感。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Target-oriented+Few-shot+Transferring+via+Measuring+Task+Similarity)|0|
|[Enhancing Catalog Relationship Problems with Heterogeneous Graphs and Graph Neural Networks Distillation](https://doi.org/10.1145/3583780.3615472)|Boxin Du, Robert A. Barton, Grant Galloway, Junzhou Huang, Shioulin Sam, Ismail B. Tutar, Changhe Yuan|Amazon, Edinburgh, United Kingdom; Amazon, Seattle, WA, USA; Amazon, New York, NY, USA|Traditionally, catalog relationship problems in e-commerce stores have been handled as pairwise classification tasks, which limit the ability of machine learning models to learn from the diverse relationships among different entities in the catalog. In this paper, we leverage heterogeneous graphs and Graph Neural Networks (GNNs) for improving catalog relationship inference. We start from investigating how to create multi-entity, multi-relationship graphs from diverse relationship data sources, and then explore how to utilizing GNNs to leverage the knowledge of the constructed graph in a self-supervised fashion. We finally propose a distillation approach to transfer the knowledge learned by GNNs into a pairwise neural network for seamless deployment in the catalog pipeline that relies on pairwise input for inductive relationship inference. Our experiments exhibit that in two of the representative catalog relationship problems, Title Authority/Contributor Authority and Broken Variation, the proposed framework is able to improve the recall at 95% precision of a pairwise baseline by up to 33.6% and 14.0%, respectively. Our findings highlight the effectiveness of this approach in advancing catalog quality maintenance and accurate relationship modeling, with potential for broader industry adoption.|传统上，电子商务商店中的目录关系问题被当作成对分类任务来处理，这限制了机器学习模型从目录中不同实体之间的不同关系中学习的能力。在本文中，我们利用异构图和图神经网络(GNN)来改进目录关系推理。本文从研究如何从不同的关系数据源创建多实体、多关系图入手，然后探讨如何利用 GNN 以自我监督的方式利用已构建图的知识。最后，我们提出了一种精馏方法，将 GNN 所学到的知识转化成成对的神经网络，以便在目录流水线中进行无缝部署，该网络依赖于成对的输入来进行归纳关系推理。我们的实验表明，在两个具有代表性的目录关系问题，标题权威/贡献者权威和断裂变异，提出的框架能够提高召回的95% 精度的成对基线高达33.6% 和14.0% ，分别。我们的研究结果强调了这种方法在提高目录质量维护和准确的关系建模方面的有效性，具有更广泛的行业采用的潜力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Catalog+Relationship+Problems+with+Heterogeneous+Graphs+and+Graph+Neural+Networks+Distillation)|0|
|[DoRA: Domain-Based Self-Supervised Learning Framework for Low-Resource Real Estate Appraisal](https://doi.org/10.1145/3583780.3615470)|WeiWei Du, WeiYao Wang, WenChih Peng|National Yang Ming Chiao Tung University, Hsinchu, Taiwan Roc|The marketplace system connecting demands and supplies has been explored to develop unbiased decision-making in valuing properties. Real estate appraisal serves as one of the high-cost property valuation tasks for financial institutions since it requires domain experts to appraise the estimation based on the corresponding knowledge and the judgment of the market. Existing automated valuation models reducing the subjectivity of domain experts require a large number of transactions for effective evaluation, which is predominantly limited to not only the labeling efforts of transactions but also the generalizability of new developing and rural areas. To learn representations from unlabeled real estate sets, existing self-supervised learning (SSL) for tabular data neglects various important features, and fails to incorporate domain knowledge. In this paper, we propose DoRA, a Domain-based self-supervised learning framework for low-resource Real estate Appraisal. DoRA is pre-trained with an intra-sample geographic prediction as the pretext task based on the metadata of the real estate for equipping the real estate representations with prior domain knowledge. Furthermore, inter-sample contrastive learning is employed to generalize the representations to be robust for limited transactions of downstream tasks. Our benchmark results on three property types of real-world transactions show that DoRA significantly outperforms the SSL baselines for tabular data, the graph-based methods, and the supervised approaches in the few-shot scenarios by at least 7.6% for MAPE, 11.59% for MAE, and 3.34% for HR10%. We expect DoRA to be useful to other financial practitioners with similar marketplace applications who need general models for properties that are newly built and have limited records. The source code is available at https://github.com/wwweiwei/DoRA.|探讨了连接需求和供应的市场体系，以便在估价财产时做出公正的决策。不动产估价师是金融机构的高成本物业估值工作之一，因为它需要专业人士根据相应的知识和市场判断来评估估值。现有的自动化评估模型降低了领域专家的主观性，需要大量的交易才能进行有效的评估，这主要限于交易的标识工作以及新发展中国家和农村地区的普遍性。为了从未标记的不动产集合中学习表示，现有的表格数据自监督学习(SSL)忽视了表格数据的各种重要特征，并且未能整合领域知识。在这篇文章中，我们提出了一个基于领域的自我监督学习框架 DoRA，用于低资源不动产估价师。DoRA 预先训练了一个样本内地理预测作为借口任务的基础上的元数据的房地产装备与先前的领域知识的房地产表示。此外，采用样本间对比学习方法，对下游任务的有限事务进行鲁棒表示。我们对现实世界事务的三种属性类型的基准测试结果显示，DoRA 显着优于表格数据的 SSL 基线，基于图表的方法和监督方法，MAPE 至少为7.6% ，MAE 为11.59% ，HR10% 为3.34% 。我们希望 DORA 对其他有类似市场应用程序的金融从业者有用，这些从业者需要针对新建房产和有限记录的通用模型。源代码可在 https://github.com/wwweiwei/dora 下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DoRA:+Domain-Based+Self-Supervised+Learning+Framework+for+Low-Resource+Real+Estate+Appraisal)|0|
|[A Stochastic Online Forecast-and-Optimize Framework for Real-Time Energy Dispatch in Virtual Power Plants under Uncertainty](https://doi.org/10.1145/3583780.3614653)|Wei Jiang, Zhongkai Yi, Li Wang, Hanwei Zhang, Jihai Zhang, Fangquan Lin, Cheng Yang|Alibaba Group, Hangzhou, China|Aggregating distributed energy resources in power systems significantly increases uncertainties, in particular caused by the fluctuation of renewable energy generation. This issue has driven the necessity of widely exploiting advanced predictive control techniques under uncertainty to ensure long-term economics and decarbonization. In this paper, we propose a real-time uncertainty-aware energy dispatch framework, which is composed of two key elements: (i) A hybrid forecast-and-optimize sequential task, integrating deep learning-based forecasting and stochastic optimization, where these two stages are connected by the uncertainty estimation at multiple temporal resolutions; (ii) An efficient online data augmentation scheme, jointly involving model pre-training and online fine-tuning stages. In this way, the proposed framework is capable to rapidly adapt to the real-time data distribution, as well as to target on uncertainties caused by data drift, model discrepancy and environment perturbations in the control process, and finally to realize an optimal and robust dispatch solution. The proposed framework won the championship in CityLearn Challenge 2022, which provided an influential opportunity to investigate the potential of AI application in the energy domain. In addition, comprehensive experiments are conducted to interpret its effectiveness in the real-life scenario of smart building energy management.|电力系统中分布式能源资源的聚集显著增加了系统的不确定性，尤其是可再生能源发电量的波动。这一问题促使人们有必要在不确定条件下广泛利用先进的预测控制技术，以确保长期的经济效益和脱碳。本文提出了一种基于不确定性的实时能量调度框架，该框架由两个关键部分组成: (1)基于深度学习的预测与随机优化相结合的混合预测与优化序列任务，这两个阶段通过多时间分辨率的不确定性估计相连接; (2)一种高效的在线数据增强方案，共同包括模型预训练阶段和在线微调阶段。这样，该框架能够快速适应实时数据分布，并能够针对控制过程中数据漂移、模型偏差和环境扰动等引起的不确定性，最终实现最优的鲁棒调度解决方案。提出的框架赢得了2022年城市学习挑战赛的冠军，这为研究人工智能在能源领域的应用潜力提供了一个有影响力的机会。此外，还进行了综合实验，以解释其在智能建筑能源管理的实际情景中的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Stochastic+Online+Forecast-and-Optimize+Framework+for+Real-Time+Energy+Dispatch+in+Virtual+Power+Plants+under+Uncertainty)|0|
|[Generating Product Insights from Community Q&A](https://doi.org/10.1145/3583780.3615480)|Lital Kuchy, Ran Levy, Avihai Mejer, Noam Segev, Shunit Agmon, Miriam Farber|Technion - Israel Institute of Technology, Haifa, Israel; Amazon, Haifa, Israel; Amazon, Tel Aviv, Israel; Unaffiliated, Haifa, Israel|In e-commerce sites, customer questions on the product details-page express the customers' information needs about the product. The answers to these questions often provide the necessary information. In this work, we present and address the novel task of generating product insights from community questions and answers (Q&A). These insights can be presented to customers to assist them in their shopping journey. Our method first generates concise, self-contained sentences based on the information in the Q&A. Then insights are selected based on the prominence of their associated questions. Empirical evaluation attests to the effectiveness of our approach in generating well-formed, objective, and helpful insights that are often not available in the product description or in summaries of customer reviews.|在电子商务网站中，客户在产品详细信息页面上提出的问题表达了客户对产品的信息需求。这些问题的答案往往提供了必要的信息。在这项工作中，我们提出并解决从社区问答(Q & A)中产生产品见解的新任务。这些见解可以呈现给客户，以帮助他们在他们的购物之旅。我们的方法首先根据问答环节中的信息生成简洁、自成一体的句子。然后根据相关问题的突出性来选择洞察力。经验性评估证明了我们的方法在产生形式良好、客观和有用的见解方面的有效性，而这些见解往往在产品描述或客户评论摘要中无法获得。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generating+Product+Insights+from+Community+Q&A)|0|
|[GBTTE: Graph Attention Network Based Bus Travel Time Estimation](https://doi.org/10.1145/3583780.3614730)|Yuecheng Rong, Juntao Yao, Jun Liu, Yifan Fang, Wei Luo, Hao Liu, Jie Ma, Zepeng Dan, Jinzhu Lin, Zhi Wu, Yan Zhang, Chuanming Zhang|Baidu Inc., Beijing, China; Xi'an Jiaotong University, Baidu Inc., Xi'an, Beijing, China; The Hong Kong University of Science and Technology (Guangzhou) & The Hong Kong University of Science and Technology, Guangzhou, HongKong, China; Xi'an Jiaotong University, Xi'an, China|Real-time bus travel time is crucial for the smart public transportation system and is beneficial for improving user satisfaction for online map services. However, it faces great challenges due to fine-grained spatial dependencies and dynamic temporal dependencies. To address the above problem, we propose GBTTE, a novel end-to-end graph attention network framework to estimate bus travel time. Specifically, we construct a novel graph structure of bus routes and use a graph attention network to capture the fine-grained spatial features of bus routes. Then, we fully exploit the joint spatial-temporal relations of bus stops through a spatial-temporal graph attention network and also capture the dynamic correlation between the route and the bus transportation network with a cross graph attention network. Finally, we integrate the route representation, the spatial-temporal representation and contextual information to estimate bus travel time. Extensive experiments carried out on two large-scale real-world datasets demonstrate the effectiveness of GBTTE. In addition, GBTTE has been deployed in production at Baidu Maps, handling tens of millions of requests every day.|实时公交出行时间是智能公交系统的关键，有利于提高用户对在线地图服务的满意度。然而，由于细粒度的空间依赖性和动态的时间依赖性，它面临着巨大的挑战。为了解决上述问题，我们提出了一种新的端到端图注意网络框架 GBTTE 来估计公共汽车行驶时间。具体来说，我们构造了一种新的公交线路图结构，并利用图注意网络来捕捉公交线路的细粒度空间特征。然后，通过时空图形注意网络充分利用公交站点之间的联合时空关系，并利用交叉图形注意网络捕捉公交线路与公交网络之间的动态相关性。最后，结合路径表示、时空表示和上下文信息对公交行程时间进行估计。在两个大规模实际数据集上进行的大量实验证明了 GBTTE 算法的有效性。此外，GBTTE 已在百度地图投入生产，每天处理数千万个请求。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GBTTE:+Graph+Attention+Network+Based+Bus+Travel+Time+Estimation)|0|
|[STREAMS: Towards Spatio-Temporal Causal Discovery with Reinforcement Learning for Streamflow Rate Prediction](https://doi.org/10.1145/3583780.3614719)|Paras Sheth, Ahmadreza Mosallanezhad, Kaize Ding, Reepal Shah, John Sabo, Huan Liu, K. Selçuk Candan|Tulane University, New Orleans, LA, USA; Arizona State University, Tempe, AZ, USA|The capacity to anticipate streamflow is critical to the efficient functioning of reservoir systems as it gives vital information to reservoir operators about water release quantities as well as help quantify the impact of environmental factors on downstream water quality. Yet, streamflow modelling is difficult owing to the intricate interactions between different watershed outlets. In this paper, we argue that one possible solution to this problem is to identify the causal structure of these outlets, which would allow for the identification of crucial watershed outlets while capturing the spatiotemporally informed complex relationships leading to improved hydrological resource management. However, due to the inherent complexity of spatiotemporal causal learning problems, extending existing causal discovery methods to a whole basin is a major hurdle. To address these issues, we offer STREAMS, a new framework that uses Reinforcement Learning (RL) to optimize the search space for causal discovery and an LSTM-GCN based autoencoder to infer spatiotemporal causal features for streamflow rate prediction. We conduct extensive experiments on the Brazos river basin carried out within the scope of a US Army Corps of Engineers, Engineering With Nature Initiative project, including empirical studies of generalization performance to verify the nature of the inferred relationships.|预测流量的能力对于水库系统的有效运作至关重要，因为它向水库管理人员提供关于水释放量的重要信息，并有助于量化环境因素对下游水质的影响。然而，由于不同流域出口之间错综复杂的相互作用，流量建模是困难的。在本文中，我们认为一个可能的解决方案是确定这些出口的因果结构，这将有助于确定关键的流域出口，同时捕捉时空信息的复杂关系，从而改善水文资源管理。然而，由于时空因果学习问题的固有复杂性，将现有的因果发现方法推广到整个流域是一个主要障碍。为了解决这些问题，我们提供了一个新的框架—— STREAMS，它使用强化学习(RL)来优化因果发现的搜索空间，以及一个基于 LSTM-gcn 的自动编码器来推断用于流量预测的时空因果特征。我们在美国陆军工兵（印度）“自然工程倡议”项目范围内对布拉索斯河流域进行了广泛的实验，包括对推断关系的性质进行泛化性能的实证研究。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=STREAMS:+Towards+Spatio-Temporal+Causal+Discovery+with+Reinforcement+Learning+for+Streamflow+Rate+Prediction)|0|
|[Combating Ad Fatigue via Frequency-Recency Features in Online Advertising Systems](https://doi.org/10.1145/3583780.3615461)|Natalia Silberstein, Or Shoham, Assaf Klein|Outbrain, Netanya, Israel|Online advertising is a driving force of Internet services today. One of the main challenges in advertising systems is finding the right balance between user experience and overall revenue. In this paper we address one of the problems that negatively impacts the user experience, specifically, the repeated display of identical ads to the same user. This problem leads to the phenomenon called "ad fatigue", characterized by diminished interest in the ad, resulting in a decrease in the click-through rate (CTR) as users encounter the same ad repeatedly. Naive solutions such as placing a hard limit on the number of times a specific ad is displayed to a specific user, usually come at the cost of reduced revenue. To address the ad fatigue problem, we introduce a new family of features, called FoRI (Frequency over Recent Intervals). FoRI features integrate information about frequency and recency of previous user-ad interactions within the CTR prediction model. This approach involves allocating these interactions to unevenly distributed time intervals, enabling a higher emphasis on more recent interactions. Furthermore, we introduce new metrics to assess ad fatigue in terms of the repetitiveness and novelty of the displayed ads. We conducted a comprehensive large-scale online evaluation which shows that integrating FoRI features into our CTR prediction model offers two-fold benefits. Firstly, it improves user experience by reducing the occurrence of repeated ads by 15%, and increasing the exposure to unseen ads by 5% (ads not previously displayed to the user), leading to a substantial boost in CTR. Secondly, it significantly increases revenue.|在线广告是当今互联网服务的驱动力。广告系统的主要挑战之一是在用户体验和总收入之间找到正确的平衡。在本文中，我们解决了一个对用户体验产生负面影响的问题，具体来说，就是对同一用户重复显示相同的广告。这个问题导致了所谓的“广告疲劳”现象，即拥有属性对广告的兴趣降低，导致用户反复看到同一个广告时点进率(ctrr)下降。一些简单的解决方案，比如对某个特定的广告向某个特定的用户显示的次数设置严格的限制，通常是以减少收入为代价的。为了解决广告疲劳问题，我们引入了一系列新的特性，称为 FoRI (最近间隔的频率)。ForRI 在 CTR 预测模型中整合了以前用户-广告交互的频率和近期信息。这种方法涉及到将这些交互分配给不均匀分布的时间间隔，从而能够更加强调最近的交互。此外，我们引入了新的指标来评估广告疲劳的重复性和新颖性的显示广告。我们进行了一次全面的大规模在线评估，结果表明将 FoRI 特征集成到我们的 CTR 预测模型中可以带来双重好处。首先，它通过减少15% 的重复广告和增加5% 的无形广告(之前没有显示给用户的广告)提高了用户体验，从而大大提高了点击率。其次，它显著增加了收入。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Combating+Ad+Fatigue+via+Frequency-Recency+Features+in+Online+Advertising+Systems)|0|
|[PRODIGY: Product Design Guidance at Scale](https://doi.org/10.1145/3583780.3615494)|Sambeet Tiady, Anirban Majumder, Deepak Gupta|Amazon, Bangalore, India|Growth of e-commerce has enabled the creation of thousands of small-scale brands. However, these brands lack information on a) what new products to develop and b) how to refine existing products to improve on business metrics. We present a comprehensive Product Design Insights and Guidance service (named PRODIGY) that mines product attributes data available on e-commerce platforms and surface insights on a) new product development and b) product refinement. Our core contribution is a novel demand forecasting model for product designs based on a notable extension of the recently proposed FTTransformer architecture combined with a self-supervised pre-training task, akin to Masked Language Modeling (MLM) objective. For the product refinement use-case, we present a novel algorithm by embedding the design search in a data-density approximator, namely Conditional Variational Autoencoder. We run a thorough and comprehensive set of experiments and establish that PRODIGY achieves significant improvement in demand prediction as compared to state-of-the-art alternatives. Finally, we present our findings from an online experiment where PRODIGY helps to launch new products with +20% lift in sales and +1.3% lift in product ratings.|电子商务的发展创造了数以千计的小规模品牌。然而，这些品牌缺乏以下信息: a)开发什么新产品; b)如何改进现有产品以提高业务指标。我们提出了一个全面的产品设计洞察和指导服务(命名为 PRODIGY) ，挖掘产品属性数据可用的电子商务平台和表面见解 a)新产品开发和 b)产品改进。我们的核心贡献是一个新颖的产品设计需求预测模型，该模型基于最近提出的 FTTransformer 架构的显著扩展，结合自我监督的预训练任务，类似于蒙版语言建模(MLM)目标。对于产品细化用例，我们提出了一种新的算法，将设计搜索嵌入到数据密度近似器中，即条件变分自动编码器。我们进行了一系列全面彻底的实验，结果表明，与最先进的方案相比，PRODIGY 在需求预测方面取得了显著的改善。最后，我们展示了一个在线实验的结果，PRODIGY 帮助推出的新产品销售额提高了20% ，产品评级提高了1.3% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PRODIGY:+Product+Design+Guidance+at+Scale)|0|
|[LittleMu: Deploying an Online Virtual Teaching Assistant via Heterogeneous Sources Integration and Chain of Teach Prompts](https://doi.org/10.1145/3583780.3615484)|Shangqing Tu, Zheyuan Zhang, Jifan Yu, Chunyang Li, Siyu Zhang, Zijun Yao, Lei Hou, Juanzi Li|Tsinghua University, Beijing, China|Teaching assistants have played essential roles in the long history of education. However, few MOOC platforms are providing human or virtual teaching assistants to support learning for massive online students due to the complexity of real-world online education scenarios and the lack of training data. In this paper, we present a virtual MOOC teaching assistant, LittleMu with minimum labeled training data, to provide question answering and chit-chat services. Consisting of two interactive modules of heterogeneous retrieval and language model prompting, LittleMu first integrates structural, semi- and unstructured knowledge sources to support accurate answers for a wide range of questions. Then, we design delicate demonstrations named "Chain of Teach" prompts to exploit the large-scale pre-trained model to handle complex uncollected questions. Except for question answering, we develop other educational services such as knowledge-grounded chit-chat. We test the system's performance via both offline evaluation and online deployment. Since May 2020, our LittleMu system has served over 80,000 users with over 300,000 queries from over 500 courses on XuetangX MOOC platform, which continuously contributes to a more convenient and fair education. Our code, services, and dataset will be available at https://github.com/THU-KEG/VTA.|教学助理在教育的悠久历史中发挥了重要作用。然而，由于现实世界在线教育场景的复杂性和缺乏培训数据，很少有 MOOC 平台提供人工或虚拟教学助理来支持大量在线学生的学习。本文介绍了一个虚拟的 MOOC 教学助手 LittleMu，它使用最少的标记训练数据来提供问答和聊天服务。LittleMu 首先集成了结构化、半结构化和非结构化的知识源，以支持对广泛问题的准确回答，它由异构检索和语言模型提示两个交互模块组成。然后，我们设计了一个名为“教学链”的精致演示，利用大规模的预训练模型来处理复杂的未收集问题。除了回答问题，我们还开发其他教育服务，例如基于知识的闲聊。我们通过离线评估和在线部署来测试系统的性能。自2020年5月以来，我们的 LittleMu 系统在学堂 X MOOC 平台上为超过80,000名用户提供了超过300,000条来自500多门课程的查询，不断为更加便利和公平的教育做出贡献。我们的代码、服务和数据集将在 https://github.com/thu-keg/vta 提供。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LittleMu:+Deploying+an+Online+Virtual+Teaching+Assistant+via+Heterogeneous+Sources+Integration+and+Chain+of+Teach+Prompts)|0|
|[MArBLE: Hierarchical Multi-Armed Bandits for Human-in-the-Loop Set Expansion](https://doi.org/10.1145/3583780.3615485)|Muntasir Wahed, Daniel Gruhl, Ismini Lourentzou|Virginia Tech, Blacksburg, VA, USA; IBM Almaden Research Center, San Jose, CA, USA|The modern-day research community has an embarrassment of riches regarding pre-trained AI models. Even for a simple task such as lexicon set expansion, where an AI model suggests new entities to add to a predefined seed set of entities, thousands of models are available. However, deciding which model to use for a given set expansion task is non-trivial. In hindsight, some models can be 'off topic' for specific set expansion tasks, while others might work well initially but quickly exhaust what they have to offer. Additionally, certain models may require more careful priming in the form of samples or feedback before being finetuned to the task at hand. In this work, we frame this model selection as a sequential non-stationary problem, where there exist a large number of diverse pre-trained models that may or may not fit a task at hand, and an expert is shown one suggestion at a time to include in the set or not, i.e., accept or reject the suggestion. The goal is to expand the list with the most entities as quickly as possible. We introduce MArBLE, a hierarchical multi-armed bandit method for this task, and two strategies designed to address cold-start problems. Experimental results on three set expansion tasks demonstrate MArBLE's effectiveness compared to baselines.|现代研究界对于预先训练好的人工智能模型有着丰富的资料，这令人尴尬。即使是像词典集扩展这样的简单任务(AI 模型建议新的实体添加到预定义的实体种子集中) ，也有数千个模型可用。然而，决定对给定的集合扩展任务使用哪个模型是非常重要的。事后看来，对于特定的集合扩展任务，一些模型可能会“偏离主题”，而其他模型可能一开始工作得很好，但很快就会用尽它们所能提供的东西。此外，某些模型可能需要以样本或反馈的形式进行更仔细的启动，然后才能适应手头的任务。在这项工作中，我们将这个模型选择框架为一个连续的非平稳问题，其中存在大量不同的预先训练的模型，这些模型可能适合也可能不适合手头的任务，并且每次向专家展示一个建议，以便将其包含在集合中，也就是说，接受或拒绝这个建议。目标是尽可能快地扩展包含最多实体的列表。我们将介绍一种用于这项任务的分层多臂老虎机方法—— MARBLE，以及用于解决冷启动问题的两种策略。在三个集合扩展任务上的实验结果证明了该算法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MArBLE:+Hierarchical+Multi-Armed+Bandits+for+Human-in-the-Loop+Set+Expansion)|0|
|[SEDAR: A Semantic Data Reservoir for Heterogeneous Datasets](https://doi.org/10.1145/3583780.3614753)|Sayed Hoseini, Ahmed Ali, Haron Shaker, Christoph Quix|RWTH Aachen University, Aachen, Germany; Fraunhofer FIT & Hochschule Niederrhein, St. Augustin & Krefeld, Germany; Hochschule Niederrhein, Krefeld, Germany|Data lakes have emerged as a solution for managing vast and diverse datasets for modern data analytics. To prevent them from becoming ungoverned, semantic data management techniques are crucial, which involve connecting metadata with knowledge graphs, following the principles of Linked Data. This semantic layer enables more expressive data management, integration from various sources and enhances data access utilizing the concepts and relations to semantically enrich the data. Some frameworks have been proposed, but requirements like data versioning, linking of datasets, managing machine learning projects, automated semantic modeling and ontology-based data access are not supported in one uniform system. We demonstrate SEDAR, a comprehensive semantic data lake that includes support for data ingestion, storage, processing, and governance with a special focus on semantic data management. The demo will showcase how the system allows for various ingestion scenarios, metadata enrichment, data source linking, profiling, semantic modeling, data integration and processing inside a machine learning life cycle.|数据湖已经成为现代数据分析中管理大量多样化数据集的解决方案。为了防止它们变得无法治理，语义数据管理技术是至关重要的，其中包括按照关联数据的原则将元数据与知识图连接起来。这个语义层支持更具表现力的数据管理、来自不同来源的集成，并利用概念和关系增强数据访问，从而在语义上丰富数据。虽然已经提出了一些框架，但是数据版本化、数据集链接、机器学习项目管理、自动语义建模和基于本体的数据访问等需求并不能在一个统一的系统中得到支持。我们演示了 SEDAR，这是一个全面的语义数据湖，包括对数据摄入、存储、处理和治理的支持，特别关注语义数据管理。演示将展示该系统如何在机器学习生命周期内实现各种摄取场景、元数据充实、数据源链接、剖析、语义建模、数据集成和处理。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SEDAR:+A+Semantic+Data+Reservoir+for+Heterogeneous+Datasets)|0|
|[EFFECTS: Explorable and Explainable Feature Extraction Framework for Multivariate Time-Series Classification](https://doi.org/10.1145/3583780.3614740)|Ido Ikar, Amit Somech|Bar-Ilan University, Ramat Gan, Israel|We demonstrate EFFECTS, an automated system for explorable and explainable feature extraction for multivariate time series classification. EFFECTS has a twofold contribution: (1) It significantly facilitates the exploration of MTSC data, and (2) it generates informative yet intuitive and explainable features to be used by the classification model. EFFECTS first mines the MTS data and extracts a set of interpretable features using an optimized transform-slice-aggregate process. To evaluate the quality of EFFECTS features, we gauge how well each feature distinguishes between every two classes, and how well they characterize each single class. Users can then explore the MTS data via the EFFECTS Explorer, which facilitates the visual inspection of important features, dimensions, and time slices. Last, the user can use the top features for each class when building a classification pipeline. We demonstrate EFFECTS on several real-world MTSC datasets, inviting the audience to investigate the data via EFFECTS Explorer and obtain initial insights on the time series data. Then, we will show how EFFECTS features are used in an ML model, and obtain accuracy that is on par with state-of-the-art MTSC models that do not optimize on explainability.|我们展示了 EFFECTS，一个用于多变量时间序列分类的可探索性和可解释性特征提取的自动化系统。EFFECTS 有两方面的贡献: (1)它极大地促进了 MTSC 数据的探索; (2)它产生了信息丰富但直观和可解释的特征，供分类模型使用。EFFECTS 首先挖掘 MTS 数据，并使用优化的转换切片聚合过程提取一组可解释的特征。为了评估 EFFECTS 特征的质量，我们衡量每个特征在每两个类之间的区别，以及它们如何很好地表征每个单一类。然后，用户可以通过 EFFECTS Explorer 浏览 MTS 数据，该浏览器便于对重要特征、尺寸和时间片进行目视检查。最后，用户可以在构建分类管道时使用每个类的顶部特性。我们在几个真实的 MTSC 数据集上演示 EFFECTS，邀请观众通过 EFFECTS 资源管理器调查数据，并获得对时间序列数据的初步认识。然后，我们将展示如何在机器学习模型中使用 EFFECTS 特征，并获得与不优化可解释性的最新 MTSC 模型相当的准确性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EFFECTS:+Explorable+and+Explainable+Feature+Extraction+Framework+for+Multivariate+Time-Series+Classification)|0|
|[Misinformation Concierge: A Proof-of-Concept with Curated Twitter Dataset on COVID-19 Vaccination](https://doi.org/10.1145/3583780.3614746)|Shakshi Sharma, Anwitaman Datta, Vigneshwaran Shankaran, Rajesh Sharma|Nanyang Technological University, Singapore, Singapore; University of Surrey, Guildford, United Kingdom; University of Tartu, Tartu, Estonia|We demonstrate the Misinformation Concierge, a proof-of-concept that provides actionable intelligence on misinformation prevalent in social media. Specifically, it uses language processing and machine learning tools to identify subtopics of discourse and discern non/misleading posts; presents statistical reports for policy-makers to understand the big picture of prevalent misinformation in a timely manner; and recommends rebuttal messages for specific pieces of misinformation, identified from within the corpus of data - providing means to intervene and counter misinformation promptly. The Misinformation Concierge proof-of-concept using a curated dataset is accessible at: https://demo-frontend-uy34.onrender.com/|我们展示了错误信息门房，一个概念的证明，提供可行的情报在社会媒体流行的错误信息。具体而言，它使用语言处理和机器学习工具来确定话语的次主题和辨别非误导性的帖子; 为决策者提供统计报告，以便及时了解流行的错误信息的大局; 并就从数据提供手段中查明的具体错误信息建议反驳信息，以便迅速干预和反击错误信息。错误信息礼宾使用策划数据集的概念验证可以在以下 https://demo-frontend-uy34.onrender.com/找到|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Misinformation+Concierge:+A+Proof-of-Concept+with+Curated+Twitter+Dataset+on+COVID-19+Vaccination)|0|
|[NumJoin: Discovering Numeric Joinable Tables with Semantically Related Columns](https://doi.org/10.1145/3583780.3614750)|Pranav Subramaniam, Udayan Khurana, Kavitha Srinivas, Horst Samulowitz|The University of Chicago, Chicago, IL, USA; IBM Research, Yorktown Heights, NY, USA|Join discovery is a crucial part of exploration on data lakes. It often involves finding joinable tables that are semantically relevant. However, data lakes often contain numeric tables with unreliable column headers, and ID columns whose text names have been lost. Finding semantically relevant joins over numeric tables is a challenge. State-of-the-art describes join discovery using semantic similarity, but do not consider purely numeric tables. In this paper, we describe a system, NumJoin that includes two novel approaches for discovering joinable tables in a data lake: one that maps tables to knowledge graphs, and another that leverages numeric types and distributions. We demonstrate the effectiveness of NumJoin on a large data lake, including transportation data and finance data.|联合发现是数据湖勘探的重要组成部分。它通常包括寻找语义相关的可接合表。但是，数据湖通常包含具有不可靠列标题的数字表和文本名已丢失的 ID 列。在数字表上查找语义相关的联接是一个挑战。最先进的技术使用语义相似性描述联接发现，但是不考虑纯数值表。在本文中，我们描述了一个系统 NumJoin，它包括两种在数据湖中发现可接合表的新方法: 一种是将表映射到知识图，另一种是利用数值类型和分布。我们展示了 NumJoin 在大型数据湖(包括运输数据和财务数据)上的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NumJoin:+Discovering+Numeric+Joinable+Tables+with+Semantically+Related+Columns)|0|
|[Cluster-Explorer: An interactive Framework for Explaining Black-Box Clustering Results](https://doi.org/10.1145/3583780.3614734)|Sariel Tutay, Amit Somech|Bar-Ilan University, Ramat Gan, Israel|Interpreting clustering results is a challenging, manual task, that often requires the user to perform additional analytical queries and visualizations. To this end, we demonstrate Cluster-Explorer, an interactive, easy-to-use framework that provides explanations for black-box clustering results. Cluster-Explorer takes as input the raw dataset alongside cluster labels, and automatically generates multiple coherent explanations that characterize each cluster. We first propose a threefold quality measure that considers the conciseness, cluster coverage, and separation error of an explanation. We tackle the challenge of efficiently computing high-quality explanations using a modified version of a generalized frequent-itemsets mining (gFIM) algorithm. The gFIM algorithm is employed over multiple filter predicates which are extracted by applying various binning methods of different granularities. We implemented Cluster-Explorer as a Python library that can be easily used by data scientists in their ongoing workflows. After employing the clustering pipeline of their choice, Cluster-Explorer opens an integrated, interactive interface for the user to explore the various different explanations for each cluster. In our demonstration, the audience is invited to use Cluster-Explorer on numerous real-life datasets and different clustering pipelines and examine the usefulness of the cluster explanations provided by the system, as well as its efficiency of computation.|解释聚类结果是一项具有挑战性的手工任务，通常需要用户执行额外的分析查询和可视化。为此，我们演示了 Cluster-Explorer，这是一个交互式的、易于使用的框架，它为黑盒集群结果提供了解释。Cluster-Explorer 将原始数据集与簇标签一起作为输入，并自动生成描述每个簇特征的多个一致的解释。我们首先提出了一个三重质量度量，它考虑了解释的简洁性、聚类覆盖率和分离误差。我们使用广义频繁项集挖掘(gFIM)算法的修改版本来解决有效计算高质量解释的挑战。GFIM 算法适用于多个过滤谓词，这些谓词是通过应用不同粒度的不同分组方法提取出来的。我们将 Cluster-Explorer 实现为一个 Python 库，数据科学家可以很容易地在他们正在进行的工作流程中使用它。在使用了他们选择的集群管道之后，Cluster-Explorer 为用户打开了一个集成的交互式界面，以探索每个集群的各种不同解释。在我们的演示中，我们邀请观众在大量的实际数据集和不同的聚类管道上使用 Cluster-Explorer，并检验系统提供的聚类解释的有用性和计算效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cluster-Explorer:+An+interactive+Framework+for+Explaining+Black-Box+Clustering+Results)|0|
|[Investigating Natural and Artificial Dynamics in Graph Data Mining and Machine Learning](https://doi.org/10.1145/3583780.3616007)|Dongqi Fu|University of Illinois at Urbana-Champaign, Urbana, IL, USA|The complexity of relationships between entities is increasing in the era of big data, leading to a growing interest in graph (network) data, owing to its ability to encode intricate relational information. Graph data mining and machine learning methods extract informative node and graph representations to support broad applications, which have been proven effective for various high-impact tasks in the fields such as computer vision, natural language processing, and recommendation systems. Despite their effectiveness, graph data mining and machine learning methods face practical challenges in real-world scenarios. First, the input graphs may change over time, making it necessary to integrate time-evolving information to enhance representation capabilities. Second, the input graphs may contain unreliable, noisy, or sub-optimal information, requiring researchers and practitioners to intentionally modify the graph topology and node features to improve downstream performance. Facing these two phenomena, our research works focus on natural and artificial dynamics for benefiting graph data mining and machine learning. In this paper, we will briefly introduce our recent works in investigative natural and artificial dynamics and point out some under-explored research problems in the interaction of these dynamics.|随着大数据时代的到来，实体间关系的复杂性日益增加，由于图形(网络)数据能够对复杂的关系信息进行编码，因此人们对图形(网络)数据的兴趣日益浓厚。图形数据挖掘和机器学习方法提取信息的节点和图形表示，以支持广泛的应用，这已被证明是有效的各种高影响力的任务，如计算机视觉，自然语言处理和推荐系统。尽管图形数据挖掘和机器学习方法很有效，但它们在现实世界中面临着实际的挑战。首先，输入图可能随着时间的推移而改变，因此有必要整合随时间演变的信息以增强表示能力。其次，输入图可能包含不可靠的、有噪声的或次优的信息，需要研究人员和从业人员有意地修改图的拓扑结构和节点特征，以改善下游性能。面对这两种现象，我们的研究工作集中在自然和人工动力学有利于图形数据挖掘和机器学习。本文简要介绍了我们近年来在自然动力学和人工动力学研究方面的工作，并指出了在这两种动力学相互作用方面尚未得到充分研究的一些问题。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Investigating+Natural+and+Artificial+Dynamics+in+Graph+Data+Mining+and+Machine+Learning)|0|
|[Intersectional Bias Mitigation in Pre-trained Language Models: A Quantum-Inspired Approach](https://doi.org/10.1145/3583780.3616003)|Omid Shokrollahi|Toronto Metropolitan University, Toronto, ON, Canada|The growing criticality of contextualized language models has raised concerns about the perpetuation of biases. Current fairness research often concentrates on single aspects of social groups. However, our study brings a multifaceted approach to the table, reflecting the intricate realities of intersectionality. We propose a bias mitigation algorithm inspired by quantum theory to fine-tune pre-trained language models. Our method applies Jensen-Shannon divergence alongside an entanglement entropy measure to quantify the complexity of entwined identities. Moreover, we utilize an innovative entanglement embedding neural network to address emergent features from different intersectional groups. An Actor-Critic setup facilitates effective fine-tuning. Our approach broadens the scope of intersectional fairness beyond just statistical parity, providing a strategic tool to tackle complex, interrelated biases. We anticipate that this fresh approach to bias mitigation will substantially enhance fairness in a wide range of language model applications.|语境化语言模式的日益严重性引起了人们对偏见长期存在的关注。当前的公平研究往往集中在社会群体的单一方面。然而，我们的研究带来了一个多方面的方法表，反映了错综复杂的现实的交叉性。我们提出了一个受量子理论启发的偏差抑制算法来微调预训练语言模型。我们的方法应用 Jensen-Shannon 散度和纠缠熵度量来量化纠缠恒等式的复杂性。此外，我们利用一个创新的纠缠嵌入式神经网络来处理不同交叉群的突现特征。演员-评论家设置有助于进行有效的微调。我们的方法扩大了交叉公平的范围，不仅仅是统计平价，提供了一个战略工具来解决复杂的，相互关联的偏见。我们期望这种新的减少偏差的方法将大大提高在广泛的语言模型应用中的公平性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Intersectional+Bias+Mitigation+in+Pre-trained+Language+Models:+A+Quantum-Inspired+Approach)|0|
|[Tutorial on User Simulation for Evaluating Information Access Systems](https://doi.org/10.1145/3583780.3615296)|Krisztian Balog, ChengXiang Zhai|University of Stavanger, Stavanger, Norway; University of Illinois at Urbana-Champaign, Urbana, IL, USA|With the emergence of various information access systems exhibiting increasing complexity, there is a critical need for sound and scalable means of automatic evaluation. To address this challenge, user simulation emerges as a promising solution. This half-day tutorial focuses on providing a thorough understanding of user simulation techniques designed specifically for evaluation purposes. We systematically review major research progress, covering both general frameworks for designing user simulators, and specific models and algorithms for simulating user interactions with search engines, recommender systems, and conversational assistants. We also highlight some important future research directions.|随着越来越复杂的各种信息获取系统的出现，迫切需要健全和可扩展的自动评价手段。为了应对这一挑战，用户模拟成为一种有前途的解决方案。本教程为期半天，重点介绍为评估目的专门设计的用户模拟技术。我们系统地回顾了主要的研究进展，包括用于设计用户模拟器的一般框架，以及用于模拟用户与搜索引擎、推荐系统和会话助手的交互的具体模型和算法。我们还强调了一些重要的未来研究方向。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tutorial+on+User+Simulation+for+Evaluating+Information+Access+Systems)|0|
|[Leveraging Graph Neural Networks for User Profiling: Recent Advances and Open Challenges](https://doi.org/10.1145/3583780.3615292)|Erasmo Purificato, Ludovico Boratto, Ernesto William De Luca|Otto von Guericke University Magdeburg & Georg Eckert Institute, Magdeburg & Brunswick, Germany; University of Cagliari, Cagliari, Italy; Otto von Guericke University Magdeburg & Georg Eckert Institute, Magdeburg, Germany|The proposed tutorial aims to familiarise the CIKM community with modern user profiling techniques that utilise Graph Neural Networks (GNNs). Initially, we will delve into the foundational principles of user profiling and GNNs, accompanied by an overview of relevant literature. We will subsequently systematically examine cutting-edge GNN architectures specifically developed for user profiling, highlighting the typical data utilised in this context. Furthermore, ethical considerations and beyond-accuracy perspectives, e.g. fairness and explainability, will be discussed regarding the potential applications of GNNs in user profiling. During the hands-on session, participants will gain practical insights into constructing and training recent GNN models for user profiling using open-source tools and publicly available datasets. The audience will actively explore the impact of these models through case studies focused on bias analysis and explanations of user profiles. To conclude the tutorial, we will analyse existing and emerging challenges in the field and discuss future research directions.|建议的教程旨在使 CIKM 社区熟悉使用图形神经网络(GNN)的现代用户分析技术。首先，我们将深入研究用户分析和 GNN 的基本原则，并对相关文献进行概述。随后，我们将系统地研究专门为用户剖析开发的前沿 GNN 体系结构，突出在这种情况下使用的典型数据。此外，关于 GNN 在用户特征分析中的潜在应用，还将讨论道德考虑和超越准确性的观点，例如公平性和可解释性。在实践会议上，与会者将获得使用开放源码工具和公开数据集构建和培训最新 GNN 模型用于用户特征分析的实用见解。受众将通过侧重于偏见分析和用户简介解释的案例研究，积极探索这些模式的影响。在结束本教程时，我们将分析该领域现有的和新出现的挑战，并讨论未来的研究方向。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Graph+Neural+Networks+for+User+Profiling:+Recent+Advances+and+Open+Challenges)|0|
|[From User Activity Traces to Navigation Graph for Software Enhancement: An Application of Graph Neural Network (GNN) on a Real-World Non-Attributed Graph](https://doi.org/10.1145/3583780.3615998)|Ikram Boukharouba, Florence Sèdes, Christophe Bortolaso, Florent Mouysset|IRIT Universite Toulouse 3 Paul Sabatier; Berger-Levrault, Toulouse, France; IRIT Universite Toulouse 3 Paul Sabatier, Toulouse, France; Berger-Levrault, Labège, France|Understanding software's user behavior is key to personalizing and enriching the user experience and improving the quality of the software. In this paper, we consider the use of user navigation graphs issued from user activity traces. The aim of our study is to do node classification over the user graph navigation in order to understand better the composition of the software and to offer a better experience to the users. Traditional baseline methods has shown good performance in the node classification task, but can't be applied for tasks as link prediction. Graph Neural Network on the contrary can satisfy both node classification and link prediction. However, GNN produce significant results when the features on the nodes are numerous enough. This is not always the case in real-world problems, because too many features implies too much data, storage issues, affect the performances of apps, etc. Indeed, due to the origin of the data and their uncontrolled generation, the resulting graphs contain few or no features (AKA non-attributed graphs). In addition, in industrial fields, some external requirements particularly legal may limit the collection and the use of data. In this article, we show that graphs issued from real-world data also have such limitations, and we propose the generation of artificial features on the nodes as a solution to this problem. The obtained results showed that the usage of artificial node features is a promising solution to overcome the greediness of GNN in terms of node features and applying GNN on the non-attributed graphs.|理解软件的用户行为是个性化和丰富用户体验以及提高软件质量的关键。在本文中，我们考虑使用用户导航图发出的用户活动跟踪。我们的研究目的是在用户图导航上进行节点分类，以便更好地了解软件的组成，并为用户提供更好的体验。传统的基线方法在节点分类任务中表现出了良好的性能，但不适用于链路预测任务。相反，图神经网络可以同时满足节点分类和链路预测。然而，当节点上的特征足够多时，GNN 会产生显著的结果。在现实世界的问题中并不总是这样，因为太多的特性意味着太多的数据、存储问题、影响应用程序的性能等等。事实上，由于数据的来源及其不受控制的生成，所得到的图包含很少或没有特征(AKA 非属性图)。此外，在工业领域，一些特别合法的外部要求可能会限制数据的收集和使用。在这篇文章中，我们表明，从现实世界的数据发布的图也有这样的局限性，我们提出了在节点上生成人工特征作为这个问题的解决方案。结果表明，利用人工节点特征克服 GNN 在节点特征方面的贪婪性，并将 GNN 应用于非属性图是一种有前途的解决方案。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=From+User+Activity+Traces+to+Navigation+Graph+for+Software+Enhancement:+An+Application+of+Graph+Neural+Network+(GNN)+on+a+Real-World+Non-Attributed+Graph)|0|
|[Proactive and Automatic Detection of Product Misclassifications at Massive Scale](https://doi.org/10.1145/3583780.3615510)|Ling Jiang, Xiaoyu Chu, Saaransh Gulati, Pulkit Garg, Andrew Borthwick, Gang Luo|Amazon, Sunnyvale, CA, USA; Amazon & University of Washington, Seattle, WA, USA; Amazon, Seattle, WA, USA|In e-commerce, product classification is widely used for various purposes. Misclassifying products can cause compliance issues and hurt the company's reputation. To address this problem, we propose an automated system to proactively detect product misclassifications by overcoming several challenges. A large e-commerce retailer can sell billions of distinct products, on which many thousands of classification tasks are performed. At this massive scale, we need to quickly detect misclassifications under a limited budget. In this talk, we point out these challenges and show how we design our system to handle them. When evaluated on a set of Amazon's product classification data, at an overhead of <10% of the classification cost, our system automatically identified and corrected many misclassifications, which would take a human many thousand years to manually find and 14.6 years to manually review and correct if our system were not used.|在电子商务中，产品分类被广泛用于各种目的。错误分类产品可能会导致法规遵循问题，并损害公司的声誉。为了解决这个问题，我们提出了一个自动化系统，通过克服几个挑战来主动检测产品错误分类。大型电子商务零售商可以销售数十亿种不同的产品，在这些产品上执行成千上万的分类任务。在如此巨大的规模下，我们需要在有限的预算下快速发现错误分类。在这个演讲中，我们指出了这些挑战，并展示了我们如何设计系统来应对它们。当在亚马逊的一组产品分类数据上进行评估时，我们的系统自动识别和纠正了许多错误分类，如果我们的系统没有被使用，这将需要人类数千年的时间来手动发现和14.6年的时间来手动审查和纠正。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Proactive+and+Automatic+Detection+of+Product+Misclassifications+at+Massive+Scale)|0|
|[KID34K: A Dataset for Online Identity Card Fraud Detection](https://doi.org/10.1145/3583780.3615122)|EunJu Park, SeungYeon Back, Jeongho Kim, Simon S. Woo|Sungkyunkwan University, Suwon, Republic of Korea; Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea|Though digital financial systems have provided users with convenient and accessible services, such as supporting banking or payment services anywhere, it is necessary to have robust security to protect against identity misuse. Thus, online digital identity (ID) verification plays a crucial role in securing financial services on mobile platforms. One of the most widely employed techniques for digital ID verification is that mobile applications request users to take and upload a picture of their own ID cards. However, this approach has vulnerabilities where someone takes pictures of the ID cards belonging to another person displayed on a screen, or printed on paper to be verified as the ID card owner. To mitigate the risks associated with fraudulent ID card verification, we present a novel dataset for classifying cases where the ID card images that users upload to the verification system are genuine or digitally represented. Our dataset is replicas designed to resemble real ID cards, making it available while avoiding privacy issues. Through extensive experiments, we demonstrate that our dataset is effective for detecting digitally represented ID card images, not only in our replica dataset but also in the dataset consisting of real ID cards. Our dataset is available at https://github.com/DASH-Lab/idcard_fraud_detection.|虽然数字金融系统为用户提供了方便易用的服务，例如在任何地方支持银行或支付服务，但必须有强大的安全保障，以防止身份被滥用。因此，在线数字身份(ID)验证在保障移动平台上的金融服务安全方面起着至关重要的作用。数字身份验证最广泛使用的技术之一是，移动应用程序要求用户拍摄并上传自己身份证的照片。然而，这种方法存在一些漏洞，即有人将属于另一个人的身份证照片显示在屏幕上，或打印在纸上，以便核实身份证持有人。为了减低验证伪造身份证的风险，我们提供了一个新的数据集，用于分类用户上载到验证系统的身份证图像是真实或数码表示的情况。我们的数据集是复制品，设计得像真正的身份证，使其可用，同时避免隐私问题。通过大量的实验，我们证明了我们的数据集对于检测数字表示的身份证图像是有效的，不仅在我们的副本数据集中，而且在由真实身份证组成的数据集中。我们的数据集 https://github.com/dash-lab/idcard_fraud_detection 可用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KID34K:+A+Dataset+for+Online+Identity+Card+Fraud+Detection)|0|
|[OpenGDA: Graph Domain Adaptation Benchmark for Cross-network Learning](https://doi.org/10.1145/3583780.3615127)|Boshen Shi, Yongqing Wang, Fangda Guo, Jiangli Shao, Huawei Shen, Xueqi Cheng|Institute of Computing Technology, CAS, Beijing, China; Institute of Computing Technology, CAS & University of Chinese Academy of Sciences, Beijing, China|Graph domain adaptation models are widely adopted in cross-network learning tasks, with the aim of transferring labeling or structural knowledge. Currently, there mainly exist two limitations in evaluating graph domain adaptation models. On one side, they are primarily tested for the specific cross-network node classification task, leaving tasks at edge-level and graph-level largely under-explored. Moreover, they are primarily tested in limited scenarios, such as social networks or citation networks, lacking validation of model's capability in richer scenarios. As comprehensively assessing models could enhance model practicality in real-world applications, we propose a benchmark, known as OpenGDA. It provides abundant pre-processed and unified datasets for different types of tasks (node, edge, graph). They originate from diverse scenarios, covering web information systems, urban systems and natural systems. Furthermore, it integrates state-of-the-art models with standardized and end-to-end pipelines. Overall, OpenGDA provides a user-friendly, scalable and reproducible benchmark for evaluating graph domain adaptation models. The benchmark experiments highlight the challenges of applying GDA models to real-world applications with consistent good performance, and potentially provide insights to future research. As an emerging project, OpenGDA will be regularly updated with new datasets and models. It could be accessed from https://github.com/Skyorca/OpenGDA.|图域自适应模型广泛应用于跨网络学习任务中，其目的是传递标记或结构化知识。目前，评估图域自适应模型主要存在两个局限性。一方面，它们主要针对特定的跨网络节点分类任务进行测试，使得边缘层和图层的任务在很大程度上没有得到充分的探索。此外，它们主要在有限的场景中进行测试，如社交网络或引文网络，缺乏对模型在更丰富场景中的能力的验证。由于综合评估模型可以增强模型在实际应用中的实用性，我们提出了一个基准，称为 OpenGDA。它为不同类型的任务(节点、边、图)提供了丰富的预处理和统一的数据集。它们来源于不同的场景，包括网络信息系统、城市系统和自然系统。此外，它还将最先进的模型与标准化的端到端管道集成在一起。总的来说，OpenGDA 为评估图形域适应模型提供了一个用户友好、可伸缩和可重复的基准。基准实验突出了将 GDA 模型应用于具有一致良好性能的现实世界应用程序的挑战，并可能为未来的研究提供深刻见解。作为一个新兴的项目，OpenGDA 将定期更新新的数据集和模型。可以从 https://github.com/skyorca/opengda 进入。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=OpenGDA:+Graph+Domain+Adaptation+Benchmark+for+Cross-network+Learning)|0|
|[Generative AI and the Future of Information Access](https://doi.org/10.1145/3583780.3615317)|Chirag Shah|University of Washington, Seattle, WA, USA|The prominent model of retrieving, evaluating, and using relevant information from databases, collections, and the web is going through a significant transformation. This is largely due to wide-scale availability of various generative AI systems that can take in natural language inputs and generate highly customized natural language text, images, audio, and videos. This transformation in how people seek and access information will have profound impacts on users, developers, and policymakers. It is already changing many sectors including education, health, and commerce. But the hopes and hypes of generative AI are often not clear as we get swept up by either the current capabilities and limitations of this technology in the short term or fear from speculative future in the long term. Instead, I believe we need to approach this area pragmatically and with scientific curiosity, scholarly rigor, and societal responsibility. In this talk, I will highlight some of the opportunities and challenges for information access stemming from recent advancements in generative AI. For instance, there are new possibilities now for addressing accessibility, low-resource domains, and bias in training data using generative AI tools. On the other hand, there are new challenges concerning hallucination, toxicity, and information provenance. It is clear that we want to benefit from what AI systems are capable of, but how do we do that while curbing some of these problems? I will argue that the solution is multifaceted and complex -- some will require technical advancements and others will call for policy changes. We will need to not only build information systems with fairness, transparency, and accountability in mind, but also train a new generation of developers, policymakers, and of course the users. The goal here is to cut through both hype and fear and think pragmatically about the future of information access.|检索、评估和使用来自数据库、集合和网络的相关信息的突出模式正在经历一个重大转变。这在很大程度上归功于各种生成 AI 系统的广泛应用，这些系统可以接收自然语言输入并生成高度定制的自然语言文本、图像、音频和视频。人们如何寻找和获取信息的这种转变将对用户、开发人员和决策者产生深远的影响。它已经改变了包括教育、卫生和商业在内的许多领域。但是，生成性人工智能的希望和炒作往往并不明朗，因为我们要么在短期内被这种技术的当前能力和局限性所席卷，要么在长期内对投机性未来感到恐惧。相反，我认为我们需要以务实的态度，带着科学的好奇心、学术的严谨性和社会责任感来处理这个问题。在这次演讲中，我将强调一些信息获取的机遇和挑战，这些机遇和挑战来自生成性人工智能的最新进展。例如，现在有新的可能性解决可访问性，低资源领域，和偏见的训练数据使用生成人工智能工具。另一方面，有关幻觉，毒性和信息来源的新挑战。很明显，我们希望从人工智能系统的能力中获益，但我们如何做到这一点，同时抑制其中一些问题？我认为解决方案是多方面和复杂的——有些需要技术进步，有些需要政策变更。我们不仅需要建立公平、透明和负责任的信息系统，还需要培训新一代的开发人员、决策者，当然还有用户。这里的目标是消除大肆宣传和恐惧，实事求是地思考信息访问的未来。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generative+AI+and+the+Future+of+Information+Access)|0|
|[Knowledge Graphs for Knowing More and Knowing for Sure](https://doi.org/10.1145/3583780.3615316)|Steffen Staab|University of Stuttgart, Sttutgart, Germany|Knowledge graphs have been conceived to collect heterogeneous data and knowledge about large domains, e.g. medical or engineering domains, and to allow versatile access to such collections by means of querying and logical reasoning. A surge of methods has responded to additional requirements in recent years. (i) Knowledge graph embeddings use similarity and analogy of structures to speculatively add to the collected data and knowledge. (ii) Queries with shapes and schema information can be typed to provide certainty about results. We survey both developments and find that the development of techniques happens in disjoint communities that mostly do not understand each other, thus limiting the proper and most versatile use of knowledge graphs.|知识图表被设计用来收集关于大型领域(例如医疗或工程领域)的异质数据和知识，并允许通过查询和逻辑推理的方式对这些收集进行多种访问。近年来，随着需求的增加，各种方法应运而生。(i)知识图嵌入使用结构的相似性和类比性来推测性地增加收集的数据和知识。(ii)可以键入带有形状和模式信息的查询，以提供关于结果的确定性。我们调查了这两方面的发展，发现技术的发展发生在不相连的社区，这些社区大多彼此不了解，从而限制了知识图表的正确和最多才多艺的使用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge+Graphs+for+Knowing+More+and+Knowing+for+Sure)|0|
|[Optimizing for Member Value in an Edge Building Marketplace](https://doi.org/10.1145/3583780.3615000)|Ayan Acharya, Siyuan Gao, Ankan Saha, Borja Ocejo, Kinjal Basu, Sathiya Keerthi Selvaraj, Rahul Mazumder, Aman Gupta, Parag Agrawal, Ayan Acharya|LinkedIn Inc., Sunnyvale, CA, USA; Aliveo AI, Austin, TX, USA; LinkedIn Inc. (MIT), Sunnyvale (Cambridge), USA|Social networks are prosperous marketplaces where creators and consumers congregate to share and consume various content. In general, products that rank content for distribution (such as newsfeeds, stories, and notifications) and are related to edge recommendations (such as connect to members, follow celebrities or groups or hashtags) optimize the experience of active users. Typically, such users generate ample interaction data amenable to accurate model training and prediction. In contrast, we prioritize enhancing the experience of inactive members (IMs) who do not have a rich connection network. We formulate strategies for recommending superior edges to help members grow their connection network. Adapting the recommendations provides enormous value to the IMs and can significantly influence their future behaviour and engagement with the ecosystem. To that end, we propose a general and scalable multi-objective optimization (MOO) framework to provide more value to IMs as invitation recipients on LinkedIn, a professional network with over 900M members. To deal with the enormous scale, we formulate the problem as a massive constrained linear optimization involving billions of variables and millions of constraints and efficiently solve it using accelerated gradient descent,making this the largest deployment of LP-based recommender systems worldwide. Furthermore, the proposed MOO paradigm can solve the general problem of matching different types of entities in an m-sided marketplace. Finally, we discuss the challenges and benefits of implementing and ramping our method in production at scale at LinkedIn and report our findings about the core business metrics related to users' engagement and network health.|社交网络是繁荣的市场，创作者和消费者聚集在一起分享和消费各种内容。一般来说，对发布内容进行排名的产品(如新闻源、故事和通知)和与边缘推荐相关的产品(如与成员联系、关注名人或群组或标签)优化了活跃用户的体验。通常，这样的用户生成大量的交互数据，可以进行精确的模型训练和预测。相比之下，我们优先考虑增强没有丰富连接网络的非活动成员(IM)的体验。我们制定策略，推荐优势，以帮助会员发展他们的联系网络。采纳这些建议为管理系统提供了巨大的价值，可以对它们今后的行为和与生态系统的接触产生重大影响。为此，我们提出了一个通用的和可扩展的多目标优化(MOO)框架，以提供更多的价值即时通讯作为邀请收件人在 LinkedIn，一个专业网络超过900万成员。为了解决这个庞大的问题，我们将这个问题表述为一个涉及数十亿变量和数百万约束的大规模约束线性优化问题，并使用加速梯度下降法有效地解决这个问题，从而使这个问题成为全球范围内基于 LP 的推荐系统中规模最大的部署。此外，提出的 MOO 范式可以解决在多边市场中匹配不同类型实体的一般问题。最后，我们在 LinkedIn 上讨论了在大规模生产中实施和扩展我们的方法的挑战和好处，并报告了我们关于与用户参与和网络健康相关的核心业务指标的发现。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimizing+for+Member+Value+in+an+Edge+Building+Marketplace)|0|
|[Interpretable Natural Language Understanding](https://doi.org/10.1145/3583780.3615315)|Yulan He|Sun Yat-sen University; Beihang University; Tsinghua University; Microsoft Research AI; Mila; South China University of Technology|Recently generating natural language explanations has shown very promising results in not only offering interpretable explanations but also providing additional information and supervision for prediction. However, existing approaches usually require a large set of human annotated explanations for training while collecting a large set of explanations is not only time consuming but also expensive. In this paper, we develop a general framework for interpretable natural language understanding that requires only a small set of human annotated explanations for training. Our framework treats natural language explanations as latent variables that model the underlying reasoning process of a neural model. We develop a variational EM framework for optimization where an explanation generation module and an explanation-augmented prediction module are alternatively optimized and mutually enhance each other. Moreover, we further propose an explanation-based self-training method under this framework for semi-supervised learning. It alternates between assigning pseudo-labels to unlabeled data and generating new explanations to iteratively improve each other. Experiments on two natural language understanding tasks demonstrate that our framework can not only make effective predictions in both supervised and semi-supervised settings, but also generate good natural language explanation.|最近生成的自然语言解释已经显示出非常有希望的结果，不仅提供可解释的解释，而且提供额外的信息和监督预测。然而，现有的方法通常需要大量的人工注释解释来进行培训，而收集大量的解释不仅耗费时间，而且成本高昂。在本文中，我们开发了一个可解释的自然语言理解的一般框架，只需要一小组人工注释的训练解释。我们的框架将自然语言解释作为潜在变量，模拟神经模型的潜在推理过程。本文提出了一个变分 EM 优化框架，其中解释生成模块和解释增强预测模块交替优化并相互增强。此外，我们进一步建议在这个架构下，采用以解释为本的自我训练方法，训练半监督学习。它可以将伪标签分配给未标记的数据，也可以生成新的解释以反复改进彼此。在两个自然语言理解任务上的实验表明，该框架不仅能够在监督和半监督环境下进行有效的预测，而且能够产生良好的自然语言解释。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interpretable+Natural+Language+Understanding)|0|
|[Deep Integrated Explanations](https://doi.org/10.1145/3583780.3614836)|Oren Barkan, Yehonatan Elisha, Jonathan Weill, Yuval Asher, Amit Eshel, Noam Koenigstein|The Open University, Raanana, Israel; Tel Aviv University, Tel Aviv, Israel|This paper presents Deep Integrated Explanations (DIX) - a universal method for explaining vision models. DIX generates explanation maps by integrating information from the intermediate representations of the model, coupled with their corresponding gradients. Through an extensive array of both objective and subjective evaluations spanning diverse tasks, datasets, and model configurations, we showcase the efficacy of DIX in generating faithful and accurate explanation maps, while surpassing current state-of-the-art methods. Our code is available at: https://github.com/dix-cikm23/dix|本文介绍了深度集成解释(DIX)——一种解释视觉模型的通用方法。DIX 通过集成来自模型中间表示的信息以及它们相应的梯度来生成解释映射。通过跨越不同任务，数据集和模型配置的客观和主观评估的广泛阵列，我们展示了 DIX 在生成忠实和准确的解释地图方面的功效，同时超越了当前的最先进的方法。我们的代码可以在以下 https://github.com/dix-cikm23/dix 找到|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Integrated+Explanations)|0|
|[MPMRC-MNER: A Unified MRC framework for Multimodal Named Entity Recognition based Multimodal Prompt](https://doi.org/10.1145/3583780.3614975)|Xigang Bao, Mengyuan Tian, Zhiyuan Zha, Biao Qin|Renmin University of China, Beijing, China|Multimodal named entity recognition (MNER) is a vision-language task, which aims to detect entity spans and classify them to corresponding entity types given a sentence-image pair. Existing methods often regard an image as a set of visual objects, trying to explicitly capture the relations between visual objects and entities. However, since visual objects are often not identical to entities in quantity and type, they may suffer the bias introduced by visual objects rather than aid. Inspired by the success of textual prompt-based fine-tuning (PF) approaches in many methods, in this paper, we propose a Multimodal Prompt-based Machine Reading Comprehension based framework to implicit alignment between text and image for improving MNER, namely MPMRC-MNER. Specifically, we transform text-only query in MRC into multimodal prompt containing image tokens and text tokens. To better integrate image tokens and text tokens, we design a prompt-aware attention mechanism for better cross-modal fusion. At last, contrastive learning with two types of contrastive losses is designed to learn more consistent representation of two modalities and reduce noise. Extensive experiments and analyses on two public MNER datasets, Twitter2015 and Twitter2017, demonstrate the better performance of our model against the state-of-the-art methods.|多模态命名实体识别(MNER)是一个视觉语言任务，其目的是检测实体跨度，并将其分类为相应的实体类型给出一个句子-图像对。现有的方法通常将图像视为一组可视对象，试图显式地捕获可视对象和实体之间的关系。然而，由于视觉对象在数量和类型上往往与实体不完全相同，它们可能受到视觉对象引入的偏见的影响，而不是受到辅助的影响。受基于文本提示的微调(PF)方法在许多方法中取得成功的启发，本文提出了一种基于多模式提示的机器阅读理解的框架，用于文本和图像之间的隐式对齐以改善 MNER，即 MPMRC-MNER。具体来说，我们将 MRC 中的纯文本查询转换为包含图像标记和文本标记的多模式提示。为了更好地集成图像标记和文本标记，我们设计了一种更好的跨模态融合的快速感知注意机制。最后，设计了两种对比损失下的对比学习算法，使两种模式的表示更加一致，从而降低了噪声。对两个公开的 MNER 数据集 Twitter2015和 Twitter2017进行了大量的实验和分析，证明了我们的模型比最先进的方法具有更好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MPMRC-MNER:+A+Unified+MRC+framework+for+Multimodal+Named+Entity+Recognition+based+Multimodal+Prompt)|0|
|[Bridged-GNN: Knowledge Bridge Learning for Effective Knowledge Transfer](https://doi.org/10.1145/3583780.3614796)|Wendong Bi, Xueqi Cheng, Bingbing Xu, Xiaoqian Sun, Easton Li Xu, Huawei Shen|Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China|The data-hungry problem, characterized by insufficiency and low-quality of data, poses obstacles for deep learning models. Transfer learning has been a feasible way to transfer knowledge from high-quality external data of source domains to limited data of target domains, which follows a domain-level knowledge transfer to learn a shared posterior distribution. However, they are usually built on strong assumptions, e.g., the domain invariant posterior distribution, which is usually unsatisfied and may introduce noises, resulting in poor generalization ability on target domains. Inspired by Graph Neural Networks (GNNs) that aggregate information from neighboring nodes, we redefine the paradigm as learning a knowledge-enhanced posterior distribution for target domains, namely Knowledge Bridge Learning (KBL). KBL first learns the scope of knowledge transfer by constructing a Bridged-Graph that connects knowledgeable samples to each target sample and then performs sample-wise knowledge transfer via GNNs.KBL is free from strong assumptions and is robust to noises in the source data. Guided by KBL, we propose the Bridged-GNN} including an Adaptive Knowledge Retrieval module to build Bridged-Graph and a Graph Knowledge Transfer module. Comprehensive experiments on both un-relational and relational data-hungry scenarios demonstrate the significant improvements of Bridged-GNN compared with SOTA methods|数据匮乏、拥有属性不足和数据质量低下的问题，对深度学习模型构成了障碍。迁移学习是一种可行的方法，可以将来源领域的高质量外部数据转移到目标领域的有限数据中，这种方法遵循领域级别的知识转移，以学习共享的后验概率。然而，它们通常建立在强烈的假设之上，例如，领域不变后验概率，这通常是不满足的，并可能引入噪声，导致对目标领域的概括能力差。受到聚集邻近节点信息的图形神经网络(GNN)的启发，我们将该范式重新定义为学习目标领域的知识增强后验概率，即知识桥梁学习(Knowledge Bridge Learning，KBL)。KBL 首先通过构造一个连接知识样本和目标样本的桥图来学习知识转移的范围，然后通过 GNNs 进行样本智能知识转移。 KBL 不受强假设的约束，对源数据中的噪声具有鲁棒性。在 KBL 的指导下，本文提出了桥接 GNN 模型，包括自适应知识检索模块和图形知识传递模块。在非关系和关系数据饥饿场景下的综合实验表明，与 SOTA 方法相比，桥接 GNN 方法有显著的改进|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bridged-GNN:+Knowledge+Bridge+Learning+for+Effective+Knowledge+Transfer)|0|
|[Enabling Health Data Sharing with Fine-Grained Privacy](https://doi.org/10.1145/3583780.3614864)|Luca Bonomi, Sepand Gousheh, Liyue Fan|University of North Carolina at Charlotte, Charlotte, NC, USA; Vanderbilt University Medical Center, Nashville, TN, USA|Sharing health data is vital in advancing medical research and transforming knowledge into clinical practice. Meanwhile, protecting the privacy of data contributors is of paramount importance. To that end, several privacy approaches have been proposed to protect individual data contributors in data sharing, including data anonymization and data synthesis techniques. These approaches have shown promising results in providing privacy protection at the dataset level. In this work, we study the privacy challenges in enabling fine-grained privacy in health data sharing. Our work is motivated by recent research findings, in which patients and healthcare providers may have different privacy preferences and policies that need to be addressed. Specifically, we propose a novel and effective privacy solution that enables data curators (e.g., healthcare providers) to protect sensitive data elements while preserving data usefulness. Our solution builds on randomized techniques to provide rigorous privacy protection for sensitive elements and leverages graphical models to mitigate privacy leakage due to dependent elements. To enhance the usefulness of the shared data, our randomized mechanism incorporates domain knowledge to preserve semantic similarity and adopts a block-structured design to minimize utility loss. Evaluations with real-world health data demonstrate the effectiveness of our approach and the usefulness of the shared data for health applications.|共享健康数据对于推进医学研究和将知识转化为临床实践至关重要。同时，保护数据提供者的隐私至关重要。为此，提出了几种保护数据共享中个人数据贡献者的隐私方法，包括数据匿名化和数据合成技术。这些方法在提供数据集级别的隐私保护方面显示了有希望的结果。在这项工作中，我们研究了在健康数据共享中实现细粒度隐私的隐私挑战。我们的工作是由最近的研究发现，其中病人和医疗保健提供者可能有不同的隐私偏好和政策，需要加以解决。具体来说，我们提出了一个新颖而有效的隐私解决方案，使数据管理者(例如，医疗保健提供者)能够在保护数据有用性的同时保护敏感的数据元素。我们的解决方案建立在随机技术的基础上，为敏感元素提供严格的隐私保护，并利用图形化模型来缓解因依赖元素而导致的隐私泄漏。为了提高共享数据的有用性，我们的随机机制结合了领域知识来保持语义相似性，并采用了块结构设计来最小化效用损失。使用真实世界卫生数据进行的评估表明了我们的方法的有效性以及共享数据对卫生应用的有用性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enabling+Health+Data+Sharing+with+Fine-Grained+Privacy)|0|
|[Fair&Share: Fast and Fair Multi-Criteria Selections](https://doi.org/10.1145/3583780.3614874)|Kathleen Cachel, Elke A. Rundensteiner|USC-ISI|AbstractWith the widespread use of artificial intelligence (AI) systems and applications in our everyday lives, accounting for fairness has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. With the commercialization of these systems, researchers are becoming more aware of the biases that these applications can contain and are attempting to address them. In this survey, we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and ways they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.|随着人工智能(AI)系统和应用在日常生活中的广泛应用，公平会计在人工智能系统的设计和工程中显得越来越重要。人工智能系统可以在许多敏感的环境中作出重要和改变生活的决定; 因此，至关重要的是确保这些决定不反映对某些群体或人口的歧视行为。最近，在传统的机器学习和深度学习领域开展了一些工作，以应对不同子领域的此类挑战。随着这些系统的商业化，研究人员越来越意识到这些应用程序可能存在的偏差，并试图解决这些偏差。在这项调查中，我们调查了不同的现实世界中的应用程序，它们以不同的方式表现出偏差，我们列出了可能影响人工智能应用程序的不同偏差来源。然后，我们创建了一个公平定义的分类，机器学习研究人员已经定义，以避免在人工智能系统中存在的偏见。除此之外，我们研究了 AI 中的不同领域和子领域，显示了研究人员在最先进的方法和他们试图解决这些问题的方法中所观察到的不公平结果。为了减轻人工智能系统中的偏差问题，仍然有许多未来的方向和解决方案可以采取。我们希望这项调查能够激励研究人员在不久的将来通过观察他们各自领域的现有工作来解决这些问题。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fair&Share:+Fast+and+Fair+Multi-Criteria+Selections)|0|
|[MemDA: Forecasting Urban Time Series with Memory-based Drift Adaptation](https://doi.org/10.1145/3583780.3614962)|Zekun Cai, Renhe Jiang, Xinyu Yang, Zhaonan Wang, Diansheng Guo, Hill Hiroki Kobayashi, Xuan Song, Ryosuke Shibasaki|Tencent Corporation, Beijing, China; The University of Tokyo, Tokyo, Japan|Urban time series data forecasting featuring significant contributions to sustainable development is widely studied as an essential task of the smart city. However, with the dramatic and rapid changes in the world environment, the assumption that data obey Independent Identically Distribution is undermined by the subsequent changes in data distribution, known as concept drift, leading to weak replicability and transferability of the model over unseen data. To address the issue, previous approaches typically retrain the model, forcing it to fit the most recent observed data. However, retraining is problematic in that it leads to model lag, consumption of resources, and model re-invalidation, causing the drift problem to be not well solved in realistic scenarios. In this study, we propose a new urban time series prediction model for the concept drift problem, which encodes the drift by considering the periodicity in the data and makes on-the-fly adjustments to the model based on the drift using a meta-dynamic network. Experiments on real-world datasets show that our design significantly outperforms state-of-the-art methods and can be well generalized to existing prediction backbones by reducing their sensitivity to distribution changes.|城市时间序列数据预测作为智能城市的一项重要任务，对城市可持续发展作出了重要贡献。然而，随着世界环境的急剧和迅速变化，数据服从独立同一分布的假设被随后的数据分布变化(称为概念漂移)所破坏，导致模型对无形数据的可复制性和可转移性较弱。为了解决这个问题，以前的方法通常会重新训练模型，迫使它适应最近观察到的数据。然而，再训练会导致模型滞后、资源消耗和模型再失效，使得漂移问题在现实情况下得不到很好的解决。针对概念漂移问题，提出了一种新的城市时间序列预测模型。在真实世界数据集上的实验表明，我们的设计明显优于最先进的方法，可以很好地推广到现有的预测骨干，降低其对分布变化的敏感性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MemDA:+Forecasting+Urban+Time+Series+with+Memory-based+Drift+Adaptation)|0|
|[Inducing Causal Structure for Abstractive Text Summarization](https://doi.org/10.1145/3583780.3614934)|Lu Chen, Ruqing Zhang, Wei Huang, Wei Chen, Jiafeng Guo, Xueqi Cheng|ICT, CAS & University of Chinese Academy of Sciences, Beijing, China|The mainstream of data-driven abstractive summarization models tends to explore the correlations rather than the causal relationships. Among such correlations, there can be spurious ones which suffer from the language prior learned from the training corpus and therefore undermine the overall effectiveness of the learned model. To tackle this issue, we introduce a Structural Causal Model (SCM) to induce the underlying causal structure of the summarization data. We assume several latent causal factors and non-causal factors, representing the content and style of the document and summary. Theoretically, we prove that the latent factors in our SCM can be identified by fitting the observed training data under certain conditions. On the basis of this, we propose a Causality Inspired Sequence-to-Sequence model (CI-Seq2Seq) to learn the causal representations that can mimic the causal factors, guiding us to pursue causal information for summary generation. The key idea is to reformulate the Variational Auto-encoder (VAE) to fit the joint distribution of the document and summary variables from the training corpus. Experimental results on two widely used text summarization datasets demonstrate the advantages of our approach.|数据驱动的抽象摘要模型的主流趋向于探索相关性，而不是因果关系。在这些相关性中，可能存在一些虚假的相关性，这些相关性受到事先从培训语料库中学到的语言的影响，因此会破坏所学模型的整体有效性。为了解决这个问题，我们引入了一个结构性因果模型(SCM)来归纳总结数据的潜在因果结构。我们假设几个潜在的因果因素和非因果因素，代表的内容和风格的文件和总结。从理论上证明了在一定条件下，通过拟合观测训练数据可以识别供应链管理中的潜在因素。在此基础上，我们提出了一个受因果关系启发的序列到序列模型(CI-Seq2Seq)来学习可以模拟因果因素的因果表征，指导我们追求因果信息以进行摘要生成。其核心思想是对变分自动编码器(VAE)进行重构，以适应训练语料中文档和汇总变量的联合分布。在两个广泛使用的文本摘要数据集上的实验结果证明了该方法的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Inducing+Causal+Structure+for+Abstractive+Text+Summarization)|0|
|[Region Profile Enhanced Urban Spatio-Temporal Prediction via Adaptive Meta-Learning](https://doi.org/10.1145/3583780.3615027)|Jie Chen, Tong Liu, Ruiyuan Li|Shanghai University, Shanghai, China; Chongqing University, Chongqing, China|Urban spatio-temporal (ST) prediction plays a crucial role in smart city construction. Due to the high cost of ST data collection, improving ST prediction in a lack of data is significant. For this purpose, existing meta-learning methods have been demonstrated powerful by learning an initial network from training tasks and adjusting to target tasks with limited data. However, such shared knowledge from a set of tasks may contain irrelevant noise due to the gap of region-varying ST dynamics, resulting in the negative transfer issue. As a revelation of regional functional patterns, region profiles give rise to the diversity of ST dynamics. Thus, we design a novel adaptive meta-optimized model MetaRSTP, which conducts the initial prediction model in a finer-granularity of region level with region profiles as semantic evidence. To enhance the expressiveness of profiles, we firstly build a semantic alignment space to explore the inter-view co-semantics. Fusing it with view-specific uniqueness, the multi-view region profiles can be better applied in urban tasks. Then, a regional bias generator derives non-shared parameters in terms of profiles, which alleviates the divergence among regions. We set a new meta-learning strategy as initialize the network with fixed generalizable parameters and region-adaptive bias, thus enhancing the personalized prediction performance even in few-shot scenarios. Extensive experiments on real-world datasets illustrate the effectiveness of our MetaRSTP and our learned region profiles.|城市时空预测在智能城市建设中起着至关重要的作用。由于 ST 段数据采集成本较高，因此在缺乏数据的情况下改进 ST 段预测具有重要意义。为此，现有的元学习方法通过从训练任务中学习初始网络并根据有限的数据调整到目标任务已被证明是有效的。然而，由于区域变化的 ST 动力学之间的差异，来自一组任务的共享知识可能含有不相关的噪声，从而导致负迁移问题。区域剖面揭示了区域功能格局，引起了 ST 动力学的多样性。因此，我们设计了一个新的自适应元优化模型 MetaRSTP，该模型以区域轮廓作为语义证据，在较细粒度的区域水平上进行初始预测模型。为了提高配置文件的表达能力，我们首先构建了一个语义对齐空间来探索访问共语义。结合视图特定的唯一性，多视图区域轮廓可以更好地应用于城市任务。然后，区域偏差发生器根据轮廓推导出非共享参数，减小了区域间的差异。我们设置了一种新的元学习策略，即在固定的可推广参数和区域自适应偏差的情况下对网络进行初始化，从而提高了在少镜头情况下的个性化预测性能。对真实世界数据集的大量实验说明了我们的 MetaRSTP 和我们学习的区域概况的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Region+Profile+Enhanced+Urban+Spatio-Temporal+Prediction+via+Adaptive+Meta-Learning)|0|
|[Learning Pair-Centric Representation for Link Sign Prediction with Subgraph](https://doi.org/10.1145/3583780.3614951)|Jushuo Chen, Feifei Dai, Xiaoyan Gu, Haihui Fan, Jiang Zhou, Bo Li, Weiping Wang|Institute of Information Engineering, Chinese Academy of Sciences & School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China|Signed graphs are prevalent data structures containing both positive and negative links. Recently, the fundamental network analysis task on signed graphs, namely link sign prediction, has received careful attention. Existing methods learn two target node representations independently, and the sign between these two nodes is predicted based on similarity. However, such a paradigm is node-centric that cannot distinguish node pairs with distinct contexts, thus lowering the prediction performance. Learning pair-centric representation is therefore a rewarding way to be aware of differences between pairs. There is no study yet on how to build such an appropriate representation that can effectively infer the sign between the target node pair. In this paper, we provide a new perspective to conduct link sign prediction within the paradigm of subgraph classification and propose a novel Subgraph-based link Sign Prediction (SSP) model. Technically, SSP uses importance-based sampling to extract an informative subgraph around each target node pair. For each subgraph, an innovative node labeling scheme is designed to encode its structural and signed information for representation learning. To further utilize the subgraph representation for imbalanced sign classification, SSP employs self-pruning contrastive learning to gain balanced representations. Extensive experiments on real-world datasets demonstrate that SSP consistently and significantly outperforms all the state-of-the-art baselines.|签名图是一种普遍的数据结构，包含正向和负向链接。近年来，有符号图的基本网络分析任务，即链路符号预测，受到了广泛的关注。现有的方法分别学习两个目标节点的表示，并根据相似性对这两个节点之间的符号进行预测。然而，这种模式是以节点为中心的，不能区分具有不同上下文的节点对，从而降低了预测性能。因此，学习以配对为中心的表征是了解配对之间差异的一种有益的方法。目前还没有研究如何建立这样一个适当的表示，可以有效地推断符号之间的目标节点对。本文从子图分类的角度提出了一种新的链路符号预测方法，并提出了一种新的基于子图的链路符号预测(SSP)模型。从技术上讲，SSP 使用基于重要性的抽样来提取每个目标节点对周围的信息子图。针对每个子图，设计了一种新的节点标记方案，对其结构信息和符号信息进行编码，用于表示学习。为了进一步利用子图表示进行不平衡符号分类，SSP 采用自剪枝对比学习来获得平衡表示。对真实世界数据集的大量实验表明，SSP 始终如一地显著优于所有最先进的基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Pair-Centric+Representation+for+Link+Sign+Prediction+with+Subgraph)|0|
|[Meta-Transfer-Learning for Time Series Data with Extreme Events: An Application to Water Temperature Prediction](https://doi.org/10.1145/3583780.3614966)|Shengyu Chen, Nasrin Kalanat, Simon Topp, Jeffrey M. Sadler, Yiqun Xie, Zhe Jiang, Xiaowei Jia|Upstream Tech, Fridley, MN, USA; University of Maryland, College Park, MD, USA; University of Florida, Gainesville, FL, USA; University of Pittsburgh, Pittsburgh, PA, USA; Oklahoma State University, Stillwater, OK, USA|This paper proposes a meta-transfer-learning method for predicting daily maximum water temperature in stream networks with explicit modeling of extreme events. Accurate prediction of these extreme events is challenging because of their sparsity in the training data and their distinct responses to external drivers when compared to non-extreme observations. To overcome these challenges, we propose a sample reweighting strategy to escalate the importance of extreme events in the training process while preserving the predictive performance in normal time periods. The sample weight for each training data point is estimated as the similarity with the target test data point using contextual information and physical simulation. The obtained sample weight values are then used to fine-tune the initial model to transfer it to the test data. This method is further enhanced by an extreme value theory-based loss function to enforce the distribution of extreme data points and accelerated by a clustering algorithm based on the estimated similarities. Additionally, we introduce an online learning strategy to further refine the predictive model using newly collected observed data. The experimental results using real stream data from the Delaware River Basin over the past 36 years demonstrate that our meta-transfer-learning method produces more accurate predictions in both normal and extreme time periods when compared to baselines without the sample re-weighting scheme. The similarity learning method can reveal meaningful relationships amongst data points. We also show that the clustering algorithm can be used to accelerate the prediction while not compromising the predictive performance. The online learning strategy is shown to further improve predictive performance using recently observed data.|提出了一种基于显式极端事件模型的元传递学习方法来预测河网日最高水温。这些极端事件的准确预测是具有挑战性的，因为它们的训练数据稀少，与非极端观测相比，它们对外部驱动因素的反应截然不同。为了克服这些挑战，我们提出了一个样本重新加权策略，以提高极端事件在训练过程中的重要性，同时保持在正常时间段的预测性能。利用上下文信息和物理仿真，将每个训练数据点的样本权重估计为与目标测试数据点的相似度。然后使用获得的样本权重值对初始模型进行微调，将其传输到测试数据。该方法进一步通过基于极值理论的损失函数增强极值数据点的分布，并通过基于估计相似度的聚类算法加速。此外，我们引入了一个在线学习策略，使用新收集的观测数据进一步完善预测模型。使用特拉华河流域过去36年的实际水流数据的实验结果表明，与没有样本重新加权方案的基线相比，我们的元转移学习方法在正常和极端时间段产生更准确的预测。相似性学习方法可以揭示数据点之间有意义的关系。我们还表明，聚类算法可以在不影响预测性能的前提下加快预测速度。在线学习策略利用最近的观测数据进一步提高了预测性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Meta-Transfer-Learning+for+Time+Series+Data+with+Extreme+Events:+An+Application+to+Water+Temperature+Prediction)|0|
|[Hadamard Adapter: An Extreme Parameter-Efficient Adapter Tuning Method for Pre-trained Language Models](https://doi.org/10.1145/3583780.3614904)|Yuyan Chen, Qiang Fu, Ge Fan, Lun Du, JianGuang Lou, Shi Han, Dongmei Zhang, Zhixu Li, Yanghua Xiao|Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, Shanghai, China; Tencent, Shenzhen, China; Microsoft, Beijing, China; Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University & Fudan-Aishu Cognitive Intelligence Joint Research Center, Shanghai, China|Recent years, Pre-trained Language models (PLMs) have swept into various fields of artificial intelligence and achieved great success. However, most PLMs, such as T5 and GPT3, have a huge amount of parameters, fine-tuning them is often expensive and time consuming, and storing them takes up a lot of space. Therefore, it is necessary to adopt a parameter-efficient approach to reduce parameters of PLMs in fine-tuning without compromising their performance in downstream tasks. In this paper, we design a novel adapter which only acts on self-attention outputs in PLMs. This adapter adopts element-wise linear transformation using Hadamard product, hence named as Hadamard adapter, requires the fewest parameters compared to previous parameter-efficient adapters. In addition, we also summarize some tuning patterns for Hadamard adapter shared by various downstream tasks, expecting to provide some guidance for further parameter reduction with shared adapters in future studies. The experiments conducted on the widely-used GLUE benchmark with several SOTA PLMs prove that the Hadamard adapter achieves competitive performance with only 0.033% parameters compared with full fine-tuning, and it has the fewest parameters compared with other adapters. Moreover, we further find that there is also some redundant layers in the Hadamard adapter which can be removed to achieve more parameter efficiency with only 0.022% parameters.|近年来，预训练语言模型(PLM)已经深入人工智能的各个领域，并取得了巨大的成功。然而，大多数 PLM，如 T5和 GPT3，都有大量的参数，对它们进行微调通常代价高昂且耗时，并且存储它们占用大量空间。因此，有必要采取一种参数有效的方法，以减少参数的 PLM 在微调，而不损害其在下游任务的性能。在本文中，我们设计了一种新颖的适配器，它只作用于 PLM 中的自注意输出。这个适配器采用了使用 Hadamard 产品的元素线性映射，因此被命名为 Hadamard 适配器，与以前的参数高效适配器相比，需要的参数最少。此外，我们还总结了各种下游任务共享的 Hadamard 适配器的一些调优模式，希望在未来的研究中为共享适配器的进一步参数减少提供一些指导。利用多个 SOTA PLM 在广泛使用的 GLUE 基准上进行的实验表明，与完全微调相比，Hadamard 适配器的参数只有0.033% ，而且参数最少，具有一定的竞争力。此外，我们进一步发现，在 Hadamard 适配器中也存在一些冗余层，可以删除这些冗余层，以便在只有0.022% 参数的情况下实现更高的参数效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hadamard+Adapter:+An+Extreme+Parameter-Efficient+Adapter+Tuning+Method+for+Pre-trained+Language+Models)|0|
|[Hallucination Detection: Robustly Discerning Reliable Answers in Large Language Models](https://doi.org/10.1145/3583780.3614905)|Yuyan Chen, Qiang Fu, Yichen Yuan, Zhihao Wen, Ge Fan, Dayiheng Liu, Dongmei Zhang, Zhixu Li, Yanghua Xiao|Shanghai Key Laboratory of Data Science & School of Computer Science, Fudan University, Shanghai, China; DAMO Academy, Hangzhou, China; Shanghai Key Laboratory of Data Science & School of Computer Science, Fudan University & Fudan-Aishu Cognitive Intelligence Joint Research Center, Beijing, China; Shanghai Key Laboratory of Data Science & School of Computer Science, Fudan University & Fudan-Aishu Cognitive Intelligence Joint Research Center, Shanghai, China; Shanghai Key Laboratory of Data Science, Beijing, China; Tencent, Shenzhen, China; Singapore Management University, Singapore, Singapore; Microsoft, Shanghai, China; Microsoft, Beijing, China|Large language models (LLMs) have gained widespread adoption in various natural language processing tasks, including question answering and dialogue systems. However, a major drawback of LLMs is the issue of hallucination, where they generate unfaithful or inconsistent content that deviates from the input source, leading to severe consequences. In this paper, we propose a robust discriminator named RelD to effectively detect hallucination in LLMs' generated answers. RelD is trained on the constructed RelQA, a bilingual question-answering dialogue dataset along with answers generated by LLMs and a comprehensive set of metrics. Our experimental results demonstrate that the proposed RelD successfully detects hallucination in the answers generated by diverse LLMs. Moreover, it performs well in distinguishing hallucination in LLMs' generated answers from both in-distribution and out-of-distribution datasets. Additionally, we also conduct a thorough analysis of the types of hallucinations that occur and present valuable insights. This research significantly contributes to the detection of reliable answers generated by LLMs and holds noteworthy implications for mitigating hallucination in the future work.|大语言模型(LLM)已经广泛应用于各种自然语言处理任务，包括问答和对话系统。然而，LLM 的一个主要缺点是产生幻觉的问题，它们产生不忠实或不一致的内容，偏离输入源，导致严重的后果。在本文中，我们提出了一个鲁棒的鉴别器 RelD 来有效地检测 LLM 生成的答案中的幻觉。RelD 是基于构建的 RelQA 进行训练的，RelQA 是一个双语问答对话数据集，以及由 LLM 生成的答案和一套全面的度量标准。我们的实验结果表明，提出的 RelD 成功地检测幻觉的答案所产生的不同的 LLM。此外，它还能很好地区分 LLM 生成的分布内和分布外数据集中的幻觉。此外，我们还对出现的幻觉类型进行了全面分析，并提出了有价值的见解。这项研究显著有助于发现可靠的答案所产生的 LLM 和举行值得注意的影响，以减轻幻觉在未来的工作。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hallucination+Detection:+Robustly+Discerning+Reliable+Answers+in+Large+Language+Models)|0|
|[Deep Generative Imputation Model for Missing Not At Random Data](https://doi.org/10.1145/3583780.3614835)|Jialei Chen, Yuanbo Xu, Pengyang Wang, Yongjian Yang|MIC Lab, Department of Computer Science and Technology, Jilin University, Changchun, China; SKL-IOTSC, Department of Computer and Information Science, University of Macau, Macao, China|Data analysis usually suffers from the Missing Not At Random (MNAR) problem, where the cause of the value missing is not fully observed. Compared to the naive Missing Completely At Random (MCAR) problem, it is more in line with the realistic scenario whereas more complex and challenging. Existing statistical methods model the MNAR mechanism by different decomposition of the joint distribution of the complete data and the missing mask. But we empirically find that directly incorporating these statistical methods into deep generative models is sub-optimal. Specifically, it would neglect the confidence of the reconstructed mask during the MNAR imputation process, which leads to insufficient information extraction and less-guaranteed imputation quality. In this paper, we revisit the MNAR problem from a novel perspective that the complete data and missing mask are two modalities of incomplete data on an equal footing. Along with this line, we put forward a generative-model-specific joint probability decomposition method, conjunction model, to represent the distributions of two modalities in parallel and extract sufficient information from both complete data and missing mask. Taking a step further, we exploit a deep generative imputation model, namely GNR, to process the real-world missing mechanism in the latent space and concurrently impute the incomplete data and reconstruct the missing mask. The experimental results show that our GNR surpasses state-of-the-art MNAR baselines with significant margins (averagely improved from 9.9% to 18.8% in RMSE) and always gives a better mask reconstruction accuracy which makes the imputation more principle.|数据分析通常会遇到丢失不随机(MNAR)问题，其中值丢失的原因没有得到充分的观察。与天真的完全随机缺失(MCAR)问题相比，它更符合现实情况，而更复杂和具有挑战性。现有的统计方法通过对完整数据和缺失模板的联合分布进行不同的分解来模拟 MNAR 机制。但我们经验发现，直接将这些统计方法纳入深层生成模型是次优的。具体来说，它会忽略重建掩码在 MNAR 估算过程中的置信度，导致信息抽取不足和估算质量得不到保证。本文从一个新的角度重新讨论了 MNAR 问题，即完全数据和缺失掩模是不完全数据在同等条件下的两种形式。在此基础上，提出了一种特定于生成模型的联合概率分解方法——联合模型，用于并行表示两种模式的分布，并从完整数据和缺失模板中提取足够的信息。进一步，我们利用一个深层生成插补模型，即 GNR，来处理潜在空间中真实世界的缺失机制，同时对不完全数据进行插补并重构缺失掩模。实验结果表明，我们的 GNR 超越了最先进的 MNAR 基线，具有显著的边界(RMSE 平均值从9.9% 提高到18.8%) ，并且总是具有较好的掩模重建精度，使得插补更加原则。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Generative+Imputation+Model+for+Missing+Not+At+Random+Data)|0|
|[Towards Spoken Language Understanding via Multi-level Multi-grained Contrastive Learning](https://doi.org/10.1145/3583780.3615093)|Xuxin Cheng, Wanshi Xu, Zhihong Zhu, Hongxiang Li, Yuexian Zou|Peking University, Shenzhen, China|Spoken language understanding (SLU) is a core task in task-oriented dialogue systems, which aims at understanding user's current goal through constructing semantic frames. SLU usually consists of two subtasks, including intent detection and slot filling. Although there are some SLU frameworks joint modeling the two subtasks and achieve the high performance, most of them still overlook the inherent relationships between intents and slots, and fail to achieve mutual guidance between the two subtasks. To solve the problem, we propose a multi-level multi-grained SLU framework MMCL to apply contrastive learning at three levels, including utterance level, slot level, and word level to enable intent and slot to mutually guide each other. For the utterance level, our framework implements coarse granularity contrastive learning and fine granularity contrastive learning simultaneously. Besides, we also apply the self-distillation method to improve the robustness of the model. Experimental results and further analysis demonstrate that our proposed model achieves new state-of-the-art results on two public multi-intent SLU datasets, obtaining a 2.6 overall accuracy improvement on MixATIS dataset compared to previous best models.|口语理解是面向任务的对话系统的核心任务，其目的是通过构建语义框架来理解用户当前的目标。SLU 通常由两个子任务组成，包括意图检测和插槽填充。虽然有一些 SLU 框架对这两个子任务进行了联合建模并实现了高性能，但大多数框架仍然忽视了意图和插槽之间的内在关系，无法实现两个子任务之间的相互引导。为了解决这个问题，我们提出了一个多层次多粒度 SLU 框架 MMMCL，在话语层次、时隙层次和词语层次三个层次上应用对比学习，使意图和时隙能够相互引导。在话语层面，该框架同时实现了粗粒度对比学习和细粒度对比学习。此外，我们还应用自蒸馏方法来提高模型的鲁棒性。实验结果和进一步的分析表明，我们提出的模型在两个公共的多意图 SLU 数据集上获得了新的最新的结果，与以前的最佳模型相比，在 MixATIS 数据集上获得了2.6的整体精度提高。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Spoken+Language+Understanding+via+Multi-level+Multi-grained+Contrastive+Learning)|0|
|[DAS-CL: Towards Multimodal Machine Translation via Dual-Level Asymmetric Contrastive Learning](https://doi.org/10.1145/3583780.3614832)|Xuxin Cheng, Zhihong Zhu, Yaowei Li, Hongxiang Li, Yuexian Zou|Peking University, Shenzhen, China|Multimodal machine translation (MMT) aims to exploit visual information to improve neural machine translation (NMT). It has been demonstrated that image captioning and object detection can further improve MMT. In this paper, to leverage image captioning and object detection more effectively, we propose a Dual-level ASymmetric Contrastive Learning (DAS-CL) framework. Specifically, we leverage image captioning and object detection to generate more pairs of visual inputs and textual inputs. At the utterance level, we introduce an image captioning model to generate more coarse-grained pairs. At the word level, we introduce an object detection model to generate more fine-grained pairs. To mitigate the negative impact of noise in generated pairs, we apply asymmetric contrastive learning at these two levels. Experiments on the Multi30K dataset of three translation directions demonstrate that DAS-CL significantly outperforms existing MMT frameworks and achieves new state-of-the-art performance. More encouragingly, further analysis displays that DAS-CL is more robust to irrelevant visual information.|多模态机器翻译(MMT)旨在利用视觉信息改善神经机器翻译(NMT)。研究结果显示，影像字幕及目标检测可进一步改善 MMT。在本文中，为了更有效地利用图像字幕和目标检测，我们提出了一个双层非对称对比学习(das-CL)框架。具体来说，我们利用图像字幕和目标检测来生成更多的视觉输入和文本输入。在话语层面，我们引入了一个图像字幕模型来生成更多的粗粒度对。在单词层面，我们引入一个目标检测模型来生成更多的细粒度对。为了减轻噪声对生成对的负面影响，我们在这两个水平上应用了非对称对比学习。在三个平移方向的 Multi30K 数据集上进行的实验表明，DAS-CL 的性能明显优于现有的 MMT 框架，达到了新的性能水平。更令人鼓舞的是，进一步的分析表明，DAS-CL 对不相关的视觉信息更加健壮。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DAS-CL:+Towards+Multimodal+Machine+Translation+via+Dual-Level+Asymmetric+Contrastive+Learning)|0|
|[PCT-CycleGAN: Paired Complementary Temporal Cycle-Consistent Adversarial Networks for Radar-Based Precipitation Nowcasting](https://doi.org/10.1145/3583780.3615006)|Jaeho Choi, Yura Kim, KwangHo Kim, SungHwa Jung, Ikhyun Cho|Korea Meteorological Administration, Seoul, Republic of Korea|The precipitation nowcasting methods have been elaborated over the centuries because rain has a crucial impact on human life. Not only quantitative precipitation forecast (QPF) models and convolutional long short-term memory (ConvLSTM), but also various sophisticated methods such as the latest MetNet-2 are emerging. In this paper, we propose a paired complementary temporal cycle-consistent adversarial networks (PCT-CycleGAN) for radar-based precipitation nowcasting, inspired by cycle-consistent adversarial networks (CycleGAN), which shows strong performance in image-to-image translation. PCT-CycleGAN generates temporal causality using two generator networks with forward and backward temporal dynamics in paired complementary cycles. Each generator network learns a huge number of one-to-one mappings about time-dependent radar-based precipitation data to approximate a mapping function representing the temporal dynamics in each direction. To create robust temporal causality between paired complementary cycles, novel connection loss is proposed. The generator network learning forward temporal dynamics in PCT-CycleGAN generates radar-based precipitation data 10 minutes from the current time. Also, it provides a reliable prediction of up to 2 hours with iterative forecasting. The superiority of PCT-CycleGAN is demonstrated through qualitative and quantitative comparisons with several previous methods.|由于降雨对人类生活有着至关重要的影响，降雨临近预报方法已经研究了几个世纪。不仅仅是定量降水预报模型和卷积长期记忆模型，还有各种复杂的方法，比如最新的 MetNet-2也正在出现。本文在循环一致对抗网络(CycleGAN)的启发下，提出了一种用于雷达降水临近预报的成对互补时间循环一致对抗网络(PCT-CycleGAN)。PCT-CycleGAN 使用两个具有正向和反向时间动态的生成器网络在成对的互补循环中产生时间因果关系。每个发生器网络学习大量与时间相关的基于雷达的降水数据的一对一映射，以近似表示每个方向的时间动态的映射函数。为了在成对互补周期之间建立鲁棒的时间因果关系，提出了一种新的连接损失方法。在 PCT-CycleGAN 中学习前向时间动态的发生器网络从当前时间起10分钟生成基于雷达的降水数据。此外，它提供了一个可靠的预测长达2小时的迭代预测。通过与以往几种方法的定性和定量比较，证明了 PCT-CycleGAN 方法的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PCT-CycleGAN:+Paired+Complementary+Temporal+Cycle-Consistent+Adversarial+Networks+for+Radar-Based+Precipitation+Nowcasting)|0|
|[Can Knowledge Graphs Simplify Text?](https://doi.org/10.1145/3583780.3615514)|Anthony Colas, Haodi Ma, Xuanli He, Yang Bai, Daisy Zhe Wang|University College London, London, United Kingdom; University of Florida, Gainesville, FL, USA|Knowledge Graph (KG)-to-Text Generation has seen recent improvements in generating fluent and informative sentences which describe a given KG. As KGs are widespread across multiple domains and contain important entity-relation information, and as text simplification aims to reduce the complexity of a text while preserving the meaning of the original text, we propose KGSimple, a novel approach to unsupervised text simplification which infuses KG-established techniques in order to construct a simplified KG path and generate a concise text which preserves the original input's meaning. Through an iterative and sampling KG-first approach, our model is capable of simplifying text when starting from a KG by learning to keep important information while harnessing KG-to-text generation to output fluent and descriptive sentences. We evaluate various settings of the KGSimple model on currently-available KG-to-text datasets, demonstrating its effectiveness compared to unsupervised text simplification models which start with a given complex text. Our code is available on GitHub.|知识图(KG)到文本的生成在生成描述给定 KG 的流畅且信息丰富的句子方面已经看到了最近的改进。由于 KG 广泛存在于多个领域，并且包含重要的实体关系信息，而且文本简化的目的是在保留原文意义的同时降低文本的复杂度，因此我们提出了一种新的无监督文本简化方法 KGSimple，该方法融入了 KG 建立的技术，以构造一个简化的 KG 路径并生成一个保留原文意义的简洁文本。通过一个迭代和抽样的 KG 优先的方法，我们的模型能够简化文本，当从一个 KG 开始，学习保持重要的信息，同时利用 KG 到文本的生成输出流畅和描述性的句子。我们评估了 KGSimple 模型在当前可用的 KG-to-text 数据集上的各种设置，证明了它与从给定复杂文本开始的无监督文本简化模型相比的有效性。我们的代码可以在 GitHub 上找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Can+Knowledge+Graphs+Simplify+Text?)|0|
|[Cross-heterogeneity Graph Few-shot Learning](https://doi.org/10.1145/3583780.3614830)|Pengfei Ding, Yan Wang, Guanfeng Liu|Macquarie University, Sydney, NSW, Australia|In recent years, heterogeneous graph few-shot learning has been proposed to address the label sparsity issue in heterogeneous graphs (HGs), which contain various types of nodes and edges. The existing methods have achieved good performance by transferring generalized knowledge extracted from rich-labeled classes in source HG(s) to few-labeled classes in a target HG. However, these methods only consider the single-heterogeneity scenario where the source and target HGs share a fixed set of node/edge types, ignoring the more general scenario of cross-heterogeneity, where each HG can have a different and non-fixed set of node/edge types. To this end, we focus on the unexplored cross-heterogeneity scenario and propose a novel model for Cross-heterogeneity Graph Few-shot Learning, namely CGFL. In CGFL, we first extract meta-patterns to capture heterogeneous information and propose a multi-view heterogeneous graph neural network (MHGN) to learn meta-patterns across HGs. Then, we propose a score module to measure the informativeness of labeled samples and determine the transferability of each source HG. Finally, by integrating MHGN and the score module into a meta-learning mechanism, CGFL can effectively transfer generalized knowledge to predict new classes with few-labeled data. Extensive experiments on four real-world datasets have demonstrated the superior performance of CGFL over the state-of-the-art methods.|近年来，异构图少镜头学习被提出来解决包含各种节点和边的异构图中的标签稀疏问题。现有的方法通过将源 HG 中富标记类提取的广义知识转移到目标 HG 中的少标记类，获得了良好的性能。然而，这些方法只考虑单一异质性场景，其中源和目标 HG 共享一组固定的节点/边缘类型，忽略了更一般的交叉异质性场景，其中每个 HG 可以具有不同的和非固定的节点/边缘类型集。为此，我们着眼于未探索的跨异构情景，提出了一种新的跨异构图少镜头学习模型，即 CGFL。在 CGFL 中，我们首先提取元模式来捕获异构信息，并提出了一种多视图异构图神经网络(MHGN)来学习跨 HG 的元模式。然后，我们提出了一个评分模块来衡量被标记样本的信息性，并确定每个源 HG 的可转移性。最后，通过将 MHGN 和评分模块集成到一个元学习机制中，CGFL 可以有效地传递广义知识，利用少量标记数据预测新的类别。在四个真实世界数据集上的大量实验已经证明了 CGFL 比最先进的方法具有更好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cross-heterogeneity+Graph+Few-shot+Learning)|0|
|[NeoMaPy: A Parametric Framework for Reasoning with MAP Inference on Temporal Markov Logic Networks](https://doi.org/10.1145/3583780.3614757)|Victor David, Raphaël FournierS'niehotta, Nicolas Travers|Conservatoire National des Arts et Métiers, Paris, France; Léonard de Vinci Pôle Universitaire, Research Center, Paris La Défense, France; University of Perugia, Perugia, Italy|Reasoning on inconsistent and uncertain data is challenging, especially for Knowledge-Graphs (KG) to abide temporal consistency. Our goal is to enhance inference with more general time interval semantics that specify their validity, as regularly found in historical sciences. We propose a new Temporal Markov Logic Networks (TMLN) model which extends the Markov Logic Networks (MLN) model with uncertain temporal facts and rules. Total and partial temporal (in)consistency relations between sets of temporal formulae are examined. We then propose a new Temporal Parametric Semantics (TPS) which allows combining several sub-functions leading to different assessment strategies. Finally, we present the new NeoMaPy tool, to compute the MAP inference on MLNs and TMLNs with several TPS. We compare our performances with state-of-the-art inference tools and exhibit faster and higher quality results.|对不一致和不确定的数据进行推理具有挑战性，尤其是知识图(KG)要遵守时间一致性。我们的目标是使用更一般的时间间隔语义来加强推理，这些语义指定了它们的有效性，这在历史科学中是经常发现的。提出了一种新的时态马尔可夫逻辑网络(TMLN)模型，该模型扩展了具有不确定时态事实和规则的马尔可夫逻辑网络(MLN)模型。研究了时态公式集之间的全时态和部分时态一致性关系。然后，我们提出了一个新的时态参数语义(TPS) ，它允许组合多个子功能导致不同的评估策略。最后，我们提出了新的 NeoMaPy 工具，用于计算多个 TPS 对 MLN 和 TMLN 的 MAP 推断。我们将我们的性能与最先进的推理工具进行比较，并显示出更快和更高质量的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NeoMaPy:+A+Parametric+Framework+for+Reasoning+with+MAP+Inference+on+Temporal+Markov+Logic+Networks)|0|
|[Reveal the Unknown: Out-of-Knowledge-Base Mention Discovery with Entity Linking](https://doi.org/10.1145/3583780.3615036)|Hang Dong, Jiaoyan Chen, Yuan He, Yinan Liu, Ian Horrocks||Discovering entity mentions that are out of a Knowledge Base (KB) from texts plays a critical role in KB maintenance, but has not yet been fully explored. The current methods are mostly limited to the simple threshold-based approach and feature-based classification, and the datasets for evaluation are relatively rare. We propose BLINKout, a new BERT-based Entity Linking (EL) method which can identify mentions that do not have corresponding KB entities by matching them to a special NIL entity. To better utilize BERT, we propose new techniques including NIL entity representation and classification, with synonym enhancement. We also propose KB Pruning and Versioning strategies to automatically construct out-of-KB datasets from common in-KB EL datasets. Results on five datasets of clinical notes, biomedical publications, and Wikipedia articles in various domains show the advantages of BLINKout over existing methods to identify out-of-KB mentions for the medical ontologies, UMLS, SNOMED CT, and the general KB, WikiData.|从文本中发现知识库(KB)之外的实体提及在知识库维护中起着至关重要的作用，但是还没有得到充分的研究。目前的方法大多局限于简单的基于阈值的方法和基于特征的分类，用于评价的数据集相对较少。我们提出了 BLINKout，一种新的基于 BERT 的实体链接(EL)方法，它可以通过将没有相应知识库实体的提及与一个特殊的 NIL 实体匹配来识别它们。为了更好地利用 BERT，我们提出了新的技术，包括 NIL 实体表示和分类，同义词增强。我们还提出了 KB 修剪和版本控制策略，从常见的 in-KB EL 数据集中自动构造超出 KB 的数据集。临床注释，生物医学出版物和维基百科文章在不同领域的五个数据集的结果显示，BLINKout 优于现有的方法来识别医学本体论，UMLS，SNOMED CT 和一般知识库 WikiData 的外部知识库提及。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reveal+the+Unknown:+Out-of-Knowledge-Base+Mention+Discovery+with+Entity+Linking)|0|
|[Spatial-Temporal Graph Boosting Networks: Enhancing Spatial-Temporal Graph Neural Networks via Gradient Boosting](https://doi.org/10.1145/3583780.3615066)|Yujie Fan, ChinChia Michael Yeh, Huiyuan Chen, Yan Zheng, Liang Wang, Junpeng Wang, Xin Dai, Zhongfang Zhuang, Wei Zhang|Visa Research, Palo Alto, CA, USA|Spatial-temporal graph neural networks (STGNNs) are promising in solving real-world spatial-temporal forecasting problems. Recognizing the inherent sequential relationship of spatial-temporal data, it is natural to explore the integration of boosting training mechanism to further enhance the performance of STGNNs. However, few studies have touched this research area. To bridge this gap, in this work, we propose spatial-temporal graph boosting networks, namely STGBN, which to the best of our knowledge is the first attempt to leverage gradient boosting for enhancing STGNNs. STGBN follows the general training procedure of conventional gradient boosting, but incorporates two distinctive designs to improve its efficiency in training on spatial-temporal graphs. Specifically, we design an incremental learning strategy that progressively includes spatial-temporal data into training. Additionally, we enforce an identical architecture for the base learner in all boosting iterations with each base learner inheriting from the one in the previous iteration. These designs facilitate rapid convergence of the base learner and expedite the overall training process. The base learner in STGBN is designed as a Transformer sandwich, which consists of two temporal Transformers on the top and bottom and a spatial Transformer in the middle. Structuring them in such a way helps the model capture long-range temporal dynamics, global spatial dependencies, and deep spatial-temporal interactions. We perform extensive spatial-temporal forecasting experiments on four spatial-temporal graph benchmarks. Promising results demonstrate the outstanding performance of STGBN against a wide range of state-of-the-art baseline models.|时空图形神经网络(STGNN)在解决实际时空预测问题方面具有广阔的应用前景。认识到时空数据的内在时序关系，探索增强训练机制的整合以进一步提高 STGNN 的性能是很自然的。然而，很少有研究涉及到这个研究领域。为了弥合这一差距，在这项工作中，我们提出了时空图增强网络，即 STGBN，据我们所知，这是第一次尝试利用梯度提升增强 STGNN。STGBN 遵循传统梯度提升的一般训练程序，但结合了两种独特的设计，以提高其在时空图形上的训练效率。具体来说，我们设计了一个在线机机器学习策略，逐步将时空数据纳入训练。此外，我们在所有提升迭代中为基础学习者实施一个相同的体系结构，每个基础学习者从前一个迭代继承。这些设计有利于基础学习者的快速融合，加快整个培训过程。STGBN 的基础学习器设计为一个变压器夹层，由顶部和底部的两个时间变压器和中间的一个空间变压器组成。以这种方式构造它们有助于模型捕获长期的时间动态、全局的空间依赖性和深入的时空交互。我们在四个时空图基准上进行了广泛的时空预测实验。有希望的结果表明，STGBN 的出色性能对广泛的国家最先进的基线模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spatial-Temporal+Graph+Boosting+Networks:+Enhancing+Spatial-Temporal+Graph+Neural+Networks+via+Gradient+Boosting)|0|
|[Cognitive-inspired Graph Redundancy Networks for Multi-source Information Fusion](https://doi.org/10.1145/3583780.3614815)|Yao Fu, Junhong Wan, Junlan Yu, Weihao Jiang, Shiliang Pu|Hikvision Research Institute, Hangzhou, China|The recent developments in technologies bring not only increasing amount of information but also multiple information sources for Graph Representation Learning. With the success of Graph Neural Networks (GNN), there have been increasing attempts to learn representation of multi-source information leveraging its graph structures. However, existing graph methods basically combine multi-source information with different contribution scores and over-simplify the graph structures based on prior knowledge, which fail to unify complex and conflicting multi-source information. Multisensory Processing theory in cognitive neuroscience reveals human mechanism of learning multi-source information by identifying the redundancy and complementarity. Inspired by that, we propose Graph Redundancy Network (GRN) that: 1). learns a suitable representation space that maximizes multi-source interactions; 2). encodes the redundant and complementary information according to Graph Intersection and Difference of their graph structures; 3). further reinforces and explores the redundant and complementary information through low-pass and high-pass graph filters. The empirical study shows that GRN outperforms existing methods on various tasks.|近年来技术的发展不仅为图形表示学习带来了越来越多的信息，而且为图形表示学习带来了多种信息源。随着图形神经网络(GNN)的成功，人们越来越多地尝试利用其图形结构来学习多源信息的表示。然而，现有的图论方法基本上是将不同贡献分数的多源信息结合起来，过分简化了基于先验知识的图论结构，无法统一复杂、冲突的多源信息。认知神经科学的多感官加工理论揭示了人类通过识别冗余和互补来学习多源信息的机制。受此启发，我们提出了图冗余网络(GRN) : 1)。学习最大化多源交互的合适的表示空间;。根据图结构的交差对冗余信息和互补信息进行编码;。通过低通和高通图形滤波器进一步加强和探索冗余和互补信息。实证研究表明，GRN 在各种任务中的表现优于现有的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cognitive-inspired+Graph+Redundancy+Networks+for+Multi-source+Information+Fusion)|0|
|[Cross-Scenario Maneuver Decision with Adaptive Perception for Autonomous Driving](https://doi.org/10.1145/3583780.3614831)|Yuan Fu, Shuncheng Liu, Yuyang Xia, Fangda Guo, Kai Zheng|Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; University of Electronic Science and Technology of China, Chengdu, China|Autonomous driving is a rapidly advancing field that promises to revolutionize the transportation industry through an intelligent perception-and-decision paradigm. Despite decades of research, existing methods are limited in adapting to complex scenarios or expanding to unseen situations, which pose significant challenges to the development of autonomous driving. Inspired by the process of human learning to drive, autonomous vehicles can prioritize developing driving capabilities in basic scenarios and then extending the atomic abilities to more complex scenarios. To this end, we proposed a perception-and-decision framework, called ATEND, which consists of an adaptive perception module and a maneuver decision module. Specifically, the perception module based on Variational Autoencoder is proposed to map perceptual data of complex scenarios into basic scenarios. Then the reinforcement learning-based decision module can make high-level decisions in transformed scenarios. Once ATEND learns to drive in basic scenarios, it can achieve safe and efficient driving in real scenarios without additional training. Extensive experiments in different traffic scenarios evidence that the proposed framework advances the state of the art in terms of both macroscopic and microscopic effectiveness.|自动驾驶是一个迅速发展的领域，有望通过智能感知和决策范式彻底改革交通行业。尽管经过了几十年的研究，现有的方法在适应复杂的情景或扩展到未知的情况方面仍有局限性，这对自动驾驶的发展构成了重大挑战。受到人类学习驾驶过程的启发，自动驾驶汽车可以优先发展基本场景中的驾驶能力，然后将原子能力扩展到更复杂的场景中。为此，我们提出了一个感知与决策框架 ATEND，它由一个自适应感知模块和一个机动决策模块组成。提出了基于变分自动编码器的感知模块，将复杂场景的感知数据映射到基本场景。然后基于强化学习的决策模块可以在变换后的情景中进行高层决策。一旦 ATEND 学会驾驶在基本的情况下，它可以实现安全和有效的驾驶在真正的情况下没有额外的培训。在不同的交通情景下进行的大量实验表明，所提出的框架在宏观和微观效果方面都提高了技术水平。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cross-Scenario+Maneuver+Decision+with+Adaptive+Perception+for+Autonomous+Driving)|0|
|[On the Trade-off between Over-smoothing and Over-squashing in Deep Graph Neural Networks](https://doi.org/10.1145/3583780.3614997)|Jhony H. Giraldo, Konstantinos Skianis, Thierry Bouwmans, Fragkiskos D. Malliaros|Université Paris-Saclay, CentraleSupélec, Inria, Gif-sur-Yvette, France; Laboratoire MIA, La Rochelle Université, La Rochelle, France; BLUAI, Athens, Greece; LTCI, Télécom Paris - Institut Polytechnique de Paris, Palaiseau, France|Graph Neural Networks (GNNs) have succeeded in various computer science applications, yet deep GNNs underperform their shallow counterparts despite deep learning's success in other domains. Over-smoothing and over-squashing are key challenges when stacking graph convolutional layers, hindering deep representation learning and information propagation from distant nodes. Our work reveals that over-smoothing and over-squashing are intrinsically related to the spectral gap of the graph Laplacian, resulting in an inevitable trade-off between these two issues, as they cannot be alleviated simultaneously. To achieve a suitable compromise, we propose adding and removing edges as a viable approach. We introduce the Stochastic Jost and Liu Curvature Rewiring (SJLR) algorithm, which is computationally efficient and preserves fundamental properties compared to previous curvature-based methods. Unlike existing approaches, SJLR performs edge addition and removal during GNN training while maintaining the graph unchanged during testing. Comprehensive comparisons demonstrate SJLR's competitive performance in addressing over-smoothing and over-squashing.|图形神经网络(GNN)已经在各种计算机科学应用中取得了成功，然而深层神经网络在其他领域的成功表现不如浅层神经网络。过度平滑和过度压缩是叠加图卷积层时面临的主要挑战，它们阻碍了深度表示学习和远距离节点的信息传播。我们的工作揭示了过度平滑和过度压缩与图的拉普拉斯谱间隙有着内在的联系，由于这两个问题不能同时得到解决，因此在这两个问题之间必然会出现权衡。为了达到一个合适的折衷，我们建议添加和去除边缘作为一个可行的方法。我们介绍了随机 Jost 和 Liu 曲率重布线(SJLR)算法，与以前的基于曲率的方法相比，SJLR 算法具有计算效率高和保持基本性质的优点。与现有的方法不同，SJLR 在 GNN 训练期间执行边添加和去除，同时在测试期间保持图形不变。全面的比较证明了 SJLR 在解决过度平滑和过度压缩方面的竞争表现。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+the+Trade-off+between+Over-smoothing+and+Over-squashing+in+Deep+Graph+Neural+Networks)|0|
|[Homophily-enhanced Structure Learning for Graph Clustering](https://doi.org/10.1145/3583780.3614915)|Ming Gu, Gaoming Yang, Sheng Zhou, Ning Ma, Jiawei Chen, Qiaoyu Tan, Meihan Liu, Jiajun Bu|Zhejiang University, Hangzhou, China; New York University Shanghai, Shanghai, China|Graph clustering is a fundamental task in graph analysis, and recent advances in utilizing graph neural networks (GNNs) have shown impressive results. Despite the success of existing GNN-based graph clustering methods, they often overlook the quality of graph structure, which is inherent in real-world graphs due to their sparse and multifarious nature, leading to subpar performance. Graph structure learning allows refining the input graph by adding missing links and removing spurious connections. However, previous endeavors in graph structure learning have predominantly centered around supervised settings, and cannot be directly applied to our specific clustering tasks due to the absence of ground-truth labels. To bridge the gap, we propose a novel method called \textbf{ho}mophily-enhanced structure \textbf{le}arning for graph clustering (HoLe). Our motivation stems from the observation that subtly enhancing the degree of homophily within the graph structure can significantly improve GNNs and clustering outcomes. To realize this objective, we develop two clustering-oriented structure learning modules, i.e., hierarchical correlation estimation and cluster-aware sparsification. The former module enables a more accurate estimation of pairwise node relationships by leveraging guidance from latent and clustering spaces, while the latter one generates a sparsified structure based on the similarity matrix and clustering assignments. Additionally, we devise a joint optimization approach alternating between training the homophily-enhanced structure learning and GNN-based clustering, thereby enforcing their reciprocal effects. Extensive experiments on seven benchmark datasets of various types and scales, across a range of clustering metrics, demonstrate the superiority of HoLe against state-of-the-art baselines.|图聚类是图分析的基本任务，近年来利用图神经网络(GNN)的研究取得了令人瞩目的成果。尽管现有的基于 GNN 的图聚类方法已经取得了一定的成功，但是它们往往忽视了图结构的质量。图结构学习允许通过添加缺失链接和消除伪连接来精炼输入图。然而，以前在图结构学习的努力主要集中在监督设置，不能直接应用到我们的具体聚类任务，由于没有地面真理标签。为了弥补这一缺陷，我们提出了一种新的图聚类方法 textbf { ho } mophily 增强结构 textbf { le } arning。我们的动机来自于这样一个观察: 微妙地提高图结构中的同质性程度可以显著改善 GNN 和聚类结果。为了实现这一目标，我们开发了两个面向聚类的结构学习模块，即层次相关估计和聚类感知的稀疏化。前一个模块利用潜在空间和聚类空间的引导，更准确地估计成对节点关系，而后一个模块基于相似矩阵和聚类分配生成稀疏结构。此外，我们设计了一个联合优化方法，交替训练同质增强结构学习和基于 GNN 的聚类，从而增强它们的互惠效应。在七个不同类型和尺度的基准数据集上进行了大量的实验，通过一系列聚类度量，证明了 HoLe 相对于最先进的基准线的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Homophily-enhanced+Structure+Learning+for+Graph+Clustering)|0|
|[Hierarchical Meta-Learning with Hyper-Tasks for Few-Shot Learning](https://doi.org/10.1145/3583780.3614911)|Yunchuan Guan, Yu Liu, Ke Zhou, Junyuan Huang|Huazhong University of Science and Technology, Wuhan, China|Meta-learning excels in few-shot learning by extracting shared knowledge from the observed tasks. However, it needs the tasks to adhere to the i.i.d. constraint, which is challenging to achieve due to complex task relationships between data content. Current methods that create tasks in a one-dimensional structure and use meta-learning to learn all tasks flatly struggle with extracting shared knowledge from tasks with overlapping concepts. To address this issue, we propose further constructing tasks from the same environment into hyper-tasks. Since the distributions of hyper-tasks and tasks in a hyper-task can both be approximated as i.i.d. due to further summarization, the meta-learning algorithm can capture shared knowledge more efficiently. Based on the hyper-task, we propose a hierarchical meta-learning paradigm to meta-learn the meta-learning algorithm. The paradigm builds a customized meta-learner for each hyper-task, which makes meta-learners more flexible and expressive. We apply the paradigm to three classic meta-learning algorithms and conduct extensive experiments on public datasets, which confirm the superiority of hierarchical meta-learning in the few-shot learning setting. The code is released at https://github.com/tuantuange/H-meta-learning.|元学习通过从观察到的任务中提取共享知识，在少镜头学习中表现出色。然而，它需要任务遵守 i.d. 约束，由于数据内容之间复杂的任务关系，这一点很难实现。当前的方法是在一维结构中创建任务，并使用元学习来学习所有任务，这些方法在从概念重叠的任务中提取共享知识时显然遇到了困难。为了解决这个问题，我们提出进一步构造任务从相同的环境到超任务。由于超任务和超任务中任务的分布可以通过进一步的归纳近似为标识符，因此元学习算法可以更有效地获取共享的知识。基于超任务，本文提出了一种分层元学习范式来元学习元学习算法。该范式为每个超任务建立一个定制的元学习者，使元学习者更加灵活和富有表现力。我们将该范式应用于三种经典的元学习算法，并在公共数据集上进行了广泛的实验，证实了分层元学习在少镜头学习环境下的优越性。密码在 https://github.com/tuantuange/h-meta-learning 发布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Meta-Learning+with+Hyper-Tasks+for+Few-Shot+Learning)|0|
|[RoCourseNet: Robust Training of a Prediction Aware Recourse Model](https://doi.org/10.1145/3583780.3615040)|Hangzhi Guo, Feiran Jia, Jinghui Chen, Anna Cinzia Squicciarini, Amulya Yadav|The Pennsylvania State University, State College, PA, USA|Counterfactual (CF) explanations for machine learning (ML) models are preferred by end-users, as they explain the predictions of ML models by providing a recourse (or contrastive) case to individuals who are adversely impacted by predicted outcomes. Existing CF explanation methods generate recourses under the assumption that the underlying target ML model remains stationary over time. However, due to commonly occurring distributional shifts in training data, ML models constantly get updated in practice, which might render previously generated recourses invalid and diminish end-users trust in our algorithmic framework. To address this problem, we propose RoCourseNet, a training framework that jointly optimizes predictions and recourses that are robust to future data shifts. This work contains four key contributions: (1) We formulate the robust recourse generation problem as a tri-level optimization problem which consists of two sub-problems: (i) a bi-level problem that finds the worst-case adversarial shift in the training data, and (ii) an outer minimization problem to generate robust recourses against this worst-case shift. (2) We leverage adversarial training to solve this tri-level optimization problem by: (i) proposing a novel virtual data shift (VDS) algorithm to find worst-case shifted ML models via explicitly considering the worst-case data shift in the training dataset, and (ii) a block-wise coordinate descent procedure to optimize for prediction and corresponding robust recourses. (3) We evaluate RoCourseNet's performance on three real-world datasets, and show that RoCourseNet consistently achieves more than 96% robust validity and outperforms state-of-the-art baselines by at least 10% in generating robust CF explanations. (4) Finally, we generalize the RoCourseNet framework to accommodate any parametric post-hoc methods for improving robust validity.|机器学习(ML)模型的反事实(CF)解释是最终用户的首选，因为他们解释机器学习模型的预测，通过提供一个追索权(或对比)的情况下，受到预测结果的不利影响的个人。现有的 CF 解释方法在假设潜在目标 ML 模型随时间保持稳定的前提下生成资源。然而，由于训练数据中普遍存在的分布变化，机器学习模型在实际应用中不断更新，这可能导致以前生成的资源无效，并削弱最终用户对我们算法框架的信任。为了解决这个问题，我们提出了 RoCourseNet，一个联合优化预测和资源的培训框架，这些预测和资源对未来的数据转移是健壮的。这项工作包含四个关键的贡献: (1)我们把鲁棒追索生成问题描述成一个三层次的最佳化问题，其中包括两个子问题: (1)一个在训练数据中发现最坏情况下的对手变化的双层次问题，和(2)一个针对最坏情况变化生成鲁棒追索的外部最小化问题。(2)我们利用对抗性训练来解决这个三级最佳化问题: (i)提出一种新的虚拟数据移位(VDS)算法，通过明确考虑训练数据集中的最坏情况数据移位来找到最坏情况移位的机器学习模型，以及(ii)一个分块的坐标下降法程序来优化预测和相应的稳健资源。(3)我们对 RoCourseNet 在三个实际数据集上的表现进行了评估，结果显示 RoCourseNet 在产生稳健的 CF 解释方面始终达到超过96% 的稳健有效性，并且比最先进的基线至少高出10% 。(4)最后，我们推广了 RoCourseNet 框架，以适应任何参数化的事后方法来提高鲁棒有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RoCourseNet:+Robust+Training+of+a+Prediction+Aware+Recourse+Model)|0|
|[Attacking Neural Networks with Neural Networks: Towards Deep Synchronization for Backdoor Attacks](https://doi.org/10.1145/3583780.3614784)|Zihan Guan, Lichao Sun, Mengnan Du, Ninghao Liu|Lehigh University, Bethlehem, PA, USA; University of Georgia, Athens, GA, USA; New Jersey Institute of Technology, Newark, NJ, USA|Backdoor attacks inject poisoned samples into training data, where backdoor triggers are embedded into the model trained on the mixture of poisoned and clean samples. An interesting phenomenon can be observed in the training process: the loss of poisoned samples tends to drop significantly faster than that of clean samples, which we call the early-fitting phenomenon. Early-fitting provides a simple but effective evidence to defend against backdoor attacks, where the poisoned samples can be detected by selecting the samples with the lowest loss values in the early training epochs. Then, two questions naturally arise: (1) What characteristics of poisoned samples cause early-fitting? (2) Does a stronger attack exist which could circumvent the defense methods? To answer the first question, we find that early-fitting could be attributed to a unique property among poisoned samples called synchronization, which depicts the similarity between two samples at different layers of a model. Meanwhile, the degree of synchronization could be controlled based on whether it is captured by shallow or deep layers of the model. Then, we give an affirmative answer to the second question by proposing a new backdoor attack method, Deep Backdoor Attack (DBA), which utilizes deep synchronization to reverse engineer trigger patterns by activating neurons in the deep layer of a base neural network. Experimental results validate our propositions and the effectiveness of DBA. Our code is available at https://github.com/GuanZihan/Deep-Backdoor-Attack.|后门攻击将有毒样本注入到训练数据中，其中后门触发器被嵌入到对有毒样本和无毒样本混合进行训练的模型中。在训练过程中可以观察到一个有趣的现象: 中毒样本的损失下降速度明显快于未中毒样本，我们称之为早期拟合现象。早期拟合提供了一个简单而有效的证据来抵御后门攻击，其中中毒样本可以通过选择在早期训练阶段损失值最低的样本来检测。然后，自然而然地出现了两个问题: (1)中毒样本的什么特征会导致早期拟合？(2)是否存在可以规避防御手段的更强攻击？为了回答第一个问题，我们发现早期拟合可以归因于中毒样本之间的一个独特属性，即同步，它描述了模型不同层次上两个样本之间的相似性。同时，可以根据模型的浅层或深层对同步进行控制。然后，我们提出了一种新的后门攻击方法——深度后门攻击(Deep Backdoor Strategy，DBA) ，该方法利用深度同步技术通过激活基础神经网络深层的神经元来逆向工程触发模式，从而对第二个问题给出了肯定的回答。实验结果验证了我们的提议和 DBA 的有效性。我们的代码可以在 https://github.com/guanzihan/deep-backdoor-attack 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Attacking+Neural+Networks+with+Neural+Networks:+Towards+Deep+Synchronization+for+Backdoor+Attacks)|0|
|[MGICL: Multi-Grained Interaction Contrastive Learning for Multimodal Named Entity Recognition](https://doi.org/10.1145/3583780.3614967)|Aibo Guo, Xiang Zhao, Zhen Tan, Weidong Xiao|National University of Defense Technology, Changsha, China|Multimodal Named Entity Recognition (MNER) aims to combine data from different modalities (e.g. text, images, videos, etc.) for recognition and classification of named entities, which is crucial for constructing Multimodal Knowledge Graphs (MMKGs). However, existing researches suffer from two prominant issues: over-reliance on textual features while neglecting visual features, and the lack of effective reduction of the feature space discrepancy of multimodal data. To overcome these challenges, this paper proposes a Multi-Grained Interaction Contrastive Learning framework for MNER task, namely MGICL. MGICL slices data into different granularities, i.e., sentence level/word token level for text, and image level/object level for image. By utilizing multimodal features with different granularities, the framework enables cross-contrast and narrows down the feature space discrepancy between modalities. Moreover, it facilitates the acquisition of valuable visual features by the text. Additionally, a visual gate control mechanism is introduced to dynamically select relevant visual information, thereby reducing the impact of visual noise. Experimental results demonstrate that the proposed MGICL framework satisfactorily tackles the challenges of MNER through enhancing information interaction of multimodal data and reducing the effect of noise, and hence, effectively improves the performance of MNER.|多模态命名实体识别(MNER)的目的是将来自不同模式(如文本、图像、视频等)的数据结合起来，对命名实体进行识别和分类，这对于构建多模态知识图(MMKG)至关重要。然而，现有的研究存在两个突出问题: 过度依赖文本特征而忽视视觉特征，以及缺乏有效的减少多模态数据的特征空间差异。为了克服这些挑战，本文提出了一个用于 MNER 任务的多粒度交互对比学习框架，即 MGICL。MGICL 将数据切割成不同的粒度，即，文本的句子级/词标记级，图像的图像级/对象级。该框架利用不同粒度的多模态特征，实现了模态间的交叉对比，缩小了模态间的特征空间差异。此外，它还有助于文本获得有价值的视觉特征。此外，还引入了视觉门控制机制，动态选择相关的视觉信息，从而减少视觉噪声的影响。实验结果表明，所提出的 MGICL 框架通过增强多模态数据的信息交互和降低噪声的影响，较好地解决了 MNER 的挑战，从而有效地提高了 MNER 的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MGICL:+Multi-Grained+Interaction+Contrastive+Learning+for+Multimodal+Named+Entity+Recognition)|0|
|[Interpretable Fake News Detection with Graph Evidence](https://doi.org/10.1145/3583780.3614936)|Hao Guo, Weixin Zeng, Jiuyang Tang, Xiang Zhao|National University of Defense Technology, Changsha, China|Automatic detection of fake news has received widespread attentions over recent years. A pile of efforts has been put forward to address the problem with high accuracy, while most of them lack convincing explanations, making it difficult to curb the continued spread of false news in real-life cases. Although some models leverage external resources to provide preliminary interpretability, such external signals are not always available. To fill in this gap, in this work, we put forward an interpretable fake news detection model IKA by making use of the historical evidence in the form of graphs. Specifically, we establish both positive and negative evidence graphs by collecting the signals from the historical news, i.e., training data. Then, given a piece of news to be detected, in addition to the common features used for detecting false news, we compare the news and evidence graphs to generate both the matching vector and the related graph evidence for explaining the prediction. We conduct extensive experiments on both Chinese and English datasets. The experiment results show that the detection accuracy of IKA exceeds the state-of-the-art approaches and IKA can provide useful explanations for the prediction results. Besides, IKA is general and can be applied on other models to improve their interpretability.|虚假新闻的自动检测近年来受到了广泛的关注。为了解决这一问题，人们付出了大量努力，但大多数努力都缺乏令人信服的解释，因此难以遏制在现实案件中继续传播虚假新闻。虽然有些模型利用外部资源提供初步的可解释性，但这种外部信号并不总是可用的。为了填补这一空白，本文利用图表形式的历史证据，提出了一种可解释的假新闻检测模型 IKA。具体来说，我们通过收集历史新闻的信号，即训练数据，建立了正证据图和负证据图。然后，给定一条待检测的新闻，除了用于检测虚假新闻的常见特征之外，对新闻图和证据图进行比较，生成匹配向量和相关图证据来解释预测。我们对中文和英文数据集进行了广泛的实验。实验结果表明，IKA 算法的检测精度超过了现有的方法，为预测结果提供了有用的解释。此外，IKA 具有通用性，可以应用于其他模型以提高模型的可解释性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interpretable+Fake+News+Detection+with+Graph+Evidence)|0|
|[Towards Fair Graph Neural Networks via Graph Counterfactual](https://doi.org/10.1145/3583780.3615092)|Zhimeng Guo, Jialiang Li, Teng Xiao, Yao Ma, Suhang Wang|The Pennsylvania State University, State College, PA, USA; New Jersey Institute of Technology, Newark, NJ, USA; Rensselaer Polytechnic Institute, Troy, USA|Graph neural networks have shown great ability in representation (GNNs) learning on graphs, facilitating various tasks. Despite their great performance in modeling graphs, recent works show that GNNs tend to inherit and amplify the bias from training data, causing concerns of the adoption of GNNs in high-stake scenarios. Hence, many efforts have been taken for fairness-aware GNNs. However, most existing fair GNNs learn fair node representations by adopting statistical fairness notions, which may fail to alleviate bias in the presence of statistical anomalies. Motivated by causal theory, there are several attempts utilizing graph counterfactual fairness to mitigate root causes of unfairness. However, these methods suffer from non-realistic counterfactuals obtained by perturbation or generation. In this paper, we take a causal view on fair graph learning problem. Guided by the casual analysis, we propose a novel framework CAF, which can select counterfactuals from training data to avoid non-realistic counterfactuals and adopt selected counterfactuals to learn fair node representations for node classification task. Extensive experiments on synthetic and real-world datasets show the effectiveness of CAF. Our code is available at https://github.com/TimeLovercc/CAF-GNN.|图形神经网络具有良好的图形表示学习能力，能够方便地完成各种任务。尽管 GNN 在建模图中表现出色，但近年来的研究表明，GNN 倾向于继承和放大训练数据中的偏差，这引起了人们对在高风险场景中采用 GNN 的担忧。因此，对于公平感知的 GNN，人们付出了很多努力。然而，现有的公平 GNN 大多通过采用统计公平概念来学习公平节点表示，这可能不能减轻存在统计异常时的偏差。受因果关系理论的启发，人们多次尝试利用图的反事实公平性来减轻不公平的根本原因。然而，这些方法遭受非现实的反事实由摄动或生成获得。本文对公平图学习问题提出了因果观点。在随机分析的指导下，提出了一种新的 CAF 框架，该框架可以从训练数据中选择反事实，避免非现实反事实，并采用选择的反事实来学习节点分类任务的公平节点表示。在合成数据集和真实数据集上的大量实验表明了 CAF 的有效性。我们的代码可以在 https://github.com/timelovercc/caf-gnn 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Fair+Graph+Neural+Networks+via+Graph+Counterfactual)|0|
|[James ate 5 oranges = Steve bought 5 pencils: Structure-Aware Denoising for Paraphrasing Word Problems](https://doi.org/10.1145/3583780.3614940)|Rishabh Gupta, Venktesh V, Mukesh K. Mohania, Vikram Goyal|IIIT Delhi, Delhi, India|We propose SCANING, an unsupervised framework for paraphrasing via controlled noise injection. We focus on the novel task of paraphrasing algebraic word problems having practical applications in online pedagogy as a means to reduce plagiarism as well as evoke reasoning capabilities on the part of the student instead of rote memorization. This task is more complex than paraphrasing general-domain corpora due to the difficulty in preserving critical information for solution consistency of the paraphrased word problem, managing the increased length of the text and ensuring diversity in the generated paraphrase. Existing approaches fail to demonstrate adequate performance on at least one, if not all, of these facets, necessitating the need for a more comprehensive solution. To this end, we model the noising search space as a composition of contextual and syntactic aspects to sample noising functions. This allows for learning a denoising function, that operates over both aspects and produces semantically equivalent and syntactically diverse outputs through grounded noise injection. The denoising function serves as a foundation for training a paraphrasing function, which operates solely in the input-paraphrase space without carrying any direct dependency on noise. We demonstrate that SCANING improves performance in terms of producing semantically equivalent and syntactically diverse paraphrases by 35% through extensive automated and human evaluation across 4 datasets.|我们提出扫描，一个无监督的框架释义通过控制噪声注入。我们的重点是解释代数词问题的新颖任务有实际应用在在线教学作为一种手段，以减少剽窃，并唤起部分学生的推理能力，而不是死记硬背。这项任务比解释一般领域语料库更为复杂，因为在解决解释词问题的一致性方面保留关键信息、管理增加的文本长度和确保生成的解释的多样性方面存在困难。现有方法未能在至少一个(如果不是全部的话)这些方面展示出足够的性能，因此需要一个更全面的解决方案。为此，我们将噪声搜索空间建模为由上下文和句法两个方面组成的样本噪声函数。这允许学习一个去噪函数，通过接地噪声注入，该函数在两个方面都起作用，并产生语义等效和语法不同的输出。去噪函数是训练复述函数的基础，复述函数只在输入-复述空间中运行，不直接依赖于噪声。我们证明，SCANING 通过在4个数据集中广泛的自动化和人工评估，提高了35% 的语义等效和句法多样性转述的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=James+ate+5+oranges+=+Steve+bought+5+pencils:+Structure-Aware+Denoising+for+Paraphrasing+Word+Problems)|0|
|[Enhancing Spatio-temporal Traffic Prediction through Urban Human Activity Analysis](https://doi.org/10.1145/3583780.3614867)|Sumin Han, Youngjun Park, Minji Lee, Jisun An, Dongman Lee|Indiana University Bloomington (IUB), Bloomington, IN, USA; Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea|Traffic prediction is one of the key elements to ensure the safety and convenience of citizens. Existing traffic prediction models primarily focus on deep learning architectures to capture spatial and temporal correlation. They often overlook the underlying nature of traffic. Specifically, the sensor networks in most traffic datasets do not accurately represent the actual road network exploited by vehicles, failing to provide insights into the traffic patterns in urban activities. To overcome these limitations, we propose an improved traffic prediction method based on graph convolution deep learning algorithms. We leverage human activity frequency data from National Household Travel Survey to enhance the inference capability of a causal relationship between activity and traffic patterns. Despite making minimal modifications to the conventional graph convolutional recurrent networks and graph convolutional transformer architectures, our approach achieves state-of-the-art performance without introducing excessive computational overhead.|交通预测是保障市民安全和便利的关键因素之一。现有的流量预测模型主要集中在深度学习体系结构上，以捕捉空间和时间的相关性。他们常常忽视交通的潜在本质。具体来说，大多数交通数据集中的传感器网络不能准确地表示车辆实际使用的道路网络，无法提供对城市活动中交通模式的深入了解。为了克服这些局限性，我们提出了一种改进的基于图卷积深度学习算法的流量预测方法。我们利用全国家庭旅行调查中的人类活动频率数据来加强对活动和交通模式之间因果关系的推断能力。尽管对传统的图卷积递归网络和图卷积转换器结构进行了最小的修改，但是我们的方法在不引入过多计算开销的情况下实现了最先进的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Spatio-temporal+Traffic+Prediction+through+Urban+Human+Activity+Analysis)|0|
|[On Root Cause Localization and Anomaly Mitigation through Causal Inference](https://doi.org/10.1145/3583780.3614995)|Xiao Han, Lu Zhang, Yongkai Wu, Shuhan Yuan|University of Arkansas, Fayetteville, AR, USA; Utah State University, Logan, UT, USA; Clemson University, Clemson, SC, USA|Due to a wide spectrum of applications in the real world, such as security, financial surveillance, and health risk, various deep anomaly detection models have been proposed and achieved state-of-the-art performance. However, besides being effective, in practice, the practitioners would further like to know what causes the abnormal outcome and how to further fix it. In this work, we propose RootCLAM, which aims to achieve Root Cause Localization and Anomaly Mitigation from a causal perspective. Especially, we formulate anomalies caused by external interventions on the normal causal mechanism and aim to locate the abnormal features with external interventions as root causes. After that, we further propose an anomaly mitigation approach that aims to recommend mitigation actions on abnormal features to revert the abnormal outcomes such that the counterfactuals guided by the causal mechanism are normal. Experiments on three datasets show that our approach can locate the root causes and further flip the abnormal labels.|由于在现实世界中的应用范围广泛，例如安全、金融监管和健康风险，各种深度异常检测模型已被提出，并取得了最先进的性能。然而，在实践中，除了有效之外，实践者还想进一步了解导致异常结果的原因以及如何进一步修复它。在这项工作中，我们提出了 RootCLAM，旨在从因果关系的角度实现根源定位和异常缓解。特别是在正常因果机制上提出了外部干预引起的异常，并以外部干预为根本原因定位异常特征。然后，我们进一步提出了一种异常缓解方法，目的是建议对异常特征采取缓解行动，以恢复异常结果，使由因果机制引导的反事实是正常的。在三个数据集上的实验表明，该方法能够定位异常标签的根本原因，并进一步翻转异常标签。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Root+Cause+Localization+and+Anomaly+Mitigation+through+Causal+Inference)|0|
|[SANN: Programming Code Representation Using Attention Neural Network with Optimized Subtree Extraction](https://doi.org/10.1145/3583780.3615047)|Muntasir Hoq, Sushanth Reddy Chilla, Melika Ahmadi Ranjbar, Peter Brusilovsky, Bita Akram|University of Pittsburgh, Pittsburgh, PA, USA; North Carolina State University, Raleigh, NC, USA|Automated analysis of programming data using code representation methods offers valuable services for programmers, from code completion to clone detection to bug detection. Recent studies show the effectiveness of Abstract Syntax Trees (AST), pre-trained Transformer-based models, and graph-based embeddings in programming code representation. However, pre-trained large language models lack interpretability, while other embedding-based approaches struggle with extracting important information from large ASTs. This study proposes a novel Subtree-based Attention Neural Network (SANN) to address these gaps by integrating different components: an optimized sequential subtree extraction process using Genetic algorithm optimization, a two-way embedding approach, and an attention network. We investigate the effectiveness of SANN by applying it to two different tasks: program correctness prediction and algorithm detection on two educational datasets containing both small and large-scale code snippets written in Java and C, respectively. The experimental results show SANN's competitive performance against baseline models from the literature, including code2vec, ASTNN, TBCNN, CodeBERT, GPT-2, and MVG, regarding accurate predictive power. Finally, a case study is presented to show the interpretability of our model prediction and its application for an important human-centered computing application, student modeling. Our results indicate the effectiveness of the SANN model in capturing important syntactic and semantic information from students' code, allowing the construction of accurate student models, which serve as the foundation for generating adaptive instructional support such as individualized hints and feedback.|使用代码表示方法自动分析编程数据为程序员提供了有价值的服务，从代码完成到克隆检测到 bug 检测。最近的研究表明抽象语法树(AST)、预训练的基于变压器的模型和基于图的嵌入在编程代码表示中是有效的。然而，预先训练的大型语言模型缺乏可解释性，而其他基于嵌入的方法难以从大型 AST 中提取重要信息。本研究提出一种新的基于子树的注意力神经网络(SANN) ，通过集成不同的组成部分来解决这些差距: 使用遗传算法优化的优化顺序子树提取过程，双向嵌入方法，和一个注意力网络。通过将 SANN 应用于两个不同的任务: 程序正确性预测和算法检测，我们研究了 SANN 在两个教育数据集上的有效性，这两个数据集分别包含用 Java 和 C 编写的小代码片段和大代码片段。实验结果显示，在准确预测能力方面，SANN 与文献中的基线模型(包括 code2vec、 ASTNN、 TBCNN、 CodeBERT、 GPT-2和 MVG)的竞争表现。最后，通过一个实例说明了模型预测的可解释性及其在以人为中心的重要计算应用——学生建模中的应用。我们的研究结果表明了 SANN 模型在从学生代码中捕捉重要的句法和语义信息方面的有效性，允许建立精确的学生模型，这些模型作为产生适应性教学支持(如个性化提示和反馈)的基础。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SANN:+Programming+Code+Representation+Using+Attention+Neural+Network+with+Optimized+Subtree+Extraction)|0|
|[Designing and Evaluating Presentation Strategies for Fact-Checked Content](https://doi.org/10.1145/3583780.3614841)|Danula Hettiachchi, Kaixin Ji, Jenny Kennedy, Anthony McCosker, Flora D. Salim, Mark Sanderson, Falk Scholer, Damiano Spina|RMIT University, Melbourne, Australia; Swinburne University of Technology, Melbourne, Australia; UNSW, Sydney, Australia|With the rapid growth of online misinformation, it is crucial to have reliable fact-checking methods. Recent research on finding check-worthy claims and automated fact-checking have made significant advancements. However, limited guidance exists regarding the presentation of fact-checked content to effectively convey verified information to users. We address this research gap by exploring the critical design elements in fact-checking reports and investigating whether credibility and presentation-based design improvements can enhance users' ability to interpret the report accurately. We co-developed potential content presentation strategies through a workshop involving fact-checking professionals, communication experts, and researchers. The workshop examined the significance and utility of elements such as veracity indicators and explored the feasibility of incorporating interactive components for enhanced information disclosure. Building on the workshop outcomes, we conducted an online experiment involving 76 crowd workers to assess the efficacy of different design strategies. The results indicate that proposed strategies significantly improve users' ability to accurately interpret the verdict of fact-checking articles. Our findings underscore the critical role of effective presentation of fact reports in addressing the spread of misinformation. By adopting appropriate design enhancements, the effectiveness of fact-checking reports can be maximized, enabling users to make informed judgments.|随着网络虚假信息的快速增长，建立可靠的事实核查方法至关重要。最近关于寻找值得核实的索赔和自动事实核查的研究取得了重大进展。然而，在提供经事实核查的内容以有效地向用户传达经核实的信息方面，存在着有限的指导。我们通过探索事实核查报告中的关键设计元素，以及调查可信度和基于表现的设计改进是否能够提高用户准确解释报告的能力来弥补这一研究差距。我们通过一个由事实核查专家、沟通专家和研究人员参加的研讨会，共同开发了潜在的内容展示策略。讲习班审查了诸如真实性指标等要素的重要性和效用，并探讨了纳入互动性要素以加强信息披露的可行性。在研讨会成果的基础上，我们进行了一项在线实验，涉及76名群体工作者，以评估不同设计策略的有效性。结果表明，提出的策略显著提高了用户对事实核查文章结论的准确理解能力。我们的研究结果强调了有效介绍事实报告在解决错误信息传播方面的关键作用。通过采用适当的设计改进，可以最大限度地提高事实核查报告的有效性，使用户能够做出明智的判断。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Designing+and+Evaluating+Presentation+Strategies+for+Fact-Checked+Content)|0|
|[HyperFormer: Enhancing Entity and Relation Interaction for Hyper-Relational Knowledge Graph Completion](https://doi.org/10.1145/3583780.3614922)|Zhiwei Hu, Víctor GutiérrezBasulto, Zhiliang Xiang, Ru Li, Jeff Z. Pan|University of Edinburgh, Edinburgh, United Kingdom; Shanxi University, Taiyuan , China; Shanxi University, Taiyuan, China; Cardiff University, Cardiff, United Kingdom|Hyper-relational knowledge graphs (HKGs) extend standard knowledge graphs by associating attribute-value qualifiers to triples, which effectively represent additional fine-grained information about its associated triple. Hyper-relational knowledge graph completion (HKGC) aims at inferring unknown triples while considering its qualifiers. Most existing approaches to HKGC exploit a global-level graph structure to encode hyper-relational knowledge into the graph convolution message passing process. However, the addition of multi-hop information might bring noise into the triple prediction process. To address this problem, we propose HyperFormer, a model that considers local-level sequential information, which encodes the content of the entities, relations and qualifiers of a triple. More precisely, HyperFormer is composed of three different modules: an entity neighbor aggregator module allowing to integrate the information of the neighbors of an entity to capture different perspectives of it; a relation qualifier aggregator module to integrate hyper-relational knowledge into the corresponding relation to refine the representation of relational content; a convolution-based bidirectional interaction module based on a convolutional operation, capturing pairwise bidirectional interactions of entity-relation, entity-qualifier, and relation-qualifier. realize the depth perception of the content related to the current statement. Furthermore, we introduce a Mixture-of-Experts strategy into the feed-forward layers of HyperFormer to strengthen its representation capabilities while reducing the amount of model parameters and computation. Extensive experiments on three well-known datasets with four different conditions demonstrate HyperFormer's effectiveness. Datasets and code are available at https://github.com/zhiweihu1103/HKGC-HyperFormer.|超关系知识图(HKG)通过将属性值限定符关联到三元组来扩展标准知识图，三元组有效地表示关联三元组的附加细粒度信息。超关系知识图完备化(HKGC)的目的是在考虑其限定词的同时推断出未知的三元组。大部分现有的 HKGC 方法都采用全球层次的图结构，将超关系知识编码到图卷积信息传递过程中。然而，多跳信息的加入可能会给三重预测过程带来噪声。为了解决这个问题，我们提出了一种考虑局部层次序列信息的 HyperForm 模型，它对三元组的实体、关系和限定符的内容进行编码。更准确地说，HyperForter 由三个不同的模块组成: 一个实体邻居聚合器模块，允许集成实体邻居的信息来捕获不同的视角; 一个关系限定器聚合器模块，将超关系知识集成到相应的关系中，以精化关系内容的表示; 一个基于卷积运算的双向交互模块，捕获实体关系、实体限定器和关系限定器的成对双向交互。了解与当前声明有关的内容的深度知觉。在此基础上，我们引入了一种专家混合策略，在减少模型参数和计算量的同时，增强了 HyperForm 的前馈层的表示能力。在三个著名的数据集上进行的四种不同条件的大量实验证明了 HyperForm 的有效性。数据集和代码可在 https://github.com/zhiweihu1103/hkgc-hyperformer 获得。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HyperFormer:+Enhancing+Entity+and+Relation+Interaction+for+Hyper-Relational+Knowledge+Graph+Completion)|0|
|[Liberate Pseudo Labels from Over-Dependence: Label Information Migration on Sparsely Labeled Graphs](https://doi.org/10.1145/3583780.3614954)|Zhihui Hu, Yao Fu, Hong Zhao, Xiaoyu Cai, Weihao Jiang, Shiliang Pu|Hikvision Research Institute & Key Laboratory of Peace-building Big Data of Zhejiang Province, Hangzhou, China; Hikvision Research Institute, Hangzhou, China|Graph Convolutional Networks (GCNs) have made outstanding achievements in many tasks on graphs in recent years, but their success relies on sufficient training data. In practice, sparsely labeled graphs widely exist in the real world so self-training methods have become popular approaches by adding pseudo labeled nodes to enhance the performance of GCNs. However, we observe that most selected high-confidence pseudo labeled nodes by the existing methods would surround the true labeled nodes. It is what we called pseudo label over-dependence, which could lead to the non-uniform pseudo label distribution. Furthermore, a thorough experiment shows that the classification accuracy changes significantly under different label densities and the label-sparse regions show great potential improvement in the model performance. Based on the above findings, we theoretically analyze the constraint factors in the label-sparse regions and further propose reducing the feature distribution difference between the label-dense regions and label-sparse regions can effectively decrease the classification error. Thus, in this paper, we propose a novel Graph Label Information Migration framework (GLIM) to liberate pseudo labels from over-dependence. Specifically, we first propose a training dynamics module (TDM) that uses abundant training process information to find more reliable node labels and improve the model robustness against label noise. Then we propose a label migration module (LMM) that migrates label information from label-dense regions to label-sparse regions by a spectral based graph matching algorithm. These migrated labels are like the glimmers in the darkness, providing the supervision signals for the unlabeled nodes in label-sparse regions. Finally, we conduct extensive experiments to demonstrate the effectiveness of the proposed GLIM.|图卷积网络(GCNs)近年来在许多图任务中取得了突出的成就，但它的成功依赖于充分的训练数据。在实际应用中，稀疏标记图广泛存在于现实世界中，因此通过增加伪标记节点来提高 GCNs 性能的自训练方法已经成为一种流行的方法。然而，我们观察到，现有方法选择的大多数高置信度伪标记节点将包围真正的标记节点。这就是我们所说的伪标签过度依赖，它可能导致非均匀的伪标签分布。实验表明，在不同的标签密度下，分类精度有显著的变化，标签稀疏区域对模型性能有很大的改善潜力。在此基础上，从理论上分析了标签稀疏区域的约束因素，进一步提出减小标签密集区域与标签稀疏区域之间的特征分布差异可以有效地减小分类误差。因此，本文提出了一种新的图形标签信息迁移框架(GLIM) ，将伪标签从过度依赖中解放出来。具体来说，我们首先提出了一个训练动力学模块(TDM) ，利用大量的训练过程信息来寻找更可靠的节点标签，提高模型对标签噪声的鲁棒性。然后提出了一种基于谱图匹配算法的标签迁移模块(LMM) ，将标签信息从标签密集区域迁移到标签稀疏区域。这些迁移的标签就像黑暗中的微光，为标签稀疏区域的未标记节点提供监控信号。最后，我们进行了广泛的实验来验证所提出的 GLIM 的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Liberate+Pseudo+Labels+from+Over-Dependence:+Label+Information+Migration+on+Sparsely+Labeled+Graphs)|0|
|[Enhanced Template-Free Reaction Prediction with Molecular Graphs and Sequence-based Data Augmentation](https://doi.org/10.1145/3583780.3614865)|Haozhe Hu, Yongquan Jiang, Yan Yang, Jim X. Chen|Southwest Jiaotong University, Chengdu, China; George Mason University, Fairfax, USA|Retrosynthesis and forward synthesis prediction are fundamental challenges in organic synthesis, computer-aided synthesis planning (CASP), and computer-aided drug design (CADD). The objective is to predict plausible reactants for a given target product and its corresponding inverse task. With the rapid development of deep learning, numerous approaches have been proposed to solve this problem from various perspectives. The methods based on molecular graphs benefit from their rich features embedded inside but face difficulties in applying existing sequence-based data augmentations due to the permutation invariance of graph structures. In this work, we propose SeqAGraph, a template-free approach that annotates input graphs with its root atom index to ensure compatibility with sequence-based data augmentation. The matrix product for global attention in graph encoders is implemented by indexing, elementwise product, and aggregation to fuse global attention with local message passing without graph padding. Experiments demonstrate that SeqAGraph fully benefits from molecular graphs and sequence-based data augmentation and achieves state-of-the-art accuracy in template-free approaches.|回溯合成和正向合成预测是有机合成、计算机辅助合成计划(cASP)和计算机辅助药物设计(cADD)的基本挑战。目的是预测给定目标产物的合理反应物及其相应的逆任务。随着深度学习的迅速发展，人们从不同的角度提出了许多解决这一问题的方法。基于分子图的方法得益于其内嵌的丰富特征，但由于图结构的排列不变性，使得现有的基于序列的数据增广方法难以应用。在这项工作中，我们提出了 SeqAGGraph，一种无模板的方法，用它的根原子索引对输入图进行注释，以确保与基于序列的数据增强的兼容性。在图形编码器中，通过索引、元素乘积和聚合实现全局注意力矩阵积，使全局注意力与无图形填充的局部消息传递相融合。实验表明，SeqAGGraph 完全受益于分子图和基于序列的数据增强，并在无模板的方法中实现了最先进的准确性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhanced+Template-Free+Reaction+Prediction+with+Molecular+Graphs+and+Sequence-based+Data+Augmentation)|0|
|[Spans, Not Tokens: A Span-Centric Model for Multi-Span Reading Comprehension](https://doi.org/10.1145/3583780.3615064)|Zixian Huang, Jiaying Zhou, Chenxu Niu, Gong Cheng|Nanjing University, Nanjing, China|Many questions should be answered by not a single answer but a set of multiple answers. This emerging Multi-Span Reading Comprehension (MSRC) task requires extracting multiple non-contiguous spans from a given context to answer a question. Existing methods extend conventional single-span models to predict the positions of the start and end tokens of answer spans, or predict the beginning-inside-outside tag of each token. Such token-centric paradigms can hardly capture dependencies among span-level answers which are critical to MSRC. In this paper, we propose SpanQualifier, a span-centric scheme where spans, as opposed to tokens, are directly represented and scored to qualify as answers. Explicit span representations enable their interaction which exploits their dependencies to enhance representations. Experiments on three MSRC datasets demonstrate the effectiveness of our span-centric scheme and show that SpanQualifier achieves state-of-the-art results.|许多问题的答案不应该是一个单一的答案，而应该是一系列的多重答案。这个新兴的多阅读理解任务需要从给定的上下文中提取多个非连续的跨度来回答问题。现有的方法扩展了传统的单跨度模型来预测答案跨度的开始和结束标记的位置，或者预测每个标记的开始-内部-外部标记。这种以令牌为中心的范例很难捕获对 MSRC 至关重要的跨级应答之间的依赖性。在本文中，我们提出了 SpanQualifier，这是一个以跨度为中心的方案，其中跨度(而不是标记)直接表示并打分以符合答案的要求。显式跨度表示使它们的交互能够利用它们的依赖性来增强表示。在三个 MSRC 数据集上的实验表明了我们的跨度中心方案的有效性，并且表明 SpanQualifier 达到了最先进的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spans,+Not+Tokens:+A+Span-Centric+Model+for+Multi-Span+Reading+Comprehension)|0|
|[STAMINA (Spatial-Temporal Aligned Meteorological INformation Attention) and FPL (Focal Precip Loss): Advancements in Precipitation Nowcasting for Heavy Rainfall Events](https://doi.org/10.1145/3583780.3615069)|PingChia Huang, YuehLi Chen, YiSyuan Liou, BingChen Tsai, ChunChieh Wu, Winston H. Hsu|National Taiwan University, Taipei, Taiwan Roc|Precipitation nowcasting is crucial for weather-dependent decision-making in various sectors, providing accurate and high-resolution predictions of precipitation within a typical two-hour timeframe. Deep learning techniques have shown promise in improving nowcasting accuracy by leveraging large radar datasets. However, accurately predicting heavy rainfall events remains challenging due to several persistent problems in previous work. These include spatial-temporal misalignment between meteorological information and precipitation data, as well as the performance gap between different rainfall levels. To address these challenges, we propose two innovative modules: Spatial-Temporal Aligned Meteorological INformation Attention (STAMINA) and Focal Precip Loss (FPL). STAMINA integrates meteorological information using spatial-temporal embedding and pixelwise linear attention mechanisms to overcome spatial-temporal misalignment. FPL addresses event imbalance through event weighting and a penalty mechanism. Through extensive experiments, we demonstrate significant performance improvements achieved by STAMINA and FPL, with an 8% improvement in predicting light rainfall and, more significantly, a 30% improvement in heavy rainfall compared to the state-of-the-art DGMR model. These modules offer practical and effective solutions for enhancing nowcasting accuracy, with a specific focus on improving predictions for heavy rainfall events. By tackling the persistent problems in previous work, our proposed approach represents a significant advancement in the field of precipitation nowcasting.|降水临近预报对于各部门依赖天气的决策至关重要，能够在典型的两小时时间范围内提供准确和高分辨率的降水预报。深度学习技术在利用大型雷达数据集提高临近预报精度方面已显示出前景。然而，由于以往工作中的一些持续性问题，准确预测强降水事件仍然具有挑战性。其中包括气象信息与降水数据之间的时空错位，以及不同降水水平之间的性能差距。为了应对这些挑战，我们提出了两个创新模块: 时空对齐气象信息注意(STAMINA)和焦点降水损失(FPL)。STAMINA 利用时空嵌入和像素线性注意机制对气象信息进行集成，克服了时空失调问题。FPL 通过事件加权和惩罚机制解决事件不平衡问题。通过广泛的实验，我们证明了 STAMINA 和 FPL 实现的显著性能改进，与最先进的 DGMR 模型相比，在预测小降雨方面提高了8% ，更显著的是，在强降雨方面提高了30% 。这些模块为提高临近预报的准确性提供了切实有效的解决方案，特别侧重于改进对强降雨事件的预报。通过解决以往工作中存在的问题，我们提出的方法代表了降水临近预报领域的一个重大进展。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=STAMINA+(Spatial-Temporal+Aligned+Meteorological+INformation+Attention)+and+FPL+(Focal+Precip+Loss):+Advancements+in+Precipitation+Nowcasting+for+Heavy+Rainfall+Events)|0|
|[SAGE: A Storage-Based Approach for Scalable and Efficient Sparse Generalized Matrix-Matrix Multiplication](https://doi.org/10.1145/3583780.3615044)|MyungHwan Jang, YunYong Ko, HyuckMoo Gwon, Ikhyeon Jo, Yongjun Park, SangWook Kim|Yonsei University, Seoul, Republic of Korea; Hanyang University, Seoul, Republic of Korea|Sparse generalized matrix-matrix multiplication (SpGEMM) is a fundamental operation for real-world network analysis. With the increasing size of real-world networks, the single-machine-based SpGEMM approach cannot perform SpGEMM on large-scale networks, exceeding the size of main memory (i.e., not scalable). Although the distributed-system-based approach could handle large-scale SpGEMM based on multiple machines, it suffers from severe inter-machine communication overhead to aggregate results of multiple machines (i.e., not efficient). To address this dilemma, in this paper, we propose a novel storage-based SpGEMM approach (SAGE) that stores given networks in storage (e.g., SSD) and loads only the necessary parts of the networks into main memory when they are required for processing via a 3-layer architecture. Furthermore, we point out three challenges that could degrade the overall performance of SAGE and propose three effective strategies to address them: (1) block-based workload allocation for balancing workloads across threads, (2) in-memory partial aggregation for reducing the amount of unnecessarily generated storage-memory I/Os, and (3) distribution-aware memory allocation for preventing unexpected buffer overflows in main memory. Via extensive evaluation, we verify the superiority of SAGE over existing SpGEMM methods in terms of scalability and efficiency.|稀疏广义矩阵乘法(SpGEMM)是实际网络分析的基本运算。随着现实网络规模的不断扩大，基于单机的 SpGEMM 方法不能在大规模网络上运行，超出了主存的规模(即不可伸缩性)。尽管基于分布式系统的方法可以处理基于多台机器的大规模 SpGEMM，但是由于需要对多台机器的结果进行聚合(即效率不高) ，使得该方法存在严重的机器间通信开销。为了解决这一难题，本文提出了一种新的基于存储的 SpGEMM 方法(SAGE) ，该方法将给定的网络存储在存储器中(如 SSD) ，当需要通过3层架构进行处理时，只将网络的必要部分加载到主存中。此外，我们指出了可能降低 SAGE 整体性能的三个挑战，并提出了三种有效的策略来解决这些问题: (1)基于块的工作负载分配，用于平衡线程间的工作负载; (2)内存部分聚合，用于减少不必要的生成存储内存 I/O 的数量; (3)分布式感知内存分配，用于防止主存中意外的缓冲区溢出。通过广泛的评估，我们验证了 SAGE 方法在可扩展性和效率方面优于现有的 SpGEMM 方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SAGE:+A+Storage-Based+Approach+for+Scalable+and+Efficient+Sparse+Generalized+Matrix-Matrix+Multiplication)|0|
|[Relevant Entity Selection: Knowledge Graph Bootstrapping via Zero-Shot Analogical Pruning](https://doi.org/10.1145/3583780.3615030)|Lucas Jarnac, Miguel Couceiro, Pierre Monnin|Orange & Université de Lorraine, CNRS, LORIA, Belfort & Nancy, France; Orange, Belfort, France; Université de Lorraine, CNRS, LORIA, Nancy, France|Knowledge Graph Construction (KGC) can be seen as an iterative process starting from a high quality nucleus that is refined by knowledge extraction approaches in a virtuous loop. Such a nucleus can be obtained from knowledge existing in an open KG like Wikidata. However, due to the size of such generic KGs, integrating them as a whole may entail irrelevant content and scalability issues. We propose an analogy-based approach that starts from seed entities of interest in a generic KG, and keeps or prunes their neighboring entities. We evaluate our approach on Wikidata through two manually labeled datasets that contain either domain-homogeneous or -heterogeneous seed entities. We empirically show that our analogy-based approach outperforms LSTM, Random Forest, SVM, and MLP, with a drastically lower number of parameters. We also evaluate its generalization potential in a transfer learning setting. These results advocate for the further integration of analogy-based inference in tasks related to the KG lifecycle.|知识图构建(KGC)可以看作是一个迭代过程，它从一个高质量的核心开始，通过知识抽取方法在一个良性循环中精炼。这样的细胞核可以从像 Wikidata 这样的开放幼儿园中存在的知识中获得。然而，由于这些通用幼稚园的规模，将它们作为一个整体进行集成可能会带来不相关的内容和可伸缩性问题。我们提出了一种基于类比的方法，它从一般 KG 中感兴趣的种子实体开始，并保留或删除它们的相邻实体。我们评估我们的方法对 Wikidata 通过两个手动标记的数据集，包含领域同质或异质种子实体。我们的经验表明，我们的类比为基础的方法优于 LSTM，随机森林，支持向量机和 MLP，大大减少了参数数量。我们还评估了它在迁移学习环境中的推广潜力。这些结果提倡在与 KG 生命周期相关的任务中进一步集成基于类比的推理。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Relevant+Entity+Selection:+Knowledge+Graph+Bootstrapping+via+Zero-Shot+Analogical+Pruning)|0|
|[PriSHAP: Prior-guided Shapley Value Explanations for Correlated Features](https://doi.org/10.1145/3583780.3615013)|Guanyu Jiang, Fuzhen Zhuang, Bowen Song, Tianyi Zhang, Deqing Wang|Beihang University, Beijing, China; Ant Group, Hangzhou, China; Beihang University & Zhongguancun Laboratory, Beijing, China|Among numerous explainable AI (XAI) methods proposed in recent years, model explanations based on Shapley values are widely accepted for their solid theoretical support from game theory. However, most existing methods approximate Shapley values based on a feature independence assumption considering the complexity of calculating exact Shapley values. This assumption could bring some counterfactual problems when interpreted features are highly correlated and result in explanations contrary to human intuition. In this paper, we propose PriSHAP to explicitly model the dependency relationship between correlated features and provide reasonable explanations for tabular data. Feature dependencies are analyzed and taken as prior information to guide the process of estimating Shapley values. Additionally, PriSHAP is free to be applied in popular Shapley value-based explainers to address counterfactual problems while providing more faithful explanations. A pipeline is given to apply PriSHAP in existing explainers with simple adjustments. Extensive experiments on both public datasets and artificial datasets are provided to demonstrate the effectiveness of our method.|在近年来提出的众多可解释 AI (XAI)方法中，基于 Shapley 值的模型解释因其博弈论的坚实理论支持而被广泛接受。然而，考虑到计算准确的 Shapley 值的复杂性，现有的方法大多基于特征无关的假设来逼近 Shapley 值。当解释特征高度相关时，这种假设会带来一些反事实问题，导致解释与人的直觉相悖。在本文中，我们提出了 PriSHAP 显式模型相关特征之间的依赖关系，并提供合理的解释表数据。将特征依赖关系作为先验信息进行分析，指导 Shapley 值的估计过程。此外，PriSHAP 可以自由地应用于流行的 Shapley 价值为基础的解释，以解决反事实的问题，同时提供更忠实的解释。通过简单的调整，给出了在现有解释器中应用 PriSHAP 的流水线。在公共数据集和人工数据集上进行了大量的实验，验证了该方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PriSHAP:+Prior-guided+Shapley+Value+Explanations+for+Correlated+Features)|0|
|[A Momentum Loss Reweighting Method for Improving Recall](https://doi.org/10.1145/3583780.3614764)|Chenzhi Jiang, Yin Jin, Ningtao Wang, Ruofan Wu, Xing Fu, Weiqiang Wang|Tiansuan Lab, Ant Group, Shanghai, China; Tiansuan Lab, Ant Group, Hangzhou, China|In many practical binary classification applications, such as financial fraud detection or medical diagnosis, it is crucial to optimize a model's performance on high-confidence samples whose scores are higher than a specific threshold, which is calculated by a given false positive rate according to practical requirements. However, the proportion of high-confidence samples is typically extremely small, especially in long-tailed datasets, which can lead to poor recall results and an alignment bias between realistic goals and loss. To address this challenge, we propose a novel loss reweighting framework called Momentum Threshold-Oriented Loss (MTOL) for binary classification tasks and propose two instantiated losses of it. Given a limited FPR range, MTOL aims to improve the recall of binary classification models at that FPR range by incorporating a batch memory queue and momentum estimation mechanisms. The MTOL adaptively estimates thresholds of FPR during the model training iterations and up-weights the loss of samples in the threshold range, with little consumption of storage and computation. Our experimental results on various datasets, including CIFAR-10, CIFAR-100, Tiny-ImageNet, demonstrate the significant effect of MTOL in improving the recall at low FPR especially in class imbalance settings. These results suggest that MTOL is a promising approach in scenarios where the model's performance in the low FPR range is of utmost importance.|在许多实际的二进制分类应用中，如金融欺诈检测或医疗诊断，优化模型对高置信度样本的性能是至关重要的，这些样本的得分高于特定的阈值，根据实际需求，该阈值是通过给定的假阳性率计算的。然而，高置信度样本的比例通常非常小，尤其是在长尾数据集中，这可能导致较差的召回结果和现实目标与损失之间的一致性偏差。为了解决这个问题，我们提出了一个新的损失重新加权框架，称为动量阈值导向损失(MTOL)的二进制分类任务，并提出了两个实例化的损失。在有限的 FPR 范围内，MTOL 旨在通过引入批记忆队列和动量估计机制来提高该 FPR 范围内二进制分类模型的召回率。在模型训练迭代过程中，MTOL 自适应估计 FPR 的阈值，并在阈值范围内增加样本损失的权重，同时减少存储和计算的消耗。我们在各种数据集上的实验结果，包括 CIFAR-10，CIFAR-100，Tiny-ImageNet，证明了 MTOL 在改善低 FPR 的召回方面的显着效果，特别是在类不平衡设置中。这些结果表明，MTOL 是一种有前途的方法在情况下，模型的性能在低 FPR 范围是至关重要的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Momentum+Loss+Reweighting+Method+for+Improving+Recall)|0|
|[Hierarchical Multi-Label Classification with Partial Labels and Unknown Hierarchy](https://doi.org/10.1145/3583780.3614912)|Suhyeon Jo, DongHyeok Shin, Byeonghu Na, JoonHo Jang, IlChul Moon|Korea Advanced Institute of Science & Technology, Daejeon, Republic of Korea|Hierarchical multi-label classification aims at learning a multi-label classifier from a dataset whose labels are organized into a hierarchical structure. To the best of our knowledge, we propose for the first time the problem of finding a multi-label classifier given a partially labeled hierarchical multi-label dataset. We also assume the situation where the classifier cannot access hierarchical information during training. This work proposes an iterative framework for learning both multi-labels and a hierarchical structure of classes. When training a multi-label classifier from partial labels, our model extracts a class hierarchy from the classifier output using our hierarchy extraction algorithm. Then, our proposed loss exploits the extracted hierarchy to train the classifier. Theoretically, we show that our hierarchy extraction algorithm correctly finds the unknown hierarchy under a mild condition, and we prove that our loss function of multi-label classification with such hierarchy becomes an unbiased estimator of true multi-label classification risk. Our experiments show that our model obtains a class hierarchy close to the ground-truth dataset hierarchy, and simultaneously, our method outperforms previous methods for hierarchical multi-label classification and multi-label classification from partial labels.|分层多标签分类旨在从标签组织成分层结构的数据集中学习多标签分类器。根据我们的知识，我们首次提出了在给定部分标记的层次化多标记数据集的情况下寻找多标记分类器的问题。我们还假设分类器在训练期间不能访问层次信息的情况。这项工作提出了一个迭代的框架学习两个多标签和分层结构的类。当从部分标签中训练多标签分类器时，我们的模型使用我们的层次提取算法从分类器输出中提取类层次。然后，我们提出的损失利用提取的层次结构来训练分类器。从理论上证明了我们的层次提取算法在温和的条件下正确地找到了未知的层次，并且证明了我们的具有这种层次的多标签分类的损失函数成为真正的多标签分类风险的无偏估计。实验结果表明，该模型获得了一个接近于地面真实数据集层次结构的类层次结构，同时该方法在多标签分类和部分标签多标签分类方面优于以往的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Multi-Label+Classification+with+Partial+Labels+and+Unknown+Hierarchy)|0|
|[Robust Graph Clustering via Meta Weighting for Noisy Graphs](https://doi.org/10.1145/3583780.3615038)|Hyeonsoo Jo, Fanchen Bu, Kijung Shin||How can we find meaningful clusters in a graph robustly against noise edges? Graph clustering (i.e., dividing nodes into groups of similar ones) is a fundamental problem in graph analysis with applications in various fields. Recent studies have demonstrated that graph neural network (GNN) based approaches yield promising results for graph clustering. However, we observe that their performance degenerates significantly on graphs with noise edges, which are prevalent in practice. In this work, we propose MetaGC for robust GNN-based graph clustering. MetaGC employs a decomposable clustering loss function, which can be rephrased as a sum of losses over node pairs. We add a learnable weight to each node pair, and MetaGC adaptively adjusts the weights of node pairs using meta-weighting so that the weights of meaningful node pairs increase and the weights of less-meaningful ones (e.g., noise edges) decrease. We show empirically that MetaGC learns weights as intended and consequently outperforms the state-of-the-art GNN-based competitors, even when they are equipped with separate denoising schemes, on five real-world graphs under varying levels of noise. Our code and datasets are available at https://github.com/HyeonsooJo/MetaGC.|我们怎样才能在一个图中找到有意义的集群对噪声边强健？图聚类(即将节点划分为相似的节点组)是图分析中的一个基本问题，在各个领域都有应用。最近的研究表明，基于图神经网络(GNN)的方法在图聚类方面取得了很好的效果。然而，我们观察到它们的性能在具有噪声边的图上明显退化，这在实际中是普遍存在的。在这项工作中，我们提出了 MetaGC 的健壮 GNN 为基础的图聚类。MetaGC 使用了一个可分解的聚类损失函数，它可以被重新表述为节点对损失的总和。我们给每个节点对添加一个可学习的权重，MetaGC 使用元加权自适应地调整节点对的权重，以便有意义的节点对的权重增加，而无意义的节点对(例如噪声边缘)的权重减少。我们的经验表明，MetaGC 按照预期学习权重，因此优于最先进的基于 GNN 的竞争对手，即使它们配备了独立的去噪方案，在五个不同噪声水平的真实世界图上。我们的代码和数据集 https://github.com/hyeonsoojo/metagc 可用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Graph+Clustering+via+Meta+Weighting+for+Noisy+Graphs)|0|
|[CFOM: Lead Optimization For Drug Discovery With Limited Data](https://doi.org/10.1145/3583780.3614807)|Natan Kaminsky, Uriel Singer, Kira Radinsky|Technion - Israel Institute of Technology, Haifa, Israel; Meta AI Research, Tel-Aviv, Israel|Drug development is a long and costly process consisting of several stages that can take many years to complete. One of the early stage's goals is to optimize a novel chemical compound to be active against a target protein associated with the disease. Often machine learning techniques are used to improve the procedure of discovering and optimizing potential drug candidates. The goal of molecule optimization is, given an input molecule, to produce a new molecule that is chemically similar to the input molecule but with an improved property. We present a novel algorithm that during optimization divides a molecule into two disjoint substructures that we call: the molecule chains and the molecule core. Our approach is inspired by expert design of chemical compounds that employ a fundamental molecular template and add to it chemical functional groups to generate compounds with desired properties. We train a model to generate the molecule chains with the desired properties for optimization, which are then attached to the molecule core to construct a novel molecule with high similarity to the input molecule. This is achieved by selective masking of pairs of input molecules' chains and cores during training. Additionally, we demonstrate the extension of this approach to data-scarce tasks, like targeting a drug to a novel protein. We first evaluate our method on standard molecule optimization tasks such as inhibition against glycogen synthase kinase-3 beta (GSK3β). We then empirically compared the model performance with the state-of-the-art algorithms over 21 novel proteins and show superior performance.|药物开发是一个漫长而昂贵的过程，包括几个阶段，可能需要许多年才能完成。早期阶段的目标之一是优化一种新的化合物，使其对与疾病相关的靶蛋白具有活性。机器学习技术经常被用来改进发现和优化潜在候选药物的过程。分子优化的目标是，给定一个输入分子，以产生一个新的分子，这是化学类似的输入分子，但具有改进的性能。我们提出了一个新的算法，在优化过程中分裂成两个不相交的子结构，我们称之为: 分子链和分子核心。我们的方法的灵感来自专家设计的化合物，采用一个基本的分子模板，并添加到它的化学功能基团，以产生具有期望的性质的化合物。我们训练一个模型来产生具有优化所需特性的分子链，然后将这些分子链连接到分子核心以构建一个与输入分子具有高度相似性的新分子。这是通过在训练过程中对输入分子的链和核进行选择性掩蔽来实现的。此外，我们还展示了这种方法在数据稀缺任务中的应用，比如将药物定位于一种新的蛋白质。我们首先评估我们的方法在标准分子优化任务，如抑制糖原合成酶激酶 -3β (GSK3β)。然后，我们经验性地比较了模型性能与国家的最先进的算法超过21个新的蛋白质和显示优越的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CFOM:+Lead+Optimization+For+Drug+Discovery+With+Limited+Data)|0|
|[Diving into a Sea of Opinions: Multi-modal Abstractive Summarization with Comment Sensitivity](https://doi.org/10.1145/3583780.3614849)|Raghvendra Kumar, Ratul Chakraborty, Abhishek Tiwari, Sriparna Saha, Naveen Saini|Indian Institute of Technology Patna, Patna, India; Ramakrishna Mission Vivekananda Educational & Research Institute Kolkata, Kolkata, India; Indian Institute of Information Technology Lucknow, Lucknow, India|In the modern era, the rapid expansion of social media and the proliferation of the internet community has led to a multi-fold increase in the richness and range of views and outlooks expressed by readers and viewers. To obtain valuable insights from this vast sea of opinions, we present an inventive and holistic procedure for multi-modal abstractive summarization with comment sensitivity. Our proposed model utilizes both textual and visual modalities and examines the remarks provided by the readers to produce summaries that apprehend the significant points and opinions made by them. Our model features a transformer-based encoder that seamlessly processes both news articles and comments, merging them before transmitting the amalgamated information to the decoder. Additionally, the core segment of our architecture consists of an attention-based merging technique which is trained adversarially by means of a generator and discriminator to bridge the semantic gap between comments and articles. We have used a Bi-LSTM-based branch for image pointer generation. We assess our model on the reader-aware multi-document summarization (RA-MDS) dataset which contains news articles, their summaries, and related comments. We have extended the dataset by adding images pertaining to news articles in the corpus to increase the richness and diversity of the dataset. Our comprehensive experiments reveal that our model outperforms similar pre-trained models and baselines across two of the four evaluated metrics, showcasing its superior performance.|在现代社会，社会媒体的迅速扩张和互联网社区的扩散，使得读者和观众表达的观点和观点的丰富性和范围增加了数倍。为了从这一浩瀚的意见海洋中获得有价值的见解，我们提出了一个创造性和整体性的多模态抽象摘要过程，具有评论敏感性。我们提出的模型利用文本和视觉模式，检查读者提供的评论，以产生理解他们所提出的重要观点和意见的摘要。我们的模型具有一个基于转换器的编码器，它可以无缝地处理新闻文章和评论，在将合并后的信息传输给解码器之前将它们合并。此外，我们的体系结构的核心部分包括一个基于注意力的合并技术，该技术通过生成器和鉴别器进行对立训练，以消除评论和文章之间的语义差距。我们使用了一个基于双 LSTM 的分支来生成图像指针。我们在读者感知的多文档摘要(RA-MDS)数据集上评估我们的模型，该数据集包含新闻文章、它们的摘要和相关的评论。我们通过在语料库中添加与新闻文章相关的图像来扩展数据集，以增加数据集的丰富性和多样性。我们的综合实验表明，我们的模型优于类似的预训练模型和基线，在四个评估指标中的两个，显示了其优越的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Diving+into+a+Sea+of+Opinions:+Multi-modal+Abstractive+Summarization+with+Comment+Sensitivity)|0|
|[Prompting Strategies for Citation Classification](https://doi.org/10.1145/3583780.3615018)|Suchetha N. Kunnath, David Pride, Petr Knoth|The Open University, Milton Keynes, United Kingdom|Citation classification aims to identify the purpose of the cited article in the citing article. Previous citation classification methods rely largely on supervised approaches. The models are trained on datasets with citing sentences or citation contexts annotated for a citation's purpose or function or intent. Recent advancements in Large Language Models (LLMs) have dramatically improved the ability of NLP systems to achieve state-of-the-art performances under zero or few-shot settings. This makes LLMs particularly suitable for tasks where sufficiently large labelled datasets are not yet available, which remains to be the case for citation classification. This paper systematically investigates the effectiveness of different prompting strategies for citation classification and compares them to promptless strategies as a baseline. Specifically, we evaluate the following four strategies, two of which we introduce for the first time, which involve updating Language Model (LM) parameters while training the model: (1) Promptless fine-tuning, (2) Fixed-prompt LM tuning, (3) Dynamic Context-prompt LM tuning (proposed), (4) Prompt + LM fine-tuning (proposed). Additionally, we test the zero-shot performance of LLMs, GPT3.5, a (5) Tuning-free prompting strategy that involves no parameter updating. Our results show that prompting methods based on LM parameter updating significantly improve citation classification performances on both domain-specific and multi-disciplinary citation classifications. Moreover, our Dynamic Context-prompting method achieves top scores both for the ACL-ARC and ACT2 citation classification datasets, surpassing the highest-performing system in the 3C shared task benchmark. Interestingly, we observe zero-shot GPT3.5 to perform well on ACT2 but poorly on the ACL-ARC dataset.|引文分类旨在识别引文中被引文章的目的。以往的引文分类方法主要依赖于监督方法。这些模型在数据集上进行训练，引用的句子或引用上下文被注释为引用的目的、功能或意图。大语言模型(LLM)的最新进展极大地提高了自然语言处理(NLP)系统的能力，使其能够在零或少镜头设置下实现最先进的性能。这使得 LLM 特别适合于那些没有足够大标记的数据集的任务，这仍然是引文分类的情况。本文系统地研究了引文分类中不同激励策略的有效性，并将其与非激励策略进行了比较。具体来说，我们评估了以下四种策略，其中两种是我们首次引入的，它们涉及在训练语言模型时更新语言模型(LM)参数: (1)无提示微调，(2)固定提示 LM 微调，(3)动态上下文提示 LM 微调(建议) ，(4)提示 + LM 微调(建议)。此外，我们还测试了 LLM，GPT3.5，这是一种不需要参数更新的无调优提示策略。研究结果表明，基于 LM 参数更新的提示方法显著提高了特定领域和多学科引文分类的分类性能。此外，我们的动态上下文提示方法在 ACL-ARC 和 ACT2引文分类数据集中都获得了最高分，超过了3C 共享任务基准中表现最好的系统。有趣的是，我们观察到零射 GPT3.5在 ACT2上表现良好，但在 ACL-ARC 数据集上表现不佳。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Prompting+Strategies+for+Citation+Classification)|0|
|[VFedAD: A Defense Method Based on the Information Mechanism Behind the Vertical Federated Data Poisoning Attack](https://doi.org/10.1145/3583780.3615106)|Jinrong Lai, Tong Wang, Chuan Chen, Yihao Li, Zibin Zheng|Sun Yat-sen University, Guangzhou, China|In recent years, federated learning has achieved remarkable results in the medical and financial fields, but various attacks have always plagued federated learning. Data poisoning attack and defense research in horizontal federated learning are sufficient, yet vertical federated data poisoning attack and defense remains an open area due to two challenges: (1) Complex data distributions lead to immense attack possibilities, and (2) defense methods are insufficient for complex data distributions. We have discovered that from the perspective of information theory, the above challenges can be addressed elegantly and succinctly with a solution. We first reveal the information-theoretic mechanisms underlying vertical federated data poisoning attacks and then propose an unsupervised vertical federated data poisoning defense method (VFedAD) based on information theory. VFedAD learns semantic-rich client data representations through contrastive learning task and cross-client prediction task to identify anomalies. Experiments show VFedAD effectively detects vertical federated anomalies, protecting subsequent algorithms from vertical federated data poisoning attacks.|近年来，联邦学习在医学和金融领域取得了显著的成绩，但各种攻击一直困扰着联邦学习。水平联邦学习中的数据中毒攻击和防御研究已经足够，但垂直联邦数据中毒攻击和防御仍然是一个开放的领域，这是由于两个挑战: (1)复杂的数据分布导致巨大的攻击可能性，(2)防御方法不足以应对复杂的数据分布。我们发现，从信息论的角度来看，上述挑战可以通过一个解决方案得到优雅而简洁的解决。首先揭示了垂直联邦数据中毒攻击的信息论机制，然后提出了一种基于信息论的无监督垂直联邦数据中毒防御方法(VFedAD)。VFedAD 通过对比学习任务和跨客户端预测任务学习语义丰富的客户端数据表示来识别异常。实验表明，VFedAD 可以有效地检测垂直联邦异常，保护后续算法免受垂直联邦数据中毒攻击。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=VFedAD:+A+Defense+Method+Based+on+the+Information+Mechanism+Behind+the+Vertical+Federated+Data+Poisoning+Attack)|0|
|[A Re-evaluation of Deep Learning Methods for Attributed Graph Clustering](https://doi.org/10.1145/3583780.3614768)|Xinying Lai, Dingming Wu, Christian S. Jensen, Kezhong Lu|Aalborg University, Aalborg, Denmark; Shenzhen University, Shenzhen, China|Attributed graph clustering aims to partition the nodes in a graph into groups such that the nodes in the same group are close in terms of graph proximity and also have similar attribute values. Recently, deep learning methods have achieved state-of-the-art clustering performance. However, the effectiveness of existing methods remains unclear due to two reasons. First, the datasets used for evaluation do not support fully the goal of attributed graph clustering. The category labels of nodes are only relevant to node attributes, and nodes with the same category label are often distant in the graph. Second, existing methods for the attributed graph clustering are complex and consist of several components. There is lack of comparisons of methods composed of different components from existing methods. This study proposes six benchmark datasets that support better the goal of attributed graph clustering and reports the performance of existing representative methods. Given that existing methods leave room for improvement on the proposed benchmark datasets, we systematically analyze five aspects of existing methods: encoded information, training networks, fusion mechanisms, loss functions, and clustering result generation. Based on these aspects, we decompose existing methods into modules and evaluate the performance of reconfigured methods based on these modules. According to the experimental results on the proposed benchmark datasets, we identify two promising configurations: (i) taking the attribute matrix as input to a graph convolutional network and (ii) layer-wise linear fusing deep neural network and graph attention network. And we also find that complex loss function fails to improve the clustering performance.|属性图聚类的目的是将一个图中的节点划分为若干组，使得同一组中的节点在图的邻近性方面相近，并且具有相似的属性值。近年来，深度学习方法取得了一流的聚类性能。然而，由于两个原因，现有方法的有效性仍不清楚。首先，用于评估的数据集不完全支持属性图聚类的目标。节点的类别标签只与节点属性相关，具有相同类别标签的节点在图中往往相距较远。其次，现有的属性图聚类方法是复杂的，由多个部分组成。由现有方法的不同组件组成的方法缺乏比较。本研究提出了六个基准数据集，更好地支持属性图聚类的目标，并报告了现有的代表性方法的性能。鉴于现有的方法在基准数据集上还有改进的空间，我们系统地分析了现有方法的五个方面: 编码信息、训练网络、融合机制、损失函数和聚类结果生成。基于这些方面，我们将现有的方法分解为模块，并对基于这些模块的重新配置方法的性能进行评估。根据基准数据集的实验结果，我们确定了两种有前景的构型: (i)将属性矩阵作为图卷积网络的输入; (ii)分层线性融合深度神经网络和图注意网络。同时发现复杂损失函数不能提高聚类性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Re-evaluation+of+Deep+Learning+Methods+for+Attributed+Graph+Clustering)|0|
|[Tackling Diverse Minorities in Imbalanced Classification](https://doi.org/10.1145/3583780.3615071)|KweiHerng Lai, Daochen Zha, Huiyuan Chen, Mangesh Bendre, Yuzhong Chen, Mahashweta Das, Hao Yang, Xia Hu|Rice University, Houston, TX, USA; Visa Research, PAlo Alto, CA, USA; Visa Research, Palo Alto, CA, USA|Imbalanced datasets are commonly observed in various real-world applications, presenting significant challenges in training classifiers. When working with large datasets, the imbalanced issue can be further exacerbated, making it exceptionally difficult to train classifiers effectively. To address the problem, over-sampling techniques have been developed to linearly interpolating data instances between minorities and their neighbors. However, in many real-world scenarios such as anomaly detection, minority instances are often dispersed diversely in the feature space rather than clustered together. Inspired by domain-agnostic data mix-up, we propose generating synthetic samples iteratively by mixing data samples from both minority and majority classes. It is non-trivial to develop such a framework, the challenges include source sample selection, mix-up strategy selection, and the coordination between the underlying model and mix-up strategies. To tackle these challenges, we formulate the problem of iterative data mix-up as a Markov decision process (MDP) that maps data attributes onto an augmentation strategy. To solve the MDP, we employ an actor-critic framework to adapt the discrete-continuous decision space. This framework is utilized to train a data augmentation policy and design a reward signal that explores classifier uncertainty and encourages performance improvement, irrespective of the classifier's convergence. We demonstrate the effectiveness of our proposed framework through extensive experiments conducted on seven publicly available benchmark datasets using three different types of classifiers. The results of these experiments showcase the potential and promise of our framework in addressing imbalanced datasets with diverse minorities.|不平衡数据集在各种实际应用中普遍存在，对分类器的训练提出了严峻的挑战。在处理大型数据集时，不平衡问题会进一步加剧，使得有效地训练分类器变得异常困难。为了解决这个问题，已经开发了过采样技术来线性插值少数民族和他们的邻居之间的数据实例。然而，在许多实际场景中，例如异常检测，少数实例通常分散在不同的特性空间中，而不是聚集在一起。受领域不可知数据混合的启发，我们提出通过混合来自少数和多数类的数据样本迭代生成合成样本。开发这样一个框架并非易事，其挑战包括源样本选择、混合策略选择以及底层模型与混合策略之间的协调。为了应对这些挑战，我们将迭代数据混淆的问题制定为一个马可夫决策过程(mDP) ，将数据属性映射到一个增强策略上。为了解决 MDP 问题，我们采用了一个行为者-批评框架来适应离散-连续决策空间。该框架用于训练数据增强策略和设计奖励信号，以探索分类器的不确定性，并鼓励性能的改善，无论分类器的收敛。我们通过使用三种不同类型的分类器对七个公开可用的基准数据集进行广泛的实验，证明了我们提出的框架的有效性。这些实验的结果展示了我们的框架在处理不同少数群体的不平衡数据集方面的潜力和希望。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tackling+Diverse+Minorities+in+Imbalanced+Classification)|0|
|[DuoGAT: Dual Time-oriented Graph Attention Networks for Accurate, Efficient and Explainable Anomaly Detection on Time-series](https://doi.org/10.1145/3583780.3614857)|Jongsoo Lee, Byeongtae Park, DongKyu Chae|Hanyang University, Seoul, Republic of Korea|Recently, Graph Neural Networks (GNNs) have achieved state-of-the-art performance on the multivariate time-series anomaly detection task by learning relationships between variables (sensors). However, they show limitations in capturing temporal dependencies due to lack of sufficient consideration on the characteristics of time to their graph structure. Several studies constructed a time-oriented graph, where each node represents a timestamp within a certain sliding window, to model temporal dependencies, but they failed to learn the trend of changes in time-series. This paper proposes Dual time-oriented Graph ATtention networks (DuoGAT) that resolves the aforementioned problems. Unlike previous work that uses the simple complete undirected structure for time-oriented graphs, our work models directed graphs with weighted edges that only connect from prior events to posterior events, and the edges that connect nearby events are given higher weights. In addition, another time-oriented graph is used to model time series stationary via differencing, which especially focuses on capturing the series of changes. Empirically, our method outperformed the existing state-of-the-art work with the highest F1-score for the four real-world dataset while maintaining low training cost. We also proposed a novel explanation method for anomaly detection using DuoGAT, which provides time-oriented reasoning via hierarchically tracking time points critical in a specific anomaly detection. Our code is available at: https://github.com/ByeongtaePark/DuoGAT|最近，图形神经网络(GNN)通过学习变量(传感器)之间的关系，在多变量时间序列异常检测任务中取得了最先进的性能。然而，由于缺乏对图结构时间特性的充分考虑，它们在捕获时间依赖性方面存在局限性。一些研究构建了一个面向时间的图表，其中每个节点代表一个特定滑动窗口中的时间戳，以模拟时间依赖，但他们未能了解时间序列的变化趋势。针对上述问题，本文提出了面向双时间的图注意网络(DuoGAT)。不同于以往的工作，使用简单的完全无向结构的时间导向图，我们的工作模型指导图的加权边，只连接从先前的事件到后续事件，并连接附近的事件的边被赋予更高的权重。此外，还利用另一种时间导向图通过差分方法对时间序列进行建模，重点捕捉时间序列的变化。经验上，我们的方法在保持低训练成本的同时，以四个真实世界数据集的最高 F1分数超过了现有的最先进的工作。我们还提出了一种使用 DuogAT 的新颖的异常检测解释方法，该方法通过分层跟踪特定异常检测中关键的时间点，提供面向时间的推理。我们的代码可以在以下 https://github.com/byeongtaepark/duogat 找到|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DuoGAT:+Dual+Time-oriented+Graph+Attention+Networks+for+Accurate,+Efficient+and+Explainable+Anomaly+Detection+on+Time-series)|0|
|[GUARD: Graph Universal Adversarial Defense](https://doi.org/10.1145/3583780.3614903)|Jintang Li, Jie Liao, Ruofan Wu, Liang Chen, Zibin Zheng, Jiawang Dan, Changhua Meng, Weiqiang Wang||Recently, graph convolutional networks (GCNs) have shown to be vulnerable to small adversarial perturbations, which becomes a severe threat and largely limits their applications in security-critical scenarios. To mitigate such a threat, considerable research efforts have been devoted to increasing the robustness of GCNs against adversarial attacks. However, current approaches for defense are typically designed for the whole graph and consider the global performance, posing challenges in protecting important local nodes from stronger adversarial targeted attacks. In this work, we present a simple yet effective method, named \textbf{\underline{G}}raph \textbf{\underline{U}}niversal \textbf{\underline{A}}dve\textbf{\underline{R}}sarial \textbf{\underline{D}}efense (GUARD). Unlike previous works, GUARD protects each individual node from attacks with a universal defensive patch, which is generated once and can be applied to any node (node-agnostic) in a graph. Extensive experiments on four benchmark datasets demonstrate that our method significantly improves robustness for several established GCNs against multiple adversarial attacks and outperforms existing adversarial defense methods by large margins. Our code is publicly available at https://github.com/EdisonLeeeee/GUARD.|最近，图卷积网络(GCNs)已被证明易受小的对抗性扰动的影响，这成为一个严重的威胁，并在很大程度上限制了它在安全关键场景中的应用。为了减轻这种威胁，已经进行了大量的研究工作，以提高全球网络对抗敌对攻击的能力。然而，目前的防御方法通常是为整个图设计的，并考虑到全局性能，在保护重要的本地节点免受更强的敌对目标攻击方面提出了挑战。在这项工作中，我们提出了一个简单而有效的方法，命名为 textbf {下划线{ G }} raph textbf {下划线{ U }}通用 textbf {下划线{ A }} dve textbf {下划线{ R }} sarial textbf {下划线{ D }防御(GUARD)。与以前的工作不同，GUARD 使用一个通用的防御补丁保护每个节点免受攻击，该补丁只生成一次，可以应用于图中的任何节点(节点不可知)。在四个基准数据集上的大量实验表明，我们的方法显著提高了几个已建立的 GCNs 对多个对手攻击的鲁棒性，并大大优于现有的对手防御方法。我们的代码可以在 https://github.com/edisonleeeee/guard 上公开获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GUARD:+Graph+Universal+Adversarial+Defense)|0|
|[Class-Specific Word Sense Aware Topic Modeling via Soft Orthogonalized Topics](https://doi.org/10.1145/3583780.3614809)|Wenbo Li, Yao Yang, Einoshin Suzuki|Zhejiang Laboratory, Hangzhou, China; Kyushu University, Fukuoka, Japan|We propose a word sense aware topic model for document classification based on soft orthogonalized topics. An essential problem for this task is to capture word senses related to classes, i.e., class-specific word senses. Traditional models mainly introduce semantic information of knowledge libraries for word sense discovery. However, this information may not align with the classification targets, because these targets are often subjective and task-related. We aim to model the class-specific word senses in topic space. The challenge is to optimize the class separability of the senses, i.e., obtaining sense vectors with (a) high intra-class and (b) low inter-class similarities. Most existing models predefine specific topics for each class to specify the class-specific sense vectors. We call them hard orthogonalization based methods. These methods can hardly achieve both (a) and (b) since they assume the conditional independence of topics to classes and inevitably lose topic information. To this problem, we propose soft orthogonalization for topics. Specifically, we reserve all the topics and introduce a group of class-specific weights for each word to handle the importance of topic dimensions to class separability. Besides, we detect and use highly class-specific words in each document to guide sense estimation. Our experiments on two standard datasets show that our proposal outperforms other state-of-the-art models in terms of accuracy of sense estimation, document classification, and topic modeling. In addition, our joint learning experiments with the pre-trained language model BERT showcased the best complementarity of our model in most cases compared to other topic models.|我们提出了一个基于软正交主题的词义感知主题文档分类模型。这个任务的一个基本问题是捕获与类相关的词义，也就是特定于类的词义。传统的模式主要是引入语义信息知识库来发现词义。但是，这些信息可能与分类目标不一致，因为这些目标通常是主观的和与任务相关的。我们的目标是在主题空间中建立类别特定的词义模型。挑战在于优化感官的类可分性，即获得具有(a)高的类内和(b)低的类间相似性的感官向量。大多数现有的模型为每个类预先定义特定的主题，以指定特定于类的感觉向量。我们称之为基于正交化的方法。这些方法很难同时实现(a)和(b)两个目标，因为它们承担了课程的主题条件独立，并且不可避免地丢失了主题信息。针对这个问题，我们建议对话题采用软正交化。具体来说，我们保留所有的主题，并为每个单词引入一组特定于类别的权重，以处理主题维度对类别可分性的重要性。此外，我们在每个文档中检测并使用高度类别特异性的词语来指导意义估计。我们在两个标准数据集上的实验表明，我们的方案在感觉估计、文档分类和主题建模的准确性方面优于其他最先进的模型。此外，我们的联合学习实验与预先训练的语言模型 BERT 显示了我们的模型在大多数情况下最好的互补性相比，其他主题模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Class-Specific+Word+Sense+Aware+Topic+Modeling+via+Soft+Orthogonalized+Topics)|0|
|[Relation-Aware Diffusion Model for Controllable Poster Layout Generation](https://doi.org/10.1145/3583780.3615028)|Fengheng Li, An Liu, Wei Feng, Honghe Zhu, Yaoyu Li, Zheng Zhang, Jingjing Lv, Xin Zhu, Junjie Shen, Zhangang Lin, Jingping Shao|Nankai University, Tianjin, China; JD, Beijing, China|Poster layout is a crucial aspect of poster design. Prior methods primarily focus on the correlation between visual content and graphic elements. However, a pleasant layout should also consider the relationship between visual and textual contents and the relationship between elements. In this study, we introduce a relation-aware diffusion model for poster layout generation that incorporates these two relationships in the generation process. Firstly, we devise a visual-textual relation-aware module that aligns the visual and textual representations across modalities, thereby enhancing the layout's efficacy in conveying textual information. Subsequently, we propose a geometry relation-aware module that learns the geometry relationship between elements by comprehensively considering contextual information. Additionally, the proposed method can generate diverse layouts based on user constraints. To advance research in this field, we have constructed a poster layout dataset named CGL-Dataset V2. Our proposed method outperforms state-of-the-art methods on CGL-Dataset V2. The data and code will be available at https://github.com/liuan0803/RADM.|海报布局是海报设计的一个重要方面。先前的方法主要集中在视觉内容和图形元素之间的相关性。然而，一个愉快的布局还应该考虑视觉和文本内容之间的关系以及元素之间的关系。在这项研究中，我们引入了一个关系感知的海报布局生成扩散模型，在生成过程中结合了这两个关系。首先，我们设计了一个视觉-文本关系感知模块，将视觉和文本表征跨模式对齐，从而提高布局在传递文本信息方面的效率。随后，我们提出了一个几何关系感知模块，通过综合考虑上下文信息来学习元素之间的几何关系。此外，该方法还可以根据用户约束生成不同的布局。为了推进这一领域的研究，我们构建了一个海报布局数据集 CGL-DatasetV2。我们提出的方法在 CGL-Dataset V2上优于最先进的方法。数据和代码将在 https://github.com/liuan0803/radm 公布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Relation-Aware+Diffusion+Model+for+Controllable+Poster+Layout+Generation)|0|
|[ACGAN-GNNExplainer: Auxiliary Conditional Generative Explainer for Graph Neural Networks](https://doi.org/10.1145/3583780.3614772)|Yiqiao Li, Jianlong Zhou, Yifei Dong, Niusha Shafiabady, Fang Chen|Charles Darwin University, Sydney, Australia; University of Technology Sydney, Sydney, Australia|Graph neural networks (GNNs) have proven their efficacy in a variety of real-world applications, but their underlying mechanisms remain a mystery. To address this challenge and enable reliable decision-making, many GNN explainers have been proposed in recent years. However, these methods often encounter limitations, including their dependence on specific instances, lack of generalizability to unseen graphs, producing potentially invalid explanations, and yielding inadequate fidelity. To overcome these limitations, we, in this paper, introduce the Auxiliary Classifier Generative Adversarial Network (ACGAN) into the field of GNN explanation and propose a new GNN explainer dubbed~\emph{ACGAN-GNNExplainer}. Our approach leverages a generator to produce explanations for the original input graphs while incorporating a discriminator to oversee the generation process, ensuring explanation fidelity and improving accuracy. Experimental evaluations conducted on both synthetic and real-world graph datasets demonstrate the superiority of our proposed method compared to other existing GNN explainers.|图形神经网络(GNN)已经证明了它们在各种现实应用中的有效性，但是它们的基本机制仍然是一个谜。为了应对这一挑战，并使可靠的决策，许多 GNN 解释者已提出近年来。然而，这些方法经常遇到限制，包括它们依赖于特定的实例，缺乏对看不见的图的普遍性，产生可能无效的解释，以及产生不足的保真度。为了克服这些局限性，本文将辅助分类器生成对抗网络(ACGAN)引入 GNN 解释领域，提出了一种新的 GNN 解释器，命名为 ~ emph { ACGAN-GNNExplainer }。我们的方法利用一个生成器为原始输入图生成解释，同时加入一个鉴别器来监督生成过程，确保解释的保真度和提高准确性。实验结果表明，与现有的 GNN 解释器相比，本文提出的方法具有明显的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ACGAN-GNNExplainer:+Auxiliary+Conditional+Generative+Explainer+for+Graph+Neural+Networks)|0|
|[REST: Drug-Drug Interaction Prediction via Reinforced Student-Teacher Curriculum Learning](https://doi.org/10.1145/3583780.3615033)|Xinhang Li, Zhaopeng Qiu, Xiangyu Zhao, Yong Zhang, Chunxiao Xing, Xian Wu|Tencent Jarvis Lab, Beijing, China; BOSS Zhipin, Beijing, China; Tsinghua University, Beijing, China; City University of Hong Kong, Hong Kong, Hong Kong|Accurate prediction of drug-drug interaction (DDI) is crucial to achieving effective decision-making in medical treatment for both doctors and patients. Recently, many deep learning based methods have been proposed to learn from drug-related features and conduct DDI prediction. These works have achieved promising results. However, the extreme imbalance of medical data poses a serious problem to DDI prediction, where a small fraction of DDI types occupy the majority training data. A straightforward way is to develop an appropriate policy to sample the data. Due to the high complexity and speciality of medical science, a dynamic learnable policy is required instead of a heuristic, uniform or static one. Therefore, we propose a REinforced Student-Teacher curriculum learning model (REST) for effective sampling to tackle this imbalance problem. Specifically, REST consists of two interactive parts, which are a heterogeneous graph neural network as the student and a reinforced sampler as the teacher. In each interaction, the teacher model takes action to sample an appropriate batch to train the student model according to the student model state while the cumulated improvement in performance of the student model is treated as the reward for policy gradient of the teacher model. The experimental results on two benchmarking datasets have demonstrated the significant effectiveness of our proposed model in DDI prediction, especially for the DDI types with low frequency.|准确预测药物相互作用(DDI)是实现医患双方有效决策的关键。近年来，人们提出了许多基于深度学习的方法来学习药物相关特征并进行 DDI 预测。这些工作取得了可喜的成果。然而，医学数据的极端不平衡性给 DDI 预测带来了严重的问题，其中一小部分 DDI 类型占据了大多数训练数据。一个直接的方法是开发一个适当的策略来抽样数据。由于医学科学的高度复杂性和特殊性，需要一个动态的可学习策略，而不是一个启发式的、统一的或静态的策略。因此，我们提出了一个强化的学生-教师课程学习模式(REST) ，以有效的抽样来解决这一不平衡问题。具体来说，REST 由两个交互部分组成，即作为学生的异构图形神经网络和作为教师的强化采样器。在每个交互过程中，教师模型根据学生模型的状态采取行动抽样适当的批次来训练学生模型，而学生模型的绩效的累积提高被视为对教师模型的政策梯度的奖励。在两个基准测试数据集上的实验结果表明，该模型在 DDI 预测中具有显著的效果，特别是对于低频率的 DDI 类型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=REST:+Drug-Drug+Interaction+Prediction+via+Reinforced+Student-Teacher+Curriculum+Learning)|0|
|[Simplifying Temporal Heterogeneous Network for Continuous-Time Link prediction](https://doi.org/10.1145/3583780.3615059)|Ce Li, Rongpei Hong, Xovee Xu, Goce Trajcevski, Fan Zhou|Iowa State University, Ames, IA, USA; University of Electronic Science and Technology of China & Kash Institute of Electronics and Information Industry, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China|Temporal heterogeneous networks (THNs) investigate the structural interactions and their evolution over time in graphs with multiple types of nodes or edges. Existing THNs describe evolving networks as a sequence of graph snapshots and adopt mechanisms from static heterogeneous networks to capture the spatial-temporal correlation. However, these works are confined to the discrete-time setting and the implementation of stacked mechanisms often introduces a high level of complexity, both conceptually and computationally. Here, we conduct comprehensive examinations and propose STHN, a simplifying THN for continuous-time link prediction. Concretely, to integrate continuous dynamics, we maintain a historical interaction memory for each node. A link encoder that incorporates two components - type encoding and relative time encoding - is introduced to encapsulate implicit heterogeneous characteristics of interaction and extract the most informative temporal information. We further propose to use a patching technique that assists with Transformer feature extractor to support the interaction sequence with long histories. Extensive experiments on three real-world datasets empirically demonstrate that STHN outperforms state-of-the-art methods with competitive task accuracy and predictive efficiency on both transductive and inductive settings.|时间异质网络(THN)研究具有多种节点或边的图的结构相互作用及其随时间的演化。现有的 THN 将演化网络描述为一系列图形快照，并采用静态异构网络的机制来捕获时空相关性。然而，这些工作仅限于离散时间设置和实现堆叠机制往往引入了高水平的复杂性，无论是在概念上和计算上。在这里，我们进行了全面的检验，并提出了一种简化的连续时间链路预测的 THN。具体地说，为了整合连续动态，我们为每个节点维护一个历史交互记忆。提出了一种结合类型编码和相对时间编码的链路编码器，用于封装隐式异构交互特性，提取信息量最大的时间信息。我们进一步建议使用补丁技术，协助变压器特征提取，以支持交互序列的长历史。在三个真实世界数据集上的大量实验表明，STHN 在传导性和归纳性设置上都优于最先进的方法，具有竞争性的任务准确性和预测效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Simplifying+Temporal+Heterogeneous+Network+for+Continuous-Time+Link+prediction)|0|
|[Heterogeneous Temporal Graph Neural Network Explainer](https://doi.org/10.1145/3583780.3614909)|Jiazheng Li, Chunhui Zhang, Chuxu Zhang|Brandeis University, Waltham, MA, USA|Graph Neural Networks (GNNs) have been a prominent research area and have been widely deployed in various high-stakes applications in recent years, leading to a growing demand for explanations. While existing explainer methods focus on explaining homogeneous and static GNNs, none of them have attempted to explain heterogeneous temporal GNNs. However, in practice, many real-world databases should be represented as heterogeneous temporal graphs (HTGs), which serve as the fundamental data structure for GNN backbone models in applications. To address this gap, in this paper, we propose HTGExplainer, a novel method for explaining heterogeneous temporal GNNs by considering temporal dependencies and preserving heterogeneity when generating subgraphs as explanations. HTGExplainer employs a deep neural network to re-parameterize the generation process of explanations and incorporates effective heterogeneous and temporal edge embeddings to capture informative semantics used for generating explanatory subgraphs. Extensive experiments are conducted on multiple HTG datasets constructed from real-world scenarios, and the results demonstrate the superior performance of HTGExplainer compared to state-of-the-art baselines.|图形神经网络(GNN)近年来已成为一个突出的研究领域，并被广泛应用于各种高风险的应用领域，导致对其解释的需求日益增长。虽然现有的解释方法集中于解释同质和静态 GNN，但没有一种方法尝试解释异质时态 GNN。然而，在实际应用中，许多现实世界的数据库应该表示为异构时态图(HTGs) ，它们作为 GNN 骨干网模型在应用中的基本数据结构。为了解决这一问题，本文提出了一种新的解释异构时态 GNN 的方法—— HTGExplainer，该方法在生成子图时考虑了时态依赖性并保留了异构性。HTGExplainer 使用深层神经网络重新参数化解释的生成过程，并结合有效的异构和时间边缘嵌入来捕获用于生成解释子图的信息语义。在实际场景构建的多个 HTG 数据集上进行了广泛的实验，结果表明 HTGExplainer 的性能优于最先进的基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Heterogeneous+Temporal+Graph+Neural+Network+Explainer)|0|
|[Harnessing the Power of Pre-trained Vision-Language Models for Efficient Medical Report Generation](https://doi.org/10.1145/3583780.3614961)|Qi Li|Tsinghua University, Shenzhen, China|Medical images are commonly used in clinical practice. But the need for diagnosis and reporting from image-based examinations far excels the current medical capacity. Automatic Medical Report Generation (MRG) can help to ease the burden of radiologists. Vision-Language Pre-training (VLP) has received tremendous success on various tasks, therefore it is naturally expected that MRG can harvest from this rapid advancement. However, directly applying existing VLP models in the medical domain is impracticable due to their data-hungry nature, the need for aligning different modalities, prohibitive training time, exorbitant hardware barrier, and the challenge of open-ended text generation. To address these problems, we propose MedEPT, a parameter-efficient approach for MRG that can utilize ever-ignored image-only datasets. It employs parameter-efficient tuning (PET) for VLP adaption to mitigate inefficiency in fine-tuning time and hardware. MedEPT also employs MRGPID to augment and expand adaption datasets by synthesizing meaningful text for image-only datasets. We perform a systematic evaluation of our method. Empirical results show that we obtain a better performance than the state-of-the-art method while using less than 10% trainable parameters and not more than 30% training time than ever before.|医学影像在临床实践中有着广泛的应用。但是，通过图像检查进行诊断和报告的需要远远超过了目前的医疗能力。自动医疗报告生成(MRG)有助于减轻放射科医师的负担。视觉语言预训练(VLP)已经在各种任务中取得了巨大的成功，因此 MRG 能够从这种快速发展中获得收获是很自然的事情。然而，直接应用现有的 VLP 模型在医学领域是不切实际的，因为它们的数据饥饿的性质，需要调整不同的模式，禁止训练时间，过高的硬件障碍，以及开放式文本生成的挑战。为了解决这些问题，我们提出了 MedEPT，一种 MRG 的参数效率方法，它可以利用被忽略的仅有图像的数据集。它采用参数有效调整(PET)的 VLP 自适应，以减少微调时间和硬件效率低下。MedEPT 还使用 MRGPID 通过为纯图像数据集合成有意义的文本来增强和扩展自适应数据集。我们对我们的方法进行系统的评估。实验结果表明，在使用可训练参数少于10% 、训练时间不超过30% 的情况下，该方法具有比现有方法更好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Harnessing+the+Power+of+Pre-trained+Vision-Language+Models+for+Efficient+Medical+Report+Generation)|0|
|[Contrastive Representation Learning Based on Multiple Node-centered Subgraphs](https://doi.org/10.1145/3583780.3614825)|Dong Li, Wenjun Wang, Minglai Shao, Chen Zhao|Baylor University, Waco, TX, USA; Tianjin University, Tianjin, China|As the basic element of graph-structured data, node has been recognized as the main object of study in graph representation learning. A single node intuitively has multiple node-centered subgraphs from the whole graph (e.g., one person in a social network has multiple social circles based on his different relationships). We study this intuition under the framework of graph contrastive learning, and propose a multiple node-centered subgraphs contrastive representation learning method to learn node representation on graphs in a self-supervised way. Specifically, we carefully design a series of node-centered regional subgraphs of the central node. Then, the mutual information between different subgraphs of the same node is maximized by contrastive loss. Experiments on various real-world datasets and different downstream tasks demonstrate that our model has achieved state-of-the-art results.|节点作为图结构化数据的基本元素，已经成为图表示学习的主要研究对象。一个节点直观地拥有来自整个图的多个以节点为中心的子图(例如，一个社交网络中的一个人根据其不同的关系拥有多个社交圈)。本文在图的对比学习框架下研究了这种直觉，提出了一种以多个节点为中心的子图对比表示学习方法，用于自监督的方法学习图上的节点表示。具体地说，我们精心设计了一系列以节点为中心的中心节点区域子图。然后，利用对比损失最大化同一节点的不同子图之间的互信息。在各种真实世界数据集和不同的下游任务上的实验表明，我们的模型已经取得了最先进的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Representation+Learning+Based+on+Multiple+Node-centered+Subgraphs)|0|
|[Multi-Order Relations Hyperbolic Fusion for Heterogeneous Graphs](https://doi.org/10.1145/3583780.3614979)|Junlin Li, Yueheng Sun, Minglai Shao|College of Intelligence and Computing, Tianjin University, Tianjin, China; School of New Media and Communication, Tianjin University, Tianjin, China|Heterogeneous graphs with multiple node and edge types are prevalent in real-world scenarios. However, most methods use meta-paths on the original graph structure to learn information in heterogeneous graphs, and these methods only consider pairwise relations and rely on meta-paths. In this paper, we use simplicial complexes to extract higher-order relations containing multiple nodes from heterogeneous graphs. We also discover power-law structures in both the heterogeneous graph and the extracted simplicial complex. Thus, we propose the Simplicial Hyperbolic Attention Network (SHAN), a graph neural network for heterogeneous graphs. SHAN extracts simplicial complexes and the original graph structure from the heterogeneous graph to represent multi-order relations between nodes. Next, SHAN uses hyperbolic multi-perspective attention to learn the importance of different neighbors and relations in hyperbolic space. Finally, SHAN integrates multi-order relations to obtain a more comprehensive node representation. We conducted extensive experiments to verify the effectiveness of SHAN and the results of node classification experiments on three publicly available heterogeneous graph datasets demonstrate that SHAN outperforms representative baseline models.|具有多个节点和边类型的异构图在现实世界中普遍存在。然而，大多数方法在原始图结构上使用元路径来学习异构图中的信息，这些方法只考虑成对关系，依赖于元路径。本文利用单纯复形从异质图中提取包含多个节点的高阶关系。我们还发现幂律结构的异质图和提取的单纯复形。因此，我们提出了单纯双曲注意网络(SHAN) ，一个适用于异构图的图神经网络。SHAN 从异构图中提取单纯复形和原始图结构来表示节点之间的多阶关系。接下来，SHAN 使用双曲线多视角注意力来学习不同邻居和关系在双曲空间中的重要性。最后，SHAN 整合了多阶关系，得到了更全面的节点表示。为了验证 SHAN 算法的有效性，我们进行了大量的实验，并在三个公开的异构图形数据集上进行了节点分类实验，实验结果表明，SHAN 算法的性能优于典型的基线模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Order+Relations+Hyperbolic+Fusion+for+Heterogeneous+Graphs)|0|
|[SAILOR: Structural Augmentation Based Tail Node Representation Learning](https://doi.org/10.1145/3583780.3615045)|Jie Liao, Jintang Li, Liang Chen, Bingzhe Wu, Yatao Bian, Zibin Zheng|Tecent AI Lab, Shenzhen, China; Sun Yat-sen University, Guangzhou, China; Tencent AI Lab, Shenzhen, China|Graph Neural Networks (GNNs) have achieved state-of-the-art performance in representation learning for graphs recently. However, the effectiveness of GNNs, which capitalize on the key operation of message propagation, highly depends on the quality of the topology structure. Most of the graphs in real-world scenarios follow a long-tailed distribution on their node degrees, that is, a vast majority of the nodes in the graph are tail nodes with only a few connected edges. GNNs produce inferior node representations for tail nodes since they lack structural information. In the pursuit of promoting the expressiveness of GNNs for tail nodes, we explore how the deficiency of structural information deteriorates the performance of tail nodes and propose a general Structural Augmentation based taIL nOde Representation learning framework, dubbed as SAILOR, which can jointly learn to augment the graph structure and extract more informative representations for tail nodes. Extensive experiments on public benchmark datasets demonstrate that SAILOR can significantly improve the tail node representations and outperform the state-of-the-art baselines.|近年来，图神经网络在图表示学习方面取得了较好的效果。然而，利用消息传播关键操作的 GNN 的有效性在很大程度上取决于拓扑结构的质量。现实场景中的大多数图在节点度上遵循长尾分布，即图中的绝大多数节点都是尾节点，只有少数连接边。GNN 由于缺乏结构信息，对尾节点产生较差的节点表示。为了提高 GNN 对尾节点的表达能力，研究了结构信息不足对尾节点表达能力的影响，提出了一种通用的基于结构增强的尾节点表示学习框架 SAILOR。在公共基准数据集上的大量实验表明，SAILOR 能够显著改善尾节点的表示，并优于最先进的基准线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SAILOR:+Structural+Augmentation+Based+Tail+Node+Representation+Learning)|0|
|[Adaptation Speed Analysis for Fairness-aware Causal Models](https://doi.org/10.1145/3583780.3614774)|Yujie Lin, Chen Zhao, Minglai Shao, Xujiang Zhao, Haifeng Chen||For example, in machine translation tasks, to achieve bidirectional translation between two languages, the source corpus is often used as the target corpus, which involves the training of two models with opposite directions. The question of which one can adapt most quickly to a domain shift is of significant importance in many fields. Specifically, consider an original distribution p that changes due to an unknown intervention, resulting in a modified distribution p*. In aligning p with p*, several factors can affect the adaptation rate, including the causal dependencies between variables in p. In real-life scenarios, however, we have to consider the fairness of the training process, and it is particularly crucial to involve a sensitive variable (bias) present between a cause and an effect variable. To explore this scenario, we examine a simple structural causal model (SCM) with a cause-bias-effect structure, where variable A acts as a sensitive variable between cause (X) and effect (Y). The two models, respectively, exhibit consistent and contrary cause-effect directions in the cause-bias-effect SCM. After conducting unknown interventions on variables within the SCM, we can simulate some kinds of domain shifts for analysis. We then compare the adaptation speeds of two models across four shift scenarios. Additionally, we prove the connection between the adaptation speeds of the two models across all interventions.|例如，在机器翻译任务中，为了实现两种语言之间的双向翻译，常常使用源语料库作为目标语料库，这涉及到训练两种方向相反的模型。在许多领域中，哪一个人能够最快地适应领域转移的问题是非常重要的。具体来说，考虑一个原始分布 p，该分布 p 由于未知的干预而发生变化，从而导致修改分布 p * 。在 p 与 p * 对齐时，有几个因素可以影响适应率，包括 p 中变量之间的因果依赖关系。然而，在现实生活中，我们必须考虑训练过程的公平性，尤其是涉及到一个敏感的变量(偏见)之间的原因和结果变量。为了探索这种情况，我们研究了一个简单的结构性因果模型(SCM) ，其中变量 A 作为原因(X)和结果(Y)之间的敏感变量。这两个模型在因果-偏倚-效应供应链管理中分别表现出一致和相反的因果方向。在对供应链管理中的变量进行未知的干预之后，我们可以模拟某些领域的移位进行分析。然后我们比较了两个模型在四个移位情景下的适应速度。此外，我们证明了两个模型在所有干预措施中的适应速度之间的联系。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adaptation+Speed+Analysis+for+Fairness-aware+Causal+Models)|0|
|[On the Thresholding Strategy for Infrequent Labels in Multi-label Classification](https://doi.org/10.1145/3583780.3614996)|YuJen Lin, ChihJen Lin|National Taiwan University, Taipei, Taiwan Roc; National Taiwan University & Mohamed bin Zayed University of Artificial Intelligence, Taipei, Taiwan Roc|In multi-label classification, the imbalance between labels is often a concern. For a label that seldom occurs, the default threshold used to generate binarized predictions of that label is usually sub-optimal. However, directly tuning the threshold to optimize F-measure has been observed to overfit easily. In this work, we explain why this overfitting occurs. Then, we analyze the FBR heuristic, a previous technique proposed to address the overfitting issue. We explain its success but also point out some problems unobserved before. Then, we first propose a variant of the FBR heuristic that not only fixes the problems but is also more justifiable. Second, we propose a new technique based on smoothing the F-measure when tuning the threshold. We theoretically prove that, with proper parameters, smoothing results in desirable properties of the tuned threshold. Based on the idea of smoothing, we then propose jointly optimizing micro-F and macro-F as a lightweight alternative free from extra hyperparameters. Our methods are empirically evaluated on text and node classification datasets. The results show that our methods consistently outperform the FBR heuristic.|在多标签分类中，标签之间的不平衡往往是一个值得关注的问题。对于很少出现的标签，用于生成该标签的二进制预测的默认阈值通常是次优的。然而，直接调整阈值以优化 F 测度已被观察到很容易过拟合。在这项工作中，我们解释了为什么会发生这种过拟合。然后，我们分析了 FBR 启发式算法，这是一种先前提出的解决过拟合问题的技术。我们解释了它的成功，但也指出了一些以前没有注意到的问题。然后，我们首先提出了 FBR 启发式的一个变体，它不仅解决了问题，而且更加合理。其次，提出了一种基于平滑 F- 测度的阈值调整新方法。我们从理论上证明，在适当的参数下，光滑化可以得到理想的调谐阈值特性。基于平滑的思想，我们提出联合优化微 F 和宏 F 作为一个轻量级的替代方案，不需要额外的超参数。在文本和节点分类数据集上对我们的方法进行了实证评估。结果表明，我们的方法始终优于 FBR 启发式。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+the+Thresholding+Strategy+for+Infrequent+Labels+in+Multi-label+Classification)|0|
|[Cross-city Few-Shot Traffic Forecasting via Traffic Pattern Bank](https://doi.org/10.1145/3583780.3614829)|Zhanyu Liu, Guanjie Zheng, Yanwei Yu|Shanghai Jiao Tong University, Shanghai, China; Ocean University of China, Qingdao, China|Traffic forecasting is a critical service in Intelligent Transportation Systems (ITS). Utilizing deep models to tackle this task relies heavily on data from traffic sensors or vehicle devices, while some cities might lack device support and thus have few available data. So, it is necessary to learn from data-rich cities and transfer the knowledge to data-scarce cities in order to improve the performance of traffic forecasting. To address this problem, we propose a cross-city few-shot traffic forecasting framework via Traffic Pattern Bank (TPB) due to that the traffic patterns are similar across cities. TPB utilizes a pre-trained traffic patch encoder to project raw traffic data from data-rich cities into high-dimensional space, from which a traffic pattern bank is generated through clustering. Then, the traffic data of the data-scarce city could query the traffic pattern bank and explicit relations between them are constructed. The metaknowledge is aggregated based on these relations and an adjacency matrix is constructed to guide a downstream spatial-temporal model in forecasting future traffic. The frequently used meta-training framework Reptile is adapted to find a better initial parameter for the learnable modules. Experiments on real-world traffic datasets show that TPB outperforms existing methods and demonstrates the effectiveness of our approach in cross-city few-shot traffic forecasting.|交通预测是智能交通系统(ITS)中的一项重要业务。利用深度模型来解决这个问题主要依赖于来自交通传感器或车辆设备的数据，而一些城市可能缺乏设备支持，因此可用的数据很少。因此，有必要向数据丰富的城市学习，向数据稀缺的城市转移知识，以提高交通预测的性能。针对这一问题，针对城市间交通模式相似的特点，提出了一种基于交通模式库(TPB)的跨城市少镜头交通预测框架。TPB 利用预先训练好的交通补丁编码器将数据丰富的城市的原始交通数据投影到高维空间中，通过聚类生成交通模式库。然后，利用数据稀缺城市的交通数据对交通模式库进行查询，建立二者之间的显式关系。基于这些关系，元知识被聚合起来，并构建一个邻接矩阵来指导下游的时空模型来预测未来的交通。为了给可学习模块提供一个更好的初始参数，对经常使用的元训练框架爬行动物进行了改进。在实际交通数据集上的实验结果表明，TPB 方法的性能优于现有的方法，并证明了该方法在城市间少镜头交通预测中的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cross-city+Few-Shot+Traffic+Forecasting+via+Traffic+Pattern+Bank)|0|
|[GranCATs: Cross-Lingual Enhancement through Granularity-Specific Contrastive Adapters](https://doi.org/10.1145/3583780.3614896)|Meizhen Liu, Jiakai He, Xu Guo, Jianye Chen, Siu Cheung Hui, Fengyu Zhou|Nanyang Technological University, Singapore, China; Shandong University, Jinan city, China; Shandong University, Jinan, China; Nanyang Technological University, Singapore, Singapore|Multilingual language models (MLLMs) have demonstrated remarkable success in various cross-lingual downstream tasks, facilitating the transfer of knowledge across numerous languages, whereas this transfer is not universally effective. Our study reveals that while existing MLLMs like mBERT can capturephrase-level alignments across the language families, they struggle to effectively capturesentence-level andparagraph-level alignments. To address this limitation, we propose GranCATs, Granularity-specific Contrastive AdapTers. We collect a new dataset that observes each sample at three distinct levels of granularity and employ contrastive learning as a pre-training task to train GranCATs on this dataset. Our objective is to enhance MLLMs' adaptation to a broader range of cross-lingual tasks by equipping them with improved capabilities to capture global information at different levels of granularity. Extensive experiments show that MLLMs with GranCATs yield significant performance advancements across various language tasks with different text granularities, including entity alignment, relation extraction, sentence classification and retrieval, and question-answering. These results validate the effectiveness of our proposed GranCATs in enhancing cross-lingual alignments across various text granularities and effectively transferring this knowledge to downstream tasks.|多语言语言模型(MLLM)在各种跨语言的下游任务中取得了显著的成功，促进了跨多种语言的知识转移，然而这种转移并非普遍有效。我们的研究表明，现有的 MLLM，如 mBERT，可以捕捉跨语系的短语水平对齐，他们努力有效捕捉句子水平和段落水平对齐。为了解决这个限制，我们提出了 GranCATs，特定于粒度的对比适配器。我们收集了一个新的数据集，在三个不同的粒度级别上观察每个样本，并将对比学习作为一个预训练任务来训练这个数据集上的 GranCATs。我们的目标是提高 MLLM 的适应性，使其能够更好地捕获不同粒度级别的全球信息，从而适应更广泛的跨语言任务。大量实验表明，使用 GranCATs 的 MLLM 在不同文本粒度的不同语言任务中，包括实体对齐、关系提取、句子分类和检索以及问答，都取得了显著的性能提升。这些结果验证了我们提出的 GranCATs 在增强不同文本粒度之间的跨语言对齐以及有效地将这些知识传递给下游任务方面的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GranCATs:+Cross-Lingual+Enhancement+through+Granularity-Specific+Contrastive+Adapters)|0|
|[Quantifying the Effectiveness of Advertising: A Bootstrap Proportion Test for Brand Lift Testing](https://doi.org/10.1145/3583780.3615021)|Wanjun Liu, Xiufan Yu, Jialiang Mao, Xiaoxu Wu, Justin Dyer|University of Notre Dame, Notre Dame, IN, USA; LinkedIn Corporation, Sunnyvale, CA, USA|Brand Lift test is a widely deployed statistical tool for measuring the effectiveness of online advertisements on brand perception such as ad recall, brand familiarity and favorability. By formulating the problem of interest into a two-sample test on the binomial proportions from the control group (p_0) and the treatment group (p_1), Brand Lift test evaluates ads impact based on the statistical significance of test results. Traditional approaches construct the test statistics based on the absolute difference between the two observed proportions, a.k.a, absolute lift. In this work, we propose a new bootstrap test based on the percentage difference between the two observed proportions, i.e., relative lift. We provide rigorous theoretical guarantees on the asymptotic validity of the proposed relative-lift-based test. Our numerical studies suggest that the relative-lift-based test requires less stringent conditions than the absolute-lift-based test for controlling the type-I error rate. Interestingly, we also prove that the relative-lift-based test is more powerful than the absolute-lift-based test when the alternative is positive (i.e., p1 - p0 > 0), but less powerful when the alternative is negative (i.e., p1 - p0 < 0). The empirical performance of the proposed test is demonstrated by extensive simulation studies, an application to a publicly available A/B testing dataset from advertising, and real datasets collected from the Brand Lift Testing platform at LinkedIn.|品牌提升测试(Brand Lift test)是一种广泛应用的统计工具，用于测量在线广告对品牌认知的有效性，如广告回忆、品牌熟悉度和好感度。通过对对照组(p _ 0)和治疗组(p _ 1)的二项式比例的双样本检验，Brand Lift 检验基于检验结果的统计显著性来评估广告的影响。传统的方法建立测试统计基于两个观察比例之间的绝对差异，即绝对提升。在这项工作中，我们提出了一个新的自举测试基于两个观察比例之间的百分比差异，即相对提升。我们提供了严格的理论保证，渐近有效的相对提升为基础的检验。我们的数值研究表明，为了控制 I 型错误率，基于相对升力的测试比基于绝对升力的测试要求的条件要宽松。有趣的是，我们还证明，当替代方案为阳性(即 p1-p0 > 0)时，基于相对提升的测试比基于绝对提升的测试更强大，但是当替代方案为阴性(即 p1-p0 < 0)时则不那么强大。广泛的模拟研究，广告中公开的 A/B 测试数据集的应用，以及从 LinkedIn 的 Brand Lift 测试平台收集的真实数据集，都证明了该测试的经验性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quantifying+the+Effectiveness+of+Advertising:+A+Bootstrap+Proportion+Test+for+Brand+Lift+Testing)|0|
|[BRep-BERT: Pre-training Boundary Representation BERT with Sub-graph Node Contrastive Learning](https://doi.org/10.1145/3583780.3614795)|Yunzhong Lou, Xueyang Li, Haotian Chen, Xiangdong Zhou|Fudan University, Shanghai, China|Obtaining effective entity feature representations is crucial in the field of Boundary Representation (B-Rep), a key parametric representation method in Computer-Aided Design (CAD). However, the lack of labeled large-scale database and the scarcity of task-specific label sets pose significant challenges. To address these problems, we propose an innovative unsupervised neural network approach called BRep-BERT, which extends the concept of BERT to the B-Rep domain. Specifically, we utilize Graph Neural Network (GNN) Tokenizer to generate discrete entity labels with geometric and structural semantic information. We construct new entity representation sequences based on the structural relationships and pre-train the model through the Masked Entity Modeling (MEM) task. To address the attention sparsity issue in large-scale geometric models, we incorporate graph structure information and learnable relative position encoding into the attention module to optimize feature updates. Additionally, we employ geometric sub-graphs and multi-level contrastive learning techniques to enhance the model's ability to learn regional features. Comparisons with previous methods demonstrate that BRep-BERT achieves the state-of-the-art performance on both full-data training and few-shot learning tasks across multiple B-Rep datasets. Particularly, BRep-BERT outperforms previous methods significantly in the few-shot learning scenarios. Comprehensive experiments demonstrate the substantial advantages and potential of BRep-BERT in handling B-Rep data representation. Code will be released at https://github.com/louyz1026/Brep_Bert.|获得有效的实体特征表示在边界表示领域(B-Rep)是至关重要的，这是计算机辅助设计领域(CAD)中一种关键的参数表示方法。然而，缺乏大规模的标签数据库和缺乏特定任务的标签集构成了重大的挑战。为了解决这些问题，我们提出了一种新的无监督神经网络方法 BRep-BERT，它将 BERT 的概念扩展到了 B-Rep 域。具体来说，我们利用图形神经网络(GNN)标记器生成具有几何和结构语义信息的离散实体标签。我们基于结构关系构造新的实体表示序列，并通过掩模实体建模(MEM)任务对模型进行预训练。为了解决大规模几何模型中的注意稀疏问题，将图结构信息和可学习的相对位置编码结合到注意模块中，优化特征更新。此外，采用几何子图和多层次对比学习技术，提高了模型学习区域特征的能力。与以往的方法比较表明，BRep-BERT 在跨多个 B-Rep 数据集的全数据训练和少镜头学习任务中都取得了最好的性能。特别是，BRep-BERT 在少镜头学习场景中的性能明显优于以前的方法。综合实验表明，BRep-BERT 在处理 B-Rep 数据表示方面具有很大的优势和潜力。密码将在 https://github.com/louyz1026/brep_bert 公布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BRep-BERT:+Pre-training+Boundary+Representation+BERT+with+Sub-graph+Node+Contrastive+Learning)|0|
|[Forward Creation, Reverse Selection: Achieving Highly Pertinent Multimodal Responses in Dialogue Contexts](https://doi.org/10.1145/3583780.3614888)|Ge Luo, Manman Zhang, Yuchen Ma, Sheng Li, Zhenxing Qian, Xinpeng Zhang|Fudan University, Shanghai, China|Multimodal Dialogue agents are often required to respond to conversation history using both textual and visual content. Even though current dialogue studies predominantly strive to generate natural texts or images, they fall short in considering the relevance of multimodal responses within a dialogue context, consequently confining agents from making prudent choices based on multiple alternatives and their associated relevance scores for decision-making. In this paper, we present a bidirectional multimodal dialogue framework that skillfully combines the forward generation of multiple text and image response candidates with reverse selection guided by relevance scores evaluated on dialogue context, facilitating agents in selecting the most suitable multimodal responses. Specifically, the forward generation aspect of our framework leverages a stage-wise approach, first producing textual replies and composite visual descriptions from the dialogue context, followed by the generation of visual responses aligned with the descriptions. In the reverse selection process, visual responses are translated into tangible descriptive texts that, in conjunction with textual responses, are inversely tied back to the dialogue context for relevance assessment, assigning a reference score to each multimodal response candidate to assist the intelligent agent in making informed decisions. Experimental outcomes demonstrate that our proposed bidirectional dialogue response framework markedly elevates performance in both automatic and human evaluations, yielding a range of contextually fitting multimodal responses for selection.|多模式对话代理经常需要使用文本和视觉内容来响应会话历史。尽管目前的对话研究主要致力于产生自然的文本或图像，但它们在对话背景下考虑多式联运反应的相关性方面存在不足，从而限制了行为体根据多种备选方案及其相关的决策相关性得分作出谨慎的选择。本文提出了一个双向多模式对话框架，该框架巧妙地将多个文本和图像响应候选者的前向生成与在对话背景下评估的相关性分数指导下的反向选择相结合，促进代理人选择最合适的多模式响应。具体来说，我们框架的前向生成方面采用了分阶段的方法，首先从对话上下文生成文本回复和组合视觉描述，然后生成与描述相一致的视觉回复。在反向选择过程中，视觉反应被转化为有形的描述性文本，与文字反应一起，与相关性评估的对话背景成反比，为每个多式联运反应候选人指定一个参考评分，以协助智能代理人作出知情决定。实验结果表明，我们提出的双向对话响应框架显着提高了自动和人工评估的绩效，产生了一系列符合上下文的多模式选择响应。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Forward+Creation,+Reverse+Selection:+Achieving+Highly+Pertinent+Multimodal+Responses+in+Dialogue+Contexts)|0|
|[Context-Aware Prompt for Generation-based Event Argument Extraction with Diffusion Models](https://doi.org/10.1145/3583780.3614820)|Lei Luo, Yajing Xu|Beijing University of Posts and Telecommunications, Beijing, China|Event argument extraction (EAE) has attracted increasing attention via generation-based methods. However, most existing works tend to independently extract arguments for each role, ignoring the correlation between different arguments, especially in long contexts. Motivated by these observations and the high-quality generation results of recent diffusion models, we propose an effective model called PGAD (Context-Aware Prompt for Generation-based EAE with Diffusion models) for both sentence-level and document-level EAE. In PGAD, a text diffusion model is designed to generate diverse context-aware prompt representations in conjunction with a series of random Gaussian noise. Firstly, cross-attention is employed between the designed prompt and input context within the text diffusion model in order to generate the context-aware prompt. Through this interaction, the context-aware prompt is able to capture multiple role-specific argument span queriers. Secondly, the context-aware prompt is aligned with the context to generate event arguments by joint optimization. Extensive experiments on three publicly available EAE datasets demonstrate the superiority of our proposed PGAD model over existing approaches.|事件参数提取(EAE)通过基于生成的方法得到了越来越多的关注。然而，大多数现有的作品倾向于为每个角色独立提取论点，忽略了不同论点之间的相关性，特别是在较长的上下文中。基于这些观察结果和最近扩散模型的高质量生成结果，我们提出了一个有效的模型 PGAD (Context-Aware Prompt for Generation-based EAE with Disversation model)用于句子级和文档级 EAE。在 PGAD 中，文本扩散模型被设计用来产生不同的上下文感知的提示表示和一系列随机高斯噪声。首先，在文本扩散模型中，在设计的提示语和输入语之间引入交叉注意，生成感知上下文的提示语。通过这种交互，上下文感知提示符能够捕获多个特定于角色的参数 span 查询器。其次，将上下文感知提示符与上下文对齐，通过联合优化生成事件参数。在三个公开的 EAE 数据集上的大量实验证明了我们提出的 PGAD 模型优于现有的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Context-Aware+Prompt+for+Generation-based+Event+Argument+Extraction+with+Diffusion+Models)|0|
|[Multi-scale Graph Pooling Approach with Adaptive Key Subgraph for Graph Representations](https://doi.org/10.1145/3583780.3614981)|Yiqin Lv, Zhiliang Tian, Zheng Xie, Yiping Song|National University of Defense Technology, China, China|The recent progress in graph representation learning boosts the development of many graph classification tasks, such as protein classification and social network classification. One of the mainstream approaches for graph representation learning is the hierarchical pooling method. It learns the graph representation by gradually reducing the scale of the graph, so it can be easily adapted to large-scale graphs. However, existing graph pooling methods discard the original graph structure during downsizing the graph, resulting in a lack of graph topological structure. In this paper, we propose a multi-scale graph neural network (MSGNN) model that not only retains the topological information of the graph but also maintains the key-subgraph for better interpretability. MSGNN gradually discards the unimportant nodes and retains the important subgraph structure during the iteration. The key subgraphs are first chosen by experience and then adaptively evolved to tailor specific graph structures for downstream tasks. The extensive experiments on seven datasets show that MSGNN improves the SOTA performance on graph classification and better retains key subgraphs.|图表示学习的最新进展促进了许多图分类任务的发展，如蛋白质分类和社会网络分类。图表示学习的主流方法之一是层次化池方法。它通过逐渐缩小图的尺度来学习图的表示，因此可以很容易地适应大尺度的图。然而，现有的图池方法在缩小图的尺寸时会丢弃原有的图结构，从而导致图拓扑结构的缺失。本文提出了一种多尺度图神经网络(MSGNN)模型，该模型不仅保留了图的拓扑信息，而且保留了关键子图，从而提高了图的可解释性。在迭代过程中，MSGNN 逐渐丢弃不重要的节点，保留重要的子图结构。首先根据经验选择关键子图，然后自适应地进化，为下游任务裁剪特定的图结构。通过对7个数据集的大量实验表明，MSGNN 提高了 SOTA 在图分类方面的性能，并且能够更好地保留关键子图。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-scale+Graph+Pooling+Approach+with+Adaptive+Key+Subgraph+for+Graph+Representations)|0|
|[Rethinking Sensors Modeling: Hierarchical Information Enhanced Traffic Forecasting](https://doi.org/10.1145/3583780.3614910)|Qian Ma, Zijian Zhang, Xiangyu Zhao, Haoliang Li, Hongwei Zhao, Yiqi Wang, Zitao Liu, Wanyu Wang|Jinan University, Guangzhou, China; Michigan State University, Michigan , MI, USA; City University of Hong Kong, Hong Kong, Hong Kong; Jilin University, Changchun, China|With the acceleration of urbanization, traffic forecasting has become an essential role in smart city construction. In the context of spatio-temporal prediction, the key lies in how to model the dependencies of sensors. However, existing works basically only consider the micro relationships between sensors, where the sensors are treated equally, and their macroscopic dependencies are neglected. In this paper, we argue to rethink the sensor's dependency modeling from two hierarchies: regional and global perspectives. Particularly, we merge original sensors with high intra-region correlation as a region node to preserve the inter-region dependency. Then, we generate representative and common spatio-temporal patterns as global nodes to reflect a global dependency between sensors and provide auxiliary information for spatio-temporal dependency learning. In pursuit of the generality and reality of node representations, we incorporate a Meta GCN to calibrate the regional and global nodes in the physical data space. Furthermore, we devise the cross-hierarchy graph convolution to propagate information from different hierarchies. In a nutshell, we propose a Hierarchical Information Enhanced Spatio-Temporal prediction method, HIEST, to create and utilize the regional dependency and common spatio-temporal patterns. Extensive experiments have verified the leading performance of our HIEST against state-of-the-art baselines. We publicize the code to ease reproducibility.|随着城市化进程的加快，交通预测已经成为智能城市建设的重要内容。在时空预测方面，关键在于如何对传感器的依赖关系进行建模。然而，现有的工作基本上只考虑传感器之间的微观关系，其中传感器被平等对待，它们的宏观依赖性被忽略。本文从区域和全局两个层次对传感器的依赖性建模进行了反思。特别地，我们将具有高区域内相关性的原始传感器合并为区域节点，以保持区域间的相关性。然后，我们生成具有代表性和共性的时空模式作为全局节点，以反映传感器之间的全局依赖关系，并为时空依赖学习提供辅助信息。为了追求节点表示的通用性和真实性，我们引入了一个元 GCN 来标定物理数据空间中的区域和全局节点。此外，我们还设计了跨层次图卷积来传播来自不同层次的信息。简而言之，我们提出了一种分层信息增强的时空预测方法，HIEST，来创建和利用区域依赖性和常见的时空模式。广泛的实验已经证实了我们的领先性能的 HIEST 对国家的最先进的基线。我们公布代码以减轻重复性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rethinking+Sensors+Modeling:+Hierarchical+Information+Enhanced+Traffic+Forecasting)|0|
|[MultiCAD: Contrastive Representation Learning for Multi-modal 3D Computer-Aided Design Models](https://doi.org/10.1145/3583780.3614982)|Weijian Ma, Minyang Xu, Xueyang Li, Xiangdong Zhou|Fudan University, Shanghai, China|CAD models are multimodal data where information and knowledge contained in construction sequences and shapes are complementary to each other and representation learning methods should consider both of them. Such traits have been neglected in previous methods learning unimodal representations. To leverage the information from both modalities, we develop a multimodal contrastive learning strategy where features from different modalities interact via contrastive learning paradigm, driven by a novel multimodal contrastive loss. Two pretext tasks on both geometry and sequence domains are designed along with a two-stage training strategy to make the representation focus on encoding geometric details and decoding representations into construction sequences, thus being more applicable to downstream tasks such as multimodal retrieval and CAD sequence reconstruction. Experimental results show that the performance of our multimodal representation learning scheme has surpassed the baselines and unimodal methods significantly.|CAD 模型是多模态的数据，其中包含的信息和知识建设序列和形状是互补的，表示学习方法应考虑这两者。这些特征在以前的单峰表征学习方法中被忽略了。为了利用这两种模式的信息，我们开发了一个多模式对比学习策略，其中来自不同模式的特征通过对比学习范式相互作用，由一个新的多模式对比损失驱动。设计了几何域和序列域上的两个托词任务，并采用两阶段训练策略，使表示集中于编码几何细节，并将表示解码为结构序列，从而更适用于多模态检索和 CAD 序列重构等下游任务。实验结果表明，我们的多模态表示学习方案的性能明显优于基线和单模态方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MultiCAD:+Contrastive+Representation+Learning+for+Multi-modal+3D+Computer-Aided+Design+Models)|0|
|[A Graph Neural Network Model for Concept Prerequisite Relation Extraction](https://doi.org/10.1145/3583780.3614761)|Debjani Mazumder, Jiaul H. Paik, Anupam Basu|Indian Institute of Technology, Kharagpur, Kharagpur, India; National Institute of Technology Durgapur, Kolkata, India|In recent years, with the emergence of online learning platforms and e-learning resources, many documents are available for a particular topic. For a better learning experience, the learner often needs to know and learn first the prerequisite concepts for a given concept. Traditionally, the identification of such prerequisite concepts is done manually by subject experts, which in turn, often limits self-paced learning. Recently, machine learning models have found encouraging success for the task, obviating manual effort. In this paper, we propose a graph neural network based approach that leverages node attention over a heterogeneous graph to extract the prerequisite concepts for a given concept. Experiments on a set of benchmark data show that the proposed model outperforms the existing models by large margins almost always, making the model a new state-of-the-art for the task.|近年来，随着在线学习平台和电子学习资源的出现，针对特定主题的文献越来越多。为了获得更好的学习体验，学习者往往需要首先了解和学习给定概念的前提概念。传统上，这种先决条件概念的识别是由学科专家手工完成的，这反过来又常常限制了自主学习。最近，机器学习模型发现这项任务取得了令人鼓舞的成功，避免了人工劳动。本文提出了一种基于图神经网络的方法，该方法利用异构图上的节点注意力来提取给定概念的前提概念。在一组基准数据上的实验表明，该模型的性能几乎总是大大优于现有的模型，使得该模型成为该任务的一种新的技术状态。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Graph+Neural+Network+Model+for+Concept+Prerequisite+Relation+Extraction)|0|
|[Disparity, Inequality, and Accuracy Tradeoffs in Graph Neural Networks for Node Classification](https://doi.org/10.1145/3583780.3614847)|Arpit Merchant, Carlos Castillo|University of Helsinki, Helsinki, Finland; ICREA & Universitat Pompeu Fabra, Barcelona, Spain|Graph neural networks (GNNs) are increasingly used in critical human applications for predicting node labels in attributed graphs. Their ability to aggregate features from nodes' neighbors for accurate classification also has the capacity to exacerbate existing biases in data or to introduce new ones towards members from protected demographic groups. Thus, it is imperative to quantify how GNNs may be biased and to what extent their harmful effects may be mitigated. To this end, we propose two new GNN-agnostic interventions namely, (i) PFR-AX which decreases the separability between nodes in protected and non-protected groups, and (ii) PostProcess which updates model predictions based on a blackbox policy to minimize differences between error rates across demographic groups. Through a large set of experiments on four datasets, we frame the efficacies of our approaches (and three variants) in terms of their algorithmic fairness-accuracy tradeoff and benchmark our results against three strong baseline interventions on three state-of-the-art GNN models. Our results show that no single intervention offers a universally optimal tradeoff, but PFR-AX and PostProcess provide granular control and improve model confidence when correctly predicting positive outcomes for nodes in protected groups.|图神经网络(GNN)越来越多地应用于关键的人类应用中，用于预测属性图中的节点标记。他们聚合节点邻居特征进行精确分类的能力也有能力加剧现有的数据偏差，或者向来自受保护人口群体的成员引入新的偏差。因此，必须量化 GNN 如何可能带有偏见，以及在多大程度上可以减轻其有害影响。为此，我们提出了两种新的 GNN 不可知干预措施，即(i) PFR-AX，其降低了受保护组和非受保护组中节点之间的可分性，以及(ii) PostProcess，其根据黑盒政策更新模型预测，以尽量减少人口组之间的差异。通过对四个数据集的大量实验，我们构建了我们的方法(和三个变体)在算法公平性-准确性权衡方面的功效，并将我们的结果与三个最先进的 GNN 模型上的三个强基线干预进行比较。我们的研究结果表明，没有单一的干预提供了普遍的最佳折衷，但 PFR-AX 和 PostProcess 提供了粒度控制，并提高了模型的置信度，当正确预测保护组中节点的积极结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Disparity,+Inequality,+and+Accuracy+Tradeoffs+in+Graph+Neural+Networks+for+Node+Classification)|0|
|[Unlocking the Potential of Non-PSD Kernel Matrices: A Polar Decomposition-based Transformation for Improved Prediction Models](https://doi.org/10.1145/3583780.3615102)|Maximilian Münch, Manuel Röder, FrankMichael Schleif|Technical University of Applied Sciences Würzburg-Schweinfurt, Center for Artificial Intelligence and Robotics, Würzburg, Germany; University of Groningen, Groningen, Netherlands|Kernel functions are a key element in many machine learning methods to capture the similarity between data points. However, a considerable number of these functions do not meet all mathematical requirements to be a valid positive semi-definite kernel, a crucial precondition for kernel-based classifiers such as Support Vector Machines or Kernel Fisher Discriminant classifiers. In this paper, we propose a novel strategy employing a polar decomposition to effectively transform invalid kernel matrices to positive semi-definite matrices, while preserving the topological structure inherent to the data points. Utilizing polar decomposition allows the effective transformation of indefinite kernel matrices from Krein space to positive semi-definite matrices in Hilbert space, thereby providing an efficient out-of-sample extension for new unseen data and enhancing kernel method applicability across diverse classification tasks. We evaluate our approach on a variety of benchmark datasets and demonstrate its superiority over competitive methods.|核函数是许多机器学习方法中捕捉数据点之间相似性的关键元素。然而，这些函数中有相当一部分不能满足作为有效正半定核的所有数学要求，这是支持向量机或核 Fisher 鉴别分类器等基于核的分类器的关键先决条件。在本文中，我们提出了一个新的策略，使用极分解有效地转换无效的核矩阵到正的半定矩阵，同时保留数据点固有的拓扑结构。利用极分解可以有效地将不定核矩阵从 Krein 空间转化为 Hilbert 空间中的正半定矩阵，从而为新的不可见数据提供了有效的样本外扩展，并增强了核方法在不同分类任务中的适用性。我们评估了我们的方法在各种基准数据集，并证明了其优势竞争的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unlocking+the+Potential+of+Non-PSD+Kernel+Matrices:+A+Polar+Decomposition-based+Transformation+for+Improved+Prediction+Models)|0|
|[Joint Link Prediction Via Inference from a Model](https://doi.org/10.1145/3583780.3614941)|Parmis Naddaf, Erfaneh Mahmoudzaheh Ahmadi Nejad, Kiarash Zahirnia, Manfred Jaeger, Oliver Schulte|Simon Fraser University, Burnaby, BC, Canada; Aalborg University, Aalborg, Denmark|A Joint Link Prediction Query (JLPQ) specifies a set of links to be predicted, given another set of links as well as node attributes as evidence. While single link prediction has been well studied in literature on deep graph learning, predicting multiple links together has gained little attention. This paper presents a novel framework for computing JLPQs using a probabilistic deep Graph Generative Model. Specifically, we develop inference procedures for an inductively trained Variational Graph Auto-Encoder (VGAE) that estimates the joint link probability for any input JLPQ, without retraining. For evaluation, we apply inference to a range of joint link prediction queries on six benchmark datasets. We find that for most datasets and query types, joint link prediction via inference from a model achieves good predictive performance, better than the independent link prediction baselines (by 0.02-0.4 AUC points depending on the dataset).|联合链接预测查询(JLPQ)指定一组要预测的链接，给定另一组链接以及节点属性作为证据。在深度图学习的文献中，单链接预测已经得到了很好的研究，但是多链接一起预测却很少受到关注。本文提出了一个使用概率深度图生成模型计算 JLPQs 的新框架。具体来说，我们开发了一个归纳训练的变分图自动编码器(VGAE)的推理程序，估计任何输入 JLPQ 的联合链接概率，没有再训练。为了进行评估，我们对六个基准数据集上的一系列联合链接预测查询进行了推断。我们发现，对于大多数数据集和查询类型，通过模型推断的联合链接预测实现了良好的预测性能，优于独立链接预测基线(根据数据集的不同，增加0.02 -0.4 AUC 点)。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Joint+Link+Prediction+Via+Inference+from+a+Model)|0|
|[Non-Uniform Adversarial Perturbations for Discrete Tabular Datasets](https://doi.org/10.1145/3583780.3614992)|Jay Nandy, Jatin Chauhan, Rishi Saket, Aravindan Raghuveer|Google Research, Bangalore, India|We study the problem of adversarial attack and robustness on tabular datasets with discrete features. The discrete features of a tabular dataset represent high-level meaningful concepts, with different sets of vocabularies, leading to requiring non-uniform robustness. Further, the notion of distance between tabular input instances is not well defined, making the problem of producing adversarial examples with minor perturbations qualitatively more challenging compared to existing methods. Towards this, our paper defines the notion of distance through the lens of feature embeddings, learnt to represent the discrete features. We then formulate the task of generating adversarial examples as abinary set selection problem under non-uniform feature importance. Next, we propose an efficient approximate gradient-descent based algorithm, calledDiscrete Non-uniform Approximation (DNA) attack, by reformulating the problem into a continuous domain to solve the original optimization problem for generating adversarial examples. We demonstrate the effectiveness of our proposed DNA attack using two large real-world discrete tabular datasets from e-commerce domains for binary classification, where the datasets are heavily biased for one-class. We also analyze challenges for existing adversarial training frameworks for such datasets under our DNA attack.|研究了具有离散特征的表格数据集的对抗性攻击和鲁棒性问题。表格数据集的离散特征代表了高层次的有意义的概念，具有不同的词汇集，导致需要非统一的鲁棒性。此外，表格输入实例之间的距离的概念没有得到很好的定义，使得产生具有微小扰动的对抗性实例的问题在质量上比现有方法更具挑战性。为此，本文通过特征嵌入的透镜定义了距离的概念，学会了表示离散的特征。然后将生成对手例子的任务表述为非一致特征重要度下的二进制集合选择问题。接下来，我们提出了一种有效的基于梯度下降的近似算法，称为离散非均匀近似(DNA)攻击，通过将问题重新构造成一个连续的域来解决生成对抗性例子的原始最佳化问题。我们证明了我们提出的 DNA 攻击的有效性，使用两个大型现实世界的离散表格数据集从电子商务领域的二进制分类，其中数据集是严重偏见的一类。我们还分析了在我们的 DNA 攻击下，针对这些数据集的现有对抗性训练框架所面临的挑战。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Non-Uniform+Adversarial+Perturbations+for+Discrete+Tabular+Datasets)|0|
|[Measuring the Effect of Causal Disentanglement on the Adversarial Robustness of Neural Network Models](https://doi.org/10.1145/3583780.3614960)|Preben M. Ness, Dusica Marijan, Sunanda Bose|Simula Research Laboratory, Oslo, Norway|Causal Neural Network models have shown high levels of robustness to adversarial attacks as well as an increased capacity for generalisation tasks such as few-shot learning and rare-context classification compared to traditional Neural Networks. This robustness is argued to stem from the disentanglement of causal and confounder input signals. However, no quantitative study has yet measured the level of disentanglement achieved by these types of causal models or assessed how this relates to their adversarial robustness. Existing causal disentanglement metrics are not applicable to deterministic models trained on real-world datasets. We, therefore, utilise metrics of content/style disentanglement from the field of Computer Vision to measure different aspects of the causal disentanglement for four state-of-the-art causal Neural Network models. By re-implementing these models with a common ResNet18 architecture we are able to fairly measure their adversarial robustness on three standard image classification benchmarking datasets under seven common white-box attacks. We find a strong association (r=0.820, p=0.001) between the degree to which models decorrelate causal and confounder signals and their adversarial robustness. Additionally, we find a moderate negative association between the pixel-level information content of the confounder signal and adversarial robustness (r=-0.597, p=0.040).|与传统神经网络相比，因果神经网络模型显示了对敌对攻击的高水平鲁棒性，以及对概括性任务(如少镜头学习和罕见背景分类)的增强能力。这种稳健性被认为源于因果和混杂输入信号的分离。然而，还没有定量研究测量这些类型的因果模型所达到的解纠缠水平，或评估这与它们的对抗稳健性的关系。现有的因果解缠度量不适用于在真实世界数据集上训练的确定性模型。因此，我们利用计算机视觉领域的内容/风格脱离度量来衡量四个最先进的因果神经网络模型的因果脱离的不同方面。通过使用一个通用的 ResNet18架构重新实现这些模型，我们能够在七种常见的白盒攻击下，在三种标准图像分类基准数据集上公平地测量它们的对抗鲁棒性。我们发现在模型去除因果信号和混杂信号的程度与它们的对抗稳健性之间有很强的相关性(r = 0.820，p = 0.001)。此外，我们发现混杂信号的像素级信息含量与对抗鲁棒性之间存在中度负相关(r = -0.597，p = 0.040)。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Measuring+the+Effect+of+Causal+Disentanglement+on+the+Adversarial+Robustness+of+Neural+Network+Models)|0|
|[How Discriminative Are Your Qrels? How To Study the Statistical Significance of Document Adjudication Methods](https://doi.org/10.1145/3583780.3614916)|David Otero, Javier Parapar, Nicola Ferro|Universidade da Coruña, A Coruña, Spain; Univesidade da Coruña, A Coruña, Spain; University of Padua, Padova, Italy|Creating test collections for offline retrieval evaluation requires human effort to judge documents' relevance. This expensive activity motivated much work in developing methods for constructing benchmarks with fewer assessment costs. In this respect, adjudication methods actively decide both which documents and the order in which experts review them, in order to better exploit the assessment budget or to lower it. Researchers evaluate the quality of those methods by measuring the correlation between the known gold ranking of systems under the full collection and the observed ranking of systems under the lower-cost one. This traditional analysis ignores whether and how the low-cost judgements impact on the statistically significant differences among systems with respect to the full collection. We fill this void by proposing a novel methodology to evaluate how the low-cost adjudication methods preserve the pairwise significant differences between systems as the full collection. In other terms, while traditional approaches look for stability in answering the question "is system A better than system B?", our proposed approach looks for stability in answering the question "is system A significantly better than system B?", which is the ultimate questions researchers need to answer to guarantee the generalisability of their results. Among other results, we found that the best methods in terms of ranking of systems correlation do not always match those preserving statistical significance.|为离线检索评估创建测试集需要人力来判断文档的相关性。这项昂贵的活动促使人们开展大量工作，制定方法以构建评估成本较低的基准。在这方面，裁定方法积极决定哪些文件和专家审查这些文件的顺序，以便更好地利用或降低评估预算。研究人员评估这些方法的质量，通过测量之间的相关性已知黄金排名的系统下的全部收集和观察排名的系统下的低成本。这种传统的分析忽略了低成本判断是否以及如何影响各系统在完整收集方面的统计显著差异。为了填补这一空白，我们提出了一种新的方法来评估低成本的判决方法如何保持系统之间的成对显著差异作为完整的集合。换句话说，虽然传统方法在回答“系统 A 比系统 B 更好吗?”在回答“系统 A 是否明显优于系统 B?”这个问题时，我们提出的方法寻求稳定性这是研究人员需要回答的最终问题，以保证他们的结果的普遍性。除了其他结果之外，我们发现在系统相关性排序方面的最佳方法并不总是与那些保持统计显著性的方法相匹配。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+Discriminative+Are+Your+Qrels?+How+To+Study+the+Statistical+Significance+of+Document+Adjudication+Methods)|0|
|[Rule-based Knowledge Graph Completion with Canonical Models](https://doi.org/10.1145/3583780.3615042)|Simon Ott, Patrick Betz, Daria Stepanova, Mohamed H. GadElrab, Christian Meilicke, Heiner Stuckenschmidt|Bosch Center for Artificial Intelligence & AIT Austrian Institute of Technology GmbH, Renningen, Germany; Bosch Center for Artificial Intelligence, Renningen, Germany; University Mannheim, Mannheim, Germany|Rule-based approaches have proven to be an efficient and explainable method for knowledge base completion. Their predictive quality is on par with classic knowledge graph embedding models such as TransE or ComplEx, however, they cannot achieve the results of neural models proposed recently. The performance of a rule-based approach depends crucially on the solution of the rule aggregation problem, which is concerned with the computation of a score for a prediction that is generated by several rules. Within this paper, we propose a supervised approach to learn a reweighted confidence value for each rule to get an optimal explanation for the training set given a specific aggregation function. In particular, we apply our approach to two aggregation functions: We learn weights for a noisy-or multiplication and apply logistic regression, which computes the score of a prediction as a sum of these weights. Due to the simplicity of both models the final score is fully explainable. Our experimental results show that we can significantly improve the predictive quality of a rule-based approach. We compare our method with current state-of-the-art latent models that lack explainability, and achieve promising results.|基于规则的方法已被证明是完成知识库的一种有效和可解释的方法。它们的预测性能与传统的知识图嵌入模型如 TransE 或 CompleEx 相当，但是还不能达到最近提出的神经模型的预测效果。基于规则的方法的性能关键取决于规则聚合问题的解决方案，该问题涉及由多个规则生成的预测的得分计算。在本文中，我们提出了一种监督方法来学习每个规则的重新加权置信值，以获得一个给定特定聚集函数的训练集的最优解释。特别是，我们将我们的方法应用于两个聚合函数: 我们学习噪声或乘法的权重，并应用 Logit模型，它将预测的分数计算为这些权重的总和。由于两个模型的简单性，最终得分是完全可以解释的。实验结果表明，我们可以显著提高基于规则的方法的预测质量。我们比较了我们的方法与目前最先进的潜在模型，缺乏解释性，并取得了有希望的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rule-based+Knowledge+Graph+Completion+with+Canonical+Models)|0|
|[Concept Evolution in Deep Learning Training: A Unified Interpretation Framework and Discoveries](https://doi.org/10.1145/3583780.3614819)|Haekyu Park, Seongmin Lee, Benjamin Hoover, Austin P. Wright, Omar Shaikh, Rahul Duggal, Nilaksh Das, Kevin Li, Judy Hoffman, Duen Horng Chau|Georgia Tech, Atlanta, GA, USA|We present ConceptEvo, a unified interpretation framework for deep neural networks (DNNs) that reveals the inception and evolution of learned concepts during training. Our work addresses a critical gap in DNN interpretation research, as existing methods primarily focus on post-training interpretation. ConceptEvo introduces two novel technical contributions: (1) an algorithm that generates a unified semantic space, enabling side-by-side comparison of different models during training, and (2) an algorithm that discovers and quantifies important concept evolutions for class predictions. Through a large-scale human evaluation and quantitative experiments, we demonstrate that ConceptEvo successfully identifies concept evolutions across different models, which are not only comprehensible to humans but also crucial for class predictions. ConceptEvo is applicable to both modern DNN architectures, such as ConvNeXt, and classic DNNs, such as VGGs and InceptionV3.|我们提出概念 Evo，一个深度神经网络(DNN)的统一解释框架，揭示了在训练过程中学习概念的开始和发展。我们的工作解决了 DNN 口译研究中的一个关键差距，因为现有的方法主要集中在训练后口译。概念 Evo 介绍了两个新的技术贡献: (1)一个算法，生成一个统一的语义空间，使不同的模型在训练期间并排比较，和(2)一个算法，发现和量化重要的概念进化类预测。通过一个大规模的人类评估和定量实验，我们证明 ConeptEvo 成功地识别了不同模型之间的概念进化，这不仅对人类是可以理解的，而且对类别预测也是至关重要的。概念 Evo 既适用于现代 DNN 体系结构，如 ConvNeXt，也适用于经典 DNN，如 VGGs 和 InceptionV3。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Concept+Evolution+in+Deep+Learning+Training:+A+Unified+Interpretation+Framework+and+Discoveries)|0|
|[RotDiff: A Hyperbolic Rotation Representation Model for Information Diffusion Prediction](https://doi.org/10.1145/3583780.3615041)|Hongliang Qiao, Shanshan Feng, Xutao Li, Huiwei Lin, Han Hu, Wei Wei, Yunming Ye|Beijing Institute of Technology, Beijing, China; Harbin Institute of Technology, Shenzhen, Shenzhen, China; Wecar Technology Co., Ltd., Shenzhen, China; Harbin Institute of Technology Shenzhen Graduate School, Shenzhen, China; Huazhong University of Science and Technology, Wuhan, China|The massive amounts of online user behavior data on social networks allow for the investigation of information diffusion prediction, which is essential to comprehend how information propagates among users. The main difficulty in diffusion prediction problem is to effectively model the complex social factors in social networks and diffusion cascades. However, existing methods are mainly based on Euclidean space, which cannot well preserve the underlying hierarchical structures that could better reflect the strength of user influence. Meanwhile, existing methods cannot accurately model the obvious asymmetric features of the diffusion process. To alleviate these limitations, we utilize rotation transformation in the hyperbolic to model complex diffusion patterns. The modulus of representations in the hyperbolic space could effectively describe the strength of the user's influence. Rotation transformations could represent a variety of complex asymmetric features. Further, rotation transformation could model various social factors without changing the strength of influence. In this paper, we propose a novel hyperbolic rotation representation model RotDiff for the diffusion prediction problem. Specifically, we first map each social user to a Lorentzian vector and use two groups of transformations to encode global social factors in the social graph and the diffusion graph. Then, we combine attention mechanism in the hyperbolic space with extra rotation transformations to capture local diffusion dependencies within a given cascade. Experimental results on five real-world datasets demonstrate that the proposed model RotDiff outperforms various state-of-the-art diffusion prediction models.|社交网络中海量的在线用户行为数据为信息扩散预测提供了研究平台，对于理解信息在用户之间的传播方式具有重要意义。扩散预测问题的主要困难在于如何有效地模拟社会网络和扩散级联中的复杂社会因素。然而，现有的方法主要是基于欧几里德空间，不能很好地保留潜在的层次结构，可以更好地反映用户的影响力。同时，现有的方法不能准确地模拟扩散过程明显的非对称特征。为了减轻这些限制，我们利用双曲线中的旋转变换来模拟复杂的扩散模式。双曲空间中的表示模数可以有效地描述用户影响力的强度。旋转变换可以代表各种复杂的不对称特征。此外，轮换转换可以在不改变影响力的情况下模拟各种社会因素。本文针对扩散预测问题，提出了一种新的双曲旋转表示模型 RotDiff。具体来说，我们首先将每个社会用户映射到一个洛伦兹向量，并使用两组转换在社会图和扩散图中编码全球社会因素。然后，我们将双曲空间中的注意机制与额外的旋转变换结合起来，捕捉给定级联中的局部扩散依赖。在五个实际数据集上的实验结果表明，该模型的性能优于各种最先进的扩散预测模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RotDiff:+A+Hyperbolic+Rotation+Representation+Model+for+Information+Diffusion+Prediction)|0|
|[Federated Competing Risk Analysis](https://doi.org/10.1145/3583780.3614880)|Md Mahmudur Rahman, Sanjay Purushotham|University of Maryland, Baltimore County, Baltimore, MD, USA|Conducting survival analysis on distributed healthcare data is an important research problem, as privacy laws and emerging data-sharing regulations prohibit the sharing of sensitive patient data across multiple institutions. The distributed healthcare survival data often exhibit heterogeneity, non-uniform censoring and involve patients with multiple health conditions (competing risks), which can result in biased and unreliable risk predictions. To address these challenges, we propose employing federated learning (FL) for survival analysis with competing risks. In this work, we present two main contributions. Firstly, we propose a simple algorithm for estimating consistent federated pseudo values (FPV) for survival analysis with competing risks and censoring. Secondly, we introduce a novel and flexible FPV-based deep learning framework named Fedora, which jointly trains our proposed transformer-based model, TransPseudo, specific to the participating institutions (clients) within the Fedora framework without accessing clients' data, thus, preserving data privacy. We conducted extensive experiments on both real-world distributed healthcare datasets characterized by non-IID and non-uniform censoring properties, as well as synthetic data with various censoring settings. Our results demonstrate that our Fedora framework with the TransPseudo model performs better than the federated learning frameworks employing state-of-the-art survival models for competing risk analysis.|对分布式医疗数据进行生存分析是一个重要的研究问题，因为隐私法和新出现的数据共享规定禁止在多个机构之间共享敏感的患者数据。分布式医疗生存数据往往表现出异质性，审查不统一，并涉及多种健康状况(竞争风险)的患者，这可能导致有偏见和不可靠的风险预测。为了应对这些挑战，我们建议使用联邦学习(FL)进行具有竞争风险的生存分析。在这项工作中，我们提出了两个主要贡献。首先，我们提出了一个简单的算法估计一致性联邦伪值(FPV)的生存分析竞争风险和审查。其次，我们引入了一个新颖而灵活的基于 FPV 的深度学习框架 Fedora，该框架在不访问客户数据的情况下，联合训练我们提出的基于转换器的模型 TransPseuto，该模型特定于 Fedora 框架中的参与机构(客户) ，从而保护了数据隐私。我们在真实世界的分布式医疗数据集上进行了广泛的实验，这些数据集包括非拥有属性 ID 和非统一审查属性，以及具有各种审查设置的合成数据。我们的研究结果表明，我们的 Fedora 框架与 TransPseuto 模型执行优于联邦学习框架使用最先进的生存模型竞争风险分析。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Federated+Competing+Risk+Analysis)|0|
|[Incremental Graph Classification by Class Prototype Construction and Augmentation](https://doi.org/10.1145/3583780.3614932)|Yixin Ren, Li Ke, Dong Li, Hui Xue, Zhao Li, Shuigeng Zhou|Alibaba, Hangzhou, China; Alibaba Group, Hangzhou, China; Fudan University, Shanghai, China; Hangzhou Yugu Technology, Hangzhou, China|Graph neural networks (GNNs) are prone to catastrophic forgetting of past experience in continuous learning scenarios. In this work, we propose a novel method for class-incremental graph learning (CGL) by class prototype construction and augmentation, which can effectively overcome catastrophic forgetting and requires no storage of exemplars (i.e., data-free). Concretely, on the one hand, we construct class prototypes in the embedding space that contain rich topological information of nodes or graphs to represent past data, which are then used for future learning. On the other hand, to boost the adaptability of the model to new classes, we employ class prototype augmentation (PA) to create virtual classes by combining current prototypes. Theoretically, we show that PA can promote the model's adaptation to new data and reduce the inconsistency of old prototypes in the embedding space, therefore further mitigate catastrophic forgetting. Extensive experiments on both node and graph classification datasets show that our method significantly outperforms the existing methods in reducing catastrophic forgetting, and beats the existing methods in most cases in terms of classification accuracy.|在连续学习情境中，图神经网络容易发生灾难性遗忘。本文提出了一种基于类原型构造和扩充的类增量图学习方法，该方法可以有效地克服灾难性遗忘，不需要存储样本(即无数据)。具体来说，我们一方面在嵌入空间中构造类原型，包含丰富的节点或图的拓扑信息来表示过去的数据，然后用于未来的学习。另一方面，为了提高模型对新类的适应性，我们采用类原型增强(PA)的方法，通过组合当前的原型来创建虚拟类。从理论上说，PA 可以提高模型对新数据的适应性，减少嵌入空间中原型的不一致性，从而进一步减轻灾难性遗忘。在节点和图分类数据集上的大量实验表明，该方法在减少灾难性遗忘方面明显优于现有方法，并且在大多数情况下在分类精度方面优于现有方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Incremental+Graph+Classification+by+Class+Prototype+Construction+and+Augmentation)|0|
|[Seq-HyGAN: Sequence Classification via Hypergraph Attention Network](https://doi.org/10.1145/3583780.3615057)|Khaled Mohammed Saifuddin, Corey May, Farhan Tanvir, Muhammad Ifte Khairul Islam, Esra Akbas|Oklahoma State University, Stillwater, OK, USA; Georgia State University, Atlanta, GA, USA; Arkansas Tech University, Russellville, AR, USA|Sequence classification has a wide range of real-world applications in different domains, such as genome classification in health and anomaly detection in business. However, the lack of explicit features in sequence data makes it difficult for machine learning models. While Neural Network (NN) models address this with learning features automatically, they are limited to capturing adjacent structural connections and ignore global, higher-order information between the sequences. To address these challenges in the sequence classification problems, we propose a novel Hypergraph Attention Network model, namely Seq-HyGAN. To capture the complex structural similarity between sequence data, we first create a hypergraph where the sequences are depicted as hyperedges and subsequences extracted from sequences are depicted as nodes. Additionally, we introduce an attention-based Hypergraph Neural Network model that utilizes a two-level attention mechanism. This model generates a sequence representation as a hyperedge while simultaneously learning the crucial subsequences for each sequence. We conduct extensive experiments on four data sets to assess and compare our model with several state-of-the-art methods. Experimental results demonstrate that our proposed Seq-HyGAN model can effectively classify sequence data and significantly outperform the baselines. We also conduct case studies to investigate the contribution of each module in Seq-HyGAN.|序列分类在不同的领域有着广泛的实际应用，例如健康领域的基因组分类和商业领域的异常检测分类。然而，由于序列数据缺乏明确的特征，使得机器学习模型难以建立。虽然神经网络(NN)模型解决了这一问题，自动学习功能，他们仅限于捕获相邻的结构连接和忽略全局，高阶信息之间的序列。为了解决序列分类问题中的这些挑战，我们提出了一种新的 Hypergraph 注意网络模型，即 Seq-HyGAN。为了捕获序列数据之间的复杂结构相似性，我们首先创建一个超图，其中序列被描述为超边，从序列中提取的子序列被描述为节点。此外，我们还介绍了一个基于注意的超图神经网络模型，该模型采用了两级注意机制。该模型以超边界的形式生成序列表示，同时学习每个序列的关键子序列。我们对四个数据集进行了广泛的实验，以评估和比较我们的模型与几种最先进的方法。实验结果表明，我们提出的 Seq-HyGAN 模型能够有效地对序列数据进行分类，并明显优于基线。我们还进行了案例研究，以调查每个模块在 Seq-HyGAN 的贡献。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Seq-HyGAN:+Sequence+Classification+via+Hypergraph+Attention+Network)|0|
|[PaperLM: A Pre-trained Model for Hierarchical Examination Paper Representation Learning](https://doi.org/10.1145/3583780.3615003)|Minghui Shan, Yixiao Ma, Shulan Ruan, Zhi Cao, Shiwei Tong, Qi Liu, Yu Su, Shijin Wang|Hefei Normal University,Institute of Artificial Intelligence & Hefei Comprehensive National Science Center, Hefei, China; iFLYTEK AI Research (Central China) & State Key Laboratory of Cognitive Intelligence, Hefei, China; University of Science and Technology of China & State Key Laboratory of Cognitive Intelligence, Hefei, China|Representation learning of examination papers is significantly crucial for online education systems, as it benefits various applications such as estimating paper difficulty and examination paper retrieval. Previous works mainly explore the representation learning of individual questions in an examination paper, with limited attention given to the examination paper as a whole. In fact, the structure of examination papers is strongly correlated with paper properties such as paper difficulty, which existing paper representation methods fail to capture adequately. To this end, we propose a pre-trained model namely PaperLM to learn the representation of examination papers. Our model integrates both the text content and hierarchical structure of examination papers within a single framework by converting the path of the Examination Organization Tree (EOT) into embedding. Furthermore, we specially design three pre-training objectives for PaperLM, namely EOT Node Relationship Prediction (ENRP), Question Type Prediction (QTP) and Paper Contrastive Learning (PCL), aiming to capture features from text and structure effectively. We pre-train our model on a real-world examination paper dataset, and then evaluate the model with three down-stream tasks: paper difficulty estimation, examination paper retrieval, and paper clustering. The experimental results demonstrate the effectiveness of our method.|试卷表征学习对于在线教育系统具有重要意义，因为它有利于评估试卷难度和检索试卷等多种应用。以往的研究主要探讨个别试题在试卷中的表征学习，对试卷整体的关注有限。事实上，试卷的结构与试卷的难度等特性密切相关，而现有的试卷表示方法未能充分捕捉到这些特性。为此，我们提出了一种预训练模型，即 PaperLM 来学习试卷的表示。该模型通过将考试组织树(EOT)的路径转换为嵌入式，将试卷的文本内容和层次结构集成在一个框架内。此外，我们特别设计了三个 PaperLM 的预训目标，即 EOT 节点关系预测(ENRP)、问题类型预测(QTP)和纸张对比学习(PCL) ，旨在有效地从文本和结构中捕捉特征。我们在一个真实的试卷数据集上预训练我们的模型，然后通过三个下游任务来评估模型: 试卷难度估计，试卷检索和试卷聚类。实验结果表明了该方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PaperLM:+A+Pre-trained+Model+for+Hierarchical+Examination+Paper+Representation+Learning)|0|
|[Transferable Structure-based Adversarial Attack of Heterogeneous Graph Neural Network](https://doi.org/10.1145/3583780.3615095)|Yu Shang, Yudong Zhang, Jiansheng Chen, Depeng Jin, Yong Li|University of Science and Technology Beijing, Beijing, China; Tsinghua University, Beijing, China|Heterogeneous graph neural networks (HGNNs) have achieved remarkable development recently and exhibited superior performance in various tasks. However, recently HGNNs have been shown to have robustness weakness towards adversarial perturbations, which brings critical pitfalls for real applications, e.g. node classification and recommender systems. In particular, the transfer-based black-box attack is the most practical method to attack unknown models and poses a great threat to the reliability of HGNNs. In this work, we take the first step to explore the transferability of adversarial examples of HGNNs. Due to the overfitting of the source model, the adversarial perturbations generated by traditional methods usually exhibit unpromising transferability. To address this problem and boost adversarial transferability, we expect to seek common vulnerable directions of different models to attack. Inspired by the observation of the notable commonality of edge attention distribution between different HGNNs, we propose to guide the perturbation generation toward disrupting edge attention distribution. This edge attention-guided attack prioritizes the perturbation on edges that are more likely to be given common attention by different models, which benefits the transferability of adversarial perturbations. Finally, we develop two edge attention-guided attack methods towards heterogeneous relations tailored for HGNNs, called EA-FGSM and EA-PGD. Extensive experiments on six representative models and two datasets verify the effectiveness of our methods and form an unprecedented transfer robustness benchmark for HGNNs.|异构图神经网络(HGNN)近年来取得了显著的发展，在各种任务中表现出了优异的性能。然而，最近 HGNN 已被证明对抗性扰动具有鲁棒性弱点，这给实际应用带来了关键的陷阱，如节点分类和推荐系统。特别是基于传输的黑盒攻击是最实用的攻击未知模型的方法，对 HGNN 的可靠性构成了很大的威胁。在这项工作中，我们采取的第一步，探讨可转移的对抗性例子的 HGNN。由于源模型的过度拟合，传统方法产生的对抗扰动通常表现出不良的可转移性。为了解决这一问题，提高对抗性的可转移性，我们期望寻找不同模型共同的易受攻击的方向。受不同 HGNN 之间边缘注意分布的显著共性的启发，我们提出将扰动产生引向破坏边缘注意分布的方向。这种边缘注意引导攻击优先考虑边缘上的扰动，这些扰动更有可能被不同的模型给予共同的关注，这有利于对抗性扰动的可转移性。最后，我们针对 HGNN 的异构关系提出了两种边缘注意引导攻击方法: EA-FGSM 和 EA-PGD。在六个典型模型和两个数据集上的大量实验验证了该方法的有效性，为 HGNN 提供了一个前所未有的传输鲁棒性基准。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Transferable+Structure-based+Adversarial+Attack+of+Heterogeneous+Graph+Neural+Network)|0|
|[CANA: Causal-enhanced Social Network Alignment](https://doi.org/10.1145/3583780.3614799)|Jiangli Shao, Yongqing Wang, Fangda Guo, Boshen Shi, Huawei Shen, Xueqi Cheng|Institute of Computing Technology, CAS, Beijing, China; Institute of Computing Technology, CAS & University of Chinese Academy of Sciences, Beijing, China|Social network alignment is widely applied in web applications for identifying corresponding nodes across different networks, such as linking users across two social networks. Existing methods for social network alignment primarily rely on alignment consistency, assuming that nodes with similar attributes and neighbors are more likely to be aligned. However, distributional discrepancies in node attributes and neighbors across different networks would bring biases in alignment consistency, leading to inferior alignment performance. To address this issue, we conduct a causal analysis of alignment consistency. Based on this analysis, we propose a novel model called CANA that uses causal inference approaches to mitigate biases and enhance social network alignment. Firstly, we disentangle observed node attributes into endogenous features and exogenous features with multi-task learning. Only endogenous features are retained to overcome node attribute discrepancies. To eliminate biases caused by neighbors discrepancies, we propose causal-aware attention mechanisms and integrate them in graph neural network to reweight contributions of different neighbors in alignment consistency comparison. Additionally, backdoor adjustment is applied to reduce confounding effects and estimate unbiased alignment probability. Through experimental evaluation on four real-world datasets, the proposed method demonstrates superior performance in terms of alignment accuracy and top-k hits precision.|社交网络对齐被广泛应用于 Web 应用程序中，用于识别跨不同网络的相应节点，例如在两个社交网络之间链接用户。现有的社会网络对齐方法主要依赖于对齐的一致性，假设具有相似属性和邻居的节点更有可能进行对齐。然而，不同网络中节点属性和邻居属性的分布差异会导致对齐一致性的偏差，从而导致对齐性能的下降。为了解决这个问题，我们对比对一致性进行了因果分析。在此基础上，我们提出了一个新的模型，称为 CANA，使用因果推理的方法，以减轻偏见和增强社会网络的一致性。首先，利用多任务学习将观测节点属性分解为内生特征和外生特征。只保留内生特征以克服节点属性差异。为了消除邻居间差异造成的偏差，本文提出了因果感知注意机制，并将其集成到图神经网络中，以重新权重不同邻居对对齐一致性比较的贡献。此外，后门调整的应用，以减少混杂效应和估计无偏的对齐概率。通过对四个实际数据集的实验评估，表明该方法在对准精度和 top-k 命中精度方面具有较好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CANA:+Causal-enhanced+Social+Network+Alignment)|0|
|[Representation Learning in Continuous-Time Dynamic Signed Networks](https://doi.org/10.1145/3583780.3615032)|Kartik Sharma, Mohit Raghavendra, YeonChang Lee, Anand Kumar M, Srijan Kumar|National Institute of Technology Karnataka, Surathkal, India; Georgia Institute of Technology, Atlanta, GA, USA|Signed networks allow us to model conflicting relationships and interactions, such as friend/enemy and support/oppose. These signed interactions happen in real-time. Modeling such dynamics of signed networks is crucial to understanding the evolution of polarization in the network and enabling effective prediction of the signed structure (i.e., link signs and signed weights) in the future. However, existing works have modeled either (static) signed networks or dynamic (unsigned) networks but not dynamic signed networks. Since both sign and dynamics inform the graph structure in different ways, it is non-trivial to model how to combine the two features. In this work, we propose a new Graph Neural Network (GNN)-based approach to model dynamic signed networks, named SEMBA: Signed link's Evolution using Memory modules and Balanced Aggregation. Here, the idea is to incorporate the signs of temporal interactions using separate modules guided by balance theory and to evolve the embeddings from a higher-order neighborhood. Experiments on 4 real-world datasets and 4 different tasks demonstrate that SEMBA consistently and significantly outperforms the baselines by up to $80\%$ on the tasks of predicting signs of future links while matching the state-of-the-art performance on predicting the existence of these links in the future. We find that this improvement is due specifically to the superior performance of SEMBA on the minority negative class.|签名网络允许我们建立冲突的关系和互动，例如朋友/敌人和支持/反对。这些签名的交互实时发生。建立符号网络的动力学模型对于理解网络中极化的演化过程以及有效预测未来的符号结构(即链路符号和符号权重)是至关重要的。然而，现有的作品已经模拟了(静态)有符号网络或动态(无符号)网络，但没有动态有符号网络。由于符号和动力学都以不同的方式告知图形结构，因此建立如何结合这两个特征的模型是非常重要的。在这项工作中，我们提出了一个新的图神经网络(GNN)为基础的模型动态签名网络，称为 SEMBA: 签名链路的演化使用记忆模块和平衡聚合。在这里，我们的想法是使用平衡理论指导下的独立模块合并时间相互作用的标志，并从一个高阶邻域演化嵌入。在4个真实世界的数据集和4个不同的任务上的实验表明，SEMBA 在预测未来链接迹象的任务上持续而显著地优于基线80% ，同时在预测未来链接存在的任务上匹配最先进的表现。我们发现，这种改善主要是由于 SEMBA 在少数消极阶层中的卓越表现。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Representation+Learning+in+Continuous-Time+Dynamic+Signed+Networks)|0|
|[Investigating the Impact of Multimodality and External Knowledge in Aspect-level Complaint and Sentiment Analysis](https://doi.org/10.1145/3583780.3614937)|Apoorva Singh, Apoorv Verma, Raghav Jain, Sriparna Saha|IIT Patna, Patna, India|Automated complaint analysis is vital for generating critical insights, which in turn enhance customer satisfaction, product quality, and overall business performance. Nevertheless, conventional methods frequently fail to capture the nuances of aspect-level complaints and inadequately utilize external knowledge, thus creating a gap in effective complaint detection and analysis. In response to this issue, we proactively explore the role of external knowledge and multimodality in this domain. This leads to the development of MGasD (Multimodal Generative framework for aspect-based complaint and sentiment Detection), a multimodal knowledge-infused unified framework. MGasD diverges from traditional methods by reframing the complaint detection problem as a multimodal text-to-text generation task. Significantly, our research includes the development of a novel aspect-level dataset. Annotated for both complaint and sentiment categories across diverse domains such as books, electronics, edibles, fashion, and miscellaneous, this dataset provides a comprehensive platform for the concurrent study of complaints and sentiment. This resource facilitates a more robust understanding of consumer feedback. Our proposed methodology establishes a benchmark performance in the novel aspect-based complaint and sentiment detection tasks based on extensive evaluation. We also demonstrate that our model consistently outperforms all other baselines and state-of-the-art models in both full and few-shot settings (The dataset and code are available at:https://github.com/appy1608/CIKM2023).|自动化的投诉分析对于产生关键见解至关重要，这反过来又能提高客户满意度、产品质量和整体业务表现。然而，传统方法往往无法捕捉方面一级投诉的细微差别，也不能充分利用外部知识，从而在有效的投诉侦测和分析方面造成空白。针对这一问题，我们积极探索外部知识和多模态在这一领域的作用。这导致了 MGasD (用于基于方面的投诉和情绪检测的多模态生成框架)的开发，这是一个基于多模态知识的统一框架。MGasD 将抱怨检测问题重新定义为一个多模态的文本到文本生成任务，从而背离了传统的方法。值得注意的是，我们的研究包括开发一个新的方面级别的数据集。该数据集涵盖了书籍、电子产品、食品、时尚和杂项等不同领域的抱怨和情绪类别，为同时研究抱怨和情绪提供了一个全面的平台。这种资源有助于更好地理解消费者的反馈。我们提出的方法建立了一个新的基于方面的投诉和情绪检测任务的基准性能的广泛评估的基础上。我们还展示了我们的模型在完整和少量的设置中始终优于所有其他基线和最先进的模型(数据集和代码可在以下 https://github.com/appy1608/cikm2023获得)。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Investigating+the+Impact+of+Multimodality+and+External+Knowledge+in+Aspect-level+Complaint+and+Sentiment+Analysis)|0|
|[Follow the Will of the Market: A Context-Informed Drift-Aware Method for Stock Prediction](https://doi.org/10.1145/3583780.3614886)|ChenHui Song, Xi Xiao, Bin Zhang, ShuTao Xia|Tsinghua University, Shenzhen, China; Peng Cheng Laboratory, Shenzhen, China; Tsinghua University & Peng Cheng Laboratory, Shenzhen, China|The dynamic nature of stock market styles, referred to as concept drift, poses a formidable challenge when applying deep learning to stock prediction. Models trained on historical data often struggle to adapt to the latest market styles, as the patterns they have learned may no longer hold true over time. To alleviate this issue, the recently popularized concept of In-Context learning has provided us with valuable insights. In this approach, large language models (LLMs) are exposed to multiple examples of input-label pairs, also known as demonstrations, as part of the prompt before performing a task on an unseen example. By thoroughly analyzing these demonstrations, LLMs can uncover potential patterns and effectively adapt to new tasks. Building upon this concept, we propose a Context-Informed drift-aware method for Stock Prediction (CISP), which continually adjusts to the latest market styles and offers more accurate predictions. Our proposed method consists of two key parts. Firstly, we introduce a straightforward and efficient technique for designing demonstrations that aggregate current market information, thereby indicating the prevailing stock market style. Secondly, we incorporate a prediction module with dynamic parameters, allowing it to appropriately adjust its model parameters based on the market patterns embedded in the aforementioned demonstrations. Through extensive experiments conducted on real-world stock market datasets, our approach consistently outperforms the most advanced existing methods for stock prediction.|股票市场风格的动态特性，即概念漂移，对深度学习在股票预测中的应用提出了严峻的挑战。受过历史数据训练的模型往往难以适应最新的市场风格，因为他们所学到的模式可能不再适用于未来。为了解决这个问题，最近推广的 In-Context 学习概念为我们提供了宝贵的见解。在这种方法中，大型语言模型(LLM)在对一个看不见的示例执行任务之前，作为提示的一部分向多个输入标签对示例(也称为演示)公开。通过深入分析这些演示，LLM 可以发现潜在的模式，并有效地适应新的任务。基于这一概念，我们提出了一种基于上下文信息的漂移感知股票预测方法(CISP) ，该方法可以不断地根据最新的市场风格进行调整，并提供更准确的预测。我们提出的方法包括两个关键部分。首先，我们介绍了一种简单有效的方法来设计演示，聚合当前的市场信息，从而表明流行的股票市场风格。其次，我们引入了一个具有动态参数的预测模块，使其能够根据上述示范中所包含的市场模式适当地调整其模型参数。通过在真实股市数据集上进行的大量实验，我们的方法始终优于现有的最先进的股票预测方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Follow+the+Will+of+the+Market:+A+Context-Informed+Drift-Aware+Method+for+Stock+Prediction)|0|
|[Towards Fair Financial Services for All: A Temporal GNN Approach for Individual Fairness on Transaction Networks](https://doi.org/10.1145/3583780.3615091)|Zixing Song, Yuji Zhang, Irwin King|The Chinese University of Hong Kong, New Territories, Hong Kong; The Hong Kong Polytechnic University, Kowloon, Hong Kong|Discrimination against minority groups within the banking sector has long resulted in unequal treatment in financial services. Recent works in the general machine learning domain can promote group fairness for predictions on static tabular data, but their direct application in finance often proves ineffective. Financial losses of banks may arise from inaccurate predictions due to the overlooked dynamic nature of data, and illegal discrimination against some individual clients could still occur since fairness is promoted on the subgroup level. Therefore, we model the data as a dynamic or temporal transaction network for better utility and investigate individual fairness on this dynamic graph for the loan approval task. We define two novel individual fairness properties on temporal graphs with a theoretical analysis of their respective regret. Using these notions, we design a temporally fair graph neural network (TF-GNN) approach under a new real-time evaluation scheme for dynamic transaction networks. Experiments on real-world datasets demonstrate the superiority of the proposed method for both utility improvement in accuracy and fairness promotion in NDCG@k.|长期以来，银行部门对少数群体的歧视导致了金融服务方面的不平等待遇。最近在一般机器学习领域的研究工作可以促进对静态表格数据的预测的群公平性，但它们在金融中的直接应用往往被证明是无效的。由于数据的动态性质被忽视，银行的财务损失可能来自不准确的预测，而且由于在小组一级促进公平，仍然可能发生对某些个别客户的非法歧视。因此，我们将数据建模为一个动态或时态的交易网络，以获得更好的效用，并在这个动态图上研究贷款批准任务的个体公平性。在时间图上定义了两个新的个体公平性质，并对它们各自的遗憾进行了理论分析。利用这些概念，我们设计了一种新的动态事务网络实时评估方案下的时间公平图神经网络(TF-GNN)方法。实际数据集的实验结果表明，该方法在提高 NDCG@k 的准确性和公平性方面具有优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Fair+Financial+Services+for+All:+A+Temporal+GNN+Approach+for+Individual+Fairness+on+Transaction+Networks)|0|
|[Topic-Aware Contrastive Learning and K-Nearest Neighbor Mechanism for Stance Detection](https://doi.org/10.1145/3583780.3615085)|Yepeng Sun, Jicang Lu, Ling Wang, Shunhang Li, Ningbo Huang|State Key Laboratory of Mathematical Engineering and Advanced Computing, Zhengzhou, Henan, China|The goal of stance detection is to automatically recognize the author's expressed attitude in text towards a given target. However, social media users often express themselves briefly and implicitly, which leads to a significant number of comments lacking explicit reference information to the target, posing a challenge for stance detection. To address the missing relationship between text and target, existing studies primarily focus on incorporating external knowledge, which inevitably introduces noise information. In contrast to their work, we are dedicated to mining implicit relational information within data. Typically, users tend to emphasize their attitudes towards a relevant topic or aspect of the target while concealing others when expressing opinions. Motivated by this phenomenon, we suggest that the potential correlation between text and target can be learned from instances with similar topics. Therefore, we design a pretext task to mine the topic associations between samples and model this topic association as a dynamic weight introduced into contrastive learning. In this way, we can selectively cluster samples that have similar topics and consistent stances, while enlarging the gap between samples with different stances in the feature space. Additionally, we propose a nearest-neighbor prediction mechanism for stance classification to better utilize the features we constructed. Our experiments on two datasets demonstrate the advanced and generalization ability of our method, yielding the state-of-the-art results.|姿势检测的目的是自动识别作者在文本中对给定目标所表达的态度。然而，社会媒体用户往往表达自己的简短和隐含，这导致大量的评论缺乏明确的参考信息的目标，造成了立场检测的挑战。为了解决文本与目标语之间缺失的关系，现有的研究主要集中在外部知识的融合上，这就不可避免地引入了噪声信息。与他们的工作相反，我们致力于在数据中挖掘隐式关系信息。通常情况下，用户倾向于强调他们对目标相关话题或方面的态度，而在表达意见时隐瞒其他人。基于这一现象，我们认为文本与目标语之间的潜在相关性可以通过类似话题的实例来学习。因此，我们设计了一个借口任务来挖掘样本之间的主题关联，并将这种主题关联作为一个动态权重引入到对比学习中。这样，我们可以选择性地对具有相似主题和一致立场的样本进行聚类，同时在特征空间中扩大具有不同立场的样本之间的差距。此外，为了更好地利用所构造的特征，我们提出了一种姿态分类的最近邻预测机制。我们在两个数据集上的实验证明了我们方法的先进性和泛化能力，得到了最先进的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Topic-Aware+Contrastive+Learning+and+K-Nearest+Neighbor+Mechanism+for+Stance+Detection)|0|
|[Fairness through Aleatoric Uncertainty](https://doi.org/10.1145/3583780.3614875)|Anique Tahir, Lu Cheng, Huan Liu|University of Illinois Chicago, Chicago, IL, USA; Arizona State University, Tempe, AZ, USA|We propose a unique solution to tackle the often-competing goals of fairness and utility in machine learning classification tasks. While fairness ensures that the model's predictions are unbiased and do not discriminate against any particular group, utility focuses on maximizing the accuracy of the model's predictions. Our aim is to investigate the relationship between uncertainty and fairness. Our approach leverages this concept by employing Bayesian learning to estimate the uncertainty in sample predictions where the estimation is independent of confounding effects related to the protected attribute. Through empirical evidence, we show that samples with low classification uncertainty are modeled more accurately and fairly than those with high uncertainty, which may have biased representations and higher prediction errors. To address the challenge of balancing fairness and utility, we propose a novel fairness-utility objective that is defined based on uncertainty quantification. The weights in this objective are determined by the level of uncertainty, allowing us to optimize both fairness and utility simultaneously. Experiments on real-world datasets demonstrate the effectiveness of our approach. Our results show that our method outperforms state-of-the-art methods in terms of the fairness-utility tradeoff and this applies to both group and individual fairness metrics. This work presents a fresh perspective on the trade-off between accuracy and fairness in machine learning and highlights the potential of using uncertainty as a means to achieve optimal fairness and utility.|针对机器学习分类任务中公平性和效用性这两个经常相互竞争的目标，提出了一种独特的解决方案。虽然公平性确保模型的预测是无偏见的，不歧视任何特定的群体，效用的重点是最大限度地提高模型的预测的准确性。我们的目的是研究不确定性和公平性之间的关系。我们的方法利用这个概念，通过使用贝叶斯学习来估计样本预测中的不确定性，其中估计独立于与受保护属性相关的混杂效应。通过经验证明分析，我们发现分类不确定性低的样本比不确定性高的样本建模更加准确和公平，因为不确定性高的样本可能有偏差表示和更高的预测误差。为了解决平衡公平与效用的难题，我们提出了一种新的基于不确定性量化的公平效用目标。该目标中的权重由不确定性水平决定，使我们能够同时优化公平性和效用。在实际数据集上的实验证明了该方法的有效性。我们的结果表明，我们的方法在公平-效用权衡方面优于最先进的方法，这适用于群体和个人的公平度量。这项工作提出了一个新的视角之间的权衡准确性和公平的机器学习，并强调了潜在的使用不确定性作为一种手段，以实现最佳的公平性和效用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fairness+through+Aleatoric+Uncertainty)|0|
|[EAGLE: Enhance Target-Oriented Dialogs by Global Planning and Topic Flow Integration](https://doi.org/10.1145/3583780.3614860)|Zee Hen Tang, MiYen Yeh|National Taiwan University and Academia Sinica, Taipei, Taiwan Roc|In this study, we propose a novel model EAGLE for target-oriented dialogue generation. Without relying on any knowledge graphs, our method integrates the global planning strategy in both topic path generation and response generation given the initial and target topics. EAGLE comprises three components: a topic path sampling strategy, a topic flow generator, and a global planner. Our approach confers a number of advantages: EAGLE is robust to the target that has never appeared in the training data set and able to plan the topic flow globally. The topic path sampling strategy samples topic paths based on two predefined rules and use the sampled paths to train the topic path generator. The topic flow generator then applies a non-autoregressive method to generate intermediate topics that link the initial and target topics smoothly. In addition, the global planner is a response generator that generates a response based on the future topic sequence and conversation history, enabling it to plan how to transition to future topics smoothly. Our experimental results demonstrate that EAGLE produces more coherent responses and smoother transitions than state-of-the-art baselines, with an overall success rate improvement of approximately 25% and an average smoothness score improvement of 10% in both offline and human evaluations.|在这项研究中，我们提出了一个新的模型 EAGLE 面向目标的对话生成。该方法在不依赖任何知识图的情况下，将全局规划策略集成到给定初始和目标主题的主题路径生成和响应生成中。EAGLE 由三部分组成: 主题路径抽样策略、主题流生成器和全局规划器。我们的方法提供了许多优点: EAGLE 对从未出现在训练数据集中的目标是健壮的，并且能够在全局范围内规划主题流。主题路径采样策略根据两个预定义的规则对主题路径进行采样，并利用采样后的路径对主题路径生成器进行训练。然后，主题流生成器应用非自回归方法来生成中间主题，这些中间主题将初始主题和目标主题平滑地连接起来。此外，全局规划器是一个响应生成器，它根据未来的主题顺序和会话历史生成响应，使其能够规划如何平稳地过渡到未来的主题。我们的实验结果表明，与最先进的基线相比，EAGLE 产生更连贯的响应和更平滑的转换，总体成功率提高约25% ，在离线和人类评估中平均平滑评分提高10% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EAGLE:+Enhance+Target-Oriented+Dialogs+by+Global+Planning+and+Topic+Flow+Integration)|0|
|[Spatio-Temporal Meta Contrastive Learning](https://doi.org/10.1145/3583780.3615065)|Jiabin Tang, Lianghao Xia, Jie Hu, Chao Huang|University of Hong Kong, Hong Kong, China; Southwest Jiaotong University, Chengdu, China|Spatio-temporal prediction is crucial in numerous real-world applications, including traffic forecasting and crime prediction, which aim to improve public transportation and safety management. Many state-of-the-art models demonstrate the strong capability of spatio-temporal graph neural networks (STGNN) to capture complex spatio-temporal correlations. However, despite their effectiveness, existing approaches do not adequately address several key challenges. Data quality issues, such as data scarcity and sparsity, lead to data noise and a lack of supervised signals, which significantly limit the performance of STGNN. Although recent STGNN models with contrastive learning aim to address these challenges, most of them use pre-defined augmentation strategies that heavily depend on manual design and cannot be customized for different Spatio-Temporal Graph (STG) scenarios. To tackle these challenges, we propose a new spatio-temporal contrastive learning (CL4ST) framework to encode robust and generalizable STG representations via the STG augmentation paradigm. Specifically, we design the meta view generator to automatically construct node and edge augmentation views for each disentangled spatial and temporal graph in a data-driven manner. The meta view generator employs meta networks with parameterized generative model to customize the augmentations for each input. This personalizes the augmentation strategies for every STG and endows the learning framework with spatio-temporal-aware information. Additionally, we integrate a unified spatio-temporal graph attention network with the proposed meta view generator and two-branch graph contrastive learning paradigms. Extensive experiments demonstrate that our CL4ST significantly improves performance over various state-of-the-art baselines in traffic and crime prediction. Our model implementation is available at the link: https://github.com/HKUDS/CL4ST.|时空预测在许多实际应用中至关重要，包括交通预测和犯罪预测，其目的是改善公共交通和安全管理。许多国家的最新模型表明，强大的能力时空图神经网络(STGNN)捕捉复杂的时空相关性。然而，尽管有效，现有的方法并没有充分解决几个关键的挑战。数据质量问题，如数据稀缺性和稀疏性，导致数据噪声和监督信号的缺乏，严重限制了 STGNN 的性能。虽然最近的 STGNN 模型与对比学习旨在解决这些挑战，他们中的大多数使用预定义的增强策略，严重依赖于手工设计，不能定制为不同的时空图(STG)场景。为了应对这些挑战，我们提出了一个新的时空对比学习(CL4ST)框架，通过 STG 增强范式编码健壮的和可推广的 STG 表示。具体来说，我们设计了元视图生成器，以数据驱动的方式自动构造每个分离的空间和时间图的节点和边增强视图。元视图生成器使用带有参数化生成模型的元网络来定制每个输入的扩展。这使每个 STG 的增强策略个性化，并赋予学习框架具有时空感知的信息。此外，我们将统一的时空图形注意网络与提出的元视图生成器和两分支图形对比学习范式相结合。大量的实验表明，我们的 CL4ST 显著提高了各种最先进的交通和犯罪预测基线的性能。我们的模型实现可在以下链接获得:  https://github.com/hkuds/cl4st。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spatio-Temporal+Meta+Contrastive+Learning)|0|
|[Single-Cell Multimodal Prediction via Transformers](https://doi.org/10.1145/3583780.3615061)|Wenzhuo Tang, Hongzhi Wen, Renming Liu, Jiayuan Ding, Wei Jin, Yuying Xie, Hui Liu, Jiliang Tang|Emory University, Atlanta, GA, USA; Michigan State University, East Lansing, MI, USA|The recent development of multimodal single-cell technology has made the possibility of acquiring multiple omics data from individual cells, thereby enabling a deeper understanding of cellular states and dynamics. Nevertheless, the proliferation of multimodal single-cell data also introduces tremendous challenges in modeling the complex interactions among different modalities. The recently advanced methods focus on constructing static interaction graphs and applying graph neural networks (GNNs) to learn from multimodal data. However, such static graphs can be suboptimal as they do not take advantage of the downstream task information; meanwhile GNNs also have some inherent limitations when deeply stacking GNN layers. To tackle these issues, in this work, we investigate how to leverage transformers for multimodal single-cell data in an end-to-end manner while exploiting downstream task information. In particular, we propose a scMoFormer framework which can readily incorporate external domain knowledge and model the interactions within each modality and cross modalities. Extensive experiments demonstrate that scMoFormer achieves superior performance on various benchmark datasets. Note that scMoFormer won a Kaggle silver medal with the rank of $24\ /\ 1221$ (Top 2%) without ensemble in a NeurIPS 2022 competition. Our implementation is publicly available at Github.|多模式单细胞技术的最新发展使得从单个细胞获取多组学数据成为可能，从而能够更深入地理解细胞状态和动力学。然而，多模态单细胞数据的增殖也给建立不同模态之间复杂的相互作用模型带来了巨大的挑战。最近提出的方法主要集中在构造静态交互图和应用图神经网络(GNN)学习多模态数据。然而，这样的静态图可能是次优的，因为它们没有利用下游任务信息; 同时 GNN 在深度堆叠 GNN 层时也有一些固有的局限性。为了解决这些问题，在这项工作中，我们研究如何利用变压器的多模式单细胞数据的端到端方式，同时利用下游任务信息。特别是，我们提出了一个 scMoForm 框架，它可以很容易地结合外部领域的知识，并在每个模式和交叉模式的交互模型。大量的实验表明，scMoForm 在各种基准数据集上取得了优越的性能。值得注意的是 scMoForm 在 NeurIPS 2022比赛中赢得了 Kaggle 银牌，没有合唱的成绩为 $24/1221 $(最高2%)。我们的实现可以在 Github 上公开获得。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Single-Cell+Multimodal+Prediction+via+Transformers)|0|
|[Explainable Spatio-Temporal Graph Neural Networks](https://doi.org/10.1145/3583780.3614871)|Jiabin Tang, Lianghao Xia, Chao Huang|University of Hong Kong, Hong Kong SAR, China|Spatio-temporal graph neural networks (STGNNs) have gained popularity as a powerful tool for effectively modeling spatio-temporal dependencies in diverse real-world urban applications, including intelligent transportation and public safety. However, the black-box nature of STGNNs limits their interpretability, hindering their application in scenarios related to urban resource allocation and policy formulation. To bridge this gap, we propose an Explainable Spatio-Temporal Graph Neural Networks (STExplainer) framework that enhances STGNNs with inherent explainability, enabling them to provide accurate predictions and faithful explanations simultaneously. Our framework integrates a unified spatio-temporal graph attention network with a positional information fusion layer as the STG encoder and decoder, respectively. Furthermore, we propose a structure distillation approach based on the Graph Information Bottleneck (GIB) principle with an explainable objective, which is instantiated by the STG encoder and decoder. Through extensive experiments, we demonstrate that our STExplainer outperforms state-of-the-art baselines in terms of predictive accuracy and explainability metrics (i.e., sparsity and fidelity) on traffic and crime prediction tasks. Furthermore, our model exhibits superior representation ability in alleviating data missing and sparsity issues. The implementation code is available at: https://github.com/HKUDS/STExplainer.|时空图形神经网络(STGNNs)作为一种有效的时空依赖建模工具，在智能交通和公共安全等多种现实世界的城市应用中得到了广泛的应用。然而，STGNN 的黑匣子性质限制了它们的可解释性，阻碍了它们在与城市资源分配和政策制定有关的情景中的应用。为了弥合这一差距，我们提出了一个可解释的时空图形神经网络(STExplainer)框架，增强了固有的可解释性，使他们能够同时提供准确的预测和忠实的解释。该框架将统一的时空图形注意网络与位置信息融合层分别作为 STG 编码器和解码器集成在一起。在此基础上，本文提出了一种基于图形信息瓶颈(GIB)原理的结构提取方法，该方法以 STG 编解码器为实例，具有可解释的目标。通过大量的实验，我们证明了我们的 STExplainer 在交通和犯罪预测任务的预测准确性和可解释性指标(即稀疏性和保真度)方面优于最先进的基线。此外，我们的模型表现出优越的表示能力，以减轻数据丢失和稀疏问题。实施守则可于以下 https://github.com/hkuds/stexplainer 索取:。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explainable+Spatio-Temporal+Graph+Neural+Networks)|0|
|[PSLF: Defending Against Label Leakage in Split Learning](https://doi.org/10.1145/3583780.3615019)|Xinwei Wan, Jiankai Sun, Shengjie Wang, Lei Chen, Zhenzhe Zheng, Fan Wu, Guihai Chen|Bytedance Inc., San Jose, USA; Shanghai Jiao Tong University, Shanghai, China; Bytedance Inc., Seattle, USA|With increasing concern over data privacy, split learning has become a widely used distributed machine learning paradigm in practice, where two participants (namely the non-label party and the label party) own raw features and raw labels respectively, and jointly train a model. Although no raw data is communicated between the two parties during model training, several works have demonstrated that data privacy, especially label privacy, is still vulnerable in split learning, and have proposed several defense algorithms against label attacks. However, the theoretical guarantee on the privacy preservation of these algorithms is limited. In this work, we propose a novel Private Split Learning Framework (PSLF). In PSLF, the label party shares only the gradients computed by flipped labels with the non-label party, which improves privacy preservation on raw labels, and meanwhile, we further design an extra sub-model from true labels to improve prediction accuracy. We also design a Flipped Multi-Label Generation mechanism (FMLG) based on randomized response for the label party to generate flipped labels. FMLG is proven differentially private and the label party could make a trade-off between privacy and utility by setting the DP budget. In addition, we design an upsampling method to further protect the labels against some existing attacks. We have evaluated PSLF over real-world datasets to demonstrate its effectiveness in protecting label privacy and achieving promising prediction accuracy.|随着人们对数据隐私问题的日益关注，分离学习已经成为实践中广泛使用的分布式机器学习范式，其中两个参与者(即非标签方和标签方)分别拥有原始特征和原始标签，并共同训练一个模型。虽然在模型训练过程中双方之间没有原始数据的交流，但是已有的研究表明，数据隐私，特别是标签隐私，在分割学习中仍然是脆弱的，并且提出了几种防御标签攻击的算法。然而，这些算法在保护隐私方面的理论保障是有限的。在这项工作中，我们提出了一个新颖的私人拆分学习框架(PSLF)。在 PSLF 中，标签方只与非标签方共享由翻转标签计算的梯度，从而提高了对原始标签的隐私保护，同时，我们进一步从真实标签中设计了一个额外的子模型，以提高预测的准确性。我们还设计了一个基于随机化回答的翻转多标签生成机制(FMLG) ，供标签方生成翻转标签。FMLG 被证明是不同的私人和标签方可以作出权衡之间的隐私和公用事业设置 DP 预算。此外，我们设计了一个向上采样的方法来进一步保护标签免受一些现有的攻击。我们已经在现实世界的数据集上评估了 PSLF，以证明它在保护标签隐私和实现有希望的预测准确性方面的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PSLF:+Defending+Against+Label+Leakage+in+Split+Learning)|0|
|[GraphFADE: Field-aware Decorrelation Neural Network for Graphs with Tabular Features](https://doi.org/10.1145/3583780.3614900)|Junhong Wan, Yao Fu, Junlan Yu, Weihao Jiang, Shiliang Pu, Ruiheng Yang|Hikvision Research Institute, Hangzhou, China|Graph Neural Networks (GNNs) have achieved great success in recent years for their remarkable ability to extract effective representations from both node features and graph structures. Most of GNNs only focus on graphs with homogeneous features that correspond to one single feature field. For tabular features that are heterogeneous with multiple feature fields, GNNs often perform less favorably compared to machine learning methods such as boosted trees. In this work, we propose a new perspective to uncover the problem of GNNs on graphs with tabular features through both empirical study and theoretical analysis. The assumption of GNNs that connected nodes exhibit similar patterns can barely hold true for tabular features since multiple feature fields already exhibit different patterns. And propagation on such mismatched graph causes propagated features overcorrelated on graphs, which leads to the reduction of feature diversity and the increase of information redundancy. Therefore, we propose Field-aware Decorrelation Neural Network for graphs with tabular features (GraphFADE), a novel framework that directly optimizes the overcorrelation problem for graphs with tabular features. We first hierarchically partition the dataset into subsets with minimal correlation and then according to the decorrelation clustering results assemble the optimal matched graphs for each feature dimension to propagate on. The empirical study shows that our method achieves superior performance on multiple graphs with tabular features, demonstrating the effectiveness of our model.|近年来，图神经网络(GNN)以其从节点特征和图结构中提取有效表示的能力取得了巨大的成功。大多数 GNN 只关注对应于单一特征域的具有同质特征的图。对于具有多个特征域的异构表格特征，GNN 的性能往往不如增强树等机器学习方法。本文通过实证研究和理论分析，提出了一个新的视角来揭示具有表格特征的图的 GNN 问题。由于多个特征字段已经表现出不同的模式，所以连接节点表现出相似模式的 GNN 假设对于表格特征几乎不成立。而在这种不匹配图上的传播会导致图上的传播特征过度相关，从而导致特征多样性的降低和信息冗余的增加。因此，我们提出了基于场感知的具有表格特征图的去相关神经网络(GraphFADE) ，这是一种直接优化具有表格特征图的过相关问题的新框架。首先对数据集进行最小相关性分层划分，然后根据去相关聚类结果组合出每个特征维数传播的最优匹配图。实证研究表明，该方法对具有表格特征的多个图形具有较好的性能，证明了该模型的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphFADE:+Field-aware+Decorrelation+Neural+Network+for+Graphs+with+Tabular+Features)|0|
|[MPerformer: An SE(3) Transformer-based Molecular Perceptron](https://doi.org/10.1145/3583780.3614974)|Fanmeng Wang, Hongteng Xu, Xi Chen, Shuqi Lu, Yuqing Deng, Wenbing Huang|Renmin University of China, Beijing, China; DP Technology, Beijing, China; Renmin University of China & DP Technology, Beijing, China|Molecular perception aims to construct 3D molecules from 3D atom clouds (i.e., atom types and corresponding 3D coordinates), determining bond connections, bond orders, and other molecular attributes within molecules. It is essential for realizing many applications in cheminformatics and bioinformatics, such as modeling quantum chemistry-derived molecular structures in protein-ligand complexes. Additionally, many molecular generation methods can only generate molecular 3D atom clouds, requiring molecular perception as a necessary post-processing. However, existing molecular perception methods mainly rely on predefined chemical rules and fail to leverage 3D geometric information, whose performance is sub-optimal fully. In this study, we propose MPerformer, an SE(3) Transformer-based molecular perceptron exhibiting SE(3)-invariance, to construct 3D molecules from 3D atom clouds efficiently. Besides, we propose a multi-task pretraining-and-finetuning paradigm to learn this model. In the pretraining phase, we jointly minimize an attribute prediction loss and an atom cloud reconstruction loss, mitigating the data imbalance issue of molecular attributes and enhancing the robustness and generalizability of the model. Experiments show that MPerformer significantly outperforms state-of-the-art molecular perception methods in precision and robustness, benefiting various molecular generation scenarios.|分子感知旨在从三维原子云(即原子类型和相应的三维坐标)构建三维分子，确定分子内的键连接、键顺序和其他分子属性。这对于实现化学信息学和生物信息学中的许多应用，例如在蛋白质-配体复合物中建立量子化学衍生的分子结构是必不可少的。此外，许多分子生成方法只能生成分子三维原子云，需要分子感知作为必要的后处理。然而，现有的分子感知方法主要依赖于预定义的化学规则，不能充分利用三维几何信息，其性能完全是次优的。在这项研究中，我们提出了一个基于 SE (3)变压器的分子感知器，它具有 SE (3)不变性，可以有效地从三维原子云中构建三维分子。此外，我们提出了一个多任务预训练和微调范式来学习这个模型。在预训练阶段，我们将属性预测损失和原子云重构损失最小化，减轻了分子属性的数据不平衡问题，提高了模型的鲁棒性和通用性。实验结果表明，该算法在精度和鲁棒性方面明显优于目前最先进的分子感知方法，有利于各种分子生成场景。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MPerformer:+An+SE(3)+Transformer-based+Molecular+Perceptron)|0|
|[Iteratively Learning Representations for Unseen Entities with Inter-Rule Correlations](https://doi.org/10.1145/3583780.3614938)|Zihan Wang, Kai Zhao, Yongquan He, Zhumin Chen, Pengjie Ren, Maarten de Rijke, Zhaochun Ren|Leiden University, Leiden, Netherlands; Meituan, Beijing, China; Georgia State University, Atlanta, GA, USA; University of Amsterdam, Amsterdam, Netherlands; Shandong University, Qingdao, China; Shandong University & University of Amsterdam, Qingdao, China|Recent work on knowledge graph completion (KGC) focused on learning embeddings of entities and relations in knowledge graphs. These embedding methods require that all test entities are observed at training time, resulting in a time-consuming retraining process for out-of-knowledge-graph (OOKG) entities. To address this issue, current inductive knowledge embedding methods employ graph neural networks (GNNs) to represent unseen entities by aggregating information of known neighbors. They face three important challenges: (i) data sparsity, (ii) the presence of complex patterns in knowledge graphs (e.g., inter-rule correlations), and (iii) the presence of interactions among rule mining, rule inference, and embedding. In this paper, we propose a virtual neighbor network with inter-rule correlations (VNC) that consists of three stages: (i) rule mining, (ii) rule inference, and (iii) embedding. In the rule mining process, to identify complex patterns in knowledge graphs, both logic rules and inter-rule correlations are extracted from knowledge graphs based on operations over relation embeddings. To reduce data sparsity, virtual neighbors for OOKG entities are predicted and assigned soft labels by optimizing a rule-constrained problem. We also devise an iterative framework to capture the underlying relations between rule learning and embedding learning. In our experiments, results on both link prediction and triple classification tasks show that the proposed VNC framework achieves state-of-the-art performance on four widely-used knowledge graphs. Further analysis reveals that VNC is robust to the proportion of unseen entities and effectively mitigates data sparsity.|最近关于知识图完备化(KGC)的研究主要集中在知识图中实体的学习嵌入和关系的学习。这些嵌入方法要求所有的测试实体在训练时都被观察到，从而导致对知识外图(OOKG)实体进行耗时的再训练过程。为了解决这一问题，现有的归纳知识嵌入方法采用图神经网络(GNN)通过聚合已知邻居的信息来表示未知实体。他们面临三个重要的挑战: (i)数据稀疏，(ii)知识图中存在复杂模式(例如，规则间相关性) ，以及(iii)规则挖掘，规则推理和嵌入之间存在交互作用。本文提出了一种具有规则间相关性的虚拟邻居网络(VNC) ，该网络由三个阶段组成: (i)规则挖掘、(ii)规则推理和(iii)嵌入。在规则挖掘过程中，为了识别知识图中的复杂模式，基于关系嵌入操作从知识图中提取逻辑规则和规则间相关性。为了减少数据稀疏性，通过优化规则约束问题，对 OOKG 实体的虚拟邻居进行预测并分配软标签。我们还设计了一个迭代框架来捕捉规则学习和嵌入式学习之间的潜在关系。在我们的实验中，链路预测和三重分类任务的结果表明，所提出的 VNC 框架在四个广泛使用的知识图上实现了最先进的性能。进一步的分析表明，VNC 对不可见实体的比例具有鲁棒性，并有效地减少了数据稀疏性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Iteratively+Learning+Representations+for+Unseen+Entities+with+Inter-Rule+Correlations)|0|
|[UrbanFloodKG: An Urban Flood Knowledge Graph System for Risk Assessment](https://doi.org/10.1145/3583780.3615105)|Yu Wang, Feng Ye, Binquan Li, Gaoyang Jin, Dong Xu, Fengsheng Li|Hohai University, Nanjing, China; China Water Resources Pearl River Planning, Surveying & Designing Co., Ltd, Guangzhou, China; Hydrologic Bureau (Information Center) of Huaihe River Commission, Bengbu, China|Increasing numbers of people live in flood-prone areas worldwide. With continued development, urban flood will become more frequent, which has caused casualties and property damage. Researchers have been dedicating to urban flood risk assessments in recent years. However, current research is still facing the challenges of multi-modal data fusion and knowledge representation of urban flood events. Therefore, in this paper, we propose an Urban Flood Knowledge Graph (UrbanFloodKG) system that enables KG to support urban flood risk assessment. The system consists of data layer, graph layer, algorithm layer, and application layer, which implements knowledge extraction and storage functions, integrates knowledge representation learning models and graph neural network models to support link prediction and node classification tasks. We conduct model comparison experiments on link prediction and node classification tasks based on urban flood event data from Guangzhou, and demonstrate the effectiveness of the models used. Our experiments prove that the accuracy of risk assessment can reach 91% when using GEN, which provides a a promising research direction for urban flood risk assessment.|全世界越来越多的人生活在洪水易发地区。随着城市的不断发展，城市洪水将越来越频繁，造成人员伤亡和财产损失。近年来，研究人员一直致力于城市洪水风险评估。然而，目前的研究仍然面临着城市洪水事件多模态数据融合和知识表示的挑战。因此，本文提出了一个城市洪水知识图(UrbanFloodKG)系统，以支持城市洪水风险评估。该系统由数据层、图层、算法层和应用层组成，实现知识提取和存储功能，集成知识表示学习模型和图神经网络模型，支持链路预测和节点分类任务。基于广州市的城市洪水事件数据，对链路预测和节点分类任务进行了模型对比实验，验证了模型的有效性。实验证明，利用遗传网络进行城市洪水风险评价的准确率可达91% ，为城市洪水风险评价提供了一个有前途的研究方向。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UrbanFloodKG:+An+Urban+Flood+Knowledge+Graph+System+for+Risk+Assessment)|0|
|[Flexible and Robust Counterfactual Explanations with Minimal Satisfiable Perturbations](https://doi.org/10.1145/3583780.3614885)|Yongjie Wang, Hangwei Qian, Yongjie Liu, Wei Guo, Chunyan Miao|A*STAR, Singapore, Singapore; Shandong University, Jinan, China; Nanyang Technological University, Singapore, Singapore|Counterfactual explanations (CFEs) exemplify how to minimally modify a feature vector to achieve a different prediction for an instance. CFEs can enhance informational fairness and trustworthiness, and provide suggestions for users who receive adverse predictions. However, recent research has shown that multiple CFEs can be offered for the same instance or instances with slight differences. Multiple CFEs provide flexible choices and cover diverse desiderata for user selection. However, individual fairness and model reliability will be damaged if unstable CFEs with different costs are returned. Existing methods fail to exploit flexibility and address the concerns of non-robustness simultaneously. To address these issues, we propose a conceptually simple yet effective solution named Counterfactual Explanations with Minimal Satisfiable Perturbations (CEMSP). Specifically, CEMSP constrains changing values of abnormal features with the help of their semantically meaningful normal ranges. For efficiency, we model the problem as a Boolean satisfiability problem to modify as few features as possible. Additionally, CEMSP is a general framework and can easily accommodate more practical requirements, e.g., casualty and actionability. Compared to existing methods, we conduct comprehensive experiments on both synthetic and real-world datasets to demonstrate that our method provides more robust explanations while preserving flexibility.|反事实解释(CFE)举例说明了如何最小限度地修改特征向量以实现对实例的不同预测。CFE 可以提高信息的公平性和可信度，并为收到负面预测的用户提供建议。然而，最近的研究表明，对于相同的实例或者稍有不同的实例，可以提供多个 CFE。多个 CFE 提供灵活的选择，并涵盖用户选择所需的各种数据。然而，如果返回不稳定且成本不同的 CFE，则会损害个体的公平性和模型的可靠性。现有的方法不能同时利用灵活性和解决非健壮性问题。为了解决这些问题，我们提出了一个概念上简单但有效的解决方案，称为最小可满足扰动反事实解释(CEMSP)。具体来说，CEMSP 利用异常特征的语义有意义的正常范围来约束异常特征的变化值。为了提高效率，我们将问题建模为一个布尔可满足性问题，以尽可能少地修改功能。此外，CEMSP 是一个通用框架，可以很容易地适应更多的实际需求，例如，伤亡和可操作性。与已有的方法相比，我们对合成和真实数据集进行了全面的实验，结果表明该方法在保持灵活性的同时提供了更加稳健的解释。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Flexible+and+Robust+Counterfactual+Explanations+with+Minimal+Satisfiable+Perturbations)|0|
|[Low-bit Quantization for Deep Graph Neural Networks with Smoothness-aware Message Propagation](https://doi.org/10.1145/3583780.3614955)|Shuang Wang, Bahaeddin Eravci, Rustam Guliyev, Hakan Ferhatosmanoglu|TOBB University of Economics and Technology, Ankara, Turkey; University of Warwick, Coventry, United Kingdom|Graph Neural Network (GNN) training and inference involve significant challenges of scalability with respect to both model sizes and number of layers, resulting in degradation of efficiency and accuracy for large and deep GNNs. We present an end-to-end solution that aims to address these challenges for efficient GNNs in resource constrained environments while avoiding the oversmoothing problem in deep GNNs. We introduce a quantization based approach for all stages of GNNs, from message passing in training to node classification, compressing the model and enabling efficient processing. The proposed GNN quantizer learns quantization ranges and reduces the model size with comparable accuracy even under low-bit quantization. To scale with the number of layers, we devise a message propagation mechanism in training that controls layer-wise changes of similarities between neighboring nodes. This objective is incorporated into a Lagrangian function with constraints and a differential multiplier method is utilized to iteratively find optimal embeddings. This mitigates oversmoothing and suppresses the quantization error to a bound. Significant improvements are demonstrated over state-of-the-art quantization methods and deep GNN approaches in both full-precision and quantized models. The proposed quantizer demonstrates superior performance in INT2 configurations across all stages of GNN, achieving a notable level of accuracy. In contrast, existing quantization approaches fail to generate satisfactory accuracy levels. Finally, the inference with INT2 and INT4 representations exhibits a speedup of 5.11 $\times$ and 4.70 $\times$ compared to full precision counterparts, respectively.|图形神经网络(GNN)的训练和推理涉及到模型大小和层数的可扩展性方面的重大挑战，导致大型和深度 GNN 的效率和精度下降。我们提出了一个端到端的解决方案，旨在解决这些挑战，有效的 GNN 在资源受限的环境中，同时避免深 GNN 过于平滑的问题。我们介绍了一种基于量化的方法，适用于 GNN 的各个阶段，从训练中的消息传递到节点分类，压缩模型并实现有效的处理。所提出的 GNN 量化器即使在低位量化情况下也能学习量化范围并以相当的精度缩小模型尺寸。为了根据层数进行调整，我们设计了一种训练中的消息传播机制，控制相邻节点之间相似性的层次变化。将该目标引入具有约束条件的拉格朗日函数中，并利用微分乘子法迭代寻找最优嵌入。这减轻了过度平滑，并将量化噪声压缩到一定程度。在全精度和量化模型方面，对最先进的量化方法和深度 GNN 方法都作了重大改进。所提议的量化器在 GNN 的所有阶段都表现出优越的 INT2配置性能，达到了显著的精确度水平。相比之下，现有的量化方法不能产生令人满意的精度水平。最后，使用 INT2和 INT4表示的推断与完全精确的对应物相比，分别显示出5.11 $乘以 $和4.70 $乘以 $的加速效果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Low-bit+Quantization+for+Deep+Graph+Neural+Networks+with+Smoothness-aware+Message+Propagation)|0|
|[A Mix-up Strategy to Enhance Adversarial Training with Imbalanced Data](https://doi.org/10.1145/3583780.3614762)|Wentao Wang, Harry Shomer, Yuxuan Wan, Yaxin Li, Jiangtao Huang, Hui Liu|; Michigan State Univ, E Lansing, MI 48824 USA|Adversarial training has been proven to be one of the most effective techniques to defend against adversarial examples. The majority of existing adversarial training methods assume that every class in the training data is equally distributed. However, in reality, some classes often have a large number of training data while others only have a very limited amount. Recent studies have shown that the performance of adversarial training will degrade drastically if the training data is imbalanced. In this paper, we propose a simple yet effective framework to enhance the robustness of DNN models under imbalanced scenarios. Our framework, Imb-Mix, first augments the training dataset by generating multiple adversarial examples for samples in the minority classes. This is done by first adding random noise to the original adversarial examples created by one specific adversarial attack method. It then constructs Mixup-mimic mixed examples upon the augmented dataset used by adversarial training. In addition, we theoretically prove the regularization effect of our Mixup-mimic mixed examples generation technique in Imb-Mix. Extensive experiments on various imbalanced datasets verify the effectiveness of the proposed framework.|对抗训练已被证明是防御对抗样本的最有效技术之一。现有的大多数对抗训练方法都假设训练数据中的每个类别是均匀分布的。然而，在现实中，某些类别通常拥有大量的训练数据，而其他类别则只有非常有限的数据量。最近的研究表明，如果训练数据不平衡，对抗训练的性能将显著下降。在本文中，我们提出了一种简单而有效的框架，以增强深度神经网络（DNN）模型在不平衡场景下的鲁棒性。我们的框架——Imb-Mix，首先通过对少数类别的样本生成多个对抗样本来扩充训练数据集。具体而言，我们首先通过向由特定对抗攻击方法生成的原始对抗样本中添加随机噪声来实现这一目标。随后，在对抗训练使用的扩充数据集上构建Mixup模拟的混合样本。此外，我们从理论上证明了Imb-Mix中Mixup模拟混合样本生成技术的正则化效果。在各种不平衡数据集上的大量实验验证了所提出框架的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Mix-up+Strategy+to+Enhance+Adversarial+Training+with+Imbalanced+Data)|0|
|[NOVO: Learnable and Interpretable Document Identifiers for Model-Based IR](https://doi.org/10.1145/3583780.3614993)|Zihan Wang, Yujia Zhou, Yiteng Tu, Zhicheng Dou|Renmin University of China, Beijing, China|Model-based Information Retrieval (Model-based IR) has gained attention due to advancements in generative language models. Unlike traditional dense retrieval methods relying on dense vector representations of documents, model-based IR leverages language models to retrieve documents by generating their unique discrete identifiers (docids). This approach effectively reduces the requirements to store separate document representations in an index. Most existing model-based IR approaches utilize pre-defined static docids, i.e., these docids are fixed and are not learnable by training on the retrieval tasks. However, these docids are not specifically optimized for retrieval tasks, which makes it difficult to learn semantics and relationships between documents and achieve satisfactory retrieval performance. To address the above limitations, we propose Neural Optimized VOcabularial (NOVO) docids. NOVO docids are unique n-gram sets identifying each document. They can be generated in any order to retrieve the corresponding document and can be optimized through training to better learn semantics and relationships between documents. We propose to optimize NOVO docids through query denoising modeling and retrieval tasks, allowing for optimizing both semantic and token representations for such docids. Experiments on two datasets under the normal and zero-shot settings show that NOVO exhibits strong performance in more effective and interpretable model-based IR.|基于模型的信息检索(Model-based IR)因为生成语言模型的进步而受到关注。与传统的依赖于文档密集向量表示的密集检索方法不同，基于模型的 IR 利用语言模型通过生成独特的离散标识符(docids)来检索文档。这种方法有效地减少了在索引中存储单独文档表示形式的需求。大多数现有的基于模型的检索方法利用预定义的静态文档，即这些文档是固定的，不能通过检索任务的训练来学习。然而，这些文档并没有针对检索任务进行专门的优化，这使得学习文档之间的语义和关系以及获得令人满意的检索性能变得十分困难。针对上述局限性，我们提出了神经优化词汇表(NOVO)文档。NOVO docids 是唯一的 n-gram 集合，用于标识每个文档。它们可以以任何顺序生成，以检索相应的文档，并且可以通过培训进行优化，以更好地学习文档之间的语义和关系。我们建议通过查询去噪建模和检索任务来优化 NOVO 文档，允许优化此类文档的语义和令牌表示。在两个数据集上的实验表明，NOVO 在更有效、更易于解释的基于模型的 IR 中表现出很强的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NOVO:+Learnable+and+Interpretable+Document+Identifiers+for+Model-Based+IR)|0|
|[WOT-Class: Weakly Supervised Open-world Text Classification](https://doi.org/10.1145/3583780.3615109)|Tianle Wang, Zihan Wang, Weitang Liu, Jingbo Shang|Shanghai Jiao Tong University, Shanghai, China; University of California, San Diego, La Jolla, CA, USA|State-of-the-art weakly supervised text classification methods, while significantly reduced the required human supervision, still requires the supervision to cover all the classes of interest. This is never easy to meet in practice when human explore new, large corpora without complete pictures. In this paper, we work on a novel yet important problem of weakly supervised open-world text classification, where supervision is only needed for a few examples from a few known classes and the machine should handle both known and unknown classes in test time. General open-world classification has been studied mostly using image classification; however, existing methods typically assume the availability of sufficient known-class supervision and strong unknown-class prior knowledge (e.g., the number and/or data distribution). We propose a novel framework WOT-Class that lifts those strong assumptions. Specifically, it follows an iterative process of (a) clustering text to new classes, (b) mining and ranking indicative words for each class, and (c) merging redundant classes by using the overlapped indicative words as a bridge. Extensive experiments on 7 popular text classification datasets demonstrate that WOT-Class outperforms strong baselines consistently with a large margin, attaining 23.33% greater average absolute macro-F1 over existing approaches across all datasets. Such competent accuracy illuminates the practical potential of further reducing human effort for text classification.|最先进的弱监督文本分类方法，虽然大大减少了所需的人工监督，但仍然要求监督覆盖所有感兴趣的类别。当人们在没有完整图片的情况下探索新的、大型的语料库时，这在实践中是不容易实现的。本文研究了弱监督开放世界文本分类的一个新的重要问题。一般的开放世界分类主要是利用图像分类进行研究，然而，现有的分类方法通常假定有足够的已知类监督和强大的未知类先验知识(例如，数字和/或数据分布)。我们提出了一个新的框架 WOT-Class，消除了这些强烈的假设。具体来说，它遵循以下迭代过程: (a)将文本聚类到新类; (b)为每个类挖掘和排序指示性词; (c)通过使用重叠的指示性词作为桥梁来合并冗余类。在7个流行的文本分类数据集上进行的大量实验表明，WOT-Class 一直以大幅度优于强基线，在所有数据集上比现有方法获得23.33% 更高的平均绝对宏 F1。这种称职的准确性说明了进一步减少文本分类工作的实际潜力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=WOT-Class:+Weakly+Supervised+Open-world+Text+Classification)|0|
|[Selecting Top-k Data Science Models by Example Dataset](https://doi.org/10.1145/3583780.3615051)|Mengying Wang, Sheng Guan, Hanchao Ma, Yiyang Bian, Haolai Che, Abhishek Daundkar, Alp Sehirlioglu, Yinghui Wu|Case Western Reserve University, Cleveland, OH, USA|Data analytical pipelines routinely involve various domain-specific data science models. Such models require expensive manual or training effort and often incur expensive validation costs (e.g., via scientific simulation analysis). Meanwhile, high-value models remain to be ad-hocly created, isolated, and underutilized for a broad community. Searching and accessing proper models for data analysis pipelines is desirable yet challenging for users without domain knowledge. This paper introduces ModsNet, a novel MODel SelectioN framework that only requires an Example daTaset. (1) We investigate the following problem: Given a library of pre-trained models, a limited amount of historical observations of their performance, and an "example" dataset as a query, return k models that are expected to perform the best over the query dataset. (2) We formulate a regression problem and introduce a knowledge-enhanced framework using a model-data interaction graph. Unlike traditional methods, (1) ModsNet uses a dynamic, cost-bounded "probe-and-select" strategy to incrementally identify promising pre-trained models in a strict cold-start scenario (when a new dataset without any interaction with existing models is given). (2) To reduce the learning cost, we develop a clustering-based sparsification strategy to prune unpromising models and their interactions. (3) We showcase of ModsNet built on top of a crowdsourced materials knowledge base platform. Our experiments verified its effectiveness, efficiency, and applications over real-world analytical pipelines.|数据分析管道通常涉及各种领域特定的数据科学模型。这样的模型需要昂贵的人工或培训工作，并且经常产生昂贵的验证成本(例如，通过科学模拟分析)。与此同时，高价值的模式仍然是临时创造的，孤立的，未充分利用的一个广泛的社区。对于没有领域知识的用户来说，搜索和访问数据分析管道的适当模型是可取的，但也是具有挑战性的。本文介绍了一种新的 MODel 选择框架 ModsNet，它只需要一个示例数据集。(1)我们研究以下问题: 给定一个预先训练的模型库，有限数量的历史观察它们的性能，以及一个“示例”数据集作为查询，返回预期在查询数据集上表现最好的 k 模型。(2)利用模型-数据交互图构造回归问题并引入知识增强框架。与传统方法不同，(1) ModsNet 使用一种动态的、成本有限的“探测-选择”策略，在一个严格的冷启动场景(当给定一个与现有模型没有任何交互的新数据集时)中增量识别有前景的预先训练的模型。(2)为了降低学习成本，本文提出了一种基于聚类的稀疏化策略，用于修剪无希望模型及其相互作用。(3)我们展示了建立在众包材料知识库平台之上的 ModsNet。我们的实验验证了它的有效性、效率和在实际分析管道上的应用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Selecting+Top-k+Data+Science+Models+by+Example+Dataset)|0|
|[A Multi-Modality Framework for Drug-Drug Interaction Prediction by Harnessing Multi-source Data](https://doi.org/10.1145/3583780.3614765)|Qianlong Wen, Jiazheng Li, Chuxu Zhang, Yanfang Ye|University of Notre Dame, Notre Dame, IN, USA; Brandeis University, Waltham, MA, USA|Drug-drug interaction (DDI), as a possible result of drug combination treatment, could lead to adverse physiological reactions and increasing mortality rates of patients. Therefore, predicting potential DDI has always been an important and challenging issue in medical health applications. Owing to the extensive pharmacological research, we can get access to various drug-related features for DDI predictions; however, most of the existing works on DDI prediction do not incorporate comprehensive features to analyze the DDI patterns. Despite the high performance that the existing works have achieved, the incomplete and noisy information generated from limited sources usually leads to sub-optimal performance and poor generalization ability on the unknown DDI pairs. In this work, we propose a holistic framework, namely Multi-modality Feature Optimal Fusion for Drug-Drug Interaction Prediction (MOF-DDI), that incorporates the features from multiple data sources to resolve the DDI predictions. Specifically, the proposed model jointly considers DDIs literature descriptions, biomedical knowledge graphs, and drug molecular structures to make the prediction. To overcome the issue induced by directly aggregating features in different modalities, we bring a new insight by mapping the representations learned from different sources to a unified hidden space before the combination. The empirical results show that MOF-DDI achieves a large performance gain on different DDI datasets compared with multiple state-of-the-art baselines, especially under the inductive setting.|药物相互作用(DDI)是药物联合治疗的可能结果，可能导致不良生理反应，增加患者的死亡率。因此，预测潜在的 DDI 一直是医疗卫生应用中的一个重要和具有挑战性的问题。由于广泛的药理学研究，我们可以获得各种 DDI 预测的药物相关特征，然而，现有的 DDI 预测工作大多没有包含全面的特征来分析 DDI 模式。尽管现有的工作已经取得了很高的性能，但是由有限信源产生的不完全信息和噪声信息通常会导致未知 DDI 对的性能次优和泛化能力较差。在这项工作中，我们提出了一个整体框架，即多模态特征最优融合药物-药物相互作用预测(MOF-DDI) ，它结合了来自多个数据源的特征来解决 DDI 预测。具体地说，该模型综合考虑了 DDI 文献描述、生物医学知识图和药物分子结构等因素进行预测。为了克服在不同模式下直接聚合特征所引起的问题，我们将从不同来源学到的表征映射到合并前的统一隐藏空间，提出了一种新的观点。实验结果表明，MOF-DDI 在不同的 DDI 数据集上，特别是在归纳设置下，比多个最新的基线数据集获得了更大的性能增益。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Multi-Modality+Framework+for+Drug-Drug+Interaction+Prediction+by+Harnessing+Multi-source+Data)|0|
|[Prompt-and-Align: Prompt-Based Social Alignment for Few-Shot Fake News Detection](https://doi.org/10.1145/3583780.3615015)|Jiaying Wu, Shen Li, Ailin Deng, Miao Xiong, Bryan Hooi|National University of Singapore, Singapore, Singapore|Despite considerable advances in automated fake news detection, due to the timely nature of news, it remains a critical open question how to effectively predict the veracity of news articles based on limited fact-checks. Existing approaches typically follow a "Train-from-Scratch" paradigm, which is fundamentally bounded by the availability of large-scale annotated data. While expressive pre-trained language models (PLMs) have been adapted in a "Pre-Train-and-Fine-Tune" manner, the inconsistency between pre-training and downstream objectives also requires costly task-specific supervision. In this paper, we propose "Prompt-and-Align" (P&A), a novel prompt-based paradigm for few-shot fake news detection that jointly leverages the pre-trained knowledge in PLMs and the social context topology. Our approach mitigates label scarcity by wrapping the news article in a task-related textual prompt, which is then processed by the PLM to directly elicit task-specific knowledge. To supplement the PLM with social context without inducing additional training overheads, motivated by empirical observation on user veracity consistency (i.e., social users tend to consume news of the same veracity type), we further construct a news proximity graph among news articles to capture the veracity-consistent signals in shared readerships, and align the prompting predictions along the graph edges in a confidence-informed manner. Extensive experiments on three real-world benchmarks demonstrate that P&A sets new states-of-the-art for few-shot fake news detection performance by significant margins.|尽管假新闻自动检测技术取得了长足的进步，但由于新闻的及时性，如何在有限的事实核查基础上有效地预测新闻报道的真实性仍然是一个悬而未决的问题。现有的方法通常遵循“从头开始训练”的范式，这种范式从根本上受到大规模注释数据可用性的限制。虽然表达式预训练语言模型(PLM)已经以“预训练和微调”的方式进行了调整，但预训练和下游目标之间的不一致性也需要昂贵的特定任务监督。在本文中，我们提出了“提示-对齐”(P & A) ，一个新颖的基于提示的范例，用于少拍摄假新闻检测，共同利用 PLM 中的预训练知识和社会上下文拓扑。我们的方法通过将新闻文章包装在一个与任务相关的文本提示符中来缓解标签稀缺性，然后由 PLM 处理该提示符直接获取特定任务的知识。为了在不引入额外培训开销的情况下，通过对用户准确性一致性(即社交用户倾向于消费相同准确性类型的新闻)的实证观察来补充 PLM，我们进一步构建了新闻文章之间的新闻接近度图，以捕获共享读者群中的准确性一致信号，并以信心知情的方式沿图边缘对齐提示预测。在三个现实世界的基准上进行的大量实验表明，P & A 为几乎没有镜头的假新闻检测性能提供了新的最高水平。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Prompt-and-Align:+Prompt-Based+Social+Alignment+for+Few-Shot+Fake+News+Detection)|0|
|[Community-Based Hierarchical Positive-Unlabeled (PU) Model Fusion for Chronic Disease Prediction](https://doi.org/10.1145/3583780.3614818)|Yang Wu, Xurui Li, Xuhong Zhang, Yangyang Kang, Changlong Sun, Xiaozhong Liu|Indiana University Bloomington, Bloomington, IN, USA; Alibaba Group, Hangzhou, China; Worcester Polytechnic Institute, Worcester, MA, USA|Positive-Unlabeled (PU) Learning is a challenge presented by binary classification problems where there is an abundance of unlabeled data along with a small number of positive data instances, which can be used to address chronic disease screening problem. State-of-the-art PU learning methods have resulted in the development of various risk estimators, yet they neglect the differences among distinct populations. To address this issue, we present a novel Positive-Unlabeled Learning Tree (PUtree) algorithm. PUtree is designed to take into account communities such as different age or income brackets, in tasks of chronic disease prediction. We propose a novel approach for binary decision-making, which hierarchically builds community-based PU models and then aggregates their deliverables. Our method can explicate each PU model on the tree for the optimized non-leaf PU node splitting. Furthermore, a mask-recovery data augmentation strategy enables sufficient training of the model in individual communities. Additionally, the proposed approach includes an adversarial PU risk estimator to capture hierarchical PU-relationships, and a model fusion network that integrates data from each tree path, resulting in robust binary classification results. We demonstrate the superior performance of PUtree as well as its variants on two benchmarks and a new diabetes-prediction dataset.|阳性未标记(PU)学习是由二元分类问题提出的一个挑战，其中存在大量的未标记数据和少量的阳性数据实例，可用于解决慢性疾病筛查问题。最先进的 PU 学习方法导致了各种风险评估的发展，但它们忽略了不同人群之间的差异。为了解决这个问题，我们提出了一种新的正无标记学习树(PUtree)算法。PUtree 的设计是为了在慢性病预测任务中考虑到不同年龄段或收入等级的社区。我们提出了一种新的二元决策方法，它分层建立基于社区的 PU 模型，然后聚合它们的可交付成果。我们的方法可以解释树上的每个 PU 模型来优化无叶 PU 节点的分裂。此外，掩码恢复数据增强策略可以在个别社区中对模型进行充分的培训。此外，提出的方法还包括一个对抗性 PU 风险估计器来捕获分层的 PU 关系，以及一个模型融合网络，该网络整合来自每个树路径的数据，从而产生鲁棒的二进制分类结果。我们在两个基准和一个新的糖尿病预测数据集上展示了 PUtree 及其变体的优越性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Community-Based+Hierarchical+Positive-Unlabeled+(PU)+Model+Fusion+for+Chronic+Disease+Prediction)|0|
|[Rethinking Sentiment Analysis under Uncertainty](https://doi.org/10.1145/3583780.3615034)|Yuefei Wu, Bin Shi, Jiarun Chen, Yuhang Liu, Bo Dong, Qinghua Zheng, Hua Wei|Arizona State University, Phoenix, AZ, USA; Xi'an Jiaotong University, Xi'an, China|Sentiment Analysis (SA) is a fundamental task in natural language processing, which is widely used in public decision-making. Recently, deep learning have demonstrated great potential to deal with this task. However, prior works have mostly treated SA as a deterministic classification problem, and meanwhile, without quantifying the predictive uncertainty. This presents a serious problem in the SA, different annotator, due to the differences in beliefs, values, and experiences, may have different perspectives on how to label the text sentiment. Such situation will lead to inevitable data uncertainty and make the deterministic classification models feel puzzle to make decision. To address this issue, we propose a new SA paradigm with the consideration of uncertainty and conduct an expensive empirical study. Specifically, we treat SA as the regression task and introduce uncertainty quantification to obtain confidence intervals for predictions, which enables the risk assessment ability of the model and can improve the credibility of SA-aids decision-making. Experiments on five datasets show that our proposed new paradigm effectively quantifies uncertainty in SA while remaining competitive performance to point estimation, in addition to being capable of Out-Of-Distribution~(OOD) detection.|情感分析是自然语言处理中的一项基础性工作，在公共决策中得到了广泛的应用。近年来，深度学习在解决这一问题上显示出巨大的潜力。然而，以往的工作大多将模拟退火视为一个确定性的分类问题，同时没有量化预测的不确定性。由于信仰、价值观和经验的差异，不同的注释者对于如何标注文本情感可能有不同的看法。这种情况将导致不可避免的数据不确定性，使确定性分类模型感到困惑而作出决策。为了解决这个问题，我们提出了一个考虑不确定性的 SA 范式，并进行了一个昂贵的实证研究。具体来说，我们将模拟退火作为回归任务，引入不确定性量化来获得预测的置信区间，从而使模型具有风险评估能力，提高了模拟退火辅助决策的可信度。在5个数据集上的实验表明，我们提出的新范式有效地量化了 SA 中的不确定性，同时保持了对点估计的竞争性能，此外还能够检测到外部分布的 ~ (OOD)。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rethinking+Sentiment+Analysis+under+Uncertainty)|0|
|[HiPo: Detecting Fake News via Historical and Multi-Modal Analyses of Social Media Posts](https://doi.org/10.1145/3583780.3614914)|Tianshu Xiao, Sichang Guo, Jingcheng Huang, Riccardo Spolaor, Xiuzhen Cheng|Shandong University, Qingdao, China|In recent years, fake news has been a primary concern as it plays a significant role in influencing the political, economic, and social spheres. The scientific community has proposed several solutions to detect such fraudulent information. However, such solutions are unsuitable for social media posts since they cannot extract sufficient information from one-line textual and graphical content or are highly dependent on prior knowledge, which may be unavailable in the case of unprecedented events (e.g., breaking news). This paper tackles this issue by proposing HiPo, a novel multi-modal historical post-based fake news detection method. By combining the features extracted from the graphical and textual content, HiPo assesses the truthfulness of a social media post by building its historical context from prior off-label posts with high similarity, therefore, achieving online detection without maintaining a context or knowledge database. We evaluate the performance of HiPo via an exhaustive set of experiments involving four real-world datasets. Our method achieves a detection accuracy higher than 84%, outperforming the state-of-the-art methods in most experimental instances.|近年来，假新闻在政治、经济、社会等领域发挥着重要的影响力，成为人们关注的焦点。科学界已经提出了几种方案来检测这种欺诈性信息。然而，这样的解决方案并不适用于社交媒体帖子，因为它们不能从单行文本和图形内容中提取足够的信息，或者高度依赖于先前的知识，而这些知识在发生前所未有的事件(例如突发新闻)时可能无法获得。为了解决这个问题，本文提出了一种新的多模态历史邮政假新闻检测方法—— HiPo。通过结合从图形和文本内容中提取的特征，HiPo 评估了一个社交媒体帖子的真实性，通过建立其历史背景，从以前的标签外的帖子具有高度相似性，因此，实现在线检测，而不需要维护背景或知识数据库。我们通过一系列包含四个现实世界数据集的详尽实验来评估 HiPo 的表现。我们的方法实现了高于84% 的检测准确率，在大多数实验实例中优于最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HiPo:+Detecting+Fake+News+via+Historical+and+Multi-Modal+Analyses+of+Social+Media+Posts)|0|
|[An Efficient Selective Ensemble Learning with Rejection Approach for Classification](https://doi.org/10.1145/3583780.3614780)|Hao Xu, Chiranjeet Chetia|Visa Research, Austin, TX, USA|Recent studies found that selective ensemble learning (e.g., dynamic ensemble selection) shows better predictive performance for classification tasks, compared to traditional static ensemble. However, there are some limitations of the available methods, such as high computational cost and multiple restrictions in base model ranking and aggregation (especially for class-imbalanced data modeling). Besides, the current methods make predictions for all data without measuring the credibility regarding different data patterns. This paper proposes a selective ensemble learning with rejection approach that aggregates base models from a different perspective. The approach introduces rejection measures to quantify base model credibility, and learns how to use the models according to their credibility on different sample patterns. It avoids the complexity in base model ranking and therefore is computationally more efficient than current methods. Any common evaluation metrics can be adopted in the selective ensemble strategy, which allows the developed model to handle class-imbalanced data properly. Also, a global rejection region is developed which indicates whether the ensemble model can provide reliable predictions for the targets. We implement the approach in the modeling of 12 datasets, including both class-imbalanced and class-balanced cases. Results show that the approach significantly reduces the inference time while showing promising performance, compared to 8 dynamic ensemble selection methods in the literature. Feature contributions and impacts of different rejection ratios on performance are also investigated to better demonstrate the approach.|最近的研究发现，与传统的静态集合相比，选择性集成学习(例如，动态集合选择)对分类任务有更好的预测性能。然而，现有的方法存在一些局限性，如计算成本高和基本模型排序和聚合的多重限制(特别是对于类不平衡的数据建模)。此外，目前的方法对所有的数据进行预测，而没有测量关于不同数据模式的可信度。这篇文章提出了一个选择性的集成学习和拒绝方法，从不同的角度聚合了基础模型。该方法引入拒绝测度来量化基本模型的可信度，并学习如何根据模型在不同样本模式上的可信度来使用模型。它避免了基本模型排序的复杂性，因此计算效率比目前的方法。在选择性集成策略中可以采用任何通用的评价指标，使得开发的模型能够正确处理类不平衡的数据。此外，还建立了一个全局抑制区域，用以表明系综模型能否为目标提供可靠的预测。我们在12个数据集的建模中实现了该方法，包括类不平衡和类平衡两种情况。结果表明，与文献中的8种动态集合选择方法相比，该方法在显示出良好性能的同时显著缩短了推理时间。为了更好地验证该方法，还研究了不同拒绝率对性能的影响和特征贡献。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Efficient+Selective+Ensemble+Learning+with+Rejection+Approach+for+Classification)|0|
|[Density-Aware Temporal Attentive Step-wise Diffusion Model For Medical Time Series Imputation](https://doi.org/10.1145/3583780.3614840)|Jingwen Xu, Fei Lyu, Pong C. Yuen|Hong Kong Baptist University, Hong Kong, China; Hong Kong Baptist University, Hong Kong, Hong Kong|Medical time series have been widely employed for disease prediction. Missing data hinders accurate prediction. While existing imputation methods partially solve the problem, there are two challenges for medical time series: (1) High dimensionality: Existing imputation methods existing methods suffer from the trade-off between accuracy and computational efficiency. (2) Irregularity: Medical time series exhibit the dynamic temporal relationship that changes over varying sampling densities. However, existing methods mainly take the stationary mechanism, which struggles with capturing the dynamic temporal relationships. To overcome the above deficiencies, we propose a Density-Aware Temporal Attentive Step-wise Diffusion Model (DA-TASWDM), which imputes each time step based on a non-iterative diffusion model and captures inter-step dependency with the density-aware time similarity. Specifically, DA-TASWDM exploits two novel modules: (1) Density-Aware Temporal Attention (DA-TA): It correlates inter-step values from the time embedding similarity adjusted with varying sampling densities. (2) Non-Iterative Step-wise Diffusion Imputer (NI-SWDI): It directly recovers the missing values at each time step from noise without diffusion iteration. Compared with the existing methods, DA-TASWDM can achieve promising accuracy without sacrificing computational efficiency. Extensive experimental results on three real-world datasets demonstrate that our method can significantly outperform state-of-the-art methods in both imputation and post-imputation performance.|医学时间序列已被广泛应用于疾病预测。缺少数据妨碍准确预测。现有的插补方法虽然部分地解决了这个问题，但是对于医学时间序列来说，仍然存在两个挑战: (1)高维度: 现有的插补方法在精度和计算效率之间存在折衷。(2)不规则性: 医学时间序列表现出随采样密度变化而变化的动态时间关系。然而，现有的方法主要采用平稳机制，难以捕捉动态的时间关系。为了克服上述缺陷，我们提出了一种基于非迭代扩散模型的密度感知时态注意逐步扩散模型(DA-TASWDM) ，该模型基于非迭代扩散模型计算每个时间步长，并捕获具有密度感知时间相似性的步间相关性。具体而言，DA-TASWDM 采用了两个新颖的模块: (1)密度感知时间注意(DA-TA) : 它通过改变采样密度来调整时间嵌入相似度的步间值。(2)非迭代逐步扩散计算器(NI-SWDI) : 它不需要扩散迭代，直接从噪声中恢复每个时间步的缺失值。与现有方法相比，DA-TASWDM 在不牺牲计算效率的前提下，能够获得较高的精度。在三个实际数据集上的大量实验结果表明，该方法在插补性能和插补后性能方面都明显优于最新的插补方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Density-Aware+Temporal+Attentive+Step-wise+Diffusion+Model+For+Medical+Time+Series+Imputation)|0|
|[Minimizing Polarization in Noisy Leader-Follower Opinion Dynamics](https://doi.org/10.1145/3583780.3614968)|Wanyue Xu, Zhongzhi Zhang|Fudan University, Shanghai, China|The operation of creating edges has been widely applied to optimize relevant quantities of opinion dynamics. In this paper, we consider a problem of polarization optimization for the leader-follower opinion dynamics in a noisy social network with $n$ nodes and $m$ edges, where a group $Q$ of $q$ nodes are leaders, and the remaining $n-q$ nodes are followers. We adopt the popular leader-follower DeGroot model, where the opinion of every leader is identical and remains unchanged, while the opinion of every follower is subject to white noise. The polarization is defined as the steady-state variance of the deviation of each node's opinion from leaders' opinion, which equals one half of the effective resistance $\mathcal{R}_Q$ between the node group $Q$ and all other nodes. Concretely, we propose and study the problem of minimizing $\mathcal{R}_Q$ by adding $k$ new edges with each incident to a node in $Q$. We show that the objective function is monotone and supermodular. We then propose a simple greedy algorithm with an approximation factor $1-1/e$ that approximately solves the problem in $O((n-q)^3)$ time. To speed up the computation, we also provide a fast algorithm to compute $(1-1/e-\eps)$-approximate effective resistance $\mathcal{R}_Q$, the running time of which is $\Otil (mk\eps^{-2})$ for any $\eps>0$, where the $\Otil (\cdot)$ notation suppresses the ${\rm poly} (\log n)$ factors. Extensive experiment results show that our second algorithm is both effective and efficient.|创建边界运算已被广泛应用于优化相关数量的舆论动力学。本文研究了一类具有 $n $节点和 $m $棱边的噪声社交网络中的领导者-追随者意见动力学的极化优化问题，其中 $q $节点的群体 $Q $为领导者，剩余的 $n-q $节点为追随者。我们采用流行的领导者-追随者 DeGroot 模型，每个领导者的观点都是一致的，并且保持不变，而每个追随者的观点都受到白噪音的影响。极化定义为每个节点的意见偏离领导意见的稳态方差，等于节点组 $Q $与所有其他节点之间的有效阻力 $R } _ Q $的一半。具体地，我们提出并研究了通过在 $Q $中的一个节点上添加每个事件的 $k $新边来使 $mathcal { R } _ Q $最小化的问题。证明了目标函数是单调的、超模的。然后，我们提出了一个简单的贪婪算法，其近似因子为 $1-1/e $，大致可以在 $O ((n-q) ^ 3) $时间内解决问题。为了加快计算速度，我们还提供了一个快速算法来计算 $(1-1/e-ep) $- 近似有效电阻 $数学{ R } _ Q $，其运行时间是 $Otil (mk ep ^ {-2}) $对于任何 $ep > 0 $，其中 $Otil (cdot) $符号抑制 ${ rm poly}(log n) $因子。广泛的实验结果表明，第二种算法是有效和高效的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Minimizing+Polarization+in+Noisy+Leader-Follower+Opinion+Dynamics)|0|
|[Time-series Shapelets with Learnable Lengths](https://doi.org/10.1145/3583780.3615082)|Akihiro Yamaguchi, Ken Ueno, Hisashi Kashima|Toshiba Corporation, Kawasaki, Japan; Kyoto University, Kyoto, Japan|Shapelets are subsequences that are effective for classifying time-series instances. Learning shapelets by a continuous optimization has recently been studied to improve computational efficiency and classification performance. However, existing methods have employed predefined and fixed shapelet lengths during the continuous optimization, despite the fact that shapelets and their lengths are inherently interdependent and thus should be jointly optimized. To efficiently explore shapelets of high quality in terms of interpretability and inter-class separability, this study makes the shapelet lengths continuous and learnable. The proposed formulation jointly optimizes not only a binary classifier and shapelets but also shapelet lengths. The derived SGD optimization can be theoretically interpreted as improving the quality of shapelets in terms of shapelet closeness to the time series for target / off-target classes. We demonstrate improvements in area under the curve, total training time, and shapelet interpretability on UCR binary datasets.|形状是对时间序列实例进行有效分类的子序列。为了提高计算效率和分类性能，最近研究了连续优化学习形状的方法。然而，现有的方法在连续优化过程中采用了预定义和固定的小波长度，尽管事实上小波长度和它们的长度本质上是相互依赖的，因此应该联合优化。为了在可解释性和类间可分性方面有效地探索高质量的形状，本研究使得形状长度是连续的和可学习的。该公式不仅对二元分类器和形状进行了联合优化，而且对形状长度进行了联合优化。推导出的 SGD 优化算法可以从理论上解释为提高目标/非目标类的小波接近时间序列的形状质量。我们在 UCR 二值数据集上展示了曲线下面积、总训练时间和小波可解释性的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Time-series+Shapelets+with+Learnable+Lengths)|0|
|[Few-Shot Learning via Task-Aware Discriminant Local Descriptors Network](https://doi.org/10.1145/3583780.3614883)|Leilei Yan, Fanzhang Li, Xiaohan Zheng, Li Zhang|Soochow University, Suzhou, China|Few-shot learning for image classification task aims to classify images from several novel classes with limited number of samples. Recent studies have shown that the deep local descriptors have better representation ability than image-level features, and achieve great success. However, most of these methods often use all local descriptors or over-screening local descriptors for classification. The former contains some task-irrelevant descriptors, which may misguide the final classification result. The latter is likely to lose some key descriptors. In this paper, we propose a novel Task-Aware Discriminant local descriptors Network (TADNet) to address these issues, which can adaptively select the discriminative query descriptors and eliminate the task-irrelevant query descriptors among the entire task. Specifically, TADNet assigns a value to each query descriptor by comparing its similarity to all support classes to represent its discriminant power for classification. Then the discriminative query descriptors can be preserved via a task-aware attention map. Extensive experiments on both fine-grained and generalized datasets demonstrate that the proposed TADNet outperforms the existing state-of-the-art methods.|图像分类任务中的少镜头学习是针对有限样本数的几类新图像进行分类。近年来的研究表明，深层局部描述符比图像级特征具有更好的表示能力，并取得了很大的成功。然而，大多数这些方法往往使用所有的局部描述符或过度筛选局部描述符进行分类。前者包含一些与任务无关的描述符，可能会误导最终的分类结果。后者可能会丢失一些关键的描述符。针对这些问题，本文提出了一种新的任务感知鉴别局部描述符网络(TADNet) ，该网络可以自适应地选择鉴别查询描述符，消除整个任务中与任务无关的查询描述符。具体来说，TADNet 通过比较每个查询描述符与所有支持类的相似性，为每个查询描述符分配一个值，以表示其分类的判别能力。然后通过任务感知的注意图保留区分查询描述符。在细粒度和广义数据集上的大量实验表明，所提出的 TADNet 优于现有的最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Few-Shot+Learning+via+Task-Aware+Discriminant+Local+Descriptors+Network)|0|
|[A Bipartite Graph is All We Need for Enhancing Emotional Reasoning with Commonsense Knowledge](https://doi.org/10.1145/3583780.3614758)|Kailai Yang, Tianlin Zhang, Shaoxiong Ji, Sophia Ananiadou|University of Helsinki, Helsinki, Finland; The University of Manchester, Manchester, United Kingdom|The context-aware emotional reasoning ability of AI systems, especially in conversations, is of vital importance in applications such as online opinion mining from social media and empathetic dialogue systems. Due to the implicit nature of conveying emotions in many scenarios, commonsense knowledge is widely utilized to enrich utterance semantics and enhance conversation modeling. However, most previous knowledge infusion methods perform empirical knowledge filtering and design highly customized architectures for knowledge interaction with the utterances, which can discard useful knowledge aspects and limit their generalizability to different knowledge sources. Based on these observations, we propose a Bipartite Heterogeneous Graph (BHG) method for enhancing emotional reasoning with commonsense knowledge. In BHG, the extracted context-aware utterance representations and knowledge representations are modeled as heterogeneous nodes. Two more knowledge aggregation node types are proposed to perform automatic knowledge filtering and interaction. BHG-based knowledge infusion can be directly generalized to multi-type and multi-grained knowledge sources. In addition, we propose a Multi-dimensional Heterogeneous Graph Transformer (MHGT) to perform graph reasoning, which can retain unchanged feature spaces and unequal dimensions for heterogeneous node types during inference to prevent unnecessary loss of information. Experiments show that BHG-based methods significantly outperform state-of-the-art knowledge infusion methods and show generalized knowledge infusion ability with higher efficiency. Further analysis proves that previous empirical knowledge filtering methods do not guarantee to provide the most useful knowledge information. Our code is available at: https://github.com/SteveKGYang/BHG.|人工智能系统的上下文感知情感推理能力，尤其是在对话中，在社交媒体和移情对话系统的在线意见挖掘等应用中至关重要。由于在许多场景中表达情感的内隐性，常识性知识被广泛地用于丰富话语语义和加强会话建模。然而，以往的知识灌输方法大多采用经验知识过滤的方法，设计高度自定义的知识交互体系结构，放弃了有用的知识方面，限制了它们对不同知识源的推广能力。在此基础上，我们提出了一种基于常识知识增强情绪推理的二部异质图(BHG)方法。在 BHG 中，提取的上下文感知话语表示和知识表示被建模为异构节点。为了实现知识的自动过滤和交互，提出了两种新的知识聚合节点类型。基于 BHG 的知识灌输可以直接推广到多类型、多粒度的知识源。此外，本文还提出了一种多维异构图形变换器(MHGT)来进行图形推理，在推理过程中对异构节点类型保持不变的特征空间和不等的维数，以防止不必要的信息丢失。实验结果表明，基于 BHG 的方法明显优于现有的知识灌输方法，具有更高的广义知识灌输效率。进一步分析表明，以往的经验知识过滤方法不能保证提供最有用的知识信息。我们的代码可以在以下 https://github.com/stevekgyang/bhg 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Bipartite+Graph+is+All+We+Need+for+Enhancing+Emotional+Reasoning+with+Commonsense+Knowledge)|0|
|[CARPG: Cross-City Knowledge Transfer for Traffic Accident Prediction via Attentive Region-Level Parameter Generation](https://doi.org/10.1145/3583780.3614802)|Guang Yang, Yuequn Zhang, Jinquan Hang, Xinyue Feng, Zejun Xie, Desheng Zhang, Yu Yang|Lehigh University, Bethlehem, PA, USA; Rutgers University, Piscataway, NJ, USA|Traffic accident prediction is a crucial problem for public safety, emergency treatment, and urban management. Existing works leverage extensive data collected from city infrastructures to achieve encouraging performance based on various machine learning techniques but cannot achieve a good performance in situations with limited data (i.e., data scarcity). Recent developments in transfer learning bring a new opportunity to solve the data scarcity problem. In this paper, we design a novel cross-city transfer learning framework named CARPG for predicting traffic accidents in data-scarce cities. We address the unique challenge of predicting traffic accidents caused by its two fundamental characteristics, i.e., spatial heterogeneity and inherent rareness, which result in the biased performance of the state-of-the-art transfer learning methods. Specifically, we build cross-city region connections by jointly learning the spatial region representations for both source and target cities with an inter-city global graph knowledge transfer process. Further, we design an efficient attention-based parameter-generating mechanism to learn region-specific traffic accident patterns, while controlling the total number of parameters. Built upon that, we ensure that only relevant patterns are transferred to each target region during the knowledge transfer process and further to be fine-tuned. We conduct extensive experiments on three real-world datasets, and the evaluation results demonstrate the superiority of our framework compared with state-of-the-art baseline models.|交通事故预测是公共安全、应急处置和城市管理的关键问题。现有的工程利用从城市基础设施中收集的大量数据，基于各种机器学习技术实现令人鼓舞的性能，但在数据有限(即数据稀缺)的情况下无法实现良好的性能。近年来迁移学习的发展为解决数据稀缺问题带来了新的机遇。在本文中，我们设计了一个新颖的跨城市交通事故转移学习框架 CARPG 来预测数据稀缺城市的交通事故。由于交通事故的两个基本特征，即空间异质性和固有的稀有性，导致了最新的迁移学习方法在预测交通事故时存在偏差。具体来说，我们通过城市间全局图形知识转移过程来联合学习源城市和目标城市的空间区域表示，从而建立城市间的区域联系。进一步，我们设计了一个有效的基于注意的参数生成机制来学习区域特定的交通事故模式，同时控制参数的总数。在此基础上，我们确保在知识转移过程中只将相关模式转移到每个目标区域，并进一步进行微调。我们在三个真实世界的数据集上进行了广泛的实验，评估结果显示了我们的框架相对于最先进的基线模型的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CARPG:+Cross-City+Knowledge+Transfer+for+Traffic+Accident+Prediction+via+Attentive+Region-Level+Parameter+Generation)|0|
|[Group Identification via Transitional Hypergraph Convolution with Cross-view Self-supervised Learning](https://doi.org/10.1145/3583780.3614902)|Mingdai Yang, Zhiwei Liu, Liangwei Yang, Xiaolong Liu, Chen Wang, Hao Peng, Philip S. Yu|Salesforce AI Research, Palo Alto, CA, USA; University of Illinois at Chicago, Chicago, IL, USA; Beihang University & Kunming University of Science and Technology, Beijing, China|With the proliferation of social media, a growing number of users search for and join group activities in their daily life. This develops a need for the study on the group identification (GI) task, i.e., recommending groups to users. The major challenge in this task is how to predict users' preferences for groups based on not only previous group participation of users but also users' interests in items. Although recent developments in Graph Neural Networks (GNNs) accomplish embedding multiple types of objects in graph-based recommender systems, they, however, fail to address this GI problem comprehensively. In this paper, we propose a novel framework named Group Identification via Transitional Hypergraph Convolution with Graph Self-supervised Learning (GTGS). We devise a novel transitional hypergraph convolution layer to leverage users' preferences for items as prior knowledge when seeking their group preferences. To construct comprehensive user/group representations for GI task, we design the cross-view self-supervised learning to encourage the intrinsic consistency between item and group preferences for each user, and the group-based regularization to enhance the distinction among group embeddings. Experimental results on three benchmark datasets verify the superiority of GTGS. Additional detailed investigations are conducted to demonstrate the effectiveness of the proposed framework.|随着社交媒体的普及，越来越多的用户在日常生活中搜索和参加小组活动。这就需要对群体识别(GI)任务进行研究，即向用户推荐群体。这项任务的主要挑战是如何预测用户对群组的偏好，不仅基于用户以前的群组参与，而且基于用户对项目的兴趣。尽管近年来图形神经网络(GNN)已经实现了在基于图形的推荐系统中嵌入多种类型的对象，但是它们并没有全面地解决这个 GI 问题。本文提出了一种基于过渡超图卷积的图自监督学习(GTGS)的群体识别方法。我们设计了一个新的过渡超图卷积层，以利用用户的项目偏好作为先验知识时，寻找他们的群体偏好。为了构建 GI 任务的全面的用户/组表示，我们设计了跨视图自监督学习来鼓励每个用户项目和组偏好之间的内在一致性，以及基于组的正则化来增强组嵌入之间的区别。在三个基准数据集上的实验结果验证了 GTGS 算法的优越性。还进行了更多的详细调查，以证明拟议框架的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Group+Identification+via+Transitional+Hypergraph+Convolution+with+Cross-view+Self-supervised+Learning)|0|
|[Mulco: Recognizing Chinese Nested Named Entities through Multiple Scopes](https://doi.org/10.1145/3583780.3615026)|Jiuding Yang, Jinwen Luo, Weidong Guo, Jerry Chen, Di Niu, Yu Xu|University of Alberta, Edmonton, AB, Canada; Platform and Content Group, Tencent, Beijing, China|Nested Named Entity Recognition (NNER) has been a long-term challenge to researchers as an important sub-area of Named Entity Recognition. NNER is where one entity may be part of a longer entity, and this may happen on multiple levels, as the term nested suggests. These nested structures make traditional sequence labeling methods unable to properly recognize all entities. While recent researches focus on designing better recognition methods for NNER in a variety of languages, the Chinese NNER (CNNER) still lacks attention, where a free-for-access, CNNER-specialized benchmark is absent. In this paper, we aim to solve CNNER problems by providing a Chinese dataset and a learning-based model to tackle the issue. To facilitate the research on this task, we release ChiNesE, a CNNER dataset with 20,000 sentences sampled from online passages of multiple domains, containing 117,284 entities failing in 10 categories, where 43.8 percent of those entities are nested. Based on ChiNesE, we propose Mulco, a novel method that can recognize named entities in nested structures through multiple scopes. Each scope use a designed scope-based sequence labeling method, which predicts an anchor and the length of a named entity to recognize it. Experiment results show that Mulco has outperformed several baseline methods with the different recognizing schemes on ChiNesE. We also conduct extensive experiments on ACE2005 Chinese corpus, where Mulco has achieved the best performance compared with the baseline methods.|嵌套命名实体识别(NNER)作为命名实体识别的一个重要分支，长期以来一直是研究者面临的挑战。NNER 是指一个实体可能是一个较长实体的一部分，这可能发生在多个层次上，正如术语嵌套所暗示的那样。这些嵌套结构使得传统的序列标记方法无法正确识别所有实体。目前的研究主要集中在设计多种语言的 NNER 识别方法，但对于中文 NNER (CNNER)识别仍缺乏足够的重视，缺乏自由访问的 CNNER 专用基准。本文旨在通过提供一个中文数据集和一个基于学习的模型来解决 CNNER 问题。为了促进这项任务的研究，我们发布了 ChiNesE，一个 CNNER 数据集，从多个域的在线段落中抽取了20,000个句子，包含117,284个在10个类别中失败的实体，其中43.8% 是嵌套的。提出了一种基于嵌套结构的多作用域命名实体识别方法—— Mulco。每个作用域使用一个设计的基于作用域的序列标记方法，该方法预测一个锚和一个命名实体的长度来识别它。实验结果表明，采用不同的识别方案，Mulco 算法的识别性能优于几种基线方法。我们还在 ACE2005中文语料库上进行了广泛的实验，其中 Mulco 的性能优于基线方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mulco:+Recognizing+Chinese+Nested+Named+Entities+through+Multiple+Scopes)|0|
|[FINRule: Feature Interactive Neural Rule Learning](https://doi.org/10.1145/3583780.3614884)|Lu Yu, Meng Li, YaLin Zhang, Longfei Li, Jun Zhou|Ant Group, Hangzhou, China|Though neural networks have achieved impressive prediction performance, it's still hard for people to understand what neural networks have learned from the data. The black-box property of neural networks already becomes one of the main obstacles preventing from being applied to many high-stakes applications, such as finance and medicine that have critical requirement on the model transparency and interpretability. In order to enhance the explainability of neural networks, we propose a neural rule learning method-Feature Interactive Neural Rule Learning (FINRule) to incorporate the expressivity of neural networks and the interpretability of rule-based systems. Specifically, we conduct rule learning as differential discrete combination encoded by a feedforward neural network, in which each layer acts as a logical operator of explainable decision conditions. The first hidden layer can act as sharable atomic conditions which are connected to next hidden layer for formulating decision rules. Moreover, we propose to represent both atomic condition and rules with contextual embeddings, with aim to enrich the expressivity power by capturing high-order feature interactions. We conduct comprehensive experiments on real-world datasets to validate both effectiveness and explainability of the proposed method.|尽管神经网络已经取得了令人印象深刻的预测性能，但人们仍然很难理解神经网络从数据中学到了什么。神经网络的黑盒特性已经成为阻碍其应用于金融、医药等对模型透明度和可解释性有关键要求的高风险应用领域的主要障碍之一。为了提高神经网络的可解释性，提出了一种神经规则学习方法——特征交互式神经规则学习(FINRule) ，将神经网络的表达能力和基于规则的系统的可解释性结合起来。具体来说，我们将规则学习作为由前馈神经网络编码的微分离散组合，其中每一层作为可解释决策条件的逻辑运算符。第一个隐藏层可以作为可共享的原子条件，这些原子条件连接到下一个隐藏层，用于制定决策规则。此外，我们提出用语境嵌入来表示原子条件和规则，目的是通过捕捉高阶特征交互来丰富表达能力。为了验证该方法的有效性和可解释性，我们对真实世界的数据集进行了全面的实验。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FINRule:+Feature+Interactive+Neural+Rule+Learning)|0|
|[MUSE: Multi-view Contrastive Learning for Heterophilic Graphs via Information Reconstruction](https://doi.org/10.1145/3583780.3614985)|Mengyi Yuan, Minjie Chen, Xiang Li|East China Normal University, Shanghai, China|In recent years, self-supervised learning has emerged as a promising approach in addressing the issues of label dependency and poor generalization performance in traditional GNNs. However, existing self-supervised methods have limited effectiveness on heterophilic graphs, due to the homophily assumption that results in similar node representations for connected nodes. In this work, we propose a multi-view contrastive learning model for heterophilic graphs, namely, MUSE. Specifically, we construct two views to capture the information of the ego node and its neighborhood by GNNs enhanced with contrastive learning, respectively. Then we integrate the information from these two views to fuse the node representations. Fusion contrast is utilized to enhance the effectiveness of fused node representations. Further, considering that the influence of neighboring contextual information on information fusion may vary across different ego nodes, we employ an information fusion controller to model the diversity of node-neighborhood similarity at both the local and global levels. Finally, an alternating training scheme is adopted to ensure that unsupervised node representation learning and information fusion controller can mutually reinforce each other. We conduct extensive experiments to evaluate the performance of MUSE on 9 benchmark datasets. Our results show the effectiveness of MUSE on both node classification and clustering tasks. We provide our data and codes at https://github.com/dcxr969/MUSE.|近年来，自监督学习已经成为解决传统 GNN 中标签依赖和泛化性能差等问题的一种有前途的方法。然而，现有的自监督方法对异质图的有效性是有限的，因为同质假设会导致连通节点的相似节点表示。在这项工作中，我们提出了一个异质图的多视图对比学习模型，即 MUSE。具体来说，我们构造了两个视图，分别通过对比学习增强的 GNN 来捕获自我节点及其邻域的信息。然后我们整合这两个视图的信息来融合节点表示。融合对比度用于提高融合节点表示的有效性。此外，考虑到相邻上下文信息对信息融合的影响在不同的自我节点之间可能不同，我们采用信息融合控制器在局部和全局两个层次上对节点-邻域相似性的多样性进行建模。最后，采用交替训练方案，保证无监督节点表示学习与信息融合控制相互补充。我们进行了广泛的实验来评估 MUSE 在9个基准数据集上的性能。我们的结果显示了 MUSE 在节点分类和聚类任务上的有效性。我们在 https://github.com/dcxr969/muse 提供数据和代码。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MUSE:+Multi-view+Contrastive+Learning+for+Heterophilic+Graphs+via+Information+Reconstruction)|0|
|[Target-Oriented Maneuver Decision for Autonomous Vehicle: A Rule-Aided Reinforcement Learning Framework](https://doi.org/10.1145/3583780.3615072)|Ximu Zeng, Quanlin Yu, Shuncheng Liu, Yuyang Xia, Han Su, Kai Zheng|Yangtze Delta Region Institute (Quzhou), University of Electronic Science and Technology of China, Quzhou, China; University of Electronic Science and Technology of China, Chengdu, China|Autonomous driving systems (ADSs) have the potential to revolutionize transportation by improving traffic safety and efficiency. As the core component of ADSs, maneuver decision aims to make tactical decisions to accomplish road following, obstacle avoidance, and efficient driving. In this work, we consider a typical but rarely studied task, called Target-Lane-Entering (TLE), where an autonomous vehicle should enter a target lane before reaching an intersection to ensure a smooth transition to another road. For navigation-assisted autonomous driving, a maneuver decision module chooses the optimal timing to enter the target lane in each road section, thus avoiding rerouting and reducing travel time. To achieve the TLE task, we propose a ruLe-aided reINforcement lEarning framework, called LINE, which combines the advantages of RL-based policy and rule-based strategy, allowing the autonomous vehicle to make target-oriented maneuver decisions. Specifically, an RL-based policy with a hybrid reward function is able to make safe, efficient, and comfortable decisions while considering the factors of target lanes. Then a strategy of rule revision aims to help the policy learn from intervention and block the risk of missing target lanes. Extensive experiments based on the SUMO simulator confirm the effectiveness of our framework. The results show that LINE achieves state-of-the-art driving performance with over 95% task success rate.|自主驾驶系统(ADS)具有通过提高交通安全性和效率来彻底改变交通的潜力。机动决策作为自动驾驶系统的核心组成部分，其目的是为了实现道路跟踪、避障和高效驾驶而进行战术决策。在这项工作中，我们考虑了一个典型但很少被研究的任务，称为目标车道进入(TLE) ，其中无人机应该在到达一个十字路口之前进入一个目标车道，以确保平稳过渡到另一条道路。对于导航辅助自主驾驶，机动决策模块选择最佳时机进入每个路段的目标车道，从而避免了改道，减少了行驶时间。为了完成 TLE 任务，我们提出了一个基于规则的辅助强化学习框架，称为 LINE，它结合了基于规则的策略和基于规则的策略的优势，允许无人机做出面向目标的机动决策。具体来说，基于 RL 的混合报酬策略能够在考虑目标车道因素的情况下做出安全、有效和舒适的决策。然后采用规则修正策略，帮助政策从干预中吸取教训，防止错过目标车道的风险。基于 SUMO 模拟器的大量实验证实了该框架的有效性。结果表明，LINE 具有最先进的驱动性能，任务成功率达到95% 以上。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Target-Oriented+Maneuver+Decision+for+Autonomous+Vehicle:+A+Rule-Aided+Reinforcement+Learning+Framework)|0|
|[AKE-GNN: Effective Graph Learning with Adaptive Knowledge Exchange](https://doi.org/10.1145/3583780.3614778)|Liang Zeng, Jin Xu, Zijun Yao, Yanqiao Zhu, Jian Li|Tsinghua University, Beijing, China; University of California, Los Angeles, Los Angeles, CA, USA|Graph Neural Networks (GNNs) have already been widely used in various graph mining tasks. However, recent works reveal that the learned weights (channels) in well-trained GNNs are highly redundant, which inevitably limits the performance of GNNs. Instead of removing these redundant channels for efficiency consideration, we aim to reactivate them to enlarge the representation capacity of GNNs for effective graph learning. In this paper, we propose to substitute these redundant channels with other informative channels to achieve this goal. We introduce a novel GNN learning framework named AKE-GNN, which performs the Adaptive Knowledge Exchange strategy among multiple graph views generated by graph augmentations. AKE-GNN first trains multiple GNNs each corresponding to one graph view to obtain informative channels. Then, AKE-GNN iteratively exchanges redundant channels in the weight parameter matrix of one GNN with informative channels of another GNN in a layer-wise manner. Additionally, existing GNNs can be seamlessly incorporated into our framework. AKE-GNN achieves superior performance compared with various baselines across a suite of experiments on node classification, link prediction, and graph classification. In particular, we conduct a series of experiments on 15 public benchmark datasets, 8 popular GNN models, and 3 graph tasks and show that AKE-GNN consistently outperforms existing popular GNN models and even their ensembles. Extensive ablation studies and analyses on knowledge exchange methods validate the effectiveness of AKE-GNN.|图神经网络(GNN)已经广泛应用于各种图挖掘任务中。然而，最近的研究表明，训练有素的 GNN 中的学习权重(信道)是高度冗余的，这不可避免地限制了 GNN 的性能。我们的目标是重新激活这些冗余通道，以扩大 GNN 的表示能力，从而达到有效的图学习，而不是去除这些冗余通道以考虑效率。在本文中，我们建议用其他信息通道替代这些冗余通道来实现这一目标。本文介绍了一种新的 GNN 学习框架 AKE-GNN，它在通过图增强生成的多个图视图之间执行自适应知识交换策略。AKE-GNN 首先训练多个 GNN，每个 GNN 对应于一个图视图，以获得信息通道。然后，AKE-GNN 将一个 GNN 的权参数矩阵中的冗余信道与另一个 GNN 的信息信道分层迭代地交换。此外，现有的 GNN 可以无缝地合并到我们的框架中。通过一系列关于节点分类、链路预测和图分类的实验，AKE-GNN 获得了比各种基线更好的性能。特别是，我们在15个公共基准数据集、8个流行的 GNN 模型和3个图任务上进行了一系列的实验，结果表明 AKE-GNN 一直优于现有流行的 GNN 模型，甚至优于它们的集合。广泛的消融研究和知识交换方法的分析验证了 AKE-GNN 的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AKE-GNN:+Effective+Graph+Learning+with+Adaptive+Knowledge+Exchange)|0|
|[DYANE: DYnamic Attributed Node rolEs Generative Model](https://doi.org/10.1145/3583780.3614858)|Giselle Zeno, Jennifer Neville|Microsoft Research & Purdue University, West Lafayette, IN, USA; Purdue University, West Lafayette, IN, USA|Recent work has shown that modeling higher-order structures, such as motifs or graphlets, can capture the complex network structure and dynamics in a variety of graph domains (e.g., social sciences, biology, chemistry). However, many dynamic networks are not only rich in structure, but also in content information. For example, an academic citation network has content such as the title and abstracts of the papers. Currently, there is a lack of generative models for dynamic networks that also generate content. To address this gap, in this work we propose DYnamic Attributed Node rolEs (DYANE)-a generative model that (i) captures network structure dynamics through temporal motifs, and (ii) extends the structural roles of nodes in motifs (e.g., a node acting as a hub in a wedge) to roles that generate content embeddings. We evaluate DYANE on real-world networks against other dynamic graph generative model baselines. DYANE outperforms the baselines in graph structure and node behavior, improving the KS score for graph metrics by 21-31% and node metrics by 17-27% on average, and produces content embeddings similar to the observed network. We also derive a methodology to evaluate the content embeddings generated by nodes, taking into account keywords extracted from the content (as topic representations), and using distance metrics.|最近的工作已经表明，建模高阶结构，如图案或图形，可以捕捉复杂的网络结构和动态在各种图形领域(如，社会科学，生物学，化学)。然而，许多动态网络不仅具有丰富的结构，而且具有丰富的内容信息。例如，一个学术引文网络包含论文的标题和摘要等内容。目前，动态网络还缺乏生成内容的生成模型。为了解决这一差距，在这项工作中，我们提出了动态属性节点角色(dYANE)-一个生成模型，(i)捕获网络结构动态通过时间图案，和(ii)扩展结构角色的节点在图案(例如，一个节点作为一个中心在楔形)的角色，生成内容嵌入。我们根据其他动态图形生成模型基线来评估现实世界网络上的 DYANE。DYANE 在图结构和节点行为方面优于基线，平均提高了图度量的 KS 分数21-31% ，节点度量的 KS 分数提高了17-27% ，并且产生了类似于观察网络的内容嵌入。我们还推导了一种评估节点生成的内容嵌入的方法，考虑了从内容中提取的关键字(作为主题表示) ，并使用距离度量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DYANE:+DYnamic+Attributed+Node+rolEs+Generative+Model)|0|
|[TriD-MAE: A Generic Pre-trained Model for Multivariate Time Series with Missing Values](https://doi.org/10.1145/3583780.3615097)|Kai Zhang, Chao Li, Qinmin Yang|Zhejiang University, Hangzhou, China|Multivariate time series(MTS) is a universal data type related to various real-world applications. Data imputation methods are widely used in MTS applications to deal with the frequent data missing problem. However, these methods inevitably introduce biased imputation and training-redundancy problems in downstream training. To address these challenges, we propose TriD-MAE, a generic pre-trained model for MTS data with missing values. Firstly, we introduce TriD-TCN, an end-to-end module based on TCN that effectively extracts temporal features by integrating dynamic kernel mechanisms and a time-flipping trick. Building upon that, we designed an MAE-based pre-trained model as the precursor of specialized downstream models. Our model cooperates with a dynamic positional embedding mechanism to represent the missing information and generate transferable representation through our proposed encoder units. The overall mixed data feed-in strategy and weighted loss function are established to ensure adequate training of the whole model. Comparative experiment results in time series prediction and classification manifest that our TriD-MAE model outperforms the other state-of-the-art methods within six real-world datasets. Moreover, ablation and interpretability experiments are delivered to verify the validity of TriD-MAE's|多变量时间序列(MTS)是一种与各种实际应用相关的通用数据类型。数据填补方法在 MTS 应用中被广泛应用于处理频繁的数据丢失问题。然而，这些方法不可避免地在下游训练中引入了有偏的归责和训练冗余问题。为了应对这些挑战，我们提出了 TriD-MAE，一个通用的 MTS 数据缺失值预训练模型。首先介绍了基于 TCN 的端到端模块 TriD-TCN，该模块集成了动态内核机制和时间翻转技术，有效地提取了时间特征。在此基础上，我们设计了一个基于 MAE 的预训练模型，作为专门的下游模型的前身。该模型采用动态位置嵌入机制来表示缺失的信息，并通过编码单元生成可转移的表示。建立了整体混合数据输入策略和加权损失函数，保证了整个模型的充分训练。时间序列预测和分类的对比实验结果表明，我们的 TriD-MAE 模型在六个实际数据集中优于其他最先进的方法。此外，还进行了烧蚀实验和可解释性实验，验证了 TriD-MAE 方法的有效性|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TriD-MAE:+A+Generic+Pre-trained+Model+for+Multivariate+Time+Series+with+Missing+Values)|0|
|[RDGSL: Dynamic Graph Representation Learning with Structure Learning](https://doi.org/10.1145/3583780.3615023)|Siwei Zhang, Yun Xiong, Yao Zhang, Yiheng Sun, Xi Chen, Yizhu Jiao, Yangyong Zhu|Tencent Weixin Group, Shenzhen, China; University of Illinois Urbana-Champaign, Champaign, IL, USA; Fudan University, Shanghai, China|Temporal Graph Networks (TGNs) have shown remarkable performance in learning representation for continuous-time dynamic graphs. However, real-world dynamic graphs typically contain diverse and intricate noise. Noise can significantly degrade the quality of representation generation, impeding the effectiveness of TGNs in downstream tasks. Though structure learning is widely applied to mitigate noise in static graphs, its adaptation to dynamic graph settings poses two significant challenges. i) Noise dynamics. Existing structure learning methods are ill-equipped to address the temporal aspect of noise, hampering their effectiveness in such dynamic and ever-changing noise patterns. ii) More severe noise. Noise may be introduced along with multiple interactions between two nodes, leading to the re-pollution of these nodes and consequently causing more severe noise compared to static graphs. In this paper, we present RDGSL, a representation learning method in continuous-time dynamic graphs. Meanwhile, we propose dynamic graph structure learning, a novel supervisory signal that empowers RDGSL with the ability to effectively combat noise in dynamic graphs. To address the noise dynamics issue, we introduce the Dynamic Graph Filter, where we innovatively propose a dynamic noise function that dynamically captures both current and historical noise, enabling us to assess the temporal aspect of noise and generate a denoised graph. We further propose the Temporal Embedding Learner to tackle the challenge of more severe noise, which utilizes an attention mechanism to selectively turn a blind eye to noisy edges and hence focus on normal edges, enhancing the expressiveness for representation generation that remains resilient to noise. Our method demonstrates robustness towards downstream tasks, resulting in up to 5.1% absolute AUC improvement in evolving classification versus the second-best baseline.|时态图网络(TGNs)在连续时间动态图的学习表示方面表现出显著的性能。然而，真实世界的动态图通常包含不同和复杂的噪音。噪声可以显著降低表示生成的质量，阻碍 TGN 在下游任务中的有效性。尽管结构学习被广泛应用于降低静态图中的噪声，但其对动态图设置的适应性提出了两个重要的挑战。I)噪音动态。现有的结构学习方法在处理噪声的时间方面装备不足，妨碍了它们在这种动态和不断变化的噪声模式中的有效性。Ii)更严重的噪音。噪声可能随着两个节点之间的多重相互作用而引入，导致这些节点的重新污染，从而导致比静态图更严重的噪声。本文提出了连续时间动态图表示学习方法 RDGSL。同时，我们提出了动态图结构学习，这是一种新颖的监控信号，使 RDGSL 能够有效地对抗动态图中的噪声。为了解决噪声动态问题，我们引入了动态图形滤波器，在这里我们创新地提出了一个动态噪声函数，动态捕获当前和历史噪声，使我们能够评估噪声的时间方面，并生成一个去噪图。我们进一步建议时态嵌入学习器来解决更严重的噪声的挑战，其利用注意机制选择性地对噪声边缘视而不见，从而集中在正常边缘上，增强表示生成的表达能力，仍然对噪声具有弹性。我们的方法证明了对下游任务的鲁棒性，导致高达5.1% 的绝对 AUC 改善进化分类相对第二最佳基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RDGSL:+Dynamic+Graph+Representation+Learning+with+Structure+Learning)|0|
|[PromptST: Prompt-Enhanced Spatio-Temporal Multi-Attribute Prediction](https://doi.org/10.1145/3583780.3615016)|Zijian Zhang, Xiangyu Zhao, Qidong Liu, Chunxu Zhang, Qian Ma, Wanyu Wang, Hongwei Zhao, Yiqi Wang, Zitao Liu|Jinan University, Guangzhou, China; Jilin University, Changchun, China; Jilin University & City University of Hong Kong, Changchun, China; City University of Hong Kong, Hong Kong, Hong Kong; Xi'an Jiaotong University & City University of Hong Kong, Xi'an, China; Michigan State University, East Lansing, MI, USA|In the era of information explosion, spatio-temporal data mining serves as a critical part of urban management. Considering the various fields demanding attention, e.g., traffic state, human activity, and social event, predicting multiple spatio-temporal attributes simultaneously can alleviate regulatory pressure and foster smart city construction. However, current research can not handle the spatio-temporal multi-attribute prediction well due to the complex relationships between diverse attributes. The key challenge lies in how to address the common spatio-temporal patterns while tackling their distinctions. In this paper, we propose an effective solution for spatio-temporal multi-attribute prediction, PromptST. We devise a spatio-temporal transformer and a parameter-sharing training scheme to address the common knowledge among different spatio-temporal attributes. Then, we elaborate a spatio-temporal prompt tuning strategy to fit the specific attributes in a lightweight manner. Through the pretrain and prompt tuning phases, our PromptST is able to enhance the specific spatio-temoral characteristic capture by prompting the backbone model to fit the specific target attribute while maintaining the learned common knowledge. Extensive experiments on real-world datasets verify that our PromptST attains state-of-the-art performance. Furthermore, we also prove PromptST owns good transferability on unseen spatio-temporal attributes, which brings promising application potential in urban computing. The implementation code is available to ease reproducibility.|在信息爆炸时代，时空数据挖掘是城市管理的重要组成部分。考虑到交通状态、人类活动、社会事件等需要关注的各个领域，同时预测多个时空属性可以缓解调控压力，促进智能城市建设。然而，由于不同属性之间关系复杂，目前的研究不能很好地处理时空多属性预测问题。关键的挑战在于如何处理共同的时空模式，同时处理它们的区别。本文提出了一种有效的时空多属性预测方法 PromptST。为了解决不同时空属性之间的共同知识，我们设计了一个时空变换器和一个参数共享训练方案。然后，我们阐述了一个时空提示调优策略，以轻量级的方式适应特定的属性。通过预训练和快速调整阶段，我们的 PromptST 能够通过提示骨干模型来适应特定的目标属性，同时保持所学到的公共知识，从而增强特定的时空特征捕获。在真实世界数据集上的大量实验证明，我们的 PromptST 获得了最先进的性能。此外，我们还证明了 PromptST 在不可见的时空属性上具有良好的可转移性，在城市计算中具有广阔的应用前景。实现代码可用于简化重现性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PromptST:+Prompt-Enhanced+Spatio-Temporal+Multi-Attribute+Prediction)|0|
|[Out of the Box Thinking: Improving Customer Lifetime Value Modelling via Expert Routing and Game Whale Detection](https://doi.org/10.1145/3583780.3615002)|Shijie Zhang, Xin Yan, Xuejiao Yang, Binfeng Jia, Shuangyang Wang|Tencent, Shenzhen, China|Customer lifetime value (LTV) prediction is essential for mobile game publishers trying to optimize the advertising investment for each user acquisition based on the estimated worth. In mobile games, deploying microtransactions is a simple yet effective monetization strategy, which attracts a tiny group of game whales who splurge on in-game purchases. The presence of such game whales may impede the practicality of existing LTV prediction models, since game whales' purchase behaviours always exhibit varied distribution from general users. Consequently, identifying game whales can open up new opportunities to improve the accuracy of LTV prediction models. However, little attention has been paid to applying game whale detection in LTV prediction, and existing works are mainly specialized for the long-term LTV prediction with the assumption that the high-quality user features are available, which is not applicable in the UA stage. In this paper, we propose ExpLTV, a novel multi-task framework to perform LTV prediction and game whale detection in a unified way. In ExpLTV, we first innovatively design a deep neural network-based game whale detector that can not only infer the intrinsic order in accordance with monetary value, but also precisely identify high spenders (i.e., game whales) and low spenders. Then, by treating the game whale detector as a gating network to decide the different mixture patterns of LTV experts assembling, we can thoroughly leverage the shared information and scenario-specific information (i.e., game whales modelling and low spenders modelling). Finally, instead of separately designing a purchase rate estimator for two tasks, we design a shared estimator that can preserve the inner task relationships. The superiority of ExpLTV is further validated via extensive experiments on three industrial datasets.|客户生命周期价值(LTV)预测是手机游戏发行商基于估计价值优化每次用户获取广告投资的关键。在手机游戏中，部署微交易是一种简单而有效的货币化策略，它吸引了一小群游戏巨头在游戏中大肆消费。这种游戏鲸的存在可能会阻碍现有 LTV 预测模型的实用性，因为游戏鲸的购买行为总是表现出不同于一般用户的分布。因此，识别猎鲸可以为提高 LTV 预测模型的准确性开辟新的机会。然而，现有的工作主要是专门用于长期的按揭成数预测，假设有高质量的用户功能，这在 UA 阶段是不适用的。在本文中，我们提出了一个新的多任务框架 ExpLTV，以统一的方式执行 LTV 预测和游戏鲸鱼检测。在 ExpLTV 中，我们首先创新性地设计了一个基于深度神经网络的游戏鲸探测器，它不仅可以根据货币价值推断内在顺序，而且还可以精确地识别高消费者(即，游戏鲸)和低消费者。然后，通过把游戏鲸鱼探测器当作一个门控网络来决定不同的 LTV 专家组合的混合模式，我们可以充分利用共享的信息和特定场景的信息(例如，游戏鲸鱼模型和低消费者模型)。最后，我们设计了一个能够保持内部任务关系的共享估计器，而不是分别设计两个任务的购买率估计器。通过在三个工业数据集上的大量实验，进一步验证了 ExpLTV 的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Out+of+the+Box+Thinking:+Improving+Customer+Lifetime+Value+Modelling+via+Expert+Routing+and+Game+Whale+Detection)|0|
|[No Length Left Behind: Enhancing Knowledge Tracing for Modeling Sequences of Excessive or Insufficient Lengths](https://doi.org/10.1145/3583780.3614988)|Moyu Zhang, Xinning Zhu, Chunhong Zhang, Feng Pan, Wenchen Qian, Hui Zhao|Beijing University of Posts and Telecommunications, Beijing, China|Knowledge tracing (KT) aims to predict students' responses to practices based on their historical question-answering behaviors. However, most current KT methods focus on improving overall AUC, leaving ample room for optimization in modeling sequences of excessive or insufficient lengths. As sequences get longer, computational costs will increase exponentially. Therefore, KT methods usually truncate sequences to an acceptable length, which makes it difficult for models on online service systems to capture complete historical practice behaviors of students with too long sequences. Conversely, modeling students with short practice sequences using most KT methods may result in overfitting due to limited observation samples. To address the above limitations, we propose a model called Sequence-Flexible Knowledge Tracing (SFKT).|知识追踪(KT)旨在根据学生历史问答行为预测学生对实践的反应。然而，大多数当前的 KT 方法侧重于改善整体 AUC，为过长或不足长度的建模序列留下了充足的优化空间。随着序列变长，计算成本将呈指数增长。因此，KT 方法通常将序列截断到一个可接受的长度，这使得在线服务系统的模型很难捕捉到序列过长的学生的完整的历史实践行为。相反，使用大多数 KT 方法对练习序列较短的学生进行建模，由于观察样本有限，可能导致过度拟合。针对上述局限性，本文提出了一种序列柔性知识追踪模型(SFKT)。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=No+Length+Left+Behind:+Enhancing+Knowledge+Tracing+for+Modeling+Sequences+of+Excessive+or+Insufficient+Lengths)|0|
|[Counterfactual Monotonic Knowledge Tracing for Assessing Students' Dynamic Mastery of Knowledge Concepts](https://doi.org/10.1145/3583780.3614827)|Moyu Zhang, Xinning Zhu, Chunhong Zhang, Wenchen Qian, Feng Pan, Hui Zhao|Beijing University of Posts and Telecommunications, Beijing, China|As the core of the Knowledge Tracking (KT) task, assessing students' dynamic mastery of knowledge concepts is crucial for both offline teaching and online educational applications. Since students' mastery of knowledge concepts is often unlabeled, existing KT methods rely on the implicit paradigm of historical practice to mastery of knowledge concepts to students' responses to practices to address the challenge of unlabeled concept mastery. However, purely predicting student responses without imposing specific constraints on hidden concept mastery values does not guarantee the accuracy of these intermediate values as concept mastery values. To address this issue, we propose a principled approach called Counterfactual Monotonic Knowledge Tracing (CMKT), which builds on the implicit paradigm described above by using a counterfactual assumption to constrain the evolution of students' mastery of knowledge concepts.|作为知识跟踪(KT)任务的核心，评估学生对知识概念的动态掌握对离线教学和网络教育应用都至关重要。由于学生对知识概念的掌握往往是未标记的，现有的 KT 方法依赖于历史实践的内隐范式来掌握知识概念，以学生对实践的反应来应对未标记概念掌握的挑战。然而，纯粹预测学生的反应而不对隐藏的概念掌握价值施加特定的限制，并不能保证这些中间价值作为概念掌握价值的准确性。为了解决这一问题，我们提出了一种原则性的方法，称为反事实单调知识追踪(CMKT) ，它建立在上述内隐范式的基础上，通过使用反事实假设来约束学生对知识概念掌握的进化。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Counterfactual+Monotonic+Knowledge+Tracing+for+Assessing+Students'+Dynamic+Mastery+of+Knowledge+Concepts)|0|
|[Non-IID always Bad? Semi-Supervised Heterogeneous Federated Learning with Local Knowledge Enhancement](https://doi.org/10.1145/3583780.3614991)|Chao Zhang, Fangzhao Wu, Jingwei Yi, Derong Xu, Yang Yu, Jindong Wang, Yidong Wang, Tong Xu, Xing Xie, Enhong Chen|University of Science and Technology of China, Hefei, China; Microsoft Research Asia, Beijing, China|Federated learning (FL) is important for privacy-preserving services by training models without collecting raw user data. Most FL algorithms assume all data is annotated, which is impractical due to the high cost of labeling data in real applications. To alleviate the reliance on labeled data, semi-supervised federated learning (SSFL) has been proposed to utilize unlabeled data on clients to improve model performance. However, most existing methods either have privacy issues which share models trained on other clients, or generate pseudo-labels for unlabeled local datasets with the global model, which is usually biased towards the global data distribution. The latter may lead to sub-optimal accuracy of pseudo-labels, due to the gap between the local data distribution and the global model, especially in non-IID settings. In this paper, we propose a semi-supervised heterogeneous federated learning method with local knowledge enhancement, called FedLoKe, which aims to train an accurate global model from both labeled and unlabeled local data with non-IID distributions. Specifically, in FedLoKe, the server maintains a global model to capture global data distribution, and each client learns a local model to capture local data distribution. Since the distribution captured by the local model is aligned with the local data distribution, we utilize it to generate high-accuracy pseudo-labels of the unlabeled dataset for global model training. To prevent the local model from severely overfitting the small number of local labeled data, we further use the exponential moving average and apply the global model to generate pseudo-labels for local modeling training. Experiments on four datasets show the effectiveness of FedLoKe. Our code is available at: https://github.com/zcfinal/FedLoKe.|联邦学习(FL)通过不收集原始用户数据的训练模型对保护隐私的服务非常重要。大多数 FL 算法都假设所有数据都是注释的，这是不切实际的，因为在实际应用中标记数据的成本很高。为了减少对标记数据的依赖，半监督联邦学习(SSFL)已被提出，利用客户端的未标记数据来提高模型的性能。然而，大多数现有的方法或者存在隐私问题，这些隐私问题共享在其他客户机上训练的模型，或者在全局模型下为未标记的本地数据集生成伪标签，这通常偏向于全局数据分布。由于本地数据分布与全局模型之间的差距，特别是在非 IID 设置中，后者可能导致伪标签的准确性不理想。本文提出了一种基于局部知识增强的半监督异构联邦学习方法 FedLoke，该方法旨在从带有非 IID 分布的标记和未标记的局部数据中训练出一个精确的全局模型。具体来说，在 FedLoke 中，服务器维护一个全局模型来捕获全局数据分布，每个客户机学习一个本地模型来捕获本地数据分布。由于局部模型所捕获的分布与局部数据分布是一致的，因此我们利用局部模型生成未标记数据集的高精度伪标签，用于全局模型训练。为了防止局部模型严重过度拟合少量的局部标记数据，我们进一步使用指数移动平均，并应用全局模型生成伪标记进行局部建模训练。在四个数据集上的实验表明了 FedLoke 算法的有效性。我们的代码可以在以下 https://github.com/zcfinal/fedloke 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Non-IID+always+Bad?+Semi-Supervised+Heterogeneous+Federated+Learning+with+Local+Knowledge+Enhancement)|0|
|[Mutual Information-Driven Multi-View Clustering](https://doi.org/10.1145/3583780.3614986)|Lei Zhang, Lele Fu, Tong Wang, Chuan Chen, Chuanfu Zhang|Sun Yat-Sen University, Guangzhou, China|In deep multi-view clustering, three intractable problems are posed ahead of researchers, namely, the complementarity exploration problem, the information preservation problem, and the cluster structure discovery problem. In this paper, we consider the deep multi-view clustering from the perspective of mutual information (MI), and attempt to address the three important concerns with a Mutual Information-Driven Multi-View Clustering (MIMC) method, which extracts the common and view-specific information hidden in multi-view data and constructs a clustering-oriented comprehensive representation. Specifically, three constraints based on MI are devised in response to three issues. Correspondingly, we minimize the MI between the common representation and view-specific representations to exploit the inter-view complementary information. Further, we maximize the MI between the refined data representations and original data representations to preserve the principal information. Moreover, to learn a clustering-friendly comprehensive representation, the MI between the comprehensive embedding space and cluster structure is maximized. Finally, we conduct extensive experiments on six benchmark datasets, and the experimental results indicate that the proposed MIMC outperforms other clustering methods.|在深度多视图聚类中，研究人员面临三个棘手的问题，即互补性探索问题、信息保存问题和聚类结构发现问题。本文从互信息的角度考虑深度多视图聚类问题，尝试用互信息驱动的多视图聚类(MIMC)方法解决深度多视图聚类的三个重要问题，提取隐藏在多视图数据中的公共信息和特定视图信息，构建面向聚类的综合表示。具体而言，针对三个问题设计了基于 MI 的三个约束条件。相应地，我们将公共表示和视图特定表示之间的 MI 最小化，以利用视图间的互补信息。进一步，我们最大化精化数据表示和原始数据表示之间的 MI，以保留主信息。此外，为了学习一种聚类友好的综合表示方法，最大化了综合嵌入空间与聚类结构之间的 MI。最后，我们在六个基准数据集上进行了广泛的实验，实验结果表明所提出的 MIMC 方法优于其他聚类方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mutual+Information-Driven+Multi-View+Clustering)|0|
|[Closed-form Machine Unlearning for Matrix Factorization](https://doi.org/10.1145/3583780.3614811)|Shuijing Zhang, Jian Lou, Li Xiong, Xiaoyu Zhang, Jing Liu|Emory University, Atlanta, GA, USA; Xidian University, Guangzhou, China; Zhejiang University, Guangzhou, China; Xidian University, Xi'an, China|Matrix factorization (MF) is a fundamental model in data mining and machine learning, which finds wide applications in diverse application areas, including recommendation systems with user-item rating matrices, phenotype extraction from electronic health records, and spatial-temporal data analysis for check-in records. The "right to be forgotten" has become an indispensable privacy consideration due to the widely enforced data protection regulations, which allow personal users having contributed their data for model training to revoke their data through a data deletion request. Consequently, it gives rise to the emerging task of machine unlearning for the MF model, which removes the influence of the matrix rows/columns from the trained MF factors upon receiving the deletion requests from the data owners of these rows/columns. The central goal is to effectively remove the influence of the rows/columns to be forgotten, while avoiding the computationally prohibitive baseline approach of retraining from scratch. Existing machine unlearning methods are either designed for single-variable models and not compatible with MF that has two factors as coupled model variables, or require alternative updates that are not efficient enough. In this paper, we propose a closed-form machine unlearning method. In particular, we explicitly capture the implicit dependency between the two factors, which yields the total Hessian-based Newton step as the closed-form unlearning update. In addition, we further introduce a series of efficiency-enhancement strategies by exploiting the structural properties of the total Hessian. Extensive experiments on five real-world datasets from three application areas as well as synthetic datasets validate the efficiency, effectiveness, and utility of the proposed method.|矩阵分解是数据挖掘和机器学习的基本模型，在不同的应用领域有广泛的应用，包括使用用户项目评分矩阵的推荐系统、从电子健康记录中提取表型，以及为签到记录进行时空数据分析。“被遗忘的权利”已成为一个不可或缺的隐私考虑，由于广泛执行的数据保护法规，允许个人用户贡献了他们的数据模型培训，撤销他们的数据通过一个数据删除请求。因此，它产生了 MF 模型的机器学习新任务，消除了训练后的 MF 因子的矩阵行/列在接收到这些行/列的数据所有者的删除请求时的影响。中心目标是有效地消除要忘记的行/列的影响，同时避免从头开始再训练的计算上禁止的基线方法。现有的机器去学习方法要么是为单变量模型设计的，与有两个因素作为耦合模型变量的 MF 不兼容，要么需要不够有效的替代更新。本文提出了一种闭式机器去学习方法。特别地，我们显式地捕捉了这两个因素之间的隐式依赖关系，从而产生了基于 Hessian 的牛顿步作为闭合形式的无学习更新。此外，我们进一步介绍了一系列的效率提高策略，利用结构性质的总黑森。通过对来自三个应用领域的五个实际数据集以及合成数据集的大量实验，验证了该方法的有效性和实用性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Closed-form+Machine+Unlearning+for+Matrix+Factorization)|0|
|[Time-aware Graph Structure Learning via Sequence Prediction on Temporal Graphs](https://doi.org/10.1145/3583780.3615081)|Haozhen Zhang, Xueting Han, Xi Xiao, Jing Bai|Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Microsoft Research Asia, Beijing, China|Temporal Graph Learning, which aims to model the time-evolving nature of graphs, has gained increasing attention and achieved remarkable performance recently. However, in reality, graph structures are often incomplete and noisy, which hinders temporal graph networks (TGNs) from learning informative representations. Graph contrastive learning uses data augmentation to generate plausible variations of existing data and learn robust representations. However, rule-based augmentation approaches may be suboptimal as they lack learnability and fail to leverage rich information from downstream tasks. To address these issues, we propose a Time-aware Graph Structure Learning (TGSL) approach via sequence prediction on temporal graphs, which learns better graph structures for downstream tasks through adding potential temporal edges. In particular, it predicts time-aware context embedding based on previously observed interactions and uses the Gumble-Top-K to select the closest candidate edges to this context embedding. Additionally, several candidate sampling strategies are proposed to ensure both efficiency and diversity. Furthermore, we jointly learn the graph structure and TGNs in an end-to-end manner and perform inference on the refined graph. Extensive experiments on temporal link prediction benchmarks demonstrate that TGSL yields significant gains for the popular TGNs such as TGAT and GraphMixer, and it outperforms other contrastive learning methods on temporal graphs. We will release the code in the future.|时态图学习作为一种对图的时间演化特性进行建模的学习方法，近年来得到了越来越多的关注，并取得了显著的效果。然而，在现实中，图结构往往是不完整和噪声，这阻碍了时间图网络(TGNs)学习信息表示。图形对比学习使用数据增强来生成现有数据的合理变化，并学习健壮的表示。然而，基于规则的增强方法可能是次优的，因为它们缺乏可学性，并且无法从下游任务中利用丰富的信息。为了解决这些问题，我们提出了一种基于时间图序列预测的时间感知图结构学习(TGSL)方法，该方法通过增加潜在的时间边来学习下游任务的图结构。特别是，它预测基于先前观察到的交互的时间感知上下文嵌入，并使用 Gumble-Top-K 选择最接近这种上下文嵌入的候选边缘。此外，本文还提出了几种候选抽样策略，以保证抽样的有效性和多样性。此外，我们还以端到端的方式共同学习图的结构和 TGN，并对精化后的图进行推理。通过对时间链路预测基准的大量实验表明，TGSL 在 TGAT 和 GraphMixer 等流行的时间链路预测基准上取得了显著的效果，并且在时间图上优于其他对比学习方法。我们将来会发布代码。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Time-aware+Graph+Structure+Learning+via+Sequence+Prediction+on+Temporal+Graphs)|0|
|[Mask- and Contrast-Enhanced Spatio-Temporal Learning for Urban Flow Prediction](https://doi.org/10.1145/3583780.3614958)|Xu Zhang, Yongshun Gong, Xinxin Zhang, Xiaoming Wu, Chengqi Zhang, Xiangjun Dong|School of Software, Shandong University, Jinan, China; Key Laboratory of Computing Power Network and Information Security, Ministry of Education, Shandong Computer Science Center, Qilu University of Technology (Shandong Academy of Sciences) & Shandong Provincial Key Laboratory of Computer Networks, Shandong Fundamental Research Center for Computer Science, Jinan, China; Centre for Artificial inteligence, Facuty of Engineering and informalion Technology, Universily of Technology Sydney, Sydney, NSW, Australia|As a critical mission of intelligent transportation systems, urban flow prediction (UFP) benefits in many city services including trip planning, congestion control, and public safety. Despite the achievements of previous studies, limited efforts have been observed on simultaneous investigation of the heterogeneity in both space and time aspects. That is, regional correlations would be variable at different timestamps. In this paper, we propose a spatio-temporal learning framework with mask and contrast enhancements to capture spatio-temporal variabilities among city regions. We devise a mask-enhanced pre-training task to learn latent correlations across the spatial and temporal dimensions, and then a graph-based method is developed to extract the significance of regions by using the inter-regional attention weights. To further acquire contrastive correlations of regions, we elaborate a pre-trained contrastive learning task with the global-local cross-attention mechanism. Thereafter, two well-trained encoders have strong capability to capture latent spatio-temporal representations for the flow forecasting with time-varying. Extensive experiments conducted on real-world urban flow datasets demonstrate that our method compares favorably with other state-of-the-art models.|作为智能交通系统的一项关键任务，城市流量预测(uFP)在许多城市服务领域都有着重要的应用价值，包括出行规划、拥塞控制和公共安全。尽管以前的研究已经取得了一些成果，但是在同时考察空间和时间方面的异质性方面所做的努力还是有限的。也就是说，在不同的时间戳下，地区间的相关性是可变的。在本文中，我们提出了一个具有掩模和对比度增强的时空学习框架来捕捉城市地区之间的时空变量。提出了一种基于面具增强的训练前任务来学习跨时间和空间维度的潜在相关性，然后利用区域间注意权重提取区域的显著性。为了进一步获得区域的对比相关性，我们设计了一个预训练的具有全局-局部交叉注意机制的对比学习任务。此后，两个训练有素的编码器具有强大的能力，捕获潜在的时空表示的流量预测与时变。在真实世界的城市流量数据集上进行的大量实验表明，我们的方法与其他最先进的模型相比具有良好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mask-+and+Contrast-Enhanced+Spatio-Temporal+Learning+for+Urban+Flow+Prediction)|0|
|[A Co-training Approach for Noisy Time Series Learning](https://doi.org/10.1145/3583780.3614759)|Weiqi Zhang, Jianfeng Zhang, Jia Li, Fugee Tsung|The Hong Kong University of Science and Technology, Hong Kong SAR, Hong Kong; The Hong Kong University of Science and Technology (Guangzhou) & Hong Kong University of Science and Technology, Guangzhou & Hong Kong SAR, China; Huawei Noah's Ark Lab, Shenzhen, China|In this work, we focus on robust time series representation learning. Our assumption is that real-world time series is noisy and complementary information from different views of the same time series plays an important role while analyzing noisy input. Based on this, we create two views for the input time series through two different encoders. We conduct co-training based contrastive learning iteratively to learn the encoders. Our experiments demonstrate that this co-training approach leads to a significant improvement in performance. Especially, by leveraging the complementary information from different views, our proposed TS-CoT method can mitigate the impact of data noise and corruption. Empirical evaluations on four time series benchmarks in unsupervised and semi-supervised settings reveal that TS-CoT outperforms existing methods. Furthermore, the representations learned by TS-CoT can transfer well to downstream tasks through fine-tuning.|在这项工作中，我们着重于鲁棒的时间序列表示学习。我们假设现实世界的时间序列是有噪声的，同一时间序列的不同观点的互补信息在分析有噪声的输入时起着重要作用。在此基础上，我们通过两个不同的编码器为输入时间序列创建两个视图。我们反复进行基于协同训练的对比学习来学习编码器。我们的实验表明，这种协同训练方法可以显著提高性能。特别是，通过利用来自不同视图的互补信息，我们提出的 TS-CoT 方法可以减轻数据噪声和腐败的影响。对四个时间序列基准在无监督和半监督情况下的实证评估表明，TS-CoT 优于现有的方法。此外，通过微调，TS-CoT 学到的表示能够很好地传递到下游任务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Co-training+Approach+for+Noisy+Time+Series+Learning)|0|
|[Unleashing the Power of Shared Label Structures for Human Activity Recognition](https://doi.org/10.1145/3583780.3615101)|Xiyuan Zhang, Ranak Roy Chowdhury, Jiayun Zhang, Dezhi Hong, Rajesh K. Gupta, Jingbo Shang|University of California, San Diego, La Jolla, CA, USA; Amazon, Seattle, WA, USA|Current human activity recognition (HAR) techniques regard activity labels as integer class IDs without explicitly modeling the semantics of class labels. We observe that different activity names often have shared structures. For example, "open door" and "open fridge" both have "open" as the action; "kicking soccer ball" and "playing tennis ball" both have "ball" as the object. Such shared structures in label names can be translated to the similarity in sensory data and modeling common structures would help uncover knowledge across different activities, especially for activities with limited samples. In this paper, we propose SHARE, a HAR framework that takes into account shared structures of label names for different activities. To exploit the shared structures, SHARE comprises an encoder for extracting features from input sensory time series and a decoder for generating label names as a token sequence. We also propose three label augmentation techniques to help the model more effectively capture semantic structures across activities, including a basic token-level augmentation, and two enhanced embedding-level and sequence-level augmentations utilizing the capabilities of pre-trained models. SHARE outperforms state-of-the-art HAR models in extensive experiments on seven HAR benchmark datasets. We also evaluate in few-shot learning and label imbalance settings and observe even more significant performance gap.|当前的人类活动识别(HAR)技术将活动标签视为整数类 ID，而没有明确建模类标签的语义。我们注意到，不同的活动名称通常具有共享的结构。例如，“开门”和“开冰箱”都以“开”为动作; “踢足球”和“打网球”都以“球”为对象。标签名称中的这种共享结构可以转化为感官数据中的相似性，建立共同结构模型将有助于揭示不同活动之间的知识，特别是对于样本有限的活动。在本文中，我们提出了 SHARE，一个考虑到不同活动的标签名共享结构的 HAR 框架。为了利用共享结构，SHARE 包括用于从输入感官时间序列中提取特征的编码器和用于生成标签名作为标记序列的解码器。我们还提出了三种标签增强技术，以帮助模型更有效地捕获跨活动的语义结构，包括一个基本的令牌级增强，以及两个增强的嵌入级和序列级增强利用预训练模型的能力。在七个 HAR 基准数据集的广泛实验中，SHARE 优于最先进的 HAR 模型。我们也评估在少镜头学习和标签不平衡的设置，并观察到更显着的性能差距。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unleashing+the+Power+of+Shared+Label+Structures+for+Human+Activity+Recognition)|0|
|[AspectMMKG: A Multi-modal Knowledge Graph with Aspect-aware Entities](https://doi.org/10.1145/3583780.3614782)|Jingdan Zhang, Jiaan Wang, Xiaodan Wang, Zhixu Li, Yanghua Xiao|Soochow University, Suzhou, China; Fudan University, Shanghai, China|Multi-modal knowledge graphs (MMKGs) combine different modal data (e.g., text and image) for a comprehensive understanding of entities. Despite the recent progress of large-scale MMKGs, existing MMKGs neglect the multi-aspect nature of entities, limiting the ability to comprehend entities from various perspectives. In this paper, we construct AspectMMKG, the first MMKG with aspect-related images by matching images to different entity aspects. Specifically, we collect aspect-related images from a knowledge base, and further extract aspect-related sentences from the knowledge base as queries to retrieve a large number of aspect-related images via an online image search engine. Finally, AspectMMKG contains 2,380 entities, 18,139 entity aspects, and 645,383 aspect-related images. We demonstrate the usability of AspectMMKG in entity aspect linking (EAL) downstream task and show that previous EAL models achieve a new state-of-the-art performance with the help of AspectMMKG. To facilitate the research on aspect-related MMKG, we further propose an aspect-related image retrieval (AIR) model, that aims to correct and expand aspect-related images in AspectMMKG. We train an AIR model to learn the relationship between entity image and entity aspect-related images by incorporating entity image, aspect, and aspect image information. Experimental results indicate that the AIR model could retrieve suitable images for a given entity w.r.t different aspects.|多模态知识图(MMKGs)将不同的模态数据(例如文本和图像)组合在一起，以便对实体进行全面的理解。尽管大规模 MMKG 近年来取得了一些进展，但是现有的 MMKG 忽视了实体的多面性，限制了从不同角度理解实体的能力。本文通过对不同实体方面的图像进行匹配，构造了第一个具有方面相关图像的 MMKG-AspectMMKG。具体来说，我们从知识库中收集与方面相关的图像，并进一步从知识库中提取与方面相关的句子作为查询，通过在线图像搜索引擎检索大量与方面相关的图像。最后，AspectMMKG 包含2,380个实体、18,139个实体方面和645,383个与方面相关的图像。我们证明了 AspectMMKG 在实体方面连接(EAL)下游任务中的可用性，并表明以前的 EAL 模型在 AspectMMKG 的帮助下取得了新的最佳性能。为了方便对 AspectMMKG 的研究，我们进一步提出了一种 AIR 模型，用于校正和扩展 AspectMMKG 中与 AspectMMKG 相关的图像。我们训练一个 AIR 模型来学习实体图像和实体体相关图像之间的关系，通过合并实体图像、体相和体相图像信息。实验结果表明，AIR 模型能够在给定实体的不同方面提取出合适的图像。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AspectMMKG:+A+Multi-modal+Knowledge+Graph+with+Aspect-aware+Entities)|0|
|[Towards Dynamic and Reliable Private Key Management for Hierarchical Access Structure in Decentralized Storage](https://doi.org/10.1145/3583780.3615090)|Yifang Zhang, Mingyue Wang, Yu Guo, Fangda Guo|Chinese Academy of Sciences, Beijing, China; Beijing Normal University, Beijing, China; City University of Hong Kong, Hong Kong, Hong Kong|With the widespread development of decentralized storage, it is increasingly popular for users to store their data to the decentralized database systems for the well-understood benefits of outsourced storage. To ensure the data privacy, systems commonly require users to securely keep their private keys. Thus, the secure storage of private keys is an important issue in these systems. However, existing key-management schemes commonly rely on a Trusted Third Party (TTP), which raises critical security concerns such as the single point of failure and Distributed Denial of Service (DDoS) attacks. In this paper, we propose HasDPSS, a secure and efficient blockchain-based key-management scheme for decentralized storage systems. It uses secret sharing, a lightweight cryptographic technique, to build the decentralized key-management scheme. Considering that the reliability of managing participants has inherent heterogeneity, we introduce the hierarchical access structure to achieve fine-grained key management. Meanwhile, to adapt the node churn of decentralized key management, HasDPSS enables a dynamic management committee to provide reliable services with a proactive refresh mechanism while protecting the integrity and security of private keys. In our design, we use the dimension switch method of polynomials in the evolving process to achieve the committee change of the hierarchical access structure. The reliability of participants is guaranteed by the customized commitment protocol and the immutable property of the blockchain. We thoroughly analyze security strengths and conduct extensive experiments to demonstrate the practicality of our design.|随着分散存储的广泛发展，用户将数据存储到分散数据库系统中以获得外包存储的好处越来越受欢迎。为了确保数据的私密性，系统通常要求用户安全地保存他们的私钥。因此，私钥的安全存储是这些系统中的一个重要问题。然而，现有的密钥管理方案通常依赖可信第三方(tTP) ，这引起了严重的安全问题，例如单点故障和分布式分布式拒绝服务攻击(dDoS)攻击。本文提出了一种基于区块链的分散存储系统密钥管理方案 HasDPSS。它使用秘密共享这种轻量级密码技术来构建分散式密钥管理方案。考虑到管理参与者的可靠性具有内在的异构性，引入分层访问结构实现细粒度密钥管理。同时，为了适应分散密钥管理的节点流失，HasDPSS 使得动态管理委员会能够在保护私钥完整性和安全性的同时，通过主动刷新机制提供可靠的服务。在我们的设计中，我们使用多项式在演化过程中的维数切换方法来实现层级访问结构的委员会变化。定制的承诺协议和区块链的不变性保证了参与者的可靠性。我们深入分析了安全优势，并进行了广泛的实验，以证明我们的设计的实用性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Dynamic+and+Reliable+Private+Key+Management+for+Hierarchical+Access+Structure+in+Decentralized+Storage)|0|
|[MLPST: MLP is All You Need for Spatio-Temporal Prediction](https://doi.org/10.1145/3583780.3614969)|Zijian Zhang, Ze Huang, Zhiwei Hu, Xiangyu Zhao, Wanyu Wang, Zitao Liu, Junbo Zhang, S. Joe Qin, Hongwei Zhao|Lingnan University, Hong Kong, Hong Kong; Jinan University, Guangzhou, China; City University of Hong Kong, Hong Kong, China; JD Intelligent Cities Research & JD iCity, JD Technology, Beijing, China; Jilin University, Changchun, China; City University of Hong Kong, Hong Kong, Hong Kong|Traffic prediction is a typical spatio-temporal data mining task and has great significance to the public transportation system. Considering the demand for its grand application, we recognize key factors for an ideal spatio-temporal prediction method: efficient, lightweight, and effective. However, the current deep model-based spatio-temporal prediction solutions generally own intricate architectures with cumbersome optimization, which can hardly meet these expectations. To accomplish the above goals, we propose an intuitive and novel framework, MLPST, a pure multi-layer perceptron architecture for traffic prediction. Specifically, we first capture spatial relationships from both local and global receptive fields. Then, temporal dependencies in different intervals are comprehensively considered. Through compact and swift MLP processing, MLPST can well capture the spatial and temporal dependencies while requiring only linear computational complexity, as well as model parameters that are more than an order of magnitude lower than baselines. Extensive experiments validated the superior effectiveness and efficiency of MLPST against advanced baselines, and among models with optimal accuracy, MLPST achieves the best time and space efficiency.|交通预测是一个典型的时空数据挖掘任务，对公共交通系统具有重要意义。考虑到其广泛应用的需求，我们认识到一个理想的时空预测方法的关键因素: 高效、轻量和有效。然而，目前基于深度模型的时空预测解决方案通常具有复杂的体系结构和繁琐的优化，难以满足这些期望。为了实现上述目标，我们提出了一个直观和新颖的框架，MLPST，一个纯粹的多层感知器体系结构的交通预测。具体来说，我们首先从局部和全局接收字段捕获空间关系。然后，综合考虑不同区间的时间依赖关系。通过紧凑和快速的 MLP 处理，MLPST 可以很好地捕获空间和时间的依赖性，同时只需要线性计算复杂度，以及比基线低一个数量级以上的模型参数。大量的实验验证了 MLPST 算法对高精度基线的有效性和效率，在精度最高的模型中，MLPST 算法获得了最佳的时间和空间效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MLPST:+MLP+is+All+You+Need+for+Spatio-Temporal+Prediction)|0|
|[Geometric Graph Learning for Protein Mutation Effect Prediction](https://doi.org/10.1145/3583780.3614893)|Kangfei Zhao, Yu Rong, Biaobin Jiang, Jianheng Tang, Hengtong Zhang, Jeffrey Xu Yu, Peilin Zhao|Hong Kong University of Science and Technology, Hong Kong, China; Beijing Institute of Technology, Tencent AI Lab, None, China; The Chinese University of Hong Kong, Hong Kong, China; Tencent AI Lab, Shenzhen, China|Proteins govern a wide range of biological systems. Evaluating the changes in protein properties upon protein mutation is a fundamental application of protein design, where modeling the 3D protein structure is a principal task for AI-driven computational approaches. Existing deep learning (DL) approaches represent the protein structure as a 3D geometric graph and simplify the graph modeling to different degrees, thereby failing to capture the low-level atom patterns and high-level amino acid patterns simultaneously. In addition, limited training samples with ground truth labels and protein structures further restrict the effectiveness of DL approaches. In this paper, we propose a new graph learning framework, Hierarchical Graph Invariant Network (HGIN), a fine-grained and data-efficient graph neural encoder for encoding protein structures and predicting the mutation effect on protein properties. For fine-grained modeling, HGIN hierarchically models the low-level interactions of atoms and the high-level interactions of amino acid residues by Graph Neural Networks. For data efficiency, HGIN preserves the invariant encoding for atom permutation and coordinate transformation, which is an intrinsic inductive bias of property prediction that bypasses data augmentations. We integrate HGIN into a Siamese network to predict the quantitative effect on protein properties upon mutations. Our approach outperforms 9 state-of-the-art approaches on 3 protein datasets. More inspiringly, when predicting the neutralizing ability of human antibodies against COVID-19 mutant viruses, HGIN achieves an absolute improvement of 0.23 regarding the Spearman coefficient.|蛋白质控制着广泛的生物系统。评估蛋白质突变后蛋白质特性的变化是蛋白质设计的一个基本应用，其中建立三维蛋白质结构是人工智能驱动的计算方法的主要任务。现有的深度学习(DL)方法将蛋白质结构表示为一个三维几何图形，并对图形建模进行了不同程度的简化，从而无法同时捕获低级原子模式和高级氨基酸模式。此外，有限的训练样本与地面真相标签和蛋白质结构进一步限制了 DL 方法的有效性。本文提出了一种新的图形学习框架——层次图不变网络(HGIN) ，它是一种细粒度、数据高效的图形神经编码器，用于编码蛋白质结构和预测突变对蛋白质性质的影响。对于细粒度建模，HGIN 通过图形神经网络对原子间的低能级相互作用和氨基酸残基间的高能级相互作用进行分层建模。为了提高数据效率，HGIN 保留了原子置换和坐标变换的不变编码，这是一种绕过数据增广的属性预测的内在归纳偏差。我们将 HGIN 整合到一个暹罗网络中，以预测突变对蛋白质特性的定量影响。我们的方法在3个蛋白质数据集上优于9个最先进的方法。更鼓舞人心的是，当预测人类抗体对2019冠状病毒疾病突变病毒的中和能力时，HGIN 在斯皮尔曼系数方面实现了0.23的绝对改善。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Geometric+Graph+Learning+for+Protein+Mutation+Effect+Prediction)|0|
|[Simulating Student Interactions with Two-stage Imitation Learning for Intelligent Educational Systems](https://doi.org/10.1145/3583780.3615060)|Guanhao Zhao, Zhenya Huang, Yan Zhuang, Jiayu Liu, Qi Liu, Zhiding Liu, Jinze Wu, Enhong Chen|Anhui Province Key Laboratory of Big Data Analysis and Application, University of Science and Technology of China & State Key Laboratory of Cognitive Intelligence, Hefei, China; School of Data Science, University of Science and Technology of China & State Key Laboratory of Cognitive Intelligence, Hefei, China; iFLYTEK AI Research (Central China), iFLYTEK Co., Ltd, Hefei, China; School of Computer Science and Technology, University of Science and Technology of China & State Key Laboratory of Cognitive Intelligence, Hefei, China|The fundamental task of intelligent educational systems is to offer adaptive learning services to students, such as exercise recommendations and computerized adaptive testing. However, optimizing required models in these systems would always encounter the collection difficulty of high-quality interaction data in practice. Therefore, establishing a student simulator is of great value since it can generate valid interactions to help optimize models. Existing advances have achieved success but generally suffer from exposure bias and overlook long-term intentions. To tackle these problems, we propose a novel Direct-Adversarial Imitation Student Simulator (DAISim) by formulating it as a Markov Decision Process (MDP), which unifies the workflow of the simulator in training and generating to alleviate the exposure bias and single-step optimization problems. To construct the intentions underlying the complex student interactions, we first propose a direct imitation strategy to mimic the interactions with a simple reward function. Then, we propose an adversarial imitation strategy to learn a rational distribution with the reward given by a parameterized discriminator. Furthermore, we optimize the discriminator in adversarial imitation in a pairwise manner, and the theoretical analysis shows that the pairwise discriminator would improve the generation quality. We conduct extensive experiments on real-world datasets, where the results demonstrate that our DAISim can simulate high-quality student interactions whose distribution is close to real distribution and can promote several downstream services.|智能教育系统的基本任务是为学生提供在线机机器学习服务，如练习推荐和计算机自适应测试。然而，在这些系统中优化所需的模型在实践中总是会遇到收集高质量交互数据的困难。因此，建立一个学生模拟器是非常有价值的，因为它可以产生有效的交互，以帮助优化模型。现有的进展取得了成功，但普遍存在暴露偏见，忽视了长期意图。为了解决这些问题，我们提出了一种新颖的直接对抗模拟学生模拟器(DAISim) ，将其设计为一个马可夫决策过程(mDP) ，统一了模拟器在训练和生成过程中的工作流程，以减少暴露偏差和单步优化问题。为了构建复杂学生互动的意图，我们首先提出了一种直接模仿策略，通过一个简单的奖励函数来模拟学生互动。然后，我们提出了一个对抗模仿策略来学习一个由参数化鉴别器给出报酬的有理分布。进一步，我们以成对的方式优化了对抗模仿中的鉴别器，理论分析表明成对鉴别器可以提高生成质量。我们在真实世界的数据集上进行了广泛的实验，结果表明我们的 DAISim 可以模拟高质量的学生交互，其分布接近真实分布，并可以促进几个下游服务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Simulating+Student+Interactions+with+Two-stage+Imitation+Learning+for+Intelligent+Educational+Systems)|0|
|[Highly-Optimized Forgetting for Creating Signature-Based Views of Ontologies](https://doi.org/10.1145/3583780.3614771)|Yizheng Zhao|Nanjing University, Nanjing, China|Uniform interpolation (UI) is a non-standard reasoning service that seeks to project an ontology down to its sub-signature --- given an ontology taking a certain signature, and a subset Σ of "relevant names'' of that signature, compute a new ontology, called a uniform interpolant, that uses only the relevant names while preserving the semantics of the relevant names in the uniform interpolant. UI is of great potential importance since it may be used in a variety of applications where suitable views of ontologies need to be computed. However, this potential can only be fully realized if a highly optimized method for computing such views exists. Previous research has shown that computing uniform interpolants of ELH-ontologies is a computationally extremely hard problem --- a finite uniform interpolant does not always exist for ELH, and if it exists, then there exists one of at most triple exponential size in terms of the original ontology, and that, in the worst case, no shorter interpolant exists. Despite the inherent difficulty of the problem, in this paper, we present a highly optimized forgetting method for computing uniform interpolants of ELH-ontologies, and show however that, with good reduction and inference strategies, such uniform interpolants can be efficiently computed. The method is an improvement of the one presented in our previous work. What sets it apart is its flexibility to treat concept names of different types differently, effectively cutting down on the inferences involved. This treatment is primarily driven by the polarities of the concept names within an ontology. A comprehensive evaluation with a prototypical implementation of the method shows >95% average success rates over two popular benchmark datasets and demonstrates a clear computational advantage over state-of-the-art systems.|统一插值(UI)是一种非标准的推理服务，它试图将一个本体投射到它的子签名——给定一个带有特定签名的本体，以及该签名的“相关名称”的子集 Σ，计算一个新的本体，称为统一插值，它只使用相关名称，同时在统一插值中保留相关名称的语义。UI 具有很大的潜在重要性，因为它可以用于需要计算合适的本体视图的各种应用程序中。然而，只有存在一种高度优化的计算这种视图的方法，这种潜力才能完全实现。先前的研究已经表明，计算 ELH 本体的一致插值是一个计算上非常困难的问题——-一个有限的一致插值并不总是存在于 ELH 中，如果它存在，那么就存在一个最多三倍指数大小的插值，在最坏的情况下，没有更短的插值存在。本文提出了一种计算 ELH- 本体一致插值的高度优化遗忘方法，并证明了采用良好的约简和推理策略，可以有效地计算 ELH- 本体的一致插值。该方法是对我们以前工作中提出的方法的改进。它之所以与众不同，是因为它可以灵活地区别对待不同类型的概念名称，有效地减少了所涉及的推论。这种处理主要是由本体中概念名称的极性驱动的。通过该方法的原型实现进行的综合评估显示，与两个流行的基准数据集相比，该方法的平均成功率 > 95% ，并且显示出与最先进的系统相比，该方法具有明显的计算优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Highly-Optimized+Forgetting+for+Creating+Signature-Based+Views+of+Ontologies)|0|
|[Unveiling the Role of Message Passing in Dual-Privacy Preservation on GNNs](https://doi.org/10.1145/3583780.3615104)|Tianyi Zhao, Hui Hu, Lu Cheng|University of Southern California, Los Angeles, CA, USA; Wyoming University, Larami, WY, USA; University of Illinois Chicago, Chicago, IL, USA|Graph Neural Networks (GNNs) are powerful tools for learning representations on graphs, such as social networks. However, their vulnerability to privacy inference attacks restricts their practicality, especially in high-stake domains. To address this issue, privacy-preserving GNNs have been proposed, focusing on preserving node and/or link privacy. This work takes a step back and investigates how GNNs contribute to privacy leakage. Through theoretical analysis and simulations, we identify message passing under structural bias as the core component that allows GNNs to \textit{propagate} and \textit{amplify} privacy leakage. Building upon these findings, we propose a principled privacy-preserving GNN framework that effectively safeguards both node and link privacy, referred to as dual-privacy preservation. The framework comprises three major modules: a Sensitive Information Obfuscation Module that removes sensitive information from node embeddings, a Dynamic Structure Debiasing Module that dynamically corrects the structural bias, and an Adversarial Learning Module that optimizes the privacy-utility trade-off. Experimental results on four benchmark datasets validate the effectiveness of the proposed model in protecting both node and link privacy while preserving high utility for downstream tasks, such as node classification.|图形神经网络(GNN)是学习图形表示的强大工具，例如社交网络。然而，它们易受隐私推断攻击的弱点限制了它们的实用性，尤其是在高风险领域。为了解决这个问题，提出了保护隐私的 GNN，重点是保护节点和/或链路的隐私。这项工作退一步来研究 GNN 是如何导致隐私泄露的。通过理论分析和仿真，我们确定了结构偏差下的消息传递是 GNN 发送传播信息和发送放大隐私泄露信息的核心组件。在这些发现的基础上，我们提出了一个原则性的隐私保护 GNN 框架，有效地保护节点和链路的隐私，称为双重隐私保护。该框架由三个主要模块组成: 一个敏感信息模糊模块，从节点嵌入中删除敏感信息; 一个动态结构消偏模块，动态纠正结构偏差; 以及一个对抗性学习模块，优化隐私-效用的权衡。在四个基准数据集上的实验结果验证了该模型在保护节点和链路隐私的同时，对下游任务(如节点分类)保持较高效用的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unveiling+the+Role+of+Message+Passing+in+Dual-Privacy+Preservation+on+GNNs)|0|
|[DiffUFlow: Robust Fine-grained Urban Flow Inference with Denoising Diffusion Model](https://doi.org/10.1145/3583780.3614842)|Yuhao Zheng, Lian Zhong, Senzhang Wang, Yu Yang, Weixi Gu, Junbo Zhang, Jianxin Wang|Central South University, Changsha, China; China Academy of Industrial Internet, Beijing, China; The Hong Kong Polytechnic University, Hong Kong, Hong Kong; JD Intelligent Cities Research, Beijing, China|Inferring the fine-grained urban flows based on the coarse-grained flow observations is practically important to many smart city-related applications. However, the collected human/vehicle trajectory flows are usually rather unreliable, may contain various noise and sometimes are incomplete, thus posing great challenges to existing approaches. In this paper, we present a pioneering study on robust fine-grained urban flow inference with noisy and incomplete urban flow observations, and propose a denoising diffusion model named DiffUFlow to effectively address it. Specifically, we propose an improved reverse diffusion strategy. A spatial-temporal feature extraction network called STFormer and a semantic features extraction network called ELFetcher are also proposed. Then, we overlay the spatial-temporal feature map extracted by STFormer onto the coarse-grained flow map, serving as a conditional guidance for the reverse diffusion process. We further integrate the semantic features extracted by ELFetcher to cross-attention layers, enabling the comprehensive consideration of semantic information encompassing the entirety of urban data in fine-grained inference. Extensive experiments on two large real-world datasets validate the effectiveness of our method compared with the state-of-the-art baselines.|基于粗粒度流观测的细粒度城市流推断对于智能城市相关应用具有重要的实际意义。然而，收集的人/车轨迹流通常是相当不可靠的，可能包含各种噪声，有时是不完整的，从而对现有的方法提出了巨大的挑战。本文首次提出了一种基于噪声和不完全城市流量观测的鲁棒细粒度城市流量推断方法，并提出了一种去噪扩散模型，称之为 DISUFlow，以有效地解决这一问题。具体来说，我们提出了一种改进的反向扩散策略。提出了一种时空特征提取网络 STForm 和一种语义特征提取网络 ELFetcher。在此基础上，将时空特征图叠加到粗粒度流图上，作为反向扩散过程的条件指导。我们进一步将 ELfetcher 提取的语义特征整合到交叉注意层，使得我们能够在细粒度推理中全面考虑包含整个城市数据的语义信息。在两个大型真实世界数据集上的大量实验验证了我们的方法与最先进的基线相比的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DiffUFlow:+Robust+Fine-grained+Urban+Flow+Inference+with+Denoising+Diffusion+Model)|0|
|[Assessing the Continuous Causal Responses of Typhoon-related Weather on Human Mobility: An Empirical Study in Japan](https://doi.org/10.1145/3583780.3615513)|Zhiwen Zhang, Hongjun Wang, Zipei Fan, Ryosuke Shibasaki, Xuan Song|SUSTech, Shenzhen, China; The University of Tokyo, Tokyo, Japan|To understand human mobility following the typhoon, analyzing the causal impact of extreme typhoon weather on human mobility is important for disaster emergency management. However, the unobserved confounders (e.g., the characteristic of each region) correlate with the strength of typhoon weather and also affect human mobility during typhoon, which may generate biased influences on the causal analysis process. Besides, these confounders may be time-varying following the dynamic movements of typhoon. In this work, we develop a neural network-based continuous causal effect estimation framework to mitigate the interference from (unobserved) confounders and assess the continuous causal responses of typhoon-related weather (treatment) on several types of human mobility (outcome) across different counties at any given period. To this end, we integrate the big data from two huge typhoons in Japan (i.e., Typhoon Faxai and Hagibis) and leverage multiple sources of covariates (i.e., residents' vigilance and basic mobility patterns) from different counties to learn the representations of time-varying confounders. The experimental results indicate the effectiveness of our proposed framework in capturing the confounders for quantifying the causal impact of extreme weather during the typhoon process, compared with several existing causal studies.|为了了解台风过后的人员流动情况，分析极端台风天气对人员流动的影响对灾害应急管理具有重要意义。但未观测到的混杂因素(如各区域的特征)与台风天气强度相关，并影响台风期间的人口流动，可能对因果分析过程产生偏差影响。此外，这些混杂因子可能随台风的动态变化而变化。在这项工作中，我们开发了一个基于神经网络的连续因果效应估计框架，以减轻(未观察到的)混杂因素的干扰，并评估台风相关天气(处理)对几种类型的人口流动(结果)的连续因果响应，在不同的县在任何给定的时期。为此，我们整合了来自日本两个巨大台风(即台风法赛和哈吉比斯)的大数据，并利用来自不同县的多个协变量来源(即居民的警觉性和基本流动模式)来学习时变混杂因素的表征。实验结果表明，与已有的因果关系研究相比，我们提出的框架在捕获混杂因子以量化台风过程中极端天气的因果影响方面是有效的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Assessing+the+Continuous+Causal+Responses+of+Typhoon-related+Weather+on+Human+Mobility:+An+Empirical+Study+in+Japan)|0|
|[Learning Node Abnormality with Weak Supervision](https://doi.org/10.1145/3583780.3614950)|Qinghai Zhou, Kaize Ding, Huan Liu, Hanghang Tong|Northwestern University, Evanston, IL, USA; Arizona State University, Tempe, AZ, USA; University of Illinois at Urbana-Champaign, Urbana, IL, USA|Graph anomaly detection aims to identify the atypical substructures and has attracted an increasing amount of research attention due to its profound impacts in a variety of application domains, including social network analysis, security, finance, and many more. The lack of prior knowledge of the ground-truth anomaly has been a major obstacle in acquiring fine-grained annotations (e.g., anomalous nodes), therefore, a plethora of existing methods have been developed either with a limited number of node-level supervision or in an unsupervised manner. Nonetheless, annotations for coarse-grained graph elements (e.g., a suspicious group of nodes), which often require marginal human effort in terms of time and expertise, are comparatively easier to obtain. Therefore, it is appealing to investigate anomaly detection in a weakly-supervised setting and to establish the intrinsic relationship between annotations at different levels of granularity. In this paper, we tackle the challenging problem of weakly-supervised graph anomaly detection with coarse-grained supervision by (1) proposing a novel architecture of graph neural network with attention mechanism named WEDGE that can identify the critical node-level anomaly given a few labels of anomalous subgraphs, and (2) designing a novel objective with contrastive loss that facilitates node representation learning by enforcing distinctive representations between normal and abnormal graph elements. Through extensive evaluations on real-world datasets, we corroborate the efficacy of our proposed method, improving AUC-ROC by up to 16.48% compared to the best competitor.|图形异常检测旨在识别非典型的子结构，由于其在各种应用领域(包括社交网络分析、安全、金融等)的深远影响，已经吸引了越来越多的研究注意力。缺乏对地面真实异常的事先知识一直是获取细粒度注释(例如异常节点)的主要障碍，因此，已经开发了大量现有的方法，要么是有限数量的节点级监督，要么是以无监督的方式。尽管如此，粗粒度图元素(例如，一组可疑的节点)的注释相对容易获得，这些注释通常需要人们在时间和专业知识方面的边际努力。因此，在弱监督环境下研究异常检测，并在不同粒度级别上建立注释之间的内在关系，是很有吸引力的。在本文中，我们解决了粗粒度监督的弱监督图异常检测的挑战性问题，通过(1)提出了一种新的带注意机制的图神经网络结构，称为 WEDGE，它可以识别临界节点级异常，给出几个异常子图的标签，和(2)设计一个新的对比损失的目标，通过强制正常和异常图元之间的独特表示，促进节点表示学习。通过对真实世界数据集的广泛评估，我们证实了我们提出的方法的有效性，与最好的竞争对手相比，AUC-ROC 提高了16.48% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Node+Abnormality+with+Weak+Supervision)|0|
|[Privacy-Preserving Federated Learning via Disentanglement](https://doi.org/10.1145/3583780.3615014)|Wenjie Zhou, Piji Li, Zhaoyang Han, Xiaozhen Lu, Juan Li, Zhaochun Ren, Zhe Liu|Nanjing University of Aeronautics and Astronautics, Nanjing, China; Shandong University, Jinan, China|The trade-off between privacy and accuracy presents a challenge for current federated learning (FL) frameworks, hindering their progress from theory to application. The main issues with existing FL frameworks stem from a lack of interpretability and targeted privacy protections. To cope with these, we proposed Disentangled Federated Learning for Privacy (DFLP) which employes disentanglement, one of interpretability techniques, in private FL frameworks. Since sensitive properties are client-specific in nature, our main idea is to turn this feature into a tool that strikes the balance between data privacy and FL model performance, enabling the sensitive attributes to be private. DFLP disentangles the client-specific and class-invariant attributes to mask the sensitive attributes precisely. To our knowledge, this is the first work that successfully integrates disentanglement and the nature of sensitive attributes to achieve privacy protection while ensuring high FL model performance. Extensive experiments validate that disentanglement is an effective method for accuracy-aware privacy protection in FL frameworks.|隐私和准确性之间的权衡给当前的联邦学习(FL)框架带来了挑战，阻碍了它们从理论到应用的进步。现有 FL 框架的主要问题源于缺乏可解释性和有针对性的隐私保护。为了解决这些问题，我们提出了在私人 FL 框架中采用解释技术之一的“解缠”技术的联邦隐私分离学习(DFLP)。由于敏感属性本质上是特定于客户端的，因此我们的主要想法是将这个特性转换为一个工具，在数据隐私和 FL 模型性能之间取得平衡，使敏感属性成为私有的。DFLP 解开了客户特定属性和类不变属性之间的关系，精确地屏蔽了敏感属性。据我们所知，这是第一个工作，成功地集成解纠缠和敏感属性的性质，以实现隐私保护，同时确保高 FL 模型性能。大量的实验证明，在 FL 框架中，解缠是一种有效的精确隐私保护方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Privacy-Preserving+Federated+Learning+via+Disentanglement)|0|
|[CANDY: A Causality-Driven Model for Hotel Dynamic Pricing](https://doi.org/10.1145/3583780.3614800)|Ruitao Zhu, Wendong Xiao, Yao Yu, Yizhi Yu, Zhenzhe Zheng, Ke Bu, Dong Li, Fan Wu|Shanghai Jiao Tong University, Shanghai, China; Alibaba Group, Hangzhou, China|Broad adoption of online travel platforms (OTPs) has led to increasing focus on hotel dynamic pricing algorithms, which directly affect the revenue of platform and hotels. Existing approaches, which directly model the correlation between price and occupancy, have limitations in improving occupancy prediction accuracy while ensuring interpretability for dynamic pricing. Moreover, these methods struggle to address the significant data sparsity issue in hotel pricing scenarios. To overcome these limitations, we propose a novel Causality-driven Hotel Dynamic Pricing Model (CANDY) that captures the essential causal relationship between price and occupancy, enhancing occupancy prediction accuracy and interpretability for dynamic pricing. Specifically, we decompose confounders into three orthogonal groups of factors: characteristic factors, competitive factors, and temporal factors, and design submodules to capture the features of each dimension. To address the treatment bias and sample imbalance issues faced by existing causal inference methods in hotel pricing scenarios, we propose a novel data augmentation method based on the monotonic relationship between price and occupancy, and further design a multi-task learning framework tailored to multi-valued treatment scenarios, simultaneously alleviating the data sparsity issue. Both offline and online experiments demonstrate the effectiveness of CANDY in occupancy prediction and dynamic pricing. CANDY has been successfully deployed to provide price suggestion service at Fliggy, a leading OTP in China, serving thousands of hotel operators.|在线旅游平台(OTP)的广泛应用导致人们越来越关注酒店动态定价算法，这直接影响到平台和酒店的收入。现有的方法直接模拟价格与入住率之间的相关性，在提高入住率预测精度的同时保证动态定价的可解释性方面存在局限性。此外，这些方法很难解决酒店定价场景中的重大数据稀疏问题。为了克服这些限制，我们提出了一个新的因果关系驱动的酒店动态定价模型(CANDY) ，捕捉价格和入住率之间的基本因果关系，提高入住率预测的准确性和动态定价的可解释性。具体来说，我们将混杂因素分解为三组正交的因素: 特征因素、竞争因素和时间因素，并设计子模块来捕获每个维度的特征。针对现有因果推理方法在酒店定价场景中存在的治疗偏差和样本不平衡问题，提出了一种基于价格与入住率单调关系的数据增强方法，并进一步设计了适合多值治疗场景的多任务学习框架，同时缓解了数据稀疏问题。离线和在线实验都证明了 CANDY 在入住率预测和动态定价方面的有效性。CANDY 已成功部署于 Fliggy，为数以千计的酒店运营商提供价格建议服务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CANDY:+A+Causality-Driven+Model+for+Hotel+Dynamic+Pricing)|0|
|[FVW: Finding Valuable Weight on Deep Neural Network for Model Pruning](https://doi.org/10.1145/3583780.3614889)|Zhiyu Zhu, Huaming Chen, Zhibo Jin, Xinyi Wang, Jiayu Zhang, Minhui Xue, Qinghua Lu, Jun Shen, KimKwang Raymond Choo|The University of Sydney, Sydney, NSW, Australia; SCIT, University of Wollongong, Australia, Wollongong , Australia; Suzhou Yierqi, Suzhou, China; University of Texas at San Antonio, San Antonio, TX, USA; Data61, CSIRO, Sydney, NSW, Australia; Jiangsu University, Zhenjiang, China|The rapid development of deep learning has demonstrated its potential for deployment in many intelligent service systems. However, some issues such as optimisation (e.g., how to reduce the deployment resources costs and further improve the detection speed), especially in scenarios where limited resources are available, remain challenging to address. In this paper, we aim to delve into the principles of deep neural networks, focusing on the importance of network neurons. The goal is to identify the neurons that exert minimal impact on model performances, thereby aiding in the process of model pruning. In this work, we have thoroughly considered the deep learning model pruning process with and without fine-tuning step, ensuring the model performance consistency. To achieve our objectives, we propose a methodology that employs adversarial attack methods to explore deep neural network parameters. This approach is combined with an innovative attribution algorithm to analyse the level of network neurons involvement. In our experiments, our approach can effectively quantify the importance of network neuron. We extend the evaluation through comprehensive experiments conducted on a range of datasets, including CIFAR-10, CIFAR-100 and Caltech101. The results demonstrate that, our method have consistently achieved the state-of-the-art performance over many existing methods. We anticipate that this work will help to reduce the heavy training and inference cost of deep neural network models where a lightweight deep learning enhanced service and system is possible. The source code is open source at https://github.com/LMBTough/FVW.|深度学习的迅速发展已经证明了它在许多智能服务系统中的部署潜力。然而，一些问题，如优化(例如，如何降低部署资源成本和进一步提高检测速度) ，特别是在有限的资源可用的情况下，仍然具有挑战性的解决。本文旨在深入研究深层神经网络的原理，重点研究网络神经元的重要性。目标是识别对模型性能影响最小的神经元，从而有助于模型修剪过程。在这项工作中，我们充分考虑了有和没有微调步骤的深度学习模型修剪过程，保证了模型性能的一致性。为了实现我们的目标，我们提出了一种使用对抗性攻击方法来探索深层神经网络参数的方法。该方法结合了一种创新的归因算法来分析网络神经元参与的水平。在我们的实验中，我们的方法可以有效地量化网络神经元的重要性。我们通过在 CIFAR-10、 CIFAR-100和 Caltech101等一系列数据集上进行的综合实验来扩展评估。结果表明，我们的方法在许多现有的方法中始终达到了最先进的性能。我们期望这项工作将有助于减少沉重的训练和推理成本的深度神经网络模型，其中一个轻量级的深度学习增强服务和系统是可能的。源代码在 https://github.com/lmbtough/fvw 上是开源的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FVW:+Finding+Valuable+Weight+on+Deep+Neural+Network+for+Model+Pruning)|0|
|[Fine-Grained Socioeconomic Prediction from Satellite Images with Distributional Adjustment](https://doi.org/10.1145/3583780.3615226)|Donghyun Ahn, Minhyuk Song, SeungEon Lee, Yubin Choi, Jihee Kim, Sangyoon Park, Hyunjoo Yang, Meeyoung Cha|KAIST, IBS, Daejeon, Republic of Korea; Sogang University, Seoul, Republic of Korea; HKUST, Hong Kong, China; IBS, KAIST, Daejeon, Republic of Korea|While measuring socioeconomic indicators is critical for local governments to make informed policy decisions, such measurements are often unavailable at fine-grained levels like municipality. This study employs deep learning-based predictions from satellite images to close the gap. We propose a method that assigns a socioeconomic score to each satellite image by capturing the distributional behavior observed in larger areas based on the ground truth. We train an ordinal regression scoring model and adjust the scores to follow the common power law within and across regions. Evaluation based on official statistics in South Korea shows that our method outperforms previous models in predicting population and employment size at both the municipality and grid levels. Our method also demonstrates robust performance in districts with uneven development, suggesting its potential use in developing countries where reliable, fine-grained data is scarce.|虽然衡量社会经济指标对于地方政府作出知情的政策决定至关重要，但在细粒度级别(如市政当局)往往无法获得这种衡量。这项研究利用卫星图像中基于深度学习的预测来缩小差距。我们提出了一种方法，通过捕获在更大的区域观察到的基于地面真实的分布行为为每个卫星图像分配一个社会经济评分。我们训练一个有序回归得分模型，并调整得分以遵循区域内和区域间的普遍幂律。基于韩国官方统计数据的评估表明，我们的方法在预测市级和电网级的人口和就业规模方面优于以前的模型。我们的方法还在发展不平衡的地区表现出强劲的性能，表明它在缺乏可靠、细粒度数据的发展中国家有潜力使用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fine-Grained+Socioeconomic+Prediction+from+Satellite+Images+with+Distributional+Adjustment)|0|
|[Logarithmic Dimension Reduction for Quantum Neural Networks](https://doi.org/10.1145/3583780.3615240)|Hankyul Baek, Soohyun Park, Joongheon Kim|Korea University, Seoul, Republic of Korea|In recent years, quantum neural network (QNN) based on quantum computing has attracted attention due to its potential for computation-acceleration and parallelism. However, the intrinsic limitations of QNN, where the output (i.e., observables) can only be obtained through a measurement process, pose scalability challenges. Motivated by this, this paper aims to address the scalability challenges by incorporating Pauli-Z measurement and Basis measurement. In conventional frameworks, QNN typically relies on classical fully connected networks (FCNs) or increases the number of qubits to achieve large output dimensions. However, by leveraging our proposed framework, this paper successfully expands the output dimensions to an exponential scale, surpassing the limitations imposed by the limited number of qubits without relying on FCNs. Through extensive experiments, this paper demonstrates that the proposed framework outperforms existing QNN frameworks in multi-class classification tasks that require numerous output dimensions.|近年来，基于量子计算的量子神经网络(QNN)由于其在计算加速和并行性方面的潜力而引起了人们的关注。然而，QNN 的内在局限性，其中的输出(即，可观测的)只能通过测量过程获得，提出了可伸缩性的挑战。基于此，本文旨在通过结合 Pauli-Z 度量和基础度量来解决可伸缩性方面的挑战。在传统的框架中，QNN 通常依赖于经典的全连通网络(FCNs)或增加量子位的数量来实现较大的输出维数。然而，通过利用我们提出的框架，本文成功地将输出维度扩展到指数级，超越了不依赖 FCNs 的有限量子比特数量所带来的限制。通过大量的实验证明，该框架在多类分类任务中优于现有的 QNN 框架，因为多类分类任务需要大量的输出维数。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Logarithmic+Dimension+Reduction+for+Quantum+Neural+Networks)|0|
|[A Comparative Study of Reference Reliability in Multiple Language Editions of Wikipedia](https://doi.org/10.1145/3583780.3615254)|Aitolkyn Baigutanova, Diego SáezTrumper, Miriam Redi, Meeyoung Cha, Pablo Aragón|KAIST, IBS, Daejeon, Republic of Korea; Wikimedia Foundation, London, United Kingdom; Wikimedia Foundation, Barcelona, Spain; IBS, KAIST, Daejeon, Republic of Korea|Information presented in Wikipedia articles must be attributable to reliable published sources in the form of references. This study examines over 5 million Wikipedia articles to assess the reliability of references in multiple language editions. We quantify the cross-lingual patterns of the perennial sources list, a collection of reliability labels for web domains identified and collaboratively agreed upon by Wikipedia editors. We discover that some sources (or web domains) deemed untrustworthy in one language (i.e., English) continue to appear in articles in other languages. This trend is especially evident with sources tailored for smaller communities. Furthermore, non-authoritative sources found in the English version of a page tend to persist in other language versions of that page. We finally present a case study on the Chinese, Russian, and Swedish Wikipedias to demonstrate a discrepancy in reference reliability across cultures. Our finding highlights future challenges in coordinating global knowledge on source reliability.|维基百科条目中提供的信息必须归因于以参考文献形式出版的可靠来源。这项研究检查了超过500万维基百科文章，以评估在多种语言版本的参考文献的可靠性。我们量化了多年来源列表的跨语言模式，这是一个由维基百科编辑共同确定和认可的网络域名的可靠性标签集合。我们发现一些在一种语言(如英语)中被认为不可信的来源(或网络域名)继续出现在其他语言的文章中。这种趋势在为小型社区量身定制的信息来源中尤为明显。此外，在英文版本的网页中发现的非权威来源往往会保留在该网页的其他语言版本中。最后，我们提出了一个案例研究的中国，俄罗斯和瑞典的维基百科，以证明在不同文化的参考可靠性的差异。我们的发现突出了未来在协调源可靠性全球知识方面的挑战。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Comparative+Study+of+Reference+Reliability+in+Multiple+Language+Editions+of+Wikipedia)|0|
|[Linkage Attack on Skeleton-based Motion Visualization](https://doi.org/10.1145/3583780.3615263)|Thomas Carr, Aidong Lu, Depeng Xu|University of North Carolina at Charlotte, Charlotte, NC, USA|Skeleton-based motion capture and visualization is an important computer vision task, especially in the virtual reality (VR) environment. It has grown increasingly popular due to the ease of gathering skeleton data and the high demand of virtual socialization. The captured skeleton data seems anonymous but can still be used to extract personal identifiable information (PII). This can lead to an unintended privacy leakage inside a VR meta-verse. We propose a novel linkage attack on skeleton-based motion visualization. It detects if a target and a reference skeleton are the same individual. The proposed model, called Linkage Attack Neural Network (LAN), is based on the principles of a Siamese Network. It incorporates deep neural networks to embed the relevant PII then uses a classifier to match the reference and target skeletons. We also employ classical and deep motion retargeting (MR) to cast the target skeleton onto a dummy skeleton such that the motion sequence is anonymized for privacy protection. Our evaluation shows that the effectiveness of LAN in the linkage attack and the effectiveness of MR in anonymization.|基于骨架的运动捕获与可视化是计算机视觉的一项重要任务，尤其是在虚拟现实(VR)环境中。由于收集骨架数据的便捷性和虚拟社交的高要求，它已经变得越来越流行。捕获的骨骼数据似乎是匿名的，但仍然可以用来提取个人识别信息(PII)。这可能会导致虚拟现实元宇宙中意外的隐私泄露。针对基于骨架的运动可视化提出了一种新的联动攻击方法。它检测目标和引用框架是否是同一个个体。提出的连锁攻击神经网络(LAN)模型是基于暹罗网络的原理。它结合了深度神经网络来嵌入相关的 PII，然后使用分类器来匹配参考和目标骨架。我们还采用经典的和深度运动重定向(MR)将目标骨架投射到一个虚拟骨架上，使运动序列匿名以保护隐私。我们的评估表明局域网在链路攻击中的有效性和 MR 在匿名化中的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Linkage+Attack+on+Skeleton-based+Motion+Visualization)|0|
|[Identify Risky Rules to Reduce Side Effects in Association Rule Hiding](https://doi.org/10.1145/3583780.3615259)|Peng Cheng|Southwest Univeristy, Chongqing, China|Data sharing is necessary for many practical applications. People do, however, frequently worry about the problem of privacy leaking.This study focuses on preventing the disclosure of sensitive information using association rules and frequent itemsets, which are frequently utilized in numerous applications. How to minimize side effects while hiding, particularly side effects on non-sensitive knowledge, is the difficult part of the problem. The majority of association rule hiding techniques currently in use solely consider reducing side effects on frequent itemsets (patterns), rather than rules, in order to conceal sensitive rules by reducing the statistical disclosure of the itemsets that generate such rules. In this study, we provide a concealment technique utilizing potentially risky rules to lessen adverse impacts on non-sensitive rules, not only itemsets. In addition, this method can be tailored to conceal sensitive itemsets, instead of rules. Extensive experiments show that in most cases the proposed solution can bring fewer side effects on rules, frequent patterns or data quality than existing methods.|数据共享对于许多实际应用是必要的。然而，人们确实经常担心隐私泄露的问题。本研究的重点是利用关联规则和频繁项目集来防止敏感信息的泄露，这些关联规则和频繁项目集在许多应用中经常被使用。如何在隐藏的同时尽量减少副作用，尤其是对非敏感知识的副作用，是问题的难点。目前使用的大多数关联规则隐藏技术只考虑减少对频繁项集(模式)的副作用，而不考虑规则，以通过减少生成此类规则的项集的统计信息披露来隐藏敏感规则。在这项研究中，我们提供了一种隐藏技术，利用潜在的风险规则，以减少对非敏感性规则的不利影响，而不仅仅是项集。此外，可以对此方法进行修改以隐藏敏感项集，而不是隐藏规则。大量实验表明，在大多数情况下，与现有方法相比，提出的解决方案对规则、频繁模式或数据质量带来的副作用更小。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Identify+Risky+Rules+to+Reduce+Side+Effects+in+Association+Rule+Hiding)|0|
|[Patient Clustering via Integrated Profiling of Clinical and Digital Data](https://doi.org/10.1145/3583780.3615262)|Dongjin Choi, Andy Xiang, Ozgur Ozturk, Deep Shrestha, Barry L. Drake, Hamid Haidarian, Faizan Javed, Haesun Park|Kaiser Permanente, Atlanta, GA, USA; Kaiser Permanente, Los Angeles, CA, USA; Georgia Institute of Technology, Atlanta, GA, USA|We introduce a novel profile-based patient clustering model designed for clinical data in healthcare. By utilizing a method grounded on constrained low-rank approximation, our model takes advantage of patients' clinical data and digital interaction data, including browsing and search, to construct patient profiles. As a result of the method, nonnegative embedding vectors are generated, serving as a low-dimensional representation of the patients. Our model was assessed using real-world patient data from a healthcare web portal, with a comprehensive evaluation approach which considered clustering and recommendation capabilities. In comparison to other baselines, our approach demonstrated superior performance in terms of clustering coherence and recommendation accuracy.|我们介绍了一种新的基于特征的患者聚类模型，该模型是为医疗保健领域的临床数据而设计的。该模型采用基于约束低秩近似的方法，利用患者的临床数据和数字交互数据，包括浏览和搜索，构建患者的个人资料。作为该方法的结果，非负嵌入向量生成，作为低维表示的患者。我们的模型使用来自医疗保健门户网站的真实世界患者数据进行评估，并采用综合评估方法，其中考虑了聚类和推荐功能。与其他基线相比，我们的方法在聚类一致性和推荐准确性方面表现出更好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Patient+Clustering+via+Integrated+Profiling+of+Clinical+and+Digital+Data)|0|
|[Reconciling Training and Evaluation Objectives in Location Agnostic Surrogate Explainers](https://doi.org/10.1145/3583780.3615284)|Matthew Clifford, Jonathan Erskine, Alexander Hepburn, Peter A. Flach, Raúl SantosRodríguez|University of Bristol, Bristol, United Kingdom|Transparency in AI models is crucial to designing, auditing, and deploying AI systems. However, 'black box' models are still used in practice for their predictive power despite their lack of transparency. This has led to a demand for post-hoc, model-agnostic surrogate explainers which provide explanations for decisions of any model by approximating its behaviour close to a query point with a surrogate model. However, it is often overlooked how the location of the query point in the decision surface of the black box model affects the faithfulness of the surrogate explainer. Here, we show that when using standard techniques, there is a decrease in agreement between the black box and the surrogate model for query points towards the edge of the test dataset and when moving away from the decision boundary. This originates from a mismatch between the data distributions used to train and evaluate surrogate explainers. We address this by leveraging knowledge about the test data distribution captured in the class labels of the black box model. By addressing this and encouraging users to take care in understanding the alignment of training and evaluation objectives, we empower them to construct more faithful surrogate explainers.|人工智能模型的透明度对于人工智能系统的设计、审核和部署至关重要。然而，尽管缺乏透明度，“黑匣子”模型在实践中仍然被用来预测未来。这导致了对事后的、模型无关的代理解释器的需求，这些代理解释器通过使用代理模型在接近查询点的地方近似模型的行为，为任何模型的决策提供解释。然而，人们往往忽视了查询点在黑盒模型决策表面中的位置对代理解释器的忠实性的影响。在这里，我们展示了当使用标准技术时，黑匣子和查询点的替代模型之间的一致性在测试数据集的边缘以及远离决策边界时有所下降。这源于用于训练和评估代理解释器的数据分布之间的不匹配。我们通过利用在黑盒模型的类标签中捕获的关于测试数据分布的知识来解决这个问题。通过解决这个问题，并鼓励用户注意理解培训和评估目标的一致性，我们授权他们构建更忠实的代理解释器。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reconciling+Training+and+Evaluation+Objectives+in+Location+Agnostic+Surrogate+Explainers)|0|
|[Efficient Variant Calling on Human Genome Sequences Using a GPU-Enabled Commodity Cluster](https://doi.org/10.1145/3583780.3615268)|Manas Jyoti Das, Khawar Shehzad, Praveen Rao|University of Missouri, Columbia, MO, USA|Human genome sequences are very large in size and require significant compute and storage resources for processing and analysis. Variant calling is a key task performed on an individual's genome to identify different types of variants. Knowing these variants can lead to new advances in disease diagnosis and treatment. In this work, we propose a new approach for accelerating variant calling pipelines on a large workload of human genomes using a commodity cluster with graphics processing units (GPUs). Our approach has two salient features: First, it enables a pipeline stage to use GPUs and/or CPUs based on the availability of resources in the cluster. Second, it employs a mutual exclusion strategy for executing a pipeline stage on the GPUs of a cluster node so that the stages (for other sequences) can be executed using CPUs if needed. We evaluated our approach on a 8-node cluster with bare metal servers and virtual machines (VMs) containing different types of GPUs. On publicly available genome sequences, our approach was 3.6X-5X faster compared to an approach that used only the cluster CPUs.|人类基因组序列非常大，需要大量的计算和存储资源进行处理和分析。变异调用是对个体基因组进行识别不同类型变异的关键任务。了解这些变异可以导致疾病诊断和治疗的新进展。在这项工作中，我们提出了一种新的方法，加速变体调用管道上的大量工作负载的人类基因组使用商品集群的图形处理单元(GPU)。我们的方法有两个显著特性: 首先，它允许管道阶段根据集群中资源的可用性使用 GPU 和/或 CPU。其次，它采用了一种互斥锁策略，在集群节点的 GPU 上执行流水线阶段，以便在需要时可以使用 CPU 执行这些阶段(对于其他序列)。我们在一个8节点集群上评估了我们的方法，该集群包含裸金属服务器和包含不同类型 GPU 的虚拟机(VM)。对于公开可用的基因组序列，我们的方法比仅使用集群 CPU 的方法快3.6X-5X 倍。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Variant+Calling+on+Human+Genome+Sequences+Using+a+GPU-Enabled+Commodity+Cluster)|0|
|[Self-supervised Learning and Graph Classification under Heterophily](https://doi.org/10.1145/3583780.3615166)|Yilin Ding, Zhen Liu, Hao Hao|School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China|Self-supervised learning has shown its promising capability in graph representation learning in recent work. Most existing pre-training strategies usually choose the popular Graph neural networks (GNNs), which can be seen as a special form of low-pass filter, fail to effectively capture heterophily. In this paper, we first present an experimental investigation exploring the performance of low-pass and high-pass filters in heterophily graph classification, where the results clearly show that high-frequency signal is important for learning heterophily graph representation. On the other hand, it is still unclear how to effectively capture the structural pattern of graphs and how to measure the capability of the self-supervised pre-training strategy in capturing graph structure. To address the problem, we first design a quantitative metric to Measure Graph Structure (MGS), which analyzes correlation between structural similarity and embedding similarity of graph pairs. Then, to enhance the graph structural information captured by self-supervised learning, we propose a novel self-supervised strategy for Pre-training GNNs based on the Metric (PGM). Extensive experiments validate our pre-training strategy achieves state-of-the-art performance for molecular property prediction and protein function prediction. In addition, we find choosing the suitable filter sometimes may be better than designing good pre-training strategies for heterophily graph classification.|近年来，自监督学习在图表示学习方面表现出了很好的应用前景。现有的预训练策略大多采用流行的图形神经网络(GNN) ，它可以看作是一种特殊形式的低通滤波器，不能有效地捕获异质性。本文首先对异构图分类中的低通和高通滤波器的性能进行了实验研究，结果表明高频信号对于学习异构图表示是非常重要的。另一方面，如何有效地捕获图的结构模式以及如何衡量自监督预训练策略在捕获图结构方面的能力，目前尚不清楚。为了解决这个问题，我们首先设计了一个量化度量来度量图结构(MGS) ，它分析了图对的结构相似性和嵌入相似度之间的相关性。然后，为了增强自监督学习所获得的图结构信息，提出了一种新的基于度量(PGM)的自监督预训练 GNN 策略。大量的实验验证了我们的预训练策略在分子特性预测和蛋白质功能预测方面达到了最先进的性能。此外，我们发现选择合适的滤波器有时可能比设计好的异构图分类预训练策略更好。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-supervised+Learning+and+Graph+Classification+under+Heterophily)|0|
|[Bridging the KB-Text Gap: Leveraging Structured Knowledge-aware Pre-training for KBQA](https://doi.org/10.1145/3583780.3615150)|Guanting Dong, Rumei Li, Sirui Wang, Yupeng Zhang, Yunsen Xian, Weiran Xu|Beijing University of Posts and Telecommunications, Beijing, China; Meituan Group, Beijing, China; Beijing University of Aeronautics and Astronautics, Beijing, China|Knowledge Base Question Answering (KBQA) aims to answer natural language questions with factual information such as entities and relations in KBs. However, traditional Pre-trained Language Models (PLMs) are directly pre-trained on large-scale natural language corpus, which poses challenges for them in understanding and representing complex subgraphs in structured KBs. To bridge the gap between texts and structured KBs, we propose a Structured Knowledge-aware Pre-training method (SKP). In the pre-training stage, we introduce two novel structured knowledge-aware tasks, guiding the model to effectively learn the implicit relationship and better representations of complex subgraphs. In downstream KBQA task, we further design an efficient linearization strategy and an interval attention mechanism, which assist the model to better encode complex subgraphs and shield the interference of irrelevant subgraphs during reasoning respectively. Detailed experiments and analyses on WebQSP verify the effectiveness of SKP, especially the significant improvement in subgraph retrieval (+4.08% H@10).|知识库问题解答(KBQA)的目的是利用知识库中的实体和关系等事实信息来回答自然语言问题。然而，传统的预训练语言模型直接在大规模的自然语言语料库上进行预训练，这对它们在结构化知识库中理解和表示复杂子图提出了挑战。为了弥合文本和结构化知识库之间的差距，我们提出了一种结构化知识感知的预训练方法(SKP)。在预训练阶段，我们引入了两个新的结构化知识感知任务，引导模型有效地学习复杂子图的隐含关系和更好的表示。在后续的 KBQA 任务中，我们进一步设计了有效的线性化策略和区间注意机制，分别帮助模型更好地编码复杂子图和屏蔽推理过程中不相关子图的干扰。通过对 WebQSP 的详细实验和分析，验证了 SKP 的有效性，尤其是子图检索的显著改善(+ 4.08% H@10)。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bridging+the+KB-Text+Gap:+Leveraging+Structured+Knowledge-aware+Pre-training+for+KBQA)|0|
|[Geometric Matrix Completion via Sylvester Multi-Graph Neural Network](https://doi.org/10.1145/3583780.3615170)|Boxin Du, Changhe Yuan, Fei Wang, Hanghang Tong|Amazon, New York, USA; Amazon, San Francisco, USA; University of Illinois at Urbana-Champaign, Urbana, USA|Despite the success of the Sylvester equation empowered methods on various graph mining applications, such as semi-supervised label learning and network alignment, there also exists several limitations. The Sylvester equation's inability of modeling non-linear relations and the inflexibility of tuning towards different tasks restrict its performance. In this paper, we propose an end-to-end neural framework, SYMGNN, which consists of a multi-network neural aggregation module and a prior multi-network association incorporation learning module. The proposed framework inherits the key ideas of the Sylvester equation, and meanwhile generalizes it to overcome aforementioned limitations. Empirical evaluations on real-world datasets show that the instantiations of SYMGNN overall outperform the baselines in geometric matrix completion task, and its low-rank instantiation could further reduce the memory consumption by 16.98\% on average.|尽管 Sylvester 方程在半监督标记学习和网络对齐等各种图挖掘应用中取得了成功，但也存在一些局限性。Sylvester 方程不能建立非线性关系，对不同任务的调整也不灵活，这些都限制了它的性能。在本文中，我们提出了一个端到端的神经元架构，SYMGNN，它由一个多网络神经元聚合模块和一个先前的多网络关联结合学习模块组成。该框架继承了 Sylvester 方程的核心思想，同时对其进行了推广，克服了上述局限性。对实际数据集的实证分析表明，SYMGNN 的实例化效果总体优于几何矩阵完成任务的基线，其低秩实例化平均可以进一步降低内存消耗16.98% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Geometric+Matrix+Completion+via+Sylvester+Multi-Graph+Neural+Network)|0|
|[Neighborhood Homophily-based Graph Convolutional Network](https://doi.org/10.1145/3583780.3615195)|Shengbo Gong, Jiajun Zhou, Chenxuan Xie, Qi Xuan|Zhejiang University of Technology & Binjiang Cyberspace Security Institute of ZJUT, Hangzhou, China|Graph neural networks (GNNs) have been proved powerful in graph-oriented tasks. However, many real-world graphs are heterophilous, challenging the homophily assumption of classical GNNs. To solve the universality problem, many studies deepen networks or concatenate intermediate representations, which does not inherently change neighbor aggregation and introduces noise. Recent studies propose new metrics to characterize the homophily, but rarely consider the correlation of the proposed metrics and models. In this paper, we first design a new metric, Neighborhood Homophily (NH), to measure the label complexity or purity in node neighborhoods. Furthermore, we incorporate the metric into the classical graph convolutional network (GCN) architecture and propose Neighborhood Homophily-based Graph Convolutional Network (NHGCN). In this framework, neighbors are grouped by estimated NH values and aggregated from different channels, and the resulting node predictions are then used in turn to estimate and update NH values. The two processes of metric estimation and model inference are alternately optimized to achieve better node classification. NHGCN achieves top overall performance on both homophilous and heterophilous benchmarks, with an improvement of up to 7.4% compared to the current SOTA methods.|图神经网络(GNN)已被证明在面向图的任务中是强大的。然而，许多现实世界的图是异质的，挑战了经典 GNN 的同质假设。为了解决通用性问题，许多研究深化了网络或级联了中间表示，这种方法本身并不改变邻居聚集，而是引入了噪声。最近的研究提出了新的度量来表征同质性，但很少考虑提出的度量和模型的相关性。在本文中，我们首先设计了一个新的度量，邻域同伦(NH) ，来度量标签的复杂度或节点邻域的纯度。此外，我们将度量结合到经典的图卷积网络(GCN)体系结构中，并提出了基于邻域同构的图卷积网络(NHGCN)。在这个框架中，根据估计的 NH 值对邻居进行分组，并从不同的通道汇总，然后使用所得到的节点预测来估计和更新 NH 值。交替优化度量估计和模型推理两个过程，以实现更好的节点分类。NHGCN 在同质性和异质性基准测试上都取得了最好的总体性能，与目前的 SOTA 方法相比提高了7.4% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neighborhood+Homophily-based+Graph+Convolutional+Network)|0|
|[Explainable and Accurate Natural Language Understanding for Voice Assistants and Beyond](https://doi.org/10.1145/3583780.3615277)|Kalpa Gunaratna, Vijay Srinivasan, Hongxia Jin|Samsung Research America, Mountain View, CA, USA|Joint intent detection and slot filling, which is also termed as joint NLU (Natural Language Understanding) is invaluable for smart voice assistants. Recent advancements in this area have been heavily focusing on improving accuracy using various techniques. Explainability is undoubtedly an important aspect for deep learning-based models including joint NLU models. Without explainability, their decisions are opaque to the outside world and hence, have tendency to lack user trust. Therefore to bridge this gap, we transform the full joint NLU model to be `inherently' explainable at granular levels without compromising on accuracy. Further, as we enable the full joint NLU model explainable, we show that our extension can be successfully used in other general classification tasks. We demonstrate this using sentiment analysis and named entity recognition.|联合意图检测和插槽填充，也被称为联合 NLU (自然语言理解)是非常宝贵的智能语音助手。该领域的最新进展主要集中在利用各种技术提高精度。可解释性无疑是包括联合 NLU 模型在内的基于深度学习模型的一个重要方面。如果没有可解释性，他们的决策对于外部世界是不透明的，因此有缺乏用户信任的倾向。因此，为了弥合这一差距，我们将完整的联合 NLU 模型转换为“固有的”可解释的粒度级别，而不影响精度。进一步，当我们能够解释完整的联合 NLU 模型，我们表明我们的扩展可以成功地用于其他一般的分类任务。我们使用情感分析和命名实体识别来证明这一点。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explainable+and+Accurate+Natural+Language+Understanding+for+Voice+Assistants+and+Beyond)|0|
|[Hateful Comment Detection and Hate Target Type Prediction for Video Comments](https://doi.org/10.1145/3583780.3615260)|Shrey Gupta, Pratyush Priyadarshi, Manish Gupta|IIIT-Hyderabad & Microsoft, Hyderabad, India; IIIT-Hyderabad, Hyderabad, India|With the widespread increase in hateful content on the web, hate detection has become more crucial than ever. Although vast literature exists on hate detection from text, images and videos, interestingly, there has been no previous work on hateful comment detection (HCD) from video pages. HCD is critical for comment moderation and for flagging controversial videos. Comments are often short, contextual and convoluted making the problem challenging. Toward solving this problem, we contribute a dataset, HateComments, consisting of 2071 comments for 401 videos obtained from two popular video sharing platforms. We investigate two related tasks: binary HCD and 4-class multi-label hate target-type prediction (HTP). We systematically explore the importance of various forms of context for effective HCD. Our initial experiments show that our best method which leverages rich video context (like description, transcript and visual input) leads to an HCD accuracy of ~78.6% and an ROC AUC score of ~0.61 for HTP. Code and data is at https://drive.google.com/file/d/1EUbWDUokv1CYkWKlwByUC6yIuBGUw2MN/.|随着互联网上仇恨内容的广泛增加，仇恨检测变得比以往任何时候都更加重要。虽然大量的文献存在从文本，图像和视频仇恨检测，有趣的是，还没有以前的工作在仇恨评论检测(HCD)从视频网页。HCD 对于评论节制和标记有争议的视频至关重要。评论通常很短，上下文相关，而且令人费解，使问题具有挑战性。为了解决这个问题，我们贡献了一个数据集，仇恨评论，包括从两个流行的视频分享平台获得的401个视频的2071条评论。我们研究了两个相关的任务: 二进制 HCD 和4类多标签仇恨目标类型预测(HTTP)。我们系统地探讨了各种形式的背景对有效 HCD 的重要性。我们最初的实验表明，我们利用丰富的视频上下文(如描述，转录本和视觉输入)的最佳方法导致 HCD 准确率约为78.6% ，对于 HTTP，ROC AUC 评分约为0.61。代码和数据处于 https://drive.google.com/file/d/1eubwduokv1cykwklwbyuc6yiubguw2mn/。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hateful+Comment+Detection+and+Hate+Target+Type+Prediction+for+Video+Comments)|0|
|[Latent Aspect Detection via Backtranslation Augmentation](https://doi.org/10.1145/3583780.3615205)|Farinam Hemmatizadeh, Christine Wong, Alice Yu, Hossein Fani|Vincent Massey Secondary School, Windsor, ON, Canada; University of Windsor, Windsor, ON, Canada|Within the context of review analytics, aspects are the features of products and services at which customers target their opinions and sentiments. Aspect detection helps product owners and service providers identify shortcomings and prioritize customers' needs. Existing methods focus on detecting the surface form of an aspect falling short when aspects are latent in reviews, especially in an informal context like in social posts. In this paper, we propose data augmentation via natural language backtranslation to extract latent occurrences of aspects. We presume that backtranslation (1) can reveal latent aspects because they may not be commonly known in the target language and can be generated through backtranslation; (2) augments context-aware synonymous aspects from a target language to the original language, hence addressing the out-of-vocabulary issue; and (3) helps with the semantic disambiguation of polysemous words and collocations. Through our experiments on well-known aspect detection methods across semeval datasets of restaurant and laptop reviews, we demonstrate that review augmentation via backtranslation yields a steady performance boost in baselines. We further contribute LADy at https://github.com/fani-lab/LADy, a benchmark library to support the reproducibility of our research.|在评论分析的背景下，方面是产品和服务的特征，客户针对这些特征提出他们的意见和看法。方面检测可以帮助产品所有者和服务提供者识别缺点并优先考虑客户的需求。现有的研究方法主要集中在检测评论中，尤其是在非正式场合，如社会职位中，某一方面的表面形式不足。本文提出了一种基于自然语言反翻译的数据增强方法来提取潜在的方面。我们假设，反向翻译(1)可以揭示潜在的方面，因为它们可能在目的语中并不常见，可以通过反向翻译产生; (2)从目的语到原语增加了上下文感知的同义方面，从而解决了词汇表外的问题; (3)有助于多义词和搭配的语义消歧。通过我们在餐馆和笔记本电脑评论的中期数据集上的著名方面检测方法的实验，我们证明了通过反向翻译的评论增强在基线上产生了稳定的性能提升。我们进一步贡献了 https://github.com/fani-lab/LADy  ，一个基准图书馆，以支持我们的研究的可重复性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Latent+Aspect+Detection+via+Backtranslation+Augmentation)|0|
|[Stochastic Subgraph Neighborhood Pooling for Subgraph Classification](https://doi.org/10.1145/3583780.3615227)|Shweta Ann Jacob, Paul Louis, Amirali SalehiAbari|University of Ontario Institute of Technology, Oshawa, ON, Canada|Subgraph classification is an emerging field in graph representation learning where the task is to classify a group of nodes (i.e., a subgraph) within a graph. Subgraph classification has applications such as predicting the cellular function of a group of proteins or identifying rare diseases given a collection of phenotypes. Graph neural networks (GNNs) are the de facto solution for node, link, and graph-level tasks but fail to perform well on subgraph classification tasks. Even GNNs tailored for graph classification are not directly transferable to subgraph classification as they ignore the external topology of the subgraph, thus failing to capture how the subgraph is located within the larger graph. The current state-of-the-art models for subgraph classification address this shortcoming through either labeling tricks or multiple message-passing channels, both of which impose a computation burden and are not scalable to large graphs. To address the scalability issue while maintaining generalization, we propose Stochastic Subgraph Neighborhood Pooling (SSNP), which jointly aggregates the subgraph and its neighborhood (i.e., external topology) information without any computationally expensive operations such as labeling tricks. To improve scalability and generalization further, we also propose a simple data augmentation pre-processing step for SSNP that creates multiple sparse views of the subgraph neighborhood. We show that our model is more expressive than GNNs without labeling tricks. Our extensive experiments demonstrate that our models outperform current state-of-the-art methods (with a margin of up to 2%) while being up to 3X faster in training.|子图分类是图表示学习中的一个新兴领域，其任务是对图中的一组节点(即子图)进行分类。子图分类的应用，如预测一组蛋白质的细胞功能或鉴定罕见疾病的表型集合。图神经网络(GNN)是节点、链路和图级任务的实际解决方案，但在子图分类任务中表现不佳。即使是专门用于图分类的 GNN 也不能直接转移到子图分类，因为它们忽略了子图的外部拓扑结构，因此无法捕捉子图在较大图中的位置。目前最先进的子图分类模型通过标记技巧或多个消息传递通道来解决这一缺陷，这两种方法都增加了计算负担，而且不能扩展到大图。为了在保持泛化的同时解决可扩展性问题，我们提出了随机子图邻域池(SSNP) ，它不需要任何计算代价高昂的操作，如标记技巧，就可以联合聚集子图及其邻域(即外部拓扑)信息。为了进一步提高可扩展性和泛化能力，我们还提出了一个简单的数据增强预处理步骤，用于产生子图邻域的多个稀疏视图。我们展示了我们的模型比没有标记技巧的 GNN 更有表现力。我们广泛的实验表明，我们的模型表现优于目前的最先进的方法(利润率高达2%) ，同时在训练快达3倍。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Stochastic+Subgraph+Neighborhood+Pooling+for+Subgraph+Classification)|0|
|[Uncertainty Quantification via Spatial-Temporal Tweedie Model for Zero-inflated and Long-tail Travel Demand Prediction](https://doi.org/10.1145/3583780.3615215)|Xinke Jiang, Dingyi Zhuang, Xianghui Zhang, Hao Chen, Jiayuan Luo, Xiaowei Gao||Understanding Origin-Destination (O-D) travel demand is crucial for transportation management. However, traditional spatial-temporal deep learning models grapple with addressing the sparse and long-tail characteristics in high-resolution O-D matrices and quantifying prediction uncertainty. This dilemma arises from the numerous zeros and over-dispersed demand patterns within these matrices, which challenge the Gaussian assumption inherent to deterministic deep learning models. To address these challenges, we propose a novel approach: the Spatial-Temporal Tweedie Graph Neural Network (STTD). The STTD introduces the Tweedie distribution as a compelling alternative to the traditional 'zero-inflated' model and leverages spatial and temporal embeddings to parameterize travel demand distributions. Our evaluations using real-world datasets highlight STTD's superiority in providing accurate predictions and precise confidence intervals, particularly in high-resolution scenarios.|理解起点-目的地(O-D)旅游需求对于运输管理至关重要。然而，传统的时空深度学习模型致力于解决高分辨率 O-D 矩阵中的稀疏和长尾特征以及预测不确定性的量化问题。这种困境源于这些矩阵中大量的零和过分分散的需求模式，这挑战了确定性深度学习模型固有的高斯假设。为了应对这些挑战，我们提出了一种新的方法: 时空 Tweedie 图神经网络(STTD)。STTD 引入了 Tweedie 发行版，作为传统“零膨胀”模型的一个引人注目的替代品，并利用空间和时间嵌入来参数化旅游需求分布。我们使用真实世界数据集的评估突出了 STTD 在提供准确预测和精确置信区间方面的优势，特别是在高分辨率情况下。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Uncertainty+Quantification+via+Spatial-Temporal+Tweedie+Model+for+Zero-inflated+and+Long-tail+Travel+Demand+Prediction)|0|
|[Effective Slogan Generation with Noise Perturbation](https://doi.org/10.1145/3583780.3615193)|Jongeun Kim, MinChung Kim, Taehwan Kim|UNIST, Ulsan, Republic of Korea|Slogans play a crucial role in building the brand's identity of the firm. A slogan is expected to reflect firm's vision and the brand's value propositions in memorable and likeable ways. Automating the generation of slogans with such characteristics is challenging. Previous studies developed and tested slogan generation with syntactic control and summarization models which are not capable of generating distinctive slogans. We introduce a novel approach that leverages pre-trained transformer T5 model with noise perturbation on newly proposed 1:N matching pair dataset. This approach serves as a contributing factor in generating distinctive and coherent slogans. Furthermore, the proposed approach incorporates descriptions about the firm and brand into the generation of slogans. We evaluate generated slogans based on ROUGE-1, ROUGE-L and Cosine Similarity metrics and also assess them with human subjects in terms of slogan's distinctiveness, coherence, and fluency. The results demonstrate that our approach yields better performance than baseline models and other transformer-based models.|口号在树立公司品牌形象方面起着至关重要的作用。一个口号被期望以令人难忘和可爱的方式反映公司的愿景和品牌的价值主张。自动生成具有这些特征的口号具有挑战性。以往的研究开发和测试口号生成的句法控制和总结模型，不能产生独特的口号。我们提出了一种新的方法，利用预训练的变压器 T5模型与噪声扰动新提出的1: N 匹配对数据集。这种方法在产生与众不同和连贯的口号方面起到了影响因素的作用。此外，建议的方法将有关企业和品牌的描述纳入口号的生成。我们基于 ROUge-1、 ROUge-L 和余弦距离度量对生成的口号进行评估，同时也根据口号的独特性、连贯性和流畅性对人类受试者进行评估。结果表明，我们的方法比基线模型和其他基于变压器的模型产生更好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Effective+Slogan+Generation+with+Noise+Perturbation)|0|
|[S-Mixup: Structural Mixup for Graph Neural Networks](https://doi.org/10.1145/3583780.3615280)|Junghurn Kim, Sukwon Yun, Chanyoung Park|KAIST, Daejeon, Republic of Korea|Existing studies for applying the mixup technique on graphs mainly focus on graph classification tasks, while the research in node classification is still under-explored. In this paper, we propose a novel mixup augmentation for node classification called Structural Mixup (S-Mixup). The core idea is to take into account the structural information while mixing nodes. Specifically, S-Mixup obtains pseudo-labels for unlabeled nodes in a graph along with their prediction confidence via a Graph Neural Network (GNN) classifier. These serve as the criteria for the composition of the mixup pool for both inter and intra-class mixups. Furthermore, we utilize the edge gradient obtained from the GNN training and propose a gradient-based edge selection strategy for selecting edges to be attached to the nodes generated by the mixup. Through extensive experiments on real-world benchmark datasets, we demonstrate the effectiveness of S-Mixup evaluated on the node classification task. We observe that S-Mixup enhances the robustness and generalization performance of GNNs, especially in heterophilous situations. The source code of S-Mixup can be found at \url{https://github.com/SukwonYun/S-Mixup}|现有的将混合技术应用于图的研究主要集中在图的分类任务上，而对节点分类的研究还很少。本文提出了一种新的节点分类混合增强算法——结构混合算法(S- 混合算法)。其核心思想是在混合节点时考虑结构信息。具体来说，S-Mixup 通过图神经网络(GNN)分类器获得了图中未标记节点的伪标签，以及它们的预测置信度。对于类间和类内的混合，它们作为混合池组成的标准。在此基础上，利用 GNN 训练得到的边缘梯度，提出了一种基于梯度的边缘选择策略，用于选择连接在混合算法生成的节点上的边缘。通过对实际基准数据集的大量实验，验证了 S-Mixup 评估算法在节点分类任务中的有效性。我们观察到 S- 混合增强了 GNN 的鲁棒性和泛化性能，特别是在异构情况下。S-Mixup 的源代码可以在 url { https://github.com/sukwonyun/S-Mixup }找到|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=S-Mixup:+Structural+Mixup+for+Graph+Neural+Networks)|0|
|[Class Label-aware Graph Anomaly Detection](https://doi.org/10.1145/3583780.3615249)|Junghoon Kim, Yeonjun In, Kanghoon Yoon, Junmo Lee, Chanyoung Park|KAIST, Daejeon, Republic of Korea|Unsupervised GAD methods assume the lack of anomaly labels, i.e., whether a node is anomalous or not. One common observation we made from previous unsupervised methods is that they not only assume the absence of such anomaly labels, but also the absence of class labels (the class a node belongs to used in a general node classification task). In this work, we study the utility of class labels for unsupervised GAD; in particular, how they enhance the detection of structural anomalies. To this end, we propose a Class Label-aware Graph Anomaly Detection framework (CLAD) that utilizes a limited amount of labeled nodes to enhance the performance of unsupervised GAD. Extensive experiments on ten datasets demonstrate the superior performance of CLAD in comparison to existing unsupervised GAD methods, even in the absence of ground-truth class label information. The source code for CLAD is available at \url{https://github.com/jhkim611/CLAD}.|无监督的 GAD 方法假定缺乏异常标签，即节点是否异常。我们从以前的无监督方法中得到的一个常见的观察结果是，它们不仅假设没有这种异常标签，而且还假设没有类标签(节点所属的类在一般节点分类任务中使用)。在这项工作中，我们研究了类标签对于无监督广义系统的效用，特别是它们如何增强结构异常的检测。为此，我们提出了一个类标签感知图形异常检测框架(CLAD) ，该框架利用有限数量的标记节点来提高无监督广义相关设计的性能。在10个数据集上的大量实验表明，与现有的无监督 GAD 方法相比，即使在没有地面真值类标签信息的情况下，CLAD 的性能也更好。CLAD 的源代码可以在 url { https://github.com/jhkim611/CLAD }找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Class+Label-aware+Graph+Anomaly+Detection)|0|
|[Can a Chatbot be Useful in Childhood Cancer Survivorship? Development of a Chatbot for Survivors of Childhood Cancer](https://doi.org/10.1145/3583780.3615234)|Mirae Kim, Kyubum Hwang, Hayoung Oh, Heejin Kim, MinAh Kim|Sungkyunkwan University, Seoul, Republic of Korea|This study introduces an informational and empathetic chatbot for childhood cancer survivors. As the survival rates for childhood cancer around the world have increased, survivors often face various psychosocial challenges during and after cancer treatment. However, they rarely seek support from psychosocial professionals due to the low availability of resources and stigma toward cancer survivors in countries like South Korea. This study aimed to develop a chatbot tailed to the unique characteristics of childhood cancer survivors in need of informational and emotional support. Given the limited availability of empirical data on childhood cancer survivors, quotes from survivors were gathered from academic articles and social media, then large language models were employed to generate appropriate responses. Furthermore, we incorporated domain learning techniques to ensure a more tailored and suitable model for addressing the needs of survivors.|这项研究为儿童癌症幸存者介绍了一个信息和移情聊天机器人。随着世界各地儿童癌症存活率的提高，幸存者在癌症治疗期间和治疗后往往面临各种心理社会挑战。然而，他们很少寻求社会心理学专业人士的支持，因为在韩国等国家，资源的可用性很低，癌症幸存者也被视为耻辱。这项研究旨在开发一个聊天机器人尾随儿童癌症幸存者的独特特征，需要信息和情感支持。鉴于儿童癌症幸存者的经验数据有限，从学术文章和社交媒体中收集幸存者的引文，然后使用大型语言模型来产生适当的反应。此外，我们纳入了领域学习技术，以确保更加量身定制和适当的模式，以满足幸存者的需求。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Can+a+Chatbot+be+Useful+in+Childhood+Cancer+Survivorship?+Development+of+a+Chatbot+for+Survivors+of+Childhood+Cancer)|0|
|[You're Not Alone in Battle: Combat Threat Analysis Using Attention Networks and a New Open Benchmark](https://doi.org/10.1145/3583780.3615196)|Soo Yong Lee, Juwon Kim, Kiwoong Park, Dong Kuk Ryu, Sang Heun Shim, Kijung Shin|Agency for Defense Development, Seoul, Republic of Korea; KAIST, Seoul, Republic of Korea|For military commands, combat threat analysis is crucial in predicting future outcomes and informing consequent decisions. Its primary objectives include determining the intention and attack likelihood of the hostiles. The complex, dynamic, and noisy nature of combat, however, presents significant challenges in its analysis. The prior research has been limited in accounting for such characteristics, assuming independence of each entity, no unobserved tactics, and clean combat data. As such, we present spatio-temporal attention for threat analysis (SAFETY) to encode complex interactions that arise within combat. We test the model performance for unobserved tactics and with various perturbations. To do so, we also present the first open-source benchmark for combat threat analysis with two downstream tasks of predicting entity intention and attack probability. Our experiments show that SAFETY achieves a significant improvement in model performance, with enhancements of up to 13% in intention prediction and 7% in attack prediction compared to the strongest competitor, even when confronted with noisy or missing data. This result highlights the importance of encoding dynamic interactions among entities for combat threat analysis. Our codes and dataset are available at https://github.com/syleeheal/SAFETY.|对于军事指挥来说，战斗威胁分析在预测未来结果和通知后续决策方面是至关重要的。它的主要目标包括确定敌人的意图和攻击可能性。然而，战斗的复杂性、动态性和嘈杂性在其分析中提出了重大的挑战。先前的研究在考虑这些特征方面受到限制，假设每个实体独立，没有未观察到的战术，以及清晰的作战数据。因此，我们提出时空注意力的威胁分析(安全) ，以编码复杂的相互作用中出现的战斗。我们测试模型的性能未观测的战术和各种摄动。为此，我们还提出了第一个用于作战威胁分析的开源基准，其下游任务是预测实体意图和攻击概率。我们的实验表明，SAFETY 在模型性能方面取得了显著的改进，与最强大的竞争对手相比，即使面对有噪音或丢失的数据，在意图预测和攻击预测方面的改进分别高达13% 和7% 。该结果突出了编码实体间动态交互对于作战威胁分析的重要性。我们的代码和数据集 https://github.com/syleeheal/safety 可查。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=You're+Not+Alone+in+Battle:+Combat+Threat+Analysis+Using+Attention+Networks+and+a+New+Open+Benchmark)|0|
|[Look At Me, No Replay! SurpriseNet: Anomaly Detection Inspired Class Incremental Learning](https://doi.org/10.1145/3583780.3615236)|Anton Lee, Yaqian Zhang, Heitor Murilo Gomes, Albert Bifet, Bernhard Pfahringer|University of Waikato, Hamilton, New Zealand; Victoria University of Wellington & University of Waikato, Wellington, New Zealand; Victoria University of Wellington, Wellington, New Zealand; University of Waikato & Institute Polytechnique de Paris, Hamilton, New Zealand|Continual learning aims to create artificial neural networks capable of accumulating knowledge and skills through incremental training on a sequence of tasks. The main challenge of continual learning is catastrophic interference, wherein new knowledge overrides or interferes with past knowledge, leading to forgetting. An associated issue is the problem of learning "cross-task knowledge," where models fail to acquire and retain knowledge that helps differentiate classes across task boundaries. A common solution to both problems is "replay," where a limited buffer of past instances is utilized to learn cross-task knowledge and mitigate catastrophic interference. However, a notable drawback of these methods is their tendency to overfit the limited replay buffer. In contrast, our proposed solution, SurpriseNet, addresses catastrophic interference by employing a parameter isolation method and learning cross-task knowledge using an auto-encoder inspired by anomaly detection. SurpriseNet is applicable to both structured and unstructured data, as it does not rely on image-specific inductive biases. We have conducted empirical experiments demonstrating the strengths of SurpriseNet on various traditional vision continual-learning benchmarks, as well as on structured data datasets. Source code made available at https://doi.org/10.5281/zenodo.8247906 and https://github.com/tachyonicClock/SurpriseNet-CIKM-23|持续学习的目的是创建人工神经网络，能够通过一系列任务的增量训练来积累知识和技能。持续学习的主要挑战是灾难性干扰，即新知识凌驾于过去的知识之上或干扰过去的知识，导致遗忘。一个相关的问题是学习“跨任务知识”的问题，其中模型无法获取和保留有助于跨任务边界区分类别的知识。这两个问题的一个共同解决方案是“重播”，即利用过去实例的有限缓冲区来学习跨任务知识和减轻灾难性干扰。然而，这些方法的一个显著缺点是它们倾向于过载有限的重播缓冲区。相比之下，我们提出的解决方案“惊喜网络”通过使用参数隔离方法和使用受灾难性干扰异常检测启发的自动编码器学习跨任务知识来解决问题。因为它不依赖于特定于图像的归纳偏差，所以它同时适用于结构化和非结构化数据化。我们已经进行了实证实验，证明了在各种传统的视觉连续学习基准，以及结构化数据集的优势惊喜网络。源代码可在 https://doi.org/10.5281/zenodo.8247906和 https://github.com/tachyonicclock/surprisenet-cikm-23获得|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Look+At+Me,+No+Replay!+SurpriseNet:+Anomaly+Detection+Inspired+Class+Incremental+Learning)|0|
|[UNDO: Effective and Accurate Unlearning Method for Deep Neural Networks](https://doi.org/10.1145/3583780.3615235)|Sangyong Lee, Simon S. Woo|Sungkyunkwan University, Suwon, Republic of Korea|Machine learning has evolved through extensive data usage, including personal and private information. Regulations like GDPR highlight the "Right to be forgotten" for user and data privacy. Research in machine unlearning aims to remove specific data from pre-trained models. We introduce a novel two-step unlearning method, UNDO. First, we selectively disrupt the decision boundary of forgetting data at the coarse-grained level. However, this can also inadvertently affect the decision boundary of other remaining data, lowering the overall performance of classification task. Hence, we subsequently repair and refining the decision boundary for each class at the fine-grained level by introducing a loss for maintain the overall performance, while completely removing the class. Our approach is validated through experiments on two datasets, outperforming other methods in effectiveness and efficiency.|机器学习已经通过广泛的数据使用，包括个人和私人信息的演变。GDPR 等法规强调了用户和数据隐私的“被遗忘的权利”。机器学习研究的目的是从预先训练的模型中去除特定的数据。我们介绍了一种新的两步去学习方法，UNDO。首先，我们在粗粒度层面有选择性地中断遗忘数据的决策边界。然而，这也会无意中影响其他数据的决策边界，降低分类任务的整体性能。因此，我们随后在细粒度水平上修复和改进每个类的决策边界，引入损失以保持整体性能，同时完全删除该类。我们的方法是通过两个数据集的实验验证，在有效性和效率方面优于其他方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UNDO:+Effective+and+Accurate+Unlearning+Method+for+Deep+Neural+Networks)|0|
|[ST-RAP: A Spatio-Temporal Framework for Real Estate Appraisal](https://doi.org/10.1145/3583780.3615168)|Hojoon Lee, Hawon Jeong, Byungkun Lee, Kyungyup Daniel Lee, Jaegul Choo|KAIST AI, Seongnam-si, Republic of Korea; Spacewalk Inc., Seoul-si, Republic of Korea|In this paper, we introduce ST-RAP, a novel Spatio-Temporal framework for Real estate APpraisal. ST-RAP employs a hierarchical architecture with a heterogeneous graph neural network to encapsulate temporal dynamics and spatial relationships simultaneously. Through comprehensive experiments on a large-scale real estate dataset, ST-RAP outperforms previous methods, demonstrating the significant benefits of integrating spatial and temporal aspects in real estate appraisal. Our code and dataset are available at https://github.com/dojeon-ai/STRAP.|在这篇文章中，我们介绍了 ST-RAP，一个新的不动产估价师时空框架。RAP 采用层次结构和异构图形神经网络来同时封装时间动态和空间关系。通过在大规模房地产数据集上的全面实验，ST-RAP 优于以往的方法，展示了在不动产估价师中整合空间和时间方面的显著好处。我们的代码和数据集可在 https://github.com/dojeon-ai/strap 下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ST-RAP:+A+Spatio-Temporal+Framework+for+Real+Estate+Appraisal)|0|
|[Temporal and Topological Augmentation-based Cross-view Contrastive Learning Model for Temporal Link Prediction](https://doi.org/10.1145/3583780.3615231)|Dongyuan Li, Shiyin Tan, Yusong Wang, Kotaro Funakoshi, Manabu Okumura|Tokyo Institute of Technology, Tokyo, Japan; Kuaishou Technology, Beijing, China|With the booming development of social media, temporal link prediction (TLP), as a core technology, has been receiving increasing attention. However, current methods are based on graph neural networks, which suffer from the over-smoothing issue and easily yield indistinguishable node representations, degrading the prediction accuracy. Besides, they lack the ability to eliminate noisy temporal information and ignore the importance of high-order neighbor information for measuring the link probability between nodes. To solve these issues, we design a cross-view graph contrastive learning (GCL) framework for TLP, called Tacl. We first design two augmented views for GCL by enhancing the temporal and topological information to obtain distinguishable node representations. Then, we learn the evolution rule of temporal networks to help constrain consistency of node representations and eliminate noise. Finally, we incorporate the high-order neighbor information to measure the link probability between nodes. Extensive experiments demonstrate the effectiveness and robustness of Tacl.|随着社交媒体的蓬勃发展，时间链接预测(TLP)作为一种核心技术，受到越来越多的关注。然而，目前的方法都是基于图神经网络的，这种方法存在过于平滑的问题，容易产生难以区分的节点表示，降低了预测的准确性。此外，它们缺乏消除噪声时间信息的能力，忽略了高阶邻居信息对于测量节点间链路概率的重要性。为了解决这些问题，我们设计了一个跨视图图形对比学习(GCL)的 TLP 框架，称为 Tacl。首先通过增强 GCL 的时间和拓扑信息设计两个增强视图，以获得可区分的节点表示。然后通过学习时间网络的演化规律来约束节点表示的一致性，消除噪声。最后，结合高阶邻居信息来度量节点之间的链路概率。大量的实验证明了 Tacl 的有效性和鲁棒性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Temporal+and+Topological+Augmentation-based+Cross-view+Contrastive+Learning+Model+for+Temporal+Link+Prediction)|0|
|[CORD: A Three-Stage Coarse-to-Fine Framework for Relation Detection in Knowledge Base Question Answering](https://doi.org/10.1145/3583780.3615178)|Yanzeng Li, Sen Hu, Wenjuan Han, Lei Zou|Ant Group, Beijing, China; Peking University, Beijing, China; Beijing Jiaotong University & DUOMO, Beijing, China; Peking University & National Key Laboratory of General Artificial Intelligence, BIGAI, Beijing, China|As a fundamental subtask of Knowledge Base Question Answering (KBQA), Relation Detection (KBQA-RD) plays a crucial role to detect the KB relations between entities or variables in natural language questions. It remains, however, a challenging task, particularly for significant large-scale relations and in the presence of easily confused relations. Recent state-of-the-art methods not only struggle with such scenarios, but often take into account only one facet and fail to incorporate the subtle discrepancy among the relations. In this paper, we propose a simple and efficient three-stage framework to exploit the coarse-to-fine paradigm. Specifically, we employ a natural clustering over all KB relations and perform a coarse-to-fine relation recognition process based on the relation clustering. In this way, our framework (i.e., CORD) refines the detection of relations, so as to scale well with large-scale relations. Experiments on both single-relation (i.e., SimpleQuestions (SQ)) and multi-relation (i.e., WebQSP (WQ)) benchmarks show that CORD not only achieves the outstanding relation detection performance in KBQA-RD subtask; but more importantly, further improves the accuracy of KBQA systems.|关系检测作为知识库问题回答(KBQA)的一个基本子任务，对于检测自然语言问题中实体或变量之间的知识库关系起着至关重要的作用。然而，这仍然是一项具有挑战性的任务，特别是对于重大的大规模关系和容易混淆的关系。最近的最先进的方法不仅与这种情况作斗争，而且往往只考虑一个方面，而且未能纳入关系之间的微妙差异。在本文中，我们提出了一个简单而有效的三阶段框架来开发从粗到精的范式。具体来说，我们在所有知识库关系上采用自然聚类，并在关系聚类的基础上进行从粗到精的关系识别过程。通过这种方式，我们的框架(即 CORD)改进了关系的检测，从而可以很好地扩展大规模关系。在单关系(SimpleQuestions，SQ)和多关系(WebQSP，WQ)基准上的实验表明，CORD 不仅在 KBQA-RD 子任务中取得了优异的关系检测性能，更重要的是进一步提高了 KBQA 系统的准确性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CORD:+A+Three-Stage+Coarse-to-Fine+Framework+for+Relation+Detection+in+Knowledge+Base+Question+Answering)|0|
|[Homogeneous Cohort-Aware Group Cognitive Diagnosis: A Multi-grained Modeling Perspective](https://doi.org/10.1145/3583780.3615287)|Shuhuan Liu, Xiaoshan Yu, Haiping Ma, Ziwen Wang, Chuan Qin, Xingyi Zhang|BOSS Zhipin, Beijing, China; Institutes of Physical Science and Information Technology, Anhui University, Hefei, China; School of Artificial Intelligence, Anhui University, Hefei, China|Cognitive Diagnosis has been widely investigated as a fundamental task in the field of education, aiming at effectively assessing the students' knowledge proficiency level by mining their exercise records. Recently, group-level cognitive diagnosis is also attracting attention, which measures the group-level knowledge proficiency on specific concepts by modeling the response behaviors of all students within the classes. However, existing work tends to explore group characteristics with a coarse-grained perspective while ignoring the inter-individual variability within groups, which is prone to unstable diagnosis results. To this end, in this paper, we propose a novel Homogeneous cohort-aware Group Cognitive Diagnosis model, namely HomoGCD, to effectively model the group's knowledge proficiency level from a multi-grained modeling perspective. Specifically, we first design a homogeneous cohort mining module to explore subgroups of students with similar ability status within a class by modeling their routine exercising performance. Then, we construct the mined cohorts into fine-grained organizations for exploring stable and uniformly distributed features of groups. Subsequently, we develop a multi-grained modeling module to comprehensively learn the cohort and group ability status, which jointly trains both interactions with the exercises. In particular, an extensible diagnosis module is introduced to support the incorporation of different diagnosis functions. Finally, extensive experiments on two real-world datasets clearly demonstrate the generality and effectiveness of our HomoGCD in group as well as cohort~assessments.|认知诊断作为教育领域的一项基础性课题已经得到了广泛的研究，其目的是通过挖掘学生的运动记录来有效地评估学生的知识水平。近年来，群体认知诊断也引起了人们的关注，它通过建立班级内所有学生的反应行为模型来衡量群体对特定概念的认知水平。然而，现有的研究倾向于从粗粒度的角度探索群体特征，而忽视了群体内个体间的差异性，这容易导致诊断结果不稳定。为此，本文提出了一种新的同质队列感知群体认知诊断模型 HomoGCD，从多粒度建模的角度对群体的知识水平进行有效建模。具体来说，我们首先设计了一个同质队列挖掘模块，通过模拟学生的日常锻炼表现来探索班级内具有相似能力地位的学生群体。然后，我们将挖掘的队列构造成细粒度组织，以探索群体的稳定和均匀分布特征。随后，我们开发了一个多粒度建模模块来全面学习队列和群体能力状态，并将这两种能力状态与练习相互作用进行联合训练。特别地，引入了一个可扩展的诊断模块来支持不同诊断功能的集成。最后，在两个实际数据集上的广泛实验清楚地证明了我们的 HomoGCD 在群体和队列 ~ 评估中的普遍性和有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Homogeneous+Cohort-Aware+Group+Cognitive+Diagnosis:+A+Multi-grained+Modeling+Perspective)|0|
|[Epidemiology-aware Deep Learning for Infectious Disease Dynamics Prediction](https://doi.org/10.1145/3583780.3615139)|Mutong Liu, Yang Liu, Jiming Liu|Hong Kong Baptist University, Kowloon, Hong Kong|Infectious disease risk prediction plays a vital role in disease control and prevention. Recent studies in machine learning have attempted to incorporate epidemiological knowledge into the learning process to enhance the accuracy and informativeness of prediction results for decision-making. However, these methods commonly involve single-patch mechanistic models, overlooking the disease spread across multiple locations caused by human mobility. Additionally, these methods often require extra information beyond the infection data, which is typically unavailable in reality. To address these issues, this paper proposes a novel epidemiology-aware deep learning framework that integrates a fundamental epidemic component, the next-generation matrix (NGM), into the deep architecture and objective function. This integration enables the inclusion of both mechanistic models and human mobility in the learning process to characterize within- and cross-location disease transmission. From this framework, two novel methods, Epi-CNNRNN-Res and Epi-Cola-GNN, are further developed to predict epidemics, with experimental results validating their effectiveness.|传染病风险预测在疾病控制和预防方面起着至关重要的作用。最近的机器学习研究试图将流行病学知识纳入学习过程，以提高决策预测结果的准确性和信息量。然而，这些方法通常涉及单一斑块的机制模型，忽略了疾病传播的多个地点造成的人类流动性。此外，这些方法通常需要感染数据之外的额外信息，而这些数据在现实中通常是不可用的。为了解决这些问题，本文提出了一种新的流行病学意识深度学习框架，它将流行病学的基本组成部分——下一代矩阵(NGM)集成到深度体系结构和目标函数中。这种整合使机械模型和人类流动性都能纳入学习过程，以描述疾病传播的内部和跨部位特征。在此框架下，进一步发展了两种新的流行病预测方法 Epi-CNNRNN-Res 和 Epi-Cola-GNN，实验结果验证了它们的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Epidemiology-aware+Deep+Learning+for+Infectious+Disease+Dynamics+Prediction)|0|
|[Towards Trustworthy Rumor Detection with Interpretable Graph Structural Learning](https://doi.org/10.1145/3583780.3615228)|Leyuan Liu, Junyi Chen, Zhangtao Cheng, Wenxin Tai, Fan Zhou|University of Electronic Science and Technology of China & Kash Institute of Electronics and Information Industry, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China|The exponential growth of digital information has amplified the necessity for effective rumor detection on social media. However, existing approaches often neglect the inherent noise and uncertainty in rumor propagation, leading to obscure learning mechanisms. Moreover, current deep-learning methodologies, despite their top-tier performance, are heavily dependent on supervised learning, which is labor-intensive and inefficient. Their prediction credibility is also questionable. To tackle these issues, we present a new framework, TrustRD, for reliable rumor detection. Our framework incorporates a self-supervised learning module, designed to derive interpretable and informative representations with less reliance on large labeled data sets. A downstream model based on Bayesian networks, which is further refined with adversarial training, enhances performance while providing a quantifiable trustworthiness assessment of results. Our methods' effectiveness is confirmed through experiments on two benchmark datasets.|数字信息的指数增长增强了有效侦测社交媒体谣言的必要性。然而，现有的方法往往忽视了谣言传播中固有的噪声和不确定性，导致模糊的学习机制。此外，目前的深度学习方法，尽管表现一流，但严重依赖于监督式学习，这是劳动密集型和效率低下的。他们的预测可信度也值得怀疑。为了解决这些问题，我们提出了一个新的框架 TrustRD，用于可靠的谣言检测。我们的框架结合了一个自我监督的学习模块，旨在获得可解释和信息表示，较少依赖于大型标记数据集。一个基于贝叶斯网络的下游模型，通过对抗性训练进一步完善，提高了性能，同时提供了一个可量化的结果可信度评估。通过对两个基准数据集的实验验证了该方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Trustworthy+Rumor+Detection+with+Interpretable+Graph+Structural+Learning)|0|
|[TemDep: Temporal Dependency Priority for Multivariate Time Series Prediction](https://doi.org/10.1145/3583780.3615164)|Shu Liu, Jiaheng Wang, Jiamin Chen, Jianliang Gao, Yuhui Zhong|Central South University, Changsha, China|The multivariate fusion transformation is ubiquitous in multivariate time series prediction (MTSP) problems. The previous multivariate fusion transformation fuses the feature of different variates at a time step, then projects them to a new feature space for effective feature representation. However, temporal dependency is the most fundamental property of time series. The previous manner fails to capture the temporal dependency of the feature, which is destroyed in the transformed feature matrix. Multivariate feature extraction based on the feature matrix with missing temporal dependency leads to the loss of predictive performance of MTSP. To address this problem, we propose the Temporal Dependency Priority for Multivariate Time Series Prediction (TemDep) method. Specifically, TemDep extracts feature temporal dependency of multivariate time series first and then considers multivariate feature fusion. Moreover, the low-dimensional and high-dimensional feature fusion manners are designed with the temporal dependency priority to fit different dimensional multivariate time series. The extensive experimental results of different datasets show that our proposed method can outperform all state-of-the-art baseline methods. It proves the significance of temporal dependency priority for MTSP.|多元融合变换在多元时间序列预测(MTSP)问题中普遍存在。以往的多变量融合变换是在一个时间步上对不同变量的特征进行融合，然后将它们投影到一个新的特征空间中进行有效的特征表示。然而，时间依赖性是时间序列最基本的性质。前一种方法不能捕获特征的时间依赖关系，这种依赖关系在转换后的特征矩阵中被破坏。基于时间相关性缺失的特征矩阵的多变量特征提取导致 MTSP 预测性能的损失。为了解决这个问题，我们提出了多变量时间序列预测(TemDep)的时间依赖优先级方法。具体来说，TemDep 首先提取多元时间序列的特征时间相关性，然后考虑多元特征融合。同时设计了具有时间依赖优先级的低维和高维特征融合方法，以适应不同维数的多元时间序列。不同数据集的大量实验结果表明，我们提出的方法可以优于所有最先进的基线方法。证明了时间依赖优先级对 MTSP 的重要性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TemDep:+Temporal+Dependency+Priority+for+Multivariate+Time+Series+Prediction)|0|
|[DCGNN: Dual-Channel Graph Neural Network for Social Bot Detection](https://doi.org/10.1145/3583780.3615237)|Nuoyan Lyu, Bingbing Xu, Fangda Guo, Huawei Shen|Beijing University of Posts and Telecommunications, Beijing, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China|The importance of social bot detection has been increasingly recognized due to its profound impact on information dissemination. Existing methodologies can be categorized into feature engineering and deep learning-based methods, which mainly focus on static features, e.g., post characteristics and user profiles.However, existing methods often overlook the burst phenomena when distinguishing social bots and genuine users, i.e, the sudden and intense activity or behavior of bots after prolonged inter. Through comprehensive analysis, we find that both burst behavior and static features play pivotal roles in social bot detection. To capture such properties, the dual-channel GNN (DCGNN) is proposed which consists of a burst-aware channel with an adaptive-pass filter and a static-aware channel with a low-pass filter to model user characteristics effectively. Experimental results demonstrate the superiority of this method over competitive baselines.|由于社会机器人检测对信息传播的深刻影响，其重要性得到了越来越多的重视。现有的方法可以分为特征工程方法和基于深度学习的方法，主要集中在静态特征方面，如文章特征和用户概况。然而，现有的方法在区分社交机器人和真正的用户时往往忽略了突发现象，即机器人在长时间间隔后突然的、强烈的活动或行为。通过综合分析，我们发现突发行为和静态特征在社会机器人检测中起着关键作用。为了捕获这些特性，提出了一种双信道 GNN (DCGNN) ，它由一个带有自适应通滤波器的突发感知信道和一个带有低通滤波器的静态感知信道组成，可以有效地模拟用户特性。实验结果表明，该方法优于竞争基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DCGNN:+Dual-Channel+Graph+Neural+Network+for+Social+Bot+Detection)|0|
|[Contrastive Learning for Rumor Detection via Fitting Beta Mixture Model](https://doi.org/10.1145/3583780.3615138)|Jiachen Ma, Jing Dai, Yong Liu, Meng Han, Chunyu Ai|University of South Carolina Upstate, Spartanburg, SC, USA; Zhejiang University, Hangzhou, China; Heilongjiang University, Harbin, China|The rise of social media has posed a challenging problem of effectively identifying rumors. With the great success of contrastive learning in many fields, many contrastive learning models for rumor detection have been proposed. However, existing models usually use the propagation structure of other events as negative samples and regard more similar samples to anchor events as hard ones across all the training processes, resulting in undesirably pushing away the samples of the same class. Thus, we propose a novel contrastive learning model (CRFB) to solve the above problem. Specifically, we employ contrastive learning between two augmented propagation structure and fit a two-component (true-false) beta mixture model (BMM) to measure the probability of negative samples being true. In addition, we propose a CNN-based model to capture the consistent and complementary information between two augmented propagation structure. The experimental results on public datasets demonstrate that our CRFB outperforms the existing state-of-the-art models for rumor detection.|社交媒体的兴起提出了一个有效识别谣言的挑战性问题。随着对比学习在许多领域取得的巨大成功，人们提出了许多用于谣言检测的对比学习模型。然而，现有的模型通常将其他事件的传播结构作为负样本，并将更多相似样本作为硬样本锚定在所有训练过程中，导致不必要地推开同类样本。因此，我们提出了一种新的对比学习模型(CRFB)来解决上述问题。具体来说，我们使用两个增广传播结构之间的对比学习，并拟合一个双组分(真假)混合模型(BMM)来测量负样本为真的概率。此外，我们提出了一个基于 CNN 的模型来捕获两个增强传播结构之间的一致性和互补信息。在公共数据集上的实验结果表明，我们的 CRFB 优于现有的最先进的谣言检测模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Learning+for+Rumor+Detection+via+Fitting+Beta+Mixture+Model)|0|
|[Generating News-Centric Crossword Puzzles As A Constraint Satisfaction and Optimization Problem](https://doi.org/10.1145/3583780.3615151)|Kaito Majima, Shotaro Ishihara|Nikkei Inc., Otemachi, Tokyo, Japan|Crossword puzzles have traditionally served not only as entertainment but also as an educational tool that can be used to acquire vocabulary and language proficiency. One strategy to enhance the educational purpose is personalization, such as including more words on a particular topic. This paper focuses on the case of encouraging people's interest in news and proposes a framework for automatically generating news-centric crossword puzzles. We designed possible scenarios and built a prototype as a constraint satisfaction and optimization problem, that is, containing as many news-derived words as possible. Our experiments reported the generation probabilities and time required under several conditions. The results showed that news-centric crossword puzzles can be generated even with few news-derived words. We summarize the current issues and future research directions through a qualitative evaluation of the prototype. This is the first proposal that a formulation of a constraint satisfaction and optimization problem can be beneficial as an educational application.|纵横字谜传统上不仅作为一种娱乐，而且作为一种教育工具，可以用来获得词汇和语言熟练程度。增强教育目的的一个策略是个性化，例如包含更多关于特定主题的单词。本文以激发人们对新闻的兴趣为例，提出了一个自动生成以新闻为中心的填字游戏的框架。我们设计了可能的场景，并建立了一个原型作为约束补偿和最佳化问题，也就是说，包含尽可能多的新闻衍生词。我们的实验报告了在几种条件下所需的生成概率和时间。结果表明，即使只有很少的新闻词汇，也可以生成以新闻为中心的填字游戏。通过对样机的定性评价，总结了目前存在的问题和未来的研究方向。这是第一个建议，一个约束补偿和最佳化问题的制定可以作为一个有益的教育应用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generating+News-Centric+Crossword+Puzzles+As+A+Constraint+Satisfaction+and+Optimization+Problem)|0|
|[Age-Aware Guidance via Masking-Based Attention in Face Aging](https://doi.org/10.1145/3583780.3615183)|Junyeong Maeng, Kwanseok Oh, HeungIl Suk|Korea University, Seoul, Republic of Korea|Face age transformation aims to convert reference images into synthesized images so that they portray the specified target ages. The crux of this task is to change only age-related areas of the given image while maintaining the age-irrelevant areas unchanged. Nevertheless, a common limitation among most existing models is the struggle to generate high-quality aging images that effectively consider both crucial properties. To address this problem, we propose a novel GAN-based face-aging framework that utilizes age-aware Guidance via Masking-Based Attention (GMBA). Specifically, we devise an age-aware guidance module to adjust age-relevant and age-irrelevant attributes within the image seamlessly. By virtue of its capability, it enables the model to produce realistic age-transformed images that certainly preserve the input's identities while delicately imposing age-related properties. Experimental results show that our proposed GMBA outperformed other state-of-the-art methods in terms of identity preservation and accurate age conversion, as well as providing superior visual quality for age-transformed images.|人脸年龄变换的目的是将参考图像转换为合成图像，从而刻画出特定的目标年龄。这项任务的关键是只改变给定图像中与年龄相关的区域，同时保持与年龄无关的区域不变。尽管如此，大多数现有模型的一个共同限制是难以产生高质量的老化图像，有效地考虑到这两个关键属性。为了解决这一问题，我们提出了一种新的基于 GAN 的面孔老化框架，该框架利用基于掩蔽注意的年龄感知指导(GMBA)。具体来说，我们设计了一个年龄感知的指导模块来无缝地调整图像中与年龄相关和与年龄无关的属性。凭借其能力，它使模型能够产生真实的年龄转换的图像，当然保留输入的身份，同时微妙地施加与年龄有关的属性。实验结果表明，我们提出的 gMBA 在食品生产履历和准确的年龄转换方面优于其他最先进的方法，并且为年龄转换图像提供了优越的视觉质量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Age-Aware+Guidance+via+Masking-Based+Attention+in+Face+Aging)|0|
|[Metapath-Guided Data-Augmentation For Knowledge Graphs](https://doi.org/10.1145/3583780.3615186)|Saurav Manchanda|Instacart, San Francisco, CA, USA|Knowledge graph (KG) embedding techniques use relationships between entities to learn low-dimensional representations of entities and relations. The traditional KG embedding techniques (such as TransE and DistMult) estimate these embeddings using the observed KG triplets and differ in their triplet scoring loss functions. As these models only use the observed triplets to estimate the embeddings, they are prone to suffer through data sparsity that usually occurs in the real-world knowledge graphs, i.e., the lack of enough triplets per entity. In this paper, we propose an efficient method to augment the triplets to address the problem of data sparsity. We use random walks to create additional triplets, such that the relations carried by these introduced triplets correspond to the metapath (sequence of underlying relations) induced by the random walks. We also provide approaches to accurately and efficiently choose the informative metapaths from the possible set of metapaths. The proposed augmentation approaches can be used with any KG embedding approach out of the box. Experimental results on benchmarks show the advantages of the proposed approach.|知识图(KG)嵌入技术利用实体之间的关系来学习实体和关系的低维表示。传统的 KG 嵌入技术(如 TransE 和 distMult)使用观察到的 KG 三联体估计这些嵌入，并且它们的三联体得分损失函数不同。由于这些模型只使用观察到的三联体来估计嵌入，因此它们容易遭受通常出现在现实世界知识图中的数据稀疏问题，即每个实体缺乏足够的三联体。在本文中，我们提出了一种有效的方法来增加三联体，以解决数据稀疏的问题。我们使用随机游走来创建额外的三联体，使得这些引入的三联体所携带的关系对应于由随机游走诱导的元路径(基础关系序列)。我们还提供了从可能的元路径集合中准确有效地选择信息元路径的方法。所提出的增广方法可以用于任何 KG 嵌入方法开箱即用。基准测试的实验结果表明了该方法的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Metapath-Guided+Data-Augmentation+For+Knowledge+Graphs)|0|
|[Learning Visibility Attention Graph Representation for Time Series Forecasting](https://doi.org/10.1145/3583780.3615289)|Shengzhong Mao, XiaoJun Zeng|The University of Manchester, Manchester, United Kingdom|Visibility algorithm acts as a mapping that bridges graph representation learning with time series analysis, which has been broadly investigated for forecasting tasks. However, the intrinsic nature of visibility encoding yields graphs structured exclusively by binary adjacency matrix, leading to inevitable information loss of temporal sequence during the mapping. To this end, we introduce Angular Visibility Graph Networks (AVGNets), designed with two core features: (i) The framework reconstructs weighted graphs to encode time series by leveraging topological insights derived from visual angles of visibility networks, which capture sequential and structural information within weighted angular matrix. (ii) ProbAttention module is proposed for evaluating probabilistic attention of weighted networks, with remarkable capabilities to extract intrinsic and extrinsic temporal dependencies across multi-layer graphs. Extensive experiments and ablation studies on real-world datasets covering diverse ranges demonstrate that AVGNets achieve state-of-the-art performance, offering an innovative perspective on graph representation for sequence modeling.|可见性算法作为一种将图表示学习与时间序列分析相结合的映射方法，在预测任务中得到了广泛的研究。然而，可见性编码的固有特性产生了完全由二进制邻接矩阵构成的图形，导致在映射过程中不可避免地会丢失时间序列的信息。为此，我们介绍了角度可见性图形网络(AVGNets) ，其设计具有两个核心特征: (i)该框架通过利用从可见性网络的视角获得的拓扑洞察力来重构加权图，以编码时间序列，这些拓扑洞察力捕获加权角矩阵中的序列和结构信息。(ii)利用概率注意模型对加权网络的概率注意进行评估，该模型具有显著的跨多层图提取内在和外在时间依赖的能力。对现实世界中覆盖不同范围的数据集进行的大量实验和消融研究表明，AVGNets 实现了最先进的性能，为序列建模的图表示提供了一个创新的视角。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Visibility+Attention+Graph+Representation+for+Time+Series+Forecasting)|0|
|[A Robust Backward Compatibility Metric for Model Retraining](https://doi.org/10.1145/3583780.3615213)|Ryuta Matsuno, Keita Sakuma|NEC Corporation, Minato-ku, Japan|Model retraining and updating are essential processes in AI applications. However, during updates, there is a potential for performance degradation, in which the overall performance improves, but local performance deteriorates. This study proposes a backward compatibility metric that focuses on the compatibility of local predictive performance. The score of the proposed metric increases if the accuracy over the conditional distribution for each input is higher than before. Furthermore, we propose a model retraining method based on the proposed metric. Due to the use of the conditional distribution, our metric and retraining method are robust against label noises, while existing sample-based backward compatibility metrics are often affected by noise. We perform a theoretical analysis of our method and derive an upper bound for the generalization error. Numerical experiments demonstrate that our retraining method enhances compatibility while achieving equal or better trade-offs in overall performance compared to existing methods.|模型再训练和更新是人工智能应用中必不可少的环节。但是，在更新期间，存在性能下降的可能性，即总体性能提高，但局部性能下降。这项研究提出了一个向下兼容的衡量标准，着重于局部预测性能的兼容性。如果每个输入的条件分布的精度高于以前，则提出的度量的得分会增加。在此基础上，提出了一种基于该度量的模型再训练方法。由于使用了条件分布，我们的度量和再训练方法对标签噪声具有鲁棒性，而现有的基于样本的向下兼容度量常常受到噪声的影响。我们对这个方法进行了理论分析，得到了泛化误差的上界。数值实验表明，我们的再训练方法增强了兼容性，同时在整体性能方面取得了与现有方法相同或更好的平衡。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Robust+Backward+Compatibility+Metric+for+Model+Retraining)|0|
|[Graph Contrastive Learning with Graph Info-Min](https://doi.org/10.1145/3583780.3615162)|En Meng, Yong Liu|Heilongjiang University, Haerbin, China|The complexity of the graph structure poses a challenge for graph representation learning. Contrastive learning offers a straightforward and efficient unsupervised framework for graph representation learning. It achieves unsupervised learning by augmenting the original views and comparing them with the augmented views. Several methods based on this framework have achieved significant progress in the field of graph representation learning. Despite its success, the factors contributing to good augmented views in graph contrast learning have received less attention. In order to address this issue, we introduce the graph info-min principle. We investigate the relationship between mutual information (MI) and good augmented views through experimental and theoretical analysis. Additionally, we present a new contrastive learning method called Info-min Contrastive Learning (IMCL). Specifically, The method comprises an adaptive graph augmentation generator and a pseudo-label generator. The graph augmentation generator ensures sufficient differentiation between the augmented and original views. The pseudo-label generator generates pseudo-labels as supervision signals, ensuring consistency between the classification results of augmented views and original views. Our method demonstrates excellent performance through extensive experimental results on various datasets.|图结构的复杂性对图表示学习提出了挑战。对比学习为图形表示学习提供了一个简单有效的无监督学习框架。它通过增强原始视图并将其与增强视图进行比较来达到非监督式学习。基于该框架的几种方法在图表示学习领域取得了显著的进展。尽管在图形对比度学习中取得了一定的成功，但有助于提高图形对比度学习效果的因素却没有得到足够的重视。为了解决这个问题，我们引入了图的信息最小原则。通过实验和理论分析，研究了互信息(MI)与良好增广视图之间的关系。此外，我们提出了一种新的对比学习方法称为信息最小对比学习(IMCL)。具体地说，该方法包括一个自适应图增强生成器和一个伪标记生成器。图增强生成器确保了增强视图和原始视图之间的充分区分。伪标签生成器生成伪标签作为监控信号，保证了增强视图分类结果与原始视图分类结果的一致性。我们的方法通过在各种数据集上的广泛的实验结果证明了优异的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Contrastive+Learning+with+Graph+Info-Min)|0|
|[Generative Graph Augmentation for Minority Class in Fraud Detection](https://doi.org/10.1145/3583780.3615255)|Lin Meng, Hesham Mostafa, Marcel Nassar, Xiaonan Zhang, Jiawei Zhang|University of California, Davis, Davis, CA, USA; Intel Labs, San Diego, CA, USA; Florida State University, Tallahassee, FL, USA|Class imbalance is a well-recognized challenge in GNN-based fraud detection. Traditional methods like re-sampling and re-weighting address this issue by balancing class distribution. However, node class balancing with simple re-sampling or re-weighting may greatly distort the data distributions and eventually lead to the ineffective performance of GNNs. In this paper, we propose a novel approach named Graph Generative Node Augmentation (GGA), which improves GNN-based fraud detection models by augmenting synthetic nodes of the minority class. GGA utilizes the GAN framework to synthesize node features and related edges of fake fraudulent nodes. To introduce greater variety in the generated nodes, we employ an MLP for feature generation. We also introduce an attention module to encode feature-level information before graph convolutional layers for edge generation. Our empirical results on two real-world fraud datasets demonstrate that GGA improves the performance of GNN-based fraud detection models by a large margin with much fewer nodes than traditional class balance methods, and outperforms recent graph augmentation methods with the same number of synthetic nodes.|类不平衡是基于 GNN 的欺诈检测中公认的挑战。传统的方法如重新抽样和重新加权通过平衡类的分布来解决这个问题。然而，通过简单的重采样或重加权来实现节点类平衡，可能会严重扭曲数据分布，最终导致 GNN 的无效性能。本文提出了一种新的图生成节点增强(GGA)方法，通过增强少数类的合成节点来改进基于 GNN 的欺诈检测模型。GGA 利用 GAN 框架综合假冒节点的节点特征和相关边。为了在生成的节点中引入更大的多样性，我们使用 MLP 进行特征生成。在图卷积层之前引入注意模块对特征层信息进行编码，实现边缘生成。我们对两个实际欺诈数据集的实验结果表明，与传统的类平衡方法相比，GGA 在节点较少的情况下大大提高了基于 GNN 的欺诈检测模型的性能，并且在合成节点数相同的情况下优于现有的图增强方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generative+Graph+Augmentation+for+Minority+Class+in+Fraud+Detection)|0|
|[Efficient Differencing of System-level Provenance Graphs](https://doi.org/10.1145/3583780.3615171)|Yuta Nakamura, Iyad Kanj, Tanu Malik|DePaul University, Chicago, IL, USA|Data provenance, when audited at the operating system level, generates a large volume of low-level events. Current provenance systems infer causal flow from these event traces, but do not infer application structure, such as loops and branches. The absence of these inferred structures decreases accuracy when comparing two event traces, leading to low-quality answers from a provenance system. In this paper, we infer nested natural and unnatural loop structures over a collection of provenance event traces. We describe an 'unrolling method' that uses the inferred nested loop structure to systematically mark loop iterations. Our loop-based unrolling improves the accuracy of trace comparison by 20-70% over trace comparisons that do not rely on inferred structures.|当在操作系统级审计数据来源时，会生成大量低级事件。当前的起源系统从这些事件跟踪推断因果流，但不推断应用程序结构，如循环和分支。缺少这些推断结构会降低比较两个事件轨迹的准确性，从而导致来源系统的低质量答案。在本文中，我们推断嵌套的自然和非自然循环结构上的起源事件痕迹的集合。我们描述了一种“展开方法”，它使用推断的嵌套循环结构来系统地标记循环迭代。我们基于循环的展开比不依赖于推断结构的跟踪比较提高了20-70% 的跟踪比较准确性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Differencing+of+System-level+Provenance+Graphs)|0|
|[Camaraderie: Content-based Knowledge Transfer for Medical Image Labelling using Supervised Autoencoders in a Decentralized Setting](https://doi.org/10.1145/3583780.3615216)|Advait Padhye, Shreeja Bhakat, Humaira Firdowse, Atharv Savarkar, Ganesh Ramakrishnan, Kshitij S. Jadhav|Indian Statistical Institute, Kolkata, Kolkata, India; Indian Institute of Technology, Bombay, Mumbai, India; Indian Institute Of Technology, Bombay, Mumbai, India|Deep neural networks for medical imaging require large high-quality labelled data, a huge bottleneck for resource poor settings. Given the privacy requirements of medical data, institutes are un-willing to share data, causing an hindrance in resource poor settings. In the present paper, (Camaraderie: Content-based Knowledge Transfer for Medical Image Labelling using Supervised Autoencoders in a Decentralized Setting) we propose to use Discrete Classifier Supervised Autoencoder (DC-SAE) to generate low-dimensional representations of a few annotated images at the Donor client and transfer both the DC-SAE's encoder part and the latent space representations to the Recipient client without sharing raw data. We then pass the unlabelled images of the Recipient Client through this encoder to obtain their latent space representation. In a supervised setting, using latent space representation of Donor client's labelled images, we accurately annotate images of Recipient client. Camaraderie demonstrates that DC-SAE outperforms Recipient end label accuracy beyond classical VAE based classification and anomaly detection based VAE. Thus, given a limited amount of labelled data in a decentralized privacy preserving scenario, one can transfer latent space representation across clients to annotate large number of unlabelled images with high accuracy.|医学成像的深层神经网络需要大量高质量的标记数据，这是资源匮乏设置的一个巨大瓶颈。鉴于医疗数据的隐私要求，研究机构不愿意共享数据，在资源匮乏的环境中造成了障碍。在本文中(Camaraderie: 基于内容的医学图像标签知识转移使用监督自动编码器在分散的设置) ，我们建议使用离散分类器监督自动编码器(DC-SAE)在捐助客户端生成几个注释图像的低维表示，并转移 DC-SAE 的编码器部分和潜在空间表示到接收客户端，而不共享原始数据。然后，我们通过这个编码器传递收件人客户端的未标记图像，以获得它们的潜在空间表示。在监督设置下，利用捐献者客户标记图像的潜在空间表示，准确地对接受者客户的图像进行注释。Camaraderie 表明，DC-SAE 的收件人终端标签准确性优于经典的基于 VAE 的分类和基于异常检测的 VAE。因此，在分散保护隐私的场景中，给定有限数量的标记数据，可以跨客户机传输潜在空间表示，以高精度注释大量未标记的图像。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Camaraderie:+Content-based+Knowledge+Transfer+for+Medical+Image+Labelling+using+Supervised+Autoencoders+in+a+Decentralized+Setting)|0|
|[Quantum Split Learning for Privacy-Preserving Information Management](https://doi.org/10.1145/3583780.3615144)|Soohyun Park, Hankyul Baek, Joongheon Kim|Korea University, Seoul, Republic of Korea|Recently, research on quantum neural network (QNN) architectures has been attracted in various fields. Among them, the distributed computation of QNN has been actively discussed for privacy-preserving information management due to data and model distribution over multiple computing devices. Based on this concept, this paper proposes quantum split learning (QSL) which splits a single QNN architecture across multiple distributed computing devices to avoid entire QNN architecture exposure. In order to realize QSL design, this paper also proposes cross-channel pooling, which utilizes quantum state tomography. Our evaluation results verifies that QSL preserves privacy in classification tasks and also improves accuracy at most by 6.83% compared to existing methods.|近年来，量子神经网络(QNN)体系结构的研究引起了各个领域的关注。其中，由于数据和模型在多个计算设备上的分布，QNN 的分布式计算在保护隐私的信息管理中得到了积极的讨论。基于这个概念，本文提出量子分裂学习(QSL) ，它将一个单一的量子神经网络体系结构分割到多个分布式计算设备上，以避免整个量子神经网络体系结构的暴露。为了实现 QSL 的设计，本文还提出了利用量子态层析成像技术的跨信道池技术。我们的评估结果验证了 QSL 在分类任务中保护了隐私，并且与现有的方法相比，最多提高了6.83% 的准确率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quantum+Split+Learning+for+Privacy-Preserving+Information+Management)|0|
|[Quantitative Decomposition of Prediction Errors Revealing Multi-Cause Impacts: An Insightful Framework for MLOps](https://doi.org/10.1145/3583780.3615238)|Keita Sakuma, Ryuta Matsuno, Yoshio Kameda|NEC Corporation, Minato-ku, Japan|As machine learning applications expand in various industries, MLOps, which enables continuous model operation and improvement, becomes increasingly significant. Identifying causes of prediction errors, such as low model performance or anomalous samples, and implementing appropriate countermeasures are essential for effective MLOps. Furthermore, quantitatively evaluating each cause's impact is necessary to determine the effectiveness of countermeasures. In this study, we propose a method to quantitatively decompose a single sample's prediction error into contributions from multiple causes. Our method involves four steps: calculating the prediction error, computing metrics related to error causes, using a regression model to learn the relationship between the error and metrics, and applying SHAP to interpret the model's predictions and calculate the contribution of each cause to the prediction error. Numerical experiments with open data show that our method offers valuable insights for model improvement, confirming the effectiveness of our approach.|随着机器学习应用在各个行业的不断扩展，使模型持续运行和改进成为可能的 MLOPs 变得越来越重要。识别预测错误的原因，如低模型性能或异常样本，并实施适当的对策是有效的 MLOP 所必需的。此外，定量评估每个原因的影响是必要的，以确定对策的有效性。在这项研究中，我们提出了一种方法，定量分解单个样本的预测误差，以多种原因的贡献。我们的方法包括四个步骤: 计算预测误差，计算与误差原因相关的指标，使用回归模型来了解误差与指标之间的关系，以及应用 SHAP 来解释模型的预测，并计算每个原因对预测误差的贡献。开放数据的数值实验表明，我们的方法为模型改进提供了有价值的见解，证实了我们的方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quantitative+Decomposition+of+Prediction+Errors+Revealing+Multi-Cause+Impacts:+An+Insightful+Framework+for+MLOps)|0|
|[VN-Solver: Vision-based Neural Solver for Combinatorial Optimization over Graphs](https://doi.org/10.1145/3583780.3615156)|Mina Samizadeh, Guangmo Tong|University of Delaware, Newark, DE, USA|Data-driven approaches have been proven effective in solving combinatorial optimization problems over graphs such as the traveling salesman problems and the vehicle routing problem. The rationale behind such methods is that the input instances may follow distributions with salient patterns that can be leveraged to overcome the worst-case computational hardness. For optimization problems over graphs, the common practice of neural combinatorial solvers consumes the inputs in the form of adjacency matrices. In this paper, we explore a vision-based method that is conceptually novel: can neural models solve graph optimization problems by \textit{taking a look at the graph pattern}? Our results suggest that the performance of such vision-based methods is not only non-trivial but also comparable to the state-of-the-art matrix-based methods, which opens a new avenue for developing data-driven optimization solvers.|数据驱动的方法已经被证明可以有效地解决图表中的组合优化问题，比如旅行推销员问题和车辆路径问题问题。这些方法背后的基本原理是，输入实例可能遵循具有显著模式的分布，这些模式可以用来克服最坏情况下的计算难度。对于图上的最优化问题，神经组合求解器通常以邻接矩阵的形式消耗输入。在本文中，我们探索了一种概念上新颖的基于视觉的方法: 神经模型能否通过文本{查看图形模式}来解决图形优化问题？我们的研究结果表明，这种基于视觉的方法的性能不仅是不平凡的，而且可以与最先进的基于矩阵的方法相媲美，这为开发数据驱动的优化求解器开辟了一条新的途径。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=VN-Solver:+Vision-based+Neural+Solver+for+Combinatorial+Optimization+over+Graphs)|0|
|[Findability: A Novel Measure of Information Accessibility](https://doi.org/10.1145/3583780.3615256)|Aman Sinha, Priyanshu Raj Mall, Dwaipayan Roy|Indian Institute of Science Education and Research, Kolkata, Kolkata, India|The overwhelming volume of data generated and indexed by search engines poses a significant challenge in retrieving documents from the index efficiently and effectively. Even with a well-crafted query, several relevant documents often get buried among a multitude of competing documents, resulting in reduced accessibility or `findability' of the desired document. Consequently, it is crucial to develop a robust methodology for assessing this dimension of Information Retrieval (IR) system performance. While previous studies have focused on measuring document accessibility disregarding user queries and document relevance, there exists no metric to quantify the findability of a document within a given IR system without resorting to manual labor. This paper aims to address this gap by defining and deriving a metric to evaluate the findability of documents as perceived by end-users. Through experiments, we demonstrate the varying impact of different retrieval models and collections on the findability of documents. Furthermore, we establish the findability measure as an independent metric distinct from retrievability, an accessibility measure introduced in prior literature.|搜索引擎生成和索引的大量数据对从索引中有效和高效地检索文件提出了重大挑战。即使是一个精心设计的查询，几个相关的文档通常也会被淹没在众多相互竞争的文档中，从而降低了所需文档的可访问性或“可找到性”。因此，开发一套可靠的方法来评估信息检索系统的性能是至关重要的。虽然以前的研究侧重于无视用户查询和文档相关性来衡量文档的可访问性，但是在给定的 IR 系统中，没有一个度量标准可以量化文档的可查找性，而不需要人工劳动。本文旨在通过定义和推导一个度量标准来评估最终用户所感知的文档的可查找性，从而弥补这一差距。通过实验，我们证明了不同的检索模型和集合对文档可查找性的不同影响。此外，我们建立了可查找性度量作为一个独立的度量区别于可检索性，一个可访问性度量介绍了以往的文献。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Findability:+A+Novel+Measure+of+Information+Accessibility)|0|
|[Learning to Simulate Complex Physical Systems: A Case Study](https://doi.org/10.1145/3583780.3615169)|Jiasheng Shi, Fu Lin, Weixiong Rao|Tongji University, Shanghai, China|Complex physical system simulation is important in many real world applications. We study the general simulation scenario to generate the response result when a physical object is applied by external factors. Traditional solvers on Partial Differential Equations (PDEs) suffer from significantly high computational cost. Many recent learning-based approaches focus on multivariate time series alike simulation prediction problem and do not work for our case. In this paper, we propose a novel two-level graph neural networks (GNNs) to learn the simulation result of a physical object applied by external factors. The key is a two-level graph structure where one fine mesh graph is mapped to multiple coarse one. Our preliminary evaluation on both synthetic and real datasets demonstrates that our work outperforms three state-of-the-arts by much lower errors.|复杂物理系统仿真在许多实际应用中具有重要意义。我们研究了一般的模拟场景，以产生响应结果时，一个物理对象的外部因素应用。偏微分方程(PDE)的传统求解方法计算量大。近年来，许多基于学习的方法都集中在多变量时间序列的仿真预测问题上，这些方法对我们的案例都不起作用。本文提出了一种新的两级图形神经网络(GNN) ，用于学习外部因素对物理对象的模拟结果。其关键是一个两层图结构，其中一个细网格图映射到多个粗网格图。我们对合成数据集和真实数据集的初步评估表明，我们的工作比三种最先进的数据集有更低的误差。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Simulate+Complex+Physical+Systems:+A+Case+Study)|0|
|[Higher-Order Peak Decomposition](https://doi.org/10.1145/3583780.3615209)|Xingyu Tan, Jingya Qian, Chen Chen, Sima Qing, Yanping Wu, Xiaoyang Wang, Wenjie Zhang|University of New South Wales, Sydney, NSW, Australia; University of Technology Sydney, Sydney, NSW, Australia; University of Wollongong, Wollongong, Australia; Zhejiang Gongshang University, Hangzhou, China|k-peak is a well-regarded cohesive subgraph model in graph analysis. However, the k-peak model only considers the direct neighbors of a vertex, consequently limiting its capacity to uncover higher-order structural information of the graph. To address this limitation, we propose a new model in this paper, named (k,h)-peak, which incorporates higher-order (h-hops) neighborhood information of vertices. Employing the (k,h)-peak model, we explore the higher-order peak decomposition problem that calculates the vertex peakness for all conceivable k values given a particular h. To tackle this problem efficiently, we propose an advanced local computation based algorithm, which is parallelizable, and additionally, devise novel pruning strategies to mitigate unnecessary computation. Experiments as well as case studies are conducted on real-world datasets to evaluate the efficiency and effectiveness of our proposed solutions.|K- 峰是图分析中一个被广泛认可的内聚子图模型。然而，k- 峰模型只考虑顶点的直接邻居，从而限制了它揭示图的高阶结构信息的能力。针对这一局限性，本文提出了一种新的模型——(k，h)-峰模型，该模型结合了顶点的高阶邻域信息。利用(k，h)-峰值模型，我们研究了高阶峰值分解问题，该问题计算给定一个特定的 h 的所有可能 k 值的顶点峰值。为了有效地解决这个问题，我们提出了一种改进的基于局部计算的并行算法，此外，设计了新的剪枝策略来减少不必要的计算。在实际数据集上进行了实验和案例研究，以评估我们提出的解决方案的效率和有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Higher-Order+Peak+Decomposition)|0|
|[Leveraging Knowledge and Reinforcement Learning for Enhanced Reliability of Language Models](https://doi.org/10.1145/3583780.3615273)|Nancy Tyagi, Surjodeep Sarkar, Manas Gaur|University of Maryland, Baltimore County, MD, USA|The Natural Language Processing(NLP) community has been using crowd sourcing techniques to create benchmark datasets such as General Language Understanding and Evaluation(GLUE) for training modern Language Models such as BERT. GLUE tasks measure the reliability scores using inter annotator metrics i.e. Cohens Kappa. However, the reliability aspect of LMs has often been overlooked. To counter this problem, we explore a knowledge-guided LM ensembling approach that leverages reinforcement learning to integrate knowledge from ConceptNet and Wikipedia as knowledge graph embeddings. This approach mimics human annotators resorting to external knowledge to compensate for information deficits in the datasets. Across nine GLUE datasets, our research shows that ensembling strengthens reliability and accuracy scores, outperforming state of the art.|自然语言处理(NLP)社区一直在使用众包技术来创建基准数据集，如通用语言理解和评估(GLUE) ，用于培训现代语言模型，如 BERT。GLUE 任务使用注释器间指标(即 Cohen Kappa)来度量可靠性得分。然而，LM 的可靠性方面往往被忽视。为了解决这个问题，我们探索了一种知识引导的 LM 集成方法，这种方法利用强化学习来整合概念网和维基百科的知识，将其作为知识图表嵌入。这种方法模仿人类注释者求助于外部知识来弥补数据集中的信息缺陷。在九个 GLUE 数据集中，我们的研究表明，集合增强了可靠性和准确性得分，表现优于最先进的水平。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Knowledge+and+Reinforcement+Learning+for+Enhanced+Reliability+of+Language+Models)|0|
|[Clustering-property Matters: A Cluster-aware Network for Large Scale Multivariate Time Series Forecasting](https://doi.org/10.1145/3583780.3615253)|Yuan Wang, Zezhi Shao, Tao Sun, Chengqing Yu, Yongjun Xu, Fei Wang|Institute of Computing Technology, Chinese Academy of Sciences & University of Chinese Academy of Sciences, Beijing, China|Large-scale Multivariate Time Series(MTS) widely exist in various real-world systems, imposing significant demands on model efficiency. A recent work, STID, addressed the high complexity issue of popular Spatial-Temporal Graph Neural Networks(STGNNs). Despite its success, when applied to large-scale MTS data, the number of parameters of STID for modeling spatial dependencies increases substantially, leading to over-parameterization issues and suboptimal performance. These observations motivate us to explore new approaches for modeling spatial dependencies in a parameter-friendly manner. In this paper, we argue that the spatial properties of variables are essentially the superposition of multiple cluster centers. Accordingly, we propose a Cluster-Aware Network(CANet), which effectively captures spatial dependencies by mining the implicit cluster centers of variables. CANet solely optimizes the cluster centers instead of the spatial information of all nodes, thereby significantly reducing the parameter amount. Extensive experiments on two large-scale datasets validate our motivation and demonstrate the superiority of CANet.|大规模多变量时间序列(MTS)广泛存在于各种实际系统中，对模型的效率提出了很高的要求。最近的一项工作，STID，解决了流行的时空图形神经网络(STGNN)的高复杂性问题。尽管 STID 在大规模 MTS 数据建模方面取得了成功，但 STID 用于空间依赖建模的参数数量却大幅增加，导致过度参数化问题和性能欠佳。这些观察促使我们探索新的方法，以参数友好的方式建模空间依赖性。本文认为变量的空间性质实质上是多个聚类中心的叠加。因此，我们提出了一个集群感知网络(CANet) ，它通过挖掘变量的隐式集群中心来有效地捕获空间依赖。CANet 只优化集群中心，而不优化所有节点的空间信息，从而大大减少了参数量。在两个大规模数据集上的大量实验验证了我们的动机，并证明了 CANet 的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Clustering-property+Matters:+A+Cluster-aware+Network+for+Large+Scale+Multivariate+Time+Series+Forecasting)|0|
|[Adaptive Graph Neural Diffusion for Traffic Demand Forecasting](https://doi.org/10.1145/3583780.3615153)|Yiling Wu, Xinfeng Zhang, Yaowei Wang|University of Chinese Academy of Sciences, Beijing, China; Peng Cheng Laboratory, Shenzhen, China|This paper studies the problem of spatial-temporal modeling for traffic demand forecasting. In practice, the temporal-spatial dependencies are complex. Conventional methods using graph convolutional networks and gated recurrent units cannot fully explore the patterns of demand evolution. Therefore, we propose Adaptive Graph Neural Diffusion (AGND) for spatial-temporal graph modeling. Specifically, complex spatial relations are modeled with a diffusion process by the graph neural diffusion. The spatial attention mechanism and a data-driven semantic adjacency matrix are used to describe the diffusivity function in the graph neural diffusion, which provides both local and global spatial information. Long-term temporal dependencies are modeled by the temporal attention mechanism. The proposed method is applied to two real-world datasets, and the results show that the proposed method outperforms state-of-the-art methods.|研究了交通需求预测的时空建模问题。在实践中，时空依赖性是复杂的。传统的使用图卷积网络和门限递归单元的方法不能完全探索需求演化的模式。因此，我们提出自适应图神经扩散(AGND)的时空图建模。具体地说，复杂的空间关系是通过图神经扩散过程建模的。空间注意机制和数据驱动的语义邻接矩阵被用来描述图形神经扩散中的扩散函数，它提供局部和全局的空间信息。长期的时间依赖由时间注意机制建模。将该方法应用于两个实际数据集，结果表明，该方法的性能优于现有方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adaptive+Graph+Neural+Diffusion+for+Traffic+Demand+Forecasting)|0|
|[Promoting Diversity in Mixed Complex Cooperative and Competitive Multi-Agent Environment](https://doi.org/10.1145/3583780.3615217)|Jia Wu, Zixiao Huang|University of Electronic Science and Technology of China, ChengDu, China|This paper introduces a new approach for promoting diversity of behavior in complex multi-agent environments that pose three challenges: 1) competition or collaboration among agents of diverse types, 2) the need for complex multi-agent coordination, which makes it challenging to achieve risky cooperation strategies, and 3) a large number of agents in the environment, leading to increased complexity when considering agent-to-agent relationships. To address the first two challenges, we leverage Reward Randomization in combination with Bayesian Optimization to train agents to exhibit diverse strategic behaviors, thereby mitigating the issue of risky cooperation. To address the challenge of learning in a large number of agents, we utilize MAPPO with parameter sharing to enhance learning efficiency. Experimental results demonstrate that within this multi-agent environment, agents can effectively learn multiple visually distinct behaviors, and the incorporation of these two techniques significantly improves agents' performance.|本文介绍了一种在复杂的多主体环境中促进行为多样性的新方法，它提出了三个挑战: 1)不同类型的主体之间的竞争或协作，2)需要复杂的多主体协作，这使得实现有风险的合作策略具有挑战性，3)环境中存在大量的主体，导致在考虑主体-主体关系时复杂性增加。为了解决前两个挑战，我们利用奖励随机化和贝叶斯优化相结合的方法来训练代理人展示多样化的战略行为，从而减轻风险合作的问题。为了解决大量智能体中学习的难题，我们利用参数共享的 MAPPO 来提高学习效率。实验结果表明，在这种多智能体环境下，智能体可以有效地学习多种视觉上不同的行为，这两种技术的结合显著提高了智能体的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Promoting+Diversity+in+Mixed+Complex+Cooperative+and+Competitive+Multi-Agent+Environment)|0|
|[MC-DRE: Multi-Aspect Cross Integration for Drug Event/Entity Extraction](https://doi.org/10.1145/3583780.3615190)|Jie Yang, Soyeon Caren Han, Siqu Long, Josiah Poon, Goran Nenadic|The University of Sydney, Sydney, NSW, Australia; The University of Western Australia, Perth, WA, Australia; The University of Manchester, Manchester, United Kingdom|Extracting meaningful drug-related information chunks, such as adverse drug events (ADE), is crucial for preventing morbidity and saving many lives. Most ADE are reported via an unstructured conversation with the medical context. Hence, applying a general entity recognition approach is not sufficient enough. The key is how to integrate and align multiple crucial aspects to detect drug event information, including drug event semantics, syntactic structures, and medical domain terminology. In this paper, we propose a new multi-aspect cross-integration framework for drug entity/event detection by capturing and aligning different context/language/knowledge properties from drug-related documents. We first construct multi-aspect encoders to describe semantic, syntactic, and medical document contextual information by conducting those slot tagging tasks, main drug entity/event detection, part-of-speech tagging, and general medical named entity recognition. Then, each encoder conducts cross integration and alignment with other contextual information in three ways, including the key-value cross, attention cross, and feedforward cross, so the multi-encoders are integrated in depth. Then, we perform extensive experiments on two widely used drug-related entity recognition downstream tasks, flat entity detection and discontinuous event extraction. Our model significantly outperforms all recent twelve state-of-the-art models. The implementation code will be released at~\url{https://github.com/adlnlp/mc-dre}.|提取有意义的药物相关信息块，如药物不良事件(ADE) ，对于预防发病率和挽救许多生命至关重要。大多数 ADE 是通过与医学背景的非结构化对话报告的。因此，仅仅采用一般的实体识别方法是不够的。关键是如何整合和调整多个关键方面来检测药物事件信息，包括药物事件语义、句法结构和医学领域术语。本文提出了一种新的多方面交叉集成框架，通过捕获和对齐药物相关文献中不同的上下文、语言和知识属性，实现了药物实体/事件检测的多方面交叉集成。我们首先构造多方面编码器来描述语义、句法和医学文献上下文信息，包括时隙标记任务、主要药物实体/事件检测、词性标记和一般医学命名实体识别。然后，每个编码器通过键值交叉、注意交叉和前馈交叉三种方式对其他上下文信息进行交叉整合和对齐，从而实现多个编码器的深度整合。然后，我们对两个广泛使用的药物相关实体识别下游任务，平面实体检测和不连续事件提取进行了广泛的实验。我们的模型明显优于最近的十二个最先进的模型。实现代码将在 ~ url { https://github.com/adlnlp/mc-dre }发布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MC-DRE:+Multi-Aspect+Cross+Integration+for+Drug+Event/Entity+Extraction)|0|
|[Positive-Unlabeled Node Classification with Structure-aware Graph Learning](https://doi.org/10.1145/3583780.3615250)|Hansi Yang, Yongqi Zhang, Quanming Yao, James T. Kwok|Hong Kong University of Science and Technology, Hong Kong, Hong Kong; Tsinghua University, Beijing, China; 4Paradigm, Beijing, China|Node classification on graphs is an important research problem with many applications. Real-world graph data sets may not be balanced and accurate as assumed by most existing works. A challenging setting is positive-unlabeled (PU) node classification, where labeled nodes are restricted to positive nodes. It has diverse applications, e.g., pandemic prediction or network anomaly detection. Existing works on PU node classification overlook information in the graph structure, which can be critical. In this paper, we propose to better utilize graph structure for PU node classification. We first propose a distance-aware PU loss that uses homophily in graphs to introduce more accurate supervision. We also propose a regularizer to align the model with graph structure. Theoretical analysis shows that minimizing the proposed loss also leads to minimizing the expected loss with both positive and negative labels. Extensive empirical evaluation on diverse graph data sets demonstrates its superior performance over existing state-of-the-art methods.|图的节点分类是一个具有广泛应用前景的重要研究课题。现实世界中的图形数据集可能并不像大多数现有工作所假定的那样平衡和准确。一个具有挑战性的设置是阳性未标记(PU)节点分类，其中标记节点仅限于阳性节点。它有多种应用，例如流行病预测或网络异常检测。现有的 PU 节点分类工作忽略了图结构中的信息，这可能是至关重要的。在本文中，我们提出了更好地利用图结构对 PU 节点进行分类。我们首先提出了一种距离感知的 PU 损失，它使用图中的同质性来引入更准确的监督。我们还提出了一个正则化器来使模型与图结构相一致。理论分析表明，最小化建议的损失也导致最小化的预期损失与正面和负面的标签。对各种图形数据集的广泛实证评估表明，其性能优于现有的最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Positive-Unlabeled+Node+Classification+with+Structure-aware+Graph+Learning)|0|
|[Toward a Foundation Model for Time Series Data](https://doi.org/10.1145/3583780.3615155)|ChinChia Michael Yeh, Xin Dai, Huiyuan Chen, Yan Zheng, Yujie Fan, Audrey Der, Vivian Lai, Zhongfang Zhuang, Junpeng Wang, Liang Wang, Wei Zhang|Visa Resarch, Palo Alto, CA, USA; University of California, Riverside, Riverside, CA, USA; Visa Research, Palo Alto, CA, USA|A foundation model is a machine learning model trained on a large and diverse set of data, typically using self-supervised learning-based pre-training techniques, that can be adapted to various downstream tasks. However, current research on time series pre-training has mostly focused on models pre-trained solely on data from a single domain, resulting in a lack of knowledge about other types of time series. However, current research on time series pre-training has predominantly focused on models trained exclusively on data from a single domain. As a result, these models possess domain-specific knowledge that may not be easily transferable to time series from other domains. In this paper, we aim to develop an effective time series foundation model by leveraging unlabeled samples from multiple domains. To achieve this, we repurposed the publicly available UCR Archive and evaluated four existing self-supervised learning-based pre-training methods, along with a novel method, on the datasets. We tested these methods using four popular neural network architectures for time series to understand how the pre-training methods interact with different network designs. Our experimental results show that pre-training improves downstream classification tasks by enhancing the convergence of the fine-tuning process. Furthermore, we found that the proposed pre-training method, when combined with the Transformer model, outperforms the alternatives.|基础模型是对大量不同数据集进行训练的机器学习模型，通常使用基于自监督学习的预训练技术，可以适应各种下游任务。然而，目前关于时间序列预训练的研究主要集中在仅仅根据单一领域的数据进行预训练的模型上，导致对其他类型的时间序列缺乏了解。然而，目前关于时间序列预训练的研究主要集中在专门针对来自单一领域的数据进行训练的模型上。因此，这些模型具有领域特定的知识，可能不容易从其他领域转移到时间序列。本文旨在利用来自多个领域的未标记样本，建立一个有效的时间序列基础模型。为了实现这一目标，我们重新利用公开可用的 UCR 档案，并评估了四种现有的基于自我监督学习的预训练方法，以及一种新的方法，对数据集。我们使用四种流行的时间序列神经网络结构来测试这些方法，以了解预训练方法如何与不同的网络设计相互作用。实验结果表明，预训练通过提高微调过程的收敛性来改善下游分类任务。此外，我们发现，提出的预训练方法，当结合变压器模型，优于替代方案。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Toward+a+Foundation+Model+for+Time+Series+Data)|0|
|[Simplex2vec Backward: From Vectors Back to Simplicial Complex](https://doi.org/10.1145/3583780.3615147)|Huixin Zhan, Kun Zhang, Zhong Chen, Victor S. Sheng|Texas Tech University, Lubbock, TX, USA; Xavier University of Louisiana, New Orleans, LA, USA|Simplicial neural networks (SNNs) were proposed to generate higher-order simplicial complex representations as vectors that encode not only pairwise relationships but also higher-order interactions between nodes. Although these vectors allowing us to consider richer data representations compared to typical graph convolution, most real-world graphs associated with molecule or human-related activities are often sensitive and might contain confidential information, e.g., molecular geometry or friend lists. However, little works investigate the potential threats for these simplicial complexes (higher-order interactions between nodes). We name this threat by Simplicial Complexes Reconstruction Attack (SCRA) and conduct this attack by studying whether the vectors can be inverted to (approximately) recover the simplicial complexes who used to generate them. Specifically, we first generate the vectors via a k-simplex2vec approach that extends the node2vec algorithm to simplices of higher dimensions to associate Euclidean vectors to simplicial complexes. We then present a Simplex2vec Backward algorithm to perform the SCRA on k-simplex2vec vectors by pointwise mutual information (PMI) matrix reconstruction.|简单神经网络(SNN)被提出来生成高阶单纯复形表示，作为矢量，不仅编码成对的关系，而且编码节点之间的高阶相互作用。虽然这些向量允许我们考虑比典型的图卷积更丰富的数据表示，但大多数与分子或人类相关活动相关的现实世界图往往是敏感的，可能包含机密信息，例如分子结构或朋友列表。然而，很少有工作研究这些单纯复合体(节点之间的高阶相互作用)的潜在威胁。我们将这种威胁命名为简单复合体重构攻击(SCRA) ，并通过研究向量是否可以反转来(近似地)恢复用来产生它们的简单复合体来实施这种攻击。具体来说，我们首先通过 k-simplex2vec 方法生成向量，该方法将 node2vec 算法扩展到更高维的单纯形，以将欧氏向量关联到单纯形复合体。然后，我们提出了一个单纯形向量2/vec 向后算法，通过点间互信息矩阵重构(PMI)对 k- 单纯形向量2/vec 向量进行 SCRA。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Simplex2vec+Backward:+From+Vectors+Back+to+Simplicial+Complex)|0|
|[Unlocking the Potential of Deep Learning in Peak-Hour Series Forecasting](https://doi.org/10.1145/3583780.3615159)|Zhenwei Zhang, Xin Wang, Jingyuan Xie, Heling Zhang, Yuantao Gu|Tsinghua University, Beijing, China|Unlocking the potential of deep learning in Peak-Hour Series Forecasting (PHSF) remains a critical yet underexplored task in various domains. While state-of-the-art deep learning models excel in regular Time Series Forecasting (TSF), they struggle to achieve comparable results in PHSF. This can be attributed to the challenges posed by the high degree of non-stationarity in peak-hour series, which makes direct forecasting more difficult than standard TSF. Additionally, manually extracting the maximum value from regular forecasting results leads to suboptimal performance due to models minimizing the mean deficit. To address these issues, this paper presents Seq2Peak, a novel framework designed specifically for PHSF tasks, bridging the performance gap observed in TSF models. Seq2Peak offers two key components: the CyclicNorm pipeline to mitigate the non-stationarity issue and a simple yet effective trainable-parameter-free peak-hour decoder with a hybrid loss function that utilizes both the original series and peak-hour series as supervised signals. Extensive experimentation on publicly available time series datasets demonstrates the effectiveness of the proposed framework, yielding a remarkable average relative improvement of 37.7% across four real-world datasets for both transformer- and non-transformer-based TSF models.|在高峰时间序列预测(PHSF)中，挖掘深度学习的潜力仍然是各个领域中一个至关重要但尚未得到充分开发的课题。虽然最先进的深度学习模型在常规时间序列预测(TSF)中表现出色，但在 PHSF 中却难以取得可比较的结果。这可归因于高峰时段序列的高度非平稳性所带来的挑战，这使得直接预测比标准 TSF 更加困难。此外，由于模型的平均亏损最小，人工从常规预测结果中提取最大值会导致性能不理想。为了解决这些问题，本文提出了专门为 PHSF 任务设计的新框架 Seq2Peak，它弥补了 TSF 模型中观察到的性能差距。Seq2Peak 提供了两个关键组件: CyclicNorm 流水线以减轻非平稳性问题，以及一个简单而有效的无可训练参数的峰时解码器，该解码器具有利用原始序列和峰时序列作为监督信号的混合损耗功能。对公开可用的时间序列数据集的广泛实验证明了所提出的框架的有效性，在基于变压器和非变压器的 TSF 模型的四个现实世界数据集中产生了37.7% 的显着平均相对改善。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unlocking+the+Potential+of+Deep+Learning+in+Peak-Hour+Series+Forecasting)|0|
|[POSPAN: Position-Constrained Span Masking for Language Model Pre-training](https://doi.org/10.1145/3583780.3615197)|Zhenyu Zhang, Lei Shen, Yuming Zhao, Meng Chen, Xiaodong He|JD AI Research, Beijing, China|Span-level masked language modeling (MLM) has shown to be advantageous to pre-trained language models over the original single-token MLM, as entities/phrases and their dependencies are critical to language understanding. Previous works only consider span length with some discrete distributions, while the dependencies among spans are ignored, i.e., assuming that the positions of masked spans are uniformly distributed. In this paper, we present POSPAN, a general framework to allow diverse position-constrained span masking strategies via the combination of span length distribution and position constraint distribution, which unifies all existing span-level masking methods. To verify the effectiveness of POSPAN in pre-training, we evaluate it on the datasets from several NLU benchmarks. Experimental results indicate that the position constraint is capable of enhancing span-level masking broadly, and our best POSPAN setting consistently outperforms its span-length-only counterparts and vanilla MLM. We also conduct theoretical analysis for the position constraint in masked language models to shed light on the reason why POSPAN works well, demonstrating the rationality and necessity of POSPAN.|跨层次的掩蔽语言建模(MLM)已经证明比原始的单标记 MLM 更有利于预先训练的语言模型，因为实体/短语及其依赖关系对语言理解至关重要。以往的工作只考虑跨度长度的离散分布，而跨度之间的依赖关系被忽略，即假设掩蔽跨度的位置是均匀分布的。本文提出了一种结合跨度长度分布和位置约束分布的 POSPAN 框架，该框架统一了现有的跨度级掩蔽方法，允许采用不同的位置约束跨度掩蔽策略。为了验证 POSPAN 在预训练中的有效性，我们从几个 NLU 基准数据集上对 POSPAN 进行了评估。实验结果表明，位置约束能够广泛地增强跨度级掩蔽，我们的最佳 POSPAN 设置始终优于其仅跨度长度的对手和普通的 MLM。本文还对掩蔽语言模型中的位置约束进行了理论分析，阐明了 POSPAN 语言运行良好的原因，论证了 POSPAN 语言运行的合理性和必要性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=POSPAN:+Position-Constrained+Span+Masking+for+Language+Model+Pre-training)|0|
|[Knowledge Graph Error Detection with Hierarchical Path Structure](https://doi.org/10.1145/3583780.3615201)|Zhao Zhang, Fuwei Zhang, Fuzhen Zhuang, Yongjun Xu|Institute of Artificial Intelligence, Beihang University, Beijing, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China|Knowledge graphs (KGs) play a pivotal role in AI-related applications. In order to construct or continuously enrich KGs, automatic knowledge construction and update mechanisms are usually utilized, which inevitably bring in plenty of noise, and noise would degrade the performance of downstream applications. Existing KG error detection methods utilize the embeddings of entities and relations, or directly leverage the paths between entities to test the plausibility of triples, while ignore the valuable hierarchical information contained in the paths between entities. Indeed, the paths between a pair of entities conform to a hierarchical structure. Specifically, there may be a number of paths between two entities, and each path is comprised of several relations. The hierarchical structure is able to provide precious information, and is beneficial to leverage the path information in a fine-grained manner. To this end, in this paper, we propose a novel model named KG error detection with HiErarchical pAth stRucture (HEAR for short). Particularly, for a given triple, HEAR first learns path representations with the relations contained in the path, then integrates all path representations, and at last predicts the plausibility of the triple. Finally, we extensively validate the superiority of HEAR against various state-of-the-art baselines.|知识图(KGs)在人工智能相关的应用中起着关键的作用。为了构建或不断丰富幼稚园，通常采用自动知识构建和更新机制，不可避免地会带来大量噪声，而噪声会降低下游应用的性能。现有的 KG 错误检测方法利用实体和关系的嵌入，或者直接利用实体之间的路径来检测三元组的合理性，而忽略了实体之间路径中包含的有价值的层次信息。事实上，一对实体之间的路径符合层次结构。具体来说，两个实体之间可能有许多路径，每条路径由多个关系组成。层次结构能够提供宝贵的信息，有利于以细粒度的方式利用路径信息。为此，本文提出了一种基于层次路径结构的 KG 错误检测模型(简称 HEAR)。特别地，对于给定的三元组，HEAR 首先利用路径中包含的关系学习路径表示，然后整合所有的路径表示，最后预测三元组的合理性。最后，我们广泛地验证了 HEAR 对于各种最先进的基线的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge+Graph+Error+Detection+with+Hierarchical+Path+Structure)|0|
|[XuanYuan 2.0: A Large Chinese Financial Chat Model with Hundreds of Billions Parameters](https://doi.org/10.1145/3583780.3615285)|Xuanyu Zhang, Qing Yang||In recent years, pre-trained language models have undergone rapid development with the emergence of large-scale models. However, there is a lack of open-sourced chat models specifically designed for the Chinese language, especially in the field of Chinese finance, at the scale of hundreds of billions. To address this gap, we introduce XuanYuan 2.0, the largest Chinese chat model to date, built upon the BLOOM-176B architecture. Additionally, we propose a novel training method called hybrid-tuning to mitigate catastrophic forgetting. By combining general-domain with domain-specific knowledge and integrating the stages of pre-training and fine-tuning, XuanYuan 2.0 is capable of providing accurate and contextually appropriate responses in the Chinese financial domain.|近年来，随着大规模模型的出现，预训练语言模型得到了迅速的发展。然而，目前缺乏专门为中文设计的开源聊天模式，尤其是在规模达数千亿美元的中国金融领域。为了弥补这一差距，我们引入了宣元2.0，这是迄今为止最大的中文聊天模型，建立在 BLOOM-176B 架构之上。此外，我们提出了一种新的训练方法称为混合调整，以减轻灾难性遗忘。通过将一般领域与特定领域的知识相结合，并将预训和微调阶段相结合，宣元2.0能够在中国金融领域提供准确和适合上下文的响应。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=XuanYuan+2.0:+A+Large+Chinese+Financial+Chat+Model+with+Hundreds+of+Billions+Parameters)|0|
|[Weight Matters: An Empirical Investigation of Distance Oracles on Knowledge Graphs](https://doi.org/10.1145/3583780.3615246)|Ke Zhang, Jiageng Chen, Zixian Huang, Gong Cheng|Nanjing University, Nanjing, China|Distance computation is a bottleneck that limits the performance of many applications based on knowledge graphs (KGs). One common approach to improving online distance computation is to offline precompute certain information to be stored in an index called distance oracle. However, its effectiveness remains under-studied in the setting where edges are methodologically weighted to capture the structure and semantics of edge types in a KG. To fill the gap, in this paper, we present the first evaluation of representative distance oracles on KGs with commonly used edge weighting schemes. Our negative results and empirical justifications provide insights and a motivation for future studies of this unique setting.|距离计算是限制许多基于知识图(KGs)的应用程序性能的瓶颈。改进在线距离计算的一种常见方法是离线预计算某些信息，这些信息将存储在一个称为“距离预言”的索引中。然而，它的有效性仍然没有得到充分研究的设置，边是方法论上的权重，以捕获结构和语义的边缘类型在一个 KG。为了填补这一空白，本文首次采用常用的边缘加权方案对幼儿园中具有代表性的距离预言进行了评价。我们的负面结果和经验证据为今后对这一独特背景的研究提供了见解和动力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Weight+Matters:+An+Empirical+Investigation+of+Distance+Oracles+on+Knowledge+Graphs)|0|
|[FCT-GAN: Enhancing Global Correlation of Table Synthesis via Fourier Transform](https://doi.org/10.1145/3583780.3615202)|Zilong Zhao, Robert Birke, Lydia Y. Chen|Delft University of Technology, Delft, Netherlands; University of Turin, Turin, Italy|An alternative method for sharing knowledge while complying with strict data access regulations, such as the European General Data Protection Regulation (GDPR), is the emergence of synthetic tabular data. Mainstream table synthesizers utilize methodologies derived from Generative Adversarial Networks (GAN). Although several state-of-the-art (SOTA) tabular GAN algorithms inherit Convolutional Neural Network (CNN)-based architectures, which have proven effective for images, they tend to overlook two critical properties of tabular data: (i) the global correlation across columns, and (ii) the semantic invariance to the column order. Permuting columns in a table does not alter the semantic meaning of the data, but features extracted by CNNs can change significantly due to their limited convolution filter kernel size. To address the above problems, we propose FCT-GAN the first conditional tabular GAN to adopt Fourier networks into table synthesis. FCT-GAN enhances permutation invariant GAN training by strengthening the learning of global correlations via Fourier layers. Extensive evaluation on benchmarks and real-world datasets show that FCT-GAN can synthesize tabular data with better (up to 27.8%) machine learning utility (i.e. a proxy of global correlations) and higher (up to 26.5%) statistical similarity to real data. FCT-GAN also has the least variation on synthetic data quality among 7 SOTA baselines on 3 different training-data column orders.|在遵守严格的数据访问规定(如欧洲通用数据保护条例(GDPR))的同时，共享知识的另一种方法是出现合成表格数据。主流表合成器利用源自生成对抗网络(GAN)的方法。尽管一些最先进的(SOTA)表格式 GAN 算法继承了基于卷积神经网络(CNN)的架构，这些架构已被证明对图像有效，但它们往往忽略了表格数据的两个关键属性: (i)跨列的全局相关性，以及(ii)对列顺序的语义不变性。对表中的列进行排列并不会改变数据的语义含义，但由于 CNN 的卷积过滤器内核大小有限，所以提取的特征可能会发生显著变化。针对上述问题，我们提出了 FCT-GAN 第一个条件表 GAN，采用傅里叶网络进行表综合。FCT-GAN 通过傅里叶层强化全局相关性的学习来增强置换不变 GAN 训练。对基准和真实世界数据集的广泛评估表明，FCT-GAN 可以综合表格数据，具有更好(高达27.8%)的机器学习效用(即全球相关性的代理)和更高(高达26.5%)与真实数据的统计相似性。FCT-GAN 在3种不同训练数据列顺序的7个 SOTA 基线中，综合数据质量变化最小。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FCT-GAN:+Enhancing+Global+Correlation+of+Table+Synthesis+via+Fourier+Transform)|0|
|[A Semi-Supervised Anomaly Network Traffic Detection Framework via Multimodal Traffic Information Fusion](https://doi.org/10.1145/3583780.3615214)|Yu Zheng, Xinglin Lian, Zhangxuan Dang, Chunlei Peng, Chao Yang, Jianfeng Ma|Xidian University, Xi'An, China|Anomaly traffic detection is a crucial issue in the cyber-security field. Previously, many researchers regarded anomaly traffic detection as a supervised classification problem. However, in real scenarios, anomaly network traffic is unpredictable, dynamically changing and difficult to collect. To address these limitations, we employ anomaly detection setting to propose a novel semi-supervised anomaly network traffic detection framework. It only learns features of normal samples during the training phase. Our framework utilizes low-pass filtering to extract multi-scale low-frequency information from 2-D traffic image. Furthermore, we design a two-stage fusion scheme to incorporate information from original and multi-scale low-frequency traffic image modalities. We conduct experiments on two public datasets: ISCX Tor-nonTor and USTC-TFC2016. The experimental results show that our method outperforms current state-of-the-art anomaly detection methods.|异常流量检测是网络安全领域的一个关键问题。以前，许多研究者将异常流量检测视为一个有监督的分类问题。然而，在实际场景中，异常网络流量是不可预测的、动态变化的，并且难以收集。为了解决这些局限性，我们使用异常检测设置来提出一种新的半监督异常网络流量检测框架。它只在训练阶段学习正常样本的特征。该框架利用低通滤波从二维交通图像中提取多尺度低频信息。此外，我们设计了一个两阶段的融合方案，融合了来自原始和多尺度低频交通图像模式的信息。我们在两个公共数据集上进行了实验: ISCX Tor-nonTor 和 USTC-TFC2016。实验结果表明，我们的方法优于目前最先进的异常检测方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Semi-Supervised+Anomaly+Network+Traffic+Detection+Framework+via+Multimodal+Traffic+Information+Fusion)|0|
|[Nowcast-to-Forecast: Token-Based Multiple Remote Sensing Data Fusion for Precipitation Forecast](https://doi.org/10.1145/3583780.3614702)|Sojung An|Korea Institute of Atmospheric Prediction Systems, Seoul, Republic of Korea|Accurate short-term precipitation forecast is of social and economic significance for preventing severe weather damage. Deep learning has been rapidly adopted in nowcasting based on weather radar, which plays a key role in preventing dangerous weather conditions such as torrential rainfall. However, the limited observation range of the radar imposes constraints on shorter forecast lead times. Securing a sufficient lead time for timely flood warnings and emergency responses is crucial. Here, we propose a novel GAN-based framework that combines radar and satellite data to extend forecast lead time. First, we tokenize the satellite image to align with radar dimensions and combine the satellite and radar data. We then apply positional encoding to add positional information. Second, we design the self-conditioned generator to estimate distributions of various rainfall intensities. Finally, we employ Gaussian Fourier features to map the input noise into a continuous representation. The proposed framework realistically and accurately produces time series images of various precipitation types. Furthermore, our multisource data-driven system outperforms numerical weather prediction at forecasts of up to 6 hours in South Korea.|准确的短期降水预报对于防止严重天气灾害的发生具有重要的社会和经济意义。深度学习在基于天气雷达的临近预报中得到了迅速的应用，对于防止暴雨等危险天气状况的发生起到了关键作用。然而，雷达有限的观测范围限制了较短的预报提前时间。确保有足够的准备时间以及时发布洪水警报和作出应急反应至关重要。在这里，我们提出了一个新的基于广域网的框架，结合雷达和卫星数据，以扩大预测提前期。首先，我们对卫星图像进行标记，以便与雷达尺寸对齐，并结合卫星和雷达数据。然后，我们应用位置编码来添加位置信息。其次，我们设计了自调节发生器来估计不同降雨强度的分布。最后，利用高斯傅里叶特征将输入噪声映射成一个连续的表示。建议的框架实际而准确地生成不同锋面雨的时间序列图像。此外，我们的多源数据驱动系统在韩国的预测时间长达6小时，表现优于数值天气预报。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Nowcast-to-Forecast:+Token-Based+Multiple+Remote+Sensing+Data+Fusion+for+Precipitation+Forecast)|0|
|[CallMine: Fraud Detection and Visualization of Million-Scale Call Graphs](https://doi.org/10.1145/3583780.3614662)|Mirela Teixeira Cazzolato, Saranya Vijayakumar, MengChieh Lee, Catalina Vajiac, Namyong Park, Pedro Fidalgo, Agma J. M. Traina, Christos Faloutsos|Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University & University of Sao Paulo, Sao Carlos, Brazil; University of Sao Paulo, Sao Carlos, Brazil; Mobileum and ISCTE-IUL, Lisbon, Portugal|Given a million-scale dataset of who-calls-whom data containing imperfect labels, how can we detect existing and new fraud patterns? We propose CallMine, with carefully designed features and visualizations. Our CallMine method has the following properties: (a) Scalable, being linear on the input size, handling about 35 million records in around one hour on a stock laptop; (b) Effective, allowing natural interaction with human analysts; (c) Flexible, being applicable in both supervised and unsupervised settings; (d) Automatic, requiring no user-defined parameters. In the real world, in a multi-million-scale dataset, CallMine was able to detect fraudsters 7,000x faster, namely in a matter of hours, while expert humans took over 10 months to detect them. CIKM-ARP Categories: Application; Analytics and machine learning; Data presentation.|给定一个百万级别的数据集谁打电话-谁的数据包含不完美的标签，我们如何检测现有的和新的欺诈模式？我们提出 CallMine，它具有精心设计的特性和可视化。我们的 CallMine 方法具有以下特性: (a)可扩展，输入大小呈线性，在一台普通笔记本电脑上大约一小时内处理3500万条记录; (b)有效，允许与人类分析师自然交互; (c)灵活，适用于监督和非监督设置; (d)自动，不需要用户定义的参数。在现实世界中，在一个数百万规模的数据集中，CallMine 能够以7000倍的速度发现欺诈者，也就是在几个小时内，而专家人类花了10个月才发现他们。CIKM-ARP 分类: 应用; 分析和机器学习; 数据表示。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CallMine:+Fraud+Detection+and+Visualization+of+Million-Scale+Call+Graphs)|0|
|[Continually-Adaptive Representation Learning Framework for Time-Sensitive Healthcare Applications](https://doi.org/10.1145/3583780.3615464)|Akash Choudhuri, Hankyu Jang, Alberto M. Segre, Philip M. Polgreen, Kishlay Jha, Bijaya Adhikari|The University of Iowa, Iowa City, IA, USA|Continual learning has emerged as a powerful approach to address the challenges of non-stationary environments, allowing machine learning models to adapt to new data while retaining the previously acquired knowledge. In time-sensitive healthcare applications, where entities such as physicians, hospital rooms, and medications exhibit continuous changes over time, continual learning holds great promise, yet its application remains relatively unexplored. This paper aims to bridge this gap by proposing a novel framework, i.e., Continually-Adaptive Representation Learning, designed to adapt representations in response to changing data distributions in evolving healthcare applications. Specifically, the proposed approach develops a continual learning strategy wherein the context information (e.g., interactions) of healthcare entities is exploited to continually identify and retrain the representations of those entities whose context evolved over time. Moreover, different from existing approaches, the proposed approach leverages the valuable patient information present in clinical notes to generate accurate and robust healthcare embeddings. Notably, the proposed continually-adaptive representations have practical benefits in low-resource clinical settings where it is difficult to training machine learning models from scratch to accommodate the newly available data streams. Experimental evaluations on real-world healthcare datasets demonstrate the effectiveness of our approach in time-sensitive healthcare applications such as Clostridioides difficile (C.diff) Infection (CDI) incidence prediction task and medical intensive care unit transfer prediction task.|连续学习已成为解决非平稳环境挑战的有力方法，使机器学习模型能够适应新的数据，同时保留以前获得的知识。在时间敏感的医疗保健应用中，医生、医院病房和药物等实体随着时间的推移显示出持续的变化，持续学习具有很大的前景，但其应用仍然相对未被探索。本文旨在通过提出一个新的框架，即连续自适应表示学习来弥补这一差距，该框架旨在适应不断变化的医疗保健应用数据分布的变化。具体而言，所提出的方法开发了一种持续学习策略，其中利用医疗实体的上下文信息(例如，交互)来不断识别和重新训练那些其上下文随时间演变的实体的表示。此外，不同于现有的方法，建议的方法利用临床记录中存在的有价值的患者信息来生成准确和健壮的医疗保健嵌入。值得注意的是，提出的持续自适应表示在低资源临床环境中具有实际好处，因为在这些环境中难以从头开始训练机器学习模型以适应新的可用数据流。对现实世界医疗数据集的实验评估证明了我们的方法在时间敏感的医疗应用中的有效性，例如艰难梭状芽孢杆菌感染(cdiff)发病率预测任务和医疗重症监护室转移预测任务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Continually-Adaptive+Representation+Learning+Framework+for+Time-Sensitive+Healthcare+Applications)|0|
|[Content-Based Email Classification at Scale](https://doi.org/10.1145/3583780.3615462)|Kirstin Early, Neil O'Hare, Christopher C. LuVogt|Yahoo Research, Mountain View, CA, USA; Yahoo Research, San Francisco, CA, USA|Understanding the content of email messages can enable new features that highlight what matters to users, making email a more useful tool for people to manage their lives. We present work from a consumer email platform to build multilabel models to classify messages according to a mail-specific, content-based taxonomy that represents the topic, type, and objective of an email. While state-of-the-art Transformer-based language models can achieve impressive results for text classification, these models are too costly to deploy at the scale of email. Using a knowledge distillation framework, we first build a complex, accurate teacher model from limited human-labeled training data and then use a large amount of teacher-labeled data to train lightweight student models that are suitable for deployment. The student models retain up to 91% of the predictive performance of the teacher model while reducing inference cost by three orders of magnitude. Deployed to production in Yahoo Mail, these models classify billions of emails every day and power features that help people tackle their inboxes.|了解电子邮件的内容可以使新的功能，突出什么对用户重要，使电子邮件成为一个更有用的工具，人们管理他们的生活。我们从一个消费者电子邮件平台开始构建多标签模型，以根据邮件特定的、基于内容的分类法对邮件进行分类，该分类法代表电子邮件的主题、类型和目标。虽然最先进的基于 Transformer 的语言模型可以在文本分类方面取得令人印象深刻的结果，但是这些模型的开销太大，无法在电子邮件规模上进行部署。使用知识提取框架，我们首先从有限的人类标记的训练数据中建立一个复杂的、精确的教师模型，然后使用大量的教师标记的数据来训练适合部署的轻量级学生模型。学生模型保留了教师模型91% 的预测性能，同时减少了三个数量级的推理成本。这些模型被部署到雅虎邮箱，每天为数十亿封电子邮件分类，并提供强大的功能帮助人们处理他们的收件箱。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Content-Based+Email+Classification+at+Scale)|0|
|[AutoBuild: Automatic Community Building Labeling for Last-mile Delivery](https://doi.org/10.1145/3583780.3614658)|Zhiqing Hong, Dongjiang Cao, Haotian Wang, Guang Wang, Tian He, Desheng Zhang|JD Logistics, Beijing, China; JD Logistics & Rutgers University, New Brunswick, NJ, USA; Rutgers University, New Brunswick, NJ, USA; Florida State University, Tallahassee, FL, USA|Fine-grained community-building information, such as building names and accurate geographical coordinates, is critical for a range of practical applications like navigation and door-to-door services (e.g., on-demand delivery and last-mile delivery). A common practice of traditional methods to gather community-building information usually relies on manual collection, which is typically labor-intensive and time-consuming. To address these issues, we utilize the massive data generated from e-commerce delivery services and design a framework, AutoBuild, for fine-grained large-scale community-building labeling. AutoBuild consists of two main components: (i) a Location Candidate Detection Module that identifies potential building names and coordinates from multi-source delivery data, and (ii) a Progressive Building Matching Model that employs trajectory modeling, human behavior analysis, and heterogeneous graph alignment to match building names and coordinates. To evaluate the performance of AutoBuild, we applied it to two real-world multi-modal datasets from Beijing City and Chengdu City. The results reveal that AutoBuild significantly outperforms multiple baseline models by 50-meter accuracy of 81.8% and 100-meter accuracy of 95.9% in Beijing City. More importantly, we conduct a real-world case study to demonstrate the practical impact of AutoBuild in last-mile delivery.|细粒度的社区建设信息，如建筑物名称和准确的经纬度，对于一系列实际应用，如导航和门到门服务(如按需配送和最后一英里配送)至关重要。收集社区建设信息的传统方法通常依赖于人工收集，这通常是劳动密集型和耗时的。为了解决这些问题，我们利用电子商务交付服务产生的大量数据，并设计了一个框架 AutoBuild，用于细粒度的大规模社区建设标签。AutoBuild 由两个主要组成部分组成: (i)位置候选检测模块，从多源交付数据中识别潜在的建筑名称和坐标; (ii)渐进式建筑匹配模型，采用轨迹建模，人类行为分析和异质图形对齐来匹配建筑名称和坐标。为了评价 AutoBuild 的性能，我们将其应用于来自北京和成都两个真实世界的多模态数据集。结果表明，在北京市，AutoBuild 的50米准确率为81.8% ，100米准确率为95.9% ，明显优于多基线模型。更重要的是，我们进行了一个真实世界的案例研究，以演示 AutoBuild 在最后一英里交付中的实际影响。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AutoBuild:+Automatic+Community+Building+Labeling+for+Last-mile+Delivery)|0|
|[Urban-scale POI Updating with Crowd Intelligence](https://doi.org/10.1145/3583780.3614724)|Zhiqing Hong, Haotian Wang, Wenjun Lyu, Hai Wang, Yunhuai Liu, Guang Wang, Tian He, Desheng Zhang|Florida State University, Tallahassee, FL, USA; JD Logistics, Beijing, China; Rutgers University, New Brunswick, NJ, USA; Peking University, Beijing, China; Southeast University, Nanjing, China|Points of Interest (POIs), such as entertainment, dining, and living, are crucial for urban planning and location-based services. However, the high dynamics and expensive updating costs of POIs pose a key roadblock for their urban applications. This is especially true for developing countries, where active economic activities lead to frequent POI updates (e.g., merchants closing down and new ones opening). Therefore, POI updating, i.e., detecting new POIs and different names of the same POIs (alias) to update the POI database, has become an urgent but challenging problem to address. In this paper, we attempt to answer the research question of how to detect and update large-scale POIs via a low-cost approach. To do so, we propose a novel framework called UrbanPOI, which formulates the POI updating problem as a tagging and detection problem based on multi-modal logistics delivery data. UrbanPOI consists of two key modules: (i) a hierarchical POI candidate generation module based on the POINet model that detects POIs from shipping addresses; and (ii) a new POI detection module based on the Siamese Attention Network that models multi-modal data and crowd intelligence. We evaluate our framework on real-world logistics delivery datasets from two Chinese cities. Extensive results show that our model outperforms state-of-the-art models in Beijing City by 26.2% in precision and 10.7% in F1-score, respectively.|兴趣点(POI) ，如娱乐、餐饮和生活，对于城市规划和基于位置的服务至关重要。然而，POI 的高动态性和昂贵的更新成本对其城市应用构成了一个关键的障碍。发展中国家尤其如此，在这些国家，活跃的经济活动导致频繁的 POI 更新(例如，商家关闭和新的开业)。因此，检测新的 POI 和同一 POI (别名)的不同名称以更新 POI 数据库，已成为一个迫切但具有挑战性的问题。本文试图回答如何利用低成本方法检测和更新大规模 POI 的研究问题。为此，我们提出了一个名为 UrbanPOI 的新框架，该框架将 POI 更新问题表述为一个基于多模式物流配送数据的标记和检测问题。UrbanPOI 由两个关键模块组成: (i)基于 POINet 模型的分层 POI 候选生成模块，该模块从运输地址中检测 POI; (ii)基于暹罗注意网络的新 POI 检测模块，该模块对多模态数据和人群智能进行建模。我们评估了我们的框架在现实世界的物流配送数据集从两个中国城市。大量的实验结果表明，该模型在精度上优于北京市最先进的模型26.2% ，在 F1评分上优于北京市最先进的模型10.7% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Urban-scale+POI+Updating+with+Crowd+Intelligence)|0|
|[Climate Intervention Analysis using AI Model Guided by Statistical Physics Principles](https://doi.org/10.1145/3583780.3615460)|Soo Kyung Kim, Kalai Ramea, Salva Rühling Cachay, Haruki Hirasawa, Subhashis Hazarika, Dipti Hingmire, Peetak Mitra, Philip J. Rasch, Hansi A. Singh|Palo Alto Research Center, Palo Alto , CA, USA; Excarta, San Francisco, CA, USA; University of Victoria, Victoria, BC, Canada; University of California, San Diego, La Jolla, CA, USA; Pacific Northwest National Laboratory, Richland, WA, USA; Palo Alto Research Center, Palo Alto, CA, USA|The availability of training data remains a significant obstacle for the implementation of machine learning in scientific applications. In particular, estimating how a system might respond to external forcings or perturbations requires specialized labeled data or targeted simulations, which may be computationally intensive to generate at scale. In this study, we propose a novel solution to this challenge by utilizing a principle from statistical physics known as the Fluctuation-Dissipation Theorem (FDT) to discover knowledge using an AI model that can rapidly produce scenarios for different external forcings. By leveraging FDT, we are able to extract information encoded in a large dataset produced by Earth System Models, which includes 8250 years of internal climate fluctuations, to estimate the climate system's response to forcings. Our model, AiBEDO, is capable of capturing the complex, multi-timescale effects of radiation perturbations on global and regional surface climate, allowing for a substantial acceleration of the exploration of the impacts of spatially-heterogenous climate forcers. To demonstrate the utility of AiBEDO, we use the example of a climate intervention technique called Marine Cloud Brightening, with the ultimate goal of optimizing the spatial pattern of cloud brightening to achieve regional climate targets and prevent known climate tipping points. While we showcase the effectiveness of our approach in the context of climate science, it is generally applicable to other scientific disciplines that are limited by the extensive computational demands of domain simulation models. Source code of AiBEDO framework is made available at https://github.com/kramea/kdd_aibedo. A sample dataset is made available at https://doi.org/10.5281/zenodo.7597027. Additional data available upon request.|训练数据的可用性仍然是在科学应用中实施机器学习的一个重大障碍。特别是，估计一个系统可能如何响应外部强迫或扰动需要专门的标记数据或有针对性的模拟，这可能是计算密集型产生的规模。在这项研究中，我们提出了一个新颖的解决方案，通过利用统计物理学中的一个原理——涨落耗散定理(FDT) ，使用人工智能模型来发现知识，该模型可以快速地为不同的外部压力生成场景。通过利用 FDT，我们能够提取由地球系统模型产生的大型数据集中编码的信息，其中包括8250年的内部气候波动，以估计气候系统对外力的反应。我们的模型 AiBEDO 能够捕捉辐射扰动对全球和区域表面气候的复杂的、多时间尺度的影响，允许大幅度加速探索空间异质性气候力量的影响。为了证明 AiBEDO 的实用性，我们使用了一个名为海洋云亮化的气候干预技术的例子，其最终目标是优化云亮化的空间模式，以实现区域气候目标，并防止已知的气候临界点。虽然我们在气候科学的背景下展示了我们的方法的有效性，但它通常适用于其他受到领域模拟模型广泛的计算需求限制的科学分支。AiBEDO 框架的源代码可在 https://github.com/kramea/kdd_aibedo 查阅。Https://doi.org/10.5281/zenodo.7597027提供样本数据集。可根据要求提供其他数据。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Climate+Intervention+Analysis+using+AI+Model+Guided+by+Statistical+Physics+Principles)|0|
|[A Hierarchical Imitation Learning-based Decision Framework for Autonomous Driving](https://doi.org/10.1145/3583780.3615454)|Hebin Liang, Zibin Dong, Yi Ma, Xiaotian Hao, Yan Zheng, Jianye Hao|Harbin Institution of Technology (Shenzhen), Shenzhen, China; Tianjin University, Tianjin, China|In this paper, we focus on the decision-making challenge in autonomous driving, a central and intricate problem influencing the safety and practicality of autonomous vehicles. We propose an innovative hierarchical imitation learning framework that effectively alleviates the complexity of learning in autonomous driving decision-making problems by decoupling decision-making tasks into sub-problems. Specifically, the decision-making process is divided into two levels of sub-problems: the upper level directs the vehicle's lane selection and qualitative speed management, while the lower level implements precise control of the driving speed and direction. We harness Transformer-based models for solving each sub-problem, enabling overall hierarchical framework to comprehend and navigate diverse and various road conditions, ultimately resulting in improved decision-making. Through an evaluation in several typical driving scenarios within the SMARTS autonomous driving simulation environment, our proposed hierarchical decision-making framework significantly outperforms end-to-end reinforcement learning algorithms and behavior cloning algorithm, achieving an average pass rate of over 90%. Our framework's effectiveness is substantiated by its commendable achievements at the NeurIPS 2022 Driving SMARTS competition, where it secures dual track championships.|本文主要研究影响自主驾驶汽车安全性和实用性的核心问题——自主驾驶决策挑战。提出了一种创新的层次模拟学习框架，通过将决策任务解耦为子问题，有效地降低了自主驾驶决策问题学习的复杂性。具体来说，决策过程分为两个层次的子问题: 上层指导车辆的车道选择和定性速度管理，下层实现对行驶速度和方向的精确控制。我们利用变压器为基础的模型来解决每个子问题，使整体层次框架理解和导航不同的和各种各样的道路条件，最终导致改进的决策。通过对 SMARTS 自主驾驶模拟环境中几个典型驾驶场景的评估，我们提出的分层决策框架显著优于端到端强化学习算法和行为克隆算法，平均合格率超过90% 。我们的框架的有效性是由其值得赞扬的成就在 NeurIPS 2022驾驶 SMARTS 竞赛，其中它确保双轨锦标赛。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Hierarchical+Imitation+Learning-based+Decision+Framework+for+Autonomous+Driving)|0|
|[Enhancing Dynamic On-demand Food Order Dispatching via Future-informed and Spatial-temporal Extended Decisions](https://doi.org/10.1145/3583780.3615473)|Yile Liang, Donghui Li, Jiuxia Zhao, Xuetao Ding, Huanjia Lian, Jinghua Hao, Renqing He|Meituan Inc., Beijing, China; Meituan, Beijing, China|On-demand food delivery (OFD) service has gained fast-growing popularity all around the world. Order dispatching is instrumental to large-scale OFD platforms, such as Meituan, which continuously match food order requests to couriers at a scale of tens of millions each day to satisfy the needs of consumers, couriers, and merchants. However, due to high dynamism and inevitable uncertainties in the real-world environment, it is not an easy task to achieve long-term global objective optimization through continuous isolated optimization decisions at each dispatch moment. Our work proposes the concept of "courier occupancy" (CO) to precisely quantify the impact of order assignment on the courier's delivery efficiency, realizing a decomposition of long-term and macro goals into various dispatch moments and micro decision-making dimensions. Then in the prediction phase, an improved and universally applicable distribution estimation method is designed to quantify CO which is a stochastic variable and contains future information, combining Monte Carlo dropout and knowledge distillation. In the optimization phase, we use CO to model the objective function at each dispatch moment to introduce future information and extend dispatch decisions from merely who to assign the order to both when and who to assign it, significantly enhancing the long-term optimization capability of dispatching decisions and avoiding local greed. We conduct extensive offline simulations based on real dispatching data as well as online AB tests through Meituan's platform. Results show that our method consistently improves the couriers' delivery efficiency and consumers' satisfaction.|按需送餐(OFD)服务在全世界迅速普及。订单调度对于大型的 OfD 平台来说非常重要，例如美团，它每天以数千万的规模不断地将食品订单请求与快递匹配，以满足消费者、快递员和商家的需求。然而，由于现实环境中的高动态性和不可避免的不确定性，通过每个调度时刻的连续孤立优化决策来实现长期的全局目标优化是一项不容易的任务。我们的工作提出了“快递员占用”(CO)的概念，以精确量化订单分配对快递员配送效率的影响，实现了长期和宏观目标分解为各种分配时刻和微观决策维度。然后在预测阶段，结合蒙特卡罗退出和知识提取，设计了一种改进的、普遍适用的分布估计方法，对含有未来信息的随机变量 CO 进行量化。在优化阶段，利用 CO 对每个调度时刻的目标函数进行建模，引入未来信息，并将调度决策从单纯的由谁分配指令扩展到何时分配和由谁分配，显著提高了调度决策的长期优化能力，避免了局部贪婪。我们基于真实的调度数据进行大量的离线模拟，并通过美团平台进行在线 AB 测试。结果表明，该方法一致地提高了快递员的配送效率和消费者的满意度。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Dynamic+On-demand+Food+Order+Dispatching+via+Future-informed+and+Spatial-temporal+Extended+Decisions)|0|
|[FAF: A Risk Detection Framework on Industry-Scale Graphs](https://doi.org/10.1145/3583780.3615477)|Yice Luo, Guannan Wang, Yongchao Liu, Jiaxin Yue, Weihong Cheng, Binjie Fei|Ant Group, Hangzhou, China|It is neither effective nor profitable for individuals to attempt to bypass Ant Group's comprehensive risk control system. However, there are still criminals (such as underground loan sharks and professional hackers,), who may teach borrowers how to use hacking techniques to circumvent Ant Group and its partners' risk control system. Despite the fact that our risk control system has greatly reduced fraud losses for merchants in practice, a significant number of intermediary-related frauds still occur. During our investigation into fraud events at Zhima Credit Renting (ZCR), we discovered that more than 30 percent of fraud cases were directly linked to malicious intermediaries. To address this issue, we propose an anti-abettor fraud detection framework, called FAF (Fraud-Abettor-Fraud), specifically designed to combat intermediary-related frauds on an industry-wide scale. We have developed a series of algorithms under the FAF framework, which outperform commonly used risk detection methods and meet real-world business requirements. In this paper, we use ZCR's risk management application as a real-world example-which has deployed FAF for over 1 year-to demonstrate the superiority of the FAF framework compared to existing methods.|对个人而言，试图绕开蚂蚁集团的全面风险控制体系既无效果，也无利可图。然而，仍然有犯罪分子(如地下高利贷者和专业黑客) ，他们可能会教导借款人如何使用黑客技术来规避蚂蚁金服及其合作伙伴的风险控制系统。尽管我国的风险控制体系在实践中大大减少了商家的欺诈损失，但仍然存在大量与中介相关的欺诈行为。在我们对芝马信用租赁(ZCR)欺诈事件的调查中，我们发现超过30% 的欺诈案件直接与恶意中介有关。为了解决这一问题，我们提出了一个名为 FAF (Fraud-Abettor-Fraud)的反教唆欺诈侦查框架，专门用于在整个行业范围内打击与中介相关的欺诈行为。我们在 FAF 框架下开发了一系列算法，它们的性能优于常用的风险检测方法，并且满足了现实世界的业务需求。本文以 ZCR 的风险管理应用程序为实例，论证了 FAF 框架相对于现有方法的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FAF:+A+Risk+Detection+Framework+on+Industry-Scale+Graphs)|0|
|[Retention is All You Need](https://doi.org/10.1145/3583780.3615497)|Karishma Mohiuddin, Mirza Ariful Alam, Mirza Mohtashim Alam, Pascal Welke, Michael Martin, Jens Lehmann, Sahar Vahdati|University of Rajshahi, Rajshahi, Bangladesh; TU Wien, Vienna, Austria; InfAI, Dresden, Germany; University of Bonn, Bonn, Germany; TU Dresden, InfAI, & Amazon, Dresden, Germany; InfAI, Leipzig, Germany; FIZ Karlsruhe, Karlsruhe, Germany|Skilled employees are usually seen as the most important pillar of an organization. Despite this, most organizations face high attrition and turnover rates. While several machine learning models have been developed for analyzing attrition and its causal factors, the interpretations of those models remain opaque. In this paper, we propose the HR-DSS approach, which stands for Human Resource Decision Support System, and uses explainable AI for employee attrition problems. The system is designed to assist human resource departments in interpreting the predictions provided by machine learning models. In our experiments, eight machine learning models are employed to provide predictions, and the results achieved by the best-performing model are further processed by the SHAP explainability process. We optimize both the correctness and explanation of the results. Furthermore, using "What-if-analysis", we aim to observe plausible causes for attrition of an individual employee. The results show that by adjusting the specific dominant features of each individual, employee attrition can turn into employee retention through informative business decisions. Reducing attrition is not only a problem for any specific organization but also, in some countries, becomes a significant societal problem that impacts the well-being of both employers and employees.|有技能的员工通常被视为一个组织最重要的支柱。尽管如此，大多数组织都面临着高流失率和更替率。虽然一些机器学习模型已经开发了分析磨损及其原因的因素，这些模型的解释仍然是不透明的。本文提出了人力资源决策支持系统的人力资源决策支持系统(HR-DSS)方法，并将可解释人工智能应用于员工流失问题。该系统旨在帮助人力资源部门解释机器学习模型提供的预测。在我们的实验中，我们使用了八个机器学习模型来提供预测，并且使用 SHAP 可解释性过程来进一步处理表现最佳的模型所得到的结果。我们优化了结果的正确性和解释性。此外，使用“如果-如果-分析”，我们的目的是观察合理的原因，个别员工的磨损。研究结果表明，通过调整个体的显性特征，员工流失可以通过信息化的商业决策转化为员工留住。减少自然减员不仅是任何特定组织的问题，而且在一些国家成为影响雇主和雇员福祉的重大社会问题。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Retention+is+All+You+Need)|0|
|[GraphFC: Customs Fraud Detection with Label Scarcity](https://doi.org/10.1145/3583780.3614690)|Karandeep Singh, YuChe Tsai, ChengTe Li, Meeyoung Cha, ShouDe Lin|National Cheng Kung University, Tainan, Taiwan Roc; National Taiwan University, Taipei, Taiwan Roc; Institute for Basic Science & KAIST, Daejeon, Republic of Korea; Institute for Basic Science, Daejeon, Republic of Korea|Custom officials across the world encounter huge volumes of transactions. With increased connectivity and globalization, the customs transactions continue to grow every year. Associated with customs transactions is the customs fraud - the intentional manipulation of goods declarations to avoid the taxes and duties. With limited manpower, the custom offices can only undertake manual inspection of a limited number of declarations. This necessitates the need for automating the customs fraud detection by machine learning (ML) techniques. Due the limited manual inspection for labeling the new-incoming declarations, the ML approach should have robust performance subject to the scarcity of labeled data. However, current approaches for customs fraud detection are not well suited and designed for this real-world setting. In this work, we propose $\textbf{GraphFC}$ ($\textbf{Graph}$ neural networks for $\textbf{C}$ustoms $\textbf{F}$raud), a model-agnostic, domain-specific, semi-supervised graph neural network based customs fraud detection algorithm that has strong semi-supervised and inductive capabilities. With upto 252% relative increase in recall over the present state-of-the-art, extensive experimentation on real customs data from customs administrations of three different countries demonstrate that GraphFC consistently outperforms various baselines and the present state-of-art by a large margin.|世界各地的海关官员都会遇到大量的交易。随着互联互通和全球化程度的提高，海关交易每年都在增长。与海关交易有关的是海关欺诈——蓄意操纵货物申报以逃避税收和关税。在人力有限的情况下，海关只能对有限数量的报关单进行人工检查。这就需要通过机器学习(ML)技术实现海关欺诈检测的自动化。由于对新传入声明进行标记的人工检查有限，因此在标记数据稀缺的情况下，机器学习方法应该具有健壮的性能。然而，目前的海关欺诈检测方法并不十分适合这种现实环境。在这项工作中，我们提出了 $textbf { GraphFC } $($textbf { Graph } $神经网络为 $textbf { C } $ustoms $textbf { F } $raud) ，一个模型无关的，领域特定的，基于半监督图神经网络的海关欺诈检测算法，具有强大的半监督和归纳能力。与目前的最新技术水平相比，召回率相对增加了252% ，三个不同国家海关当局对真实海关数据的广泛实验表明，GraphFC 的表现始终大大优于各种基准和目前的最新技术水平。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphFC:+Customs+Fraud+Detection+with+Label+Scarcity)|0|
|[Generating Optimized Molecules without Patent Infringement](https://doi.org/10.1145/3583780.3615479)|Sally Turutov, Kira Radinsky|Technion - Israel Institute of Technology, Haifa, Israel|Molecular optimization seeks to improve a given molecule's therapeutic profile. It is a key challenge in drug development, but it is difficult due to the constraints of molecular similarity to the original molecule and the size of the chemical space to explore. Numerous works tackled this problem with initial success. Unlike previous works that focus on generating molecules that optimize chemical properties, we focus on the optimization while attempting to "move away" from patented molecules. We present a novel loss function and its utilization in numerous types of molecular optimization algorithms. The loss allows to improve molecular properties while decreasing patent-infringement. We perform empirical evaluation showing superior performance of state-of-the-art models when using the novel loss function. The deployment of the system is underway at the Targeted Drug Delivery and Personalized Medicine labs. It will be utilized to generate targeted carriers of mRNA, providing a new method of drug delivery. The system is also producing non-patented candidates for industrial use, making it a valuable tool in the field of personalized medicine.|分子优化试图改善给定分子的治疗特性。这是药物开发中的一个关键挑战，但由于与原始分子的分子相似性和化学空间大小的限制而难以探索。许多著作初步成功地解决了这个问题。不像以前的工作，重点是生成分子，优化化学性质，我们关注的优化，同时试图“远离”专利分子。我们提出了一种新的损失函数及其在许多类型的分子优化算法中的应用。这种损失可以在减少专利侵权的同时提高分子性质。我们进行的实证评估表明，当使用新的损失函数时，最先进的模型的优越性能。该系统正在靶向药物输送和个体化医学实验室进行部署。它将被用于产生靶向的 mRNA 载体，为药物传递提供一种新的方法。该系统还为工业用途生产非专利候选产品，使其成为个体化医学领域的一个有价值的工具。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generating+Optimized+Molecules+without+Patent+Infringement)|0|
|[Voucher Abuse Detection with Prompt-based Fine-tuning on Graph Neural Networks](https://doi.org/10.1145/3583780.3615505)|Zhihao Wen, Yuan Fang, Yihan Liu, Yang Guo, Shuji Hao|Lazada Inc., Singapore, Singapore; Singapore Management University, Singapore, Singapore|Voucher abuse detection is an important anomaly detection problem in E-commerce. While many GNN-based solutions have emerged, the supervised paradigm depends on a large quantity of labeled data. A popular alternative is to adopt self-supervised pre-training using label-free data, and further fine-tune on a downstream task with limited labels. Nevertheless, the "pre-train, fine-tune" paradigm is often plagued by the objective gap between pre-training and downstream tasks. Hence, we propose VPGNN, a prompt-based fine-tuning framework on GNNs for voucher abuse detection. We design a novel graph prompting function to reformulate the downstream task into a similar template as the pretext task in pre-training, thereby narrowing the objective gap. Extensive experiments on both proprietary and public datasets demonstrate the strength of VPGNN in both few-shot and semi-supervised scenarios. Moreover, an online deployment of VPGNN in a production environment shows a 23.4% improvement over two existing deployed models.|凭单滥用侦测是电子商务中一个重要的异常检测问题。虽然许多基于 GNN 的解决方案已经出现，监督范式依赖于大量的标记数据。一个流行的替代方案是采用自我监督的预先训练，使用无标签数据，并进一步微调下游任务与有限的标签。尽管如此，“预训练，微调”范式经常被预训练和下游任务之间的客观差距所困扰。因此，我们提出了 VPGNN，一个基于提示的微调架构 GNN，用于票据滥用检测。我们设计了一个新颖的图形提示函数，将下游任务重新表述为一个类似的模板，作为预训练中的借口任务，从而缩小了目标差距。在专有和公开数据集上的大量实验证明了 VPGNN 在少镜头和半监督场景中的强度。此外，在生产环境中在线部署 VPGNN 比现有的两个部署模型提高了23.4% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Voucher+Abuse+Detection+with+Prompt-based+Fine-tuning+on+Graph+Neural+Networks)|0|
|[Logistics Audience Expansion via Temporal Knowledge Graph](https://doi.org/10.1145/3583780.3614695)|Hua Yan, Yingqiang Ge, Haotian Wang, Desheng Zhang, Yu Yang|Lehigh University, Bethlehem, PA, USA; Rutgers University, Piscataway, NJ, USA; JD Logistics, Beijing, China|Logistics audience expansion, the process for logistics companies to find potential long-term customers, is one of the most important tasks for business growth. However, existing methods for conventional audience expansion fall short due to two significant challenges, the intricate interplay of multiple complex factors in the logistics scenario and the emphasis on long-term logistics service usage instead of one-time promotions. To address the above limitations, we design LOGAE-TKG, a logistics audience expansion method based on a temporal knowledge graph, which consists of three components: (i) a temporal logistics knowledge graph pre-trained model to model the effect of multiple complex factors and build a solid logistics knowledge base for contracting and usage prediction; (ii) an intention learning model with data augmentation-based comparison to capture the contracting intention; (iii) a future pattern discovery model to uncover post-contract patterns. We evaluate and deploy our method on the JingDong e-commerce platform. Extensive offline experiment results and real-world deployment results demonstrate the effectiveness of our method.|物流受众拓展是物流企业寻找潜在长期客户的过程，是企业发展的重要任务之一。然而，由于物流情景中多种复杂因素错综复杂的相互作用以及强调物流服务的长期使用而不是一次性促销这两个重大挑战，现有的传统扩大受众的方法存在不足。针对上述局限性，我们设计了一种基于时态知识图的物流受众扩展方法 LOGAE-TKG，该方法由三个部分组成: (1)一个时态物流知识图预训练模型，用于模拟多个复杂因素的影响，建立一个可靠的物流知识库，用于订约和使用预测; (2)一个基于数据增强的比较意向学习模型，用于捕获订约意向; (3)一个未来模式发现模型，用于揭示后订约模式。我们在京东电子商务平台上对我们的方法进行了评估和部署。大量的离线实验结果和实际部署结果证明了该方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Logistics+Audience+Expansion+via+Temporal+Knowledge+Graph)|0|
|[DeepSTA: A Spatial-Temporal Attention Network for Logistics Delivery Timely Rate Prediction in Anomaly Conditions](https://doi.org/10.1145/3583780.3614671)|Jinhui Yi, Huan Yan, Haotian Wang, Jian Yuan, Yong Li|JD Logistics, Beijing, China; Tsinghua University, Beijing, China; Tsinghua University & JD Logistics, Beijing, China|Prediction of couriers' delivery timely rates in advance is essential to the logistics industry, enabling companies to take preemptive measures to ensure the normal operation of delivery services. This becomes even more critical during anomaly conditions like the epidemic outbreak, during which couriers' delivery timely rate will decline markedly and fluctuates significantly. Existing studies pay less attention to the logistics scenario. Moreover, many works focusing on prediction tasks in anomaly scenarios fail to explicitly model abnormal events, e.g., treating external factors equally with other features, resulting in great information loss. Further, since some anomalous events occur infrequently, traditional data-driven methods perform poorly in these scenarios. To deal with them, we propose a deep spatial-temporal attention model, named DeepSTA. To be specific, to avoid information loss, we design an anomaly spatio-temporal learning module that employs a recurrent neural network to model incident information. Additionally, we utilize Node2vec to model correlations between road districts, and adopt graph neural networks and long short-term memory to capture the spatial-temporal dependencies of couriers. To tackle the issue of insufficient training data in abnormal circumstances, we propose an anomaly pattern attention module that adopts a memory network for couriers' anomaly feature patterns storage via attention mechanisms. The experiments on real-world logistics datasets during the COVID-19 outbreak in 2022 show the model outperforms the best baselines by 12.11% in MAE and 13.71% in MSE, demonstrating its superior performance over multiple competitive baselines.|提前预测快递员的送货及时率对物流业至关重要，使公司能够采取先发制人的措施，以确保送货服务的正常运作。在疫情爆发等异常情况下，这种情况变得更加严重，在这种情况下，送货员的及时送货率将显著下降并出现大幅波动。现有的研究对物流情景的关注较少。此外，许多侧重于异常场景中的预测任务的工作未能对异常事件进行明确的建模，例如，将外部因素与其他特征等同对待，造成了巨大的信息损失。此外，由于一些异常事件很少发生，传统的数据驱动方法在这些场景中表现不佳。为了解决这些问题，我们提出了一个深度时空注意模型 DeepSTA。具体来说，为了避免信息丢失，我们设计了一个异常时空学习模块，该模块使用一个递归神经网络来模拟事件信息。此外，我们利用 Node2vec 建立道路区域之间的相关性模型，并采用图形神经网络和长期短期记忆来捕捉信使的时空依赖性。针对异常情况下训练数据不足的问题，提出了一种异常模式注意模块，该模块采用记忆网络通过注意机制对信使的异常特征模式进行存储。在2022年2019冠状病毒疾病暴发期间对现实世界物流数据集的实验表明，该模型在 MAE 和 MSE 中的表现优于最佳基线12.11% 和13.71% ，表明其优于多个竞争基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DeepSTA:+A+Spatial-Temporal+Attention+Network+for+Logistics+Delivery+Timely+Rate+Prediction+in+Anomaly+Conditions)|0|
|[Detecting Social Bot on the Fly using Contrastive Learning](https://doi.org/10.1145/3583780.3615468)|Ming Zhou, Dan Zhang, Yuandong Wang, YangliAo Geng, Jie Tang|Tsinghua University, Beijing, China|Social bot detection is becoming a task of wide concern in social security. All along, the development of social bot detection technology is hindered by the lack of high-quality annotated data. Besides, the rapid development of AI Generated Content (AIGC) technology is dramatically improving the creative ability of social bots. For example, the recently released ChatGPT [2] can fool the state-of-the-art AI-text-detection method with a probability of 74%, bringing a large challenge to content-based bot detection methods. To address the above drawbacks, we propose a Contrastive Learning-driven Social Bot Detection framework (CBD). The core of CBD is characterized by a two-stage model learning strategy: a contrastive pre-training stage to mine generalization patterns from massive unlabeled social graphs, followed by a semi-supervised fine-tuning stage to model task-specific knowledge latent in social graphs with a few annotations. The above strategy endows our model with promising detection performance under an extreme scarcity of labeled data. In terms of system architecture, we propose a smart feedback mechanism to further improve detection performance. Comprehensive experiments on a real bot detection dataset show that CBD consistently outperforms 10 state-of-the-art baselines by a large margin for few-shot bot detection using very little (5-shot) labeled data. CBD has been deployed online.|社会机器人检测正成为社会保障领域广泛关注的课题。一直以来，由于缺乏高质量的注释数据，阻碍了社交机器人检测技术的发展。此外，人工智能生成内容(AIGC)技术的快速发展也极大地提高了社交机器人的创造能力。例如，最近发布的 ChatGPT [2]可以以74% 的概率欺骗最先进的 AI 文本检测方法，给基于内容的机器人检测方法带来了巨大的挑战。针对上述缺点，我们提出了一个对比学习驱动的社会机器人检测框架(CBD)。CBD 的核心拥有属性是一个两阶段的模型学习策略: 一个对比性的预训练阶段，从大量未标记的社交图中挖掘概括模式，然后是一个半监督的微调阶段，用一些注释来模拟社交图中潜在的特定任务知识。上述策略使我们的模型在标记数据极度稀缺的情况下具有良好的检测性能。在系统结构方面，我们提出了一种智能反馈机制来进一步提高检测性能。在一个真实的机器人检测数据集上的综合实验表明，CBD 在使用非常少(5次)标记数据进行少镜头机器人检测方面始终优于10个最先进的基线。CBD 已经在线部署。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Detecting+Social+Bot+on+the+Fly+using+Contrastive+Learning)|0|
|[SNAKE Challenge: Sanitization Algorithms under Attack](https://doi.org/10.1145/3583780.3614754)|Tristan Allard, Louis Béziaud, Sébastien Gambs|Univ Rennes, CNRS, IRISA, Rennes, France; Univ Rennes, CNRS, IRISA & Université du Québec à Montréal, Rennes, France; Université du Québec à Montréal, Montréal, PQ, Canada|While there were already some privacy challenges organized in the domain of data sanitization, they have mainly focused on the defense side of the problem. To favor the organization of successful challenges focusing on attacks, we introduce the SNAKE framework that is designed to facilitate the organization of challenges dedicated to attacking existing data sanitization mechanisms. In particular, it enables to easily automate the redundant tasks that are inherent to any such challenge and exhibits the following salient features: genericity with respect to attacks, ease of use and extensibility. We propose to demonstrate the main features of the SNAKE framework through a specific instantiation focusing on membership inference attacks over differentially-private synthetic data generation schemes. This instance of the SNAKE framework is currently being used for supporting a challenge co-located with APVP 2023 (the French workshop on the protection of privacy).|虽然在数据清理领域已经存在一些隐私挑战，但它们主要集中在问题的防御方面。为了有利于组织针对攻击的成功挑战，我们引入了 SNAKE 框架，该框架旨在促进组织针对攻击现有数据消毒机制的挑战。特别是，它能够轻松地自动化任何此类挑战所固有的冗余任务，并显示出以下突出特性: 与攻击相关的通用性、易用性和可扩展性。我们建议通过一个特定的实例来说明 SNAKE 框架的主要特征，该实例着重于针对差分私有合成数据生成方案的成员推理攻击。SNAKE 框架的这个实例目前正在用于支持与 APVP 2023(法国隐私保护研讨会)共处的一个挑战。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SNAKE+Challenge:+Sanitization+Algorithms+under+Attack)|0|
|[AQUAPLANE: The Argument Quality Explainer App](https://doi.org/10.1145/3583780.3614733)|Sebastian Britner, Lorik Dumani, Ralf Schenkel|Trier University, Trier, Germany|In computational argumentation, so-called quality dimensions such as coherence or rhetoric are often used for ranking arguments. However, the literature often only predicts which argument is more persuasive, but not why this is the case. In this paper, we introduce AQUAPLANE, a transparent and easy-to-extend application that not only decides for a pair of arguments which one is more convincing with respect to a statement, but also provides an explanation.|在计算论证中，所谓的质量维度，如连贯性或修辞学，经常被用来对论证进行排序。然而，文献往往只能预测哪种论点更有说服力，而不能预测为什么会出现这种情况。本文介绍了 AQUAPLANE，这是一个透明的、易于扩展的应用程序，它不仅决定了一对论证中哪一个对于一个陈述更有说服力，而且还提供了一个解释。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AQUAPLANE:+The+Argument+Quality+Explainer+App)|0|
|[Contrastive Keyword Extraction from Versioned Documents](https://doi.org/10.1145/3583780.3614735)|Lukas Eder, Ricardo Campos, Adam Jatowt|University of Innsbruck, Innsbruck, Austria; University of Beira Interior & INESC TEC, Covilha, Portugal|Versioned documents are common in many situations and play a vital part in numerous applications enabling an overview of the revisions made to a document or document collection. However, as documents increase in size, it gets difficult to summarize and comprehend all the changes made to versioned documents. In this paper, we propose a novel research problem of contrastive keyword extraction from versioned documents, and introduce an unsupervised approach that extracts keywords to reflect the key changes made to an earlier document version. In order to provide an easy-to-use comparison and summarization tool, an open-source demonstration is made available which can be found at https://contrastive-keyword-extraction.streamlit.app/|版本化的文档在许多情况下都很常见，并且在许多应用程序中发挥着至关重要的作用，从而可以对文档或文档集合的修订进行概述。然而，随着文档规模的增加，很难总结和理解对版本化文档所做的所有更改。本文提出了一个新的对比关键字提取的研究课题，并介绍了一种无监督的方法，提取关键字以反映早期文档版本的关键字变化。为了提供一个易于使用的比较和总结工具，我们提供了一个开源的演示，可以在 https://contrastive-keyword-extraction.streamlit.app/找到|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Keyword+Extraction+from+Versioned+Documents)|0|
|[ParkFlow: Intelligent Dispersal for Mitigating Parking Shortages Using Multi-Granular Spatial-Temporal Analysis](https://doi.org/10.1145/3583780.3614751)|Yang Fan Chiang, ChunWei Shen, JheWei Tsai, PeiXuan Li, TzuChang Lee, HsunPing Hsieh|National Cheng Kung University, Tainan, Taiwan Roc|Parking behaviors near popular destinations often exhibit a preference for proximity, resulting in poor habits, limited parking availability, and a range of consequential issues such as traffic chaos, economic challenges due to congestion, and imbalanced parking utilization. Taiwan has also faced escalating challenges in this regard. To effectively address these issues, the Government of Taiwan has initiated the Smart City program, encompassing various initiatives to enhance urban functionality. One notable solution implemented under this program is the Smart Parking Meter System (SPMS), designed to enhance the overall parking experience. The SPMS incorporates intelligent billing and secure parking data transmission, ensuring a safer and improved parking environment. In this paper, we propose ParkFlow, a comprehensive software-based solution that seamlessly integrates with smart parking hardware, presenting a holistic approach to tackling these challenges. ParkFlow intelligently disperses parking shortages in highly frequented areas and addresses the problem from multiple perspectives, including user, engineering, and government scenarios. By exploring and addressing these scenarios, we aim to provide valuable insights and inspiration to regions worldwide grappling with similar parking-related difficulties. Based on historical data analysis, the implementation of ParkFlow in resolving the parking imbalance problem is anticipated to lead to a significant increase of up to 10% to 20% in available parking hours in popular areas of Tainan, Taiwan. ParkFlow is in the process of being integrated into the Tainan City Government's Parking application, indicating its potential to address real-world parking challenges.|受欢迎的目的地附近的停车行为往往表现出对邻近性的偏好，导致不良的停车习惯，有限的停车可用性，以及一系列相应的问题，如交通混乱，由于拥堵造成的经济挑战，以及停车利用不平衡。台湾在这方面也面临着不断升级的挑战。为了有效地解决这些问题，台湾政府启动了智能城市计划，包括各种提高城市功能的举措。一个值得注意的解决方案是智能停车计时系统(SPMS) ，旨在提高整体停车体验。该系统集成了智能计费和安全的停车数据传输，确保了更安全和更好的停车环境。在本文中，我们提出了 ParkFlow，一个基于软件的综合解决方案，它与智能停车硬件无缝集成，提出了一个解决这些挑战的整体方法。ParkFlow 智能地将停车位短缺分散在高度频繁的地区，并从多个角度解决问题，包括用户、工程和政府场景。通过探索和处理这些情景，我们的目标是为世界各地努力解决类似停车相关困难的地区提供宝贵的见解和启发。根据历史数据分析，在台南市热门地区实施“泊车流量”以解决泊车不平衡问题，预计可令可供泊车的时间大幅增加10% 至20% 。ParkFlow 正在整合到台南市政府的泊车应用程序中，这表明它有潜力应对现实世界的泊车挑战。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ParkFlow:+Intelligent+Dispersal+for+Mitigating+Parking+Shortages+Using+Multi-Granular+Spatial-Temporal+Analysis)|0|
|[The µ-RA System for Recursive Path Queries over Graphs](https://doi.org/10.1145/3583780.3614756)|Amela Fejza, Pierre Genevès, Nabil Layaïda, Sarah Chlyah|Univ. Grenoble Alpes, CNRS, Inria, Grenoble, France|We demonstrate a system for recursive query answering over graphs. The system is based on a complete implementation of the recursive relational algebra µ-RA, extended with parsers and compilers adapted for queries over knowledge and property graphs. Each component of the system comes with novelty for processing recursion. As a result, one can formulate, optimize and efficiently answer expressive queries that navigate recursively along paths in different types of graphs. We demonstrate the system on real datasets and show how it performs considering other state-of-the-art systems.|我们展示了一个图上递归查询回答系统。该系统基于完全实施递归关系代数 μRA，并扩展了解析器和编译器，以适应对知识和属性图表的查询。系统的每个组件都带有处理递归的新颖性。因此，可以制定、优化和有效地回答表达式查询，这些查询在不同类型的图中沿着路径递归导航。我们在实际数据集上演示了该系统，并展示了在考虑其他最先进系统的情况下该系统的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+µ-RA+System+for+Recursive+Path+Queries+over+Graphs)|0|
|[DataDoc Analyzer: A Tool for Analyzing the Documentation of Scientific Datasets](https://doi.org/10.1145/3583780.3614737)|Joan GinerMiguelez, Abel Gómez, Jordi Cabot|Universitat Oberta de Catalunya, Barcelona, Spain; Luxembourg Institute of Science and Technology (LIST), Esch-sur-Alzette, Luxembourg|Recent public regulatory initiatives and relevant voices in the ML community have identified the need to document datasets according to several dimensions to ensure the fairness and trustworthiness of machine learning systems. In this sense, the data-sharing practices in the scientific field have been quickly evolving in the last years, with more and more research works publishing technical documentation together with the data for replicability purposes. However, this documentation is written in natural language, and its structure, content focus, and composition vary, making them challenging to analyze. We present DataDoc Analyzer, a tool for analyzing the documentation of scientific datasets by extracting the details of the main dimensions required to analyze the fairness and potential biases. We believe that our tool could help improve the quality of scientific datasets, aid dataset curators during its documentation process, and be a helpful tool for empirical studies on the overall quality of the datasets used in the ML field. The tool implements an ML pipeline that uses Large Language Models at its core for information retrieval. DataDoc is open-source, and a public demo is published online.|最近的公共监管倡议和机器学习社区中的相关声音已经确定需要根据几个维度来记录数据集，以确保机器学习系统的公平性和可信性。从这个意义上说，科学领域的数据共享做法在过去几年中迅速发展，越来越多的研究工作出版了技术文件和数据，以便复制。然而，这些文档是用自然语言编写的，其结构、内容重点和组成各不相同，使得分析它们具有挑战性。我们介绍了 DataDoc Analyzer，它是一个通过提取分析公平性和潜在偏差所需的主要维度的细节来分析科学数据集文档的工具。我们相信，我们的工具可以帮助提高科学数据集的质量，在其文档编制过程中帮助数据集管理人员，并成为一个有用的工具，对机器学习领域中使用的数据集的整体质量进行实证研究。该工具实现了一个机器学习管道，其核心使用大型语言模型进行信息检索。DataDoc 是开源的，公共演示在线发布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DataDoc+Analyzer:+A+Tool+for+Analyzing+the+Documentation+of+Scientific+Datasets)|0|
|[MORPHER: Structural Transformation of Ill-formed Rows](https://doi.org/10.1145/3583780.3614747)|Mazhar Hameed, Gerardo Vitagliano, Felix Naumann|Hasso Plattner Institute, University of Potsdam, Potsdam, Germany|Open data portals contain a plethora of data files, with comma-separated value (CSV) files being particularly popular with users and businesses due to their flexible standard. However, this flexibility comes with much responsibility for data consumers, as many files contain various structural problems, e.g., a different number of cells across data rows, multiple value formats within the same column, different variants of quoted fields due to user specifications, etc. We refer to rows that contain such structural inconsistencies as ill-formed. Consequently, ingesting them into a host system, such as a database or an analytics platform, often requires prior data preparation steps. We propose to demonstrate MORPHER, a desktop-based system that incorporates our state-of-the-art error detection system, SURAGH and extends it to also clean the files at hand. MORPHER facilitates ingesting CSV files by automatically identifying and cleaning ill-formed rows while preserving all data. It comprises three key components: 1) The pattern modeler, which generates syntax-based patterns for each row of the input file. The system uses these patterns to classify rows into ill-formed and well-formed. 2) The pattern classifier obtains row patterns for ill-formed rows and uses them to distinguish ill-formed but wanted rows from ill-formed unwanted rows. 3) The pattern wrangler transforms the identified wanted rows into well-formed rows, effectively repairing a wide range of formatting problems.|开放数据门户包含大量的数据文件，逗号分隔值(CSV)文件由于其灵活的标准而特别受到用户和企业的欢迎。然而，这种灵活性伴随着对数据消费者的责任，因为许多文件包含各种结构性问题，例如，跨数据行的单元格数量不同，同一列中的多个值格式，由于用户规范而引用字段的不同变体，等等。我们将包含结构不一致的行称为格式不正确的行。因此，将它们摄取到主机系统(如数据库或分析平台)中通常需要事先的数据准备步骤。我们建议演示 MORPHER，这是一个基于桌面的系统，它结合了我们最先进的错误检测系统 SURAGH，并将其扩展到清理手边的文件。MORPHER 通过自动识别和清理格式不正确的行，同时保留所有数据，促进了 CSV 文件的摄取。它包括三个关键组件: 1)模式建模器，它为输入文件的每一行生成基于语法的模式。系统使用这些模式将行分为格式不良和格式良好的两类。2)模式分类器获取格式不正确的行的行模式，并使用它们来区分格式不正确但需要的行和格式不正确的不需要的行。3)模式管理器将识别出的所需行转换为格式良好的行，有效地修复了大量的格式问题。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MORPHER:+Structural+Transformation+of+Ill-formed+Rows)|0|
|[LARCH: Large Language Model-based Automatic Readme Creation with Heuristics](https://doi.org/10.1145/3583780.3614744)|Yuta Koreeda, Terufumi Morishita, Osamu Imaichi, Yasuhiro Sogawa|Hitachi, Ltd., Kokubunji, Japan|Writing a readme is a crucial aspect of software development as it plays a vital role in managing and reusing program code. Though it is a pain point for many developers, automatically creating one remains a challenge even with the recent advancements in large language models (LLMs), because it requires generating abstract description from thousands of lines of code. In this demo paper, we show that LLMs are capable of generating a coherent and factually correct readmes if we can identify a code fragment that is representative of the repository. Building upon this finding, we developed LARCH (LLM-based Automatic Readme Creation with Heuristics) which leverages representative code identification with heuristics and weak supervision. Through human and automated evaluations, we illustrate that LARCH can generate coherent and factually correct readmes in the majority of cases, outperforming a baseline that does not rely on representative code identification. We have made LARCH open-source and provided a cross-platform Visual Studio Code interface and command-line interface, accessible at https://github.com/hitachi-nlp/larch . A demo video showcasing LARCH's capabilities is available at https://youtu.be/ZUKkh5ED-O4 .|编写自述文件是软件开发的一个关键方面，因为它在管理和重用程序代码方面起着至关重要的作用。尽管对于许多开发人员来说这是一个痛点，但是自动创建一个仍然是一个挑战，即使是在大型语言模型(LLM)最近的进步中，因为它需要从成千上万行代码中生成抽象描述。在这篇演示文章中，我们展示了 LLM 能够生成一个连贯的、事实上正确的自述文件，如果我们能够识别代表存储库的代码片段。在这个发现的基础上，我们开发了 LARCH (基于 LLM 的启发式自动自述创建) ，它利用启发式和弱监督的代表性代码标识。通过人工和自动评估，我们说明 LARCH 可以在大多数情况下产生连贯和事实上正确的自述，优于不依赖于代表性代码识别的基线。我们使 LARCH 开源，并提供了一个跨平台的 Visual Studio 代码界面和命令行界面，可以在 https://github.com/hitachi-nlp/LARCH 访问。展示 LARCH 能力的演示视频可在 https://youtu.be/zukkh5ed-o4下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LARCH:+Large+Language+Model-based+Automatic+Readme+Creation+with+Heuristics)|0|
|[CRUISE-Screening: Living Literature Reviews Toolbox](https://doi.org/10.1145/3583780.3614736)|Wojciech Kusa, Petr Knoth, Allan Hanbury|TU Wien, Vienna, Austria; The Open University, Milton Keynes, United Kingdom|Keeping up with research and finding related work is still a time-consuming task for academics. Researchers sift through thousands of studies to identify a few relevant ones. Automation techniques can help by increasing the efficiency and effectiveness of this task. To this end, we developed CRUISE-Screening, a web-based application for conducting living literature reviews - a type of literature review that is continuously updated to reflect the latest research in a particular field. CRUISE-Screening is connected to several search engines via an API, which allows for updating the search results periodically. Moreover, it can facilitate the process of screening for relevant publications by using text classification and question answering models. CRUISE-Screening can be used both by researchers conducting literature reviews and by those working on automating the citation screening process to validate their algorithms. The application is open-source: https://github.com/ProjectDoSSIER/cruise-screening, and a demo is available under this URL: https://citation-screening.ec.tuwien.ac.at. We discuss the limitations of our tool in Appendix A.|对于学术界来说，跟上研究进度和寻找相关工作仍然是一项耗时的任务。研究人员筛选了数以千计的研究，以确定一些相关的。自动化技术可以通过提高此任务的效率和有效性来提供帮助。为此，我们开发了“ CRUISE 筛选”，一种用于进行活体文献评论的网络应用程序——一种不断更新以反映特定领域最新研究的文献评论类型。CRUISE-筛选通过一个 API 连接到几个搜索引擎，它允许定期更新搜索结果。此外，利用文本分类和问答模型，可以方便相关出版物的筛选过程。CRUISE-筛选既可以用于进行文献综述的研究人员，也可以用于那些致力于引文筛选过程自动化以验证其算法的研究人员。这个应用程序是开源的:  https://github.com/projectdossier/cruise-screening 的，并且可以在这个网址下面找到一个演示 https://citation-screening.ec.tuwien.ac.at。我们在附录 A 中讨论了我们的工具的局限性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CRUISE-Screening:+Living+Literature+Reviews+Toolbox)|0|
|[HugNLP: A Unified and Comprehensive Library for Natural Language Processing](https://doi.org/10.1145/3583780.3614742)|Jianing Wang, Nuo Chen, Qiushi Sun, Wenkang Huang, Chengyu Wang, Ming Gao|East China Normal University, Shanghai, China; Alibaba Group, Hangzhou, China; Ant Group, Hangzhou, China; National University of Singapore, Singapore, Singapore|In this paper, we introduce HugNLP, a unified and comprehensive library for natural language processing (NLP) with the prevalent backend of HuggingFace Transformers, which is designed for NLP researchers to easily utilize off-the-shelf algorithms and develop novel methods with user-defined models and tasks in real-world scenarios. HugNLP consists of a hierarchical structure including models, processors and applications that unifies the learning process of pre-trained language models (PLMs) on different NLP tasks. Additionally, we present some featured NLP applications to show the effectiveness of HugNLP, such as knowledge-enhanced PLMs, universal information extraction, low-resource mining, and code understanding and generation, etc. The source code will be released on GitHub (https://github.com/wjn1996/HugNLP).|本文介绍了 HugNLP，这是一个自然语言处理(NLP)的统一和综合库，它的后端是 HuggingFace Transformers，它是为自然语言处理的研究人员设计的，可以方便地利用现成的算法，并开发新的方法与用户定义的模型和任务在真实世界的场景。HugNLP 由模型、处理器和应用程序组成的层次结构，统一了针对不同 NLP 任务的预训练语言模型(PLM)的学习过程。此外，我们还介绍了一些特色的自然语言处理应用程序，以展示 HugNLP 的有效性，例如知识增强 PLM、通用信息抽取、低资源挖掘、代码理解和生成等。源代码将在 GitHub ( https://GitHub.com/wjn1996/hugnlp )上发布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HugNLP:+A+Unified+and+Comprehensive+Library+for+Natural+Language+Processing)|0|
|[PyABSA: A Modularized Framework for Reproducible Aspect-based Sentiment Analysis](https://doi.org/10.1145/3583780.3614752)|Heng Yang, Chen Zhang, Ke Li||The advancement of aspect-based sentiment analysis (ABSA) has urged the lack of a user-friendly framework that can largely lower the difficulty of reproducing state-of-the-art ABSA performance, especially for beginners. To meet the demand, we present \our, a modularized framework built on PyTorch for reproducible ABSA. To facilitate ABSA research, PyABSA supports several ABSA subtasks, including aspect term extraction, aspect sentiment classification, and end-to-end aspect-based sentiment analysis. Concretely, PyABSA integrates 29 models and 26 datasets. With just a few lines of code, the result of a model on a specific dataset can be reproduced. With a modularized design, PyABSA can also be flexiblely extended to considered models, datasets, and other related tasks. Besides, PyABSA highlights its data augmentation and annotation features, which significantly address data scarity. All are welcome to have a try at \url{https://github.com/yangheng95/PyABSA}.|基于方面的情绪分析(ABSA)的进步促使缺乏一个用户友好的框架，可以在很大程度上降低复制最先进的 ABSA 性能的难度，特别是对于初学者。为了满足这一需求，我们提出了一个基于 PyTorch 的模块化框架，用于可重现的 ABSA。为了便于 ABSA 研究，PyABSA 支持几个 ABSA 子任务，包括方面词提取、方面情绪分类和端到端基于方面的情绪分析。具体来说，PyABSA 集成了29个模型和26个数据集。只需几行代码，就可以复制特定数据集上模型的结果。通过模块化设计，PyABSA 还可以灵活地扩展到所考虑的模型、数据集和其他相关任务。此外，PyABSA 强调了其数据增强和注释特性，这些特性显著地解决了数据稀缺问题。欢迎大家到 url { https://github.com/yangheng95/pyabsa }试一试。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PyABSA:+A+Modularized+Framework+for+Reproducible+Aspect-based+Sentiment+Analysis)|0|
|[NP-SSL: A Modular and Extensible Self-supervised Learning Library with Neural Processes](https://doi.org/10.1145/3583780.3614749)|Zesheng Ye, Jing Du, Yao Liu, Yihong Zhang, Lina Yao|CSIRO's Data61 & UNSW, Sydney, NSW, Australia; The University of New South Wales, Sydney, NSW, Australia; Osaka University, Osaka, Japan|Neural Processes (NPs) are a family of supervised density estimators devoted to probabilistic function approximation with meta-learning. Despite extensive research on the subject, the absence of a unified framework for NPs leads to varied architectural solutions across diverse studies. This non-consensus poses challenges to reproducing and benchmarking different NPs. Moreover, existing codebases mainly prioritize generative density estimation, yet rarely consider expanding the capability of NPs to self-supervised representation learning, which however has gained growing importance in data mining applications. To this end, we present NP-SSL, a modular and configurable framework with built-in support, requiring minimal effort to 1) implement classical NPs architectures; 2) customize specific components; 3) integrate hybrid training scheme (e.g., contrastive); and 4) extend NPs to act as a self-supervised learning toolkit, producing latent representations of data, and facilitating diverse downstream predictive tasks. To illustrate, we discuss a case study that applies NP-SSL to model time-series data. We interpret that NP-SSL can handle different predictive tasks such as imputation and forecasting, by a simple switch in data samplings, without significant change to the underlying structure. We hope this study can reduce the workload of future research on leveraging NPs to tackle more a broader range of real-world data mining applications. Code and documentation are at https://github.com/zyecs/NP-SSL.|神经过程(NPs)是一个有监督的密度估计家族，致力于元学习的概率函数逼近。尽管对这一课题进行了广泛的研究，但由于缺乏一个统一的 NPs 框架，导致了不同研究领域的建筑解决方案各不相同。这种不一致性对复制和基准测试不同的 NPs 提出了挑战。此外，现有的代码库主要优先考虑生成密度估计，但很少考虑扩展能力的 NP 的自我监督表示学习，但在数据挖掘应用越来越重要。为此，我们提出了 NP-SSL，一个内置支持的模块化和可配置框架，只需要最小的努力: 1)实现经典的 NP 架构; 2)定制特定的组件; 3)集成混合训练方案(例如，对比) ; 4)扩展 NP 作为自我监督的学习工具包，产生数据的潜在表示，并促进多样化的下游预测任务。为了说明，我们讨论了一个案例研究，应用 NP-SSL 模型的时间序列数据。我们解释说，NP-SSL 可以处理不同的预测任务，如插补和预测，通过一个简单的切换数据采样，没有显着的变化，基础结构。我们希望这项研究能够减少未来利用 NPs 处理更广泛的现实世界数据挖掘应用的研究工作量。代码和文档都在 https://github.com/zyecs/np-ssl。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NP-SSL:+A+Modular+and+Extensible+Self-supervised+Learning+Library+with+Neural+Processes)|0|
|[MOSS: AI Platform for Discovery of Corrosion-Resistant Materials](https://doi.org/10.1145/3583780.3614748)|Biao Yin, Nicholas Josselyn, Ziming Zhang, Elke A. Rundensteiner, Thomas A. Considine, John V. Kelley, Berend C. Rinderspacher, Robert E. Jensen, James F. Snyder|Worcester Polytechnic Institute, Worcester, MA, USA; DEVCOM Army Research Laboratory, Aberdeen Proving Ground, MD, USA|Amid corrosion degradation of metallic structures causing expenses nearing 3 trillion or 4% of the GDP annually along with major safety risks, the adoption of AI technologies for accelerating the materials science life-cycle for developing materials with better corrosive properties is paramount. While initial machine learning models for corrosion assessment are being proposed in the literature, their incorporation into end-to-end tools for field experimentation by corrosion scientists remains largely unexplored. To fill this void, our university data science team in collaboration with the materials science unit at the Army Research Lab have jointly developed MOSS, an innovative AI-based digital platform to support material science corrosion research. MOSS features user-friendly iPadOS app for in-field corrosion progression data collection, deep-learning corrosion assessor, robust data repository system for long-term experimental data modeling, and visual analytics web portal for material science research. In this demonstration, we showcase the key innovations of the MOSS platform via use cases supporting the corrosion exploration processes, with the promise of accelerating the discovery of new materials. We open a MOSS video demo at: https://www.youtube.com/watch?v=CzcxMMRsxkE|由于金属结构的腐蚀退化导致每年的支出接近国内生产总值的3万亿或4% ，并伴随着重大的安全风险，因此采用人工智能技术加快材料科学的生命周期以开发具有更好腐蚀性能的材料是至关重要的。虽然文献中提出了腐蚀评估的初始机器学习模型，但是将其纳入腐蚀科学家现场试验的端到端工具中仍然大部分未被探索。为了填补这一空白，我们的大学数据科学团队与美国陆军研究实验室的材料科学部门合作，共同开发了 MOSS，一个创新的基于人工智能的数字平台，以支持材料科学腐蚀研究。MOSS 具有用于现场腐蚀进程数据收集的用户友好的 iPadOS 应用程序，深度学习腐蚀评估器，用于长期实验数据建模的健壮的数据存储系统，以及用于材料科学研究的可视化分析门户网站。在这个演示中，我们通过支持腐蚀探测过程的用例展示了 MOSS 平台的关键创新，并承诺加速新材料的发现。我们在 https://www.youtube.com/watch?v=czcxmmrsxke 打开一个 MOSS 视频演示|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MOSS:+AI+Platform+for+Discovery+of+Corrosion-Resistant+Materials)|0|
|[Demonstration of ViTA: Visualizing, Testing and Analyzing Index Advisors](https://doi.org/10.1145/3583780.3614738)|Wei Zhou, Chen Lin, Xuanhe Zhou, Guoliang Li, Tianqing Wang|Xiamen University, Xiamen, China; Tsinghua University, Beijing, China; Huawei, Beijing, China|Index advisors have become an essential tool to optimize index selection and accelerate query processing. Various index advisors have been developed in recent years, and comprehensively assessing their performance from multiple aspects is necessary. In this demonstration, we introduce VITA, a user-friendly and informative tool for interactively Visualizing, Testing, and Analyzing index advisors. For a user-given workload, VITA can visualize the main steps of the index selection procedure in ten existing index advisors to facilitate the management of index advisors. Moreover, VITA can assess the index advisor's robustness w.r.t. workload drift by generating testing workloads, i.e., potentially future workloads that may damage the index advisor's performance. Finally, VITA provides a comparative analysis across index advisors on four aspects, including the index advisor's utility (i.e., the ratio of the reduced workload cost), robustness (i.e., the performance under dynamic workload), overhead (i.e., the time to acquire the final configuration), and scalability (i.e., the volume of the enumerated index candidates). Therefore, VITA can thoroughly compare existing index advisors to help users determine the most suitable index advisor that meets their requirements. VITA is now being integrated into the openGauss platform as a plug-in.|索引顾问已经成为优化索引选择和加速查询处理的重要工具。指数顾问是近年来发展起来的各种指数顾问，需要从多方面对其业绩进行综合评价。在本演示中，我们将介绍 VITA，这是一个用户友好的、信息丰富的工具，用于交互式地对索引顾问进行可视化、测试和分析。对于用户给定的工作量，VITA 可以在现有的10个索引顾问中直观地显示索引选择程序的主要步骤，以方便索引顾问的管理。此外，VITA 还可以通过生成测试工作负载来评估索引顾问的健壮性。最后，VITA 从四个方面对索引顾问进行了比较分析，包括索引顾问的效用(即降低工作负载成本的比率)、健壮性(即动态工作负载下的性能)、开销(即获得最终配置的时间)和可伸缩性(即枚举索引候选者的数量)。因此，VITA 可以彻底比较现有的索引顾问，以帮助用户确定最合适的索引顾问，以满足他们的要求。VITA 现在正作为一个插件集成到 openGauss 平台中。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Demonstration+of+ViTA:+Visualizing,+Testing+and+Analyzing+Index+Advisors)|0|
|[An AI-based Simulation and Optimization Framework for Logistic Systems](https://doi.org/10.1145/3583780.3614732)|Zefang Zong, Huan Yan, Hongjie Sui, Haoxiang Li, Peiqi Jiang, Yong Li|Tsinghua University, Beijing, China|Improving logistics efficiency is a challenging task in logistic systems, since planning the vehicle routes highly relies on the changing traffic conditions and diverse demand scenarios. However, most existing approaches either neglect the dynamic traffic environment or adopt manually designed rules, which fails to efficiently find a high-quality routing strategy. In this paper, we present a novel artificial intelligence (AI) based framework for logistic systems. This framework can simulate the spatio-temporal traffic conditions to form a dynamic environment in a data-driven manner. Under such a simulated environment, it adopts deep reinforcement learning techniques to intelligently generate the optimized routing strategy. Meanwhile, we also design an interactive frontend to visualize the simulated environment and routing strategies, which help operators evaluate the task performance. We will showcase the results of AI-based simulation and optimization in our demonstration.|在物流系统中，提高物流效率是一项具有挑战性的任务，因为车辆路线的规划高度依赖于不断变化的交通条件和不同的需求情景。然而，现有的路由策略大多忽视了动态流量环境，或者采用了人工设计的规则，无法有效地找到高质量的路由策略。本文提出了一种新的基于人工智能的物流系统框架。该框架能够模拟时空交通状况，以数据驱动的方式形成动态环境。在这样的模拟环境下，它采用深度强化学习技术智能地生成优化的路由策略。同时，我们还设计了一个交互式前端，可视化模拟环境和路由策略，帮助操作员评估任务性能。我们将在演示中展示基于人工智能的仿真和优化的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+AI-based+Simulation+and+Optimization+Framework+for+Logistic+Systems)|0|
|[Data and Decision Fusion with Uncertainty Quantification for ML-based Healthcare Decision Systems](https://doi.org/10.1145/3583780.3616004)|Grigor Bezirganyan|Aix-Marseille University, CNRS, LIS, Marseille, France|This paper outlines the PhD research plan to develop a comprehensive, uncertainty-aware, multimodal deep learning approach to be used in the healthcare domain. The goal is to design a multimodal deep learning framework that can leverage the complex interconnections between various modalities in order to generate highly precise predictions for intricate healthcare datasets. In addition, the framework should also incorporate methods for quantifying and dealing with uncertainty, which is an important consideration in many real-world healthcare applications. The approach will be tested on real-world multimodal datasets from Marseilles hospitals in France. We further represent some preliminary results of our early stage experiments with uncertainty quantification on multimodal datasets.|本文概述了博士研究计划，开发一个全面的，不确定性意识，多模式深入学习方法，在医疗领域使用。目标是设计一个多模式深度学习框架，可以利用各种模式之间复杂的相互联系，以便为复杂的医疗保健数据集生成高度精确的预测。此外，该框架还应该包含量化和处理不确定性的方法，这是许多现实世界医疗保健应用程序中的一个重要考虑因素。该方法将在法国马赛医院的现实世界多式联运数据集上进行测试。我们进一步展示了我们的早期实验的一些初步结果与不确定性量化的多模态数据集。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Data+and+Decision+Fusion+with+Uncertainty+Quantification+for+ML-based+Healthcare+Decision+Systems)|0|
|[A Neuro-symbolic Approach to Enhance Interpretability of Graph Neural Network through the Integration of External Knowledge](https://doi.org/10.1145/3583780.3616008)|Kislay Raj|Dublin City University, Dublin, Ireland|Graph Neural Networks (GNNs) have shown remarkable performance in tackling complex tasks. However, interpreting the decision-making process of GNNs remains a challenge. To address the challenge, we explore representing the behaviour of a GNN in a representation space that is more transparent such as a knowledge graph, in a way that captures the behaviour of a GNN as a graph. Our initial experiments on the node classification task can represent the trained graph convolutional neural network (GCN) behaviour with some semantics uncovered by state-of-the-art approaches. This research offers a promising direction for enhancing GNN interpretability and understanding by providing structured, human-understandable representations and incorporating external knowledge for more accurate predictions.|图形神经网络(GNN)在处理复杂任务方面表现出显著的性能。然而，解释 GNN 的决策过程仍然是一个挑战。为了应对这一挑战，我们探索在一个更加透明的表示空间(如知识图)中表示 GNN 的行为，以一种将 GNN 的行为捕获为图的方式。我们在节点分类任务上的初步实验可以用最先进的方法发现的一些语义来表示经过训练的图形卷积神经网络(GCN)行为。本研究通过提供结构化的、人类可理解的表示，并结合外部知识进行更精确的预测，为提高 GNN 的可解释性和理解性提供了一个有希望的方向。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Neuro-symbolic+Approach+to+Enhance+Interpretability+of+Graph+Neural+Network+through+the+Integration+of+External+Knowledge)|0|
|[Enhancing Badminton Player Performance via a Closed-Loop AI Approach: Imitation, Simulation, Optimization, and Execution](https://doi.org/10.1145/3583780.3616001)|KuangDa Wang|National Yang Ming Chiao Tung University, Hsinchu, Taiwan Roc|In recent years, the sports industry has witnessed a significant rise in interest in leveraging artificial intelligence to enhance players' performance. However, the application of deep learning to improve badminton athletes' performance faces challenges related to identifying weaknesses, generating winning suggestions, and validating strategy effectiveness. These challenges arise due to the limited availability of realistic environments and agents. This paper aims to address these research gaps and make contributions to the badminton community. To achieve this goal, we propose a closed-loop approach consisting of six key components: Badminton Data Acquisition, Imitating Players' Styles, Simulating Matches, Optimizing Strategies, Training Execution, and Real-World Competitions. Specifically, we developed a novel model called RallyNet, which excels at imitating players' styles, allowing agents to accurately replicate real players' behavior. Secondly, we created a sophisticated badminton simulation environment that incorporates real-world physics, faithfully recreating game situations. Thirdly, we employed reinforcement learning techniques to improve players' strategies, enhancing their chances of winning while preserving their unique playing styles. By comparing strategy differences before and after improvement, we provide winning suggestions to players, which can be validated against diverse opponents within our carefully designed environment. Lastly, through collaborations with badminton venues and players, we apply the generated suggestions to the players' training and competitions, ensuring the effectiveness of our approach. Moreover, we continuously gather data from training and competitions, incorporating it into the closed-loop cycle to refine strategies and suggestions. This research presents an innovative approach for continuously improving players' performance, contributing to the field of AI-driven sports performance enhancement. This dissertation is supervised by Wen-Chih Peng (wcp [email protected] ) and Ping-Chun Hsieh ( [email protected] ).|近年来，体育产业对利用人工智能提高运动员表现的兴趣显著上升。然而，应用深度学习来提高羽毛球运动员的成绩面临着识别弱点、产生获胜建议和验证策略有效性等方面的挑战。由于现实环境和代理的可用性有限，出现了这些挑战。本文旨在填补这些研究空白，为羽毛球界做出贡献。为了实现这一目标，我们提出了一个由六个关键部分组成的闭环方法: 羽毛球数据采集、模仿运动员的风格、模拟比赛、优化策略、训练执行和真实世界的比赛。具体来说，我们开发了一个名为 RallyNet 的新模型，它擅长模仿玩家的风格，允许代理精确地复制真实玩家的行为。其次，我们创建了一个复杂的羽毛球模拟环境，结合了真实世界的物理学，忠实地再现了比赛场景。第三，我们采用强化学习技术来改善球员的战术，提高他们赢球的机会，同时保留他们独特的踢球风格。通过比较改进前后的策略差异，我们为玩家提供获胜的建议，这些建议可以在我们精心设计的环境中针对不同的对手进行验证。最后，通过与羽毛球场地和运动员的合作，我们将生成的建议应用到运动员的训练和比赛中，确保我们的方法的有效性。此外，我们不断从训练和比赛中收集数据，将其纳入闭环周期，以完善战略和建议。本研究提出了一种不断提升运动员成绩的创新方法，有助于人工智能驱动的运动成绩提升领域。本论文由彭(wcp [ email protected ])和谢平春(Ping-Chun Hsieh ([ email protected ])指导。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Badminton+Player+Performance+via+a+Closed-Loop+AI+Approach:+Imitation,+Simulation,+Optimization,+and+Execution)|0|
|[Exploiting Homeostatic Synaptic Modulation in Spiking Neural Networks for Semi-Supervised Graph Learning](https://doi.org/10.1145/3583780.3616000)|Mingkun Xu|Guangdong Institute of Intelligence Science and Technology & Tsinghua University, Zhuhai & Beijing, China|Semi-supervised graph learning (SSL) is an important task in machine learning that aims to make predictions based on a limited amount of labeled data and a larger set of unlabeled structured data, which can be effectively processed by biological neural networks. In this paper, we investigate the effects of the underlying homeostatic synaptic modulation (HSM) in spiking neural networks (SNNs) on such scenario. We propose a novel framework that integrates HSM into the spiking graph convolutional network to maintain stability by regulating the strength of synapses based on the activity of neurons, allowing for stable graph learning in a semi-supervised setting. Experimental results on citation benchmark datasets demonstrate that the proposed HSM mechanism can enable SNNs with superior capabilities of convergence and generalization, meanwhile possessing expected characteristics of sparsity and call-back phenomenon. The proposed framework provides a promising approach for exploiting HSM in neural network architectures for efficient graph learning.|半监督图学习(SSL)是机器学习中的一项重要任务，其目标是基于有限的标记数据和大量的未标记结构化数据进行预测，这些数据能够被生物神经网络有效地处理。本文研究了刺激神经网络中潜在的稳态突触调制(HSM)对这种情况的影响。我们提出了一个新的框架，将 HSM 集成到峰值图卷积网络，通过调节突触的强度来维持稳定性，基于神经元的活动，允许在半监督环境下稳定的图学习。对引文基准数据集的实验结果表明，所提出的 HSM 机制能够使 SNN 具有较强的收敛和泛化能力，同时具有稀疏和回调现象的预期特征。该框架为利用神经网络结构中的 HSM 进行有效的图形学习提供了一种有前途的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploiting+Homeostatic+Synaptic+Modulation+in+Spiking+Neural+Networks+for+Semi-Supervised+Graph+Learning)|0|
|[Some Useful Things to Know When Combining IR and NLP: the Easy, the Hard and the Ugly](https://doi.org/10.1145/3583780.3615295)|Omar Alonso, Kenneth Church|Amazon, Santa Clara, CA, USA; Northeastern University, San Jose, CA, USA|Deep nets such as GPT are at the core of the current advances in many systems and applications. Things are moving very fast, and it appears that techniques are out of date within weeks. How can we take advantage of new discoveries and incorporate them into our existing work? Are these radical new developments, repetitions of older concepts, or both? In this tutorial, we aim to bring interested researchers and practitioners up to speed on the recent and ongoing techniques around ML and Deep learning in the context of IR and NLP. Additionally, our goal is to clarify terminology, emphasize fundamentals, and outline new research opportunities.|像 GPT 这样的深网是当前许多系统和应用进展的核心。事情发展得非常快，而且技术似乎在几周内就过时了。我们如何利用新的发现，并将其纳入我们现有的工作？这些是激进的新发展，旧观念的重复，还是两者兼而有之？在本教程中，我们的目的是让感兴趣的研究人员和从业人员加快最近和正在进行的技术在机器学习和深度学习的背景下的 IR 和 NLP。此外，我们的目标是澄清术语，强调基本原理，并概述新的研究机会。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Some+Useful+Things+to+Know+When+Combining+IR+and+NLP:+the+Easy,+the+Hard+and+the+Ugly)|0|
|[Application of Deep Clustering Algorithms](https://doi.org/10.1145/3583780.3615290)|Collin Leiber, Lukas Miklautz, Claudia Plant, Christian Böhm|LMU Munich, Munich, Germany; University of Vienna, Vienna, Austria|Deep clustering algorithms have gained popularity for clustering complex, large-scale data sets, but getting started is difficult because of numerous decisions regarding architecture, optimizer, and other hyperparameters. Theoretical foundations must be known to obtain meaningful results. At the same time, ease of use is necessary to get used by a broader audience. Therefore, we require a unified framework that allows for easy execution in diverse settings. While this applies to established clustering methods like k-Means and DBSCAN, deep clustering algorithms lack a standard structure, resulting in significant programming overhead. This complicates empirical evaluations, which are essential in both scientific and practical applications. We present a solution to this problem by providing a theoretical background on deep clustering as well as practical implementation techniques and a unified structure with predefined neural networks. For the latter, we use the Python package ClustPy. The aim is to share best practices and facilitate community participation in deep clustering research.|深度聚类算法已经在对复杂的、大规模的数据集进行聚类方面获得了普及，但是由于在体系结构、优化器和其他超参数方面的许多决策，开始这项工作变得很困难。要想得到有意义的结果，必须了解理论基础。同时，易于使用对于更广泛的受众来说是必要的。因此，我们需要一个统一的框架，以便在不同的设置中轻松执行。虽然这适用于已建立的聚类方法，如 k-Means 和 DBSCAN，但是深度聚类算法缺乏标准结构，导致大量的编程开销。这使得经验性评估复杂化，而这些评估在科学和实际应用中都是必不可少的。我们提出了一个解决这个问题的方案，提供了深度聚类的理论背景和实际的实现技术，并提出了一个统一的结构与预定义的神经网络。对于后者，我们使用 Python 包 ClustPy。其目的是分享最佳做法，促进社区参与深度集群研究。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Application+of+Deep+Clustering+Algorithms)|0|
|[RT2S: A Framework for Learning with Noisy Labels](https://doi.org/10.1145/3583780.3615996)|Indranil Bhattacharya, Ze Ye, Kaushik Pavani, Sunny Dasgupta|Amazon.com, Inc., Seattle, WA, USA|We introduce Robust Training with Trust Scores (RT2S), a framework to train machine learning classifiers with potentially noisy labels. RT2S calculates a trust score for each training sample, which indicates the quality of its corresponding label. These trust scores are employed as sample weights during training and optionally during threshold optimization. The trust scores are generated from two sources: (i) the model's confidence in the observed label, leveraging out-of-fold prediction scores to detect anomalous labels in the training data, and (ii) the probability of the correct label, ascertained by a Large Language Model with the ability to identify biased label noise. We evaluate RT2S by training machine learning models on 6 product classification datasets that utilize low-quality labels generated by a rule-based classification engine acting as a surrogate labeler. Our experimental findings indicate that RT2S outperforms all baselines, and achieves an average accuracy improvement of 4.38% (max 7.18%) over rule-based classifiers in particular.|我们引入了带信任分数的鲁棒训练(RT2S) ，这是一个用潜在噪声标签训练机器学习分类器的框架。RT2S 为每个训练样本计算一个信任评分，表明其相应标签的质量。这些信任得分被用作训练期间和阈值优化期间的样本权重。信任分数来自两个来源: (i)模型对观察标签的信心，利用外部预测分数来检测训练数据中的异常标签，以及(ii)由具有识别偏倚标签噪声能力的大语言模型确定的正确标签的概率。通过对6个产品分类数据集的机器学习模型进行训练，利用基于规则的分类引擎作为替代标签生成的低质量标签，对 RT2S 进行评估。实验结果表明，RT2S 分类器的性能优于所有基线分类器，特别是与基于规则的分类器相比，RT2S 分类器的平均准确率提高了4.38% (最大7.18%)。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RT2S:+A+Framework+for+Learning+with+Noisy+Labels)|0|
|[Type Theory as a Unifying Paradigm for Modern Databases](https://doi.org/10.1145/3583780.3615999)|Christoph Dorn, Haikal Pribadi|Vaticle, London, United Kingdom|Over the past decades, data modeling has become a highly diversified discipline with many competing paradigms emerging across various application domains. We argue that higher levels of abstraction including, in particular, the integration of high-level programming and reasoning techniques, will pave the way forward for future knowledge management systems. As a programmatic foundation for this endeavor, we will discuss a novel type theoretical modeling and reasoning paradigm, which aims to strike a powerful balance between what can be naturally semantically modeled and what can be practically implemented. TypeQL is a multi-purpose database language rooted in these foundations: it is designed around the expressivity of natural language and backed by type theoretical principles. This rigorous high-level approach to database language reduces development and maintenance loads, preventing hard to spot data integrity and logic errors through its underlying type system, while also providing a unifying toolset for a large class of domain-specific applications ranging from querying connected data in knowledge graphs for drug discovery to reasoning and adaptive decision making in cognitive robotics.|在过去的几十年中，数据建模已经成为一个高度多样化的学科，在不同的应用领域中出现了许多相互竞争的范例。我们认为，更高层次的抽象，尤其是高层次编程和推理技术的集成，将为未来的知识管理系统铺平道路。作为这一努力的纲领性基础，我们将讨论一种新型的理论建模和推理范式，其目的是在可以自然语义建模和可以实际实现之间达成有力的平衡。TypeQL 是一种基于这些基础的多用途数据库语言: 它是围绕自然语言的表达性设计的，并以类型理论原则为支撑。这种严格的高级数据库语言方法减少了开发和维护的负荷，通过其底层类型系统防止难以发现数据完整性和逻辑错误，同时也为一大类特定领域的应用程序提供了统一的工具集，从查询知识图中的连接数据用于药物发现，到认知机器人中的推理和自适应决策。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Type+Theory+as+a+Unifying+Paradigm+for+Modern+Databases)|0|
|[Comparing Fine-Tuned Transformers and Large Language Models for Sales Call Classification: A Case Study](https://doi.org/10.1145/3583780.3615509)|Roy Eisenstadt, Abedelkader Asi, Royi Ronen|Microsoft Dynamics 365 Sales, Sammamish, WA, USA; Microsoft Dynamics 365 Sales, Tel Aviv, Israel|We present a research project carried out to enable a Call Categorization Service (CCS) for Dynamics 365 Sales Conversation Intelligence. CCS identifies prevalent types of sales calls based on their transcription, for the purpose of automating manual sales processes and making informed business decisions. We sift through R&D process, and provide clear evidence that purpose-focused fine-tuned transformers out-perform GPT-3 in this text classification task. Additionally we share: an efficient, non-trivial data annotation approach suited to the problem of finding data related to rare categories in a highly unbalanced data source; Considerations regarding zero-shot and in-context learning (i.e. few-shot learning) when using LLMs for classification and cost and performance analysis that opt in favor of fine-tuned transformers as well.|我们提出了一个研究项目，以启用呼叫分类服务(CCS)的动态365销售会话智能。CCS 根据销售电话的转录来识别流行的销售电话类型，目的是实现手工销售流程的自动化，并做出明智的商业决策。我们通过研发过程中筛选，并提供明确的证据表明，目的为重点的微调变压器性能优于 GPT-3在这个文本分类任务。此外，我们共享: 一个有效的，非平凡的数据注释方法，适合于在一个高度不平衡的数据源中找到与罕见类别相关的数据的问题; 关于零拍摄和上下文学习(即少拍摄学习)的考虑，当使用 LLM 进行分类，成本和性能分析，选择有利于微调变压器以及。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Comparing+Fine-Tuned+Transformers+and+Large+Language+Models+for+Sales+Call+Classification:+A+Case+Study)|0|
|[Application and Evaluation of Large Language Models for the Generation of Survey Questions](https://doi.org/10.1145/3583780.3615506)|Antonio Maiorino, Zoe Padgett, Chun Wang, Misha Yakubovskiy, Peng Jiang|SurveyMonkey, San Mateo, USA|Generative Language Models have shown promising results in various domains, and some of the most successful applications are related to "concept expansion", which is the task of generating extensive text based on concise instructions provided through a "seed" prompt. In this presentation we will discuss the recent work conducted by the Data Science team at SurveyMonkey, where we have recently introduced a new feature that harnesses Generative AI models to streamline the survey design process. With this feature users can effortlessly initiate this process by specifying their desired objectives through a prompt, allowing them to automate the creation of surveys that include the critical aspects they wish to investigate. We will share our findings regarding some of the challenges encountered during the development of this feature. These include techniques for conditioning the model outputs, integrating generated text with industry-standard questions, fine-tuning Language Models using semi-synthetic Data Generation techniques, and more. Moreover, we will showcase the Evaluation Methodology that we have developed to measure the quality of the generated surveys across several dimensions. This evaluation process is crucial in ensuring that the generated surveys align well with user expectations and serve their intended purpose effectively. Our goal is to demonstrate the promising potential of Generative Language Models in the context of Survey Research, and we believe that sharing our learnings on these challenges and how we addressed them will be useful for practitioners working with Language Models on similar problems.|生成语言模型已经在各个领域显示了有希望的结果，并且一些最成功的应用与“概念扩展”有关，这是一个基于通过“种子”提示提供的简洁指令生成大量文本的任务。在本次演讲中，我们将讨论 SurveyMonkey 数据科学团队最近的工作，我们最近引入了一个新特性，利用生成人工智能模型来简化调查设计过程。有了这个功能，用户可以通过迅速指定他们想要的目标，轻松地启动这个过程，允许他们自动创建包括他们想要调查的关键方面的调查。我们将分享我们关于在开发这一功能过程中遇到的一些挑战的调查结果。这些技术包括调节模型输出、将生成的文本与行业标准问题集成、使用半合成数据生成技术微调语言模型等。此外，我们将展示我们开发的评价方法，以衡量所生成的调查在几个方面的质量。这一评价过程对于确保生成的调查符合用户的期望并有效地达到预期目的至关重要。我们的目标是在调查研究的背景下展示生成语言模型的潜力，我们相信分享我们在这些挑战上的经验以及我们如何解决这些挑战将对从事语言模型工作的人员在类似问题上有所帮助。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Application+and+Evaluation+of+Large+Language+Models+for+the+Generation+of+Survey+Questions)|0|
|[Harnessing GPT for Topic-Based Call Segmentation in Microsoft Dynamics 365 Sales](https://doi.org/10.1145/3583780.3615508)|Itzik Malkiel, Uri Alon, Yakir Yehuda, Shahar Keren, Oren Barkan, Royi Ronen, Noam Koenigstein|Microsoft, Tel Aviv Yaffo, Israel|Transcriptions of phone calls hold significant value in sales, customer service, healthcare, law enforcement, and more. However, analyzing recorded conversations can be a time-consuming process, especially for complex dialogues. In Microsoft Dynamics 365 Sales, a novel system, named GPT-Calls, is applied for efficient and accurate topic-based call segmentation. GPT-Calls comprises offline and online phases. In the offline phase, the system leverages a GPT model to generate synthetic sentences and extract anchor vectors for predefined topics. This phase, performed once on a given topic list, significantly reduces the computational burden. The online phase scores the similarity between the transcribed conversation and the topic anchors from the offline phase, followed by time domain analysis to group utterances into segments and tag them with topics. The GPT-Calls scheme offers an accurate and efficient approach to call segmentation and topic extraction, eliminating the need for labeled data. It is a versatile solution applicable to various industry domains. GPT-Calls operates in production under Dynamics 365 Sales Conversation Intelligence, applied to real sales conversations from diverse Dynamics 365 Sales tenants, streamlining call analysis, and saving time and resources while ensuring accuracy and effectiveness.|电话记录在销售、客户服务、医疗保健、执法等方面具有重要价值。然而，分析记录的对话可能是一个耗时的过程，特别是对于复杂的对话。在 Microsoft Dynamics 365 Sales 中，一个名为 GPT-Call 的新系统被应用于高效、准确的基于主题的呼叫分类。GPT-通话包括离线和在线两个阶段。在离线阶段，系统利用 GPT 模型生成合成语句，并为预定义的主题提取锚向量。这个阶段在给定的主题列表上执行一次，就可以大大减少计算负担。在线阶段记录转录的会话与离线阶段的主题锚之间的相似性，然后进行时域分析，将话语分成片段，并给它们加上主题标签。GPT-Call 方案提供了一种准确有效的呼叫分割和主题提取方法，从而消除了对标记数据的需求。它是一个适用于各种行业领域的通用解决方案。GPT-Call 在 Dynamics 365 Sales Conversation Intelligence 下运作，应用于来自不同 Dynamics 365销售租户的真实销售对话，简化呼叫分析，节省时间和资源，同时确保准确性和有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Harnessing+GPT+for+Topic-Based+Call+Segmentation+in+Microsoft+Dynamics+365+Sales)|0|
|[Astrolabe: Visual Graph Database Queries with Tabular Output](https://doi.org/10.1145/3583780.3615992)|Michael Miller|Northrop Grumman Space Systems, Roy, UT, USA|Graph databases are an established solution for large, highly connected datasets. One challenge associated with deploying graph databases in industrial settings is usability. Typically, developers interact with graph databases through queries in languages such as Cypher or GraphQL. Many end-users, analysts, and administrators are not familiar with these specialized languages. Additionally, these queries return hierarchical data in formats such as JSON (JavaScript Object Notation) or XML (Extensible Markup Language). Additional scripts and interfaces are needed to convert hierarchical data into more easily digested tables. To overcome these challenges, each graph database use-case typically involves significant custom software to explore, view, and export data. We introduce Astrolabe, a generalized interface that addresses the challenges of querying graph databases. In Astrolabe, queries are constructed visually, so users do not need to learn new graph query languages. Results are returned as tables, which can be easily digested by end users or down-stream applications. Astrolabe was designed to function with arbitrary graph databases, so schema definition is not required. Astrolabe revolutionizes graph exploration and querying by allowing graph databases to be viewed as tables, without the need for custom software adapters.|图形数据库是大型、高度连接数据集的一种已建立的解决方案。在工业环境中部署图形数据库的一个挑战是可用性。通常，开发人员通过 Cypher 或 GraphQL 等语言中的查询与图形数据库交互。许多最终用户、分析人员和管理员不熟悉这些专用语言。此外，这些查询以 JSON (JSON)或 XML (XML)等格式返回分层数据。需要额外的脚本和接口将分层数据转换为更容易消化的表。为了克服这些挑战，每个图形数据库用例通常需要使用重要的定制软件来探索、查看和导出数据。我们介绍 Astrolabe，它是一个通用的接口，用于解决查询图形数据库的挑战。在 Astrolabe 中，查询是可视化构建的，因此用户不需要学习新的图形查询语言。结果以表的形式返回，终端用户或下游应用程序可以很容易地消化这些结果。星盘被设计用于任意图形数据库，因此不需要模式定义。Astrolabe 通过允许将图形数据库视为表格，而不需要自定义软件适配器，彻底改革了图形探索和查询。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Astrolabe:+Visual+Graph+Database+Queries+with+Tabular+Output)|0|
|[LAMM: Language Aware Active Learning for Multilingual Models](https://doi.org/10.1145/3583780.3615507)|Ze Ye, Dantong Liu, Kaushik Pavani, Sunny Dasgupta|Amazon.com, Inc., Sunnyvale, CA, USA; Amazon.com, Inc., Seattle, WA, USA|In industrial settings, it is often necessary to achieve language-level accuracy targets. For example, Amazon business teams need to build multilingual product classifiers that operate accurately in all European languages. It is unacceptable for the accuracy of product classification to meet the target in one language (e.g, English), while falling below the target in other languages (e.g, Portuguese). To fix such issues, we propose Language Aware Active Learning for Multilingual Models (LAMM), an active learning strategy that enables a classifier to learn from a small amount of labeled data in a targeted manner to improve the accuracy of Low-resource languages (LRLs) with limited amounts of data for model training. Our empirical results on two open-source datasets and two proprietary product classification datasets demonstrate that LAMM is able to improve the LRL performance by 4%--11% when compared to strong baselines.|在工业设置中，通常需要达到语言级别的精度目标。例如，亚马逊的业务团队需要构建多语言的产品分类器，这些分类器可以准确地在所有欧洲语言中运行。以一种语言(例如英文)达到目标，而以其他语言(例如葡萄牙文)达不到目标，产品分类的准确性是不可接受的。为了解决这些问题，我们提出了语言感知的多语言模型主动学习(LAMM) ，这是一种主动学习策略，使分类器能够以有针对性的方式从少量的标记数据中学习，以提高低资源语言(LRL)的准确性，用有限的数据进行模型训练。我们对两个开源数据集和两个专有产品分类数据集的实证结果表明，与强基线相比，LAMM 能够提高 LRL 性能4% -11% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LAMM:+Language+Aware+Active+Learning+for+Multilingual+Models)|0|
|[Unleashing the Power of Large Language Models for Legal Applications](https://doi.org/10.1145/3583780.3615993)|Dell Zhang, Alina Petrova, Dietrich Trautmann, Frank Schilder|Thomson Reuters Labs, London, United Kingdom; Thomson Reuters Labs, Zug, Switzerland; Thomson Reuters Labs, Eagan, MN, USA|The use of Large Language Models (LLMs) is revolutionizing the legal industry. In this technical talk, we would like to explore the various use cases of LLMs in legal tasks, discuss the best practices, investigate the available resources, examine the ethical concerns, and suggest promising research directions.|大型语言模型(LLM)的使用正在给法律行业带来革命性的变化。在这个技术演讲中，我们将探讨法律任务中 LLM 的各种用例，讨论最佳实践，调查可用资源，审查伦理问题，并提出有前途的研究方向。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unleashing+the+Power+of+Large+Language+Models+for+Legal+Applications)|0|
|[Info-Wild: Knowledge Extraction and Management for Wildlife Conservation](https://doi.org/10.1145/3583780.3615313)|Prasenjit Mitra, Shreya Ghosh, Bistra Dilkina, Thomas Müller|University of Southern California, Los Angeles, CA, USA; Goethe University and Senckenberg Biodiversity & Climate Research Centre, Senckenberg, Germany; Pennsylvania State University, State College, PA, USA|Our primary objective is to explore and enhance AI's role for wildlife conservation, in brief, Nature Through the Lens of AI. It seeks to address crucial challenges related to data heterogeneity, scale integration, data privacy, mitigating biases, and decision-making under uncertainty. This workshop is centred around leveraging AI's prowess in deciphering complex spatio-temporal data patterns for wildlife conservation, thereby contributing significantly to the broader canvas of AI for social good. The workshop intends to create an interdisciplinary platform bringing together computer scientists, data scientists, geospatial experts, ecologists, and conservation practitioners, fostering collaboration and driving real-world impact. The program will include keynote speeches, panel discussions, and interactive sessions focusing on efficient knowledge extraction and management, remote sensing technologies, predictive modeling, species distribution modeling, habitat quality assessment, and human-wildlife conflict mitigation. With an em- phasis on CIKM's primary interests, our aim is not only to enrich understanding of AI's symbiotic potential with ecology but also to utilize it to address pressing societal and environmental challenges.|我们的主要目标是探索和加强人工智能在野生动物保护方面的作用，简而言之，就是通过人工智能的镜头来观察自然。它寻求解决与数据异构性、规模集成、数据隐私、减少偏差和不确定性下的决策相关的关键挑战。这个研讨会的中心是利用人工智能破译复杂的野生动物保护时空数据模式的能力，从而为更广泛的人工智能社会公益事业做出重大贡献。研讨会打算创建一个跨学科平台，将计算机科学家、数据科学家、地理空间专家、生态学家和环境保护从业人员聚集在一起，促进合作，推动现实世界的影响。该项目将包括主题演讲、小组讨论和互动会议，重点是有效的知识提取和管理、遥感技术、预测建模、物种分布建模、栖息地质量评估和人类与野生动植物冲突的缓解。重点关注 CIKM 的主要兴趣，我们的目标不仅是丰富对人工智能与生态共生潜力的理解，而且利用它来应对紧迫的社会和环境挑战。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Info-Wild:+Knowledge+Extraction+and+Management+for+Wildlife+Conservation)|0|
|[Anomaly and Novelty detection for Satellite and Drone systems (ANSD '23)](https://doi.org/10.1145/3583780.3615306)|Shahroz Tariq, Daewon Chung, Simon Woo, Youjin Shin|The Catholic University of Korea, Bucheon, South Korea; Sungkyunkwan University, Suwon, South Korea; CSIRO's Data61, Sydney, Australia; Korea Aerospace Research Institute (KARI), Daejeon, South Korea|In recent times, there has been a notable surge in the amount of vision and sensing/time-series data obtained from drones and satellites. This data can be utilized in various fields, such as precision agriculture, disaster management, environmental monitoring, and others. However, the analysis of such data poses significant challenges due to its complexity, heterogeneity, and scale. Furthermore, it is critical to identify anomalies and maintain/monitor the health of drones and satellite systems to enable the aforementioned applications and sciences. This workshop presents an excellent opportunity to explore solutions that specifically target the detection of anomalies and novel occurrences in drones and satellite systems and their data. For more information, visit our website at https://sites.google.com/view/ansd23|近年来，从无人机和卫星获得的视觉和传感/时间序列数据量显著增加。这些数据可用于各种领域，如精细农业、灾害管理、环境监测等。然而，由于其复杂性、异构性和规模，对这些数据的分析提出了重大挑战。此外，必须查明异常情况并维持/监测无人机和卫星系统的健康状况，以便能够开展上述应用和科学研究。这次研讨会提供了一个极好的机会，可以探讨具体针对探测无人机和卫星系统及其数据中的异常和新现象的解决办法。如欲查询更多资料，请浏览本署网页( https://sites.google.com/view/ansd23)|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Anomaly+and+Novelty+detection+for+Satellite+and+Drone+systems+(ANSD+'23))|0|
|[Knowledge-driven Analytics and Systems Impacting Human Quality of Life- Neurosymbolic AI, Explainable AI and Beyond](https://doi.org/10.1145/3583780.3615300)|Arijit Ukil, Joao Gama, Antonio J. Jara, Leandro Marín|University of Porto, Porto, Portugal; Libelium, Murcia, Spain; University of Murcia, Murcia, Spain; TCS Research, Kolkata, India|The management of knowledge-driven artificial intelligence technologies is essential in order to evaluate their impact on human life and society. Social networks and tech use can have a negative impact on us physically, emotionally, socially and mentally. On the other hand, intelligent systems can have a positive effect on people's lives. Currently, we are witnessing the power of large language models (LLMs) like chatGPT and its influence towards the society. The objective of the workshop is to contribute to the advancement of intelligent technologies designed to address the human condition. This could include precise and personalized medicine, better care for elderly people, reducing private data leaks, using AI to manage resources better, using AI to predict risks, augmenting human capabilities, and more. The workshop's objective is to present research findings and perspectives that demonstrate how knowledge-enabled technologies and applications improve human well-being. This workshop indeed focuses on the impacts at different granularity levels made by Artificial Intelligence (AI) research on the micro granular level, where the daily or regular functioning of human life is affected, and also the macro granulate level, where the long-term or far-future effects of artificial intelligence on people's lives and the human society could be pretty high. In conclusion, this workshop explores how AI research can potentially address the most pressing challenges facing modern societies, and how knowledge management can potentially contribute to these solutions.|知识驱动的人工智能技术的管理对于评估其对人类生活和社会的影响至关重要。社交网络和科技的使用会对我们的身体、情感、社交和精神产生负面影响。另一方面，智能系统可以对人们的生活产生积极的影响。目前，我们正在见证像 chatGPT 这样的大型语言模型(LLM)的力量及其对社会的影响。讲习班的目的是促进智能技术的进步，以解决人类的条件。这可能包括精确和个体化医学，更好地照顾老年人，减少私人数据泄露，使用人工智能更好地管理资源，使用人工智能预测风险，增强人类能力等等。研讨会的目的是展示研究结果和观点，说明知识技术和应用如何改善人类福祉。这个研讨会确实关注人工智能(AI)研究在不同粒度水平上对微观粒度水平(人类生活的日常或正常功能受到影响)和宏观粒度水平(人工智能对人类生活和人类社会的长期或远期影响可能相当高)的影响。最后，本次研讨会探讨了人工智能研究如何能够潜在地应对现代社会面临的最紧迫挑战，以及知识管理如何能够潜在地为这些解决方案做出贡献。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge-driven+Analytics+and+Systems+Impacting+Human+Quality+of+Life-+Neurosymbolic+AI,+Explainable+AI+and+Beyond)|0|
|[Knowledge-enhanced Artificial Intelligence in Drug Discovery (KAIDD)](https://doi.org/10.1145/3583780.3615309)|Qingpeng Zhang, Jiannan Yang|The University of Hong Kong, Hong Kong SAR, Hong Kong|Artificial Intelligence (AI) in drug discovery is a rapidly evolving field that combines computational methods with biological knowledge and applications. Traditionally, the process of developing a new drug has been time-consuming and expensive, spanning several years and costing billions of dollars. The emergence of AI technologies offers the potential to significantly reduce both the timeline and cost involved in this critical endeavour. However, it is crucial to acknowledge that AI applications in pharmacy and drug discovery require a high degree of interpretability and transparency. The integration of domain knowledge into AI models becomes paramount to ensure the reliability and trustworthiness of the generated results. In light of these considerations, we propose a workshop on "Knowledge-enhanced Artificial Intelligence in Drug Discovery (KAIDD)." This workshop aims to explore the profound impact of incorporating various knowledge databases into the development of explainable AI models for drug discovery. Participants will have the opportunity to delve into cutting-edge research, methodologies, and practical applications that leverage the fusion of AI techniques with domain-specific knowledge. Authors of accepted papers will have the opportunity to submit extended versions of their work for a full-paper review process and potential publication in Philosophical Transactions of the Royal Society B.|药物发现中的人工智能(AI)是一个快速发展的领域，它将计算方法与生物学知识和应用相结合。传统上，开发一种新药的过程既耗时又昂贵，需要花费数年时间和数十亿美元。人工智能技术的出现有可能大大缩短这一关键工作的时间和成本。然而，认识到 AI 在药剂学和药物发现中的应用需要高度的可解释性和透明度是至关重要的。将领域知识集成到人工智能模型中对于确保所生成结果的可靠性和可信度至关重要。基于这些考虑，我们提议举办“药物发现中的知识增强型人工智能(KAIDD)”研讨会这次研讨会的目的是探讨将各种知识数据库纳入药物发现可解释的人工智能模型开发的深远影响。与会者将有机会深入研究前沿的研究，方法学和实际应用，利用人工智能技术与特定领域的知识融合。被接受的论文的作者将有机会提交他们的工作的扩展版本的全文审查过程和潜在的出版物在英国皇家学会哲学会报 B。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge-enhanced+Artificial+Intelligence+in+Drug+Discovery+(KAIDD))|0|
|[Ontology Enrichment from Texts: A Biomedical Dataset for Concept Discovery and Placement](https://doi.org/10.1145/3583780.3615126)|Hang Dong, Jiaoyan Chen, Yuan He, Ian Horrocks|University of Oxford, Oxford, United Kingdom; The University of Manchester & University of Oxford, Manchester, United Kingdom|Mentions of new concepts appear regularly in texts and require automated approaches to harvest and place them into Knowledge Bases (KB), e.g., ontologies and taxonomies. Existing datasets suffer from three issues, (i) mostly assuming that a new concept is pre-discovered and cannot support out-of-KB mention discovery; (ii) only using the concept label as the input along with the KB and thus lacking the contexts of a concept label; and (iii) mostly focusing on concept placement w.r.t a taxonomy of atomic concepts, instead of complex concepts, i.e., with logical operators. To address these issues, we propose a new benchmark, adapting MedMentions dataset (PubMed abstracts) with SNOMED CT versions in 2014 and 2017 under the Diseases sub-category and the broader categories of Clinical finding, Procedure, and Pharmaceutical / biologic product. We provide usage on the evaluation with the dataset for out-of-KB mention discovery and concept placement, adapting recent Large Language Model based methods.|新概念的提及经常出现在文本中，需要自动化的方法来收集并放入知识库(KB)中，例如，本体论和分类法。现有的数据集存在三个问题，(i)主要假设一个新的概念是预先发现的，不能支持知识库之外的发现; (ii)只使用概念标签作为输入以及知识库，因此缺乏概念标签的上下文; 以及(iii)主要关注概念放置.r.t 原子概念的分类，而不是复杂的概念，即逻辑运算符。为了解决这些问题，我们提出了一个新的基准，在2014年和2017年在疾病子类别和更广泛的临床发现，程序和药物/生物产品类别下使用 SNOMED CT 版本的 MedMations 数据集(PubMed 摘要)。我们提供了使用数据集进行评估的方法，用于知识库以外的提及发现和概念放置，并采用了最新的基于大语言模型的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ontology+Enrichment+from+Texts:+A+Biomedical+Dataset+for+Concept+Discovery+and+Placement)|0|
|[FlaCGEC: A Chinese Grammatical Error Correction Dataset with Fine-grained Linguistic Annotation](https://doi.org/10.1145/3583780.3615119)|Hanyue Du, Yike Zhao, Qingyuan Tian, Jiani Wang, Lei Wang, Yunshi Lan, Xuesong Lu||Chinese Grammatical Error Correction (CGEC) has been attracting growing attention from researchers recently. In spite of the fact that multiple CGEC datasets have been developed to support the research, these datasets lack the ability to provide a deep linguistic topology of grammar errors, which is critical for interpreting and diagnosing CGEC approaches. To address this limitation, we introduce FlaCGEC, which is a new CGEC dataset featured with fine-grained linguistic annotation. Specifically, we collect raw corpus from the linguistic schema defined by Chinese language experts, conduct edits on sentences via rules, and refine generated samples manually, which results in 10k sentences with 78 instantiated grammar points and 3 types of edits. We evaluate various cutting-edge CGEC methods on the proposed FlaCGEC dataset and their unremarkable results indicate that this dataset is challenging in covering a large range of grammatical errors. In addition, we also treat FlaCGEC as a diagnostic dataset for testing generalization skills and conduct a thorough evaluation of existing CGEC models.|近年来，汉语语法错误纠正(CGEC)越来越受到研究者的关注。尽管已经开发了多个 CGEC 数据集来支持这项研究，但是这些数据集缺乏提供深层语法错误语言拓扑的能力，这对于解释和诊断 CGEC 方法至关重要。为了解决这个问题，我们引入了 FlaCGEC，它是一个新的具有细粒度语言标注的 CGEC 数据集。具体来说，我们从汉语专家定义的语言图式中收集原始语料，通过规则对句子进行编辑，并对生成的样本进行人工精炼，得到10000个句子，其中78个实例化语法点，3种类型的编辑。我们评估了各种尖端的 CGEC 方法对提出的 FlaCGEC 数据集和他们的不起眼的结果表明，这个数据集是具有挑战性的，以涵盖大范围的语法错误。此外，我们还将 FlaCGEC 作为一个诊断数据集，用于测试泛化技能，并对现有的 CGEC 模型进行全面评估。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FlaCGEC:+A+Chinese+Grammatical+Error+Correction+Dataset+with+Fine-grained+Linguistic+Annotation)|0|
|[PGB: A PubMed Graph Benchmark for Heterogeneous Network Representation Learning](https://doi.org/10.1145/3583780.3615128)|Eric Wonhee Lee, Joyce C. Ho|Emory University, Atlanta, GA, USA|There has been a rapid growth in biomedical literature, yet capturing the heterogeneity of the bibliographic information of these articles remains relatively understudied. Although graph mining research via heterogeneous graph neural networks has taken center stage, it remains unclear whether these approaches capture the heterogeneity of the PubMed database, a vast digital repository containing over 33 million articles. We introduce PubMed Graph Benchmark (PGB), a new benchmark dataset for evaluating heterogeneous graph embeddings for biomedical literature. PGB is one of the largest heterogeneous networks to date and consists of 30 million English articles. The benchmark contains rich metadata including abstract, authors, citations, MeSH terms, MeSH hierarchy, and some other information. The benchmark contains an evaluation task of 21 systematic reviews topics from 3 different datasets. In PGB, we aggregate the metadata associated with the biomedical articles from PubMed into a unified source and make the benchmark publicly available for any future works.|生物医学文献发展迅速，然而对这些文献书目信息的异质性的捕捉仍然相对缺乏研究。尽管通过异构图形神经网络进行的图形挖掘研究已经占据了中心地位，但是这些方法是否能够捕捉到 PubMed 数据库的异构性仍然是个未知数。 PubMed 数据库是一个包含超过3300万篇文章的庞大数字图书馆。我们介绍了 PubMed 图基准(PGB) ，一个新的基准数据集评估异构图嵌入生物医学文献。PGB 是迄今为止最大的异构网络之一，拥有3000万篇英文文章。基准测试包含丰富的元数据，包括摘要、作者、引用、 MeSH 术语、 MeSH 层次结构和其他一些信息。该基准包含来自3个不同数据集的21个系统评价主题的评价任务。在 PGB，我们将来自 PubMed 的生物医学文章的元数据聚合成一个统一的来源，并将基准公开发布给未来的任何工作。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PGB:+A+PubMed+Graph+Benchmark+for+Heterogeneous+Network+Representation+Learning)|0|
|[CTCam: Enhancing Transportation Evaluation through Fusion of Cellular Traffic and Camera-Based Vehicle Flows](https://doi.org/10.1145/3583780.3615116)|ChungYi Lin, ShenLung Tung, HungTing Su, Winston H. Hsu|National Taiwan University & Mobile Drive Technology, Taipei City, Taiwan Roc; National Taiwan University & Chunghwa Telecom Laboratories, Taipei City, Taiwan Roc; National Taiwan University, Taipei City, Taiwan Roc; Chunghwa Telecom Laboratories, Taipei City, Taiwan Roc|Traffic prediction utility often faces infrastructural limitations, which restrict its coverage. To overcome this challenge, we present Geographical Cellular Traffic (GCT) flow that leverages cellular network data as a new source for transportation evaluation. The broad coverage of cellular networks allows GCT flow to capture various mobile user activities across regions, aiding city authorities in resource management through precise predictions. Acknowledging the complexity arising from the diversity of mobile users in GCT flow, we supplement it with camera-based vehicle flow data from limited deployments and verify their spatio-temporal attributes and correlations through extensive data analysis. Our two-stage fusion approach integrates these multi-source data, addressing their coverage and magnitude discrepancies, thereby enhancing the prediction of GCT flow for accurate transportation evaluation. Overall, we propose novel uses of telecom data in transportation and verify its effectiveness in multi-source fusion with vision-based data.|交通预测效用往往面临基础设施的限制，从而限制了其覆盖范围。为了克服这一挑战，我们提出地理蜂窝流量(GCT)流，利用蜂窝网络数据作为一个新的来源，运输评估。蜂窝网络的广泛覆盖使得 GCT 流能够捕获跨区域的各种移动用户活动，通过精确的预测帮助城市当局进行资源管理。认识到 GCT 流中移动用户的多样性所带来的复杂性，我们补充了有限部署的基于摄像头的车流数据，并通过广泛的数据分析验证了它们的时空属性和相关性。我们的两阶段融合方法集成了这些多源数据，解决了它们的覆盖范围和数量级差异，从而提高了 GCT 流量的预测，以便准确地进行交通评估。总之，我们提出了电信数据在交通运输中的新用途，并验证了其在基于视觉数据的多源融合中的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CTCam:+Enhancing+Transportation+Evaluation+through+Fusion+of+Cellular+Traffic+and+Camera-Based+Vehicle+Flows)|0|
|[Datasets and Interfaces for Benchmarking Heterogeneous Graph Neural Networks](https://doi.org/10.1145/3583780.3615117)|Yijian Liu, Hongyi Zhang, Cheng Yang, Ao Li, Yugang Ji, Luhao Zhang, Tao Li, Jinyu Yang, Tianyu Zhao, Juan Yang, Hai Huang, Chuan Shi|Beijing University of Posts and Telecommunications, Beijing, China; Meituan, Beijing, China; Orange Shield Technology, Hangzhou, China|In recent years, Heterogeneous Graph Neural Networks (HGNNs) have gained increasing attention due to their excellent performance in applications. However, the lack of high-quality benchmarks in new fields has become a critical limitation for developing and applying HGNNs. To accommodate the urgent need for emerging fields and the advancement of HGNNs, we present two large-scale, real-world, and challenging heterogeneous graph datasets from real scenarios: risk commodity detection and takeout recommendation. Meanwhile, we establish standard benchmark interfaces that provide over 40 heterogeneous graph datasets. We provide initial data split, unified evaluation metrics, and baseline results for future work, making it fair and handy to explore state-of-the-art HGNNs. Our interfaces also offer a comprehensive toolkit to research the characteristics of graph datasets. The above new datasets are publicly available on https://zenodo.org/communities/hgd, and the interface codes are available at https://github.com/BUPT-GAMMA/hgbi.|近年来，异构图神经网络(HGNN)以其优异的性能在应用中受到越来越多的关注。然而，在新领域缺乏高质量的基准已经成为开发和应用 HGNN 的一个关键限制因素。为了适应新兴领域的迫切需要和 HGNN 的发展，我们提出了两个来自真实场景的大规模、真实世界和具有挑战性的异构图形数据集: 风险商品检测和外卖推荐。同时，我们建立了标准的基准接口，提供了40多个异构图形数据集。我们为未来的工作提供了初始数据分割、统一的评估指标和基线结果，使得探索最先进的 HGNN 变得公平和方便。我们的接口还提供了一个全面的工具包来研究图形数据集的特征。上述新的数据集可在 https://zenodo.org/communities/hgd 上公开查阅，而界面代码则可在 https://github.com/bupt-gamma/hgbi 上查阅。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Datasets+and+Interfaces+for+Benchmarking+Heterogeneous+Graph+Neural+Networks)|0|
|[ContributionSum: Generating Disentangled Contributions for Scientific Papers](https://doi.org/10.1145/3583780.3615115)|MengHuan Liu, AnZi Yen, HenHsen Huang, HsinHsi Chen|National Yang Ming Chiao Tung University, Hsinchu, Taiwan Roc; Institute of Information Science, Academia Sinica, Taipei, Taiwan Roc; National Taiwan University, Taipei, Taiwan Roc|Contributions are essentially the core of every scientific research, highlighting their key values to the academic community. Systems that are capable of identifying the contributions from scientific papers precisely and organizing them into well-structured summaries can facilitate both text processing and human comprehension. In this paper, we present ContributionSum, a dataset consisting of 24K computer science papers with contributions explicitly listed by the authors, which are further classified into different contribution types based on a newly-proposed annotation scheme. In addition, we study the task of generating disentangled contributions that summarize the values of scientific papers into key points. We propose a fine-grained post-training strategy tailored to our task and leverage salient information of different contribution types in the papers. To assess the coherency and coverage of each contribution aspect, we perform summary-level and contribution-level evaluations for our task. Experimental results show that our method improves upon mainstream baselines.|贡献本质上是每项科学研究的核心，突出其对学术界的关键价值。能够准确识别科学论文的贡献并将其组织成结构良好的摘要的系统能够促进文本处理和人类理解。本文提出了一个由24K 计算机科学论文组成的数据集，其中包括作者明确列出的贡献，并根据新提出的注释方案将这些贡献进一步分为不同的贡献类型。此外，我们研究的任务，产生分离的贡献，总结成关键点的科学论文的价值。我们提出了一个细粒度的后培训策略，针对我们的任务和利用不同贡献类型的突出信息的文件。为了评估每个贡献方面的一致性和覆盖面，我们对我们的任务进行了总结一级和贡献一级的评价。实验结果表明，该方法在主流基线的基础上得到了改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ContributionSum:+Generating+Disentangled+Contributions+for+Scientific+Papers)|0|
|[ClinicalRisk: A New Therapy-related Clinical Trial Dataset for Predicting Trial Status and Failure Reasons](https://doi.org/10.1145/3583780.3615113)|Junyu Luo, Zhi Qiao, Lucas Glass, Cao Xiao, Fenglong Ma|The Pennsylvania State University, University Park, PA, USA; United Imaging Healthcare, Beijing, China; IQVIA, Chicago, IL, USA; GE HealthCare, Chicago, IL, USA|Clinical trials aim to study new tests and evaluate their effects on human health outcomes, which has a huge market size. However, carrying out clinical trials is expensive and time-consuming and often ends in no results. It will revolutionize clinical practice if we can develop an effective model to automatically estimate the status of a clinical trial and find out possible failure reasons. However, it is challenging to develop such a model because of the lack of a benchmark dataset. To address these challenges, in this paper, we first build a new dataset by extracting the publicly available clinical trial reports from ClinicalTrials.gov. The associated status of each report is treated as the status label. To analyze the failure reasons, domain experts help us manually annotate each failed report based on the description associated with it. More importantly, we examine several state-of-the-art text classification baselines on this task and find out that the unique format of the clinical trial protocols plays an essential role in affecting prediction accuracy, demonstrating the need for specially designed clinical trial classification models.|临床试验的目的是研究新的测试方法，并评估其对人类健康结果的影响，这方面的市场规模巨大。然而，进行临床试验是昂贵和费时的，往往没有结果。如果我们能够开发一个有效的模型来自动估计临床试验的状态，并找出可能的失败原因，这将彻底改变临床实践。然而，由于缺乏基准数据集，开发这样一个模型是具有挑战性的。为了应对这些挑战，在本文中，我们首先从 clinicaltrials.gov 中提取公开可用的临床试验报告，建立一个新的数据集。每个报表的关联状态被视为状态标签。为了分析失败的原因，领域专家帮助我们根据相关的描述手动注释每个失败的报告。更重要的是，我们在这项任务上检查了几个最先进的文本分类基线，发现临床试验方案的独特格式在影响预测准确性方面起着至关重要的作用，表明需要特别设计的临床试验分类模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ClinicalRisk:+A+New+Therapy-related+Clinical+Trial+Dataset+for+Predicting+Trial+Status+and+Failure+Reasons)|0|
|[ThyExp: An explainable AI-assisted Decision Making Toolkit for Thyroid Nodule Diagnosis based on Ultra-sound Images](https://doi.org/10.1145/3583780.3615131)|Jamie Morris, Zehao Liu, Huizhi Liang, Sidhartha Nagala, Xia Hong|The University of Reading, Reading, United Kingdom; Royal Berkshire Hospital, Reading, United Kingdom; Newcastle University, Newcastle Upon Tyne, United Kingdom|Radiologists have an important task of diagnosing thyroid nodules present in ultra sound images. Although reporting systems exist to aid in the diagnosis process, these systems do not provide explanations about the diagnosis results. We present ThyExp -- a web based toolkit for it use by medical professionals, allowing for accurate diagnosis with explanations of thyroid nodules present in ultrasound images utilising artificial intelligence models. The proposed web-based toolkit can be easily incorporated into current medical workflows, and allows medical professionals to have the confidence of a highly accurate machine learning model with explanations to provide supplementary diagnosis data. The solution provides classification results with their probability accuracy, as well as the explanations in the form of presenting the key features or characteristics that contribute to the classification results. The experiments conducted on a real-world UK NHS hospital patient dataset demonstrate the effectiveness of the proposed approach. This toolkit can improve the trust of medical professional to understand the confidence of the model in its predictions. This toolkit can improve the trust of medical professionals in understanding the models reasoning behind its predictions.|放射科医生的一项重要任务是诊断甲状腺结节存在于超声图像。虽然报告系统的存在有助于诊断过程，这些系统不提供对诊断结果的解释。我们介绍 ThyExp ——一个基于网络的医疗专业人员使用的工具包，允许使用人工智能模型对超声图像中出现的甲状腺结节进行精确诊断。建议的基于网络的工具包可以很容易地纳入当前的医疗工作流程，并允许医疗专业人员有信心的一个高度准确的机器学习模型与解释，以提供补充诊断数据。该解决方案提供了分类结果及其概率准确性，以及以显示有助于分类结果的关键特征或特征的形式提供的解释。在一个真实的英国 NHS 医院病人数据集上进行的实验证明了该方法的有效性。该工具包可以提高医疗专业人员的信任，以了解模型的信心，在其预测。这个工具包可以提高医疗专业人员在理解其预测背后的模型推理的信任。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ThyExp:+An+explainable+AI-assisted+Decision+Making+Toolkit+for+Thyroid+Nodule+Diagnosis+based+on+Ultra-sound+Images)|0|
|[GOAL: A Challenging Knowledge-grounded Video Captioning Benchmark for Real-time Soccer Commentary Generation](https://doi.org/10.1145/3583780.3615120)|Ji Qi, Jifan Yu, Teng Tu, Kunyu Gao, Yifan Xu, Xinyu Guan, Xiaozhi Wang, Bin Xu, Lei Hou, Juanzi Li, Jie Tang||Despite the recent emergence of video captioning models, how to generate vivid, fine-grained video descriptions based on the background knowledge (i.e., long and informative commentary about the domain-specific scenes with appropriate reasoning) is still far from being solved, which however has great applications such as automatic sports narrative. In this paper, we present GOAL, a benchmark of over 8.9k soccer video clips, 22k sentences, and 42k knowledge triples for proposing a challenging new task setting as Knowledge-grounded Video Captioning (KGVC). Moreover, we conduct experimental adaption of existing methods to show the difficulty and potential directions for solving this valuable and applicable task.|尽管最近出现了视频字幕模型，但是如何基于背景知识生成生动的、细粒度的视频描述(例如，对特定领域场景进行长时间的、信息丰富的评论，并进行适当的推理)仍然是一个有待解决的问题。在本文中，我们提出了目标，一个基准的超过8.9 k 足球视频剪辑，22k 句子，和42k 知识三元组提出了一个具有挑战性的新任务设置作为知识为基础的视频字幕(KGVC)。此外，我们对现有的方法进行了实验改编，以显示解决这一有价值和适用的任务的困难和潜在的方向。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GOAL:+A+Challenging+Knowledge-grounded+Video+Captioning+Benchmark+for+Real-time+Soccer+Commentary+Generation)|0|
|[DynamicESG: A Dataset for Dynamically Unearthing ESG Ratings from News Articles](https://doi.org/10.1145/3583780.3615118)|YuMin Tseng, ChungChi Chen, HenHsen Huang, HsinHsi Chen|Institute of Information Science, Academia Sinica, Taipei, Taiwan Roc; National Taiwan University, Taipei, Taiwan Roc; AIST, Tokyo, Japan|This paper introduces the DynamicESG dataset, a unique resource for dynamically extracting ESG ratings from news articles. The ESG rating, a novel metric employed annually to gauge a company's sustainability, relies heavily on corporate disclosure and other external information, especially news narratives. Our dataset, comprising a wide spectrum of news over a twelve-year span, annotates articles in accordance with MSCI ESG ratings methodology and SASB standards, with relevance to ESG issues. DynamicESG provides a comprehensive means of investigating the relationship between public discourse, ESG-related events, and subsequent ESG rating adjustments. We detail our data collection, curation, annotation procedure, and inter-rater agreement, ensuring high data quality and usability. Importantly, our dataset includes a temporal dimension, enabling the analysis of longitudinal trends in ESG ratings and their correlation with news coverage. Moreover, the dataset incorporates an opportunity/risk tendency, thus permitting analysis from diverse perspectives to discern if the news is beneficial or detrimental to the company. We believe this dataset will serve as a valuable resource for researchers in fields such as corporate social responsibility, sustainable investing, machine learning, and natural language processing. Initial analysis using the dataset underscores its potential to facilitate new insights into the dynamics of ESG ratings and the influence of news media on these ratings.|本文介绍了 DynamicESG 数据集，这是一个从新闻文章中动态提取 ESG 评分的独特资源。ESG 评级是每年用来衡量一家公司可持续性的新指标，严重依赖于公司信息披露和其他外部信息，尤其是新闻报道。我们的数据集，包括一个12年跨度的广泛的新闻频谱，根据摩根士丹利资本国际 ESG 评级方法和 SASB 标准注释文章，与 ESG 问题相关。DynamicESG 提供了一种全面的方法来调查公共话语、 ESG 相关事件和随后的 ESG 评级调整之间的关系。我们详细说明了我们的数据收集、管理、注释程序和评价者之间的协议，确保了高数据质量和可用性。重要的是，我们的数据集包括一个时间维度，使 ESG 评级的纵向趋势及其与新闻报道的相关性分析成为可能。此外，数据集包含了机会/风险倾向，从而允许从不同角度进行分析，以辨别新闻对公司是有利还是有害。我们相信，这个数据集将成为企业社会责任、可持续投资、机器学习和自然语言处理等领域的研究人员的宝贵资源。使用数据集进行的初步分析强调了其促进对 ESG 评级动态和新闻媒体对这些评级的影响的新见解的潜力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DynamicESG:+A+Dataset+for+Dynamically+Unearthing+ESG+Ratings+from+News+Articles)|0|
|[MDCC: A Multimodal Dynamic Dataset for Donation-based Crowdfunding Campaigns](https://doi.org/10.1145/3583780.3615124)|Xovee Xu, Jiayang Li, Fan Zhou|University of Electronic Science and Technology of China & Kash Institute of Electronics and Information Industry, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China|Crowdfunding platforms have become pivotal financial support avenues for diverse causes, yet the success rates are surprisingly low. Previous research has largely focused on reward-based crowdfunding, leaving donation-based platforms under-studied. In addition, the roles of multimodal data (e.g., textual descriptions and visual photos) and dynamic elements (e.g., sequences of donations, project updates, and comments) in influencing campaign success have been largely overlooked. This paper introduces MDCC, a Multimodal Dynamic dataset for donation-based Crowdfunding Campaigns, collected from 14,961 projects on GoFundMe, incorporates multimodal project information and captures project dynamics, thus providing a comprehensive tool for analyzing donation-based crowdfunding. The dataset is expected to inspire innovative methodologies and facilitate understanding of project success determinants. Our preliminary experiments demonstrate the significance of multimodal and dynamic crowdfunding data on predicting the success of donation-based projects.|众筹平台已经成为各种不同事业的关键金融支持渠道，但成功率却低得惊人。以前的研究主要集中在基于奖励的众筹，而基于捐赠的平台研究不足。此外，多模态数据(例如文本描述和视觉照片)和动态元素(例如捐赠序列、项目更新和评论)在影响活动成功方面的作用在很大程度上被忽视了。本文介绍了从 GoFundMe 上的14,961个项目收集的基于捐赠的众筹活动的多模式动态数据集 MDCC，它整合了多模式项目信息并捕捉项目动态，从而为分析基于捐赠的众筹活动提供了一个全面的工具。预计该数据集将启发创新方法并促进对项目成功决定因素的理解。我们的初步实验证明了多模式和动态众筹数据在预测基于捐赠的项目成功方面的重要性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MDCC:+A+Multimodal+Dynamic+Dataset+for+Donation-based+Crowdfunding+Campaigns)|0|
|[Causality-guided Graph Learning for Session-based Recommendation](https://doi.org/10.1145/3583780.3614803)|Dianer Yu, Qian Li, Hongzhi Yin, Guandong Xu|University of Queensland, Brisbane, QLD, Australia; University of Technology, Sydney, Sydney, NSW, Australia; Curtin University, Perth, WA, Australia|Session-based recommendation systems (SBRs) aim to capture user preferences over time by taking into account the sequential order of interactions within sessions. One promising approach within this domain is session graph-based recommendation, which leverages graph-based models to represent and analyze user sessions. However, current graph-based methods for SBRs mainly rely on attention or pooling mechanisms that are prone to exploiting shortcut paths and thus lead to suboptimal recommendations. To address this issue, we propose Causality-guided Graph Learning for Session-based Recommendation (CGSR) that is capable of blocking shortcut paths on the session graph and exploring robust causal connections capturing users' true preferences. Specifically, by employing back-door adjustment of causality, we can generate a distilled causal session graph capturing causal relations among items. CGSR then performs high-order aggregation on the distilled graph, incorporating information from various edge types, to estimate the session preference of the user. This enables us to provide more accurate recommendations grounded in causality while offering fine-grained interaction explanations by highlighting influential items in the graph. Extensive experiments on three datasets show the superior performance of CGSR compared to state-of-the-art SBRs.|基于会话的推荐系统(SBRs)旨在通过考虑会话内交互的顺序顺序来获取用户的偏好。这个领域中一个很有前途的方法是基于会话图的推荐，它利用基于图的模型来表示和分析用户会话。然而，目前基于图表的 SBR 方法主要依赖于注意力或汇集机制，这些机制易于利用捷径，从而导致次优建议。为了解决这个问题，我们提出了基于因果关系的会话推荐图学习(CGSR) ，它能够阻塞会话图上的快捷路径，并探索捕捉用户真实偏好的健壮的因果关系。具体来说，通过因果关系的后门调整，我们可以生成一个提取的因果会话图，捕捉项目之间的因果关系。然后 CGSR 对提取的图进行高阶聚合，结合来自各种边缘类型的信息，以估计用户的会话偏好。这使我们能够提供更准确的建议，基于因果关系，同时提供细粒度的交互解释，突出显示图中有影响力的项目。在三个数据集上的大量实验表明，CGSR 的性能优于最先进的 SBR。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causality-guided+Graph+Learning+for+Session-based+Recommendation)|-1|
|[gFOV: A Full-Stack SPARQL Query Optimizer & Plan Visualizer](https://doi.org/10.1145/3583780.3614741)|Yue Pang, Linglin Yang, Lei Zou, M. Tamer Özsu|Peking University, Beijing, China; University of Waterloo, Waterloo, Canada|SPARQL is the standard query language for RDF data. A SPARQL query consists of basic graph patterns (BGPs), which are matched onto the data graph, and graph pattern operators, which specify how to merge the matched results. Despite the prevalence of graph pattern operators in real-world SPARQL workloads, the optimization of SPARQL queries with graph pattern operators has scarcely been studied. We hence propose gFOV, a full-stack SPARQL query optimizer and plan visualizer targeting both BGPs and graph pattern operators. As its basis, we propose a novel BGP-based evaluation tree (BE-tree) plan representation for SPARQL queries that integrates the physical plan for BGPs, which directly accesses the RDF store, and the logical plan for graph pattern operators, which operates on existent results in memory. On top of it, we devise a full-stack cost-based optimization scheme, combining logical and physical plan optimization, that outperforms the state-of-the-art. In the demonstration, we present an interactive interface that explains our optimization scheme and shows its efficiency by visualizing changes in the query plan and allowing the audience to inspect and execute alternative plans.|SPARQL 是 RDF 数据的标准查询语言。SPARQL 查询包括与数据图匹配的基本图形模式(BGP)和指定如何合并匹配结果的图形模式运算符。尽管在实际的 SPARQL 工作负载中普遍使用图形模式算子，但是对于使用图形模式算子优化 SPARQL 查询的研究却很少。因此，我们提出了 gFOV，一个针对 BGP 和图形模式运算符的全栈 SPARQL 查询优化器和计划可视化器。作为其基础，我们提出了一种新的基于 BGP 的 SPARQL 查询计划表示(BE-tree) ，它集成了 BGP 的物理计划(直接访问 RDF 存储)和图模式运算符的逻辑计划(对存储器中已有的结果进行操作)。在此基础上，我们设计了一个基于全堆栈成本的优化方案，将逻辑和物理计划优化相结合，优于最先进的水平。在演示中，我们展示了一个交互式界面，它解释了我们的优化方案，并通过可视化查询计划中的更改来显示其效率，并允许受众检查和执行替代计划。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=gFOV:+A+Full-Stack+SPARQL+Query+Optimizer+&+Plan+Visualizer)|-1|
|[Semantic-aware Node Synthesis for Imbalanced Heterogeneous Information Networks](https://doi.org/10.1145/3583780.3615055)|Xinyi Gao, Wentao Zhang, Tong Chen, Junliang Yu, Nguyen Quoc Viet Hung, Hongzhi Yin|Griffith University, Gold Coast, SEQ, Australia; Peking University, Beijing, China; The University of Queensland, Brisbane, QLD, Australia|Heterogeneous graph neural networks (HGNNs) have exhibited exceptional efficacy in modeling the complex heterogeneity in heterogeneous information networks (HINs). The critical advantage of HGNNs is their ability to handle diverse node and edge types in HINs by extracting and utilizing the abundant semantic information for effective representation learning. However, as a widespread phenomenon in many real-world scenarios, the class-imbalance distribution in HINs creates a performance bottleneck for existing HGNNs. Apart from the quantity imbalance of nodes, another more crucial and distinctive challenge in HINs is semantic imbalance. Minority classes in HINs often lack diverse and sufficient neighbor nodes, resulting in biased and incomplete semantic information. This semantic imbalance further compounds the difficulty of accurately classifying minority nodes, leading to the performance degradation of HGNNs. To tackle the imbalance of minority classes and supplement their inadequate semantics, we present the first method for the semantic imbalance problem in imbalanced HINs named Semantic-aware Node Synthesis (SNS). By assessing the influence on minority classes, SNS adaptively selects the heterogeneous neighbor nodes and augments the network with synthetic nodes while preserving the minority semantics. In addition, we introduce two regularization approaches for HGNNs that constrain the representation of synthetic nodes from both semantic and class perspectives to effectively suppress the potential noises from synthetic nodes, facilitating more expressive embeddings for classification. The comprehensive experimental study demonstrates that SNS consistently outperforms existing methods by a large margin in different benchmark datasets.|异构图神经网络(HGNNs)在异构信息网络(HINs)的复杂异构性建模中表现出了非凡的功效。HGNN 的关键优势在于它们能够通过提取和利用丰富的语义信息来处理 HINs 中不同的节点和边缘类型，从而有效地进行表示学习。然而，作为现实世界中普遍存在的一种现象，HIN 中的类不平衡分布为现有的 HGNN 造成了性能瓶颈。除了节点的数量不平衡外，HIN 中另一个更为关键和独特的挑战是语义不平衡。HIN 中的少数族群往往缺乏多样性和足够的邻居节点，导致偏倚和不完全的语义信息。这种语义不平衡进一步加大了对少数节点进行准确分类的难度，导致 HGNN 的性能下降。为了解决不平衡 HIN 中少数类的语义不平衡问题，并补充其不足的语义，我们提出了第一种解决不平衡 HIN 中语义不平衡问题的方法——语义感知节点合成(SNS)。通过评估对少数族群的影响，SNS 自适应地选择异构邻居节点，在保留少数族群语义的前提下使用合成节点对网络进行扩展。此外，我们还介绍了两种 HGNN 的正则化方法，它们从语义和类的角度约束合成节点的表示，以有效地抑制合成节点的潜在噪声，促进更具表达性的分类嵌入。综合实验研究表明，在不同的基准数据集中，SNS 的性能一直大大优于现有的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Semantic-aware+Node+Synthesis+for+Imbalanced+Heterogeneous+Information+Networks)|-1|
|[Unsupervised Aspect Term Extraction by Integrating Sentence-level Curriculum Learning with Token-level Self-paced Learning](https://doi.org/10.1145/3583780.3615103)|Jihong Ouyang, Zhiyao Yang, Chang Xuan, Bing Wang, Yiyuan Wang, Ximing Li|Northeast Normal University, Changchun, China; Jilin University, Changchun, China|Aspect Term Extraction (ATE), a key sub-task of aspect-based sentiment analysis, aims to extract aspect terms from review sentences on which users express opinions. Existing studies mainly treat ATE as a sequence labeling problem, and the aspect terms of training data are annotated at the token level, such as "BIO'' tagging. However, such fine-grained annotations are often too costly to collect in many real applications, giving rise to the urgent demand for the challenging Unsupervised ATE (UATE). This paper suggests a novel UATE method by integrating sentence-level curriculum learning with token-level self-paced learning, namely UATE-SCTS. We design a set of hand-crafted rules to generate pseudo-labels but with noise. To combat this issue, our key idea is to train the ATE model from easier samples to harder samples to achieve a more robust model with more precise predictions at the early training epochs. This enables better refining of the noisy pseudo-labels. At the sentence level, we propose a frequency-induced pseudo-label cardinality to measure the learning difficulty of the review sentence and train the model in a curriculum-learning manner. At the token level, we formulate a self-paced learning objective that can adaptively select easier samples for training. We compare UATE-SCTS with baseline methods on benchmark collections of reviews from different domains. Empirical results demonstrate that UATE-SCTS can outperform existing UATE baselines.|体词提取(ATE)是基于体词的情感分析的一个关键子任务，旨在从用户表达意见的复习句中提取体词。现有的研究主要将 ATE 作为一个序列标注问题来处理，训练数据的方面术语在标记层次上进行标注，如“ BIO”标注。然而，这样的细粒度注释往往是太昂贵的收集在许多实际应用中，引起了对具有挑战性的无监督 ATE (UATE)的迫切需求。本文提出了一种将句子层次课程学习与表征层次自主学习相结合的 UATE 方法，即 UATE-SCS。我们设计了一组手工制作的规则来生成伪标签，但是带有噪音。为了解决这个问题，我们的关键思想是训练 ATE 模型从更容易的样本到更难的样本，以实现一个更稳健的模型与更精确的预测在早期训练阶段。这样可以更好地精炼嘈杂的伪标签。在句子层面，我们提出了一个频率诱导的伪标记基数来度量复习句的学习难度，并以课程学习的方式训练该模型。在表征层面，我们制定了一个自定步调的学习目标，可以自适应地选择更容易的样本进行训练。我们比较了 UATE-SCT 和基准方法对不同领域的评论的基准收集。实证结果表明，UATE-SCS 的性能优于现有的 UATE 基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unsupervised+Aspect+Term+Extraction+by+Integrating+Sentence-level+Curriculum+Learning+with+Token-level+Self-paced+Learning)|-1|
|[Weak Regression Enhanced Lifelong Learning for Improved Performance and Reduced Training Data](https://doi.org/10.1145/3583780.3615108)|Tong Liu, Xulong Wang, He Huang, Po Yang|Institute of Intelligent Machines, Chinese Academy Of Sciences, Hefei, China; Department of Computer Science, University of Sheffield, Sheffield, United Kingdom|As an emerging learning paradigm, lifelong learning intends to solve multiple consecutive tasks over long-time scales upon previously accumulated knowledge. When facing with a new task, existing lifelong learning approaches need first gather sufficient training data to identify task relationships before knowledge transfer can succeed. However, annotating large number of training data persistently for every coming task is time-consuming, which can be prohibitive for real-world lifelong regression problems. To reduce this burden, we propose to incorporate weak regression into lifelong learning so as to enhance training data and improve predictive performance. Specifically, the weak prediction is first produced by single-task predictor, which is encoded as feature vectors that contain essential prior output information. This weak regression is further linked with task model via coupled dictionary learning. The integration of weak regression and task model can facilitate both cross-task and inter-task knowledge transfer, thus improving the overall performance. More critically, the weak regression can backup the task model especially when there is insufficient training data to construct an accurate model. Three real-world datasets are used to evaluate the effectiveness of our proposed method. Results show that our method outperforms existing lifelong models and single-task models even if training data is minimal.|作为一种新兴的学习范式，终身学习试图在以前积累的知识的基础上，在长时间尺度上解决多个连续的任务。当面对一项新任务时，现有的终身学习方法需要首先收集足够的训练数据，以确定任务关系，然后才能成功地进行知识转移。然而，为每个即将到来的任务持久地注释大量的训练数据是非常耗时的，这对于现实世界中的终身回归问题来说是非常困难的。为了减轻这种负担，我们建议在终身学习中加入弱回归，以增强训练数据，提高预测性能。具体来说，弱预测首先由单任务预测器产生，该预测器被编码为包含必要先验输出信息的特征向量。这种弱回归通过耦合词典学习进一步与任务模型联系起来。弱回归与任务模型的结合可以促进跨任务和跨任务的知识转移，从而提高整体绩效。更关键的是，弱回归可以备份任务模型，特别是当没有足够的训练数据来建立一个准确的模型。利用三个实际数据集对该方法的有效性进行了评估。结果表明，即使训练数据最少，该方法仍优于现有的终身模型和单任务模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Weak+Regression+Enhanced+Lifelong+Learning+for+Improved+Performance+and+Reduced+Training+Data)|-1|
|[Calibrate Graph Neural Networks under Out-of-Distribution Nodes via Deep Q-learning](https://doi.org/10.1145/3583780.3614797)|Weili Shi, Xueying Yang, Xujiang Zhao, Haifeng Chen, Zhiqiang Tao, Sheng Li|University of Virginia, Charlottesville, VA, USA; Santa Clara University, Santa Clara, CA, USA; NEC-Labs, Princeton, NJ, USA; Rochester Institute of Technology, Rochester, NY, USA|Graph neural networks (GNNs) have achieved great success in dealing with graph-structured data that are prevalent in the real world. The core of graph neural networks is the message passing mechanism that aims to generate the embeddings of nodes by aggregating the neighboring node information. However, recent work suggests that GNNs also suffer the trustworthiness issues. Our empirical study shows that the calibration error of the in-distribution (ID) nodes would be exacerbated if a graph is mixed with out-of-distribution (OOD) nodes, and we assume that the noisy information from OOD nodes is the root for the worsened calibration error. Both previous study and our empirical study suggest that adjusting the weights of edges could be a promising way to reduce the adverse impact from the OOD nodes. However, how to precisely select the desired edges and modify the corresponding weights is not trivial, since the distribution of OOD nodes is unknown to us. To tackle this problem, we propose a Graph Edge Re-weighting via Deep Q-learning (GERDQ) framework to calibrate the graph neural networks. Our framework aims to explore the potential influence of the change of the edge weights on target ID nodes by sampling and traversing the edges in the graph, and we formulate this process as a Markov Decision Process (MDP). Many existing GNNs could be seamlessly incorporated into our framework. Experimental results show that when wrapped with our method, the existing GNN models can yield lower calibration error under OOD nodes as well as comparable accuracy compared to the original ones and other strong baselines. The source code is available at:|图形神经网络(GNN)在处理现实世界中普遍存在的图形结构数据方面取得了巨大的成功。图神经网络的核心是消息传递机制，其目的是通过聚合相邻节点的信息来产生节点的嵌入。然而，最近的工作表明，GNN 也遭受信任问题。我们的实证研究表明，当一个图与分布外(OOD)节点混合时，分布内(ID)节点的校准误差将会加剧，并且我们假设来自 OOD 节点的噪声信息是校准误差加剧的根源。以往的研究和我们的实证研究都表明，调整边缘的权重可能是一个有希望的方法，以减少不利的影响从面向对象的节点。然而，如何精确地选择所需的边缘和修改相应的权重是不容易的，因为我们不知道面向对象的节点的分布。为了解决这一问题，我们提出了一种基于深度 Q 学习(GERDQ)的图边重新加权方法来标定图神经网络。我们的框架旨在通过采样和遍历图中的边来探索边权重变化对目标 ID 节点的潜在影响，并将这一过程表述为一个马可夫决策过程(mDP)。许多现有的 GNN 可以无缝地并入到我们的框架中。实验结果表明，与原始模型和其他强基线相比，现有的 GNN 模型在 OOD 节点下可以获得较低的标定误差和可比较的精度。源代码可在以下网址查阅:|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Calibrate+Graph+Neural+Networks+under+Out-of-Distribution+Nodes+via+Deep+Q-learning)|-1|
|[MoCLIM: Towards Accurate Cancer Subtyping via Multi-Omics Contrastive Learning with Omics-Inference Modeling](https://doi.org/10.1145/3583780.3614970)|Ziwei Yang, Zheng Chen, Yasuko Matsubara, Yasushi Sakurai|SANKEN, Osaka University, Osaka, Japan; Bioinformatics Center, Institute for Chemical Research, Kyoto University, Kyoto, Japan|Precision medicine fundamentally aims to establish causality between dysregulated biochemical mechanisms and cancer subtypes. Omics-based cancer subtyping has emerged as a revolutionary approach, as different level of omics records the biochemical products of multistep processes in cancers. This paper focuses on fully exploiting the potential of multi-omics data to improve cancer subtyping outcomes, and hence developed MoCLIM, a representation learning framework. MoCLIM independently extracts the informative features from distinct omics modalities. Using a unified representation informed by contrastive learning of different omics modalities, we can well-cluster the subtypes, given cancer, into a lower latent space. This contrast can be interpreted as a projection of inter-omics inference observed in biological networks. Experimental results on six cancer datasets demonstrate that our approach significantly improves data fit and subtyping performance in fewer high-dimensional cancer instances. Moreover, our framework incorporates various medical evaluations as the final component, providing high interpretability in medical analysis.|精准医学的基本目标是建立失调的生化机制和癌症亚型之间的因果关系。基于组学的癌症分型已经成为一种革命性的方法，因为不同水平的组学记录癌症中多步骤过程的生化产物。本文着重于充分利用多组学数据的潜力，以改善癌症亚型的结果，因此开发了 MoCLIM，一个代表性学习框架。MoCLIM 独立地从不同的组学模式中提取信息特征。通过对不同组学模式的对比学习，使用统一的表示方法，我们可以很好地将给定癌症的亚型聚类到一个较低的潜伏空间。这种对比可以解释为在生物网络中观察到的组间推断的投影。在六个癌症数据集上的实验结果表明，我们的方法在较少的高维癌症实例中显著提高了数据拟合和分型性能。此外，我们的框架整合了各种医疗评价作为最终组成部分，提供了高解释性的医疗分析。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MoCLIM:+Towards+Accurate+Cancer+Subtyping+via+Multi-Omics+Contrastive+Learning+with+Omics-Inference+Modeling)|-1|
|[RLIFE: Remaining Lifespan Prediction for E-scooters](https://doi.org/10.1145/3583780.3615037)|Shuxin Zhong, William Yubeaton, Wenjun Lyu, Guang Wang, Desheng Zhang, Yu Yang|New York University, New York, NY, USA; Lehigh University, Bethlehem, PA, USA; Rutgers University, New Brunswick, NJ, USA; Florida State University, Tallahassee, FL, USA|Shared electric scooters (e-scooters) have been increasingly popular because of their characteristics of convenience and eco-friendliness. Due to their shared nature and widespread usage, e-scooters usually have a short lifespan (e.g., two to five months[2]), which makes it important to predict the remaining lifespan accurately, ensuring timely replacements. While several studies have focused on the lifespan prediction of various systems, such as batteries and bridges, they present a two-fold drawback. Firstly, they require significant manual labor or additional sensor resources to ascertain the explicit status of the object, rendering them cost-ineffective. Secondly, these studies assume that future usage is similar as the historical usage. To solve these limitations, we aim at accurately predicting the remaining lifespan of e-scooters without extra cost, and its essence is to accurately represent its current status and anticipate its future usage. However, it is challenging because: i) lack of explicit rules for the e-scooters' status representation; and ii) e-scooters' future usage may significantly differ from their historical usage. In this paper, we design a framework called RLIFE, whose key insight is modeling user behaviors from trip transactions is of great importance in predicting the Remaining LIFespan of shared E-scooters. Specifically, we introduce an unsupervised contrastive learning component to learn the e-scooters' status representation over time considering degradation, where user preferences are served as a status reflector; We further design an LSTM-based recursive component to dynamically predict uncertain future usage, upon which we fuse the current status and predicted usage of the e-scooter for its remaining lifespan prediction. Extensive experiments are conducted on large-scale, real-world datasets collected from an e-scooter company. It shows that RLIFE improves the baselines by 35.67% and benefits from the learned user preferences and predicted future usage.|共享电动滑板车(e-scooter)因其方便、环保的特点而越来越受到人们的青睐。由于它们的共同性质和广泛使用，电动滑板车通常寿命较短(例如，2至5个月[2]) ，这使得准确预测剩余寿命，确保及时更换非常重要。虽然一些研究集中在各种系统的寿命预测，如电池和桥梁，他们提出了一个双重的缺点。首先，它们需要大量的人工或额外的传感器资源来确定目标的明确状态，从而降低成本。其次，这些研究假设未来的用法与历史上的用法相似。为了解决这些局限性，我们的目标是准确地预测电动滑板车的剩余寿命，而不需要额外的费用，其本质是准确地表示其目前的状态和预测其未来的使用。然而，这是具有挑战性的，因为: i)缺乏明确的规则，电动滑板车的地位表示; 和 ii)电动滑板车的未来使用可能与其历史使用明显不同。在本文中，我们设计了一个名为 RLIFE 的框架，其核心思想是从出行事务中建立用户行为模型，这对于预测共享电动滑板车的剩余寿命非常重要。具体来说，我们引入了一个无监督的对比学习组件来学习电动滑板车的状态表示随着时间的推移考虑退化，其中用户偏好被用作状态反映器; 我们进一步设计了一个基于 LSTM 的递归组件来动态预测不确定的未来使用，在此基础上，我们融合了电动滑板车的当前状态和预测使用寿命预测。广泛的实验进行了大规模，真实世界的数据集收集从电动滑板车公司。结果表明，RLIFE 提高了35.67% 的基线，并且受益于学习到的用户偏好和预测未来的使用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RLIFE:+Remaining+Lifespan+Prediction+for+E-scooters)|-1|
|[Semi-supervised Curriculum Ensemble Learning for Financial Precision Marketing](https://doi.org/10.1145/3583780.3615251)|HsinYu Chen, ChengTe Li, TingYu Chen|National Cheng Kung University, Tainan, Taiwan Roc; Bank SinoPac, Taipei, Taiwan Roc|This paper tackles precision marketing in financial technology, focusing on the accurate prediction of potential customers' interest in specific financial products amidst extreme class imbalance and a significant volume of unlabeled data. We propose the innovative Semi-supervised Curriculum Ensemble (SSCE) framework, which integrates curriculum pseudo-labeling and balanced bagging with tree-based models. This novel approach enables the effective utilization of high-confidence predicted instances from unlabeled data and mitigates the impact of extreme class imbalance. Experiments conducted on a large-scale real-world banking dataset, featuring five financial products, demonstrate that the SSCE consistently outperforms existing methods, thereby promising significant advances in the domain of financial precision marketing.|本文针对金融技术中的精确营销问题，重点在于在极端的等级不平衡和大量未标记数据的情况下，准确预测潜在客户对特定金融产品的兴趣。提出了一种创新的半监督课程集成(SSCE)框架，该框架将课程伪标注和平衡包装与基于树的模型集成在一起。这种新颖的方法能够有效地利用来自未标记数据的高置信度预测实例，并减轻极端类不平衡的影响。在一个以五种金融产品为特征的大规模现实世界银行数据集上进行的实验表明，SSCE 始终优于现有方法，从而有望在金融精确营销领域取得重大进展。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Semi-supervised+Curriculum+Ensemble+Learning+for+Financial+Precision+Marketing)|-1|
|[A Deep Conditional Generative Approach for Constrained Community Detection](https://doi.org/10.1145/3583780.3615145)|Chaobo He, Junwei Cheng, Quanlong Guan, Xiang Fei, Hanchao Li, Yong Tang|Institute for Digital Technologies, Loughborough University, Leicester, United Kingdom; Department of Computing, Coventry University, Coventry, United Kingdom; College of Information Science and Technology, Jinan University, Guangzhou, China; School of Computer Science, South China Normal University, Pazhou Lab, Guangzhou, China; School of Computer Science, South China Normal University, Guangzhou, China|Constrained community detection is one of the popular topics in graph data mining, and it aims to improve the performance by exploiting prior pairwise constraints, such as must-link and cannot-link constraints. However, most of existing methods for constrained community detection are shallow approaches, and are also not robust to handle constraints information with noises. In view of this, we propose a deep conditional generative approach CGMVGAE. It firstly treats pairwise constraints as the priors with different degrees of certainty, and then integrates them into the conditional Gaussian mixture model. By further combing variational graph auto-encoders and the Wasserstein regularization, CGMVGAE can learn the latent node representations preserving community structures in a deep generative manner. Experimental results show that CGMVGAE outperforms state-of-the-art approaches, and is also more robust.|约束社区检测是图形数据挖掘中的热点问题之一，其目的是利用先验的成对约束，如必须链接约束和不能链接约束，提高社区检测的性能。然而，现有的约束群体检测方法大多是浅层检测方法，对于带有噪声的约束信息也不具有鲁棒性。鉴于此，我们提出了一种深度条件生成方法 CGMVGAE。它首先将成对约束作为不同确定度的先验条件，然后将其集成到条件高斯混合模型中。通过进一步结合变分图自动编码器和 Wasserstein 正则化，CGMVGAE 能够以深层生成的方式学习保持群体结构的潜在节点表示。实验结果表明，CGMVGAE 算法的性能优于目前最先进的算法，并且具有更强的鲁棒性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Deep+Conditional+Generative+Approach+for+Constrained+Community+Detection)|-1|
|[Pseudo Triplet Networks for Classification Tasks with Cross-Source Feature Incompleteness](https://doi.org/10.1145/3583780.3615154)|Cayon Liow, ChengTe Li, ChunPai Yang, ShouDe Lin|National Cheng Kung University, Tainan, Taiwan Roc; National Taiwan University, Taipei, Taiwan Roc|Cross-source feature incompleteness -- a scenario where certain features are only available in one data source but missing in another -- is a common and significant challenge in machine learning. It typically arises in situations where the training data and testing data are collected from different sources with distinct feature sets. Addressing this challenge has the potential to greatly improve the utility of valuable datasets that might otherwise be considered incomplete and enhance model performance. This paper introduces the novel Pseudo Triplet Network (PTN) to address cross-source feature incompleteness. PTN fuses two Siamese network architectures -- Triplet Networks and Pseudo Networks. By segregating data into instance, positive, and negative subsets, PTN facilitates effectively contrastive learning through a hybrid loss function design. The model was rigorously evaluated on six benchmark datasets from the UCI Repository, in comparison with five other methods for managing missing data, under a range of feature overlap and missing data scenarios. The PTN consistently exhibited superior performance, displaying resilience in high missing ratio situations and maintaining robust stability across various data scenarios.|跨源特性不完整性——某些特性只在一个数据源中可用，而在另一个数据源中缺失——是机器学习中常见的重大挑战。它通常出现在训练数据和测试数据是从具有不同特征集的不同来源收集的情况下。应对这一挑战有可能大大提高可能被认为不完整的宝贵数据集的效用，并提高模型性能。针对跨源特征不完全性问题，提出了一种新的伪三重网(PTN)算法。PTN 融合了两种连体网络结构——三联网络和伪网络。PTN 通过将数据分为实例子集、正子集和负子集，通过混合损失函数设计有效地促进了对比学习。在一系列特征重叠和缺失数据情景下，对 UCI 知识库的六个基准数据集进行了严格的评估，并与其他五种管理缺失数据的方法进行了比较。PTN 始终表现出优越的性能，在高缺失率情况下显示出弹性，并在各种数据场景中保持稳健的稳定性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pseudo+Triplet+Networks+for+Classification+Tasks+with+Cross-Source+Feature+Incompleteness)|-1|
|[Towards Understanding of Deepfake Videos in the Wild](https://doi.org/10.1145/3583780.3614729)|Beomsang Cho, Binh M. Le, Jiwon Kim, Simon S. Woo, Shahroz Tariq, Alsharif Abuadbba, Kristen Moore|Sungkyunkwan University, Suwon, Republic of Korea; CSIRO's Data61, Sydney, Australia; CSIRO's Data61, Melbourne, Australia|Deepfakes have become a growing concern in recent years, prompting researchers to develop benchmark datasets and detection algorithms to tackle the issue. However, existing datasets suffer from significant drawbacks that hamper their effectiveness. Notably, these datasets fail to encompass the latest deepfake videos produced by state-of-the-art methods that are being shared across various platforms. This limitation impedes the ability to keep pace with the rapid evolution of generative AI techniques employed in real-world deepfake production. Our contributions in this IRB-approved study are to bridge this knowledge gap from current real-world deepfakes by providing in-depth analysis. We first present the largest and most diverse and recent deepfake dataset (RWDF-23) collected from the wild to date, consisting of 2,000 deepfake videos collected from 4 platforms targeting 4 different languages span created from 21 countries: Reddit, YouTube, TikTok, and Bilibili. By expanding the dataset's scope beyond the previous research, we capture a broader range of real-world deepfake content, reflecting the ever-evolving landscape of online platforms. Also, we conduct a comprehensive analysis encompassing various aspects of deepfakes, including creators, manipulation strategies, purposes, and real-world content production methods. This allows us to gain valuable insights into the nuances and characteristics of deepfakes in different contexts. Lastly, in addition to the video content, we also collect viewer comments and interactions, enabling us to explore the engagements of internet users with deepfake content. By considering this rich contextual information, we aim to provide a holistic understanding of the {evolving} deepfake phenomenon and its impact on online platforms.|近年来，Deepfakes 已经成为一个日益令人担忧的问题，促使研究人员开发基准数据集和检测算法来解决这个问题。但是，现有的数据集存在严重的缺陷，妨碍了它们的有效性。值得注意的是，这些数据集未能涵盖最新的深度伪造视频产生的最先进的方法，正在分享各种平台。这种局限性阻碍了生成性人工智能技术在现实世界深度伪造生产中的快速发展。我们在这个 IRB 批准的研究中的贡献是通过提供深入的分析来弥补与现实世界中的深度造假者之间的知识差距。我们首先展示迄今为止从野外收集的最大、最多样化和最新的深度伪造数据集(rWDF-23) ，包括从4个平台收集的2000个深度伪造视频，这些平台针对来自21个国家的4种不同语言: Reddit、 YouTube、 tikTok 和 Bilibili。通过扩大数据集的范围超越以前的研究，我们捕获了更广泛的现实世界深度假内容，反映了不断发展的在线平台景观。此外，我们进行了全面的分析，包括各个方面的深假，包括创作者，操作策略，目的，和现实世界的内容生产方法。这使我们能够获得有价值的洞察深度假的细微差别和特点在不同的背景下。最后，除了视频内容，我们还收集观众的评论和互动，使我们能够探索互联网用户与深度假内容的参与。通过考虑这丰富的上下文信息，我们旨在提供一个整体的理解{演变}深度假现象及其对在线平台的影响。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Understanding+of+Deepfake+Videos+in+the+Wild)|-1|
|[Commonsense Temporal Action Knowledge (CoTAK) Dataset](https://doi.org/10.1145/3583780.3615114)|Steven J. Lynden, Hailemariam Mehari Yohannes, KyoungSook Kim, Adam Jatowt, Akiyoshi Matono, HaiTao Yu, Xin Liu, Yijun Duan|National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; University of Tsukuba, Tsukuba, Japan; University of Innsbruck, Innsbruck, Austria|This paper presents a publicly available, large-scale dataset resource, CoTAK (COmmonsense Temporal Action Knowledge) consisting of short descriptions of action-describing sentences manually annotated with temporal commonsense knowledge. The dataset consists of over 300K instructional sentences extracted from WikiHow, which are annotated with commonsense knowledge-based temporal labels indicating implicitly understood information about the actions described by the sentences, including approximately how long an action takes to perform and approximately how long its effects last for. For short duration actions labeled as taking seconds or minutes, which would be of relevance to automated task planning, e.g. in robotics applications, the dataset also provides scalar values to accurately label the temporal durations of how long actions take to perform. Experimental results are presented demonstrating that state-of-the-art machine learning techniques such as fine-tuning of large language models are effective in making predictions of commonsense temporal knowledge using the dataset, with up to 80% accuracy, showing the high utility and promising impact of the constructed resource and its applicability towards generating commonsense temporal knowledge relevant to various|本文提出了一个公开的、大规模的数据集资源——常识时态行为知识 CoTAK (COmmonsense 颞 al Action Knowledge) ，它包含用时态常识知识手工注释的行为描述句子的简短描述。该数据集包括从 WikiHow 中提取的超过300K 的指导性句子，这些句子被注释为基于常识的时间标签，表明隐含地理解了句子所描述的行为的信息，包括大约多长时间的行为需要执行，以及大约多长时间的影响持续。对于那些被标记为“花费几秒钟或几分钟”的短时间动作，这些动作与自动化任务规划有关，例如在机器人应用中，数据集还提供标量值来准确标记动作执行的时间长度。实验结果表明，最先进的机器学习技术，如大型语言模型的微调，是有效的预测常识时间知识使用数据集，高达80% 的准确率，显示了高效用和有希望的影响构造的资源和它的适用性，生成常识时间知识相关的各种|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Commonsense+Temporal+Action+Knowledge+(CoTAK)+Dataset)|-1|

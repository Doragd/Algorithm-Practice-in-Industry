# RECSYS2025 Paper List

|论文|作者|组织|摘要|翻译|代码|引用数|
|---|---|---|---|---|---|---|
|[Test-Time Alignment with State Space Model for Tracking User Interest Shifts in Sequential Recommendation](https://doi.org/10.1145/3705328.3748060)|Changshuo Zhang, Xiao Zhang, Teng Shi, Jun Xu, JiRong Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Test-Time+Alignment+with+State+Space+Model+for+Tracking+User+Interest+Shifts+in+Sequential+Recommendation)|3|
|[Time to Split: Exploring Data Splitting Strategies for Offline Evaluation of Sequential Recommenders](https://doi.org/10.1145/3705328.3748164)|Danil Gusak, Anna Volodkevich, Anton Klenitskiy, Alexey Vasilev, Evgeny Frolov||Modern sequential recommender systems, ranging from lightweight transformer-based variants to large language models, have become increasingly prominent in academia and industry due to their strong performance in the next-item prediction task. Yet common evaluation protocols for sequential recommendations remain insufficiently developed: they often fail to reflect the corresponding recommendation task accurately, or are not aligned with real-world scenarios. Although the widely used leave-one-out split matches next-item prediction, it permits the overlap between training and test periods, which leads to temporal leakage and unrealistically long test horizon, limiting real-world relevance. Global temporal splitting addresses these issues by evaluating on distinct future periods. However, its applications to sequential recommendations remain loosely defined, particularly in terms of selecting target interactions and constructing a validation subset that provides necessary consistency between validation and test metrics. In this paper, we demonstrate that evaluation outcomes can vary significantly across splitting strategies, influencing model rankings and practical deployment decisions. To improve reproducibility in both academic and industrial settings, we systematically compare different splitting strategies for sequential recommendations across multiple datasets and established baselines. Our findings show that prevalent splits, such as leave-one-out, may be insufficiently aligned with more realistic evaluation strategies. Code: https://github.com/monkey0head/time-to-split|现代序列推荐系统——从基于轻量级Transformer的变体到大型语言模型——因其在下一项预测任务中的优异表现，正日益成为学术界与工业界的焦点。然而当前的序列推荐通用评估方案仍存在明显不足：它们往往无法准确反映对应的推荐任务特性，或与真实应用场景存在偏差。尽管广泛采用的留一法划分与下一项预测任务相匹配，但该方法允许训练集与测试集的时间段重叠，导致时序数据泄露和失真的长测试周期，削弱了实际应用价值。全局时序划分通过评估独立未来时段解决了这些问题，但其在序列推荐中的应用定义仍显松散，特别是在选择目标交互行为及构建能确保验证集与测试集指标一致性的验证子集方面。本文通过实验证明，不同划分策略会导致评估结果显著差异，进而影响模型排序与实际部署决策。为提升学术研究与工业应用的可复现性，我们系统比较了多种数据集和主流基线模型下的序列推荐划分策略。研究结果表明，留一法等主流划分方式与更贴近现实的评估策略存在明显偏差。代码已开源：https://github.com/monkey0head/time-to-split|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Time+to+Split:+Exploring+Data+Splitting+Strategies+for+Offline+Evaluation+of+Sequential+Recommenders)|2|
|[The Future is Sparse: Embedding Compression for Scalable Retrieval in Recommender Systems](https://doi.org/10.1145/3705328.3748147)|Petr Kasalický, Martin Spisák, Vojtech Vancura, Daniel Bohunek, Rodrigo Alves, Pavel Kordík||Industry-scale recommender systems face a core challenge: representing entities with high cardinality, such as users or items, using dense embeddings that must be accessible during both training and inference. However, as embedding sizes grow, memory constraints make storage and access increasingly difficult. We describe a lightweight, learnable embedding compression technique that projects dense embeddings into a high-dimensional, sparsely activated space. Designed for retrieval tasks, our method reduces memory requirements while preserving retrieval performance, enabling scalable deployment under strict resource constraints. Our results demonstrate that leveraging sparsity is a promising approach for improving the efficiency of large-scale recommenders. We release our code at https://github.com/recombee/CompresSAE.|工业级推荐系统面临一个核心挑战：如何用稠密嵌入表示高基数实体（如用户或商品），且这些嵌入需在训练和推理阶段均可访问。然而随着嵌入维度增长，内存限制使得存储与访问日益困难。我们提出一种轻量级可学习的嵌入压缩技术，将稠密嵌入投影到高维稀疏激活空间。该方法专为检索任务设计，在保持检索性能的同时显著降低内存需求，实现在严格资源约束下的可扩展部署。实验结果表明，利用稀疏性是提升大规模推荐系统效率的有效途径。代码已发布于 https://github.com/recombee/CompresSAE。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Future+is+Sparse:+Embedding+Compression+for+Scalable+Retrieval+in+Recommender+Systems)|1|
|[Fashion-AlterEval: A Dataset for Improved Evaluation of Conversational Recommendation Systems with Alternative Relevant Items](https://doi.org/10.1145/3705328.3748149)|Maria Vlachou||In Conversational Recommendation Systems (CRS), a user provides feedback on recommended items at each turn, leading the CRS towards improved recommendations. Due to the need for a large amount of data, a user simulator is employed for both training and evaluation. Such user simulators critique the current retrieved item based on knowledge of a single target item. However, system evaluation in offline settings with simulators is limited by the focus on a single target item and their unlimited patience over a large number of turns. To overcome these limitations of existing simulators, we propose Fashion-AlterEval, a new dataset that contains human judgments for a selection of alternative items by adding new annotations in common fashion CRS datasets. Consequently, we propose two novel meta-user simulators that use the collected judgments and allow simulated users not only to express their preferences about alternative items to their original target, but also to change their mind and level of patience. In our experiments using the Shoes and Fashion IQ as the original datasets and three CRS models, we find that using the knowledge of alternatives by the simulator can have a considerable impact on the evaluation of existing CRS models, specifically that the existing single-target evaluation underestimates their effectiveness, and when simulatedusers are allowed to instead consider alternative relevant items, the system can rapidly respond to more quickly satisfy the user.|在对话推荐系统（CRS）中，用户会在每个交互轮次对推荐项目提供反馈，从而引导系统持续优化推荐效果。由于需要大量数据支撑，用户模拟器被广泛应用于训练和评估环节。现有模拟器通常基于单一目标项目的认知对当前检索到的项目进行评价。然而，这种基于单一目标项目且允许无限轮次交互的离线评估方式存在明显局限。为突破现有模拟器的限制，我们提出Fashion-AlterEval数据集——通过在常见时尚对话推荐数据集上新增标注，构建包含人类对备选项目判断的全新数据集。基于此，我们进一步设计了两类新型元用户模拟器：这些模拟器不仅能利用收集到的判断数据表达对原始目标项目之外其他备选项目的偏好，还支持模拟用户改变心意并调整其耐心阈值。在以Shoes和Fashion IQ作为原始数据集、采用三种CRS模型的实验中，我们发现模拟器引入备选项目认知会对现有CRS模型评估产生显著影响——具体表现为：传统单一目标评估方式会低估系统效能，而当模拟用户被允许考虑其他相关备选项目时，系统能更快响应并满足用户需求。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fashion-AlterEval:+A+Dataset+for+Improved+Evaluation+of+Conversational+Recommendation+Systems+with+Alternative+Relevant+Items)|1|
|[Enhancing Embedding Representation Stability in Recommendation Systems with Semantic ID](https://doi.org/10.1145/3705328.3748123)|Carolina Zheng, Minhui Huang, Dmitrii Pedchenko, Kaushik Rangadurai, Siyu Wang, Fan Xia, Gaby Nahum, Jie Lei, Yang Yang, Tao Liu, Zutian Luo, Xiaohan Wei, Dinesh Ramasamy, Jiyan Yang, Yiping Han, Lin Yang, Hangjun Xu, Rong Jin, Shuang Yang||The exponential growth of online content has posed significant challenges to ID-based models in industrial recommendation systems, ranging from extremely high cardinality and dynamically growing ID space, to highly skewed engagement distributions, to prediction instability as a result of natural id life cycles (e.g, the birth of new IDs and retirement of old IDs). To address these issues, many systems rely on random hashing to handle the id space and control the corresponding model parameters (i.e embedding table). However, this approach introduces data pollution from multiple ids sharing the same embedding, leading to degraded model performance and embedding representation instability. This paper examines these challenges and introduces Semantic ID prefix ngram, a novel token parameterization technique that significantly improves the performance of the original Semantic ID. Semantic ID prefix ngram creates semantically meaningful collisions by hierarchically clustering items based on their content embeddings, as opposed to random assignments. Through extensive experimentation, we demonstrate that Semantic ID prefix ngram not only addresses embedding instability but also significantly improves tail id modeling, reduces overfitting, and mitigates representation shifts. We further highlight the advantages of Semantic ID prefix ngram in attention-based models that contextualize user histories, showing substantial performance improvements. We also report our experience of integrating Semantic ID into Meta production Ads Ranking system, leading to notable performance gains and enhanced prediction stability in live deployments.|在线内容的指数级增长给工业推荐系统中的ID类模型带来重大挑战：包括极高的特征维度、动态扩张的ID空间、高度倾斜的交互分布，以及因ID自然生命周期（如新ID产生和旧ID淘汰）导致的预测不稳定。为应对这些问题，现有系统多采用随机哈希处理ID空间并控制相应模型参数（即嵌入表）。然而这种方法会因多个ID共享同一嵌入向量引发数据污染，导致模型性能下降和嵌入表示不稳定。本文系统剖析这些挑战后，提出语义ID前缀n元组——一种创新的令牌参数化技术，能显著提升原始语义ID的性能。该技术通过基于内容嵌入的层次化聚类实现有语义意义的碰撞，取代随机分配机制。大量实验表明，语义ID前缀n元组不仅能解决嵌入不稳定问题，还可显著改善尾部ID建模、减少过拟合现象并缓解表示偏移。我们进一步揭示了该技术在基于注意力的用户历史上下文模型中优势，展现出显著的性能提升。文中还分享了将语义ID集成至Meta广告排序生产系统的实践经验，在线上部署中实现了显著效果提升和预测稳定性增强。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Embedding+Representation+Stability+in+Recommendation+Systems+with+Semantic+ID)|1|
|[Exploring the Effect of Context-Awareness and Popularity Calibration on Popularity Bias in POI Recommendations](https://doi.org/10.1145/3705328.3748017)|Andrea Forster, Simone Kopeinik, Denis Helic, Stefan Thalmann, Dominik Kowald||Point-of-interest (POI) recommender systems help users discover relevant locations, but their effectiveness is often compromised by popularity bias, which disadvantages less popular, yet potentially meaningful places. This paper addresses this challenge by evaluating the effectiveness of context-aware models and calibrated popularity techniques as strategies for mitigating popularity bias. Using four real-world POI datasets (Brightkite, Foursquare, Gowalla, and Yelp), we analyze the individual and combined effects of these approaches on recommendation accuracy and popularity bias. Our results reveal that context-aware models cannot be considered a uniform solution, as the models studied exhibit divergent impacts on accuracy and bias. In contrast, calibration techniques can effectively align recommendation popularity with user preferences, provided there is a careful balance between accuracy and bias mitigation. Notably, the combination of calibration and context-awareness yields recommendations that balance accuracy and close alignment with the users' popularity profiles, i.e., popularity calibration.|兴趣点（POI）推荐系统虽能帮助用户发现相关地点，但其有效性常受流行度偏差的影响——那些知名度较低却可能具有独特价值的地点往往被系统忽视。本文通过评估情境感知模型与校准化流行度技术这两种缓解流行度偏差的策略，对该问题展开深入研究。基于四个真实世界POI数据集（Brightkite、Foursquare、Gowalla和Yelp），我们分析了这些方法对推荐准确性和流行度偏差的独立及联合影响。研究结果表明：情境感知模型不能被视为通用解决方案，因为不同模型对准确性与偏差的影响存在显著差异；相比之下，校准技术若能精准平衡准确性提升与偏差缓解，则可有效使推荐内容的流行度与用户偏好相匹配。值得注意的是，将校准技术与情境感知相结合，能够生成既保证准确性又与用户流行度偏好高度契合的推荐结果，即实现流行度校准。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+the+Effect+of+Context-Awareness+and+Popularity+Calibration+on+Popularity+Bias+in+POI+Recommendations)|1|
|[Impacts of Mainstream-Driven Algorithms on Recommendations for Children Across Domains: A Reproducibility Study](https://doi.org/10.1145/3705328.3748160)|Robin Ungruh, Alejandro Bellogín, Dominik Kowald, Maria Soledad Pera||Children are often exposed to items curated by recommendation algorithms. Yet, research seldom considers children as a user group, and when it does, it is anchored on datasets where children are underrepresented, risking overlooking their interests, favoring those of the majority, i.e., mainstream users. Recently, Ungruh et al. demonstrated that children's consumption patterns and preferences differ from those of mainstream users, resulting in inconsistent recommendation algorithm performance and behavior for this user group. These findings, however, are based on two datasets with a limited child user sample. We reproduce and replicate this study on a wider range of datasets in the movie, music, and book domains, uncovering interaction patterns and aspects of child-recommender interactions consistent across domains, as well as those specific to some user samples in the data. We also extend insights from the original study with popularity bias metrics, given the interpretation of results from the original study. With this reproduction and extension, we uncover consumption patterns and differences between age groups stemming from intrinsic differences between children and others, and those unique to specific datasets or domains.|儿童常接触到由推荐算法筛选的内容，然而相关研究很少将儿童视为特定用户群体。即便涉及该群体，也往往基于儿童样本不足的数据集，这可能导致忽视儿童兴趣、偏向主流用户需求的风险。近期Ungruh等人的研究表明，儿童的消费模式与偏好区别于主流用户，导致推荐算法在该群体上表现出不一致的性能与行为。但该结论仅基于两个儿童用户样本有限的数据集。我们在电影、音乐和图书领域的多个数据集上复现并拓展了此项研究，发现了跨领域一致的儿童-推荐系统交互模式特征，以及特定用户样本中的独有现象。基于原研究的结果解读，我们还通过流行度偏差指标延伸了研究视角。通过复现与拓展，我们揭示了源自儿童与其他群体本质差异的消费模式及年龄组差异，以及特定数据集或领域中的独特现象。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Impacts+of+Mainstream-Driven+Algorithms+on+Recommendations+for+Children+Across+Domains:+A+Reproducibility+Study)|1|
|[Affect-aware Cross-Domain Recommendation for Art Therapy via Music Preference Elicitation](https://doi.org/10.1145/3705328.3748084)|Bereket Abera Yilma, Luis A. Leiva||Art Therapy (AT) is an established practice that facilitates emotional processing and recovery through creative expression. Recently, Visual Art Recommender Systems (VA RecSys) have emerged to support AT, demonstrating their potential by personalizing therapeutic artwork recommendations. Nonetheless, current VA RecSys rely on visual stimuli for user modeling, limiting their ability to capture the full spectrum of emotional responses during preference elicitation. Previous studies have shown that music stimuli elicit unique affective reflections, presenting an opportunity for cross-domain recommendation (CDR) to enhance personalization in AT. Since CDR has not yet been explored in this context, we propose a family of CDR methods for AT based on music-driven preference elicitation. A large-scale study with 200 users demonstrates the efficacy of music-driven preference elicitation, outperforming the classic visual-only elicitation approach. Our source code, data, and models are available at https://github.com/ArtAICare/Affect-aware-CDR|艺术疗法（AT）作为一门成熟的专业实践，通过创造性表达促进情绪处理与心理康复。近年来，视觉艺术推荐系统（VA RecSys）开始应用于辅助艺术治疗，其通过个性化推荐治疗性艺术作品展现出巨大潜力。然而，现有VA RecSys在用户建模时仅依赖视觉刺激，导致在偏好获取过程中难以全面捕捉用户的情感反应。已有研究表明，音乐刺激能引发独特的情感共鸣，这为利用跨域推荐（CDR）技术提升艺术疗法个性化水平提供了新思路。鉴于该领域尚未有CDR相关研究，我们提出了一套基于音乐驱动偏好获取的跨域推荐方法体系。一项涉及200名用户的大规模研究证实，音乐驱动的偏好获取方法显著优于传统的纯视觉获取方式。相关源代码、数据及模型已开源：https://github.com/ArtAICare/Affect-aware-CDR|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Affect-aware+Cross-Domain+Recommendation+for+Art+Therapy+via+Music+Preference+Elicitation)|1|
|[A Language Model-Based Playlist Generation Recommender System](https://doi.org/10.1145/3705328.3748053)|Enzo CharoloisPasqua, Eléa Vellard, Youssra Rebboud, Pasquale Lisena, Raphaël Troncy||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Language+Model-Based+Playlist+Generation+Recommender+System)|1|
|[D-RDW: Diversity-Driven Random Walks for News Recommender Systems](https://doi.org/10.1145/3705328.3748016)|Runze Li, Lucien Heitz, Oana Inel, Abraham Bernstein||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=D-RDW:+Diversity-Driven+Random+Walks+for+News+Recommender+Systems)|1|
|[Counterfactual Inference under Thompson Sampling](https://doi.org/10.1145/3705328.3748011)|Olivier Jeunen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Counterfactual+Inference+under+Thompson+Sampling)|1|
|[Scaling Retrieval for Web-Scale Recommenders: Lessons from Inverted Indexes to Embedding Search](https://doi.org/10.1145/3705328.3748116)|Yuchin Juan, Jianqiang Shen, Shaobo Zhang, Qianqi Shen, Caleb Johnson, Luke Simon, Liangjie Hong, Wenjing Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scaling+Retrieval+for+Web-Scale+Recommenders:+Lessons+from+Inverted+Indexes+to+Embedding+Search)|0|
|[Contrastive Conditional Embeddings for Item-based Recommendation at E-commerce Scale](https://doi.org/10.1145/3705328.3748095)|Akira Fukumoto, Aghiles Salah, Sarthak Shrivastava, Alexandru Tatar, Yannick Schwartz, Vincent Michel, Lee Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Conditional+Embeddings+for+Item-based+Recommendation+at+E-commerce+Scale)|0|
|[Beyond Immediate Click: Engagement-Aware and MoE-Enhanced Transformers for Sequential Movie Recommendation](https://doi.org/10.1145/3705328.3748076)|Haotian Jiang, Sibendu Paul, Haiyang Zhang, Caren Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Immediate+Click:+Engagement-Aware+and+MoE-Enhanced+Transformers+for+Sequential+Movie+Recommendation)|0|
|[GenSAR: Unifying Balanced Search and Recommendation with Generative Retrieval](https://doi.org/10.1145/3705328.3748071)|Teng Shi, Jun Xu, Xiao Zhang, Xiaoxue Zang, Kai Zheng, Yang Song, Enyun Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GenSAR:+Unifying+Balanced+Search+and+Recommendation+with+Generative+Retrieval)|0|
|[Do We Really Need Specialization? Evaluating Generalist Text Embeddings for Zero-Shot Recommendation and Search](https://doi.org/10.1145/3705328.3748040)|Matteo Attimonelli, Alessandro De Bellis, Claudio Pomo, Dietmar Jannach, Eugenio Di Sciascio, Tommaso Di Noia||Pre-trained language models (PLMs) are widely used to derive semantic representations from item metadata in recommendation and search. In sequential recommendation, PLMs enhance ID-based embeddings through textual metadata, while in product search, they align item characteristics with user intent. Recent studies suggest task and domain-specific fine-tuning are needed to improve representational power. This paper challenges this assumption, showing that Generalist Text Embedding Models (GTEs), pre-trained on large-scale corpora, can guarantee strong zero-shot performance without specialized adaptation. Our experiments demonstrate that GTEs outperform traditional and fine-tuned models in both sequential recommendation and product search. We attribute this to a superior representational power, as they distribute features more evenly across the embedding space. Finally, we show that compressing embedding dimensions by focusing on the most informative directions (e.g., via PCA) effectively reduces noise and improves the performance of specialized models. To ensure reproducibility, we provide our repository at https://split.to/gte4ps.|预训练语言模型（PLM）在推荐和搜索系统中被广泛用于从物品元数据中提取语义表示。在序列推荐任务中，PLM通过文本元数据增强基于ID的嵌入表示；而在商品搜索场景中，它们将物品特性与用户意图进行对齐。现有研究通常认为需要通过任务和领域特定的微调来提升表征能力。本文对此假设提出挑战，证明在大规模语料上预训练的通用文本嵌入模型（GTE）无需专门适配即可保证强大的零样本性能。实验结果表明，GTE在序列推荐和商品搜索任务中均优于传统模型及微调模型。我们将其归因于更优越的表征能力——这些模型能将特征更均匀地分布在嵌入空间中。最后，我们证实通过聚焦信息量最大的方向（如主成分分析法）压缩嵌入维度，可有效降低噪声并提升专用模型性能。为保障可复现性，我们已在 https://split.to/gte4ps 公开代码库。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Do+We+Really+Need+Specialization?+Evaluating+Generalist+Text+Embeddings+for+Zero-Shot+Recommendation+and+Search)|0|
|[Determinants of Users' Chance-Seeking Behavior in Search-Based Recommendation](https://doi.org/10.1145/3705328.3748019)|Yuki Ninomiya, Yutaro Sone, Kazuhisa Miwa, Yuichiro Sumi, Ryosuke Nakanishi, Eiji Mitsuda, Koji Sato, Tadashi Odashima||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Determinants+of+Users'+Chance-Seeking+Behavior+in+Search-Based+Recommendation)|0|
|[Improve the Personalization of Large-Scale Ranking Systems by Integrating User Survey Feedback](https://doi.org/10.1145/3705328.3748119)|Mengxi Lv, Drew Hogg, Thomas Grubb, Shashank Bassi, Min Li, Cayman Simpson, Senthil Rajagopalan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improve+the+Personalization+of+Large-Scale+Ranking+Systems+by+Integrating+User+Survey+Feedback)|0|
|[User Long-Term Multi-Interest Retrieval Model for Recommendation](https://doi.org/10.1145/3705328.3748107)|Yue Meng, Cheng Guo, Xiaohui Hu, Honghu Deng, Yi Cao, Tong Liu, Bo Zheng||User behavior sequence modeling, which captures user interest from rich historical interactions, is pivotal for industrial recommendation systems. Despite breakthroughs in ranking-stage models capable of leveraging ultra-long behavior sequences with length scaling up to thousands, existing retrieval models remain constrained to sequences of hundreds of behaviors due to two main challenges. One is strict latency budget imposed by real-time service over large-scale candidate pool. The other is the absence of target-aware mechanisms and cross-interaction architectures, which prevent utilizing ranking-like techniques to simplify long sequence modeling. To address these limitations, we propose a new framework named User Long-term Multi-Interest Retrieval Model(ULIM), which enables thousand-scale behavior modeling in retrieval stages. ULIM includes two novel components: 1)Category-Aware Hierarchical Dual-Interest Learning partitions long behavior sequences into multiple category-aware subsequences representing multi-interest and jointly optimizes long-term and short-term interests within specific interest cluster. 2)Pointer-Enhanced Cascaded Category-to-Item Retrieval introduces Pointer-Generator Interest Network(PGIN) for next-category prediction, followed by next-item retrieval upon the top-K predicted categories. Comprehensive experiments on Taobao dataset show that ULIM achieves substantial improvement over state-of-the-art methods, and brings 5.54|用户行为序列建模通过丰富的历史交互捕捉用户兴趣，对工业推荐系统至关重要。尽管排序阶段模型已实现突破，能够处理长度高达数千的超长行为序列，但现有召回模型仍受限于数百长度的序列，主要面临两大挑战：一是大规模候选池实时服务的严格延迟限制；二是缺乏目标感知机制和交叉交互架构，导致无法采用类排序技术简化长序列建模。为解决这些局限，我们提出名为用户长期多兴趣召回模型（ULIM）的新框架，可在召回阶段实现千级行为序列建模。该框架包含两大创新模块：1）类别感知分层双兴趣学习——将长行为序列划分为多个表征多兴趣的类别感知子序列，在特定兴趣簇内联合优化长期与短期兴趣；2）指针增强级联类别-物品召回——通过指针生成器兴趣网络（PGIN）预测下一类别，继而基于预测的Top-K类别进行下一物品召回。在淘宝数据集上的综合实验表明，ULIM相较现有最优方法实现显著提升，并带来5.54%的核心指标增益。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=User+Long-Term+Multi-Interest+Retrieval+Model+for+Recommendation)|0|
|[LLM-RecG: A Semantic Bias-Aware Framework for Zero-Shot Sequential Recommendation](https://doi.org/10.1145/3705328.3748077)|Yunzhe Li, Junting Wang, Hari Sundaram, Zhining Liu||Zero-shot cross-domain sequential recommendation (ZCDSR) enables predictions in unseen domains without additional training or fine-tuning, addressing the limitations of traditional models in sparse data environments. Recent advancements in large language models (LLMs) have significantly enhanced ZCDSR by facilitating cross-domain knowledge transfer through rich, pretrained representations. Despite this progress, domain semantic bias – arising from differences in vocabulary and content focus between domains – remains a persistent challenge, leading to misaligned item embeddings and reduced generalization across domains. To address this, we propose a novel semantic bias-aware framework that enhances LLM-based ZCDSR by improving cross-domain alignment at both the item and sequential levels. At the item level, we introduce a generalization loss that aligns the embeddings of items across domains (inter-domain compactness), while preserving the unique characteristics of each item within its own domain (intra-domain diversity). This ensures that item embeddings can be transferred effectively between domains without collapsing into overly generic or uniform representations. At the sequential level, we develop a method to transfer user behavioral patterns by clustering source domain user sequences and applying attention-based aggregation during target domain inference. We dynamically adapt user embeddings to unseen domains, enabling effective zero-shot recommendations without requiring target-domain interactions...|零样本跨域序列推荐（ZCDSR）能够在无需额外训练或微调的情况下对未知领域进行预测，从而解决传统模型在稀疏数据环境中的局限性。大型语言模型（LLM）的最新进展通过预训练的丰富表征促进跨领域知识迁移，显著提升了ZCDSR的性能。尽管取得这些进展，领域语义偏差——源自不同领域间词汇表与内容聚焦点的差异——仍是持续存在的挑战，会导致项目嵌入失准及跨域泛化能力下降。为此，我们提出一种新颖的语义偏差感知框架，通过在项目级和序列级同时增强跨域对齐来改进基于LLM的ZCDSR。在项目级别，我们引入泛化损失函数，既实现跨域项目嵌入的对齐（域间紧致性），又保持各项目在其所属领域内的独特性（域内多样性）。这确保项目嵌入能在领域间有效迁移，而不会坍缩为过度通用或单一的表征。在序列级别，我们开发了通过聚类源域用户序列并在目标域推理时采用基于注意力的聚合方法，实现用户行为模式的迁移。通过动态适应用户嵌入至未知领域，我们的方法无需目标域交互即可实现有效的零样本推荐...|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LLM-RecG:+A+Semantic+Bias-Aware+Framework+for+Zero-Shot+Sequential+Recommendation)|0|
|[Disentangling User and Item Sequence Patterns in Sequential Recommendation Data Sets](https://doi.org/10.1145/3705328.3748042)|Kaiyue Liu, Yang Liu, Alan Medlar, Dorota Glowacka||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Disentangling+User+and+Item+Sequence+Patterns+in+Sequential+Recommendation+Data+Sets)|0|
|[Let It Go? Not Quite: Addressing Item Cold Start in Sequential Recommendations with Content-Based Initialization](https://doi.org/10.1145/3705328.3748038)|Anton Pembek, Artem Fatkulin, Anton Klenitskiy, Alexey Vasilev||Many sequential recommender systems suffer from the cold start problem, where items with few or no interactions cannot be effectively used by the model due to the absence of a trained embedding. Content-based approaches, which leverage item metadata, are commonly used in such scenarios. One possible way is to use embeddings derived from content features such as textual descriptions as initialization for the model embeddings. However, directly using frozen content embeddings often results in suboptimal performance, as they may not fully adapt to the recommendation task. On the other hand, fine-tuning these embeddings can degrade performance for cold-start items, as item representations may drift far from their original structure after training. We propose a novel approach to address this limitation. Instead of entirely freezing the content embeddings or fine-tuning them extensively, we introduce a small trainable delta to frozen embeddings that enables the model to adapt item representations without letting them go too far from their original semantic structure. This approach demonstrates consistent improvements across multiple datasets and modalities, including e-commerce datasets with textual descriptions and a music dataset with audio-based representation.|许多序列推荐系统存在冷启动问题——由于缺乏训练嵌入向量，交互数据稀少或缺失的物品难以被模型有效利用。基于内容的方法（利用物品元数据）是此类场景的常用解决方案。一种可行方案是使用文本描述等内容特征生成的嵌入向量作为模型嵌入的初始化值。但直接冻结内容嵌入向量通常会导致次优效果，因为它们可能无法完全适应推荐任务；而对这些嵌入进行微调又可能损害冷启动物品的表现，因为训练后物品表征会偏离原始语义结构。针对这一局限，我们提出创新解决方案：既不完全冻结内容嵌入，也不进行大规模微调，而是在冻结嵌入基础上引入可训练的微小增量，使模型既能适配物品表征，又不会过度偏离其原始语义结构。该方法在多个数据集和模态中均展现出稳定提升，包括含文本描述的电商数据集和基于音频表征的音乐数据集。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Let+It+Go?+Not+Quite:+Addressing+Item+Cold+Start+in+Sequential+Recommendations+with+Content-Based+Initialization)|0|
|[DistillRecDial: A Knowledge-Distilled Dataset Capturing User Diversity in Conversational Recommendation](https://doi.org/10.1145/3705328.3748161)|Alessandro Francesco Maria Martina, Alessandro Petruzzelli, Cataldo Musto, Marco de Gemmis, Pasquale Lops, Giovanni Semeraro||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DistillRecDial:+A+Knowledge-Distilled+Dataset+Capturing+User+Diversity+in+Conversational+Recommendation)|0|
|[In-context Learning for Addressing User Cold-start in Sequential Movie Recommenders](https://doi.org/10.1145/3705328.3748109)|Xurong Liang, Vu Nguyen, Vuong Le, Paul Albert, Julien Monteil||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=In-context+Learning+for+Addressing+User+Cold-start+in+Sequential+Movie+Recommenders)|0|
|[Leveraging Explicit Negative Feedback in Large-Scale Recommendation Systems: A Case Study](https://doi.org/10.1145/3705328.3748145)|Madhura Raju, Manisha Sharma, Hongyu Xiong, Bingfeng Deng, Meng Na||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Explicit+Negative+Feedback+in+Large-Scale+Recommendation+Systems:+A+Case+Study)|0|
|[IP2: Entity-Guided Interest Probing for Personalized News Recommendation](https://doi.org/10.1145/3705328.3748091)|Youlin Wu, Yuanyuan Sun, Xiaokun Zhang, Haoxi Zhan, Bo Xu, Liang Yang, Hongfei Lin||News recommender systems aim to provide personalized news reading experiences for users based on their reading history. Behavioral science studies suggest that screen-based news reading contains three successive steps: scanning, title reading, and then clicking. Adhering to these steps, we find that intra-news entity interest dominates the scanning stage, while the inter-news entity interest guides title reading and influences click decisions. Unfortunately, current methods overlook the unique utility of entities in news recommendation. To this end, we propose a novel method called IP2 to probe entity-guided reading interest at both intra- and inter-news levels. At the intra-news level, a Transformer-based entity encoder is devised to aggregate mentioned entities in the news title into one signature entity. Then, a signature entity-title contrastive pre-training is adopted to initialize entities with proper meanings using the news story context, which in the meantime facilitates us to probe for intra-news entity interest. As for the inter-news level, a dual tower user encoder is presented to capture inter-news reading interest from both the title meaning and entity sides. In addition to highlighting the contribution of inter-news entity guidance, a cross-tower attention link is adopted to calibrate title reading interest using inter-news entity interest, thus further aligning with real-world behavior. Extensive experiments on two real-world datasets demonstrate that our IP2 achieves state-of-the-art performance in news recommendation.|新闻推荐系统旨在基于用户的阅读历史，提供个性化的新闻阅读体验。行为科学研究表明，基于屏幕的新闻阅读包含三个连续步骤：扫描浏览、标题阅读和点击行为。通过分析这些步骤，我们发现新闻内部实体兴趣主导扫描阶段，而跨新闻实体兴趣则引导标题阅读并影响点击决策。然而现有方法忽视了实体在新闻推荐中的独特作用。为此，我们提出名为IP2的创新方法，在新闻内与跨新闻两个层面探究实体引导的阅读兴趣。在新闻内层面，设计基于Transformer的实体编码器，将新闻标题中提及的实体聚合为签名实体；采用签名实体-标题对比预训练，通过新闻故事上下文初始化具有准确语义的实体，同时助力新闻内实体兴趣的探测。在跨新闻层面，提出双塔式用户编码器，从标题语义和实体两个维度捕捉跨新闻阅读兴趣。除突显跨新闻实体引导的贡献外，采用跨塔注意力链接机制，通过跨新闻实体兴趣校准标题阅读兴趣，从而进一步贴合真实用户行为。在两个真实数据集上的大量实验表明，我们的IP2方法在新闻推荐任务中实现了最先进的性能表现。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=IP2:+Entity-Guided+Interest+Probing+for+Personalized+News+Recommendation)|0|
|[LEAF: Lightweight, Efficient, Adaptive and Flexible Embedding for Large-Scale Recommendation Models](https://doi.org/10.1145/3705328.3748078)|Chaoyi Jiang, Abdulla Alshabanah, Murali Annavaram||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LEAF:+Lightweight,+Efficient,+Adaptive+and+Flexible+Embedding+for+Large-Scale+Recommendation+Models)|0|
|[Collaborative Interest Modeling in Recommender Systems](https://doi.org/10.1145/3705328.3748023)|YuTing Cheng, YuYen Ho, JyunYu Jiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Collaborative+Interest+Modeling+in+Recommender+Systems)|0|
|["We Share Our Code Online": Why This Is Not Enough to Ensure Reproducibility and Progress in Recommender Systems Research](https://doi.org/10.1145/3705328.3748157)|Faisal Shehzad, Timo Breuer, Maria Maistro, Dietmar Jannach||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q="We+Share+Our+Code+Online":+Why+This+Is+Not+Enough+to+Ensure+Reproducibility+and+Progress+in+Recommender+Systems+Research)|0|
|[Yambda-5B - A Large-Scale Multi-Modal Dataset for Ranking and Retrieval](https://doi.org/10.1145/3705328.3748163)|Alexander Ploshkin, Vladislav Tytskiy, Alexey Pismenny, Vladimir Baikalov, Evgeny Taychinov, Artem Permiakov, Daniil Burlakov, Eugene Krofto||We present Yambda-5B, a large-scale open dataset sourced from the Yandex.Music streaming platform. Yambda-5B contains 4.79 billion user-item interactions from 1 million users across 9.39 million tracks. The dataset includes two primary types of interactions: implicit feedback (listening events) and explicit feedback (likes, dislikes, unlikes and undislikes). In addition, we provide audio embeddings for most tracks, generated by a convolutional neural network trained on audio spectrograms. A key distinguishing feature of Yambda-5B is the inclusion of the is_organic flag, which separates organic user actions from recommendation-driven events. This distinction is critical for developing and evaluating machine learning algorithms, as Yandex.Music relies on recommender systems to personalize track selection for users. To support rigorous benchmarking, we introduce an evaluation protocol based on a Global Temporal Split, allowing recommendation algorithms to be assessed in conditions that closely mirror real-world use. We report benchmark results for standard baselines (ItemKNN, iALS) and advanced models (SANSA, SASRec) using a variety of evaluation metrics. By releasing Yambda-5B to the community, we aim to provide a readily accessible, industrial-scale resource to advance research, foster innovation, and promote reproducible results in recommender systems.|我们正式发布Yambda-5B数据集——一个源自Yandex.Music流媒体平台的大规模开放数据集。该数据集包含来自100万用户与939万条音轨之间的47.9亿次用户-项目交互记录，涵盖两种主要交互类型：隐式反馈（收听行为）和显式反馈（喜欢/不喜欢/取消喜欢/取消不喜欢）。此外，我们为多数音轨提供了基于频谱图训练的卷积神经网络所生成的音频嵌入向量。Yambda-5B的核心特色在于引入is_organic标志位，可区分用户自发行为与推荐系统驱动的事件——这一特性对机器学习算法的开发与评估至关重要，因为Yandex.Music正是依赖推荐系统来实现个性化音轨推送。为支持严谨的基准测试，我们设计了基于全局时间分割的评估方案，使推荐算法能在高度模拟真实场景的条件下进行评估。通过多种评估指标，我们报告了经典基线模型（ItemKNN、iALS）与先进模型（SANSA、SASRec）的基准性能。我们希望通过开放Yambda-5B数据集，为推荐系统领域提供一个易于获取的工业级资源，以推动前沿研究、促进技术创新，并增强研究成果的可复现性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Yambda-5B+-+A+Large-Scale+Multi-Modal+Dataset+for+Ranking+and+Retrieval)|0|
|[An Analysis of Learned Product Embeddings in an E-Commerce Context](https://doi.org/10.1145/3705328.3748131)|Mate Hartstein, Eva Giannatou, Martin Tegner||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Analysis+of+Learned+Product+Embeddings+in+an+E-Commerce+Context)|0|
|[Decoupled Entity Representation Learning for Pinterest Ads Ranking](https://doi.org/10.1145/3705328.3748098)|Jie Liu, Yinrui Li, Jiankai Sun, Kungang Li, Han Sun, Sihan Wang, Huasen Wu, Siyuan Gao, Paulo Soares, Nan Li, Zhifang Liu, Haoyang Li, Siping Ji, Ling Leng, Prathibha Deshikachar||In this paper, we introduce a novel framework following an upstream-downstream paradigm to construct user and item (Pin) embeddings from diverse data sources, which are essential for Pinterest to deliver personalized Pins and ads effectively. Our upstream models are trained on extensive data sources featuring varied signals, utilizing complex architectures to capture intricate relationships between users and Pins on Pinterest. To ensure scalability of the upstream models, entity embeddings are learned, and regularly refreshed, rather than real-time computation, allowing for asynchronous interaction between the upstream and downstream models. These embeddings are then integrated as input features in numerous downstream tasks, including ad retrieval and ranking models for CTR and CVR predictions. We demonstrate that our framework achieves notable performance improvements in both offline and online settings across various downstream tasks. This framework has been deployed in Pinterest's production ad ranking systems, resulting in significant gains in online metrics.|本文提出了一种遵循上游-下游范式的新型框架，通过整合多源数据构建用户与内容图钉（Pin）的嵌入表示，这对Pinterest实现个性化内容推送与广告精准分发起着关键作用。我们的上游模型基于海量多信号数据源进行训练，采用复杂架构以捕捉平台中用户与图钉间的深层关联。为确保模型可扩展性，系统通过定期更新学习实体嵌入向量，而非实时计算，从而实现上下游模型的异步协同。这些嵌入向量作为核心特征被集成至多个下游任务中，包括广告召回机制以及基于CTR（点击通过率）与CVR（转化率）预测的排序模型。实验表明，该框架在各类下游任务的离线测试与在线部署中均取得显著性能提升。目前该框架已部署于Pinterest生产级广告排序系统，并带来关键线上指标的实质性增长。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Decoupled+Entity+Representation+Learning+for+Pinterest+Ads+Ranking)|0|
|[Deep Reinforcement Learning for Ranking Utility Tuning in the Ad Recommender System at Pinterest](https://doi.org/10.1145/3705328.3748144)|Xiao Yang, Mehdi Ayed, Longyu Zhao, Fan Zhou, Yuchen Shen, Abe Engle, Jinfeng Zhuang, Ling Leng, Jiajing Xu, Charles Rosenberg, Prathibha Deshikachar||The ranking utility function in an ad recommender system, which linearly combines predictions of various business goals, plays a central role in balancing values across the platform, advertisers, and users. Traditional manual tuning, while offering simplicity and interpretability, often yields suboptimal results due to its unprincipled tuning objectives, the vast amount of parameter combinations, and its lack of personalization and adaptability to seasonality. In this work, we propose a general Deep Reinforcement Learning framework for Personalized Utility Tuning (DRL-PUT) to address the challenges of multi-objective optimization within ad recommender systems. Our key contributions include: 1) Formulating the problem as a reinforcement learning task: given the state of an ad request, we predict the optimal hyperparameters to maximize a pre-defined reward. 2) Developing an approach to directly learn an optimal policy model using online serving logs, avoiding the need to estimate a value function, which is inherently challenging due to the high variance and unbalanced distribution of immediate rewards. We evaluated DRL-PUT through an online A/B experiment in Pinterest's ad recommender system. Compared to the baseline manual utility tuning approach, DRL-PUT improved the click-through rate by 9.7|广告推荐系统中的排序效用函数通过线性组合多个业务目标的预测值，在平衡平台、广告主和用户价值方面起着核心作用。传统人工调参方法虽然具有简洁性和可解释性，但由于其调参目标缺乏理论依据、参数组合空间庞大，且无法实现个性化与季节性适应，往往导致结果欠优。本研究提出一种基于深度强化学习的个性化效用调参通用框架（DRL-PUT），以解决广告推荐系统中的多目标优化挑战。我们的核心贡献包括：1）将问题构建为强化学习任务：根据广告请求状态预测最优超参数，以最大化预设奖励；2）开发直接通过在线服务日志学习最优策略模型的方法，避免因即时奖励高方差和分布不均衡而难以进行价值函数估计的问题。通过在Pinterest广告推荐系统中进行在线A/B实验评估，与基线人工调参方法相比，DRL-PUT将点击率提升9.7%|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Reinforcement+Learning+for+Ranking+Utility+Tuning+in+the+Ad+Recommender+System+at+Pinterest)|0|
|[RankGraph: Unified Heterogeneous Graph Learning for Cross-Domain Recommendation](https://doi.org/10.1145/3705328.3748118)|Renzhi Wu, Junjie Yang, Li Chen, Hong Li, Li Yu, Hong Yan||Cross-domain recommendation systems face the challenge of integrating fine-grained user and item relationships across various product domains. To address this, we introduce RankGraph, a scalable graph learning framework designed to serve as a core component in recommendation foundation models (FMs). By constructing and leveraging graphs composed of heterogeneous nodes and edges across multiple products, RankGraph enables the integration of complex relationships between users, posts, ads, and other entities. Our framework employs a GPU-accelerated Graph Neural Network and contrastive learning, allowing for dynamic extraction of subgraphs such as item-item and user-user graphs to support similarity-based retrieval and real-time clustering. Furthermore, RankGraph integrates graph-based pretrained representations as contextual tokens into FM sequence models, enriching them with structured relational knowledge. RankGraph has demonstrated improvements in click (+0.92|跨领域推荐系统面临整合不同产品领域中细粒度用户与物品关系的挑战。为此，我们提出RankGraph——一个可扩展的图学习框架，旨在作为推荐基础模型的核心组件。通过构建并利用跨多个产品的异构节点与边构成的图结构，RankGraph能够整合用户、帖子、广告等实体间的复杂关系。该框架采用GPU加速的图神经网络与对比学习技术，可动态提取物品-物品图、用户-用户图等子图，以支持基于相似性的检索与实时聚类。此外，RankGraph将基于图的预训练表征作为上下文标记融入基础模型序列，通过结构化关系知识增强模型表达能力。实验表明，RankGraph在点击率（+0.92%）等关键指标上实现显著提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RankGraph:+Unified+Heterogeneous+Graph+Learning+for+Cross-Domain+Recommendation)|0|
|[Unified Survey Modeling to Limit Negative User Experiences in Recommendation Systems](https://doi.org/10.1145/3705328.3748108)|Chenghui Yu, Haoze Wu, Jian Ding, Bingfeng Deng, Hongyu Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unified+Survey+Modeling+to+Limit+Negative+User+Experiences+in+Recommendation+Systems)|0|
|[USD: A User-Intent-Driven Sampling and Dual-Debiasing Framework for Large-Scale Homepage Recommendations](https://doi.org/10.1145/3705328.3748096)|Jiaqi Zheng, Cheng Guo, Yi Cao, Chaoqun Hou, Tong Liu, Bo Zheng||Large-scale homepage recommendations face critical challenges from pseudo-negative samples caused by exposure bias, where non-clicks may indicate inattention rather than disinterest. Existing work lacks thorough analysis of invalid exposures and typically addresses isolated aspects (e.g., sampling strategies), overlooking the critical impact of pseudo-positive samples - such as homepage clicks merely to visit marketing portals. We propose a unified framework for large-scale homepage recommendation sampling and debiasing. Our framework consists of two key components: (1) a user intent-aware negative sampling module to filter invalid exposure samples, and (2) an intent-driven dual-debiasing module that jointly corrects exposure bias and click bias. Extensive online experiments on Taobao demonstrate the efficacy of our framework, achieving significant improvements in user click-through rates (UCTR) by 35.4% and 14.5% in two variants of the marketing block on the Taobao homepage, Baiyibutie and Taobaomiaosha.|大规模首页推荐面临曝光偏差导致的伪负样本关键挑战——用户未点击可能源于未注意到内容而非缺乏兴趣。现有研究缺乏对无效曝光的深入分析，通常仅解决局部问题（如采样策略），忽视了伪正样本的关键影响（例如用户点击首页仅为了访问营销入口）。我们提出一个统一的大规模首页推荐采样与去偏框架，该框架包含两个核心组件：（1）用户意图感知负采样模块，用于过滤无效曝光样本；（2）意图驱动的双重去偏模块，联合修正曝光偏差与点击偏差。在淘宝平台进行的在线实验表明，我们的框架在首页营销板块“百亿补贴”和“淘宝秒杀”的两个变体中，用户点击率分别实现35.4%和14.5%的显著提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=USD:+A+User-Intent-Driven+Sampling+and+Dual-Debiasing+Framework+for+Large-Scale+Homepage+Recommendations)|0|
|[You Say Search, I Say Recs: A Scalable Agentic Approach to Query Understanding and Exploratory Search at Spotify](https://doi.org/10.1145/3705328.3748127)|Enrico Palumbo, Marcus Isaksson, Alexandre Tamborrino, Maria Movin, Catalin Dincu, Ali Vardasbi, Lev Nikeshkin, Oksana Gorobets, Anders Nyman, Poppy Newdick, Hugues Bouchard, Paul N. Bennett, Mounia Lalmas, Dani Doro, Christine Doig Cardet, Ziad Sultan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=You+Say+Search,+I+Say+Recs:+A+Scalable+Agentic+Approach+to+Query+Understanding+and+Exploratory+Search+at+Spotify)|0|
|[Benefiting from Negative yet Informative Feedback by Contrasting Opposing Sequential Patterns](https://doi.org/10.1145/3705328.3759333)|Veronika Ivanova, Evgeny Frolov, Alexey Vasilev||We consider the task of learning from both positive and negative feedback in a sequential recommendation scenario, as both types of feedback are often present in user interactions. Meanwhile, conventional sequential learning models usually focus on considering and predicting positive interactions, ignoring that reducing items with negative feedback in recommendations improves user satisfaction with the service. Moreover, the negative feedback can potentially provide a useful signal for more accurate identification of true user interests. In this work, we propose to train two transformer encoders on separate positive and negative interaction sequences. We incorporate both types of feedback into the training objective of the sequential recommender using a composite loss function that includes positive and negative cross-entropy as well as a cleverly crafted contrastive term, that helps better modeling opposing patterns. We demonstrate the effectiveness of this approach in terms of increasing true-positive metrics compared to state-of-the-art sequential recommendation methods while reducing the number of wrongly promoted negative items.|在序列化推荐场景中，我们研究如何同时利用正负反馈进行学习，因为这两种反馈类型常同时存在于用户交互中。传统序列学习模型通常侧重于考量和预测正向交互，却忽略了减少负反馈项目的推荐能够有效提升用户对服务的满意度。此外，负反馈可能为更精准识别用户真实兴趣提供重要信号。本研究提出分别使用两个Transformer编码器对正向与负向交互序列进行训练。我们通过融合正负向交叉熵损失函数与精心设计的对比项，构建复合损失目标将两种反馈类型纳入序列推荐器的训练体系，该对比项有助于更好地建模对立模式。实验证明，相较于最先进的序列推荐方法，该方案在提升真阳性指标的同时，能有效减少错误推荐的负向项目数量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Benefiting+from+Negative+yet+Informative+Feedback+by+Contrasting+Opposing+Sequential+Patterns)|0|
|[Beyond Clicks: Eye-Tracking Insights into User Responses to Different Recommendation Types](https://doi.org/10.1145/3705328.3759304)|Georgios Koutroumpas, Matteo Mazzini, Sebastian Idesis, Mireia Masias Bruns, Joemon M. Jose, Sergi Abadal, Ioannis Arapakis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Clicks:+Eye-Tracking+Insights+into+User+Responses+to+Different+Recommendation+Types)|0|
|[Semantic IDs for Joint Generative Search and Recommendation](https://doi.org/10.1145/3705328.3759300)|Gustavo Penha, Edoardo D'Amico, Marco De Nadai, Enrico Palumbo, Alexandre Tamborrino, Ali Vardasbi, Max Lefarov, Shawn Lin, Timothy Christopher Heath, Francesco Fabbri, Hugues Bouchard||Generative models powered by Large Language Models (LLMs) are emerging as a unified solution for powering both recommendation and search tasks. A key design choice in these models is how to represent items, traditionally through unique identifiers (IDs) and more recently with Semantic IDs composed of discrete codes, obtained from embeddings. While task-specific embedding models can improve performance for individual tasks, they may not generalize well in a joint setting. In this paper, we explore how to construct Semantic IDs that perform well both in search and recommendation when using a unified model. We compare a range of strategies to construct Semantic IDs, looking into task-specific and cross-tasks approaches, and also whether each task should have its own semantic ID tokens in a joint search and recommendation generative model. Our results show that using a bi-encoder model fine-tuned on both search and recommendation tasks to obtain item embeddings, followed by the construction of a unified Semantic ID space provides an effective trade-off, enabling strong performance in both tasks. We hope these findings spark follow-up work on generalisable, semantically grounded ID schemes and inform the next wave of unified generative recommender architectures.|基于大语言模型（LLM）的生成式模型正逐渐成为支持推荐与搜索任务的统一解决方案。这些模型的核心设计在于如何表征物品：传统方法采用唯一标识符（ID），而近期则使用通过嵌入向量获得的离散码组成的语义ID。虽然针对特定任务的嵌入模型可以提升单项任务性能，但在联合场景中可能泛化能力不足。本文探索了如何在使用统一模型时构建能同时胜任搜索与推荐任务的语义ID。我们比较了多种语义ID构建策略，包括任务专用与跨任务方法，并研究了在联合搜索推荐生成模型中是否应为各任务分配独立语义ID标记。实验结果表明：通过使用经搜索和推荐任务联合微调的双编码器模型获取物品嵌入，继而构建统一语义ID空间，能够在两项任务中实现强劲性能的有效平衡。我们希望这些发现能推动关于可泛化、语义化ID方案的后续研究，并为新一代统一生成式推荐架构提供设计依据。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Semantic+IDs+for+Joint+Generative+Search+and+Recommendation)|0|
|[Unobserved Negative Items in Recommender Systems: Challenges and Solutions for Evaluation and Learning](https://doi.org/10.1145/3705328.3759315)|Masahiro Sato||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unobserved+Negative+Items+in+Recommender+Systems:+Challenges+and+Solutions+for+Evaluation+and+Learning)|0|
|[VisualReF: Interactive Image Search Prototype with Visual Relevance Feedback](https://doi.org/10.1145/3705328.3759341)|Bulat Khaertdinov, Mirela Popa, Nava Tintarev||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=VisualReF:+Interactive+Image+Search+Prototype+with+Visual+Relevance+Feedback)|0|
|[Advancing User-Centric Evaluation and Design of Conversational Recommender Systems](https://doi.org/10.1145/3705328.3748759)|Michael Müller||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Advancing+User-Centric+Evaluation+and+Design+of+Conversational+Recommender+Systems)|0|
|[A Multi-Factor Collaborative Prediction for Review-based Recommendation](https://doi.org/10.1145/3705328.3748062)|Junrui Liu, Tong Li, Mingliang Yu, Shiqiu Yang, Zifang Tang, Zhen Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Multi-Factor+Collaborative+Prediction+for+Review-based+Recommendation)|0|
|[Enhancing Sequential Recommender with Large Language Models for Joint Video and Comment Recommendation](https://doi.org/10.1145/3705328.3748075)|Bowen Zheng, Zihan Lin, Enze Liu, Chen Yang, Enyang Bai, Cheng Ling, Han Li, Wayne Xin Zhao, JiRong Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Sequential+Recommender+with+Large+Language+Models+for+Joint+Video+and+Comment+Recommendation)|0|
|[Mapping Stakeholder Needs to Multi-Sided Fairness in Candidate Recommendation for Algorithmic Hiring](https://doi.org/10.1145/3705328.3748079)|Mesut Kaya, Toine Bogers||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mapping+Stakeholder+Needs+to+Multi-Sided+Fairness+in+Candidate+Recommendation+for+Algorithmic+Hiring)|0|
|[Modeling Long-term User Behaviors with Diffusion-driven Multi-interest Network for CTR Prediction](https://doi.org/10.1145/3705328.3748045)|Weijiang Lai, Beihong Jin, Yapeng Zhang, Yiyuan Zheng, Rui Zhao, Jian Dong, Jun Lei, Xingxing Wang||CTR (Click-Through Rate) prediction, crucial for recommender systems and online advertising, etc., has been confirmed to benefit from modeling long-term user behaviors. Nonetheless, the vast number of behaviors and complexity of noise interference pose challenges to prediction efficiency and effectiveness. Recent solutions have evolved from single-stage models to two-stage models. However, current two-stage models often filter out significant information, resulting in an inability to capture diverse user interests and build the complete latent space of user interests. Inspired by multi-interest and generative modeling, we propose DiffuMIN (Diffusion-driven Multi-Interest Network) to model long-term user behaviors and thoroughly explore the user interest space. Specifically, we propose a target-oriented multi-interest extraction method that begins by orthogonally decomposing the target to obtain interest channels. This is followed by modeling the relationships between interest channels and user behaviors to disentangle and extract multiple user interests. We then adopt a diffusion module guided by contextual interests and interest channels, which anchor users' personalized and target-oriented interest types, enabling the generation of augmented interests that align with the latent spaces of user interests, thereby further exploring restricted interest space. Finally, we leverage contrastive learning to ensure that the generated augmented interests align with users' genuine preferences. Extensive offline experiments are conducted on two public datasets and one industrial dataset, yielding results that demonstrate the superiority of DiffuMIN. Moreover, DiffuMIN increased CTR by 1.52|点击率预测在推荐系统和在线广告等领域至关重要，现有研究证实其对长期用户行为建模具有显著效益。然而，海量行为数据与复杂噪声干扰对预测效率和效果构成挑战。近期解决方案已从单阶段模型演进至两阶段模型，但现有两阶段模型往往过滤掉重要信息，导致无法捕捉多元用户兴趣并构建完整的用户兴趣隐空间。受多兴趣建模与生成式建模的启发，我们提出DiffuMIN（扩散驱动多兴趣网络）来建模长期用户行为并深入探索用户兴趣空间。具体而言，我们提出目标导向的多兴趣提取方法：首先通过正交分解目标来获取兴趣通道，继而建模兴趣通道与用户行为间的关联以解耦并提取多重用户兴趣。随后采用基于上下文兴趣和兴趣通道的扩散模块，锚定用户的个性化目标导向兴趣类型，生成符合用户兴趣隐空间的增强兴趣，从而进一步探索受限兴趣空间。最后，我们通过对比学习确保生成的增强兴趣与用户真实偏好保持一致。在两个公共数据集和一个工业数据集上的大量离线实验表明，DiffuMIN具有显著优越性。此外，该模型在实际应用中使点击率提升1.52%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modeling+Long-term+User+Behaviors+with+Diffusion-driven+Multi-interest+Network+for+CTR+Prediction)|0|
|[MoRE: A Mixture of Reflectors Framework for Large Language Model-Based Sequential Recommendation](https://doi.org/10.1145/3705328.3748055)|Weicong Qin, Yi Xu, Weijie Yu, Chenglei Shen, Xiao Zhang, Ming He, Jianping Fan, Jun Xu||Large language models (LLMs) have emerged as a cutting-edge approach in sequential recommendation, leveraging historical interactions to model dynamic user preferences. Current methods mainly focus on learning processed recommendation data in the form of sequence-to-sequence text. While effective, they exhibit three key limitations: 1) failing to decouple intra-user explicit features (e.g., product titles) from implicit behavioral patterns (e.g., brand loyalty) within interaction histories; 2) underutilizing cross-user collaborative filtering (CF) signals; and 3) relying on inefficient reflection update strategies. To address this, We propose MoRE (Mixture of REflectors), which introduces three perspective-aware offline reflection processes to address these gaps. This decomposition directly resolves Challenges 1 (explicit/implicit ambiguity) and 2 (CF underutilization). Furthermore, MoRE's meta-reflector employs a self-improving strategy and a dynamic selection mechanism (Challenge 3) to adapt to evolving user preferences. First, two intra-user reflectors decouple explicit and implicit patterns from a user's interaction sequence, mimicking traditional recommender systems' ability to distinguish surface-level and latent preferences. A third cross-user reflector captures CF signals by analyzing user similarity patterns from multiple users' interactions. To optimize reflection quality, MoRE's meta-reflector employs a offline self-improving strategy that evaluates reflection impacts through comparisons of presence/absence and iterative refinement of old/new versions, with a online contextual bandit mechanism dynamically selecting the optimal perspective for recommendation for each user. Code: https://github.com/E-qin/MoRE-Rec.|大型语言模型作为序列推荐领域的前沿方法，通过利用历史交互行为来建模动态用户偏好。现有方法主要侧重于学习以序列到序列文本形式处理的推荐数据。虽然有效，但这些方法存在三个关键局限：1）未能从交互历史中解耦用户内部显性特征（如商品标题）与隐性行为模式（如品牌忠诚度）；2）未能充分利用跨用户协同过滤信号；3）依赖低效的反射更新策略。为此，我们提出MoRE（混合反射器），通过引入三个视角感知的离线反射流程来解决上述问题。这种解耦设计直接解决了挑战1（显性/隐性特征模糊）和挑战2（协同过滤利用不足）。此外，MoRE的元反射器采用自我优化策略和动态选择机制（挑战3）来适应不断演变的用户偏好。具体而言，两个用户内部反射器从用户交互序列中解耦显性与隐性模式，模拟传统推荐系统区分表层偏好与潜在偏好的能力；第三个跨用户反射器通过分析多用户交互中的相似性模式来捕捉协同过滤信号。为优化反射质量，MoRE的元反射器采用离线自我优化策略，通过存在/缺失对比和新旧版本迭代优化来评估反射效果，并配备在线情境赌博机机制为每位用户动态选择最佳推荐视角。代码地址：https://github.com/E-qin/MoRE-Rec。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MoRE:+A+Mixture+of+Reflectors+Framework+for+Large+Language+Model-Based+Sequential+Recommendation)|0|
|[Non-parametric Graph Convolution for Re-ranking in Recommendation Systems](https://doi.org/10.1145/3705328.3748058)|Zhongyu Ouyang, Mingxuan Ju, Soroush Vosoughi, Yanfang Ye||Graph knowledge has been proven effective in enhancing item rankings in recommender systems (RecSys), particularly during the retrieval stage. However, its application in the ranking stage, especially when richer contextual information in user-item interactions is available, remains underexplored. A major challenge lies in the substantial computational cost associated with repeatedly retrieving neighborhood information from billions of items stored in distributed systems. This resource-intensive requirement makes it difficult to scale graph-based methods in practical RecSys. To bridge this gap, we first demonstrate that incorporating graphs in the ranking stage improves ranking qualities. Notably, while the improvement is evident, we show that the substantial computational overheads entailed by graphs are prohibitively expensive for real-world recommendations. In light of this, we propose a non-parametric strategy that utilizes graph convolution for re-ranking only during test time. Our strategy circumvents the notorious computational overheads from graph convolution during training, and utilizes structural knowledge hidden in graphs on-the-fly during testing. It can be used as a plug-and-play module and easily employed to enhance the ranking ability of various ranking layers of a real-world RecSys with significantly reduced computational overhead. Through comprehensive experiments across four benchmark datasets with varying levels of sparsity, we demonstrate that our strategy yields noticeable improvements (i.e., 8.1|图知识已被证实能有效提升推荐系统（RecSys）中的物品排序效果，尤其在召回阶段表现突出。然而在排序阶段，特别是当用户-物品交互中包含更丰富的上下文信息时，图知识的应用仍待探索。主要挑战在于从分布式系统中存储的数十亿物品中重复获取邻域信息会产生巨大计算成本。这种资源密集型需求使得基于图的方法在实际推荐系统中难以规模化应用。为弥补这一空白，我们首先验证了在排序阶段引入图知识能提升排序质量。值得注意的是，虽然改进效果明显，但我们发现图方法带来的巨大计算开销在实际推荐场景中难以承受。基于此，我们提出一种非参数化策略，仅在测试阶段使用图卷积进行重排序。该策略在训练阶段规避了图卷积 notorious 的计算开销，并在测试阶段动态利用图中隐含的结构知识。该模块可作为即插即用组件，显著降低计算开销的同时，轻松增强实际推荐系统中各类排序层的排序能力。通过在四个具有不同稀疏度的基准数据集上进行综合实验，我们证明该策略可带来显著提升（即8.1%）。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Non-parametric+Graph+Convolution+for+Re-ranking+in+Recommendation+Systems)|0|
|[Off-Policy Evaluation of Candidate Generators in Two-Stage Recommender Systems](https://doi.org/10.1145/3705328.3748057)|Peiyao Wang, Zhan Shi, Amina Shabbeer, Ben London||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Off-Policy+Evaluation+of+Candidate+Generators+in+Two-Stage+Recommender+Systems)|0|
|[Paragon: Parameter Generation for Controllable Multi-Task Recommendation](https://doi.org/10.1145/3705328.3748069)|Chenglei Shen, Jiahao Zhao, Xiao Zhang, Weijie Yu, Ming He, Jianping Fan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Paragon:+Parameter+Generation+for+Controllable+Multi-Task+Recommendation)|0|
|[USB-Rec: An Effective Framework for Improving Conversational Recommendation Capability of Large Language Model](https://doi.org/10.1145/3705328.3748089)|Jianyu Wen, Jingyun Wang, Cilin Yan, Jiayin Cai, Xiaolong Jiang, Ying Zhang||Recently, Large Language Models (LLMs) have been widely employed in Conversational Recommender Systems (CRSs). Unlike traditional language model approaches that focus on training, all existing LLMs-based approaches are mainly centered around how to leverage the summarization and analysis capabilities of LLMs while ignoring the issue of training. Therefore, in this work, we propose an integrated training-inference framework, User-Simulator-Based framework (USB-Rec), for improving the performance of LLMs in conversational recommendation at the model level. Firstly, we design a LLM-based Preference Optimization (PO) dataset construction strategy for RL training, which helps the LLMs understand the strategies and methods in conversational recommendation. Secondly, we propose a Self-Enhancement Strategy (SES) at the inference stage to further exploit the conversational recommendation potential obtained from RL training. Extensive experiments on various datasets demonstrate that our method consistently outperforms previous state-of-the-art methods.|近年来，大语言模型（LLMs）在对话推荐系统（CRSs）中得到广泛应用。与传统聚焦于训练过程的语言模型方法不同，现有基于LLM的方法主要围绕如何利用其总结分析能力展开，而忽视了模型训练环节。为此，我们提出一种融合训练与推理的集成框架——用户模拟器框架（USB-Rec），从模型层面提升LLM在对话推荐任务中的性能。首先，我们设计了基于LLM的偏好优化数据集构建策略，用于强化学习训练，帮助LLM深入理解对话推荐中的策略与方法；其次，在推理阶段提出自增强策略，进一步释放通过强化学习获得的对话推荐潜力。在多组数据集上的大量实验表明，我们的方法始终优于以往最先进的模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=USB-Rec:+An+Effective+Framework+for+Improving+Conversational+Recommendation+Capability+of+Large+Language+Model)|0|
|[VL-CLIP: Enhancing Multimodal Recommendations via Visual Grounding and LLM-Augmented CLIP Embeddings](https://doi.org/10.1145/3705328.3748064)|Ramin Giahi, Kehui Yao, Sriram Kollipara, Kai Zhao, Vahid Mirjalili, Jianpeng Xu, Topojoy Biswas, Evren Körpeoglu, Kannan Achan||Multimodal learning plays a critical role in e-commerce recommendation platforms today, enabling accurate recommendations and product understanding. However, existing vision-language models, such as CLIP, face key challenges in e-commerce recommendation systems: 1) Weak object-level alignment, where global image embeddings fail to capture fine-grained product attributes, leading to suboptimal retrieval performance; 2) Ambiguous textual representations, where product descriptions often lack contextual clarity, affecting cross-modal matching; and 3) Domain mismatch, as generic vision-language models may not generalize well to e-commerce-specific data. To address these limitations, we propose a framework, VL-CLIP, that enhances CLIP embeddings by integrating Visual Grounding for fine-grained visual understanding and an LLM-based agent for generating enriched text embeddings. Visual Grounding refines image representations by localizing key products, while the LLM agent enhances textual features by disambiguating product descriptions. Our approach significantly improves retrieval accuracy, multimodal retrieval effectiveness, and recommendation quality across tens of millions of items on one of the largest e-commerce platforms in the U.S., increasing CTR by 18.6|多模态学习在当今电商推荐平台中扮演着关键角色，能够实现精准推荐和商品理解。然而现有视觉语言模型（如CLIP）在电商推荐系统中面临三大挑战：1）弱对象级对齐——全局图像嵌入难以捕捉细粒度商品属性，导致检索效果欠佳；2）文本表征模糊——商品描述常缺乏上下文清晰度，影响跨模态匹配；3）领域失配——通用视觉语言模型难以适配电商特定数据。为突破这些局限，我们提出VL-CLIP框架，通过整合视觉定位技术实现细粒度视觉理解，并采用基于大语言模型的智能体生成增强文本嵌入。视觉定位通过定位关键商品优化图像表征，而大语言模型智能体通过消除商品描述歧义来增强文本特征。该方案在美国某头部电商平台的数千万商品数据上显著提升了检索精度、多模态检索效能及推荐质量，点击率提升达18.6%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=VL-CLIP:+Enhancing+Multimodal+Recommendations+via+Visual+Grounding+and+LLM-Augmented+CLIP+Embeddings)|0|
|["Beyond the past": Leveraging Audio and Human Memory for Sequential Music Recommendation](https://doi.org/10.1145/3705328.3748018)|VietAnh Tran, Bruno Sguerra, Gabriel MeseguerBrocal, Léa Briand, Manuel Moussallam||On music streaming services, listening sessions are often composed of a balance of familiar and new tracks. Recently, sequential recommender systems have adopted cognitive-informed approaches, such as Adaptive Control of Thought-Rational (ACT-R), to successfully improve the prediction of the most relevant tracks for the next user session. However, one limitation of using a model inspired by human memory (or the past), is that it struggles to recommend new tracks that users have not previously listened to. To bridge this gap, here we propose a model that leverages audio information to predict in advance the ACT-R-like activation of new tracks and incorporates them into the recommendation scoring process. We demonstrate the empirical effectiveness of the proposed model using proprietary data, which we publicly release along with the model's source code to foster future research in this field.|在音乐流媒体服务中，用户收听会话通常由熟悉曲目与新曲目共同构成。近期，序列推荐系统开始采用认知启发方法（例如理性自适应控制理论ACT-R），成功提升了对下一用户会话中最相关曲目的预测能力。然而，这类受人类记忆（或过往经历）启发的模型存在一个局限：难以推荐用户未曾听过的新曲目。为弥补这一不足，本文提出一种创新模型：通过音频信息预先预测新曲目的类ACT-R激活值，并将其纳入推荐评分体系。基于专有数据的实证研究表明，该模型具有显著效能。我们已将数据集与模型源代码公开发布，以推动该领域的后续研究。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q="Beyond+the+past":+Leveraging+Audio+and+Human+Memory+for+Sequential+Music+Recommendation)|0|
|[Failure Prediction in Conversational Recommendation Systems](https://doi.org/10.1145/3705328.3748043)|Maria Vlachou||In a Conversational Image Recommendation task, users can provide natural language feedback on a recommended image item, which leads to an improved recommendation in the next turn. While typical instantiations of this task assume that the user's target item will (eventually) be returned, this might often not be true, for example, the item the user seeks is not within the item catalogue. Failing to return a user's desired item can lead to user frustration, as the user needs to interact with the system for an increased number of turns. To mitigate this issue, in this paper, we introduce the task of Supervised Conversational Performance Prediction, inspired by Query Performance Prediction (QPP) for predicting effectiveness in response to a search engine query. In this regard, we propose predictors for conversational performance that detect conversation failures using multi-turn semantic information contained in the embedded representations of retrieved image items. Specifically, our AutoEncoder-based predictor learns a compressed representation of top-retrieved items of the train turns and uses the classification labels to predict the evaluation turn. Our evaluation scenario addressed two recommendation scenarios, by differentiating between system failure, where the system is unable to find the target, and catalogue failure, where the target does not exist in the item catalogue. In our experiments using the Shoes and FashionIQ Dresses datasets, we measure the accuracy of predictors for both system and catalogue failures. Our results demonstrate the promise of our proposed predictors for predicting system failures (existing evaluation scenario), while we detect a considerable decrease in predictive performance in the case of catalogue failure prediction (when inducing a missing item scenario) compared to system failures.|在会话式图像推荐任务中，用户可对推荐图像项目提供自然语言反馈，从而在下一轮获得优化推荐。虽然该任务的典型实现假定用户目标项目（最终）会被返回，但实际情况往往并非如此——例如用户寻找的商品可能不在商品目录中。若未能返回用户期望商品，将导致用户挫败感加剧，因为用户需要与系统进行更多轮次交互。为缓解此问题，本文受查询性能预测（QPP）中预测搜索引擎查询有效性的启发，引入监督式会话性能预测任务。据此，我们提出通过嵌入表征中检索图像项目所含的多轮语义信息来检测会话失败的预测器。具体而言，我们基于自编码器的预测器通过学习训练轮次中顶部检索项目的压缩表征，并利用分类标签来预测评估轮次。我们的评估方案通过区分系统故障（系统无法找到目标）和目录故障（目标不存在于商品目录），处理了两种推荐场景。在使用Shoes和FashionIQ Dresses数据集的实验中，我们测量了针对系统故障与目录故障的预测器准确率。结果表明：在预测系统故障（现有评估场景）时，我们提出的预测器展现出良好潜力；而在目录故障预测（模拟缺失商品场景）中，相较于系统故障，其预测性能出现显著下降。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Failure+Prediction+in+Conversational+Recommendation+Systems)|0|
|[Just Ask for Music (JAM): Multimodal and Personalized Natural Language Music Recommendation](https://doi.org/10.1145/3705328.3748020)|Alessandro B. Melchiorre, Elena V. Epure, Shahed Masoudian, Gustavo Escobedo, Anna Hausberger, Manuel Moussallam, Markus Schedl||Natural language interfaces offer a compelling approach for music recommendation, enabling users to express complex preferences conversationally. While Large Language Models (LLMs) show promise in this direction, their scalability in recommender systems is limited by high costs and latency. Retrieval-based approaches using smaller language models mitigate these issues but often rely on single-modal item representations, overlook long-term user preferences, and require full model retraining, posing challenges for real-world deployment. In this paper, we present JAM (Just Ask for Music), a lightweight and intuitive framework for natural language music recommendation. JAM models user-query-item interactions as vector translations in a shared latent space, inspired by knowledge graph embedding methods like TransE. To capture the complexity of music and user intent, JAM aggregates multimodal item features via cross-attention and sparse mixture-of-experts. We also introduce JAMSessions, a new dataset of over 100k user-query-item triples with anonymized user/item embeddings, uniquely combining conversational queries and user long-term preferences. Our results show that JAM provides accurate recommendations, produces intuitive representations suitable for practical use cases, and can be easily integrated with existing music recommendation stacks.|自然语言交互界面为音乐推荐提供了一种引人注目的方法，使用户能够以对话方式表达复杂偏好。尽管大型语言模型（LLMs）在这一方向展现出潜力，但其在推荐系统中的可扩展性受限于高计算成本与延迟问题。基于检索的方法采用较小语言模型虽能缓解这些问题，但通常依赖单模态项目表征、忽略长期用户偏好，且需要完整模型重训练，这为实际部署带来挑战。本文提出JAM（音乐即时查询）框架——一个轻量级、直观的自然语言音乐推荐系统。受TransE等知识图谱嵌入方法启发，JAM将用户-查询-项目交互建模为共享潜在空间中的向量平移。为捕捉音乐特性与用户意图的复杂性，JAM通过交叉注意力机制与稀疏专家混合实现多模态项目特征聚合。我们还推出了JAMSessions数据集，包含超过10万条经过匿名化处理的用户/项目嵌入三元组，首次将会话式查询与用户长期偏好相结合。实验结果表明，JAM不仅能提供精准推荐，生成适用于实际场景的直观表征，还可轻松集成至现有音乐推荐技术栈。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Just+Ask+for+Music+(JAM):+Multimodal+and+Personalized+Natural+Language+Music+Recommendation)|0|
|[Not Just What, But When: Integrating Irregular Intervals to LLM for Sequential Recommendation](https://doi.org/10.1145/3705328.3748013)|WeiWei Du, Takuma Udagawa, Kei Tateno||Time intervals between purchasing items are a crucial factor in sequential recommendation tasks, whereas existing approaches focus on item sequences and often overlook by assuming the intervals between items are static. However, dynamic intervals serve as a dimension that describes user profiling on not only the history within a user but also different users with the same item history. In this work, we propose IntervalLLM, a novel framework that integrates interval information into LLM and incorporates the novel interval-infused attention to jointly consider information of items and intervals. Furthermore, unlike prior studies that address the cold-start scenario only from the perspectives of users and items, we introduce a new viewpoint: the interval perspective to serve as an additional metric for evaluating recommendation methods on the warm and cold scenarios. Extensive experiments on 3 benchmarks with both traditional- and LLM-based baselines demonstrate that our IntervalLLM achieves not only 4.4|商品购买时间间隔是序列推荐任务中的关键因素，而现有方法主要关注商品序列，往往通过假设商品间间隔固定不变而忽略这一要素。然而，动态间隔作为描述用户画像的维度，既能反映同一用户的历史行为特征，也能区分具有相同商品历史的不同用户。本研究提出IntervalLLM创新框架，将间隔信息融入大语言模型，并通过新型的间隔注入注意力机制协同处理商品与间隔信息。此外，与仅从用户和商品视角处理冷启动场景的已有研究不同，我们引入间隔视角作为评估推荐方法在温启动与冷启动场景下表现的新指标。在3个基准数据集上与传统方法和基于大语言模型的基线方法进行的广泛实验表明，IntervalLLM不仅在温启动场景下取得4.4%的NDCG提升，在冷启动场景下更实现高达12.1%的性能改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Not+Just+What,+But+When:+Integrating+Irregular+Intervals+to+LLM+for+Sequential+Recommendation)|0|
|[Personalized Persuasion-Aware Explanations in Recommender Systems](https://doi.org/10.1145/3705328.3748021)|Havva Alizadeh Noughabi, Behshid Behkamal, Fattane Zarrinkalam, Mohsen Kahani||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Persuasion-Aware+Explanations+in+Recommender+Systems)|0|
|[Towards Personality-Aware Explanations for Music Recommendations Using Generative AI](https://doi.org/10.1145/3705328.3748032)|Gabrielle Alves, Dietmar Jannach, Luan Soares de Souza, Marcelo Garcia Manzato||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Personality-Aware+Explanations+for+Music+Recommendations+Using+Generative+AI)|0|
|[TreatRAG: A Framework for Personalized Treatment Recommendation](https://doi.org/10.1145/3705328.3748022)|ChaoChin Liu, HaoRen Yao, DerChen Chang, Ophir Frieder||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TreatRAG:+A+Framework+for+Personalized+Treatment+Recommendation)|0|
|[Model Meets Knowledge: Analyzing Knowledge Types for Conversational Recommender Systems](https://doi.org/10.1145/3705328.3748152)|Jujia Zhao, Yumeng Wang, Zhaochun Ren, Suzan Verberne||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Model+Meets+Knowledge:+Analyzing+Knowledge+Types+for+Conversational+Recommender+Systems)|0|
|[Revisiting Prompt Engineering: A Comprehensive Evaluation for LLM-based Personalized Recommendation](https://doi.org/10.1145/3705328.3748159)|Genki Kusano, Kosuke Akimoto, Kunihiro Takeoka||Large language models (LLMs) can perform recommendation tasks by taking prompts written in natural language as input. Compared to traditional methods such as collaborative filtering, LLM-based recommendation offers advantages in handling cold-start, cross-domain, and zero-shot scenarios, as well as supporting flexible input formats and generating explanations of user behavior. In this paper, we focus on a single-user setting, where no information from other users is used. This setting is practical for privacy-sensitive or data-limited applications. In such cases, prompt engineering becomes especially important for controlling the output generated by the LLM. We conduct a large-scale comparison of 23 prompt types across 8 public datasets and 12 LLMs. We use statistical tests and linear mixed-effects models to evaluate both accuracy and inference cost. Our results show that for cost-efficient LLMs, three types of prompts are especially effective: those that rephrase instructions, consider background knowledge, and make the reasoning process easier to follow. For high-performance LLMs, simple prompts often outperform more complex ones while reducing cost. In contrast, commonly used prompting styles in natural language processing, such as step-by-step reasoning, or the use of reasoning models often lead to lower accuracy. Based on these findings, we provide practical suggestions for selecting prompts and LLMs depending on the required balance between accuracy and cost.|大语言模型能够通过自然语言提示执行推荐任务。与传统协同过滤方法相比，基于大语言模型的推荐系统在冷启动、跨领域和零样本场景中展现优势，同时支持灵活输入格式并能为用户行为生成解释。本文聚焦于单用户场景，该场景不涉及其他用户信息，适用于隐私敏感或数据受限的实际应用。在此情境下，提示工程对于控制大语言模型输出尤为重要。我们在8个公共数据集和12个大语言模型上对23种提示类型进行大规模对比，采用统计检验和线性混合效应模型评估准确性与推理成本。实验表明：对于成本敏感型模型，三类提示效果显著——指令重述、背景知识整合和简化推理流程的提示；而高性能模型使用简单提示既能降低成本又能获得更优效果。相比之下，自然语言处理中常用的逐步推理提示或复杂推理模型往往导致准确率下降。基于这些发现，我们针对不同精度与成本平衡需求，为提示策略与大语言模型选择提供了实用建议。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revisiting+Prompt+Engineering:+A+Comprehensive+Evaluation+for+LLM-based+Personalized+Recommendation)|0|
|[A Media Content Recommendation Method for Playlist Curators using LLM-Based Query Expansion](https://doi.org/10.1145/3705328.3748129)|Yuta Hagio, Chigusa Yamamura, Hiromu Ogawa, Hisayuki Ohmata, Arisa Fujii||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Media+Content+Recommendation+Method+for+Playlist+Curators+using+LLM-Based+Query+Expansion)|0|
|[Improving Visual Recommendation on E-commerce Platforms Using Vision-Language Models](https://doi.org/10.1145/3705328.3748128)|Yuki Yada, Sho Akiyama, Ryo Watanabe, Yuta Ueno, Yusuke Shido, Andre Rusli||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Visual+Recommendation+on+E-commerce+Platforms+Using+Vision-Language+Models)|0|
|[Industry Insights from Comparing Deep Learning and GBDT Models for E-Commerce Learning-to-Rank](https://doi.org/10.1145/3705328.3748130)|Yunus Lutz, Timo Wilm, Philipp Duwe||In e-commerce recommender and search systems, tree-based models, such as LambdaMART, have set a strong baseline for Learning-to-Rank (LTR) tasks. Despite their effectiveness and widespread adoption in industry, the debate continues whether deep neural networks (DNNs) can outperform traditional tree-based models in this domain. To contribute to this discussion, we systematically benchmark DNNs against our production-grade LambdaMART model. We evaluate multiple DNN architectures and loss functions on a proprietary dataset from OTTO and validate our findings through an 8-week online A/B test. The results show that a simple DNN architecture outperforms a strong tree-based baseline in terms of total clicks and revenue, while achieving parity in total units sold.|在电商推荐与搜索系统中，基于树的模型（如LambdaMART）已为学习排序任务树立了坚实的基准。尽管这类模型在工业界具有显著效能并被广泛采用，但关于深度神经网络能否在该领域超越传统树模型的争论始终存在。为推进这一讨论，我们系统性地将深度神经网络与生产级LambdaMART模型进行基准测试。基于OTTO专有数据集，我们评估了多种DNN架构与损失函数，并通过为期八周的在线A/B测试验证研究结果。实验表明：在总点击量与营收指标上，简单DNN架构优于强大的树模型基线，同时在总销量指标上与之持平。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Industry+Insights+from+Comparing+Deep+Learning+and+GBDT+Models+for+E-Commerce+Learning-to-Rank)|0|
|[Location Matters: Leveraging Multi-Resolution Geo-Embeddings for Housing Search](https://doi.org/10.1145/3705328.3748136)|Ivo Silva, Guilherme G. Bonaldo, Pedro F. Nogueira||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Location+Matters:+Leveraging+Multi-Resolution+Geo-Embeddings+for+Housing+Search)|0|
|[Minimize Negative Experiences in Video Recommendation Systems with Multimodal Large Language Models](https://doi.org/10.1145/3705328.3748102)|Suman Malani, Youwei Zhang, Liang Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Minimize+Negative+Experiences+in+Video+Recommendation+Systems+with+Multimodal+Large+Language+Models)|0|
|[Orthogonal Low Rank Embedding Stabilization](https://doi.org/10.1145/3705328.3748141)|Kevin Zielnicki, KoJen Hsiao||The instability of embedding spaces across model retraining cycles presents significant challenges to downstream applications using user or item embeddings derived from recommendation systems as input features. This paper introduces a novel orthogonal low-rank transformation methodology designed to stabilize the user/item embedding space, ensuring consistent embedding dimensions across retraining sessions. Our approach leverages a combination of efficient low-rank singular value decomposition and orthogonal Procrustes transformation to map embeddings into a standardized space. This transformation is computationally efficient, lossless, and lightweight, preserving the dot product and inference quality while reducing operational burdens. Unlike existing methods that modify training objectives or embedding structures, our approach maintains the integrity of the primary model application and can be seamlessly integrated with other stabilization techniques.|推荐模型重训练过程中嵌入空间的不稳定性，对使用用户/商品嵌入作为输入特征的下游应用构成了重大挑战。本文提出一种新颖的正交低秩变换方法，旨在稳定用户/商品嵌入空间，确保重训练周期中嵌入维度的一致性。该方法结合高效低秩奇异值分解与正交普氏变换，将嵌入映射至标准化空间。该变换过程具有计算高效、无损处理和轻量级的特点，在保持点积运算特性与推理质量的同时降低了运维负担。与现有需要修改训练目标或嵌入结构的方法不同，我们的方案既保持了主模型应用的完整性，又可与其他稳定化技术无缝集成。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Orthogonal+Low+Rank+Embedding+Stabilization)|0|
|[Practical Multi-Task Learning for Rare Conversions in Ad Tech](https://doi.org/10.1145/3705328.3748110)|Yuval Dishi, Ophir Friedler, Yonatan Karni, Natalia Silberstein, Yulia Stolin||We present a Multi-Task Learning (MTL) approach for improving predictions for rare (e.g., <1|我们提出了一种多任务学习（MTL）方法，旨在提升对稀有事件（例如发生率低于1%的情况）的预测性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Practical+Multi-Task+Learning+for+Rare+Conversions+in+Ad+Tech)|0|
|[Scaling Generative Recommendations with Context Parallelism on Hierarchical Sequential Transducers](https://doi.org/10.1145/3705328.3748143)|Yue Dong, Han Li, Shen Li, Nikhil Patel, Xing Liu, Xiaodong Wang, Chuanhao Zhuge||Large-scale recommendation systems are pivotal to process an immense volume of daily user interactions, requiring the effective modeling of high cardinality and heterogeneous features to ensure accurate predictions. In prior work, we introduced Hierarchical Sequential Transducers (HSTU), an attention-based architecture for modeling high cardinality, non-stationary streaming recommendation data, providing good scaling law in the generative recommender framework (GR). Recent studies and experiments demonstrate that attending to longer user history sequences yields significant metric improvements. However, scaling sequence length is activation-heavy, necessitating parallelism solutions to effectively shard activation memory. In transformer-based LLMs, context parallelism (CP) is a commonly used technique that distributes computation along the sequence-length dimension across multiple GPUs, effectively reducing memory usage from attention activations. In contrast, production ranking models typically utilize jagged input tensors to represent user interaction features, introducing unique CP implementation challenges. In this work, we introduce context parallelism with jagged tensor support for HSTU attention, establishing foundational capabilities for scaling up sequence dimensions. Our approach enables a 5.3x increase in supported user interaction sequence length, while achieving a 1.55x scaling factor when combined with Distributed Data Parallelism (DDP).|大规模推荐系统对处理海量日常用户交互至关重要，需要有效建模高基数异构特征以确保预测准确性。在先前工作中，我们提出了分层序列转换器（HSTU），这是一种基于注意力机制的架构，专门用于建模高基数、非平稳的流式推荐数据，并在生成式推荐框架（GR）中展现出良好的扩展规律。近期研究与实验表明，关注更长的用户历史序列能带来显著的指标提升。然而，扩展序列长度会大幅增加激活内存负担，需要并行化解决方案来实现激活内存的有效分片。在基于Transformer的大语言模型中，上下文并行（CP）是一种常用技术，通过将序列维度上的计算分布到多个GPU，有效降低注意力激活的内存占用。相比之下，生产级排序模型通常采用不规则张量来表征用户交互特征，这为CP实现带来了独特挑战。本研究针对HSTU注意力机制引入了支持不规则张量的上下文并行方案，为扩展序列维度建立了基础能力。我们的方法使用户交互序列长度支持提升5.3倍，结合分布式数据并行（DDP）时可实现1.55倍的扩展系数。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scaling+Generative+Recommendations+with+Context+Parallelism+on+Hierarchical+Sequential+Transducers)|0|
|[SEMORec: A Scalarized Efficient Multi-Objective Recommendation Framework](https://doi.org/10.1145/3705328.3748140)|Sofia Maria Nikolakaki, Siyong Ma, Srivas Chennu, Humeyra Topcu Altintas||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SEMORec:+A+Scalarized+Efficient+Multi-Objective+Recommendation+Framework)|0|
|[Suggest, Complement, Inspire: Story of Two-Tower Recommendations at Allegro.com](https://doi.org/10.1145/3705328.3748135)|Aleksandra Maria OsowskaKurczab, Klaudia Nazarko, Mateusz Marzec, Lidia Wojciechowska, Eliska Kremenová||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Suggest,+Complement,+Inspire:+Story+of+Two-Tower+Recommendations+at+Allegro.com)|0|
|[A Dual-Key Attention Framework for Sequential Recommendation with Side Information](https://doi.org/10.1145/3705328.3759326)|Minje Kim, Wooseung Kang, GunWoo Kim, Chie Hoon Song, Suwon Lee, SangMin Choi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Dual-Key+Attention+Framework+for+Sequential+Recommendation+with+Side+Information)|0|
|[Don't Get Ahead of Yourself: A Critical Study on Data Leakage in Offline Evaluation of Sequential Recommenders](https://doi.org/10.1145/3705328.3759329)|Huy Hoang Le, Yang Liu, Alan Medlar, Dorota Glowacka||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Don't+Get+Ahead+of+Yourself:+A+Critical+Study+on+Data+Leakage+in+Offline+Evaluation+of+Sequential+Recommenders)|0|
|[End-to-End Time Interval-wise Segmentation for Sequential Recommendation](https://doi.org/10.1145/3705328.3759327)|Minje Kim, Wooseung Kang, GunWoo Kim, Chie Hoon Song, Suwon Lee, SangMin Choi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=End-to-End+Time+Interval-wise+Segmentation+for+Sequential+Recommendation)|0|
|[Parameter-Efficient Single Collaborative Branch for Recommendation](https://doi.org/10.1145/3705328.3759302)|Marta Moscati, Shah Nawaz, Markus Schedl||Recommender Systems (RS) often rely on representations of users and items in a joint embedding space and on a similarity metric to compute relevance scores. In modern RS, the modules to obtain user and item representations consist of two distinct and separate neural networks (NN). In multimodal representation learning, weight sharing has been proven effective in reducing the distance between multiple modalities of a same item. Inspired by these approaches, we propose a novel RS that leverages weight sharing between the user and item NN modules used to obtain the latent representations in the shared embedding space. The proposed framework consists of a single Collaborative Branch for Recommendation (CoBraR). We evaluate CoBraR by means of quantitative experiments on e-commerce and movie recommendation. Our experiments show that by reducing the number of parameters and improving beyond-accuracy aspects without compromising accuracy, CoBraR has the potential to be applied and extended for real-world scenarios.|推荐系统通常依赖于用户与物品在联合嵌入空间中的表征，以及用于计算相关性得分的相似性度量。现代推荐系统中，获取用户和物品表征的模块由两个独立分离的神经网络构成。在多模态表示学习领域，权重共享已被证明能有效缩小同一物品不同模态间的距离。受此启发，我们提出了一种创新推荐系统，在用户与物品神经网络模块之间实现权重共享，以获取共享嵌入空间中的潜在表征。该框架包含一个统一的协同推荐分支（CoBraR）。我们通过电子商务和电影推荐场景的定量实验评估CoBraR性能。实验表明，该模型在保持准确率的同时，既能减少参数量又能提升超精确度指标，具有实际应用场景推广的潜力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Parameter-Efficient+Single+Collaborative+Branch+for+Recommendation)|0|
|[Rethinking Subjective Features in Recommender Systems: Personal Views Over Aggregated Values](https://doi.org/10.1145/3705328.3759316)|Arsen Matej Golubovikj, Marko Tkalcic||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rethinking+Subjective+Features+in+Recommender+Systems:+Personal+Views+Over+Aggregated+Values)|0|
|[SAGEA: Sparse Autoencoder-based Group Embeddings Aggregation for Fairness-Preserving Group Recommendations](https://doi.org/10.1145/3705328.3759322)|Vit Kostejn, Ladislav Peska, Martin Spisák||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SAGEA:+Sparse+Autoencoder-based+Group+Embeddings+Aggregation+for+Fairness-Preserving+Group+Recommendations)|0|
|[A Tutorial on Recent Advances in Generative Conversational Recommender Systems](https://doi.org/10.1145/3705328.3748010)|Thomas Elmar Kolb, Ahmadou Wagne, Ashmi Banerjee, Fatemeh Nazary, Julia Neidhardt, Yashar Deldjoo, Tommaso Di Noia||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Tutorial+on+Recent+Advances+in+Generative+Conversational+Recommender+Systems)|0|
|[concept2code: Sequential Recommendation with Large Language Models](https://doi.org/10.1145/3705328.3748003)|Omprakash Sonie||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=concept2code:+Sequential+Recommendation+with+Large+Language+Models)|0|
|[Data Access for Recommender Systems Research: leveraging the EU's Digital Services Act](https://doi.org/10.1145/3705328.3748004)|João Vinagre, Lorenzo Porcaro, Silvia Merisio, Erasmo Purificato, Emilia Gómez||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Data+Access+for+Recommender+Systems+Research:+leveraging+the+EU's+Digital+Services+Act)|0|
|[Multi-Agentic Recommender Systems: Foundations, Design Patterns, and E-Commerce Applications - An Industrial Tutorial](https://doi.org/10.1145/3705328.3748008)|Reza Yousefi Maragheh, Yashar Deldjoo, Chi Wang, Jason Cho, Derek Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Agentic+Recommender+Systems:+Foundations,+Design+Patterns,+and+E-Commerce+Applications+-+An+Industrial+Tutorial)|0|
|[Personalized Image Generation for Recommendations Beyond Catalogs](https://doi.org/10.1145/3705328.3748757)|Gabriel Alfonso Patron||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Image+Generation+for+Recommendations+Beyond+Catalogs)|0|
|[On Inherited Popularity Bias in Cold-Start Item Recommendation](https://doi.org/10.1145/3705328.3748035)|Gregor Meehan, Johan Pauwels||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Inherited+Popularity+Bias+in+Cold-Start+Item+Recommendation)|0|
|[Exploitation Over Exploration: Unmasking the Bias in Linear Bandit Recommender Offline Evaluation](https://doi.org/10.1145/3705328.3748166)|Pedro R. Pires, Gregório F. Azevedo, Pietro L. Campos, Rafael T. Sereicikas, Tiago A. Almeida||Multi-Armed Bandit (MAB) algorithms are widely used in recommender systems that require continuous, incremental learning. A core aspect of MABs is the exploration-exploitation trade-off: choosing between exploiting items likely to be enjoyed and exploring new ones to gather information. In contextual linear bandits, this trade-off is particularly central, as many variants share the same linear regression backbone and differ primarily in their exploration strategies. Despite its prevalent use, offline evaluation of MABs is increasingly recognized for its limitations in reliably assessing exploration behavior. This study conducts an extensive offline empirical comparison of several linear MABs. Strikingly, across over 90|多臂老虎机（MAB）算法在需要持续增量学习的推荐系统中应用广泛。其核心在于探索-利用的权衡：是在可能受青睐的内容上持续利用，还是探索新内容以收集信息。在上下文线性老虎机中，这一权衡尤为关键，因为许多变体共享相同的线性回归框架，主要区别在于探索策略。尽管应用广泛，但学界日益认识到MAB离线评估在可靠检验探索行为方面存在局限。本研究对多种线性MAB算法展开了大规模离线实证比较。值得关注的是，在超过90组实验环境中，我们观察到...|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploitation+Over+Exploration:+Unmasking+the+Bias+in+Linear+Bandit+Recommender+Offline+Evaluation)|0|
|[Generalized User Representations for Large-Scale Recommendations and Downstream Tasks](https://doi.org/10.1145/3705328.3748132)|Ghazal Fazelnia, Sanket Gupta, Claire Keum, Mark Koh, Timothy Christopher Heath, Guillermo Carrasco Hernández, Stephen Xie, Nandini Singh, Ian Anderson, Maya Hristakeva, Petter Pehrson Skidén, Mounia Lalmas||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generalized+User+Representations+for+Large-Scale+Recommendations+and+Downstream+Tasks)|0|
|[Personalized Interest Graphs for Theme-Driven User Behavior](https://doi.org/10.1145/3705328.3748133)|Oded Zinman, Nazmul Chowdhury, Leandro Fiaschetti, Yuri M. Brovman, Guy Feigenblat, Yotam Eshel||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Interest+Graphs+for+Theme-Driven+User+Behavior)|0|
|[SlateLLM: Distilling LLM Semantics into Session-Aware Slate Recommendation without Inference Overhead](https://doi.org/10.1145/3705328.3759306)|Aayush Singha Roy, Elias Z. Tragos, Aonghus Lawlor, Neil Hurley||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SlateLLM:+Distilling+LLM+Semantics+into+Session-Aware+Slate+Recommendation+without+Inference+Overhead)|0|
|[Auditing Recommender Systems for User Empowerment in Very Large Online Platforms under the Digital Services Act](https://doi.org/10.1145/3705328.3748074)|Matteo Fabbri, Ludovico Boratto||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Auditing+Recommender+Systems+for+User+Empowerment+in+Very+Large+Online+Platforms+under+the+Digital+Services+Act)|0|
|[Breaking Knowledge Boundaries: Cognitive Distillation-enhanced Cross-Behavior Course Recommendation Model](https://doi.org/10.1145/3705328.3748083)|Ruoyu Li, Yangtao Zhou, Chenzhang Li, Hua Chu, Jianan Li, Yuhan Bian||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Breaking+Knowledge+Boundaries:+Cognitive+Distillation-enhanced+Cross-Behavior+Course+Recommendation+Model)|0|
|[Enhancing Online Video Recommendation via a Coarse-to-fine Dynamic Uplift Modeling Framework](https://doi.org/10.1145/3705328.3748070)|Chang Meng, Chenhao Zhai, Xueliang Wang, Shuchang Liu, Xiaoqiang Feng, Lantao Hu, Xiu Li, Han Li, Kun Gai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Online+Video+Recommendation+via+a+Coarse-to-fine+Dynamic+Uplift+Modeling+Framework)|0|
|[Exploring Scaling Laws of CTR Model for Online Performance Improvement](https://doi.org/10.1145/3705328.3748046)|Weijiang Lai, Beihong Jin, Jiongyan Zhang, Yiyuan Zheng, Jian Dong, Jia Cheng, Jun Lei, Xingxing Wang||CTR models play a vital role in improving user experience and boosting business revenue in many online personalized services. However, current CTR models generally encounter bottlenecks in performance improvement. Inspired by the scaling law phenomenon of LLMs, we propose a new paradigm for improving CTR predictions: first, constructing a CTR model with accuracy scalable to the model grade and data size, and then distilling the knowledge implied in this model into its lightweight model that can serve online users. To put it into practice, we construct a CTR model named SUAN (Stacked Unified Attention Network). In SUAN, we propose the UAB as a behavior sequence encoder. A single UAB unifies the modeling of the sequential and non-sequential features and also measures the importance of each user behavior feature from multiple perspectives. Stacked UABs elevate the configuration to a high grade, paving the way for performance improvement. In order to benefit from the high performance of the high-grade SUAN and avoid the disadvantage of its long inference time, we modify the SUAN with sparse self-attention and parallel inference strategies to form LightSUAN, and then adopt online distillation to train the low-grade LightSUAN, taking a high-grade SUAN as a teacher. The distilled LightSUAN has superior performance but the same inference time as the LightSUAN, making it well-suited for online deployment. Experimental results show that SUAN performs exceptionally well and holds the scaling laws spanning three orders of magnitude in model grade and data size, and the distilled LightSUAN outperforms the SUAN configured with one grade higher. More importantly, the distilled LightSUAN has been integrated into an online service, increasing the CTR by 2.81|点击率（CTR）模型在提升在线个性化服务的用户体验和促进商业收入方面发挥着关键作用。然而，当前CTR模型普遍面临性能提升的瓶颈。受大语言模型（LLM）规模定律现象的启发，我们提出了一种改进CTR预测的新范式：首先构建一个精度可随模型等级和数据规模扩展的CTR模型，然后将该模型中蕴含的知识蒸馏至可服务在线用户的轻量级模型。为实现这一目标，我们构建了名为SUAN（堆叠统一注意力网络）的CTR模型。该模型提出统一注意力块（UAB）作为行为序列编码器：单个UAB模块既能统一建模序列与非序列特征，又能从多维度衡量用户行为特征的重要性；通过堆叠UAB模块实现高等级配置，为性能提升奠定基础。为兼顾高等级SUAN的优异性能与规避其推理时延较长的缺陷，我们通过引入稀疏自注意力与并行推理策略构建LightSUAN，并以高等级SUAN作为教师模型，采用在线蒸馏技术训练低等级LightSUAN。最终获得的蒸馏版LightSUAN在保持与原始LightSUAN相同推理速度的同时实现了性能超越，非常适合在线部署。实验结果表明：SUAN在模型等级和数据规模跨越三个数量级的场景下均表现出卓越性能并遵循规模定律，蒸馏后的LightSUAN性能甚至超越配置等级提升一级的SUAN模型。目前该技术已成功应用于在线服务，实现点击率提升2.81%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+Scaling+Laws+of+CTR+Model+for+Online+Performance+Improvement)|0|
|[Leave No One Behind: Fairness-Aware Cross-Domain Recommender Systems for Non-Overlapping Users](https://doi.org/10.1145/3705328.3748082)|Weixin Chen, Yuhan Zhao, Li Chen, Weike Pan||Cross-domain recommendation (CDR) methods predominantly leverage overlapping users to transfer knowledge from a source domain to a target domain. However, through empirical studies, we uncover a critical bias inherent in these approaches: while overlapping users experience significant enhancements in recommendation quality, non-overlapping users benefit minimally and even face performance degradation. This unfairness may erode user trust, and, consequently, negatively impact business engagement and revenue. To address this issue, we propose a novel solution that generates virtual source-domain users for non-overlapping target-domain users. Our method utilizes a dual attention mechanism to discern similarities between overlapping and non-overlapping users, thereby synthesizing realistic virtual user embeddings. We further introduce a limiter component that ensures the generated virtual users align with real-data distributions while preserving each user's unique characteristics. Notably, our method is model-agnostic and can be seamlessly integrated into any CDR model. Comprehensive experiments conducted on three public datasets with five CDR baselines demonstrate that our method effectively mitigates the CDR non-overlapping user bias, without loss of overall accuracy. Our code is publicly available at https://github.com/WeixinChen98/VUG.|跨领域推荐方法主要依赖重叠用户将知识从源领域迁移至目标领域。然而，通过实证研究，我们发现这类方法存在关键偏差：虽然重叠用户的推荐质量显著提升，但非重叠用户获益甚微甚至面临性能下降。这种不公平性可能损害用户信任，进而对商业参与度和收入产生负面影响。为解决该问题，我们提出了一种创新方案，通过为非重叠的目标域用户生成虚拟源域用户。该方法采用双重注意力机制识别重叠与非重叠用户间的相似性，从而合成逼真的虚拟用户嵌入表示。我们进一步引入限制器组件，确保生成的虚拟用户既符合真实数据分布，又能保留每位用户的独特性。值得注意的是，该方法具有模型无关性，可无缝集成至任意跨领域推荐模型。在三个公开数据集上采用五种跨领域推荐基线模型进行的全面实验表明，我们的方法能有效缓解非重叠用户偏差，且不会损失整体推荐精度。代码已发布于https://github.com/WeixinChen98/VUG。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leave+No+One+Behind:+Fairness-Aware+Cross-Domain+Recommender+Systems+for+Non-Overlapping+Users)|0|
|[Lasso: Large Language Model-based User Simulator for Cross-Domain Recommendation](https://doi.org/10.1145/3705328.3748048)|Yue Chen, Susen Yang, Tong Zhang, Chao Wang, Mingyue Cheng, Chenyi Lei, Han Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Lasso:+Large+Language+Model-based+User+Simulator+for+Cross-Domain+Recommendation)|0|
|[Correcting the LogQ Correction: Revisiting Sampled Softmax for Large-Scale Retrieval](https://doi.org/10.1145/3705328.3748033)|Kirill Khrylchenko, Vladimir Baikalov, Sergei S. Makeev, Artem Matveev, Sergei Liamaev||Two-tower neural networks are a popular architecture for the retrieval stage in recommender systems. These models are typically trained with a softmax loss over the item catalog. However, in web-scale settings, the item catalog is often prohibitively large, making full softmax infeasible. A common solution is sampled softmax, which approximates the full softmax using a small number of sampled negatives. One practical and widely adopted approach is to use in-batch negatives, where negatives are drawn from items in the current mini-batch. However, this introduces a bias: items that appear more frequently in the batch (i.e., popular items) are penalized more heavily. To mitigate this issue, a popular industry technique known as logQ correction adjusts the logits during training by subtracting the log-probability of an item appearing in the batch. This correction is derived by analyzing the bias in the gradient and applying importance sampling, effectively twice, using the in-batch distribution as a proposal distribution. While this approach improves model quality, it does not fully eliminate the bias. In this work, we revisit the derivation of logQ correction and show that it overlooks a subtle but important detail: the positive item in the denominator is not Monte Carlo-sampled - it is always present with probability 1. We propose a refined correction formula that accounts for this. Notably, our loss introduces an interpretable sample weight that reflects the model's uncertainty - the probability of misclassification under the current parameters. We evaluate our method on both public and proprietary datasets, demonstrating consistent improvements over the standard logQ correction.|双塔神经网络是推荐系统召回阶段的主流架构。这类模型通常采用项目目录上的softmax损失进行训练。然而，在网络级应用场景中，项目目录往往过于庞大，使得完整softmax计算难以实现。常见的解决方案是采样softmax，即通过少量负样本对完整softmax进行近似估计。业界广泛采用的一种实用方法是在批次内采样负样本，即从当前小批次中抽取负样本。但这种方法会引入偏差：在批次中出现频率更高的项目（即热门项目）会受到更严重的惩罚。为缓解该问题，业界流行的logQ校正技术通过减去项目在批次中出现概率的对数值来调整训练过程中的逻辑输出。该校正方法通过分析梯度偏差并两次应用重要性采样推导得出，其中将批次内分布作为建议分布。虽然这种方法提升了模型质量，但未能完全消除偏差。本文重新推导了logQ校正公式，发现其忽略了一个微妙但重要的细节：分母中的正样本并非通过蒙特卡洛采样获得——它总是以概率1存在。据此我们提出了考虑这一特性的改进校正公式。值得注意的是，我们提出的损失函数引入了一个可解释的样本权重，该权重反映了模型的不确定性——即当前参数下产生误分类的概率。通过在公开数据集和专有数据集上的实验验证，我们的方法相较于标准logQ校正实现了持续的性能提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Correcting+the+LogQ+Correction:+Revisiting+Sampled+Softmax+for+Large-Scale+Retrieval)|0|
|[Large Scale E-Commerce Model for Learning and Analyzing Long-Term User Preferences](https://doi.org/10.1145/3705328.3748027)|Yonatan Hadar, Yotam Eshel, Tal Franji, Bracha Shapira, Michelle Hwang, Guy Feigenblat||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large+Scale+E-Commerce+Model+for+Learning+and+Analyzing+Long-Term+User+Preferences)|0|
|[Mitigating Latent User Biases in Pre-trained VAE Recommendation Models via On-demand Input Space Transformation](https://doi.org/10.1145/3705328.3748012)|David Penz, Gustavo Junior Escobedo Ticona, Markus Schedl||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mitigating+Latent+User+Biases+in+Pre-trained+VAE+Recommendation+Models+via+On-demand+Input+Space+Transformation)|0|
|[TIM-Rec: Explicit Sparse Feedback on Multi-Item Upselling Recommendations in an Industrial Dataset of Telco Calls](https://doi.org/10.1145/3705328.3748150)|Alessandro Sbandi, Federico Siciliano, Fabrizio Silvestri||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TIM-Rec:+Explicit+Sparse+Feedback+on+Multi-Item+Upselling+Recommendations+in+an+Industrial+Dataset+of+Telco+Calls)|0|
|[Debiasing Implicit Feedback Recommenders via Sliced Wasserstein Distance-based Regularization](https://doi.org/10.1145/3705328.3759320)|Gustavo Escobedo, David Penz, Markus Schedl||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Debiasing+Implicit+Feedback+Recommenders+via+Sliced+Wasserstein+Distance-based+Regularization)|0|
|[From Previous Plays to Long-Term Tastes: Exploring the Long-term Reliability of Recommender Systems Simulations for Children](https://doi.org/10.1145/3705328.3759301)|Robin Ungruh, Alejandro Bellogín, Maria Soledad Pera||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=From+Previous+Plays+to+Long-Term+Tastes:+Exploring+the+Long-term+Reliability+of+Recommender+Systems+Simulations+for+Children)|0|
|[A Non-Parametric Choice Model That Learns How Users Choose Between Recommended Options](https://doi.org/10.1145/3705328.3748090)|Thorsten Krause, Harrie Oosterhuis||Choice models predict which items users choose from presented options. In recommendation settings, they can infer user preferences while countering exposure bias. In contrast with traditional univariate recommendation models, choice models consider which competitors appeared with the chosen item. This ability allows them to distinguish whether a user chose an item due to preference, i.e., they liked it; or competition, i.e., it was the best available option. Each choice model assumes specific user behavior, e.g., the multinomial logit model. However, it is currently unclear how accurately these assumptions capture actual user behavior, how wrong assumptions impact inference, and whether better models exist. In this work, we propose the learned choice model for recommendation (LCM4Rec), a non-parametric method for estimating the choice model. By applying kernel density estimation, LCM4Rec infers the most likely error distribution that describes the effect of inter-item cannibalization and thereby characterizes the users' choice model. Thus, it simultaneously infers what users prefer and how they make choices. Our experimental results indicate that our method (i) can accurately recover the choice model underlying a dataset; (ii) provides robust user preference inference, in contrast with existing choice models that are only effective when their assumptions match user behavior; and (iii) is more resistant against exposure bias than existing choice models. Thereby, we show that learning choice models, instead of assuming them, can produce more robust predictions. We believe this work provides an important step towards better understanding users' choice behavior.|选择模型用于预测用户从呈现选项中选取哪些项目。在推荐场景中，这类模型能够推断用户偏好，同时应对曝光偏差问题。与传统单变量推荐模型不同，选择模型会考虑被选项目与哪些竞品同时出现。这种能力使其能够区分用户选择某个项目是出于偏好（即真正喜爱），还是由于竞争关系（即该选项是当前最佳选择）。每种选择模型都基于特定用户行为假设，例如多项式Logit模型。但目前尚不明确这些假设对真实用户行为的捕捉准确度、错误假设如何影响推断结果，以及是否存在更优模型。本研究提出用于推荐的习得选择模型（LCM4Rec），这是一种通过核密度估计来推断选择模型的非参数方法。LCM4Rec通过核密度估计推断最可能的误差分布，该分布描述了商品间相互蚕食效应的影响，从而刻画用户的选择模型特性。因此，该方法能同步推断用户的偏好特征及其决策机制。实验结果表明我们的方法具有以下优势：（i）能精确还原数据集底层的选择模型；（ii）提供稳健的用户偏好推断，而现有选择模型仅在其假设符合用户行为时有效；（iii）相比现有选择模型具有更强的抗曝光偏差能力。由此证明，通过学习而非假设构建选择模型，能够产生更稳健的预测结果。我们相信这项研究为深入理解用户选择行为迈出了重要一步。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Non-Parametric+Choice+Model+That+Learns+How+Users+Choose+Between+Recommended+Options)|0|
|[Enhancing Transferability and Consistency in Cross-Domain Recommendations via Supervised Disentanglement](https://doi.org/10.1145/3705328.3748044)|Yuhan Wang, Qing Xie, Zhifeng Bao, Mengzi Tang, Lin Li, Yongjian Liu||Cross-domain recommendation (CDR) aims to alleviate the data sparsity by transferring knowledge across domains. Disentangled representation learning provides an effective solution to model complex user preferences by separating intra-domain features (domain-shared and domain-specific features), thereby enhancing robustness and interpretability. However, disentanglement-based CDR methods employing generative modeling or GNNs with contrastive objectives face two key challenges: (i) pre-separation strategies decouple features before extracting collaborative signals, disrupting intra-domain interactions and introducing noise; (ii) unsupervised disentanglement objectives lack explicit task-specific guidance, resulting in limited consistency and suboptimal alignment. To address these challenges, we propose DGCDR, a GNN-enhanced encoder-decoder framework. To handle challenge (i), DGCDR first applies GNN to extract high-order collaborative signals, providing enriched representations as a robust foundation for disentanglement. The encoder then dynamically disentangles features into domain-shared and -specific spaces, preserving collaborative information during the separation process. To handle challenge (ii), the decoder introduces an anchor-based supervision that leverages hierarchical feature relationships to enhance intra-domain consistency and cross-domain alignment. Extensive experiments on real-world datasets demonstrate that DGCDR achieves state-of-the-art performance, with improvements of up to 11.59|跨领域推荐（CDR）通过跨域知识迁移缓解数据稀疏性问题。解耦表征学习通过分离域内特征（域共享特征与域特定特征）为建模复杂用户偏好提供了有效解决方案，从而增强模型的鲁棒性与可解释性。然而，基于解耦的CDR方法在采用生成式建模或基于对比学习的图神经网络时面临两大挑战：（i）预分离策略在提取协同信号前进行特征解耦，这会破坏域内交互并引入噪声；（ii）无监督解耦目标缺乏显式的任务特定指导，导致特征一致性有限且对齐效果欠佳。针对这些挑战，我们提出DGCDR——一种图神经网络增强的编码器-解码器框架。针对挑战（i），DGCDR首先应用图神经网络提取高阶协同信号，为解耦过程提供富含语义的鲁棒表征基础；编码器随后动态将特征解耦至域共享与域特定空间，确保分离过程中协同信息的完整性。针对挑战（ii），解码器引入基于锚点的监督机制，利用层次化特征关系增强域内一致性与跨域对齐能力。在真实场景数据集上的大量实验表明，DGCDR实现了最先进的性能，各项指标提升最高达11.59%|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Transferability+and+Consistency+in+Cross-Domain+Recommendations+via+Supervised+Disentanglement)|0|
|[Heterogeneous User Modeling for LLM-based Recommendation](https://doi.org/10.1145/3705328.3748085)|Honghui Bao, Wenjie Wang, Xinyu Lin, Fengbin Zhu, Teng Sun, Fuli Feng, TatSeng Chua||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Heterogeneous+User+Modeling+for+LLM-based+Recommendation)|0|
|[Hierarchical Graph Information Bottleneck for Multi-Behavior Recommendation](https://doi.org/10.1145/3705328.3748073)|Hengyu Zhang, Chunxu Shen, Xiangguo Sun, Jie Tan, Yanchao Tan, Yu Rong, Hong Cheng, Lingling Yi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Graph+Information+Bottleneck+for+Multi-Behavior+Recommendation)|0|
|[How Do Users Perceive Recommender Systems' Objectives?](https://doi.org/10.1145/3705328.3748066)|Patrik Dokoupil, Ludovico Boratto, Ladislav Peska||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+Do+Users+Perceive+Recommender+Systems'+Objectives?)|0|
|[LANCE: Exploration and Reflection for LLM-based Textual Attacks on News Recommender Systems](https://doi.org/10.1145/3705328.3748081)|Yuyue Zhao, Jin Huang, Shuchang Liu, Jiancan Wu, Xiang Wang, Maarten de Rijke||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LANCE:+Exploration+and+Reflection+for+LLM-based+Textual+Attacks+on+News+Recommender+Systems)|0|
|[MDSBR: Multimodal Denoising for Session-based Recommendation](https://doi.org/10.1145/3705328.3748061)|Yutong Li, Xinyi Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MDSBR:+Multimodal+Denoising+for+Session-based+Recommendation)|0|
|[On the Reliability of Sampling Strategies in Offline Recommender Evaluation](https://doi.org/10.1145/3705328.3748086)|Bruno L. Pereira, Alan Said, Rodrygo L. T. Santos||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+the+Reliability+of+Sampling+Strategies+in+Offline+Recommender+Evaluation)|0|
|[Privacy-Preserving Social Recommendation: Privacy Leakage and Countermeasure](https://doi.org/10.1145/3705328.3748051)|Yuyue Chen, Peng Yang, Zoe Lin Jiang, Wenhao Wu, Junbin Fang, Xuan Wang, Chuanyi Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Privacy-Preserving+Social+Recommendation:+Privacy+Leakage+and+Countermeasure)|0|
|[Tag-augmented Dual-target Cross-domain Recommendation](https://doi.org/10.1145/3705328.3748067)|Mingfan Pan, Qingyang Mao, Xu An, Jianhui Ma, Gang Zhou, Mingyue Cheng, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tag-augmented+Dual-target+Cross-domain+Recommendation)|0|
|[Biases in LLM-Generated Musical Taste Profiles for Recommendation](https://doi.org/10.1145/3705328.3748030)|Bruno Sguerra, Elena V. Epure, Harin Lee, Manuel Moussallam||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Biases+in+LLM-Generated+Musical+Taste+Profiles+for+Recommendation)|0|
|[Estimating Quantum Execution Requirements for Feature Selection in Recommender Systems Using Extreme Value Theory](https://doi.org/10.1145/3705328.3748029)|Jiayang Niu, Qihan Zou, Jie Li, Ke Deng, Mark Sanderson, Yongli Ren||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Estimating+Quantum+Execution+Requirements+for+Feature+Selection+in+Recommender+Systems+Using+Extreme+Value+Theory)|0|
|[Not One News Recommender To Fit Them All: How Different Recommender Strategies Serve Various User Segments](https://doi.org/10.1145/3705328.3748034)|Hanne Vandenbroucke, Ulysse Maes, Lien Michiels, Annelien Smets||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Not+One+News+Recommender+To+Fit+Them+All:+How+Different+Recommender+Strategies+Serve+Various+User+Segments)|0|
|[Popularity‑Bias Vulnerability: Semi‑Supervised Label Inference Attack on Federated Recommender Systems](https://doi.org/10.1145/3705328.3748024)|Kenji Shinoda, Takeyuki Sasai, Shintaro Fukushima||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Popularity‑Bias+Vulnerability:+Semi‑Supervised+Label+Inference+Attack+on+Federated+Recommender+Systems)|0|
|[A Reproducibility Study of Product-side Fairness in Bundle Recommendation](https://doi.org/10.1145/3705328.3748169)|HuySon Nguyen, Yuanna Liu, Masoud Mansoury, Mohammad Aliannejadi, Alan Hanjalic, Maarten de Rijke||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Reproducibility+Study+of+Product-side+Fairness+in+Bundle+Recommendation)|0|
|[Exploring the Potential of LLMs for Serendipity Evaluation in Recommender Systems](https://doi.org/10.1145/3705328.3748167)|Li Kang, Yuhan Zhao, Li Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+the+Potential+of+LLMs+for+Serendipity+Evaluation+in+Recommender+Systems)|0|
|[Informfully Recommenders - Reproducibility Framework for Diversity-aware Intra-session Recommendations](https://doi.org/10.1145/3705328.3748148)|Lucien Heitz, Runze Li, Oana Inel, Abraham Bernstein||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Informfully+Recommenders+-+Reproducibility+Framework+for+Diversity-aware+Intra-session+Recommendations)|0|
|[Revisiting the Performance of Graph Neural Networks for Session-based Recommendation](https://doi.org/10.1145/3705328.3748156)|Faisal Shehzad, Dietmar Jannach||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revisiting+the+Performance+of+Graph+Neural+Networks+for+Session-based+Recommendation)|0|
|[Cross-Batch Aggregation for Streaming Learning from Label Proportions in Industrial-Scale Recommendation Systems](https://doi.org/10.1145/3705328.3748115)|Jonathan Valverde, Tiansheng Yao, Xiang Li, Yuan Gao, Yin Zhang, Andrew Evdokimov, Adam Kraft, Samuel Ieong, Jerry Zhang, Ed H. Chi, Derek Zhiyuan Cheng, Ruoxi Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cross-Batch+Aggregation+for+Streaming+Learning+from+Label+Proportions+in+Industrial-Scale+Recommendation+Systems)|0|
|[Enhancing Online Ranking Systems via Multi-Surface Co-Training for Content Understanding](https://doi.org/10.1145/3705328.3748101)|Gwendolyn Zhao, Yilin Zheng, Raghu Keshavan, Lukasz Heldt, Qian Sun, Fabio Soldo, Li Wei, Aniruddh Nath, Nikhil Khani, Weilong Yang, Dapo Omidiran, Rein Zhang, Mei Chen, Lichan Hong, Xinyang Yi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Online+Ranking+Systems+via+Multi-Surface+Co-Training+for+Content+Understanding)|0|
|[Identifying Offline Metrics that Predict Online Impact: A Pragmatic Strategy for Real-World Recommender Systems](https://doi.org/10.1145/3705328.3748111)|Timo Wilm, Philipp Normann||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Identifying+Offline+Metrics+that+Predict+Online+Impact:+A+Pragmatic+Strategy+for+Real-World+Recommender+Systems)|0|
|[Semantic IDs for Music Recommendation](https://doi.org/10.1145/3705328.3748139)|M. Jeffrey Mei, Florian Henkel, Samuel E. Sandberg, Oliver Bembom, Andreas F. Ehmann||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Semantic+IDs+for+Music+Recommendation)|0|
|[SocRipple: A Two-Stage Framework for Cold-Start Video Recommendations](https://doi.org/10.1145/3705328.3748124)|Amit Jaspal, Kapil Dalwani, Ajantha Ramineni||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SocRipple:+A+Two-Stage+Framework+for+Cold-Start+Video+Recommendations)|0|
|[Stream Normalization for CTR Prediction](https://doi.org/10.1145/3705328.3748093)|Yizhou Sang, Congcong Liu, Yuying Chen, Zhiwei Fang, Xue Jiang, Changping Peng, Zhangang Lin, Ching Law, Jingping Shao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Stream+Normalization+for+CTR+Prediction)|0|
|[Addressing Multiple Hypothesis Bias in CTR Prediction for Ad Selection](https://doi.org/10.1145/3705328.3759299)|Oren Sar Shalom, Neil Daftary||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Addressing+Multiple+Hypothesis+Bias+in+CTR+Prediction+for+Ad+Selection)|0|
|[Opening the Black Box: Interpretable Remedies for Popularity Bias in Recommender Systems](https://doi.org/10.1145/3705328.3759310)|Parviz Ahmadov, Masoud Mansoury||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Opening+the+Black+Box:+Interpretable+Remedies+for+Popularity+Bias+in+Recommender+Systems)|0|
|[ArtEx: A User-Controllable Web Interface for Visual Art Recommendations](https://doi.org/10.1145/3705328.3759343)|Rully Agus Hendrawan, Peter Brusilovsky, Luis A. Leiva, Bereket Abera Yilma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ArtEx:+A+User-Controllable+Web+Interface+for+Visual+Art+Recommendations)|0|
|[Flights Pricelock Fee Recommendation on Online Travel Agent Platform](https://doi.org/10.1145/3705328.3759339)|Akash Khetan, Narasimha Medeme, Deepak Yadav, Anmol Porwal||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Flights+Pricelock+Fee+Recommendation+on+Online+Travel+Agent+Platform)|0|
|[RecViz: Intuitive Graph-based Visual Analytics for Dataset Exploration and Recommender System Evaluation](https://doi.org/10.1145/3705328.3759335)|Jackson Dam, Zixuan Yi, Iadh Ounis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RecViz:+Intuitive+Graph-based+Visual+Analytics+for+Dataset+Exploration+and+Recommender+System+Evaluation)|0|
|[RecSys Challenge 2025: Universal Behavioral Profiles for Recommender Systems](https://doi.org/10.1145/3705328.3748172)|Jacek Dabrowski, Maria Janicka, Lukasz Sienkiewicz, Gergely Stomfai, Dietmar Jannach, Francesco Barile, Marco Polignano, Claudio Pomo, Abhishek Srivastava||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RecSys+Challenge+2025:+Universal+Behavioral+Profiles+for+Recommender+Systems)|0|
|[Recommender Systems for Digital Humanities and Archives: Multistakeholder Evaluation, Scholarly Information Needs, and Multimodal Similarity](https://doi.org/10.1145/3705328.3748761)|Florian AtzenhoferBaumgartner||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recommender+Systems+for+Digital+Humanities+and+Archives:+Multistakeholder+Evaluation,+Scholarly+Information+Needs,+and+Multimodal+Similarity)|0|
|[An Off-Policy Learning Approach for Steering Sentence Generation towards Personalization](https://doi.org/10.1145/3705328.3748088)|Haruka Kiyohara, Daniel Yiming Cao, Yuta Saito, Thorsten Joachims||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Off-Policy+Learning+Approach+for+Steering+Sentence+Generation+towards+Personalization)|0|
|[GRACE: Generative Recommendation via Journey-Aware Sparse Attention on Chain-of-Thought Tokenization](https://doi.org/10.1145/3705328.3748056)|Luyi Ma, Wanjia Zhang, Kai Zhao, Abhishek Kulkarni, Lalitesh Morishetti, Anjana Ganesh, Ashish Ranjan, Aashika Padmanabhan, Jianpeng Xu, Jason H. D. Cho, Praveenkumar Kanumala, Kaushiki Nag, Sumit Dutta, Kamiya Motwani, Malay Patel, Evren Körpeoglu, Sushant Kumar, Kannan Achan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GRACE:+Generative+Recommendation+via+Journey-Aware+Sparse+Attention+on+Chain-of-Thought+Tokenization)|0|
|[Integrating Individual and Group Fairness for Recommender Systems through Social Choice](https://doi.org/10.1145/3705328.3748087)|Amanda Aird, Elena Stefancova, Anas Buhayh, Cassidy All, Martin Homola, Nicholas Mattei, Robin Burke||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Integrating+Individual+and+Group+Fairness+for+Recommender+Systems+through+Social+Choice)|0|
|[LONGER: Scaling Up Long Sequence Modeling in Industrial Recommenders](https://doi.org/10.1145/3705328.3748065)|Zheng Chai, Qin Ren, Xijun Xiao, Huizhi Yang, Bo Han, Sijun Zhang, Di Chen, Hui Lu, Wenlin Zhao, Lele Yu, Xionghang Xie, Shiru Ren, Xiang Sun, Yaocheng Tan, Peng Xu, Yuchao Zheng, Di Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LONGER:+Scaling+Up+Long+Sequence+Modeling+in+Industrial+Recommenders)|0|
|[Measuring Interaction-Level Unlearning Difficulty for Collaborative Filtering](https://doi.org/10.1145/3705328.3748092)|Haocheng Dou, Tao Lian, Xin Xin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Measuring+Interaction-Level+Unlearning+Difficulty+for+Collaborative+Filtering)|0|
|[NLGCL: Naturally Existing Neighbor Layers Graph Contrastive Learning for Recommendation](https://doi.org/10.1145/3705328.3748059)|Jinfeng Xu, Zheyu Chen, Shuo Yang, Jinze Li, Hewei Wang, Wei Wang, Xiping Hu, Edith C. H. Ngai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NLGCL:+Naturally+Existing+Neighbor+Layers+Graph+Contrastive+Learning+for+Recommendation)|0|
|[Off-Policy Evaluation and Learning for Matching Markets](https://doi.org/10.1145/3705328.3748047)|Yudai Hayashi, Shuhei Goda, Yuta Saito||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Off-Policy+Evaluation+and+Learning+for+Matching+Markets)|0|
|[R4ec: A Reasoning, Reflection, and Refinement Framework for Recommendation Systems](https://doi.org/10.1145/3705328.3748068)|Hao Gu, Rui Zhong, Yu Xia, Wei Yang, Chi Lu, Peng Jiang, Kun Gai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=R4ec:+A+Reasoning,+Reflection,+and+Refinement+Framework+for+Recommendation+Systems)|0|
|[Scalable Data Debugging for Neighborhood-based Recommendation with Data Shapley Values](https://doi.org/10.1145/3705328.3748049)|Barrie Kersbergen, Olivier Sprangers, Bojan Karlas, Maarten de Rijke, Sebastian Schelter||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+Data+Debugging+for+Neighborhood-based+Recommendation+with+Data+Shapley+Values)|0|
|[RecPS: Privacy Risk Scoring for Recommender Systems](https://doi.org/10.1145/3705328.3748052)|Jiajie He, Yuechun Gu, Keke Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RecPS:+Privacy+Risk+Scoring+for+Recommender+Systems)|0|
|[Recommendation and Temptation](https://doi.org/10.1145/3705328.3748063)|Md Sanzeed Anwar, Paramveer S. Dhillon, Grant Schoenebeck||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recommendation+and+Temptation)|0|
|[You Don't Bring Me Flowers: Mitigating Unwanted Recommendations Through Conformal Risk Control](https://doi.org/10.1145/3705328.3748054)|Giovanni De Toni, Erasmo Purificato, Emilia Gómez, Andrea Passerini, Bruno Lepri, Cristian Consonni||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=You+Don't+Bring+Me+Flowers:+Mitigating+Unwanted+Recommendations+Through+Conformal+Risk+Control)|0|
|[A Multistakeholder Approach to Value-Driven Co-Design of Recommender Systems Evaluation Metrics in Digital Archives](https://doi.org/10.1145/3705328.3748026)|Florian AtzenhoferBaumgartner, Georg Vogeler, Dominik Kowald||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Multistakeholder+Approach+to+Value-Driven+Co-Design+of+Recommender+Systems+Evaluation+Metrics+in+Digital+Archives)|0|
|[Beyond Visit Trajectories: Enhancing POI Recommendation via LLM-Augmented Text and Image Representations](https://doi.org/10.1145/3705328.3748014)|Zehui Wang, Wolfram Höpken, Dietmar Jannach||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Visit+Trajectories:+Enhancing+POI+Recommendation+via+LLM-Augmented+Text+and+Image+Representations)|0|
|[Beyond Top-1: Addressing Inconsistencies in Evaluating Counterfactual Explanations for Recommender Systems](https://doi.org/10.1145/3705328.3748028)|Amir Reza Mohammadi, Andreas Peintner, Michael Müller, Eva Zangerle||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Top-1:+Addressing+Inconsistencies+in+Evaluating+Counterfactual+Explanations+for+Recommender+Systems)|0|
|[Consistent Explainers or Unreliable Narrators? Understanding LLM-generated Group Recommendations](https://doi.org/10.1145/3705328.3748015)|Cedric Waterschoot, Nava Tintarev, Francesco Barile||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Consistent+Explainers+or+Unreliable+Narrators?+Understanding+LLM-generated+Group+Recommendations)|0|
|[Emotion Vector-Based Fine-Tuning of Large Language Models for Age-Aware Teenage Book Recommendations](https://doi.org/10.1145/3705328.3748037)|Kate Hill, YiuKai Ng, Joey Sherrill||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Emotion+Vector-Based+Fine-Tuning+of+Large+Language+Models+for+Age-Aware+Teenage+Book+Recommendations)|0|
|[HiDePCC: A Novel Dual-Pronged Untargeted Attack on Federated Recommendation via Gradient Perturbation and Cluster Crafting](https://doi.org/10.1145/3705328.3748041)|Yamini Jha, Krishna Tewari, Sukomal Pal||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HiDePCC:+A+Novel+Dual-Pronged+Untargeted+Attack+on+Federated+Recommendation+via+Gradient+Perturbation+and+Cluster+Crafting)|0|
|[SGCL: Unifying Self-Supervised and Supervised Learning for Graph Recommendation](https://doi.org/10.1145/3705328.3748036)|Weizhi Zhang, Liangwei Yang, Zihe Song, Henry Peng Zou, Ke Xu, Yuanjie Zhu, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SGCL:+Unifying+Self-Supervised+and+Supervised+Learning+for+Graph+Recommendation)|0|
|[Are We Really Making Recommendations Robust? Revisiting Model Evaluation for Denoising Recommendation](https://doi.org/10.1145/3705328.3748153)|Guohang Zeng, Jie Lu, Guangquan Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Are+We+Really+Making+Recommendations+Robust?+Revisiting+Model+Evaluation+for+Denoising+Recommendation)|0|
|[Context Trails: A Dataset to Study Contextual and Route Recommendation](https://doi.org/10.1145/3705328.3748151)|Pablo Sánchez, Alejandro Bellogín, Jose L. JorroAragoneses||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Context+Trails:+A+Dataset+to+Study+Contextual+and+Route+Recommendation)|0|
|[GreenFoodLens: Sustainability Labels for Food Recommendation](https://doi.org/10.1145/3705328.3748165)|Giacomo Balloccu, Ludovico Boratto, Gianni Fenu, Mirko Marras, Giacomo Medda, Giovanni Murgia||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GreenFoodLens:+Sustainability+Labels+for+Food+Recommendation)|0|
|[How Powerful are LLMs to Support Multimodal Recommendation? A Reproducibility Study of LLMRec](https://doi.org/10.1145/3705328.3748154)|Maria Lucia Fioretti, Nicola Laterza, Alessia Preziosa, Daniele Malitesta, Claudio Pomo, Fedelucio Narducci, Tommaso Di Noia||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+Powerful+are+LLMs+to+Support+Multimodal+Recommendation?+A+Reproducibility+Study+of+LLMRec)|0|
|[Rethinking the Privacy of Text Embeddings: A Reproducibility Study of "Text Embeddings Reveal (Almost) As Much As Text"](https://doi.org/10.1145/3705328.3748155)|Dominykas Seputis, Yongkang Li, Karsten Langerak, Serghei Mihailov||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rethinking+the+Privacy+of+Text+Embeddings:+A+Reproducibility+Study+of+"Text+Embeddings+Reveal+(Almost)+As+Much+As+Text")|0|
|[Privacy Risks of LLM-Empowered Recommender Systems: An Inversion Attack Perspective](https://doi.org/10.1145/3705328.3748158)|Yubo Wang, Min Tang, Nuo Shen, Shujie Cui, Weiqing Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Privacy+Risks+of+LLM-Empowered+Recommender+Systems:+An+Inversion+Attack+Perspective)|0|
|[Agentic Personalisation of Cross-Channel Marketing Experiences](https://doi.org/10.1145/3705328.3748125)|Sami Abboud, Eleanor Hanna, Olivier Jeunen, Vineesha Raheja, Schaun Wheeler||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Agentic+Personalisation+of+Cross-Channel+Marketing+Experiences)|0|
|[Balanced Public Service Media Recommendation Trade-offs with a Light Carbon Footprint](https://doi.org/10.1145/3705328.3748106)|Marcel Hauck, Michael Huber, Juri Diels, David Wittenberg, Dietmar Jannach||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Balanced+Public+Service+Media+Recommendation+Trade-offs+with+a+Light+Carbon+Footprint)|0|
|[Balancing Fine-tuning and RAG: A Hybrid Strategy for Dynamic LLM Recommendation Updates](https://doi.org/10.1145/3705328.3748105)|Changping Meng, Hongyi Ling, Jianling Wang, Yifan Liu, Shuzhou Zhang, Dapeng Hong, Mingyan Gao, Onkar Dalal, Ed H. Chi, Lichan Hong, Haokai Lu, Ningren Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Balancing+Fine-tuning+and+RAG:+A+Hybrid+Strategy+for+Dynamic+LLM+Recommendation+Updates)|0|
|[LADDER: LLM-Annotated Data for Dogfooded Evaluation of Rankings](https://doi.org/10.1145/3705328.3748094)|Mattia Ottoborgo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LADDER:+LLM-Annotated+Data+for+Dogfooded+Evaluation+of+Rankings)|0|
|[LLM-Powered Nuanced Video Attribute Annotation for Enhanced Recommendations](https://doi.org/10.1145/3705328.3748103)|Boyuan Long, Yueqi Wang, Hiloni Mehta, Mick Zomnir, Omkar Pathak, Changping Meng, Ruolin Jia, Yajun Peng, Dapeng Hong, Xia Wu, Mingyan Gao, Onkar Dalal, Ningren Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LLM-Powered+Nuanced+Video+Attribute+Annotation+for+Enhanced+Recommendations)|0|
|[Not All Impressions Are Created Equal: Psychology-Informed Retention Optimization for Short-Form Video Recommendation](https://doi.org/10.1145/3705328.3748122)|Yuyan Wang, Jing Zhong, Yuxin Cui, Zhaohui Guo, Chuanqi Wei, Yanchen Wang, Zellux Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Not+All+Impressions+Are+Created+Equal:+Psychology-Informed+Retention+Optimization+for+Short-Form+Video+Recommendation)|0|
|[Operational Twin-Driven AI Recommender for Strategic Service Planning](https://doi.org/10.1145/3705328.3748099)|Vivek Singh, Sarith Mohan, Chetan Srinidhi, Santosh Pai, Ullaskrishnan Poikavila, Codruta Ene, Ankur Kapoor, Neil Biehn, Dorin Comaniciu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Operational+Twin-Driven+AI+Recommender+for+Strategic+Service+Planning)|0|
|[RADAR: Recall Augmentation through Deferred Asynchronous Retrieval](https://doi.org/10.1145/3705328.3748146)|Amit Jaspal, Qian Dang, Ajantha Ramineni||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RADAR:+Recall+Augmentation+through+Deferred+Asynchronous+Retrieval)|0|
|[Describe What You See with Multimodal Large Language Models to Enhance Video Recommendations](https://doi.org/10.1145/3705328.3759303)|Marco De Nadai, Andreas Damianou, Mounia Lalmas||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Describe+What+You+See+with+Multimodal+Large+Language+Models+to+Enhance+Video+Recommendations)|0|
|[eSASRec: Enhancing Transformer-based Recommendations in a Modular Fashion](https://doi.org/10.1145/3705328.3759317)|Daria Tikhonovich, Nikita Zelinskiy, Aleksandr V. Petrov, Mayya Spirina, Andrei Semenov, Andrey V. Savchenko, Sergei Kuliev||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=eSASRec:+Enhancing+Transformer-based+Recommendations+in+a+Modular+Fashion)|0|
|[Evaluating Podcast Recommendations with Profile-Aware LLM-as-a-Judge](https://doi.org/10.1145/3705328.3759305)|Francesco Fabbri, Gustavo Penha, Edoardo D'Amico, Alice Wang, Marco De Nadai, Jackie Doremus, Paul Gigioli, Andreas Damianou, Oskar Stål, Mounia Lalmas||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Evaluating+Podcast+Recommendations+with+Profile-Aware+LLM-as-a-Judge)|0|
|[Fine-tuning for Inference-efficient Calibrated Recommendations](https://doi.org/10.1145/3705328.3759319)|Oleg Lesota, Adrian Bajko, Max Walder, Matthias Wenzel, Antonela Tommasel, Markus Schedl||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fine-tuning+for+Inference-efficient+Calibrated+Recommendations)|0|
|[How Fair is Your Diffusion Recommender Model?](https://doi.org/10.1145/3705328.3759318)|Daniele Malitesta, Giacomo Medda, Erasmo Purificato, Mirko Marras, Fragkiskos D. Malliaros, Ludovico Boratto||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+Fair+is+Your+Diffusion+Recommender+Model?)|0|
|[Investigating Carbon Footprint of Recommender Systems Beyond Training Time](https://doi.org/10.1145/3705328.3759324)|Josef Schodl, Oleg Lesota, Antonela Tommasel, Markus Schedl||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Investigating+Carbon+Footprint+of+Recommender+Systems+Beyond+Training+Time)|0|
|[Learning geometry-aware recommender systems with manifold regularization](https://doi.org/10.1145/3705328.3759323)|Zaira Zainulabidova, Julia Borisova, Alexander Hvatov||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+geometry-aware+recommender+systems+with+manifold+regularization)|0|
|[Leveraging Geometric Insights in Hyperbolic Triplet Loss for Improved Recommendations](https://doi.org/10.1145/3705328.3759328)|Viacheslav Yusupov, Maxim Rakhuba, Evgeny Frolov||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Geometric+Insights+in+Hyperbolic+Triplet+Loss+for+Improved+Recommendations)|0|
|[Lift It Up Right: A Recommender System for Safer Lifting Postures](https://doi.org/10.1145/3705328.3759314)|Gaetano Dibenedetto, Pasquale Lops, Marco Polignano, Helma Torkamaan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Lift+It+Up+Right:+A+Recommender+System+for+Safer+Lifting+Postures)|0|
|[Normative Alignment of Recommender Systems via Internal Label Shift](https://doi.org/10.1145/3705328.3759309)|Johannes Kruse, Kasper Lindskow, Michael Riis Andersen, Ryotaro Shimizu, Julian J. McAuley, PierreAlexandre Mattei, Jes Frellsen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Normative+Alignment+of+Recommender+Systems+via+Internal+Label+Shift)|0|
|[Recommendation Is a Dish Better Served Warm](https://doi.org/10.1145/3705328.3759331)|Danil Gusak, Nikita Sukhorukov, Evgeny Frolov||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recommendation+Is+a+Dish+Better+Served+Warm)|0|
|[Recurrent Autoregressive Linear Model for Next-Basket Recommendation](https://doi.org/10.1145/3705328.3759313)|Tereza Zmeskalová, Antoine Ledent, Martin Spisák, Pavel Kordík, Rodrigo Alves||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recurrent+Autoregressive+Linear+Model+for+Next-Basket+Recommendation)|0|
|[RicciFlowRec: A Geometric Root Cause Recommender Using Ricci Curvature on Financial Graphs](https://doi.org/10.1145/3705328.3759312)|Zhongtian Sun, Anoushka Harit||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RicciFlowRec:+A+Geometric+Root+Cause+Recommender+Using+Ricci+Curvature+on+Financial+Graphs)|0|
|[The Hidden Cost of Defaults in Recommender System Evaluation](https://doi.org/10.1145/3705328.3759321)|Hannah Berling, Robin Svahn, Alan Said||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Hidden+Cost+of+Defaults+in+Recommender+System+Evaluation)|0|
|[ArtAICare: An End-to-End Platform for Personalized Art Therapy](https://doi.org/10.1145/3705328.3759338)|Bereket Abera Yilma, Saravanakumar Duraisamy, Stefan Penchev, Tudor Pristav, Luis A. Leiva||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ArtAICare:+An+End-to-End+Platform+for+Personalized+Art+Therapy)|0|
|[Blooming Beats: An Interactive Music Recommender System Grounded in TRACE Principles and Data Humanism](https://doi.org/10.1145/3705328.3759337)|Ibrahim Al Hazwani, Daniel Lutziger, Carlos Kirchdorfer, Luca Huber, Oliver Robin Aschwanden, Jürgen Bernard, Ludovico Boratto||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Blooming+Beats:+An+Interactive+Music+Recommender+System+Grounded+in+TRACE+Principles+and+Data+Humanism)|0|
|[Large Language Model-based Recommendation System Agents](https://doi.org/10.1145/3705328.3759334)|Tommaso Carraro, Brijraj Singh, Niranjan Pedanekar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large+Language+Model-based+Recommendation+System+Agents)|0|
|[PRISM: From Individual Preferences to Group Consensus through Conversational AI-Mediated and Visual Explanations](https://doi.org/10.1145/3705328.3759340)|Ibrahim Al Hazwani, Oliver Robin Aschwanden, Oana Inel, Jürgen Bernard, Ludovico Boratto||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PRISM:+From+Individual+Preferences+to+Group+Consensus+through+Conversational+AI-Mediated+and+Visual+Explanations)|0|
|[Travel Together, Play Together: Gamifying a Group Recommender System for Tourism](https://doi.org/10.1145/3705328.3759344)|Patrícia Alves, Joana Neto, Jorge Lima, José Silva, Luís Conceição, Goreti Marreiros||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Travel+Together,+Play+Together:+Gamifying+a+Group+Recommender+System+for+Tourism)|0|
|[Beyond Algorithms: Reclaiming the Interdisciplinary Roots of Recommender Systems (BEYOND 2025)](https://doi.org/10.1145/3705328.3747998)|Eva Zangerle, Alan Said, Christine Bauer||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Algorithms:+Reclaiming+the+Interdisciplinary+Roots+of+Recommender+Systems+(BEYOND+2025))|0|
|[A Tutorial on Agentic LLM for Recommender Systems](https://doi.org/10.1145/3705328.3748007)|Chengkai Huang, Junda Wu, Tong Yu, Julian J. McAuley, Lina Yao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Tutorial+on+Agentic+LLM+for+Recommender+Systems)|0|
|[A Hands-on Dive Into Quantum Computing for Recommender Systems](https://doi.org/10.1145/3705328.3748006)|Maurizio Ferrari Dacrema, Paolo Cremonesi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Hands-on+Dive+Into+Quantum+Computing+for+Recommender+Systems)|0|
|[Standard Practices for Data Processing and Multimodal Feature Extraction in Recommendation with DataRec and Ducho (D&D4Rec)](https://doi.org/10.1145/3705328.3748009)|Alberto Carlo Maria Mancino, Matteo Attimonelli, Angela Di Fazio, Daniele Malitesta, Tommaso Di Noia||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Standard+Practices+for+Data+Processing+and+Multimodal+Feature+Extraction+in+Recommendation+with+DataRec+and+Ducho+(D&D4Rec))|0|
|[Adding Value to Low-Resource Industrial Recommender Systems](https://doi.org/10.1145/3705328.3748760)|Cornelia M. Kloppers||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adding+Value+to+Low-Resource+Industrial+Recommender+Systems)|0|
|[Addressing Multi-stakeholder Fairness Concerns in Recommender Systems Through Social Choice](https://doi.org/10.1145/3705328.3748756)|Amanda Aird||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Addressing+Multi-stakeholder+Fairness+Concerns+in+Recommender+Systems+Through+Social+Choice)|0|
|[Are Recommender Systems Serving Children? Toward Child-Aware Design and Evaluation](https://doi.org/10.1145/3705328.3748752)|Robin Ungruh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Are+Recommender+Systems+Serving+Children?+Toward+Child-Aware+Design+and+Evaluation)|0|
|[Bayesian Perspectives on Offline Evaluation for Recommender Systems](https://doi.org/10.1145/3705328.3748762)|Michael Benigni||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bayesian+Perspectives+on+Offline+Evaluation+for+Recommender+Systems)|0|
|[Beyond Persuasion: Adaptive Warnings and Balanced Explanations for Informed Decision-Making in Recommender Systems](https://doi.org/10.1145/3705328.3748758)|Elaheh Jafari||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Persuasion:+Adaptive+Warnings+and+Balanced+Explanations+for+Informed+Decision-Making+in+Recommender+Systems)|0|
|[Challenges in Perfume Recommender Systems: Navigating Subjectivity, Context and Sensory Data](https://doi.org/10.1145/3705328.3748754)|ElenaRuxandra Lutan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Challenges+in+Perfume+Recommender+Systems:+Navigating+Subjectivity,+Context+and+Sensory+Data)|0|
|[Fair and Transparent Recommender Systems for Advertisements](https://doi.org/10.1145/3705328.3748755)|Dina Zilbershtein||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fair+and+Transparent+Recommender+Systems+for+Advertisements)|0|
|[Full-Page Recommender: A Modular Framework for Multi-Carousel Recommendations](https://doi.org/10.1145/3705328.3748753)|Jan Kislinger||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Full-Page+Recommender:+A+Modular+Framework+for+Multi-Carousel+Recommendations)|0|
|[Narrative-Driven Itinerary Recommendation: LLM Integration for Immersive Urban Walking](https://doi.org/10.1145/3705328.3748751)|Fabio Ferrero||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Narrative-Driven+Itinerary+Recommendation:+LLM+Integration+for+Immersive+Urban+Walking)|0|
|[Item-centric Exploration for Cold Start Problem](https://doi.org/10.1145/3705328.3748113)|Dong Wang, Junyi Jiao, Arnab Bhadury, Yaping Zhang, Mingyan Gao, Onkar Dalal||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Item-centric+Exploration+for+Cold+Start+Problem)|0|
|[Cold Starting a New Content Type: A Case Study with Netflix Live](https://doi.org/10.1145/3705328.3748112)|Yunan Hu, Mark Thornburg, Mario GarcíaArmas, Vito Ostuni, Anne Cocos, Kriti Kohli, Christoph Kofler, Rob Saltiel||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cold+Starting+a+New+Content+Type:+A+Case+Study+with+Netflix+Live)|0|
|[Zero-shot Cross-domain Knowledge Distillation: A Case study on YouTube Music](https://doi.org/10.1145/3705328.3748138)|Srivaths Ranganathan, Chieh Lo, Bernardo Cunha, Nikhil Khani, Li Wei, Aniruddh Nath, Shawn Andrews, Gergo Varady, Yanwei Song, Jochen Klingenhoefer, Tim Steele||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Zero-shot+Cross-domain+Knowledge+Distillation:+A+Case+study+on+YouTube+Music)|0|
|[PAIRSAT: Integrating Preference-Based Signals for User Satisfaction Estimation in Dialogue Systems](https://doi.org/10.1145/3705328.3759325)|Eran Fainman, Adir Solomon, Osnat Mokryn||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PAIRSAT:+Integrating+Preference-Based+Signals+for+User+Satisfaction+Estimation+in+Dialogue+Systems)|0|
|[PinFM: Foundation Model for User Activity Sequences at a Billion-scale Visual Discovery Platform](https://doi.org/10.1145/3705328.3748050)|Xiangyi Chen, Kousik Rajesh, Matthew Lawhon, Zelun Wang, Hanyu Li, Haomiao Li, Saurabh Vishwas Joshi, Pong Eksombatchai, Jaewon Yang, YiPing Hsu, Jiajing Xu, Charles Rosenberg||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PinFM:+Foundation+Model+for+User+Activity+Sequences+at+a+Billion-scale+Visual+Discovery+Platform)|0|
|[Feedback-Driven Gradual Discovery for Expanding Musical Preferences](https://doi.org/10.1145/3705328.3748025)|Alec Nonnemaker, Ralvi Isufaj, Zoltán Szlávik, Cynthia Liem||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Feedback-Driven+Gradual+Discovery+for+Expanding+Musical+Preferences)|0|
|[The XITE Million Sessions Dataset](https://doi.org/10.1145/3705328.3748168)|Ralvi Isufaj, Ruslan Tsygankov, Zoltán Szlávik||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+XITE+Million+Sessions+Dataset)|0|
|[Closing the Online-Offline Gap: A Scalable Framework for Composed Model Evaluation](https://doi.org/10.1145/3705328.3748117)|Mahanth Kumar Beeraka, Chen Chen, Yining Lu, Briac Marcatte, Weikun Lyu, Brooke Bian, Enriko Aryanto, Ellie Wen, Mohamed A. Radwan, Tianshan Cui, Wenjing Lu, Mohsen Malmir, Yang Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Closing+the+Online-Offline+Gap:+A+Scalable+Framework+for+Composed+Model+Evaluation)|0|
|[SASRec in Action: Real-World Adaptations for ZDF Streaming Service](https://doi.org/10.1145/3705328.3748097)|Venkata Harshit Koneru, Xenija Neufeld, Sebastian Loth, Andreas Grün||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SASRec+in+Action:+Real-World+Adaptations+for+ZDF+Streaming+Service)|0|
|[Scaling Image Variant Optimization Through Customer Bucketing and Response Caching: A Large-Scale Implementation at Amazon Prime Video](https://doi.org/10.1145/3705328.3748134)|Haiyun Jin, Bobby Patel||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scaling+Image+Variant+Optimization+Through+Customer+Bucketing+and+Response+Caching:+A+Large-Scale+Implementation+at+Amazon+Prime+Video)|0|
|[Streaming Trends: A Low-Latency Platform for Dynamic Video Grouping and Trending Corpora Building](https://doi.org/10.1145/3705328.3748120)|Yang Gu, Caroline Zhou, Qiao Zhang, Scott Wang, Yongzhe Wang, Li Zhang, Nikos Parotsidis, CJ Carey, Ashkan Fard, Mingyan Gao, Yaping Zhang, Sourabh Bansod||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Streaming+Trends:+A+Low-Latency+Platform+for+Dynamic+Video+Grouping+and+Trending+Corpora+Building)|0|
|[Balancing Accuracy and Novelty with Sub-Item Popularity](https://doi.org/10.1145/3705328.3759311)|Chiara Mallamaci, Aleksandr V. Petrov, Alberto Carlo Maria Mancino, Vito Walter Anelli, Tommaso Di Noia, Craig Macdonald||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Balancing+Accuracy+and+Novelty+with+Sub-Item+Popularity)|0|
|[Meta Off-Policy Estimation](https://doi.org/10.1145/3705328.3759308)|Olivier Jeunen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Meta+Off-Policy+Estimation)|0|
|[Mitigating Popularity Bias in Counterfactual Explanations using Large Language Models](https://doi.org/10.1145/3705328.3759330)|Arjan Hasami, Masoud Mansoury||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mitigating+Popularity+Bias+in+Counterfactual+Explanations+using+Large+Language+Models)|0|
|[Probabilistic Modeling, Learnability and Uncertainty Estimation for Interaction Prediction in Movie Rating Datasets](https://doi.org/10.1145/3705328.3759332)|Jennifer Poernomo, Nicole Gabrielle Lee Tan, Rodrigo Alves, Antoine Ledent||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Probabilistic+Modeling,+Learnability+and+Uncertainty+Estimation+for+Interaction+Prediction+in+Movie+Rating+Datasets)|0|
|[t-Testing the Waters: Empirically Validating Assumptions for Reliable A/B-Testing](https://doi.org/10.1145/3705328.3759307)|Olivier Jeunen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=t-Testing+the+Waters:+Empirically+Validating+Assumptions+for+Reliable+A/B-Testing)|0|
|[APS Explorer: Navigating Algorithm Performance Spaces for Informed Dataset Selection](https://doi.org/10.1145/3705328.3759342)|Tobias Vente, Michael Heep, Abdullah Abbas, Theodor Sperle, Joeran Beel, Bart Goethals||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=APS+Explorer:+Navigating+Algorithm+Performance+Spaces+for+Informed+Dataset+Selection)|0|
|[Multi-Armed Bandits in the Wild](https://doi.org/10.1145/3705328.3748005)|Kim Falk||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Armed+Bandits+in+the+Wild)|0|
|[Multi-Granularity Distribution Modeling for Video Watch Time Prediction via Exponential-Gaussian Mixture Network](https://doi.org/10.1145/3705328.3748080)|Xu Zhao, Ruibo Ma, Jiaqi Chen, Weiqi Zhao, Ping Yang, Yao Hu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Granularity+Distribution+Modeling+for+Video+Watch+Time+Prediction+via+Exponential-Gaussian+Mixture+Network)|0|
|[Prompt-to-Slate: Diffusion Models for Prompt-Conditioned Slate Generation](https://doi.org/10.1145/3705328.3748072)|Federico Tomasi, Francesco Fabbri, Justin Carter, Elias Kalomiris, Mounia Lalmas, Zhenwen Dai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Prompt-to-Slate:+Diffusion+Models+for+Prompt-Conditioned+Slate+Generation)|0|
|[Rethinking Overconfidence in VAEs: Can Label Smoothing Help?](https://doi.org/10.1145/3705328.3748039)|WooSeong Yun, Yeojun Choi, YoonSik Cho||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rethinking+Overconfidence+in+VAEs:+Can+Label+Smoothing+Help?)|0|
|[Stairway to Fairness: Connecting Group and Individual Fairness](https://doi.org/10.1145/3705328.3748031)|Theresia Veronika Rampisela, Maria Maistro, Tuukka Ruotsalo, Falk Scholer, Christina Lioma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Stairway+to+Fairness:+Connecting+Group+and+Individual+Fairness)|0|
|[See the Movie, Hear the Song, Read the Book: Extending MovieLens-1M, Last.fm-2K, and DBbook with Multimodal Data](https://doi.org/10.1145/3705328.3748162)|Giuseppe Spillo, Elio Musacchio, Cataldo Musto, Marco de Gemmis, Pasquale Lops, Giovanni Semeraro||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=See+the+Movie,+Hear+the+Song,+Read+the+Book:+Extending+MovieLens-1M,+Last.fm-2K,+and+DBbook+with+Multimodal+Data)|0|
|[Efficient Off-Policy Evaluation of Content Blending in Station-Based Music Experiences](https://doi.org/10.1145/3705328.3748114)|Chelsea Weaver, Arvind Balasubramanian, Juan Borgnino, Ben London||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Off-Policy+Evaluation+of+Content+Blending+in+Station-Based+Music+Experiences)|0|
|[Kamae: Bridging Spark and Keras for Seamless ML Preprocessing](https://doi.org/10.1145/3705328.3748126)|George Barrowclough, Marian Andrecki, James Shinner, Daniele Donghi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Kamae:+Bridging+Spark+and+Keras+for+Seamless+ML+Preprocessing)|0|
|[Metadata Generation and Evaluation using LLMs - Case Study on Canonical Titles](https://doi.org/10.1145/3705328.3748100)|Sinan Zhu, Sanja Simonovikj, Darren Edmonds, Yang Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Metadata+Generation+and+Evaluation+using+LLMs+-+Case+Study+on+Canonical+Titles)|0|
|[Never Miss an Episode: How LLMs are Powering Serial Content Discovery on YouTube](https://doi.org/10.1145/3705328.3748104)|Aditee Kumthekar, Li Wei, Andrea Bettale, Mahesh Sathiamoorthy, Zrinka Puljiz, Aditya Mahajan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Never+Miss+an+Episode:+How+LLMs+are+Powering+Serial+Content+Discovery+on+YouTube)|0|
|[Pareto-Optimal Solution: Optimizing Engagement and Revenue](https://doi.org/10.1145/3705328.3748142)|Shaghayegh Agah, Shaun Schaeffer, Maria Peifer, Neeraj Sharma, Ankit Maheshwari, Sardar Hamidian||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pareto-Optimal+Solution:+Optimizing+Engagement+and+Revenue)|0|
|[Simulating Discoverability for Upcoming Content in TV Entertainment Platforms](https://doi.org/10.1145/3705328.3748137)|Adeep Hande, Kishorekumar Sundararajan, Yidnekachew Endale, Sardar Hamidian||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Simulating+Discoverability+for+Upcoming+Content+in+TV+Entertainment+Platforms)|0|
|[Interactive Playlist Generation from Titles](https://doi.org/10.1145/3705328.3759336)|Eléa Vellard, Enzo CharoloisPasqua, Youssra Rebboud, Pasquale Lisena, Raphaël Troncy||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interactive+Playlist+Generation+from+Titles)|0|

# RECSYS2025 Paper List

|论文|作者|组织|摘要|翻译|代码|引用数|
|---|---|---|---|---|---|---|
|[Test-Time Alignment with State Space Model for Tracking User Interest Shifts in Sequential Recommendation](https://doi.org/10.1145/3705328.3748060)|Changshuo Zhang, Xiao Zhang, Teng Shi, Jun Xu, JiRong Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Test-Time+Alignment+with+State+Space+Model+for+Tracking+User+Interest+Shifts+in+Sequential+Recommendation)|3|
|[Time to Split: Exploring Data Splitting Strategies for Offline Evaluation of Sequential Recommenders](https://doi.org/10.1145/3705328.3748164)|Danil Gusak, Anna Volodkevich, Anton Klenitskiy, Alexey Vasilev, Evgeny Frolov||Modern sequential recommender systems, ranging from lightweight transformer-based variants to large language models, have become increasingly prominent in academia and industry due to their strong performance in the next-item prediction task. Yet common evaluation protocols for sequential recommendations remain insufficiently developed: they often fail to reflect the corresponding recommendation task accurately, or are not aligned with real-world scenarios. Although the widely used leave-one-out split matches next-item prediction, it permits the overlap between training and test periods, which leads to temporal leakage and unrealistically long test horizon, limiting real-world relevance. Global temporal splitting addresses these issues by evaluating on distinct future periods. However, its applications to sequential recommendations remain loosely defined, particularly in terms of selecting target interactions and constructing a validation subset that provides necessary consistency between validation and test metrics. In this paper, we demonstrate that evaluation outcomes can vary significantly across splitting strategies, influencing model rankings and practical deployment decisions. To improve reproducibility in both academic and industrial settings, we systematically compare different splitting strategies for sequential recommendations across multiple datasets and established baselines. Our findings show that prevalent splits, such as leave-one-out, may be insufficiently aligned with more realistic evaluation strategies. Code: https://github.com/monkey0head/time-to-split|现代序列推荐系统——从基于轻量级Transformer的变体到大型语言模型——因其在下一项预测任务中的优异表现，正日益成为学术界与工业界的焦点。然而当前的序列推荐通用评估方案仍存在明显不足：它们往往无法准确反映对应的推荐任务特性，或与真实应用场景存在偏差。尽管广泛采用的留一法划分与下一项预测任务相匹配，但该方法允许训练集与测试集的时间段重叠，导致时序数据泄露和失真的长测试周期，削弱了实际应用价值。全局时序划分通过评估独立未来时段解决了这些问题，但其在序列推荐中的应用定义仍显松散，特别是在选择目标交互行为及构建能确保验证集与测试集指标一致性的验证子集方面。本文通过实验证明，不同划分策略会导致评估结果显著差异，进而影响模型排序与实际部署决策。为提升学术研究与工业应用的可复现性，我们系统比较了多种数据集和主流基线模型下的序列推荐划分策略。研究结果表明，留一法等主流划分方式与更贴近现实的评估策略存在明显偏差。代码已开源：https://github.com/monkey0head/time-to-split|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Time+to+Split:+Exploring+Data+Splitting+Strategies+for+Offline+Evaluation+of+Sequential+Recommenders)|2|
|[The Future is Sparse: Embedding Compression for Scalable Retrieval in Recommender Systems](https://doi.org/10.1145/3705328.3748147)|Petr Kasalický, Martin Spisák, Vojtech Vancura, Daniel Bohunek, Rodrigo Alves, Pavel Kordík||Industry-scale recommender systems face a core challenge: representing entities with high cardinality, such as users or items, using dense embeddings that must be accessible during both training and inference. However, as embedding sizes grow, memory constraints make storage and access increasingly difficult. We describe a lightweight, learnable embedding compression technique that projects dense embeddings into a high-dimensional, sparsely activated space. Designed for retrieval tasks, our method reduces memory requirements while preserving retrieval performance, enabling scalable deployment under strict resource constraints. Our results demonstrate that leveraging sparsity is a promising approach for improving the efficiency of large-scale recommenders. We release our code at https://github.com/recombee/CompresSAE.|工业级推荐系统面临一个核心挑战：如何用稠密嵌入表示高基数实体（如用户或商品），且这些嵌入需在训练和推理阶段均可访问。然而随着嵌入维度增长，内存限制使得存储与访问日益困难。我们提出一种轻量级可学习的嵌入压缩技术，将稠密嵌入投影到高维稀疏激活空间。该方法专为检索任务设计，在保持检索性能的同时显著降低内存需求，实现在严格资源约束下的可扩展部署。实验结果表明，利用稀疏性是提升大规模推荐系统效率的有效途径。代码已发布于 https://github.com/recombee/CompresSAE。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Future+is+Sparse:+Embedding+Compression+for+Scalable+Retrieval+in+Recommender+Systems)|1|
|[Fashion-AlterEval: A Dataset for Improved Evaluation of Conversational Recommendation Systems with Alternative Relevant Items](https://doi.org/10.1145/3705328.3748149)|Maria Vlachou||In Conversational Recommendation Systems (CRS), a user provides feedback on recommended items at each turn, leading the CRS towards improved recommendations. Due to the need for a large amount of data, a user simulator is employed for both training and evaluation. Such user simulators critique the current retrieved item based on knowledge of a single target item. However, system evaluation in offline settings with simulators is limited by the focus on a single target item and their unlimited patience over a large number of turns. To overcome these limitations of existing simulators, we propose Fashion-AlterEval, a new dataset that contains human judgments for a selection of alternative items by adding new annotations in common fashion CRS datasets. Consequently, we propose two novel meta-user simulators that use the collected judgments and allow simulated users not only to express their preferences about alternative items to their original target, but also to change their mind and level of patience. In our experiments using the Shoes and Fashion IQ as the original datasets and three CRS models, we find that using the knowledge of alternatives by the simulator can have a considerable impact on the evaluation of existing CRS models, specifically that the existing single-target evaluation underestimates their effectiveness, and when simulatedusers are allowed to instead consider alternative relevant items, the system can rapidly respond to more quickly satisfy the user.|在对话推荐系统（CRS）中，用户会在每个交互轮次对推荐项目提供反馈，从而引导系统持续优化推荐效果。由于需要大量数据支撑，用户模拟器被广泛应用于训练和评估环节。现有模拟器通常基于单一目标项目的认知对当前检索到的项目进行评价。然而，这种基于单一目标项目且允许无限轮次交互的离线评估方式存在明显局限。为突破现有模拟器的限制，我们提出Fashion-AlterEval数据集——通过在常见时尚对话推荐数据集上新增标注，构建包含人类对备选项目判断的全新数据集。基于此，我们进一步设计了两类新型元用户模拟器：这些模拟器不仅能利用收集到的判断数据表达对原始目标项目之外其他备选项目的偏好，还支持模拟用户改变心意并调整其耐心阈值。在以Shoes和Fashion IQ作为原始数据集、采用三种CRS模型的实验中，我们发现模拟器引入备选项目认知会对现有CRS模型评估产生显著影响——具体表现为：传统单一目标评估方式会低估系统效能，而当模拟用户被允许考虑其他相关备选项目时，系统能更快响应并满足用户需求。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fashion-AlterEval:+A+Dataset+for+Improved+Evaluation+of+Conversational+Recommendation+Systems+with+Alternative+Relevant+Items)|1|
|[Enhancing Embedding Representation Stability in Recommendation Systems with Semantic ID](https://doi.org/10.1145/3705328.3748123)|Carolina Zheng, Minhui Huang, Dmitrii Pedchenko, Kaushik Rangadurai, Siyu Wang, Fan Xia, Gaby Nahum, Jie Lei, Yang Yang, Tao Liu, Zutian Luo, Xiaohan Wei, Dinesh Ramasamy, Jiyan Yang, Yiping Han, Lin Yang, Hangjun Xu, Rong Jin, Shuang Yang||The exponential growth of online content has posed significant challenges to ID-based models in industrial recommendation systems, ranging from extremely high cardinality and dynamically growing ID space, to highly skewed engagement distributions, to prediction instability as a result of natural id life cycles (e.g, the birth of new IDs and retirement of old IDs). To address these issues, many systems rely on random hashing to handle the id space and control the corresponding model parameters (i.e embedding table). However, this approach introduces data pollution from multiple ids sharing the same embedding, leading to degraded model performance and embedding representation instability. This paper examines these challenges and introduces Semantic ID prefix ngram, a novel token parameterization technique that significantly improves the performance of the original Semantic ID. Semantic ID prefix ngram creates semantically meaningful collisions by hierarchically clustering items based on their content embeddings, as opposed to random assignments. Through extensive experimentation, we demonstrate that Semantic ID prefix ngram not only addresses embedding instability but also significantly improves tail id modeling, reduces overfitting, and mitigates representation shifts. We further highlight the advantages of Semantic ID prefix ngram in attention-based models that contextualize user histories, showing substantial performance improvements. We also report our experience of integrating Semantic ID into Meta production Ads Ranking system, leading to notable performance gains and enhanced prediction stability in live deployments.|在线内容的指数级增长给工业推荐系统中的ID类模型带来重大挑战：包括极高的特征维度、动态扩张的ID空间、高度倾斜的交互分布，以及因ID自然生命周期（如新ID产生和旧ID淘汰）导致的预测不稳定。为应对这些问题，现有系统多采用随机哈希处理ID空间并控制相应模型参数（即嵌入表）。然而这种方法会因多个ID共享同一嵌入向量引发数据污染，导致模型性能下降和嵌入表示不稳定。本文系统剖析这些挑战后，提出语义ID前缀n元组——一种创新的令牌参数化技术，能显著提升原始语义ID的性能。该技术通过基于内容嵌入的层次化聚类实现有语义意义的碰撞，取代随机分配机制。大量实验表明，语义ID前缀n元组不仅能解决嵌入不稳定问题，还可显著改善尾部ID建模、减少过拟合现象并缓解表示偏移。我们进一步揭示了该技术在基于注意力的用户历史上下文模型中优势，展现出显著的性能提升。文中还分享了将语义ID集成至Meta广告排序生产系统的实践经验，在线上部署中实现了显著效果提升和预测稳定性增强。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Embedding+Representation+Stability+in+Recommendation+Systems+with+Semantic+ID)|1|
|[Exploring the Effect of Context-Awareness and Popularity Calibration on Popularity Bias in POI Recommendations](https://doi.org/10.1145/3705328.3748017)|Andrea Forster, Simone Kopeinik, Denis Helic, Stefan Thalmann, Dominik Kowald||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+the+Effect+of+Context-Awareness+and+Popularity+Calibration+on+Popularity+Bias+in+POI+Recommendations)|1|
|[Impacts of Mainstream-Driven Algorithms on Recommendations for Children Across Domains: A Reproducibility Study](https://doi.org/10.1145/3705328.3748160)|Robin Ungruh, Alejandro Bellogín, Dominik Kowald, Maria Soledad Pera||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Impacts+of+Mainstream-Driven+Algorithms+on+Recommendations+for+Children+Across+Domains:+A+Reproducibility+Study)|1|
|[Affect-aware Cross-Domain Recommendation for Art Therapy via Music Preference Elicitation](https://doi.org/10.1145/3705328.3748084)|Bereket Abera Yilma, Luis A. Leiva||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Affect-aware+Cross-Domain+Recommendation+for+Art+Therapy+via+Music+Preference+Elicitation)|1|
|[A Language Model-Based Playlist Generation Recommender System](https://doi.org/10.1145/3705328.3748053)|Enzo CharoloisPasqua, Eléa Vellard, Youssra Rebboud, Pasquale Lisena, Raphaël Troncy||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Language+Model-Based+Playlist+Generation+Recommender+System)|1|
|[D-RDW: Diversity-Driven Random Walks for News Recommender Systems](https://doi.org/10.1145/3705328.3748016)|Runze Li, Lucien Heitz, Oana Inel, Abraham Bernstein||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=D-RDW:+Diversity-Driven+Random+Walks+for+News+Recommender+Systems)|1|
|[Counterfactual Inference under Thompson Sampling](https://doi.org/10.1145/3705328.3748011)|Olivier Jeunen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Counterfactual+Inference+under+Thompson+Sampling)|1|
|[Scaling Retrieval for Web-Scale Recommenders: Lessons from Inverted Indexes to Embedding Search](https://doi.org/10.1145/3705328.3748116)|Yuchin Juan, Jianqiang Shen, Shaobo Zhang, Qianqi Shen, Caleb Johnson, Luke Simon, Liangjie Hong, Wenjing Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scaling+Retrieval+for+Web-Scale+Recommenders:+Lessons+from+Inverted+Indexes+to+Embedding+Search)|0|
|[Contrastive Conditional Embeddings for Item-based Recommendation at E-commerce Scale](https://doi.org/10.1145/3705328.3748095)|Akira Fukumoto, Aghiles Salah, Sarthak Shrivastava, Alexandru Tatar, Yannick Schwartz, Vincent Michel, Lee Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Conditional+Embeddings+for+Item-based+Recommendation+at+E-commerce+Scale)|0|
|[Beyond Immediate Click: Engagement-Aware and MoE-Enhanced Transformers for Sequential Movie Recommendation](https://doi.org/10.1145/3705328.3748076)|Haotian Jiang, Sibendu Paul, Haiyang Zhang, Caren Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Immediate+Click:+Engagement-Aware+and+MoE-Enhanced+Transformers+for+Sequential+Movie+Recommendation)|0|
|[GenSAR: Unifying Balanced Search and Recommendation with Generative Retrieval](https://doi.org/10.1145/3705328.3748071)|Teng Shi, Jun Xu, Xiao Zhang, Xiaoxue Zang, Kai Zheng, Yang Song, Enyun Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GenSAR:+Unifying+Balanced+Search+and+Recommendation+with+Generative+Retrieval)|0|
|[Do We Really Need Specialization? Evaluating Generalist Text Embeddings for Zero-Shot Recommendation and Search](https://doi.org/10.1145/3705328.3748040)|Matteo Attimonelli, Alessandro De Bellis, Claudio Pomo, Dietmar Jannach, Eugenio Di Sciascio, Tommaso Di Noia||Pre-trained language models (PLMs) are widely used to derive semantic representations from item metadata in recommendation and search. In sequential recommendation, PLMs enhance ID-based embeddings through textual metadata, while in product search, they align item characteristics with user intent. Recent studies suggest task and domain-specific fine-tuning are needed to improve representational power. This paper challenges this assumption, showing that Generalist Text Embedding Models (GTEs), pre-trained on large-scale corpora, can guarantee strong zero-shot performance without specialized adaptation. Our experiments demonstrate that GTEs outperform traditional and fine-tuned models in both sequential recommendation and product search. We attribute this to a superior representational power, as they distribute features more evenly across the embedding space. Finally, we show that compressing embedding dimensions by focusing on the most informative directions (e.g., via PCA) effectively reduces noise and improves the performance of specialized models. To ensure reproducibility, we provide our repository at https://split.to/gte4ps.|预训练语言模型（PLM）在推荐和搜索系统中被广泛用于从物品元数据中提取语义表示。在序列推荐任务中，PLM通过文本元数据增强基于ID的嵌入表示；而在商品搜索场景中，它们将物品特性与用户意图进行对齐。现有研究通常认为需要通过任务和领域特定的微调来提升表征能力。本文对此假设提出挑战，证明在大规模语料上预训练的通用文本嵌入模型（GTE）无需专门适配即可保证强大的零样本性能。实验结果表明，GTE在序列推荐和商品搜索任务中均优于传统模型及微调模型。我们将其归因于更优越的表征能力——这些模型能将特征更均匀地分布在嵌入空间中。最后，我们证实通过聚焦信息量最大的方向（如主成分分析法）压缩嵌入维度，可有效降低噪声并提升专用模型性能。为保障可复现性，我们已在 https://split.to/gte4ps 公开代码库。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Do+We+Really+Need+Specialization?+Evaluating+Generalist+Text+Embeddings+for+Zero-Shot+Recommendation+and+Search)|0|
|[Determinants of Users' Chance-Seeking Behavior in Search-Based Recommendation](https://doi.org/10.1145/3705328.3748019)|Yuki Ninomiya, Yutaro Sone, Kazuhisa Miwa, Yuichiro Sumi, Ryosuke Nakanishi, Eiji Mitsuda, Koji Sato, Tadashi Odashima||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Determinants+of+Users'+Chance-Seeking+Behavior+in+Search-Based+Recommendation)|0|
|[Improve the Personalization of Large-Scale Ranking Systems by Integrating User Survey Feedback](https://doi.org/10.1145/3705328.3748119)|Mengxi Lv, Drew Hogg, Thomas Grubb, Shashank Bassi, Min Li, Cayman Simpson, Senthil Rajagopalan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improve+the+Personalization+of+Large-Scale+Ranking+Systems+by+Integrating+User+Survey+Feedback)|0|
|[User Long-Term Multi-Interest Retrieval Model for Recommendation](https://doi.org/10.1145/3705328.3748107)|Yue Meng, Cheng Guo, Xiaohui Hu, Honghu Deng, Yi Cao, Tong Liu, Bo Zheng||User behavior sequence modeling, which captures user interest from rich historical interactions, is pivotal for industrial recommendation systems. Despite breakthroughs in ranking-stage models capable of leveraging ultra-long behavior sequences with length scaling up to thousands, existing retrieval models remain constrained to sequences of hundreds of behaviors due to two main challenges. One is strict latency budget imposed by real-time service over large-scale candidate pool. The other is the absence of target-aware mechanisms and cross-interaction architectures, which prevent utilizing ranking-like techniques to simplify long sequence modeling. To address these limitations, we propose a new framework named User Long-term Multi-Interest Retrieval Model(ULIM), which enables thousand-scale behavior modeling in retrieval stages. ULIM includes two novel components: 1)Category-Aware Hierarchical Dual-Interest Learning partitions long behavior sequences into multiple category-aware subsequences representing multi-interest and jointly optimizes long-term and short-term interests within specific interest cluster. 2)Pointer-Enhanced Cascaded Category-to-Item Retrieval introduces Pointer-Generator Interest Network(PGIN) for next-category prediction, followed by next-item retrieval upon the top-K predicted categories. Comprehensive experiments on Taobao dataset show that ULIM achieves substantial improvement over state-of-the-art methods, and brings 5.54|用户行为序列建模通过丰富的历史交互捕捉用户兴趣，对工业推荐系统至关重要。尽管排序阶段模型已实现突破，能够处理长度高达数千的超长行为序列，但现有召回模型仍受限于数百长度的序列，主要面临两大挑战：一是大规模候选池实时服务的严格延迟限制；二是缺乏目标感知机制和交叉交互架构，导致无法采用类排序技术简化长序列建模。为解决这些局限，我们提出名为用户长期多兴趣召回模型（ULIM）的新框架，可在召回阶段实现千级行为序列建模。该框架包含两大创新模块：1）类别感知分层双兴趣学习——将长行为序列划分为多个表征多兴趣的类别感知子序列，在特定兴趣簇内联合优化长期与短期兴趣；2）指针增强级联类别-物品召回——通过指针生成器兴趣网络（PGIN）预测下一类别，继而基于预测的Top-K类别进行下一物品召回。在淘宝数据集上的综合实验表明，ULIM相较现有最优方法实现显著提升，并带来5.54%的核心指标增益。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=User+Long-Term+Multi-Interest+Retrieval+Model+for+Recommendation)|0|
|[LLM-RecG: A Semantic Bias-Aware Framework for Zero-Shot Sequential Recommendation](https://doi.org/10.1145/3705328.3748077)|Yunzhe Li, Junting Wang, Hari Sundaram, Zhining Liu||Zero-shot cross-domain sequential recommendation (ZCDSR) enables predictions in unseen domains without additional training or fine-tuning, addressing the limitations of traditional models in sparse data environments. Recent advancements in large language models (LLMs) have significantly enhanced ZCDSR by facilitating cross-domain knowledge transfer through rich, pretrained representations. Despite this progress, domain semantic bias – arising from differences in vocabulary and content focus between domains – remains a persistent challenge, leading to misaligned item embeddings and reduced generalization across domains. To address this, we propose a novel semantic bias-aware framework that enhances LLM-based ZCDSR by improving cross-domain alignment at both the item and sequential levels. At the item level, we introduce a generalization loss that aligns the embeddings of items across domains (inter-domain compactness), while preserving the unique characteristics of each item within its own domain (intra-domain diversity). This ensures that item embeddings can be transferred effectively between domains without collapsing into overly generic or uniform representations. At the sequential level, we develop a method to transfer user behavioral patterns by clustering source domain user sequences and applying attention-based aggregation during target domain inference. We dynamically adapt user embeddings to unseen domains, enabling effective zero-shot recommendations without requiring target-domain interactions...|零样本跨域序列推荐（ZCDSR）能够在无需额外训练或微调的情况下对未知领域进行预测，从而解决传统模型在稀疏数据环境中的局限性。大型语言模型（LLM）的最新进展通过预训练的丰富表征促进跨领域知识迁移，显著提升了ZCDSR的性能。尽管取得这些进展，领域语义偏差——源自不同领域间词汇表与内容聚焦点的差异——仍是持续存在的挑战，会导致项目嵌入失准及跨域泛化能力下降。为此，我们提出一种新颖的语义偏差感知框架，通过在项目级和序列级同时增强跨域对齐来改进基于LLM的ZCDSR。在项目级别，我们引入泛化损失函数，既实现跨域项目嵌入的对齐（域间紧致性），又保持各项目在其所属领域内的独特性（域内多样性）。这确保项目嵌入能在领域间有效迁移，而不会坍缩为过度通用或单一的表征。在序列级别，我们开发了通过聚类源域用户序列并在目标域推理时采用基于注意力的聚合方法，实现用户行为模式的迁移。通过动态适应用户嵌入至未知领域，我们的方法无需目标域交互即可实现有效的零样本推荐...|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LLM-RecG:+A+Semantic+Bias-Aware+Framework+for+Zero-Shot+Sequential+Recommendation)|0|
|[Disentangling User and Item Sequence Patterns in Sequential Recommendation Data Sets](https://doi.org/10.1145/3705328.3748042)|Kaiyue Liu, Yang Liu, Alan Medlar, Dorota Glowacka||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Disentangling+User+and+Item+Sequence+Patterns+in+Sequential+Recommendation+Data+Sets)|0|
|[Let It Go? Not Quite: Addressing Item Cold Start in Sequential Recommendations with Content-Based Initialization](https://doi.org/10.1145/3705328.3748038)|Anton Pembek, Artem Fatkulin, Anton Klenitskiy, Alexey Vasilev||Many sequential recommender systems suffer from the cold start problem, where items with few or no interactions cannot be effectively used by the model due to the absence of a trained embedding. Content-based approaches, which leverage item metadata, are commonly used in such scenarios. One possible way is to use embeddings derived from content features such as textual descriptions as initialization for the model embeddings. However, directly using frozen content embeddings often results in suboptimal performance, as they may not fully adapt to the recommendation task. On the other hand, fine-tuning these embeddings can degrade performance for cold-start items, as item representations may drift far from their original structure after training. We propose a novel approach to address this limitation. Instead of entirely freezing the content embeddings or fine-tuning them extensively, we introduce a small trainable delta to frozen embeddings that enables the model to adapt item representations without letting them go too far from their original semantic structure. This approach demonstrates consistent improvements across multiple datasets and modalities, including e-commerce datasets with textual descriptions and a music dataset with audio-based representation.|许多序列推荐系统存在冷启动问题——由于缺乏训练嵌入向量，交互数据稀少或缺失的物品难以被模型有效利用。基于内容的方法（利用物品元数据）是此类场景的常用解决方案。一种可行方案是使用文本描述等内容特征生成的嵌入向量作为模型嵌入的初始化值。但直接冻结内容嵌入向量通常会导致次优效果，因为它们可能无法完全适应推荐任务；而对这些嵌入进行微调又可能损害冷启动物品的表现，因为训练后物品表征会偏离原始语义结构。针对这一局限，我们提出创新解决方案：既不完全冻结内容嵌入，也不进行大规模微调，而是在冻结嵌入基础上引入可训练的微小增量，使模型既能适配物品表征，又不会过度偏离其原始语义结构。该方法在多个数据集和模态中均展现出稳定提升，包括含文本描述的电商数据集和基于音频表征的音乐数据集。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Let+It+Go?+Not+Quite:+Addressing+Item+Cold+Start+in+Sequential+Recommendations+with+Content-Based+Initialization)|0|
|[DistillRecDial: A Knowledge-Distilled Dataset Capturing User Diversity in Conversational Recommendation](https://doi.org/10.1145/3705328.3748161)|Alessandro Francesco Maria Martina, Alessandro Petruzzelli, Cataldo Musto, Marco de Gemmis, Pasquale Lops, Giovanni Semeraro||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DistillRecDial:+A+Knowledge-Distilled+Dataset+Capturing+User+Diversity+in+Conversational+Recommendation)|0|
|[In-context Learning for Addressing User Cold-start in Sequential Movie Recommenders](https://doi.org/10.1145/3705328.3748109)|Xurong Liang, Vu Nguyen, Vuong Le, Paul Albert, Julien Monteil||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=In-context+Learning+for+Addressing+User+Cold-start+in+Sequential+Movie+Recommenders)|0|
|[Leveraging Explicit Negative Feedback in Large-Scale Recommendation Systems: A Case Study](https://doi.org/10.1145/3705328.3748145)|Madhura Raju, Manisha Sharma, Hongyu Xiong, Bingfeng Deng, Meng Na||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Explicit+Negative+Feedback+in+Large-Scale+Recommendation+Systems:+A+Case+Study)|0|
|[IP2: Entity-Guided Interest Probing for Personalized News Recommendation](https://doi.org/10.1145/3705328.3748091)|Youlin Wu, Yuanyuan Sun, Xiaokun Zhang, Haoxi Zhan, Bo Xu, Liang Yang, Hongfei Lin||News recommender systems aim to provide personalized news reading experiences for users based on their reading history. Behavioral science studies suggest that screen-based news reading contains three successive steps: scanning, title reading, and then clicking. Adhering to these steps, we find that intra-news entity interest dominates the scanning stage, while the inter-news entity interest guides title reading and influences click decisions. Unfortunately, current methods overlook the unique utility of entities in news recommendation. To this end, we propose a novel method called IP2 to probe entity-guided reading interest at both intra- and inter-news levels. At the intra-news level, a Transformer-based entity encoder is devised to aggregate mentioned entities in the news title into one signature entity. Then, a signature entity-title contrastive pre-training is adopted to initialize entities with proper meanings using the news story context, which in the meantime facilitates us to probe for intra-news entity interest. As for the inter-news level, a dual tower user encoder is presented to capture inter-news reading interest from both the title meaning and entity sides. In addition to highlighting the contribution of inter-news entity guidance, a cross-tower attention link is adopted to calibrate title reading interest using inter-news entity interest, thus further aligning with real-world behavior. Extensive experiments on two real-world datasets demonstrate that our IP2 achieves state-of-the-art performance in news recommendation.|新闻推荐系统旨在基于用户的阅读历史，提供个性化的新闻阅读体验。行为科学研究表明，基于屏幕的新闻阅读包含三个连续步骤：扫描浏览、标题阅读和点击行为。通过分析这些步骤，我们发现新闻内部实体兴趣主导扫描阶段，而跨新闻实体兴趣则引导标题阅读并影响点击决策。然而现有方法忽视了实体在新闻推荐中的独特作用。为此，我们提出名为IP2的创新方法，在新闻内与跨新闻两个层面探究实体引导的阅读兴趣。在新闻内层面，设计基于Transformer的实体编码器，将新闻标题中提及的实体聚合为签名实体；采用签名实体-标题对比预训练，通过新闻故事上下文初始化具有准确语义的实体，同时助力新闻内实体兴趣的探测。在跨新闻层面，提出双塔式用户编码器，从标题语义和实体两个维度捕捉跨新闻阅读兴趣。除突显跨新闻实体引导的贡献外，采用跨塔注意力链接机制，通过跨新闻实体兴趣校准标题阅读兴趣，从而进一步贴合真实用户行为。在两个真实数据集上的大量实验表明，我们的IP2方法在新闻推荐任务中实现了最先进的性能表现。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=IP2:+Entity-Guided+Interest+Probing+for+Personalized+News+Recommendation)|0|
|[LEAF: Lightweight, Efficient, Adaptive and Flexible Embedding for Large-Scale Recommendation Models](https://doi.org/10.1145/3705328.3748078)|Chaoyi Jiang, Abdulla Alshabanah, Murali Annavaram||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LEAF:+Lightweight,+Efficient,+Adaptive+and+Flexible+Embedding+for+Large-Scale+Recommendation+Models)|0|
|[Collaborative Interest Modeling in Recommender Systems](https://doi.org/10.1145/3705328.3748023)|YuTing Cheng, YuYen Ho, JyunYu Jiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Collaborative+Interest+Modeling+in+Recommender+Systems)|0|
|["We Share Our Code Online": Why This Is Not Enough to Ensure Reproducibility and Progress in Recommender Systems Research](https://doi.org/10.1145/3705328.3748157)|Faisal Shehzad, Timo Breuer, Maria Maistro, Dietmar Jannach||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q="We+Share+Our+Code+Online":+Why+This+Is+Not+Enough+to+Ensure+Reproducibility+and+Progress+in+Recommender+Systems+Research)|0|
|[Yambda-5B - A Large-Scale Multi-Modal Dataset for Ranking and Retrieval](https://doi.org/10.1145/3705328.3748163)|Alexander Ploshkin, Vladislav Tytskiy, Alexey Pismenny, Vladimir Baikalov, Evgeny Taychinov, Artem Permiakov, Daniil Burlakov, Eugene Krofto||We present Yambda-5B, a large-scale open dataset sourced from the Yandex.Music streaming platform. Yambda-5B contains 4.79 billion user-item interactions from 1 million users across 9.39 million tracks. The dataset includes two primary types of interactions: implicit feedback (listening events) and explicit feedback (likes, dislikes, unlikes and undislikes). In addition, we provide audio embeddings for most tracks, generated by a convolutional neural network trained on audio spectrograms. A key distinguishing feature of Yambda-5B is the inclusion of the is_organic flag, which separates organic user actions from recommendation-driven events. This distinction is critical for developing and evaluating machine learning algorithms, as Yandex.Music relies on recommender systems to personalize track selection for users. To support rigorous benchmarking, we introduce an evaluation protocol based on a Global Temporal Split, allowing recommendation algorithms to be assessed in conditions that closely mirror real-world use. We report benchmark results for standard baselines (ItemKNN, iALS) and advanced models (SANSA, SASRec) using a variety of evaluation metrics. By releasing Yambda-5B to the community, we aim to provide a readily accessible, industrial-scale resource to advance research, foster innovation, and promote reproducible results in recommender systems.|我们正式发布Yambda-5B数据集——一个源自Yandex.Music流媒体平台的大规模开放数据集。该数据集包含来自100万用户与939万条音轨之间的47.9亿次用户-项目交互记录，涵盖两种主要交互类型：隐式反馈（收听行为）和显式反馈（喜欢/不喜欢/取消喜欢/取消不喜欢）。此外，我们为多数音轨提供了基于频谱图训练的卷积神经网络所生成的音频嵌入向量。Yambda-5B的核心特色在于引入is_organic标志位，可区分用户自发行为与推荐系统驱动的事件——这一特性对机器学习算法的开发与评估至关重要，因为Yandex.Music正是依赖推荐系统来实现个性化音轨推送。为支持严谨的基准测试，我们设计了基于全局时间分割的评估方案，使推荐算法能在高度模拟真实场景的条件下进行评估。通过多种评估指标，我们报告了经典基线模型（ItemKNN、iALS）与先进模型（SANSA、SASRec）的基准性能。我们希望通过开放Yambda-5B数据集，为推荐系统领域提供一个易于获取的工业级资源，以推动前沿研究、促进技术创新，并增强研究成果的可复现性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Yambda-5B+-+A+Large-Scale+Multi-Modal+Dataset+for+Ranking+and+Retrieval)|0|
|[An Analysis of Learned Product Embeddings in an E-Commerce Context](https://doi.org/10.1145/3705328.3748131)|Mate Hartstein, Eva Giannatou, Martin Tegner||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Analysis+of+Learned+Product+Embeddings+in+an+E-Commerce+Context)|0|
|[Decoupled Entity Representation Learning for Pinterest Ads Ranking](https://doi.org/10.1145/3705328.3748098)|Jie Liu, Yinrui Li, Jiankai Sun, Kungang Li, Han Sun, Sihan Wang, Huasen Wu, Siyuan Gao, Paulo Soares, Nan Li, Zhifang Liu, Haoyang Li, Siping Ji, Ling Leng, Prathibha Deshikachar||In this paper, we introduce a novel framework following an upstream-downstream paradigm to construct user and item (Pin) embeddings from diverse data sources, which are essential for Pinterest to deliver personalized Pins and ads effectively. Our upstream models are trained on extensive data sources featuring varied signals, utilizing complex architectures to capture intricate relationships between users and Pins on Pinterest. To ensure scalability of the upstream models, entity embeddings are learned, and regularly refreshed, rather than real-time computation, allowing for asynchronous interaction between the upstream and downstream models. These embeddings are then integrated as input features in numerous downstream tasks, including ad retrieval and ranking models for CTR and CVR predictions. We demonstrate that our framework achieves notable performance improvements in both offline and online settings across various downstream tasks. This framework has been deployed in Pinterest's production ad ranking systems, resulting in significant gains in online metrics.|本文提出了一种遵循上游-下游范式的新型框架，通过整合多源数据构建用户与内容图钉（Pin）的嵌入表示，这对Pinterest实现个性化内容推送与广告精准分发起着关键作用。我们的上游模型基于海量多信号数据源进行训练，采用复杂架构以捕捉平台中用户与图钉间的深层关联。为确保模型可扩展性，系统通过定期更新学习实体嵌入向量，而非实时计算，从而实现上下游模型的异步协同。这些嵌入向量作为核心特征被集成至多个下游任务中，包括广告召回机制以及基于CTR（点击通过率）与CVR（转化率）预测的排序模型。实验表明，该框架在各类下游任务的离线测试与在线部署中均取得显著性能提升。目前该框架已部署于Pinterest生产级广告排序系统，并带来关键线上指标的实质性增长。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Decoupled+Entity+Representation+Learning+for+Pinterest+Ads+Ranking)|0|
|[Deep Reinforcement Learning for Ranking Utility Tuning in the Ad Recommender System at Pinterest](https://doi.org/10.1145/3705328.3748144)|Xiao Yang, Mehdi Ayed, Longyu Zhao, Fan Zhou, Yuchen Shen, Abe Engle, Jinfeng Zhuang, Ling Leng, Jiajing Xu, Charles Rosenberg, Prathibha Deshikachar||The ranking utility function in an ad recommender system, which linearly combines predictions of various business goals, plays a central role in balancing values across the platform, advertisers, and users. Traditional manual tuning, while offering simplicity and interpretability, often yields suboptimal results due to its unprincipled tuning objectives, the vast amount of parameter combinations, and its lack of personalization and adaptability to seasonality. In this work, we propose a general Deep Reinforcement Learning framework for Personalized Utility Tuning (DRL-PUT) to address the challenges of multi-objective optimization within ad recommender systems. Our key contributions include: 1) Formulating the problem as a reinforcement learning task: given the state of an ad request, we predict the optimal hyperparameters to maximize a pre-defined reward. 2) Developing an approach to directly learn an optimal policy model using online serving logs, avoiding the need to estimate a value function, which is inherently challenging due to the high variance and unbalanced distribution of immediate rewards. We evaluated DRL-PUT through an online A/B experiment in Pinterest's ad recommender system. Compared to the baseline manual utility tuning approach, DRL-PUT improved the click-through rate by 9.7|广告推荐系统中的排序效用函数通过线性组合多个业务目标的预测值，在平衡平台、广告主和用户价值方面起着核心作用。传统人工调参方法虽然具有简洁性和可解释性，但由于其调参目标缺乏理论依据、参数组合空间庞大，且无法实现个性化与季节性适应，往往导致结果欠优。本研究提出一种基于深度强化学习的个性化效用调参通用框架（DRL-PUT），以解决广告推荐系统中的多目标优化挑战。我们的核心贡献包括：1）将问题构建为强化学习任务：根据广告请求状态预测最优超参数，以最大化预设奖励；2）开发直接通过在线服务日志学习最优策略模型的方法，避免因即时奖励高方差和分布不均衡而难以进行价值函数估计的问题。通过在Pinterest广告推荐系统中进行在线A/B实验评估，与基线人工调参方法相比，DRL-PUT将点击率提升9.7%|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Reinforcement+Learning+for+Ranking+Utility+Tuning+in+the+Ad+Recommender+System+at+Pinterest)|0|
|[RankGraph: Unified Heterogeneous Graph Learning for Cross-Domain Recommendation](https://doi.org/10.1145/3705328.3748118)|Renzhi Wu, Junjie Yang, Li Chen, Hong Li, Li Yu, Hong Yan||Cross-domain recommendation systems face the challenge of integrating fine-grained user and item relationships across various product domains. To address this, we introduce RankGraph, a scalable graph learning framework designed to serve as a core component in recommendation foundation models (FMs). By constructing and leveraging graphs composed of heterogeneous nodes and edges across multiple products, RankGraph enables the integration of complex relationships between users, posts, ads, and other entities. Our framework employs a GPU-accelerated Graph Neural Network and contrastive learning, allowing for dynamic extraction of subgraphs such as item-item and user-user graphs to support similarity-based retrieval and real-time clustering. Furthermore, RankGraph integrates graph-based pretrained representations as contextual tokens into FM sequence models, enriching them with structured relational knowledge. RankGraph has demonstrated improvements in click (+0.92|跨领域推荐系统面临整合不同产品领域中细粒度用户与物品关系的挑战。为此，我们提出RankGraph——一个可扩展的图学习框架，旨在作为推荐基础模型的核心组件。通过构建并利用跨多个产品的异构节点与边构成的图结构，RankGraph能够整合用户、帖子、广告等实体间的复杂关系。该框架采用GPU加速的图神经网络与对比学习技术，可动态提取物品-物品图、用户-用户图等子图，以支持基于相似性的检索与实时聚类。此外，RankGraph将基于图的预训练表征作为上下文标记融入基础模型序列，通过结构化关系知识增强模型表达能力。实验表明，RankGraph在点击率（+0.92%）等关键指标上实现显著提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RankGraph:+Unified+Heterogeneous+Graph+Learning+for+Cross-Domain+Recommendation)|0|
|[Unified Survey Modeling to Limit Negative User Experiences in Recommendation Systems](https://doi.org/10.1145/3705328.3748108)|Chenghui Yu, Haoze Wu, Jian Ding, Bingfeng Deng, Hongyu Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unified+Survey+Modeling+to+Limit+Negative+User+Experiences+in+Recommendation+Systems)|0|
|[USD: A User-Intent-Driven Sampling and Dual-Debiasing Framework for Large-Scale Homepage Recommendations](https://doi.org/10.1145/3705328.3748096)|Jiaqi Zheng, Cheng Guo, Yi Cao, Chaoqun Hou, Tong Liu, Bo Zheng||Large-scale homepage recommendations face critical challenges from pseudo-negative samples caused by exposure bias, where non-clicks may indicate inattention rather than disinterest. Existing work lacks thorough analysis of invalid exposures and typically addresses isolated aspects (e.g., sampling strategies), overlooking the critical impact of pseudo-positive samples - such as homepage clicks merely to visit marketing portals. We propose a unified framework for large-scale homepage recommendation sampling and debiasing. Our framework consists of two key components: (1) a user intent-aware negative sampling module to filter invalid exposure samples, and (2) an intent-driven dual-debiasing module that jointly corrects exposure bias and click bias. Extensive online experiments on Taobao demonstrate the efficacy of our framework, achieving significant improvements in user click-through rates (UCTR) by 35.4% and 14.5% in two variants of the marketing block on the Taobao homepage, Baiyibutie and Taobaomiaosha.|大规模首页推荐面临曝光偏差导致的伪负样本关键挑战——用户未点击可能源于未注意到内容而非缺乏兴趣。现有研究缺乏对无效曝光的深入分析，通常仅解决局部问题（如采样策略），忽视了伪正样本的关键影响（例如用户点击首页仅为了访问营销入口）。我们提出一个统一的大规模首页推荐采样与去偏框架，该框架包含两个核心组件：（1）用户意图感知负采样模块，用于过滤无效曝光样本；（2）意图驱动的双重去偏模块，联合修正曝光偏差与点击偏差。在淘宝平台进行的在线实验表明，我们的框架在首页营销板块“百亿补贴”和“淘宝秒杀”的两个变体中，用户点击率分别实现35.4%和14.5%的显著提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=USD:+A+User-Intent-Driven+Sampling+and+Dual-Debiasing+Framework+for+Large-Scale+Homepage+Recommendations)|0|
|[You Say Search, I Say Recs: A Scalable Agentic Approach to Query Understanding and Exploratory Search at Spotify](https://doi.org/10.1145/3705328.3748127)|Enrico Palumbo, Marcus Isaksson, Alexandre Tamborrino, Maria Movin, Catalin Dincu, Ali Vardasbi, Lev Nikeshkin, Oksana Gorobets, Anders Nyman, Poppy Newdick, Hugues Bouchard, Paul N. Bennett, Mounia Lalmas, Dani Doro, Christine Doig Cardet, Ziad Sultan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=You+Say+Search,+I+Say+Recs:+A+Scalable+Agentic+Approach+to+Query+Understanding+and+Exploratory+Search+at+Spotify)|0|
|[Benefiting from Negative yet Informative Feedback by Contrasting Opposing Sequential Patterns](https://doi.org/10.1145/3705328.3759333)|Veronika Ivanova, Evgeny Frolov, Alexey Vasilev||We consider the task of learning from both positive and negative feedback in a sequential recommendation scenario, as both types of feedback are often present in user interactions. Meanwhile, conventional sequential learning models usually focus on considering and predicting positive interactions, ignoring that reducing items with negative feedback in recommendations improves user satisfaction with the service. Moreover, the negative feedback can potentially provide a useful signal for more accurate identification of true user interests. In this work, we propose to train two transformer encoders on separate positive and negative interaction sequences. We incorporate both types of feedback into the training objective of the sequential recommender using a composite loss function that includes positive and negative cross-entropy as well as a cleverly crafted contrastive term, that helps better modeling opposing patterns. We demonstrate the effectiveness of this approach in terms of increasing true-positive metrics compared to state-of-the-art sequential recommendation methods while reducing the number of wrongly promoted negative items.|在序列化推荐场景中，我们研究如何同时利用正负反馈进行学习，因为这两种反馈类型常同时存在于用户交互中。传统序列学习模型通常侧重于考量和预测正向交互，却忽略了减少负反馈项目的推荐能够有效提升用户对服务的满意度。此外，负反馈可能为更精准识别用户真实兴趣提供重要信号。本研究提出分别使用两个Transformer编码器对正向与负向交互序列进行训练。我们通过融合正负向交叉熵损失函数与精心设计的对比项，构建复合损失目标将两种反馈类型纳入序列推荐器的训练体系，该对比项有助于更好地建模对立模式。实验证明，相较于最先进的序列推荐方法，该方案在提升真阳性指标的同时，能有效减少错误推荐的负向项目数量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Benefiting+from+Negative+yet+Informative+Feedback+by+Contrasting+Opposing+Sequential+Patterns)|0|
|[Beyond Clicks: Eye-Tracking Insights into User Responses to Different Recommendation Types](https://doi.org/10.1145/3705328.3759304)|Georgios Koutroumpas, Matteo Mazzini, Sebastian Idesis, Mireia Masias Bruns, Joemon M. Jose, Sergi Abadal, Ioannis Arapakis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Clicks:+Eye-Tracking+Insights+into+User+Responses+to+Different+Recommendation+Types)|0|
|[Semantic IDs for Joint Generative Search and Recommendation](https://doi.org/10.1145/3705328.3759300)|Gustavo Penha, Edoardo D'Amico, Marco De Nadai, Enrico Palumbo, Alexandre Tamborrino, Ali Vardasbi, Max Lefarov, Shawn Lin, Timothy Christopher Heath, Francesco Fabbri, Hugues Bouchard||Generative models powered by Large Language Models (LLMs) are emerging as a unified solution for powering both recommendation and search tasks. A key design choice in these models is how to represent items, traditionally through unique identifiers (IDs) and more recently with Semantic IDs composed of discrete codes, obtained from embeddings. While task-specific embedding models can improve performance for individual tasks, they may not generalize well in a joint setting. In this paper, we explore how to construct Semantic IDs that perform well both in search and recommendation when using a unified model. We compare a range of strategies to construct Semantic IDs, looking into task-specific and cross-tasks approaches, and also whether each task should have its own semantic ID tokens in a joint search and recommendation generative model. Our results show that using a bi-encoder model fine-tuned on both search and recommendation tasks to obtain item embeddings, followed by the construction of a unified Semantic ID space provides an effective trade-off, enabling strong performance in both tasks. We hope these findings spark follow-up work on generalisable, semantically grounded ID schemes and inform the next wave of unified generative recommender architectures.|基于大语言模型（LLM）的生成式模型正逐渐成为支持推荐与搜索任务的统一解决方案。这些模型的核心设计在于如何表征物品：传统方法采用唯一标识符（ID），而近期则使用通过嵌入向量获得的离散码组成的语义ID。虽然针对特定任务的嵌入模型可以提升单项任务性能，但在联合场景中可能泛化能力不足。本文探索了如何在使用统一模型时构建能同时胜任搜索与推荐任务的语义ID。我们比较了多种语义ID构建策略，包括任务专用与跨任务方法，并研究了在联合搜索推荐生成模型中是否应为各任务分配独立语义ID标记。实验结果表明：通过使用经搜索和推荐任务联合微调的双编码器模型获取物品嵌入，继而构建统一语义ID空间，能够在两项任务中实现强劲性能的有效平衡。我们希望这些发现能推动关于可泛化、语义化ID方案的后续研究，并为新一代统一生成式推荐架构提供设计依据。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Semantic+IDs+for+Joint+Generative+Search+and+Recommendation)|0|
|[Unobserved Negative Items in Recommender Systems: Challenges and Solutions for Evaluation and Learning](https://doi.org/10.1145/3705328.3759315)|Masahiro Sato||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unobserved+Negative+Items+in+Recommender+Systems:+Challenges+and+Solutions+for+Evaluation+and+Learning)|0|
|[VisualReF: Interactive Image Search Prototype with Visual Relevance Feedback](https://doi.org/10.1145/3705328.3759341)|Bulat Khaertdinov, Mirela Popa, Nava Tintarev||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=VisualReF:+Interactive+Image+Search+Prototype+with+Visual+Relevance+Feedback)|0|
|[Advancing User-Centric Evaluation and Design of Conversational Recommender Systems](https://doi.org/10.1145/3705328.3748759)|Michael Müller||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Advancing+User-Centric+Evaluation+and+Design+of+Conversational+Recommender+Systems)|0|
|[A Multi-Factor Collaborative Prediction for Review-based Recommendation](https://doi.org/10.1145/3705328.3748062)|Junrui Liu, Tong Li, Mingliang Yu, Shiqiu Yang, Zifang Tang, Zhen Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Multi-Factor+Collaborative+Prediction+for+Review-based+Recommendation)|0|
|[Enhancing Sequential Recommender with Large Language Models for Joint Video and Comment Recommendation](https://doi.org/10.1145/3705328.3748075)|Bowen Zheng, Zihan Lin, Enze Liu, Chen Yang, Enyang Bai, Cheng Ling, Han Li, Wayne Xin Zhao, JiRong Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Sequential+Recommender+with+Large+Language+Models+for+Joint+Video+and+Comment+Recommendation)|0|
|[Mapping Stakeholder Needs to Multi-Sided Fairness in Candidate Recommendation for Algorithmic Hiring](https://doi.org/10.1145/3705328.3748079)|Mesut Kaya, Toine Bogers||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mapping+Stakeholder+Needs+to+Multi-Sided+Fairness+in+Candidate+Recommendation+for+Algorithmic+Hiring)|0|
|[Modeling Long-term User Behaviors with Diffusion-driven Multi-interest Network for CTR Prediction](https://doi.org/10.1145/3705328.3748045)|Weijiang Lai, Beihong Jin, Yapeng Zhang, Yiyuan Zheng, Rui Zhao, Jian Dong, Jun Lei, Xingxing Wang||CTR (Click-Through Rate) prediction, crucial for recommender systems and online advertising, etc., has been confirmed to benefit from modeling long-term user behaviors. Nonetheless, the vast number of behaviors and complexity of noise interference pose challenges to prediction efficiency and effectiveness. Recent solutions have evolved from single-stage models to two-stage models. However, current two-stage models often filter out significant information, resulting in an inability to capture diverse user interests and build the complete latent space of user interests. Inspired by multi-interest and generative modeling, we propose DiffuMIN (Diffusion-driven Multi-Interest Network) to model long-term user behaviors and thoroughly explore the user interest space. Specifically, we propose a target-oriented multi-interest extraction method that begins by orthogonally decomposing the target to obtain interest channels. This is followed by modeling the relationships between interest channels and user behaviors to disentangle and extract multiple user interests. We then adopt a diffusion module guided by contextual interests and interest channels, which anchor users' personalized and target-oriented interest types, enabling the generation of augmented interests that align with the latent spaces of user interests, thereby further exploring restricted interest space. Finally, we leverage contrastive learning to ensure that the generated augmented interests align with users' genuine preferences. Extensive offline experiments are conducted on two public datasets and one industrial dataset, yielding results that demonstrate the superiority of DiffuMIN. Moreover, DiffuMIN increased CTR by 1.52|点击率预测在推荐系统和在线广告等领域至关重要，现有研究证实其对长期用户行为建模具有显著效益。然而，海量行为数据与复杂噪声干扰对预测效率和效果构成挑战。近期解决方案已从单阶段模型演进至两阶段模型，但现有两阶段模型往往过滤掉重要信息，导致无法捕捉多元用户兴趣并构建完整的用户兴趣隐空间。受多兴趣建模与生成式建模的启发，我们提出DiffuMIN（扩散驱动多兴趣网络）来建模长期用户行为并深入探索用户兴趣空间。具体而言，我们提出目标导向的多兴趣提取方法：首先通过正交分解目标来获取兴趣通道，继而建模兴趣通道与用户行为间的关联以解耦并提取多重用户兴趣。随后采用基于上下文兴趣和兴趣通道的扩散模块，锚定用户的个性化目标导向兴趣类型，生成符合用户兴趣隐空间的增强兴趣，从而进一步探索受限兴趣空间。最后，我们通过对比学习确保生成的增强兴趣与用户真实偏好保持一致。在两个公共数据集和一个工业数据集上的大量离线实验表明，DiffuMIN具有显著优越性。此外，该模型在实际应用中使点击率提升1.52%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modeling+Long-term+User+Behaviors+with+Diffusion-driven+Multi-interest+Network+for+CTR+Prediction)|0|
|[MoRE: A Mixture of Reflectors Framework for Large Language Model-Based Sequential Recommendation](https://doi.org/10.1145/3705328.3748055)|Weicong Qin, Yi Xu, Weijie Yu, Chenglei Shen, Xiao Zhang, Ming He, Jianping Fan, Jun Xu||Large language models (LLMs) have emerged as a cutting-edge approach in sequential recommendation, leveraging historical interactions to model dynamic user preferences. Current methods mainly focus on learning processed recommendation data in the form of sequence-to-sequence text. While effective, they exhibit three key limitations: 1) failing to decouple intra-user explicit features (e.g., product titles) from implicit behavioral patterns (e.g., brand loyalty) within interaction histories; 2) underutilizing cross-user collaborative filtering (CF) signals; and 3) relying on inefficient reflection update strategies. To address this, We propose MoRE (Mixture of REflectors), which introduces three perspective-aware offline reflection processes to address these gaps. This decomposition directly resolves Challenges 1 (explicit/implicit ambiguity) and 2 (CF underutilization). Furthermore, MoRE's meta-reflector employs a self-improving strategy and a dynamic selection mechanism (Challenge 3) to adapt to evolving user preferences. First, two intra-user reflectors decouple explicit and implicit patterns from a user's interaction sequence, mimicking traditional recommender systems' ability to distinguish surface-level and latent preferences. A third cross-user reflector captures CF signals by analyzing user similarity patterns from multiple users' interactions. To optimize reflection quality, MoRE's meta-reflector employs a offline self-improving strategy that evaluates reflection impacts through comparisons of presence/absence and iterative refinement of old/new versions, with a online contextual bandit mechanism dynamically selecting the optimal perspective for recommendation for each user. Code: https://github.com/E-qin/MoRE-Rec.|大型语言模型作为序列推荐领域的前沿方法，通过利用历史交互行为来建模动态用户偏好。现有方法主要侧重于学习以序列到序列文本形式处理的推荐数据。虽然有效，但这些方法存在三个关键局限：1）未能从交互历史中解耦用户内部显性特征（如商品标题）与隐性行为模式（如品牌忠诚度）；2）未能充分利用跨用户协同过滤信号；3）依赖低效的反射更新策略。为此，我们提出MoRE（混合反射器），通过引入三个视角感知的离线反射流程来解决上述问题。这种解耦设计直接解决了挑战1（显性/隐性特征模糊）和挑战2（协同过滤利用不足）。此外，MoRE的元反射器采用自我优化策略和动态选择机制（挑战3）来适应不断演变的用户偏好。具体而言，两个用户内部反射器从用户交互序列中解耦显性与隐性模式，模拟传统推荐系统区分表层偏好与潜在偏好的能力；第三个跨用户反射器通过分析多用户交互中的相似性模式来捕捉协同过滤信号。为优化反射质量，MoRE的元反射器采用离线自我优化策略，通过存在/缺失对比和新旧版本迭代优化来评估反射效果，并配备在线情境赌博机机制为每位用户动态选择最佳推荐视角。代码地址：https://github.com/E-qin/MoRE-Rec。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MoRE:+A+Mixture+of+Reflectors+Framework+for+Large+Language+Model-Based+Sequential+Recommendation)|0|
|[Non-parametric Graph Convolution for Re-ranking in Recommendation Systems](https://doi.org/10.1145/3705328.3748058)|Zhongyu Ouyang, Mingxuan Ju, Soroush Vosoughi, Yanfang Ye||Graph knowledge has been proven effective in enhancing item rankings in recommender systems (RecSys), particularly during the retrieval stage. However, its application in the ranking stage, especially when richer contextual information in user-item interactions is available, remains underexplored. A major challenge lies in the substantial computational cost associated with repeatedly retrieving neighborhood information from billions of items stored in distributed systems. This resource-intensive requirement makes it difficult to scale graph-based methods in practical RecSys. To bridge this gap, we first demonstrate that incorporating graphs in the ranking stage improves ranking qualities. Notably, while the improvement is evident, we show that the substantial computational overheads entailed by graphs are prohibitively expensive for real-world recommendations. In light of this, we propose a non-parametric strategy that utilizes graph convolution for re-ranking only during test time. Our strategy circumvents the notorious computational overheads from graph convolution during training, and utilizes structural knowledge hidden in graphs on-the-fly during testing. It can be used as a plug-and-play module and easily employed to enhance the ranking ability of various ranking layers of a real-world RecSys with significantly reduced computational overhead. Through comprehensive experiments across four benchmark datasets with varying levels of sparsity, we demonstrate that our strategy yields noticeable improvements (i.e., 8.1|图知识已被证实能有效提升推荐系统（RecSys）中的物品排序效果，尤其在召回阶段表现突出。然而在排序阶段，特别是当用户-物品交互中包含更丰富的上下文信息时，图知识的应用仍待探索。主要挑战在于从分布式系统中存储的数十亿物品中重复获取邻域信息会产生巨大计算成本。这种资源密集型需求使得基于图的方法在实际推荐系统中难以规模化应用。为弥补这一空白，我们首先验证了在排序阶段引入图知识能提升排序质量。值得注意的是，虽然改进效果明显，但我们发现图方法带来的巨大计算开销在实际推荐场景中难以承受。基于此，我们提出一种非参数化策略，仅在测试阶段使用图卷积进行重排序。该策略在训练阶段规避了图卷积 notorious 的计算开销，并在测试阶段动态利用图中隐含的结构知识。该模块可作为即插即用组件，显著降低计算开销的同时，轻松增强实际推荐系统中各类排序层的排序能力。通过在四个具有不同稀疏度的基准数据集上进行综合实验，我们证明该策略可带来显著提升（即8.1%）。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Non-parametric+Graph+Convolution+for+Re-ranking+in+Recommendation+Systems)|0|
|[Off-Policy Evaluation of Candidate Generators in Two-Stage Recommender Systems](https://doi.org/10.1145/3705328.3748057)|Peiyao Wang, Zhan Shi, Amina Shabbeer, Ben London||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Off-Policy+Evaluation+of+Candidate+Generators+in+Two-Stage+Recommender+Systems)|0|
|[Paragon: Parameter Generation for Controllable Multi-Task Recommendation](https://doi.org/10.1145/3705328.3748069)|Chenglei Shen, Jiahao Zhao, Xiao Zhang, Weijie Yu, Ming He, Jianping Fan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Paragon:+Parameter+Generation+for+Controllable+Multi-Task+Recommendation)|0|
|[USB-Rec: An Effective Framework for Improving Conversational Recommendation Capability of Large Language Model](https://doi.org/10.1145/3705328.3748089)|Jianyu Wen, Jingyun Wang, Cilin Yan, Jiayin Cai, Xiaolong Jiang, Ying Zhang||Recently, Large Language Models (LLMs) have been widely employed in Conversational Recommender Systems (CRSs). Unlike traditional language model approaches that focus on training, all existing LLMs-based approaches are mainly centered around how to leverage the summarization and analysis capabilities of LLMs while ignoring the issue of training. Therefore, in this work, we propose an integrated training-inference framework, User-Simulator-Based framework (USB-Rec), for improving the performance of LLMs in conversational recommendation at the model level. Firstly, we design a LLM-based Preference Optimization (PO) dataset construction strategy for RL training, which helps the LLMs understand the strategies and methods in conversational recommendation. Secondly, we propose a Self-Enhancement Strategy (SES) at the inference stage to further exploit the conversational recommendation potential obtained from RL training. Extensive experiments on various datasets demonstrate that our method consistently outperforms previous state-of-the-art methods.|近年来，大语言模型（LLMs）在对话推荐系统（CRSs）中得到广泛应用。与传统聚焦于训练过程的语言模型方法不同，现有基于LLM的方法主要围绕如何利用其总结分析能力展开，而忽视了模型训练环节。为此，我们提出一种融合训练与推理的集成框架——用户模拟器框架（USB-Rec），从模型层面提升LLM在对话推荐任务中的性能。首先，我们设计了基于LLM的偏好优化数据集构建策略，用于强化学习训练，帮助LLM深入理解对话推荐中的策略与方法；其次，在推理阶段提出自增强策略，进一步释放通过强化学习获得的对话推荐潜力。在多组数据集上的大量实验表明，我们的方法始终优于以往最先进的模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=USB-Rec:+An+Effective+Framework+for+Improving+Conversational+Recommendation+Capability+of+Large+Language+Model)|0|
|[VL-CLIP: Enhancing Multimodal Recommendations via Visual Grounding and LLM-Augmented CLIP Embeddings](https://doi.org/10.1145/3705328.3748064)|Ramin Giahi, Kehui Yao, Sriram Kollipara, Kai Zhao, Vahid Mirjalili, Jianpeng Xu, Topojoy Biswas, Evren Körpeoglu, Kannan Achan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=VL-CLIP:+Enhancing+Multimodal+Recommendations+via+Visual+Grounding+and+LLM-Augmented+CLIP+Embeddings)|0|
|["Beyond the past": Leveraging Audio and Human Memory for Sequential Music Recommendation](https://doi.org/10.1145/3705328.3748018)|VietAnh Tran, Bruno Sguerra, Gabriel MeseguerBrocal, Léa Briand, Manuel Moussallam||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q="Beyond+the+past":+Leveraging+Audio+and+Human+Memory+for+Sequential+Music+Recommendation)|0|
|[Failure Prediction in Conversational Recommendation Systems](https://doi.org/10.1145/3705328.3748043)|Maria Vlachou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Failure+Prediction+in+Conversational+Recommendation+Systems)|0|
|[Just Ask for Music (JAM): Multimodal and Personalized Natural Language Music Recommendation](https://doi.org/10.1145/3705328.3748020)|Alessandro B. Melchiorre, Elena V. Epure, Shahed Masoudian, Gustavo Escobedo, Anna Hausberger, Manuel Moussallam, Markus Schedl||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Just+Ask+for+Music+(JAM):+Multimodal+and+Personalized+Natural+Language+Music+Recommendation)|0|
|[Not Just What, But When: Integrating Irregular Intervals to LLM for Sequential Recommendation](https://doi.org/10.1145/3705328.3748013)|WeiWei Du, Takuma Udagawa, Kei Tateno||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Not+Just+What,+But+When:+Integrating+Irregular+Intervals+to+LLM+for+Sequential+Recommendation)|0|
|[Personalized Persuasion-Aware Explanations in Recommender Systems](https://doi.org/10.1145/3705328.3748021)|Havva Alizadeh Noughabi, Behshid Behkamal, Fattane Zarrinkalam, Mohsen Kahani||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Persuasion-Aware+Explanations+in+Recommender+Systems)|0|
|[Towards Personality-Aware Explanations for Music Recommendations Using Generative AI](https://doi.org/10.1145/3705328.3748032)|Gabrielle Alves, Dietmar Jannach, Luan Soares de Souza, Marcelo Garcia Manzato||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Personality-Aware+Explanations+for+Music+Recommendations+Using+Generative+AI)|0|
|[TreatRAG: A Framework for Personalized Treatment Recommendation](https://doi.org/10.1145/3705328.3748022)|ChaoChin Liu, HaoRen Yao, DerChen Chang, Ophir Frieder||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TreatRAG:+A+Framework+for+Personalized+Treatment+Recommendation)|0|
|[Model Meets Knowledge: Analyzing Knowledge Types for Conversational Recommender Systems](https://doi.org/10.1145/3705328.3748152)|Jujia Zhao, Yumeng Wang, Zhaochun Ren, Suzan Verberne||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Model+Meets+Knowledge:+Analyzing+Knowledge+Types+for+Conversational+Recommender+Systems)|0|
|[Revisiting Prompt Engineering: A Comprehensive Evaluation for LLM-based Personalized Recommendation](https://doi.org/10.1145/3705328.3748159)|Genki Kusano, Kosuke Akimoto, Kunihiro Takeoka||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revisiting+Prompt+Engineering:+A+Comprehensive+Evaluation+for+LLM-based+Personalized+Recommendation)|0|
|[A Media Content Recommendation Method for Playlist Curators using LLM-Based Query Expansion](https://doi.org/10.1145/3705328.3748129)|Yuta Hagio, Chigusa Yamamura, Hiromu Ogawa, Hisayuki Ohmata, Arisa Fujii||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Media+Content+Recommendation+Method+for+Playlist+Curators+using+LLM-Based+Query+Expansion)|0|
|[Improving Visual Recommendation on E-commerce Platforms Using Vision-Language Models](https://doi.org/10.1145/3705328.3748128)|Yuki Yada, Sho Akiyama, Ryo Watanabe, Yuta Ueno, Yusuke Shido, Andre Rusli||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Visual+Recommendation+on+E-commerce+Platforms+Using+Vision-Language+Models)|0|
|[Industry Insights from Comparing Deep Learning and GBDT Models for E-Commerce Learning-to-Rank](https://doi.org/10.1145/3705328.3748130)|Yunus Lutz, Timo Wilm, Philipp Duwe||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Industry+Insights+from+Comparing+Deep+Learning+and+GBDT+Models+for+E-Commerce+Learning-to-Rank)|0|
|[Location Matters: Leveraging Multi-Resolution Geo-Embeddings for Housing Search](https://doi.org/10.1145/3705328.3748136)|Ivo Silva, Guilherme G. Bonaldo, Pedro F. Nogueira||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Location+Matters:+Leveraging+Multi-Resolution+Geo-Embeddings+for+Housing+Search)|0|
|[Minimize Negative Experiences in Video Recommendation Systems with Multimodal Large Language Models](https://doi.org/10.1145/3705328.3748102)|Suman Malani, Youwei Zhang, Liang Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Minimize+Negative+Experiences+in+Video+Recommendation+Systems+with+Multimodal+Large+Language+Models)|0|
|[Orthogonal Low Rank Embedding Stabilization](https://doi.org/10.1145/3705328.3748141)|Kevin Zielnicki, KoJen Hsiao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Orthogonal+Low+Rank+Embedding+Stabilization)|0|
|[Practical Multi-Task Learning for Rare Conversions in Ad Tech](https://doi.org/10.1145/3705328.3748110)|Yuval Dishi, Ophir Friedler, Yonatan Karni, Natalia Silberstein, Yulia Stolin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Practical+Multi-Task+Learning+for+Rare+Conversions+in+Ad+Tech)|0|
|[Scaling Generative Recommendations with Context Parallelism on Hierarchical Sequential Transducers](https://doi.org/10.1145/3705328.3748143)|Yue Dong, Han Li, Shen Li, Nikhil Patel, Xing Liu, Xiaodong Wang, Chuanhao Zhuge||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scaling+Generative+Recommendations+with+Context+Parallelism+on+Hierarchical+Sequential+Transducers)|0|
|[SEMORec: A Scalarized Efficient Multi-Objective Recommendation Framework](https://doi.org/10.1145/3705328.3748140)|Sofia Maria Nikolakaki, Siyong Ma, Srivas Chennu, Humeyra Topcu Altintas||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SEMORec:+A+Scalarized+Efficient+Multi-Objective+Recommendation+Framework)|0|
|[Suggest, Complement, Inspire: Story of Two-Tower Recommendations at Allegro.com](https://doi.org/10.1145/3705328.3748135)|Aleksandra Maria OsowskaKurczab, Klaudia Nazarko, Mateusz Marzec, Lidia Wojciechowska, Eliska Kremenová||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Suggest,+Complement,+Inspire:+Story+of+Two-Tower+Recommendations+at+Allegro.com)|0|
|[A Dual-Key Attention Framework for Sequential Recommendation with Side Information](https://doi.org/10.1145/3705328.3759326)|Minje Kim, Wooseung Kang, GunWoo Kim, Chie Hoon Song, Suwon Lee, SangMin Choi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Dual-Key+Attention+Framework+for+Sequential+Recommendation+with+Side+Information)|0|
|[Don't Get Ahead of Yourself: A Critical Study on Data Leakage in Offline Evaluation of Sequential Recommenders](https://doi.org/10.1145/3705328.3759329)|Huy Hoang Le, Yang Liu, Alan Medlar, Dorota Glowacka||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Don't+Get+Ahead+of+Yourself:+A+Critical+Study+on+Data+Leakage+in+Offline+Evaluation+of+Sequential+Recommenders)|0|
|[End-to-End Time Interval-wise Segmentation for Sequential Recommendation](https://doi.org/10.1145/3705328.3759327)|Minje Kim, Wooseung Kang, GunWoo Kim, Chie Hoon Song, Suwon Lee, SangMin Choi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=End-to-End+Time+Interval-wise+Segmentation+for+Sequential+Recommendation)|0|
|[Parameter-Efficient Single Collaborative Branch for Recommendation](https://doi.org/10.1145/3705328.3759302)|Marta Moscati, Shah Nawaz, Markus Schedl||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Parameter-Efficient+Single+Collaborative+Branch+for+Recommendation)|0|
|[Rethinking Subjective Features in Recommender Systems: Personal Views Over Aggregated Values](https://doi.org/10.1145/3705328.3759316)|Arsen Matej Golubovikj, Marko Tkalcic||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rethinking+Subjective+Features+in+Recommender+Systems:+Personal+Views+Over+Aggregated+Values)|0|
|[SAGEA: Sparse Autoencoder-based Group Embeddings Aggregation for Fairness-Preserving Group Recommendations](https://doi.org/10.1145/3705328.3759322)|Vit Kostejn, Ladislav Peska, Martin Spisák||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SAGEA:+Sparse+Autoencoder-based+Group+Embeddings+Aggregation+for+Fairness-Preserving+Group+Recommendations)|0|
|[A Tutorial on Recent Advances in Generative Conversational Recommender Systems](https://doi.org/10.1145/3705328.3748010)|Thomas Elmar Kolb, Ahmadou Wagne, Ashmi Banerjee, Fatemeh Nazary, Julia Neidhardt, Yashar Deldjoo, Tommaso Di Noia||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Tutorial+on+Recent+Advances+in+Generative+Conversational+Recommender+Systems)|0|
|[concept2code: Sequential Recommendation with Large Language Models](https://doi.org/10.1145/3705328.3748003)|Omprakash Sonie||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=concept2code:+Sequential+Recommendation+with+Large+Language+Models)|0|
|[Data Access for Recommender Systems Research: leveraging the EU's Digital Services Act](https://doi.org/10.1145/3705328.3748004)|João Vinagre, Lorenzo Porcaro, Silvia Merisio, Erasmo Purificato, Emilia Gómez||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Data+Access+for+Recommender+Systems+Research:+leveraging+the+EU's+Digital+Services+Act)|0|
|[Multi-Agentic Recommender Systems: Foundations, Design Patterns, and E-Commerce Applications - An Industrial Tutorial](https://doi.org/10.1145/3705328.3748008)|Reza Yousefi Maragheh, Yashar Deldjoo, Chi Wang, Jason Cho, Derek Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Agentic+Recommender+Systems:+Foundations,+Design+Patterns,+and+E-Commerce+Applications+-+An+Industrial+Tutorial)|0|
|[Personalized Image Generation for Recommendations Beyond Catalogs](https://doi.org/10.1145/3705328.3748757)|Gabriel Alfonso Patron||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Image+Generation+for+Recommendations+Beyond+Catalogs)|0|
|[On Inherited Popularity Bias in Cold-Start Item Recommendation](https://doi.org/10.1145/3705328.3748035)|Gregor Meehan, Johan Pauwels||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Inherited+Popularity+Bias+in+Cold-Start+Item+Recommendation)|0|
|[Exploitation Over Exploration: Unmasking the Bias in Linear Bandit Recommender Offline Evaluation](https://doi.org/10.1145/3705328.3748166)|Pedro R. Pires, Gregório F. Azevedo, Pietro L. Campos, Rafael T. Sereicikas, Tiago A. Almeida||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploitation+Over+Exploration:+Unmasking+the+Bias+in+Linear+Bandit+Recommender+Offline+Evaluation)|0|
|[Generalized User Representations for Large-Scale Recommendations and Downstream Tasks](https://doi.org/10.1145/3705328.3748132)|Ghazal Fazelnia, Sanket Gupta, Claire Keum, Mark Koh, Timothy Christopher Heath, Guillermo Carrasco Hernández, Stephen Xie, Nandini Singh, Ian Anderson, Maya Hristakeva, Petter Pehrson Skidén, Mounia Lalmas||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generalized+User+Representations+for+Large-Scale+Recommendations+and+Downstream+Tasks)|0|
|[Personalized Interest Graphs for Theme-Driven User Behavior](https://doi.org/10.1145/3705328.3748133)|Oded Zinman, Nazmul Chowdhury, Leandro Fiaschetti, Yuri M. Brovman, Guy Feigenblat, Yotam Eshel||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Interest+Graphs+for+Theme-Driven+User+Behavior)|0|
|[SlateLLM: Distilling LLM Semantics into Session-Aware Slate Recommendation without Inference Overhead](https://doi.org/10.1145/3705328.3759306)|Aayush Singha Roy, Elias Z. Tragos, Aonghus Lawlor, Neil Hurley||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SlateLLM:+Distilling+LLM+Semantics+into+Session-Aware+Slate+Recommendation+without+Inference+Overhead)|0|
|[Auditing Recommender Systems for User Empowerment in Very Large Online Platforms under the Digital Services Act](https://doi.org/10.1145/3705328.3748074)|Matteo Fabbri, Ludovico Boratto||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Auditing+Recommender+Systems+for+User+Empowerment+in+Very+Large+Online+Platforms+under+the+Digital+Services+Act)|0|
|[Breaking Knowledge Boundaries: Cognitive Distillation-enhanced Cross-Behavior Course Recommendation Model](https://doi.org/10.1145/3705328.3748083)|Ruoyu Li, Yangtao Zhou, Chenzhang Li, Hua Chu, Jianan Li, Yuhan Bian||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Breaking+Knowledge+Boundaries:+Cognitive+Distillation-enhanced+Cross-Behavior+Course+Recommendation+Model)|0|
|[Enhancing Online Video Recommendation via a Coarse-to-fine Dynamic Uplift Modeling Framework](https://doi.org/10.1145/3705328.3748070)|Chang Meng, Chenhao Zhai, Xueliang Wang, Shuchang Liu, Xiaoqiang Feng, Lantao Hu, Xiu Li, Han Li, Kun Gai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Online+Video+Recommendation+via+a+Coarse-to-fine+Dynamic+Uplift+Modeling+Framework)|0|
|[Exploring Scaling Laws of CTR Model for Online Performance Improvement](https://doi.org/10.1145/3705328.3748046)|Weijiang Lai, Beihong Jin, Jiongyan Zhang, Yiyuan Zheng, Jian Dong, Jia Cheng, Jun Lei, Xingxing Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+Scaling+Laws+of+CTR+Model+for+Online+Performance+Improvement)|0|
|[Leave No One Behind: Fairness-Aware Cross-Domain Recommender Systems for Non-Overlapping Users](https://doi.org/10.1145/3705328.3748082)|Weixin Chen, Yuhan Zhao, Li Chen, Weike Pan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leave+No+One+Behind:+Fairness-Aware+Cross-Domain+Recommender+Systems+for+Non-Overlapping+Users)|0|
|[Lasso: Large Language Model-based User Simulator for Cross-Domain Recommendation](https://doi.org/10.1145/3705328.3748048)|Yue Chen, Susen Yang, Tong Zhang, Chao Wang, Mingyue Cheng, Chenyi Lei, Han Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Lasso:+Large+Language+Model-based+User+Simulator+for+Cross-Domain+Recommendation)|0|
|[Correcting the LogQ Correction: Revisiting Sampled Softmax for Large-Scale Retrieval](https://doi.org/10.1145/3705328.3748033)|Kirill Khrylchenko, Vladimir Baikalov, Sergei S. Makeev, Artem Matveev, Sergei Liamaev||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Correcting+the+LogQ+Correction:+Revisiting+Sampled+Softmax+for+Large-Scale+Retrieval)|0|
|[Large Scale E-Commerce Model for Learning and Analyzing Long-Term User Preferences](https://doi.org/10.1145/3705328.3748027)|Yonatan Hadar, Yotam Eshel, Tal Franji, Bracha Shapira, Michelle Hwang, Guy Feigenblat||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large+Scale+E-Commerce+Model+for+Learning+and+Analyzing+Long-Term+User+Preferences)|0|
|[Mitigating Latent User Biases in Pre-trained VAE Recommendation Models via On-demand Input Space Transformation](https://doi.org/10.1145/3705328.3748012)|David Penz, Gustavo Junior Escobedo Ticona, Markus Schedl||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mitigating+Latent+User+Biases+in+Pre-trained+VAE+Recommendation+Models+via+On-demand+Input+Space+Transformation)|0|
|[TIM-Rec: Explicit Sparse Feedback on Multi-Item Upselling Recommendations in an Industrial Dataset of Telco Calls](https://doi.org/10.1145/3705328.3748150)|Alessandro Sbandi, Federico Siciliano, Fabrizio Silvestri||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TIM-Rec:+Explicit+Sparse+Feedback+on+Multi-Item+Upselling+Recommendations+in+an+Industrial+Dataset+of+Telco+Calls)|0|
|[Debiasing Implicit Feedback Recommenders via Sliced Wasserstein Distance-based Regularization](https://doi.org/10.1145/3705328.3759320)|Gustavo Escobedo, David Penz, Markus Schedl||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Debiasing+Implicit+Feedback+Recommenders+via+Sliced+Wasserstein+Distance-based+Regularization)|0|
|[From Previous Plays to Long-Term Tastes: Exploring the Long-term Reliability of Recommender Systems Simulations for Children](https://doi.org/10.1145/3705328.3759301)|Robin Ungruh, Alejandro Bellogín, Maria Soledad Pera||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=From+Previous+Plays+to+Long-Term+Tastes:+Exploring+the+Long-term+Reliability+of+Recommender+Systems+Simulations+for+Children)|0|
|[A Non-Parametric Choice Model That Learns How Users Choose Between Recommended Options](https://doi.org/10.1145/3705328.3748090)|Thorsten Krause, Harrie Oosterhuis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Non-Parametric+Choice+Model+That+Learns+How+Users+Choose+Between+Recommended+Options)|0|
|[Enhancing Transferability and Consistency in Cross-Domain Recommendations via Supervised Disentanglement](https://doi.org/10.1145/3705328.3748044)|Yuhan Wang, Qing Xie, Zhifeng Bao, Mengzi Tang, Lin Li, Yongjian Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Transferability+and+Consistency+in+Cross-Domain+Recommendations+via+Supervised+Disentanglement)|0|
|[Heterogeneous User Modeling for LLM-based Recommendation](https://doi.org/10.1145/3705328.3748085)|Honghui Bao, Wenjie Wang, Xinyu Lin, Fengbin Zhu, Teng Sun, Fuli Feng, TatSeng Chua||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Heterogeneous+User+Modeling+for+LLM-based+Recommendation)|0|
|[Hierarchical Graph Information Bottleneck for Multi-Behavior Recommendation](https://doi.org/10.1145/3705328.3748073)|Hengyu Zhang, Chunxu Shen, Xiangguo Sun, Jie Tan, Yanchao Tan, Yu Rong, Hong Cheng, Lingling Yi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Graph+Information+Bottleneck+for+Multi-Behavior+Recommendation)|0|
|[How Do Users Perceive Recommender Systems' Objectives?](https://doi.org/10.1145/3705328.3748066)|Patrik Dokoupil, Ludovico Boratto, Ladislav Peska||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+Do+Users+Perceive+Recommender+Systems'+Objectives?)|0|
|[LANCE: Exploration and Reflection for LLM-based Textual Attacks on News Recommender Systems](https://doi.org/10.1145/3705328.3748081)|Yuyue Zhao, Jin Huang, Shuchang Liu, Jiancan Wu, Xiang Wang, Maarten de Rijke||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LANCE:+Exploration+and+Reflection+for+LLM-based+Textual+Attacks+on+News+Recommender+Systems)|0|
|[MDSBR: Multimodal Denoising for Session-based Recommendation](https://doi.org/10.1145/3705328.3748061)|Yutong Li, Xinyi Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MDSBR:+Multimodal+Denoising+for+Session-based+Recommendation)|0|
|[On the Reliability of Sampling Strategies in Offline Recommender Evaluation](https://doi.org/10.1145/3705328.3748086)|Bruno L. Pereira, Alan Said, Rodrygo L. T. Santos||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+the+Reliability+of+Sampling+Strategies+in+Offline+Recommender+Evaluation)|0|
|[Privacy-Preserving Social Recommendation: Privacy Leakage and Countermeasure](https://doi.org/10.1145/3705328.3748051)|Yuyue Chen, Peng Yang, Zoe Lin Jiang, Wenhao Wu, Junbin Fang, Xuan Wang, Chuanyi Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Privacy-Preserving+Social+Recommendation:+Privacy+Leakage+and+Countermeasure)|0|
|[Tag-augmented Dual-target Cross-domain Recommendation](https://doi.org/10.1145/3705328.3748067)|Mingfan Pan, Qingyang Mao, Xu An, Jianhui Ma, Gang Zhou, Mingyue Cheng, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tag-augmented+Dual-target+Cross-domain+Recommendation)|0|
|[Biases in LLM-Generated Musical Taste Profiles for Recommendation](https://doi.org/10.1145/3705328.3748030)|Bruno Sguerra, Elena V. Epure, Harin Lee, Manuel Moussallam||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Biases+in+LLM-Generated+Musical+Taste+Profiles+for+Recommendation)|0|
|[Estimating Quantum Execution Requirements for Feature Selection in Recommender Systems Using Extreme Value Theory](https://doi.org/10.1145/3705328.3748029)|Jiayang Niu, Qihan Zou, Jie Li, Ke Deng, Mark Sanderson, Yongli Ren||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Estimating+Quantum+Execution+Requirements+for+Feature+Selection+in+Recommender+Systems+Using+Extreme+Value+Theory)|0|
|[Not One News Recommender To Fit Them All: How Different Recommender Strategies Serve Various User Segments](https://doi.org/10.1145/3705328.3748034)|Hanne Vandenbroucke, Ulysse Maes, Lien Michiels, Annelien Smets||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Not+One+News+Recommender+To+Fit+Them+All:+How+Different+Recommender+Strategies+Serve+Various+User+Segments)|0|
|[Popularity‑Bias Vulnerability: Semi‑Supervised Label Inference Attack on Federated Recommender Systems](https://doi.org/10.1145/3705328.3748024)|Kenji Shinoda, Takeyuki Sasai, Shintaro Fukushima||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Popularity‑Bias+Vulnerability:+Semi‑Supervised+Label+Inference+Attack+on+Federated+Recommender+Systems)|0|
|[A Reproducibility Study of Product-side Fairness in Bundle Recommendation](https://doi.org/10.1145/3705328.3748169)|HuySon Nguyen, Yuanna Liu, Masoud Mansoury, Mohammad Aliannejadi, Alan Hanjalic, Maarten de Rijke||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Reproducibility+Study+of+Product-side+Fairness+in+Bundle+Recommendation)|0|
|[Exploring the Potential of LLMs for Serendipity Evaluation in Recommender Systems](https://doi.org/10.1145/3705328.3748167)|Li Kang, Yuhan Zhao, Li Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+the+Potential+of+LLMs+for+Serendipity+Evaluation+in+Recommender+Systems)|0|
|[Informfully Recommenders - Reproducibility Framework for Diversity-aware Intra-session Recommendations](https://doi.org/10.1145/3705328.3748148)|Lucien Heitz, Runze Li, Oana Inel, Abraham Bernstein||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Informfully+Recommenders+-+Reproducibility+Framework+for+Diversity-aware+Intra-session+Recommendations)|0|
|[Revisiting the Performance of Graph Neural Networks for Session-based Recommendation](https://doi.org/10.1145/3705328.3748156)|Faisal Shehzad, Dietmar Jannach||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revisiting+the+Performance+of+Graph+Neural+Networks+for+Session-based+Recommendation)|0|
|[Cross-Batch Aggregation for Streaming Learning from Label Proportions in Industrial-Scale Recommendation Systems](https://doi.org/10.1145/3705328.3748115)|Jonathan Valverde, Tiansheng Yao, Xiang Li, Yuan Gao, Yin Zhang, Andrew Evdokimov, Adam Kraft, Samuel Ieong, Jerry Zhang, Ed H. Chi, Derek Zhiyuan Cheng, Ruoxi Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cross-Batch+Aggregation+for+Streaming+Learning+from+Label+Proportions+in+Industrial-Scale+Recommendation+Systems)|0|
|[Enhancing Online Ranking Systems via Multi-Surface Co-Training for Content Understanding](https://doi.org/10.1145/3705328.3748101)|Gwendolyn Zhao, Yilin Zheng, Raghu Keshavan, Lukasz Heldt, Qian Sun, Fabio Soldo, Li Wei, Aniruddh Nath, Nikhil Khani, Weilong Yang, Dapo Omidiran, Rein Zhang, Mei Chen, Lichan Hong, Xinyang Yi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Online+Ranking+Systems+via+Multi-Surface+Co-Training+for+Content+Understanding)|0|
|[Identifying Offline Metrics that Predict Online Impact: A Pragmatic Strategy for Real-World Recommender Systems](https://doi.org/10.1145/3705328.3748111)|Timo Wilm, Philipp Normann||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Identifying+Offline+Metrics+that+Predict+Online+Impact:+A+Pragmatic+Strategy+for+Real-World+Recommender+Systems)|0|
|[Semantic IDs for Music Recommendation](https://doi.org/10.1145/3705328.3748139)|M. Jeffrey Mei, Florian Henkel, Samuel E. Sandberg, Oliver Bembom, Andreas F. Ehmann||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Semantic+IDs+for+Music+Recommendation)|0|
|[SocRipple: A Two-Stage Framework for Cold-Start Video Recommendations](https://doi.org/10.1145/3705328.3748124)|Amit Jaspal, Kapil Dalwani, Ajantha Ramineni||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SocRipple:+A+Two-Stage+Framework+for+Cold-Start+Video+Recommendations)|0|
|[Stream Normalization for CTR Prediction](https://doi.org/10.1145/3705328.3748093)|Yizhou Sang, Congcong Liu, Yuying Chen, Zhiwei Fang, Xue Jiang, Changping Peng, Zhangang Lin, Ching Law, Jingping Shao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Stream+Normalization+for+CTR+Prediction)|0|
|[Addressing Multiple Hypothesis Bias in CTR Prediction for Ad Selection](https://doi.org/10.1145/3705328.3759299)|Oren Sar Shalom, Neil Daftary||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Addressing+Multiple+Hypothesis+Bias+in+CTR+Prediction+for+Ad+Selection)|0|
|[Opening the Black Box: Interpretable Remedies for Popularity Bias in Recommender Systems](https://doi.org/10.1145/3705328.3759310)|Parviz Ahmadov, Masoud Mansoury||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Opening+the+Black+Box:+Interpretable+Remedies+for+Popularity+Bias+in+Recommender+Systems)|0|
|[ArtEx: A User-Controllable Web Interface for Visual Art Recommendations](https://doi.org/10.1145/3705328.3759343)|Rully Agus Hendrawan, Peter Brusilovsky, Luis A. Leiva, Bereket Abera Yilma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ArtEx:+A+User-Controllable+Web+Interface+for+Visual+Art+Recommendations)|0|
|[Flights Pricelock Fee Recommendation on Online Travel Agent Platform](https://doi.org/10.1145/3705328.3759339)|Akash Khetan, Narasimha Medeme, Deepak Yadav, Anmol Porwal||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Flights+Pricelock+Fee+Recommendation+on+Online+Travel+Agent+Platform)|0|
|[RecViz: Intuitive Graph-based Visual Analytics for Dataset Exploration and Recommender System Evaluation](https://doi.org/10.1145/3705328.3759335)|Jackson Dam, Zixuan Yi, Iadh Ounis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RecViz:+Intuitive+Graph-based+Visual+Analytics+for+Dataset+Exploration+and+Recommender+System+Evaluation)|0|
|[RecSys Challenge 2025: Universal Behavioral Profiles for Recommender Systems](https://doi.org/10.1145/3705328.3748172)|Jacek Dabrowski, Maria Janicka, Lukasz Sienkiewicz, Gergely Stomfai, Dietmar Jannach, Francesco Barile, Marco Polignano, Claudio Pomo, Abhishek Srivastava||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RecSys+Challenge+2025:+Universal+Behavioral+Profiles+for+Recommender+Systems)|0|
|[Recommender Systems for Digital Humanities and Archives: Multistakeholder Evaluation, Scholarly Information Needs, and Multimodal Similarity](https://doi.org/10.1145/3705328.3748761)|Florian AtzenhoferBaumgartner||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recommender+Systems+for+Digital+Humanities+and+Archives:+Multistakeholder+Evaluation,+Scholarly+Information+Needs,+and+Multimodal+Similarity)|0|
|[An Off-Policy Learning Approach for Steering Sentence Generation towards Personalization](https://doi.org/10.1145/3705328.3748088)|Haruka Kiyohara, Daniel Yiming Cao, Yuta Saito, Thorsten Joachims||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Off-Policy+Learning+Approach+for+Steering+Sentence+Generation+towards+Personalization)|0|
|[GRACE: Generative Recommendation via Journey-Aware Sparse Attention on Chain-of-Thought Tokenization](https://doi.org/10.1145/3705328.3748056)|Luyi Ma, Wanjia Zhang, Kai Zhao, Abhishek Kulkarni, Lalitesh Morishetti, Anjana Ganesh, Ashish Ranjan, Aashika Padmanabhan, Jianpeng Xu, Jason H. D. Cho, Praveenkumar Kanumala, Kaushiki Nag, Sumit Dutta, Kamiya Motwani, Malay Patel, Evren Körpeoglu, Sushant Kumar, Kannan Achan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GRACE:+Generative+Recommendation+via+Journey-Aware+Sparse+Attention+on+Chain-of-Thought+Tokenization)|0|
|[Integrating Individual and Group Fairness for Recommender Systems through Social Choice](https://doi.org/10.1145/3705328.3748087)|Amanda Aird, Elena Stefancova, Anas Buhayh, Cassidy All, Martin Homola, Nicholas Mattei, Robin Burke||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Integrating+Individual+and+Group+Fairness+for+Recommender+Systems+through+Social+Choice)|0|
|[LONGER: Scaling Up Long Sequence Modeling in Industrial Recommenders](https://doi.org/10.1145/3705328.3748065)|Zheng Chai, Qin Ren, Xijun Xiao, Huizhi Yang, Bo Han, Sijun Zhang, Di Chen, Hui Lu, Wenlin Zhao, Lele Yu, Xionghang Xie, Shiru Ren, Xiang Sun, Yaocheng Tan, Peng Xu, Yuchao Zheng, Di Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LONGER:+Scaling+Up+Long+Sequence+Modeling+in+Industrial+Recommenders)|0|
|[Measuring Interaction-Level Unlearning Difficulty for Collaborative Filtering](https://doi.org/10.1145/3705328.3748092)|Haocheng Dou, Tao Lian, Xin Xin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Measuring+Interaction-Level+Unlearning+Difficulty+for+Collaborative+Filtering)|0|
|[NLGCL: Naturally Existing Neighbor Layers Graph Contrastive Learning for Recommendation](https://doi.org/10.1145/3705328.3748059)|Jinfeng Xu, Zheyu Chen, Shuo Yang, Jinze Li, Hewei Wang, Wei Wang, Xiping Hu, Edith C. H. Ngai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NLGCL:+Naturally+Existing+Neighbor+Layers+Graph+Contrastive+Learning+for+Recommendation)|0|
|[Off-Policy Evaluation and Learning for Matching Markets](https://doi.org/10.1145/3705328.3748047)|Yudai Hayashi, Shuhei Goda, Yuta Saito||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Off-Policy+Evaluation+and+Learning+for+Matching+Markets)|0|
|[R4ec: A Reasoning, Reflection, and Refinement Framework for Recommendation Systems](https://doi.org/10.1145/3705328.3748068)|Hao Gu, Rui Zhong, Yu Xia, Wei Yang, Chi Lu, Peng Jiang, Kun Gai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=R4ec:+A+Reasoning,+Reflection,+and+Refinement+Framework+for+Recommendation+Systems)|0|
|[Scalable Data Debugging for Neighborhood-based Recommendation with Data Shapley Values](https://doi.org/10.1145/3705328.3748049)|Barrie Kersbergen, Olivier Sprangers, Bojan Karlas, Maarten de Rijke, Sebastian Schelter||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+Data+Debugging+for+Neighborhood-based+Recommendation+with+Data+Shapley+Values)|0|
|[RecPS: Privacy Risk Scoring for Recommender Systems](https://doi.org/10.1145/3705328.3748052)|Jiajie He, Yuechun Gu, Keke Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RecPS:+Privacy+Risk+Scoring+for+Recommender+Systems)|0|
|[Recommendation and Temptation](https://doi.org/10.1145/3705328.3748063)|Md Sanzeed Anwar, Paramveer S. Dhillon, Grant Schoenebeck||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recommendation+and+Temptation)|0|
|[You Don't Bring Me Flowers: Mitigating Unwanted Recommendations Through Conformal Risk Control](https://doi.org/10.1145/3705328.3748054)|Giovanni De Toni, Erasmo Purificato, Emilia Gómez, Andrea Passerini, Bruno Lepri, Cristian Consonni||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=You+Don't+Bring+Me+Flowers:+Mitigating+Unwanted+Recommendations+Through+Conformal+Risk+Control)|0|
|[A Multistakeholder Approach to Value-Driven Co-Design of Recommender Systems Evaluation Metrics in Digital Archives](https://doi.org/10.1145/3705328.3748026)|Florian AtzenhoferBaumgartner, Georg Vogeler, Dominik Kowald||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Multistakeholder+Approach+to+Value-Driven+Co-Design+of+Recommender+Systems+Evaluation+Metrics+in+Digital+Archives)|0|
|[Beyond Visit Trajectories: Enhancing POI Recommendation via LLM-Augmented Text and Image Representations](https://doi.org/10.1145/3705328.3748014)|Zehui Wang, Wolfram Höpken, Dietmar Jannach||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Visit+Trajectories:+Enhancing+POI+Recommendation+via+LLM-Augmented+Text+and+Image+Representations)|0|
|[Beyond Top-1: Addressing Inconsistencies in Evaluating Counterfactual Explanations for Recommender Systems](https://doi.org/10.1145/3705328.3748028)|Amir Reza Mohammadi, Andreas Peintner, Michael Müller, Eva Zangerle||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Top-1:+Addressing+Inconsistencies+in+Evaluating+Counterfactual+Explanations+for+Recommender+Systems)|0|
|[Consistent Explainers or Unreliable Narrators? Understanding LLM-generated Group Recommendations](https://doi.org/10.1145/3705328.3748015)|Cedric Waterschoot, Nava Tintarev, Francesco Barile||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Consistent+Explainers+or+Unreliable+Narrators?+Understanding+LLM-generated+Group+Recommendations)|0|
|[Emotion Vector-Based Fine-Tuning of Large Language Models for Age-Aware Teenage Book Recommendations](https://doi.org/10.1145/3705328.3748037)|Kate Hill, YiuKai Ng, Joey Sherrill||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Emotion+Vector-Based+Fine-Tuning+of+Large+Language+Models+for+Age-Aware+Teenage+Book+Recommendations)|0|
|[HiDePCC: A Novel Dual-Pronged Untargeted Attack on Federated Recommendation via Gradient Perturbation and Cluster Crafting](https://doi.org/10.1145/3705328.3748041)|Yamini Jha, Krishna Tewari, Sukomal Pal||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HiDePCC:+A+Novel+Dual-Pronged+Untargeted+Attack+on+Federated+Recommendation+via+Gradient+Perturbation+and+Cluster+Crafting)|0|
|[SGCL: Unifying Self-Supervised and Supervised Learning for Graph Recommendation](https://doi.org/10.1145/3705328.3748036)|Weizhi Zhang, Liangwei Yang, Zihe Song, Henry Peng Zou, Ke Xu, Yuanjie Zhu, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SGCL:+Unifying+Self-Supervised+and+Supervised+Learning+for+Graph+Recommendation)|0|
|[Are We Really Making Recommendations Robust? Revisiting Model Evaluation for Denoising Recommendation](https://doi.org/10.1145/3705328.3748153)|Guohang Zeng, Jie Lu, Guangquan Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Are+We+Really+Making+Recommendations+Robust?+Revisiting+Model+Evaluation+for+Denoising+Recommendation)|0|
|[Context Trails: A Dataset to Study Contextual and Route Recommendation](https://doi.org/10.1145/3705328.3748151)|Pablo Sánchez, Alejandro Bellogín, Jose L. JorroAragoneses||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Context+Trails:+A+Dataset+to+Study+Contextual+and+Route+Recommendation)|0|
|[GreenFoodLens: Sustainability Labels for Food Recommendation](https://doi.org/10.1145/3705328.3748165)|Giacomo Balloccu, Ludovico Boratto, Gianni Fenu, Mirko Marras, Giacomo Medda, Giovanni Murgia||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GreenFoodLens:+Sustainability+Labels+for+Food+Recommendation)|0|
|[How Powerful are LLMs to Support Multimodal Recommendation? A Reproducibility Study of LLMRec](https://doi.org/10.1145/3705328.3748154)|Maria Lucia Fioretti, Nicola Laterza, Alessia Preziosa, Daniele Malitesta, Claudio Pomo, Fedelucio Narducci, Tommaso Di Noia||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+Powerful+are+LLMs+to+Support+Multimodal+Recommendation?+A+Reproducibility+Study+of+LLMRec)|0|
|[Rethinking the Privacy of Text Embeddings: A Reproducibility Study of "Text Embeddings Reveal (Almost) As Much As Text"](https://doi.org/10.1145/3705328.3748155)|Dominykas Seputis, Yongkang Li, Karsten Langerak, Serghei Mihailov||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rethinking+the+Privacy+of+Text+Embeddings:+A+Reproducibility+Study+of+"Text+Embeddings+Reveal+(Almost)+As+Much+As+Text")|0|
|[Privacy Risks of LLM-Empowered Recommender Systems: An Inversion Attack Perspective](https://doi.org/10.1145/3705328.3748158)|Yubo Wang, Min Tang, Nuo Shen, Shujie Cui, Weiqing Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Privacy+Risks+of+LLM-Empowered+Recommender+Systems:+An+Inversion+Attack+Perspective)|0|
|[Agentic Personalisation of Cross-Channel Marketing Experiences](https://doi.org/10.1145/3705328.3748125)|Sami Abboud, Eleanor Hanna, Olivier Jeunen, Vineesha Raheja, Schaun Wheeler||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Agentic+Personalisation+of+Cross-Channel+Marketing+Experiences)|0|
|[Balanced Public Service Media Recommendation Trade-offs with a Light Carbon Footprint](https://doi.org/10.1145/3705328.3748106)|Marcel Hauck, Michael Huber, Juri Diels, David Wittenberg, Dietmar Jannach||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Balanced+Public+Service+Media+Recommendation+Trade-offs+with+a+Light+Carbon+Footprint)|0|
|[Balancing Fine-tuning and RAG: A Hybrid Strategy for Dynamic LLM Recommendation Updates](https://doi.org/10.1145/3705328.3748105)|Changping Meng, Hongyi Ling, Jianling Wang, Yifan Liu, Shuzhou Zhang, Dapeng Hong, Mingyan Gao, Onkar Dalal, Ed H. Chi, Lichan Hong, Haokai Lu, Ningren Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Balancing+Fine-tuning+and+RAG:+A+Hybrid+Strategy+for+Dynamic+LLM+Recommendation+Updates)|0|
|[LADDER: LLM-Annotated Data for Dogfooded Evaluation of Rankings](https://doi.org/10.1145/3705328.3748094)|Mattia Ottoborgo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LADDER:+LLM-Annotated+Data+for+Dogfooded+Evaluation+of+Rankings)|0|
|[LLM-Powered Nuanced Video Attribute Annotation for Enhanced Recommendations](https://doi.org/10.1145/3705328.3748103)|Boyuan Long, Yueqi Wang, Hiloni Mehta, Mick Zomnir, Omkar Pathak, Changping Meng, Ruolin Jia, Yajun Peng, Dapeng Hong, Xia Wu, Mingyan Gao, Onkar Dalal, Ningren Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LLM-Powered+Nuanced+Video+Attribute+Annotation+for+Enhanced+Recommendations)|0|
|[Not All Impressions Are Created Equal: Psychology-Informed Retention Optimization for Short-Form Video Recommendation](https://doi.org/10.1145/3705328.3748122)|Yuyan Wang, Jing Zhong, Yuxin Cui, Zhaohui Guo, Chuanqi Wei, Yanchen Wang, Zellux Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Not+All+Impressions+Are+Created+Equal:+Psychology-Informed+Retention+Optimization+for+Short-Form+Video+Recommendation)|0|
|[Operational Twin-Driven AI Recommender for Strategic Service Planning](https://doi.org/10.1145/3705328.3748099)|Vivek Singh, Sarith Mohan, Chetan Srinidhi, Santosh Pai, Ullaskrishnan Poikavila, Codruta Ene, Ankur Kapoor, Neil Biehn, Dorin Comaniciu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Operational+Twin-Driven+AI+Recommender+for+Strategic+Service+Planning)|0|
|[RADAR: Recall Augmentation through Deferred Asynchronous Retrieval](https://doi.org/10.1145/3705328.3748146)|Amit Jaspal, Qian Dang, Ajantha Ramineni||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RADAR:+Recall+Augmentation+through+Deferred+Asynchronous+Retrieval)|0|
|[Describe What You See with Multimodal Large Language Models to Enhance Video Recommendations](https://doi.org/10.1145/3705328.3759303)|Marco De Nadai, Andreas Damianou, Mounia Lalmas||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Describe+What+You+See+with+Multimodal+Large+Language+Models+to+Enhance+Video+Recommendations)|0|
|[eSASRec: Enhancing Transformer-based Recommendations in a Modular Fashion](https://doi.org/10.1145/3705328.3759317)|Daria Tikhonovich, Nikita Zelinskiy, Aleksandr V. Petrov, Mayya Spirina, Andrei Semenov, Andrey V. Savchenko, Sergei Kuliev||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=eSASRec:+Enhancing+Transformer-based+Recommendations+in+a+Modular+Fashion)|0|
|[Evaluating Podcast Recommendations with Profile-Aware LLM-as-a-Judge](https://doi.org/10.1145/3705328.3759305)|Francesco Fabbri, Gustavo Penha, Edoardo D'Amico, Alice Wang, Marco De Nadai, Jackie Doremus, Paul Gigioli, Andreas Damianou, Oskar Stål, Mounia Lalmas||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Evaluating+Podcast+Recommendations+with+Profile-Aware+LLM-as-a-Judge)|0|
|[Fine-tuning for Inference-efficient Calibrated Recommendations](https://doi.org/10.1145/3705328.3759319)|Oleg Lesota, Adrian Bajko, Max Walder, Matthias Wenzel, Antonela Tommasel, Markus Schedl||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fine-tuning+for+Inference-efficient+Calibrated+Recommendations)|0|
|[How Fair is Your Diffusion Recommender Model?](https://doi.org/10.1145/3705328.3759318)|Daniele Malitesta, Giacomo Medda, Erasmo Purificato, Mirko Marras, Fragkiskos D. Malliaros, Ludovico Boratto||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+Fair+is+Your+Diffusion+Recommender+Model?)|0|
|[Investigating Carbon Footprint of Recommender Systems Beyond Training Time](https://doi.org/10.1145/3705328.3759324)|Josef Schodl, Oleg Lesota, Antonela Tommasel, Markus Schedl||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Investigating+Carbon+Footprint+of+Recommender+Systems+Beyond+Training+Time)|0|
|[Learning geometry-aware recommender systems with manifold regularization](https://doi.org/10.1145/3705328.3759323)|Zaira Zainulabidova, Julia Borisova, Alexander Hvatov||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+geometry-aware+recommender+systems+with+manifold+regularization)|0|
|[Leveraging Geometric Insights in Hyperbolic Triplet Loss for Improved Recommendations](https://doi.org/10.1145/3705328.3759328)|Viacheslav Yusupov, Maxim Rakhuba, Evgeny Frolov||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Geometric+Insights+in+Hyperbolic+Triplet+Loss+for+Improved+Recommendations)|0|
|[Lift It Up Right: A Recommender System for Safer Lifting Postures](https://doi.org/10.1145/3705328.3759314)|Gaetano Dibenedetto, Pasquale Lops, Marco Polignano, Helma Torkamaan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Lift+It+Up+Right:+A+Recommender+System+for+Safer+Lifting+Postures)|0|
|[Normative Alignment of Recommender Systems via Internal Label Shift](https://doi.org/10.1145/3705328.3759309)|Johannes Kruse, Kasper Lindskow, Michael Riis Andersen, Ryotaro Shimizu, Julian J. McAuley, PierreAlexandre Mattei, Jes Frellsen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Normative+Alignment+of+Recommender+Systems+via+Internal+Label+Shift)|0|
|[Recommendation Is a Dish Better Served Warm](https://doi.org/10.1145/3705328.3759331)|Danil Gusak, Nikita Sukhorukov, Evgeny Frolov||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recommendation+Is+a+Dish+Better+Served+Warm)|0|
|[Recurrent Autoregressive Linear Model for Next-Basket Recommendation](https://doi.org/10.1145/3705328.3759313)|Tereza Zmeskalová, Antoine Ledent, Martin Spisák, Pavel Kordík, Rodrigo Alves||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recurrent+Autoregressive+Linear+Model+for+Next-Basket+Recommendation)|0|
|[RicciFlowRec: A Geometric Root Cause Recommender Using Ricci Curvature on Financial Graphs](https://doi.org/10.1145/3705328.3759312)|Zhongtian Sun, Anoushka Harit||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RicciFlowRec:+A+Geometric+Root+Cause+Recommender+Using+Ricci+Curvature+on+Financial+Graphs)|0|
|[The Hidden Cost of Defaults in Recommender System Evaluation](https://doi.org/10.1145/3705328.3759321)|Hannah Berling, Robin Svahn, Alan Said||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Hidden+Cost+of+Defaults+in+Recommender+System+Evaluation)|0|
|[ArtAICare: An End-to-End Platform for Personalized Art Therapy](https://doi.org/10.1145/3705328.3759338)|Bereket Abera Yilma, Saravanakumar Duraisamy, Stefan Penchev, Tudor Pristav, Luis A. Leiva||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ArtAICare:+An+End-to-End+Platform+for+Personalized+Art+Therapy)|0|
|[Blooming Beats: An Interactive Music Recommender System Grounded in TRACE Principles and Data Humanism](https://doi.org/10.1145/3705328.3759337)|Ibrahim Al Hazwani, Daniel Lutziger, Carlos Kirchdorfer, Luca Huber, Oliver Robin Aschwanden, Jürgen Bernard, Ludovico Boratto||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Blooming+Beats:+An+Interactive+Music+Recommender+System+Grounded+in+TRACE+Principles+and+Data+Humanism)|0|
|[Large Language Model-based Recommendation System Agents](https://doi.org/10.1145/3705328.3759334)|Tommaso Carraro, Brijraj Singh, Niranjan Pedanekar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large+Language+Model-based+Recommendation+System+Agents)|0|
|[PRISM: From Individual Preferences to Group Consensus through Conversational AI-Mediated and Visual Explanations](https://doi.org/10.1145/3705328.3759340)|Ibrahim Al Hazwani, Oliver Robin Aschwanden, Oana Inel, Jürgen Bernard, Ludovico Boratto||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PRISM:+From+Individual+Preferences+to+Group+Consensus+through+Conversational+AI-Mediated+and+Visual+Explanations)|0|
|[Travel Together, Play Together: Gamifying a Group Recommender System for Tourism](https://doi.org/10.1145/3705328.3759344)|Patrícia Alves, Joana Neto, Jorge Lima, José Silva, Luís Conceição, Goreti Marreiros||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Travel+Together,+Play+Together:+Gamifying+a+Group+Recommender+System+for+Tourism)|0|
|[Beyond Algorithms: Reclaiming the Interdisciplinary Roots of Recommender Systems (BEYOND 2025)](https://doi.org/10.1145/3705328.3747998)|Eva Zangerle, Alan Said, Christine Bauer||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Algorithms:+Reclaiming+the+Interdisciplinary+Roots+of+Recommender+Systems+(BEYOND+2025))|0|
|[A Tutorial on Agentic LLM for Recommender Systems](https://doi.org/10.1145/3705328.3748007)|Chengkai Huang, Junda Wu, Tong Yu, Julian J. McAuley, Lina Yao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Tutorial+on+Agentic+LLM+for+Recommender+Systems)|0|
|[A Hands-on Dive Into Quantum Computing for Recommender Systems](https://doi.org/10.1145/3705328.3748006)|Maurizio Ferrari Dacrema, Paolo Cremonesi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Hands-on+Dive+Into+Quantum+Computing+for+Recommender+Systems)|0|
|[Standard Practices for Data Processing and Multimodal Feature Extraction in Recommendation with DataRec and Ducho (D&D4Rec)](https://doi.org/10.1145/3705328.3748009)|Alberto Carlo Maria Mancino, Matteo Attimonelli, Angela Di Fazio, Daniele Malitesta, Tommaso Di Noia||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Standard+Practices+for+Data+Processing+and+Multimodal+Feature+Extraction+in+Recommendation+with+DataRec+and+Ducho+(D&D4Rec))|0|
|[Adding Value to Low-Resource Industrial Recommender Systems](https://doi.org/10.1145/3705328.3748760)|Cornelia M. Kloppers||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adding+Value+to+Low-Resource+Industrial+Recommender+Systems)|0|
|[Addressing Multi-stakeholder Fairness Concerns in Recommender Systems Through Social Choice](https://doi.org/10.1145/3705328.3748756)|Amanda Aird||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Addressing+Multi-stakeholder+Fairness+Concerns+in+Recommender+Systems+Through+Social+Choice)|0|
|[Are Recommender Systems Serving Children? Toward Child-Aware Design and Evaluation](https://doi.org/10.1145/3705328.3748752)|Robin Ungruh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Are+Recommender+Systems+Serving+Children?+Toward+Child-Aware+Design+and+Evaluation)|0|
|[Bayesian Perspectives on Offline Evaluation for Recommender Systems](https://doi.org/10.1145/3705328.3748762)|Michael Benigni||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bayesian+Perspectives+on+Offline+Evaluation+for+Recommender+Systems)|0|
|[Beyond Persuasion: Adaptive Warnings and Balanced Explanations for Informed Decision-Making in Recommender Systems](https://doi.org/10.1145/3705328.3748758)|Elaheh Jafari||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Persuasion:+Adaptive+Warnings+and+Balanced+Explanations+for+Informed+Decision-Making+in+Recommender+Systems)|0|
|[Challenges in Perfume Recommender Systems: Navigating Subjectivity, Context and Sensory Data](https://doi.org/10.1145/3705328.3748754)|ElenaRuxandra Lutan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Challenges+in+Perfume+Recommender+Systems:+Navigating+Subjectivity,+Context+and+Sensory+Data)|0|
|[Fair and Transparent Recommender Systems for Advertisements](https://doi.org/10.1145/3705328.3748755)|Dina Zilbershtein||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fair+and+Transparent+Recommender+Systems+for+Advertisements)|0|
|[Full-Page Recommender: A Modular Framework for Multi-Carousel Recommendations](https://doi.org/10.1145/3705328.3748753)|Jan Kislinger||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Full-Page+Recommender:+A+Modular+Framework+for+Multi-Carousel+Recommendations)|0|
|[Narrative-Driven Itinerary Recommendation: LLM Integration for Immersive Urban Walking](https://doi.org/10.1145/3705328.3748751)|Fabio Ferrero||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Narrative-Driven+Itinerary+Recommendation:+LLM+Integration+for+Immersive+Urban+Walking)|0|
|[Item-centric Exploration for Cold Start Problem](https://doi.org/10.1145/3705328.3748113)|Dong Wang, Junyi Jiao, Arnab Bhadury, Yaping Zhang, Mingyan Gao, Onkar Dalal||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Item-centric+Exploration+for+Cold+Start+Problem)|0|
|[Cold Starting a New Content Type: A Case Study with Netflix Live](https://doi.org/10.1145/3705328.3748112)|Yunan Hu, Mark Thornburg, Mario GarcíaArmas, Vito Ostuni, Anne Cocos, Kriti Kohli, Christoph Kofler, Rob Saltiel||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cold+Starting+a+New+Content+Type:+A+Case+Study+with+Netflix+Live)|0|
|[Zero-shot Cross-domain Knowledge Distillation: A Case study on YouTube Music](https://doi.org/10.1145/3705328.3748138)|Srivaths Ranganathan, Chieh Lo, Bernardo Cunha, Nikhil Khani, Li Wei, Aniruddh Nath, Shawn Andrews, Gergo Varady, Yanwei Song, Jochen Klingenhoefer, Tim Steele||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Zero-shot+Cross-domain+Knowledge+Distillation:+A+Case+study+on+YouTube+Music)|0|
|[PAIRSAT: Integrating Preference-Based Signals for User Satisfaction Estimation in Dialogue Systems](https://doi.org/10.1145/3705328.3759325)|Eran Fainman, Adir Solomon, Osnat Mokryn||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PAIRSAT:+Integrating+Preference-Based+Signals+for+User+Satisfaction+Estimation+in+Dialogue+Systems)|0|
|[PinFM: Foundation Model for User Activity Sequences at a Billion-scale Visual Discovery Platform](https://doi.org/10.1145/3705328.3748050)|Xiangyi Chen, Kousik Rajesh, Matthew Lawhon, Zelun Wang, Hanyu Li, Haomiao Li, Saurabh Vishwas Joshi, Pong Eksombatchai, Jaewon Yang, YiPing Hsu, Jiajing Xu, Charles Rosenberg||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PinFM:+Foundation+Model+for+User+Activity+Sequences+at+a+Billion-scale+Visual+Discovery+Platform)|0|
|[Feedback-Driven Gradual Discovery for Expanding Musical Preferences](https://doi.org/10.1145/3705328.3748025)|Alec Nonnemaker, Ralvi Isufaj, Zoltán Szlávik, Cynthia Liem||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Feedback-Driven+Gradual+Discovery+for+Expanding+Musical+Preferences)|0|
|[The XITE Million Sessions Dataset](https://doi.org/10.1145/3705328.3748168)|Ralvi Isufaj, Ruslan Tsygankov, Zoltán Szlávik||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+XITE+Million+Sessions+Dataset)|0|
|[Closing the Online-Offline Gap: A Scalable Framework for Composed Model Evaluation](https://doi.org/10.1145/3705328.3748117)|Mahanth Kumar Beeraka, Chen Chen, Yining Lu, Briac Marcatte, Weikun Lyu, Brooke Bian, Enriko Aryanto, Ellie Wen, Mohamed A. Radwan, Tianshan Cui, Wenjing Lu, Mohsen Malmir, Yang Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Closing+the+Online-Offline+Gap:+A+Scalable+Framework+for+Composed+Model+Evaluation)|0|
|[SASRec in Action: Real-World Adaptations for ZDF Streaming Service](https://doi.org/10.1145/3705328.3748097)|Venkata Harshit Koneru, Xenija Neufeld, Sebastian Loth, Andreas Grün||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SASRec+in+Action:+Real-World+Adaptations+for+ZDF+Streaming+Service)|0|
|[Scaling Image Variant Optimization Through Customer Bucketing and Response Caching: A Large-Scale Implementation at Amazon Prime Video](https://doi.org/10.1145/3705328.3748134)|Haiyun Jin, Bobby Patel||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scaling+Image+Variant+Optimization+Through+Customer+Bucketing+and+Response+Caching:+A+Large-Scale+Implementation+at+Amazon+Prime+Video)|0|
|[Streaming Trends: A Low-Latency Platform for Dynamic Video Grouping and Trending Corpora Building](https://doi.org/10.1145/3705328.3748120)|Yang Gu, Caroline Zhou, Qiao Zhang, Scott Wang, Yongzhe Wang, Li Zhang, Nikos Parotsidis, CJ Carey, Ashkan Fard, Mingyan Gao, Yaping Zhang, Sourabh Bansod||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Streaming+Trends:+A+Low-Latency+Platform+for+Dynamic+Video+Grouping+and+Trending+Corpora+Building)|0|
|[Balancing Accuracy and Novelty with Sub-Item Popularity](https://doi.org/10.1145/3705328.3759311)|Chiara Mallamaci, Aleksandr V. Petrov, Alberto Carlo Maria Mancino, Vito Walter Anelli, Tommaso Di Noia, Craig Macdonald||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Balancing+Accuracy+and+Novelty+with+Sub-Item+Popularity)|0|
|[Meta Off-Policy Estimation](https://doi.org/10.1145/3705328.3759308)|Olivier Jeunen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Meta+Off-Policy+Estimation)|0|
|[Mitigating Popularity Bias in Counterfactual Explanations using Large Language Models](https://doi.org/10.1145/3705328.3759330)|Arjan Hasami, Masoud Mansoury||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mitigating+Popularity+Bias+in+Counterfactual+Explanations+using+Large+Language+Models)|0|
|[Probabilistic Modeling, Learnability and Uncertainty Estimation for Interaction Prediction in Movie Rating Datasets](https://doi.org/10.1145/3705328.3759332)|Jennifer Poernomo, Nicole Gabrielle Lee Tan, Rodrigo Alves, Antoine Ledent||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Probabilistic+Modeling,+Learnability+and+Uncertainty+Estimation+for+Interaction+Prediction+in+Movie+Rating+Datasets)|0|
|[t-Testing the Waters: Empirically Validating Assumptions for Reliable A/B-Testing](https://doi.org/10.1145/3705328.3759307)|Olivier Jeunen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=t-Testing+the+Waters:+Empirically+Validating+Assumptions+for+Reliable+A/B-Testing)|0|
|[APS Explorer: Navigating Algorithm Performance Spaces for Informed Dataset Selection](https://doi.org/10.1145/3705328.3759342)|Tobias Vente, Michael Heep, Abdullah Abbas, Theodor Sperle, Joeran Beel, Bart Goethals||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=APS+Explorer:+Navigating+Algorithm+Performance+Spaces+for+Informed+Dataset+Selection)|0|
|[Multi-Armed Bandits in the Wild](https://doi.org/10.1145/3705328.3748005)|Kim Falk||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Armed+Bandits+in+the+Wild)|0|
|[Multi-Granularity Distribution Modeling for Video Watch Time Prediction via Exponential-Gaussian Mixture Network](https://doi.org/10.1145/3705328.3748080)|Xu Zhao, Ruibo Ma, Jiaqi Chen, Weiqi Zhao, Ping Yang, Yao Hu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Granularity+Distribution+Modeling+for+Video+Watch+Time+Prediction+via+Exponential-Gaussian+Mixture+Network)|0|
|[Prompt-to-Slate: Diffusion Models for Prompt-Conditioned Slate Generation](https://doi.org/10.1145/3705328.3748072)|Federico Tomasi, Francesco Fabbri, Justin Carter, Elias Kalomiris, Mounia Lalmas, Zhenwen Dai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Prompt-to-Slate:+Diffusion+Models+for+Prompt-Conditioned+Slate+Generation)|0|
|[Rethinking Overconfidence in VAEs: Can Label Smoothing Help?](https://doi.org/10.1145/3705328.3748039)|WooSeong Yun, Yeojun Choi, YoonSik Cho||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rethinking+Overconfidence+in+VAEs:+Can+Label+Smoothing+Help?)|0|
|[Stairway to Fairness: Connecting Group and Individual Fairness](https://doi.org/10.1145/3705328.3748031)|Theresia Veronika Rampisela, Maria Maistro, Tuukka Ruotsalo, Falk Scholer, Christina Lioma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Stairway+to+Fairness:+Connecting+Group+and+Individual+Fairness)|0|
|[See the Movie, Hear the Song, Read the Book: Extending MovieLens-1M, Last.fm-2K, and DBbook with Multimodal Data](https://doi.org/10.1145/3705328.3748162)|Giuseppe Spillo, Elio Musacchio, Cataldo Musto, Marco de Gemmis, Pasquale Lops, Giovanni Semeraro||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=See+the+Movie,+Hear+the+Song,+Read+the+Book:+Extending+MovieLens-1M,+Last.fm-2K,+and+DBbook+with+Multimodal+Data)|0|
|[Efficient Off-Policy Evaluation of Content Blending in Station-Based Music Experiences](https://doi.org/10.1145/3705328.3748114)|Chelsea Weaver, Arvind Balasubramanian, Juan Borgnino, Ben London||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Off-Policy+Evaluation+of+Content+Blending+in+Station-Based+Music+Experiences)|0|
|[Kamae: Bridging Spark and Keras for Seamless ML Preprocessing](https://doi.org/10.1145/3705328.3748126)|George Barrowclough, Marian Andrecki, James Shinner, Daniele Donghi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Kamae:+Bridging+Spark+and+Keras+for+Seamless+ML+Preprocessing)|0|
|[Metadata Generation and Evaluation using LLMs - Case Study on Canonical Titles](https://doi.org/10.1145/3705328.3748100)|Sinan Zhu, Sanja Simonovikj, Darren Edmonds, Yang Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Metadata+Generation+and+Evaluation+using+LLMs+-+Case+Study+on+Canonical+Titles)|0|
|[Never Miss an Episode: How LLMs are Powering Serial Content Discovery on YouTube](https://doi.org/10.1145/3705328.3748104)|Aditee Kumthekar, Li Wei, Andrea Bettale, Mahesh Sathiamoorthy, Zrinka Puljiz, Aditya Mahajan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Never+Miss+an+Episode:+How+LLMs+are+Powering+Serial+Content+Discovery+on+YouTube)|0|
|[Pareto-Optimal Solution: Optimizing Engagement and Revenue](https://doi.org/10.1145/3705328.3748142)|Shaghayegh Agah, Shaun Schaeffer, Maria Peifer, Neeraj Sharma, Ankit Maheshwari, Sardar Hamidian||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pareto-Optimal+Solution:+Optimizing+Engagement+and+Revenue)|0|
|[Simulating Discoverability for Upcoming Content in TV Entertainment Platforms](https://doi.org/10.1145/3705328.3748137)|Adeep Hande, Kishorekumar Sundararajan, Yidnekachew Endale, Sardar Hamidian||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Simulating+Discoverability+for+Upcoming+Content+in+TV+Entertainment+Platforms)|0|
|[Interactive Playlist Generation from Titles](https://doi.org/10.1145/3705328.3759336)|Eléa Vellard, Enzo CharoloisPasqua, Youssra Rebboud, Pasquale Lisena, Raphaël Troncy||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interactive+Playlist+Generation+from+Titles)|0|

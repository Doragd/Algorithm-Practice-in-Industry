# KDD2022 Paper List

|论文|作者|组织|摘要|翻译|代码|引用数|
|---|---|---|---|---|---|---|
|[Contrastive Cross-domain Recommendation in Matching](https://doi.org/10.1145/3534678.3539125)|Ruobing Xie, Qi Liu, Liangdong Wang, Shukai Liu, Bo Zhang, Leyu Lin|WeChat, Tencent, Beijing, China|Cross-domain recommendation (CDR) aims to provide better recommendation results in the target domain with the help of the source domain, which is widely used and explored in real-world systems. However, CDR in the matching (i.e., candidate generation) module struggles with the data sparsity and popularity bias issues in both representation learning and knowledge transfer. In this work, we propose a novel Contrastive Cross-Domain Recommendation (CCDR) framework for CDR in matching. Specifically, we build a huge diversified preference network to capture multiple information reflecting user diverse interests, and design an intra-domain contrastive learning (intra-CL) and three inter-domain contrastive learning (inter-CL) tasks for better representation learning and knowledge transfer. The intra-CL enables more effective and balanced training inside the target domain via a graph augmentation, while the inter-CL builds different types of cross-domain interactions from user, taxonomy, and neighbor aspects. In experiments, CCDR achieves significant improvements on both offline and online evaluations in a real-world system. Currently, we have deployed our CCDR on WeChat Top Stories, affecting plenty of users. The source code is in https://github.com/lqfarmer/CCDR.|跨域推荐(CDR)是在源域的帮助下在目标域中提供更好的推荐结果，在现实系统中得到了广泛的应用和探索。然而，匹配(即候选人生成)模块中的 CDR 在表示学习和知识转移中都面临着数据稀疏和流行偏差的问题。在这项工作中，我们提出了一个新的对比跨域推荐(CCDR)框架的 CDR 匹配。具体来说，我们建立了一个巨大的多样化偏好网络来捕获反映用户不同兴趣的多种信息，并设计了一个域内对比学习(域内对比学习)和三个域间对比学习(域间对比学习)任务来更好地表示学习和知识转移。CL 内部通过图增强实现了目标域内更有效和平衡的培训，而 CL 间从用户、分类和邻居方面构建不同类型的跨域交互。在实验中，CCDR 对现实系统中的离线和在线评估都有显著的改进。目前，我们已经在微信上部署了 CCDR，影响了大量的用户。源代码在 https://github.com/lqfarmer/ccdr 里。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Cross-domain+Recommendation+in+Matching)|12|
|[Graph-Flashback Network for Next Location Recommendation](https://doi.org/10.1145/3534678.3539383)|Xuan Rao, Lisi Chen, Yong Liu, Shuo Shang, Bin Yao, Peng Han|Univ Elect Sci & Technol China, Chengdu, Peoples R China; Aalborg Univ, Aalborg, Denmark; Nanyang Technol Univ, Singapore, Singapore; Shanghai Jiao Tong Univ, Shanghai, Peoples R China|Next Point-of Interest (POI) recommendation plays an important role in location-based applications, which aims to recommend the next POIs to users that they are most likely to visit based on their historical trajectories. Existing methods usually use rich side information, or customized POI graphs to capture the sequential patterns among POIs. However, the graphs only focus on connectivity between POIs. Few studies propose to explicitly learn a weighted POI graph, which could reflect the transition patterns among POIs and show the importance of its different neighbors for each POI. In addition, these approaches simply utilize the user characteristics for personalized POI recommendation without sufficient consideration. To this end, we construct a novel User-POI Knowledge Graph with strong representation ability, called Spatial-Temporal Knowledge Graph (STKG). STKG is used to learn the representations of each node (i.e., user, POI) and each edge. Then, we design a similarity function to construct our POI transition graph based on the learned representations. To incorporate the learned graph into sequential model, we propose a novel network Graph-Flashback for recommendation. Graph-Flashback applies a simplified Graph Convolution Network (GCN) on the POI transition graph to enrich the representation of each POI. Further, we define a similarity function to consider both spatiotemporal information and user preference in modelling sequential regularity. Experimental results on two real-world datasets show that our proposed method achieves the state-of-the-art performance and significantly outperforms all existing solutions.|下一兴趣点（POI）推荐在基于位置的服务中具有重要作用，其目标是根据用户的历史轨迹推荐最可能访问的下一个POI。现有方法通常使用丰富的辅助信息或定制化POI图来捕捉POI间的序列模式。然而这些图结构仅关注POI间的连通性，目前鲜有研究尝试显式学习加权POI图——这种图既能反映POI间的转移模式，又能展示每个POI不同邻居的重要性。此外，现有方案在个性化POI推荐中未能充分考量用户特征。为此，我们构建了具有强表征能力的用户-兴趣点知识图谱（STKG），该图谱可用于学习每个节点（用户、POI）及边的表征。基于学习到的表征，我们设计了相似度函数构建POI转移图。为了将学习到的图结构融入序列模型，我们提出新型推荐网络Graph-Flashback：该网络在POI转移图上应用简化图卷积网络（GCN）以丰富每个POI的表征，并通过定义融合时空信息与用户偏好的相似度函数来建模序列规律性。在两个真实数据集上的实验表明，所提方法实现了最先进的性能，显著优于所有现有解决方案。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph-Flashback+Network+for+Next+Location+Recommendation)|9|
|[Meta-Learned Metrics over Multi-Evolution Temporal Graphs](https://doi.org/10.1145/3534678.3539313)|Dongqi Fu, Liri Fang, Ross Maciejewski, Vetle I. Torvik, Jingrui He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Meta-Learned+Metrics+over+Multi-Evolution+Temporal+Graphs)|9|
|[FLDetector: Defending Federated Learning Against Model Poisoning Attacks via Detecting Malicious Clients](https://doi.org/10.1145/3534678.3539231)|Zaixi Zhang, Xiaoyu Cao, Jinyuan Jia, Neil Zhenqiang Gong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FLDetector:+Defending+Federated+Learning+Against+Model+Poisoning+Attacks+via+Detecting+Malicious+Clients)|8|
|[Surrogate for Long-Term User Experience in Recommender Systems](https://doi.org/10.1145/3534678.3539073)|Yuyan Wang, Mohit Sharma, Can Xu, Sriraj Badam, Qian Sun, Lee Richardson, Lisa Chung, Ed H. Chi, Minmin Chen|Google, Mountain View, CA, USA; Google Research, Brain Team, Mountain View, CA, USA|Over the years we have seen recommender systems shifting focus from optimizing short-term engagement toward improving long-term user experience on the platforms. While defining good long-term user experience is still an active research area, we focus on one specific aspect of improved long-term user experience here, which is user revisiting the platform. These long term outcomes however are much harder to optimize due to the sparsity in observing these events and low signal-to-noise ratio (weak connection) between these long-term outcomes and a single recommendation. To address these challenges, we propose to establish the association between these long-term outcomes and a set of more immediate term user behavior signals that can serve as surrogates for optimization. To this end, we conduct a large-scale study of user behavior logs on one of the largest industrial recommendation platforms serving billions of users. We study a broad set of sequential user behavior patterns and standardize a procedure to pinpoint the subset that has strong predictive power of the change in users' long-term visiting frequency. Specifically, they are predictive of users' increased visiting to the platform in $5$ months among the group of users with the same visiting frequency to begin with. We validate the identified subset of user behaviors by incorporating them as reward surrogates for long-term user experience in a reinforcement learning (RL) based recommender. Results from multiple live experiments on the industrial recommendation platform demonstrate the effectiveness of the proposed set of surrogates in improving long-term user experience.|多年来，我们已经看到推荐系统的重点从优化短期参与转向改善平台上的长期用户体验。虽然定义良好的长期用户体验仍然是一个活跃的研究领域，我们在这里重点关注改善长期用户体验的一个具体方面，即用户重新访问平台。然而，这些长期结果更难优化，因为观察这些事件的信噪比很少，而且这些长期结果与单一建议之间的联系很弱。为了应对这些挑战，我们建议在这些长期结果和一组更直接的用户行为信号之间建立联系，这些信号可以作为优化的替代品。为此，我们在为数十亿用户服务的最大的工业推荐平台之一上，对用户行为日志进行了大规模的研究。我们研究了一组广泛的顺序用户行为模式，并标准化了一个过程，以确定子集有强大的预测能力的变化，用户的长期访问频率。具体来说，他们预测用户访问该平台的次数将在5美元一个月内增加，而且访问频率从一开始就相同。我们通过将已识别的用户行为子集作为基于强化学习(RL)的推荐系统中长期用户体验的奖励替代品来验证它们。在工业推荐平台上的多个现场实验结果证明了所提出的替代品集在改善长期用户体验方面的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Surrogate+for+Long-Term+User+Experience+in+Recommender+Systems)|7|
|[Multi-modal Siamese Network for Entity Alignment](https://doi.org/10.1145/3534678.3539244)|Liyi Chen, Zhi Li, Tong Xu, Han Wu, Zhefeng Wang, Nicholas Jing Yuan, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-modal+Siamese+Network+for+Entity+Alignment)|7|
|[GraphMAE: Self-Supervised Masked Graph Autoencoders](https://doi.org/10.1145/3534678.3539321)|Zhenyu Hou, Xiao Liu, Yukuo Cen, Yuxiao Dong, Hongxia Yang, Chunjie Wang, Jie Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphMAE:+Self-Supervised+Masked+Graph+Autoencoders)|7|
|[MSDR: Multi-Step Dependency Relation Networks for Spatial Temporal Forecasting](https://doi.org/10.1145/3534678.3539397)|Dachuan Liu, Jin Wang, Shuo Shang, Peng Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MSDR:+Multi-Step+Dependency+Relation+Networks+for+Spatial+Temporal+Forecasting)|7|
|[Joint Knowledge Graph Completion and Question Answering](https://doi.org/10.1145/3534678.3539289)|Lihui Liu, Boxin Du, Jiejun Xu, Yinglong Xia, Hanghang Tong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Joint+Knowledge+Graph+Completion+and+Question+Answering)|7|
|[Graph Neural Networks for Multimodal Single-Cell Data Integration](https://doi.org/10.1145/3534678.3539213)|Hongzhi Wen, Jiayuan Ding, Wei Jin, Yiqi Wang, Yuying Xie, Jiliang Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Neural+Networks+for+Multimodal+Single-Cell+Data+Integration)|7|
|[Multi-Behavior Hypergraph-Enhanced Transformer for Sequential Recommendation](https://doi.org/10.1145/3534678.3539342)|Yuhao Yang, Chao Huang, Lianghao Xia, Yuxuan Liang, Yanwei Yu, Chenliang Li|Wuhan University, Wuhan, China; University of Hong Kong, Hong Kong, China; National University of Singapore, Singapore, Singapore; Ocean University of China, Qingdao, China|Learning dynamic user preference has become an increasingly important component for many online platforms (e.g., video-sharing sites, e-commerce systems) to make sequential recommendations. Previous works have made many efforts to model item-item transitions over user interaction sequences, based on various architectures, e.g., recurrent neural networks and self-attention mechanism. Recently emerged graph neural networks also serve as useful backbone models to capture item dependencies in sequential recommendation scenarios. Despite their effectiveness, existing methods have far focused on item sequence representation with singular type of interactions, and thus are limited to capture dynamic heterogeneous relational structures between users and items (e.g., page view, add-to-favorite, purchase). To tackle this challenge, we design a Multi-Behavior Hypergraph-enhanced T ransformer framework (MBHT) to capture both short-term and long-term cross-type behavior dependencies. Specifically, a multi-scale Transformer is equipped with low-rank self-attention to jointly encode behavior-aware sequential patterns from fine-grained and coarse-grained levels. Additionally,we incorporate the global multi-behavior dependency into the hypergraph neural architecture to capture the hierarchical long-range item correlations in a customized manner. Experimental results demonstrate the superiority of our MBHT over various state-of- the-art recommendation solutions across different settings. Further ablation studies validate the effectiveness of our model design and benefits of the new MBHT framework. Our implementation code is released at: https://github.com/yuh-yang/MBHT-KDD22.|学习动态用户偏好已经成为许多在线平台(如视频分享网站、电子商务系统)提供顺序推荐的一个越来越重要的组成部分。以往的研究基于多种体系结构，如递归神经网络和自我注意机制，对用户交互序列上的项目-项目转换进行了大量的研究。最近出现的图形神经网络也可以作为有用的骨干模型，以捕获项目依赖的顺序推荐场景。尽管现有的方法很有效，但是现有的方法都集中在单一交互类型的项目序列表示上，因此仅限于捕获用户和项目之间的动态异构关系结构(例如，页面查看、添加到收藏夹、购买)。为了应对这一挑战，我们设计了一个多行为超图增强型 T 变换器框架(MBHT)来捕获短期和长期的跨类型行为依赖。具体而言，多尺度变压器配备低级自注意，以从细粒度和粗粒度级别联合编码行为感知的序列模式。此外，我们将全局多行为依赖引入到超图神经结构中，以自定义的方式获取层次化的远程项目相关性。实验结果表明，我们的 MBHT 优于不同设置的各种最先进的推荐解决方案。进一步的消融研究验证了我们的模型设计的有效性和新的 MBHT 框架的好处。我们的实施代码在以下 https://github.com/yuh-yang/mbht-kdd22发布:。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Behavior+Hypergraph-Enhanced+Transformer+for+Sequential+Recommendation)|6|
|[CommerceMM: Large-Scale Commerce MultiModal Representation Learning with Omni Retrieval](https://doi.org/10.1145/3534678.3539151)|Licheng Yu, Jun Chen, Animesh Sinha, Mengjiao Wang, Yu Chen, Tamara L. Berg, Ning Zhang|Meta AI, Menlo Park, CA, USA|We introduce CommerceMM - a multimodal model capable of providing a diverse and granular understanding of commerce topics associated to the given piece of content (image, text, image+text), and having the capability to generalize to a wide range of tasks, including Multimodal Categorization, Image-Text Retrieval, Query-to-Product Retrieval, Image-to-Product Retrieval, etc. We follow the pre-training + fine-tuning training regime and present 5 effective pre-training tasks on image-text pairs. To embrace more common and diverse commerce data with text-to-multimodal, image-to-multimodal, and multimodal-to-multimodal mapping, we propose another 9 novel cross-modal and cross-pair retrieval tasks, called Omni-Retrieval pre-training. We also propose a novel approach of modality randomization to dynamically adjust our model under different efficiency constraints. The pre-training is conducted in an efficient manner with only two forward/backward updates for the combined 14 tasks. Extensive experiments and analysis show the effectiveness of each task. When combining all pre-training tasks, our model achieves state-of-the-art performance on 7 commerce-related downstream tasks after fine-tuning.|我们介绍 CommerceMM ——一个多模态模型，它能够提供对与给定内容(图像、文本、图像 + 文本)相关的商业主题的多样化和细粒度的理解，并且能够泛化到广泛的任务，包括多模态分类、图像-文本检索、查询到产品检索、图像到产品检索等。我们遵循预先训练 + 微调训练制度，提出了5个有效的图像-文本对预先训练任务。为了使用文本到多模式、图像到多模式以及多模式到多模式映射来接受更多常见和多样化的商业数据，我们提出了另外9个新的跨模式和交叉对检索任务，称为 Omni-Retrieval pre-training。提出了一种新的模态随机化方法，在不同的效率约束下动态调整模型。预先培训是在一个有效的方式进行，只有两个向前/向后更新的合并14个任务。大量的实验和分析表明了每个任务的有效性。当结合所有的预训练任务时，我们的模型在经过微调后在7个与商业相关的下游任务上达到了最先进的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CommerceMM:+Large-Scale+Commerce+MultiModal+Representation+Learning+with+Omni+Retrieval)|6|
|[Learning to Rotate: Quaternion Transformer for Complicated Periodical Time Series Forecasting](https://doi.org/10.1145/3534678.3539234)|Weiqi Chen, Wenwei Wang, Bingqing Peng, Qingsong Wen, Tian Zhou, Liang Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Rotate:+Quaternion+Transformer+for+Complicated+Periodical+Time+Series+Forecasting)|6|
|[FederatedScope-GNN: Towards a Unified, Comprehensive and Efficient Package for Federated Graph Learning](https://doi.org/10.1145/3534678.3539112)|Zhen Wang, Weirui Kuang, Yuexiang Xie, Liuyi Yao, Yaliang Li, Bolin Ding, Jingren Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FederatedScope-GNN:+Towards+a+Unified,+Comprehensive+and+Efficient+Package+for+Federated+Graph+Learning)|6|
|[CrossCBR: Cross-view Contrastive Learning for Bundle Recommendation](https://doi.org/10.1145/3534678.3539229)|Yunshan Ma, Yingzhi He, An Zhang, Xiang Wang, TatSeng Chua|Sea NExT Joint Lab, Galaxis, Singapore; Univ Sci & Technol China, Hefei, Peoples R China|Bundle recommendation aims to recommend a bundle of related items to users, which can satisfy the users' various needs with one-stop convenience. Recent methods usually take advantage of both user-bundle and user-item interactions information to obtain informative representations for users and bundles, corresponding to bundle view and item view, respectively. However, they either use a unified view without differentiation or loosely combine the predictions of two separate views, while the crucial cooperative association between the two views' representations is overlooked. In this work, we propose to model the cooperative association between the two different views through cross-view contrastive learning. By encouraging the alignment of the two separately learned views, each view can distill complementary information from the other view, achieving mutual enhancement. Moreover, by enlarging the dispersion of different users/bundles, the self-discrimination of representations is enhanced. Extensive experiments on three public datasets demonstrate that our method outperforms SOTA baselines by a large margin. Meanwhile, our method requires minimal parameters of three set of embeddings (user, bundle, and item) and the computational costs are largely reduced due to more concise graph structure and graph learning module. In addition, various ablation and model studies demystify the working mechanism and justify our hypothesis. Codes and datasets are available at https://github.com/mysbupt/CrossCBR.|捆绑推荐旨在向用户推荐一组相关项目，通过一站式服务满足用户的多样化需求。现有方法通常同时利用用户-捆绑包和用户-项目交互信息，分别从捆绑包视图和项目视图获取用户与捆绑包的信息表征。然而，这些方法要么未加区分地使用统一视图，要么松散地组合两个独立视图的预测结果，却忽视了两个视图表征间至关重要的协同关联。本研究通过跨视图对比学习建模两种视图间的协同关联：通过促进两个独立学习视图的对齐，使每个视图能从另一视图中提取互补信息，实现相互增强。此外，通过扩大不同用户/捆绑包的分散度，增强了表征的自区分能力。在三个公开数据集上的大量实验表明，本方法以显著优势超越现有最优基线模型。同时，我们的方法仅需用户、捆绑包和项目三组嵌入的最小参数量，且得益于更简洁的图结构和图学习模块，计算成本大幅降低。多种消融实验与模型研究揭示了工作机制并验证了我们的假设。代码和数据集已开源：https://github.com/mysbupt/CrossCBR。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CrossCBR:+Cross-view+Contrastive+Learning+for+Bundle+Recommendation)|5|
|[Data-Efficient Brain Connectome Analysis via Multi-Task Meta-Learning](https://doi.org/10.1145/3534678.3542680)|Yi Yang, Yanqiao Zhu, Hejie Cui, Xuan Kan, Lifang He, Ying Guo, Carl Yang|Emory Univ, Dept Biostat & Bioinformat, Atlanta, GA USA; Lehigh Univ, Dept Comp Sci & Engn, Bethlehem, PA USA; Emory Univ, Dept Comp Sci, Atlanta, GA 30322 USA; Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA USA|Brain networks characterize complex connectivities among brain regions as graph structures, which provide a powerful means to study brain connectomes. In recent years, graph neural networks have emerged as a prevalent paradigm of learning with structured data. However, most brain network datasets are limited in sample sizes due to the relatively high cost of data acquisition, which hinders the deep learning models from sufficient training. Inspired by meta-learning that learns new concepts fast with limited training examples, this paper studies data-efficient training strategies for analyzing brain connectomes in a cross-dataset setting. Specifically, we propose to meta-train the model on datasets of large sample sizes and transfer the knowledge to small datasets. In addition, we also explore two brain-network-oriented designs, including atlas transformation and adaptive task reweighing. Compared to other pre-training strategies, our meta-learning-based approach achieves higher and stabler performance, which demonstrates the effectiveness of our proposed solutions. The framework is also able to derive new insights regarding the similarities among datasets and diseases in a data-driven fashion.|脑网络以图结构形式刻画了大脑区域间复杂的连接关系，为研究脑连接组提供了有力工具。近年来，图神经网络已成为处理结构化数据的主流范式。然而，由于数据采集成本较高，大多数脑网络数据集的样本量有限，这阻碍了深度学习模型的充分训练。受元学习能够通过少量训练样本快速学习新概念的启发，本研究探索了在跨数据集场景下进行脑连接组分析的数据高效训练策略。具体而言，我们提出在多样本数据集上进行元训练，并将知识迁移至小规模数据集。此外，我们还探索了两种面向脑网络的定制化设计：图谱转换和自适应任务权重调整。与其他预训练策略相比，基于元学习的方法获得了更高且更稳定的性能，验证了所提出方案的有效性。该框架还能以数据驱动的方式揭示数据集与疾病间相似性的新见解。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Data-Efficient+Brain+Connectome+Analysis+via+Multi-Task+Meta-Learning)|5|
|[Matrix Profile XXIV: Scaling Time Series Anomaly Detection to Trillions of Datapoints and Ultra-fast Arriving Data Streams](https://doi.org/10.1145/3534678.3539271)|Yue Lu, Renjie Wu, Abdullah Mueen, Maria A. Zuluaga, Eamonn J. Keogh||Time series anomaly detection remains one of the most active areas of research in data mining. In spite of the dozens of creative solutions proposed for this problem, recent empirical evidence suggests that time series discords, a relatively simple twenty-year old distance-based technique, remains among the state-of-art techniques. While there are many algorithms for computing the time series discords, they all have limitations. First, they are limited to the batch case, whereas the online case is more actionable. Second, these algorithms exhibit poor scalability beyond tens of thousands of datapoints. In this work we introduce DAMP, a novel algorithm that addresses both these issues. DAMP computes exact left-discords on fast arriving streams, at up to 300,000 Hz using a commodity desktop. This allows us to find time series discords in datasets with trillions of datapoints for the first time. We will demonstrate the utility of our algorithm with the most ambitious set of time series anomaly detection experiments ever conducted.|时间序列异常检测一直是数据挖掘领域中最活跃的研究方向之一。尽管已有数十种创新性解决方案被提出，但近期实证研究表明，时间序列不和谐模式——一种相对简单、具有二十年历史的基于距离的技术——仍处于最先进技术行列。尽管存在多种计算时间序列不和谐模式的算法，但它们都存在局限性：首先，这些算法仅限于批处理场景，而在线检测场景更具可操作性；其次，这些算法在超过数万个数据点时的可扩展性表现不佳。本研究提出新型算法DAMP，可同时解决这两个问题。DAMP能在普通台式计算机上以最高30万赫兹的频率，对快速到达的数据流进行精确左向不和谐模式检测。这使我们首次能够在具有数万亿数据点的数据集中发现时间序列不和谐模式。我们将通过执行迄今最雄心勃勃的时间序列异常检测实验集，来证明该算法的实用价值。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Matrix+Profile+XXIV:+Scaling+Time+Series+Anomaly+Detection+to+Trillions+of+Datapoints+and+Ultra-fast+Arriving+Data+Streams)|5|
|[ROLAND: Graph Learning Framework for Dynamic Graphs](https://doi.org/10.1145/3534678.3539300)|Jiaxuan You, Tianyu Du, Jure Leskovec||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ROLAND:+Graph+Learning+Framework+for+Dynamic+Graphs)|5|
|[Multiplex Heterogeneous Graph Convolutional Network](https://doi.org/10.1145/3534678.3539482)|Pengyang Yu, Chaofan Fu, Yanwei Yu, Chao Huang, Zhongying Zhao, Junyu Dong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multiplex+Heterogeneous+Graph+Convolutional+Network)|5|
|[ERNIE-GeoL: A Geography-and-Language Pre-trained Model and its Applications in Baidu Maps](https://doi.org/10.1145/3534678.3539021)|Jizhou Huang, Haifeng Wang, Yibo Sun, Yunsheng Shi, Zhengjie Huang, An Zhuo, Shikun Feng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ERNIE-GeoL:+A+Geography-and-Language+Pre-trained+Model+and+its+Applications+in+Baidu+Maps)|5|
|[ChemicalX: A Deep Learning Library for Drug Pair Scoring](https://doi.org/10.1145/3534678.3539023)|Benedek Rozemberczki, Charles Tapley Hoyt, Anna Gogleva, Piotr Grabowski, Klas Karis, Andrej Lamov, Andriy Nikolov, Sebastian Nilsson, Michaël Ughetto, Yu Wang, Tyler Derr, Benjamin M. Gyori||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ChemicalX:+A+Deep+Learning+Library+for+Drug+Pair+Scoring)|5|
|[DuARE: Automatic Road Extraction with Aerial Images and Trajectory Data at Baidu Maps](https://doi.org/10.1145/3534678.3539029)|Jianzhong Yang, Xiaoqing Ye, Bin Wu, Yanlei Gu, Ziyu Wang, Deguo Xia, Jizhou Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DuARE:+Automatic+Road+Extraction+with+Aerial+Images+and+Trajectory+Data+at+Baidu+Maps)|5|
|[TwHIN: Embedding the Twitter Heterogeneous Information Network for Personalized Recommendation](https://doi.org/10.1145/3534678.3539080)|Ahmed ElKishky, Thomas Markovich, Serim Park, Chetan Verma, Baekjin Kim, Ramy Eskander, Yury Malkov, Frank Portman, Sofía Samaniego, Ying Xiao, Aria Haghighi|Twitter Cortex, New York, NY, USA; Twitter Cortex, Seattle, WA, USA; Twitter Cortex, San Francisco, CA, USA; Twitter Cortex, Boston, MA, USA; Twitter, San Francisco, CA, USA|Social networks, such as Twitter, form a heterogeneous information network (HIN) where nodes represent domain entities (e.g., user, content, advertiser, etc.) and edges represent one of many entity interactions (e.g, a user re-sharing content or "following" another). Interactions from multiple relation types can encode valuable information about social network entities not fully captured by a single relation; for instance, a user's preference for accounts to follow may depend on both user-content engagement interactions and the other users they follow. In this work, we investigate knowledge-graph embeddings for entities in the Twitter HIN (TwHIN); we show that these pretrained representations yield significant offline and online improvement for a diverse range of downstream recommendation and classification tasks: personalized ads rankings, account follow-recommendation, offensive content detection, and search ranking. We discuss design choices and practical challenges of deploying industry-scale HIN embeddings, including compressing them to reduce end-to-end model latency and handling parameter drift across versions.|社交网络，如 Twitter，形成了一个异构的信息网络(HIN) ，其中节点代表领域实体(例如，用户，内容，广告商等) ，边缘代表许多实体交互之一(例如，用户重新分享内容或“关注”另一个)。来自多种关系类型的交互可以编码关于社交网络实体的有价值的信息，而这些信息并没有被单个关系完全捕获; 例如，用户对账户的偏好可能同时取决于用户内容参与交互和他们所关注的其他用户。在这项工作中，我们调查了知识图表嵌入实体在 Twitter HIN (TwHIN) ; 我们表明，这些预先训练的表示产生了显着的离线和在线改善的下游推荐和分类任务的范围: 个性化广告排名，帐户跟踪推荐，攻击性内容检测和搜索排名。我们讨论了部署行业规模的 HIN 嵌入的设计选择和实际挑战，包括压缩它们以减少端到端模型延迟和处理跨版本的参数漂移。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TwHIN:+Embedding+the+Twitter+Heterogeneous+Information+Network+for+Personalized+Recommendation)|4|
|[Multi-Task Fusion via Reinforcement Learning for Long-Term User Satisfaction in Recommender Systems](https://doi.org/10.1145/3534678.3539040)|Qihua Zhang, Junning Liu, Yuzhuo Dai, Yiyan Qi, Yifan Yuan, Kunlun Zheng, Fan Huang, Xianfeng Tan|Tencent, Shenzhen, China; Tencent, Beijing, China|Recommender System (RS) is an important online application that affects billions of users every day. The mainstream RS ranking framework is composed of two parts: a Multi-Task Learning model (MTL) that predicts various user feedback, i.e., clicks, likes, sharings, and a Multi-Task Fusion model (MTF) that combines the multi-task outputs into one final ranking score with respect to user satisfaction. There has not been much research on the fusion model while it has great impact on the final recommendation as the last crucial process of the ranking. To optimize long-term user satisfaction rather than obtain instant returns greedily, we formulate MTF task as Markov Decision Process (MDP) within a recommendation session and propose a Batch Reinforcement Learning (RL) based Multi-Task Fusion framework (BatchRL-MTF) that includes a Batch RL framework and an online exploration. The former exploits Batch RL to learn an optimal recommendation policy from the fixed batch data offline for long-term user satisfaction, while the latter explores potential high-value actions online to break through the local optimal dilemma. With a comprehensive investigation on user behaviors, we model the user satisfaction reward with subtle heuristics from two aspects of user stickiness and user activeness. Finally, we conduct extensive experiments on a billion-sample level real-world dataset to show the effectiveness of our model. We propose a conservative offline policy estimator (Conservative-OPEstimator) to test our model offline. Furthermore, we take online experiments in a real recommendation environment to compare performance of different models. As one of few Batch RL researches applied in MTF task successfully, our model has also been deployed on a large-scale industrial short video platform, serving hundreds of millions of users.|推荐系统(RS)是一个重要的在线应用程序，每天影响数十亿用户。RS 的主流排名框架由两部分组成: 一个是多任务学习模型(Multi-Task Learning model，MTL) ，它预测用户的各种反馈，即点击、喜欢、分享; 另一个是多任务融合模型(Multi-Task Fusion model，MTF) ，它将多任务输出结合成一个用户满意度的最终排名得分。融合模型作为排名的最后一个关键过程，对最终推荐有着重要的影响。为了优化长期用户满意度，而不是贪婪地获得即时回报，我们在一个推荐会话中将 MTF 任务制定为马可夫决策过程(mDP) ，并提出了一个基于批处理强化学习(RL)的多任务融合框架(BatchRL-MTF) ，其中包括一个批处理强化学习框架和一个在线探索。前者利用批量 RL 从离线的固定批量数据中学习最优推荐策略以获得长期用户满意度，后者利用在线的潜在高价值行为来突破局部最优困境。通过对用户行为的全面调查，从用户粘性和用户主动性两个方面采用微妙的启发式方法建立了用户满意奖励模型。最后，我们在十亿个样本级别的真实世界数据集上进行了广泛的实验，以显示我们的模型的有效性。我们提出了一个保守的离线策略估计(保守-最优估计)来测试我们的模型离线。此外，我们在一个真实的推荐环境中进行在线实验，比较不同模型的性能。作为少数几个成功应用于 MTF 任务的批量 RL 研究之一，我们的模型也已经部署在一个大型工业短视频平台上，为数亿用户服务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Task+Fusion+via+Reinforcement+Learning+for+Long-Term+User+Satisfaction+in+Recommender+Systems)|4|
|[Feature-aware Diversified Re-ranking with Disentangled Representations for Relevant Recommendation](https://doi.org/10.1145/3534678.3539130)|Zihan Lin, Hui Wang, Jingshu Mao, Wayne Xin Zhao, Cheng Wang, Peng Jiang, JiRong Wen|Renmin University of China, Beijing Key Laboratory of Big Data Management and Analysis Methods, & Beijing Academy of Artificial Intelligence, Beijing, China; Kuaishou Inc., Beijing, China; Renmin University of China, Beijing, China|Relevant recommendation is a special recommendation scenario which provides relevant items when users express interests on one target item (e.g., click, like and purchase). Besides considering the relevance between recommendations and trigger item, the recommendations should also be diversified to avoid information cocoons. However, existing diversified recommendation methods mainly focus on item-level diversity which is insufficient when the recommended items are all relevant to the target item. Moreover, redundant or noisy item features might affect the performance of simple feature-aware recommendation approaches. Faced with these issues, we propose a Feature Disentanglement Self-Balancing Re-ranking framework (FDSB) to capture feature- aware diversity. The framework consists of two major modules, namely disentangled attention encoder (DAE) and self-balanced multi-aspect ranker. In DAE, we use multi-head attention to learn disentangled aspects from rich item features. In the ranker, we develop an aspect-specific ranking mechanism that is able to adaptively balance the relevance and diversity for each aspect. In experiments, we conduct offline evaluation on the collected dataset and deploy FDSB on KuaiShou app for online ??/?? test on the function of relevant recommendation. The significant improvements on both recommendation quality and user experience verify the effectiveness of our approach.|相关推荐是一种特殊的推荐场景，当用户对一个目标项目表示兴趣时(例如，点击、喜欢和购买) ，它会提供相关的项目。除了考虑建议与触发项目之间的相关性之外，建议还应当多样化，以避免信息茧。然而，现有的多样化推荐方法主要侧重于项目层次的多样性，当推荐项目都与目标项目相关时，这种多样性是不够的。此外，冗余或嘈杂的项目特征可能会影响简单的特征感知推荐方法的性能。针对这些问题，我们提出了一种特征分离自平衡重排框架(FDSB)来捕获特征感知的多样性。该框架包括两个主要模块，即分离注意编码器(DAE)和自平衡多方面排序器。在 DAE 中，我们使用多头注意从丰富的项目特征中学习分离的方面。在排名中，我们开发了一个方面特定的排名机制，能够自适应地平衡每个方面的相关性和多样性。在实验中，我们对收集到的数据集进行离线评估，并在快手应用上部署 FDSB 以实现在线? ? ？/?？检验有关推荐的作用。在推荐质量和用户体验方面的重大改进验证了我们方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Feature-aware+Diversified+Re-ranking+with+Disentangled+Representations+for+Relevant+Recommendation)|4|
|[Counteracting User Attention Bias in Music Streaming Recommendation via Reward Modification](https://doi.org/10.1145/3534678.3539393)|Xiao Zhang, Sunhao Dai, Jun Xu, Zhenhua Dong, Quanyu Dai, JiRong Wen|Huawei Noah's Ark Lab, Shenzhen, China; Renmin University of China, Beijing, China|In streaming media applications, like music Apps, songs are recommended in a continuous way in users' daily life. The recommended songs are played automatically although users may not pay any attention to them, posing a challenge of user attention bias in training recommendation models, i.e., the training instances contain a large number of false-positive labels (users' feedback). Existing approaches either directly use the auto-feedbacks or heuristically delete the potential false-positive labels. Both of the approaches lead to biased results because the false-positive labels cause the shift of training data distribution, hurting the accuracy of the recommendation models. In this paper, we propose a learning-based counterfactual approach to adjusting the user auto-feedbacks and learning the recommendation models using Neural Dueling Bandit algorithm, called NDB. Specifically, NDB maintains two neural networks: a user attention network for computing the importance weights that are used for modifying the original rewards, and another random network trained with dueling bandit for conducting online recommendations based on the modified rewards. Theoretical analysis showed that the modified rewards are statistically unbiased, and the learned bandit policy enjoys a sub-linear regret bound. Experimental results demonstrated that NDB can significantly outperform the state-of-the-art baselines.|在流媒体应用程序中，比如音乐应用程序，歌曲被持续推荐到用户的日常生活中。虽然用户可能没有注意到这些歌曲，但推荐的歌曲会自动播放，这对训练推荐模型中的用户注意偏差提出了挑战，即训练实例中包含大量假阳性标签(用户反馈)。现有的方法要么直接使用自动反馈，要么启发性地删除潜在的假阳性标签。这两种方法都会导致结果偏差，因为假阳性标签会引起训练数据分布的变化，从而影响推荐模型的准确性。在本文中，我们提出了一种基于学习的反事实方法来调整用户自动反馈和学习推荐模型的神经决斗盗贼算法，称为 NDB。具体来说，新开发银行维护两个神经网络: 一个是用户注意力网络，用于计算用于修改原始奖励的重要性权重，另一个是与决斗强盗一起训练的随机网络，用于根据修改后的奖励进行在线推荐。理论分析表明，修正后的奖励具有统计上的无偏性，学会的土匪政策具有亚线性后悔界限。实验结果表明，新数据库的性能明显优于最先进的基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Counteracting+User+Attention+Bias+in+Music+Streaming+Recommendation+via+Reward+Modification)|4|
|[Knowledge-enhanced Black-box Attacks for Recommendations](https://doi.org/10.1145/3534678.3539359)|Jingfan Chen, Wenqi Fan, Guanghui Zhu, Xiangyu Zhao, Chunfeng Yuan, Qing Li, Yihua Huang|Hong Kong Polytech Univ, Hong Kong, Peoples R China; Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China; City Univ Hong Kong, Hong Kong, Peoples R China|Recent studies have shown that deep neural networks-based recommender systems are vulnerable to adversarial attacks, where attackers can inject carefully crafted fake user profiles (i.e., a set of items that fake users have interacted with) into a target recommender system to achieve malicious purposes, such as promote or demote a set of target items. Due to the security and privacy concerns, it is more practical to perform adversarial attacks under the black-box setting, where the architecture/parameters and training data of target systems cannot be easily accessed by attackers. However, generating high-quality fake user profiles under black-box setting is rather challenging with limited resources to target systems. To address this challenge, in this work, we introduce a novel strategy by leveraging items' attribute information (i.e., items' knowledge graph), which can be publicly accessible and provide rich auxiliary knowledge to enhance the generation of fake user profiles. More specifically, we propose a knowledge graph-enhanced black-box attacking framework (KGAttack) to effectively learn attacking policies through deep reinforcement learning techniques, in which knowledge graph is seamlessly integrated into hierarchical policy networks to generate fake user profiles for performing adversarial black-box attacks. Comprehensive experiments on various real-world datasets demonstrate the effectiveness of the proposed attacking framework under the black-box setting.|近期研究表明，基于深度神经网络的推荐系统易受对抗性攻击影响——攻击者可通过向目标系统注入精心伪造的用户画像（即伪造用户交互过的物品集合），实现提升或降低特定目标物品排名的恶意目的。鉴于安全与隐私限制，在黑盒设置下实施攻击更具现实意义，因此攻击者难以获取目标系统的架构/参数及训练数据。然而在有限资源条件下，生成高质量伪造用户画像面临巨大挑战。为解决该问题，本研究创新性地利用可公开获取的物品属性信息（即物品知识图谱），通过其丰富的辅助知识增强伪造用户画像的生成效果。具体而言，我们提出知识图谱增强型黑盒攻击框架（KGAttack），通过深度强化学习技术有效学习攻击策略：该框架将知识图谱无缝集成至分层策略网络，生成用于执行对抗性黑盒攻击的伪造用户画像。基于多个真实数据集的综合实验表明，所提攻击框架在黑盒设置下具有显著有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge-enhanced+Black-box+Attacks+for+Recommendations)|4|
|[Towards Universal Sequence Representation Learning for Recommender Systems](https://doi.org/10.1145/3534678.3539381)|Yupeng Hou, Shanlei Mu, Wayne Xin Zhao, Yaliang Li, Bolin Ding, JiRong Wen|Renmin Univ China, Sch Informat, Beijing, Peoples R China; Renmin University of China & Beijing Key Laboratory of Big Data Management and Analysis Methods, Beijing, China; Alibaba Grp, Hangzhou, Peoples R China; Renmin University of China & Beijing Academy of Artificial Intelligence, Beijing, China|In order to develop effective sequential recommenders, a series of sequence representation learning (SRL) methods are proposed to model historical user behaviors. Most existing SRL methods rely on explicit item IDs for developing the sequence models to better capture user preference. Though effective to some extent, these methods are difficult to be transferred to new recommendation scenarios, due to the limitation by explicitly modeling item IDs. To tackle this issue, we present a novel universal sequence representation learning approach, named UniSRec. The proposed approach utilizes the associated description text of items to learn transferable representations across different recommendation scenarios. For learning universal item representations, we design a lightweight item encoding architecture based on parametric whitening and mixture-of-experts enhanced adaptor. For learning universal sequence representations, we introduce two contrastive pre-training tasks by sampling multi-domain negatives. With the pre-trained universal sequence representation model, our approach can be effectively transferred to new recommendation domains or platforms in a parameter-efficient way, under either inductive or transductive settings. Extensive experiments conducted on real-world datasets demonstrate the effectiveness of the proposed approach. Especially, our approach also leads to a performance improvement in a cross-platform setting, showing the strong transferability of the proposed universal SRL method. The code and pre-trained model are available at: https://github.com/RUCAIBox/UniSRec.|为开发高效的序列推荐系统，一系列序列表示学习（SRL）方法被提出以建模用户历史行为。现有大多数SRL方法依赖显式商品ID构建序列模型，以更好地捕捉用户偏好。尽管这些方法具有一定效果，但由于显式商品ID建模的局限性，它们难以迁移到新的推荐场景。针对该问题，我们提出名为UniSRec的新型通用序列表示学习方法。该方法利用商品关联描述文本，学习跨推荐场景的可迁移表示。在学习通用商品表示时，我们基于参数白化与专家混合增强适配器设计了轻量级商品编码架构；在学习通用序列表示时，我们通过多域负采样引入两个对比预训练任务。通过预训练的通用序列表示模型，该方法可在归纳式或直推式设置下，以参数高效的方式有效迁移到新推荐域或平台。在真实数据集上的大量实验证明了该方法的有效性。特别值得注意的是，我们的方法在跨平台设置下实现了性能提升，展现出所提通用SRL方法的强大迁移能力。代码与预训练模型已开源：https://github.com/RUCAIBox/UniSRec。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Universal+Sequence+Representation+Learning+for+Recommender+Systems)|4|
|[On Structural Explanation of Bias in Graph Neural Networks](https://doi.org/10.1145/3534678.3539319)|Yushun Dong, Song Wang, Yu Wang, Tyler Derr, Jundong Li|Univ Virginia, Charlottesville, VA 22903 USA; Vanderbilt Univ, 221 Kirkland Hall, Nashville, TN 37235 USA|Graph Neural Networks (GNNs) have shown satisfying performance in various graph analytical problems. Hence, they have become the de facto solution in a variety of decision-making scenarios. However, GNNs could yield biased results against certain demographic subgroups. Some recent works have empirically shown that the biased structure of the input network is a significant source of bias for GNNs. Nevertheless, no studies have systematically scrutinized which part of the input network structure leads to biased predictions for any given node. The low transparency on how the structure of the input network influences the bias in GNN outcome largely limits the safe adoption of GNNs in various decision-critical scenarios. In this paper, we study a novel research problem of structural explanation of bias in GNNs. Specifically, we propose a novel post-hoc explanation framework to identify two edge sets that can maximally account for the exhibited bias and maximally contribute to the fairness level of the GNN prediction for any given node, respectively. Such explanations not only provide a comprehensive understanding of bias/fairness of GNN predictions but also have practical significance in building an effective yet fair GNN model. Extensive experiments on real-world datasets validate the effectiveness of the proposed framework towards delivering effective structural explanations for the bias of GNNs. Open-source code can be found at https://github.com/yushundong/REFEREE.|图神经网络（GNN）在各种图分析任务中展现出令人满意的性能，已成为多类决策场景中的事实解决方案。然而，GNN可能对某些人口统计子群体产生有偏差的结果。近期研究通过实证表明，输入网络的偏见结构是导致GNN产生偏差的重要根源。但迄今为止，尚未有研究系统性地揭示对于任意给定节点，输入网络结构的哪些具体部分会导致预测偏差。输入网络结构如何影响GNN结果偏差的低透明度问题，极大限制了GNN在各类决策关键场景中的安全应用。本文针对GNN偏差的结构性解释这一新颖研究问题展开探讨，提出了一种创新的事后解释框架，能够分别识别出对已显现偏差贡献最大、以及对任意给定节点GNN预测公平性提升最关键的两类边集。此类解释不仅能提供对GNN预测偏差/公平性的全面理解，更对构建有效且公平的GNN模型具有实际意义。在真实数据集上的大量实验验证了所提出框架在提供GNN偏差有效结构性解释方面的卓越性能。开源代码详见：https://github.com/yushundong/REFEREE。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Structural+Explanation+of+Bias+in+Graph+Neural+Networks)|4|
|[SMORE: Knowledge Graph Completion and Multi-hop Reasoning in Massive Knowledge Graphs](https://doi.org/10.1145/3534678.3539405)|Hongyu Ren, Hanjun Dai, Bo Dai, Xinyun Chen, Denny Zhou, Jure Leskovec, Dale Schuurmans||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SMORE:+Knowledge+Graph+Completion+and+Multi-hop+Reasoning+in+Massive+Knowledge+Graphs)|4|
|[Improving Fairness in Graph Neural Networks via Mitigating Sensitive Attribute Leakage](https://doi.org/10.1145/3534678.3539404)|Yu Wang, Yuying Zhao, Yushun Dong, Huiyuan Chen, Jundong Li, Tyler Derr||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Fairness+in+Graph+Neural+Networks+via+Mitigating+Sensitive+Attribute+Leakage)|4|
|[COSTA: Covariance-Preserving Feature Augmentation for Graph Contrastive Learning](https://doi.org/10.1145/3534678.3539425)|Yifei Zhang, Hao Zhu, Zixing Song, Piotr Koniusz, Irwin King||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=COSTA:+Covariance-Preserving+Feature+Augmentation+for+Graph+Contrastive+Learning)|4|
|[How does Heterophily Impact the Robustness of Graph Neural Networks?: Theoretical Connections and Practical Implications](https://doi.org/10.1145/3534678.3539418)|Jiong Zhu, Junchen Jin, Donald Loveland, Michael T. Schaub, Danai Koutra||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+does+Heterophily+Impact+the+Robustness+of+Graph+Neural+Networks?:+Theoretical+Connections+and+Practical+Implications)|4|
|[Company-as-Tribe: Company Financial Risk Assessment on Tribe-Style Graph with Hierarchical Graph Neural Networks](https://doi.org/10.1145/3534678.3539129)|Wendong Bi, Bingbing Xu, Xiaoqian Sun, Zidong Wang, Huawei Shen, Xueqi Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Company-as-Tribe:+Company+Financial+Risk+Assessment+on+Tribe-Style+Graph+with+Hierarchical+Graph+Neural+Networks)|4|
|[Distributed Hybrid CPU and GPU training for Graph Neural Networks on Billion-Scale Heterogeneous Graphs](https://doi.org/10.1145/3534678.3539177)|Da Zheng, Xiang Song, Chengru Yang, Dominique LaSalle, George Karypis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Distributed+Hybrid+CPU+and+GPU+training+for+Graph+Neural+Networks+on+Billion-Scale+Heterogeneous+Graphs)|4|
|[Graph Neural Networks: Foundation, Frontiers and Applications](https://doi.org/10.1145/3534678.3542609)|Lingfei Wu, Peng Cui, Jian Pei, Liang Zhao, Xiaojie Guo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Neural+Networks:+Foundation,+Frontiers+and+Applications)|4|
|[Deconfounding Duration Bias in Watch-time Prediction for Video Recommendation](https://doi.org/10.1145/3534678.3539092)|Ruohan Zhan, Changhua Pei, Qiang Su, Jianfeng Wen, Xueliang Wang, Guanyu Mu, Dong Zheng, Peng Jiang, Kun Gai|Unaffiliated, Beijing, China; Kuaishou Technol, Beijing, Peoples R China; Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China|Watch-time prediction remains to be a key factor in reinforcing user engagement via video recommendations. It has become increasingly important given the ever-growing popularity of online videos. However, prediction of watch time not only depends on the match between the user and the video but is often mislead by the duration of the video itself. With the goal of improving watch time, recommendation is always biased towards videos with long duration. Models trained on this imbalanced data face the risk of bias amplification, which misguides platforms to over-recommend videos with long duration but overlook the underlying user interests. This paper presents the first work to study duration bias in watch-time prediction for video recommendation. We employ a causal graph illuminating that duration is a confounding factor that concurrently affects video exposure and watch-time prediction---the first effect on video causes the bias issue and should be eliminated, while the second effect on watch time originates from video intrinsic characteristics and should be preserved. To remove the undesired bias but leverage the natural effect, we propose a Duration-Deconfounded Quantile-based (D2Q) watch-time prediction framework, which allows for scalability to perform on industry production systems. Through extensive offline evaluation and live experiments, we showcase the effectiveness of this duration-deconfounding framework by significantly outperforming the state-of-the-art baselines. We have fully launched our approach on Kuaishou App, which has substantially improved real-time video consumption due to more accurate watch-time predictions.|观看时长预测始终是通过视频推荐增强用户参与度的关键因素。随着在线视频的日益普及，其重要性愈发凸显。然而观看时长的预测不仅取决于用户与视频的匹配度，还经常受到视频时长这一误导性因素影响。为提升观看时长，推荐系统往往会偏向长视频，基于这种不平衡数据训练的模型面临偏差放大的风险——这会导致平台过度推荐长视频，却忽视了用户深层次兴趣。本文首次系统研究视频推荐中观看时长预测的时长偏差问题。我们通过因果图论证发现：时长是同时影响视频曝光和观看时长的混杂因素——前者会导致偏差问题需被消除，而后者源于视频固有特性应予以保留。为消除不良偏差同时保留自然效应，我们提出基于时长去混杂分位数（D2Q）的观看时长预测框架，该框架具备在工业级系统实现规模化部署的能力。通过大量离线评估和线上实验证明，本去混杂框架显著优于现有最优基线模型。该方案已在快手APP全面上线，凭借更精准的观看时长预测有效提升了实时视频消费体验。

（注：译文采用技术论文常见的学术表达方式，通过拆分长句、使用专业术语（如"混杂因素""分位数"）、保留英文缩写（D2Q）等策略，既确保学术严谨性又符合中文表达习惯。针对"confounding factor"等核心概念采用医学/统计学领域通用译法"混杂因素"，"state-of-the-art"译为"现有最优"体现技术先进性，末句"实时视频消费"的表述契合互联网行业特征。）|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deconfounding+Duration+Bias+in+Watch-time+Prediction+for+Video+Recommendation)|3|
|[Learning Binarized Graph Representations with Multi-faceted Quantization Reinforcement for Top-K Recommendation](https://doi.org/10.1145/3534678.3539452)|Yankai Chen, Huifeng Guo, Yingxue Zhang, Chen Ma, Ruiming Tang, Jingjie Li, Irwin King|City Univ Hong Kong, Hong Kong, Peoples R China; Huawei Noahs Ark Lab, Hong Kong, Peoples R China; Chinese Univ Hong Kong, Hong Kong, Peoples R China|Learning vectorized embeddings is at the core of various recommender systems for user-item matching. To perform efficient online inference, representation quantization, aiming to embed the latent features by a compact sequence of discrete numbers, recently shows the promising potentiality in optimizing both memory and computation overheads. However, existing work merely focuses on numerical quantization whilst ignoring the concomitant information loss issue, which, consequently, leads to conspicuous performance degradation. In this paper, we propose a novel quantization framework to learn Binarized Graph Representations for Top-K Recommendation (BiGeaR). We introduce multi-faceted quantization reinforcement at the pre-, mid-, and post-stage of binarized representation learning, which substantially retains the informativeness against embedding binarization. In addition to saving the memory footprint, it further develops solid online inference acceleration with bitwise operations, providing alternative flexibility for the realistic deployment. The empirical results over five large real-world benchmarks show that BiGeaR achieves about 22%~40% performance improvement over the state-of-the-art quantization-based recommender system, and recovers about 95%~102% of the performance capability of the best full-precision counterpart with over 8× time and space reduction.|学习向量化嵌入是各类用户-物品匹配推荐系统的核心。为实现高效在线推理，表征量化技术通过将隐特征嵌入为紧凑的离散数值序列，在优化内存和计算开销方面展现出巨大潜力。然而现有研究仅聚焦数值量化，却忽视了伴随的信息损失问题，导致系统性能显著下降。本文提出一种新型量化框架BiGeaR，通过二值化图表示实现Top-K推荐。我们在二值化表征学习的前、中、后三阶段引入多层面量化增强机制，显著保留了嵌入二值化过程中的信息完整性。该方案在节省内存占用的同时，进一步通过位运算实现实时的在线推理加速，为实际部署提供灵活选择。在五个大型真实场景基准测试中，BiGeaR相比最先进的量化推荐系统性能提升约22%~40%，并以超过8倍的时间空间压缩比，恢复最佳全精度对比模型约95%~102%的性能表现。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Binarized+Graph+Representations+with+Multi-faceted+Quantization+Reinforcement+for+Top-K+Recommendation)|3|
|[Addressing Unmeasured Confounder for Recommendation with Sensitivity Analysis](https://doi.org/10.1145/3534678.3539240)|Sihao Ding, Peng Wu, Fuli Feng, Yitong Wang, Xiangnan He, Yong Liao, Yongdong Zhang|Univ Sci & Technol China, Hefei, Peoples R China; Beijing Technol & Business Univ, Beijing, Peoples R China|Recommender systems should answer the intervention question "if recommending an item to a user, what would the feedback be", calling for estimating the causal effect of a recommendation on user feedback. Generally, this requires blocking the effect of confounders that simultaneously affect the recommendation and feedback. To mitigate the confounding bias, a strategy is incorporating propensity into model learning. However, existing methods forgo possible unmeasured confounders (e.g., user financial status), which can result in biased propensities and hurt recommendation performance. This work combats the risk of unmeasured confounders in recommender systems. Towards this end, we propose Robust Deconfounder (RD) that accounts for the effect of unmeasured confounders on propensities, under the mild assumption that the effect is bounded. It estimates the bound with sensitivity analysis, learning a recommender model robust to unmeasured confounders within the bound by adversarial learning. However, pursuing robustness within a bound may restrict model accuracy. To avoid the trade-off between robustness and accuracy, we further propose Benchmarked RD (BRD) that incorporates a pre-trained model into the learning as the benchmark. Theoretical analyses prove the stronger robustness of our methods compared to existing propensity-based deconfounders, and also prove the no-harm property of BRD. Our methods are applicable to any propensity-based estimators, where we select three representative ones: IPS, Doubly Robust, and AutoDebias. We conduct experiments on three real-world datasets to demonstrate the effectiveness of our methods.|推荐系统需回应干预性问题“若向用户推荐某项目，其反馈将如何”，这要求估算推荐行为对用户反馈的因果效应。通常需要阻断同时影响推荐结果和用户反馈的混杂因子干扰。为减轻混杂偏差，现有策略将倾向性评分纳入模型学习，但这类方法忽略了潜在未测混杂因子（如用户财务状况）的影响，可能导致倾向性估计偏差并损害推荐性能。本研究致力于应对推荐系统中未测混杂因子带来的风险。为此，我们提出鲁棒去混杂（RD）方法，在"未测混杂因子对倾向性的影响有界"这一温和假设下，量化未测混杂因子对倾向评分的影响。该方法通过敏感性分析估计影响边界，并采用对抗学习训练出在边界内对未测混杂因子具有鲁棒性的推荐模型。然而追求边界内的鲁棒性可能限制模型精度，为避免鲁棒性与精度的权衡，我们进一步提出基准化RD（BRD）方法，将预训练模型作为基准融入学习过程。理论分析证明：相比现有基于倾向性评分的去混杂方法，我们提出的方法具有更强鲁棒性，同时证明了BRD的"无损"特性。我们的方法适用于所有基于倾向性评分的估计器，本文选取三种代表性方法：逆概率加权、双稳健估计和AutoDebias。通过在三个真实数据集上的实验，验证了所提方法的有效性。

（注：根据学术论文摘要的翻译规范，对以下要点进行了专业化处理：
1. 专业术语统一："propensity"译为"倾向性评分"，"unmeasured confounders"译为"未测混杂因子"
2. 方法名称保留英文缩写RD/BRD并补充中文全称
3. 技术概念准确传达："adversarial learning"译为"对抗学习"，"sensitivity analysis"译为"敏感性分析"
4. 因果推断核心思想完整呈现：明确区分"因果效应"、"混杂偏差"等关键概念
5. 长难句拆分重组：将英语复合句转换为符合中文表达习惯的短句结构）|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Addressing+Unmeasured+Confounder+for+Recommendation+with+Sensitivity+Analysis)|3|
|[Disentangled Ontology Embedding for Zero-shot Learning](https://doi.org/10.1145/3534678.3539453)|Yuxia Geng, Jiaoyan Chen, Wen Zhang, Yajing Xu, Zhuo Chen, Jeff Z. Pan, Yufeng Huang, Feiyu Xiong, Huajun Chen|Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou, Peoples R China; Univ Oxford, Dept Comp Sci, Oxford, England; Alibaba Grp, Hangzhou, Peoples R China; Zhejiang Univ, Sch Software Technol, Ningbo, Peoples R China; Univ Edinburgh, Sch Informat, Edinburgh, Midlothian, Scotland|Knowledge Graph (KG) and its variant of ontology have been widely used for knowledge representation, and have shown to be quite effective in augmenting Zero-shot Learning (ZSL). However, existing ZSL methods that utilize KGs all neglect the intrinsic complexity of inter-class relationships represented in KGs. One typical feature is that a class is often related to other classes in different semantic aspects. In this paper, we focus on ontologies for augmenting ZSL, and propose to learn disentangled ontology embeddings guided by ontology properties to capture and utilize more fine-grained class relationships in different aspects. We also contribute a new ZSL framework named DOZSL, which contains two new ZSL solutions based on generative models and graph propagation models, respectively, for effectively utilizing the disentangled ontology embeddings. Extensive evaluations have been conducted on five benchmarks across zero-shot image classification (ZS-IMGC) and zero-shot KG completion (ZS-KGC). DOZSL often achieves better performance than the state-of-the-art, and its components have been verified by ablation studies and case studies. Our codes and datasets are available at https://github.com/zjukg/DOZSL.|知识图谱（KG）及其本体论变体已广泛应用于知识表示领域，并在增强零样本学习（ZSL）方面展现出显著效果。然而，现有基于知识图谱的零样本学习方法普遍忽略了图谱中类间关系的内在复杂性——其中一个典型特征是：一个类别往往通过不同语义层面与其他类别产生关联。本文聚焦于利用本体论增强零样本学习，提出通过本体属性引导解耦式本体嵌入学习，以捕捉并利用多维度下更细粒度的类别关系。我们进一步提出了名为DOZSL的新型零样本学习框架，该框架包含基于生成模型和图传播模型的两种全新解决方案，可有效利用解耦式本体嵌入。我们在零样本图像分类（ZS-IMGC）和零样本知识图谱补全（ZS-KGC）的五个基准数据集上进行了广泛评估。实验表明DOZSL在多数情况下优于现有最优方法，其各组件的有效性已通过消融研究和案例研究得到验证。相关代码和数据集已开源：https://github.com/zjukg/DOZSL。

（注：本翻译严格遵循学术论文摘要的规范表述，具有以下特点：
1. 专业术语准确对应："disentangled ontology embeddings"译为"解耦式本体嵌入"，"graph propagation models"译为"图传播模型"
2. 长句结构符合中文表达习惯：将英文复合句拆分为符合中文阅读节奏的短句
3. 逻辑连接词自然转换："however"转化为"然而"并调整句式结构
4. 技术概念系统保持："Zero-shot Learning"统一译为"零样本学习"并与括号内缩写(ZSL)同步呈现
5. 被动语态主动化："have been conducted"转化为"进行了"使表述更符合中文主动语态倾向）|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Disentangled+Ontology+Embedding+for+Zero-shot+Learning)|3|
|[Detecting Arbitrary Order Beneficial Feature Interactions for Recommender Systems](https://doi.org/10.1145/3534678.3539238)|Yixin Su, Yunxiang Zhao, Sarah M. Erfani, Junhao Gan, Rui Zhang|Tsinghua Univ, Beijing, Peoples R China; Univ Melbourne, Melbourne, Vic, Australia; Hebei Univ Technol, Tianjin, Peoples R China|Feature interactions are essential for achieving high accuracy in recommender systems. Many studies take into account the interaction between every pair of features. However, this is suboptimal because some feature interactions may not be that relevant to the recommendation result, and taking them into account may introduce noise and decrease recommendation accuracy. To make the best out of feature interactions, we propose a graph neural network approach to effectively model them, together with a novel technique to automatically detect those feature interactions that are beneficial in terms of recommendation accuracy. The automatic feature interaction detection is achieved via edge prediction with an L0 activation regularization. Our proposed model is proved to be effective through the information bottleneck principle and statistical interaction theory. Experimental results show that our model (i) outperforms existing baselines in terms of accuracy, and (ii) automatically identifies beneficial feature interactions.|特征交互对于提升推荐系统的准确性至关重要。现有研究大多考虑所有特征对之间的交互作用，但这种方式并非最优——部分特征交互可能与推荐结果关联性较弱，引入噪声反而会降低推荐精度。为优化特征交互的利用效率，我们提出一种图神经网络建模方法，并创新性地实现了可自动识别提升推荐精度的有效特征交互机制。该机制通过结合L0激活正则化的边预测来实现自动特征交互检测。基于信息瓶颈原理与统计交互理论，我们验证了所提出模型的有效性。实验结果表明：1）本模型在推荐精度上优于现有基线模型；2）能够自动识别具有增益效果的特征交互。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Detecting+Arbitrary+Order+Beneficial+Feature+Interactions+for+Recommender+Systems)|3|
|[AdaFS: Adaptive Feature Selection in Deep Recommender System](https://doi.org/10.1145/3534678.3539204)|Weilin Lin, Xiangyu Zhao, Yejing Wang, Tong Xu, Xian Wu|City Univ Hong Kong, Hong Kong, Peoples R China; Univ Sci & Technol China, Hefei, Peoples R China; Tencent Jarvis Lab, Shenzhen, Peoples R China|Feature selection plays an impactful role in deep recommender systems, which selects a subset of the most predictive features, so as to boost the recommendation performance and accelerate model optimization. The majority of existing feature selection methods, however, aim to select only a fixed subset of features. This setting cannot fit the dynamic and complex environments of practical recommender systems, where the contribution of a specific feature varies significantly across user-item interactions. In this paper, we propose an adaptive feature selection framework, AdaFS, for deep recommender systems. To be specific, we develop a novel controller network to automatically select the most relevant features from the whole feature space, which fits the dynamic recommendation environment better. Besides, different from classic feature selection approaches, the proposed controller can adaptively score each example of user-item interactions, and identify the most informative features correspondingly for subsequent recommendation tasks. We conduct extensive experiments based on two public benchmark datasets from a real-world recommender system. Experimental results demonstrate the effectiveness of AdaFS, and its excellent transferability to the most popular deep recommendation models.|特征选择在深度推荐系统中发挥着重要作用，它通过筛选最具预测性的特征子集来提升推荐性能并加速模型优化。然而现有大多数特征选择方法仅致力于选择固定特征子集，这种设定难以适应实际推荐系统中动态复杂的环境——在用户-项目交互过程中，特定特征的贡献度会呈现显著差异。本文提出一种面向深度推荐系统的自适应特征选择框架AdaFS。具体而言，我们开发了一种新型控制器网络，能够从完整特征空间中自动选择最相关的特征，从而更好地适应动态推荐环境。与传统特征选择方法不同，该控制器可自适应地为每个用户-项目交互实例进行评分，并据此识别最具信息量的特征以供后续推荐任务使用。基于两个真实推荐系统的公开基准数据集，我们开展了大量实验。结果表明AdaFS具有显著有效性，且对主流深度推荐模型展现出优异的可迁移性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AdaFS:+Adaptive+Feature+Selection+in+Deep+Recommender+System)|3|
|[ClusterEA: Scalable Entity Alignment with Stochastic Training and Normalized Mini-batch Similarities](https://doi.org/10.1145/3534678.3539331)|Yunjun Gao, Xiaoze Liu, Junyang Wu, Tianyi Li, Pengfei Wang, Lu Chen|Aalborg Univ, Aalborg, Denmark; Zhejiang Univ, Hangzhou, Peoples R China; Zhejiang Univ, Ningbo, Peoples R China|Entity alignment (EA) aims at finding equivalent entities in different knowledge graphs (KGs). Embedding-based approaches have dominated the EA task in recent years. Those methods face problems that come from the geometric properties of embedding vectors, including hubness and isolation. To solve these geometric problems, many normalization approaches have been adopted for EA. However, the increasing scale of KGs renders it hard for EA models to adopt the normalization processes, thus limiting their usage in real-world applications. To tackle this challenge, we present ClusterEA, a general framework that is capable of scaling up EA models and enhancing their results by leveraging normalization methods on mini-batches with a high entity equivalent rate. ClusterEA contains three components to align entities between large-scale KGs, including stochastic training, ClusterSampler, and SparseFusion. It first trains a large-scale Siamese GNN for EA in a stochastic fashion to produce entity embeddings. Based on the embeddings, a novel ClusterSampler strategy is proposed for sampling highly overlapped mini-batches. Finally, ClusterEA incorporates SparseFusion, which normalizes local and global similarity and then fuses all similarity matrices to obtain the final similarity matrix. Extensive experiments with real-life datasets on EA benchmarks offer insight into the proposed framework, and suggest that it is capable of outperforming the state-of-the-art scalable EA framework by up to 8 times in terms of Hits@1.|实体对齐（EA）旨在发现不同知识图谱（KG）中的等价实体。近年来，基于嵌入的方法在该任务中占据主导地位，但这些方法面临嵌入向量几何特性带来的问题，包括枢纽性和孤立性。为解决这些几何问题，多种归一化方法被应用于实体对齐。然而，知识图谱规模的持续增长使对齐模型难以实施归一化处理，限制了其在实际应用中的效果。为应对这一挑战，我们提出ClusterEA通用框架，该框架通过在具有高实体等价率的微型批处理中应用归一化方法，既能扩展对齐模型规模又能提升其结果质量。ClusterEA包含三个核心组件：随机训练、聚类采样器（ClusterSampler）和稀疏融合（SparseFusion）。该框架首先通过随机方式训练大规模孪生图神经网络生成实体嵌入表示，基于这些嵌入向量提出创新的ClusterSampler策略来采样高重叠度的微型批处理数据，最后通过SparseFusion组件对局部与全局相似度进行归一化处理，并融合所有相似度矩阵得到最终对齐结果。在实体对齐基准上的真实数据集实验表明，该框架在Hits@1指标上最高可超越现有可扩展对齐框架达8倍性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ClusterEA:+Scalable+Entity+Alignment+with+Stochastic+Training+and+Normalized+Mini-batch+Similarities)|3|
|[Source Localization of Graph Diffusion via Variational Autoencoders for Graph Inverse Problems](https://doi.org/10.1145/3534678.3539288)|Chen Ling, Junji Jiang, Junxiang Wang, Liang Zhao|Emory Univ, Atlanta, GA 30322 USA; Tianjin Univ, Tianjin, Peoples R China|Graph diffusion problems such as the propagation of rumors, computer viruses, or smart grid failures are ubiquitous and societal. Hence it is usually crucial to identify diffusion sources according to the current graph diffusion observations. Despite its tremendous necessity and significance in practice, source localization, as the inverse problem of graph diffusion, is extremely challenging as it is ill-posed: different sources may lead to the same graph diffusion patterns. Different from most traditional source localization methods, this paper focuses on a probabilistic manner to account for the uncertainty of different candidate sources. Such endeavors require to overcome significant challenges along the way including: 1) the uncertainty in graph diffusion source localization is hard to be quantified; 2) the complex patterns of the graph diffusion sources are difficult to be probabilistically characterized; 3) the generalization under any underlying diffusion patterns is hard to be imposed. To solve the above challenges, this paper presents a generic framework: Source Localization Variational AutoEncoder (SL-VAE) for locating the diffusion sources under arbitrary diffusion patterns. Particularly, we propose a probabilistic model that leverages the forward diffusion estimation model along with deep generative models to approximate the diffusion source distribution for quantifying the uncertainty. SL-VAE further utilizes prior knowledge of the source-observation pairs to characterize the complex patterns of diffusion sources by a learned generative prior. Lastly, a unified objective that integrates the forward diffusion estimation model is derived to enforce the model to generalize under arbitrary diffusion patterns. Extensive experiments are conducted on $7$ real-world datasets to demonstrate the superiority of SL-VAE in reconstructing the diffusion sources by excelling the state-of-the-arts on average 20% in AUC score. The code and data are available at: https://github.com/triplej0079/SLVAE.|图扩散问题（如谣言传播、计算机病毒蔓延或智能电网故障）普遍存在且具有广泛社会影响。因此，根据当前图扩散观测结果定位扩散源通常至关重要。尽管源定位作为图扩散逆问题在实践中具有巨大需求和重要性，但由于其不适定性——不同源可能产生相同的扩散模式——这一问题极具挑战性。与大多数传统源定位方法不同，本文采用概率化方法来解决不同候选源的不确定性。这一研究需要克服三大核心挑战：1）图扩散源定位中的不确定性难以量化；2）图扩散源的复杂模式难以进行概率化表征；3）任意潜在扩散模式下的泛化能力难以实现。

为解决上述挑战，本文提出通用框架SL-VAE（源定位变分自编码器），用于在任意扩散模式下定位扩散源。具体而言，我们构建了一个概率模型，通过结合前向扩散估计模型与深度生成模型，近似扩散源分布以量化不确定性。SL-VAE进一步利用源-观测对的先验知识，通过学习的生成先验来表征扩散源的复杂模式。最后，本文推导出整合前向扩散估计模型的统一目标函数，强制模型在任意扩散模式下实现泛化。

通过在7个真实世界数据集上的大量实验证明，SL-VAE在重构扩散源方面显著优于现有最优方法，平均AUC分数提升20%。代码与数据已开源：https://github.com/triplej0079/SLVAE。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Source+Localization+of+Graph+Diffusion+via+Variational+Autoencoders+for+Graph+Inverse+Problems)|3|
|[Variational Flow Graphical Model](https://doi.org/10.1145/3534678.3539450)|Shaogang Ren, Belhal Karimi, Dingcheng Li, Ping Li|Baidu Res, Cognit Comp Lab, 10900 NE 8th St, Bellevue, WA 98004 USA|This paper introduces a novel approach embedding flow-based models in hierarchical structures. The proposed model learns the representation of high-dimensional data via a message-passing scheme by integrating flow-based functions through variational inference. Meanwhile, our model produces a representation of the data using a lower dimension, thus overcoming the drawbacks of many flow-based models, usually requiring a high dimensional latent space involving many trivial variables. With the proposed aggregation nodes, our model provides a new approach for distribution modeling and numerical inference on datasets. Multiple experiments on synthetic and real-world datasets show the benefits of our~proposed~method and potentially broad applications.|本文提出了一种将基于流的模型嵌入层次化结构的新方法。该模型通过变分推理整合基于流的函数，采用消息传递机制学习高维数据的表示。与此同时，我们的模型能够生成低维数据表示，从而克服了许多基于流的模型需要高维潜在空间且包含大量冗余变量的缺陷。通过引入聚合节点，本模型为数据集的分布建模和数值推理提供了新思路。在合成数据集和真实数据集上的多项实验表明，我们所提出的方法具有显著优势及广阔的应用前景。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Variational+Flow+Graphical+Model)|3|
|[Interpretability, Then What? Editing Machine Learning Models to Reflect Human Knowledge and Values](https://doi.org/10.1145/3534678.3539074)|Zijie J. Wang, Alex Kale, Harsha Nori, Peter Stella, Mark E. Nunnally, Duen Horng Chau, Mihaela Vorvoreanu, Jennifer Wortman Vaughan, Rich Caruana||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interpretability,+Then+What?+Editing+Machine+Learning+Models+to+Reflect+Human+Knowledge+and+Values)|3|
|[GBPNet: Universal Geometric Representation Learning on Protein Structures](https://doi.org/10.1145/3534678.3539441)|Sarp Aykent, Tian Xia|Auburn University, Auburn, AL, USA|Representation learning of protein 3D structures is challenging and essential for applications, e.g., computational protein design or protein engineering. Recently, geometric deep learning has achieved great success in non-Euclidean domains. Although protein can be represented as a graph naturally, it remains under-explored mainly due to the significant challenges in modeling the complex representations and capturing the inherent correlation in the 3D structure modeling. Several challenges include: 1) It is challenging to extract and preserve multi-level rotation and translation equivariant information during learning. 2) Difficulty in developing appropriate tools to effectively leverage the input spatial representations to capture complex geometries across the spatial dimension. 3) Difficulty in incorporating various geometric features and preserving the inherent structural relations. In this work, we introduce geometric bottleneck perceptron, and a general SO(3)-equivariant message passing neural network built on top of it for protein structure representation learning. The proposed geometric bottleneck perceptron can be incorporated into diverse network architecture backbones to process geometric data in different domains. This research shed new light on geometric deep learning in 3D structure studies. Empirically, we demonstrate the strength of our proposed approach on three core downstream tasks, where our model achieves significant improvements and outperforms existing benchmarks. The implementation is available at https://github.com/sarpaykent/GBPNet.|蛋白质三维结构的表示学习是具有挑战性和必要的应用，例如，计算蛋白质设计或蛋白质工程。近年来，几何深度学习在非欧几里德领域取得了巨大的成功。虽然蛋白质可以自然地表示为一个图形，但是它仍然没有得到充分的开发，主要是由于在建模复杂的表示和捕获三维结构建模中的内在关联方面的重大挑战。这些挑战包括: 1)在学习过程中提取和保存多层次旋转和翻译等变信息是一个挑战。2)难以开发合适的工具来有效地利用输入空间表示来捕获跨空间维度的复杂几何图形。3)难以结合各种几何特征和保持固有的结构关系。本文介绍了几何瓶颈感知器，并在此基础上构建了一个通用的 SO (3)等变信息传递神经网络，用于蛋白质结构表示学习。提出的几何瓶颈感知器可以整合到不同的网络结构骨架中，用于处理不同领域的几何数据。本研究为三维结构研究中的几何深度学习提供了新的思路。实际上，我们在三个核心的下游任务中展示了我们提议的方法的优势，在这些任务中，我们的模型实现了显著的改进，并优于现有的基准测试。有关实施方案可于 https://github.com/sarpaykent/gbpnet 索取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GBPNet:+Universal+Geometric+Representation+Learning+on+Protein+Structures)|3|
|[Motif Prediction with Graph Neural Networks](https://doi.org/10.1145/3534678.3539343)|Maciej Besta, Raphael Grob, Cesare Miglioli, Nicola Bernold, Grzegorz Kwasniewski, Gabriel Gjini, Raghavendra Kanakagiri, Saleh Ashkboos, Lukas Gianinazzi, Nikoli Dryden, Torsten Hoefler|ETH Zürich, Zurich, Switzerland; ETH Zurich, Zurich, Switzerland; University of Illinois at Urbana-Champaign, Urbana-Champaign, IL, USA; University of Geneva, Geneva, Switzerland|Link prediction is one of the central problems in graph mining. However, recent studies highlight the importance of higher-order network analysis, where complex structures called motifs are the first-class citizens. We first show that existing link prediction schemes fail to effectively predict motifs. To alleviate this, we establish a general motif prediction problem and we propose several heuristics that assess the chances for a specified motif to appear. To make the scores realistic, our heuristics consider - among others - correlations between links, i.e., the potential impact of some arriving links on the appearance of other links in a given motif. Finally, for highest accuracy, we develop a graph neural network (GNN) architecture for motif prediction. Our architecture offers vertex features and sampling schemes that capture the rich structural properties of motifs. While our heuristics are fast and do not need any training, GNNs ensure highest accuracy of predicting motifs, both for dense (e.g., k-cliques) and for sparse ones (e.g., k-stars). We consistently outperform the best available competitor by more than 10% on average and up to 32% in area under the curve. Importantly, the advantages of our approach over schemes based on uncorrelated link prediction increase with the increasing motif size and complexity. We also successfully apply our architecture for predicting more arbitrary clusters and communities, illustrating its potential for graph mining beyond motif analysis.|链接预测是图挖掘的核心问题之一。然而，最近的研究强调了高阶网络分析的重要性，在这种网络分析中，被称为图案的复杂结构是一等公民。我们首先证明了现有的链路预测方案不能有效地预测图案。为了解决这个问题，我们建立了一个通用的主题预测问题，并提出了几种启发式算法来评估特定主题出现的可能性。为了使得分数更加真实，我们的启发式方法考虑了链接之间的相关性，也就是说，一些到达的链接对给定主题中其他链接的外观的潜在影响。最后，为了获得最高的精度，我们开发了一个图形神经网络(GNN)结构用于模体预测。我们的体系结构提供了顶点特征和抽样方案，这些特征和抽样方案捕获了图案丰富的结构属性。虽然我们的启发式算法是快速的，不需要任何训练，GNN 确保预测图案的最高准确性，无论是对于密集的(例如，k- 团)和稀疏的(例如，k- 星)。我们始终超越最好的竞争对手超过10% 的平均水平和高达32% 的面积下的曲线。重要的是，与基于不相关链路预测的方案相比，我们的方法的优势随着基序大小和复杂度的增加而增加。我们还成功地应用了我们的体系结构来预测更多的任意集群和社区，说明了它在图形挖掘方面的潜力超越了主题分析。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Motif+Prediction+with+Graph+Neural+Networks)|3|
|[Efficient Orthogonal Multi-view Subspace Clustering](https://doi.org/10.1145/3534678.3539282)|Mansheng Chen, ChangDong Wang, Dong Huang, JianHuang Lai, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Orthogonal+Multi-view+Subspace+Clustering)|3|
|[Local Evaluation of Time Series Anomaly Detection Algorithms](https://doi.org/10.1145/3534678.3539339)|Alexis Huet, José Manuel Navarro, Dario Rossi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Local+Evaluation+of+Time+Series+Anomaly+Detection+Algorithms)|3|
|[Feature Overcorrelation in Deep Graph Neural Networks: A New Perspective](https://doi.org/10.1145/3534678.3539445)|Wei Jin, Xiaorui Liu, Yao Ma, Charu C. Aggarwal, Jiliang Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Feature+Overcorrelation+in+Deep+Graph+Neural+Networks:+A+New+Perspective)|3|
|[Learned Token Pruning for Transformers](https://doi.org/10.1145/3534678.3539260)|Sehoon Kim, Sheng Shen, David Thorsley, Amir Gholami, Woosuk Kwon, Joseph Hassoun, Kurt Keutzer||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learned+Token+Pruning+for+Transformers)|3|
|[KPGT: Knowledge-Guided Pre-training of Graph Transformer for Molecular Property Prediction](https://doi.org/10.1145/3534678.3539426)|Han Li, Dan Zhao, Jianyang Zeng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KPGT:+Knowledge-Guided+Pre-training+of+Graph+Transformer+for+Molecular+Property+Prediction)|3|
|[Learning Causal Effects on Hypergraphs](https://doi.org/10.1145/3534678.3539299)|Jing Ma, Mengting Wan, Longqi Yang, Jundong Li, Brent J. Hecht, Jaime Teevan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Causal+Effects+on+Hypergraphs)|3|
|[Pre-training Enhanced Spatial-temporal Graph Neural Network for Multivariate Time Series Forecasting](https://doi.org/10.1145/3534678.3539396)|Zezhi Shao, Zhao Zhang, Fei Wang, Yongjun Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pre-training+Enhanced+Spatial-temporal+Graph+Neural+Network+for+Multivariate+Time+Series+Forecasting)|3|
|[GPPT: Graph Pre-training and Prompt Tuning to Generalize Graph Neural Networks](https://doi.org/10.1145/3534678.3539249)|Mingchen Sun, Kaixiong Zhou, Xin He, Ying Wang, Xin Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GPPT:+Graph+Pre-training+and+Prompt+Tuning+to+Generalize+Graph+Neural+Networks)|3|
|[Reinforcement Subgraph Reasoning for Fake News Detection](https://doi.org/10.1145/3534678.3539277)|Ruichao Yang, Xiting Wang, Yiqiao Jin, Chaozhuo Li, Jianxun Lian, Xing Xie||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reinforcement+Subgraph+Reasoning+for+Fake+News+Detection)|3|
|[Unsupervised Key Event Detection from Massive Text Corpora](https://doi.org/10.1145/3534678.3539395)|Yunyi Zhang, Fang Guo, Jiaming Shen, Jiawei Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unsupervised+Key+Event+Detection+from+Massive+Text+Corpora)|3|
|[Learning Sparse Latent Graph Representations for Anomaly Detection in Multivariate Time Series](https://doi.org/10.1145/3534678.3539117)|Siho Han, Simon S. Woo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Sparse+Latent+Graph+Representations+for+Anomaly+Detection+in+Multivariate+Time+Series)|3|
|[DuIVA: An Intelligent Voice Assistant for Hands-free and Eyes-free Voice Interaction with the Baidu Maps App](https://doi.org/10.1145/3534678.3539030)|Jizhou Huang, Haifeng Wang, Shiqiang Ding, Shaolei Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DuIVA:+An+Intelligent+Voice+Assistant+for+Hands-free+and+Eyes-free+Voice+Interaction+with+the+Baidu+Maps+App)|3|
|[A New Generation of Perspective API: Efficient Multilingual Character-level Transformers](https://doi.org/10.1145/3534678.3539147)|Alyssa Lees, Vinh Q. Tran, Yi Tay, Jeffrey Sorensen, Jai Prakash Gupta, Donald Metzler, Lucy Vasserman||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+New+Generation+of+Perspective+API:+Efficient+Multilingual+Character-level+Transformers)|3|
|[OAG-BERT: Towards a Unified Backbone Language Model for Academic Knowledge Services](https://doi.org/10.1145/3534678.3539210)|Xiao Liu, Da Yin, Jingnan Zheng, Xingjian Zhang, Peng Zhang, Hongxia Yang, Yuxiao Dong, Jie Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=OAG-BERT:+Towards+a+Unified+Backbone+Language+Model+for+Academic+Knowledge+Services)|3|
|[Fed-LTD: Towards Cross-Platform Ride Hailing via Federated Learning to Dispatch](https://doi.org/10.1145/3534678.3539047)|Yansheng Wang, Yongxin Tong, Zimu Zhou, Ziyao Ren, Yi Xu, Guobin Wu, Weifeng Lv||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fed-LTD:+Towards+Cross-Platform+Ride+Hailing+via+Federated+Learning+to+Dispatch)|3|
|[Graph Attention Multi-Layer Perceptron](https://doi.org/10.1145/3534678.3539121)|Wentao Zhang, Ziqi Yin, Zeang Sheng, Yang Li, Wen Ouyang, Xiaosen Li, Yangyu Tao, Zhi Yang, Bin Cui||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Attention+Multi-Layer+Perceptron)|3|
|[ItemSage: Learning Product Embeddings for Shopping Recommendations at Pinterest](https://doi.org/10.1145/3534678.3539170)|Paul Baltescu, Haoyu Chen, Nikil Pancha, Andrew Zhai, Jure Leskovec, Charles Rosenberg|Pinterest, San Francisco, CA, USA|Learned embeddings for products are an important building block for web-scale e-commerce recommendation systems. At Pinterest, we build a single set of product embeddings called ItemSage to provide relevant recommendations in all shopping use cases including user, image and search based recommendations. This approach has led to significant improvements in engagement and conversion metrics, while reducing both infrastructure and maintenance cost. While most prior work focuses on building product embeddings from features coming from a single modality, we introduce a transformer-based architecture capable of aggregating information from both text and image modalities and show that it significantly outperforms single modality baselines. We also utilize multi-task learning to make ItemSage optimized for several engagement types, leading to a candidate generation system that is efficient for all of the engagement objectives of the end-to-end recommendation system. Extensive offline experiments are conducted to illustrate the effectiveness of our approach and results from online A/B experiments show substantial gains in key business metrics (up to +7% gross merchandise value/user and +11% click volume).|产品学习嵌入是网络电子商务推荐系统的重要组成部分。在 Pinterest，我们构建了一套名为 ItemSage 的产品嵌入，在所有购物用例中提供相关推荐，包括用户、图片和基于搜索的推荐。这种方法显著改善了参与度和转换度量，同时降低了基础设施和维护成本。虽然大多数先前的工作集中于构建来自单一模式的特征的产品嵌入，但是我们引入了一个基于转换器的体系结构，该体系结构能够聚合来自文本和图像模式的信息，并表明它明显优于单一模式基线。我们还利用多任务学习来使 ItemSage 针对几种参与类型进行优化，从而产生一个对端到端推荐系统的所有参与目标都有效的候选人生成系统。为了说明我们的方法的有效性，我们进行了大量的离线实验，在线 A/B 实验的结果显示，在关键的商业指标方面取得了实质性的进展(高达7% 的商品总价值/用户和 + 11% 的点击量)。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ItemSage:+Learning+Product+Embeddings+for+Shopping+Recommendations+at+Pinterest)|2|
|[Towards Unified Conversational Recommender Systems via Knowledge-Enhanced Prompt Learning](https://doi.org/10.1145/3534678.3539382)|Xiaolei Wang, Kun Zhou, JiRong Wen, Wayne Xin Zhao|Renmin University of China, Beijing, China|Conversational recommender systems (CRS) aim to proactively elicit user preference and recommend high-quality items through natural language conversations. Typically, a CRS consists of a recommendation module to predict preferred items for users and a conversation module to generate appropriate responses. To develop an effective CRS, it is essential to seamlessly integrate the two modules. Existing works either design semantic alignment strategies, or share knowledge resources and representations between the two modules. However, these approaches still rely on different architectures or techniques to develop the two modules, making it difficult for effective module integration. To address this problem, we propose a unified CRS model named UniCRS based on knowledge-enhanced prompt learning. Our approach unifies the recommendation and conversation subtasks into the prompt learning paradigm, and utilizes knowledge-enhanced prompts based on a fixed pre-trained language model (PLM) to fulfill both subtasks in a unified approach. In the prompt design, we include fused knowledge representations, task-specific soft tokens, and the dialogue context, which can provide sufficient contextual information to adapt the PLM for the CRS task. Besides, for the recommendation subtask, we also incorporate the generated response template as an important part of the prompt, to enhance the information interaction between the two subtasks. Extensive experiments on two public CRS datasets have demonstrated the effectiveness of our approach. Our code is publicly available at the link: https://github.com/RUCAIBox/UniCRS.|会话推荐系统(CRS)的目标是通过自然语言的对话主动地引导用户偏好，并推荐高质量的项目。通常，CRS 由一个推荐模块和一个会话模块组成，前者用于预测用户的首选项，后者用于生成适当的响应。为了开发一个有效的 CRS 系统，必须将这两个模块无缝地结合起来。现有的工作或者设计语义对齐策略，或者在两个模块之间共享知识资源和表示。然而，这些方法仍然依赖于不同的体系结构或技术来开发这两个模块，这使得有效的模块集成变得困难。针对这一问题，提出了一种基于知识增强的快速学习的统一 CRS 模型 UniCRS。该方法将推荐子任务和会话子任务统一到快速学习范式中，并利用基于固定预训练语言模型(PLM)的知识增强提示来统一实现推荐子任务和会话子任务。在快速设计中，我们包括融合知识表示、任务特定的软标记和对话上下文，它们可以提供足够的上下文信息来使 PLM 适应 CRS 任务。此外，对于推荐子任务，我们还将生成的响应模板作为提示的重要组成部分，以增强两个子任务之间的信息交互。在两个公共 CRS 数据集上的大量实验已经证明了我们方法的有效性。我们的代码可在以下 https://github.com/rucaibox/unicrs 公开获得:。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Unified+Conversational+Recommender+Systems+via+Knowledge-Enhanced+Prompt+Learning)|2|
|[Device-cloud Collaborative Recommendation via Meta Controller](https://doi.org/10.1145/3534678.3539181)|Jiangchao Yao, Feng Wang, Xichen Ding, Shaohu Chen, Bo Han, Jingren Zhou, Hongxia Yang|Ant Group, Beijing, China; CMIC, Shanghai Jiao Tong University, Shanghai, China; Hong Kong Baptist University, Hong Kong, China; DAMO Academy, Alibaba Group, Hangzhou, China|On-device machine learning enables the lightweight deployment of recommendation models in local clients, which reduces the burden of the cloud-based recommenders and simultaneously incorporates more real-time user features. Nevertheless, the cloud-based recommendation in the industry is still very important considering its powerful model capacity and the efficient candidate generation from the billion-scale item pool. Previous attempts to integrate the merits of both paradigms mainly resort to a sequential mechanism, which builds the on-device recommender on top of the cloud-based recommendation. However, such a design is inflexible when user interests dramatically change: the on-device model is stuck by the limited item cache while the cloud-based recommendation based on the large item pool do not respond without the new re-fresh feedback. To overcome this issue, we propose a meta controller to dynamically manage the collaboration between the on-device recommender and the cloud-based recommender, and introduce a novel efficient sample construction from the causal perspective to solve the dataset absence issue of meta controller. On the basis of the counterfactual samples and the extended training, extensive experiments in the industrial recommendation scenarios show the promise of meta controller in the device-cloud collaboration.|设备上的机器学习支持在本地客户机中轻量级部署推荐模型，这减轻了基于云的推荐模型的负担，同时包含了更多的实时用户特性。尽管如此，考虑到其强大的模型容量和从数十亿规模的项目库中有效地生成候选项，基于云的推荐在业界仍然非常重要。以前整合这两种模式优点的尝试主要依赖于一种顺序机制，这种机制在基于云的推荐之上构建设备上的推荐。然而，当用户的兴趣发生巨大变化时，这样的设计是不灵活的: 设备上的模型被有限的项目缓存卡住了，而基于大型项目池的基于云的推荐在没有新的更新反馈的情况下不会响应。针对这一问题，本文提出了一种元控制器来动态管理设备上的推荐器和基于云的推荐器之间的协作，并从因果关系的角度提出了一种新的有效的样本结构来解决元控制器数据集缺失的问题。在反事实样本和扩展训练的基础上，在工业推荐场景中的大量实验显示了元控制器在设备-云协作中的应用前景。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Device-cloud+Collaborative+Recommendation+via+Meta+Controller)|2|
|[MolSearch: Search-based Multi-objective Molecular Generation and Property Optimization](https://doi.org/10.1145/3534678.3542676)|Mengying Sun, Jing Xing, Han Meng, Huijun Wang, Bin Chen, Jiayu Zhou|Michigan State University, Grand Rapids, MI, USA; Agios Pharmaceuticals, Cambridge, MA, USA; Michigan State University, East Lansing, MI, USA|Leveraging computational methods to generate small molecules with desired properties has been an active research area in the drug discovery field. Towards real-world applications, however, efficient generation of molecules that satisfy multiple property requirements simultaneously remains a key challenge. In this paper, we tackle this challenge using a search-based approach and propose a simple yet effective framework called MolSearch for multi-objective molecular generation (optimization).We show that given proper design and sufficient domain information, search-based methods can achieve performance comparable or even better than deep learning methods while being computationally efficient. Such efficiency enables massive exploration of chemical space given constrained computational resources. In particular, MolSearch starts with existing molecules and uses a two-stage search strategy to gradually modify them into new ones, based on transformation rules derived systematically and exhaustively from large compound libraries. We evaluate MolSearch in multiple benchmark generation settings and demonstrate its effectiveness and efficiency.|利用计算方法生成具有期望特性的小分子已经成为药物发现领域的一个活跃的研究领域。然而，对于实际应用来说，同时满足多种性能要求的高效生产分子仍然是一个关键的挑战。在本文中，我们使用基于搜索的方法来解决这一挑战，并提出了一个简单而有效的框架，称为 MolSearch 的多目标分子生成(优化)。我们表明，给定适当的设计和充分的领域信息，基于搜索的方法可以实现性能可比，甚至比深度学习方法更好，同时计算效率。这样的效率使得在计算资源有限的情况下对化学空间进行大规模探索成为可能。特别是，MolSearch 从现有的分子开始，使用一个两阶段的搜索策略，逐渐修改成新的，基于转换规则，系统地和详尽地从大型化合物库。我们评估了 MolSearch 在多个基准测试生成环境中的性能，并证明了它的有效性和效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MolSearch:+Search-based+Multi-objective+Molecular+Generation+and+Property+Optimization)|2|
|[Invariant Preference Learning for General Debiasing in Recommendation](https://doi.org/10.1145/3534678.3539439)|Zimu Wang, Yue He, Jiashuo Liu, Wenchao Zou, Philip S. Yu, Peng Cui|University of Illinois at Chicago, Chicago, IL, USA; Tsinghua University, Beijing, China; Siemens China, Shanghai, China|Current recommender systems have achieved great successes in online services, such as E-commerce and social media. However, they still suffer from the performance degradation in real scenarios, because various biases always occur in the generation process of user behaviors. Despite the recent development of addressing some specific type of bias, a variety of data bias, some of which are even unknown, are often mixed up in real applications. Although the uniform (or unbiased) data may help for the purpose of general debiasing, such data can either be hardly available or induce high experimental cost. In this paper, we consider a more practical setting where we aim to conduct general debiasing with the biased observational data alone. We assume that the observational user behaviors are determined by invariant preference (i.e. a user's true preference) and the variant preference (affected by some unobserved confounders). We propose a novel recommendation framework called InvPref which iteratively decomposes the invariant preference and variant preference from biased observational user behaviors by estimating heterogeneous environments corresponding to different types of latent bias. Extensive experiments, including the settings of general debiasing and specific debiasing, verify the advantages of our method.|现有的推荐系统在电子商务和社交媒体等在线服务领域取得了巨大的成功。然而，在实际场景中，它们仍然会受到性能下降的影响，因为在用户行为的生成过程中总是会出现各种偏差。尽管最近的发展解决一些特定类型的偏差，各种各样的数据偏差，其中一些甚至是未知的，往往是混合在实际应用。虽然统一(或无偏)的数据可能有助于一般的去偏目的，这样的数据可能难以获得或诱导高实验成本。在本文中，我们考虑一个更实际的设置，其中我们的目的是进行一般的去偏与有偏的观测数据单独。我们假设观察用户行为是由不变偏好(即用户的真实偏好)和变异偏好(受一些未观察到的混杂因素的影响)决定的。提出了一种新的推荐框架 InvPref，该框架通过估计不同类型潜在偏差对应的异质环境，迭代分解有偏差的观察用户行为的不变偏好和变异偏好。广泛的实验，包括一般消偏和具体消偏的设置，验证了我们的方法的优点。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Invariant+Preference+Learning+for+General+Debiasing+in+Recommendation)|2|
|[Automatic Controllable Product Copywriting for E-Commerce](https://doi.org/10.1145/3534678.3539171)|Xiaojie Guo, Qingkai Zeng, Meng Jiang, Yun Xiao, Bo Long, Lingfei Wu|JD.COM, Beijing, China; JD.COM Silicon Valley Research Center, Mountain View, CA, USA; University of Notre Dame, Notre Dame, IN, USA|Automatic product description generation for e-commerce has witnessed significant advancement in the past decade. Product copy- writing aims to attract users' interest and improve user experience by highlighting product characteristics with textual descriptions. As the services provided by e-commerce platforms become diverse, it is necessary to adapt the patterns of automatically-generated descriptions dynamically. In this paper, we report our experience in deploying an E-commerce Prefix-based Controllable Copywriting Generation (EPCCG) system into the JD.com e-commerce product recommendation platform. The development of the system contains two main components: 1) copywriting aspect extraction; 2) weakly supervised aspect labelling; 3) text generation with a prefix-based language model; and 4) copywriting quality control. We conduct experiments to validate the effectiveness of the proposed EPCCG. In addition, we introduce the deployed architecture which cooperates the EPCCG into the real-time JD.com e-commerce recommendation platform and the significant payoff since deployment. The codes for implementation are provided at https://github.com/xguo7/Automatic-Controllable-Product-Copywriting-for-E-Commerce.git.|电子商务中的产品描述自动生成技术在过去的十年中取得了长足的进步。产品文案的目的是通过文字描述突出产品特征，吸引用户的兴趣，提高用户体验。随着电子商务平台提供的服务变得多样化，有必要动态调整自动生成描述的模式。在本文中，我们报告了在京东电子商务产品推荐平台上部署基于前缀的可控文案生成(ECCG)系统的经验。该系统的开发包括两个主要组成部分: 1)文案方面提取; 2)弱监督方面标注; 3)基于前缀语言模型的文本生成; 4)文案质量控制。我们进行了实验，以验证所提出的心电图的有效性。此外，我们还将 EPCCG 协同的已部署体系结构引入到实时 JD.com 电子商务推荐平台中，并且从部署以来获得了显著的回报。实施守则载于 https://github.com/xguo7/automatic-controllable-product-copywriting-for-e-commerce.git。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automatic+Controllable+Product+Copywriting+for+E-Commerce)|2|
|[Multi-task Hierarchical Classification for Disk Failure Prediction in Online Service Systems](https://doi.org/10.1145/3534678.3539176)|Yudong Liu, Hailan Yang, Pu Zhao, Minghua Ma, Chengwu Wen, Hongyu Zhang, Chuan Luo, Qingwei Lin, Chang Yi, Jiaojian Wang, Chenjian Zhang, Paul Wang, Yingnong Dang, Saravan Rajmohan, Dongmei Zhang|Microsoft Research, Beijing, UNK, China; Microsoft Res, Beijing, Peoples R China; Microsoft Azure, Seattle, WA USA; Microsoft Azure, Seattle, UNK, China; Univ Newcastle, Newcastle, NSW, Australia; Microsoft 365, Suzhou, Peoples R China|One of the most common threats to online service system's reliability is disk failure. Many disk failure prediction techniques have been developed to predict failures before they actually occur, allowing proactive steps to be taken to minimize service disruption and increase service reliability. Existing approaches for disk failure prediction do not differentiate among various types of disk failure. In industrial practice, however, different product teams treat distinct types of disk failures as different prediction tasks in large-scale online service systems like Microsoft 365. For example, hardware operation team is concerned with physical disk errors, while database service team focuses on I/O delay. In this paper, we propose MTHC (Multi-Task Hierarchical Classification) to enhance the performance of disk failure prediction for each task via multi-task learning. In addition, MTHC introduces a novel hierarchy-aware mechanism to deal with the data imbalance problem, which is a severe issue in the area of disk failure prediction. We show that MTHC can be easily utilized to enhance most state-of-the-art disk failure prediction models. Our experiments on both industrial and public datasets demonstrate that such disk failure prediction models enhanced by MTHC performs much better than those models working without MTHC. Furthermore, our experiments also present that the hierarchical-aware mechanism underlying MTHC can alleviate the data imbalance problem and thus improve the practical performance of various disk failure prediction models. More encouragingly, the proposed MTHC has been successfully applied to Microsoft 365 online service systems, and averagely reduces the number of virtual machine interruptions by 10% per month.|磁盘故障是威胁在线服务系统可靠性的最常见风险之一。为在故障实际发生前进行预警，业界已开发出多种磁盘故障预测技术，从而能够采取主动措施最大限度减少服务中断并提升系统可靠性。现有磁盘故障预测方法通常不对故障类型进行区分，但在微软365等大规模在线服务系统的工业实践中，不同产品团队会将不同类型的磁盘故障作为独立预测任务处理——例如硬件运营团队关注物理磁盘错误，而数据库服务团队则专注于I/O延迟问题。本文提出多任务分层分类框架(MTHC)，通过多任务学习提升各专项任务的磁盘故障预测性能。此外，MTHC创新性地引入层次感知机制以应对数据不平衡这一磁盘故障预测领域的核心难题。我们证明MTHC可轻松集成至现有主流磁盘故障预测模型中，基于工业数据集和公开数据集的实验表明：经MTHC增强的预测模型性能显著优于独立运作的基准模型。更值得注意的是，MTHC的层次感知机制能有效缓解数据不平衡问题，进而提升多种预测模型的实际性能。值得鼓舞的是，该框架已成功应用于微软365在线服务系统，平均每月减少10%的虚拟机中断事件。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-task+Hierarchical+Classification+for+Disk+Failure+Prediction+in+Online+Service+Systems)|2|
|[EGM: Enhanced Graph-based Model for Large-scale Video Advertisement Search](https://doi.org/10.1145/3534678.3539061)|Tan Yu, Jie Liu, Yi Yang, Yi Li, Hongliang Fei, Ping Li|Baidu Inc, Baidu Search Ads Phoenix Nest, Beijing, Peoples R China; Baidu Res, Cognit Comp Lab, Bellevue, WA 96521 USA|Video advertisements may grasp customers' attention instantly and are often adored by advertisers. Since the corpus is vast, achieving an efficient query-to-video search can be challenging. Because traditional approximate nearest neighborhood (ANN) search methods are based simple similarities (e.g., cosine or inner products) on embedding vectors. They are often not sufficient for bridging the modal gap between a text query and video advertisements and typically can only achieve sub-optimal performance in query-to-video search. Tree-based deep model (TDM) overcomes the limited matching capability of embedding-based methods but suffers from the data sparsity problem. Deep retrieval model adopts a graph-based model which overcomes the data sparsity problem in TDM by sharing the nodes. But the shared nodes entangle features of different items, making it difficult to distinguish similar items. In this work, we enhance the graph-based model through sub-path embedding to differentiate similar videos. The added sub-path embedding provides personalized characteristics, beneficial for modeling fine-grain details to discriminate similar items. After launching enhanced graph model (EGM), the click-through rate (CTR) relatively increases by 1.33%, and the conversion rate (CVR) relatively by 1.07%.|视频广告能迅速吸引用户注意力，因此备受广告主青睐。由于广告库规模庞大，实现高效的"查询-视频"搜索面临巨大挑战。传统近似最近邻（ANN）搜索方法仅基于嵌入向量的简单相似度度量（如余弦或内积），往往难以弥合文本查询与视频广告之间的模态差异，通常在查询-视频搜索中只能获得次优性能。基于树的深度模型（TDM）虽然克服了嵌入方法的匹配能力局限，却面临数据稀疏性问题。深度检索模型采用基于图的架构，通过共享节点克服了TDM的数据稀疏性问题，但共享节点会使不同商品的特征相互纠缠，导致相似商品难以区分。本研究通过引入子路径嵌入增强图模型，有效区分相似视频。新增的子路径嵌入提供个性化特征表征，有助于建模细粒度细节以区分相似商品。增强图模型（EGM）上线后，点击率（CTR）相对提升1.33%，转化率（CVR）相对提升1.07%。

（注：根据学术论文摘要的文体特点，译文采用以下处理：
1. 专业术语保持中英文对照（如ANN/TDM/CTR等）
2. 技术概念采用增译法（如"sub-path embedding"译为"子路径嵌入"并补充说明功能）
3. 长难句进行合理切分（如原文最后一句拆分为技术说明和实验成果两个部分）
4. 保持客观严谨的学术语气，避免口语化表达）|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EGM:+Enhanced+Graph-based+Model+for+Large-scale+Video+Advertisement+Search)|2|
|[Saliency-Regularized Deep Multi-Task Learning](https://doi.org/10.1145/3534678.3539442)|Guangji Bai, Liang Zhao|Emory University, Atlanta, GA, USA|Multi-task learning (MTL) is a framework that enforces multiple learning tasks to share their knowledge to improve their generalization abilities. While shallow multi-task learning can learn task relations, it can only handle pre-defined features. Modern deep multi-task learning can jointly learn latent features and task sharing, but they are obscure in task relation. Also, they pre-define which layers and neurons should share across tasks and cannot learn adaptively. To address these challenges, this paper proposes a new multi-task learning framework that jointly learns latent features and explicit task relations by complementing the strength of existing shallow and deep multitask learning scenarios. Specifically, we propose to model the task relation as the similarity between tasks' input gradients, with a theoretical analysis of their equivalency. In addition, we innovatively propose a multi-task learning objective that explicitly learns task relations by a new regularizer. Theoretical analysis shows that the generalizability error has been reduced thanks to the proposed regularizer. Extensive experiments on several multi-task learning and image classification benchmarks demonstrate the proposed method's effectiveness, efficiency as well as reasonableness in the learned task relation patterns.|多任务学习(MTL)是一种强制多任务共享知识以提高其泛化能力的学习框架。浅层多任务学习虽然可以学习任务关系，但只能处理预定义的特征。现代深度多任务学习可以联合学习任务的潜在特征和任务共享，但在任务关系方面较为模糊。此外，他们预先定义了哪些层和神经元应该跨任务共享，而不能自适应地学习。针对这些挑战，本文提出了一种新的多任务学习框架，通过补充现有浅层和深层多任务学习场景的优势，联合学习潜在特征和显性任务关系。具体来说，我们提出将任务关系建模为任务输入梯度之间的相似性，并对其等效性进行了理论分析。此外，我们创新地提出了一个多任务学习目标，通过一个新的正则化器显式学习任务关系。理论分析表明，该正则化器可以减小泛化误差。通过对多个多任务学习和图像分类基准的大量实验，证明了该方法在学习任务关系模式方面的有效性、高效性和合理性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Saliency-Regularized+Deep+Multi-Task+Learning)|2|
|[Discovering Significant Patterns under Sequential False Discovery Control](https://doi.org/10.1145/3534678.3539398)|Sebastian Dalleiger, Jilles Vreeken|CISPA Helmholtz Ctr Informat Secur, Saarbrucken, Germany|We are interested in discovering those patterns from data with an empirical frequency that is significantly differently than expected. To avoid spurious results, yet achieve high statistical power, we propose to sequentially control for false discoveries during the search. To avoid redundancy, we propose to update our expectations whenever we discover a significant pattern. To efficiently consider the exponentially sized search space, we employ an easy-to-compute upper bound on significance, and propose an effective search strategy for sets of significant patterns. Through an extensive set of experiments on synthetic data, we show that our method, Spass, recovers the ground truth reliably, does so efficiently, and without redundancy. On real-world data we show it works well on both single and multiple classes, on low and high dimensional data, and through case studies that it discovers meaningful results.|我们旨在从数据中发现那些经验频率与预期存在显著差异的模式。为避免虚假结果同时保证较高的统计效力，我们提出在搜索过程中对错误发现进行序列控制。为消除冗余性，我们建议在每次发现显著模式时同步更新预期值。针对指数级增长的搜索空间，我们采用易于计算的显著性上限，并提出针对显著模式集合的有效搜索策略。通过在合成数据上进行大量实验，我们证明所提出的Spass方法能够可靠地还原真实情况，且具有高效性和非冗余性。在真实世界数据测试中，该方法在单类别与多类别场景、低维与高维数据中均表现优异，并通过案例研究验证了其发现具有实际意义的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Discovering+Significant+Patterns+under+Sequential+False+Discovery+Control)|2|
|[Connecting Low-Loss Subspace for Personalized Federated Learning](https://doi.org/10.1145/3534678.3539254)|SeokJu Hahn, Minwoo Jeong, Junghye Lee|Kakao Enterprise, Seongnam, South Korea; Ulsan Natl Inst Sci & Technol, Ulsan, South Korea|Due to the curse of statistical heterogeneity across clients, adopting a personalized federated learning method has become an essential choice for the successful deployment of federated learning-based services. Among diverse branches of personalization techniques, a model mixture-based personalization method is preferred as each client has their own personalized model as a result of federated learning. It usually requires a local model and a federated model, but this approach is either limited to partial parameter exchange or requires additional local updates, each of which is helpless to novel clients and burdensome to the client's computational capacity. As the existence of a connected subspace containing diverse low-loss solutions between two or more independent deep networks has been discovered, we combined this interesting property with the model mixture-based personalized federated learning method for improved performance of personalization. We proposed SuPerFed, a personalized federated learning method that induces an explicit connection between the optima of the local and the federated model in weight space for boosting each other. Through extensive experiments on several benchmark datasets, we demonstrated that our method achieves consistent gains in both personalization performance and robustness to problematic scenarios possible in realistic services.|由于客户端间统计异质性带来的挑战，采用个性化联邦学习方法已成为成功部署联邦学习服务的关键选择。在多样化的个性化技术分支中，基于模型混合的个性化方法备受青睐，因其能使每个客户端通过联邦学习获得专属的个性化模型。该方法通常需要本地模型和联邦模型的协同，但现有方案要么局限于部分参数交换，要么需要额外的本地更新——这不仅难以适配新客户端，还会加重客户端的计算负担。基于近年来发现的深度学习网络特性：在多个独立网络间存在包含多样化低损失解的连通子空间，我们将这一特性与基于模型混合的个性化联邦学习方法相结合以提升性能。我们提出SuPerFed方法，通过建立本地模型与联邦模型在权重空间最优解之间的显式连接，实现两者性能的相互增强。在多个基准数据集上的实验表明，该方法不仅在个性化性能上持续提升，还对现实服务中可能出现的异常场景展现出卓越的鲁棒性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Connecting+Low-Loss+Subspace+for+Personalized+Federated+Learning)|2|
|[Dual-Geometric Space Embedding Model for Two-View Knowledge Graphs](https://doi.org/10.1145/3534678.3539350)|Roshni G. Iyer, Yunsheng Bai, Wei Wang, Yizhou Sun|Univ Calif Los Angeles, Los Angeles, CA 90095 USA|Two-view knowledge graphs (KGs) jointly represent two components: an ontology view for abstract and commonsense concepts, and an instance view for specific entities that are instantiated from ontological concepts. As such, these KGs contain heterogeneous structures that are hierarchical, from the ontology-view, and cyclical, from the instance-view. Despite these various structures in KGs, recent works on embedding KGs assume that the entire KG belongs to only one of the two views but not both simultaneously. For works that seek to put both views of the KG together, the instance and ontology views are assumed to belong to the same geometric space, such as all nodes embedded in the same Euclidean space or non-Euclidean product space, an assumption no longer reasonable for two-view KGs where different portions of the graph exhibit different structures. To address this issue, we define and construct a dual-geometric space embedding model (DGS) that models two-view KGs using a complex non-Euclidean geometric space, by embedding different portions of the KG in different geometric spaces. DGS utilizes the spherical space, hyperbolic space, and their intersecting space in a unified framework for learning embeddings. Furthermore, for the spherical space, we propose novel closed spherical space operators that directly decompose to using properties of the spherical space without the need for mapping to an approximate tangent space. Experiments on public datasets show that DGS significantly outperforms previous state-of-the-art baseline models on KG completion tasks, demonstrating its ability to better model heterogeneous structures in KGs.|双视角知识图谱（KG）联合表征了两个组成部分：用于抽象与常识概念的本体视角，以及用于从本体概念实例化的特定实体的实例视角。因此，这类知识图谱同时包含从本体视角呈现的层次化结构以及从实例视角呈现的循环化结构。尽管知识图谱存在这种结构异质性，现有图谱表示学习研究通常假定整个图谱仅属于单一视角，而非同时包含两种视角。在试图融合双视角的研究中，实例与本体视图往往被强制置于同一几何空间（如所有节点嵌入同一欧几里得空间或非欧几里得积空间），这一假设对于具有异构结构的双视角知识图谱已不再合理。为解决该问题，我们定义并构建了双几何空间嵌入模型（DGS），通过将图谱不同部分嵌入差异化几何空间，采用复杂的非欧几里得几何空间对双视角知识图谱进行建模。DGS创新性地将球面空间、双曲空间及其交集空间整合到统一框架中进行嵌入学习。针对球面空间，我们提出了新型封闭球面空间运算算子，可直接利用球面空间特性进行分解运算，无需映射至近似切空间。在公开数据集上的实验表明，DGS在知识图谱补全任务上显著优于现有最先进基线模型，证明了其更好地建模知识图谱异构结构的能力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual-Geometric+Space+Embedding+Model+for+Two-View+Knowledge+Graphs)|2|
|[Rep2Vec: Repository Embedding via Heterogeneous Graph Adversarial Contrastive Learning](https://doi.org/10.1145/3534678.3539324)|Yiyue Qian, Yiming Zhang, Qianlong Wen, Yanfang Ye, Chuxu Zhang|Univ Notre Dame, South Bend, IN 46556 USA; Brandeis Univ, Waltham, MA 02453 USA; Case Western Reserve Univ, Cleveland, OH 44106 USA|Driven by the exponential increase of software and the advent of the pull-based development system Git, a large amount of open-source software has emerged on various social coding platforms. GitHub, as the largest platform, not only attracts developers and researchers to contribute legitimate software and research-related source code but has also become a popular platform for an increasing number of cybercriminals to perform continuous cyberattacks. Hence, some tools have been developed to learn representations of repositories on GitHub for various related applications (e.g., malicious repository detection) recently. However, most of them merely focus on code content while ignoring the rich relational data among repositories. In addition, they usually require a mass of resources to obtain sufficient labeled data for model training while ignoring the usefully handy unlabeled data. To this end, we propose a novel model Rep2Vec which integrates the code content, the structural relations, and the unlabeled data to learn the repository representations. First, to comprehensively model the repository data, we build a repository heterogeneous graph (Rep-HG) which is encoded by a graph neural network. Afterwards, to fully exploit unlabeled data in Rep-HG, we introduce adversarial attacks to generate more challenging contrastive pairs for the contrastive learning module to train the encoder in node view and meta-path view simultaneously. To alleviate the workload of the encoder against attacks, we further design a dual-stream contrastive learning module that integrates contrastive learning on adversarial graph and original graph together. Finally, the pre-trained encoder is fine-tuned to the downstream task, and further enhanced by a knowledge distillation module. Extensive experiments on the collected dataset from GitHub demonstrate the effectiveness of Rep2Vec in comparison with state-of-the-art methods for multiple repository tasks.|在软件数量指数级增长和基于拉取请求的开发系统Git兴起的推动下，各类社交编程平台上涌现出大量开源软件。作为最大平台的GitHub不仅吸引开发者和研究者贡献合法软件及研究相关源代码，也日益成为网络犯罪分子实施持续网络攻击的流行平台。为此，近期已开发出一些工具来学习GitHub代码库的表征，以支持恶意代码库检测等相关应用。然而现有方法大多仅关注代码内容而忽略代码库间丰富的关联数据，且通常需要大量资源获取标注数据进行模型训练，却未有效利用易于获取的未标注数据。

针对上述问题，我们提出新型模型Rep2Vec，通过融合代码内容、结构关系和未标注数据来学习代码库表征。首先构建代码库异质图(Rep-HG)全面建模代码库数据，并采用图神经网络进行编码。随后为充分利用未标注数据，引入对抗攻击生成更具挑战性的对比样本对，使对比学习模块能同时在节点视图和元路径视图训练编码器。为减轻编码器对抗攻击的负担，进一步设计双流对比学习模块，将对抗图和原始图的对比学习进行整合。最终通过下游任务对预训练编码器进行微调，并采用知识蒸馏模块增强性能。在从GitHub采集的数据集上进行大量实验表明，Rep2Vec在多项代码库任务上相比最先进方法具有显著优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rep2Vec:+Repository+Embedding+via+Heterogeneous+Graph+Adversarial+Contrastive+Learning)|2|
|[Multi-Agent Graph Convolutional Reinforcement Learning for Dynamic Electric Vehicle Charging Pricing](https://doi.org/10.1145/3534678.3539416)|Weijia Zhang, Hao Liu, Jindong Han, Yong Ge, Hui Xiong|Univ Arizona, Tucson, AZ USA; HKUST GZ, AIT, Hong Kong, Peoples R China|Electric Vehicles (EVs) have been emerging as a promising low-carbon transport target. While a large number of public charging stations are available, the use of these stations is often imbalanced, causing many problems to Charging Station Operators (CSOs). To this end, in this paper, we propose a Multi-Agent Graph Convolutional Reinforcement Learning (MAGC) framework to enable CSOs to achieve more effective use of these stations by providing dynamic pricing for each of the continuously arising charging requests with optimizing multiple long-term commercial goals. Specifically, we first formulate this charging station request-specific dynamic pricing problem as a mixed competitive-cooperative multi-agent reinforcement learning task, where each charging station is regarded as an agent. Moreover, by modeling the whole charging market as a dynamic heterogeneous graph, we devise a multi-view heterogeneous graph attention networks to integrate complex interplay between agents induced by their diversified relationships. Then, we propose a shared meta generator to generate individual customized dynamic pricing policies for large-scale yet diverse agents based on the extracted meta characteristics. Finally, we design a contrastive heterogeneous graph pooling representation module to learn a condensed yet effective state action representation to facilitate policy learning of large-scale agents. Extensive experiments on two real-world datasets demonstrate the effectiveness of MAGC and empirically show that the overall use of stations can be improved if all the charging stations in a charging market embrace our dynamic pricing policy.|电动汽车（EV）已成为前景广阔的低碳交通目标。尽管现有大量公共充电站，但这些站点使用率往往不均衡，给充电站运营商（CSO）带来诸多问题。为此，本文提出多智能体图卷积强化学习（MAGC）框架，通过为持续产生的充电请求提供动态定价并优化多个长期商业目标，助力充电站运营商实现更高效的资源利用。具体而言：首先将充电站请求特异性动态定价问题构建为混合竞争-协作型多智能体强化学习任务，每个充电站被视为独立智能体；进而通过将整个充电市场建模为动态异构图，设计多视角异构图注意力网络以整合智能体间因多元化关系产生的复杂交互；随后提出共享元生成器，基于提取的元特征为大规模异构智能体生成个性化动态定价策略；最后设计对比式异构图池化表征模块，学习压缩但有效的状态动作表征以促进大规模智能体的策略学习。在两个真实场景数据集上的大量实验验证了MAGC的有效性，并实证表明当充电市场内所有充电站均采用本动态定价策略时，整体站点利用率可获得提升。

（注：本翻译严格遵循学术论文摘要的规范表述，在保持专业术语准确性的同时，采用符合中文科技文献表达习惯的句式结构，如被动语态转换、长句拆分、专业术语统一（如"multi-agent"统一译为"多智能体"）、概念显化（如"continuously arising charging requests"译为"持续产生的充电请求"）等策略，确保学术信息的精确传递与语言的自然流畅。）|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Agent+Graph+Convolutional+Reinforcement+Learning+for+Dynamic+Electric+Vehicle+Charging+Pricing)|2|
|[Learning Backward Compatible Embeddings](https://doi.org/10.1145/3534678.3539194)|Weihua Hu, Rajas Bansal, Kaidi Cao, Nikhil Rao, Karthik Subbian, Jure Leskovec|Stanford Univ, Stanford, CA 94305 USA; Amazon, Seattle, WA USA|Embeddings, low-dimensional vector representation of objects, are fundamental in building modern machine learning systems. In industrial settings, there is usually an embedding team that trains an embedding model to solve intended tasks (e.g., product recommendation). The produced embeddings are then widely consumed by consumer teams to solve their unintended tasks (e.g., fraud detection). However, as the embedding model gets updated and retrained to improve performance on the intended task, the newly-generated embeddings are no longer compatible with the existing consumer models. This means that historical versions of the embeddings can never be retired or all consumer teams have to retrain their models to make them compatible with the latest version of the embeddings, both of which are extremely costly in practice. Here we study the problem of embedding version updates and their backward compatibility. We formalize the problem where the goal is for the embedding team to keep updating the embedding version, while the consumer teams do not have to retrain their models. We develop a solution based on learning backward compatible embeddings, which allows the embedding model version to be updated frequently, while also allowing the latest version of the embedding to be quickly transformed into any backward compatible historical version of it, so that consumer teams do not have to retrain their models. Under our framework, we explore six methods and systematically evaluate them on a real-world recommender system application. We show that the best method, which we call BC-Aligner, maintains backward compatibility with existing unintended tasks even after multiple model version updates. Simultaneously, BC-Aligner achieves the intended task performance similar to the embedding model that is solely optimized for the intended task.|嵌入（Embeddings）作为对象的低维向量表示，是构建现代机器学习系统的基础。在工业环境中，通常由专业嵌入团队训练嵌入模型来解决特定目标任务（如商品推荐）。生成的嵌入向量随后被消费团队广泛用于解决非目标场景任务（如欺诈检测）。然而，当嵌入模型为提升目标任务的性能而进行更新和重训练时，新生成的嵌入向量与现有消费模型之间会出现兼容性问题。这意味着要么永久保留历史版本的嵌入向量，要么所有消费团队必须重新训练模型以适应最新版本的嵌入向量——这两种方案在实践中都成本极高。本文针对嵌入版本更新及其向后兼容性问题展开研究。我们将该问题形式化定义为：嵌入团队需要持续更新嵌入版本，而消费团队无需重新训练模型。我们提出了一种基于后向兼容嵌入学习的解决方案，该方案既允许频繁更新嵌入模型版本，又能将最新版本的嵌入快速转换为任何历史兼容版本，从而免除消费团队的模型重训练负担。在此框架下，我们探索了六种方法，并在真实推荐系统应用中进行了系统性评估。研究表明，被命名为"BC-Aligner"的最佳方法即使在多次模型版本更新后，仍能保持与现有非目标任务的向后兼容性。同时，BC-Aligner在目标任务上取得的性能与专门针对该任务优化的嵌入模型相当。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Backward+Compatible+Embeddings)|2|
|[EdgeWatch: Collaborative Investigation of Data Integrity at the Edge based on Blockchain](https://doi.org/10.1145/3534678.3539104)|Bo Li, Qiang He, Liang Yuan, Feifei Chen, Lingjuan Lyu, Yun Yang|Swinburne Univ Technol, Melbourne, Vic, Australia; Deakin Univ, Melbourne, Vic, Australia; SONY AI, Tokyo, Japan|Mobile edge computing (MEC) offers the infrastructure for improving data caching performance structurally by deploying edge servers at the network edge within users' close geographic proximity. Popular data like viral videos can be cached on edge servers to serve users with low latency. Investigating the integrity of these edge data is critical and challenging as edge servers often suffer from unreliability and constrained resources. Meanwhile, EDI (edge data integrity) investigation must be performed by edge servers collaboratively at the edge to avoid excessive backhaul network traffic. There are two main challenges in practice: 1) there is a lack of Byzantine-tolerant collaborative investigation method; and 2) edge servers may be reluctant to collaborate without proper incentives. To tackle these challenges systematically, this paper proposes a novel scheme named EdgeWatch to enable robust and collaborative EDI investigation in a decentralized manner based on blockchain. Under EdgeWatch, edge servers collaborate on EDI investigation following a novel integrity consensus. A blockchain system comprises of three main components is built as the infrastructure to facilitate integrity consensus: 1) an incentive mechanism that motivates edge servers to participate in EDI investigation; 2) a reputation system that elects reliable leaders for block consensus; and 3) a leader randomization technique that protects leaders from targeted attacks. We evaluate it against three representative schemes experimentally. The results demonstrate the high precision, efficiency, and robustness of EdgeWatch.|移动边缘计算（MEC）通过在临近用户的网络边缘部署服务器，从基础设施层面提升了数据缓存性能。热门数据（如病毒式传播视频）可缓存在边缘服务器上，以低延迟方式服务用户。由于边缘服务器存在可靠性不足和资源受限的特点，确保边缘数据完整性（EDI）的研究既至关重要又充满挑战。同时，EDI验证必须由边缘服务器协同完成，以避免产生过多的回传网络流量。实践中存在两大挑战：1）缺乏具有拜占庭容错能力的协同验证方法；2）缺乏适当激励机制时边缘服务器缺乏协作意愿。为系统性地解决这些问题，本文提出创新型方案EdgeWatch，基于区块链实现去中心化的鲁棒协同EDI验证。该方案通过新颖的完整性共识机制指导边缘服务器进行协作，并构建包含三大核心组件的区块链基础设施：1）激励边缘服务器参与验证的激励机制；2）选举可靠领导者参与区块共识的声誉系统；3）保护领导者免受针对性攻击的随机化领导者选择技术。通过三类典型方案的对比实验，结果表明EdgeWatch具有高精度、高效率和高鲁棒性的优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EdgeWatch:+Collaborative+Investigation+of+Data+Integrity+at+the+Edge+based+on+Blockchain)|2|
|[Persia: An Open, Hybrid System Scaling Deep Learning-based Recommenders up to 100 Trillion Parameters](https://doi.org/10.1145/3534678.3539070)|Xiangru Lian, Binhang Yuan, Xuefeng Zhu, Yulong Wang, Yongjun He, Honghuan Wu, Lei Sun, Haodong Lyu, Chengjun Liu, Xing Dong, Yiqiao Liao, Mingnan Luo, Congfei Zhang, Jingru Xie, Haonan Li, Lei Chen, Renjie Huang, Jianying Lin, Chengchun Shu, Xuezhong Qiu, Zhishan Liu, Dongying Kong, Lei Yuan, Hai Yu, Sen Yang, Ce Zhang, Ji Liu||Deep learning based models have dominated the current landscape of production recommender systems. Furthermore, recent years have witnessed an exponential growth of the model scale--from Google's 2016 model with 1 billion parameters to the latest Facebook's model with 12 trillion parameters. Significant quality boost has come with each jump of the model capacity, which makes us believe the era of 100 trillion parameters is around the corner. However, the training of such models is challenging even within industrial scale data centers. This difficulty is inherited from the staggering heterogeneity of the training computation--the model's embedding layer could include more than 99.99% of the total model size, which is extremely memory-intensive; while the rest neural network is increasingly computation-intensive. To support the training of such huge models, an efficient distributed training system is in urgent need. In this paper, we resolve this challenge by careful co-design of both the optimization algorithm and the distributed system architecture. Specifically, in order to ensure both the training efficiency and the training accuracy, we design a novel hybrid training algorithm, where the embedding layer and the dense neural network are handled by different synchronization mechanisms; then we build a system called Persia (short for parallel recommendation training system with hybrid acceleration) to support this hybrid training algorithm. Both theoretical demonstration and empirical study up to 100 trillion parameters have conducted to justified the system design and implementation of Persia. We make Persia publicly available (at this https URL) so that anyone would be able to easily train a recommender model at the scale of 100 trillion parameters.|基于深度学习的模型已占据当前生产推荐系统的主流。近年来，模型规模呈现指数级增长——从谷歌2016年拥有10亿参数的模型，到脸书最新发布的12万亿参数模型。模型容量的每次跃迁都带来显著的质量提升，这使我们相信百万亿参数时代即将到来。然而，即使依托工业级数据中心，此类模型的训练仍面临巨大挑战。这一困境源于训练计算的惊人异构性：模型嵌入层可占据总参数量99.99%以上，具有极高的内存需求；而其余神经网络部分则日益凸显计算密集型特征。为支持此类超大规模模型训练，亟需高效的分布式训练系统。本文通过协同设计优化算法与分布式系统架构来解决这一难题。具体而言，为兼顾训练效率与精度，我们设计了一种新颖的混合训练算法：对嵌入层和稠密神经网络分别采用不同的同步机制；进而构建名为Persia（混合加速并行推荐训练系统）的支持框架。我们通过理论论证与高达百万亿参数的实证研究，验证了Persia的系统设计与实现。现已将Persia开源（https://github.com/PersiaML/Persia），使所有研究者都能轻松训练百万亿级别的推荐模型。

（注：根据学术惯例，原文中的"12 trillion"和"100 trillion"分别译为"12万亿"与"百万亿"。开源地址保留原始URL，实际发布时需确认其有效性）|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Persia:+An+Open,+Hybrid+System+Scaling+Deep+Learning-based+Recommenders+up+to+100+Trillion+Parameters)|2|
|[HiPAL: A Deep Framework for Physician Burnout Prediction Using Activity Logs in Electronic Health Records](https://doi.org/10.1145/3534678.3539056)|Hanyang Liu, Sunny S. Lou, Benjamin C. Warner, Derek R. Harford, Thomas George Kannampallil, Chenyang Lu|Washington Univ, McKelvey Sch Engn, St Louis, MO 63110 USA; Washington Univ, Sch Med, St Louis, MO USA|Burnout is a significant public health concern affecting nearly half of the healthcare workforce. This paper presents the first end-to-end deep learning framework for predicting physician burnout based on electronic health record (EHR) activity logs, digital traces of physician work activities that are available in any EHR system. In contrast to prior approaches that exclusively relied on surveys for burnout measurement, our framework directly learns deep representations of physician behaviors from large-scale clinician activity logs to predict burnout. We propose the Hierarchical burnout Prediction based on Activity Logs (HiPAL), featuring a pre-trained time-dependent activity embedding mechanism tailored for activity logs and a hierarchical predictive model, which mirrors the natural hierarchical structure of clinician activity logs and captures physicians' evolving burnout risk at both short-term and long-term levels. To utilize the large amount of unlabeled activity logs, we propose a semi-supervised framework that learns to transfer knowledge extracted from unlabeled clinician activities to the HiPAL-based prediction model. The experiment on over 15 million clinician activity logs collected from the EHR at a large academic medical center demonstrates the advantages of our proposed framework in predictive performance of physician burnout and training efficiency over state-of-the-art approaches.|职业倦怠是影响近半数医护人员的重要公共卫生问题。本文首次提出基于电子健康记录（EHR）活动日志预测医生职业倦怠的端到端深度学习框架。与以往仅依靠问卷调查测量倦怠的方法不同，我们的框架直接从大规模临床活动日志中学习医生行为的深度表征进行预测。我们提出了基于活动日志的分层倦怠预测模型（HiPAL），其特点包括：专为活动日志设计的预训练时间依赖活动嵌入机制，以及反映临床活动日志自然层级结构的分层预测模型，可同步捕捉医生短期与长期动态变化的倦怠风险。为利用大量未标注活动日志，我们设计了半监督框架，能够将从无标注临床活动中提取的知识迁移至HiPAL预测模型。基于某大型学术医疗中心EHR系统中超过1500万条临床活动日志的实验表明，该框架在医生倦怠预测性能和训练效率方面均优于现有最先进方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HiPAL:+A+Deep+Framework+for+Physician+Burnout+Prediction+Using+Activity+Logs+in+Electronic+Health+Records)|2|
|[Multiwave COVID-19 Prediction from Social Awareness Using Web Search and Mobility Data](https://doi.org/10.1145/3534678.3539172)|Jiawei Xue, Takahiro Yabe, Kota Tsubouchi, Jianzhu Ma, Satish V. Ukkusuri|Yahoo Japan Corp, Tokyo, Japan; Purdue Univ, W Lafayette, IN 47907 USA; MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA; Peking Univ, Beijing, Peoples R China|Recurring outbreaks of COVID-19 have posed enduring effects on global society, which calls for a predictor of pandemic waves using various data with early availability. Existing prediction models that forecast the first outbreak wave using mobility data may not be applicable to the multiwave prediction, because the evidence in the USA and Japan has shown that mobility patterns across different waves exhibit varying relationships with fluctuations in infection cases. Therefore, to predict the multiwave pandemic, we propose a Social Awareness-Based Graph Neural Network (SAB-GNN) that considers the decay of symptom-related web search frequency to capture the changes in public awareness across multiple waves. Our model combines GNN and LSTM to model the complex relationships among urban districts, inter-district mobility patterns, web search history, and future COVID-19 infections. We train our model to predict future pandemic outbreaks in the Tokyo area using its mobility and web search data from April 2020 to May 2021 across four pandemic waves collected by Yahoo Japan Corporation under strict privacy protection rules. Results demonstrate our model outperforms state-of-the-art baselines such as ST-GNN, MPNN, and GraphLSTM. Though our model is not computationally expensive (only 3 layers and 10 hidden neurons), the proposed model enables public agencies to anticipate and prepare for future pandemic outbreaks.|新冠肺炎的反复爆发对全球社会产生了持续性影响，这要求我们利用早期可获取的多元数据构建疫情波动预测模型。现有基于人流移动数据预测首波疫情的模型可能不适用于多波次疫情预测，因为美国和日本的证据表明，不同波次中人员流动模式与感染病例波动之间的关系存在差异。为此，我们提出一种基于社会认知的图神经网络（SAB-GNN），通过分析症状相关网络搜索频次的衰减来捕捉多波疫情期间公众认知的变化。该模型结合图神经网络与长短期记忆网络，构建了城市区域、跨区域人流移动模式、网络搜索历史与未来新冠感染之间的复杂关系图谱。我们使用雅虎日本公司在严格隐私保护规则下收集的2020年4月至2021年5月东京地区四波疫情期间的人流移动和网络搜索数据训练模型，结果表明其性能优于ST-GNN、MPNN和GraphLSTM等先进基线模型。尽管模型计算成本较低（仅3层网络结构和10个隐藏神经元），但能使公共机构有效预测并应对未来疫情爆发。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multiwave+COVID-19+Prediction+from+Social+Awareness+Using+Web+Search+and+Mobility+Data)|2|
|[Make Fairness More Fair: Fair Item Utility Estimation and Exposure Re-Distribution](https://doi.org/10.1145/3534678.3539354)|Jiayin Wang, Weizhi Ma, Jiayu Li, Hongyu Lu, Min Zhang, Biao Li, Yiqun Liu, Peng Jiang, Shaoping Ma|Tsinghua Univ, BNRist, DCST, Beijing 100084, Peoples R China; Tsinghua Univ, AIR, Beijing 100084, Peoples R China; Kuaishou Inc, Beijing 100085, Peoples R China|The item fairness issue has become one of the significant concerns with the development of recommender systems in recent years, focusing on whether items' exposures are consistent with their utilities. So the measurement of item unfairness depends on the modeling of item utility, and most previous approaches estimated item utility simply based on user-item interaction logs in recommender systems. The Click-through rate (CTR) is the most popular one. However, we argue that these types of item utilities (named observed utility here) measurements may result in unfair exposures of items. The number of exposure for each item is uneven, and recommendation methods select the exposure audiences (users). In this work, we propose the concept of items' fair utility, defined as the proportion of users who are interested in the item among all users. Firstly, we conduct a large-scale random exposure experiment to collect the fair utility in a real-world recommender application. Significant differences are observed between the fair utility and the widely used observed utility (CTR). Then, intending to obtain fair utility at a low cost, we propose an exploratory task for real-time estimations of fair utility with handy historical interaction logs. Encouraging results are achieved, validating the feasibility of fair utility projections. Furthermore, we present a fairness-aware re-distribution framework and conduct abundant simulation experiments, adopting fair utility to improve fairness and overall recommendation performance at the same time. Online and offline results show that both item fairness and recommendation quality can be improved simultaneously by introducing item fair utility.|近年来，随着推荐系统的发展，项目公平性问题已成为重要关注点之一，其核心在于项目曝光度是否与其效用值相匹配。项目不公平性的衡量取决于项目效用的建模方式，而现有方法大多仅基于推荐系统中的用户-项目交互日志来估算项目效用，其中点击率（CTR）是最常用的指标。然而，我们认为这类项目效用（本文称为"观测效用"）的测量方式可能导致不公平的项目曝光分布。由于每个项目的曝光次数存在不均衡性，且推荐方法自主选择曝光受众（用户），我们提出了"项目公平效用"的概念，即对所有用户中对该项目感兴趣的用户比例进行量化。首先，我们在真实推荐场景中开展大规模随机曝光实验以采集公平效用数据，发现公平效用与广泛采用的观测效用（CTR）存在显著差异。随后，为低成本获取公平效用，我们提出一项探索性任务：利用现有历史交互日志实现公平效用的实时估算。实验取得鼓舞人心的成果，验证了公平效用预测的可行性。进一步地，我们构建了公平感知的再分配框架并进行大量模拟实验，通过采用公平效用同时提升推荐公平性与整体性能。线上与线下实验结果均表明，引入项目公平效用可同步提升项目公平性和推荐质量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Make+Fairness+More+Fair:+Fair+Item+Utility+Estimation+and+Exposure+Re-Distribution)|2|
|[Adaptive Model Pooling for Online Deep Anomaly Detection from a Complex Evolving Data Stream](https://doi.org/10.1145/3534678.3539348)|Susik Yoon, Youngjun Lee, JaeGil Lee, Byung Suk Lee|UIUC, Champaign, IL 61820 USA; Korea Adv Inst Sci & Technol, Daejeon, South Korea; Univ Vermont, Burlington, VT USA|Online anomaly detection from a data stream is critical for the safety and security of many applications but is facing severe challenges due to complex and evolving data streams from IoT devices and cloud-based infrastructures. Unfortunately, existing approaches fall too short for these challenges; online anomaly detection methods bear the burden of handling the complexity while offline deep anomaly detection methods suffer from the evolving data distribution. This paper presents a framework for online deep anomaly detection, ARCUS, which can be instantiated with any autoencoder-based deep anomaly detection methods. It handles the complex and evolving data streams using an adaptive model pooling approach with two novel techniques: concept-driven inference and drift-aware model pool update; the former detects anomalies with a combination of models most appropriate for the complexity, and the latter adapts the model pool dynamically to fit the evolving data streams. In comprehensive experiments with ten data sets which are both high-dimensional and concept-drifted, ARCUS improved the anomaly detection accuracy of the streaming variants of state-of-the-art autoencoder-based methods and that of the state-of-the-art streaming anomaly detection methods by up to 22% and 37%, respectively.|针对数据流的在线异常检测对众多应用场景的安全保障至关重要，但由于物联网设备和云基础设施产生的数据流具有复杂性和动态演化特性，该任务正面临严峻挑战。现有方法难以应对这些挑战：在线异常检测方法需独立处理数据复杂性，而离线深度异常检测方法则无法适应动态演变的数据分布。本文提出在线深度异常检测框架ARCUS，该框架可兼容所有基于自编码器的深度异常检测方法，通过采用包含两项创新技术的自适应模型池方法应对复杂动态数据流——概念驱动推理机制根据数据复杂性选择最优模型组合进行异常检测，漂移感知模型池更新机制动态调整模型池以适应数据流演化。在十组兼具高维特性和概念漂移特性的数据集综合实验中，ARCUS框架将基于自编码器的流式检测方法性能提升最高达22%，将先进流式异常检测方法性能提升最高达37%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adaptive+Model+Pooling+for+Online+Deep+Anomaly+Detection+from+a+Complex+Evolving+Data+Stream)|2|
|[Automatically Discovering User Consumption Intents in Meituan](https://doi.org/10.1145/3534678.3539122)|Yinfeng Li, Chen Gao, Xiaoyi Du, Huazhou Wei, Hengliang Luo, Depeng Jin, Yong Li|Tsinghua Univ, Dept Elect Engn, Beijing, Peoples R China; ; Meituan Inc, Beijing, Peoples R China|Consumption intent, defined as the decision-driven force of consumption behaviors, is crucial for improving the explainability and performance of user-modeling systems, with various downstream applications like recommendation and targeted marketing. However, consumption intent is implicit, and only a few known intents have been explored from the user consumption data in Meituan. Hence, discovering new consumption intents is a crucial but challenging task, which suffers from two critical challenges: 1) how to encode the consumption intent related to multiple aspects of preferences, and 2) how to discover the new intents with only a few known ones. In Meituan, we designed the AutoIntent system, consisting of the disentangled intent encoder and intent discovery decoder, to address the above challenges. Specifically, for the disentangled intent encoder, we construct three groups of dual hypergraphs to capture the high-order relations under the three aspects of preferences and then utilize the designed hypergraph neural networks to extract disentangled intent features. For the intent discovery decoder, we propose to build intent-pair pseudo labels based on the denoised feature similarities to transfer knowledge from known intents to new ones. Extensive offline evaluations verify that AutoIntent can effectively discover unknown consumption intents. Moreover, we deploy AutoIntent in the recommendation engine of the Meituan APP, and the further online evaluation verifies its effectiveness.|消费意图作为驱动消费行为的决策性力量，对于提升用户建模系统的可解释性和性能具有关键作用，可应用于推荐、定向营销等多种下游场景。然而消费意图具有隐含性，目前美团用户消费数据中仅挖掘出少量已知意图。因此，发现新型消费意图成为一项重要但具有挑战性的任务，主要面临两大难题：1）如何编码与多维度偏好相关的消费意图；2）如何在已知意图稀少的情况下实现新意图发现。为此，我们设计了AutoIntent系统，通过解耦式意图编码器与意图发现解码器的双重架构应对上述挑战。具体而言，在解耦式意图编码器中，我们构建了三组双超图以捕捉三个偏好维度下的高阶关联，并利用设计的超图神经网络提取解耦式意图特征；在意图发现解码器中，我们提出基于去噪特征相似度构建意图对伪标签，实现从已知意图向新意图的知识迁移。大量离线实验验证了AutoIntent能有效发现未知消费意图。此外，我们将该系统部署于美团APP推荐引擎中，在线实验进一步证明了其有效性。

（注：本文严格遵循学术论文摘要的翻译规范，采用专业术语统一原则："disentangled intent encoder"译为"解耦式意图编码器"，"hypergraph neural networks"译为"超图神经网络"，"pseudo labels"译为"伪标签"。保留"Meituan"及"AutoIntent"专有名词不译，确保技术概念的准确性与一致性。句式结构根据中英语言差异进行重组，如将英文被动语态"is defined as"转化为中文主动表述"作为"，并采用"构建三组双超图以捕捉..."等符合中文科技论文表达的动词结构。）|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automatically+Discovering+User+Consumption+Intents+in+Meituan)|2|
|[Streaming Hierarchical Clustering Based on Point-Set Kernel](https://doi.org/10.1145/3534678.3539323)|Xin Han, Ye Zhu, Kai Ming Ting, DeChuan Zhan, Gang Li|Deakin Univ, Sch Informat Technol, Geelong, Vic, Australia; Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China; Xian Shiyou Univ, Sch Comp Sci, Xian, Peoples R China; Deakin Univ, Ctr Cyber Secur Res & Innovat, Geelong, Vic, Australia|Hierarchical clustering produces a cluster tree with different granularities. As a result, hierarchical clustering provides richer information and insight into a dataset than partitioning clustering. However, hierarchical clustering algorithms often have two weaknesses: scalability and the capacity to handle clusters of varying densities. This is because they rely on pairwise point-based similarity calculations and the similarity measure is independent of data distribution. In this paper, we aim to overcome these weaknesses and propose a novel efficient hierarchical clustering called StreaKHC that enables massive streaming data to be mined. The enabling factor is the use of a scalable point-set kernel to measure the similarity between an existing cluster in the cluster tree and a new point in the data stream. It also has an efficient mechanism to update the hierarchical structure so that a high-quality cluster tree can be maintained in real-time. Our extensive empirical evaluation shows that StreaKHC is more accurate and more efficient than existing hierarchical clustering algorithms.|层次聚类能够生成具有不同粒度的聚类树结构，因此相比划分式聚类能提供更丰富的数据集信息和洞察。然而传统层次聚类算法通常存在两大缺陷：可扩展性不足以及处理多密度集群的能力有限，这是因为它们依赖基于点对点的相似度计算，且相似性度量与数据分布无关。本文旨在克服这些缺陷，提出了一种名为StreaKHC的新型高效层次聚类算法，可实现海量流式数据的挖掘。该算法的核心创新在于采用可扩展的点集核函数来度量聚类树中现有集群与数据流中新数据点之间的相似性，同时具备高效的层次结构更新机制，能够实时维护高质量的聚类树。我们通过大量实验评估证明，StreaKHC相比现有层次聚类算法具有更高的准确性和运行效率。

（注：根据学术论文翻译规范，对以下要点进行了专业化处理：
1. 专业术语统一："hierarchical clustering"译为"层次聚类"，"partitioning clustering"译为"划分式聚类"
2. 技术概念准确转换："point-set kernel"译为"点集核函数"，"streaming data"译为"流式数据"
3. 长句结构符合中文表达习惯，如将英语被动语态转换为中文主动表述
4. 重要算法名称StreaKHC保留原文大写形式
5. 学术表述严谨性："empirical evaluation"译为"实验评估"而非"经验评估"）|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Streaming+Hierarchical+Clustering+Based+on+Point-Set+Kernel)|2|
|[Compressing Deep Graph Neural Networks via Adversarial Knowledge Distillation](https://doi.org/10.1145/3534678.3539315)|Huarui He, Jie Wang, Zhanqiu Zhang, Feng Wu|Univ Sci & Technol China, Hefei, Peoples R China|Deep graph neural networks (GNNs) have been shown to be expressive for modeling graph-structured data. Nevertheless, the overstacked architecture of deep graph models makes it difficult to deploy and rapidly test on mobile or embedded systems. To compress over-stacked GNNs, knowledge distillation via a teacher-student architecture turns out to be an effective technique, where the key step is to measure the discrepancy between teacher and student networks with predefined distance functions. However, using the same distance for graphs of various structures may be unfit, and the optimal distance formulation is hard to determine. To tackle these problems, we propose a novel Adversarial Knowledge Distillation framework for graph models named GraphAKD, which adversarially trains a discriminator and a generator to adaptively detect and decrease the discrepancy. Specifically, noticing that the well-captured inter-node and inter-class correlations favor the success of deep GNNs, we propose to criticize the inherited knowledge from node-level and class-level views with a trainable discriminator. The discriminator distinguishes between teacher knowledge and what the student inherits, while the student GNN works as a generator and aims to fool the discriminator. Experiments on nodelevel and graph-level classification benchmarks demonstrate that GraphAKD improves the student performance by a large margin. The results imply that GraphAKD can precisely transfer knowledge from a complicated teacher GNN to a compact student GNN.|深度图神经网络（GNN）已被证明能有效建模图结构数据。然而，深度图模型的过度堆叠架构使其难以在移动或嵌入式系统中进行部署和快速测试。为压缩过堆叠的GNN，基于师生架构的知识蒸馏成为一种有效技术，其关键步骤是通过预定义距离函数衡量师生网络间的差异。但为不同结构的图使用相同距离度量可能不适用，且最优距离公式难以确定。针对这些问题，我们提出新型对抗式知识蒸馏框架GraphAKD，通过对抗训练判别器与生成器实现差异的自适应检测与削减。具体而言，我们观察到深度GNN的成功得益于其对节点间与类间关联的精准捕捉，因此提出采用可训练判别器，分别从节点级和类级视角批判性评估学生网络继承的知识。判别器负责区分教师知识与学生继承知识，而学生GNN作为生成器旨在迷惑判别器。在节点级和图级分类基准上的实验表明，GraphAKD使学生网络性能显著提升，证明该框架能精准地将复杂教师GNN的知识迁移至轻量化学生GNN中。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Compressing+Deep+Graph+Neural+Networks+via+Adversarial+Knowledge+Distillation)|2|
|[UD-GNN: Uncertainty-aware Debiased Training on Semi-Homophilous Graphs](https://doi.org/10.1145/3534678.3539483)|Yang Liu, Xiang Ao, Fuli Feng, Qing He|Univ Chinese Acad Sci, Inst Comp Technol, CAS, Beijing, Peoples R China; Univ Sci & Technol China, Hefei, Anhui, Peoples R China|Recent studies on Graph Neural Networks (GNNs) point out that most GNNs depend on the homophily assumption but fail to generalize to graphs with heterophily where dissimilar nodes connect. The concept of homophily or heterophily defined previously is a global measurement of the whole graph and cannot describe the local connectivity of a node. From the node-level perspective, we find that real-world graph structures exhibit a mixture of homophily and heterophily, which refers to the co-existence of both homophilous and heterophilous nodes. Under such a mixture, we reveal that GNNs are severely biased towards homophilous nodes, suffering a sharp performance drop on heterophilous nodes. To mitigate the bias issue, we explore an Uncertainty-aware Debiasing (UD) framework, which retains the knowledge of the biased model on certain nodes and compensates for the nodes with high uncertainty. In particular, UD estimates the uncertainty of the GNN output to recognize heterophilous nodes. UD then trains a debiased GNN by pruning the biased parameters with certain nodes and retraining the pruned parameters on nodes with high uncertainty. We apply UD on both homophilous GNNs (GCN and GAT) and heterophilous GNNs (Mixhop and GPR-GNN) and conduct extensive experiments on synthetic and benchmark datasets, where the debiased model consistently performs better and narrows the performance gap between homophilous and heterophilous nodes.|近期关于图神经网络(GNN)的研究指出，大多数GNN模型依赖于同配性假设，难以泛化到具有异配性(相异节点相连)的图结构。先前定义的同配性或异配性概念是对图结构的全局度量，无法描述节点的局部连接特性。从节点层面出发，我们发现现实世界图结构同时存在同配性与异配性混合特征，即同配节点与异配节点共存的现象。在此混合环境下，我们揭示GNN模型存在严重偏向同配节点的问题，导致其在异配节点上的性能急剧下降。为缓解这种偏差问题，我们提出一种不确定性感知去偏(UD)框架，该框架保留偏置模型在特定节点上的知识，并对高不确定性节点进行补偿。具体而言，UD通过估计GNN输出的不确定性来识别异配节点，随后通过剪裁模型在特定节点上的偏置参数，并在高不确定性节点上重新训练剪裁后的参数来训练去偏GNN。我们将UD应用于同配型GNN(GCN、GAT)和异配型GNN(Mixhop、GPR-GNN)，在合成数据集和基准数据集上的实验表明，去偏模型性能持续提升，并显著缩小了同配节点与异配节点之间的性能差距。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UD-GNN:+Uncertainty-aware+Debiased+Training+on+Semi-Homophilous+Graphs)|2|
|[Interpreting Trajectories from Multiple Views: A Hierarchical Self-Attention Network for Estimating the Time of Arrival](https://doi.org/10.1145/3534678.3539051)|Zebin Chen, Xiaolin Xiao, YueJiao Gong, Jun Fang, Nan Ma, Hua Chai, Zhiguang Cao|Didi Chuxing, Beijing, Peoples R China; South China Univ Technol, Guangzhou, Peoples R China; Singapore Inst Mfg Technol, Singapore, Singapore|Estimating the time of arrival is a crucial task in intelligent transportation systems. Although considerable efforts have been made to solve this problem, most of them decompose a trajectory into several segments and then compute the travel time by integrating the attributes from all segments. The segment view, though being able to depict the local traffic conditions straightforwardly, is insufficient to embody the intrinsic structure of trajectories on the road network. To overcome the limitation, this study proposes multi-view trajectory representation that comprehensively interprets a trajectory from the segment-, link-, and intersection-views. To fulfill the purpose, we design a hierarchical self-attention network (HierETA) that accurately models the local traffic conditions and the underlying trajectory structure. Specifically, a segment encoder is developed to capture the spatio-temporal dependencies at a fine granularity, within which an adaptive self-attention module is designed to boost performance. Further, a joint link-intersection encoder is developed to characterize the natural trajectory structure consisting of alternatively arranged links and intersections. Afterward, a hierarchy-aware attention decoder is designed to realize a tradeoff between the multi-view spatio-temporal features. The hierarchical encoders and the attentive decoder are simultaneously learned to achieve an overall optimality. Experiments on two large-scale practical datasets show the superiority of HierETA over the state-of-the-arts.|到达时间估计是智能交通系统中的关键任务。尽管已有大量研究致力于解决该问题，但多数方法将轨迹分解为若干路段，通过整合所有路段的属性来计算行程时间。这种路段视角虽能直观反映局部交通状况，却难以体现路网轨迹的内在结构特征。为突破这一局限，本研究提出多视角轨迹表征方法，从路段、连接线和交叉口三个维度综合解析轨迹。基于此，我们设计了分层自注意力网络（HierETA），精准建模局部交通状况与深层轨迹结构。具体而言：开发路段编码器以细粒度捕捉时空依赖性，其中创新性引入自适应自注意力模块以提升性能；构建联合连接线-交叉口编码器，表征由连接线与交叉口交替构成的天然轨迹结构；设计层次感知注意力解码器，实现多视角时空特征的动态权衡。通过同步优化分层编码器与注意力解码器，实现整体性能最优。在两个大规模真实数据集上的实验表明，HierETA显著优于现有最优方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interpreting+Trajectories+from+Multiple+Views:+A+Hierarchical+Self-Attention+Network+for+Estimating+the+Time+of+Arrival)|2|
|[Causal Inference-Based Root Cause Analysis for Online Service Systems with Intervention Recognition](https://doi.org/10.1145/3534678.3539041)|Mingjie Li, Zeyan Li, Kanglin Yin, Xiaohui Nie, Wenchi Zhang, Kaixin Sui, Dan Pei|BizSeer, Beijing, Peoples R China; Tsinghua Univ, Beijing, Peoples R China|Fault diagnosis is critical in many domains, as faults may lead to safety threats or economic losses. In the field of online service systems, operators rely on enormous monitoring data to detect and mitigate failures. Quickly recognizing a small set of root cause indicators for the underlying fault can save much time for failure mitigation. In this paper, we formulate the root cause analysis problem as a new causal inference task namedintervention recognition. We proposed a novel unsupervised causal inference-based method namedCausal Inference-based Root Cause Analysis (CIRCA). The core idea is a sufficient condition for a monitoring variable to be a root cause indicator,i.e., the change of probability distribution conditioned on the parents in the Causal Bayesian Network (CBN). Towards the application in online service systems, CIRCA constructs a graph among monitoring metrics based on the knowledge of system architecture and a set of causal assumptions. The simulation study illustrates the theoretical reliability of CIRCA. The performance on a real-world dataset further shows that CIRCA can improve the recall of the top-1 recommendation by 25% over the best baseline method.|故障诊断在诸多领域至关重要，因为故障可能导致安全威胁或经济损失。在线服务系统领域中，运维人员依赖海量监控数据来检测并缓解故障。快速识别出底层故障的核心根因指标能为故障排除节省大量时间。本文将根因分析问题构建为一种名为"干预识别"的新型因果推理任务，提出了一种基于因果推理的无监督创新方法——基于因果推理的根因分析法（CIRCA）。其核心思想是判定监控变量成为根因指标的充分条件：即以因果贝叶斯网络（CBN）中父节点为条件时概率分布发生的变化。针对在线服务系统的应用场景，CIRCA基于系统架构知识和一系列因果假设构建监控指标关系图。仿真研究验证了CIRCA的理论可靠性，在真实数据集上的性能表现进一步表明：相较于最佳基线方法，CIRCA能将Top-1推荐的召回率提升25%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causal+Inference-Based+Root+Cause+Analysis+for+Online+Service+Systems+with+Intervention+Recognition)|2|
|[RES: A Robust Framework for Guiding Visual Explanation](https://doi.org/10.1145/3534678.3539419)|Yuyang Gao, Tong Steven Sun, Guangji Bai, Siyi Gu, Sungsoo Ray Hong, Liang Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RES:+A+Robust+Framework+for+Guiding+Visual+Explanation)|2|
|[ProActive: Self-Attentive Temporal Point Process Flows for Activity Sequences](https://doi.org/10.1145/3534678.3539477)|Vinayak Gupta, Srikanta Bedathur||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ProActive:+Self-Attentive+Temporal+Point+Process+Flows+for+Activity+Sequences)|2|
|[Communication-Efficient Robust Federated Learning with Noisy Labels](https://doi.org/10.1145/3534678.3539328)|Junyi Li, Jian Pei, Heng Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Communication-Efficient+Robust+Federated+Learning+with+Noisy+Labels)|2|
|[Reliable Representations Make A Stronger Defender: Unsupervised Structure Refinement for Robust GNN](https://doi.org/10.1145/3534678.3539484)|Kuan Li, Yang Liu, Xiang Ao, Jianfeng Chi, Jinghua Feng, Hao Yang, Qing He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reliable+Representations+Make+A+Stronger+Defender:+Unsupervised+Structure+Refinement+for+Robust+GNN)|2|
|[Mask and Reason: Pre-Training Knowledge Graph Transformers for Complex Logical Queries](https://doi.org/10.1145/3534678.3539472)|Xiao Liu, Shiyu Zhao, Kai Su, Yukuo Cen, Jiezhong Qiu, Mengdi Zhang, Wei Wu, Yuxiao Dong, Jie Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mask+and+Reason:+Pre-Training+Knowledge+Graph+Transformers+for+Complex+Logical+Queries)|2|
|[Learning on Graphs with Out-of-Distribution Nodes](https://doi.org/10.1145/3534678.3539457)|Yu Song, Donglin Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+on+Graphs+with+Out-of-Distribution+Nodes)|2|
|[Causal Attention for Interpretable and Generalizable Graph Classification](https://doi.org/10.1145/3534678.3539366)|Yongduo Sui, Xiang Wang, Jiancan Wu, Min Lin, Xiangnan He, TatSeng Chua||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causal+Attention+for+Interpretable+and+Generalizable+Graph+Classification)|2|
|[Graph Neural Networks with Node-wise Architecture](https://doi.org/10.1145/3534678.3539387)|Zhen Wang, Zhewei Wei, Yaliang Li, Weirui Kuang, Bolin Ding||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Neural+Networks+with+Node-wise+Architecture)|2|
|[CLARE: A Semi-supervised Community Detection Algorithm](https://doi.org/10.1145/3534678.3539370)|Xixi Wu, Yun Xiong, Yao Zhang, Yizhu Jiao, Caihua Shan, Yiheng Sun, Yangyong Zhu, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CLARE:+A+Semi-supervised+Community+Detection+Algorithm)|2|
|[Learning the Evolutionary and Multi-scale Graph Structure for Multivariate Time Series Forecasting](https://doi.org/10.1145/3534678.3539274)|Junchen Ye, Zihan Liu, Bowen Du, Leilei Sun, Weimiao Li, Yanjie Fu, Hui Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+the+Evolutionary+and+Multi-scale+Graph+Structure+for+Multivariate+Time+Series+Forecasting)|2|
|[M3Care: Learning with Missing Modalities in Multimodal Healthcare Data](https://doi.org/10.1145/3534678.3539388)|Chaohe Zhang, Xu Chu, Liantao Ma, Yinghao Zhu, Yasha Wang, Jiangtao Wang, Junfeng Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=M3Care:+Learning+with+Missing+Modalities+in+Multimodal+Healthcare+Data)|2|
|[SAMCNet: Towards a Spatially Explainable AI Approach for Classifying MxIF Oncology Data](https://doi.org/10.1145/3534678.3539168)|Majid Farhadloo, Carl Molnar, Gaoxiang Luo, Yan Li, Shashi Shekhar, Rachel L. Maus, Svetomir N. Markovic, Alexey A. Leontovich, Raymond Moore||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SAMCNet:+Towards+a+Spatially+Explainable+AI+Approach+for+Classifying+MxIF+Oncology+Data)|2|
|[No One Left Behind: Inclusive Federated Learning over Heterogeneous Devices](https://doi.org/10.1145/3534678.3539086)|Ruixuan Liu, Fangzhao Wu, Chuhan Wu, Yanlin Wang, Lingjuan Lyu, Hong Chen, Xing Xie||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=No+One+Left+Behind:+Inclusive+Federated+Learning+over+Heterogeneous+Devices)|2|
|[What Makes Good Contrastive Learning on Small-Scale Wearable-based Tasks?](https://doi.org/10.1145/3534678.3539134)|Hangwei Qian, Tian Tian, Chunyan Miao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=What+Makes+Good+Contrastive+Learning+on+Small-Scale+Wearable-based+Tasks?)|2|
|[Shallow and Deep Non-IID Learning on Complex Data](https://doi.org/10.1145/3534678.3542605)|Longbing Cao, Philip S. Yu, Zhilin Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Shallow+and+Deep+Non-IID+Learning+on+Complex+Data)|2|
|[Gradual AutoML using Lale](https://doi.org/10.1145/3534678.3542630)|Martin Hirzel, Kiran Kate, Parikshit Ram, Avraham Shinnar, Jason Tsay||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Gradual+AutoML+using+Lale)|2|
|[Robust Time Series Analysis and Applications: An Industrial Perspective](https://doi.org/10.1145/3534678.3542612)|Qingsong Wen, Linxiao Yang, Tian Zhou, Liang Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Time+Series+Analysis+and+Applications:+An+Industrial+Perspective)|2|
|[PECOS: Prediction for Enormous and Correlated Output Spaces](https://doi.org/10.1145/3534678.3542629)|HsiangFu Yu, Jiong Zhang, WeiCheng Chang, JyunYu Jiang, Wei Li, ChoJui Hsieh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PECOS:+Prediction+for+Enormous+and+Correlated+Output+Spaces)|2|
|[Extracting Relevant Information from User's Utterances in Conversational Search and Recommendation](https://doi.org/10.1145/3534678.3539471)|Ali Montazeralghaem, James Allan|University of Massachusetts Amherst, Amherst, MA, USA|Conversational search and recommendation systems can ask clarifying questions through the conversation and collect valuable information from users. However, an important question remains: how can we extract relevant information from the user's utterances and use it in the retrieval or recommendation in the next turn of the conversation? Utilizing relevant information from users' utterances leads the system to better results at the end of the conversation. In this paper, we propose a model based on reinforcement learning, namely RelInCo, which takes the user's utterances and the context of the conversation and classifies each word in the user's utterances as belonging to the relevant or non-relevant class. RelInCo uses two Actors: 1) Arrangement-Actor, which finds the most relevant order of words in user's utterances, and 2) Selector-Actor, which determines which words, in the order provided by the arrangement Actor, can bring the system closer to the target of the conversation. In this way, we can find relevant information in the user's utterance and use it in the conversation. The objective function in our model is designed in such a way that it can maximize any desired retrieval and recommendation metrics (i.e., the ultimate|会话搜索和推荐系统可以通过会话提出澄清问题，并从用户那里收集有价值的信息。然而，一个重要的问题仍然存在: 我们如何从用户的话语中提取相关信息，并将其用于下一轮对话中的检索或推荐？利用用户话语中的相关信息，可以使系统在对话结束时获得更好的结果。在本文中，我们提出了一个基于强化学习的模型，即 RelinCo，该模型根据用户的话语和对话的上下文，将用户话语中的每个单词归类为相关或非相关类别。RelInCo 使用了两个参与者: 1)安排-参与者，它找到用户话语中最相关的词语顺序; 2)选择-参与者，它根据安排-参与者提供的顺序决定哪些词语可以使系统更接近对话的目标。通过这种方式，我们可以在用户的话语中找到相关信息，并在对话中加以利用。我们模型中的目标函数是这样设计的，它可以最大化任何所需的检索和推荐指标(即，最终的|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Extracting+Relevant+Information+from+User's+Utterances+in+Conversational+Search+and+Recommendation)|1|
|[Uni-Retriever: Towards Learning the Unified Embedding Based Retriever in Bing Sponsored Search](https://doi.org/10.1145/3534678.3539212)|Jianjin Zhang, Zheng Liu, Weihao Han, Shitao Xiao, Ruicheng Zheng, Yingxia Shao, Hao Sun, Hanqing Zhu, Premkumar Srinivasan, Weiwei Deng, Qi Zhang, Xing Xie|Microsoft, Newark, NJ, USA; Microsoft, Seattle, DC, USA; Beijing University of Posts and Telecommunications, Beijing, China; Microsoft, Beijing, China|Embedding based retrieval (EBR) is a fundamental building block in many web applications. However, EBR in sponsored search is distinguished from other generic scenarios and technically challenging due to the need of serving multiple retrieval purposes: firstly, it has to retrieve high-relevance ads, which may exactly serve user's search intent; secondly, it needs to retrieve high-CTR ads so as to maximize the overall user clicks. In this paper, we present a novel representation learning framework Uni-Retriever developed for Bing Search, which unifies two different training modes knowledge distillation and contrastive learning to realize both required objectives. On one hand, the capability of making high-relevance retrieval is established by distilling knowledge from the "relevance teacher model''. On the other hand, the capability of making high-CTR retrieval is optimized by learning to discriminate user's clicked ads from the entire corpus. The two training modes are jointly performed as a multi-objective learning process, such that the ads of high relevance and CTR can be favored by the generated embeddings. Besides the learning strategy, we also elaborate our solution for EBR serving pipeline built upon the substantially optimized DiskANN, where massive-scale EBR can be performed with competitive time and memory efficiency, and accomplished in high-quality. We make comprehensive offline and online experiments to evaluate the proposed techniques, whose findings may provide useful insights for the future development of EBR systems. Uni-Retriever has been mainstreamed as the major retrieval path in Bing's production thanks to the notable improvements on the representation and EBR serving quality.|嵌入式基于检索(EBR)是许多 Web 应用程序的基础构件。然而，由于需要服务于多种检索目的，赞助商搜索中的 EBR 不同于其他一般情况，在技术上具有挑战性: 首先，它必须检索高相关度的广告，这可能恰好服务于用户的搜索意图; 其次，它需要检索高点击率的广告，以最大限度地提高用户的总体点击率。本文提出了一种新的面向 Bing 搜索的 Uni-Retriever 表示学习框架，该框架将两种不同的训练模式知识提取和对比学习相结合，实现了两种不同的目标。一方面，从“关联教师模型”中提取知识，建立高关联检索能力;。另一方面，通过学习从整个语料库中区分用户点击广告，优化了高点击率检索的能力。这两种训练模式作为一个多目标学习过程共同执行，使得嵌入生成的广告更有利于高关联度和点击率的广告。除了学习策略，我们还详细阐述了我们的解决方案，EBR 服务流水线的基础上大幅度优化的 DiskANN，其中大规模的 EBR 可以执行竞争时间和内存效率，并完成在高质量。我们进行了全面的离线和在线实验来评估所提出的技术，其结果可能为未来 EBR 系统的发展提供有用的见解。统一检索已成为主流的检索路径在必应的生产显着改善的表示和 EBR 服务质量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Uni-Retriever:+Towards+Learning+the+Unified+Embedding+Based+Retriever+in+Bing+Sponsored+Search)|1|
|[An Online Multi-task Learning Framework for Google Feed Ads Auction Models](https://doi.org/10.1145/3534678.3539055)|Ning Ma, Mustafa Ispir, Yuan Li, Yongpeng Yang, Zhe Chen, Derek Zhiyuan Cheng, Lan Nie, Kishor Barman|Google Inc., Mountain View, CA, USA|In this paper, we introduce a large scale online multi-task deep learning framework for modeling multiple feed ads auction prediction tasks on an industry-scale feed ads recommendation platform. Multiple prediction tasks are combined into one single model which is continuously trained on real time new ads data. Multi-tasking ads auction models in real-time faces many real-world challenges. For example, each task may be trained on different set of training data; the labels of different tasks may have different arrival time due to label delay; different tasks will interact with each other; combining the losses of each task is non-trivial. We tackle these challenges using practical and novel techniques such as multi-stage training for handling label delay, Multi-gate Mixture-of-Experts (MMoE) to optimize model interaction and an auto-parameter learning algorithm to optimize the loss weights of different tasks. We demonstrate that our proposed techniques can lead to quality improvements and substantial resource saving compared to modeling each single task independently.|本文介绍了一个大规模的在线多任务深度学习框架，在一个行业规模的推荐平台上对多种推广广告拍卖预测任务进行建模。将多个预测任务组合成一个单独的模型，对实时的新广告数据进行连续的训练。实时多任务广告拍卖模型在现实生活中面临着许多挑战。例如，每个任务可以在不同的训练数据集上进行训练; 由于标签延迟，不同任务的标签可能有不同的到达时间; 不同的任务将相互作用;。针对这些问题，我们采用了多阶段训练来处理标签延迟，多门专家混合(MMoE)来优化模型交互，以及自动参数学习算法来优化不同任务的损失权重。我们证明，与独立建模每个单独的任务相比，我们提出的技术可以导致质量改进和大量资源节省。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Online+Multi-task+Learning+Framework+for+Google+Feed+Ads+Auction+Models)|1|
|[NxtPost: User To Post Recommendations In Facebook Groups](https://doi.org/10.1145/3534678.3539042)|Kaushik Rangadurai, Yiqun Liu, Siddarth Malreddy, Xiaoyi Liu, Piyush Maheshwari, Vishwanath Sangale, Fedor Borisyuk|Meta Platforms Inc., Menlo Park, CA, USA|In this paper, we present NxtPost, a deployed user-to-post content based sequential recommender system for Facebook Groups. Inspired by recent advances in NLP, we have adapted a Transformer based model to the domain of sequential recommendation. We explore causal masked multi-head attention that optimizes both short and long-term user interests. From a user's past activities validated by defined safety process, NxtPost seeks to learn a representation for the user's dynamic content preference and to predict the next post user may be interested in. In contrast to previous Transformer based methods, we do not assume that the recommendable posts have a fixed corpus. Accordingly, we use an external item/token embedding to extend a sequence-based approach to a large vocabulary. We achieve 49% abs. improvement in offline evaluation. As a result of NxtPost deployment, 0.6% more users are meeting new people, engaging with the community, sharing knowledge and getting support. The paper shares our experience in developing a personalized sequential recommender system, lessons deploying the model for cold start users, how to deal with freshness, and tuning strategies to reach higher efficiency in online A/B experiments.|在本文中，我们介绍了 NxtPost，这是一个为 Facebook group 部署的基于用户到发布内容的顺序推荐系统。受自然语言处理最新进展的启发，我们将一个基于 Transform- 的模型应用于顺序推荐领域。我们探索因果掩盖多头注意，优化短期和长期用户的兴趣。通过定义的安全过程验证用户过去的活动，NxtPost 试图学习用户动态内容偏好的表示，并预测下一个帖子用户可能感兴趣的内容。与以前基于 former 的方法相比，我们不假定推荐的帖子具有固定的语料库。因此，我们使用外部项/令牌嵌入来将基于序列的方法扩展到大型词汇表。我们有49% 的腹肌。离线评估的改进。作为 NxtPost 部署的结果，0.6% 的用户正在结识新朋友，参与社区活动，分享知识并获得支持。本文分享了我们在开发个性化连续推荐系统的经验、为冷启动用户部署模型的教训、如何处理新鲜感，以及在线 A/B 实验中为提高效率而调整策略的经验。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NxtPost:+User+To+Post+Recommendations+In+Facebook+Groups)|1|
|[ReprBERT: Distilling BERT to an Efficient Representation-Based Relevance Model for E-Commerce](https://doi.org/10.1145/3534678.3539090)|Shaowei Yao, Jiwei Tan, Xi Chen, Juhao Zhang, Xiaoyi Zeng, Keping Yang|Alibaba Group, Hangzhou, China|Text relevance or text matching of query and product is an essential technique for e-commerce search engine, which helps users find the desirable products and is also crucial to ensuring user experience. A major difficulty for e-commerce text relevance is the severe vocabulary gap between query and product. Recently, neural networks have been the mainstream for the text matching task owing to the better performance for semantic matching. Practical e-commerce relevance models are usually representation-based architecture, which can pre-compute representations offline and are therefore online efficient. Interaction-based models, although can achieve better performance, are mostly time-consuming and hard to be deployed online. Recently BERT has achieved significant progress on many NLP tasks including text matching, and it is of great value but also big challenge to deploy BERT to the e-commerce relevance task. To realize this goal, we propose ReprBERT, which has the advantages of both excellent performance and low latency, by distilling the interaction-based BERT model to a representation-based architecture. To reduce the performance decline, we investigate the key reasons and propose two novel interaction strategies to resolve the absence of representation interaction and low-level semantic interaction. Finally, ReprBERT can achieve only about 1.5% AUC loss from the interaction-based BERT, but has more than 10% AUC improvement compared to previous state-of-the-art representation-based models. ReprBERT has already been deployed on the search engine of Taobao and serving the entire search traffic, achieving significant gain of user experience and business profit.|查询和产品的文本相关性或文本匹配是电子商务搜索引擎的关键技术，它可以帮助用户找到想要的产品，也是保证用户体验的关键。电子商务文本相关性的一个主要困难是查询和产品之间严重的词汇差距。近年来，神经网络以其较好的语义匹配性能成为文本匹配的主流。实用的电子商务相关性模型通常是基于表示的体系结构，它可以离线预先计算表示，因此具有在线效率。基于交互的模型，尽管可以获得更好的性能，但是大部分都是耗时的，并且很难在线部署。近年来，BERT 在包括文本匹配在内的许多自然语言处理任务中取得了显著的进展，将 BERT 部署到电子商务相关任务中具有很大的价值，但也面临很大的挑战。为了实现这一目标，我们提出了 ReprBERT，它具有良好的性能和低延迟的优点，通过提炼基于交互的 BERT 模型到一个基于表示的体系结构。为了减少表征交互和低层次语义交互的缺失，本文研究了表征交互和低层次语义交互的关键原因，并提出了两种新的交互策略来解决表征交互和低层次语义交互的缺失问题。最后，ReprBERT 只能从基于交互的 BERT 中获得约1.5% 的 AUC 损失，但与以前的基于最先进表示的模型相比，具有超过10% 的 AUC 改善。ReprBERT 已经部署在淘宝的搜索引擎上，服务于整个搜索流量，取得了显著的用户体验和商业利润收益。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ReprBERT:+Distilling+BERT+to+an+Efficient+Representation-Based+Relevance+Model+for+E-Commerce)|1|
|[Learning Supplementary NLP Features for CTR Prediction in Sponsored Search](https://doi.org/10.1145/3534678.3539064)|Dong Wang, Shaoguang Yan, Yunqing Xia, Kavé Salamatian, Weiwei Deng, Qi Zhang|Microsoft Corporation, Beijing, China; University of Savoie & Tallinn University of Technology, Annecy, France|In sponsored search engines, pre-trained language models have shown promising performance improvements on Click-Through-Rate (CTR) prediction. A widely used approach for utilizing pre-trained language models in CTR prediction consists of fine-tuning the language models with click labels and early stopping on peak value of the obtained Area Under the ROC Curve (AUC). Thereafter the output of these fine-tuned models, i.e., the final score or intermediate embedding generated by language model, is used as a new Natural Language Processing (NLP) feature into CTR prediction baseline. This cascade approach avoids complicating the CTR prediction baseline, while keeping flexibility and agility. However, we show in this work that calibrating separately the language model based on the peak single model AUC does not always yield NLP features that give the best performance in CTR prediction model ultimately. Our analysis reveals that the misalignment is due to overlap and redundancy between the new NLP features and the existing features in CTR prediction baseline. In other words, the NLP features can improve CTR prediction better if such overlap can be reduced. For this purpose, we introduce a simple and general joint-training framework for fine-tuning of language models, combined with the already existing features in CTR prediction baseline, to extract supplementary knowledge for NLP feature. Moreover, we develop an efficient Supplementary Knowledge Distillation (SuKD) that transfers the supplementary knowledge learned by a heavy language model to a light and serviceable model. Comprehensive experiments on both public data and commercial data presented in this work demonstrate that the new NLP features resulting from the joint-training framework can outperform significantly the ones from the independent fine-tuning based on click labels. we also show that the light model distilled with SuKD can provide obvious AUC improvement in CTR prediction over the traditional feature-based knowledge distillation.|在赞助商搜索引擎中，预先训练好的语言模型在点击率(Click-Through-Rate，CTR)预测方面显示出有希望的性能改进。一个广泛使用的方法，利用预先训练的语言模型在点击率预测包括微调的语言模型与点击标签和早期停止在 ROC 曲线下面积(AUC)峰值获得。然后，这些微调模型的输出，即语言模型生成的最终分数或中间嵌入，被用作 CTR 预测基线的一个新的自然语言处理(NLP)特征。这种级联方法避免了使 CTR 预测基线复杂化，同时保持了灵活性和敏捷性。然而，我们的工作表明，基于峰值单模型 AUC 分别标定语言模型并不总是产生 NLP 特征，最终给出 CTR 预测模型的最佳性能。我们的分析表明，失调是由于重叠和冗余之间的新 NLP 特征和现有的特征在 CTR 预测基线。换句话说，如果能够减少这种重叠，NLP 特征能够更好地提高 CTR 预测。为此，本文提出了一种简单通用的语言模型微调联合训练框架，结合 CTR 预测基线中已有的特征，提取 NLP 特征的补充知识。此外，我们开发了一个有效的补充知识提取(SuKD) ，将重语言模型所学到的补充知识转化为一个简单易用的模型。对公共数据和商业数据的综合实验表明，联合训练框架所产生的新的自然语言处理特征可以显著优于基于点击标签的独立微调。与传统的基于特征的知识提取方法相比，用 SuKD 提取的光模型在 CTR 预测方面可以提供明显的 AUC 改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Supplementary+NLP+Features+for+CTR+Prediction+in+Sponsored+Search)|1|
|[AutoShard: Automated Embedding Table Sharding for Recommender Systems](https://doi.org/10.1145/3534678.3539034)|Daochen Zha, Louis Feng, Bhargav Bhushanam, Dhruv Choudhary, Jade Nie, Yuandong Tian, Jay Chae, Yinbin Ma, Arun Kejariwal, Xia Hu|Meta Platforms, Inc., Menlo Park, CA, USA; Rice University, Houston, TX, USA|Embedding learning is an important technique in deep recommendation models to map categorical features to dense vectors. However, the embedding tables often demand an extremely large number of parameters, which become the storage and efficiency bottlenecks. Distributed training solutions have been adopted to partition the embedding tables into multiple devices. However, the embedding tables can easily lead to imbalances if not carefully partitioned. This is a significant design challenge of distributed systems named embedding table sharding, i.e., how we should partition the embedding tables to balance the costs across devices, which is a non-trivial task because 1) it is hard to efficiently and precisely measure the cost, and 2) the partition problem is known to be NP-hard. In this work, we introduce our novel practice in Meta, namely AutoShard, which uses a neural cost model to directly predict the multi-table costs and leverages deep reinforcement learning to solve the partition problem. Experimental results on an open-sourced large-scale synthetic dataset and Meta's production dataset demonstrate the superiority of AutoShard over the heuristics. Moreover, the learned policy of AutoShard can transfer to sharding tasks with various numbers of tables and different ratios of the unseen tables without any fine-tuning. Furthermore, AutoShard can efficiently shard hundreds of tables in seconds. The effectiveness, transferability, and efficiency of AutoShard make it desirable for production use. Our algorithms have been deployed in Meta production environment. A prototype is available at https://github.com/daochenzha/autoshard|嵌入式学习是深度推荐模型中将分类特征映射到密集向量的一项重要技术。然而，嵌入式表往往需要大量的参数，成为存储和效率的瓶颈。采用分布式训练解决方案将嵌入表划分为多个设备。然而，如果不仔细分区，嵌入表很容易导致不平衡。这是分布式系统嵌入表分片的一个重大设计挑战，即我们应该如何划分嵌入表来平衡设备之间的成本，这是一个非常重要的任务，因为1)很难有效和精确地度量成本，2)划分问题是已知的 NP 难题。在这项工作中，我们介绍了我们在 Meta 中的新实践，即 AutoShard，它使用一个神经成本模型来直接预测多表成本，并利用深度强化学习来解决分区问题。在一个开源的大规模合成数据集和 Meta 生产数据集上的实验结果证明了 AutoShard 相对于启发式算法的优越性。此外，AutoShard 的学习策略可以转换为使用不同数量的表和看不见的表的不同比例的分片任务，而不需要进行任何微调。此外，AutoShard 可以在几秒钟内高效地切分数百个表。AutoShard 的有效性、可转移性和效率使其适合生产使用。我们的算法已经部署在元生产环境中。Https://github.com/daochenzha/autoshard 上有一个原型|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AutoShard:+Automated+Embedding+Table+Sharding+for+Recommender+Systems)|1|
|[On-Device Learning for Model Personalization with Large-Scale Cloud-Coordinated Domain Adaption](https://doi.org/10.1145/3534678.3539263)|Yikai Yan, Chaoyue Niu, Renjie Gu, Fan Wu, Shaojie Tang, Lifeng Hua, Chengfei Lyu, Guihai Chen|University of Texas at Dallas, Richardson, TX, USA; Shanghai Jiao Tong University, Shanghai, China; Alibaba Group, Hangzhou, China|Cloud-based learning is currently the mainstream in both academia and industry. However, the global data distribution, as a mixture of all the users' data distributions, for training a global model may deviate from each user's local distribution for inference, making the global model non-optimal for each individual user. To mitigate distribution discrepancy, on-device training over local data for model personalization is a potential solution, but suffers from serious overfitting. In this work, we propose a new device-cloud collaborative learning framework under the paradigm of domain adaption, called MPDA, to break the dilemmas of purely cloud-based learning and on-device training. From the perspective of a certain user, the general idea of MPDA is to retrieve some similar data from the cloud's global pool, which functions as large-scale source domains, to augment the user's local data as the target domain. The key principle of choosing which outside data depends on whether the model trained over these data can generalize well over the local data. We theoretically analyze that MPDA can reduce distribution discrepancy and overfitting risk. We also extensively evaluate over the public MovieLens 20M and Amazon Electronics datasets, as well as an industrial dataset collected from Mobile Taobao over a period of 30 days. We finally build a device-tunnel-cloud system pipeline, deploy MPDA in the icon area of Mobile Taobao for click-through rate prediction, and conduct online A/B testing. Both offline and online results demonstrate that MPDA outperforms the baselines of cloud-based learning and on-device training only over local data, from multiple offline and online metrics.|基于云的学习是目前学术界和工业界的主流。然而，全局数据分布作为所有用户数据分布的混合，用于训练全局模型可能偏离每个用户的局部分布进行推理，使得全局模型对于每个用户不是最优的。为了缓解分布差异，对模型个性化的本地数据进行设备上的训练是一个潜在的解决方案，但是存在严重的过拟合问题。在这项工作中，我们提出了一个新的设备-云计算合作学习框架，在领域适应的范例下称为 MPDA，以打破纯粹基于云的学习和设备上培训的困境。从某个用户的角度来看，MPDA 的总体思想是从作为大规模源域的云的全局池中检索一些类似的数据，以增加用户的本地数据作为目标域。选择哪些外部数据的关键原则取决于对这些数据进行训练的模型是否能够比本地数据更好地推广。从理论上分析了 MPDA 可以降低分布差异和过拟合风险。我们还广泛评估了公开的 MovieLens 20M 和亚马逊电子数据集，以及在30天内从移动淘宝收集的工业数据集。最后，我们建立了设备-隧道-云系统流水线，在移动淘宝的图标区域部署 MPDA 进行点进率预测，并进行在线 A/B 测试。离线和在线结果都表明，MPDA 仅在多个离线和在线指标的本地数据上优于基于云的学习和设备上培训的基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On-Device+Learning+for+Model+Personalization+with+Large-Scale+Cloud-Coordinated+Domain+Adaption)|1|
|[Debiasing Learning for Membership Inference Attacks Against Recommender Systems](https://doi.org/10.1145/3534678.3539392)|Zihan Wang, Na Huang, Fei Sun, Pengjie Ren, Zhumin Chen, Hengliang Luo, Maarten de Rijke, Zhaochun Ren|Meituan, Beijing, China; University of Amsterdam, Amsterdam, Netherlands; Alibaba Group, Beijing, China; Shandong University, Qingdao, China|Learned recommender systems may inadvertently leak information about their training data, leading to privacy violations. We investigate privacy threats faced by recommender systems through the lens of membership inference. In such attacks, an adversary aims to infer whether a user's data is used to train the target recommender. To achieve this, previous work has used a shadow recommender to derive training data for the attack model, and then predicts the membership by calculating difference vectors between users' historical interactions and recommended items. State-of-the-art methods face two challenging problems: (i) training data for the attack model is biased due to the gap between shadow and target recommenders, and (ii) hidden states in recommenders are not observational, resulting in inaccurate estimations of difference vectors. To address the above limitations, we propose a Debiasing Learning for Membership Inference Attacks against recommender systems (DL-MIA) framework that has four main components: (i) a difference vector generator, (ii) a disentangled encoder, (iii) a weight estimator, and (iv) an attack model. To mitigate the gap between recommenders, a variational auto-encoder (VAE) based disentangled encoder is devised to identify recommender invariant and specific features. To reduce the estimation bias, we design a weight estimator, assigning a truth-level score for each difference vector to indicate estimation accuracy. We evaluate DL-MIA against both general recommenders and sequential recommenders on three real-world datasets. Experimental results show that DL-MIA effectively alleviates training and estimation biases simultaneously, and Íachieves state-of-the-art attack performance.|经验丰富的推荐系统可能无意中泄露有关其培训数据的信息，从而导致侵犯隐私。我们通过成员推理的视角来研究推荐系统所面临的隐私威胁。在这种攻击中，对手的目的是推断用户的数据是否被用来训练目标推荐器。为了实现这一目标，以前的工作是使用阴影推荐来获取攻击模型的训练数据，然后通过计算用户历史交互和推荐项目之间的差异向量来预测成员关系。最先进的方法面临两个具有挑战性的问题: (i)攻击模型的训练数据由于阴影和目标推荐器之间的差距而有偏差，以及(ii)推荐器中的隐藏状态不是观察性的，导致差异向量的估计不准确。为了解决上述局限性，我们提出了针对推荐系统(DL-MIA)的成员推断攻击的去偏学习框架，其具有四个主要组成部分: (i)差分矢量生成器，(ii)分离编码器，(iii)权重估计器和(iv)攻击模型。为了缩小推荐器之间的差距，设计了一种基于变分自动编码器(VAE)的解纠缠编码器来识别推荐器的不变性和特定特征。为了减少估计偏差，我们设计了一个权重估计器，为每个差异向量指定一个真值水平分数来表示估计的准确性。我们在三个真实世界的数据集上评估 DL-MIA 与通用推荐和顺序推荐的对比。实验结果表明，DL-MIA 同时有效地减小了训练偏差和估计偏差，并取得了一流的攻击性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Debiasing+Learning+for+Membership+Inference+Attacks+Against+Recommender+Systems)|1|
|[Automatic Generation of Product-Image Sequence in E-commerce](https://doi.org/10.1145/3534678.3539149)|Xiaochuan Fan, Chi Zhang, Yong Yang, Yue Shang, Xueying Zhang, Zhen He, Yun Xiao, Bo Long, Lingfei Wu|JD.COM Research, Mountain View, CA, USA; JD.COM, Beijing, UNK, China|Product images are essential for providing desirable user experience in an e-commerce platform. For a platform with billions of products, it is extremely time-costly and labor-expensive to manually pick and organize qualified images. Furthermore, there are the numerous and complicated image rules that a product image needs to comply in order to be generated/selected. To address these challenges, in this paper, we present a new learning framework in order to achieve Automatic Generation of Product-Image Sequence (AGPIS) in e-commerce. To this end, we propose a Multi-modality Unified Image-sequence Classifier (MUIsC), which is able to simultaneously detect all categories of rule violations through learning. MUIsC leverages textual review feedback as the additional training target and utilizes product textual description to provide extra semantic information. %Without using prior knowledge or manually-crafted task, a single MUIsC model is able to learn the holistic knowledge of image reviewing and detect all categories of rule violations simultaneously. Based on offline evaluations, we show that the proposed MUIsC significantly outperforms various baselines. Besides MUIsC, we also integrate some other important modules in the proposed framework, such as primary image selection, non-compliant content detection, and image deduplication. With all these modules, our framework works effectively and efficiently in JD.com recommendation platform. By Dec 2021, our AGPIS framework has generated high-standard images for about 1.5 million products and achieves 13.6% in reject rate. Code of this work is available at https://github.com/efan3000/muisc.|在电子商务平台中，产品图像对于提供理想的用户体验至关重要。对于一个拥有数十亿产品的平台来说，手动挑选和组织合格的图像是非常耗费时间和人力的。此外，还有许多复杂的图像规则，产品图像需要遵守这些规则才能生成/选择。针对这些挑战，本文提出了一种新的学习框架，以实现电子商务中产品图像序列(AGPIS)的自动生成。为此，我们提出了一种多模态统一图像序列分类器(MUIsC) ，它能够通过学习同时检测所有类别的违规行为。MUisC 利用文本评论反馈作为额外的培训目标，并利用产品文本描述提供额外的语义信息。% 在不使用先前知识或手工制作任务的情况下，单一的 MUIsC 模型能够学习图像审查的整体知识，并同时发现所有类别的违规行为。基于离线评估，我们表明所提出的 MUIsC 明显优于各种基线。除了 MUIsC，我们还整合了一些其他的重要模块，如初始图像选择、不兼容的内容检测和图像去重。通过所有这些模块，我们的框架在 JD.com 推荐平台上高效地工作。到2021年12月，我们的 AGPIS 框架已经为大约150万个产品生成了高标准的图像，并且实现了13.6% 的拒绝率。这项工作的代码可在 https://github.com/efan3000/muisc 查阅。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automatic+Generation+of+Product-Image+Sequence+in+E-commerce)|1|
|[Semantic Retrieval at Walmart](https://doi.org/10.1145/3534678.3539164)|Alessandro Magnani, Feng Liu, Suthee Chaidaroon, Sachin Yadav, Praveen Reddy Suram, Ajit Puthenputhussery, Sijie Chen, Min Xie, Anirudh Kashi, Tony Lee, Ciya Liao|Univ Southern Calif, Los Angeles, CA USA; Walmart Global Technol, Bangalore, Karnataka, India; Instacart, San Francisco, CA USA; Santa Clara Univ, Santa Clara, CA USA; Walmart Global Technol, Sunnyvale, CA 94088 USA|In product search, the retrieval of candidate products before re-ranking is more mission critical and challenging than other search like web search, especially for tail queries, which have a complex and specific search intent. In this paper, we present a hybrid system for e-commerce search deployed at Walmart that combines traditional inverted index and embedding-based neural retrieval to better answer user tail queries. Our system significantly improved the relevance of the search engine, measured by both offline and online evaluations. The improvements were achieved through a combination of different approaches. We present a new technique to train the neural model at scale. and describe how the system was deployed in production with little impact on response time. We highlight multiple learnings and practical tricks that were used in the deployment of this system.|在产品搜索中，重新排序前的候选商品检索比网页搜索等其他搜索任务更具关键性和挑战性，尤其对于表达复杂特定搜索意图的长尾查询而言。本文提出一种部署于沃尔玛电商平台的混合检索系统，通过结合传统倒排索引与基于嵌入向量的神经检索，以更精准地响应用户长尾查询。该系统通过离线和在线评估均显著提升了搜索引擎的相关性。这些改进得益于多项方法的综合运用：我们提出了一种大规模训练神经模型的新技术，阐述了如何在几乎不影响响应时间的前提下实现生产环境部署，并重点分享了系统部署过程中积累的多项实践经验和实用技巧。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Semantic+Retrieval+at+Walmart)|1|
|[Training Large-Scale News Recommenders with Pretrained Language Models in the Loop](https://doi.org/10.1145/3534678.3539120)|Shitao Xiao, Zheng Liu, Yingxia Shao, Tao Di, Bhuvan Middha, Fangzhao Wu, Xing Xie|; Microsoft, Redmond, WA USA; Microsoft Res Asia, Beijing, Peoples R China; Beijing Univ Posts & Telecommun, Beijing, Peoples R China|News recommendation calls for deep insights of news articles' underlying semantics. Therefore, pretrained language models (PLMs), like BERT and RoBERTa, may substantially contribute to the recommendation quality. However, it's extremely challenging to have news recommenders trained together with such big models: the learning of news recommenders requires intensive news encoding operations, whose cost is prohibitive if PLMs are used as the news encoder. In this paper, we propose a novel framework, SpeedyFeed, which efficiently trains PLMs-based news recommenders of superior quality. SpeedyFeed is highlighted for its light-weight encoding pipeline, which gives rise to three major advantages. Firstly, it makes the intermediate results fully reusable for the training workflow, which removes most of the repetitive but redundant encoding operations. Secondly, it improves the data efficiency of the training workflow, where non-informative data can be eliminated from encoding. Thirdly, it further saves the cost by leveraging simplified news encoding and compact news representation. SpeedyFeed leads to more than 100x acceleration of the training process, which enables big models to be trained efficiently and effectively over massive user data. The well-trained PLMs-based model significantly outperforms the state-of-the-art news recommenders in comprehensive offline experiments. It is applied to Microsoft News to empower the training of large-scale production models, which demonstrate highly competitive online performances. SpeedyFeed is also a model-agnostic framework, thus being potentially applicable to a wide spectrum of content-based recommender systems. We've made the source code open to the public so as to facilitate research and applications in related areas.|新闻推荐任务要求深入理解新闻文本的底层语义。因此，预训练语言模型（如BERT和RoBERTa）可显著提升推荐质量。但将此类大型模型与新闻推荐系统联合训练面临巨大挑战：新闻推荐器的学习过程需要密集型新闻编码操作，若采用预训练模型作为新闻编码器，其计算成本将难以承受。本文提出创新框架SpeedyFeed，能够高效训练出基于预训练模型的优质新闻推荐系统。该框架的核心优势在于其轻量级编码管道，主要体现为三大突破：首先，实现中间结果在训练流程中的完全可复用性，消除了大部分重复冗余的编码操作；其次，通过剔除非信息性数据参与编码，显著提升训练流程的数据效率；第三，采用简化新闻编码和紧凑型新闻表征进一步降低成本。SpeedyFeed实现了训练过程超百倍加速，使得大型模型能基于海量用户数据实现高效训练。经全面离线实验验证，基于该框架训练的预训练模型显著优于现有最优新闻推荐系统。该技术已应用于微软新闻平台，支持大规模生产模型的训练，并展现出极具竞争力的在线性能。SpeedyFeed作为模型无关框架，未来可广泛应用于各类基于内容的推荐系统。我们已公开源代码以促进相关领域的研究与应用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Training+Large-Scale+News+Recommenders+with+Pretrained+Language+Models+in+the+Loop)|1|
|[DDR: Dialogue Based Doctor Recommendation for Online Medical Service](https://doi.org/10.1145/3534678.3539201)|Zhi Zheng, Zhaopeng Qiu, Hui Xiong, Xian Wu, Tong Xu, Enhong Chen, Xiangyu Zhao|City Univ Hong Kong, Hong Kong, Peoples R China; Univ Sci & Technol China, Sch Data Sci, Shenzhen, Peoples R China; Tencent Jarvis Lab, Shenzhen, Peoples R China; HKUST GZ, HKUST Shenzhen Hong Kong, Collaborat Innovat Res Inst, AIT, Hong Kong, Peoples R China|Online medical consultation, which enables patients to remotely inquire doctors in the form of web chatting, has become an indispensable part of the social health care system. Intuitively, it is a crucial step to recommend suitable doctor candidates for patients, especially with suffering the severe cold-start challenge of patients due to the limited historical records and insufficient description of patient condition. Along this line, in this paper, we propose a novel Dialogue based Doctor Recommendation (DDR) model, which comprehensively integrates three types of information in modeling, including the profile and chief complaint from patients, the historical records of doctors and the patient-doctor dialogue. Accordingly, we propose 1) a patient encoder which represents the patient's condition and medical requirements; 2) a doctor encoder which distills the doctor's expertise and communication skills; 3) a dialogue encoder which extracts textual features from doctor-patient conversation. Specifically, since the patient-doctor dialogue is not available in the testing stage, we propose to simulate the dialogue embedding with patient embedding via a contrastive learning based module. Experimental results on a real-world data set show that the proposed DDR model can outperform state-of-the-art recommendation-based methods. Moreover, considering the accessibility variance of online medical consultation services between the youth and the elderly, we also conduct a fairness study on the proposed DDR model.|在线医疗咨询作为社会医疗体系的重要组成部分，使患者能够通过网络聊天的形式远程问诊。在此过程中，如何为患者推荐合适的医生尤为关键——由于患者历史记录有限且病情描述不充分，该场景面临着严峻的冷启动挑战。为此，本文提出一种新颖的基于对话的医生推荐模型（DDR），该模型在建模过程中综合整合了三类信息：患者基本资料与主诉、医生历史记录以及医患对话记录。我们相应设计了：1）患者编码器，用于表征患者健康状况与医疗需求；2）医生编码器，用于提炼医生专业能力与沟通技巧；3）对话编码器，用于提取医患对话的文本特征。特别需要指出的是，由于测试阶段无法获取真实医患对话，我们创新性地通过基于对比学习的模块，利用患者嵌入向量来模拟对话嵌入向量。在真实数据集上的实验表明，所提出的DDR模型性能优于当前最先进的推荐方法。此外，针对线上医疗服务在青年与老年群体间的可及性差异，我们还对DDR模型进行了公平性研究。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DDR:+Dialogue+Based+Doctor+Recommendation+for+Online+Medical+Service)|1|
|[FedMSplit: Correlation-Adaptive Federated Multi-Task Learning across Multimodal Split Networks](https://doi.org/10.1145/3534678.3539384)|Jiayi Chen, Aidong Zhang|Univ Virginia, Charlottesville, VA 22903 USA|With the advancement of data collection techniques, end users are interested in how different types of data can collaborate to improve our life experiences. Multimodal Federated Learning (MFL) is an emerging area allowing many distributed clients, each of which can collect data from multiple types of sensors, to participate in the training of some multimodal data-related models without sharing their data. In this paper, we address a novel challenging issue in MFL, the modality incongruity, where clients may have heterogeneous setups of sensors and their local data consists of different combinations of modalities. With the modality incongruity, clients may solve different tasks on different parameter spaces, which escalates the difficulties in dealing with the statistical heterogeneity problem of federated learning; also, it would be hard to perform accurate model aggregation across different types of clients. To tackle these challenges, in this work, we propose the FedMSplit framework, which allows federated training over multimodal distributed data without assuming similar active sensors in all clients. The key idea is to employ a dynamic and multi-view graph structure to adaptively capture the correlations amongst multimodal client models. More specifically, we split client models into smaller shareable blocks and allow each type of blocks to provide a specific view on client relationships. With the graph representation, the underlying correlations between clients can be captured as the edge features in the multi-view graph, and then be utilized to promote local model relations through the neighborhood message passing in the graph. Our experimental results demonstrate the effectiveness of our method under different sensor setups with statistical heterogeneity.|随着数据采集技术的进步，终端用户开始关注如何利用多类型数据的协同作用提升生活体验。多模态联邦学习(MFL)作为一个新兴领域，允许多个分布式客户端（每个客户端可通过多种传感器采集数据）在不共享本地数据的前提下，共同参与多模态相关模型的训练。本文针对MFL中一个新颖且具有挑战性的问题——模态异质性问题展开研究：客户端可能配备异构的传感器组合，其本地数据包含不同模态的组合形式。这种模态异质性问题导致客户端可能在不同的参数空间上处理不同任务，加剧了联邦学习中统计异构问题的处理难度；同时，跨不同类型客户端的精确模型聚合也面临巨大挑战。为解决这些问题，我们提出FedMSplit框架，该框架支持在多模态分布式数据上进行联邦训练，且无需假设所有客户端具有相同的活跃传感器配置。其核心思想是采用动态多视图图结构自适应地捕捉多模态客户端模型间的关联关系。具体而言，我们将客户端模型拆分为更小的可共享模块，使每类模块能够提供客户端关系的特定视图。通过图表示学习，客户端间的潜在关联被转化为多视图图中的边特征，并利用图中邻域消息传递机制来增强本地模型关联性。实验结果表明，在统计异构的不同传感器配置环境下，我们的方法均展现出卓越有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FedMSplit:+Correlation-Adaptive+Federated+Multi-Task+Learning+across+Multimodal+Split+Networks)|1|
|[A Spectral Representation of Networks: The Path of Subgraphs](https://doi.org/10.1145/3534678.3539433)|Shengmin Jin, Hao Tian, Jiayu Li, Reza Zafarani|Syracuse Univ, Dept EECS, Data Lab, Syracuse, NY 13244 USA|Network representation learning has played a critical role in studying networks. One way to study a graph is to focus on its spectrum, i.e., the eigenvalue distribution of its associated matrices. Recent advancements in spectral graph theory show that spectral moments of a network can be used to capture the network structure and various graph properties. However, sometimes networks with different structures or sizes can have the same or similar spectral moments, not to mention the existence of the cospectral graphs. To address such problems, we propose a 3D network representation that relies on the spectral information of subgraphs: the Spectral Path, a path connecting the spectral moments of the network and those of its subgraphs of different sizes. We show that the spectral path is interpretable and can capture relationship between a network and its subgraphs, for which we present a theoretical foundation. We demonstrate the effectiveness of the spectral path in applications such as network visualization and network identification.|网络表示学习在网络研究中发挥着关键作用。研究图结构的一种重要方法是关注其谱特性，即关联矩阵的特征值分布。谱图理论的最新进展表明，网络谱矩能够有效捕捉网络结构和各类图属性。然而，不同结构或规模的网络可能具有相同或相似的谱矩，更不用说共谱图的存在。为解决这一问题，我们提出了一种基于子图谱信息的三维网络表示方法——谱路径，该路径通过连接原始网络及其不同规模子图的谱矩构成。我们证明谱路径具有可解释性，能够有效捕捉网络与其子图之间的关联关系，并为此提供了理论基础。通过网络可视化和网络识别等应用场景，我们验证了谱路径的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Spectral+Representation+of+Networks:+The+Path+of+Subgraphs)|1|
|[Condensing Graphs via One-Step Gradient Matching](https://doi.org/10.1145/3534678.3539429)|Wei Jin, Xianfeng Tang, Haoming Jiang, Zheng Li, Danqing Zhang, Jiliang Tang, Bing Yin|Michigan State Univ, E Lansing, MI 48824 USA; Amazon, Seattle, WA 98109 USA|As training deep learning models on large dataset takes a lot of time and resources, it is desired to construct a small synthetic dataset with which we can train deep learning models sufficiently. There are recent works that have explored solutions on condensing image datasets through complex bi-level optimization. For instance, dataset condensation (DC) matches network gradients w.r.t. large-real data and small-synthetic data, where the network weights are optimized for multiple steps at each outer iteration. However, existing approaches have their inherent limitations: (1) they are not directly applicable to graphs where the data is discrete; and (2) the condensation process is computationally expensive due to the involved nested optimization. To bridge the gap, we investigate efficient dataset condensation tailored for graph datasets where we model the discrete graph structure as a probabilistic model. We further propose a one-step gradient matching scheme, which performs gradient matching for only one single step without training the network weights. Our theoretical analysis shows this strategy can generate synthetic graphs that lead to lower classification loss on real graphs. Extensive experiments on various graph datasets demonstrate the effectiveness and efficiency of the proposed method. In particular, we are able to reduce the dataset size by 90% while approximating up to 98% of the original performance and our method is significantly faster than multi-step gradient matching (e.g. $15$× in CIFAR10 for synthesizing 500 graphs).|由于在大型数据集上训练深度学习模型耗时且资源密集，构建小型合成数据集以充分训练模型成为迫切需求。近期研究通过复杂的双层优化探索图像数据集压缩方案，例如数据集压缩（DC）技术通过匹配网络在大型真实数据与小型合成数据上的梯度实现压缩，其中网络权重在每个外部迭代中需经过多步优化。然而现有方法存在固有局限性：（1）无法直接适用于数据离散的图结构；（2）嵌套优化导致计算成本高昂。为弥补这一差距，我们研究针对图数据集的高效压缩方法，将离散图结构建模为概率模型。我们进一步提出单步梯度匹配方案，仅通过单步梯度匹配即可完成压缩，无需训练网络权重。理论分析表明该策略生成的合成图能在真实图上实现更低的分类损失。在多类图数据集上的实验证明了方法的有效性和高效性——在将数据集规模压缩90%的同时，仍可保持高达98%的原始性能，且速度显著优于多步梯度匹配方案（如在CIFAR10上合成500张图时速度提升15倍）。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Condensing+Graphs+via+One-Step+Gradient+Matching)|1|
|[RGVisNet: A Hybrid Retrieval-Generation Neural Framework Towards Automatic Data Visualization Generation](https://doi.org/10.1145/3534678.3539330)|Yuanfeng Song, Xuefang Zhao, Raymond ChiWing Wong, Di Jiang|WeBank Co Ltd, AI Grp, Shenzhen, Peoples R China; Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China|Recent years have witnessed the burgeoning of data visualization (DV) systems in both the research and the industrial communities since they provide vivid and powerful tools to convey the insights behind the massive data. A necessary step to visualize data is through creating suitable specifications in some declarative visualization languages (DVLs, e.g., Vega-Lite, ECharts). Due to the steep learning curve of mastering DVLs, automatically generating DVs via natural language questions, or text-to-vis, has been proposed and received great attention. However, existing neural network-based text-to-vis models, such as Seq2Vis or ncNet, usually generate DVs from scratch, limiting their performance due to the complex nature of this problem. Inspired by how developers reuse previously validated source code snippets from code search engines or a large-scale codebase when they conduct software development, we provide a novel hybrid retrieval-generation framework named RGVisNet for text-to-vis. It retrieves the most relevant DV query candidate as a prototype from the DV query codebase, and then revises the prototype to generate the desired DV query. Specifically, the DV query retrieval model is a neural ranking model which employs a schema-aware encoder for the NL question, and a GNN-based DV query encoder to capture the structure information of a DV query. At the same time, the DV query revision model shares the same structure and parameters of the encoders, and employs a DV grammar-aware decoder to reuse the retrieved prototype. Experimental evaluation on the public NVBench dataset validates that RGVisNet can significantly outperform existing generative text-to-vis models such as ncNet, by up to 74.28% relative improvement in terms of overall accuracy. To the best of our knowledge, RGVisNet is the first framework that seamlessly integrates the retrieval- with the generative-based approach for the text-to-vis task.|近年来，随着数据可视化系统成为传递海量数据背后洞察力的生动有力工具，其在学术界和工业界呈现蓬勃发展态势。实现数据可视化的必要步骤是通过声明式可视化语言（如Vega-Lite、ECharts）创建合适的规范。由于掌握这类语言存在较高学习门槛，基于自然语言问题自动生成可视化（即文本到可视化转换）的技术应运而生并广受关注。然而现有基于神经网络的文本到可视化模型（如Seq2Vis、ncNet）通常从零开始生成可视化方案，受限于该问题的复杂性，其性能存在明显瓶颈。受开发者从代码搜索引擎或大型代码库复用已验证代码片段的开发模式启发，我们提出了一种新颖的检索-生成混合框架RGVisNet。该框架首先从可视化查询代码库中检索最相关的候选原型，继而通过修订原型生成目标可视化查询。具体而言：可视化查询检索模型采用神经排序架构，使用模式感知编码器处理自然语言问题，并基于图神经网络的查询编码器捕捉可视化查询的结构信息；可视化查询修订模型共享编码器结构与参数，采用语法感知解码器实现原型复用。在公开基准NVBench上的实验表明，RGVisNet相比ncNet等生成式模型取得显著提升，整体准确率最高相对提升74.28%。据我们所知，这是首个将检索式与生成式方法无缝融合的文本到可视化转换框架。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RGVisNet:+A+Hybrid+Retrieval-Generation+Neural+Framework+Towards+Automatic+Data+Visualization+Generation)|1|
|[Clustering with Fair-Center Representation: Parameterized Approximation Algorithms and Heuristics](https://doi.org/10.1145/3534678.3539487)|Suhas Thejaswi, Ameet Gadekar, Bruno Ordozgoiti, Michal Osadnik|Aalto Univ, Espoo, Finland; Queen Mary Univ London, London, England|We study a variant of classical clustering formulations in the context of algorithmic fairness, known as diversity-aware clustering. In this variant we are given a collection of facility subsets, and a solution must contain at least a specified number of facilities from each subset while simultaneously minimizing the clustering objective (k-median or k-means). We investigate the fixed-parameter tractability of these problems and show several negative hardness and inapproximability results, even when we afford exponential running time with respect to some parameters. Motivated by these results we identify natural parameters of the problem, and present fixed-parameter approximation algorithms with approximation ratios (1 + 2 over e + ∈) and (1 + 8 over e + ∈) for diversity-aware k-median and diversity-aware k-means respectively, and argue that these ratios are essentially tight assuming the gap-exponential time hypothesis. We also present a simple and more practical bicriteria approximation algorithm with better running time bounds. We finally propose efficient and practical heuristics. We evaluate the scalability and effectiveness of our methods in a wide variety of rigorously conducted experiments, on both real and synthetic data.|我们在算法公平性背景下研究经典聚类问题的变体——多样性感知聚类。该变体中给定设施子集集合，要求解决方案在最小化聚类目标（k中值或k均值）的同时，每个子集必须包含指定数量的设施点。我们深入分析了这些问题的固定参数可处理性，证明了即使允许针对某些参数采用指数级时间复杂度，依然存在负面的硬度结果和不可近似性结论。基于这些发现，我们识别出问题的自然参数，并分别针对多样性感知k中值和多样性感知k均值问题，提出了近似比为(1+2/e+ε)和(1+8/e+ε)的固定参数近似算法，同时论证了在间隙指数时间假设下这些近似比本质上是最优的。我们还提出了一种更简单实用且具有更好时间复杂度的双准则近似算法。最后我们设计了高效实用的启发式算法。通过在真实数据集和合成数据集上开展大量严格实验，我们评估了所提出方法的可扩展性与有效性。

（注：此处保留"k-median"和"k-means"的专业术语特征，采用"k中值"和"k均值"的规范译法；"fixed-parameter tractability"译为"固定参数可处理性"以符合计算复杂性理论术语；数学表达式保持原公式形式；"gap-exponential time hypothesis"译为"间隙指数时间假设"是理论计算机科学领域的标准译法）|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Clustering+with+Fair-Center+Representation:+Parameterized+Approximation+Algorithms+and+Heuristics)|1|
|[Towards Representation Alignment and Uniformity in Collaborative Filtering](https://doi.org/10.1145/3534678.3539253)|Chenyang Wang, Yuanqing Yu, Weizhi Ma, Min Zhang, Chong Chen, Yiqun Liu, Shaoping Ma|Tsinghua Univ, BNRist, DCST, Beijing 100084, Peoples R China; Tsinghua Univ, AIR, Beijing 100084, Peoples R China|Collaborative filtering (CF) plays a critical role in the development of recommender systems. Most CF methods utilize an encoder to embed users and items into the same representation space, and the Bayesian personalized ranking (BPR) loss is usually adopted as the objective function to learn informative encoders. Existing studies mainly focus on designing more powerful encoders (e.g., graph neural network) to learn better representations. However, few efforts have been devoted to investigating the desired properties of representations in CF, which is important to understand the rationale of existing CF methods and design new learning objectives. In this paper, we measure the representation quality in CF from the perspective of alignment and uniformity on the hypersphere. We first theoretically reveal the connection between the BPR loss and these two properties. Then, we empirically analyze the learning dynamics of typical CF methods in terms of quantified alignment and uniformity, which shows that better alignment or uniformity both contribute to higher recommendation performance. Based on the analyses results, a learning objective that directly optimizes these two properties is proposed, named DirectAU. We conduct extensive experiments on three public datasets, and the proposed learning framework with a simple matrix factorization model leads to significant performance improvements compared to state-of-the-art CF methods.|协同过滤（CF）在推荐系统发展中具有关键作用。大多数CF方法通过编码器将用户和项目嵌入到同一表示空间，并通常采用贝叶斯个性化排序（BPR）损失作为目标函数来学习信息编码器。现有研究主要集中于设计更强大的编码器（如图神经网络）以获取更好的表示，但鲜有工作深入探究协同过滤中表示质量应具备的特性，而这对于理解现有CF方法的原理和设计新的学习目标具有重要意义。本文从超球面对齐性（alignment）和均匀性（uniformity）的视角衡量CF中的表示质量：首先从理论层面揭示BPR损失与这两个特性之间的关联；进而通过量化指标实证分析典型CF方法在学习过程中的对齐性与均匀性变化，证明更好的对齐性或均匀性均有助提升推荐性能。基于分析结果，我们提出直接优化这两个特性的学习目标DirectAU。在三个公共数据集上的大量实验表明，采用简单矩阵分解模型的该学习框架相比最先进的CF方法能带来显著的性能提升。

（注：根据学术论文摘要的翻译规范，采用以下处理：
1. 专业术语保留英文缩写（CF/BPR）并与中文全称并列呈现
2. "alignment/uniformity"译为"对齐性/均匀性"并添加括号标注英文原词
3. 长难句按中文习惯拆分为逻辑清晰的短句
4. 保持被动语态与原文学术风格一致（"被证明"简化为"证明"）
5. 方法名称"DirectAU"保留英文原名以符合学术惯例）|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Representation+Alignment+and+Uniformity+in+Collaborative+Filtering)|1|
|[Comprehensive Fair Meta-learned Recommender System](https://doi.org/10.1145/3534678.3539269)|Tianxin Wei, Jingrui He|Univ Illinois, Champaign, IL 61820 USA|In recommender systems, one common challenge is the cold-start problem, where interactions are very limited for fresh users in the systems. To address this challenge, recently, many works introduce the meta-optimization idea into the recommendation scenarios, i.e. learning to learn the user preference by only a few past interaction items. The core idea is to learn global shared meta-initialization parameters for all users and rapidly adapt them into local parameters for each user respectively. They aim at deriving general knowledge across preference learning of various users, so as to rapidly adapt to the future new user with the learned prior and a small amount of training data. However, previous works have shown that recommender systems are generally vulnerable to bias and unfairness. Despite the success of meta-learning at improving the recommendation performance with cold-start, the fairness issues are largely overlooked. In this paper, we propose a comprehensive fair meta-learning framework, named CLOVER, for ensuring the fairness of meta-learned recommendation models. We systematically study three kinds of fairness - individual fairness, counterfactual fairness, and group fairness in the recommender systems, and propose to satisfy all three kinds via a multi-task adversarial learning scheme. Our framework offers a generic training paradigm that is applicable to different meta-learned recommender systems. We demonstrate the effectiveness of CLOVER on the representative meta-learned user preference estimator on three real-world data sets. Empirical results show that CLOVER achieves comprehensive fairness without deteriorating the overall cold-start recommendation performance.|在推荐系统中，冷启动问题是一个常见挑战——新用户与系统的交互行为极为有限。为应对这一挑战，近期研究将元优化思想引入推荐场景，即通过少量历史交互项实现用户偏好学习。其核心思想是为所有用户学习全局共享的元初始化参数，并快速将其分别适配至各用户的本地参数。该方法旨在从不同用户的偏好学习中提取通用知识，从而利用已学先验知识和少量训练数据快速适应新用户。然而已有研究表明，推荐系统普遍存在易受偏差与不公平性影响的缺陷。尽管元学习在提升冷启动推荐性能方面取得成效，其公平性问题却长期被忽视。本文提出名为CLOVER的综合公平元学习框架，用于确保元学习推荐模型的公平性。我们系统研究了推荐系统中个体公平性、反事实公平性和群体公平性三类公平问题，并通过多任务对抗学习方案实现三重公平保障。该框架提供适用于不同元学习推荐系统的通用训练范式，并在三个真实数据集上通过代表性元学习用户偏好估计器验证CLOVER的有效性。实验结果表明，CLOVER在保持冷启动推荐性能不衰减的前提下实现了全面公平保障。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Comprehensive+Fair+Meta-learned+Recommender+System)|1|
|[RetroGraph: Retrosynthetic Planning with Graph Search](https://doi.org/10.1145/3534678.3539446)|Shufang Xie, Rui Yan, Peng Han, Yingce Xia, Lijun Wu, Chenjuan Guo, Bin Yang, Tao Qin|Aalborg Univ, Aalborg, Denmark; East China Normal Univ, Shanghai, Peoples R China; Microsoft Res Asia, Beijing, Peoples R China; Renmin Univ China, Gaoling Sch AI GSAI, Beijing, Peoples R China|Retrosynthetic planning, which aims to find a reaction pathway to synthesize a target molecule, plays an important role in chemistry and drug discovery. This task is usually modeled as a search problem. Recently, data-driven methods have attracted many research interests and shown promising results for retrosynthetic planning. We observe that the same intermediate molecules are visited many times in the searching process, and they are usually independently treated in previous tree-based methods (e.g., AND-OR tree search, Monte Carlo tree search). Such redundancies make the search process inefficient. We propose a graph-based search policy that eliminates the redundant explorations of any intermediate molecules. As searching over a graph is more complicated than over a tree, we further adopt a graph neural network to guide the search over graphs. Meanwhile, our method can search a batch of targets together in the graph and remove the inter-target duplication in the tree-based search methods. Experimental results on two datasets demonstrate the effectiveness of our method. Especially on the widely used USPTO benchmark, we improve the search success rate to 99.47%, advancing previous state-of-the-art performance for 2.6 points.|逆合成规划旨在寻找合成目标分子的反应路径，在化学和药物发现领域具有重要作用。该任务通常被建模为搜索问题。近年来，数据驱动方法吸引了大量研究关注，并在逆合成规划中展现出优异性能。我们发现同一中间分子在搜索过程中会被多次访问，而传统基于树结构的搜索方法（如与或树搜索、蒙特卡洛树搜索）通常对其独立处理，这种冗余导致搜索效率低下。我们提出一种基于图的搜索策略，可消除对任何中间分子的冗余探索。由于图搜索比树搜索更复杂，我们进一步采用图神经网络来指导图搜索过程。同时，本方法能在图中批量搜索多个目标分子，消除树搜索方法中存在的目标间重复探索。在两个数据集上的实验结果表明了我们方法的有效性。尤其在广泛使用的USPTO基准测试中，我们将搜索成功率提升至99.47%，较先前最优性能提高了2.6个百分点。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RetroGraph:+Retrosynthetic+Planning+with+Graph+Search)|1|
|[Ultrahyperbolic Knowledge Graph Embeddings](https://doi.org/10.1145/3534678.3539333)|Bo Xiong, Shichao Zhu, Mojtaba Nayyeri, Chengjin Xu, Shirui Pan, Chuan Zhou, Steffen Staab|Univ Bonn, Bonn, Germany; Chinese Acad Sci, UCAS, IIE, Sch Cyber Secur, Beijing, Peoples R China; Univ Stuttgart, Univ Southampton, Stuttgart, Germany; Chinese Acad Sci, AMSS, Beijing, Peoples R China; Univ Stuttgart, Stuttgart, Germany; Monash Univ, Melbourne, Vic, Australia|Recent knowledge graph (KG) embeddings have been advanced by hyperbolic geometry due to its superior capability for representing hierarchies. The topological structures of real-world KGs, however, are rather heterogeneous, i.e., a KG is composed of multiple distinct hierarchies and non-hierarchical graph structures. Therefore, a homogeneous (either Euclidean or hyperbolic) geometry is not sufficient for fairly representing such heterogeneous structures. To capture the topological heterogeneity of KGs, we present an ultrahyperbolic KG embedding (UltraE) in an ultrahyperbolic (or pseudo-Riemannian) manifold that seamlessly interleaves hyperbolic and spherical manifolds. In particular, we model each relation as a pseudo-orthogonal transformation that preserves the pseudo-Riemannian bilinear form. The pseudo-orthogonal transformation is decomposed into various operators (i.e., circular rotations, reflections and hyperbolic rotations), allowing for simultaneously modeling heterogeneous structures as well as complex relational patterns. Experimental results on three standard KGs show that UltraE outperforms previous Euclidean, hyperbolic, and mixed-curvature KG embedding approaches.|近年来，双曲几何因其在表示层次结构方面的卓越能力，推动了知识图谱（KG）嵌入技术的发展。然而现实世界知识图谱的拓扑结构具有高度异质性，即一个知识图谱由多个不同的层次结构和非层次图结构组成。因此，采用单一几何空间（欧几里得或双曲）无法充分表征这种异质结构。为捕捉知识图谱的拓扑异质性，我们提出在超双曲（或称伪黎曼）流形中构建超双曲知识图谱嵌入模型（UltraE），该流形可无缝交织双曲流形与球面流形。具体而言，我们将每种关系建模为保持伪黎曼双线性形式的伪正交变换。通过将伪正交变换分解为多种算子（圆周旋转、反射和双曲旋转），该模型能同时处理异质结构和复杂关系模式。在三个标准知识图谱上的实验结果表明，UltraE优于以往基于欧几里得几何、双曲几何及混合曲率的知识图谱嵌入方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ultrahyperbolic+Knowledge+Graph+Embeddings)|1|
|[HICF: Hyperbolic Informative Collaborative Filtering](https://doi.org/10.1145/3534678.3539475)|Menglin Yang, Zhihao Li, Min Zhou, Jiahong Liu, Irwin King|Harbin Inst Technol, Shenzhen, Peoples R China; Chinese Univ Hong Kong, Hong Kong, Peoples R China; Huawei Technol Co Ltd, Shenzhen, Peoples R China|Considering the prevalence of the power-law distribution in user-item networks, hyperbolic space has attracted considerable attention and achieved impressive performance in the recommender system recently. The advantage of hyperbolic recommendation lies in that its exponentially increasing capacity is well-suited to describe the power-law distributed user-item network whereas the Euclidean equivalent is deficient. Nonetheless, it remains unclear which kinds of items can be effectively recommended by the hyperbolic model and which cannot. To address the above concerns, we take the most basic recommendation technique, collaborative filtering, as a medium, to investigate the behaviors of hyperbolic and Euclidean recommendation models. The results reveal that (1) tail items get more emphasis in hyperbolic space than that in Euclidean space, but there is still ample room for improvement; (2) head items receive modest attention in hyperbolic space, which could be considerably improved; (3) and nonetheless, the hyperbolic models show more competitive performance than Euclidean models. Driven by the above observations, we design a novel learning method, named hyperbolic informative collaborative learning (HICF), aiming to compensate for the recommendation effectiveness of the head item while at the same time improving the performance of the tail item. The main idea is to adapt the hyperbolic margin ranking learning, making its pull and push procedure geometric-aware, and providing informative guidance for the learning of both head and tail items. Extensive experiments back up the analytic findings and also show the effectiveness of the proposed method. The work is valuable for personalized recommendations since it reveals that the hyperbolic space facilitates modeling the tail item, which often represents user-customized preferences or new products.|考虑到用户-项目网络中普遍存在的幂律分布特性，双曲空间近年来在推荐系统领域受到广泛关注并展现出卓越性能。双曲推荐的优势在于其指数级增长的容量特性恰好契合描述幂律分布的用户-项目网络，而欧几里得模型在此方面存在固有缺陷。然而，目前尚不清楚双曲模型究竟能有效推荐哪些类型的项目，又会在哪些项目上表现不佳。针对这一问题，我们以最基础的协同过滤技术为媒介，深入探究双曲与欧几里得推荐模型的行为特征。研究发现：（1）与欧几里得空间相比，双曲空间对长尾项目的关注度更高，但仍有较大提升空间；（2）头部项目在双曲空间中获得的关注相对有限，存在显著改进余地；（3）尽管如此，双曲模型整体仍展现出较欧几里得模型更具竞争力的性能。基于这些发现，我们创新性地提出双曲信息协同学习框架（HICF），在提升长尾项目推荐效果的同时补偿头部项目的推荐效能。该方法的核心理念是通过适配双曲边际排序学习，使其推拉过程具备几何感知能力，并为头部与长尾项目的学习提供信息指导。大量实验不仅验证了分析结论，也证明了所提方法的有效性。本研究对个性化推荐具有重要价值，它揭示出双曲空间特别有利于建模往往代表用户定制偏好或新产品的长尾项目。

（注：本翻译严格遵循学术论文摘要的规范表述，重点处理了以下专业要素：
1. 专业术语统一："power-law distribution"译作"幂律分布"，"hyperbolic space"译作"双曲空间"
2. 技术概念准确："collaborative filtering"译为"协同过滤"，"margin ranking learning"译为"边际排序学习"
3. 长难句拆分：将原文复合句按中文表达习惯重构为多个短句
4. 逻辑连接词优化：使用"尽管如此""基于这些发现"等符合中文论文表述习惯的连接词
5. 术语一致性：全程保持"头部项目/长尾项目"的对应译法统一）|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HICF:+Hyperbolic+Informative+Collaborative+Filtering)|1|
|[Improving Social Network Embedding via New Second-Order Continuous Graph Neural Networks](https://doi.org/10.1145/3534678.3539415)|Yanfu Zhang, Shangqian Gao, Jian Pei, Heng Huang|Simon Fraser Univ, Sch Comp Sci, Vancouver, BC, Canada; Univ Pittsburgh, Elect & Comp Engn, Pittsburgh, PA 15213 USA|Graph neural networks (GNN) are powerful tools in many web research problems. However, existing GNNs are not fully suitable for many real-world web applications. For example, over-smoothing may affect personalized recommendations and the lack of an explanation for the GNN prediction hind the understanding of many business scenarios. To address these problems, in this paper, we propose a new second-order continuous GNN which naturally avoids over-smoothing and enjoys better interpretability. There is some research interest in continuous graph neural networks inspired by the recent success of neural ordinary differential equations (ODEs). However, there are some remaining problems w.r.t. the prevailing first-order continuous GNN frameworks. Firstly, augmenting node features is an essential, however heuristic step for the numerical stability of current frameworks; secondly, first-order methods characterize a diffusion process, in which the over-smoothing effect w.r.t. node representations are intrinsic; and thirdly, there are some difficulties to integrate the topology of graphs into the ODEs. Therefore, we propose a framework employing second-order graph neural networks, which usually learn a less stiff transformation than the first-order counterpart. Our method can also be viewed as a coupled first-order model, which is easy to implement. We propose a semi-model-agnostic method based on our model to enhance the prediction explanation using high-order information. We construct an analog between continuous GNNs and some famous partial differential equations and discuss some properties of the first and second-order models. Extensive experiments demonstrate the effectiveness of our proposed method, and the results outperform related baselines.|图神经网络（GNN）是解决众多网络研究问题的有力工具。然而现有GNN并不能完全适用于现实世界的网络应用场景。例如，过度平滑效应可能影响个性化推荐效果，且GNN预测缺乏可解释性会阻碍对商业场景的理解。针对这些问题，本文提出了一种新型二阶连续图神经网络，其天然避免过度平滑问题并具有更优的可解释性。近年来神经常微分方程（ODE）的成功激发了学界对连续图神经网络的研究兴趣，但主流的一阶连续GNN框架仍存在若干问题：首先，增强节点特征虽是当前框架维持数值稳定性的关键步骤，但其策略依赖启发式设计；其次，一阶方法本质刻画扩散过程，其节点表示存在固有的过度平滑效应；第三，现有方法难以将图拓扑结构有效融入ODE框架。为此，我们提出采用二阶图神经网络的框架，其学习到的变换比一阶方法具有更低刚性。该方法亦可视为耦合的一阶模型，易于实现。基于该模型，我们提出半模型无关的高阶信息解释方法以增强预测可解释性。通过构建连续GNN与经典偏微分方程的类比，我们深入分析了一阶与二阶模型特性。大量实验证明所提方法的有效性，其性能显著超越相关基线模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Social+Network+Embedding+via+New+Second-Order+Continuous+Graph+Neural+Networks)|1|
|[SoccerCPD: Formation and Role Change-Point Detection in Soccer Matches Using Spatiotemporal Tracking Data](https://doi.org/10.1145/3534678.3539150)|Hyunsung Kim, Bit Kim, Dongwook Chung, Jinsung Yoon, SangKi Ko|Fitogether Inc, Seoul, South Korea|In fluid team sports such as soccer and basketball, analyzing team formation is one of the most intuitive ways to understand tactics from domain participants' point of view. However, existing approaches either assume that team formation is consistent throughout a match or assign formations frame-by-frame, which disagree with real situations. To tackle this issue, we propose a change-point detection framework named SoccerCPD that distinguishes tactically intended formation and role changes from temporary changes in soccer matches. We first assign roles to players frame-by-frame and perform two-step change-point detections: (1) formation change-point detection based on the sequence of role-adjacency matrices and (2) role change-point detection based on the sequence of role permutations. The evaluation of SoccerCPD using the ground truth annotated by domain experts shows that our method accurately detects the points of tactical changes and estimates the formation and role assignment per segment. Lastly, we introduce practical use-cases that domain participants can easily interpret and utilize.|在足球和篮球等流动性团队运动中，分析阵型布局是从领域参与者角度理解战术最直观的方法之一。然而现有方法要么假设整场比赛阵型保持不变，要么逐帧分配阵型，这与实际情况不符。为解决这一问题，我们提出名为SoccerCPD的变点检测框架，用于区分足球比赛中战术性阵型调整、角色转换与临时性变化。我们首先逐帧分配球员角色，并执行两阶段变点检测：(1) 基于角色邻接矩阵序列的阵型变点检测；(2) 基于角色置换序列的角色变点检测。通过领域专家标注的真实数据评估显示，SoccerCPD能准确检测战术变化点并估算每个时段的阵型与角色分配。最后我们介绍了领域参与者易于解读和实际应用的用例。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SoccerCPD:+Formation+and+Role+Change-Point+Detection+in+Soccer+Matches+Using+Spatiotemporal+Tracking+Data)|1|
|[Multi-Aspect Dense Retrieval](https://doi.org/10.1145/3534678.3539137)|Weize Kong, Swaraj Khadanga, Cheng Li, Shaleen Kumar Gupta, Mingyang Zhang, Wensong Xu, Michael Bendersky|Google, Mountain View, CA 94043 USA|Prior work in Dense Retrieval usually encodes queries and documents using single-vector representations (also called embeddings) and performs retrieval in the embedding space using approximate nearest neighbor search. This paradigm enables efficient semantic retrieval. However, the single-vector representations can be ineffective at capturing different aspects of the queries and documents in relevance matching, especially for some vertical domains. For example, in e-commerce search, these aspects could be category, brand and color. Given a query ''white nike socks", a Dense Retrieval model may mistakenly retrieve some ''white adidas socks" while missing out the intended brand. We propose to explicitly represent multiple aspects using one embedding per aspect. We introduce an aspect prediction task to teach the model to capture aspect information with particular aspect embeddings. We design a lightweight network to fuse the aspect embeddings for representing queries and documents. Our evaluation using an e-commerce dataset shows impressive improvements over strong Dense Retrieval baselines. We also discover that the proposed aspect embeddings can enhance the interpretability of Dense Retrieval models as a byproduct.|以往的研究通常采用单向量表示（亦称嵌入）对查询项和文档进行编码，并借助近似最近邻搜索在嵌入空间执行检索。该范式虽能实现高效的语义检索，但在相关匹配中难以有效捕捉查询项与文档的多维度特征，尤其在特定垂直领域表现更为明显。以电商搜索为例，这些维度可能包含商品类别、品牌和颜色。当用户查询"白色耐克袜子"时，密集检索模型可能会错误返回"白色阿迪达斯袜子"，却遗漏了目标品牌。为此，我们提出为每个维度生成独立嵌入向量的多维度显式表征方案：通过引入维度预测任务，指导模型使用特定维度嵌入捕捉维度信息；设计轻量级网络融合各维度嵌入以表征查询项和文档。在电商数据集上的评估表明，该方法较现有强基线模型取得显著提升。我们还发现，所提出的维度嵌入表征能够作为副产品增强密集检索模型的可解释性。

注：本文在保持学术论文摘要严谨性的基础上，采用以下处理：
1. 将"aspect"译为"维度"而非字面意义的"方面"，更符合中文信息检索领域的术语习惯
2. 使用"嵌入"而非"向量表示"保持技术一致性
3. 对长难句进行合理切分，如将原文倒数第二句拆分为两个中文句子
4. 保留专业术语"基线模型(baselines)"的规范译法
5. 通过"为此""还发现"等连接词保持逻辑连贯性
6. 采用"范式""表征""可解释性"等学术用语保持文体统一|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Aspect+Dense+Retrieval)|1|
|[Multi-objective Optimization of Notifications Using Offline Reinforcement Learning](https://doi.org/10.1145/3534678.3539193)|Prakruthi Prabhakar, Yiping Yuan, Guangyu Yang, Wensheng Sun, Ajith Muralidharan|LinkedIn Corp, Mountain View, CA 94041 USA|Mobile notification systems play a major role in a variety of applications to communicate, send alerts and reminders to the users to inform them about news, events or messages. In this paper, we formulate the near-real-time notification decision problem as a Markov Decision Process where we optimize for multiple objectives in the rewards. We propose an end-to-end offline reinforcement learning framework to optimize sequential notification decisions. We address the challenge of offline learning using a Double Deep Q-network method based on Conservative Q-learning that mitigates the distributional shift problem and Q-value overestimation. We illustrate our fully-deployed system and demonstrate the performance and benefits of the proposed approach through both offline and online experiments.|移动通知系统在各类应用中扮演着重要角色，通过向用户发送提醒、警报和通知来实现信息传递，使其及时知悉新闻、事件或消息。本文将准实时通知决策问题构建为马尔可夫决策过程，在奖励函数中实现多目标优化。我们提出端到端的离线强化学习框架来优化序列化通知决策，采用基于保守Q学习的双深度Q网络方法解决离线学习中的分布偏移问题和Q值高估挑战。文中展示了完整部署的系统架构，并通过离线和在线实验验证了所提方法的性能优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-objective+Optimization+of+Notifications+Using+Offline+Reinforcement+Learning)|1|
|[Seq2Event: Learning the Language of Soccer Using Transformer-based Match Event Prediction](https://doi.org/10.1145/3534678.3539138)|Ian Simpson, Ryan J. Beal, Duncan Locke, Timothy J. Norman|Rugby Football Union, London, England; Univ Southampton, Southampton, Hants, England|Soccer is a sport characterised by open and dynamic play, with player actions and roles aligned according to team strategies simultaneously and at multiple temporal scales with high spatial freedom. This complexity presents an analytics challenge, which to date has largely been solved by decomposing the game according to specific criteria to analyse specific problems. We propose a more holistic approach, utilising Transformer or RNN components in the novel Seq2Event model, in which the next match event is predicted given prior match events and context. We show metric creation using a general purpose context-aware model as a deployable practical application, and demonstrate development of the poss-util metric using a Seq2Event model. Summarising the expectation of key attacking events (shot, cross) during each possession, our metric is shown to correlate over matches (r = 0.91, n = 190) with the popular xG metric. Example practical application of poss-util to analyse behaviour over possessions and matches is made. Potential in sports with stronger sequentiality, such as rugby union, is discussed.|足球运动具有开放性和动态性的特点，球员根据团队策略在多个时间尺度上同时调整行动与角色，并享有高度的空间自由度。这种复杂性为数据分析带来挑战，迄今为止主要解决方案是依据特定标准分解比赛以分析具体问题。我们提出一种更全面的方法——在新型Seq2Event模型中运用Transformer或RNN组件，通过先前比赛事件及上下文预测后续赛事。我们展示了将通用上下文感知模型用于创建可部署实际应用的指标，并演示了基于Seq2Event模型开发poss-util指标的过程。该指标通过汇总每次控球期间关键进攻事件（射门、传中）的预期值，在190场比赛中与广受欢迎的xG指标呈现显著相关性（r=0.91）。我们通过实际案例应用poss-util指标分析单次控球及整场比赛的表现特征，并探讨了该方法在英式橄榄球等具有更强序列性特征的运动中的应用潜力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Seq2Event:+Learning+the+Language+of+Soccer+Using+Transformer-based+Match+Event+Prediction)|1|
|[Friend Recommendations with Self-Rescaling Graph Neural Networks](https://doi.org/10.1145/3534678.3539192)|Xiran Song, Jianxun Lian, Hong Huang, Mingqi Wu, Hai Jin, Xing Xie|Huazhong Univ Sci & Technol, Natl Engn Res Ctr Big Data Technol & Syst, Serv Comp Technol & Syst Lab, Wuhan, Peoples R China; Microsoft Res Asia, Beijing, Peoples R China; Microsoft Gaming, Redmond, WA USA|Friend recommendation service plays an important role in shaping and facilitating the growth of online social networks. Graph embedding models, which can learn low-dimensional embeddings for nodes in the social graph to effectively represent the proximity between nodes, have been widely adopted for friend recommendations. Recently, Graph Neural Networks (GNNs) have demonstrated superiority over shallow graph embedding methods, thanks to their ability to explicitly encode neighborhood context. This is also verified in our Xbox friend recommendation scenario, where some simplified GNNs, such as LightGCN and PPRGo, achieve the best performance. However, we observe that many GNN variants, including LightGCN and PPRGo, use a static and pre-defined normalizer in neighborhood aggregation, which is decoupled with the representation learning process and can cause the scale distortion issue. As a consequence, the true power of GNNs has not yet been fully demonstrated in friend recommendations. In this paper, we propose a simple but effective self-rescaling network (SSNet) to alleviate the scale distortion issue. At the core of SSNet is a generalized self-rescaling mechanism, which bridges the neighborhood aggregator's normalization with the node embedding learning process in an end-to-end framework. Meanwhile, we provide some theoretical analysis to help us understand the benefit of SSNet. We conduct extensive offline experiments on three large-scale real-world datasets. Results demonstrate that our proposed method can significantly improve the accuracy of various GNNs. When deployed online for one month's A/B test, our method achieves 24% uplift in adding suggested friends actions. At last, we share some interesting findings and hope the experience can motivate future applications and research in social link predictions.|好友推荐服务对在线社交网络的形态塑造与增长促进具有重要作用。图嵌入模型通过学习社交图中节点的低维嵌入来有效表征节点间邻近度，已被广泛用于好友推荐场景。近年来，图神经网络（GNN）因能显式编码邻域上下文信息，在性能上超越了浅层图嵌入方法。我们在Xbox好友推荐场景中也验证了这一结论——LightGCN、PPRGo等简化GNN模型取得了最佳性能。但研究发现，包括LightGCN和PPRGo在内的多种GNN变体在邻域聚合中使用静态预定义归一化器，这种与表示学习过程解耦的设计会导致尺度失真问题，使得GNN在好友推荐中的潜力未能完全释放。本文提出一种简单有效的自缩放网络（SSNet）来解决尺度失真问题。其核心是通过端到端框架构建广义自缩放机制，将邻域聚合器的归一化过程与节点嵌入学习相融合，同时辅以理论分析阐明其优势。基于三个大规模真实数据集的离线实验表明，该方法能显著提升多种GNN的预测精度。经过为期一个月的在线A/B测试，推荐好友添加操作量提升达24%。最后我们分享了一些有趣发现，期待这些实践经验能为社交链接预测领域的应用与研究提供新思路。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Friend+Recommendations+with+Self-Rescaling+Graph+Neural+Networks)|1|
|[4SDrug: Symptom-based Set-to-set Small and Safe Drug Recommendation](https://doi.org/10.1145/3534678.3539089)|Yanchao Tan, Chengjun Kong, Leisheng Yu, Pan Li, Chaochao Chen, Xiaolin Zheng, Vicki Hertzberg, Carl Yang|Emory Univ, Dept Comp Sci, Atlanta, GA 30322 USA; Zhejiang Univ, Coll Comp Sci, Hangzhou, Zhejiang, Peoples R China; Fuzhou Univ, Coll Comp & Data Sci, Fuzhou, Peoples R China; Natl Univ Singapore, Fac Sci, Singapore, Singapore; Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA; Emory Univ, Nell Hodgson Woodruff Sch Nursing, Atlanta, GA 30322 USA|Drug recommendation is an important task of AI for healthcare. To recommend proper drugs, existing methods rely on various clinical records (e.g., diagnosis and procedures), which are commonly found in data such as electronic health records (EHRs). However, detailed records as such are often not available and the inputs might merely include a set of symptoms provided by doctors. Moreover, existing drug recommender systems usually treat drugs as individual items, ignoring the unique requirements that drug recommendation has to be done on a set of items (drugs), which should be as small as possible and safe without harmful drug-drug interactions (DDIs). To deal with the challenges above, in this paper, we propose a novel framework of Symptom-based Set-to-set Small and Safe drug recommendation (4SDrug). To enable set-to-set comparison, we design set-oriented representation and similarity measurement for both symptoms and drugs. Further, towards the symptom sets, we devise importance-based set aggregation to enhance the accuracy of symptom set representation; towards the drug sets, we devise intersection-based set augmentation to ensure smaller drug sets, and apply knowledge-based and data-driven penalties to ensure safer drug sets. Extensive experiments on two real-world EHR datasets, i.e., the public benchmark one of MIMIC-III and the industrial large-scale one of NELL, show drastic performance gains brought by 4SDrug, which outperforms all baselines in most effectiveness measures, while yielding the smallest sets of recommended drugs and 26.83% DDI rate reduction from the ground-truth data.|药物推荐是人工智能在医疗领域的重要应用任务。为提供准确的药物推荐，现有方法通常依赖电子健康记录（EHR）等数据中常见的各类临床记录（如诊断和治疗方案）。然而此类详细记录往往难以获取，实际输入可能仅包含医生提供的一组症状描述。此外，现有药物推荐系统通常将药物视为独立个体，忽略了药物推荐必须满足的特殊要求：推荐结果应为尽可能精简的药物组合，且需确保安全性以避免有害的药物相互作用（DDI）。为应对上述挑战，本文提出基于症状的集对集精简安全药物推荐创新框架（4SDrug）。为实现集合层面的匹配，我们设计了针对症状集和药物集的定向表征与相似度度量机制：对于症状集合，采用基于重要性的集合聚合方法以提升症状表征精度；对于药物集合，通过基于交集的集合扩增技术确保推荐药物集最小化，同时应用知识驱动与数据驱动的双重惩罚机制保障药物安全性。在MIMIC-III公共基准数据集和NELL工业级大规模数据集上的实验表明，4SDrug在多数效能指标上超越所有基线模型，其推荐药物集规模最小且DDI发生率较真实数据降低26.83%，展现出显著性能提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=4SDrug:+Symptom-based+Set-to-set+Small+and+Safe+Drug+Recommendation)|1|
|[Interpretable Personalized Experimentation](https://doi.org/10.1145/3534678.3539175)|Han Wu, Sarah Tan, Weiwei Li, Mia Garrard, Adam Obeng, Drew Dimmery, Shaun Singh, Hanson Wang, Daniel R. Jiang, Eytan Bakshy|Stanford Univ, Stanford, CA 94305 USA; Meta, Menlo Pk, CA USA; Univ Vienna, Vienna, Austria|Black-box heterogeneous treatment effect (HTE) models are increasingly being used to create personalized policies that assign individuals to their optimal treatments. However, they are difficult to understand, and can be burdensome to maintain in a production environment. In this paper, we present a scalable, interpretable personalized experimentation system, implemented and deployed in production at Meta. The system works in a multiple treatment, multiple outcome setting typical at Meta to: (1) learn explanations for black-box HTE models; (2) generate interpretable personalized policies. We evaluate the methods used in the system on publicly available data and Meta use cases, and discuss lessons learnt during the development of the system.|黑盒异质处理效应（HTE）模型正被越来越多地用于创建个性化策略，从而为个体分配最优治疗方案。然而，这类模型难以理解，且在生产环境中维护成本高昂。本文提出了一种可扩展、可解释的个性化实验系统，该系统已在Meta公司实现并投入生产部署。该系统适用于Meta典型的多元处理、多元结果场景，能够：(1) 为黑盒HTE模型生成解释；(2) 产生可解释的个性化策略。我们通过公开数据集和Meta实际用例对系统采用的方法进行了评估，并总结了系统开发过程中获得的经验教训。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interpretable+Personalized+Experimentation)|1|
|[Graph-based Representation Learning for Web-scale Recommender Systems](https://doi.org/10.1145/3534678.3542598)|Ahmed ElKishky, Michael M. Bronstein, Ying Xiao, Aria Haghighi|Twitter Cortex, London, England; Twitter Cortex, Seattle, WA 94041 USA; Twitter Cortex, San Francisco, CA USA|Recommender systems are fundamental building blocks of modern consumer web applications that seek to predict user preferences to better serve relevant items. As such, high-quality user and item representations as inputs to recommender systems are crucial for personalized recommendation. To construct these user and item representations, self-supervised graph embedding has emerged as a principled approach to embed relational data such as user social graphs, user membership graphs, user-item engagements, and other heterogeneous graphs. In this tutorial we discuss different families of approaches to self-supervised graph embedding. Within each family, we outline a variety of techniques, their merits and disadvantages, and expound on latest works. Finally, we demonstrate how to effectively utilize the resultant large embedding tables to improve candidate retrieval and ranking in modern industry-scale deep-learning recommender systems.|推荐系统是现代消费类网络应用的基础构建模块，其通过预测用户偏好来更好地提供相关项目。因此，作为推荐系统输入的高质量用户与项目表征对实现个性化推荐至关重要。为构建这些用户与项目表征，自监督图嵌入已成为嵌入关系数据（如用户社交图、用户会员关系图、用户-项目交互图及其他异构图）的系统化方法。本教程将探讨自监督图嵌入的不同方法体系，针对每个体系梳理多种技术方案、分析其优势与局限，并详细阐释最新研究成果。最后，我们将展示如何有效利用生成的大规模嵌入表，以改进现代工业级深度学习推荐系统中的候选项目检索与排序流程。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph-based+Representation+Learning+for+Web-scale+Recommender+Systems)|1|
|[concept2code: Deep Reinforcement Learning for Conversational AI](https://doi.org/10.1145/3534678.3542635)|Omprakash Sonie, Abir Chakraborty, Ankan Mullick|IIT Kharagpur, Kharagpur, W Bengal, India; DeepThinking AI, Hyderabad, India; Microsoft, Seattle, WA USA|Deep Reinforcement Learning uses best of both Reinforcement Learning and Deep Learning for solving problems which cannot be addressed by them individually. Deep Reinforcement Learning has been used widely for games, robotics etc. Limited work has been done for applying Deep Reinforcement Learning for Conversational AI. Hence, in this tutorial cover application of Deep Reinforcement Learning for Conversational AI. We give conceptual introduction to Reinforcement Learning and Deep Reinforcement Learning. We then present various real-life approaches with increasing complexity in detail. The approaches include dialog generation, task-oriented dialog generation, modelling chitchat, natural language generation, hierarchical, weakly supervised, multi-domain and decision transformer. We then walk-through code for implementation of core ideas and for some of the real-life approaches.|深度强化学习融合了强化学习与深度学习的优势，用于解决二者单独无法应对的复杂问题。该技术已在游戏、机器人等领域获得广泛应用，但在对话式人工智能领域的应用研究仍处于初步阶段。本教程将系统阐述深度强化学习在对话式人工智能中的实践应用：首先阐释强化学习与深度强化学习的核心概念，随后由浅入深地详解多种现实场景中的技术路径，包括对话生成、任务导向型对话生成、闲聊建模、自然语言生成，以及分层模型、弱监督学习、多领域适配和决策 Transformer 等进阶方法。最后将通过代码实践演示核心思想的实现过程，并选取部分现实应用方案进行实现演练。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=concept2code:+Deep+Reinforcement+Learning+for+Conversational+AI)|1|
|[Variational Inference for Training Graph Neural Networks in Low-Data Regime through Joint Structure-Label Estimation](https://doi.org/10.1145/3534678.3539283)|Danning Lao, Xinyu Yang, Qitian Wu, Junchi Yan|Shanghai Jiao Tong Univ, Shanghai, Peoples R China|Graph Neural Networks (GNNs) are one of the prominent methods to solve semi-supervised learning on graphs. However, most of the existing GNN models often need sufficient observed data to allow for effective learning and generalization. In real-world scenarios where complete input graph structure and sufficient node labels might not be achieved easily, GNN models would encounter with severe performance degradation. To address this problem, we propose WSGNN, short for weakly-supervised graph neural network. WSGNN is a flexible probabilistic generative framework which harnesses variational inference approach to solve graph semi-supervised learning in a label-structure joint estimation manner. It collaboratively learns task-related new graph structure and node representations through a two-branch network, and targets a composite variational objective derived from underlying data generation distribution concerning the inter-dependence between scarce observed data and massive missing data. Especially, under weakly-supervised low-data regime where labeled nodes and observed edges are both very limited, extensive experimental results on node classification and link prediction over common benchmarks demonstrate the state-of-the-art performance of WSGNN over strong competitors. Concretely, when only 1 label per class and 1% edges are observed on Cora, WSGNN maintains a decent 52.00% classification accuracy, exceeding GCN by 75.6%.|图神经网络（GNN）是解决图上半监督学习问题的重要方法之一。然而现有大多数GNN模型往往需要充足的观测数据才能实现有效学习与泛化。在现实场景中，当完整的输入图结构和充足节点标签难以获取时，GNN模型会出现严重的性能退化。针对此问题，我们提出弱监督图神经网络WSGNN——一个基于变分推理的灵活概率生成框架，通过标签-结构联合估计方式解决图上半监督学习问题。该框架通过双分支网络协同学习任务相关的新图结构与节点表示，并基于底层数据生成分布中稀缺观测数据与海量缺失数据间的相互依赖关系，推导出复合变分优化目标。特别是在标记节点和观测边都极其有限的弱监督低数据场景下，我们在节点分类和链路预测任务上对常用基准数据集进行了大量实验，结果表明WSGNN相较强基线模型展现出最先进的性能。具体而言，当Cora数据集每类仅1个标签且仅观测1%边时，WSGNN仍保持52.00%的分类准确率，较GCN模型提升75.6%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Variational+Inference+for+Training+Graph+Neural+Networks+in+Low-Data+Regime+through+Joint+Structure-Label+Estimation)|1|
|[Pairwise Adversarial Training for Unsupervised Class-imbalanced Domain Adaptation](https://doi.org/10.1145/3534678.3539243)|Weili Shi, Ronghang Zhu, Sheng Li|Associate Professor, University of Virginia, Charlottesville; PhD student, Computer Science, University of Georgia; PhD student, University of Virginia, Charlottesville|Unsupervised domain adaptation (UDA) has become an appealing approach for knowledge transfer from a labeled source domain to an unlabeled target domain. However, when the classes in source and target domains are imbalanced, most existing UDA methods experience significant performance drop, as the decision boundary usually favors the majority classes. Some recent class-imbalanced domain adaptation (CDA) methods aim to tackle the challenge of biased label distribution by exploiting pseudo-labeled target samples during training process. However, these methods suffer from the issues with unreliable pseudo labels and error accumulation during training. In this paper, we propose a pairwise adversarial training approach for class-imbalanced domain adaptation. Unlike conventional adversarial training in which the adversarial samples are obtained from the lp ball of the original samples, we generate adversarial samples from the interpolated line of the aligned pairwise samples from source and target domains. The pairwise adversarial training (PAT) is a novel data-augmentation method which can be integrated into existing UDA models to tackle with the CDA problem. Experimental results and ablation studies show that the UDA models integrated with our method achieve considerable improvements on benchmarks compared with the original models as well as the state-of-the-art CDA methods. Our source code is available at: https://github.com/DamoSWL/Pairwise-Adversarial-Training|无监督领域自适应（UDA）已成为从带标注的源领域向无标注目标领域迁移知识的重要方法。然而当源领域与目标领域的类别分布不均衡时，大多数现有UDA方法会出现显著性能下降，因为决策边界通常会偏向多数类。近期一些类别不平衡领域自适应（CDA）方法试图通过在训练过程中利用伪标注目标样本来解决标签分布偏差的挑战，但这些方法存在伪标签可靠性不足及训练过程中误差累积的问题。本文提出一种面向类别不平衡领域自适应的成对对抗训练方法。与传统对抗训练从原始样本的lp范数邻域生成对抗样本不同，我们从源领域与目标领域对齐的成对样本插值线上生成对抗样本。这种成对对抗训练（PAT）是一种新型数据增强方法，可集成到现有UDA模型中解决CDA问题。实验结果表明，采用本方法的UDA模型在基准测试中相比原模型及当前最优CDA方法均取得显著提升，消融研究也验证了方法的有效性。源代码已开源：https://github.com/DamoSWL/Pairwise-Adversarial-Training

（注：根据学术论文摘要的翻译规范，保留UDA/CDA/PAT等专业术语缩写，采用"领域自适应""伪标注""消融研究"等符合计算机领域中文表达习惯的译法，同时确保技术细节的准确传递和长句的合理切分。）|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pairwise+Adversarial+Training+for+Unsupervised+Class-imbalanced+Domain+Adaptation)|1|
|[TrajGAT: A Graph-based Long-term Dependency Modeling Approach for Trajectory Similarity Computation](https://doi.org/10.1145/3534678.3539358)|Di Yao, Haonan Hu, Lun Du, Gao Cong, Shi Han, Jingping Bi|Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China; Nanyang Technol Univ, Singapore, Singapore; Microsoft Res Asia, Beijing, Peoples R China|Computing trajectory similarities is a critical and fundamental task for various spatial-temporal applications, such as clustering, prediction, and anomaly detection. Traditional similarity metrics, i.e. DTW and Hausdorff, suffer from quadratic computation complexity, leading to their inability on large-scale data. To solve this problem, many trajectory representation learning techniques are proposed to approximate the metric space while reducing the complexity of similarity computation. Nevertheless, these works are designed based on RNN backend, resulting in a serious performance decline on long trajectories. In this paper, we propose a novel graph-based method, namely TrajGAT, to explicitly model the hierarchical spatial structure and improve the performance of long trajectory similarity computation. TrajGAT consists of two main modules, i.e., graph construction and trajectory encoding. For graph construction, TrajGAT first employs PR quadtree to build the hierarchical structure of the whole spatial area, and then constructs a graph for each trajectory based on the original records and the leaf nodes of the quadtree. For trajectory encoding, we replace the self-attention in Transformer with graph attention and design an encoder to represent the generated graph trajectory. With these two modules, TrajGAT can capture the long-term dependencies of trajectories while reducing the GPU memory usage of Transformer. Our experiments on two real-life datasets show that TrajGAT not only improves the performance on long trajectories but also outperforms the state-of-the-art methods on mixture trajectories significantly.|轨迹相似度计算是时空聚类、预测及异常检测等应用中的核心基础任务。传统相似性度量方法（如动态时间规整DTW和豪斯多夫距离Hausdorff）存在二次计算复杂度问题，难以支撑大规模数据处理。针对这一局限性，学界提出了多种轨迹表示学习技术，在保持度量空间近似性的同时降低相似度计算复杂度。然而现有方法均基于循环神经网络（RNN）架构，导致长轨迹处理性能显著下降。本文提出一种新颖的图神经网络方法TrajGAT，通过显式建模层次化空间结构提升长轨迹相似度计算性能。TrajGAT包含两大核心模块：图构建模块与轨迹编码模块。在图构建阶段，系统首先采用PR四叉树建立全域层次化空间结构，随后基于原始轨迹数据与四叉树叶节点为每条轨迹构建专属图结构。在轨迹编码阶段，我们采用图注意力机制替代Transformer中的自注意力机制，设计出可表征图结构轨迹的编码器。通过这种双模块设计，TrajGAT在捕捉轨迹长期依赖关系的同时显著降低了Transformer的GPU内存占用。在两个真实数据集上的实验表明，TrajGAT不仅在长轨迹处理上性能优越，在混合轨迹场景下也显著超越现有最优方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TrajGAT:+A+Graph-based+Long-term+Dependency+Modeling+Approach+for+Trajectory+Similarity+Computation)|1|
|[A/B Testing Intuition Busters: Common Misunderstandings in Online Controlled Experiments](https://doi.org/10.1145/3534678.3539160)|Ron Kohavi, Alex Deng, Lukas Vermeer|Airbnb Inc, Seattle, WA USA; Kohavi, Los Altos, CA 94024 USA; Vista, Delft, Netherlands|A/B tests, or online controlled experiments, are heavily used in industry to evaluate implementations of ideas. While the statistics behind controlled experiments are well documented and some basic pitfalls known, we have observed some seemingly intuitive concepts being touted, including by A/B tool vendors and agencies, which are misleading, often badly so. Our goal is to describe these misunderstandings, the "intuition" behind them, and to explain and bust that intuition with solid statistical reasoning. We provide recommendations that experimentation platform designers can implement to make it harder for experimenters to make these intuitive mistakes.|A/B测试（又称在线对照实验）在业界被广泛用于评估创意方案的落地效果。尽管对照实验背后的统计学原理已被充分记录，且某些基础认知误区已被察觉，但我们注意到一些看似直观的概念——包括被A/B测试工具供应商和代理机构鼓吹的观点——实际上具有误导性，甚至往往存在严重谬误。本文旨在剖析这些误解及其背后的"直观逻辑"，并通过严谨的统计学论证进行解释与纠偏。我们为实验平台设计者提供可实施的建议方案，以降低实验人员犯此类直觉性错误的风险。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A/B+Testing+Intuition+Busters:+Common+Misunderstandings+in+Online+Controlled+Experiments)|1|
|[Pricing the Long Tail by Explainable Product Aggregation and Monotonic Bandits](https://doi.org/10.1145/3534678.3539142)|Marco Mussi, Gianmarco Genalti, Francesco Trovò, Alessandro Nuara, Nicola Gatti, Marcello Restelli|Politecn Milan, Milan, Italy; ML Cube, Milan, Italy; Politecn Milan, ML Cube, Milan, Italy|In several e-commerce scenarios, pricing long-tail products effectively is a central task for the companies, and there is broad agreement that Artificial Intelligence (AI) will play a prominent role in doing that in the next future. Nevertheless, dealing with long-tail products raises major open technical issues due to data scarcity which preclude the adoption of the mainstream approaches requiring usually a huge amount of data, such as, e.g., deep learning. In this paper, we provide a novel online learning algorithm for dynamic pricing that deals with non-stationary settings due to, e.g., the seasonality or adaptive competitors, and is very efficient in terms of the need for data thanks to assumptions such as, e.g., the monotonicity of the demand curve in the price that are customarily satisfied in long-tail markets. Furthermore, our dynamic pricing algorithm is paired with a clustering algorithm for the long-tail products which aggregates similar products such that the data of all the products of the same cluster are merged and used to choose their best price. We first evaluate our algorithms in an offline synthetic setting, comparing their performance with the state of the art and showing that our algorithms are more robust and data-efficient in long-tail settings. Subsequently, we evaluate our algorithms in an online setting with more than 8,000 products, including popular and long-tail, in an A/B test with humans for about two months. The increase of revenue thanks to our algorithms is about 18% for the popular products and about 90% for the long-tail products.|在多个电子商务场景中，如何为长尾产品有效定价始终是企业的核心任务，业界普遍认为人工智能（AI）将在未来这一领域发挥重要作用。然而，由于长尾产品存在数据稀缺性，处理这类产品会引发重大技术难题——数据匮乏使得需要海量数据支持的主流方法（如深度学习）难以适用。本文提出一种创新的在线学习算法，用于处理因季节性变化或竞争对手策略调整导致的非平稳环境下的动态定价问题；通过引入需求曲线随价格单调变化等长尾市场普遍适用的假设，该算法显著降低了对数据量的需求。此外，我们还将该动态定价算法与长尾产品聚类算法相结合，通过聚合相似产品并将同一聚类中所有产品的数据合并使用，以确定最优定价策略。我们首先在离线模拟环境中评估算法性能，与现有技术对比表明：在长尾场景下，我们的算法具有更强的鲁棒性和数据利用效率。随后，我们开展了为期两个月的在线A/B测试，对包括热门产品和长尾产品在内的8000余件商品进行实证评估。实验结果显示：应用我们的算法后，热门产品收入提升约18%，而长尾产品收入增幅高达约90%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pricing+the+Long+Tail+by+Explainable+Product+Aggregation+and+Monotonic+Bandits)|1|
|[PinnerFormer: Sequence Modeling for User Representation at Pinterest](https://doi.org/10.1145/3534678.3539156)|Nikil Pancha, Andrew Zhai, Jure Leskovec, Charles Rosenberg|Pinterest Inc, San Francisco, CA 94107 USA; |Sequential models have become increasingly popular in powering personalized recommendation systems over the past several years. These approaches traditionally model a user's actions on a website as a sequence to predict the user's next action. While theoretically simplistic, these models are quite challenging to deploy in production, commonly requiring streaming infrastructure to reflect the latest user activity and potentially managing mutable data for encoding a user's hidden state. Here we introduce PinnerFormer, a user representation trained to predict a user's future long-term engagement using a sequential model of a user's recent actions. Unlike prior approaches, we adapt our modeling to a batch infrastructure via our new dense all-action loss, modeling long-term future actions instead of next action prediction. We show that by doing so, we significantly close the gap between batch user embeddings that are generated once a day and realtime user embeddings generated whenever a user takes an action. We describe our design decisions via extensive offline experimentation and ablations and validate the efficacy of our approach in A/B experiments showing substantial improvements in Pinterest's user retention and engagement when comparing PinnerFormer against our previous user representation. PinnerFormer is deployed in production as of Fall 2021.|过去几年中，序列模型在个性化推荐系统中的应用日益广泛。这类方法传统上将用户在网站上的行为建模为序列，以预测用户的下一步行为。虽然理论简洁，但这些模型在实际部署中面临诸多挑战——通常需要流式基础设施来反映最新用户活动，并可能需要管理可变数据以编码用户的隐藏状态。本文推出PinnerFormer，这是一种通过用户近期行为序列模型来预测用户长期参与度的用户表征方法。与现有方法不同，我们通过新型密集全行为损失函数将建模适配至批处理基础设施，重点对长期未来行为而非即时下一步行为进行预测。研究表明，这种方法显著缩小了每日生成一次的批量用户嵌入与用户每次行动时实时生成的用户嵌入之间的性能差距。我们通过大量离线实验和消融分析阐释设计决策，并通过A/B实验验证方法有效性——与原有用户表征相比，PinnerFormer为Pinterest平台的用户留存率和参与度带来显著提升。该模型已于2021年秋季正式投入生产环境部署。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PinnerFormer:+Sequence+Modeling+for+User+Representation+at+Pinterest)|1|
|[Open-Domain Aspect-Opinion Co-Mining with Double-Layer Span Extraction](https://doi.org/10.1145/3534678.3539386)|Mohna Chakraborty, Adithya Kulkarni, Qi Li|Iowa State University, Ames, IA, USA|The aspect-opinion extraction tasks extract aspect terms and opinion terms from reviews. The supervised extraction methods achieve state-of-the-art performance but require large-scale human-annotated training data. Thus, they are restricted for open-domain tasks due to the lack of training data. This work addresses this challenge and simultaneously mines aspect terms, opinion terms, and their correspondence in a joint model. We propose an Open-Domain Aspect-Opinion Co-Mining (ODAO) method with a Double-Layer span extraction framework. Instead of acquiring human annotations, ODAO first generates weak labels for unannotated corpus by employing rules-based on universal dependency parsing. Then, ODAO utilizes this weak supervision to train a double-layer span extraction framework to extract aspect terms (ATE), opinion terms (OTE), and aspect-opinion pairs (AOPE). ODAO applies canonical correlation analysis as an early stopping indicator to avoid the model over-fitting to the noise to tackle the noisy weak supervision. ODAO applies a self-training process to gradually enrich the training data to tackle the weak supervision bias issue. We conduct extensive experiments and demonstrate the power of the proposed ODAO. The results on four benchmark datasets for aspect-opinion co-extraction and pair extraction tasks show that ODAO can achieve competitive or even better performance compared with the state-of-the-art fully supervised methods.|方面意见提取任务从评论中提取方面术语和意见术语。有监督的提取方法取得了最先进的性能，但需要大规模的人工注释的训练数据。因此，由于缺乏训练数据，它们在开放域任务中受到限制。这项工作解决了这个挑战，同时挖掘方面术语，意见术语，以及它们在联合模型中的对应关系。我们提出了一个开放领域的方面-意见共同挖掘(ODAO)方法与双层跨度提取框架。ODAO 不是获取人工注释，而是首先通过使用基于通用依赖解析的规则为未注释的语料库生成弱标签。然后，ODAO 利用这种弱监督训练一个双层跨度提取框架来提取方面术语(ATE)、观点术语(OTE)和方面-观点对(AOPE)。《噪音管制条例》采用典型相关分析作为及早停止的指标，以避免模型过分配合噪音，以对付噪音较大而监管薄弱的情况。ODAO 采用自我训练过程，逐步丰富训练数据，解决监督偏差问题。我们进行了广泛的实验，并演示了所提出的 ODAO 的功能。通过对四个基准数据集的侧面意见协同提取和对提取任务的实验结果表明，ODAO 算法可以获得比现有全监督算法更好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Open-Domain+Aspect-Opinion+Co-Mining+with+Double-Layer+Span+Extraction)|1|
|[Spatio-Temporal Trajectory Similarity Learning in Road Networks](https://doi.org/10.1145/3534678.3539375)|Ziquan Fang, Yuntao Du, Xinjun Zhu, Danlei Hu, Lu Chen, Yunjun Gao, Christian S. Jensen|Aalborg Univ, Aalborg, Denmark; Zhejiang Univ, Hangzhou, Peoples R China; Zhejiang Univ, Ningbo, Peoples R China|Deep learning based trajectory similarity computation holds the potential for improved efficiency and adaptability over traditional similarity computation. However, existing learning-based trajectory similarity learning solutions prioritize spatial similarity over temporal similarity, making them suboptimal for time-aware analyses. To this end, we propose ST2Vec, a representation learning based solution that considers fine-grained spatial and temporal relations between trajectories to enable spatio-temporal similarity computation in road networks. Specifically, ST2Vec encompasses two steps: (i) spatial and temporal modeling that encode spatial and temporal information of trajectories, where a generic temporal modeling module is proposed for the first time; and (ii) spatio-temporal co-attention fusion, where two fusion strategies are designed to enable the generation of unified spatio-temporal embeddings of trajectories. Further, under the guidance of triplet loss, ST2Vec employs curriculum learning in model optimization to improve convergence and effectiveness. An experimental study offers evidence that ST2Vec outperforms state-of-the-art competitors substantially in terms of effectiveness and efficiency, while showing low parameter sensitivity and good model robustness. Moreover, similarity involved case studies including top-k querying and DBSCAN clustering offer further insight into the capabilities of ST2Vec.|基于深度学习的轨迹相似度计算有望比传统相似度计算方法提升效率与适应性。然而现有基于学习的轨迹相似度解决方案往往侧重空间相似性而忽视时间相似性，导致其在时间敏感分析中表现欠佳。为此，我们提出ST2Vec——一种基于表征学习的解决方案，通过细粒度捕捉轨迹间的时空关联关系，实现路网环境下的时空相似度计算。具体而言，ST2Vec包含两个核心步骤：(i) 时空建模阶段首次提出通用时序建模模块，对轨迹的空间与时间信息进行编码；(ii) 时空协同注意力融合阶段设计两种融合策略，生成统一的轨迹时空嵌入向量。在三元组损失函数的指导下，该模型采用课程学习策略进行优化以提升收敛速度与效果。实验研究表明，ST2Vec在效果与效率方面显著优于现有先进方案，同时展现出较低的参数敏感度和良好的模型鲁棒性。此外，通过top-k查询和DBSCAN聚类等涉及相似度计算的案例研究，进一步验证了ST2Vec的实际应用能力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spatio-Temporal+Trajectory+Similarity+Learning+in+Road+Networks)|1|
|[Detecting Cash-out Users via Dense Subgraphs](https://doi.org/10.1145/3534678.3539252)|Yingsheng Ji, Zheng Zhang, Xinlei Tang, Jiachen Shen, Xi Zhang, Guangwen Yang|Tsinghua Univ, Beijing, Peoples R China; Beijing University of Posts and Telecommunications, Beijing, China; China Etek Serv & Technol, Shanghai, Peoples R China|Cash-out fraud refers to the withdrawal of cash from a credit card by illegitimate payments with merchants. Conventional data-driven approaches for cash-out detection commonly construct a classifier with domain specific feature engineering. To further spot cash-out behaviors in complex scenarios, recent efforts adopt graph models to exploit the interaction relations rich in financial transactions. However, most existing graph-based methods are proposed for online payment activities in internet financial institutions. Moreover, these methods commonly rely on a large amount of online user data, which are not well suitable for the traditional credit card services in commercial banks. In this paper, we focus on discerning fraudulent cash-out users by taking advantage of only the personal credit card data from banks. To alleviate the scarcity of available labeled data, we formulate the cash-out detection problem as identifying dense blocks. First, we define a bipartite multigraph to hold transactions between users and merchants, where cash-out activities generate cyclically intensive and high-volume flows. Second, we give a formal definition of cash-out behaviors from four perspectives: time, capital, cyclicity, and topotaxy. Then, we develop ANTICO, with a class of metrics to capture suspicious signals of the activities and a greedy algorithm to spot suspicious blocks by optimizing the proposed metric. Theoretical analysis shows a provable upper bound of ANTICO on the effectiveness of detecting cash-out users. Experimental results show that ANTICO outperforms state-of-the-art methods in accurately detecting cash-out users on both synthetic and real-world banking data.|套现欺诈指通过非法商户交易进行信用卡资金套取的行为。传统数据驱动检测方法通常需依赖领域特定的特征工程来构建分类器。为应对复杂场景下的套现行为识别，近期研究开始采用图模型挖掘金融交易中丰富的交互关系。然而现有图方法多针对互联网金融平台的线上支付活动设计，且严重依赖大量线上用户数据，难以适用于商业银行传统信用卡业务场景。本文聚焦于仅利用银行个人信用卡数据识别欺诈性套现用户。为缓解标注数据稀缺问题，我们将套现检测任务形式化为稠密块识别问题：首先构建用户-商户二分多重图建模交易关系，其中套现行为会形成周期性密集大额资金流；继而从时间、资金、周期性和拓扑结构四个维度给出套现行为的形式化定义；随后提出ANTICO模型，通过设计综合指标捕捉可疑活动信号，并采用贪心算法优化指标以定位可疑区块。理论分析证明ANTICO在检测效果上具有可证明的上界。实验结果表明，在合成与真实银行数据上，ANTICO在套现用户检测准确率方面均优于现有先进方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Detecting+Cash-out+Users+via+Dense+Subgraphs)|1|
|[Semantic Enhanced Text-to-SQL Parsing via Iteratively Learning Schema Linking Graph](https://doi.org/10.1145/3534678.3539294)|Aiwei Liu, Xuming Hu, Li Lin, Lijie Wen|Tsinghua Univ, Beijing, Peoples R China|The generalizability to new databases is of vital importance to Text-to-SQL systems which aim to parse human utterances into SQL statements. Existing works achieve this goal by leveraging the exact matching method to identify the lexical matching between the question words and the schema items. However, these methods fail in other challenging scenarios, such as the synonym substitution in which the surface form differs between the corresponding question words and schema items. In this paper, we propose a framework named ISESL-SQL to iteratively build a semantic enhanced schema-linking graph between question tokens and database schemas. First, we extract a schema linking graph from PLMs through a probing procedure in an unsupervised manner. Then the schema linking graph is further optimized during the training process through a deep graph learning method. Meanwhile, we also design an auxiliary task called graph regularization to improve the schema information mentioned in the schema-linking graph. Extensive experiments on three benchmarks demonstrate that ISESL-SQL could consistently outperform the baselines and further investigations show its generalizability and robustness.|文本转SQL系统旨在将人类自然语言解析为SQL语句，其对新数据库的泛化能力至关重要。现有研究通过精确匹配方法识别问题词与模式项之间的词汇匹配来实现这一目标，但该方法在对应问题词与模式项存在表层形式差异（如同义词替换）等挑战性场景中表现不佳。本文提出ISESL-SQL框架，通过迭代式构建问题词与数据库模式间的语义增强模式链接图。首先以无监督方式通过探针过程从预训练语言模型中提取模式链接图，随后通过深度图学习方法在训练过程中持续优化该图结构。同时，我们设计了图正则化辅助任务以增强模式链接图中提及的模式信息。在三个基准测试上的大量实验表明，ISESL-SQL能够持续超越基线模型，进一步研究验证了其良好的泛化能力和鲁棒性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Semantic+Enhanced+Text-to-SQL+Parsing+via+Iteratively+Learning+Schema+Linking+Graph)|1|
|[Semi-supervised Drifted Stream Learning with Short Lookback](https://doi.org/10.1145/3534678.3539297)|Weijieying Ren, Pengyang Wang, Xiaolin Li, Charles E. Hughes, Yanjie Fu|Nanjing Univ, Nanjing, Peoples R China; Univ Macau, Macau, Peoples R China; Univ Cent Florida, Orlando, FL 32816 USA|In many scenarios, 1) data streams are generated in real time; 2) labeled data are expensive and only limited labels are available in the beginning; 3) real-world data is not always i.i.d. and data drift over time gradually; 4) the storage of historical streams is limited. This learning setting limits the applicability and availability of many Machine Learning (ML) algorithms. We generalize the learning task under such setting as a semi-supervised drifted stream learning with short lookback problem (SDSL). SDSL imposes two under-addressed challenges on existing methods in semi-supervised learning and continuous learning: 1) robust pseudo-labeling under gradual shifts and 2) anti-forgetting adaptation with short lookback. To tackle these challenges, we propose a principled and generic generation-replay framework to solve SDSL. To achieve robust pseudo-labeling, we develop a novel pseudo-label classification model to leverage supervised knowledge of previously labeled data, unsupervised knowledge of new data, and, structure knowledge of invariant label semantics. To achieve adaptive anti-forgetting model replay, we propose to view the anti-forgetting adaptation task as a flat region search problem. We propose a novel minimax game-based replay objective function to solve the flat region search problem and develop an effective optimization solver. Experimental results demonstrate the effectiveness of the proposed method.|在许多应用场景中，1) 数据流实时生成；2) 标注数据成本高昂且初始阶段仅能获取有限标签；3) 现实数据并非始终满足独立同分布假设，且会随时间逐渐发生漂移；4) 历史数据流的存储能力受限。这种学习设定限制了许多机器学习算法的适用性与可用性。我们将此类设定下的学习任务归纳为"短时回溯的半监督漂移流学习"问题（SDSL）。该问题为现存的半监督学习与持续学习方法带来两个尚未得到充分解决的挑战：1) 渐变漂移下的鲁棒伪标注生成；2) 短时回溯约束的抗遗忘自适应。为应对这些挑战，我们提出一个基于生成-回放机制的通用理论框架。为实现鲁棒伪标注，我们开发了一种新型伪标注分类模型，该模型融合三类知识：已标注数据的监督知识、新数据的无监督知识，以及不变标签语义的结构化知识。针对抗遗忘自适应回放，我们将该任务转化为平坦区域搜索问题，提出基于极小极大博弈的新型回放目标函数，并开发了高效优化求解器。实验结果验证了所提方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Semi-supervised+Drifted+Stream+Learning+with+Short+Lookback)|1|
|[State Dependent Parallel Neural Hawkes Process for Limit Order Book Event Stream Prediction and Simulation](https://doi.org/10.1145/3534678.3539462)|Zijian Shi, John Cartlidge|Univ Bristol, Bristol, Avon, England|The majority of trading in financial markets is executed through a limit order book (LOB). The LOB is an event-based continuously-updating system that records contemporaneous demand (`bids' to buy) and supply (`asks' to sell) for a financial asset. Following recent successes in the literature that combine stochastic point processes with neural networks to model event stream patterns, we propose a novel state-dependent parallel neural Hawkes process to predict LOB events and simulate realistic LOB data. The model is characterized by: (1) separate intensity rate modelling for each event type through a parallel structure of continuous time LSTM units; and (2) an event-state interaction mechanism that improves prediction accuracy and enables efficient sampling of the event-state stream. We first demonstrate the superiority of the proposed model over traditional stochastic or deep learning models for predicting event type and time of a real world LOB dataset. Using stochastic point sampling from a well trained model, we then develop a realistic deep learning-based LOB simulator that exhibits multiple stylized facts found in real LOB data.|金融市场中的交易主要通过限价订单簿（LOB）执行。LOB是一种基于事件的持续更新系统，记录金融资产当前的需求（买入"报价"）与供给（卖出"要价"）。近年来学界成功将随机点过程与神经网络结合以建模事件流模式，基于此我们提出一种新颖的状态依赖型并行神经霍克斯过程，用于预测LOB事件并生成逼真的LOB数据。该模型具有两大特征：（1）通过并行连续时间LSTM单元结构，为每种事件类型建立独立的强度率模型；（2）采用事件-状态交互机制，既提升预测精度又实现事件-状态流的高效采样。我们首先证明该模型在预测真实LOB数据集的事件类型和发生时间方面，优于传统随机模型或深度学习模型。通过从训练完善的模型中进行随机点采样，我们进一步开发出基于深度学习的逼真LOB模拟器，该模拟器呈现出真实LOB数据中存在的多重典型特征。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=State+Dependent+Parallel+Neural+Hawkes+Process+for+Limit+Order+Book+Event+Stream+Prediction+and+Simulation)|1|
|[Improving Data-driven Heterogeneous Treatment Effect Estimation Under Structure Uncertainty](https://doi.org/10.1145/3534678.3539444)|Christopher Tran, Elena Zheleva|Univ Illinois, Chicago, IL 60607 USA|Estimating how a treatment affects units individually, known as heterogeneous treatment effect (HTE) estimation, is an essential part of decision-making and policy implementation. The accumulation of large amounts of data in many domains, such as healthcare and e-commerce, has led to increased interest in developing data-driven algorithms for estimating heterogeneous effects from observational and experimental data. However, these methods often make strong assumptions about the observed features and ignore the underlying causal model structure, which can lead to biased HTE estimation. At the same time, accounting for the causal structure of real-world data is rarely trivial since the causal mechanisms that gave rise to the data are typically unknown. To address this problem, we develop a feature selection method that considers each feature's value for HTE estimation and learns the relevant parts of the causal structure from data. We provide strong empirical evidence that our method improves existing data-driven HTE estimation methods under arbitrary underlying causal structures. Our results on synthetic, semi-synthetic, and real-world datasets show that our feature selection algorithm leads to lower HTE estimation error.|估计处理对个体单元的影响，即异质性处理效应（HTE）估计，是决策和政策实施的关键环节。随着医疗健康和电子商务等领域大规模数据的积累，利用观察性和实验性数据开发数据驱动的异质性效应估计算法受到日益广泛的关注。然而这些方法通常对观测特征做出强假设，且忽略底层因果模型结构，可能导致HTE估计出现偏差。与此同时，由于生成数据的因果机制通常未知，处理现实世界数据的因果结构往往具有挑战性。针对这一问题，我们开发了一种特征选择方法，该方法综合考虑每个特征对HTE估计的价值，并从数据中学习因果结构的相关部分。我们提供了强有力的实证证据，表明在任意底层因果结构下，我们的方法能改进现有数据驱动的HTE估计方法。通过在合成数据、半合成数据和真实数据集上的实验验证，我们的特征选择算法显著降低了HTE估计误差。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Data-driven+Heterogeneous+Treatment+Effect+Estimation+Under+Structure+Uncertainty)|1|
|[Variational Graph Author Topic Modeling](https://doi.org/10.1145/3534678.3539310)|Delvin Ce Zhang, Hady Wirawan Lauw|Singapore Management Univ, Singapore, Singapore|While Variational Graph Auto-Encoder (VGAE) has presented promising ability to learn representations for documents, most existing VGAE methods do not model a latent topic structure and therefore lack semantic interpretability. Exploring hidden topics within documents and discovering key words associated with each topic allow us to develop a semantic interpretation of the corpus. Moreover, documents are usually associated with authors. For example, news reports have journalists specializing in writing certain type of events, academic papers have authors with expertise in certain research topics, etc. Modeling authorship information could benefit topic modeling, since documents by the same authors tend to reveal similar semantics. This observation also holds for documents published on the same venues. However, most topic models ignore the auxiliary authorship and publication venues. Given above two challenges, we propose a Variational Graph Author Topic Model for documents to integrate both semantic interpretability and authorship and venue modeling into a unified VGAE framework. For authorship and venue modeling, we construct a hierarchical multi-layered document graph with both intra- and cross-layer topic propagation. For semantic interpretability, three word relations (contextual, syntactic, semantic) are modeled and constitute three word sub-layers in the document graph. We further propose three alternatives for variational divergence. Experiments verify the effectiveness of our model on supervised and unsupervised tasks.|尽管变分图自编码器（VGAE）在文档表征学习方面展现出强大能力，但现有方法大多未对潜在主题结构建模，导致语义可解释性不足。通过挖掘文档中的隐藏主题并识别各主题关联关键词，可实现语料库的语义解析。此外，文档通常与作者相关联——新闻报道由专攻特定事件类型的记者撰写，学术论文的作者则深耕特定研究领域。由于同一作者的文档往往呈现相似语义特征，作者信息建模有助于提升主题建模效果，这一规律同样适用于同一发布场所的文档。然而现有主题模型普遍忽略作者与发布场所这类辅助信息。

针对上述两个挑战，我们提出面向文档的变分图作者主题模型，将语义可解释性、作者及发布场所建模统一整合至VGAE框架中。在作者与场所建模方面，我们构建了具有层内与跨层主题传播的分层多文档图；在语义可解释性方面，通过建模三种词关系（上下文、句法、语义）构建文档图中的三个词子层。我们进一步提出三种变分散度的替代方案。实验结果表明，该模型在监督与非监督任务中均具有卓越性能。

（注：根据学术翻译规范，对以下术语进行标准化处理：
- Variational Graph Auto-Encoder → 变分图自编码器
- semantic interpretability → 语义可解释性
- topic propagation → 主题传播
- variational divergence → 变分散度
- supervised/unsupervised tasks → 监督/非监督任务
保留专业缩写VGAE，采用中文学术文献常用的四字结构表达）|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Variational+Graph+Author+Topic+Modeling)|1|
|[Alexa Teacher Model: Pretraining and Distilling Multi-Billion-Parameter Encoders for Natural Language Understanding Systems](https://doi.org/10.1145/3534678.3539173)|Jack FitzGerald, Shankar Ananthakrishnan, Konstantine Arkoudas, Davide Bernardi, Abhishek Bhagia, Claudio Delli Bovi, Jin Cao, Rakesh Chada, Amit Chauhan, Luoxin Chen, Anurag Dwarakanath, Satyam Dwivedi, Turan Gojayev, Karthik Gopalakrishnan, Thomas Gueudré, Dilek HakkaniTur, Wael Hamza, Jonathan J. Hüser, Kevin Martin Jose, Haidar Khan, Beiye Liu, Jianhua Lu, Alessandro Manzotti, Pradeep Natarajan, Karolina Owczarzak, Gokmen Oz, Enrico Palumbo, Charith Peris, Chandana Satya Prakash, Stephen Rawls, Andy Rosenbaum, Anjali Shenoy, Saleh Soltan, Mukund Harakere Sridhar, Lizhen Tan, Fabian Triefenbach, Pan Wei, Haiyang Yu, Shuai Zheng, Gökhan Tür, Prem Natarajan|Spotify, Turin, Italy; Amazon, Santa Clara, CA USA; Amazon, Aachen, Germany; Amazon, Cambridge, MA USA; Amazon, Seattle, WA USA; Amazon, Los Angeles, CA USA; Amazon, Bangalore, Karnataka, India; Amazon, Sunnyvale, CA USA; Amazon, Turin, Italy; Amazon, New York, NY USA; Amazon, Denver, CO 80216 USA; Amazon, Chicago, IL USA|We present results from a large-scale experiment on pretraining encoders with non-embedding parameter counts ranging from 700M to 9.3B, their subsequent distillation into smaller models ranging from 17M-170M parameters, and their application to the Natural Language Understanding (NLU) component of a virtual assistant system. Though we train using 70% spoken-form data, our teacher models perform comparably to XLM-R and mT5 when evaluated on the written-form Cross-lingual Natural Language Inference (XNLI) corpus. We perform a second stage of pretraining on our teacher models using in-domain data from our system, improving error rates by 3.86% relative for intent classification and 7.01% relative for slot filling. We find that even a 170M-parameter model distilled from our Stage 2 teacher model has 2.88% better intent classification and 7.69% better slot filling error rates when compared to the 2.3B-parameter teacher trained only on public data (Stage 1), emphasizing the importance of in-domain data for pretraining. When evaluated offline using labeled NLU data, our 17M-parameter Stage 2 distilled model outperforms both XLM-R Base (85M params) and DistillBERT (42M params) by 4.23% to 6.14%, respectively. Finally, we present results from a full virtual assistant experimentation platform, where we find that models trained using our pretraining and distillation pipeline outperform models distilled from 85M-parameter teachers by 3.74%-4.91% on an automatic measurement of full-system user dissatisfaction.|我们在一项大规模实验中展示了以下成果：使用参数量（非嵌入参数）从7亿到93亿不等的编码器进行预训练，随后将其蒸馏为参数量介于1700万至1.7亿的小型模型，并应用于虚拟助手系统的自然语言理解（NLU）组件。尽管训练数据中70%为口语形式，我们的教师模型在书面形式的跨语言自然语言推理（XNLI）语料库评估中表现与XLM-R和mT5相当。通过使用系统内领域数据对教师模型进行第二阶段预训练，意图分类错误率相对降低3.86%，槽填充错误率相对降低7.01%。研究发现，与仅使用公开数据训练的第一阶段23亿参数教师模型相比，从第二阶段教师模型蒸馏得到的1.7亿参数模型在意图分类错误率上降低2.88%，槽填充错误率降低7.69%，这突显了领域内数据对预训练的重要性。在使用标注NLU数据进行的离线评估中，我们的1700万参数第二阶段蒸馏模型比XLM-R Base（8500万参数）和DistillBERT（4200万参数）分别高出4.23%和6.14%。最后，在完整虚拟助手实验平台上的测试表明：通过我们的预训练与蒸馏流程训练的模型，在全系统用户不满意度的自动测量中，比从8500万参数教师模型蒸馏的模型表现优3.74%-4.91%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Alexa+Teacher+Model:+Pretraining+and+Distilling+Multi-Billion-Parameter+Encoders+for+Natural+Language+Understanding+Systems)|1|
|[Augmenting Log-based Anomaly Detection Models to Reduce False Anomalies with Human Feedback](https://doi.org/10.1145/3534678.3539106)|Tong Jia, Ying Li, Yong Yang, Gang Huang, Zhonghai Wu|Peking Univ, Adv Inst Big Data, Beijing, Peoples R China; Peking Univ, Beijing, Peoples R China|With the increasing complexity of modern software systems, it is essential yet hard to detect anomalies and diagnose problems precisely. Existing log-based anomaly detection approaches rely on a few key assumptions on system logs and perform well in some experimental systems. However, real-world industrial systems are often with poor logging quality, in which system logs are noisy and often violate the assumptions of existing approaches. This makes these approaches inefficient. This paper first conducts a comprehensive study on the system logs of three large-scale industrial software systems. Through the study, we identify four typical anti-patterns that affect the detection results the most. Based on these patterns, we propose HiLog, an effective human-in-the-loop log-based anomaly detection approach that integrates human knowledge to augment anomaly detection models. With little human labeling effort, our approach can significantly improve the effectiveness of existing models. Experiment results on three large-scale industrial software systems show that our method improves over 50% precision rate on average.|随着现代软件系统日益复杂，精确检测异常和诊断问题变得至关重要却也更加困难。现有的基于日志的异常检测方法依赖于对系统日志的若干关键假设，在部分实验系统中表现良好。然而，现实工业系统往往存在日志质量不佳的问题，系统日志存在噪声且经常违反现有方法的假设条件，导致这些方法效率低下。本文首先对三个大型工业软件系统的日志进行全面研究，通过分析确定了四种对检测结果影响最大的典型反模式。基于这些模式，我们提出HiLog——一种有效的人机协同日志异常检测方法，通过融入人类知识来增强异常检测模型。该方法仅需少量人工标注即可显著提升现有模型效能。在三个大型工业软件系统上的实验结果表明，我们的方法平均将检测精确率提升了50%以上。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Augmenting+Log-based+Anomaly+Detection+Models+to+Reduce+False+Anomalies+with+Human+Feedback)|1|
|[DNA-Stabilized Silver Nanocluster Design via Regularized Variational Autoencoders](https://doi.org/10.1145/3534678.3539032)|Fariha Moomtaheen, Matthew Killeen, James T. Oswald, Anna GonzàlezRosell, Peter Mastracco, Alexander Gorovits, Stacy M. Copp, Petko Bogdanov||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DNA-Stabilized+Silver+Nanocluster+Design+via+Regularized+Variational+Autoencoders)|1|
|[Amazon SageMaker Model Monitor: A System for Real-Time Insights into Deployed Machine Learning Models](https://doi.org/10.1145/3534678.3539145)|David Nigenda, Zohar Karnin, Muhammad Bilal Zafar, Raghu Ramesha, Alan Tan, Michele Donini, Krishnaram Kenthapadi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Amazon+SageMaker+Model+Monitor:+A+System+for+Real-Time+Insights+into+Deployed+Machine+Learning+Models)|1|
|[A Graph Learning Based Framework for Billion-Scale Offline User Identification](https://doi.org/10.1145/3534678.3539191)|Daixin Wang, Zujian Weng, Zhengwei Wu, Zhiqiang Zhang, Peng Cui, Hongwei Zhao, Jun Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Graph+Learning+Based+Framework+for+Billion-Scale+Offline+User+Identification)|1|
|[Learning Large-scale Subsurface Simulations with a Hybrid Graph Network Simulator](https://doi.org/10.1145/3534678.3539045)|Tailin Wu, Qinchen Wang, Yinan Zhang, Rex Ying, Kaidi Cao, Rok Sosic, Ridwan Jalali, Hassan Hamam, Marko Maucec, Jure Leskovec||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Large-scale+Subsurface+Simulations+with+a+Hybrid+Graph+Network+Simulator)|1|
|[User Engagement in Mobile Health Applications](https://doi.org/10.1145/3534678.3542681)|Babaniyi Yusuf Olaniyi, Ana Fernández del Río, África Periáñez, Lauren Bellhouse||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=User+Engagement+in+Mobile+Health+Applications)|1|
|[Advances in Exploratory Data Analysis, Visualisation and Quality for Data Centric AI Systems](https://doi.org/10.1145/3534678.3542604)|Hima Patel, Shanmukha C. Guttula, Ruhi Sharma Mittal, Naresh Manwani, Laure BertiÉquille, Abhijit Manatkar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Advances+in+Exploratory+Data+Analysis,+Visualisation+and+Quality+for+Data+Centric+AI+Systems)|1|
|[Submodular Feature Selection for Partial Label Learning](https://doi.org/10.1145/3534678.3539292)|WeiXuan Bao, JunYi Hang, MinLing Zhang|Southeast University & Key Laboratory of Computer Network and Information Integration (Southeast University), Ministry of Education, Nanjing, China|Partial label learning induces a multi-class classifier from training examples each associated with a candidate label set where the ground-truth label is concealed. Feature selection improves the generalization ability of learning system via selecting essential features for classification from the original feature set, while the task of partial label feature selection is challenging due to ambiguous labeling information. In this paper, the first attempt towards partial label feature selection is investigated via mutual-information-based dependency maximization. Specifically, the proposed approach SAUTE iteratively maximizes the dependency between selected features and labeling information, where the value of mutual information is estimated from confidence-based latent variable inference. In each iteration, the near-optimal features are selected greedily according to properties of submodular mutual information function, while the density of latent label variable is inferred with the help of updated labeling confidences over candidate labels by resorting to kNN aggregation in the induced lower-dimensional feature space. Extensive experiments over synthetic as well as real-world partial label data sets show that the generalization ability of well-established partial label learning algorithms can be significantly improved after coupling with the proposed feature selection approach.|部分标签学习从训练样本中归纳出一个多类分类器，每个样本与一个隐藏地面真实标签的候选标签集相关联。特征选择通过从原始特征集中选择分类所需的基本特征来提高学习系统的泛化能力，而部分标记特征选择则由于标记信息不明确而面临挑战。本文首次研究了基于互信息的依赖最大化方法在部分标签特征选择中的应用。特别地，提出的方法 SAUTE 迭代地最大化选择的特征和标记信息之间的依赖性，其中互信息的价值是估计基于置信度的潜变量推断。在每次迭代中，根据子模互信息函数的性质贪婪地选择接近最优的特征，利用诱导的低维特征空间中的 kNN 聚集，借助候选标签上更新的标签置信度推断潜在标签变量的密度。通过对合成和实际部分标签数据集的大量实验表明，与所提出的特征选择方法相结合，可以显著提高已有部分标签学习算法的泛化能力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Submodular+Feature+Selection+for+Partial+Label+Learning)|1|
|[Practical Lossless Federated Singular Vector Decomposition over Billion-Scale Data](https://doi.org/10.1145/3534678.3539402)|Di Chai, Leye Wang, Junxue Zhang, Liu Yang, Shuowei Cai, Kai Chen, Qiang Yang|Hong Kong University of Science and Technology, Hong Kong, China; Peking University, Beijing, China|With the enactment of privacy-preserving regulations, e.g., GDPR, federated SVD is proposed to enable SVD-based applications over different data sources without revealing the original data. However, many SVD-based applications cannot be well supported by existing federated SVD solutions. The crux is that these solutions, adopting either differential privacy (DP) or homomorphic encryption (HE), suffer from accuracy loss caused by unremovable noise or degraded efficiency due to inflated data. In this paper, we propose FedSVD, a practical lossless federated SVD method over billion-scale data, which can simultaneously achieve lossless accuracy and high efficiency. At the heart of FedSVD is a lossless matrix masking scheme delicately designed for SVD: 1) While adopting the masks to protect private data, FedSVD completely removes them from the final results of SVD to achieve lossless accuracy; and 2) As the masks do not inflate the data, FedSVD avoids extra computation and communication overhead during the factorization to maintain high efficiency. Experiments with real-world datasets show that FedSVD is over 10000x faster than the HE-based method and has 10 orders of magnitude smaller error than the DP-based solution (ε=0.1, δ=0.1) on SVD tasks. We further build and evaluate FedSVD over three real-world applications: principal components analysis (PCA), linear regression (LR), and latent semantic analysis (LSA), to show its superior performance in practice. On federated LR tasks, compared with two state-of-the-art solutions: FATE [17] and SecureML [19], FedSVD-LR is 100x faster than SecureML and 10x faster than FATE.|随着 GDPR 等隐私保护规则的制定，联邦奇异值分解被提出，以使基于奇异值分解的应用能够在不同数据源之间进行而不暴露原始数据。然而，现有的联邦 SVD 解决方案不能很好地支持许多基于 SVD 的应用程序。问题的关键是，这些解决方案，无论是采用差分隐私(DP)或同态加密(HE) ，都会受到不可去除的噪声或因数据膨胀而导致效率降低所造成的精度损失。在本文中，我们提出了 FedSVD，一种实用的无损联邦 SVD 方法，它可以同时达到无损精度和高效率。FedSVD 的核心是一种为 SVD 精心设计的无损矩阵掩蔽方案: 1)在采用掩蔽保护私有数据的同时，FedSVD 从 SVD 的最终结果中完全去除掩蔽，以实现无损精度; 2)由于掩蔽不会使数据膨胀，FedSVD 避免了因子分解过程中的额外计算和通信开销，保持了高效率。实际数据集的实验表明，在奇异值分解任务中，FedSVD 比基于 HE 的方法快10000倍以上，并且比基于 DP 的方法(ε = 0.1，δ = 0.1)误差小10数量级。我们进一步构建和评估 FedSVD 在三个现实世界中的应用: 主成分分析(PCA)、线性回归分析(LR)和潜在语义学分析(LSA) ，以显示其在实践中的卓越性能。在联邦 LR 任务上，与 FATE [17]和 SecureML [19]这两种最先进的解决方案相比，FedSVD-LR 比 SecureML 快100倍，比 FATE 快10倍。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Practical+Lossless+Federated+Singular+Vector+Decomposition+over+Billion-Scale+Data)|1|
|[Efficient Join Order Selection Learning with Graph-based Representation](https://doi.org/10.1145/3534678.3539303)|Jin Chen, Guanyu Ye, Yan Zhao, Shuncheng Liu, Liwei Deng, Xu Chen, Rui Zhou, Kai Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Join+Order+Selection+Learning+with+Graph-based+Representation)|1|
|[RLogic: Recursive Logical Rule Learning from Knowledge Graphs](https://doi.org/10.1145/3534678.3539421)|Kewei Cheng, Jiahao Liu, Wei Wang, Yizhou Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RLogic:+Recursive+Logical+Rule+Learning+from+Knowledge+Graphs)|1|
|[TARNet: Task-Aware Reconstruction for Time-Series Transformer](https://doi.org/10.1145/3534678.3539329)|Ranak Roy Chowdhury, Xiyuan Zhang, Jingbo Shang, Rajesh K. Gupta, Dezhi Hong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TARNet:+Task-Aware+Reconstruction+for+Time-Series+Transformer)|1|
|[Sufficient Vision Transformer](https://doi.org/10.1145/3534678.3539322)|Zhi Cheng, Xiu Su, Xueyu Wang, Shan You, Chang Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sufficient+Vision+Transformer)|1|
|[Collaboration Equilibrium in Federated Learning](https://doi.org/10.1145/3534678.3539237)|Sen Cui, Jian Liang, Weishen Pan, Kun Chen, Changshui Zhang, Fei Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Collaboration+Equilibrium+in+Federated+Learning)|1|
|[Robust Event Forecasting with Spatiotemporal Confounder Learning](https://doi.org/10.1145/3534678.3539427)|Songgaojun Deng, Huzefa Rangwala, Yue Ning||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Event+Forecasting+with+Spatiotemporal+Confounder+Learning)|1|
|[Robust Inverse Framework using Knowledge-guided Self-Supervised Learning: An application to Hydrology](https://doi.org/10.1145/3534678.3539448)|Rahul Ghosh, Arvind Renganathan, Kshitij Tayal, Xiang Li, Ankush Khandelwal, Xiaowei Jia, Christopher J. Duffy, John Nieber, Vipin Kumar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Inverse+Framework+using+Knowledge-guided+Self-Supervised+Learning:+An+application+to+Hydrology)|1|
|[Core-periphery Partitioning and Quantum Annealing](https://doi.org/10.1145/3534678.3539261)|Catherine F. Higham, Desmond J. Higham, Francesco Tudisco||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Core-periphery+Partitioning+and+Quantum+Annealing)|1|
|[Few-Shot Fine-Grained Entity Typing with Automatic Label Interpretation and Instance Generation](https://doi.org/10.1145/3534678.3539443)|Jiaxin Huang, Yu Meng, Jiawei Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Few-Shot+Fine-Grained+Entity+Typing+with+Automatic+Label+Interpretation+and+Instance+Generation)|1|
|[Global Self-Attention as a Replacement for Graph Convolution](https://doi.org/10.1145/3534678.3539296)|Md. Shamim Hussain, Mohammed J. Zaki, Dharmashankar Subramanian||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Global+Self-Attention+as+a+Replacement+for+Graph+Convolution)|1|
|[JuryGCN: Quantifying Jackknife Uncertainty on Graph Convolutional Networks](https://doi.org/10.1145/3534678.3539286)|Jian Kang, Qinghai Zhou, Hanghang Tong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=JuryGCN:+Quantifying+Jackknife+Uncertainty+on+Graph+Convolutional+Networks)|1|
|[Graph Rationalization with Environment-based Augmentations](https://doi.org/10.1145/3534678.3539347)|Gang Liu, Tong Zhao, Jiaxin Xu, Tengfei Luo, Meng Jiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Rationalization+with+Environment-based+Augmentations)|1|
|[Graph-in-Graph Network for Automatic Gene Ontology Description Generation](https://doi.org/10.1145/3534678.3539258)|Fenglin Liu, Bang Yang, Chenyu You, Xian Wu, Shen Ge, Adelaide Woicik, Sheng Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph-in-Graph+Network+for+Automatic+Gene+Ontology+Description+Generation)|1|
|[Geometer: Graph Few-Shot Class-Incremental Learning via Prototype Representation](https://doi.org/10.1145/3534678.3539280)|Bin Lu, Xiaoying Gan, Lina Yang, Weinan Zhang, Luoyi Fu, Xinbing Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Geometer:+Graph+Few-Shot+Class-Incremental+Learning+via+Prototype+Representation)|1|
|[Spatio-Temporal Graph Few-Shot Learning with Cross-City Knowledge Transfer](https://doi.org/10.1145/3534678.3539281)|Bin Lu, Xiaoying Gan, Weinan Zhang, Huaxiu Yao, Luoyi Fu, Xinbing Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spatio-Temporal+Graph+Few-Shot+Learning+with+Cross-City+Knowledge+Transfer)|1|
|[Learning Differential Operators for Interpretable Time Series Modeling](https://doi.org/10.1145/3534678.3539245)|Yingtao Luo, Chang Xu, Yang Liu, Weiqing Liu, Shun Zheng, Jiang Bian||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Differential+Operators+for+Interpretable+Time+Series+Modeling)|1|
|[Core-periphery Models for Hypergraphs](https://doi.org/10.1145/3534678.3539272)|Marios Papachristou, Jon M. Kleinberg||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Core-periphery+Models+for+Hypergraphs)|1|
|[Synthesising Audio Adversarial Examples for Automatic Speech Recognition](https://doi.org/10.1145/3534678.3539268)|Xinghua Qu, Pengfei Wei, Mingyong Gao, Zhu Sun, Yew Soon Ong, Zejun Ma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Synthesising+Audio+Adversarial+Examples+for+Automatic+Speech+Recognition)|1|
|[On Missing Labels, Long-tails and Propensities in Extreme Multi-label Classification](https://doi.org/10.1145/3534678.3539466)|Erik Schultheis, Marek Wydmuch, Rohit Babbar, Krzysztof Dembczynski||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Missing+Labels,+Long-tails+and+Propensities+in+Extreme+Multi-label+Classification)|1|
|[ERNet: Unsupervised Collective Extraction and Registration in Neuroimaging Data](https://doi.org/10.1145/3534678.3539227)|Yao Su, Zhentian Qian, Lifang He, Xiangnan Kong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ERNet:+Unsupervised+Collective+Extraction+and+Registration+in+Neuroimaging+Data)|1|
|[Towards an Optimal Asymmetric Graph Structure for Robust Semi-supervised Node Classification](https://doi.org/10.1145/3534678.3539332)|Zixing Song, Yifei Zhang, Irwin King||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+an+Optimal+Asymmetric+Graph+Structure+for+Robust+Semi-supervised+Node+Classification)|1|
|[Stabilizing Voltage in Power Distribution Networks via Multi-Agent Reinforcement Learning with Transformer](https://doi.org/10.1145/3534678.3539480)|Minrui Wang, Mingxiao Feng, Wengang Zhou, Houqiang Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Stabilizing+Voltage+in+Power+Distribution+Networks+via+Multi-Agent+Reinforcement+Learning+with+Transformer)|1|
|[Task-Adaptive Few-shot Node Classification](https://doi.org/10.1145/3534678.3539265)|Song Wang, Kaize Ding, Chuxu Zhang, Chen Chen, Jundong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Task-Adaptive+Few-shot+Node+Classification)|1|
|[Disentangled Dynamic Heterogeneous Graph Learning for Opioid Overdose Prediction](https://doi.org/10.1145/3534678.3539279)|Qianlong Wen, Zhongyu Ouyang, Jianfei Zhang, Yiyue Qian, Yanfang Ye, Chuxu Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Disentangled+Dynamic+Heterogeneous+Graph+Learning+for+Opioid+Overdose+Prediction)|1|
|[Multi-fidelity Hierarchical Neural Processes](https://doi.org/10.1145/3534678.3539364)|Dongxia Wu, Matteo Chinazzi, Alessandro Vespignani, YiAn Ma, Rose Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-fidelity+Hierarchical+Neural+Processes)|1|
|[Availability Attacks Create Shortcuts](https://doi.org/10.1145/3534678.3539241)|Da Yu, Huishuai Zhang, Wei Chen, Jian Yin, TieYan Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Availability+Attacks+Create+Shortcuts)|1|
|[Model Degradation Hinders Deep Graph Neural Networks](https://doi.org/10.1145/3534678.3539374)|Wentao Zhang, Zeang Sheng, Ziqi Yin, Yuezihan Jiang, Yikuan Xia, Jun Gao, Zhi Yang, Bin Cui||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Model+Degradation+Hinders+Deep+Graph+Neural+Networks)|1|
|[Contrastive Learning with Complex Heterogeneity](https://doi.org/10.1145/3534678.3539311)|Lecheng Zheng, Jinjun Xiong, Yada Zhu, Jingrui He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Learning+with+Complex+Heterogeneity)|1|
|[AntiBenford Subgraphs: Unsupervised Anomaly Detection in Financial Networks](https://doi.org/10.1145/3534678.3539100)|Tianyi Chen, Charalampos E. Tsourakakis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AntiBenford+Subgraphs:+Unsupervised+Anomaly+Detection+in+Financial+Networks)|1|
|[Talent Demand-Supply Joint Prediction with Dynamic Heterogeneous Graph Enhanced Meta-Learning](https://doi.org/10.1145/3534678.3539139)|Zhuoning Guo, Hao Liu, Le Zhang, Qi Zhang, Hengshu Zhu, Hui Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Talent+Demand-Supply+Joint+Prediction+with+Dynamic+Heterogeneous+Graph+Enhanced+Meta-Learning)|1|
|[Greykite: Deploying Flexible Forecasting at Scale at LinkedIn](https://doi.org/10.1145/3534678.3539165)|Reza Hosseini, Albert Chen, Kaixu Yang, Sayan Patra, Yi Su, Saad Eddin Al Orjany, Sishi Tang, Parvez Ahammad||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Greykite:+Deploying+Flexible+Forecasting+at+Scale+at+LinkedIn)|1|
|[A Fully Differentiable Set Autoencoder](https://doi.org/10.1145/3534678.3539153)|Nikita Janakarajan, Jannis Born, Matteo Manica||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Fully+Differentiable+Set+Autoencoder)|1|
|[Precision CityShield Against Hazardous Chemicals Threats via Location Mining and Self-Supervised Learning](https://doi.org/10.1145/3534678.3539028)|Jiahao Ji, Jingyuan Wang, Junjie Wu, Boyang Han, Junbo Zhang, Yu Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Precision+CityShield+Against+Hazardous+Chemicals+Threats+via+Location+Mining+and+Self-Supervised+Learning)|1|
|[Towards Learning Disentangled Representations for Time Series](https://doi.org/10.1145/3534678.3539140)|Yuening Li, Zhengzhang Chen, Daochen Zha, Mengnan Du, Jingchao Ni, Denghui Zhang, Haifeng Chen, Xia Hu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Learning+Disentangled+Representations+for+Time+Series)|1|
|[CS-RAD: Conditional Member Status Refinement and Ability Discovery for Social Network Applications](https://doi.org/10.1145/3534678.3539046)|Yiming Ma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CS-RAD:+Conditional+Member+Status+Refinement+and+Ability+Discovery+for+Social+Network+Applications)|1|
|[GraphWorld: Fake Graphs Bring Real Insights for GNNs](https://doi.org/10.1145/3534678.3539203)|John Palowitch, Anton Tsitsulin, Brandon Mayer, Bryan Perozzi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphWorld:+Fake+Graphs+Bring+Real+Insights+for+GNNs)|1|
|[Temporal Multimodal Multivariate Learning](https://doi.org/10.1145/3534678.3539159)|Hyoshin Park, Justice Darko, Niharika Deshpande, Venktesh Pandey, Hui Su, Masahiro Ono, Dedrick Barkely, Larkin Folsom, Derek J. Posselt, Steve Chien||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Temporal+Multimodal+Multivariate+Learning)|1|
|[Downscaling Earth System Models with Deep Learning](https://doi.org/10.1145/3534678.3539031)|Sungwon Park, Karandeep Singh, Arjun Nellikkattil, Elke Zeller, TungDuong Mai, Meeyoung Cha||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Downscaling+Earth+System+Models+with+Deep+Learning)|1|
|[DocLayNet: A Large Human-Annotated Dataset for Document-Layout Segmentation](https://doi.org/10.1145/3534678.3539043)|Birgit Pfitzmann, Christoph Auer, Michele Dolfi, Ahmed S. Nassar, Peter W. J. Staar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DocLayNet:+A+Large+Human-Annotated+Dataset+for+Document-Layout+Segmentation)|1|
|[What is the Most Effective Intervention to Increase Job Retention for this Disabled Worker?](https://doi.org/10.1145/3534678.3539026)|Ha Xuan Tran, Thuc Duy Le, Jiuyong Li, Lin Liu, Jixue Liu, Yanchang Zhao, Tony Waters||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=What+is+the+Most+Effective+Intervention+to+Increase+Job+Retention+for+this+Disabled+Worker?)|1|
|[Reinforcement Learning-based Placement of Charging Stations in Urban Road Networks](https://doi.org/10.1145/3534678.3539154)|Leonie von Wahl, Nicolas Tempelmeier, Ashutosh Sao, Elena Demidova||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reinforcement+Learning-based+Placement+of+Charging+Stations+in+Urban+Road+Networks)|1|
|[Learning to Discover Causes of Traffic Congestion with Limited Labeled Data](https://doi.org/10.1145/3534678.3539185)|Mudan Wang, Huan Yan, Hongjie Sui, Fan Zuo, Yue Liu, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Discover+Causes+of+Traffic+Congestion+with+Limited+Labeled+Data)|1|
|[A Framework for Multi-stage Bonus Allocation in Meal Delivery Platform](https://doi.org/10.1145/3534678.3539202)|Zhuolin Wu, Li Wang, Fangsheng Huang, Linjun Zhou, Yu Song, Chengpeng Ye, Pengyu Nie, Hao Ren, Jinghua Hao, Renqing He, Zhizhao Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Framework+for+Multi-stage+Bonus+Allocation+in+Meal+Delivery+Platform)|1|
|[Uncertainty Quantification of Sparse Travel Demand Prediction with Spatial-Temporal Graph Neural Networks](https://doi.org/10.1145/3534678.3539093)|Dingyi Zhuang, Shenhao Wang, Haris N. Koutsopoulos, Jinhua Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Uncertainty+Quantification+of+Sparse+Travel+Demand+Prediction+with+Spatial-Temporal+Graph+Neural+Networks)|1|
|[Effective Social Network-Based Allocation of COVID-19 Vaccines](https://doi.org/10.1145/3534678.3542673)|Jiangzhuo Chen, Stefan Hoops, Achla Marathe, Henning S. Mortveit, Bryan L. Lewis, Srinivasan Venkatramanan, Arash Haddadan, Parantapa Bhattacharya, Abhijin Adiga, Anil Vullikanti, Aravind Srinivasan, Mandy L. Wilson, Gal Ehrlich, Maier Fenster, Stephen G. Eubank, Christopher L. Barrett, Madhav V. Marathe||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Effective+Social+Network-Based+Allocation+of+COVID-19+Vaccines)|1|
|[Automatic Phenotyping by a Seed-guided Topic Model](https://doi.org/10.1145/3534678.3542675)|Ziyang Song, Yuanyi Hu, Aman Verma, David L. Buckeridge, Yue Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automatic+Phenotyping+by+a+Seed-guided+Topic+Model)|1|
|[Activity Trajectory Generation via Modeling Spatiotemporal Dynamics](https://doi.org/10.1145/3534678.3542671)|Yuan Yuan, Jingtao Ding, Huandong Wang, Depeng Jin, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Activity+Trajectory+Generation+via+Modeling+Spatiotemporal+Dynamics)|1|
|[Multimodal AutoML for Image, Text and Tabular Data](https://doi.org/10.1145/3534678.3542616)|Nick Erickson, Xingjian Shi, James Sharpnack, Alexander J. Smola||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multimodal+AutoML+for+Image,+Text+and+Tabular+Data)|1|
|[Model Monitoring in Practice: Lessons Learned and Open Challenges](https://doi.org/10.1145/3534678.3542617)|Krishnaram Kenthapadi, Himabindu Lakkaraju, Pradeep Natarajan, Mehrnoosh Sameki||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Model+Monitoring+in+Practice:+Lessons+Learned+and+Open+Challenges)|1|
|[Algorithmic Fairness on Graphs: Methods and Trends](https://doi.org/10.1145/3534678.3542599)|Jian Kang, Hanghang Tong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Algorithmic+Fairness+on+Graphs:+Methods+and+Trends)|1|
|[A Practical Introduction to Federated Learning](https://doi.org/10.1145/3534678.3542631)|Yaliang Li, Bolin Ding, Jingren Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Practical+Introduction+to+Federated+Learning)|1|
|[Toolkit for Time Series Anomaly Detection](https://doi.org/10.1145/3534678.3542625)|Dhaval Patel, Dzung Phan, Markus Mueller, Amaresh Rajasekharan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Toolkit+for+Time+Series+Anomaly+Detection)|1|
|[Epidemic Forecasting with a Data-Centric Lens](https://doi.org/10.1145/3534678.3542620)|Alexander Rodríguez, Harshavardhan Kamarthi, B. Aditya Prakash||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Epidemic+Forecasting+with+a+Data-Centric+Lens)|1|
|[EXTR: Click-Through Rate Prediction with Externalities in E-Commerce Sponsored Search](https://doi.org/10.1145/3534678.3539053)|Chi Chen, Hui Chen, Kangzhi Zhao, Junsheng Zhou, Li He, Hongbo Deng, Jian Xu, Bo Zheng, Yong Zhang, Chunxiao Xing|Alibaba Group, BeiJing, China; Tsinghua University, BeiJing, China|Click-Through Rate (CTR) prediction, estimating the probability of a user clicking on items, plays a key fundamental role in sponsored search. E-commerce platforms display organic search results and advertisements (ads), collectively called items, together as a mixed list. The items displayed around the predicted ad, i.e. external items, may affect the user clicking on the predicted. Previous CTR models assume the user click only relies on the ad itself, which overlooks the effects of external items, referred to as external effects, or externalities. During the advertising prediction, the organic results have been generated by the organic system, while the final displayed ads on multiple ad slots have not been figured out, which leads to two challenges: 1) the predicted (target) ad may win any ad slot, bringing about diverse externalities. 2) external ads are undetermined, resulting in incomplete externalities. Facing the above challenges, inspired by the Transformer, we propose EXternality TRansformer (EXTR) which regards target ad with all slots as query and external items as key&value to model externalities in all exposure situations in parallel. Furthermore, we design a Potential Allocation Generator (PAG) for EXTR, to learn the allocation of potential external ads to complete the externalities. Extensive experimental results on Alibaba datasets demonstrate the effectiveness of externalities in the task of CTR prediction and illustrate that our proposed approach can bring significant profits to the real-world e-commerce platform. EXTR now has been successfully deployed in the online search advertising system in Alibaba, serving the main traffic.|点进率(ctrl)预测，估计用户点击项目的概率，在赞助商搜索中起着关键的基础作用。电子商务平台显示有机搜索结果和广告(广告) ，统称项目，一起作为一个混合清单。在预测广告周围显示的项目，即外部项目，可能会影响用户点击预测广告。以前的 CTR 模型假设用户的点击只依赖于广告本身，它忽略了外部项目的影响，称为外部影响，或外部性。在广告预测过程中，有机结果是由有机系统产生的，而最终在多个广告时段上显示的广告还没有计算出来，这就带来了两个挑战: 1)预测的(目标)广告可能赢得任何一个广告时段，带来不同的外部性。2)外部广告不确定性，导致外部性不完全。面对上述挑战，我们提出外部性变压器(EXTR)的启发，以所有时隙为查询目标广告和外部项目为关键和价值模型的外部性在所有曝光情况下并行。此外，我们还为 EXTR 设计了一个潜在分配生成器(PAG) ，学习如何分配潜在的外部广告来完成外部性。对阿里巴巴数据集的大量实验结果显示了外部性在点击率预测任务中的有效性，并说明我们建议的方法可以为现实世界的电子商务平台带来显著的利润。EXTR 现已成功应用于阿里巴巴的在线搜索广告系统，为主要流量提供服务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EXTR:+Click-Through+Rate+Prediction+with+Externalities+in+E-Commerce+Sponsored+Search)|0|
|[PARSRec: Explainable Personalized Attention-fused Recurrent Sequential Recommendation Using Session Partial Actions](https://doi.org/10.1145/3534678.3539432)|Ehsan Gholami, Mohammad Motamedi, Ashwin Aravindakshan|University of California, Davis, Davis, CA, USA|The emerging meta- and multi-verse landscape is yet another step towards the more prevalent use of already ubiquitous online markets. In such markets, recommender systems play critical roles by offering items of interest to the users, thereby narrowing down a vast search space that comprises hundreds of thousands of products. Recommender systems are usually designed to learn common user behaviors and rely on them for inference. This approach, while effective, is oblivious to subtle idiosyncrasies that differentiate humans from each other. Focusing on this observation, we propose an architecture that relies on common patterns as well as individual behaviors to tailor its recommendations for each person. Simulations under a controlled environment show that our proposed model learns interpretable personalized user behaviors. Our empirical results on Nielsen Consumer Panel dataset indicate that the proposed approach achieves up to 27.9% performance improvement compared to the state-of-the-art.|新兴的元和多元宇宙景观是朝着更普遍地使用已经无处不在的在线市场迈出的又一步。在这样的市场中，推荐系统通过向用户提供感兴趣的项目发挥着关键作用，从而缩小了由成千上万个产品组成的巨大搜索空间。推荐系统通常被设计用来学习常见的用户行为，并依赖它们进行推理。这种方法虽然有效，却忽略了区分人与人之间的微妙特质。基于这一观察，我们提出了一个依赖于公共模式和个人行为的体系结构，以便为每个人量身定制其建议。在受控环境下的仿真表明，我们提出的模型学习可解释的个性化用户行为。我们对 AC尼尔森面板数据集的实验结果表明，与最先进的技术相比，提出的方法实现了高达27.9% 的性能改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PARSRec:+Explainable+Personalized+Attention-fused+Recurrent+Sequential+Recommendation+Using+Session+Partial+Actions)|0|
|[Pretraining Representations of Multi-modal Multi-query E-commerce Search](https://doi.org/10.1145/3534678.3539200)|Xinyi Liu, Wanxian Guan, Lianyun Li, Hui Li, Chen Lin, Xubin Li, Si Chen, Jian Xu, Hongbo Deng, Bo Zheng|Xiamen University, Xiamen, China; Alibaba Group, Hangzhou, China|The importance of modeling contextual information within a search session has been widely acknowledged. However, learning representations of multi-query multi-modal (MM) search, in which Mobile Taobao users repeatedly submit textual and visual queries, remains unexplored in literature. Previous work which learns task-specific representations of textual query sessions fails to capture diverse query types and correlations in MM search sessions. This paper presents to represent MM search sessions by heterogeneous graph neural network (HGN). A multi-view contrastive learning framework is proposed to pretrain the HGN, with two views to model different intra-query, inter-query, and inter-modality information diffusion in MM search. Extensive experiments demonstrate that, the pretrained session representation can benefit state-of-the-art baselines on various downstream tasks, such as personalized click prediction, query suggestion, and intent classification.|在搜索会话中建模上下文信息的重要性已经得到了广泛的认可。然而，多查询多模态(MM)搜索的学习表征，其中移动淘宝用户重复提交文本和视觉查询，仍然没有文献探索。前面的工作学习了文本查询会话的特定任务表示，但未能在 MM 搜索会话中捕获不同的查询类型和相关性。本文提出用异构图神经网络(HGN)来表示 MM 搜索会话。提出了一种多视图对比学习框架对 HGN 进行预训练，使用两种视图对 MM 搜索中不同的查询内、查询间和模态间信息扩散进行建模。大量的实验表明，预先训练的会话表示可以使各种下游任务的最先进的基线受益，例如个性化的点击预测、查询建议和意图分类。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Pretraining+Representations+of+Multi-modal+Multi-query+E-commerce+Search)|0|
|[Deep Search Relevance Ranking in Practice](https://doi.org/10.1145/3534678.3542632)|Linsey Pang, Wei Liu, Kenghao Chang, Xue Li, Moumita Bhattacharya, Xianjing Liu, Stephen Guo|Salesforce, San Francisco, CA, USA; Walmart Global Tech, Sunnyvale, CA, USA; University of Technology Sydney, Sydney, Australia; Netflix, Los Gatos, CA, USA; Microsoft, Mountain View, CA, USA; Twitter, San Jose , CA, USA|Machine learning techniques for developing industry-scale search engines have long been a prominent part of most domains and their online products. Search relevance algorithms are key components of products across different fields, including e-commerce, streaming services, and social networks. In this tutorial, we give an introduction to such large-scale search ranking systems, specifically focusing on deep learning techniques in this area. The topics we cover are the following: (1) Overview of search ranking systems in practice, including classical and machine learning techniques; (2) Introduction to sequential and language models in the context of search ranking; and (3) Knowledge distillation approaches for this area. For each of the aforementioned sessions, we first give an introductory talk and then go over an hands-on tutorial to really hone in on the concepts. We cover fundamental concepts using demos, case studies, and hands-on examples, including the latest Deep Learning methods that have achieved state-of-the-art results in generating the most relevant search results. Moreover, we show example implementations of these methods in python, leveraging a variety of open-source machine-learning/deep-learning libraries as well as real industrial data or open-source data.|用于开发行业规模搜索引擎的机器学习技术长期以来一直是大多数领域及其在线产品的重要组成部分。搜索相关算法是不同领域产品的关键组成部分，包括电子商务、流媒体服务和社交网络。在本教程中，我们将介绍这种大规模的搜索排名系统，特别关注这一领域的深度学习技术。我们讨论的主题如下: (1)搜索排名系统在实践中的概述，包括经典的和机器学习技术; (2)在搜索排名的背景下序列和语言模型的介绍; 和(3)这个领域的知识提取方法。对于前面提到的每一个会议，我们首先做一个介绍性的演讲，然后通过一个实践教程来真正地深入理解这些概念。我们使用演示、案例研究和实践例子介绍基本概念，包括最新的深度学习方法，这些方法在生成最相关的搜索结果时取得了最先进的结果。此外，我们还展示了这些方法在 python 中的实现示例，利用了各种开源机器学习/深度学习库以及真实的工业数据或开源数据。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Search+Relevance+Ranking+in+Practice)|0|
|[Debiasing the Cloze Task in Sequential Recommendation with Bidirectional Transformers](https://doi.org/10.1145/3534678.3539430)|Khalil Damak, Sami Khenissi, Olfa Nasraoui|University of Louisville, Louisville, KY, USA|Bidirectional Transformer architectures are state-of-the-art sequential recommendation models that use a bi-directional representation capacity based on the Cloze task, a.k.a. Masked Language Modeling. The latter aims to predict randomly masked items within the sequence. Because they assume that the true interacted item is the most relevant one, an exposure bias results, where non-interacted items with low exposure propensities are assumed to be irrelevant. The most common approach to mitigating exposure bias in recommendation has been Inverse Propensity Scoring (IPS), which consists of down-weighting the interacted predictions in the loss function in proportion to their propensities of exposure, yielding a theoretically unbiased learning. In this work, we argue and prove that IPS does not extend to sequential recommendation because it fails to account for the temporal nature of the problem. We then propose a novel propensity scoring mechanism, which can theoretically debias the Cloze task in sequential recommendation. Finally we empirically demonstrate the debiasing capabilities of our proposed approach and its robustness to the severity of exposure bias.|双向转换器体系结构是最先进的顺序推荐模型，它使用基于完形填空任务的双向表示能力，也就是掩码语言建模。后者旨在预测序列中随机掩盖的项目。因为他们假设真正的相互作用的项目是最相关的一个，暴露偏差的结果，其中没有相互作用的项目低暴露倾向被认为是无关紧要的。减轻推荐中暴露偏倚的最常见方法是逆倾向评分(IPS) ，其包括按照暴露倾向的比例降低损失函数中的相互作用预测的权重，从而产生理论上无偏倚的学习。在这项工作中，我们争论和证明 IPS 没有扩展到顺序推荐，因为它没有考虑到问题的时间性质。然后，我们提出了一种新的倾向评分机制，它可以在理论上降低完形填空任务的顺序推荐。最后，我们通过实证证明了我们提出的方法的去偏能力及其对暴露偏差严重程度的鲁棒性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Debiasing+the+Cloze+Task+in+Sequential+Recommendation+with+Bidirectional+Transformers)|0|
|[A Generalized Doubly Robust Learning Framework for Debiasing Post-Click Conversion Rate Prediction](https://doi.org/10.1145/3534678.3539270)|Quanyu Dai, Haoxuan Li, Peng Wu, Zhenhua Dong, XiaoHua Zhou, Rui Zhang, Rui Zhang, Jie Sun|Huawei Noah's Ark Lab, Shenzhen, China; Huawei Hong Kong Theory Lab, Hong Kong, China; Peking University, Beijing, China; Beijing Technology and Business University, Beijing, China; ruizhang.info, Shenzhen, China|Post-click conversion rate (CVR) prediction is an essential task for discovering user interests and increasing platform revenues in a range of industrial applications. One of the most challenging problems of this task is the existence of severe selection bias caused by the inherent self-selection behavior of users and the item selection process of systems. Currently, doubly robust (DR) learning approaches achieve the state-of-the-art performance for debiasing CVR prediction. However, in this paper, by theoretically analyzing the bias, variance and generalization bounds of DR methods, we find that existing DR approaches may have poor generalization caused by inaccurate estimation of propensity scores and imputation errors, which often occur in practice. Motivated by such analysis, we propose a generalized learning framework that not only unifies existing DR methods, but also provides a valuable opportunity to develop a series of new debiasing techniques to accommodate different application scenarios. Based on the framework, we propose two new DR methods, namely DR-BIAS and DR-MSE. DR-BIAS directly controls the bias of DR loss, while DR-MSE balances the bias and variance flexibly, which achieves better generalization performance. In addition, we propose a novel tri-level joint learning optimization method for DR-MSE in CVR prediction, and an efficient training algorithm correspondingly. We conduct extensive experiments on both real-world and semi-synthetic datasets, which validate the effectiveness of our proposed methods.|点击后转换率(CVR)预测是发现用户兴趣和增加平台收入的一个重要任务，在一系列的工业应用。这项任务最具挑战性的问题之一是由于用户固有的自我选择行为和系统的项目选择过程所引起的严重选择偏差的存在。目前，双鲁棒(DR)学习方法在降低 CVR 预测偏差方面取得了最好的效果。然而，通过对 DR 方法的偏差、方差和泛化界限的理论分析，我们发现现有的 DR 方法可能由于在实际应用中经常出现的倾向分数估计不准确和插补错误而导致泛化能力较差。基于这样的分析，我们提出了一个通用的学习框架，它不仅统一了现有的 DR 方法，而且为开发一系列新的去偏技术以适应不同的应用场景提供了宝贵的机会。在此基础上，提出了两种新的 DR 方法: DR-BIAS 和 DR-MSE。DR-BIAS 直接控制 DR 损失的偏差，而 DR-MSE 灵活地平衡偏差和方差，从而获得更好的泛化性能。此外，本文还提出了一种新的基于 DR-MSE 的 CVR 预测三层联合学习优化方法，并给出了相应的训练算法。我们在真实世界和半合成数据集上进行了广泛的实验，验证了我们提出的方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Generalized+Doubly+Robust+Learning+Framework+for+Debiasing+Post-Click+Conversion+Rate+Prediction)|0|
|[User-Event Graph Embedding Learning for Context-Aware Recommendation](https://doi.org/10.1145/3534678.3539458)|Dugang Liu, Mingkai He, Jinwei Luo, Jiangxu Lin, Meng Wang, Xiaolian Zhang, Weike Pan, Zhong Ming|Southeast University, Nanjing, China; Huawei Technologies Co Ltd, Shenzhen, China; Shenzhen University, Shenzhen, China; Shenzhen University & Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ), Shenzhen, China|Most methods for context-aware recommendation focus on improving the feature interaction layer, but overlook the embedding layer. However, an embedding layer with random initialization often suffers in practice from the sparsity of the contextual features, as well as the interactions between the users (or items) and context. In this paper, we propose a novel user-event graph embedding learning (UEG-EL) framework to address these two sparsity challenges. Specifically, our UEG-EL contains three modules: 1) a graph construction module is used to obtain a user-event graph containing nodes for users, intents and items, where the intent nodes are generated by applying intent node attention (INA) on nodes of the contextual features; 2) a user-event collaborative graph convolution module is designed to obtain the refined embeddings of all features by executing a new convolution strategy on the user-event graph, where each intent node acts as a hub to efficiently propagate the information among different features; 3) a recommendation module is equipped to integrate some existing context-aware recommendation model, where the feature embeddings are directly initialized with the obtained refined embeddings. Moreover, we identify a unique challenge of the basic framework, that is, the contextual features associated with too many instances may suffer from noise when aggregating the information. We thus further propose a simple but effective variant, i.e., UEG-EL-V, in order to prune the information propagation of the contextual features. Finally, we conduct extensive experiments on three public datasets to verify the effectiveness and compatibility of our UEG-EL and its variant.|大多数上下文感知的推荐方法侧重于改进特征交互层，而忽略了嵌入层。然而，具有随机初始化的嵌入层在实践中经常受到上下文特征稀疏性以及用户(或项目)与上下文之间交互的影响。本文提出了一种新的用户事件图嵌入学习(UEG-EL)框架来解决这两个稀疏性问题。具体来说，我们的 UEG-EL 包含三个模块: 1)一个图形构造模块用于获得一个包含用户、意图和项目节点的用户事件图，其中意图节点是通过在上下文特征的节点上应用意图节点注意力(INA)来生成的; 2)一个用户事件协作图卷积模块用于通过在用户事件图上执行一个新的卷积策略来获得所有特征的精细嵌入，其中每个意图节点作为一个中心来有效地传播不同特征之间的信息; 3)一个推荐模块用于集成一些现有的上下文感知的推荐模型，其中特征嵌入是直接初始化。此外，我们发现了基本框架的一个独特的挑战，即与太多实例相关的上下文特征在聚合信息时可能会受到噪声的影响。因此，我们进一步提出了一个简单而有效的变体，即 UEG-EL-V，以修剪信息传播的上下文特征。最后，我们在三个公共数据集上进行了广泛的实验，以验证我们的 UEG-EL 及其变体的有效性和兼容性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=User-Event+Graph+Embedding+Learning+for+Context-Aware+Recommendation)|0|
|[Adversarial Gradient Driven Exploration for Deep Click-Through Rate Prediction](https://doi.org/10.1145/3534678.3539461)|Kailun Wu, Weijie Bian, Zhangming Chan, Lejian Ren, Shiming Xiang, Shuguang Han, Hongbo Deng, Bo Zheng|Alibaba Group, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China|Exploration-Exploitation (E& E) algorithms are commonly adopted to deal with the feedback-loop issue in large-scale online recommender systems. Most of existing studies believe that high uncertainty can be a good indicator of potential reward, and thus primarily focus on the estimation of model uncertainty. We argue that such an approach overlooks the subsequent effect of exploration on model training. From the perspective of online learning, the adoption of an exploration strategy would also affect the collecting of training data, which further influences model learning. To understand the interaction between exploration and training, we design a Pseudo-Exploration module that simulates the model updating process after a certain item is explored and the corresponding feedback is received. We further show that such a process is equivalent to adding an adversarial perturbation to the model input, and thereby name our proposed approach as an the Adversarial Gradient Driven Exploration (AGE). For production deployment, we propose a dynamic gating unit to pre-determine the utility of an exploration. This enables us to utilize the limited amount of resources for exploration, and avoid wasting pageview resources on ineffective exploration. The effectiveness of AGE was firstly examined through an extensive number of ablation studies on an academic dataset. Meanwhile, AGE has also been deployed to one of the world-leading display advertising platforms, and we observe significant improvements on various top-line evaluation metrics.|在大规模在线推荐系统中，探索-开发(E & E)算法是处理反馈回路问题的常用算法。大多数已有的研究认为高不确定性可以作为潜在报酬的一个很好的指标，因此主要集中在模型不确定性的估计上。我们认为这种方法忽视了探索对模型训练的后续影响。从在线学习的角度来看，探索策略的采用也会影响训练数据的收集，从而进一步影响模型学习。为了理解探索与训练的相互作用，我们设计了一个拟探索模块，模拟探索某一项目并收到相应反馈后的模型更新过程。我们进一步表明，这样一个过程是相当于添加一个对抗扰动的模型输入，从而命名我们提出的方法作为一个对抗梯度驱动探索(AGE)。对于生产部署，我们提出了一个动态门控单元来预先确定勘探的效用。这使我们能够利用有限的资源进行探索，避免在无效探索上浪费页面浏览资源。AGE 的有效性首先通过一个学术数据集上的大量消融研究进行了检验。与此同时，AGE 也被部署到世界领先的展示广告平台之一，我们观察到各种顶线评估指标的显著改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adversarial+Gradient+Driven+Exploration+for+Deep+Click-Through+Rate+Prediction)|0|
|[Graph-based Multilingual Language Model: Leveraging Product Relations for Search Relevance](https://doi.org/10.1145/3534678.3539158)|Nurendra Choudhary, Nikhil Rao, Karthik Subbian, Chandan K. Reddy|Amazon, Palo Alto, CA, USA; Virginia Tech, Arlington, VA, USA|The large-scale nature of product catalog and the changing demands of customer queries makes product search a challenging problem. The customer queries are ambiguous and implicit. They may be looking for an exact match of their query, or a functional equivalent (i.e., substitute), or an accessory to go with it (i.e., complement). It is important to distinguish these three categories from merely classifying an item for a customer query as relevant or not. This information can help direct the customer and improve search applications to understand the customer mission. In this paper, we formulate search relevance as a multi-class classification problem and propose a graph-based solution to classify a given query-item pair as exact, substitute, complement, or irrelevant (ESCI). The customer engagement (clicks, add-to-cart, and purchases) between query and items serve as a crucial information for this problem. However, existing approaches rely purely on the textual information (such as BERT) and do not sufficiently focus on the structural relationships. Another challenge in including the structural information is the sparsity of such data in some regions. We propose Structure-Aware multilingual LAnguage Model (SALAM), that utilizes a language model along with a graph neural network, to extract region-specific semantics as well as relational information for the classification of query-product pairs. Our model is first pre-trained on a large region-agnostic dataset and behavioral graph data and then fine-tuned on region-specific versions to address the sparsity. We show in our experiments that SALAM significantly outperforms the current matching frameworks on the ESCI classification task in several regions. We also demonstrate the effectiveness of using a two-phased training setup (i.e., pre-training and fine-tuning) in capturing region-specific information. Also, we provide various challenges and solutions for using the model in an industrial setting and outline its contribution to the e-commerce engine.|产品目录的大规模性和客户查询需求的变化使得产品搜索成为一个具有挑战性的问题。客户查询是模糊和隐式的。他们可能在寻找与他们的查询完全匹配的查询，或者功能等价的查询(即替代查询) ，或者附属查询(即补充查询)。区分这三个类别与仅仅为客户查询分类一个项目是否相关是很重要的。这些信息可以帮助指导客户并改进搜索应用程序，以理解客户的使命。本文将搜索相关性表述为一个多类分类问题，并提出了一种基于图的解决方案，将给定的查询项对分类为精确、替代、补充或不相关(ESCI)。查询和项目之间的客户参与(单击、添加到购物车和购买)是解决此问题的关键信息。然而，现有的方法仅仅依赖于文本信息(比如 BERT) ，并没有充分关注结构关系。在纳入结构信息方面的另一个挑战是，一些区域的此类数据稀少。提出了一种基于结构感知的多语言语言模型(SALAM) ，该模型利用语言模型和图神经网络提取区域特定的语义和关系信息，用于查询产品对的分类。我们的模型首先在大型区域不可知数据集和行为图数据上进行预训练，然后在区域特定版本上进行微调，以解决稀疏性问题。我们的实验表明，在 ESCI 分类任务中，SALAM 在几个地区的性能明显优于目前的匹配框架。我们还演示了使用两阶段的训练设置(即预训练和微调)在捕获特定区域的信息方面的有效性。此外，我们提供了在工业环境中使用该模型的各种挑战和解决方案，并概述了其对电子商务引擎的贡献。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph-based+Multilingual+Language+Model:+Leveraging+Product+Relations+for+Search+Relevance)|0|
|[ASPIRE: Air Shipping Recommendation for E-commerce Products via Causal Inference Framework](https://doi.org/10.1145/3534678.3539197)|Abhirup Mondal, Anirban Majumder, Vineet Chaoji|Amazon, Bengaluru, India|Speed of delivery is critical for the success of e-commerce platforms. Faster delivery promise to the customer results in increased conversion and revenue. There are typically two mechanisms to control the delivery speed - a) replication of products across warehouses, and b) air-shipping the product. In this paper, we present a machine learning based framework to recommend air-shipping eligibility for products. Specifically, we develop a causal inference framework (referred to as Air Shipping Recommendation or ASPIRE) that balances the trade-off between revenue or conversion and delivery cost to decide whether a product should be shipped via air. We propose a doubly-robust estimation technique followed by an optimization algorithm to determine air eligibility of products and calculate the uplift in revenue and shipping cost. We ran extensive experiments (both offline and online) to demonstrate the superiority of our technique as compared to the incumbent policies and baseline approaches. ASPIRE resulted in a lift of +79 bps of revenue as measured through an A/B experiment in an emerging marketplace on Amazon.|交付速度对电子商务平台的成功至关重要。更快的交付承诺给客户的结果增加转换和收入。通常有两种机制来控制交付速度: a)在仓库之间复制产品，b)空运产品。在本文中，我们提出了一个基于机器学习的框架来推荐产品的空运资格。具体来说，我们开发了一个因果推理框架(称为航空运输建议书或 ASPIRE) ，平衡收入或转换和交付成本之间的权衡，以决定是否应该通过空运运输产品。我们提出了一个双稳健估计技术和一个优化算法来确定产品的空气合格性，并计算收入和运输成本的提高。我们进行了大量的实验(线下和线上) ，以证明我们的技术相对于现有的策略和基线方法的优越性。通过在亚马逊新兴市场的 A/B 实验，ASPIRE 的收入提高了79个基点。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ASPIRE:+Air+Shipping+Recommendation+for+E-commerce+Products+via+Causal+Inference+Framework)|0|
|[Improving Relevance Modeling via Heterogeneous Behavior Graph Learning in Bing Ads](https://doi.org/10.1145/3534678.3539128)|Bochen Pang, Chaozhuo Li, Yuming Liu, Jianxun Lian, Jianan Zhao, Hao Sun, Weiwei Deng, Xing Xie, Qi Zhang|University of Notre Dame, Indiana, IN, USA; Microsoft, Beijing, China; Microsoft Research Asia, Beijing, China|As the fundamental basis of sponsored search, relevance modeling measures the closeness between the input queries and the candidate ads. Conventional relevance models solely rely on the textual data, which suffer from the scarce semantic signals within the short queries. Recently, user historical click behaviors are incorporated in the format of click graphs to provide additional correlations beyond pure textual semantics, which contributes to advancing the relevance modeling performance. However, user behaviors are usually arbitrary and unpredictable, leading to the noisy and sparse graph topology. In addition, there exist other types of user behaviors besides clicks, which may also provide complementary information. In this paper, we study the novel problem of heterogeneous behavior graph learning to facilitate relevance modeling task. Our motivation lies in learning an optimal and task-relevant heterogeneous behavior graph consisting of multiple types of user behaviors. We further propose a novel HBGLR model to learn the behavior graph structure by mining the sophisticated correlations between node semantics and graph topology, and encode the textual semantics and structural heterogeneity into the learned representations. Our proposal is evaluated over real-world industry datasets, and has been mainstreamed in the Bing ads. Both offline and online experimental results demonstrate its superiority.|作为赞助商搜索的基础，相关性建模测量了输入查询和候选广告之间的密切程度。传统的关联模型仅仅依赖于文本数据，而文本数据受到短查询中语义信号稀缺的影响。近年来，用户的历史点击行为被整合到点击图的格式中，提供了超越纯文本语义的额外相关性，这有助于提高相关性建模的性能。然而，用户行为通常是任意和不可预测的，导致噪声和稀疏图拓扑。此外，除了点击之外，还存在其他类型的用户行为，这些行为也可能提供补充信息。本文研究了异构行为图学习的新问题，以促进相关建模任务的完成。我们的动机在于学习一个由多种类型的用户行为组成的最优的和与任务相关的异构行为图。我们进一步提出了一种新的 HBGLR 模型，通过挖掘节点语义和图拓扑之间复杂的相关性来学习行为图结构，并将文本语义和结构异质性编码到所学习的表示中。我们的建议是评估在现实世界的行业数据集，并已成为主流的必应广告。离线和在线实验结果都证明了该方法的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Relevance+Modeling+via+Heterogeneous+Behavior+Graph+Learning+in+Bing+Ads)|0|
|[Type Linking for Query Understanding and Semantic Search](https://doi.org/10.1145/3534678.3539067)|Giorgos Stoilos, Nikos Papasarantopoulos, Pavlos Vougiouklis, Patrik Bansky|Huawei Technologies, Edinburgh, United Kingdom|Huawei is currently undertaking an effort to build map and web search services using query understanding and semantic search techniques. We present our efforts to built a low-latency type mention detection and linking service for map search. In addition to latency challenges, we only had access to low quality and biased training data plus we had to support 13 languages. Consequently, our service is based mostly on unsupervised term- and vector-based methods. Nevertheless, we trained a Transformer-based query tagger which we integrated with the rest of the pipeline using a reward and penalisation approach. We present techniques that we designed in order to address challenges with the type dictionary, incompatibilities in scoring between the term-based and vector-based methods as well as over-segmentation issues in Thai, Chinese, and Japanese. We have evaluated our approach on the Huawei map search use case as well as on community Question Answering benchmarks.|华为目前正致力于利用查询理解和语义搜索技术建立地图和网络搜索服务。我们介绍了我们的努力，建立一个低延迟类型提及检测和地图搜索链接服务。除了延迟挑战，我们只能访问低质量和有偏见的培训数据，加上我们必须支持13种语言。因此，我们的服务主要是基于无监督的术语和向量方法。尽管如此，我们还是训练了一个基于 Transformer 的查询标记器，并使用奖励和惩罚方法将其与管道的其他部分集成在一起。我们提出的技术，我们设计的目的是为了解决类型字典的挑战，在评分之间的基于术语和基于向量的方法以及在泰国，中国和日本的过分割问题。我们评估了华为地图搜索用例和社区问答基准的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Type+Linking+for+Query+Understanding+and+Semantic+Search)|0|
|[Combo-Fashion: Fashion Clothes Matching CTR Prediction with Item History](https://doi.org/10.1145/3534678.3539101)|Chenxu Zhu, Peng Du, Weinan Zhang, Yong Yu, Yang Cao|Shanghai Jiao Tong University, Shanghai, China; Alibaba Group, Hangzhou, China|As one of the fundamental trends for future development of recommender systems, Fashion Clothes Matching Recommendation for click-through rate (CTR) prediction has become an increasingly essential task. Unlike traditional single-item recommendation, a combo item, composed of a top item (e.g. a shirt) and a bottom item (e.g. a skirt), is recommended. In such a task, the matching effect between these two single items plays a crucial role, and greatly influences the users' preferences; however, it is usually neglected by previous approaches in CTR prediction. In this work, we tackle this problem by designing a novel algorithm called Combo-Fashion, which extracts the matching effect by introducing the matching history of the combo item with two cascaded modules: (i) Matching Search Module (MSM) seeks the popular combo items and undesirable ones as a positive set and a negative set, respectively; (ii) Matching Prediction Module (MPM) models the precise relationship between the candidate combo item and the positive/negative set by an attention-based deep model. Besides, the CPM Fashion Attribute, considered from characteristic, pattern and material, is applied to capture the matching effect further. As part of this work, we release two large-scale datasets consisting of 3.56 million and 6.01 million user behaviors with rich context and fashion information in millions of combo items. The experimental results over these two real-world datasets have demonstrated the superiority of our proposed model with significant improvements. Furthermore, we have deployed Combo-Fashion onto the platform of Taobao to recommend the combo items to the users, where an 8-day online A/B test proved the effectiveness of Combo-Fashion with an improvement of pCTR by 1.02% and uCTR by 0.70%.|作为推荐系统未来发展的基本趋势之一，服装搭配推荐系统的点进率预测已经成为一项日益重要的任务。不同于传统的单一项目推荐，一个组合项目，组成的顶部项目(如衬衫)和底部项目(如裙子) ，是推荐的。在这样一个任务中，这两个项目之间的匹配效果起着至关重要的作用，并且对用户的偏好有很大的影响，但是在以往的 CTR 预测方法中往往忽略了这一点。针对这一问题，本文设计了一种新的组合时尚算法，该算法通过引入组合项目的匹配历史来提取匹配效果，该算法由两个级联模块组成: (1)匹配搜索模块(MSM)分别将流行的组合项目和不受欢迎的组合项目作为一个正集和一个负集来搜索; (2)匹配预测模块(MPM)通过基于注意的深度模型来建立候选组合项目与正/负集之间的精确关系。此外，从特征、图案和材质三个方面考虑，运用 CPM 时尚属性进一步捕捉匹配效果。作为这项工作的一部分，我们发布了两个大型数据集，包括356万和601万用户行为，其中包含数百万个组合项目的丰富上下文和时尚信息。在这两个实际数据集上的实验结果显示了我们提出的模型的优越性，并有显著的改进。此外，我们还在淘宝平台上部署了 Combo-Fashion，向用户推荐组合项目，通过8天的在线 A/B 测试证明了 Combo-Fashion 的有效性，pCTR 提高了1.02% ，uCTR 提高了0.70% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Combo-Fashion:+Fashion+Clothes+Matching+CTR+Prediction+with+Item+History)|0|
|[Reward Optimizing Recommendation using Deep Learning and Fast Maximum Inner Product Search](https://doi.org/10.1145/3534678.3542622)|Imad Aouali, Amine Benhalloum, Martin Bompaire, Achraf Ait Sidi Hammou, Sergey Ivanov, Benjamin Heymann, David Rohde, Otmane Sakhi, Flavian Vasile, Maxime Vono|Criteo, Paris, France|How can we build and optimize a recommender system that must rapidly fill slates (i.e. banners) of personalized recommendations? The combination of deep learning stacks with fast maximum inner product search (MIPS) algorithms have shown it is possible to deploy flexible models in production that can rapidly deliver personalized recommendations to users. Albeit promising, this methodology is unfortunately not sufficient to build a recommender system which maximizes the reward, e.g. the probability of click. Usually instead a proxy loss is optimized and A/B testing is used to test if the system actually improved performance. This tutorial takes participants through the necessary steps to model the reward and directly optimize the reward of recommendation engines built upon fast search algorithms to produce high-performance reward-optimizing recommender systems.|我们如何构建和优化一个必须快速填充个性化推荐板块(即横幅)的推荐系统？深度学习栈与快速最大内部产品搜索(MIPS)算法的结合表明，在生产中部署灵活的模型可以迅速向用户提供个性化的建议。尽管这种方法很有前途，但不幸的是，它不足以建立一个最大化回报的推荐系统，例如点击的概率。通常代理丢失是优化和 A/B 测试用于测试系统是否实际上提高了性能。本教程将带领参与者通过必要的步骤来建立奖励模型，并直接优化建立在快速搜索算法基础上的推荐引擎的奖励，从而产生高性能的奖励优化推荐系统。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reward+Optimizing+Recommendation+using+Deep+Learning+and+Fast+Maximum+Inner+Product+Search)|0|
|[Low-rank Nonnegative Tensor Decomposition in Hyperbolic Space](https://doi.org/10.1145/3534678.3539317)|Bo Hui, WeiShinn Ku|Auburn University, Auburn, AL, USA|Tensor decomposition aims to factorize an input tensor into a number of latent factors. Due to the low-rank nature of tensor in real applications, the latent factors can be used to perform tensor completion in numerous tasks, such as knowledge graph completion and timely recommendation. However, existing works solve the problem in Euclidean space, where the tensor is decomposed into Euclidean vectors. Recent studies show that hyperbolic space is roomier than Euclidean space. With the same dimension, a hyperbolic vector can represent richer information (e.g., hierarchical structure) than a Euclidean vector. In this paper, we propose to decompose tensor in hyperbolic space. Considering that the most popular optimization tools (e.g, SGD, Adam) have not been generalized in hyperbolic space, we design an adaptive optimization algorithm according to the distinctive property of hyperbolic manifold. To address the non-convex property of the problem, we adopt gradient ascent in our optimization algorithm to avoid getting trapped in local optimal landscapes. We conduct experiments on various tensor completion tasks and the result validates the superiority of our method over these baselines that solve the problem in Euclidean space.|张量分解旨在将输入张量分解为若干潜在因子。由于张量在实际应用中的低秩特性，潜在因子可以用来完成许多任务，如知识图的完成和及时推荐。然而，现有的工作解决了欧氏空间中的问题，其中张量分解成欧氏向量。最近的研究表明双曲空间比欧几里得空间更宽敞。在相同的维度下，双曲向量可以比矢量表示更丰富的信息(例如，层次结构)。在这篇文章中，我们提出在双曲空间中分解张量。考虑到最流行的优化工具(例如，SGD，Adam)还没有在双曲空间中推广，我们根据双曲流形的独特性质设计了一个自适应优化算法。为了解决该问题的非凸性，在优化算法中采用了梯度上升的方法，以避免陷入局部最优景观中。我们对各种张量完成任务进行了实验，实验结果验证了该方法相对于这些基线解决欧氏空间问题的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Low-rank+Nonnegative+Tensor+Decomposition+in+Hyperbolic+Space)|0|
|[Personalized Chit-Chat Generation for Recommendation Using External Chat Corpora](https://doi.org/10.1145/3534678.3539215)|Changyu Chen, Xiting Wang, Xiaoyuan Yi, Fangzhao Wu, Xing Xie, Rui Yan|Microsoft Research Asia, Beijing, China; Renmin University of China, Beijing, China|Chit-chat has been shown effective in engaging users in human-computer interaction. We find with a user study that generating appropriate chit-chat for news articles can help expand user interest and increase the probability that a user reads a recommended news article. Based on this observation, we propose a method to generate personalized chit-chat for news recommendation. Different from existing methods for personalized text generation, our method only requires an external chat corpus obtained from an online forum, which can be disconnected from the recommendation dataset from both the user and item (news) perspectives. This is achieved by designing a weak supervision method for estimating users' personalized interest in a chit-chat post by transferring knowledge learned by a news recommendation model. Based on the method for estimating user interest, a reinforcement learning framework is proposed to generate personalized chit-chat. Extensive experiments, including the automatic offline evaluation and user studies, demonstrate the effectiveness of our method.|聊天已被证明能有效地吸引用户参与人机交互。我们通过用户研究发现，为新闻文章产生适当的闲聊可以帮助扩大用户的兴趣，并增加用户阅读推荐新闻文章的可能性。在此基础上，本文提出了一种新闻推荐个性化聊天的生成方法。与现有的个性化文本生成方法不同，该方法只需要一个从在线论坛获得的外部聊天语料库，该语料库可以从用户和项目(新闻)的角度与推荐数据集分离。这是通过设计一种弱监督方法，通过传递新闻推荐模型中学到的知识来估计用户在闲聊帖子中的个性化兴趣来实现的。基于评估用户兴趣的方法，提出了一个强化学习框架来生成个性化的聊天。广泛的实验，包括自动离线评估和用户研究，证明了我们的方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Chit-Chat+Generation+for+Recommendation+Using+External+Chat+Corpora)|0|
|[G2NET: A General Geography-Aware Representation Network for Hotel Search Ranking](https://doi.org/10.1145/3534678.3539025)|Jia Xu, Fei Xiong, Zulong Chen, Mingyuan Tao, Liangyue Li, Quan Lu|Alibaba Group, Hangzhou, China; Guangxi University, Nanning, China|Hotel search ranking is the core function of Online Travel Platforms (OTPs), while geography information of location entities involved in it plays a critically important role in guaranteeing its ranking quality. The closest line of works to the hotel search ranking problem is thus the next POI (or location) recommendation problem, which has extensive works but fails to cope with two new challenges, i.e., consideration of two more location entities and effective utilization of geographical information, in a hotel search ranking scenario. To this end, we propose a General Geography-aware representation NETwork (G2NET for short) to better represent geography information of location entities so as to optimize the hotel search ranking. In G2NET, to address the first challenge, we first propose the concept of Geography Interaction Schema (GIS) which is a meta template for representing the arbitrary number of location entity types and their interactions. Then, a novel geography interaction encoder is devised providing general representation ability for an instance of GIS, followed by an attentive operation that aggregates representations of instances corresponding to all historically interacted hotels of a user in a weighted manner. The second challenge is handled by the combined application of three proposed geography embedding modules in G2NET, each of which focuses on computing embeddings of location entities based on a certain aspect of geographical information of location entities. Moreover, a self-attention layer is deployed in G2NET, to capture correlations among historically interacted hotels of a user which provides non-trivial functionality of understanding the user's behaviors. Both offline and online experiments show that G2NET outperforms the state-of-the-art methods. G2NET has now been successfully deployed to provide the high-quality hotel search ranking service at Fliggy, one of the most popular OTPs in China, serving tens of millions of users.|酒店搜索排名是在线旅游平台(OTP)的核心功能，而位置实体的地理信息对于保证其排名质量起着至关重要的作用。因此，与酒店搜索排名问题最接近的工作是下一个 POI (或位置)推荐问题，这个问题有大量的工作，但未能应对两个新的挑战，即在一个酒店搜索排名场景中考虑另外两个位置实体和有效利用地理信息。为此，我们提出了一个通用地理感知表示网络(G2NET) ，以更好地表示位置实体的地理信息，从而优化酒店搜索排名。在 G2NET 中，为了应对第一个挑战，我们首先提出了地理交互模式(GIS)的概念，它是一个元模板，用于表示任意数量的位置实体类型及其交互。然后，设计了一种新颖的地理交互编码器，提供了 GIS 实例的一般表示能力，然后进行了注意操作，以加权的方式聚合了对应于用户的所有历史交互酒店的实例表示。第二个挑战是通过在 G2NET 中联合应用三个地理嵌入模块来解决，每个模块的重点都是基于位置实体的地理信息的某一方面来计算位置实体的嵌入。此外，在 G2NET 中部署了一个自我关注层，以捕获用户在历史上交互的酒店之间的相关性，从而提供了理解用户行为的重要功能。离线和在线实验都表明，G2NET 的性能优于最先进的方法。目前，g2NET 已成功部署到 Fliggy，为数千万用户提供高质量的酒店搜索排名服务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=G2NET:+A+General+Geography-Aware+Representation+Network+for+Hotel+Search+Ranking)|0|
|[Avoiding Biases due to Similarity Assumptions in Node Embeddings](https://doi.org/10.1145/3534678.3539287)|Deepayan Chakrabarti|University of Texas at Austin, Austin, TX, USA|Node embeddings are vectors, one per node, that capture a graph's structure. The basic structure is the adjacency matrix of the graph. Recent methods also make assumptions about the similarity of unlinked nodes. However, such assumptions can lead to unintentional but systematic biases against groups of nodes. Calculating similarities between far-off nodes is also difficult under privacy constraints and in dynamic graphs. Our proposed embedding, called NEWS, makes no similarity assumptions, avoiding potential risks to privacy and fairness. NEWS is parameter-free, enables fast link prediction, and has linear complexity. These gains from avoiding assumptions do not significantly affect accuracy, as we show via comparisons against several existing methods on $21$ real-world networks. Code is available at https://github.com/deepayan12/news.|节点嵌入是向量，每个节点一个，它捕获图的结构。基本结构是图形的邻接矩阵。最近的方法也对未链接节点的相似性做了假设。然而，这样的假设可能会导致对节点群的无意的但是系统性的偏见。在隐私约束和动态图中，计算远程节点之间的相似度也很困难。我们提出的嵌入，称为新闻，没有相似的假设，避免了隐私和公平的潜在风险。NEWS 是无参数的，支持快速链路预测，具有线性复杂度。这些从避免假设中获得的收益不会显著影响准确性，正如我们通过比较现有的几种方法在 $21 $真实世界的网络上所显示的。密码可于 https://github.com/deepayan12/news 索取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Avoiding+Biases+due+to+Similarity+Assumptions+in+Node+Embeddings)|0|
|[Task-optimized User Clustering based on Mobile App Usage for Cold-start Recommendations](https://doi.org/10.1145/3534678.3539105)|Bulou Liu, Bing Bai, Weibang Xie, Yiwen Guo, Hao Chen|University of California, Davis, Davis, CA, USA; Tencent Inc., Guangzhou, China; Tencent Security Big Data Lab, Beijing, China; Independent Researcher, Beijing, China|This paper reports our recent practice of recommending articles to cold-start users at Tencent. Transferring knowledge from information-rich domains to help user modeling is an effective way to address the user-side cold-start problem. Our previous work demonstrated that general-purpose user embeddings based on mobile app usage helped article recommendations. However, high-dimensional embeddings are cumbersome for online usage, thus limiting the adoption. On the other hand, user clustering, which partitions users into several groups, can provide a lightweight, online-friendly, and explainable way to help recommendations. Effective user clustering for article recommendations based on mobile app usage faces unique challenges, including (1) the gap between an active user's behavior of mobile app usage and article reading, and (2) the gap between mobile app usage patterns of active and cold-start users. To address the challenges, we propose a tailored Dual Alignment User Clustering (DAUC) model, which applies a sample-wise contrastive alignment to eliminate the gap between active users' mobile app usage and article reading behavior, and a distribution-wise adversarial alignment to eliminate the gap between active users' and cold-start users' app usage behavior. With DAUC, cold-start recommendation-optimized user clustering based on mobile app usage can be achieved. On top of the user clusters, we further build candidate generation strategies, real-time features, and corresponding ranking models without much engineering difficulty. Both online and offline experiments demonstrate the effectiveness of our work.|本文报道了我们最近向腾讯的冷启动用户推荐文章的做法。从信息丰富的领域转移知识以帮助用户建模是解决用户端冷启动问题的有效途径。我们以前的工作表明，基于移动应用程序使用的通用用户嵌入有助于文章推荐。但是，高维嵌入对于在线使用来说很麻烦，因此限制了采用。另一方面，用户集群(将用户划分为几个组)可以提供一种轻量级的、在线友好的、可解释的方式来帮助推荐。基于移动应用使用的文章推荐的有效用户聚类面临独特的挑战，包括(1)活跃用户的移动应用使用行为和文章阅读之间的差距，以及(2)活跃用户和冷启动用户的移动应用使用模式之间的差距。为了应对这些挑战，我们提出了一个定制的双对齐用户聚类(DAUC)模型，该模型应用样本对比对齐来消除活跃用户的移动应用程序使用和文章阅读行为之间的差距，以及分布式对抗对齐来消除活跃用户和冷启动用户的应用程序使用行为之间的差距。利用 DAUC，可以实现基于移动应用使用情况的冷启动推荐优化用户聚类。在用户集群的基础上，我们进一步构建了候选生成策略、实时特征以及相应的排序模型，这些都不需要很大的工程难度。这两个在线和离线实验都证明了我们工作的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Task-optimized+User+Clustering+based+on+Mobile+App+Usage+for+Cold-start+Recommendations)|0|
|[Promotheus: An End-to-End Machine Learning Framework for Optimizing Markdown in Online Fashion E-commerce](https://doi.org/10.1145/3534678.3539148)|Eleanor Loh, Jalaj Khandelwal, Brian Regan, Duncan A. Little|ASOS.com, London, United Kingdom|Managing discount promotional events ("markdown") is a significant part of running an e-commerce business, and inefficiencies here can significantly hamper a retailer's profitability. Traditional approaches for tackling this problem rely heavily on price elasticity modelling. However, the partial information nature of price elasticity modelling, together with the non-negotiable responsibility for protecting profitability, mean that machine learning practitioners must often go through great lengths to define strategies for measuring offline model quality. In the face of this, many retailers fall back on rule-based methods, thus forgoing significant gains in profitability that can be captured by machine learning. In this paper, we introduce two novel end-to-end markdown management systems for optimising markdown at different stages of a retailer's journey. The first system, "Ithax," enacts a rational supply-side pricing strategy without demand estimation, and can be usefully deployed as a "cold start" solution to collect markdown data while maintaining revenue control. The second system, "Promotheus," presents a full framework for markdown optimization with price elasticity. We describe in detail the specific modelling and validation procedures that, within our experience, have been crucial to building a system that performs robustly in the real world. Both markdown systems achieve superior profitability compared to decisions made by our experienced operations teams in a controlled online test, with improvements of 86% (Promotheus) and 79% (Ithax) relative to manual strategies. These systems have been deployed to manage markdown at ASOS.com, and both systems can be fruitfully deployed for price optimization across a wide variety of retail e-commerce settings.|管理折扣促销活动(“降价”)是经营电子商务业务的一个重要组成部分，这里的低效率会严重阻碍零售商的盈利能力。解决这一问题的传统方法在很大程度上依赖于价格弹性模型。然而，价格弹性建模的部分信息性质，加上保护盈利能力的不可协商的责任，意味着机器学习从业人员必须经常花费大量的时间来确定衡量离线模型质量的策略。面对这种情况，许多零售商退回到基于规则的方法，因此放弃了可以通过机器学习获得的利润率的显著增长。在本文中，我们介绍了两个新颖的端到端降价管理系统优化降价在不同阶段的零售商的旅程。第一个系统，“ Ithax”，制定了一个合理的供应侧定价策略，没有需求估计，可以作为一个有用的“冷启动”解决方案，收集降价数据，同时保持收入控制。第二个系统，“茂德修斯”，提出了一个完整的框架降价优化与价格弹性。我们详细描述了具体的建模和验证程序，根据我们的经验，这些程序对于建立一个在现实世界中运行良好的系统至关重要。与我们经验丰富的运营团队在受控的在线测试中做出的决策相比，这两种降价系统都实现了更高的盈利能力，相对于手工策略，降价系统的改进率分别为86% 和79% 。这些系统已经部署到 ASOS.com 管理降价，这两个系统都可以在各种零售电子商务环境中进行价格优化，从而取得丰硕成果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Promotheus:+An+End-to-End+Machine+Learning+Framework+for+Optimizing+Markdown+in+Online+Fashion+E-commerce)|0|
|[Scalar is Not Enough: Vectorization-based Unbiased Learning to Rank](https://doi.org/10.1145/3534678.3539468)|Mouxiang Chen, Chenghao Liu, Zemin Liu, Jianling Sun|Zhejiang University & Alibaba-Zhejiang University Joint Institute of Frontier Technologies, Hangzhou, China; Salesforce Research Area, Singapore, Singapore; Singapore Management University, Singapore, Singapore|Unbiased learning to rank (ULTR) aims to train an unbiased ranking model from biased user click logs. Most of the current ULTR methods are based on the examination hypothesis (EH), which assumes that the click probability can be factorized into two scalar functions, one related to ranking features and the other related to bias factors. Unfortunately, the interactions among features, bias factors and clicks are complicated in practice, and usually cannot be factorized in this independent way. Fitting click data with EH could lead to model misspecification and bring the approximation error. In this paper, we propose a vector-based EH and formulate the click probability as a dot product of two vector functions. This solution is complete due to its universality in fitting arbitrary click functions. Based on it, we propose a novel model named Vectorization to adaptively learn the relevance embeddings and sort documents by projecting embeddings onto a base vector. Extensive experiments show that our method significantly outperforms the state-of-the-art ULTR methods on complex real clicks as well as simple simulated clicks.|无偏学习排名(ULTR)的目的是从有偏见的用户点击日志中训练一个无偏见的排名模型。目前的 ULTR 方法大多基于检验假设(EH) ，假设点击概率可以分解为两个标量函数，一个与排序特征有关，另一个与偏差因子有关。遗憾的是，特征、偏差因素和点击之间的相互作用在实践中是复杂的，通常不能以这种独立的方式进行因子分解。将 click 数据与 EH 进行匹配可能导致模型错误说明，并带来逼近误差。本文提出了一种基于向量的 EH，并将点击概率表示为两个向量函数的点乘。该解决方案是完整的，因为它在拟合任意点击函数的通用性。在此基础上，提出了一种新的向量化模型，通过向基向量投影来自适应地学习相关嵌入和排序文档。大量的实验表明，我们的方法在复杂的真实点击和简单的模拟点击方面明显优于最先进的 ULTR 方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalar+is+Not+Enough:+Vectorization-based+Unbiased+Learning+to+Rank)|0|
|[Efficient Approximate Algorithms for Empirical Variance with Hashed Block Sampling](https://doi.org/10.1145/3534678.3539377)|Xingguang Chen, Fangyuan Zhang, Sibo Wang|The Chinese University of Hong Kong, Hong Kong, China|Empirical variance is a fundamental concept widely used in data management and data analytics, e.g., query optimization, approximate query processing, and feature selection. A direct solution to derive the empirical variance is scanning the whole data table, which is expensive when the data size is huge. Hence, most current works focus on approximate answers by sampling. For results with approximation guarantees, the samples usually need to be uniformly independent random, incurring high cache miss rates especially in compact columnar style layouts. An alternative uses block sampling to avoid this issue, which directly samples a block of consecutive records fitting page sizes instead of sampling one record each time. However, this provides no theoretical guarantee. Existing studies show that the practical estimations can be inaccurate as the records within a block can be correlated. Motivated by this, we investigate how to provide approximation guarantees for empirical variances with block sampling from a theoretical perspective. Our results shows that if the records stored in a table are 4-wise independent to each other according to keys, a slightly modified block sampling can provide the same approximation guarantee with the same asymptotic sampling cost as that of independent random sampling. In practice, storing records via hash clusters or hash organized tables are typical scenarios in modern commercial database systems. Thus, for data analysis on tables in the data lake or OLAP stores that are exported from such hash-based storage, our strategy can be easily integrated to improve the sampling efficiency. Based on our sampling strategy, we present an approximate algorithm for empirical variance and an approximate top-k algorithm to return the k columns with the highest empirical variance scores. Extensive experiments show that our solutions outperform existing solutions by up to an order of magnitude.|经验方差是数据管理和数据分析中广泛使用的一个基本概念，如查询优化、近似查询处理和特征选择。推导经验方差的直接方法是对整个数据表进行扫描，当数据量很大时，扫描成本很高。因此，目前大多数的工作集中在抽样近似答案。对于具有近似保证的结果，样本通常需要是一致独立的随机的，特别是在紧凑的柱状样式布局中，会导致高缓存错过率。另一种方法是使用块抽样来避免这个问题，即直接抽样一个连续的记录块来适应页面大小，而不是每次抽样一个记录。然而，这并不能提供理论上的保证。现有的研究表明，实际的估计可能是不准确的，因为一个区块内的记录可以相关。在此基础上，我们从理论的角度研究了如何为区组抽样的经验方差提供近似保证。结果表明，如果存储在表中的记录按键相互独立，稍加修改的块抽样可以提供与独立随机抽样相同的渐近抽样代价的近似保证。在实践中，通过散列集群或散列组织表存储记录是现代商业数据库系统中的典型场景。因此，对于从这种基于散列的存储器导出的数据湖或 OLAP 存储器中的表的数据分析，可以很容易地将我们的策略集成起来以提高采样效率。基于我们的抽样策略，我们提出了一个经验方差的近似算法和一个近似 top-k 算法来返回经验方差得分最高的 k 列。大量的实验表明，我们的解决方案比现有解决方案的性能高出一个数量级。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Approximate+Algorithms+for+Empirical+Variance+with+Hashed+Block+Sampling)|0|
|[Towards a Native Quantum Paradigm for Graph Representation Learning: A Sampling-based Recurrent Embedding Approach](https://doi.org/10.1145/3534678.3539327)|Ge Yan, Yehui Tang, Junchi Yan|Shanghai Jiao Tong University, Shanghai, China|Graph representation learning has been extensively studied, and recent models can well incorporate both node features and graph structures. Despite these progress, the inherent scalability challenge for classical computers of processing graph data and solving the downstream tasks (many are NP-hard) is still a bottleneck for existing classical graph learning models. On the other hand, quantum computing is known a promising direction for its theoretically verified scalability as well as the increasing evidence for the access to physical quantum machine in near-term. Different from many existing classical-quantum hybrid machine learning models on graphs, in this paper we take a more aggressive initiative for developing a native quantum paradigm for (attributed) graph representation learning, which to our best knowledge, has not been fulfilled in literature yet. Specifically, our model adopts the well-established theory and technique in quantum computing e.g. quantum random walk, and adapt it to the attributed graph. Then the node attribute quantum state sequence is fed into a quantum recurrent network to obtain the final node embedding. Experimental results on three public datasets show the effectiveness of our quantum model which also outperforms a classical learning approach GraphRNA notably in terms of efficiency even on a classical computer. Though it is still restricted to the classical loss-based learning paradigm with gradient descent for model parameter training, while our computing scheme is compatible with quantum computing without involving classical computers. This is in fact largely in contrast to many hybrid quantum graph learning models which often involve many steps and modules having to be performed on classical computers.|图表示学习已经得到了广泛的研究，现有的模型能够很好地结合节点特征和图结构。尽管取得了这些进展，经典计算机在处理图形数据和解决下游任务(许多是 NP 难的)方面固有的可伸缩性挑战仍然是现有经典图形学习模型的瓶颈。另一方面，量子计算因其在理论上被证实的可扩展性以及近期越来越多的物理量子计算的证据而被认为是一个有前途的方向。与许多现有的经典-量子混合机器学习模型不同，本文采取了更积极的主动性，开发了一个本土的量子范式(属性)图表示学习，据我们所知，这尚未在文献中得到实现。具体地说，我们的模型采用了量子计算中已经成熟的理论和技术，例如量子随机游走，并将其适用于属性图。然后将节点属性量子状态序列输入到量子递归网络中，得到最终的节点嵌入。在三个公共数据集上的实验结果表明了量子模型的有效性，即使在经典的计算机上，量子模型的效率也明显优于经典的学习方法 GraphRNA。虽然我们的计算机系统仍然局限于传统的以损失为基础的学习范式，并且只有模型参数训练的梯度下降法，但我们的计算机系统可以与量子计算兼容，而不需要使用传统的计算机。这实际上在很大程度上与许多混合量子图学习模型形成对比，这些模型通常涉及许多步骤和模块，必须在经典计算机上执行。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+a+Native+Quantum+Paradigm+for+Graph+Representation+Learning:+A+Sampling-based+Recurrent+Embedding+Approach)|0|
|[Toward Real-life Dialogue State Tracking Involving Negative Feedback Utterances](https://doi.org/10.1145/3534678.3539385)|Puhai Yang, Heyan Huang, Wei Wei, XianLing Mao|Beijing Institute of Technology & Beijing Engineering Research Center of High Volume Language Information Processing and Cloud Computing Applications, Beijing, China; Huazhong University of Science and Technology, Wuhan, China; Beijing Institute of Technology, Beijing, China|Recently, the research of dialogue systems has been widely concerned, especially task-oriented dialogue systems, which have received increased attention due to their wide application prospect. As a core component, dialogue state tracking (DST) plays a key role in task-oriented dialogue systems, and its function is to parse natural language dialogues into dialogue state formed by slot-value pairs. It is well known that dialogue state tracking has been well studied and explored on current benchmark datasets such as the MultiWOZ. However, almost all current research completely ignores the user negative feedback utterances that exist in real-life conversations when a system error occurs, which often contains user-provided corrective information for the system error. Obviously, user negative feedback utterances can be used to correct the inevitable errors in automatic speech recognition and model generalization. Thus, in this paper, we will explore the role of negative feedback utterances in dialogue state tracking in detail through simulated negative feedback utterances. Specifically, due to the lack of dataset involving negative feedback utterances, first, we have to define the schema of user negative feedback utterances and propose a joint modeling method for feedback utterance generation and filtering. Then, we explore three aspects of interaction mechanism that should be considered in real-life conversations involving negative feedback utterances and propose evaluation metrics related to negative feedback utterances. Finally, on WOZ2.0 and MultiWOZ2.1 datasets, by constructing simulated negative feedback utterances in training and testing, we not only verify the important role of negative feedback utterances in dialogue state tracking, but also analyze the advantages and disadvantages of different interaction mechanisms involving negative feedback utterances, lighting future research on negative feedback utterances.|近年来，对话系统的研究受到了广泛的关注，尤其是面向任务的对话系统，由于其广阔的应用前景而受到越来越多的关注。对话状态跟踪(DST)是任务导向对话系统的核心组成部分，其功能是将自然语言对话解析为由插槽值对形成的对话状态。众所周知，对话状态跟踪已经在当前的基准数据集(如 MultiWOZ)上得到了很好的研究和探索。然而，目前几乎所有的研究都完全忽视了系统错误发生时用户在现实交谈中的负面反馈语，其中往往包含用户提供的系统错误纠正信息。显然，用户负反馈话语可以用来纠正语音自动识别和模型推广中不可避免的错误。因此，本文将通过模拟负反馈话语来详细探讨负反馈话语在对话状态跟踪中的作用。具体来说，由于缺乏涉及负反馈话语的数据集，首先，我们必须定义用户负反馈话语的模式，并提出一种联合建模的方法来生成和过滤反馈话语。然后，从三个方面探讨了负反馈话语在现实会话中应该考虑的互动机制，并提出了与负反馈话语相关的评价指标。最后，在 WOZ2.0和 MultiWOZ2.1数据集上，通过构建训练和测试中的模拟负反馈话语，不仅验证了负反馈话语在对话状态跟踪中的重要作用，而且分析了负反馈话语不同交互机制的优缺点，为进一步研究负反馈话语提供参考。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Toward+Real-life+Dialogue+State+Tracking+Involving+Negative+Feedback+Utterances)|0|
|[M-Mix: Generating Hard Negatives via Multi-sample Mixing for Contrastive Learning](https://doi.org/10.1145/3534678.3539248)|Shaofeng Zhang, Meng Liu, Junchi Yan, Hengrui Zhang, Lingxiao Huang, Xiaokang Yang, Pinyan Lu|Shanghai University of Finance and Economics & Huawei TCS Lab, Shanghai, China; Huawei TCS Lab, Shanghai, China; Shanghai Jiao Tong University, Shanghai, China|Negative pairs, especially hard negatives as combined with common negatives (easy to discriminate), are essential in contrastive learning, which plays a role of avoiding degenerate solutions in the sense of constant representation across different instances. Inspired by recent hard negative mining methods via pairwise mixup operation in vision, we propose M-Mix, which dynamically generates a sequence of hard negatives. Compared with previous methods, M-Mix mainly has three features: 1) adaptively choose samples to mix; 2) simultaneously mix multiple samples; 3) automatically assign different mixing weights to the selected samples. We evaluate our method on two image datasets (CIFAR-10, CIFAR-100), five node classification datasets (PPI, DBLP, Pubmed, etc), five graph classification datasets (IMDB, PTC_MR, etc), and two downstream combinatorial tasks (graph edit distance and node clustering). Results show that it achieves state-of-the-art performance under self-supervised settings. Code is available at: https://github.com/Sherrylone/m-mix.|否定对，尤其是硬否定与普通否定(容易区分)的结合，在对比学习中是必不可少的，对比学习的作用是避免退化的解决方案在不同情况下的持续表征。受当前视觉硬负片挖掘方法的启发，提出了 M-Mix 算法，该算法动态生成硬负片序列。与以往的混合方法相比，M-Mix 方法主要有三个特点: 1)自适应地选择混合样本; 2)同时混合多个样本; 3)自动分配不同的混合权重给选定的样本。我们在两个图像数据集(CIFAR-10，CIFAR-100) ，五个节点分类数据集(PPI，DBLP，Pubmed 等) ，五个图形分类数据集(IMDB，PTC _ MR 等)和两个下游组合任务(图形编辑距离和节点聚类)上评估我们的方法。结果表明，该算法在自监督设置下达到了最佳性能。密码可于以下 https://github.com/sherrylone/m-mix 索取:。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=M-Mix:+Generating+Hard+Negatives+via+Multi-sample+Mixing+for+Contrastive+Learning)|0|
|[Modeling Persuasion Factor of User Decision for Recommendation](https://doi.org/10.1145/3534678.3539114)|Chang Liu, Chen Gao, Yuan Yuan, Chen Bai, Lingrui Luo, Xiaoyi Du, Xinlei Shi, Hengliang Luo, Depeng Jin, Yong Li|Meituan Inc., Beijing, China; Tsinghua University, Beijing, China|In online information systems, users make decisions based on factors of several specific aspects, such as brand, price, etc. Existing recommendation engines ignore the explicit modeling of these factors, leading to sub-optimal recommendation performance. In this paper, we focus on the real-world scenario where these factors can be explicitly captured (the users are exposed with decision factor-based persuasion texts, i.e., persuasion factors). Although it allows us for explicit modeling of user-decision process, there are critical challenges including the persuasion factor's representation learning and effect estimation, along with the data-sparsity problem. To address them, in this work, we present our POEM (short for Persuasion factOr Effect Modeling) system. We first propose the persuasion-factor graph convolutional layers for encoding and learning representations from the persuasion-aware interaction data. Then we develop a prediction layer that fully considers the user sensitivity to the persuasion factors. Finally, to address the data-sparsity issue, we propose a counterfactual learning-based data augmentation method to enhance the supervision signal. Real-world experiments demonstrate the effectiveness of our proposed framework of modeling the effect of persuasion factors.|在网络信息系统中，用户根据品牌、价格等几个具体方面的因素进行决策。现有的推荐引擎忽略了这些因素的显式建模，导致推荐性能不理想。在本文中，我们关注的是真实世界中这些因素可以被明确地捕获的场景(用户暴露在基于决策因素的说服文本中，即，说服因素)。尽管它允许我们对用户决策过程进行明确的建模，但是仍然存在一些关键的挑战，包括说服因子的表示学习和效果估计，以及数据稀疏问题。为了解决这些问题，在本文中，我们提出了我们的 POEM (劝导因素效果建模的缩写)系统。我们首先提出了说服因子图卷积层，用于从感知说服的交互数据中编码和学习表示。然后我们开发了一个预测层，充分考虑了用户对说服因素的敏感性。最后，针对数据稀疏问题，提出了一种基于反事实学习的数据增强方法来增强监控信号。现实世界的实验证明了我们提出的说服因素效应建模框架的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modeling+Persuasion+Factor+of+User+Decision+for+Recommendation)|0|
|[Lion: A GPU-Accelerated Online Serving System for Web-Scale Recommendation at Baidu](https://doi.org/10.1145/3534678.3539058)|Hao Liu, Qian Gao, Xiaochao Liao, Guangxing Chen, Hao Xiong, Silin Ren, Guobao Yang, Zhiwei Zha|Baidu, Inc., Beijing, China; HKUST(GZ), HKUST, Guangzhou, China|Deep Neural Network (DNN) based recommendation systems are widely used in the modern internet industry for a variety of services. However, the rapid expansion of application scenarios and the explosive global internet traffic growth have caused the industry to face increasing challenges to serve the complicated recommendation workflow regarding online recommendation efficiency and compute resource overhead. In this paper, we present a GPU-accelerated online serving system, namely Lion, which consists of the staged event-driven heterogeneous pipeline, unified memory manager, and automatic execution optimizer to handle web-scale traffic in a real-time and cost-effective way. Moreover, Lion provides a heterogeneous template library to enable fast development and migration for diverse in-house web-scale recommendation systems without requiring knowledge of heterogeneous programming. The system is currently deployed at Baidu, supporting over twenty recommendation services, including news feed, short video clips, and the search engine. Extensive experimental studies on five real-world deployed online recommendation services demonstrate the superiority of the proposed GPU-accelerated online serving system. Since launched in early 2020, Lion has answered billions of recommendation requests per day, and has helped Baidu successfully save millions of U.S. dollars in hardware and utility costs per year.|基于深度神经网络(DNN)的推荐系统广泛应用于现代互联网行业的各种服务。然而，应用场景的快速扩展和全球互联网流量的爆炸性增长，使得业界面临着越来越多的挑战，以服务复杂的推荐工作流，包括在线推荐效率和计算资源开销。本文提出了一种基于 GPU 加速的在线服务系统 Lion，该系统由分级事件驱动的异构流水线、统一内存管理器和自动执行优化器组成，能够实时、高效地处理网络流量。此外，Lion 还提供了一个异构模板库，可以在不需要异构编程知识的情况下快速开发和迁移各种内部 Web 规模的推荐系统。该系统目前部署在百度，支持超过20种推荐服务，包括新闻馈送、短视频剪辑和搜索引擎。通过对五个实际部署的在线推荐服务的大量实验研究，证明了所提出的 GPU 加速在线服务系统的优越性。自2020年初推出以来，Lion 每天回应了数十亿的推荐请求，并帮助百度每年成功节省了数百万美元的硬件和公用事业成本。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Lion:+A+GPU-Accelerated+Online+Serving+System+for+Web-Scale+Recommendation+at+Baidu)|0|
|[CognitionNet: A Collaborative Neural Network for Play Style Discovery in Online Skill Gaming Platform](https://doi.org/10.1145/3534678.3539179)|Rukma Talwadker, Surajit Chakrabarty, Aditya Pareek, Tridib Mukherjee, Deepak Saini|Games24x7, Artificial Intelligence & Sci, Bangalore, Karnataka, India; Games24x7, Prod Delight, Bangalore, Karnataka, India|Games are one of the safest source of realizing self-esteem and relaxation at the same time. An online gaming platform typically has massive data coming in, e.g., in-game actions, player moves, clickstreams, transactions etc. It is rather interesting, as something as simple as data on gaming moves can help create a psychological imprint of the user at that moment, based on her impulsive reactions and response to a situation in the game. Mining this knowledge can: (a) immediately help better explain observed and predicted player behavior; and (b) consequently propel deeper understanding towards players' experience, growth and protection. To this effect, we focus on discovery of the "game behaviours" as micro-patterns formed by continuous sequence of games and the persistent "play styles" of the players' as a sequence of such sequences on an online skill gaming platform for Rummy. We propose a two stage deep neural network, CognitionNet. The first stage focuses on mining game behaviours as cluster representations in a latent space while the second aggregates over these micro patterns to discover play styles via a supervised classification objective around player engagement. The dual objective allows CognitionNet to reveal several player psychology inspired decision making and tactics. To our knowledge, this is the first and one-of-its-kind research to fully automate the discovery of: (i) player psychology and game tactics from telemetry data; and (ii) relevant diagnostic explanations to players' engagement predictions. The collaborative training of the two networks with differential input dimensions is enabled using a novel formulation of "bridge loss". The network plays pivotal role in obtaining homogeneous and consistent play style definitions and significantly outperforms the SOTA baselines wherever applicable.|游戏是实现自尊与放松双重需求最安全的途径之一。在线游戏平台通常会产生海量数据，例如游戏内操作、玩家移动轨迹、点击流、交易记录等。有趣的是，仅通过游戏操作这类简单数据，就能基于玩家在游戏情境中的即时反应，构建其当下的心理画像。挖掘这种知识能够：(a) 即时帮助更好地解释已观测和预测的玩家行为；(b) 进而深化对玩家体验、成长和保护机制的理解。基于此，我们专注于在拉米牌技能游戏平台上发现由连续游戏序列形成的"游戏行为"微模式，以及由这类序列链构成的持久性"游戏风格"。我们提出双阶段深度神经网络CognitionNet：第一阶段通过潜在空间中的聚类表征挖掘游戏行为，第二阶段通过围绕玩家参与度的监督分类目标聚合微模式以发现游戏风格。双重目标使CognitionNet能够揭示多种受玩家心理启发的决策与战术。据我们所知，这是首个实现全自动化发现的研究：(i) 从遥测数据中解析玩家心理与游戏战术；(ii) 为玩家参与度预测提供相关诊断解释。通过创新性提出的"桥接损失"公式，实现了双网络在差异输入维度下的协同训练。该网络在获取同质化、一致性的游戏风格定义方面发挥关键作用，并在所有适用场景中显著优于当前最先进的基线模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CognitionNet:+A+Collaborative+Neural+Network+for+Play+Style+Discovery+in+Online+Skill+Gaming+Platform)|0|
|[FedAttack: Effective and Covert Poisoning Attack on Federated Recommendation via Hard Sampling](https://doi.org/10.1145/3534678.3539119)|Chuhan Wu, Fangzhao Wu, Tao Qi, Yongfeng Huang, Xing Xie|Tsinghua Univ, Dept Elect Engn, Beijing, Peoples R China; Microsoft Res Asia, Beijing, Peoples R China|Federated learning (FL) is a feasible technique to learn personalized recommendation models from decentralized user data. Unfortunately, federated recommender systems are vulnerable to poisoning attacks by malicious clients. Existing recommender system poisoning methods mainly focus on promoting the recommendation chances of target items due to financial incentives. In fact, in real-world scenarios, the attacker may also attempt to degrade the overall performance of recommender systems. However, existing general FL poisoning methods for degrading model performance are either ineffective or not concealed in poisoning federated recommender systems. In this paper, we propose a simple yet effective and covert poisoning attack method on federated recommendation, named FedAttack. Its core idea is using globally hardest samples to subvert model training. More specifically, the malicious clients first infer user embeddings based on local user profiles. Next, they choose the candidate items that are most relevant to the user embeddings as hardest negative samples, and find the candidates farthest from the user embeddings as hardest positive samples. The model gradients inferred from these poisoned samples are then uploaded for aggregation. Extensive experiments on two benchmark datasets show that FedAttack can effectively degrade the performance of various federated recommender systems, meanwhile cannot be effectively detected nor defended by many existing methods.|联邦学习（FL）是一种从去中心化用户数据中学习个性化推荐模型的可行技术。然而，联邦推荐系统易受恶意客户端投毒攻击的威胁。现有推荐系统投毒方法主要基于经济利益驱动，侧重于提升目标物品的推荐概率。事实上，在真实场景中，攻击者可能还会试图降低推荐系统的整体性能。但现有旨在降低模型性能的通用联邦学习投毒方法，在攻击联邦推荐系统时要么效果有限，要么缺乏隐蔽性。本文提出一种简单却高效隐蔽的联邦推荐投毒攻击方法FedAttack，其核心思想是利用全局最难样本颠覆模型训练。具体而言：恶意客户端首先基于本地用户画像推断用户嵌入向量；接着选择与用户嵌入最相关的候选物品作为最难负样本，同时选取距离用户嵌入最远的候选物品作为最难正样本；最终将这些 poisoned 样本推断出的模型梯度上传聚合。在两个基准数据集上的大量实验表明，FedAttack能有效降低多种联邦推荐系统的性能，且现有检测与防御方法均难以有效应对该攻击。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FedAttack:+Effective+and+Covert+Poisoning+Attack+on+Federated+Recommendation+via+Hard+Sampling)|0|
|[Mixture of Virtual-Kernel Experts for Multi-Objective User Profile Modeling](https://doi.org/10.1145/3534678.3539062)|Zhenhui Xu, Meng Zhao, Liqun Liu, Lei Xiao, Xiaopeng Zhang, Bifeng Zhang|Tencent Inc, Shenzhen, Guangdong, Peoples R China; Tencent Inc, Beijing, Peoples R China|In industrial applications like online advertising and recommendation systems, diverse and accurate user profiles can greatly help improve personalization. Deep learning is widely applied to mine expressive tags to users from their historical interactions in the system, e.g., click, conversion action in the advertising chain. The usual approach is to take a certain action as the objective, and introduce multiple independent Two-Tower models to predict the possibility of users' action on tags (known as CTR or CVR prediction). The predicted users' high probably attractive tags are to represent their preferences. However, the single-action models cannot learn complementarily and support effective training on data-sparse actions. Besides, limited by the lack of information fusion between the two towers, the model learns insufficiently to represent users' preferences on various tag topics well. This paper introduces a novel multi-task model called Mixture of Virtual-Kernel Experts (MVKE) to learn user preferences on various actions and topics unitedly. In MVKE, we propose a concept of Virtual-Kernel Expert, which focuses on modeling one particular facet of the user's preferences, and all of them learn coordinately. Besides, the gate-based structure used in MVKE builds an information fusion bridge between two towers, improving the model's capability and maintaining high efficiency. We apply the model in Tencent Advertising System, where both online and offline evaluations show that our method has a significant improvement compared with the existing ones and brings about an obvious lift to actual advertising revenue.|在在线广告和推荐系统等工业应用中，多样化且准确的用户画像能极大助力个性化提升。深度学习被广泛应用于从用户历史交互行为（如广告链中的点击、转化行为）中挖掘富有表现力的用户标签。常规做法是以特定动作为目标，引入多个独立双塔模型来预测用户对标签的行为可能性（即CTR或CVR预测），再将预测的高吸引力标签作为用户偏好表征。然而，单行为模型无法实现互补学习，也难以在数据稀疏的行为上有效训练。此外，受限于双塔间信息融合的缺失，模型难以充分学习用户在不同标签主题上的偏好表征。本文提出一种名为虚拟核专家混合模型（MVKE）的新型多任务模型，可联合学习用户在不同行为和主题上的偏好。该模型创新性地提出虚拟核专家概念——每个专家专注于建模用户偏好的特定维度，并通过协同学习机制实现知识共享。MVKE采用的门控结构在双塔间构建了信息融合桥梁，在提升模型能力的同时保持了高效率。我们将该模型应用于腾讯广告系统，线上线下评估均表明：相较现有方法，本方案带来显著提升并实际拉动广告收入增长。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mixture+of+Virtual-Kernel+Experts+for+Multi-Objective+User+Profile+Modeling)|0|
|[Embedding Compression with Hashing for Efficient Representation Learning in Large-Scale Graph](https://doi.org/10.1145/3534678.3539068)|ChinChia Michael Yeh, Mengting Gu, Yan Zheng, Huiyuan Chen, Javid Ebrahimi, Zhongfang Zhuang, Junpeng Wang, Liang Wang, Wei Zhang|Research Scientist, VISA; Principal Scientist, VISA; Visa Res, Austin, TX 78759 USA; Researcher, VISA|Graph neural networks (GNNs) are deep learning models designed specifically for graph data, and they typically rely on node features as the input to the first layer. When applying such a type of network on the graph without node features, one can extract simple graph-based node features (e.g., number of degrees) or learn the input node representations (i.e., embeddings) when training the network. While the latter approach, which trains node embeddings, more likely leads to better performance, the number of parameters associated with the embeddings grows linearly with the number of nodes. It is therefore impractical to train the input node embeddings together with GNNs within graphics processing unit (GPU) memory in an end-to-end fashion when dealing with industrial-scale graph data. Inspired by the embedding compression methods developed for natural language processing (NLP) tasks, we develop a node embedding compression method where each node is compactly represented with a bit vector instead of a floating-point vector. The parameters utilized in the compression method can be trained together with GNNs. We show that the proposed node embedding compression method achieves superior performance compared to the alternatives.|图神经网络（GNN）是专为图数据设计的深度学习模型，其第一层通常以节点特征作为输入。当将此类网络应用于无节点特征的图结构时，既可提取基于图的简单节点特征（如度数值），也可在训练网络时学习输入节点的表示（即嵌入）。虽然通过训练节点嵌入的方法往往能获得更优性能，但与之相关的参数量会随节点数量线性增长。因此，在处理工业级规模的图数据时，以端到端方式在图形处理器（GPU）内存中同时训练输入节点嵌入与图神经网络实际上并不可行。受自然语言处理（NLP）任务中嵌入压缩方法的启发，我们开发了一种节点嵌入压缩技术：每个节点通过比特向量而非浮点向量进行紧凑表示，且压缩方法中涉及的参数可与图神经网络协同训练。实验表明，相较于其他方案，本文提出的节点嵌入压缩方法实现了更优越的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Embedding+Compression+with+Hashing+for+Efficient+Representation+Learning+in+Large-Scale+Graph)|0|
|[Medical Symptom Detection in Intelligent Pre-Consultation Using Bi-directional Hard-Negative Noise Contrastive Estimation](https://doi.org/10.1145/3534678.3539124)|Shiwei Zhang, Jichao Sun, Yu Huang, Xueqi Ding, Yefeng Zheng|Tencent Jarvis Lab, Shenzhen, Peoples R China|Leveraging artificial intelligence (AI) techniques in medical applications is helping our world to deal with the shortage of healthcare workers and improve the efficiency and productivity of healthcare delivery. Intelligent pre-consultation (IPC) is a relatively new application deployed on mobile terminals for collecting patient's information before a face-to-face consultation. It takes advantages of state-of-the-art machine learning techniques to assist doctors on clinical decision-making. One of key functions of IPC is to detect medical symptoms from patient queries. By extracting symptoms from patient queries, IPC is able to collect more information on patient's health status by asking symptom-related questions. All collected information will be summarized as a medical record for doctors to make clinical decision. This saves a great deal of time for both doctors and patients. Detecting symptoms from patient's query is challenging, as most patients lack medical background and often tend to use colloquial language to describe their symptoms. In this work, we formulate symptom detection as a retrieval problem and propose a bi-directional hard-negative enforced noise contrastive estimation method (Bi-hardNCE) to tackle the symptom detection problem. Bi-hardNCE has both forward contrastive estimation and backward contrastive estimation, which forces model to distinguish the true symptom from negative symptoms and meanwhile distinguish true query from negative queries. To include more informative negatives, our Bi-hardNCE adopts a hard-negative mining strategy and a false-negative eliminating strategy, which achieved a significant improvement on performance. Our proposed model outperforms commonly used retrieval models by a large margin.|在医疗应用中运用人工智能（AI）技术，有助于全球应对医护人员短缺问题，并提升医疗服务的效率与生产力。智能预问诊（IPC）作为新兴移动终端应用，可在面诊前收集患者信息。该系统依托前沿机器学习技术辅助医生进行临床决策，其核心功能是从患者主诉中识别医疗症状。通过提取症状信息，IPC能进一步提出症状相关问题以获取更全面的健康状况数据，所有采集信息将汇总成医疗档案供医生临床决策，显著节省医患双方时间。由于患者多缺乏医学背景且常使用口语化描述，症状检测面临巨大挑战。本研究将症状检测构建为检索任务，提出双向硬负样本增强噪声对比估计方法（Bi-hardNCE）。该模型同时具备前向对比估计与后向对比估计机制，既能区分真实症状与负样本症状，又能区分真实主诉与负样本主诉。通过采用硬负样本挖掘策略和假负样本消除策略，Bi-hardNCE实现了更具信息量的负样本纳入，显著提升检测性能。实验表明，该模型性能远超常用检索模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Medical+Symptom+Detection+in+Intelligent+Pre-Consultation+Using+Bi-directional+Hard-Negative+Noise+Contrastive+Estimation)|0|
|[User-tag Profile Modeling in Recommendation System via Contrast Weighted Tag Masking](https://doi.org/10.1145/3534678.3539102)|Chenxu Zhu, Peng Du, Xianghui Zhu, Weinan Zhang, Yong Yu, Yang Cao|Alibaba Grp, Beijing, Peoples R China; Shanghai Jiao Tong Univ, Shanghai, Peoples R China|User-tag profile modeling has become one of the novel and significant trends for the future development of industrial recommendation systems, which can be divided into two fundamental tasks: User Preferred Tag (UPT) and Tag Preferred User (TPU) in practical scenarios. In most existing deep learning models for user-tag profiling, the network inputs all the combined tags of the item with the user features when training but inputs only one tag with the user feature to evaluate the user's preference on a single tag when testing. This leads to data discrepancy between the training and testing samples. To address such an issue, we attempt a novel Random Masking Model (RMM) to remain only one tag at the training time by masking. However, it causes two other serious downsides. First, not all tags attached to the same item are equally predictive. Irrelevant tags may introduce noisy signals and thus cause performance degradation. Second, it neglects the impact of combined tags aggregated together, which may be an essential factor leading to user clicks. Therefore, we further propose a framework called Contrast Weighted Tag Masking (CWTM) in this work, which tackles these two issues with two modules: (i) Weighted Masking Module (WMM) introduces the importance network to compute a score for each tag attached to the item and then samples from these tags weightedly according to the score; (ii) Contrast Module (CM) makes use of a contrastive learning architecture to inherit and distill some understanding about the effect of aggregated tags. Offline experiments on four datasets (three public datasets and one proprietary industrial dataset) demonstrate the superiority and effectiveness of CWTM over the state-of-the-art baselines. Moreover, CWTM has been deployed on the training platform of Alibaba advertising systems and achieved substantial improvements of ROI and CVR by 16.8% and 9.6%, respectively.|用户标签画像建模已成为工业推荐系统未来发展的新兴重要趋势，在实际场景中可分解为两大基础任务：用户偏好标签（UPT）和标签偏好用户（TPU）。现有大多数用户标签画像深度学习模型在训练时将商品所有组合标签与用户特征共同输入网络，但在测试时仅使用单一标签与用户特征评估用户对单个标签的偏好，导致训练样本与测试样本存在数据分布差异。为解决该问题，我们尝试采用随机掩码模型（RMM）在训练时通过掩码仅保留一个标签。然而这种方法会引发两个新问题：首先，同一商品的所有标签并非都具有同等预测力，无关标签可能引入噪声信号导致性能下降；其次，该方法忽略了组合标签聚合产生的影响，而这可能是引发用户点击的关键因素。因此，我们进一步提出对比加权标签掩码框架（CWTM），通过两个核心模块解决上述问题：（1）加权掩码模块（WMM）引入重要性网络计算商品各标签的权重分数，并依此进行加权采样；（2）对比模块（CM）采用对比学习架构继承并提炼对聚合标签效应的理解。在四个数据集（三个公共数据集和一个工业专有数据集）上的离线实验表明，CWTM在效果上显著优于现有最优基线模型。此外，CWTM已部署于阿里巴巴广告系统训练平台，成功实现投资回报率（ROI）和转化率（CVR）分别提升16.8%和9.6%的显著改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=User-tag+Profile+Modeling+in+Recommendation+System+via+Contrast+Weighted+Tag+Masking)|0|
|[AI for Social Impact: Results from Deployments for Public Health and Conversation](https://doi.org/10.1145/3534678.3539217)|Milind Tambe|Harvard University & Google Research, Cambridge, MA, USA|With the maturing of AI and multiagent systems research, we have a tremendous opportunity to direct these advances towards addressing complex societal problems. I will focus on domains of public health and conservation, and address one key cross-cutting challenge: how to effectively deploy our limited intervention resources in these problem domains. I will present results from work around the globe in using AI for challenges in public health such as Maternal and Child care interventions, HIV prevention, and in conservation such as endangered wildlife protection. Achieving social impact in these domains often requires methodological advances. To that end, I will highlight key research advances in multiagent reasoning and learning, in particular in, restless multiarmed bandits, influence maximization in social networks, computational game theory and decision-focused learning. In pushing this research agenda, our ultimate goal is to facilitate local communities and non-profits to directly benefit from advances in AI tools and techniques|随着人工智能和多智能体系统研究的成熟，我们有一个巨大的机会来指导这些进步，以解决复杂的社会问题。我将侧重于公共卫生和保护领域，并解决一个关键的跨领域挑战: 如何在这些问题领域有效部署我们有限的干预资源。我将介绍全球在利用人工智能应对公共卫生挑战方面的工作成果，如母婴保健干预、艾滋病毒预防以及濒危野生动物保护等方面的工作。要在这些领域产生社会影响，往往需要方法上的进步。为此，我将重点介绍多智能体推理和学习方面的关键研究进展，特别是在不安分的多武装匪徒、社交网络中的影响最大化、计算博弈理论和决策集中学习方面。在推动这一研究议程的过程中，我们的最终目标是促进当地社区和非营利组织直接受益于人工智能工具和技术的进步|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AI+for+Social+Impact:+Results+from+Deployments+for+Public+Health+and+Conversation)|0|
|[Noisy Interactive Graph Search](https://doi.org/10.1145/3534678.3539267)|Qianhao Cong, Jing Tang, Kai Han, Yuming Huang, Lei Chen, Yeow Meng Chee|Hong Kong Univ Sci & Technol, Guangzhou, Peoples R China; Natl Univ Singapore, Dept Ind Syst Engn & Management, Singapore, Singapore; Soochow Univ, Sch Comp Sci & Technol, Suzhou, Peoples R China|The interactive graph search (IGS) problem aims to locate an initially unknown target node leveraging human intelligence. In IGS, we can gradually find the target node by sequentially asking humans some reachability queries like "is the target node reachable from a given node x?". However, human workers may make mistakes when answering these queries. Motivated by this concern, in this paper, we study a noisy version of the IGS problem. Our objective in this problem is to minimize the query complexity while ensuring accuracy. We propose a method to select the query node such that we can push the search process as much as possible and an online method to infer which node is the target after collecting a new answer. By rigorous theoretical analysis, we show that the query complexity of our approach is near-optimal up to a constant factor. The extensive experiments on two real datasets also demonstrate the superiorities of our approach.|交互式图搜索（IGS）问题旨在利用人类智能定位初始未知的目标节点。在该问题中，我们可以通过连续向人类提出诸如"目标节点是否可从给定节点x到达？"的可达性查询来逐步定位目标节点。然而，人工工作者在回答这些查询时可能出现错误。基于这一考量，本文研究了含噪声的IGS问题，目标是在保证准确性的前提下最小化查询复杂度。我们提出了选择查询节点的方法以最大化推进搜索进程，并设计了一种在线推断机制，在获得新应答后实时推测目标节点。通过严格的理论分析，我们证明所提方法的查询复杂度在常数因子范围内接近最优。在两个真实数据集上的大量实验也验证了本方法的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Noisy+Interactive+Graph+Search)|0|
|[LinE: Logical Query Reasoning over Hierarchical Knowledge Graphs](https://doi.org/10.1145/3534678.3539338)|Zijian Huang, MengFen Chiang, WangChien Lee|Penn State Univ, University Pk, PA 16802 USA; Univ Auckland, Auckland, New Zealand|Logical reasoning over Knowledge Graphs (KGs) for first-order logic (FOL) queries performs the query inference over KGs with logical operators, including conjunction, disjunction, existential quantification and negation, to approximate true answers in embedding spaces. However, most existing work imposes strong distributional assumptions (e.g., Beta distribution) to represent entities and queries into presumed distributional shape, which limits their expressive power. Moreover, query embeddings are challenging due to the relational complexities in multi-relational KGs (e.g., symmetry, anti-symmetry and transitivity). To bridge the gap, we propose a logical query reasoning framework, Line Embedding (LinE), for FOL queries. To relax the distributional assumptions, we introduce the logic space transformation layer, which is a generic neural function that converts embeddings from probabilistic distribution space to LinE embeddings space. To tackle multi-relational and logical complexities, we formulate neural relation-specific projections and individual logical operators to truthfully ground LinE query embeddings on logical regularities and KG factoids. Lastly, to verify the LinE embedding quality, we generate a FOL query dataset from WordNet, which richly encompasses hierarchical relations. Extensive experiments show superior reasoning sensitivity of LinE on three benchmarks against strong baselines, particularly for multi-hop relational queries and negation-related queries.|知识图谱（KG）上的一阶逻辑（FOL）查询推理通过逻辑运算符（包括合取、析取、存在量词与否定）在嵌入空间中执行查询推断以逼近真实答案。然而现有研究大多采用强分布假设（如贝塔分布）将实体与查询映射至预设分布形态，限制了其表达能力。此外，由于多关系知识图谱中存在复杂关系特性（如对称性、非对称性与传递性），查询嵌入面临巨大挑战。为此，我们提出面向一阶逻辑查询的逻辑推理框架Line Embedding（LinE）。为弱化分布假设，我们设计了逻辑空间转换层——一种将嵌入从概率分布空间转换至LinE嵌入空间的通用神经函数。针对多关系与逻辑复杂性，我们构建了神经关系特定投影与独立逻辑运算符，使LinE查询嵌入忠实遵循逻辑规则与知识图谱事实。最后，为验证LinE嵌入质量，我们从富含层次关系的WordNet中生成了一阶逻辑查询数据集。大量实验表明，LinE在三个基准数据集上对多跳关系查询和否定相关查询展现出卓越的推理敏感性，显著优于现有强基线模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LinE:+Logical+Query+Reasoning+over+Hierarchical+Knowledge+Graphs)|0|
|[Transfer Learning based Search Space Design for Hyperparameter Tuning](https://doi.org/10.1145/3534678.3539369)|Yang Li, Yu Shen, Huaijun Jiang, Tianyi Bai, Wentao Zhang, Ce Zhang, Bin Cui|Peking Univ, Sch CS, Beijing, Peoples R China; Peking Univ Qingdao, Sch CS, Peking Univ Inst Computat Social Sci, Beijing, Peoples R China; Beijing Inst Technol, Sch Math & Stat, Beijing, Peoples R China; Swiss Fed Inst Technol, Syst Grp, DS3Lab, Dept Comp Sci, Zurich, Switzerland; Peking Univ Tencent Data Platform, Tencent Inc, Sch CS, Technol & Engn Grp, Beijing, Peoples R China|The tuning of hyperparameters becomes increasingly important as machine learning (ML) models have been extensively applied in data mining applications. Among various approaches, Bayesian optimization (BO) is a successful methodology to tune hyper-parameters automatically. While traditional methods optimize each tuning task in isolation, there has been recent interest in speeding up BO by transferring knowledge across previous tasks. In this work, we introduce an automatic method to design the BO search space with the aid of tuning history from past tasks. This simple yet effective approach can be used to endow many existing BO methods with transfer learning capabilities. In addition, it enjoys the three advantages: universality, generality, and safeness. The extensive experiments show that our approach considerably boosts BO by designing a promising and compact search space instead of using the entire space, and outperforms the state-of-the-arts on a wide range of benchmarks, including machine learning and deep learning tuning tasks, and neural architecture search.|随着机器学习(ML)模型在数据挖掘应用中的广泛使用，超参数调优的重要性日益凸显。在众多方法中，贝叶斯优化(BO)已成为实现超参数自动调优的有效方法。传统方法往往孤立地优化每个调优任务，而最新研究方向则关注通过跨任务知识迁移来加速BO过程。本研究提出一种借助历史调优记录自动设计BO搜索空间的方法。这种简洁而高效的解决方案可为现有BO方法赋予迁移学习能力，并具有三大优势：普适性、通用性和安全性。大量实验表明，通过构建紧凑且具有潜力的搜索空间来替代全空间搜索，我们的方法显著提升了BO性能，在包括机器学习和深度学习调优任务、神经架构搜索等广泛基准测试中均超越了现有最优水平。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Transfer+Learning+based+Search+Space+Design+for+Hyperparameter+Tuning)|0|
|[Graph Structural Attack by Perturbing Spectral Distance](https://doi.org/10.1145/3534678.3539435)|Lu Lin, Ethan Blaser, Hongning Wang|Univ Virginia, Charlottesville, VA 22904 USA|Graph Convolutional Networks (GCNs) have fueled a surge of research interest due to their encouraging performance on graph learning tasks, but they are also shown vulnerability to adversarial attacks. In this paper, an effective graph structural attack is investigated to disrupt graph spectral filters in the Fourier domain, which are the theoretical foundation of GCNs. We define the notion of spectral distance based on the eigenvalues of graph Laplacian to measure the disruption of spectral filters. We realize the attack by maximizing the spectral distance and propose an efficient approximation to reduce the time complexity brought by eigen-decomposition. The experiments demonstrate the remarkable effectiveness of the proposed attack in both black-box and white-box settings for both test-time evasion attacks and training-time poisoning attacks. Our qualitative analysis suggests the connection between the imposed spectral changes in the Fourier domain and the attack behavior in the spatial domain, which provides empirical evidence that maximizing spectral distance is an effective way to change the graph structural property and thus disturb the frequency components for graph filters to affect the learning of GCNs.|图卷积网络（GCN）因其在图学习任务中展现出的优异性能激发了广泛研究兴趣，但同时也被证实易受对抗攻击影响。本文研究了一种有效的图结构攻击方法，通过干扰傅里叶域的图谱滤波器——该理论构成GCN的基础框架——来实现攻击效果。我们基于图拉普拉斯矩阵的特征值定义了谱距离概念，用以衡量对谱滤波器的破坏程度。通过最大化谱距离实现攻击，并提出一种高效近似算法以降低特征分解带来的时间复杂度。实验证明，所提出的攻击方法在黑盒与白盒设置下，针对测试阶段规避攻击和训练阶段投毒攻击均具有显著效果。定性分析表明，傅里叶域的频谱变化与空间域的攻击行为存在关联，这为"最大化谱距离是通过改变图结构属性来干扰图谱滤波器频率成分，进而影响GCN学习"的有效性提供了实证依据。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Structural+Attack+by+Perturbing+Spectral+Distance)|0|
|[Practical Counterfactual Policy Learning for Top-K Recommendations](https://doi.org/10.1145/3534678.3539295)|Yaxu Liu, JuiNan Yen, BoWen Yuan, Rundong Shi, Peng Yan, ChihJen Lin|Meituan, Beijing, Peoples R China; Natl Taiwan Univ, Taipei, Taiwan|For building recommender systems, a critical task is to learn a policy with collected feedback (e.g., ratings, clicks) to decide which items to be recommended to users. However, it has been shown that the selection bias in the collected feedback leads to biased learning and thus a sub-optimal policy. To deal with this issue, counterfactual learning has received much attention, where existing approaches can be categorized as either value learning or policy learning approaches. This work studies policy learning approaches for top-K recommendations with a large item space and points out several difficulties related to importance weight explosion, observation insufficiency, and training efficiency. A practical framework for policy learning is then proposed to overcome these difficulties. Our experiments confirm the effectiveness and efficiency of the proposed framework.|在构建推荐系统时，一项关键任务是根据收集到的用户反馈（如评分、点击等）学习策略，以确定应向用户推荐哪些项目。然而已有研究表明，收集反馈中的选择偏差会导致学习过程产生偏差，从而形成次优策略。为解决这一问题，反事实学习受到广泛关注，现有方法可分为价值学习和策略学习两类。本研究针对海量项目空间中的Top-K推荐策略学习方法展开探讨，指出重要性权重爆炸、观测数据不足及训练效率等多重困难，进而提出克服这些困难的实用策略学习框架。实验结果表明，该框架具有显著的有效性和高效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Practical+Counterfactual+Policy+Learning+for+Top-K+Recommendations)|0|
|[FedWalk: Communication Efficient Federated Unsupervised Node Embedding with Differential Privacy](https://doi.org/10.1145/3534678.3539308)|Qiying Pan, Yifei Zhu||Node embedding aims to map nodes in the complex graph into low-dimensional representations. The real-world large-scale graphs and difficulties of labeling motivate wide studies of unsupervised node embedding problems. Nevertheless, previous effort mostly operates in a centralized setting where a complete graph is given. With the growing awareness of data privacy, data holders who are only aware of one vertex and its neighbours demand greater privacy protection. In this paper, we introduce FedWalk, a random-walk-based unsupervised node embedding algorithm that operates in such a node-level visibility graph with raw graph information remaining locally. FedWalk is designed to offer centralized competitive graph representation capability with data privacy protection and great communication efficiency. FedWalk instantiates the prevalent federated paradigm and contains three modules. We first design a hierarchical clustering tree (HCT) constructor to extract the structural feature of each node. A dynamic time warping algorithm seamlessly handles the structural heterogeneity across different nodes. Based on the constructed HCT, we then design a random walk generator, wherein a sequence encoder is designed to preserve privacy and a two-hop neighbor predictor is designed to save communication cost. The generated random walks are then used to update node embedding based on a SkipGram model. Extensive experiments on two large graphs demonstrate that Fed-Walk achieves competitive representativeness as a centralized node embedding algorithm does with only up to 1.8% Micro-F1 score and 4.4% Marco-F1 score loss while reducing about 6.7 times of inter-device communication per walk.|节点嵌入旨在将复杂网络中的节点映射为低维表示。现实世界的大规模图数据与标注困难性推动了无监督节点嵌入问题的广泛研究。然而现有方法大多基于集中式设置运行，需获取完整的图结构。随着数据隐私意识的增强，仅掌握单个顶点及其邻域信息的数据持有者需要更强的隐私保护。本文提出FedWalk——一种基于随机游走的无监督节点嵌入算法，可在仅具有节点级可见性的图数据上运行，保持原始图信息始终存储于本地。该算法在实现与集中式方法竞争力相当的图表示能力的同时，兼具数据隐私保护特性和优异的通信效率。FedWalk具体实现了联邦学习范式，包含三大核心模块：首先设计层次化聚类树（HCT）构造器以提取节点结构特征，通过动态时间规整算法无缝处理不同节点间的结构异质性；基于构建的HCT，设计包含隐私保护序列编码器和双跳邻居预测器的随机游走生成器以节省通信成本；生成的游走序列最终通过SkipGram模型更新节点嵌入。在两大真实图谱上的实验表明，FedWalk仅产生最高1.8%的Micro-F1分数和4.4%的Macro-F1分数损失即可达到与集中式节点嵌入算法相当的表示能力，同时将每次游走的设备间通信量降低约6.7倍。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FedWalk:+Communication+Efficient+Federated+Unsupervised+Node+Embedding+with+Differential+Privacy)|0|
|[Fair Ranking as Fair Division: Impact-Based Individual Fairness in Ranking](https://doi.org/10.1145/3534678.3539353)|Yuta Saito, Thorsten Joachims|Cornell Univ, Ithaca, NY 14850 USA|Rankings have become the primary interface in two-sided online markets. Many have noted that the rankings not only affect the satisfaction of the users (e.g., customers, listeners, employers, travelers), but that the position in the ranking allocates exposure -- and thus economic opportunity -- to the ranked items (e.g., articles, products, songs, job seekers, restaurants, hotels). This has raised questions of fairness to the items, and most existing works have addressed fairness by explicitly linking item exposure to item relevance. However, we argue that any particular choice of such a link function may be difficult to defend, and we show that the resulting rankings can still be unfair. To avoid these shortcomings, we develop a new axiomatic approach that is rooted in principles of fair division. This not only avoids the need to choose a link function, but also more meaningfully quantifies the impact on the items beyond exposure. Our axioms of envy-freeness and dominance over uniform ranking postulate that for a fair ranking policy every item should prefer their own rank allocation over that of any other item, and that no item should be actively disadvantaged by the rankings. To compute ranking policies that are fair according to these axioms, we propose a new ranking objective related to the Nash Social Welfare. We show that the solution has guarantees regarding its envy-freeness, its dominance over uniform rankings for every item, and its Pareto optimality. In contrast, we show that conventional exposure-based fairness can produce large amounts of envy and have a highly disparate impact on the items. Beyond these theoretical results, we illustrate empirically how our framework controls the trade-off between impact-based individual item fairness and user utility.|排名已成为双边在线市场的主要界面。许多研究指出，排名不仅影响用户（如顾客、听众、雇主、旅行者）的满意度，更通过排序位置为被排名对象（如文章、产品、歌曲、求职者、餐厅、酒店）分配曝光度——进而影响其经济机会。这引发了关于对待被排名对象公平性的讨论，现有研究大多通过将曝光度与内容相关性显式关联来实现公平。然而我们认为，这种关联函数的具体选择往往缺乏理论依据，且实证表明由此产生的排名仍可能存在不公。为克服这些缺陷，我们基于公平分配原则提出了一种新的公理化方法。该方法不仅无需选择关联函数，还能超越曝光度维度更有效地量化排名对被排名对象的影响。我们提出的"无嫉妒性"和"均匀排名优势"公理要求：在公平排名策略下，每个被排名对象都应更偏好自身获得的排名分配而非其他对象的排名分配，且没有对象会因排名策略而处于主动劣势。为实现符合这些公理要求的排名策略，我们提出了与纳什社会福利相关的新排名目标函数。研究证明该解决方案具有无嫉妒性保障、对所有对象的均匀排名优势特性以及帕累托最优性。相比之下，传统基于曝光度的公平性方法可能产生严重嫉妒现象并对不同对象造成高度差异化影响。除理论成果外，我们通过实证研究表明该框架如何基于影响力实现个体公平性与用户效用的权衡控制。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fair+Ranking+as+Fair+Division:+Impact-Based+Individual+Fairness+in+Ranking)|0|
|[Knowledge Enhanced Search Result Diversification](https://doi.org/10.1145/3534678.3539459)|Zhan Su, Zhicheng Dou, Yutao Zhu, JiRong Wen|Univ Montreal, Montreal, PQ, Canada; Renmin Univ China, Gaoling Sch Artificial Intelligence, Beijing, Peoples R China; Beijing Key Lab Big Data Management & Anal Method, Beijing, Peoples R China|Search result diversification focuses on reducing redundancy and improving subtopic richness in the results for a given query. Most existing approaches measure document diversity mainly based on text or pre-trained representations. However, some underlying relationships between the query and documents are difficult for the model to capture only from the content. Given that the knowledge base can offer well-defined entities and explicit relationships between entities, we exploit knowledge to model the relationship between documents and the query and propose a knowledge-enhanced search result diversification approach KEDIV. Concretely, we build a query-specific relation graph to model the complicated query-document relationship from an entity view. Then a graph neural network and node weight adjust algorithm are applied to the relation graph to obtain context-aware entity representations and document representations at each selection step. The diversity features are derived from the updated node representations of the relation graph. In this way, we can take advantage of entities' abundant information to model document's diversity in search result diversification. Experimental results on commonly used datasets show that our proposed approach can outperform the state-of-the-art methods.|搜索结果多样化旨在降低给定查询结果中的冗余度并提升子主题丰富性。现有方法主要基于文本或预训练表征来衡量文档多样性，但仅从内容角度难以捕捉查询与文档间的某些潜在关联。鉴于知识库能够提供定义明确的实体及实体间显式关系，我们利用知识对文档与查询的关系进行建模，提出一种知识增强的搜索结果多样化方法KEDIV。具体而言，我们构建查询特定关系图，从实体视角建模复杂的查询-文档关系，随后应用图神经网络和节点权重调整算法，在每轮选择步骤中获得上下文感知的实体表征与文档表征。多样性特征通过关系图中更新的节点表征推导得出。该方法可利用实体蕴含的丰富信息，在搜索结果多样化任务中有效建模文档多样性。在常用数据集上的实验表明，本方法性能优于现有最先进方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge+Enhanced+Search+Result+Diversification)|0|
|[Self-Supervised Hypergraph Transformer for Recommender Systems](https://doi.org/10.1145/3534678.3539473)|Lianghao Xia, Chao Huang, Chuxu Zhang|Univ Hong Kong, Hong Kong, Peoples R China; Brandeis Univ, Waltham, MA 02254 USA|Graph Neural Networks (GNNs) have been shown as promising solutions for collaborative filtering (CF) with the modeling of user-item interaction graphs. The key idea of existing GNN-based recommender systems is to recursively perform the message passing along the user-item interaction edge for refining the encoded embeddings. Despite their effectiveness, however, most of the current recommendation models rely on sufficient and high-quality training data, such that the learned representations can well capture accurate user preference. User behavior data in many practical recommendation scenarios is often noisy and exhibits skewed distribution, which may result in suboptimal representation performance in GNN-based models. In this paper, we propose SHT, a novel Self-Supervised Hypergraph Transformer framework (SHT) which augments user representations by exploring the global collaborative relationships in an explicit way. Specifically, we first empower the graph neural CF paradigm to maintain global collaborative effects among users and items with a hypergraph transformer network. With the distilled global context, a cross-view generative self-supervised learning component is proposed for data augmentation over the user-item interaction graph, so as to enhance the robustness of recommender systems. Extensive experiments demonstrate that SHT can significantly improve the performance over various state-of-the-art baselines. Further ablation studies show the superior representation ability of our SHT recommendation framework in alleviating the data sparsity and noise issues. The source code and evaluation datasets are available at: https://github.com/akaxlh/SHT.|图神经网络（GNN）已被证明是通过用户-物品交互图建模实现协同过滤（CF）的有效解决方案。现有基于GNN的推荐系统的核心思想是沿着用户-物品交互边递归执行消息传递，以优化编码嵌入表示。尽管效果显著，但当前大多数推荐模型依赖于充足且高质量的训练数据，才能确保学习到的表征准确捕捉用户偏好。实际推荐场景中的用户行为数据往往存在噪声且呈偏态分布，这可能导致基于GNN的模型出现次优表征性能。本文提出SHT——一种新颖的自监督超图Transformer框架，通过显式探索全局协作关系来增强用户表征。具体而言，我们首先通过超图Transformer网络增强图神经协同过滤范式，以维持用户与物品间的全局协作效应。基于提炼的全局上下文信息，进一步提出跨视图生成式自监督学习组件，在用户-物品交互图上进行数据增强，从而提升推荐系统的鲁棒性。大量实验表明，SHT能显著超越现有各类先进基线模型。进一步的消融研究验证了我们的SHT推荐框架在缓解数据稀疏性和噪声问题方面具有卓越的表征能力。源代码和评估数据集已开源：https://github.com/akaxlh/SHT。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-Supervised+Hypergraph+Transformer+for+Recommender+Systems)|0|
|[MetaPTP: An Adaptive Meta-optimized Model for Personalized Spatial Trajectory Prediction](https://doi.org/10.1145/3534678.3539360)|Yuan Xu, Jiajie Xu, Jing Zhao, Kai Zheng, An Liu, Lei Zhao, Xiaofang Zhou|Soochow Univ, Suzhou, Peoples R China; Univ Elect Sci & Technol China, Chengdu, Peoples R China; Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China|Trajectory prediction is a fundamental problem for a wide spectrum of location-based applications. Existing methods can achieve inspiring results in predicting personal frequent routes conditioned on massive historical data. However, trajectory estimation may involve cold-start routes or users due to the data sparsity problem, which severely limits the performance of spatial trajectory prediction. Although meta-learning models can alleviate the cold-start problem, they simply utilize the same initialization for all tasks and thus cannot fit each user well due to users' varying travel preferences. To this end, we propose an adaptive meta-optimized model called MetaPTP for personalized spatial trajectory prediction. Specifically, it adopts a soft-clustering based method to guide the network initialization in a finer granularity, so that shared knowledge can be better transferred across users with similar travel preferences. Besides, towards model fine-tuning, an effective trajectory sampling method is introduced to generate meaningful support set, which simultaneously considers user preference and spatial trace similarities to provide task-related information for model adaptation. In addition, we design a weight generator to adaptively assign reasonable weights to trajectories in support set to avoid sub-optimal results which will occur when fine-tuning the initial network with the same weight for trajectories with different user preferences and spatial distributions. Finally, extensive experiments on two real-world datasets demonstrate the superiority of our model.|轨迹预测是各类基于位置应用的基础性问题。现有方法在利用海量历史数据预测个人高频路线方面已能取得优异效果。但由于数据稀疏性问题，轨迹估算可能涉及冷启动路线或用户，这严重限制了空间轨迹预测的性能。尽管元学习模型能够缓解冷启动问题，但它们对所有任务采用相同的初始化方式，由于用户出行偏好存在差异，无法很好地适配每个用户。为此，我们提出了一种自适应元优化模型MetaPTP，用于个性化空间轨迹预测。该模型采用基于软聚类的方法，以更细粒度指导网络初始化，使得具有相似出行偏好的用户之间能更好地实现知识迁移。在模型微调方面，我们引入有效的轨迹采样方法生成高质量支持集，该方法同时考虑用户偏好和空间轨迹相似性，为模型适配提供任务相关信息。此外，我们设计了权重生成器，自适应地为支持集中的轨迹分配合适权重，避免在对初始网络进行微调时，因对不同用户偏好和空间分布的轨迹采用相同权重而导致的次优结果。最终，在两个真实数据集上的大量实验证明了我们模型的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MetaPTP:+An+Adaptive+Meta-optimized+Model+for+Personalized+Spatial+Trajectory+Prediction)|0|
|[Nimble GNN Embedding with Tensor-Train Decomposition](https://doi.org/10.1145/3534678.3539423)|Chunxing Yin, Da Zheng, Israt Nisa, Christos Faloutsos, George Karypis, Richard W. Vuduc|Amazon, Seattle, WA USA; Georgia Inst Technol, Atlanta, GA 30332 USA|This paper describes a new method for representing embedding tables of graph neural networks (GNNs) more compactly via tensor-train (TT) decomposition. We consider the scenario where (a) the graph data that lack node features, thereby requiring the learning of embeddings during training; and (b) we wish to exploit GPU platforms, where smaller tables are needed to reduce host-to-GPU communication even for large-memory GPUs. The use of TT enables a compact parameterization of the embedding, rendering it small enough to fit entirely on modern GPUs even for massive graphs. When combined with judicious schemes for initialization and hierarchical graph partitioning, this approach can reduce the size of node embedding vectors by 1,659 times to 81,362 times on large publicly available benchmark datasets, achieving comparable or better accuracy and significant speedups on multi-GPU systems. In some cases, our model without explicit node features on input can even match the accuracy of models that use node features.|本文介绍了一种通过张量链(TT)分解实现图神经网络嵌入表紧凑表示的新方法。该方法主要针对两种场景：(a) 图数据缺乏节点特征，需要在训练过程中学习嵌入表示；(b)需要在GPU平台上运行，即使是大内存GPU也需要通过减小表规模来降低主机到GPU的通信开销。TT分解技术能够实现嵌入参数的紧凑化表征，使其即使处理超大规模图数据时也能完全适配现代GPU的显存容量。当结合智能初始化策略和分层图划分方案时，该方法在大型公开基准数据集上可将节点嵌入向量的尺寸缩小1,659至81,362倍，在保持相当或更优精度的同时，显著提升多GPU系统的训练速度。在某些情况下，我们未使用显式节点特征的模型甚至可以达到使用节点特征模型的精度水平。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Nimble+GNN+Embedding+with+Tensor-Train+Decomposition)|0|
|[MDP2 Forest: A Constrained Continuous Multi-dimensional Policy Optimization Approach for Short-video Recommendation](https://doi.org/10.1145/3534678.3539341)|Sizhe Yu, Ziyi Liu, Shixiang Wan, Jia Zheng, Zang Li, Fan Zhou|Tencent Inc, Beijing, Peoples R China; Shanghai Univ Finance & Econ, Sch Stat & Management, Shanghai, Peoples R China; Renmin Univ China, Sch Stat, Beijing, Peoples R China|In the ecology of short video platforms, the optimal exposure proportion of each video category is crucial to guide recommendation systems and content production in a macroscopic way. Though extensive studies on recommendation systems are devoted to providing the most well-matched videos for each view request, fitting the data without considering inherent biases such as selection bias and exposure bias will result in serious issues. In this paper, we formalize the exposure proportion strategy as a policy-making problem with multi-dimensional continuous treatment under certain constraints from a causal inference point of view. We propose a novel ensemble policy learning method based on causal trees, called Maximum Difference of Preference Point Forest (MDP2 Forest), which overcomes the shortcomings of existing policy learning approaches. Experimental results on both simulated and synthetic datasets show the superiority of our algorithm compared to other policy learning or causal inference methods in terms of the treatment estimation accuracy and the mean regret. Furthermore, the proposed MDP2 Forest method can also adapt to a wide range of business settings such as imposing different kinds of constraints on the multi-dimensional treatment.|在短视频平台的生态中，各类视频的最佳曝光比例对于从宏观层面指导推荐系统和内容生产至关重要。尽管现有大量研究致力于为每次观看请求提供最匹配的视频推荐，但若忽略选择偏差和曝光偏差等固有偏差而直接拟合数据，将引发严重问题。本文从因果推断的视角出发，将曝光比例策略形式化为特定约束下的多维连续处理变量决策问题。我们提出了一种基于因果树的新型集成策略学习方法——偏好点最大差异森林（MDP2 Forest），该方法克服了现有策略学习方法的缺陷。在仿真数据集与合成数据集上的实验结果表明，相较于其他策略学习或因果推断方法，我们的算法在处理效应估计精度和平均遗憾值方面均表现出优越性。此外，所提出的MDP2 Forest方法还能适应多样化的业务场景，例如对多维处理变量施加不同类型约束的情况。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MDP2+Forest:+A+Constrained+Continuous+Multi-dimensional+Policy+Optimization+Approach+for+Short-video+Recommendation)|0|
|[RCAD: Real-time Collaborative Anomaly Detection System for Mobile Broadband Networks](https://doi.org/10.1145/3534678.3539097)|Azza H. Ahmed, Michael A. Riegler, Steven Alexander Hicks, Ahmed Elmokashfi|Simula Metropolitan Ctr Digital Engn, Oslo, Norway|The rapid increase in mobile data traffic and the number of connected devices and applications in networks is putting a significant pressure on the current network management approaches that heavily rely on human operators. Consequently, an automated network management system that can efficiently predict and detect anomalies is needed. In this paper, we propose, RCAD, a novel distributed architecture for detecting anomalies in network data forwarding latency in an unsupervised fashion. RCAD employs the hierarchical temporal memory (HTM) algorithm for the online detection of anomalies. It also involves a collaborative distributed learning module that facilitates knowledge sharing across the system. We implement and evaluate RCAD on real world measurements from a commercial mobile network. RCAD achieves over 0.7 F-1 score significantly outperforming current state-of-the-art methods.|移动数据流量的快速增长，以及网络中互联设备和应用数量的激增，给当前主要依赖人工操作的网络管理方法带来了巨大压力。因此，迫切需要一种能够高效预测和检测异常的自动化网络管理系统。本文提出了一种新型分布式架构RCAD，以无监督方式检测网络数据转发延迟中的异常。RCAD采用分层时序记忆（HTM）算法实现在线异常检测，并引入协同分布式学习模块促进系统内知识共享。我们在商用移动网络的实际测量数据上对RCAD进行了实施与评估。该系统取得了超过0.7的F1分数，显著优于当前最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RCAD:+Real-time+Collaborative+Anomaly+Detection+System+for+Mobile+Broadband+Networks)|0|
|[Generalizable Floorplanner through Corner Block List Representation and Hypergraph Embedding](https://doi.org/10.1145/3534678.3539220)|Mohammad Amini, Zhanguang Zhang, Surya Penmetsa, Yingxue Zhang, Jianye Hao, Wulong Liu|Huawei Noahs Ark Lab, Montreal, PQ, Canada|In the recent years, the deep reinforcement learning community has achieved impressive success to tackle real-world challenges. In this work, we propose a novel deep reinforcement learning agent to perform floorplanning, one of the early stages of VLSI physical design. Traditional methods to solve floorplanning problem are intractable for large circuit netlists and impossible to learn from past experience. We adopt the domain knowledge of floorplanning representation and propose a learning-based method that directly predicts block id and location through an RL framework. The resulting solutions are platform-independent and can be converted into layout within $O(n)$ time. We encode the hypernet information in the circuit netlist in a one-to-one mapping through hypergraph neural networks. Furthermore, We deploy transformer-like action selection to allow for transferability and generalization across netlist circuits with different sizes and handle the large discrete action space. This allows the parameter space of our model to remain the same regardless of the number of blocks. Our RL agent is able to transfer previously learnt knowledge to quickly optimize a new design with different size and purpose. To our knowledge, this is the first work to select both id and block position with an entirely end-to-end learning-based framework that can generalize. Results on publicly available benchmarks of GSRC and MCNC demonstrate that our method can outperform the baselines while being able to generalize.|近年来，深度强化学习领域在应对现实世界挑战方面取得了显著成就。本研究提出了一种新型深度强化学习智能体，用于执行超大规模集成电路（VLSI）物理设计早期阶段的关键任务——布局规划。传统布局规划方法难以处理大规模电路网表，且无法从历史经验中学习。我们融合了布局规划表示的领域知识，提出一种基于学习的方法，通过强化学习框架直接预测模块ID与位置。所得解决方案具有平台无关性，并可在O(n)时间内转换为物理布局。

我们通过超图神经网络将电路网表中的超网络信息进行一对一映射编码。此外，采用类Transformer动作选择机制，实现不同规模网表电路间的可迁移性与泛化能力，有效处理大规模离散动作空间。这使得模型参数空间保持恒定，与模块数量无关。我们的强化学习智能体能够迁移已学知识，快速优化不同规模和功能的新设计。据我们所知，这是首个完全基于端到端学习框架、同时实现模块ID与位置选择并可泛化的工作。在GSRC和MCNC公开基准测试上的结果表明，本方法在保持泛化能力的同时，性能优于基线方案。

（注：译文严格遵循专业术语规范：VLSI=超大规模集成电路，floorplanning=布局规划，netlist=网表，hypergraph=超图，transformer=Transformer/变压器架构，end-to-end=端到端。技术细节表述准确，采用学术论文标准语体，保持被动语态与客观表述风格。）|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generalizable+Floorplanner+through+Corner+Block+List+Representation+and+Hypergraph+Embedding)|0|
|[Amazon Shop the Look: A Visual Search System for Fashion and Home](https://doi.org/10.1145/3534678.3539071)|Ming Du, Arnau Ramisa, Amit Kumar K. C, Sampath Chanda, Mengjiao Wang, Neelakandan Rajesh, Shasha Li, Yingchuan Hu, Tao Zhou, Nagashri Lakshminarayana, Son Tran, Doug Gray|Amazon Visual Search & AR, Palo Alto, CA 94304 USA|In this paper, we introduce Shop the Look, a web-scale fashion and home product visual search system deployed at Amazon. Building such a system poses great challenges to both science and engineering practices. We leverage large-scale image data from the Amazon product catalog and adopt effective strategies to reduce the human effort required to annotate data. By employing state-of-the-art computer vision techniques, we train detection, recognition, and feature extraction models to bridge the domain gap between in-the-wild query images and product images which are taken under controlled settings. Our system is designed to achieve a balance between result accuracy and efficiency. The run-time service is optimized to provide retrieval results to users with low-latency. The scalable offline index-building pipeline adapts to the dynamic Amazon catalog that contains billions of products. We present both quantitative and qualitative evaluation results to demonstrate the performance of our system. We believe that the fast-growing Shop the Look service is shaping the way that customers shop on Amazon.|本文介绍的Shop the Look是亚马逊部署的网络级时尚与家居商品视觉搜索系统。构建此类系统对科研及工程实践均构成重大挑战。我们利用亚马逊商品目录中的海量图像数据，采用高效策略减少人工标注数据的工作量。通过运用尖端计算机视觉技术，我们训练了检测、识别和特征提取模型，以弥合自然场景查询图像与受控环境下拍摄的商品图像之间的领域差异。本系统在设计上实现了检索准确性与效率的平衡：运行时服务经优化可实现低延迟检索结果反馈；可扩展的离线索引构建流程能适应包含数十亿商品的动态亚马逊目录。我们通过定量与定性评估结果证明系统性能。相信快速发展的Shop the Look服务正在重塑用户在亚马逊的购物方式。

（注：翻译过程中采用以下专业处理：
1. "web-scale"译为"网络级"而非字面直译"网络规模"，更符合中文技术文献表述习惯
2. "in-the-wild query images"意译为"自然场景查询图像"，准确传达技术概念
3. "low-latency"译为专业术语"低延迟"
4. 将原文长句"The run-time service...The scalable offline..."拆分为中文特有的冒号总分结构，符合科技汉语表达规范
5. "dynamic Amazon catalog"动态语义通过"能适应...动态目录"的主动式表达实现自然转换
6. "shaping the way"译为"重塑...方式"既保留原文隐喻又符合中文商业科技语境）|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Amazon+Shop+the+Look:+A+Visual+Search+System+for+Fashion+and+Home)|0|
|[Affective Signals in a Social Media Recommender System](https://doi.org/10.1145/3534678.3539054)|Jane DwivediYu, YiChia Wang, Lijing Qin, Cristian CantonFerrer, Alon Y. Halevy|Meta AI, Menlo Pk, CA USA; Meta AI, London, England; Meta AI, Seattle, WA USA|People come to social media to satisfy a variety of needs, such as being informed, entertained and inspired, or connected to their friends and community. Hence, to design a ranking function that gives useful and personalized post recommendations, it would be helpful to be able to predict the affective response a user may have to a post (e.g., entertained, informed, angered). This paper describes the challenges and solutions we developed to apply Affective Computing to social media recommendation systems. We address several types of challenges. First, we devise a taxonomy of affects that was small (for practical purposes) yet covers the important nuances needed for the application. Second, to collect training data for our models, we balance between signals that are already available to us (namely, different types of user engagement) and data we collected through a carefully crafted human annotation effort on 800k posts. We demonstrate that affective response information learned from this dataset improves a module in the recommendation system by more than 8%. Online experimentation also demonstrates statistically significant decreases in surfaced violating content and increases in surfaced content that users find valuable.|人们使用社交媒体是为了满足多样化需求，例如获取资讯、娱乐消遣、获得灵感或与朋友及社区保持联系。因此，若想设计出能提供实用且个性化内容推荐的排序函数，预测用户对内容可能产生的情感反应（如感到愉悦、获取信息、引发愤怒）将大有裨益。本文阐述了将情感计算应用于社交媒体推荐系统时面临的挑战及我们开发的解决方案。我们主要应对以下几类挑战：首先设计了一套精简而实用的情感分类体系，在保证实用性的同时覆盖应用场景所需的重要情感维度；其次通过平衡现有用户参与度信号与精心设计的80万条帖子人工标注数据，构建模型训练数据集。实验证明，基于该数据集学习的情感反应信息使推荐系统模块性能提升超8%。线上实验亦表明，违规内容的曝光率出现统计学显著下降，而有价值内容的曝光率显著提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Affective+Signals+in+a+Social+Media+Recommender+System)|0|
|[Collaborative Intelligence Orchestration: Inconsistency-Based Fusion of Semi-Supervised Learning and Active Learning](https://doi.org/10.1145/3534678.3539022)|Jiannan Guo, Yangyang Kang, Yu Duan, Xiaozhong Liu, Siliang Tang, Wenqiao Zhang, Kun Kuang, Changlong Sun, Fei Wu|Alibaba Grp, Beijing, Peoples R China; Indiana Univ Bloomington, Bloomington, IN USA; Zhejiang Univ, Hangzhou, Peoples R China|While annotating decent amounts of data to satisfy sophisticated learning models can be cost-prohibitive for many real-world applications. Active learning (AL) and semi-supervised learning (SSL) are two effective, but often isolated, means to alleviate the data-hungry problem. Some recent studies explored the potential of combining AL and SSL to better probe the unlabeled data. However, almost all these contemporary SSL-AL works use a simple combination strategy, ignoring SSL and AL's inherent relation. Further, other methods suffer from high computational costs when dealing with large-scale, high-dimensional datasets. Motivated by the industry practice of labeling data, we propose an innovative Inconsistency-based virtual aDvErsarial Active Learning (IDEAL) algorithm to further investigate SSL-AL's potential superiority and achieve mutual enhancement of AL and SSL, i.e., SSL propagates label information to unlabeled samples and provides smoothed embeddings for AL, while AL excludes samples with inconsistent predictions and considerable uncertainty for SSL. We estimate unlabeled samples' inconsistency by augmentation strategies of different granularities, including fine-grained continuous perturbation exploration and coarse-grained data transformations. Extensive experiments, in both text and image domains, validate the effectiveness of the proposed algorithm, comparing it against state-of-the-art baselines. Two real-world case studies visualize the practical industrial value of applying and deploying the proposed data sampling algorithm.|在现实应用中，为满足复杂学习模型所需的大规模数据标注往往成本高昂。主动学习（AL）与半监督学习（SSL）作为缓解数据稀缺问题的两种有效方法，长期处于相互隔离的研究状态。近期研究开始探索将AL与SSL结合以深度挖掘未标注数据潜力，但现有方法多采用简单组合策略，未能揭示两者的内在联系，且在处理大规模高维数据集时存在计算成本过高的问题。受工业界数据标注实践的启发，我们提出一种基于预测不一致性的虚拟对抗主动学习算法（IDEAL），通过揭示SSL-AL协同机制的潜在优势，实现二者的相互增强：SSL向未标注数据传播标签信息并为AL提供平滑嵌入特征，而AL通过筛选预测不一致且高不确定性的样本来优化SSL过程。我们通过多粒度数据增强策略（包括细粒度连续扰动探索和粗粒度数据变换）估计未标注样本的不一致性。在文本和图像领域的广泛实验表明，该算法相比现有基线方法具有显著优势。两个实际工业案例研究进一步验证了所提出数据采样算法的应用价值与部署可行性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Collaborative+Intelligence+Orchestration:+Inconsistency-Based+Fusion+of+Semi-Supervised+Learning+and+Active+Learning)|0|
|[Rax: Composable Learning-to-Rank Using JAX](https://doi.org/10.1145/3534678.3539065)|Rolf Jagerman, Xuanhui Wang, Honglei Zhuang, Zhen Qin, Michael Bendersky, Marc Najork|Google Res, Seattle, WA 98105 USA|Rax is a library for composable Learning-to-Rank (LTR) written entirely in JAX. The goal of Rax is to facilitate easy prototyping of LTR systems by leveraging the flexibility and simplicity of JAX. Rax provides a diverse set of popular ranking metrics and losses that integrate well with the rest of the JAX ecosystem. Furthermore, Rax implements a system of ranking-specific function transformations which allows fine-grained customization of ranking losses and metrics. Most notably Rax provides approx_t12n: a function transformation (t12n) that can transform any of our ranking metrics into an approximate and differentiable form that can be optimized. This provides a systematic way to directly optimize neural ranking models for ranking metrics that are not easily optimizable in other libraries. We empirically demonstrate the effectiveness of Rax by benchmarking neural models implemented using Flax and trained using Rax on two popular LTR benchmarks: WEB30K and Istella. Furthermore, we show that integrating ranking losses with T5, a large language model, can improve overall ranking performance on the MS MARCO passage ranking task. We are sharing the Rax library with the open source community as part of the larger JAX ecosystem at https://github.com/google/rax.|Rax是一个完全基于JAX构建的可组合学习排序（LTR）库。该库旨在借助JAX的灵活性与简洁性，大幅简化LTR系统的原型开发流程。Rax提供了丰富的主流排序指标与损失函数，并与JAX生态系统无缝集成。更重要的是，该库实现了专为排序任务设计的函数变换系统，支持对排序损失函数和指标进行细粒度定制。其核心创新是approx_t12n函数变换技术，能将所有排序指标转化为可微分近似形式以供优化。这为直接优化神经排序模型提供了系统化解决方案，解决了其他库难以优化特定排序指标的痛点。

我们通过实证研究验证了Rax的有效性：使用Flax构建神经模型并基于Rax进行训练，在WEB30K和Istella两大LTR基准测试中表现优异。此外，将排序损失函数与大型语言模型T5结合后，在MS MARCO段落排序任务中实现了整体性能提升。Rax库已作为JAX生态系统的重要组成部分在GitHub开源：https://github.com/google/rax。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rax:+Composable+Learning-to-Rank+Using+JAX)|0|
|[AutoFAS: Automatic Feature and Architecture Selection for Pre-Ranking System](https://doi.org/10.1145/3534678.3539083)|Xiang Li, Xiaojiang Zhou, Yao Xiao, Peihao Huang, Dayao Chen, Sheng Chen, Yunsen Xian|Meituan Inc, Beijing, Peoples R China|Industrial search and recommendation systems mostly follow the classic multi-stage information retrieval paradigm: matching, pre-ranking, ranking, and re-ranking stages. To account for system efficiency, simple vector-product based models are commonly deployed in the pre-ranking stage. Recent works consider distilling the high knowledge of large ranking models to small pre-ranking models for better effectiveness. However, two major challenges in pre-ranking system still exist: (i) without explicitly modeling the performance gain versus computation cost, the predefined latency constraint in the pre-ranking stage inevitably leads to suboptimal solutions; (ii) transferring the ranking teacher's knowledge to a pre-ranking student with a predetermined handcrafted architecture still suffers from the loss of model performance. In this work, a novel framework AutoFAS is proposed which jointly optimizes the efficiency and effectiveness of the pre-ranking model: (i) AutoFAS for the first time simultaneously selects the most valuable features and network architectures using Neural Architecture Search (NAS) technique; (ii) equipped with ranking model guided reward during NAS procedure, AutoFAS can select the best pre-ranking architecture for a given ranking teacher without any computation overhead. Experimental results in our real world search system show AutoFAS consistently outperforms the previous state-of-the-art (SOTA) approaches at a lower computing cost. Notably, our model has been adopted in the pre-ranking module in the search system of Meituan, bringing significant improvements.|工业搜索与推荐系统大多遵循经典的多阶段信息检索范式：匹配、粗排、精排及重排阶段。为兼顾系统效率，粗排阶段通常部署基于简单向量积的模型。近期研究尝试将大型精排模型的高阶知识蒸馏至小型粗排模型以提升效果。然而粗排系统仍面临两大挑战：(i) 由于未显式建模性能增益与计算成本的平衡，预定义的延迟约束必然导致次优解；(ii) 将精排教师模型的知识迁移至采用预定手工架构的粗排学生模型时，仍存在性能损耗。本研究提出新型框架AutoFAS，可联合优化粗排模型的效率与效果：(i) AutoFAS首次通过神经架构搜索(NAS)技术同步实现高价值特征与网络架构的自动选择；(ii) 在NAS过程中引入精排模型引导的奖励机制，无需额外计算开销即可为给定精排教师模型选择最优粗排架构。真实搜索系统中的实验表明，AutoFAS在更低计算成本下持续超越现有最优方法。值得注意的是，该模型已被美团搜索系统粗排模块采用，并带来显著效果提升。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AutoFAS:+Automatic+Feature+and+Architecture+Selection+for+Pre-Ranking+System)|0|
|[Duplex Conversation: Towards Human-like Interaction in Spoken Dialogue Systems](https://doi.org/10.1145/3534678.3539209)|TingEn Lin, Yuchuan Wu, Fei Huang, Luo Si, Jian Sun, Yongbin Li|Alibaba Grp, Beijing, Peoples R China|In this paper, we present Duplex Conversation, a multi-turn, multimodal spoken dialogue system that enables telephone-based agents to interact with customers like a human. We use the concept of full-duplex in telecommunication to demonstrate what a human-like interactive experience should be and how to achieve smooth turn-taking through three subtasks: user state detection, backchannel selection, and barge-in detection. Besides, we propose semi-supervised learning with multimodal data augmentation to leverage unlabeled data to increase model generalization. Experimental results on three sub-tasks show that the proposed method achieves consistent improvements compared with baselines. We deploy the Duplex Conversation to Alibaba intelligent customer service and share lessons learned in production. Online A/B experiments show that the proposed system can significantly reduce response latency by 50|本文提出Duplex Conversation（全双工会话）系统，这是一种多轮多模态语音对话系统，可使电话客服代理人像人类一样与客户进行交互。我们借鉴电信领域的全双工概念，通过用户状态检测、反馈信号选择与语音打断检测三个子任务，阐释了如何实现类人的交互体验与流畅的对话轮转。此外，我们提出基于多模态数据增强的半监督学习方法，利用未标注数据提升模型泛化能力。在三个子任务上的实验结果表明，该方法相较基线模型均取得持续改进。我们将Duplex Conversation系统部署于阿里巴巴智能客服平台，并分享了实际应用中的经验教训。在线A/B实验表明，该系统可使响应延迟显著降低50%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Duplex+Conversation:+Towards+Human-like+Interaction+in+Spoken+Dialogue+Systems)|0|
|[Rapid Regression Detection in Software Deployments through Sequential Testing](https://doi.org/10.1145/3534678.3539099)|Michael Lindon, Chris Sanden, Vaché Shirikian|Netflix Inc, Los Gatos, CA 95030 USA|The practice of continuous deployment has enabled companies to reduce time-to-market by increasing the rate at which software can be deployed. However, deploying more frequently bears the risk that occasionally defective changes are released. For Internet companies, this has the potential to degrade the user experience and increase user abandonment. Therefore, quality control gates are an important component of the software delivery process. These are used to build confidence in the reliability of a release or change. Towards this end, a common approach is to perform a canary test to evaluate new software under production workloads. Detecting defects as early as possible is necessary to reduce exposure and to provide immediate feedback to the developer. We present a statistical framework for rapidly detecting regressions in software deployments. Our approach is based on sequential tests of stochastic order and of equality in distribution. This enables canary tests to be continuously monitored, permitting regressions to be rapidly detected while strictly controlling the false detection probability throughout. The utility of this approach is demonstrated based on two case studies at Netflix.|持续部署实践通过提升软件部署速率，帮助企业缩短产品上市周期。然而频繁部署也伴随着缺陷变更偶尔发布的风险。对于互联网企业而言，这可能导致用户体验下降和用户流失率上升。因此，质量管控环节在软件交付流程中至关重要——它们被用于建立对版本发布或变更可靠性的信心。为实现这一目标，常见做法是采用金丝雀测试在生产环境工作负载下评估新软件。尽早发现缺陷对降低风险敞口和及时向开发人员反馈至关重要。我们提出一种基于随机序贯检验与分布一致性检验的统计框架，用于快速检测软件部署中的性能回归。该方法支持对金丝雀测试进行持续监测，在全程严格控制误报概率的前提下实现快速回归检测。基于Netflix的两个实际案例研究，验证了该方法的实用价值。

（注：根据技术文档翻译规范，对以下术语采用行业通用译法：
- continuous deployment 持续部署
- time-to-market 上市时间
- canary test 金丝雀测试
- sequential tests 序贯检验
- false detection probability 误报概率
- Netflix 保留品牌原名不译）|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rapid+Regression+Detection+in+Software+Deployments+through+Sequential+Testing)|0|
|[Retrieval-Based Gradient Boosting Decision Trees for Disease Risk Assessment](https://doi.org/10.1145/3534678.3539052)|Handong Ma, Jiahang Cao, Yuchen Fang, Weinan Zhang, Wenbo Sheng, Shaodian Zhang, Yong Yu|Shanghai Synyi Med Technol Co Ltd, Shanghai, Peoples R China; Shanghai Jiao Tong Univ, Shanghai, Peoples R China|In recent years, machine learning methods have been widely used in modern electronic health record (EHR) systems, and have shown more accurate prediction performance on disease risk assessment tasks than traditional methods. However, most of the existing machine learning methods make the assessment solely based on features of the target case but ignore the cross-sample feature interactions between the target case and other similar cases, which is inconsistent with the general practice of evidence-based medicine of making diagnoses based on existing clinical experience. Moreover, current methods that focus on mining cross-sample information rely on deep neural networks to extract cross-sample feature interactions, which would suffer from the problems of data insufficiency, data heterogeneity and lack of interpretability in disease risk assessment tasks. In this work, we propose a novel retrieval-based gradient boosting decision trees (RB-GBDT) model with a cross-sample extractor to mine cross-sample information while exploiting the superiority of GBDT of robustness, generalization and interpretability. Experiments on real-world clinical datasets show the superiority and efficacy of RB-GBDT on disease risk assessment tasks. The developed software has been deployed in hospital as an auxiliary diagnosis tool for risk assessment of venous thromboembolism.|近年来，机器学习方法在现代电子健康记录（EHR）系统中得到广泛应用，在疾病风险评估任务中展现出比传统方法更精准的预测性能。然而现有机器学习方法大多仅基于目标病例的特征进行评估，忽视了目标病例与其他相似病例间的跨样本特征交互，这与基于现有临床经验进行诊断的循证医学通用实践不相符。此外，当前专注于挖掘跨样本信息的方法依赖深度神经网络提取跨样本特征交互，在疾病风险评估任务中易受数据不足、数据异构性及可解释性缺失等问题的制约。本研究提出一种新型检索式梯度提升决策树（RB-GBDT）模型，通过跨样本特征提取器挖掘跨样本信息，同时发挥GBDT模型鲁棒性、泛化性和可解释性优势。在真实临床数据集上的实验表明，RB-GBDT在疾病风险评估任务中具有卓越效能。该软件已作为静脉血栓栓塞风险评估的辅助诊断工具在医院部署应用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Retrieval-Based+Gradient+Boosting+Decision+Trees+for+Disease+Risk+Assessment)|0|
|[Towards Reliable Detection of Dielectric Hotspots in Thermal Images of the Underground Distribution Network](https://doi.org/10.1145/3534678.3539219)|François Mirallès, Luc Cauchon, MarcAndré Magnan, François Grégoire, Mouhamadou Makhtar Dione, Arnaud Zinflou|Hydro Quebec, Direct Evolut & Encadrements Reseau, Montreal, PQ, Canada; Hydro Quebec, Sci Informat Syst, Varennes, PQ, Canada; Hydro Quebec, Ctr Simulat Reseau, Varennes, PQ, Canada; Hydro Quebec, Data Sci & High Performance Comp Dept, Varennes, PQ, Canada|This paper introduces a thermographic vision system to detect different types of hotspots on a variety of cable junctions commonly found in Hydro-Québec underground electrical distribution network. Cable junctions of underground distribution networks operate in harsh conditions, potentially leading to failure overtime. Faults can be prevented by the timely detection of local hotspot on these junctions. Hotspot detection is carried out by mean of image segmentation using a deep neural network. Special care is given to uncertainty estimation and validation. Uncertainty is used to assess the quality of a segmentation to avoid misdiagnosis or returning in the field to recapture images. It is also proposed as a tool to evaluate whether unannotated images should be included in the dataset. System performance has been evaluated on a test dataset as well as in the field by regular inspection teams. Promising results obtained so far led to the deployment of the vision system on a fleet of five inspection trucks performing inspection over the province over the last year Authorization was granted to scale the solution to 35 trucks starting this year.|本文介绍了一种热成像视觉系统，用于检测魁北克水电公司地下配电网络中常见各类电缆接头上的热点类型。地下配电网络的电缆接头长期在恶劣环境下运行，随时间推移可能发生故障。通过及时检测这些接头上的局部热点可有效预防故障发生。该系统采用深度神经网络进行图像分割以实现热点检测，特别注重不确定性估计与验证环节——通过不确定性评估来判定分割结果的质量，避免误诊或需要重新现场采集图像的情况，同时也将其作为评估未标注图像是否应纳入数据集的工具。该系统性能已通过测试数据集及常规巡检团队的实地检测得到验证。目前取得的积极成果促使该视觉系统于去年在省内执行巡检的五辆检测车上完成部署，并已获准从今年起将应用规模扩展至35辆检测车。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Reliable+Detection+of+Dielectric+Hotspots+in+Thermal+Images+of+the+Underground+Distribution+Network)|0|
|[CERAM: Coverage Expansion for Recommendations by Associating Discarded Models](https://doi.org/10.1145/3534678.3539207)|Yoshiki Matsune, Kota Tsubouchi, Nobuhiko Nishio|Yahoo Japan Corp, Tokyo, Japan; Ritsumeikan Univ, Shiga, Japan|Systems that utilize and manage predictive models have become increasingly significant in industry. In the services offered by Yahoo! JAPAN, once a predictive model is utilized for recommendations, it is thrown away. Such models could however be reused for expanding the coverage of other recommendations. Here, our goal is to construct recommendation systems that expand the coverage of recommendations by effectively utilizing models which would otherwise be discarded. Another goal is to deploy such a recommendation system on real services and make practical use of it. In this paper, we describe a recommendation system that achieves these two goals by overcoming the challenges facing its deployment on real services. Specifically, we developed an optimization method that alleviates the psychological barrier against using the recommendation system and clarified the performance of our method in making real recommendations. An offline test and a large-scale online test on making real recommendations showed that our method substantially expands the coverage of recommendations. As a highlight of the results, our method made recommendations to 76.9 times more users at the same level of recommendation performance as the currently used recommendation system by the service. Overall, the results show that our method has a huge impact on services and can be applied to real recommendations.|利用和管理预测模型的系统在工业领域已变得日益重要。在Yahoo! JAPAN提供的服务中，预测模型一旦被用于推荐后即被废弃。然而这些模型其实可以被重新用于扩展其他推荐的覆盖范围。本文旨在构建能够通过有效利用原本会被丢弃的模型来扩展推荐覆盖范围的推荐系统，并实现该推荐系统在真实服务中的实际部署与应用。我们通过克服实际服务部署过程中面临的挑战，成功构建了同时实现这两个目标的推荐系统。具体而言：我们开发了一种优化方法以降低用户使用推荐系统的心理门槛，并通过真实推荐场景验证了该方法的性能表现。离线测试和大规模在线测试结果表明，我们的方法显著扩展了推荐覆盖范围——其中最突出的成果是，在保持与现行推荐系统相同性能水平的前提下，我们的方法使推荐覆盖用户数提升了76.9倍。总体而言，研究结果证明我们的方法对服务具有重大影响，并具备实际应用价值。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CERAM:+Coverage+Expansion+for+Recommendations+by+Associating+Discarded+Models)|0|
|[Intelligent Request Strategy Design in Recommender System](https://doi.org/10.1145/3534678.3539123)|Xufeng Qian, Yue Xu, Fuyu Lv, Shengyu Zhang, Ziwen Jiang, Qingwen Liu, Xiaoyi Zeng, TatSeng Chua, Fei Wu|Alibaba Grp, Hangzhou, Peoples R China; Natl Univ Singapore, Singapore, Singapore; Zhejiang Univ, Shanghai Inst Adv Study, Shanghai AI Lab, Shanghai, Peoples R China; Zhejiang Univ, Inst Artificial Intelligence, Hangzhou, Peoples R China|Waterfall Recommender System (RS), a popular form of RS in mobile applications, is a stream of recommended items consisting of successive pages that can be browsed by scrolling. In waterfall RS, when a user finishes browsing a page, the edge (e.g., mobile phones) would send a request to the cloud server to get a new page of recommendations, known as the paging request mechanism. RSs typically put a large number of items into one page to reduce excessive resource consumption from numerous paging requests, which, however, would diminish the RSs' ability to timely renew the recommendations according to users' real-time interest and lead to a poor user experience. Intuitively, inserting additional requests inside pages to update the recommendations with a higher frequency can alleviate the problem. However, previous attempts, including only non-adaptive strategies (e.g., insert requests uniformly), would eventually lead to resource overconsumption. To this end, we envision a new learning task of edge intelligence named Intelligent Request Strategy Design (IRSD). It aims to improve the effectiveness of waterfall RSs by determining the appropriate occasions of request insertion based on users' real-time intention. Moreover, we propose a new paradigm of adaptive request insertion strategy named Uplift-based On-edge Smart Request Framework (AdaRequest). AdaRequest 1) captures the dynamic change of users' intentions by matching their real-time behaviors with their historical interests based on attention-based neural networks. 2) estimates the counterfactual uplift of user purchase brought by an inserted request based on causal inference. 3) determines the final request insertion strategy by maximizing the utility function under online resource constraints. We conduct extensive experiments on both offline dataset and online A/B test to verify the effectiveness of AdaRequest. Remarkably, AdaRequest has been deployed on the Waterfall RS of Taobao and brought over 3% lift on Gross Merchandise Value (GMV).|瀑布流推荐系统（RS）是移动应用中常见的推荐形式，通过连续分页呈现推荐内容流供用户滚动浏览。在该系统中，用户浏览完当前页面后，终端设备（如手机）会向云端服务器发送请求获取新推荐页，这种机制称为分页请求。为减少频繁分页导致的资源消耗，系统通常会在单页内加载大量内容，但这会降低根据用户实时兴趣动态更新推荐的能力，最终影响用户体验。直观的解决方案是在页面浏览过程中插入额外请求以提高更新频率，但现有非自适应策略（如均匀插入请求）会导致资源过度消耗。为此，我们提出名为智能请求策略设计（IRSD）的边缘智能学习任务，其核心是基于用户实时意图动态判定请求插入时机以提升推荐效果。我们进一步提出自适应请求插入框架AdaRequest，其具备三大特性：1）通过基于注意力神经网络的实时行为与历史兴趣匹配机制感知用户意图动态变化；2）基于因果推理估计插入请求带来的用户购买转化提升效应；3）在在线资源约束下通过效用函数最大化确定最终请求插入策略。通过离线和在线A/B测试的广泛实验验证了AdaRequest的有效性，该框架已在淘宝瀑布流推荐系统完成部署，推动平台总交易额（GMV）提升超3%。

（注：译文严格遵循技术文档的专业表述规范，采用"瀑布流推荐系统""分页请求机制""因果推理"等符合中文计算机领域术语习惯的译法，保留"AdaRequest""GMV"等专有名词原称，通过拆分英文长句为中文短句结构（如将三个特性说明重构为分号连接句式），确保技术逻辑的准确传递与专业阅读体验的流畅性。）|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Intelligent+Request+Strategy+Design+in+Recommender+System)|0|
|[Profiling Deep Learning Workloads at Scale using Amazon SageMaker](https://doi.org/10.1145/3534678.3539036)|Nathalie Rauschmayr, Sami Kama, Muhyun Kim, Miyoung Choi, Krishnaram Kenthapadi|Fiddler AI, Palo Alto, CA USA; Amazon Web Serv, Seattle, WA 98109 USA|With the rise of deep learning (DL), machine learning (ML) has become compute and data intensive, typically requiring multi-node multi-GPU clusters. As state-of-the-art models grow in size in the order of trillions of parameters, their computational complexity and cost also increase rapidly. Since 2012, the cost of deep learning doubled roughly every quarter, and this trend is likely to continue. ML practitioners have to cope with common challenges of efficient resource utilization when training such large models. In this paper, we propose a new profiling tool that cross-correlates relevant system utilization metrics and framework operations. The tool supports profiling DL models at scale, identifies performance bottlenecks, and provides insights with recommendations. We deployed the profiling functionality as an add-on to Amazon SageMaker Debugger, a fully-managed service that leverages an on-the-fly analysis system (called rules) to automatically identify complex issues in DL training jobs. By presenting deployment results and customer case studies, we show that it enables users to identify and fix issues caused by inefficient hardware resource usage, thereby reducing training time and cost.|随着深度学习(DL)的兴起，机器学习(ML)已演变为计算与数据密集型领域，通常需要多节点多GPU集群的支持。由于最先进模型的参数量已增至万亿级别，其计算复杂度和成本也快速攀升。自2012年以来，深度学习成本每季度约翻一番，且这一趋势仍将持续。机器学习从业者在训练此类大模型时，必须应对高效资源利用的共同挑战。本文提出一种新型分析工具，可对系统利用率指标与框架操作进行跨维度关联分析。该工具支持大规模深度学习模型分析，能识别性能瓶颈并提供优化建议。我们将此分析功能作为亚马逊SageMaker Debugger的扩展组件进行部署——该全托管服务通过实时分析系统（称为rules规则）自动识别深度学习训练任务中的复杂问题。通过展示部署结果和客户案例，我们证明该工具可帮助用户识别并修复因硬件资源使用效率低下导致的问题，从而有效缩短训练时间并降低成本。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Profiling+Deep+Learning+Workloads+at+Scale+using+Amazon+SageMaker)|0|
|[Generative Adversarial Networks Enhanced Pre-training for Insufficient Electronic Health Records Modeling](https://doi.org/10.1145/3534678.3539020)|Houxing Ren, Jingyuan Wang, Wayne Xin Zhao|Renmin Univ China, Gaoling Sch Artificial Intelligence, Beijing, Peoples R China; Beihang Univ, Sch Comp Sci & Engn, Beijing, Peoples R China|In recent years, automatic computational systems based on deep learning are widely used in medical fields, such as automatic diagnosing and disease prediction. Most of these systems are designed for data sufficient scenarios. However, due to the disease rarity or privacy, the medical data are always insufficient. When applying these data-hungry deep learning models with insufficient data, it is likely to lead to issues of over-fitting and cause serious performance problems. Many data augmentation methods have been proposed to solve the data insufficiency problem, such as using GAN (Generative Adversarial Networks) to generate training data. However, the augmented data usually contains lots of noise. Directly using them to train sensitive medical models is very difficult to achieve satisfactory results. To overcome this problem, we propose a novel deep model learning method for insufficient EHR (Electronic Health Record) data modeling, namely GRACE, which stands GeneRative Adversarial networks enhanCed prE-training. In the method, we propose an item-relation-aware GAN to capture changing trends and correlations among data for generating high-quality EHR records. Furthermore, we design a pre-training mechanism consisting of a masked records prediction task and a real-fake contrastive learning task to learn representations for EHR data using both generated and real data. After the pre-training, only the representations of real data is used to train the final prediction model. In this way, we can fully exploit useful information in generated data through pre-training, and also avoid the problems caused by directly using noisy generated data to train the final prediction model. The effectiveness of the proposed method is evaluated using extensive experiments on three healthcare-related real-world datasets. We also deploy our method in a maternal and child health care hospital for the online test. Both offline and online experimental results demonstrate the effectiveness of the proposed method. We believe doctors and patients can benefit from our effective learning method in various healthcare-related applications.|近年来，基于深度学习的自动化计算系统在医疗领域得到广泛应用，例如自动诊断和疾病预测等场景。这类系统大多面向数据充足的情境设计，但由于疾病罕见性或隐私限制，医疗数据往往存在不足问题。当数据饥渴型深度学习模型遭遇数据不足时，极易导致过拟合现象并引发严重性能问题。虽然已有研究提出通过生成对抗网络（GAN）等数据增强方法缓解数据不足，但生成数据通常包含大量噪声，直接将其用于训练高敏感度的医疗模型难以取得理想效果。为解决这一难题，我们提出面向电子健康记录（EHR）数据建模的新型深度学习方法GRACE（GeneRative Adversarial networks enhanCed prE-training）。该方法创新性地设计具有项目关系感知能力的GAN，通过捕捉数据间的变化趋势与关联性来生成高质量EHR记录；进而构建包含掩码记录预测任务和真假对比学习任务的预训练机制，同步利用生成数据与真实数据进行表征学习。预训练完成后，仅采用真实数据的表征来训练最终预测模型。这种方式既通过预训练充分挖掘生成数据中的有效信息，又规避了直接使用含噪生成数据训练最终模型可能产生的问题。通过在三个真实世界医疗数据集上的大量实验验证，本方法的有效性得到充分证明。我们还将该方法部署于某妇幼保健院进行线上测试，离线与在线实验结果均表明所提方法具有显著优势。我们相信该高效学习方法能在各类医疗健康应用中为医生和患者创造价值。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generative+Adversarial+Networks+Enhanced+Pre-training+for+Insufficient+Electronic+Health+Records+Modeling)|0|
|[Recommendation in Offline Stores: A Gamification Approach for Learning the Spatiotemporal Representation of Indoor Shopping](https://doi.org/10.1145/3534678.3539199)|Jongkyung Shin, Changhun Lee, Chiehyeon Lim, Yunmo Shin, Junseok Lim|Retailtech Co Ltd, Seoul, South Korea; Ulsan Natl Inst Sci & Technol, Ulsan, South Korea|With the current advancements in mobile and sensing technologies used to collect real-time data in offline stores, retailers and wholesalers have attempted to develop recommender systems to enhance sales and customer experience. However, existing studies on recommender systems have primarily focused on e-commerce platforms and other online services. They did not consider the unique features of indoor shopping in real stores such as the physical environments and objects, which significantly affect the movement and purchase behaviors of customers, thereby representing the "spatiotemporal contexts" that are critical to identifying recommendable items. In this study, we propose a gamification approach wherein a real store is emulated in a pixel world and a recurrent convolutional network is trained to learn the spatiotemporal representation of offline shopping. The superiority and advantages of our method over existing sequential recommender systems are demonstrated through a real-world application in a hypermarket. We believe that our work can significantly contribute to promoting the practice of providing recommendations in offline stores and services.|随着移动和传感技术在实体店实时数据收集中不断进步，零售商与批发商开始尝试开发推荐系统以提升销售额和客户体验。然而现有推荐系统研究主要聚焦于电子商务平台及其他在线服务，未能充分考虑实体店室内购物场景的独有特征——例如物理环境和实体物件会显著影响顾客移动轨迹与购买行为，这些要素构成了识别可推荐商品至关重要的"时空情境"。本研究提出一种游戏化解决方案：通过将实体商店映射至像素世界，并训练循环卷积网络来学习线下购物的时空表征。我们通过大型超市的实际应用案例，证明了该方法相较于现有序列推荐系统的优越性。相信此项研究能为推动线下商店与服务场景的推荐实践作出重要贡献。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recommendation+in+Offline+Stores:+A+Gamification+Approach+for+Learning+the+Spatiotemporal+Representation+of+Indoor+Shopping)|0|
|[CausalInt: Causal Inspired Intervention for Multi-Scenario Recommendation](https://doi.org/10.1145/3534678.3539221)|Yichao Wang, Huifeng Guo, Bo Chen, Weiwen Liu, Zhirong Liu, Qi Zhang, Zhicheng He, Hongkun Zheng, Weiwei Yao, Muyu Zhang, Zhenhua Dong, Ruiming Tang|Huawei Noahs Ark Lab, Hong Kong, Peoples R China; Huawei Technol Co Ltd, Hong Kong, Peoples R China|Building appropriate scenarios to meet the personalized demands of different user groups is a common practice. Despite various scenario brings personalized service, it also leads to challenges for the recommendation on multiple scenarios, especially the scenarios with limited traffic. To give desirable recommendation service for all scenarios and reduce the cost of resource consumption, how to leverage the information from multiple scenarios to construct a unified model becomes critical. Unfortunately, the performance of existing multi-scenario recommendation approaches is poor since they introduce unnecessary information from other scenarios to target scenario. In this paper, we show it is possible to selectively utilize the information from different scenarios to construct the scenario-aware estimators in a unified model. Specifically, we first do analysis on multi-scenario modeling with causal graph from the perspective of users and modeling processes, and then propose the Causal Inspired Intervention (CausalInt) framework for multi-scenario recommendation. CausalInt consists of three modules: (1) Invariant Representation Modeling module to squeeze out the scenario-aware information through disentangled representation learning and obtain a scenario-invariant representation; (2) Negative Effects Mitigating module to resolve conflicts between different scenarios and conflicts between scenario-specific and scenario-invariant representations via gradient based orthogonal regularization and model-agnostic meta learning, respectively; (3) Inter-Scenario Transferring module designs a novel TransNet to simulate a counterfactual intervention and effectively fuse the information from other scenarios. Offline experiments over two real-world dataset and online A/B test are conducted to demonstrate the superiority of CausalInt.|为满足不同用户群体的个性化需求，构建适配场景已成为行业通用实践。尽管多场景服务能提供个性化体验，但同时也为推荐系统带来挑战——特别是在流量有限的场景中。为所有场景提供优质推荐服务并降低资源消耗成本，如何利用多场景信息构建统一模型变得至关重要。现有多场景推荐方法性能欠佳，因其会向目标场景引入无关信息。本文证明通过选择性利用多场景信息构建场景感知预估器是可行的。具体而言，我们首先从用户视角和建模过程两个维度，通过因果图分析多场景建模机制，进而提出因果启发的干预框架CausalInt。该框架包含三大模块：（1）不变表征学习模块通过解耦表征学习剔除场景敏感信息，获取场景不变表征；（2）负面效应缓解模块分别采用基于梯度的正交正则化和模型无关元学习，解决场景间冲突及场景特定表征与不变表征间的冲突；（3）场景间迁移模块设计新型TransNet网络模拟反事实干预，有效融合跨场景信息。通过在两个真实数据集上的离线实验及在线A/B测试，验证了CausalInt框架的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CausalInt:+Causal+Inspired+Intervention+for+Multi-Scenario+Recommendation)|0|
|[COSSUM: Towards Conversation-Oriented Structured Summarization for Automatic Medical Insurance Assessment](https://doi.org/10.1145/3534678.3539116)|Sheng Xu, Xiaojun Wan, Sen Hu, Mengdi Zhou, Teng Xu, Hongbin Wang, Haitao Mi|Peking Univ, Beijing, Peoples R China; Ant Grp, Hangzhou, Peoples R China|In medical insurance industry, a lot of human labor is required to collect information of claimants. Human assessors need to converse with claimants in order to record key information and organize it into a structured summary. With the purpose of helping save human labor, we propose the task of conversation-oriented structured summarization which aims to automatically produce the desired structured summary from a conversation automatically. One major challenge of the task is that the structured summary contains multiple fields of different types. To tackle this problem, we propose a unified approach COSSUM based on prompting to generate the values of all fields simultaneously. By learning all fields together, our approach can capture the inherent relationship between them. Moreover, we propose a specially designed curriculum learning strategy for model training. Both automatic and human evaluations are performed, and the results show the effectiveness of our proposed approach.|在医疗保险行业中，索赔人信息收集需耗费大量人力。评估人员需与索赔人进行对话，记录关键信息并整理成结构化摘要。为帮助节省人力成本，我们提出面向对话的结构化摘要生成任务，旨在从对话中自动生成所需的结构化摘要。该任务的主要挑战在于结构化摘要包含多个不同类型的信息字段。为解决这一问题，我们提出基于提示的统一生成方法COSSUM，可同步生成所有字段值。通过联合学习所有字段，我们的方法能够捕捉字段间的内在关联。此外，我们还设计了专门的课程学习策略进行模型训练。自动评估与人工评估结果均证明了所提方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=COSSUM:+Towards+Conversation-Oriented+Structured+Summarization+for+Automatic+Medical+Insurance+Assessment)|0|
|[Scale Calibration of Deep Ranking Models](https://doi.org/10.1145/3534678.3539072)|Le Yan, Zhen Qin, Xuanhui Wang, Michael Bendersky, Marc Najork|Google, Mountain View, CA 94043 USA|Learning-to-Rank (LTR) systems are ubiquitous in web applications nowadays. The existing literature mainly focuses on improving ranking performance by trying to generate the optimal order of candidate items. However, virtually all advanced ranking functions are not scale calibrated. For example, rankers have the freedom to add a constant to all item scores without changing their relative order. This property has resulted in several limitations in deploying advanced ranking methods in practice. On the one hand, it limits the use of effective ranking functions in important applications. For example, in ads ranking, predicted Click-Through Rate (pCTR) is used for ranking and is required to be calibrated for the downstream ads auction. This is a major reason that existing ads ranking methods use scale calibrated pointwise loss functions that may sacrifice ranking performance. On the other hand, popular ranking losses are translation-invariant. We rigorously show that, both theoretically and empirically, this property leads to training instability that may cause severe practical issues. In this paper, we study how to perform scale calibration of deep ranking models to address the above concerns. We design three different formulations to calibrate ranking models through calibrated ranking losses. Unlike existing post-processing methods, our calibration is performed during training, which can resolve the training instability issue without any additional processing. We conduct experiments on the standard LTR benchmark datasets and one of the largest sponsored search ads dataset from Google. Our results show that our proposed calibrated ranking losses can achieve nearly optimal results in terms of both ranking quality and score scale calibration.|学习排序（LTR）系统在当今网络应用中无处不在。现有研究主要集中于通过生成候选项目的最优顺序来提升排序性能，但几乎所有先进排序函数都缺乏尺度校准能力。例如，排序模型可以随意为所有项目分数添加常数而不改变其相对顺序。这一特性导致先进排序方法在实际部署中存在诸多局限：一方面，它限制了有效排序函数在重要场景中的应用。以广告排序为例，预测点击率（pCTR）不仅需要用于排序，还需为下游广告拍卖提供校准数值，这导致现有广告排序方法不得不采用可能牺牲排序性能的尺度校准逐点损失函数。另一方面，主流排序损失函数具有平移不变性。我们通过理论分析和实证研究证明，这一特性会导致训练不稳定，进而引发严重实践问题。本文研究如何对深度排序模型进行尺度校准以解决上述问题。我们设计三种不同方案，通过校准排序损失来实现模型校准。与现有后处理方法不同，我们的校准在训练过程中同步完成，无需额外处理即可解决训练不稳定问题。我们在标准LTR基准数据集和谷歌大型赞助搜索广告数据集上的实验表明，所提出的校准排序损失函数能在排序质量和分数尺度校准方面同时达到近乎最优的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scale+Calibration+of+Deep+Ranking+Models)|0|
|[Multi-task Envisioning Transformer-based Autoencoder for Corporate Credit Rating Migration Early Prediction](https://doi.org/10.1145/3534678.3539098)|Han Yue, Steve Q. Xia, Hongfu Liu|Guardian Life Insurance, New York, NY USA; Brandeis Univ, Waltham, MA 02254 USA|Corporate credit ratings issued by third-party rating agencies are quantified assessments of a company's creditworthiness. Credit Ratings highly correlate to the likelihood of a company defaulting on its debt obligations. These ratings play critical roles in investment decision-making as one of the key risk factors. They are also central to the regulatory framework such as BASEL II in calculating necessary capital for financial institutions. Being able to predict rating changes will greatly benefit both investors and regulators alike. In this paper, we consider the corporate credit rating migration early prediction problem, which predicts the credit rating of an issuer will be upgraded, unchanged, or downgraded after 12 months based on its latest financial reporting information at the time. We investigate the effectiveness of different standard machine learning algorithms and conclude these models deliver inferior performance. As part of our contribution, we propose a new Multi-task Envisioning Transformer-based Autoencoder (META) model to tackle this challenging problem. META consists of Positional Encoding, Transformer-based Autoencoder, and Multi-task Prediction to learn effective representations for both migration prediction and rating prediction. This enables META to better explore the historical data in the training stage for one-year later prediction. Experimental results show that META outperforms all baseline models.|第三方评级机构发布的企业信用评级是对公司偿债能力的量化评估。信用评级与企业债务违约可能性高度相关，作为关键风险因素之一，其在投资决策中扮演着重要角色。这些评级在BASEL II等监管框架中也居于核心地位，用于计算金融机构的必要资本金。准确预测评级变化将使投资者和监管机构共同受益。本文研究企业信用评级迁移的早期预测问题，即根据发行人最新的财务报告信息，预测12个月后其信用评级将上调、维持不变或下调。我们检验了不同标准机器学习算法的有效性，发现这些模型表现欠佳。作为创新贡献，我们提出新型多任务愿景变换器自编码器（META）模型来解决这一挑战性问题。该模型通过位置编码、基于变换器的自编码器和多任务预测三大组件，有效学习适用于评级迁移预测和信用评级预测的表征表示，从而在训练阶段更好地利用历史数据实现一年后的预测。实验结果表明，META模型在所有基线模型上均展现出更优性能。

（注：根据学术论文摘要的文体特征，译文采用以下处理：
1. 专业术语标准化："credit ratings"统一译为"信用评级"，"BASEL II"保留国际通用表述
2. 长句拆分：将原文复合长句按中文表达习惯分解为多个短句
3. 逻辑显化：通过"即"明确解释预测问题的具体含义
4. 被动语态转化："are quantified assessments"转换为主动式"是...量化评估"
5. 概念准确传递："Multi-task Envisioning Transformer-based Autoencoder"采用意译+缩写的专业术语处理方式）|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-task+Envisioning+Transformer-based+Autoencoder+for+Corporate+Credit+Rating+Migration+Early+Prediction)|0|
|[Felicitas: Federated Learning in Distributed Cross Device Collaborative Frameworks](https://doi.org/10.1145/3534678.3539039)|Qi Zhang, Tiancheng Wu, Peichen Zhou, Shan Zhou, Yuan Yang, Xiulang Jin|Huawei Technol Co Ltd, Cent Software Inst, Shenzhen, Peoples R China|Felicitas is a distributed cross-device Federated Learning (FL) framework to solve the industrial difficulties of FL in large-scale device deployment scenarios. In Felicitas, FL-Clients are deployed on mobile or embedded devices, while FL-Server is deployed on the cloud platform. We also summarize the challenges of FL deployment in industrial cross-device scenarios (massively parallel, stateless clients, non-use of client identifiers, highly unreliable, unsteady and complex deployment), and provide reliable solutions. We provide the source code and documents at https://www.mindspore.cn/. In addition, the Felicitas has been deployed on mobile phones in real world. At the end of the paper, we demonstrate the validity of the framework through experiments.|Felicitas是一种分布式跨设备联邦学习（FL）框架，旨在解决大规模设备部署场景下联邦学习的工业级应用难题。该框架将FL客户端部署于移动终端或嵌入式设备，FL服务器端部署于云端平台。我们系统总结了工业跨设备场景中联邦学习部署面临的挑战（包括大规模并行、无状态客户端、禁用客户端标识符、高度不可靠性、运行环境不稳定及复杂部署），并提供了可靠的解决方案。相关源代码及文档已发布于https://www.mindspore.cn/。目前Felicitas已在真实场景中成功部署于移动设备集群，文末通过实验验证了该框架的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Felicitas:+Federated+Learning+in+Distributed+Cross+Device+Collaborative+Frameworks)|0|
|[Reducing the Friction for Building Recommender Systems with Merlin](https://doi.org/10.1145/3534678.3542633)|Sara Rabhi, Ronay Ak, Marc Romeijn, Gabriel de Souza Pereira Moreira, Benedikt D. Schifferer|NVIDIA, Stockholm, Sweden; NVIDIA, Sao Paulo, Brazil; NVIDIA, Berlin, Germany; NVIDIA, Toronto, ON, Canada; NVIDIA, Sarasota, FL 95051 USA|Recommender Systems (RecSys) are the engine of the modern internet and the catalyst for human decisions. The goal of a recommender system is to generate relevant recommendations for users from a collection of items or services that might interest them. Building a recommendation system is challenging because it requires multiple stages (item retrieval, filtering, ranking, ordering) to work together seamlessly and efficiently during training and inference. The biggest challenges faced by new practitioners are the lack of understanding around what RecSys look like in the real world and the difficulty in transitioning from the simple Matrix Factorization (MF) to more complex deep learning architectures with multiple input features, neural components and prediction heads. To address these challenges on building recommender systems, NVIDIA developed an open source framework, called Merlin. Merlin consists of a set of libraries and tools to help RecSys practitioners build models and pipelines easily and more efficiently. Merlin Models provides modularized building blocks that can be easily connected to build classic and state-of-the-art models. It offers flexibility at each stage: multiple input processing/representation modules, different layers for designing the model's architecture, prediction heads, loss functions, negative sampling techniques, among others. In this hands-on tutorial, participants will start with data preparation using NVTabular an open-source feature engineering and preprocessing library designed to quickly and easily manipulate large scale datasets. Participants will then work on modeling with Merlin Models library, building the fundamental recommendation models such as MF and then transitioning to more complex deep learning-based models for candidate retrieval. In each iteration, we will demonstrate the seamless integration between data preparation and model training. Over the span of this tutorial, participants will learn the fundamentals of recommender systems modeling and how to build a two-stage recommender system easily using open source Merlin libraries.|推荐系统（RecSys）是现代互联网的引擎，也是人类决策的催化剂。其核心目标是从可能吸引用户的物品或服务集合中生成相关推荐。构建推荐系统具有挑战性，因其需要多个阶段（物品召回、过滤、排序、序列调整）在训练与推理过程中无缝高效协同运作。新手从业者面临的最大挑战在于：一方面不了解真实场景中推荐系统的实际形态，另一方面难以从简单的矩阵分解（MF）模型过渡到具有多输入特征、神经组件和预测头的复杂深度学习架构。

为应对这些挑战，英伟达开发了名为Merlin的开源框架。该框架包含一系列库和工具，可帮助推荐系统从业者更轻松高效地构建模型与流水线。Merlin Models提供模块化构建单元，通过简单连接即可搭建经典模型与最先进模型。其在每个阶段均具备灵活性：支持多输入处理/表征模块、多种模型架构设计层、可定制预测头、损失函数及负采样技术等。

在本实践教程中，学员将首先使用NVTabular进行数据准备——这是一个专为快速处理大规模数据集而设计的开源特征工程与预处理库。随后学员将通过Merlin Models库构建基础推荐模型（如矩阵分解），并逐步过渡到基于深度学习的复杂候选召回模型。每个环节都将展示数据准备与模型训练间的无缝集成。通过本教程，学员将掌握推荐系统建模的基础知识，并学会使用开源Merlin库快速构建两阶段推荐系统。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reducing+the+Friction+for+Building+Recommender+Systems+with+Merlin)|0|
|[Modern Theoretical Tools for Designing Information Retrieval System](https://doi.org/10.1145/3534678.3542614)|Da Xu, Chuanwei Ruan|Instacart, San Francisco, CA USA; Walmart Labs, Sunnyvale, CA 94086 USA|In the past decade, deep learning has significantly reshaped the landscape of information retrieval (IR). The community has recently begun to notice the potential dangers of overusing less-understood mechanisms and over-simplified assumptions to learn patterns and make decisions. In particular, there is growing concerns on the interpretation, reliability, social impact, and long-term utility of real-world IR systems. Therefore, it has become a pressing issue to bring the IR community comprehensive and systematic tools to understand empirical domain solutions and motivate principled design ideas. We focus on the three pillar stones of modern IR systems: pattern recognition with deep learning, causal inference analysis, and online decision making (with bandits and reinforcement learning). Our objectives are as follows. For pattern recognition, we introduce theoretical tools that address the expressivity, optimization, generalization, and model diagnostic for widespread domain practices, including models from unsupervised, (semi-)supervised, meta-learning, and online learning. For causal inference analysis, we emphasize both learning from observational studies and optimizing online experiment design, leveraging the recent theoretical advancements from various domains. Finally, for online decision making (with bandits and reinforcement learning), we aim to resolve both the conceptual and practical learning, evaluation and deployment challenges by introducing powerful tools from robust optimization and optimal control. Our tutorial is inclusive: we not only cover a broad range of heating topics, more importantly, we substantiate our discussion with the production examples at Walmart and Instacart such that audiences with different backgrounds can learn to leverage the tools as instructed. Our tutorial can serve as a guideline for practitioners seeking justifications and principled design ideas, a playbook for researchers landing their innovations on IR productions, and an introductory course for those interested in learning the advanced topics and tools of IR.|过去十年间，深度学习显著重塑了信息检索（IR）领域的发展图景。学界近期开始注意到过度使用尚未被充分理解的机制和过度简化的假设来学习模式并做出决策的潜在风险。尤其值得关注的是，现实世界信息检索系统在可解释性、可靠性、社会影响及长期效用方面正引发日益增长的担忧。因此，为信息检索领域提供全面系统的工具以理解实证领域解决方案并激发基于原理的设计理念，已成为紧迫议题。我们聚焦现代信息检索系统的三大基石：基于深度学习的模式识别、因果推理分析以及在线决策（通过多臂老虎机和强化学习实现）。我们的目标如下：在模式识别方面，引入理论工具以解决广泛领域实践中的表达能力、优化、泛化及模型诊断问题，涵盖无监督、（半）监督、元学习及在线学习等模型；在因果推理分析方面，结合多领域最新理论进展，重点探讨从观察性研究中学习以及优化在线实验设计；最后针对在线决策（通过多臂老虎机和强化学习），通过引入鲁棒优化和最优控制的强大工具，旨在解决概念层面和实践层面的学习、评估与部署挑战。本教程具有广泛包容性：不仅涵盖众多热点议题，更重要的是通过沃尔玛和Instacart的生产案例实证分析，使不同背景的受众能按指导有效运用这些工具。本教程既可作为寻求理论依据与原理化设计思路的实践者指南，也可作为研究人员将其创新落地于信息检索产品的操作手册，同时还能为有意深入了解信息检索前沿议题与工具的学习者提供入门课程。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modern+Theoretical+Tools+for+Designing+Information+Retrieval+System)|0|
|[Data Science and Artificial Intelligence for Responsible Recommendations](https://doi.org/10.1145/3534678.3542916)|Shoujin Wang, Ninghao Liu, Xiuzhen Zhang, Yan Wang, Francesco Ricci, Bamshad Mobasher|Free Univ Bozen Bolzano, Bolzano, Italy; RMIT Univ, Melbourne, Vic, Australia; DePaul Univ, Chicago, IL USA; Macquarie Univ, Sydney, NSW, Australia; Macquarie Univ, RMIT Univ, Sydney, NSW, Australia; Univ Georgia, Athens, GA 30602 USA|With the advancement of data science and AI, more and more powerful and accurate recommender systems (RSs) have been developed. They provide recommendation services in various areas, including shopping, eating, travelling and entertainment. RSs have achieved a great success and benefted the society. However, most of the research on RS has focused on the improvement of the recommendation accuracy, while ignoring other important qualities, such as trustworthiness (robustness, fairness, explainability, privacy and security) and social impact (influence on users' recognition and behaviours) of the recommendations. These are important aspects and cannot be overlooked since they measure properties that determine whether the recommendation service is reliable, trustworthy and benefcial to individual users and society. In this work, responsible recommendations refer to trustworthy recommendation techniques and positive-social-impact recommendation results. This workshop aims to engage with active researchers from the RS community, and other communities, as social science, to discuss state-of-the-art research results related to the core challenges of responsible recommendation services. We will focus on two main topics of responsible RSs: (1) developing reliable and trustworthy RS models and algorithms, to provide reliable recommendation results when facing a complex, uncertain and dynamic scenario; (2) assessing the social influence of RSs on human's recognition and behaviours and ensuring the influence is positive to the society.|随着数据科学与人工智能技术的进步，推荐系统日益呈现出更强大的功能与更高的精准度。这类系统已在购物、餐饮、旅行、娱乐等多个领域提供推荐服务，取得了显著成功并产生了积极的社会效益。然而现有研究大多聚焦于提升推荐准确度，却忽视了其他重要特性——包括推荐结果的可信度（涵盖鲁棒性、公平性、可解释性、隐私保护与安全性）以及社会影响（对用户认知与行为模式的塑造作用）。这些维度至关重要，因其直接决定了推荐服务是否具备可靠性、可信度以及对用户与社会产生正向价值。本研究将"负责任推荐"定义为兼具技术可信度与社会正向影响力的推荐范式。本次研讨会旨在汇聚推荐系统领域及其他相关学科（如社会科学）的活跃研究者，共同探讨负责任推荐服务的核心挑战与前沿研究成果。我们将重点关注两大主题：（1）开发可靠且可信的推荐模型与算法，使其在复杂、不确定和动态场景中仍能提供稳健的推荐结果；（2）评估推荐系统对人类认知与行为的社会影响，并确保这种影响对社会产生积极推动作用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Data+Science+and+Artificial+Intelligence+for+Responsible+Recommendations)|0|
|[User Behavior Pre-training for Online Fraud Detection](https://doi.org/10.1145/3534678.3539126)|Can Liu, Yuncong Gao, Li Sun, Jinghua Feng, Hao Yang, Xiang Ao|Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China; Alibaba Grp, Hangzhou, Peoples R China|The outbreak of COVID-19 burgeons newborn services on online platforms and simultaneously buoys multifarious online fraud activities. Due to the rapid technological and commercial innovation that opens up an ever-expanding set of products, the insufficient labeling data renders existing supervised or semi-supervised fraud detection models ineffective in these emerging services. However, the ever accumulated user behavioral data on online platforms might be helpful in improving the performance of fraud detection on newborn services. To this end, in this paper, we propose to pre-train user behavior sequences, which consist of orderly arranged actions, from the large-scale unlabeled data sources for online fraud detection. Recent studies illustrate accurate extraction of user intentions~(formed by consecutive actions) in behavioral sequences can propel improvements in the performance of online fraud detection. By anatomizing the characteristic of online fraud activities, we devise a model named UB-PTM that learns knowledge of fraud activities by three agent tasks at different granularities, i.e., action, intention, and sequence levels, from large-scale unlabeled data. Extensive experiments on three downstream transaction and user-level online fraud detection tasks demonstrate that our UB-PTM is able to outperform the state-of-the-art designing for specific tasks.|新冠疫情催生了大量新兴在线服务,同时也滋生了多样化的网络欺诈活动。由于技术和商业创新快速发展带来产品种类不断扩展,标注数据的匮乏使得现有监督或半监督欺诈检测模型在这些新兴服务中效果有限。然而,在线平台上持续积累的用户行为数据可能有助于提升新兴服务的欺诈检测性能。为此,本文提出从大规模无标注数据源中预训练用户行为序列(由有序排列的操作组成)以进行在线欺诈检测。近期研究表明,准确提取行为序列中用户意图(由连续操作形成)能够有效提升在线欺诈检测性能。通过剖析网络欺诈活动特征,我们设计了UB-PTM模型,该模型通过动作、意图和序列三个不同粒度的代理任务,从大规模无标注数据中学习欺诈活动知识。在三个下游交易级和用户级在线欺诈检测任务上的大量实验表明,我们的UB-PTM模型能够超越针对特定任务设计的最先进方案。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=User+Behavior+Pre-training+for+Online+Fraud+Detection)|0|
|[Sampling-based Estimation of the Number of Distinct Values in Distributed Environment](https://doi.org/10.1145/3534678.3539390)|Jiajun Li, Zhewei Wei, Bolin Ding, Xiening Dai, Lu Lu, Jingren Zhou|Renmin Univ China, Beijing, Peoples R China; Alibaba Grp, Hangzhou, Peoples R China|In data mining, estimating the number of distinct values (NDV) is a fundamental problem with various applications. Existing methods for estimating NDV can be broadly classified into two categories: i) scanning-based methods, which scan the entire data and maintain a sketch to approximate NDV; and ii) sampling-based methods, which estimate NDV using sampling data rather than accessing the entire data warehouse. Scanning-based methods achieve a lower approximation error at the cost of higher I/O and more time. Sampling-based estimation is preferable in applications with a large data volume and a permissible error restriction due to its higher scalability. However, while the sampling-based method is more effective on a single machine, it is less practical in a distributed environment with massive data volumes. For obtaining the final NDV estimators, the entire sample must be transferred throughout the distributed system, incurring a prohibitive communication cost when the sample rate is significant. This paper proposes a novel sketch-based distributed method that achieves sub-linear communication costs for distributed sampling-based NDV estimation under mild assumptions. Our method leverages a sketch-based algorithm to estimate the sample's frequency of frequency in the distributed streaming model, which is compatible with most classical sampling-based NDV estimators. Additionally, we provide theoretical evidence for our method's ability to minimize communication costs in the worst-case scenario. Extensive experiments show that our method saves orders of magnitude in communication costs compared to existing sampling- and sketch-based methods.|在数据挖掘领域，基数估计（NDV）是一个具有多种应用价值的基础性问题。现有NDV估计方法可分为两大类：一是基于扫描的方法，通过全量扫描数据并维护草图结构来近似估算基数；二是基于采样的方法，利用样本数据而非访问整个数据仓库进行估计。基于扫描的方法虽能实现较低近似误差，但需付出更高的I/O开销和时间成本。基于采样的方法因其更优的可扩展性，更适合数据量庞大且允许一定误差的应用场景。然而，尽管基于采样的方法在单机环境下表现优异，但在海量数据分布式环境中实用性有限——为获得最终基数估计值，需将完整样本在分布式系统中传输，当采样率较高时会产生难以承受的通信开销。本文提出一种基于草图的创新分布式方法，在温和假设条件下实现分布式采样基数估计的次线性通信成本。该方法通过基于草图的算法在分布式流模型下估计样本的频数之频数，可与多数经典采样基数估计器兼容。此外，我们通过理论证明该方法在最坏情况下仍能最小化通信成本。大量实验表明，相较现有基于采样和草图的方法，本方法可节省数量级的通信开销。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sampling-based+Estimation+of+the+Number+of+Distinct+Values+in+Distributed+Environment)|0|
|[Sample-Efficient Kernel Mean Estimator with Marginalized Corrupted Data](https://doi.org/10.1145/3534678.3539318)|Xiaobo Xia, Shuo Shan, Mingming Gong, Nannan Wang, Fei Gao, Haikun Wei, Tongliang Liu|Univ Sydney, Sydney, NSW, Australia; Univ Melbourne, Melbourne, Vic, Australia; Xidian Univ, Xian, Peoples R China; Southeast Univ, Nanjing, Peoples R China; Hangzhou Dianzi Univ, Hangzhou, Peoples R China|Estimating the kernel mean in a reproducing kernel Hilbert space is central to many kernel-based learning algorithms. Given a finite sample, an empirical average is used as a standard estimation of the target kernel mean. Prior works have shown that better estimators can be constructed by shrinkage methods. In this work, we propose to corrupt data examples with noise from known distributions and present a new kernel mean estimator, called the marginalized kernel mean estimator, which estimates kernel mean under the corrupted distributions. Theoretically, we justify that the marginalized kernel mean estimator introduces implicit regularization in kernel mean estimation. Empirically, on a variety of tasks, we show that the marginalized kernel mean estimator is sample-efficient and obtains much lower estimation errors than the existing estimators.|再生核希尔伯特空间中的核均值估计是众多基于核的学习算法的核心。给定有限样本，经验平均值通常被用作目标核均值的标准估计方法。先前研究已证明，通过收缩方法可以构建出更优的估计量。本研究提出通过已知分布噪声干扰数据样本，进而提出一种新型核均值估计器——边缘化核均值估计器，该估计器可在受干扰分布下实现核均值估计。理论上，我们证明了边缘化核均值估计器在核均值估计中引入了隐式正则化机制。在实证研究中，通过多任务测试表明，边缘化核均值估计器具有优异的样本效率，其估计误差显著低于现有估计器。

（译文说明：采用学术论文的规范表述方式，精准翻译专业术语如"reproducing kernel Hilbert space"译为"再生核希尔伯特空间"，"implicit regularization"译为"隐式正则化"。保持原文的学术严谨性，同时通过"显著低于"等符合中文论文表达的措辞增强专业性。句式结构根据中文表达习惯进行了重组，如将英文长句拆分为符合中文阅读节奏的短句。）|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sample-Efficient+Kernel+Mean+Estimator+with+Marginalized+Corrupted+Data)|0|
|[Accurate Node Feature Estimation with Structured Variational Graph Autoencoder](https://doi.org/10.1145/3534678.3539337)|Jaemin Yoo, Hyunsik Jeon, Jinhong Jung, U Kang|Carnegie Mellon Univ, Pittsburgh, PA 15213 USA; Seoul Natl Univ, Seoul, South Korea; JBNU, Jeonju, South Korea|Given a graph with partial observations of node features, how can we estimate the missing features accurately? Feature estimation is a crucial problem for analyzing real-world graphs whose features are commonly missing during the data collection process. Accurate estimation not only provides diverse information of nodes but also supports the inference of graph neural networks that require the full observation of node features. However, designing an effective approach for estimating high-dimensional features is challenging, since it requires an estimator to have large representation power, increasing the risk of overfitting. In this work, we propose SVGA (Structured Variational Graph Autoencoder), an accurate method for feature estimation. SVGA applies strong regularization to the distribution of latent variables by structured variational inference, which models the prior of variables as Gaussian Markov random field based on the graph structure. As a result, SVGA combines the advantages of probabilistic inference and graph neural networks, achieving state-of-the-art performance in real datasets.|给定一个节点特征存在部分观测的图，我们如何准确估计缺失特征？特征估计是分析现实世界图数据的关键问题，由于数据收集过程中常出现特征缺失现象。精确的特征估计不仅能提供丰富的节点信息，还能支持需要完整节点特征观测的图神经网络进行推理。然而，为高维特征估计设计有效方法具有挑战性，因为这要求估计器具备强大表征能力，同时会增大过拟合风险。本研究提出SVGA（结构化变分图自编码器）——一种精准的特征估计方法。该方法通过结构化变分推断对潜在变量分布实施强正则化，将变量先验建模为基于图结构的高斯马尔可夫随机场。SVGA由此融合了概率推断与图神经网络的双重优势，在真实数据集中实现了最先进的性能表现。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Accurate+Node+Feature+Estimation+with+Structured+Variational+Graph+Autoencoder)|0|
|[Semantic Aware Answer Sentence Selection Using Self-Learning Based Domain Adaptation](https://doi.org/10.1145/3534678.3539162)|Rajdeep Sarkar, Sourav Dutta, Haytham Assem, Mihael Arcan, John P. McCrae|Amazon Alexa AI, Cambridge, England; Huawei Res, Dublin, Ireland; Natl Univ Ireland Galway, Data Sci Inst, Galway, Ireland|Selecting an appropriate and relevant context forms an essential component for the efficacy of several information retrieval applications like Question Answering (QA) systems. The problem of Answer Sentence Selection (AS2) refers to the task of selecting sentences, from a larger text, that are relevant and contain the answer to users' queries. While there has been a lot of success in building AS2 systems trained on open-domain data (e.g., SQuAD, NQ), they do not generalize well in closed-domain settings, since domain adaptation can be challenging due to poor availability and annotation expense of domain-specific data. This paper proposes SEDAN, an effective self-learning framework to adapt AS2 models for domain-specific applications. We leverage large pre-trained language models to automatically generate domain-specific QA pairs for domain adaptation. We further fine-tune a pre-trained Sentence-BERT architecture to capture semantic relatedness between questions and answer sentences for AS2. Extensive experiments demonstrate the effectiveness of our proposed approach (over existing state-of-the-art AS2 baselines) on different Question Answering benchmark datasets.|选择合适的相关语境是提升问答系统等多项信息检索应用效能的关键环节。答案句选择（AS2）任务旨在从长篇文本中筛选出与用户查询相关且包含答案的句子。尽管基于开放领域数据（如SQuAD、NQ）训练的AS2系统已取得显著成果，但由于领域特定数据获取困难且标注成本高昂，这类系统在封闭领域场景中的泛化能力仍然有限。本文提出SEDAN——一种有效的自学习框架，用于使AS2模型适配特定领域应用。我们利用大规模预训练语言模型自动生成领域特定的问答对以实现领域自适应，并进一步对预训练的Sentence-BERT架构进行微调，以捕捉问答句之间的语义相关性。大量实验证明，我们所提出的方法在不同问答基准数据集上均优于现有最先进的AS2基线模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Semantic+Aware+Answer+Sentence+Selection+Using+Self-Learning+Based+Domain+Adaptation)|0|
|[CONFLUX: A Request-level Fusion Framework for Impression Allocation via Cascade Distillation](https://doi.org/10.1145/3534678.3539044)|XiaoYu Wang, Bin Tan, Yonghui Guo, Tao Yang, Dongbo Huang, Lan Xu, Nikolaos M. Freris, Hao Zhou, Xiangyang Li|Univ Sci & Technol China, LINKE Lab, Sch Comp Sci & Technol, Beijing, Peoples R China; Tencent Advertising, Shenzhen, Peoples R China|Guaranteed delivery (GD) and real-time bidding (RTB) constitute two parallel profit streams for the publisher. The diverse advertiser demands (brand or instant effect) result in different selling (in bulk or via auction) and pricing (fixed unit price or various bids) patterns, which naturally raises the fusion allocation issue of breaking the two markets' barrier and selling out at the global highest price boosting the total revenue. The fusion process complicates the competition between GD and RTB, and GD contracts with overlapping targeting. The non-stationary user traffic and bid landscape further worsen the situation, making the assignment unsupervised and hard to evaluate. Thus, a static policy or coarse-grained modeling from existing work is inferior to facing the above challenges. This paper proposes CONFLUX, a fusion framework located at the confluence of the parallel GD and RTB markets. CONFLUX functions in a cascaded process: a paradigm is first forged via linear programming to supervise CONFLUX's training, then a cumbersome network distills such paradigm by precisely modeling the competition at a request level and further transfers the generalization ability to a lightweight student via knowledge distillation. Finally, fine-tuning is periodically executed at the online stage to remedy the student's degradation, and a temporal distillation loss between the current and the previous model serves as a regularizer to prevent over-fitting. The procedure is analogous to a cascade distillation and hence its name. CONFLUX has been deployed on the Tencent advertising system for over six months through extensive experiments. Online A/B tests present a lift of 3.29%, 1.77%, and 3.63% of ad income, overall click-through rate, and cost-per-mille, respectively, which jointly contribute a revenue increase by hundreds of thousands RMB per day. Our code is publicly available at https://github.com/zslomo/CONFLUX.|保量投放（GD）与实时竞价（RTB）构成了发布商的两大并行收益渠道。品牌广告主与效果广告主的不同需求（品牌曝光或即时转化），导致了不同的销售模式（批量预售或实时竞价）与定价机制（固定单价或动态出价），这自然引出了打破两个市场壁垒、以全局最高价售出库存并提升总收益的融合分配问题。该融合过程使得GD与RTB的竞争关系复杂化，且存在目标受众重叠的GD合约。非稳态的用户流量与竞价环境进一步加剧了问题难度，导致分配过程缺乏监督信号且难以评估。因此，面对上述挑战时，静态策略或现有工作的粗粒度建模方法均存在明显不足。

本文提出CONFLUX框架，该框架立足于GD与RTB并行市场的交汇点。CONFLUX采用级联式架构运作：首先通过线性规划构建最优分配范式以指导模型训练；随后通过笨重教师网络对请求级竞争关系进行精确建模，并利用知识蒸馏将泛化能力迁移至轻量级学生网络；最后在在线阶段定期执行微调以修正模型退化，同时通过当前模型与历史模型间的时序蒸馏损失作为正则项防止过拟合。该流程类似于级联蒸馏过程，故得名CONFLUX。本框架已在腾讯广告系统持续部署超过六个月，大量实验表明：在线A/B测试中广告收入、整体点击率和千次展示收益分别提升3.29%、1.77%和3.63，共同实现每日数十万元人民币的收入增长。代码已开源：https://github.com/zslomo/CONFLUX。

（注：根据学术规范，技术术语采用以下译法：
- Guaranteed delivery: 保量投放（GD）
- Real-time bidding: 实时竞价（RTB）  
- Click-through rate: 点击率
- Cost-per-mille: 千次展示收益
- Knowledge distillation: 知识蒸馏
- Linear programming: 线性规划
- Fine-tuning: 微调
- Over-fitting: 过拟合）|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CONFLUX:+A+Request-level+Fusion+Framework+for+Impression+Allocation+via+Cascade+Distillation)|0|
|[Multi Armed Bandit vs. A/B Tests in E-commence - Confidence Interval and Hypothesis Test Power Perspectives](https://doi.org/10.1145/3534678.3539144)|Ding Xiang, Rebecca West, Jiaqi Wang, Xiquan Cui, Jinzhou Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi+Armed+Bandit+vs.+A/B+Tests+in+E-commence+-+Confidence+Interval+and+Hypothesis+Test+Power+Perspectives)|0|
|[CausalMTA: Eliminating the User Confounding Bias for Causal Multi-touch Attribution](https://doi.org/10.1145/3534678.3539108)|Di Yao, Chang Gong, Lei Zhang, Sheng Chen, Jingping Bi|Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China; Chinese Acad Sci, Univ Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China; Alibaba Inc, Strat Data Solut SDS Grp, Hangzhou, Peoples R China|Multi-touch attribution (MTA), aiming to estimate the contribution of each advertisement touchpoint in conversion journeys, is essential for budget allocation and automatically advertising. Existing methods first train a model to predict the conversion probability of the advertisement journeys with historical data and calculate the attribution of each touchpoint by using the results counterfactual predictions. An assumption of these works is the conversion prediction model is unbiased. It can give accurate predictions on any randomly assigned journey, including both the factual and counterfactual ones. Nevertheless, this assumption does not always hold as the user preferences act as the common cause for both ad generation and user conversion, involving the confounding bias and leading to an out-of-distribution (OOD) problem in the counterfactual prediction. In this paper, we define the causal MTA task and propose CausalMTA to solve this problem. It systemically eliminates the confounding bias from both static and dynamic perspectives and learn an unbiased conversion prediction model using historical data. We also provide a theoretical analysis to prove the effectiveness of CausalMTA with sufficient ad journeys. Extensive experiments on both synthetic and real data in Alibaba advertising platform show that CausalMTA can not only achieve better prediction performance than the state-of-the-art method but also generate meaningful attribution credits across different advertising channels.|多触点归因（MTA）旨在量化用户转化路径中每个广告触点的贡献度，对预算分配与自动化广告投放至关重要。现有方法通常先基于历史数据训练转化概率预测模型，再通过反事实预测计算各触点 attribution。这类方法隐含一个重要假设：转化预测模型需保持无偏性，即能对随机分配的广告路径（包括事实与反事实路径）进行准确预测。然而，由于用户偏好同时影响广告生成与用户转化行为，会引发混淆偏差并导致反事实预测中的分布外（OOD）问题，使得该假设在实际场景中难以成立。本文首次明确定义因果MTA任务，并提出CausalMTA解决方案：通过静态与动态双视角系统消除混淆偏差，基于历史数据学习无偏的转化预测模型。我们同时提供理论证明，论证CausalMTA在充足广告路径数据下的有效性。在阿里巴巴广告平台的合成数据与真实数据实验中，CausalMTA不仅超越了现有最优方法的预测性能，还能在不同广告渠道间生成具有业务解释性的归因分值。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CausalMTA:+Eliminating+the+User+Confounding+Bias+for+Causal+Multi-touch+Attribution)|0|
|[Why Data Scientists Prefer Glassbox Machine Learning: Algorithms, Differential Privacy, Editing and Bias Mitigation](https://doi.org/10.1145/3534678.3542627)|Rich Caruana, Harsha Nori|Microsoft Res, Redmond, WA 98052 USA|Recent research has shown that interpretable machine learning models can be just as accurate as blackbox learning methods on tabular datasets. In this tutorial we will walk you through leading open source tools for glassbox learning, and show how intelligible machine learning helps practitioners uncover flaws in their datasets, discover new science, and build models that are more fair and robust. We'll begin with an introduction to the science behind glassbox modeling, and walk through a series of case-studies that highlight the added value of interpretable methods in a variety of domains such as finance and healthcare without compromising accuracy. We'll also show how glassbox models can be used for state of the art differentially private learning, bias detection/mitigation, and how these models can be edited to remove undesirable effects with GAMChanger. We'll also discuss how to train interpretable models with deep neural nets.|近期研究表明，在表格数据集上，可解释性机器学习模型能够达到与黑盒学习方法相当的准确度。本教程将带您深入了解领先的开源玻璃盒学习工具，并展示可解释机器学习如何帮助从业者发现数据集缺陷、推动科学新发现，以及构建更公平稳健的模型。我们将首先介绍玻璃盒建模的科学原理，并通过一系列跨领域（如金融与医疗）案例研究，展示可解释方法在保持准确性的前提下如何为不同行业创造附加价值。我们还将演示如何运用玻璃盒模型实现前沿的差分隐私学习、偏差检测/缓解，以及如何通过GAMChanger工具编辑模型以消除不良影响。最后我们将探讨如何利用深度神经网络训练可解释模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Why+Data+Scientists+Prefer+Glassbox+Machine+Learning:+Algorithms,+Differential+Privacy,+Editing+and+Bias+Mitigation)|0|
|[Efficient Machine Learning on Large-Scale Graphs](https://doi.org/10.1145/3534678.3542623)|Parker Erickson, Victor E. Lee, Feng Shi, Jiliang Tang|Michigan State Univ, E Lansing, MI 48824 USA; TigerGraph, Redwood City, CA 94065 USA|Machine learning on graph data has become a common area of interest across academia and industry. However, due to the size of real-world industry graphs (hundreds of millions of vertices and billions of edges) and the special architecture of graph neural net- works, it is still a challenge for practitioners and researchers to perform machine learning tasks on large-scale graph data. It typi- cally takes a powerful and expensive GPU machine to train a graph neural network on a million-vertex scale graph, let alone doing deep learning on real enterprise graphs. In this tutorial, we will cover how to develop and run performant graph algorithms and graph neural network models with TigerGraph [3], a massively parallel platform for graph analytics, and its Machine Learning Workbench with PyTorch Geometric [4] and DGL [8] support. Using an NFT transaction dataset [6], we will first investigate transactions using graph algorithms by themselves as methods of graph traversing, clustering, classification, and determining similarities between data. Secondly, we will show how to use those graph-derived features such as PageRank and embeddings to empower traditional machine learning models. Finally, we will demonstrate how to train common graph neural networks with TigerGraph and how to implement novel graph neural network models. Participants will use the Tiger- Graph ML Workbench Cloud to perform graph feature engineering and train their machine learning algorithms during the session.|图数据上的机器学习已成为学术界与工业界的共同关注点。然而，由于现实工业级图谱的庞大规模（数亿顶点与数十亿边）以及图神经网络的特殊架构，从业者与研究者在大规模图数据上执行机器学习任务仍面临挑战。通常需要配备高性能昂贵GPU的机器才能训练百万级顶点规模的图神经网络，更不用说在真实企业级图谱上进行深度学习。本教程将系统介绍如何利用TigerGraph[3]——一个支持大规模并行图分析的计算平台及其集成PyTorch Geometric[4]和DGL[8]的机器学习工作台，来开发并运行高性能图算法与图神经网络模型。我们将以NFT交易数据集[6]为例，首先演示如何通过图遍历、聚类、分类及数据相似性判定等图算法进行交易分析；其次展示如何运用PageRank和嵌入表示等图衍生特征增强传统机器学习模型；最后详解基于TigerGraph训练常见图神经网络的方法及创新模型的实现路径。参会者将使用TigerGraph机器学习云工作台，在课程中实际完成图特征工程与机器学习算法训练。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Machine+Learning+on+Large-Scale+Graphs)|0|
|[FreeKD: Free-direction Knowledge Distillation for Graph Neural Networks](https://doi.org/10.1145/3534678.3539320)|Kaituo Feng, Changsheng Li, Ye Yuan, Guoren Wang|Beijing Inst Technol, Beijing, Peoples R China|Knowledge distillation (KD) has demonstrated its effectiveness to boost the performance of graph neural networks (GNNs), where its goal is to distill knowledge from a deeper teacher GNN into a shallower student GNN. However, it is actually difficult to train a satisfactory teacher GNN due to the well-known over-parametrized and over-smoothing issues, leading to invalid knowledge transfer in practical applications. In this paper, we propose the first Free-direction Knowledge Distillation framework via Reinforcement learning for GNNs, called FreeKD, which is no longer required to provide a deeper well-optimized teacher GNN. The core idea of our work is to collaboratively build two shallower GNNs in an effort to exchange knowledge between them via reinforcement learning in a hierarchical way. As we observe that one typical GNN model often has better and worse performances at different nodes during training, we devise a dynamic and free-direction knowledge transfer strategy that consists of two levels of actions: 1) node-level action determines the directions of knowledge transfer between the corresponding nodes of two networks; and then 2) structure-level action determines which of the local structures generated by the node-level actions to be propagated. In essence, our FreeKD is a general and principled framework which can be naturally compatible with GNNs of different architectures. Extensive experiments on five benchmark datasets demonstrate our FreeKD outperforms two base GNNs in a large margin, and shows its efficacy to various GNNs. More surprisingly, our FreeKD has comparable or even better performance than traditional KD algorithms that distill knowledge from a deeper and stronger teacher GNN.|知识蒸馏（KD）已证明能有效提升图神经网络（GNN）性能，其核心目标是将深层教师GNN的知识提炼到浅层学生GNN中。然而由于众所周知的过参数化和过平滑问题，实际应用中难以训练出令人满意的教师GNN，导致知识传递失效。本文提出首个基于强化学习的自由方向知识蒸馏框架FreeKD，该框架不再需要提供经过深度优化的教师GNN。我们的核心思想是通过强化学习以分层方式协同构建两个浅层GNN，实现二者间的知识交换。通过观察到典型GNN模型在训练过程中不同节点往往存在性能波动，我们设计了一种动态自由方向知识传递策略，该策略包含两级动作：1）节点级动作决定两个网络对应节点间的知识传递方向；2）结构级动作决定由节点级动作生成的哪些局部结构需要传播。本质上，FreeKD是一个通用且具有原则性的框架，可自然兼容不同架构的GNN。在五个基准数据集上的大量实验表明，FreeKD显著优于两个基线GNN，并证明其对各类GNN的有效性。更令人惊讶的是，FreeKD的性能与传统KD算法（从更深层、更强壮的教师GNN中提取知识）相当甚至更优。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FreeKD:+Free-direction+Knowledge+Distillation+for+Graph+Neural+Networks)|0|
|[SIPF: Sampling Method for Inverse Protein Folding](https://doi.org/10.1145/3534678.3539284)|Tianfan Fu, Jimeng Sun|Univ Illinois, Urbana, IL USA; Georgia Inst Technol, Atlanta, GA 30332 USA|Protein engineering has important applications in drug discovery. Among others, inverse protein folding is a fundamental task in protein design, which aims at generating protein's amino acid sequence given a 3D graph structure. However, most existing methods for inverse protein folding are based on sequential generative models and therefore limited in uncertainty quantification and exploration ability to the entire protein space. To address the issues, we propose a sampling method for inverse protein folding (SIPF). Specifically, we formulate inverse protein folding as a sampling problem and design two pretrained neural networks as Markov Chain Monte Carlo (MCMC) proposal distribution. To ensure sampling efficiency, we further design (i) an adaptive sampling scheme to select variables for sampling and (ii) an approximate target distribution as a surrogate of the unavailable target distribution. Empirical studies have been conducted to validate the effectiveness of SIPF, achieving 7.4% relative improvement on recovery rate and 6.4% relative reduction in perplexity compared to the best baseline.|蛋白质工程在药物发现领域具有重要应用价值。其中，逆蛋白质折叠是蛋白质设计中的一项基础性任务，其目标是根据三维图结构生成蛋白质的氨基酸序列。然而，现有的大多数逆蛋白质折叠方法基于序列生成模型，因此存在不确定性量化能力不足以及对整个蛋白质空间探索能力有限的问题。为解决这些局限性，我们提出了一种逆蛋白质折叠采样方法（SIPF）。具体而言，我们将逆蛋白质折叠问题构建为采样问题，并设计两个预训练神经网络作为马尔可夫链蒙特卡洛（MCMC）的建议分布。为确保采样效率，我们进一步设计了：（1）自适应采样方案用于选择待采样变量；（2）近似目标分布作为不可获得目标分布的替代。实证研究验证了SIPF方法的有效性，与最佳基线相比，恢复率相对提升7.4%，困惑度相对降低6.4%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SIPF:+Sampling+Method+for+Inverse+Protein+Folding)|0|
|[Antibody Complementarity Determining Regions (CDRs) design using Constrained Energy Model](https://doi.org/10.1145/3534678.3539285)|Tianfan Fu, Jimeng Sun|Univ Illinois, Urbana, IL USA; Georgia Inst Technol, Atlanta, GA 30332 USA|In recent years, therapeutic antibodies have become one of the fastest-growing classes of drugs and have been approved for the treatment of a wide range of indications, from cancer to autoimmune diseases. Complementarity-determining regions (CDRs) are part of the variable chains in antibodies and determine specific antibody-antigen binding. Some explorations use in silicon methods to design antibody CDR loops. However, the existing methods faced the challenges of maintaining the specific geometry shape of the CDR loops. This paper proposes a Constrained Energy Model (CEM) to address this issue. Specifically, we design a constrained manifold to characterize the geometry constraints of the CDR loops. Then we design the energy model in the constrained manifold and only depict the energy landscape of the manifold instead of the whole space in the vanilla energy model. The geometry shape of the generated CDR loops is automatically preserved. Theoretical analysis shows that learning on the constrained manifold requires less sample complexity than the unconstrained method. CEM's superiority is validated via thorough empirical studies, achieving consistent and significant improvement with up to 33.4% relative reduction in terms of 3D geometry error (Root Mean Square Deviation, RMSD) and 8.4% relative reduction in terms of amino acid sequence metric (perplexity) compared to the best baseline method. The code is publicly available at https://github.com/futianfan/energy_model4antibody_design|近年来，治疗性抗体已成为增长最快的药物类别之一，被批准用于从癌症到自身免疫性疾病等多种适应症的治疗。互补决定区（CDR）是抗体可变区的重要组成部分，决定了抗体与抗原的特异性结合。现有研究尝试采用计算机辅助方法设计抗体CDR环，但如何在设计中保持CDR环的特有几何构型始终是技术难点。本文提出约束能量模型（CEM）以解决该问题：首先构建约束流形来表征CDR环的几何约束，随后在约束流形上建立能量模型，仅描述该流形而非原始全域的能量态势，从而自动保持生成CDR环的几何构型。理论分析表明，在约束流形上的学习比无约束方法具有更低的样本复杂度。大量实验验证了CEM的优越性——相较于最佳基线方法，三维几何误差（均方根偏差，RMSD）相对降低33.4%，氨基酸序列指标（困惑度）相对降低8.4%，且改进效果具有一致性和显著性。代码已开源：https://github.com/futianfan/energy_model4antibody_design。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Antibody+Complementarity+Determining+Regions+(CDRs)+design+using+Constrained+Energy+Model)|0|
|[Partial Label Learning with Semantic Label Representations](https://doi.org/10.1145/3534678.3539434)|Shuo He, Lei Feng, Fengmao Lv, Wen Li, Guowu Yang|Univ Elect Sci & Technol China, Chengdu, Peoples R China; Southwest Jiaotong Univ, Chengdu, Peoples R China; Chongqing Univ, Chongqing, Peoples R China|Partial-label learning (PLL) solves the problem where each training instance is assigned a candidate label set, among which only one is the ground-truth label. The core of PLL is to learn efficient feature representations to facilitate label disambiguation. However, existing PLL methods only learn plain representations by coarse supervision, which is incapable of capturing sufficiently distinguishable representations, especially when confronted with the knotty label ambiguity, i.e., certain candidate labels share similar visual patterns. In this paper, we propose a novel framework partial label learning with semantic label representations dubbed ParSE, which consists of two synergistic processes, including visual-semantic representation learning and powerful label disambiguation. In the former process, we propose a novel weighted calibration rank loss that has two implications. First, it implies a progressive calibration strategy that utilizes the disambiguated label confidence to weight the similarity between each image feature embedding and its corresponding semantic label representations of all candidates. Second, it also considers the ranking relationship between candidate and non-candidate ones. Based on learned visual-semantic representations, subsequent label disambiguation is desirably endowed with more powerful abilities. Experiments on benchmarks show that ParSE outperforms state-of-the-art counterparts.|部分标记学习（PLL）致力于解决每个训练实例被赋予候选标记集合、而其中仅有一个为真实标记的问题。其核心在于学习有效的特征表示以促进标记消歧。然而现有PLL方法仅通过粗粒度监督学习平面表示，难以捕获足够区分的特征表征，尤其在处理棘手的标记模糊性问题时（即某些候选标记具有相似视觉模式）。本文提出新型语义标签表示框架ParSE，该框架包含视觉-语义表示学习与强效标记消歧两个协同过程。在前者中，我们提出具有双重作用的新型加权校准排序损失：一方面采用渐进式校准策略，利用已消解的标记置信度加权处理图像特征嵌入与所有候选语义标签表示之间的相似度；另一方面综合考虑候选标记与非候选标记间的排序关系。基于学习到的视觉-语义表示，后续标记消歧过程被赋予更强大的能力。基准测试表明，ParSE性能优于现有最先进方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Partial+Label+Learning+with+Semantic+Label+Representations)|0|
|[HyperLogLogLog: Cardinality Estimation With One Log More](https://doi.org/10.1145/3534678.3539246)|Matti Karppa, Rasmus Pagh|IT Univ Copenhagen, BARC, Copenhagen, Denmark|We present HyperLogLogLog, a practical compression of the HyperLogLog sketch that compresses the sketch from $O(młogłog n)$ bits down to $m łog_2łog_2łog_2 m + O(m+łogłog n)$ bits for estimating the number of distinct elements~n using m~registers. The algorithm works as a drop-in replacement that preserves all estimation properties of the HyperLogLog sketch, it is possible to convert back and forth between the compressed and uncompressed representations, and the compressed sketch maintains mergeability in the compressed domain. The compressed sketch can be updated in amortized constant time, assuming n is sufficiently larger than m. We provide a C++ implementation of the sketch, and show by experimental evaluation against well-known implementations by Google and Apache that our implementation provides small sketches while maintaining competitive update and merge times. Concretely, we observed approximately a 40% reduction in the sketch size. Furthermore, we obtain as a corollary a theoretical algorithm that compresses the sketch down to $młog_2łog_2łog_2łog_2 m+O(młogłogłog m/łogłog m+łogłog n)$ bits.|我们提出HyperLogLogLog——一种实用的HyperLogLog草图压缩方案，将用于估计不同元素数量n的m个寄存器草图从$O(m\log\log n)$比特压缩至$m\log_2\log_2\log_2 m + O(m+\log\log n)$比特。该算法可作为即插即用的替代方案，完整保留HyperLogLog草图的所有估计特性，支持压缩与未压缩表示形式之间的双向转换，且在压缩状态下仍保持可合并性。当n远大于m时，压缩草图的更新操作可在摊销常数时间内完成。我们提供了该草图的C++实现，并通过与谷歌和Apache知名实现的实验对比表明：我们的实现能在保持竞争力的更新与合并速度的同时，显著减小草图体积——具体观测到近40%的体积缩减。此外，我们推导出一个理论算法作为推论，可将草图进一步压缩至$m\log_2\log_2\log_2\log_2 m+O(m\log\log\log m/\log\log m+\log\log n)$比特。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HyperLogLogLog:+Cardinality+Estimation+With+One+Log+More)|0|
|[SOS: Score-based Oversampling for Tabular Data](https://doi.org/10.1145/3534678.3539454)|Jayoung Kim, Chaejeong Lee, Yehjin Shin, Sewon Park, Minjung Kim, Noseong Park, Jihoon Cho|Yonsei Univ, Seoul, South Korea; Samsung SDS, Seoul, South Korea|Score-based generative models (SGMs) are a recent breakthrough in generating fake images. SGMs are known to surpass other generative models, e.g., generative adversarial networks (GANs) and variational autoencoders (VAEs). Being inspired by their big success, in this work, we fully customize them for generating fake tabular data. In particular, we are interested in oversampling minor classes since imbalanced classes frequently lead to sub-optimal training outcomes. To our knowledge, we are the first presenting a score-based tabular data oversampling method. Firstly, we re-design our own score network since we have to process tabular data. Secondly, we propose two options for our generation method: the former is equivalent to a style transfer for tabular data and the latter uses the standard generative policy of SGMs. Lastly, we define a fine-tuning method, which further enhances the oversampling quality. In our experiments with 6 datasets and 10 baselines, our method outperforms other oversampling methods in all cases.|基于分数的生成模型（SGMs）是近期生成伪造图像领域的一项突破性技术。该模型已知能够超越其他生成模型，例如生成对抗网络（GANs）和变分自编码器（VAEs）。受其巨大成功的启发，本研究将其完全定制用于生成伪造表格数据。我们特别关注对少数类别的过采样，因为类别不平衡往往会导致训练效果欠佳。据我们所知，这是首个基于分数的表格数据过采样方法。首先，由于需要处理表格数据，我们重新设计了专用的分数网络架构。其次，我们提出两种生成方案：前者等效于表格数据的风格迁移技术，后者采用SGM的标准生成策略。最后，我们定义了可进一步提升过采样质量的微调方法。在包含6个数据集和10个基线方法的实验中，本方法在所有案例中都优于其他过采样方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SOS:+Score-based+Oversampling+for+Tabular+Data)|0|
|[Domain Adaptation in Physical Systems via Graph Kernel](https://doi.org/10.1145/3534678.3539380)|Haoran Li, Hanghang Tong, Yang Weng|Univ Illinois, Champaign, IL USA; Arizona State Univ, Tempe, AZ 85287 USA|Physical systems are extending their monitoring capacities to edge areas with low-cost, low-power sensors and advanced data mining and machine learning techniques. However, new systems often have limited data for training the model, calling for effective knowledge transfer from other relevant grids. Specifically, Domain Adaptation (DA) seeks domain-invariant features to boost the model performance in the target domain. Nonetheless, existing DA techniques face significant challenges due to the unique characteristics of physical datasets: (1) complex spatial-temporal correlations, (2) diverse data sources including node/edge measurements and labels, and (3) large-scale data sizes. In this paper, we propose a novel cross-graph DA based on two core designs of graph kernels and graph coarsening. The former design handles spatial-temporal correlations and can incorporate networked measurements and labels conveniently. The spatial structures, temporal trends, measurement similarity, and label information together determine the similarity of two graphs, guiding the DA to find domain-invariant features. Mathematically, we construct a Graph kerNel-based distribution Adaptation (GNA) with a specifically-designed graph kernel. Then, we prove the proposed kernel is positive definite and universal, which strictly guarantees the feasibility of the used DA measure. However, the computation cost of the kernel is prohibitive for large systems. In response, we propose a novel coarsening process to obtain much smaller graphs for GNA. Finally, we report the superiority of GNA in diversified systems, including power systems, mass-damper systems, and human-activity sensing systems.|物理系统正通过低成本、低功耗传感器及先进的数据挖掘与机器学习技术，将监测能力延伸至边缘区域。然而，新建系统往往缺乏足够的训练数据，亟需从其他相关电网中实现有效的知识迁移。具体而言，域适应（DA）通过寻找域不变特征来提升模型在目标域的性能。但由于物理数据集具有三大独特特性：（1）复杂的时空相关性；（2）节点/边缘测量值和标签等多源数据；（3）大规模数据量，现有DA技术面临重大挑战。本文提出基于图核与图粗化双核心设计的新型跨图域适应方法。前者通过专门设计的图核处理时空相关性，并可无缝整合网络化测量值与标签数据——空间结构、时间趋势、测量相似性和标签信息共同决定了图的相似度，从而指导DA寻找域不变特征。在数学层面，我们构建了基于图核的分布自适应（GNA）框架，并严格证明了所提出核函数的正定性与普适性，从理论上保障了DA度量的可行性。针对大型系统核计算成本过高的问题，我们创新性地提出粗化处理方案，为GNA生成规模显著缩减的图结构。最终在电力系统、质量-阻尼系统和人体活动感知系统等多元场景中验证了GNA的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Domain+Adaptation+in+Physical+Systems+via+Graph+Kernel)|0|
|[RL2: A Call for Simultaneous Representation Learning and Rule Learning for Graph Streams](https://doi.org/10.1145/3534678.3539309)|Qu Liu, Tingjian Ge|Univ Massachusetts, Lowell, MA 01854 USA|Heterogeneous graph streams are very common in the applications today. Although representation learning has advantages in prediction accuracy, it is inherently deficient in the abilities to interpret or to reason well. It has long been realized as far back as in 1990 by Marvin Minsky that connectionist networks and symbolic rules should co-exist in a system and overcome the deficiencies of each other. The goal of this paper is to show that it is feasible to simultaneously and efficiently perform representation learning (for connectionist networks) and rule learning spontaneously out of the same online training process for graph streams. We devise such a system called RL$^2$, and show, both analytically and empirically, that it is highly efficient and responsive for graph streams, and produces good results for both representation learning and rule learning in terms of prediction accuracy and returning top-quality rules for interpretation and building dynamic Bayesian networks.|异构图流在当今应用中十分普遍。尽管表示学习在预测准确性方面具有优势，但其在解释与推理能力方面存在固有不足。早在1990年，马文·明斯基就已指出：连接主义网络与符号规则应当共存于系统中，以相互弥补不足。本文旨在证明，针对图流数据，通过同一在线训练过程同步高效地实现表示学习（面向连接主义网络）与规则自主学习具有可行性。我们设计了名为RL$^2$的系统，通过理论分析和实验验证表明：该系统对图流处理具有高效性与快速响应特性，在表示学习和规则学习方面均能取得优异成果——既保证了预测精度，又能产出高质量规则用于解释推理与构建动态贝叶斯网络。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RL2:+A+Call+for+Simultaneous+Representation+Learning+and+Rule+Learning+for+Graph+Streams)|0|
|[Learning Models of Individual Behavior in Chess](https://doi.org/10.1145/3534678.3539367)|Reid McIlroyYoung, Russell Wang, Siddhartha Sen, Jon M. Kleinberg, Ashton Anderson|Univ Calif Berkeley, Berkeley, CA USA; Univ Toronto, Toronto, ON, Canada; Cornell, Ithaca, NY USA; Microsoft Res, New York, NY USA|AI systems that can capture human-like behavior are becoming increasingly useful in situations where humans may want to learn from these systems, collaborate with them, or engage with them as partners for an extended duration. In order to develop human-oriented AI systems, the problem of predicting human actions---as opposed to predicting optimal actions---has received considerable attention. Existing work has focused on capturing human behavior in an aggregate sense, which potentially limits the benefit any particular individual could gain from interaction with these systems. We extend this line of work by developing highly accurate predictive models of individual human behavior in chess. Chess is a rich domain for exploring human-AI interaction because it combines a unique set of properties: AI systems achieved superhuman performance many years ago, and yet humans still interact with them closely, both as opponents and as preparation tools, and there is an enormous corpus of recorded data on individual player games. Starting with Maia, an open-source version of AlphaZero trained on a population of human players, we demonstrate that we can significantly improve prediction accuracy of a particular player's moves by applying a series of fine-tuning methods. Furthermore, our personalized models can be used to perform stylometry---predicting who made a given set of moves---indicating that they capture human decision-making at an individual level. Our work demonstrates a way to bring AI systems into better alignment with the behavior of individual people, which could lead to large improvements in human-AI interaction.|能够模拟人类行为的AI系统正变得日益重要，这类系统适用于人类向其学习、与其协作或长期作为合作伙伴等场景。为开发以人类为中心的AI系统，预测人类行为（而非最优行为）的问题已受到广泛关注。现有研究主要聚焦于从整体层面捕捉人类行为模式，这可能限制了个体从与系统互动中获得的收益。我们通过构建高精度的国际象棋个人行为预测模型拓展了这一研究方向。国际象棋是探索人机交互的绝佳领域，因其兼具以下特性：多年前AI系统就已实现超人类水平的表现，但人类仍以对手和训练工具的形式与之密切互动，且存在海量的个人棋局数据记录。基于开源人类棋手训练版AlphaZero——Maia系统，我们通过应用系列微调方法，显著提升了对特定棋手行棋预测的准确率。此外，个性化模型可实现笔迹鉴定式预测（通过棋路风格识别对应棋手），这表明模型能在个体层面捕捉人类决策特征。本研究展示了使AI系统更好契合个体行为特征的技术路径，有望显著提升人机交互体验。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Models+of+Individual+Behavior+in+Chess)|0|
|[Nonlinearity Encoding for Extrapolation of Neural Networks](https://doi.org/10.1145/3534678.3539326)|Gyoung S. Na, Chanyoung Park|Korea Adv Inst Sci & Technol, Seoul, South Korea; Korea Res Inst Chem Technol, Seoul, South Korea|Extrapolation to predict unseen data outside the training distribution is a common challenge in real-world scientific applications of physics and chemistry. However, the extrapolation capabilities of neural networks have not been extensively studied in machine learning. Although it has been recently revealed that neural networks become linear regression in extrapolation problems, a universally applicable method to support the extrapolation of neural networks in general regression settings has not been investigated. In this paper, we propose automated nonlinearity encoder (ANE) that is a data-agnostic embedding method to improve the extrapolation capabilities of neural networks by conversely linearizing the original input-to-target relationships without architectural modifications of prediction models. ANE achieved state-of-the-art extrapolation accuracies in extensive scientific applications of various data formats. As a real-world application, we applied ANE for high-throughput screening to discover novel solar cell materials, and ANE significantly improved the screening accuracy.|预测训练分布之外未见数据的泛化能力，是物理化学实际科学应用中的常见挑战。然而神经网络的外推性能在机器学习领域尚未得到系统研究。尽管近期研究表明神经网络在外推问题中会退化为线性回归，但尚未有普适性方法支持一般回归场景中神经网络的外推性能。本文提出自动化非线性编码器（ANE）——一种与数据无关的嵌入方法，通过逆向线性化原始输入与目标的关系，在不改变预测模型架构的前提下提升神经网络的外推能力。ANE在多种数据格式的科学应用中取得了最先进的外推精度。作为实际应用案例，我们将ANE用于高通量筛选新型太阳能电池材料，显著提升了筛选准确率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Nonlinearity+Encoding+for+Extrapolation+of+Neural+Networks)|0|
|[Neural Bandit with Arm Group Graph](https://doi.org/10.1145/3534678.3539312)|Yunzhe Qi, Yikun Ban, Jingrui He|Univ Illinois, Champaign, IL 61820 USA|Contextual bandits aim to identify among a set of arms the optimal one with the highest reward based on their contextual information. Motivated by the fact that the arms usually exhibit group behaviors and the mutual impacts exist among groups, we introduce a new model, Arm Group Graph (AGG), where the nodes represent the groups of arms and the weighted edges formulate the correlations among groups. To leverage the rich information in AGG, we propose a bandit algorithm, AGG-UCB, where the neural networks are designed to estimate rewards, and we propose to utilize graph neural networks (GNN) to learn the representations of arm groups with correlations. To solve the exploitation-exploration dilemma in bandits, we derive a new upper confidence bound (UCB) built on neural networks (exploitation) for exploration. Furthermore, we prove that AGG-UCB can achieve a near-optimal regret bound with over-parameterized neural networks, and provide the convergence analysis of GNN with fully-connected layers which may be of independent interest. In the end, we conduct extensive experiments against state-of-the-art baselines on multiple public data sets, showing the effectiveness of the proposed algorithm.|情境赌博机旨在根据一组臂（选项）的情境信息，从中识别出具有最高奖励的最优臂。受现实中臂通常呈现群体行为且群体间存在相互影响的启发，我们提出了一种新模型——臂群图（AGG），其中节点代表臂的群体，加权边构建群体间的关联关系。为充分利用AGG中的丰富信息，我们提出一种赌博机算法AGG-UCB：通过设计神经网络来估计奖励，并利用图神经网络（GNN）学习具有关联性的臂群表征。针对赌博机中的"利用-探索"困境，我们推导出基于神经网络（利用）的新上置信界（UCB）进行探索。此外，我们证明当神经网络过参数化时，AGG-UCB能够实现近乎最优的遗憾界，同时提供了全连接层GNN的收敛性分析（该分析本身具有独立价值）。最后通过在多个公共数据集上与最先进基线方法的对比实验，验证了所提算法的有效性。

（注：本翻译严格遵循技术文献规范，对关键术语如"contextual bandits"译为"情境赌博机"、"graph neural networks"译为"图神经网络"等保持学术一致性，同时采用中文科技论文常用的四字结构与逻辑连接词，如"受...启发"、"针对...困境"等，确保专业性与可读性的平衡。长难句按中文习惯拆分，并补充"（该分析本身具有独立价值）"等解释性内容以符合中文学术表述惯例。）|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neural+Bandit+with+Arm+Group+Graph)|0|
|[Importance Prioritized Policy Distillation](https://doi.org/10.1145/3534678.3539266)|Xinghua Qu, Yew Soon Ong, Abhishek Gupta, Pengfei Wei, Zhu Sun, Zejun Ma|Nanyang Technol Univ, A STAR, Ctr Frontier AI Res, Singapore, Singapore; ASTAR, Inst High Performance Comp & Ctr Frontier AI Res, Singapore, Singapore; Bytedance AI Lab, Speech & Audio Team, Singapore, Singapore; Singapore Inst Mfg Technol, Singapore, Singapore|Policy distillation (PD) has been widely studied in deep reinforcement learning (RL), while existing PD approaches assume that the demonstration data (i.e., state-action pairs in frames) in a decision making sequence is uniformly distributed. This may bring in unwanted bias since RL is a reward maximizing process instead of simple label matching. Given such an issue, we denote the frame importance as its contribution to the expected reward on a particular frame, and hypothesize that adapting such frame importance could benefit the performance of the distilled student policy. To verify our hypothesis, we analyze why and how frame importance matters in RL settings. Based on the analysis, we propose an importance prioritized PD framework that highlights the training on important frames, so as to learn efficiently. Particularly, the frame importance is measured by the reciprocal of weighted Shannon entropy from a teacher policy's action prescriptions. Experiments on Atari games and policy compression tasks show that capturing the frame importance significantly boosts the performance of the distilled policies.|策略蒸馏（PD）在深度强化学习（RL）领域已被广泛研究，但现有方法通常假设决策序列中的演示数据（即帧中的状态-动作对）呈均匀分布。这种假设可能引入偏差，因为强化学习本质是奖励最大化过程而非简单的标签匹配。针对该问题，我们将帧重要性定义为其对特定帧预期奖励的贡献度，并提出假设：适配帧重要性可提升被蒸馏学生策略的性能。为验证该假设，我们分析了帧重要性在强化学习环境中产生影响的机理，并基于此提出重要性优先的策略蒸馏框架，通过突出重要帧的训练实现高效学习。具体而言，帧重要性通过教师策略动作分布的加权香农熵倒数进行量化。在Atari游戏和策略压缩任务上的实验表明，捕捉帧重要性能够显著提升蒸馏策略的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Importance+Prioritized+Policy+Distillation)|0|
|[DICE: Domain-attack Invariant Causal Learning for Improved Data Privacy Protection and Adversarial Robustness](https://doi.org/10.1145/3534678.3539242)|Qibing Ren, Yiting Chen, Yichuan Mo, Qitian Wu, Junchi Yan|Shanghai Jiao Tong Univ, Shanghai, Peoples R China|The adversarial attack reveals the vulnerability of deep models by incurring test domain shift, while delusive attack relieves the privacy concern about personal data by injecting malicious noise into the training domain to make data unexploitable. However, beyond their successful applications, the two attacks can be easily defended by adversarial training (AT). While AT is not the panacea, it suffers from poor generalization for robustness. For the limitations of attack and defense, we argue that to fit data well, DNNs can learn the spurious relations between inputs and outputs, which are consequently utilized by the attack and defense and degrade their effectiveness, and DNNs can not easily capture the causal relations like humans to make robust decisions under attacks. In this paper, to better understand and improve attack and defense, we first take a bottom-up perspective to describe the correlations between latent factors and observed data, then analyze the effect of domain shift on DNNs induced by attack and finally develop our causal graph, namely Domain-attack Invariant Causal Model (DICM). Based on DICM, we propose a coherent causal invariant principle, which guides our algorithm design to infer the human-like causal relations. We call our algorithm Domain-attack Invariant Causal Learning (DICE) and the experimental results on two attacks and one defense task verify its effectiveness.|对抗性攻击通过引发测试域偏移揭示深度模型的脆弱性，而欺骗性攻击则通过向训练域注入恶意噪声使数据无法被利用，从而缓解个人隐私担忧。然而这两种攻击虽成功应用，却极易被对抗训练（AT）所防御。但对抗训练并非万能良方，其存在鲁棒性泛化能力不足的缺陷。针对攻击与防御的局限性，我们认为深度神经网络为更好地拟合数据，可能学习到输入与输出间的伪相关关系——这些伪关系被攻击与防御机制利用后反而会削弱其有效性，且深度神经网络难以像人类那样捕捉因果关系以在攻击下做出鲁棒决策。本文为深入理解并改进攻击与防御机制，首先采用自下而上的视角描述潜在因子与观测数据间的关联，进而分析攻击引发的域偏移对深度神经网络的影响，最终构建出域攻击不变因果模型（DICM）这一因果图。基于DICM，我们提出连贯的因果不变性原则指导算法设计，以推断类人因果关系的域攻击不变因果学习（DICE）算法。在两种攻击和一项防御任务上的实验结果验证了该算法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DICE:+Domain-attack+Invariant+Causal+Learning+for+Improved+Data+Privacy+Protection+and+Adversarial+Robustness)|0|
|[Balancing Bias and Variance for Active Weakly Supervised Learning](https://doi.org/10.1145/3534678.3539264)|Hitesh Sapkota, Qi Yu|Rochester Inst Technol, Rochester, NY 14623 USA|As a widely used weakly supervised learning scheme, modern multiple instance learning (MIL) models achieve competitive performance at the bag level. However, instance-level prediction, which is essential for many important applications, remains largely unsatisfactory. We propose to conduct novel active deep multiple instance learning that samples a small subset of informative instances for annotation, aiming to significantly boost the instance-level prediction. A variance regularized loss function is designed to properly balance the bias and variance of instance-level predictions, aiming to effectively accommodate the highly imbalanced instance distribution in MIL and other fundamental challenges. Instead of directly minimizing the variance regularized loss that is non-convex, we optimize a distributionally robust bag level likelihood as its convex surrogate. The robust bag likelihood provides a good approximation of the variance based MIL loss with a strong theoretical guarantee. It also automatically balances bias and variance, making it effective to identify the potentially positive instances to support active sampling. The robust bag likelihood can be naturally integrated with a deep architecture to support deep model training using mini-batches of positive-negative bag pairs. Finally, a novel P-F sampling function is developed that combines a probability vector and predicted instance scores, obtained by optimizing the robust bag likelihood. By leveraging the key MIL assumption, the sampling function can explore the most challenging bags and effectively detect their positive instances for annotation, which significantly improves the instance-level prediction. Experiments conducted over multiple real-world datasets clearly demonstrate the state-of-the-art instance-level prediction achieved by the proposed model.|作为一项广泛应用的弱监督学习方案，现代多示例学习（MIL）模型在包级别已实现优异性能。然而对于许多关键应用至关重要的实例级预测，其表现仍不尽如人意。我们提出一种新型主动深度多示例学习方法，通过采样少量信息丰富的实例进行标注，旨在显著提升实例级预测性能。本研究设计了一种方差正则化损失函数，通过合理平衡实例级预测的偏差与方差，有效应对MIL中高度不平衡的实例分布及其他基础性挑战。针对该非凸的方差正则化损失函数，我们通过优化分布鲁棒的包级别似然函数作为其凸替代目标。该鲁棒包似然函数在强理论保证下可有效近似基于方差的MIL损失，同时自动平衡偏差与方差，从而有效识别潜在正实例以支持主动采样。该鲁棒包似然可自然融入深度架构，支持使用正负包对的小批量数据进行深度模型训练。此外，通过结合概率向量与鲁棒包似然优化得到的实例预测分数，我们开发了新型P-F采样函数。该方法利用MIL的核心假设，能够探索最具挑战性的包并有效检测其中待标注的正实例，从而显著提升实例级预测精度。在多个真实数据集上的实验结果表明，所提出模型实现了当前最先进的实例级预测性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Balancing+Bias+and+Variance+for+Active+Weakly+Supervised+Learning)|0|
|[Learning Optimal Priors for Task-Invariant Representations in Variational Autoencoders](https://doi.org/10.1145/3534678.3539291)|Hiroshi Takahashi, Tomoharu Iwata, Atsutoshi Kumagai, Sekitoshi Kanai, Masanori Yamada, Yuki Yamanaka, Hisashi Kashima|NTT, Nairobi, Kenya; Kyoto Univ, Kyoto, Japan|The variational autoencoder (VAE) is a powerful latent variable model for unsupervised representation learning. However, it does not work well in case of insufficient data points. To improve the performance in such situations, the conditional VAE (CVAE) is widely used, which aims to share task-invariant knowledge with multiple tasks through the task-invariant latent variable. In the CVAE, the posterior of the latent variable given the data point and task is regularized by the task-invariant prior, which is modeled by the standard Gaussian distribution. Although this regularization encourages independence between the latent variable and task, the latent variable remains dependent on the task. To reduce this task-dependency, the previous work introduced an additional regularizer. However, its learned representation does not work well on the target tasks. In this study, we theoretically investigate why the CVAE cannot sufficiently reduce the task-dependency and show that the simple standard Gaussian prior is one of the causes. Based on this, we propose a theoretical optimal prior for reducing the task-dependency. In addition, we theoretically show that unlike the previous work, our learned representation works well on the target tasks. Experiments on various datasets show that our approach obtains better task-invariant representations, which improves the performances of various downstream applications such as density estimation and classification.|变分自编码器（VAE）是一种强大的潜在变量模型，可用于无监督表示学习。但在数据点不足的情况下，其性能表现不佳。为改善这一局限，条件变分自编码器（CVAE）被广泛采用，其通过任务无关潜在变量实现多任务间的知识共享。在CVAE框架中，基于数据点和任务给出的潜在变量后验分布会受到任务无关先验分布（以标准高斯分布建模）的正则化约束。尽管这种正则化促进了潜在变量与任务间的独立性，但潜在变量仍会保留对任务的依赖性。为降低这种任务依赖性，先前研究引入了额外的正则化项，但所学表征在目标任务上表现仍不理想。本研究从理论角度揭示了CVAE无法充分降低任务依赖性的原因，并证明简单的标准高斯先验是成因之一。基于此，我们提出了理论最优先验分布以降低任务依赖性。此外，我们通过理论证明：与先前工作不同，本方法所学表征在目标任务上表现优异。在多数据集上的实验表明，我们的方法能获得更优的任务无关表征，从而提升密度估计和分类等下游应用的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Optimal+Priors+for+Task-Invariant+Representations+in+Variational+Autoencoders)|0|
|[Aligning Dual Disentangled User Representations from Ratings and Textual Content](https://doi.org/10.1145/3534678.3539474)|NhuThuat Tran, Hady W. Lauw|Singapore Management Univ, Singapore, Singapore|Classical recommendation methods typically render user representation as a single vector in latent space. Oftentimes, a user's interactions with items are influenced by several hidden factors. To better uncover these hidden factors, we seek disentangled representations. Existing disentanglement methods for recommendations are mainly concerned with user-item interactions alone. To further improve not only the effectiveness of recommendations but also the interpretability of the representations, we propose to learn a second set of disentangled user representations from textual content and to align the two sets of representations with one another. The purpose of this coupling is two-fold. For one benefit, we leverage textual content to resolve sparsity of user-item interactions, leading to higher recommendation accuracy. For another benefit, by regularizing factors learned from user-item interactions with factors learned from textual content, we map uninterpretable dimensions from user representation into words. An attention-based alignment is introduced to align and enrich hidden factors representations. A series of experiments conducted on four real-world datasets show the efficacy of our methods in improving recommendation quality.|传统推荐方法通常将用户表征呈现为潜在空间中的单一向量。由于用户与项目的交互行为往往受到多个潜在因素的影响，为了更好地揭示这些隐藏因素，我们寻求解耦式表征学习。现有推荐系统中的解耦方法主要仅关注用户-项目交互行为。为了进一步提升推荐效果并增强表征的可解释性，我们提出从文本内容中学习第二组解耦式用户表征，并将两组表征进行对齐。这种耦合设计具有双重优势：一方面，利用文本内容缓解用户-项目交互的稀疏性问题，从而提高推荐准确率；另一方面，通过将交互数据学习的因子与文本内容学习的因子进行正则化对齐，我们将用户表征中难以解释的维度映射到可理解的词汇空间。本文引入基于注意力机制的对齐方法来实现隐藏因子表征的对齐与增强。在四个真实数据集上进行的一系列实验证明了我们方法在提升推荐质量方面的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Aligning+Dual+Disentangled+User+Representations+from+Ratings+and+Textual+Content)|0|
|[Estimating Individualized Causal Effect with Confounded Instruments](https://doi.org/10.1145/3534678.3539335)|Haotian Wang, Wenjing Yang, Longqi Yang, Anpeng Wu, Liyang Xu, Jing Ren, Fei Wu, Kun Kuang|Zhejiang Univ, Inst Artificial Intelligence, Hangzhou, Peoples R China; Natl Univ Def Technol, Inst Quantum Informat, Singapore, Singapore|Learning individualized causal effect (ICE) plays a vital role in various fields of big data analysis, ranging from fine-grained policy evaluation to personalized treatment development. However, the presence of unmeasured confounders increases the difficulty of estimating ICE in real-world scenarios. A wide range of methods have been proposed to address the unmeasured confounders with the aid of instrument variable (IV), which sources from the treatment randomization. The performance of these methods relies on the well-predefined IVs that satisfy the unconfounded instruments assumption (i.e., the IVs are independent with the unmeasured confounders given observed covariates), which is untestable and leads to finding a valid IV becomes an art rather than science. In this paper, we focus on estimating the ICE with confounded instruments that violate the unconfounded instruments assumption. By considering the conditional independence between the set of confounded instruments and the outcome variable, we propose a novel method, named CVAE-IV, to generate a substitute of the unmeasured confounder with a conditional variational autoencoder. Our theoretical analysis guarantees that the generated confounder substitute will identify unbiased ICE. Extensive experiments on bias demand prediction and Mendelian randomization analysis verify the effectiveness of our method.|学习个体化因果效应（ICE）在大数据分析的诸多领域具有至关重要的作用，从精细化政策评估到个性化治疗方案制定皆涵盖其中。然而在实际场景中，未测量混杂因子的存在增加了ICE估计的难度。现有研究多借助源自处理随机化的工具变量（IV）来解决未测量混杂因子问题，这些方法的性能依赖于满足"无混杂工具变量假设"（即给定观测协变量后IV与未测量混杂因子独立）的预定义IV。由于该假设不可检验，导致寻找有效IV的过程更像艺术而非科学。本文重点研究违反无混杂工具变量假设的混杂工具变量下的ICE估计问题。通过考虑混杂工具变量集与结果变量间的条件独立性，我们提出名为CVAE-IV的新方法，利用条件变分自编码器生成未测量混杂因子的替代变量。理论分析证明生成的混杂因子替代变量能够识别无偏ICE。在偏置需求预测和孟德尔随机化分析上的大量实验验证了本方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Estimating+Individualized+Causal+Effect+with+Confounded+Instruments)|0|
|[Streaming Graph Neural Networks with Generative Replay](https://doi.org/10.1145/3534678.3539336)|Junshan Wang, Wenhao Zhu, Guojie Song, Liang Wang|Alibaba Grp, Beijing, Peoples R China; Peking Univ, Key Lab Machine Percept, Minist Educ, Sch AI, Beijing, Peoples R China|Training Graph Neural Networks (GNNs) incrementally is a particularly urgent problem, because real-world graph data usually arrives in a streaming fashion, and inefficiently updating of the models results in out-of-date embeddings, thus degrade its performance in downstream tasks. Traditional incremental learning methods will gradually forget old knowledge when learning new patterns, which is the catastrophic forgetting problem. Although saving and revisiting historical graph data alleviates the problem, the storage limitation in real-world applications reduces the amount of saved data, causing GNN to forget other knowledge. In this paper, we propose a streaming GNN based on generative replay, which can incrementally learn new patterns while maintaining existing knowledge without accessing historical data. Specifically, our model consists of the main model (GNN) and an auxiliary generative model. The generative model based on random walks with restart can learn and generate fake historical samples (i.e., nodes and their neighborhoods), which can be trained with real data to avoid the forgetting problem. Besides, we also design an incremental update algorithm for the generative model to maintain the graph distribution and for GNN to capture the current patterns. Our model is evaluated on different streaming data sets. The node classification results prove that our model can update the model efficiently and achieve comparable performance to model retraining. Code is available at https://github.com/Junshan-Wang/SGNN-GR.|图神经网络（GNN）的增量训练是一个亟待解决的问题，因为现实世界中的图数据通常以流式形式持续到达，低效的模型更新会导致嵌入表示过时，从而影响下游任务性能。传统增量学习方法在学习新模式时会逐渐遗忘旧知识，即出现灾难性遗忘问题。虽然保存和重访历史图数据能缓解该问题，但实际应用中的存储限制会减少可保存数据量，导致GNN遗忘其他知识。本文提出一种基于生成式回放的流式图神经网络，能够在无需访问历史数据的情况下，既学习新模式又保持现有知识。具体而言，我们的模型由主模型（GNN）和辅助生成模型构成：基于重启随机游走的生成模型可学习并生成伪历史样本（即节点及其邻域），通过与真实数据联合训练来避免遗忘问题；此外，我们还设计了生成模型的增量更新算法以维持图分布特性，并帮助GNN捕获当前数据模式。通过在多个流式数据集上的实验验证，节点分类结果表明我们的模型能实现高效更新，其性能可与完全重新训练的模型相媲美。代码已开源：https://github.com/Junshan-Wang/SGNN-GR。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Streaming+Graph+Neural+Networks+with+Generative+Replay)|0|
|[Domain Adaptation with Dynamic Open-Set Targets](https://doi.org/10.1145/3534678.3539235)|Jun Wu, Jingrui He|Univ Illinois, Champaign, IL 61820 USA|Open-set domain adaptation aims to improve the generalization performance of a learning algorithm on a target task of interest by leveraging the label information from a relevant source task with only a subset of classes. However, most existing works are designed for the static setting, and can be hardly extended to the dynamic setting commonly seen in many real-world applications. In this paper, we focus on the more realistic open-set domain adaptation setting with a static source task and a time evolving target task where novel unknown target classes appear over time. Specifically, we show that the classification error of the new target task can be tightly bounded in terms of positive-unlabeled classification errors for historical tasks and open-set domain discrepancy across tasks. By empirically minimizing the upper bound of the target error, we propose a novel positive-unlabeled learning based algorithm named OuterAdapter for dynamic open-set domain adaptation with time evolving unknown classes. Extensive experiments on various data sets demonstrate the effectiveness and efficiency of our proposed OuterAdapter algorithm over state-of-the-art domain adaptation baselines.|开放集域自适应旨在利用仅包含部分类别的相关源任务标签信息，提升学习算法在目标感兴趣任务上的泛化性能。然而现有方法大多针对静态场景设计，难以扩展至现实应用中常见的动态场景。本文聚焦于更具现实意义的开放集域自适应场景：源任务保持静态，而目标任务随时间动态演化，其中未知目标类别会随时间不断涌现。我们通过理论证明表明，新目标任务的分类误差可由历史任务的正-无标记分类误差及跨任务开放集域差异项构成紧致上界。通过对该误差上界进行经验性最小化，我们提出基于正-无标记学习的新型算法OuterAdapter，用于处理具有时序演化未知类别的动态开放集域自适应问题。在多组数据集上的大量实验表明，相较于最先进的域自适应基线方法，我们提出的OuterAdapter算法具有显著优越的性能与效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Domain+Adaptation+with+Dynamic+Open-Set+Targets)|0|
|[Non-stationary A/B Tests](https://doi.org/10.1145/3534678.3539325)|Yuhang Wu, Zeyu Zheng, Guangyu Zhang, Zuohua Zhang, Chu Wang|Univ Calif Berkeley, Berkeley, CA 94720 USA; Amazon, Seattle, WA USA|A/B tests, also known as online controlled experiments, have been used at scale by data-driven enterprises to guide decisions and test innovative ideas. Meanwhile, nonstationarity, such as the time-of-day effect, can commonly arise in various business metrics. We show that inadequately addressing nonstationarity can cause A/B tests to be statistically inefficient or invalid, leading to wrong conclusions. To address these issues, we develop a new framework that provides appropriate modeling and adequate statistical analysis for nonstationary A/B tests. Without changing the infrastructure for any existing A/B test procedure, we propose a new estimator that views time as a continuous covariate to perform post stratification with a sample-dependent number of stratification levels. We prove central limit theorem in a natural limiting regime under nonstationarity, so that valid large-sample statistical inference is available. We show that the proposed estimator achieves the optimal asymptotic variance among all estimators. When the experiment design phase of an A/B test allows, we propose a new time-grouped randomization approach to make a better balance on treatment and control assignments in presence of time nonstationarity. A brief account of numerical experiments are conducted to illustrate the theoretical analysis.|A/B测试（亦称在线对照实验）已被数据驱动型企业大规模应用于决策指导与创新理念验证。然而，各类业务指标中普遍存在非稳态现象（如时段效应）。本研究证明，若未能妥善处理非稳态问题，将导致A/B测试统计效率低下或结论无效，进而产生错误推断。针对该问题，我们开发了一种新型分析框架，为非稳态A/B测试提供适配的建模方法与完备的统计分析方法。在不改变现有A/B测试基础设施的前提下，提出将时间作为连续协变量的新型估计量，通过样本依赖的分层级数进行事后分层。我们在非稳态条件下证明了自然极限状态下的中心极限定理，从而确保有效的大样本统计推断。研究结果表明，该估计量在所有估计量中达到了最优渐近方差。当A/B测试允许调整实验设计阶段时，我们提出新型时间分组随机化方法，以在时间非稳态条件下实现处理组与对照组的更优平衡。通过数值实验简要验证了理论分析的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Non-stationary+A/B+Tests)|0|
|[Enhancing Machine Learning Approaches for Graph Optimization Problems with Diversifying Graph Augmentation](https://doi.org/10.1145/3534678.3539437)|ChenHsu Yang, ChihYa Shen|Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu, Taiwan|Recently, many machine learning-based approaches that effectively solve graph optimization problems have been proposed. These approaches are usually trained on graphs randomly generated with graph generators or sampled from existing datasets. However, we observe that such training graphs lead to poor testing performance if the testing graphs are not generated analogously, i.e., the generalibility of the models trained on those randomly generated training graphs are very limited. To address this critical issue, in this paper, we propose a new framework, named Learning with Iterative Graph Diversification (LIGD), and formulate a new research problem, named Diverse Graph Modification Problem (DGMP), that iteratively generate diversified training graphs and train the models that solve graph optimization problems to significantly improve their performance. We propose three approaches to solve DGMP by considering both the performance of the machine-learning approaches and the structural properties of the training graphs. Experimental results on well-known problems show that our proposed approaches significantly boost the performance of both supervised and reinforcement learning approaches and produce near-optimal results, significantly outperforming the baseline approaches, such as graph augmentation and deep learning-based graph generation approaches.|近期，大量基于机器学习的图优化问题高效求解方法被提出。这类方法通常在通过图生成器随机生成或从现有数据集中采样的图结构上进行训练。但我们发现，若测试图的生成方式与训练图不同，此类训练图会导致模型测试性能显著下降——即基于随机生成训练图所训练模型的泛化能力具有明显局限性。针对这一关键问题，本文提出名为"迭代式图多样化学习"（LIGD）的新框架，并构建了称为"多样化图修改问题"（DGMP）的新研究课题，通过迭代生成多样化训练图来训练解决图优化问题的模型，从而显著提升模型性能。我们提出三种求解DGMP的方法，这些方法同时考虑了机器学习模型的性能表现与训练图的结构特性。在经典问题上的实验结果表明：我们所提出的方法显著提升了监督学习与强化学习方法的性能，获得了接近最优解的结果，其表现明显优于图数据增强和基于深度学习的图生成等基线方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Machine+Learning+Approaches+for+Graph+Optimization+Problems+with+Diversifying+Graph+Augmentation)|0|
|[Learning Classifiers under Delayed Feedback with a Time Window Assumption](https://doi.org/10.1145/3534678.3539372)|Shota Yasui, Masahiro Kato||We consider training a binary classifier under delayed feedback (\emph{DF learning}). For example, in the conversion prediction in online ads, we initially receive negative samples that clicked the ads but did not buy an item; subsequently, some samples among them buy an item then change to positive. In the setting of DF learning, we observe samples over time, then learn a classifier at some point. We initially receive negative samples; subsequently, some samples among them change to positive. This problem is conceivable in various real-world applications such as online advertisements, where the user action takes place long after the first click. Owing to the delayed feedback, naive classification of the positive and negative samples returns a biased classifier. One solution is to use samples that have been observed for more than a certain time window assuming these samples are correctly labeled. However, existing studies reported that simply using a subset of all samples based on the time window assumption does not perform well, and that using all samples along with the time window assumption improves empirical performance. We extend these existing studies and propose a method with the unbiased and convex empirical risk that is constructed from all samples under the time window assumption. To demonstrate the soundness of the proposed method, we provide experimental results on a synthetic and open dataset that is the real traffic log datasets in online advertising.|我们研究在延迟反馈（\emph{DF学习}）场景下的二分类器训练问题。以在线广告转化预测为例：初始阶段我们获得的是点击广告但未购买商品的负样本；后续其中部分样本会产生购买行为并转为正样本。在DF学习框架中，我们随时间推移持续观测样本，并在特定时间点构建分类器。这种设置普遍存在于在线广告等现实应用场景中，用户行为往往在首次点击后很长时间才发生。

由于延迟反馈的存在，直接对正负样本进行分类会导致分类器产生偏差。现有解决方案之一是采用时间窗口假设，即仅使用观察时长超过特定阈值的样本（假定这些样本已被正确标记）。然而研究表明，单纯基于时间窗口假设使用样本子集效果有限，而结合时间窗口假设使用全量样本能提升模型性能。

我们在此基础上提出创新方法：在时间窗口假设下，利用全量样本构建无偏且凸的经验风险函数。为验证方法的有效性，我们分别在合成数据集和开放数据集（真实在线广告流量日志）上进行了实验验证。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Classifiers+under+Delayed+Feedback+with+a+Time+Window+Assumption)|0|
|[Intrinsic-Motivated Sensor Management: Exploring with Physical Surprise](https://doi.org/10.1145/3534678.3539230)|Jingyi Yuan, Yang Weng, Erik Blasch|Air Force Res Lab, Arlington, VA USA; Arizona State Univ, Tempe, AZ 85281 USA|In modern complex physical systems, advanced sensing technologies extend the sensor coverage but also increase the difficulties of improving system monitoring capabilities based on real-time data availability. Traditional model-based methods of sensor management are limited to specific systems/settings, which can be challenged when system knowledge is intractable. Fortunately, the large amount of data collected in real-time allows machine learning methods to be a complement. Especially, reinforcement learning-based control is recognized for its capability to dynamically interact with systems. However, the direct implementation of learning methods easily overfits and results in inaccurate physics modeling for sensor management. Although physical regularization is a popular direction to bridge the gap, learning-based sensor control still suffers from convergence failure under highly complex and uncertain scenarios. This paper develops physics-embedded and self-supervised reinforcement learning for sensor management using an intrinsic reward. Specifically, the intrinsic-motivated sensor management (IMSM) constructs the local surprise information from the physical latent features, which captures hidden states in observations, and thus intrinsically motivates the agent to speed-up exploration. We show that the designs can not only relieve the lack of consistency with underlying physics/physical dynamics, but also adapt the global objective of maximizing monitoring capabilities to local environment changes. We demonstrate its effectiveness by experiments on physical system sensor control. The proposed model is implemented for the sensor management of unmanned vehicles and sensor rescheduling in complex/settled power systems, with or without observability constraints. Numerical results show that our model provides consistently higher threat detection accuracy and better observability recovery, as compared to existing methods.|在现代复杂物理系统中，先进传感技术虽扩展了传感器覆盖范围，但也增加了基于实时数据提升系统监测能力的难度。传统基于模型的传感器管理方法受限于特定系统/场景，当系统知识难以获取时其有效性面临挑战。幸运的是，实时采集的海量数据为机器学习方法提供了补充途径，其中基于强化学习的控制方法因其动态系统交互能力备受关注。然而直接应用学习方法易导致过拟合，造成传感器管理中的物理建模失准。尽管物理正则化是弥合这一差距的热门方向，但在高度复杂和不确定场景下，基于学习的传感器控制仍存在收敛失败问题。本文提出一种嵌入物理机制且具有自监督特性的强化学习方法，通过内在奖励实现传感器管理。具体而言，内在激励传感器管理（IMSM）框架从物理潜在特征中构建局部惊奇信息，这些特征可捕捉观测中的隐藏状态，从而通过内在激励加速智能体的探索过程。我们证明该设计不仅能缓解与底层物理/物理动力学的一致性缺失问题，还能使最大化监测能力的全局目标适配局部环境变化。通过物理系统传感器控制实验验证了方法的有效性：将所提模型应用于无人驾驶车辆传感器管理及复杂/稳定电力系统中的传感器重调度任务，涵盖可观测性与不可观测性约束场景。数值结果表明，相较于现有方法，本模型持续提供更高的威胁检测精度和更优的可观测性恢复能力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Intrinsic-Motivated+Sensor+Management:+Exploring+with+Physical+Surprise)|0|
|[Dual Bidirectional Graph Convolutional Networks for Zero-shot Node Classification](https://doi.org/10.1145/3534678.3539316)|Qin Yue, Jiye Liang, Junbiao Cui, Liang Bai|Shanxi Univ, Sch Comp & Informat Technol, Taiyuan, Peoples R China|Zero-shot node classification is a very important challenge for classical semi-supervised node classification algorithms, such as Graph Convolutional Network (GCN) which has been widely applied to node classification. In order to predict the unlabeled nodes from unseen classes, zero-shot node classification needs to transfer knowledge from seen classes to unseen classes. It is crucial to consider the relations between the classes in zero-shot node classification. However, the GCN only considers the relations between the nodes, not the relations between the classes. Therefore, the GCN can not handle the zero-shot node classification effectively. This paper proposes a Dual Bidirectional Graph Convolutional Networks (DBiGCN) that consists of dual BiGCNs from the perspective of the nodes and the classes, respectively. The BiGCN can integrate the relations between the nodes and between the classes simultaneously in an united network. In addition, to make the dual BiGCNs work collaboratively, a label consistency loss is introduced, which can achieve mutual guidance and mutual improvement between the dual BiGCNs. Finally, the experimental results on real-world graph data sets verify the effectiveness of the proposed method.|零样本节点分类对图卷积网络(GCN)等经典半监督节点分类算法构成重要挑战，尽管GCN已在节点分类领域获得广泛应用。为预测未知类别中的未标记节点，零样本节点分类需要实现从已知类别到未知类别的知识迁移。在此过程中，准确捕捉类别间关联至关重要。然而传统GCN仅考虑节点间关系而忽略类别间关联，导致其难以有效处理零样本节点分类任务。本文提出双双向图卷积网络(DBiGCN)，通过分别从节点视角和类别视角构建的双BiGCN结构，在统一网络中同步整合节点间与类别间关联。此外，通过引入标签一致性损失函数实现双BiGCN的协同工作机制，形成双向引导与共同优化的学习范式。最终在真实图数据集上的实验结果验证了所提方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual+Bidirectional+Graph+Convolutional+Networks+for+Zero-shot+Node+Classification)|0|
|[Physics-infused Machine Learning for Crowd Simulation](https://doi.org/10.1145/3534678.3539440)|Guozhen Zhang, Zihan Yu, Depeng Jin, Yong Li|Tsinghua Univ, Dept Elect Engn, Beijing, Peoples R China|Crowd simulation acts as the basic component in traffic management, urban planning, and emergency management. Most existing approaches use physics-based models due to their robustness and strong generalizability, yet they fall short in fidelity since human behaviors are too complex and heterogeneous for a universal physical model to describe. Recent research tries to solve this problem by deep learning methods. However, they are still unable to generalize well beyond training distributions. In this work, we propose to jointly leverage the strength of the physical and neural network models for crowd simulation by a Physics-Infused Machine Learning (PIML) framework. The key idea is to let the two models learn from each other by iteratively going through a physics-informed machine learning process and a machine-learning-aided physics discovery process. We present our realization of the framework with a novel neural network model, Physics-informed Crowd Simulator (PCS), and tailored interaction mechanisms enabling the two models to facilitate each other. Specifically, our designs enable the neural network model to identify generalizable signals from real-world data better and yield physically consistent simulations with the physical model's form and simulation results as a prior. Further, by performing symbolic regression on the well-trained neural network, we obtain improved physical models that better describe crowd dynamics. Extensive experiments on two publicly available large-scale real-world datasets show that, with the framework, we successfully obtain a neural network model with strong generalizability and a new physical model with valid physical meanings at the same time. Both models outperform existing state-of-the-art simulation methods in accuracy, fidelity, and generalizability, which demonstrates the effectiveness of the PIML framework for improving simulation performance and its capability for facilitating scientific discovery and deepening our understandings of crowd dynamics. We release the codes at https://github.com/tsinghua-fib-lab/PIML.|人群模拟是交通管理、城市规划与应急管理的基础组成部分。现有方法多采用基于物理学的模型，因其鲁棒性强且泛化能力优异，但由于人类行为过于复杂和异质，单一物理模型难以准确描述，导致仿真保真度不足。近期研究尝试通过深度学习方法解决此问题，但这些方法在训练分布之外仍缺乏良好的泛化能力。本研究提出通过物理信息机器学习（PIML）框架，协同融合物理模型与神经网络模型的优势。核心思想是通过物理信息机器学习过程与机器学习辅助的物理发现过程的迭代循环，实现两种模型的相互学习。我们通过新型神经网络模型——物理信息人群模拟器（PCS）以及定制化的交互机制实现了该框架，使两种模型能够相互促进。具体而言，我们的设计使神经网络能够更好地从真实数据中识别可泛化信号，并以物理模型的形式和仿真结果为先验，生成物理一致性更高的模拟结果。此外，通过对训练完善的神经网络进行符号回归，我们获得了能更好描述人群动力学特性的改进物理模型。在两个公开大规模真实数据集上的实验表明：通过该框架，我们同步获得了具有强泛化能力的神经网络模型和具备有效物理意义的新物理模型。两种模型在精度、保真度和泛化能力上均优于现有最先进仿真方法，证明了PIML框架在提升仿真性能方面的有效性，及其在促进科学发现、深化人群动力学认知方面的潜力。代码已发布于https://github.com/tsinghua-fib-lab/PIML。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Physics-infused+Machine+Learning+for+Crowd+Simulation)|0|
|[Few-shot Heterogeneous Graph Learning via Cross-domain Knowledge Transfer](https://doi.org/10.1145/3534678.3539431)|Qiannan Zhang, Xiaodong Wu, Qiang Yang, Chuxu Zhang, Xiangliang Zhang|Brandeis Univ, Waltham, MA 02254 USA; King Abdullah Univ Sci & Technol, Thuwal, Saudi Arabia; Univ Notre Dame, Notre Dame, IN 46556 USA|Graph few-shot learning seeks to alleviate the label scarcity problem resulting from the difficulties and high cost of data annotations in graph learning. However, the overwhelming solutions in graph few-shot learning focus on homogeneous graphs, ignoring the ubiquitous heterogeneous graphs (HGs), which represent real-world complex systems and domain knowledge with multi-typed nodes interconnected by multi-typed edges. To this end, we study the cross-domain few-shot learning problem over HGs and develop a novel model for Cross-domain Heterogeneous Graph Meta learning (CrossHG-Meta). The general idea is to promote the HG node classification in the data-scarce target domain by transferring meta-knowledge from a series of HGs in data-rich source domains. The key challenges are to 1) combat the heterogeneity in HGs to acquire the transferable meta-knowledge; 2) handle the domain shifts between the source HG and target HG; and 3) fast adapt to novel target tasks with few-shot annotated examples. Regarding the graph heterogeneity, CrossHG-Meta firstly builds a graph encoder to aggregate heterogeneous neighborhood information from multiple semantic contexts. Secondly, to tackle domain shifts, a cross-domain meta-learning strategy is proposed to include a domain critic, which is designed to explicitly lead cross-domain adaptation for meta-tasks in different domains and improve model generalizability. Last, to further alleviate data scarcity, CrossHG-Meta leverages unlabelled information in source domains with auxiliary self-supervised learning task to provide cross-domain contrastive regularization alongside the meta-optimization process to facilitate node embedding. Extensive experimental results on three multi-domain HG datasets demonstrate that the proposed model outperforms various state-of-the-art baselines for multiple few-shot node classification tasks under the cross-domain setting.|图少样本学习旨在缓解图学习中因数据标注困难和高成本导致的标签稀缺问题。然而，现有图少样本学习方法大多聚焦于同构图，忽略了普遍存在的异构图（HGs）——这种由多类型节点通过多类型边相互连接构成的图结构能更真实地反映现实世界复杂系统和领域知识。为此，我们研究异构图的跨域少样本学习问题，并提出新型跨域异构图元学习模型CrossHG-Meta。该模型核心思想是通过从多个数据丰富的源域异构图中迁移元知识，提升数据稀缺目标域的异构图节点分类性能。研究面临三大关键挑战：1）克服异质性以获取可迁移的元知识；2）处理源域与目标域异构图间的域偏移；3）通过少量标注样本快速适应新目标任务。针对异质性挑战，CrossHG-Meta首先构建图编码器，从多语义上下文中聚合异构邻域信息；其次通过设计域批判器实现跨域元学习策略，显式引导不同域元任务的跨域适配并提升模型泛化能力；最后利用源域未标注信息，通过辅助自监督学习任务提供跨域对比正则化，在元优化过程中增强节点嵌入表示。在三个多域异构图数据集上的实验表明，该模型在跨域设置下的多种少样本节点分类任务中均优于现有先进基线方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Few-shot+Heterogeneous+Graph+Learning+via+Cross-domain+Knowledge+Transfer)|0|
|[Adaptive Learning for Weakly Labeled Streams](https://doi.org/10.1145/3534678.3539351)|ZhenYu Zhang, Yuyang Qian, YuJie Zhang, Yuan Jiang, ZhiHua Zhou|Univ Elect Sci & Technol China, Chengdu, Peoples R China; Kyushu Inst Technol, Kitakyushu, Fukuoka, Japan|The Weakly-Supervised Audio-Visual Video Parsing (AVVP) task aims to parse a video into temporal segments and predict their event categories in terms of modalities, labeling them as either audible, visible, or both. Since the temporal boundaries and modalities annotations are not provided, only video-level event labels are available, this task is more challenging than conventional video understanding tasks.Most previous works attempt to analyze videos by jointly modeling the audio and video data and then learning information from the segment-level features with fixed lengths. However, such a design exist two defects: 1) The various semantic information hidden in temporal lengths is neglected, which may lead the models to learn incorrect information; 2) Due to the joint context modeling, the unique features of different modalities are not fully explored. In this paper, we propose a novel AVVP framework termedDual Hierarchical Hybrid Network (DHHN) to tackle the above two problems. Our DHHN method consists of three components: 1) A hierarchical context modeling network for extracting different semantics in multiple temporal lengths; 2) A modality-wise guiding network for learning unique information from different modalities; 3) A dual-stream framework generating audio and visual predictions separately. It maintains the best adaptions on different modalities, further boosting the video parsing performance. Extensive quantitative and qualitative experiments demonstrate that our proposed method establishes the new state-of-the-art performance on the AVVP task.|弱监督音视频解析(AVVP)任务旨在将视频划分为时间片段，并根据模态预测事件类别，将其标记为可听、可见或两者兼具。由于未提供时间边界和模态标注，仅具备视频级事件标签，该任务比传统视频理解任务更具挑战性。现有方法大多通过联合建模音频与视频数据，从固定长度的片段级特征中学习信息，但此类设计存在两个缺陷：1）忽视了不同时间长度中隐含的多样化语义信息，可能导致模型学习错误信息；2）由于采用联合上下文建模，未能充分挖掘不同模态的独特特征。本文提出新型双层次混合网络(DHHN)框架以解决上述问题。该框架包含三个核心组件：1）分层上下文建模网络，用于提取多时间尺度的差异化语义；2）模态感知引导网络，用于学习不同模态的独特信息；3）双流预测框架，分别生成音频与视觉预测。该设计保持了对不同模态的最佳适应性，显著提升了视频解析性能。大量定量与定性实验表明，本方法在AVVP任务上取得了最先进的性能表现。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adaptive+Learning+for+Weakly+Labeled+Streams)|0|
|[Adaptive Fairness-Aware Online Meta-Learning for Changing Environments](https://doi.org/10.1145/3534678.3539420)|Chen Zhao, Feng Mi, Xintao Wu, Kai Jiang, Latifur Khan, Feng Chen|Univ Texas Dallas, Richardson, TX 75083 USA; Univ Arkansas, Fayetteville, AR 72701 USA|The fairness-aware online learning framework has arisen as a powerful tool for the continual lifelong learning setting. The goal for the learner is to sequentially learn new tasks where they come one after another over time and the learner ensures the statistic parity of the new coming task across different protected sub-populations (e.g. race and gender). A major drawback of existing methods is that they make heavy use of the i.i.d assumption for data and hence provide static regret analysis for the framework. However, low static regret cannot imply a good performance in changing environments where tasks are sampled from heterogeneous distributions. To address the fairness-aware online learning problem in changing environments, in this paper, we first construct a novel regret metric FairSAR by adding long-term fairness constraints onto a strongly adapted loss regret. Furthermore, to determine a good model parameter at each round, we propose a novel adaptive fairness-aware online meta-learning algorithm, namely FairSAOML, which is able to adapt to changing environments in both bias control and model precision. The problem is formulated in the form of a bi-level convex-concave optimization with respect to the model's primal and dual parameters that are associated with the model's accuracy and fairness, respectively. The theoretic analysis provides sub-linear upper bounds for both loss regret and violation of cumulative fairness constraints. Our experimental evaluation on different real-world datasets with settings of changing environments suggests that the proposed FairSAOML significantly outperforms alternatives based on the best prior online learning approaches.|公平感知在线学习框架已成为持续终身学习场景中的强大工具。学习者的目标是按时间顺序依次学习不断出现的新任务，并确保新任务在不同受保护子群体（如种族和性别）间满足统计均等性。现有方法的主要缺陷在于严重依赖数据的独立同分布假设，因此仅能提供该框架的静态遗憾分析。然而在从异质分布中采样任务的变化环境中，低静态遗憾并不能保证良好的性能表现。为解决变化环境中的公平感知在线学习问题，本文首先通过在强适应损失遗憾中施加长期公平约束，构建了新型遗憾度量指标FairSAR。进而为在每轮迭代中确定最优模型参数，我们提出了一种新型自适应公平感知在线元学习算法FairSAOML，该算法能够在偏差控制和模型精度两方面适应变化环境。通过将模型参数分别关联精度与公平性的原对偶变量，该问题被构建为双层凸凹优化形式。理论分析表明，算法在损失遗憾和累计公平约束违反度上均具有次线性上界。在变化环境设置下对多个真实世界数据集的实验评估表明，所提出的FairSAOML算法显著优于基于现有最佳在线学习方法的对比方案。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adaptive+Fairness-Aware+Online+Meta-Learning+for+Changing+Environments)|0|
|[Physics-Guided Graph Meta Learning for Predicting Water Temperature and Streamflow in Stream Networks](https://doi.org/10.1145/3534678.3539115)|Shengyu Chen, Jacob A. Zwart, Xiaowei Jia|US Geol Survey, Pittsburgh, PA USA; Univ Pittsburgh, Pittsburgh, PA 15213 USA|This paper proposes a graph-based meta learning approach to separately predict water quantity and quality variables for river segments in stream networks. Given the heterogeneous water dynamic patterns in large-scale basins, we introduce an additional meta-learning condition based on physical characteristics of stream segments, which allows learning different sets of initial parameters for different stream segments. Specifically, we develop a representation learning method that leverages physical simulations to embed the physical characteristics of each segment. The obtained embeddings are then used to cluster river segments and add the condition for the meta-learning process. We have tested the performance of the proposed method for predicting daily water temperature and streamflow for the Delaware River Basin (DRB) over a 14 year period. The results confirm the effectiveness of our method in predicting target variables even using sparse training samples. We also show that our method can achieve robust performance with different numbers of clusterings.|本文提出一种基于图的元学习方法，用于分别预测河网中各河段的水量和水质变量。针对大尺度流域中异质性的水动力模式，我们引入基于河段物理特征的附加元学习条件，使模型能够为不同河段学习不同的初始参数集。具体而言，我们开发了一种表征学习方法，通过物理模拟嵌入各河段的物理特征。所得嵌入向量用于对河段进行聚类，并为元学习过程添加条件约束。我们在特拉华河流域（DRB）开展了为期14年的日尺度水温与径流量预测实验，测试结果表明：即使在训练样本稀疏的情况下，该方法仍能有效预测目标变量。实验还证明，在不同聚类数量设置下，该方法均能保持稳健的预测性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Physics-Guided+Graph+Meta+Learning+for+Predicting+Water+Temperature+and+Streamflow+in+Stream+Networks)|0|
|[ILASR: Privacy-Preserving Incremental Learning for Automatic Speech Recognition at Production Scale](https://doi.org/10.1145/3534678.3539174)|Gopinath Chennupati, Milind Rao, Gurpreet Chadha, Aaron Eakin, Anirudh Raju, Gautam Tiwari, Anit Kumar Sahu, Ariya Rastrow, Jasha Droppo, Andy Oberlin, Buddha Nandanoor, Prahalad Venkataramanan, Zheng Wu, Pankaj Sitpure|Amazon Alexa, Madison, WI 98109 USA|Incremental learning is one paradigm to enable model building and updating at scale with streaming data. For end-to-end automatic speech recognition (ASR) tasks, the absence of human annotated labels along with the need for privacy preserving policies for model building makes it a daunting challenge. Motivated by these challenges, in this paper we use a cloud based framework for production systems to demonstrate insights from privacy preserving incremental learning for automatic speech recognition (ILASR). By privacy preserving, we mean, usage of ephemeral data which are not human annotated. This system is a step forward for production level ASR models for incremental/continual learning that offers near real-time test-bed for experimentation in the cloud for end-to-end ASR, while adhering to privacy-preserving policies. We show that the proposed system can improve the production models significantly ($3%$) over a new time period of six months even in the absence of human annotated labels with varying levels of weak supervision and large batch sizes in incremental learning. This improvement is $20%$ over test sets with new words and phrases in the new time period. We demonstrate the effectiveness of model building in a privacy-preserving incremental fashion for ASR while further exploring the utility of having an effective teacher model and use of large batch sizes.|增量学习是一种能够利用流式数据大规模构建和更新模型的范式。对于端到端自动语音识别（ASR）任务，由于缺乏人工标注标签且需遵循模型构建的隐私保护政策，这成为一项艰巨挑战。基于这些挑战，本文采用面向生产系统的云端框架，展示隐私保护型增量学习在自动语音识别（ILASR）中的应用价值。所谓隐私保护，是指使用未经人工标注的瞬时数据。该系统推动了生产级ASR模型在增量/持续学习领域的发展，为端到端ASR提供了近乎实时的云端实验测试平台，同时严格遵守隐私保护政策。实验表明，即使在没有人工标注标签的情况下，通过采用不同级别的弱监督和大批量增量学习策略，所提出的系统能在六个月内持续提升生产模型性能（提升幅度达3%）。对于包含新时段新词新短语的测试集，性能提升幅度高达20%。我们验证了隐私保护型增量学习在ASR模型构建中的有效性，并深入探讨了高效教师模型架构与大批量训练策略的实际效用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ILASR:+Privacy-Preserving+Incremental+Learning+for+Automatic+Speech+Recognition+at+Production+Scale)|0|
|[Large-Scale Acoustic Automobile Fault Detection: Diagnosing Engines Through Sound](https://doi.org/10.1145/3534678.3539066)|Dennis Fedorishin, Justas Birgiolas, Deen Dayal Mohan, Livio Forte, Philip Schneider, Srirangaraj Setlur, Venu Govindaraju|ACV Auct Inc, Buffalo, NY USA; Univ Buffalo, Buffalo, NY 14203 USA; ACV Auct Inc, Ronin Inst, Buffalo, NY USA|In this paper we present AMPNet, an acoustic abnormality detection model deployed at ACV Auctions to automatically identify engine faults of vehicles listed on the ACV Auctions platform. We investigate the problem of engine fault detection and discuss our approach of deep-learning based audio classification on a large-scale automobile dataset collected at ACV Auctions. Specifically, we discuss our data collection pipeline and its challenges, dataset preprocessing and training procedures, and deployment of our trained models into a production setting. We perform empirical evaluations of AMPNet and demonstrate that our framework is able to successfully capture various engine anomalies agnostic of vehicle type. Finally we demonstrate the effectiveness and impact of AMPNet in the real world, specifically showing a 20.85% reduction in vehicle arbitrations on ACV Auctions' live auction platform.|本文提出AMPNet声学异常检测模型——该模型已部署于ACV Auctions平台，用于自动识别平台所列车辆的发动机故障。我们针对发动机故障检测问题展开研究，并探讨了基于深度学习的音频分类方法在ACV Auctions大规模汽车数据集上的应用。具体而言，我们阐述了数据收集流程及其挑战、数据集预处理与训练流程，以及训练模型在生产环境中的部署方案。通过实证评估，我们证明AMPNet框架能够有效捕捉不同车型的各类发动机异常。最终，我们展示了AMPNet在真实场景中的有效性及其实际影响：该模型使ACV Auctions实时拍卖平台的车辆仲裁率显著降低了20.85%。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large-Scale+Acoustic+Automobile+Fault+Detection:+Diagnosing+Engines+Through+Sound)|0|
|[Real-Time Rideshare Driver Supply Values Using Online Reinforcement Learning](https://doi.org/10.1145/3534678.3539141)|Benjamin Han, Hyungjun Lee, Sébastien Martin|OpenSea, San Francisco, CA 94110 USA; Snap Inc, San Francisco, CA USA; Northwestern Univ, Evanston, IL USA|In this paper, we present Online Supply Values (OSV), a system for estimating the return of available rideshare drivers to match drivers to ride requests at Lyft. Because a future driver state can be accurately predicted from a request destination, it is possible to estimate the expected action value of assigning a ride request to an available driver as a Markov Decision Process using the Bellman Equation. These estimates are updated using temporal difference and are shown to adapt to changing marketplace conditions in real-time. While reinforcement learning has been studied for rideshare dispatch, fully-online approaches without offline priors or other guardrails had never been evaluated in the real world. This work presents the algorithmic changes needed to bridge this gap. OSV is now deployed globally as a core component of Lyft's dispatch matching system. Our A/B user experiments in major US cities measure a +(0.96±0.53)% increase in the request fulfillment rate and a +(0.73±0.22)% increase to profit per passenger session over the previous algorithm.|本文提出在线供给价值（Online Supply Values, OSV）系统，该系统通过预估网约车平台Lyft现有可用司机的回报价值，实现司机与出行需求的精准匹配。由于可根据订单目的地准确预测司机的未来状态，该系统能够基于贝尔曼方程，通过马尔可夫决策过程来估算将出行订单分配给可用司机时期的望动作价值。这些估值通过时序差分法实时更新，并被证明可适应动态变化的市场环境。虽然强化学习在网约车调度领域已有研究，但完全在线、无需离线先验或其他保护机制的方法从未在现实场景中得到验证。本研究提出了实现这一突破所需的算法改进。目前OSV系统已作为核心调度组件在Lyft全球平台完成部署。通过在美国主要城市开展的A/B用户实验验证，新系统相较原有算法实现了订单达成率提升(0.96±0.53)%，单乘客会话利润增长(0.73±0.22)%的显著效果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Real-Time+Rideshare+Driver+Supply+Values+Using+Online+Reinforcement+Learning)|0|
|[Three-Stage Root Cause Analysis for Logistics Time Efficiency via Explainable Machine Learning](https://doi.org/10.1145/3534678.3539024)|Shiqi Hao, Yang Liu, Yu Wang, Yuan Wang, Wenming Zhe|JD Logist, Beijing, Peoples R China|The performance of logistics highly depends on the time efficiency, and hence, plenty of efforts have been devoted to ensuring the on-time delivery in modern logistics industry. However, the delay in logistics transportation and delivery can still happen due to various practical issues, which significantly impact the quality of logistics service. In order to address this issue, this work investigates the root causes impacting the time efficiency, thereby facilitating the operation of logistics systems such that resources can be appropriately allocated to improve the performance. The proposed solution comprises three stages, where statistical methods are employed in the first stage to analyze the pattern of on-time delivery rate and detect the abnormalities induced by non-ideality of operations. Subsequently, a machine learning model is trained to capture the underlying correlations between time efficiency and potential impacting factors. Finally, explainable machine learning techniques are utilized to quantify the contributions of the impacting factors to the time efficiency, thereby recognizing the root causes. The proposed method is comprehensively studied on the real JD Logistics data through experiments, where it can identify the root causes that impact the time efficiency of logistics delivery with high accuracy. Furthermore, it is also demonstrated to outperform the baselines including a recent state-of-the-art method.|物流服务的绩效高度依赖于时效性，因此现代物流业投入大量精力确保准时送达。然而由于各类现实因素，物流运输与配送环节仍可能出现延迟，严重影响物流服务质量。为应对该问题，本研究深入探究影响时效性的根本原因，以优化物流系统运作模式，实现资源的精准配置从而提升效能。我们提出的解决方案包含三阶段架构：第一阶段采用统计方法分析准时送达率的变化规律，检测因操作不规范引发的异常状况；第二阶段通过机器学习模型挖掘时效性与潜在影响因素间的内在关联；最终借助可解释机器学习技术量化各因素对时效性的贡献度，从而精准定位根本原因。基于京东物流真实数据的实验表明，该方法能高精度识别影响物流配送时效的根本原因，其性能显著优于包括当前最先进方法在内的多种基线模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Three-Stage+Root+Cause+Analysis+for+Logistics+Time+Efficiency+via+Explainable+Machine+Learning)|0|
|[Unsupervised Learning Style Classification for Learning Path Generation in Online Education Platforms](https://doi.org/10.1145/3534678.3539107)|Zhicheng He, Wei Xia, Kai Dong, Huifeng Guo, Ruiming Tang, Dingyin Xia, Rui Zhang|www.ruizhang.info, Shenzhen, China; Huawei Noahs Ark Lab, Shenzhen, Peoples R China; Huawei CBG Edu AI Lab, Shenzhen, Peoples R China|Online education, which educates students that cannot be present at school, has become an important supplement to traditional education. Without the direct supervision and instruction of teachers, online education is always concerned with potential distractions and misunderstandings. Learning Style Classification (LSC) is proposed to analyze the learning behavior patterns of online learning users, based on which personalized learning paths are generated to help them learn and maintain their interests. Existing LSC studies rely on expert-labored labeling, which is infeasible in large-scale applications, so we resort to unsupervised classification techniques. However, current unsupervised classification methods are not applicable due to two important challenges: C1) the unawareness of the LSC problem formulation and pedagogy domain knowledge; C2) the absence of any supervision signals. In this paper, we give a formal definition of the unsupervised LSC problem and summarize the domain knowledge into problem-solving heuristics (which addresses C1). A rule-based approach is first designed to provide a tentative solution in a principled manner (which addresses C2). On top of that, a novel Deep Unsupervised Classifier with domain Knowledge (DUCK) is proposed to convert the discovered conclusions and domain knowledge into learnable model components (which addresses both C1 and C2), which significantly improves the effectiveness, efficiency, and robustness. Extensive offline experiments on both public and industrial datasets demonstrate the superiority of our proposed methods. Moreover, the proposed methods are now deployed in the Huawei Education Center, and the ongoing A/B testing results verify the effectiveness of the methods.|在线教育为无法亲临校园的学生提供教学服务，已成为传统教育的重要补充。由于缺乏教师的直接监督与指导，在线教育始终面临着注意力分散与知识理解偏差的隐忧。学习风格分类（LSC）通过分析在线学习用户的行为模式，为其生成个性化学习路径以维持学习兴趣。现有LSC研究依赖专家人工标注，难以应用于大规模场景，因此我们采用无监督分类技术。但当前无监督分类方法面临两大挑战：C1）缺乏对LSC问题形式化及教育学领域知识的认知；C2）不存在任何监督信号。本文首次对无监督LSC问题进行形式化定义，并将领域知识凝练为问题求解启发式规则（解决C1）；率先设计基于规则的方法以原则性方式提供初步解决方案（解决C2）；进而提出融合领域知识的深度无监督分类模型DUCK，将已发现的结论与领域知识转化为可学习的模型组件（同时解决C1与C2），显著提升模型效能、效率与鲁棒性。在公开数据集和工业数据集上的大量离线实验证明了所提方法的优越性。目前该方法已部署于华为教育中心，持续进行的A/B测试结果验证了其实际有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unsupervised+Learning+Style+Classification+for+Learning+Path+Generation+in+Online+Education+Platforms)|0|
|[Analyzing Online Transaction Networks with Network Motifs](https://doi.org/10.1145/3534678.3539096)|Jiawei Jiang, Yusong Hu, Xiaosen Li, Wen Ouyang, Zhitao Wang, Fangcheng Fu, Bin Cui|Tencent Inc, Shenzhen, Peoples R China; Peking Univ, Sch CS, Beijing, Peoples R China; Wuhan Univ, Sch Comp Sci, Wuhan, Peoples R China|Network motif is a kind of frequently occurring subgraph that reflects local topology in graphs. Although network motif has been studied in graph analytics, e.g., social network and biological network, it is yet unclear whether network motif is useful for analyzing online transaction network that is generated in applications such as instant messaging and e-commerce. In this work, we analyze online transaction networks from the perspective of network motif. We define vertex features based on size-2 and size-3 motifs, and introduce motif-based centrality measurements. We further design motif-based vertex embedding that integrates weighted motif counts and centrality measurements. Afterward, we implement a distributed framework for motif detection in large-scale online transaction networks. To understand the effectiveness of motif for analyzing online transaction network, we study the statistical distribution of motifs in various kinds of graphs in Tencent and assess the benefit of motif-based embedding in a range of downstream graph analytical tasks. Empirical results show that our proposed method can efficiently find motifs in large-scale graphs, help interpretability, and benefit downstream tasks.|网络模体是一种反映图结构局部拓扑特征的频繁子图模式。尽管网络模体已在社交网络和生物网络等图分析领域得到研究，但尚不清楚其是否适用于分析即时通讯和电子商务等应用中产生的在线交易网络。本研究从网络模体视角对在线交易网络进行分析：基于二阶与三阶模体定义顶点特征，引入模体中心性度量指标，进一步设计融合加权模体计数与中心性度量的模体顶点嵌入方法。随后实现面向大规模在线交易网络的分布式模体检测框架。为验证模体分析在线交易网络的有效性，我们研究腾讯各类图中模体的统计分布特征，并评估模体嵌入在多类下游图分析任务中的性能增益。实验结果表明，所提方法能高效发现大规模图中的模体结构，增强模型可解释性，并显著提升下游任务性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Analyzing+Online+Transaction+Networks+with+Network+Motifs)|0|
|[COBART: Controlled, Optimized, Bidirectional and Auto-Regressive Transformer for Ad Headline Generation](https://doi.org/10.1145/3534678.3539069)|Yashal Shakti Kanungo, Gyanendra Das, Pooja A, Sumit Negi|Amazon, New Delhi, India; Amazon, Seattle, WA 98109 USA|Online ads are essential to all businesses and ad headlines are one of their core creative component. Existing methods can generate headlines automatically and also optimize their click-through-rate (CTR) and quality. However, evolving ad formats and changing creative requirements make it difficult to generate optimized & customized headlines. We propose a novel method that uses prefix control tokens along with BART [16] fine-tuning. It yields the highest CTR and also allows users to control the length of generated headlines for use across different ad formats. The method is also flexible and can easily be adapted to other architectures, creative requirements and optimization criteria. Our experiments demonstrate a 25.82% increment in Rouge-L and a 5.82% increment in estimated CTR over previously published strong ad headline generation baseline.|在线广告对所有企业都至关重要，而广告标题是其核心创意要素之一。现有方法虽能自动生成标题并优化点击率（CTR）与质量，但不断演变的广告形式与变化的创意需求使生成优化定制化标题变得困难。我们提出一种创新方法，通过结合前缀控制令牌与BART模型[16]进行微调。该方法不仅实现了最高点击率，还允许用户控制生成标题的长度以适应不同广告格式。该方案具备高度灵活性，可轻松适配其他架构、创意需求及优化标准。实验表明，相较于已发布的强基线模型，我们的方法在Rouge-L指标上提升25.82%，预估点击率提升5.82%。

注：
1. 专业术语处理：CTR（点击率）、Rouge-L（自动摘要评估指标）保留英文缩写+中文注释，BART（预训练模型）直接保留原名
2. 技术概念传达："prefix control tokens"译为"前缀控制令牌"，"fine-tuning"译为"微调"符合NLP领域惯例
3. 长句拆分：将原文复合长句按中文表达习惯分解为多个短句，如首句拆分为背景陈述与问题指认
4. 逻辑显化：通过"虽能...但..."、"不仅...还..."等连接词强化技术方案的对比优势和功能特性
5. 数据呈现：百分比数据保留精确值，采用"提升X%"符合中文技术报告表述规范
6. 文献引用：[16]保留原格式体现学术规范性|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=COBART:+Controlled,+Optimized,+Bidirectional+and+Auto-Regressive+Transformer+for+Ad+Headline+Generation)|0|
|[Fast Mining and Forecasting of Co-evolving Epidemiological Data Streams](https://doi.org/10.1145/3534678.3539078)|Tasuku Kimura, Yasuko Matsubara, Koki Kawabata, Yasushi Sakurai|Osaka Univ, SANKEN, Osaka, Japan|Given a large, semi-infinite collection of co-evolving epidemiological data containing the daily counts of cases/deaths/recovered in multiple locations, how can we incrementally monitor current dynamical patterns and forecast future behavior? The world faces the rapid spread of infectious diseases such as SARS-CoV-2 (COVID-19), where a crucial goal is to predict potential future outbreaks and pandemics, as quickly as possible, using available data collected throughout the world. In this paper, we propose a new streaming algorithm, EPICAST, which is able to model, understand and forecast dynamical patterns in large co-evolving epidemiological data streams. Our proposed method is designed as a dynamic and flexible system, and is based on a unified non-linear differential equation. Our method has the following properties: (a) Effective: it operates on large co-evolving epidemiological data streams, and captures important world-wide trends, as well as location-specific patterns. It also performs real-time and long-term forecasting; (b) Adaptive: it incrementally monitors current dynamical patterns, and also identifies any abrupt changes in streams; (c) Scalable: our algorithm does not depend on data size, and thus is applicable to very large data streams. In extensive experiments on real datasets, we demonstrate that EPICAST outperforms the best existing state-of-the-art methods as regards accuracy and execution speed.|给定一个包含多地区每日病例/死亡/康复计数的大规模半无限共演化流行病学数据集合，我们如何实现增量式动态模式监测与未来行为预测？面对SARS-CoV-2（COVID-19）等传染病在全球的快速传播，核心目标在于利用全球收集的可用数据尽可能快速地预测潜在疫情爆发与流行趋势。本文提出新型流式算法EPICAST，能够对大规模共演化流行病学数据流中的动态模式进行建模、理解与预测。该方法采用动态灵活的系统设计，基于统一的非线性微分方程框架，具有以下特性：（a）高效性：可处理大规模共演化数据流，捕捉全球总体趋势与地区特异性模式，实现实时与长期预测；（b）自适应性：增量监测当前动态模式并识别数据流中的突变；（c）可扩展性：算法性能与数据规模无关，适用于超大规模数据流。在真实数据集上的大量实验表明，EPICAST在预测精度与执行效率方面均优于现有最先进方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fast+Mining+and+Forecasting+of+Co-evolving+Epidemiological+Data+Streams)|0|
|[Design Domain Specific Neural Network via Symbolic Testing](https://doi.org/10.1145/3534678.3539118)|Hui Li, Xing Fu, Ruofan Wu, Jinyu Xu, Kai Xiao, Xiaofu Chang, Weiqiang Wang, Shuai Chen, Leilei Shi, Tao Xiong, Yuan Qi|Ant Grp, Hangzhou, Peoples R China|Deep sequence networks such as multi-head self-attention networks provide a promising way to extract effective representations from raw sequence data in an end-to-end fashion and have shown great success in various domains such as natural language processing, computer vision, $etc$. However, in domains such as financial risk management and anti-fraud where expert-derived features are heavily relied on, deep sequence models struggle to dominate the game.In this paper, we introduce a simple framework called symbolic testing to verify the learnability of certain expert-derived features over sequence data. A systematic investigation over simulated data reveals the fact that the self-attention architecture fails to learn some standard symbolic expressions like the count distinct operation. To overcome this deficiency, we propose a novel architecture named SHORING, which contains two components:event network andsequence network. Theevent network efficiently learns arbitrary high-orderevent-level conditional embeddings via a reparameterization trick while thesequence network integrates domain-specific aggregations into the sequence-level representation, thereby providing richer inductive biases compare to standard sequence architectures like self-attention. We conduct comprehensive experiments and ablation studies on synthetic datasets that mimic sequence data commonly seen in anti-fraud domain and three real-world datasets. The results show that SHORING learns commonly used symbolic features well, and experimentally outperforms the state-of-the-art methods by a significant margin over real-world online transaction datasets. The symbolic testing framework and SHORING have been applied in anti-fraud model development at Alipay and improved performance of models for real-time fraud-detection.|多头自注意力网络等深度序列网络为从原始序列数据中端到端提取有效表征提供了可行路径，已在自然语言处理、计算机视觉等领域取得显著成功。然而在金融风险管理和反欺诈等高度依赖专家特征的领域，深度序列模型难以占据主导地位。本文提出名为符号化测试的简易框架，用于验证特定专家派生特征在序列数据上的可学习性。通过对模拟数据的系统性研究，我们发现自注意力架构无法学习计数去重等标准符号表达式。为克服这一缺陷，我们提出名为SHORING的新型架构，其包含事件网络与序列网络两大组件：事件网络通过重参数化技巧高效学习任意高阶事件级条件嵌入，而序列网络将领域特异性聚合运算融入序列级表征，相比自注意力等标准序列架构能提供更强的归纳偏置。我们在模拟反欺诈领域常见序列数据的合成数据集及三个真实数据集上进行了全面实验与消融研究。结果表明SHORING能有效学习常用符号特征，且在真实在线交易数据集上显著超越现有最优方法。该符号化测试框架与SHORING架构已应用于支付宝反欺诈模型开发，提升了实时欺诈检测模型的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Design+Domain+Specific+Neural+Network+via+Symbolic+Testing)|0|
|[Arbitrary Distribution Modeling with Censorship in Real-Time Bidding Advertising](https://doi.org/10.1145/3534678.3539048)|Xu Li, Michelle Ma Zhang, Zhenya Wang, Youjun Tong|FreeWheel, Comcast Co, Beijing, Peoples R China; Northwestern Univ, Evanston, IL USA|The purpose of Inventory Pricing is to bid the right prices to online ad opportunities, which is crucial for a Demand-Side Platform (DSP) to win advertising auctions in Real-Time Bidding (RTB). In the planning stage, advertisers need the forecast of probabilistic models to make bidding decisions. However, most of the previous works made strong assumptions on the distribution form of the winning price, which reduced their accuracy and weakened their ability to make generalizations. Though some works recently tried to fit the distribution directly, their complex structure lacked efficiency on online inference, which is critical for advertising systems. In this paper, we devise a novel loss function, Neighborhood Likelihood Loss (NLL), collaborating with a proposed framework, Arbitrary Distribution Modeling (ADM), to predict the winning price distribution under censorship with no pre-assumption required. We conducted experiments on two real-world experimental datasets and one large-scale, non-simulated production dataset in our system. Experiments showed that ADM outperformed the baselines both on algorithm and business metrics. This method has been released for one year and led to good yield in our system. Without any pre-assumed specific distribution form, ADM showed significant advantages in effectiveness and efficiency, demonstrating its great capability in modeling sophisticated price landscapes.|库存定价旨在为在线广告机会提供精准出价，这对需求方平台（DSP）在实时竞价（RTB）中赢得广告拍卖至关重要。在广告投放规划阶段，广告主需要概率模型的预测来制定竞价策略。然而现有研究大多对中标价格分布形式做了强假设，这既降低了预测准确性，也削弱了模型的泛化能力。尽管近期有研究尝试直接拟合价格分布，但其复杂结构难以满足广告系统对在线推断效率的严苛要求。本文设计了一种新型损失函数——邻域似然损失（NLL），结合提出的任意分布建模（ADM）框架，能够在无需预设分布形式的条件下预测截尾状态下的中标价格分布。我们在两个真实场景数据集和一个大规模非仿真生产数据集上进行实验，结果表明ADM在算法指标和商业指标上均超越基线模型。该方法已上线运行一年，为系统带来了显著收益。ADM无需预设特定分布形式，在效果和效率方面展现出显著优势，展现出对复杂价格场景的强大建模能力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Arbitrary+Distribution+Modeling+with+Censorship+in+Real-Time+Bidding+Advertising)|0|
|[Para-Pred: Addressing Heterogeneity for City-Wide Indoor Status Estimation in On-Demand Delivery](https://doi.org/10.1145/3534678.3539167)|Wei Liu, Yi Ding, Shuai Wang, Yu Yang, Desheng Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Para-Pred:+Addressing+Heterogeneity+for+City-Wide+Indoor+Status+Estimation+in+On-Demand+Delivery)|0|
|[Uncovering the Heterogeneous Effects of Preference Diversity on User Activeness: A Dynamic Mixture Model](https://doi.org/10.1145/3534678.3539033)|Yunfei Lu, Peng Cui, Linyun Yu, Lei Li, Wenwu Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Uncovering+the+Heterogeneous+Effects+of+Preference+Diversity+on+User+Activeness:+A+Dynamic+Mixture+Model)|0|
|[Looper: An End-to-End ML Platform for Product Decisions](https://doi.org/10.1145/3534678.3539059)|Igor L. Markov, Hanson Wang, Nitya S. Kasturi, Shaun Singh, Mia R. Garrard, Yin Huang, Sze Wai Celeste Yuen, Sarah Tran, Zehui Wang, Igor Glotov, Tanvi Gupta, Peng Chen, Boshuang Huang, Xiaowen Xie, Michael Belkin, Sal Uryasev, Sam Howie, Eytan Bakshy, Norm Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Looper:+An+End-to-End+ML+Platform+for+Product+Decisions)|0|
|[Proactively Reducing the Hate Intensity of Online Posts via Hate Speech Normalization](https://doi.org/10.1145/3534678.3539161)|Sarah Masud, Manjot Bedi, Mohammad Aflah Khan, Md. Shad Akhtar, Tanmoy Chakraborty||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Proactively+Reducing+the+Hate+Intensity+of+Online+Posts+via+Hate+Speech+Normalization)|0|
|[Human-in-the-Loop Large-Scale Predictive Maintenance of Workstations](https://doi.org/10.1145/3534678.3539196)|Alexander V. Nikitin, Samuel Kaski||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Human-in-the-Loop+Large-Scale+Predictive+Maintenance+of+Workstations)|0|
|[Regional-Local Adversarially Learned One-Class Classifier Anomalous Sound Detection in Global Long-Term Space](https://doi.org/10.1145/3534678.3539133)|Yu Sha, Shuiping Gou, Johannes Faber, Bo Liu, Wei Li, Stefan Schramm, Horst Stoecker, Thomas Steckenreiter, Domagoj Vnucec, Nadine Wetzstein, Andreas Widl, Kai Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Regional-Local+Adversarially+Learned+One-Class+Classifier+Anomalous+Sound+Detection+in+Global+Long-Term+Space)|0|
|[Septor: Seismic Depth Estimation Using Hierarchical Neural Networks](https://doi.org/10.1145/3534678.3539166)|M. Ashraf Siddiquee, Vinicius M. A. Souza, Glenn Eli Baker, Abdullah Mueen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Septor:+Seismic+Depth+Estimation+Using+Hierarchical+Neural+Networks)|0|
|[Optimizing Long-Term Efficiency and Fairness in Ride-Hailing via Joint Order Dispatching and Driver Repositioning](https://doi.org/10.1145/3534678.3539060)|Jiahui Sun, Haiming Jin, Zhaoxing Yang, Lu Su, Xinbing Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimizing+Long-Term+Efficiency+and+Fairness+in+Ride-Hailing+via+Joint+Order+Dispatching+and+Driver+Repositioning)|0|
|[NENYA: Cascade Reinforcement Learning for Cost-Aware Failure Mitigation at Microsoft 365](https://doi.org/10.1145/3534678.3539127)|Lu Wang, Pu Zhao, Chao Du, Chuan Luo, Mengna Su, Fangkai Yang, Yudong Liu, Qingwei Lin, Min Wang, Yingnong Dang, Hongyu Zhang, Saravan Rajmohan, Dongmei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NENYA:+Cascade+Reinforcement+Learning+for+Cost-Aware+Failure+Mitigation+at+Microsoft+365)|0|
|[ROI-Constrained Bidding via Curriculum-Guided Bayesian Reinforcement Learning](https://doi.org/10.1145/3534678.3539211)|Haozhe Wang, Chao Du, Panyan Fang, Shuo Yuan, Xuming He, Liang Wang, Bo Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ROI-Constrained+Bidding+via+Curriculum-Guided+Bayesian+Reinforcement+Learning)|0|
|[Adaptive Multi-view Rule Discovery for Weakly-Supervised Compatible Products Prediction](https://doi.org/10.1145/3534678.3539208)|Rongzhi Zhang, Rebecca West, Xiquan Cui, Chao Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adaptive+Multi-view+Rule+Discovery+for+Weakly-Supervised+Compatible+Products+Prediction)|0|
|[DESCN: Deep Entire Space Cross Networks for Individual Treatment Effect Estimation](https://doi.org/10.1145/3534678.3539198)|Kailiang Zhong, Fengtong Xiao, Yan Ren, Yaorong Liang, Wenqing Yao, Xiaofeng Yang, Ling Cen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DESCN:+Deep+Entire+Space+Cross+Networks+for+Individual+Treatment+Effect+Estimation)|0|
|[RBG: Hierarchically Solving Large-Scale Routing Problems in Logistic Systems via Reinforcement Learning](https://doi.org/10.1145/3534678.3539037)|Zefang Zong, Hansen Wang, Jingwei Wang, Meng Zheng, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RBG:+Hierarchically+Solving+Large-Scale+Routing+Problems+in+Logistic+Systems+via+Reinforcement+Learning)|0|
|[Scalable Online Disease Diagnosis via Multi-Model-Fused Actor-Critic Reinforcement Learning](https://doi.org/10.1145/3534678.3542672)|Weijie He, Ting Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+Online+Disease+Diagnosis+via+Multi-Model-Fused+Actor-Critic+Reinforcement+Learning)|0|
|[Reinforcement Learning Enhances the Experts: Large-scale COVID-19 Vaccine Allocation with Multi-factor Contact Network](https://doi.org/10.1145/3534678.3542679)|Qianyue Hao, Wenzhen Huang, Fengli Xu, Kun Tang, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reinforcement+Learning+Enhances+the+Experts:+Large-scale+COVID-19+Vaccine+Allocation+with+Multi-factor+Contact+Network)|0|
|[The Battlefront of Combating Misinformation and Coping with Media Bias](https://doi.org/10.1145/3534678.3542615)|Yi R. Fung, KungHsiang Huang, Preslav Nakov, Heng Ji||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Battlefront+of+Combating+Misinformation+and+Coping+with+Media+Bias)|0|
|[Large-Scale Information Extraction under Privacy-Aware Constraints](https://doi.org/10.1145/3534678.3547352)|Rajeev Gupta, Ranganath Kondapally||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large-Scale+Information+Extraction+under+Privacy-Aware+Constraints)|0|
|[Online Clustering: Algorithms, Evaluation, Metrics, Applications and Benchmarking](https://doi.org/10.1145/3534678.3542600)|Jacob Montiel, HoangAnh Ngo, MinhHuong Le Nguyen, Albert Bifet||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Online+Clustering:+Algorithms,+Evaluation,+Metrics,+Applications+and+Benchmarking)|0|
|[Automated Machine Learning & Tuning with FLAML](https://doi.org/10.1145/3534678.3542636)|Chi Wang, Qingyun Wu, Xueqing Liu, Luis Quintanilla||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automated+Machine+Learning+&+Tuning+with+FLAML)|0|
|[Decision Intelligence and Analytics for Online Marketplaces: Jobs, Ridesharing, Retail and Beyond](https://doi.org/10.1145/3534678.3542895)|Zhiwei (Tony) Qin, Liangjie Hong, Rui Song, Hongtu Zhu, Mohammed Korayem, Haiyan Luo, Michael I. Jordan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Decision+Intelligence+and+Analytics+for+Online+Marketplaces:+Jobs,+Ridesharing,+Retail+and+Beyond)|0|
|[Machine Learning for Materials Science (MLMS)](https://doi.org/10.1145/3534678.3542902)|Avadhut Sardeshmukh, Sreedhar Reddy, Gautham B. P., Ankit Agrawal||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Machine+Learning+for+Materials+Science+(MLMS))|0|
|[The Power of (Statistical) Relational Thinking](https://doi.org/10.1145/3534678.3539216)|Lise Getoor|UC Santa Cruz, Santa Cruz, CA, USA|Taking into account relational structure during data mining can lead to better results, both in terms of quality and computational efficiency. This structure may be captured in the schema, in links between entities (e.g., graphs) or in rules describing the domain (e.g., knowledge graphs). Further, for richly structured prediction problems, there is often a need for a mix of both logical reasoning and statistical inference. In this talk, I will give an introduction to the field of Statistical Relational Learning (SRL), and I'll identify useful tips and tricks for exploiting structure in both the input and output space. I'll describe our recent work on highly scalable approaches for statistical relational inference. I'll close by introducing a broader interpretation of relational thinking that reveals new research opportunities (and challenges!).|在数据挖掘过程中考虑到关系结构，可以在质量和计算效率方面取得更好的结果。这种结构可以在模式、实体之间的链接(例如图形)或描述领域的规则(例如知识图形)中捕获。此外，对于结构丰富的预测问题，通常需要同时考虑逻辑推理和推论统计学。在这个演讲中，我将介绍统计关系学习(SRL)领域，并且我将确定在输入和输出空间中利用结构的有用提示和技巧。我将描述我们最近关于统计关系推理的高度可伸缩方法的工作。最后，我将介绍关系思维的更广泛的解释，揭示新的研究机会(和挑战!).|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Power+of+(Statistical)+Relational+Thinking)|0|
|[Beyond Traditional Characterizations in the Age of Data: Big Models, Scalable Algorithms, and Meaningful Solutions](https://doi.org/10.1145/3534678.3539510)|ShangHua Teng|University of Southern California, Los Angeles, CA, USA|What are data and network models? What are efficient algorithms? What are meaningful solutions? Big Data, Network Sciences, and Machine Learning have fundamentally challenged the basic characterizations in computing, from the conventional graph-theoretical modeling of networks to the traditional polynomial-time worst-case measures of efficiency: For a long time, graphs have been widely used for defining the structure of social and information networks. However, real-world network data and phenomena are much richer and more complex than what can be captured by nodes and edges. Network data is multifaceted, and thus network sciences require new theories, going beyond classic graph theory and graph-theoretical frameworks, to capture the multifaceted data. More than ever before, it is not just desirable, but essential, that efficient algorithms should be scalable. In other words, their complexity should be nearly linear or even sub-linear with respect to the problem size. Thus, scalability, not just polynomial-time computability, should be elevated as the central complexity notion for characterizing efficient computation.|什么是数据和网络模型？什么是高效算法？什么是有意义的解决方案？大数据、网络科学和机器学习从根本上挑战了计算的基本特征，从传统的网络图形理论建模到传统的多项式时间最坏情况的效率度量: 长期以来，图形被广泛用于定义社会和信息网络的结构。然而，真实世界的网络数据和现象比节点和边所能捕获的要丰富和复杂得多。网络数据是多方面的，因此网络科学需要超越经典图论和图论框架的新理论来捕获多方面的数据。与以往任何时候相比，有效的算法应该是可伸缩的，这不仅是可取的，而且是必要的。换句话说，相对于问题的大小，它们的复杂度应该接近线性，甚至是次线性。因此，可伸缩性，而不仅仅是多项式时间的可计算性，应该被提升为表征有效计算的核心复杂性概念。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Traditional+Characterizations+in+the+Age+of+Data:+Big+Models,+Scalable+Algorithms,+and+Meaningful+Solutions)|0|
|[Multi-Variate Time Series Forecasting on Variable Subsets](https://doi.org/10.1145/3534678.3539394)|Jatin Chauhan, Aravindan Raghuveer, Rishi Saket, Jay Nandy, Balaraman Ravindran||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Variate+Time+Series+Forecasting+on+Variable+Subsets)|0|
|[HyperAid: Denoising in Hyperbolic Spaces for Tree-fitting and Hierarchical Clustering](https://doi.org/10.1145/3534678.3539378)|Eli Chien, Puoya Tabaghi, Olgica Milenkovic||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HyperAid:+Denoising+in+Hyperbolic+Spaces+for+Tree-fitting+and+Hierarchical+Clustering)|0|
|[Scalable Differentially Private Clustering via Hierarchically Separated Trees](https://doi.org/10.1145/3534678.3539409)|Vincent CohenAddad, Alessandro Epasto, Silvio Lattanzi, Vahab Mirrokni, Andres Muñoz Medina, David Saulpic, Chris Schwiegelshohn, Sergei Vassilvitskii||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+Differentially+Private+Clustering+via+Hierarchically+Separated+Trees)|0|
|[Framing Algorithmic Recourse for Anomaly Detection](https://doi.org/10.1145/3534678.3539344)|Debanjan Datta, Feng Chen, Naren Ramakrishnan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Framing+Algorithmic+Recourse+for+Anomaly+Detection)|0|
|[Fair Labeled Clustering](https://doi.org/10.1145/3534678.3539451)|Seyed A. Esmaeili, Sharmila Duppala, John P. Dickerson, Brian Brubach||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fair+Labeled+Clustering)|0|
|[On Aligning Tuples for Regression](https://doi.org/10.1145/3534678.3539373)|Chenguang Fang, Shaoxu Song, Yinan Mei, Ye Yuan, Jianmin Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Aligning+Tuples+for+Regression)|0|
|[Optimal Interpretable Clustering Using Oblique Decision Trees](https://doi.org/10.1145/3534678.3539361)|Magzhan Gabidolla, Miguel Á. CarreiraPerpiñán||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimal+Interpretable+Clustering+Using+Oblique+Decision+Trees)|0|
|[Finding Meta Winning Ticket to Train Your MAML](https://doi.org/10.1145/3534678.3539467)|Dawei Gao, Yuexiang Xie, Zimu Zhou, Zhen Wang, Yaliang Li, Bolin Ding||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Finding+Meta+Winning+Ticket+to+Train+Your+MAML)|0|
|[BLISS: A Billion scale Index using Iterative Re-partitioning](https://doi.org/10.1145/3534678.3539414)|Gaurav Gupta, Tharun Medini, Anshumali Shrivastava, Alexander J. Smola||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BLISS:+A+Billion+scale+Index+using+Iterative+Re-partitioning)|0|
|[Subset Node Anomaly Tracking over Large Dynamic Graphs](https://doi.org/10.1145/3534678.3539389)|Xingzhi Guo, Baojian Zhou, Steven Skiena||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Subset+Node+Anomaly+Tracking+over+Large+Dynamic+Graphs)|0|
|[Continuous-Time and Multi-Level Graph Representation Learning for Origin-Destination Demand Prediction](https://doi.org/10.1145/3534678.3539273)|Liangzhe Han, Xiaojian Ma, Leilei Sun, Bowen Du, Yanjie Fu, Weifeng Lv, Hui Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Continuous-Time+and+Multi-Level+Graph+Representation+Learning+for+Origin-Destination+Demand+Prediction)|0|
|[Quantifying and Reducing Registration Uncertainty of Spatial Vector Labels on Earth Imagery](https://doi.org/10.1145/3534678.3539410)|Wenchong He, Zhe Jiang, Marcus Kriby, Yiqun Xie, Xiaowei Jia, Da Yan, Yang Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quantifying+and+Reducing+Registration+Uncertainty+of+Spatial+Vector+Labels+on+Earth+Imagery)|0|
|[AdaAX: Explaining Recurrent Neural Networks by Learning Automata with Adaptive States](https://doi.org/10.1145/3534678.3539356)|Dat Hong, Alberto Maria Segre, Tong Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AdaAX:+Explaining+Recurrent+Neural+Networks+by+Learning+Automata+with+Adaptive+States)|0|
|[Flexible Modeling and Multitask Learning using Differentiable Tree Ensembles](https://doi.org/10.1145/3534678.3539412)|Shibal Ibrahim, Hussein Hazimeh, Rahul Mazumder||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Flexible+Modeling+and+Multitask+Learning+using+Differentiable+Tree+Ensembles)|0|
|[Selective Cross-City Transfer Learning for Traffic Prediction via Source City Region Re-Weighting](https://doi.org/10.1145/3534678.3539250)|Yilun Jin, Kai Chen, Qiang Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Selective+Cross-City+Transfer+Learning+for+Traffic+Prediction+via+Source+City+Region+Re-Weighting)|0|
|[CoRGi: Content-Rich Graph Neural Networks with Attention](https://doi.org/10.1145/3534678.3539306)|Jooyeon Kim, Angus Lamb, Simon Woodhead, Simon Peyton Jones, Cheng Zhang, Miltiadis Allamanis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CoRGi:+Content-Rich+Graph+Neural+Networks+with+Attention)|0|
|[ExMeshCNN: An Explainable Convolutional Neural Network Architecture for 3D Shape Analysis](https://doi.org/10.1145/3534678.3539463)|Seonggyeom Kim, DongKyu Chae||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ExMeshCNN:+An+Explainable+Convolutional+Neural+Network+Architecture+for+3D+Shape+Analysis)|0|
|[In Defense of Core-set: A Density-aware Core-set Selection for Active Learning](https://doi.org/10.1145/3534678.3539476)|Yeachan Kim, Bonggun Shin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=In+Defense+of+Core-set:+A+Density-aware+Core-set+Selection+for+Active+Learning)|0|
|[Modeling Network-level Traffic Flow Transitions on Sparse Data](https://doi.org/10.1145/3534678.3539236)|Xiaoliang Lei, Hao Mei, Bin Shi, Hua Wei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modeling+Network-level+Traffic+Flow+Transitions+on+Sparse+Data)|0|
|[FlowGEN: A Generative Model for Flow Graphs](https://doi.org/10.1145/3534678.3539406)|Furkan Kocayusufoglu, Arlei Silva, Ambuj K. Singh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FlowGEN:+A+Generative+Model+for+Flow+Graphs)|0|
|[The DipEncoder: Enforcing Multimodality in Autoencoders](https://doi.org/10.1145/3534678.3539407)|Collin Leiber, Lena G. M. Bauer, Michael Neumayr, Claudia Plant, Christian Böhm||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+DipEncoder:+Enforcing+Multimodality+in+Autoencoders)|0|
|[HierCDF: A Bayesian Network-based Hierarchical Cognitive Diagnosis Framework](https://doi.org/10.1145/3534678.3539486)|Jiatong Li, Fei Wang, Qi Liu, Mengxiao Zhu, Wei Huang, Zhenya Huang, Enhong Chen, Yu Su, Shijin Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HierCDF:+A+Bayesian+Network-based+Hierarchical+Cognitive+Diagnosis+Framework)|0|
|[Mining Spatio-Temporal Relations via Self-Paced Graph Contrastive Learning](https://doi.org/10.1145/3534678.3539422)|Rongfan Li, Ting Zhong, Xinke Jiang, Goce Trajcevski, Jin Wu, Fan Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mining+Spatio-Temporal+Relations+via+Self-Paced+Graph+Contrastive+Learning)|0|
|[PAC-Wrap: Semi-Supervised PAC Anomaly Detection](https://doi.org/10.1145/3534678.3539408)|Shuo Li, Xiayan Ji, Edgar Dobriban, Oleg Sokolsky, Insup Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PAC-Wrap:+Semi-Supervised+PAC+Anomaly+Detection)|0|
|[TransBO: Hyperparameter Optimization via Two-Phase Transfer Learning](https://doi.org/10.1145/3534678.3539255)|Yang Li, Yu Shen, Huaijun Jiang, Wentao Zhang, Zhi Yang, Ce Zhang, Bin Cui||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TransBO:+Hyperparameter+Optimization+via+Two-Phase+Transfer+Learning)|0|
|[Sparse Conditional Hidden Markov Model for Weakly Supervised Named Entity Recognition](https://doi.org/10.1145/3534678.3539247)|Yinghao Li, Le Song, Chao Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sparse+Conditional+Hidden+Markov+Model+for+Weakly+Supervised+Named+Entity+Recognition)|0|
|[Deep Representations for Time-varying Brain Datasets](https://doi.org/10.1145/3534678.3539301)|Sikun Lin, Shuyun Tang, Scott T. Grafton, Ambuj K. Singh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Representations+for+Time-varying+Brain+Datasets)|0|
|[Partial-Quasi-Newton Methods: Efficient Algorithms for Minimax Optimization Problems with Unbalanced Dimensionality](https://doi.org/10.1145/3534678.3539379)|Chengchang Liu, Shuxian Bi, Luo Luo, John C. S. Lui||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Partial-Quasi-Newton+Methods:+Efficient+Algorithms+for+Minimax+Optimization+Problems+with+Unbalanced+Dimensionality)|0|
|[Label-enhanced Prototypical Network with Contrastive Learning for Multi-label Few-shot Aspect Category Detection](https://doi.org/10.1145/3534678.3539340)|Han Liu, Feng Zhang, Xiaotong Zhang, Siyang Zhao, Junjie Sun, Hong Yu, Xianchao Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Label-enhanced+Prototypical+Network+with+Contrastive+Learning+for+Multi-label+Few-shot+Aspect+Category+Detection)|0|
|[Fair Representation Learning: An Alternative to Mutual Information](https://doi.org/10.1145/3534678.3539302)|Ji Liu, Zenan Li, Yuan Yao, Feng Xu, Xiaoxing Ma, Miao Xu, Hanghang Tong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fair+Representation+Learning:+An+Alternative+to+Mutual+Information)|0|
|[S2RL: Do We Really Need to Perceive All States in Deep Multi-Agent Reinforcement Learning?](https://doi.org/10.1145/3534678.3539481)|Shuang Luo, Yinchuan Li, Jiahui Li, Kun Kuang, Furui Liu, Yunfeng Shao, Chao Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=S2RL:+Do+We+Really+Need+to+Perceive+All+States+in+Deep+Multi-Agent+Reinforcement+Learning?)|0|
|[ML4S: Learning Causal Skeleton from Vicinal Graphs](https://doi.org/10.1145/3534678.3539447)|Pingchuan Ma, Rui Ding, Haoyue Dai, Yuanyuan Jiang, Shuai Wang, Shi Han, Dongmei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ML4S:+Learning+Causal+Skeleton+from+Vicinal+Graphs)|0|
|[Non-stationary Time-aware Kernelized Attention for Temporal Event Prediction](https://doi.org/10.1145/3534678.3539470)|Yu Ma, Zhining Liu, Chenyi Zhuang, Yize Tan, Yi Dong, Wenliang Zhong, Jinjie Gu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Non-stationary+Time-aware+Kernelized+Attention+for+Temporal+Event+Prediction)|0|
|[Discovering Invariant and Changing Mechanisms from Data](https://doi.org/10.1145/3534678.3539479)|Sarah Mameche, David Kaltenpoth, Jilles Vreeken||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Discovering+Invariant+and+Changing+Mechanisms+from+Data)|0|
|[Minimizing Congestion for Balanced Dominators](https://doi.org/10.1145/3534678.3539371)|Yosuke Mizutani, Annie Staker, Blair D. Sullivan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Minimizing+Congestion+for+Balanced+Dominators)|0|
|[Learning Fair Representation via Distributional Contrastive Disentanglement](https://doi.org/10.1145/3534678.3539232)|Changdae Oh, Heeji Won, Junhyuk So, Taero Kim, Yewon Kim, Hosik Choi, Kyungwoo Song||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Fair+Representation+via+Distributional+Contrastive+Disentanglement)|0|
|[MetaV: A Meta-Verifier Approach to Task-Agnostic Model Fingerprinting](https://doi.org/10.1145/3534678.3539257)|Xudong Pan, Yifan Yan, Mi Zhang, Min Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MetaV:+A+Meta-Verifier+Approach+to+Task-Agnostic+Model+Fingerprinting)|0|
|[Predicting Opinion Dynamics via Sociologically-Informed Neural Networks](https://doi.org/10.1145/3534678.3539228)|Maya Okawa, Tomoharu Iwata||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Predicting+Opinion+Dynamics+via+Sociologically-Informed+Neural+Networks)|0|
|[Bilateral Dependency Optimization: Defending Against Model-inversion Attacks](https://doi.org/10.1145/3534678.3539376)|Xiong Peng, Feng Liu, Jingfeng Zhang, Long Lan, Junjie Ye, Tongliang Liu, Bo Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bilateral+Dependency+Optimization:+Defending+Against+Model-inversion+Attacks)|0|
|[Compute Like Humans: Interpretable Step-by-step Symbolic Computation with Deep Neural Network](https://doi.org/10.1145/3534678.3539276)|Shuai Peng, Di Fu, Yong Cao, Yijun Liang, Gu Xu, Liangcai Gao, Zhi Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Compute+Like+Humans:+Interpretable+Step-by-step+Symbolic+Computation+with+Deep+Neural+Network)|0|
|[Evaluating Knowledge Graph Accuracy Powered by Optimized Human-machine Collaboration](https://doi.org/10.1145/3534678.3539233)|Yifan Qi, Weiguo Zheng, Liang Hong, Lei Zou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Evaluating+Knowledge+Graph+Accuracy+Powered+by+Optimized+Human-machine+Collaboration)|0|
|[Releasing Private Data for Numerical Queries](https://doi.org/10.1145/3534678.3539424)|Yuan Qiu, Wei Dong, Ke Yi, Bin Wu, Feifei Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Releasing+Private+Data+for+Numerical+Queries)|0|
|[External Knowledge Infusion for Tabular Pre-training Models with Dual-adapters](https://doi.org/10.1145/3534678.3539403)|Can Qin, Sungchul Kim, Handong Zhao, Tong Yu, Ryan A. Rossi, Yun Fu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=External+Knowledge+Infusion+for+Tabular+Pre-training+Models+with+Dual-adapters)|0|
|[p-Meta: Towards On-device Deep Model Adaptation](https://doi.org/10.1145/3534678.3539293)|Zhongnan Qu, Zimu Zhou, Yongxin Tong, Lothar Thiele||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=p-Meta:+Towards+On-device+Deep+Model+Adaptation)|0|
|[Fair and Interpretable Models for Survival Analysis](https://doi.org/10.1145/3534678.3539259)|Md. Mahmudur Rahman, Sanjay Purushotham||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fair+and+Interpretable+Models+for+Survival+Analysis)|0|
|[A Generalized Backward Compatibility Metric](https://doi.org/10.1145/3534678.3539465)|Tomoya Sakai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Generalized+Backward+Compatibility+Metric)|0|
|[Multi-View Clustering for Open Knowledge Base Canonicalization](https://doi.org/10.1145/3534678.3539449)|Wei Shen, Yang Yang, Yinan Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-View+Clustering+for+Open+Knowledge+Base+Canonicalization)|0|
|[Deep Learning for Prognosis Using Task-fMRI: A Novel Architecture and Training Scheme](https://doi.org/10.1145/3534678.3539362)|Ge Shi, Jason Smucny, Ian Davidson||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Learning+for+Prognosis+Using+Task-fMRI:+A+Novel+Architecture+and+Training+Scheme)|0|
|[Active Model Adaptation Under Unknown Shift](https://doi.org/10.1145/3534678.3539262)|JieJing Shao, Yunlu Xu, Zhanzhan Cheng, YuFeng Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Active+Model+Adaptation+Under+Unknown+Shift)|0|
|[GUIDE: Group Equality Informed Individual Fairness in Graph Neural Networks](https://doi.org/10.1145/3534678.3539346)|Weihao Song, Yushun Dong, Ninghao Liu, Jundong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GUIDE:+Group+Equality+Informed+Individual+Fairness+in+Graph+Neural+Networks)|0|
|[Robust and Informative Text Augmentation (RITA) via Constrained Worst-Case Transformations for Low-Resource Named Entity Recognition](https://doi.org/10.1145/3534678.3539349)|Hyunwoo Sohn, Baekkwan Park||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+and+Informative+Text+Augmentation+(RITA)+via+Constrained+Worst-Case+Transformations+for+Low-Resource+Named+Entity+Recognition)|0|
|[pureGAM: Learning an Inherently Pure Additive Model](https://doi.org/10.1145/3534678.3539256)|Xingzhi Sun, Ziyu Wang, Rui Ding, Shi Han, Dongmei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=pureGAM:+Learning+an+Inherently+Pure+Additive+Model)|0|
|[Demystify Hyperparameters for Stochastic Optimization with Transferable Representations](https://doi.org/10.1145/3534678.3539298)|Jianhui Sun, Mengdi Huai, Kishlay Jha, Aidong Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Demystify+Hyperparameters+for+Stochastic+Optimization+with+Transferable+Representations)|0|
|[Dense Feature Tracking of Atmospheric Winds with Deep Optical Flow](https://doi.org/10.1145/3534678.3539345)|Thomas J. Vandal, Kate Duffy, Will McCarty, Akira Sewnath, Ramakrishna R. Nemani||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dense+Feature+Tracking+of+Atmospheric+Winds+with+Deep+Optical+Flow)|0|
|[Incremental Cognitive Diagnosis for Intelligent Education](https://doi.org/10.1145/3534678.3539399)|Shiwei Tong, Jiayu Liu, Yuting Hong, Zhenya Huang, Le Wu, Qi Liu, Wei Huang, Enhong Chen, Dan Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Incremental+Cognitive+Diagnosis+for+Intelligent+Education)|0|
|[A Model-Agnostic Approach to Differentially Private Topic Mining](https://doi.org/10.1145/3534678.3539417)|Han Wang, Jayashree Sharma, Shuya Feng, Kai Shu, Yuan Hong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Model-Agnostic+Approach+to+Differentially+Private+Topic+Mining)|0|
|[Toward Learning Robust and Invariant Representations with Alignment Regularization and Data Augmentation](https://doi.org/10.1145/3534678.3539438)|Haohan Wang, Zeyi Huang, Xindi Wu, Eric P. Xing||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Toward+Learning+Robust+and+Invariant+Representations+with+Alignment+Regularization+and+Data+Augmentation)|0|
|[Group-wise Reinforcement Feature Generation for Optimal and Explainable Representation Space Reconstruction](https://doi.org/10.1145/3534678.3539278)|Dongjie Wang, Yanjie Fu, Kunpeng Liu, Xiaolin Li, Yan Solihin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Group-wise+Reinforcement+Feature+Generation+for+Optimal+and+Explainable+Representation+Space+Reconstruction)|0|
|[Proton: Probing Schema Linking Information from Pre-trained Language Models for Text-to-SQL Parsing](https://doi.org/10.1145/3534678.3539305)|Lihan Wang, Bowen Qin, Binyuan Hui, Bowen Li, Min Yang, Bailin Wang, Binhua Li, Jian Sun, Fei Huang, Luo Si, Yongbin Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Proton:+Probing+Schema+Linking+Information+from+Pre-trained+Language+Models+for+Text-to-SQL+Parsing)|0|
|[Partial Label Learning with Discrimination Augmentation](https://doi.org/10.1145/3534678.3539363)|Wei Wang, MinLing Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Partial+Label+Learning+with+Discrimination+Augmentation)|0|
|[An Embedded Feature Selection Framework for Control](https://doi.org/10.1145/3534678.3539290)|Jiawen Wei, Fangyuan Wang, Wanxin Zeng, Wenwei Lin, Ning Gui||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Embedded+Feature+Selection+Framework+for+Control)|0|
|[SagDRE: Sequence-Aware Graph-Based Document-Level Relation Extraction with Adaptive Margin Loss](https://doi.org/10.1145/3534678.3539304)|Ying Wei, Qi Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SagDRE:+Sequence-Aware+Graph-Based+Document-Level+Relation+Extraction+with+Adaptive+Margin+Loss)|0|
|[Beyond Point Prediction: Capturing Zero-Inflated & Heavy-Tailed Spatiotemporal Data with Deep Extreme Mixture Models](https://doi.org/10.1145/3534678.3539464)|Tyler Wilson, Andrew McDonald, Asadullah Hill Galib, PangNing Tan, Lifeng Luo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Point+Prediction:+Capturing+Zero-Inflated+&+Heavy-Tailed+Spatiotemporal+Data+with+Deep+Extreme+Mixture+Models)|0|
|[Geometric Policy Iteration for Markov Decision Processes](https://doi.org/10.1145/3534678.3539478)|Yue Wu, Jesús A. De Loera||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Geometric+Policy+Iteration+for+Markov+Decision+Processes)|0|
|[Robust Tensor Graph Convolutional Networks via T-SVD based Graph Augmentation](https://doi.org/10.1145/3534678.3539436)|Zhebin Wu, Lin Shu, Ziyue Xu, Yaomin Chang, Chuan Chen, Zibin Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Tensor+Graph+Convolutional+Networks+via+T-SVD+based+Graph+Augmentation)|0|
|[End-to-End Semi-Supervised Ordinal Regression AUC Maximization with Convolutional Kernel Networks](https://doi.org/10.1145/3534678.3539307)|Ziran Xiong, Wanli Shi, Bin Gu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=End-to-End+Semi-Supervised+Ordinal+Regression+AUC+Maximization+with+Convolutional+Kernel+Networks)|0|
|[Solving the Batch Stochastic Bin Packing Problem in Cloud: A Chance-constrained Optimization Approach](https://doi.org/10.1145/3534678.3539334)|Jie Yan, Yunlei Lu, Liting Chen, Si Qin, Yixin Fang, Qingwei Lin, Thomas Moscibroda, Saravan Rajmohan, Dongmei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Solving+the+Batch+Stochastic+Bin+Packing+Problem+in+Cloud:+A+Chance-constrained+Optimization+Approach)|0|
|[Causal Discovery on Non-Euclidean Data](https://doi.org/10.1145/3534678.3539485)|Jing Yang, Kai Xie, Ning An||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causal+Discovery+on+Non-Euclidean+Data)|0|
|[Learning Task-relevant Representations for Generalization via Characteristic Functions of Reward Sequence Distributions](https://doi.org/10.1145/3534678.3539391)|Rui Yang, Jie Wang, Zijie Geng, Mingxuan Ye, Shuiwang Ji, Bin Li, Feng Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Task-relevant+Representations+for+Generalization+via+Characteristic+Functions+of+Reward+Sequence+Distributions)|0|
|[Numerical Tuple Extraction from Tables with Pre-training](https://doi.org/10.1145/3534678.3539460)|Qingping Yang, Yixuan Cao, Ping Luo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Numerical+Tuple+Extraction+from+Tables+with+Pre-training)|0|
|[Deconfounding Actor-Critic Network with Policy Adaptation for Dynamic Treatment Regimes](https://doi.org/10.1145/3534678.3539413)|Changchang Yin, Ruoqi Liu, Jeffrey M. Caterino, Ping Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deconfounding+Actor-Critic+Network+with+Policy+Adaptation+for+Dynamic+Treatment+Regimes)|0|
|[LeapAttack: Hard-Label Adversarial Attack on Text via Gradient-Based Optimization](https://doi.org/10.1145/3534678.3539357)|Muchao Ye, Jinghui Chen, Chenglin Miao, Ting Wang, Fenglong Ma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LeapAttack:+Hard-Label+Adversarial+Attack+on+Text+via+Gradient-Based+Optimization)|0|
|[MetroGAN: Simulating Urban Morphology with Generative Adversarial Network](https://doi.org/10.1145/3534678.3539239)|Weiyu Zhang, Yiyang Ma, Di Zhu, Lei Dong, Yu Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MetroGAN:+Simulating+Urban+Morphology+with+Generative+Adversarial+Network)|0|
|[MT-FlowFormer: A Semi-Supervised Flow Transformer for Encrypted Traffic Classification](https://doi.org/10.1145/3534678.3539314)|Ruijie Zhao, Xianwen Deng, Zhicong Yan, Jun Ma, Zhi Xue, Yijun Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MT-FlowFormer:+A+Semi-Supervised+Flow+Transformer+for+Encrypted+Traffic+Classification)|0|
|[Integrity Authentication in Tree Models](https://doi.org/10.1145/3534678.3539428)|Weijie Zhao, Yingjie Lao, Ping Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Integrity+Authentication+in+Tree+Models)|0|
|[Instant Graph Neural Networks for Dynamic Graphs](https://doi.org/10.1145/3534678.3539352)|Yanping Zheng, Hanzhi Wang, Zhewei Wei, Jiajun Liu, Sibo Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Instant+Graph+Neural+Networks+for+Dynamic+Graphs)|0|
|[KRATOS: Context-Aware Cell Type Classification and Interpretation using Joint Dimensionality Reduction and Clustering](https://doi.org/10.1145/3534678.3539455)|Zihan Zhou, Zijia Du, Somali Chaterji||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KRATOS:+Context-Aware+Cell+Type+Classification+and+Interpretation+using+Joint+Dimensionality+Reduction+and+Clustering)|0|
|[Unified 2D and 3D Pre-Training of Molecular Representations](https://doi.org/10.1145/3534678.3539368)|Jinhua Zhu, Yingce Xia, Lijun Wu, Shufang Xie, Tao Qin, Wengang Zhou, Houqiang Li, TieYan Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unified+2D+and+3D+Pre-Training+of+Molecular+Representations)|0|
|[A Nearly-Linear Time Algorithm for Minimizing Risk of Conflict in Social Networks](https://doi.org/10.1145/3534678.3539469)|Liwang Zhu, Zhongzhi Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Nearly-Linear+Time+Algorithm+for+Minimizing+Risk+of+Conflict+in+Social+Networks)|0|
|[A Process-Aware Decision Support System for Business Processes](https://doi.org/10.1145/3534678.3539088)|Prerna Agarwal, Buyu Gao, Siyu Huo, Prabhat Reddy, Sampath Dechu, Yazan Obeidi, Vinod Muthusamy, Vatche Isahagian, Sebastian Carbajales||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Process-Aware+Decision+Support+System+for+Business+Processes)|0|
|[BrainNet: Epileptic Wave Detection from SEEG with Hierarchical Graph Diffusion Learning](https://doi.org/10.1145/3534678.3539178)|Junru Chen, Yang Yang, Tao Yu, Yingying Fan, Xiaolong Mo, Carl Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BrainNet:+Epileptic+Wave+Detection+from+SEEG+with+Hierarchical+Graph+Diffusion+Learning)|0|
|[Ask to Know More: Generating Counterfactual Explanations for Fake Claims](https://doi.org/10.1145/3534678.3539205)|ShihChieh Dai, YiLi Hsu, Aiping Xiong, LunWei Ku||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ask+to+Know+More:+Generating+Counterfactual+Explanations+for+Fake+Claims)|0|
|[The Good, the Bad, and the Outliers: A Testing Framework for Decision Optimization Model Learning](https://doi.org/10.1145/3534678.3539094)|Orit Davidovich, GheorgheTeodor Bercea, Segev Wasserkrug||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Good,+the+Bad,+and+the+Outliers:+A+Testing+Framework+for+Decision+Optimization+Model+Learning)|0|
|[Precise Mobility Intervention for Epidemic Control Using Unobservable Information via Deep Reinforcement Learning](https://doi.org/10.1145/3534678.3539195)|Tao Feng, Tong Xia, Xiaochen Fan, Huandong Wang, Zefang Zong, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Precise+Mobility+Intervention+for+Epidemic+Control+Using+Unobservable+Information+via+Deep+Reinforcement+Learning)|0|
|[DP-GAT: A Framework for Image-based Disease Progression Prediction](https://doi.org/10.1145/3534678.3539113)|Alex Foo, Wynne Hsu, MongLi Lee, Gavin Siew Wei Tan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DP-GAT:+A+Framework+for+Image-based+Disease+Progression+Prediction)|0|
|[Graph Meta-Reinforcement Learning for Transferable Autonomous Mobility-on-Demand](https://doi.org/10.1145/3534678.3539180)|Daniele Gammelli, Kaidi Yang, James Harrison, Filipe Rodrigues, Francisco C. Pereira, Marco Pavone||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Meta-Reinforcement+Learning+for+Transferable+Autonomous+Mobility-on-Demand)|0|
|[Applying Deep Learning Based Probabilistic Forecasting to Food Preparation Time for On-Demand Delivery Service](https://doi.org/10.1145/3534678.3539035)|Chengliang Gao, Fan Zhang, Yue Zhou, Ronggen Feng, Qiang Ru, Kaigui Bian, Renqing He, Zhizhao Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Applying+Deep+Learning+Based+Probabilistic+Forecasting+to+Food+Preparation+Time+for+On-Demand+Delivery+Service)|0|
|[T-Cell Receptor-Peptide Interaction Prediction with Physical Model Augmented Pseudo-Labeling](https://doi.org/10.1145/3534678.3539075)|Yiren Jian, Erik Kruus, Martin Renqiang Min||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=T-Cell+Receptor-Peptide+Interaction+Prediction+with+Physical+Model+Augmented+Pseudo-Labeling)|0|
|[Predicting Bearings Degradation Stages for Predictive Maintenance in the Pharmaceutical Industry](https://doi.org/10.1145/3534678.3539057)|Dovile Juodelyte, Veronika Cheplygina, Therese Graversen, Philippe Bonnet||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Predicting+Bearings+Degradation+Stages+for+Predictive+Maintenance+in+the+Pharmaceutical+Industry)|0|
|[Vexation-Aware Active Learning for On-Menu Restaurant Dish Availability](https://doi.org/10.1145/3534678.3539152)|JeanFrançois Kagy, Flip Korn, Afshin Rostamizadeh, Chris Welty||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Vexation-Aware+Active+Learning+for+On-Menu+Restaurant+Dish+Availability)|0|
|[Preventing Catastrophic Forgetting in Continual Learning of New Natural Language Tasks](https://doi.org/10.1145/3534678.3539169)|Sudipta Kar, Giuseppe Castellucci, Simone Filice, Shervin Malmasi, Oleg Rokhlenko||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Preventing+Catastrophic+Forgetting+in+Continual+Learning+of+New+Natural+Language+Tasks)|0|
|[Self-Supervised Augmentation and Generation for Multi-lingual Text Advertisements at Bing](https://doi.org/10.1145/3534678.3539091)|Xiaoyu Kou, Tianqi Zhao, Fan Zhang, Song Li, Qi Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-Supervised+Augmentation+and+Generation+for+Multi-lingual+Text+Advertisements+at+Bing)|0|
|[TaxoTrans: Taxonomy-Guided Entity Translation](https://doi.org/10.1145/3534678.3539188)|Zhuliu Li, Yiming Wang, Xiao Yan, Weizhi Meng, Yanen Li, Jaewon Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TaxoTrans:+Taxonomy-Guided+Entity+Translation)|0|
|[A Logic Aware Neural Generation Method for Explainable Data-to-text](https://doi.org/10.1145/3534678.3539082)|Xiexiong Lin, Huaisong Li, Tao Huang, Feng Wang, Linlin Chao, Fuzhen Zhuang, Taifeng Wang, Tianyi Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Logic+Aware+Neural+Generation+Method+for+Explainable+Data-to-text)|0|
|[BE3R: BERT based Early-Exit Using Expert Routing](https://doi.org/10.1145/3534678.3539132)|Sourab Mangrulkar, Ankith M. S, Vivek Sembium||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BE3R:+BERT+based+Early-Exit+Using+Expert+Routing)|0|
|[Graph Neural Network Training and Data Tiering](https://doi.org/10.1145/3534678.3539038)|Seungwon Min, Kun Wu, Mert Hidayetoglu, Jinjun Xiong, Xiang Song, WenMei Hwu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Neural+Network+Training+and+Data+Tiering)|0|
|[Generating Examples from CLI Usage: Can Transformers Help?](https://doi.org/10.1145/3534678.3549983)|Roshanak Zilouchian Moghaddam, Spandan Garg, Colin B. Clement, Yevhen Mohylevskyy, Neel Sundaresan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generating+Examples+from+CLI+Usage:+Can+Transformers+Help?)|0|
|[GradMask: Gradient-Guided Token Masking for Textual Adversarial Example Detection](https://doi.org/10.1145/3534678.3539206)|Han Cheol Moon, Shafiq R. Joty, Xu Chi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GradMask:+Gradient-Guided+Token+Masking+for+Textual+Adversarial+Example+Detection)|0|
|[Counterfactual Phenotyping with Censored Time-to-Events](https://doi.org/10.1145/3534678.3539110)|Chirag Nagpal, Mononito Goswami, Keith Dufendach, Artur Dubrawski||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Counterfactual+Phenotyping+with+Censored+Time-to-Events)|0|
|[Crowdsourcing with Contextual Uncertainty](https://doi.org/10.1145/3534678.3539184)|VietAn Nguyen, Peibei Shi, Jagdish Ramakrishnan, Narjes Torabi, Nimar S. Arora, Udi Weinsberg, Michael Tingley||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Crowdsourcing+with+Contextual+Uncertainty)|0|
|[Solar: Science of Entity Loss Attribution](https://doi.org/10.1145/3534678.3539087)|Anshuman Mourya, Prateek Sircar, Anirban Majumder, Deepak Gupta||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Solar:+Science+of+Entity+Loss+Attribution)|0|
|[Packet Representation Learning for Traffic Classification](https://doi.org/10.1145/3534678.3539085)|Xuying Meng, Yequan Wang, Runxin Ma, Haitong Luo, Xiang Li, Yujun Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Packet+Representation+Learning+for+Traffic+Classification)|0|
|[Characterizing Covid Waves via Spatio-Temporal Decomposition](https://doi.org/10.1145/3534678.3539136)|Kevin Quinn, Evimaria Terzi, Mark Crovella||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Characterizing+Covid+Waves+via+Spatio-Temporal+Decomposition)|0|
|[Service Time Prediction for Delivery Tasks via Spatial Meta-Learning](https://doi.org/10.1145/3534678.3539027)|Sijie Ruan, Cheng Long, Zhipeng Ma, Jie Bao, Tianfu He, Ruiyuan Li, Yiheng Chen, Shengnan Wu, Yu Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Service+Time+Prediction+for+Delivery+Tasks+via+Spatial+Meta-Learning)|0|
|[Reinforcement Learning in the Wild: Scalable RL Dispatching Algorithm Deployed in Ridehailing Marketplace](https://doi.org/10.1145/3534678.3539095)|Soheil Sadeghi Eshkevari, Xiaocheng Tang, Zhiwei Qin, Jinhan Mei, Cheng Zhang, Qianying Meng, Jia Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reinforcement+Learning+in+the+Wild:+Scalable+RL+Dispatching+Algorithm+Deployed+in+Ridehailing+Marketplace)|0|
|[Generalized Deep Mixed Models](https://doi.org/10.1145/3534678.3539103)|Jun Shi, Chengming Jiang, Aman Gupta, Mingzhou Zhou, Yunbo Ouyang, Qiang Charles Xiao, Qingquan Song, Yi (Alice) Wu, Haichao Wei, Huiji Gao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generalized+Deep+Mixed+Models)|0|
|[Counseling Summarization Using Mental Health Knowledge Guided Utterance Filtering](https://doi.org/10.1145/3534678.3539187)|Aseem Srivastava, Tharun Suresh, Sarah Peregrine Lord, Md. Shad Akhtar, Tanmoy Chakraborty||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Counseling+Summarization+Using+Mental+Health+Knowledge+Guided+Utterance+Filtering)|0|
|[Few-shot Learning for Trajectory-based Mobile Game Cheating Detection](https://doi.org/10.1145/3534678.3539157)|Yueyang Su, Di Yao, Xiaokai Chu, Wenbin Li, Jingping Bi, Shiwei Zhao, Runze Wu, Shize Zhang, Jianrong Tao, Hao Deng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Few-shot+Learning+for+Trajectory-based+Mobile+Game+Cheating+Detection)|0|
|[RT-VeD: Real-Time VoI Detection on Edge Nodes with an Adaptive Model Selection Framework](https://doi.org/10.1145/3534678.3539183)|Shuai Wang, Junke Lu, Baoshen Guo, Zheng Dong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RT-VeD:+Real-Time+VoI+Detection+on+Edge+Nodes+with+an+Adaptive+Model+Selection+Framework)|0|
|[Representative Routes Discovery from Massive Trajectories](https://doi.org/10.1145/3534678.3539079)|Tingting Wang, Shixun Huang, Zhifeng Bao, J. Shane Culpepper, Reza Arablouei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Representative+Routes+Discovery+from+Massive+Trajectories)|0|
|[Connecting the Hosts: Street-Level IP Geolocation with Graph Neural Networks](https://doi.org/10.1145/3534678.3539049)|Zhiyuan Wang, Fan Zhou, Wenxuan Zeng, Goce Trajcevski, Chunjing Xiao, Yong Wang, Kai Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Connecting+the+Hosts:+Street-Level+IP+Geolocation+with+Graph+Neural+Networks)|0|
|[Graph2Route: A Dynamic Spatial-Temporal Graph Neural Network for Pick-up and Delivery Route Prediction](https://doi.org/10.1145/3534678.3539084)|Haomin Wen, Youfang Lin, Xiaowei Mao, Fan Wu, Yiji Zhao, Haochen Wang, Jianbin Zheng, Lixia Wu, Haoyuan Hu, Huaiyu Wan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph2Route:+A+Dynamic+Spatial-Temporal+Graph+Neural+Network+for+Pick-up+and+Delivery+Route+Prediction)|0|
|[Perioperative Predictions with Interpretable Latent Representation](https://doi.org/10.1145/3534678.3539190)|Bing Xue, York Jiao, Thomas George Kannampallil, Bradley A. Fritz, Christopher Ryan King, Joanna Abraham, Michael Avidan, Chenyang Lu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Perioperative+Predictions+with+Interpretable+Latent+Representation)|0|
|[A Meta Reinforcement Learning Approach for Predictive Autoscaling in the Cloud](https://doi.org/10.1145/3534678.3539063)|Siqiao Xue, Chao Qu, Xiaoming Shi, Cong Liao, Shiyi Zhu, Xiaoyu Tan, Lintao Ma, Shiyu Wang, Shijun Wang, Yun Hu, Lei Lei, Yangfei Zheng, Jianguo Li, James Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Meta+Reinforcement+Learning+Approach+for+Predictive+Autoscaling+in+the+Cloud)|0|
|[CMMD: Cross-Metric Multi-Dimensional Root Cause Analysis](https://doi.org/10.1145/3534678.3539109)|Shifu Yan, Caihua Shan, Wenyi Yang, Bixiong Xu, Dongsheng Li, Lili Qiu, Jie Tong, Qi Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CMMD:+Cross-Metric+Multi-Dimensional+Root+Cause+Analysis)|0|
|[TAG: Toward Accurate Social Media Content Tagging with a Concept Graph](https://doi.org/10.1145/3534678.3539077)|Jiuding Yang, Weidong Guo, Bang Liu, Yakun Yu, Chaoyue Wang, Jinwen Luo, Linglong Kong, Di Niu, Zhen Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TAG:+Toward+Accurate+Social+Media+Content+Tagging+with+a+Concept+Graph)|0|
|[Multilingual Taxonomic Web Page Classification for Contextual Targeting at Yahoo](https://doi.org/10.1145/3534678.3539189)|Eric Ye, Xiao Bai, Neil O'Hare, Eliyar Asgarieh, Kapil Thadani, Francisco PerezSorrosal, Sujyothi Adiga||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multilingual+Taxonomic+Web+Page+Classification+for+Contextual+Targeting+at+Yahoo)|0|
|[A Stochastic Shortest Path Algorithm for Optimizing Spaced Repetition Scheduling](https://doi.org/10.1145/3534678.3539081)|Junyao Ye, Jingyong Su, Yilong Cao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Stochastic+Shortest+Path+Algorithm+for+Optimizing+Spaced+Repetition+Scheduling)|0|
|[Predicting Age-Related Macular Degeneration Progression with Contrastive Attention and Time-Aware LSTM](https://doi.org/10.1145/3534678.3539163)|Changchang Yin, Sayoko E. Moroi, Ping Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Predicting+Age-Related+Macular+Degeneration+Progression+with+Contrastive+Attention+and+Time-Aware+LSTM)|0|
|[Spatio-Temporal Vehicle Trajectory Recovery on Road Network Based on Traffic Camera Video Data](https://doi.org/10.1145/3534678.3539186)|Fudan Yu, Wenxuan Ao, Huan Yan, Guozhen Zhang, Wei Wu, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spatio-Temporal+Vehicle+Trajectory+Recovery+on+Road+Network+Based+on+Traffic+Camera+Video+Data)|0|
|[XDAI: A Tuning-free Framework for Exploiting Pre-trained Language Models in Knowledge Grounded Dialogue Generation](https://doi.org/10.1145/3534678.3539135)|Jifan Yu, Xiaohan Zhang, Yifan Xu, Xuanyu Lei, Xinyu Guan, Jing Zhang, Lei Hou, Juanzi Li, Jie Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=XDAI:+A+Tuning-free+Framework+for+Exploiting+Pre-trained+Language+Models+in+Knowledge+Grounded+Dialogue+Generation)|0|
|[Data-Driven Oracle Bone Rejoining: A Dataset and Practical Self-Supervised Learning Scheme](https://doi.org/10.1145/3534678.3539050)|Chongsheng Zhang, Bin Wang, Ke Chen, Ruixing Zong, Bofeng Mo, Yi Men, George Almpanidis, Shanxiong Chen, Xiangliang Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Data-Driven+Oracle+Bone+Rejoining:+A+Dataset+and+Practical+Self-Supervised+Learning+Scheme)|0|
|[Sparx: Distributed Outlier Detection at Scale](https://doi.org/10.1145/3534678.3539076)|Sean Zhang, Varun Ursekar, Leman Akoglu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sparx:+Distributed+Outlier+Detection+at+Scale)|0|
|[CAT: Beyond Efficient Transformer for Content-Aware Anomaly Detection in Event Sequences](https://doi.org/10.1145/3534678.3539155)|Shengming Zhang, Yanchi Liu, Xuchao Zhang, Wei Cheng, Haifeng Chen, Hui Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CAT:+Beyond+Efficient+Transformer+for+Content-Aware+Anomaly+Detection+in+Event+Sequences)|0|
|[JiuZhang: A Chinese Pre-trained Language Model for Mathematical Problem Understanding](https://doi.org/10.1145/3534678.3539131)|Wayne Xin Zhao, Kun Zhou, Zheng Gong, Beichen Zhang, Yuanhang Zhou, Jing Sha, Zhigang Chen, Shijin Wang, Cong Liu, JiRong Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=JiuZhang:+A+Chinese+Pre-trained+Language+Model+for+Mathematical+Problem+Understanding)|0|
|[Dynamic Graph Segmentation for Deep Graph Neural Networks](https://doi.org/10.1145/3534678.3539111)|Johan Kok Zhi Kang, Suwei Yang, Suriya Venkatesan, Sien Yi Tan, Feng Cheng, Bingsheng He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamic+Graph+Segmentation+for+Deep+Graph+Neural+Networks)|0|
|[Dynamic Network Anomaly Modeling of Cell-Phone Call Detail Records for Infectious Disease Surveillance](https://doi.org/10.1145/3534678.3542678)|Carl Yang, Hongwen Song, Mingyue Tang, Leon Danon, Ymir Vigfusson||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamic+Network+Anomaly+Modeling+of+Cell-Phone+Call+Detail+Records+for+Infectious+Disease+Surveillance)|0|
|[Medical Dialogue Response Generation with Pivotal Information Recalling](https://doi.org/10.1145/3534678.3542674)|Yu Zhao, Yunxin Li, Yuxiang Wu, Baotian Hu, Qingcai Chen, Xiaolong Wang, Yuxin Ding, Min Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Medical+Dialogue+Response+Generation+with+Pivotal+Information+Recalling)|0|
|[Classifying Multimodal Data Using Transformers](https://doi.org/10.1145/3534678.3542634)|Watson W. K. Chua, Lu Li, Alvina Goh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Classifying+Multimodal+Data+Using+Transformers)|0|
|[Hyperbolic Neural Networks: Theory, Architectures and Applications](https://doi.org/10.1145/3534678.3542613)|Nurendra Choudhary, Nikhil Rao, Karthik Subbian, Srinivasan H. Sengamedu, Chandan K. Reddy||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hyperbolic+Neural+Networks:+Theory,+Architectures+and+Applications)|0|
|[Toward Graph Minimally-Supervised Learning](https://doi.org/10.1145/3534678.3542602)|Kaize Ding, Chuxu Zhang, Jie Tang, Nitesh V. Chawla, Huan Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Toward+Graph+Minimally-Supervised+Learning)|0|
|[Frontiers of Graph Neural Networks with DIG](https://doi.org/10.1145/3534678.3542624)|Shuiwang Ji, Meng Liu, Yi Liu, Youzhi Luo, Limei Wang, Yaochen Xie, Zhao Xu, Haiyang Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Frontiers+of+Graph+Neural+Networks+with+DIG)|0|
|[Adapting Pretrained Representations for Text Mining](https://doi.org/10.1145/3534678.3542607)|Yu Meng, Jiaxin Huang, Yu Zhang, Jiawei Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adapting+Pretrained+Representations+for+Text+Mining)|0|
|[Deep Learning for Network Traffic Data](https://doi.org/10.1145/3534678.3542618)|Manish Marwah, Martin F. Arlitt||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Learning+for+Network+Traffic+Data)|0|
|[Temporal Graph Learning for Financial World: Algorithms, Scalability, Explainability & Fairness](https://doi.org/10.1145/3534678.3542619)|Nitendra Rajput, Karamjit Singh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Temporal+Graph+Learning+for+Financial+World:+Algorithms,+Scalability,+Explainability+&+Fairness)|0|
|[Accelerated GNN Training with DGL and RAPIDS cuGraph in a Fraud Detection Workflow](https://doi.org/10.1145/3534678.3542603)|Brad Rees, Xiaoyun Wang, Joe Eaton, Onur Yilmaz, Rick Ratzel, Dominque LaSalle||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Accelerated+GNN+Training+with+DGL+and+RAPIDS+cuGraph+in+a+Fraud+Detection+Workflow)|0|
|[Counterfactual Evaluation and Learning for Interactive Systems: Foundations, Implementations, and Recent Advances](https://doi.org/10.1145/3534678.3542601)|Yuta Saito, Thorsten Joachims||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Counterfactual+Evaluation+and+Learning+for+Interactive+Systems:+Foundations,+Implementations,+and+Recent+Advances)|0|
|[Towards Adversarial Learning: From Evasion Attacks to Poisoning Attacks](https://doi.org/10.1145/3534678.3542608)|Wentao Wang, Han Xu, Yuxuan Wan, Jie Ren, Jiliang Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Adversarial+Learning:+From+Evasion+Attacks+to+Poisoning+Attacks)|0|
|[New Frontiers of Scientific Text Mining: Tasks, Data, and Tools](https://doi.org/10.1145/3534678.3542606)|Xuan Wang, Hongwei Wang, Heng Ji, Jiawei Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=New+Frontiers+of+Scientific+Text+Mining:+Tasks,+Data,+and+Tools)|0|
|[Graph Neural Networks in Life Sciences: Opportunities and Solutions](https://doi.org/10.1145/3534678.3542628)|Zichen Wang, Vassilis N. Ioannidis, Huzefa Rangwala, Tatsuya Arai, Ryan Brand, Mufei Li, Yohei Nakayama||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Neural+Networks+in+Life+Sciences:+Opportunities+and+Solutions)|0|
|[Trustworthy Graph Learning: Reliability, Explainability, and Privacy Protection](https://doi.org/10.1145/3534678.3542597)|Bingzhe Wu, Yatao Bian, Hengtong Zhang, Jintang Li, Junchi Yu, Liang Chen, Chaochao Chen, Junzhou Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Trustworthy+Graph+Learning:+Reliability,+Explainability,+and+Privacy+Protection)|0|
|[Anomaly Detection for Spatiotemporal Data in Action](https://doi.org/10.1145/3534678.3542626)|Guang Yang, Ninad Kulkarni, Paavani Dua, Dipika Khullar, Alex Anto Chirayath||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Anomaly+Detection+for+Spatiotemporal+Data+in+Action)|0|
|[HoloViz: Visualization and Interactive Dashboards in Python](https://doi.org/10.1145/3534678.3542621)|Sophia Yang, Marc Skov Madsen, James A. Bednar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HoloViz:+Visualization+and+Interactive+Dashboards+in+Python)|0|
|[AdKDD 2022](https://doi.org/10.1145/3534678.3542920)|Abraham Bagherjeiran, Nemanja Djuric, Mihajlo Grbovic, KuangChih Lee, Kun Liu, Wei Liu, Linsey Pang, Vladan Radosavljevic, Suju Rajan, Kexin Xie||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AdKDD+2022)|0|
|[Fragile Earth: AI for Climate Mitigation, Adaptation, and Environmental Justice](https://doi.org/10.1145/3534678.3542906)|Naoki Abe, Kathleen Buckingham, Bistra Dilkina, Emre Eftelioglu, Auroop R. Ganguly, James Hodson, Ramakrishnan Kannan, Rose Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fragile+Earth:+AI+for+Climate+Mitigation,+Adaptation,+and+Environmental+Justice)|0|
|[Data-driven Humanitarian Mapping and Policymaking: Toward Planetary-Scale Resilience, Equity, and Sustainability](https://doi.org/10.1145/3534678.3542918)|Snehalkumar (Neil) S. Gaikwad, Shankar Iyer, Dalton D. Lunga, Takahiro Yabe, Xiaofan Liang, Bhavani Ananthabhotla, Nikhil Behari, Sreelekha Guggilam, Guanghua Chi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Data-driven+Humanitarian+Mapping+and+Policymaking:+Toward+Planetary-Scale+Resilience,+Equity,+and+Sustainability)|0|
|[ANDEA: Anomaly and Novelty Detection, Explanation, and Accommodation](https://doi.org/10.1145/3534678.3542910)|Guansong Pang, Jundong Li, Anton van den Hengel, Longbing Cao, Thomas G. Dietterich||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ANDEA:+Anomaly+and+Novelty+Detection,+Explanation,+and+Accommodation)|0|
|[Visualization in Data Science VDS @ KDD 2022](https://doi.org/10.1145/3534678.3542903)|Claudia Plant, Nina C. Hubig, Junming Shao, Alvitta Ottley, Liang Gou, Torsten Möller, Adam Perer, Alexander Lex, Anamaria Crisan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Visualization+in+Data+Science+VDS+@+KDD+2022)|0|
|[Deep Learning on Graphs: Methods and Applications (DLG-KDD2022)](https://doi.org/10.1145/3534678.3542907)|Lingfei Wu, Jian Pei, Jiliang Tang, Yinglong Xia, Xiaojie Guo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Learning+on+Graphs:+Methods+and+Applications+(DLG-KDD2022))|0|

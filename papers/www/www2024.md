# WWW2024 Paper List

|论文|作者|组织|摘要|翻译|代码|引用数|
|---|---|---|---|---|---|---|
|[Unmasking the Web of Deceit: Uncovering Coordinated Activity to Expose Information Operations on Twitter](https://doi.org/10.1145/3589334.3645529)|Luca Luceri, Valeria Pantè, Keith Burghardt, Emilio Ferrara||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unmasking+the+Web+of+Deceit:+Uncovering+Coordinated+Activity+to+Expose+Information+Operations+on+Twitter)|2|
|[Blockchain Censorship](https://doi.org/10.1145/3589334.3645431)|Anton Wahrstätter, Jens Ernstberger, Aviv Yaish, Liyi Zhou, Kaihua Qin, Taro Tsuchiya, Sebastian Steinhorst, Davor Svetinovic, Nicolas Christin, Mikolaj Barczentewicz, Arthur Gervais||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Blockchain+Censorship)|2|
|[Fast Graph Condensation with Structure-based Neural Tangent Kernel](https://doi.org/10.1145/3589334.3645694)|Lin Wang, Wenqi Fan, Jiatong Li, Yao Ma, Qing Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fast+Graph+Condensation+with+Structure-based+Neural+Tangent+Kernel)|2|
|[Susceptibility to Unreliable Information Sources: Swift Adoption with Minimal Exposure](https://doi.org/10.1145/3589334.3648154)|Jinyi Ye, Luca Luceri, Julie Jiang, Emilio Ferrara||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Susceptibility+to+Unreliable+Information+Sources:+Swift+Adoption+with+Minimal+Exposure)|2|
|[Personalized Audiobook Recommendations at Spotify Through Graph Neural Networks](https://doi.org/10.1145/3589335.3648339)|Marco De Nadai, Francesco Fabbri, Paul Gigioli, Alice Wang, Ang Li, Fabrizio Silvestri, Laura Kim, Shawn Lin, Vladan Radosavljevic, Sandeep Ghael, David Nyhan, Hugues Bouchard, Mounia Lalmas, Andreas Damianou||In the ever-evolving digital audio landscape, Spotify, well-known for its music and talk content, has recently introduced audiobooks to its vast user base. While promising, this move presents significant challenges for personalized recommendations. Unlike music and podcasts, audiobooks, initially available for a fee, cannot be easily skimmed before purchase, posing higher stakes for the relevance of recommendations. Furthermore, introducing a new content type into an existing platform confronts extreme data sparsity, as most users are unfamiliar with this new content type. Lastly, recommending content to millions of users requires the model to react fast and be scalable. To address these challenges, we leverage podcast and music user preferences and introduce 2T-HGNN, a scalable recommendation system comprising Heterogeneous Graph Neural Networks (HGNNs) and a Two Tower (2T) model. This novel approach uncovers nuanced item relationships while ensuring low latency and complexity. We decouple users from the HGNN graph and propose an innovative multi-link neighbor sampler. These choices, together with the 2T component, significantly reduce the complexity of the HGNN model. Empirical evaluations involving millions of users show significant improvement in the quality of personalized recommendations, resulting in a +46 a +23 beyond audiobooks, benefiting established products like podcasts.|在不断发展的数字音频领域，以音乐和谈话内容闻名的 Spotify 最近向其庞大的用户群推出了有声读物。尽管前景看好，但这一举措对个性化推荐提出了重大挑战。与音乐和播客不同，有声书籍最初是收费的，不能在购买前轻易浏览，这对推荐的相关性构成了更大的威胁。此外，在现有平台中引入新的内容类型会面临数据极度稀缺的问题，因为大多数用户不熟悉这种新的内容类型。最后，向数百万用户推荐内容需要模型快速反应和可伸缩性。为了应对这些挑战，我们利用播客和音乐用户的偏好，引入了2T-HGNN，一个由异构图神经网络(HGNN)和双塔(2T)模型组成的可扩展推荐系统。这种新颖的方法揭示了细微的项目关系，同时确保低延迟和复杂性。我们从 HGNN 图解耦用户，并提出了一个创新的多链路邻居采样器。这些选择以及2T 组件显著降低了 HGNN 模型的复杂性。涉及数百万用户的经验性评价显示，个性化推荐的质量有了显著提高，在有声读物之外产生了 + 46 a + 23，使播客等既有产品受益。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Audiobook+Recommendations+at+Spotify+Through+Graph+Neural+Networks)|1|
|[Intelligent Model Update Strategy for Sequential Recommendation](https://doi.org/10.1145/3589334.3645316)|Zheqi Lv, Wenqiao Zhang, Zhengyu Chen, Shengyu Zhang, Kun Kuang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Intelligent+Model+Update+Strategy+for+Sequential+Recommendation)|1|
|[Top-Personalized-K Recommendation](https://doi.org/10.1145/3589334.3645417)|Wonbin Kweon, SeongKu Kang, Sanghwan Jang, Hwanjo Yu||The conventional top-K recommendation, which presents the top-K items with the highest ranking scores, is a common practice for generating personalized ranking lists. However, is this fixed-size top-K recommendation the optimal approach for every user's satisfaction? Not necessarily. We point out that providing fixed-size recommendations without taking into account user utility can be suboptimal, as it may unavoidably include irrelevant items or limit the exposure to relevant ones. To address this issue, we introduce Top-Personalized-K Recommendation, a new recommendation task aimed at generating a personalized-sized ranking list to maximize individual user satisfaction. As a solution to the proposed task, we develop a model-agnostic framework named PerK. PerK estimates the expected user utility by leveraging calibrated interaction probabilities, subsequently selecting the recommendation size that maximizes this expected utility. Through extensive experiments on real-world datasets, we demonstrate the superiority of PerK in Top-Personalized-K recommendation task. We expect that Top-Personalized-K recommendation has the potential to offer enhanced solutions for various real-world recommendation scenarios, based on its great compatibility with existing models.|传统的 top-K 推荐是生成个性化排名列表的一种常见实践，它给出排名最高的 top-K 项目。然而，这个固定大小的 top-K 推荐是否是每个用户满意度的最佳方法？不一定。我们指出，在不考虑用户效用的情况下提供固定大小的推荐可能是次优的，因为它可能不可避免地包括不相关的项目或限制相关项目的曝光。为了解决这个问题，我们引入了 Top-Personalization-K 推荐，这是一个新的推荐任务，旨在产生一个个性化大小的排名列表，以最大限度地提高个人用户的满意度。作为提出的任务的解决方案，我们开发了一个名为 PerK 的模型无关框架。PerK 通过利用校准的交互概率来估计预期的用户效用，随后选择最大化这个预期效用的推荐大小。通过对实际数据集的大量实验，验证了 PerK 在 Top-Personalization-K 推荐任务中的优越性。我们期望 Top-Personalization-K 推荐基于其与现有模型的巨大兼容性，有潜力为各种真实世界的推荐场景提供增强的解决方案。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Top-Personalized-K+Recommendation)|1|
|[AgentCF: Collaborative Learning with Autonomous Language Agents for Recommender Systems](https://doi.org/10.1145/3589334.3645537)|Junjie Zhang, Yupeng Hou, Ruobing Xie, Wenqi Sun, Julian J. McAuley, Wayne Xin Zhao, Leyu Lin, JiRong Wen||Recently, there has been an emergence of employing LLM-powered agents as believable human proxies, based on their remarkable decision-making capability. However, existing studies mainly focus on simulating human dialogue. Human non-verbal behaviors, such as item clicking in recommender systems, although implicitly exhibiting user preferences and could enhance the modeling of users, have not been deeply explored. The main reasons lie in the gap between language modeling and behavior modeling, as well as the incomprehension of LLMs about user-item relations. To address this issue, we propose AgentCF for simulating user-item interactions in recommender systems through agent-based collaborative filtering. We creatively consider not only users but also items as agents, and develop a collaborative learning approach that optimizes both kinds of agents together. Specifically, at each time step, we first prompt the user and item agents to interact autonomously. Then, based on the disparities between the agents' decisions and real-world interaction records, user and item agents are prompted to reflect on and adjust the misleading simulations collaboratively, thereby modeling their two-sided relations. The optimized agents can also propagate their preferences to other agents in subsequent interactions, implicitly capturing the collaborative filtering idea. Overall, the optimized agents exhibit diverse interaction behaviors within our framework, including user-item, user-user, item-item, and collective interactions. The results show that these agents can demonstrate personalized behaviors akin to those of real-world individuals, sparking the development of next-generation user behavior simulation.|近年来，基于 LLM 驱动的智能体显著的决策能力，出现了一种使用 LLM 驱动的智能体作为可信的人类代理的方法。然而，现有的研究主要集中在模拟人类对话方面。人类的非语言行为，如推荐系统中的项目点击，虽然隐含地表现出用户的偏好，可以增强用户的建模，但还没有被深入探索。其主要原因在于语言建模与行为建模之间的差距，以及对用户-项目关系的 LLM 模型的不理解。为了解决这个问题，我们建议 AgentCF 通过基于代理的协同过滤来模拟推荐系统中的用户-项目交互。我们不仅创造性地考虑用户，而且还将物品作为代理，并开发一种合作学习的方法，将这两种代理结合起来优化。具体来说，在每个步骤中，我们首先提示用户和项代理自主交互。然后，基于智能体的决策与实际交互记录之间的差异，提示用户和项目智能体协同反思和调整误导性模拟，从而建立它们之间的双边关系模型。经过优化的代理还可以在随后的交互中将自己的偏好传播给其他代理，从而隐含地捕捉到协同过滤的想法。总的来说，优化的代理在我们的框架中展示了不同的交互行为，包括用户-项目、用户-用户、项目-项目和集体交互。结果表明，这些代理能够表现出类似于真实世界个体的个性化行为，从而推动了下一代用户行为仿真的发展。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AgentCF:+Collaborative+Learning+with+Autonomous+Language+Agents+for+Recommender+Systems)|1|
|[Aligning Language Models for Versatile Text-based Item Retrieval](https://doi.org/10.1145/3589335.3651468)|Yuxuan Lei, Jianxun Lian, Jing Yao, Mingqi Wu, Defu Lian, Xing Xie||This paper addresses the gap between general-purpose text embeddings and the specific demands of item retrieval tasks. We demonstrate the shortcomings of existing models in capturing the nuances necessary for zero-shot performance on item retrieval tasks. To overcome these limitations, we propose generate in-domain dataset from ten tasks tailored to unlocking models' representation ability for item retrieval. Our empirical studies demonstrate that fine-tuning embedding models on the dataset leads to remarkable improvements in a variety of retrieval tasks. We also illustrate the practical application of our refined model in a conversational setting, where it enhances the capabilities of LLM-based Recommender Agents like Chat-Rec. Our code is available at https://github.com/microsoft/RecAI.|本文探讨了通用文本嵌入与项目检索任务的具体要求之间的差距。我们证明了现有模型在捕捉项目检索任务中零拍性能所必需的细微差别方面的不足。为了克服这些限制，我们提出从十个任务中生成域内数据集，以解锁项目检索模型的表示能力。我们的实证研究表明，在数据集上微调嵌入模型可以显著改善各种检索任务。我们还举例说明了我们的改进模型在会话环境中的实际应用，它增强了基于 LLM 的推荐代理(如 Chat-Rec)的功能。我们的代码可以在 https://github.com/microsoft/recai 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Aligning+Language+Models+for+Versatile+Text-based+Item+Retrieval)|1|
|[Macro Graph Neural Networks for Online Billion-Scale Recommender Systems](https://doi.org/10.1145/3589334.3645517)|Hao Chen, Yuanchen Bei, Qijie Shen, Yue Xu, Sheng Zhou, Wenbing Huang, Feiran Huang, Senzhang Wang, Xiao Huang||Predicting Click-Through Rate (CTR) in billion-scale recommender systems poses a long-standing challenge for Graph Neural Networks (GNNs) due to the overwhelming computational complexity involved in aggregating billions of neighbors. To tackle this, GNN-based CTR models usually sample hundreds of neighbors out of the billions to facilitate efficient online recommendations. However, sampling only a small portion of neighbors results in a severe sampling bias and the failure to encompass the full spectrum of user or item behavioral patterns. To address this challenge, we name the conventional user-item recommendation graph as "micro recommendation graph" and introduce a more suitable MAcro Recommendation Graph (MAG) for billion-scale recommendations. MAG resolves the computational complexity problems in the infrastructure by reducing the node count from billions to hundreds. Specifically, MAG groups micro nodes (users and items) with similar behavior patterns to form macro nodes. Subsequently, we introduce tailored Macro Graph Neural Networks (MacGNN) to aggregate information on a macro level and revise the embeddings of macro nodes. MacGNN has already served Taobao's homepage feed for two months, providing recommendations for over one billion users. Extensive offline experiments on three public benchmark datasets and an industrial dataset present that MacGNN significantly outperforms twelve CTR baselines while remaining computationally efficient. Besides, online A/B tests confirm MacGNN's superiority in billion-scale recommender systems.|在十亿规模的推荐系统中预测点进率(CTR)对于图形神经网络(GNN)来说是一个长期存在的挑战，因为聚合数十亿个邻居涉及到极其复杂的计算。为了解决这个问题，基于 GNN 的点击率模型通常从数十亿个邻居中抽样数百个，以促进有效的在线推荐。然而，只有一小部分邻居的抽样导致严重的抽样偏差和未能涵盖用户或项目的行为模式的全部范围。为了解决这个问题，我们将传统的用户项目推荐图命名为“微推荐图”，并为十亿级推荐引入了更合适的宏推荐图(MAG)。MAG 通过将节点数从几十亿减少到几百个，解决了基础设施中的计算复杂度问题。具体来说，MAG 将具有相似行为模式的微节点(用户和项)分组以形成宏节点。随后，我们引入量身定制的宏图神经网络(MacGNN) ，在宏观层面上聚集信息，并修正宏观节点的嵌入。MacGNN 已经为淘宝网服务了两个月，为超过十亿用户提供推荐。针对三个公共基准数据集和一个工业数据集进行的大量离线实验表明，MacGNN 在保持计算效率的同时，显著优于十二个点击率基准。此外，在线 A/B 测试证实了 MacGNN 在数十亿规模的推荐系统中的优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Macro+Graph+Neural+Networks+for+Online+Billion-Scale+Recommender+Systems)|1|
|[Doubly Calibrated Estimator for Recommendation on Data Missing Not at Random](https://doi.org/10.1145/3589334.3645617)|Wonbin Kweon, Hwanjo Yu||Recommender systems often suffer from selection bias as users tend to rate their preferred items. The datasets collected under such conditions exhibit entries missing not at random and thus are not randomized-controlled trials representing the target population. To address this challenge, a doubly robust estimator and its enhanced variants have been proposed as they ensure unbiasedness when accurate imputed errors or predicted propensities are provided. However, we argue that existing estimators rely on miscalibrated imputed errors and propensity scores as they depend on rudimentary models for estimation. We provide theoretical insights into how miscalibrated imputation and propensity models may limit the effectiveness of doubly robust estimators and validate our theorems using real-world datasets. On this basis, we propose a Doubly Calibrated Estimator that involves the calibration of both the imputation and propensity models. To achieve this, we introduce calibration experts that consider different logit distributions across users. Moreover, we devise a tri-level joint learning framework, allowing the simultaneous optimization of calibration experts alongside prediction and imputation models. Through extensive experiments on real-world datasets, we demonstrate the superiority of the Doubly Calibrated Estimator in the context of debiased recommendation tasks.|推荐系统经常受到选择偏差的影响，因为用户倾向于对他们喜欢的项目进行评分。在这种条件下收集的数据集显示条目不是随机丢失的，因此不是代表目标人群的随机对照试验。为了应对这一挑战，提出了一种双稳健估计器及其增强变量，以确保在提供准确的估计误差或预测倾向时的无偏性。然而，我们认为，现有的估计依赖于错误校准估算误差和倾向得分，因为他们依赖于估计的基本模型。我们提供的理论见解，如何错误校准插补和倾向模型可以限制双鲁棒估计器的有效性，并验证我们的定理使用真实世界的数据集。在此基础上，我们提出了一个双校正估计，涉及校准的插补和倾向模型。为了实现这一点，我们介绍了校准专家，他们考虑了不同用户之间的 logit 分布。此外，我们设计了一个三级联合学习框架，使校准专家同时优化预测和插补模型。通过对实际数据集的大量实验，我们证明了双校正估计器在去偏推荐任务中的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Doubly+Calibrated+Estimator+for+Recommendation+on+Data+Missing+Not+at+Random)|1|
|[Item-side Fairness of Large Language Model-based Recommendation System](https://doi.org/10.1145/3589334.3648158)|Meng Jiang, Keqin Bao, Jizhi Zhang, Wenjie Wang, Zhengyi Yang, Fuli Feng, Xiangnan He||Recommendation systems for Web content distribution intricately connect to the information access and exposure opportunities for vulnerable populations. The emergence of Large Language Models-based Recommendation System (LRS) may introduce additional societal challenges to recommendation systems due to the inherent biases in Large Language Models (LLMs). From the perspective of item-side fairness, there remains a lack of comprehensive investigation into the item-side fairness of LRS given the unique characteristics of LRS compared to conventional recommendation systems. To bridge this gap, this study examines the property of LRS with respect to item-side fairness and reveals the influencing factors of both historical users' interactions and inherent semantic biases of LLMs, shedding light on the need to extend conventional item-side fairness methods for LRS. Towards this goal, we develop a concise and effective framework called IFairLRS to enhance the item-side fairness of an LRS. IFairLRS covers the main stages of building an LRS with specifically adapted strategies to calibrate the recommendations of LRS. We utilize IFairLRS to fine-tune LLaMA, a representative LLM, on MovieLens and Steam datasets, and observe significant item-side fairness improvements. The code can be found in https://github.com/JiangM-C/IFairLRS.git.|网络内容分发推荐系统与弱势群体的信息获取和接触机会错综复杂地联系在一起。基于大语言模型的推荐系统(LRS)的出现可能会给推荐系统带来额外的社会挑战，因为大语言模型(LLM)存在固有的偏差。由于推荐系统与传统推荐系统相比具有独特的特点，从项目侧公平的角度来看，对于推荐系统的项目侧公平性缺乏全面的研究。为了弥补这一差距，本研究考察了 LRS 在项目侧公平性方面的性质，揭示了历史用户交互和 LLM 固有语义偏差的影响因素，阐明了传统项目侧公平性方法在 LRS 中扩展的必要性。为了实现这一目标，我们开发了一个简洁有效的框架，称为 IFairLRS，以增强 LRS 项目的公平性。IFairLRS 涵盖了建立 LRS 的主要阶段，其中特别采用了校准 LRS 建议的策略。我们利用 IFairLRS 在 MovieLens 和 STEAM 数据集上对 LLaMA (一种代表性的 LLM)进行微调，并观察到显著的项目端公平性改进。密码可以在 https://github.com/jiangm-c/ifairlrs.git 中找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Item-side+Fairness+of+Large+Language+Model-based+Recommendation+System)|1|
|[Dynamic Contexts for Generating Suggestion Questions in RAG Based Conversational Systems](https://doi.org/10.1145/3589335.3651905)|Anuja Tayal, Aman Tyagi||When interacting with Retrieval-Augmented Generation (RAG)-based conversational agents, the users must carefully craft their queries to be understood correctly. Yet, understanding the system's capabilities can be challenging for the users, leading to ambiguous questions that necessitate further clarification. This work aims to bridge the gap by developing a suggestion question generator. To generate suggestion questions, our approach involves utilizing dynamic context, which includes both dynamic few-shot examples and dynamically retrieved contexts. Through experiments, we show that the dynamic contexts approach can generate better suggestion questions as compared to other prompting approaches.|当与基于检索增强生成(RAG)的会话代理交互时，用户必须精心设计他们的查询才能被正确理解。然而，理解系统的功能对用户来说可能是一个挑战，导致需要进一步澄清的模棱两可的问题。本研究旨在通过开发一个建议问题产生器来弥补这一差距。为了产生建议问题，我们的方法涉及到利用动态上下文，其中包括动态少镜头示例和动态检索的上下文。通过实验，我们发现动态语境法比其他激励方法能够产生更好的建议问题。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamic+Contexts+for+Generating+Suggestion+Questions+in+RAG+Based+Conversational+Systems)|1|
|[Linear-Time Graph Neural Networks for Scalable Recommendations](https://doi.org/10.1145/3589334.3645486)|Jiahao Zhang, Rui Xue, Wenqi Fan, Xin Xu, Qing Li, Jian Pei, Xiaorui Liu||In an era of information explosion, recommender systems are vital tools to deliver personalized recommendations for users. The key of recommender systems is to forecast users' future behaviors based on previous user-item interactions. Due to their strong expressive power of capturing high-order connectivities in user-item interaction data, recent years have witnessed a rising interest in leveraging Graph Neural Networks (GNNs) to boost the prediction performance of recommender systems. Nonetheless, classic Matrix Factorization (MF) and Deep Neural Network (DNN) approaches still play an important role in real-world large-scale recommender systems due to their scalability advantages. Despite the existence of GNN-acceleration solutions, it remains an open question whether GNN-based recommender systems can scale as efficiently as classic MF and DNN methods. In this paper, we propose a Linear-Time Graph Neural Network (LTGNN) to scale up GNN-based recommender systems to achieve comparable scalability as classic MF approaches while maintaining GNNs' powerful expressiveness for superior prediction accuracy. Extensive experiments and ablation studies are presented to validate the effectiveness and scalability of the proposed algorithm. Our implementation based on PyTorch is available.|在信息爆炸的时代，推荐系统是为用户提供个性化推荐的重要工具。推荐系统的关键是根据用户之前的交互行为预测用户的未来行为。由于它们在用户交互数据中捕获高阶连接性的强大表达能力，近年来人们对利用图形神经网络(GNN)来提高推荐系统的预测性能越来越感兴趣。尽管如此，经典的矩阵分解(MF)和深度神经网络(DNN)方法仍然在现实世界的大规模推荐系统中发挥着重要作用，因为它们具有可扩展性的优势。尽管存在 GNN 加速解决方案，但是基于 GNN 的推荐系统能否像经典的 MF 和 DNN 方法那样有效地扩展仍然是一个悬而未决的问题。本文提出了一种线性时间图神经网络(LTGNN)来扩展基于 GNN 的推荐系统，以实现与经典 MF 方法相当的可扩展性，同时保持 GNN 的强大表达能力，获得更高的预测精度。通过大量的实验和烧蚀研究，验证了该算法的有效性和可扩展性。我们基于 PyTorch 的实现是可用的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Linear-Time+Graph+Neural+Networks+for+Scalable+Recommendations)|1|
|[Collaborate to Adapt: Source-Free Graph Domain Adaptation via Bi-directional Adaptation](https://doi.org/10.1145/3589334.3645507)|Zhen Zhang, Meihan Liu, Anhui Wang, Hongyang Chen, Zhao Li, Jiajun Bu, Bingsheng He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Collaborate+to+Adapt:+Source-Free+Graph+Domain+Adaptation+via+Bi-directional+Adaptation)|1|
|[Assessing Web Fingerprinting Risk](https://doi.org/10.1145/3589335.3648322)|Enrico Bacis, Igor Bilogrevic, Róbert BusaFekete, Asanka Herath, Antonio Sartori, Umar Syed||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Assessing+Web+Fingerprinting+Risk)|1|
|[Large Language Model Powered Agents in the Web](https://doi.org/10.1145/3589335.3641240)|Yang Deng, An Zhang, Yankai Lin, Xu Chen, JiRong Wen, TatSeng Chua||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large+Language+Model+Powered+Agents+in+the+Web)|1|
|[Automatic Design Summary Generation with Generative AI](https://doi.org/10.1145/3589335.3651901)|Daisuke Ikoma, Eisuke Aoki, Tomoki Taniguchi, Shinya Suzuki, Tomoko Ohkuma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automatic+Design+Summary+Generation+with+Generative+AI)|1|
|[Data Augmentation for Smishing Detection: A Theory-based Prompt Engineering Approach](https://doi.org/10.1145/3589335.3651903)|Ho Sung Shim, Hyoungjun Park, Kyuhan Lee, JangSun Park, Seonhye Kang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Data+Augmentation+for+Smishing+Detection:+A+Theory-based+Prompt+Engineering+Approach)|1|
|[Prompt-Eng: Healthcare Prompt Engineering: Revolutionizing Healthcare Applications with Precision Prompts](https://doi.org/10.1145/3589335.3651904)|Awais Ahmed, Mengshu Hou, Rui Xi, Xiaoyang Zeng, Syed Attique Shah||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Prompt-Eng:+Healthcare+Prompt+Engineering:+Revolutionizing+Healthcare+Applications+with+Precision+Prompts)|1|
|[Implementing Sustainable Urban Mobility Transitions in Positive Energy Districts](https://doi.org/10.1145/3589335.3651899)|Dirk Ahlers, Bjørn Ove Berthelsen, Tor Rune Skoglund, Kelly Riedesel||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Implementing+Sustainable+Urban+Mobility+Transitions+in+Positive+Energy+Districts)|1|
|[Contextualizing Internet Memes Across Social Media Platforms](https://doi.org/10.1145/3589335.3651970)|Saurav Joshi, Filip Ilievski, Luca Luceri||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contextualizing+Internet+Memes+Across+Social+Media+Platforms)|1|
|[Faithful Temporal Question Answering over Heterogeneous Sources](https://doi.org/10.1145/3589334.3645547)|Zhen Jia, Philipp Christmann, Gerhard Weikum||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Faithful+Temporal+Question+Answering+over+Heterogeneous+Sources)|1|
|[From Shapes to Shapes: Inferring SHACL Shapes for Results of SPARQL CONSTRUCT Queries](https://doi.org/10.1145/3589334.3645550)|Philipp Seifer, Daniel Hernández, Ralf Lämmel, Steffen Staab||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=From+Shapes+to+Shapes:+Inferring+SHACL+Shapes+for+Results+of+SPARQL+CONSTRUCT+Queries)|1|
|[A Multifaceted Look at Starlink Performance](https://doi.org/10.1145/3589334.3645328)|Nitinder Mohan, Andrew E. Ferguson, Hendrik Cech, Rohan Bose, Prakita Rayyan Renatin, Mahesh K. Marina, Jörg Ott||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Multifaceted+Look+at+Starlink+Performance)|1|
|[Best of Three Worlds: Adaptive Experimentation for Digital Marketing in Practice](https://doi.org/10.1145/3589334.3645504)|Tanner Fiez, Houssam Nassif, YuCheng Chen, Sergio Gamez, Lalit Jain||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Best+of+Three+Worlds:+Adaptive+Experimentation+for+Digital+Marketing+in+Practice)|1|
|[PRINT: Personalized Relevance Incentive Network for CTR Prediction in Sponsored Search](https://doi.org/10.1145/3589335.3648316)|Zhaolin Hong, Haitao Wang, Chengjie Qian, Wei Chen, Tianqi He, Yajie Zou, Qiang Liu, Xingxing Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PRINT:+Personalized+Relevance+Incentive+Network+for+CTR+Prediction+in+Sponsored+Search)|0|
|[Dynamic Search Results Re-ranking Method by Advertisement Relevance Feedback based on Users' Unconscious Expectations for Listing Advertisement](https://doi.org/10.1145/3589335.3651495)|Da Li, Shigenaga Hamaguchi, Ruman Suyama, Shinsuke Nakajima, Yukiko Kawai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamic+Search+Results+Re-ranking+Method+by+Advertisement+Relevance+Feedback+based+on+Users'+Unconscious+Expectations+for+Listing+Advertisement)|0|
|[Adversarial-Enhanced Causal Multi-Task Framework for Debiasing Post-Click Conversion Rate Estimation](https://doi.org/10.1145/3589334.3645379)|Xinyue Zhang, Cong Huang, Kun Zheng, Hongzu Su, Tianxu Ji, Wei Wang, Hongkai Qi, Jingjing Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adversarial-Enhanced+Causal+Multi-Task+Framework+for+Debiasing+Post-Click+Conversion+Rate+Estimation)|0|
|[Enhancing Sequential Recommendation via LLM-based Semantic Embedding Learning](https://doi.org/10.1145/3589335.3648307)|Jun Hu, Wenwen Xia, Xiaolu Zhang, Chilin Fu, Weichang Wu, Zhaoxin Huan, Ang Li, Zuoli Tang, Jun Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Sequential+Recommendation+via+LLM-based+Semantic+Embedding+Learning)|0|
|[OmniSearchSage: Multi-Task Multi-Entity Embeddings for Pinterest Search](https://doi.org/10.1145/3589335.3648309)|Prabhat Agarwal, Minhazul Islam SK, Nikil Pancha, Kurchi Subhra Hazra, Jiajing Xu, Chuck Rosenberg||In this paper, we present OmniSearchSage, a versatile and scalable system for understanding search queries, pins, and products for Pinterest search. We jointly learn a unified query embedding coupled with pin and product embeddings, leading to an improvement of >8% relevance, >7% engagement, and >5% ads CTR in Pinterest's production search system. The main contributors to these gains are improved content understanding, better multi-task learning, and real-time serving. We enrich our entity representations using diverse text derived from image captions from a generative LLM, historical engagement, and user-curated boards. Our multitask learning setup produces a single search query embedding in the same space as pin and product embeddings and compatible with pre-existing pin and product embeddings. We show the value of each feature through ablation studies, and show the effectiveness of a unified model compared to standalone counterparts. Finally, we share how these embeddings have been deployed across the Pinterest search stack, from retrieval to ranking, scaling to serve 300k requests per second at low latency. Our implementation of this work is available at https://github.com/pinterest/atg-research/tree/main/omnisearchsage.|在本文中，我们介绍 OmniSearchSage，这是一个通用的、可扩展的系统，用于理解 Pinterest 搜索的查询、引脚和产品。我们共同学习了一个统一的查询嵌入结合引脚和产品嵌入，导致在 Pinterest 的产品搜索系统中相关性提高 > 8% ，参与度提高 > 7% ，广告点击率提高 > 5% 。这些收获的主要贡献者是改进的内容理解、更好的多任务学习和实时服务。我们丰富了我们的实体表示使用不同的文字衍生自一个生成 LLM 的图像标题，历史参与和用户策划的董事会。我们的多任务学习设置产生一个单一的搜索查询嵌入在同样的空间作为引脚和产品嵌入和兼容预先存在的引脚和产品嵌入。我们通过烧蚀研究显示了每个特征的价值，并且与独立的对应物相比，显示了统一模型的有效性。最后，我们将分享如何在 Pinterest 搜索堆栈中部署这些嵌入，从检索到排名，扩展到以低延迟每秒30万个请求。我们的这项工作可以在 https://github.com/pinterest/atg-research/tree/main/omnisearchsage 得到落实。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=OmniSearchSage:+Multi-Task+Multi-Entity+Embeddings+for+Pinterest+Search)|0|
|[ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation](https://doi.org/10.1145/3589334.3645467)|Jianghao Lin, Rong Shan, Chenxu Zhu, Kounianhua Du, Bo Chen, Shigang Quan, Ruiming Tang, Yong Yu, Weinan Zhang||With large language models (LLMs) achieving remarkable breakthroughs in natural language processing (NLP) domains, LLM-enhanced recommender systems have received much attention and have been actively explored currently. In this paper, we focus on adapting and empowering a pure large language model for zero-shot and few-shot recommendation tasks. First and foremost, we identify and formulate the lifelong sequential behavior incomprehension problem for LLMs in recommendation domains, i.e., LLMs fail to extract useful information from a textual context of long user behavior sequence, even if the length of context is far from reaching the context limitation of LLMs. To address such an issue and improve the recommendation performance of LLMs, we propose a novel framework, namely Retrieval-enhanced Large Language models (ReLLa) for recommendation tasks in both zero-shot and few-shot settings. For zero-shot recommendation, we perform semantic user behavior retrieval (SUBR) to improve the data quality of testing samples, which greatly reduces the difficulty for LLMs to extract the essential knowledge from user behavior sequences. As for few-shot recommendation, we further design retrieval-enhanced instruction tuning (ReiT) by adopting SUBR as a data augmentation technique for training samples. Specifically, we develop a mixed training dataset consisting of both the original data samples and their retrieval-enhanced counterparts. We conduct extensive experiments on three real-world public datasets to demonstrate the superiority of ReLLa compared with existing baseline models, as well as its capability for lifelong sequential behavior comprehension. To be highlighted, with only less than 10 traditional CTR models that are trained on the entire training set (e.g., DCNv2, DIN, SIM). The code is available <https://github.com/LaVieEnRose365/ReLLa>.|随着大型语言模型(LLM)在自然语言处理(NLP)领域取得显著突破，LLM 增强型推荐系统受到了广泛关注，目前正在积极探索之中。在本文中，我们着重于适应和授权一个纯大型语言模型来完成零镜头和少镜头的推荐任务。首先，我们确定并制定了推荐域中 LLM 的终身序列行为不理解问题，即 LLM 不能从长用户行为序列的文本上下文中提取有用的信息，即使上下文的长度远未达到 LLM 的上下文限制。为了解决这一问题，提高 LLM 的推荐性能，我们提出了一种新的框架，即检索增强的大语言模型(ReLLa) ，用于在零镜头和少镜头情况下的推荐任务。对于零镜头推荐，我们通过语义用户行为检索(SUBR)来提高测试样本的数据质量，大大降低了 LLM 从用户行为序列中提取基本知识的难度。对于少镜头推荐，我们采用 SUBR 作为训练样本的数据增强技术，进一步设计了检索增强型指令调优(ReiT)。具体来说，我们开发了一个混合训练数据集，包括原始数据样本和它们的检索增强对应物。我们在三个真实世界的公共数据集上进行了广泛的实验，以证明与现有的基线模型相比，ReLLa 的优越性，以及它终身连续行为理解的能力。要突出显示的是，只有少于10个传统的 CTR 模型是在整个训练集(例如，DCNv2，DIN，SIM)上训练的。代码可在 <  https://github.com/lavieenrose365/rella。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ReLLa:+Retrieval-enhanced+Large+Language+Models+for+Lifelong+Sequential+Behavior+Comprehension+in+Recommendation)|0|
|[Large Language Model based Long-tail Query Rewriting in Taobao Search](https://doi.org/10.1145/3589335.3648298)|Wenjun Peng, Guiyang Li, Yue Jiang, Zilong Wang, Dan Ou, Xiaoyi Zeng, Derong Xu, Tong Xu, Enhong Chen||In the realm of e-commerce search, the significance of semantic matching cannot be overstated, as it directly impacts both user experience and company revenue. Along this line, query rewriting, serving as an important technique to bridge the semantic gaps inherent in the semantic matching process, has attached wide attention from the industry and academia. However, existing query rewriting methods often struggle to effectively optimize long-tail queries and alleviate the phenomenon of "few-recall" caused by semantic gap. In this paper, we present BEQUE, a comprehensive framework that Bridges the sEmantic gap for long-tail QUEries. In detail, BEQUE comprises three stages: multi-instruction supervised fine tuning (SFT), offline feedback, and objective alignment. We first construct a rewriting dataset based on rejection sampling and auxiliary tasks mixing to fine-tune our large language model (LLM) in a supervised fashion. Subsequently, with the well-trained LLM, we employ beam search to generate multiple candidate rewrites, and feed them into Taobao offline system to obtain the partial order. Leveraging the partial order of rewrites, we introduce a contrastive learning method to highlight the distinctions between rewrites, and align the model with the Taobao online objectives. Offline experiments prove the effectiveness of our method in bridging semantic gap. Online A/B tests reveal that our method can significantly boost gross merchandise volume (GMV), number of transaction (#Trans) and unique visitor (UV) for long-tail queries. BEQUE has been deployed on Taobao, one of most popular online shopping platforms in China, since October 2023.|在电子商务搜索领域，语义匹配的重要性怎么强调都不为过，因为它直接影响用户体验和公司收入。沿着这条路线，查询重写作为弥合语义匹配过程中固有的语义差异的一项重要技术，受到了业界和学术界的广泛关注。然而，现有的查询重写方法往往难以有效地优化长尾查询，缓解由于语义差异造成的“少召回”现象。在本文中，我们提出了 BEQUE，一个综合框架，桥梁的语义差距为长尾查询。具体而言，BEQUE 包括三个阶段: 多指令监督微调(SFT)、离线反馈和目标校准。我们首先构建一个基于拒绝采样和辅助任务混合的重写数据集，以监督的方式对大型语言模型(LLM)进行微调。然后，利用训练有素的 LLM，通过波束搜索生成多个候选重写，并将其输入到淘宝离线系统中，获得部分序列。利用重写的部分顺序，我们引入了一种对比学习方法来突出重写之间的区别，并使模型与淘宝在线目标相一致。离线实验证明了该方法在消除语义鸿沟方面的有效性。在线 A/B 测试表明，我们的方法可以显着提高总商品数量(GMV) ，交易数量(# Trans)和独立访问者(UV)的长尾查询。自2023年10月以来，BEQUE 已经部署在淘宝上，淘宝是中国最受欢迎的在线购物平台之一。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large+Language+Model+based+Long-tail+Query+Rewriting+in+Taobao+Search)|0|
|[An Interpretable Ensemble of Graph and Language Models for Improving Search Relevance in E-Commerce](https://doi.org/10.1145/3589335.3648318)|Nurendra Choudhary, Edward W. Huang, Karthik Subbian, Chandan K. Reddy||The problem of search relevance in the E-commerce domain is a challenging one since it involves understanding the intent of a user's short nuanced query and matching it with the appropriate products in the catalog. This problem has traditionally been addressed using language models (LMs) and graph neural networks (GNNs) to capture semantic and inter-product behavior signals, respectively. However, the rapid development of new architectures has created a gap between research and the practical adoption of these techniques. Evaluating the generalizability of these models for deployment requires extensive experimentation on complex, real-world datasets, which can be non-trivial and expensive. Furthermore, such models often operate on latent space representations that are incomprehensible to humans, making it difficult to evaluate and compare the effectiveness of different models. This lack of interpretability hinders the development and adoption of new techniques in the field. To bridge this gap, we propose Plug and Play Graph LAnguage Model (PP-GLAM), an explainable ensemble of plug and play models. Our approach uses a modular framework with uniform data processing pipelines. It employs additive explanation metrics to independently decide whether to include (i) language model candidates, (ii) GNN model candidates, and (iii) inter-product behavioral signals. For the task of search relevance, we show that PP-GLAM outperforms several state-of-the-art baselines as well as a proprietary model on real-world multilingual, multi-regional e-commerce datasets. To promote better model comprehensibility and adoption, we also provide an analysis of the explainability and computational complexity of our model. We also provide the public codebase and provide a deployment strategy for practical implementation.|电子商务领域中的搜索相关性问题是一个具有挑战性的问题，因为它涉及到理解用户的短细微差别查询的意图，并将其与目录中适当的产品进行匹配。传统上，这个问题被分别用语言模型(LMs)和图神经网络(GNN)来捕获语义信号和产品间行为信号。然而，新体系结构的快速发展在这些技术的研究和实际应用之间产生了差距。评估这些部署模型的通用性需要在复杂的、真实世界的数据集上进行大量的实验，这些实验可能是非常重要和昂贵的。此外，这些模型经常运行在人类无法理解的潜在空间表征上，使得难以评估和比较不同模型的有效性。这种缺乏可解释性的情况妨碍了这一领域新技术的开发和采用。为了弥补这一差距，我们提出了即插即用图语言模型(PP-GLAM) ，这是一个可解释的即插即用模型集合。我们的方法使用具有统一数据处理管道的模块化框架。它使用加性解释度量来独立决定是否包括(i)语言模型候选者，(ii) GNN 模型候选者，和(iii)产品间行为信号。对于搜索相关性的任务，我们表明，PP-GLAM 优于几个最先进的基线，以及在现实世界中的多语言，多地区电子商务数据集的专有模型。为了促进更好的模型可理解性和采用性，我们还对模型的可解释性和计算复杂性进行了分析。我们还提供了公共代码库，并为实际实现提供了部署策略。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Interpretable+Ensemble+of+Graph+and+Language+Models+for+Improving+Search+Relevance+in+E-Commerce)|0|
|[Hierarchical Query Classification in E-commerce Search](https://doi.org/10.1145/3589335.3648332)|Bing He, Sreyashi Nag, Limeng Cui, Suhang Wang, Zheng Li, Rahul Goutam, Zhen Li, Haiyang Zhang||E-commerce platforms typically store and structure product information and search data in a hierarchy. Efficiently categorizing user search queries into a similar hierarchical structure is paramount in enhancing user experience on e-commerce platforms as well as news curation and academic research. The significance of this task is amplified when dealing with sensitive query categorization or critical information dissemination, where inaccuracies can lead to considerable negative impacts. The inherent complexity of hierarchical query classification is compounded by two primary challenges: (1) the pronounced class imbalance that skews towards dominant categories, and (2) the inherent brevity and ambiguity of search queries that hinder accurate classification. To address these challenges, we introduce a novel framework that leverages hierarchical information through (i) enhanced representation learning that utilizes the contrastive loss to discern fine-grained instance relationships within the hierarchy, called ”instance hierarchy”, and (ii) a nuanced hierarchical classification loss that attends to the intrinsic label taxonomy, named ”label hierarchy”. Additionally, based on our observation that certain unlabeled queries share typographical similarities with labeled queries, we propose a neighborhood-aware sampling technique to intelligently select these unlabeled queries to boost the classification performance. Extensive experiments demonstrate that our proposed method is better than state-of-the-art (SOTA) on the proprietary Amazon dataset, and comparable to SOTA on the public datasets of Web of Science and RCV1-V2. These results underscore the efficacy of our proposed solution, and pave the path toward the next generation of hierarchy-aware query classification systems.|电子商务平台通常在一个层次结构中存储和构造产品信息和搜索数据。有效地将用户搜索查询分类到一个类似的层次结构中，对于提高电子商务平台上的用户体验以及新闻策划和学术研究都是至关重要的。在处理敏感的查询分类或关键信息传播时，这项任务的重要性被放大，因为不准确可能导致相当大的负面影响。层次化查询分类的内在复杂性由两个主要挑战所复杂化: (1)明显的类不平衡倾向于主导类别，(2)搜索查询的内在简洁性和模糊性阻碍了准确分类。为了解决这些挑战，我们引入了一个新的框架，通过(i)增强的表示学习利用层次结构中的细粒度实例关系，称为“实例层次结构”，以及(ii)一个细微的层次分类损失，涉及内在的标签分类法，称为“标签层次结构”。此外，基于我们观察到的某些未标记查询与标记查询在字体上有相似之处，我们提出了一种邻域感知抽样技术来智能地选择这些未标记查询以提高分类性能。大量的实验表明，我们提出的方法在专有 Amazon 数据集上优于最先进的 SOTA (State-of-art) ，在公共数据集上与 SOTA (Web of Science)和 RCV1-V2相当。这些结果强调了我们提出的解决方案的有效性，并为下一代感知层次的查询分类系统铺平了道路。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Query+Classification+in+E-commerce+Search)|0|
|[Detecting Generated Native Ads in Conversational Search](https://doi.org/10.1145/3589335.3651489)|Sebastian Schmidt, Ines Zelch, Janek Bevendorff, Benno Stein, Matthias Hagen, Martin Potthast||Conversational search engines such as YouChat and Microsoft Copilot use large language models (LLMs) to generate answers to queries. It is only a small step to also use this technology to generate and integrate advertising within these answers - instead of placing ads separately from the organic search results. This type of advertising is reminiscent of native advertising and product placement, both of which are very effective forms of subtle and manipulative advertising. It is likely that information seekers will be confronted with such use of LLM technology in the near future, especially when considering the high computational costs associated with LLMs, for which providers need to develop sustainable business models. This paper investigates whether LLMs can also be used as a countermeasure against generated native ads, i.e., to block them. For this purpose we compile a large dataset of ad-prone queries and of generated answers with automatically integrated ads to experiment with fine-tuned sentence transformers and state-of-the-art LLMs on the task of recognizing the ads. In our experiments sentence transformers achieve detection precision and recall values above 0.9, while the investigated LLMs struggle with the task.|像 YouChat 和 Microsoft Copilot 这样的会话搜索引擎使用大型语言模型(LLM)来生成查询的答案。使用这种技术在这些答案中生成和整合广告，而不是将广告与有机搜索结果分开放置，这只是一小步。这种类型的广告让人想起原生广告和植入性营销，它们都是非常有效的微妙和操纵性的广告形式。在不久的将来，信息寻求者可能会遇到这种使用 LLM 技术的情况，特别是考虑到与 LLM 相关的高计算成本，供应商需要为此开发可持续的商业模式。本文研究 LLM 是否也可以作为一种对抗生成本地广告的对策，即屏蔽本地广告。为此，我们编译了一个大型的广告倾向查询数据集和自动整合广告生成的答案数据集，以便在识别广告的任务中使用微调的句子转换器和最先进的 LLM 进行实验。在我们的实验中，句子转换器的检测准确率召回率大于0.9，而被调查的 LLM 则在努力完成这项任务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Detecting+Generated+Native+Ads+in+Conversational+Search)|0|
|[Recall-Augmented Ranking: Enhancing Click-Through Rate Prediction Accuracy with Cross-Stage Data](https://doi.org/10.1145/3589335.3651551)|Junjie Huang, Guohao Cai, Jieming Zhu, Zhenhua Dong, Ruiming Tang, Weinan Zhang, Yong Yu||Click-through rate (CTR) prediction plays an indispensable role in online platforms. Numerous models have been proposed to capture users' shifting preferences by leveraging user behavior sequences. However, these historical sequences often suffer from severe homogeneity and scarcity compared to the extensive item pool. Relying solely on such sequences for user representations is inherently restrictive, as user interests extend beyond the scope of items they have previously engaged with. To address this challenge, we propose a data-driven approach to enrich user representations. We recognize user profiling and recall items as two ideal data sources within the cross-stage framework, encompassing the u2u (user-to-user) and i2i (item-to-item) aspects respectively. In this paper, we propose a novel architecture named Recall-Augmented Ranking (RAR). RAR consists of two key sub-modules, which synergistically gather information from a vast pool of look-alike users and recall items, resulting in enriched user representations. Notably, RAR is orthogonal to many existing CTR models, allowing for consistent performance improvements in a plug-and-play manner. Extensive experiments are conducted, which verify the efficacy and compatibility of RAR against the SOTA methods.|点进率预测在网络平台上扮演着不可或缺的角色。已经有很多模型被提出来通过利用用户行为序列来捕捉用户不断变化的偏好。然而，这些历史序列往往遭受严重的同质性和稀缺性相比，广泛的项目池。仅仅依靠这些序列来表示用户本身就是限制性的，因为用户的兴趣已经超出了他们以前参与的项目的范围。为了解决这个问题，我们提出了一种数据驱动的方法来丰富用户表示。我们将用户分析和召回项目视为跨阶段框架内的两个理想数据源，分别包括 u2u (用户对用户)和 i2i (项目对项目)方面。在本文中，我们提出了一种新的体系结构，称为召回增强排序(RAR)。RAR 由两个关键的子模块组成，它们协同地从大量外观相似的用户和召回项目中收集信息，从而丰富用户表示。值得注意的是，RAR 与许多现有的 CTR 模型是正交的，允许以即插即用的方式提高性能。进行了大量的实验，验证了 RAR 方法对 SOTA 方法的有效性和相容性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recall-Augmented+Ranking:+Enhancing+Click-Through+Rate+Prediction+Accuracy+with+Cross-Stage+Data)|0|
|[RAT: Retrieval-Augmented Transformer for Click-Through Rate Prediction](https://doi.org/10.1145/3589335.3651550)|Yushen Li, Jinpeng Wang, Tao Dai, Jieming Zhu, Jun Yuan, Rui Zhang, ShuTao Xia||Predicting click-through rates (CTR) is a fundamental task for Web applications, where a key issue is to devise effective models for feature interactions. Current methodologies predominantly concentrate on modeling feature interactions within an individual sample, while overlooking the potential cross-sample relationships that can serve as a reference context to enhance the prediction. To make up for such deficiency, this paper develops a Retrieval-Augmented Transformer (RAT), aiming to acquire fine-grained feature interactions within and across samples. By retrieving similar samples, we construct augmented input for each target sample. We then build Transformer layers with cascaded attention to capture both intra- and cross-sample feature interactions, facilitating comprehensive reasoning for improved CTR prediction while retaining efficiency. Extensive experiments on real-world datasets substantiate the effectiveness of RAT and suggest its advantage in long-tail scenarios. The code has been open-sourced at <https://github.com/YushenLi807/WWW24-RAT>.|预测点击率(CTR)是 Web 应用程序的基本任务，其中一个关键问题是为特性交互设计有效的模型。目前的方法主要集中在建模个体样本内的特征相互作用，而忽视了可以作为参考背景的潜在跨样本关系，以增强预测。为了弥补这一不足，本文开发了一种检索增强变压器(RAT) ，旨在获取样本内部和样本间的细粒度特征交互。通过检索相似的样本，我们为每个目标样本构造增强的输入。然后，我们建立级联注意力的变压器层，以捕获内部和交叉样本的特征相互作用，促进综合推理改善 CTR 预测，同时保留效率。对真实世界数据集的大量实验证实了 RAT 的有效性，并提出了它在长尾场景中的优势。该代码已在 <  https://github.com/yushenli807/www24-rat 开放源码。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RAT:+Retrieval-Augmented+Transformer+for+Click-Through+Rate+Prediction)|0|
|[Personalized Ordering of Recommendation-Modules on an E-Commerce Homepage](https://doi.org/10.1145/3589335.3651545)|Haggai Roitman, Alexander Nus, Yotam Eshel||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Personalized+Ordering+of+Recommendation-Modules+on+an+E-Commerce+Homepage)|0|
|[Retrieval-augmented Query Reformulation for Heterogeneous Research Asset Retrieval in Virtual Research Environment](https://doi.org/10.1145/3589335.3651553)|Peide Zhu, Na Li, Zhiming Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Retrieval-augmented+Query+Reformulation+for+Heterogeneous+Research+Asset+Retrieval+in+Virtual+Research+Environment)|0|
|[List-aware Reranking-Truncation Joint Model for Search and Retrieval-augmented Generation](https://doi.org/10.1145/3589334.3645336)|Shicheng Xu, Liang Pang, Jun Xu, Huawei Shen, Xueqi Cheng||The results of information retrieval (IR) are usually presented in the form of a ranked list of candidate documents, such as web search for humans and retrieval-augmented generation for large language models (LLMs). List-aware retrieval aims to capture the list-level contextual features to return a better list, mainly including reranking and truncation. Reranking finely re-scores the documents in the list. Truncation dynamically determines the cut-off point of the ranked list to achieve the trade-off between overall relevance and avoiding misinformation from irrelevant documents. Previous studies treat them as two separate tasks and model them separately. However, the separation is not optimal. First, it is hard to share the contextual information of the ranking list between the two tasks. Second, the separate pipeline usually meets the error accumulation problem, where the small error from the reranking stage can largely affect the truncation stage. To solve these problems, we propose a Reranking-Truncation joint model (GenRT) that can perform the two tasks concurrently. GenRT integrates reranking and truncation via generative paradigm based on encoder-decoder architecture. We also design the novel loss functions for joint optimization to make the model learn both tasks. Sharing parameters by the joint model is conducive to making full use of the common modeling information of the two tasks. Besides, the two tasks are performed concurrently and co-optimized to solve the error accumulation problem between separate stages. Experiments on public learning-to-rank benchmarks and open-domain Q&A tasks show that our method achieves SOTA performance on both reranking and truncation tasks for web search and retrieval-augmented LLMs.|信息检索检索(IR)的结果通常以候选文档的排序列表的形式呈现，例如人类的网络搜索和大型语言模型的检索增强生成(LLM)。列表感知检索旨在捕获列表级上下文特征以返回更好的列表，主要包括重新排序和截断。对列表中的文档进行精细的重新排序。截断动态确定排序列表的截止点，以实现总体相关性和避免来自不相关文档的错误信息之间的权衡。以往的研究将它们视为两个独立的任务，并分别建立模型。然而，这种分离并不理想。首先，很难在两个任务之间共享排名列表的上下文信息。其次，分离的流水线通常会遇到误差累积问题，重新排序阶段的小误差会对截断阶段产生很大的影响。为了解决这些问题，我们提出了一个可以同时执行这两个任务的重新排序-截断联合模型(GenRT)。GenRT 通过基于编解码体系结构的生成范式集成了重新排序和截断。设计了新的联合优化损失函数，使模型能够同时学习两个任务。通过联合模型共享参数有利于充分利用两个任务的共同建模信息。此外，为了解决不同阶段之间的误差累积问题，两个任务同时进行，并进行了协同优化。通过对公共学习排序基准测试和开放域问答任务的实验表明，该方法在网络搜索和检索增强 LLM 的重排序任务和截断任务上都达到了 SOTA 性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=List-aware+Reranking-Truncation+Joint+Model+for+Search+and+Retrieval-augmented+Generation)|0|
|[Query in Your Tongue: Reinforce Large Language Models with Retrievers for Cross-lingual Search Generative Experience](https://doi.org/10.1145/3589334.3645701)|Ping Guo, Yue Hu, Yanan Cao, Yubing Ren, Yunpeng Li, Heyan Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Query+in+Your+Tongue:+Reinforce+Large+Language+Models+with+Retrievers+for+Cross-lingual+Search+Generative+Experience)|0|
|[UnifiedSSR: A Unified Framework of Sequential Search and Recommendation](https://doi.org/10.1145/3589334.3645427)|Jiayi Xie, Shang Liu, Gao Cong, Zhenzhong Chen||In this work, we propose a Unified framework of Sequential Search and Recommendation (UnifiedSSR) for joint learning of user behavior history in both search and recommendation scenarios. Specifically, we consider user-interacted products in the recommendation scenario, user-interacted products and user-issued queries in the search scenario as three distinct types of user behaviors. We propose a dual-branch network to encode the pair of interacted product history and issued query history in the search scenario in parallel. This allows for cross-scenario modeling by deactivating the query branch for the recommendation scenario. Through the parameter sharing between dual branches, as well as between product branches in two scenarios, we incorporate cross-view and cross-scenario associations of user behaviors, providing a comprehensive understanding of user behavior patterns. To further enhance user behavior modeling by capturing the underlying dynamic intent, an Intent-oriented Session Modeling module is designed for inferring intent-oriented semantic sessions from the contextual information in behavior sequences. In particular, we consider self-supervised learning signals from two perspectives for intent-oriented semantic session locating, which encourage session discrimination within each behavior sequence and session alignment between dual behavior sequences. Extensive experiments on three public datasets demonstrate that UnifiedSSR consistently outperforms state-of-the-art methods for both search and recommendation.|在这项工作中，我们提出了一个统一的线性搜索和推荐框架(UnifiedSSR) ，用于在搜索和推荐场景中联合学习用户行为历史。具体来说，我们将推荐场景中的用户交互产品、搜索场景中的用户交互产品和用户发布的查询视为三种不同类型的用户行为。我们提出了一个双分支网络，在搜索场景中并行编码交互的产品历史记录和发布的查询历史记录。这允许通过停用推荐场景的查询分支来进行跨场景建模。通过双分支之间的参数共享，以及两个场景中产品分支之间的参数共享，我们整合了用户行为的跨视图和跨场景关联，提供了对用户行为模式的全面理解。为了通过捕获潜在的动态意图进一步增强用户行为建模，设计了一个面向意图的会话建模模块，用于从行为序列中的上下文信息推断面向意图的语义会话。特别地，我们从两个角度考虑了自我监督学习信号的意图导向语义会话定位，它鼓励在每个行为序列中的会话区分和双行为序列之间的会话对齐。在三个公共数据集上的大量实验表明，UnifiedSSR 在搜索和推荐方面始终优于最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UnifiedSSR:+A+Unified+Framework+of+Sequential+Search+and+Recommendation)|0|
|[Scaling User Modeling: Large-scale Online User Representations for Ads Personalization in Meta](https://doi.org/10.1145/3589335.3648301)|Wei Zhang, Dai Li, Chen Liang, Fang Zhou, Zhongke Zhang, Xuewei Wang, Ru Li, Yi Zhou, Yaning Huang, Dong Liang, Kai Wang, Zhangyuan Wang, Zhengxing Chen, Fenggang Wu, Minghai Chen, Huayu Li, Yunnan Wu, Zhan Shu, Mindi Yuan, Sri Reddy||Effective user representations are pivotal in personalized advertising. However, stringent constraints on training throughput, serving latency, and memory, often limit the complexity and input feature set of online ads ranking models. This challenge is magnified in extensive systems like Meta's, which encompass hundreds of models with diverse specifications, rendering the tailoring of user representation learning for each model impractical. To address these challenges, we present Scaling User Modeling (SUM), a framework widely deployed in Meta's ads ranking system, designed to facilitate efficient and scalable sharing of online user representation across hundreds of ads models. SUM leverages a few designated upstream user models to synthesize user embeddings from massive amounts of user features with advanced modeling techniques. These embeddings then serve as inputs to downstream online ads ranking models, promoting efficient representation sharing. To adapt to the dynamic nature of user features and ensure embedding freshness, we designed SUM Online Asynchronous Platform (SOAP), a latency free online serving system complemented with model freshness and embedding stabilization, which enables frequent user model updates and online inference of user embeddings upon each user request. We share our hands-on deployment experiences for the SUM framework and validate its superiority through comprehensive experiments. To date, SUM has been launched to hundreds of ads ranking models in Meta, processing hundreds of billions of user requests daily, yielding significant online metric gains and infrastructure cost savings.|有效的用户表示是个性化广告的关键。然而，严格限制训练吞吐量、服务延迟和内存，往往限制了在线广告排名模型的复杂性和输入特征集。这个挑战在像 Meta 这样的广泛系统中被放大，它包含了数百个具有不同规格的模型，使得为每个模型裁剪用户表示学习变得不切实际。为了应对这些挑战，我们提出了缩放用户建模(SUM) ，这是一个广泛应用于 Meta 广告排名系统的框架，旨在促进高效和可扩展的在线用户表示在数百个广告模型之间的共享。SUM 利用一些指定的上游用户模型，通过先进的建模技术从大量的用户特性中综合用户嵌入。然后这些嵌入作为下游在线广告排名模型的输入，促进有效的表示共享。为了适应用户特征的动态性和保证嵌入的新鲜性，我们设计了 SUM 在线异步平台(SOAP) ，这是一个无延迟的在线服务系统，它补充了模型的新鲜性和嵌入的稳定性，能够根据用户的每个请求频繁地更新用户模型和在线推断用户的嵌入。我们分享了 SUM 框架的实际部署经验，并通过全面的实验验证了其优越性。迄今为止，SUM 已经在 Meta 中推出了数百个广告排名模型，每天处理数千亿用户请求，产生了显著的在线度量收益和基础设施成本节约。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scaling+User+Modeling:+Large-scale+Online+User+Representations+for+Ads+Personalization+in+Meta)|0|
|[Finding What Users Look for by Attribute-Aware Personalized Item Comparison in Relevant Recommendation](https://doi.org/10.1145/3589335.3651508)|Rui Ma, Dike Sun, Jincheng Xu, Jingsong Yuan, Jiandong Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Finding+What+Users+Look+for+by+Attribute-Aware+Personalized+Item+Comparison+in+Relevant+Recommendation)|0|
|[De-Anchor: Mitigating Attention Polarization for Lifelong User Behavior Modeling in Click-Through Rate Prediction](https://doi.org/10.1145/3589335.3651486)|Hongzun Liu, Kang Yin, Tianyu Sun, Rui Huang, Yunsong Li, Xiao Fang, Zhaojie Liu, Weidong Liu, Guorui Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=De-Anchor:+Mitigating+Attention+Polarization+for+Lifelong+User+Behavior+Modeling+in+Click-Through+Rate+Prediction)|0|
|[User Distribution Mapping Modelling with Collaborative Filtering for Cross Domain Recommendation](https://doi.org/10.1145/3589334.3645331)|Weiming Liu, Chaochao Chen, Xinting Liao, Mengling Hu, Jiajie Su, Yanchao Tan, Fan Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=User+Distribution+Mapping+Modelling+with+Collaborative+Filtering+for+Cross+Domain+Recommendation)|0|
|[Leave No One Behind: Online Self-Supervised Self-Distillation for Sequential Recommendation](https://doi.org/10.1145/3589334.3645590)|Shaowei Wei, Zhengwei Wu, Xin Li, Qintong Wu, Zhiqiang Zhang, Jun Zhou, Lihong Gu, Jinjie Gu||Sequential recommendation methods play a pivotal role in modern recommendation systems. A key challenge lies in accurately modeling user preferences in the face of data sparsity. To tackle this challenge, recent methods leverage contrastive learning (CL) to derive self-supervision signals by maximizing the mutual information of two augmented views of the original user behavior sequence. Despite their effectiveness, CL-based methods encounter a limitation in fully exploiting self-supervision signals for users with limited behavior data, as users with extensive behaviors naturally offer more information. To address this problem, we introduce a novel learning paradigm, named Online Self-Supervised Self-distillation for Sequential Recommendation ($S^4$Rec), effectively bridging the gap between self-supervised learning and self-distillation methods. Specifically, we employ online clustering to proficiently group users by their distinct latent intents. Additionally, an adversarial learning strategy is utilized to ensure that the clustering procedure is not affected by the behavior length factor. Subsequently, we employ self-distillation to facilitate the transfer of knowledge from users with extensive behaviors (teachers) to users with limited behaviors (students). Experiments conducted on four real-world datasets validate the effectiveness of the proposed method\footnote{Code is available at https://github.com/xjaw/S4Rec|序贯推荐方法在现代推荐系统中占有举足轻重的地位。一个关键的挑战在于在面对数据稀少的情况下准确地建模用户偏好。为了应对这一挑战，最近的方法利用对比学习(CL) ，通过最大化原始用户行为序列的两个增强视图的互信息来获得自我监督信号。尽管有效，但基于 CL 的方法在充分利用行为数据有限的用户的自我监督信号方面遇到了局限，因为行为广泛的用户自然会提供更多的信息。为了解决这一问题，我们引入了一种新的学习范式，称为序贯推荐在线自我监督自我精馏($S ^ 4 $Rec) ，有效地弥补了自我监督学习和自我精馏方法之间的差距。具体来说，我们使用在线集群来熟练地根据用户不同的潜在意图对他们进行分组。此外，采用对抗学习策略，确保聚类过程不受行为长度因子的影响。随后，我们采用自我提取的方法，促进知识从行为广泛的用户(教师)转移到行为有限的用户(学生)。在四个真实世界的数据集上进行的实验验证了提议方法的有效性脚注{代码可在 https://github.com/xjaw/s4rec 获得|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leave+No+One+Behind:+Online+Self-Supervised+Self-Distillation+for+Sequential+Recommendation)|0|
|[Improving Search for New Product Categories via Synthetic Query Generation Strategies](https://doi.org/10.1145/3589335.3648299)|Akshay Jagatap, Srujana Merugu, Prakash Mandayam Comar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Search+for+New+Product+Categories+via+Synthetic+Query+Generation+Strategies)|0|
|[MS MARCO Web Search: A Large-scale Information-rich Web Dataset with Millions of Real Click Labels](https://doi.org/10.1145/3589335.3648327)|Qi Chen, Xiubo Geng, Corby Rosset, Carolyn Buractaon, Jingwen Lu, Tao Shen, Kun Zhou, Chenyan Xiong, Yeyun Gong, Paul N. Bennett, Nick Craswell, Xing Xie, Fan Yang, Bryan Tower, Nikhil Rao, Anlei Dong, Wenqi Jiang, Zheng Liu, Mingqin Li, Chuanjie Liu, Zengzhong Li, Rangan Majumder, Jennifer Neville, Andy Oakley, Knut Magne Risvik, Harsha Vardhan Simhadri, Manik Varma, Yujing Wang, Linjun Yang, Mao Yang, Ce Zhang||Recent breakthroughs in large models have highlighted the critical significance of data scale, labels and modals. In this paper, we introduce MS MARCO Web Search, the first large-scale information-rich web dataset, featuring millions of real clicked query-document labels. This dataset closely mimics real-world web document and query distribution, provides rich information for various kinds of downstream tasks and encourages research in various areas, such as generic end-to-end neural indexer models, generic embedding models, and next generation information access system with large language models. MS MARCO Web Search offers a retrieval benchmark with three web retrieval challenge tasks that demand innovations in both machine learning and information retrieval system research domains. As the first dataset that meets large, real and rich data requirements, MS MARCO Web Search paves the way for future advancements in AI and system research. MS MARCO Web Search dataset is available at: https://github.com/microsoft/MS-MARCO-Web-Search.|最近在大型模型方面的突破突出了数据规模、标签和模态的关键意义。本文介绍了第一个大规模信息丰富的网络数据集 MS MARCO Web Search，它包含了数百万个实际点击的查询文档标签。这个数据集非常接近真实世界的网络文档和查询分布，为各种下游任务提供丰富的信息，并鼓励在各个领域的研究，如通用的端到端神经索引器模型，通用的嵌入模型，下一代信息访问系统与大型语言模型。微软 MARCO 网络搜索提供了一个检索基准，包含三个网络检索挑战任务，需要在机器学习和信息检索系统研究领域进行创新。作为第一个满足大型、真实、丰富数据需求的数据集，微软 MARCO 网络搜索为人工智能和系统研究的未来发展铺平了道路。微软马可网上搜寻资料集可于以下 https://github.com/microsoft/MS-MARCO-Web-Search 索取:。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MS+MARCO+Web+Search:+A+Large-scale+Information-rich+Web+Dataset+with+Millions+of+Real+Click+Labels)|0|
|[Enhancing Cross-Domain Click-Through Rate Prediction via Explicit Feature Augmentation](https://doi.org/10.1145/3589335.3648341)|Xu Chen, Zida Cheng, Jiangchao Yao, Chen Ju, Weilin Huang, Jinsong Lan, Xiaoyi Zeng, Shuai Xiao||Cross-domain CTR (CDCTR) prediction is an important research topic that studies how to leverage meaningful data from a related domain to help CTR prediction in target domain. Most existing CDCTR works design implicit ways to transfer knowledge across domains such as parameter-sharing that regularizes the model training in target domain. More effectively, recent researchers propose explicit techniques to extract user interest knowledge and transfer this knowledge to target domain. However, the proposed method mainly faces two issues: 1) it usually requires a super domain, i.e. an extremely large source domain, to cover most users or items of target domain, and 2) the extracted user interest knowledge is static no matter what the context is in target domain. These limitations motivate us to develop a more flexible and efficient technique to explicitly transfer knowledge. In this work, we propose a cross-domain augmentation network (CDAnet) being able to perform explicit knowledge transfer between two domains. Specifically, CDAnet contains a designed translation network and an augmentation network which are trained sequentially. The translation network computes latent features from two domains and learns meaningful cross-domain knowledge of each input in target domain by using a designed cross-supervised feature translator. Later the augmentation network employs the explicit cross-domain knowledge as augmented information to boost the target domain CTR prediction. Through extensive experiments on two public benchmarks and one industrial production dataset, we show CDAnet can learn meaningful translated features and largely improve the performance of CTR prediction. CDAnet has been conducted online A/B test in image2product retrieval at Taobao app, bringing an absolute 0.11 point CTR improvement, a relative 0.64|跨域 CTR (Cross-domain CTR)预测是研究如何利用相关领域有意义的数据来帮助目标领域 CTR 预测的一个重要研究课题。大多数现有的 CDCTR 工作设计了隐式的跨领域知识转移方法，如参数共享，规范了目标领域的模型训练。更有效的是，最近的研究人员提出了显性技术来提取用户兴趣知识并将这些知识转移到目标领域。然而，该方法主要面临两个问题: 1)它通常需要一个超级域，即一个非常大的源域，以覆盖目标域的大多数用户或项目; 2)提取的用户兴趣知识是静态的，不管目标域的上下文是什么。这些限制促使我们开发一种更灵活、更有效的技术来明确地传递知识。在这项工作中，我们提出了一个跨域增强网络(CDAnet) ，它可以在两个域之间进行外显知识传输。具体来说，CDAnet 包含一个设计好的翻译网络和一个按顺序训练的增强网络。该翻译网络利用设计的交叉监督特征转换器计算两个领域的潜在特征，并学习目标领域中每个输入的有意义的跨领域知识。随后增强网络利用显式的跨领域知识作为增强信息来提高目标领域的 CTR 预测能力。通过对两个公共基准和一个工业生产数据集的大量实验，我们发现 CDAnet 能够学习到有意义的翻译特征，从而大大提高了 CTR 预测的性能。CDAnet 在淘宝应用图像2产品检索中进行了在线 A/B 测试，绝对点击率提高了0.11个百分点，相对提高了0.64个百分点|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Cross-Domain+Click-Through+Rate+Prediction+via+Explicit+Feature+Augmentation)|0|
|[Item-Ranking Promotion in Recommender Systems](https://doi.org/10.1145/3589335.3651529)|HongKyun Bae, HaeRi Jang, YangSae Moon, SangWook Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Item-Ranking+Promotion+in+Recommender+Systems)|0|
|[Understanding and Counteracting Feature-Level Bias in Click-Through Rate Prediction](https://doi.org/10.1145/3589335.3651576)|Jinqiu Jin, Sihao Ding, Wenjie Wang, Fuli Feng||Common click-through rate (CTR) prediction recommender models tend to exhibit feature-level bias, which leads to unfair recommendations among item groups and inaccurate recommendations for users. While existing methods address this issue by adjusting the learning of CTR models, such as through additional optimization objectives, they fail to consider how the bias is caused within these models. To address this research gap, our study performs a top-down analysis on representative CTR models. Through blocking different components of a trained CTR model one by one, we identify the key contribution of the linear component to feature-level bias. We conduct a theoretical analysis of the learning process for the weights in the linear component, revealing how group-wise properties of training data influence them. Our experimental and statistical analyses demonstrate a strong correlation between imbalanced positive sample ratios across item groups and feature-level bias. Based on this understanding, we propose a minimally invasive yet effective strategy to counteract feature-level bias in CTR models by removing the biased linear weights from trained models. Additionally, we present a linear weight adjusting strategy that requires fewer random exposure records than relevant debiasing methods. The superiority of our proposed strategies are validated through extensive experiments on three real-world datasets.|常见的点进率预测推荐模型往往表现出特征层面的偏差，导致项目组之间的不公平推荐和对用户的不准确推荐。虽然现有的方法通过调整 CTR 模型的学习来解决这个问题，例如通过额外的优化目标，但是他们没有考虑这些模型中偏差是如何产生的。为了解决这一研究差距，我们的研究对代表性的 CTR 模型进行了自上而下的分析。通过对训练好的 CTR 模型的不同分量逐个进行分块，我们确定了线性分量对特征级偏差的主要贡献。我们对线性分量中权重的学习过程进行了理论分析，揭示了训练数据的群体性质如何影响它们。我们的实验和统计分析表明，项目组间不平衡的正样本比率和特征水平偏差之间有很强的相关性。基于这一认识，我们提出了一种微创但有效的策略，通过去除训练后的模型中有偏的线性权重来抵消 CTR 模型中的特征水平偏差。此外，我们提出了一个线性权重调整策略，需要较少的随机曝光记录比相关的消偏方法。通过在三个实际数据集上的大量实验，验证了所提策略的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+and+Counteracting+Feature-Level+Bias+in+Click-Through+Rate+Prediction)|0|
|[A Demonstration of Decentralized Search Over Solid Personal Online Datastores](https://doi.org/10.1145/3589335.3651248)|Mohamed Ragab, Yury Savateev, Helen Oliver, Reza Moosaei, Thanassis Tiropanis, Alexandra Poulovassilis, Adriane Chapman, George Roussos||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Demonstration+of+Decentralized+Search+Over+Solid+Personal+Online+Datastores)|0|
|[Neural Contextual Bandits for Personalized Recommendation](https://doi.org/10.1145/3589335.3641241)|Yikun Ban, Yunzhe Qi, Jingrui He||In the dynamic landscape of online businesses, recommender systems are pivotal in enhancing user experiences. While traditional approaches have relied on static supervised learning, the quest for adaptive, user-centric recommendations has led to the emergence of the formulation of contextual bandits. This tutorial investigates the contextual bandits as a powerful framework for personalized recommendations. We delve into the challenges, advanced algorithms and theories, collaborative strategies, and open challenges and future prospects within this field. Different from existing related tutorials, (1) we focus on the exploration perspective of contextual bandits to alleviate the ``Matthew Effect'' in the recommender systems, i.e., the rich get richer and the poor get poorer, concerning the popularity of items; (2) in addition to the conventional linear contextual bandits, we will also dedicated to neural contextual bandits which have emerged as an important branch in recent years, to investigate how neural networks benefit contextual bandits for personalized recommendation both empirically and theoretically; (3) we will cover the latest topic, collaborative neural contextual bandits, to incorporate both user heterogeneity and user correlations customized for recommender system; (4) we will provide and discuss the new emerging challenges and open questions for neural contextual bandits with applications in the personalized recommendation, especially for large neural models.|在动态的在线商务环境中，推荐系统是增强用户体验的关键。虽然传统的方法依赖于静态的监督式学习，但是对适应性的、以用户为中心的建议的追求已经导致了关联强盗的出现。本教程研究了上下文强盗作为个性化推荐的强大框架。我们深入研究这个领域的挑战、先进的算法和理论、协作策略、开放的挑战和未来的前景。与现有的相关教程不同的是，(1)我们着重从语境土匪的角度来探索，以缓解推荐系统中的“马太效应”。(2)除了传统的线性情境强盗，我们还将致力于近年来兴起的一个重要分支——神经情境强盗，研究神经网络如何在实证和理论上有利于情境强盗的个性化推荐;(3)我们将涵盖最新的主题，协作神经上下文盗贼，以纳入用户异质性和用户相关性定制的推荐系统; (4)我们将提供和讨论新出现的挑战和神经上下文盗贼的开放性问题的应用，在个性化推荐，特别是在大型神经模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Neural+Contextual+Bandits+for+Personalized+Recommendation)|0|
|[Causality-driven User Modeling for Sequential Recommendations over Time](https://doi.org/10.1145/3589335.3651896)|Xingming Chen, Qing Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causality-driven+User+Modeling+for+Sequential+Recommendations+over+Time)|0|
|[ConvSDG: Session Data Generation for Conversational Search](https://doi.org/10.1145/3589335.3651940)|Fengran Mo, Bole Yi, Kelong Mao, Chen Qu, Kaiyu Huang, JianYun Nie||Conversational search provides a more convenient interface for users to search by allowing multi-turn interaction with the search engine. However, the effectiveness of the conversational dense retrieval methods is limited by the scarcity of training data required for their fine-tuning. Thus, generating more training conversational sessions with relevant labels could potentially improve search performance. Based on the promising capabilities of large language models (LLMs) on text generation, we propose ConvSDG, a simple yet effective framework to explore the feasibility of boosting conversational search by using LLM for session data generation. Within this framework, we design dialogue/session-level and query-level data generation with unsupervised and semi-supervised learning, according to the availability of relevance judgments. The generated data are used to fine-tune the conversational dense retriever. Extensive experiments on four widely used datasets demonstrate the effectiveness and broad applicability of our ConvSDG framework compared with several strong baselines.|通过允许与搜索引擎进行多次交互，对话式搜索为用户提供了更方便的搜索界面。然而，会话密集检索方法的有效性受限于其微调所需的训练数据的稀缺性。因此，使用相关标签生成更多的训练对话会话可能会提高搜索性能。基于大语言模型(LLM)在文本生成方面的潜在能力，本文提出了一个简单而有效的框架，用于探索利用 LLM 进行会话数据生成来提高会话搜索的可行性。在这个框架内，我们根据相关性判断的可用性，设计无监督和半监督学习的对话/会话级和查询级数据生成。生成的数据用于对会话密集型检索器进行微调。在四个广泛使用的数据集上进行的大量实验表明，与几个强大的基线相比，我们的 ConvSDG 框架是有效的，并且具有广泛的适用性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ConvSDG:+Session+Data+Generation+for+Conversational+Search)|0|
|[How Reliable is Your Simulator? Analysis on the Limitations of Current LLM-based User Simulators for Conversational Recommendation](https://doi.org/10.1145/3589335.3651955)|Lixi Zhu, Xiaowen Huang, Jitao Sang||Conversational Recommender System (CRS) interacts with users through natural language to understand their preferences and provide personalized recommendations in real-time. CRS has demonstrated significant potential, prompting researchers to address the development of more realistic and reliable user simulators as a key focus. Recently, the capabilities of Large Language Models (LLMs) have attracted a lot of attention in various fields. Simultaneously, efforts are underway to construct user simulators based on LLMs. While these works showcase innovation, they also come with certain limitations that require attention. In this work, we aim to analyze the limitations of using LLMs in constructing user simulators for CRS, to guide future research. To achieve this goal, we conduct analytical validation on the notable work, iEvaLM. Through multiple experiments on two widely-used datasets in the field of conversational recommendation, we highlight several issues with the current evaluation methods for user simulators based on LLMs: (1) Data leakage, which occurs in conversational history and the user simulator's replies, results in inflated evaluation results. (2) The success of CRS recommendations depends more on the availability and quality of conversational history than on the responses from user simulators. (3) Controlling the output of the user simulator through a single prompt template proves challenging. To overcome these limitations, we propose SimpleUserSim, employing a straightforward strategy to guide the topic toward the target items. Our study validates the ability of CRS models to utilize the interaction information, significantly improving the recommendation results.|会话推荐系统(CRS)通过自然语言与用户互动，了解他们的偏好，并实时提供个性化的建议。CRS 显示了巨大的潜力，促使研究人员将开发更加现实和可靠的用户模拟器作为一个关键重点。近年来，大语言模型(LLM)的性能在各个领域引起了广泛的关注。同时，正在努力构建基于 LLM 的用户模拟器。虽然这些作品展示了创新，但它们也有一定的局限性，需要注意。本文旨在分析 LLM 在构建 CRS 用户模拟器方面的局限性，以指导未来的研究工作。为了实现这个目标，我们对值得注意的工作 iEvaLM 进行了分析验证。通过对会话推荐领域两个广泛使用的数据集进行多次实验，突出了目前基于 LLM 的用户模拟器评估方法存在的几个问题: (1)会话历史和用户模拟器回复中出现的数据泄漏导致评估结果膨胀。(2) CRS 推荐的成功与否更多地取决于会话历史的可用性和质量，而非来自用户模拟器的响应。(3)通过一个单一的提示模板控制用户模拟器的输出具有挑战性。为了克服这些限制，我们提出了 SimpleUserSim，它采用了一种简单的策略来将主题引导到目标项。我们的研究验证了 CRS 模型利用交互信息的能力，显著提高了推荐结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+Reliable+is+Your+Simulator?+Analysis+on+the+Limitations+of+Current+LLM-based+User+Simulators+for+Conversational+Recommendation)|0|
|[Mining Exploratory Queries for Conversational Search](https://doi.org/10.1145/3589334.3645424)|Wenhan Liu, Ziliang Zhao, Yutao Zhu, Zhicheng Dou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mining+Exploratory+Queries+for+Conversational+Search)|0|
|[An In-depth Investigation of User Response Simulation for Conversational Search](https://doi.org/10.1145/3589334.3645447)|Zhenduo Wang, Zhichao Xu, Vivek Srikumar, Qingyao Ai||Conversational search has seen increased recent attention in both the IR and NLP communities. It seeks to clarify and solve users' search needs through multi-turn natural language interactions. However, most existing systems are trained and demonstrated with recorded or artificial conversation logs. Eventually, conversational search systems should be trained, evaluated, and deployed in an open-ended setting with unseen conversation trajectories. A key challenge is that training and evaluating such systems both require a human-in-the-loop, which is expensive and does not scale. One strategy is to simulate users, thereby reducing the scaling costs. However, current user simulators are either limited to only responding to yes-no questions from the conversational search system or unable to produce high-quality responses in general. In this paper, we show that existing user simulation systems could be significantly improved by a smaller finetuned natural language generation model. However, rather than merely reporting it as the new state-of-the-art, we consider it a strong baseline and present an in-depth investigation of simulating user response for conversational search. Our goal is to supplement existing work with an insightful hand-analysis of unsolved challenges by the baseline and propose our solutions. The challenges we identified include (1) a blind spot that is difficult to learn, and (2) a specific type of misevaluation in the standard setup. We propose a new generation system to effectively cover the training blind spot and suggest a new evaluation setup to avoid misevaluation. Our proposed system leads to significant improvements over existing systems and large language models such as GPT-4. Additionally, our analysis provides insights into the nature of user simulation to facilitate future work.|会话搜索最近在 IR 和 NLP 社区都受到了越来越多的关注。它试图通过多回合的自然语言交互来阐明和解决用户的搜索需求。然而，大多数现有的系统都是通过记录或人工会话日志进行训练和演示的。最终，会话搜索系统应该训练，评估，并部署在一个开放的设置与看不见的会话轨迹。一个关键的挑战是，培训和评估这样的系统都需要一个人在回路，这是昂贵的，而且没有规模。一种策略是模拟用户，从而降低缩放成本。然而，目前的用户模拟器要么仅限于回答会话搜索系统中的“是”或“否”问题，要么一般无法产生高质量的回答。在本文中，我们表明，现有的用户模拟系统可以显着改善，一个较小的微调自然语言生成模型。然而，我们并不仅仅把它作为最新的技术来报告，我们认为它是一个强有力的基准，并且提出了一个模拟用户对会话搜索的反应的深入研究。我们的目标是通过对未解决的挑战进行深刻的手工分析来补充现有的工作，并提出我们的解决方案。我们确定的挑战包括(1)一个难以学习的盲点，和(2)在标准设置中一个特定类型的错误评估。我们提出了一个新的系统，以有效地覆盖训练盲点，并提出了一个新的评估设置，以避免错误的评估。我们提出的系统导致了对现有系统和大型语言模型(如 GPT-4)的重大改进。此外，我们的分析提供了对用户模拟的本质的洞察，以促进未来的工作。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+In-depth+Investigation+of+User+Response+Simulation+for+Conversational+Search)|0|
|[Rethinking Cross-Domain Sequential Recommendation under Open-World Assumptions](https://doi.org/10.1145/3589334.3645351)|Wujiang Xu, Qitian Wu, Runzhong Wang, Mingming Ha, Qiongxu Ma, Linxun Chen, Bing Han, Junchi Yan||Cross-Domain Sequential Recommendation (CDSR) methods aim to tackle the data sparsity and cold-start problems present in Single-Domain Sequential Recommendation (SDSR). Existing CDSR works design their elaborate structures relying on overlapping users to propagate the cross-domain information. However, current CDSR methods make closed-world assumptions, assuming fully overlapping users across multiple domains and that the data distribution remains unchanged from the training environment to the test environment. As a result, these methods typically result in lower performance on online real-world platforms due to the data distribution shifts. To address these challenges under open-world assumptions, we design an Adaptive Multi-Interest Debiasing framework for cross-domain sequential recommendation (AMID), which consists of a multi-interest information module (MIM) and a doubly robust estimator (DRE). Our framework is adaptive for open-world environments and can improve the model of most off-the-shelf single-domain sequential backbone models for CDSR. Our MIM establishes interest groups that consider both overlapping and non-overlapping users, allowing us to effectively explore user intent and explicit interest. To alleviate biases across multiple domains, we developed the DRE for the CDSR methods. We also provide a theoretical analysis that demonstrates the superiority of our proposed estimator in terms of bias and tail bound, compared to the IPS estimator used in previous work.|跨域序列推荐(CDSR)方法旨在解决单域序列推荐(SDSR)中存在的数据稀疏和冷启动问题。现有的 CDSR 作品设计了复杂的结构，依靠重叠用户传播跨域信息。然而，目前的 CDSR 方法是封闭世界的假设，假设用户在多个域之间完全重叠，并且从训练环境到测试环境的数据分布保持不变。因此，由于数据分布的变化，这些方法通常会导致在线真实世界平台上的性能降低。为了解决开放世界条件下的这些挑战，我们设计了一个跨域序列推荐(AMID)的自适应多兴趣去偏框架，该框架由一个多兴趣信息模块(MIM)和一个双鲁棒估计器(DRE)组成。我们的框架是适应开放世界的环境，可以改进大多数现成的单域顺序骨干模型的 CDSR。我们的 MIM 建立了考虑重叠和非重叠用户的兴趣组，允许我们有效地探索用户意图和明确的兴趣。为了减轻跨多个域的偏差，我们为 CDSR 方法开发了 DRE。我们还提供了一个理论分析，证明了我们提出的估计器在偏差和尾界方面的优越性，相比之下，在以前的工作中使用的 IPS 估计器。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rethinking+Cross-Domain+Sequential+Recommendation+under+Open-World+Assumptions)|0|
|[Not All Embeddings are Created Equal: Towards Robust Cross-domain Recommendation via Contrastive Learning](https://doi.org/10.1145/3589334.3645357)|Wenhao Yang, Yingchun Jian, Yibo Wang, Shiyin Lu, Lei Shen, Bing Wang, Haihong Tang, Lijun Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Not+All+Embeddings+are+Created+Equal:+Towards+Robust+Cross-domain+Recommendation+via+Contrastive+Learning)|0|
|[Efficient Noise-Decoupling for Multi-Behavior Sequential Recommendation](https://doi.org/10.1145/3589334.3645380)|Yongqiang Han, Hao Wang, Kefan Wang, Likang Wu, Zhi Li, Wei Guo, Yong Liu, Defu Lian, Enhong Chen||In recommendation systems, users frequently engage in multiple types of behaviors, such as clicking, adding to a cart, and purchasing. However, with diversified behavior data, user behavior sequences will become very long in the short term, which brings challenges to the efficiency of the sequence recommendation model. Meanwhile, some behavior data will also bring inevitable noise to the modeling of user interests. To address the aforementioned issues, firstly, we develop the Efficient Behavior Sequence Miner (EBM) that efficiently captures intricate patterns in user behavior while maintaining low time complexity and parameter count. Secondly, we design hard and soft denoising modules for different noise types and fully explore the relationship between behaviors and noise. Finally, we introduce a contrastive loss function along with a guided training strategy to compare the valid information in the data with the noisy signal, and seamlessly integrate the two denoising processes to achieve a high degree of decoupling of the noisy signal. Sufficient experiments on real-world datasets demonstrate the effectiveness and efficiency of our approach in dealing with multi-behavior sequential recommendation.|在推荐系统中，用户经常参与多种类型的行为，比如点击、添加到购物车和购买。然而，随着用户行为数据的多样化，短期内用户行为序列将变得非常长，这对序列推荐模型的有效性提出了挑战。同时，一些行为数据也会给用户兴趣建模带来不可避免的干扰。为了解决上述问题，首先，我们开发了高效行为序列挖掘器(EBM) ，它能够有效地捕获用户行为中的复杂模式，同时保持较低的时间复杂度和参数计数。其次，针对不同的噪声类型设计了软硬件去噪模块，并充分探讨了行为与噪声之间的关系。最后，引入对比损失函数和引导训练策略，将数据中的有效信息与噪声信号进行比较，并将两个去噪过程无缝结合，实现了噪声信号的高度解耦。通过对实际数据集的大量实验，验证了该方法处理多行为顺序推荐的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Noise-Decoupling+for+Multi-Behavior+Sequential+Recommendation)|0|
|[Debiasing Recommendation with Personal Popularity](https://doi.org/10.1145/3589334.3645421)|Wentao Ning, Reynold Cheng, Xiao Yan, Ben Kao, Nan Huo, Nur Al Hasan Haldar, Bo Tang||Global popularity (GP) bias is the phenomenon that popular items are recommended much more frequently than they should be, which goes against the goal of providing personalized recommendations and harms user experience and recommendation accuracy. Many methods have been proposed to reduce GP bias but they fail to notice the fundamental problem of GP, i.e., it considers popularity from a global perspective of all users and uses a single set of popular items, and thus cannot capture the interests of individual users. As such, we propose a user-aware version of item popularity named personal popularity (PP), which identifies different popular items for each user by considering the users that share similar interests. As PP models the preferences of individual users, it naturally helps to produce personalized recommendations and mitigate GP bias. To integrate PP into recommendation, we design a general personal popularity aware counterfactual (PPAC) framework, which adapts easily to existing recommendation models. In particular, PPAC recognizes that PP and GP have both direct and indirect effects on recommendations and controls direct effects with counterfactual inference techniques for unbiased recommendations. All codes and datasets are available at <https://github.com/Stevenn9981/PPAC>.|全球流行度偏差(GP 偏差)是指流行项目被推荐的频率大大高于其应有频率的现象，与提供个性化推荐的目标背道而驰，损害了用户体验和推荐准确性。人们提出了许多减少 GP 偏差的方法，但都没有注意到 GP 的根本问题，即它从全局的角度考虑所有用户的受欢迎程度，使用单一的流行项目集，因此不能捕捉到个体用户的兴趣。因此，我们提出了一个名为个人知名度(PP)的项目知名度的用户感知版本，它通过考虑具有相似兴趣的用户来为每个用户识别不同的流行项目。作为 PP 模型的个人用户的偏好，它自然有助于产生个性化的推荐和减轻 GP 偏见。为了将 PP 整合到推荐中，我们设计了一个通用的个人知名度反事实(PPAC)框架，该框架很容易适应现有的推荐模型。特别是，PPAC 认识到 PP 和 GP 对建议有直接和间接的影响，并通过反事实推理技术控制对无偏见建议的直接影响。所有代码和数据集都可以在 <  https://github.com/stevenn9981/ppac 获得。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Debiasing+Recommendation+with+Personal+Popularity)|0|
|[Negative Sampling in Next-POI Recommendations: Observation, Approach, and Evaluation](https://doi.org/10.1145/3589334.3645681)|HongKyun Bae, Yebeen Kim, Hyunjoon Kim, SangWook Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Negative+Sampling+in+Next-POI+Recommendations:+Observation,+Approach,+and+Evaluation)|0|
|[Towards Personalized Privacy: User-Governed Data Contribution for Federated Recommendation](https://doi.org/10.1145/3589334.3645690)|Liang Qu, Wei Yuan, Ruiqi Zheng, Lizhen Cui, Yuhui Shi, Hongzhi Yin||Federated recommender systems (FedRecs) have gained significant attention for their potential to protect user's privacy by keeping user privacy data locally and only communicating model parameters/gradients to the server. Nevertheless, the currently existing architecture of FedRecs assumes that all users have the same 0-privacy budget, i.e., they do not upload any data to the server, thus overlooking those users who are less concerned about privacy and are willing to upload data to get a better recommendation service. To bridge this gap, this paper explores a user-governed data contribution federated recommendation architecture where users are free to take control of whether they share data and the proportion of data they share to the server. To this end, this paper presents a cloud-device collaborative graph neural network federated recommendation model, named CDCGNNFed. It trains user-centric ego graphs locally, and high-order graphs based on user-shared data in the server in a collaborative manner via contrastive learning. Furthermore, a graph mending strategy is utilized to predict missing links in the graph on the server, thus leveraging the capabilities of graph neural networks over high-order graphs. Extensive experiments were conducted on two public datasets, and the results demonstrate the effectiveness of the proposed method.|联邦推荐系统(FedRecs)通过将用户隐私数据保存在本地，并且只与服务器通信模型参数/梯度，从而保护用户隐私，因此受到了广泛关注。然而，目前现有的 FedRecs 架构假设所有用户都有相同的零隐私预算，也就是说，他们不向服务器上传任何数据，从而忽略了那些不太关心隐私并愿意上传数据以获得更好的推荐服务的用户。为了弥合这一差距，本文探索了一种用户治理的数据贡献联邦推荐体系结构，在该体系结构中，用户可以自由控制是否共享数据以及共享数据到服务器的比例。为此，本文提出了一种云设备协同图形神经网络联邦推荐模型 CDCGNNFed。它通过对比学习，以协作的方式在本地培训以用户为中心的自我图形和基于服务器中用户共享数据的高阶图形。此外，利用图修正策略来预测服务器上图中缺失的链接，从而利用图神经网络对高阶图的能力。在两个公共数据集上进行了广泛的实验，实验结果表明了该方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Personalized+Privacy:+User-Governed+Data+Contribution+for+Federated+Recommendation)|0|
|[A Semi-supervised Multi-channel Graph Convolutional Network for Query Classification in E-commerce](https://doi.org/10.1145/3589335.3648302)|Chunyuan Yuan, Ming Pang, Zheng Fang, Xue Jiang, Changping Peng, Zhangang Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Semi-supervised+Multi-channel+Graph+Convolutional+Network+for+Query+Classification+in+E-commerce)|0|
|[Rankitect: Ranking Architecture Search Battling World-class Engineers at Meta Scale](https://doi.org/10.1145/3589335.3648304)|Wei Wen, KuangHung Liu, Igor Fedorov, Xin Zhang, Hang Yin, Weiwei Chu, Kaveh Hassani, Mengying Sun, Jiang Liu, Xu Wang, Lin Jiang, Yuxin Chen, Buyun Zhang, Xi Liu, Dehua Cheng, Zhengxing Chen, Guang Zhao, Fangqiu Han, Jiyan Yang, Yuchen Hao, Liang Xiong, WenYen Chen||Neural Architecture Search (NAS) has demonstrated its efficacy in computer vision and potential for ranking systems. However, prior work focused on academic problems, which are evaluated at small scale under well-controlled fixed baselines. In industry system, such as ranking system in Meta, it is unclear whether NAS algorithms from the literature can outperform production baselines because of: (1) scale - Meta ranking systems serve billions of users, (2) strong baselines - the baselines are production models optimized by hundreds to thousands of world-class engineers for years since the rise of deep learning, (3) dynamic baselines - engineers may have established new and stronger baselines during NAS search, and (4) efficiency - the search pipeline must yield results quickly in alignment with the productionization life cycle. In this paper, we present Rankitect, a NAS software framework for ranking systems at Meta. Rankitect seeks to build brand new architectures by composing low level building blocks from scratch. Rankitect implements and improves state-of-the-art (SOTA) NAS methods for comprehensive and fair comparison under the same search space, including sampling-based NAS, one-shot NAS, and Differentiable NAS (DNAS). We evaluate Rankitect by comparing to multiple production ranking models at Meta. We find that Rankitect can discover new models from scratch achieving competitive tradeoff between Normalized Entropy loss and FLOPs. When utilizing search space designed by engineers, Rankitect can generate better models than engineers, achieving positive offline evaluation and online A/B test at Meta scale.|神经结构搜索(NAS)在计算机视觉方面的有效性和排序系统的潜力已得到证实。然而，以前的工作集中在学术问题，这是在小规模评估良好控制的固定基线。在工业系统中，例如 Meta 中的排名系统，目前还不清楚文献中的 NAS 算法是否能够胜过生产基线，因为: (1)规模-Meta 排名系统服务于数十亿用户，(2)强大的基线-基线是自深度学习兴起以来数十到数千名世界级工程师多年来优化的生产模型，(3)动态基线-工程师可能在 NAS 搜索期间建立了新的和更强大的基线，(4)效率-搜索管道必须迅速产生与生产生命周期一致的结果。在本文中，我们介绍了 Rankitect，一个用于 Meta 排序系统的 NAS 软件框架。Rankitect 通过从零开始构建低层次的构建块来构建全新的体系结构。Rankitect 实现并改进了最先进的(SOTA) NAS 方法，以便在同一搜索空间下进行全面和公平的比较，包括基于抽样的 NAS、一次性 NAS 和可微 NAS (DNAS)。我们评估 Rankitect 通过比较在 Meta 的多个生产排名模型。我们发现 Rankitect 可以从头开始发现新的模型，实现归一化熵损失和 FLOP 之间的竞争权衡。当利用工程师设计的搜索空间，Rankitect 可以产生比工程师更好的模型，实现积极的离线评价和在线 A/B 测试在 Meta 规模。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rankitect:+Ranking+Architecture+Search+Battling+World-class+Engineers+at+Meta+Scale)|0|
|[Aligned Side Information Fusion Method for Sequential Recommendation](https://doi.org/10.1145/3589335.3648308)|Shuhan Wang, Bin Shen, Xu Min, Yong He, Xiaolu Zhang, Liang Zhang, Jun Zhou, Linjian Mo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Aligned+Side+Information+Fusion+Method+for+Sequential+Recommendation)|0|
|[Discrete Conditional Diffusion for Reranking in Recommendation](https://doi.org/10.1145/3589335.3648313)|Xiao Lin, Xiaokai Chen, Chenyang Wang, Hantao Shu, Linfeng Song, Biao Li, Peng Jiang||Reranking plays a crucial role in modern multi-stage recommender systems by rearranging the initial ranking list to model interplay between items. Considering the inherent challenges of reranking such as combinatorial searching space, some previous studies have adopted the evaluator-generator paradigm, with a generator producing feasible sequences and a evaluator selecting the best one based on estimated listwise utility. Inspired by the remarkable success of diffusion generative models, this paper explores the potential of diffusion models for generating high-quality sequences in reranking. However, we argue that it is nontrivial to take diffusion models as the generator in the context of recommendation. Firstly, diffusion models primarily operate in continuous data space, differing from the discrete data space of item permutations. Secondly, the recommendation task is different from conventional generation tasks as the purpose of recommender systems is to fulfill user interests. Lastly, real-life recommender systems require efficiency, posing challenges for the inference of diffusion models. To overcome these challenges, we propose a novel Discrete Conditional Diffusion Reranking (DCDR) framework for recommendation. DCDR extends traditional diffusion models by introducing a discrete forward process with tractable posteriors, which adds noise to item sequences through step-wise discrete operations (e.g., swapping). Additionally, DCDR incorporates a conditional reverse process that generates item sequences conditioned on expected user responses. Extensive offline experiments conducted on public datasets demonstrate that DCDR outperforms state-of-the-art reranking methods. Furthermore, DCDR has been deployed in a real-world video app with over 300 million daily active users, significantly enhancing online recommendation quality.|重新排序在现代多阶段推荐系统中起着至关重要的作用，它通过重新排列初始排序列表来模拟项目之间的相互作用。考虑到组合搜索空间等重新排序的内在挑战，以前的一些研究采用了评价者-生成器范式，生成器生成可行序列，评价者根据估计的列表效用选择最佳序列。受扩散生成模型的巨大成功的启发，本文探讨了扩散模型在重新排序中生成高质量序列的潜力。然而，我们认为，在推荐的上下文中，将扩散模型作为生成器是不平凡的。首先，扩散模型主要在连续数据空间中运行，不同于项目排列的离散数据空间。其次，推荐任务不同于传统的生成任务，推荐系统的目的是满足用户的兴趣。最后，现实生活中的推荐系统需要效率，对扩散模型的推理提出了挑战。为了克服这些挑战，我们提出了一个新的离散条件扩散重排序(DCDR)框架的推荐。DCDR 扩展了传统的扩散模型，引入了一个离散的前向过程和易处理的后向过程，通过分步离散操作(例如交换)给项目序列增加了噪声。此外，DCDR 还包含一个条件反向过程，该过程根据预期的用户响应生成项目序列。在公共数据集上进行的大量离线实验表明，DCDR 优于最先进的重新排序方法。此外，DCDR 已经部署在一个现实世界的视频应用程序中，每天有超过3亿的活跃用户，大大提高了在线推荐的质量。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Discrete+Conditional+Diffusion+for+Reranking+in+Recommendation)|0|
|[A New Creative Generation Pipeline for Click-Through Rate with Stable Diffusion Model](https://doi.org/10.1145/3589335.3648315)|Hao Yang, Jianxin Yuan, Shuai Yang, Linhe Xu, Shuo Yuan, Yifan Zeng||In online advertising scenario, sellers often create multiple creatives to provide comprehensive demonstrations, making it essential to present the most appealing design to maximize the Click-Through Rate (CTR). However, sellers generally struggle to consider users preferences for creative design, leading to the relatively lower aesthetics and quantities compared to Artificial Intelligence (AI)-based approaches. Traditional AI-based approaches still face the same problem of not considering user information while having limited aesthetic knowledge from designers. In fact that fusing the user information, the generated creatives can be more attractive because different users may have different preferences. To optimize the results, the generated creatives in traditional methods are then ranked by another module named creative ranking model. The ranking model can predict the CTR score for each creative considering user features. However, the two above stages are regarded as two different tasks and are optimized separately. In this paper, we proposed a new automated Creative Generation pipeline for Click-Through Rate (CG4CTR) with the goal of improving CTR during the creative generation stage. Our contributions have 4 parts: 1) The inpainting mode in stable diffusion is firstly applied to creative generation task in online advertising scene. A self-cyclic generation pipeline is proposed to ensure the convergence of training. 2) Prompt model is designed to generate individualized creatives for different user groups, which can further improve the diversity and quality. 3) Reward model comprehensively considers the multimodal features of image and text to improve the effectiveness of creative ranking task, and it is also critical in self-cyclic pipeline. 4) The significant benefits obtained in online and offline experiments verify the significance of our proposed method.|在网络广告中，卖家经常创造出多种创意来提供全面的展示，因此展示最具吸引力的设计来最大限度地提高点进率是必不可少的。然而，与基于人工智能(AI)的方法相比，卖家通常难以考虑用户对创意设计的偏好，导致相对较低的审美和数量。传统的基于人工智能的方法仍然面临着同样的问题，没有考虑用户信息，同时从设计师有限的美学知识。事实上，融合用户信息，生成的创意可以更具吸引力，因为不同的用户可能有不同的偏好。为了优化结果，在传统方法中生成的创意，然后排名的另一个模块称为创意排名模型。该排名模型可以预测每个创意的 CTR 得分考虑用户的特点。然而，上述两个阶段被视为两个不同的任务，并分别进行了优化。在这篇文章中，我们提出了一个新的自动化创意生成流水线(cg4CTR)点进率，目标是在创意生成阶段提高点击率。本文的工作主要包括四个部分: 1)首次将稳定扩散的修补模式应用于网络广告场景的创意生成任务。为了保证训练的收敛性，提出了一种自循环发电流水线。2)提示模型针对不同的用户群体生成个性化的创意，从而进一步提高用户群体的多样性和质量。3)奖励模型综合考虑了图像和文本的多模态特征，提高了创造性排序任务的有效性，在自循环流水线中起着关键作用。4)在在线和离线实验中获得的显著好处验证了我们提出的方法的重要性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+New+Creative+Generation+Pipeline+for+Click-Through+Rate+with+Stable+Diffusion+Model)|0|
|[NoteLLM: A Retrievable Large Language Model for Note Recommendation](https://doi.org/10.1145/3589335.3648314)|Chao Zhang, Shiwei Wu, Haoxin Zhang, Tong Xu, Yan Gao, Yao Hu, Enhong Chen||People enjoy sharing "notes" including their experiences within online communities. Therefore, recommending notes aligned with user interests has become a crucial task. Existing online methods only input notes into BERT-based models to generate note embeddings for assessing similarity. However, they may underutilize some important cues, e.g., hashtags or categories, which represent the key concepts of notes. Indeed, learning to generate hashtags/categories can potentially enhance note embeddings, both of which compress key note information into limited content. Besides, Large Language Models (LLMs) have significantly outperformed BERT in understanding natural languages. It is promising to introduce LLMs into note recommendation. In this paper, we propose a novel unified framework called NoteLLM, which leverages LLMs to address the item-to-item (I2I) note recommendation. Specifically, we utilize Note Compression Prompt to compress a note into a single special token, and further learn the potentially related notes' embeddings via a contrastive learning approach. Moreover, we use NoteLLM to summarize the note and generate the hashtag/category automatically through instruction tuning. Extensive validations on real scenarios demonstrate the effectiveness of our proposed method compared with the online baseline and show major improvements in the recommendation system of Xiaohongshu.|人们喜欢分享“笔记”，包括他们在网上社区的经历。因此，推荐符合用户兴趣的注意事项已成为一项关键任务。现有的在线方法仅将注释输入到基于 BERT 的模型中，以生成注释嵌入以评估相似性。然而，他们可能没有充分利用一些重要的线索，例如，标签或类别，这代表了笔记的关键概念。事实上，学习生成 # 标签/类别可以潜在地增强笔记的嵌入，这两者都可以将关键笔记信息压缩到有限的内容中。此外，大型语言模型(LLM)在理解自然语言方面明显优于 BERT。有希望将 LLM 引入票据推荐中。在本文中，我们提出了一个新的统一框架 NoteLLM，它利用 LLM 来处理项到项(I2I)注释推荐。具体来说，我们利用 Note CompressionPrompt 将一个音符压缩成一个单独的特殊标记，并通过对比学习的方法进一步学习潜在相关音符的嵌入。此外，我们使用 NoteLLM 来汇总注释，并通过指令调优自动生成 hashtag/type。对实际情景的广泛验证表明，与在线基准相比，我们建议的方法是有效的，并显示 Xiaohongshu 的推荐系统有了重大改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NoteLLM:+A+Retrievable+Large+Language+Model+for+Note+Recommendation)|0|
|[Lightweight GCN Encoder and Sequential Decoder for Multi-Candidate Carpooling Route Planning in Road Network](https://doi.org/10.1145/3589335.3648328)|Yucen Gao, Li Ma, Zhemeng Yu, Songjian Zhang, Jun Fang, Xiaofeng Gao, Guihai Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Lightweight+GCN+Encoder+and+Sequential+Decoder+for+Multi-Candidate+Carpooling+Route+Planning+in+Road+Network)|0|
|[PPM : A Pre-trained Plug-in Model for Click-through Rate Prediction](https://doi.org/10.1145/3589335.3648329)|Yuanbo Gao, Peng Lin, Dongyue Wang, Feng Mei, Xiwei Zhao, Sulong Xu, Jinghe Hu||Click-through rate (CTR) prediction is a core task in recommender systems. Existing methods (IDRec for short) rely on unique identities to represent distinct users and items that have prevailed for decades. On one hand, IDRec often faces significant performance degradation on cold-start problem; on the other hand, IDRec cannot use longer training data due to constraints imposed by iteration efficiency. Most prior studies alleviate the above problems by introducing pre-trained knowledge(e.g. pre-trained user model or multi-modal embeddings). However, the explosive growth of online latency can be attributed to the huge parameters in the pre-trained model. Therefore, most of them cannot employ the unified model of end-to-end training with IDRec in industrial recommender systems, thus limiting the potential of the pre-trained model. To this end, we propose a Pre-trained Plug-in CTR Model, namely PPM. PPM employs multi-modal features as input and utilizes large-scale data for pre-training. Then, PPM is plugged in IDRec model to enhance unified model's performance and iteration efficiency. Upon incorporating IDRec model, certain intermediate results within the network are cached, with only a subset of the parameters participating in training and serving. Hence, our approach can successfully deploy an end-to-end model without causing huge latency increases. Comprehensive offline experiments and online A/B testing at JD E-commerce demonstrate the efficiency and effectiveness of PPM.|点进率预测是推荐系统的核心任务。现有的方法(简称 IDRec)依赖于独特的标识来表示流行了几十年的不同用户和项目。一方面，IDRec 在冷启动问题上经常面临严重的性能下降; 另一方面，由于迭代效率的限制，IDRec 不能使用更长的训练数据。大多数先前的研究通过引入预先训练的知识(例如预先训练的用户模型或多模态嵌入)来缓解上述问题。然而，在线延迟的爆炸性增长可归因于预训练模型中的大量参数。因此，它们中的大多数无法在工业推荐系统中使用 IDRec 的端到端培训统一模型，从而限制了预先培训模型的潜力。为此，我们提出了一个预训练的插件点击率模型，即 PPM。PPM 采用多模态特征作为输入，利用大规模数据进行预训练。然后，在 IDRec 模型中插入 PPM，以提高统一模型的性能和迭代效率。在加入 IDRec 模型后，网络中的某些中间结果被缓存，只有一部分参数参与训练和服务。因此，我们的方法可以成功地部署端到端模型，而不会造成巨大的延迟增加。JD 电子商务的全面离线实验和在线 A/B 测试证明了 PPM 的效率和有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PPM+:+A+Pre-trained+Plug-in+Model+for+Click-through+Rate+Prediction)|0|
|[Towards Robustness Analysis of E-Commerce Ranking System](https://doi.org/10.1145/3589335.3648335)|Ningfei Wang, Yupin Huang, Han Cheng, Jiri Gesi, Xiaojie Wang, Vivek Mittal||Information retrieval (IR) is a pivotal component in various applications. Recent advances in machine learning (ML) have enabled the integration of ML algorithms into IR, particularly in ranking systems. While there is a plethora of research on the robustness of ML-based ranking systems, these studies largely neglect commercial e-commerce systems and fail to establish a connection between real-world and manipulated query relevance. In this paper, we present the first systematic measurement study on the robustness of e-commerce ranking systems. We define robustness as the consistency of ranking outcomes for semantically identical queries. To quantitatively analyze robustness, we propose a novel metric that considers both ranking position and item-specific information that are absent in existing metrics. Our large-scale measurement study with real-world data from e-commerce retailers reveals an open opportunity to measure and improve robustness since semantically identical queries often yield inconsistent ranking results. Based on our observations, we propose several solution directions to enhance robustness, such as the use of Large Language Models. Note that the issue of robustness discussed herein does not constitute an error or oversight. Rather, in scenarios where there exists a vast array of choices, it is feasible to present a multitude of products in various permutations, all of which could be equally appealing. However, this extensive selection may lead to customer confusion. As e-commerce retailers use various techniques to improve the quality of search results, we hope that this research offers valuable guidance for measuring the robustness of the ranking systems.|信息检索(IR)是各种应用中的关键组成部分。机器学习(ML)的最新进展使得 ML 算法能够集成到 IR 中，特别是在排序系统中。尽管对基于机器学习的排序系统的稳健性有大量的研究，但这些研究很大程度上忽视了商业电子商务系统，并且未能在现实世界和被操纵的查询相关性之间建立联系。本文首次对电子商务排名系统的稳健性进行了系统的度量研究。我们将鲁棒性定义为语义相同查询的排序结果的一致性。为了定量分析稳健性，我们提出了一种新的度量方法，该方法同时考虑了排名位置和现有度量方法中不存在的项目特定信息。我们对来自电子商务零售商的真实世界数据进行的大规模测量研究揭示了测量和提高健壮性的公开机会，因为语义相同的查询经常产生不一致的排名结果。基于我们的观察，我们提出了几个增强健壮性的解决方案方向，例如使用大型语言模型。请注意，本文讨论的健壮性问题并不构成错误或疏忽。相反，在存在大量选择的情况下，以不同的排列方式呈现多种产品是可行的，所有这些产品都同样具有吸引力。然而，这种广泛的选择可能会导致客户的困惑。随着电子商务零售商使用各种技术来提高搜索结果的质量，我们希望这项研究能够为衡量排名系统的稳健性提供有价值的指导。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Robustness+Analysis+of+E-Commerce+Ranking+System)|0|
|[End-to-End Graph-Sequential Representation Learning for Accurate Recommendations](https://doi.org/10.1145/3589335.3651499)|Vladimir Baikalov, Evgeny Frolov||Recent recommender system advancements have focused on developing sequence-based and graph-based approaches. Both approaches proved useful in modeling intricate relationships within behavioral data, leading to promising outcomes in personalized ranking and next-item recommendation tasks while maintaining good scalability. However, they capture very different signals from data. While the former approach represents users directly through ordered interactions with recent items, the latter aims to capture indirect dependencies across the interactions graph. This paper presents a novel multi-representational learning framework exploiting these two paradigms' synergies. Our empirical evaluation on several datasets demonstrates that mutual training of sequential and graph components with the proposed framework significantly improves recommendations performance.|最近的推荐系统进展集中在开发基于序列和基于图表的方法。事实证明，这两种方法在建模行为数据中错综复杂的关系时都很有用，在保持良好可伸缩性的同时，在个性化排名和下一项推荐任务中产生了有希望的结果。然而，它们从数据中捕获非常不同的信号。前一种方法通过与最近项目的有序交互直接表示用户，而后一种方法旨在捕获交互图中的间接依赖关系。本文提出了一个新的多表征学习框架，利用这两个范式的协同作用。我们对几个数据集的实证评估表明，使用所提出的框架对顺序和图形组件进行相互训练可以显著提高推荐性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=End-to-End+Graph-Sequential+Representation+Learning+for+Accurate+Recommendations)|0|
|[DiffuRetrieval: A Chain-of-Thought Enhanced Diffusion Retrieval in Sponsored Search](https://doi.org/10.1145/3589335.3651491)|Yadong Zhang, Siyu Lu, Qiang Liu, Xingxing Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DiffuRetrieval:+A+Chain-of-Thought+Enhanced+Diffusion+Retrieval+in+Sponsored+Search)|0|
|[The Impact of Cluster Centroid and Text Review Embeddings on Recommendation Methods](https://doi.org/10.1145/3589335.3651570)|Peter Dolog, Ylli Sadikaj, Yllka Velaj, Andreas Stephan, Benjamin Roth, Claudia Plant||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Impact+of+Cluster+Centroid+and+Text+Review+Embeddings+on+Recommendation+Methods)|0|
|[Rethinking Sequential Relationships: Improving Sequential Recommenders with Inter-Sequence Data Augmentation](https://doi.org/10.1145/3589335.3651552)|Yang Jiao, Fan Yang, Yetian Chen, Yan Gao, Jia Liu, Yi Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rethinking+Sequential+Relationships:+Improving+Sequential+Recommenders+with+Inter-Sequence+Data+Augmentation)|0|
|[Unsupervised Search Algorithm Configuration using Query Performance Prediction](https://doi.org/10.1145/3589335.3651579)|Haggai Roitman||Search engine configuration can be quite difficult for inexpert developers. Instead, an auto-configuration approach can be used to speed up development time. Yet, such an automatic process usually requires relevance labels to train a supervised model. In this work, we suggest a simple solution based on query performance prediction that requires no relevance labels but only a sample of queries in a given domain. Using two example usecases we demonstrate the merits of our solution.|搜索 engine configuration 对于不专业的开发者来说是相当困难的。相反，可以使用自动配置方法来加快开发时间。然而，这样一个自动化的过程通常需要相关标签来训练一个受监督的模型。在这项工作中，我们提出了一个基于查询性能预测的简单解决方案，它不需要相关标签，只需要给定域中的查询样本。通过两个例子，我们证明了我们的解决方案的优点。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unsupervised+Search+Algorithm+Configuration+using+Query+Performance+Prediction)|0|
|[I-CoSim: Efficient Dynamic CoSimRank Retrieval on Evolving Networks](https://doi.org/10.1145/3589335.3651523)|Xiaoyu Xu, Weiren Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=I-CoSim:+Efficient+Dynamic+CoSimRank+Retrieval+on+Evolving+Networks)|0|
|[Unlocking the Potential of Health Data with Decentralised Search in Personal Health Datastores](https://doi.org/10.1145/3589335.3651454)|Mohamed Ragab, Yury Savateev, Helen Oliver, Thanassis Tiropanis, Alexandra Poulovassilis, Adriane Chapman, George Roussos||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unlocking+the+Potential+of+Health+Data+with+Decentralised+Search+in+Personal+Health+Datastores)|0|
|[TATKC: A Temporal Graph Neural Network for Fast Approximate Temporal Katz Centrality Ranking](https://doi.org/10.1145/3589334.3645432)|Tianming Zhang, Junkai Fang, Zhengyi Yang, Bin Cao, Jing Fan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TATKC:+A+Temporal+Graph+Neural+Network+for+Fast+Approximate+Temporal+Katz+Centrality+Ranking)|0|
|[FairSync: Ensuring Amortized Group Exposure in Distributed Recommendation Retrieval](https://doi.org/10.1145/3589334.3645413)|Chen Xu, Jun Xu, Yiming Ding, Xiao Zhang, Qi Qi||In pursuit of fairness and balanced development, recommender systems (RS) often prioritize group fairness, ensuring that specific groups maintain a minimum level of exposure over a given period. For example, RS platforms aim to ensure adequate exposure for new providers or specific categories of items according to their needs. Modern industry RS usually adopts a two-stage pipeline: stage-1 (retrieval stage) retrieves hundreds of candidates from millions of items distributed across various servers, and stage-2 (ranking stage) focuses on presenting a small-size but accurate selection from items chosen in stage-1. Existing efforts for ensuring amortized group exposures focus on stage-2, however, stage-1 is also critical for the task. Without a high-quality set of candidates, the stage-2 ranker cannot ensure the required exposure of groups. Previous fairness-aware works designed for stage-2 typically require accessing and traversing all items. In stage-1, however, millions of items are distributively stored in servers, making it infeasible to traverse all of them. How to ensure group exposures in the distributed retrieval process is a challenging question. To address this issue, we introduce a model named FairSync, which transforms the problem into a constrained distributed optimization problem. Specifically, FairSync resolves the issue by moving it to the dual space, where a central node aggregates historical fairness data into a vector and distributes it to all servers. To trade off the efficiency and accuracy, the gradient descent technique is used to periodically update the parameter of the dual vector. The experiment results on two public recommender retrieval datasets showcased that FairSync outperformed all the baselines, achieving the desired minimum level of exposures while maintaining a high level of retrieval accuracy.|为了追求公平和均衡发展，推荐系统(RS)经常优先考虑群体公平性，确保特定群体在给定的时间内保持最低的曝光水平。例如，RS 平台旨在确保新供应商或根据其需要的具体项目类别获得足够的曝光。现代工业 RS 通常采用两阶段流水线: 阶段1(检索阶段)从分布在不同服务器上的数百万个项目中检索数百个候选项，阶段2(排名阶段)侧重于从阶段1中选择的项目中提供一个小型但准确的选择。现有的努力，以确保摊销群体暴露集中在第二阶段，然而，第一阶段也是至关重要的任务。如果没有一组高质量的候选人，阶段2的排名不能确保所需的群体曝光。以前为阶段2设计的公平感知工作通常需要访问和遍历所有项。然而，在阶段1中，数以百万计的条目分布式地存储在服务器中，这使得遍历所有条目变得不可行。如何保证分布式检索过程中的群体曝光是一个具有挑战性的问题。为了解决这个问题，我们引入了一个名为 FairSync 的模型，它将问题转化为一个受限的分布式最佳化问题。具体来说，FairSync 通过将其移动到双空间来解决这个问题，在双空间中，一个中央节点将历史公平数据聚合到一个向量中，并将其分发到所有服务器。为了权衡效率和准确性，梯度下降法技术被用来定期更新双向量的参数。在两个公共推荐检索数据集上的实验结果表明，FairSync 的性能优于所有基线，在保持较高的检索准确率的同时，达到了预期的最小曝光水平。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FairSync:+Ensuring+Amortized+Group+Exposure+in+Distributed+Recommendation+Retrieval)|0|
|[Cognitive Personalized Search Integrating Large Language Models with an Efficient Memory Mechanism](https://doi.org/10.1145/3589334.3645482)|Yujia Zhou, Qiannan Zhu, Jiajie Jin, Zhicheng Dou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cognitive+Personalized+Search+Integrating+Large+Language+Models+with+an+Efficient+Memory+Mechanism)|0|
|[Asking Multimodal Clarifying Questions in Mixed-Initiative Conversational Search](https://doi.org/10.1145/3589334.3645483)|Yifei Yuan, Clemencia Siro, Mohammad Aliannejadi, Maarten de Rijke, Wai Lam||In mixed-initiative conversational search systems, clarifying questions are used to help users who struggle to express their intentions in a single query. These questions aim to uncover user's information needs and resolve query ambiguities. We hypothesize that in scenarios where multimodal information is pertinent, the clarification process can be improved by using non-textual information. Therefore, we propose to add images to clarifying questions and formulate the novel task of asking multimodal clarifying questions in open-domain, mixed-initiative conversational search systems. To facilitate research into this task, we collect a dataset named Melon that contains over 4k multimodal clarifying questions, enriched with over 14k images. We also propose a multimodal query clarification model named Marto and adopt a prompt-based, generative fine-tuning strategy to perform the training of different stages with different prompts. Several analyses are conducted to understand the importance of multimodal contents during the query clarification phase. Experimental results indicate that the addition of images leads to significant improvements of up to 90 images. Extensive analyses are also performed to show the superiority of Marto compared with discriminative baselines in terms of effectiveness and efficiency.|在混合主动会话搜索系统中，澄清问题用于帮助那些在单个查询中难以表达意图的用户。这些问题旨在揭示用户的信息需求和解决查询模糊性。我们假设在多模态信息相关的场景中，可以通过使用非文本信息来改进澄清过程。因此，我们建议在会话搜索系统中增加图像来解决问题，并提出在开放领域、混合主动的会话搜索系统中提出多模态问题的新任务。为了促进这项任务的研究，我们收集了一个名为 Melon 的数据集，其中包含了超过4k 个多模式澄清问题，丰富了超过14k 个图像。我们还提出了一个名为 Marto 的多模式查询澄清模型，并采用基于提示的生成式微调策略对不同提示的不同阶段进行训练。为了理解在查询澄清阶段多通道内容的重要性，进行了一些分析。实验结果表明，增加图像导致显着改善高达90图像。还进行了广泛的分析，以显示 Marto 相对于有效性和效率的判别基线的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Asking+Multimodal+Clarifying+Questions+in+Mixed-Initiative+Conversational+Search)|0|
|[Benchmark and Neural Architecture for Conversational Entity Retrieval from a Knowledge Graph](https://doi.org/10.1145/3589334.3645676)|Mona Zamiri, Yao Qiang, Fedor Nikolaev, Dongxiao Zhu, Alexander Kotov||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Benchmark+and+Neural+Architecture+for+Conversational+Entity+Retrieval+from+a+Knowledge+Graph)|0|
|[A Data-Centric Multi-Objective Learning Framework for Responsible Recommendation Systems](https://doi.org/10.1145/3589334.3645324)|Xu Huang, Jianxun Lian, Hao Wang, Hao Liao, Defu Lian, Xing Xie||Recommendation systems effectively guide users in locating their desired information within extensive content repositories. Generally, a recommendation model is optimized to enhance accuracy metrics from a user utility standpoint, such as click-through rate or matching relevance. However, a responsible industrial recommendation system must address not only user utility (responsibility to users) but also other objectives, including increasing platform revenue (responsibility to platforms), ensuring fairness (responsibility to content creators), and maintaining unbiasedness (responsibility to long-term healthy development). Multi-objective learning is a potent approach for achieving responsible recommendation systems. Nevertheless, current methods encounter two challenges: difficulty in scaling to heterogeneous objectives within a unified framework, and inadequate controllability over objective priority during optimization, leading to uncontrollable solutions. In this paper, we present a data-centric optimization framework, MoRec, which unifies the learning of diverse objectives. MoRec is a tri-level framework: the outer level manages the balance between different objectives, utilizing a proportional-integral-derivative (PID)-based controller to ensure a preset regularization on the primary objective. The middle level transforms objective-aware optimization into data sampling weights using sign gradients. The inner level employs a standard optimizer to update model parameters with the sampled data. Consequently, MoRec can flexibly support various objectives while maintaining the original model intact. Comprehensive experiments on two public datasets and one industrial dataset showcase the effectiveness, controllability, flexibility, and Pareto efficiency of MoRec, making it highly suitable for real-world implementation.|推荐系统有效地指导用户在广泛的内容存储库中查找所需的信息。一般来说，推荐模型会优化，以从用户效用的角度提高准确性指标，比如点进率或匹配相关性。然而，一个负责任的行业推荐系统不仅要解决用户效用(对用户的责任) ，还要解决其他目标，包括增加平台收入(对平台的责任) ，确保公平(对内容创建者的责任) ，保持无偏见(对长期健康发展的责任)。多目标学习是实现负责任推荐系统的有效方法。然而，目前的方法遇到两个挑战: 难以在统一的框架内扩展到异构的目标，以及在优化过程中对目标优先级的可控性不足，导致不可控的解决方案。在本文中，我们提出了一个以数据为中心的优化框架 MoRec，它统一了不同目标的学习。MoRec 是一个三层框架: 外层管理不同目标之间的平衡，利用比例积分微分(PID)为基础的控制器，以确保预设正则化的主要目标。中间层利用符号梯度将目标感知优化转换为数据采样权重。内部级别使用标准优化器用采样数据更新模型参数。因此，MoRec 可以灵活地支持各种目标，同时保持原始模型的完整性。在两个公共数据集和一个工业数据集上进行的全面实验展示了 MoRec 的有效性、可控性、灵活性和帕累托最优，使其非常适合于现实世界的实现。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Data-Centric+Multi-Objective+Learning+Framework+for+Responsible+Recommendation+Systems)|0|
|[Collaborative Large Language Model for Recommender Systems](https://doi.org/10.1145/3589334.3645347)|Yaochen Zhu, Liang Wu, Qi Guo, Liangjie Hong, Jundong Li||Recently, there is a growing interest in developing next-generation recommender systems (RSs) based on pretrained large language models (LLMs), fully utilizing their encoded knowledge and reasoning ability. However, the semantic gap between natural language and recommendation tasks is still not well addressed, leading to multiple issues such as spuriously-correlated user/item descriptors, ineffective language modeling on user/item contents, and inefficient recommendations via auto-regression, etc. In this paper, we propose CLLM4Rec, the first generative RS that tightly integrates the LLM paradigm and ID paradigm of RS, aiming to address the above challenges simultaneously. We first extend the vocabulary of pretrained LLMs with user/item ID tokens to faithfully model the user/item collaborative and content semantics. Accordingly, in the pretraining stage, a novel soft+hard prompting strategy is proposed to effectively learn user/item collaborative/content token embeddings via language modeling on RS-specific corpora established from user-item interactions and user/item features, where each document is split into a prompt consisting of heterogeneous soft (user/item) tokens and hard (vocab) tokens and a main text consisting of homogeneous item tokens or vocab tokens that facilitates stable and effective language modeling. In addition, a novel mutual regularization strategy is introduced to encourage the CLLM4Rec to capture recommendation-oriented information from user/item contents. Finally, we propose a novel recommendation-oriented finetuning strategy for CLLM4Rec, where an item prediction head with multinomial likelihood is added to the pretrained CLLM4Rec backbone to predict hold-out items based on the soft+hard prompts established from masked user-item interaction history, where recommendations of multiple items can be generated efficiently.|近年来，基于预先训练的大语言模型(LLM) ，充分利用其编码知识和推理能力，开发下一代推荐系统(RS)越来越受到人们的关注。然而，自然语言和推荐任务之间的语义差距仍然没有得到很好的解决，导致多种问题，如虚假相关的用户/项目描述符，对用户/项目内容无效的语言建模，以及通过自动回归的低效推荐等。在本文中，我们提出了 CLLM4Rec，这是第一个紧密集成了 RS 的 LLM 范式和 ID 范式的生成 RS，旨在同时解决上述挑战。我们首先扩展带有用户/项目 ID 令牌的预训练 LLM 的词汇表，以忠实地建立用户/项目协作和内容语义的模型。因此，在预训练阶段，提出了一种新的软硬件提示策略，通过对基于用户-项目交互和用户/项目特征建立的 RS 特定语料库进行语言建模，有效地学习用户/项目协作/内容令牌嵌入，将每个文档分解为由异构软(用户/项目)令牌和硬(词汇)令牌组成的提示和由同质项目令牌或词汇令牌组成的主文本，以促进稳定有效的语言建模。此外，还引入了一种新的相互正则化策略，以鼓励 CLLM4Rec 从用户/项目内容中捕获面向推荐的信息。最后，我们为 CLLM4Rec 提出了一种新的面向推荐的微调策略，其中将具有多项式可能性的项目预测头添加到预先训练的 CLLM4Rec 骨干中，以基于从掩盖的用户项目交互历史建立的软 + 硬提示来预测坚持项目，其中可以有效地生成多个项目的推荐。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Collaborative+Large+Language+Model+for+Recommender+Systems)|0|
|[Harnessing Large Language Models for Text-Rich Sequential Recommendation](https://doi.org/10.1145/3589334.3645358)|Zhi Zheng, Wenshuo Chao, Zhaopeng Qiu, Hengshu Zhu, Hui Xiong||Recent advances in Large Language Models (LLMs) have been changing the paradigm of Recommender Systems (RS). However, when items in the recommendation scenarios contain rich textual information, such as product descriptions in online shopping or news headlines on social media, LLMs require longer texts to comprehensively depict the historical user behavior sequence. This poses significant challenges to LLM-based recommenders, such as over-length limitations, extensive time and space overheads, and suboptimal model performance. To this end, in this paper, we design a novel framework for harnessing Large Language Models for Text-Rich Sequential Recommendation (LLM-TRSR). Specifically, we first propose to segment the user historical behaviors and subsequently employ an LLM-based summarizer for summarizing these user behavior blocks. Particularly, drawing inspiration from the successful application of Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) models in user modeling, we introduce two unique summarization techniques in this paper, respectively hierarchical summarization and recurrent summarization. Then, we construct a prompt text encompassing the user preference summary, recent user interactions, and candidate item information into an LLM-based recommender, which is subsequently fine-tuned using Supervised Fine-Tuning (SFT) techniques to yield our final recommendation model. We also use Low-Rank Adaptation (LoRA) for Parameter-Efficient Fine-Tuning (PEFT). We conduct experiments on two public datasets, and the results clearly demonstrate the effectiveness of our approach.|大语言模型(LLM)的最新进展已经改变了推荐系统(RS)的范式。但是，当推荐场景中的条目包含丰富的文本信息时，如在线购物中的产品描述或社交媒体上的新闻标题，LLM 需要更长的文本来全面描述历史用户行为序列。这对基于 LLM 的推荐程序提出了重大挑战，例如超长限制、大量的时间和空间开销以及次优模型性能。为此，在本文中，我们设计了一个新的框架，用于利用大型语言模型进行富文本顺序推荐(LLM-TRSR)。具体来说，我们首先建议分割用户的历史行为，然后使用一个基于 LLM 的总结器来总结这些用户行为块。特别地，借鉴了卷积神经网络(CNN)和递归神经网络(RNN)模型在用户建模中的成功应用，本文介绍了两种独特的文摘技术，分别是层次文摘和递归文摘。然后，我们构建一个包含用户偏好摘要，最近的用户交互和候选项信息的提示文本到基于 LLM 的推荐器中，随后使用监督微调(SFT)技术进行微调以产生我们的最终推荐模型。我们还使用低秩自适应(LoRA)的参数有效微调(PEFT)。我们在两个公共数据集上进行了实验，结果清楚地证明了我们方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Harnessing+Large+Language+Models+for+Text-Rich+Sequential+Recommendation)|0|
|[ClickPrompt: CTR Models are Strong Prompt Generators for Adapting Language Models to CTR Prediction](https://doi.org/10.1145/3589334.3645396)|Jianghao Lin, Bo Chen, Hangyu Wang, Yunjia Xi, Yanru Qu, Xinyi Dai, Kangning Zhang, Ruiming Tang, Yong Yu, Weinan Zhang||Click-through rate (CTR) prediction has become increasingly indispensable for various Internet applications. Traditional CTR models convert the multi-field categorical data into ID features via one-hot encoding, and extract the collaborative signals among features. Such a paradigm suffers from the problem of semantic information loss. Another line of research explores the potential of pretrained language models (PLMs) for CTR prediction by converting input data into textual sentences through hard prompt templates. Although semantic signals are preserved, they generally fail to capture the collaborative information (e.g., feature interactions, pure ID features), not to mention the unacceptable inference overhead brought by the huge model size. In this paper, we aim to model both the semantic knowledge and collaborative knowledge for accurate CTR estimation, and meanwhile address the inference inefficiency issue. To benefit from both worlds and close their gaps, we propose a novel model-agnostic framework (i.e., ClickPrompt), where we incorporate CTR models to generate interaction-aware soft prompts for PLMs. We design a prompt-augmented masked language modeling (PA-MLM) pretraining task, where PLM has to recover the masked tokens based on the language context, as well as the soft prompts generated by CTR model. The collaborative and semantic knowledge from ID and textual features would be explicitly aligned and interacted via the prompt interface. Then, we can either tune the CTR model with PLM for superior performance, or solely tune the CTR model without PLM for inference efficiency. Experiments on four real-world datasets validate the effectiveness of ClickPrompt compared with existing baselines.|对于各种互联网应用而言，点进率预测(ctrl)已变得越来越不可或缺。传统的 CTR 模型通过一次热编码将多领域分类数据转换为 ID 特征，并提取特征间的协同信号。这种模式存在语义信息损失的问题。另一项研究通过硬提示模板将输入数据转换成文本句子，探索了预训练语言模型(PLM)在 CTR 预测中的潜力。尽管保留了语义信号，但它们通常无法捕获协作信息(例如，特征交互、纯 ID 特征) ，更不用说巨大的模型规模带来的不可接受的推理开销。本文旨在建立语义知识和协同知识的模型，以便准确地估计 CTR，同时解决推理效率低下的问题。为了从这两个世界中获益并弥合它们之间的差距，我们提出了一个新的模型无关框架(即 ClickPrompt) ，其中我们结合了 CTR 模型来为 PLM 生成感知交互的软提示。我们设计了一个提示增强的掩码语言建模(PA-MLM)预训练任务，其中 PLM 必须基于语言上下文以及由 CTR 模型生成的软提示来恢复掩码标记。来自 ID 和文本特性的协作和语义知识将通过提示界面显式地对齐和交互。然后，我们可以使用 PLM 调整 CTR 模型以获得更好的性能，或者单独调整不使用 PLM 的 CTR 模型以获得更高的推理效率。在四个实际数据集上的实验验证了 ClickPrompt 与现有基线相比的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ClickPrompt:+CTR+Models+are+Strong+Prompt+Generators+for+Adapting+Language+Models+to+CTR+Prediction)|0|
|[Knowledge-Augmented Large Language Models for Personalized Contextual Query Suggestion](https://doi.org/10.1145/3589334.3645404)|Jinheon Baek, Nirupama Chandrasekaran, Silviu Cucerzan, Allen Herring, Sujay Kumar Jauhar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge-Augmented+Large+Language+Models+for+Personalized+Contextual+Query+Suggestion)|0|
|[Enhancing Recommendation Accuracy and Diversity with Box Embedding: A Universal Framework](https://doi.org/10.1145/3589334.3645577)|Cheng Wu, Shaoyun Shi, Chaokun Wang, Ziyang Liu, Wang Peng, Wenjin Wu, Dongying Kong, Han Li, Kun Gai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Recommendation+Accuracy+and+Diversity+with+Box+Embedding:+A+Universal+Framework)|0|
|[Is Contrastive Learning Necessary? A Study of Data Augmentation vs Contrastive Learning in Sequential Recommendation](https://doi.org/10.1145/3589334.3645661)|Peilin Zhou, YouLiang Huang, Yueqi Xie, Jingqi Gao, Shoujin Wang, Jae Boum Kim, Sunghun Kim||Sequential recommender systems (SRS) are designed to predict users' future behaviors based on their historical interaction data. Recent research has increasingly utilized contrastive learning (CL) to leverage unsupervised signals to alleviate the data sparsity issue in SRS. In general, CL-based SRS first augments the raw sequential interaction data by using data augmentation strategies and employs a contrastive training scheme to enforce the representations of those sequences from the same raw interaction data to be similar. Despite the growing popularity of CL, data augmentation, as a basic component of CL, has not received sufficient attention. This raises the question: Is it possible to achieve superior recommendation results solely through data augmentation? To answer this question, we benchmark eight widely used data augmentation strategies, as well as state-of-the-art CL-based SRS methods, on four real-world datasets under both warm- and cold-start settings. Intriguingly, the conclusion drawn from our study is that, certain data augmentation strategies can achieve similar or even superior performance compared with some CL-based methods, demonstrating the potential to significantly alleviate the data sparsity issue with fewer computational overhead. We hope that our study can further inspire more fundamental studies on the key functional components of complex CL techniques. Our processed datasets and codes are available at https://github.com/AIM-SE/DA4Rec.|序贯推荐系统(SRS)是基于用户的历史交互数据来预测用户未来行为的系统。最近的研究越来越多地利用对比学习(CL)来利用无监督信号来缓解 SRS 中的数据稀疏问题。一般情况下，基于 CL 的 SRS 首先通过数据增强策略对原始序列交互数据进行增强，然后采用对比训练方案强制相同原始交互数据的序列表示相似。数据增强作为协同学习的一个基本组成部分，虽然受到了越来越多的关注，但并没有得到足够的重视。这就提出了一个问题: 是否有可能仅仅通过数据增强来获得更好的推荐结果？为了回答这个问题，我们基准八个广泛使用的数据增强策略，以及最先进的基于 CL 的 SRS 方法，在四个真实世界的数据集上，在暖启动和冷启动设置下。有趣的是，我们的研究得出的结论是，与一些基于 CL 的方法相比，某些数据增强策略可以实现相似甚至更好的性能，表明可以显着缓解数据稀疏问题，计算开销更少。我们希望我们的研究能够进一步启发更多关于复杂化学发光技术关键功能成分的基础研究。我们处理过的数据集和代码可以在 https://github.com/aim-se/da4rec 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Is+Contrastive+Learning+Necessary?+A+Study+of+Data+Augmentation+vs+Contrastive+Learning+in+Sequential+Recommendation)|0|
|[Can Small Language Models be Good Reasoners for Sequential Recommendation?](https://doi.org/10.1145/3589334.3645671)|Yuling Wang, Changxin Tian, Binbin Hu, Yanhua Yu, Ziqi Liu, Zhiqiang Zhang, Jun Zhou, Liang Pang, Xiao Wang||Large language models (LLMs) open up new horizons for sequential recommendations, owing to their remarkable language comprehension and generation capabilities. However, there are still numerous challenges that should be addressed to successfully implement sequential recommendations empowered by LLMs. Firstly, user behavior patterns are often complex, and relying solely on one-step reasoning from LLMs may lead to incorrect or task-irrelevant responses. Secondly, the prohibitively resource requirements of LLM (e.g., ChatGPT-175B) are overwhelmingly high and impractical for real sequential recommender systems. In this paper, we propose a novel Step-by-step knowLedge dIstillation fraMework for recommendation (SLIM), paving a promising path for sequential recommenders to enjoy the exceptional reasoning capabilities of LLMs in a "slim" (i.e., resource-efficient) manner. We introduce CoT prompting based on user behavior sequences for the larger teacher model. The rationales generated by the teacher model are then utilized as labels to distill the downstream smaller student model (e.g., LLaMA2-7B). In this way, the student model acquires the step-by-step reasoning capabilities in recommendation tasks. We encode the generated rationales from the student model into a dense vector, which empowers recommendation in both ID-based and ID-agnostic scenarios. Extensive experiments demonstrate the effectiveness of SLIM over state-of-the-art baselines, and further analysis showcasing its ability to generate meaningful recommendation reasoning at affordable costs.|大型语言模型(LLM)由于其卓越的语言理解和生成能力，为顺序推荐开辟了新的视野。然而，要成功实施 LLM 授权的顺序建议，仍然需要应对许多挑战。首先，用户行为模式通常很复杂，仅仅依靠 LLM 的一步推理可能会导致不正确的或与任务无关的响应。其次，对于真正的顺序推荐系统来说，LLM (如 ChatGPT-175B)过高的资源需求是不切实际的。在本文中，我们提出了一种新的逐步推荐知识提取框架(SLIM) ，为顺序推荐者以“苗条”(即资源效率)的方式享受 LLM 的异常推理能力铺平了一条有希望的道路。我们在较大的教师模型中引入了基于用户行为序列的 CoT 提示。由教师模型产生的基本原理然后被用作标签来提取下游较小的学生模型(例如，LLaMA2-7B)。通过这种方式，学生模型在推荐任务中获得了分步推理的能力。我们将从学生模型生成的基本原理编码成一个密集向量，这使得推荐在基于身份和身份不可知的情况下都有效。大量的实验证明了 SLIM 在最先进的基线上的有效性，并且进一步的分析显示了它以可承受的成本产生有意义的推荐推理的能力。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Can+Small+Language+Models+be+Good+Reasoners+for+Sequential+Recommendation?)|0|
|[Predictive Relevance Uncertainty for Recommendation Systems](https://doi.org/10.1145/3589334.3645689)|Charul Paliwal, Anirban Majumder, Sivaramakrishnan Kaveri||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Predictive+Relevance+Uncertainty+for+Recommendation+Systems)|0|
|[Decentralized Collaborative Learning with Adaptive Reference Data for On-Device POI Recommendation](https://doi.org/10.1145/3589334.3645696)|Ruiqi Zheng, Liang Qu, Tong Chen, Lizhen Cui, Yuhui Shi, Hongzhi Yin||In Location-based Social Networks, Point-of-Interest (POI) recommendation helps users discover interesting places. There is a trend to move from the cloud-based model to on-device recommendations for privacy protection and reduced server reliance. Due to the scarcity of local user-item interactions on individual devices, solely relying on local instances is not adequate. Collaborative Learning (CL) emerges to promote model sharing among users, where reference data is an intermediary that allows users to exchange their soft decisions without directly sharing their private data or parameters, ensuring privacy and benefiting from collaboration. However, existing CL-based recommendations typically use a single reference for all users. Reference data valuable for one user might be harmful to another, given diverse user preferences. Users may not offer meaningful soft decisions on items outside their interest scope. Consequently, using the same reference data for all collaborations can impede knowledge exchange and lead to sub-optimal performance. To address this gap, we introduce the Decentralized Collaborative Learning with Adaptive Reference Data (DARD) framework, which crafts adaptive reference data for effective user collaboration. It first generates a desensitized public reference data pool with transformation and probability data generation methods. For each user, the selection of adaptive reference data is executed in parallel by training loss tracking and influence function. Local models are trained with individual private data and collaboratively with the geographical and semantic neighbors. During the collaboration between two users, they exchange soft decisions based on a combined set of their adaptive reference data. Our evaluations across two real-world datasets highlight DARD's superiority in recommendation performance and addressing the scarcity of available reference data.|在基于位置的社交网络中，兴趣点(POI)推荐帮助用户发现有趣的地方。有一种趋势是从基于云的模型转向基于设备的建议，以保护隐私并减少对服务器的依赖。由于在单个设备上缺乏本地用户项交互，仅仅依赖本地实例是不够的。合作学习(CL)的出现是为了促进用户之间的模式共享，其中参考数据是一种中介，允许用户在不直接共享其私人数据或参数的情况下交换软决策，确保隐私并从合作中受益。但是，现有的基于 CL 的建议通常对所有用户使用单个引用。鉴于不同的用户偏好，对一个用户有价值的参考数据可能对另一个用户有害。用户可能不会对他们感兴趣的范围之外的项目提供有意义的软决策。因此，对所有协作使用相同的参考数据可能会阻碍知识交流并导致次优性能。为了解决这一差距，我们引入了自适应参考数据(dARD)框架的分散式合作学习，该框架为有效的用户协作提供自适应参考数据。它首先使用转换和概率数据生成方法生成一个不敏感的公共参考数据池。对于每个用户，通过训练损失跟踪和影响函数并行执行自适应参考数据的选择。局部模型用单个私有数据进行训练，并与地理和语义邻居协作进行训练。在两个用户之间的协作过程中，他们基于一组自适应参考数据交换软决策。我们对两个实际数据集的评估突出了 DARD 在推荐性能和解决可用参考数据稀缺性方面的优势。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Decentralized+Collaborative+Learning+with+Adaptive+Reference+Data+for+On-Device+POI+Recommendation)|0|
|[Towards Efficient Communication and Secure Federated Recommendation System via Low-rank Training](https://doi.org/10.1145/3589334.3645702)|NgocHieu Nguyen, TuanAnh Nguyen, Tuan Nguyen, Vu Tien Hoang, Dung D. Le, KokSeng Wong||Federated Recommendation (FedRec) systems have emerged as a solution to safeguard users' data in response to growing regulatory concerns. However, one of the major challenges in these systems lies in the communication costs that arise from the need to transmit neural network models between user devices and a central server. Prior approaches to these challenges often lead to issues such as computational overheads, model specificity constraints, and compatibility issues with secure aggregation protocols. In response, we propose a novel framework, called Correlated Low-rank Structure (CoLR), which leverages the concept of adjusting lightweight trainable parameters while keeping most parameters frozen. Our approach substantially reduces communication overheads without introducing additional computational burdens. Critically, our framework remains fully compatible with secure aggregation protocols, including the robust use of Homomorphic Encryption. The approach resulted in a reduction of up to 93.75 recommendation performance across datasets. Code for reproducing our experiments can be found at https://github.com/NNHieu/CoLR-FedRec.|联邦推荐(FedRec)系统已经成为保护用户数据的一种解决方案，以应对日益增长的监管问题。然而，这些系统的主要挑战之一在于需要在用户设备和中央服务器之间传输神经网络模型而产生的通信成本。先前解决这些挑战的方法通常会导致诸如计算开销、模型特异性约束和与安全聚合协议的兼容性问题等问题。作为回应，我们提出了一种新的框架，称为相关低级结构(CoLR) ，它利用了调整轻量级可训练参数的概念，同时保持大多数参数冻结。我们的方法大大减少了通信开销，而不会引入额外的计算负担。重要的是，我们的框架仍然完全兼容安全的聚合协议，包括同态加密的健壮使用。这种方法导致跨数据集的推荐性能最多降低了93.75。重现我们实验的代码可以在 https://github.com/nnhieu/colr-fedrec 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Efficient+Communication+and+Secure+Federated+Recommendation+System+via+Low-rank+Training)|0|
|[A User-State Based Interest Transfer Network for Cross-Domain Recommendation](https://doi.org/10.1145/3589335.3651465)|Pingjun Pan, Jialu Wang, Tingting Zhou, Wenyu Yang, Hongxiang Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+User-State+Based+Interest+Transfer+Network+for+Cross-Domain+Recommendation)|0|
|[Position Bias Estimation with Item Embedding for Sparse Dataset](https://doi.org/10.1145/3589335.3651546)|Shion Ishikawa, Yun Ching Liu, Youngjoo Chung, Yu Hirate||Estimating position bias is a well-known challenge in Learning to Rank (L2R). Click data in e-commerce applications, such as targeted advertisements and search engines, provides implicit but abundant feedback to improve personalized rankings. However, click data inherently includes various biases like position bias. Based on the position-based click model, Result Randomization and Regression Expectation-Maximization algorithm (REM) have been proposed to estimate position bias, but they require various paired observations of (item, position). In real-world scenarios of advertising, marketers frequently display advertisements in a fixed pre-determined order, which creates difficulties in estimation due to the limited availability of various pairs in the training data, resulting in a sparse dataset. We propose a variant of the REM that utilizes item embeddings to alleviate the sparsity of (item, position). Using a public dataset and internal carousel advertisement click dataset, we empirically show that item embedding with Latent Semantic Indexing (LSI) and Variational Auto-Encoder (VAE) improves the accuracy of position bias estimation and the estimated position bias enhances Learning to Rank performance. We also show that LSI is more effective as an embedding creation method for position bias estimation.|估计位置偏差是学习排名(L2R)中一个众所周知的挑战。电子商务应用程序中的点击数据，例如有针对性的广告和搜索引擎，提供了隐含但丰富的反馈，以改善个性化排名。然而，点击数据本质上包含各种偏差，如位置偏差。基于位置点击模型，结果随机化和回归期望最大化算法(REM)已被提出来估计位置偏差，但它们需要不同的配对观察(项目，位置)。在现实世界的广告情景中，营销人员经常以固定的预先确定的顺序显示广告，由于训练数据中各种对的可用性有限，造成估计困难，从而导致数据集稀疏。我们提出了 REM 的一种变体，它利用项目嵌入来减轻(项目，位置)的稀疏性。使用公共数据集和内部旋转木马广告点击数据集，我们经验表明，项目嵌入潜在语义索引(LSI)和变分自动编码器(VAE)提高了位置偏差估计的准确性，估计的位置偏差提高了学习排名的性能。我们还证明了大规模集成电路作为位置偏差估计的一种嵌入式创建方法是更有效的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Position+Bias+Estimation+with+Item+Embedding+for+Sparse+Dataset)|0|
|[When Federated Recommendation Meets Cold-Start Problem: Separating Item Attributes and User Interactions](https://doi.org/10.1145/3589334.3645525)|Chunxu Zhang, Guodong Long, Tianyi Zhou, Zijian Zhang, Peng Yan, Bo Yang||Federated recommendation system usually trains a global model on the server without direct access to users' private data on their own devices. However, this separation of the recommendation model and users' private data poses a challenge in providing quality service, particularly when it comes to new items, namely cold-start recommendations in federated settings. This paper introduces a novel method called Item-aligned Federated Aggregation (IFedRec) to address this challenge. It is the first research work in federated recommendation to specifically study the cold-start scenario. The proposed method learns two sets of item representations by leveraging item attributes and interaction records simultaneously. Additionally, an item representation alignment mechanism is designed to align two item representations and learn the meta attribute network at the server within a federated learning framework. Experiments on four benchmark datasets demonstrate IFedRec's superior performance for cold-start scenarios. Furthermore, we also verify IFedRec owns good robustness when the system faces limited client participation and noise injection, which brings promising practical application potential in privacy-protection enhanced federated recommendation systems. The implementation code is available|联邦推荐系统通常在服务器上培训一个全局模型，而不直接访问用户自己设备上的私有数据。然而，推荐模型和用户私有数据的这种分离对提供高质量的服务提出了挑战，特别是当涉及到新项目时，即联邦设置中的冷启动推荐。本文介绍了一种新的方法，称为项目对齐联邦聚合(IFedRec) ，以解决这一挑战。这是联合推荐系统中第一个专门研究冷启动方案的研究工作。该方法通过同时利用项目属性和交互记录来学习两组项目表示。此外，设计了一种项表示对齐机制，用于对齐两个项表示，并在联邦学习框架内学习服务器上的元属性网络。在四个基准数据集上的实验证明了 IFedRec 在冷启动场景下的优越性能。此外，我们还验证了 IFedRec 在有限的客户参与和噪声注入情况下具有良好的鲁棒性，这为隐私保护增强型联邦推荐系统带来了很好的实际应用前景。实现代码是可用的|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=When+Federated+Recommendation+Meets+Cold-Start+Problem:+Separating+Item+Attributes+and+User+Interactions)|0|
|[Context-based Fast Recommendation Strategy for Long User Behavior Sequence in Meituan Waimai](https://doi.org/10.1145/3589335.3648334)|Zhichao Feng, Junjie Xie, Kaiyuan Li, Yu Qin, Pengfei Wang, Qianzhong Li, Bin Yin, Xiang Li, Wei Lin, Shangguang Wang||In the recommender system of Meituan Waimai, we are dealing with ever-lengthening user behavior sequences, which pose an increasing challenge to modeling user preference effectively. Existing sequential recommendation models often fail to capture long-term dependencies or are too complex, complicating the fulfillment of Meituan Waimai's unique business needs. To better model user interests, we consider selecting relevant sub-sequences from users' extensive historical behaviors based on their preferences. In this specific scenario, we've noticed that the contexts in which users interact have a significant impact on their preferences. For this purpose, we introduce a novel method called Context-based Fast Recommendation Strategy to tackle the issue of long sequences. We first identify contexts that share similar user preferences with the target context and then locate the corresponding PoIs based on these identified contexts. This approach eliminates the necessity to select a sub-sequence for every candidate PoI, thereby avoiding high time complexity. Specifically, we implement a prototype-based approach to pinpoint contexts that mirror similar user preferences. To amplify accuracy and interpretability, we employ JS divergence of PoI attributes such as categories and prices as a measure of similarity between contexts. A temporal graph integrating both prototype and context nodes helps incorporate temporal information. We then identify appropriate prototypes considering both target contexts and short-term user preferences. Following this, we utilize contexts aligned with these prototypes to generate a sub-sequence, aimed at predicting CTR and CTCVR scores with target attention. Since its inception in 2023, this strategy has been adopted in Meituan Waimai's display recommender system, leading to a 4.6 in CTR and a 4.2|在 Waimai 的推荐系统美团中，我们正在处理不断延长的用户行为序列，这对有效地建立用户偏好模型提出了越来越大的挑战。现有的顺序推荐模型往往无法捕捉到长期的依赖关系，或者过于复杂，使得美团外卖独特业务需求的实现变得复杂。为了更好地建立用户兴趣模型，我们考虑根据用户的偏好，从用户广泛的历史行为中选择相关的子序列。在这个特定的场景中，我们已经注意到用户交互的上下文对他们的偏好有显著的影响。为此，我们提出了一种基于上下文的快速推荐策略来解决长序列的问题。我们首先识别与目标上下文共享相似用户偏好的上下文，然后基于这些识别的上下文定位相应的 PoI。这种方法消除了为每个候选 PoI 选择子序列的必要性，从而避免了高时间复杂度。具体来说，我们实现了一种基于原型的方法来精确定位反映类似用户偏好的上下文。为了增强准确性和可解释性，我们使用 PoI 属性(如类别和价格)的 JS 差异作为上下文之间相似性的度量。集成原型节点和上下文节点的时态图有助于合并时态信息。然后，我们根据目标环境和短期用户偏好确定合适的原型。接下来，我们利用与这些原型对齐的上下文来生成一个子序列，目的是用目标注意力预测 CTR 和 CTCVR 评分。自2023年推出以来，Waimai 美团的显示器推荐系统一直采用这一策略，点击率分别为4.6和4.2|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Context-based+Fast+Recommendation+Strategy+for+Long+User+Behavior+Sequence+in+Meituan+Waimai)|0|
|[Large Language Models as Data Augmenters for Cold-Start Item Recommendation](https://doi.org/10.1145/3589335.3651532)|Jianling Wang, Haokai Lu, James Caverlee, Ed H. Chi, Minmin Chen||The reasoning and generalization capabilities of LLMs can help us better understand user preferences and item characteristics, offering exciting prospects to enhance recommendation systems. Though effective while user-item interactions are abundant, conventional recommendation systems struggle to recommend cold-start items without historical interactions. To address this, we propose utilizing LLMs as data augmenters to bridge the knowledge gap on cold-start items during training. We employ LLMs to infer user preferences for cold-start items based on textual description of user historical behaviors and new item descriptions. The augmented training signals are then incorporated into learning the downstream recommendation models through an auxiliary pairwise loss. Through experiments on public Amazon datasets, we demonstrate that LLMs can effectively augment the training signals for cold-start items, leading to significant improvements in cold-start item recommendation for various recommendation models.|LLM 的推理和推广能力可以帮助我们更好地理解用户的偏好和项目特征，提供令人兴奋的前景，以加强推荐系统。尽管用户项目交互非常丰富，但传统的推荐系统很难在没有历史交互的情况下推荐冷启动项目。为了解决这个问题，我们提出利用 LLM 作为数据增强器来弥补训练过程中冷启动项目的知识缺口。我们使用 LLM 根据用户历史行为的文本描述和新项描述来推断用户对冷启动项的偏好。然后通过辅助成对损失将增强的训练信号合并到下游推荐模型中。通过对公共 Amazon 数据集的实验，我们发现 LLM 可以有效地增强冷启动项目的训练信号，从而显著改善了各种推荐模型的冷启动项目推荐。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large+Language+Models+as+Data+Augmenters+for+Cold-Start+Item+Recommendation)|0|
|[Filter Bubble or Homogenization? Disentangling the Long-Term Effects of Recommendations on User Consumption Patterns](https://doi.org/10.1145/3589334.3645497)|Md Sanzeed Anwar, Grant Schoenebeck, Paramveer S. Dhillon||Recommendation algorithms play a pivotal role in shaping our media choices, which makes it crucial to comprehend their long-term impact on user behavior. These algorithms are often linked to two critical outcomes: homogenization, wherein users consume similar content despite disparate underlying preferences, and the filter bubble effect, wherein individuals with differing preferences only consume content aligned with their preferences (without much overlap with other users). Prior research assumes a trade-off between homogenization and filter bubble effects and then shows that personalized recommendations mitigate filter bubbles by fostering homogenization. However, because of this assumption of a tradeoff between these two effects, prior work cannot develop a more nuanced view of how recommendation systems may independently impact homogenization and filter bubble effects. We develop a more refined definition of homogenization and the filter bubble effect by decomposing them into two key metrics: how different the average consumption is between users (inter-user diversity) and how varied an individual's consumption is (intra-user diversity). We then use a novel agent-based simulation framework that enables a holistic view of the impact of recommendation systems on homogenization and filter bubble effects. Our simulations show that traditional recommendation algorithms (based on past behavior) mainly reduce filter bubbles by affecting inter-user diversity without significantly impacting intra-user diversity. Building on these findings, we introduce two new recommendation algorithms that take a more nuanced approach by accounting for both types of diversity.|推荐算法在塑造我们的媒体选择中起着关键作用，这使得理解它们对用户行为的长期影响至关重要。这些算法通常与两个关键的结果相关联: 同质化，其中用户尽管不同的潜在偏好消费相似的内容，以及过滤泡沫效应，其中具有不同偏好的个体仅消费与其偏好一致的内容(与其他用户没有太多重叠)。先前的研究假设在均匀化和过滤泡效应之间进行权衡，然后表明个性化推荐通过促进均匀化来减轻过滤泡。然而，由于在这两种效应之间进行权衡的假设，以前的工作无法对推荐系统如何独立地影响同质化和过滤泡沫效应形成更加细致入微的观点。我们通过将同质化和过滤泡沫效应分解为两个关键指标，发展了一个更精确的定义: 用户之间的平均消费有多大差异(用户间多样性)和个人的消费有多大差异(用户内部多样性)。然后，我们使用一个新的基于代理的仿真框架，使推荐系统的同质化和过滤气泡效应的影响的整体观点。我们的仿真结果表明，传统的推荐算法(基于过去的行为)主要通过影响用户间的分集来减少滤波器泡沫，而不会显著影响用户内的分集。在这些发现的基础上，我们引入了两种新的推荐算法，它们通过考虑两种类型的多样性，采取了更加细致入微的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Filter+Bubble+or+Homogenization?+Disentangling+the+Long-Term+Effects+of+Recommendations+on+User+Consumption+Patterns)|0|
|[Can One Embedding Fit All? A Multi-Interest Learning Paradigm Towards Improving User Interest Diversity Fairness](https://doi.org/10.1145/3589334.3645662)|Yuying Zhao, Minghua Xu, Huiyuan Chen, Yuzhong Chen, Yiwei Cai, Rashidul Islam, Yu Wang, Tyler Derr||Recommender systems (RSs) have gained widespread applications across various domains owing to the superior ability to capture users' interests. However, the complexity and nuanced nature of users' interests, which span a wide range of diversity, pose a significant challenge in delivering fair recommendations. In practice, user preferences vary significantly; some users show a clear preference toward certain item categories, while others have a broad interest in diverse ones. Even though it is expected that all users should receive high-quality recommendations, the effectiveness of RSs in catering to this disparate interest diversity remains under-explored. In this work, we investigate whether users with varied levels of interest diversity are treated fairly. Our empirical experiments reveal an inherent disparity: users with broader interests often receive lower-quality recommendations. To mitigate this, we propose a multi-interest framework that uses multiple (virtual) interest embeddings rather than single ones to represent users. Specifically, the framework consists of stacked multi-interest representation layers, which include an interest embedding generator that derives virtual interests from shared parameters, and a center embedding aggregator that facilitates multi-hop aggregation. Experiments demonstrate the effectiveness of the framework in achieving better trade-off between fairness and utility across various datasets and backbones.|推荐系统(RS)由于具有捕获用户兴趣的优越能力，在各个领域得到了广泛的应用。然而，用户兴趣的复杂性和细微差别，跨越广泛的多样性，对提供公平的建议构成重大挑战。实际上，用户的偏好差异很大; 一些用户对某些项目类别有明显的偏好，而另一些用户对不同的项目类别有广泛的兴趣。尽管预计所有用户都会收到高质量的建议，但是对于 RSS 在满足这种不同兴趣多样性方面的有效性仍然探索不足。在这项工作中，我们调查是否不同水平的兴趣多样性的用户被公平对待。我们的经验实验揭示了一个内在的差异: 兴趣广泛的用户经常收到质量较低的推荐。为了解决这个问题，我们提出了一个多兴趣框架，它使用多个(虚拟)兴趣嵌入而不是单个兴趣嵌入来表示用户。具体来说，该框架由多个层叠的多兴趣表示层组成，其中包括一个从共享参数获取虚拟兴趣的兴趣嵌入生成器和一个促进多跳聚合的中心嵌入聚合器。实验证明了该框架在实现跨各种数据集和主干网的公平性和实用性之间更好的平衡方面的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Can+One+Embedding+Fit+All?+A+Multi-Interest+Learning+Paradigm+Towards+Improving+User+Interest+Diversity+Fairness)|0|
|[Uplift Modeling for Target User Attacks on Recommender Systems](https://doi.org/10.1145/3589334.3645403)|Wenjie Wang, Changsheng Wang, Fuli Feng, Wentao Shi, Daizong Ding, TatSeng Chua||Recommender systems are vulnerable to injective attacks, which inject limited fake users into the platforms to manipulate the exposure of target items to all users. In this work, we identify that conventional injective attackers overlook the fact that each item has its unique potential audience, and meanwhile, the attack difficulty across different users varies. Blindly attacking all users will result in a waste of fake user budgets and inferior attack performance. To address these issues, we focus on an under-explored attack task called target user attacks, aiming at promoting target items to a particular user group. In addition, we formulate the varying attack difficulty as heterogeneous treatment effects through a causal lens and propose an Uplift-guided Budget Allocation (UBA) framework. UBA estimates the treatment effect on each target user and optimizes the allocation of fake user budgets to maximize the attack performance. Theoretical and empirical analysis demonstrates the rationality of treatment effect estimation methods of UBA. By instantiating UBA on multiple attackers, we conduct extensive experiments on three datasets under various settings with different target items, target users, fake user budgets, victim models, and defense models, validating the effectiveness and robustness of UBA.|推荐系统容易受到注入式攻击，即向平台注入有限的虚假用户，以操纵目标项目对所有用户的暴露。在本研究中，我们发现传统的注入式攻击者忽略了每个项目都有其独特的潜在受众这一事实，同时，不同用户之间的攻击难度是不同的。盲目攻击所有用户将导致虚假用户预算的浪费和较差的攻击性能。为了解决这些问题，我们将重点放在一个未被充分研究的攻击任务，称为目标用户攻击，旨在将目标项提升到特定的用户组。此外，我们通过因果透镜将不同的攻击难度描述为异质治疗效果，并提出了一个提升引导的预算分配(UBA)框架。UBA 估计每个目标用户的治疗效果，优化虚假用户预算的分配，以最大限度地提高攻击性能。理论和实证分析证明了 UBA 治疗效果评价方法的合理性。通过实例化多个攻击者的 UBA，我们在不同目标条目、目标用户、虚假用户预算、受害者模型和防御模型的不同设置下对三个数据集进行了广泛的实验，验证了 UBA 的有效性和鲁棒性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Uplift+Modeling+for+Target+User+Attacks+on+Recommender+Systems)|0|
|[TikTok and the Art of Personalization: Investigating Exploration and Exploitation on Social Media Feeds](https://doi.org/10.1145/3589334.3645600)|Karan Vombatkere, Sepehr Mousavi, Savvas Zannettou, Franziska Roesner, Krishna P. Gummadi||Recommendation algorithms for social media feeds often function as black boxes from the perspective of users. We aim to detect whether social media feed recommendations are personalized to users, and to characterize the factors contributing to personalization in these feeds. We introduce a general framework to examine a set of social media feed recommendations for a user as a timeline. We label items in the timeline as the result of exploration vs. exploitation of the user's interests on the part of the recommendation algorithm and introduce a set of metrics to capture the extent of personalization across user timelines. We apply our framework to a real TikTok dataset and validate our results using a baseline generated from automated TikTok bots, as well as a randomized baseline. We also investigate the extent to which factors such as video viewing duration, liking, and following drive the personalization of content on TikTok. Our results demonstrate that our framework produces intuitive and explainable results, and can be used to audit and understand personalization in social media feeds.|从用户的角度来看，社交媒体 feed 的推荐算法通常起到黑盒的作用。我们的目标是检测社交媒体的 feed 推荐是否对用户个性化，并描述这些 feed 中促成个性化的因素。我们引入了一个通用框架来检查一组社交媒体提要推荐给用户作为时间轴。我们根据推荐算法对用户兴趣的探索和利用来标记时间线中的项目，并引入一组度量标准来捕获跨用户时间线的个性化程度。我们将框架应用于一个真实的 TikTok 数据集，并使用自动化 TikTok 机器人生成的基线以及随机基线验证结果。我们还调查了视频观看时间、喜欢程度和跟随程度等因素在多大程度上驱动了 TikTok 上内容的个性化。我们的结果表明，我们的框架产生直观和可解释的结果，并可用于审计和理解个性化的社会媒体饲料。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TikTok+and+the+Art+of+Personalization:+Investigating+Exploration+and+Exploitation+on+Social+Media+Feeds)|0|
|[Which LLM to Play? Convergence-Aware Online Model Selection with Time-Increasing Bandits](https://doi.org/10.1145/3589334.3645420)|Yu Xia, Fang Kong, Tong Yu, Liya Guo, Ryan A. Rossi, Sungchul Kim, Shuai Li||Web-based applications such as chatbots, search engines and news recommendations continue to grow in scale and complexity with the recent surge in the adoption of LLMs. Online model selection has thus garnered increasing attention due to the need to choose the best model among a diverse set while balancing task reward and exploration cost. Organizations faces decisions like whether to employ a costly API-based LLM or a locally finetuned small LLM, weighing cost against performance. Traditional selection methods often evaluate every candidate model before choosing one, which are becoming impractical given the rising costs of training and finetuning LLMs. Moreover, it is undesirable to allocate excessive resources towards exploring poor-performing models. While some recent works leverage online bandit algorithm to manage such exploration-exploitation trade-off in model selection, they tend to overlook the increasing-then-converging trend in model performances as the model is iteratively finetuned, leading to less accurate predictions and suboptimal model selections. In this paper, we propose a time-increasing bandit algorithm TI-UCB, which effectively predicts the increase of model performances due to finetuning and efficiently balances exploration and exploitation in model selection. To further capture the converging points of models, we develop a change detection mechanism by comparing consecutive increase predictions. We theoretically prove that our algorithm achieves a logarithmic regret upper bound in a typical increasing bandit setting, which implies a fast convergence rate. The advantage of our method is also empirically validated through extensive experiments on classification model selection and online selection of LLMs. Our results highlight the importance of utilizing increasing-then-converging pattern for more efficient and economic model selection in the deployment of LLMs.|基于 Web 的应用程序，如聊天机器人、搜索引擎和新闻推荐，随着最近采用 LLM 的激增，其规模和复杂性继续增长。因此，在线模型选择越来越受到人们的关注，因为在平衡任务报酬和探索成本的同时，需要在多样化的模型集合中选择最佳模型。组织面临是否使用昂贵的基于 API 的 LLM 或局部微调的小型 LLM 等决策，权衡成本和性能。传统的选择方法通常在选择一个候选模型之前对每个候选模型进行评估，但由于训练和微调 LLM 的成本不断上升，这种方法已经变得不切实际。此外，将过多的资源用于探索表现不佳的模型也是不可取的。虽然最近的一些工作利用在线盗贼算法来管理模型选择中的这种勘探-开发权衡，但是他们往往忽略了模型性能的增加然后收敛的趋势，因为模型是迭代微调的，导致不太准确的预测和次优模型选择。本文提出了一种时间增长的土匪算法 TI-UCB，该算法能够有效地预测由于微调而带来的模型性能的提高，并能够有效地平衡模型选择中的探索和开发。为了进一步捕捉模型的收敛点，我们通过比较连续的增长预测，发展了一种变化检测机制。从理论上证明了该算法在典型的增长型强盗环境下达到了对数遗憾上界，具有较快的收敛速度。通过广泛的分类模型选择和 LLM 在线选择实验，验证了该方法的优越性。我们的研究结果突出了利用增加-然后收敛模式的重要性，更有效和经济的模型选择在 LLM 的部署。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Which+LLM+to+Play?+Convergence-Aware+Online+Model+Selection+with+Time-Increasing+Bandits)|0|
|[Full-stage Diversified Recommendation: Large-scale Online Experiments in Short-video Platform](https://doi.org/10.1145/3589334.3648144)|Nian Li, Yunzhu Pan, Chen Gao, Depeng Jin, Qingmin Liao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Full-stage+Diversified+Recommendation:+Large-scale+Online+Experiments+in+Short-video+Platform)|0|
|[Improving Item-side Fairness of Multimodal Recommendation via Modality Debiasing](https://doi.org/10.1145/3589334.3648156)|Yu Shang, Chen Gao, Jiansheng Chen, Depeng Jin, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Item-side+Fairness+of+Multimodal+Recommendation+via+Modality+Debiasing)|0|
|[Knowledge Enhanced Multi-intent Transformer Network for Recommendation](https://doi.org/10.1145/3589335.3648296)|Ding Zou, Wei Wei, Feida Zhu, Chuanyu Xu, Tao Zhang, Chengfu Huo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge+Enhanced+Multi-intent+Transformer+Network+for+Recommendation)|0|
|[Modeling User Viewing Flow using Large Language Models for Article Recommendation](https://doi.org/10.1145/3589335.3648305)|Zhenghao Liu, Zulong Chen, Moufeng Zhang, Shaoyang Duan, Hong Wen, Liangyue Li, Nan Li, Yu Gu, Ge Yu||This paper proposes the User Viewing Flow Modeling (SINGLE) method for the article recommendation task, which models the user constant preference and instant interest from user-clicked articles. Specifically, we first employ a user constant viewing flow modeling method to summarize the user's general interest to recommend articles. In this case, we utilize Large Language Models (LLMs) to capture constant user preferences from previously clicked articles, such as skills and positions. Then we design the user instant viewing flow modeling method to build interactions between user-clicked article history and candidate articles. It attentively reads the representations of user-clicked articles and aims to learn the user's different interest views to match the candidate article. Our experimental results on the Alibaba Technology Association (ATA) website show the advantage of SINGLE, achieving a 2.4 improvement over previous baseline models in the online A/B test. Our further analyses illustrate that SINGLE has the ability to build a more tailored recommendation system by mimicking different article viewing behaviors of users and recommending more appropriate and diverse articles to match user interests.|针对文章推荐任务，提出了用户查看流建模(SINGLE)方法，该方法从用户点击的文章中建立用户常量偏好和即时兴趣模型。具体来说，我们首先使用一个用户常量查看流建模方法来总结用户的一般兴趣来推荐文章。在这种情况下，我们利用大型语言模型(LLM)从以前单击的文章(如技能和职位)中获取常量用户首选项。然后设计用户即时查看流建模方法，建立用户点击文章历史和候选文章之间的交互。它专注地阅读用户点击的文章的表示，并旨在了解用户的不同兴趣视图，以匹配候选文章。我们在阿里巴巴科技协会(ATA)网站上的实验结果显示了 SINGLE 的优势，在线 A/B 测试中比以前的基准模型提高了2.4个百分点。我们进一步的分析表明，SINGLE 能够通过模仿用户不同的文章浏览行为，推荐更合适、更多样的文章来匹配用户的兴趣，从而建立一个更具针对性的推荐系统。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modeling+User+Viewing+Flow+using+Large+Language+Models+for+Article+Recommendation)|0|
|[Counterfactual Data Augmentation for Debiased Coupon Recommendations Based on Potential Knowledge](https://doi.org/10.1145/3589335.3648306)|Junpeng Fang, Gongduo Zhang, Qing Cui, Lihong Gu, Longfei Li, Jinjie Gu, Jun Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Counterfactual+Data+Augmentation+for+Debiased+Coupon+Recommendations+Based+on+Potential+Knowledge)|0|
|[User Response Modeling in Reinforcement Learning for Ads Allocation](https://doi.org/10.1145/3589335.3648310)|Zhiyuan Zhang, Qichao Zhang, Xiaoxu Wu, Xiaowen Shi, Guogang Liao, Yongkang Wang, Xingxing Wang, Dongbin Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=User+Response+Modeling+in+Reinforcement+Learning+for+Ads+Allocation)|0|
|[Cluster Anchor Regularization to Alleviate Popularity Bias in Recommender Systems](https://doi.org/10.1145/3589335.3648312)|Bo Chang, Changping Meng, He Ma, Shuo Chang, Yang Gu, Yajun Peng, Jingchen Feng, Yaping Zhang, Shuchao Bi, Ed H. Chi, Minmin Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cluster+Anchor+Regularization+to+Alleviate+Popularity+Bias+in+Recommender+Systems)|0|
|[MetaSplit: Meta-Split Network for Limited-Stock Product Recommendation](https://doi.org/10.1145/3589335.3648319)|Wenhao Wu, Jialiang Zhou, Ailong He, Shuguang Han, Jufeng Chen, Bo Zheng||Compared to business-to-consumer (B2C) e-commerce systems, consumer-to-consumer (C2C) e-commerce platforms usually encounter the limited-stock problem, that is, a product can only be sold one time in a C2C system. This poses several unique challenges for click-through rate (CTR) prediction. Due to limited user interactions for each product (i.e. item), the corresponding item embedding in the CTR model may not easily converge. This makes the conventional sequence modeling based approaches cannot effectively utilize user history information since historical user behaviors contain a mixture of items with different volume of stocks. Particularly, the attention mechanism in a sequence model tends to assign higher score to products with more accumulated user interactions, making limited-stock products being ignored and contribute less to the final output. To this end, we propose the Meta-Split Network (MSN) to split user history sequence regarding to the volume of stock for each product, and adopt differentiated modeling approaches for different sequences. As for the limited-stock products, a meta-learning approach is applied to address the problem of inconvergence, which is achieved by designing meta scaling and shifting networks with ID and side information. In addition, traditional approach can hardly update item embedding once the product is consumed. Thereby, we propose an auxiliary loss that makes the parameters updatable even when the product is no longer in distribution. To the best of our knowledge, this is the first solution addressing the recommendation of limited-stock product. Experimental results on the production dataset and online A/B testing demonstrate the effectiveness of our proposed method.|与 B2C 电子商务系统相比，C2C (C2C)电子商务平台通常会遇到库存有限的问题，即产品只能在 C2C 系统中销售一次。这给点进率预测带来了几个独特的挑战。由于每个产品(即项目)的用户交互有限，嵌入在 CTR 模型中的相应项目可能不容易收敛。这使得传统的基于序列建模的方法不能有效地利用用户历史信息，因为历史用户行为包含不同股票数量的混合项。特别地，序列模型中的注意机制倾向于给具有更多累积用户交互的产品分配更高的分数，使得有限库存产品被忽略，对最终产出的贡献更小。为此，我们提出了元分割网络(MSN)来分割用户历史序列对于每个产品的库存量，并采用不同的建模方法为不同的序列。对于库存有限的产品，采用元学习方法解决不收敛问题，通过设计具有 ID 和边信息的元尺度和移位网络来实现。此外，传统的方法很难更新嵌入项一旦产品消耗。因此，我们提出了一个辅助损失，使参数可更新，即使当产品不再在分布。据我们所知，这是第一个解决推荐有限库存产品的解决方案。生产数据集和在线 A/B 测试的实验结果证明了该方法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MetaSplit:+Meta-Split+Network+for+Limited-Stock+Product+Recommendation)|0|
|[Knowledge Graph-based Session Recommendation with Session-Adaptive Propagation](https://doi.org/10.1145/3589335.3648324)|Yu Wang, Amin Javari, Janani Balaji, Walid Shalaby, Tyler Derr, Xiquan Cui||Session-based recommender systems (SBRSs) predict users' next interacted items based on their historical activities. While most SBRSs capture purchasing intentions locally within each session, capturing items' global information across different sessions is crucial in characterizing their general properties. Previous works capture this cross-session information by constructing graphs and incorporating neighbor information. However, this incorporation cannot vary adaptively according to the unique intention of each session, and the constructed graphs consist of only one type of user-item interaction. To address these limitations, we propose knowledge graph-based session recommendation with session-adaptive propagation. Specifically, we build a knowledge graph by connecting items with multi-typed edges to characterize various user-item interactions. Then, we adaptively aggregate items' neighbor information considering user intention within the learned session. Experimental results demonstrate that equipping our constructed knowledge graph and session-adaptive propagation enhances session recommendation backbones by 10 study showing our proposed framework achieves 2 existing well-deployed model at The Home Depot e-platform.|基于会话的推荐系统(SBRS)根据用户的历史活动预测用户的下一个交互项。虽然大多数 SBRS 在每个会话中捕获本地的购买意图，但是在不同会话中捕获物品的全局信息对于描述它们的一般属性是至关重要的。以前的作品通过构造图表和合并邻居信息来捕获这种跨会话信息。但是，此合并不能根据每个会话的独特意图自适应地变化，并且构造的图仅包含一种类型的用户项交互。为了解决这些局限性，我们提出了基于知识图的会话推荐和会话自适应传播。具体来说，我们通过连接具有多种类型边的项目来描述各种用户-项目交互，从而构建一个知识图。然后，在学习会话中考虑用户意图，自适应地聚合项目的邻居信息。实验结果表明，我们构建的知识图和会话自适应传播增强了会话推荐骨干的10个研究表明，我们提出的框架实现了2个现有的良好部署模型在家得宝电子平台。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge+Graph-based+Session+Recommendation+with+Session-Adaptive+Propagation)|0|
|[Cache-Aware Reinforcement Learning in Large-Scale Recommender Systems](https://doi.org/10.1145/3589335.3648326)|Xiaoshuang Chen, Gengrui Zhang, Yao Wang, Yulin Wu, Shuo Su, Kaiqiao Zhan, Ben Wang||Modern large-scale recommender systems are built upon computation-intensive infrastructure and usually suffer from a huge difference in traffic between peak and off-peak periods. In peak periods, it is challenging to perform real-time computation for each request due to the limited budget of computational resources. The recommendation with a cache is a solution to this problem, where a user-wise result cache is used to provide recommendations when the recommender system cannot afford a real-time computation. However, the cached recommendations are usually suboptimal compared to real-time computation, and it is challenging to determine the items in the cache for each user. In this paper, we provide a cache-aware reinforcement learning (CARL) method to jointly optimize the recommendation by real-time computation and by the cache. We formulate the problem as a Markov decision process with user states and a cache state, where the cache state represents whether the recommender system performs recommendations by real-time computation or by the cache. The computational load of the recommender system determines the cache state. We perform reinforcement learning based on such a model to improve user engagement over multiple requests. Moreover, we show that the cache will introduce a challenge called critic dependency, which deteriorates the performance of reinforcement learning. To tackle this challenge, we propose an eigenfunction learning (EL) method to learn independent critics for CARL. Experiments show that CARL can significantly improve the users' engagement when considering the result cache. CARL has been fully launched in Kwai app, serving over 100 million users.|现代大规模推荐系统是建立在计算密集型基础设施之上的，通常在高峰期和非高峰期之间存在巨大的流量差异。在高峰期，由于计算资源的预算有限，对每个请求执行实时计算是一个挑战。使用缓存的推荐就是这个问题的解决方案，当推荐系统无法支付实时计算时，使用用户明智的结果缓存来提供推荐。然而，与实时计算相比，缓存的建议通常是次优的，并且为每个用户确定缓存中的项目是具有挑战性的。在本文中，我们提供了一个缓存感知强化学习(CARL)方法，通过实时计算和缓存联合优化推荐。我们用用户状态和缓存状态来描述问题，缓存状态表示马可夫决策过程是通过实时计算还是通过缓存执行推荐推荐系统。推荐系统的计算负载决定了缓存的状态。我们基于这种模型执行强化学习，以提高用户对多个请求的参与度。此外，我们表明缓存将引入一个叫做评论依赖的挑战，这会恶化强化学习的性能。为了应对这一挑战，我们提出了一种特征函数学习(EL)方法来学习独立的批评家为卡尔。实验表明，在考虑结果缓存的情况下，CARL 可以显著提高用户参与度。CARL 已经在葵应用程序中全面推出，为超过1亿用户提供服务。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cache-Aware+Reinforcement+Learning+in+Large-Scale+Recommender+Systems)|0|
|[Enhancing Interpretability and Effectiveness in Recommendation with Numerical Features via Learning to Contrast the Counterfactual samples](https://doi.org/10.1145/3589335.3648345)|Xiaoxiao Xu, Hao Wu, Wenhui Yu, Lantao Hu, Peng Jiang, Kun Gai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Interpretability+and+Effectiveness+in+Recommendation+with+Numerical+Features+via+Learning+to+Contrast+the+Counterfactual+samples)|0|
|[Term Importance for Transformer-Based QA Retrieval: A Case Study of StackExchange](https://doi.org/10.1145/3589335.3651568)|Bryan Zhi Yang Tan, Hady W. Lauw||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Term+Importance+for+Transformer-Based+QA+Retrieval:+A+Case+Study+of+StackExchange)|0|
|[GreenRec: A Large-Scale Dataset for Green Food Recommendation](https://doi.org/10.1145/3589335.3651516)|Lingzi Zhang, Yinan Zhang, Xin Zhou, Zhiqi Shen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GreenRec:+A+Large-Scale+Dataset+for+Green+Food+Recommendation)|0|
|[RimiRec: Modeling Refined Multi-interest in Hierarchical Structure for Recommendation](https://doi.org/10.1145/3589335.3651554)|Haolei Pei, Yuanyuan Xu, Yangping Zhu, Yuan Nie||Industrial recommender systems usually consist of the retrieval stage and the ranking stage, to handle the billion-scale of users and items. The retrieval stage retrieves candidate items relevant to user interests for recommendations and has attracted much attention. Frequently, a user shows refined multi-interests in a hierarchical structure. For example, a user likes Conan and Kuroba Kaito, which are the roles in hierarchical structure "Animation, Japanese Animation, Detective Conan". However, most existing methods ignore this hierarchical nature, and simply average the fine-grained interest information. Therefore, we propose a novel two-stage approach to explicitly modeling refined multi-interest in a hierarchical structure for recommendation. In the first hierarchical multi-interest mining stage, the hierarchical clustering and transformer-based model adaptively generate circles or sub-circles that users are interested in. In the second stage, the partition of retrieval space allows the EBR models to deal only with items within each circle and accurately capture users' refined interests. Experimental results show that the proposed approach achieves state-of-the-art performance. Our framework has also been deployed at Lofter.|工业推荐系统通常由检索阶段和排名阶段组成，用于处理数十亿规模的用户和项目。检索阶段检索与用户兴趣相关的候选项，以便进行推荐，引起了人们的广泛关注。通常，用户在层次结构中显示精确的多重兴趣。例如，一个用户喜欢柯南和黑叶海东，这是角色的层次结构“动画，日本动画，侦探柯南”。然而，大多数现有的方法忽略了这种层次性质，只是对细粒度的兴趣信息进行平均。因此，我们提出了一种新的两阶段的方法来显式建模精细的多兴趣在一个层次结构的推荐。在第一层次多兴趣挖掘阶段，层次聚类和基于变换器的模型自适应地生成用户感兴趣的圈或子圈。在第二阶段，检索空间的划分允许 EBR 模型只处理每个圈内的项目，并准确地捕获用户的细化兴趣。实验结果表明，该方法具有较好的性能。我们的架构也已部署在洛夫特。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RimiRec:+Modeling+Refined+Multi-interest+in+Hierarchical+Structure+for+Recommendation)|0|
|[Is Cosine-Similarity of Embeddings Really About Similarity?](https://doi.org/10.1145/3589335.3651526)|Harald Steck, Chaitanya Ekanadham, Nathan Kallus||Cosine-similarity is the cosine of the angle between two vectors, or equivalently the dot product between their normalizations. A popular application is to quantify semantic similarity between high-dimensional objects by applying cosine-similarity to a learned low-dimensional feature embedding. This can work better but sometimes also worse than the unnormalized dot-product between embedded vectors in practice. To gain insight into this empirical observation, we study embeddings derived from regularized linear models, where closed-form solutions facilitate analytical insights. We derive analytically how cosine-similarity can yield arbitrary and therefore meaningless `similarities.' For some linear models the similarities are not even unique, while for others they are implicitly controlled by the regularization. We discuss implications beyond linear models: a combination of different regularizations are employed when learning deep models; these have implicit and unintended effects when taking cosine-similarities of the resulting embeddings, rendering results opaque and possibly arbitrary. Based on these insights, we caution against blindly using cosine-similarity and outline alternatives.|余弦相似度是两个向量之间夹角的余弦，或者相当于两个向量标准化之间的点积。一个流行的应用是将余弦相似度应用于学习的低维特征嵌入，量化高维对象之间的语义相似度。在实际应用中，这种方法可以比嵌入向量之间的非规范化点积更好，但有时也更差。为了深入了解这一经验观察，我们研究了从正则线性模型衍生的嵌入，其中闭式解决方案促进了分析见解。我们解析地推导出余弦相似度如何产生任意的，因此也就是无意义的相似度。对于一些线性模型，相似性甚至不是唯一的，而对于另一些线性模型，它们是由正则化隐式控制的。我们讨论线性模型以外的含义: 当学习深度模型时，使用不同的正则化组合; 当采用结果嵌入的余弦相似性时，这些组合具有隐含的和意想不到的效果，使得结果不透明，可能是任意的。基于这些见解，我们警告不要盲目地使用余弦相似性和轮廓替代。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Is+Cosine-Similarity+of+Embeddings+Really+About+Similarity?)|0|
|[Discrete Semantic Tokenization for Deep CTR Prediction](https://doi.org/10.1145/3589335.3651558)|Qijiong Liu, Hengchang Hu, Jiahao Wu, Jieming Zhu, MinYen Kan, XiaoMing Wu||Incorporating item content information into click-through rate (CTR) prediction models remains a challenge, especially with the time and space constraints of industrial scenarios. The content-encoding paradigm, which integrates user and item encoders directly into CTR models, prioritizes space over time. In contrast, the embedding-based paradigm transforms item and user semantics into latent embeddings and then caches them, prioritizes space over time. In this paper, we introduce a new semantic-token paradigm and propose a discrete semantic tokenization approach, namely UIST, for user and item representation. UIST facilitates swift training and inference while maintaining a conservative memory footprint. Specifically, UIST quantizes dense embedding vectors into discrete tokens with shorter lengths and employs a hierarchical mixture inference module to weigh the contribution of each user–item token pair. Our experimental results on news recommendation showcase the effectiveness and efficiency (about 200-fold space compression) of UIST for CTR prediction.|将项目内容信息纳入点进率预测模型仍然是一个挑战，特别是在工业情景的时间和空间限制下。内容编码范例将用户和条目编码器直接集成到 CTR 模型中，随着时间的推移优先考虑空间。相比之下，基于嵌入的范例将项目和用户语义转换为潜在嵌入，然后缓存它们，随着时间的推移优先考虑空间。本文介绍了一种新的语义标记方法，提出了一种用于用户和项目表示的离散语义标记方法 UIST。UIST 促进快速训练和推理，同时保持一个保守的记忆足迹。具体来说，UIST 将密集嵌入向量量化为较短长度的离散令牌，并采用分层混合推理模块来衡量每个用户项令牌对的贡献。我们在新闻推荐上的实验结果展示了 UIST 用于 CTR 预测的有效性和效率(约200倍的空间压缩)。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Discrete+Semantic+Tokenization+for+Deep+CTR+Prediction)|0|
|[Cornac-AB: An Open-Source Recommendation Framework with Native A/B Testing Integration](https://doi.org/10.1145/3589335.3651241)|Darryl Ong, QuocTuan Truong, Hady W. Lauw||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cornac-AB:+An+Open-Source+Recommendation+Framework+with+Native+A/B+Testing+Integration)|0|
|[Towards Reliable and Efficient Long-Term Recommendation with Large Foundation Models](https://doi.org/10.1145/3589335.3651258)|Wentao Shi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Reliable+and+Efficient+Long-Term+Recommendation+with+Large+Foundation+Models)|0|
|[Clickbait vs. Quality: How Engagement-Based Optimization Shapes the Content Landscape in Online Platforms](https://doi.org/10.1145/3589334.3645353)|Nicole Immorlica, Meena Jagadeesan, Brendan Lucier||Online content platforms commonly use engagement-based optimization when making recommendations. This encourages content creators to invest in quality, but also rewards gaming tricks such as clickbait. To understand the total impact on the content landscape, we study a game between content creators competing on the basis of engagement metrics and analyze the equilibrium decisions about investment in quality and gaming. First, we show the content created at equilibrium exhibits a positive correlation between quality and gaming, and we empirically validate this finding on a Twitter dataset. Using the equilibrium structure of the content landscape, we then examine the downstream performance of engagement-based optimization along several axes. Perhaps counterintuitively, the average quality of content consumed by users can decrease at equilibrium as gaming tricks become more costly for content creators to employ. Moreover, engagement-based optimization can perform worse in terms of user utility than a baseline with random recommendations, and engagement-based optimization is also suboptimal in terms of realized engagement relative to quality-based optimization. Altogether, our results highlight the need to consider content creator incentives when evaluating a platform's choice of optimization metric.|在线内容平台通常在提出建议时使用基于参与的优化。这鼓励内容创作者投资于质量，但也奖励了点击诱饵等游戏技巧。为了理解对内容景观的总体影响，我们研究了基于参与度指标的内容创作者之间的竞争博弈，并分析了质量投资和博弈的均衡决策。首先，我们展示了在均衡状态下创建的内容在质量和游戏之间呈现出正相关性，并且我们在 Twitter 数据集上验证了这一发现。然后利用内容景观的均衡结构，考察了基于约定的优化在多个轴上的下游性能。也许与直觉相反的是，随着内容创作者使用游戏技巧的成本越来越高，用户消费的内容的平均质量可能在均衡状态下下降。此外，就用户效用而言，基于约定的优化可能比基于随机推荐的基线执行得更差，而就已实现的约定而言，相对于基于质量的优化而言，基于约定的优化也是次优的。总之，我们的研究结果强调了在评估平台对优化指标的选择时需要考虑内容创建者的激励因素。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Clickbait+vs.+Quality:+How+Engagement-Based+Optimization+Shapes+the+Content+Landscape+in+Online+Platforms)|0|
|[Bidder Selection Problem in Position Auctions: A Fast and Simple Algorithm via Poisson Approximation](https://doi.org/10.1145/3589334.3645418)|Nikolai Gravin, Yixuan Even Xu, Renfei Zhou||In the Bidder Selection Problem (BSP) there is a large pool of n potential advertisers competing for ad slots on the user's web page. Due to strict computational restrictions, the advertising platform can run a proper auction only for a fraction k<n of advertisers. We consider the basic optimization problem underlying BSP: given n independent prior distributions, how to efficiently find a subset of k with the objective of either maximizing expected social welfare or revenue of the platform. We study BSP in the classic multi-winner model of position auctions for welfare and revenue objectives using the optimal (respectively, VCG mechanism, or Myerson's auction) format for the selected set of bidders. Previous PTAS results for BSP optimization were only known for single-item auctions and in case of [Segev and Singla 2021] for l-unit auctions. More importantly, all of these PTASes were computational complexity results with impractically large running times, which defeats the purpose of using these algorithms under severe computational constraints. We propose a novel Poisson relaxation of BSP for position auctions that immediately implies that 1) BSP is polynomial-time solvable up to a vanishingly small error as the problem size k grows; 2) there is a PTAS for position auctions after combining our relaxation with the trivial brute force algorithm. Unlike all previous PTASes, we implemented our algorithm and did extensive numerical experiments on practically relevant input sizes. First, our experiments corroborate the previous experimental findings of Mehta et al. that a few simple heuristics used in practice perform surprisingly well in terms of approximation factor. Furthermore, our algorithm outperforms Greedy both in running time and approximation on medium and large-sized instances.|在投标人选择问题(BSP)中，有大量潜在的广告商在争夺用户网页上的广告位置。由于严格的计算限制，广告平台可以运行一个适当的拍卖只有一小部分 k < n 的广告商。我们考虑了基本的最佳化问题: 给定 n 个独立的先验分布，如何有效地找到 k 的一个子集，目标是最大化期望的社会福利或平台的收入。我们研究了福利和收入目标的经典多赢家位置拍卖模型中的 BSP 问题。以前的 PTAS 结果的 BSP 优化只知道单项拍卖和情况下的[ Segev 和 Singla 2021]的 l- 单位拍卖。更重要的是，所有这些 PTASes 都是计算复杂度不切实际的大运行时间的结果，这违背了在严格的计算约束下使用这些算法的目的。我们提出了一个新的位置拍卖的 BSP 的泊松松弛立即意味着: 1) BSP 是多项式时间可解到一个消失的小误差随着问题大小 k 的增长; 2)有一个 PTAS 的位置拍卖结合我们的松弛与平凡的蛮力算法。与以前的 PTASes 不同，我们实现了我们的算法，并对实际相关的输入大小进行了广泛的数值实验。首先，我们的实验证实了 Mehta 等人先前的实验结果，即在实践中使用的一些简单的启发式算法在近似因子方面表现出令人惊讶的好。此外，我们的算法在运行时间和对中型和大型实例的逼近方面都优于贪婪算法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bidder+Selection+Problem+in+Position+Auctions:+A+Fast+and+Simple+Algorithm+via+Poisson+Approximation)|0|
|[A Fast Hop-Biased Approximation Algorithm for the Quadratic Group Steiner Tree Problem](https://doi.org/10.1145/3589334.3645325)|Xiaoqing Wang, Gong Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Fast+Hop-Biased+Approximation+Algorithm+for+the+Quadratic+Group+Steiner+Tree+Problem)|0|
|[Link Prediction on Multilayer Networks through Learning of Within-Layer and Across-Layer Node-Pair Structural Features and Node Embedding Similarity](https://doi.org/10.1145/3589334.3645646)|Lorenzo Zangari, Domenico Mandaglio, Andrea Tagarelli||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Link+Prediction+on+Multilayer+Networks+through+Learning+of+Within-Layer+and+Across-Layer+Node-Pair+Structural+Features+and+Node+Embedding+Similarity)|0|
|[Diffusion-based Negative Sampling on Graphs for Link Prediction](https://doi.org/10.1145/3589334.3645650)|TrungKien Nguyen, Yuan Fang||Link prediction is a fundamental task for graph analysis with important applications on the Web, such as social network analysis and recommendation systems, etc. Modern graph link prediction methods often employ a contrastive approach to learn robust node representations, where negative sampling is pivotal. Typical negative sampling methods aim to retrieve hard examples based on either predefined heuristics or automatic adversarial approaches, which might be inflexible or difficult to control. Furthermore, in the context of link prediction, most previous methods sample negative nodes from existing substructures of the graph, missing out on potentially more optimal samples in the latent space. To address these issues, we investigate a novel strategy of multi-level negative sampling that enables negative node generation with flexible and controllable “hardness” levels from the latent space. Our method, called Conditional Diffusion-based Multi-level Negative Sampling (DMNS), leverages the Markov chain property of diffusion models to generate negative nodes in multiple levels of variable hardness and reconcile them for effective graph link prediction. We further demonstrate that DMNS follows the sub-linear positivity principle for robust negative sampling. Extensive experiments on several benchmark datasets demonstrate the effectiveness of DMNS.|链接预测是图形分析的基础性工作，在网络上有着重要的应用，如社会网络分析和推荐系统等。现代图形链接预测方法往往采用对比的方法来学习鲁棒的节点表示，其中负采样是关键。典型的负抽样方法旨在检索基于预定义启发式或自动对抗式方法的硬实例，这些方法可能缺乏灵活性或难以控制。此外，在链路预测的背景下，大多数以前的方法从图的现有子结构中抽取负节点，在潜在空间中遗漏了潜在的更优样本。为了解决这些问题，我们研究了一种新的多级负采样策略，该策略使负节点的生成具有灵活和可控的潜在空间“硬度”水平。该方法利用扩散模型的马尔可夫链特性，在多个可变硬度水平上生成负节点，并协调它们进行有效的图形链接预测。进一步证明了对于鲁棒负采样，DMNS 遵循亚线性正性原理。在几个基准数据集上的大量实验证明了 DMNS 的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Diffusion-based+Negative+Sampling+on+Graphs+for+Link+Prediction)|0|
|[InfoRank: Unbiased Learning-to-Rank via Conditional Mutual Information Minimization](https://doi.org/10.1145/3589334.3645356)|Jiarui Jin, Zexue He, Mengyue Yang, Weinan Zhang, Yong Yu, Jun Wang, Julian J. McAuley||Ranking items regarding individual user interests is a core technique of multiple downstream tasks such as recommender systems. Learning such a personalized ranker typically relies on the implicit feedback from users' past click-through behaviors. However, collected feedback is biased toward previously highly-ranked items and directly learning from it would result in a "rich-get-richer" phenomenon. In this paper, we propose a simple yet sufficient unbiased learning-to-rank paradigm named InfoRank that aims to simultaneously address both position and popularity biases. We begin by consolidating the impacts of those biases into a single observation factor, thereby providing a unified approach to addressing bias-related issues. Subsequently, we minimize the mutual information between the observation estimation and the relevance estimation conditioned on the input features. By doing so, our relevance estimation can be proved to be free of bias. To implement InfoRank, we first incorporate an attention mechanism to capture latent correlations within user-item features, thereby generating estimations of observation and relevance. We then introduce a regularization term, grounded in conditional mutual information, to promote conditional independence between relevance estimation and observation estimation. Experimental evaluations conducted across three extensive recommendation and search datasets reveal that InfoRank learns more precise and unbiased ranking strategies.|关于个人用户兴趣的项目排序是多下游任务(如推荐系统)的核心技术。学习这样一个个性化的排名通常依赖于来自用户过去点击行为的隐式反馈。然而，收集的反馈偏向于先前排名较高的项目，直接从中学习将导致“富者越富”的现象。在本文中，我们提出了一个简单而充分的无偏学习排名范式称为 InfoRank，旨在同时解决位置和流行偏见。我们首先将这些偏见的影响合并为一个单一的观察因素，从而为解决偏见相关问题提供一个统一的方法。然后，在输入特征的条件下，最小化观测估计和相关估计之间的互信息。通过这样做，我们的相关性估计可以证明是没有偏见的。为了实现 InfoRank，我们首先引入一个注意机制来捕捉用户项目特征中的潜在相关性，从而产生观察和相关性的估计。然后，我们引入一个基于条件互信息的正则项，以促进相关估计和观测估计之间的条件独立。对三个广泛的推荐和搜索数据集进行的实验评估表明，InfoRank 学会了更精确和无偏见的排名策略。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=InfoRank:+Unbiased+Learning-to-Rank+via+Conditional+Mutual+Information+Minimization)|0|
|[Multimodal Query Suggestion with Multi-Agent Reinforcement Learning from Human Feedback](https://doi.org/10.1145/3589334.3645365)|Zheng Wang, Bingzheng Gan, Wei Shi||In the rapidly evolving landscape of information retrieval, search engines strive to provide more personalized and relevant results to users. Query suggestion systems play a crucial role in achieving this goal by assisting users in formulating effective queries. However, existing query suggestion systems mainly rely on textual inputs, potentially limiting user search experiences for querying images. In this paper, we introduce a novel Multimodal Query Suggestion (MMQS) task, which aims to generate query suggestions based on user query images to improve the intentionality and diversity of search results. We present the RL4Sugg framework, leveraging the power of Large Language Models (LLMs) with Multi-Agent Reinforcement Learning from Human Feedback to optimize the generation process. Through comprehensive experiments, we validate the effectiveness of RL4Sugg, demonstrating a 18 compared to the best existing approach. Moreover, the MMQS has been transferred into real-world search engine products, which yield enhanced user engagement. Our research advances query suggestion systems and provides a new perspective on multimodal information retrieval.|在快速发展的信息检索中，搜索引擎努力为用户提供更个性化和相关的结果。查询建议系统通过协助用户构建有效的查询，在实现这一目标方面发挥着至关重要的作用。然而，现有的查询建议系统主要依赖于文本输入，这可能会限制用户查询图像的搜索体验。本文介绍了一种新的多模式查询建议(MMQS)任务，该任务旨在基于用户查询图像生成查询建议，以提高搜索结果的意向性和多样性。我们介绍了 RL4Sugg 框架，利用大型语言模型(LLM)和来自人类反馈的多代理强化学习的能力来优化生成过程。通过综合实验，验证了 RL4Sugg 的有效性，与现有的最佳方法相比，验证了18种方法的有效性。此外，MMQS 已经转移到现实世界的搜索引擎产品，从而提高了用户参与度。我们的研究发展了查询建议系统，为多模式信息检索提供了一个新的视角。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multimodal+Query+Suggestion+with+Multi-Agent+Reinforcement+Learning+from+Human+Feedback)|0|
|[A Fast Similarity Matrix Calibration Method with Incomplete Query](https://doi.org/10.1145/3589334.3645456)|Changyi Ma, Runsheng Yu, Youzhi Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Fast+Similarity+Matrix+Calibration+Method+with+Incomplete+Query)|0|
|[Whole Page Unbiased Learning to Rank](https://doi.org/10.1145/3589334.3645474)|Haitao Mao, Lixin Zou, Yujia Zheng, Jiliang Tang, Xiaokai Chu, Jiashu Zhao, Qian Wang, Dawei Yin||The page presentation biases in the information retrieval system, especially on the click behavior, is a well-known challenge that hinders improving ranking models' performance with implicit user feedback. Unbiased Learning to Rank (ULTR) algorithms are then proposed to learn an unbiased ranking model with biased click data. However, most existing algorithms are specifically designed to mitigate position-related bias, e.g., trust bias, without considering biases induced by other features in search result page presentation(SERP), e.g. attractive bias induced by the multimedia. Unfortunately, those biases widely exist in industrial systems and may lead to an unsatisfactory search experience. Therefore, we introduce a new problem, i.e., whole-page Unbiased Learning to Rank(WP-ULTR), aiming to handle biases induced by whole-page SERP features simultaneously. It presents tremendous challenges: (1) a suitable user behavior model (user behavior hypothesis) can be hard to find; and (2) complex biases cannot be handled by existing algorithms. To address the above challenges, we propose a Bias Agnostic whole-page unbiased Learning to rank algorithm, named BAL, to automatically find the user behavior model with causal discovery and mitigate the biases induced by multiple SERP features with no specific design. Experimental results on a real-world dataset verify the effectiveness of the BAL.|信息检索系统中的页面呈现偏差，尤其是点击行为，是一个众所周知的挑战，它阻碍了隐含用户反馈来提高排名模型的性能。然后提出无偏学习排序(ULTR)算法来学习一个有偏点击数据的无偏排序模型。然而，大多数现有的算法都是专门设计来减轻位置相关的偏差，例如信任偏差，而不考虑搜索结果页面呈现(SERP)中其他特征引起的偏差，例如多媒体引起的吸引力偏差。不幸的是，这些偏见广泛存在于工业系统中，并可能导致不令人满意的搜索体验。因此，我们引入了一个新的问题，即整页无偏学习排序(WP-ULTR) ，旨在同时处理整页 SERP 特征引起的偏差。它提出了巨大的挑战: (1)一个合适的用户行为模型(用户行为假设)可能很难找到; (2)复杂的偏差不能处理现有的算法。为了解决上述挑战，我们提出了一种名为 BAL 的偏倚不可知全页无偏学习排序算法，以自动找到具有因果发现的用户行为模型，并减轻由没有特定设计的多个 SERP 特征引起的偏差。在实际数据集上的实验结果验证了 BAL 算法的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Whole+Page+Unbiased+Learning+to+Rank)|0|
|[Mitigating Exploitation Bias in Learning to Rank with an Uncertainty-aware Empirical Bayes Approach](https://doi.org/10.1145/3589334.3645487)|Tao Yang, Cuize Han, Chen Luo, Parth Gupta, Jeff M. Phillips, Qingyao Ai||Ranking is at the core of many artificial intelligence (AI) applications, including search engines, recommender systems, etc. Modern ranking systems are often constructed with learning-to-rank (LTR) models built from user behavior signals. While previous studies have demonstrated the effectiveness of using user behavior signals (e.g., clicks) as both features and labels of LTR algorithms, we argue that existing LTR algorithms that indiscriminately treat behavior and non-behavior signals in input features could lead to suboptimal performance in practice. Particularly because user behavior signals often have strong correlations with the ranking objective and can only be collected on items that have already been shown to users, directly using behavior signals in LTR could create an exploitation bias that hurts the system performance in the long run. To address the exploitation bias, we propose EBRank, an empirical Bayes-based uncertainty-aware ranking algorithm. Specifically, to overcome exploitation bias brought by behavior features in ranking models, EBRank uses a sole non-behavior feature based prior model to get a prior estimation of relevance. In the dynamic training and serving of ranking systems, EBRank uses the observed user behaviors to update posterior relevance estimation instead of concatenating behaviors as features in ranking models. Besides, EBRank additionally applies an uncertainty-aware exploration strategy to explore actively, collect user behaviors for empirical Bayesian modeling and improve ranking performance. Experiments on three public datasets show that EBRank is effective, practical and significantly outperforms state-of-the-art ranking algorithms.|排名是许多人工智能(AI)应用程序的核心，包括搜索引擎、推荐系统等。现代排序系统通常是由用户行为信号构建的学习排序(LTR)模型构建的。虽然以前的研究已经证明了使用用户行为信号(例如点击)作为 LTR 算法的特征和标签的有效性，但是我们认为现有的 LTR 算法在输入特征中不加区分地处理行为和非行为信号可能导致实践中的次优性能。特别是由于用户行为信号往往与排名目标有很强的相关性，只能在已经显示给用户的条目上收集，直接在 LTR 中使用行为信号可能会产生利用偏差，从长远来看会损害系统性能。针对开发偏差问题，提出了一种基于经验贝叶斯的不确定性排序算法 EBRank。具体来说，为了克服排序模型中行为特征带来的利用偏差，EBRank 使用基于非行为特征的先验模型来获得相关性的先验估计。在排序系统的动态训练和服务中，EBRank 利用观察到的用户行为更新后验相关估计，而不是将用户行为作为排序模型的特征进行连接。此外，EBRank 还采用了不确定性探索策略，积极探索，收集用户行为进行经验贝叶斯建模，提高排序性能。在三个公共数据集上的实验表明，EBRank 算法是有效的、实用的，其性能明显优于最先进的排序算法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mitigating+Exploitation+Bias+in+Learning+to+Rank+with+an+Uncertainty-aware+Empirical+Bayes+Approach)|0|
|[Unify Graph Learning with Text: Unleashing LLM Potentials for Session Search](https://doi.org/10.1145/3589334.3645574)|Songhao Wu, Quan Tu, Hong Liu, Jia Xu, Zhongyi Liu, Guannan Zhang, Ran Wang, Xiuying Chen, Rui Yan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unify+Graph+Learning+with+Text:+Unleashing+LLM+Potentials+for+Session+Search)|0|
|[Matching Feature Separation Network for Domain Adaptation in Entity Matching](https://doi.org/10.1145/3589334.3645397)|Chenchen Sun, Yang Xu, Derong Shen, Tiezheng Nie||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Matching+Feature+Separation+Network+for+Domain+Adaptation+in+Entity+Matching)|0|
|[FedUP: Querying Large-Scale Federations of SPARQL Endpoints](https://doi.org/10.1145/3589334.3645704)|Julien AimonierDavat, Brice Nédelec, Minh Hoang Dang, Pascal Molli, Hala SkafMolli||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FedUP:+Querying+Large-Scale+Federations+of+SPARQL+Endpoints)|0|
|[Prompt-enhanced Federated Content Representation Learning for Cross-domain Recommendation](https://doi.org/10.1145/3589334.3645337)|Lei Guo, Ziang Lu, Junliang Yu, Quoc Viet Hung Nguyen, Hongzhi Yin||Cross-domain Recommendation (CDR) as one of the effective techniques in alleviating the data sparsity issues has been widely studied in recent years. However, previous works may cause domain privacy leakage since they necessitate the aggregation of diverse domain data into a centralized server during the training process. Though several studies have conducted privacy preserving CDR via Federated Learning (FL), they still have the following limitations: 1) They need to upload users' personal information to the central server, posing the risk of leaking user privacy. 2) Existing federated methods mainly rely on atomic item IDs to represent items, which prevents them from modeling items in a unified feature space, increasing the challenge of knowledge transfer among domains. 3) They are all based on the premise of knowing overlapped users between domains, which proves impractical in real-world applications. To address the above limitations, we focus on Privacy-preserving Cross-domain Recommendation (PCDR) and propose PFCR as our solution. For Limitation 1, we develop a FL schema by exclusively utilizing users' interactions with local clients and devising an encryption method for gradient encryption. For Limitation 2, we model items in a universal feature space by their description texts. For Limitation 3, we initially learn federated content representations, harnessing the generality of natural language to establish bridges between domains. Subsequently, we craft two prompt fine-tuning strategies to tailor the pre-trained model to the target domain. Extensive experiments on two real-world datasets demonstrate the superiority of our PFCR method compared to the SOTA approaches.|跨域推荐(CDR)作为缓解数据稀疏性问题的有效技术之一，近年来得到了广泛的研究。然而，以前的工作可能会导致域隐私泄漏，因为它们需要在培训过程中将不同的域数据集中到一个集中的服务器。虽然已有多项研究通过联邦学习(FL)进行隐私保护 CDR，但仍存在以下局限性: 1)需要将用户的个人信息上传到中央服务器，存在泄露用户隐私的风险。2)现有的联邦方法主要依靠原子项目 ID 来表示项目，这使得联邦方法无法在统一的特征空间中对项目进行建模，增加了领域间知识转移的难度。3)它们都是建立在知道域间重叠用户的前提上的，这在现实应用中是不切实际的。针对上述局限性，本文重点研究了保护隐私的跨域推荐(PCDR)技术，并提出了 PCR 技术作为解决方案。对于限制1，我们通过专门利用用户与本地客户端的交互和设计一种梯度加密的加密方法来开发一个 FL 模式。对于局限性2，我们通过描述文本在通用特征空间中对项目进行建模。对于限制3，我们最初学习联邦内容表示，利用自然语言的通用性在域之间建立桥梁。随后，我们制定了两个快速微调策略，以裁剪预训练模型的目标领域。在两个实际数据集上的大量实验证明了我们的 PFCR 方法相对于 SOTA 方法的优越性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Prompt-enhanced+Federated+Content+Representation+Learning+for+Cross-domain+Recommendation)|0|
|[PromptMM: Multi-Modal Knowledge Distillation for Recommendation with Prompt-Tuning](https://doi.org/10.1145/3589334.3645359)|Wei Wei, Jiabin Tang, Lianghao Xia, Yangqin Jiang, Chao Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PromptMM:+Multi-Modal+Knowledge+Distillation+for+Recommendation+with+Prompt-Tuning)|0|
|[Cold-start Bundle Recommendation via Popularity-based Coalescence and Curriculum Heating](https://doi.org/10.1145/3589334.3645377)|Hyunsik Jeon, Jongeun Lee, Jeongin Yun, U Kang||How can we recommend cold-start bundles to users? The cold-start problem in bundle recommendation is crucial because new bundles are continuously created on the Web for various marketing purposes. Despite its importance, existing methods for cold-start item recommendation are not readily applicable to bundles. They depend overly on historical information, even for less popular bundles, failing to address the primary challenge of the highly skewed distribution of bundle interactions. In this work, we propose CoHeat (Popularity-based Coalescence and Curriculum Heating), an accurate approach for cold-start bundle recommendation. CoHeat first represents users and bundles through graph-based views, capturing collaborative information effectively. To estimate the user-bundle relationship more accurately, CoHeat addresses the highly skewed distribution of bundle interactions through a popularity-based coalescence approach, which incorporates historical and affiliation information based on the bundle's popularity. Furthermore, it effectively learns latent representations by exploiting curriculum learning and contrastive learning. CoHeat demonstrates superior performance in cold-start bundle recommendation, achieving up to 193|我们如何向用户推荐冷启动捆绑包？捆绑包推荐中的冷启动问题是至关重要的，因为出于各种营销目的，新的捆绑包不断地在 Web 上创建。尽管它的重要性，现有的冷启动项目推荐方法不容易适用于捆绑包。它们过度依赖于历史信息，即使对于不太流行的捆绑包也是如此，未能解决捆绑包交互的高度倾斜分布这一主要挑战。在这项工作中，我们提出了 CoHeat (基于流行度的聚合和课程加热) ，一种准确的冷启动捆绑推荐方法。CoHeat 首先通过基于图形的视图表示用户和捆绑包，有效地捕获协作信息。为了更准确地估计用户与捆绑包的关系，CoHeat 通过基于流行度的合并方法解决了捆绑包交互的高度倾斜分布，该方法结合了基于捆绑包流行度的历史和从属关系信息。此外，它还通过课程学习和对比学习有效地学习潜在表征。CoHeat 在冷启动捆绑推荐系统中表现出卓越的性能，最高达到193|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cold-start+Bundle+Recommendation+via+Popularity-based+Coalescence+and+Curriculum+Heating)|0|
|[Scalable and Provably Fair Exposure Control for Large-Scale Recommender Systems](https://doi.org/10.1145/3589334.3645390)|Riku Togashi, Kenshi Abe, Yuta Saito||Typical recommendation and ranking methods aim to optimize the satisfaction of users, but they are often oblivious to their impact on the items (e.g., products, jobs, news, video) and their providers. However, there has been a growing understanding that the latter is crucial to consider for a wide range of applications, since it determines the utility of those being recommended. Prior approaches to fairness-aware recommendation optimize a regularized objective to balance user satisfaction and item fairness based on some notion such as exposure fairness. These existing methods have been shown to be effective in controlling fairness, however, most of them are computationally inefficient, limiting their applications to only unrealistically small-scale situations. This indeed implies that the literature does not yet provide a solution to enable a flexible control of exposure in the industry-scale recommender systems where millions of users and items exist. To enable a computationally efficient exposure control even for such large-scale systems, this work develops a scalable, fast, and fair method called exposure-aware ADMM (exADMM). exADMM is based on implicit alternating least squares (iALS), a conventional scalable algorithm for collaborative filtering, but optimizes a regularized objective to achieve a flexible control of accuracy-fairness tradeoff. A particular technical challenge in developing exADMM is the fact that the fairness regularizer destroys the separability of optimization subproblems for users and items, which is an essential property to ensure the scalability of iALS. Therefore, we develop a set of optimization tools to enable yet scalable fairness control with provable convergence guarantees as a basis of our algorithm.|典型的推荐和排名方法旨在优化用户的满意度，但他们往往忽视了它们对项目(例如，产品、工作、新闻、视频)及其提供商的影响。然而，人们日益认识到，后者对于考虑范围广泛的应用至关重要，因为它决定了所推荐的应用的效用。先前的公平感知推荐方法优化了一个规范化的目标，以平衡用户满意度和项目公平性，基于一些概念，如曝光公平性。这些现有的方法已被证明是有效的控制公平，但是，其中大多数是计算效率低下，限制其应用于不切实际的小规模情况。这实际上意味着，文献尚未提供一个解决方案，以便在存在数百万用户和项目的行业规模的推荐系统中实现对曝光的灵活控制。为了实现计算效率高的曝光控制，即使是在这样的大规模系统中，这项工作开发了一种可伸缩、快速和公平的方法，称为曝光感知 ADMM (exADMM)。ExADMM 基于隐式交替最小二乘(iALS)算法，这是一种传统的可扩展的协同过滤算法，但优化了正则化目标，以实现灵活的精度-公平权衡控制。开发 exADMM 的一个特殊的技术挑战是公平正则化器破坏了用户和项目优化子问题的可分性，而这种可分性是保证 iALS 可扩展性的一个重要特性。因此，我们开发了一套优化工具，使得可扩展的公平性控制具有可证明的收敛保证作为我们的算法的基础。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+and+Provably+Fair+Exposure+Control+for+Large-Scale+Recommender+Systems)|0|
|[Causally Debiased Time-aware Recommendation](https://doi.org/10.1145/3589334.3645400)|Lei Wang, Chen Ma, Xian Wu, Zhaopeng Qiu, Yefeng Zheng, Xu Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causally+Debiased+Time-aware+Recommendation)|0|
|[Learning Category Trees for ID-Based Recommendation: Exploring the Power of Differentiable Vector Quantization](https://doi.org/10.1145/3589334.3645484)|Qijiong Liu, Jiaren Xiao, Lu Fan, Jieming Zhu, XiaoMing Wu||Category information plays a crucial role in enhancing the quality and personalization of recommender systems. Nevertheless, the availability of item category information is not consistently present, particularly in the context of ID-based recommendations. In this work, we propose a novel approach to automatically learn and generate entity (i.e., user or item) category trees for ID-based recommendation. Specifically, we devise a differentiable vector quantization framework for automatic category tree generation, namely CAGE, which enables the simultaneous learning and refinement of categorical code representations and entity embeddings in an end-to-end manner, starting from the randomly initialized states. With its high adaptability, CAGE can be easily integrated into both sequential and non-sequential recommender systems. We validate the effectiveness of CAGE on various recommendation tasks including list completion, collaborative filtering, and click-through rate prediction, across different recommendation models. We release the code and data for others to reproduce the reported results.|分类信息在提高推荐系统的质量和个性化方面起着至关重要的作用。尽管如此，项目类别信息的可用性并不一致，特别是在基于 ID 的推荐上下文中。在这项工作中，我们提出了一个新颖的方法来自动学习和生成实体(即，用户或项目)的类别树为基于身份的推荐。具体来说，我们设计了一个自动分类树生成的可微向量量化框架，即 CAGE，它能够从随机初始化状态开始，以端到端的方式同时学习和细化分类代码表示和实体嵌入。CAGE 具有很强的适应性，可以很容易地集成到顺序推荐系统和非顺序推荐系统中。在不同的推荐模型中，我们验证了 CAGE 在各种推荐任务中的有效性，包括列表完成、协同过滤和点进率预测。我们将代码和数据发布给其他人，以重现报告的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Category+Trees+for+ID-Based+Recommendation:+Exploring+the+Power+of+Differentiable+Vector+Quantization)|0|
|[Poisoning Federated Recommender Systems with Fake Users](https://doi.org/10.1145/3589334.3645492)|Ming Yin, Yichang Xu, Minghong Fang, Neil Zhenqiang Gong||Federated recommendation is a prominent use case within federated learning, yet it remains susceptible to various attacks, from user to server-side vulnerabilities. Poisoning attacks are particularly notable among user-side attacks, as participants upload malicious model updates to deceive the global model, often intending to promote or demote specific targeted items. This study investigates strategies for executing promotion attacks in federated recommender systems. Current poisoning attacks on federated recommender systems often rely on additional information, such as the local training data of genuine users or item popularity. However, such information is challenging for the potential attacker to obtain. Thus, there is a need to develop an attack that requires no extra information apart from item embeddings obtained from the server. In this paper, we introduce a novel fake user based poisoning attack named PoisonFRS to promote the attacker-chosen targeted item in federated recommender systems without requiring knowledge about user-item rating data, user attributes, or the aggregation rule used by the server. Extensive experiments on multiple real-world datasets demonstrate that PoisonFRS can effectively promote the attacker-chosen targeted item to a large portion of genuine users and outperform current benchmarks that rely on additional information about the system. We further observe that the model updates from both genuine and fake users are indistinguishable within the latent space.|联合推荐是联合学习中一个突出的用例，但它仍然容易受到从用户到服务器端漏洞的各种攻击。中毒攻击在用户端攻击中尤其显著，因为参与者上传恶意模型更新以欺骗全局模型，通常意图促进或降级特定目标项目。本研究探讨在联邦推荐系统中执行推广攻击的策略。当前对联邦推荐系统的中毒攻击通常依赖于附加信息，比如真正用户的本地培训数据或项目流行度。然而，这样的信息对于潜在的攻击者来说是具有挑战性的。因此，需要开发一种除了从服务器获得的项嵌入之外不需要额外信息的攻击。本文提出了一种新的基于虚假用户的中毒攻击 PoisonFRS，它在不需要用户评分数据、用户属性和服务器聚合规则的情况下，在联邦推荐系统中推广攻击者选择的目标项。在多个真实世界数据集上的大量实验表明，PoisonFRS 能够有效地将攻击者选择的目标项目推广到大部分真实用户，并且比依赖于系统附加信息的当前基准测试表现更好。我们进一步观察到，来自真实用户和虚假用户的模型更新在潜在空间内是不可区分的。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Poisoning+Federated+Recommender+Systems+with+Fake+Users)|0|
|[Could Small Language Models Serve as Recommenders? Towards Data-centric Cold-start Recommendation](https://doi.org/10.1145/3589334.3645494)|Xuansheng Wu, Huachi Zhou, Yucheng Shi, Wenlin Yao, Xiao Huang, Ninghao Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Could+Small+Language+Models+Serve+as+Recommenders?+Towards+Data-centric+Cold-start+Recommendation)|0|
|[Recommender Transformers with Behavior Pathways](https://doi.org/10.1145/3589334.3645528)|Zhiyu Yao, Xinyang Chen, Sinan Wang, Qinyan Dai, Yumeng Li, Tanchao Zhu, Mingsheng Long||Sequential recommendation requires the recommender to capture the evolving behavior characteristics from logged user behavior data for accurate recommendations. However, user behavior sequences are viewed as a script with multiple ongoing threads intertwined. We find that only a small set of pivotal behaviors can be evolved into the user's future action. As a result, the future behavior of the user is hard to predict. We conclude this characteristic for sequential behaviors of each user as the Behavior Pathway. Different users have their unique behavior pathways. Among existing sequential models, transformers have shown great capacity in capturing global-dependent characteristics. However, these models mainly provide a dense distribution over all previous behaviors using the self-attention mechanism, making the final predictions overwhelmed by the trivial behaviors not adjusted to each user. In this paper, we build the Recommender Transformer (RETR) with a novel Pathway Attention mechanism. RETR can dynamically plan the behavior pathway specified for each user, and sparingly activate the network through this behavior pathway to effectively capture evolving patterns useful for recommendation. The key design is a learned binary route to prevent the behavior pathway from being overwhelmed by trivial behaviors. We empirically verify the effectiveness of RETR on seven real-world datasets and RETR yields state-of-the-art performance.|连续推荐需要推荐者从日志用户行为数据中捕获不断变化的行为特征，以获得准确的推荐。但是，用户行为序列被看作是一个多个正在进行的线程交织在一起的脚本。我们发现只有一小部分关键行为可以演化为用户未来的行为。因此，用户未来的行为很难预测。我们将每个用户的连续行为归结为行为路径。不同的用户有他们独特的行为路径。在现有的顺序模型中，变压器在捕捉全局相关特性方面表现出了很大的能力。然而，这些模型主要利用自我注意机制，在所有以前的行为上提供了一个密集的分布，使得最终的预测被不适应每个用户的琐碎行为所淹没。在本文中，我们建立了推荐变压器(RETR)与一个新的路径注意机制。RETR 可以动态规划为每个用户指定的行为路径，并通过该行为路径激活网络，以有效地捕获推荐所需的演化模式。关键的设计是一个学习的二进制路径，以防止行为路径被琐碎的行为所淹没。我们通过实验验证了 RETR 在七个实际数据集上的有效性，并且 RETR 产生了最先进的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recommender+Transformers+with+Behavior+Pathways)|0|
|[Ensuring User-side Fairness in Dynamic Recommender Systems](https://doi.org/10.1145/3589334.3645536)|Hyunsik Yoo, Zhichen Zeng, Jian Kang, Ruizhong Qiu, David Zhou, Zhining Liu, Fei Wang, Charlie Xu, Eunice Chan, Hanghang Tong||User-side group fairness is crucial for modern recommender systems, aiming to alleviate performance disparities among user groups defined by sensitive attributes like gender, race, or age. In the ever-evolving landscape of user-item interactions, continual adaptation to newly collected data is crucial for recommender systems to stay aligned with the latest user preferences. However, we observe that such continual adaptation often exacerbates performance disparities. This necessitates a thorough investigation into user-side fairness in dynamic recommender systems, an area that has been unexplored in the literature. This problem is challenging due to distribution shifts, frequent model updates, and non-differentiability of ranking metrics. To our knowledge, this paper presents the first principled study on ensuring user-side fairness in dynamic recommender systems. We start with theoretical analyses on fine-tuning v.s. retraining, showing that the best practice is incremental fine-tuning with restart. Guided by our theoretical analyses, we propose FAir Dynamic rEcommender (FADE), an end-to-end fine-tuning framework to dynamically ensure user-side fairness over time. To overcome the non-differentiability of recommendation metrics in the fairness loss, we further introduce Differentiable Hit (DH) as an improvement over the recent NeuralNDCG method, not only alleviating its gradient vanishing issue but also achieving higher efficiency. Besides that, we also address the instability issue of the fairness loss by leveraging the competing nature between the recommendation loss and the fairness loss. Through extensive experiments on real-world datasets, we demonstrate that FADE effectively and efficiently reduces performance disparities with little sacrifice in the overall recommendation performance.|用户端群组公平性对于现代推荐系统至关重要，旨在缓解由性别、种族或年龄等敏感属性定义的用户群之间的性能差异。在不断变化的用户项交互环境中，持续适应新收集的数据对于推荐系统保持与最新用户偏好一致至关重要。然而，我们观察到这种持续的适应常常加剧性能差异。这就需要对动态推荐系统中的用户端公平性进行彻底的研究，这是文献中未曾探索过的领域。这个问题是具有挑战性的，因为分布转移，频繁的模型更新，和不可区分的排名度量。据我们所知，本文提出了第一个原则性的研究，以确保用户端公平性的动态推荐系统。我们从微调和再训练的理论分析开始，表明最佳实践是重新启动后的渐进微调。在理论分析的指导下，我们提出了 FAir Dynamic reComdender (FADE) ，这是一个端到端的微调框架，可以随着时间的推移动态地保证用户端的公平性。为了克服推荐度量在公平性损失中的不可微性，我们进一步引入了可微命中(DH)算法，作为对最近的神经网络 NDCG 方法的改进，不仅减轻了它的梯度消失问题，而且实现了更高的效率。此外，我们还利用推荐损失和公平损失之间的竞争性质来解决公平损失的不稳定性问题。通过对现实世界数据集的大量实验，我们证明了 FADE 能够有效地降低性能差异，并且在总体推荐性能方面做出了很小的牺牲。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ensuring+User-side+Fairness+in+Dynamic+Recommender+Systems)|0|
|[Mirror Gradient: Towards Robust Multimodal Recommender Systems via Exploring Flat Local Minima](https://doi.org/10.1145/3589334.3645553)|Shanshan Zhong, Zhongzhan Huang, Daifeng Li, Wushao Wen, Jinghui Qin, Liang Lin||Multimodal recommender systems utilize various types of information to model user preferences and item features, helping users discover items aligned with their interests. The integration of multimodal information mitigates the inherent challenges in recommender systems, e.g., the data sparsity problem and cold-start issues. However, it simultaneously magnifies certain risks from multimodal information inputs, such as information adjustment risk and inherent noise risk. These risks pose crucial challenges to the robustness of recommendation models. In this paper, we analyze multimodal recommender systems from the novel perspective of flat local minima and propose a concise yet effective gradient strategy called Mirror Gradient (MG). This strategy can implicitly enhance the model's robustness during the optimization process, mitigating instability risks arising from multimodal information inputs. We also provide strong theoretical evidence and conduct extensive empirical experiments to show the superiority of MG across various multimodal recommendation models and benchmarks. Furthermore, we find that the proposed MG can complement existing robust training methods and be easily extended to diverse advanced recommendation models, making it a promising new and fundamental paradigm for training multimodal recommender systems. The code is released at https://github.com/Qrange-group/Mirror-Gradient.|多模式推荐系统利用各种类型的信息来建模用户偏好和项目特征，帮助用户发现符合他们兴趣的项目。多模态信息的集成缓解了推荐系统固有的挑战，如数据稀疏问题和冷启动问题。然而，它同时放大了来自多模态信息输入的某些风险，如信息调整风险和固有噪声风险。这些风险对推荐模型的稳健性提出了严峻的挑战。本文从平坦局部极小的角度分析了多模态推荐系统，提出了一种简洁有效的梯度策略——镜像梯度(MG)。该策略可以在优化过程中增强模型的鲁棒性，减少多模态信息输入引起的不稳定风险。我们还提供了强有力的理论证据，并进行了广泛的实证实验，以显示 MG 在各种多模式推荐模型和基准测试中的优越性。此外，我们发现所提出的 MG 可以补充现有的鲁棒训练方法，并且可以很容易地扩展到不同的高级推荐模型，使它成为训练多模式推荐系统的一个有前途的新的和基本的范例。密码在 https://github.com/qrange-group/mirror-gradient 发布。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mirror+Gradient:+Towards+Robust+Multimodal+Recommender+Systems+via+Exploring+Flat+Local+Minima)|0|
|[Adaptive Neural Ranking Framework: Toward Maximized Business Goal for Cascade Ranking Systems](https://doi.org/10.1145/3589334.3645605)|Yunli Wang, Zhiqiang Wang, Jian Yang, Shiyang Wen, Dongying Kong, Han Li, Kun Gai||Cascade ranking is widely used for large-scale top-k selection problems in online advertising and recommendation systems, and learning-to-rank is an important way to optimize the models in cascade ranking. Previous works on learning-to-rank usually focus on letting the model learn the complete order or top-k order, and adopt the corresponding rank metrics (e.g. OPA and NDCG@k) as optimization targets. However, these targets can not adapt to various cascade ranking scenarios with varying data complexities and model capabilities; and the existing metric-driven methods such as the Lambda framework can only optimize a rough upper bound of limited metrics, potentially resulting in sub-optimal and performance misalignment. To address these issues, we propose a novel perspective on optimizing cascade ranking systems by highlighting the adaptability of optimization targets to data complexities and model capabilities. Concretely, we employ multi-task learning to adaptively combine the optimization of relaxed and full targets, which refers to metrics Recall@m@k and OPA respectively. We also introduce permutation matrix to represent the rank metrics and employ differentiable sorting techniques to relax hard permutation matrix with controllable approximate error bound. This enables us to optimize both the relaxed and full targets directly and more appropriately. We named this method as Adaptive Neural Ranking Framework (abbreviated as ARF). Furthermore, we give a specific practice under ARF. We use the NeuralSort to obtain the relaxed permutation matrix and draw on the variant of the uncertainty weight method in multi-task learning to optimize the proposed losses jointly. Experiments on a total of 4 public and industrial benchmarks show the effectiveness and generalization of our method, and online experiment shows that our method has significant application value.|在在线广告和推荐系统中，级联排名被广泛应用于大规模的 Top-k 选择问题，而学习排名是级联排名模型优化的重要途径。先前关于学习排序的工作通常集中在让模型学习完整的顺序或 top-k 顺序，并采用相应的排序指标(如 OPA 和 NDCG@k)作为优化目标。然而，这些目标不能适应各种级联排序场景与不同的数据复杂性和模型能力; 和现有的度量驱动的方法，如 Lambda 框架只能优化一个粗略的上限有限的度量，潜在地导致次优化和性能不一致。为了解决这些问题，我们提出了一个优化级联排序系统的新视角，强调优化目标对数据复杂性和模型能力的适应性。具体而言，我们采用多任务学习的方法，自适应地将松弛目标和完全目标的优化结合起来，分别使用 Recall@m@k 和 OPA 度量。我们还引入置换矩阵来表示排名度量，并使用可微分排序技术来放松具有可控近似误差界限的硬置换矩阵。这使我们能够直接和更适当地优化宽松和完整的目标。我们将这种方法命名为自适应神经排序框架(简称 ARF)。此外，我们还给出了 ARF 下的具体实践。我们使用神经排序来获得松弛置换矩阵，并利用多任务学习中不确定性权重方法的变体来共同优化提出的损失。在4个公共基准和行业基准上的实验表明了该方法的有效性和推广性，在线实验表明该方法具有较高的应用价值。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adaptive+Neural+Ranking+Framework:+Toward+Maximized+Business+Goal+for+Cascade+Ranking+Systems)|0|
|[General Debiasing for Graph-based Collaborative Filtering via Adversarial Graph Dropout](https://doi.org/10.1145/3589334.3645667)|An Zhang, Wenchang Ma, Pengbo Wei, Leheng Sheng, Xiang Wang||Graph neural networks (GNNs) have shown impressive performance in recommender systems, particularly in collaborative filtering (CF). The key lies in aggregating neighborhood information on a user-item interaction graph to enhance user/item representations. However, we have discovered that this aggregation mechanism comes with a drawback, which amplifies biases present in the interaction graph. For instance, a user's interactions with items can be driven by both unbiased true interest and various biased factors like item popularity or exposure. However, the current aggregation approach combines all information, both biased and unbiased, leading to biased representation learning. Consequently, graph-based recommenders can learn distorted views of users/items, hindering the modeling of their true preferences and generalizations. To address this issue, we introduce a novel framework called Adversarial Graph Dropout (AdvDrop). It differentiates between unbiased and biased interactions, enabling unbiased representation learning. For each user/item, AdvDrop employs adversarial learning to split the neighborhood into two views: one with bias-mitigated interactions and the other with bias-aware interactions. After view-specific aggregation, AdvDrop ensures that the bias-mitigated and bias-aware representations remain invariant, shielding them from the influence of bias. We validate AdvDrop's effectiveness on five public datasets that cover both general and specific biases, demonstrating significant improvements. Furthermore, our method exhibits meaningful separation of subgraphs and achieves unbiased representations for graph-based CF models, as revealed by in-depth analysis. Our code is publicly available at https://github.com/Arthurma71/AdvDrop.|图形神经网络(GNN)在推荐系统中表现出了令人印象深刻的性能，特别是在协同过滤(CF)中。关键在于聚合用户-项目交互图上的邻域信息，以增强用户/项目的表示。然而，我们发现这种聚合机制有一个缺点，那就是放大了交互图中存在的偏差。例如，用户与项目的交互可以由无偏见的真实兴趣和各种偏见的因素驱动，如项目受欢迎程度或曝光率。然而，目前的聚合方法结合了所有的信息，包括有偏的和无偏的，导致有偏的表征学习。因此，基于图表的推荐程序可以了解用户/项目的扭曲视图，从而阻碍对其真实偏好和概括的建模。为了解决这个问题，我们引入了一个新的框架，称为对抗图丢失(AdvDrop)。它区分无偏见和有偏见的互动，使无偏见的表征学习。对于每个用户/项目，AdvDrop 使用对抗性学习将邻居分成两个视图: 一个视图具有减轻偏见的交互作用，另一个视图具有意识到偏见的交互作用。在视图特定聚合之后，AdvDrop 确保偏差缓解和偏差感知表示保持不变，从而保护它们免受偏差的影响。我们验证了 AdvDrop 在五个公共数据集上的有效性，这些数据集涵盖了一般和特定的偏差，显示了显著的改进。此外，我们的方法表现出有意义的子图分离，并实现了基于图的 CF 模型的无偏表示，如深入分析所揭示的。我们的代码可以在 https://github.com/arthurma71/advdrop 上公开获取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=General+Debiasing+for+Graph-based+Collaborative+Filtering+via+Adversarial+Graph+Dropout)|0|
|[Online Sequential Decision-Making with Unknown Delays](https://doi.org/10.1145/3589334.3645388)|Ping Wu, Heyan Huang, Zhengyang Liu||In the field of online sequential decision-making, we address the problem with delays utilizing the framework of online convex optimization (OCO), where the feedback of a decision can arrive with an unknown delay. Unlike previous research that is limited to Euclidean norm and gradient information, we propose three families of delayed algorithms based on approximate solutions to handle different types of received feedback. Our proposed algorithms are versatile and applicable to universal norms. Specifically, we introduce a family of Follow the Delayed Regularized Leader algorithms for feedback with full information on the loss function, a family of Delayed Mirror Descent algorithms for feedback with gradient information on the loss function and a family of Simplified Delayed Mirror Descent algorithms for feedback with the value information of the loss function's gradients at corresponding decision points. For each type of algorithm, we provide corresponding regret bounds under cases of general convexity and relative strong convexity, respectively. We also demonstrate the efficiency of each algorithm under different norms through concrete examples. Furthermore, our theoretical results are consistent with the current best bounds when degenerated to standard settings.|在在线顺序决策领域，我们利用在线凸优化(OCO)的框架来解决延迟问题，其中决策的反馈可以以未知的延迟到达。与以往仅限于欧氏范数和梯度信息的研究不同，我们提出了三类基于近似解的延迟算法来处理不同类型的接收反馈。我们提出的算法是通用的，并适用于普遍规范。具体来说，我们介绍了一系列的延迟正则化领先算法用于损失函数的全信息反馈，一系列的延迟镜像下降算法用于损失函数的梯度信息反馈，以及一系列的简化延迟镜像下降算法用于相应决策点的损失函数梯度的值信息反馈。对于每种算法，我们分别在一般凸性和相对强凸性情况下给出了相应的后悔界。并通过具体实例说明了每种算法在不同规范下的有效性。此外，我们的理论结果与当前退化到标准设置的最佳界限一致。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Online+Sequential+Decision-Making+with+Unknown+Delays)|0|
|[Triage of Messages and Conversations in a Large-Scale Child Victimization Corpus](https://doi.org/10.1145/3589334.3648142)|Prasanna Lakkur Subramanyam, Mohit Iyyer, Brian Neil Levine||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Triage+of+Messages+and+Conversations+in+a+Large-Scale+Child+Victimization+Corpus)|0|
|[Collaborative-Enhanced Prediction of Spending on Newly Downloaded Mobile Games under Consumption Uncertainty](https://doi.org/10.1145/3589335.3648297)|Peijie Sun, Yifan Wang, Min Zhang, Chuhan Wu, Yan Fang, Hong Zhu, Yuan Fang, Meng Wang||With the surge in mobile gaming, accurately predicting user spending on newly downloaded games has become paramount for maximizing revenue. However, the inherently unpredictable nature of user behavior poses significant challenges in this endeavor. To address this, we propose a robust model training and evaluation framework aimed at standardizing spending data to mitigate label variance and extremes, ensuring stability in the modeling process. Within this framework, we introduce a collaborative-enhanced model designed to predict user game spending without relying on user IDs, thus ensuring user privacy and enabling seamless online training. Our model adopts a unique approach by separately representing user preferences and game features before merging them as input to the spending prediction module. Through rigorous experimentation, our approach demonstrates notable improvements over production models, achieving a remarkable 17.11% enhancement on offline data and an impressive 50.65% boost in an online A/B test. In summary, our contributions underscore the importance of stable model training frameworks and the efficacy of collaborative-enhanced models in predicting user spending behavior in mobile gaming.|随着手机游戏的迅猛发展，准确预测用户在新下载游戏上的支出对于实现收入最大化至关重要。然而，用户行为固有的不可预测性在这方面提出了重大的挑战。为了解决这个问题，我们提出了一个健壮的模型训练和评估框架，旨在标准化支出数据，以减少标签差异和极端情况，确保建模过程的稳定性。在这个框架中，我们引入了一个协作增强的模型，该模型旨在预测用户的游戏支出，而不依赖于用户 ID，从而确保用户的隐私并实现无缝在线培训。我们的模型采用了一种独特的方法，分别表示用户偏好和游戏特征，然后将它们合并为消费预测模块的输入。通过严格的实验，我们的方法显示了生产模型的显著改进，在离线数据上实现了17.11% 的显著增强，在线 A/B 测试中实现了50.65% 的显著增强。总之，我们的贡献强调了稳定模型训练框架的重要性，以及协作增强模型在预测手机游戏用户消费行为方面的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Collaborative-Enhanced+Prediction+of+Spending+on+Newly+Downloaded+Mobile+Games+under+Consumption+Uncertainty)|0|
|[HiFI: Hierarchical Fairness-aware Integrated Ranking with Constrained Reinforcement Learning](https://doi.org/10.1145/3589335.3648317)|Yifan Liu, Wei Xia, Weiwen Liu, Menghui Zhu, Weinan Zhang, Ruiming Tang, Yong Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HiFI:+Hierarchical+Fairness-aware+Integrated+Ranking+with+Constrained+Reinforcement+Learning)|0|
|[On Practical Diversified Recommendation with Controllable Category Diversity Framework](https://doi.org/10.1145/3589335.3648323)|Tao Zhang, Luwei Yang, Zhibo Xiao, Wen Jiang, Wei Ning||Recommender systems have made significant strides in various industries, primarily driven by extensive efforts to enhance recommendation accuracy. However, this pursuit of accuracy has inadvertently given rise to echo chamber/filter bubble effects. Especially in industry, it could impair user's experiences and prevent user from accessing a wider range of items. One of the solutions is to take diversity into account. However, most of existing works focus on user's explicit preferences, while rarely exploring user's non-interaction preferences. These neglected non-interaction preferences are especially important for broadening user's interests in alleviating echo chamber/filter bubble effects.Therefore, in this paper, we first define diversity as two distinct definitions, i.e., user-explicit diversity (U-diversity) and user-item non-interaction diversity (N-diversity) based on user historical behaviors. Then, we propose a succinct and effective method, named as Controllable Category Diversity Framework (CCDF) to achieve both high U-diversity and N-diversity simultaneously.Specifically, CCDF consists of two stages, User-Category Matching and Constrained Item Matching. The User-Category Matching utilizes the DeepU2C model and a combined loss to capture user's preferences in categories, and then selects the top-K categories with a controllable parameter K.These top-K categories will be used as trigger information in Constrained Item Matching. Offline experimental results show that our proposed DeepU2C outperforms state-of-the-art diversity-oriented methods, especially on N-diversity task. The whole framework is validated in a real-world production environment by conducting online A/B testing.|推荐系统在各个行业都取得了长足的进步，主要是受到提高推荐准确性的广泛努力的推动。然而，这种对准确性的追求无意中导致了回声室/过滤器气泡效应。特别是在工业领域，它会损害用户的体验，阻止用户访问更广泛的项目。解决办法之一是考虑到多样性。然而，现有的大多数作品只关注用户的显性偏好，很少探讨用户的非交互偏好。这些被忽视的非交互偏好对于扩大用户的兴趣以减轻回声室/过滤器气泡效应特别重要。因此，本文首先将多样性定义为基于用户历史行为的用户显性多样性(U 多样性)和用户项非交互多样性(N 多样性)。然后，我们提出了一种简洁有效的方法，称为可控分类分集框架(CCDF) ，同时实现高 U 分集和 N 分集。具体来说，CCDF 包括两个阶段，用户类别匹配和约束条目匹配。用户类别匹配利用 DeepU2C 模型和综合损失来获取用户在类别中的偏好，然后选择带有可控参数 K 的 top-K 类别。这些 top-K 类别将作为受限项目匹配的触发信息。离线实验结果表明，本文提出的 DeepU2C 方法优于目前最先进的面向多样性的方法，尤其是在 N 分集任务上。通过在线 A/B 测试，在现实生产环境中验证了整个框架的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Practical+Diversified+Recommendation+with+Controllable+Category+Diversity+Framework)|0|
|[Optimization-Based Budget Pacing in eBay Sponsored Search](https://doi.org/10.1145/3589335.3648331)|Qinyi Chen, Phuong Ha Nguyen, Djordje Gligorijevic||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimization-Based+Budget+Pacing+in+eBay+Sponsored+Search)|0|
|[AutoML for Large Capacity Modeling of Meta's Ranking Systems](https://doi.org/10.1145/3589335.3648336)|Hang Yin, KuangHung Liu, Mengying Sun, Yuxin Chen, Buyun Zhang, Jiang Liu, Vivek Sehgal, Rudresh Rajnikant Panchal, Eugen Hotaj, Xi Liu, Daifeng Guo, Jamey Zhang, Zhou Wang, Shali Jiang, Huayu Li, Zhengxing Chen, WenYen Chen, Jiyan Yang, Wei Wen||Web-scale ranking systems at Meta serving billions of users is complex. Improving ranking models is essential but engineering heavy. Automated Machine Learning (AutoML) can release engineers from labor intensive work of tuning ranking models; however, it is unknown if AutoML is efficient enough to meet tight production timeline in real-world and, at the same time, bring additional improvements to the strong baselines. Moreover, to achieve higher ranking performance, there is an ever-increasing demand to scale up ranking models to even larger capacity, which imposes more challenges on the efficiency. The large scale of models and tight production schedule requires AutoML to outperform human baselines by only using a small number of model evaluation trials (around 100). We presents a sampling-based AutoML method, focusing on neural architecture search and hyperparameter optimization, addressing these challenges in Meta-scale production when building large capacity models. Our approach efficiently handles large-scale data demands. It leverages a lightweight predictor-based searcher and reinforcement learning to explore vast search spaces, significantly reducing the number of model evaluations. Through experiments in large capacity modeling for CTR and CVR applications, we show that our method achieves outstanding Return on Investment (ROI) versus human tuned baselines, with up to 0.09% Normalized Entropy (NE) loss reduction or $25\%$ Query per Second (QPS) increase by only sampling one hundred models on average from a curated search space. The proposed AutoML method has already made real-world impact where a discovered Instagram CTR model with up to -0.36% NE gain (over existing production baseline) was selected for large-scale online A/B test and show statistically significant gain. These production results proved AutoML efficacy and accelerated its adoption in ranking systems at Meta.|Meta 为数十亿用户服务的网络级别排名系统非常复杂。改进排名模型至关重要，但工程量很大。自动机器学习(Automated Machine Learning，AutoML)可以让工程师们摆脱劳动密集型的排序模型调整工作; 然而，目前还不清楚 AutoML 是否足够有效，能够满足现实世界中紧张的生产时间表，同时还能给强大的基线带来额外的改进。此外，为了获得更高的排序性能，将排序模型扩展到更大容量的需求也在不断增加，这对效率提出了更多的挑战。大规模的模型和紧凑的生产进度要求 AutoML 仅仅使用少量的模型评估试验(大约100次)就能超越人类基线。提出了一种基于抽样的 AutoML 方法，重点研究了神经网络结构搜索和超参数优化，解决了元规模生产在建立大容量模型时遇到的问题。我们的方法有效地处理大规模的数据需求。它利用一个轻量级的基于预测器的搜索器和强化学习来探索广阔的搜索空间，大大减少了模型评估的数量。通过在 CTR 和 CVR 应用中的大容量建模实验，我们表明我们的方法实现了出色的投资回报率(ROI)相对于人工调整的基线，高达0.09% 的归一化熵(NE)损失减少或 $25% $Query per Second (QPS)增加通过平均抽样一百个模型从一个精心策划的搜索空间。提出的 AutoML 方法已经产生了现实世界的影响，其中发现的 Instagram CTR 模型具有高达 -0.36% 的 NE 增益(超过现有的生产基线) ，被选择用于大规模在线 A/B 测试，并显示出统计学显着的增益。这些生产结果证明了 AutoML 的有效性，并加速了其在 Meta 排名系统中的应用。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AutoML+for+Large+Capacity+Modeling+of+Meta's+Ranking+Systems)|0|
|[OneSparse: A Unified System for Multi-index Vector Search](https://doi.org/10.1145/3589335.3648338)|Yaoqi Chen, Ruicheng Zheng, Qi Chen, Shuotao Xu, Qianxi Zhang, Xue Wu, Weihao Han, Hua Yuan, Mingqin Li, Yujing Wang, Jason Li, Fan Yang, Hao Sun, Weiwei Deng, Feng Sun, Qi Zhang, Mao Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=OneSparse:+A+Unified+System+for+Multi-index+Vector+Search)|0|
|[LLaCE: Locally Linear Contrastive Embedding](https://doi.org/10.1145/3589335.3651534)|Ruichen Liu, Yang Liu, Jiming Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LLaCE:+Locally+Linear+Contrastive+Embedding)|0|
|[GraphSAGE-based POI Recommendation via Continuous-Time Modeling](https://doi.org/10.1145/3589335.3651515)|Yuwen Liu, Lianyong Qi, Weiming Liu, Xiaolong Xu, Xuyun Zhang, Wanchun Dou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphSAGE-based+POI+Recommendation+via+Continuous-Time+Modeling)|0|
|[Boost Social Recommendation via Adaptive Denoising Network](https://doi.org/10.1145/3589335.3651473)|Xinran Chen, Chaobo He, Quanlong Guan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Boost+Social+Recommendation+via+Adaptive+Denoising+Network)|0|
|[3D Face Reconstruction Using A Spectral-Based Graph Convolution Encoder](https://doi.org/10.1145/3589335.3651460)|Haoxin Xu, Zezheng Zhao, Yuxin Cao, Chunyu Chen, Hao Ge, Ziyao Liu||Monocular 3D face reconstruction plays a crucial role in avatar generation, with significant demand in web-related applications such as generating virtual financial advisors in FinTech. Current reconstruction methods predominantly rely on deep learning techniques and employ 2D self-supervision as a means to guide model learning. However, these methods encounter challenges in capturing the comprehensive 3D structural information of the face due to the utilization of 2D images for model training purposes. To overcome this limitation and enhance the reconstruction of 3D structural features, we propose an innovative approach that integrates existing 2D features with 3D features to guide the model learning process. Specifically, we introduce the 3D-ID Loss, which leverages the high-dimensional structure features extracted from a Spectral-Based Graph Convolution Encoder applied to the facial mesh. This approach surpasses the sole reliance on the 3D information provided by the facial mesh vertices coordinates. Our model is trained using 2D-3D data pairs from a combination of datasets and achieves state-of-the-art performance on the NoW benchmark.|单目3D 人脸重建在虚拟化身生成中起着至关重要的作用，在金融科技虚拟财务顾问生成等网络相关应用方面有着巨大的需求。目前的重建方法主要依赖于深度学习技术，采用二维自我监督作为指导模型学习的手段。然而，由于二维图像用于模型训练目的，这些方法在获取人脸的全面三维结构信息方面遇到了挑战。为了克服这一局限性，并加强三维结构特征的重建，我们提出了一种创新的方法，集成现有的二维特征与三维特征，以指导模型学习过程。具体来说，我们介绍了3D-ID 丢失，它利用了从基于光谱的图卷积编码器提取的高维结构特征应用到面部网格。这种方法超越了对面部网格顶点坐标提供的三维信息的唯一依赖。我们的模型是训练使用的2D-3D 数据对从一个组合的数据集，并实现了国家的最先进的性能的 NoW 基准。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=3D+Face+Reconstruction+Using+A+Spectral-Based+Graph+Convolution+Encoder)|0|
|[General2Specialized LLMs Translation for E-commerce](https://doi.org/10.1145/3589335.3651510)|Kaidi Chen, Ben Chen, Dehong Gao, Huangyu Dai, Wen Jiang, Wei Ning, Shanqing Yu, Libin Yang, Xiaoyan Cai||Existing Neural Machine Translation (NMT) models mainly handle translation in the general domain, while overlooking domains with special writing formulas, such as e-commerce and legal documents. Taking e-commerce as an example, the texts usually include amounts of domain-related words and have more grammar problems, which leads to inferior performances of current NMT methods. To address these problems, we collect two domain-related resources, including a set of term pairs (aligned Chinese-English bilingual terms) and a parallel corpus annotated for the e-commerce domain. Furthermore, we propose a two-step fine-tuning paradigm (named G2ST) with self-contrastive semantic enhancement to transfer one general NMT model to the specialized NMT model for e-commerce. The paradigm can be used for the NMT models based on Large language models (LLMs). Extensive evaluations on real e-commerce titles demonstrate the superior translation quality and robustness of our G2ST approach, as compared with state-of-the-art NMT models such as LLaMA, Qwen, GPT-3.5, and even GPT-4.|现有的神经机器翻译(NMT)模型主要处理一般领域的翻译，而忽略了电子商务、法律文件等具有特殊写作公式的领域。以电子商务为例，文本通常包含大量领域相关词汇，存在较多的语法问题，导致现有的 NMT 方法性能较差。为了解决这些问题，我们收集了两个与领域相关的资源，包括一组术语对(对齐的汉英双语术语)和一个为电子商务领域注释的平行语料库。在此基础上，本文提出了一个具有自对比语义增强的两步微调范式(G2ST) ，将一个通用的 NMT 模型转化为电子商务的专用 NMT 模型。该范例可用于基于大型语言模型(LLM)的 NMT 模型。对实际电子商务标题的广泛评估表明，与 LLaMA，Qwen，GPT-3.5甚至 GPT-4等最先进的 NMT 模型相比，我们的 G2ST 方法具有优越的翻译质量和稳健性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=General2Specialized+LLMs+Translation+for+E-commerce)|0|
|[Counterfactual Explanations for Visual Recommender Systems](https://doi.org/10.1145/3589335.3651484)|Neham Jain, Vibhhu Sharma, Gaurav Sinha||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Counterfactual+Explanations+for+Visual+Recommender+Systems)|0|
|[Ad Laundering: How Websites Deceive Advertisers into Rendering Ads Next to Illicit Content](https://doi.org/10.1145/3589335.3651466)|Emmanouil Papadogiannakis, Panagiotis Papadopoulos, Evangelos P. Markatos, Nicolas Kourtellis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ad+Laundering:+How+Websites+Deceive+Advertisers+into+Rendering+Ads+Next+to+Illicit+Content)|0|
|[Is the 'Impression Log' Beneficial to Evaluating News Recommender Systems? No, it is Not!](https://doi.org/10.1145/3589335.3651527)|Jeewon Ahn, HongKyun Bae, SangWook Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Is+the+'Impression+Log'+Beneficial+to+Evaluating+News+Recommender+Systems?+No,+it+is+Not!)|0|
|[How Good are LLMs in Generating Personalized Advertisements?](https://doi.org/10.1145/3589335.3651520)|Elyas Meguellati, Lei Han, Abraham Bernstein, Shazia W. Sadiq, Gianluca Demartini||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+Good+are+LLMs+in+Generating+Personalized+Advertisements?)|0|
|[Compact Interpretable Tensor Graph Multi-Modal News Embeddings](https://doi.org/10.1145/3589335.3651480)|Dawon Ahn, William Shiao, Arindam Khaled, Andrew Bauer, Stefanos Poulis, Evangelos E. Papalexakis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Compact+Interpretable+Tensor+Graph+Multi-Modal+News+Embeddings)|0|
|[Proactive Recommendation with Iterative Preference Guidance](https://doi.org/10.1145/3589335.3651548)|Shuxian Bi, Wenjie Wang, Hang Pan, Fuli Feng, Xiangnan He||Recommender systems mainly tailor personalized recommendations according to user interests learned from user feedback. However, such recommender systems passively cater to user interests and even reinforce existing interests in the feedback loop, leading to problems like filter bubbles and opinion polarization. To counteract this, proactive recommendation actively steers users towards developing new interests in a target item or topic by strategically modulating recommendation sequences. Existing work for proactive recommendation faces significant hurdles: 1) overlooking the user feedback in the guidance process; 2) lacking explicit modeling of the guiding objective; and 3) insufficient flexibility for integration into existing industrial recommender systems. To address these issues, we introduce an Iterative Preference Guidance (IPG) framework. IPG performs proactive recommendation in a flexible post-processing manner by ranking items according to their IPG scores that consider both interaction probability and guiding value. These scores are explicitly estimated with iteratively updated user representation that considers the most recent user interactions. Extensive experiments validate that IPG can effectively guide user interests toward target interests with a reasonable trade-off in recommender accuracy. The code is available at https://github.com/GabyUSTC/IPG-Rec.|推荐系统主要根据用户反馈中学到的用户兴趣量身定制个性化推荐。然而，这样的推荐系统被动地迎合了用户的兴趣，甚至加强了反馈回路中已有的兴趣，导致了过滤泡沫和观点两极分化等问题。为了解决这个问题，主动推荐通过策略性地调整推荐顺序，积极地引导用户在目标项目或主题中发展新的兴趣。主动推荐的现有工作面临着重大障碍: 1)忽视指导过程中的用户反馈; 2)缺乏指导目标的明确建模; 3)集成到现有行业推荐系统的灵活性不足。为了解决这些问题，我们引入了一个迭代偏好指导(IPG)框架。IPG 采用灵活的后处理方式，根据 IPG 分数对项目进行排序，同时考虑交互概率和指导价值，从而实现主动推荐。这些分数是通过考虑最近的用户交互的迭代更新的用户表示来显式估计的。大量的实验验证了 IPG 能够有效地引导用户兴趣向目标兴趣转移，并在推荐准确性方面做出了合理的权衡。密码可在 https://github.com/gabyustc/ipg-rec 查阅。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Proactive+Recommendation+with+Iterative+Preference+Guidance)|0|
|[FACT-GPT: Fact-Checking Augmentation via Claim Matching with LLMs](https://doi.org/10.1145/3589335.3651504)|EunCheol Choi, Emilio Ferrara||Our society is facing rampant misinformation harming public health and trust. To address the societal challenge, we introduce FACT-GPT, a system leveraging Large Language Models (LLMs) to automate the claim matching stage of fact-checking. FACT-GPT, trained on a synthetic dataset, identifies social media content that aligns with, contradicts, or is irrelevant to previously debunked claims. Our evaluation shows that our specialized LLMs can match the accuracy of larger models in identifying related claims, closely mirroring human judgment. This research provides an automated solution for efficient claim matching, demonstrates the potential of LLMs in supporting fact-checkers, and offers valuable resources for further research in the field.|我们的社会正面临猖獗的错误信息危害公众健康和信任。为了应对社会挑战，我们引入了 FACT-GPT，这是一个利用大型语言模型(LLM)来自动化索赔匹配事实检查阶段的系统。FACT-GPT 在一个合成数据集上进行训练，识别与之前被揭穿的主张相一致、相互矛盾或无关的社交媒体内容。我们的评估表明，我们的专业 LLM 可以匹配的准确性较大的模型在识别相关的索赔，密切反映人类的判断。该研究为索赔匹配提供了一个自动化的解决方案，展示了 LLM 在支持事实核查方面的潜力，并为该领域的进一步研究提供了有价值的资源。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FACT-GPT:+Fact-Checking+Augmentation+via+Claim+Matching+with+LLMs)|0|
|[Benchmarking News Recommendation in the Era of Green AI](https://doi.org/10.1145/3589335.3651472)|Qijiong Liu, Jieming Zhu, Quanyu Dai, XiaoMing Wu||Over recent years, news recommender systems have gained significant attention in both academia and industry, emphasizing the need for a standardized benchmark to evaluate and compare the performance of these systems. Concurrently, Green AI advocates for reducing the energy consumption and environmental impact of machine learning. To address these concerns, we introduce the first Green AI benchmarking framework for news recommendation, known as GreenRec, and propose a metric for assessing the tradeoff between recommendation accuracy and efficiency. Our benchmark encompasses 30 base models and their variants, covering traditional end-to-end training paradigms as well as our proposed efficient only-encode-once (OLEO) paradigm. Through experiments consuming 2000 GPU hours, we observe that the OLEO paradigm achieves competitive accuracy compared to state-of-the-art end-to-end paradigms and delivers up to a 2992% improvement in sustainability metrics.|近年来，新闻推荐系统引起了学术界和工业界的重视，强调需要一个标准化的基准来评估和比较这些系统的性能。同时，绿色人工智能倡导降低机器学习的能源消耗和环境影响。为了解决这些问题，我们引入了第一个新闻推荐的绿色 AI 基准框架，称为 GreenRec，并提出了一个评估推荐准确性和效率之间权衡的度量标准。我们的基准包括30个基本模型及其变体，涵盖了传统的端到端训练范例以及我们提出的有效的只编码一次(OLEO)范例。通过消耗2000 GPU 小时的实验，我们观察到 OLEO 范例与最先进的端到端范例相比达到了具有竞争力的准确性，并在可持续性指标方面提供了高达2992% 的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Benchmarking+News+Recommendation+in+the+Era+of+Green+AI)|0|
|[Event GDR: Event-Centric Generative Document Retrieval](https://doi.org/10.1145/3589335.3651500)|Yong Guan, Dingxiao Liu, Jinchen Ma, Hao Peng, Xiaozhi Wang, Lei Hou, Ru Li||Generative document retrieval, an emerging paradigm in information retrieval, learns to build connections between documents and identifiers within a single model, garnering significant attention. However, there are still two challenges: (1) neglecting inner-content correlation during document representation; (2) lacking explicit semantic structure during identifier construction. Nonetheless, events have enriched relations and well-defined taxonomy, which could facilitate addressing the above two challenges. Inspired by this, we propose Event GDR, an event-centric generative document retrieval model, integrating event knowledge into this task. Specifically, we utilize an exchange-then-reflection method based on multi-agents for event knowledge extraction. For document representation, we employ events and relations to model the document to guarantee the comprehensiveness and inner-content correlation. For identifier construction, we map the events to well-defined event taxonomy to construct the identifiers with explicit semantic structure. Our method achieves significant improvement over the baselines on two datasets, and also hopes to provide insights for future research.|生成文献检索是一种新兴的信息检索范式，它学会在单一模型中建立文档和标识符之间的联系，引起了人们的极大关注。但是，目前仍然存在两个问题: (1)忽视文档表示中的内容相关性; (2)标识符构造中缺乏明确的语义结构。尽管如此，事件丰富了关系和明确的分类，这可能有助于解决上述两个挑战。受此启发，我们提出以事件为中心的生成文献检索模型 Event gDR，将事件知识整合到这项任务中。具体地说，我们利用了一种基于多智能体的交换-反射方法来提取事件知识。对于文档表示，我们使用事件和关系对文档进行建模，以保证文档的全面性和内容的相关性。对于标识符构造，我们将事件映射到定义良好的事件分类法，以构造具有显式语义结构的标识符。我们的方法在两个数据集的基线上取得了显著的改进，同时也希望能够为以后的研究提供一些启示。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Event+GDR:+Event-Centric+Generative+Document+Retrieval)|0|
|[DIAERESIS: Knowledge Graph Partitioning for Efficient Query Answering](https://doi.org/10.1145/3589335.3651231)|Georgia Troullinou, Kostas Stefanidis, Dimitris Plexousakis, Haridimos Kondylakis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DIAERESIS:+Knowledge+Graph+Partitioning+for+Efficient+Query+Answering)|0|
|[Box2Go: Collaborative Interactive Infobox Filling](https://doi.org/10.1145/3589335.3651235)|Benjamin Hättasch, Carsten Binnig||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Box2Go:+Collaborative+Interactive+Infobox+Filling)|0|
|[HINCare: An Intelligent Helper Recommender System for Elderly Care](https://doi.org/10.1145/3589335.3651236)|Carrie Wang, Wentao Ning, Xiaoman Wu, Reynold Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HINCare:+An+Intelligent+Helper+Recommender+System+for+Elderly+Care)|0|
|[Linked Open Literature Review using the Neuro-symbolic Open Research Knowledge Graph](https://doi.org/10.1145/3589335.3651238)|Azanzi Jiomekong, Sören Auer, Allard Oelen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Linked+Open+Literature+Review+using+the+Neuro-symbolic+Open+Research+Knowledge+Graph)|0|
|[RecAI: Leveraging Large Language Models for Next-Generation Recommender Systems](https://doi.org/10.1145/3589335.3651242)|Jianxun Lian, Yuxuan Lei, Xu Huang, Jing Yao, Wei Xu, Xing Xie||This paper introduces RecAI, a practical toolkit designed to augment or even revolutionize recommender systems with the advanced capabilities of Large Language Models (LLMs). RecAI provides a suite of tools, including Recommender AI Agent, Recommendation-oriented Language Models, Knowledge Plugin, RecExplainer, and Evaluator, to facilitate the integration of LLMs into recommender systems from multifaceted perspectives. The new generation of recommender systems, empowered by LLMs, are expected to be more versatile, explainable, conversational, and controllable, paving the way for more intelligent and user-centric recommendation experiences. We hope the open-source of RecAI can help accelerate evolution of new advanced recommender systems. The source code of RecAI is available at <https://github.com/microsoft/RecAI>.|本文介绍了 RecAI，这是一个实用的工具包，旨在用大型语言模型(LLM)的先进功能来增强甚至革新推荐系统。RecAI 提供了一套工具，包括推荐人工智能代理、面向推荐的语言模型、知识插件、重新解释器和评估器，以促进从多方面的角度将 LLM 集成到推荐系统中。由 LLM 授权的新一代推荐系统预计将更加通用、可解释、可对话和可控，为更加智能和以用户为中心的推荐体验铺平道路。我们希望 RecAI 的开源能够帮助加速新的高级推荐系统的发展。RecAI 的源代码可于 <  https://github.com/microsoft/RecAI 下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RecAI:+Leveraging+Large+Language+Models+for+Next-Generation+Recommender+Systems)|0|
|[Towards Personalized Evaluation of Large Language Models with An Anonymous Crowd-Sourcing Platform](https://doi.org/10.1145/3589335.3651243)|Mingyue Cheng, Hao Zhang, Jiqian Yang, Qi Liu, Li Li, Xin Huang, Liwei Song, Zhi Li, Zhenya Huang, Enhong Chen||Large language model evaluation plays a pivotal role in the enhancement of its capacity. Previously, numerous methods for evaluating large language models have been proposed in this area. Despite their effectiveness, these existing works mainly focus on assessing objective questions, overlooking the capability to evaluate subjective questions which is extremely common for large language models. Additionally, these methods predominantly utilize centralized datasets for evaluation, with question banks concentrated within the evaluation platforms themselves. Moreover, the evaluation processes employed by these platforms often overlook personalized factors, neglecting to consider the individual characteristics of both the evaluators and the models being evaluated. To address these limitations, we propose a novel anonymous crowd-sourcing evaluation platform, BingJian, for large language models that employs a competitive scoring mechanism where users participate in ranking models based on their performance. This platform stands out not only for its support of centralized evaluations to assess the general capabilities of models but also for offering an open evaluation gateway. Through this gateway, users have the opportunity to submit their questions, testing the models on a personalized and potentially broader range of capabilities. Furthermore, our platform introduces personalized evaluation scenarios, leveraging various forms of human-computer interaction to assess large language models in a manner that accounts for individual user preferences and contexts. The demonstration of BingJian can be accessed at https://github.com/Mingyue-Cheng/Bingjian.|大型语言模型评价在提高语言能力方面起着举足轻重的作用。在此之前，许多评估大型语言模型的方法已经被提出在这个领域。尽管这些工作很有效，但现有的工作主要集中在评价客观问题上，忽视了评价主观问题的能力，而这种能力在大型语言模型中极为常见。此外，这些方法主要利用集中的数据集进行评估，问题库集中在评估平台本身。此外，这些平台所采用的评价过程往往忽视个性化因素，忽视考虑评价者和被评价模型的个性特征。为了解决这些局限性，我们提出了一个新的匿名众包评估平台，兵鉴，为大型语言模型，采用竞争性评分机制，其中用户参与排名模型的基础上，他们的表现。该平台不仅支持集中评价，以评估模型的一般能力，而且还提供了一个开放的评价网关。通过这个网关，用户有机会提交他们的问题，测试模型的个性化和潜在的更广泛的能力范围。此外，我们的平台引入了个性化的评估场景，利用各种形式的人机交互来评估大型语言模型，以考虑到个人用户偏好和上下文的方式。市民可透过 https://github.com/mingyue-cheng/BingJian 浏览「冰箭」的演示资料。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Personalized+Evaluation+of+Large+Language+Models+with+An+Anonymous+Crowd-Sourcing+Platform)|0|
|[PKG API: A Tool for Personal Knowledge Graph Management](https://doi.org/10.1145/3589335.3651247)|Nolwenn Bernard, Ivica Kostric, Weronika Lajewska, Krisztian Balog, Petra Galuscáková, Vinay Setty, Martin G. Skjæveland||Personal knowledge graphs (PKGs) offer individuals a way to store and consolidate their fragmented personal data in a central place, improving service personalization while maintaining full user control. Despite their potential, practical PKG implementations with user-friendly interfaces remain scarce. This work addresses this gap by proposing a complete solution to represent, manage, and interface with PKGs. Our approach includes (1) a user-facing PKG Client, enabling end-users to administer their personal data easily via natural language statements, and (2) a service-oriented PKG API. To tackle the complexity of representing these statements within a PKG, we present an RDF-based PKG vocabulary that supports this, along with properties for access rights and provenance.|个人知识图(PKG)为个人提供了一种在中心位置存储和整合支离破碎的个人数据的方法，改善了服务的个性化，同时保持了完全的用户控制。尽管 PKG 具有潜力，但实际的具有用户友好界面的 PKG 实现仍然很少。这项工作通过提出一个完整的解决方案来表示、管理和与 PKG 的接口来弥补这一差距。我们的方法包括(1)一个面向用户的 PKG 客户端，使最终用户能够通过自然语言语句轻松地管理他们的个人数据，和(2)一个面向服务的 PKG API。为了解决在 PKG 中表示这些语句的复杂性，我们提供了一个基于 RDF 的 PKG 词汇表来支持这一点，以及访问权限和出处的属性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PKG+API:+A+Tool+for+Personal+Knowledge+Graph+Management)|0|
|[Brinjal: A Web-Plugin for Collaborative Hate Speech Detection](https://doi.org/10.1145/3589335.3651250)|Ming Shan Hee, Karandeep Singh, Charlotte Ng Si Min, Kenny Tsu Wei Choo, Roy KaWei Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Brinjal:+A+Web-Plugin+for+Collaborative+Hate+Speech+Detection)|0|
|[SocialGenPod: Privacy-Friendly Generative AI Social Web Applications with Decentralised Personal Data Stores](https://doi.org/10.1145/3589335.3651251)|Vidminas Vizgirda, Rui Zhao, Naman Goel||We present SocialGenPod, a decentralised and privacy-friendly way of deploying generative AI Web applications. Unlike centralised Web and data architectures that keep user data tied to application and service providers, we show how one can use Solid – a decentralised Web specification – to decouple user data from generative AI applications. We demonstrate SocialGenPod using a prototype that allows users to converse with different Large Language Models, optionally leveraging Retrieval Augmented Generation to generate answers grounded in private documents stored in any Solid Pod that the user is allowed to access, directly or indirectly. SocialGenPod makes use of Solid access control mechanisms to give users full control of determining who has access to data stored in their Pods. SocialGenPod keeps all user data (chat history, app configuration, personal documents, etc) securely in the user's personal Pod; separate from specific model or application providers. Besides better privacy controls, this approach also enables portability across different services and applications. Finally, we discuss challenges, posed by the large compute requirements of state-of-the-art models, that future research in this area should address. Our prototype is open-source and available at: https://github.com/Vidminas/socialgenpod/.|我们展示了 SocialGenPod，一种分散的和隐私友好的方式来部署生成性 AI Web 应用程序。与将用户数据与应用程序和服务提供商绑定在一起的集中式 Web 和数据架构不同，我们展示了如何使用 Solid ——一种分散式 Web 规范——将用户数据与生成式 AI 应用程序分离开来。我们使用一个允许用户与不同的大型语言模型进行对话的原型来演示 SocialGenPod，可以选择性地利用获取增强生成技术来生成基于私有文档的答案，这些私有文档存储在 Solid Pod 中，用户可以直接或间接地访问这些文档。SocialGenPod 利用 Solid 访问控制机制，让用户完全控制谁可以访问存储在 Pods 中的数据。SocialGenPod 将所有用户数据(聊天记录、应用程序配置、个人文档等)安全地保存在用户的个人 Pod 中; 与特定的模型或应用程序提供商分开。除了更好的隐私控制，这种方法还支持跨不同服务和应用程序的可移植性。最后，我们讨论了这一领域未来研究应该解决的挑战，这些挑战是由最先进模型的巨大计算需求造成的。我们的原型是开源的，可以在以下 https://github.com/vidminas/socialgenpod/获得。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SocialGenPod:+Privacy-Friendly+Generative+AI+Social+Web+Applications+with+Decentralised+Personal+Data+Stores)|0|
|[Ducho 2.0: Towards a More Up-to-Date Unified Framework for the Extraction of Multimodal Features in Recommendation](https://doi.org/10.1145/3589335.3651440)|Matteo Attimonelli, Danilo Danese, Daniele Malitesta, Claudio Pomo, Giuseppe Gassi, Tommaso Di Noia||In this work, we introduce Ducho 2.0, the latest stable version of our framework. Differently from Ducho, Ducho 2.0 offers a more personalized user experience with the definition and import of custom extraction models fine-tuned on specific tasks and datasets. Moreover, the new version is capable of extracting and processing features through multimodal-by-design large models. Notably, all these new features are supported by optimized data loading and storing to the local memory. To showcase the capabilities of Ducho 2.0, we demonstrate a complete multimodal recommendation pipeline, from the extraction/processing to the final recommendation. The idea is to provide practitioners and experienced scholars with a ready-to-use tool that, put on top of any multimodal recommendation framework, may permit them to run extensive benchmarking analyses. All materials are accessible at: <https://github.com/sisinflab/Ducho>.|在本文中，我们将介绍 Ducho 2.0，它是我们框架的最新稳定版本。与 Ducho 不同，Ducho 2.0提供了更个性化的用户体验，定义和导入了针对特定任务和数据集进行微调的自定义提取模型。此外，新版本还能够通过设计的多模态大模型提取和处理特征。值得注意的是，所有这些新特性都得到了优化的数据加载和存储到本地内存的支持。为了展示 Ducho 2.0的功能，我们展示了一个完整的多模式推荐管道，从提取/处理到最终推荐。这个想法是为从业人员和有经验的学者提供一个现成的工具，放在任何多模式建议框架之上，可以允许他们进行广泛的基准分析。所有资料可浏览以下 https://github.com/sisinflab/ducho  :。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ducho+2.0:+Towards+a+More+Up-to-Date+Unified+Framework+for+the+Extraction+of+Multimodal+Features+in+Recommendation)|0|
|[SE-PQA: Personalized Community Question Answering](https://doi.org/10.1145/3589335.3651445)|Pranav Kasela, Marco Braga, Gabriella Pasi, Raffaele Perego||Personalization in Information Retrieval is a topic studied for a long time. Nevertheless, there is still a lack of high-quality, real-world datasets to conduct large-scale experiments and evaluate models for personalized search. This paper contributes to filling this gap by introducing SE-PQA (StackExchange - Personalized Question Answering), a new curated resource to design and evaluate personalized models related to the task of community Question Answering (cQA). The contributed dataset includes more than 1 million queries and 2 million answers, annotated with a rich set of features modeling the social interactions among the users of a popular cQA platform. We describe the characteristics of SE-PQA and detail the features associated with questions and answers. We also provide reproducible baseline methods for the cQA task based on the resource, including deep learning models and personalization approaches. The results of the preliminary experiments conducted show the appropriateness of SE-PQA to train effective cQA models; they also show that personalization remarkably improves the effectiveness of all the methods tested. Furthermore, we show the benefits in terms of robustness and generalization of combining data from multiple communities for personalization purposes.|信息检索的个性化是一个长期研究的课题。尽管如此，仍然缺乏高质量的、真实世界的数据集来进行大规模的实验和评估个性化检索模型。本文通过引入 SE-PQA 来填补这一空白。 SE-PQA 是一种新的策划资源，用于设计和评估与社区问答任务(cQA)相关的个性化模型。贡献的数据集包括超过100万个查询和200万个答案，并用一组丰富的特性对流行的 cQA 平台的用户之间的社交互动进行了建模。我们描述了 SE-PQA 的特征，并详细描述了与问答相关的特征。我们还为基于资源的 cQA 任务提供了可重复的基线方法，包括深度学习模型和个性化方法。初步实验结果表明，SE-PQA 方法训练有效的 cQA 模型是合适的，并且个性化显著提高了所有测试方法的有效性。此外，我们还展示了将来自多个社区的数据用于个性化目的的健壮性和通用性方面的好处。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SE-PQA:+Personalized+Community+Question+Answering)|0|
|[Digital Democracy at Crossroads: A Meta-Analysis of Web and AI Influence on Global Elections](https://doi.org/10.1145/3589335.3652003)|Zheng Wei, Xian Xu, Pan Hui||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Digital+Democracy+at+Crossroads:+A+Meta-Analysis+of+Web+and+AI+Influence+on+Global+Elections)|0|
|[BoxCare: A Box Embedding Model for Disease Representation and Diagnosis Prediction in Healthcare Data](https://doi.org/10.1145/3589335.3651448)|Hang Lv, Zehai Chen, Yacong Yang, Guofang Ma, Yanchao Tan, Carl Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BoxCare:+A+Box+Embedding+Model+for+Disease+Representation+and+Diagnosis+Prediction+in+Healthcare+Data)|0|
|[Enabling Pre-Shock State Detection using Electrogram Signals from Implantable Cardioverter-Defibrillators](https://doi.org/10.1145/3589335.3651450)|Runze Yan, Neal K. Bhatia, Faisal M. Merchant, Alex Fedorov, Ran Xiao, Cheng Ding, Xiao Hu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enabling+Pre-Shock+State+Detection+using+Electrogram+Signals+from+Implantable+Cardioverter-Defibrillators)|0|
|[In The Beginning, Let There Be The Word: Challenges and Insights in Applying Sentiment Analysis to Social Research](https://doi.org/10.1145/3589335.3651264)|Andrzej Meler||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=In+The+Beginning,+Let+There+Be+The+Word:+Challenges+and+Insights+in+Applying+Sentiment+Analysis+to+Social+Research)|0|
|[Modeling Multidimensional Cognitive Search in Creativity with Generalized Additive Model](https://doi.org/10.1145/3589335.3651267)|Jia Lin Cheoh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modeling+Multidimensional+Cognitive+Search+in+Creativity+with+Generalized+Additive+Model)|0|
|[Data Augmentation for Conversational AI](https://doi.org/10.1145/3589335.3641238)|Heydar Soudani, Roxana Petcu, Evangelos Kanoulas, Faegheh Hasibi|Radboud Univ Nijmegen, Nijmegen, Netherlands; Univ Amsterdam, Amsterdam, Netherlands|Advancements in conversational systems have revolutionized information access, surpassing the limitations of single queries. However, developing dialogue systems requires a large amount of training data, which is a challenge in low-resource domains and languages. Traditional data collection methods like crowd-sourcing are labor-intensive and time-consuming, making them ineffective in this context. Data augmentation (DA) is an affective approach to alleviate the data scarcity problem in conversational systems. This tutorial provides a comprehensive and up-to-date overview of DA approaches in the context of conversational systems. It highlights recent advances in conversation augmentation, open domain and task-oriented conversation generation, and different paradigms of evaluating these models. We also discuss current challenges and future directions in order to help researchers and practitioners to further advance the field in this area.|会话系统的进步彻底改变了信息访问，超越了单个查询的局限性。然而，开发对话系统需要大量的训练数据，这在资源不足的领域和语言中是一个挑战。传统的数据收集方法，如众包，是劳动密集型和耗时的，使他们在这种情况下无效。数据增强是解决会话系统中数据稀缺问题的有效途径。本教程提供了在会话系统上下文中 DA 方法的全面和最新概述。它强调了会话增强，开放领域和面向任务的会话生成的最新进展，以及评估这些模型的不同范式。我们还讨论了当前的挑战和未来的方向，以帮助研究人员和从业人员进一步推进该领域。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Data+Augmentation+for+Conversational+AI)|0|
|[Recent Advances in Generative Information Retrieval](https://doi.org/10.1145/3589335.3641239)|Yubao Tang, Ruqing Zhang, Weiwei Sun, Jiafeng Guo, Maarten de Rijke||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Recent+Advances+in+Generative+Information+Retrieval)|0|
|[Large Language Models for Recommendation: Progresses and Future Directions](https://doi.org/10.1145/3589335.3641247)|Jizhi Zhang, Keqin Bao, Yang Zhang, Wenjie Wang, Fuli Feng, Xiangnan He|Univ Sci & Technol China, Hefei, Peoples R China; Natl Univ Singapore, Singapore, Singapore|The powerful large language models (LLMs) have played a pivotal role in advancing recommender systems. Recently, in both academia and industry, there has been a surge of interest in developing LLMs for recommendation, referred to as LLM4Rec. This includes endeavors like leveraging LLMs for generative item retrieval and ranking, as well as the exciting possibility of building universal LLMs for diverse open-ended recommendation tasks. These developments hold the potential to reshape the traditional recommender paradigm, paving the way for the next-generation recommender systems. In this tutorial, we aim to retrospect the evolution of LLM4Rec and conduct a comprehensive review of existing research. In particular, we will clarify how recommender systems benefit from LLMs through a variety of perspectives, including the model architecture, learning paradigm, and the strong abilities of LLMs such as chatting, generalization, planning, and generation. Furthermore, we will discuss the critical challenges and open problems in this emerging field, for instance, the trustworthiness, efficiency, and model retraining issues. Lastly, we will summarize the implications of previous work and outline future research directions. We believe that this tutorial will assist the audience in better understanding the progress and prospects of LLM4Rec, inspiring them for future exploration. This, in turn, will drive the prosperity of LLM4Rec, possibly fostering a paradigm shift in recommendation systems.|强大的大型语言模型(LLM)在推进推荐系统方面发挥了关键作用。最近，在学术界和工业界，对开发推荐 LLM 的兴趣激增，称为 LLM4Rec。这包括利用 LLM 进行生成性项目检索和排名，以及为各种开放式推荐任务构建通用 LLM 的令人兴奋的可能性。这些发展有可能重塑传统的推荐模式，为下一代推荐系统铺平道路。在本教程中，我们的目标是回顾 LLM4Rec 的演变，并对现有的研究进行一个全面的回顾。特别是，我们将通过多种视角阐明推荐系统如何从 LLM 中受益，包括模型体系结构、学习范式以及 LLM 的强大能力，如聊天、泛化、规划和生成。此外，我们将讨论在这个新兴领域的关键挑战和公开问题，例如，可信赖性，效率和模型再培训问题。最后，我们将总结以往工作的启示，并概述未来的研究方向。我们相信，本教程将帮助观众更好地了解 LLM4Rec 的进展和前景，鼓舞他们进行未来的探索。这反过来将推动 LLM4Rec 的繁荣，可能促进推荐系统的范式转变。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large+Language+Models+for+Recommendation:+Progresses+and+Future+Directions)|0|
|[Multimodal Pretraining and Generation for Recommendation: A Tutorial](https://doi.org/10.1145/3589335.3641248)|Jieming Zhu, Xin Zhou, Chuhan Wu, Rui Zhang, Zhenhua Dong||Personalized recommendation stands as a ubiquitous channel for users to explore information or items aligned with their interests. Nevertheless, prevailing recommendation models predominantly rely on unique IDs and categorical features for user-item matching. While this ID-centric approach has witnessed considerable success, it falls short in comprehensively grasping the essence of raw item contents across diverse modalities, such as text, image, audio, and video. This underutilization of multimodal data poses a limitation to recommender systems, particularly in the realm of multimedia services like news, music, and short-video platforms. The recent surge in pretraining and generation techniques presents both opportunities and challenges in the development of multimodal recommender systems. This tutorial seeks to provide a thorough exploration of the latest advancements and future trajectories in multimodal pretraining and generation techniques within the realm of recommender systems. The tutorial comprises three parts: multimodal pretraining, multimodal generation, and industrial applications and open challenges in the field of recommendation. Our target audience encompasses scholars, practitioners, and other parties interested in this domain. By providing a succinct overview of the field, we aspire to facilitate a swift understanding of multimodal recommendation and foster meaningful discussions on the future development of this evolving landscape.|个性化推荐是用户探索符合自己兴趣的信息或项目的一个无处不在的渠道。然而，流行的推荐模型主要依赖于用户项匹配的唯一 ID 和分类特征。虽然这种以 ID 为中心的方法已经取得了相当大的成功，但是它不能全面地掌握原始项目内容在不同模式(如文本、图像、音频和视频)中的本质。这种对多模式数据的利用不足对推荐系统造成了限制，特别是在新闻、音乐和短视频平台等多媒体服务领域。最近在培训前和生成技术方面的激增在开发多式联运推荐系统方面既带来了机遇，也带来了挑战。本教程旨在全面探讨推荐系统领域内多模式预培训和生成技术的最新进展和未来发展轨迹。本教程包括三个部分: 多模式预训练、多模式生成、工业应用和推荐领域的公开挑战。我们的目标受众包括学者、实践者和对该领域感兴趣的其他方面。我们希望通过简要介绍这一领域的情况，促进对多式联运建议的迅速理解，并推动就这一不断变化的格局的未来发展进行有意义的讨论。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multimodal+Pretraining+and+Generation+for+Recommendation:+A+Tutorial)|0|
|[On-Device Recommender Systems: A Tutorial on The New-Generation Recommendation Paradigm](https://doi.org/10.1145/3589335.3641250)|Hongzhi Yin, Tong Chen, Liang Qu, Bin Cui||Given the sheer volume of contemporary e-commerce applications, recommender systems (RSs) have gained significant attention in both academia and industry. However, traditional cloud-based RSs face inevitable challenges, such as resource-intensive computation, reliance on network access, and privacy breaches. In response, a new paradigm called on-device recommender systems (ODRSs) has emerged recently in various industries like Taobao, Google, and Kuaishou. ODRSs unleash the computational capacity of user devices with lightweight recommendation models tailored for resource-constrained environments, enabling real-time inference with users' local data. This tutorial aims to systematically introduce methodologies of ODRSs, including (1) an overview of existing research on ODRSs; (2) a comprehensive taxonomy of ODRSs, where the core technical content to be covered span across three major ODRS research directions, including on-device deployment and inference, on-device training, and privacy/security of ODRSs; (3) limitations and future directions of ODRSs. This tutorial expects to lay the foundation and spark new insights for follow-up research and applications concerning this new recommendation paradigm.|鉴于当代电子商务应用的庞大数量，推荐系统(RS)已经引起了学术界和工业界的重视。然而，传统的基于云的 RSS 面临着不可避免的挑战，如资源密集型计算、对网络访问的依赖和隐私泄露。作为回应，最近在淘宝、谷歌和 Kuaishou 等不同行业出现了一种名为在设备上推荐系统(on-device )的新模式。ODRS 使用轻量级推荐模型释放用户设备的计算能力，这些模型专门针对资源受限的环境，支持对用户的本地数据进行实时推断。本教程旨在系统地介绍 ODRS 的方法，包括(1) ODRS 现有研究的概述; (2) ODRS 的综合分类，其中涵盖的核心技术内容跨越三个主要的 ODRS 研究方向，包括在设备上的部署和推理，在设备上的培训，以及 ODRS 的隐私/安全; (3) ODRS 的局限性和未来的方向。本教程期望为后续研究和有关这种新的推荐范例的应用程序奠定基础并激发新的见解。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On-Device+Recommender+Systems:+A+Tutorial+on+The+New-Generation+Recommendation+Paradigm)|0|
|[TransDrift: Modeling Word-Embedding Drift using Transformer](https://doi.org/10.1145/3589335.3651894)|Nishtha Madaan, Prateek Chaudhury, Nishant Kumar, Srikanta Bedathur||In modern NLP applications, word embeddings are a crucial backbone that can be readily shared across a number of tasks. However as the text distributions change and word semantics evolve over time, the downstream applications using the embeddings can suffer if the word representations do not conform to the data drift. Thus, maintaining word embeddings to be consistent with the underlying data distribution is a key problem. In this work, we tackle this problem and propose TransDrift, a transformer-based prediction model for word embeddings. Leveraging the flexibility of transformer, our model accurately learns the dynamics of the embedding drift and predicts the future embedding. In experiments, we compare with existing methods and show that our model makes significantly more accurate predictions of the word embedding than the baselines. Crucially, by applying the predicted embeddings as a backbone for downstream classification tasks, we show that our embeddings lead to superior performance compared to the previous methods.|在现代自然语言处理应用中，单词嵌入是一个关键的骨干，可以很容易地跨多个任务共享。然而，随着文本分布的变化和词语义的演变，如果词表示不符合数据漂移，使用嵌入的下游应用程序可能会受到影响。因此，维护单词嵌入与底层数据分布的一致性是一个关键问题。在这项工作中，我们解决了这个问题，并提出了 TransDrift，一个基于变压器的字嵌入预测模型。利用变压器的灵活性，我们的模型准确地学习嵌入漂移的动态，并预测未来的嵌入。在实验中，我们与现有的方法进行了比较，结果表明我们的模型对单词嵌入的预测明显比基线更准确。重要的是，通过将预测嵌入作为下游分类任务的骨干，我们表明我们的嵌入方法比以前的方法具有更好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TransDrift:+Modeling+Word-Embedding+Drift+using+Transformer)|0|
|[Automated Claim Matching with Large Language Models: Empowering Fact-Checkers in the Fight Against Misinformation](https://doi.org/10.1145/3589335.3651910)|EunCheol Choi, Emilio Ferrara||In today's digital era, the rapid spread of misinformation poses threats to public well-being and societal trust. As online misinformation proliferates, manual verification by fact checkers becomes increasingly challenging. We introduce FACT-GPT (Fact-checking Augmentation with Claim matching Task-oriented Generative Pre-trained Transformer), a framework designed to automate the claim matching phase of fact-checking using Large Language Models (LLMs). This framework identifies new social media content that either supports or contradicts claims previously debunked by fact-checkers. Our approach employs GPT-4 to generate a labeled dataset consisting of simulated social media posts. This data set serves as a training ground for fine-tuning more specialized LLMs. We evaluated FACT-GPT on an extensive dataset of social media content related to public health. The results indicate that our fine-tuned LLMs rival the performance of larger pre-trained LLMs in claim matching tasks, aligning closely with human annotations. This study achieves three key milestones: it provides an automated framework for enhanced fact-checking; demonstrates the potential of LLMs to complement human expertise; offers public resources, including datasets and models, to further research and applications in the fact-checking domain.|在当今的数字时代，错误信息的迅速传播对公众福祉和社会信任构成了威胁。随着在线错误信息的激增，事实核查人员的手工验证变得越来越具有挑战性。本文介绍了 FACT-GPT (FACT-GPT) ，这是一个使用大型语言模型(LLM)实现索赔匹配阶段事实检查自动化的框架。该框架确定了新的社交媒体内容，这些内容要么支持要么与事实核查人员之前揭穿的说法相矛盾。我们的方法使用 GPT-4来生成一个由模拟的社交媒体帖子组成的标记数据集。这个数据集可以作为微调更专业化 LLM 的训练基地。我们评估了 FACT-GPT 的广泛数据集的社会媒体内容相关的公共卫生。结果表明，我们的微调 LLM 在索赔匹配任务中的性能与较大的预训练 LLM 相当，与人工注释非常接近。这项研究达到了三个关键的里程碑: 它提供了一个增强事实核查的自动化框架; 展示了 LLM 补充人类专业知识的潜力; 提供公共资源，包括数据集和模型，以进一步研究和应用在事实核查领域。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automated+Claim+Matching+with+Large+Language+Models:+Empowering+Fact-Checkers+in+the+Fight+Against+Misinformation)|0|
|[Decoding YouTube's Recommendation System: A Comparative Study of Metadata and GPT-4 Extracted Narratives](https://doi.org/10.1145/3589335.3651913)|Mayor Inna Gurung, Md Monoarul Islam Bhuiyan, Ahmed AlTaweel, Nitin Agarwal||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Decoding+YouTube's+Recommendation+System:+A+Comparative+Study+of+Metadata+and+GPT-4+Extracted+Narratives)|0|
|[Graph Coarsening via Convolution Matching for Scalable Graph Neural Network Training](https://doi.org/10.1145/3589335.3651920)|Charles Dickens, Edward W. Huang, Aishwarya Reganti, Jiong Zhu, Karthik Subbian, Danai Koutra||Graph summarization as a preprocessing step is an effective and complementary technique for scalable graph neural network (GNN) training. In this work, we propose the Coarsening Via Convolution Matching (CONVMATCH) algorithm and a highly scalable variant, A-CONVMATCH, for creating summarized graphs that preserve the output of graph convolution. We evaluate CONVMATCH on six real-world link prediction and node classification graph datasets, and show it is efficient and preserves prediction performance while significantly reducing the graph size. Notably, CONVMATCH achieves up to 95 performance of GNNs on node classification while trained on graphs summarized down to 1 tasks, CONVMATCH consistently outperforms all baselines, achieving up to a 2x improvement.|图形摘要作为一种预处理步骤，是可扩展图神经网络(GNN)训练的有效补充技术。在这项工作中，我们提出了粗化通过卷积匹配(CONVMATCH)算法和一个高度可伸缩的变体，A-CONVMATCH，用于创建总结图保持图卷积的输出。对实际的六个链路预测和节点分类图数据集进行了 CONVMATCH 评估，结果表明该算法在保持预测性能的同时，显著减小了图的大小。值得注意的是，CONVMATCH 在节点分类上实现了高达95个 GNN 的性能，同时对归纳为1个任务的图进行训练，CONVMATCH 始终优于所有基线，实现了高达2倍的改进。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Coarsening+via+Convolution+Matching+for+Scalable+Graph+Neural+Network+Training)|0|
|[FedHLT: Efficient Federated Low-Rank Adaption with Hierarchical Language Tree for Multilingual Modeling](https://doi.org/10.1145/3589335.3651933)|Zhihan Guo, Yifei Zhang, Zhuo Zhang, Zenglin Xu, Irwin King||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FedHLT:+Efficient+Federated+Low-Rank+Adaption+with+Hierarchical+Language+Tree+for+Multilingual+Modeling)|0|
|[Information Retrieval Meets Large Language Models](https://doi.org/10.1145/3589335.3641299)|Zheng Liu, Yujia Zhou, Yutao Zhu, Jianxun Lian, Chaozhuo Li, Zhicheng Dou, Defu Lian, JianYun Nie|Tsinghua University, China; South China University of Technology, China; Wuhan University, China; Zhejiang University, China; Jilin University, China; Shandong University, China; Shandong Artificial Intelligence Institute, China; Renmin University of China, China; Beijing University of Posts and Telecommunications, China; Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, China; University of Science and Technology of China, China; Institute of Computing Technology, Chinese Academy of Sciences, China; Huawei Technologies Ltd. Co, China|The research field of Information Retrieval (IR) has evolved significantly, expanding beyond traditional search to meet diverse user information needs. Recently, Large Language Models (LLMs) have demonstrated exceptional capabilities in text understanding, generation, and knowledge inference, opening up exciting avenues for IR research. LLMs not only facilitate generative retrieval but also offer improved solutions for user understanding, model evaluation, and user-system interactions. More importantly, the synergistic relationship among IR models, LLMs, and humans forms a new technical paradigm that is more powerful for information seeking. IR models provide real-time and relevant information, LLMs contribute internal knowledge, and humans play a central role of demanders and evaluators to the reliability of information services. Nevertheless, significant challenges exist, including computational costs, credibility concerns, domain-specific limitations, and ethical considerations. To thoroughly discuss the transformative impact of LLMs on IR research, the Chinese IR community conducted a strategic workshop in April 2023, yielding valuable insights. This paper provides a summary of the workshop’s outcomes, including the rethinking of IR’s core values, the mutual enhancement of LLMs and IR, the proposal of a novel IR technical paradigm, and open challenges.|信息检索搜索(IR)的研究领域已经发生了显著的变化，超越了传统的搜索，以满足不同的用户信息需求。最近，大语言模型(LLM)在文本理解、生成和知识推理方面展示了非凡的能力，为 IR 研究开辟了令人兴奋的途径。LLM 不仅促进了生成检索，而且为用户理解、模型评估和用户系统交互提供了改进的解决方案。更重要的是，IR 模型、 LLM 和人类之间的协同关系形成了一种新的技术范式，这种范式在信息搜索方面更加强大。IR 模型提供实时和相关的信息，LLM 提供内部知识，而人在信息服务的可靠性中扮演着需求者和评估者的中心角色。尽管如此，仍然存在重大的挑战，包括计算成本、可信度问题、特定领域的局限性和伦理考虑。为了深入讨论 LLM 对国际关系研究的变革性影响，中国国际关系界于2023年4月举办了一次战略研讨会，提出了宝贵的见解。本文提供了研讨会成果的总结，包括重新思考 IR 的核心价值，LLM 和 IR 的相互增强，一个新的 IR 技术范式的提议，以及开放的挑战。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Information+Retrieval+Meets+Large+Language+Models)|0|
|[Heterogeneous Knowledge Grounding for Medical Question Answering with Retrieval Augmented Large Language Model](https://doi.org/10.1145/3589335.3651941)|Wenting Zhao, Zhongfen Deng, Shweta Yadav, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Heterogeneous+Knowledge+Grounding+for+Medical+Question+Answering+with+Retrieval+Augmented+Large+Language+Model)|0|
|[Weakly Supervised Video Moment Retrieval via Location-irrelevant Proposal Learning](https://doi.org/10.1145/3589335.3651942)|Wei Ji, Ruiqi Shi, Yinwei Wei, Shanshan Zhao, Roger Zimmermann||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Weakly+Supervised+Video+Moment+Retrieval+via+Location-irrelevant+Proposal+Learning)|0|
|[One-step Reach: LLM-based Keyword Generation for Sponsored Search Advertising](https://doi.org/10.1145/3589335.3651943)|Yang Wang, Zheyi Sha, Kunhai Lin, Chaobing Feng, Kunhong Zhu, Lipeng Wang, Xuewu Jiao, Fei Huang, Chao Ye, Dengwu He, Zhi Guo, Shuanglong Li, Lin Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=One-step+Reach:+LLM-based+Keyword+Generation+for+Sponsored+Search+Advertising)|0|
|[A Case Study of Enhancing Sparse Retrieval using LLMs](https://doi.org/10.1145/3589335.3651945)|Michael Antonios Kruse Ayoub, Zhan Su, Qiuchi Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Case+Study+of+Enhancing+Sparse+Retrieval+using+LLMs)|0|
|[Bi-CAT: Improving Robustness of LLM-based Text Rankers to Conditional Distribution Shifts](https://doi.org/10.1145/3589335.3651947)|Sriram Srinivasan, Stephen Sheng, Rishabh Deshmukh, Chen Luo, Yesh Dattatreya, Subhajit Sanyal, S. V. N. Vishwanathan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bi-CAT:+Improving+Robustness+of+LLM-based+Text+Rankers+to+Conditional+Distribution+Shifts)|0|
|[Deep Learning for Hate Speech Detection: A Personality-based Approach](https://doi.org/10.1145/3589335.3652502)|Kyuhan Lee, Sudha Ram||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deep+Learning+for+Hate+Speech+Detection:+A+Personality-based+Approach)|0|
|[Requirements and Challenges for Query Execution across Decentralized Environments](https://doi.org/10.1145/3589335.3652523)|Ruben Taelman||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Requirements+and+Challenges+for+Query+Execution+across+Decentralized+Environments)|0|
|[Diffusion Recommendation with Implicit Sequence Influence](https://doi.org/10.1145/3589335.3651951)|Yong Niu, Xing Xing, Zhichun Jia, Ruidi Liu, Mindong Xin, Jianfu Cui||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Diffusion+Recommendation+with+Implicit+Sequence+Influence)|0|
|[Multimodal Conditioned Diffusion Model for Recommendation](https://doi.org/10.1145/3589335.3651956)|Haokai Ma, Yimeng Yang, Lei Meng, Ruobing Xie, Xiangxu Meng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multimodal+Conditioned+Diffusion+Model+for+Recommendation)|0|
|[Universal Knowledge Graph Embeddings](https://doi.org/10.1145/3589335.3651978)|N'Dah Jean Kouagou, Caglar Demir, Hamada M. Zahera, Adrian Wilke, Stefan Heindorf, Jiayi Li, AxelCyrille Ngonga Ngomo||A variety of knowledge graph embedding approaches have been developed. Most of them obtain embeddings by learning the structure of the knowledge graph within a link prediction setting. As a result, the embeddings reflect only the semantics of a single knowledge graph, and embeddings for different knowledge graphs are not aligned, e.g., they cannot be used to find similar entities across knowledge graphs via nearest neighbor search. However, knowledge graph embedding applications such as entity disambiguation require a more global representation, i.e., a representation that is valid across multiple sources. We propose to learn universal knowledge graph embeddings from large-scale interlinked knowledge sources. To this end, we fuse large knowledge graphs based on the owl:sameAs relation such that every entity is represented by a unique identity. We instantiate our idea by computing universal embeddings based on DBpedia and Wikidata yielding embeddings for about 180 million entities, 15 thousand relations, and 1.2 billion triples. Moreover, we develop a convenient API to provide embeddings as a service. Experiments on link prediction show that universal knowledge graph embeddings encode better semantics compared to embeddings computed on a single knowledge graph. For reproducibility purposes, we provide our source code and datasets open access at https://github.com/dice-group/Universal_Embeddings|发展了各种知识图嵌入方法。它们中的大多数通过学习链接预测设置中的知识图的结构来获得嵌入。因此，嵌入只能反映单个知识图的语义，不同知识图的嵌入是不一致的，例如，它们不能通过最近邻搜索在知识图中找到相似的实体。然而，知识图嵌入应用程序(如实体消歧)需要一个更全局的表示，即一个跨多个源有效的表示。我们提出了从大规模相互关联的知识源中学习通用知识图嵌入。为此，我们融合了基于猫头鹰的大型知识图: 相同的关系，使每个实体都有一个独特的身份。我们通过基于 DBpedia 和 Wikidata 的通用嵌入计算实例化了我们的想法，产生了大约1.8亿个实体、1.5万个关系和12亿个三元组的嵌入。此外，我们还开发了一个方便的 API 来提供嵌入式服务。链接预测实验表明，通用知识图的嵌入编码比单一知识图的嵌入编码具有更好的语义性能。出于可重复性的目的，我们提供源代码和数据集的开放访问 https://github.com/dice-group/universal_embeddings|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Universal+Knowledge+Graph+Embeddings)|0|
|[Towards Graph Foundation Models for Personalization](https://doi.org/10.1145/3589335.3651980)|Andreas Damianou, Francesco Fabbri, Paul Gigioli, Marco De Nadai, Alice Wang, Enrico Palumbo, Mounia Lalmas||In the realm of personalization, integrating diverse information sources such as consumption signals and content-based representations is becoming increasingly critical to build state-of-the-art solutions. In this regard, two of the biggest trends in research around this subject are Graph Neural Networks (GNNs) and Foundation Models (FMs). While GNNs emerged as a popular solution in industry for powering personalization at scale, FMs have only recently caught attention for their promising performance in personalization tasks like ranking and retrieval. In this paper, we present a graph-based foundation modeling approach tailored to personalization. Central to this approach is a Heterogeneous GNN (HGNN) designed to capture multi-hop content and consumption relationships across a range of recommendable item types. To ensure the generality required from a Foundation Model, we employ a Large Language Model (LLM) text-based featurization of nodes that accommodates all item types, and construct the graph using co-interaction signals, which inherently transcend content specificity. To facilitate practical generalization, we further couple the HGNN with an adaptation mechanism based on a two-tower (2T) architecture, which also operates agnostically to content type. This multi-stage approach ensures high scalability; while the HGNN produces general purpose embeddings, the 2T component models in a continuous space the sheer size of user-item interaction data. Our comprehensive approach has been rigorously tested and proven effective in delivering recommendations across a diverse array of products within a real-world, industrial audio streaming platform.|在个性化领域，集成消费信号和基于内容的表示等多种信息源对于构建最先进的解决方案正变得越来越重要。在这方面，围绕这个主题的两个最大的研究趋势是图形神经网络(GNN)和基础模型(FM)。虽然 GNN 作为一种大规模个性化的解决方案出现在行业中，但是 FM 只是在最近才因其在个性化任务(如排名和检索)中的良好表现而引起人们的注意。在本文中，我们提出了一种基于图的基础建模方法，以适应个性化。这种方法的核心是异构 GNN (HGNN) ，它设计用于捕获跨一系列可推荐的项目类型的多跳内容和消费关系。为了确保基础模型所需的通用性，我们采用了基于大语言模型(LLM)的节点文本特征化，以适应所有项目类型，并使用共同交互信号构建图，这本质上超越了内容特异性。为了便于实际推广，我们进一步将 HGNN 与一个基于双塔(2T)架构的适应机制耦合，该架构也对内容类型不可知地运行。这种多阶段的方法确保了高度的可伸缩性; 当 HGNN 产生通用的嵌入时，2T 组件模型在一个连续的空间中，大量的用户项交互数据。我们的综合方法已经经过严格的测试，并被证明是有效的，可以在一个真实世界的工业音频流媒体平台上提供多种产品的建议。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Graph+Foundation+Models+for+Personalization)|0|
|[AI for Materials Innovation: Self-Improving Photosensitizer Discovery System via Bayesian Search with First-Principles Simulation](https://doi.org/10.1145/3589334.3649115)|Bin Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AI+for+Materials+Innovation:+Self-Improving+Photosensitizer+Discovery+System+via+Bayesian+Search+with+First-Principles+Simulation)|0|
|[Tight Competitive and Variance Analyses of Matching Policies in Gig Platforms](https://doi.org/10.1145/3589334.3645335)|Pan Xu||In this paper, we propose an online-matching-based model to tackle the two fundamental issues, matching and pricing, existing in a wide range of real-world gig platforms, including ride-hailing (matching riders and drivers), crowdsourcing markets (pairing workers and tasks), and online recommendations (offering items to customers). Our model assumes the arriving distributions of dynamic agents (e.g., riders, workers, and buyers) are accessible in advance, and they can change over time, which is referred to as Known Heterogeneous Distributions (KHD). In this paper, we initiate variance analysis for online matching algorithms under KHD. Unlike the popular competitive-ratio (CR) metric, the variance of online algorithms' performance is rarely studied due to inherent technical challenges, though it is well linked to robustness. We focus on two natural parameterized sampling policies, denoted by 𝖠𝖳𝖳(γ) and 𝖲𝖠𝖬𝖯(γ), which appear as foundational bedrock in online algorithm design. We offer rigorous competitive ratio (CR) and variance analyses for both policies. Specifically, we show that 𝖠𝖳𝖳(γ) with γ∈ [0,1/2] achieves a CR of γ and a variance of γ· (1-γ) · B on the total number of matches with B being the total matching capacity. In contrast, 𝖲𝖠𝖬𝖯(γ) with γ∈ [0,1] accomplishes a CR of γ (1-γ) and a variance of γ̅ (1-γ̅)· B with γ̅=min(γ,1/2). All CR and variance analyses are tight and unconditional of any benchmark. As a byproduct, we prove that 𝖠𝖳𝖳(γ=1/2) achieves an optimal CR of 1/2.|在本文中，我们提出了一个基于在线匹配的模型来解决两个基本问题，匹配和定价，存在于广泛的现实世界的零工平台，包括叫车(匹配乘客和司机) ，众包市场(配对工人和任务)和在线推荐(提供项目给客户)。我们的模型假设动态代理人(如乘客、工人和购买者)的到达分布可以提前获得，并且它们可以随时间变化，这被称为已知的异质分布(KHD)。本文对 KHD 下的在线匹配算法进行了方差分析。与流行的竞争比率(CR)度量不同，在线算法的性能方差很少被研究，由于固有的技术挑战，虽然它很好地与健壮性联系在一起。本文重点研究了在线算法设计中的两个自然参数化抽样策略，即 ATT (γ)和 SAMP (γ) ，它们是在线算法设计的基础。我们提供了严格的竞争比率(CR)和方差分析的两个政策。具体地说，我们证明了当总匹配次数为 B 时，具有 γ ∈[0,1/2]的 ATT (γ)达到 γ 的 CR 和 γ · (1-γ) · B 的方差。相比之下，具有 γ ∈[0,1]的 SAMP (γ)实现了 γ (1-γ)的 CR 和 γ (1-γ) · B 与 γ = min (γ，1/2)的方差。所有 CR 和方差分析对任何基准都是严格和无条件的。作为副产品，我们证明了 ATT (γ = 1/2)达到了1/2的最优 CR。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tight+Competitive+and+Variance+Analyses+of+Matching+Policies+in+Gig+Platforms)|0|
|[Ad vs Organic: Revisiting Incentive Compatible Mechanism Design in E-commerce Platforms](https://doi.org/10.1145/3589334.3645638)|Ningyuan Li, Yunxuan Ma, Yang Zhao, Qian Wang, Zhilin Zhang, Chuan Yu, Jian Xu, Bo Zheng, Xiaotie Deng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ad+vs+Organic:+Revisiting+Incentive+Compatible+Mechanism+Design+in+E-commerce+Platforms)|0|
|[Towards Expansive and Adaptive Hard Negative Mining: Graph Contrastive Learning via Subspace Preserving](https://doi.org/10.1145/3589334.3645327)|Zhezheng Hao, Haonan Xin, Long Wei, Liaoyuan Tang, Rong Wang, Feiping Nie||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Expansive+and+Adaptive+Hard+Negative+Mining:+Graph+Contrastive+Learning+via+Subspace+Preserving)|0|
|[Hierarchical Position Embedding of Graphs with Landmarks and Clustering for Link Prediction](https://doi.org/10.1145/3589334.3645372)|Minsang Kim, Seung Baek||Learning positional information of nodes in a graph is important for link prediction tasks. We propose a representation of positional information using representative nodes called landmarks. A small number of nodes with high degree centrality are selected as landmarks, which serve as reference points for the nodes' positions. We justify this selection strategy for well-known random graph models and derive closed-form bounds on the average path lengths involving landmarks. In a model for power-law graphs, we prove that landmarks provide asymptotically exact information on inter-node distances. We apply theoretical insights to practical networks and propose Hierarchical Position embedding with Landmarks and Clustering (HPLC). HPLC combines landmark selection and graph clustering, where the graph is partitioned into densely connected clusters in which nodes with the highest degree are selected as landmarks. HPLC leverages the positional information of nodes based on landmarks at various levels of hierarchy such as nodes' distances to landmarks, inter-landmark distances and hierarchical grouping of clusters. Experiments show that HPLC achieves state-of-the-art performances of link prediction on various datasets in terms of HIT@K, MRR, and AUC. The code is available at <https://github.com/kmswin1/HPLC>.|学习图中节点的位置信息是链路预测任务的重要内容。我们提出了一种位置信息的表示使用代表性的节点称为地标。选取少量高度集中的节点作为标志点，作为节点位置的参考点。对于已知的随机图模型，我们证明了这种选择策略的合理性，并推导出了包含地标的平均路径长度的闭合界。在幂律图模型中，我们证明了路标提供节点间距离的渐近精确信息。将理论知识应用于实际网络，提出了基于地标和聚类(HPLC)的层次位置嵌入算法。高效液相色谱将地标选择和图聚类相结合，将图划分为密集连通的聚类，其中选择程度最高的节点作为地标。高效液相色谱利用节点的位置信息的基础上，在不同的层次结构，如节点的距离地标，地标之间的距离和等级分组的集群。实验结果表明，高效液相色谱在 HIT@K、 MRR 和 AUC 方面实现了对不同数据集的链接预测。代码可在 <  https://github.com/kmswin1/hplc 下载。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Position+Embedding+of+Graphs+with+Landmarks+and+Clustering+for+Link+Prediction)|0|
|[Collaborative Metapath Enhanced Corporate Default Risk Assessment on Heterogeneous Graph](https://doi.org/10.1145/3589334.3645402)|Zheng Zhang, Yingsheng Ji, Jiachen Shen, Yushu Chen, Xi Zhang, Guangwen Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Collaborative+Metapath+Enhanced+Corporate+Default+Risk+Assessment+on+Heterogeneous+Graph)|0|
|[Graph Contrastive Learning with Kernel Dependence Maximization for Social Recommendation](https://doi.org/10.1145/3589334.3645412)|Xuelian Ni, Fei Xiong, Yu Zheng, Liang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Contrastive+Learning+with+Kernel+Dependence+Maximization+for+Social+Recommendation)|0|
|[MultiGPrompt for Multi-Task Pre-Training and Prompting on Graphs](https://doi.org/10.1145/3589334.3645423)|Xingtong Yu, Chang Zhou, Yuan Fang, Xinming Zhang||Graphs can inherently model interconnected objects on the Web, thereby facilitating a series of Web applications, such as web analyzing and content recommendation. Recently, Graph Neural Networks (GNNs) have emerged as a mainstream technique for graph representation learning. However, their efficacy within an end-to-end supervised framework is significantly tied to the availabilityof task-specific labels. To mitigate labeling costs and enhance robustness in few-shot settings, pre-training on self-supervised tasks has emerged as a promising method, while prompting has been proposed to further narrow the objective gap between pretext and downstream tasks. Although there has been some initial exploration of prompt-based learning on graphs, they primarily leverage a single pretext task, resulting in a limited subset of general knowledge that could be learned from the pre-training data. Hence, in this paper, we propose MultiGPrompt, a novel multi-task pre-training and prompting framework to exploit multiple pretext tasks for more comprehensive pre-trained knowledge. First, in pre-training, we design a set of pretext tokens to synergize multiple pretext tasks. Second, we propose a dual-prompt mechanism consisting of composed and open prompts to leverage task-specific and global pre-training knowledge, to guide downstream tasks in few-shot settings. Finally, we conduct extensive experiments on six public datasets to evaluate and analyze MultiGPrompt.|图形可以内在地对 Web 上相互连接的对象建模，从而方便了一系列 Web 应用程序，例如 Web 分析和内容推荐。近年来，图神经网络已经成为图表示学习的主流技术。然而，它们在端到端监督框架内的有效性与特定任务标签的可用性有着显著的联系。为了降低标记成本和增强在少镜头环境下的鲁棒性，自我监督任务的预训练已经成为一种有前途的方法，同时提出了提示来进一步缩小借口和下游任务之间的目标差距。虽然已经有一些基于图表的及时学习的初步探索，他们主要利用一个单一的借口任务，导致有限的一般知识子集，可以从培训前的数据学习。因此，本文提出了一种新颖的多任务预训练和激励框架 MultiGPrompt，该框架可以利用多任务来获得更全面的预训练知识。首先，在预训中，我们设计一组借口标记来协同多个借口任务。其次，我们提出了一个双提示机制，包括组成和开放的提示，以利用任务特定和全球培训前的知识，以指导下游任务在少镜头设置。最后，我们在六个公共数据集上进行了广泛的实验来评估和分析 MultiGPrompt。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MultiGPrompt+for+Multi-Task+Pre-Training+and+Prompting+on+Graphs)|0|
|[SSTKG: Simple Spatio-Temporal Knowledge Graph for Intepretable and Versatile Dynamic Information Embedding](https://doi.org/10.1145/3589334.3645441)|Ruiyi Yang, Flora D. Salim, Hao Xue||Knowledge graphs (KGs) have been increasingly employed for link prediction and recommendation using real-world datasets. However, the majority of current methods rely on static data, neglecting the dynamic nature and the hidden spatio-temporal attributes of real-world scenarios. This often results in suboptimal predictions and recommendations. Although there are effective spatio-temporal inference methods, they face challenges such as scalability with large datasets and inadequate semantic understanding, which impede their performance. To address these limitations, this paper introduces a novel framework - Simple Spatio-Temporal Knowledge Graph (SSTKG), for constructing and exploring spatio-temporal KGs. To integrate spatial and temporal data into KGs, our framework exploited through a new 3-step embedding method. Output embeddings can be used for future temporal sequence prediction and spatial information recommendation, providing valuable insights for various applications such as retail sales forecasting and traffic volume prediction. Our framework offers a simple but comprehensive way to understand the underlying patterns and trends in dynamic KG, thereby enhancing the accuracy of predictions and the relevance of recommendations. This work paves the way for more effective utilization of spatio-temporal data in KGs, with potential impacts across a wide range of sectors.|知识图(KGs)越来越多地被用于利用实际数据集进行链接预测和推荐。然而，现有的方法大多依赖于静态数据，忽视了真实场景的动态性和隐藏的时空属性。这常常导致不理想的预测和建议。虽然有效的时空推理方法已经存在，但是它们面临着大数据集的可扩展性和语义理解不足等问题，这些问题阻碍了它们的性能。针对这些局限性，本文提出了一种构建和探索时空 KG 的新框架——简单时空知识图(SSTKG)。为了将空间数据和时间数据整合到 KG 中，我们的框架采用了一种新的三步嵌入方法。输出嵌入可用于未来的时间序列预测和空间信息推荐，为零售业销售预测和交通量预测等各种应用提供有价值的见解。我们的框架提供了一个简单而全面的方法来了解动态幼稚园的基本模式和趋势，从而提高预测的准确性和建议的相关性。这项工作为幼儿园更有效地利用时空数据铺平了道路，并可能对多个部门产生影响。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SSTKG:+Simple+Spatio-Temporal+Knowledge+Graph+for+Intepretable+and+Versatile+Dynamic+Information+Embedding)|0|
|[Spectral Heterogeneous Graph Convolutions via Positive Noncommutative Polynomials](https://doi.org/10.1145/3589334.3645515)|Mingguo He, Zhewei Wei, Shikun Feng, Zhengjie Huang, Weibin Li, Yu Sun, Dianhai Yu||Heterogeneous Graph Neural Networks (HGNNs) have gained significant popularity in various heterogeneous graph learning tasks. However, most existing HGNNs rely on spatial domain-based methods to aggregate information, i.e., manually selected meta-paths or some heuristic modules, lacking theoretical guarantees. Furthermore, these methods cannot learn arbitrary valid heterogeneous graph filters within the spectral domain, which have limited expressiveness. To tackle these issues, we present a positive spectral heterogeneous graph convolution via positive noncommutative polynomials. Then, using this convolution, we propose PSHGCN, a novel Positive Spectral Heterogeneous Graph Convolutional Network. PSHGCN offers a simple yet effective method for learning valid heterogeneous graph filters. Moreover, we demonstrate the rationale of PSHGCN in the graph optimization framework. We conducted an extensive experimental study to show that PSHGCN can learn diverse heterogeneous graph filters and outperform all baselines on open benchmarks. Notably, PSHGCN exhibits remarkable scalability, efficiently handling large real-world graphs comprising millions of nodes and edges. Our codes are available at https://github.com/ivam-he/PSHGCN.|异构图神经网络在各种异构图学习任务中得到了广泛的应用。然而，现有的 HGNN 大多依赖于基于空间域的方法来聚合信息，即手工选择元路径或一些启发式模块，缺乏理论保证。此外，这些方法不能在谱域内学习任意有效的异构图滤波器，表达能力有限。为了解决这些问题，我们提出了一个正谱异质图卷积通过正的非交换多项式。然后，利用这种卷积，我们提出了一种新的正谱异质图卷积网络 PSHGCN。PSHGCN 为学习有效的异构图过滤器提供了一种简单而有效的方法。此外，本文还在图优化框架中论证了 PSHGCN 算法的基本原理。我们进行了广泛的实验研究表明，PSHGCN 可以学习不同的异构图过滤器和优于所有基线的开放基准。值得注意的是，PSHGCN 具有显著的可伸缩性，能够有效地处理包含数百万个节点和边的大型真实世界图。我们的代码可以在 https://github.com/ivam-he/pshgcn 找到。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spectral+Heterogeneous+Graph+Convolutions+via+Positive+Noncommutative+Polynomials)|0|
|[Densest Subhypergraph: Negative Supermodular Functions and Strongly Localized Methods](https://doi.org/10.1145/3589334.3645624)|Yufan Huang, David F. Gleich, Nate Veldt||Dense subgraph discovery is a fundamental primitive in graph and hypergraph analysis which among other applications has been used for real-time story detection on social media and improving access to data stores of social networking systems. We present several contributions for localized densest subgraph discovery, which seeks dense subgraphs located nearby given seed sets of nodes. We first introduce a generalization of a recent anchored densest subgraph problem, extending this previous objective to hypergraphs and also adding a tunable locality parameter that controls the extent to which the output set overlaps with seed nodes. Our primary technical contribution is to prove when it is possible to obtain a strongly-local algorithm for solving this problem, meaning that the runtime depends only on the size of the input set. We provide a strongly-local algorithm that applies whenever the locality parameter is not too small, and show via counterexample why strongly-local algorithms are impossible below a certain threshold. Along the way to proving our results for localized densest subgraph discovery, we also provide several advances in solving global dense subgraph discovery objectives. This includes the first strongly polynomial time algorithm for the densest supermodular set problem and a flow-based exact algorithm for a heavy and dense subgraph discovery problem in graphs with arbitrary node weights. We demonstrate our algorithms on several web-based data analysis tasks.|密集子图发现是图和超图分析中的一个基本原理，除其他应用外，它还被用于社交媒体上的实时故事检测和改善对社交网络系统数据存储的访问。我们提出了局部密集子图发现的几个贡献，它寻找位于给定种子集附近的密集子图。我们首先引入了一个最近抛锚的最密集子图问题的推广，将这个先前的目标扩展到超图，并且添加了一个可调的局部性参数来控制输出集与种子节点重叠的程度。我们的主要技术贡献是证明何时可以获得解决这个问题的强局部算法，这意味着运行时仅取决于输入集的大小。我们提供了一个强局部算法，适用于局部参数不太小的情况，并通过反例说明为什么强局部算法不可能低于一定的阈值。在证明局部密集子图发现结果的过程中，我们还提供了解决全局密集子图发现目标的一些进展。这包括求解最稠密上模集问题的第一个强多项式时间算法和求解任意节点权图中的稠密子图发现问题的基于流的精确算法。我们在几个基于 Web 的数据分析任务中演示了我们的算法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Densest+Subhypergraph:+Negative+Supermodular+Functions+and+Strongly+Localized+Methods)|0|
|[Towards Deeper Understanding of PPR-based Embedding Approaches: A Topological Perspective](https://doi.org/10.1145/3589334.3645663)|Xingyi Zhang, Zixuan Weng, Sibo Wang||Node embedding learns low-dimensional vectors for nodes in the graph. Recent state-of-the-art embedding approaches take Personalized PageRank (PPR) as the proximity measure and factorize the PPR matrix or its adaptation to generate embeddings. However, little previous work analyzes what information is encoded by these approaches, and how the information correlates with their superb performance in downstream tasks. In this work, we first show that state-of-the-art embedding approaches that factorize a PPR-related matrix can be unified into a closed-form framework. Then, we study whether the embeddings generated by this strategy can be inverted to better recover the graph topology information than random-walk based embeddings. To achieve this, we propose two methods for recovering graph topology via PPR-based embeddings, including the analytical method and the optimization method. Extensive experimental results demonstrate that the embeddings generated by factorizing a PPR-related matrix maintain more topological information, such as common edges and community structures, than that generated by random walks, paving a new way to systematically comprehend why PPR-based node embedding approaches outperform random walk-based alternatives in various downstream tasks. To the best of our knowledge, this is the first work that focuses on the interpretability of PPR-based node embedding approaches.|节点嵌入学习图中节点的低维向量。最新的嵌入方法采用个性化 PageRank (PPR)作为邻近度量，对 PPR 矩阵或其适应性进行因子分解以生成嵌入。然而，以前的工作很少分析这些方法编码的信息，以及这些信息如何与它们在下游任务中的卓越性能相关联。在这项工作中，我们首先表明，国家的最先进的嵌入方法，分解一个 PPR 相关的矩阵可以统一成一个封闭的形式框架。然后，研究该策略生成的嵌入能否比基于随机游走的嵌入更好地恢复图的拓扑信息。为此，我们提出了两种基于 PPR 嵌入的图拓扑恢复方法，包括解析法和优化法。大量的实验结果表明，PPR 相关矩阵分解产生的嵌入比随机游走产生的嵌入保持了更多的拓扑信息，如共同边和社区结构，为系统地理解为什么 PPR 节点嵌入方法在各种下游任务中优于随机游走方法提供了新的途径。据我们所知，这是第一个重点研究基于 PPR 的节点嵌入方法的可解释性的工作。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Deeper+Understanding+of+PPR-based+Embedding+Approaches:+A+Topological+Perspective)|0|
|[Globally Interpretable Graph Learning via Distribution Matching](https://doi.org/10.1145/3589334.3645674)|Yi Nian, Yurui Chang, Wei Jin, Lu Lin||Graph neural networks (GNNs) have emerged as a powerful model to capture critical graph patterns. Instead of treating them as black boxes in an end-to-end fashion, attempts are arising to explain the model behavior. Existing works mainly focus on local interpretation to reveal the discriminative pattern for each individual instance, which however cannot directly reflect the high-level model behavior across instances. To gain global insights, we aim to answer an important question that is not yet well studied: how to provide a global interpretation for the graph learning procedure? We formulate this problem as globally interpretable graph learning, which targets on distilling high-level and human-intelligible patterns that dominate the learning procedure, such that training on this pattern can recover a similar model. As a start, we propose a novel model fidelity metric, tailored for evaluating the fidelity of the resulting model trained on interpretations. Our preliminary analysis shows that interpretative patterns generated by existing global methods fail to recover the model training procedure. Thus, we further propose our solution, Graph Distribution Matching (GDM), which synthesizes interpretive graphs by matching the distribution of the original and interpretive graphs in the GNN's feature space as its training proceeds, thus capturing the most informative patterns the model learns during training. Extensive experiments on graph classification datasets demonstrate multiple advantages of the proposed method, including high model fidelity, predictive accuracy and time efficiency, as well as the ability to reveal class-relevant structure.|图形神经网络(GNN)已经成为一种捕获关键图形模式的强大模型。不是以端到端的方式将它们视为黑盒，而是尝试解释模型行为。现有的工作主要集中在局部解释上，以揭示每个实例的区分模式，但不能直接反映跨实例的高层模型行为。为了获得全局性的见解，我们的目标是回答一个尚未得到很好研究的重要问题: 如何为图形学习过程提供一个全局性的解释？我们把这个问题表述为全局可解释的图学习，其目标是提取主导学习过程的高层次和人类可理解的模式，这样对这种模式的训练可以恢复类似的模型。作为一个开始，我们提出了一个新的模型保真度量，专为评估保真度的结果模型训练的解释。我们的初步分析表明，现有的全局方法产生的解释模式不能恢复模型训练过程。因此，我们进一步提出了我们的解决方案，图分布匹配(GDM) ，它通过在 GNN 的特征空间中匹配原始图和解释图的分布来合成解释图，从而捕获模型在训练过程中学习到的最具信息量的模式。在图形分类数据集上的大量实验表明，该方法具有模型保真度高、预测精度高、时间效率高、能够揭示类相关结构等优点。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Globally+Interpretable+Graph+Learning+via+Distribution+Matching)|0|
|[Retention Depolarization in Recommender System](https://doi.org/10.1145/3589334.3645485)|Xiaoying Zhang, Hongning Wang, Yang Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Retention+Depolarization+in+Recommender+System)|0|
|[Uncovering the Hidden Data Costs of Mobile YouTube Video Ads](https://doi.org/10.1145/3589334.3645496)|Emaan Atique, Saad Sher Alam, Harris Ahmad, Ihsan Ayyub Qazi, Zafar Ayyub Qazi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Uncovering+the+Hidden+Data+Costs+of+Mobile+YouTube+Video+Ads)|0|
|[Perceptions in Pixels: Analyzing Perceived Gender and Skin Tone in Real-world Image Search Results](https://doi.org/10.1145/3589334.3645666)|Jeffrey L. Gleason, Avijit Ghosh, Ronald E. Robertson, Christo Wilson||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Perceptions+in+Pixels:+Analyzing+Perceived+Gender+and+Skin+Tone+in+Real-world+Image+Search+Results)|0|
|[Reconciling the Accuracy-Diversity Trade-off in Recommendations](https://doi.org/10.1145/3589334.3645625)|Kenny Peng, Manish Raghavan, Emma Pierson, Jon M. Kleinberg, Nikhil Garg||In recommendation settings, there is an apparent trade-off between the goals of accuracy (to recommend items a user is most likely to want) and diversity (to recommend items representing a range of categories). As such, real-world recommender systems often explicitly incorporate diversity separately from accuracy. This approach, however, leaves a basic question unanswered: Why is there a trade-off in the first place? We show how the trade-off can be explained via a user's consumption constraints -- users typically only consume a few of the items they are recommended. In a stylized model we introduce, objectives that account for this constraint induce diverse recommendations, while objectives that do not account for this constraint induce homogeneous recommendations. This suggests that accuracy and diversity appear misaligned because standard accuracy metrics do not consider consumption constraints. Our model yields precise and interpretable characterizations of diversity in different settings, giving practical insights into the design of diverse recommendations.|在推荐设置中，在准确性目标(推荐用户最可能想要的项目)和多样性目标(推荐代表一系列类别的项目)之间存在明显的权衡。因此，现实世界中的推荐系统通常明确地将多样性与准确性分开。然而，这种方法留下了一个基本问题没有得到解答: 为什么首先要进行权衡？我们展示了如何通过用户的消费约束来解释这种权衡——用户通常只消费推荐的几个项目。在我们引入的程式化模型中，解释这种约束的目标会产生不同的建议，而不解释这种约束的目标会产生同质的建议。这表明准确性和多样性似乎不一致，因为标准的准确性指标没有考虑消费约束。我们的模型产生了不同环境下多样性的精确和可解释的特征，为不同建议的设计提供了实用的见解。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reconciling+the+Accuracy-Diversity+Trade-off+in+Recommendations)|0|
|[MileCut: A Multi-view Truncation Framework for Legal Case Retrieval](https://doi.org/10.1145/3589334.3645349)|Fuda Ye, Shuangyin Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MileCut:+A+Multi-view+Truncation+Framework+for+Legal+Case+Retrieval)|0|
|[Search-in-the-Chain: Interactively Enhancing Large Language Models with Search for Knowledge-intensive Tasks](https://doi.org/10.1145/3589334.3645363)|Shicheng Xu, Liang Pang, Huawei Shen, Xueqi Cheng, TatSeng Chua||Making the content generated by Large Language Model (LLM), accurate, credible and traceable is crucial, especially in complex knowledge-intensive tasks that require multi-step reasoning and each step needs knowledge to solve. Retrieval-augmented generation is good potential to solve this problem. However, where and how to introduce Information Retrieval (IR) to LLM is a big challenge. Previous work has the problems that wrong knowledge retrieved by IR misleads the LLM and interaction between IR and LLM breaks the reasoning chain of LLM. This paper proposes a novel framework named Search-in-the-Chain (SearChain) for the interaction between LLM and IR to solve the challenges. First, LLM generates the reasoning chain named Chain-of-Query (CoQ) where each node consists of an IR-oriented query-answer pair. Second, IR verifies the answer of each node of CoQ. It corrects the answer that is not consistent with the retrieved information when IR gives high confidence, which improves the credibility. Third, LLM can indicate its missing knowledge in CoQ and rely on IR to provide this knowledge to LLM. These operations improve the accuracy in terms of reasoning and knowledge. Finally, SearChain generates the reasoning process and marks references to supporting documents for each reasoning step, which improves traceability. Interaction with IR in SearChain forms a novel reasoning path based on a tree, which enables LLM to dynamically modify the direction of reasoning. Experiments show that SearChain outperforms state-of-the-art baselines on complex knowledge-intensive tasks including multi-hop Q&A, slot filling, fact checking, and long-form Q&A.|使大语言模型(LLM)生成的内容准确、可信、可追溯是关键，特别是在需要多步推理、每一步都需要知识求解的复杂知识密集型任务中。提取增强生成技术是解决这一问题的有力工具。然而，在何处以及如何向 LLM 引入信息检索是一个巨大的挑战。以往的研究存在的问题是，由 IR 检索出的错误知识误导了 LLM，而且 IR 与 LLM 之间的相互作用破坏了 LLM 的推理链。本文提出了一个新的框架，称为搜索在链(搜索链)之间的交互 LLM 和信息检索，以解决这一挑战。首先，LLM 生成名为查询链(Chain-of-Query，CoQ)的推理链，其中每个节点由一个面向 IR 的查询-应答对组成。其次，IR 验证 CoQ 的每个节点的答案。当信息检索的可信度较高时，它可以纠正与检索到的信息不一致的答案，从而提高了信息的可信度。第三，LLM 可以在 CoQ 中表示其缺失的知识，并依靠 IR 向 LLM 提供这些知识。这些操作提高了推理和知识的准确性。最后，SearChain 生成推理过程，并在每个推理步骤中标记对支持文档的引用，从而提高了可追溯性。在 SearChain 中，与 IR 的交互形成了一种新的基于树的推理路径，使 LLM 能够动态地修改推理的方向。实验表明，SearChain 在复杂的知识密集型任务(包括多跳问答、插槽填充、事实检查和长形式问答)中的表现优于最先进的基线。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Search-in-the-Chain:+Interactively+Enhancing+Large+Language+Models+with+Search+for+Knowledge-intensive+Tasks)|0|
|[Scalable and Effective Generative Information Retrieval](https://doi.org/10.1145/3589334.3645477)|Hansi Zeng, Chen Luo, Bowen Jin, Sheikh Muhammad Sarwar, Tianxin Wei, Hamed Zamani||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+and+Effective+Generative+Information+Retrieval)|0|
|[Metacognitive Retrieval-Augmented Large Language Models](https://doi.org/10.1145/3589334.3645481)|Yujia Zhou, Zheng Liu, Jiajie Jin, JianYun Nie, Zhicheng Dou||Retrieval-augmented generation have become central in natural language processing due to their efficacy in generating factual content. While traditional methods employ single-time retrieval, more recent approaches have shifted towards multi-time retrieval for multi-hop reasoning tasks. However, these strategies are bound by predefined reasoning steps, potentially leading to inaccuracies in response generation. This paper introduces MetaRAG, an approach that combines the retrieval-augmented generation process with metacognition. Drawing from cognitive psychology, metacognition allows an entity to self-reflect and critically evaluate its cognitive processes. By integrating this, MetaRAG enables the model to monitor, evaluate, and plan its response strategies, enhancing its introspective reasoning abilities. Through a three-step metacognitive regulation pipeline, the model can identify inadequacies in initial cognitive responses and fixes them. Empirical evaluations show that MetaRAG significantly outperforms existing methods.|提取增强生成由于其生成事实内容的功效，已成为自然语言处理的核心。传统的检索方法采用单次检索，而最近的检索方法已经转向多跳推理任务的多次检索。然而，这些策略受到预先定义的推理步骤的约束，可能导致响应生成的不准确性。本文介绍了一种将检索增强生成过程与元认知相结合的方法 MetaRAG。元认知从认知心理学的角度出发，允许一个实体对其认知过程进行自我反思和批判性评价。通过集成这一点，MetaRAG 使模型能够监视、评估和规划其响应策略，增强其内省推理能力。通过三步元认知调节管道，该模型可以识别初始认知反应中的不足并加以修正。经验性评估表明，MetaRAG 的性能明显优于现有方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Metacognitive+Retrieval-Augmented+Large+Language+Models)|0|
|[Improving Retrieval in Theme-specific Applications using a Corpus Topical Taxonomy](https://doi.org/10.1145/3589334.3645512)|SeongKu Kang, Shivam Agarwal, Bowen Jin, Dongha Lee, Hwanjo Yu, Jiawei Han||Document retrieval has greatly benefited from the advancements of large-scale pre-trained language models (PLMs). However, their effectiveness is often limited in theme-specific applications for specialized areas or industries, due to unique terminologies, incomplete contexts of user queries, and specialized search intents. To capture the theme-specific information and improve retrieval, we propose to use a corpus topical taxonomy, which outlines the latent topic structure of the corpus while reflecting user-interested aspects. We introduce ToTER (Topical Taxonomy Enhanced Retrieval) framework, which identifies the central topics of queries and documents with the guidance of the taxonomy, and exploits their topical relatedness to supplement missing contexts. As a plug-and-play framework, ToTER can be flexibly employed to enhance various PLM-based retrievers. Through extensive quantitative, ablative, and exploratory experiments on two real-world datasets, we ascertain the benefits of using topical taxonomy for retrieval in theme-specific applications and demonstrate the effectiveness of ToTER.|大规模预先培训语言模型(plm)的发展极大地促进了文献检索的发展。然而，由于独特的术语、用户查询的不完整上下文以及专门的搜索意图，它们在专门领域或行业的特定主题应用程序中的有效性往往受到限制。为了获取特定主题的信息，提高检索效率，我们提出了一种语料库主题分类法，它在反映用户感兴趣的方面的同时，勾勒出语料库的潜在主题结构。本文介绍了 ToTER (Topical Taxonomy Advanced Retrieval，主题分类增强检索)框架，该框架在分类学的指导下识别查询和文档的中心主题，并利用它们的主题相关性来补充缺失的上下文。作为一个即插即用的框架，ToTER 可以灵活地用于增强各种基于 PLM 的检索器。通过对两个实际数据集进行广泛的定量、消融和探索性实验，我们确定了在特定主题应用中使用主题分类法进行检索的好处，并证明了 ToTER 的有效性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Retrieval+in+Theme-specific+Applications+using+a+Corpus+Topical+Taxonomy)|0|
|[(In)Security of File Uploads in Node.js](https://doi.org/10.1145/3589334.3645342)|Harun Oz, Abbas Acar, Ahmet Aris, Güliz Seray Tuncay, Amin Kharraz, A. Selcuk Uluagac||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=(In)Security+of+File+Uploads+in+Node.js)|0|
|[IME: Integrating Multi-curvature Shared and Specific Embedding for Temporal Knowledge Graph Completion](https://doi.org/10.1145/3589334.3645361)|Jiapu Wang, Zheng Cui, Boyue Wang, Shirui Pan, Junbin Gao, Baocai Yin, Wen Gao||Temporal Knowledge Graphs (TKGs) incorporate a temporal dimension, allowing for a precise capture of the evolution of knowledge and reflecting the dynamic nature of the real world. Typically, TKGs contain complex geometric structures, with various geometric structures interwoven. However, existing Temporal Knowledge Graph Completion (TKGC) methods either model TKGs in a single space or neglect the heterogeneity of different curvature spaces, thus constraining their capacity to capture these intricate geometric structures. In this paper, we propose a novel Integrating Multi-curvature shared and specific Embedding (IME) model for TKGC tasks. Concretely, IME models TKGs into multi-curvature spaces, including hyperspherical, hyperbolic, and Euclidean spaces. Subsequently, IME incorporates two key properties, namely space-shared property and space-specific property. The space-shared property facilitates the learning of commonalities across different curvature spaces and alleviates the spatial gap caused by the heterogeneous nature of multi-curvature spaces, while the space-specific property captures characteristic features. Meanwhile, IME proposes an Adjustable Multi-curvature Pooling (AMP) approach to effectively retain important information. Furthermore, IME innovatively designs similarity, difference, and structure loss functions to attain the stated objective. Experimental results clearly demonstrate the superior performance of IME over existing state-of-the-art TKGC models.|时间知识图(TKGs)包含了一个时间维度，允许精确地捕捉知识的演变，并反映真实世界的动态性质。通常，TKG 包含复杂的几何结构，各种几何结构交织在一起。然而，现有的时态知识图完成(TKGC)方法要么在单个空间中对 TKG 进行建模，要么忽略了不同曲率空间的异质性，从而限制了它们捕获这些复杂几何结构的能力。针对 TKGC 任务，提出了一种新的集成多曲率共享和特定嵌入(IME)模型。具体而言，IME 将 TKG 模型分解为多曲率空间，包括超球面空间、双曲空间和欧氏空间。随后，IME 合并了两个关键属性，即空间共享属性和空间特定属性。空间共享属性有利于不同曲率空间之间的共性学习，缓解了多曲率空间异质性所造成的空间差距，而空间特定属性则捕捉特征。同时，IME 提出了一种可调多曲率池(AMP)方法来有效地保留重要信息。此外，IME 创新地设计了相似性、差异性和结构损失函数来达到既定的目标。实验结果清楚地表明，IME 的性能优于现有的最先进的 TKGC 模型。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=IME:+Integrating+Multi-curvature+Shared+and+Specific+Embedding+for+Temporal+Knowledge+Graph+Completion)|0|
|[Poisoning Attack on Federated Knowledge Graph Embedding](https://doi.org/10.1145/3589334.3645422)|Enyuan Zhou, Song Guo, Zhixiu Ma, Zicong Hong, Tao Guo, Peiran Dong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Poisoning+Attack+on+Federated+Knowledge+Graph+Embedding)|0|
|[ReliK: A Reliability Measure for Knowledge Graph Embeddings](https://doi.org/10.1145/3589334.3645430)|Maximilian K. Egger, Wenyue Ma, Davide Mottin, Panagiotis Karras, Ilaria Bordino, Francesco Gullo, Aris Anagnostopoulos||Can we assess a priori how well a knowledge graph embedding will perform on a specific downstream task and in a specific part of the knowledge graph? Knowledge graph embeddings (KGEs) represent entities (e.g., "da Vinci," "Mona Lisa") and relationships (e.g., "painted") of a knowledge graph (KG) as vectors. KGEs are generated by optimizing an embedding score, which assesses whether a triple (e.g., "da Vinci," "painted," "Mona Lisa") exists in the graph. KGEs have been proven effective in a variety of web-related downstream tasks, including, for instance, predicting relationships among entities. However, the problem of anticipating the performance of a given KGE in a certain downstream task and locally to a specific individual triple, has not been tackled so far. In this paper, we fill this gap with ReliK, a Reliability measure for KGEs. ReliK relies solely on KGE embedding scores, is task- and KGE-agnostic, and requires no further KGE training. As such, it is particularly appealing for semantic web applications which call for testing multiple KGE methods on various parts of the KG and on each individual downstream task. Through extensive experiments, we attest that ReliK correlates well with both common downstream tasks, such as tail or relation prediction and triple classification, as well as advanced downstream tasks, such as rule mining and question answering, while preserving locality.|我们能否先验地评估知识图表嵌入在特定的下游任务和知识图表的特定部分中的表现如何？知识图嵌入(KGEs)表示知识图的实体(如“达芬奇”、“蒙娜丽莎”)和关系(如“画”)作为向量。KGE 是通过优化嵌入分数生成的，嵌入分数评估图中是否存在三元组(例如，“达芬奇”、“绘画”、“蒙娜丽莎”)。KGEs 已被证明在各种与网络相关的下游任务中是有效的，包括，例如，预测实体之间的关系。然而，预测某一知识专长在某一下游任务中的表现以及局部地区对某一特定个体三重性的表现这一问题迄今尚未得到解决。在本文中，我们填补这一空白与 ReliK，一个可靠性测度的 KGE。ReliK 完全依赖于 KGE 嵌入分数，是任务和 KGE 不可知的，不需要进一步的 KGE 培训。因此，它对语义 Web 应用程序特别有吸引力，这些应用程序需要在 KG 的各个部分和每个单独的下游任务上测试多个 KGE 方法。通过大量的实验，我们证明了 ReliK 与常见的下游任务(如尾部或关系预测和三重分类)以及高级的下游任务(如规则挖掘和问题回答)都有很好的相关性，同时保留了局部性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ReliK:+A+Reliability+Measure+for+Knowledge+Graph+Embeddings)|0|
|[A Method for Assessing Inference Patterns Captured by Embedding Models in Knowledge Graphs](https://doi.org/10.1145/3589334.3645505)|Narayanan Asuri Krishnan, Carlos R. Rivero||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Method+for+Assessing+Inference+Patterns+Captured+by+Embedding+Models+in+Knowledge+Graphs)|0|
|[Fact Embedding through Diffusion Model for Knowledge Graph Completion](https://doi.org/10.1145/3589334.3645451)|Xiao Long, Liansheng Zhuang, Aodi Li, Houqiang Li, Shafei Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fact+Embedding+through+Diffusion+Model+for+Knowledge+Graph+Completion)|0|
|[HaSa: Hardness and Structure-Aware Contrastive Knowledge Graph Embedding](https://doi.org/10.1145/3589334.3645564)|Honggen Zhang, June Zhang, Igor Molybog||We consider a contrastive learning approach to knowledge graph embedding (KGE) via InfoNCE. For KGE, efficient learning relies on augmenting the training data with negative triples. However, most KGE works overlook the bias from generating the negative triples-false negative triples (factual triples missing from the knowledge graph). We argue that the generation of high-quality (i.e., hard) negative triples might lead to an increase in false negative triples. To mitigate the impact of false negative triples during the generation of hard negative triples, we propose the Hardness and Structure-aware (\textbf{HaSa}) contrastive KGE method, which alleviates the effect of false negative triples while generating the hard negative triples. Experiments show that HaSa improves the performance of InfoNCE-based KGE approaches and achieves state-of-the-art results in several metrics for WN18RR datasets and competitive results for FB15k-237 datasets compared to both classic and pre-trained LM-based KGE methods.|提出了一种基于 InfoNCE 的知识图嵌入对比学习方法。对于 KGE，有效的学习依赖于用负三元组增加训练数据。然而，大多数 KGE 作品忽略了产生负三元组的偏差-假负三元组(知识图中缺失的事实三元组)。我们认为产生高质量(例如，硬)负三元组可能导致增加假负三元组。为了减轻硬负三元组生成过程中假负三元组的影响，提出了硬度和结构感知(textbf { HaSa })对比 KGE 方法，该方法在生成硬负三元组的同时，减轻了假负三元组的影响。实验表明，与经典的和预先训练的基于 LM 的 KGE 方法相比，HaSa 提高了基于 InfoNCE 的 KGE 方法的性能，在 WN18RR 数据集的几个度量指标和 FB15k-237数据集的竞争结果方面取得了最先进的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HaSa:+Hardness+and+Structure-Aware+Contrastive+Knowledge+Graph+Embedding)|0|
|[Bridging the Space Gap: Unifying Geometry Knowledge Graph Embedding with Optimal Transport](https://doi.org/10.1145/3589334.3645565)|Yuhan Liu, Zelin Cao, Xing Gao, Ji Zhang, Rui Yan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bridging+the+Space+Gap:+Unifying+Geometry+Knowledge+Graph+Embedding+with+Optimal+Transport)|0|
|[Query Optimization for Ontology-Mediated Query Answering](https://doi.org/10.1145/3589334.3645567)|Wafaa El Husseini, Cheikh Brahim El Vaigh, François Goasdoué, Hélène Jaudoin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Query+Optimization+for+Ontology-Mediated+Query+Answering)|0|
|[Query2GMM: Learning Representation with Gaussian Mixture Model for Reasoning over Knowledge Graphs](https://doi.org/10.1145/3589334.3645569)|Yuhan Wu, Yuanyuan Xu, Wenjie Zhang, Xiwei Xu, Ying Zhang||Logical query answering over Knowledge Graphs (KGs) is a fundamental yet complex task. A promising approach to achieve this is to embed queries and entities jointly into the same embedding space. Research along this line suggests that using multi-modal distribution to represent answer entities is more suitable than uni-modal distribution, as a single query may contain multiple disjoint answer subsets due to the compositional nature of multi-hop queries and the varying latent semantics of relations. However, existing methods based on multi-modal distribution roughly represent each subset without capturing its accurate cardinality, or even degenerate into uni-modal distribution learning during the reasoning process due to the lack of an effective similarity measure. To better model queries with diversified answers, we propose Query2GMM for answering logical queries over knowledge graphs. In Query2GMM, we present the GMM embedding to represent each query using a univariate Gaussian Mixture Model (GMM). Each subset of a query is encoded by its cardinality, semantic center and dispersion degree, allowing for precise representation of multiple subsets. Then we design specific neural networks for each operator to handle the inherent complexity that comes with multi-modal distribution while alleviating the cascading errors. Last, we design a new similarity measure to assess the relationships between an entity and a query's multi-answer subsets, enabling effective multi-modal distribution learning for reasoning. Comprehensive experimental results show that Query2GMM outperforms the best competitor by an absolute average of 6.35%.|基于知识图的逻辑查询回答是一项基本而又复杂的任务。实现这一点的一个有希望的方法是将查询和实体联合嵌入到相同的嵌入空间中。沿着这条线的研究表明，使用多模态分布来表示答案实体比单模态分布更合适，因为由于多跳查询的组合性质和关系的不同潜在语义，单个查询可能包含多个不相交的答案子集。然而，现有的基于多模态分布的方法在推理过程中，由于缺乏有效的相似性度量，往往不能准确地表示每个子集，甚至退化为单模态分布学习。为了更好地建立具有多样化答案的查询模型，我们提出了基于知识图的查询模型 Query2GMM。在 Query2GMM 中，我们使用单变量高斯混合模型(GMM)来表示每个查询。查询的每个子集由其基数、语义中心和分散度编码，允许对多个子集进行精确表示。然后针对每个算子设计特定的神经网络，以处理多模态分布所带来的固有复杂性，同时减小级联误差。最后，我们设计了一个新的相似性度量来评估一个实体和查询的多答案子集之间的关系，使有效的多模态分布学习推理。综合实验结果表明，Query2GMM 的性能绝对平均优于最佳竞争对手6.35% 。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Query2GMM:+Learning+Representation+with+Gaussian+Mixture+Model+for+Reasoning+over+Knowledge+Graphs)|0|
|[Enhancing Complex Question Answering over Knowledge Graphs through Evidence Pattern Retrieval](https://doi.org/10.1145/3589334.3645563)|Wentao Ding, Jinmao Li, Liangchuan Luo, Yuzhong Qu||Information retrieval (IR) methods for KGQA consist of two stages: subgraph extraction and answer reasoning. We argue current subgraph extraction methods underestimate the importance of structural dependencies among evidence facts. We propose Evidence Pattern Retrieval (EPR) to explicitly model the structural dependencies during subgraph extraction. We implement EPR by indexing the atomic adjacency pattern of resource pairs. Given a question, we perform dense retrieval to obtain atomic patterns formed by resource pairs. We then enumerate their combinations to construct candidate evidence patterns. These evidence patterns are scored using a neural model, and the best one is selected to extract a subgraph for downstream answer reasoning. Experimental results demonstrate that the EPR-based approach has significantly improved the F1 scores of IR-KGQA methods by over 10 points on ComplexWebQuestions and achieves competitive performance on WebQuestionsSP.|信息检索分析方法包括子图提取和答案推理两个阶段。我们认为现有的子图提取方法低估了证据事实之间结构相关性的重要性。我们提出证据模式检索(EPR)来显式建模子图提取过程中的结构依赖。我们通过索引资源对的原子邻接模式来实现 EPR。给定一个问题，我们执行密集检索来获得由资源对形成的原子模式。然后我们列举它们的组合来构造候选证据模式。这些证据模式评分使用神经模型，并选择最好的一个提取子图的下游答案推理。实验结果表明，基于 EPR 的方法显著提高了 IR-KGQA 方法在 ComplexWebquestions 上的 F1得分，提高了10分以上，并且在 Webquestions-SP 上取得了较好的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Complex+Question+Answering+over+Knowledge+Graphs+through+Evidence+Pattern+Retrieval)|0|
|[Author Name Disambiguation via Paper Association Refinement and Compositional Contrastive Embedding](https://doi.org/10.1145/3589334.3645596)|Dezhi Liu, Richong Zhang, Junfan Chen, Xinyue Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Author+Name+Disambiguation+via+Paper+Association+Refinement+and+Compositional+Contrastive+Embedding)|0|
|[Dual Box Embeddings for the Description Logic EL++](https://doi.org/10.1145/3589334.3645648)|Mathias Jackermeier, Jiaoyan Chen, Ian Horrocks||OWL ontologies, whose formal semantics are rooted in Description Logic (DL), have been widely used for knowledge representation. Similar to Knowledge Graphs (KGs), ontologies are often incomplete, and maintaining and constructing them has proved challenging. While classical deductive reasoning algorithms use the precise formal semantics of an ontology to predict missing facts, recent years have witnessed growing interest in inductive reasoning techniques that can derive probable facts from an ontology. Similar to KGs, a promising approach is to learn ontology embeddings in a latent vector space, while additionally ensuring they adhere to the semantics of the underlying DL. While a variety of approaches have been proposed, current ontology embedding methods suffer from several shortcomings, especially that they all fail to faithfully model one-to-many, many-to-one, and many-to-many relations and role inclusion axioms. To address this problem and improve ontology completion performance, we propose a novel ontology embedding method named Box^2EL for the DL EL++, which represents both concepts and roles as boxes (i.e., axis-aligned hyperrectangles), and models inter-concept relationships using a bumping mechanism. We theoretically prove the soundness of Box^2EL and conduct an extensive experimental evaluation, achieving state-of-the-art results across a variety of datasets on the tasks of subsumption prediction, role assertion prediction, and approximating deductive reasoning.|OWL 本体形式语义学植根于描述逻辑(Description Logic，DL) ，已被广泛用于知识表示。与知识图(KGs)类似，本体通常是不完整的，维护和构建它们被证明是具有挑战性的。虽然经典的演绎推理算法使用本体的精确形式语义学来预测缺失的事实，但近年来人们对从本体中获取可能事实的归纳推理技术的兴趣日益增长。与 KG 类似，一种有前途的方法是学习潜在向量空间中的本体嵌入，同时确保它们遵循底层 DL 的语义。虽然提出了各种方法，但是现有的本体嵌入方法都存在一些缺陷，特别是它们都不能忠实地建模一对多、多对一和多对多的关系和角色包含公理。为了解决这个问题，提高本体的完成性能，我们提出了一种新的本体嵌入方法，称为盒子 ^ 2EL 的 DL EL + + ，表示概念和角色的盒子(即，轴对齐的超矩形) ，并使用碰撞机制模型的概念间关系。我们从理论上证明了 Box ^ 2EL 的可靠性，并进行了广泛的实验评估，在包容预测、角色断言预测和近似演绎推理任务的各种数据集上取得了最先进的结果。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual+Box+Embeddings+for+the+Description+Logic+EL++)|0|
|[Jointly Canonicalizing and Linking Open Knowledge Base via Unified Embedding Learning](https://doi.org/10.1145/3589334.3645700)|Wei Shen, Binhan Yang, Yinan Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Jointly+Canonicalizing+and+Linking+Open+Knowledge+Base+via+Unified+Embedding+Learning)|0|
|[Efficient Exact and Approximate Betweenness Centrality Computation for Temporal Graphs](https://doi.org/10.1145/3589334.3645438)|Tianming Zhang, Yunjun Gao, Jie Zhao, Lu Chen, Lu Jin, Zhengyi Yang, Bin Cao, Jing Fan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Exact+and+Approximate+Betweenness+Centrality+Computation+for+Temporal+Graphs)|0|
|[PaCEr: Network Embedding From Positional to Structural](https://doi.org/10.1145/3589334.3645516)|Yuchen Yan, Yongyi Hu, Qinghai Zhou, Lihui Liu, Zhichen Zeng, Yuzhong Chen, Menghai Pan, Huiyuan Chen, Mahashweta Das, Hanghang Tong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PaCEr:+Network+Embedding+From+Positional+to+Structural)|0|
|[Link Recommendation to Augment Influence Diffusion with Provable Guarantees](https://doi.org/10.1145/3589334.3645521)|Xiaolong Chen, Yifan Song, Jing Tang||Link recommendation systems in online social networks (OSNs), such as Facebook's “People You May Know”, Twitter's “Who to Follow”, and Instagram's “Suggested Accounts”, facilitate the formation of new connections among users. This paper addresses the challenge of link recommendation for the purpose of social influence maximization. In particular, given a graph G and the seed set S, our objective is to select k edges that connect seed nodes and ordinary nodes to optimize the influence dissemination of the seed set. This problem, referred to as influence maximization with augmentation (IMA), has been proven to be NP-hard. In this paper, we propose an algorithm, namely , consisting of an efficient estimator for augmented influence estimation and an accelerated sampling approach. provides a (1-1/e-ε)-approximate solution with a high probability of 1-δ, and runs in O(k^2 (m+n) log (n / δ) / ε^2 + k |E_𝒞|) time assuming that the influence of any singleton node is smaller than that of the seed set. To the best of our knowledge, this is the first algorithm that can be implemented on large graphs containing millions of nodes while preserving strong theoretical guarantees. We conduct extensive experiments to demonstrate the effectiveness and efficiency of our proposed algorithm.|在线社交网络(OSNs)中的链接推荐系统，如 Facebook 的“你可能认识的人”、 Twitter 的“关注谁”和 Instagram 的“推荐账户”，促进了用户之间新的联系的形成。本文以社会影响力最大化为目标，解决了链接推荐的挑战。特别地，给定一个图 G 和种子集 S，我们的目标是选择连接种子节点和普通节点的 k 条边，以优化种子集的影响传播。这个问题被称为增广影响最大化问题(IMA) ，已被证明是 NP 难的。在本文中，我们提出了一个算法，即由一个有效的估计增强影响估计和加速抽样方法。提供了一个(1-1/e-ε)-近似解，其概率为1-δ，假设任一单点节点的影响小于种子集的影响，在 O (k ^ 2(m + n) log (n/δ)/ε ^ 2 + k | E _ C |)时间内运行。据我们所知，这是第一个可以在包含数百万个节点的大图上实现的算法，同时保留了很强的理论保证。我们进行了广泛的实验，以证明我们提出的算法的有效性和效率。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Link+Recommendation+to+Augment+Influence+Diffusion+with+Provable+Guarantees)|0|
|[Fairness Rising from the Ranks: HITS and PageRank on Homophilic Networks](https://doi.org/10.1145/3589334.3645609)|AnaAndreea Stoica, Nelly Litvak, Augustin Chaintreau||In this paper, we investigate the conditions under which link analysis algorithms prevent minority groups from reaching high ranking slots. We find that the most common link-based algorithms using centrality metrics, such as PageRank and HITS, can reproduce and even amplify bias against minority groups in networks. Yet, their behavior differs: one one hand, we empirically show that PageRank mirrors the degree distribution for most of the ranking positions and it can equalize representation of minorities among the top ranked nodes; on the other hand, we find that HITS amplifies pre-existing bias in homophilic networks through a novel theoretical analysis, supported by empirical results. We find the root cause of bias amplification in HITS to be the level of homophily present in the network, modeled through an evolving network model with two communities. We illustrate our theoretical analysis on both synthetic and real datasets and we present directions for future work.|在本文中，我们研究了链接分析算法阻止少数群体达到高排名位置的条件。我们发现，最常见的基于链路的算法使用中心度量，如 PageRank 和 HITS，可以重现，甚至放大对少数群体的偏见网络。然而，他们的行为是不同的: 一方面，我们经验证明 PageRank 反映了大多数排名位置的程度分布，它可以平衡顶级节点中少数群体的代表性; 另一方面，我们发现 HITS 通过一个新的理论分析放大了同质网络中预先存在的偏见，并得到了经验结果的支持。我们发现 HITS 中偏差放大的根本原因是网络中存在的同质性水平，通过一个具有两个群体的演化网络模型来模拟。我们举例说明我们的理论分析合成和真实的数据集，我们提出了未来的工作方向。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fairness+Rising+from+the+Ranks:+HITS+and+PageRank+on+Homophilic+Networks)|0|
|[Modeling the Impact of Timeline Algorithms on Opinion Dynamics Using Low-rank Updates](https://doi.org/10.1145/3589334.3645714)|Tianyi Zhou, Stefan Neumann, Kiran Garimella, Aristides Gionis||Timeline algorithms are key parts of online social networks, but during recent years they have been blamed for increasing polarization and disagreement in our society. Opinion-dynamics models have been used to study a variety of phenomena in online social networks, but an open question remains on how these models can be augmented to take into account the fine-grained impact of user-level timeline algorithms. We make progress on this question by providing a way to model the impact of timeline algorithms on opinion dynamics. Specifically, we show how the popular Friedkin–Johnsen opinion-formation model can be augmented based on aggregate information, extracted from timeline data. We use our model to study the problem of minimizing the polarization and disagreement; we assume that we are allowed to make small changes to the users' timeline compositions by strengthening some topics of discussion and penalizing some others. We present a gradient descent-based algorithm for this problem, and show that under realistic parameter settings, our algorithm computes a (1+ε)-approximate solution in time Õ(m√(n)(1/ε)), where m is the number of edges in the graph and n is the number of vertices. We also present an algorithm that provably computes an ε-approximation of our model in near-linear time. We evaluate our method on real-world data and show that it effectively reduces the polarization and disagreement in the network. Finally, we release an anonymized graph dataset with ground-truth opinions and more than 27 000 nodes (the previously largest publicly available dataset contains less than 550 nodes).|时间轴算法是在线社交网络的关键组成部分，但近年来，它们被指责为导致社会两极分化和分歧加剧的罪魁祸首。舆论动力学模型已经被用来研究在线社交网络中的各种现象，但是一个悬而未决的问题是如何扩展这些模型以考虑用户级时间轴算法的细粒度影响。我们在这个问题上取得了进展，提供了一种方法来模拟时间轴算法对意见动态的影响。具体地说，我们展示了如何基于从时间轴数据中提取的聚合信息扩展流行的 Friedkin-Johnsen 意见形成模型。我们使用我们的模型来研究最小化两极分化和分歧的问题; 我们假设我们可以通过加强讨论的一些话题和惩罚其他一些话题来对用户的时间表组成做一些小的改变。本文提出了一种基于梯度下降的算法，并证明了在实际参数设置条件下，该算法计算的时间域(m √(n)(1/ε))为(1 + ε)-近似解，其中 m 是图的边数，n 是顶点数。我们还提出了一个算法，可证明计算我们的模型在近线性时间的 ε- 近似。我们评估了我们的方法对真实世界的数据，并表明它有效地减少了极化和网络中的分歧。最后，我们发布了一个匿名的图形数据集，其中包含地面真相观点和超过27000个节点(以前最大的公开可用数据集包含不到550个节点)。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modeling+the+Impact+of+Timeline+Algorithms+on+Opinion+Dynamics+Using+Low-rank+Updates)|0|
|[PAGE: Equilibrate Personalization and Generalization in Federated Learning](https://doi.org/10.1145/3589334.3645513)|Qian Chen, Zilong Wang, Jiaqi Hu, Haonan Yan, Jianying Zhou, Xiaodong Lin||Federated learning (FL) is becoming a major driving force behind machine learning as a service, where customers (clients) collaboratively benefit from shared local updates under the orchestration of the service provider (server). Representing clients' current demands and the server's future demand, local model personalization and global model generalization are separately investigated, as the ill-effects of data heterogeneity enforce the community to focus on one over the other. However, these two seemingly competing goals are of equal importance rather than black and white issues, and should be achieved simultaneously. In this paper, we propose the first algorithm to balance personalization and generalization on top of game theory, dubbed PAGE, which reshapes FL as a co-opetition game between clients and the server. To explore the equilibrium, PAGE further formulates the game as Markov decision processes, and leverages the reinforcement learning algorithm, which simplifies the solving complexity. Extensive experiments on four widespread datasets show that PAGE outperforms state-of-the-art FL baselines in terms of global and local prediction accuracy simultaneously, and the accuracy can be improved by up to 35.20% and 39.91%, respectively. In addition, biased variants of PAGE imply promising adaptiveness to demand shifts in practice.|联邦学习(FL)正在成为机器学习作为一种服务背后的主要驱动力，在服务提供者(服务器)的协调下，客户(客户)协同受益于共享的本地更新。由于数据异构性的负面影响迫使社区将注意力放在一个服务器上，因此本地模型个性化和全局模型泛化分别代表了客户当前的需求和服务器未来的需求。然而，这两个看似相互竞争的目标是同等重要的，而不是黑白分明的问题，应该同时实现。本文在博弈论的基础上，提出了平衡个性化和泛化的第一种算法 PAGE，它将 FL 重塑为客户端和服务器之间的一种合作竞争博弈。为了探索均衡，PAGE 进一步将博弈表述为马尔可夫决策过程，并利用强化学习算法，从而简化了求解的复杂性。在四个广泛使用的数据集上进行的大量实验表明，PAGE 在全局和局部预测准确度方面同时优于最先进的 FL 基线，其准确度分别可提高35.20% 和39.91% 。此外，有偏见的 PAGE 变体意味着有希望在实践中适应需求变化。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PAGE:+Equilibrate+Personalization+and+Generalization+in+Federated+Learning)|0|
|[MatchNAS: Optimizing Edge AI in Sparse-Label Data Contexts via Automating Deep Neural Network Porting for Mobile Deployment](https://doi.org/10.1145/3589334.3645538)|Hongtao Huang, Xiaojun Chang, Wen Hu, Lina Yao||Recent years have seen the explosion of edge intelligence with powerful Deep Neural Networks (DNNs). One popular scheme is training DNNs on powerful cloud servers and subsequently porting them to mobile devices after being lightweight. Conventional approaches manually specialized DNNs for various edge platforms and retrain them with real-world data. However, as the number of platforms increases, these approaches become labour-intensive and computationally prohibitive. Additionally, real-world data tends to be sparse-label, further increasing the difficulty of lightweight models. In this paper, we propose MatchNAS, a novel scheme for porting DNNs to mobile devices. Specifically, we simultaneously optimise a large network family using both labelled and unlabelled data and then automatically search for tailored networks for different hardware platforms. MatchNAS acts as an intermediary that bridges the gap between cloud-based DNNs and edge-based DNNs.|近年来，随着强大的深度神经网络(DNN)的出现，边缘智能得到了迅猛发展。一个流行的方案是在强大的云服务器上培训 DNN，然后在轻量级之后将它们移植到移动设备上。传统的方法手动为各种边缘平台专门化 DNN，并用真实世界的数据重新训练它们。然而，随着平台数量的增加，这些方法变得劳动密集型和计算禁止。此外，真实世界的数据往往是稀疏标签，进一步增加了轻量级模型的难度。在本文中，我们提出了 MatchNAS，一种移植 DNN 到移动设备的新方案。具体来说，我们同时使用有标签和无标签的数据优化一个大型网络系列，然后自动为不同的硬件平台搜索量身定制的网络。MatchNAS 作为一个中介，在基于云的 DNN 和基于边缘的 DNN 之间架起了桥梁。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MatchNAS:+Optimizing+Edge+AI+in+Sparse-Label+Data+Contexts+via+Automating+Deep+Neural+Network+Porting+for+Mobile+Deployment)|0|
|[Temporal Conformity-aware Hawkes Graph Network for Recommendations](https://doi.org/10.1145/3589334.3645354)|Chenglong Ma, Yongli Ren, Pablo Castells, Mark Sanderson||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Temporal+Conformity-aware+Hawkes+Graph+Network+for+Recommendations)|0|
|[Hierarchical Graph Signal Processing for Collaborative Filtering](https://doi.org/10.1145/3589334.3645368)|Jiafeng Xia, Dongsheng Li, Hansu Gu, Tun Lu, Peng Zhang, Li Shang, Ning Gu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Graph+Signal+Processing+for+Collaborative+Filtering)|0|
|[Lower-Left Partial AUC: An Effective and Efficient Optimization Metric for Recommendation](https://doi.org/10.1145/3589334.3645371)|Wentao Shi, Chenxu Wang, Fuli Feng, Yang Zhang, Wenjie Wang, Junkang Wu, Xiangnan He||Optimization metrics are crucial for building recommendation systems at scale. However, an effective and efficient metric for practical use remains elusive. While Top-K ranking metrics are the gold standard for optimization, they suffer from significant computational overhead. Alternatively, the more efficient accuracy and AUC metrics often fall short of capturing the true targets of recommendation tasks, leading to suboptimal performance. To overcome this dilemma, we propose a new optimization metric, Lower-Left Partial AUC (LLPAUC), which is computationally efficient like AUC but strongly correlates with Top-K ranking metrics. Compared to AUC, LLPAUC considers only the partial area under the ROC curve in the Lower-Left corner to push the optimization focus on Top-K. We provide theoretical validation of the correlation between LLPAUC and Top-K ranking metrics and demonstrate its robustness to noisy user feedback. We further design an efficient point-wise recommendation loss to maximize LLPAUC and evaluate it on three datasets, validating its effectiveness and robustness.|优化度量对于大规模构建推荐系统至关重要。然而，对于实际应用来说，一个有效和高效的度量标准仍然是难以捉摸的。尽管 Top-K 排名指标是优化的黄金标准，但它们承受着巨大的计算开销。或者，更有效的准确性和 AUC 指标往往不能捕获推荐任务的真正目标，导致性能不理想。为了克服这一困境，我们提出了一种新的优化度量，下左偏 AUC (LLPAUC) ，它与 AUC 一样具有计算效率，但与 Top-K 排名度量强相关。与 AUC 相比，LLPAUC 只考虑了 Lower-Left 角 ROC 曲线下的部分面积，从而将优化重点放在 Top-K 上。我们提供了 LLPAUC 和 Top-K 排名指标之间相关性的理论验证，并证明了其对噪声用户反馈的鲁棒性。我们进一步设计了一个有效的逐点推荐损失来最大化 LLPAUC，并在三个数据集上对其进行评估，验证了其有效性和鲁棒性。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Lower-Left+Partial+AUC:+An+Effective+and+Efficient+Optimization+Metric+for+Recommendation)|0|
|[Learning to Rewrite Prompts for Personalized Text Generation](https://doi.org/10.1145/3589334.3645408)|Cheng Li, Mingyang Zhang, Qiaozhu Mei, Weize Kong, Michael Bendersky||Facilitated by large language models (LLMs), personalized text generation has become a rapidly growing research direction. Most existing studies focus on designing specialized models for a particular domain, or they require fine-tuning the LLMs to generate personalized text. We consider a typical scenario in which the large language model, which generates personalized output, is frozen and can only be accessed through APIs. Under this constraint, all one can do is to improve the input text (i.e., text prompts) sent to the LLM, a procedure that is usually done manually. In this paper, we propose a novel method to automatically revise prompts for personalized text generation. The proposed method takes the initial prompts generated by a state-of-the-art, multistage framework for personalized generation and rewrites a few critical components that summarize and synthesize the personal context. The prompt rewriter employs a training paradigm that chains together supervised learning (SL) and reinforcement learning (RL), where SL reduces the search space of RL and RL facilitates end-to-end training of the rewriter. Using datasets from three representative domains, we demonstrate that the rewritten prompts outperform both the original prompts and the prompts optimized via supervised learning or reinforcement learning alone. In-depth analysis of the rewritten prompts shows that they are not only human readable, but also able to guide manual revision of prompts when there is limited resource to employ reinforcement learning to train the prompt rewriter, or when it is costly to deploy an automatic prompt rewriter for inference.|在大型语言模型(LLM)的推动下，个性化文本生成已经成为一个迅速发展的研究方向。大多数现有的研究侧重于为特定领域设计专门的模型，或者需要对 LLM 进行微调以生成个性化的文本。我们考虑一个典型的场景，其中生成个性化输出的大型语言模型被冻结，只能通过 API 访问。在这个约束下，我们所能做的就是改进发送到 LLM 的输入文本(即文本提示) ，这个过程通常是手动完成的。针对个性化文本生成，提出了一种新的自动修改提示的方法。提出的方法采用最先进的多阶段个性化生成框架产生的初始提示，并重写了一些总结和综合个性化上下文的关键组件。提示重写器采用了一种将监督式学习(SL)和强化学习(RL)连接在一起的培训范式，其中 SL 减少了 RL 的搜索空间，而 RL 促进了重写器的端到端培训。通过使用来自三个代表性领域的数据集，我们证明了重写提示符的表现优于原始提示符和单独通过监督式学习或强化学习优化的提示符。对重写提示的深入分析表明，它们不仅具有人类可读性，而且在资源有限、无法使用强化学习培训提示重写程序、或者部署自动提示重写程序进行推理成本高昂的情况下，还能指导人工修改提示。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Rewrite+Prompts+for+Personalized+Text+Generation)|0|
|[Physical Trajectory Inference Attack and Defense in Decentralized POI Recommendation](https://doi.org/10.1145/3589334.3645410)|Jing Long, Tong Chen, Guanhua Ye, Kai Zheng, Quoc Viet Hung Nguyen, Hongzhi Yin||As an indispensable personalized service within Location-Based Social Networks (LBSNs), the Point-of-Interest (POI) recommendation aims to assist individuals in discovering attractive and engaging places. However, the accurate recommendation capability relies on the powerful server collecting a vast amount of users' historical check-in data, posing significant risks of privacy breaches. Although several collaborative learning (CL) frameworks for POI recommendation enhance recommendation resilience and allow users to keep personal data on-device, they still share personal knowledge to improve recommendation performance, thus leaving vulnerabilities for potential attackers. Given this, we design a new Physical Trajectory Inference Attack (PTIA) to expose users' historical trajectories. Specifically, for each user, we identify the set of interacted POIs by analyzing the aggregated information from the target POIs and their correlated POIs. We evaluate the effectiveness of PTIA on two real-world datasets across two types of decentralized CL frameworks for POI recommendation. Empirical results demonstrate that PTIA poses a significant threat to users' historical trajectories. Furthermore, Local Differential Privacy (LDP), the traditional privacy-preserving method for CL frameworks, has also been proven ineffective against PTIA. In light of this, we propose a novel defense mechanism (AGD) against PTIA based on an adversarial game to eliminate sensitive POIs and their information in correlated POIs. After conducting intensive experiments, AGD has been proven precise and practical, with minimal impact on recommendation performance.|作为基于位置的社交网络(LBSNs)中不可或缺的个性化服务，兴趣点(POI)推荐旨在帮助个人发现有吸引力和有吸引力的地方。然而，准确的推荐功能依赖于强大的服务器收集大量用户的历史签入数据，从而带来严重的隐私泄露风险。虽然一些用于 POI 推荐的合作学习(CL)框架增强了推荐的弹性，并允许用户将个人数据保存在设备上，但它们仍然共享个人知识以提高推荐性能，从而为潜在的攻击者留下了漏洞。鉴于此，我们设计了一个新的物理轨迹推断攻击(PTIA)来暴露用户的历史轨迹。具体来说，对于每个用户，我们通过分析来自目标 POI 及其相关 POI 的聚合信息来识别交互的 POI 集合。我们评估 PTIA 在两种分散式 CL 框架的两个实际数据集上对 POI 推荐的有效性。实证结果表明，PTIA 对用户的历史轨迹构成了显著的威胁。此外，CL 框架传统的保护隐私的方法——本地差分隐私(LDP)也被证明对 PTIA 无效。在此基础上，提出了一种新的基于对抗博弈的防御机制(AGD)来消除敏感 POI 及其相关 POI 中的信息。经过深入的实验，AGD 已经被证明是精确和实用的，对推荐性能的影响最小。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Physical+Trajectory+Inference+Attack+and+Defense+in+Decentralized+POI+Recommendation)|0|
|[Towards the Identifiability and Explainability for Personalized Learner Modeling: An Inductive Paradigm](https://doi.org/10.1145/3589334.3645437)|Jiatong Li, Qi Liu, Fei Wang, Jiayu Liu, Zhenya Huang, Fangzhou Yao, Linbo Zhu, Yu Su||Personalized learner modeling using cognitive diagnosis (CD), which aims to model learners' cognitive states by diagnosing learner traits from behavioral data, is a fundamental yet significant task in many web learning services. Existing cognitive diagnosis models (CDMs) follow the proficiency-response paradigm that views learner traits and question parameters as trainable embeddings and learns them through learner performance prediction. However, we notice that this paradigm leads to the inevitable non-identifiability and explainability overfitting problem, which is harmful to the quantification of learners' cognitive states and the quality of web learning services. To address these problems, we propose an identifiable cognitive diagnosis framework (ID-CDF) based on a novel response-proficiency-response paradigm inspired by encoder-decoder models. Specifically, we first devise the diagnostic module of ID-CDF, which leverages inductive learning to eliminate randomness in optimization to guarantee identifiability and captures the monotonicity between overall response data distribution and cognitive states to prevent explainability overfitting. Next, we propose a flexible predictive module for ID-CDF to ensure diagnosis preciseness. We further present an implementation of ID-CDF, i.e., ID-CDM, to illustrate its usability. Extensive experiments on four real-world datasets with different characteristics demonstrate that ID-CDF can effectively address the problems without loss of diagnosis preciseness.|基于认知诊断的个性化学习者建模是许多网络学习服务中的基础性工作，其目的是通过对学习者行为特征的诊断来建立学习者的认知状态模型。现有的认知诊断模型遵循熟练度-反应范式，将学习者特征和问题参数视为可训练的嵌入，并通过学习者表现预测来学习。然而，我们注意到这种范式导致了不可避免的不可识别性和可解释性过度拟合问题，这不利于学习者认知状态的量化和网络学习服务的质量。为了解决这些问题，我们提出了一个可识别的认知诊断框架(ID-CDF)基于一个新的反应-熟练程度-反应范式的启发编码器-解码器模型。具体而言，我们首先设计 ID-CDF 的诊断模块，其利用归纳学习消除优化中的随机性以保证可识别性，并捕获总体响应数据分布和认知状态之间的单调性以防止可解释性过度拟合。接下来，我们提出了一个灵活的 ID-CDF 预测模块，以确保诊断的准确性。我们进一步展示了 ID-CDF 的实现，即 ID-CDM，以说明其可用性。对四个具有不同特征的实际数据集进行的大量实验表明，ID-CDF 算法能够在不损失诊断精度的情况下有效地解决问题。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+the+Identifiability+and+Explainability+for+Personalized+Learner+Modeling:+An+Inductive+Paradigm)|0|
|[Generative News Recommendation](https://doi.org/10.1145/3589334.3645448)|Shen Gao, Jiabao Fang, Quan Tu, Zhitao Yao, Zhumin Chen, Pengjie Ren, Zhaochun Ren||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generative+News+Recommendation)|0|
|[MMPOI: A Multi-Modal Content-Aware Framework for POI Recommendations](https://doi.org/10.1145/3589334.3645449)|Yang Xu, Gao Cong, Lei Zhu, Lizhen Cui||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MMPOI:+A+Multi-Modal+Content-Aware+Framework+for+POI+Recommendations)|0|
|[Representation Learning with Large Language Models for Recommendation](https://doi.org/10.1145/3589334.3645458)|Xubin Ren, Wei Wei, Lianghao Xia, Lixin Su, Suqi Cheng, Junfeng Wang, Dawei Yin, Chao Huang||Recommender systems have seen significant advancements with the influence of deep learning and graph neural networks, particularly in capturing complex user-item relationships. However, these graph-based recommenders heavily depend on ID-based data, potentially disregarding valuable textual information associated with users and items, resulting in less informative learned representations. Moreover, the utilization of implicit feedback data introduces potential noise and bias, posing challenges for the effectiveness of user preference learning. While the integration of large language models (LLMs) into traditional ID-based recommenders has gained attention, challenges such as scalability issues, limitations in text-only reliance, and prompt input constraints need to be addressed for effective implementation in practical recommender systems. To address these challenges, we propose a model-agnostic framework RLMRec that aims to enhance existing recommenders with LLM-empowered representation learning. It proposes a recommendation paradigm that integrates representation learning with LLMs to capture intricate semantic aspects of user behaviors and preferences. RLMRec incorporates auxiliary textual signals, develops a user/item profiling paradigm empowered by LLMs, and aligns the semantic space of LLMs with the representation space of collaborative relational signals through a cross-view alignment framework. This work further establish a theoretical foundation demonstrating that incorporating textual signals through mutual information maximization enhances the quality of representations. In our evaluation, we integrate RLMRec with state-of-the-art recommender models, while also analyzing its efficiency and robustness to noise data. Our implementation codes are available at https://github.com/HKUDS/RLMRec.|在深度学习和图形神经网络的影响下，推荐系统已经取得了显著的进步，特别是在捕获复杂的用户-项目关系方面。然而，这些基于图表的推荐严重依赖于基于 ID 的数据，可能会忽略与用户和项目相关的有价值的文本信息，从而导致信息量较小的学习表示。此外，隐式反馈数据的利用还会引入潜在的噪声和偏差，对用户偏好学习的有效性提出了挑战。在传统的基于 ID 的推荐系统中集成大型语言模型(LLM)已经引起了人们的关注，但是为了在实际的推荐系统中有效地实现，需要解决诸如可伸缩性问题、仅依赖文本的局限性和及时的输入限制等挑战。为了应对这些挑战，我们提出了一个模型无关的框架 RLMRec，旨在通过 LLM 授权的表示学习来增强现有的推荐系统。它提出了一种推荐范式，将表示学习与 LLM 相结合，以捕获用户行为和偏好的复杂语义方面。RLMRec 结合了辅助文本信号，开发了一个由 LLM 授权的用户/项目剖析范式，并通过跨视图对齐框架将 LLM 的语义空间与协作关系信号的表示空间对齐。本文的工作进一步奠定了理论基础，表明通过互信息最大化结合文本信号可以提高表征的质量。在我们的评估中，我们整合了 RLMRec 和最先进的推荐模型，同时也分析了它的效率和对噪声数据的鲁棒性。我们的执行守则可在 https://github.com/hkuds/rlmrec 索取。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Representation+Learning+with+Large+Language+Models+for+Recommendation)|0|
|[Challenging Low Homophily in Social Recommendation](https://doi.org/10.1145/3589334.3645460)|Wei Jiang, Xinyi Gao, Guandong Xu, Tong Chen, Hongzhi Yin||Social relations are leveraged to tackle the sparsity issue of user-item interaction data in recommendation under the assumption of social homophily. However, social recommendation paradigms predominantly focus on homophily based on user preferences. While social information can enhance recommendations, its alignment with user preferences is not guaranteed, thereby posing the risk of introducing informational redundancy. We empirically discover that social graphs in real recommendation data exhibit low preference-aware homophily, which limits the effect of social recommendation models. To comprehensively extract preference-aware homophily information latent in the social graph, we propose Social Heterophily-alleviating Rewiring (SHaRe), a data-centric framework for enhancing existing graph-based social recommendation models. We adopt Graph Rewiring technique to capture and add highly homophilic social relations, and cut low homophilic (or heterophilic) relations. To better refine the user representations from reliable social relations, we integrate a contrastive learning method into the training of SHaRe, aiming to calibrate the user representations for enhancing the result of Graph Rewiring. Experiments on real-world datasets show that the proposed framework not only exhibits enhanced performances across varying homophily ratios but also improves the performance of existing state-of-the-art (SOTA) social recommendation models.|在社会同质性假设下，利用社会关系解决推荐中用户交互数据的稀疏性问题。然而，社交推荐模式主要关注基于用户偏好的同质性。虽然社交信息可以增强推荐，但它与用户偏好的一致性并不能得到保证，从而带来了引入信息冗余的风险。实证研究发现，真实推荐数据中的社会图表现出较低的偏好感知同质性，从而限制了社会推荐模型的效果。为了全面提取隐藏在社会图中的偏好感知同质性信息，本文提出了基于数据的社会推荐模型——社会异质性缓解重构框架(SHaRe)。我们采用图重构技术来捕获和添加高度同质的社会关系，并切断低度同质(或异质)关系。为了更好地从可靠的社会关系中提炼出用户表征，我们将对比学习方法融入到 ShareRe 的训练中，旨在校准用户表征以提高图重构的效果。在实际数据集上的实验表明，该框架不仅在不同的同质性比率下表现出更好的性能，而且改善了现有的最先进的社会推荐模型(SOTA)的性能。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Challenging+Low+Homophily+in+Social+Recommendation)|0|
|[Helen: Optimizing CTR Prediction Models with Frequency-wise Hessian Eigenvalue Regularization](https://doi.org/10.1145/3589334.3645463)|Zirui Zhu, Yong Liu, Zangwei Zheng, Huifeng Guo, Yang You||Click-Through Rate (CTR) prediction holds paramount significance in online advertising and recommendation scenarios. Despite the proliferation of recent CTR prediction models, the improvements in performance have remained limited, as evidenced by open-source benchmark assessments. Current researchers tend to focus on developing new models for various datasets and settings, often neglecting a crucial question: What is the key challenge that truly makes CTR prediction so demanding? In this paper, we approach the problem of CTR prediction from an optimization perspective. We explore the typical data characteristics and optimization statistics of CTR prediction, revealing a strong positive correlation between the top hessian eigenvalue and feature frequency. This correlation implies that frequently occurring features tend to converge towards sharp local minima, ultimately leading to suboptimal performance. Motivated by the recent advancements in sharpness-aware minimization (SAM), which considers the geometric aspects of the loss landscape during optimization, we present a dedicated optimizer crafted for CTR prediction, named Helen. Helen incorporates frequency-wise Hessian eigenvalue regularization, achieved through adaptive perturbations based on normalized feature frequencies. Empirical results under the open-source benchmark framework underscore Helen's effectiveness. It successfully constrains the top eigenvalue of the Hessian matrix and demonstrates a clear advantage over widely used optimization algorithms when applied to seven popular models across three public benchmark datasets on BARS. Our code locates at github.com/NUS-HPC-AI-Lab/Helen.|在在线广告和推荐场景中，点进率(ctrl)预测具有至关重要的意义。尽管最近 CTR 预测模型激增，但性能的改进仍然有限，开源基准评估就是证明。目前的研究人员往往专注于为各种数据集和设置开发新的模型，往往忽略了一个关键问题: 什么是真正使 CTR 预测如此苛刻的关键挑战？本文从最优化的角度探讨了 CTR 预测问题。我们探讨了 CTR 预测的典型数据特征和优化统计，发现最高黑森特征值与特征频率之间存在很强的正相关关系。这种相关性意味着频繁出现的特征往往趋向于尖锐的局部极小值，最终导致次优性能。由于最近在锐度感知最小化(SAM)方面的进展，其中考虑了优化过程中损失景观的几何方面，我们提出了一个专用的 CTR 预测优化器，命名为 Helen。海伦采用了频率明确的黑森特征值正则化，实现了通过自适应扰动的基础上归一化的特征频率。开源基准框架下的实证结果强调了 Helen 的有效性。该算法成功地约束了 Hessian 矩阵的最高特征值，并且在 BARS 的三个公共基准数据集上应用于七个流行的模型时，显示出比广泛使用的优化算法有明显的优势。我们的代码位于 github.com/nus-hpc-ai-lab/helen。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Helen:+Optimizing+CTR+Prediction+Models+with+Frequency-wise+Hessian+Eigenvalue+Regularization)|0|
|[Intersectional Two-sided Fairness in Recommendation](https://doi.org/10.1145/3589334.3645518)|Yifan Wang, Peijie Sun, Weizhi Ma, Min Zhang, Yuan Zhang, Peng Jiang, Shaoping Ma||Fairness of recommender systems (RS) has attracted increasing attention recently. Based on the involved stakeholders, the fairness of RS can be divided into user fairness, item fairness, and two-sided fairness which considers both user and item fairness simultaneously. However, we argue that the intersectional two-sided unfairness may still exist even if the RS is two-sided fair, which is observed and shown by empirical studies on real-world data in this paper, and has not been well-studied previously. To mitigate this problem, we propose a novel approach called Intersectional Two-sided Fairness Recommendation (ITFR). Our method utilizes a sharpness-aware loss to perceive disadvantaged groups, and then uses collaborative loss balance to develop consistent distinguishing abilities for different intersectional groups. Additionally, predicted score normalization is leveraged to align positive predicted scores to fairly treat positives in different intersectional groups. Extensive experiments and analyses on three public datasets show that our proposed approach effectively alleviates the intersectional two-sided unfairness and consistently outperforms previous state-of-the-art methods.|推荐系统的公平性近年来受到越来越多的关注。基于所涉及的利益相关者，RS 的公平性可以分为用户公平性、项目公平性和同时考虑用户公平性和项目公平性的双边公平性。然而，本文通过对实际数据的实证研究发现，即使 RS 是双边公平的，交叉口的双边不公平性仍然存在，而且这种不公平性还没有得到很好的研究。为了缓解这一问题，我们提出了一种新的方法称为交叉双边公平推荐(ITFR)。我们的方法利用敏锐感知损失来感知弱势群体，然后利用协作损失平衡来发展不同交叉群体的一致识别能力。此外，预测分数标准化是利用调整积极的预测分数，以公平对待积极的不同交叉组。对三个公共数据集的大量实验和分析表明，我们提出的方法有效地缓解了交叉口的双向不公平性，并始终优于以前的最先进的方法。|[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Intersectional+Two-sided+Fairness+in+Recommendation)|0|
|[Full Stage Learning to Rank: A Unified Framework for Multi-Stage Systems](https://doi.org/10.1145/3589334.3645523)|Kai Zheng, Haijun Zhao, Rui Huang, Beichuan Zhang, Na Mou, Yanan Niu, Yang Song, Hongning Wang, Kun Gai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Full+Stage+Learning+to+Rank:+A+Unified+Framework+for+Multi-Stage+Systems)|0|
|[RecDCL: Dual Contrastive Learning for Recommendation](https://doi.org/10.1145/3589334.3645533)|Dan Zhang, Yangliao Geng, Wenwen Gong, Zhongang Qi, Zhiyu Chen, Xing Tang, Ying Shan, Yuxiao Dong, Jie Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RecDCL:+Dual+Contrastive+Learning+for+Recommendation)|0|
|[GraphPro: Graph Pre-training and Prompt Learning for Recommendation](https://doi.org/10.1145/3589334.3645546)|Yuhao Yang, Lianghao Xia, Da Luo, Kangyi Lin, Chao Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphPro:+Graph+Pre-training+and+Prompt+Learning+for+Recommendation)|0|
|[Modeling Balanced Explicit and Implicit Relations with Contrastive Learning for Knowledge Concept Recommendation in MOOCs](https://doi.org/10.1145/3589334.3645559)|Hengnian Gu, Zhiyi Duan, Pan Xie, Dongdai Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modeling+Balanced+Explicit+and+Implicit+Relations+with+Contrastive+Learning+for+Knowledge+Concept+Recommendation+in+MOOCs)|0|
|[A Counterfactual Framework for Learning and Evaluating Explanations for Recommender Systems](https://doi.org/10.1145/3589334.3645560)|Oren Barkan, Veronika Bogina, Liya Gurevitch, Yuval Asher, Noam Koenigstein||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Counterfactual+Framework+for+Learning+and+Evaluating+Explanations+for+Recommender+Systems)|0|
|[Category-based and Popularity-guided Video Game Recommendation: A Balance-oriented Framework](https://doi.org/10.1145/3589334.3645573)|Xiping Li, Jianghong Ma, Kangzhe Liu, Shanshan Feng, Haijun Zhang, Yutong Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Category-based+and+Popularity-guided+Video+Game+Recommendation:+A+Balance-oriented+Framework)|0|
|[Unleashing the Power of Knowledge Graph for Recommendation via Invariant Learning](https://doi.org/10.1145/3589334.3645576)|Shuyao Wang, Yongduo Sui, Chao Wang, Hui Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unleashing+the+Power+of+Knowledge+Graph+for+Recommendation+via+Invariant+Learning)|0|
|[Distributionally Robust Graph-based Recommendation System](https://doi.org/10.1145/3589334.3645598)|Bohao Wang, Jiawei Chen, Changdong Li, Sheng Zhou, Qihao Shi, Yang Gao, Yan Feng, Chun Chen, Can Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Distributionally+Robust+Graph-based+Recommendation+System)|0|
|[Co-clustering for Federated Recommender System](https://doi.org/10.1145/3589334.3645626)|Xinrui He, Shuo Liu, Jacky Keung, Jingrui He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Co-clustering+for+Federated+Recommender+System)|0|
|[PMG : Personalized Multimodal Generation with Large Language Models](https://doi.org/10.1145/3589334.3645633)|Xiaoteng Shen, Rui Zhang, Xiaoyan Zhao, Jieming Zhu, Xi Xiao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PMG+:+Personalized+Multimodal+Generation+with+Large+Language+Models)|0|
|[M-scan: A Multi-Scenario Causal-driven Adaptive Network for Recommendation](https://doi.org/10.1145/3589334.3645635)|Jiachen Zhu, Yichao Wang, Jianghao Lin, Jiarui Qin, Ruiming Tang, Weinan Zhang, Yong Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=M-scan:+A+Multi-Scenario+Causal-driven+Adaptive+Network+for+Recommendation)|0|
|[Federated Heterogeneous Graph Neural Network for Privacy-preserving Recommendation](https://doi.org/10.1145/3589334.3645693)|Bo Yan, Yang Cao, Haoyu Wang, Wenchuan Yang, Junping Du, Chuan Shi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Federated+Heterogeneous+Graph+Neural+Network+for+Privacy-preserving+Recommendation)|0|
|[Understanding Human Preferences: Towards More Personalized Video to Text Generation](https://doi.org/10.1145/3589334.3645711)|Yihan Wu, Ruihua Song, Xu Chen, Hao Jiang, Zhao Cao, Jin Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+Human+Preferences:+Towards+More+Personalized+Video+to+Text+Generation)|0|
|[Entity Disambiguation with Extreme Multi-label Ranking](https://doi.org/10.1145/3589334.3645498)|JyunYu Jiang, WeiCheng Chang, Jiong Zhang, ChoJui Hsieh, HsiangFu Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Entity+Disambiguation+with+Extreme+Multi-label+Ranking)|0|
|[BOND: Bootstrapping From-Scratch Name Disambiguation with Multi-task Promoting](https://doi.org/10.1145/3589334.3645580)|Yuqing Cheng, Bo Chen, Fanjin Zhang, Jie Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BOND:+Bootstrapping+From-Scratch+Name+Disambiguation+with+Multi-task+Promoting)|0|
|[Inductive Graph Alignment Prompt: Bridging the Gap between Graph Pre-training and Inductive Fine-tuning From Spectral Perspective](https://doi.org/10.1145/3589334.3645620)|Yuchen Yan, Peiyan Zhang, Zheng Fang, Qingqing Long||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Inductive+Graph+Alignment+Prompt:+Bridging+the+Gap+between+Graph+Pre-training+and+Inductive+Fine-tuning+From+Spectral+Perspective)|0|
|[Consistency Guided Knowledge Retrieval and Denoising in LLMs for Zero-shot Document-level Relation Triplet Extraction](https://doi.org/10.1145/3589334.3645678)|Qi Sun, Kun Huang, Xiaocui Yang, Rong Tong, Kun Zhang, Soujanya Poria||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Consistency+Guided+Knowledge+Retrieval+and+Denoising+in+LLMs+for+Zero-shot+Document-level+Relation+Triplet+Extraction)|0|
|[Detecting Illicit Food Factories from Chemical Declaration Data via Graph-aware Self-supervised Contrastive Anomaly Ranking](https://doi.org/10.1145/3589334.3648138)|ShengFang Yang, ChengTe Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Detecting+Illicit+Food+Factories+from+Chemical+Declaration+Data+via+Graph-aware+Self-supervised+Contrastive+Anomaly+Ranking)|0|
|[Bayesian Iterative Prediction and Lexical-based Interpretation for Disturbed Chinese Sentence Pair Matching](https://doi.org/10.1145/3589334.3648149)|Muzhe Guo, Muhao Guo, Juntao Su, Junyu Chen, Jiaqian Yu, Jiaqi Wang, Hongfei Du, Parmanand Sahu, Ashwin Assysh Sharma, Fang Jin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bayesian+Iterative+Prediction+and+Lexical-based+Interpretation+for+Disturbed+Chinese+Sentence+Pair+Matching)|0|
|[Uncovering the Deep Filter Bubble: Narrow Exposure in Short-Video Recommendation](https://doi.org/10.1145/3589334.3648159)|Nicholas Sukiennik, Chen Gao, Nian Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Uncovering+the+Deep+Filter+Bubble:+Narrow+Exposure+in+Short-Video+Recommendation)|0|
|[Mining Interest Diffusion in Online Activity Data Streams](https://doi.org/10.1145/3589335.3651259)|Shingo Higashiguchi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mining+Interest+Diffusion+in+Online+Activity+Data+Streams)|0|
|[Temporal Interest Network for User Response Prediction](https://doi.org/10.1145/3589335.3648340)|Haolin Zhou, Junwei Pan, Xinyi Zhou, Xihua Chen, Jie Jiang, Xiaofeng Gao, Guihai Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Temporal+Interest+Network+for+User+Response+Prediction)|0|
|[Practical Batch Bayesian Sampling Algorithms for Online Adaptive Traffic Experimentation](https://doi.org/10.1145/3589335.3648347)|Zezhong Zhang, Ted Tao Yuan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Practical+Batch+Bayesian+Sampling+Algorithms+for+Online+Adaptive+Traffic+Experimentation)|0|
|[Exploring Representational Similarity Analysis to Protect Federated Learning from Data Poisoning](https://doi.org/10.1145/3589335.3651503)|Gengxiang Chen, Kai Li, Ahmed M. Abdelmoniem, Linlin You||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+Representational+Similarity+Analysis+to+Protect+Federated+Learning+from+Data+Poisoning)|0|
|[Online Sampling of Summaries from Public SPARQL Endpoints](https://doi.org/10.1145/3589335.3651543)|Thi Hoang Thi Pham, Hala SkafMolli, Pascal Molli, Brice Nédelec||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Online+Sampling+of+Summaries+from+Public+SPARQL+Endpoints)|0|
|[Coordinated Activity Modulates the Behavior and Emotions of Organic Users: A Case Study on Tweets about the Gaza Conflict](https://doi.org/10.1145/3589335.3651483)|Priyanka Dey, Luca Luceri, Emilio Ferrara||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Coordinated+Activity+Modulates+the+Behavior+and+Emotions+of+Organic+Users:+A+Case+Study+on+Tweets+about+the+Gaza+Conflict)|0|
|[From Files to Streams: Revisiting Web History and Exploring Potentials for Future Prospects](https://doi.org/10.1145/3589335.3652001)|Lucas Vogel, Thomas Springer, Matthias Wählisch||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=From+Files+to+Streams:+Revisiting+Web+History+and+Exploring+Potentials+for+Future+Prospects)|0|
|[Revisiting the Behavioral Foundations of User Modeling Algorithms](https://doi.org/10.1145/3589334.3649114)|Jon M. Kleinberg||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revisiting+the+Behavioral+Foundations+of+User+Modeling+Algorithms)|0|
|[User Response in Ad Auctions: An MDP Formulation of Long-term Revenue Optimization](https://doi.org/10.1145/3589334.3645495)|Yang Cai, Zhe Feng, Christopher Liaw, Aranyak Mehta, Grigoris Velegkas||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=User+Response+in+Ad+Auctions:+An+MDP+Formulation+of+Long-term+Revenue+Optimization)|0|
|[Exploring Neural Scaling Law and Data Pruning Methods For Node Classification on Large-scale Graphs](https://doi.org/10.1145/3589334.3645571)|Zhen Wang, Yaliang Li, Bolin Ding, Yule Li, Zhewei Wei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+Neural+Scaling+Law+and+Data+Pruning+Methods+For+Node+Classification+on+Large-scale+Graphs)|0|
|[Bit-mask Robust Contrastive Knowledge Distillation for Unsupervised Semantic Hashing](https://doi.org/10.1145/3589334.3645440)|Liyang He, Zhenya Huang, Jiayu Liu, Enhong Chen, Fei Wang, Jing Sha, Shijin Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bit-mask+Robust+Contrastive+Knowledge+Distillation+for+Unsupervised+Semantic+Hashing)|0|
|[Perennial Semantic Data Terms of Use for Decentralized Web](https://doi.org/10.1145/3589334.3645631)|Rui Zhao, Jun Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Perennial+Semantic+Data+Terms+of+Use+for+Decentralized+Web)|0|
|[Enhancing Fairness in Meta-learned User Modeling via Adaptive Sampling](https://doi.org/10.1145/3589334.3645369)|Zheng Zhang, Qi Liu, Zirui Hu, Yi Zhan, Zhenya Huang, Weibo Gao, Qingyang Mao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Fairness+in+Meta-learned+User+Modeling+via+Adaptive+Sampling)|0|
|[MMLSCU: A Dataset for Multi-modal Multi-domain Live Streaming Comment Understanding](https://doi.org/10.1145/3589334.3645677)|Zixiang Meng, Qiang Gao, Di Guo, Yunlong Li, Bobo Li, Hao Fei, Shengqiong Wu, Fei Li, Chong Teng, Donghong Ji||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MMLSCU:+A+Dataset+for+Multi-modal+Multi-domain+Live+Streaming+Comment+Understanding)|0|
|[Entire Chain Uplift Modeling with Context-Enhanced Learning for Intelligent Marketing](https://doi.org/10.1145/3589335.3648320)|Yinqiu Huang, Shuli Wang, Min Gao, Xue Wei, Changhao Li, Chuan Luo, Yinhua Zhu, Xiong Xiao, Yi Luo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Entire+Chain+Uplift+Modeling+with+Context-Enhanced+Learning+for+Intelligent+Marketing)|0|
|[Large Multimodal Model Compression via Iterative Efficient Pruning and Distillation](https://doi.org/10.1145/3589335.3648321)|Maolin Wang, Yao Zhao, Jiajia Liu, Jingdong Chen, Chenyi Zhuang, Jinjie Gu, Ruocheng Guo, Xiangyu Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large+Multimodal+Model+Compression+via+Iterative+Efficient+Pruning+and+Distillation)|0|
|[Mystique: A Budget Pacing System for Performance Optimization in Online Advertising](https://doi.org/10.1145/3589335.3648342)|Rotem Stram, Rani Abboud, Alex Shtoff, Oren Somekh, Ariel Raviv, Yair Koren||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mystique:+A+Budget+Pacing+System+for+Performance+Optimization+in+Online+Advertising)|0|
|[HBIAS FedAvg: Smooth Federated Learning Transition for In-use Edge Models](https://doi.org/10.1145/3589335.3651518)|Anupam Gupta, Pabitra Mitra, Sudip Misra||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HBIAS+FedAvg:+Smooth+Federated+Learning+Transition+for+In-use+Edge+Models)|0|
|[The Effect of Alter Ego Accounts on A/B Tests in Social Networks](https://doi.org/10.1145/3589335.3651569)|Katherine Avery, Amir Houmansadr, David D. Jensen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Effect+of+Alter+Ego+Accounts+on+A/B+Tests+in+Social+Networks)|0|
|[CardiO: Predicting Cardinality from Online Sources](https://doi.org/10.1145/3589335.3651477)|Shrestha Ghosh, Simon Razniewski, Damien Graux, Gerhard Weikum||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CardiO:+Predicting+Cardinality+from+Online+Sources)|0|
|[An Identity Alignment Method based on Online Tracking](https://doi.org/10.1145/3589335.3651469)|Ruisheng Shi, Zhiyuan Peng, Tong Fu, Lina Lan, Jiaqi Zeng, Yuyang Shi, Jinqiao Shi, Shenwen Lin, Lin Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Identity+Alignment+Method+based+on+Online+Tracking)|0|
|[Semantic interlinking of Immigration Data using LLMs for Knowledge Graph Construction](https://doi.org/10.1145/3589335.3651557)|Radhakrishnan Venkatakrishnan, Emrah Tanyildizi, M. Abdullah Canbaz||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Semantic+interlinking+of+Immigration+Data+using+LLMs+for+Knowledge+Graph+Construction)|0|
|[Why Deeper Layers May Introduce More Bias](https://doi.org/10.1145/3589335.3651583)|Rui Xia, Lisong Wang, Pingping Shi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Why+Deeper+Layers+May+Introduce+More+Bias)|0|
|[Shock! Quantifying the Impact of Core Developers' Dropout on the Productivity of OSS Projects](https://doi.org/10.1145/3589335.3651559)|Giuseppe Russo Latona, Christoph Gote, Christian Zingg, Giona Casiraghi, Luca Verginer, Frank Schweitzer||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Shock!+Quantifying+the+Impact+of+Core+Developers'+Dropout+on+the+Productivity+of+OSS+Projects)|0|
|[Over-Sampling Strategy in Feature Space for Graphs based Class-imbalanced Bot Detection](https://doi.org/10.1145/3589335.3651544)|Shuhao Shi, Kai Qiao, Chen Chen, Jie Yang, Jian Chen, Bin Yan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Over-Sampling+Strategy+in+Feature+Space+for+Graphs+based+Class-imbalanced+Bot+Detection)|0|
|[Dual Graph Networks with Synthetic Oversampling for Imbalanced Rumor Detection on Social Media](https://doi.org/10.1145/3589335.3651494)|YenWen Lu, ChihYao Chen, ChengTe Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual+Graph+Networks+with+Synthetic+Oversampling+for+Imbalanced+Rumor+Detection+on+Social+Media)|0|
|[Travel Demand Prediction with Application to Commuter Demand Estimation on Urban Railways](https://doi.org/10.1145/3589335.3651574)|Yohei Kodama, Yuki Akeyama, Yusuke Miyazaki, Koh Takeuchi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Travel+Demand+Prediction+with+Application+to+Commuter+Demand+Estimation+on+Urban+Railways)|0|
|[Burstiness-aware Bipartite Graph Neural Networks for Fraudulent User Detection on Rating Platforms](https://doi.org/10.1145/3589335.3651475)|YenWen Lu, YuChe Tsai, ChengTe Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Burstiness-aware+Bipartite+Graph+Neural+Networks+for+Fraudulent+User+Detection+on+Rating+Platforms)|0|
|[A Tale of Two Communities: Exploring Academic References on Stack Overflow](https://doi.org/10.1145/3589335.3651464)|Run Huang, Souti Chattopadhyay||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Tale+of+Two+Communities:+Exploring+Academic+References+on+Stack+Overflow)|0|
|[Efficient Location Sampling Algorithms for Road Networks](https://doi.org/10.1145/3589335.3651497)|Sara Ahmadian, Sreenivas Gollapudi, Kostas Kollias, Vivek Kumar, Ameya Velingker, Santhoshini Velusamy||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Location+Sampling+Algorithms+for+Road+Networks)|0|
|[A Category-agnostic Graph Attention-based Approach for Determining Notability of Articles for Wikipedia](https://doi.org/10.1145/3589335.3651461)|Gokul Thota, Vasudeva Varma||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Category-agnostic+Graph+Attention-based+Approach+for+Determining+Notability+of+Articles+for+Wikipedia)|0|
|[Concentration of Power and Participation in Online Governance: the Ecosystem of Decentralized Autonomous Organizations](https://doi.org/10.1145/3589335.3651481)|Andrea PeñaCalvin, Javier Arroyo, Andrew Schwartz, Samer Hassan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Concentration+of+Power+and+Participation+in+Online+Governance:+the+Ecosystem+of+Decentralized+Autonomous+Organizations)|0|
|["All of Me": Mining Users' Attributes from their Public Spotify Playlists](https://doi.org/10.1145/3589335.3651459)|Pier Paolo Tricomi, Luca Pajola, Luca Pasa, Mauro Conti||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q="All+of+Me":+Mining+Users'+Attributes+from+their+Public+Spotify+Playlists)|0|
|[PyGDebias: A Python Library for Debiasing in Graph Learning](https://doi.org/10.1145/3589335.3651239)|Yushun Dong, Zhenyu Lei, Zaiyi Zheng, Song Wang, Jing Ma, Alex Jing Huang, Chen Chen, Jundong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PyGDebias:+A+Python+Library+for+Debiasing+in+Graph+Learning)|0|
|[Synslator: An Interactive Machine Translation Tool with Online Learning](https://doi.org/10.1145/3589335.3651240)|Jiayi Wang, Ke Wang, Fengming Zhou, Chengyu Wang, Zhiyong Fu, Zeyu Feng, Yu Zhao, Yuqi Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Synslator:+An+Interactive+Machine+Translation+Tool+with+Online+Learning)|0|
|[ACCORD: Constraint-driven Mediation of Multi-user Conflicts in Cloud Services](https://doi.org/10.1145/3589335.3651244)|Abhiroop Tippavajjula, Primal Pappachan, Anna Cinzia Squicciarini, Jose Such||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ACCORD:+Constraint-driven+Mediation+of+Multi-user+Conflicts+in+Cloud+Services)|0|
|[Fediscount: Shopping Online at a Federated Store Using FedUP as SPARQL Federation Engine](https://doi.org/10.1145/3589335.3651249)|Julien AimonierDavat, Minh Hoang Dang, Pascal Molli, Brice Nédelec, Hala SkafMolli||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fediscount:+Shopping+Online+at+a+Federated+Store+Using+FedUP+as+SPARQL+Federation+Engine)|0|
|[Online Disinformation and Generative Language Models: Motivations, Challenges, and Mitigations](https://doi.org/10.1145/3589335.3651254)|Ziyi Guo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Online+Disinformation+and+Generative+Language+Models:+Motivations,+Challenges,+and+Mitigations)|0|
|[Quantifying Governance of Online Communities at Web Scale](https://doi.org/10.1145/3589335.3651266)|Galen Cassebeer Weld||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Quantifying+Governance+of+Online+Communities+at+Web+Scale)|0|
|[Tutorial on User Simulation for Evaluating Information Access Systems on the Web](https://doi.org/10.1145/3589335.3641243)|Krisztian Balog, ChengXiang Zhai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tutorial+on+User+Simulation+for+Evaluating+Information+Access+Systems+on+the+Web)|0|
|[Archiving and Temporal Analysis of Behavioral Web Data - Tales from the Inside](https://doi.org/10.1145/3589335.3641260)|Stefan Dietze||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Archiving+and+Temporal+Analysis+of+Behavioral+Web+Data+-+Tales+from+the+Inside)|0|
|[A Case Study Comparing Twitter Communities Detected by the Louvain and Leiden Algorithms During the 2022 War in Ukraine](https://doi.org/10.1145/3589335.3651892)|Karolina Sliwa, Ema Kusen, Mark Strembeck||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Case+Study+Comparing+Twitter+Communities+Detected+by+the+Louvain+and+Leiden+Algorithms+During+the+2022+War+in+Ukraine)|0|
|[AI Driven Online Advertising: Market Design, Generative AI, and Ethics](https://doi.org/10.1145/3589335.3641295)|Fengxiang He, Mengnan Du, Aris FilosRatsikas, Lu Cheng, Qingquan Song, Min Lin, John Vines||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AI+Driven+Online+Advertising:+Market+Design,+Generative+AI,+and+Ethics)|0|
|[Comparative Analysis of Discussion Intensity and Semantic Diversity in Early vs. Late Engagers: A Study of Japanese Tweets about ChatGPT](https://doi.org/10.1145/3589335.3651908)|Tomoki Fukuma, Koki Noda, Yuta Yamamoto, Takaya Hoshi, Yoshiharu Ichikawa, Kyosuke Kambe, Yu Masubuchi, Fujio Toriumi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Comparative+Analysis+of+Discussion+Intensity+and+Semantic+Diversity+in+Early+vs.+Late+Engagers:+A+Study+of+Japanese+Tweets+about+ChatGPT)|0|
|[Analysis of the Effect between the Information Type on SNSs and User Attributes during Disaster](https://doi.org/10.1145/3589335.3652500)|Kosuke Wakasugi, Yu Suzuki, Akiyo Nadamoto||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Analysis+of+the+Effect+between+the+Information+Type+on+SNSs+and+User+Attributes+during+Disaster)|0|
|[Understanding the Impact of COVID-19 on Online Eating Disorder Communities on Reddit](https://doi.org/10.1145/3589335.3652506)|Md Al Amin, Lu Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+the+Impact+of+COVID-19+on+Online+Eating+Disorder+Communities+on+Reddit)|0|
|[Statistical Confidence in Mining Power Estimates for PoW Blockchains](https://doi.org/10.1145/3589335.3651960)|Mary Milad, Christina Ovezik, Dimitris Karakostas, Daniel W. Woods||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Statistical+Confidence+in+Mining+Power+Estimates+for+PoW+Blockchains)|0|
|[From Bollywood Son Preference to Moral Policing on Women in Iran - A 360° View of Gender Bias](https://doi.org/10.1145/3589335.3653010)|Ashiqur R. KhudaBukhsh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=From+Bollywood+Son+Preference+to+Moral+Policing+on+Women+in+Iran+-+A+360°+View+of+Gender+Bias)|0|
|[On Truthful Item-Acquiring Mechanisms for Reward Maximization](https://doi.org/10.1145/3589334.3645345)|Liang Shan, Shuo Zhang, Jie Zhang, Zihe Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+Truthful+Item-Acquiring+Mechanisms+for+Reward+Maximization)|0|
|[Barter Exchange with Shared Item Valuations](https://doi.org/10.1145/3589334.3645632)|Juan Luque, Sharmila Duppala, John P. Dickerson, Aravind Srinivasan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Barter+Exchange+with+Shared+Item+Valuations)|0|
|[Efficiency of Non-Truthful Auctions in Auto-bidding with Budget Constraints](https://doi.org/10.1145/3589334.3645636)|Christopher Liaw, Aranyak Mehta, Wennan Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficiency+of+Non-Truthful+Auctions+in+Auto-bidding+with+Budget+Constraints)|0|
|[Individual Welfare Guarantees in the Autobidding World with Machine-learned Advice](https://doi.org/10.1145/3589334.3645660)|Yuan Deng, Negin Golrezaei, Patrick Jaillet, Jason Cheuk Nam Liang, Vahab Mirrokni||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Individual+Welfare+Guarantees+in+the+Autobidding+World+with+Machine-learned+Advice)|0|
|[Non-uniform Bid-scaling and Equilibria for Different Auctions: An Empirical Study](https://doi.org/10.1145/3589334.3645659)|Yuan Deng, Jieming Mao, Vahab Mirrokni, Yifeng Teng, Song Zuo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Non-uniform+Bid-scaling+and+Equilibria+for+Different+Auctions:+An+Empirical+Study)|0|
|[A Similarity-based Approach for Efficient Large Quasi-clique Detection](https://doi.org/10.1145/3589334.3645374)|Jiayang Pang, Chenhao Ma, Yixiang Fang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Similarity-based+Approach+for+Efficient+Large+Quasi-clique+Detection)|0|
|[GraphControl: Adding Conditional Control to Universal Graph Pre-trained Models for Graph Domain Transfer Learning](https://doi.org/10.1145/3589334.3645439)|Yun Zhu, Yaoke Wang, Haizhou Shi, Zhenshuo Zhang, Dian Jiao, Siliang Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphControl:+Adding+Conditional+Control+to+Universal+Graph+Pre-trained+Models+for+Graph+Domain+Transfer+Learning)|0|
|[Rethinking Node-wise Propagation for Large-scale Graph Learning](https://doi.org/10.1145/3589334.3645450)|Xunkai Li, Jingyuan Ma, Zhengyu Wu, Daohan Su, Wentao Zhang, RongHua Li, Guoren Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rethinking+Node-wise+Propagation+for+Large-scale+Graph+Learning)|0|
|[Graph Contrastive Learning Reimagined: Exploring Universality](https://doi.org/10.1145/3589334.3645480)|Jiaming Zhuo, Can Cui, Kun Fu, Bingxin Niu, Dongxiao He, Chuan Wang, Yuanfang Guo, Zhen Wang, Xiaochun Cao, Liang Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Contrastive+Learning+Reimagined:+Exploring+Universality)|0|
|[MuGSI: Distilling GNNs with Multi-Granularity Structural Information for Graph Classification](https://doi.org/10.1145/3589334.3645542)|Tianjun Yao, Jiaqi Sun, Defu Cao, Kun Zhang, Guangyi Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MuGSI:+Distilling+GNNs+with+Multi-Granularity+Structural+Information+for+Graph+Classification)|0|
|[Efficient Computation for Diagonal of Forest Matrix via Variance-Reduced Forest Sampling](https://doi.org/10.1145/3589334.3645578)|Haoxin Sun, Zhongzhi Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Computation+for+Diagonal+of+Forest+Matrix+via+Variance-Reduced+Forest+Sampling)|0|
|[Decoupled Variational Graph Autoencoder for Link Prediction](https://doi.org/10.1145/3589334.3645601)|YoonSik Cho||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Decoupled+Variational+Graph+Autoencoder+for+Link+Prediction)|0|
|[ModelGo: A Practical Tool for Machine Learning License Analysis](https://doi.org/10.1145/3589334.3645520)|Moming Duan, Qinbin Li, Bingsheng He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ModelGo:+A+Practical+Tool+for+Machine+Learning+License+Analysis)|0|
|[Content Moderation and the Formation of Online Communities: A Theoretical Framework](https://doi.org/10.1145/3589334.3645490)|Cynthia Dwork, Chris Hays, Jon M. Kleinberg, Manish Raghavan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Content+Moderation+and+the+Formation+of+Online+Communities:+A+Theoretical+Framework)|0|
|[Getting Bored of Cyberwar: Exploring the Role of Low-level Cybercrime Actors in the Russia-Ukraine Conflict](https://doi.org/10.1145/3589334.3645401)|Anh V. Vu, Daniel R. Thomas, Ben Collier, Alice Hutchings, Richard Clayton, Ross J. Anderson||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Getting+Bored+of+Cyberwar:+Exploring+the+Role+of+Low-level+Cybercrime+Actors+in+the+Russia-Ukraine+Conflict)|0|
|[The Double Edged Sword: Identifying Authentication Pages and their Fingerprinting Behavior](https://doi.org/10.1145/3589334.3645493)|Asuman Senol, Alisha Ukani, Dylan Cutler, Igor Bilogrevic||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Double+Edged+Sword:+Identifying+Authentication+Pages+and+their+Fingerprinting+Behavior)|0|
|["Are Adversarial Phishing Webpages a Threat in Reality?" Understanding the Users' Perception of Adversarial Webpages](https://doi.org/10.1145/3589334.3645502)|Ying Yuan, Qingying Hao, Giovanni Apruzzese, Mauro Conti, Gang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q="Are+Adversarial+Phishing+Webpages+a+Threat+in+Reality?"+Understanding+the+Users'+Perception+of+Adversarial+Webpages)|0|
|[Hyperlink Hijacking: Exploiting Erroneous URL Links to Phantom Domains](https://doi.org/10.1145/3589334.3645510)|Kevin Saric, Felix Savins, Gowri Sankar Ramachandran, Raja Jurdak, Surya Nepal||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hyperlink+Hijacking:+Exploiting+Erroneous+URL+Links+to+Phantom+Domains)|0|
|[Fake Resume Attacks: Data Poisoning on Online Job Platforms](https://doi.org/10.1145/3589334.3645524)|Michiharu Yamashita, Thanh Tran, Dongwon Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fake+Resume+Attacks:+Data+Poisoning+on+Online+Job+Platforms)|0|
|[Identifying VPN Servers through Graph-Represented Behaviors](https://doi.org/10.1145/3589334.3645552)|Chenxu Wang, Jiangyi Yin, Zhao Li, Hongbo Xu, Zhongyi Zhang, Qingyun Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Identifying+VPN+Servers+through+Graph-Represented+Behaviors)|0|
|[Discovering and Measuring CDNs Prone to Domain Fronting](https://doi.org/10.1145/3589334.3645656)|Karthika Subramani, Roberto Perdisci, PierrosChristos Skafidas, Manos Antonakakis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Discovering+and+Measuring+CDNs+Prone+to+Domain+Fronting)|0|
|[Exploring Unconfirmed Transactions for Effective Bitcoin Address Clustering](https://doi.org/10.1145/3589334.3645684)|Kai Wang, Yakun Cheng, Michael Wen Tong, Zhenghao Niu, Jun Pang, Weili Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploring+Unconfirmed+Transactions+for+Effective+Bitcoin+Address+Clustering)|0|
|[AdFlush: A Real-World Deployable Machine Learning Solution for Effective Advertisement and Web Tracker Prevention](https://doi.org/10.1145/3589334.3645698)|Kiho Lee, Chaejin Lim, Beomjin Jin, Taeyoung Kim, Hyoungshick Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AdFlush:+A+Real-World+Deployable+Machine+Learning+Solution+for+Effective+Advertisement+and+Web+Tracker+Prevention)|0|
|[Fingerprinting the Shadows: Unmasking Malicious Servers with Machine Learning-Powered TLS Analysis](https://doi.org/10.1145/3589334.3645719)|Andreas Theofanous, Eva Papadogiannaki, Alexander Shevtsov, Sotiris Ioannidis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fingerprinting+the+Shadows:+Unmasking+Malicious+Servers+with+Machine+Learning-Powered+TLS+Analysis)|0|
|[Efficient Computation of Signature-Restricted Views for Semantic Web Ontologies](https://doi.org/10.1145/3589334.3645317)|Yizheng Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficient+Computation+of+Signature-Restricted+Views+for+Semantic+Web+Ontologies)|0|
|[Follow the Path: Hierarchy-Aware Extreme Multi-Label Completion for Semantic Text Tagging](https://doi.org/10.1145/3589334.3645558)|Natalia Ostapuk, Julien Audiffren, Ljiljana Dolamic, Alain Mermoud, Philippe CudréMauroux||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Follow+the+Path:+Hierarchy-Aware+Extreme+Multi-Label+Completion+for+Semantic+Text+Tagging)|0|
|[Multi-Label Zero-Shot Product Attribute-Value Extraction](https://doi.org/10.1145/3589334.3645649)|Jiaying Gong, Hoda Eldardiry||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Label+Zero-Shot+Product+Attribute-Value+Extraction)|0|
|[Aligning Out-of-Distribution Web Images and Caption Semantics via Evidential Learning](https://doi.org/10.1145/3589334.3645653)|Guohao Sun, Yue Bai, Xueying Yang, Yi Fang, Yun Fu, Zhiqiang Tao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Aligning+Out-of-Distribution+Web+Images+and+Caption+Semantics+via+Evidential+Learning)|0|
|[Deliberate Exposure to Opposing Views and Its Association with Behavior and Rewards on Political Communities](https://doi.org/10.1145/3589334.3645375)|Alexandros Efstratiou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deliberate+Exposure+to+Opposing+Views+and+Its+Association+with+Behavior+and+Rewards+on+Political+Communities)|0|
|[Invariant Graph Learning for Causal Effect Estimation](https://doi.org/10.1145/3589334.3645549)|Yongduo Sui, Caizhi Tang, Zhixuan Chu, Junfeng Fang, Yuan Gao, Qing Cui, Longfei Li, Jun Zhou, Xiang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Invariant+Graph+Learning+for+Causal+Effect+Estimation)|0|
|[Sublinear-Time Opinion Estimation in the Friedkin-Johnsen Model](https://doi.org/10.1145/3589334.3645572)|Stefan Neumann, Yinhao Dong, Pan Peng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sublinear-Time+Opinion+Estimation+in+the+Friedkin-Johnsen+Model)|0|
|[Bots, Elections, and Controversies: Twitter Insights from Brazil's Polarised Elections](https://doi.org/10.1145/3589334.3645651)|Diogo Pacheco||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bots,+Elections,+and+Controversies:+Twitter+Insights+from+Brazil's+Polarised+Elections)|0|
|[Scalable Continuous-time Diffusion Framework for Network Inference and Influence Estimation](https://doi.org/10.1145/3589334.3645652)|Keke Huang, Ruize Gao, Bogdan Cautis, Xiaokui Xiao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scalable+Continuous-time+Diffusion+Framework+for+Network+Inference+and+Influence+Estimation)|0|
|[Friend or Foe? Mining Suspicious Behavior via Graph Capsule Infomax Detector against Fraudsters](https://doi.org/10.1145/3589334.3645706)|Xiangping Zheng, Bo Wu, Xun Liang, Wei Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Friend+or+Foe?+Mining+Suspicious+Behavior+via+Graph+Capsule+Infomax+Detector+against+Fraudsters)|0|
|[PASS: Predictive Auto-Scaling System for Large-scale Enterprise Web Applications](https://doi.org/10.1145/3589334.3645330)|Yunda Guo, Jiake Ge, Panfeng Guo, Yunpeng Chai, Tao Li, Mengnan Shi, Yang Tu, Jian Ouyang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PASS:+Predictive+Auto-Scaling+System+for+Large-scale+Enterprise+Web+Applications)|0|
|[Unlocking the Non-deterministic Computing Power with Memory-Elastic Multi-Exit Neural Networks](https://doi.org/10.1145/3589334.3645340)|Jiaming Huang, Yi Gao, Wei Dong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unlocking+the+Non-deterministic+Computing+Power+with+Memory-Elastic+Multi-Exit+Neural+Networks)|0|
|[ZipZap: Efficient Training of Language Models for Large-Scale Fraud Detection on Blockchain](https://doi.org/10.1145/3589334.3645352)|Sihao Hu, Tiansheng Huang, KaHo Chow, Wenqi Wei, Yanzhao Wu, Ling Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ZipZap:+Efficient+Training+of+Language+Models+for+Large-Scale+Fraud+Detection+on+Blockchain)|0|
|[Cold Start or Hot Start? Robust Slow Start in Congestion Control with A Priori Knowledge for Mobile Web Services](https://doi.org/10.1145/3589334.3645393)|Jia Zhang, Haixuan Tong, Enhuan Dong, Xin Qian, Mingwei Xu, Xiaotian Li, Zili Meng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cold+Start+or+Hot+Start?+Robust+Slow+Start+in+Congestion+Control+with+A+Priori+Knowledge+for+Mobile+Web+Services)|0|
|[Investigations of Top-Level Domain Name Collisions in Blockchain Naming Services](https://doi.org/10.1145/3589334.3645459)|Daiki Ito, Yuta Takata, Hiroshi Kumagai, Masaki Kamizono||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Investigations+of+Top-Level+Domain+Name+Collisions+in+Blockchain+Naming+Services)|0|
|[Don't Bite Off More than You Can Chew: Investigating Excessive Permission Requests in Trigger-Action Integrations](https://doi.org/10.1145/3589334.3645721)|Liuhuo Wan, Kailong Wang, Kulani Mahadewa, Haoyu Wang, Guangdong Bai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Don't+Bite+Off+More+than+You+Can+Chew:+Investigating+Excessive+Permission+Requests+in+Trigger-Action+Integrations)|0|
|[Off-Policy Evaluation of Slate Bandit Policies via Optimizing Abstraction](https://doi.org/10.1145/3589334.3645343)|Haruka Kiyohara, Masahiro Nomura, Yuta Saito||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Off-Policy+Evaluation+of+Slate+Bandit+Policies+via+Optimizing+Abstraction)|0|
|[Long-term Off-Policy Evaluation and Learning](https://doi.org/10.1145/3589334.3645446)|Yuta Saito, Himan Abdollahpouri, Jesse Anderton, Ben Carterette, Mounia Lalmas||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Long-term+Off-Policy+Evaluation+and+Learning)|0|
|[Unified Uncertainty Estimation for Cognitive Diagnosis Models](https://doi.org/10.1145/3589334.3645488)|Fei Wang, Qi Liu, Enhong Chen, Chuanren Liu, Zhenya Huang, Jinze Wu, Shijin Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unified+Uncertainty+Estimation+for+Cognitive+Diagnosis+Models)|0|
|[A Cross Domain Method for Customer Lifetime Value Prediction in Supply Chain Platform](https://doi.org/10.1145/3589334.3645391)|Zhiyuan Zhou, Li Lin, Hai Wang, Xiaolei Zhou, Gong Wei, Shuai Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Cross+Domain+Method+for+Customer+Lifetime+Value+Prediction+in+Supply+Chain+Platform)|0|
|[UniTime: A Language-Empowered Unified Model for Cross-Domain Time Series Forecasting](https://doi.org/10.1145/3589334.3645434)|Xu Liu, Junfeng Hu, Yuan Li, Shizhe Diao, Yuxuan Liang, Bryan Hooi, Roger Zimmermann||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UniTime:+A+Language-Empowered+Unified+Model+for+Cross-Domain+Time+Series+Forecasting)|0|
|[Semantic Evolvement Enhanced Graph Autoencoder for Rumor Detection](https://doi.org/10.1145/3589334.3645478)|Xiang Tao, Liang Wang, Qiang Liu, Shu Wu, Liang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Semantic+Evolvement+Enhanced+Graph+Autoencoder+for+Rumor+Detection)|0|
|[Trajectory-wise Iterative Reinforcement Learning Framework for Auto-bidding](https://doi.org/10.1145/3589334.3645534)|Haoming Li, Yusen Huo, Shuai Dou, Zhenzhe Zheng, Zhilin Zhang, Chuan Yu, Jian Xu, Fan Wu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Trajectory-wise+Iterative+Reinforcement+Learning+Framework+for+Auto-bidding)|0|
|[Stable-Sketch: A Versatile Sketch for Accurate, Fast, Web-Scale Data Stream Processing](https://doi.org/10.1145/3589334.3645581)|Weihe Li, Paul Patras||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Stable-Sketch:+A+Versatile+Sketch+for+Accurate,+Fast,+Web-Scale+Data+Stream+Processing)|0|
|[Self-Paced Pairwise Representation Learning for Semi-Supervised Text Classification](https://doi.org/10.1145/3589334.3645664)|Junfan Chen, Richong Zhang, Jiarui Wang, Chunming Hu, Yongyi Mao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-Paced+Pairwise+Representation+Learning+for+Semi-Supervised+Text+Classification)|0|
|[Harnessing Multi-Role Capabilities of Large Language Models for Open-Domain Question Answering](https://doi.org/10.1145/3589334.3645670)|Hongda Sun, Yuxuan Liu, Chengwei Wu, Haiyu Yan, Cheng Tai, Xin Gao, Shuo Shang, Rui Yan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Harnessing+Multi-Role+Capabilities+of+Large+Language+Models+for+Open-Domain+Question+Answering)|0|
|[POLISH: Adaptive Online Cross-Modal Hashing for Class Incremental Data](https://doi.org/10.1145/3589334.3645716)|YuWei Zhan, Xin Luo, ZhenDuo Chen, Yongxin Wang, Yinwei Wei, XinShun Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=POLISH:+Adaptive+Online+Cross-Modal+Hashing+for+Class+Incremental+Data)|0|
|[How Contentious Terms About People and Cultures are Used in Linked Open Data](https://doi.org/10.1145/3589334.3648140)|Andrei Nesterov, Laura Hollink, Jacco van Ossenbruggen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+Contentious+Terms+About+People+and+Cultures+are+Used+in+Linked+Open+Data)|0|
|[MMAdapt: A Knowledge-guided Multi-source Multi-class Domain Adaptive Framework for Early Health Misinformation Detection](https://doi.org/10.1145/3589334.3648152)|Lanyu Shang, Yang Zhang, Bozhang Chen, Ruohan Zong, Zhenrui Yue, Huimin Zeng, Na Wei, Dong Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MMAdapt:+A+Knowledge-guided+Multi-source+Multi-class+Domain+Adaptive+Framework+for+Early+Health+Misinformation+Detection)|0|
|[LightCS: Selecting Quadratic Feature Crosses in Linear Complexity](https://doi.org/10.1145/3589335.3648300)|Zhaocheng Du, Junhao Chen, Qinglin Jia, Chuhan Wu, Jieming Zhu, Zhenhua Dong, Ruiming Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LightCS:+Selecting+Quadratic+Feature+Crosses+in+Linear+Complexity)|0|
|[SOIL: Score Conditioned Diffusion Model for Imbalanced Cloud Failure Prediction](https://doi.org/10.1145/3589335.3648303)|Chiming Duan, Fangkai Yang, Pu Zhao, Lingling Zheng, Yash Dagli, Yudong Liu, Qingwei Lin, Dongmei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SOIL:+Score+Conditioned+Diffusion+Model+for+Imbalanced+Cloud+Failure+Prediction)|0|
|[Dependency Aware Incident Linking in Large Cloud Systems](https://doi.org/10.1145/3589335.3648311)|Supriyo Ghosh, Karish Grover, Jimmy Wong, Chetan Bansal, Rakesh Namineni, Mohit Verma, Saravan Rajmohan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dependency+Aware+Incident+Linking+in+Large+Cloud+Systems)|0|
|[A Graph-based Framework for Reducing False Positives in Authentication Alerts in Security Systems](https://doi.org/10.1145/3589335.3648325)|Yanbang Wang, Karl Hallgren, Jonathan Larson||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Graph-based+Framework+for+Reducing+False+Positives+in+Authentication+Alerts+in+Security+Systems)|0|
|[FinReport: Explainable Stock Earnings Forecasting via News Factor Analyzing Model](https://doi.org/10.1145/3589335.3648330)|Xiangyu Li, Xinjie Shen, Yawen Zeng, Xiaofen Xing, Jin Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FinReport:+Explainable+Stock+Earnings+Forecasting+via+News+Factor+Analyzing+Model)|0|
|[DISKCO : Disentangling Knowledge from Cross-Encoder to Bi-Encoder](https://doi.org/10.1145/3589335.3648333)|Ankith M. S, Arindam Bhattacharya, Ankit Gandhi, Vijay Huddar, Atul Saroop, Rahul Bhagat||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DISKCO+:+Disentangling+Knowledge+from+Cross-Encoder+to+Bi-Encoder)|0|
|[Information Diffusion Meets Invitation Mechanism](https://doi.org/10.1145/3589335.3648337)|Shiqi Zhang, Jiachen Sun, Wenqing Lin, Xiaokui Xiao, Yiqian Huang, Bo Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Information+Diffusion+Meets+Invitation+Mechanism)|0|
|[The MMO Economist: AI Empowers Robust, Healthy, and Sustainable P2W MMO Economies](https://doi.org/10.1145/3589335.3648344)|Shiwei Zhao, Xi Yuan, Runze Wu, Zhipeng Hu, Haoyu Liu, Kai Wang, Yujing Hu, Tangjie Lv, Changjie Fan, Xin Tong, Jiangze Han, Yan Zheng, Jianye Hao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+MMO+Economist:+AI+Empowers+Robust,+Healthy,+and+Sustainable+P2W+MMO+Economies)|0|
|[Skewness-aware Boosting Regression Trees for Customer Contribution Prediction in Financial Precision Marketing](https://doi.org/10.1145/3589335.3648346)|HsinYu Chen, ChengTe Li, TingYu Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Skewness-aware+Boosting+Regression+Trees+for+Customer+Contribution+Prediction+in+Financial+Precision+Marketing)|0|
|[Can we Soft Prompt LLMs for Graph Learning Tasks?](https://doi.org/10.1145/3589335.3651476)|Zheyuan Liu, Xiaoxin He, Yijun Tian, Nitesh V. Chawla||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Can+we+Soft+Prompt+LLMs+for+Graph+Learning+Tasks?)|0|
|[Everything Perturbed All at Once: Enabling Differentiable Graph Attacks](https://doi.org/10.1145/3589335.3651501)|Haoran Liu, Bokun Wang, Jianling Wang, Xiangjue Dong, Tianbao Yang, James Caverlee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Everything+Perturbed+All+at+Once:+Enabling+Differentiable+Graph+Attacks)|0|
|[Unlink to Unlearn: Simplifying Edge Unlearning in GNNs](https://doi.org/10.1145/3589335.3651578)|Jiajun Tan, Fei Sun, Ruichen Qiu, Du Su, Huawei Shen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unlink+to+Unlearn:+Simplifying+Edge+Unlearning+in+GNNs)|0|
|[Near-duplicate Question Detection](https://doi.org/10.1145/3589335.3651538)|Preetam Prabhu Srikar Dammu, Omar Alonso||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Near-duplicate+Question+Detection)|0|
|[Tackling Long-Tail Entities for Temporal Knowledge Graph Completion](https://doi.org/10.1145/3589335.3651565)|Mehrnoosh Mirtaheri, Ryan A. Rossi, Sungchul Kim, Kanak Mahadik, Tong Yu, Xiang Chen, Mohammad Rostami||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tackling+Long-Tail+Entities+for+Temporal+Knowledge+Graph+Completion)|0|
|[From Creation to Clarification: ChatGPT's Journey Through the Fake News Quagmire](https://doi.org/10.1145/3589335.3651509)|Yue Huang, Kai Shu, Philip S. Yu, Lichao Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=From+Creation+to+Clarification:+ChatGPT's+Journey+Through+the+Fake+News+Quagmire)|0|
|[The Invisible Game on the Internet: A Case Study of Decoding Deceptive Patterns](https://doi.org/10.1145/3589335.3651571)|Zewei Shi, Ruoxi Sun, Jieshan Chen, Jiamou Sun, Minhui Xue||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Invisible+Game+on+the+Internet:+A+Case+Study+of+Decoding+Deceptive+Patterns)|0|
|[Improving Model Robustness against Adversarial Examples with Redundant Fully Connected Layer](https://doi.org/10.1145/3589335.3651524)|Ziming Zhao, Zhaoxuan Li, Tingting Li, Jiongchi Yu, Fan Zhang, Rui Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Model+Robustness+against+Adversarial+Examples+with+Redundant+Fully+Connected+Layer)|0|
|[Thought Graph: Generating Thought Process for Biological Reasoning](https://doi.org/10.1145/3589335.3651572)|ChiYang Hsu, Kyle Cox, Jiawei Xu, Zhen Tan, Tianhua Zhai, Mengzhou Hu, Dexter Pratt, Tianlong Chen, Ziniu Hu, Ying Ding||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Thought+Graph:+Generating+Thought+Process+for+Biological+Reasoning)|0|
|[On the Scale-Free Property of Citation Networks: An Empirical Study](https://doi.org/10.1145/3589335.3651541)|Xiaoshi Zhong, Huizhi Liang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+the+Scale-Free+Property+of+Citation+Networks:+An+Empirical+Study)|0|
|[Automatic Construction of Expiration Time Expression Dataset from Retweets](https://doi.org/10.1145/3589335.3651471)|Hirotaka Nagashima, Keishi Tajima||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automatic+Construction+of+Expiration+Time+Expression+Dataset+from+Retweets)|0|
|[Finding Dense and Persistently Expansive Subgraphs](https://doi.org/10.1145/3589335.3651507)|Petros Petsinis, Charalampos E. Tsourakakis, Panagiotis Karras||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Finding+Dense+and+Persistently+Expansive+Subgraphs)|0|
|[Hyperbolic Heterogeneous Graph Attention Networks](https://doi.org/10.1145/3589335.3651522)|Jongmin Park, Seunghoon Han, Soohwan Jeong, Sungsu Lim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hyperbolic+Heterogeneous+Graph+Attention+Networks)|0|
|[Task-Driven Quantum Device Fingerprint Identification via Modeling QNN Outcome Shift Induced by Quantum Noise](https://doi.org/10.1145/3589335.3651567)|Tingting Li, Ziming Zhao, Jianwei Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Task-Driven+Quantum+Device+Fingerprint+Identification+via+Modeling+QNN+Outcome+Shift+Induced+by+Quantum+Noise)|0|
|[News-Driven Price Movement Forecasting with Label-Prior Graph Attention](https://doi.org/10.1145/3589335.3651539)|YiTing Liu, ChungChi Chen, HenHsen Huang, HsinHsi Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=News-Driven+Price+Movement+Forecasting+with+Label-Prior+Graph+Attention)|0|
|[Enabling Patient-side Disease Prediction via the Integration of Patient Narratives](https://doi.org/10.1145/3589335.3651498)|Zhixiang Su, Yinan Zhang, Jiazheng Jing, Jie Xiao, Zhiqi Shen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enabling+Patient-side+Disease+Prediction+via+the+Integration+of+Patient+Narratives)|0|
|[LinkGuard: Link Locally Privacy-Preserving Graph Neural Networks with Integrated Denoising and Private Learning](https://doi.org/10.1145/3589335.3651533)|Yuxin Qi, Xi Lin, Ziyao Liu, Gaolei Li, Jingyu Wang, Jianhua Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LinkGuard:+Link+Locally+Privacy-Preserving+Graph+Neural+Networks+with+Integrated+Denoising+and+Private+Learning)|0|
|[Generator-Guided Crowd Reaction Assessment](https://doi.org/10.1145/3589335.3651512)|Sohom Ghosh, ChungChi Chen, Sudip Kumar Naskar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generator-Guided+Crowd+Reaction+Assessment)|0|
|[Hierarchical Tensor Clustering for Multiple Graphs Representation](https://doi.org/10.1145/3589335.3651519)|Karima Boutalbi, Rafika Boutalbi, Hervé Verjus, Kavé Salamatian||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Hierarchical+Tensor+Clustering+for+Multiple+Graphs+Representation)|0|
|[Smooth Anonymity for Sparse Graphs](https://doi.org/10.1145/3589335.3651561)|Alessandro Epasto, Hossein Esfandiari, Vahab Mirrokni, Andrés Muñoz Medina||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Smooth+Anonymity+for+Sparse+Graphs)|0|
|[Predicting Node Influence in Complex Networks by the K-Shell Entropy and Degree Centrality](https://doi.org/10.1145/3589335.3651547)|Shima Esfandiari, Mostafa Fakhrahmad||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Predicting+Node+Influence+in+Complex+Networks+by+the+K-Shell+Entropy+and+Degree+Centrality)|0|
|[Knowledge Induced Transformer Network for Causality Prediction](https://doi.org/10.1145/3589335.3651531)|Tirthankar Dasgupta, Manjira Sinha, Abir Naskar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge+Induced+Transformer+Network+for+Causality+Prediction)|0|
|[MetroGNN: Metro Network Expansion with Reinforcement Learning](https://doi.org/10.1145/3589335.3651536)|Hongyuan Su, Yu Zheng, Jingtao Ding, Depeng Jin, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MetroGNN:+Metro+Network+Expansion+with+Reinforcement+Learning)|0|
|[Breaking the Bot Barrier: Evaluating Adversarial AI Techniques Against Multi-Modal Defense Models](https://doi.org/10.1145/3589335.3651474)|Behzad Ousat, Dongsheng Luo, Amin Kharraz||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Breaking+the+Bot+Barrier:+Evaluating+Adversarial+AI+Techniques+Against+Multi-Modal+Defense+Models)|0|
|[RealGraphGPU++: A High-Performance GPU-Based Graph Engine with Direct Storage-to-DM IO](https://doi.org/10.1145/3589335.3651549)|JeongMin Park, MyungHwan Jang, DuckHo Bae, SangWook Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RealGraphGPU++:+A+High-Performance+GPU-Based+Graph+Engine+with+Direct+Storage-to-DM+IO)|0|
|[A Study of Vulnerability Repair in JavaScript Programs with Large Language Models](https://doi.org/10.1145/3589335.3651463)|Tan Khang Le, Saba Alimadadi, Steven Y. Ko||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Study+of+Vulnerability+Repair+in+JavaScript+Programs+with+Large+Language+Models)|0|
|[Deanonymizing Transactions Originating from Monero Tor Hidden Service Nodes](https://doi.org/10.1145/3589335.3651487)|Ruisheng Shi, Yulian Ge, Lina Lan, Zhiyuan Peng, Shenwen Lin, Lin Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Deanonymizing+Transactions+Originating+from+Monero+Tor+Hidden+Service+Nodes)|0|
|[WebGraph: The Next Generation (Is in Rust)](https://doi.org/10.1145/3589335.3651581)|Tommaso Fontana, Sebastiano Vigna, Stefano Zacchiroli||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=WebGraph:+The+Next+Generation+(Is+in+Rust))|0|
|[GradFilt: Class-wise Targeted Data Reconstruction from Gradients in Federated Learning](https://doi.org/10.1145/3589335.3651514)|Rui Zhang, Song Guo, Ping Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GradFilt:+Class-wise+Targeted+Data+Reconstruction+from+Gradients+in+Federated+Learning)|0|
|[Advancing Stance Detection of Political Fan Pages: A Multimodal Approach](https://doi.org/10.1145/3589335.3651467)|KuanHung Kuo, MingHung Wang, HungYu Kao, YuChen Dai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Advancing+Stance+Detection+of+Political+Fan+Pages:+A+Multimodal+Approach)|0|
|[Structural Podcast Content Modeling with Generalizability](https://doi.org/10.1145/3589335.3651563)|Yijun Tian, Maryam Aziz, Alice Wang, Enrico Palumbo, Hugues Bouchard||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Structural+Podcast+Content+Modeling+with+Generalizability)|0|
|[Detecting Poisoning Attacks on Federated Learning Using Gradient-Weighted Class Activation Mapping](https://doi.org/10.1145/3589335.3651490)|Jingjing Zheng, Kai Li, Xin Yuan, Wei Ni, Eduardo Tovar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Detecting+Poisoning+Attacks+on+Federated+Learning+Using+Gradient-Weighted+Class+Activation+Mapping)|0|
|[Fighting against Fake News on Newly-Emerging Crisis: A Case Study of COVID-19](https://doi.org/10.1145/3589335.3651506)|Migyeong Yang, Chaewon Park, Jiwon Kang, Daeun Lee, Daejin Choi, Jinyoung Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fighting+against+Fake+News+on+Newly-Emerging+Crisis:+A+Case+Study+of+COVID-19)|0|
|[Targeted Filter Bubbles Mitigating via Edges Insertion](https://doi.org/10.1145/3589335.3651566)|Yanping Wu, Jinghao Wang, Renjie Sun, Chen Chen, Xiaoyang Wang, Ying Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Targeted+Filter+Bubbles+Mitigating+via+Edges+Insertion)|0|
|[Unveiling Wash Trading in Popular NFT Markets](https://doi.org/10.1145/3589335.3651580)|Yuanzheng Niu, Xiaoqi Li, Hongli Peng, Wenkai Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unveiling+Wash+Trading+in+Popular+NFT+Markets)|0|
|[Understanding Deployment Experience of 5G](https://doi.org/10.1145/3589335.3651577)|Ziyi Liu, Huandong Wang, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+Deployment+Experience+of+5G)|0|
|[FaST: Accelerating Web Front-end Data Binding with Compiler and Visible Anchor](https://doi.org/10.1145/3589335.3651505)|Tatsuru Tomizawa, Seiki Makino, Taiga Kume, Satoki Hamanaka, Tadashi Okoshi, Jin Nakazawa||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FaST:+Accelerating+Web+Front-end+Data+Binding+with+Compiler+and+Visible+Anchor)|0|
|[How We Refute Claims: Automatic Fact-Checking through Flaw Identification and Explanation](https://doi.org/10.1145/3589335.3651521)|WeiYu Kao, AnZi Yen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+We+Refute+Claims:+Automatic+Fact-Checking+through+Flaw+Identification+and+Explanation)|0|
|[Characterizing the Solana NFT Ecosystem](https://doi.org/10.1145/3589335.3651478)|Dechao Kong, Xiaoqi Li, Wenkai Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Characterizing+the+Solana+NFT+Ecosystem)|0|
|[Multi-round Counterfactual Generation: Interpreting and Improving Models of Text Classification](https://doi.org/10.1145/3589335.3651537)|Huajie Zhang, Yuxin Ying, Fuzhen Zhuang, Haiqin Weng, Sun Ying, Zhao Zhang, Yiqi Tong, Yan Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-round+Counterfactual+Generation:+Interpreting+and+Improving+Models+of+Text+Classification)|0|
|[iSpLib: A Library for Accelerating Graph Neural Networks using Auto-tuned Sparse Operations](https://doi.org/10.1145/3589335.3651528)|Md Saidul Hoque Anik, Pranav Badhe, Rohit Gampa, Ariful Azad||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=iSpLib:+A+Library+for+Accelerating+Graph+Neural+Networks+using+Auto-tuned+Sparse+Operations)|0|
|[DeFiTail: DeFi Protocol Inspection through Cross-Contract Execution Analysis](https://doi.org/10.1145/3589335.3651488)|Wenkai Li, Xiaoqi Li, Yuqing Zhang, Zongwei Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DeFiTail:+DeFi+Protocol+Inspection+through+Cross-Contract+Execution+Analysis)|0|
|[Are we Making Much Progress? Revisiting Chemical Reaction Yield Prediction from an Imbalanced Regression Perspective](https://doi.org/10.1145/3589335.3651470)|Yihong Ma, Xiaobao Huang, Bozhao Nan, Nuno Moniz, Xiangliang Zhang, Olaf Wiest, Nitesh V. Chawla||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Are+we+Making+Much+Progress?+Revisiting+Chemical+Reaction+Yield+Prediction+from+an+Imbalanced+Regression+Perspective)|0|
|[Simple Multigraph Convolution Networks](https://doi.org/10.1145/3589335.3651560)|Danyang Wu, Xinjie Shen, Jitao Lu, Jin Xu, Feiping Nie||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Simple+Multigraph+Convolution+Networks)|0|
|[Robust Federated Learning Mitigates Client-side Training Data Distribution Inference Attacks](https://doi.org/10.1145/3589335.3651555)|Yichang Xu, Ming Yin, Minghong Fang, Neil Zhenqiang Gong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Federated+Learning+Mitigates+Client-side+Training+Data+Distribution+Inference+Attacks)|0|
|[Group-wise K-anonymity meets (ε, δ) Differentially Privacy Scheme](https://doi.org/10.1145/3589335.3651517)|Kenneth Odoh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Group-wise+K-anonymity+meets+(ε,+δ)+Differentially+Privacy+Scheme)|0|
|[Generating Privacy-preserving Educational Data Records with Diffusion Model](https://doi.org/10.1145/3589335.3651511)|Quanlong Guan, Yanchong Yu, Xiujie Huang, Liangda Fang, Chaobo He, Lusheng Wu, Weiqi Luo, Guanliang Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generating+Privacy-preserving+Educational+Data+Records+with+Diffusion+Model)|0|
|[StateGuard: Detecting State Derailment Defects in Decentralized Exchange Smart Contract](https://doi.org/10.1145/3589335.3651562)|Zongwei Li, Wenkai Li, Xiaoqi Li, Yuqing Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=StateGuard:+Detecting+State+Derailment+Defects+in+Decentralized+Exchange+Smart+Contract)|0|
|[Rumor Mitigation in Social Media Platforms with Deep Reinforcement Learning](https://doi.org/10.1145/3589335.3651556)|Hongyuan Su, Yu Zheng, Jingtao Ding, Depeng Jin, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Rumor+Mitigation+in+Social+Media+Platforms+with+Deep+Reinforcement+Learning)|0|
|[SWATTING Spambots: Real-time Detection of Malicious Bots on X](https://doi.org/10.1145/3589335.3651564)|Cristian Brokate, Manon Richard, Lisa Giordani, Jean Liénard||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SWATTING+Spambots:+Real-time+Detection+of+Malicious+Bots+on+X)|0|
|[One-shot Pairing and Authentication Using Moms Secret](https://doi.org/10.1145/3589335.3651542)|Ubaid Ur Rehman, Sungyoung Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=One-shot+Pairing+and+Authentication+Using+Moms+Secret)|0|
|[GPT-generated Text Detection: Benchmark Dataset and Tensor-based Detection Method](https://doi.org/10.1145/3589335.3651513)|Zubair Qazi, William Shiao, Evangelos E. Papalexakis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GPT-generated+Text+Detection:+Benchmark+Dataset+and+Tensor-based+Detection+Method)|0|
|[Knowledge Guided Conditional Diffusion Model for Controllable Mobile Traffic Generation](https://doi.org/10.1145/3589335.3651530)|Haoye Chai, Tong Li, Fenyu Jiang, Shiyuan Zhang, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge+Guided+Conditional+Diffusion+Model+for+Controllable+Mobile+Traffic+Generation)|0|
|[Critical Nodes Detection: Node Merging Approach](https://doi.org/10.1145/3589335.3651485)|Hongbo Qiu, Renjie Sun, Chen Chen, Xiaoyang Wang, Ying Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Critical+Nodes+Detection:+Node+Merging+Approach)|0|
|[Dual-level Hypergraph Contrastive Learning with Adaptive Temperature Enhancement](https://doi.org/10.1145/3589335.3651493)|Yiyue Qian, Tianyi Ma, Chuxu Zhang, Yanfang Ye||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dual-level+Hypergraph+Contrastive+Learning+with+Adaptive+Temperature+Enhancement)|0|
|[Towards Understanding Crypto-Asset Risks on Ethereum Caused by Key Leakage on the Internet](https://doi.org/10.1145/3589335.3651573)|Yuxuan Zhou, Jiaqi Chen, Yibo Wang, Yuzhe Tang, Guofei Gu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Understanding+Crypto-Asset+Risks+on+Ethereum+Caused+by+Key+Leakage+on+the+Internet)|0|
|[Turning A Curse into A Blessing: Data-Aware Memory-Efficient Training of Graph Neural Networks by Dynamic Exiting](https://doi.org/10.1145/3589335.3651575)|Yan Han, Kaiqi Chen, Shan Li, Ji Yan, Baoxu Shi, Lei Zhang, Fei Chen, Jaewon Yang, Yunpeng Xu, Xiaoqiang Luo, Qi He, Ying Ding, Zhangyang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Turning+A+Curse+into+A+Blessing:+Data-Aware+Memory-Efficient+Training+of+Graph+Neural+Networks+by+Dynamic+Exiting)|0|
|[A Heterogeneous Network fused with Context-aware Contrastive Learning for Sarcasm Topic-Target Pair Identification](https://doi.org/10.1145/3589335.3651462)|Minjie Yuan, Mengyu Xiang, Yuxuan Song, Qiudan Li, Jinye Fu, Daniel Dajun Zeng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Heterogeneous+Network+fused+with+Context-aware+Contrastive+Learning+for+Sarcasm+Topic-Target+Pair+Identification)|0|
|[Disentangled Anomaly Detection For Multivariate Time Series](https://doi.org/10.1145/3589335.3651492)|Xin Jie, Xixi Zhou, Chanfei Su, Zijun Zhou, Yuqing Yuan, Jiajun Bu, Haishuai Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Disentangled+Anomaly+Detection+For+Multivariate+Time+Series)|0|
|[Content Moderation on Social Media in the EU: Insights From the DSA Transparency Database](https://doi.org/10.1145/3589335.3651482)|Chiara Patricia Drolsbach, Nicolas Pröllochs||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Content+Moderation+on+Social+Media+in+the+EU:+Insights+From+the+DSA+Transparency+Database)|0|
|[Object-level Copy-Move Forgery Image Detection based on Inconsistency Mining](https://doi.org/10.1145/3589335.3651540)|Jingyu Wang, Niantai Jing, Ziyao Liu, Jie Nie, Yuxin Qi, ChiHung Chi, KwokYan Lam||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Object-level+Copy-Move+Forgery+Image+Detection+based+on+Inconsistency+Mining)|0|
|[Efficacy of Large Language Models in Predicting Hindi Movies' Attributes: A Comprehensive Survey and Content-Based Analysis](https://doi.org/10.1145/3589335.3651496)|Prabir Mondal, Siddharth Singh, Kushum, Sriparna Saha, Jyoti Prakash Singh, Brijraj Singh, Niranjan Pedanekar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficacy+of+Large+Language+Models+in+Predicting+Hindi+Movies'+Attributes:+A+Comprehensive+Survey+and+Content-Based+Analysis)|0|
|[Interpretation-Empowered Neural Cleanse for Backdoor Attacks](https://doi.org/10.1145/3589335.3651525)|Liangbo Ning, Zeyu Dai, Jingran Su, Chao Pan, Luning Wang, Wenqi Fan, Qing Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interpretation-Empowered+Neural+Cleanse+for+Backdoor+Attacks)|0|
|[Who is Creating Malware Repositories on GitHub and Why?](https://doi.org/10.1145/3589335.3651582)|Nishat Ara Tania, Md Rayhanul Masud, Md Omar Faruk Rokon, Qian Zhang, Michalis Faloutsos||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Who+is+Creating+Malware+Repositories+on+GitHub+and+Why?)|0|
|[Zero-shot Explainable Mental Health Analysis on Social Media by Incorporating Mental Scales](https://doi.org/10.1145/3589335.3651584)|Wenyu Li, Yinuo Zhu, Xin Lin, Ming Li, Ziyue Jiang, Ziqian Zeng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Zero-shot+Explainable+Mental+Health+Analysis+on+Social+Media+by+Incorporating+Mental+Scales)|0|
|[MART: Learning Hierarchical Music Audio Representations with Part-Whole Transformer](https://doi.org/10.1145/3589335.3651535)|Dong Yao, Jieming Zhu, Jiahao Xun, Shengyu Zhang, Zhou Zhao, Liqun Deng, Wenqiao Zhang, Zhenhua Dong, Xin Jiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MART:+Learning+Hierarchical+Music+Audio+Representations+with+Part-Whole+Transformer)|0|
|[Exploiting Associations among Multi-Aspect Node Properties in Heterogeneous Graphs for Link Prediction](https://doi.org/10.1145/3589335.3651502)|Chenguang Du, Hao Geng, Deqing Wang, Fuzhen Zhuang, Zhiqiang Zhang, Lanshan Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exploiting+Associations+among+Multi-Aspect+Node+Properties+in+Heterogeneous+Graphs+for+Link+Prediction)|0|
|[Automating the Information Extraction from Semi-Structured Interview Transcripts](https://doi.org/10.1145/3589335.3651230)|Angelina Parfenova Lucerne||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automating+the+Information+Extraction+from+Semi-Structured+Interview+Transcripts)|0|
|[FashionReGen: LLM-Empowered Fashion Report Generation](https://doi.org/10.1145/3589335.3651232)|Yujuan Ding, Yunshan Ma, Wenqi Fan, Yige Yao, TatSeng Chua, Qing Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FashionReGen:+LLM-Empowered+Fashion+Report+Generation)|0|
|[Tender Document Analyzer with the Combination of Supervised Learning and LLM-based Improver](https://doi.org/10.1145/3589335.3651233)|Tomoki Ito, Shun Nakagawa||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tender+Document+Analyzer+with+the+Combination+of+Supervised+Learning+and+LLM-based+Improver)|0|
|[GRACE: Generating Cause and Effect of Disaster Sub-Events from Social Media Text](https://doi.org/10.1145/3589335.3651234)|Xinxi Jiang, Xiang Li, Qifeng Zhou, Qing Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GRACE:+Generating+Cause+and+Effect+of+Disaster+Sub-Events+from+Social+Media+Text)|0|
|[RealGraphGPUWeb: A Convenient and Efficient GPU-Based Graph Analysis Platform on the Web](https://doi.org/10.1145/3589335.3651237)|JeongMin Park, MyungHwan Jang, SangWook Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RealGraphGPUWeb:+A+Convenient+and+Efficient+GPU-Based+Graph+Analysis+Platform+on+the+Web)|0|
|[BoostER: Leveraging Large Language Models for Enhancing Entity Resolution](https://doi.org/10.1145/3589335.3651245)|Huahang Li, Shuangyin Li, Fei Hao, Chen Jason Zhang, Yuanfeng Song, Lei Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BoostER:+Leveraging+Large+Language+Models+for+Enhancing+Entity+Resolution)|0|
|[Scenario-Driven Cyber-Physical-Social System: Intelligent Workflow Generation Based on Capability](https://doi.org/10.1145/3589335.3651246)|Yi Li, Xinkui Zhao, Chen Chen, Shengye Pang, Zhengyang Zhou, Jianwei Yin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Scenario-Driven+Cyber-Physical-Social+System:+Intelligent+Workflow+Generation+Based+on+Capability)|0|
|[REAL-UP: Urban Perceptions From LBSNs Helping Moving Real-Estate Market to the Next Level](https://doi.org/10.1145/3589335.3651252)|Frances Albert Santos, Thiago H. Silva, Leandro A. Villas||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=REAL-UP:+Urban+Perceptions+From+LBSNs+Helping+Moving+Real-Estate+Market+to+the+Next+Level)|0|
|[The Web Data Commons Schema.org Table Corpora](https://doi.org/10.1145/3589335.3651441)|Ralph Peeters, Alexander Brinkmann, Christian Bizer||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Web+Data+Commons+Schema.org+Table+Corpora)|0|
|[Tel2Veh: Fusion of Telecom Data and Vehicle Flow to Predict Camera-Free Traffic via a Spatio-Temporal Framework](https://doi.org/10.1145/3589335.3651442)|ChungYi Lin, ShenLung Tung, HungTing Su, Winston H. Hsu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Tel2Veh:+Fusion+of+Telecom+Data+and+Vehicle+Flow+to+Predict+Camera-Free+Traffic+via+a+Spatio-Temporal+Framework)|0|
|[An Open Platform for Quality Measures in a Linked Data Index](https://doi.org/10.1145/3589335.3651443)|Pierre Maillot, Jennie Andersen, Sylvie Cazalens, Catherine Faron, Fabien Gandon, Philippe Lamarre, Franck Michel||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Open+Platform+for+Quality+Measures+in+a+Linked+Data+Index)|0|
|[CompMix: A Benchmark for Heterogeneous Question Answering](https://doi.org/10.1145/3589335.3651444)|Philipp Christmann, Rishiraj Saha Roy, Gerhard Weikum||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CompMix:+A+Benchmark+for+Heterogeneous+Question+Answering)|0|
|[Can LLM Substitute Human Labeling? A Case Study of Fine-grained Chinese Address Entity Recognition Dataset for UAV Delivery](https://doi.org/10.1145/3589335.3651446)|Yuxuan Yao, Sichun Luo, Haohan Zhao, Guanzhi Deng, Linqi Song||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Can+LLM+Substitute+Human+Labeling?+A+Case+Study+of+Fine-grained+Chinese+Address+Entity+Recognition+Dataset+for+UAV+Delivery)|0|
|[Graphameleon: Relational Learning and Anomaly Detection on Web Navigation Traces Captured as Knowledge Graphs](https://doi.org/10.1145/3589335.3651447)|Lionel Tailhardat, Benjamin Stach, Yoan Chabot, Raphaël Troncy||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graphameleon:+Relational+Learning+and+Anomaly+Detection+on+Web+Navigation+Traces+Captured+as+Knowledge+Graphs)|0|
|[Revisiting 30 years of the Network Time Protocol](https://doi.org/10.1145/3589335.3651998)|Simon S. Woo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revisiting+30+years+of+the+Network+Time+Protocol)|0|
|[Toward Making Opaque Web Content More Accessible: Accessibility From Adobe Flash to Canvas-Rendered Apps](https://doi.org/10.1145/3589335.3651999)|Thomas Steiner||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Toward+Making+Opaque+Web+Content+More+Accessible:+Accessibility+From+Adobe+Flash+to+Canvas-Rendered+Apps)|0|
|[History in Making: Political Campaigns in the Era of Artificial Intelligence-Generated Content](https://doi.org/10.1145/3589335.3652000)|Ehsan ul Haq, Yiming Zhu, Pan Hui, Gareth Tyson||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=History+in+Making:+Political+Campaigns+in+the+Era+of+Artificial+Intelligence-Generated+Content)|0|
|[Me, the Web and Digital Accessibility](https://doi.org/10.1145/3589335.3652002)|Reinaldo Ferraz||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Me,+the+Web+and+Digital+Accessibility)|0|
|[A Non-Intrusive Approach to Assessing Dysarthria Severity: Advancing Clinical Diagnosis](https://doi.org/10.1145/3589335.3651449)|Ganjun Liu, Xiaohui Hou, Meng Ge, Tao Zhang, Haizhou Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Non-Intrusive+Approach+to+Assessing+Dysarthria+Severity:+Advancing+Clinical+Diagnosis)|0|
|[AI-based Prediction of Catheter-related Thrombosis Risk for Cancer Patients](https://doi.org/10.1145/3589335.3651452)|Yaoqi Guo, Yun Ma, Zijian Shao, Weichen Bi, Yanfeng Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AI-based+Prediction+of+Catheter-related+Thrombosis+Risk+for+Cancer+Patients)|0|
|[Health CLIP: Depression Rate Prediction Using Health Related Features in Satellite and Street View Images](https://doi.org/10.1145/3589335.3651451)|Tianjian Ouyang, Xin Zhang, Zhenyu Han, Yu Shang, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Health+CLIP:+Depression+Rate+Prediction+Using+Health+Related+Features+in+Satellite+and+Street+View+Images)|0|
|[AI in Health and Social Care: A Methodology for Privacy Risk Modeling and Simulation](https://doi.org/10.1145/3589335.3651453)|Laura Carmichael, Steve Taylor, Adriane Chapman, Michael J. Boniface||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AI+in+Health+and+Social+Care:+A+Methodology+for+Privacy+Risk+Modeling+and+Simulation)|0|
|[Sociotechnical Considerations for Accessibility and Equity in AI for Healthcare](https://doi.org/10.1145/3589335.3651455)|Adriane Chapman, Chloe L. Harrison, Caroline Jones, James Thornton, Rose Worley, Jeremy C. Wyatt||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Sociotechnical+Considerations+for+Accessibility+and+Equity+in+AI+for+Healthcare)|0|
|[Uncertainty-Aware Pre-Trained Foundation Models for Patient Risk Prediction via Gaussian Process](https://doi.org/10.1145/3589335.3651456)|Jiaying Lu, Shifan Zhao, Wenjing Ma, Hui Shao, Xiao Hu, Yuanzhe Xi, Carl Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Uncertainty-Aware+Pre-Trained+Foundation+Models+for+Patient+Risk+Prediction+via+Gaussian+Process)|0|
|[Enhancing Progressive Diagnosis Prediction in Healthcare with Continuous Normalizing Flows](https://doi.org/10.1145/3589335.3651457)|Yanchao Tan, Hengyu Zhang, Zihao Zhou, Guofang Ma, Fan Wang, Weiming Liu, Xinting Liao, Vicki Stover Hertzberg, Carl Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Enhancing+Progressive+Diagnosis+Prediction+in+Healthcare+with+Continuous+Normalizing+Flows)|0|
|[Improving Prostate Cancer Risk Prediction through Partial AUC Optimization](https://doi.org/10.1145/3589335.3651458)|Xinyuan Zhu, Xiaohan Ren, Wentao Shi, Changming Wang, Xuehan Liu, Yuqing Liu, Tao Tao, Fuli Feng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Improving+Prostate+Cancer+Risk+Prediction+through+Partial+AUC+Optimization)|0|
|[Distributed Transparent Data Layer for Next Generation Blockchains](https://doi.org/10.1145/3589335.3651255)|Li Quan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Distributed+Transparent+Data+Layer+for+Next+Generation+Blockchains)|0|
|[Temporal Knowledge Graph Extraction and Modeling across Multiple Documents for Health Risk Prediction](https://doi.org/10.1145/3589335.3651256)|Rochana Chaturvedi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Temporal+Knowledge+Graph+Extraction+and+Modeling+across+Multiple+Documents+for+Health+Risk+Prediction)|0|
|[When Crypto Economics Meet Graph Analytics and Learning](https://doi.org/10.1145/3589335.3651257)|Bingqiao Luo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=When+Crypto+Economics+Meet+Graph+Analytics+and+Learning)|0|
|[Comprehensively Auditing the TikTok Mobile App](https://doi.org/10.1145/3589335.3651260)|Levi Kaplan, Piotr Sapiezynski||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Comprehensively+Auditing+the+TikTok+Mobile+App)|0|
|[Outgroup Dehumanisation in Telegram - the Role of Ingroup Identity and Perception](https://doi.org/10.1145/3589335.3651261)|Elizaveta Chernenko||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Outgroup+Dehumanisation+in+Telegram+-+the+Role+of+Ingroup+Identity+and+Perception)|0|
|[Leveraging Knowledge-aware Methodologies for Multi-document Summarization](https://doi.org/10.1145/3589335.3651262)|Yutong Qu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Knowledge-aware+Methodologies+for+Multi-document+Summarization)|0|
|[Knowledge Enabled Relation Extraction](https://doi.org/10.1145/3589335.3651263)|Monika Jain||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Knowledge+Enabled+Relation+Extraction)|0|
|[Graph Unlearning with Efficient Partial Retraining](https://doi.org/10.1145/3589335.3651265)|Jiahao Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Unlearning+with+Efficient+Partial+Retraining)|0|
|[Incentives in the Ether: Practical Cryptocurrency Economics & Security](https://doi.org/10.1145/3589335.3651268)|Aviv Yaish||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Incentives+in+the+Ether:+Practical+Cryptocurrency+Economics+&+Security)|0|
|[Social Psychology Meets Social Computing: State of the Art and Future Directions](https://doi.org/10.1145/3589335.3641242)|Sourav S. Bhowmick, Hui Li, S. H. Annabel Chen, Yining Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Social+Psychology+Meets+Social+Computing:+State+of+the+Art+and+Future+Directions)|0|
|[Discrete Choice and Applications](https://doi.org/10.1145/3589335.3641244)|Flavio Chierichetti, Ravi Kumar, Andrew Tomkins||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Discrete+Choice+and+Applications)|0|
|[Mining Temporal Networks](https://doi.org/10.1145/3589335.3641245)|Aristides Gionis, Lutz Oettershagen, Ilie Sarpe||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mining+Temporal+Networks)|0|
|[Lecture-style Tutorial: Towards Graph Foundation Models](https://doi.org/10.1145/3589335.3641246)|Chuan Shi, Cheng Yang, Yuan Fang, Lichao Sun, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Lecture-style+Tutorial:+Towards+Graph+Foundation+Models)|0|
|[Understanding (Dark) Humour with Internet Meme Analysis](https://doi.org/10.1145/3589335.3641249)|Ming Shan Hee, Rui Cao, Tanmoy Chakraborty, Roy KaWei Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+(Dark)+Humour+with+Internet+Meme+Analysis)|0|
|[Privacy in Web Advertising: Analytics and Modeling](https://doi.org/10.1145/3589335.3641252)|Badih Ghazi, Ravi Kumar, Pasin Manurangsi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Privacy+in+Web+Advertising:+Analytics+and+Modeling)|0|
|[Large Language Models for Graphs: Progresses and Directions](https://doi.org/10.1145/3589335.3641251)|Chao Huang, Xubin Ren, Jiabin Tang, Dawei Yin, Nitesh V. Chawla||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large+Language+Models+for+Graphs:+Progresses+and+Directions)|0|
|[New Frontiers of Knowledge Graph Reasoning: Recent Advances and Future Trends](https://doi.org/10.1145/3589335.3641254)|Lihui Liu, Zihao Wang, Jiaxin Bai, Yangqiu Song, Hanghang Tong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=New+Frontiers+of+Knowledge+Graph+Reasoning:+Recent+Advances+and+Future+Trends)|0|
|[Simulating Human Society with Large Language Model Agents: City, Social Media, and Economic System](https://doi.org/10.1145/3589335.3641253)|Chen Gao, Fengli Xu, Xu Chen, Xiang Wang, Xiangnan He, Yong Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Simulating+Human+Society+with+Large+Language+Model+Agents:+City,+Social+Media,+and+Economic+System)|0|
|[Text-Attributed Graph Representation Learning: Methods, Applications, and Challenges](https://doi.org/10.1145/3589335.3641255)|Delvin Ce Zhang, Menglin Yang, Rex Ying, Hady W. Lauw||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Text-Attributed+Graph+Representation+Learning:+Methods,+Applications,+and+Challenges)|0|
|[Toward Mitigating Misinformation and Social Media Manipulation in LLM Era](https://doi.org/10.1145/3589335.3641256)|Yizhou Zhang, Karishma Sharma, Lun Du, Yan Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Toward+Mitigating+Misinformation+and+Social+Media+Manipulation+in+LLM+Era)|0|
|[Curriculum Learning: Theories, Approaches, Applications, Tools, and Future Directions in the Era of Large Language Models](https://doi.org/10.1145/3589335.3641257)|Xin Wang, Yuwei Zhou, Hong Chen, Wenwu Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Curriculum+Learning:+Theories,+Approaches,+Applications,+Tools,+and+Future+Directions+in+the+Era+of+Large+Language+Models)|0|
|[English Prompts are Better for NLI-based Zero-Shot Emotion Classification than Target-Language Prompts](https://doi.org/10.1145/3589335.3651902)|Patrick Bareiß, Roman Klinger, Jeremy Barnes||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=English+Prompts+are+Better+for+NLI-based+Zero-Shot+Emotion+Classification+than+Target-Language+Prompts)|0|
|[Towards Invariant Time Series Forecasting in Smart Cities](https://doi.org/10.1145/3589335.3651897)|Ziyi Zhang, Shaogang Ren, Xiaoning Qian, Nick Duffield||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Invariant+Time+Series+Forecasting+in+Smart+Cities)|0|
|[Open Metaverse: Issues, Evolution, and Future](https://doi.org/10.1145/3589335.3651898)|Zefeng Chen, Wensheng Gan, Jiayi Sun, Jiayang Wu, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Open+Metaverse:+Issues,+Evolution,+and+Future)|0|
|[Homogenizing Data Flows in Smart Cities: Value-driven use Cases in the Era of Citiverse](https://doi.org/10.1145/3589335.3651900)|Leonidas G. Anthopoulos, Ioannis Nikolaou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Homogenizing+Data+Flows+in+Smart+Cities:+Value-driven+use+Cases+in+the+Era+of+Citiverse)|0|
|[Spatio-Temporal Challenges in Understanding your (Smart) City](https://doi.org/10.1145/3589335.3652580)|Dirk Ahlers||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spatio-Temporal+Challenges+in+Understanding+your+(Smart)+City)|0|
|[A Longitudinal Study of Content Control Mechanisms](https://doi.org/10.1145/3589335.3651893)|Michael Dinzinger, Michael Granitzer||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Longitudinal+Study+of+Content+Control+Mechanisms)|0|
|[TIQ: A Benchmark for Temporal Question Answering with Implicit Time Constraints](https://doi.org/10.1145/3589335.3651895)|Zhen Jia, Philipp Christmann, Gerhard Weikum||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=TIQ:+A+Benchmark+for+Temporal+Question+Answering+with+Implicit+Time+Constraints)|0|
|[Attentive Partial Convolution for RGBD Image Inpainting](https://doi.org/10.1145/3589335.3651906)|Ankan Dash, Guiling Wang, Tao Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Attentive+Partial+Convolution+for+RGBD+Image+Inpainting)|0|
|[GPT Assisted Annotation of Rhetorical and Linguistic Features for Interpretable Propaganda Technique Detection in News Text](https://doi.org/10.1145/3589335.3651909)|Kyle Hamilton, Luca Longo, Bojan Bozic||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GPT+Assisted+Annotation+of+Rhetorical+and+Linguistic+Features+for+Interpretable+Propaganda+Technique+Detection+in+News+Text)|0|
|[A Bayesian Framework for Measuring Association and Its Application to Emotional Dynamics in Web Discourse](https://doi.org/10.1145/3589335.3651911)|Henrique S. Xavier, Diogo Cortiz, Mateus Silvestrin, Ana Luísa Freitas, Letícia Yumi Nakao Morello, Fernanda Naomi Pantaleão, Gabriel Gaudencio do Rêgo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Bayesian+Framework+for+Measuring+Association+and+Its+Application+to+Emotional+Dynamics+in+Web+Discourse)|0|
|[Leveraging Large Language Models to Detect Influence Campaigns on Social Media](https://doi.org/10.1145/3589335.3651912)|Luca Luceri, Eric Boniardi, Emilio Ferrara||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Leveraging+Large+Language+Models+to+Detect+Influence+Campaigns+on+Social+Media)|0|
|[Towards Fact-check Summarization Leveraging on Argumentation Elements Tied to Entity Graphs](https://doi.org/10.1145/3589335.3651914)|Katerina Haniková, David Chudán, Vojtech Svátek, Peter Vajdecka, Raphaël Troncy, Filip Vencovský, Jana Syrovátková||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Fact-check+Summarization+Leveraging+on+Argumentation+Elements+Tied+to+Entity+Graphs)|0|
|[DCAI: Data-centric Artificial Intelligence](https://doi.org/10.1145/3589335.3641297)|Wei Jin, Haohan Wang, Daochen Zha, Qiaoyu Tan, Yao Ma, Sharon Li, SuIn Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DCAI:+Data-centric+Artificial+Intelligence)|0|
|[Robust Data-centric Graph Structure Learning for Text Classification](https://doi.org/10.1145/3589335.3651915)|Jun Zhuang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Data-centric+Graph+Structure+Learning+for+Text+Classification)|0|
|[Data Quality-based Gradient Optimization for Recurrent Neural Networks](https://doi.org/10.1145/3589335.3651918)|Feihu Huang, Peiyu Yi, Shan Li, Haiwen Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Data+Quality-based+Gradient+Optimization+for+Recurrent+Neural+Networks)|0|
|[CFinDEE: A Chinese Fine-Grained Financial Dataset for Document-Level Event Extraction](https://doi.org/10.1145/3589335.3651921)|Tian Zhang, Maofu Liu, Bingying Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CFinDEE:+A+Chinese+Fine-Grained+Financial+Dataset+for+Document-Level+Event+Extraction)|0|
|[FASETS: Discovering Faceted Sets of Entities](https://doi.org/10.1145/3589335.3651924)|Koninika Pal, Hiba Arnaout, Simon Razniewski, Gerhard Weikum||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FASETS:+Discovering+Faceted+Sets+of+Entities)|0|
|[Prompt Optimizer of Text-to-Image Diffusion Models for Abstract Concept Understanding](https://doi.org/10.1145/3589335.3651927)|Zezhong Fan, Xiaohan Li, Kaushiki Nag, Chenhao Fang, Topojoy Biswas, Jianpeng Xu, Kannan Achan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Prompt+Optimizer+of+Text-to-Image+Diffusion+Models+for+Abstract+Concept+Understanding)|0|
|[LLM-Guided Counterfactual Data Generation for Fairer AI](https://doi.org/10.1145/3589335.3651929)|Ashish Mishra, Gyanaranjan Nayak, Suparna Bhattacharya, Tarun Kumar, Arpit Shah, Martin Foltin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LLM-Guided+Counterfactual+Data+Generation+for+Fairer+AI)|0|
|[Only Send What You Need: Learning to Communicate Efficiently in Federated Multilingual Machine Translation](https://doi.org/10.1145/3589335.3651931)|YunWei Chu, DongJun Han, Christopher G. Brinton||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Only+Send+What+You+Need:+Learning+to+Communicate+Efficiently+in+Federated+Multilingual+Machine+Translation)|0|
|[Federated Learning in Large Model Era: Vision-Language Model for Smart City Safety Operation Management](https://doi.org/10.1145/3589335.3651939)|Zengxiang Li, Zhaoxiang Hou, Hui Liu, Tongzhi Li, Chengyi Yang, Ying Wang, Chao Shi, Longfei Xie, Weishan Zhang, Liang Xu, Zelei Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Federated+Learning+in+Large+Model+Era:+Vision-Language+Model+for+Smart+City+Safety+Operation+Management)|0|
|[Phoenix: A Federated Generative Diffusion Model](https://doi.org/10.1145/3589335.3651935)|Fiona Victoria Stanley Jothiraj, Afra Mashhadi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Phoenix:+A+Federated+Generative+Diffusion+Model)|0|
|[LLM Driven Web Profile Extraction for Identical Names](https://doi.org/10.1145/3589335.3651946)|Prateek Sancheti, Kamalakar Karlapalem, Kavita Vemuri||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LLM+Driven+Web+Profile+Extraction+for+Identical+Names)|0|
|[Contrastive Disentanglement for Authorship Attribution](https://doi.org/10.1145/3589335.3652501)|Zhiqiang Hu, Thao Thanh Nguyen, Yujia Hu, ChiaYu Hung, Ming Shan Hee, ChunWei Seah, Roy KaWei Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Disentanglement+for+Authorship+Attribution)|0|
|[Large Language Models for Graph Learning](https://doi.org/10.1145/3589335.3641300)|Yujuan Ding, Wenqi Fan, Xiao Huang, Qing Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Large+Language+Models+for+Graph+Learning)|0|
|[Multi-Granularity Tibetan Textual Adversarial Attack Method Based on Masked Language Model](https://doi.org/10.1145/3589335.3652503)|Xi Cao, Nuo Qun, Quzong Gesang, Yulei Zhu, Trashi Nyima||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Granularity+Tibetan+Textual+Adversarial+Attack+Method+Based+on+Masked+Language+Model)|0|
|[Decoding Memes: A Comprehensive Analysis of Late and Early Fusion Models for Explainable Meme Analysis](https://doi.org/10.1145/3589335.3652504)|Faseela Abdullakutty, Usman Naseem||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Decoding+Memes:+A+Comprehensive+Analysis+of+Late+and+Early+Fusion+Models+for+Explainable+Meme+Analysis)|0|
|[SigBart: Enhanced Pre-training via Salient Content Representation Learning for Social Media Summarization](https://doi.org/10.1145/3589335.3652505)|Sajad Sotudeh, Nazli Goharian||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SigBart:+Enhanced+Pre-training+via+Salient+Content+Representation+Learning+for+Social+Media+Summarization)|0|
|[An Investigation into the Feasibility of Performing Federated Learning on Social Linked Data Servers](https://doi.org/10.1145/3589335.3651950)|Nayil Arana, Mohamed Ragab, Thanassis Tiropanis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Investigation+into+the+Feasibility+of+Performing+Federated+Learning+on+Social+Linked+Data+Servers)|0|
|[Detecting Financial Bots on the Ethereum Blockchain](https://doi.org/10.1145/3589335.3651959)|Thomas Niedermayer, Pietro Saggese, Bernhard Haslhofer||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Detecting+Financial+Bots+on+the+Ethereum+Blockchain)|0|
|[Measuring Arbitrage Losses and Profitability of AMM Liquidity](https://doi.org/10.1145/3589335.3651961)|Robin Fritsch, Andrea Canidio||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Measuring+Arbitrage+Losses+and+Profitability+of+AMM+Liquidity)|0|
|[Anonymity Analysis of the Umbra Stealth Address Scheme on Ethereum](https://doi.org/10.1145/3589335.3651963)|Alex Márk Kovács, István András Seres||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Anonymity+Analysis+of+the+Umbra+Stealth+Address+Scheme+on+Ethereum)|0|
|[Seamlessly Transferring Assets through Layer-0 Bridges: An Empirical Analysis of Stargate Bridge's Architecture and Dynamics](https://doi.org/10.1145/3589335.3651964)|Chuanshan Huang, Tao Yan, Claudio J. Tessone||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Seamlessly+Transferring+Assets+through+Layer-0+Bridges:+An+Empirical+Analysis+of+Stargate+Bridge's+Architecture+and+Dynamics)|0|
|[Understanding, Leveraging, and Improving Large Language Models](https://doi.org/10.1145/3589335.3653009)|Soujanya Poria||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding,+Leveraging,+and+Improving+Large+Language+Models)|0|
|[Love-Hate Dataset: A Multi-Modal Multi-Platform Dataset Depicting Emotions in the 2023 Israel-Hamas War](https://doi.org/10.1145/3589335.3651966)|Lynnette Hui Xian Ng, Adrian Xuan Wei Lim, Roy KaWei Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Love-Hate+Dataset:+A+Multi-Modal+Multi-Platform+Dataset+Depicting+Emotions+in+the+2023+Israel-Hamas+War)|0|
|[Textual Context guided Vision Transformer with Rotated Multi-Head Attention for Sentiment Analysis](https://doi.org/10.1145/3589335.3651968)|Chhavi Dhiman, Gaurav Kumar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Textual+Context+guided+Vision+Transformer+with+Rotated+Multi-Head+Attention+for+Sentiment+Analysis)|0|
|[A Novel Dual-Pipeline based Attention Mechanism for Multimodal Social Sentiment Analysis](https://doi.org/10.1145/3589335.3651967)|Ali Braytee, Andy ShuehChih Yang, Ali Anaissi, Kunal Chaturvedi, Mukesh Prasad||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Novel+Dual-Pipeline+based+Attention+Mechanism+for+Multimodal+Social+Sentiment+Analysis)|0|
|[Unraveling the Tangle of Disinformation: A Multimodal Approach for Fake News Identification on Social Media](https://doi.org/10.1145/3589335.3651972)|Junaid Rashid, Jungeun Kim, Anum Masood||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unraveling+the+Tangle+of+Disinformation:+A+Multimodal+Approach+for+Fake+News+Identification+on+Social+Media)|0|
|[RUHate-MM: Identification of Hate Speech and Targets using Multimodal Data from Russia-Ukraine Crisis](https://doi.org/10.1145/3589335.3651973)|Surendrabikram Thapa, Farhan Ahmad Jafri, Kritesh Rauniyar, Mehwish Nasim, Usman Naseem||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RUHate-MM:+Identification+of+Hate+Speech+and+Targets+using+Multimodal+Data+from+Russia-Ukraine+Crisis)|0|
|[Unveiling Misogyny Memes: A Multimodal Analysis of Modality Effects on Identification](https://doi.org/10.1145/3589335.3651974)|Shijing Chen, Usman Naseem, Imran Razzak, Flora D. Salim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unveiling+Misogyny+Memes:+A+Multimodal+Analysis+of+Modality+Effects+on+Identification)|0|
|[Ensemble Pretrained Models for Multimodal Sentiment Analysis using Textual and Video Data Fusion](https://doi.org/10.1145/3589335.3651971)|Zhicheng Liu, Ali Braytee, Ali Anaissi, Guifu Zhang, Lingyun Qin, Junaid Akram||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Ensemble+Pretrained+Models+for+Multimodal+Sentiment+Analysis+using+Textual+and+Video+Data+Fusion)|0|
|[AI Deepfakes on the Web: The 'Wicked' Challenges for AI Ethics, Law and Technology](https://doi.org/10.1145/3589334.3649116)|Jeannie Marie Paterson||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AI+Deepfakes+on+the+Web:+The+'Wicked'+Challenges+for+AI+Ethics,+Law+and+Technology)|0|
|[Challenges Toward AGI and Its Impact to the Web](https://doi.org/10.1145/3589334.3649113)|Bo Zhang, Jie Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Challenges+Toward+AGI+and+Its+Impact+to+the+Web)|0|
|[Budget-Constrained Auctions with Unassured Priors: Strategic Equivalence and Structural Properties](https://doi.org/10.1145/3589334.3645344)|Zhaohua Chen, Mingwei Yang, Chang Wang, Jicheng Li, Zheng Cai, Yukun Ren, Zhihua Zhu, Xiaotie Deng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Budget-Constrained+Auctions+with+Unassured+Priors:+Strategic+Equivalence+and+Structural+Properties)|0|
|[Efficiency of the Generalized Second-Price Auction for Value Maximizers](https://doi.org/10.1145/3589334.3645360)|Yuan Deng, Mohammad Mahdian, Jieming Mao, Vahab Mirrokni, Hanrui Zhang, Song Zuo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Efficiency+of+the+Generalized+Second-Price+Auction+for+Value+Maximizers)|0|
|[Data Exchange Markets via Utility Balancing](https://doi.org/10.1145/3589334.3645364)|Aditya Bhaskara, Sreenivas Gollapudi, Sungjin Im, Kostas Kollias, Kamesh Munagala, Govind S. Sankar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Data+Exchange+Markets+via+Utility+Balancing)|0|
|[Fine-Tuning Games: Bargaining and Adaptation for General-Purpose Models](https://doi.org/10.1145/3589334.3645366)|Benjamin Laufer, Jon M. Kleinberg, Hoda Heidari||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fine-Tuning+Games:+Bargaining+and+Adaptation+for+General-Purpose+Models)|0|
|[Robust Decision Aggregation with Second-order Information](https://doi.org/10.1145/3589334.3645384)|Yuqi Pan, Zhaohua Chen, Yuqing Kong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Decision+Aggregation+with+Second-order+Information)|0|
|[Identifying Risky Vendors in Cryptocurrency P2P Marketplaces](https://doi.org/10.1145/3589334.3645475)|Taro Tsuchiya, Alejandro Cuevas, Nicolas Christin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Identifying+Risky+Vendors+in+Cryptocurrency+P2P+Marketplaces)|0|
|[Prior-Free Mechanism with Welfare Guarantees](https://doi.org/10.1145/3589334.3645500)|Guru Guruganesh, Jon Schneider, Joshua R. Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Prior-Free+Mechanism+with+Welfare+Guarantees)|0|
|[Mechanism Design for Large Language Models](https://doi.org/10.1145/3589334.3645511)|Paul Dütting, Vahab Mirrokni, Renato Paes Leme, Haifeng Xu, Song Zuo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Mechanism+Design+for+Large+Language+Models)|0|
|[Core-Competitiveness in Partially Observable Networked Market](https://doi.org/10.1145/3589334.3645555)|Bin Li, Dong Hao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Core-Competitiveness+in+Partially+Observable+Networked+Market)|0|
|[Unveiling the Paradox of NFT Prosperity](https://doi.org/10.1145/3589334.3645566)|Jintao Huang, Pengcheng Xia, Jiefeng Li, Kai Ma, Gareth Tyson, Xiapu Luo, Lei Wu, Yajin Zhou, Wei Cai, Haoyu Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unveiling+the+Paradox+of+NFT+Prosperity)|0|
|[Fair Surveillance Assignment Problem](https://doi.org/10.1145/3589334.3645613)|Fangxiao Wang, Bo Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fair+Surveillance+Assignment+Problem)|0|
|[Reinforcement Learning with Maskable Stock Representation for Portfolio Management in Customizable Stock Pools](https://doi.org/10.1145/3589334.3645615)|Wentao Zhang, Yilei Zhao, Shuo Sun, Jie Ying, Yonggang Xie, Zitao Song, Xinrun Wang, Bo An||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Reinforcement+Learning+with+Maskable+Stock+Representation+for+Portfolio+Management+in+Customizable+Stock+Pools)|0|
|[Exit Ripple Effects: Understanding the Disruption of Socialization Networks Following Employee Departures](https://doi.org/10.1145/3589334.3645634)|David Gamba, Yulin Yu, Yuan Yuan, Grant Schoenebeck, Daniel M. Romero||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Exit+Ripple+Effects:+Understanding+the+Disruption+of+Socialization+Networks+Following+Employee+Departures)|0|
|[APT-Pipe: A Prompt-Tuning Tool for Social Data Annotation using ChatGPT](https://doi.org/10.1145/3589334.3645642)|Yiming Zhu, Zhizhuo Yin, Gareth Tyson, Ehsan ul Haq, LikHang Lee, Pan Hui||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=APT-Pipe:+A+Prompt-Tuning+Tool+for+Social+Data+Annotation+using+ChatGPT)|0|
|[Spot Check Equivalence: An Interpretable Metric for Information Elicitation Mechanisms](https://doi.org/10.1145/3589334.3645679)|Shengwei Xu, Yichi Zhang, Paul Resnick, Grant Schoenebeck||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Spot+Check+Equivalence:+An+Interpretable+Metric+for+Information+Elicitation+Mechanisms)|0|
|[Optimal Engagement-Diversity Tradeoffs in Social Media](https://doi.org/10.1145/3589334.3645713)|Fabian Baumann, Daniel Halpern, Ariel D. Procaccia, Iyad Rahwan, Itai Shapira, Manuel Wüthrich||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimal+Engagement-Diversity+Tradeoffs+in+Social+Media)|0|
|[MARIO: Model Agnostic Recipe for Improving OOD Generalization of Graph Contrastive Learning](https://doi.org/10.1145/3589334.3645322)|Yun Zhu, Haizhou Shi, Zhenshuo Zhang, Siliang Tang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MARIO:+Model+Agnostic+Recipe+for+Improving+OOD+Generalization+of+Graph+Contrastive+Learning)|0|
|[Cooperative Classification and Rationalization for Graph Generalization](https://doi.org/10.1145/3589334.3645332)|Linan Yue, Qi Liu, Ye Liu, Weibo Gao, Fangzhou Yao, Wenfeng Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cooperative+Classification+and+Rationalization+for+Graph+Generalization)|0|
|[Cost-effective Data Labelling for Graph Neural Networks](https://doi.org/10.1145/3589334.3645339)|Shixun Huang, Ge Lee, Zhifeng Bao, Shirui Pan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cost-effective+Data+Labelling+for+Graph+Neural+Networks)|0|
|[Masked Graph Autoencoder with Non-discrete Bandwidths](https://doi.org/10.1145/3589334.3645370)|Ziwen Zhao, Yuhua Li, Yixiong Zou, Jiliang Tang, Ruixuan Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Masked+Graph+Autoencoder+with+Non-discrete+Bandwidths)|0|
|[Graph Contrastive Learning Meets Graph Meta Learning: A Unified Method for Few-shot Node Tasks](https://doi.org/10.1145/3589334.3645367)|Hao Liu, Jiarui Feng, Lecheng Kong, Dacheng Tao, Yixin Chen, Muhan Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Contrastive+Learning+Meets+Graph+Meta+Learning:+A+Unified+Method+for+Few-shot+Node+Tasks)|0|
|[Local Centrality Minimization with Quality Guarantees](https://doi.org/10.1145/3589334.3645382)|Atsushi Miyauchi, Lorenzo Severini, Francesco Bonchi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Local+Centrality+Minimization+with+Quality+Guarantees)|0|
|[Fast Inference of Removal-Based Node Influence](https://doi.org/10.1145/3589334.3645389)|Weikai Li, Zhiping Xiao, Xiao Luo, Yizhou Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fast+Inference+of+Removal-Based+Node+Influence)|0|
|[Memory Disagreement: A Pseudo-Labeling Measure from Training Dynamics for Semi-supervised Graph Learning](https://doi.org/10.1145/3589334.3645398)|Hongbin Pei, Yuheng Xiong, Pinghui Wang, Jing Tao, Jialun Liu, Huiqi Deng, Jie Ma, Xiaohong Guan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Memory+Disagreement:+A+Pseudo-Labeling+Measure+from+Training+Dynamics+for+Semi-supervised+Graph+Learning)|0|
|[Descriptive Kernel Convolution Network with Improved Random Walk Kernel](https://doi.org/10.1145/3589334.3645405)|MengChieh Lee, Lingxiao Zhao, Leman Akoglu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Descriptive+Kernel+Convolution+Network+with+Improved+Random+Walk+Kernel)|0|
|[Dynamic Graph Information Bottleneck](https://doi.org/10.1145/3589334.3645411)|Haonan Yuan, Qingyun Sun, Xingcheng Fu, Cheng Ji, Jianxin Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamic+Graph+Information+Bottleneck)|0|
|[Extracting Small Subgraphs in Road Networks](https://doi.org/10.1145/3589334.3645415)|Sara Ahmadian, Sreenivas Gollapudi, Gregory Hutchins, Kostas Kollias, Xizhi Tan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Extracting+Small+Subgraphs+in+Road+Networks)|0|
|[Game-theoretic Counterfactual Explanation for Graph Neural Networks](https://doi.org/10.1145/3589334.3645419)|Chirag Chhablani, Sarthak Jain, Akshay Channesh, Ian A. Kash, Sourav Medya||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Game-theoretic+Counterfactual+Explanation+for+Graph+Neural+Networks)|0|
|[Graph-Skeleton: ~1% Nodes are Sufficient to Represent Billion-Scale Graph](https://doi.org/10.1145/3589334.3645452)|Linfeng Cao, Haoran Deng, Yang Yang, Chunping Wang, Lei Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph-Skeleton:+~1%+Nodes+are+Sufficient+to+Represent+Billion-Scale+Graph)|0|
|[GAUSS: GrAph-customized Universal Self-Supervised Learning](https://doi.org/10.1145/3589334.3645453)|Liang Yang, Weixiao Hu, Jizhong Xu, Runjie Shi, Dongxiao He, Chuan Wang, Xiaochun Cao, Zhen Wang, Bingxin Niu, Yuanfang Guo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GAUSS:+GrAph-customized+Universal+Self-Supervised+Learning)|0|
|[Optimizing Network Resilience via Vertex Anchoring](https://doi.org/10.1145/3589334.3645465)|Siyi Teng, Jiadong Xie, Fan Zhang, Can Lu, Juntao Fang, Kai Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimizing+Network+Resilience+via+Vertex+Anchoring)|0|
|[VilLain: Self-Supervised Learning on Homogeneous Hypergraphs without Features via Virtual Label Propagation](https://doi.org/10.1145/3589334.3645454)|Geon Lee, Soo Yong Lee, Kijung Shin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=VilLain:+Self-Supervised+Learning+on+Homogeneous+Hypergraphs+without+Features+via+Virtual+Label+Propagation)|0|
|[SMUG: Sand Mixing for Unobserved Class Detection in Graph Few-Shot Learning](https://doi.org/10.1145/3589334.3645466)|Chenxu Wang, Xichan Nie, Jinfeng Chen, Pinghui Wang, Junzhou Zhao, Xiaohong Guan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SMUG:+Sand+Mixing+for+Unobserved+Class+Detection+in+Graph+Few-Shot+Learning)|0|
|[Graph Contrastive Learning with Cohesive Subgraph Awareness](https://doi.org/10.1145/3589334.3645470)|Yucheng Wu, Leye Wang, Xiao Han, HanJia Ye||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Contrastive+Learning+with+Cohesive+Subgraph+Awareness)|0|
|[GNNFingers: A Fingerprinting Framework for Verifying Ownerships of Graph Neural Networks](https://doi.org/10.1145/3589334.3645489)|Xiaoyu You, Youhe Jiang, Jianwei Xu, Mi Zhang, Min Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GNNFingers:+A+Fingerprinting+Framework+for+Verifying+Ownerships+of+Graph+Neural+Networks)|0|
|[Graph Fairness Learning under Distribution Shifts](https://doi.org/10.1145/3589334.3645508)|Yibo Li, Xiao Wang, Yujie Xing, Shaohua Fan, Ruijia Wang, Yaoqi Liu, Chuan Shi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Fairness+Learning+under+Distribution+Shifts)|0|
|[Self-Guided Robust Graph Structure Refinement](https://doi.org/10.1145/3589334.3645522)|Yeonjun In, Kanghoon Yoon, Kibum Kim, Kijung Shin, Chanyoung Park||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Self-Guided+Robust+Graph+Structure+Refinement)|0|
|[DSLR: Diversity Enhancement and Structure Learning for Rehearsal-based Graph Continual Learning](https://doi.org/10.1145/3589334.3645561)|Seungyoon Choi, Wonjoong Kim, Sungwon Kim, Yeonjun In, Sein Kim, Chanyoung Park||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DSLR:+Diversity+Enhancement+and+Structure+Learning+for+Rehearsal-based+Graph+Continual+Learning)|0|
|[Calibrating Graph Neural Networks from a Data-centric Perspective](https://doi.org/10.1145/3589334.3645562)|Cheng Yang, Chengdong Yang, Chuan Shi, Yawen Li, Zhiqiang Zhang, Jun Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Calibrating+Graph+Neural+Networks+from+a+Data-centric+Perspective)|0|
|[EXGC: Bridging Efficiency and Explainability in Graph Condensation](https://doi.org/10.1145/3589334.3645551)|Junfeng Fang, Xinglin Li, Yongduo Sui, Yuan Gao, Guibin Zhang, Kun Wang, Xiang Wang, Xiangnan He||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=EXGC:+Bridging+Efficiency+and+Explainability+in+Graph+Condensation)|0|
|[Fast and Accurate Fair k-Center Clustering in Doubling Metrics](https://doi.org/10.1145/3589334.3645568)|Matteo Ceccarello, Andrea Pietracaprina, Geppino Pucci||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fast+and+Accurate+Fair+k-Center+Clustering+in+Doubling+Metrics)|0|
|[Graph Principal Flow Network for Conditional Graph Generation](https://doi.org/10.1145/3589334.3645570)|Zhanfeng Mo, Tianze Luo, Sinno Jialin Pan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Principal+Flow+Network+for+Conditional+Graph+Generation)|0|
|[Cross-Space Adaptive Filter: Integrating Graph Topology and Node Attributes for Alleviating the Over-smoothing Problem](https://doi.org/10.1145/3589334.3645583)|Chen Huang, Haoyang Li, Yifan Zhang, Wenqiang Lei, Jiancheng Lv||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cross-Space+Adaptive+Filter:+Integrating+Graph+Topology+and+Node+Attributes+for+Alleviating+the+Over-smoothing+Problem)|0|
|[A Quasi-Wasserstein Loss for Learning Graph Neural Networks](https://doi.org/10.1145/3589334.3645586)|Minjie Cheng, Hongteng Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Quasi-Wasserstein+Loss+for+Learning+Graph+Neural+Networks)|0|
|[GNNShap: Scalable and Accurate GNN Explanation using Shapley Values](https://doi.org/10.1145/3589334.3645599)|Selahattin Akkas, Ariful Azad||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GNNShap:+Scalable+and+Accurate+GNN+Explanation+using+Shapley+Values)|0|
|[Graph Out-of-Distribution Generalization via Causal Intervention](https://doi.org/10.1145/3589334.3645604)|Qitian Wu, Fan Nie, Chenxiao Yang, Tianyi Bao, Junchi Yan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Out-of-Distribution+Generalization+via+Causal+Intervention)|0|
|[Adversarial Mask Explainer for Graph Neural Networks](https://doi.org/10.1145/3589334.3645608)|Wei Zhang, Xiaofan Li, Wolfgang Nejdl||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Adversarial+Mask+Explainer+for+Graph+Neural+Networks)|0|
|[On the Feasibility of Simple Transformer for Dynamic Graph Modeling](https://doi.org/10.1145/3589334.3645622)|Yuxia Wu, Yuan Fang, Lizi Liao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=On+the+Feasibility+of+Simple+Transformer+for+Dynamic+Graph+Modeling)|0|
|[Can GNN be Good Adapter for LLMs?](https://doi.org/10.1145/3589334.3645627)|Xuanwen Huang, Kaiqiao Han, Yang Yang, Dezheng Bao, Quanjin Tao, Ziwei Chai, Qi Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Can+GNN+be+Good+Adapter+for+LLMs?)|0|
|[When Imbalance Meets Imbalance: Structure-driven Learning for Imbalanced Graph Classification](https://doi.org/10.1145/3589334.3645629)|Wei Xu, Pengkun Wang, Zhe Zhao, Binwu Wang, Xu Wang, Yang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=When+Imbalance+Meets+Imbalance:+Structure-driven+Learning+for+Imbalanced+Graph+Classification)|0|
|[Disambiguated Node Classification with Graph Neural Networks](https://doi.org/10.1145/3589334.3645637)|Tianxiang Zhao, Xiang Zhang, Suhang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Disambiguated+Node+Classification+with+Graph+Neural+Networks)|0|
|[Finding Densest Subgraphs with Edge-Color Constraints](https://doi.org/10.1145/3589334.3645647)|Lutz Oettershagen, Honglian Wang, Aristides Gionis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Finding+Densest+Subgraphs+with+Edge-Color+Constraints)|0|
|[Low Mileage, High Fidelity: Evaluating Hypergraph Expansion Methods by Quantifying the Information Loss](https://doi.org/10.1145/3589334.3645657)|David Y. Kang, Qiaozhu Mei, SangWook Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Low+Mileage,+High+Fidelity:+Evaluating+Hypergraph+Expansion+Methods+by+Quantifying+the+Information+Loss)|0|
|[Learning Scalable Structural Representations for Link Prediction with Bloom Signatures](https://doi.org/10.1145/3589334.3645672)|Tianyi Zhang, Haoteng Yin, Rongzhe Wei, Pan Li, Anshumali Shrivastava||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+Scalable+Structural+Representations+for+Link+Prediction+with+Bloom+Signatures)|0|
|[GraphTranslator: Aligning Graph Model to Large Language Model for Open-ended Tasks](https://doi.org/10.1145/3589334.3645682)|Mengmei Zhang, Mingwei Sun, Peng Wang, Shen Fan, Yanhu Mo, Xiaoxiao Xu, Hong Liu, Cheng Yang, Chuan Shi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphTranslator:+Aligning+Graph+Model+to+Large+Language+Model+for+Open-ended+Tasks)|0|
|[HetGPT: Harnessing the Power of Prompt Tuning in Pre-Trained Heterogeneous Graph Neural Networks](https://doi.org/10.1145/3589334.3645685)|Yihong Ma, Ning Yan, Jiayu Li, Masood S. Mortazavi, Nitesh V. Chawla||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HetGPT:+Harnessing+the+Power+of+Prompt+Tuning+in+Pre-Trained+Heterogeneous+Graph+Neural+Networks)|0|
|[Graph Contrastive Learning via Interventional View Generation](https://doi.org/10.1145/3589334.3645687)|Zengyi Wo, Minglai Shao, Wenjun Wang, Xuan Guo, Lu Lin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Contrastive+Learning+via+Interventional+View+Generation)|0|
|[Endowing Pre-trained Graph Models with Provable Fairness](https://doi.org/10.1145/3589334.3645703)|Zhongjian Zhang, Mengmei Zhang, Yue Yu, Cheng Yang, Jiawei Liu, Chuan Shi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Endowing+Pre-trained+Graph+Models+with+Provable+Fairness)|0|
|[Unveiling Delay Effects in Traffic Forecasting: A Perspective from Spatial-Temporal Delay Differential Equations](https://doi.org/10.1145/3589334.3645688)|Qingqing Long, Zheng Fang, Chen Fang, Chong Chen, Pengfei Wang, Yuanchun Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unveiling+Delay+Effects+in+Traffic+Forecasting:+A+Perspective+from+Spatial-Temporal+Delay+Differential+Equations)|0|
|[Optimizing Polynomial Graph Filters: A Novel Adaptive Krylov Subspace Approach](https://doi.org/10.1145/3589334.3645705)|Keke Huang, Wencai Cao, Hoang Ta, Xiaokui Xiao, Pietro Liò||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Optimizing+Polynomial+Graph+Filters:+A+Novel+Adaptive+Krylov+Subspace+Approach)|0|
|[Full-Attention Driven Graph Contrastive Learning: with Effective Mutual Information Insight](https://doi.org/10.1145/3589334.3645717)|Long Li, Zemin Liu, Chenghao Liu, Jianling Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Full-Attention+Driven+Graph+Contrastive+Learning:+with+Effective+Mutual+Information+Insight)|0|
|[Understanding GDPR Non-Compliance in Privacy Policies of Alexa Skills in European Marketplaces](https://doi.org/10.1145/3589334.3645409)|Song Liao, Mohammed Aldeen, Jingwen Yan, Long Cheng, Xiapu Luo, Haipeng Cai, Hongxin Hu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Understanding+GDPR+Non-Compliance+in+Privacy+Policies+of+Alexa+Skills+in+European+Marketplaces)|0|
|[Differentially Private Selection from Secure Distributed Computing](https://doi.org/10.1145/3589334.3645435)|Ivan Damgård, Hannah Keller, Boel Nelson, Claudio Orlandi, Rasmus Pagh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Differentially+Private+Selection+from+Secure+Distributed+Computing)|0|
|[The Dynamics of (Not) Unfollowing Misinformation Spreaders](https://doi.org/10.1145/3589334.3645445)|Joshua Ashkinaze, Eric Gilbert, Ceren Budak||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Dynamics+of+(Not)+Unfollowing+Misinformation+Spreaders)|0|
|[Federated Learning Vulnerabilities: Privacy Attacks with Denoising Diffusion Probabilistic Models](https://doi.org/10.1145/3589334.3645514)|Hongyan Gu, Xinyi Zhang, Jiang Li, Hui Wei, Baiqi Li, Xinli Huang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Federated+Learning+Vulnerabilities:+Privacy+Attacks+with+Denoising+Diffusion+Probabilistic+Models)|0|
|[Fair Graph Representation Learning via Sensitive Attribute Disentanglement](https://doi.org/10.1145/3589334.3645532)|Yuchang Zhu, Jintang Li, Zibin Zheng, Liang Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Fair+Graph+Representation+Learning+via+Sensitive+Attribute+Disentanglement)|0|
|[DPAR: Decoupled Graph Neural Networks with Node-Level Differential Privacy](https://doi.org/10.1145/3589334.3645531)|Qiuchen Zhang, HongKyu Lee, Jing Ma, Jian Lou, Carl Yang, Li Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DPAR:+Decoupled+Graph+Neural+Networks+with+Node-Level+Differential+Privacy)|0|
|[A Worldwide View on the Reachability of Encrypted DNS Services](https://doi.org/10.1145/3589334.3645539)|Ruixuan Li, Baojun Liu, Chaoyi Lu, Haixin Duan, Jun Shao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Worldwide+View+on+the+Reachability+of+Encrypted+DNS+Services)|0|
|[Contrastive Fingerprinting: A Novel Website Fingerprinting Attack over Few-shot Traces](https://doi.org/10.1145/3589334.3645575)|Yi Xie, Jiahao Feng, Wenju Huang, Yixi Zhang, Xueliang Sun, Xiaochou Chen, Xiapu Luo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Fingerprinting:+A+Novel+Website+Fingerprinting+Attack+over+Few-shot+Traces)|0|
|[Analyzing Ad Exposure and Content in Child-Oriented Videos on YouTube](https://doi.org/10.1145/3589334.3645585)|Emaan Bilal Khan, Nida Tanveer, Aima Shahid, Mohammad Jaffer Iqbal, Haashim Ali Mirza, Armish Javed, Ihsan Ayyub Qazi, Zafar Ayyub Qazi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Analyzing+Ad+Exposure+and+Content+in+Child-Oriented+Videos+on+YouTube)|0|
|[A Study of GDPR Compliance under the Transparency and Consent Framework](https://doi.org/10.1145/3589334.3645618)|Michael Smith, Antonio TorresAgüero, Riley Grossman, Pritam Sen, Yi Chen, Cristian Borcea||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Study+of+GDPR+Compliance+under+the+Transparency+and+Consent+Framework)|0|
|[Breaking the Trilemma of Privacy, Utility, and Efficiency via Controllable Machine Unlearning](https://doi.org/10.1145/3589334.3645669)|Zheyuan Liu, Guangyao Dou, Eli Chien, Chunhui Zhang, Yijun Tian, Ziwei Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Breaking+the+Trilemma+of+Privacy,+Utility,+and+Efficiency+via+Controllable+Machine+Unlearning)|0|
|[Heterogeneous Subgraph Transformer for Fake News Detection](https://doi.org/10.1145/3589334.3645680)|Yuchen Zhang, Xiaoxiao Ma, Jia Wu, Jian Yang, Hao Fan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Heterogeneous+Subgraph+Transformer+for+Fake+News+Detection)|0|
|[Experimental Security Analysis of Sensitive Data Access by Browser Extensions](https://doi.org/10.1145/3589334.3645683)|Asmit Nayak, Rishabh Khandelwal, Earlence Fernandes, Kassem Fawaz||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Experimental+Security+Analysis+of+Sensitive+Data+Access+by+Browser+Extensions)|0|
|[Automating Website Registration for Studying GDPR Compliance](https://doi.org/10.1145/3589334.3645709)|Karel Kubicek, Jakob Merane, Ahmed Bouhoula, David A. Basin||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Automating+Website+Registration+for+Studying+GDPR+Compliance)|0|
|[Generating Multi-turn Clarification for Web Information Seeking](https://doi.org/10.1145/3589334.3645712)|Ziliang Zhao, Zhicheng Dou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Generating+Multi-turn+Clarification+for+Web+Information+Seeking)|0|
|[Advancing Web 3.0: Making Smart Contracts Smarter on Blockchain](https://doi.org/10.1145/3589334.3645319)|Junqin Huang, Linghe Kong, Guanjie Cheng, Qiao Xiang, Guihai Chen, Gang Huang, Xue Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Advancing+Web+3.0:+Making+Smart+Contracts+Smarter+on+Blockchain)|0|
|[From Promises to Practice: Evaluating the Private Browsing Modes of Android Browser Apps](https://doi.org/10.1145/3589334.3645320)|Xiaoyin Liu, Wenzhi Li, Qinsheng Hou, Shishuai Yang, Lingyun Ying, Wenrui Diao, Yanan Li, Shanqing Guo, Haixin Duan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=From+Promises+to+Practice:+Evaluating+the+Private+Browsing+Modes+of+Android+Browser+Apps)|0|
|[Interface Illusions: Uncovering the Rise of Visual Scams in Cryptocurrency Wallets](https://doi.org/10.1145/3589334.3645348)|Guoyi Ye, Geng Hong, Yuan Zhang, Min Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interface+Illusions:+Uncovering+the+Rise+of+Visual+Scams+in+Cryptocurrency+Wallets)|0|
|[Trident: A Universal Framework for Fine-Grained and Class-Incremental Unknown Traffic Detection](https://doi.org/10.1145/3589334.3645407)|Ziming Zhao, Zhaoxuan Li, Zhuoxue Song, Wenhao Li, Fan Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Trident:+A+Universal+Framework+for+Fine-Grained+and+Class-Incremental+Unknown+Traffic+Detection)|0|
|[SSI, from Specifications to Protocol? Formally Verify Security!](https://doi.org/10.1145/3589334.3645426)|Christoph H.J. Braun, Ross Horne, Tobias Käfer, Sjouke Mauw||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SSI,+from+Specifications+to+Protocol?+Formally+Verify+Security!)|0|
|[GRASP: Hardening Serverless Applications through Graph Reachability Analysis of Security Policies](https://doi.org/10.1145/3589334.3645436)|Isaac Polinsky, Pubali Datta, Adam Bates, William Enck||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GRASP:+Hardening+Serverless+Applications+through+Graph+Reachability+Analysis+of+Security+Policies)|0|
|[Divide, Conquer, and Coalesce: Meta Parallel Graph Neural Network for IoT Intrusion Detection at Scale](https://doi.org/10.1145/3589334.3645457)|Hua Ding, Lixing Chen, Shenghong Li, Yang Bai, Pan Zhou, Zhe Qu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Divide,+Conquer,+and+Coalesce:+Meta+Parallel+Graph+Neural+Network+for+IoT+Intrusion+Detection+at+Scale)|0|
|[Medusa: Unveil Memory Exhaustion DoS Vulnerabilities in Protocol Implementations](https://doi.org/10.1145/3589334.3645476)|Zhengjie Du, Yuekang Li, Yaowen Zheng, Xiaohan Zhang, Cen Zhang, Yi Liu, Sheikh Mahbub Habib, Xinghua Li, Linzhang Wang, Yang Liu, Bing Mao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Medusa:+Unveil+Memory+Exhaustion+DoS+Vulnerabilities+in+Protocol+Implementations)|0|
|[ContraMTD: An Unsupervised Malicious Network Traffic Detection Method based on Contrastive Learning](https://doi.org/10.1145/3589334.3645479)|Xueying Han, Susu Cui, Jian Qin, Song Liu, Bo Jiang, Cong Dong, Zhigang Lu, Baoxu Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ContraMTD:+An+Unsupervised+Malicious+Network+Traffic+Detection+Method+based+on+Contrastive+Learning)|0|
|[Unfiltered: Measuring Cloud-based Email Filtering Bypasses](https://doi.org/10.1145/3589334.3645499)|Sumanth Rao, Enze Liu, Grant Ho, Geoffrey M. Voelker, Stefan Savage||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unfiltered:+Measuring+Cloud-based+Email+Filtering+Bypasses)|0|
|[RecurScan: Detecting Recurring Vulnerabilities in PHP Web Applications](https://doi.org/10.1145/3589334.3645530)|Youkun Shi, Yuan Zhang, Tianhao Bai, Lei Zhang, Xin Tan, Min Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RecurScan:+Detecting+Recurring+Vulnerabilities+in+PHP+Web+Applications)|0|
|[Phishing Vs. Legit: Comparative Analysis of Client-Side Resources of Phishing and Target Brand Websites](https://doi.org/10.1145/3589334.3645535)|Kyungchan Lim, Jaehwan Park, Doowon Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Phishing+Vs.+Legit:+Comparative+Analysis+of+Client-Side+Resources+of+Phishing+and+Target+Brand+Websites)|0|
|[Detecting and Understanding Self-Deleting JavaScript Code](https://doi.org/10.1145/3589334.3645540)|Xinzhe Wang, Zeyang Zhuang, Wei Meng, James Cheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Detecting+and+Understanding+Self-Deleting+JavaScript+Code)|0|
|[Malicious Package Detection using Metadata Information](https://doi.org/10.1145/3589334.3645543)|Sajal Halder, Michael Bewong, Arash Mahboubi, Yinhao Jiang, Md Rafiqul Islam, Md Zahidul Islam, Ryan HL Ip, Muhammad Ejaz Ahmed, Gowri Sankar Ramachandran, Muhammad Ali Babar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Malicious+Package+Detection+using+Metadata+Information)|0|
|[Unveiling the Invisible: Detection and Evaluation of Prototype Pollution Gadgets with Dynamic Taint Analysis](https://doi.org/10.1145/3589334.3645579)|Mikhail Shcherbakov, Paul Moosbrugger, Musard Balliu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unveiling+the+Invisible:+Detection+and+Evaluation+of+Prototype+Pollution+Gadgets+with+Dynamic+Taint+Analysis)|0|
|[ARTEMIS: Detecting Airdrop Hunters in NFT Markets with a Graph Learning System](https://doi.org/10.1145/3589334.3645597)|Chenyu Zhou, Hongzhou Chen, Hao Wu, Junyu Zhang, Wei Cai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ARTEMIS:+Detecting+Airdrop+Hunters+in+NFT+Markets+with+a+Graph+Learning+System)|0|
|[HSDirSniper: A New Attack Exploiting Vulnerabilities in Tor's Hidden Service Directories](https://doi.org/10.1145/3589334.3645591)|Qingfeng Zhang, Zhiyang Teng, Xuebin Wang, Yue Gao, Qingyun Liu, Jinqiao Shi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HSDirSniper:+A+New+Attack+Exploiting+Vulnerabilities+in+Tor's+Hidden+Service+Directories)|0|
|[The Matter of Captchas: An Analysis of a Brittle Security Feature on the Modern Web](https://doi.org/10.1145/3589334.3645619)|Behzad Ousat, Esteban Schafir, Duc C. Hoang, Mohammad Ali Tofighi, Cuong V. Nguyen, Sajjad Arshad, A. Selcuk Uluagac, Amin Kharraz||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=The+Matter+of+Captchas:+An+Analysis+of+a+Brittle+Security+Feature+on+the+Modern+Web)|0|
|[Characterizing Ethereum Upgradable Smart Contracts and Their Security Implications](https://doi.org/10.1145/3589334.3645640)|Xiaofan Li, Jin Yang, Jiaqi Chen, Yuzhe Tang, Xing Gao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Characterizing+Ethereum+Upgradable+Smart+Contracts+and+Their+Security+Implications)|0|
|[IDEA-DAC: Integrity-Driven Editing for Accountable Decentralized Anonymous Credentials via ZK-JSON](https://doi.org/10.1145/3589334.3645658)|Shuhao Zheng, Zonglun Li, Junliang Luo, Ziyue Xin, Xue Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=IDEA-DAC:+Integrity-Driven+Editing+for+Accountable+Decentralized+Anonymous+Credentials+via+ZK-JSON)|0|
|[Is It Safe to Share Your Files? An Empirical Security Analysis of Google Workspace](https://doi.org/10.1145/3589334.3645697)|Liuhuo Wan, Kailong Wang, Haoyu Wang, Guangdong Bai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Is+It+Safe+to+Share+Your+Files?+An+Empirical+Security+Analysis+of+Google+Workspace)|0|
|[PanoptiChrome: A Modern In-browser Taint Analysis Framework](https://doi.org/10.1145/3589334.3645699)|Rahul Kanyal, Smruti R. Sarangi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PanoptiChrome:+A+Modern+In-browser+Taint+Analysis+Framework)|0|
|[PhishinWebView: Analysis of Anti-Phishing Entities in Mobile Apps with WebView Targeted Phishing](https://doi.org/10.1145/3589334.3645708)|Yoonjung Choi, Woonghee Lee, Junbeom Hur||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=PhishinWebView:+Analysis+of+Anti-Phishing+Entities+in+Mobile+Apps+with+WebView+Targeted+Phishing)|0|
|[Back to the Future: Towards Explainable Temporal Reasoning with Large Language Models](https://doi.org/10.1145/3589334.3645376)|Chenhan Yuan, Qianqian Xie, Jimin Huang, Sophia Ananiadou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Back+to+the+Future:+Towards+Explainable+Temporal+Reasoning+with+Large+Language+Models)|0|
|[A Knowledge-Injected Curriculum Pretraining Framework for Question Answering](https://doi.org/10.1145/3589334.3645406)|Xin Lin, Tianhuang Su, Zhenya Huang, Shangzi Xue, Haifeng Liu, Enhong Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Knowledge-Injected+Curriculum+Pretraining+Framework+for+Question+Answering)|0|
|[Using Model Calibration to Evaluate Link Prediction in Knowledge Graphs](https://doi.org/10.1145/3589334.3645506)|Aishwarya Rao, Narayanan Asuri Krishnan, Carlos R. Rivero||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Using+Model+Calibration+to+Evaluate+Link+Prediction+in+Knowledge+Graphs)|0|
|[Zero-shot Image Classification with Logic Adapter and Rule Prompt](https://doi.org/10.1145/3589334.3645554)|Dongran Yu, Xueyan Liu, Bo Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Zero-shot+Image+Classification+with+Logic+Adapter+and+Rule+Prompt)|0|
|[NPCS: Native Provenance Computation for SPARQL](https://doi.org/10.1145/3589334.3645557)|Zubaria Asma, Daniel Hernández, Luis Galárraga, Giorgos Flouris, Irini Fundulaki, Katja Hose||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NPCS:+Native+Provenance+Computation+for+SPARQL)|0|
|[Taxonomy Completion via Implicit Concept Insertion](https://doi.org/10.1145/3589334.3645584)|Jingchuan Shi, Hang Dong, Jiaoyan Chen, Zhe Wu, Ian Horrocks||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Taxonomy+Completion+via+Implicit+Concept+Insertion)|0|
|[UniLP: Unified Topology-aware Generative Framework for Link Prediction in Knowledge Graph](https://doi.org/10.1145/3589334.3645592)|Ben Liu, Miao Peng, Wenjie Xu, Xu Jia, Min Peng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UniLP:+Unified+Topology-aware+Generative+Framework+for+Link+Prediction+in+Knowledge+Graph)|0|
|[A Symbolic Rule Integration Framework with Logic Transformer for Inductive Relation Prediction](https://doi.org/10.1145/3589334.3645594)|Yudai Pan, Jun Liu, Tianzhe Zhao, Lingling Zhang, Yun Lin, Jin Song Dong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Symbolic+Rule+Integration+Framework+with+Logic+Transformer+for+Inductive+Relation+Prediction)|0|
|[Causal Question Answering with Reinforcement Learning](https://doi.org/10.1145/3589334.3645610)|Lukas Blübaum, Stefan Heindorf||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causal+Question+Answering+with+Reinforcement+Learning)|0|
|[DRAM-like Architecture with Asynchronous Refreshing for Continual Relation Extraction](https://doi.org/10.1145/3589334.3645621)|Tianci Bu, Kang Yang, Wenchuan Yang, Jiawei Feng, Xiaoyu Zhang, Xin Lu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DRAM-like+Architecture+with+Asynchronous+Refreshing+for+Continual+Relation+Extraction)|0|
|[KGQuiz: Evaluating the Generalization of Encoded Knowledge in Large Language Models](https://doi.org/10.1145/3589334.3645623)|Yuyang Bai, Shangbin Feng, Vidhisha Balachandran, Zhaoxuan Tan, Shiqi Lou, Tianxing He, Yulia Tsvetkov||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=KGQuiz:+Evaluating+the+Generalization+of+Encoded+Knowledge+in+Large+Language+Models)|0|
|[Robust Link Prediction over Noisy Hyper-Relational Knowledge Graphs via Active Learning](https://doi.org/10.1145/3589334.3645686)|Weijian Yu, Jie Yang, Dingqi Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Link+Prediction+over+Noisy+Hyper-Relational+Knowledge+Graphs+via+Active+Learning)|0|
|[OODREB: Benchmarking State-of-the-Art Methods for Out-Of-Distribution Generalization on Relation Extraction](https://doi.org/10.1145/3589334.3645695)|Haotian Chen, Houjing Guo, Bingsheng Chen, Xiangdong Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=OODREB:+Benchmarking+State-of-the-Art+Methods+for+Out-Of-Distribution+Generalization+on+Relation+Extraction)|0|
|[Toward Practical Entity Alignment Method Design: Insights from New Highly Heterogeneous Knowledge Graph Datasets](https://doi.org/10.1145/3589334.3645720)|Xuhui Jiang, Chengjin Xu, Yinghan Shen, Yuanzhuo Wang, Fenglong Su, Zhichao Shi, Fei Sun, Zixuan Li, Jian Guo, Huawei Shen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Toward+Practical+Entity+Alignment+Method+Design:+Insights+from+New+Highly+Heterogeneous+Knowledge+Graph+Datasets)|0|
|[Social Media Discourses on Interracial Intimacy: Tracking Racism and Sexism through Chinese Geo-located Social Media Data](https://doi.org/10.1145/3589334.3645334)|Zheng Wei, Yixuan Xie, Danyun Xiao, Simin Zhang, Pan Hui, Muzhi Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Social+Media+Discourses+on+Interracial+Intimacy:+Tracking+Racism+and+Sexism+through+Chinese+Geo-located+Social+Media+Data)|0|
|[Towards Explainable Harmful Meme Detection through Multimodal Debate between Large Language Models](https://doi.org/10.1145/3589334.3645381)|Hongzhan Lin, Ziyang Luo, Wei Gao, Jing Ma, Bo Wang, Ruichao Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Explainable+Harmful+Meme+Detection+through+Multimodal+Debate+between+Large+Language+Models)|0|
|[What News Do People Get on Social Media? Analyzing Exposure and Consumption of News through Data Donations](https://doi.org/10.1145/3589334.3645399)|Salim Chouaki, Abhijnan Chakraborty, Oana Goga, Savvas Zannettou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=What+News+Do+People+Get+on+Social+Media?+Analyzing+Exposure+and+Consumption+of+News+through+Data+Donations)|0|
|[Euphemism Identification via Feature Fusion and Individualization](https://doi.org/10.1145/3589334.3645433)|Yuxue Hu, Mingmin Wu, Zhongqiang Huang, Junsong Li, Xing Ge, Ying Sha||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Euphemism+Identification+via+Feature+Fusion+and+Individualization)|0|
|[Team Formation amidst Conflicts](https://doi.org/10.1145/3589334.3645444)|Iasonas Nikolaou, Evimaria Terzi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Team+Formation+amidst+Conflicts)|0|
|[T3RD: Test-Time Training for Rumor Detection on Social Media](https://doi.org/10.1145/3589334.3645443)|Huaiwen Zhang, Xinxin Liu, Qing Yang, Yang Yang, Fan Qi, Shengsheng Qian, Changsheng Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=T3RD:+Test-Time+Training+for+Rumor+Detection+on+Social+Media)|0|
|[ESCNet: Entity-enhanced and Stance Checking Network for Multi-modal Fact-Checking](https://doi.org/10.1145/3589334.3645455)|Fanrui Zhang, Jiawei Liu, Jingyi Xie, Qiang Zhang, Yongchao Xu, ZhengJun Zha||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ESCNet:+Entity-enhanced+and+Stance+Checking+Network+for+Multi-modal+Fact-Checking)|0|
|[Labor Space: A Unifying Representation of the Labor Market via Large Language Models](https://doi.org/10.1145/3589334.3645464)|Seongwoon Kim, YongYeol Ahn, Jaehyuk Park||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Labor+Space:+A+Unifying+Representation+of+the+Labor+Market+via+Large+Language+Models)|0|
|[Explainable Fake News Detection with Large Language Model via Defense Among Competing Wisdom](https://doi.org/10.1145/3589334.3645471)|Bo Wang, Jing Ma, Hongzhan Lin, Zhiwei Yang, Ruichao Yang, Yuan Tian, Yi Chang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Explainable+Fake+News+Detection+with+Large+Language+Model+via+Defense+Among+Competing+Wisdom)|0|
|[Navigating the Post-API Dilemma](https://doi.org/10.1145/3589334.3645503)|Amrit Poudel, Tim Weninger||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Navigating+the+Post-API+Dilemma)|0|
|[Unraveling the Dynamics of Stable and Curious Audiences in Web Systems](https://doi.org/10.1145/3589334.3645473)|Rodrigo Alves, Antoine Ledent, Renato Assunção, Pedro O. S. Vaz de Melo, Marius Kloft||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unraveling+the+Dynamics+of+Stable+and+Curious+Audiences+in+Web+Systems)|0|
|[SymLearn: A Symbiotic Crowd-AI Collective Learning Framework to Web-based Healthcare Policy Adherence Assessment](https://doi.org/10.1145/3589334.3645519)|Yang Zhang, Ruohan Zong, Lanyu Shang, Huimin Zeng, Zhenrui Yue, Dong Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SymLearn:+A+Symbiotic+Crowd-AI+Collective+Learning+Framework+to+Web-based+Healthcare+Policy+Adherence+Assessment)|0|
|[An Efficient Automatic Meta-Path Selection for Social Event Detection via Hyperbolic Space](https://doi.org/10.1145/3589334.3645526)|Zitai Qiu, Congbo Ma, Jia Wu, Jian Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=An+Efficient+Automatic+Meta-Path+Selection+for+Social+Event+Detection+via+Hyperbolic+Space)|0|
|[NETEVOLVE: Social Network Forecasting using Multi-Agent Reinforcement Learning with Interpretable Features](https://doi.org/10.1145/3589334.3647982)|Kentaro Miyake, Hiroyoshi Ito, Christos Faloutsos, Hirotomo Matsumoto, Atsuyuki Morishima||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NETEVOLVE:+Social+Network+Forecasting+using+Multi-Agent+Reinforcement+Learning+with+Interpretable+Features)|0|
|[Analysis and Detection of "Pink Slime" Websites in Social Media Posts](https://doi.org/10.1145/3589334.3645588)|Abdullah Aljebreen, Weiyi Meng, Eduard C. Dragut||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Analysis+and+Detection+of+"Pink+Slime"+Websites+in+Social+Media+Posts)|0|
|[Navigating Multidimensional Ideologies with Reddit's Political Compass: Economic Conflict and Social Affinity](https://doi.org/10.1145/3589334.3645606)|Ernesto Colacrai, Federico Cinus, Gianmarco De Francisci Morales, Michele Starnini||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Navigating+Multidimensional+Ideologies+with+Reddit's+Political+Compass:+Economic+Conflict+and+Social+Affinity)|0|
|[Unifying Local and Global Knowledge: Empowering Large Language Models as Political Experts with Knowledge Graphs](https://doi.org/10.1145/3589334.3645616)|Xinyi Mou, Zejun Li, Hanjia Lyu, Jiebo Luo, Zhongyu Wei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unifying+Local+and+Global+Knowledge:+Empowering+Large+Language+Models+as+Political+Experts+with+Knowledge+Graphs)|0|
|[Not All Asians are the Same: A Disaggregated Approach to Identifying Anti-Asian Racism in Social Media](https://doi.org/10.1145/3589334.3645630)|Fan Wu, Sanyam Lakhanpal, Qian Li, Kookjin Lee, Doowon Kim, Heewon Chae, Kyounghee Hazel Kwon||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Not+All+Asians+are+the+Same:+A+Disaggregated+Approach+to+Identifying+Anti-Asian+Racism+in+Social+Media)|0|
|[Global News Synchrony and Diversity During the Start of the COVID-19 Pandemic](https://doi.org/10.1145/3589334.3645645)|Xi Chen, Scott A. Hale, David Jurgens, Mattia Samory, Ethan Zuckerman, Przemyslaw A. Grabowicz||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Global+News+Synchrony+and+Diversity+During+the+Start+of+the+COVID-19+Pandemic)|0|
|[Better to Ask in English: Cross-Lingual Evaluation of Large Language Models for Healthcare Queries](https://doi.org/10.1145/3589334.3645643)|Yiqiao Jin, Mohit Chandra, Gaurav Verma, Yibo Hu, Munmun De Choudhury, Srijan Kumar||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Better+to+Ask+in+English:+Cross-Lingual+Evaluation+of+Large+Language+Models+for+Healthcare+Queries)|0|
|[Bridging or Breaking: Impact of Intergroup Interactions on Religious Polarization](https://doi.org/10.1145/3589334.3645675)|Rochana Chaturvedi, Sugat Chaturvedi, Elena Zheleva||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Bridging+or+Breaking:+Impact+of+Intergroup+Interactions+on+Religious+Polarization)|0|
|[ARES: Predictable Traffic Engineering under Controller Failures in SD-WANs](https://doi.org/10.1145/3589334.3645321)|Songshi Dou, Li Qi, Zehua Guo||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=ARES:+Predictable+Traffic+Engineering+under+Controller+Failures+in+SD-WANs)|0|
|[QUIC is not Quick Enough over Fast Internet](https://doi.org/10.1145/3589334.3645323)|Xumiao Zhang, Shuowei Jin, Yi He, Ahmad Hassan, Z. Morley Mao, Feng Qian, ZhiLi Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=QUIC+is+not+Quick+Enough+over+Fast+Internet)|0|
|[GEES: Enabling Location Privacy-Preserving Energy Saving in Multi-Access Edge Computing](https://doi.org/10.1145/3589334.3645329)|Ziqi Wang, Xiaoyu Xia, Minhui Xue, Ibrahim Khalil, Minghui Liwang, Xun Yi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GEES:+Enabling+Location+Privacy-Preserving+Energy+Saving+in+Multi-Access+Edge+Computing)|0|
|[DirectFaaS: A Clean-Slate Network Architecture for Efficient Serverless Chain Communications](https://doi.org/10.1145/3589334.3645333)|Qingyang Zeng, Kaiyu Hou, Xue Leng, Yan Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DirectFaaS:+A+Clean-Slate+Network+Architecture+for+Efficient+Serverless+Chain+Communications)|0|
|[Meet Challenges of RTT Jitter, A Hybrid Internet Congestion Control Algorithm](https://doi.org/10.1145/3589334.3645338)|Lianchen Jia, Chao Zhou, Tianchi Huang, Chaoyang Li, Lifeng Sun||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Meet+Challenges+of+RTT+Jitter,+A+Hybrid+Internet+Congestion+Control+Algorithm)|0|
|[Towards Energy-efficient Federated Learning via INT8-based Training on Mobile DSPs](https://doi.org/10.1145/3589334.3645341)|Jinliang Yuan, Shangguang Wang, Hongyu Li, Daliang Xu, Yuanchun Li, Mengwei Xu, Xuanzhe Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Energy-efficient+Federated+Learning+via+INT8-based+Training+on+Mobile+DSPs)|0|
|[FreqMAE: Frequency-Aware Masked Autoencoder for Multi-Modal IoT Sensing](https://doi.org/10.1145/3589334.3645346)|Denizhan Kara, Tomoyoshi Kimura, Shengzhong Liu, Jinyang Li, Dongxin Liu, Tianshi Wang, Ruijie Wang, Yizhuo Chen, Yigong Hu, Tarek F. Abdelzaher||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FreqMAE:+Frequency-Aware+Masked+Autoencoder+for+Multi-Modal+IoT+Sensing)|0|
|[Air-CAD: Edge-Assisted Multi-Drone Network for Real-time Crowd Anomaly Detection](https://doi.org/10.1145/3589334.3645362)|Yuanzheng Tan, Qing Li, Junkun Peng, Zhenhui Yuan, Yong Jiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Air-CAD:+Edge-Assisted+Multi-Drone+Network+for+Real-time+Crowd+Anomaly+Detection)|0|
|[λGrapher: A Resource-Efficient Serverless System for GNN Serving through Graph Sharing](https://doi.org/10.1145/3589334.3645383)|Haichuan Hu, Fangming Liu, Qiangyu Pei, Yongjie Yuan, Zichen Xu, Lin Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=λGrapher:+A+Resource-Efficient+Serverless+System+for+GNN+Serving+through+Graph+Sharing)|0|
|[SPRING: Improving the Throughput of Sharding Blockchain via Deep Reinforcement Learning Based State Placement](https://doi.org/10.1145/3589334.3645386)|Pengze Li, Mingxuan Song, Mingzhe Xing, Zhen Xiao, Qiuyu Ding, Shengjie Guan, Jieyi Long||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SPRING:+Improving+the+Throughput+of+Sharding+Blockchain+via+Deep+Reinforcement+Learning+Based+State+Placement)|0|
|[Supervised Fine-Tuning for Unsupervised KPI Anomaly Detection for Mobile Web Systems](https://doi.org/10.1145/3589334.3645392)|Zhaoyang Yu, Shenglin Zhang, Mingze Sun, Yingke Li, Yankai Zhao, Xiaolei Hua, Lin Zhu, Xidao Wen, Dan Pei||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Supervised+Fine-Tuning+for+Unsupervised+KPI+Anomaly+Detection+for+Mobile+Web+Systems)|0|
|[NCTM: A Novel Coded Transmission Mechanism for Short Video Deliveries](https://doi.org/10.1145/3589334.3645387)|Zhenge Xu, Qing Li, Wanxin Shi, Yong Jiang, Zhenhui Yuan, Peng Zhang, GabrielMiro Muntean||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NCTM:+A+Novel+Coded+Transmission+Mechanism+for+Short+Video+Deliveries)|0|
|[InArt: In-Network Aggregation with Route Selection for Accelerating Distributed Training](https://doi.org/10.1145/3589334.3645394)|Jiawei Liu, Yutong Zhai, Gongming Zhao, Hongli Xu, Jin Fang, Zhen Zeng, Ying Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=InArt:+In-Network+Aggregation+with+Route+Selection+for+Accelerating+Distributed+Training)|0|
|[FusionRender: Harnessing WebGPU's Power for Enhanced Graphics Performance on Web Browsers](https://doi.org/10.1145/3589334.3645395)|Weichen Bi, Yun Ma, Yudong Han, Yifan Chen, Deyu Tian, Jiaqi Du||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FusionRender:+Harnessing+WebGPU's+Power+for+Enhanced+Graphics+Performance+on+Web+Browsers)|0|
|[FedDSE: Distribution-aware Sub-model Extraction for Federated Learning over Resource-constrained Devices](https://doi.org/10.1145/3589334.3645416)|Haozhao Wang, Yabo Jia, Meng Zhang, Qinghao Hu, Hao Ren, Peng Sun, Yonggang Wen, Tianwei Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=FedDSE:+Distribution-aware+Sub-model+Extraction+for+Federated+Learning+over+Resource-constrained+Devices)|0|
|[BlockDFL: A Blockchain-based Fully Decentralized Peer-to-Peer Federated Learning Framework](https://doi.org/10.1145/3589334.3645425)|Zhen Qin, Xueqiang Yan, Mengchu Zhou, Shuiguang Deng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=BlockDFL:+A+Blockchain-based+Fully+Decentralized+Peer-to-Peer+Federated+Learning+Framework)|0|
|[Incentive and Dynamic Client Selection for Federated Unlearning](https://doi.org/10.1145/3589334.3645462)|Yijing Lin, Zhipeng Gao, Hongyang Du, Dusit Niyato, Jiawen Kang, Xiaoyuan Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Incentive+and+Dynamic+Client+Selection+for+Federated+Unlearning)|0|
|[Accelerating the Decentralized Federated Learning via Manipulating Edges](https://doi.org/10.1145/3589334.3645509)|Mingyang Zhou, Gang Liu, Kezhong Lu, Rui Mao, Hao Liao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Accelerating+the+Decentralized+Federated+Learning+via+Manipulating+Edges)|0|
|[How Few Davids Improve One Goliath: Federated Learning in Resource-Skewed Edge Computing Environments](https://doi.org/10.1145/3589334.3645544)|Jiayun Zhang, Shuheng Li, Haiyu Huang, Zihan Wang, Xiaohan Fu, Dezhi Hong, Rajesh K. Gupta, Jingbo Shang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=How+Few+Davids+Improve+One+Goliath:+Federated+Learning+in+Resource-Skewed+Edge+Computing+Environments)|0|
|[Privacy-Preserving and Fairness-Aware Federated Learning for Critical Infrastructure Protection and Resilience](https://doi.org/10.1145/3589334.3645545)|Yanjun Zhang, Ruoxi Sun, Liyue Shen, Guangdong Bai, Minhui Xue, Mark Huasong Meng, Xue Li, Ryan K. L. Ko, Surya Nepal||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Privacy-Preserving+and+Fairness-Aware+Federated+Learning+for+Critical+Infrastructure+Protection+and+Resilience)|0|
|[Making Cloud Spot Instance Interruption Events Visible](https://doi.org/10.1145/3589334.3645548)|Kyunghwan Kim, Kyungyong Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Making+Cloud+Spot+Instance+Interruption+Events+Visible)|0|
|[E2Usd: Efficient-yet-effective Unsupervised State Detection for Multivariate Time Series](https://doi.org/10.1145/3589334.3645593)|Zhichen Lai, Huan Li, Dalin Zhang, Yan Zhao, Weizhu Qian, Christian S. Jensen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=E2Usd:+Efficient-yet-effective+Unsupervised+State+Detection+for+Multivariate+Time+Series)|0|
|[Robust Route Planning under Uncertain Pickup Requests for Last-mile Delivery](https://doi.org/10.1145/3589334.3645595)|Hua Yan, Heng Tan, Haotian Wang, Desheng Zhang, Yu Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Robust+Route+Planning+under+Uncertain+Pickup+Requests+for+Last-mile+Delivery)|0|
|[Unity is Strength? Benchmarking the Robustness of Fusion-based 3D Object Detection against Physical Sensor Attack](https://doi.org/10.1145/3589334.3645612)|Zizhi Jin, Xuancun Lu, Bo Yang, Yushi Cheng, Chen Yan, Xiaoyu Ji, Wenyuan Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unity+is+Strength?+Benchmarking+the+Robustness+of+Fusion-based+3D+Object+Detection+against+Physical+Sensor+Attack)|0|
|[WEFix: Intelligent Automatic Generation of Explicit Waits for Efficient Web End-to-End Flaky Tests](https://doi.org/10.1145/3589334.3645628)|Xinyue Liu, Zihe Song, Weike Fang, Wei Yang, Weihang Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=WEFix:+Intelligent+Automatic+Generation+of+Explicit+Waits+for+Efficient+Web+End-to-End+Flaky+Tests)|0|
|[SatGuard: Concealing Endless and Bursty Packet Losses in LEO Satellite Networks for Delay-Sensitive Web Applications](https://doi.org/10.1145/3589334.3645639)|Jihao Li, Hewu Li, Zeqi Lai, Qian Wu, Yijie Liu, Qi Zhang, Yuanjie Li, Jun Liu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SatGuard:+Concealing+Endless+and+Bursty+Packet+Losses+in+LEO+Satellite+Networks+for+Delay-Sensitive+Web+Applications)|0|
|[More Than Routing: Joint GPS and Route Modeling for Refine Trajectory Representation Learning](https://doi.org/10.1145/3589334.3645644)|Zhipeng Ma, Zheyan Tu, Xinhai Chen, Yan Zhang, Deguo Xia, Guyue Zhou, Yilun Chen, Yu Zheng, Jiangtao Gong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=More+Than+Routing:+Joint+GPS+and+Route+Modeling+for+Refine+Trajectory+Representation+Learning)|0|
|[Cardinality Counting in "Alcatraz": A Privacy-aware Federated Learning Approach](https://doi.org/10.1145/3589334.3645655)|Nan Wu, Xin Yuan, Shuo Wang, Hongsheng Hu, Minhui Xue||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Cardinality+Counting+in+"Alcatraz":+A+Privacy-aware+Federated+Learning+Approach)|0|
|[GAMMA: Graph Neural Network-Based Multi-Bottleneck Localization for Microservices Applications](https://doi.org/10.1145/3589334.3645665)|Gagan Somashekar, Anurag Dutt, Mainak Adak, Tania LoridoBotran, Anshul Gandhi||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GAMMA:+Graph+Neural+Network-Based+Multi-Bottleneck+Localization+for+Microservices+Applications)|0|
|[Revisiting VAE for Unsupervised Time Series Anomaly Detection: A Frequency Perspective](https://doi.org/10.1145/3589334.3645710)|Zexin Wang, Changhua Pei, Minghua Ma, Xin Wang, Zhihan Li, Dan Pei, Saravan Rajmohan, Dongmei Zhang, Qingwei Lin, Haiming Zhang, Jianhui Li, Gaogang Xie||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Revisiting+VAE+for+Unsupervised+Time+Series+Anomaly+Detection:+A+Frequency+Perspective)|0|
|[Interpretable Knowledge Tracing with Multiscale State Representation](https://doi.org/10.1145/3589334.3645373)|Jianwen Sun, Fenghua Yu, Qian Wan, Qing Li, Sannyuya Liu, Xiaoxuan Shen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Interpretable+Knowledge+Tracing+with+Multiscale+State+Representation)|0|
|[COLA: Cross-city Mobility Transformer for Human Trajectory Simulation](https://doi.org/10.1145/3589334.3645469)|Yu Wang, Tongya Zheng, Yuxuan Liang, Shunyu Liu, Mingli Song||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=COLA:+Cross-city+Mobility+Transformer+for+Human+Trajectory+Simulation)|0|
|[Off-Policy Evaluation for Large Action Spaces via Policy Convolution](https://doi.org/10.1145/3589334.3645501)|Noveen Sachdeva, Lequn Wang, Dawen Liang, Nathan Kallus, Julian J. McAuley||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Off-Policy+Evaluation+for+Large+Action+Spaces+via+Policy+Convolution)|0|
|[LFDe: A Lighter, Faster and More Data-Efficient Pre-training Framework for Event Extraction](https://doi.org/10.1145/3589334.3645318)|Zhigang Kan, Liwen Peng, Yifu Gao, Ning Liu, Linbo Qiao, Dongsheng Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LFDe:+A+Lighter,+Faster+and+More+Data-Efficient+Pre-training+Framework+for+Event+Extraction)|0|
|[Multi-Scenario Pricing for Hotel Revenue Management](https://doi.org/10.1145/3589334.3645350)|Wendong Xiao, Shuqi Zhang, Zhiyi Huang, Yao Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multi-Scenario+Pricing+for+Hotel+Revenue+Management)|0|
|[Collaboration-Aware Hybrid Learning for Knowledge Development Prediction](https://doi.org/10.1145/3589334.3645326)|Liyi Chen, Chuan Qin, Ying Sun, Xin Song, Tong Xu, Hengshu Zhu, Hui Xiong||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Collaboration-Aware+Hybrid+Learning+for+Knowledge+Development+Prediction)|0|
|[Span-Pair Interaction and Tagging for Dialogue-Level Aspect-Based Sentiment Quadruple Analysis](https://doi.org/10.1145/3589334.3645355)|Changzhi Zhou, Zhijing Wu, Dandan Song, Linmei Hu, Yuhang Tian, Jing Xu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Span-Pair+Interaction+and+Tagging+for+Dialogue-Level+Aspect-Based+Sentiment+Quadruple+Analysis)|0|
|[UrbanCLIP: Learning Text-enhanced Urban Region Profiling with Contrastive Language-Image Pretraining from the Web](https://doi.org/10.1145/3589334.3645378)|Yibo Yan, Haomin Wen, Siru Zhong, Wei Chen, Haodong Chen, Qingsong Wen, Roger Zimmermann, Yuxuan Liang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=UrbanCLIP:+Learning+Text-enhanced+Urban+Region+Profiling+with+Contrastive+Language-Image+Pretraining+from+the+Web)|0|
|[MCFEND: A Multi-source Benchmark Dataset for Chinese Fake News Detection](https://doi.org/10.1145/3589334.3645385)|Yupeng Li, Haorui He, Jin Bai, Dacheng Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MCFEND:+A+Multi-source+Benchmark+Dataset+for+Chinese+Fake+News+Detection)|0|
|[LinkNER: Linking Local Named Entity Recognition Models to Large Language Models using Uncertainty](https://doi.org/10.1145/3589334.3645414)|Zhen Zhang, Yuhua Zhao, Hang Gao, Mengting Hu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LinkNER:+Linking+Local+Named+Entity+Recognition+Models+to+Large+Language+Models+using+Uncertainty)|0|
|[RicciNet: Deep Clustering via A Riemannian Generative Model](https://doi.org/10.1145/3589334.3645428)|Li Sun, Jingbin Hu, Suyang Zhou, Zhenhao Huang, Junda Ye, Hao Peng, Zhengtao Yu, Philip S. Yu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RicciNet:+Deep+Clustering+via+A+Riemannian+Generative+Model)|0|
|[Weakly Supervised Anomaly Detection via Knowledge-Data Alignment](https://doi.org/10.1145/3589334.3645429)|Haihong Zhao, Chenyi Zi, Yang Liu, Chen Zhang, Yan Zhou, Jia Li||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Weakly+Supervised+Anomaly+Detection+via+Knowledge-Data+Alignment)|0|
|[MULAN: Multi-modal Causal Structure Learning and Root Cause Analysis for Microservice Systems](https://doi.org/10.1145/3589334.3645442)|Lecheng Zheng, Zhengzhang Chen, Jingrui He, Haifeng Chen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MULAN:+Multi-modal+Causal+Structure+Learning+and+Root+Cause+Analysis+for+Microservice+Systems)|0|
|[Dynamic Multi-Network Mining of Tensor Time Series](https://doi.org/10.1145/3589334.3645461)|Kohei Obata, Koki Kawabata, Yasuko Matsubara, Yasushi Sakurai||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Dynamic+Multi-Network+Mining+of+Tensor+Time+Series)|0|
|[MSynFD: Multi-hop Syntax Aware Fake News Detection](https://doi.org/10.1145/3589334.3645468)|Liang Xiao, Qi Zhang, Chongyang Shi, Shoujin Wang, Usman Naseem, Liang Hu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MSynFD:+Multi-hop+Syntax+Aware+Fake+News+Detection)|0|
|[LARA: A Light and Anti-overfitting Retraining Approach for Unsupervised Time Series Anomaly Detection](https://doi.org/10.1145/3589334.3645472)|Feiyi Chen, Zhen Qin, Mengchu Zhou, Yingying Zhang, Shuiguang Deng, Lunting Fan, Guansong Pang, Qingsong Wen||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=LARA:+A+Light+and+Anti-overfitting+Retraining+Approach+for+Unsupervised+Time+Series+Anomaly+Detection)|0|
|[Markovletics: Methods and A Novel Application for Learning Continuous-Time Markov Chain Mixtures](https://doi.org/10.1145/3589334.3645491)|Fabian Spaeh, Charalampos E. Tsourakakis||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Markovletics:+Methods+and+A+Novel+Application+for+Learning+Continuous-Time+Markov+Chain+Mixtures)|0|
|[NAT4AT: Using Non-Autoregressive Translation Makes Autoregressive Translation Faster and Better](https://doi.org/10.1145/3589334.3645527)|Huanran Zheng, Wei Zhu, Xiaoling Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=NAT4AT:+Using+Non-Autoregressive+Translation+Makes+Autoregressive+Translation+Faster+and+Better)|0|
|[Breaking the Time-Frequency Granularity Discrepancy in Time-Series Anomaly Detection](https://doi.org/10.1145/3589334.3645556)|Youngeun Nam, Susik Yoon, Yooju Shin, Minyoung Bae, Hwanjun Song, JaeGil Lee, Byung Suk Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Breaking+the+Time-Frequency+Granularity+Discrepancy+in+Time-Series+Anomaly+Detection)|0|
|[Question Difficulty Consistent Knowledge Tracing](https://doi.org/10.1145/3589334.3645582)|Guimei Liu, Huijing Zhan, Jungjae Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Question+Difficulty+Consistent+Knowledge+Tracing)|0|
|[A Simple but Effective Approach for Unsupervised Few-Shot Graph Classification](https://doi.org/10.1145/3589334.3645587)|Yonghao Liu, Lan Huang, Bowen Cao, Ximing Li, Fausto Giunchiglia, Xiaoyue Feng, Renchu Guan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=A+Simple+but+Effective+Approach+for+Unsupervised+Few-Shot+Graph+Classification)|0|
|[Inductive Cognitive Diagnosis for Fast Student Learning in Web-Based Intelligent Education Systems](https://doi.org/10.1145/3589334.3645589)|Shuo Liu, Junhao Shen, Hong Qian, Aimin Zhou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Inductive+Cognitive+Diagnosis+for+Fast+Student+Learning+in+Web-Based+Intelligent+Education+Systems)|0|
|[RulePrompt: Weakly Supervised Text Classification with Prompting PLMs and Self-Iterative Logical Rules](https://doi.org/10.1145/3589334.3645602)|Miaomiao Li, Jiaqi Zhu, Yang Wang, Yi Yang, Yilin Li, Hongan Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=RulePrompt:+Weakly+Supervised+Text+Classification+with+Prompting+PLMs+and+Self-Iterative+Logical+Rules)|0|
|[Multimodal Relation Extraction via a Mixture of Hierarchical Visual Context Learners](https://doi.org/10.1145/3589334.3645603)|Xiyang Liu, Chunming Hu, Richong Zhang, Kai Sun, Samuel Mensah, Yongyi Mao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Multimodal+Relation+Extraction+via+a+Mixture+of+Hierarchical+Visual+Context+Learners)|0|
|[Diagrammatic Reasoning for ALC Visualization with Logic Graphs](https://doi.org/10.1145/3589334.3645607)|Ildar Baimuratov||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Diagrammatic+Reasoning+for+ALC+Visualization+with+Logic+Graphs)|0|
|[Learning to Generate Explainable Stock Predictions using Self-Reflective Large Language Models](https://doi.org/10.1145/3589334.3645611)|Kelvin J. L. Koa, Yunshan Ma, Ritchie Ng, TatSeng Chua||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Learning+to+Generate+Explainable+Stock+Predictions+using+Self-Reflective+Large+Language+Models)|0|
|[High-Frequency-aware Hierarchical Contrastive Selective Coding for Representation Learning on Text Attributed Graphs](https://doi.org/10.1145/3589334.3645614)|Peiyan Zhang, Chaozhuo Li, Liying Kang, Feiran Huang, Senzhang Wang, Xing Xie, Sunghun Kim||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=High-Frequency-aware+Hierarchical+Contrastive+Selective+Coding+for+Representation+Learning+on+Text+Attributed+Graphs)|0|
|[Distributed Data Placement and Content Delivery in Web Caches with Non-Metric Access Costs](https://doi.org/10.1145/3589334.3645654)|||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Distributed+Data+Placement+and+Content+Delivery+in+Web+Caches+with+Non-Metric+Access+Costs)|0|
|[DualCL: Principled Supervised Contrastive Learning as Mutual Information Maximization for Text Classification](https://doi.org/10.1145/3589334.3645668)|Junfan Chen, Richong Zhang, Yaowei Zheng, Qianben Chen, Chunming Hu, Yongyi Mao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DualCL:+Principled+Supervised+Contrastive+Learning+as+Mutual+Information+Maximization+for+Text+Classification)|0|
|[Graph Anomaly Detection with Bi-level Optimization](https://doi.org/10.1145/3589334.3645673)|Yuan Gao, Junfeng Fang, Yongduo Sui, Yangyang Li, Xiang Wang, Huamin Feng, Yongdong Zhang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Graph+Anomaly+Detection+with+Bi-level+Optimization)|0|
|[AN-Net: an Anti-Noise Network for Anonymous Traffic Classification](https://doi.org/10.1145/3589334.3645691)|Xianwen Deng, Yijun Wang, Zhi Xue||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=AN-Net:+an+Anti-Noise+Network+for+Anonymous+Traffic+Classification)|0|
|[DenseFlow: Spotting Cryptocurrency Money Laundering in Ethereum Transaction Graphs](https://doi.org/10.1145/3589334.3645692)|Dan Lin, Jiajing Wu, Yunmei Yu, Qishuang Fu, Zibin Zheng, Changlin Yang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=DenseFlow:+Spotting+Cryptocurrency+Money+Laundering+in+Ethereum+Transaction+Graphs)|0|
|[Towards Cross-Table Masked Pretraining for Web Data Mining](https://doi.org/10.1145/3589334.3645707)|Chao Ye, Guoshan Lu, Haobo Wang, Liyao Li, Sai Wu, Gang Chen, Junbo Zhao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Towards+Cross-Table+Masked+Pretraining+for+Web+Data+Mining)|0|
|[Beyond Labels and Topics: Discovering Causal Relationships in Neural Topic Modeling](https://doi.org/10.1145/3589334.3645715)|YiKun Tang, Heyan Huang, Xuewen Shi, XianLing Mao||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Beyond+Labels+and+Topics:+Discovering+Causal+Relationships+in+Neural+Topic+Modeling)|0|
|[HD-KT: Advancing Robust Knowledge Tracing via Anomalous Learning Interaction Detection](https://doi.org/10.1145/3589334.3645718)|Haiping Ma, Yong Yang, Chuan Qin, Xiaoshan Yu, Shangshang Yang, Xingyi Zhang, Hengshu Zhu||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=HD-KT:+Advancing+Robust+Knowledge+Tracing+via+Anomalous+Learning+Interaction+Detection)|0|
|[MentaLLaMA: Interpretable Mental Health Analysis on Social Media with Large Language Models](https://doi.org/10.1145/3589334.3648137)|Kailai Yang, Tianlin Zhang, Ziyan Kuang, Qianqian Xie, Jimin Huang, Sophia Ananiadou||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MentaLLaMA:+Interpretable+Mental+Health+Analysis+on+Social+Media+with+Large+Language+Models)|0|
|[Message Injection Attack on Rumor Detection under the Black-Box Evasion Setting Using Large Language Model](https://doi.org/10.1145/3589334.3648139)|Yifeng Luo, Yupeng Li, Dacheng Wen, Liang Lan||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Message+Injection+Attack+on+Rumor+Detection+under+the+Black-Box+Evasion+Setting+Using+Large+Language+Model)|0|
|[Human vs ChatGPT: Effect of Data Annotation in Interpretable Crisis-Related Microblog Classification](https://doi.org/10.1145/3589334.3648141)|Thi Huyen Nguyen, Koustav Rudra||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Human+vs+ChatGPT:+Effect+of+Data+Annotation+in+Interpretable+Crisis-Related+Microblog+Classification)|0|
|[Contrastive Learning for Multimodal Classification of Crisis related Tweets](https://doi.org/10.1145/3589334.3648143)|Bishwas Mandal, Sarthak Khanal, Doina Caragea||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Contrastive+Learning+for+Multimodal+Classification+of+Crisis+related+Tweets)|0|
|[Modularized Networks for Few-shot Hateful Meme Detection](https://doi.org/10.1145/3589334.3648145)|Rui Cao, Roy KaWei Lee, Jing Jiang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Modularized+Networks+for+Few-shot+Hateful+Meme+Detection)|0|
|[CapAlign: Improving Cross Modal Alignment via Informative Captioning for Harmful Meme Detection](https://doi.org/10.1145/3589334.3648146)|Junhui Ji, Xuanrui Lin, Usman Naseem||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=CapAlign:+Improving+Cross+Modal+Alignment+via+Informative+Captioning+for+Harmful+Meme+Detection)|0|
|[Unveiling Climate Drivers via Feature Importance Shift Analysis in New Zealand](https://doi.org/10.1145/3589334.3648147)|Bowen Chen, Gillian Dobbie, Neelesh Rampal, Yun Sing Koh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Unveiling+Climate+Drivers+via+Feature+Importance+Shift+Analysis+in+New+Zealand)|0|
|[Causal Graph ODE: Continuous Treatment Effect Modeling in Multi-agent Dynamical Systems](https://doi.org/10.1145/3589334.3648148)|Zijie Huang, Jeehyun Hwang, Junkai Zhang, Jinwoo Baik, Weitong Zhang, Dominik Wodarz, Yizhou Sun, Quanquan Gu, Wei Wang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Causal+Graph+ODE:+Continuous+Treatment+Effect+Modeling+in+Multi-agent+Dynamical+Systems)|0|
|[SceneDAPR: A Scene-Level Free-Hand Drawing Dataset for Web-based Psychological Drawing Assessment](https://doi.org/10.1145/3589334.3648150)|Jiwon Kang, Jiwon Kim, Migyeong Yang, Chaehee Park, Taeeun Kim, Hayeon Song, Jinyoung Han||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=SceneDAPR:+A+Scene-Level+Free-Hand+Drawing+Dataset+for+Web-based+Psychological+Drawing+Assessment)|0|
|[MemeCraft: Contextual and Stance-Driven Multimodal Meme Generation](https://doi.org/10.1145/3589334.3648151)|Han Wang, Roy KaWei Lee||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=MemeCraft:+Contextual+and+Stance-Driven+Multimodal+Meme+Generation)|0|
|[Infrastructure Ombudsman: Mining Future Failure Concerns from Structural Disaster Response](https://doi.org/10.1145/3589334.3648153)|Md Towhidul Absar Chowdhury, Soumyajit Datta, Naveen Sharma, Ashiqur R. KhudaBukhsh||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Infrastructure+Ombudsman:+Mining+Future+Failure+Concerns+from+Structural+Disaster+Response)|0|
|[Predicting and Presenting Task Difficulty for Crowdsourcing Food Rescue Platforms](https://doi.org/10.1145/3589334.3648155)|Zheyuan Ryan Shi, Jiayin Zhi, Siqi Zeng, Zhicheng Zhang, Ameesh Kapoor, Sean Hudson, Hong Shen, Fei Fang||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=Predicting+and+Presenting+Task+Difficulty+for+Crowdsourcing+Food+Rescue+Platforms)|0|
|[GraphLeak: Patient Record Leakage through Gradients with Knowledge Graph](https://doi.org/10.1145/3589334.3648157)|Xi Sheryl Zhang, Weifan Guan, Jiahao Lu, Zhaopeng Qiu, Jian Cheng, Xian Wu, Yefeng Zheng||||[code](https://paperswithcode.com/search?q_meta=&q_type=&q=GraphLeak:+Patient+Record+Leakage+through+Gradients+with+Knowledge+Graph)|0|

import re
import ast
import os
import random
import json
import argparse
import requests
import datetime
import sys
import re

# æ·»åŠ å½“å‰ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# ç›´æ¥å®šä¹‰é…ç½®é¡¹
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
# è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆå‘ä¸Šä¸¤å±‚ï¼‰
PROJECT_ROOT = os.path.dirname(os.path.dirname(BASE_DIR))
DATA_DIR = os.path.join(BASE_DIR, "data")
ARTICLE_CSV_FILE = os.path.join(DATA_DIR, "article.csv")
ARTICLE_JSON_FILE = os.path.join(DATA_DIR, "article.json")
# æ­£ç¡®æŒ‡å‘æ ¹ç›®å½•çš„README.md
README_FILE = os.path.join(PROJECT_ROOT, "README.md")

FEISHU_URL = os.environ.get("FEISHU_URL", None)

def set_args():
    parser = argparse.ArgumentParser()
    parser.add_argument("--issue", "-i", type=str, help="input issue JSON string", required=False)
    parser.add_argument("--file", "-f", type=str, help="input issue JSON file", required=False)
    args = parser.parse_args()
    
    # ç¡®ä¿è‡³å°‘æä¾›äº†ä¸€ä¸ªå‚æ•°
    if not args.issue and not args.file:
        parser.error("Either --issue or --file must be provided")
        
    # å¦‚æœæä¾›äº†æ–‡ä»¶å‚æ•°ï¼Œè¯»å–æ–‡ä»¶å†…å®¹
    if args.file:
        try:
            with open(args.file, 'r', encoding='utf-8') as f:
                args.issue = f.read()
        except Exception as e:
            parser.error(f"Failed to read file {args.file}: {e}")
            
    return args


def parse_issue(issue):
    try:
        issue = issue.replace("\\n", "").replace("\\r", "")
        info = ast.literal_eval(issue)
        print(info)
        assert isinstance(info, list)
        assert len(info) > 0 and info[0].get("å…¬å¸") and info[0].get("å†…å®¹") and info[0].get("æ ‡ç­¾") and info[0].get("æ—¶é—´") and info[0].get("é“¾æ¥")
    except:
        raise Exception("[-] Wrong input!")
    return info

def update_json_and_csv(args):
    """æ›´æ–°JSONå’ŒCSVæ–‡ä»¶ä¸­çš„æ–‡ç« æ•°æ®
    
    è¯»å–ç°æœ‰çš„JSONå’ŒCSVæ–‡ä»¶ï¼Œæ·»åŠ æ–°çš„æ–‡ç« æ•°æ®ï¼Œå¹¶ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
    """
    print("[+] å¼€å§‹æ›´æ–°JSONå’ŒCSVæ–‡ä»¶...")
    
    try:
        # è§£ææ–°çš„æ–‡ç« æ•°æ®
        new_items = parse_issue(args.issue)
        print(f"[+] è§£æåˆ° {len(new_items)} æ¡æ–°æ–‡ç« æ•°æ®")
        
        # è¯»å–ç°æœ‰çš„JSONæ•°æ®
        existing_json_data = []
        if os.path.exists(ARTICLE_JSON_FILE):
            with open(ARTICLE_JSON_FILE, 'r', encoding='utf-8') as f:
                existing_json_data = json.load(f)
        
        # è¯»å–ç°æœ‰çš„CSVæ•°æ®
        existing_csv_data = []
        if os.path.exists(ARTICLE_CSV_FILE):
            with open(ARTICLE_CSV_FILE, 'r', encoding='utf-8') as f:
                import csv
                reader = csv.DictReader(f)
                existing_csv_data = list(reader)
        
        # å¤„ç†å¹¶æ·»åŠ æ–°çš„æ•°æ®
        for item in new_items:
            # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨ç›¸åŒçš„æ–‡ç« 
            is_duplicate = False
            for existing_item in existing_json_data:
                if existing_item.get('link') == item.get('é“¾æ¥') or existing_item.get('title') == item.get('å†…å®¹'):
                    is_duplicate = True
                    print(f"[-] è·³è¿‡é‡å¤æ–‡ç« : {item.get('å†…å®¹')}")
                    break
            
            if not is_duplicate:
                # æ ¼å¼åŒ–JSONæ•°æ®
                json_item = {
                    "company": item.get('å…¬å¸'),
                    "link": item.get('é“¾æ¥'),
                    "title": item.get('å†…å®¹'),
                    "tags": [tag.strip() for tag in item.get('æ ‡ç­¾').split(',')],
                    "date": item.get('æ—¶é—´')
                }
                existing_json_data.append(json_item)
                
                # æ ¼å¼åŒ–CSVæ•°æ®
                csv_item = {
                    "å…¬å¸": item.get('å…¬å¸'),
                    "é“¾æ¥": item.get('é“¾æ¥'),
                    "æ ‡é¢˜": item.get('å†…å®¹'),
                    "æ ‡ç­¾": item.get('æ ‡ç­¾'),
                    "æ—¥æœŸ": item.get('æ—¶é—´')
                }
                existing_csv_data.append(csv_item)
                
                print(f"[+] æ·»åŠ æ–°æ–‡ç« : {item.get('å†…å®¹')}")
        
        # æŒ‰æ—¶é—´æ’åºæ•°æ®ï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        existing_json_data.sort(key=lambda x: get_sortable_date(x.get("date", x.get("æ—¶é—´", ""))), reverse=True)
        existing_csv_data.sort(key=lambda x: get_sortable_date(x["æ—¥æœŸ"]), reverse=True)
        
        # ä¿å­˜æ›´æ–°åçš„JSONæ–‡ä»¶
        with open(ARTICLE_JSON_FILE, 'w', encoding='utf-8') as f:
            json.dump(existing_json_data, f, ensure_ascii=False, indent=2)
        print(f"[+] JSONæ–‡ä»¶æ›´æ–°æˆåŠŸ: {ARTICLE_JSON_FILE}")
        
        # ä¿å­˜æ›´æ–°åçš„CSVæ–‡ä»¶
        with open(ARTICLE_CSV_FILE, 'w', encoding='utf-8', newline='') as f:
            fieldnames = ['å…¬å¸', 'é“¾æ¥', 'æ ‡é¢˜', 'æ ‡ç­¾', 'æ—¥æœŸ']
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(existing_csv_data)
        print(f"[+] CSVæ–‡ä»¶æ›´æ–°æˆåŠŸ: {ARTICLE_CSV_FILE}")
        
        return True
    except Exception as e:
        print(f"[-] æ›´æ–°JSONå’ŒCSVæ–‡ä»¶å¤±è´¥: {e}")
        import traceback
        print(f"[-] é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        return False

def get_sortable_date(date_str):
    """å°†æ—¥æœŸå­—ç¬¦ä¸²è½¬æ¢ä¸ºå¯æ’åºçš„æ ¼å¼
    
    Args:
        date_str: æ—¥æœŸå­—ç¬¦ä¸²
    
    Returns:
        str: æ ‡å‡†æ ¼å¼çš„æ—¥æœŸå­—ç¬¦ä¸²
    """
    try:
        # å¤„ç†æ ¼å¼ï¼šYYYY-MM-DD
        if len(date_str) == 10 and '-' in date_str:
            return date_str
        # å¤„ç†æ ¼å¼ï¼šYYYY.MM.DD
        elif len(date_str) == 10 and '.' in date_str:
            return date_str.replace('.', '-')
        # å¤„ç†æ ¼å¼ï¼šMM/DD/YYYY
        elif len(date_str) == 10 and '/' in date_str:
            parts = date_str.split('/')
            if len(parts) == 3:
                return f"{parts[2]}-{parts[0]}-{parts[1]}"
        # å¤„ç†æ ¼å¼ï¼šYYYYå¹´MMæœˆDDæ—¥
        elif len(date_str) >= 8 and 'å¹´' in date_str and 'æœˆ' in date_str:
            year = date_str.split('å¹´')[0]
            month_part = date_str.split('å¹´')[1].split('æœˆ')[0]
            day_part = date_str.split('æœˆ')[1].split('æ—¥')[0] if 'æ—¥' in date_str else date_str.split('æœˆ')[1]
            return f"{year}-{month_part.zfill(2)}-{day_part.zfill(2)}"
        # å¤„ç†æ ¼å¼ï¼šMM-DD-YY
        elif len(date_str) == 8 and '-' in date_str:
            parts = date_str.split('-')
            if len(parts) == 3 and len(parts[2]) == 2:
                return f"20{parts[2]}-{parts[0]}-{parts[1]}"
        # é»˜è®¤è¿”å›å½“å‰æ—¥æœŸ
        return datetime.datetime.now().strftime('%Y-%m-%d')
    except Exception as e:
        print(f"æ—¥æœŸæ ¼å¼è½¬æ¢é”™è¯¯: {date_str}, {e}")
        return datetime.datetime.now().strftime('%Y-%m-%d')

def update_readme(args, info=None):
    print("[+] Add new items into readme...")
    if info is None:
        info = parse_issue(args.issue)
    with open(README_FILE, "r", encoding="utf-8") as f:
        lines = f.readlines()

    # æŸ¥æ‰¾è¡¨æ ¼ä½ç½®
    table_title = "## å¤§å‚å®è·µæ–‡ç« "
    table_index = None
    for i, line in enumerate(lines):
        if line.strip() == table_title:
            table_index = i
            break

    # å¦‚æœæ‰¾åˆ°è¡¨æ ¼ä½ç½®ï¼Œåˆ™æ›´æ–°è¡¨æ ¼
    if table_index is not None:
        j = table_index + 2
        while j < len(lines) and not re.search(r"\|(\s-+\s\|)+", lines[j]):
            j += 1
        index = j + 1
        newlines = []
        for item in info:
            newline = "".join("| {} | [{}]({}) | {} | {} |\n".format(
                item["å…¬å¸"], item["å†…å®¹"], item["é“¾æ¥"], item["æ ‡ç­¾"], item["æ—¶é—´"]))
            newlines.append(newline)
        lines = lines[:index] + newlines + lines[index:]
        with open(README_FILE, "w", encoding="utf-8") as f:
            f.writelines(lines)
        print("[+] Add items Done!")
    else:
        print("[-] Table not found!")

def update_message(args):
    "æ›´æ–°æ¶ˆæ¯é€šçŸ¥"
    print("[+] å¼€å§‹æ›´æ–°æ¶ˆæ¯é€šçŸ¥...")
    
    try:
        # å¦‚æœæ²¡æœ‰è®¾ç½®FEISHU_URLï¼Œè·³è¿‡å‘é€æ¶ˆæ¯
        if not FEISHU_URL:
            print("[-] FEISHU_URLæœªè®¾ç½®ï¼Œè·³è¿‡å‘é€æ¶ˆæ¯")
            return
        
        # è§£æissueæ•°æ®
        infos = parse_issue(args.issue)
        print(f"[+] è§£æåˆ° {len(infos)} æ¡æ–°æ–‡ç« æ•°æ®")
        
        today = datetime.datetime.now().strftime('%Y-%m-%d')
        title = f"ğŸŒ¸å¤§å‚å®è·µæ–‡ç« è‡ªåŠ¨æ›´æ–°@{today}"
        content = []
        for info in infos:
            emoji = random.choice("ğŸŒ±ğŸŒ¿ğŸ€ğŸª´ğŸ‹ğŸƒğŸª·ğŸŒ¸âœ¨")
            meta_info = f"ğŸ¥¹ {info['å…¬å¸']}  ğŸ“† {info['æ—¶é—´']}  ğŸ‰ {info['æ ‡ç­¾']}"
            info_title = f"âœ… {info['å†…å®¹']}"
            line_len = max(len(meta_info), len(info_title))
            sepline = emoji * line_len
            content.append(
                [{
                    "tag": "text",
                    "text": ""
                }]
            )
            # content.append(
            #     [{
            #         "tag": "text",
            #         "text": sepline
            #     }]
            # )
            # content.append(
            #     [{
            #         "tag": "text",
            #         "text": ""
            #     }]
            # )
            content.append(
                [{
                    "tag": "text",
                    "text": meta_info
                }]
            )
            content.append(
                [{
                    "tag": "text",
                    "text": ""
                }]
            )
            content.append(
                [{
                    "tag": "a",
                    "text": info_title,
                    "href": f"{info['é“¾æ¥']}"
                }]
            )
            content.append(
                [{
                    "tag": "text",
                    "text": ""
                }]
            )
        content.append(
            [{
                "tag": "text",
                "text": "-----",
            }]
        )
        content.append(
            [{
                "tag": "a",
                "text": "â¡ï¸ ç‚¹å‡»æŸ¥çœ‹å®Œæ•´å¤§å‚å®è·µæ–‡ç« åˆ—è¡¨",
                "href": "https://github.com/Doragd/Algorithm-Practice-in-Industry"
            }]
        )
        send_feishu_message(title, content, url=FEISHU_URL)
        print("[+] æ¶ˆæ¯é€šçŸ¥å‘é€æˆåŠŸï¼")
    except Exception as e:
        print(f"[-] æ›´æ–°æ¶ˆæ¯é€šçŸ¥å¤±è´¥: {e}")
        import traceback
        print(f"[-] é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")

def send_feishu_message(title, content, url=FEISHU_URL):
    raw_data = {
        "msg_type": "post",
        "content": {
            "post": {
                "zh_cn": {
                    "title": title,
                    "content": content
                }
            }
        }
    }  
    body = json.dumps(raw_data)
    headers = {"Content-Type":"application/json"}
    ret = requests.post(url=url, data=body, headers=headers)
    print(ret.text)



def update_industry_practice_page():
    """æ›´æ–°å¤§å‚å®è·µæ–‡ç« é¡µé¢
    
    è°ƒç”¨generate_industry_html.pyç”ŸæˆHTMLé¡µé¢
    """
    print("[+] å¼€å§‹æ›´æ–°å¤§å‚å®è·µæ–‡ç« é¡µé¢...")
    
    try:
        import os
        import sys
        import subprocess
        
        # ä½¿ç”¨subprocessè¿è¡Œgenerate_industry_html.pyï¼Œä¸ä¼ é€’ä»»ä½•å‚æ•°
        script_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "generate_industry_html.py")
        result = subprocess.run([sys.executable, script_path], capture_output=True, text=True)
        
        if result.returncode == 0:
            print("[+] æ›´æ–°å¤§å‚å®è·µæ–‡ç« é¡µé¢æˆåŠŸ!")
            return True
        else:
            print(f"[-] æ›´æ–°å¤§å‚å®è·µæ–‡ç« é¡µé¢å¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
            print(f"[-] é”™è¯¯è¾“å‡º: {result.stderr}")
            return False
    except Exception as e:
        print(f"[-] æ›´æ–°å¤§å‚å®è·µæ–‡ç« é¡µé¢å¤±è´¥: {e}")
        import traceback
        print(f"[-] é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        return False

def main():
    args = set_args()
    update_json_and_csv(args)
    update_readme(args)
    update_message(args)
    update_industry_practice_page()

if __name__ == "__main__":
    main()
